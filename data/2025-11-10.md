<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 67]
- [cs.AI](#cs.AI) [Total: 8]
- [cs.DC](#cs.DC) [Total: 3]
- [cs.GR](#cs.GR) [Total: 3]
- [cs.SE](#cs.SE) [Total: 9]
- [cs.RO](#cs.RO) [Total: 26]
- [cs.DS](#cs.DS) [Total: 4]
- [cs.NI](#cs.NI) [Total: 7]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [IndicVisionBench: Benchmarking Cultural and Multilingual Understanding in VLMs](https://arxiv.org/abs/2511.04727)
*Ali Faraz,Akash,Shaharukh Khan,Raja Kolla,Akshat Patidar,Suranjan Goswami,Abhinav Ravi,Chandra Khatri,Shubham Agarwal*

Main category: cs.CV

TL;DR: IndicVisionBench是首个以印度次大陆为中心的大规模多模态基准测试，涵盖英语和10种印度语言，评估3种任务（OCR、MMT、VQA），揭示当前视觉语言模型在文化多样性语境中的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型的评估基准多为西方中心，缺乏对文化多样性和多语言环境的考察，因此研究团队开发了IndicVisionBench以填补这一空白。

Method: 构建包含约5K图像和37K+问答对的基准测试，覆盖13个文化主题，并发布10种印度语言的平行标注语料库，评估8种不同规模的模型。

Result: 实验显示当前视觉语言模型在文化多样性语境中存在显著性能差距。

Conclusion: IndicVisionBench为多模态研究提供了可复现的评估框架，推动更具包容性的模型发展。

Abstract: Vision-language models (VLMs) have demonstrated impressive generalization
across multimodal tasks, yet most evaluation benchmarks remain Western-centric,
leaving open questions about their performance in culturally diverse and
multilingual settings. To address this gap, we introduce IndicVisionBench, the
first large-scale benchmark centered on the Indian subcontinent. Covering
English and 10 Indian languages, our benchmark spans 3 multimodal tasks,
including Optical Character Recognition (OCR), Multimodal Machine Translation
(MMT), and Visual Question Answering (VQA), covering 6 kinds of question types.
Our final benchmark consists of a total of ~5K images and 37K+ QA pairs across
13 culturally grounded topics. In addition, we release a paired parallel corpus
of annotations across 10 Indic languages, creating a unique resource for
analyzing cultural and linguistic biases in VLMs. We evaluate a broad spectrum
of 8 models, from proprietary closed-source systems to open-weights medium and
large-scale models. Our experiments reveal substantial performance gaps,
underscoring the limitations of current VLMs in culturally diverse contexts. By
centering cultural diversity and multilinguality, IndicVisionBench establishes
a reproducible evaluation framework that paves the way for more inclusive
multimodal research.

</details>


### [2] [Knowledge-based anomaly detection for identifying network-induced shape artifacts](https://arxiv.org/abs/2511.04729)
*Rucha Deshpande,Tahsin Rahman,Miguel Lago,Adarsh Subbaswamy,Jana G. Delfino,Ghada Zamzmi,Elim Thompson,Aldo Badano,Seyed Kahaki*

Main category: cs.CV

TL;DR: 提出基于知识的异常检测方法，有效识别合成图像中的网络诱导形状伪影，提升合成数据质量。


<details>
  <summary>Details</summary>
Motivation: 合成数据训练机器学习模型时可能引入伪影和失真，影响模型性能和临床效用，需质量评估方法。

Method: 两阶段框架：1）新型特征提取器通过分析解剖边界角度梯度的每图像分布构建专用特征空间；2）基于隔离森林的异常检测器。

Result: 在CSAW-M和VinDr-Mammo数据集上，AUC值分别为0.97和0.91，人类读者与算法检测结果一致性显著。

Conclusion: 该方法为负责任地使用合成数据提供了重要工具，能够评估合成图像是否符合解剖学约束，从而提升合成数据集质量。

Abstract: Synthetic data provides a promising approach to address data scarcity for
training machine learning models; however, adoption without proper quality
assessments may introduce artifacts, distortions, and unrealistic features that
compromise model performance and clinical utility. This work introduces a novel
knowledge-based anomaly detection method for detecting network-induced shape
artifacts in synthetic images. The introduced method utilizes a two-stage
framework comprising (i) a novel feature extractor that constructs a
specialized feature space by analyzing the per-image distribution of angle
gradients along anatomical boundaries, and (ii) an isolation forest-based
anomaly detector. We demonstrate the effectiveness of the method for
identifying network-induced shape artifacts in two synthetic mammography
datasets from models trained on CSAW-M and VinDr-Mammo patient datasets
respectively. Quantitative evaluation shows that the method successfully
concentrates artifacts in the most anomalous partition (1st percentile), with
AUC values of 0.97 (CSAW-syn) and 0.91 (VMLO-syn). In addition, a reader study
involving three imaging scientists confirmed that images identified by the
method as containing network-induced shape artifacts were also flagged by human
readers with mean agreement rates of 66% (CSAW-syn) and 68% (VMLO-syn) for the
most anomalous partition, approximately 1.5-2 times higher than the least
anomalous partition. Kendall-Tau correlations between algorithmic and human
rankings were 0.45 and 0.43 for the two datasets, indicating reasonable
agreement despite the challenging nature of subtle artifact detection. This
method is a step forward in the responsible use of synthetic data, as it allows
developers to evaluate synthetic images for known anatomic constraints and
pinpoint and address specific issues to improve the overall quality of a
synthetic dataset.

</details>


### [3] [CPO: Condition Preference Optimization for Controllable Image Generation](https://arxiv.org/abs/2511.04753)
*Zonglin Lyu,Ming Li,Xinxin Liu,Chen Chen*

Main category: cs.CV

TL;DR: CPO通过直接优化控制信号偏好，显著提升文本到图像生成的可控性，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法（如ControlNet++）在优化过程中忽略高噪声时间步和引入近似误差的问题，以及DPO方法因生成模型不确定性导致的训练目标高方差问题。

Method: 提出了一种名为条件偏好优化（CPO）的方法，通过直接对控制信号进行偏好学习，避免了生成图像的不确定性，并降低了训练目标的方差。

Result: CPO在分割、人体姿态、边缘和深度地图等多种控制类型上，实现了10%至80%的错误率降低，显著优于ControlNet++。

Conclusion: CPO（条件偏好优化）显著提升了文本到图像生成中的可控性，优于现有技术ControlNet++，并在多种控制类型上展示了显著的性能提升。

Abstract: To enhance controllability in text-to-image generation, ControlNet introduces
image-based control signals, while ControlNet++ improves pixel-level cycle
consistency between generated images and the input control signal. To avoid the
prohibitive cost of back-propagating through the sampling process, ControlNet++
optimizes only low-noise timesteps (e.g., $t < 200$) using a single-step
approximation, which not only ignores the contribution of high-noise timesteps
but also introduces additional approximation errors. A straightforward
alternative for optimizing controllability across all timesteps is Direct
Preference Optimization (DPO), a fine-tuning method that increases model
preference for more controllable images ($I^{w}$) over less controllable ones
($I^{l}$). However, due to uncertainty in generative models, it is difficult to
ensure that win--lose image pairs differ only in controllability while keeping
other factors, such as image quality, fixed. To address this, we propose
performing preference learning over control conditions rather than generated
images. Specifically, we construct winning and losing control signals,
$\mathbf{c}^{w}$ and $\mathbf{c}^{l}$, and train the model to prefer
$\mathbf{c}^{w}$. This method, which we term \textit{Condition Preference
Optimization} (CPO), eliminates confounding factors and yields a low-variance
training objective. Our approach theoretically exhibits lower contrastive loss
variance than DPO and empirically achieves superior results. Moreover, CPO
requires less computation and storage for dataset curation. Extensive
experiments show that CPO significantly improves controllability over the
state-of-the-art ControlNet++ across multiple control types: over $10\%$ error
rate reduction in segmentation, $70$--$80\%$ in human pose, and consistent
$2$--$5\%$ reductions in edge and depth maps.

</details>


### [4] [DARN: Dynamic Adaptive Regularization Networks for Efficient and Robust Foundation Model Adaptation](https://arxiv.org/abs/2511.04766)
*Dhenenjay Yadav,Rohan Sawai*

Main category: cs.CV

TL;DR: DARN是一种新型解码器架构，通过动态调整模型复杂度，显著提升了地理空间基础模型的适应性和性能。


<details>
  <summary>Details</summary>
Motivation: 传统的地理空间分析模型采用固定的正则化策略，无法应对卫星图像的显著异构性，DARN旨在解决这一局限性。

Method: DARN结合了三个关键创新：轻量级任务复杂度预测器（TCP）、自适应丢弃调制（ADM）和动态容量门控（DCG），动态调整模型复杂度以提高适应性。

Result: DARN在完全微调（86.66% mIoU）和高效适应（90.5% mIoU）中均达到SOTA性能，同时表现出优异的OOD泛化能力和鲁棒性。

Conclusion: DARN提出了一种智能、鲁棒且高效的方法，用于在关键地理空间应用中利用基础模型，显著提升了性能和多任务适应性。

Abstract: Foundation models (FMs) offer powerful representations for geospatial
analysis, but adapting them effectively remains challenging. Standard
adaptation methods, whether full fine-tuning or efficient frozen-backbone
approaches, typically employ decoders with fixed regularization strategies,
failing to account for the significant heterogeneity in satellite imagery. We
introduce Dynamic Adaptive Regularization Networks (DARN), a novel decoder
architecture designed to address this limitation. DARN integrates three key
innovations: (1) a lightweight Task Complexity Predictor (TCP) that estimates
per-sample difficulty, (2) Adaptive Dropout Modulation (ADM), dynamically
adjusting dropout rates (from 0.1 to 0.5) based on predicted complexity, and
(3) Dynamic Capacity Gating (DCG) that modulates channel activation. We provide
theoretical justifications linking DARN's optimization to stationary point
convergence and its mechanism to adaptive information bottlenecks. Empirically,
DARN demonstrates exceptional performance across both major adaptation
paradigms. In full fine-tuning (unfrozen backbone), DARN achieves a new
state-of-the-art on the multi-task GeoBench benchmark (86.66% mIoU, +5.56 pp
over prior SOTA). In efficient adaptation (frozen backbone), DARN achieves
SOTA-competitive accuracy (90.5% mIoU on Sen1Floods11) while delivering
substantial advantages crucial for real-world deployment: superior
out-of-distribution (OOD) generalization (+9.5 pp mIoU on AI4SmallFarms),
enhanced robustness (17% relative reduction in corruption error), and improved
performance on minority classes. DARN offers a more intelligent, robust, and
efficient approach to leveraging FMs in critical geospatial applications.

</details>


### [5] [Splatography: Sparse multi-view dynamic Gaussian Splatting for filmmaking challenges](https://arxiv.org/abs/2511.05152)
*Adrian Azzarelli,Nantheera Anantrasirichai,David R Bull*

Main category: cs.CV

TL;DR: 通过分割前景和背景高斯表示，新方法在稀疏相机配置下实现了更高效的动态3D重建，性能优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 解决在低成本稀疏相机配置下，现有方法难以捕捉复杂动态特征的问题。

Method: 该方法将规范高斯表示和变形场分割为前景和背景组件，并使用不同的损失函数进行训练。前景学习颜色、位置和旋转变化，背景仅学习位置变化。

Result: 在3D和2.5D娱乐数据集上，该方法在PSNR上提升了3分，模型大小减半，并能生成分割的动态重建结果。

Conclusion: Deformable Gaussian Splatting (GS) 方法通过在稀疏相机配置下分割前景和背景高斯表示，显著提升了动态3D重建的质量和效率，且在模型大小和性能上优于现有技术。

Abstract: Deformable Gaussian Splatting (GS) accomplishes photorealistic dynamic 3-D
reconstruction from dense multi-view video (MVV) by learning to deform a
canonical GS representation. However, in filmmaking, tight budgets can result
in sparse camera configurations, which limits state-of-the-art (SotA) methods
when capturing complex dynamic features. To address this issue, we introduce an
approach that splits the canonical Gaussians and deformation field into
foreground and background components using a sparse set of masks for frames at
t=0. Each representation is separately trained on different loss functions
during canonical pre-training. Then, during dynamic training, different
parameters are modeled for each deformation field following common filmmaking
practices. The foreground stage contains diverse dynamic features so changes in
color, position and rotation are learned. While, the background containing
film-crew and equipment, is typically dimmer and less dynamic so only changes
in point position are learned. Experiments on 3-D and 2.5-D entertainment
datasets show that our method produces SotA qualitative and quantitative
results; up to 3 PSNR higher with half the model size on 3-D scenes. Unlike the
SotA and without the need for dense mask supervision, our method also produces
segmented dynamic reconstructions including transparent and dynamic textures.
Code and video comparisons are available online:
https://interims-git.github.io/

</details>


### [6] [Global 3D Reconstruction of Clouds & Tropical Cyclones](https://arxiv.org/abs/2511.04773)
*Shirin Ermis,Cesar Aybar,Lilli Freischem,Stella Girtsou,Kyriaki-Margarita Bintsi,Emiliano Diaz Salas-Porras,Michael Eisinger,William Jones,Anna Jungbluth,Benoit Tremblay*

Main category: cs.CV

TL;DR: 新机器学习框架通过预训练-微调流程，将2D卫星图像转化为3D云图，首次实现全球强风暴3D结构重建，提升TC预报能力。


<details>
  <summary>Details</summary>
Motivation: 热带气旋（TC）的准确预报因卫星观测有限及云属性解析困难而具挑战性。现有机器学习方法局限于TC罕见区域且对强风暴验证不足。

Method: 基于预训练-微调流程的新框架，利用多颗全球覆盖卫星数据将2D卫星图像转化为3D云图，并在自定义TC数据集上评估性能。

Result: 模型能生成全球瞬时3D云图，并准确重建强风暴的3D结构，填补观测缺失时的数据空白。

Conclusion: 该模型首次实现了全球瞬时3D云图生成，并准确重建强风暴的3D结构，不仅扩展了卫星观测能力，还能在观测缺失时提供估计，这对提升热带气旋（TC）强度理解和预报至关重要。

Abstract: Accurate forecasting of tropical cyclones (TCs) remains challenging due to
limited satellite observations probing TC structure and difficulties in
resolving cloud properties involved in TC intensification. Recent research has
demonstrated the capabilities of machine learning methods for 3D cloud
reconstruction from satellite observations. However, existing approaches have
been restricted to regions where TCs are uncommon, and are poorly validated for
intense storms. We introduce a new framework, based on a
pre-training--fine-tuning pipeline, that learns from multiple satellites with
global coverage to translate 2D satellite imagery into 3D cloud maps of
relevant cloud properties. We apply our model to a custom-built TC dataset to
evaluate performance in the most challenging and relevant conditions. We show
that we can - for the first time - create global instantaneous 3D cloud maps
and accurately reconstruct the 3D structure of intense storms. Our model not
only extends available satellite observations but also provides estimates when
observations are missing entirely. This is crucial for advancing our
understanding of TC intensification and improving forecasts.

</details>


### [7] [EETnet: a CNN for Gaze Detection and Tracking for Smart-Eyewear](https://arxiv.org/abs/2511.04779)
*Andrea Aspesi,Andrea Simpsi,Aaron Tognoli,Simone Mentasti,Luca Merigo,Matteo Matteucci*

Main category: cs.CV

TL;DR: EETnet是一种用于事件数据眼追踪的轻量级CNN，可在微控制器上运行，并提供分类和回归两种模型。


<details>
  <summary>Details</summary>
Motivation: 事件相机因其稀疏和异步的数据特性，具有低功耗和低延迟优势，但现有解决方案多依赖高性能GPU，无法在嵌入式设备上部署。

Method: 提出两种架构版本：一种是基于网格的分类模型，用于检测瞳孔；另一种是基于像素级的回归模型。

Result: EETnet能够在微控制器上高效运行，并通过公开数据集验证了方法的可行性。

Conclusion: 本文提出了EETnet，一种专为事件数据设计的卷积神经网络，能够在资源有限的微控制器上运行。此外，还介绍了训练、评估和量化网络的方法。

Abstract: Event-based cameras are becoming a popular solution for efficient, low-power
eye tracking. Due to the sparse and asynchronous nature of event data, they
require less processing power and offer latencies in the microsecond range.
However, many existing solutions are limited to validation on powerful GPUs,
with no deployment on real embedded devices. In this paper, we present EETnet,
a convolutional neural network designed for eye tracking using purely
event-based data, capable of running on microcontrollers with limited
resources. Additionally, we outline a methodology to train, evaluate, and
quantize the network using a public dataset. Finally, we propose two versions
of the architecture: a classification model that detects the pupil on a grid
superimposed on the original image, and a regression model that operates at the
pixel level.

</details>


### [8] [3D Gaussian Point Encoders](https://arxiv.org/abs/2511.04797)
*Jim James,Ben Wilson,Simon Lucey,James Hays*

Main category: cs.CV

TL;DR: 提出 3D Gaussian Point Encoders，通过优化技术和计算几何启发式方法，实现比 PointNet 更快的速度和更高的参数效率，适用于 CPU-only 设备。


<details>
  <summary>Details</summary>
Motivation: 提出显式的 3D 高斯点编码器，以替代广泛使用的隐式表示（如 PointNet），解决端到端学习 3D 高斯编码器的困难。

Method: 基于自然梯度和从 PointNet 蒸馏的优化技术，开发了能重建 PointNet 激活的 Gaussian Basis，并利用计算几何启发式方法进一步加速。

Result: 3D Gaussian Point Encoders 比 PointNet 快 2.7 倍，内存和 FLOPs 分别减少 46% 和 88%；在 Mamba3D 中速度快 1.27 倍，内存和 FLOPs 分别减少 42% 和 54%。

Conclusion: 3D Gaussian Point Encoders 在速度和参数效率上优于传统 PointNet，适用于 CPU-only 设备的高帧率应用。

Abstract: In this work, we introduce the 3D Gaussian Point Encoder, an explicit
per-point embedding built on mixtures of learned 3D Gaussians. This explicit
geometric representation for 3D recognition tasks is a departure from widely
used implicit representations such as PointNet. However, it is difficult to
learn 3D Gaussian encoders in end-to-end fashion with standard optimizers. We
develop optimization techniques based on natural gradients and distillation
from PointNets to find a Gaussian Basis that can reconstruct PointNet
activations. The resulting 3D Gaussian Point Encoders are faster and more
parameter efficient than traditional PointNets. As in the 3D reconstruction
literature where there has been considerable interest in the move from implicit
(e.g., NeRF) to explicit (e.g., Gaussian Splatting) representations, we can
take advantage of computational geometry heuristics to accelerate 3D Gaussian
Point Encoders further. We extend filtering techniques from 3D Gaussian
Splatting to construct encoders that run 2.7 times faster as a comparable
accuracy PointNet while using 46% less memory and 88% fewer FLOPs. Furthermore,
we demonstrate the effectiveness of 3D Gaussian Point Encoders as a component
in Mamba3D, running 1.27 times faster and achieving a reduction in memory and
FLOPs by 42% and 54% respectively. 3D Gaussian Point Encoders are lightweight
enough to achieve high framerates on CPU-only devices.

</details>


### [9] [Data Efficiency and Transfer Robustness in Biomedical Image Segmentation: A Study of Redundancy and Forgetting with Cellpose](https://arxiv.org/abs/2511.04803)
*Shuo Zhao,Jianxu Chen*

Main category: cs.CV

TL;DR: 研究发现生物医学图像分割中数据冗余显著，仅需少量数据即可达到性能饱和。跨领域迁移时，选择性重放源数据可有效缓解灾难性遗忘，而完整重放则可能适得其反。


<details>
  <summary>Details</summary>
Motivation: 探索通用生物医学图像分割模型（如Cellpose）在多样化成像模态和细胞类型应用中的两大未充分研究的挑战：训练数据冗余和跨领域迁移对模型保留的影响。

Method: 本研究采用简单的数据集量化（DQ）策略构建紧凑且多样的训练子集，并通过潜在空间分析和跨领域微调实验来评估数据冗余和灾难性遗忘的影响。

Result: 实验显示，仅使用10%的数据即可达到图像分割性能饱和，表明数据存在显著冗余。跨领域微调实验中，选择性DQ重放能有效恢复源领域性能，而完整的重放可能阻碍目标领域适应。

Conclusion: 研究强调了在生物医学图像分割中数据为中心设计的重要性，提出高效训练不仅需要紧凑的数据子集，还需要具有保留意识的学习策略和明智的领域顺序安排。

Abstract: Generalist biomedical image segmentation models such as Cellpose are
increasingly applied across diverse imaging modalities and cell types. However,
two critical challenges remain underexplored: (1) the extent of training data
redundancy and (2) the impact of cross domain transfer on model retention. In
this study, we conduct a systematic empirical analysis of these challenges
using Cellpose as a case study. First, to assess data redundancy, we propose a
simple dataset quantization (DQ) strategy for constructing compact yet diverse
training subsets. Experiments on the Cyto dataset show that image segmentation
performance saturates with only 10% of the data, revealing substantial
redundancy and potential for training with minimal annotations. Latent space
analysis using MAE embeddings and t-SNE confirms that DQ selected patches
capture greater feature diversity than random sampling. Second, to examine
catastrophic forgetting, we perform cross domain finetuning experiments and
observe significant degradation in source domain performance, particularly when
adapting from generalist to specialist domains. We demonstrate that selective
DQ based replay reintroducing just 5-10% of the source data effectively
restores source performance, while full replay can hinder target adaptation.
Additionally, we find that training domain sequencing improves generalization
and reduces forgetting in multi stage transfer. Our findings highlight the
importance of data centric design in biomedical image segmentation and suggest
that efficient training requires not only compact subsets but also retention
aware learning strategies and informed domain ordering. The code is available
at https://github.com/MMV-Lab/biomedseg-efficiency.

</details>


### [10] [An Active Learning Pipeline for Biomedical Image Instance Segmentation with Minimal Human Intervention](https://arxiv.org/abs/2511.04811)
*Shuo Zhao,Yu Zhou,Jianxu Chen*

Main category: cs.CV

TL;DR: 研究提出了一种结合主动学习和伪标签的AI工作流程，减少了生物医学图像分割对手动标注的依赖，性能仍具竞争力。


<details>
  <summary>Details</summary>
Motivation: 解决生物医学图像分割中传统方法对噪声敏感、nnU-Net需要大量标注数据进行交叉验证，以及大型基础模型在特定数据集上表现不佳的问题。

Method: 研究提出了一种结合主动学习和伪标签的工作流程：首先利用基础模型生成伪标签，用于nnU-Net的自配置；随后选择代表性核心集进行少量手动标注，以微调nnU-Net模型。

Result: 该方法显著减少了对手动标注的需求，同时保持了与现有技术竞争的性能，为生物医学研究人员提供了可访问的先进AI分割解决方案。

Conclusion: 该研究提出了一种数据中心的AI工作流程，结合主动学习和伪标签技术，有效减少了生物医学图像分割任务中对大量手动标注的依赖，同时保持了较高的分割性能。

Abstract: Biomedical image segmentation is critical for precise structure delineation
and downstream analysis. Traditional methods often struggle with noisy data,
while deep learning models such as U-Net have set new benchmarks in
segmentation performance. nnU-Net further automates model configuration, making
it adaptable across datasets without extensive tuning. However, it requires a
substantial amount of annotated data for cross-validation, posing a challenge
when only raw images but no labels are available. Large foundation models offer
zero-shot generalizability, but may underperform on specific datasets with
unique characteristics, limiting their direct use for analysis. This work
addresses these bottlenecks by proposing a data-centric AI workflow that
leverages active learning and pseudo-labeling to combine the strengths of
traditional neural networks and large foundation models while minimizing human
intervention. The pipeline starts by generating pseudo-labels from a foundation
model, which are then used for nnU-Net's self-configuration. Subsequently, a
representative core-set is selected for minimal manual annotation, enabling
effective fine-tuning of the nnU-Net model. This approach significantly reduces
the need for manual annotations while maintaining competitive performance,
providing an accessible solution for biomedical researchers to apply
state-of-the-art AI techniques in their segmentation tasks. The code is
available at https://github.com/MMV-Lab/AL_BioMed_img_seg.

</details>


### [11] [Geometry Denoising with Preferred Normal Vectors](https://arxiv.org/abs/2511.04848)
*Manuel Weiß,Lukas Baumgärtner,Roland Herzog,Stephan Schmidt*

Main category: cs.CV

TL;DR: 提出基于标签向量的几何去噪新方法，结合分割和正则化，采用ADMM优化。


<details>
  <summary>Details</summary>
Motivation: 利用表面法向量的先验知识（标签向量）进行几何去噪，并自然嵌入分割过程。

Method: 采用分割Bregman（ADMM）方法解决优化问题，顶点更新步骤基于二阶形状微积分。

Result: 该方法通过标签向量相似性和总变分正则化，实现了有效的几何去噪和分割。

Conclusion: 论文提出了一种基于标签向量的几何去噪新方法，通过分割和正则化实现了高效的去噪效果。

Abstract: We introduce a new paradigm for geometry denoising using prior knowledge
about the surface normal vector. This prior knowledge comes in the form of a
set of preferred normal vectors, which we refer to as label vectors. A
segmentation problem is naturally embedded in the denoising process. The
segmentation is based on the similarity of the normal vector to the elements of
the set of label vectors. Regularization is achieved by a total variation term.
We formulate a split Bregman (ADMM) approach to solve the resulting
optimization problem. The vertex update step is based on second-order shape
calculus.

</details>


### [12] [Self-Supervised Implicit Attention Priors for Point Cloud Reconstruction](https://arxiv.org/abs/2511.04864)
*Kyle Fogarty,Chenyue Cai,Jing Yang,Zhilin Guo,Cengiz Öztireli*

Main category: cs.CV

TL;DR: 提出了一种隐式自先验方法，通过联合训练嵌入字典与隐式距离场，从点云中提取先验并整合到RIMLS框架，显著提升了表面重建效果。


<details>
  <summary>Details</summary>
Motivation: 解决从不规则点云恢复高质量表面的病态问题，避免依赖外部训练数据。

Method: 联合训练一个小型可学习嵌入字典与隐式距离场，并通过交叉注意力机制捕获和重用形状中的重复结构和长程相关性。随后通过自动微分提取密集点云和分析法线，并整合到鲁棒隐式移动最小二乘（RIMLS）框架中。

Result: 实验表明，该方法在细节保留和鲁棒性方面优于传统和基于学习的方法。

Conclusion: 通过结合隐式自先验和隐式最小二乘方法，该方法在保留输入点云细节的同时，有效解决了稀疏区域的规整化问题，显著提升了表面重建的质量和鲁棒性。

Abstract: Recovering high-quality surfaces from irregular point cloud is ill-posed
unless strong geometric priors are available. We introduce an implicit
self-prior approach that distills a shape-specific prior directly from the
input point cloud itself and embeds it within an implicit neural
representation. This is achieved by jointly training a small dictionary of
learnable embeddings with an implicit distance field; at every query location,
the field attends to the dictionary via cross-attention, enabling the network
to capture and reuse repeating structures and long-range correlations inherent
to the shape. Optimized solely with self-supervised point cloud reconstruction
losses, our approach requires no external training data. To effectively
integrate this learned prior while preserving input fidelity, the trained field
is then sampled to extract densely distributed points and analytic normals via
automatic differentiation. We integrate the resulting dense point cloud and
corresponding normals into a robust implicit moving least squares (RIMLS)
formulation. We show this hybrid strategy preserves fine geometric details in
the input data, while leveraging the learned prior to regularize sparse
regions. Experiments show that our method outperforms both classical and
learning-based approaches in generating high-fidelity surfaces with superior
detail preservation and robustness to common data degradations.

</details>


### [13] [Clinical-ComBAT: a diffusion-weighted MRI harmonization method for clinical applications](https://arxiv.org/abs/2511.04871)
*Gabriel Girard,Manon Edde,Félix Dumais,Yoan David,Matthieu Dumont,Guillaume Theaud,Jean-Christophe Houde,Arnaud Boré,Maxime Descoteaux,Pierre-Marc Jodoin*

Main category: cs.CV

TL;DR: Clinical-ComBAT是一种针对多站点DW-MRI数据协调的改进方法，通过非线性建模和灵活协调策略，解决了现有方法的临床适用性问题。


<details>
  <summary>Details</summary>
Motivation: DW-MRI数据在多站点采集时存在扫描仪特异性偏差，现有ComBAT方法因线性协变量关系、同质群体等限制，难以适用于临床场景。

Method: Clinical-ComBAT通过独立协调每个站点、引入非线性多项式数据模型、基于规范站点的站点特定协调以及适用于小群体的方差先验，实现了灵活的数据协调。还包括超参数调优和协调评估的拟合优度指标。

Result: 在模拟和真实数据中，Clinical-ComBAT显著改善了扩散指标的协调性，并增强了规范建模的适用性。

Conclusion: Clinical-ComBAT 提供了一种适用于现实临床场景的灵活且高效的DW-MRI数据协调方法，克服了ComBAT的局限性，并在模拟和真实数据中验证了其有效性。

Abstract: Diffusion-weighted magnetic resonance imaging (DW-MRI) derived scalar maps
are effective for assessing neurodegenerative diseases and microstructural
properties of white matter in large number of brain conditions. However, DW-MRI
inherently limits the combination of data from multiple acquisition sites
without harmonization to mitigate scanner-specific biases. While the widely
used ComBAT method reduces site effects in research, its reliance on linear
covariate relationships, homogeneous populations, fixed site numbers, and well
populated sites constrains its clinical use. To overcome these limitations, we
propose Clinical-ComBAT, a method designed for real-world clinical scenarios.
Clinical-ComBAT harmonizes each site independently, enabling flexibility as new
data and clinics are introduced. It incorporates a non-linear polynomial data
model, site-specific harmonization referenced to a normative site, and variance
priors adaptable to small cohorts. It further includes hyperparameter tuning
and a goodness-of-fit metric for harmonization assessment. We demonstrate its
effectiveness on simulated and real data, showing improved alignment of
diffusion metrics and enhanced applicability for normative modeling.

</details>


### [14] [Validating Vision Transformers for Otoscopy: Performance and Data-Leakage Effects](https://arxiv.org/abs/2511.04872)
*James Ndubuisi,Fernando Auat,Marta Vallejo*

Main category: cs.CV

TL;DR: 研究比较了Swin变换器和ResNet在耳病诊断中的表现，初始结果优异但发现数据泄漏问题，校正后性能下降，强调了严格数据处理的重要性。


<details>
  <summary>Details</summary>
Motivation: 由于耳鼻喉专科医生的误诊率高达27%，提高诊断准确性至关重要。

Method: 研究使用了来自智利大学临床医院耳鼻喉科的真实世界数据集，包括耳镜检查视频。通过拉普拉斯和香农熵阈值选择帧，并移除空白帧。比较了Swin v1、Swin v2变换器模型和ResNet模型的性能。

Result: 初始结果显示Swin v1和Swin v2分别达到100%和99.1%的准确率，略优于ResNet模型（99.5%）。但发现数据泄漏问题后，校正后的准确率降至83%（Swin v1和v2）和82%（ResNet）。

Conclusion: 本研究强调了在机器学习研究中，尤其是医学应用中，严格数据处理的重要性。虽然视觉变换器显示出潜力，但必须在高级模型架构的优势与有效数据预处理之间找到最佳平衡，这是开发可靠的耳病诊断机器学习模型的关键。

Abstract: This study evaluates the efficacy of vision transformer models, specifically
Swin transformers, in enhancing the diagnostic accuracy of ear diseases
compared to traditional convolutional neural networks. With a reported 27%
misdiagnosis rate among specialist otolaryngologists, improving diagnostic
accuracy is crucial. The research utilised a real-world dataset from the
Department of Otolaryngology at the Clinical Hospital of the Universidad de
Chile, comprising otoscopic videos of ear examinations depicting various middle
and external ear conditions. Frames were selected based on the Laplacian and
Shannon entropy thresholds, with blank frames removed. Initially, Swin v1 and
Swin v2 transformer models achieved accuracies of 100% and 99.1%, respectively,
marginally outperforming the ResNet model (99.5%). These results surpassed
metrics reported in related studies. However, the evaluation uncovered a
critical data leakage issue in the preprocessing step, affecting both this
study and related research using the same raw dataset. After mitigating the
data leakage, model performance decreased significantly. Corrected accuracies
were 83% for both Swin v1 and Swin v2, and 82% for the ResNet model. This
finding highlights the importance of rigorous data handling in machine learning
studies, especially in medical applications. The findings indicate that while
vision transformers show promise, it is essential to find an optimal balance
between the benefits of advanced model architectures and those derived from
effective data preprocessing. This balance is key to developing a reliable
machine learning model for diagnosing ear diseases.

</details>


### [15] [Beta Distribution Learning for Reliable Roadway Crash Risk Assessment](https://arxiv.org/abs/2511.04886)
*Ahmad Elallaf,Nathan Jacobs,Xinyue Ye,Mei Chen,Gongbo Liang*

Main category: cs.CV

TL;DR: 新型地理空间深度学习框架通过卫星图像预测致命交通事故风险，提升召回率17-23%，提供不确定性感知输出，助力自动驾驶和城市规划。


<details>
  <summary>Details</summary>
Motivation: 传统交通安全研究常孤立分析风险因素，忽视空间复杂性；传统神经网络风险估计器缺乏模型不确定性表达，限制了关键决策的实用性。

Method: 利用卫星图像作为综合空间输入，构建地理空间深度学习框架，生成完整的Beta概率分布而非单一确定性输出，以捕捉致命事故风险的空间复杂性和环境交互。

Result: 模型在召回率（关键危险标记指标）上比基线提升17-23%，同时提供更优的校准性，支持从卫星图像中获取可靠且可解释的风险评估。

Conclusion: 本文提出了一种新型地理空间深度学习框架，通过卫星图像捕捉复杂空间模式和潜在环境风险因素，为致命交通事故风险提供准确且不确定性感知的预测，显著提升了召回率和校准性，为自动驾驶和城市规划提供了可扩展的工具。

Abstract: Roadway traffic accidents represent a global health crisis, responsible for
over a million deaths annually and costing many countries up to 3% of their
GDP. Traditional traffic safety studies often examine risk factors in
isolation, overlooking the spatial complexity and contextual interactions
inherent in the built environment. Furthermore, conventional Neural
Network-based risk estimators typically generate point estimates without
conveying model uncertainty, limiting their utility in critical
decision-making. To address these shortcomings, we introduce a novel geospatial
deep learning framework that leverages satellite imagery as a comprehensive
spatial input. This approach enables the model to capture the nuanced spatial
patterns and embedded environmental risk factors that contribute to fatal crash
risks. Rather than producing a single deterministic output, our model estimates
a full Beta probability distribution over fatal crash risk, yielding accurate
and uncertainty-aware predictions--a critical feature for trustworthy AI in
safety-critical applications. Our model outperforms baselines by achieving a
17-23% improvement in recall, a key metric for flagging potential dangers,
while delivering superior calibration. By providing reliable and interpretable
risk assessments from satellite imagery alone, our method enables safer
autonomous navigation and offers a highly scalable tool for urban planners and
policymakers to enhance roadway safety equitably and cost-effectively.

</details>


### [16] [Learning to Restore Multi-Degraded Images via Ingredient Decoupling and Task-Aware Path Adaptation](https://arxiv.org/abs/2511.04920)
*Hu Gao,Xiaoning Lei,Ying Zhang,Xichen Xu,Guannan Jiang,Lizhuang Ma*

Main category: cs.CV

TL;DR: IMDNet通过动态路径选择和成分解耦，有效处理多退化图像恢复问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的图像常受多种退化共同影响，现有方法多专注于单一退化，限制了实际应用效果。

Method: 提出了一种自适应的多退化图像恢复网络（IMDNet），包含退化成分解耦块（DIDBlock）、融合块（FBlock）和任务适应块（TABlock）。

Result: IMDNet在多退化恢复任务中性能优越，且在单一退化任务中表现竞争力。

Conclusion: IMDNet通过分离和动态适应多种退化成分，在多退化图像恢复任务中表现出色，同时在单一退化任务中保持竞争力。

Abstract: Image restoration (IR) aims to recover clean images from degraded
observations. Despite remarkable progress, most existing methods focus on a
single degradation type, whereas real-world images often suffer from multiple
coexisting degradations, such as rain, noise, and haze coexisting in a single
image, which limits their practical effectiveness. In this paper, we propose an
adaptive multi-degradation image restoration network that reconstructs images
by leveraging decoupled representations of degradation ingredients to guide
path selection. Specifically, we design a degradation ingredient decoupling
block (DIDBlock) in the encoder to separate degradation ingredients
statistically by integrating spatial and frequency domain information,
enhancing the recognition of multiple degradation types and making their
feature representations independent. In addition, we present fusion block
(FBlock) to integrate degradation information across all levels using learnable
matrices. In the decoder, we further introduce a task adaptation block
(TABlock) that dynamically activates or fuses functional branches based on the
multi-degradation representation, flexibly selecting optimal restoration paths
under diverse degradation conditions. The resulting tightly integrated
architecture, termed IMDNet, is extensively validated through experiments,
showing superior performance on multi-degradation restoration while maintaining
strong competitiveness on single-degradation tasks.

</details>


### [17] [A benchmark multimodal oro-dental dataset for large vision-language models](https://arxiv.org/abs/2511.04948)
*Haoxin Lv,Ijazul Haq,Jin Du,Jiaxin Ma,Binnian Zhu,Xiaobing Dang,Chaoan Liang,Ruxu Du,Yingjie Zhang,Muhammad Saqib*

Main category: cs.CV

TL;DR: 本文介绍了一个包含8775次牙科检查的多模态数据集，并验证了其在AI口腔医疗任务中的有效性，模型性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 人工智能在口腔医疗中的应用需要大规模多模态数据集以反映临床实践的复杂性。

Method: 通过微调先进的视觉语言模型（Qwen-VL 3B和7B），并在两个任务上评估其性能：六种口腔异常的分类和基于多模态输入的完整诊断报告生成。

Result: 微调后的模型在分类和诊断报告生成任务上显著优于基准模型（包括GPT-4o），验证了数据集的有效性。

Conclusion: 该数据集为AI驱动的口腔医疗解决方案提供了重要资源，验证了其在分类和诊断报告生成任务中的有效性，并已公开供未来研究使用。

Abstract: The advancement of artificial intelligence in oral healthcare relies on the
availability of large-scale multimodal datasets that capture the complexity of
clinical practice. In this paper, we present a comprehensive multimodal
dataset, comprising 8775 dental checkups from 4800 patients collected over
eight years (2018-2025), with patients ranging from 10 to 90 years of age. The
dataset includes 50000 intraoral images, 8056 radiographs, and detailed textual
records, including diagnoses, treatment plans, and follow-up notes. The data
were collected under standard ethical guidelines and annotated for
benchmarking. To demonstrate its utility, we fine-tuned state-of-the-art large
vision-language models, Qwen-VL 3B and 7B, and evaluated them on two tasks:
classification of six oro-dental anomalies and generation of complete
diagnostic reports from multimodal inputs. We compared the fine-tuned models
with their base counterparts and GPT-4o. The fine-tuned models achieved
substantial gains over these baselines, validating the dataset and underscoring
its effectiveness in advancing AI-driven oro-dental healthcare solutions. The
dataset is publicly available, providing an essential resource for future
research in AI dentistry.

</details>


### [18] [DeepForgeSeal: Latent Space-Driven Semi-Fragile Watermarking for Deepfake Detection Using Multi-Agent Adversarial Reinforcement Learning](https://arxiv.org/abs/2511.04949)
*Tharindu Fernando,Clinton Fookes,Sridha Sridharan*

Main category: cs.CV

TL;DR: 本文提出了一种基于MAARL的鲁棒水印框架，显著提升了深度伪造检测的性能。


<details>
  <summary>Details</summary>
Motivation: 现有被动深度伪造检测方法因依赖特定伪造伪影而难以泛化，主动水印检测方法则在鲁棒性与敏感性之间难以平衡。

Method: 利用高维潜在空间表示和MAARL范式，开发了一种可学习的水印嵌入器，能够在潜在空间中捕获高级图像语义，并精确控制消息编码与提取。

Result: 在CelebA和CelebA-HQ基准测试中，该方法分别取得了超过4.5%和5.3%的性能提升。

Conclusion: 本文提出的基于高维潜在空间表示和多智能体对抗强化学习（MAARL）的水印框架，在CelebA和CelebA-HQ基准测试中显著优于现有方法，证明了其在平衡鲁棒性和脆弱性方面的有效性。

Abstract: Rapid advances in generative AI have led to increasingly realistic deepfakes,
posing growing challenges for law enforcement and public trust. Existing
passive deepfake detectors struggle to keep pace, largely due to their
dependence on specific forgery artifacts, which limits their ability to
generalize to new deepfake types. Proactive deepfake detection using watermarks
has emerged to address the challenge of identifying high-quality synthetic
media. However, these methods often struggle to balance robustness against
benign distortions with sensitivity to malicious tampering. This paper
introduces a novel deep learning framework that harnesses high-dimensional
latent space representations and the Multi-Agent Adversarial Reinforcement
Learning (MAARL) paradigm to develop a robust and adaptive watermarking
approach. Specifically, we develop a learnable watermark embedder that operates
in the latent space, capturing high-level image semantics, while offering
precise control over message encoding and extraction. The MAARL paradigm
empowers the learnable watermarking agent to pursue an optimal balance between
robustness and fragility by interacting with a dynamic curriculum of benign and
malicious image manipulations simulated by an adversarial attacker agent.
Comprehensive evaluations on the CelebA and CelebA-HQ benchmarks reveal that
our method consistently outperforms state-of-the-art approaches, achieving
improvements of over 4.5% on CelebA and more than 5.3% on CelebA-HQ under
challenging manipulation scenarios.

</details>


### [19] [CLM: Removing the GPU Memory Barrier for 3D Gaussian Splatting](https://arxiv.org/abs/2511.04951)
*Hexu Zhao,Xiwen Min,Xiaoteng Liu,Moonjun Gong,Yiming Li,Ang Li,Saining Xie,Jinyang Li,Aurojit Panda*

Main category: cs.CV

TL;DR: CLM系统通过智能卸载和优化通信，使3DGS能在消费级GPU上渲染大型场景，保持高质量。


<details>
  <summary>Details</summary>
Motivation: 3DGS在处理大型或复杂场景时因内存需求大而难以在消费级GPU上实现，CLM旨在解决这一问题。

Method: CLM系统通过将高斯分布数据卸载到CPU内存，并按需加载到GPU内存，结合流水线技术和通信优化，减少了性能和通信开销。

Result: CLM在单个RTX4090上成功渲染了需要1亿个高斯分布的大型场景，并实现了最先进的重建质量。

Conclusion: CLM系统成功实现了在单个消费级GPU（如RTX4090）上渲染大型3DGS场景，通过智能卸载策略和通信优化，显著降低了内存需求并保持了高质量的渲染效果。

Abstract: 3D Gaussian Splatting (3DGS) is an increasingly popular novel view synthesis
approach due to its fast rendering time, and high-quality output. However,
scaling 3DGS to large (or intricate) scenes is challenging due to its large
memory requirement, which exceed most GPU's memory capacity. In this paper, we
describe CLM, a system that allows 3DGS to render large scenes using a single
consumer-grade GPU, e.g., RTX4090. It does so by offloading Gaussians to CPU
memory, and loading them into GPU memory only when necessary. To reduce
performance and communication overheads, CLM uses a novel offloading strategy
that exploits observations about 3DGS's memory access pattern for pipelining,
and thus overlap GPU-to-CPU communication, GPU computation and CPU computation.
Furthermore, we also exploit observation about the access pattern to reduce
communication volume. Our evaluation shows that the resulting implementation
can render a large scene that requires 100 million Gaussians on a single
RTX4090 and achieve state-of-the-art reconstruction quality.

</details>


### [20] [Pattern-Aware Diffusion Synthesis of fMRI/dMRI with Tissue and Microstructural Refinement](https://arxiv.org/abs/2511.04963)
*Xiongri Shen,Jiaqi Wang,Yi Zhong,Zhenxi Song,Leilei Zhao,Yichen Wei,Lingyan Liang,Shuqiang Wang,Baiying Lei,Demao Deng,Zhiguo Zhang*

Main category: cs.CV

TL;DR: PDS通过创新的双模态扩散框架和微结构细化网络，显著提升了fMRI和dMRI合成的性能，临床验证效果优异。


<details>
  <summary>Details</summary>
Motivation: 解决fMRI和dMRI合成中的挑战：(1) BOLD与扩散加权信号在时间/梯度轴上的显著差异，(2) 生成过程中疾病相关神经解剖模式整合不足。

Method: 提出了PDS方法，包含两个关键创新：(1) 模式感知的双模态3D扩散框架用于跨模态学习，(2) 结合高效微结构细化的组织细化网络以保持结构保真度和细节。

Result: 在OASIS-3、ADNI和内部数据集上评估，PSNR/SSIM得分分别为29.83 dB/90.84%（fMRI合成）和30.00 dB/77.55%（dMRI合成），临床验证中合成数据诊断准确率为67.92%/66.02%/64.15%（NC vs. MCI vs. AD）。

Conclusion: PDS方法在fMRI和dMRI合成中取得了最先进的结果，临床验证表明合成数据具有强大的诊断性能，代码已开源。

Abstract: Magnetic resonance imaging (MRI), especially functional MRI (fMRI) and
diffusion MRI (dMRI), is essential for studying neurodegenerative diseases.
However, missing modalities pose a major barrier to their clinical use.
Although GAN- and diffusion model-based approaches have shown some promise in
modality completion, they remain limited in fMRI-dMRI synthesis due to (1)
significant BOLD vs. diffusion-weighted signal differences between fMRI and
dMRI in time/gradient axis, and (2) inadequate integration of disease-related
neuroanatomical patterns during generation. To address these challenges, we
propose PDS, introducing two key innovations: (1) a pattern-aware dual-modal 3D
diffusion framework for cross-modality learning, and (2) a tissue refinement
network integrated with a efficient microstructure refinement to maintain
structural fidelity and fine details. Evaluated on OASIS-3, ADNI, and in-house
datasets, our method achieves state-of-the-art results, with PSNR/SSIM scores
of 29.83 dB/90.84\% for fMRI synthesis (+1.54 dB/+4.12\% over baselines) and
30.00 dB/77.55\% for dMRI synthesis (+1.02 dB/+2.2\%). In clinical validation,
the synthesized data show strong diagnostic performance, achieving
67.92\%/66.02\%/64.15\% accuracy (NC vs. MCI vs. AD) in hybrid real-synthetic
experiments. Code is available in \href{https://github.com/SXR3015/PDS}{PDS
GitHub Repository}

</details>


### [21] [Learning Fourier shapes to probe the geometric world of deep neural networks](https://arxiv.org/abs/2511.04970)
*Jian Wang,Yixing Yong,Haixia Bi,Lijun He,Fan Li*

Main category: cs.CV

TL;DR: 该论文提出了一种框架，通过优化形状来探究DNNs的几何理解，展示了形状作为语义载体、可解释性工具和对抗范式的潜力。


<details>
  <summary>Details</summary>
Motivation: 尽管形状和纹理对视觉识别都很重要，但现有研究主要关注纹理，对DNNs的几何理解探究不足。

Method: 通过一个端到端的可微分框架，结合傅里叶级数参数化任意形状、基于绕组数的映射将形状转换为DNN所需的像素网格，以及信号能量约束来优化效率并确保物理上合理的形状。

Result: 优化的形状可作为强语义载体，生成高置信度的分类结果；它们也是高保真的可解释性工具，能精确隔离模型的显著区域；并构成一种新的、可泛化的对抗范式，能够欺骗下游视觉任务。

Conclusion: 本研究提供了一个统一的框架，用于探索深度神经网络（DNNs）的几何世界，并为挑战和理解机器感知开辟了新领域。

Abstract: While both shape and texture are fundamental to visual recognition, research
on deep neural networks (DNNs) has predominantly focused on the latter, leaving
their geometric understanding poorly probed. Here, we show: first, that
optimized shapes can act as potent semantic carriers, generating
high-confidence classifications from inputs defined purely by their geometry;
second, that they are high-fidelity interpretability tools that precisely
isolate a model's salient regions; and third, that they constitute a new,
generalizable adversarial paradigm capable of deceiving downstream visual
tasks. This is achieved through an end-to-end differentiable framework that
unifies a powerful Fourier series to parameterize arbitrary shapes, a winding
number-based mapping to translate them into the pixel grid required by DNNs,
and signal energy constraints that enhance optimization efficiency while
ensuring physically plausible shapes. Our work provides a versatile framework
for probing the geometric world of DNNs and opens new frontiers for challenging
and understanding machine perception.

</details>


### [22] [Challenges in 3D Data Synthesis for Training Neural Networks on Topological Features](https://arxiv.org/abs/2511.04972)
*Dylan Peek,Matthew P. Skerritt,Siddharth Pritam,Stephan Chalup*

Main category: cs.CV

TL;DR: 论文提出了一种生成标记3D数据集的新方法，用于训练TDA任务的神经网络估计器，并展示了拓扑和几何复杂性对估计器性能的影响。


<details>
  <summary>Details</summary>
Motivation: 传统TDA方法如持久同调计算成本高，而神经网络估计器能减少计算开销，但缺乏专门用于监督学习的标记3D数据集阻碍了这些方法的发展。

Method: 论文提出了一种使用排斥表面算法系统生成标记3D数据集的方法，并采用3D卷积变换器架构训练了一个属估计网络。

Result: 生成的合成3D数据集具有多样的几何和拓扑标记，适合训练和基准测试神经网络估计器。实验表明，随着变形的增加，估计器的准确性下降，突出了拓扑和几何复杂性在训练通用估计器中的作用。

Conclusion: 该论文通过引入一种系统生成标记3D数据集的新方法，填补了TDA任务中缺乏专门用于监督学习的标记3D数据集的空白，并通过实验展示了拓扑和几何复杂性对估计器性能的影响。

Abstract: Topological Data Analysis (TDA) involves techniques of analyzing the
underlying structure and connectivity of data. However, traditional methods
like persistent homology can be computationally demanding, motivating the
development of neural network-based estimators capable of reducing
computational overhead and inference time. A key barrier to advancing these
methods is the lack of labeled 3D data with class distributions and diversity
tailored specifically for supervised learning in TDA tasks. To address this, we
introduce a novel approach for systematically generating labeled 3D datasets
using the Repulsive Surface algorithm, allowing control over topological
invariants, such as hole count. The resulting dataset offers varied geometry
with topological labeling, making it suitable for training and benchmarking
neural network estimators. This paper uses a synthetic 3D dataset to train a
genus estimator network, created using a 3D convolutional transformer
architecture. An observed decrease in accuracy as deformations increase
highlights the role of not just topological complexity, but also geometric
complexity, when training generalized estimators. This dataset fills a gap in
labeled 3D datasets and generation for training and evaluating models and
techniques for TDA.

</details>


### [23] [GSE: Evaluating Sticker Visual Semantic Similarity via a General Sticker Encoder](https://arxiv.org/abs/2511.04977)
*Heng Er Metilda Chee,Jiayin Wang,Zhiqiang Guo,Weizhi Ma,Min Zhang*

Main category: cs.CV

TL;DR: 本研究定义了贴纸语义相似性任务并提出了首个基准Triple-S，开发了GSE模型以解决现有模型在捕捉贴纸语义时的不足。


<details>
  <summary>Details</summary>
Motivation: 贴纸作为一种流行的视觉交流形式，其多样化和符号化的内容使得理解其语义关系具有挑战性。

Method: 提出了General Sticker Encoder (GSE)，一种轻量级且通用的模型，利用Triple-S和其他数据集学习鲁棒的贴纸嵌入表示。

Result: GSE在未见过的贴纸上表现出优越性能，并在情感分类和贴纸检索等下游任务中取得强劲结果。

Conclusion: 通过发布Triple-S基准和GSE模型，本研究为标准化的贴纸语义理解、检索及多模态内容生成提供了工具和嵌入表示。

Abstract: Stickers have become a popular form of visual communication, yet
understanding their semantic relationships remains challenging due to their
highly diverse and symbolic content. In this work, we formally {define the
Sticker Semantic Similarity task} and introduce {Triple-S}, the first benchmark
for this task, consisting of 905 human-annotated positive and negative sticker
pairs. Through extensive evaluation, we show that existing pretrained vision
and multimodal models struggle to capture nuanced sticker semantics. To address
this, we propose the {General Sticker Encoder (GSE)}, a lightweight and
versatile model that learns robust sticker embeddings using both Triple-S and
additional datasets. GSE achieves superior performance on unseen stickers, and
demonstrates strong results on downstream tasks such as emotion classification
and sticker-to-sticker retrieval. By releasing both Triple-S and GSE, we
provide standardized evaluation tools and robust embeddings, enabling future
research in sticker understanding, retrieval, and multimodal content
generation. The Triple-S benchmark and GSE have been publicly released and are
available here.

</details>


### [24] [Towards Mitigating Hallucinations in Large Vision-Language Models by Refining Textual Embeddings](https://arxiv.org/abs/2511.05017)
*Aakriti Agrawal,Gouthaman KV,Rohith Aralikatti,Gauri Jagatap,Jiaxin Yuan,Vijay Kamarshi,Andrea Fanelli,Furong Huang*

Main category: cs.CV

TL;DR: 论文揭示LVLM架构对语言模态的偏见，提出通过整合视觉特征优化文本嵌入的方法，有效减少幻觉现象。


<details>
  <summary>Details</summary>
Motivation: 发现主流LVLM架构存在对语言模态的固有偏见，主要源于将视觉嵌入简单附加到输入文本序列的常见做法。

Method: 提出了一种通过整合平均池化视觉特征来优化文本嵌入的方法。

Result: 方法显著改善了视觉基础并减少了在已有基准上的幻觉现象。

Conclusion: 论文提出了一种简单有效的方法，通过整合平均池化的视觉特征来优化文本嵌入，显著改善了视觉基础并减少了幻觉现象。未来工作可探索更先进的融合策略以进一步提升效果。

Abstract: In this work, we identify an inherent bias in prevailing LVLM architectures
toward the language modality, largely resulting from the common practice of
simply appending visual embeddings to the input text sequence. To address this,
we propose a simple yet effective method that refines textual embeddings by
integrating average-pooled visual features. Our approach demonstrably improves
visual grounding and significantly reduces hallucinations on established
benchmarks. While average pooling offers a straightforward, robust, and
efficient means of incorporating visual information, we believe that more
sophisticated fusion methods could further enhance visual grounding and
cross-modal alignment. Given that the primary focus of this work is to
highlight the modality imbalance and its impact on hallucinations -- and to
show that refining textual embeddings with visual information mitigates this
issue -- we leave exploration of advanced fusion strategies for future work.

</details>


### [25] [Dynamic Residual Encoding with Slide-Level Contrastive Learning for End-to-End Whole Slide Image Representation](https://arxiv.org/abs/2511.05034)
*Jing Jin,Xu Liu,Te Gao,Zhihong Shi,Yixiong Liang,Ruiqing Zheng,Hulin Kuang,Min Zeng,Shichao Kan*

Main category: cs.CV

TL;DR: DRE-SLCL通过动态残差编码和对比学习解决WSI表示难题，实验验证其在癌症相关任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: 由于WSI包含大量图块且GPU计算能力有限，传统方法难以高效处理，需开发新的端到端WSI表示方法。

Method: 提出动态残差编码结合幻灯片级对比学习（DRE-SLCL），利用内存库存储所有WSI的图块特征，通过随机采样和特征检索生成WSI表示。

Result: 实验证明DRE-SLCL在癌症亚型分类、识别和突变预测任务中效果显著。

Conclusion: DRE-SLCL方法通过动态残差编码和幻灯片级对比学习，有效解决了WSI表示中的计算挑战，并在癌症亚型分类、识别和突变预测任务中表现出色。

Abstract: Whole Slide Image (WSI) representation is critical for cancer subtyping,
cancer recognition and mutation prediction.Training an end-to-end WSI
representation model poses significant challenges, as a standard gigapixel
slide can contain tens of thousands of image tiles, making it difficult to
compute gradients of all tiles in a single mini-batch due to current GPU
limitations. To address this challenge, we propose a method of dynamic residual
encoding with slide-level contrastive learning (DRE-SLCL) for end-to-end WSI
representation. Our approach utilizes a memory bank to store the features of
tiles across all WSIs in the dataset. During training, a mini-batch usually
contains multiple WSIs. For each WSI in the batch, a subset of tiles is
randomly sampled and their features are computed using a tile encoder. Then,
additional tile features from the same WSI are selected from the memory bank.
The representation of each individual WSI is generated using a residual
encoding technique that incorporates both the sampled features and those
retrieved from the memory bank. Finally, the slide-level contrastive loss is
computed based on the representations and histopathology reports ofthe WSIs
within the mini-batch. Experiments conducted over cancer subtyping, cancer
recognition, and mutation prediction tasks proved the effectiveness of the
proposed DRE-SLCL method.

</details>


### [26] [Pressure2Motion: Hierarchical Motion Synthesis from Ground Pressure with Text Guidance](https://arxiv.org/abs/2511.05038)
*Zhengxuan Li,Qinhui Yang,Yiyu Zhuang,Chuan Guo,Xinxin Zuo,Xiaoxiao Long,Yao Yao,Xun Cao,Qiu Shen,Hao Zhu*

Main category: cs.CV

TL;DR: Pressure2Motion 是一种利用地面压力序列和文本提示生成人体运动的算法，适用于隐私保护、低光和低成本场景，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统运动捕捉需要专业设备（如摄像头或可穿戴设备），限制了其在隐私保护、低光和低成本场景的应用。Pressure2Motion 旨在通过地面压力序列和文本提示解决这一问题。

Method: Pressure2Motion 是一种生成模型，利用压力特征作为输入，并结合文本提示作为高级指导约束。模型采用双级特征提取器解析压力数据，并通过分层扩散模型识别大尺度运动轨迹和细微姿势调整。

Result: 实验证明 Pressure2Motion 能够生成高保真、物理上合理的运动，并在新建立的 MPL 基准测试中达到最先进的性能。

Conclusion: Pressure2Motion 是一种创新的运动捕捉算法，通过地面压力序列和文本提示合成人体运动，适用于隐私保护、低光和低成本场景，并在实验中表现出色，生成了高保真、物理上合理的运动。

Abstract: We present Pressure2Motion, a novel motion capture algorithm that synthesizes
human motion from a ground pressure sequence and text prompt. It eliminates the
need for specialized lighting setups, cameras, or wearable devices, making it
suitable for privacy-preserving, low-light, and low-cost motion capture
scenarios. Such a task is severely ill-posed due to the indeterminate nature of
the pressure signals to full-body motion. To address this issue, we introduce
Pressure2Motion, a generative model that leverages pressure features as input
and utilizes a text prompt as a high-level guiding constraint. Specifically,
our model utilizes a dual-level feature extractor that accurately interprets
pressure data, followed by a hierarchical diffusion model that discerns
broad-scale movement trajectories and subtle posture adjustments. Both the
physical cues gained from the pressure sequence and the semantic guidance
derived from descriptive texts are leveraged to guide the motion generation
with precision. To the best of our knowledge, Pressure2Motion is a pioneering
work in leveraging both pressure data and linguistic priors for motion
generation, and the established MPL benchmark is the first benchmark for this
task. Experiments show our method generates high-fidelity, physically plausible
motions, establishing a new state-of-the-art for this task. The codes and
benchmarks will be publicly released upon publication.

</details>


### [27] [No Pose Estimation? No Problem: Pose-Agnostic and Instance-Aware Test-Time Adaptation for Monocular Depth Estimation](https://arxiv.org/abs/2511.05055)
*Mingyu Sung,Hyeonmin Choe,Il-Min Kim,Sangseok Yun,Jae Mo Kang*

Main category: cs.CV

TL;DR: 提出PITTA框架，通过姿态无关TTA和实例感知掩码，显著提升单目深度估计在动态环境中的适应性。


<details>
  <summary>Details</summary>
Motivation: 解决现有TTA方法在多样化和动态环境中效果不佳的问题。

Method: 结合了两种创新策略：(i) 姿态无关的TTA范式；(ii) 实例感知图像掩码。此外，还提出了边缘提取方法。

Result: 在DrivingStereo和Waymo数据集上的实验表明，PITTA性能显著优于现有技术。

Conclusion: PITTA框架在单目深度估计（MDE）的测试时域适应（TTA）中表现优异，显著超越了现有技术。

Abstract: Monocular depth estimation (MDE), inferring pixel-level depths in single RGB
images from a monocular camera, plays a crucial and pivotal role in a variety
of AI applications demanding a three-dimensional (3D) topographical scene. In
the real-world scenarios, MDE models often need to be deployed in environments
with different conditions from those for training. Test-time (domain)
adaptation (TTA) is one of the compelling and practical approaches to address
the issue. Although there have been notable advancements in TTA for MDE,
particularly in a self-supervised manner, existing methods are still
ineffective and problematic when applied to diverse and dynamic environments.
To break through this challenge, we propose a novel and high-performing TTA
framework for MDE, named PITTA. Our approach incorporates two key innovative
strategies: (i) pose-agnostic TTA paradigm for MDE and (ii) instance-aware
image masking. Specifically, PITTA enables highly effective TTA on a pretrained
MDE network in a pose-agnostic manner without resorting to any camera pose
information. Besides, our instance-aware masking strategy extracts
instance-wise masks for dynamic objects (e.g., vehicles, pedestrians, etc.)
from a segmentation mask produced by a pretrained panoptic segmentation
network, by removing static objects including background components. To further
boost performance, we also present a simple yet effective edge extraction
methodology for the input image (i.e., a single monocular image) and depth map.
Extensive experimental evaluations on DrivingStereo and Waymo datasets with
varying environmental conditions demonstrate that our proposed framework,
PITTA, surpasses the existing state-of-the-art techniques with remarkable
performance improvements in MDE during TTA.

</details>


### [28] [Medical Referring Image Segmentation via Next-Token Mask Prediction](https://arxiv.org/abs/2511.05044)
*Xinyu Chen,Yiran Wang,Gaoyang Pang,Jiafu Hao,Chentao Yue,Luping Zhou,Yonghui Li*

Main category: cs.CV

TL;DR: NTP-MRISeg通过自回归令牌预测和多模态序列统一架构简化MRIS任务，并引入三种优化策略，在实验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有MRIS方法中复杂的多模态融合或多阶段解码器设计问题，并提升模型泛化能力和适应性。

Method: 提出NTP-MRISeg框架，将MRIS任务重新定义为多模态序列的自回归下一令牌预测任务，并引入NkTP、TCL和HET三种策略优化训练。

Result: 在QaTa-COV19和MosMedData+数据集上，NTP-MRISeg实现了最先进的性能。

Conclusion: NTP-MRISeg通过创新的自回归下一令牌预测任务和多模态序列统一架构，简化了MRIS任务的模型设计，并实现了最先进的性能。

Abstract: Medical Referring Image Segmentation (MRIS) involves segmenting target
regions in medical images based on natural language descriptions. While
achieving promising results, recent approaches usually involve complex design
of multimodal fusion or multi-stage decoders. In this work, we propose
NTP-MRISeg, a novel framework that reformulates MRIS as an autoregressive
next-token prediction task over a unified multimodal sequence of tokenized
image, text, and mask representations. This formulation streamlines model
design by eliminating the need for modality-specific fusion and external
segmentation models, supports a unified architecture for end-to-end training.
It also enables the use of pretrained tokenizers from emerging large-scale
multimodal models, enhancing generalization and adaptability. More importantly,
to address challenges under this formulation-such as exposure bias, long-tail
token distributions, and fine-grained lesion edges-we propose three novel
strategies: (1) a Next-k Token Prediction (NkTP) scheme to reduce cumulative
prediction errors, (2) Token-level Contrastive Learning (TCL) to enhance
boundary sensitivity and mitigate long-tail distribution effects, and (3) a
memory-based Hard Error Token (HET) optimization strategy that emphasizes
difficult tokens during training. Extensive experiments on the QaTa-COV19 and
MosMedData+ datasets demonstrate that NTP-MRISeg achieves new state-of-the-art
performance, offering a streamlined and effective alternative to traditional
MRIS pipelines.

</details>


### [29] [Deep learning models are vulnerable, but adversarial examples are even more vulnerable](https://arxiv.org/abs/2511.05073)
*Jun Li,Yanwei Xu,Keran Li,Xiaoli Zhang*

Main category: cs.CV

TL;DR: 研究发现对抗样本在遮挡下置信度波动显著高于原始样本，据此提出的SWM-AED方法在CIFAR-10上检测准确率最高达96.5%。


<details>
  <summary>Details</summary>
Motivation: 理解对抗样本与原始样本之间的本质差异，以增强DNN的鲁棒性和对抗攻击检测能力。

Method: 使用九种典型攻击（如FGSM、PGD）生成对抗样本，并引入滑动掩码置信熵（SMCE）来量化模型在遮挡下的置信度波动。通过掩码熵场图和统计分布支持SMCE计算。

Result: 对抗样本在遮挡下表现出显著高于原始样本的置信度波动性。SWM-AED方法在大多数情况下检测准确率超过62%，最高达96.5%。

Conclusion: 本研究通过SMCE量化模型在遮挡下的置信度波动，发现对抗样本比原始样本具有更高的置信度波动性。基于此提出的SWM-AED方法在CIFAR-10数据集上表现出色，检测准确率最高达96.5%。

Abstract: Understanding intrinsic differences between adversarial examples and clean
samples is key to enhancing DNN robustness and detection against adversarial
attacks. This study first empirically finds that image-based adversarial
examples are notably sensitive to occlusion. Controlled experiments on CIFAR-10
used nine canonical attacks (e.g., FGSM, PGD) to generate adversarial examples,
paired with original samples for evaluation. We introduce Sliding Mask
Confidence Entropy (SMCE) to quantify model confidence fluctuation under
occlusion. Using 1800+ test images, SMCE calculations supported by Mask Entropy
Field Maps and statistical distributions show adversarial examples have
significantly higher confidence volatility under occlusion than originals.
Based on this, we propose Sliding Window Mask-based Adversarial Example
Detection (SWM-AED), which avoids catastrophic overfitting of conventional
adversarial training. Evaluations across classifiers and attacks on CIFAR-10
demonstrate robust performance, with accuracy over 62% in most cases and up to
96.5%.

</details>


### [30] [From Linear Probing to Joint-Weighted Token Hierarchy: A Foundation Model Bridging Global and Cellular Representations in Biomarker Detection](https://arxiv.org/abs/2511.05150)
*Jingsong Liu,Han Li,Nassir Navab,Peter J. Schüffler*

Main category: cs.CV

TL;DR: JWTH模型通过细胞级形态学整合，提升了AI生物标志物检测的准确性和稳健性，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的病理学基础模型（PFMs）主要依赖全局补丁级嵌入，忽略了细胞级形态学，限制了AI生物标志物检测的准确性和可解释性。

Method: JWTH模型整合了大规模自监督预训练、细胞中心的后调优以及注意力池化技术，以融合局部和全局标记。

Result: 在涉及四个生物标志物和八个队列的四项任务中，JWTH的平衡准确率最高提升了8.3%，平均提升了1.2%，优于现有PFMs。

Conclusion: JWTH模型通过结合细胞中心的后调优和注意力池化，显著提升了AI生物标志物检测的准确性和稳健性，推动了数字病理学中可解释AI的发展。

Abstract: AI-based biomarkers can infer molecular features directly from hematoxylin &
eosin (H&E) slides, yet most pathology foundation models (PFMs) rely on global
patch-level embeddings and overlook cell-level morphology. We present a PFM
model, JWTH (Joint-Weighted Token Hierarchy), which integrates large-scale
self-supervised pretraining with cell-centric post-tuning and attention pooling
to fuse local and global tokens. Across four tasks involving four biomarkers
and eight cohorts, JWTH achieves up to 8.3% higher balanced accuracy and 1.2%
average improvement over prior PFMs, advancing interpretable and robust
AI-based biomarker detection in digital pathology.

</details>


### [31] [Role-SynthCLIP: A Role Play Driven Diverse Synthetic Data Approach](https://arxiv.org/abs/2511.05057)
*Yuanxiang Huangfu,Chaochao Wang,Weilei Wang*

Main category: cs.CV

TL;DR: Role-SynthCLIP通过多视角角色扮演提示生成语义多样的图像-文本对，提升CLIP模型的训练效果。


<details>
  <summary>Details</summary>
Motivation: 现有合成数据方法过于关注数据量而忽视语义多样性，导致冗余和浅层描述。

Method: 利用多视角角色扮演提示（如组合分析师、图像上下文解释者）指导MLLMs生成多样化描述。

Result: 仅用100万对数据训练的CLIP-B/16模型在MS COCO验证集上Recall@1达64.1%，优于现有基线2.8个百分点。

Conclusion: Role-SynthCLIP有效提升合成数据的语义多样性和细粒度对齐，显著提高模型性能。

Abstract: The effectiveness of Contrastive Language-Image Pre-training (CLIP) models
critically depends on the semantic diversity and quality of their training
data. However, while existing synthetic data generation methods primarily focus
on increasing data volume, such emphasis often leads to limited semantic
diversity and redundant or shallow captions. To address this limitation, we
propose Role-SynthCLIP, a novel data synthesis framework that leverages
multi-perspective role-playing prompts (e.g., a compositional analyst, an
interpreter of image context) to guide Multimodal Large Language Models (MLLMs)
in generating semantically diverse captions from distinct viewpoints. This
mechanism enhances the semantic diversity and fine-grained image-text alignment
of synthetic pairs, thereby improving caption expressiveness and accuracy while
keeping the total number of image-text pairs unchanged. Experimental results
demonstrate the effectiveness and efficiency of our method. A CLIP-B/16 model
trained on only 1 million Role-SynthCLIP pairs achieves a Recall@1 of 64.1% on
the MS COCO validation set, surpassing the best existing synthetic data
baseline (trained on 5M pairs) by 2.8 percentage points. The code and trained
models are released at https://github.com/huangfu170/Role-SynthCLIP.

</details>


### [32] [SurgiATM: A Physics-Guided Plug-and-Play Model for Deep Learning-Based Smoke Removal in Laparoscopic Surgery](https://arxiv.org/abs/2511.05059)
*Mingyu Sheng,Jianan Fan,Dongnan Liu,Guoyan Zheng,Ron Kikinis,Weidong Cai*

Main category: cs.CV

TL;DR: 提出SurgiATM模型，结合物理模型和深度学习，有效去除手术烟雾，提升图像质量和手术安全性。


<details>
  <summary>Details</summary>
Motivation: 腹腔镜手术中组织烧灼产生的烟雾会显著降低内窥镜图像质量，增加手术风险，影响临床决策和计算机辅助视觉分析。

Method: 结合基于物理的大气模型和数据驱动的深度学习模型，提出Surgical Atmospheric Model (SurgiATM)，仅引入两个超参数且不增加可训练权重。

Result: 在三个公共手术数据集和十种去雾方法上的实验表明，SurgiATM能普遍减少现有模型的恢复误差并提升泛化能力。

Conclusion: SurgiATM作为一种轻量级、即插即用的模块，能有效提升现有手术烟雾去除方法的准确性和泛化能力，且无需增加可训练参数，具有便捷、低成本、高效和泛化的特点。

Abstract: During laparoscopic surgery, smoke generated by tissue cauterization can
significantly degrade the visual quality of endoscopic frames, increasing the
risk of surgical errors and hindering both clinical decision-making and
computer-assisted visual analysis. Consequently, removing surgical smoke is
critical to ensuring patient safety and maintaining operative efficiency. In
this study, we propose the Surgical Atmospheric Model (SurgiATM) for surgical
smoke removal. SurgiATM statistically bridges a physics-based atmospheric model
and data-driven deep learning models, combining the superior generalizability
of the former with the high accuracy of the latter. Furthermore, SurgiATM is
designed as a lightweight, plug-and-play module that can be seamlessly
integrated into diverse surgical desmoking architectures to enhance their
accuracy and stability, better meeting clinical requirements. It introduces
only two hyperparameters and no additional trainable weights, preserving the
original network architecture with minimal computational and modification
overhead. We conduct extensive experiments on three public surgical datasets
with ten desmoking methods, involving multiple network architectures and
covering diverse procedures, including cholecystectomy, partial nephrectomy,
and diaphragm dissection. The results demonstrate that incorporating SurgiATM
commonly reduces the restoration errors of existing models and relatively
enhances their generalizability, without adding any trainable layers or
weights. This highlights the convenience, low cost, effectiveness, and
generalizability of the proposed method. The code for SurgiATM is released at
https://github.com/MingyuShengSMY/SurgiATM.

</details>


### [33] [4D3R: Motion-Aware Neural Reconstruction and Rendering of Dynamic Scenes from Monocular Videos](https://arxiv.org/abs/2511.05229)
*Mengqi Guo,Bo Xu,Yanyan Li,Gim Hee Lee*

Main category: cs.CV

TL;DR: 4D3R提出了一种无需预计算位姿的动态神经渲染框架，通过两阶段解耦和运动感知技术，显著提升渲染效率和质量。


<details>
  <summary>Details</summary>
Motivation: 解决单目视频动态场景中未知相机位姿下的新视角合成问题，克服现有方法对动态内容处理不足和依赖预计算位姿的局限性。

Method: 两阶段方法：1) 利用3D基础模型进行初始位姿和几何估计；2) 运动感知细化，包括MA-BA模块（结合Transformer先验和SAM2分割）和MA-GS表示（控制点与变形场MLP）。

Result: 在真实动态数据集上，PSNR提升1.8dB，计算需求降低5倍，尤其在大型动态物体场景中表现优异。

Conclusion: 4D3R框架通过两阶段方法解耦静态和动态组件，结合MA-BA模块和MA-GS表示，显著提升了动态场景的渲染质量并降低了计算成本。

Abstract: Novel view synthesis from monocular videos of dynamic scenes with unknown
camera poses remains a fundamental challenge in computer vision and graphics.
While recent advances in 3D representations such as Neural Radiance Fields
(NeRF) and 3D Gaussian Splatting (3DGS) have shown promising results for static
scenes, they struggle with dynamic content and typically rely on pre-computed
camera poses. We present 4D3R, a pose-free dynamic neural rendering framework
that decouples static and dynamic components through a two-stage approach. Our
method first leverages 3D foundational models for initial pose and geometry
estimation, followed by motion-aware refinement. 4D3R introduces two key
technical innovations: (1) a motion-aware bundle adjustment (MA-BA) module that
combines transformer-based learned priors with SAM2 for robust dynamic object
segmentation, enabling more accurate camera pose refinement; and (2) an
efficient Motion-Aware Gaussian Splatting (MA-GS) representation that uses
control points with a deformation field MLP and linear blend skinning to model
dynamic motion, significantly reducing computational cost while maintaining
high-quality reconstruction. Extensive experiments on real-world dynamic
datasets demonstrate that our approach achieves up to 1.8dB PSNR improvement
over state-of-the-art methods, particularly in challenging scenarios with large
dynamic objects, while reducing computational requirements by 5x compared to
previous dynamic scene representations.

</details>


### [34] [Accurate online action and gesture recognition system using detectors and Deep SPD Siamese Networks](https://arxiv.org/abs/2511.05250)
*Mohamed Sanim Akremi,Rim Slama,Hedi Tabia*

Main category: cs.CV

TL;DR: 提出了一种基于半正定矩阵和Siamese网络的在线骨架序列识别系统，实验证明其在手势和身体动作识别中优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有方法多专注于分段识别，不适合在线场景，因此需要一种能够连续识别运动的系统。

Method: 系统由检测器和分类器组成，检测器使用半正定矩阵表示，分类器使用Siamese网络。

Result: 系统在未分割序列中能够预测运动时间区间，并在每个区间内准确识别动作。

Conclusion: 提出的在线识别系统在手势和身体动作识别基准测试中表现出色，多数情况下优于现有技术。

Abstract: Online continuous motion recognition is a hot topic of research since it is
more practical in real life application cases. Recently, Skeleton-based
approaches have become increasingly popular, demonstrating the power of using
such 3D temporal data. However, most of these works have focused on
segment-based recognition and are not suitable for the online scenarios. In
this paper, we propose an online recognition system for skeleton sequence
streaming composed from two main components: a detector and a classifier, which
use a Semi-Positive Definite (SPD) matrix representation and a Siamese network.
The powerful statistical representations for the skeletal data given by the SPD
matrices and the learning of their semantic similarity by the Siamese network
enable the detector to predict time intervals of the motions throughout an
unsegmented sequence. In addition, they ensure the classifier capability to
recognize the motion in each predicted interval. The proposed detector is
flexible and able to identify the kinetic state continuously. We conduct
extensive experiments on both hand gesture and body action recognition
benchmarks to prove the accuracy of our online recognition system which in most
cases outperforms state-of-the-art performances.

</details>


### [35] [A Dual-stage Prompt-driven Privacy-preserving Paradigm for Person Re-Identification](https://arxiv.org/abs/2511.05092)
*Ruolin Li,Min Liu,Yuan Bian,Zhaoyang Li,Yuzhen Li,Xueping Wang,Yaonan Wang*

Main category: cs.CV

TL;DR: 提出双阶段提示驱动的隐私保护范式（DPPP），通过生成多样化虚拟数据和域不变特征学习，显著提升行人重识别模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有虚拟数据集构建复杂、域泛化能力差的问题，探索更高效且隐私保护的虚拟数据生成方法。

Method: 第一阶段通过多维度属性生成丰富提示，驱动扩散模型合成多样化数据构建GenePerson数据集；第二阶段提出提示驱动解耦机制（PDM），结合对比学习，通过两个文本反转网络分别映射图像到风格和内容的伪词表示，学习域不变内容特征。

Result: 在GenePerson数据集上训练的模型表现出最先进的泛化性能，超越了现有真实和虚拟Re-ID数据集的表现。

Conclusion: 论文提出的DPPP范式通过双阶段提示驱动的方法，显著提升了虚拟数据在行人重识别任务中的泛化性能，实验结果优于现有真实和虚拟数据集训练的模型。

Abstract: With growing concerns over data privacy, researchers have started using
virtual data as an alternative to sensitive real-world images for training
person re-identification (Re-ID) models. However, existing virtual datasets
produced by game engines still face challenges such as complex construction and
poor domain generalization, making them difficult to apply in real scenarios.
To address these challenges, we propose a Dual-stage Prompt-driven
Privacy-preserving Paradigm (DPPP). In the first stage, we generate rich
prompts incorporating multi-dimensional attributes such as pedestrian
appearance, illumination, and viewpoint that drive the diffusion model to
synthesize diverse data end-to-end, building a large-scale virtual dataset
named GenePerson with 130,519 images of 6,641 identities. In the second stage,
we propose a Prompt-driven Disentanglement Mechanism (PDM) to learn
domain-invariant generalization features. With the aid of contrastive learning,
we employ two textual inversion networks to map images into pseudo-words
representing style and content, respectively, thereby constructing
style-disentangled content prompts to guide the model in learning
domain-invariant content features at the image level. Experiments demonstrate
that models trained on GenePerson with PDM achieve state-of-the-art
generalization performance, surpassing those on popular real and virtual Re-ID
datasets.

</details>


### [36] [OregairuChar: A Benchmark Dataset for Character Appearance Frequency Analysis in My Teen Romantic Comedy SNAFU](https://arxiv.org/abs/2511.05263)
*Qi Sun,Dingju Zhou,Lina Zhang*

Main category: cs.CV

TL;DR: OregairuChar是一个标注数据集，用于分析动漫角色出现频率，揭示了角色在叙事中的突出性模式。


<details>
  <summary>Details</summary>
Motivation: 分析角色出现频率对理解动漫叙事结构、角色突出性和故事进展至关重要。

Method: 通过手动选取1600帧并标注2860个边界框，构建OregairuChar数据集；使用目标检测模型进行定量分析，并进行细粒度的集级角色出现时间分析。

Result: 数据集捕捉了多样化的视觉挑战（如遮挡、姿态变化等），并通过模型预测揭示了角色突出性的模式及其在叙事中的演变。

Conclusion: OregairuChar数据集为动漫角色出现频率分析提供了有价值的资源，有助于理解叙事动态和角色中心化的叙事风格。

Abstract: The analysis of character appearance frequency is essential for understanding
narrative structure, character prominence, and story progression in anime. In
this work, we introduce OregairuChar, a benchmark dataset designed for
appearance frequency analysis in the anime series My Teen Romantic Comedy
SNAFU. The dataset comprises 1600 manually selected frames from the third
season, annotated with 2860 bounding boxes across 11 main characters.
OregairuChar captures diverse visual challenges, including occlusion, pose
variation, and inter-character similarity, providing a realistic basis for
appearance-based studies. To enable quantitative research, we benchmark several
object detection models on the dataset and leverage their predictions for
fine-grained, episode-level analysis of character presence over time. This
approach reveals patterns of character prominence and their evolution within
the narrative. By emphasizing appearance frequency, OregairuChar serves as a
valuable resource for exploring computational narrative dynamics and
character-centric storytelling in stylized media.

</details>


### [37] [Real-World Adverse Weather Image Restoration via Dual-Level Reinforcement Learning with High-Quality Cold Start](https://arxiv.org/abs/2511.05095)
*Fuyang Liu,Jiaqi Xu,Xiaowei Hu*

Main category: cs.CV

TL;DR: 论文通过构建高保真天气数据集HFLS-Weather和双层次强化学习框架，实现了对复杂天气条件下视觉感知的自适应优化。


<details>
  <summary>Details</summary>
Motivation: 恶劣天气严重影响实际视觉感知，现有基于固定参数合成数据训练的视觉模型难以泛化到复杂退化场景。

Method: 构建了HFLS-Weather数据集，并设计了双层次强化学习框架：局部层次通过扰动驱动的图像质量优化细化天气特定恢复模型；全局层次通过元控制器动态协调模型选择和执行顺序。

Result: 该框架实现了对真实世界条件的持续适应，并在多种恶劣天气场景中取得了最先进的性能。

Conclusion: 该论文提出的双层次强化学习框架通过HFLS-Weather数据集实现了对复杂天气条件下视觉感知的持续适应性，并在多种恶劣天气场景中达到了最先进的性能。

Abstract: Adverse weather severely impairs real-world visual perception, while existing
vision models trained on synthetic data with fixed parameters struggle to
generalize to complex degradations. To address this, we first construct
HFLS-Weather, a physics-driven, high-fidelity dataset that simulates diverse
weather phenomena, and then design a dual-level reinforcement learning
framework initialized with HFLS-Weather for cold-start training. Within this
framework, at the local level, weather-specific restoration models are refined
through perturbation-driven image quality optimization, enabling reward-based
learning without paired supervision; at the global level, a meta-controller
dynamically orchestrates model selection and execution order according to scene
degradation. This framework enables continuous adaptation to real-world
conditions and achieves state-of-the-art performance across a wide range of
adverse weather scenarios. Code is available at
https://github.com/xxclfy/AgentRL-Real-Weather

</details>


### [38] [DeepEyesV2: Toward Agentic Multimodal Model](https://arxiv.org/abs/2511.05271)
*Jack Hong,Chenxiao Zhao,ChengLin Zhu,Weiheng Lu,Guohai Xu,Xing Yu*

Main category: cs.CV

TL;DR: DeepEyesV2通过两阶段训练和多样化数据集，实现了多模态模型的工具调用和推理能力，并在多个任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有强化学习单独使用时无法诱导稳健工具使用行为的问题，探索如何在数据构建、训练方法和模型评估方面构建代理式多模态模型。

Method: 采用两阶段训练流程：冷启动阶段建立工具使用模式，强化学习阶段优化工具调用。构建多样化、适度挑战性的训练数据集，并引入RealX-Bench评估基准。

Result: DeepEyesV2在RealX-Bench和其他基准测试中表现优异，尤其在真实世界理解、数学推理和搜索密集型任务中。模型能根据任务自适应调用工具，强化学习进一步实现复杂工具组合和基于上下文的工具选择。

Conclusion: DeepEyesV2通过两阶段训练流程和多样化数据集，展示了多模态模型在工具调用和推理任务中的有效性，为社区开发代理式多模态模型提供了指导。

Abstract: Agentic multimodal models should not only comprehend text and images, but
also actively invoke external tools, such as code execution environments and
web search, and integrate these operations into reasoning. In this work, we
introduce DeepEyesV2 and explore how to build an agentic multimodal model from
the perspectives of data construction, training methods, and model evaluation.
We observe that direct reinforcement learning alone fails to induce robust
tool-use behavior. This phenomenon motivates a two-stage training pipeline: a
cold-start stage to establish tool-use patterns, and reinforcement learning
stage to further refine tool invocation. We curate a diverse, moderately
challenging training dataset, specifically including examples where tool use is
beneficial. We further introduce RealX-Bench, a comprehensive benchmark
designed to evaluate real-world multimodal reasoning, which inherently requires
the integration of multiple capabilities, including perception, search, and
reasoning. We evaluate DeepEyesV2 on RealX-Bench and other representative
benchmarks, demonstrating its effectiveness across real-world understanding,
mathematical reasoning, and search-intensive tasks. Moreover, DeepEyesV2
exhibits task-adaptive tool invocation, tending to use image operations for
perception tasks and numerical computations for reasoning tasks. Reinforcement
learning further enables complex tool combinations and allows model to
selectively invoke tools based on context. We hope our study can provide
guidance for community in developing agentic multimodal models.

</details>


### [39] [Early Alzheimer's Disease Detection from Retinal OCT Images: A UK Biobank Study](https://arxiv.org/abs/2511.05106)
*Yasemin Turkan,F. Boray Tek,M. Serdar Nazlı,Öykü Eren*

Main category: cs.CV

TL;DR: 研究首次应用深度学习于原始OCT B-scan进行AD预测，通过微调预训练模型和增强技术，在UK Biobank队列中验证，ResNet-34表现最佳，AUC为0.62，揭示了AD与对照组的视网膜结构差异。


<details>
  <summary>Details</summary>
Motivation: 探索直接对OCT B-scan图像进行分类用于AD早期检测，这是深度学习在原始OCT B-scan上首次应用于AD预测的研究。

Method: 微调并评估了多个预训练模型，包括基于ImageNet的网络和OCT特定的RETFound transformer，应用了标准和OCT特定的增强技术以及年份加权损失函数。

Result: ResNet-34在4年队列中实现了0.62的AUC，解释性分析确认了AD组与对照组在中央黄斑亚区的局部结构差异。

Conclusion: 研究为基于OCT的AD预测提供了基线，强调了在AD诊断前几年检测细微视网膜生物标志物的挑战，并指出需要更大的数据集和多模态方法。

Abstract: Alterations in retinal layer thickness, measurable using Optical Coherence
Tomography (OCT), have been associated with neurodegenerative diseases such as
Alzheimer's disease (AD). While previous studies have mainly focused on
segmented layer thickness measurements, this study explored the direct
classification of OCT B-scan images for the early detection of AD. To our
knowledge, this is the first application of deep learning to raw OCT B-scans
for AD prediction in the literature. Unlike conventional medical image
classification tasks, early detection is more challenging than diagnosis
because imaging precedes clinical diagnosis by several years. We fine-tuned and
evaluated multiple pretrained models, including ImageNet-based networks and the
OCT-specific RETFound transformer, using subject-level cross-validation
datasets matched for age, sex, and imaging instances from the UK Biobank
cohort. To reduce overfitting in this small, high-dimensional dataset, both
standard and OCT-specific augmentation techniques were applied, along with a
year-weighted loss function that prioritized cases diagnosed within four years
of imaging. ResNet-34 produced the most stable results, achieving an AUC of
0.62 in the 4-year cohort. Although below the threshold for clinical
application, our explainability analyses confirmed localized structural
differences in the central macular subfield between the AD and control groups.
These findings provide a baseline for OCT-based AD prediction, highlight the
challenges of detecting subtle retinal biomarkers years before AD diagnosis,
and point to the need for larger datasets and multimodal approaches.

</details>


### [40] [LiveStar: Live Streaming Assistant for Real-World Online Video Understanding](https://arxiv.org/abs/2511.05299)
*Zhenyu Yang,Kairui Zhang,Yuhang Hu,Bing Wang,Shengsheng Qian,Bin Wen,Fan Yang,Tingting Gao,Weiming Dong,Changsheng Xu*

Main category: cs.CV

TL;DR: LiveStar是一种新型在线视频语言模型，通过自适应流解码技术显著提升实时视频理解的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有在线视频语言模型在连续帧处理和响应时机选择上的不足，提升实时性和叙事连贯性。

Method: LiveStar采用自适应流解码技术，包括增量视频-语言对齐训练策略、响应-静默解码框架以及内存感知加速方法。

Result: 实验显示，LiveStar在语义正确性上平均提升19.5%，时间差减少18.1%，并在所有OmniStar任务中FPS提升12.0%。

Conclusion: LiveStar模型在语义正确性和响应时间上显著优于现有的在线视频语言模型，并通过OmniStar数据集提供了全面的训练和评估基准。

Abstract: Despite significant progress in Video Large Language Models (Video-LLMs) for
offline video understanding, existing online Video-LLMs typically struggle to
simultaneously process continuous frame-by-frame inputs and determine optimal
response timing, often compromising real-time responsiveness and narrative
coherence. To address these limitations, we introduce LiveStar, a pioneering
live streaming assistant that achieves always-on proactive responses through
adaptive streaming decoding. Specifically, LiveStar incorporates: (1) a
training strategy enabling incremental video-language alignment for
variable-length video streams, preserving temporal consistency across
dynamically evolving frame sequences; (2) a response-silence decoding framework
that determines optimal proactive response timing via a single forward pass
verification; (3) memory-aware acceleration via peak-end memory compression for
online inference on 10+ minute videos, combined with streaming key-value cache
to achieve 1.53x faster inference. We also construct an OmniStar dataset, a
comprehensive dataset for training and benchmarking that encompasses 15 diverse
real-world scenarios and 5 evaluation tasks for online video understanding.
Extensive experiments across three benchmarks demonstrate LiveStar's
state-of-the-art performance, achieving an average 19.5% improvement in
semantic correctness with 18.1% reduced timing difference compared to existing
online Video-LLMs, while improving FPS by 12.0% across all five OmniStar tasks.
Our model and dataset can be accessed at https://github.com/yzy-bupt/LiveStar.

</details>


### [41] [SnowyLane: Robust Lane Detection on Snow-covered Rural Roads Using Infrastructural Elements](https://arxiv.org/abs/2511.05108)
*Jörg Gamerdinger,Benedict Wetzel,Patrick Schulz,Sven Teufel,Oliver Bringmann*

Main category: cs.CV

TL;DR: 提出一种通过检测路标杆作为间接车道指示器的鲁棒方法，并在合成数据集SnowyLane上验证其在大雪环境中的优越性能。


<details>
  <summary>Details</summary>
Motivation: 雪覆盖环境中车道标记的频繁缺失或遮挡使得车道检测成为重大挑战。

Method: 提出了一种新颖、鲁棒且实时的方法，通过检测路边特征（特别是垂直路标杆）作为间接车道指示器，并使用参数化的贝塞尔曲线模型拟合平滑车道轨迹。

Result: 相比最先进的车道检测系统，该方法在恶劣天气（尤其是大雪遮挡情况下）表现出显著提升的鲁棒性。

Conclusion: 本研究为冬季场景下的可靠车道检测奠定了坚实基础，并为全天候自动驾驶的未来研究提供了宝贵资源。

Abstract: Lane detection for autonomous driving in snow-covered environments remains a
major challenge due to the frequent absence or occlusion of lane markings. In
this paper, we present a novel, robust and realtime capable approach that
bypasses the reliance on traditional lane markings by detecting roadside
features,specifically vertical roadside posts called delineators, as indirect
lane indicators. Our method first perceives these posts, then fits a smooth
lane trajectory using a parameterized Bezier curve model, leveraging spatial
consistency and road geometry. To support training and evaluation in these
challenging scenarios, we introduce SnowyLane, a new synthetic dataset
containing 80,000 annotated frames capture winter driving conditions, with
varying snow coverage, and lighting conditions. Compared to state-of-the-art
lane detection systems, our approach demonstrates significantly improved
robustness in adverse weather, particularly in cases with heavy snow occlusion.
This work establishes a strong foundation for reliable lane detection in winter
scenarios and contributes a valuable resource for future research in
all-weather autonomous driving. The dataset is available at
https://ekut-es.github.io/snowy-lane

</details>


### [42] [Rethinking Metrics and Diffusion Architecture for 3D Point Cloud Generation](https://arxiv.org/abs/2511.05308)
*Matteo Bastico,David Ryckelynck,Laurent Corté,Yannick Tillier,Etienne Decencière*

Main category: cs.CV

TL;DR: 本文改进了点云生成模型的评估指标，提出了DCD和SNC，并设计了Diffusion Point Transformer，实验证明其在点云生成质量上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前点云生成模型的评估指标（如基于Chamfer Distance的指标）在鲁棒性和几何保真度方面存在不足，需要更可靠的评估方法和生成模型。

Method: 提出了结合DCD和SNC的综合评估方法，并设计了Diffusion Point Transformer架构，利用transformer-based模型生成高保真3D点云。

Result: 在ShapeNet数据集上的实验表明，Diffusion Point Transformer在生成点云质量上优于现有方法，达到了新的先进水平。

Conclusion: 本文提出了一种新的点云生成模型评估方法，结合了Density-Aware Chamfer Distance (DCD)和Surface Normal Concordance (SNC)指标，显著提升了评估的鲁棒性和全面性。同时，Diffusion Point Transformer在生成高质量3D点云方面达到了新的先进水平。

Abstract: As 3D point clouds become a cornerstone of modern technology, the need for
sophisticated generative models and reliable evaluation metrics has grown
exponentially. In this work, we first expose that some commonly used metrics
for evaluating generated point clouds, particularly those based on Chamfer
Distance (CD), lack robustness against defects and fail to capture geometric
fidelity and local shape consistency when used as quality indicators. We
further show that introducing samples alignment prior to distance calculation
and replacing CD with Density-Aware Chamfer Distance (DCD) are simple yet
essential steps to ensure the consistency and robustness of point cloud
generative model evaluation metrics. While existing metrics primarily focus on
directly comparing 3D Euclidean coordinates, we present a novel metric, named
Surface Normal Concordance (SNC), which approximates surface similarity by
comparing estimated point normals. This new metric, when combined with
traditional ones, provides a more comprehensive evaluation of the quality of
generated samples. Finally, leveraging recent advancements in transformer-based
models for point cloud analysis, such as serialized patch attention , we
propose a new architecture for generating high-fidelity 3D structures, the
Diffusion Point Transformer. We perform extensive experiments and comparisons
on the ShapeNet dataset, showing that our model outperforms previous solutions,
particularly in terms of quality of generated point clouds, achieving new
state-of-the-art. Code available at
https://github.com/matteo-bastico/DiffusionPointTransformer.

</details>


### [43] [AI Assisted AR Assembly: Object Recognition and Computer Vision for Augmented Reality Assisted Assembly](https://arxiv.org/abs/2511.05394)
*Alexander Htet Kyaw,Haotian Ma,Sasa Zivkovic,Jenny Sabin*

Main category: cs.CV

TL;DR: AI辅助AR装配系统利用深度学习实时识别并指导组件装配，通过LEGO案例验证其高效性。


<details>
  <summary>Details</summary>
Motivation: 通过将装配指令与相关组件的实时位置连接，消除装配前的手动搜索、分类或标记需求，提高装配效率。

Method: 使用基于深度学习的物体识别技术，识别装配组件，并在物理空间中显示逐步的装配指令，包括组件的边界框和放置位置。

Result: 通过LEGO雕塑组装的案例研究，证明了该系统在AR辅助装配中的实用性。

Conclusion: 该论文展示了AI辅助的增强现实装配工作流程的可行性，特别是在识别组件和提供实时指导方面，显著提高了装配效率。

Abstract: We present an AI-assisted Augmented Reality assembly workflow that uses deep
learning-based object recognition to identify different assembly components and
display step-by-step instructions. For each assembly step, the system displays
a bounding box around the corresponding components in the physical space, and
where the component should be placed. By connecting assembly instructions with
the real-time location of relevant components, the system eliminates the need
for manual searching, sorting, or labeling of different components before each
assembly. To demonstrate the feasibility of using object recognition for
AR-assisted assembly, we highlight a case study involving the assembly of LEGO
sculptures.

</details>


### [44] [Multi-modal Loop Closure Detection with Foundation Models in Severely Unstructured Environments](https://arxiv.org/abs/2511.05404)
*Laura Alejandra Encinar Gonzalez,John Folkesson,Rudolph Triebel,Riccardo Giubilato*

Main category: cs.CV

TL;DR: MPRF是一种多模态闭环检测方法，结合视觉和LiDAR的Transformer模型，显著提升非结构化环境中的检测精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在GNSS缺失环境（如行星探索）中，传统视觉或LiDAR方法因纹理弱或稀疏性导致闭环检测不可靠，MPRF旨在解决这一问题。

Method: MPRF采用两阶段视觉检索策略，结合DINOv2特征与SALAD聚合进行候选筛选，并使用SONATA-based LiDAR描述子进行几何验证。

Result: 在S3LI数据集上的实验表明，MPRF在精度和低纹理区域的姿态估计鲁棒性上优于现有检索方法。

Conclusion: MPRF通过结合视觉和LiDAR模态的Transformer基础模型，在非结构化环境中实现了高效且鲁棒的闭环检测，为SLAM后端提供了可解释的对应关系，平衡了准确性、效率和可靠性。

Abstract: Robust loop closure detection is a critical component of Simultaneous
Localization and Mapping (SLAM) algorithms in GNSS-denied environments, such as
in the context of planetary exploration. In these settings, visual place
recognition often fails due to aliasing and weak textures, while LiDAR-based
methods suffer from sparsity and ambiguity. This paper presents MPRF, a
multimodal pipeline that leverages transformer-based foundation models for both
vision and LiDAR modalities to achieve robust loop closure in severely
unstructured environments. Unlike prior work limited to retrieval, MPRF
integrates a two-stage visual retrieval strategy with explicit 6-DoF pose
estimation, combining DINOv2 features with SALAD aggregation for efficient
candidate screening and SONATA-based LiDAR descriptors for geometric
verification. Experiments on the S3LI dataset and S3LI Vulcano dataset show
that MPRF outperforms state-of-the-art retrieval methods in precision while
enhancing pose estimation robustness in low-texture regions. By providing
interpretable correspondences suitable for SLAM back-ends, MPRF achieves a
favorable trade-off between accuracy, efficiency, and reliability,
demonstrating the potential of foundation models to unify place recognition and
pose estimation. Code and models will be released at github.com/DLR-RM/MPRF.

</details>


### [45] [Another BRIXEL in the Wall: Towards Cheaper Dense Features](https://arxiv.org/abs/2511.05168)
*Alexander Lappe,Martin A. Giese*

Main category: cs.CV

TL;DR: BRIXEL通过知识蒸馏提升DINOv3在高分辨率任务中的性能，降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 解决DINOv3模型在高分辨率任务中计算成本高的问题。

Method: 提出BRIXEL，一种知识蒸馏方法，让学生模型学习在高分辨率下复现自身的特征图。

Result: BRIXEL在固定分辨率下显著超越基线DINOv3模型，并以更低计算成本生成与教师模型相似的特征图。

Conclusion: BRIXEL通过简单的知识蒸馏方法，显著提升了DINOv3模型在高分辨率任务中的性能，同时大幅降低了计算成本。

Abstract: Vision foundation models achieve strong performance on both global and
locally dense downstream tasks. Pretrained on large images, the recent DINOv3
model family is able to produce very fine-grained dense feature maps, enabling
state-of-the-art performance. However, computing these feature maps requires
the input image to be available at very high resolution, as well as large
amounts of compute due to the squared complexity of the transformer
architecture. To address these issues, we propose BRIXEL, a simple knowledge
distillation approach that has the student learn to reproduce its own feature
maps at higher resolution. Despite its simplicity, BRIXEL outperforms the
baseline DINOv3 models by large margins on downstream tasks when the resolution
is kept fixed. Moreover, it is able to produce feature maps that are very
similar to those of the teacher at a fraction of the computational cost. Code
and model weights are available at https://github.com/alexanderlappe/BRIXEL.

</details>


### [46] [MUSE: Multi-Scale Dense Self-Distillation for Nucleus Detection and Classification](https://arxiv.org/abs/2511.05170)
*Zijiang Yang,Hanqing Chao,Bokai Zhao,Yelin Yang,Yunshuo Zhang,Dongmei Fu,Junping Zhang,Le Lu,Ke Yan,Dakai Jin,Minfeng Xu,Yun Bian,Hui Jiang*

Main category: cs.CV

TL;DR: MUSE是一种针对病理图像细胞核检测与分类的自监督学习方法，通过NuLo机制和半监督微调，显著提升性能，超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖大量手动标注且难以利用未标注数据，限制了细胞核级表征的学习。

Method: 提出了MUSE（多尺度密集自蒸馏）方法，核心是NuLo（基于细胞核的局部自蒸馏）机制，结合坐标引导实现灵活的局部自蒸馏，并设计了编码器-解码器架构及半监督微调策略。

Result: 在三个广泛使用的基准测试中，MUSE显著优于现有监督方法和通用病理模型。

Conclusion: MUSE通过自监督学习方法显著提升了病理图像中细胞核检测与分类的性能，不仅超越了现有监督学习方法，还优于通用的病理基础模型。

Abstract: Nucleus detection and classification (NDC) in histopathology analysis is a
fundamental task that underpins a wide range of high-level pathology
applications. However, existing methods heavily rely on labor-intensive
nucleus-level annotations and struggle to fully exploit large-scale unlabeled
data for learning discriminative nucleus representations. In this work, we
propose MUSE (MUlti-scale denSE self-distillation), a novel self-supervised
learning method tailored for NDC. At its core is NuLo (Nucleus-based Local
self-distillation), a coordinate-guided mechanism that enables flexible local
self-distillation based on predicted nucleus positions. By removing the need
for strict spatial alignment between augmented views, NuLo allows critical
cross-scale alignment, thus unlocking the capacity of models for fine-grained
nucleus-level representation. To support MUSE, we design a simple yet effective
encoder-decoder architecture and a large field-of-view semi-supervised
fine-tuning strategy that together maximize the value of unlabeled pathology
images. Extensive experiments on three widely used benchmarks demonstrate that
MUSE effectively addresses the core challenges of histopathological NDC. The
resulting models not only surpass state-of-the-art supervised baselines but
also outperform generic pathology foundation models.

</details>


### [47] [TimeSearch-R: Adaptive Temporal Search for Long-Form Video Understanding via Self-Verification Reinforcement Learning](https://arxiv.org/abs/2511.05489)
*Junwen Pan,Qizhe Zhang,Rui Zhang,Ming Lu,Xin Wan,Yuan Zhang,Chang Liu,Qi She*

Main category: cs.CV

TL;DR: TimeSearch-R通过强化学习和自我验证机制优化视频时间搜索，显著提升性能并在多个测试中领先。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖手工设计的搜索流程，缺乏端到端优化，导致视频内容探索不足和逻辑推理不一致。

Method: 提出TimeSearch-R，将时间搜索重新定义为交错的文本-视频思考过程，结合强化学习（RL）和GRPO-CSV自我验证机制，优化搜索策略。

Result: 在Haystack-LVBench、Haystack-Ego4D等基准测试中表现优异，并在LongVideoBench上以4.1%的优势超越基础模型Qwen2.5-VL。

Conclusion: TimeSearch-R通过引入GRPO-CSV和自我验证机制，显著提升了长视频理解和时间搜索任务的性能，并在多个基准测试中创下新记录。

Abstract: Temporal search aims to identify a minimal set of relevant frames from tens
of thousands based on a given query, serving as a foundation for accurate
long-form video understanding. Existing works attempt to progressively narrow
the search space. However, these approaches typically rely on a hand-crafted
search process, lacking end-to-end optimization for learning optimal search
strategies. In this paper, we propose TimeSearch-R, which reformulates temporal
search as interleaved text-video thinking, seamlessly integrating searching
video clips into the reasoning process through reinforcement learning (RL).
However, applying RL training methods, such as Group Relative Policy
Optimization (GRPO), to video reasoning can result in unsupervised intermediate
search decisions. This leads to insufficient exploration of the video content
and inconsistent logical reasoning. To address these issues, we introduce GRPO
with Completeness Self-Verification (GRPO-CSV), which gathers searched video
frames from the interleaved reasoning process and utilizes the same policy
model to verify the adequacy of searched frames, thereby improving the
completeness of video reasoning. Additionally, we construct datasets
specifically designed for the SFT cold-start and RL training of GRPO-CSV,
filtering out samples with weak temporal dependencies to enhance task
difficulty and improve temporal search capabilities. Extensive experiments
demonstrate that TimeSearch-R achieves significant improvements on temporal
search benchmarks such as Haystack-LVBench and Haystack-Ego4D, as well as
long-form video understanding benchmarks like VideoMME and MLVU. Notably,
TimeSearch-R establishes a new state-of-the-art on LongVideoBench with 4.1%
improvement over the base model Qwen2.5-VL and 2.0% over the advanced video
reasoning model Video-R1. Our code is available at
https://github.com/Time-Search/TimeSearch-R.

</details>


### [48] [Walk the Lines 2: Contour Tracking for Detailed Segmentation](https://arxiv.org/abs/2511.05210)
*André Peter Kelm,Max Braeschke,Emre Gülsoylu,Simone Frintrop*

Main category: cs.CV

TL;DR: WtL2是一种创新的轮廓跟踪算法，扩展了原始WtL的应用范围，适用于IR船舶和RGB对象的分割，提供高精度细节和闭合轮廓，成为图像分割领域的理想选择。


<details>
  <summary>Details</summary>
Motivation: 为了扩展原始Walk the Lines（WtL）算法的应用范围，使其不仅限于彩色船舶的详细分割，还能适应红外（IR）船舶及RGB环境中的多种对象分割需求。

Method: WtL2通过轮廓跟踪技术替代传统的非极大值抑制（NMS），能够将对象轮廓细化至1像素宽的闭合形状，形成可分割的前景-背景区域。该算法通过调整输入（如IR船舶的轮廓检测器）并增强处理能力，适应了多种RGB对象的分割需求。

Result: WtL2在实现闭合对象轮廓时，表现优于最新的基于轮廓的方法，提供了高峰值交并比（IoU）和令人印象深刻的细节，适用于需要详细分割或高质量样本的专业应用。

Conclusion: WtL2作为一种创新的轮廓跟踪算法，不仅在红外（IR）船舶分割中表现出色，还能广泛应用于RGB环境中的多种对象分割，成为图像分割领域中高质量样本和详细分割的理想选择。

Abstract: This paper presents Walk the Lines 2 (WtL2), a unique contour tracking
algorithm specifically adapted for detailed segmentation of infrared (IR) ships
and various objects in RGB.1 This extends the original Walk the Lines (WtL)
[12], which focused solely on detailed ship segmentation in color. These
innovative WtLs can replace the standard non-maximum suppression (NMS) by using
contour tracking to refine the object contour until a 1-pixel-wide closed shape
can be binarized, forming a segmentable area in foreground-background
scenarios. WtL2 broadens the application range of WtL beyond its original
scope, adapting to IR and expanding to diverse objects within the RGB context.
To achieve IR segmentation, we adapt its input, the object contour detector, to
IR ships. In addition, the algorithm is enhanced to process a wide range of RGB
objects, outperforming the latest generation of contour-based methods when
achieving a closed object contour, offering high peak Intersection over Union
(IoU) with impressive details. This positions WtL2 as a compelling method for
specialized applications that require detailed segmentation or high-quality
samples, potentially accelerating progress in several niche areas of image
segmentation.

</details>


### [49] [FreeControl: Efficient, Training-Free Structural Control via One-Step Attention Extraction](https://arxiv.org/abs/2511.05219)
*Jiang Lin,Xinyu Chen,Song Wu,Zhiqiu Zhang,Jizhi Zhang,Ye Wang,Qiang Tang,Qian Wang,Jian Yang,Zili Yi*

Main category: cs.CV

TL;DR: FreeControl is a training-free method for controlling diffusion-generated images efficiently, using one-step attention extraction and LCD, with 5% extra cost.


<details>
  <summary>Details</summary>
Motivation: Existing methods like ControlNet and inversion-based approaches have limitations in flexibility, generalization, and inference cost, necessitating a more efficient solution.

Method: FreeControl performs one-step attention extraction from a single key timestep and reuses it throughout denoising, coupled with Latent-Condition Decoupling (LCD) for finer control.

Result: FreeControl achieves structurally and semantically aligned, visually coherent generation directly from raw images, with intuitive compositional design.

Conclusion: FreeControl introduces a training-free framework for semantic structural control in diffusion models, enabling efficient guidance without inversion or retraining, with approximately 5% additional cost.

Abstract: Controlling the spatial and semantic structure of diffusion-generated images
remains a challenge. Existing methods like ControlNet rely on handcrafted
condition maps and retraining, limiting flexibility and generalization.
Inversion-based approaches offer stronger alignment but incur high inference
cost due to dual-path denoising. We present FreeControl, a training-free
framework for semantic structural control in diffusion models. Unlike prior
methods that extract attention across multiple timesteps, FreeControl performs
one-step attention extraction from a single, optimally chosen key timestep and
reuses it throughout denoising. This enables efficient structural guidance
without inversion or retraining. To further improve quality and stability, we
introduce Latent-Condition Decoupling (LCD): a principled separation of the key
timestep and the noised latent used in attention extraction. LCD provides finer
control over attention quality and eliminates structural artifacts. FreeControl
also supports compositional control via reference images assembled from
multiple sources - enabling intuitive scene layout design and stronger prompt
alignment. FreeControl introduces a new paradigm for test-time control,
enabling structurally and semantically aligned, visually coherent generation
directly from raw images, with the flexibility for intuitive compositional
design and compatibility with modern diffusion models at approximately 5
percent additional cost.

</details>


### [50] [ADPretrain: Advancing Industrial Anomaly Detection via Anomaly Representation Pretraining](https://arxiv.org/abs/2511.05245)
*Xincheng Yao,Yan Luo,Zefeng Qian,Chongyang Zhang*

Main category: cs.CV

TL;DR: 本文提出了一种专门针对工业异常检测的预训练表示学习框架，解决了ImageNet预训练特征不匹配的问题，并在多个数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 当前主流的异常检测方法基于ImageNet预训练特征，但ImageNet预训练与异常检测目标不匹配，且存在分布偏移问题，导致其特征不适用于AD任务。

Method: 设计了一种新型的异常检测表示学习框架，包括角度和范数对比损失，以最大化正常和异常特征之间的差异，并使用大规模AD数据集RealIAD进行预训练。

Result: 在五个AD数据集和五个骨干网络上，使用提出的预训练特征显著提升了现有嵌入基AD方法的性能。

Conclusion: 提出的针对工业异常检测的预训练表示框架显著提升了现有方法的性能，证明了其优越性。

Abstract: The current mainstream and state-of-the-art anomaly detection (AD) methods
are substantially established on pretrained feature networks yielded by
ImageNet pretraining. However, regardless of supervised or self-supervised
pretraining, the pretraining process on ImageNet does not match the goal of
anomaly detection (i.e., pretraining in natural images doesn't aim to
distinguish between normal and abnormal). Moreover, natural images and
industrial image data in AD scenarios typically have the distribution shift.
The two issues can cause ImageNet-pretrained features to be suboptimal for AD
tasks. To further promote the development of the AD field, pretrained
representations specially for AD tasks are eager and very valuable. To this
end, we propose a novel AD representation learning framework specially designed
for learning robust and discriminative pretrained representations for
industrial anomaly detection. Specifically, closely surrounding the goal of
anomaly detection (i.e., focus on discrepancies between normals and anomalies),
we propose angle- and norm-oriented contrastive losses to maximize the angle
size and norm difference between normal and abnormal features simultaneously.
To avoid the distribution shift from natural images to AD images, our
pretraining is performed on a large-scale AD dataset, RealIAD. To further
alleviate the potential shift between pretraining data and downstream AD
datasets, we learn the pretrained AD representations based on the
class-generalizable representation, residual features. For evaluation, based on
five embedding-based AD methods, we simply replace their original features with
our pretrained representations. Extensive experiments on five AD datasets and
five backbones consistently show the superiority of our pretrained features.
The code is available at https://github.com/xcyao00/ADPretrain.

</details>


### [51] [Automatic segmentation of colorectal liver metastases for ultrasound-based navigated resection](https://arxiv.org/abs/2511.05253)
*Tiziano Natali,Karin A. Olthof,Niels F. M. Kok,Koert F. D. Kuhlmann,Theo J. M. Ruers,Matteo Fusaglia*

Main category: cs.CV

TL;DR: 该研究通过裁剪3D U-Net实现了CRLM在iUS中的自动3D分割，显著提升了分割精度和速度，适用于实时手术导航。


<details>
  <summary>Details</summary>
Motivation: Accurate intraoperative delineation of colorectal liver metastases (CRLM) is crucial for achieving negative resection margins but remains challenging using intraoperative ultrasound (iUS) due to low contrast, noise, and operator dependency. Automated segmentation could enhance precision and efficiency in ultrasound-based navigation workflows.

Method: Eighty-five tracked 3D iUS volumes from 85 CRLM patients were used to train and evaluate a 3D U-Net implemented via the nnU-Net framework. Two variants were compared: one trained on full iUS volumes and another on cropped regions around tumors. Segmentation accuracy was assessed using Dice Similarity Coefficient (DSC), Hausdorff Distance (HDist.), and Relative Volume Difference (RVD) on retrospective and prospective datasets. The workflow was integrated into 3D Slicer for real-time intraoperative use.

Result: The cropped-volume model significantly outperformed the full-volume model across all metrics (AUC-ROC = 0.898 vs 0.718). It achieved median DSC = 0.74, recall = 0.79, and HDist. = 17.1 mm comparable to semi-automatic segmentation but with ~4x faster execution (~ 1 min). Prospective intraoperative testing confirmed robust and consistent performance, with clinically acceptable accuracy for real-time surgical guidance.

Conclusion: Automatic 3D segmentation of CRLM in iUS using a cropped 3D U-Net provides reliable, near real-time results with minimal operator input. The method enables efficient, registration-free ultrasound-based navigation for hepatic surgery, approaching expert-level accuracy while substantially reducing manual workload and procedure time.

Abstract: Introduction: Accurate intraoperative delineation of colorectal liver
metastases (CRLM) is crucial for achieving negative resection margins but
remains challenging using intraoperative ultrasound (iUS) due to low contrast,
noise, and operator dependency. Automated segmentation could enhance precision
and efficiency in ultrasound-based navigation workflows.
  Methods: Eighty-five tracked 3D iUS volumes from 85 CRLM patients were used
to train and evaluate a 3D U-Net implemented via the nnU-Net framework. Two
variants were compared: one trained on full iUS volumes and another on cropped
regions around tumors. Segmentation accuracy was assessed using Dice Similarity
Coefficient (DSC), Hausdorff Distance (HDist.), and Relative Volume Difference
(RVD) on retrospective and prospective datasets. The workflow was integrated
into 3D Slicer for real-time intraoperative use.
  Results: The cropped-volume model significantly outperformed the full-volume
model across all metrics (AUC-ROC = 0.898 vs 0.718). It achieved median DSC =
0.74, recall = 0.79, and HDist. = 17.1 mm comparable to semi-automatic
segmentation but with ~4x faster execution (~ 1 min). Prospective
intraoperative testing confirmed robust and consistent performance, with
clinically acceptable accuracy for real-time surgical guidance.
  Conclusion: Automatic 3D segmentation of CRLM in iUS using a cropped 3D U-Net
provides reliable, near real-time results with minimal operator input. The
method enables efficient, registration-free ultrasound-based navigation for
hepatic surgery, approaching expert-level accuracy while substantially reducing
manual workload and procedure time.

</details>


### [52] [What's on Your Plate? Inferring Chinese Cuisine Intake from Wearable IMUs](https://arxiv.org/abs/2511.05292)
*Jiaxi Yin,Pengcheng Wang,Han Ding,Fei Wang*

Main category: cs.CV

TL;DR: CuisineSense是一种结合智能手表和智能眼镜的传感器数据，用于高精度分类中餐类型的系统，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 传统自我报告方法存在回忆偏差，基于相机的方法涉及隐私问题，现有可穿戴设备方法对中餐多样性覆盖不足。

Method: 设计了一个两阶段检测流程：第一阶段通过区分特征时间模式识别进食状态；第二阶段基于进食期间捕获的动作进行细粒度的食物类型识别。

Result: 实验表明，CuisineSense在进食状态检测和食物分类方面均达到了高准确率。

Conclusion: CuisineSense提供了一种实用的解决方案，通过结合智能手表和智能眼镜的传感器数据，实现了对中国食物类型的高精度分类，为无侵入式的饮食监测提供了可能。

Abstract: Accurate food intake detection is vital for dietary monitoring and chronic
disease prevention. Traditional self-report methods are prone to recall bias,
while camera-based approaches raise concerns about privacy. Furthermore,
existing wearable-based methods primarily focus on a limited number of food
types, such as hamburgers and pizza, failing to address the vast diversity of
Chinese cuisine. To bridge this gap, we propose CuisineSense, a system that
classifies Chinese food types by integrating hand motion cues from a smartwatch
with head dynamics from smart glasses. To filter out irrelevant daily
activities, we design a two-stage detection pipeline. The first stage
identifies eating states by distinguishing characteristic temporal patterns
from non-eating behaviors. The second stage then conducts fine-grained food
type recognition based on the motions captured during food intake. To evaluate
CuisineSense, we construct a dataset comprising 27.5 hours of IMU recordings
across 11 food categories and 10 participants. Experiments demonstrate that
CuisineSense achieves high accuracy in both eating state detection and food
classification, offering a practical solution for unobtrusive, wearable-based
dietary monitoring.The system code is publicly available at
https://github.com/joeeeeyin/CuisineSense.git.

</details>


### [53] [Cross-domain EEG-based Emotion Recognition with Contrastive Learning](https://arxiv.org/abs/2511.05293)
*Rui Yan,Yibo Li,Han Ding,Fei Wang*

Main category: cs.CV

TL;DR: EmotionCLIP利用EEG-文本匹配和多尺度Transformer，显著提升EEG情感识别的跨域性能。


<details>
  <summary>Details</summary>
Motivation: EEG情感识别在特征利用和跨域泛化方面存在挑战，需要一种更鲁棒的方法。

Method: 提出EmotionCLIP框架，将情感识别任务重构为EEG-文本匹配问题，并设计了SST-LegoViT骨干网络，结合多尺度卷积和Transformer模块捕获空间、频谱和时序特征。

Result: 在SEED和SEED-IV数据集上，跨被试准确率分别达到88.69%和73.50%，跨时间准确率分别为88.46%和77.54%，优于现有模型。

Conclusion: EmotionCLIP通过多模态对比学习框架，显著提升了EEG情感识别的跨域泛化能力，实验结果验证了其有效性。

Abstract: Electroencephalogram (EEG)-based emotion recognition is vital for affective
computing but faces challenges in feature utilization and cross-domain
generalization. This work introduces EmotionCLIP, which reformulates
recognition as an EEG-text matching task within the CLIP framework. A tailored
backbone, SST-LegoViT, captures spatial, spectral, and temporal features using
multi-scale convolution and Transformer modules. Experiments on SEED and
SEED-IV datasets show superior cross-subject accuracies of 88.69% and 73.50%,
and cross-time accuracies of 88.46% and 77.54%, outperforming existing models.
Results demonstrate the effectiveness of multimodal contrastive learning for
robust EEG emotion recognition.

</details>


### [54] [$\mathbf{S^2LM}$: Towards Semantic Steganography via Large Language Models](https://arxiv.org/abs/2511.05319)
*Huanqi Wu,Huangbiao Xu,Runfeng Xie,Jiaxin Cai,Kaixin Zhang,Xiao Ke*

Main category: cs.CV

TL;DR: 论文提出了一种句子到图像的语义隐写方法$\mathrm{S^2LM}$，利用LLMs嵌入高级文本信息，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在当前AIGC时代，隐写术的能力比以往任何时候都更为关键，但仍难以嵌入语义丰富的句子级信息。

Method: 提出了一个名为Invisible Text（IVT）的基准测试集，并开发了$\mathbf{S^2LM}$模型，利用LLMs在整个过程中嵌入高级文本信息到图像中。

Result: 定量和定性实验表明，$\mathrm{S^2LM}$方法有效解锁了LLMs在语义隐写中的新能力。

Conclusion: 论文提出了一种新型的句子到图像隐写术任务，并通过实验验证了其有效性，展示了LLMs在语义隐写中的潜力。源代码即将发布。

Abstract: Although steganography has made significant advancements in recent years, it
still struggles to embed semantically rich, sentence-level information into
carriers. However, in the era of AIGC, the capacity of steganography is more
critical than ever. In this work, we present Sentence-to-Image Steganography,
an instance of Semantic Steganography, a novel task that enables the hiding of
arbitrary sentence-level messages within a cover image. Furthermore, we
establish a benchmark named Invisible Text (IVT), comprising a diverse set of
sentence-level texts as secret messages for evaluation. Finally, we present
$\mathbf{S^2LM}$: Semantic Steganographic Language Model, which utilizes large
language models (LLMs) to embed high-level textual information, such as
sentences or even paragraphs, into images. Unlike traditional bit-level
counterparts, $\mathrm{S^2LM}$ enables the integration of semantically rich
content through a newly designed pipeline in which the LLM is involved
throughout the entire process. Both quantitative and qualitative experiments
demonstrate that our method effectively unlocks new semantic steganographic
capabilities for LLMs. The source code will be released soon.

</details>


### [55] [Canonical Space Representation for 4D Panoptic Segmentation of Articulated Objects](https://arxiv.org/abs/2511.05356)
*Manuel Gomes,Bogdan Raducanu,Miguel Oliveira*

Main category: cs.CV

TL;DR: 研究提出CanonSeg4D框架和Artic4D数据集，通过时间建模和规范对齐提升动态物体的全景分割精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法大多忽略时间动态，而动态物体本质上具有时序特性。4D时间数据在全景分割中的应用尚未充分探索，且缺乏基准数据集。

Method: 研究提出了CanonSeg4D框架，该框架通过估计每帧偏移将观察到的物体部分映射到学习的规范空间，从而增强部分级别的分割。框架利用这种规范表示实现序列帧中物体部分的一致对齐。

Result: 在Artic4D数据集上的实验表明，CanonSeg4D在复杂场景下的全景分割精度优于现有方法。

Conclusion: 该研究通过引入Artic4D数据集和CanonSeg4D框架，显著提升了动态物体理解的准确性，特别是在复杂场景下的全景分割任务中。结果表明，时间建模和规范对齐在动态物体感知中具有显著效果。

Abstract: Articulated object perception presents significant challenges in computer
vision, particularly because most existing methods ignore temporal dynamics
despite the inherently dynamic nature of such objects. The use of 4D temporal
data has not been thoroughly explored in articulated object perception and
remains unexamined for panoptic segmentation. The lack of a benchmark dataset
further hurt this field. To this end, we introduce Artic4D as a new dataset
derived from PartNet Mobility and augmented with synthetic sensor data,
featuring 4D panoptic annotations and articulation parameters. Building on this
dataset, we propose CanonSeg4D, a novel 4D panoptic segmentation framework.
This approach explicitly estimates per-frame offsets mapping observed object
parts to a learned canonical space, thereby enhancing part-level segmentation.
The framework employs this canonical representation to achieve consistent
alignment of object parts across sequential frames. Comprehensive experiments
on Artic4D demonstrate that the proposed CanonSeg4D outperforms state of the
art approaches in panoptic segmentation accuracy in more complex scenarios.
These findings highlight the effectiveness of temporal modeling and canonical
alignment in dynamic object understanding, and pave the way for future advances
in 4D articulated object perception.

</details>


### [56] [Dense Motion Captioning](https://arxiv.org/abs/2511.05369)
*Shiyao Xu,Benedetta Liberatori,Gül Varol,Paolo Rota*

Main category: cs.CV

TL;DR: 提出密集动作描述任务及CompMo数据集，DEMO模型在动作理解与描述上表现卓越。


<details>
  <summary>Details</summary>
Motivation: 现有3D人体动作与语言整合研究多集中于文本生成动作，动作理解任务相对未被充分探索。

Method: 提出DEMO模型，结合大语言模型与简单动作适配器，生成密集且时间锚定的描述。

Result: DEMO在CompMo数据集上表现优异，显著超越现有方法。

Conclusion: DEMO模型在CompMo数据集及适配基准测试中显著优于现有方法，为未来3D动作理解与描述研究奠定了坚实基础。

Abstract: Recent advances in 3D human motion and language integration have primarily
focused on text-to-motion generation, leaving the task of motion understanding
relatively unexplored. We introduce Dense Motion Captioning, a novel task that
aims to temporally localize and caption actions within 3D human motion
sequences. Current datasets fall short in providing detailed temporal
annotations and predominantly consist of short sequences featuring few actions.
To overcome these limitations, we present the Complex Motion Dataset (CompMo),
the first large-scale dataset featuring richly annotated, complex motion
sequences with precise temporal boundaries. Built through a carefully designed
data generation pipeline, CompMo includes 60,000 motion sequences, each
composed of multiple actions ranging from at least two to ten, accurately
annotated with their temporal extents. We further present DEMO, a model that
integrates a large language model with a simple motion adapter, trained to
generate dense, temporally grounded captions. Our experiments show that DEMO
substantially outperforms existing methods on CompMo as well as on adapted
benchmarks, establishing a robust baseline for future research in 3D motion
understanding and captioning.

</details>


### [57] [PreResQ-R1: Towards Fine-Grained Rank-and-Score Reinforcement Learning for Visual Quality Assessment via Preference-Response Disentangled Policy Optimization](https://arxiv.org/abs/2511.05393)
*Zehui Feng,Tian Qiu,Tong Wu,Junxuan Li,Huayuan Xu,Ting Han*

Main category: cs.CV

TL;DR: PreResQ-R1通过双分支奖励和GRPO优化，在少量数据上实现IQA/VQA的SOTA性能，并生成人类对齐的推理解释。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖监督微调或仅排名目标，导致推理浅显、分数校准差、跨域泛化能力有限。

Method: 提出PreResQ-R1框架，结合绝对分数回归和相对排名一致性，采用双分支奖励机制（分别建模样本内响应一致性和样本间偏好对齐），并通过GRPO优化。

Result: 在仅6K图像和28K视频的强化微调下，PreResQ-R1在10个IQA和5个VQA基准测试中取得最佳性能（SRCC和PLCC指标），IQA任务分别提升5.30%和2.15%。

Conclusion: PreResQ-R1通过引入双分支奖励机制和GRPO优化，在视觉质量评估（IQA和VQA）任务中实现了最先进的性能，并生成与人类感知一致的解释性推理轨迹。

Abstract: Visual Quality Assessment (QA) seeks to predict human perceptual judgments of
visual fidelity. While recent multimodal large language models (MLLMs) show
promise in reasoning about image and video quality, existing approaches mainly
rely on supervised fine-tuning or rank-only objectives, resulting in shallow
reasoning, poor score calibration, and limited cross-domain generalization. We
propose PreResQ-R1, a Preference-Response Disentangled Reinforcement Learning
framework that unifies absolute score regression and relative ranking
consistency within a single reasoning-driven optimization scheme. Unlike prior
QA methods, PreResQ-R1 introduces a dual-branch reward formulation that
separately models intra-sample response coherence and inter-sample preference
alignment, optimized via Group Relative Policy Optimization (GRPO). This design
encourages fine-grained, stable, and interpretable chain-of-thought reasoning
about perceptual quality. To extend beyond static imagery, we further design a
global-temporal and local-spatial data flow strategy for Video Quality
Assessment. Remarkably, with reinforcement fine-tuning on only 6K images and
28K videos, PreResQ-R1 achieves state-of-the-art results across 10 IQA and 5
VQA benchmarks under both SRCC and PLCC metrics, surpassing by margins of 5.30%
and textbf2.15% in IQA task, respectively. Beyond quantitative gains, it
produces human-aligned reasoning traces that reveal the perceptual cues
underlying quality judgments. Code and model are available.

</details>


### [58] [PALM: A Dataset and Baseline for Learning Multi-subject Hand Prior](https://arxiv.org/abs/2511.05403)
*Zicong Fan,Edoardo Remelli,David Dimond,Fadime Sener,Liuhao Ge,Bugra Tekin,Cem Keskin,Shreyas Hampali*

Main category: cs.CV

TL;DR: PALM数据集和PALM-Net通过多样化的手部扫描和逆向渲染技术，实现了高质量个性化手部建模。


<details>
  <summary>Details</summary>
Motivation: 解决因复杂几何、外观和关节结构导致的高质量个性化手部建模难题，并提供多样化的数据集支持。

Method: 通过物理基础的逆向渲染学习多主体的手部几何和材质属性先验，构建PALM-Net模型。

Result: PALM数据集包含13k高质量手部扫描和90k多视角图像，PALM-Net实现了单图像驱动的逼真、可重光照手部虚拟化身。

Conclusion: PALM数据集及其配套的PALM-Net方法为高质量、个性化的手部建模提供了有效解决方案，推动了手部建模及相关研究的发展。

Abstract: The ability to grasp objects, signal with gestures, and share emotion through
touch all stem from the unique capabilities of human hands. Yet creating
high-quality personalized hand avatars from images remains challenging due to
complex geometry, appearance, and articulation, particularly under
unconstrained lighting and limited views. Progress has also been limited by the
lack of datasets that jointly provide accurate 3D geometry, high-resolution
multiview imagery, and a diverse population of subjects. To address this, we
present PALM, a large-scale dataset comprising 13k high-quality hand scans from
263 subjects and 90k multi-view images, capturing rich variation in skin tone,
age, and geometry. To show its utility, we present a baseline PALM-Net, a
multi-subject prior over hand geometry and material properties learned via
physically based inverse rendering, enabling realistic, relightable
single-image hand avatar personalization. PALM's scale and diversity make it a
valuable real-world resource for hand modeling and related research.

</details>


### [59] [Sharing the Learned Knowledge-base to Estimate Convolutional Filter Parameters for Continual Image Restoration](https://arxiv.org/abs/2511.05421)
*Aupendu Kar,Krishnendu Ghosh,Prabir Kumar Biswas*

Main category: cs.CV

TL;DR: 该论文提出了一种简单的卷积层修改方法，用于持续学习中的图像恢复任务，无需主干架构修改，减少了计算开销，并提升了新任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的持续学习方法在图像恢复领域存在不足，尤其是处理大尺寸图像和多样化退化类型时。现有方法需要大量工程化的架构修改，导致显著的计算开销。

Method: 通过修改卷积层来适应先前恢复任务的知识，无需改变主干架构。这种方法可以无缝应用于任何深度架构。

Result: 实验验证表明，新恢复任务的引入不会影响现有任务的性能，并且通过适应先前任务创建的知识库，新任务的性能有所提升。

Conclusion: 该论文提出了一种简单的卷积层修改方法，能够在不需要对主干架构进行结构修改的情况下，适应先前恢复任务的知识，从而在不显著增加计算开销或推理时间的情况下，提升新恢复任务的性能。

Abstract: Continual learning is an emerging topic in the field of deep learning, where
a model is expected to learn continuously for new upcoming tasks without
forgetting previous experiences. This field has witnessed numerous
advancements, but few works have been attempted in the direction of image
restoration. Handling large image sizes and the divergent nature of various
degradation poses a unique challenge in the restoration domain. However,
existing works require heavily engineered architectural modifications for new
task adaptation, resulting in significant computational overhead.
Regularization-based methods are unsuitable for restoration, as different
restoration challenges require different kinds of feature processing. In this
direction, we propose a simple modification of the convolution layer to adapt
the knowledge from previous restoration tasks without touching the main
backbone architecture. Therefore, it can be seamlessly applied to any deep
architecture without any structural modifications. Unlike other approaches, we
demonstrate that our model can increase the number of trainable parameters
without significantly increasing computational overhead or inference time.
Experimental validation demonstrates that new restoration tasks can be
introduced without compromising the performance of existing tasks. We also show
that performance on new restoration tasks improves by adapting the knowledge
from the knowledge base created by previous restoration tasks. The code is
available at https://github.com/aupendu/continual-restore.

</details>


### [60] [Shared Latent Representation for Joint Text-to-Audio-Visual Synthesis](https://arxiv.org/abs/2511.05432)
*Dogucan Yaman,Seymanur Akti,Fevziye Irem Eyiokur,Alexander Waibel*

Main category: cs.CV

TL;DR: 提出基于HierSpeech++的文本到说话人脸合成框架，通过两阶段训练实现高质量视听同步，无需真实音频输入。


<details>
  <summary>Details</summary>
Motivation: 目标是实现无需真实音频输入的文本到语音及面部合成的紧密视听对齐，同时保持说话人身份和自然表达。

Method: 采用两阶段训练策略：先在Wav2Vec2嵌入上进行预训练，再在TTS输出上进行微调，以处理干净特征和TTS预测特征之间的分布偏移。

Result: 实验表明，基于TTS预测潜在特征的条件生成在唇同步和视觉真实感上均优于级联流程。

Conclusion: 该框架通过在TTS预测的潜在特征上进行条件生成，显著提升了唇同步和视觉真实感，优于传统的级联流程。

Abstract: We propose a text-to-talking-face synthesis framework leveraging latent
speech representations from HierSpeech++. A Text-to-Vec module generates
Wav2Vec2 embeddings from text, which jointly condition speech and face
generation. To handle distribution shifts between clean and TTS-predicted
features, we adopt a two-stage training: pretraining on Wav2Vec2 embeddings and
finetuning on TTS outputs. This enables tight audio-visual alignment, preserves
speaker identity, and produces natural, expressive speech and synchronized
facial motion without ground-truth audio at inference. Experiments show that
conditioning on TTS-predicted latent features outperforms cascaded pipelines,
improving both lip-sync and visual realism.

</details>


### [61] [How Many Tokens Do 3D Point Cloud Transformer Architectures Really Need?](https://arxiv.org/abs/2511.05449)
*Tuan Anh Tran,Duy M. H. Nguyen,Hoai-Chau Tran,Michael Barz,Khoa D. Doan,Roger Wattenhofer,Ngo Anh Vien,Mathias Niepert,Daniel Sonntag,Paul Swoboda*

Main category: cs.CV

TL;DR: gitmerge3D通过合并冗余令牌减少90-95%的计算量，保持性能，挑战了现有3D变换器的设计假设。


<details>
  <summary>Details</summary>
Motivation: 现有3D点云变换器依赖密集令牌表示，导致计算和内存成本高昂，研究发现令牌存在显著冗余。

Method: 提出了一种全局信息图令牌合并方法gitmerge3D，能将令牌数量减少90-95%，同时保持性能。

Result: 在多个3D视觉任务中验证了方法的有效性，计算效率显著提升。

Conclusion: 本研究挑战了现有3D点云变换器中令牌数量越多性能越好的假设，提出了gitmerge3D方法，显著减少了令牌冗余，提高了计算效率。

Abstract: Recent advances in 3D point cloud transformers have led to state-of-the-art
results in tasks such as semantic segmentation and reconstruction. However,
these models typically rely on dense token representations, incurring high
computational and memory costs during training and inference. In this work, we
present the finding that tokens are remarkably redundant, leading to
substantial inefficiency. We introduce gitmerge3D, a globally informed graph
token merging method that can reduce the token count by up to 90-95% while
maintaining competitive performance. This finding challenges the prevailing
assumption that more tokens inherently yield better performance and highlights
that many current models are over-tokenized and under-optimized for
scalability. We validate our method across multiple 3D vision tasks and show
consistent improvements in computational efficiency. This work is the first to
assess redundancy in large-scale 3D transformer models, providing insights into
the development of more efficient 3D foundation architectures. Our code and
checkpoints are publicly available at https://gitmerge3d.github.io

</details>


### [62] [The Potential of Copernicus Satellites for Disaster Response: Retrieving Building Damage from Sentinel-1 and Sentinel-2](https://arxiv.org/abs/2511.05461)
*Olivier Dietrich,Merlin Alfredsson,Emilia Arens,Nando Metzger,Torben Peters,Linus Scheibenreif,Jan Dirk Wegner,Konrad Schindler*

Main category: cs.CV

TL;DR: 研究证明中等分辨率（10米）的Copernicus图像可用于快速、大范围的建筑物损害评估，复杂模型架构和地理空间基础模型的实际优势有限。


<details>
  <summary>Details</summary>
Motivation: 自然灾害需要快速损害评估以指导人道主义响应，研究是否可以利用中等分辨率的地球观测图像补充超高分辨率图像的不足。

Method: 引入xBD-S12数据集，进行一系列实验，评估中等分辨率（10米）的Sentinel-1和Sentinel-2图像在建筑物损害检测和映射中的表现。

Result: 实验表明，尽管分辨率中等（10米），建筑物损害在许多灾害场景中可以被较好地检测和映射；复杂的模型架构在泛化到未见过的灾害时表现不佳，地理空间基础模型的实用价值有限。

Conclusion: Copernicus图像是快速、大面积损害评估的可行数据源，可以与超高分辨率图像一起发挥重要作用。

Abstract: Natural disasters demand rapid damage assessment to guide humanitarian
response. Here, we investigate whether medium-resolution Earth observation
images from the Copernicus program can support building damage assessment,
complementing very-high resolution imagery with often limited availability. We
introduce xBD-S12, a dataset of 10,315 pre- and post-disaster image pairs from
both Sentinel-1 and Sentinel-2, spatially and temporally aligned with the
established xBD benchmark. In a series of experiments, we demonstrate that
building damage can be detected and mapped rather well in many disaster
scenarios, despite the moderate 10$\,$m ground sampling distance. We also find
that, for damage mapping at that resolution, architectural sophistication does
not seem to bring much advantage: more complex model architectures tend to
struggle with generalization to unseen disasters, and geospatial foundation
models bring little practical benefit. Our results suggest that Copernicus
images are a viable data source for rapid, wide-area damage assessment and
could play an important role alongside VHR imagery. We release the xBD-S12
dataset, code, and trained models to support further research.

</details>


### [63] [Photo Dating by Facial Age Aggregation](https://arxiv.org/abs/2511.05464)
*Jakub Paplham,Vojtech Franc*

Main category: cs.CV

TL;DR: 本文提出了一种利用面部信息估计照片年代的新方法，通过多面部信息聚合显著提升了性能，并发布了一个包含160万标注面孔的数据集。


<details>
  <summary>Details</summary>
Motivation: 为了解决照片年代估计的问题，本文通过利用图像中人物面部的信息，提出了一种新方法，并发布了CSFD-1.6M数据集以支持相关研究。

Method: 本文提出了一种概率框架，结合了现代人脸识别和年龄估计模型的视觉证据，以及基于职业的时间先验，来推断照片的拍摄年份。

Result: 实验表明，聚合多个面部的证据能持续提高性能，该方法在包含多个可识别个体的图像中显著优于基于场景的基线方法。

Conclusion: 本文提出的多面部信息聚合方法在照片年代估计任务中表现优于基于场景的基线方法，特别是在包含多个可识别个体的图像中。

Abstract: We introduce a novel method for Photo Dating which estimates the year a
photograph was taken by leveraging information from the faces of people present
in the image. To facilitate this research, we publicly release CSFD-1.6M, a new
dataset containing over 1.6 million annotated faces, primarily from movie
stills, with identity and birth year annotations. Uniquely, our dataset
provides annotations for multiple individuals within a single image, enabling
the study of multi-face information aggregation. We propose a probabilistic
framework that formally combines visual evidence from modern face recognition
and age estimation models, and career-based temporal priors to infer the photo
capture year. Our experiments demonstrate that aggregating evidence from
multiple faces consistently improves the performance and the approach
significantly outperforms strong, scene-based baselines, particularly for
images containing several identifiable individuals.

</details>


### [64] [EventFlow: Real-Time Neuromorphic Event-Driven Classification of Two-Phase Boiling Flow Regimes](https://arxiv.org/abs/2511.05467)
*Sanghyeon Chang,Srikar Arani,Nishant Sai Nuthalapati,Youngjoon Suh,Nicholas Choi,Siavash Khodakarami,Md Rakibul Hasan Roni,Nenad Miljkovic,Aparna Chandramowlishwaran,Yoonjin Won*

Main category: cs.CV

TL;DR: 提出基于神经形态传感器的实时流态分类框架，事件数据模型优于传统方法，最佳模型达到97.6%准确率和0.28ms处理速度。


<details>
  <summary>Details</summary>
Motivation: 传统光学成像方法因计算需求高和时间分辨率不足，无法捕捉瞬态流动行为，需开发更高效的实时监测方法。

Method: 开发了五种分类模型，使用传统图像数据和事件数据进行比较，并设计了异步处理流水线以实现低延迟预测。

Result: 事件型长短期记忆模型实现了97.6%的分类准确率和0.28毫秒的处理时间，异步流水线支持连续低延迟预测。

Conclusion: 该论文提出了一种基于神经形态传感器的实时框架，用于流态分类，证明了利用事件数据的模型在动态流特征敏感性上优于基于帧的方法，尤其是事件型长短期记忆模型在准确性和速度上达到了最佳平衡。

Abstract: Flow boiling is an efficient heat transfer mechanism capable of dissipating
high heat loads with minimal temperature variation, making it an ideal thermal
management method. However, sudden shifts between flow regimes can disrupt
thermal performance and system reliability, highlighting the need for accurate
and low-latency real-time monitoring. Conventional optical imaging methods are
limited by high computational demands and insufficient temporal resolution,
making them inadequate for capturing transient flow behavior. To address this,
we propose a real-time framework based on signals from neuromorphic sensors for
flow regime classification. Neuromorphic sensors detect changes in brightness
at individual pixels, which typically correspond to motion at edges, enabling
fast and efficient detection without full-frame reconstruction, providing
event-based information. We develop five classification models using both
traditional image data and event-based data, demonstrating that models
leveraging event data outperform frame-based approaches due to their
sensitivity to dynamic flow features. Among these models, the event-based long
short-term memory model provides the best balance between accuracy and speed,
achieving 97.6% classification accuracy with a processing time of 0.28 ms. Our
asynchronous processing pipeline supports continuous, low-latency predictions
and delivers stable output through a majority voting mechanisms, enabling
reliable real-time feedback for experimental control and intelligent thermal
management.

</details>


### [65] [Semantic-Guided Natural Language and Visual Fusion for Cross-Modal Interaction Based on Tiny Object Detection](https://arxiv.org/abs/2511.05474)
*Xian-Hong Huang,Hui-Kai Su,Chi-Chia Sun,Jun-Wei Hsieh*

Main category: cs.CV

TL;DR: 该论文提出了一种结合自然语言处理与视觉识别骨干网络的新方法，显著提升了微小物体检测的精度和效率。


<details>
  <summary>Details</summary>
Motivation: 为了提升微小和复杂物体的检测精度，研究探索了语义引导的自然语言处理与先进视觉识别骨干网络的结合。

Method: 提出了一种将BERT语言模型与基于CNN的PRB-FPN-Net集成的方法，结合ELAN、MSP和CSP等骨干网络优化特征提取与融合，并使用词形还原和微调技术对齐文本与视觉特征。

Result: 在COCO2017验证集上取得了52.6%的平均精度（AP），显著优于YOLO-World，同时参数消耗仅为Transformer模型（如GLIP）的一半。

Conclusion: 本研究展示了结合自然语言理解与先进骨干网络架构在目标检测中的潜力，为准确性、效率和适应现实挑战设定了新基准。

Abstract: This paper introduces a cutting-edge approach to cross-modal interaction for
tiny object detection by combining semantic-guided natural language processing
with advanced visual recognition backbones. The proposed method integrates the
BERT language model with the CNN-based Parallel Residual Bi-Fusion Feature
Pyramid Network (PRB-FPN-Net), incorporating innovative backbone architectures
such as ELAN, MSP, and CSP to optimize feature extraction and fusion. By
employing lemmatization and fine-tuning techniques, the system aligns semantic
cues from textual inputs with visual features, enhancing detection precision
for small and complex objects. Experimental validation using the COCO and
Objects365 datasets demonstrates that the model achieves superior performance.
On the COCO2017 validation set, it attains a 52.6% average precision (AP),
outperforming YOLO-World significantly while maintaining half the parameter
consumption of Transformer-based models like GLIP. Several test on different of
backbones such ELAN, MSP, and CSP further enable efficient handling of
multi-scale objects, ensuring scalability and robustness in
resource-constrained environments. This study underscores the potential of
integrating natural language understanding with advanced backbone
architectures, setting new benchmarks in object detection accuracy, efficiency,
and adaptability to real-world challenges.

</details>


### [66] [GroupKAN: Rethinking Nonlinearity with Grouped Spline-based KAN Modeling for Efficient Medical Image Segmentation](https://arxiv.org/abs/2511.05477)
*Guojie Li,Anwar P. P. Abdul Majeed,Muhammad Ateeq,Anh Nguyen,Fan Zhang*

Main category: cs.CV

TL;DR: GroupKAN是一种轻量级医学图像分割网络，通过分组KAN变换和激活模块，在保持高准确性的同时降低计算复杂度和参数量。


<details>
  <summary>Details</summary>
Motivation: 解决现有卷积和Transformer架构在医学图像分割中缺乏自适应非线性、透明决策及高计算复杂度的问题。

Method: 采用分组KAN变换（降低复杂度至O(C^2/G)）和分组KAN激活（共享样条映射）模块。

Result: 在三个医学基准测试中平均IoU达79.80%，参数量仅为U-KAN的47.6%（3.02M vs 6.35M）。

Conclusion: GroupKAN在准确性、轻量化和可解释性上均优于现有方法，展现了高效的分割性能。

Abstract: Medical image segmentation requires models that are accurate, lightweight,
and interpretable. Convolutional architectures lack adaptive nonlinearity and
transparent decision-making, whereas Transformer architectures are hindered by
quadratic complexity and opaque attention mechanisms. U-KAN addresses these
challenges using Kolmogorov-Arnold Networks, achieving higher accuracy than
both convolutional and attention-based methods, fewer parameters than
Transformer variants, and improved interpretability compared to conventional
approaches. However, its O(C^2) complexity due to full-channel transformations
limits its scalability as the number of channels increases. To overcome this,
we introduce GroupKAN, a lightweight segmentation network that incorporates two
novel, structured functional modules: (1) Grouped KAN Transform, which
partitions channels into G groups for multivariate spline mappings, reducing
complexity to O(C^2/G), and (2) Grouped KAN Activation, which applies shared
spline-based mappings within each channel group for efficient, token-wise
nonlinearity. Evaluated on three medical benchmarks (BUSI, GlaS, and CVC),
GroupKAN achieves an average IoU of 79.80 percent, surpassing U-KAN by +1.11
percent while requiring only 47.6 percent of the parameters (3.02M vs 6.35M),
and shows improved interpretability.

</details>


### [67] [Visual Spatial Tuning](https://arxiv.org/abs/2511.05491)
*Rui Yang,Ziyu Zhu,Yanwei Li,Jingjia Huang,Shen Yan,Siyuan Zhou,Zhe Liu,Xiangtai Li,Shuangye Li,Wenqian Wang,Yi Lin,Hengshuang Zhao*

Main category: cs.CV

TL;DR: VST enhances VLMs' spatial abilities via large-scale datasets and progressive training, achieving top benchmark scores without compromising general performance.


<details>
  <summary>Details</summary>
Motivation: To enhance the spatial ability in general architectures without adding extra overhead or harming general capabilities.

Method: VST introduces a comprehensive framework including VST-P (a large-scale dataset for spatial perception) and VST-R (a curated dataset for spatial reasoning), followed by a progressive training pipeline with supervised fine-tuning and reinforcement learning.

Result: VST achieves state-of-the-art results, including 34.8% on MMSI-Bench and 61.2% on VSIBench.

Conclusion: The proposed Visual Spatial Tuning (VST) framework significantly enhances the spatial abilities of Vision-Language Models without compromising general capabilities, achieving state-of-the-art performance on spatial benchmarks.

Abstract: Capturing spatial relationships from visual inputs is a cornerstone of
human-like general intelligence. Several previous studies have tried to enhance
the spatial awareness of Vision-Language Models (VLMs) by adding extra expert
encoders, which brings extra overhead and usually harms general capabilities.
To enhance the spatial ability in general architectures, we introduce Visual
Spatial Tuning (VST), a comprehensive framework to cultivate VLMs with
human-like visuospatial abilities, from spatial perception to reasoning. We
first attempt to enhance spatial perception in VLMs by constructing a
large-scale dataset termed VST-P, which comprises 4.1 million samples spanning
19 skills across single views, multiple images, and videos. Then, we present
VST-R, a curated dataset with 135K samples that instruct models to reason in
space. In particular, we adopt a progressive training pipeline: supervised
fine-tuning to build foundational spatial knowledge, followed by reinforcement
learning to further improve spatial reasoning abilities. Without the
side-effect to general capabilities, the proposed VST consistently achieves
state-of-the-art results on several spatial benchmarks, including $34.8\%$ on
MMSI-Bench and $61.2\%$ on VSIBench. It turns out that the
Vision-Language-Action models can be significantly enhanced with the proposed
spatial tuning paradigm, paving the way for more physically grounded AI.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [68] [A hybrid solution approach for the Integrated Healthcare Timetabling Competition 2024](https://arxiv.org/abs/2511.04685)
*Daniela Guericke,Rolf van der Hulst,Asal Karimpour,Ieke Schrader,Matthias Walter*

Main category: cs.AI

TL;DR: 团队Twente在2024年综合医疗时间表竞赛中获第三名，采用混合整数规划、约束编程和模拟退火的三阶段方法，并提出未解决问题以改进方法。


<details>
  <summary>Details</summary>
Motivation: 参与2024年综合医疗时间表竞赛，并获得第三名。

Method: 结合混合整数规划、约束编程和模拟退火的三阶段解决方案，基于子问题分解。

Result: 分享了设计决策和见解，首次提供了基准实例最优解的下界。

Conclusion: 团队强调了未解决的问题，认为解决这些问题可以进一步提升他们的方法。

Abstract: We report about the algorithm, implementation and results submitted to the
Integrated Healthcare Timetabling Competition 2024 by Team Twente, which scored
third in the competition. Our approach combines mixed-integer programming,
constraint programming and simulated annealing in a 3-phase solution approach
based on decomposition into subproblems. Next to describing our approach and
describing our design decisions, we share our insights and, for the first time,
lower bounds on the optimal solution values for the benchmark instances. We
finally highlight open problems for which we think that addressing them could
improve our approach even further.

</details>


### [69] [Epistemic Reject Option Prediction](https://arxiv.org/abs/2511.04855)
*Vojtech Franc,Jakub Paplham*

Main category: cs.AI

TL;DR: 本文提出了一种新的拒绝选项预测器，专注于处理数据不足导致的高认知不确定性，通过最小化预期遗憾优化模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统拒绝选项方法仅关注随机不确定性，假设训练数据足够大以使认知不确定性可忽略，但实际场景中数据有限，此假设不成立。

Method: 基于贝叶斯学习，重新定义最优预测器为最小化预期遗憾的模型，并在输入超出指定拒绝成本时拒绝预测。

Result: 提出了首个能够识别训练数据不足以做出可靠决策的输入的原则性框架。

Conclusion: 本文提出了一个基于贝叶斯学习的拒绝选项预测器，通过最小化预期遗憾来优化模型，使其在数据不足的情况下能够识别并拒绝高认知不确定性的输入。

Abstract: In high-stakes applications, predictive models must not only produce accurate
predictions but also quantify and communicate their uncertainty. Reject-option
prediction addresses this by allowing the model to abstain when prediction
uncertainty is high. Traditional reject-option approaches focus solely on
aleatoric uncertainty, an assumption valid only when large training data makes
the epistemic uncertainty negligible. However, in many practical scenarios,
limited data makes this assumption unrealistic. This paper introduces the
epistemic reject-option predictor, which abstains in regions of high epistemic
uncertainty caused by insufficient data. Building on Bayesian learning, we
redefine the optimal predictor as the one that minimizes expected regret -- the
performance gap between the learned model and the Bayes-optimal predictor with
full knowledge of the data distribution. The model abstains when the regret for
a given input exceeds a specified rejection cost. To our knowledge, this is the
first principled framework that enables learning predictors capable of
identifying inputs for which the training data is insufficient to make reliable
decisions.

</details>


### [70] [DMA: Online RAG Alignment with Human Feedback](https://arxiv.org/abs/2511.04880)
*Yu Bai,Yukai Miao,Dawei Wang,Li Chen,Fei Long,Rundi Zhai,Dan Li,Yanyu Ren,Tianfeng Liu,Hongtao Xie,Ce Yang,Xuhui Cai*

Main category: cs.AI

TL;DR: DMA框架通过多粒度反馈实现RAG系统的动态调整，提升在线和离线性能。


<details>
  <summary>Details</summary>
Motivation: 解决RAG系统中静态检索无法适应动态意图和内容漂移的问题。

Method: DMA框架通过整合多粒度人类反馈，构建了一个连贯的学习流程，包括监督训练、策略优化和知识蒸馏。

Result: 在线部署显示人类参与度显著提升；离线测试在知识密集型基准上表现优异。

Conclusion: DMA作为一种反馈驱动的实时适应方法，在不牺牲基线能力的前提下，为RAG系统提供了有效的动态调整方案。

Abstract: Retrieval-augmented generation (RAG) systems often rely on static retrieval,
limiting adaptation to evolving intent and content drift. We introduce Dynamic
Memory Alignment (DMA), an online learning framework that systematically
incorporates multi-granularity human feedback to align ranking in interactive
settings. DMA organizes document-, list-, and response-level signals into a
coherent learning pipeline: supervised training for pointwise and listwise
rankers, policy optimization driven by response-level preferences, and
knowledge distillation into a lightweight scorer for low-latency serving.
Throughout this paper, memory refers to the model's working memory, which is
the entire context visible to the LLM for In-Context Learning.
  We adopt a dual-track evaluation protocol mirroring deployment: (i)
large-scale online A/B ablations to isolate the utility of each feedback
source, and (ii) few-shot offline tests on knowledge-intensive benchmarks.
Online, a multi-month industrial deployment further shows substantial
improvements in human engagement. Offline, DMA preserves competitive
foundational retrieval while yielding notable gains on conversational QA
(TriviaQA, HotpotQA). Taken together, these results position DMA as a
principled approach to feedback-driven, real-time adaptation in RAG without
sacrificing baseline capability.

</details>


### [71] [Real-Time Reasoning Agents in Evolving Environments](https://arxiv.org/abs/2511.04898)
*Yule Wen,Yixin Ye,Yanzhe Zhang,Diyi Yang,Hao Zhu*

Main category: cs.AI

TL;DR: 论文提出实时推理问题，构建实验平台，比较反应式和规划式代理，提出 AgileThinker 结合两者优势，在动态环境中表现更优。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的代理不仅需要逻辑判断，还需要及时判断，现有语言模型推理方法未能充分考虑动态环境的变化。

Method: 引入了实时推理作为动态环境中代理的新问题表述，并构建了 Real-Time Reasoning Gym 进行实验，研究了反应式代理和规划式代理两种范式。

Result: 实验表明，即使最先进的模型在任一范式中也难以同时满足逻辑和及时判断。AgileThinker 在任务难度和时间压力增加时表现优于单一范式代理。

Conclusion: AgileThinker 通过同时采用反应式和规划式推理范式，在任务难度和时间压力增加时表现优于单一范式代理，为开发实时能力代理提供了关键测试平台和研究基础。

Abstract: Agents in the real world must make not only logical but also timely
judgments. This requires continuous awareness of the dynamic environment:
hazards emerge, opportunities arise, and other agents act, while the agent's
reasoning is still unfolding. Despite advances in language model reasoning,
existing approaches fail to account for this dynamic nature. We introduce
real-time reasoning as a new problem formulation for agents in evolving
environments and build Real-Time Reasoning Gym to demonstrate it. We study two
paradigms for deploying language models in agents: (1) reactive agents, which
employ language models with bounded reasoning computation for rapid responses,
and (2) planning agents, which allow extended reasoning computation for complex
problems. Our experiments show that even state-of-the-art models struggle with
making logical and timely judgments in either paradigm. To address this
limitation, we propose AgileThinker, which simultaneously engages both
reasoning paradigms. AgileThinker consistently outperforms agents engaging only
one reasoning paradigm as the task difficulty and time pressure rise,
effectively balancing reasoning depth and response latency. Our work
establishes real-time reasoning as a critical testbed for developing practical
agents and provides a foundation for research in temporally constrained AI
systems, highlighting a path toward real-time capable agents.

</details>


### [72] [ORCHID: Orchestrated Retrieval-Augmented Classification with Human-in-the-Loop Intelligent Decision-Making for High-Risk Property](https://arxiv.org/abs/2511.04956)
*Maria Mahbub,Vanessa Lama,Sanjay Das,Brian Starks,Christopher Polchek,Saffell Silvers,Lauren Deck,Prasanna Balaprakash,Tirthankar Ghosal*

Main category: cs.AI

TL;DR: ORCHID是一个模块化代理系统，结合RAG和人类监督，提升高风险财产分类的准确性和可追溯性，适用于敏感的美国能源部合规工作流。


<details>
  <summary>Details</summary>
Motivation: 传统的高风险财产分类工作流依赖专家，耗时且易产生积压，难以跟上不断变化的法规边界，ORCHID旨在解决这些问题。

Method: ORCHID采用检索增强生成（RAG）与人类监督结合的模块化代理系统，通过小协作代理（检索、描述精炼器、分类器、验证器和反馈记录器）协调工作，利用模型上下文协议（MCP）实现模型无关的本地操作。

Result: 在真实高风险财产案例的初步测试中，ORCHID相比非代理基线提高了准确性和可追溯性，并将不确定项目交由专家处理。

Conclusion: ORCHID系统通过模块化代理和人类监督的结合，提升了高风险财产分类的准确性和可追溯性，为敏感的美国能源部合规工作流提供了可信赖的LLM辅助路径。

Abstract: High-Risk Property (HRP) classification is critical at U.S. Department of
Energy (DOE) sites, where inventories include sensitive and often dual-use
equipment. Compliance must track evolving rules designated by various export
control policies to make transparent and auditable decisions. Traditional
expert-only workflows are time-consuming, backlog-prone, and struggle to keep
pace with shifting regulatory boundaries. We demo ORCHID, a modular agentic
system for HRP classification that pairs retrieval-augmented generation (RAG)
with human oversight to produce policy-based outputs that can be audited. Small
cooperating agents, retrieval, description refiner, classifier, validator, and
feedback logger, coordinate via agent-to-agent messaging and invoke tools
through the Model Context Protocol (MCP) for model-agnostic on-premise
operation. The interface follows an Item to Evidence to Decision loop with
step-by-step reasoning, on-policy citations, and append-only audit bundles
(run-cards, prompts, evidence). In preliminary tests on real HRP cases, ORCHID
improves accuracy and traceability over a non-agentic baseline while deferring
uncertain items to Subject Matter Experts (SMEs). The demonstration shows
single item submission, grounded citations, SME feedback capture, and
exportable audit artifacts, illustrating a practical path to trustworthy LLM
assistance in sensitive DOE compliance workflows.

</details>


### [73] [Autonomous generation of different courses of action in mechanized combat operations](https://arxiv.org/abs/2511.05182)
*Johan Schubert,Patrik Hansen,Pontus Hörling,Ronnie Johansson*

Main category: cs.AI

TL;DR: 论文提出了一种机械化营作战决策支持方法，通过动态生成和评估行动方案，优化战场决策。


<details>
  <summary>Details</summary>
Motivation: 旨在提升机械化营在地面作战中的决策效率和质量，通过动态生成和评估行动方案，适应不断变化的战场条件。

Method: 该方法论从初始行动集出发，系统生成数千个行动替代方案，并基于对手状态和行动进行评价，考量单元组成、力量比例、进攻和防御类型及预期推进率等因素。

Result: 通过并发生成和评估过程，该方法能提供多样化的行动替代方案，并在战斗条件变化时实时更新建议。

Conclusion: 该论文提出了一种方法论，旨在支持机械化营在地面作战行动执行阶段的决策，通过生成和评估多种行动方案，为决策者提供优化的行动建议。

Abstract: In this paper, we propose a methodology designed to support decision-making
during the execution phase of military ground combat operations, with a focus
on one's actions. This methodology generates and evaluates recommendations for
various courses of action for a mechanized battalion, commencing with an
initial set assessed by their anticipated outcomes. It systematically produces
thousands of individual action alternatives, followed by evaluations aimed at
identifying alternative courses of action with superior outcomes. These
alternatives are appraised in light of the opponent's status and actions,
considering unit composition, force ratios, types of offense and defense, and
anticipated advance rates. Field manuals evaluate battle outcomes and
advancement rates. The processes of generation and evaluation work
concurrently, yielding a variety of alternative courses of action. This
approach facilitates the management of new course generation based on
previously evaluated actions. As the combat unfolds and conditions evolve,
revised courses of action are formulated for the decision-maker within a
sequential decision-making framework.

</details>


### [74] [Cleaning Maintenance Logs with LLM Agents for Improved Predictive Maintenance](https://arxiv.org/abs/2511.05311)
*Valeriu Dimidov,Faisal Hawlader,Sasan Jafarnejad,Raphaël Frank*

Main category: cs.AI

TL;DR: LLM-based agents effectively clean maintenance logs for PdM, though domain-specific errors remain challenging, suggesting need for further improvements.


<details>
  <summary>Details</summary>
Motivation: Economic constraints, limited datasets, and expertise shortages hinder PdM adoption in the automotive sector. LLMs present an opportunity to overcome these barriers and accelerate PdM's transition from research to industry.

Method: The study evaluates LLM-based agents on cleaning tasks involving six distinct types of noise in maintenance logs, a critical data source for training ML models.

Result: LLMs are effective at handling generic cleaning tasks, offering a promising foundation for future industrial applications.

Conclusion: LLM-based agents show promise in handling generic cleaning tasks for predictive maintenance (PdM) in the automotive sector, though domain-specific errors remain a challenge. Further improvements through specialized training and enhanced agentic capabilities are needed.

Abstract: Economic constraints, limited availability of datasets for reproducibility
and shortages of specialized expertise have long been recognized as key
challenges to the adoption and advancement of predictive maintenance (PdM) in
the automotive sector. Recent progress in large language models (LLMs) presents
an opportunity to overcome these barriers and speed up the transition of PdM
from research to industrial practice. Under these conditions, we explore the
potential of LLM-based agents to support PdM cleaning pipelines. Specifically,
we focus on maintenance logs, a critical data source for training
well-performing machine learning (ML) models, but one often affected by errors
such as typos, missing fields, near-duplicate entries, and incorrect dates. We
evaluate LLM agents on cleaning tasks involving six distinct types of noise.
Our findings show that LLMs are effective at handling generic cleaning tasks
and offer a promising foundation for future industrial applications. While
domain-specific errors remain challenging, these results highlight the
potential for further improvements through specialized training and enhanced
agentic capabilities.

</details>


### [75] [Reasoning Is All You Need for Urban Planning AI](https://arxiv.org/abs/2511.05375)
*Sijie Yang,Jiatong Li,Filip Biljecki*

Main category: cs.AI

TL;DR: 该论文提出了一个AI代理框架，用于城市规划决策，结合推理能力和多代理协作，以透明和规范的方式增强人类规划者。


<details>
  <summary>Details</summary>
Motivation: AI在分析城市规划方面已高度成功，但下一步是AI辅助决策：代理能推荐地点、分配资源并评估权衡，同时透明地推理约束和利益相关者价值。

Method: 该立场论文提出了一个具有推理能力的规划代理框架，整合了三个认知层（感知、基础、推理）与六个逻辑组件（分析、生成、验证、评估、协作、决策），并通过多代理协作框架实现。

Result: 该框架展示了为什么规划决策需要明确的推理能力，这些能力基于价值（应用规范原则）、基于规则（保证约束满足）和可解释（生成透明理由），这是统计学习无法单独实现的。

Conclusion: 该框架展示了AI代理如何通过系统探索解决方案空间、验证法规合规性及透明权衡利弊来增强人类规划者的能力，而非替代人类判断，而是通过计算推理能力放大其判断。

Abstract: AI has proven highly successful at urban planning analysis -- learning
patterns from data to predict future conditions. The next frontier is
AI-assisted decision-making: agents that recommend sites, allocate resources,
and evaluate trade-offs while reasoning transparently about constraints and
stakeholder values. Recent breakthroughs in reasoning AI -- CoT prompting,
ReAct, and multi-agent collaboration frameworks -- now make this vision
achievable.
  This position paper presents the Agentic Urban Planning AI Framework for
reasoning-capable planning agents that integrates three cognitive layers
(Perception, Foundation, Reasoning) with six logic components (Analysis,
Generation, Verification, Evaluation, Collaboration, Decision) through a
multi-agents collaboration framework. We demonstrate why planning decisions
require explicit reasoning capabilities that are value-based (applying
normative principles), rule-grounded (guaranteeing constraint satisfaction),
and explainable (generating transparent justifications) -- requirements that
statistical learning alone cannot fulfill. We compare reasoning agents with
statistical learning, present a comprehensive architecture with benchmark
evaluation metrics, and outline critical research challenges. This framework
shows how AI agents can augment human planners by systematically exploring
solution spaces, verifying regulatory compliance, and deliberating over
trade-offs transparently -- not replacing human judgment but amplifying it with
computational reasoning capabilities.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [76] [Marionette: Data Structure Description and Management for Heterogeneous Computing](https://arxiv.org/abs/2511.04853)
*Nuno dos Santos Fernandes,Pedro Tomás,Nuno Roma,Frank Winklmeier,Patricia Conde-Muíño*

Main category: cs.DC

TL;DR: Marionette是一个C++17库，旨在简化大型C++代码库在异构平台的硬件加速，通过解耦数据布局与接口描述，支持高效跨设备数据传输。


<details>
  <summary>Details</summary>
Motivation: 解决大型面向对象C++代码库在异构平台（如GPU）硬件加速中的复杂性和挑战。

Method: Marionette采用C++17库设计，通过编译时抽象实现低运行时开销，支持接口增强和跨设备数据传输。

Result: 通过CUDA案例研究展示了Marionette的高效性和灵活性。

Conclusion: Marionette库通过解耦数据布局与接口描述，支持多种内存管理策略，并提供高效的数据传输和转换，有效解决了大型C++代码库在异构平台硬件加速中的挑战。

Abstract: Adapting large, object-oriented C++ codebases for hardware acceleration might
be extremely challenging, particularly when targeting heterogeneous platforms
such as GPUs. Marionette is a C++17 library designed to address this by
enabling flexible, efficient, and portable data structure definitions. It
decouples data layout from the description of the interface, supports multiple
memory management strategies, and provides efficient data transfers and
conversions across devices, all of this with minimal runtime overhead due to
the compile-time nature of its abstractions. By allowing interfaces to be
augmented with arbitrary functions, Marionette maintains compatibility with
existing code and offers a streamlined interface that supports both
straightforward and advanced use cases. This paper outlines its design, usage,
and performance, including a CUDA-based case study demonstrating its efficiency
and flexibility.

</details>


### [77] [Accelerating HDC-CNN Hybrid Models Using Custom Instructions on RISC-V GPUs](https://arxiv.org/abs/2511.05053)
*Wakuto Matsumi,Riaz-Ul-Haque Mian*

Main category: cs.DC

TL;DR: Hybrid HDC-CNN workloads benefit from custom GPU instructions on RISC-V, achieving up to 56.2x performance gains.


<details>
  <summary>Details</summary>
Motivation: To address the high energy consumption of neural networks and the limitations of HDC in complex visual tasks by leveraging the flexibility of RISC-V GPUs.

Method: Design and implementation of custom GPU instructions optimized for HDC operations to enable efficient processing for hybrid HDC-CNN workloads.

Result: Experimental results show a performance improvement of up to 56.2 times in microbenchmark tests with custom HDC instructions.

Conclusion: The study demonstrates the potential of RISC-V GPUs with custom HDC instructions for energy-efficient, high-performance computing, showing significant performance improvements.

Abstract: Machine learning based on neural networks has advanced rapidly, but the high
energy consumption required for training and inference remains a major
challenge. Hyperdimensional Computing (HDC) offers a lightweight,
brain-inspired alternative that enables high parallelism but often suffers from
lower accuracy on complex visual tasks. To overcome this, hybrid accelerators
combining HDC and Convolutional Neural Networks (CNNs) have been proposed,
though their adoption is limited by poor generalizability and programmability.
The rise of open-source RISC-V architectures has created new opportunities for
domain-specific GPU design. Unlike traditional proprietary GPUs, emerging
RISC-V-based GPUs provide flexible, programmable platforms suitable for custom
computation models such as HDC. In this study, we design and implement custom
GPU instructions optimized for HDC operations, enabling efficient processing
for hybrid HDC-CNN workloads. Experimental results using four types of custom
HDC instructions show a performance improvement of up to 56.2 times in
microbenchmark tests, demonstrating the potential of RISC-V GPUs for
energy-efficient, high-performance computing.

</details>


### [78] [GPU Under Pressure: Estimating Application's Stress via Telemetry and Performance Counters](https://arxiv.org/abs/2511.05067)
*Giuseppe Esposito,Juan-David Guerrero-Balaguera,Josie Esteban Rodriguez Condia,Matteo Sonza Reorda,Marco Barbiero,Rossella Fortuna*

Main category: cs.DC

TL;DR: 该论文通过结合在线遥测参数和硬件性能计数器，评估了不同应用程序对GPU的压力，以预测可靠性问题。


<details>
  <summary>Details</summary>
Motivation: 持续工作负载会对GPU组件造成显著压力，可能导致故障和计算错误，因此需要准确评估压力以预测可靠性问题。

Method: 结合在线遥测参数和硬件性能计数器，重点关注吞吐量、已发出指令数量和停顿事件。

Result: 实验结果表明，通过结合遥测数据和使用性能计数器可以准确评估并行工作负载对GPU的压力。

Conclusion: 结合在线遥测参数和硬件性能计数器可以有效地评估不同应用程序对GPU的压力，从而预测可靠性问题。

Abstract: Graphics Processing Units (GPUs) are specialized accelerators in data centers
and high-performance computing (HPC) systems, enabling the fast execution of
compute-intensive applications, such as Convolutional Neural Networks (CNNs).
However, sustained workloads can impose significant stress on GPU components,
raising reliability concerns due to potential faults that corrupt the
intermediate application computations, leading to incorrect results. Estimating
the stress induced by an application is thus crucial to predict reliability
(with\,special\,emphasis\,on\,aging\,effects). In this work, we combine online
telemetry parameters and hardware performance counters to assess GPU stress
induced by different applications. The experimental results indicate the stress
induced by a parallel workload can be estimated by combining telemetry data and
Performance Counters that reveal the efficiency in the resource usage of the
target workload. For this purpose the selected performance counters focus on
measuring the i) throughput, ii) amount of issued instructions and iii) stall
events.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [79] [DAFM: Dynamic Adaptive Fusion for Multi-Model Collaboration in Composed Image Retrieval](https://arxiv.org/abs/2511.05020)
*Yawei Cai,Jiapeng Mi,Nan Ji,Haotian Rong,Yawei Zhang,Zhangti Li,Wenbin Guo,Rensong Xie*

Main category: cs.GR

TL;DR: DAFM通过动态多模型协作解决了CIR中单一模型的局限性，显著提升了检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有单一模型方法无法同时兼顾全局与细节，且缺乏动态权重分配机制，导致检索性能受限。

Method: 提出了动态自适应融合（DAFM）方法，通过自适应调整异构模型的贡献权重，实现多模型协作。

Result: 在CIRR和FashionIQ基准测试中，DAFM分别取得了93.21的Recall@10和84.43的Rmean，以及平均Rmean 67.48，性能提升最高达4.5%。

Conclusion: 动态自适应融合（DAFM）方法通过多模型协作，显著提升了组合图像检索（CIR）的准确性和鲁棒性，并在多个基准测试中超越了现有基线方法。

Abstract: Composed Image Retrieval (CIR) is a cross-modal task that aims to retrieve
target images from large-scale databases using a reference image and a
modification text. Most existing methods rely on a single model to perform
feature fusion and similarity matching. However, this paradigm faces two major
challenges. First, one model alone can't see the whole picture and the tiny
details at the same time; it has to handle different tasks with the same
weights, so it often misses the small but important links between image and
text. Second, the absence of dynamic weight allocation prevents adaptive
leveraging of complementary model strengths, so the resulting embedding drifts
away from the target and misleads the nearest-neighbor search in CIR. To
address these limitations, we propose Dynamic Adaptive Fusion (DAFM) for
multi-model collaboration in CIR. Rather than optimizing a single method in
isolation, DAFM exploits the complementary strengths of heterogeneous models
and adaptively rebalances their contributions. This not only maximizes
retrieval accuracy but also ensures that the performance gains are independent
of the fusion order, highlighting the robustness of our approach. Experiments
on the CIRR and FashionIQ benchmarks demonstrate consistent improvements. Our
method achieves a Recall@10 of 93.21 and an Rmean of 84.43 on CIRR, and an
average Rmean of 67.48 on FashionIQ, surpassing recent strong baselines by up
to 4.5%. These results confirm that dynamic multi-model collaboration provides
an effective and general solution for CIR.

</details>


### [80] [Efficient representation of 3D spatial data for defense-related applications](https://arxiv.org/abs/2511.05109)
*Benjamin Kahl,Marcus Hebel,Michael Arens*

Main category: cs.GR

TL;DR: 本文比较了传统与现代3D建模方法，发现传统方法几何精度高，现代方法视觉效果佳但几何可靠性低，提出混合方法结合两者优势。


<details>
  <summary>Details</summary>
Motivation: 地理空间传感器数据对现代防御和安全至关重要，提供不可或缺的3D信息以增强态势感知能力。数据来源包括激光雷达传感器和光学相机，可用于创建详细的操作环境模型。

Method: 本文提供了传统表示方法（如点云、体素网格和三角网格）与现代神经和隐式技术（如NeRFs和3DGS）的比较分析。

Result: 评估揭示了基本权衡：传统模型提供稳健的几何精度，适合功能任务（如视线分析和物理模拟）；而现代方法擅长生成高保真、逼真的视觉效果，但几何可靠性不足。

Conclusion: 基于研究发现，混合方法是最有前景的前进方向。作者提出了一种系统架构，结合传统网格支架的几何完整性和神经表示（如3DGS）的视觉细节，通过分层场景结构管理以确保可扩展性和性能。

Abstract: Geospatial sensor data is essential for modern defense and security, offering
indispensable 3D information for situational awareness. This data, gathered
from sources like lidar sensors and optical cameras, allows for the creation of
detailed models of operational environments. In this paper, we provide a
comparative analysis of traditional representation methods, such as point
clouds, voxel grids, and triangle meshes, alongside modern neural and implicit
techniques like Neural Radiance Fields (NeRFs) and 3D Gaussian Splatting
(3DGS). Our evaluation reveals a fundamental trade-off: traditional models
offer robust geometric accuracy ideal for functional tasks like line-of-sight
analysis and physics simulations, while modern methods excel at producing
high-fidelity, photorealistic visuals but often lack geometric reliability.
Based on these findings, we conclude that a hybrid approach is the most
promising path forward. We propose a system architecture that combines a
traditional mesh scaffold for geometric integrity with a neural representation
like 3DGS for visual detail, managed within a hierarchical scene structure to
ensure scalability and performance.

</details>


### [81] [Neural Image Abstraction Using Long Smoothing B-Splines](https://arxiv.org/abs/2511.05360)
*Daniel Berio,Michael Stroh,Sylvain Calinon,Frederic Fol Leymarie,Oliver Deussen,Ariel Shamir*

Main category: cs.GR

TL;DR: 将平滑B样条集成到DiffVG流程中，实现风格化矢量图形的多功能生成。


<details>
  <summary>Details</summary>
Motivation: 旨在生成平滑且任意长度的路径，同时支持几何和图像空间的风格化控制。

Method: 通过线性映射将平滑B样条集成到可微分矢量图形（DiffVG）流程中，利用基于导数的平滑成本实现保真度与简洁性的参数化控制。

Result: 展示了四种风格化矢量图形生成应用，证明了方法的有效性。

Conclusion: 该方法在风格化矢量图形生成中表现出高度的多功能性，适用于多种应用场景。

Abstract: We integrate smoothing B-splines into a standard differentiable vector
graphics (DiffVG) pipeline through linear mapping, and show how this can be
used to generate smooth and arbitrarily long paths within image-based deep
learning systems. We take advantage of derivative-based smoothing costs for
parametric control of fidelity vs. simplicity tradeoffs, while also enabling
stylization control in geometric and image spaces. The proposed pipeline is
compatible with recent vector graphics generation and vectorization methods. We
demonstrate the versatility of our approach with four applications aimed at the
generation of stylized vector graphics: stylized space-filling path generation,
stroke-based image abstraction, closed-area image abstraction, and stylized
text generation.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [82] [Agentic Refactoring: An Empirical Study of AI Coding Agents](https://arxiv.org/abs/2511.04824)
*Kosei Horikawa,Hao Li,Yutaro Kashiwa,Bram Adams,Hajimu Iida,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: AI代理在代码重构中主要进行低级别编辑，显著改善代码质量，尤其在中等复杂度变更中效果明显。


<details>
  <summary>Details</summary>
Motivation: 解决关于AI代理重构在实践中如何应用、与人类驱动的重构相比如何以及其对代码质量影响的经验理解缺乏问题。

Method: 通过对AIDev数据集中12,256个拉取请求和14,988次提交中的15,451个重构实例进行大规模实证分析。

Result: 代理驱动的重构在26.1%的提交中明确针对重构，主要集中在低级别编辑，如变量类型更改（11.8%）和重命名参数（10.4%）。这些重构显著改善了代码质量指标，尤其是中等复杂度的变更。

Conclusion: AI代理驱动的重构在实践中是常见且有意的活动，主要集中在低级别、一致性导向的编辑，如变量类型更改和重命名。这些重构显著改善了代码的结构指标，尤其是中等复杂度的变更，减少了类的大小和复杂性。

Abstract: Agentic coding tools, such as OpenAI Codex, Claude Code, and Cursor, are
transforming the software engineering landscape. These AI-powered systems
function as autonomous teammates capable of planning and executing complex
development tasks. Agents have become active participants in refactoring, a
cornerstone of sustainable software development aimed at improving internal
code quality without altering observable behavior. Despite their increasing
adoption, there is a critical lack of empirical understanding regarding how
agentic refactoring is utilized in practice, how it compares to human-driven
refactoring, and what impact it has on code quality. To address this empirical
gap, we present a large-scale study of AI agent-generated refactorings in
real-world open-source Java projects, analyzing 15,451 refactoring instances
across 12,256 pull requests and 14,988 commits derived from the AIDev dataset.
Our empirical analysis shows that refactoring is a common and intentional
activity in this development paradigm, with agents explicitly targeting
refactoring in 26.1% of commits. Analysis of refactoring types reveals that
agentic efforts are dominated by low-level, consistency-oriented edits, such as
Change Variable Type (11.8%), Rename Parameter (10.4%), and Rename Variable
(8.5%), reflecting a preference for localized improvements over the high-level
design changes common in human refactoring. Additionally, the motivations
behind agentic refactoring focus overwhelmingly on internal quality concerns,
with maintainability (52.5%) and readability (28.1%). Furthermore, quantitative
evaluation of code quality metrics shows that agentic refactoring yields small
but statistically significant improvements in structural metrics, particularly
for medium-level changes, reducing class size and complexity (e.g., Class LOC
median $\Delta$ = -15.25).

</details>


### [83] [Software Defined Vehicle Code Generation: A Few-Shot Prompting Approach](https://arxiv.org/abs/2511.04849)
*Quang-Dung Nguyen,Tri-Dung Tran,Thanh-Hieu Chu,Hoang-Loc Tran,Xiangwei Cheng,Dirk Slama*

Main category: cs.SE

TL;DR: 通过少量示例提示策略，无需训练即可优化大型语言模型在SDV代码生成中的表现。


<details>
  <summary>Details</summary>
Motivation: 软件定义车辆（SDV）的发展需要高效的工具支持代码生成，但现有通用大型语言模型因专有架构限制难以直接适配此类特定任务。

Method: 研究采用多种提示技术（包括裸模型和少量示例提示）对多个大型语言模型进行实验，使用专门设计的SDV代码生成基准进行评估。

Result: 实验结果显示，少量示例提示策略在定量指标上表现最优，能更准确地调整模型输出以符合预期结果。

Conclusion: 研究表明，通过少量示例提示策略（few-shot prompting）可以显著提升大型语言模型在生成软件定义车辆（SDV）代码任务中的表现，无需依赖专有模型架构或训练过程。

Abstract: The emergence of Software-Defined Vehicles (SDVs) marks a paradigm shift in
the automotive industry, where software now plays a pivotal role in defining
vehicle functionality, enabling rapid innovation of modern vehicles. Developing
SDV-specific applications demands advanced tools to streamline code generation
and improve development efficiency. In recent years, general-purpose large
language models (LLMs) have demonstrated transformative potential across
domains. Still, restricted access to proprietary model architectures hinders
their adaption to specific tasks like SDV code generation. In this study, we
propose using prompts, a common and basic strategy to interact with LLMs and
redirect their responses. Using only system prompts with an appropriate and
efficient prompt structure designed using advanced prompt engineering
techniques, LLMs can be crafted without requiring a training session or access
to their base design. This research investigates the extensive experiments on
different models by applying various prompting techniques, including bare
models, using a benchmark specifically created to evaluate LLMs' performance in
generating SDV code. The results reveal that the model with a few-shot
prompting strategy outperforms the others in adjusting the LLM answers to match
the expected outcomes based on quantitative metrics.

</details>


### [84] [What About Our Bug? A Study on the Responsiveness of NPM Package Maintainers](https://arxiv.org/abs/2511.04986)
*Mohammadreza Saeidi,Ethan Thoma,Raula Gaikovina Kula,Gema Rodríguez-Pérez*

Main category: cs.SE

TL;DR: 研究分析了npm包中错误报告的响应情况，发现维护者普遍响应积极，并提出了错误未被解决的分类法。


<details>
  <summary>Details</summary>
Motivation: 验证维护者可能不总是决定修复错误的假设，尤其是在他们认为错误超出了他们在依赖链中的责任范围时。

Method: 采用混合方法挖掘仓库问题数据，并进行定性开放编码分析未解决错误报告的原因。

Result: 研究发现维护者通常响应积极，项目级别的响应中位数为70%（IQR：55%-89%），反映了他们对支持下游开发者的承诺。

Conclusion: 本文提出了一个分类法，解释了一些错误未被解决的原因，包括贡献实践、依赖限制和库特定标准。理解维护者行为可以促进更健壮和响应迅速的开源生态系统。

Abstract: Background: Widespread use of third-party libraries makes ecosystems like
Node Package Manager (npm) critical to modern software development. However,
this interconnected chain of dependencies also creates challenges: bugs in one
library can propagate downstream, potentially impacting many other libraries
that rely on it. We hypothesize that maintainers may not always decide to fix a
bug, especially if the maintainer decides it falls out of their responsibility
within the chain of dependencies. Aims: To confirm this hypothesis, we
investigate the responsiveness of 30,340 bug reports across 500 of the most
depended-upon npm packages. Method: We adopt a mixed-method approach to mine
repository issue data and perform qualitative open coding to analyze reasons
behind unaddressed bug reports. Results: Our findings show that maintainers are
generally responsive, with a median project-level responsiveness of 70% (IQR:
55%-89%), reflecting their commitment to support downstream developers.
Conclusions: We present a taxonomy of the reasons some bugs remain unresolved.
The taxonomy includes contribution practices, dependency constraints, and
library-specific standards as reasons for not being responsive. Understanding
maintainer behavior can inform practices that promote a more robust and
responsive open-source ecosystem that benefits the entire community.

</details>


### [85] [Generating Software Architecture Description from Source Code using Reverse Engineering and Large Language Model](https://arxiv.org/abs/2511.05165)
*Ahmad Hatahet,Christoph Knieke,Andreas Rausch*

Main category: cs.SE

TL;DR: 论文提出了一种半自动化生成软件架构描述的方法，结合逆向工程和LLM，显著提升架构文档的准确性和维护性。


<details>
  <summary>Details</summary>
Motivation: 实践中，软件架构描述常常缺失、过时或与实现不一致，导致开发者需直接从源代码推导架构，增加了认知负担和系统维护难度。

Method: 通过逆向工程技术提取全面的组件图，利用提示工程筛选架构核心组件，并通过few-shots提示生成状态机图以建模组件行为。

Result: 该方法在C++示例中验证了其有效性，能够自动化生成静态和动态架构视图，减少对专家参与的依赖，并准确表示复杂行为。

Conclusion: 该论文提出了一种结合逆向工程和大型语言模型的半自动化方法，用于从源代码生成软件架构描述（SADs），显著减少了人工工作量并提升了系统的长期可维护性。

Abstract: Software Architecture Descriptions (SADs) are essential for managing the
inherent complexity of modern software systems. They enable high-level
architectural reasoning, guide design decisions, and facilitate effective
communication among diverse stakeholders. However, in practice, SADs are often
missing, outdated, or poorly aligned with the system's actual implementation.
Consequently, developers are compelled to derive architectural insights
directly from source code-a time-intensive process that increases cognitive
load, slows new developer onboarding, and contributes to the gradual
degradation of clarity over the system's lifetime. To address these issues, we
propose a semi-automated generation of SADs from source code by integrating
reverse engineering (RE) techniques with a Large Language Model (LLM). Our
approach recovers both static and behavioral architectural views by extracting
a comprehensive component diagram, filtering architecturally significant
elements (core components) via prompt engineering, and generating state machine
diagrams to model component behavior based on underlying code logic with
few-shots prompting. This resulting views representation offer a scalable and
maintainable alternative to traditional manual architectural documentation.
This methodology, demonstrated using C++ examples, highlights the potent
capability of LLMs to: 1) abstract the component diagram, thereby reducing the
reliance on human expert involvement, and 2) accurately represent complex
software behaviors, especially when enriched with domain-specific knowledge
through few-shot prompting. These findings suggest a viable path toward
significantly reducing manual effort while enhancing system understanding and
long-term maintainability.

</details>


### [86] [CodeMapper: A Language-Agnostic Approach to Mapping Code Regions Across Commits](https://arxiv.org/abs/2511.05205)
*Huimin Hu,Michael Pradel*

Main category: cs.SE

TL;DR: CodeMapper 提出了一种独立于语言和代码元素的代码映射方法，通过两阶段处理显著提升了映射准确性。


<details>
  <summary>Details</summary>
Motivation: 解决开发者在软件演化过程中需要将特定代码区域从一个提交映射到另一个提交的问题，现有方法（如 git diff）无法聚焦于开发者选择的代码区域，且其他技术局限于特定代码元素和语言。

Method: CodeMapper 采用两阶段方法：计算候选区域（通过分析差异、检测代码移动和搜索特定代码片段）和选择最可能的目标区域（通过计算相似性）。

Result: CodeMapper 在四个数据集上的评估显示，其正确识别目标区域的准确率为 71.0%--94.5%，比最佳基线方法提高了 1.5--58.8 个百分点。

Conclusion: CodeMapper 是一种独立于特定程序元素和编程语言的代码映射方法，显著提高了代码区域映射的准确性，优于现有基线方法。

Abstract: During software evolution, developers commonly face the problem of mapping a
specific code region from one commit to another. For example, they may want to
determine how the condition of an if-statement, a specific line in a
configuration file, or the definition of a function changes. We call this the
code mapping problem. Existing techniques, such as git diff, address this
problem only insufficiently because they show all changes made to a file
instead of focusing on a code region of the developer's choice. Other
techniques focus on specific code elements and programming languages (e.g.,
methods in Java), limiting their applicability. This paper introduces
CodeMapper, an approach to address the code mapping problem in a way that is
independent of specific program elements and programming languages. Given a
code region in one commit, CodeMapper finds the corresponding region in another
commit. The approach consists of two phases: (i) computing candidate regions by
analyzing diffs, detecting code movements, and searching for specific code
fragments, and (ii) selecting the most likely target region by calculating
similarities. Our evaluation applies CodeMapper to four datasets, including two
new hand-annotated datasets containing code region pairs in ten popular
programming languages. CodeMapper correctly identifies the expected target
region in 71.0%--94.5% of all cases, improving over the best available
baselines by 1.5--58.8 absolute percent points.

</details>


### [87] [Building Specialized Software-Assistant ChatBot with Graph-Based Retrieval-Augmented Generation](https://arxiv.org/abs/2511.05297)
*Mohammed Hilel,Yannis Karmim,Jean De Bodinat,Reda Sarehane,Antoine Gillon*

Main category: cs.SE

TL;DR: 论文提出了一种图检索增强生成框架，通过自动构建知识图谱提升LLMs在企业软件辅助中的准确性和可靠性，已在工业场景中验证。


<details>
  <summary>Details</summary>
Motivation: 解决现有Digital Adoption Platforms（DAPs）依赖手动构建交互式指南的问题，以及LLMs因缺乏对目标软件的结构化理解而产生不可靠答案的挑战。

Method: 框架通过自动将企业Web应用转换为状态-动作知识图谱，结合图检索过程，为LLMs提供结构化的上下文信息。

Result: 开发了一个工程管道，成功提取并结构化软件接口，并将该方法集成到生产级DAP工作流中。

Conclusion: 论文提出了一种基于图检索增强生成（Graph-based Retrieval-Augmented Generation）的框架，有效解决了LLMs在企业软件辅助中的幻觉问题，并通过工业案例验证了其可扩展性和鲁棒性。

Abstract: Digital Adoption Platforms (DAPs) have become essential tools for helping
employees navigate complex enterprise software such as CRM, ERP, or HRMS
systems. Companies like LemonLearning have shown how digital guidance can
reduce training costs and accelerate onboarding. However, building and
maintaining these interactive guides still requires extensive manual effort.
Leveraging Large Language Models as virtual assistants is an appealing
alternative, yet without a structured understanding of the target software,
LLMs often hallucinate and produce unreliable answers. Moreover, most
production-grade LLMs are black-box APIs, making fine-tuning impractical due to
the lack of access to model weights. In this work, we introduce a Graph-based
Retrieval-Augmented Generation framework that automatically converts enterprise
web applications into state-action knowledge graphs, enabling LLMs to generate
grounded and context-aware assistance. The framework was co-developed with the
AI enterprise RAKAM, in collaboration with Lemon Learning. We detail the
engineering pipeline that extracts and structures software interfaces, the
design of the graph-based retrieval process, and the integration of our
approach into production DAP workflows. Finally, we discuss scalability,
robustness, and deployment lessons learned from industrial use cases.

</details>


### [88] [Code Review Automation using Retrieval Augmented Generation](https://arxiv.org/abs/2511.05302)
*Qianru Meng,Xiao Zhang,Zhaochen Ren,Joost Visser*

Main category: cs.SE

TL;DR: RARe结合检索与生成方法，提升自动代码审查质量，在基准测试和人工评估中表现优异。


<details>
  <summary>Details</summary>
Motivation: 自动化代码审查生成虽已有进展，但现有方法生成的审查可能偏离重点或过于笼统，需结合外部领域知识提升质量。

Method: RARe采用检索增强生成（RAG）技术，结合密集检索器和神经生成器，利用大型语言模型的上下文学习能力生成最终审查。

Result: RARe在两个基准数据集上表现优于现有方法，BLEU-4分数分别为12.32和12.96，并通过人工评估和案例研究验证了其实用性。

Conclusion: RARe通过结合检索和生成方法，显著提高了自动代码审查的准确性和实用性，验证了其在实践中的可靠性和有效性。

Abstract: Code review is essential for maintaining software quality but is
labor-intensive. Automated code review generation offers a promising solution
to this challenge. Both deep learning-based generative techniques and
retrieval-based methods have demonstrated strong performance in this task.
However, despite these advancements, there are still some limitations where
generated reviews can be either off-point or overly general. To address these
issues, we introduce Retrieval-Augmented Reviewer (RARe), which leverages
Retrieval-Augmented Generation (RAG) to combine retrieval-based and generative
methods, explicitly incorporating external domain knowledge into the code
review process. RARe uses a dense retriever to select the most relevant reviews
from the codebase, which then enrich the input for a neural generator,
utilizing the contextual learning capacity of large language models (LLMs), to
produce the final review. RARe outperforms state-of-the-art methods on two
benchmark datasets, achieving BLEU-4 scores of 12.32 and 12.96, respectively.
Its effectiveness is further validated through a detailed human evaluation and
a case study using an interpretability tool, demonstrating its practical
utility and reliability.

</details>


### [89] [SWE-Compass: Towards Unified Evaluation of Agentic Coding Abilities for Large Language Models](https://arxiv.org/abs/2511.05459)
*Jingxuan Xu,Ken Deng,Weihao Li,Songwei Yu,Huaixi Tang,Haoyang Huang,Zhiyi Lai,Zizheng Zhan,Yanan Wu,Chenchen Zhang,Kepeng Lei,Yifan Yao,Xinping Lei,Wenqiang Zhu,Zongxian Feng,Han Li,Junqi Xiong,Dailin Li,Zuchen Gao,Kun Wu,Wen Xiang,Ziqi Zhan,Yuanxing Zhang,Wuxuan Gong,Ziyuan Gao,Guanxiang Wang,Yirong Xue,Xiaojiang Zhang,Jinghui Wang,Huiming Wang,Wenhao Zhuang,Zhaoxiang Zhang,Yuqun Zhang,Haotian Zhang,Bin Chen,Jiaheng Liu*

Main category: cs.SE

TL;DR: SWE-Compass 是一个全面的软件工程基准测试，覆盖多任务、多语言和多场景，旨在更真实地评估LLM的实际编码能力。


<details>
  <summary>Details</summary>
Motivation: 现有的软件工程评估基准存在任务覆盖窄、语言偏见和与实际开发者工作流程不匹配的问题，需要更全面的解决方案。

Method: 引入 SWE-Compass 基准测试，覆盖8种任务类型、8种编程场景和10种编程语言，包含2000个高质量实例，并采用 SWE-Agent 和 Claude Code 两种代理框架对10种最先进的LLM进行测试。

Result: 揭示了不同任务类型、语言和场景下的难度层次，为诊断和提升大型语言模型的代理编码能力提供了可复现的基础。

Conclusion: SWE-Compass 提供了一个全面、结构化的基准测试框架，能够更准确地评估大型语言模型在软件工程中的实际应用能力。

Abstract: Evaluating large language models (LLMs) for software engineering has been
limited by narrow task coverage, language bias, and insufficient alignment with
real-world developer workflows. Existing benchmarks often focus on algorithmic
problems or Python-centric bug fixing, leaving critical dimensions of software
engineering underexplored. To address these gaps, we introduce SWE-Compass1, a
comprehensive benchmark that unifies heterogeneous code-related evaluations
into a structured and production-aligned framework. SWE-Compass spans 8 task
types, 8 programming scenarios, and 10 programming languages, with 2000
high-quality instances curated from authentic GitHub pull requests and refined
through systematic filtering and validation. We benchmark ten state-of-the-art
LLMs under two agentic frameworks, SWE-Agent and Claude Code, revealing a clear
hierarchy of difficulty across task types, languages, and scenarios. Moreover,
by aligning evaluation with real-world developer practices, SWE-Compass
provides a rigorous and reproducible foundation for diagnosing and advancing
agentic coding capabilities in large language models.

</details>


### [90] [A Metamorphic Testing Perspective on Knowledge Distillation for Language Models of Code: Does the Student Deeply Mimic the Teacher?](https://arxiv.org/abs/2511.05476)
*Md. Abdul Awal,Mrigank Rochan,Chanchal K. Roy*

Main category: cs.SE

TL;DR: MetaCompress是一个变形测试框架，用于评估知识蒸馏压缩代码语言模型的行为保真度，发现学生模型与传统评估方法未能捕捉的行为差异。


<details>
  <summary>Details</summary>
Motivation: 当前基于准确性的评估方法只能提供模型质量的表面视图，往往无法捕捉教师和学生模型之间更深层次的行为保真度差异。

Method: 提出了MetaCompress，一个基于变形测试的框架，通过比较教师和学生模型在一组行为保持的变形关系下的输出，系统地评估行为保真度。

Result: MetaCompress在两种广泛研究的任务上评估，发现学生模型中高达62%的行为差异。

Conclusion: MetaCompress被提出作为一个实用的框架，用于测试通过知识蒸馏得到的压缩代码语言模型，强调了在知识蒸馏流程中进行行为保真度评估的必要性。

Abstract: Transformer-based language models of code have achieved state-of-the-art
performance across a wide range of software analytics tasks, but their
practical deployment remains limited due to high computational costs, slow
inference speeds, and significant environmental impact. To address these
challenges, recent research has increasingly explored knowledge distillation as
a method for compressing a large language model of code (the teacher) into a
smaller model (the student) while maintaining performance. However, the degree
to which a student model deeply mimics the predictive behavior and internal
representations of its teacher remains largely unexplored, as current
accuracy-based evaluation provides only a surface-level view of model quality
and often fails to capture more profound discrepancies in behavioral fidelity
between the teacher and student models. To address this gap, we empirically
show that the student model often fails to deeply mimic the teacher model,
resulting in up to 285% greater performance drop under adversarial attacks,
which is not captured by traditional accuracy-based evaluation. Therefore, we
propose MetaCompress, a metamorphic testing framework that systematically
evaluates behavioral fidelity by comparing the outputs of teacher and student
models under a set of behavior-preserving metamorphic relations. We evaluate
MetaCompress on two widely studied tasks, using compressed versions of popular
language models of code, obtained via three different knowledge distillation
techniques: Compressor, AVATAR, and MORPH. The results show that MetaCompress
identifies up to 62% behavioral discrepancies in student models, underscoring
the need for behavioral fidelity evaluation within the knowledge distillation
pipeline and establishing MetaCompress as a practical framework for testing
compressed language models of code derived through knowledge distillation.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [91] [ScheduleStream: Temporal Planning with Samplers for GPU-Accelerated Multi-Arm Task and Motion Planning & Scheduling](https://arxiv.org/abs/2511.04758)
*Caelan Garrett,Fabio Ramos*

Main category: cs.RO

TL;DR: ScheduleStream扩展TAMP算法，通过混合持续时间动作和GPU加速实现多臂机器人并行运动规划，提升效率。


<details>
  <summary>Details</summary>
Motivation: 解决多臂机器人控制中因离散-连续混合动作空间增长导致的并行运动规划挑战。

Method: 提出了ScheduleStream框架，采用混合持续时间动作模型异步启动动作，并利用GPU加速采样器以加快规划速度。

Result: ScheduleStream在仿真和实际任务中相比其他方法能生成更高效的解决方案。

Conclusion: ScheduleStream是一个通用框架，能有效扩展TAMP算法以生成并行臂运动计划，且在仿真和实际机器人任务中表现出更高的效率。

Abstract: Bimanual and humanoid robots are appealing because of their human-like
ability to leverage multiple arms to efficiently complete tasks. However,
controlling multiple arms at once is computationally challenging due to the
growth in the hybrid discrete-continuous action space. Task and Motion Planning
(TAMP) algorithms can efficiently plan in hybrid spaces but generally produce
plans, where only one arm is moving at a time, rather than schedules that allow
for parallel arm motion. In order to extend TAMP to produce schedules, we
present ScheduleStream, the first general-purpose framework for planning &
scheduling with sampling operations. ScheduleStream models temporal dynamics
using hybrid durative actions, which can be started asynchronously and persist
for a duration that's a function of their parameters. We propose
domain-independent algorithms that solve ScheduleStream problems without any
application-specific mechanisms. We apply ScheduleStream to Task and Motion
Planning & Scheduling (TAMPAS), where we use GPU acceleration within samplers
to expedite planning. We compare ScheduleStream algorithms to several ablations
in simulation and find that they produce more efficient solutions. We
demonstrate ScheduleStream on several real-world bimanual robot tasks at
https://schedulestream.github.io.

</details>


### [92] [ReGen: Generative Robot Simulation via Inverse Design](https://arxiv.org/abs/2511.04769)
*Phat Nguyen,Tsun-Hsuan Wang,Zhang-Wei Hong,Erfan Aasi,Andrew Silva,Guy Rosman,Sertac Karaman,Daniela Rus*

Main category: cs.RO

TL;DR: ReGen是一个生成式仿真框架，通过逆向设计和大型语言模型自动化仿真设计，提升机器人策略验证和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 传统仿真构建过程劳动密集，限制了机器人学习的扩展和策略验证。ReGen旨在通过逆向设计自动化这一过程。

Method: ReGen利用大型语言模型生成场景，通过扩展编码因果关系的定向图，并将其转换为符号程序来配置和执行机器人仿真环境。

Result: 在自动驾驶和机器人操作任务中，ReGen生成的仿真环境比现有方法更复杂多样，成功率高，并能可控地生成极端案例。

Conclusion: ReGen通过自动化仿真设计，显著提升了机器人策略的验证效率和泛化能力，支持数据或仿真增强，推动了可扩展的机器人学习。

Abstract: Simulation plays a key role in scaling robot learning and validating
policies, but constructing simulations remains a labor-intensive process. This
paper introduces ReGen, a generative simulation framework that automates
simulation design via inverse design. Given a robot's behavior -- such as a
motion trajectory or an objective function -- and its textual description,
ReGen infers plausible scenarios and environments that could have caused the
behavior. ReGen leverages large language models to synthesize scenarios by
expanding a directed graph that encodes cause-and-effect relationships,
relevant entities, and their properties. This structured graph is then
translated into a symbolic program, which configures and executes a robot
simulation environment. Our framework supports (i) augmenting simulations based
on ego-agent behaviors, (ii) controllable, counterfactual scenario generation,
(iii) reasoning about agent cognition and mental states, and (iv) reasoning
with distinct sensing modalities, such as braking due to faulty GPS signals. We
demonstrate ReGen in autonomous driving and robot manipulation tasks,
generating more diverse, complex simulated environments compared to existing
simulations with high success rates, and enabling controllable generation for
corner cases. This approach enhances the validation of robot policies and
supports data or simulation augmentation, advancing scalable robot learning for
improved generalization and robustness. We provide code and example videos at:
https://regen-sim.github.io/

</details>


### [93] [Unified Multimodal Diffusion Forcing for Forceful Manipulation](https://arxiv.org/abs/2511.04812)
*Zixuan Huang,Huaidian Hou,Dmitry Berenson*

Main category: cs.RO

TL;DR: MDF是一种多模态学习框架，通过扩散模型重建轨迹，学习跨模态依赖，在复杂任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 标准模仿学习方法忽视了不同模态（如感官输入、动作和奖励）之间的丰富互动，而这些互动对建模机器人行为和理解任务结果至关重要。

Method: MDF通过随机部分掩码训练扩散模型来重建轨迹，从而学习时间和跨模态依赖关系。

Result: MDF在模拟和真实环境的接触丰富、强力的操纵任务中表现出色。

Conclusion: MDF框架不仅提供了多功能性，还在噪声观测下表现出强大的性能和鲁棒性。

Abstract: Given a dataset of expert trajectories, standard imitation learning
approaches typically learn a direct mapping from observations (e.g., RGB
images) to actions. However, such methods often overlook the rich interplay
between different modalities, i.e., sensory inputs, actions, and rewards, which
is crucial for modeling robot behavior and understanding task outcomes. In this
work, we propose Multimodal Diffusion Forcing, a unified framework for learning
from multimodal robot trajectories that extends beyond action generation.
Rather than modeling a fixed distribution, MDF applies random partial masking
and trains a diffusion model to reconstruct the trajectory. This training
objective encourages the model to learn temporal and cross-modal dependencies,
such as predicting the effects of actions on force signals or inferring states
from partial observations. We evaluate MDF on contact-rich, forceful
manipulation tasks in simulated and real-world environments. Our results show
that MDF not only delivers versatile functionalities, but also achieves strong
performance, and robustness under noisy observations. More visualizations can
be found on our website https://unified-df.github.io

</details>


### [94] [Pixi: Unified Software Development and Distribution for Robotics and AI](https://arxiv.org/abs/2511.04827)
*Tobias Fischer,Wolf Vollprecht,Bas Zalmstra,Ruben Arts,Tim de Jager,Alejandro Fontan,Adam D Hines,Michael Milford,Silvio Traversaro,Daniel Claes,Scarlett Raine*

Main category: cs.RO

TL;DR: Pixi是一个统一的包管理框架，解决了机器人研究中的可重复性问题，通过高效依赖解析和生态系统集成，显著提升了研究效率。


<details>
  <summary>Details</summary>
Motivation: 科学计算中的可重复性危机限制了机器人研究。现有研究表明，高达70%的机器人算法无法由独立团队重现，且许多算法因共享软件环境的复杂性而无法部署。这些问题源于分散、多语言和硬件-软件工具链导致的依赖地狱。

Method: Pixi通过项目级锁文件捕获精确的依赖状态，确保跨平台的比特级可重复性，并集成了conda-forge和PyPI生态系统，消除了对多个管理器的需求。其高性能SAT求解器实现了比同类工具快10倍的依赖解析速度。

Result: 自2023年以来，Pixi已被5300多个项目采用，将设置时间从几小时缩短到几分钟，降低了全球研究者的技术门槛。

Conclusion: Pixi通过提供一个统一的包管理框架，解决了科学计算中的可重复性危机，显著提升了机器人研究和AI领域的进展。

Abstract: The reproducibility crisis in scientific computing constrains robotics
research. Existing studies reveal that up to 70% of robotics algorithms cannot
be reproduced by independent teams, while many others fail to reach deployment
because creating shareable software environments remains prohibitively complex.
These challenges stem from fragmented, multi-language, and hardware-software
toolchains that lead to dependency hell. We present Pixi, a unified
package-management framework that addresses these issues by capturing exact
dependency states in project-level lockfiles, ensuring bit-for-bit
reproducibility across platforms. Its high-performance SAT solver achieves up
to 10x faster dependency resolution than comparable tools, while integration of
the conda-forge and PyPI ecosystems removes the need for multiple managers.
Adopted in over 5,300 projects since 2023, Pixi reduces setup times from hours
to minutes and lowers technical barriers for researchers worldwide. By enabling
scalable, reproducible, collaborative research infrastructure, Pixi accelerates
progress in robotics and AI.

</details>


### [95] [Isaac Lab: A GPU-Accelerated Simulation Framework for Multi-Modal Robot Learning](https://arxiv.org/abs/2511.04831)
*NVIDIA,:,Mayank Mittal,Pascal Roth,James Tigue,Antoine Richard,Octi Zhang,Peter Du,Antonio Serrano-Muñoz,Xinjie Yao,René Zurbrügg,Nikita Rudin,Lukasz Wawrzyniak,Milad Rakhsha,Alain Denzler,Eric Heiden,Ales Borovicka,Ossama Ahmed,Iretiayo Akinola,Abrar Anwar,Mark T. Carlson,Ji Yuan Feng,Animesh Garg,Renato Gasoto,Lionel Gulich,Yijie Guo,M. Gussert,Alex Hansen,Mihir Kulkarni,Chenran Li,Wei Liu,Viktor Makoviychuk,Grzegorz Malczyk,Hammad Mazhar,Masoud Moghani,Adithyavairavan Murali,Michael Noseworthy,Alexander Poddubny,Nathan Ratliff,Welf Rehberg,Clemens Schwarke,Ritvik Singh,James Latham Smith,Bingjie Tang,Ruchik Thaker,Matthew Trepte,Karl Van Wyk,Fangzhou Yu,Alex Millane,Vikram Ramasamy,Remo Steiner,Sangeeta Subramanian,Clemens Volk,CY Chen,Neel Jawale,Ashwin Varghese Kuruttukulam,Michael A. Lin,Ajay Mandlekar,Karsten Patzwaldt,John Welsh,Huihua Zhao,Fatima Anes,Jean-Francois Lafleche,Nicolas Moënne-Loccoz,Soowan Park,Rob Stepinski,Dirk Van Gelder,Chris Amevor,Jan Carius,Jumyung Chang,Anka He Chen,Pablo de Heras Ciechomski,Gilles Daviet,Mohammad Mohajerani,Julia von Muralt,Viktor Reutskyy,Michael Sauter,Simon Schirm,Eric L. Shi,Pierre Terdiman,Kenny Vilella,Tobias Widmer,Gordon Yeoman,Tiffany Chen,Sergey Grizan,Cathy Li,Lotus Li,Connor Smith,Rafael Wiltz,Kostas Alexis,Yan Chang,David Chu,Linxi "Jim" Fan,Farbod Farshidian,Ankur Handa,Spencer Huang,Marco Hutter,Yashraj Narang,Soha Pouya,Shiwei Sheng,Yuke Zhu,Miles Macklin,Adam Moravanszky,Philipp Reist,Yunrong Guo,David Hoeller,Gavriel State*

Main category: cs.RO

TL;DR: Isaac Lab是Isaac Gym的自然继承者，扩展了GPU本地机器人模拟，集成了物理、渲染、传感器模拟和数据收集工具，用于大规模机器人学习。


<details>
  <summary>Details</summary>
Motivation: 将GPU本地机器人模拟扩展到大规模多模态学习时代，并统一强化学习和模仿学习的最佳实践。

Method: Isaac Lab结合了高保真的GPU并行物理、逼真渲染以及模块化、可组合的架构，用于设计环境和训练机器人策略。

Result: 展示了Isaac Lab在全身控制、跨体现移动、接触丰富和灵巧操作等方面的应用，并讨论了与可微分GPU加速牛顿物理引擎的集成。

Conclusion: Isaac Lab结合了先进的模拟能力、丰富的感知和数据中心规模的执行，有望推动机器人研究的下一个突破。

Abstract: We present Isaac Lab, the natural successor to Isaac Gym, which extends the
paradigm of GPU-native robotics simulation into the era of large-scale
multi-modal learning. Isaac Lab combines high-fidelity GPU parallel physics,
photorealistic rendering, and a modular, composable architecture for designing
environments and training robot policies. Beyond physics and rendering, the
framework integrates actuator models, multi-frequency sensor simulation, data
collection pipelines, and domain randomization tools, unifying best practices
for reinforcement and imitation learning at scale within a single extensible
platform. We highlight its application to a diverse set of challenges,
including whole-body control, cross-embodiment mobility, contact-rich and
dexterous manipulation, and the integration of human demonstrations for skill
acquisition. Finally, we discuss upcoming integration with the differentiable,
GPU-accelerated Newton physics engine, which promises new opportunities for
scalable, data-efficient, and gradient-based approaches to robot learning. We
believe Isaac Lab's combination of advanced simulation capabilities, rich
sensing, and data-center scale execution will help unlock the next generation
of breakthroughs in robotics research.

</details>


### [96] [Conformalized Non-uniform Sampling Strategies for Accelerated Sampling-based Motion Planning](https://arxiv.org/abs/2511.04835)
*Shubham Natraj,Bruno Sinopoli,Yiannis Kantaros*

Main category: cs.RO

TL;DR: 提出了一种基于认证区域的非均匀采样策略，显著提升了SBMPs在复杂环境中的路径规划效率。


<details>
  <summary>Details</summary>
Motivation: 基于均匀采样的运动规划器在复杂环境中效率低下且规划速度慢，因此需要一种更高效的采样策略。

Method: 该方法通过结合启发式路径预测器（如A*或视觉语言模型）生成初始路径，并应用符合性预测来量化预测器的不确定性，从而构建出具有概率保证的采样区域。

Result: 实验证明，该方法比现有基线方法更快地找到可行路径，并且能更好地泛化到未见过的环境。

Conclusion: 论文提出了一种新的非均匀采样策略，通过偏向‘认证’区域来提升采样效率，并在复杂环境中显著提高了路径规划的速度和可行性。

Abstract: Sampling-based motion planners (SBMPs) are widely used to compute dynamically
feasible robot paths. However, their reliance on uniform sampling often leads
to poor efficiency and slow planning in complex environments. We introduce a
novel non-uniform sampling strategy that integrates into existing SBMPs by
biasing sampling toward `certified' regions. These regions are constructed by
(i) generating an initial, possibly infeasible, path using any heuristic path
predictor (e.g., A* or vision-language models) and (ii) applying conformal
prediction to quantify the predictor's uncertainty. This process yields
prediction sets around the initial-guess path that are guaranteed, with
user-specified probability, to contain the optimal solution. To our knowledge,
this is the first non-uniform sampling approach for SBMPs that provides such
probabilistically correct guarantees on the sampling regions. Extensive
evaluations demonstrate that our method consistently finds feasible paths
faster and generalizes better to unseen environments than existing baselines.

</details>


### [97] [Design Exploration for Protection and Cleaning of Solar Panels with Case Studies for Space Missions](https://arxiv.org/abs/2511.04837)
*Cameron Robinson,Ganghee Jang*

Main category: cs.RO

TL;DR: 研究设计清洁机制和保护材料以解决太阳能板因覆盖物影响运行的问题，刮片系统和聚碳酸酯分层设计表现最佳。


<details>
  <summary>Details</summary>
Motivation: 太阳能板在太空探索、野火监测等关键任务中广泛应用，但其运行可能因灰尘或太空碎片覆盖而受限甚至终止，因此需要有效的清洁和保护方案。

Method: 设计了刮片系统和轨道系统两种清洁机制，并通过碰撞测试评估了聚碳酸酯等多种保护材料的性能。

Result: 刮片系统在清洁效率上优于轨道系统；聚碳酸酯作为保护材料表现良好，软硬材料分层设计是关键因素。

Conclusion: 设计的面板清洁机制和保护材料有效解决了太阳能板因灰尘或太空碎片覆盖而影响运行的问题，其中刮片系统在成本、清洁速度和总功耗方面优于轨道系统，而聚碳酸酯作为保护材料表现良好，特别是软硬材料分层设计效果显著。

Abstract: Solar energy is used for many mission-critical applications including space
exploration, sensor systems to monitor wildfires, etc. Their operation can be
limited or even terminated if solar panels are covered with dust or hit by
space debris. To address this issue, we designed panel cleaning mechanisms and
tested protective materials. For cleaning mechanisms, we designed and compared
a wiper system and a rail system. For protective materials, we found through
collision tests that polycarbonate was very promising, though the most
important factor was layering a soft material between the panel's surface and a
hard material. In the cleaning system comparisons, the wiper-based system was
more efficient than the rail-based system in terms of cost, cleaning speed, and
total power consumption.

</details>


### [98] [iFlyBot-VLM Technical Report](https://arxiv.org/abs/2511.04976)
*Xin Nie,Zhiyuan Cheng,Yuan Zhang,Chao Ji,Jiajia Wu,Yuhan Zhang,Jia Pan*

Main category: cs.RO

TL;DR: iFlyBot-VLM是一个通用视觉语言模型，通过抽象视觉信息为操作语言，桥接感知与运动控制的语义鸿沟，并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 旨在解决高维环境感知与低级机器人运动控制之间的跨模态语义鸿沟。

Method: 模型通过将复杂的视觉和空间信息抽象为与身体无关且可转移的操作语言，实现跨模态语义的桥接。

Result: 在10个主流VLM基准数据集上取得最优性能，同时保持模型的通用能力。

Conclusion: iFlyBot-VLM被设计为一个可扩展和通用化的基础模型，旨在推动从特定任务导向系统向通用认知智能体的发展。

Abstract: We introduce iFlyBot-VLM, a general-purpose Vision-Language Model (VLM) used
to improve the domain of Embodied Intelligence. The central objective of
iFlyBot-VLM is to bridge the cross-modal semantic gap between high-dimensional
environmental perception and low-level robotic motion control. To this end, the
model abstracts complex visual and spatial information into a body-agnostic and
transferable Operational Language, thereby enabling seamless perception-action
closed-loop coordination across diverse robotic platforms. The architecture of
iFlyBot-VLM is systematically designed to realize four key functional
capabilities essential for embodied intelligence: 1) Spatial Understanding and
Metric Reasoning; 2) Interactive Target Grounding; 3) Action Abstraction and
Control Parameter Generation; 4) Task Planning and Skill Sequencing. We
envision iFlyBot-VLM as a scalable and generalizable foundation model for
embodied AI, facilitating the progression from specialized task-oriented
systems toward generalist, cognitively capable agents. We conducted evaluations
on 10 current mainstream embodied intelligence-related VLM benchmark datasets,
such as Blink and Where2Place, and achieved optimal performance while
preserving the model's general capabilities. We will publicly release both the
training data and model weights to foster further research and development in
the field of Embodied Intelligence.

</details>


### [99] [A semi-analytical approach for computing the largest singularity-free spheres of a class of 6-6 Stewart-Gough platforms for specified orientation workspaces](https://arxiv.org/abs/2511.04992)
*Bibekananda Patra,Sandipan Bandyopadhyay*

Main category: cs.RO

TL;DR: 本文提出了一种计算6-6 Stewart-Gough平台操纵器在特定方向工作空间内最大无奇异球的方法，并通过实验验证了不同架构的性能差异。


<details>
  <summary>Details</summary>
Motivation: 研究旨在为6-6 Stewart-Gough平台操纵器在特定方向工作空间内计算最大的无奇异球（SFS），以评估不同架构的性能。

Method: 对于固定的移动平台方向，通过解析方法计算最大的无奇异球（SFS），并在方向工作空间内重复此过程，选取最小SFS作为结果。

Result: 通过数值实验对四种不同的SGPM架构进行了测试，比较了它们在相同方向工作空间内的SFS体积表现。

Conclusion: 该研究展示了所提出的计算方法在6-6 Stewart-Gough平台操纵器（SGPM）的分析和设计中的潜在实用性。

Abstract: This article presents a method for computing the largest singularity-free
sphere (SFS) of a 6-6 Stewart-Gough platform manipulator (SGPM) over a
specified orientation workspace. For a fixed orientation of the moving
platform, the SFS is computed analytically. This process is repeated over a set
of samples generated within the orientation workspace, and the smallest among
them is designated as the desired SFS for the given orientation workspace.
Numerical experiments are performed on four distinct architectures of the SGPM
to understand their relative performances w.r.t. SFS volumes over the same
orientation workspace. This study demonstrates the potential utility of the
proposed computational method both in analysis and design of SGPMs.

</details>


### [100] [Encoding Biomechanical Energy Margin into Passivity-based Synchronization for Networked Telerobotic Systems](https://arxiv.org/abs/2511.04994)
*Xingyuan Zhou,Peter Paik,S. Farokh Atashzar*

Main category: cs.RO

TL;DR: 论文提出TBPS2稳定器，通过生物力学感知和被动性优化位置同步，减少保守性，实验验证其优越性能。


<details>
  <summary>Details</summary>
Motivation: 在联网机器人系统中，尤其是支持触觉的人机交互，系统稳定性和精确位置跟踪至关重要。现有方法在位置不同步和非被动行为方面仍存在挑战，因此需要一种更优的稳定器。

Method: 论文通过数学设计综合和稳定性证明，开发了TBPS2稳定器。通过网格模拟和系统实验，与现有解决方案在不同时延和环境条件下进行了性能比较。

Result: TBPS2在优化位置同步和减少保守性方面表现出色，实验证明其在各种条件下的性能优于现有解决方案。

Conclusion: 论文提出了TBPS2（双端口生物力学感知的基于被动性的同步器和稳定器），在保持系统稳定性和精确位置跟踪的同时，优化了位置同步，并减少了稳定器的保守性。实验验证了其在各种时延和环境条件下的优越性能。

Abstract: Maintaining system stability and accurate position tracking is imperative in
networked robotic systems, particularly for haptics-enabled human-robot
interaction. Recent literature has integrated human biomechanics into the
stabilizers implemented for teleoperation, enhancing force preservation while
guaranteeing convergence and safety. However, position desynchronization due to
imperfect communication and non-passive behaviors remains a challenge. This
paper proposes a two-port biomechanics-aware passivity-based synchronizer and
stabilizer, referred to as TBPS2. This stabilizer optimizes position
synchronization by leveraging human biomechanics while reducing the
stabilizer's conservatism in its activation. We provide the mathematical design
synthesis of the stabilizer and the proof of stability. We also conducted a
series of grid simulations and systematic experiments, comparing their
performance with that of state-of-the-art solutions under varying time delays
and environmental conditions.

</details>


### [101] [MoE-DP: An MoE-Enhanced Diffusion Policy for Robust Long-Horizon Robotic Manipulation with Skill Decomposition and Failure Recovery](https://arxiv.org/abs/2511.05007)
*Baiye Cheng,Tianhai Liang,Suning Huang,Maanping Shao,Feihong Zhang,Botian Xu,Zhengrong Xue,Huazhe Xu*

Main category: cs.RO

TL;DR: MoE-DP通过专家混合层提升扩散策略的鲁棒性和可解释性，实验显示其成功率显著提升。


<details>
  <summary>Details</summary>
Motivation: 扩散策略在机器人视觉运动控制中缺乏鲁棒性且难以解释，MoE-DP旨在解决这些问题。

Method: 在视觉编码器和扩散模型之间插入专家混合（MoE）层，动态激活不同专家处理任务的不同阶段。

Result: 在6个长视野仿真任务中，MoE-DP在受干扰条件下平均相对成功率提升36%，并在实际应用中验证了性能提升。

Conclusion: MoE-DP通过引入专家混合层，显著提升了扩散策略在长视野、多阶段任务中的鲁棒性，并提供了可解释的技能分解。

Abstract: Diffusion policies have emerged as a powerful framework for robotic
visuomotor control, yet they often lack the robustness to recover from subtask
failures in long-horizon, multi-stage tasks and their learned representations
of observations are often difficult to interpret. In this work, we propose the
Mixture of Experts-Enhanced Diffusion Policy (MoE-DP), where the core idea is
to insert a Mixture of Experts (MoE) layer between the visual encoder and the
diffusion model. This layer decomposes the policy's knowledge into a set of
specialized experts, which are dynamically activated to handle different phases
of a task. We demonstrate through extensive experiments that MoE-DP exhibits a
strong capability to recover from disturbances, significantly outperforming
standard baselines in robustness. On a suite of 6 long-horizon simulation
tasks, this leads to a 36% average relative improvement in success rate under
disturbed conditions. This enhanced robustness is further validated in the real
world, where MoE-DP also shows significant performance gains. We further show
that MoE-DP learns an interpretable skill decomposition, where distinct experts
correspond to semantic task primitives (e.g., approaching, grasping). This
learned structure can be leveraged for inference-time control, allowing for the
rearrangement of subtasks without any re-training.Our video and code are
available at the https://moe-dp-website.github.io/MoE-DP-Website/.

</details>


### [102] [Tunable Passivity Control for Centralized Multiport Networked Systems](https://arxiv.org/abs/2511.05026)
*Xingyuan Zhou,Peter Paik,S. Farokh Atashzar*

Main category: cs.RO

TL;DR: 该论文提出了一种集中式最优被动稳定框架（TCoPC），通过数据驱动方法优化系统性能，确保稳定性，并在仿真中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: CMND系统在复杂网络系统中具有广泛应用，但其稳定性受非理想网络因素影响。传统被动稳定方法存在灵活性低、依赖节点被动性假设等限制，需要一种更灵活、通用的稳定框架。

Method: 论文提出了一种数据驱动的无模型方法——可调集中最优被动控制（TCoPC），通过集中式被动观察器监测能量流动，并由最优被动控制器分配必要的耗散。

Result: 仿真结果表明，TCoPC框架在不同时变延迟场景下表现优异，同时放宽了对远程节点最小相位和被动性的假设，提升了系统的可扩展性和通用性。

Conclusion: 该论文提出了一个集中式最优被动稳定框架（TCoPC），用于CMND系统，通过集中式被动观察器和最优被动控制器，确保系统严格被动性和L2稳定性，同时提升了系统的可扩展性和通用性。

Abstract: Centralized Multiport Networked Dynamic (CMND) systems have emerged as a key
architecture with applications in several complex network systems, such as
multilateral telerobotics and multi-agent control. These systems consist of a
hub node/subsystem connecting with multiple remote nodes/subsystems via a
networked architecture. One challenge for this system is stability, which can
be affected by non-ideal network artifacts. Conventional passivity-based
approaches can stabilize the system under specialized applications like
small-scale networked systems. However, those conventional passive stabilizers
have several restrictions, such as distributing compensation across subsystems
in a decentralized manner, limiting flexibility, and, at the same time, relying
on the restrictive assumptions of node passivity. This paper synthesizes a
centralized optimal passivity-based stabilization framework for CMND systems.
It consists of a centralized passivity observer monitoring overall energy flow
and an optimal passivity controller that distributes the just-needed
dissipation among various nodes, guaranteeing strict passivity and, thus, L2
stability. The proposed data-driven model-free approach, i.e., Tunable
Centralized Optimal Passivity Control (TCoPC), optimizes total performance
based on the prescribed dissipation distribution strategy while ensuring
stability. The controller can put high dissipation loads on some sub-networks
while relaxing the dissipation on other nodes. Simulation results demonstrate
the proposed frameworks performance in a complex task under different
time-varying delay scenarios while relaxing the remote nodes minimum phase and
passivity assumption, enhancing the scalability and generalizability.

</details>


### [103] [Epically Powerful: An open-source software and mechatronics infrastructure for wearable robotic systems](https://arxiv.org/abs/2511.05033)
*Jennifer K. Leestma,Siddharth R. Nathella,Christoph P. O. Nuesslein,Snehil Mathur,Gregory S. Sawicki,Aaron J. Young*

Main category: cs.RO

TL;DR: Epically Powerful是一个开源机器人基础设施，简化可穿戴机器人系统的开发和部署，支持快速构建模块化设备。


<details>
  <summary>Details</summary>
Motivation: 简化可穿戴机器人系统的开发流程，减少从原始硬件到模块化设备的时间和复杂性。

Method: 提供代码库、硬件选择指南、系统组装和控制器实现的全面文档，以及与各种商业现成QDD执行器、单板计算机和常见传感器的无缝接口。

Result: 成功开发了一个支持实时可视化、数据记录和传感器数据获取的开源框架，适用于多种机器人领域。

Conclusion: Epically Powerful是一个开源机器人基础设施，旨在降低开发和部署定制可穿戴机器人系统的门槛，支持快速有效地构建模块化、健壮的设备。

Abstract: Epically Powerful is an open-source robotics infrastructure that streamlines
the underlying framework of wearable robotic systems - managing communication
protocols, clocking, actuator commands, visualization, sensor data acquisition,
data logging, and more - while also providing comprehensive guides for hardware
selection, system assembly, and controller implementation. Epically Powerful
contains a code base enabling simplified user implementation via Python that
seamlessly interfaces with various commercial state-of-the-art quasi-direct
drive (QDD) actuators, single-board computers, and common sensors, provides
example controllers, and enables real-time visualization. To further support
device development, the package also includes a recommended parts list and
compatibility guide and detailed documentation on hardware and software
implementation. The goal of Epically Powerful is to lower the barrier to
developing and deploying custom wearable robotic systems without a
pre-specified form factor, enabling researchers to go from raw hardware to
modular, robust devices quickly and effectively. Though originally designed
with wearable robotics in mind, Epically Powerful is broadly applicable to
other robotic domains that utilize QDD actuators, single-board computers, and
sensors for closed-loop control.

</details>


### [104] [TAPOM: Task-Space Topology-Guided Motion Planning for Manipulating Elongated Object in Cluttered Environments](https://arxiv.org/abs/2511.05052)
*Zihao Li,Yiming Zhu,Zhe Zhong,Qinyuan Ren,Yijiang Huang*

Main category: cs.RO

TL;DR: TAPOM通过任务空间拓扑分析提升狭窄空间中机器人操作的效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 现有规划方法在低间隙场景中因采样困难或局部极小值问题而表现不佳，需要一种更高效的方法来处理狭窄空间中的物体操作。

Method: TAPOM结合高层任务空间拓扑分析识别关键路径并生成引导关键帧，随后通过低层规划器寻找可行的配置空间轨迹。

Result: 实验验证显示，TAPOM在低间隙操作任务中成功率和效率均显著优于现有先进方法。

Conclusion: TAPOM方法通过任务空间拓扑分析显著提升了机器人在狭窄空间中的操作能力，为复杂现实环境中的机器人操作提供了广泛的应用潜力。

Abstract: Robotic manipulation in complex, constrained spaces is vital for widespread
applications but challenging, particularly when navigating narrow passages with
elongated objects. Existing planning methods often fail in these low-clearance
scenarios due to the sampling difficulties or the local minima. This work
proposes Topology-Aware Planning for Object Manipulation (TAPOM), which
explicitly incorporates task-space topological analysis to enable efficient
planning. TAPOM uses a high-level analysis to identify critical pathways and
generate guiding keyframes, which are utilized in a low-level planner to find
feasible configuration space trajectories. Experimental validation demonstrates
significantly high success rates and improved efficiency over state-of-the-art
methods on low-clearance manipulation tasks. This approach offers broad
implications for enhancing manipulation capabilities of robots in complex
real-world environments.

</details>


### [105] [Decomposed Object Manipulation via Dual-Actor Policy](https://arxiv.org/abs/2511.05129)
*Bin Fan,Jianjian Jiang,Zhuohao Li,Yixiang He,Xiaoming Wu,Yihan Yang,Shengbang Liu,Weishi Zheng*

Main category: cs.RO

TL;DR: DAP是一种双重执行者策略，通过分阶段和视觉先验提升物体操作性能，实验显示其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 以往的工作通常忽略物体操作任务的分阶段特性，依赖单一策略直接学习整个过程。本文旨在通过显式分阶段和视觉先验来解决这一问题。

Method: 论文提出了DAP策略，包括基于功能性的执行者（定位功能部分以改进接近过程）和基于运动流的执行者（捕捉组件运动以促进操作过程），以及一个决策模块用于阶段选择和执行者切换。

Result: 在模拟数据集、RoboTwin基准和实际场景中，DAP方法平均分别比现有最佳方法提升了5.55%、14.7%和10.4%。

Conclusion: 论文提出了一种名为DAP的双重执行者策略，通过显式考虑物体操作的不同阶段并利用异构视觉先验来提升每个阶段的性能。实验结果表明，该方法在多个数据集和实际场景中均显著优于现有最佳方法。

Abstract: Object manipulation, which focuses on learning to perform tasks on similar
parts across different types of objects, can be divided into an approaching
stage and a manipulation stage. However, previous works often ignore this
characteristic of the task and rely on a single policy to directly learn the
whole process of object manipulation. To address this problem, we propose a
novel Dual-Actor Policy, termed DAP, which explicitly considers different
stages and leverages heterogeneous visual priors to enhance each stage.
Specifically, we introduce an affordance-based actor to locate the functional
part in the manipulation task, thereby improving the approaching process.
Following this, we propose a motion flow-based actor to capture the movement of
the component, facilitating the manipulation process. Finally, we introduce a
decision maker to determine the current stage of DAP and select the
corresponding actor. Moreover, existing object manipulation datasets contain
few objects and lack the visual priors needed to support training. To address
this, we construct a simulated dataset, the Dual-Prior Object Manipulation
Dataset, which combines the two visual priors and includes seven tasks,
including two challenging long-term, multi-stage tasks. Experimental results on
our dataset, the RoboTwin benchmark and real-world scenarios illustrate that
our method consistently outperforms the SOTA method by 5.55%, 14.7% and 10.4%
on average respectively.

</details>


### [106] [Follow-Me in Micro-Mobility with End-to-End Imitation Learning](https://arxiv.org/abs/2511.05158)
*Sahar Salimpour,Iacopo Catalano,Tomi Westerlund,Mohsen Falahi,Jorge Peña Queralta*

Main category: cs.RO

TL;DR: 模仿学习优于手动调优控制器，DAAV轮椅在跟随模式下实现高舒适度，神经网络架构在实际部署中表现良好。


<details>
  <summary>Details</summary>
Motivation: 自主微移动平台在拥挤且高度动态的环境下面临挑战，优化用户舒适度和整体体验的算法研究不足，这在商业应用中至关重要。

Method: 采用了不同的神经网络架构进行端到端控制，并在实际生产级部署中验证了其可用性。

Result: DAAV的自主轮椅在跟随模式下实现了最先进的舒适度，验证了模仿学习的优越性。

Conclusion: 模仿学习能够提供比手动调优控制器更平滑、更优的控制效果，DAAV的自主轮椅在跟随模式下实现了最先进的舒适度。

Abstract: Autonomous micro-mobility platforms face challenges from the perspective of
the typical deployment environment: large indoor spaces or urban areas that are
potentially crowded and highly dynamic. While social navigation algorithms have
progressed significantly, optimizing user comfort and overall user experience
over other typical metrics in robotics (e.g., time or distance traveled) is
understudied. Specifically, these metrics are critical in commercial
applications. In this paper, we show how imitation learning delivers smoother
and overall better controllers, versus previously used manually-tuned
controllers. We demonstrate how DAAV's autonomous wheelchair achieves
state-of-the-art comfort in follow-me mode, in which it follows a human
operator assisting persons with reduced mobility (PRM). This paper analyzes
different neural network architectures for end-to-end control and demonstrates
their usability in real-world production-level deployments.

</details>


### [107] [Procedimiento de auditoría de ciberseguridad para sistemas autónomos: metodología, amenazas y mitigaciones](https://arxiv.org/abs/2511.05185)
*Adrián Campazas-Vega,Claudia Álvarez-Aparicio,David Sobrín-Hidalgo,Laura Inyesto-Alonso,Francisco Javier Rodríguez-Lera,Vicente Matellán-Olivera,Ángel Manuel Guerrero-Higueras*

Main category: cs.RO

TL;DR: 本文针对自主系统的安全风险，提出分层审计方法，并通过实际案例验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 自主系统在医疗、物流等关键领域的广泛应用带来了显著的安全风险，其高复杂性和技术发展扩大了攻击面，亟需有效的安全审计方法。

Method: 采用分层结构方法论和适应机器人环境的威胁分类，结合具体缓解措施，设计了安全审计程序。

Result: 通过四个代表性机器人平台（如Ghost Robotics的Vision 60、Unitree Robotics的A1等）的案例研究验证了方法的有效性。

Conclusion: 本文提出了一种基于分层结构方法、适用于机器人环境的威胁分类和具体缓解措施的自主系统安全审计程序，并通过四个实际案例研究验证了其有效性。

Abstract: The deployment of autonomous systems has experienced remarkable growth in
recent years, driven by their integration into sectors such as industry,
medicine, logistics, and domestic environments. This expansion is accompanied
by a series of security issues that entail significant risks due to the
critical nature of autonomous systems, especially those operating in
human-interaction environments. Furthermore, technological advancement and the
high operational and architectural complexity of autonomous systems have
resulted in an increased attack surface. This article presents a specific
security auditing procedure for autonomous systems, based on a layer-structured
methodology, a threat taxonomy adapted to the robotic context, and a set of
concrete mitigation measures. The validity of the proposed approach is
demonstrated through four practical case studies applied to representative
robotic platforms: the Vision 60 military quadruped from Ghost Robotics, the A1
robot from Unitree Robotics, the UR3 collaborative arm from Universal Robots,
and the Pepper social robot from Aldebaran Robotics.

</details>


### [108] [Let Me Show You: Learning by Retrieving from Egocentric Video for Robotic Manipulation](https://arxiv.org/abs/2511.05199)
*Yichen Zhu,Feifei Feng*

Main category: cs.RO

TL;DR: 提出RfV方法，通过视频库和双组件系统提升机器人任务学习和泛化能力，性能显著优于传统系统。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在复杂不确定环境中依赖大量数据学习的局限性，模仿人类通过视频学习的方式提升任务适应能力。

Method: 构建视频库并提取中层信息（如物体功能掩码和手部运动轨迹），结合视频检索器和策略生成器的双组件系统，实现知识整合与任务泛化。

Result: 在模拟和真实环境中测试表明，系统性能显著优于传统方法，展现了机器人领域的重大突破。

Conclusion: 通过Retrieving-from-Video（RfV）方法，机器人能够从人类视频演示中学习并适应多样化任务，显著提升了在复杂环境中的性能。

Abstract: Robots operating in complex and uncertain environments face considerable
challenges. Advanced robotic systems often rely on extensive datasets to learn
manipulation tasks. In contrast, when humans are faced with unfamiliar tasks,
such as assembling a chair, a common approach is to learn by watching video
demonstrations. In this paper, we propose a novel method for learning robot
policies by Retrieving-from-Video (RfV), using analogies from human
demonstrations to address manipulation tasks. Our system constructs a video
bank comprising recordings of humans performing diverse daily tasks. To enrich
the knowledge from these videos, we extract mid-level information, such as
object affordance masks and hand motion trajectories, which serve as additional
inputs to enhance the robot model's learning and generalization capabilities.
We further feature a dual-component system: a video retriever that taps into an
external video bank to fetch task-relevant video based on task specification,
and a policy generator that integrates this retrieved knowledge into the
learning cycle. This approach enables robots to craft adaptive responses to
various scenarios and generalize to tasks beyond those in the training data.
Through rigorous testing in multiple simulated and real-world settings, our
system demonstrates a marked improvement in performance over conventional
robotic systems, showcasing a significant breakthrough in the field of
robotics.

</details>


### [109] [Beyond Master and Apprentice: Grounding Foundation Models for Symbiotic Interactive Learning in a Shared Latent Space](https://arxiv.org/abs/2511.05203)
*Linus Nwankwo,Björn Ellensohn,Christian Rauch,Elmar Rueckert*

Main category: cs.RO

TL;DR: SIL通过双向互动和协同适应提升人机交互，利用预训练模型和记忆架构实现任务空间表示的稳定学习。


<details>
  <summary>Details</summary>
Motivation: 现有的人机交互模式多为单向的主从关系，缺乏人类间多轮互动的协同适应性。

Method: 提出了共生交互学习（SIL）框架，利用预训练基础模型和轻量级潜在编码器，结合记忆架构防止任务空间表示的遗忘。

Result: 在模拟和真实世界的多种任务中验证了SIL的有效性，包括指令跟随、信息检索和交互对话等。

Conclusion: SIL方法通过双向互动实现了人类与自主代理的协同适应，提升了交互的主动性和灵活性，验证了其在多种任务中的有效性。

Abstract: Today's autonomous agents can understand free-form natural language
instructions and execute long-horizon tasks in a manner akin to human-level
reasoning. These capabilities are mostly driven by large-scale pre-trained
foundation models (FMs). However, the approaches with which these models are
grounded for human-robot interaction (HRI) perpetuate a master-apprentice
model, where the apprentice (embodied agent) passively receives and executes
the master's (human's) commands without reciprocal learning. This reactive
interaction approach does not capture the co-adaptive dynamics inherent in
everyday multi-turn human-human interactions. To address this, we propose a
Symbiotic Interactive Learning (SIL) approach that enables both the master and
the apprentice to co-adapt through mutual, bidirectional interactions. We
formalised SIL as a co-adaptation process within a shared latent task space,
where the agent and human maintain joint belief states that evolve based on
interaction history. This enables the agent to move beyond reactive execution
to proactive clarification, adaptive suggestions, and shared plan refinement.
To realise these novel behaviours, we leveraged pre-trained FMs for spatial
perception and reasoning, alongside a lightweight latent encoder that grounds
the models' outputs into task-specific representations. Furthermore, to ensure
stability as the tasks evolve, we augment SIL with a memory architecture that
prevents the forgetting of learned task-space representations. We validate SIL
on both simulated and real-world embodied tasks, including instruction
following, information retrieval, query-oriented reasoning, and interactive
dialogues. Demos and resources are public
at:~\href{https://linusnep.github.io/SIL/}{https://linusnep.github.io/SIL/}.

</details>


### [110] [Context-aware Learned Mesh-based Simulation via Trajectory-Level Meta-Learning](https://arxiv.org/abs/2511.05234)
*Philipp Dahlinger,Niklas Freymuth,Tai Hoang,Tobias Würth,Michael Volpp,Luise Kärger,Gerhard Neumann*

Main category: cs.RO

TL;DR: M3GN improves simulation accuracy and speed by using meta-learning and movement primitives, addressing limitations of current methods.


<details>
  <summary>Details</summary>
Motivation: The motivation stems from the limitations of existing learned simulators, which rely on single-step observations and auto-regressive rollouts, leading to error accumulation and inability to infer material properties. The need for faster and more accurate simulations in domains like robotics and manufacturing drives this research.

Method: The method involves framing mesh-based simulation as a trajectory-level meta-learning problem using Conditional Neural Processes, which allows for rapid adaptation to new scenarios and captures latent simulation properties. Movement primitives are used to predict stable and accurate simulations from a single model call.

Result: The results show that M3GN achieves higher simulation accuracy with reduced runtime costs compared to state-of-the-art GNSs across multiple tasks.

Conclusion: The paper concludes that the proposed M3GN approach significantly improves simulation accuracy and efficiency compared to existing GNS methods, making it a valuable tool for applications requiring fast and precise simulations.

Abstract: Simulating object deformations is a critical challenge across many scientific
domains, including robotics, manufacturing, and structural mechanics. Learned
Graph Network Simulators (GNSs) offer a promising alternative to traditional
mesh-based physics simulators. Their speed and inherent differentiability make
them particularly well suited for applications that require fast and accurate
simulations, such as robotic manipulation or manufacturing optimization.
However, existing learned simulators typically rely on single-step
observations, which limits their ability to exploit temporal context. Without
this information, these models fail to infer, e.g., material properties.
Further, they rely on auto-regressive rollouts, which quickly accumulate error
for long trajectories. We instead frame mesh-based simulation as a
trajectory-level meta-learning problem. Using Conditional Neural Processes, our
method enables rapid adaptation to new simulation scenarios from limited
initial data while capturing their latent simulation properties. We utilize
movement primitives to directly predict fast, stable and accurate simulations
from a single model call. The resulting approach, Movement-primitive
Meta-MeshGraphNet (M3GN), provides higher simulation accuracy at a fraction of
the runtime cost compared to state-of-the-art GNSs across several tasks.

</details>


### [111] [TwinVLA: Data-Efficient Bimanual Manipulation with Twin Single-Arm Vision-Language-Action Models](https://arxiv.org/abs/2511.05275)
*Hokyun Im,Euijin Jeong,Jianlong Fu,Andrey Kolobov,Youngwoon Lee*

Main category: cs.RO

TL;DR: TwinVLA通过组合预训练单臂VLA实现高效双臂操作，无需额外双臂数据，性能接近最先进模型。


<details>
  <summary>Details</summary>
Motivation: 现有公开数据集主要关注单臂操作，直接适应双臂任务需要大量额外数据和微调，因此需要一种更高效的方法。

Method: TwinVLA是一个模块化框架，将两个预训练的单臂VLA组合成一个协调的双臂VLA，避免了直接训练双臂模型的需求。

Result: TwinVLA在真实世界和模拟环境中均优于同规模的单体模型（如RDT-1B），且无需双臂预训练，显著缩小了与依赖大量专有数据的先进模型（如π₀）的差距。

Conclusion: TwinVLA通过模块化组合预训练的单臂VLA，提供了一种数据高效且可扩展的双臂操作解决方案，无需额外的双臂预训练即可接近最先进模型的性能。

Abstract: Vision-language-action models (VLAs) trained on large-scale robotic datasets
have demonstrated strong performance on manipulation tasks, including bimanual
tasks. However, because most public datasets focus on single-arm
demonstrations, adapting VLAs for bimanual tasks typically requires substantial
additional bimanual data and fine-tuning. To address this challenge, we
introduce TwinVLA, a modular framework that composes two copies of a pretrained
single-arm VLA into a coordinated bimanual VLA. Unlike monolithic
cross-embodiment models trained on mixtures of single-arm and bimanual data,
TwinVLA improves both data efficiency and performance by composing pretrained
single-arm policies. Across diverse bimanual tasks in real-world and simulation
settings, TwinVLA outperforms a comparably-sized monolithic RDT-1B model
without requiring any bimanual pretraining. Furthermore, it narrows the gap to
state-of-the-art model, $\pi_0$ which rely on extensive proprietary bimanual
data and compute cost. These results establish our modular composition approach
as a data-efficient and scalable path toward high-performance bimanual
manipulation, leveraging public single-arm data.

</details>


### [112] [Force-Safe Environment Maps and Real-Time Detection for Soft Robot Manipulators](https://arxiv.org/abs/2511.05307)
*Akua K. Dickson,Juan C. Pacheco Garcia,Andrew P. Sabelhaus*

Main category: cs.RO

TL;DR: 该研究提出了一种实时力安全检测框架，通过任务空间到配置空间的映射，确保软体机器人与精细障碍物交互时的安全性，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有障碍物检测和避障方法未考虑软体机器人操作器与精细障碍物接触时的力限制，因此需要一种实时力安全检测框架。

Method: 通过将任务空间（即机器人身体位置）的力安全标准映射到配置空间（即机器人关节角度），并结合环境接触力的限制，利用正向运动学确保配置的安全性与最大力阈值的关系。

Result: 仿真和硬件实验验证了该方法在与可变形障碍物交互时能准确检测力安全。

Conclusion: 该研究提出的框架能够实时检测软体机器人操作器的力安全配置，为在精细、复杂环境中实现实时安全规划奠定了基础。

Abstract: Soft robot manipulators have the potential for deployment in delicate
environments to perform complex manipulation tasks. However, existing obstacle
detection and avoidance methods do not consider limits on the forces that
manipulators may exert upon contact with delicate obstacles. This work
introduces a framework that maps force safety criteria from task space (i.e.
positions along the robot's body) to configuration space (i.e. the robot's
joint angles) and enables real-time force safety detection. We incorporate
limits on allowable environmental contact forces for given task-space
obstacles, and map them into configuration space (C-space) through the
manipulator's forward kinematics. This formulation ensures that configurations
classified as safe are provably below the maximum force thresholds, thereby
allowing us to determine force-safe configurations of the soft robot
manipulator in real-time. We validate our approach in simulation and hardware
experiments on a two-segment pneumatic soft robot manipulator. Results
demonstrate that the proposed method accurately detects force safety during
interactions with deformable obstacles, thereby laying the foundation for
real-time safe planning of soft manipulators in delicate, cluttered
environments.

</details>


### [113] [ETHOS: A Robotic Encountered-Type Haptic Display for Social Interaction in Virtual Reality](https://arxiv.org/abs/2511.05379)
*Eric Godden,Jacquie Groenewegen,Matthew K. X. J. Pan*

Main category: cs.RO

TL;DR: ETHOS是一种动态触觉显示系统，通过机器人操纵器和被动道具实现VR中的自然社交互动，展示了高保真动态人际互动的可行性。


<details>
  <summary>Details</summary>
Motivation: 旨在实现虚拟现实（VR）中社交互动（如握手、击掌等）的自然物理接触。

Method: 系统整合了扭矩控制的机器人操纵器、可互换的被动道具、基于标记的物理-虚拟注册以及安全监控器。介绍了两种控制策略：静态模式和动态模式。

Result: 静态共置精度为5.09 +/- 0.94毫米，用户互动的平均接触延迟为28.53 +/- 31.21毫秒。

Conclusion: ETHOS通过整合安全和控制机制，为虚拟环境中高保真、动态的人际互动奠定了实用基础。

Abstract: We present ETHOS (Encountered-Type Haptics for On-demand Social Interaction),
a dynamic encountered-type haptic display (ETHD) that enables natural physical
contact in virtual reality (VR) during social interactions such as handovers,
fist bumps, and high-fives. The system integrates a torque-controlled robotic
manipulator with interchangeable passive props (silicone hand replicas and a
baton), marker-based physical-virtual registration via a ChArUco board, and a
safety monitor that gates motion based on the user's head and hand pose. We
introduce two control strategies: (i) a static mode that presents a stationary
prop aligned with its virtual counterpart, consistent with prior ETHD
baselines, and (ii) a dynamic mode that continuously updates prop position by
exponentially blending an initial mid-point trajectory with real-time hand
tracking, generating a unique contact point for each interaction. Bench tests
show static colocation accuracy of 5.09 +/- 0.94 mm, while user interactions
achieved temporal alignment with an average contact latency of 28.53 +/- 31.21
ms across all interaction and control conditions. These results demonstrate the
feasibility of recreating socially meaningful haptics in VR. By incorporating
essential safety and control mechanisms, ETHOS establishes a practical
foundation for high-fidelity, dynamic interpersonal interactions in virtual
environments.

</details>


### [114] [EveryDayVLA: A Vision-Language-Action Model for Affordable Robotic Manipulation](https://arxiv.org/abs/2511.05397)
*Samarth Chopra,Alex McMoil,Ben Carnovale,Evan Sokolson,Rajkumar Kubendran,Samuel Dickerson*

Main category: cs.RO

TL;DR: EverydayVLA是一种低成本6-DOF机械臂，结合先进模型，表现优异且经济实惠。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作模型依赖昂贵硬件，且在复杂或新场景中表现不佳。

Method: 引入了一个6自由度机械臂EverydayVLA，成本低于300美元，能够承载适度负载和工作空间。采用单一统一模型输出离散和连续动作，并通过自适应时间集成监测运动不确定性以触发即时重新规划。

Result: 在LIBERO基准测试中，EverydayVLA与最先进方法的成功率相当，在真实世界测试中分别比先前方法高出49%（分布内）和34.9%（分布外）。

Conclusion: EverydayVLA通过结合先进的视觉-语言-动作模型和低成本硬件，为家庭和研究实验室提供了经济实惠的机器人基础模型，推动了其在家庭和研究实验室的经济应用。

Abstract: While Vision-Language-Action (VLA) models map visual inputs and language
instructions directly to robot actions, they often rely on costly hardware and
struggle in novel or cluttered scenes. We introduce EverydayVLA, a 6-DOF
manipulator that can be assembled for under $300, capable of modest payloads
and workspace. A single unified model jointly outputs discrete and continuous
actions, and our adaptive-horizon ensemble monitors motion uncertainty to
trigger on-the-fly re-planning for safe, reliable operation. On LIBERO,
EverydayVLA matches state-of-the-art success rates, and in real-world tests it
outperforms prior methods by 49% in-distribution and 34.9% out-of-distribution.
By combining a state-of-the-art VLA with cost-effective hardware, EverydayVLA
democratizes access to a robotic foundation model and paves the way for
economical use in homes and research labs alike. Experiment videos and details:
https://everydayvla.github.io/

</details>


### [115] [Stable and Robust SLIP Model Control via Energy Conservation-Based Feedback Cancellation for Quadrupedal Applications](https://arxiv.org/abs/2511.05402)
*Muhammad Saud Ul Hassan,Derek Vasquez,Hamza Asif,Christian Hubicki*

Main category: cs.RO

TL;DR: 基于SLIP模型和能量守恒的四足机器人动态运动控制算法，仿真验证了其稳定性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 受自然界四足动物运动行为的启发，旨在为仿生四足机器人设计一种稳定且节能的动态运动控制方法。

Method: 采用弹簧负载倒立摆（SLIP）模型，结合飞行阶段的腿部方向控制和支撑阶段的腿部长度控制，通过能量守恒原理计算稳定的抛物线样条轨迹。

Result: 仿真实验基于Ghost Robotics Minitaur机器人，验证了控制算法能生成稳定的弹跳步态，并展示了其对传感器误差的鲁棒性。

Conclusion: 该控制架构基于能量守恒原理，成功实现了四足机器人稳定动态运动，即使在传感器测量存在10%误差的情况下仍能保持稳定。

Abstract: In this paper, we present an energy-conservation based control architecture
for stable dynamic motion in quadruped robots. We model the robot as a
Spring-loaded Inverted Pendulum (SLIP), a model well-suited to represent the
bouncing motion characteristic of running gaits observed in various biological
quadrupeds and bio-inspired robotic systems. The model permits leg-orientation
control during flight and leg-length control during stance, a design choice
inspired by natural quadruped behaviors and prevalent in robotic quadruped
systems. Our control algorithm uses the reduced-order SLIP dynamics of the
quadruped to track a stable parabolic spline during stance, which is calculated
using the principle of energy conservation. Through simulations based on the
design specifications of an actual quadruped robot, Ghost Robotics Minitaur, we
demonstrate that our control algorithm generates stable bouncing gaits.
Additionally, we illustrate the robustness of our controller by showcasing its
ability to maintain stable bouncing even when faced with up to a 10% error in
sensor measurements.

</details>


### [116] [Bioinspired Soft Quadrotors Jointly Unlock Agility, Squeezability, and Collision Resilience](https://arxiv.org/abs/2511.05426)
*Luca Girardi,Gabriel Maquignaz,Stefano Mintchev*

Main category: cs.RO

TL;DR: FlexiQuad是一种软框架四旋翼设计，兼具高敏捷性、碰撞抗性和挤压性，适用于复杂环境。


<details>
  <summary>Details</summary>
Motivation: 传统四旋翼的刚性框架在碰撞抗性和挤压性上存在局限，而自然界飞行动物的软翅膀却能在多种飞行行为中表现出色。

Method: 受生物体各向异性刚度和分布式质量-能量结构的启发，开发了FlexiQuad软框架四旋翼设计方法，并通过405克的原型机验证其性能。

Result: FlexiQuad原型机在保持高敏捷性（峰值速度80 km/h，加速度3 g）的同时，碰撞抗性提高4倍，可压缩至70%宽度通过狭窄空间，结构柔软度范围为0.006至0.77 N/mm。

Conclusion: FlexiQuad通过软框架设计成功突破了传统四旋翼在碰撞抗性和挤压性上的限制，同时保持了高敏捷性，为复杂环境中的无人机应用提供了新可能。

Abstract: Natural flyers use soft wings to seamlessly enable a wide range of flight
behaviours, including agile manoeuvres, squeezing through narrow passageways,
and withstanding collisions. In contrast, conventional quadrotor designs rely
on rigid frames that support agile flight but inherently limit collision
resilience and squeezability, thereby constraining flight capabilities in
cluttered environments. Inspired by the anisotropic stiffness and distributed
mass-energy structures observed in biological organisms, we introduce
FlexiQuad, a soft-frame quadrotor design approach that limits this trade-off.
We demonstrate a 405-gram FlexiQuad prototype, three orders of magnitude more
compliant than conventional quadrotors, yet capable of acrobatic manoeuvres
with peak speeds above 80 km/h and linear and angular accelerations exceeding 3
g and 300 rad/s$^2$, respectively. Analysis demonstrates it can replicate
accelerations of rigid counterparts up to a thrust-to-weight ratio of 8.
Simultaneously, FlexiQuad exhibits fourfold higher collision resilience,
surviving frontal impacts at 5 m/s without damage and reducing destabilising
forces in glancing collisions by a factor of 39. Its frame can fully compress,
enabling flight through gaps as narrow as 70% of its nominal width. Our
analysis identifies an optimal structural softness range, from 0.006 to 0.77
N/mm, comparable to that of natural flyers' wings, whereby agility,
squeezability, and collision resilience are jointly achieved for FlexiQuad
models from 20 to 3000 grams. FlexiQuad expands hovering drone capabilities in
complex environments, enabling robust physical interactions without
compromising flight performance.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [117] [Improved Additive Approximation Algorithms for APSP](https://arxiv.org/abs/2511.04775)
*Ce Jin,Yael Kirkpatrick,Michał Stawarz,Virginia Vassilevska Williams*

Main category: cs.DS

TL;DR: 本文改进了近似APSP问题的算法，通过图分解和标准矩阵乘法，显著降低了时间复杂度。


<details>
  <summary>Details</summary>
Motivation: 近似APSP问题在理论计算机科学中具有基础性意义，但现有算法的效率仍有提升空间。本文旨在通过简化方法提升计算效率。

Method: 通过将输入图分解为少量恒定直径的簇和低度数顶点的剩余部分，结合标准快速矩阵乘法，避免了复杂的有界差异(min,+)积算法。

Result: 在+2、+4和+6近似APSP问题上，分别实现了O(n^2.2255)、O(n^2.1462)和O(n^2.1026)的时间复杂度，优于现有最佳算法。

Conclusion: 本文提出了一种新的算法，显著提高了近似APSP问题的计算效率，特别是在+2、+4和+6近似情况下，时间复杂度分别降至O(n^2.2255)、O(n^2.1462)和O(n^2.1026)。

Abstract: The All-Pairs Shortest Paths (APSP) is a foundational problem in theoretical
computer science. Approximating APSP in undirected unweighted graphs has been
studied for many years, beginning with the work of Dor, Halperin and Zwick
[SICOMP'01]. Many recent works have attempted to improve these original
algorithms using the algebraic tools of fast matrix multiplication. We improve
on these results for the following problems.
  For $+2$-approximate APSP, the state-of-the-art algorithm runs in
$O(n^{2.259})$ time [D\"urr, IPL 2023; Deng, Kirkpatrick, Rong, Vassilevska
Williams, and Zhong, ICALP 2022]. We give an improved algorithm in
$O(n^{2.2255})$ time.
  For $+4$ and $+6$-approximate APSP, we achieve time complexities
$O(n^{2.1462})$ and $O(n^{2.1026})$ respectively, improving the previous
$O(n^{2.155})$ and $O(n^{2.103})$ achieved by [Saha and Ye, SODA 2024].
  In contrast to previous works, we do not use the big hammer of
bounded-difference $(\min,+)$-product algorithms. Instead, our algorithms are
based on a simple technique that decomposes the input graph into a small number
of clusters of constant diameter and a remainder of low degree vertices, which
could be of independent interest in the study of shortest paths problems. We
then use only standard fast matrix multiplication to obtain our improvements.

</details>


### [118] [Optimal Parallel Basis Finding in Graphic and Related Matroids](https://arxiv.org/abs/2511.04826)
*Sanjeev Khanna,Aaron Putterman,Junkai Song*

Main category: cs.DS

TL;DR: 论文解决了图形拟阵并行复杂度的开放问题，提出了高效算法并证明其最优性。


<details>
  <summary>Details</summary>
Motivation: 研究图形拟阵在独立性预言访问下的并行复杂度，解决Karp等人提出的关于能否同时实现多对数轮次和多项式查询次数的开放问题。

Method: 提出了一种确定性算法，结合自适应轮次和非自适应查询，适用于图形拟阵和满足平滑电路计数性质的二元拟阵。

Result: 算法在$O(\log m)$轮次和$\mathrm{poly}(m)$查询下找到生成森林，并证明了这一结果的紧下界。

Conclusion: 该论文解决了关于图形拟阵并行复杂度的长期开放问题，提出了一个确定性算法，能够在$O(\log m)$自适应轮次和$\mathrm{poly}(m)$非自适应查询下找到生成森林，并证明了这一结果的紧下界。

Abstract: We study the parallel complexity of finding a basis of a graphic matroid
under independence-oracle access. Karp, Upfal, and Wigderson (FOCS 1985, JCSS
1988) initiated the study of this problem and established two algorithms for
finding a spanning forest: one running in $O(\log m)$ rounds with
$m^{\Theta(\log m)}$ queries, and another, for any $d \in \mathbb{Z}^+$,
running in $O(m^{2/d})$ rounds with $\Theta(m^d)$ queries. A key open question
they posed was whether one could simultaneously achieve polylogarithmic rounds
and polynomially many queries. We give a deterministic algorithm that uses
$O(\log m)$ adaptive rounds and $\mathrm{poly}(m)$ non-adaptive queries per
round to return a spanning forest on $m$ edges, and complement this result with
a matching $\Omega(\log m)$ lower bound for any (even randomized) algorithm
with $\mathrm{poly}(m)$ queries per round. Thus, the adaptive round complexity
for graphic matroids is characterized exactly, settling this long-standing
problem. Beyond graphs, we show that our framework also yields an $O(\log
m)$-round, $\mathrm{poly}(m)$-query algorithm for any binary matroid satisfying
a smooth circuit counting property, implying, among others, an optimal $O(\log
m)$-round parallel algorithms for finding bases of cographic matroids.

</details>


### [119] [Tight Bounds for Sampling q-Colorings via Coupling from the Past](https://arxiv.org/abs/2511.04982)
*Tianxing Ding,Hongyang Liu,Yitong Yin,Can Zhou*

Main category: cs.DS

TL;DR: 本研究确定了基于边界链的CFTP算法在图着色中的渐近紧阈值q≥2.5Δ，并通过优化边界链设计实现了这一目标。


<details>
  <summary>Details</summary>
Motivation: 为了改进现有的CFTP算法在图着色问题中的性能，特别是在q值接近Δ时的效率。

Method: 通过优化边界链的设计，提出了一个高效的CFTP算法。

Result: 证明了所有满足标准收缩性质的此类算法需要q≥2.5Δ，并提出了一个达到渐近最优阈值的算法。

Conclusion: 本研究确立了基于边界链的CFTP算法在图着色问题中的渐近紧阈值，提出了一个高效的CFTP算法，实现了渐近最优的阈值q≥(2.5+o(1))Δ。

Abstract: The Coupling from the Past (CFTP) paradigm is a canonical method for perfect
sampling. For uniform sampling of proper $q$-colorings in graphs with maximum
degree $\Delta$, the bounding chains of Huber (STOC 1998) provide a systematic
framework for efficiently implementing CFTP algorithms within the classical
regime $q \ge (1 + o(1))\Delta^2$. This was subsequently improved to $q >
3\Delta$ by Bhandari and Chakraborty (STOC 2020) and to $q \ge (8/3 +
o(1))\Delta$ by Jain, Sah, and Sawhney (STOC 2021).
  In this work, we establish the asymptotically tight threshold for
bounding-chain-based CFTP algorithms for graph colorings. We prove a lower
bound showing that all such algorithms satisfying the standard contraction
property require $q \ge 2.5\Delta$, and we present an efficient CFTP algorithm
that achieves this asymptotically optimal threshold $q \ge (2.5 + o(1))\Delta$
via an optimal design of bounding chains.

</details>


### [120] [Language Generation and Identification From Partial Enumeration: Tight Density Bounds and Topological Characterizations](https://arxiv.org/abs/2511.05295)
*Jon Kleinberg,Fan Wei*

Main category: cs.DS

TL;DR: 论文解决了语言生成框架中的下密度界限问题，证明了1/2的最佳界限，并扩展到部分枚举场景，同时重新审视了Gold-Angluin模型。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的成功激发了语言生成和学习的形式理论研究，本研究旨在解决该领域的核心开放性问题。

Method: 采用理论证明方法，分析了语言生成框架中的下密度界限，并通过部分枚举模型扩展了结果。

Result: 证明了在语言生成框架中，算法可以达到1/2的最佳下密度，并在部分枚举场景中匹配了上限。

Conclusion: 论文证明了在语言生成框架中，算法可以达到1/2的最佳下密度，并将结果推广到部分枚举场景，同时重新审视了Gold-Angluin模型，给出了新的拓扑表述。

Abstract: The success of large language models (LLMs) has motivated formal theories of
language generation and learning. We study the framework of \emph{language
generation in the limit}, where an adversary enumerates strings from an unknown
language $K$ drawn from a countable class, and an algorithm must generate
unseen strings from $K$. Prior work showed that generation is always possible,
and that some algorithms achieve positive lower density, revealing a
\emph{validity--breadth} trade-off between correctness and coverage. We resolve
a main open question in this line, proving a tight bound of $1/2$ on the best
achievable lower density. We then strengthen the model to allow \emph{partial
enumeration}, where the adversary reveals only an infinite subset $C \subseteq
K$. We show that generation in the limit remains achievable, and if $C$ has
lower density $\alpha$ in $K$, the algorithm's output achieves density at least
$\alpha/2$, matching the upper bound. This generalizes the $1/2$ bound to the
partial-information setting, where the generator must recover within a factor
$1/2$ of the revealed subset's density. We further revisit the classical
Gold--Angluin model of \emph{language identification} under partial
enumeration. We characterize when identification in the limit is possible --
when hypotheses $M_t$ eventually satisfy $C \subseteq M \subseteq K$ -- and in
the process give a new topological formulation of Angluin's characterization,
showing that her condition is precisely equivalent to an appropriate
topological space having the $T_D$ separation property.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [121] [AWARE: Evaluating PriorityFresh Caching for Offline Emergency Warning Systems](https://arxiv.org/abs/2511.05022)
*Charles Melvin,N. Rich Nguyen*

Main category: cs.NI

TL;DR: PriorityFresh是为离线紧急预警系统设计的缓存策略，优化警报展示，实验显示其在提高可操作性的同时不影响效率。


<details>
  <summary>Details</summary>
Motivation: 为离线紧急预警系统设计一个在连接受限情况下优化警报保留和展示的缓存策略。

Method: 设计了一个语义化、以可操作性优先的缓存策略PriorityFresh，并在模拟环境中进行实验。

Result: 实验表明，PriorityFresh在保持效率的同时，提高了可操作性优先的性能。

Conclusion: PriorityFresh在AWARE系统的模拟环境中优化了警报的保留和展示，提高了可操作性优先的性能，同时不影响效率。

Abstract: PriorityFresh is a semantic, actionability-first caching policy designed for
offline emergency warning systems. Within the AWARE system's simulation
environment, PriorityFresh optimizes which alerts to retain and surface under
constrained connectivity. Experiments indicate improved actionability-first
performance without harming efficiency. A separate Priority Forecasting model
is used only to synthesize realistic alert sequences for controlled experiments
and does not influence caching or push decisions.

</details>


### [122] [Cross-link RTS/CTS for MLO mm-Wave WLANs](https://arxiv.org/abs/2511.05027)
*Zhuoling Chen,Yi Zhong,Martin Haenggi*

Main category: cs.NI

TL;DR: 本文提出跨链路RTS/CTS机制解决毫米波Wi-Fi的隐藏终端问题，通过G-HCP模型分析空间收发关系，揭示了链路质量与吞吐量的权衡。


<details>
  <summary>Details</summary>
Motivation: 毫米波Wi-Fi的方向性RTS/CTS机制难以完美解决隐藏终端问题。

Method: 提出了在多链路操作（MLO）下的跨链路RTS/CTS机制，并引入了一种新颖的点过程——广义RTS/CTS硬核过程（G-HCP），以建模RTS/CTS机制下的空间收发关系。

Result: 理论分析和数值结果表明，跨链路RTS/CTS机制以降低网络吞吐量为代价确保了更高的链路质量，而方向性RTS/CTS则牺牲链路质量以获得更高的吞吐量。

Conclusion: 本研究揭示了链路可靠性与网络吞吐量之间的基本权衡，为下一代WLAN标准中RTS/CTS机制的选择和优化提供了关键见解。

Abstract: The directional RTS/CTS mechanism of mm-wave Wi-Fi hardly resolves the hidden
terminal problem perfectly.This paper proposes cross-link RTS/CTS under
multi-link operation (MLO) to address this problem and introduces a novel point
process, named the generalized RTS/CTS hard-core process (G-HCP), to model the
spatial transceiver relationships under the RTS/CTS mechanism, including the
directional case and the omnidirectional case.Analytical expressions are
derived for the intensity, the mean interference, an approximation of the
success probability, and the expected number of hidden nodes for the
directional RTS/CTS mechanism.Theoretical and numerical results demonstrate the
performance difference between two RTS/CTS mechanisms.The cross-link RTS/CTS
mechanism ensures higher link quality at the cost of reduced network
throughput.In contrast, the directional RTS/CTS sacrifices the link quality for
higher throughput.Our study reveals a fundamental trade-off between link
reliability and network throughput, providing critical insights into the
selection and optimization of RTS/CTS mechanisms in next-generation WLAN
standards.

</details>


### [123] [Improving Injection-Throttling Mechanisms for Congestion Control for Data-center and Supercomputer Interconnects](https://arxiv.org/abs/2511.05149)
*Cristina Olmedilla,Jesus Escudero-Sahuquillo,Pedro J. Garcia,Francisco J. Quiles,Jose Duato*

Main category: cs.NI

TL;DR: 本文优化DCQCN机制，提升拥塞控制效率。


<details>
  <summary>Details</summary>
Motivation: 当前高性能互连网络中，DCQCN的拥塞检测、通知和反应机制未随网络动态变化而更新，导致控制流量开销大和非拥塞流的不必要节流。

Method: 重新设计DCQCN的闭环机制，优化拥塞检测、通知和反应流程。

Result: 改进后的DCQCN机制减少了控制流量开销，并有效避免了非拥塞流的不必要节流。

Conclusion: 本文重新审视并改进了DCQCN的闭环机制，通过更精准的拥塞检测、信号传递和注入节流，减少了控制流量开销，并避免了非拥塞流的不必要节流。

Abstract: Over the past decade, Supercomputers and Data centers have evolved
dramatically to cope with the increasing performance requirements of
applications and services, such as scientific computing, generative AI, social
networks or cloud services. This evolution have led these systems to
incorporate high-speed networks using faster links, end nodes using multiple
and dedicated accelerators, or a advancements in memory technologies to bridge
the memory bottleneck. The interconnection network is a key element in these
systems and it must be thoroughly designed so it is not the bottleneck of the
entire system, bearing in mind the countless communication operations that
generate current applications and services. Congestion is serious threat that
spoils the interconnection network performance, and its effects are even more
dramatic when looking at the traffic dynamics and bottlenecks generated by the
communication operations mentioned above. In this vein, numerous congestion
control (CC) techniques have been developed to address congestion negative
effects. One popular example is Data Center Quantized Congestion Notification
(DCQCN), which allows congestion detection at network switch buffers, then
marking congesting packets and notifying about congestion to the sources, which
finally apply injection throttling of those packets contributing to congestion.
While DCQCN has been widely studied and improved, its main principles for
congestion detection, notification and reaction remain largely unchanged, which
is an important shortcoming considering congestion dynamics in current
high-performance interconnection networks. In this paper, we revisit the DCQCN
closed-loop mechanism and refine its design to leverage a more accurate
congestion detection, signaling, and injection throttling, reducing control
traffic overhead and avoiding unnecessary throttling of non-congesting flows.

</details>


### [124] [EPFL-REMNet: Efficient Personalized Federated Digital Twin Towards 6G Heterogeneous Radio Environme](https://arxiv.org/abs/2511.05238)
*Peide Li,Liu Cao,Lyutianyang Zhang,Dongyu Wei,Ye Hu,Qipeng Xie*

Main category: cs.NI

TL;DR: EPFL-REMNet是一种高效个性化联邦学习框架，用于构建6G异构无线电环境的高保真数字孪生，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决标准联邦学习在6G异构无线电环境中因非独立同分布数据导致的性能下降问题。

Method: 采用‘共享主干+轻量个性化头部’模型，仅传输压缩共享主干，个性化头部本地维护。

Result: 在三种非独立同分布场景中，EPFL-REMNet均实现了更高的数字孪生保真度和更低的上行开销。

Conclusion: EPFL-REMNet在非独立同分布数据条件下显著提高了数字孪生的保真度和通信效率，优于现有方法。

Abstract: Radio Environment Map (REM) is transitioning from 5G homogeneous environments
to B5G/6G heterogeneous landscapes. However, standard Federated Learning (FL),
a natural fit for this distributed task, struggles with performance degradation
in accuracy and communication efficiency under the non-independent and
identically distributed (Non-IID) data conditions inherent to these new
environments. This paper proposes EPFL-REMNet, an efficient personalized
federated framework for constructing a high-fidelity digital twin of the 6G
heterogeneous radio environment. The proposed EPFL-REMNet employs a"shared
backbone + lightweight personalized head" model, where only the compressed
shared backbone is transmitted between the server and clients, while each
client's personalized head is maintained locally. We tested EPFL-REMNet by
constructing three distinct Non-IID scenarios (light, medium, and heavy) based
on radio environment complexity, with data geographically partitioned across 90
clients. Experimental results demonstrate that EPFL-REMNet simultaneously
achieves higher digital twin fidelity (accuracy) and lower uplink overhead
across all Non-IID settings compared to standard FedAvg and recent
state-of-the-art methods. Particularly, it significantly reduces performance
disparities across datasets and improves local map accuracy for long-tail
clients, enhancing the overall integrity of digital twin.

</details>


### [125] [A Formal Model for Path Set Attribute Calculation in Network Systems](https://arxiv.org/abs/2511.05334)
*Giovanni Fiaschi,Carlo Vitucci,Thomas Westerbäck,Daniel Sundmark,Thomas Nolte*

Main category: cs.NI

TL;DR: 本文提出了一种数学模型，用于在网络应用中评估路径集，强调了属性在路径集分析中的重要性。


<details>
  <summary>Details</summary>
Motivation: 在图论及其实际网络应用中，路径选择问题至关重要。虽然已有研究对单一路径解决方案进行了全面评估，但对于路径集的评估缺乏同样的详细分析。本文强调路径特性强烈依赖于所考虑的属性，这在分析多个路径集时尤为关键。

Method: 本文提出了一种数学方法，定义了一个功能模型，适用于路径集的一般性描述，并展示了如何将特定属性纳入模型中。

Result: 本文提出的功能模型能够有效地描述路径集，并能将特定属性纳入模型中进行分析。

Conclusion: 本文通过提出一个数学模型，成功地解决了在网络应用中评估路径集的问题，强调了属性依赖性在路径集分析中的重要性。

Abstract: In graph theory and its practical networking applications, e.g.,
telecommunications and transportation, the problem of finding paths has
particular importance. Selecting paths requires giving scores to the
alternative solutions to drive a choice. While previous studies have provided
comprehensive evaluation of single-path solutions, the same level of detail is
lacking when considering sets of paths. This paper emphasizes that the path
characterization strongly depends on the properties under consideration. While
property-based characterization is also valid for single paths, it becomes
crucial to analyse multiple path sets. From the above consideration, this paper
proposes a mathematical approach, defining a functional model that lends itself
well to characterizing the path set in its general formulation. The paper shows
how the functional model contextualizes specific attributes.

</details>


### [126] [To Squelch or not to Squelch: Enabling Improved Message Dissemination on the XRP Ledger](https://arxiv.org/abs/2511.05362)
*Lucian Trestioreanu,Flaviene Scheidt,Wazen Shbair,Jerome Francois,Damien Magoni,Radu State*

Main category: cs.NI

TL;DR: 本文评估了XRP Ledger中Squelching机制的实际效果，并与替代方案进行了比较，填补了对共识验证型区块链网络通信机制研究的空白。


<details>
  <summary>Details</summary>
Motivation: 随着区块链技术的广泛应用，其底层对等网络需要高效且具有弹性的通信机制。然而，现有研究主要集中在主流的工作量证明（PoW）分布式账本技术上，如比特币或以太坊，而对于共识验证型区块链（如XRP Ledger）的研究较少。XRP Ledger依赖联邦拜占庭协议（FBA）共识机制，其交易吞吐量具有良好的可扩展性，但网络规模的显著增加会面临挑战，主要原因是共识协议相关消息的泛洪机制会在网络中产生大量重复。Squelching是最近提出的一种减少重复的解决方案，但尚未在实际生产网络中进行定量评估。

Method: 使用现实可控的测试床和XRPL生产网络来评估Squelching机制。

Result: 本文通过实验评估了Squelching机制的效果，并与基于命名数据网络和基于gossip的替代方案进行了比较。

Conclusion: 本文通过实验评估了Squelching机制在XRPL生产网络中的实际效果，并与基于命名数据网络和基于gossip的替代方案进行了比较。

Abstract: With the large increase in the adoption of blockchain technologies, their
underlying peer-to-peer networks must also scale with the demand. In this
context, previous works highlighted the importance of ensuring efficient and
resilient communication for the underlying consensus and replication
mechanisms. However, they were mainly focused on mainstream,
Proof-of-Work-based Distributed Ledger Technologies like Bitcoin or Ethereum.
  In this paper, the problem is investigated in the context of
consensus-validation based blockchains, like the XRP Ledger. The latter relies
on a Federated Byzantine Agreement (FBA) consensus mechanism which is proven to
have a good scalability in regards to transaction throughput. However, it is
known that significant increases in the size of the XRP Ledger network would be
challenging to achieve. The main reason is the flooding mechanism used to
disseminate the messages related to the consensus protocol, which creates many
duplicates in the network. Squelching is a recent solution proposed for
limiting this duplication, however, it was never evaluated quantitatively in
real-life scenarios involving the XRPL production network. In this paper, our
aim is to assess this mechanism using a real-life controllable testbed and the
XRPL production network, to assess its benefit and compare it to alternative
solutions relying on Named Data Networking and on a gossip-based approach.

</details>


### [127] [Scanning the IPv6 Internet Using Subnet-Router Anycast Probing](https://arxiv.org/abs/2511.05423)
*Maynard Koch,Raphael Hiesgen,Marcin Nawrocki,Thomas C. Schmidt,Matthias Wählisch*

Main category: cs.NI

TL;DR: SRA探测在IPv6测量中效果显著，比随机探测多发现10%地址，且受限制更少，是重要工具补充。


<details>
  <summary>Details</summary>
Motivation: IPv6地址空间庞大，识别活跃地址具有挑战性，需探索更有效的探测方法。

Method: 应用主动Subnet-Router anycast（SRA）探测技术，并与现有方法（如命中列表、新探测技术和AI生成目标列表）及随机探测结果进行比较。

Result: SRA探测平均比随机探测多发现10%的路由器IP地址，且受ICMP速率限制影响更小；相比直接探测路由器地址，SRA探测多发现80%的地址。

Conclusion: SRA探测是IPv6测量工具箱中的重要补充，可显著提升结果的稳定性。同时发现某些主动扫描可能导致当前IPv6部署中的有害状况，正与网络运营商合作修复。

Abstract: Identifying active IPv6 addresses is challenging. Various methods emerged to
master the measurement challenge in this huge address space, including
hitlists, new probing techniques, and AI-generated target lists. In this paper,
we apply active Subnet-Router anycast (SRA) probing, a commonly unused method
to explore the IPv6 address space. We compare our results with lists of active
IPv6 nodes obtained from prior methods and with random probing. Our findings
indicate that probing an SRA address reveals on average 10% more router IP
addresses than random probing and is far less affected by ICMP rate limiting.
Compared to targeting router addresses directly, SRA probing discovers 80% more
addresses. We conclude that SRA probing is an important addition to the IPv6
measurement toolbox and may improve the stability of results significantly. We
also find evidence that some active scans can cause harmful conditions in
current IPv6 deployments, which we started to fix in collaboration with network
operators.

</details>
