<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 296]
- [cs.GR](#cs.GR) [Total: 4]
- [cs.SE](#cs.SE) [Total: 24]
- [cs.DC](#cs.DC) [Total: 40]
- [cs.RO](#cs.RO) [Total: 55]
- [cs.DS](#cs.DS) [Total: 9]
- [cs.AI](#cs.AI) [Total: 82]
- [cs.NI](#cs.NI) [Total: 6]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Psychological stress during Examination and its estimation by handwriting in answer script](https://arxiv.org/abs/2511.11633)
*Abhijeet Kumar,Chetan Agarwal,Pronoy B. Neogi,Mayank Goswami*

Main category: cs.CV

TL;DR: 研究利用AI和图形学技术分析学生手写考试脚本，量化心理压力，提供超越传统评分系统的认知和情绪状态洞察。


<details>
  <summary>Details</summary>
Motivation: 探索如何超越传统评分系统，通过分析学生手写考试脚本，更深入地了解其考试期间的认知和情绪状态。

Method: 采用高分辨率图像处理、TrOCR技术和基于RoBERTa模型的情感熵融合，结合五模型投票机制和无监督异常检测，构建了一个稳健的应力指数生成系统。

Result: 提出的数据驱动方法能够有效生成数值化的应力指数，为学术法医学领域带来了创新性的解决方案。

Conclusion: 该研究通过结合图形学和人工智能技术，成功开发了一种量化学生心理压力的创新方法，为学术法医学提供了新的研究框架。

Abstract: This research explores the fusion of graphology and artificial intelligence to quantify psychological stress levels in students by analyzing their handwritten examination scripts. By leveraging Optical Character Recognition and transformer based sentiment analysis models, we present a data driven approach that transcends traditional grading systems, offering deeper insights into cognitive and emotional states during examinations. The system integrates high resolution image processing, TrOCR, and sentiment entropy fusion using RoBERTa based models to generate a numerical Stress Index. Our method achieves robustness through a five model voting mechanism and unsupervised anomaly detection, making it an innovative framework in academic forensics.

</details>


### [2] [Real-time pothole detection with onboard sensors and camera on vehicles](https://arxiv.org/abs/2511.11643)
*Aswath Muthuselvam,Jeevak Raj S,Mohanaprasad K*

Main category: cs.CV

TL;DR: 利用车载传感器和SVM分类器实时检测道路坑洼，测试准确率98.1%，代码已开源。


<details>
  <summary>Details</summary>
Motivation: 道路状况对日常通勤至关重要，小裂缝可能迅速恶化为大坑洞，需实时监测以保障交通流畅。

Method: 使用SVM分类器分析车载传感器数据，检测道路坑洼。

Result: 在2公里路段（含26个坑洞）的测试中，模型准确率达98.1%。

Conclusion: 通过车载传感器结合SVM分类器实时检测道路坑洼具有高准确性，为大规模道路管理提供了有效解决方案。

Abstract: Road conditions play an important role in our everyday commute. With the proliferating number of vehicles on the road each year, it has become necessary to access the road conditions very frequently, this would ensure that the traffic also flows smoothly. Even the smallest crack in the road could be easily be chipped into a large pothole due to changing surface temperatures of the road and from the force of vehicles riding over it. In this paper, we have addressed how we could better identify these potholes in realtime with the help of onboard sensors in vehicles so that the data could be useful for analysis and better management of potholes on a large scale. For the implementation, we used an SVM classifier to detect potholes, we achieved 98.1% accuracy based on data collected from a local road for about 2 km which had 26 potholes distributed along the road. Code is available at: https://github.com/aswathselvam/Potholes

</details>


### [3] [A Method for Identifying Farmland System Habitat Types Based on the Dynamic-Weighted Feature Fusion Network Model](https://arxiv.org/abs/2511.11659)
*Kesong Zheng,Zhi Song,Peizhou Li,Shuyi Yao,Zhenxing Bian*

Main category: cs.CV

TL;DR: 本研究开发了一个包含15类耕田系统生境的超高清遥感图像数据集，并提出了动态加权特征融合网络（DWFF-Net），通过自适应动态加权策略和混合损失函数优化，显著提升了多尺度生境分割的精度和边界清晰度。


<details>
  <summary>Details</summary>
Motivation: 针对目前耕田生态系统缺乏标准化的生境分类系统、生境类型覆盖不全、现有模型无法有效整合语义和纹理特征（导致多尺度生境分割精度不足和边界模糊）的问题。

Method: 通过分析不同类别图像与特征图之间的关系，引入数据级自适应动态加权策略进行特征融合。解码器部分采用动态权重计算网络实现多层特征的深度整合，并采用混合损失函数优化模型训练。

Result: 实验结果表明，所提出的模型在构建的数据集上实现了平均交集比并集（mIoU）0.6979和F1分数0.8049，分别比基线网络高出0.021和0.0161。

Conclusion: 本研究基于自适应多层特征融合，建立了耕田系统生境识别框架，实现了低成本亚米级精度的生境制图，为精细化的耕田景观生境监测提供了强有力的技术支持。

Abstract: Addressing the current lack of a standardized habitat classification system for cultivated land ecosystems, incomplete coverage of habitat types, and the inability of existing models to effectively integrate semantic and texture features-resulting in insufficient segmentation accuracy and blurred boundaries for multi-scale habitats (e.g., large-scale field plots and micro-habitats)-this study developed a comprehensively annotated ultra-high-resolution remote sensing image dataset encompassing 15 categories of cultivated land system habitats. Furthermore, we propose a Dynamic-Weighted Feature Fusion Network (DWFF-Net). The encoder of this model utilizes a frozen-parameter DINOv3 to extract foundational features. By analyzing the relationships between different category images and feature maps, we introduce a data-level adaptive dynamic weighting strategy for feature fusion. The decoder incorporates a dynamic weight computation network to achieve thorough integration of multi-layer features, and a hybrid loss function is adopted to optimize model training. Experimental results on the constructed dataset demonstrate that the proposed model achieves a mean Intersection over Union (mIoU) of 0.6979 and an F1-score of 0.8049, outperforming the baseline network by 0.021 and 0.0161, respectively. Ablation studies further confirm the complementary nature of multi-layer feature fusion, which effectively improves the IoU for micro-habitat categories such as field ridges. This study establishes a habitat identification framework for cultivated land systems based on adaptive multi-layer feature fusion, enabling sub-meter precision habitat mapping at a low cost and providing robust technical support for fine-grained habitat monitoring in cultivated landscapes.

</details>


### [4] [AGENet: Adaptive Edge-aware Geodesic Distance Learning for Few-Shot Medical Image Segmentation](https://arxiv.org/abs/2511.11662)
*Ziyuan Gao*

Main category: cs.CV

TL;DR: AGENet是一种新型医学图像分割框架，通过边缘感知的测地距离学习和自适应原型提取，在有限标注数据下实现了精确的边界分割。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割需要大量标注数据，这在临床应用中是一个瓶颈。现有方法在边界精确划分上表现不佳，尤其是在解剖结构相似且缺乏空间上下文的情况下。

Method: AGENet框架包含三个主要组件：(1)边缘感知的测地距离学习模块，(2)自适应原型提取模块，(3)自适应参数学习模块。这些组件共同作用，通过几何建模提升分割精度。

Result: 实验证明，AGENet在多种医学影像数据集上优于现有方法，显著减少了边界误差，同时保持了计算效率。

Conclusion: AGENet通过结合空间关系和轻量级几何建模，显著提升了医学图像分割的边界精度，尤其在标注数据有限的情况下，表现出优异的性能和计算效率。

Abstract: Medical image segmentation requires large annotated datasets, creating a significant bottleneck for clinical applications. While few-shot segmentation methods can learn from minimal examples, existing approaches demonstrate suboptimal performance in precise boundary delineation for medical images, particularly when anatomically similar regions appear without sufficient spatial context. We propose AGENet (Adaptive Geodesic Edge-aware Network), a novel framework that incorporates spatial relationships through edge-aware geodesic distance learning. Our key insight is that medical structures follow predictable geometric patterns that can guide prototype extraction even with limited training data. Unlike methods relying on complex architectural components or heavy neural networks, our approach leverages computationally lightweight geometric modeling. The framework combines three main components: (1) An edge-aware geodesic distance learning module that respects anatomical boundaries through iterative Fast Marching refinement, (2) adaptive prototype extraction that captures both global structure and local boundary details via spatially-weighted aggregation, and (3) adaptive parameter learning that automatically adjusts to different organ characteristics. Extensive experiments across diverse medical imaging datasets demonstrate improvements over state-of-the-art methods. Notably, our method reduces boundary errors compared to existing approaches while maintaining computational efficiency, making it highly suitable for clinical applications requiring precise segmentation with limited annotated data.

</details>


### [5] [LithoSeg: A Coarse-to-Fine Framework for High-Precision Lithography Segmentation](https://arxiv.org/abs/2511.12005)
*Xinyu He,Botong Zhao,Bingbing Li,Shujing Lyu,Jiwei Shen,Yue Lu*

Main category: cs.CV

TL;DR: LithoSeg是一种新型光刻SEM图像分割方法，通过粗到细网络和1D回归，显著提升精度并减少监督需求。


<details>
  <summary>Details</summary>
Motivation: 光刻SEM图像的精确分割和测量对半导体制造至关重要，但现有方法在精度和鲁棒性上不足，限制了实际应用。

Method: LithoSeg采用粗到细的两阶段方法：粗阶段使用带有人类参与的SAM模型实现鲁棒性；细阶段将2D分割转化为1D回归问题，通过轻量级MLP进行点级优化。

Result: LithoSeg在分割精度和测量精度上均优于现有方法，且所需监督更少。

Conclusion: LithoSeg通过粗到细的网络架构和创新的1D回归方法，显著提升了光刻SEM图像的分割和测量精度，同时减少了对监督的依赖，具有实际应用的广阔前景。

Abstract: Accurate segmentation and measurement of lithography scanning electron microscope (SEM) images are crucial for ensuring precise process control, optimizing device performance, and advancing semiconductor manufacturing yield. Lithography segmentation requires pixel-level delineation of groove contours and consistent performance across diverse pattern geometries and process window. However, existing methods often lack the necessary precision and robustness, limiting their practical applicability. To overcome this challenge, we propose LithoSeg, a coarse-to-fine network tailored for lithography segmentation. In the coarse stage, we introduce a Human-in-the-Loop Bootstrapping scheme for the Segment Anything Model (SAM) to attain robustness with minimal supervision. In the subsequent fine stage, we recast 2D segmentation as 1D regression problem by sampling groove-normal profiles using the coarse mask and performing point-wise refinement with a lightweight MLP. LithoSeg outperforms previous approaches in both segmentation accuracy and metrology precision while requiring less supervision, offering promising prospects for real-world applications.

</details>


### [6] [Co-Layout: LLM-driven Co-optimization for Interior Layout](https://arxiv.org/abs/2511.12474)
*Chucheng Xiang,Ruchao Bao,Biyin Feng,Wenzheng Wu,Zhongyuan Liu,Yirui Guan,Ligang Liu*

Main category: cs.CV

TL;DR: 论文提出了一种结合LLMs和网格优化的自动室内设计框架，通过粗到细策略显著提升解决方案质量和计算效率。


<details>
  <summary>Details</summary>
Motivation: 为了优化室内设计的自动化和效率，结合LLMs和网格优化方法，解决传统两阶段设计流程在解决方案质量和计算效率上的不足。

Method: 论文采用LLM驱动的代理工作流程，从文本提示中提取结构化设计约束，并将其编码为统一的基于网格的表示。采用粗到细的优化策略，先在低分辨率网格上解决简化问题，再引导全分辨率下的解决方案。

Result: 实验结果显示，该联合优化方法在多样场景中显著优于现有设计流程，并且在计算效率上有显著提升。

Conclusion: 该论文提出的结合大型语言模型（LLMs）和基于网格的整数编程的新型框架，在自动室内设计领域显著优于现有的两阶段设计流程，并通过粗到细的优化策略实现了计算效率的提升。

Abstract: We present a novel framework for automated interior design that combines large language models (LLMs) with grid-based integer programming to jointly optimize room layout and furniture placement. Given a textual prompt, the LLM-driven agent workflow extracts structured design constraints related to room configurations and furniture arrangements. These constraints are encoded into a unified grid-based representation inspired by ``Modulor". Our formulation accounts for key design requirements, including corridor connectivity, room accessibility, spatial exclusivity, and user-specified preferences. To improve computational efficiency, we adopt a coarse-to-fine optimization strategy that begins with a low-resolution grid to solve a simplified problem and guides the solution at the full resolution. Experimental results across diverse scenarios demonstrate that our joint optimization approach significantly outperforms existing two-stage design pipelines in solution quality, and achieves notable computational efficiency through the coarse-to-fine strategy.

</details>


### [7] [EPSegFZ: Efficient Point Cloud Semantic Segmentation for Few- and Zero-Shot Scenarios with Language Guidance](https://arxiv.org/abs/2511.11700)
*Jiahui Wang,Haiyue Zhu,Haoren Guo,Abdullah Al Mamun,Cheng Xiang,Tong Heng Lee*

Main category: cs.CV

TL;DR: EPSegFZ是一种无需预训练的点云语义分割网络，通过增强特征提取和利用文本信息，显著提升了少样本和零样本性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法过度依赖预训练且未充分利用支持集中的文本信息，限制了模型的灵活性和零样本能力。

Method: EPSegFZ网络包含三个关键组件：ProERA模块用于增强特征提取和查询-原型对应关系构建；DRPE机制基于交叉注意力；LGPE模块利用支持集中的文本信息提升性能。

Result: 在S3DIS和ScanNet基准测试中，EPSegFZ分别比现有最优方法提升了5.68%和3.82%。

Conclusion: EPSegFZ通过引入ProERA模块、DRPE机制和LGPE模块，有效解决了现有方法对预训练的依赖以及支持集信息利用不足的问题，显著提升了少样本和零样本场景下的点云语义分割性能。

Abstract: Recent approaches for few-shot 3D point cloud semantic segmentation typically require a two-stage learning process, i.e., a pre-training stage followed by a few-shot training stage. While effective, these methods face overreliance on pre-training, which hinders model flexibility and adaptability. Some models tried to avoid pre-training yet failed to capture ample information. In addition, current approaches focus on visual information in the support set and neglect or do not fully exploit other useful data, such as textual annotations. This inadequate utilization of support information impairs the performance of the model and restricts its zero-shot ability. To address these limitations, we present a novel pre-training-free network, named Efficient Point Cloud Semantic Segmentation for Few- and Zero-shot scenarios. Our EPSegFZ incorporates three key components. A Prototype-Enhanced Registers Attention (ProERA) module and a Dual Relative Positional Encoding (DRPE)-based cross-attention mechanism for improved feature extraction and accurate query-prototype correspondence construction without pre-training. A Language-Guided Prototype Embedding (LGPE) module that effectively leverages textual information from the support set to improve few-shot performance and enable zero-shot inference. Extensive experiments show that our method outperforms the state-of-the-art method by 5.68% and 3.82% on the S3DIS and ScanNet benchmarks, respectively.

</details>


### [8] [Lightweight Optimal-Transport Harmonization on Edge Devices](https://arxiv.org/abs/2511.12785)
*Maria Larchenko,Dmitry Guskov,Alexander Lobashev,Georgy Derevyanko*

Main category: cs.CV

TL;DR: 本文提出轻量化的MKL-Harmonizer算法，利用最优传输理论实现AR图像实时色彩协调，并发布专用数据集。


<details>
  <summary>Details</summary>
Motivation: 解决AR中色彩协调问题，填补现有算法因缺乏实时解决方案而未被集成到AR流程中的空白。

Method: 利用经典的最优传输理论，训练一个紧凑的编码器来预测Monge-Kantorovich传输映射，实现了轻量化的实时解决方案。

Result: 在真实AR合成图像的基准测试中，MKL-Harmonizer算法优于现有方法，实现了最佳综合评分。

Conclusion: 本文提出的MKL-Harmonizer算法在AR合成图像中取得了最佳的综合评分，并发布了专用的AR数据集和工具包以支持进一步研究。

Abstract: Color harmonization adjusts the colors of an inserted object so that it perceptually matches the surrounding image, resulting in a seamless composite. The harmonization problem naturally arises in augmented reality (AR), yet harmonization algorithms are not currently integrated into AR pipelines because real-time solutions are scarce. In this work, we address color harmonization for AR by proposing a lightweight approach that supports on-device inference. For this, we leverage classical optimal transport theory by training a compact encoder to predict the Monge-Kantorovich transport map. We benchmark our MKL-Harmonizer algorithm against state-of-the-art methods and demonstrate that for real composite AR images our method achieves the best aggregated score. We release our dedicated AR dataset of composite images with pixel-accurate masks and data-gathering toolkit to support further data acquisition by researchers.

</details>


### [9] [Task-Aware 3D Affordance Segmentation via 2D Guidance and Geometric Refinement](https://arxiv.org/abs/2511.11702)
*Lian He,Meng Liu,Qilang Ye,Yu Zhou,Xiang Deng,Gangyi Ding*

Main category: cs.CV

TL;DR: TASA是一种几何优化框架，结合2D语义和3D几何推理，有效提升场景级可操作性分割的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注对象级可操作性或将2D预测直接提升到3D，忽略了点云中的丰富几何结构信息且计算成本高。

Method: TASA采用几何优化的粗到细框架，结合2D语义线索和3D几何推理，包括任务感知的2D可操作性检测模块和3D可操作性细化模块。

Result: 在SceneFun3D数据集上的实验表明，TASA在场景级可操作性分割任务中显著优于基线方法。

Conclusion: TASA框架在场景级可操作性分割任务中显著优于基线方法，证明了其准确性和高效性。

Abstract: Understanding 3D scene-level affordances from natural language instructions is essential for enabling embodied agents to interact meaningfully in complex environments. However, this task remains challenging due to the need for semantic reasoning and spatial grounding. Existing methods mainly focus on object-level affordances or merely lift 2D predictions to 3D, neglecting rich geometric structure information in point clouds and incurring high computational costs. To address these limitations, we introduce Task-Aware 3D Scene-level Affordance segmentation (TASA), a novel geometry-optimized framework that jointly leverages 2D semantic cues and 3D geometric reasoning in a coarse-to-fine manner. To improve the affordance detection efficiency, TASA features a task-aware 2D affordance detection module to identify manipulable points from language and visual inputs, guiding the selection of task-relevant views. To fully exploit 3D geometric information, a 3D affordance refinement module is proposed to integrate 2D semantic priors with local 3D geometry, resulting in accurate and spatially coherent 3D affordance masks. Experiments on SceneFun3D demonstrate that TASA significantly outperforms the baselines in both accuracy and efficiency in scene-level affordance segmentation.

</details>


### [10] [PFAvatar: Pose-Fusion 3D Personalized Avatar Reconstruction from Real-World Outfit-of-the-Day Photos](https://arxiv.org/abs/2511.12935)
*Dianbing Xi,Guoyuan An,Jingsen Zhu,Zhijian Liu,Yuan Liu,Ruiyuan Zhang,Jiayuan Lu,Rui Wang,Yuchi Huo*

Main category: cs.CV

TL;DR: PFAvatar 是一种从OOTD照片快速重建高保真3D虚拟形象的方法，通过两阶段（扩散模型微调+NeRF蒸馏）解决了现有方法的分解不一致和遮挡问题，速度提升48倍，支持下游应用。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将图像分解为服装、配饰等资产进行3D组装，容易导致不一致性，且处理复杂背景和遮挡时效果有限。PFAvatar 旨在直接从多样姿态、遮挡和复杂背景的OOTD照片中高效重建高保真3D虚拟形象。

Method: PFAvatar 采用两阶段方法：1. 通过预训练的ControlNet进行姿态估计，结合新颖的Condition Prior Preservation Loss（CPPL），从少量OOTD样本中微调姿态感知扩散模型，直接建模全身外观；2. 通过基于NeRF的虚拟形象表示，利用规范SMPL-X空间采样和多分辨率3D-SDS优化，避免网格表示的分辨率依赖和遮挡几何错误。

Result: 实验证明，PFAvatar 在重建保真度、细节保留（如高频纹理）和遮挡/截断鲁棒性上优于现有方法，且个性化速度提升48倍（仅需5分钟）。重建的3D虚拟形象支持虚拟试穿、动画等应用。

Conclusion: PFAvatar 提出了一种从“每日穿搭”（OOTD）照片中重建高质量3D虚拟形象的新方法，通过两阶段流程（基于姿态感知的扩散模型微调和NeRF表示的3D虚拟形象蒸馏）显著提升了重建保真度、细节保留和对遮挡/截断的鲁棒性。该方法不仅速度快（5分钟完成个性化），还支持虚拟试穿、动画等下游应用，展示了其多功能性和实用价值。

Abstract: We propose PFAvatar (Pose-Fusion Avatar), a new method that reconstructs high-quality 3D avatars from ``Outfit of the Day'' (OOTD) photos, which exhibit diverse poses, occlusions, and complex backgrounds. Our method consists of two stages: (1) fine-tuning a pose-aware diffusion model from few-shot OOTD examples and (2) distilling a 3D avatar represented by a neural radiance field (NeRF). In the first stage, unlike previous methods that segment images into assets (e.g., garments, accessories) for 3D assembly, which is prone to inconsistency, we avoid decomposition and directly model the full-body appearance. By integrating a pre-trained ControlNet for pose estimation and a novel Condition Prior Preservation Loss (CPPL), our method enables end-to-end learning of fine details while mitigating language drift in few-shot training. Our method completes personalization in just 5 minutes, achieving a 48$\times$ speed-up compared to previous approaches. In the second stage, we introduce a NeRF-based avatar representation optimized by canonical SMPL-X space sampling and Multi-Resolution 3D-SDS. Compared to mesh-based representations that suffer from resolution-dependent discretization and erroneous occluded geometry, our continuous radiance field can preserve high-frequency textures (e.g., hair) and handle occlusions correctly through transmittance. Experiments demonstrate that PFAvatar outperforms state-of-the-art methods in terms of reconstruction fidelity, detail preservation, and robustness to occlusions/truncations, advancing practical 3D avatar generation from real-world OOTD albums. In addition, the reconstructed 3D avatar supports downstream applications such as virtual try-on, animation, and human video reenactment, further demonstrating the versatility and practical value of our approach.

</details>


### [11] [LE-CapsNet: A Light and Enhanced Capsule Network](https://arxiv.org/abs/2511.11708)
*Pouya Shiri,Amirali Baniasadi*

Main category: cs.CV

TL;DR: LE-CapsNet是一种轻量、增强且更准确的CapsNet变体，在CIFAR-10数据集上实现76.73%的准确率，推理速度快4倍，并在AffNIST数据集上达到94.3%的准确率。


<details>
  <summary>Details</summary>
Motivation: CapsNet虽然在检测重叠类别和变换图像方面优于CNN，但其速度慢、资源消耗大、参数多且准确率不如CNN。

Method: 提出LE-CapsNet，通过减少参数（仅3.8M权重）和优化结构，提升速度和准确率。

Result: 在CIFAR-10上准确率76.73%，推理速度比CapsNet快4倍；在AffNIST上准确率94.3%，优于CapsNet的90.52%。

Conclusion: LE-CapsNet在保持CapsNet优势的同时，显著提升了速度和准确率，成为更高效的替代方案。

Abstract: Capsule Network (CapsNet) classifier has several advantages over CNNs, including better detection of images containing overlapping categories and higher accuracy on transformed images. Despite the advantages, CapsNet is slow due to its different structure. In addition, CapsNet is resource-hungry, includes many parameters and lags in accuracy compared to CNNs. In this work, we propose LE-CapsNet as a light, enhanced and more accurate variant of CapsNet. Using 3.8M weights, LECapsNet obtains 76.73% accuracy on the CIFAR-10 dataset while performing inference 4x faster than CapsNet. In addition, our proposed network is more robust at detecting images with affine transformations compared to CapsNet. We achieve 94.3% accuracy on the AffNIST dataset (compared to CapsNet 90.52%).

</details>


### [12] [SymGS : Leveraging Local Symmetries for 3D Gaussian Splatting Compression](https://arxiv.org/abs/2511.13264)
*Keshav Gupta,Akshat Sanghvi,Shreyas Reddy Palley,Astitva Srivastava,Charu Sharma,Avinash Sharma*

Main category: cs.CV

TL;DR: SymGS是一种利用对称感知技术的新型压缩框架，显著提升3D高斯泼溅的压缩效率，同时保持渲染质量。


<details>
  <summary>Details</summary>
Motivation: 解决3D高斯泼溅在复杂场景中内存占用快速增加的问题，超越现有压缩方法的限制。

Method: 提出了一种新颖的压缩框架SymGS，通过引入可学习的镜像消除局部和全局的反射冗余，作为现有压缩方法（如HAC）的插件增强。

Result: 在基准数据集上实现了1.66倍的压缩（大规模场景可达3倍），平均压缩率达到108倍，同时保持渲染质量。

Conclusion: SymGS通过引入可学习的镜像和对称感知技术，显著提升了3D高斯泼溅的压缩效率，同时保持了渲染质量。

Abstract: 3D Gaussian Splatting has emerged as a transformative technique in novel view synthesis, primarily due to its high rendering speed and photorealistic fidelity. However, its memory footprint scales rapidly with scene complexity, often reaching several gigabytes. Existing methods address this issue by introducing compression strategies that exploit primitive-level redundancy through similarity detection and quantization. We aim to surpass the compression limits of such methods by incorporating symmetry-aware techniques, specifically targeting mirror symmetries to eliminate redundant primitives. We propose a novel compression framework, \textbf{\textit{SymGS}}, introducing learnable mirrors into the scene, thereby eliminating local and global reflective redundancies for compression. Our framework functions as a plug-and-play enhancement to state-of-the-art compression methods, (e.g. HAC) to achieve further compression. Compared to HAC, we achieve $1.66 \times$ compression across benchmark datasets (upto $3\times$ on large-scale scenes). On an average, SymGS enables $\bf{108\times}$ compression of a 3DGS scene, while preserving rendering quality. The project page and supplementary can be found at \textbf{\color{cyan}{symgs.github.io}}

</details>


### [13] [Target-Balanced Score Distillation](https://arxiv.org/abs/2511.11710)
*Zhou Xu,Qi Wang,Yuxiao Yang,Luyuan Zhang,Zhang Liang,Yang Li*

Main category: cs.CV

TL;DR: TBSD通过多目标优化和自适应策略解决了SDS在3D资产生成中的纹理与形状权衡问题，显著提升了纹理真实性和几何准确性。


<details>
  <summary>Details</summary>
Motivation: vanilla SDS在生成3D资产时存在过饱和和过平滑问题，现有方法通过负提示改进，但面临纹理优化受限或形状失真的权衡。

Method: 提出Target-Balanced Score Distillation (TBSD)，将生成建模为多目标优化问题，并采用自适应策略平衡纹理和形状。

Result: TBSD在实验中显著优于现有方法，生成具有高保真纹理和几何准确形状的3D资产。

Conclusion: TBSD通过系统分析和创新设计，有效解决了SDS的局限性，为3D资产生成提供了更优解决方案。

Abstract: Score Distillation Sampling (SDS) enables 3D asset generation by distilling priors from pretrained 2D text-to-image diffusion models, but vanilla SDS suffers from over-saturation and over-smoothing. To mitigate this issue, recent variants have incorporated negative prompts. However, these methods face a critical trade-off: limited texture optimization, or significant texture gains with shape distortion. In this work, we first conduct a systematic analysis and reveal that this trade-off is fundamentally governed by the utilization of the negative prompts, where Target Negative Prompts (TNP) that embed target information in the negative prompts dramatically enhancing texture realism and fidelity but inducing shape distortions. Informed by this key insight, we introduce the Target-Balanced Score Distillation (TBSD). It formulates generation as a multi-objective optimization problem and introduces an adaptive strategy that effectively resolves the aforementioned trade-off. Extensive experiments demonstrate that TBSD significantly outperforms existing state-of-the-art methods, yielding 3D assets with high-fidelity textures and geometrically accurate shape.

</details>


### [14] [CompressNAS : A Fast and Efficient Technique for Model Compression using Decomposition](https://arxiv.org/abs/2511.11716)
*Sudhakar Sah,Nikhil Chabbra,Matthieu Durnerin*

Main category: cs.CV

TL;DR: CompressNAS通过全局秩选择框架高效压缩CNN模型，显著减少参数和计算量，同时保持合理精度，推出了新压缩模型STResNet。


<details>
  <summary>Details</summary>
Motivation: 深度CNN在微控制器和轻量级NPU上的部署面临模型大小和计算需求的挑战，现有方法在秩选择上缺乏全局权衡考虑。

Method: 采用MicroNAS启发的框架，通过快速精度估计器评估候选分解，实现内存和精度约束下的高效秩探索。

Result: 在ImageNet上，CompressNAS将ResNet-18压缩8倍，精度损失小于4%；在COCO上，YOLOv5s实现2倍压缩且无精度损失，YOLOv5n压缩2倍精度下降2.5%。

Conclusion: CompressNAS提供了一种全局视角的秩选择方法，显著提升了模型压缩效率，并推出了新的压缩模型家族STResNet，展示了与现有高效模型竞争的性能。

Abstract: Deep Convolutional Neural Networks (CNNs) are increasingly difficult to deploy on microcontrollers (MCUs) and lightweight NPUs (Neural Processing Units) due to their growing size and compute demands. Low-rank tensor decomposition, such as Tucker factorization, is a promising way to reduce parameters and operations with reasonable accuracy loss. However, existing approaches select ranks locally and often ignore global trade-offs between compression and accuracy. We introduce CompressNAS, a MicroNAS-inspired framework that treats rank selection as a global search problem. CompressNAS employs a fast accuracy estimator to evaluate candidate decompositions, enabling efficient yet exhaustive rank exploration under memory and accuracy constraints. In ImageNet, CompressNAS compresses ResNet-18 by 8x with less than 4% accuracy drop; on COCO, we achieve 2x compression of YOLOv5s without any accuracy drop and 2x compression of YOLOv5n with a 2.5% drop. Finally, we present a new family of compressed models, STResNet, with competitive performance compared to other efficient models.

</details>


### [15] [AdaptFly: Prompt-Guided Adaptation of Foundation Models for Low-Altitude UAV Networks](https://arxiv.org/abs/2511.11720)
*Jiao Chen,Haoyi Wang,Jianhua Tang,Junyi Wang*

Main category: cs.CV

TL;DR: AdaptFly是一种无需权重更新的测试时适应框架，通过轻量级提示检索和梯度-free优化，提升低空无人机网络的语义分割性能。


<details>
  <summary>Details</summary>
Motivation: 低空无人机网络的语义分割模型在天气、光照和视角变化下性能迅速下降。资源有限的无人机无法运行基于梯度的测试时适应，而资源充足的无人机独立适应，浪费了共享经验。

Method: AdaptFly采用两种互补的适应模式：对于资源有限的无人机，使用轻量级令牌提示检索；对于资源充足的无人机，采用梯度-free稀疏视觉提示优化（CMA-ES）。通过激活统计检测器触发适应，跨无人机知识池整合提示知识，实现全队协作。

Result: 在UAVid和VDD基准测试及真实无人机部署中，AdaptFly显著优于静态模型和最先进的TTA基线，提升了分割准确性和鲁棒性。

Conclusion: AdaptFly提出了一种无需权重更新的测试时适应框架，显著提升了低空无人机网络中的语义分割准确性和鲁棒性，为新兴低空经济中的弹性、通信高效感知提供了实用路径。

Abstract: Low-altitude Unmanned Aerial Vehicle (UAV) networks rely on robust semantic segmentation as a foundational enabler for distributed sensing-communication-control co-design across heterogeneous agents within the network. However, segmentation foundation models deteriorate quickly under weather, lighting, and viewpoint drift. Resource-limited UAVs cannot run gradient-based test-time adaptation, while resource-massive UAVs adapt independently, wasting shared experience. To address these challenges, we propose AdaptFly, a prompt-guided test-time adaptation framework that adjusts segmentation models without weight updates. AdaptFly features two complementary adaptation modes. For resource-limited UAVs, it employs lightweight token-prompt retrieval from a shared global memory. For resource-massive UAVs, it uses gradient-free sparse visual prompt optimization via Covariance Matrix Adaptation Evolution Strategy. An activation-statistic detector triggers adaptation, while cross-UAV knowledge pool consolidates prompt knowledge and enables fleet-wide collaboration with negligible bandwidth overhead. Extensive experiments on UAVid and VDD benchmarks, along with real-world UAV deployments under diverse weather conditions, demonstrate that AdaptFly significantly improves segmentation accuracy and robustness over static models and state-of-the-art TTA baselines. The results highlight a practical path to resilient, communication-efficient perception in the emerging low-altitude economy.

</details>


### [16] [Do Blind Spots Matter for Word-Referent Mapping? A Computational Study with Infant Egocentric Video](https://arxiv.org/abs/2511.11725)
*Zekai Shi,Zhixi Cai,Kalin Stefanov*

Main category: cs.CV

TL;DR: 提出一种模仿人眼盲点的自监督掩蔽策略，用于学习视觉表征和词语指代映射，效果媲美随机掩蔽。


<details>
  <summary>Details</summary>
Motivation: 儿童在学习第一词汇时，如何从无先验知识的情况下将语音与视觉指代关联是一个复杂问题。标准随机掩蔽策略缺乏生物学合理性。

Method: 采用基于自编码器的视觉骨干网络，结合人眼盲点的知识定义新的掩蔽策略，模仿人脑填补视野空缺的方式。然后使用对比学习模型处理视频-文本数据。

Result: 提出的生物合理掩蔽策略在跨情境和时间扩展的词语指代映射学习中，效果至少与随机掩蔽相当。

Conclusion: 论文提出了一种基于生物合理掩蔽策略的自监督学习方法，用于学习视觉表征和词语指代映射，效果至少与随机掩蔽相当。

Abstract: Typically, children start to learn their first words between 6 and 9 months, linking spoken utterances to their visual referents. Without prior knowledge, a word encountered for the first time can be interpreted in countless ways; it might refer to any of the objects in the environment, their components, or attributes. Using longitudinal, egocentric, and ecologically valid data from the experience of one child, in this work, we propose a self-supervised and biologically plausible strategy to learn strong visual representations. Our masked autoencoder-based visual backbone incorporates knowledge about the blind spot in human eyes to define a novel masking strategy. This mask and reconstruct approach attempts to mimic the way the human brain fills the gaps in the eyes' field of view. This represents a significant shift from standard random masking strategies, which are difficult to justify from a biological perspective. The pretrained encoder is utilized in a contrastive learning-based video-text model capable of acquiring word-referent mappings. Extensive evaluation suggests that the proposed biologically plausible masking strategy is at least as effective as random masking for learning word-referent mappings from cross-situational and temporally extended episodes.

</details>


### [17] [GROVER: Graph-guided Representation of Omics and Vision with Expert Regulation for Adaptive Spatial Multi-omics Fusion](https://arxiv.org/abs/2511.11730)
*Yongjun Xiao,Dian Meng,Xinlei Huang,Yanran Liu,Shiwei Ruan,Ziyue Qiao,Xubin Zheng*

Main category: cs.CV

TL;DR: GROVER是一种自适应空间多组学融合框架，通过图卷积网络和动态专家路由解决异质性和分辨率问题，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 空间转录组学、蛋白质组学和表观组学缺乏病理形态学背景，整合这些组学与组织病理学图像对全面分析疾病组织至关重要，但异质性和分辨率不匹配带来了挑战。

Method: GROVER采用基于Kolmogorov-Arnold网络的图卷积编码器捕获模态间的非线性依赖关系，并通过点特征对对比学习策略和动态专家路由机制实现模态对齐与噪声抑制。

Result: 在真实空间组学数据集上的实验表明，GROVER优于现有基线方法，实现了稳健的多模态整合。

Conclusion: GROVER框架通过创新的图卷积网络和动态专家路由机制，成功解决了空间多组学数据整合中的异质性和分辨率不匹配问题，为疾病组织分析提供了可靠的多模态整合方案。

Abstract: Effectively modeling multimodal spatial omics data is critical for understanding tissue complexity and underlying biological mechanisms. While spatial transcriptomics, proteomics, and epigenomics capture molecular features, they lack pathological morphological context. Integrating these omics with histopathological images is therefore essential for comprehensive disease tissue analysis. However, substantial heterogeneity across omics, imaging, and spatial modalities poses significant challenges. Naive fusion of semantically distinct sources often leads to ambiguous representations. Additionally, the resolution mismatch between high-resolution histology images and lower-resolution sequencing spots complicates spatial alignment. Biological perturbations during sample preparation further distort modality-specific signals, hindering accurate integration. To address these challenges, we propose Graph-guided Representation of Omics and Vision with Expert Regulation for Adaptive Spatial Multi-omics Fusion (GROVER), a novel framework for adaptive integration of spatial multi-omics data. GROVER leverages a Graph Convolutional Network encoder based on Kolmogorov-Arnold Networks to capture the nonlinear dependencies between each modality and its associated spatial structure, thereby producing expressive, modality-specific embeddings. To align these representations, we introduce a spot-feature-pair contrastive learning strategy that explicitly optimizes the correspondence across modalities at each spot. Furthermore, we design a dynamic expert routing mechanism that adaptively selects informative modalities for each spot while suppressing noisy or low-quality inputs. Experiments on real-world spatial omics datasets demonstrate that GROVER outperforms state-of-the-art baselines, providing a robust and reliable solution for multimodal integration.

</details>


### [18] [Exposing DeepFakes via Hyperspectral Domain Mapping](https://arxiv.org/abs/2511.11732)
*Aditya Mehta,Swarnim Chaudhary,Pratik Narang,Jagat Sesh Challa*

Main category: cs.CV

TL;DR: HSI-Detect通过高光谱图像重构增强Deepfake检测，性能优于传统RGB方法。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法仅分析RGB的三个光谱通道，可能忽略高光谱域中的操纵痕迹。

Method: 提出HSI-Detect两阶段流程：首先从标准RGB输入重构31通道高光谱图像，然后在光谱域进行检测。

Result: 在FaceForensics++数据集上的实验表明，HSI-Detect相比仅使用RGB的基线方法有持续改进。

Conclusion: HSI-Detect通过将RGB图像扩展到31通道的高光谱图像，显著提升了Deepfake检测的准确性，展示了光谱域映射在此类任务中的潜力。

Abstract: Modern generative and diffusion models produce highly realistic images that can mislead human perception and even sophisticated automated detection systems. Most detection methods operate in RGB space and thus analyze only three spectral channels. We propose HSI-Detect, a two-stage pipeline that reconstructs a 31-channel hyperspectral image from a standard RGB input and performs detection in the hyperspectral domain. Expanding the input representation into denser spectral bands amplifies manipulation artifacts that are often weak or invisible in the RGB domain, particularly in specific frequency bands. We evaluate HSI-Detect across FaceForensics++ dataset and show the consistent improvements over RGB-only baselines, illustrating the promise of spectral-domain mapping for Deepfake detection.

</details>


### [19] [Toward bilipshiz geometric models](https://arxiv.org/abs/2511.11735)
*Yonatan Sverdlov,Eitan Rosen,Nadav Dym*

Main category: cs.CV

TL;DR: 本文探究了点云网络与自然对称性感知距离的双Lipschitz等价性，提出改进方法并在实验中验证其优势。


<details>
  <summary>Details</summary>
Motivation: 基于等变学习文献中双Lipschitz模型在其他场景的优势，本文旨在探究点云网络是否能保持点云空间上的自然对称性感知距离。

Method: 我们考察了点云空间上两种自然对称性感知度量——Procrustes匹配(PM)度量和Hard Gromov Wasserstein距离，证明它们之间并非双Lipschitz等价，并推论出流行的点云不变网络在PM度量下也不具备双Lipschitz性质。随后，我们展示了如何修改这些网络以获得双Lipschitz保证。

Result: 实验结果表明，提出的双Lipschitz模型在3D点云对应任务中优于标准不变模型。

Conclusion: 通过修改现有网络，我们实现了与PM度量的双Lipschitz等价性，并在3D点云对应任务中展示了其优于标准不变模型的优势。

Abstract: Many neural networks for point clouds are, by design, invariant to the symmetries of this datatype: permutations and rigid motions. The purpose of this paper is to examine whether such networks preserve natural symmetry aware distances on the point cloud spaces, through the notion of bi-Lipschitz equivalence. This inquiry is motivated by recent work in the Equivariant learning literature which highlights the advantages of bi-Lipschitz models in other scenarios.
  We consider two symmetry aware metrics on point clouds: (a) The Procrustes Matching (PM) metric and (b) Hard Gromov Wasserstien distances. We show that these two distances themselves are not bi-Lipschitz equivalent, and as a corollary deduce that popular invariant networks for point clouds are not bi-Lipschitz with respect to the PM metric. We then show how these networks can be modified so that they do obtain bi-Lipschitz guarantees. Finally, we provide initial experiments showing the advantage of the proposed bi-Lipschitz model over standard invariant models, for the tasks of finding correspondences between 3D point clouds.

</details>


### [20] [Concept-RuleNet: Grounded Multi-Agent Neurosymbolic Reasoning in Vision Language Models](https://arxiv.org/abs/2511.11751)
*Sanchit Sinha,Guangzhi Xiong,Zhenghao He,Aidong Zhang*

Main category: cs.CV

TL;DR: Concept-RuleNet通过视觉基础与透明推理的结合，提升了神经符号模型的性能并减少幻觉现象。


<details>
  <summary>Details</summary>
Motivation: 解决现代视觉语言模型在决策解释性上的不足，特别是在处理分布外数据时容易产生幻觉的问题。

Method: 采用多模态概念生成器从训练图像中挖掘视觉概念，并利用大语言模型推理器将符号组合成一阶规则，最后通过视觉验证器量化符号存在度并触发规则执行。

Result: 在五个基准测试中，平均提升神经符号基线性能5%，并将规则中幻觉符号的出现减少高达50%。

Conclusion: Concept-RuleNet通过多智能体系统结合视觉基础与透明推理，显著提升了神经符号基线的性能，并减少了规则中幻觉符号的出现。

Abstract: Modern vision-language models (VLMs) deliver impressive predictive accuracy yet offer little insight into 'why' a decision is reached, frequently hallucinating facts, particularly when encountering out-of-distribution data. Neurosymbolic frameworks address this by pairing black-box perception with interpretable symbolic reasoning, but current methods extract their symbols solely from task labels, leaving them weakly grounded in the underlying visual data. In this paper, we introduce a multi-agent system - Concept-RuleNet that reinstates visual grounding while retaining transparent reasoning. Specifically, a multimodal concept generator first mines discriminative visual concepts directly from a representative subset of training images. Next, these visual concepts are utilized to condition symbol discovery, anchoring the generations in real image statistics and mitigating label bias. Subsequently, symbols are composed into executable first-order rules by a large language model reasoner agent - yielding interpretable neurosymbolic rules. Finally, during inference, a vision verifier agent quantifies the degree of presence of each symbol and triggers rule execution in tandem with outputs of black-box neural models, predictions with explicit reasoning pathways. Experiments on five benchmarks, including two challenging medical-imaging tasks and three underrepresented natural-image datasets, show that our system augments state-of-the-art neurosymbolic baselines by an average of 5% while also reducing the occurrence of hallucinated symbols in rules by up to 50%.

</details>


### [21] [Batch Transformer Architecture: Case of Synthetic Image Generation for Emotion Expression Facial Recognition](https://arxiv.org/abs/2511.11754)
*Stanislav Selitskiy*

Main category: cs.CV

TL;DR: Batch Transformers通过关注主成分优化注意力机制，减少ANN瓶颈，提升合成图像生成效率。


<details>
  <summary>Details</summary>
Motivation: 传统Transformer对整个维度的注意力机制效率不高，Batch Transformers旨在通过关注重要维度来优化性能。

Method: 提出了一种隐式稀疏风格的Transformer变体架构，即Batch Transformers，专注于重要维度（主成分）的注意力机制。

Result: 在合成图像生成任务中，Batch Transformers在化妆和遮挡数据集上提高了原始数据集的变异性。

Conclusion: Batch Transformers通过关注主要维度（主成分）而非整个维度，显著减少了编码器-解码器ANN架构中的瓶颈大小，提高了合成图像生成的效率。

Abstract: A novel Transformer variation architecture is proposed in the implicit sparse style. Unlike "traditional" Transformers, instead of attention to sequential or batch entities in their entirety of whole dimensionality, in the proposed Batch Transformers, attention to the "important" dimensions (primary components) is implemented. In such a way, the "important" dimensions or feature selection allows for a significant reduction of the bottleneck size in the encoder-decoder ANN architectures. The proposed architecture is tested on the synthetic image generation for the face recognition task in the case of the makeup and occlusion data set, allowing for increased variability of the limited original data set.

</details>


### [22] [Image-POSER: Reflective RL for Multi-Expert Image Generation and Editing](https://arxiv.org/abs/2511.11780)
*Hossein Mohebbi,Mohammed Abdulrahman,Yanting Miao,Pascal Poupart,Suraj Kothawade*

Main category: cs.CV

TL;DR: Image-POSER利用强化学习框架动态组合预训练专家模型，显著提升长提示下的图像生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像生成系统难以可靠地执行长且组合的提示，而这是创意工作流程的典型需求。

Method: 引入Image-POSER，一个基于反射强化学习的框架，通过动态任务分解处理长格式提示，并通过视觉语言模型批评者的结构化反馈监督每一步的对齐。

Result: Image-POSER在行业标准和自定义基准测试中，在对齐度、保真度和美学方面均优于基线（包括前沿模型），并在人类评估中持续受到青睐。

Conclusion: 强化学习能够赋予AI系统自主分解、重组和结合视觉模型的能力，向通用视觉助手迈进。

Abstract: Recent advances in text-to-image generation have produced strong single-shot models, yet no individual system reliably executes the long, compositional prompts typical of creative workflows. We introduce Image-POSER, a reflective reinforcement learning framework that (i) orchestrates a diverse registry of pretrained text-to-image and image-to-image experts, (ii) handles long-form prompts end-to-end through dynamic task decomposition, and (iii) supervises alignment at each step via structured feedback from a vision-language model critic. By casting image synthesis and editing as a Markov Decision Process, we learn non-trivial expert pipelines that adaptively combine strengths across models. Experiments show that Image-POSER outperforms baselines, including frontier models, across industry-standard and custom benchmarks in alignment, fidelity, and aesthetics, and is consistently preferred in human evaluations. These results highlight that reinforcement learning can endow AI systems with the capacity to autonomously decompose, reorder, and combine visual models, moving towards general-purpose visual assistants.

</details>


### [23] [SOTFormer: A Minimal Transformer for Unified Object Tracking and Trajectory Prediction](https://arxiv.org/abs/2511.11824)
*Zhongping Dong,Pengyang Yu,Shuangjian Li,Liming Chen,Mohand Tahar Kechadi*

Main category: cs.CV

TL;DR: SOTFormer是一种新型的轻量级时间Transformer，统一了目标检测、跟踪和短期轨迹预测，在复杂条件下表现优异且高效。


<details>
  <summary>Details</summary>
Motivation: 解决在遮挡、尺度变化和时间漂移等复杂条件下，单目标跟踪和短期运动预测的准确性和实时性问题。

Method: SOTFormer采用了一种最小化恒定内存的时间Transformer，结合了目标检测、跟踪和短期轨迹预测，通过真实值初始化的记忆和锚点损失稳定初始化，并利用轻量级时间注意力层跨帧优化嵌入。

Result: 在Mini-LaSOT（20%）基准测试中，SOTFormer实现了76.3 AUC和53.7 FPS（AMP，4.3 GB VRAM），在快速运动、尺度变化和遮挡条件下优于TrackFormer和MOTRv2等Transformer基线模型。

Conclusion: SOTFormer在单目标跟踪和短期运动预测中表现出色，尤其在遮挡、尺度变化和时间漂移等挑战下仍能保持高精度和实时性。

Abstract: Accurate single-object tracking and short-term motion forecasting remain challenging under occlusion, scale variation, and temporal drift, which disrupt the temporal coherence required for real-time perception. We introduce \textbf{SOTFormer}, a minimal constant-memory temporal transformer that unifies object detection, tracking, and short-horizon trajectory prediction within a single end-to-end framework. Unlike prior models with recurrent or stacked temporal encoders, SOTFormer achieves stable identity propagation through a ground-truth-primed memory and a burn-in anchor loss that explicitly stabilizes initialization. A single lightweight temporal-attention layer refines embeddings across frames, enabling real-time inference with fixed GPU memory. On the Mini-LaSOT (20%) benchmark, SOTFormer attains 76.3 AUC and 53.7 FPS (AMP, 4.3 GB VRAM), outperforming transformer baselines such as TrackFormer and MOTRv2 under fast motion, scale change, and occlusion.

</details>


### [24] [MP-GFormer: A 3D-Geometry-Aware Dynamic Graph Transformer Approach for Machining Process Planning](https://arxiv.org/abs/2511.11837)
*Fatemeh Elhambakhsh,Gaurav Ameta,Aditi Roy,Hyunwoong Ko*

Main category: cs.CV

TL;DR: MP-GFormer是一种整合3D几何信息的动态图Transformer，显著提升了加工操作序列预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有动态图学习方法在加工过程规划中未能整合3D几何信息，导致缺乏领域感知能力。

Method: 提出MP-GFormer，一种3D几何感知的动态图Transformer，通过注意力机制将演化的3D几何表示整合到动态图学习中。

Result: 在合成数据集上评估，MP-GFormer在主操作和子操作预测上的准确率分别提高了24%和36%。

Conclusion: MP-GFormer通过整合3D几何信息到动态图学习中，显著提高了加工操作序列预测的准确性，相比现有方法在主操作和子操作预测上分别提升了24%和36%。

Abstract: Machining process planning (MP) is inherently complex due to structural and geometrical dependencies among part features and machining operations. A key challenge lies in capturing dynamic interdependencies that evolve with distinct part geometries as operations are performed. Machine learning has been applied to address challenges in MP, such as operation selection and machining sequence prediction. Dynamic graph learning (DGL) has been widely used to model dynamic systems, thanks to its ability to integrate spatio-temporal relationships. However, in MP, while existing DGL approaches can capture these dependencies, they fail to incorporate three-dimensional (3D) geometric information of parts and thus lack domain awareness in predicting machining operation sequences. To address this limitation, we propose MP-GFormer, a 3D-geometry-aware dynamic graph transformer that integrates evolving 3D geometric representations into DGL through an attention mechanism to predict machining operation sequences. Our approach leverages StereoLithography surface meshes representing the 3D geometry of a part after each machining operation, with the boundary representation method used for the initial 3D designs. We evaluate MP-GFormer on a synthesized dataset and demonstrate that the method achieves improvements of 24\% and 36\% in accuracy for main and sub-operation predictions, respectively, compared to state-of-the-art approaches.

</details>


### [25] [Defending Unauthorized Model Merging via Dual-Stage Weight Protection](https://arxiv.org/abs/2511.11851)
*Wei-Jia Chen,Min-Yen Tsai,Cheng-Yi Lee,Chia-Mu Yu*

Main category: cs.CV

TL;DR: MergeGuard是一种双阶段权重保护框架，防止未经授权的模型合并，同时保证原始模型性能不受影响。


<details>
  <summary>Details</summary>
Motivation: 解决预训练模型未经授权合并带来的知识产权和问责问题。

Method: 采用L2正则化优化重新分配任务相关信息，并通过结构化扰动破坏任务子空间的对齐。

Result: 实验显示MergeGuard能将合并模型准确率降低达90%，而受保护模型性能损失低于1.5%。

Conclusion: MergeGuard有效防止了未经授权的模型合并，通过双重保护机制在保持原始模型性能的同时，显著降低了合并模型的准确性。

Abstract: The rapid proliferation of pretrained models and open repositories has made model merging a convenient yet risky practice, allowing free-riders to combine fine-tuned models into a new multi-capability model without authorization. Such unauthorized model merging not only violates intellectual property rights but also undermines model ownership and accountability. To address this issue, we present MergeGuard, a proactive dual-stage weight protection framework that disrupts merging compatibility while maintaining task fidelity. In the first stage, we redistribute task-relevant information across layers via L2-regularized optimization, ensuring that important gradients are evenly dispersed. In the second stage, we inject structured perturbations to misalign task subspaces, breaking curvature compatibility in the loss landscape. Together, these stages reshape the model's parameter geometry such that merged models collapse into destructive interference while the protected model remains fully functional. Extensive experiments on both vision (ViT-L-14) and language (Llama2, Gemma2, Mistral) models demonstrate that MergeGuard reduces merged model accuracy by up to 90% with less than 1.5% performance loss on the protected model.

</details>


### [26] [FocusSDF: Boundary-Aware Learning for Medical Image Segmentation via Signed Distance Supervision](https://arxiv.org/abs/2511.11864)
*Muzammal Shafique,Nasir Rahim,Jamil Ahmad,Mohammad Siadat,Khalid Malik,Ghaus Malik*

Main category: cs.CV

TL;DR: 提出FocusSDF损失函数，通过SDFs自适应增强边界关注，实验证明其在多种医学图像分割任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割是医学图像分析的核心，但现有分割模型大多未显式编码边界信息，导致边界保留成为持续挑战。为解决这一问题，需要一种能有效关注边界区域的解决方案。

Method: 提出了FocusSDF损失函数，基于有符号距离函数（SDFs），自适应调整边界像素权重，增强网络对边界的关注。在五种最先进的医学图像分割模型（包括基础模型MedSAM）上进行了广泛评估，使用了四种基于距离的损失函数，覆盖了多种成像模态下的脑动脉瘤、中风、肝脏和乳腺肿瘤分割任务。

Result: 实验结果表明，FocusSDF在多种任务和数据集上均优于现有基于距离变换的损失函数，展现出其在边界保留方面的优越性能。

Conclusion: FocusSDF作为一种基于有符号距离函数（SDFs）的新型损失函数，通过自适应地为靠近病灶或器官边界的像素分配更高权重，有效提升了医学图像分割中边界区域的关注度，实验证明其在多种任务和数据集上优于现有基于距离变换的损失函数。

Abstract: Segmentation of medical images constitutes an essential component of medical image analysis, providing the foundation for precise diagnosis and efficient therapeutic interventions in clinical practices. Despite substantial progress, most segmentation models do not explicitly encode boundary information; as a result, making boundary preservation a persistent challenge in medical image segmentation. To address this challenge, we introduce FocusSDF, a novel loss function based on the signed distance functions (SDFs), which redirects the network to concentrate on boundary regions by adaptively assigning higher weights to pixels closer to the lesion or organ boundary, effectively making it boundary aware. To rigorously validate FocusSDF, we perform extensive evaluations against five state-of-the-art medical image segmentation models, including the foundation model MedSAM, using four distance-based loss functions across diverse datasets covering cerebral aneurysm, stroke, liver, and breast tumor segmentation tasks spanning multiple imaging modalities. The experimental results consistently demonstrate the superior performance of FocusSDF over existing distance transform based loss functions.

</details>


### [27] [Lacking Data? No worries! How synthetic images can alleviate image scarcity in wildlife surveys: a case study with muskox (Ovibos moschatus)](https://arxiv.org/abs/2511.11882)
*Simon Durand,Samuel Foucher,Alexandre Delplanque,Joëlle Taillon,Jérôme Théau*

Main category: cs.CV

TL;DR: 合成图像可补充稀缺训练数据，提升麝牛检测性能，尤其在零样本和少样本场景中。


<details>
  <summary>Details</summary>
Motivation: 传统调查方法资源密集且受限于后勤挑战，而深度学习目标检测模型（ODMs）因小数据集效果受限，尤其对于稀疏分布的物种（如麝牛）。

Method: 比较了基线模型（仅使用真实图像训练）与5个零样本（ZS）和5个少样本（FS）模型（逐步增加SI在训练集中的比例）。

Result: 对于ZS模型，添加SI提高了检测性能；对于FS模型，结合真实图像和SI提高了召回率和整体准确性（但统计不显著）。

Conclusion: 合成图像（SI）可以在数据稀缺时帮助训练准确的目标检测模型（ODMs），为野生动物监测提供重要视角，尤其适用于稀有或难以接近的物种，并提高监测频率。

Abstract: Accurate population estimates are essential for wildlife management, providing critical insights into species abundance and distribution. Traditional survey methods, including visual aerial counts and GNSS telemetry tracking, are widely used to monitor muskox populations in Arctic regions. These approaches are resource intensive and constrained by logistical challenges. Advances in remote sensing, artificial intelligence, and high resolution aerial imagery offer promising alternatives for wildlife detection. Yet, the effectiveness of deep learning object detection models (ODMs) is often limited by small datasets, making it challenging to train robust ODMs for sparsely distributed species like muskoxen. This study investigates the integration of synthetic imagery (SI) to supplement limited training data and improve muskox detection in zero shot (ZS) and few-shot (FS) settings. We compared a baseline model trained on real imagery with 5 ZS and 5 FS models that incorporated progressively more SI in the training set. For the ZS models, where no real images were included in the training set, adding SI improved detection performance. As more SI were added, performance in precision, recall and F1 score increased, but eventually plateaued, suggesting diminishing returns when SI exceeded 100% of the baseline model training dataset. For FS models, combining real and SI led to better recall and slightly higher overall accuracy compared to using real images alone, though these improvements were not statistically significant. Our findings demonstrate the potential of SI to train accurate ODMs when data is scarce, offering important perspectives for wildlife monitoring by enabling rare or inaccessible species to be monitored and to increase monitoring frequency. This approach could be used to initiate ODMs without real data and refine it as real images are acquired over time.

</details>


### [28] [Advancing Annotat3D with Harpia: A CUDA-Accelerated Library For Large-Scale Volumetric Data Segmentation](https://arxiv.org/abs/2511.11890)
*Camila Machado de Araujo,Egon P. B. S. Borges,Ricardo Marcelo Canteiro Grangeiro,Allan Pinto*

Main category: cs.CV

TL;DR: Harpia是一个基于CUDA的库，专为高效处理大规模3D数据集设计，显著提升了处理速度和内存效率，适用于高性能计算环境。


<details>
  <summary>Details</summary>
Motivation: 高分辨率体积成像技术生成的数据集越来越大，现有工具在高效处理、分割和交互式探索方面面临挑战。

Method: 通过开发基于CUDA的Harpia处理库，实现了严格的內存控制、本地分块执行以及GPU加速的过滤、注释和量化工具，支持超过单GPU内存容量的数据集。

Result: 实验结果表明，与NVIDIA cuCIM和scikit-image等广泛使用的框架相比，Harpia在处理速度、内存效率和可扩展性方面有显著提升。

Conclusion: 该论文介绍了Harpia库在高效处理大规模3D数据集方面的优势，尤其是在高分辨率体积成像技术中的应用，展示了其在内存效率、处理速度和可扩展性上的显著改进。

Abstract: High-resolution volumetric imaging techniques, such as X-ray tomography and advanced microscopy, generate increasingly large datasets that challenge existing tools for efficient processing, segmentation, and interactive exploration. This work introduces new capabilities to Annotat3D through Harpia, a new CUDA-based processing library designed to support scalable, interactive segmentation workflows for large 3D datasets in high-performance computing (HPC) and remote-access environments. Harpia features strict memory control, native chunked execution, and a suite of GPU-accelerated filtering, annotation, and quantification tools, enabling reliable operation on datasets exceeding single-GPU memory capacity. Experimental results demonstrate significant improvements in processing speed, memory efficiency, and scalability compared to widely used frameworks such as NVIDIA cuCIM and scikit-image. The system's interactive, human-in-the-loop interface, combined with efficient GPU resource management, makes it particularly suitable for collaborative scientific imaging workflows in shared HPC infrastructures.

</details>


### [29] [Prompt Triage: Structured Optimization Enhances Vision-Language Model Performance on Medical Imaging Benchmarks](https://arxiv.org/abs/2511.11898)
*Arnav Singhvi,Vasiliki Bikia,Asad Aali,Akshay Chaudhari,Roxana Daneshjou*

Main category: cs.CV

TL;DR: 通过自动提示优化技术，医学VLMs性能显著提升，减少了对人工提示设计的依赖，适用于临床图像解释任务。


<details>
  <summary>Details</summary>
Motivation: 现有VLMs在医学任务中表现不佳，而传统方法（如微调或手动提示工程）存在数据集需求大、难以泛化或不可扩展的问题，因此探索无需人工设计提示的自动化方法。

Method: 采用DSPy框架进行结构化自动提示优化，并在五个医学成像任务中实施提示管道，评估了10个开源VLMs和四种提示优化技术。

Result: 优化后的管道在零样本提示基准上实现了中位数53%的相对提升，在零样本性能较低的任务中提升幅度高达300%至3,400%。

Conclusion: 通过自动提示优化技术，显著提升了医学视觉语言系统在临床图像解释任务中的性能，同时减少了对手动提示设计的依赖，使临床医生能更专注于患者护理和决策。

Abstract: Vision-language foundation models (VLMs) show promise for diverse imaging tasks but often underperform on medical benchmarks. Prior efforts to improve performance include model finetuning, which requires large domain-specific datasets and significant compute, or manual prompt engineering, which is hard to generalize and often inaccessible to medical institutions seeking to deploy these tools. These challenges motivate interest in approaches that draw on a model's embedded knowledge while abstracting away dependence on human-designed prompts to enable scalable, weight-agnostic performance improvements. To explore this, we adapt the Declarative Self-improving Python (DSPy) framework for structured automated prompt optimization in medical vision-language systems through a comprehensive, formal evaluation. We implement prompting pipelines for five medical imaging tasks across radiology, gastroenterology, and dermatology, evaluating 10 open-source VLMs with four prompt optimization techniques. Optimized pipelines achieved a median relative improvement of 53% over zero-shot prompting baselines, with the largest gains ranging from 300% to 3,400% on tasks where zero-shot performance is low. These results highlight the substantial potential of applying automated prompt optimization to medical AI systems, demonstrating significant gains for vision-based applications requiring accurate clinical image interpretation. By reducing dependence on prompt design to elicit intended outputs, these techniques allow clinicians to focus on patient care and clinical decision-making. Furthermore, our experiments offer scalability and preserve data privacy, demonstrating performance improvement on open-source VLMs. We publicly release our evaluation pipelines to support reproducible research on specialized medical tasks, available at https://github.com/DaneshjouLab/prompt-triage-lab.

</details>


### [30] [PI-NAIM: Path-Integrated Neural Adaptive Imputation Model](https://arxiv.org/abs/2511.11908)
*Afifa Khaled,Ebrahim Hamid Sumiea*

Main category: cs.CV

TL;DR: PI-NAIM是一种创新的双路径架构，通过动态路由和跨路径注意力融合，高效解决医学影像中缺失模态问题，显著提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 医学影像和多模态临床设置中经常面临缺失模态的挑战，现有插补方法要么缺乏表示能力，要么计算成本高。

Method: PI-NAIM框架整合了：(1)智能路径路由，将低缺失样本导向高效统计插补（MICE），复杂模式导向强大的神经网络（GAIN与时间分析）；(2)跨路径注意力融合，利用缺失感知嵌入智能结合两个分支；(3)端到端联合优化插补准确性和下游任务性能。

Result: 在MIMIC-III和多模态基准测试上的广泛实验表明，PI-NAIM实现了最先进的性能，RMSE为0.108（基线为0.119-0.152），并在下游任务中取得了显著提升，死亡率预测的AUROC为0.812。

Conclusion: PI-NAIM提出了一种创新的双路径架构，通过动态路由样本到优化的插补方法，解决了医学影像和多模态临床设置中缺失模态的挑战。其模块化设计使其能够无缝集成到处理不完整传感器测量、缺失模态或损坏输入的视觉管道中，为现实场景提供了统一的解决方案。

Abstract: Medical imaging and multi-modal clinical settings often face the challange of missing modality in their diagnostic pipelines. Existing imputation methods either lack representational capacity or are computationally expensive. We propose PI-NAIM, a novel dual-path architecture that dynamically routes samples to optimized imputation approaches based on missingness complexity. Our framework integrates: (1) intelligent path routing that directs low missingness samples to efficient statistical imputation (MICE) and complex patterns to powerful neural networks (GAIN with temporal analysis); (2) cross-path attention fusion that leverages missingness-aware embeddings to intelligently combine both branches; and (3) end-to-end joint optimization of imputation accuracy and downstream task performance. Extensive experiments on MIMIC-III and multimodal benchmarks demonstrate state-of-the-art performance, achieving RMSE of 0.108 (vs. baselines' 0.119-0.152) and substantial gains in downstream tasks with an AUROC of 0.812 for mortality prediction. PI-NAIM's modular design enables seamless integration into vision pipelines handling incomplete sensor measurements, missing modalities, or corrupted inputs, providing a unified solution for real-world scenario. The code is publicly available at https://github.com/AfifaKhaled/PI-NAIM-Path-Integrated-Neural-Adaptive-Imputation-Model

</details>


### [31] [Seeing the Forest and the Trees: Query-Aware Tokenizer for Long-Video Multimodal Language Models](https://arxiv.org/abs/2511.11910)
*Siyou Li,Huanan Wu,Juexi Shao,Yinghao Ma,Yujian Gan,Yihao Luo,Yuwei Wang,Dong Nie,Lu Wang,Wengqing Wu,Le Zhang,Massimo Poesio,Juntao Yu*

Main category: cs.CV

TL;DR: QTSplus是一个动态选择视觉令牌的模块，显著降低了长视频处理的成本，同时保持了高性能。


<details>
  <summary>Details</summary>
Motivation: 长视频理解是当前多模态大型语言模型的挑战之一，主要问题在于视觉令牌数量随视频长度线性增长，导致注意力成本、内存和延迟爆炸式增加。

Method: QTSplus是一个轻量级但功能强大的视觉令牌选择模块，通过跨注意力评分、预测实例特定的保留预算以及选择Top-$n令牌来实现动态选择最重要的视觉证据。

Result: QTSplus将视觉流压缩高达89%，端到端延迟减少28%，在八个长视频理解基准测试中表现出接近原模型准确度的性能，并在TempCompass方向和顺序准确度上分别比原模型高出20.5和5.6个百分点。

Conclusion: QTSplus是一种有效且通用的机制，能够将多模态大型语言模型（MLLMs）扩展到现实世界的长视频场景，同时保留任务相关的视觉证据。

Abstract: Despite the recent advances in the video understanding ability of multimodal large language models (MLLMs), long video understanding remains a challenge. One of the main issues is that the number of vision tokens grows linearly with video length, which causes an explosion in attention cost, memory, and latency. To solve this challenge, we present Query-aware Token Selector (\textbf{QTSplus}), a lightweight yet powerful visual token selection module that serves as an information gate between the vision encoder and LLMs. Given a text query and video tokens, QTSplus dynamically selects the most important visual evidence for the input text query by (i) scoring visual tokens via cross-attention, (ii) \emph{predicting} an instance-specific retention budget based on the complexity of the query, and (iii) \emph{selecting} Top-$n$ tokens with a differentiable straight-through estimator during training and a hard gate at inference. Furthermore, a small re-encoder preserves temporal order using absolute time information, enabling second-level localization while maintaining global coverage.
  Integrated into Qwen2.5-VL, QTSplus compresses the vision stream by up to \textbf{89\%} and reduces end-to-end latency by \textbf{28\%} on long videos. The evaluation on eight long video understanding benchmarks shows near-parity accuracy overall when compared with the original Qwen models and outperforms the original model by \textbf{+20.5} and \textbf{+5.6} points respectively on TempCompass direction and order accuracies. These results show that QTSplus is an effective, general mechanism for scaling MLLMs to real-world long-video scenarios while preserving task-relevant evidence.
  We will make all code, data, and trained models' weights publicly available.

</details>


### [32] [From Events to Clarity: The Event-Guided Diffusion Framework for Dehazing](https://arxiv.org/abs/2511.11944)
*Ling Wang,Yunfan Lu,Wenzong Ma,Huizai Yao,Pengteng Li,Hui Xiong*

Main category: cs.CV

TL;DR: 首次使用事件相机结合扩散模型进行去雾，通过HDR特征映射提升细节保留，实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 传统RGB帧因动态范围有限，去雾任务仍存在结构丢失和光照细节模糊的问题。事件相机因其高动态范围和低延迟特性，更适合处理雾霾场景。

Method: 提出了一种事件引导的扩散模型，通过将事件相机的高动态范围（HDR）特征映射到扩散潜在空间，为生成过程提供精确的结构引导。

Result: 在两个基准测试及自制数据集上的实验表明，该方法实现了最先进的去雾效果。

Conclusion: 该论文通过首次将事件相机应用于去雾任务，并结合事件引导的扩散模型，有效解决了传统RGB帧动态范围有限导致的结构和光照细节丢失问题，实现了在真实场景中的先进去雾效果。

Abstract: Clear imaging under hazy conditions is a critical task. Prior-based and neural methods have improved results. However, they operate on RGB frames, which suffer from limited dynamic range. Therefore, dehazing remains ill-posed and can erase structure and illumination details. To address this, we use event cameras for dehazing for the \textbf{first time}. Event cameras offer much higher HDR ($120 dBvs.60 dB$) and microsecond latency, therefore they suit hazy scenes. In practice, transferring HDR cues from events to frames is hard because real paired data are scarce. To tackle this, we propose an event-guided diffusion model that utilizes the strong generative priors of diffusion models to reconstruct clear images from hazy inputs by effectively transferring HDR information from events. Specifically, we design an event-guided module that maps sparse HDR event features, \textit{e.g.,} edges, corners, into the diffusion latent space. This clear conditioning provides precise structural guidance during generation, improves visual realism, and reduces semantic drift. For real-world evaluation, we collect a drone dataset in heavy haze (AQI = 341) with synchronized RGB and event sensors. Experiments on two benchmarks and our dataset achieve state-of-the-art results.

</details>


### [33] [Evaluation of Attention Mechanisms in U-Net Architectures for Semantic Segmentation of Brazilian Rock Art Petroglyphs](https://arxiv.org/abs/2511.11959)
*Leonardi Melo,Luís Gustavo,Dimmy Magalhães,Lucciani Vieira,Mauro Araújo*

Main category: cs.CV

TL;DR: 研究比较了三种U-Net架构在岩画分割中的性能，发现结合注意力机制的模型表现最佳，Dice Score提升2.5-2.9%。


<details>
  <summary>Details</summary>
Motivation: 研究旨在比较不同U-Net架构在巴西考古遗址岩画语义分割中的性能，以探索注意力机制对考古遗产数字保存的效果。

Method: 研究比较了三种基于U-Net的架构：1) 使用边界增强高斯损失函数的BEGL-UNet；2) 结合残差块和门控注意力机制的Attention-Residual BEGL-UNet；3) 基于卷积块注意力模块的空间通道注意力BEGL-UNet。所有实现均采用结合二元交叉熵和高斯边缘增强的BEGL损失函数。实验在巴西Piauí的Poço da Bebidinha考古遗址图像上进行，采用5折交叉验证。

Result: Attention-Residual BEGL-UNet表现最佳，Dice Score为0.710，验证损失为0.067，召回率最高为0.854。Spatial Channel Attention BEGL-UNet表现相近，DSC为0.707，召回率为0.857。基线BEGL-UNet的DSC为0.690。

Conclusion: 研究证明了注意力机制在考古遗产数字保存中的有效性，相较于基线模型，Dice Score提升了2.5-2.9%。

Abstract: This study presents a comparative analysis of three U-Net-based architectures for semantic segmentation of rock art petroglyphs from Brazilian archaeological sites. The investigated architectures were: (1) BEGL-UNet with Border-Enhanced Gaussian Loss function; (2) Attention-Residual BEGL-UNet, incorporating residual blocks and gated attention mechanisms; and (3) Spatial Channel Attention BEGL-UNet, which employs spatial-channel attention modules based on Convolutional Block Attention Module. All implementations employed the BEGL loss function combining binary cross-entropy with Gaussian edge enhancement. Experiments were conducted on images from the Poço da Bebidinha Archaeological Complex, Piauí, Brazil, using 5-fold cross-validation. Among the architectures, Attention-Residual BEGL-UNet achieved the best overall performance with Dice Score of 0.710, validation loss of 0.067, and highest recall of 0.854. Spatial Channel Attention BEGL-UNet obtained comparable performance with DSC of 0.707 and recall of 0.857. The baseline BEGL-UNet registered DSC of 0.690. These results demonstrate the effectiveness of attention mechanisms for archaeological heritage digital preservation, with Dice Score improvements of 2.5-2.9% over the baseline.

</details>


### [34] [From Classification to Cross-Modal Understanding: Leveraging Vision-Language Models for Fine-Grained Renal Pathology](https://arxiv.org/abs/2511.11984)
*Zhenhao Guo,Rachit Saluja,Tianyuan Yao,Quan Liu,Junchao Zhu,Haibo Wang,Daniel Reisenbüchler,Yuankai Huo,Benjamin Liechty,David J. Pisapia,Kenji Ikemura,Steven Salvatoree,Surya Seshane,Mert R. Sabuncu,Yihe Yang,Ruining Deng*

Main category: cs.CV

TL;DR: 研究评估了视觉语言模型在少样本细粒度肾小球亚型分类中的表现，发现病理学专用模型在普通微调下效果最佳。


<details>
  <summary>Details</summary>
Motivation: 解决细粒度肾小球亚型分类中临床有价值标签稀缺且难以获取的问题，探索视觉语言模型在数据限制下的适用性。

Method: 将细粒度肾小球亚型分类建模为临床现实的少样本问题，评估病理学专用和通用视觉语言模型在此设定下的表现。

Result: 病理学专用模型在少样本情况下表现优异，判别能力和图像-文本对齐对性能均有重要影响。

Conclusion: 病理学专用的视觉语言模型（VLMs）在普通微调下是最有效的起点，即使每个肾小球亚型仅有4-8个标记样本，也能显著提升判别和校准能力。

Abstract: Fine-grained glomerular subtyping is central to kidney biopsy interpretation, but clinically valuable labels are scarce and difficult to obtain. Existing computational pathology approaches instead tend to evaluate coarse diseased classification under full supervision with image-only models, so it remains unclear how vision-language models (VLMs) should be adapted for clinically meaningful subtyping under data constraints. In this work, we model fine-grained glomerular subtyping as a clinically realistic few-shot problem and systematically evaluate both pathology-specialized and general-purpose vision-language models under this setting. We assess not only classification performance (accuracy, AUC, F1) but also the geometry of the learned representations, examining feature alignment between image and text embeddings and the separability of glomerular subtypes. By jointly analyzing shot count, model architecture and domain knowledge, and adaptation strategy, this study provides guidance for future model selection and training under real clinical data constraints. Our results indicate that pathology-specialized vision-language backbones, when paired with the vanilla fine-tuning, are the most effective starting point. Even with only 4-8 labeled examples per glomeruli subtype, these models begin to capture distinctions and show substantial gains in discrimination and calibration, though additional supervision continues to yield incremental improvements. We also find that the discrimination between positive and negative examples is as important as image-text alignment. Overall, our results show that supervision level and adaptation strategy jointly shape both diagnostic performance and multimodal structure, providing guidance for model selection, adaptation strategies, and annotation investment.

</details>


### [35] [BeyondFacial: Identity-Preserving Personalized Generation Beyond Facial Close-ups](https://arxiv.org/abs/2511.11989)
*Songsong Zhang,Chuanqi Tang,Hongguang Zhang,Guijian Tang,Minglong Li,Xueqiong Li,Shaowu Yang,Yuanxi Peng,Wenjing Yang,Jing Zhao*

Main category: cs.CV

TL;DR: 本文提出了一种改进的IPPG方法，通过双线推理和自适应融合策略，解决了身份与语义表达的冲突，实现了更丰富的个性化生成能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法过度强调面部区域，导致输出以面部特写为主，视觉叙事性弱且语义一致性差，核心问题是身份特征嵌入削弱了生成模型的语义表达能力。

Method: 设计了双线推理（DLI）管道和身份自适应融合（IdAF）策略，以及身份聚合预置（IdAP）模块，以分离身份与语义表示并优化融合过程。

Result: 实验验证了该方法在超越面部特写的IPPG任务中表现稳定有效，无需手动遮罩或微调即可高效生成，可作为即插即用组件快速部署。

Conclusion: 本文提出的方法通过双线推理管道和身份自适应融合策略，成功解决了传统方法中身份特征嵌入与语义表达之间的冲突，实现了身份保真度和场景语义创作的协同优化。

Abstract: Identity-Preserving Personalized Generation (IPPG) has advanced film production and artistic creation, yet existing approaches overemphasize facial regions, resulting in outputs dominated by facial close-ups.These methods suffer from weak visual narrativity and poor semantic consistency under complex text prompts, with the core limitation rooted in identity (ID) feature embeddings undermining the semantic expressiveness of generative models. To address these issues, this paper presents an IPPG method that breaks the constraint of facial close-ups, achieving synergistic optimization of identity fidelity and scene semantic creation. Specifically, we design a Dual-Line Inference (DLI) pipeline with identity-semantic separation, resolving the representation conflict between ID and semantics inherent in traditional single-path architectures. Further, we propose an Identity Adaptive Fusion (IdAF) strategy that defers ID-semantic fusion to the noise prediction stage, integrating adaptive attention fusion and noise decision masking to avoid ID embedding interference on semantics without manual masking. Finally, an Identity Aggregation Prepending (IdAP) module is introduced to aggregate ID information and replace random initializations, further enhancing identity preservation. Experimental results validate that our method achieves stable and effective performance in IPPG tasks beyond facial close-ups, enabling efficient generation without manual masking or fine-tuning. As a plug-and-play component, it can be rapidly deployed in existing IPPG frameworks, addressing the over-reliance on facial close-ups, facilitating film-level character-scene creation, and providing richer personalized generation capabilities for related domains.

</details>


### [36] [Dynamic Parameter Optimization for Highly Transferable Transformation-Based Attacks](https://arxiv.org/abs/2511.11993)
*Jiaming Liang,Chi-Man Pun*

Main category: cs.CV

TL;DR: 提出动态参数优化（DPO）方法，显著提升基于变换的攻击的可转移性，解决了现有方法的计算复杂度和参数优化问题。


<details>
  <summary>Details</summary>
Motivation: 针对现有基于变换的攻击在参数优化上的局限性，包括低迭代设置的误导性、参数统一性问题及计算复杂度高的问题。

Method: 提出了同心衰减模型（CDM）来解释可转移性的动态模式，并基于此设计了高效的动态参数优化（DPO）方法。

Result: 在不同代理模型、迭代次数和任务上的实验表明，DPO能显著提升攻击的可转移性，并将复杂度降至O(nlogm)。

Conclusion: 通过动态参数优化（DPO）方法，显著提升了基于变换的攻击的可转移性，解决了现有方法在参数优化上的盲点。

Abstract: Despite their wide application, the vulnerabilities of deep neural networks raise societal concerns. Among them, transformation-based attacks have demonstrated notable success in transfer attacks. However, existing attacks suffer from blind spots in parameter optimization, limiting their full potential. Specifically, (1) prior work generally considers low-iteration settings, yet attacks perform quite differently at higher iterations, so characterizing overall performance based only on low-iteration results is misleading. (2) Existing attacks use uniform parameters for different surrogate models, iterations, and tasks, which greatly impairs transferability. (3) Traditional transformation parameter optimization relies on grid search. For n parameters with m steps each, the complexity is O(mn). Large computational overhead limits further optimization of parameters. To address these limitations, we conduct an empirical study with various transformations as baselines, revealing three dynamic patterns of transferability with respect to parameter strength. We further propose a novel Concentric Decay Model (CDM) to effectively explain these patterns. Building on these insights, we propose an efficient Dynamic Parameter Optimization (DPO) based on the rise-then-fall pattern, reducing the complexity to O(nlogm). Comprehensive experiments on existing transformation-based attacks across different surrogate models, iterations, and tasks demonstrate that our DPO can significantly improve transferability.

</details>


### [37] [Uncertainty-Guided Selective Adaptation Enables Cross-Platform Predictive Fluorescence Microscopy](https://arxiv.org/abs/2511.12006)
*Kai-Wen K. Yang,Andrew Bai,Alexandra Bermudez,Yunqi Hong,Zoe Latham,Iris Sloan,Michael Liu,Vishrut Goyal,Cho-Jui Hsieh,Neil Y. C. Lin*

Main category: cs.CV

TL;DR: SIT-ADDA-Auto通过仅调整早期卷积层和自动选择适应深度，显著提升了显微镜图像处理的迁移学习效果。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习模型在新仪器或采集设置下图像处理失败的问题，避免传统对抗域适应方法破坏已学习的语义表示。

Method: 引入Subnetwork Image Translation ADDA with automatic depth selection (SIT-ADDA-Auto)框架，结合浅层对抗对齐和预测不确定性，自动选择适应深度。

Result: SIT-ADDA在多指标评估、专家盲测和不确定性深度消融实验中表现优异，改善了重建和下游分割效果，减少了语义特征的漂移。

Conclusion: 本研究通过仅调整早期卷积层并冻结更深层，实现了可靠的迁移学习，提出了SIT-ADDA-Auto框架，自动选择适应深度，无需目标标签。该方法在显微镜图像处理中表现出鲁棒性，并提供了标签自由适应的设计规则。

Abstract: Deep learning is transforming microscopy, yet models often fail when applied to images from new instruments or acquisition settings. Conventional adversarial domain adaptation (ADDA) retrains entire networks, often disrupting learned semantic representations. Here, we overturn this paradigm by showing that adapting only the earliest convolutional layers, while freezing deeper layers, yields reliable transfer. Building on this principle, we introduce Subnetwork Image Translation ADDA with automatic depth selection (SIT-ADDA-Auto), a self-configuring framework that integrates shallow-layer adversarial alignment with predictive uncertainty to automatically select adaptation depth without target labels. We demonstrate robustness via multi-metric evaluation, blinded expert assessment, and uncertainty-depth ablations. Across exposure and illumination shifts, cross-instrument transfer, and multiple stains, SIT-ADDA improves reconstruction and downstream segmentation over full-encoder adaptation and non-adversarial baselines, with reduced drift of semantic features. Our results provide a design rule for label-free adaptation in microscopy and a recipe for field settings; the code is publicly available.

</details>


### [38] [Enhancing Road Safety Through Multi-Camera Image Segmentation with Post-Encroachment Time Analysis](https://arxiv.org/abs/2511.12018)
*Shounak Ray Chaudhuri,Arash Jahangiri,Christopher Paolini*

Main category: cs.CV

TL;DR: 本文提出了一种基于多摄像头计算机视觉的实时安全评估框架，通过像素级PET算法在边缘设备上实现高精度风险区域识别，验证了其在智能交通系统中的可行性。


<details>
  <summary>Details</summary>
Motivation: 传统基于碰撞的研究受限于数据稀疏性和延迟性，本文旨在通过实时安全评估减少车辆和行人碰撞。

Method: 采用多摄像头计算机视觉框架，通过YOLOv11分割进行车辆检测，利用同形矩阵将检测到的车辆多边形转换为统一的鸟瞰图，并开发了一种像素级PET算法。

Result: 结果表明，该框架能够在边缘设备上以亚秒级精度识别高风险区域，并实现实时吞吐量，平均生成800 x 800像素对数热图的帧率为2.68 FPS。

Conclusion: 本研究验证了基于分散式视觉的PET分析在智能交通系统中的可行性，提供了一种可复制的方法，用于高分辨率、实时且可扩展的交叉路口安全评估。

Abstract: Traffic safety analysis at signalized intersections is vital for reducing vehicle and pedestrian collisions, yet traditional crash-based studies are limited by data sparsity and latency. This paper presents a novel multi-camera computer vision framework for real-time safety assessment through Post-Encroachment Time (PET) computation, demonstrated at the intersection of H Street and Broadway in Chula Vista, California. Four synchronized cameras provide continuous visual coverage, with each frame processed on NVIDIA Jetson AGX Xavier devices using YOLOv11 segmentation for vehicle detection. Detected vehicle polygons are transformed into a unified bird's-eye map using homography matrices, enabling alignment across overlapping camera views. A novel pixel-level PET algorithm measures vehicle position without reliance on fixed cells, allowing fine-grained hazard visualization via dynamic heatmaps, accurate to 3.3 sq-cm. Timestamped vehicle and PET data is stored in an SQL database for long-term monitoring. Results over various time intervals demonstrate the framework's ability to identify high-risk regions with sub-second precision and real-time throughput on edge devices, producing data for an 800 x 800 pixel logarithmic heatmap at an average of 2.68 FPS. This study validates the feasibility of decentralized vision-based PET analysis for intelligent transportation systems, offering a replicable methodology for high-resolution, real-time, and scalable intersection safety evaluation.

</details>


### [39] [LIHE: Linguistic Instance-Split Hyperbolic-Euclidean Framework for Generalized Weakly-Supervised Referring Expression Comprehension](https://arxiv.org/abs/2511.12020)
*Xianglong Shi,Silin Cheng,Sirui Zhao,Yunhan Jiang,Enhong Chen,Yang Liu,Sebastien Ourselin*

Main category: cs.CV

TL;DR: LIHE框架通过两阶段方法和混合相似度模块HEMix，解决了弱监督广义指称表达理解任务中的关键挑战。


<details>
  <summary>Details</summary>
Motivation: 现有WREC方法受限于一对一映射假设，无法处理零或多目标的现实场景，需扩展为更实用的WGREC任务。

Method: 提出LIHE框架，包括Referential Decoupling和Referent Grounding两阶段，结合HEMix混合相似度模块。

Result: LIHE在gRefCOCO和Ref-ZOM上表现优异，HEMix模块在标准REC基准上IoU@0.5提升高达2.5%。

Conclusion: LIHE框架通过两阶段方法成功解决了WGREC任务中的监督信号模糊和语义表示崩溃问题，并在gRefCOCO和Ref-ZOM数据集上建立了首个有效的弱监督基准。

Abstract: Existing Weakly-Supervised Referring Expression Comprehension (WREC) methods, while effective, are fundamentally limited by a one-to-one mapping assumption, hindering their ability to handle expressions corresponding to zero or multiple targets in realistic scenarios. To bridge this gap, we introduce the Weakly-Supervised Generalized Referring Expression Comprehension task (WGREC), a more practical paradigm that handles expressions with variable numbers of referents. However, extending WREC to WGREC presents two fundamental challenges: supervisory signal ambiguity, where weak image-level supervision is insufficient for training a model to infer the correct number and identity of referents, and semantic representation collapse, where standard Euclidean similarity forces hierarchically-related concepts into non-discriminative clusters, blurring categorical boundaries. To tackle these challenges, we propose a novel WGREC framework named Linguistic Instance-Split Hyperbolic-Euclidean (LIHE), which operates in two stages. The first stage, Referential Decoupling, predicts the number of target objects and decomposes the complex expression into simpler sub-expressions. The second stage, Referent Grounding, then localizes these sub-expressions using HEMix, our innovative hybrid similarity module that synergistically combines the precise alignment capabilities of Euclidean proximity with the hierarchical modeling strengths of hyperbolic geometry. This hybrid approach effectively prevents semantic collapse while preserving fine-grained distinctions between related concepts. Extensive experiments demonstrate LIHE establishes the first effective weakly supervised WGREC baseline on gRefCOCO and Ref-ZOM, while HEMix achieves consistent improvements on standard REC benchmarks, improving IoU@0.5 by up to 2.5\%. The code is available at https://anonymous.4open.science/r/LIHE.

</details>


### [40] [Null-Space Diffusion Distillation for Efficient Photorealistic Lensless Imaging](https://arxiv.org/abs/2511.12024)
*Jose Reinaldo Cunha Santos A V Silva Neto,Hodaka Kawachi,Yasushi Yagi,Tomoya Nakamura*

Main category: cs.CV

TL;DR: NSDD通过零空间扩散蒸馏，实现了无需成对监督的快速、逼真无透镜成像，性能接近教师模型且优于其他基线。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖成对的无透镜-有透镜监督可能导致模型偏差，而通用的扩散先验方法在噪声大、高度复用且不适定的无透镜去卷积场景中表现不佳。

Method: 引入Null-Space Diffusion Distillation (NSDD)，这是一种单遍学生模型，通过蒸馏迭代DDNM+求解器的零空间分量，并结合无透镜测量和范围空间锚点，实现测量一致性和逼真结果。

Result: 在Lensless-FFHQ和PhlatCam数据集上，NSDD是第二快的方法（仅次于Wiener），并达到接近教师模型的感知质量（第二优的LPIPS，低于DDNM+），优于DPS和经典凸基线方法。

Conclusion: NSDD提供了一种快速、无需真实数据的、逼真的无透镜成像方法，展示了在实际应用中的潜力。

Abstract: State-of-the-art photorealistic reconstructions for lensless cameras often rely on paired lensless-lensed supervision, which can bias models due to lens-lensless domain mismatch. To avoid this, ground-truth-free diffusion priors are attractive; however, generic formulations tuned for conventional inverse problems often break under the noisy, highly multiplexed, and ill-posed lensless deconvolution setting. We observe that methods which separate range-space enforcement from null-space diffusion-prior updates yield stable, realistic reconstructions. Building on this, we introduce Null-Space Diffusion Distillation (NSDD): a single-pass student that distills the null-space component of an iterative DDNM+ solver, conditioned on the lensless measurement and on a range-space anchor. NSDD preserves measurement consistency and achieves photorealistic results without paired supervision at a fraction of the runtime and memory. On Lensless-FFHQ and PhlatCam, NSDD is the second fastest, behind Wiener, and achieves near-teacher perceptual quality (second-best LPIPS, below DDNM+), outperforming DPS and classical convex baselines. These results suggest a practical path toward fast, ground-truth-free, photorealistic lensless imaging.

</details>


### [41] [Bridging Vision and Language for Robust Context-Aware Surgical Point Tracking: The VL-SurgPT Dataset and Benchmark](https://arxiv.org/abs/2511.12026)
*Rulin Zhou,Wenlong He,An Wang,Jianhang Zhang,Xuanhui Zeng,Xi Zhang,Chaowei Zhu,Haijun Hu,Hongliang Ren*

Main category: cs.CV

TL;DR: VL-SurgPT是首个结合视觉跟踪与文本描述的多模态数据集，TG-SurgPT方法通过语义描述提升了手术场景中的跟踪鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 手术环境中的复杂视觉条件（如烟雾遮挡、镜面反射和组织变形）使得准确点跟踪具有挑战性。现有数据集缺乏理解跟踪失败机制的语义上下文。

Method: 提出了TG-SurgPT，一种利用语义描述来增强视觉挑战条件下鲁棒性的文本引导跟踪方法。

Result: 实验结果表明，结合点状态信息显著提高了跟踪的准确性和可靠性，尤其是在视觉条件恶劣的情况下。

Conclusion: 通过结合视觉和语言模态，VL-SurgPT为开发上下文感知的跟踪系统提供了可能，这对于在具有挑战性的手术环境下保持性能至关重要。

Abstract: Accurate point tracking in surgical environments remains challenging due to complex visual conditions, including smoke occlusion, specular reflections, and tissue deformation. While existing surgical tracking datasets provide coordinate information, they lack the semantic context necessary to understand tracking failure mechanisms. We introduce VL-SurgPT, the first large-scale multimodal dataset that bridges visual tracking with textual descriptions of point status in surgical scenes. The dataset comprises 908 in vivo video clips, including 754 for tissue tracking (17,171 annotated points across five challenging scenarios) and 154 for instrument tracking (covering seven instrument types with detailed keypoint annotations). We establish comprehensive benchmarks using eight state-of-the-art tracking methods and propose TG-SurgPT, a text-guided tracking approach that leverages semantic descriptions to improve robustness in visually challenging conditions. Experimental results demonstrate that incorporating point status information significantly improves tracking accuracy and reliability, particularly in adverse visual scenarios where conventional vision-only methods struggle. By bridging visual and linguistic modalities, VL-SurgPT enables the development of context-aware tracking systems crucial for advancing computer-assisted surgery applications that can maintain performance even under challenging intraoperative conditions.

</details>


### [42] [GCAgent: Long-Video Understanding via Schematic and Narrative Episodic Memory](https://arxiv.org/abs/2511.12027)
*Jeong Hun Yeo,Sangyun Chung,Sungjune Park,Dae Hoe Kim,Jinyoung Moon,Yong Man Ro*

Main category: cs.CV

TL;DR: GCAgent框架通过结构化记忆和多阶段推理，显著提升MLLMs的长视频理解能力，达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决MLLMs在长视频理解中因令牌限制和长期依赖复杂性导致的全局上下文和复杂事件关系捕捉不足的问题。

Method: 引入GCAgent框架，采用Schematic and Narrative Episodic Memory来建模事件及其因果关系，通过多阶段的Perception-Action-Reflection循环和Memory Manager实现上下文感知推理。

Result: 在Video-MME Long split上实现23.5%的准确率提升，并在7B规模MLLMs中达到最先进性能，Long split准确率为73.4%，整体平均为71.9%。

Conclusion: GCAgent框架通过其创新的结构化和叙事性情景记忆，显著提升了MLLMs在长视频理解中的表现，验证了基于代理的推理范式和结构化记忆的有效性。

Abstract: Long-video understanding remains a significant challenge for Multimodal Large Language Models (MLLMs) due to inherent token limitations and the complexity of capturing long-term temporal dependencies. Existing methods often fail to capture the global context and complex event relationships necessary for deep video reasoning. To address this, we introduce GCAgent, a novel Global-Context-Aware Agent framework that achieves comprehensive long-video understanding. Our core innovation is the Schematic and Narrative Episodic Memory. This memory structurally models events and their causal and temporal relations into a concise, organized context, fundamentally resolving the long-term dependency problem. Operating in a multi-stage Perception-Action-Reflection cycle, our GCAgent utilizes a Memory Manager to retrieve relevant episodic context for robust, context-aware inference. Extensive experiments confirm that GCAgent significantly enhances long-video understanding, achieving up to 23.5\% accuracy improvement on the Video-MME Long split over a strong MLLM baseline. Furthermore, our framework establishes state-of-the-art performance among comparable 7B-scale MLLMs, achieving 73.4\% accuracy on the Long split and the highest overall average (71.9\%) on the Video-MME benchmark, validating our agent-based reasoning paradigm and structured memory for cognitively-inspired long-video understanding.

</details>


### [43] [VPHO: Joint Visual-Physical Cue Learning and Aggregation for Hand-Object Pose Estimation](https://arxiv.org/abs/2511.12030)
*Jun Zhou,Chi Xu,Kaifeng Tang,Yuting Ge,Tingrui Guo,Li Cheng*

Main category: cs.CV

TL;DR: 提出了一种联合视觉与物理线索的新型框架，通过联合学习和候选姿态聚合，实现了更高精度和物理合理性的手-物体姿态估计。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖视觉线索，常违反物理约束（如穿透或非接触），且物理推理通常依赖后优化或不可微物理引擎，损害视觉一致性和端到端可训练性。

Method: 1）联合视觉-物理线索学习：模型训练提取2D视觉线索和3D物理线索；2）候选姿态聚合：通过结合视觉和物理预测，聚合多个扩散生成的候选姿态，得到视觉一致且物理合理的最终估计。

Result: 实验证明，该方法在姿态准确性和物理合理性上显著优于现有最先进方法。

Conclusion: 论文提出的联合视觉与物理线索的框架显著提升了手-物体姿态估计的准确性和物理合理性，超越了现有方法。

Abstract: Estimating the 3D poses of hands and objects from a single RGB image is a fundamental yet challenging problem, with broad applications in augmented reality and human-computer interaction. Existing methods largely rely on visual cues alone, often producing results that violate physical constraints such as interpenetration or non-contact. Recent efforts to incorporate physics reasoning typically depend on post-optimization or non-differentiable physics engines, which compromise visual consistency and end-to-end trainability. To overcome these limitations, we propose a novel framework that jointly integrates visual and physical cues for hand-object pose estimation. This integration is achieved through two key ideas: 1) joint visual-physical cue learning: The model is trained to extract 2D visual cues and 3D physical cues, thereby enabling more comprehensive representation learning for hand-object interactions; 2) candidate pose aggregation: A novel refinement process that aggregates multiple diffusion-generated candidate poses by leveraging both visual and physical predictions, yielding a final estimate that is visually consistent and physically plausible. Extensive experiments demonstrate that our method significantly outperforms existing state-of-the-art approaches in both pose accuracy and physical plausibility.

</details>


### [44] [Improved Masked Image Generation with Knowledge-Augmented Token Representations](https://arxiv.org/abs/2511.12032)
*Guotao Liang,Baoquan Zhang,Zhiyuan Wen,Zihao Han,Yunming Ye*

Main category: cs.CV

TL;DR: KA-MIG通过引入显式token级语义依赖知识，提升了掩码图像生成的语义依赖捕捉能力，改进了生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅依赖模型自身学习视觉标记序列的语义依赖，但由于单个标记缺乏明确语义且序列较长，直接学习这些依赖具有挑战性。

Method: 提出了一个新颖的知识增强掩码图像生成框架KA-MIG，通过探索和利用三种token知识图（共现图、语义相似图和位置-标记不兼容图），并设计了一个图感知编码器来学习token和位置感知表示。

Result: 实验结果表明，KA-MIG在ImageNet上的类条件图像生成任务中优于现有方法。

Conclusion: KA-MIG框架通过引入显式的token级语义依赖知识作为先验，有效提升了模型捕捉语义依赖的能力，从而改善了生成质量。

Abstract: Masked image generation (MIG) has demonstrated remarkable efficiency and high-fidelity images by enabling parallel token prediction. Existing methods typically rely solely on the model itself to learn semantic dependencies among visual token sequences. However, directly learning such semantic dependencies from data is challenging because the individual tokens lack clear semantic meanings, and these sequences are usually long. To address this limitation, we propose a novel Knowledge-Augmented Masked Image Generation framework, named KA-MIG, which introduces explicit knowledge of token-level semantic dependencies (\emph{i.e.}, extracted from the training data) as priors to learn richer representations for improving performance. In particular, we explore and identify three types of advantageous token knowledge graphs, including two positive and one negative graphs (\emph{i.e.}, the co-occurrence graph, the semantic similarity graph, and the position-token incompatibility graph). Based on three prior knowledge graphs, we design a graph-aware encoder to learn token and position-aware representations. After that, a lightweight fusion mechanism is introduced to integrate these enriched representations into the existing MIG methods. Resorting to such prior knowledge, our method effectively enhances the model's ability to capture semantic dependencies, leading to improved generation quality. Experimental results demonstrate that our method improves upon existing MIG for class-conditional image generation on ImageNet.

</details>


### [45] [Calibrated Multimodal Representation Learning with Missing Modalities](https://arxiv.org/abs/2511.12034)
*Xiaohao Liu,Xiaobo Xia,Jiaheng Wei,Shuo Yang,Xiu Su,See-Kiong Ng,Tat-Seng Chua*

Main category: cs.CV

TL;DR: CalMRL通过表示层面对缺失模态建模，解决了多模态学习中缺失模态导致的锚点偏移问题，提升了数据利用灵活性。


<details>
  <summary>Details</summary>
Motivation: 当前多模态表示学习需要所有模态同时存在，难以利用普遍存在的缺失模态数据集。本文从锚点偏移的理论视角分析了这一问题。

Method: CalMRL利用先验知识和模态间的内在联系，在表示层面对缺失模态进行建模，并采用双步学习方法优化后验分布。

Result: 理论指导和实验验证表明，CalMRL有效缓解了锚点偏移问题，并在广泛实验中表现出优越性。

Conclusion: CalMRL通过校准由缺失模态引起的不完整对齐，为多模态表示学习提供了新的灵活性，能够吸收原本无法处理的缺失模态数据。

Abstract: Multimodal representation learning harmonizes distinct modalities by aligning them into a unified latent space. Recent research generalizes traditional cross-modal alignment to produce enhanced multimodal synergy but requires all modalities to be present for a common instance, making it challenging to utilize prevalent datasets with missing modalities. We provide theoretical insights into this issue from an anchor shift perspective. Observed modalities are aligned with a local anchor that deviates from the optimal one when all modalities are present, resulting in an inevitable shift. To address this, we propose CalMRL for multimodal representation learning to calibrate incomplete alignments caused by missing modalities. Specifically, CalMRL leverages the priors and the inherent connections among modalities to model the imputation for the missing ones at the representation level. To resolve the optimization dilemma, we employ a bi-step learning method with the closed-form solution of the posterior distribution of shared latents. We validate its mitigation of anchor shift and convergence with theoretical guidance. By equipping the calibrated alignment with the existing advanced method, we offer new flexibility to absorb data with missing modalities, which is originally unattainable. Extensive experiments and comprehensive analyses demonstrate the superiority of CalMRL. Our code, model checkpoints, and evaluation raw data will be publicly available.

</details>


### [46] [SRSplat: Feed-Forward Super-Resolution Gaussian Splatting from Sparse Multi-View Images](https://arxiv.org/abs/2511.12040)
*Xinyuan Hu,Changyue Shi,Chuxiao Yang,Minghao Chen,Jiajun Ding,Tao Wei,Chen Wei,Zhou Yu,Min Tan*

Main category: cs.CV

TL;DR: SRSplat利用外部参考图像和内部纹理线索，从稀疏低分辨率图像重建高分辨率3D场景，显著提升了纹理细节恢复效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在从稀疏低分辨率图像重建3D场景时，由于输入缺乏高频信息，难以恢复精细纹理细节。

Method: 提出了一种名为SRSplat的框架，包括构建场景特定参考图库、引入参考引导特征增强模块（RGFE）以及纹理感知密度控制（TADC）来优化高斯基元的预测。

Result: SRSplat在RealEstate10K、ACID和DTU等多个数据集上表现优异，并展现出强大的跨数据集和跨分辨率泛化能力。

Conclusion: SRSplat 通过结合外部高质量参考图像和内部纹理线索，成功解决了从稀疏低分辨率图像重建高分辨率3D场景时纹理细节恢复不足的问题，并在多个数据集上表现优于现有方法。

Abstract: Feed-forward 3D reconstruction from sparse, low-resolution (LR) images is a crucial capability for real-world applications, such as autonomous driving and embodied AI. However, existing methods often fail to recover fine texture details. This limitation stems from the inherent lack of high-frequency information in LR inputs. To address this, we propose \textbf{SRSplat}, a feed-forward framework that reconstructs high-resolution 3D scenes from only a few LR views. Our main insight is to compensate for the deficiency of texture information by jointly leveraging external high-quality reference images and internal texture cues. We first construct a scene-specific reference gallery, generated for each scene using Multimodal Large Language Models (MLLMs) and diffusion models. To integrate this external information, we introduce the \textit{Reference-Guided Feature Enhancement (RGFE)} module, which aligns and fuses features from the LR input images and their reference twin image. Subsequently, we train a decoder to predict the Gaussian primitives using the multi-view fused feature obtained from \textit{RGFE}. To further refine predicted Gaussian primitives, we introduce \textit{Texture-Aware Density Control (TADC)}, which adaptively adjusts Gaussian density based on the internal texture richness of the LR inputs. Extensive experiments demonstrate that our SRSplat outperforms existing methods on various datasets, including RealEstate10K, ACID, and DTU, and exhibits strong cross-dataset and cross-resolution generalization capabilities.

</details>


### [47] [PipeDiT: Accelerating Diffusion Transformers in Video Generation with Task Pipelining and Model Decoupling](https://arxiv.org/abs/2511.12056)
*Sijie Wang,Qiang Wang,Shaohuai Shi*

Main category: cs.CV

TL;DR: PipeDiT通过流水线化和模块解耦加速视频生成，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决扩散变换器（DiT）模型在视频生成中推理速度慢和内存消耗高的问题。

Method: 1. 设计了PipeSP算法，实现了序列并行计算的流水线化；2. 提出DeDiVAE方法，解耦扩散模块和VAE模块；3. 提出注意力协同处理（Aco）方法。

Result: 在多种常见分辨率和时间步配置下，PipeDiT实现了1.06x至4.02x的加速比。

Conclusion: PipeDiT框架通过三种创新方法显著提升了视频生成的推理速度和内存效率，并在OpenSoraPlan和HunyuanVideo中验证了其有效性。

Abstract: Video generation has been advancing rapidly, and diffusion transformer (DiT) based models have demonstrated remark- able capabilities. However, their practical deployment is of- ten hindered by slow inference speeds and high memory con- sumption. In this paper, we propose a novel pipelining frame- work named PipeDiT to accelerate video generation, which is equipped with three main innovations. First, we design a pipelining algorithm (PipeSP) for sequence parallelism (SP) to enable the computation of latent generation and commu- nication among multiple GPUs to be pipelined, thus reduc- ing inference latency. Second, we propose DeDiVAE to de- couple the diffusion module and the variational autoencoder (VAE) module into two GPU groups, whose executions can also be pipelined to reduce memory consumption and infer- ence latency. Third, to better utilize the GPU resources in the VAE group, we propose an attention co-processing (Aco) method to further reduce the overall video generation latency. We integrate our PipeDiT into both OpenSoraPlan and Hun- yuanVideo, two state-of-the-art open-source video generation frameworks, and conduct extensive experiments on two 8- GPU systems. Experimental results show that, under many common resolution and timestep configurations, our PipeDiT achieves 1.06x to 4.02x speedups over OpenSoraPlan and HunyuanVideo.

</details>


### [48] [FedSDA: Federated Stain Distribution Alignment for Non-IID Histopathological Image Classification](https://arxiv.org/abs/2511.12044)
*Cheng-Chang Tsai,Kai-Wen Cheng,Chun-Shien Lu*

Main category: cs.CV

TL;DR: FedSDA通过调整染色分布缓解非独立同分布问题，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决非独立同分布的病理图像数据在联邦学习中的分布偏移问题。

Method: 提出了一种联邦染色分布对齐（FedSDA）方法，利用扩散模型拟合数据分布并通过染色分离提取关键特征。

Result: FedSDA不仅有效提升了基线方法，还优于从数据分布角度解决非独立同分布问题的基线方法。

Conclusion: FedSDA方法通过调整客户端的染色分布来缓解联邦学习中的非独立同分布问题，为计算病理学社区提供了实用见解。

Abstract: Federated learning (FL) has shown success in collaboratively training a model among decentralized data resources without directly sharing privacy-sensitive training data. Despite recent advances, non-IID (non-independent and identically distributed) data poses an inevitable challenge that hinders the use of FL. In this work, we address the issue of non-IID histopathological images with feature distribution shifts from an intuitive perspective that has only received limited attention. Specifically, we address this issue from the perspective of data distribution by solely adjusting the data distributions of all clients. Building on the success of diffusion models in fitting data distributions and leveraging stain separation to extract the pivotal features that are closely related to the non-IID properties of histopathological images, we propose a Federated Stain Distribution Alignment (FedSDA) method. FedSDA aligns the stain distribution of each client with a target distribution in an FL framework to mitigate distribution shifts among clients. Furthermore, considering that training diffusion models on raw data in FL has been shown to be susceptible to privacy leakage risks, we circumvent this problem while still effectively achieving alignment. Extensive experimental results show that FedSDA is not only effective in improving baselines that focus on mitigating disparities across clients' model updates but also outperforms baselines that address the non-IID data issues from the perspective of data distribution. We show that FedSDA provides valuable and practical insights for the computational pathology community.

</details>


### [49] [DCMM-Transformer: Degree-Corrected Mixed-Membership Attention for Medical Imaging](https://arxiv.org/abs/2511.12047)
*Huimin Cheng,Xiaowei Yu,Shushan Wu,Luyang Fang,Chao Cao,Jing Zhang,Tianming Liu,Dajiang Zhu,Wenxuan Zhong,Ping Ma*

Main category: cs.CV

TL;DR: DCMM-Transformer是一种新型ViT架构，通过可微的社区结构建模提升了医学图像分析的性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 医学图像中潜在的解剖学结构（如器官、组织和病理区域）未被标准ViT充分利用，现有方法存在不可微、训练不稳定等问题。

Method: 提出了一种新型ViT架构DCMM-Transformer，采用Degree-Corrected Mixed-Membership（DCMM）模型作为自注意力的加性偏置。

Result: 在多种医学影像数据集上的实验表明，DCMM-Transformer在性能和泛化能力上均表现优越，学习到的分组结构和注意力调制显著提升了可解释性。

Conclusion: DCMM-Transformer通过引入全可微的社区结构和度异质性，显著提升了医学图像分析的性能和可解释性，优于现有方法。

Abstract: Medical images exhibit latent anatomical groupings, such as organs, tissues, and pathological regions, that standard Vision Transformers (ViTs) fail to exploit. While recent work like SBM-Transformer attempts to incorporate such structures through stochastic binary masking, they suffer from non-differentiability, training instability, and the inability to model complex community structure. We present DCMM-Transformer, a novel ViT architecture for medical image analysis that incorporates a Degree-Corrected Mixed-Membership (DCMM) model as an additive bias in self-attention. Unlike prior approaches that rely on multiplicative masking and binary sampling, our method introduces community structure and degree heterogeneity in a fully differentiable and interpretable manner. Comprehensive experiments across diverse medical imaging datasets, including brain, chest, breast, and ocular modalities, demonstrate the superior performance and generalizability of the proposed approach. Furthermore, the learned group structure and structured attention modulation substantially enhance interpretability by yielding attention maps that are anatomically meaningful and semantically coherent.

</details>


### [50] [DeiTFake: Deepfake Detection Model using DeiT Multi-Stage Training](https://arxiv.org/abs/2511.12048)
*Saksham Kumar,Ashish Singh,Srinivasarao Thota,Sunil Kumar Singh,Chandan Kumar*

Main category: cs.CV

TL;DR: DeiTFake通过两阶段渐进训练策略和DeiT模型，显著提升深度伪造检测性能，准确率超99%。


<details>
  <summary>Details</summary>
Motivation: 深度伪造对数字媒体完整性构成重大威胁，亟需高效检测方法。

Method: 采用基于DeiT的Transformer模型，结合两阶段渐进训练策略：第一阶段使用标准增强进行迁移学习，第二阶段采用高级仿射和深度伪造特定增强进行微调。

Result: 在OpenForensics数据集（190,335张图像）上，DeiTFake第一阶段准确率达98.71%，第二阶段准确率达99.22%，AUROC为0.9997。

Conclusion: DeiTFake在面部深度伪造检测中表现出色，两阶段渐进训练策略显著提升了检测准确性和鲁棒性，优于现有OpenForensics基线。

Abstract: Deepfakes are major threats to the integrity of digital media. We propose DeiTFake, a DeiT-based transformer and a novel two-stage progressive training strategy with increasing augmentation complexity. The approach applies an initial transfer-learning phase with standard augmentations followed by a fine-tuning phase using advanced affine and deepfake-specific augmentations. DeiT's knowledge distillation model captures subtle manipulation artifacts, increasing robustness of the detection model. Trained on the OpenForensics dataset (190,335 images), DeiTFake achieves 98.71\% accuracy after stage one and 99.22\% accuracy with an AUROC of 0.9997, after stage two, outperforming the latest OpenForensics baselines. We analyze augmentation impact and training schedules, and provide practical benchmarks for facial deepfake detection.

</details>


### [51] [UniABG: Unified Adversarial View Bridging and Graph Correspondence for Unsupervised Cross-View Geo-Localization](https://arxiv.org/abs/2511.12054)
*Cuiqun Chen,Qi Chen,Bin Yang,Xingyi Zhang*

Main category: cs.CV

TL;DR: UniABG 通过对抗桥接和图校准，显著提升无监督跨视角地理定位性能，超越有监督方法。


<details>
  <summary>Details</summary>
Motivation: 解决无监督跨视角地理定位方法因视角域差异导致的伪标签噪声问题，同时避免有监督方法对大量标注数据的依赖。

Method: UniABG 框架包括 View-Aware Adversarial Bridging (VAAB) 和 Heterogeneous Graph Filtering Calibration (HGFC) 两个阶段，分别用于建模视角不变特征和校准跨视角关联。

Result: 在 University-1652 和 SUES-200 数据集上，UniABG 分别将 Satellite → Drone AP 提升了 +10.63% 和 +16.73%，性能超过有监督基线。

Conclusion: UniABG 是一种创新的双阶段无监督跨视角地理定位框架，通过结合对抗性视角桥接和图基对应校准，显著提升了无监督方法的性能，甚至超越了有监督基线。

Abstract: Cross-view geo-localization (CVGL) matches query images ($\textit{e.g.}$, drone) to geographically corresponding opposite-view imagery ($\textit{e.g.}$, satellite). While supervised methods achieve strong performance, their reliance on extensive pairwise annotations limits scalability. Unsupervised alternatives avoid annotation costs but suffer from noisy pseudo-labels due to intrinsic cross-view domain gaps. To address these limitations, we propose $\textit{UniABG}$, a novel dual-stage unsupervised cross-view geo-localization framework integrating adversarial view bridging with graph-based correspondence calibration. Our approach first employs View-Aware Adversarial Bridging (VAAB) to model view-invariant features and enhance pseudo-label robustness. Subsequently, Heterogeneous Graph Filtering Calibration (HGFC) refines cross-view associations by constructing dual inter-view structure graphs, achieving reliable view correspondence. Extensive experiments demonstrate state-of-the-art unsupervised performance, showing that UniABG improves Satellite $\rightarrow$ Drone AP by +10.63\% on University-1652 and +16.73\% on SUES-200, even surpassing supervised baselines. The source code is available at https://github.com/chenqi142/UniABG

</details>


### [52] [MovSemCL: Movement-Semantics Contrastive Learning for Trajectory Similarity](https://arxiv.org/abs/2511.12061)
*Zhichen Lai,Hua Lu,Huan Li,Jialiang Li,Christian S. Jensen*

Main category: cs.CV

TL;DR: MovSemCL通过运动语义对比学习框架，改进轨迹相似性计算，解决现有方法的语义建模不足、高计算成本及物理增强不合理问题，实验显示性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有学习方法在轨迹语义和层次建模不足、计算成本高及物理增强不合理等方面存在局限，MovSemCL旨在解决这些问题。

Method: MovSemCL首先将原始GPS轨迹转换为运动语义特征并分块，然后通过块内和块间注意力机制编码局部和全局轨迹模式，实现高效层次化表示。此外，采用曲率引导的增强策略保留关键片段并掩盖冗余部分。

Result: 实验表明，MovSemCL在相似性搜索任务中接近理想排名，启发式近似性能提升达20.3%，推理延迟降低43.4%。

Conclusion: MovSemCL框架通过结合运动语义特征和层次化表示，显著提升了轨迹相似性计算的性能，并在计算效率和物理合理性上优于现有方法。

Abstract: Trajectory similarity computation is fundamental functionality that is used for, e.g., clustering, prediction, and anomaly detection. However, existing learning-based methods exhibit three key limitations: (1) insufficient modeling of trajectory semantics and hierarchy, lacking both movement dynamics extraction and multi-scale structural representation; (2) high computational costs due to point-wise encoding; and (3) use of physically implausible augmentations that distort trajectory semantics. To address these issues, we propose MovSemCL, a movement-semantics contrastive learning framework for trajectory similarity computation. MovSemCL first transforms raw GPS trajectories into movement-semantics features and then segments them into patches. Next, MovSemCL employs intra- and inter-patch attentions to encode local as well as global trajectory patterns, enabling efficient hierarchical representation and reducing computational costs. Moreover, MovSemCL includes a curvature-guided augmentation strategy that preserves informative segments (e.g., turns and intersections) and masks redundant ones, generating physically plausible augmented views. Experiments on real-world datasets show that MovSemCL is capable of outperforming state-of-the-art methods, achieving mean ranks close to the ideal value of 1 at similarity search tasks and improvements by up to 20.3% at heuristic approximation, while reducing inference latency by up to 43.4%.

</details>


### [53] [DCA-LUT: Deep Chromatic Alignment with 5D LUT for Purple Fringing Removal](https://arxiv.org/abs/2511.12066)
*Jialang Lu,Shuning Sun,Pu Wang,Chen Wu,Feng Gao,Lina Gong,Dianjie Lu,Guijuan Zhang,Zhuoran Zheng*

Main category: cs.CV

TL;DR: DCA-LUT是首个深度学习的紫色边缘去除框架，通过CA-CT模块和5D LUT技术显著提升图像质量。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖昂贵硬件和手工特征，忽视了数据驱动方法。

Method: 提出了基于深度学习的DCA-LUT框架，结合了新颖的CA-CT模块和5D LUT技术，实现了高效的紫色边缘去除。

Result: 在合成和真实数据集上，DCA-LUT表现出色，达到最先进水平。

Conclusion: DCA-LUT框架通过深度学习有效解决了紫色边缘问题，显著提升了图像质量。

Abstract: Purple fringing, a persistent artifact caused by Longitudinal Chromatic Aberration (LCA) in camera lenses, has long degraded the clarity and realism of digital imaging. Traditional solutions rely on complex and expensive apochromatic (APO) lens hardware and the extraction of handcrafted features, ignoring the data-driven approach. To fill this gap, we introduce DCA-LUT, the first deep learning framework for purple fringing removal. Inspired by the physical root of the problem, the spatial misalignment of RGB color channels due to lens dispersion, we introduce a novel Chromatic-Aware Coordinate Transformation (CA-CT) module, learning an image-adaptive color space to decouple and isolate fringing into a dedicated dimension. This targeted separation allows the network to learn a precise ``purple fringe channel", which then guides the accurate restoration of the luminance channel. The final color correction is performed by a learned 5D Look-Up Table (5D LUT), enabling efficient and powerful% non-linear color mapping. To enable robust training and fair evaluation, we constructed a large-scale synthetic purple fringing dataset (PF-Synth). Extensive experiments in synthetic and real-world datasets demonstrate that our method achieves state-of-the-art performance in purple fringing removal.

</details>


### [54] [Learning to Hear by Seeing: It's Time for Vision Language Models to Understand Artistic Emotion from Sight and Sound](https://arxiv.org/abs/2511.12077)
*Dengming Zhang,Weitao You,Jingxiong Li,Weishen Lin,Wenda Shi,Xue Zhao,Heda Zuo,Junxian Wu,Lingyun Sun*

Main category: cs.CV

TL;DR: VAEmotionLLM通过两阶段框架（视觉引导音频对齐+情感适配器）实现跨模态情感理解，在艺术情感基准测试中表现最优。


<details>
  <summary>Details</summary>
Motivation: 情感理解对于提升大型语言模型（LLMs）的通用性、可靠性和与人类的对齐至关重要。现有工作多为单模态或人类中心，忽视了艺术作品的多模态情感表达。

Method: 提出Vision Anchored Audio-Visual Emotion LLM (VAEmotionLLM)两阶段框架：第一阶段VG-Align通过视觉引导的音频对齐，使VLM具备听觉能力；第二阶段EmoAdapter通过轻量级的跨模态情感适配器增强情感理解。

Result: VAEmotionLLM在ArtEmoBenchmark上表现优于单模态和多模态基线，验证了方法的有效性。

Conclusion: VAEmotionLLM通过两阶段框架（VG-Align和EmoAdapter）实现了跨模态情感理解，在ArtEmoBenchmark上取得了最先进的成果，证明了其组件的互补性。

Abstract: Emotion understanding is critical for making Large Language Models (LLMs) more general, reliable, and aligned with humans. Art conveys emotion through the joint design of visual and auditory elements, yet most prior work is human-centered or single-modality, overlooking the emotion intentionally expressed by the artwork. Meanwhile, current Audio-Visual Language Models (AVLMs) typically require large-scale audio pretraining to endow Visual Language Models (VLMs) with hearing, which limits scalability. We present Vision Anchored Audio-Visual Emotion LLM (VAEmotionLLM), a two-stage framework that teaches a VLM to hear by seeing with limited audio pretraining and to understand emotion across modalities. In Stage 1, Vision-Guided Audio Alignment (VG-Align) distills the frozen visual pathway into a new audio pathway by aligning next-token distributions of the shared LLM on synchronized audio-video clips, enabling hearing without a large audio dataset. In Stage 2, a lightweight Cross-Modal Emotion Adapter (EmoAdapter), composed of the Emotion Enhancer and the Emotion Supervisor, injects emotion-sensitive residuals and applies emotion supervision to enhance cross-modal emotion understanding. We also construct ArtEmoBenchmark, an art-centric emotion benchmark that evaluates content and emotion understanding under audio-only, visual-only, and audio-visual inputs. VAEmotionLLM achieves state-of-the-art results on ArtEmoBenchmark, outperforming audio-only, visual-only, and audio-visual baselines. Ablations show that the proposed components are complementary.

</details>


### [55] [Point Cloud Quantization through Multimodal Prompting for 3D Understanding](https://arxiv.org/abs/2511.12079)
*Hongxuan Li,Wencheng Zhu,Huiying Xu,Xinzhong Zhu,Pengfei Zhu*

Main category: cs.CV

TL;DR: 本文提出一种多模态提示驱动的点云量化框架，利用文本嵌入作为原型先验，并通过双约束空间和Gumbel-Softmax技术提升性能，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有基于原型的方法在代表性和可解释性上不足，而多模态对齐在视觉-语言模型中显示出潜力，因此提出一种简单但有效的量化框架。

Method: 采用基于预训练模型文本嵌入的鲁棒原型先验，结合多模态提示自适应细化原型，并通过双约束量化空间（紧凑性和分离性正则化）整合视觉与原型特征。

Result: 在ModelNet40和ScanObjectNN数据集上的广泛实验证明了该方法的优越性。

Conclusion: 本文提出的多模态提示驱动量化框架在点云分析中表现出色，通过双约束量化空间和Gumbel-Softmax松弛技术，显著提升了量化效果。

Abstract: Vector quantization has emerged as a powerful tool in large-scale multimodal models, unifying heterogeneous representations through discrete token encoding. However, its effectiveness hinges on robust codebook design. Current prototype-based approaches relying on trainable vectors or clustered centroids fall short in representativeness and interpretability, even as multimodal alignment demonstrates its promise in vision-language models. To address these limitations, we propose a simple multimodal prompting-driven quantization framework for point cloud analysis. Our methodology is built upon two core insights: 1) Text embeddings from pre-trained models inherently encode visual semantics through many-to-one contrastive alignment, naturally serving as robust prototype priors; and 2) Multimodal prompts enable adaptive refinement of these prototypes, effectively mitigating vision-language semantic gaps. The framework introduces a dual-constrained quantization space, enforced by compactness and separation regularization, which seamlessly integrates visual and prototype features, resulting in hybrid representations that jointly encode geometric and semantic information. Furthermore, we employ Gumbel-Softmax relaxation to achieve differentiable discretization while maintaining quantization sparsity. Extensive experiments on the ModelNet40 and ScanObjectNN datasets clearly demonstrate the superior effectiveness of the proposed method.

</details>


### [56] [Supervised Multilabel Image Classification Using Residual Networks with Probabilistic Reasoning](https://arxiv.org/abs/2511.12082)
*Lokender Singh,Saksham Kumar,Chandan Kumar*

Main category: cs.CV

TL;DR: 该论文提出了一种改进的ResNet-101方法，通过概率推理提升多标签图像分类性能，在COCO-2014上表现优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 多标签图像分类在计算机视觉中有广泛应用，但现有方法在处理标签依赖性和不确定性方面存在不足。

Method: 提出了一种基于改进的ResNet-101架构的方法，通过模拟标签依赖性和不确定性，利用概率推理提高预测准确性。

Result: 模型在COCO-2014数据集上的mAP达到0.794，优于ResNet-SRN（0.771）和Vision Transformer基线（0.785）。

Conclusion: 该研究通过将概率推理整合到深度学习模型中，有效解决了多标签场景的挑战，并在COCO-2014数据集上实现了优于现有技术的性能。

Abstract: Multilabel image categorization has drawn interest recently because of its numerous computer vision applications. The proposed work introduces a novel method for classifying multilabel images using the COCO-2014 dataset and a modified ResNet-101 architecture. By simulating label dependencies and uncertainties, the approach uses probabilistic reasoning to improve prediction accuracy. Extensive tests show that the model outperforms earlier techniques and approaches to state-of-the-art outcomes in multilabel categorization. The work also thoroughly assesses the model's performance using metrics like precision-recall score and achieves 0.794 mAP on COCO-2014, outperforming ResNet-SRN (0.771) and Vision Transformer baselines (0.785). The novelty of the work lies in integrating probabilistic reasoning into deep learning models to effectively address the challenges presented by multilabel scenarios.

</details>


### [57] [SemanticStitch: Enhancing Image Coherence through Foreground-Aware Seam Carving](https://arxiv.org/abs/2511.12084)
*Ji-Ping Jin,Chen-Bin Feng,Rui Fan,Chi-Man Vong*

Main category: cs.CV

TL;DR: SemanticStitch利用深度学习与语义先验，改进图像拼接质量，实验效果显著。


<details>
  <summary>Details</summary>
Motivation: 传统拼接方法因忽略语义信息导致前景连续性破坏，需改进以保持视觉一致性。

Method: 提出了一种基于深度学习的框架SemanticStitch，引入了新颖的损失函数以强调显著目标的语义完整性。

Result: 实验结果表明，该方法在传统技术基础上取得了显著提升。

Conclusion: SemanticStitch通过结合语义先验显著提升了图像拼接的质量，为实际应用提供了可靠支持。

Abstract: Image stitching often faces challenges due to varying capture angles, positional differences, and object movements, leading to misalignments and visual discrepancies. Traditional seam carving methods neglect semantic information, causing disruptions in foreground continuity. We introduce SemanticStitch, a deep learning-based framework that incorporates semantic priors of foreground objects to preserve their integrity and enhance visual coherence. Our approach includes a novel loss function that emphasizes the semantic integrity of salient objects, significantly improving stitching quality. We also present two specialized real-world datasets to evaluate our method's effectiveness. Experimental results demonstrate substantial improvements over traditional techniques, providing robust support for practical applications.

</details>


### [58] [Teaching Prompts to Coordinate: Hierarchical Layer-Grouped Prompt Tuning for Continual Learning](https://arxiv.org/abs/2511.12090)
*Shengqin Jiang,Tianqi Kong,Yuankai Qi,Haokui Zhang,Lina Yao,Quan Z. Sheng,Qingshan Liu,Ming-Hsuan Yang*

Main category: cs.CV

TL;DR: A novel hierarchical prompt tuning method reduces catastrophic forgetting in continual learning by grouping layers and using a root prompt, outperforming existing methods.


<details>
  <summary>Details</summary>
Motivation: Address the risk of catastrophic forgetting in prompt-based continual learning by reducing unnecessary updates and enhancing synergy among prompts.

Method: Introduces a hierarchical layer-grouped prompt tuning method where layers in the same group share prompts adjusted by position encoding, and a single task-specific root prompt generates sub-prompts for each group.

Result: Extensive experiments show the method achieves favorable performance compared to state-of-the-art methods across four benchmarks.

Conclusion: The proposed hierarchical layer-grouped prompt tuning method effectively mitigates catastrophic forgetting by enhancing model stability through shared prompts and a root prompt mechanism, demonstrating superior performance across multiple benchmarks.

Abstract: Prompt-based continual learning methods fine-tune only a small set of additional learnable parameters while keeping the pre-trained model's parameters frozen. It enables efficient adaptation to new tasks while mitigating the risk of catastrophic forgetting. These methods typically attach one independent task-specific prompt to each layer of pre-trained models to locally modulate its features, ensuring that the layer's representation aligns with the requirements of the new task. However, although introducing learnable prompts independently at each layer provides high flexibility for adapting to new tasks, this overly flexible tuning could make certain layers susceptible to unnecessary updates. As all prompts till the current task are added together as a final prompt for all seen tasks, the model may easily overwrite feature representations essential to previous tasks, which increases the risk of catastrophic forgetting. To address this issue, we propose a novel hierarchical layer-grouped prompt tuning method for continual learning. It improves model stability in two ways: (i) Layers in the same group share roughly the same prompts, which are adjusted by position encoding. This helps preserve the intrinsic feature relationships and propagation pathways of the pre-trained model within each group. (ii) It utilizes a single task-specific root prompt to learn to generate sub-prompts for each layer group. In this way, all sub-prompts are conditioned on the same root prompt, enhancing their synergy and reducing independence. Extensive experiments across four benchmarks demonstrate that our method achieves favorable performance compared with several state-of-the-art methods.

</details>


### [59] [Learning from Dense Events: Towards Fast Spiking Neural Networks Training via Event Dataset Distillatio](https://arxiv.org/abs/2511.12095)
*Shuhan Ye,Yi Yu,Qixin Zhang,Chenqi Kong,Qiangqiang Wu,Kun Wang,Xudong Jiang*

Main category: cs.CV

TL;DR: PACE是首个针对SNN和事件视觉的数据集蒸馏框架，通过ST-DSM和PEQ-N模块显著降低训练成本，提升效率。


<details>
  <summary>Details</summary>
Motivation: SNN的训练成本高且时间编码限制其实际部署，PACE旨在通过数据集蒸馏降低训练成本。

Method: PACE通过ST-DSM模块（利用残差膜电位密集化脉冲特征并进行精细时空匹配）和PEQ-N模块（提供兼容标准事件帧管道的概率整数量化器）实现数据集蒸馏。

Result: 在DVS-Gesture、CIFAR10-DVS和N-MNIST数据集上，PACE优于现有基线，N-MNIST上达到84.4%准确率，训练时间减少50倍以上，存储成本降低6000倍。

Conclusion: PACE框架显著降低了SNN的训练成本，提升了效率，并在多个数据集上表现优异，尤其在动态事件流和低/中等IPC情况下。

Abstract: Event cameras sense brightness changes and output binary asynchronous event streams, attracting increasing attention. Their bio-inspired dynamics align well with spiking neural networks (SNNs), offering a promising energy-efficient alternative to conventional vision systems. However, SNNs remain costly to train due to temporal coding, which limits their practical deployment. To alleviate the high training cost of SNNs, we introduce \textbf{PACE} (Phase-Aligned Condensation for Events), the first dataset distillation framework to SNNs and event-based vision. PACE distills a large training dataset into a compact synthetic one that enables fast SNN training, which is achieved by two core modules: \textbf{ST-DSM} and \textbf{PEQ-N}. ST-DSM uses residual membrane potentials to densify spike-based features (SDR) and to perform fine-grained spatiotemporal matching of amplitude and phase (ST-SM), while PEQ-N provides a plug-and-play straight through probabilistic integer quantizer compatible with standard event-frame pipelines. Across DVS-Gesture, CIFAR10-DVS, and N-MNIST datasets, PACE outperforms existing coreset selection and dataset distillation baselines, with particularly strong gains on dynamic event streams and at low or moderate IPC. Specifically, on N-MNIST, it achieves \(84.4\%\) accuracy, about \(85\%\) of the full training set performance, while reducing training time by more than \(50\times\) and storage cost by \(6000\times\), yielding compact surrogates that enable minute-scale SNN training and efficient edge deployment.

</details>


### [60] [OPFormer: Object Pose Estimation leveraging foundation model with geometric encoding](https://arxiv.org/abs/2511.12614)
*Artem Moroz,Vít Zeman,Martin Mikšík,Elizaveta Isianova,Miroslav David,Pavel Burget,Varun Burde*

Main category: cs.CV

TL;DR: 论文提出了一种结合目标检测与姿态估计的端到端框架，利用NeRF快速重建和Transformer架构，在BOP测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了解决目标检测与姿态估计的集成问题，并提升在无3D CAD模型情况下的适应性，作者提出了一个端到端的统一框架。

Method: 框架采用CNOS检测器定位目标物体，结合新型姿态估计模块OPFormer（基于Transformer架构），利用多视角模板视图和NOCS几何先验学习对象表示，并通过解码器建立2D-3D对应关系。

Result: 在BOP基准测试中，该系统表现出优异的准确性与效率平衡。

Conclusion: 该论文提出的统一框架在BOP基准测试中展示了高准确性和效率，适用于基于模型和无模型的场景。

Abstract: We introduce a unified, end-to-end framework that seamlessly integrates object detection and pose estimation with a versatile onboarding process. Our pipeline begins with an onboarding stage that generates object representations from either traditional 3D CAD models or, in their absence, by rapidly reconstructing a high-fidelity neural representation (NeRF) from multi-view images. Given a test image, our system first employs the CNOS detector to localize target objects. For each detection, our novel pose estimation module, OPFormer, infers the precise 6D pose. The core of OPFormer is a transformer-based architecture that leverages a foundation model for robust feature extraction. It uniquely learns a comprehensive object representation by jointly encoding multiple template views and enriches these features with explicit 3D geometric priors using Normalized Object Coordinate Space (NOCS). A decoder then establishes robust 2D-3D correspondences to determine the final pose. Evaluated on the challenging BOP benchmarks, our integrated system demonstrates a strong balance between accuracy and efficiency, showcasing its practical applicability in both model-based and model-free scenarios.

</details>


### [61] [Sparse by Rule: Probability-Based N:M Pruning for Spiking Neural Networks](https://arxiv.org/abs/2511.12097)
*Shuhan Ye,Yi Yu,Qixin Zhang,Chenqi Kong,Qiangqiang Wu,Xudong Jiang,Dacheng Tao*

Main category: cs.CV

TL;DR: SpikeNM是一种半结构化剪枝框架，通过M-way参数化和EID方法，在保持SNN性能的同时优化硬件部署。


<details>
  <summary>Details</summary>
Motivation: 解决SNN在深度架构中参数和计算成本膨胀的问题，现有剪枝方法（非结构化或结构化）在硬件加速或灵活性上存在不足。

Method: SpikeNM采用M-way basis-logit参数化和可微分top-k采样器，线性化每块复杂度至O(M)，并结合EID方法，通过块级软目标对齐掩码概率与脉冲动态。

Result: 在2:4稀疏度下，SpikeNM在主流数据集上保持甚至提升了准确率，并生成硬件友好的稀疏模式。

Conclusion: SpikeNM通过半结构化剪枝框架和EID方法，有效平衡了SNN的稀疏性和硬件友好性，同时在主流数据集上保持了甚至提升了准确率。

Abstract: Brain-inspired Spiking neural networks (SNNs) promise energy-efficient intelligence via event-driven, sparse computation, but deeper architectures inflate parameters and computational cost, hindering their edge deployment. Recent progress in SNN pruning helps alleviate this burden, yet existing efforts fall into only two families: \emph{unstructured} pruning, which attains high sparsity but is difficult to accelerate on general hardware, and \emph{structured} pruning, which eases deployment but lack flexibility and often degrades accuracy at matched sparsity. In this work, we introduce \textbf{SpikeNM}, the first SNN-oriented \emph{semi-structured} \(N{:}M\) pruning framework that learns sparse SNNs \emph{from scratch}, enforcing \emph{at most \(N\)} non-zeros per \(M\)-weight block. To avoid the combinatorial space complexity \(\sum_{k=1}^{N}\binom{M}{k}\) growing exponentially with \(M\), SpikeNM adopts an \(M\)-way basis-logit parameterization with a differentiable top-\(k\) sampler, \emph{linearizing} per-block complexity to \(\mathcal O(M)\) and enabling more aggressive sparsification. Further inspired by neuroscience, we propose \emph{eligibility-inspired distillation} (EID), which converts temporally accumulated credits into block-wise soft targets to align mask probabilities with spiking dynamics, reducing sampling variance and stabilizing search under high sparsity. Experiments show that at \(2{:}4\) sparsity, SpikeNM maintains and even with gains across main-stream datasets, while yielding hardware-amenable patterns that complement intrinsic spike sparsity.

</details>


### [62] [Uni-Hand: Universal Hand Motion Forecasting in Egocentric Views](https://arxiv.org/abs/2511.12878)
*Junyi Ma,Wentao Bao,Jingyi Xu,Guanzhong Sun,Yu Zheng,Erhang Zhang,Xieyuanli Chen,Hesheng Wang*

Main category: cs.CV

TL;DR: EgoLoc 是一种零样本方法，通过手动力学和视觉语言模型定位手与物体的接触/分离时刻，适用于混合现实和机器人任务。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注交互行为建模（“如何交互”），但手与物体接触/分离的关键时刻（“何时交互”）尚未充分探索，这对混合现实和机器人运动规划至关重要。

Method: EgoLoc 采用手动力学引导采样生成高质量视觉提示，利用视觉语言模型识别接触/分离属性并定位具体时间戳，通过闭环反馈进一步优化结果。

Result: EgoLoc 在公开数据集和新基准测试中表现优异，能有效支持自我中心视觉和机器人操作任务的下游应用。

Conclusion: EgoLoc 是一种零样本方法，能够在自我中心视频中准确定位手与物体的接触和分离时刻，无需依赖物体掩码或动词-名词分类，具有广泛的适用性。

Abstract: Analyzing hand-object interaction in egocentric vision facilitates VR/AR applications and human-robot policy transfer. Existing research has mostly focused on modeling the behavior paradigm of interactive actions (i.e., "how to interact"). However, the more challenging and fine-grained problem of capturing the critical moments of contact and separation between the hand and the target object (i.e., "when to interact") is still underexplored, which is crucial for immersive interactive experiences in mixed reality and robotic motion planning. Therefore, we formulate this problem as temporal interaction localization (TIL). Some recent works extract semantic masks as TIL references, but suffer from inaccurate object grounding and cluttered scenarios. Although current temporal action localization (TAL) methods perform well in detecting verb-noun action segments, they rely on category annotations during training and exhibit limited precision in localizing hand-object contact/separation moments. To address these issues, we propose a novel zero-shot approach dubbed EgoLoc to localize hand-object contact and separation timestamps in egocentric videos. EgoLoc introduces hand-dynamics-guided sampling to generate high-quality visual prompts. It exploits the vision-language model to identify contact/separation attributes, localize specific timestamps, and provide closed-loop feedback for further refinement. EgoLoc eliminates the need for object masks and verb-noun taxonomies, leading to generalizable zero-shot implementation. Comprehensive experiments on the public dataset and our novel benchmarks demonstrate that EgoLoc achieves plausible TIL for egocentric videos. It is also validated to effectively facilitate multiple downstream applications in egocentric vision and robotic manipulation tasks. Code and relevant data will be released at https://github.com/IRMVLab/EgoLoc.

</details>


### [63] [DINOv3-Guided Cross Fusion Framework for Semantic-aware CT generation from MRI and CBCT](https://arxiv.org/abs/2511.12098)
*Xianhao Zhou,Jianghao Wu,Ku Zhao,Jinlong He,Huangxuan Zhao,Lei Chen,Shaoting Zhang,Guotai Wang*

Main category: cs.CV

TL;DR: 提出DGCF框架，结合DINOv3和CNN，解决医学图像转换中的语义理解问题，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的CNN模型缺乏全局语义理解，而Transformer由于高模型容量和弱归纳偏置容易在小数据集上过拟合，限制了合成CT图像在放射治疗计划中的应用。

Method: 提出了DINOv3-Guided Cross Fusion (DGCF)框架，通过可学习的交叉融合模块分层融合Transformer的全局表示和CNN的局部特征，并引入Multi-Level DINOv3 Perceptual (MLDP)损失函数来增强合成CT与真实CT在DINOv3特征空间中的语义相似性。

Result: 在SynthRAD2023骨盆数据集上的实验表明，DGCF在MS-SSIM、PSNR和基于分割的指标上均达到了最先进的性能。

Conclusion: 本文提出了一种名为DGCF的框架，通过结合自监督的DINOv3 Transformer和可训练的CNN编码器-解码器，解决了现有CNN模型缺乏全局语义理解和Transformer在小数据集上容易过拟合的问题。实验证明，DGCF在MRI→CT和CBCT→CT转换任务上达到了最先进的性能。

Abstract: Generating synthetic CT images from CBCT or MRI has a potential for efficient radiation dose planning and adaptive radiotherapy. However, existing CNN-based models lack global semantic understanding, while Transformers often overfit small medical datasets due to high model capacity and weak inductive bias. To address these limitations, we propose a DINOv3-Guided Cross Fusion (DGCF) framework that integrates a frozen self-supervised DINOv3 Transformer with a trainable CNN encoder-decoder. It hierarchically fuses global representation of Transformer and local features of CNN via a learnable cross fusion module, achieving balanced local appearance and contextual representation. Furthermore, we introduce a Multi-Level DINOv3 Perceptual (MLDP) loss that encourages semantic similarity between synthetic CT and the ground truth in DINOv3's feature space. Experiments on the SynthRAD2023 pelvic dataset demonstrate that DGCF achieved state-of-the-art performance in terms of MS-SSIM, PSNR and segmentation-based metrics on both MRI$\rightarrow$CT and CBCT$\rightarrow$CT translation tasks. To the best of our knowledge, this is the first work to employ DINOv3 representations for medical image translation, highlighting the potential of self-supervised Transformer guidance for semantic-aware CT synthesis. The code is available at https://github.com/HiLab-git/DGCF.

</details>


### [64] [DiffPixelFormer: Differential Pixel-Aware Transformer for RGB-D Indoor Scene Segmentation](https://arxiv.org/abs/2511.13047)
*Yan Gong,Jianli Lu,Yongsheng Gao,Jie Zhao,Xiaojuan Zhang,Susanto Rahardja*

Main category: cs.CV

TL;DR: DiffPixelFormer是一种新型RGB-D室内场景分割方法，通过改进模态内和模态间特征交互，显著提升分割精度。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-D融合方法存在计算复杂度高、特征对齐不精确和模态间关系建模不足的问题，限制了分割性能。

Method: DiffPixelFormer采用差分像素感知Transformer结构，结合Intra-Inter Modal Interaction Block（IIMIB）和Differential-Shared Inter-Modal（DSIM）模块，实现模态内和模态间的特征交互与对齐。

Result: 在SUN RGB-D和NYUDv2基准测试中，DiffPixelFormer-L分别达到54.28%和59.95%的mIoU，优于DFormer-L。

Conclusion: DiffPixelFormer在室内场景分割任务中表现出色，通过其独特的Intra-Inter Modal Interaction Block和动态融合策略，显著提升了RGB-D数据的利用效率和分割精度。

Abstract: Indoor semantic segmentation is fundamental to computer vision and robotics, supporting applications such as autonomous navigation, augmented reality, and smart environments. Although RGB-D fusion leverages complementary appearance and geometric cues, existing methods often depend on computationally intensive cross-attention mechanisms and insufficiently model intra- and inter-modal feature relationships, resulting in imprecise feature alignment and limited discriminative representation. To address these challenges, we propose DiffPixelFormer, a differential pixel-aware Transformer for RGB-D indoor scene segmentation that simultaneously enhances intra-modal representations and models inter-modal interactions. At its core, the Intra-Inter Modal Interaction Block (IIMIB) captures intra-modal long-range dependencies via self-attention and models inter-modal interactions with the Differential-Shared Inter-Modal (DSIM) module to disentangle modality-specific and shared cues, enabling fine-grained, pixel-level cross-modal alignment. Furthermore, a dynamic fusion strategy balances modality contributions and fully exploits RGB-D information according to scene characteristics. Extensive experiments on the SUN RGB-D and NYUDv2 benchmarks demonstrate that DiffPixelFormer-L achieves mIoU scores of 54.28% and 59.95%, outperforming DFormer-L by 1.78% and 2.75%, respectively. Code is available at https://github.com/gongyan1/DiffPixelFormer.

</details>


### [65] [Adaptive Begin-of-Video Tokens for Autoregressive Video Diffusion Models](https://arxiv.org/abs/2511.12099)
*Tianle Cheng,Zeyan Zhang,Kaifeng Gao,Jun Xiao*

Main category: cs.CV

TL;DR: 本文提出ada-BOV和流去噪细化策略，显著提升长视频生成的全局一致性和局部动态质量，实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的视频扩散模型在生成长视频时存在去噪延迟、错误累积、一致性脆弱和运动动态差等问题，需要一种更高效且一致的方法。

Method: 提出了Adaptive Begin-of-Video Tokens (ada-BOV)和流去噪细化策略，包括解耦采样轨迹长度与注意力窗口大小约束，以及扰动增强的训练噪声调度。

Result: 实验表明，ada-BOV方法在全局一致性和局部动态质量上表现优异，且在多个指标上超越了现有方法。

Conclusion: 本文提出的ada-BOV方法通过自适应层归一化调制和流去噪细化策略，显著提升了长视频生成的全局一致性和局部动态质量，同时在多个指标上取得了优异的定性和定量结果。

Abstract: Recent advancements in diffusion-based video generation have produced impressive and high-fidelity short videos. To extend these successes to generate coherent long videos, most video diffusion models (VDMs) generate videos in an autoregressive manner, i.e., generating subsequent frames conditioned on previous ones. There are generally two primary paradigms: chunk-based extension and stream denoising. The former directly concatenates previous clean frames as conditioning, suffering from denoising latency and error accumulation. The latter maintains the denoising sequence with monotonically increasing noise levels. In each denoising iteration, one clean frame is produced while a new pure noise is simultaneously appended, enabling live-stream sampling. However, it struggles with fragile consistency and poor motion dynamics. In this paper, we propose Adaptive Begin-of-Video Tokens (ada-BOV) for autoregressive VDMs. The BOV tokens are special learnable embeddings on VDMs. They adaptively absorb denoised preceding frames via an adaptive-layer-norm-like modulation. This design preserves the global consistency while allowing for flexible conditioning in dynamic scenarios. To ensure the quality of local dynamics essential in modulating BOV tokens, we further propose a refinement strategy for stream denoising. It decouples the sampling trajectory length from the attention window size constraint, leading to improved local guidance and overall imaging quality. We also propose a disturbance-augmented training noise schedule, which balances the convergence speed with model robustness for the stream denoising. Extensive experiments demonstrate that our method achieves compelling qualitative and quantitative results across multiple metrics.

</details>


### [66] [PhysX-Anything: Simulation-Ready Physical 3D Assets from Single Image](https://arxiv.org/abs/2511.13648)
*Ziang Cao,Fangzhou Hong,Zhaoxi Chen,Liang Pan,Ziwei Liu*

Main category: cs.CV

TL;DR: PhysX-Anything是首个仿真就绪物理3D生成框架，基于VLM模型和高效几何标记化，显著提升生成质量，支持具身AI和物理仿真。


<details>
  <summary>Details</summary>
Motivation: 现有3D生成方法忽视物理和关节属性，限制了在具身AI中的实用性，因此需要开发仿真就绪的物理3D生成框架。

Method: 提出了首个基于VLM的物理3D生成模型，并引入高效几何标记化方法，显著减少标记数量。构建了新的物理3D数据集PhysX-Mobility，覆盖更多类别和丰富物理标注。

Result: PhysX-Anything在PhysX-Mobility和野外图像上表现出强大的生成性能和鲁棒泛化能力，其资产可直接用于机器人策略学习。

Conclusion: PhysX-Anything 通过其高质量的仿真就绪3D资产生成能力，为具身AI和物理仿真等下游应用提供了强大支持。

Abstract: 3D modeling is shifting from static visual representations toward physical, articulated assets that can be directly used in simulation and interaction. However, most existing 3D generation methods overlook key physical and articulation properties, thereby limiting their utility in embodied AI. To bridge this gap, we introduce PhysX-Anything, the first simulation-ready physical 3D generative framework that, given a single in-the-wild image, produces high-quality sim-ready 3D assets with explicit geometry, articulation, and physical attributes. Specifically, we propose the first VLM-based physical 3D generative model, along with a new 3D representation that efficiently tokenizes geometry. It reduces the number of tokens by 193x, enabling explicit geometry learning within standard VLM token budgets without introducing any special tokens during fine-tuning and significantly improving generative quality. In addition, to overcome the limited diversity of existing physical 3D datasets, we construct a new dataset, PhysX-Mobility, which expands the object categories in prior physical 3D datasets by over 2x and includes more than 2K common real-world objects with rich physical annotations. Extensive experiments on PhysX-Mobility and in-the-wild images demonstrate that PhysX-Anything delivers strong generative performance and robust generalization. Furthermore, simulation-based experiments in a MuJoCo-style environment validate that our sim-ready assets can be directly used for contact-rich robotic policy learning. We believe PhysX-Anything can substantially empower a broad range of downstream applications, especially in embodied AI and physics-based simulation.

</details>


### [67] [Did Models Sufficient Learn? Attribution-Guided Training via Subset-Selected Counterfactual Augmentation](https://arxiv.org/abs/2511.12100)
*Yannan Chen,Ruoyu Chen,Bin Zeng,Wei Wang,Shiming Liu,Qunli Zhang,Zheng Hu,Laiyuan Wang,Yaowei Wang,Xiaochun Cao*

Main category: cs.CV

TL;DR: SS-CA通过反事实增强训练，纠正模型依赖不足因果性的问题，提升泛化与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前视觉模型训练中，模型依赖的预测原因不足，导致对分布变化或关键特征缺失敏感。模型与人类在识别反事实时的差异表明模型学习的依赖性可能不足够因果。

Method: 基于LIMA归因方法开发了Counterfactual LIMA，识别最小空间区域集，并通过替换这些区域为自然背景进行数据增强，联合训练原始和增强样本。

Result: 在多个ImageNet变体上的实验表明，SS-CA提高了分布内测试数据的泛化能力，并在分布外基准（如ImageNet-R和ImageNet-S）上表现更优。在噪声等扰动下，模型也展现出更强的泛化能力。

Conclusion: SS-CA通过将反事实解释直接整合到训练过程中，有效地纠正了模型依赖不足因果性的问题，显著提升了模型在分布内和分布外数据上的泛化能力和鲁棒性。

Abstract: In current visual model training, models often rely on only limited sufficient causes for their predictions, which makes them sensitive to distribution shifts or the absence of key features. Attribution methods can accurately identify a model's critical regions. However, masking these areas to create counterfactuals often causes the model to misclassify the target, while humans can still easily recognize it. This divergence highlights that the model's learned dependencies may not be sufficiently causal. To address this issue, we propose Subset-Selected Counterfactual Augmentation (SS-CA), which integrates counterfactual explanations directly into the training process for targeted intervention. Building on the subset-selection-based LIMA attribution method, we develop Counterfactual LIMA to identify minimal spatial region sets whose removal can selectively alter model predictions. Leveraging these attributions, we introduce a data augmentation strategy that replaces the identified regions with natural background, and we train the model jointly on both augmented and original samples to mitigate incomplete causal learning. Extensive experiments across multiple ImageNet variants show that SS-CA improves generalization on in-distribution (ID) test data and achieves superior performance on out-of-distribution (OOD) benchmarks such as ImageNet-R and ImageNet-S. Under perturbations including noise, models trained with SS-CA also exhibit enhanced generalization, demonstrating that our approach effectively uses interpretability insights to correct model deficiencies and improve both performance and robustness.

</details>


### [68] [Scaling Spatial Intelligence with Multimodal Foundation Models](https://arxiv.org/abs/2511.13719)
*Zhongang Cai,Ruisi Wang,Chenyang Gu,Fanyi Pu,Junxiang Xu,Yubo Wang,Wanqi Yin,Zhitao Yang,Chen Wei,Qingping Sun,Tongxi Zhou,Jiaqi Li,Hui En Pang,Oscar Qian,Yukun Wei,Zhiqian Lin,Xuanke Shi,Kewang Deng,Xiaoyang Han,Zukai Chen,Xiangyu Fan,Hanming Deng,Lewei Lu,Liang Pan,Bo Li,Ziwei Liu,Quan Wang,Dahua Lin,Lei Yang*

Main category: cs.CV

TL;DR: SenseNova-SI通过构建大规模多样化数据集和现有多模态模型，显著提升了空间智能能力，并在多个基准测试中取得优异表现，同时探讨了数据扩展和泛化能力的潜力。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态基础模型取得了显著进展，但在空间智能方面仍存在不足，因此探索通过数据扩展和多样化训练提升模型的空间智能能力。

Method: 构建了SenseNova-SI-8M数据集，包含八百万个多样化数据样本，基于严格的空间能力分类法，并利用现有的多模态基础模型（如Qwen3-VL、InternVL3和Bagel）进行训练。

Result: SenseNova-SI在多个空间智能基准测试中表现优异（如VSI-Bench 68.7%、MMSI 43.3%、MindCube 85.6%等），同时保持了强大的通用多模态理解能力（如MMBench-En 84.9%）。

Conclusion: SenseNova-SI项目展示了通过系统性数据扩展和多样化训练在多模态基础模型中培养空间智能的潜力，并公开了新训练的多模态基础模型以促进进一步研究。

Abstract: Despite remarkable progress, multimodal foundation models still exhibit surprising deficiencies in spatial intelligence. In this work, we explore scaling up multimodal foundation models to cultivate spatial intelligence within the SenseNova-SI family, built upon established multimodal foundations including visual understanding models (i.e., Qwen3-VL and InternVL3) and unified understanding and generation models (i.e., Bagel). We take a principled approach to constructing high-performing and robust spatial intelligence by systematically curating SenseNova-SI-8M: eight million diverse data samples under a rigorous taxonomy of spatial capabilities. SenseNova-SI demonstrates unprecedented performance across a broad range of spatial intelligence benchmarks: 68.7% on VSI-Bench, 43.3% on MMSI, 85.6% on MindCube, 54.6% on ViewSpatial, and 50.1% on SITE, while maintaining strong general multimodal understanding (e.g., 84.9% on MMBench-En). More importantly, we analyze the impact of data scaling, discuss early signs of emergent generalization capabilities enabled by diverse data training, analyze the risk of overfitting and language shortcuts, present a preliminary study on spatial chain-of-thought reasoning, and validate the potential downstream application. SenseNova-SI is an ongoing project, and this report will be updated continuously. All newly trained multimodal foundation models are publicly released to facilitate further research in this direction.

</details>


### [69] [BdSL-SPOTER: A Transformer-Based Framework for Bengali Sign Language Recognition with Cultural Adaptation](https://arxiv.org/abs/2511.12103)
*Sayad Ibna Azad,Md. Atiqur Rahman*

Main category: cs.CV

TL;DR: BdSL-SPOTER 是一种基于姿势的 Transformer 框架，用于高效识别孟加拉手语，通过优化和课程学习在有限数据上表现优异。


<details>
  <summary>Details</summary>
Motivation: 准确高效地识别孟加拉手语（BdSL），特别是在数据有限的情况下。

Method: 扩展了 SPOTER 范式，采用文化特定的预处理和紧凑的四层 Transformer 编码器，优化了可学习的位置编码，并使用课程学习来增强在有限数据上的泛化能力并加速收敛。

Result: 在 BdSLW60 基准测试中达到 97.92% 的 Top-1 验证准确率，比 Bi-LSTM 基线提高了 22.82%，同时保持较低的计算成本。

Conclusion: BdSL-SPOTER 提供了一个实用的框架，适用于现实世界的无障碍应用，并可作为其他低资源地区手语的可扩展模型。

Abstract: We introduce BdSL-SPOTER, a pose-based transformer framework for accurate and efficient recognition of Bengali Sign Language (BdSL). BdSL-SPOTER extends the SPOTER paradigm with cultural specific preprocessing and a compact four-layer transformer encoder featuring optimized learnable positional encodings, while employing curriculum learning to enhance generalization on limited data and accelerate convergence. On the BdSLW60 benchmark, it achieves 97.92% Top-1 validation accuracy, representing a 22.82% improvement over the Bi-LSTM baseline, all while keeping computational costs low. With its reduced number of parameters, lower FLOPs, and higher FPS, BdSL-SPOTER provides a practical framework for real-world accessibility applications and serves as a scalable model for other low-resource regional sign languages.

</details>


### [70] [TEMPO: Global Temporal Building Density and Height Estimation from Satellite Imagery](https://arxiv.org/abs/2511.12104)
*Tammy Glazer,Gilles Q. Hacheme,Akram Zaytar,Luana Marotti,Amy Michaels,Girmaw Abebe Tadesse,Kevin White,Rahul Dodhia,Andrew Zolli,Inbal Becker-Reshef,Juan M. Lavista Ferres,Caleb Robinson*

Main category: cs.CV

TL;DR: TEMPO是一个基于深度学习的全球建筑密度和高度季度数据集，计算成本低，适用于大范围监测。


<details>
  <summary>Details</summary>
Motivation: 解决大规模监测建筑密度和高度变化的高计算成本问题，支持全球发展和气候影响研究。

Method: 利用高分辨率卫星图像和现有建筑足迹与高度数据训练多任务深度学习模型，预测37.6米/像素分辨率的建筑密度和高度。

Result: 模型在不同手动标记子集上F1得分85%至88%，时间稳定性高（五年趋势一致性得分0.96）。

Conclusion: TEMPO数据集通过深度学习方法实现了对全球建筑密度和高度的季度监测，为全球韧性和适应气候变化提供了重要支持。

Abstract: We present TEMPO, a global, temporally resolved dataset of building density and height derived from high-resolution satellite imagery using deep learning models. We pair building footprint and height data from existing datasets with quarterly PlanetScope basemap satellite images to train a multi-task deep learning model that predicts building density and building height at a 37.6-meter per pixel resolution. We apply this model to global PlanetScope basemaps from Q1 2018 through Q2 2025 to create global, temporal maps of building density and height. We validate these maps by comparing against existing building footprint datasets. Our estimates achieve an F1 score between 85% and 88% on different hand-labeled subsets, and are temporally stable, with a 0.96 five-year trend-consistency score. TEMPO captures quarterly changes in built settlements at a fraction of the computational cost of comparable approaches, unlocking large-scale monitoring of development patterns and climate impacts essential for global resilience and adaptation efforts.

</details>


### [71] [Fine-Grained DINO Tuning with Dual Supervision for Face Forgery Detection](https://arxiv.org/abs/2511.12107)
*Tianxiang Zhang,Peipeng Yu,Zhihua Xia,Longchen Dai,Xiaoyu Zhou,Hui Gao*

Main category: cs.CV

TL;DR: 提出了DFF-Adapter方法，通过轻量化多任务优化提升DINOv2对深度伪造的检测能力，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法将DINOv2视为通用的二分类任务，忽略了不同深度伪造方法的独特伪影特征。

Method: 提出了DFF-Adapter方法，通过在每个Transformer块中嵌入轻量级多头部LoRA模块，实现高效的主干网络适配。

Result: 仅使用350万个可训练参数，DFF-Adapter在检测准确率上与或超过现有复杂方法。

Conclusion: DFF-Adapter通过轻量化的多任务优化和参数高效的设计，在检测准确率上达到或超越了当前复杂的先进方法。

Abstract: The proliferation of sophisticated deepfakes poses significant threats to information integrity. While DINOv2 shows promise for detection, existing fine-tuning approaches treat it as generic binary classification, overlooking distinct artifacts inherent to different deepfake methods. To address this, we propose a DeepFake Fine-Grained Adapter (DFF-Adapter) for DINOv2. Our method incorporates lightweight multi-head LoRA modules into every transformer block, enabling efficient backbone adaptation. DFF-Adapter simultaneously addresses authenticity detection and fine-grained manipulation type classification, where classifying forgery methods enhances artifact sensitivity. We introduce a shared branch propagating fine-grained manipulation cues to the authenticity head. This enables multi-task cooperative optimization, explicitly enhancing authenticity discrimination with manipulation-specific knowledge. Utilizing only 3.5M trainable parameters, our parameter-efficient approach achieves detection accuracy comparable to or even surpassing that of current complex state-of-the-art methods.

</details>


### [72] [MediRound: Multi-Round Entity-Level Reasoning Segmentation in Medical Images](https://arxiv.org/abs/2511.12110)
*Qinyue Tong,Ziqian Lu,Jun Liu,Rui Zuo,Zheming Lu*

Main category: cs.CV

TL;DR: 提出MEMR-Seg任务及MediRound模型，通过多轮实体级对话和纠错机制提升医学图像分割的交互性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有医学图像分割方法缺乏交互性和多轮推理能力，MEMR-Seg任务旨在通过多轮实体级对话提升分割的灵活性和用户驱动性。

Method: 提出MediRound基线模型，结合轻量级Judgment & Correction Mechanism，解决多轮分割中的错误传播问题。

Result: 实验证明MEMR-Seg任务和MediRound模型在性能上超越传统医学参考分割方法。

Conclusion: MEMR-Seg任务通过多轮实体级推理对话有效提升了医学图像分割的交互性和灵活性，MediRound模型及Judgment & Correction Mechanism显著优于传统方法。

Abstract: Despite the progress in medical image segmentation, most existing methods remain task-specific and lack interactivity. Although recent text-prompt-based segmentation approaches enhance user-driven and reasoning-based segmentation, they remain confined to single-round dialogues and fail to perform multi-round reasoning. In this work, we introduce Multi-Round Entity-Level Medical Reasoning Segmentation (MEMR-Seg), a new task that requires generating segmentation masks through multi-round queries with entity-level reasoning. To support this task, we construct MR-MedSeg, a large-scale dataset of 177K multi-round medical segmentation dialogues, featuring entity-based reasoning across rounds. Furthermore, we propose MediRound, an effective baseline model designed for multi-round medical reasoning segmentation. To mitigate the inherent error propagation in the chain-like pipeline of multi-round segmentation, we introduce a lightweight yet effective Judgment & Correction Mechanism during model inference. Experimental results demonstrate that our method effectively addresses the MEMR-Seg task and outperforms conventional medical referring segmentation methods.

</details>


### [73] [RadarMP: Motion Perception for 4D mmWave Radar in Autonomous Driving](https://arxiv.org/abs/2511.12117)
*Ruiqi Cheng,Huijun Di,Jian Li,Feng Liu,Wei Liang*

Main category: cs.CV

TL;DR: RadarMP是一种新型方法，通过联合建模雷达目标检测和运动估计，利用自监督损失实现精确的3D场景运动感知，提升自动驾驶系统在全场景下的感知能力。


<details>
  <summary>Details</summary>
Motivation: 4D毫米波雷达因其全天候操作能力和独特感知特性成为自动驾驶的关键组件，但稀疏和噪声的雷达点常导致运动感知不精确，尤其在光学传感器性能下降的恶劣天气条件下。

Method: RadarMP利用两帧连续的低级雷达回波信号，设计了一个统一的架构，结合自监督损失函数（由多普勒频移和回波强度指导），无需显式标注即可监督空间和运动一致性。

Result: 在公开数据集上的广泛实验表明，RadarMP在各种天气和光照条件下实现了可靠的3D场景运动感知，性能优于基于雷达的解耦运动感知流程。

Conclusion: RadarMP通过联合建模雷达目标检测和运动估计，实现了精确的3D场景运动感知，显著提升了自动驾驶系统在各种天气和光照条件下的感知能力。

Abstract: Accurate 3D scene motion perception significantly enhances the safety and reliability of an autonomous driving system. Benefiting from its all-weather operational capability and unique perceptual properties, 4D mmWave radar has emerged as an essential component in advanced autonomous driving. However, sparse and noisy radar points often lead to imprecise motion perception, leaving autonomous vehicles with limited sensing capabilities when optical sensors degrade under adverse weather conditions. In this paper, we propose RadarMP, a novel method for precise 3D scene motion perception using low-level radar echo signals from two consecutive frames. Unlike existing methods that separate radar target detection and motion estimation, RadarMP jointly models both tasks in a unified architecture, enabling consistent radar point cloud generation and pointwise 3D scene flow prediction. Tailored to radar characteristics, we design specialized self-supervised loss functions guided by Doppler shifts and echo intensity, effectively supervising spatial and motion consistency without explicit annotations. Extensive experiments on the public dataset demonstrate that RadarMP achieves reliable motion perception across diverse weather and illumination conditions, outperforming radar-based decoupled motion perception pipelines and enhancing perception capabilities for full-scenario autonomous driving systems.

</details>


### [74] [OAD-Promoter: Enhancing Zero-shot VQA using Large Language Models with Object Attribute Description](https://arxiv.org/abs/2511.12131)
*Quanxing Xu,Ling Zhou,Feifei Zhang,Jinyu Tian,Rubing Huang*

Main category: cs.CV

TL;DR: OAD-Promoter是一种新方法，通过减少语言偏见和增强领域转移鲁棒性，提升LLM在VQA中的性能，尤其在少样本或零样本场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在视觉问答（VQA）中处理知识密集型问题时存在语言偏见和领域转移鲁棒性不足的问题，限制了其在少样本或零样本场景下的可靠性。

Method: OAD-Promoter由三个组件组成：对象集中示例生成（OEG）模块、记忆知识辅助（MKA）模块和OAD提示。OEG模块生成全局描述和对象集中样本，增强视觉信息输入并减少偏见；MKA模块通过检索相关知识辅助处理OOD样本；OAD提示整合前两个模块的输出以优化LLM推理。

Result: 实验表明，OAD-Promoter显著提升了基于LLM的VQA方法的性能，尤其在少样本或零样本设置下达到了新的最先进水平。

Conclusion: OAD-Promoter通过减少语言偏见和增强领域转移鲁棒性，显著提升了基于LLM的VQA方法在少样本或零样本场景下的性能，实现了新的最先进结果。

Abstract: Large Language Models (LLMs) have become a crucial tool in Visual Question Answering (VQA) for handling knowledge-intensive questions in few-shot or zero-shot scenarios. However, their reliance on massive training datasets often causes them to inherit language biases during the acquisition of knowledge. This limitation imposes two key constraints on existing methods: (1) LLM predictions become less reliable due to bias exploitation, and (2) despite strong knowledge reasoning capabilities, LLMs still struggle with out-of-distribution (OOD) generalization. To address these issues, we propose Object Attribute Description Promoter (OAD-Promoter), a novel approach for enhancing LLM-based VQA by mitigating language bias and improving domain-shift robustness. OAD-Promoter comprises three components: the Object-concentrated Example Generation (OEG) module, the Memory Knowledge Assistance (MKA) module, and the OAD Prompt. The OEG module generates global captions and object-concentrated samples, jointly enhancing visual information input to the LLM and mitigating bias through complementary global and regional visual cues. The MKA module assists the LLM in handling OOD samples by retrieving relevant knowledge from stored examples to support questions from unseen domains. Finally, the OAD Prompt integrates the outputs of the preceding modules to optimize LLM inference. Experiments demonstrate that OAD-Promoter significantly improves the performance of LLM-based VQA methods in few-shot or zero-shot settings, achieving new state-of-the-art results.

</details>


### [75] [Compression and Inference of Spiking Neural Networks on Resource-Constrained Hardware](https://arxiv.org/abs/2511.12136)
*Karol C. Jurzec,Tomasz Szydlo,Maciej Wielgosz*

Main category: cs.CV

TL;DR: Optimized C-based runtime for SNNs on edge devices reduces latency/memory, enabling efficient deployment on embedded platforms.


<details>
  <summary>Details</summary>
Motivation: Training and deployment of SNNs remain challenging despite their advantages for temporal processing and energy efficiency on resource-constrained hardware.

Method: A lightweight C-based runtime for SNN inference on edge devices with optimizations to reduce latency and memory, including static, cache-friendly data layouts, preallocation, and exploiting sparse spiking activity to prune inactive neurons and synapses.

Result: Achieves ~10x speedups on desktop CPU with functional parity to Python baseline, along with memory reductions enabling microcontroller deployment (Arduino Portenta H7).

Conclusion: SNNs can be efficiently executed on conventional embedded platforms when paired with an optimized runtime and spike-driven model compression.

Abstract: Spiking neural networks (SNNs) communicate via discrete spikes in time rather than continuous activations. Their event-driven nature offers advantages for temporal processing and energy efficiency on resource-constrained hardware, but training and deployment remain challenging. We present a lightweight C-based runtime for SNN inference on edge devices and optimizations that reduce latency and memory without sacrificing accuracy. Trained models exported from SNNTorch are translated to a compact C representation; static, cache-friendly data layouts and preallocation avoid interpreter and allocation overheads. We further exploit sparse spiking activity to prune inactive neurons and synapses, shrinking computation in upstream convolutional layers. Experiments on N-MNIST and ST-MNIST show functional parity with the Python baseline while achieving ~10 speedups on desktop CPU and additional gains with pruning, together with large memory reductions that enable microcontroller deployment (Arduino Portenta H7). Results indicate that SNNs can be executed efficiently on conventional embedded platforms when paired with an optimized runtime and spike-driven model compression. Code: https://github.com/karol-jurzec/snn-generator/

</details>


### [76] [MAVIS: A Benchmark for Multimodal Source Attribution in Long-form Visual Question Answering](https://arxiv.org/abs/2511.12142)
*Seokwon Song,Minsu Park,Gunhee Kim*

Main category: cs.CV

TL;DR: MAVIS是首个评估多模态源属性系统的基准，数据集包含157K视觉问答实例，研究揭示了多模态RAG的优势与图像文档的局限性，并提出了未来方向。


<details>
  <summary>Details</summary>
Motivation: 现有工作主要关注纯文本场景，忽视了多模态在源属性中的作用，因此需要构建一个多模态源属性评估基准。

Method: 开发了细粒度的自动评估指标，涵盖信息性、基础性和流畅性三个维度，并通过人类判断验证其相关性。

Result: 研究发现：(1) 多模态RAG生成的信息更丰富、流畅，但图像文档的基础性较弱；(2) 不同提示方法在信息性和基础性之间存在权衡；(3) 未来需解决图像文档的上下文偏见问题。

Conclusion: 论文提出了MAVIS基准，用于评估多模态源属性系统，并揭示了现有系统在图像文档中的局限性，提出了未来研究方向。

Abstract: Source attribution aims to enhance the reliability of AI-generated answers by including references for each statement, helping users validate the provided answers. However, existing work has primarily focused on text-only scenario and largely overlooked the role of multimodality. We introduce MAVIS, the first benchmark designed to evaluate multimodal source attribution systems that understand user intent behind visual questions, retrieve multimodal evidence, and generate long-form answers with citations. Our dataset comprises 157K visual QA instances, where each answer is annotated with fact-level citations referring to multimodal documents. We develop fine-grained automatic metrics along three dimensions of informativeness, groundedness, and fluency, and demonstrate their strong correlation with human judgments. Our key findings are threefold: (1) LVLMs with multimodal RAG generate more informative and fluent answers than unimodal RAG, but they exhibit weaker groundedness for image documents than for text documents, a gap amplified in multimodal settings. (2) Given the same multimodal documents, there is a trade-off between informativeness and groundedness across different prompting methods. (3) Our proposed method highlights mitigating contextual bias in interpreting image documents as a crucial direction for future research. The dataset and experimental code are available at https://github.com/seokwon99/MAVIS

</details>


### [77] [Breaking the Modality Wall: Time-step Mixup for Efficient Spiking Knowledge Transfer from Static to Event Domain](https://arxiv.org/abs/2511.12150)
*Yuqi Xie,Shuhan Ye,Yi Yu,Chong Wang,Qixin Zhang,Jiazhen Xu,Le Shen,Yuanbin Qian,Jiangbo Qian,Guoqi Li*

Main category: cs.CV

TL;DR: TMKT通过时间步混合和模态感知目标，优化跨模态知识迁移，提升尖峰图像分类性能。


<details>
  <summary>Details</summary>
Motivation: 事件相机与尖峰神经网络（SNNs）的结合虽能实现高效视觉智能，但事件数据稀缺和DVS输出稀疏性阻碍了有效训练，且RGB到DVS的先验知识迁移因模态分布差异表现不佳。

Method: 提出了时间步混合知识迁移（TMKT）框架，包含时间步混合（TSM）策略和两个轻量级模态感知目标（MAG和MRP），以减少梯度方差并稳定优化。

Result: TMKT在多样化的基准测试和多种SNN骨干网络中通过实验验证了其有效性，并通过消融研究展示了方法的优越性。

Conclusion: TMKT框架通过时间步混合和模态感知目标，显著提升了跨模态知识迁移的效果，并在尖峰图像分类任务中取得了优越性能。

Abstract: The integration of event cameras and spiking neural networks (SNNs) promises energy-efficient visual intelligence, yet scarce event data and the sparsity of DVS outputs hinder effective training. Prior knowledge transfers from RGB to DVS often underperform because the distribution gap between modalities is substantial. In this work, we present Time-step Mixup Knowledge Transfer (TMKT), a cross-modal training framework with a probabilistic Time-step Mixup (TSM) strategy. TSM exploits the asynchronous nature of SNNs by interpolating RGB and DVS inputs at various time steps to produce a smooth curriculum within each sequence, which reduces gradient variance and stabilizes optimization with theoretical analysis. To employ auxiliary supervision from TSM, TMKT introduces two lightweight modality-aware objectives, Modality Aware Guidance (MAG) for per-frame source supervision and Mixup Ratio Perception (MRP) for sequence-level mix ratio estimation, which explicitly align temporal features with the mixing schedule. TMKT enables smoother knowledge transfer, helps mitigate modality mismatch during training, and achieves superior performance in spiking image classification tasks. Extensive experiments across diverse benchmarks and multiple SNN backbones, together with ablations, demonstrate the effectiveness of our method.

</details>


### [78] [FIA-Edit: Frequency-Interactive Attention for Efficient and High-Fidelity Inversion-Free Text-Guided Image Editing](https://arxiv.org/abs/2511.12151)
*Kaixiang Yang,Boyang Shen,Xin Li,Yuchen Dai,Yuxuan Luo,Yueran Ma,Wei Fang,Qiang Li,Zhiwei Wang*

Main category: cs.CV

TL;DR: FIA-Edit是一种高效的无反转图像编辑框架，通过频率交互注意力实现高保真编辑，并在医疗图像处理中展示了新应用。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于流的无反转方法在背景保留、空间一致性和过度编辑方面的问题。

Method: 提出了两个关键组件：Frequency Representation Interaction (FRI)模块和Feature Injection (FIJ)模块，分别用于增强跨域对齐和显式整合源信息。

Result: FIA-Edit在低计算成本下支持高保真编辑，并在视觉质量、背景保真度和可控性方面优于现有方法。

Conclusion: FIA-Edit通过Frequency-Interactive Attention实现了高保真和语义精确的图像编辑，并在医疗领域展示了新的应用潜力。

Abstract: Text-guided image editing has advanced rapidly with the rise of diffusion models. While flow-based inversion-free methods offer high efficiency by avoiding latent inversion, they often fail to effectively integrate source information, leading to poor background preservation, spatial inconsistencies, and over-editing due to the lack of effective integration of source information. In this paper, we present FIA-Edit, a novel inversion-free framework that achieves high-fidelity and semantically precise edits through a Frequency-Interactive Attention. Specifically, we design two key components: (1) a Frequency Representation Interaction (FRI) module that enhances cross-domain alignment by exchanging frequency components between source and target features within self-attention, and (2) a Feature Injection (FIJ) module that explicitly incorporates source-side queries, keys, values, and text embeddings into the target branch's cross-attention to preserve structure and semantics. Comprehensive and extensive experiments demonstrate that FIA-Edit supports high-fidelity editing at low computational cost (~6s per 512 * 512 image on an RTX 4090) and consistently outperforms existing methods across diverse tasks in visual quality, background fidelity, and controllability. Furthermore, we are the first to extend text-guided image editing to clinical applications. By synthesizing anatomically coherent hemorrhage variations in surgical images, FIA-Edit opens new opportunities for medical data augmentation and delivers significant gains in downstream bleeding classification. Our project is available at: https://github.com/kk42yy/FIA-Edit.

</details>


### [79] [Codebook-Centric Deep Hashing: End-to-End Joint Learning of Semantic Hash Centers and Neural Hash Function](https://arxiv.org/abs/2511.12162)
*Shuo Yin,Zhiyuan Yin,Yuqing Hou,Rui Liu,Yong Chen,Dell Zhang*

Main category: cs.CV

TL;DR: CRH是一种端到端的深度哈希框架，动态调整哈希中心并联合优化哈希函数，避免了显式的中心优化阶段，通过多头机制提升语义表示能力，实验证明其在检索任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于哈希中心的方法因随机初始化中心而忽略类间语义关系，两阶段方法虽能缓解此问题，但引入额外复杂性和计算开销，且因阶段不一致性导致性能次优。

Method: CRH框架动态重新分配预设码本中的哈希中心，并联合优化哈希函数。该方法采用多头机制增强哈希中心的表示能力，避免显式的中心优化阶段。

Result: 在三个基准测试上的广泛实验表明，CRH能够学习到具有语义意义的哈希中心，并在检索任务中优于现有的深度哈希方法。

Conclusion: CRH提出了一种端到端的框架，通过动态重新分配预设码本中的哈希中心并联合优化哈希函数，有效解决了现有方法中的阶段不一致性问题。该方法不仅避免了显式的中心优化阶段，还通过多头机制增强了哈希中心的表示能力，从而在检索任务中优于现有的深度哈希方法。

Abstract: Hash center-based deep hashing methods improve upon pairwise or triplet-based approaches by assigning fixed hash centers to each class as learning targets, thereby avoiding the inefficiency of local similarity optimization. However, random center initialization often disregards inter-class semantic relationships. While existing two-stage methods mitigate this by first refining hash centers with semantics and then training the hash function, they introduce additional complexity, computational overhead, and suboptimal performance due to stage-wise discrepancies. To address these limitations, we propose $\textbf{Center-Reassigned Hashing (CRH)}$, an end-to-end framework that $\textbf{dynamically reassigns hash centers}$ from a preset codebook while jointly optimizing the hash function. Unlike previous methods, CRH adapts hash centers to the data distribution $\textbf{without explicit center optimization phases}$, enabling seamless integration of semantic relationships into the learning process. Furthermore, $\textbf{a multi-head mechanism}$ enhances the representational capacity of hash centers, capturing richer semantic structures. Extensive experiments on three benchmarks demonstrate that CRH learns semantically meaningful hash centers and outperforms state-of-the-art deep hashing methods in retrieval tasks.

</details>


### [80] [Rethinking Multimodal Point Cloud Completion: A Completion-by-Correction Perspective](https://arxiv.org/abs/2511.12170)
*Wang Luo,Di Wu,Hengyuan Na,Yinlin Zhu,Miao Hu,Guocong Quan*

Main category: cs.CV

TL;DR: PGNet提出Completion-by-Correction范式，通过双特征编码和层次修正实现更鲁棒的点云补全，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统Completion-by-Inpainting范式因几何和语义约束不足导致结构不一致和拓扑伪影，需更鲁棒的补全方法。

Method: 提出了Completion-by-Correction范式和PGNet框架，包括双特征编码、结构对齐的粗粒度支架生成和层次化细节修正。

Result: 在ShapeNetViPC数据集上，PGNet的平均Chamfer Distance降低23.5%，F-score提升7.1%。

Conclusion: PGNet通过Completion-by-Correction范式显著提升了点云补全的结构一致性和几何对齐性，实验结果表明其在ShapeNetViPC数据集上优于现有方法。

Abstract: Point cloud completion aims to reconstruct complete 3D shapes from partial observations, which is a challenging problem due to severe occlusions and missing geometry. Despite recent advances in multimodal techniques that leverage complementary RGB images to compensate for missing geometry, most methods still follow a Completion-by-Inpainting paradigm, synthesizing missing structures from fused latent features. We empirically show that this paradigm often results in structural inconsistencies and topological artifacts due to limited geometric and semantic constraints. To address this, we rethink the task and propose a more robust paradigm, termed Completion-by-Correction, which begins with a topologically complete shape prior generated by a pretrained image-to-3D model and performs feature-space correction to align it with the partial observation. This paradigm shifts completion from unconstrained synthesis to guided refinement, enabling structurally consistent and observation-aligned reconstruction. Building upon this paradigm, we introduce PGNet, a multi-stage framework that conducts dual-feature encoding to ground the generative prior, synthesizes a coarse yet structurally aligned scaffold, and progressively refines geometric details via hierarchical correction. Experiments on the ShapeNetViPC dataset demonstrate the superiority of PGNet over state-of-the-art baselines in terms of average Chamfer Distance (-23.5%) and F-score (+7.1%).

</details>


### [81] [MixAR: Mixture Autoregressive Image Generation](https://arxiv.org/abs/2511.12181)
*Jinyuan Hu,Jiayou Zhang,Shaobo Cui,Kun Zhang,Guangyi Chen*

Main category: cs.CV

TL;DR: MixAR通过混合离散和连续自回归建模策略，解决了传统方法的局限性，提升了生成质量。


<details>
  <summary>Details</summary>
Motivation: 传统自回归方法因量化过程和有限码本大小导致细粒度信息丢失，限制了生成质量。为解决这一问题，研究探索了连续潜在空间的自回归建模，但面临高效建模的挑战。

Method: MixAR框架采用离散令牌作为连续自回归建模的先验指导，探索了多种离散-连续混合策略（如DC-SA、DC-CA、DC-Mix），并提出了训练-推断混合（TI-Mix）以确保训练与生成分布的一致性。

Result: 实验表明，DC-Mix策略在计算效率和生成保真度之间表现优异，TI-Mix方法进一步提升了生成一致性。

Conclusion: MixAR框架通过混合离散和连续自回归建模策略，显著提升了生成质量，并在计算效率和生成保真度之间取得了良好平衡。

Abstract: Autoregressive (AR) approaches, which represent images as sequences of discrete tokens from a finite codebook, have achieved remarkable success in image generation. However, the quantization process and the limited codebook size inevitably discard fine-grained information, placing bottlenecks on fidelity. Motivated by this limitation, recent studies have explored autoregressive modeling in continuous latent spaces, which offers higher generation quality. Yet, unlike discrete tokens constrained by a fixed codebook, continuous representations lie in a vast and unstructured space, posing significant challenges for efficient autoregressive modeling. To address these challenges, we introduce MixAR, a novel framework that leverages mixture training paradigms to inject discrete tokens as prior guidance for continuous AR modeling. MixAR is a factorized formulation that leverages discrete tokens as prior guidance for continuous autoregressive prediction. We investigate several discrete-continuous mixture strategies, including self-attention (DC-SA), cross-attention (DC-CA), and a simple approach (DC-Mix) that replaces homogeneous mask tokens with informative discrete counterparts. Moreover, to bridge the gap between ground-truth training tokens and inference tokens produced by the pre-trained AR model, we propose Training-Inference Mixture (TI-Mix) to achieve consistent training and generation distributions. In our experiments, we demonstrate a favorable balance of the DC-Mix strategy between computational efficiency and generation fidelity, and consistent improvement of TI-Mix.

</details>


### [82] [MMRINet: Efficient Mamba-Based Segmentation with Dual-Path Refinement for Low-Resource MRI Analysis](https://arxiv.org/abs/2511.12193)
*Abdelrahman Elsayed,Ahmed Jaheen,Mohammad Yaqub*

Main category: cs.CV

TL;DR: MMRINet是一种轻量级架构，通过高效的特征处理模块在资源受限环境中实现高精度脑肿瘤分割。


<details>
  <summary>Details</summary>
Motivation: 解决资源受限环境下深度3D网络计算成本高的问题，提升多参数MRI中脑肿瘤分割的效率。

Method: 采用线性复杂度的Mamba状态空间模型替代二次复杂度的注意力机制，结合双路径特征细化（DPFR）模块和渐进式特征聚合（PFA）实现多尺度融合。

Result: 在BraTS-Lighthouse SSA 2025中，模型仅用约250万参数即达到平均Dice分数0.752和平均HD95分数12.23的强性能。

Conclusion: MMRINet通过轻量级架构和高效的特征处理模块，在资源受限的环境中实现了准确且高效的脑肿瘤分割，适合低资源临床环境。

Abstract: Automated brain tumor segmentation in multi-parametric MRI remains challenging in resource-constrained settings where deep 3D networks are computationally prohibitive. We propose MMRINet, a lightweight architecture that replaces quadratic-complexity attention with linear-complexity Mamba state-space models for efficient volumetric context modeling. Novel Dual-Path Feature Refinement (DPFR) modules maximize feature diversity without additional data requirements, while Progressive Feature Aggregation (PFA) enables effective multi-scale fusion. In the BraTS-Lighthouse SSA 2025, our model achieves strong performance with an average Dice score of (0.752) and an average HD95 of (12.23) with only ~2.5M parameters, demonstrating efficient and accurate segmentation suitable for low-resource clinical environments. Our GitHub repository can be accessed here: github.com/BioMedIA-MBZUAI/MMRINet.

</details>


### [83] [Cross-View Cross-Modal Unsupervised Domain Adaptation for Driver Monitoring System](https://arxiv.org/abs/2511.12196)
*Aditi Bhalla,Christian Hellert,Enkelejda Kasneci*

Main category: cs.CV

TL;DR: 论文提出了一种两阶段跨视图、跨模态无监督域适应框架，显著提升了驾驶员活动识别的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 驾驶员分心是交通事故的主要原因，现有方法在跨视图泛化和无监督域适应方面存在局限性，难以实现模型在多样化车辆配置中的鲁棒部署。

Method: 研究采用了两阶段方法：第一阶段通过对比学习在多视图数据中学习视图不变和动作区分特征；第二阶段使用信息瓶颈损失进行域适应，无需新域的标记数据。

Result: 实验表明，该框架在RGB视频数据上的top-1准确率比基于监督对比学习的跨视图方法提高了近50%，同时比仅使用无监督域适应的方法高出5%。

Conclusion: 该论文提出的两阶段跨视图、跨模态无监督域适应框架显著提升了驾驶员活动识别的准确性和鲁棒性，尤其在处理不同视角和模态变化时表现出色。

Abstract: Driver distraction remains a leading cause of road traffic accidents, contributing to thousands of fatalities annually across the globe. While deep learning-based driver activity recognition methods have shown promise in detecting such distractions, their effectiveness in real-world deployments is hindered by two critical challenges: variations in camera viewpoints (cross-view) and domain shifts such as change in sensor modality or environment. Existing methods typically address either cross-view generalization or unsupervised domain adaptation in isolation, leaving a gap in the robust and scalable deployment of models across diverse vehicle configurations. In this work, we propose a novel two-phase cross-view, cross-modal unsupervised domain adaptation framework that addresses these challenges jointly on real-time driver monitoring data. In the first phase, we learn view-invariant and action-discriminative features within a single modality using contrastive learning on multi-view data. In the second phase, we perform domain adaptation to a new modality using information bottleneck loss without requiring any labeled data from the new domain. We evaluate our approach using state-of-the art video transformers (Video Swin, MViT) and multi modal driver activity dataset called Drive&Act, demonstrating that our joint framework improves top-1 accuracy on RGB video data by almost 50% compared to a supervised contrastive learning-based cross-view method, and outperforms unsupervised domain adaptation-only methods by up to 5%, using the same video transformer backbone.

</details>


### [84] [Bridging Granularity Gaps: Hierarchical Semantic Learning for Cross-domain Few-shot Segmentation](https://arxiv.org/abs/2511.12200)
*Sujun Sun,Haowen Gu,Cheng Xie,Yanxu Ren,Mingwu Ren,Haofeng Zhang*

Main category: cs.CV

TL;DR: HSL框架通过DSR和HSM模块解决跨域小样本分割中的语义粒度差距问题，实验证明其性能优越。


<details>
  <summary>Details</summary>
Motivation: 现有CD-FSS方法主要关注源域和目标域之间的风格差异，忽视了分割粒度差异，导致目标域中新类别的语义区分能力不足。

Method: 提出了Hierarchical Semantic Learning (HSL)框架，包含Dual Style Randomization (DSR)模块和Hierarchical Semantic Mining (HSM)模块，分别用于模拟目标域数据风格差异和多粒度语义挖掘。此外，还引入了Prototype Confidence-modulated Thresholding (PCMT)模块以减少分割模糊性。

Result: 在四个流行的目标域数据集上进行的大量实验表明，该方法实现了最先进的性能。

Conclusion: 提出的HSL框架通过DSR和HSM模块有效解决了跨域小样本分割中的语义粒度差距问题，显著提升了模型在目标域中的语义识别能力，并在实验中取得了最先进的性能。

Abstract: Cross-domain Few-shot Segmentation (CD-FSS) aims to segment novel classes from target domains that are not involved in training and have significantly different data distributions from the source domain, using only a few annotated samples, and recent years have witnessed significant progress on this task. However, existing CD-FSS methods primarily focus on style gaps between source and target domains while ignoring segmentation granularity gaps, resulting in insufficient semantic discriminability for novel classes in target domains. Therefore, we propose a Hierarchical Semantic Learning (HSL) framework to tackle this problem. Specifically, we introduce a Dual Style Randomization (DSR) module and a Hierarchical Semantic Mining (HSM) module to learn hierarchical semantic features, thereby enhancing the model's ability to recognize semantics at varying granularities. DSR simulates target domain data with diverse foreground-background style differences and overall style variations through foreground and global style randomization respectively, while HSM leverages multi-scale superpixels to guide the model to mine intra-class consistency and inter-class distinction at different granularities. Additionally, we also propose a Prototype Confidence-modulated Thresholding (PCMT) module to mitigate segmentation ambiguity when foreground and background are excessively similar. Extensive experiments are conducted on four popular target domain datasets, and the results demonstrate that our method achieves state-of-the-art performance.

</details>


### [85] [OmniSparse: Training-Aware Fine-Grained Sparse Attention for Long-Video MLLMs](https://arxiv.org/abs/2511.12201)
*Feng Chen,Yefei He,Shaoxuan He,Yuanyu He,Jing Liu,Lequan Lin,Akide Liu,Zhaoyang Li,Jiyuan Zhang,Zhenbang Sun,Bohan Zhuang,Qi Wu*

Main category: cs.CV

TL;DR: OmniSparse 是一种训练感知的细粒度稀疏注意力框架，通过动态令牌预算分配在多维度优化长视频MLLMs的注意力机制，实现高效性能。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏注意力方法在训练-推理间存在差距，且缺乏多维度细粒度令牌选择能力，导致性能次优和加速收益有限。

Method: OmniSparse 包含三种自适应互补机制：查询选择（通过懒-活跃分类）、KV选择（头部级动态预算分配）和KV缓存瘦身（基于头部级解码查询模式选择性获取视觉KV缓存）。

Result: 实验结果显示，OmniSparse 在性能上与完整注意力相当，同时在预填充和解码阶段实现了显著的加速和内存优化。

Conclusion: OmniSparse 在保持与完整注意力相当性能的同时，实现了预填充阶段2.7倍加速和解码阶段2.4倍内存减少。

Abstract: Existing sparse attention methods primarily target inference-time acceleration by selecting critical tokens under predefined sparsity patterns. However, they often fail to bridge the training-inference gap and lack the capacity for fine-grained token selection across multiple dimensions such as queries, key-values (KV), and heads, leading to suboptimal performance and limited acceleration gains. In this paper, we introduce OmniSparse, a training-aware fine-grained sparse attention framework for long-video MLLMs, which operates in both training and inference with dynamic token budget allocation. Specifically, OmniSparse contains three adaptive and complementary mechanisms: (1) query selection via lazy-active classification, retaining active queries that capture broad semantic similarity while discarding most lazy ones that focus on limited local context and exhibit high functional redundancy; (2) KV selection with head-level dynamic budget allocation, where a shared budget is determined based on the flattest head and applied uniformly across all heads to ensure attention recall; and (3) KV cache slimming to reduce head-level redundancy by selectively fetching visual KV cache according to the head-level decoding query pattern. Experimental results show that OmniSparse matches the performance of full attention while achieving up to 2.7x speedup during prefill and 2.4x memory reduction during decoding.

</details>


### [86] [LSS3D: Learnable Spatial Shifting for Consistent and High-Quality 3D Generation from Single-Image](https://arxiv.org/abs/2511.12202)
*Zhuojiang Cai,Yiheng Zhang,Meitong Guo,Mingdao Wang,Yuwang Wang*

Main category: cs.CV

TL;DR: LSS3D通过可学习空间移位和多视角一致性优化，提升了3D生成的质量和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决现有多视角扩散3D生成方法在多视角图像形状和纹理不对齐、非正面输入视角鲁棒性差的问题。

Method: 通过为每个视角分配可学习的空间移位参数，并利用重建的网格引导调整，实现多视角一致性。同时，将输入视角作为优化约束，增强对非正面输入的处理能力。

Result: 实验表明，LSS3D在几何和纹理评估指标上均取得领先结果，尤其适用于更灵活的输入视角。

Conclusion: LSS3D方法在多视角3D生成中表现出色，尤其在几何细节和纹理质量上优于现有方法，且对非正面输入视角具有更强的鲁棒性。

Abstract: Recently, multi-view diffusion-based 3D generation methods have gained significant attention. However, these methods often suffer from shape and texture misalignment across generated multi-view images, leading to low-quality 3D generation results, such as incomplete geometric details and textural ghosting. Some methods are mainly optimized for the frontal perspective and exhibit poor robustness to oblique perspective inputs. In this paper, to tackle the above challenges, we propose a high-quality image-to-3D approach, named LSS3D, with learnable spatial shifting to explicitly and effectively handle the multiview inconsistencies and non-frontal input view. Specifically, we assign learnable spatial shifting parameters to each view, and adjust each view towards a spatially consistent target, guided by the reconstructed mesh, resulting in high-quality 3D generation with more complete geometric details and clean textures. Besides, we include the input view as an extra constraint for the optimization, further enhancing robustness to non-frontal input angles, especially for elevated viewpoint inputs. We also provide a comprehensive quantitative evaluation pipeline that can contribute to the community in performance comparisons. Extensive experiments demonstrate that our method consistently achieves leading results in both geometric and texture evaluation metrics across more flexible input viewpoints.

</details>


### [87] [GeoMVD: Geometry-Enhanced Multi-View Generation Model Based on Geometric Information Extraction](https://arxiv.org/abs/2511.12204)
*Jiaqi Wu,Yaosen Chen,Shuyuan Zhu*

Main category: cs.CV

TL;DR: 提出Geometry-guided Multi-View Diffusion Model，通过几何信息提取和注意力机制改进多视图生成的一致性和细节。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在多视图一致性和高分辨率生成中的计算挑战。

Method: 设计多视图几何信息提取模块和解耦几何增强注意力机制，采用自适应学习策略和迭代细化过程。

Result: 生成的图像在视图间一致性和细节保留方面表现优异。

Conclusion: Geometry-guided Multi-View Diffusion Model通过引入几何信息提取和解耦注意力机制，有效提升了多视图生成的一致性和细节丰富度，适用于3D重建、虚拟现实等领域。

Abstract: Multi-view image generation holds significant application value in computer vision, particularly in domains like 3D reconstruction, virtual reality, and augmented reality. Most existing methods, which rely on extending single images, face notable computational challenges in maintaining cross-view consistency and generating high-resolution outputs. To address these issues, we propose the Geometry-guided Multi-View Diffusion Model, which incorporates mechanisms for extracting multi-view geometric information and adjusting the intensity of geometric features to generate images that are both consistent across views and rich in detail. Specifically, we design a multi-view geometry information extraction module that leverages depth maps, normal maps, and foreground segmentation masks to construct a shared geometric structure, ensuring shape and structural consistency across different views. To enhance consistency and detail restoration during generation, we develop a decoupled geometry-enhanced attention mechanism that strengthens feature focus on key geometric details, thereby improving overall image quality and detail preservation. Furthermore, we apply an adaptive learning strategy that fine-tunes the model to better capture spatial relationships and visual coherence between the generated views, ensuring realistic results. Our model also incorporates an iterative refinement process that progressively improves the output quality through multiple stages of image generation. Finally, a dynamic geometry information intensity adjustment mechanism is proposed to adaptively regulate the influence of geometric data, optimizing overall quality while ensuring the naturalness of generated images. More details can be found on the project page: https://github.com/SobeyMIL/GeoMVD.com.

</details>


### [88] [A Novel AI-Driven System for Real-Time Detection of Mirror Absence, Helmet Non-Compliance, and License Plates Using YOLOv8 and OCR](https://arxiv.org/abs/2511.12206)
*Nishant Vasantkumar Hegde,Aditi Agarwal,Minal Moharir*

Main category: cs.CV

TL;DR: 本文提出了一种基于AI的自动化交通违规检测系统，通过YOLOv8和EasyOCR技术识别头盔违规和后视镜缺失，评估结果显示高精确度和召回率，为实际部署提供了有效解决方案。


<details>
  <summary>Details</summary>
Motivation: 道路安全是全球关注的重要问题，但手动执行头盔法律和车辆安全标准（如后视镜存在）资源密集且不一致。

Method: 系统利用YOLOv8进行目标检测和EasyOCR进行车牌识别，基于自定义标注图像数据集（经过增强以提高多样性）训练，识别头盔违规、摩托车后视镜缺失等违规行为，并通过Streamlit界面实现实时监控和违规记录。

Result: 评估结果显示，模型的整体精确度为0.9147，召回率为0.886，平均精确度（mAP@50）为0.843，mAP@50-95为0.503，表明在严格IoU阈值下仍具有强大的检测能力。

Conclusion: 本文展示了一种实用且有效的自动化交通规则执行解决方案，并讨论了实际部署的考虑因素。

Abstract: Road safety is a critical global concern, with manual enforcement of helmet laws and vehicle safety standards (e.g., rear-view mirror presence) being resource-intensive and inconsistent. This paper presents an AI-powered system to automate traffic violation detection, significantly enhancing enforcement efficiency and road safety. The system leverages YOLOv8 for robust object detection and EasyOCR for license plate recognition. Trained on a custom dataset of annotated images (augmented for diversity), it identifies helmet non-compliance, the absence of rear-view mirrors on motorcycles, an innovative contribution to automated checks, and extracts vehicle registration numbers. A Streamlit-based interface facilitates real-time monitoring and violation logging. Advanced image preprocessing enhances license plate recognition, particularly under challenging conditions. Based on evaluation results, the model achieves an overall precision of 0.9147, a recall of 0.886, and a mean Average Precision (mAP@50) of 0.843. The mAP@50 95 of 0.503 further indicates strong detection capability under stricter IoU thresholds. This work demonstrates a practical and effective solution for automated traffic rule enforcement, with considerations for real-world deployment discussed.

</details>


### [89] [Mixture of States: Routing Token-Level Dynamics for Multimodal Generation](https://arxiv.org/abs/2511.12207)
*Haozhe Liu,Ding Liu,Mingchen Zhuge,Zijian Zhou,Tian Xie,Sen He,Yukang Yang,Shuming Liu,Yuren Cong,Jiadong Guo,Hongyu Xu,Ke Xu,Kam-Woh Ng,Juan C. Pérez,Juan-Manuel~Pérez-Rúa,Tao Xiang,Wei Liu,Shikun Liu,Jürgen Schmidhuber*

Main category: cs.CV

TL;DR: MoS是一种新型多模态扩散模型融合方法，通过可学习的稀疏路由器动态交互模态隐藏状态，以极小计算开销实现高效生成和编辑，性能媲美更大模型。


<details>
  <summary>Details</summary>
Motivation: 为了解决多模态扩散模型中模态间交互的灵活性和计算效率问题，提出了MoS范式，旨在通过状态混合实现高效的特征对齐和生成。

Method: MoS采用可学习的令牌级路由器，通过ε-greedy策略稀疏选择前k个隐藏状态，实现多模态间隐藏状态的动态交互，并以最小可学习参数和计算开销精确对齐扩散轨迹中的令牌级特征。

Result: 在文本到图像生成（MoS-Image）和编辑（MoS-Editing）任务中，MoS取得了最先进的性能，3B至5B参数的模型性能媲美或超越参数规模大4倍的模型。

Conclusion: MoS（Mixture of States）作为一种灵活且计算高效的多模态扩散模型融合范式，通过3B至5B参数规模的模型实现了与更大规模模型相媲美或更优的性能，为多模态扩散模型的扩展提供了新方向。

Abstract: We introduce MoS (Mixture of States), a novel fusion paradigm for multimodal diffusion models that merges modalities using flexible, state-based interactions. The core of MoS is a learnable, token-wise router that creates denoising timestep- and input-dependent interactions between modalities' hidden states, precisely aligning token-level features with the diffusion trajectory. This router sparsely selects the top-$k$ hidden states and is trained with an $ε$-greedy strategy, efficiently selecting contextual features with minimal learnable parameters and negligible computational overhead. We validate our design with text-to-image generation (MoS-Image) and editing (MoS-Editing), which achieve state-of-the-art results. With only 3B to 5B parameters, our models match or surpass counterparts up to $4\times$ larger. These findings establish MoS as a flexible and compute-efficient paradigm for scaling multimodal diffusion models.

</details>


### [90] [FaNe: Towards Fine-Grained Cross-Modal Contrast with False-Negative Reduction and Text-Conditioned Sparse Attention](https://arxiv.org/abs/2511.12215)
*Peng Zhang,Zhihui Lai,Wenting Chen,Xu Wu,Heng Kong*

Main category: cs.CV

TL;DR: FaNe通过语义增强的视觉-语言预训练框架，解决了假负样本和细粒度对齐问题，在多个医疗影像任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有医疗视觉-语言预训练方法因语义相似文本导致的假负样本和细粒度跨模态对齐不足而受限，需要改进。

Method: 提出了FaNe框架，包括基于文本-文本相似性的语义感知正对挖掘策略、文本条件稀疏注意力池化模块以及硬负样本感知对比损失。

Result: FaNe在五个医疗影像基准测试中实现了最先进的性能，涵盖图像分类、目标检测和语义分割。

Conclusion: FaNe框架通过在五个下游医疗影像基准测试中实现最先进的性能，验证了其在图像分类、目标检测和语义分割任务中的有效性。

Abstract: Medical vision-language pre-training (VLP) offers significant potential for advancing medical image understanding by leveraging paired image-report data. However, existing methods are limited by Fa}lse Negatives (FaNe) induced by semantically similar texts and insufficient fine-grained cross-modal alignment. To address these limitations, we propose FaNe, a semantic-enhanced VLP framework. To mitigate false negatives, we introduce a semantic-aware positive pair mining strategy based on text-text similarity with adaptive normalization. Furthermore, we design a text-conditioned sparse attention pooling module to enable fine-grained image-text alignment through localized visual representations guided by textual cues. To strengthen intra-modal discrimination, we develop a hard-negative aware contrastive loss that adaptively reweights semantically similar negatives. Extensive experiments on five downstream medical imaging benchmarks demonstrate that FaNe achieves state-of-the-art performance across image classification, object detection, and semantic segmentation, validating the effectiveness of our framework.

</details>


### [91] [Suppressing VLM Hallucinations with Spectral Representation Filtering](https://arxiv.org/abs/2511.12220)
*Ameen Ali,Tamim Zoabi,Lior Wolf*

Main category: cs.CV

TL;DR: SRF是一种无需训练的后处理方法，通过分析特征协方差结构抑制VLMs的幻觉，效果显著且不影响模型性能。


<details>
  <summary>Details</summary>
Motivation: VLMs常因过度依赖语言先验和跨模态基础不精确而产生幻觉，需一种轻量级、无需训练的方法来抑制。

Method: 通过特征协方差结构的分析和校正，SRF识别并减弱低秩幻觉模式，采用软谱滤波器在深层vLLM层中调整特征方差。

Result: SRF在多个VLMs和视觉任务基准上显著降低幻觉率，保持描述质量的同时达到最先进的忠实度。

Conclusion: SRF有效减少了VLMs中的幻觉现象，且在多个模型和任务上表现优异，无需额外训练或架构修改。

Abstract: Vision-language models (VLMs) frequently produce hallucinations in the form of descriptions of objects, attributes, or relations that do not exist in the image due to over-reliance on language priors and imprecise cross-modal grounding. We introduce Spectral Representation Filtering (SRF), a lightweight, training-free method to suppress such hallucinations by analyzing and correcting the covariance structure of the model's representations. SRF identifies low-rank hallucination modes through eigendecomposition of the covariance of the differences between features collected for truthful and hallucinatory captions, revealing structured biases in the feature space. A soft spectral filter then attenuates these modes in the feed-forward projection weights of deeper vLLM layers, equalizing feature variance while preserving semantic fidelity. Unlike decoding or retraining-based approaches, SRF operates entirely post-hoc, incurs zero inference overhead, and requires no architectural modifications. Across three families of VLMs (LLaVA-1.5, MiniGPT-4, and mPLUG-Owl2), SRF consistently reduces hallucination rates on MSCOCO, POPE-VQA, and other visual tasks benchmarks, achieving state-of-the-art faithfulness without degrading caption quality.

</details>


### [92] [Model Inversion Attack Against Deep Hashing](https://arxiv.org/abs/2511.12233)
*Dongdong Zhao,Qiben Xu,Ranxin Fang,Baogang Song*

Main category: cs.CV

TL;DR: DHMI是首个针对深度哈希的扩散式模型反转框架，成功在黑盒设置下重构高质量图像，揭示了深度哈希的隐私风险。


<details>
  <summary>Details</summary>
Motivation: 深度哈希引入了严重的隐私风险，但针对其的模型反转攻击尚未探索，研究填补了这一空白。

Method: 提出DHMI，一种基于扩散的模型反转框架，包括语义哈希中心作为替代锚点、替代引导的去噪优化方法和新型攻击度量。

Result: DHMI在黑盒场景下优于现有方法，成功重构高分辨率、高质量图像。

Conclusion: DHMI证实了深度哈希系统存在的严重隐私风险，并在最具挑战性的黑盒设置下成功重构了高质量图像。

Abstract: Deep hashing improves retrieval efficiency through compact binary codes, yet it introduces severe and often overlooked privacy risks. The ability to reconstruct original training data from hash codes could lead to serious threats such as biometric forgery and privacy breaches. However, model inversion attacks specifically targeting deep hashing models remain unexplored, leaving their security implications unexamined. This research gap stems from the inaccessibility of genuine training hash codes and the highly discrete Hamming space, which prevents existing methods from adapting to deep hashing. To address these challenges, we propose DHMI, the first diffusion-based model inversion framework designed for deep hashing. DHMI first clusters an auxiliary dataset to derive semantic hash centers as surrogate anchors. It then introduces a surrogate-guided denoising optimization method that leverages a novel attack metric (fusing classification consistency and hash proximity) to dynamically select candidate samples. A cluster of surrogate models guides the refinement of these candidates, ensuring the generation of high-fidelity and semantically consistent images. Experiments on multiple datasets demonstrate that DHMI successfully reconstructs high-resolution, high-quality images even under the most challenging black-box setting, where no training hash codes are available. Our method outperforms the existing state-of-the-art model inversion attacks in black-box scenarios, confirming both its practical efficacy and the critical privacy risks inherent in deep hashing systems.

</details>


### [93] [MiniGPT-Pancreas: Multimodal Large Language Model for Pancreas Cancer Classification and Detection](https://arxiv.org/abs/2412.15925)
*Andrea Moglia,Elia Clement Nastasio,Luca Mainardi,Pietro Cerveri*

Main category: cs.CV

TL;DR: MiniGPT-Pancreas通过微调多模态大语言模型，在胰腺检测和分类任务中表现良好，但在肿瘤检测方面仍需改进。


<details>
  <summary>Details</summary>
Motivation: 胰腺放射影像学因器官体积小、边界模糊及形状和位置在患者间的变异性而具有挑战性。目标是开发一种交互式聊天机器人MiniGPT-Pancreas，整合视觉和文本信息以支持临床医生的胰腺癌诊断。

Method: MiniGPT-v2（一种通用多模态大语言模型）通过级联方式微调，用于胰腺检测、肿瘤分类和肿瘤检测，结合了来自NIH和MSD数据集的CT扫描和问题的多模态提示。AbdomenCT-1k数据集用于检测肝脏、脾脏、肾脏和胰腺。

Result: 在NIH和MSD数据集上，胰腺检测的IoU分别为0.595和0.550。MSD数据集上的胰腺癌分类任务准确率、精确率和召回率分别为0.876、0.874和0.878。在AbdomenCT-1k数据集上，多器官检测的IoU分别为肝脏0.8399、肾脏0.722、脾脏0.705和胰腺0.497。胰腺肿瘤检测任务的IoU为0.168。

Conclusion: MiniGPT-Pancreas是一种有前景的解决方案，可支持临床医生对胰腺肿瘤图像进行分类。未来研究需进一步提高检测任务的得分，尤其是胰腺肿瘤检测。

Abstract: Problem: Pancreas radiological imaging is challenging due to the small size, blurred boundaries, and variability of shape and position of the organ among patients. Goal: In this work we present MiniGPT-Pancreas, a Multimodal Large Language Model (MLLM), as an interactive chatbot to support clinicians in pancreas cancer diagnosis by integrating visual and textual information. Methods: MiniGPT-v2, a general-purpose MLLM, was fine-tuned in a cascaded way for pancreas detection, tumor classification, and tumor detection with multimodal prompts combining questions and computed tomography scans from the National Institute of Health (NIH), and Medical Segmentation Decathlon (MSD) datasets. The AbdomenCT-1k dataset was used to detect the liver, spleen, kidney, and pancreas. Results: MiniGPT-Pancreas achieved an Intersection over Union (IoU) of 0.595 and 0.550 for the detection of pancreas on NIH and MSD datasets, respectively. For the pancreas cancer classification task on the MSD dataset, accuracy, precision, and recall were 0.876, 0.874, and 0.878, respectively. When evaluating MiniGPT-Pancreas on the AbdomenCT-1k dataset for multi-organ detection, the IoU was 0.8399 for the liver, 0.722 for the kidney, 0.705 for the spleen, and 0.497 for the pancreas. For the pancreas tumor detection task, the IoU score was 0.168 on the MSD dataset. Conclusions: MiniGPT-Pancreas represents a promising solution to support clinicians in the classification of pancreas images with pancreas tumors. Future research is needed to improve the score on the detection task, especially for pancreas tumors.

</details>


### [94] [Fusionista2.0: Efficiency Retrieval System for Large-Scale Datasets](https://arxiv.org/abs/2511.12255)
*Huy M. Le,Dat Tien Nguyen,Phuc Binh Nguyen,Gia-Bao Le-Tran,Phu Truong Thien,Cuong Dinh,Minh Nguyen,Nga Nguyen,Thuy T. N. Nguyen,Huy Gia Ngo,Tan Nhat Nguyen,Binh T. Nguyen,Monojit Choudhury*

Main category: cs.CV

TL;DR: Fusionista2.0是一个高效、用户友好的视频检索系统，通过优化核心模块和界面设计，显著提升了检索速度和用户体验。


<details>
  <summary>Details</summary>
Motivation: 为满足VBS挑战赛在严格时间限制下提供准确结果的需求，开发了Fusionista2.0，旨在优化速度和可用性。

Method: 系统核心模块进行了效率优化：使用ffmpeg快速提取关键帧，Vintern-1B-v3.5进行鲁棒的多语言文本识别，faster-whisper实现实时语音转录，轻量级视觉语言模型提供快速问答响应。

Result: 评估显示，检索时间减少了高达75%，准确性和用户满意度均有所提升。

Conclusion: Fusionista2.0被证实为一个在大型视频搜索中既具竞争力又用户友好的系统，检索时间减少了75%，同时准确性和用户满意度均有提升。

Abstract: The Video Browser Showdown (VBS) challenges systems to deliver accurate results under strict time constraints. To meet this demand, we present Fusionista2.0, a streamlined video retrieval system optimized for speed and usability. All core modules were re-engineered for efficiency: preprocessing now relies on ffmpeg for fast keyframe extraction, optical character recognition uses Vintern-1B-v3.5 for robust multilingual text recognition, and automatic speech recognition employs faster-whisper for real-time transcription. For question answering, lightweight vision-language models provide quick responses without the heavy cost of large models. Beyond these technical upgrades, Fusionista2.0 introduces a redesigned user interface with improved responsiveness, accessibility, and workflow efficiency, enabling even non-expert users to retrieve relevant content rapidly. Evaluations demonstrate that retrieval time was reduced by up to 75% while accuracy and user satisfaction both increased, confirming Fusionista2.0 as a competitive and user-friendly system for large-scale video search.

</details>


### [95] [Prompt-Conditioned FiLM and Multi-Scale Fusion on MedSigLIP for Low-Dose CT Quality Assessment](https://arxiv.org/abs/2511.12256)
*Tolga Demiroglu,Mehmet Ozan Unal,Metin Ertas,Isa Yildirim*

Main category: cs.CV

TL;DR: 提出一种基于文本提示的框架，通过FiLM和多尺度池化技术，显著提升低剂量CT质量评估性能。


<details>
  <summary>Details</summary>
Motivation: 旨在通过文本提示注入临床意图的先验知识，实现数据高效学习和快速适应，提升低剂量CT图像质量评估的准确性。

Method: 采用Feature-wise Linear Modulation (FiLM)和多尺度池化技术，结合全局、局部和纹理感知池化，通过轻量级MLP融合多回归头，并利用成对排序损失进行训练。

Result: 在LDCTIQA2023挑战赛的1,000张训练图像上，取得了PLCC = 0.9575、SROCC = 0.9561和KROCC = 0.8301的优异结果。

Conclusion: 该研究提出的基于文本提示的框架在低剂量CT质量评估任务中表现出色，超越了现有公开挑战的顶尖方法，证明了其高效性和适应性。

Abstract: We propose a prompt-conditioned framework built on MedSigLIP that injects textual priors via Feature-wise Linear Modulation (FiLM) and multi-scale pooling. Text prompts condition patch-token features on clinical intent, enabling data-efficient learning and rapid adaptation. The architecture combines global, local, and texture-aware pooling through separate regression heads fused by a lightweight MLP, trained with pairwise ranking loss. Evaluated on the LDCTIQA2023 (a public LDCT quality assessment challenge) with 1,000 training images, we achieve PLCC = 0.9575, SROCC = 0.9561, and KROCC = 0.8301, surpassing the top-ranked published challenge submissions and demonstrating the effectiveness of our prompt-guided approach.

</details>


### [96] [A Disease-Aware Dual-Stage Framework for Chest X-ray Report Generation](https://arxiv.org/abs/2511.12259)
*Puzhen Wu,Hexin Dong,Yi Lin,Yihao Ding,Yifan Peng*

Main category: cs.CV

TL;DR: A dual-stage disease-aware framework improves radiology report generation by enhancing disease-awareness and vision-language alignment, achieving top performance on major datasets.


<details>
  <summary>Details</summary>
Motivation: Existing approaches lack disease-awareness and vision-language alignment, leading to overlooked pathological features and clinically inaccurate reports. This paper aims to address these limitations.

Method: A novel dual-stage disease-aware framework is introduced, involving Disease-Aware Semantic Tokens (DASTs) learning in Stage 1 and Disease-Visual Attention Fusion (DVAF) with Dual-Modal Similarity Retrieval (DMSR) in Stage 2.

Result: The framework outperforms existing methods on CheXpert Plus, IU X-ray, and MIMIC-CXR datasets, demonstrating superior clinical accuracy and linguistic quality.

Conclusion: The proposed disease-aware framework significantly improves clinical accuracy and linguistic quality in radiology report generation, achieving state-of-the-art performance on benchmark datasets.

Abstract: Radiology report generation from chest X-rays is an important task in artificial intelligence with the potential to greatly reduce radiologists' workload and shorten patient wait times. Despite recent advances, existing approaches often lack sufficient disease-awareness in visual representations and adequate vision-language alignment to meet the specialized requirements of medical image analysis. As a result, these models usually overlook critical pathological features on chest X-rays and struggle to generate clinically accurate reports. To address these limitations, we propose a novel dual-stage disease-aware framework for chest X-ray report generation. In Stage~1, our model learns Disease-Aware Semantic Tokens (DASTs) corresponding to specific pathology categories through cross-attention mechanisms and multi-label classification, while simultaneously aligning vision and language representations via contrastive learning. In Stage~2, we introduce a Disease-Visual Attention Fusion (DVAF) module to integrate disease-aware representations with visual features, along with a Dual-Modal Similarity Retrieval (DMSR) mechanism that combines visual and disease-specific similarities to retrieve relevant exemplars, providing contextual guidance during report generation. Extensive experiments on benchmark datasets (i.e., CheXpert Plus, IU X-ray, and MIMIC-CXR) demonstrate that our disease-aware framework achieves state-of-the-art performance in chest X-ray report generation, with significant improvements in clinical accuracy and linguistic quality.

</details>


### [97] [CrossVid: A Comprehensive Benchmark for Evaluating Cross-Video Reasoning in Multimodal Large Language Models](https://arxiv.org/abs/2511.12263)
*Jingyao Li,Jingyun Wang,Molin Tan,Haochen Wang,Cilin Yan,Likun Shi,Jiayin Cai,Xiaolong Jiang,Yao Hu*

Main category: cs.CV

TL;DR: CrossVid是首个全面评估多模态大语言模型跨视频推理能力的基准测试，揭示当前模型在此任务上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有视频理解基准主要关注单视频分析，无法全面评估多模态大语言模型在跨视频推理（CVR）中的能力。

Method: 研究团队开发了CrossVid基准测试，包含多样化的任务和大量视频数据，用于评估模型在跨视频上下文中的时空推理能力。

Result: Gemini-2.5-Pro在CrossVid上表现最佳，平均准确率为50.4%，但大多数模型仍难以整合或比较跨视频的证据。

Conclusion: CrossVid基准测试揭示了当前多模态大语言模型在跨视频推理任务上的局限性，并为其未来改进提供了方向。

Abstract: Cross-Video Reasoning (CVR) presents a significant challenge in video understanding, which requires simultaneous understanding of multiple videos to aggregate and compare information across groups of videos. Most existing video understanding benchmarks focus on single-video analysis, failing to assess the ability of multimodal large language models (MLLMs) to simultaneously reason over various videos. Recent benchmarks evaluate MLLMs' capabilities on multi-view videos that capture different perspectives of the same scene. However, their limited tasks hinder a thorough assessment of MLLMs in diverse real-world CVR scenarios. To this end, we introduce CrossVid, the first benchmark designed to comprehensively evaluate MLLMs' spatial-temporal reasoning ability in cross-video contexts. Firstly, CrossVid encompasses a wide spectrum of hierarchical tasks, comprising four high-level dimensions and ten specific tasks, thereby closely reflecting the complex and varied nature of real-world video understanding. Secondly, CrossVid provides 5,331 videos, along with 9,015 challenging question-answering pairs, spanning single-choice, multiple-choice, and open-ended question formats. Through extensive experiments on various open-source and closed-source MLLMs, we observe that Gemini-2.5-Pro performs best on CrossVid, achieving an average accuracy of 50.4%. Notably, our in-depth case study demonstrates that most current MLLMs struggle with CVR tasks, primarily due to their inability to integrate or compare evidence distributed across multiple videos for reasoning. These insights highlight the potential of CrossVid to guide future advancements in enhancing MLLMs' CVR capabilities.

</details>


### [98] [ZoomEarth: Active Perception for Ultra-High-Resolution Geospatial Vision-Language Tasks](https://arxiv.org/abs/2511.12267)
*Ruixun Liu,Bowen Fu,Jiayi Song,Kaiyu Li,Wanchen Li,Lanxuan Xue,Hui Qiao,Weizhan Zhang,Deyu Meng,Xiangyong Cao*

Main category: cs.CV

TL;DR: 本文提出了一种主动感知框架ZoomEarth，通过自适应裁剪缩放和区域引导奖励，显著提升了超高分辨率遥感图像的处理效率和多功能性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在超高分辨率遥感图像处理中存在冗余问题，缺乏主动感知能力，无法有效利用信息丰富区域。

Method: 提出了ZoomEarth框架，结合自适应裁剪缩放技术和区域引导奖励机制，通过监督微调(SFT)和组相对策略优化(GRPO)进行训练。

Result: ZoomEarth在LRS-GRO数据集和三个公共UHR遥感基准测试中均达到最先进性能，并能无缝集成到下游任务中。

Conclusion: ZoomEarth框架通过主动感知范式显著提升了超高分辨率遥感图像的处理效率，并在多个任务中展现了强大的通用性和扩展性。

Abstract: Ultra-high-resolution (UHR) remote sensing (RS) images offer rich fine-grained information but also present challenges in effective processing. Existing dynamic resolution and token pruning methods are constrained by a passive perception paradigm, suffering from increased redundancy when obtaining finer visual inputs. In this work, we explore a new active perception paradigm that enables models to revisit information-rich regions. First, we present LRS-GRO, a large-scale benchmark dataset tailored for active perception in UHR RS processing, encompassing 17 question types across global, region, and object levels, annotated via a semi-automatic pipeline. Building on LRS-GRO, we propose ZoomEarth, an adaptive cropping-zooming framework with a novel Region-Guided reward that provides fine-grained guidance. Trained via supervised fine-tuning (SFT) and Group Relative Policy Optimization (GRPO), ZoomEarth achieves state-of-the-art performance on LRS-GRO and, in the zero-shot setting, on three public UHR remote sensing benchmarks. Furthermore, ZoomEarth can be seamlessly integrated with downstream models for tasks such as cloud removal, denoising, segmentation, and image editing through simple tool interfaces, demonstrating strong versatility and extensibility.

</details>


### [99] [TM-UNet: Token-Memory Enhanced Sequential Modeling for Efficient Medical Image Segmentation](https://arxiv.org/abs/2511.12270)
*Yaxuan Jiao,Qing Xu,Yuxiang Luo,Xiangjian He,Zhen Chen,Wenting Duan*

Main category: cs.CV

TL;DR: TM-UNet是一种轻量级医学图像分割框架，通过MSTM块实现高效全局推理，计算成本低且性能优越。


<details>
  <summary>Details</summary>
Motivation: 尽管基于transformer的方法在医学图像分割中取得了显著成果，但其高计算成本阻碍了临床部署。为了平衡性能和效率，提出了TM-UNet。

Method: 提出了一种轻量级框架TM-UNet，集成了token序列建模和高效内存机制。具体包括MSTM块，将2D空间特征转换为token序列，利用矩阵内存单元选择性保留和传播判别性上下文信息，并通过指数门控和多尺度上下文提取实现分层表示学习。

Result: TM-UNet在多种医学分割任务中表现优于现有方法，同时显著降低了计算成本。代码已开源。

Conclusion: TM-UNet通过引入多尺度token-memory（MSTM）块，成功实现了高效且轻量化的医学图像分割，显著降低了计算成本，同时在多种医学分割任务中表现优于现有方法。

Abstract: Medical image segmentation is essential for clinical diagnosis and treatment planning. Although transformer-based methods have achieved remarkable results, their high computational cost hinders clinical deployment. To address this issue, we propose TM-UNet, a novel lightweight framework that integrates token sequence modeling with an efficient memory mechanism for efficient medical segmentation. Specifically, we introduce a multi-scale token-memory (MSTM) block that transforms 2D spatial features into token sequences through strategic spatial scanning, leveraging matrix memory cells to selectively retain and propagate discriminative contextual information across tokens. This novel token-memory mechanism acts as a dynamic knowledge store that captures long-range dependencies with linear complexity, enabling efficient global reasoning without redundant computation. Our MSTM block further incorporates exponential gating to identify token effectiveness and multi-scale contextual extraction via parallel pooling operations, enabling hierarchical representation learning without computational overhead. Extensive experiments demonstrate that TM-UNet outperforms state-of-the-art methods across diverse medical segmentation tasks with substantially reduced computation cost. The code is available at https://github.com/xq141839/TM-UNet.

</details>


### [100] [D$^{3}$ToM: Decider-Guided Dynamic Token Merging for Accelerating Diffusion MLLMs](https://arxiv.org/abs/2511.12280)
*Shuochen Chang,Xiaofeng Zhang,Qingyang Liu,Li Niu*

Main category: cs.CV

TL;DR: D$^{3}$ToM 通过动态合并冗余视觉令牌，显著加速 Diffusion MLLMs 的推理，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: Diffusion MLLMs 因双向自注意力机制导致推理速度慢，尤其在处理大量视觉令牌时计算复杂度高。

Method: D$^{3}$ToM 使用决策令牌构建重要性图，动态合并冗余视觉令牌，并通过相似性聚合减少令牌序列长度。

Result: 实验表明，D$^{3}$ToM 在加速推理的同时保持了竞争性的性能。

Conclusion: D$^{3}$ToM 是一种有效的动态令牌合并方法，能够在保持性能的同时显著加速 Diffusion MLLMs 的推理过程。

Abstract: Diffusion-based multimodal large language models (Diffusion MLLMs) have recently demonstrated impressive non-autoregressive generative capabilities across vision-and-language tasks. However, Diffusion MLLMs exhibit substantially slower inference than autoregressive models: Each denoising step employs full bidirectional self-attention over the entire sequence, resulting in cubic decoding complexity that becomes computationally impractical with thousands of visual tokens. To address this challenge, we propose D$^{3}$ToM, a Decider-guided dynamic token merging method that dynamically merges redundant visual tokens at different denoising steps to accelerate inference in Diffusion MLLMs. At each denoising step, D$^{3}$ToM uses decider tokens-the tokens generated in the previous denoising step-to build an importance map over all visual tokens. Then it maintains a proportion of the most salient tokens and merges the remainder through similarity-based aggregation. This plug-and-play module integrates into a single transformer layer, physically shortening the visual token sequence for all subsequent layers without altering model parameters. Moreover, D$^{3}$ToM employs a merge ratio that dynamically varies with each denoising step, aligns with the native decoding process of Diffusion MLLMs, achieving superior performance under equivalent computational budgets. Extensive experiments show that D$^{3}$ToM accelerates inference while preserving competitive performance. The code is released at https://github.com/bcmi/D3ToM-Diffusion-MLLM.

</details>


### [101] [One target to align them all: LiDAR, RGB and event cameras extrinsic calibration for Autonomous Driving](https://arxiv.org/abs/2511.12291)
*Andrea Bertogalli,Giacomo Boracchi,Luca Magri*

Main category: cs.CV

TL;DR: 提出一种多模态外在校准框架，通过创新的3D校准目标实现事件相机、LiDAR和RGB相机的一体化联合校准，提升自动驾驶系统的传感器对齐精度。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统中多传感器精确对齐至关重要，而现有方法通常依赖单独校准，效率低且精度受限。本文旨在解决事件相机校准的挑战，提出一体化解决方案。

Method: 采用了一种新颖的3D校准目标，该目标包含平面、ChArUco和主动LED模式，分别针对LiDAR、RGB相机和事件相机的特性设计。通过一次性联合校准流程，替代传统分步校准方法。

Result: 在定制数据集上的实验验证表明，该方法能够高精度、鲁棒地完成多传感器外在校准，优于传统分步校准方法。

Conclusion: 本文提出的多模态外在校准框架通过创新的3D校准目标设计，实现了事件相机、LiDAR和RGB相机的一体化联合校准，显著提升了自动驾驶场景中复杂视觉系统的校准精度和效率。实验验证了方法的准确性和鲁棒性。

Abstract: We present a novel multi-modal extrinsic calibration framework designed to simultaneously estimate the relative poses between event cameras, LiDARs, and RGB cameras, with particular focus on the challenging event camera calibration. Core of our approach is a novel 3D calibration target, specifically designed and constructed to be concurrently perceived by all three sensing modalities. The target encodes features in planes, ChArUco, and active LED patterns, each tailored to the unique characteristics of LiDARs, RGB cameras, and event cameras respectively. This unique design enables a one-shot, joint extrinsic calibration process, in contrast to existing approaches that typically rely on separate, pairwise calibrations. Our calibration pipeline is designed to accurately calibrate complex vision systems in the context of autonomous driving, where precise multi-sensor alignment is critical. We validate our approach through an extensive experimental evaluation on a custom built dataset, recorded with an advanced autonomous driving sensor setup, confirming the accuracy and robustness of our method.

</details>


### [102] [Rethinking Bias in Generative Data Augmentation for Medical AI: a Frequency Recalibration Method](https://arxiv.org/abs/2511.12301)
*Chi Liu,Jincheng Liu,Congcong Zhu,Minghao Wang,Sheng Shen,Jia Gu,Tianqing Zhu,Wanlei Zhou*

Main category: cs.CV

TL;DR: 医疗AI中生成数据增强（GDA）的频率偏差问题通过FreRec方法（SHR+RHM）得到解决，显著提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 医疗AI依赖大型数据集但易受数据稀缺影响，生成数据增强（GDA）可能因频率未对齐而引入有害特征，影响下游任务。

Method: 论文提出了频率重新校准（FreRec）方法，包括统计高频替换（SHR）粗略对齐高频成分，以及重建高频映射（RHM）增强图像质量并重建高频细节。

Result: 在多种医学数据集（如脑MRI、胸部X光和眼底图像）上的实验显示，FreRec显著提升了分类性能。

Conclusion: FreRec是一种独立的后处理步骤，可兼容任何生成模型，并能无缝集成到常见的医学GDA流程中，显著提升下游医学图像分类性能。

Abstract: Developing Medical AI relies on large datasets and easily suffers from data scarcity. Generative data augmentation (GDA) using AI generative models offers a solution to synthesize realistic medical images. However, the bias in GDA is often underestimated in medical domains, with concerns about the risk of introducing detrimental features generated by AI and harming downstream tasks. This paper identifies the frequency misalignment between real and synthesized images as one of the key factors underlying unreliable GDA and proposes the Frequency Recalibration (FreRec) method to reduce the frequency distributional discrepancy and thus improve GDA. FreRec involves (1) Statistical High-frequency Replacement (SHR) to roughly align high-frequency components and (2) Reconstructive High-frequency Mapping (RHM) to enhance image quality and reconstruct high-frequency details. Extensive experiments were conducted in various medical datasets, including brain MRIs, chest X-rays, and fundus images. The results show that FreRec significantly improves downstream medical image classification performance compared to uncalibrated AI-synthesized samples. FreRec is a standalone post-processing step that is compatible with any generative model and can integrate seamlessly with common medical GDA pipelines.

</details>


### [103] [LiDAR-GS++:Improving LiDAR Gaussian Reconstruction via Diffusion Priors](https://arxiv.org/abs/2511.12304)
*Qifeng Chen,Jiarun Liu,Rengan Xie,Tao Tang,Sicong Du,Yiru Zhao,Yuchi Huo,Sheng Yang*

Main category: cs.CV

TL;DR: LiDAR-GS++利用扩散先验增强高斯溅射，解决了单次扫描重建不完整的问题，实现了高保真外推视角合成。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于GS的渲染方法因单次扫描重建不完整而导致的外推新视角合成中的伪影问题。

Method: 引入可控的LiDAR生成模型，基于粗略外推渲染生成额外几何一致的扫描，并采用有效的蒸馏机制进行扩展重建。

Result: 在多个公共数据集上的实验表明，LiDAR-GS++在插值和外推视角上均优于现有的GS和基于NeRF的方法。

Conclusion: LiDAR-GS++通过扩散先验增强的高斯溅射重建方法，在公共城市道路上实现了实时高保真重模拟，达到了插值和外推视角的最先进性能。

Abstract: Recent GS-based rendering has made significant progress for LiDAR, surpassing Neural Radiance Fields (NeRF) in both quality and speed. However, these methods exhibit artifacts in extrapolated novel view synthesis due to the incomplete reconstruction from single traversal scans. To address this limitation, we present LiDAR-GS++, a LiDAR Gaussian Splatting reconstruction method enhanced by diffusion priors for real-time and high-fidelity re-simulation on public urban roads. Specifically, we introduce a controllable LiDAR generation model conditioned on coarsely extrapolated rendering to produce extra geometry-consistent scans and employ an effective distillation mechanism for expansive reconstruction. By extending reconstruction to under-fitted regions, our approach ensures global geometric consistency for extrapolative novel views while preserving detailed scene surfaces captured by sensors. Experiments on multiple public datasets demonstrate that LiDAR-GS++ achieves state-of-the-art performance for both interpolated and extrapolated viewpoints, surpassing existing GS and NeRF-based methods.

</details>


### [104] [Learning Time in Static Classifiers](https://arxiv.org/abs/2511.12321)
*Xi Ding,Lei Wang,Piotr Koniusz,Yongsheng Gao*

Main category: cs.CV

TL;DR: 论文提出一种无需修改模型的时序学习框架（SEQ），通过时间连贯轨迹训练分类器，显著提升静态和时间任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的视觉数据通常随着时间逐渐变化，但传统分类器通常基于时间独立的假设训练，限制了其捕捉动态变化的能力。论文旨在克服这一局限性。

Method: 论文的核心是一种新颖的SEQ（支持-样本-查询）学习范式，它将训练数据组织成时间连贯的轨迹。这些轨迹使模型能够学习类别特定的时间原型，并通过可微分的soft-DTW损失对齐预测序列。多目标函数进一步促进了语义一致性和时间平滑性。

Result: 该方法在细粒度和超细粒度图像分类中提升了性能，并在视频异常检测中实现了精确且时间一致的预测。

Conclusion: 该论文提出了一种简单但有效的框架，使标准前馈分类器具备时间推理能力，无需修改模型架构或引入循环模块。该方法通过损失设计引入了强大的时间归纳偏差，显著提升了静态和时间任务的性能。

Abstract: Real-world visual data rarely presents as isolated, static instances. Instead, it often evolves gradually over time through variations in pose, lighting, object state, or scene context. However, conventional classifiers are typically trained under the assumption of temporal independence, limiting their ability to capture such dynamics. We propose a simple yet effective framework that equips standard feedforward classifiers with temporal reasoning, all without modifying model architectures or introducing recurrent modules. At the heart of our approach is a novel Support-Exemplar-Query (SEQ) learning paradigm, which structures training data into temporally coherent trajectories. These trajectories enable the model to learn class-specific temporal prototypes and align prediction sequences via a differentiable soft-DTW loss. A multi-term objective further promotes semantic consistency and temporal smoothness. By interpreting input sequences as evolving feature trajectories, our method introduces a strong temporal inductive bias through loss design alone. This proves highly effective in both static and temporal tasks: it enhances performance on fine-grained and ultra-fine-grained image classification, and delivers precise, temporally consistent predictions in video anomaly detection. Despite its simplicity, our approach bridges static and temporal learning in a modular and data-efficient manner, requiring only a simple classifier on top of pre-extracted features.

</details>


### [105] [SpaceVLM: Sub-Space Modeling of Negation in Vision-Language Models](https://arxiv.org/abs/2511.12331)
*Sepehr Kazemi Ranjbar,Kumail Alhamoud,Marzyeh Ghassemi*

Main category: cs.CV

TL;DR: 无需训练的框架通过子空间建模否定，提升VLMs否定理解30%，且不损害零样本性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过微调大规模否定数据集来解决VLMs的否定理解问题，但会损害模型的零样本性能。本文旨在提出一种不影响零样本性能的解决方案。

Method: 基于CLIP等模型的嵌入空间可分性，提出将否定建模为子空间，并通过构建围绕A和N嵌入的球冠区域来匹配图像。

Result: 实验表明，该方法在检索、MCQ和文本到图像任务中，平均比现有方法提升了30%的否定理解能力，同时保持了零样本性能。

Conclusion: 本文提出了一种无需训练的框架，通过将否定建模为联合嵌入空间中的子空间而非单点，显著提升了视觉语言模型（VLMs）对否定的理解能力，同时保持了零样本性能。

Abstract: Vision-Language Models (VLMs) struggle with negation. Given a prompt like "retrieve (or generate) a street scene without pedestrians," they often fail to respect the "not." Existing methods address this limitation by fine-tuning on large negation datasets, but such retraining often compromises the model's zero-shot performance on affirmative prompts. We show that the embedding space of VLMs, such as CLIP, can be divided into semantically consistent subspaces. Based on this property, we propose a training-free framework that models negation as a subspace in the joint embedding space rather than a single point (Figure 1). To find the matching image for a caption such as "A but not N," we construct two spherical caps around the embeddings of A and N, and we score images by the central direction of the region that is close to A and far from N. Across retrieval, MCQ, and text-to-image tasks, our method improves negation understanding by about 30% on average over prior methods. It closes the gap between affirmative and negated prompts while preserving the zero-shot performance that fine-tuned models fail to maintain. Code will be released upon publication.

</details>


### [106] [Ground Plane Projection for Improved Traffic Analytics at Intersections](https://arxiv.org/abs/2511.12342)
*Sajjad Pakdamansavoji,Kumar Vaibhav Jha,Baher Abdulhai,James H Elder*

Main category: cs.CV

TL;DR: 研究发现，将车辆检测从图像平面反向投影到地面平面能更准确地进行转向运动计数，多摄像头融合可进一步提高精度。


<details>
  <summary>Details</summary>
Motivation: 准确的转向运动计数对信号控制、交通管理和城市规划至关重要，而现有计算机视觉系统通常在图像平面进行分析，可能存在局限性。

Method: 通过将基础设施摄像头检测到的车辆反向投影到地面平面，分析真实世界的3D坐标，并探索单摄像头和多摄像头系统的弱融合方法。

Result: 单摄像头系统的反向投影提高了轨迹分类和转向运动计数的准确性，而多摄像头的弱融合进一步提升了准确性。

Conclusion: 分析交通应在真实世界的3D坐标（地面平面）而非图像平面进行，以提升转向运动计数的准确性。

Abstract: Accurate turning movement counts at intersections are important for signal control, traffic management and urban planning. Computer vision systems for automatic turning movement counts typically rely on visual analysis in the image plane of an infrastructure camera. Here we explore potential advantages of back-projecting vehicles detected in one or more infrastructure cameras to the ground plane for analysis in real-world 3D coordinates. For single-camera systems we find that back-projection yields more accurate trajectory classification and turning movement counts. We further show that even higher accuracy can be achieved through weak fusion of back-projected detections from multiple cameras. These results suggeest that traffic should be analyzed on the ground plane, not the image plane

</details>


### [107] [CLAReSNet: When Convolution Meets Latent Attention for Hyperspectral Image Classification](https://arxiv.org/abs/2511.12346)
*Asmit Bandyopadhyay,Anindita Das Bhattacharjee,Rakesh Das*

Main category: cs.CV

TL;DR: CLAReSNet是一种混合架构，结合卷积和变换器注意机制，有效解决高光谱图像分类中的挑战，在有限样本和类别不平衡下表现卓越。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像分类面临高光谱维度、复杂的光谱-空间关联及有限的训练样本和严重的类别不平衡等挑战，现有CNN和变换器的独立应用效果不佳。

Method: CLAReSNet结合了多尺度卷积提取与变换器风格的注意机制，通过自适应潜在瓶颈集成双向RNNs（LSTM/GRU）和多尺度光谱潜在注意（MSLA），降低了计算复杂度。

Result: 在Indian Pines和Salinas数据集上，CLAReSNet实现了99.71%和99.96%的总体准确率，显著超越了HybridSN、SSRN和SpectralFormer。

Conclusion: CLAReSNet展示了在高光谱图像分类任务中的卓越性能，特别是在有限样本和严重类别不平衡的情况下，其学习到的嵌入具有优越的类间可分离性和紧凑的类内聚类。

Abstract: Hyperspectral image (HSI) classification faces critical challenges, including high spectral dimensionality, complex spectral-spatial correlations, and limited training samples with severe class imbalance. While CNNs excel at local feature extraction and transformers capture long-range dependencies, their isolated application yields suboptimal results due to quadratic complexity and insufficient inductive biases. We propose CLAReSNet (Convolutional Latent Attention Residual Spectral Network), a hybrid architecture that integrates multi-scale convolutional extraction with transformer-style attention via an adaptive latent bottleneck. The model employs a multi-scale convolutional stem with deep residual blocks and an enhanced Convolutional Block Attention Module for hierarchical spatial features, followed by spectral encoder layers combining bidirectional RNNs (LSTM/GRU) with Multi-Scale Spectral Latent Attention (MSLA). MSLA reduces complexity from $\mathcal{O}(T^2D)$ to $\mathcal{O}(T\log(T)D)$ by adaptive latent token allocation (8-64 tokens) that scales logarithmically with the sequence length. Hierarchical cross-attention fusion dynamically aggregates multi-level representations for robust classification. Experiments conducted on the Indian Pines and Salinas datasets show state-of-the-art performance, achieving overall accuracies of 99.71% and 99.96%, significantly surpassing HybridSN, SSRN, and SpectralFormer. The learned embeddings exhibit superior inter-class separability and compact intra-class clustering, validating CLAReSNet's effectiveness under limited samples and severe class imbalance.

</details>


### [108] [Explainable AI-Generated Image Detection RewardBench](https://arxiv.org/abs/2511.12363)
*Michael Yang,Shijian Deng,William T. Doan,Kai Wang,Tianyu Yang,Harsh Singh,Yapeng Tian*

Main category: cs.CV

TL;DR: 研究提出了首个评估MLLMs判断AI生成图像解释能力的基准XAIGID-RewardBench，结果显示当前模型与人类表现仍有差距，并分析了常见缺陷。


<details>
  <summary>Details</summary>
Motivation: 传统的基于分类的AI生成图像检测方法无法以人类专家可理解的方式解释图像的真实性，降低了检测工具的可信度和说服力。

Method: 提出了XAIGID-RewardBench基准，包含约3000个标注的三元组，用于评估MLLMs作为奖励模型（评判者）的能力。

Result: 基准测试结果表明，当前最佳奖励模型的评分为88.76%。

Conclusion: 当前最佳奖励模型在基准测试中得分为88.76%，与人类标注者之间的98.30%一致性相比，显示出现有多模态大型语言模型（MLLMs）在推理能力上仍存在显著差距。研究还分析了这些模型的常见缺陷。

Abstract: Conventional, classification-based AI-generated image detection methods cannot explain why an image is considered real or AI-generated in a way a human expert would, which reduces the trustworthiness and persuasiveness of these detection tools for real-world applications. Leveraging Multimodal Large Language Models (MLLMs) has recently become a trending solution to this issue. Further, to evaluate the quality of generated explanations, a common approach is to adopt an "MLLM as a judge" methodology to evaluate explanations generated by other MLLMs. However, how well those MLLMs perform when judging explanations for AI-generated image detection generated by themselves or other MLLMs has not been well studied. We therefore propose \textbf{XAIGID-RewardBench}, the first benchmark designed to evaluate the ability of current MLLMs to judge the quality of explanations about whether an image is real or AI-generated. The benchmark consists of approximately 3,000 annotated triplets sourced from various image generation models and MLLMs as policy models (detectors) to assess the capabilities of current MLLMs as reward models (judges). Our results show that the current best reward model scored 88.76\% on this benchmark (while human inter-annotator agreement reaches 98.30\%), demonstrating that a visible gap remains between the reasoning abilities of today's MLLMs and human-level performance. In addition, we provide an analysis of common pitfalls that these models frequently encounter. Code and benchmark are available at https://github.com/RewardBench/XAIGID-RewardBench.

</details>


### [109] [Constructing and Interpreting Digital Twin Representations for Visual Reasoning via Reinforcement Learning](https://arxiv.org/abs/2511.12365)
*Yiqing Shen,Mathias Unberath*

Main category: cs.CV

TL;DR: DT-R1是一种基于强化学习和数字孪生表示的视觉推理框架，统一处理多模态任务并提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖任务特定的架构和训练，限制了统一解决方案和跨任务、跨模态的泛化能力。

Method: 使用GRPO和新型奖励机制训练DT-R1，验证结构完整性和输出准确性。

Result: 在六个视觉推理基准测试中，DT-R1均优于现有任务特定模型。

Conclusion: DT-R1通过强化学习和数字孪生表示提出了一种统一的视觉推理方法，显著提升了多任务和多模态的泛化能力。

Abstract: Visual reasoning may require models to interpret images and videos and respond to implicit text queries across diverse output formats, from pixel-level segmentation masks to natural language descriptions. Existing approaches rely on supervised fine-tuning with task-specific architectures. For example, reasoning segmentation, grounding, summarization, and visual question answering each demand distinct model designs and training, preventing unified solutions and limiting cross-task and cross-modality generalization. Hence, we propose DT-R1, a reinforcement learning framework that trains large language models to construct digital twin representations of complex multi-modal visual inputs and then reason over these high-level representations as a unified approach to visual reasoning. Specifically, we train DT-R1 using GRPO with a novel reward that validates both structural integrity and output accuracy. Evaluations in six visual reasoning benchmarks, covering two modalities and four task types, demonstrate that DT-R1 consistently achieves improvements over state-of-the-art task-specific models. DT-R1 opens a new direction where visual reasoning emerges from reinforcement learning with digital twin representations.

</details>


### [110] [Fast Reasoning Segmentation for Images and Videos](https://arxiv.org/abs/2511.12368)
*Yiqing Shen,Mathias Unberath*

Main category: cs.CV

TL;DR: FastReasonSeg通过数字孪生表示和新型蒸馏方法，高效压缩推理分割模型，实现在边缘设备的实时部署，性能优于大参数模型。


<details>
  <summary>Details</summary>
Motivation: 现有推理分割方法依赖计算资源密集的多模态大模型，无法在边缘设备部署；传统蒸馏方法未能有效保留多步推理能力。

Method: 采用数字孪生表示解耦感知与推理，结合监督微调（基于教师模型的推理链）和强化微调（联合评估分割精度与推理质量对齐）的蒸馏方案。

Result: 在四个基准测试（JiTBench、RVTBench、ReasonSeg、LLM-Seg40K）上达到SOTA性能，0.6B参数的蒸馏模型超越20倍参数模型，实现7.79 FPS和2.1GB内存消耗。

Conclusion: FastReasonSeg通过数字孪生表示和分步蒸馏方法，实现了高效的推理分割，在资源受限的环境中展现出实时处理能力，性能超越参数规模更大的模型。

Abstract: Reasoning segmentation enables open-set object segmentation via implicit text queries, therefore serving as a foundation for embodied agents that should operate autonomously in real-world environments. However, existing methods for reasoning segmentation require multimodal large language models with billions of parameters that exceed the computational capabilities of edge devices that typically deploy the embodied AI systems. Distillation offers a pathway to compress these models while preserving their capabilities. Yet, existing distillation approaches fail to transfer the multi-step reasoning capabilities that reasoning segmentation demands, as they focus on matching output predictions and intermediate features rather than preserving reasoning chains. The emerging paradigm of reasoning over digital twin representations presents an opportunity for more effective distillation by re-framing the problem. Consequently, we propose FastReasonSeg, which employs digital twin representations that decouple perception from reasoning to enable more effective distillation. Our distillation scheme first relies on supervised fine-tuning on teacher-generated reasoning chains. Then it is followed by reinforcement fine-tuning with joint rewards evaluating both segmentation accuracy and reasoning quality alignment. Experiments on two video (JiTBench, RVTBench) and two image benchmarks (ReasonSeg, LLM-Seg40K) demonstrate that our FastReasonSeg achieves state-of-the-art reasoning segmentation performance. Moreover, the distilled 0.6B variant outperforms models with 20 times more parameters while achieving 7.79 FPS throughput with only 2.1GB memory consumption. This efficiency enables deployment in resource-constrained environments to enable real-time reasoning segmentation.

</details>


### [111] [Changes in Real Time: Online Scene Change Detection with Multi-View Fusion](https://arxiv.org/abs/2511.12370)
*Chamuditha Jayanga Galappaththige,Jason Lai,Lloyd Windrim,Donald Dansereau,Niko Sünderhauf,Dimity Miller*

Main category: cs.CV

TL;DR: 首个实时、姿态无关的无标签在线场景变化检测方法，性能超越离线方法，通过自监督融合损失和快速更新策略实现。


<details>
  <summary>Details</summary>
Motivation: 在线场景变化检测（SCD）是一个极具挑战性的问题，现有在线方法的准确性远低于离线方法。本文旨在填补这一差距。

Method: 方法结合了自监督融合损失（用于从多线索和观测推断场景变化）、基于PnP的快速姿态估计（针对参考场景），以及快速变化引导更新策略（用于3D高斯泼溅场景表示）。

Result: 在复杂真实数据集上的大量实验表明，该方法在性能上超越了所有在线和离线基线。

Conclusion: 本文提出的首个姿态无关、无标签且确保多视角一致性的在线场景变化检测方法，在性能上超越了现有最佳离线方法，同时实现了超过10 FPS的实时处理速度。

Abstract: Online Scene Change Detection (SCD) is an extremely challenging problem that requires an agent to detect relevant changes on the fly while observing the scene from unconstrained viewpoints. Existing online SCD methods are significantly less accurate than offline approaches. We present the first online SCD approach that is pose-agnostic, label-free, and ensures multi-view consistency, while operating at over 10 FPS and achieving new state-of-the-art performance, surpassing even the best offline approaches. Our method introduces a new self-supervised fusion loss to infer scene changes from multiple cues and observations, PnP-based fast pose estimation against the reference scene, and a fast change-guided update strategy for the 3D Gaussian Splatting scene representation. Extensive experiments on complex real-world datasets demonstrate that our approach outperforms both online and offline baselines.

</details>


### [112] [Reasoning Text-to-Video Retrieval via Digital Twin Video Representations and Large Language Models](https://arxiv.org/abs/2511.12371)
*Yiqing Shen,Chenxiao Fan,Chenjia Li,Mathias Unberath*

Main category: cs.CV

TL;DR: 论文提出了一种结合数字孪生和大型语言模型的推理文本到视频检索方法，显著提升了隐式查询的处理能力，并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理显式查询时表现良好，但在隐式查询中因缺乏推理能力而失败。论文旨在通过引入推理能力和对象级 grounding masks来解决这一问题。

Method: 论文提出了一个两阶段框架：首先通过组合对齐分解的子查询和数字孪生表示来识别候选视频，然后利用大型语言模型进行推理，并结合即时细化来填补信息 gaps。

Result: 在ReasonT2VBench-135上达到了81.2% R@1，比最强基线高出50个百分点以上，并在扩展配置中保持了81.7% R@1。此外，在MSR-VTT、MSVD和VATEX等传统基准测试中也取得了最先进的结果。

Conclusion: 该论文提出了一个名为推理文本到视频检索的新范式，通过数字孪生表示视频内容，并结合大型语言模型进行推理，显著提升了处理隐式查询的能力。实验结果表明，该方法在多个基准测试中均达到了最先进的性能。

Abstract: The goal of text-to-video retrieval is to search large databases for relevant videos based on text queries. Existing methods have progressed to handling explicit queries where the visual content of interest is described explicitly; however, they fail with implicit queries where identifying videos relevant to the query requires reasoning. We introduce reasoning text-to-video retrieval, a paradigm that extends traditional retrieval to process implicit queries through reasoning while providing object-level grounding masks that identify which entities satisfy the query conditions. Instead of relying on vision-language models directly, we propose representing video content as digital twins, i.e., structured scene representations that decompose salient objects through specialist vision models. This approach is beneficial because it enables large language models to reason directly over long-horizon video content without visual token compression. Specifically, our two-stage framework first performs compositional alignment between decomposed sub-queries and digital twin representations for candidate identification, then applies large language model-based reasoning with just-in-time refinement that invokes additional specialist models to address information gaps. We construct a benchmark of 447 manually created implicit queries with 135 videos (ReasonT2VBench-135) and another more challenging version of 1000 videos (ReasonT2VBench-1000). Our method achieves 81.2% R@1 on ReasonT2VBench-135, outperforming the strongest baseline by greater than 50 percentage points, and maintains 81.7% R@1 on the extended configuration while establishing state-of-the-art results in three conventional benchmarks (MSR-VTT, MSVD, and VATEX).

</details>


### [113] [AGGRNet: Selective Feature Extraction and Aggregation for Enhanced Medical Image Classification](https://arxiv.org/abs/2511.12382)
*Ansh Makwe,Akansh Agrawal,Prateek Jain,Akshan Agrawal,Priyanka Bagade*

Main category: cs.CV

TL;DR: AGGRNet通过提取信息性和非信息性特征改进医学图像分类，性能优于现有模型，最高提升5%。


<details>
  <summary>Details</summary>
Motivation: 医学图像分析面临复杂视觉模式、标签数据稀缺和专家解释差异等挑战，现有注意力模型难以有效区分细微类别。

Method: 提出了AGGRNet框架，专注于提取信息性和非信息性特征，以区分细微类别并理解细粒度视觉模式。

Result: AGGRNet在多个医学影像数据集上实现了最先进性能，尤其在Kvasir数据集上比现有最佳模型提升了5%。

Conclusion: AGGRNet框架通过提取信息性和非信息性特征，有效理解了细粒度视觉模式，显著提升了复杂医学图像分析任务的分类性能，实验结果表明其性能优于现有最先进模型。

Abstract: Medical image analysis for complex tasks such as severity grading and disease subtype classification poses significant challenges due to intricate and similar visual patterns among classes, scarcity of labeled data, and variability in expert interpretations. Despite the usefulness of existing attention-based models in capturing complex visual patterns for medical image classification, underlying architectures often face challenges in effectively distinguishing subtle classes since they struggle to capture inter-class similarity and intra-class variability, resulting in incorrect diagnosis. To address this, we propose AGGRNet framework to extract informative and non-informative features to effectively understand fine-grained visual patterns and improve classification for complex medical image analysis tasks. Experimental results show that our model achieves state-of-the-art performance on various medical imaging datasets, with the best improvement up to 5% over SOTA models on the Kvasir dataset.

</details>


### [114] [Leveraging Quantum-Based Architectures for Robust Diagnostics](https://arxiv.org/abs/2511.12386)
*Shabnam Sodagari,Tommy Long*

Main category: cs.CV

TL;DR: 研究通过量子-经典混合模型提升肾脏CT图像的诊断准确率，12-qubit配置表现尤佳。


<details>
  <summary>Details</summary>
Motivation: 旨在利用CT图像诊断和区分肾结石、囊肿和肿瘤，探索量子辅助诊断的潜力。

Method: 采用混合量子-经典框架，结合预训练的ResNet50编码器与量子卷积神经网络（QCNN），通过去噪和对比度受限自适应直方图均衡化预处理图像，并利用数据增强和加权采样解决类别不平衡问题。

Result: 模型在8-qubit和12-qubit配置下均快速收敛，测试准确率达0.99。12-qubit配置在囊肿检测中实现完美召回，肿瘤F1-score达0.9956。

Conclusion: 本研究通过结合经典预处理、深度特征提取与量子电路，显著提升了医学诊断性能，尤其是在肾脏囊肿和肿瘤检测方面。

Abstract: The objective of this study is to diagnose and differentiate kidney stones, cysts, and tumors using Computed Tomography (CT) images of the kidney. This study leverages a hybrid quantum-classical framework in this regard. We combine a pretrained ResNet50 encoder, with a Quantum Convolutional Neural Network (QCNN) to explore quantum-assisted diagnosis. We pre-process the kidney images using denoising and contrast limited adaptive histogram equalization to enhance feature extraction. We address class imbalance through data augmentation and weighted sampling. Latent features extracted by the encoder are transformed into qubits via angle encoding and processed by a QCNN. The model is evaluated on both 8-qubit and 12-qubit configurations. Both architectures achieved rapid convergence with stable learning curves and high consistency between training and validation performance. The models reached a test accuracy of 0.99, with the 12-qubit configuration providing improvements in overall recall and precision, particularly for Cyst and Tumor detection, where it achieved perfect recall for Cysts and a tumor F1-score of 0.9956. Confusion matrix analysis further confirmed reliable classification behavior across all classes, with very few misclassifications. Results demonstrate that integrating classical pre-processing and deep feature extraction with quantum circuits enhances medical diagnostic performance.

</details>


### [115] [Calibrated Decomposition of Aleatoric and Epistemic Uncertainty in Deep Features for Inference-Time Adaptation](https://arxiv.org/abs/2511.12389)
*Divake Kumar,Patrick Poggi,Sina Tayebati,Devashri Naik,Nilesh Ahuja,Amit Ranjan Trivedi*

Main category: cs.CV

TL;DR: 该论文提出一种解耦数据与模型不确定性的轻量级框架，显著降低计算成本（60%），精度几乎无损，适用于自调节视觉推理。


<details>
  <summary>Details</summary>
Motivation: 现有估计器将所有不确定性模式合并为单一置信度分数，无法可靠决定何时分配更多计算或调整推理。

Method: 提出一个轻量级推理时框架，通过正则化全局密度模型估计数据驱动不确定性，并通过三个互补组件（局部支持不足、流形谱崩溃和跨层特征不一致）捕获模型驱动不确定性，无需采样、集成或额外前向传递。

Result: 在MOT17上，使用该框架进行不确定性引导的模型选择减少了约60%的计算，精度损失可忽略；不确定性分解在MOT17所有序列中均带来更高的计算节省，比基线提升13.6个百分点。

Conclusion: Uncertainty-Guided Inference-Time Selection 框架通过解耦数据驱动和模型驱动的不确定性，显著减少了计算成本（约60%），同时保持了精度，实现了自调节的视觉推理。

Abstract: Most estimators collapse all uncertainty modes into a single confidence score, preventing reliable reasoning about when to allocate more compute or adjust inference. We introduce Uncertainty-Guided Inference-Time Selection, a lightweight inference time framework that disentangles aleatoric (data-driven) and epistemic (model-driven) uncertainty directly in deep feature space. Aleatoric uncertainty is estimated using a regularized global density model, while epistemic uncertainty is formed from three complementary components that capture local support deficiency, manifold spectral collapse, and cross-layer feature inconsistency. These components are empirically orthogonal and require no sampling, no ensembling, and no additional forward passes. We integrate the decomposed uncertainty into a distribution free conformal calibration procedure that yields significantly tighter prediction intervals at matched coverage. Using these components for uncertainty guided adaptive model selection reduces compute by approximately 60 percent on MOT17 with negligible accuracy loss, enabling practical self regulating visual inference. Additionally, our ablation results show that the proposed orthogonal uncertainty decomposition consistently yields higher computational savings across all MOT17 sequences, improving margins by 13.6 percentage points over the total-uncertainty baseline.

</details>


### [116] [MSLoRA: Multi-Scale Low-Rank Adaptation via Attention Reweighting](https://arxiv.org/abs/2511.12400)
*Xu Yang,Gady Agam*

Main category: cs.CV

TL;DR: MSLoRA是一种主干无关的参数高效适配器，通过重新加权特征响应统一CNNs和ViTs的适应，性能提升显著且参数极少。


<details>
  <summary>Details</summary>
Motivation: 现有的低秩适应方法主要局限于视觉变换器（ViTs），难以跨架构泛化，MSLoRA旨在统一卷积神经网络（CNNs）和ViTs的适应。

Method: MSLoRA结合了低秩线性投影和多尺度非线性变换，通过点乘和残差连接融合，调制空间和通道注意力。

Result: MSLoRA在分类、检测和分割任务上持续提升迁移性能，仅使用不到5%的主干参数，并实现稳定优化、快速收敛和强跨架构泛化。

Conclusion: MSLoRA通过重新加权特征响应而非重新调整底层主干网络，提供了一个简单且通用的方法，用于高效适应冻结的视觉主干网络。

Abstract: We introduce MSLoRA, a backbone-agnostic, parameter-efficient adapter that reweights feature responses rather
  than re-tuning the underlying backbone. Existing low-rank adaptation methods are mostly confined to vision
  transformers (ViTs) and struggle to generalize across architectures. MSLoRA unifies adaptation for both convolutional neural networks (CNNs) and
  ViTs by combining a low-rank linear projection with a multi-scale nonlinear transformation that jointly
  modulates spatial and channel attention. The two components are fused through pointwise multiplication and
  a residual connection, yielding a lightweight module that shifts feature attention while keeping pretrained
  weights frozen.
  Extensive experiments demonstrate that MSLoRA consistently improves transfer performance on classification,
  detection, and segmentation tasks with roughly less than 5\% of backbone parameters.
  The design further enables stable optimization, fast convergence, and strong cross-architecture
  generalization. By reweighting rather than re-tuning, MSLoRA provides a simple and universal approach
  for efficient adaptation of frozen vision backbones.

</details>


### [117] [VLA-R: Vision-Language Action Retrieval toward Open-World End-to-End Autonomous Driving](https://arxiv.org/abs/2511.12405)
*Hyunki Seong,Seongwoo Moon,Hojin Ahn,Jehun Kang,David Hyunchul Shim*

Main category: cs.CV

TL;DR: VLA-R是一个开放世界端到端自动驾驶框架，通过视觉-动作检索和对比学习，在未见环境中实现强泛化。


<details>
  <summary>Details</summary>
Motivation: 解决端到端自动驾驶在非结构化户外环境中遇到的训练时未见条件的挑战。

Method: 利用冻结的视觉语言模型进行开放世界检测和分割，获取多尺度、提示引导和可解释的感知特征；通过Q-Former瓶颈聚合细粒度视觉表示与语言对齐的视觉特征；引入视觉-动作对比学习方案对齐视觉语言和动作嵌入。

Result: 在真实机器人平台上，即使在数据有限的情况下，也能在非结构化、未见环境中表现出强大的泛化和探索性能。

Conclusion: VLA-R框架通过结合开放世界感知和创新的视觉-动作检索范式，展示了在非结构化、未见环境中强大的泛化和探索性能。

Abstract: Exploring open-world situations in an end-to-end manner is a promising yet challenging task due to the need for strong generalization capabilities. In particular, end-to-end autonomous driving in unstructured outdoor environments often encounters conditions that were unfamiliar during training. In this work, we present Vision-Language Action Retrieval (VLA-R), an open-world end-to-end autonomous driving (OW-E2EAD) framework that integrates open-world perception with a novel vision-action retrieval paradigm. We leverage a frozen vision-language model for open-world detection and segmentation to obtain multi-scale, prompt-guided, and interpretable perception features without domain-specific tuning. A Q-Former bottleneck aggregates fine-grained visual representations with language-aligned visual features, bridging perception and action domains. To learn transferable driving behaviors, we introduce a vision-action contrastive learning scheme that aligns vision-language and action embeddings for effective open-world reasoning and action retrieval. Our experiments on a real-world robotic platform demonstrate strong generalization and exploratory performance in unstructured, unseen environments, even with limited data. Demo videos are provided in the supplementary material.

</details>


### [118] [Self-Supervised Visual Prompting for Cross-Domain Road Damage Detection](https://arxiv.org/abs/2511.12410)
*Xi Xiao,Zhuxuanzi Wang,Mingqiao Mo,Chen Liu,Chenrui Ma,Yanshu Li,Smita Krishnaswamy,Xiao Wang,Tianyang Wang*

Main category: cs.CV

TL;DR: 自监督提示框架（\ours）通过SPEM和DAPA提升跨域泛化，在零样本迁移和少样本适应中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有监督检测器需要昂贵重新标注和自监督方法对域偏移敏感的问题，实现跨域泛化。

Method: 提出了一种自监督框架，结合SPEM模块和DAPA目标，通过无标签目标数据生成缺陷感知提示，并对齐源域和目标域的表示。

Result: 在四个基准测试中，\ours 在零样本迁移、域变化适应性和少样本适应数据效率方面均优于基线方法。

Conclusion: 论文提出了一种自监督提示框架（\ours），通过引入SPEM和DAPA目标，显著提升了跨域泛化能力，实现了稳健的零样本迁移和对域变化的高适应性。

Abstract: The deployment of automated pavement defect detection is often hindered by poor cross-domain generalization. Supervised detectors achieve strong in-domain accuracy but require costly re-annotation for new environments, while standard self-supervised methods capture generic features and remain vulnerable to domain shift. We propose \ours, a self-supervised framework that \emph{visually probes} target domains without labels. \ours introduces a Self-supervised Prompt Enhancement Module (SPEM), which derives defect-aware prompts from unlabeled target data to guide a frozen ViT backbone, and a Domain-Aware Prompt Alignment (DAPA) objective, which aligns prompt-conditioned source and target representations. Experiments on four challenging benchmarks show that \ours consistently outperforms strong supervised, self-supervised, and adaptation baselines, achieving robust zero-shot transfer, improved resilience to domain variations, and high data efficiency in few-shot adaptation. These results highlight self-supervised prompting as a practical direction for building scalable and adaptive visual inspection systems. Source code is publicly available: https://github.com/xixiaouab/PROBE/tree/main

</details>


### [119] [Towards Rotation-only Imaging Geometry: Rotation Estimation](https://arxiv.org/abs/2511.12415)
*Xinrui Li,Qi Cai,Yuanxin Wu*

Main category: cs.CV

TL;DR: 本文提出了一种基于旋转流形的优化框架，显著提高了SfM的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 为了进一步提高结构从运动（SfM）的性能，探索场景结构、旋转和平移之间的关键关系。

Method: 提出了一种基于重投影误差的纯旋转优化框架，适用于双视图和多视图场景。

Result: 实验结果表明，该方法在旋转估计上优于当前最先进的方法，甚至可与多次束调整迭代结果相媲美。

Conclusion: 本文通过探索场景结构、旋转和平移之间的关键关系，提出了一种基于旋转流形的优化框架，显著提高了3D视觉计算的准确性、效率和可靠性。

Abstract: Structure from Motion (SfM) is a critical task in computer vision, aiming to recover the 3D scene structure and camera motion from a sequence of 2D images. The recent pose-only imaging geometry decouples 3D coordinates from camera poses and demonstrates significantly better SfM performance through pose adjustment. Continuing the pose-only perspective, this paper explores the critical relationship between the scene structures, rotation and translation. Notably, the translation can be expressed in terms of rotation, allowing us to condense the imaging geometry representation onto the rotation manifold. A rotation-only optimization framework based on reprojection error is proposed for both two-view and multi-view scenarios. The experiment results demonstrate superior accuracy and robustness performance over the current state-of-the-art rotation estimation methods, even comparable to multiple bundle adjustment iteration results. Hopefully, this work contributes to even more accurate, efficient and reliable 3D visual computing.

</details>


### [120] [Seeing Through the Rain: Resolving High-Frequency Conflicts in Deraining and Super-Resolution via Diffusion Guidance](https://arxiv.org/abs/2511.12419)
*Wenjie Li,Jinglei Shi,Jin Han,Heng Guo,Zhanyu Ma*

Main category: cs.CV

TL;DR: DHGM通过扩散模型和高通滤波器结合，有效去除雨滴伪影并增强细节，性能优于现有方法且成本更低。


<details>
  <summary>Details</summary>
Motivation: 真实世界的图像常因恶劣天气退化，而现有天气恢复方法可能牺牲对分析小物体至关重要的高频细节。简单地级联恢复和超分辨率难以解决其固有冲突。

Method: 采用基于扩散的高频引导模型（DHGM），结合预训练的扩散先验和高通滤波器，同时进行天气去除和超分辨率处理。

Result: 大量实验证明，DHGM在性能和成本上均优于现有方法。

Conclusion: DHGM通过整合预训练的扩散先验和高通滤波器，在去除雨滴伪影的同时增强结构细节，取得了优于现有方法的性能且成本更低。

Abstract: Clean images are crucial for visual tasks such as small object detection, especially at high resolutions. However, real-world images are often degraded by adverse weather, and weather restoration methods may sacrifice high-frequency details critical for analyzing small objects. A natural solution is to apply super-resolution (SR) after weather removal to recover both clarity and fine structures. However, simply cascading restoration and SR struggle to bridge their inherent conflict: removal aims to remove high-frequency weather-induced noise, while SR aims to hallucinate high-frequency textures from existing details, leading to inconsistent restoration contents. In this paper, we take deraining as a case study and propose DHGM, a Diffusion-based High-frequency Guided Model for generating clean and high-resolution images. DHGM integrates pre-trained diffusion priors with high-pass filters to simultaneously remove rain artifacts and enhance structural details. Extensive experiments demonstrate that DHGM achieves superior performance over existing methods, with lower costs.

</details>


### [121] [MFI-ResNet: Efficient ResNet Architecture Optimization via MeanFlow Compression and Selective Incubation](https://arxiv.org/abs/2511.12422)
*Nuolin Sun,Linyuan Wang,Haonan Wei,Lei Li,Bin Yan*

Main category: cs.CV

TL;DR: MFI-ResNet通过生成流场优化ResNet结构，显著减少参数并提升准确率。


<details>
  <summary>Details</summary>
Motivation: 受MeanFlow模型启发，探索生成流场在ResNet中的应用，以提升参数效率和判别性能。

Method: 采用压缩-扩展策略，压缩阶段将每个ResNet阶段的多层结构简化为1-2个MeanFlow模块，扩展阶段对前三个阶段采用选择性孵化策略，使其匹配基线ResNet的残差块配置，同时保持最后阶段为MeanFlow形式。

Result: 在CIFAR-10和CIFAR-100数据集上，MFI-ResNet参数减少46.28%和45.59%，准确率提升0.23%和0.17%。

Conclusion: MFI-ResNet通过生成流场有效表征ResNet中的特征变换过程，为理解生成建模与判别学习的关系提供了新视角。

Abstract: ResNet has achieved tremendous success in computer vision through its residual connection mechanism. ResNet can be viewed as a discretized form of ordinary differential equations (ODEs). From this perspective, the multiple residual blocks within a single ResNet stage essentially perform multi-step discrete iterations of the feature transformation for that stage. The recently proposed flow matching model, MeanFlow, enables one-step generative modeling by learning the mean velocity field to transform distributions. Inspired by this, we propose MeanFlow-Incubated ResNet (MFI-ResNet), which employs a compression-expansion strategy to jointly improve parameter efficiency and discriminative performance. In the compression phase, we simplify the multi-layer structure within each ResNet stage to one or two MeanFlow modules to construct a lightweight meta model. In the expansion phase, we apply a selective incubation strategy to the first three stages, expanding them to match the residual block configuration of the baseline ResNet model, while keeping the last stage in MeanFlow form, and fine-tune the incubated model. Experimental results show that on CIFAR-10 and CIFAR-100 datasets, MFI-ResNet achieves remarkable parameter efficiency, reducing parameters by 46.28% and 45.59% compared to ResNet-50, while still improving accuracy by 0.23% and 0.17%, respectively. This demonstrates that generative flow-fields can effectively characterize the feature transformation process in ResNet, providing a new perspective for understanding the relationship between generative modeling and discriminative learning.

</details>


### [122] [RedVTP: Training-Free Acceleration of Diffusion Vision-Language Models Inference via Masked Token-Guided Visual Token Pruning](https://arxiv.org/abs/2511.12428)
*Jingqi Xu,Jingxi Lu,Chenghao Li,Sreetama Sarkar,Souvik Kundu,Peter A. Beerel*

Main category: cs.CV

TL;DR: RedVTP通过响应驱动的视觉token剪枝策略，提升DVLMs推理效率，实验显示显著吞吐量提升和延迟降低，且不影响准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散视觉语言模型（DVLMs）因并行token解码而具吸引力，但大量视觉token仍显著影响推理效率。视觉token剪枝在自回归VLMs中研究较多，但在DVLMs中尚未充分探索。

Method: 提出RedVTP，一种基于响应驱动的视觉token剪枝策略，利用DVLMs的推理动态性，通过掩码响应token的注意力估计视觉token重要性，并在首步推理后剪枝不重要token。

Result: 实验表明，RedVTP显著提升LLaDA-V和LaViDa的token生成吞吐量（分别达186%和28.05%），并降低推理延迟（达64.97%和21.87%），同时保持或提升准确性。

Conclusion: RedVTP显著提升了DVLMs的推理效率，在不损失甚至提升准确性的情况下，实现了高达186%的生成吞吐量提升和64.97%的延迟降低。

Abstract: Vision-Language Models (VLMs) have achieved remarkable progress in multimodal reasoning and generation, yet their high computational demands remain a major challenge. Diffusion Vision-Language Models (DVLMs) are particularly attractive because they enable parallel token decoding, but the large number of visual tokens still significantly hinders their inference efficiency. While visual token pruning has been extensively studied for autoregressive VLMs (AVLMs), it remains largely unexplored for DVLMs. In this work, we propose RedVTP, a response-driven visual token pruning strategy that leverages the inference dynamics of DVLMs. Our method estimates visual token importance using attention from the masked response tokens. Based on the observation that these importance scores remain consistent across steps, RedVTP prunes the less important visual tokens from the masked tokens after the first inference step, thereby maximizing inference efficiency. Experiments show that RedVTP improves token generation throughput of LLaDA-V and LaViDa by up to 186% and 28.05%, respectively, and reduces inference latency by up to 64.97% and 21.87%, without compromising-and in some cases improving-accuracy.

</details>


### [123] [Text-Guided Channel Perturbation and Pretrained Knowledge Integration for Unified Multi-Modality Image Fusion](https://arxiv.org/abs/2511.12432)
*Xilai Li,Xiaosong Li,Weijun Jiang*

Main category: cs.CV

TL;DR: UP-Fusion框架通过通道扰动和预训练知识整合提升多模态图像融合性能，解决了模态差异导致的梯度冲突问题。


<details>
  <summary>Details</summary>
Motivation: 现有统一模型在多模态图像融合中因模态差异大导致梯度冲突，性能受限；而模态特定编码器虽提升融合质量，却降低泛化能力。

Method: 提出UP-Fusion框架，包含SCPM模块（利用预训练模型语义感知筛选通道）、GAM模块（几何仿射变换保持模态区分性）和TCPM模块（解码时通道扰动减少对特定模态的依赖）。

Result: 实验表明，该算法在多模态图像融合及下游任务中均优于现有方法。

Conclusion: UP-Fusion通过创新模块设计有效平衡了融合质量与泛化能力，为多模态图像融合提供了新思路。

Abstract: Multi-modality image fusion enhances scene perception by combining complementary information. Unified models aim to share parameters across modalities for multi-modality image fusion, but large modality differences often cause gradient conflicts, limiting performance. Some methods introduce modality-specific encoders to enhance feature perception and improve fusion quality. However, this strategy reduces generalisation across different fusion tasks. To overcome this limitation, we propose a unified multi-modality image fusion framework based on channel perturbation and pre-trained knowledge integration (UP-Fusion). To suppress redundant modal information and emphasize key features, we propose the Semantic-Aware Channel Pruning Module (SCPM), which leverages the semantic perception capability of a pre-trained model to filter and enhance multi-modality feature channels. Furthermore, we proposed the Geometric Affine Modulation Module (GAM), which uses original modal features to apply affine transformations on initial fusion features to maintain the feature encoder modal discriminability. Finally, we apply a Text-Guided Channel Perturbation Module (TCPM) during decoding to reshape the channel distribution, reducing the dependence on modality-specific channels. Extensive experiments demonstrate that the proposed algorithm outperforms existing methods on both multi-modality image fusion and downstream tasks.

</details>


### [124] [Real-Time Drivers' Drowsiness Detection and Analysis through Deep Learning](https://arxiv.org/abs/2511.12438)
*ANK Zaman,Prosenjit Chatterjee,Rajat Sharma*

Main category: cs.CV

TL;DR: Developed a real-time driver drowsiness detection system using DCNNs and OpenCV, achieving high accuracy in identifying drowsy drivers to enhance road safety.


<details>
  <summary>Details</summary>
Motivation: Long drives can lead to drowsiness, posing serious safety risks. A real-time detection system is needed to alert drivers and prevent accidents.

Method: Utilizes deep convolutional neural networks (DCNNs) and OpenCV to analyze real-time facial images for drowsiness indicators like eye closures and yawns.

Result: Achieved classification accuracies of 99.6% and 97% on the NTHU-DDD and Yawn-Eye-Dataset, respectively.

Conclusion: The proposed DCNNs-based drowsiness detection system proves to be highly accurate and cost-effective, potentially saving lives by preventing drowsy driving incidents.

Abstract: A long road trip is fun for drivers. However, a long drive for days can be tedious for a driver to accommodate stringent deadlines to reach distant destinations. Such a scenario forces drivers to drive extra miles, utilizing extra hours daily without sufficient rest and breaks. Once a driver undergoes such a scenario, it occasionally triggers drowsiness during driving. Drowsiness in driving can be life-threatening to any individual and can affect other drivers' safety; therefore, a real-time detection system is needed. To identify fatigued facial characteristics in drivers and trigger the alarm immediately, this research develops a real-time driver drowsiness detection system utilizing deep convolutional neural networks (DCNNs) and OpenCV.Our proposed and implemented model takes real- time facial images of a driver using a live camera and utilizes a Python-based library named OpenCV to examine the facial images for facial landmarks like sufficient eye openings and yawn-like mouth movements. The DCNNs framework then gathers the data and utilizes a per-trained model to detect the drowsiness of a driver using facial landmarks. If the driver is identified as drowsy, the system issues a continuous alert in real time, embedded in the Smart Car technology.By potentially saving innocent lives on the roadways, the proposed technique offers a non-invasive, inexpensive, and cost-effective way to identify drowsiness. Our proposed and implemented DCNNs embedded drowsiness detection model successfully react with NTHU-DDD dataset and Yawn-Eye-Dataset with drowsiness detection classification accuracy of 99.6% and 97% respectively.

</details>


### [125] [CoTBox-TTT: Grounding Medical VQA with Visual Chain-of-Thought Boxes During Test-time Training](https://arxiv.org/abs/2511.12446)
*Jiahe Qian,Yuhao Shen,Zhangtianyi Chen,Juexiao Zhou,Peisong Wang*

Main category: cs.CV

TL;DR: CoTBox-TTT是一种无需标签的测试时训练方法，通过视觉链式思维和局部裁剪提升医学VQA的可靠性和准确性。


<details>
  <summary>Details</summary>
Motivation: 当前医学视觉问答系统在领域转移时可靠性不足，且答案缺乏图像证据支持，亟需一种无需重新训练或额外标签的实用解决方案。

Method: 采用测试时训练（TTT）方法，仅更新少量连续的软提示（soft prompts），通过视觉链式思维信号识别问题相关区域，并确保原始图像与局部裁剪的答案一致性。整个过程无需额外标签，且可与多种骨干模型兼容。

Result: 实验表明，CoTBox-TTT显著提升了模型性能，例如在pathVQA数据集上，将LLaVA的闭式问题准确率提高了12.3%。

Conclusion: CoTBox-TTT方法通过测试时训练和视觉链式思维信号有效提升了医学视觉问答系统的可靠性和准确性，尤其在领域转移和标签不足的情况下表现出色。

Abstract: Medical visual question answering could support clinical decision making, yet current systems often fail under domain shift and produce answers that are weakly grounded in image evidence. This reliability gap arises when models attend to spurious regions and when retraining or additional labels are impractical at deployment time. We address this setting with CoTBox-TTT, an evidence-first test-time training approach that adapts a vision-language model at inference while keeping all backbones frozen. The method updates only a small set of continuous soft prompts. It identifies question-relevant regions through a visual chain-of-thought signal and encourages answer consistency across the original image and a localized crop. The procedure is label free, and plug and play with diverse backbones. Experiments on medical VQA show that the approach is practical for real deployments. For instance, adding CoTBox-TTT to LLaVA increases closed-ended accuracy by 12.3% on pathVQA.

</details>


### [126] [MOON2.0: Dynamic Modality-balanced Multimodal Representation Learning for E-commerce Product Understanding](https://arxiv.org/abs/2511.12449)
*Zhanheng Nie,Chenghan Fu,Daoze Zhang,Junxian Wu,Wanxian Guan,Pengjie Wang,Jian Xu,Bo Zheng*

Main category: cs.CV

TL;DR: MOON2.0是一个动态模态平衡的多模态表示学习框架，通过MoE模块、双级对齐和协同增强策略解决了电子商务产品理解的三大挑战，取得了优越性能。


<details>
  <summary>Details</summary>
Motivation: 电子商务的快速发展需要理解丰富的视觉和文本产品信息的多模态模型，但现有模型面临模态不平衡、内在对齐关系利用不足和数据噪声等挑战。

Method: MOON2.0包含三个核心模块：模态驱动的混合专家（MoE）模块、双级对齐方法和基于MLLM的图像-文本协同增强策略，结合动态样本过滤。

Result: 实验表明，MOON2.0在MBE2.0和多个公共数据集上实现了最先进的零样本性能，并通过注意力热图可视化展示了改进的多模态对齐效果。

Conclusion: MOON2.0通过动态模态平衡的多模态表示学习框架，解决了电子商务产品理解中的模态不平衡、内在对齐关系利用不足和数据噪声问题，实现了最先进的零样本性能。

Abstract: The rapid growth of e-commerce calls for multimodal models that comprehend rich visual and textual product information. Although recent multimodal large language models (MLLMs) for product understanding exhibit strong capability in representation learning for e-commerce, they still face three challenges: (i) the modality imbalance induced by modality mixed training; (ii) underutilization of the intrinsic alignment relationships among visual and textual information within a product; and (iii) limited handling of noise in e-commerce multimodal data. To address these, we propose MOON2.0, a dynamic modality-balanced multimodal representation learning framework for e-commerce product understanding. MOON2.0 comprises: (1) a Modality-driven Mixture-of-Experts (MoE) module that adaptively processes input samples by their modality composition, enabling Multimodal Joint Learning to mitigate the modality imbalance; (2) a Dual-level Alignment method to better leverage semantic alignment properties inside individual products; and (3) an MLLM-based Image-text Co-augmentation strategy that integrates textual enrichment with visual expansion, coupled with Dynamic Sample Filtering to improve training data quality. We further introduce MBE2.0, a co-augmented multimodal representation benchmark for e-commerce representation learning and evaluation. Experiments show that MOON2.0 delivers state-of-the-art zero-shot performance on MBE2.0 and multiple public datasets. Furthermore, attention-based heatmap visualization provides qualitative evidence of improved multimodal alignment of MOON2.0.

</details>


### [127] [DenseAnnotate: Enabling Scalable Dense Caption Collection for Images and 3D Scenes via Spoken Descriptions](https://arxiv.org/abs/2511.12452)
*Xiaoyu Lin,Aniket Ghorpade,Hansheng Zhu,Justin Qiu,Dea Rrozhani,Monica Lama,Mick Yang,Zixuan Bian,Ruohan Ren,Alan B. Hong,Jiatao Gu,Chris Callison-Burch*

Main category: cs.CV

TL;DR: DenseAnnotate平台通过音频驱动注释，高效创建密集注释，提升模型在多语言、文化对齐和3D空间能力上的表现。


<details>
  <summary>Details</summary>
Motivation: 当前训练数据集依赖稀疏注释，无法充分捕捉图像视觉内容，传统文本注释方法效率低且表达有限。

Method: 提出DenseAnnotate，一个音频驱动的在线注释平台，结合语音转文字和注意力区域标记技术。

Result: 模型在数据集上表现提升：多语言5%，文化对齐47%，3D空间能力54%。

Conclusion: DenseAnnotate平台为未来视觉语言研究提供了一种可行的方法，适用于多种任务和数据类型。

Abstract: With the rapid adoption of multimodal large language models (MLLMs) across diverse applications, there is a pressing need for task-centered, high-quality training data. A key limitation of current training datasets is their reliance on sparse annotations mined from the Internet or entered via manual typing that capture only a fraction of an image's visual content. Dense annotations are more valuable but remain scarce. Traditional text-based annotation pipelines are poorly suited for creating dense annotations: typing limits expressiveness, slows annotation speed, and underrepresents nuanced visual features, especially in specialized areas such as multicultural imagery and 3D asset annotation. In this paper, we present DenseAnnotate, an audio-driven online annotation platform that enables efficient creation of dense, fine-grained annotations for images and 3D assets. Annotators narrate observations aloud while synchronously linking spoken phrases to image regions or 3D scene parts. Our platform incorporates speech-to-text transcription and region-of-attention marking. To demonstrate the effectiveness of DenseAnnotate, we conducted case studies involving over 1,000 annotators across two domains: culturally diverse images and 3D scenes. We curate a human-annotated multi-modal dataset of 3,531 images, 898 3D scenes, and 7,460 3D objects, with audio-aligned dense annotations in 20 languages, including 8,746 image captions, 2,000 scene captions, and 19,000 object captions. Models trained on this dataset exhibit improvements of 5% in multilingual, 47% in cultural alignment, and 54% in 3D spatial capabilities. Our results show that our platform offers a feasible approach for future vision-language research and can be applied to various tasks and diverse types of data.

</details>


### [128] [MaskAnyNet: Rethinking Masked Image Regions as Valuable Information in Supervised Learning](https://arxiv.org/abs/2511.12480)
*Jingshan Hong,Haigen Hu,Huihuang Zhang,Qianwei Zhou,Zhao Li*

Main category: cs.CV

TL;DR: MaskAnyNet通过将掩码内容作为辅助知识并引入重新学习机制，有效利用了掩码区域的语义多样性，提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统图像掩码存在像素未充分利用和关键特征丢失的问题，而掩码图像建模（MIM）显示掩码区域可重建，表明不完整数据仍具强上下文一致性。因此，将掩码内容视为辅助知识而非忽略，以挖掘其语义多样性潜力。

Method: 提出MaskAnyNet，结合掩码与重新学习机制，通过额外分支共同学习重组掩码区域，以利用掩码区域的语义多样性丰富特征并保留细粒度细节。

Result: 在CNN和Transformer骨干网络上的实验表明，该方法在多个基准测试中均能带来一致性能提升，且通过重用掩码内容增强了语义多样性。

Conclusion: 本文提出MaskAnyNet，通过将掩码内容视为辅助知识而非忽略，结合重新学习机制，有效利用了可见和掩码信息。实验证明该方法在CNN和Transformer骨干网络上均能提升性能，并通过重用掩码内容增强了语义多样性。

Abstract: In supervised learning, traditional image masking faces two key issues: (i) discarded pixels are underutilized, leading to a loss of valuable contextual information; (ii) masking may remove small or critical features, especially in fine-grained tasks. In contrast, masked image modeling (MIM) has demonstrated that masked regions can be reconstructed from partial input, revealing that even incomplete data can exhibit strong contextual consistency with the original image. This highlights the potential of masked regions as sources of semantic diversity. Motivated by this, we revisit the image masking approach, proposing to treat masked content as auxiliary knowledge rather than ignored. Based on this, we propose MaskAnyNet, which combines masking with a relearning mechanism to exploit both visible and masked information. It can be easily extended to any model with an additional branch to jointly learn from the recomposed masked region. This approach leverages the semantic diversity of the masked regions to enrich features and preserve fine-grained details. Experiments on CNN and Transformer backbones show consistent gains across multiple benchmarks. Further analysis confirms that the proposed method improves semantic diversity through the reuse of masked content.

</details>


### [129] [Towards Temporal Fusion Beyond the Field of View for Camera-based Semantic Scene Completion](https://arxiv.org/abs/2511.12498)
*Jongseong Bae,Junwoo Ha,Jinnyeong Heo,Yeongin Lee,Ha Young Kim*

Main category: cs.CV

TL;DR: C3DFusion通过历史与当前帧的3D特征对齐，提升了3D语义场景补全中不可见区域的恢复能力，性能显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法侧重于增强帧内区域，但忽视了帧外关键区域的恢复，尽管历史帧中常包含这些区域的上下文信息。

Method: 提出Current-Centric Contextual 3D Fusion (C3DFusion)模块，通过历史上下文模糊化和当前中心特征密集化两种互补技术，增强时间融合效果。

Result: C3DFusion在SemanticKITTI和SSCBench-KITTI-360数据集上显著优于现有方法，并展示了强大的泛化能力。

Conclusion: C3DFusion模块通过显式对齐当前和历史帧的3D特征几何，显著提升了3D语义场景补全的性能，尤其在不可见区域的恢复上表现出色，并在多个数据集上超越了现有方法。

Abstract: Recent camera-based 3D semantic scene completion (SSC) methods have increasingly explored leveraging temporal cues to enrich the features of the current frame. However, while these approaches primarily focus on enhancing in-frame regions, they often struggle to reconstruct critical out-of-frame areas near the sides of the ego-vehicle, although previous frames commonly contain valuable contextual information about these unseen regions. To address this limitation, we propose the Current-Centric Contextual 3D Fusion (C3DFusion) module, which generates hidden region-aware 3D feature geometry by explicitly aligning 3D-lifted point features from both current and historical frames. C3DFusion performs enhanced temporal fusion through two complementary techniques-historical context blurring and current-centric feature densification-which suppress noise from inaccurately warped historical point features by attenuating their scale, and enhance current point features by increasing their volumetric contribution. Simply integrated into standard SSC architectures, C3DFusion demonstrates strong effectiveness, significantly outperforming state-of-the-art methods on the SemanticKITTI and SSCBench-KITTI-360 datasets. Furthermore, it exhibits robust generalization, achieving notable performance gains when applied to other baseline models.

</details>


### [130] [Visible Structure Retrieval for Lightweight Image-Based Relocalisation](https://arxiv.org/abs/2511.12503)
*Fereidoon Zangeneh,Leonard Bruns,Amit Dekel,Alessandro Pieropan,Patric Jensfelt*

Main category: cs.CV

TL;DR: 提出了一种新型可见结构检索网络，直接从图像映射到3D结构点，减少2D-3D对应搜索空间，实现高效定位。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖复杂的搜索启发式或图像检索，导致流程繁琐或存储需求随观测数量增长。为了解决这一问题，作者提出了直接学习图像到场景结构的映射。

Method: 通过训练一个紧凑的神经网络，直接从图像观测映射到可见场景结构，避免了传统的图像检索或搜索启发式方法。

Result: 实验表明，新方法在定位精度上与现有技术相当，但计算和存储开销更低。

Conclusion: 提出的新方法在保持定位精度的同时，显著降低了计算和存储需求，为基于结构的重定位提供了更高效的解决方案。

Abstract: Accurate camera pose estimation from an image observation in a previously mapped environment is commonly done through structure-based methods: by finding correspondences between 2D keypoints on the image and 3D structure points in the map. In order to make this correspondence search tractable in large scenes, existing pipelines either rely on search heuristics, or perform image retrieval to reduce the search space by comparing the current image to a database of past observations. However, these approaches result in elaborate pipelines or storage requirements that grow with the number of past observations. In this work, we propose a new paradigm for making structure-based relocalisation tractable. Instead of relying on image retrieval or search heuristics, we learn a direct mapping from image observations to the visible scene structure in a compact neural network. Given a query image, a forward pass through our novel visible structure retrieval network allows obtaining the subset of 3D structure points in the map that the image views, thus reducing the search space of 2D-3D correspondences. We show that our proposed method enables performing localisation with an accuracy comparable to the state of the art, while requiring lower computational and storage footprint.

</details>


### [131] [DINO-Detect: A Simple yet Effective Framework for Blur-Robust AI-Generated Image Detection](https://arxiv.org/abs/2511.12511)
*Jialiang Shen,Jiyang Zheng,Yunqi Xue,Huajie Chen,Yu Yao,Hui Kang,Ruiqi Liu,Helin Gong,Yang Yang,Dadong Wang,Tongliang Liu*

Main category: cs.CV

TL;DR: 提出一种模糊鲁棒的AIGI检测框架，通过师生知识蒸馏提升在运动模糊条件下的检测性能，实验显示其在现实场景中具有优越表现。


<details>
  <summary>Details</summary>
Motivation: 现有的AIGI检测器在现实世界中的运动模糊等退化条件下表现不佳，模糊会扭曲细微纹理并抑制高频伪影，导致性能严重下降。

Method: 采用高容量教师模型（DINOv3）在干净图像上训练，通过冻结教师模型以保持其泛化能力，将其特征和逻辑响应从清晰图像蒸馏到在模糊图像上训练的学生模型中。

Result: 实验结果表明，该方法在运动模糊和干净条件下均达到了最先进的性能，表现出改进的泛化能力和实际适用性。

Conclusion: 该论文提出了一种基于师生知识蒸馏的模糊鲁棒AIGI检测框架，显著提升了在运动模糊和干净条件下的检测性能，并展示了良好的泛化能力和实际应用价值。

Abstract: With growing concerns over image authenticity and digital safety, the field of AI-generated image (AIGI) detection has progressed rapidly. Yet, most AIGI detectors still struggle under real-world degradations, particularly motion blur, which frequently occurs in handheld photography, fast motion, and compressed video. Such blur distorts fine textures and suppresses high-frequency artifacts, causing severe performance drops in real-world settings. We address this limitation with a blur-robust AIGI detection framework based on teacher-student knowledge distillation. A high-capacity teacher (DINOv3), trained on clean (i.e., sharp) images, provides stable and semantically rich representations that serve as a reference for learning. By freezing the teacher to maintain its generalization ability, we distill its feature and logit responses from sharp images to a student trained on blurred counterparts, enabling the student to produce consistent representations under motion degradation. Extensive experiments benchmarks show that our method achieves state-of-the-art performance under both motion-blurred and clean conditions, demonstrating improved generalization and real-world applicability. Source codes will be released at: https://github.com/JiaLiangShen/Dino-Detect-for-blur-robust-AIGC-Detection.

</details>


### [132] [MdaIF: Robust One-Stop Multi-Degradation-Aware Image Fusion with Language-Driven Semantics](https://arxiv.org/abs/2511.12525)
*Jing Li,Yifan Wang,Jiafeng Yan,Renlong Zhang,Bin Yang*

Main category: cs.CV

TL;DR: 提出了一种降解感知的图像融合框架（MdaIF），结合MoE和VLM，通过DCAM模块实现多模态特征交互，在多种退化场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能考虑恶劣天气条件下可见光图像的退化问题，且网络架构固定，难以适应多样化退化场景。

Method: 结合大型语言模型驱动的混合专家系统（MoE）和预训练的视觉语言模型（VLM），提出了一种降解感知通道注意力模块（DCAM），用于多模态特征交互。

Result: 大量实验验证了MdaIF的有效性，展示了其在复杂退化场景中的优越性能。

Conclusion: 通过提出的MdaIF框架，在多种退化场景下实现了鲁棒的图像融合，性能优于现有最先进方法。

Abstract: Infrared and visible image fusion aims to integrate complementary multi-modal information into a single fused result. However, existing methods 1) fail to account for the degradation visible images under adverse weather conditions, thereby compromising fusion performance; and 2) rely on fixed network architectures, limiting their adaptability to diverse degradation scenarios. To address these issues, we propose a one-stop degradation-aware image fusion framework for multi-degradation scenarios driven by a large language model (MdaIF). Given the distinct scattering characteristics of different degradation scenarios (e.g., haze, rain, and snow) in atmospheric transmission, a mixture-of-experts (MoE) system is introduced to tackle image fusion across multiple degradation scenarios. To adaptively extract diverse weather-aware degradation knowledge and scene feature representations, collectively referred to as the semantic prior, we employ a pre-trained vision-language model (VLM) in our framework. Guided by the semantic prior, we propose degradation-aware channel attention module (DCAM), which employ degradation prototype decomposition to facilitate multi-modal feature interaction in channel domain. In addition, to achieve effective expert routing, the semantic prior and channel-domain modulated features are utilized to guide the MoE, enabling robust image fusion in complex degradation scenarios. Extensive experiments validate the effectiveness of our MdaIF, demonstrating superior performance over SOTA methods.

</details>


### [133] [D$^{2}$-VPR: A Parameter-efficient Visual-foundation-model-based Visual Place Recognition Method via Knowledge Distillation and Deformable Aggregation](https://arxiv.org/abs/2511.12528)
*Zheyuan Zhang,Jiwei Zhang,Boyu Zhou,Linzhimeng Duan,Hong Chen*

Main category: cs.CV

TL;DR: D²-VPR通过知识蒸馏和可变形聚合器优化VPR任务，显著降低模型复杂度，保持高性能。


<details>
  <summary>Details</summary>
Motivation: 解决视觉基础模型在VPR任务中模型复杂度和计算开销大的问题，提升在资源受限设备上的部署可行性。

Method: 采用两阶段训练策略结合知识蒸馏和微调，引入蒸馏恢复模块（DRM）对齐师生模型特征空间；设计基于自上而下注意力的可变形聚合器（TDDA）动态调整感兴趣区域。

Result: D²-VPR在性能上与先进方法相当，同时参数减少约64.2%，FLOPs降低约62.6%（相比CricaVPR）。

Conclusion: D²-VPR框架通过知识蒸馏和可变形聚合器，显著减少了模型参数和计算开销，同时保持了高性能，为资源受限设备的部署提供了有效解决方案。

Abstract: Visual Place Recognition (VPR) aims to determine the geographic location of a query image by retrieving its most visually similar counterpart from a geo-tagged reference database. Recently, the emergence of the powerful visual foundation model, DINOv2, trained in a self-supervised manner on massive datasets, has significantly improved VPR performance. This improvement stems from DINOv2's exceptional feature generalization capabilities but is often accompanied by increased model complexity and computational overhead that impede deployment on resource-constrained devices. To address this challenge, we propose $D^{2}$-VPR, a $D$istillation- and $D$eformable-based framework that retains the strong feature extraction capabilities of visual foundation models while significantly reducing model parameters and achieving a more favorable performance-efficiency trade-off. Specifically, first, we employ a two-stage training strategy that integrates knowledge distillation and fine-tuning. Additionally, we introduce a Distillation Recovery Module (DRM) to better align the feature spaces between the teacher and student models, thereby minimizing knowledge transfer losses to the greatest extent possible. Second, we design a Top-Down-attention-based Deformable Aggregator (TDDA) that leverages global semantic features to dynamically and adaptively adjust the Regions of Interest (ROI) used for aggregation, thereby improving adaptability to irregular structures. Extensive experiments demonstrate that our method achieves competitive performance compared to state-of-the-art approaches. Meanwhile, it reduces the parameter count by approximately 64.2% and FLOPs by about 62.6% (compared to CricaVPR).Code is available at https://github.com/tony19980810/D2VPR.

</details>


### [134] [ReaSon: Reinforced Causal Search with Information Bottleneck for Video Understanding](https://arxiv.org/abs/2511.12530)
*Yuan Zhou,Litao Hua,Shilong Jin,Wentao Huang,Haoran Duan*

Main category: cs.CV

TL;DR: ReaSon框架通过因果信息瓶颈（CIB）优化关键帧选择，结合预测充分性和因果必要性，在有限帧设置下超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决视频理解中因输入令牌有限和视频帧时间稀疏性导致的关键帧选择问题，提出既信息丰富又因果决定性的关键帧选择方法。

Method: ReaSon采用可学习的策略网络从候选帧中选择关键帧以捕捉预测充分性，并通过反事实干预评估因果必要性，最后设计符合CIB原则的复合奖励通过强化学习指导选择策略。

Result: 在NExT-QA、EgoSchema和Video-MME数据集上的广泛实验表明，ReaSon在有限帧设置下始终优于现有最先进方法。

Conclusion: ReaSon框架通过结合因果信息瓶颈（CIB）原则，在有限帧设置下显著优于现有方法，验证了其有效性和泛化能力。

Abstract: Keyframe selection has become essential for video understanding with vision-language models (VLMs) due to limited input tokens and the temporal sparsity of relevant information across video frames. Video understanding often relies on effective keyframes that are not only informative but also causally decisive. To this end, we propose Reinforced Causal Search with Information Bottleneck (ReaSon), a framework that formulates keyframe selection as an optimization problem with the help of a novel Causal Information Bottleneck (CIB), which explicitly defines keyframes as those satisfying both predictive sufficiency and causal necessity. Specifically, ReaSon employs a learnable policy network to select keyframes from a visually relevant pool of candidate frames to capture predictive sufficiency, and then assesses causal necessity via counterfactual interventions. Finally, a composite reward aligned with the CIB principle is designed to guide the selection policy through reinforcement learning. Extensive experiments on NExT-QA, EgoSchema, and Video-MME demonstrate that ReaSon consistently outperforms existing state-of-the-art methods under limited-frame settings, validating its effectiveness and generalization ability.

</details>


### [135] [HiGFA: Hierarchical Guidance for Fine-grained Data Augmentation with Diffusion Models](https://arxiv.org/abs/2511.12547)
*Zhiguang Lu,Qianqian Xu,Peisong Wen,Siran Da,Qingming Huang*

Main category: cs.CV

TL;DR: HiGFA是一种分层引导的细粒度数据增强方法，通过动态调整引导信号生成高质量合成图像，提升细粒度分类性能。


<details>
  <summary>Details</summary>
Motivation: 解决生成扩散模型在细粒度任务中难以准确捕捉细微、类别定义特征的挑战，避免生成误导性样本导致分类器性能下降。

Method: HiGFA利用扩散采样过程的时间动态性，在早期到中期阶段采用强文本和变换轮廓引导，后期阶段则激活专门的细粒度分类器引导，并根据预测置信度动态调整所有引导信号的强度。

Result: 在多个细粒度视觉分类数据集上的实验证明了HiGFA的有效性。

Conclusion: HiGFA通过分层和置信度驱动的引导方法，能够生成既多样又忠实于原始类别的合成图像，有效提升了细粒度分类任务的性能。

Abstract: Generative diffusion models show promise for data augmentation. However, applying them to fine-grained tasks presents a significant challenge: ensuring synthetic images accurately capture the subtle, category-defining features critical for high fidelity. Standard approaches, such as text-based Classifier-Free Guidance (CFG), often lack the required specificity, potentially generating misleading examples that degrade fine-grained classifier performance. To address this, we propose Hierarchically Guided Fine-grained Augmentation (HiGFA). HiGFA leverages the temporal dynamics of the diffusion sampling process. It employs strong text and transformed contour guidance with fixed strengths in the early-to-mid sampling stages to establish overall scene, style, and structure. In the final sampling stages, HiGFA activates a specialized fine-grained classifier guidance and dynamically modulates the strength of all guidance signals based on prediction confidence. This hierarchical, confidence-driven orchestration enables HiGFA to generate diverse yet faithful synthetic images by intelligently balancing global structure formation with precise detail refinement. Experiments on several FGVC datasets demonstrate the effectiveness of HiGFA.

</details>


### [136] [EmoVerse: A MLLMs-Driven Emotion Representation Dataset for Interpretable Visual Emotion Analysis](https://arxiv.org/abs/2511.12554)
*Yijie Guo,Dexiang Hong,Weidong Chen,Zihan She,Cheng Ye,Xiaojun Chang,Zhendong Mao*

Main category: cs.CV

TL;DR: EmoVerse是一个大规模开源数据集，通过B-A-S三元组和多层标注实现可解释的视觉情感分析，支持CES和DES双标注，并提出了一个解释性模型。


<details>
  <summary>Details</summary>
Motivation: 填补视觉情感分析领域开源和可解释数据集的空白，解决现有研究中对视觉元素如何影响情感的局限性理解问题。

Method: 通过将情感分解为背景-属性-主体（B-A-S）三元组并将每个元素与视觉区域关联，EmoVerse提供了词级和主体级的情感推理。此外，采用多阶段标注流程确保高标注可靠性。

Result: EmoVerse数据集包含超过219k张图像，支持分类情感状态（CES）和维度情感空间（DES）的双标注，实现了离散和连续情感表示的统一。提出的解释性模型能将视觉线索映射到DES表示并提供详细归因解释。

Conclusion: EmoVerse数据集、标注流程和解释性模型共同为推进可解释的高级情感理解提供了全面的基础。

Abstract: Visual Emotion Analysis (VEA) aims to bridge the affective gap between visual content and human emotional responses. Despite its promise, progress in this field remains limited by the lack of open-source and interpretable datasets. Most existing studies assign a single discrete emotion label to an entire image, offering limited insight into how visual elements contribute to emotion. In this work, we introduce EmoVerse, a large-scale open-source dataset that enables interpretable visual emotion analysis through multi-layered, knowledge-graph-inspired annotations. By decomposing emotions into Background-Attribute-Subject (B-A-S) triplets and grounding each element to visual regions, EmoVerse provides word-level and subject-level emotional reasoning. With over 219k images, the dataset further includes dual annotations in Categorical Emotion States (CES) and Dimensional Emotion Space (DES), facilitating unified discrete and continuous emotion representation. A novel multi-stage pipeline ensures high annotation reliability with minimal human effort. Finally, we introduce an interpretable model that maps visual cues into DES representations and provides detailed attribution explanations. Together, the dataset, pipeline, and model form a comprehensive foundation for advancing explainable high-level emotion understanding.

</details>


### [137] [SEMC: Structure-Enhanced Mixture-of-Experts Contrastive Learning for Ultrasound Standard Plane Recognition](https://arxiv.org/abs/2511.12559)
*Qing Cai,Guihao Yan,Fan Zhang,Cheng Zhang,Zhi Liu*

Main category: cs.CV

TL;DR: SEMC结合结构感知特征融合和专家引导对比学习，显著提升超声标准平面识别性能，实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有的方法未能有效利用浅层结构信息，且难以通过图像增强生成的对比样本捕捉细粒度语义差异，导致超声标准平面的结构和判别性细节识别效果不佳。

Method: 提出了SEMC框架，包括语义-结构融合模块（SSFM）和多专家对比识别模块（MCRM），以充分利用多尺度结构信息并通过MoE机制进行分层对比学习。

Result: 在内部数据集和两个公共数据集上的广泛实验表明，SEMC在各种指标上均优于当前最先进的方法。

Conclusion: SEMC框架通过结合结构感知特征融合和专家引导的对比学习，显著提升了超声标准平面的识别性能，并在多个数据集上验证了其优越性。

Abstract: Ultrasound standard plane recognition is essential for clinical tasks such as disease screening, organ evaluation, and biometric measurement. However, existing methods fail to effectively exploit shallow structural information and struggle to capture fine-grained semantic differences through contrastive samples generated by image augmentations, ultimately resulting in suboptimal recognition of both structural and discriminative details in ultrasound standard planes. To address these issues, we propose SEMC, a novel Structure-Enhanced Mixture-of-Experts Contrastive learning framework that combines structure-aware feature fusion with expert-guided contrastive learning. Specifically, we first introduce a novel Semantic-Structure Fusion Module (SSFM) to exploit multi-scale structural information and enhance the model's ability to perceive fine-grained structural details by effectively aligning shallow and deep features. Then, a novel Mixture-of-Experts Contrastive Recognition Module (MCRM) is designed to perform hierarchical contrastive learning and classification across multi-level features using a mixture-of-experts (MoE) mechanism, further improving class separability and recognition performance. More importantly, we also curate a large-scale and meticulously annotated liver ultrasound dataset containing six standard planes. Extensive experimental results on our in-house dataset and two public datasets demonstrate that SEMC outperforms recent state-of-the-art methods across various metrics.

</details>


### [138] [Through-Foliage Surface-Temperature Reconstruction for early Wildfire Detection](https://arxiv.org/abs/2511.12572)
*Mohamed Youssef,Lukas Brunner,Klaus Rundhammer,Gerald Czech,Oliver Bimber*

Main category: cs.CV

TL;DR: 新方法结合信号处理和机器学习，通过视觉状态空间模型和模拟数据生成，显著提升无人机在野火监测中的温度重建精度。


<details>
  <summary>Details</summary>
Motivation: 旨在实现无人机自动化空中野火监测，以便在烟雾或火焰可见之前早期发现地面火灾。

Method: 通过训练视觉状态空间模型来从热模糊数据中恢复被部分遮挡的土壤和火点的细微热信号，并利用潜在扩散模型和向量量化生成大量真实的地表温度模拟数据。

Result: 在模拟数据中，该方法相较于传统热成像和未校正的SA成像，RMSE降低了2到2.5倍；在高热点温度的实地实验中，改进更为显著，RMSE增益达到12.8倍（与传统热成像相比）和2.6倍（与未校正SA成像相比）。

Conclusion: 该论文提出了一种结合信号处理和机器学习的新方法，能够有效重建被森林植被遮挡的地表温度，显著提高了无人机在野火监测中的自动化能力。

Abstract: We introduce a novel method for reconstructing surface temperatures through occluding forest vegetation by combining signal processing and machine learning. Our goal is to enable fully automated aerial wildfire monitoring using autonomous drones, allowing for the early detection of ground fires before smoke or flames are visible. While synthetic aperture (SA) sensing mitigates occlusion from the canopy and sunlight, it introduces thermal blur that obscures the actual surface temperatures. To address this, we train a visual state space model to recover the subtle thermal signals of partially occluded soil and fire hotspots from this blurred data. A key challenge was the scarcity of real-world training data. We overcome this by integrating a latent diffusion model into a vector quantized to generated a large volume of realistic surface temperature simulations from real wildfire recordings, which we further expanded through temperature augmentation and procedural thermal forest simulation. On simulated data across varied ambient and surface temperatures, forest densities, and sunlight conditions, our method reduced the RMSE by a factor of 2 to 2.5 compared to conventional thermal and uncorrected SA imaging. In field experiments focused on high-temperature hotspots, the improvement was even more significant, with a 12.8-fold RMSE gain over conventional thermal and a 2.6-fold gain over uncorrected SA images. We also demonstrate our model's generalization to other thermal signals, such as human signatures for search and rescue. Since simple thresholding is frequently inadequate for detecting subtle thermal signals, the morphological characteristics are equally essential for accurate classification. Our experiments demonstrated another clear advantage: we reconstructed the complete morphology of fire and human signatures, whereas conventional imaging is defeated by partial occlusion.

</details>


### [139] [Beyond Pixels: Semantic-aware Typographic Attack for Geo-Privacy Protection](https://arxiv.org/abs/2511.12575)
*Jiayi Zhu,Yihao Huang,Yue Cao,Xiaojun Jia,Qing Guo,Felix Juefei-Xu,Geguang Pu,Bin Wang*

Main category: cs.CV

TL;DR: 通过语义感知的排版攻击，在不明显降低图像质量的前提下，有效干扰LVLMs的地理位置推断，保护用户隐私。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）可能通过用户分享的图片推断地理位置，导致隐私泄露。现有的对抗性图像扰动方法虽然有效，但会显著降低图像质量。因此，需要一种既能保护隐私又不影响视觉共享价值的方法。

Method: 研究采用两阶段的语义感知排版攻击，通过在外围添加具有欺骗性的文本来干扰LVLMs的地理位置推断。

Result: 在三个数据集上的实验表明，该方法能显著降低五种先进商业LVLMs的地理位置预测准确率。

Conclusion: 该论文提出了一种基于语义感知的排版攻击方法，有效降低大型视觉语言模型（LVLMs）的地理位置推断准确率，为地理隐私保护提供了实用且视觉保真的解决方案。

Abstract: Large Visual Language Models (LVLMs) now pose a serious yet overlooked privacy threat, as they can infer a social media user's geolocation directly from shared images, leading to unintended privacy leakage. While adversarial image perturbations provide a potential direction for geo-privacy protection, they require relatively strong distortions to be effective against LVLMs, which noticeably degrade visual quality and diminish an image's value for sharing. To overcome this limitation, we identify typographical attacks as a promising direction for protecting geo-privacy by adding text extension outside the visual content. We further investigate which textual semantics are effective in disrupting geolocation inference and design a two-stage, semantics-aware typographical attack that generates deceptive text to protect user privacy. Extensive experiments across three datasets demonstrate that our approach significantly reduces geolocation prediction accuracy of five state-of-the-art commercial LVLMs, establishing a practical and visually-preserving protection strategy against emerging geo-privacy threats.

</details>


### [140] [TempoMaster: Efficient Long Video Generation via Next-Frame-Rate Prediction](https://arxiv.org/abs/2511.12578)
*Yukuo Ma,Cong Liu,Junke Wang,Junqi Liu,Haibin Huang,Zuxuan Wu,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: TempoMaster通过逐步增加帧率和双向注意力机制，高效生成高质量长视频，实验证明其领先性。


<details>
  <summary>Details</summary>
Motivation: 解决长视频生成中的视觉细节和运动连续性问题，提升时间一致性。

Method: 首先生成低帧率视频作为粗蓝图，然后逐步增加帧率以优化视觉细节和运动连续性。采用双向注意力和自回归跨帧率策略。

Result: 在视觉和时间质量上均达到最先进水平。

Conclusion: TempoMaster通过逐步增加帧率和双向注意力机制，在长视频生成中实现了卓越的视觉和时间一致性，成为新的技术标杆。

Abstract: We present TempoMaster, a novel framework that formulates long video generation as next-frame-rate prediction. Specifically, we first generate a low-frame-rate clip that serves as a coarse blueprint of the entire video sequence, and then progressively increase the frame rate to refine visual details and motion continuity. During generation, TempoMaster employs bidirectional attention within each frame-rate level while performing autoregression across frame rates, thus achieving long-range temporal coherence while enabling efficient and parallel synthesis. Extensive experiments demonstrate that TempoMaster establishes a new state-of-the-art in long video generation, excelling in both visual and temporal quality.

</details>


### [141] [Rank-Aware Agglomeration of Foundation Models for Immunohistochemistry Image Cell Counting](https://arxiv.org/abs/2511.12588)
*Zuqi Huang,Mengxin Tian,Huan Liu,Wentao Li,Baobao Liang,Jie Wu,Fang Yan,Zhaoqing Tang,Zhongyu Li*

Main category: cs.CV

TL;DR: 提出CountIHC框架，通过rank-aware知识蒸馏和视觉-语言对齐，显著提升IHC图像中的多类细胞计数性能。


<details>
  <summary>Details</summary>
Motivation: 解决IHC图像中细胞计数的挑战，如色原重叠、生物标记染色变异和细胞形态多样性，同时探索基础模型在此任务中的潜力。

Method: 提出了一个rank-aware的融合框架，结合多个基础模型的互补表示，设计了Rank-Aware Teacher Selecting（RATS）策略，并通过视觉-语言对齐的微调阶段实现多类细胞计数。

Result: CountIHC在12种IHC生物标记和5种组织类型上优于现有方法，且与病理学家的评估高度一致。

Conclusion: CountIHC框架通过选择性知识蒸馏和rank-aware教师选择策略，显著提高了IHC图像中的多类细胞计数准确性，并在多种生物标记和组织类型上优于现有方法。

Abstract: Accurate cell counting in immunohistochemistry (IHC) images is critical for quantifying protein expression and aiding cancer diagnosis. However, the task remains challenging due to the chromogen overlap, variable biomarker staining, and diverse cellular morphologies. Regression-based counting methods offer advantages over detection-based ones in handling overlapped cells, yet rarely support end-to-end multi-class counting. Moreover, the potential of foundation models remains largely underexplored in this paradigm. To address these limitations, we propose a rank-aware agglomeration framework that selectively distills knowledge from multiple strong foundation models, leveraging their complementary representations to handle IHC heterogeneity and obtain a compact yet effective student model, CountIHC. Unlike prior task-agnostic agglomeration strategies that either treat all teachers equally or rely on feature similarity, we design a Rank-Aware Teacher Selecting (RATS) strategy that models global-to-local patch rankings to assess each teacher's inherent counting capacity and enable sample-wise teacher selection. For multi-class cell counting, we introduce a fine-tuning stage that reformulates the task as vision-language alignment. Discrete semantic anchors derived from structured text prompts encode both category and quantity information, guiding the regression of class-specific density maps and improving counting for overlapping cells. Extensive experiments demonstrate that CountIHC surpasses state-of-the-art methods across 12 IHC biomarkers and 5 tissue types, while exhibiting high agreement with pathologists' assessments. Its effectiveness on H&E-stained data further confirms the scalability of the proposed method.

</details>


### [142] [Fine-Grained Representation for Lane Topology Reasoning](https://arxiv.org/abs/2511.12590)
*Guoqing Xu,Yiheng Li,Yang Yang*

Main category: cs.CV

TL;DR: TopoFG是一种细粒度车道拓扑推理框架，通过整合空间和序列先验到细粒度查询中，并应用去噪策略，显著提升了复杂车道结构的建模精度和拓扑预测的可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常用单一查询表示每条车道，基于车道查询的相似性推断拓扑连接性，但难以准确建模复杂车道结构，导致拓扑预测不可靠。

Method: TopoFG框架分为三个阶段：Hierarchical Prior Extractor (HPE)提取全局空间先验和局部序列先验；Region-Focused Decoder (RFD)构建细粒度查询并优化车道表示；Robust Boundary-Point Topology Reasoning (RBTR)基于边界点查询特征建模车道连接性，并应用拓扑去噪策略减少匹配模糊性。

Result: 在OpenLane-V2基准测试中，TopoFG实现了最先进的性能，subsetA的OLS为48.0%，subsetB为45.4%。

Conclusion: TopoFG通过整合空间和序列先验到细粒度查询中，并应用去噪策略到边界点拓扑推理，精确建模了复杂车道结构，提供了可靠的车道拓扑预测。

Abstract: Precise modeling of lane topology is essential for autonomous driving, as it directly impacts navigation and control decisions.Existing methods typically represent each lane with a single query and infer topological connectivity based on the similarity between lane queries.However, this kind of design struggles to accurately model complex lane structures, leading to unreliable topology prediction.In this view, we propose a Fine-Grained lane topology reasoning framework (TopoFG).It divides the procedure from bird's-eye-view (BEV) features to topology prediction via fine-grained queries into three phases, i.e., Hierarchical Prior Extractor (HPE), Region-Focused Decoder (RFD), and Robust Boundary-Point Topology Reasoning (RBTR).Specifically, HPE extracts global spatial priors from the BEV mask and local sequential priors from in-lane keypoint sequences to guide subsequent fine-grained query modeling.RFD constructs fine-grained queries by integrating the spatial and sequential priors. It then samples reference points in RoI regions of the mask and applies cross-attention with BEV features to refine the query representations of each lane.RBTR models lane connectivity based on boundary-point query features and further employs a topological denoising strategy to reduce matching ambiguity.By integrating spatial and sequential priors into fine-grained queries and applying a denoising strategy to boundary-point topology reasoning, our method precisely models complex lane structures and delivers trustworthy topology predictions.Extensive experiments on the OpenLane-V2 benchmark demonstrate that TopoFG achieves new state-of-the-art performance, with an OLS of 48.0% on subsetA and 45.4% on subsetB.

</details>


### [143] [Seg-VAR: Image Segmentation with Visual Autoregressive Modeling](https://arxiv.org/abs/2511.12594)
*Rongkun Zheng,Lu Qi,Xi Chen,Yi Wang,Kun Wang,Hengshuang Zhao*

Main category: cs.CV

TL;DR: Seg-VAR是一种将分割任务重新定义为条件自回归掩码生成的新框架，通过多阶段训练策略和三个核心组件，显著提升了分割性能。


<details>
  <summary>Details</summary>
Motivation: 探索自回归模型在分割任务中的潜力，弥补其在低层次空间感知任务中的不足。

Method: Seg-VAR框架包含三个核心组件：（1）图像编码器生成潜在先验，（2）空间感知的seglat编码器将分割掩码映射为离散潜在标记，（3）解码器从潜在标记重建掩码。采用多阶段训练策略。

Result: 实验表明Seg-VAR在多种分割任务和验证基准上优于之前的判别性和生成性方法。

Conclusion: Seg-VAR通过将分割任务重新定义为条件自回归掩码生成问题，为自回归推理在空间感知视觉系统中的集成开辟了新途径。

Abstract: While visual autoregressive modeling (VAR) strategies have shed light on image generation with the autoregressive models, their potential for segmentation, a task that requires precise low-level spatial perception, remains unexplored. Inspired by the multi-scale modeling of classic Mask2Former-based models, we propose Seg-VAR, a novel framework that rethinks segmentation as a conditional autoregressive mask generation problem. This is achieved by replacing the discriminative learning with the latent learning process. Specifically, our method incorporates three core components: (1) an image encoder generating latent priors from input images, (2) a spatial-aware seglat (a latent expression of segmentation mask) encoder that maps segmentation masks into discrete latent tokens using a location-sensitive color mapping to distinguish instances, and (3) a decoder reconstructing masks from these latents. A multi-stage training strategy is introduced: first learning seglat representations via image-seglat joint training, then refining latent transformations, and finally aligning image-encoder-derived latents with seglat distributions. Experiments show Seg-VAR outperforms previous discriminative and generative methods on various segmentation tasks and validation benchmarks. By framing segmentation as a sequential hierarchical prediction task, Seg-VAR opens new avenues for integrating autoregressive reasoning into spatial-aware vision systems. Code will be available at https://github.com/rkzheng99/Seg-VAR.

</details>


### [144] [LoRA-Enhanced Vision Transformer for Single Image based Morphing Attack Detection via Knowledge Distillation from EfficientNet](https://arxiv.org/abs/2511.12602)
*Ria Shekhawat,Sushrut Patwardhan,Raghavendra Ramachandra,Praveen Kumar Chandaliya,Kishor P. Upla*

Main category: cs.CV

TL;DR: 提出一种基于师生框架的单图像合成攻击检测方法，结合LoRA提升效率，实验显示其优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 针对人脸识别系统(FRS)易受合成图像攻击的漏洞，提出一种高效的攻击检测方法。

Method: 采用基于CNN的教师模型和基于ViT的学生模型相结合的师生框架，并集成低秩适配(LoRA)进行微调。

Result: 在包含十种不同合成算法的数据集上测试，性能优于六种现有S-MAD技术。

Conclusion: 提出的S-MAD方法在检测性能和计算效率上均优于现有技术，验证了其在实际应用中的潜力。

Abstract: Face Recognition Systems (FRS) are critical for security but remain vulnerable to morphing attacks, where synthetic images blend biometric features from multiple individuals. We propose a novel Single-Image Morphing Attack Detection (S-MAD) approach using a teacher-student framework, where a CNN-based teacher model refines a ViT-based student model. To improve efficiency, we integrate Low-Rank Adaptation (LoRA) for fine-tuning, reducing computational costs while maintaining high detection accuracy. Extensive experiments are conducted on a morphing dataset built from three publicly available face datasets, incorporating ten different morphing generation algorithms to assess robustness. The proposed method is benchmarked against six state-of-the-art S-MAD techniques, demonstrating superior detection performance and computational efficiency.

</details>


### [145] [Pixels or Positions? Benchmarking Modalities in Group Activity Recognition](https://arxiv.org/abs/2511.12606)
*Drishya Karki,Merey Ramazanova,Anthony Cioppa,Silvio Giancola,Bernard Ghanem*

Main category: cs.CV

TL;DR: 研究通过SoccerNet-GAR数据集和角色感知图架构，证明追踪模态在群体活动识别中优于视频模态，并强调模态选择的重要性。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏对齐的视频和追踪数据标准化基准，无法公平比较这两种模态在GAR中的表现。研究旨在填补这一空白，并探索像素（视频）和位置（追踪）模态的相对优势。

Method: 研究引入了SoccerNet-GAR数据集，包含同步的广播视频和球员追踪数据，并定义了统一的评估协议。提出了两种强单模态方法：基于视频的分类器和基于追踪的图神经网络分类器（特别是新颖的角色感知图架构）。

Result: 基于追踪的模型达到67.2%的平衡准确率，优于最佳视频基线的58.1%，且训练速度快4.25倍，参数少438倍（197K vs 86.3M）。

Conclusion: 该研究强调了模态选择和角色感知建模对群体活动识别（GAR）的重要性，并通过实验证明基于追踪的模型在准确性和效率上优于视频基线。

Abstract: Group Activity Recognition (GAR) is well studied on the video modality for surveillance and indoor team sports (e.g., volleyball, basketball). Yet, other modalities such as agent positions and trajectories over time, i.e. tracking, remain comparatively under-explored despite being compact, agent-centric signals that explicitly encode spatial interactions. Understanding whether pixel (video) or position (tracking) modalities leads to better group activity recognition is therefore important to drive further research on the topic. However, no standardized benchmark currently exists that aligns broadcast video and tracking data for the same group activities, leading to a lack of apples-to-apples comparison between these modalities for GAR. In this work, we introduce SoccerNet-GAR, a multimodal dataset built from the $64$ matches of the football World Cup 2022. Specifically, the broadcast videos and player tracking modalities for $94{,}285$ group activities are synchronized and annotated with $10$ categories. Furthermore, we define a unified evaluation protocol to benchmark two strong unimodal approaches: (i) a competitive video-based classifiers and (ii) a tracking-based classifiers leveraging graph neural networks. In particular, our novel role-aware graph architecture for tracking-based GAR directly encodes tactical structure through positional edges and temporal attention. Our tracking model achieves $67.2\%$ balanced accuracy compared to $58.1\%$ for the best video baseline, while training $4.25 \times$ faster with $438 \times$ fewer parameters ($197K$ \vs $86.3M$). This study provides new insights into the relative strengths of pixels and positions for group activity recognition. Overall, it highlights the importance of modality choice and role-aware modeling for GAR.

</details>


### [146] [C3Net: Context-Contrast Network for Camouflaged Object Detection](https://arxiv.org/abs/2511.12627)
*Baber Jan,Aiman H. El-Maleh,Abdul Jabbar Siddiqui,Abdul Bais,Saeed Anwar*

Main category: cs.CV

TL;DR: C3Net通过双路径解码器架构解决伪装物体检测的六个挑战，在多个数据集上实现最佳性能。


<details>
  <summary>Details</summary>
Motivation: 伪装物体检测任务对传统分割方法和现代基础模型均构成挑战，需要全面的架构解决方案来应对六个基本挑战。

Method: C3Net采用双路径解码器架构，包括边缘细化路径和上下文定位路径，结合注意力融合模块，通过空间门控机制协同工作。

Result: C3Net在COD10K、CAMO和NC4K数据集上的S-measures分别达到0.898、0.904和0.913，保持了高效处理能力。

Conclusion: C3Net通过其独特的双路径解码器架构和专门的组件，成功解决了伪装物体检测中的六个基本挑战，并在多个数据集上实现了最先进的性能。

Abstract: Camouflaged object detection identifies objects that blend seamlessly with their surroundings through similar colors, textures, and patterns. This task challenges both traditional segmentation methods and modern foundation models, which fail dramatically on camouflaged objects. We identify six fundamental challenges in COD: Intrinsic Similarity, Edge Disruption, Extreme Scale Variation, Environmental Complexities, Contextual Dependencies, and Salient-Camouflaged Object Disambiguation. These challenges frequently co-occur and compound the difficulty of detection, requiring comprehensive architectural solutions. We propose C3Net, which addresses all challenges through a specialized dual-pathway decoder architecture. The Edge Refinement Pathway employs gradient-initialized Edge Enhancement Modules to recover precise boundaries from early features. The Contextual Localization Pathway utilizes our novel Image-based Context Guidance mechanism to achieve intrinsic saliency suppression without external models. An Attentive Fusion Module synergistically combines the two pathways via spatial gating. C3Net achieves state-of-the-art performance with S-measures of 0.898 on COD10K, 0.904 on CAMO, and 0.913 on NC4K, while maintaining efficient processing. C3Net demonstrates that complex, multifaceted detection challenges require architectural innovation, with specialized components working synergistically to achieve comprehensive coverage beyond isolated improvements. Code, model weights, and results are available at https://github.com/Baber-Jan/C3Net.

</details>


### [147] [Open-World Test-Time Adaptation with Hierarchical Feature Aggregation and Attention Affine](https://arxiv.org/abs/2511.12607)
*Ziqiong Liu,Yushun Tang,Junyang Ji,Zhihai He*

Main category: cs.CV

TL;DR: 提出HLN和AAN结合的TTA方法，通过增强OOD检测和自适应注意力机制，显著提升模型在分布偏移和未知类别样本下的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有TTA方法在遇到未知类别样本时性能显著下降的问题，提升模型在新环境中的适应性和鲁棒性。

Method: 通过分层梯子网络提取Transformer各层的类别标记特征以增强OOD检测，结合加权概率融合提升预测准确性；引入注意力仿射网络自适应调整自注意力机制以应对域偏移；采用加权熵机制动态抑制低置信度样本的影响。

Result: 在基准数据集上的实验结果表明，该方法显著提升了分类性能，尤其在域偏移和OOD样本场景下表现优异。

Conclusion: 提出的分层梯子网络（HLN）和注意力仿射网络（AAN）显著提升了模型在测试时适应（TTA）中的性能，尤其在处理分布偏移和未知类别（OOD）样本时表现出色。

Abstract: Test-time adaptation (TTA) refers to adjusting the model during the testing phase to cope with changes in sample distribution and enhance the model's adaptability to new environments. In real-world scenarios, models often encounter samples from unseen (out-of-distribution, OOD) categories. Misclassifying these as known (in-distribution, ID) classes not only degrades predictive accuracy but can also impair the adaptation process, leading to further errors on subsequent ID samples. Many existing TTA methods suffer substantial performance drops under such conditions. To address this challenge, we propose a Hierarchical Ladder Network that extracts OOD features from class tokens aggregated across all Transformer layers. OOD detection performance is enhanced by combining the original model prediction with the output of the Hierarchical Ladder Network (HLN) via weighted probability fusion. To improve robustness under domain shift, we further introduce an Attention Affine Network (AAN) that adaptively refines the self-attention mechanism conditioned on the token information to better adapt to domain drift, thereby improving the classification performance of the model on datasets with domain shift. Additionally, a weighted entropy mechanism is employed to dynamically suppress the influence of low-confidence samples during adaptation. Experimental results on benchmark datasets show that our method significantly improves the performance on the most widely used classification datasets.

</details>


### [148] [Multivariate Diffusion Transformer with Decoupled Attention for High-Fidelity Mask-Text Collaborative Facial Generation](https://arxiv.org/abs/2511.12631)
*Yushe Cao,Dianxi Shi,Xing Fu,Xuechao Zou,Haikuo Peng,Xueqi Li,Chun Yu,Junliang Xing*

Main category: cs.CV

TL;DR: MDiTFace是一种新型扩散变换器框架，通过统一标记化和解耦注意力机制，优化多模态面部生成的效果和计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统的特征融合方法在多模态面部生成中交叉模态交互效果不佳，导致生成结果不理想。

Method: 采用定制的扩散变换器框架（MDiTFace），通过统一的标记化策略处理语义掩码和文本输入，并设计了新型的解耦注意力机制。

Result: MDiTFace在面部保真度和条件一致性上显著优于其他竞争方法，同时减少了94%的计算开销。

Conclusion: MDiTFace通过统一的标记化策略和新颖的解耦注意力机制，显著提升了多模态面部生成的效果，同时在计算效率上也有显著优化。

Abstract: While significant progress has been achieved in multimodal facial generation using semantic masks and textual descriptions, conventional feature fusion approaches often fail to enable effective cross-modal interactions, thereby leading to suboptimal generation outcomes. To address this challenge, we introduce MDiTFace--a customized diffusion transformer framework that employs a unified tokenization strategy to process semantic mask and text inputs, eliminating discrepancies between heterogeneous modality representations. The framework facilitates comprehensive multimodal feature interaction through stacked, newly designed multivariate transformer blocks that process all conditions synchronously. Additionally, we design a novel decoupled attention mechanism by dissociating implicit dependencies between mask tokens and temporal embeddings. This mechanism segregates internal computations into dynamic and static pathways, enabling caching and reuse of features computed in static pathways after initial calculation, thereby reducing additional computational overhead introduced by mask condition by over 94% while maintaining performance. Extensive experiments demonstrate that MDiTFace significantly outperforms other competing methods in terms of both facial fidelity and conditional consistency.

</details>


### [149] [BridgeEQA: Virtual Embodied Agents for Real Bridge Inspections](https://arxiv.org/abs/2511.12676)
*Subin Varghese,Joshua Gao,Asad Ur Rahman,Vedhus Hoskere*

Main category: cs.CV

TL;DR: 论文提出BridgeEQA基准和EMVR方法，用于基础设施检查领域的开放词汇EQA，显著提升性能并公开资源。


<details>
  <summary>Details</summary>
Motivation: 基础设施检查领域缺乏能够真实反映实际操作的基准，BridgeEQA填补了这一空白，并通过多尺度推理和长距离空间理解等需求展示了其重要性。

Method: 提出了Embodied Memory Visual Reasoning (EMVR)方法，通过基于图像的场景图进行顺序导航，结合马尔可夫决策过程进行推理。

Result: EMVR方法在基准测试中表现优于现有模型，尤其在需要跨图像综合视觉证据的任务中。

Conclusion: 该论文提出了BridgeEQA基准和EMVR方法，显著提升了在基础设施检查领域的EQA性能，并公开了数据集和代码。

Abstract: Deploying embodied agents that can answer questions about their surroundings in realistic real-world settings remains difficult, partly due to the scarcity of benchmarks that faithfully capture practical operating conditions. We propose infrastructure inspection as a compelling domain for open-vocabulary Embodied Question Answering (EQA): it naturally demands multi-scale reasoning, long-range spatial understanding, and complex semantic relationships, while offering unique evaluation advantages via standardized National Bridge Inventory (NBI) condition ratings (0-9), professional inspection reports, and egocentric imagery.
  We introduce BridgeEQA, a benchmark of 2,200 open-vocabulary question-answer pairs (in the style of OpenEQA) grounded in professional inspection reports across 200 real-world bridge scenes with 47.93 images on average per scene. Questions require synthesizing visual evidence across multiple images and aligning responses with NBI condition ratings. We further propose a new EQA metric Image Citation Relevance to evaluate the ability of a model to cite relevant images.
  Evaluations of state-of-the-art vision-language models reveal substantial performance gaps under episodic memory EQA settings. To address this, we propose Embodied Memory Visual Reasoning (EMVR), which formulates inspection as sequential navigation over an image-based scene graph: images are nodes, and an agent takes actions to traverse views, compare evidence, and reason within a Markov decision process. EMVR shows strong performance over the baselines. We publicly release both the dataset and code.

</details>


### [150] [R$^{2}$Seg: Training-Free OOD Medical Tumor Segmentation via Anatomical Reasoning and Statistical Rejection](https://arxiv.org/abs/2511.12691)
*Shuaike Shen,Ke Liu,Jiaqing Xie,Shangde Gao,Chunhua Shen,Ge Liu,Mireia Crispin-Ortuzar,Shangqi Gao*

Main category: cs.CV

TL;DR: R$^{2}$Seg是一个无需训练的两阶段框架，通过解剖推理和统计测试显著提升OOD肿瘤分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有的医学图像分割基础模型在OOD肿瘤上表现不佳，常产生碎片化假阳性结果。

Method: R$^{2}$Seg采用两步流程：1. Reason步骤利用LLM引导的解剖推理规划器定位器官锚点并生成多尺度ROI；2. Reject步骤通过双样本统计测试筛选候选区域，仅保留与正常组织显著不同的候选，有效抑制假阳性。

Result: 在多中心和多模态肿瘤分割基准测试中，R$^{2}$Seg在Dice系数、特异性和敏感性上显著优于基线模型和原始基础模型。

Conclusion: R$^{2}$Seg框架通过两阶段的Reason-and-Reject流程显著提升了医学图像分割在OOD肿瘤上的性能，无需参数更新，兼容零更新测试时间增强，避免了灾难性遗忘。

Abstract: Foundation models for medical image segmentation struggle under out-of-distribution (OOD) shifts, often producing fragmented false positives on OOD tumors. We introduce R$^{2}$Seg, a training-free framework for robust OOD tumor segmentation that operates via a two-stage Reason-and-Reject process. First, the Reason step employs an LLM-guided anatomical reasoning planner to localize organ anchors and generate multi-scale ROIs. Second, the Reject step applies two-sample statistical testing to candidates generated by a frozen foundation model (BiomedParse) within these ROIs. This statistical rejection filter retains only candidates significantly different from normal tissue, effectively suppressing false positives. Our framework requires no parameter updates, making it compatible with zero-update test-time augmentation and avoiding catastrophic forgetting. On multi-center and multi-modal tumor segmentation benchmarks, R$^{2}$Seg substantially improves Dice, specificity, and sensitivity over strong baselines and the original foundation models. Code are available at https://github.com/Eurekashen/R2Seg.

</details>


### [151] [Denoising Vision Transformer Autoencoder with Spectral Self-Regularization](https://arxiv.org/abs/2511.12633)
*Xunzhi Xiang,Xingye Tian,Guiyu Zhang,Yabo Chen,Shaofeng Zhang,Xuebo Wang,Xin Tao,Qi Fan*

Main category: cs.CV

TL;DR: Denoising-VAE通过光谱自正则化和对齐策略解决了高维VAE潜在空间的优化问题，显著提升生成质量和收敛速度，达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 高维VAE潜在空间中的冗余高频成分阻碍了扩散模型的训练收敛，进而影响生成质量，需要一种方法来平衡重建保真度和生成性能。

Method: 提出了Denoising-VAE，一种基于ViT的自编码器，采用光谱自正则化策略抑制冗余高频噪声，并引入光谱对齐策略优化生成模型。

Result: 在ImageNet 256×256基准测试中，Denoising-VAE实现了rFID=0.28和PSNR=27.26的最优重建质量，以及gFID=1.82的竞争性生成性能，扩散模型收敛速度提升约2倍。

Conclusion: 通过提出一种光谱自正则化策略和光谱对齐策略，Denoising-VAE不仅改善了生成质量，还显著加快了扩散模型的收敛速度，同时在重建质量和生成性能上达到了当前最优水平。

Abstract: Variational autoencoders (VAEs) typically encode images into a compact latent space, reducing computational cost but introducing an optimization dilemma: a higher-dimensional latent space improves reconstruction fidelity but often hampers generative performance. Recent methods attempt to address this dilemma by regularizing high-dimensional latent spaces using external vision foundation models (VFMs). However, it remains unclear how high-dimensional VAE latents affect the optimization of generative models. To our knowledge, our analysis is the first to reveal that redundant high-frequency components in high-dimensional latent spaces hinder the training convergence of diffusion models and, consequently, degrade generation quality. To alleviate this problem, we propose a spectral self-regularization strategy to suppress redundant high-frequency noise while simultaneously preserving reconstruction quality. The resulting Denoising-VAE, a ViT-based autoencoder that does not rely on VFMs, produces cleaner, lower-noise latents, leading to improved generative quality and faster optimization convergence. We further introduce a spectral alignment strategy to facilitate the optimization of Denoising-VAE-based generative models. Our complete method enables diffusion models to converge approximately 2$\times$ faster than with SD-VAE, while achieving state-of-the-art reconstruction quality (rFID = 0.28, PSNR = 27.26) and competitive generation performance (gFID = 1.82) on the ImageNet 256$\times$256 benchmark.

</details>


### [152] [HEDGE: Hallucination Estimation via Dense Geometric Entropy for VQA with Vision-Language Models](https://arxiv.org/abs/2511.12693)
*Sushant Gautam,Michael A. Riegler,Pål Halvorsen*

Main category: cs.CV

TL;DR: HEDGE是一个结合视觉扰动和聚类的幻觉检测框架，评估显示VASE度量在嵌入聚类下最有效，为多模态可靠性提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLMs）在开放视觉问答中存在幻觉问题，HEDGE旨在提供一个统一的幻觉检测框架。

Method: HEDGE结合了采样、失真合成、聚类（基于蕴含和嵌入）和度量计算，形成一个统一的可复现管道。

Result: 评估显示，统一融合模型（如Qwen2.5-VL）的幻觉检测能力最强，而受限标记化架构（如Med-Gemma）最弱。嵌入聚类在生成答案上表现更优，而NLI聚类对LLaVA-Med和长句回答更有效。VASE度量在嵌入聚类和适度采样下最稳健。

Conclusion: HEDGE框架通过结合视觉扰动、语义聚类和不确定性度量，为多模态架构提供了一个可复现的幻觉检测管道。VASE度量在嵌入聚类和适度采样预算下表现最佳，为评估多模态可靠性提供了理论基础。

Abstract: Vision-language models (VLMs) enable open-ended visual question answering but remain prone to hallucinations. We present HEDGE, a unified framework for hallucination detection that combines controlled visual perturbations, semantic clustering, and robust uncertainty metrics. HEDGE integrates sampling, distortion synthesis, clustering (entailment- and embedding-based), and metric computation into a reproducible pipeline applicable across multimodal architectures.
  Evaluations on VQA-RAD and KvasirVQA-x1 with three representative VLMs (LLaVA-Med, Med-Gemma, Qwen2.5-VL) reveal clear architecture- and prompt-dependent trends. Hallucination detectability is highest for unified-fusion models with dense visual tokenization (Qwen2.5-VL) and lowest for architectures with restricted tokenization (Med-Gemma). Embedding-based clustering often yields stronger separation when applied directly to the generated answers, whereas NLI-based clustering remains advantageous for LLaVA-Med and for longer, sentence-level responses. Across configurations, the VASE metric consistently provides the most robust hallucination signal, especially when paired with embedding clustering and a moderate sampling budget (n ~ 10-15). Prompt design also matters: concise, label-style outputs offer clearer semantic structure than syntactically constrained one-sentence responses.
  By framing hallucination detection as a geometric robustness problem shaped jointly by sampling scale, prompt structure, model architecture, and clustering strategy, HEDGE provides a principled, compute-aware foundation for evaluating multimodal reliability. The hedge-bench PyPI library enables reproducible and extensible benchmarking, with full code and experimental resources available at https://github.com/Simula/HEDGE .

</details>


### [153] [Medical Knowledge Intervention Prompt Tuning for Medical Image Classification](https://arxiv.org/abs/2511.12639)
*Ye Du,Nanxi Yu,Shujun Wang*

Main category: cs.CV

TL;DR: CILMP通过结合LLMs和VLMs，提升了医疗图像分类任务中的提示调优效果，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有提示调优方法无法精确区分不同医疗概念，缺乏特定疾病相关特征，而LLMs在提供专业医疗知识方面表现优异。

Method: 提出CILMP（Conditional Intervention of Large Language Models for Prompt Tuning）方法，通过从LLMs提取疾病特定表示，干预低秩线性子空间，并生成实例自适应提示。

Result: 在多种医疗图像数据集上的实验表明，CILMP一致优于现有最先进的提示调优方法。

Conclusion: CILMP方法通过结合LLMs和VLMs，显著提升了医疗图像分类任务中的性能，优于现有最先进的提示调优方法。

Abstract: Vision-language foundation models (VLMs) have shown great potential in feature transfer and generalization across a wide spectrum of medical-related downstream tasks. However, fine-tuning these models is resource-intensive due to their large number of parameters. Prompt tuning has emerged as a viable solution to mitigate memory usage and reduce training time while maintaining competitive performance. Nevertheless, the challenge is that existing prompt tuning methods cannot precisely distinguish different kinds of medical concepts, which miss essentially specific disease-related features across various medical imaging modalities in medical image classification tasks. We find that Large Language Models (LLMs), trained on extensive text corpora, are particularly adept at providing this specialized medical knowledge. Motivated by this, we propose incorporating LLMs into the prompt tuning process. Specifically, we introduce the CILMP, Conditional Intervention of Large Language Models for Prompt Tuning, a method that bridges LLMs and VLMs to facilitate the transfer of medical knowledge into VLM prompts. CILMP extracts disease-specific representations from LLMs, intervenes within a low-rank linear subspace, and utilizes them to create disease-specific prompts. Additionally, a conditional mechanism is incorporated to condition the intervention process on each individual medical image, generating instance-adaptive prompts and thus enhancing adaptability. Extensive experiments across diverse medical image datasets demonstrate that CILMP consistently outperforms state-of-the-art prompt tuning methods, demonstrating its effectiveness. Code is available at https://github.com/usr922/cilmp.

</details>


### [154] [Which Way from B to A: The role of embedding geometry in image interpolation for Stable Diffusion](https://arxiv.org/abs/2511.12757)
*Nicholas Karris,Luke Durell,Javier Flores,Tegan Emerson*

Main category: cs.CV

TL;DR: 将CLIP嵌入视为Wasserstein空间中的点云，通过最优传输实现更平滑的图像插值。


<details>
  <summary>Details</summary>
Motivation: 受Stable Diffusion对CLIP嵌入矩阵的排列不变性启发，探索嵌入空间几何特性的新视角。

Method: 提出将嵌入插值问题重构为最优传输问题，计算嵌入之间的最短路径（或测地线），并在Stable Diffusion生成模型中进行实验验证。

Result: 最优传输方法生成的插值图像比其他标准插值方法更平滑、连贯，验证了点云视角的优越性。

Conclusion: 将CLIP嵌入矩阵视为Wasserstein空间中的点云而非欧几里得空间中的矩阵，能够更自然地反映嵌入空间的几何特性，并通过最优传输问题实现更平滑的图像插值。

Abstract: It can be shown that Stable Diffusion has a permutation-invariance property with respect to the rows of Contrastive Language-Image Pretraining (CLIP) embedding matrices. This inspired the novel observation that these embeddings can naturally be interpreted as point clouds in a Wasserstein space rather than as matrices in a Euclidean space. This perspective opens up new possibilities for understanding the geometry of embedding space. For example, when interpolating between embeddings of two distinct prompts, we propose reframing the interpolation problem as an optimal transport problem. By solving this optimal transport problem, we compute a shortest path (or geodesic) between embeddings that captures a more natural and geometrically smooth transition through the embedding space. This results in smoother and more coherent intermediate (interpolated) images when rendered by the Stable Diffusion generative model. We conduct experiments to investigate this effect, comparing the quality of interpolated images produced using optimal transport to those generated by other standard interpolation methods. The novel optimal transport--based approach presented indeed gives smoother image interpolations, suggesting that viewing the embeddings as point clouds (rather than as matrices) better reflects and leverages the geometry of the embedding space.

</details>


### [155] [DPVO-QAT++: Heterogeneous QAT and CUDA Kernel Fusion for High-Performance Deep Patch Visual Odometry](https://arxiv.org/abs/2511.12653)
*Cheng Liao*

Main category: cs.CV

TL;DR: DPVO-QAT++通过异构量化与CUDA内核融合，显著提升视觉里程计效率，同时保持精度，适用于嵌入式平台。


<details>
  <summary>Details</summary>
Motivation: 深度学习视觉SLAM系统虽有强大几何推理能力，但计算开销大，难以在资源受限的自主平台上部署。

Method: 采用可学习尺度参数化、视觉里程计前端和后端的异构精度设计（前端FP16/FP32浮点伪量化，后端全精度），以及GPU原生伪量化内核融合（定制CUDA内核）。

Result: 在TartanAir数据集上，平均FPS提升52.1%，中位延迟降低29.1%，峰值GPU内存占用减少64.9%；在EuRoC数据集上，平均FPS提升30.1%，中位延迟降低23.1%，峰值GPU内存占用减少37.7%，同时保持轨迹精度。

Conclusion: DPVO-QAT++通过分层量化优化框架，有效平衡了高精度深度视觉里程计与资源受限平台的效率需求，为实际嵌入式应用提供了可行的工程范式。

Abstract: Deep learning-based Visual SLAM (vSLAM) systems exhibit exceptional geometric reasoning capabilities, yet their prohibitive computational overhead severely restricts deployment on resource-constrained autonomous platforms. This paper presents a hierarchical quantization optimization framework, DPVO-QAT++ (DPVO-QAT++: Heterogeneous QAT and CUDA Kernel Fusion for High-Performance Deep Patch Visual Odometry). Through the synergistic integration of learnable scale parameterization, a heterogeneous precision design for the Visual Odometry (VO) front-end and back-end (front-end floating-point fake quantization with FP16/FP32; back-end full precision), and GPU-native kernel fusion for fake quantization (custom CUDA kernels), our framework significantly reduces memory footprint and increases processing speed while preserving the trajectory accuracy of the original model. On the TartanAir dataset, our framework achieves an average FPS increase of 52.1%, a 29.1% reduction in median latency, and a 64.9% reduction in peak GPU memory reservation, while maintaining trajectory accuracy (ATE) comparable to the original DPVO model across 32 validation sequences. On the EuRoC dataset, it realizes an average FPS increase of 30.1%, a 23.1% reduction in median latency, and a 37.7% reduction in peak GPU memory reservation, maintaining comparable trajectory accuracy (ATE) across 11 validation sequences. Experimental results demonstrate that DPVO-QAT++ effectively bridges the gap between high-precision deep VO and the efficiency requirements for practical deployment, offering a viable engineering paradigm for the application of this technology on real-world embedded platforms.
  Keywords: Visual Odometry, Heterogeneous Precision Architecture, Quantization-Aware Training, CUDA Kernel Fusion, Scale-Only Training, Deep Patch Visual Odometry, GPU-Native Kernel Fusion.

</details>


### [156] [Toward Real-world Text Image Forgery Localization: Structured and Interpretable Data Synthesis](https://arxiv.org/abs/2511.12658)
*Zeqin Yu,Haotao Xie,Jian Zhang,Jiangqun Ni,Wenkan Su,Jiwu Huang*

Main category: cs.CV

TL;DR: FSTS利用傅里叶级数框架合成逼真篡改数据，提升文本图像伪造检测的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有T-IFL方法因真实数据集规模有限和合成数据分布差距导致的泛化能力不足问题。

Method: 提出FSTS框架，通过收集真实篡改实例并分析行为模式，构建基于傅里叶级数的分层建模框架，生成多样且真实的训练数据。

Result: 实验表明，使用FSTS数据训练的模型在四种评估协议下均显著提升泛化性能。

Conclusion: FSTS通过结构化且可解释的框架合成篡改文本图像，显著提升了模型在真实世界数据集上的泛化能力。

Abstract: Existing Text Image Forgery Localization (T-IFL) methods often suffer from poor generalization due to the limited scale of real-world datasets and the distribution gap caused by synthetic data that fails to capture the complexity of real-world tampering. To tackle this issue, we propose Fourier Series-based Tampering Synthesis (FSTS), a structured and interpretable framework for synthesizing tampered text images. FSTS first collects 16,750 real-world tampering instances from five representative tampering types, using a structured pipeline that records human-performed editing traces via multi-format logs (e.g., video, PSD, and editing logs). By analyzing these collected parameters and identifying recurring behavioral patterns at both individual and population levels, we formulate a hierarchical modeling framework. Specifically, each individual tampering parameter is represented as a compact combination of basis operation-parameter configurations, while the population-level distribution is constructed by aggregating these behaviors. Since this formulation draws inspiration from the Fourier series, it enables an interpretable approximation using basis functions and their learned weights. By sampling from this modeled distribution, FSTS synthesizes diverse and realistic training data that better reflect real-world forgery traces. Extensive experiments across four evaluation protocols demonstrate that models trained with FSTS data achieve significantly improved generalization on real-world datasets. Dataset is available at \href{https://github.com/ZeqinYu/FSTS}{Project Page}.

</details>


### [157] [MSRNet: A Multi-Scale Recursive Network for Camouflaged Object Detection](https://arxiv.org/abs/2511.12810)
*Leena Alghamdi,Muhammad Usman,Hafeez Anwar,Abdul Bais,Saeed Anwar*

Main category: cs.CV

TL;DR: MSRNet通过多尺度特征提取和递归优化，显著提升了伪装物体检测的精度，尤其在复杂场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前伪装物体检测方法在复杂场景（如低光照、部分遮挡、小目标和多目标）中表现不佳，亟需提升模型对多尺度特征的提取和融合能力。

Method: 提出了一种结合金字塔视觉变换器（Pyramid Vision Transformer）和多粒度融合单元（Multi-Granularity Fusion Units）的多尺度递归网络，通过递归反馈解码策略增强全局上下文理解。

Result: 模型在两个基准数据集上达到最先进水平，在另外两个数据集上排名第二。

Conclusion: 该论文提出的多尺度递归网络（MSRNet）在伪装物体检测任务中表现出色，尤其在处理小目标和多目标场景时优于现有方法，并在多个基准数据集上取得了最先进的成果。

Abstract: Camouflaged object detection is an emerging and challenging computer vision task that requires identifying and segmenting objects that blend seamlessly into their environments due to high similarity in color, texture, and size. This task is further complicated by low-light conditions, partial occlusion, small object size, intricate background patterns, and multiple objects. While many sophisticated methods have been proposed for this task, current methods still struggle to precisely detect camouflaged objects in complex scenarios, especially with small and multiple objects, indicating room for improvement. We propose a Multi-Scale Recursive Network that extracts multi-scale features via a Pyramid Vision Transformer backbone and combines them via specialized Attention-Based Scale Integration Units, enabling selective feature merging. For more precise object detection, our decoder recursively refines features by incorporating Multi-Granularity Fusion Units. A novel recursive-feedback decoding strategy is developed to enhance global context understanding, helping the model overcome the challenges in this task. By jointly leveraging multi-scale learning and recursive feature optimization, our proposed method achieves performance gains, successfully detecting small and multiple camouflaged objects. Our model achieves state-of-the-art results on two benchmark datasets for camouflaged object detection and ranks second on the remaining two. Our codes, model weights, and results are available at \href{https://github.com/linaagh98/MSRNet}{https://github.com/linaagh98/MSRNet}.

</details>


### [158] [Hi-Reco: High-Fidelity Real-Time Conversational Digital Humans](https://arxiv.org/abs/2511.12662)
*Hongbin Huang,Junwei Li,Tianxin Xie,Zhuang Li,Cekai Weng,Yaodong Yang,Yue Luo,Li Liu,Jing Tang,Zhijing Shao,Zeyu Wang*

Main category: cs.CV

TL;DR: 提出了一种结合高保真3D头像、语音合成和对话生成的技术，通过异步管道和检索增强方法实现实时响应的数字人类系统。


<details>
  <summary>Details</summary>
Motivation: 解决高保真数字人类在视觉真实性和实时响应性之间的挑战，满足交互应用的需求。

Method: 采用异步执行管道协调多模态组件以减少延迟，并结合检索增强方法（如历史增强和基于意图的路由）优化对话流程和知识访问效率。

Result: 开发了一个支持唤醒词检测、情感表达韵律和上下文感知响应生成的高保真实时对话数字人类系统。

Conclusion: 该系统通过结合高保真3D头像、个性化表情语音合成和知识驱动的对话生成，实现了响应迅速且逼真的数字人类，适用于通信、教育和娱乐等沉浸式应用。

Abstract: High-fidelity digital humans are increasingly used in interactive applications, yet achieving both visual realism and real-time responsiveness remains a major challenge. We present a high-fidelity, real-time conversational digital human system that seamlessly combines a visually realistic 3D avatar, persona-driven expressive speech synthesis, and knowledge-grounded dialogue generation. To support natural and timely interaction, we introduce an asynchronous execution pipeline that coordinates multi-modal components with minimal latency. The system supports advanced features such as wake word detection, emotionally expressive prosody, and highly accurate, context-aware response generation. It leverages novel retrieval-augmented methods, including history augmentation to maintain conversational flow and intent-based routing for efficient knowledge access. Together, these components form an integrated system that enables responsive and believable digital humans, suitable for immersive applications in communication, education, and entertainment.

</details>


### [159] [SAGA: Source Attribution of Generative AI Videos](https://arxiv.org/abs/2511.12834)
*Rohit Kundu,Vishal Mohanty,Hao Xiong,Shan Jia,Athula Balachandran,Amit K. Roy-Chowdhury*

Main category: cs.CV

TL;DR: SAGA是首个综合性框架，通过多粒度归因和高效数据策略，实现生成式AI视频来源识别，并提供可解释性洞察。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的快速发展导致了超逼真合成视频的泛滥，传统的二进制真假检测方法已无法满足需求，迫切需要一种能够大规模识别视频生成来源的综合框架。

Method: SAGA采用了一种新颖的视频变换器架构，结合了强大的视觉基础模型特征，以及数据高效的预训练和归因策略。此外，还提出了时间注意力签名（T-Sigs）作为可解释性方法。

Result: SAGA在公共数据集上的广泛实验表明，其在合成视频来源识别方面设定了新的基准，尤其是在跨域场景中表现出色，仅需0.5%的源标记数据即可达到完全监督性能。

Conclusion: SAGA框架通过多粒度归因和高效的数据利用策略，为生成式AI视频的来源识别设立了新标准，并为法医和监管应用提供了关键的可解释性洞察。

Abstract: The proliferation of generative AI has led to hyper-realistic synthetic videos, escalating misuse risks and outstripping binary real/fake detectors. We introduce SAGA (Source Attribution of Generative AI videos), the first comprehensive framework to address the urgent need for AI-generated video source attribution at a large scale. Unlike traditional detection, SAGA identifies the specific generative model used. It uniquely provides multi-granular attribution across five levels: authenticity, generation task (e.g., T2V/I2V), model version, development team, and the precise generator, offering far richer forensic insights. Our novel video transformer architecture, leveraging features from a robust vision foundation model, effectively captures spatio-temporal artifacts. Critically, we introduce a data-efficient pretrain-and-attribute strategy, enabling SAGA to achieve state-of-the-art attribution using only 0.5\% of source-labeled data per class, matching fully supervised performance. Furthermore, we propose Temporal Attention Signatures (T-Sigs), a novel interpretability method that visualizes learned temporal differences, offering the first explanation for why different video generators are distinguishable. Extensive experiments on public datasets, including cross-domain scenarios, demonstrate that SAGA sets a new benchmark for synthetic video provenance, providing crucial, interpretable insights for forensic and regulatory applications.

</details>


### [160] [DensePercept-NCSSD: Vision Mamba towards Real-time Dense Visual Perception with Non-Causal State Space Duality](https://arxiv.org/abs/2511.12671)
*Tushar Anand,Advik Sinha,Abhijit Das*

Main category: cs.CV

TL;DR: 提出一种基于非因果Mamba块的快速高效模型，用于实时光学流和视差估计，兼顾速度和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决实时应用中光学流和视差估计的高效性和准确性问题。

Method: 提出了一种基于非因果Mamba块的模型，通过融合成对输入图像在非因果选择性状态空间中进行密集感知任务。

Result: 模型减少了推理时间，同时保持了高准确性和低GPU使用率。

Conclusion: 提出的模型可用于统一、实时且准确的3D密集感知估计任务，代码和模型已开源。

Abstract: In this work, we propose an accurate and real-time optical flow and disparity estimation model by fusing pairwise input images in the proposed non-causal selective state space for dense perception tasks. We propose a non-causal Mamba block-based model that is fast and efficient and aptly manages the constraints present in a real-time applications. Our proposed model reduces inference times while maintaining high accuracy and low GPU usage for optical flow and disparity map generation. The results and analysis, and validation in real-life scenario justify that our proposed model can be used for unified real-time and accurate 3D dense perception estimation tasks. The code, along with the models, can be found at https://github.com/vimstereo/DensePerceptNCSSD

</details>


### [161] [Video Finetuning Improves Reasoning Between Frames](https://arxiv.org/abs/2511.12868)
*Ruiqi Yang,Tian Yun,Zihan Wang,Ellie Pavlick*

Main category: cs.CV

TL;DR: 视频微调模型隐含时序推理能力，vCoT提升图像模型性能，视频模型在静态任务中更优。


<details>
  <summary>Details</summary>
Motivation: 探讨视频微调对多模态LLMs的影响，解决当前视频理解中帧标记简单拼接的问题。

Method: 提出视觉思维链（vCoT），生成连续帧之间的过渡事件描述，并系统比较图像与视频微调模型。

Result: vCoT显著提升仅图像模型在长视频问答中的性能，而视频微调模型提升有限；后者在静态关系推理任务中表现更优。

Conclusion: 视频微调的多模态大语言模型（LLMs）已在帧间过渡中隐含地捕捉了时序推理能力，并能在纯静态场景中优于仅基于图像的模型。

Abstract: Multimodal large language models (LLMs) have made rapid progress in visual understanding, yet their extension from images to videos often reduces to a naive concatenation of frame tokens. In this work, we investigate what video finetuning brings to multimodal LLMs. We propose Visual Chain-of-Thought (vCoT), an explicit reasoning process that generates transitional event descriptions between consecutive frames. Using vCoT, we systematically compare image-only LVLMs with their video-finetuned counterparts, both with and without access to these transitional cues. Our experiments show that vCoT significantly improves the performance of image-only models on long-form video question answering, while yielding only marginal gains for video-finetuned models. This suggests that the latter already capture frame-to-frame transitions implicitly. Moreover, we find that video models transfer this temporal reasoning ability to purely static settings, outperforming image models' baselines on relational visual reasoning tasks.

</details>


### [162] [Appreciate the View: A Task-Aware Evaluation Framework for Novel View Synthesis](https://arxiv.org/abs/2511.12675)
*Saar Stern,Ido Sobol,Or Litany*

Main category: cs.CV

TL;DR: 论文提出基于Zero123的NVS评估框架，引入$D_{\text{PRISM}}$和$\text{MMD}_{\text{PRISM}}$指标，解决了现有评估不可靠的问题，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有新视角合成（NVS）的评估指标无法准确衡量生成图像的真实性和对源视图及视角变换的忠实度，导致错误结果被误判。论文旨在填补这一评估空白。

Method: 论文提出了一种基于Zero123模型特征的评估框架，并通过轻量级调优增强其判别能力，设计了参考依赖的$D_{\text{PRISM}}$和无需参考的$\text{MMD}_{\text{PRISM}}$两种指标。

Result: 提出的指标能可靠识别错误生成结果，并与人类偏好一致地排名模型。在三个基准测试（Toys4K、GSO、OmniObject3D）中，$\text{MMD}_{\text{PRISM}}$表现稳定，低分对应更强模型。

Conclusion: 该论文提出了一个基于任务感知的评估框架，通过结合Zero123模型的特征和轻量级调优步骤，引入了两个互补的评估指标（$D_{\text{PRISM}}$和$\text{MMD}_{\text{PRISM}}$），显著提升了新视角合成（NVS）的评估可靠性，为未来研究提供了实用且理论支持的方法。

Abstract: The goal of Novel View Synthesis (NVS) is to generate realistic images of a given content from unseen viewpoints. But how can we trust that a generated image truly reflects the intended transformation? Evaluating its reliability remains a major challenge. While recent generative models, particularly diffusion-based approaches, have significantly improved NVS quality, existing evaluation metrics struggle to assess whether a generated image is both realistic and faithful to the source view and intended viewpoint transformation. Standard metrics, such as pixel-wise similarity and distribution-based measures, often mis-rank incorrect results as they fail to capture the nuanced relationship between the source image, viewpoint change, and generated output. We propose a task-aware evaluation framework that leverages features from a strong NVS foundation model, Zero123, combined with a lightweight tuning step to enhance discrimination. Using these features, we introduce two complementary evaluation metrics: a reference-based score, $D_{\text{PRISM}}$, and a reference-free score, $\text{MMD}_{\text{PRISM}}$. Both reliably identify incorrect generations and rank models in agreement with human preference studies, addressing a fundamental gap in NVS evaluation. Our framework provides a principled and practical approach to assessing synthesis quality, paving the way for more reliable progress in novel view synthesis. To further support this goal, we apply our reference-free metric to six NVS methods across three benchmarks: Toys4K, Google Scanned Objects (GSO), and OmniObject3D, where $\text{MMD}_{\text{PRISM}}$ produces a clear and stable ranking, with lower scores consistently indicating stronger models.

</details>


### [163] [DeepSport: A Multimodal Large Language Model for Comprehensive Sports Video Reasoning via Agentic Reinforcement Learning](https://arxiv.org/abs/2511.12908)
*Junbo Zou,Haotian Xia,Zhen Ye,Shengjie Zhang,Christopher Lai,Vicente Ordonez,Weining Shen,Hanjie Chen*

Main category: cs.CV

TL;DR: DeepSport 是首个端到端训练的多任务、多体育视频理解框架，通过动态推理和数据蒸馏实现高性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有体育视频理解方法的局限性（单体育中心、特定任务或缺乏学习推理过程）。

Method: 采用两阶段训练策略：监督微调（SFT）和强化学习（RL），结合新颖的门控工具使用奖励。

Result: 在6.7k问题的测试基准上，DeepSport 显著优于基线模型，达到最先进的性能。

Conclusion: DeepSport 建立了一个新的领域特定视频推理基础，能够处理多样化的体育复杂性。

Abstract: Sports video understanding presents unique challenges, requiring models to perceive high-speed dynamics, comprehend complex rules, and reason over long temporal contexts. While Multimodal Large Language Models (MLLMs) have shown promise in genral domains, the current state of research in sports remains narrowly focused: existing approaches are either single-sport centric, limited to specific tasks, or rely on training-free paradigms that lack robust, learned reasoning process. To address this gap, we introduce DeepSport, the first end-to-end trained MLLM framework designed for multi-task, multi-sport video understanding. DeepSport shifts the paradigm from passive frame processing to active, iterative reasoning, empowering the model to ``think with videos'' by dynamically interrogating content via a specialized frame-extraction tool. To enable this, we propose a data distillation pipeline that synthesizes high-quality Chain-of-Thought (CoT) trajectories from 10 diverse data source, creating a unified resource of 78k training data. We then employ a two-stage training strategy, Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL) with a novel gated tool-use reward, to optimize the model's reasoning process. Extensive experiments on the testing benchmark of 6.7k questions demonstrate that DeepSport achieves state-of-the-art performance, significantly outperforming baselines of both proprietary model and open-source models. Our work establishes a new foundation for domain-specific video reasoning to address the complexities of diverse sports.

</details>


### [164] [EndoSight AI: Deep Learning-Driven Real-Time Gastrointestinal Polyp Detection and Segmentation for Enhanced Endoscopic Diagnostics](https://arxiv.org/abs/2511.12962)
*Daniel Cavadia*

Main category: cs.CV

TL;DR: EndoSight AI, a deep learning system, excels in real-time polyp detection and segmentation, achieving high accuracy and speed, and is designed for clinical endoscopy use.


<details>
  <summary>Details</summary>
Motivation: Precise and real-time detection of gastrointestinal polyps during endoscopic procedures is crucial for early diagnosis and prevention of colorectal cancer.

Method: The system leverages a deep learning architecture, trained on the Hyper-Kvasir dataset, incorporating clinically relevant performance metrics and a novel thermal-aware procedure for robustness and efficiency.

Result: The system achieves a mean Average Precision (mAP) of 88.3% for polyp detection and a Dice coefficient of up to 69% for segmentation, with real-time inference speeds exceeding 35 fps on GPU hardware.

Conclusion: EndoSight AI is an integrated AI solution designed for seamless deployment in endoscopy workflows, promising to advance diagnostic accuracy and clinical decision-making in gastrointestinal healthcare.

Abstract: Precise and real-time detection of gastrointestinal polyps during endoscopic procedures is crucial for early diagnosis and prevention of colorectal cancer. This work presents EndoSight AI, a deep learning architecture developed and evaluated independently to enable accurate polyp localization and detailed boundary delineation. Leveraging the publicly available Hyper-Kvasir dataset, the system achieves a mean Average Precision (mAP) of 88.3% for polyp detection and a Dice coefficient of up to 69% for segmentation, alongside real-time inference speeds exceeding 35 frames per second on GPU hardware. The training incorporates clinically relevant performance metrics and a novel thermal-aware procedure to ensure model robustness and efficiency. This integrated AI solution is designed for seamless deployment in endoscopy workflows, promising to advance diagnostic accuracy and clinical decision-making in gastrointestinal healthcare.

</details>


### [165] [X-VMamba: Explainable Vision Mamba](https://arxiv.org/abs/2511.12694)
*Mohamed A. Mabrok,Yalda Zafari*

Main category: cs.CV

TL;DR: 该论文提出了一个线性复杂度的可控性框架，用于解释SSMs的内部状态动态，实验验证了其在医学影像中的分层特征细化能力。


<details>
  <summary>Details</summary>
Motivation: 尽管SSMs（尤其是Mamba架构）在序列建模中表现出色，但缺乏类似注意力机制的透明性，使得理解其如何处理空间信息具有挑战性。

Method: 论文提出了两种互补的方法：基于Jacobian的方法适用于任何SSM架构，测量状态传播链中的影响；基于Gramian的方法则针对对角SSMs，通过闭式解析解实现更快的速度。两种方法均在一次前向传递中完成，无需修改架构或调整超参数。

Result: 实验验证了SSMs在医学影像中实现了从低级纹理到临床相关模式的分层特征细化，揭示了与诊断标准一致的可控性特征和扫描策略对注意力模式的显著影响。

Conclusion: 该论文提出了一个基于可控性的可解释性框架，用于量化SSMs内部状态动态中不同输入部分的影响，并通过实验验证了其在医学影像等多种任务中的有效性。

Abstract: State Space Models (SSMs), particularly the Mamba architecture, have recently emerged as powerful alternatives to Transformers for sequence modeling, offering linear computational complexity while achieving competitive performance. Yet, despite their effectiveness, understanding how these Vision SSMs process spatial information remains challenging due to the lack of transparent, attention-like mechanisms. To address this gap, we introduce a controllability-based interpretability framework that quantifies how different parts of the input sequence (tokens or patches) influence the internal state dynamics of SSMs. We propose two complementary formulations: a Jacobian-based method applicable to any SSM architecture that measures influence through the full chain of state propagation, and a Gramian-based approach for diagonal SSMs that achieves superior speed through closed-form analytical solutions. Both methods operate in a single forward pass with linear complexity, requiring no architectural modifications or hyperparameter tuning. We validate our framework through experiments on three diverse medical imaging modalities, demonstrating that SSMs naturally implement hierarchical feature refinement from diffuse low-level textures in early layers to focused, clinically meaningful patterns in deeper layers. Our analysis reveals domain-specific controllability signatures aligned with diagnostic criteria, progressive spatial selectivity across the network hierarchy, and the substantial influence of scanning strategies on attention patterns. Beyond medical imaging, we articulate applications spanning computer vision, natural language processing, and cross-domain tasks. Our framework establishes controllability analysis as a unified, foundational interpretability paradigm for SSMs across all domains. Code and analysis tools will be made available upon publication

</details>


### [166] [CalibrateMix: Guided-Mixup Calibration of Image Semi-Supervised Models](https://arxiv.org/abs/2511.12964)
*Mehrab Mustafy Rahman,Jayanth Mohan,Tiberiu Sosea,Cornelia Caragea*

Main category: cs.CV

TL;DR: 提出CalibrateMix方法，通过针对性混合样本改善SSL模型校准，实验证明其在校准和准确性上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有SSL方法在校准方面表现不佳，伪标签的随机混合导致模型过度自信。

Method: 利用训练动态识别“易学”和“难学”样本，并针对性地混合这些样本（CalibrateMix）。

Result: 在多个基准图像数据集上，CalibrateMix实现了更低的预期校准误差（ECE）和更高的准确性。

Conclusion: CalibrateMix方法在SSL中显著改善了模型的校准性能，同时保持了分类准确性，为SSL领域提供了新的校准解决方案。

Abstract: Semi-supervised learning (SSL) has demonstrated high performance in image classification tasks by effectively utilizing both labeled and unlabeled data. However, existing SSL methods often suffer from poor calibration, with models yielding overconfident predictions that misrepresent actual prediction likelihoods. Recently, neural networks trained with {\tt mixup} that linearly interpolates random examples from the training set have shown better calibration in supervised settings. However, calibration of neural models remains under-explored in semi-supervised settings. Although effective in supervised model calibration, random mixup of pseudolabels in SSL presents challenges due to the overconfidence and unreliability of pseudolabels. In this work, we introduce CalibrateMix, a targeted mixup-based approach that aims to improve the calibration of SSL models while maintaining or even improving their classification accuracy. Our method leverages training dynamics of labeled and unlabeled samples to identify ``easy-to-learn'' and ``hard-to-learn'' samples, which in turn are utilized in a targeted mixup of easy and hard samples. Experimental results across several benchmark image datasets show that our method achieves lower expected calibration error (ECE) and superior accuracy compared to existing SSL approaches.

</details>


### [167] [Counting Through Occlusion: Framework for Open World Amodal Counting](https://arxiv.org/abs/2511.12702)
*Safaeid Hossain Arib,Rabeya Akter,Abdul Monaf Chowdhury,Md Jubair Ahmed Sourov,Md Mehedi Hasan*

Main category: cs.CV

TL;DR: CountOCC是一种遮挡物体计数框架，通过多模态特征重建和注意力一致性优化，显著提升遮挡场景下的计数精度。


<details>
  <summary>Details</summary>
Motivation: 现有物体计数方法在遮挡情况下性能下降，原因是主干网络编码了遮挡表面而非目标物体，导致特征表示不准确。

Method: 提出了CountOCC框架，通过结合可见片段的上下文信息和文本/视觉嵌入的语义先验，重建被遮挡物体的特征，并引入视觉等价性目标确保注意力空间的一致性。

Result: 在FSC 147、CARPK和CAPTUREReal数据集上，CountOCC分别实现了26.72%、49.89%和28.79%的MAE降低，显著优于现有方法。

Conclusion: CountOCC通过多模态引导和视觉等价性目标，显著提升了遮挡情况下的物体计数性能，并在多个数据集上实现了SOTA结果。

Abstract: Object counting has achieved remarkable success on visible instances, yet state-of-the-art (SOTA) methods fail under occlusion, a pervasive challenge in real world deployment. This failure stems from a fundamental architectural limitation where backbone networks encode occluding surfaces rather than target objects, thereby corrupting the feature representations required for accurate enumeration. To address this, we present CountOCC, an amodal counting framework that explicitly reconstructs occluded object features through hierarchical multimodal guidance. Rather than accepting degraded encodings, we synthesize complete representations by integrating spatial context from visible fragments with semantic priors from text and visual embeddings, generating class-discriminative features at occluded locations across multiple pyramid levels. We further introduce a visual equivalence objective that enforces consistency in attention space, ensuring that both occluded and unoccluded views of the same scene produce spatially aligned gradient-based attention maps. Together, these complementary mechanisms preserve discriminative properties essential for accurate counting under occlusion. For rigorous evaluation, we establish occlusion-augmented versions of FSC 147 and CARPK spanning both structured and unstructured scenes. CountOCC achieves SOTA performance on FSC 147 with 26.72% and 20.80% MAE reduction over prior baselines under occlusion in validation and test, respectively. CountOCC also demonstrates exceptional generalization by setting new SOTA results on CARPK with 49.89% MAE reduction and on CAPTUREReal with 28.79% MAE reduction, validating robust amodal counting across diverse visual domains. Code will be released soon.

</details>


### [168] [UNSEEN: Enhancing Dataset Pruning from a Generalization Perspective](https://arxiv.org/abs/2511.12988)
*Furui Xu,Shaobo Wang,Jiajun Zhang,Chenghao Sun,Haixiang Tang,Linfeng Zhang*

Main category: cs.CV

TL;DR: UNSEEN通过泛化视角和多步增量选择优化数据集修剪，显著提升性能并在ImageNet-1K上实现30%数据减少下的无损表现。


<details>
  <summary>Details</summary>
Motivation: 解决现有数据集修剪方法因依赖训练阶段的模型性能而导致样本评分密集分布、选择效果不佳的问题。

Method: 提出了一种即插即用的框架UNSEEN，支持多步场景和增量选择技术，通过在不同核心集上训练的评分模型动态优化核心集质量。

Result: 在CIFAR-10、CIFAR-100和ImageNet-1K上显著优于现有SOTA方法，尤其在ImageNet-1K上实现了30%训练数据减少下的无损性能。

Conclusion: UNSEEN方法通过从泛化角度进行数据集修剪，显著提升了现有方法的性能，特别是在大规模数据集上实现了无损性能的同时减少了训练数据量。

Abstract: The growing scale of datasets in deep learning has introduced significant computational challenges. Dataset pruning addresses this challenge by constructing a compact but informative coreset from the full dataset with comparable performance. Previous approaches typically establish scoring metrics based on specific criteria to identify representative samples. However, these methods predominantly rely on sample scores obtained from the model's performance during the training (i.e., fitting) phase. As scoring models achieve near-optimal performance on training data, such fitting-centric approaches induce a dense distribution of sample scores within a narrow numerical range. This concentration reduces the distinction between samples and hinders effective selection. To address this challenge, we conduct dataset pruning from the perspective of generalization, i.e., scoring samples based on models not exposed to them during training. We propose a plug-and-play framework, UNSEEN, which can be integrated into existing dataset pruning methods. Additionally, conventional score-based methods are single-step and rely on models trained solely on the complete dataset, providing limited perspective on the importance of samples. To address this limitation, we scale UNSEEN to multi-step scenarios and propose an incremental selection technique through scoring models trained on varying coresets, and optimize the quality of the coreset dynamically. Extensive experiments demonstrate that our method significantly outperforms existing state-of-the-art (SOTA) methods on CIFAR-10, CIFAR-100, and ImageNet-1K. Notably, on ImageNet-1K, UNSEEN achieves lossless performance while reducing training data by 30\%.

</details>


### [169] [FSDAM: Few-Shot Driving Attention Modeling via Vision-Language Coupling](https://arxiv.org/abs/2511.12708)
*Kaiser Hamid,Can Cui,Khandakar Ashrafi Akbar,Ziran Wang,Nade Liang*

Main category: cs.CV

TL;DR: FSDAM是一种少样本驾驶员注意力建模框架，通过双路径架构实现联合注意力预测和标题生成，仅需约100标注样本，性能媲美现有方法，且具备零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有模型依赖大规模注视数据集，但这类数据集收集和整理成本高，因此需要开发在少量标注样本下仍能有效工作的模型。

Method: 采用双路径架构，分别处理空间预测和标题生成，并通过跨模态对齐保持语义一致性。

Result: FSDAM在仅约100个标注样本下实现了与现有方法相媲美的注意力预测性能，生成了连贯且上下文感知的解释，并展示了强大的零样本泛化能力。

Conclusion: FSDAM框架在有限监督下实现了竞争性的注意力预测和上下文感知解释生成，为零样本泛化提供了新思路，推动了可解释驾驶员注意力系统在数据受限场景下的实际应用。

Abstract: Understanding where drivers look and why they shift their attention is essential for autonomous systems that read human intent and justify their actions. Most existing models rely on large-scale gaze datasets to learn these patterns; however, such datasets are labor-intensive to collect and time-consuming to curate. We present FSDAM (Few-Shot Driver Attention Modeling), a framework that achieves joint attention prediction and caption generation with approximately 100 annotated examples, two orders of magnitude fewer than existing approaches. Our approach introduces a dual-pathway architecture where separate modules handle spatial prediction and caption generation while maintaining semantic consistency through cross-modal alignment. Despite minimal supervision, FSDAM achieves competitive performance on attention prediction, generates coherent, and context-aware explanations. The model demonstrates robust zero-shot generalization across multiple driving benchmarks. This work shows that effective attention-conditioned generation is achievable with limited supervision, opening new possibilities for practical deployment of explainable driver attention systems in data-constrained scenarios.

</details>


### [170] [SAGE: Spuriousness-Aware Guided Prompt Exploration for Mitigating Multimodal Bias](https://arxiv.org/abs/2511.13005)
*Wenqian Ye,Di Wang,Guangtao Zheng,Bohan Liu,Aidong Zhang*

Main category: cs.CV

TL;DR: SAGE通过引导提示选择减轻CLIP模型的多模态虚假偏差，提升零样本分类性能，无需训练或外部知识。


<details>
  <summary>Details</summary>
Motivation: CLIP模型在多模态虚假偏差（依赖虚假特征）上表现不佳，影响其在分布外数据上的鲁棒性。现有方法通常需要微调或先验知识，限制了CLIP的即插即用性。

Method: 提出了Spuriousness-Aware Guided Exploration (SAGE)，一种无需训练、微调或外部注释的方法，通过引导提示选择来减轻虚假偏差。

Result: 在四个真实世界基准数据集和五个流行骨干模型上，SAGE一致提升了零样本性能和泛化能力，优于现有零样本方法。

Conclusion: SAGE方法通过引导提示选择有效减轻了多模态虚假偏差，无需训练或微调，显著提升了零样本分类的性能和泛化能力。

Abstract: Large vision-language models, such as CLIP, have shown strong zero-shot classification performance by aligning images and text in a shared embedding space. However, CLIP models often develop multimodal spurious biases, which is the undesirable tendency to rely on spurious features. For example, CLIP may infer object types in images based on frequently co-occurring backgrounds rather than the object's core features. This bias significantly impairs the robustness of pre-trained CLIP models on out-of-distribution data, where such cross-modal associations no longer hold. Existing methods for mitigating multimodal spurious bias typically require fine-tuning on downstream data or prior knowledge of the bias, which undermines the out-of-the-box usability of CLIP. In this paper, we first theoretically analyze the impact of multimodal spurious bias in zero-shot classification. Based on this insight, we propose Spuriousness-Aware Guided Exploration (SAGE), a simple and effective method that mitigates spurious bias through guided prompt selection. SAGE requires no training, fine-tuning, or external annotations. It explores a space of prompt templates and selects the prompts that induce the largest semantic separation between classes, thereby improving worst-group robustness. Extensive experiments on four real-world benchmark datasets and five popular backbone models demonstrate that SAGE consistently improves zero-shot performance and generalization, outperforming previous zero-shot approaches without any external knowledge or model updates.

</details>


### [171] [Backdoor Attacks on Open Vocabulary Object Detectors via Multi-Modal Prompt Tuning](https://arxiv.org/abs/2511.12735)
*Ankita Raj,Chetan Arora*

Main category: cs.CV

TL;DR: TrAP是一种针对开放词汇对象检测器的多模态后门攻击方法，通过优化提示参数和视觉触发器，实现了高攻击成功率且不影响模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 随着开放词汇对象检测器（OVODs）在高风险应用中的普及，理解其安全风险变得至关重要。

Method: 提出了一种联合优化图像和文本模态提示参数以及视觉触发器的多模态后门注入策略TrAP，并采用基于课程学习的训练策略逐步缩小触发器尺寸。

Result: 实验表明，TrAP在多个数据集上实现了高攻击成功率，同时在零样本设置下提高了下游数据集的干净图像性能。

Conclusion: TrAP（Trigger-Aware Prompt tuning）作为一种多模态后门注入策略，首次揭示了通过提示调优引入的攻击面，并在不重新训练基础模型权重的情况下，实现了高攻击成功率。

Abstract: Open-vocabulary object detectors (OVODs) unify vision and language to detect arbitrary object categories based on text prompts, enabling strong zero-shot generalization to novel concepts. As these models gain traction in high-stakes applications such as robotics, autonomous driving, and surveillance, understanding their security risks becomes crucial. In this work, we conduct the first study of backdoor attacks on OVODs and reveal a new attack surface introduced by prompt tuning. We propose TrAP (Trigger-Aware Prompt tuning), a multi-modal backdoor injection strategy that jointly optimizes prompt parameters in both image and text modalities along with visual triggers. TrAP enables the attacker to implant malicious behavior using lightweight, learnable prompt tokens without retraining the base model weights, thus preserving generalization while embedding a hidden backdoor. We adopt a curriculum-based training strategy that progressively shrinks the trigger size, enabling effective backdoor activation using small trigger patches at inference. Experiments across multiple datasets show that TrAP achieves high attack success rates for both object misclassification and object disappearance attacks, while also improving clean image performance on downstream datasets compared to the zero-shot setting.

</details>


### [172] [MeanFlow Transformers with Representation Autoencoders](https://arxiv.org/abs/2511.13019)
*Zheyuan Hu,Chieh-Hsin Lai,Ge Wu,Yuki Mitsufuji,Stefano Ermon*

Main category: cs.CV

TL;DR: 提出RAE潜在空间中的高效MF训练方案，显著提升性能并降低成本。


<details>
  <summary>Details</summary>
Motivation: 解决MF训练的计算成本高、不稳定性问题，以及推理时SD-VAE解码器的高生成成本和复杂引导超参数依赖。

Method: 采用一致性中期训练进行轨迹感知初始化，并使用两阶段方案：从预训练的流匹配教师模型蒸馏以加速收敛，随后通过单点速度估计器进行可选的自举阶段。

Result: 在ImageNet 256上，1步FID达到2.03，优于vanilla MF的3.43，同时采样GFLOPS减少38%，总训练成本降低83%。

Conclusion: 本文提出了一种在表示自编码器（RAE）潜在空间中高效训练和采样MeanFlow（MF）的方案，显著提升了训练稳定性、计算效率，并简化了配置。

Abstract: MeanFlow (MF) is a diffusion-motivated generative model that enables efficient few-step generation by learning long jumps directly from noise to data. In practice, it is often used as a latent MF by leveraging the pre-trained Stable Diffusion variational autoencoder (SD-VAE) for high-dimensional data modeling. However, MF training remains computationally demanding and is often unstable. During inference, the SD-VAE decoder dominates the generation cost, and MF depends on complex guidance hyperparameters for class-conditional generation. In this work, we develop an efficient training and sampling scheme for MF in the latent space of a Representation Autoencoder (RAE), where a pre-trained vision encoder (e.g., DINO) provides semantically rich latents paired with a lightweight decoder. We observe that naive MF training in the RAE latent space suffers from severe gradient explosion. To stabilize and accelerate training, we adopt Consistency Mid-Training for trajectory-aware initialization and use a two-stage scheme: distillation from a pre-trained flow matching teacher to speed convergence and reduce variance, followed by an optional bootstrapping stage with a one-point velocity estimator to further reduce deviation from the oracle mean flow. This design removes the need for guidance, simplifies training configurations, and reduces computation in both training and sampling. Empirically, our method achieves a 1-step FID of 2.03, outperforming vanilla MF's 3.43, while reducing sampling GFLOPS by 38% and total training cost by 83% on ImageNet 256. We further scale our approach to ImageNet 512, achieving a competitive 1-step FID of 3.23 with the lowest GFLOPS among all baselines. Code is available at https://github.com/sony/mf-rae.

</details>


### [173] [Direct Visual Grounding by Directing Attention of Visual Tokens](https://arxiv.org/abs/2511.12738)
*Parsa Esmaeilkhani,Longin Jan Latecki*

Main category: cs.CV

TL;DR: 提出KL注意力损失（KLAL）以直接监督视觉标记注意力，显著提升VLMs在视觉任务中的表现，并发现商业模型在线条追踪任务中的不足。


<details>
  <summary>Details</summary>
Motivation: 发现视觉语言模型中与查询最相关的视觉标记在LLM模块的最终层中几乎未被答案标记关注，导致视觉问题回答错误。

Method: 提出了一种新颖的损失函数KLAL，通过KL散度将视觉标记的注意力分布与真实注意力图对齐，直接监督视觉标记的注意力。

Result: 实验证实KLAL与NTP结合能显著提升模型在合成和真实数据上的表现，并揭示了商业VLMs在线条追踪任务上的不足。

Conclusion: 通过提出的KL注意力损失（KLAL）与标准下一词预测（NTP）损失结合，显著提升了视觉语言模型（VLMs）在几何任务、指向和指代表达理解等任务上的表现。

Abstract: Vision Language Models (VLMs) mix visual tokens and text tokens. A puzzling issue is the fact that visual tokens most related to the query receive little to no attention in the final layers of the LLM module of VLMs from the answer tokens, where all tokens are treated equally, in particular, visual and language tokens in the LLM attention layers. This fact may result in wrong answers to visual questions, as our experimental results confirm. It appears that the standard next-token prediction (NTP) loss provides an insufficient signal for directing attention to visual tokens. We hypothesize that a more direct supervision of the attention of visual tokens to corresponding language tokens in the LLM module of VLMs will lead to improved performance on visual tasks. To demonstrate that this is indeed the case, we propose a novel loss function that directly supervises the attention of visual tokens. It directly grounds the answer language tokens in images by directing their attention to the relevant visual tokens. This is achieved by aligning the attention distribution of visual tokens to ground truth attention maps with KL divergence. The ground truth attention maps are obtained from task geometry in synthetic cases or from standard grounding annotations (e.g., bounding boxes or point annotations) in real images, and are used inside the LLM for attention supervision without requiring new labels. The obtained KL attention loss (KLAL) when combined with NTP encourages VLMs to attend to relevant visual tokens while generating answer tokens. This results in notable improvements across geometric tasks, pointing, and referring expression comprehension on both synthetic and real-world data, as demonstrated by our experiments. We also introduce a new dataset to evaluate the line tracing abilities of VLMs. Surprisingly, even commercial VLMs do not perform well on this task.

</details>


### [174] [SpectralAdapt: Semi-Supervised Domain Adaptation with Spectral Priors for Human-Centered Hyperspectral Image Reconstruction](https://arxiv.org/abs/2511.13020)
*Yufei Wen,Yuting Zhang,Jingdan Kang,Hao Ren,Weibin Cheng,Jintai Chen,Kaishun Wu*

Main category: cs.CV

TL;DR: SpectralAdapt通过半监督域适应和两项创新技术（SDM和SERA），有效解决了医疗HSI数据稀缺问题，提升了重建性能。


<details>
  <summary>Details</summary>
Motivation: 解决人体HSI数据稀缺问题，同时利用丰富的未标记数据，提升医疗领域HSI重建的性能。

Method: 提出了Spectral Density Masking（SDM）和Spectral Endmember Representation Alignment（SERA）两项技术，分别通过自适应RGB通道掩蔽和物理可解释的端元表示对齐来增强光谱推理。

Result: 在基准数据集上验证了SpectralAdapt在光谱保真度、跨域泛化和训练稳定性方面的显著提升。

Conclusion: SpectralAdapt框架通过半监督域适应（SSDA）有效解决了人体HSI数据稀缺的问题，显著提升了光谱保真度、跨域泛化能力和训练稳定性。

Abstract: Hyperspectral imaging (HSI) holds great potential for healthcare due to its rich spectral information. However, acquiring HSI data remains costly and technically demanding. Hyperspectral image reconstruction offers a practical solution by recovering HSI data from accessible modalities, such as RGB. While general domain datasets are abundant, the scarcity of human HSI data limits progress in medical applications. To tackle this, we propose SpectralAdapt, a semi-supervised domain adaptation (SSDA) framework that bridges the domain gap between general and human-centered HSI datasets. To fully exploit limited labels and abundant unlabeled data, we enhance spectral reasoning by introducing Spectral Density Masking (SDM), which adaptively masks RGB channels based on their spectral complexity, encouraging recovery of informative regions from complementary cues during consistency training. Furthermore, we introduce Spectral Endmember Representation Alignment (SERA), which derives physically interpretable endmembers from valuable labeled pixels and employs them as domain-invariant anchors to guide unlabeled predictions, with momentum updates ensuring adaptability and stability. These components are seamlessly integrated into SpectralAdapt, a spectral prior-guided framework that effectively mitigates domain shift, spectral degradation, and data scarcity in HSI reconstruction. Experiments on benchmark datasets demonstrate consistent improvements in spectral fidelity, cross-domain generalization, and training stability, highlighting the promise of SSDA as an efficient solution for hyperspectral imaging in healthcare.

</details>


### [175] [Deep Imbalanced Multi-Target Regression: 3D Point Cloud Voxel Content Estimation in Simulated Forests](https://arxiv.org/abs/2511.12740)
*Amirhossein Hassanzadeh,Bartosz Krawczyk,Michael Saunders,Rob Wible,Keith Krause,Dimah Dera,Jan van Aardt*

Main category: cs.CV

TL;DR: 本研究通过KPConv和成本敏感学习，分析了不同体素尺寸对LiDAR点云数据中目标占用百分比估计的影响，发现较大体素尺寸误差更低，但应用需根据场景选择。


<details>
  <summary>Details</summary>
Motivation: 探讨是否可以从高级体素化的LiDAR点云数据中推断低级别体素内容信息（如目标占用百分比），以解决体素化导致细尺度结构信息丢失的问题。

Method: 提出了一种基于核点卷积（KPConv）的多目标回归方法，结合成本敏感学习（密度相关性，DBR）处理类别不平衡，采用加权均方误差（MSE）、焦点回归（FocalR）和正则化优化KPConv。

Result: 敏感性分析显示，较大体素尺寸（如2米）因变异性降低而误差较小，而较小体素尺寸（如0.25或0.5米）在树冠等高变异性区域误差显著较高。树皮和树叶目标在较小体素尺寸数据集中的误差明显高于较大体素尺寸数据集。

Conclusion: 本研究填补了深度学习不平衡模型在多目标回归和3D LiDAR点云模拟数据集中的空白，并证明了体素尺寸的选择需根据具体应用场景而定。

Abstract: Voxelization is an effective approach to reduce the computational cost of processing Light Detection and Ranging (LiDAR) data, yet it results in a loss of fine-scale structural information. This study explores whether low-level voxel content information, specifically target occupancy percentage within a voxel, can be inferred from high-level voxelized LiDAR point cloud data collected from Digital Imaging and remote Sensing Image Generation (DIRSIG) software. In our study, the targets include bark, leaf, soil, and miscellaneous materials. We propose a multi-target regression approach in the context of imbalanced learning using Kernel Point Convolutions (KPConv). Our research leverages cost-sensitive learning to address class imbalance called density-based relevance (DBR). We employ weighted Mean Saquared Erorr (MSE), Focal Regression (FocalR), and regularization to improve the optimization of KPConv. This study performs a sensitivity analysis on the voxel size (0.25 - 2 meters) to evaluate the effect of various grid representations in capturing the nuances of the forest. This sensitivity analysis reveals that larger voxel sizes (e.g., 2 meters) result in lower errors due to reduced variability, while smaller voxel sizes (e.g., 0.25 or 0.5 meter) exhibit higher errors, particularly within the canopy, where variability is greatest. For bark and leaf targets, error values at smaller voxel size datasets (0.25 and 0.5 meter) were significantly higher than those in larger voxel size datasets (2 meters), highlighting the difficulty in accurately estimating within-canopy voxel content at fine resolutions. This suggests that the choice of voxel size is application-dependent. Our work fills the gap in deep imbalance learning models for multi-target regression and simulated datasets for 3D LiDAR point clouds of forests.

</details>


### [176] [Rethinking Saliency Maps: A Cognitive Human Aligned Taxonomy and Evaluation Framework for Explanations](https://arxiv.org/abs/2511.13081)
*Yehonatan Elisha,Seffi Cohen,Oren Barkan,Noam Koenigstein*

Main category: cs.CV

TL;DR: 提出RFxG分类法和四个新指标，系统性评估显著性解释的质量，强调与用户意图对齐的重要性。


<details>
  <summary>Details</summary>
Motivation: 解决显著性图在深度学习中视觉解释的模糊性，缺乏共识的问题，以提高解释方法的评估和实用性。

Method: 引入RFxG分类法（参考框架×粒度），并开发四个新的忠实性指标来评估解释质量。

Result: 通过RFxG框架揭示了现有评估指标的局限性，并验证了十种先进显著性方法、四种模型架构和三个数据集的解释质量。

Conclusion: 我们的工作通过提出RFxG分类法和四个新颖的忠实性指标，为视觉解释提供了概念基础和实践工具，使其不仅忠实于模型行为，还与人类理解的复杂性对齐。

Abstract: Saliency maps are widely used for visual explanations in deep learning, but a fundamental lack of consensus persists regarding their intended purpose and alignment with diverse user queries. This ambiguity hinders the effective evaluation and practical utility of explanation methods.We address this gap by introducing the Reference-Frame $\times$ Granularity (RFxG) taxonomy, a principled conceptual framework that organizes saliency explanations along two essential axes:Reference-Frame: Distinguishing between pointwise ("Why this prediction?") and contrastive ("Why this and not an alternative?") explanations.Granularity: Ranging from fine-grained class-level (e.g., "Why Husky?") to coarse-grained group-level (e.g., "Why Dog?") interpretations.Using the RFxG lens, we demonstrate critical limitations in existing evaluation metrics, which overwhelmingly prioritize pointwise faithfulness while neglecting contrastive reasoning and semantic granularity. To systematically assess explanation quality across both RFxG dimensions, we propose four novel faithfulness metrics. Our comprehensive evaluation framework applies these metrics to ten state-of-the-art saliency methods, four model architectures, and three datasets.By advocating a shift toward user-intent-driven evaluation, our work provides both the conceptual foundation and the practical tools necessary to develop visual explanations that are not only faithful to the underlying model behavior but are also meaningfully aligned with the complexity of human understanding and inquiry.

</details>


### [177] [SAGE: Saliency-Guided Contrastive Embeddings](https://arxiv.org/abs/2511.12744)
*Colton R. Crum,Adam Czajka*

Main category: cs.CV

TL;DR: SAGE通过潜在空间嵌入整合人类显著性，使用对比损失提升分类性能，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖内部模型机制来整合显著性，但研究表明这些机制可能不可靠。挑战源于仅在图像空间中应用指导方法。

Method: 提出SAGE损失函数，使用对比嵌入将人类显著性整合到网络训练中。通过显著性保留和显著性退化信号增强输入，并捕捉嵌入和模型logits的变化。使用对比三元组损失引导模型关注显著性特征。

Result: SAGE在开放和封闭场景中的分类性能均优于现有方法，展示了其在多种主干网络和任务中的广泛泛化能力。

Conclusion: SAGE（Saliency-Guided Contrastive Embeddings）通过在模型潜在空间嵌入中整合人类显著性指导，显著提升了分类性能，并在开放和封闭场景中优于现有的显著性方法。

Abstract: Integrating human perceptual priors into the training of neural networks has been shown to raise model generalization, serve as an effective regularizer, and align models with human expertise for applications in high-risk domains. Existing approaches to integrate saliency into model training often rely on internal model mechanisms, which recent research suggests may be unreliable. Our insight is that many challenges associated with saliency-guided training stem from the placement of the guidance approaches solely within the image space. Instead, we move away from the image space, use the model's latent space embeddings to steer human guidance during training, and we propose SAGE (Saliency-Guided Contrastive Embeddings): a loss function that integrates human saliency into network training using contrastive embeddings. We apply salient-preserving and saliency-degrading signal augmentations to the input and capture the changes in embeddings and model logits. We guide the model towards salient features and away from non-salient features using a contrastive triplet loss. Additionally, we perform a sanity check on the logit distributions to ensure that the model outputs match the saliency-based augmentations. We demonstrate a boost in classification performance across both open- and closed-set scenarios against SOTA saliency-based methods, showing SAGE's effectiveness across various backbones, and include experiments to suggest its wide generalization across tasks.

</details>


### [178] [Shedding Light on VLN Robustness: A Black-box Framework for Indoor Lighting-based Adversarial Attack](https://arxiv.org/abs/2511.13132)
*Chenyang Li,Wenbing Tang,Yihao Huang,Sinong Simon Zhan,Ming Hu,Xiaojun Jia,Yang Liu*

Main category: cs.CV

TL;DR: ILA通过操纵室内光照（静态和动态模式）显著干扰VLN代理导航，揭示其对光照变化的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有对抗评估依赖的扰动（如异常纹理）在实际室内环境中罕见，研究聚焦于室内光照这一固有但被忽视的场景属性。

Method: 提出了室内光照对抗攻击（ILA）框架，包括静态（SILA）和动态（DILA）两种攻击模式，通过操纵全局光照干扰VLN代理。

Result: ILA在两种最先进的VLN模型和三个导航任务中评估，结果显示其显著增加了失败率并降低了轨迹效率。

Conclusion: ILA显著提高了VLN代理的失败率并降低了轨迹效率，揭示了VLN代理在实际室内光照变化下先前未被认识的脆弱性。

Abstract: Vision-and-Language Navigation (VLN) agents have made remarkable progress, but their robustness remains insufficiently studied. Existing adversarial evaluations often rely on perturbations that manifest as unusual textures rarely encountered in everyday indoor environments. Errors under such contrived conditions have limited practical relevance, as real-world agents are unlikely to encounter such artificial patterns. In this work, we focus on indoor lighting, an intrinsic yet largely overlooked scene attribute that strongly influences navigation. We propose Indoor Lighting-based Adversarial Attack (ILA), a black-box framework that manipulates global illumination to disrupt VLN agents. Motivated by typical household lighting usage, we design two attack modes: Static Indoor Lighting-based Attack (SILA), where the lighting intensity remains constant throughout an episode, and Dynamic Indoor Lighting-based Attack (DILA), where lights are switched on or off at critical moments to induce abrupt illumination changes. We evaluate ILA on two state-of-the-art VLN models across three navigation tasks. Results show that ILA significantly increases failure rates while reducing trajectory efficiency, revealing previously unrecognized vulnerabilities of VLN agents to realistic indoor lighting variations.

</details>


### [179] [Automated Road Distress Detection Using Vision Transformersand Generative Adversarial Networks](https://arxiv.org/abs/2511.13145)
*Cesar Portocarrero Rodriguez,Laura Vandeweyen,Yosuke Yamamoto*

Main category: cs.CV

TL;DR: 研究利用GAN合成数据和CV技术（CNN及MaskFormer）提升道路损伤监测效率，结果显示MaskFormer性能更优。


<details>
  <summary>Details</summary>
Motivation: 美国基础设施状况堪忧，尤其是道路系统评分低，传统检测方法低效且昂贵。利用自动驾驶车辆实时视觉数据和CV技术，有望提升道路监测效率。

Method: 研究首先评估了GAN生成的合成数据对模型训练的效用，随后应用CNN进行道路损伤分割，并对比了基于Transformer的MaskFormer模型。

Result: GAN生成的数据提升了模型性能，MaskFormer在mAP50和IoU上表现优于CNN。

Conclusion: 该研究展示了GAN生成的数据能提升模型性能，且基于Transformer的MaskFormer在mAP50和IoU两项指标上优于CNN模型，为道路监测提供了更高效的技术路径。

Abstract: The American Society of Civil Engineers has graded Americas infrastructure condition as a C, with the road system receiving a dismal D. Roads are vital to regional economic viability, yet their management, maintenance, and repair processes remain inefficient, relying on outdated manual or laser-based inspection methods that are both costly and time-consuming. With the increasing availability of real-time visual data from autonomous vehicles, there is an opportunity to apply computer vision (CV) methods for advanced road monitoring, providing insights to guide infrastructure rehabilitation efforts. This project explores the use of state-of-the-art CV techniques for road distress segmentation. It begins by evaluating synthetic data generated with Generative Adversarial Networks (GANs) to assess its usefulness for model training. The study then applies Convolutional Neural Networks (CNNs) for road distress segmentation and subsequently examines the transformer-based model MaskFormer. Results show that GAN-generated data improves model performance and that MaskFormer outperforms the CNN model in two metrics: mAP50 and IoU.

</details>


### [180] [RoCoISLR: A Romanian Corpus for Isolated Sign Language Recognition](https://arxiv.org/abs/2511.12767)
*Cătălin-Alexandru Rîpanu,Andrei-Theodor Hotnog,Giulia-Stefania Imbrea,Dumitru-Clementin Cercel*

Main category: cs.CV

TL;DR: Introduced RoCoISLR, a new Romanian sign language dataset, tested 7 models, found Swin Transformer best (34.1% accuracy), highlighting challenges in low-resource languages.


<details>
  <summary>Details</summary>
Motivation: The lack of a large-scale, standardized dataset for Romanian Isolated Sign Language Recognition (RoISLR) limits research progress, prompting the creation of RoCoISLR.

Method: Seven state-of-the-art video recognition models (I3D, SlowFast, Swin Transformer, TimeSformer, Uniformer, VideoMAE, and PoseConv3D) were evaluated under consistent experimental setups.

Result: Swin Transformer achieved a Top-1 accuracy of 34.1%, outperforming convolutional models, though challenges with long-tail class distributions in low-resource languages were noted.

Conclusion: The study established benchmark results for Romanian Isolated Sign Language Recognition (RoISLR) using RoCoISLR, a new dataset, highlighting the superior performance of transformer-based models like Swin Transformer.

Abstract: Automatic sign language recognition plays a crucial role in bridging the communication gap between deaf communities and hearing individuals; however, most available datasets focus on American Sign Language. For Romanian Isolated Sign Language Recognition (RoISLR), no large-scale, standardized dataset exists, which limits research progress. In this work, we introduce a new corpus for RoISLR, named RoCoISLR, comprising over 9,000 video samples that span nearly 6,000 standardized glosses from multiple sources. We establish benchmark results by evaluating seven state-of-the-art video recognition models-I3D, SlowFast, Swin Transformer, TimeSformer, Uniformer, VideoMAE, and PoseConv3D-under consistent experimental setups, and compare their performance with that of the widely used WLASL2000 corpus. According to the results, transformer-based architectures outperform convolutional baselines; Swin Transformer achieved a Top-1 accuracy of 34.1%. Our benchmarks highlight the challenges associated with long-tail class distributions in low-resource sign languages, and RoCoISLR provides the initial foundation for systematic RoISLR research.

</details>


### [181] [SOMA: Feature Gradient Enhanced Affine-Flow Matching for SAR-Optical Registration](https://arxiv.org/abs/2511.13168)
*Haodong Wang,Tao Zhuo,Xiuwei Zhang,Hanlin Yin,Wencong Wu,Yanning Zhang*

Main category: cs.CV

TL;DR: SOMA通过整合梯度先验和混合匹配策略，显著提升了SAR与光学图像的配准精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 由于SAR和光学图像的成像机制和视觉特性差异，像素级配准仍具挑战性。现有的深度学习方法未能有效利用梯度信息。

Method: SOMA框架整合了结构梯度先验到深度特征中，并通过混合匹配策略优化对齐。具体包括特征梯度增强器（FGE）和全局-局部仿射流匹配器（GLAM）。

Result: 实验结果表明，SOMA在配准精度上有显著提升，CMR@1px在SEN1-2和GFGE_SO数据集上分别提高了12.29%和18.50%。

Conclusion: SOMA显著提升了SAR与光学图像的配准精度，在SEN1-2和GFGE_SO数据集上分别提高了12.29%和18.50%的CMR@1px。此外，SOMA表现出强大的鲁棒性，能够适应不同场景和分辨率。

Abstract: Achieving pixel-level registration between SAR and optical images remains a challenging task due to their fundamentally different imaging mechanisms and visual characteristics. Although deep learning has achieved great success in many cross-modal tasks, its performance on SAR-Optical registration tasks is still unsatisfactory. Gradient-based information has traditionally played a crucial role in handcrafted descriptors by highlighting structural differences. However, such gradient cues have not been effectively leveraged in deep learning frameworks for SAR-Optical image matching. To address this gap, we propose SOMA, a dense registration framework that integrates structural gradient priors into deep features and refines alignment through a hybrid matching strategy. Specifically, we introduce the Feature Gradient Enhancer (FGE), which embeds multi-scale, multi-directional gradient filters into the feature space using attention and reconstruction mechanisms to boost feature distinctiveness. Furthermore, we propose the Global-Local Affine-Flow Matcher (GLAM), which combines affine transformation and flow-based refinement within a coarse-to-fine architecture to ensure both structural consistency and local accuracy. Experimental results demonstrate that SOMA significantly improves registration precision, increasing the CMR@1px by 12.29% on the SEN1-2 dataset and 18.50% on the GFGE_SO dataset. In addition, SOMA exhibits strong robustness and generalizes well across diverse scenes and resolutions.

</details>


### [182] [GeoX-Bench: Benchmarking Cross-View Geo-Localization and Pose Estimation Capabilities of Large Multimodal Models](https://arxiv.org/abs/2511.13259)
*Yushuo Zheng,Jiangyong Ying,Huiyu Duan,Chunyi Li,Zicheng Zhang,Jing Liu,Xiaohong Liu,Guangtao Zhai*

Main category: cs.CV

TL;DR: GeoX-Bench 是一个评估 LMMs 跨视角地理定位和姿态估计能力的基准，发现当前模型在地理定位中表现良好但在姿态估计中不足，指令调优可提升性能。


<details>
  <summary>Details</summary>
Motivation: 尽管 LMMs 在多种任务中表现卓越，但其在跨视角地理定位和姿态估计领域的知识与能力尚未得到充分探索，而这些能力对导航、自动驾驶、户外机器人等领域具有潜在价值。

Method: 研究者引入 GeoX-Bench，一个包含 10,859 对全景-卫星图像和 755,976 对问答对（其中 42,900 对用于基准测试）的综合性基准，用于评估 LMMs 在跨视角地理定位和姿态估计任务中的能力。

Result: 评估了 25 个先进 LMMs 的表现，发现其在跨视角地理定位任务中表现出色，但在姿态估计任务中效果显著下降。通过指令调优可显著提升模型性能。

Conclusion: GeoX-Bench 展示了当前大型多模态模型（LMMs）在跨视角地理定位任务中的出色表现，但在更复杂的姿态估计任务中表现显著下降，指出了未来改进的关键方向。通过指令调优可以显著提升 LMMs 的跨视角地理感知能力。

Abstract: Large multimodal models (LMMs) have demonstrated remarkable capabilities across a wide range of tasks, however their knowledge and abilities in the cross-view geo-localization and pose estimation domains remain unexplored, despite potential benefits for navigation, autonomous driving, outdoor robotics, \textit{etc}. To bridge this gap, we introduce \textbf{GeoX-Bench}, a comprehensive \underline{Bench}mark designed to explore and evaluate the capabilities of LMMs in \underline{cross}-view \underline{Geo}-localization and pose estimation. Specifically, GeoX-Bench contains 10,859 panoramic-satellite image pairs spanning 128 cities in 49 countries, along with corresponding 755,976 question-answering (QA) pairs. Among these, 42,900 QA pairs are designated for benchmarking, while the remaining are intended to enhance the capabilities of LMMs. Based on GeoX-Bench, we evaluate the capabilities of 25 state-of-the-art LMMs on cross-view geo-localization and pose estimation tasks, and further explore the empowered capabilities of instruction-tuning. Our benchmark demonstrate that while current LMMs achieve impressive performance in geo-localization tasks, their effectiveness declines significantly on the more complex pose estimation tasks, highlighting a critical area for future improvement, and instruction-tuning LMMs on the training data of GeoX-Bench can significantly improve the cross-view geo-sense abilities. The GeoX-Bench is available at \textcolor{magenta}{https://github.com/IntMeGroup/GeoX-Bench}.

</details>


### [183] [Enhancing Neuro-Oncology Through Self-Assessing Deep Learning Models for Brain Tumor Unified Model for MRI Segmentation](https://arxiv.org/abs/2511.12801)
*Andrew Zhou*

Main category: cs.CV

TL;DR: 该论文提出了一种不确定性感知的脑肿瘤分割方法，结合健康脑结构背景，通过单次推理提供不确定性估计，提升了临床实用性。


<details>
  <summary>Details</summary>
Motivation: 目前的方法缺乏对错误的不确定性估计，且未能在肿瘤分割中结合健康脑结构的解剖学背景，限制了临床应用的潜力。

Method: 研究在nnUNet基础上增加了一个通道用于体素级不确定性估计，并在BraTS2023数据集上训练。此外，通过结合正常和癌症数据集，构建了一个统一模型以提供全脑上下文信息。

Result: 模型在不确定性估计方面达到0.750的相关性和0.047的RMSD，且不影响肿瘤分割准确性。统一模型在脑结构分割中DSC为0.81，肿瘤分割为0.86。

Conclusion: 该研究提出了一种不确定性感知框架，结合了肿瘤分割与健康脑结构的解剖学背景，并通过单次推理提供体素级不确定性估计，有助于临床决策。

Abstract: Accurate segmentation of brain tumors is vital for diagnosis, surgical planning, and treatment monitoring. Deep learning has advanced on benchmarks, but two issues limit clinical use: no uncertainty estimates for errors and no segmentation of healthy brain structures around tumors for surgery. Current methods fail to unify tumor localization with anatomical context and lack confidence scores. This study presents an uncertainty-aware framework augmenting nnUNet with a channel for voxel-wise uncertainty. Trained on BraTS2023, it yields a correlation of 0.750 and RMSD of 0.047 for uncertainty without hurting tumor accuracy. It predicts uncertainty in one pass, with no extra networks or inferences, aiding clinical decisions. For whole-brain context, a unified model combines normal and cancer datasets, achieving a DSC of 0.81 for brain structures and 0.86 for tumor, with robust key-region performance. Combining both innovations gives the first model outputting tumor in natural surroundings plus an overlaid uncertainty map. Visual checks of outputs show uncertainty offers key insights to evaluate predictions and fix errors, helping informed surgical decisions from AI.

</details>


### [184] [Computer Vision based group activity detection and action spotting](https://arxiv.org/abs/2511.13315)
*Narthana Sivalingam,Santhirarajah Sivasthigan,Thamayanthi Mahendranathan,G. M. R. I. Godaliyadda,M. P. B. Ekanayake,H. M. V. R. Herath*

Main category: cs.CV

TL;DR: 本文提出了一种结合深度学习和图关系推理的计算机视觉框架，用于群体活动识别和动作检测，通过掩码特征细化和图神经网络显著提升了识别性能。


<details>
  <summary>Details</summary>
Motivation: 多人场景中的群体活动检测因复杂的人际互动、遮挡和外观随时间变化而具有挑战性。

Method: 该系统首先应用Mask R-CNN获取准确的演员定位，通过边界框和实例掩码。使用多种骨干网络（如Inception V3、MobileNet和VGG16）提取特征图，并应用RoIAlign保持空间对齐。掩码信息与特征图融合，获得每个演员的精细化掩码特征表示。为建模个体间交互，构建了演员关系图，编码外观相似性和位置关系，并使用图卷积网络预测个体动作和群体活动。

Result: 在Collective Activity数据集上的实验表明，基于掩码的特征细化、鲁棒的相似性搜索和图神经网络推理的组合，在拥挤和非拥挤场景中均提高了识别性能。

Conclusion: 该研究展示了将分割、特征提取和关系图推理相结合在复杂视频理解任务中的潜力。

Abstract: Group activity detection in multi-person scenes is challenging due to complex human interactions, occlusions, and variations in appearance over time. This work presents a computer vision based framework for group activity recognition and action spotting using a combination of deep learning models and graph based relational reasoning. The system first applies Mask R-CNN to obtain accurate actor localization through bounding boxes and instance masks. Multiple backbone networks, including Inception V3, MobileNet, and VGG16, are used to extract feature maps, and RoIAlign is applied to preserve spatial alignment when generating actor specific features. The mask information is then fused with the feature maps to obtain refined masked feature representations for each actor. To model interactions between individuals, we construct Actor Relation Graphs that encode appearance similarity and positional relations using methods such as normalized cross correlation, sum of absolute differences, and dot product. Graph Convolutional Networks operate on these graphs to reason about relationships and predict both individual actions and group level activities. Experiments on the Collective Activity dataset demonstrate that the combination of mask based feature refinement, robust similarity search, and graph neural network reasoning leads to improved recognition performance across both crowded and non crowded scenarios. This approach highlights the potential of integrating segmentation, feature extraction, and relational graph reasoning for complex video understanding tasks.

</details>


### [185] [View-aware Cross-modal Distillation for Multi-view Action Recognition](https://arxiv.org/abs/2511.12870)
*Trung Thanh Nguyen,Yasutomo Kawanishi,Vijay John,Takahiro Komamizu,Ichiro Ide*

Main category: cs.CV

TL;DR: ViCoKD通过跨模态知识蒸馏和视图一致性模块，有效解决部分重叠多视图动作识别问题，性能超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 部分重叠多视图设置中动作识别研究不足，且现实场景中多模态输入有限，需要从全监督多模态教师模型向受限学生模型蒸馏知识。

Method: 提出View-aware Cross-modal Knowledge Distillation (ViCoKD)框架，利用跨模态适配器和交叉注意力机制，以及View-aware Consistency模块处理视图不对齐问题。

Result: 在MultiSensor-Home数据集上，ViCoKD在多种骨干网络和环境中均优于现有蒸馏方法，性能显著提升。

Conclusion: ViCoKD框架在部分重叠多视图设置中显著优于现有方法，甚至在有限条件下超越教师模型，证明了其在多模态动作识别中的有效性。

Abstract: The widespread use of multi-sensor systems has increased research in multi-view action recognition. While existing approaches in multi-view setups with fully overlapping sensors benefit from consistent view coverage, partially overlapping settings where actions are visible in only a subset of views remain underexplored. This challenge becomes more severe in real-world scenarios, as many systems provide only limited input modalities and rely on sequence-level annotations instead of dense frame-level labels. In this study, we propose View-aware Cross-modal Knowledge Distillation (ViCoKD), a framework that distills knowledge from a fully supervised multi-modal teacher to a modality- and annotation-limited student. ViCoKD employs a cross-modal adapter with cross-modal attention, allowing the student to exploit multi-modal correlations while operating with incomplete modalities. Moreover, we propose a View-aware Consistency module to address view misalignment, where the same action may appear differently or only partially across viewpoints. It enforces prediction alignment when the action is co-visible across views, guided by human-detection masks and confidence-weighted Jensen-Shannon divergence between their predicted class distributions. Experiments on the real-world MultiSensor-Home dataset show that ViCoKD consistently outperforms competitive distillation methods across multiple backbones and environments, delivering significant gains and surpassing the teacher model under limited conditions.

</details>


### [186] [Semi-Supervised Multi-Task Learning for Interpretable Quality As- sessment of Fundus Images](https://arxiv.org/abs/2511.13353)
*Lucas Gabriel Telesco,Danila Nejamkin,Estefanía Mata,Francisco Filizzola,Kevin Wignall,Lucía Franco Troilo,María de los Angeles Cenoz,Melissa Thompson,Mercedes Leguía,Ignacio Larrabide,José Ignacio Orlando*

Main category: cs.CV

TL;DR: 通过半监督学习结合伪标签，提升视网膜图像质量评估的 interpretability 和性能，无需额外标注。


<details>
  <summary>Details</summary>
Motivation: 现有工具通常仅分类整体图像质量，缺乏对采集缺陷的指导性反馈，主要因为详细标注成本高昂。

Method: 采用混合半监督学习方法，结合整体质量的手动标签和质量细节的伪标签，在多任务框架中使用ResNet-18骨干网络进行模型微调。

Result: 多任务模型在EyeQ和DeepDRiD数据集上的性能优于单任务基线（F1: 0.875 vs. 0.863，0.778 vs. 0.763），并与专家标注结果相当。

Conclusion: 提出的半监督学习方法不仅提高了视网膜图像质量评估的整体性能，还提供了关于采集条件的可解释反馈，无需额外人工标注成本。

Abstract: Retinal image quality assessment (RIQA) supports computer-aided diagnosis of eye diseases. However, most tools classify only overall image quality, without indicating acquisition defects to guide recapture. This gap is mainly due to the high cost of detailed annotations. In this paper, we aim to mitigate this limitation by introducing a hybrid semi-supervised learning approach that combines manual labels for overall quality with pseudo-labels of quality details within a multi-task framework. Our objective is to obtain more interpretable RIQA models without requiring extensive manual labeling. Pseudo-labels are generated by a Teacher model trained on a small dataset and then used to fine-tune a pre-trained model in a multi-task setting. Using a ResNet-18 backbone, we show that these weak annotations improve quality assessment over single-task baselines (F1: 0.875 vs. 0.863 on EyeQ, and 0.778 vs. 0.763 on DeepDRiD), matching or surpassing existing methods. The multi-task model achieved performance statistically comparable to the Teacher for most detail prediction tasks (p > 0.05). In a newly annotated EyeQ subset released with this paper, our model performed similarly to experts, suggesting that pseudo-label noise aligns with expert variability. Our main finding is that the proposed semi-supervised approach not only improves overall quality assessment but also provides interpretable feedback on capture conditions (illumination, clarity, contrast). This enhances interpretability at no extra manual labeling cost and offers clinically actionable outputs to guide image recapture.

</details>


### [187] [Generalized Denoising Diffusion Codebook Models (gDDCM): Tokenizing images using a pre-trained diffusion model](https://arxiv.org/abs/2511.13387)
*Fei Kong*

Main category: cs.CV

TL;DR: gDDCM扩展了DDCM，使其适用于多种扩散模型，实验证明性能提升。


<details>
  <summary>Details</summary>
Motivation: DDCM无法应用于DDPM以外的其他方法，限制了其应用范围。

Method: 提出广义去噪扩散压缩模型（gDDCM），扩展DDCM至DDPM、Score-Based Models、Consistency Models和Rectified Flow等模型。

Result: 在CIFAR-10和LSUN Bedroom数据集上的实验结果表明，gDDCM成功泛化并提升了性能。

Conclusion: gDDCM成功将DDCM扩展至主流扩散模型及其变体，并在性能上有所提升。

Abstract: Recently, the Denoising Diffusion Codebook Models (DDCM) was proposed. DDCM leverages the Denoising Diffusion Probabilistic Model (DDPM) and replaces the random noise in the backward process with noise sampled from specific sets according to a predefined rule, thereby enabling image compression. However, DDCM cannot be applied to methods other than DDPM. In this paper, we propose the generalized Denoising Diffusion Compression Model (gDDCM), which extends DDCM to mainstream diffusion models and their variants, including DDPM, Score-Based Models, Consistency Models, and Rectified Flow. We evaluate our method on CIFAR-10 and LSUN Bedroom datasets. Experimental results demonstrate that our approach successfully generalizes DDCM to the aforementioned models and achieves improved performance.

</details>


### [188] [Simple Lines, Big Ideas: Towards Interpretable Assessment of Human Creativity from Drawings](https://arxiv.org/abs/2511.12880)
*Zihao Lin,Zhenshan Shi,Sasa Zhao,Hanwei Zhu,Lingyu Zhu,Baoliang Chen,Lei Mo*

Main category: cs.CV

TL;DR: 论文提出了一种自动评估绘画创造力的数据驱动框架，结合内容与风格维度，通过多任务学习实现高性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 当前创造力评估依赖专家主观评分，效率低且主观性强，因此需要一种自动、可解释的评估方法。

Method: 采用多模态、多任务学习框架，结合条件学习机制动态调整视觉特征提取，同时预测创造力分数、分类内容类型和提取风格特征。

Result: 实验表明，模型在性能上优于现有回归方法，并提供了与人类判断一致的可视化解释。

Conclusion: 论文提出了一种数据驱动的框架，通过多模态、多任务学习方法自动评估绘画的创造力，并在性能和可解释性上优于现有方法。

Abstract: Assessing human creativity through visual outputs, such as drawings, plays a critical role in fields including psychology, education, and cognitive science. However, current assessment practices still rely heavily on expert-based subjective scoring, which is both labor-intensive and inherently subjective. In this paper, we propose a data-driven framework for automatic and interpretable creativity assessment from drawings. Motivated by the cognitive understanding that creativity can emerge from both what is drawn (content) and how it is drawn (style), we reinterpret the creativity score as a function of these two complementary dimensions.Specifically, we first augment an existing creativity labeled dataset with additional annotations targeting content categories. Based on the enriched dataset, we further propose a multi-modal, multi-task learning framework that simultaneously predicts creativity scores, categorizes content types, and extracts stylistic features. In particular, we introduce a conditional learning mechanism that enables the model to adapt its visual feature extraction by dynamically tuning it to creativity-relevant signals conditioned on the drawing's stylistic and semantic cues.Experimental results demonstrate that our model achieves state-of-the-art performance compared to existing regression-based approaches and offers interpretable visualizations that align well with human judgments. The code and annotations will be made publicly available at https://github.com/WonderOfU9/CSCA_PRCV_2025

</details>


### [189] [Descriptor: Distance-Annotated Traffic Perception Question Answering (DTPQA)](https://arxiv.org/abs/2511.13397)
*Nikos Theodoridis,Tim Brophy,Reenu Mohandas,Ganesh Sistu,Fiachra Collins,Anthony Scanlan,Ciaran Eising*

Main category: cs.CV

TL;DR: 该论文介绍了一个名为DTPQA的视觉问答基准，专门用于评估视觉语言模型在交通场景中的感知能力，尤其是远距离物体的识别。数据集包括合成和真实两部分，并附有距离注释。


<details>
  <summary>Details</summary>
Motivation: 评估视觉语言模型在自动驾驶等安全关键领域的感知能力，尤其是在复杂交通场景和远距离物体识别中的表现。

Method: 开发了DTPQA基准，包含合成（DTP-Synthetic）和真实（DTP-Real）两部分数据集，每样本包含图像、问题、答案及物体距离注释。

Result: 提供了数据集及生成脚本，可用于分析模型性能随物体距离增加而下降的情况。

Conclusion: DTPQA为评估视觉语言模型在交通场景中的感知能力提供了有效工具，尤其关注远距离识别性能。

Abstract: The remarkable progress of Vision-Language Models (VLMs) on a variety of tasks has raised interest in their application to automated driving. However, for these models to be trusted in such a safety-critical domain, they must first possess robust perception capabilities, i.e., they must be capable of understanding a traffic scene, which can often be highly complex, with many things happening simultaneously. Moreover, since critical objects and agents in traffic scenes are often at long distances, we require systems with not only strong perception capabilities at close distances (up to 20 meters), but also at long (30+ meters) range. Therefore, it is important to evaluate the perception capabilities of these models in isolation from other skills like reasoning or advanced world knowledge. Distance-Annotated Traffic Perception Question Answering (DTPQA) is a Visual Question Answering (VQA) benchmark designed specifically for this purpose: it can be used to evaluate the perception systems of VLMs in traffic scenarios using trivial yet crucial questions relevant to driving decisions. It consists of two parts: a synthetic benchmark (DTP-Synthetic) created using a simulator, and a real-world benchmark (DTP-Real) built on top of existing images of real traffic scenes. Additionally, DTPQA includes distance annotations, i.e., how far the object in question is from the camera. More specifically, each DTPQA sample consists of (at least): (a) an image, (b) a question, (c) the ground truth answer, and (d) the distance of the object in question, enabling analysis of how VLM performance degrades with increasing object distance. In this article, we provide the dataset itself along with the Python scripts used to create it, which can be used to generate additional data of the same kind.

</details>


### [190] [ActVAR: Activating Mixtures of Weights and Tokens for Efficient Visual Autoregressive Generation](https://arxiv.org/abs/2511.12893)
*Kaixin Zhang,Ruiqing Yang,Yuan Zhang,Shan You,Tao Huang*

Main category: cs.CV

TL;DR: ActVAR是一种动态激活框架，通过双重稀疏性和两阶段知识蒸馏，在保持性能的同时显著减少计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有静态修剪方法通过永久移除权重或令牌会破坏预训练的依赖关系并降低性能，因此需要一种动态方法来提升效率而不牺牲模型容量。

Method: ActVAR将前馈网络（FFNs）分解为轻量级专家子网络，并采用可学习路由器动态选择基于内容的令牌特定专家子集；同时，通过门控令牌选择器识别高更新潜力令牌进行计算，并重建未选令牌以保留全局上下文和序列对齐。训练采用两阶段知识蒸馏策略，原始VAR模型监督路由和门控策略的学习以对齐预训练知识。

Result: 在ImageNet 256×256基准上，ActVAR实现了高达21.2%的FLOPs减少，且性能下降极小。

Conclusion: ActVAR通过动态激活框架在模型权重和令牌序列上引入双重稀疏性，有效提升了效率而不牺牲性能，实验表明在ImageNet 256×256基准上实现了高达21.2%的FLOPs减少且性能下降极小。

Abstract: Visual Autoregressive (VAR) models enable efficient image generation via next-scale prediction but face escalating computational costs as sequence length grows. Existing static pruning methods degrade performance by permanently removing weights or tokens, disrupting pretrained dependencies. To address this, we propose ActVAR, a dynamic activation framework that introduces dual sparsity across model weights and token sequences to enhance efficiency without sacrificing capacity. ActVAR decomposes feedforward networks (FFNs) into lightweight expert sub-networks and employs a learnable router to dynamically select token-specific expert subsets based on content. Simultaneously, a gated token selector identifies high-update-potential tokens for computation while reconstructing unselected tokens to preserve global context and sequence alignment. Training employs a two-stage knowledge distillation strategy, where the original VAR model supervises the learning of routing and gating policies to align with pretrained knowledge. Experiments on the ImageNet $256\times 256$ benchmark demonstrate that ActVAR achieves up to $21.2\%$ FLOPs reduction with minimal performance degradation.

</details>


### [191] [TripleFDS: Triple Feature Disentanglement and Synthesis for Scene Text Editing](https://arxiv.org/abs/2511.13399)
*Yuchen Bao,Yiting Wang,Wenjian Huang,Haowei Wang,Shen Chen,Taiping Yao,Shouhong Ding,Jianguo Zhang*

Main category: cs.CV

TL;DR: TripleFDS通过解耦模块化属性和SCB合成数据集，实现了对文本内容、样式和背景的灵活编辑，达到了最先进的图像保真度和文本准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在解耦可编辑属性方面存在不足，通常仅能处理单一属性（如文本内容编辑），导致控制性和视觉一致性受限。为了解决这些问题，提出了TripleFDS框架和SCB合成数据集。

Method: TripleFDS通过SCB Group构造解耦三重特征，利用组间对比正则化和组内多特征正交性确保语义准确性和减少冗余，在合成阶段通过特征重映射避免重建中的“捷径”现象和潜在特征泄漏。

Result: 在主流STE基准测试中，TripleFDS在125,000个SCB Groups上训练后，达到了44.54的SSIM和93.58%的ACC，支持样式替换和背景转移等新操作。

Conclusion: TripleFDS提出了一种新颖的场景文本编辑框架，通过解耦模块化属性和SCB合成数据集，实现了对文本内容、样式和背景的灵活控制，达到了最先进的图像保真度和文本准确性。

Abstract: Scene Text Editing (STE) aims to naturally modify text in images while preserving visual consistency, the decisive factors of which can be divided into three parts, i.e., text style, text content, and background. Previous methods have struggled with incomplete disentanglement of editable attributes, typically addressing only one aspect - such as editing text content - thus limiting controllability and visual consistency. To overcome these limitations, we propose TripleFDS, a novel framework for STE with disentangled modular attributes, and an accompanying dataset called SCB Synthesis. SCB Synthesis provides robust training data for triple feature disentanglement by utilizing the "SCB Group", a novel construct that combines three attributes per image to generate diverse, disentangled training groups. Leveraging this construct as a basic training unit, TripleFDS first disentangles triple features, ensuring semantic accuracy through inter-group contrastive regularization and reducing redundancy through intra-sample multi-feature orthogonality. In the synthesis phase, TripleFDS performs feature remapping to prevent "shortcut" phenomena during reconstruction and mitigate potential feature leakage. Trained on 125,000 SCB Groups, TripleFDS achieves state-of-the-art image fidelity (SSIM of 44.54) and text accuracy (ACC of 93.58%) on the mainstream STE benchmarks. Besides superior performance, the more flexible editing of TripleFDS supports new operations such as style replacement and background transfer. Code: https://github.com/yusenbao01/TripleFDS

</details>


### [192] [Reconstructing 3D Scenes in Native High Dynamic Range](https://arxiv.org/abs/2511.12895)
*Kaixuan Zhang,Minxian Li,Mingwu Ren,Jiankang Deng,Xiatian Zhu*

Main category: cs.CV

TL;DR: NH-3DGS是首个直接从原生HDR观测建模的3D场景重建方法，通过亮度-色度分解优化，显著提升了重建质量和动态范围保留。


<details>
  <summary>Details</summary>
Motivation: 现有的从LDR观察重建HDR场景的方法依赖于多曝光融合或逆色调映射，增加了捕获复杂性并依赖于合成监督，而原生HDR数据的直接捕获为3D重建提供了新的可能性。

Method: 提出了一种新颖的亮度-色度分解的颜色表示方法，支持直接从原生HDR相机数据进行优化。

Result: 在合成和真实多视角HDR数据集上的实验表明，NH-3DGS在重建质量和动态范围保留方面显著优于现有方法。

Conclusion: NH-3DGS通过在重建管道中保留完整的动态范围，显著提升了3D场景重建的质量和动态范围保留能力，为直接从原生HDR捕获进行专业级重建提供了可能。

Abstract: High Dynamic Range (HDR) imaging is essential for professional digital media creation, e.g., filmmaking, virtual production, and photorealistic rendering. However, 3D scene reconstruction has primarily focused on Low Dynamic Range (LDR) data, limiting its applicability to professional workflows. Existing approaches that reconstruct HDR scenes from LDR observations rely on multi-exposure fusion or inverse tone-mapping, which increase capture complexity and depend on synthetic supervision. With the recent emergence of cameras that directly capture native HDR data in a single exposure, we present the first method for 3D scene reconstruction that directly models native HDR observations. We propose {\bf Native High dynamic range 3D Gaussian Splatting (NH-3DGS)}, which preserves the full dynamic range throughout the reconstruction pipeline. Our key technical contribution is a novel luminance-chromaticity decomposition of the color representation that enables direct optimization from native HDR camera data. We demonstrate on both synthetic and real multi-view HDR datasets that NH-3DGS significantly outperforms existing methods in reconstruction quality and dynamic range preservation, enabling professional-grade 3D reconstruction directly from native HDR captures. Code and datasets will be made available.

</details>


### [193] [Unlocking the Forgery Detection Potential of Vanilla MLLMs: A Novel Training-Free Pipeline](https://arxiv.org/abs/2511.13442)
*Rui Zuo,Qinyue Tong,Zhe-Ming Lu,Ziqian Lu*

Main category: cs.CV

TL;DR: Foresee 是一种无需训练的多模态大语言模型管道，用于图像伪造分析，在定位准确性和解释性上表现优异，且泛化能力强。


<details>
  <summary>Details</summary>
Motivation: 由于现有图像伪造检测和定位方法难以泛化到不同数据集且解释性有限，而多模态大语言模型在视觉语言任务中展现出强大的泛化潜力，因此研究如何利用其潜力解决图像伪造问题。

Method: Foresee 采用类型先验驱动策略，并利用灵活特征检测器（FFD）模块专门处理复制-移动操作，从而有效释放了多模态大语言模型在法证领域的潜力。

Result: 实验表明，Foresee 在多种篡改类型（如复制-移动、拼接、移除、局部增强、深度伪造和基于AIGC的编辑）上均优于现有方法，同时提供更全面的文本解释。

Conclusion: Foresee 是一种无需训练的、基于多模态大语言模型的图像伪造分析流程，其在篡改定位准确性和文本解释丰富性上均优于现有方法，并展现出更强的泛化能力。

Abstract: With the rapid advancement of artificial intelligence-generated content (AIGC) technologies, including multimodal large language models (MLLMs) and diffusion models, image generation and manipulation have become remarkably effortless. Existing image forgery detection and localization (IFDL) methods often struggle to generalize across diverse datasets and offer limited interpretability. Nowadays, MLLMs demonstrate strong generalization potential across diverse vision-language tasks, and some studies introduce this capability to IFDL via large-scale training. However, such approaches cost considerable computational resources, while failing to reveal the inherent generalization potential of vanilla MLLMs to address this problem. Inspired by this observation, we propose Foresee, a training-free MLLM-based pipeline tailored for image forgery analysis. It eliminates the need for additional training and enables a lightweight inference process, while surpassing existing MLLM-based methods in both tamper localization accuracy and the richness of textual explanations. Foresee employs a type-prior-driven strategy and utilizes a Flexible Feature Detector (FFD) module to specifically handle copy-move manipulations, thereby effectively unleashing the potential of vanilla MLLMs in the forensic domain. Extensive experiments demonstrate that our approach simultaneously achieves superior localization accuracy and provides more comprehensive textual explanations. Moreover, Foresee exhibits stronger generalization capability, outperforming existing IFDL methods across various tampering types, including copy-move, splicing, removal, local enhancement, deepfake, and AIGC-based editing. The code will be released in the final version.

</details>


### [194] [FDP: A Frequency-Decomposition Preprocessing Pipeline for Unsupervised Anomaly Detection in Brain MRI](https://arxiv.org/abs/2511.12899)
*Hao Li,Zhenfeng Zhuang,Jingyu Lin,Yu Liu,Yifei Chen,Qiong Peng,Lequan Yu,Liansheng Wang*

Main category: cs.CV

TL;DR: FDP框架通过频域分解预处理提升脑MRI异常检测性能，DICE分数提高17.63%。


<details>
  <summary>Details</summary>
Motivation: 现有的无监督异常检测方法使用人工模拟的噪声扰动训练生成模型，但这些模拟异常缺乏真实临床病变的生物物理学保真度和形态复杂性。通过频域分析发现异常具有独特的频率模式，这为FDP框架提供了理论基础。

Method: 提出了Frequency-Decomposition Preprocessing (FDP)框架，利用频域重建同时抑制病理特征并保留正常解剖结构。

Result: 实验结果表明，FDP与现有方法集成时，异常检测性能显著提升，LDM模型的DICE分数提高了17.63%。

Conclusion: FDP框架通过频域分解预处理显著提升了脑MRI异常检测的性能，尤其在集成现有方法时表现突出，如LDM模型DICE分数提高了17.63%。

Abstract: Due to the diversity of brain anatomy and the scarcity of annotated data, supervised anomaly detection for brain MRI remains challenging, driving the development of unsupervised anomaly detection (UAD) approaches. Current UAD methods typically utilize artificially generated noise perturbations on healthy MRIs to train generative models for normal anatomy reconstruction, enabling anomaly detection via residual mapping. However, such simulated anomalies lack the biophysical fidelity and morphological complexity characteristic of true clinical lesions. To advance UAD in brain MRI, we conduct the first systematic frequency-domain analysis of pathological signatures, revealing two key properties: (1) anomalies exhibit unique frequency patterns distinguishable from normal anatomy, and (2) low-frequency signals maintain consistent representations across healthy scans. These insights motivate our Frequency-Decomposition Preprocessing (FDP) framework, the first UAD method to leverage frequency-domain reconstruction for simultaneous pathology suppression and anatomical preservation. FDP can integrate seamlessly with existing anomaly simulation techniques, consistently enhancing detection performance across diverse architectures while maintaining diagnostic fidelity. Experimental results demonstrate that FDP consistently improves anomaly detection performance when integrated with existing methods. Notably, FDP achieves a 17.63% increase in DICE score with LDM while maintaining robust improvements across multiple baselines. The code is available at https://github.com/ls1rius/MRI_FDP.

</details>


### [195] [Semantic Document Derendering: SVG Reconstruction via Vision-Language Modeling](https://arxiv.org/abs/2511.13478)
*Adam Hazimeh,Ke Wang,Mark Collier,Gilles Baechler,Efi Kokiopoulou,Pascal Frossard*

Main category: cs.CV

TL;DR: SliDer框架利用VLMs将栅格幻灯片转换为可编辑SVG，保留结构并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 静态栅格格式的多媒体文档限制了编辑和定制，现有方法无法保留高层次结构，导致语义信息丢失。

Method: 采用Vision-Language Models (VLMs)进行语义文档解析，通过迭代优化生成SVG代码，并引入Slide2SVG数据集支持研究。

Result: SliDer在重建LPIPS上达到0.069，82.9%的用户评价优于零-shot VLM基线。

Conclusion: SliDer框架通过结合视觉语言模型，成功地将静态栅格幻灯片转换为可编辑的SVG格式，保留了高层次结构，并在重建质量和用户体验上优于现有方法。

Abstract: Multimedia documents such as slide presentations and posters are designed to be interactive and easy to modify. Yet, they are often distributed in a static raster format, which limits editing and customization. Restoring their editability requires converting these raster images back into structured vector formats. However, existing geometric raster-vectorization methods, which rely on low-level primitives like curves and polygons, fall short at this task. Specifically, when applied to complex documents like slides, they fail to preserve the high-level structure, resulting in a flat collection of shapes where the semantic distinction between image and text elements is lost. To overcome this limitation, we address the problem of semantic document derendering by introducing SliDer, a novel framework that uses Vision-Language Models (VLMs) to derender slide images as compact and editable Scalable Vector Graphic (SVG) representations. SliDer detects and extracts attributes from individual image and text elements in a raster input and organizes them into a coherent SVG format. Crucially, the model iteratively refines its predictions during inference in a process analogous to human design, generating SVG code that more faithfully reconstructs the original raster upon rendering. Furthermore, we introduce Slide2SVG, a novel dataset comprising raster-SVG pairs of slide documents curated from real-world scientific presentations, to facilitate future research in this domain. Our results demonstrate that SliDer achieves a reconstruction LPIPS of 0.069 and is favored by human evaluators in 82.9% of cases compared to the strongest zero-shot VLM baseline.

</details>


### [196] [CASL: Curvature-Augmented Self-supervised Learning for 3D Anomaly Detection](https://arxiv.org/abs/2511.12909)
*Yaohua Zha,Xue Yuerong,Chunlin Fan,Yuansong Wang,Tao Dai,Ke Chen,Shu-Tao Xia*

Main category: cs.CV

TL;DR: 提出CASL框架，通过曲率提示的自监督学习提升3D异常检测性能，并展示良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在3D异常检测中要么专用性强泛化性差，要么自监督模型在该任务上表现不佳，因此需要一种更通用的模型。

Method: 基于重建范式，提出了一种曲率增强的自监督学习（CASL）框架，结合U-Net架构和多尺度曲率提示，指导解码器预测点的空间坐标。

Result: 仅使用曲率作为异常评分已超过多种经典方法，CASL框架在异常检测和3D理解任务中均取得领先性能。

Conclusion: CASL框架通过引入曲率提示的自监督学习方法，不仅提升了3D异常检测的性能，还能很好地泛化到其他3D理解任务中，展示了其通用性和高效性。

Abstract: Deep learning-based 3D anomaly detection methods have demonstrated significant potential in industrial manufacturing. However, many approaches are specifically designed for anomaly detection tasks, which limits their generalizability to other 3D understanding tasks. In contrast, self-supervised point cloud models aim for general-purpose representation learning, yet our investigation reveals that these classical models are suboptimal at anomaly detection under the unified fine-tuning paradigm. This motivates us to develop a more generalizable 3D model that can effectively detect anomalies without relying on task-specific designs. Interestingly, we find that using only the curvature of each point as its anomaly score already outperforms several classical self-supervised and dedicated anomaly detection models, highlighting the critical role of curvature in 3D anomaly detection. In this paper, we propose a Curvature-Augmented Self-supervised Learning (CASL) framework based on a reconstruction paradigm. Built upon the classical U-Net architecture, our approach introduces multi-scale curvature prompts to guide the decoder in predicting the spatial coordinates of each point. Without relying on any dedicated anomaly detection mechanisms, it achieves leading detection performance through straightforward anomaly classification fine-tuning. Moreover, the learned representations generalize well to standard 3D understanding tasks such as point cloud classification. The code is available at https://github.com/zyh16143998882/CASL.

</details>


### [197] [Robust Defense Strategies for Multimodal Contrastive Learning: Efficient Fine-tuning Against Backdoor Attacks](https://arxiv.org/abs/2511.13545)
*Md. Iqbal Hossain,Afia Sajeeda,Neeresh Kumar Perla,Ming Shao*

Main category: cs.CV

TL;DR: 该论文提出了一种新方法，通过图像分割‘oracle’和两种算法，有效识别并修复多模态模型中的后门攻击，实验证明其高效性。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态深度学习模型（如CLIP）易受后门攻击，且现有防御方法通常需要从头训练或使用大量数据进行微调，无法精确定位受影响的标签。

Method: 研究开发了两种算法：一是通过区分CLIP和Oracle的知识识别潜在触发器；二是精确定位受影响的标签和受害样本，并构建一个紧凑的微调数据集。

Result: 在视觉识别基准测试中，该方法在基于CLIP的后门防御方面表现出高效性。

Conclusion: 该研究提出了一种创新策略，通过引入图像分割‘oracle’作为监督者，有效识别并修复了多模态对比学习模型中的后门攻击，显著增强了模型的鲁棒性。

Abstract: The advent of multimodal deep learning models, such as CLIP, has unlocked new frontiers in a wide range of applications, from image-text understanding to classification tasks. However, these models are not safe for adversarial attacks, particularly backdoor attacks, which can subtly manipulate model behavior. Moreover, existing defense methods typically involve training from scratch or fine-tuning using a large dataset without pinpointing the specific labels that are affected. In this study, we introduce an innovative strategy to enhance the robustness of multimodal contrastive learning models against such attacks. In particular, given a poisoned CLIP model, our approach can identify the backdoor trigger and pinpoint the victim samples and labels in an efficient manner. To that end, an image segmentation ``oracle'' is introduced as the supervisor for the output of the poisoned CLIP. We develop two algorithms to rectify the poisoned model: (1) differentiating between CLIP and Oracle's knowledge to identify potential triggers; (2) pinpointing affected labels and victim samples, and curating a compact fine-tuning dataset. With this knowledge, we are allowed to rectify the poisoned CLIP model to negate backdoor effects. Extensive experiments on visual recognition benchmarks demonstrate our strategy is effective in CLIP-based backdoor defense.

</details>


### [198] [Explore How to Inject Beneficial Noise in MLLMs](https://arxiv.org/abs/2511.12917)
*Ruishu Zhu,Sida Huang,Ziheng Jiao,Hongyuan Zhang*

Main category: cs.CV

TL;DR: 提出多模态噪声生成器（MuNG），通过定制噪声提升MLLMs性能，实验显示优于全参数微调且参数效率高。


<details>
  <summary>Details</summary>
Motivation: 现有微调方法忽略跨模态异质性，限制了MLLMs的潜力，需提出更高效的微调策略。

Method: 从变分推理角度重新制定MLLMs的推理过程，设计动态分析跨模态关系的多模态噪声生成器（MuNG），生成任务自适应有益噪声。

Result: 在QwenVL和LLaVA上的实验表明，该方法优于全参数微调和其他现有方法，仅需调整约1~2%的额外参数。

Conclusion: 提出的多模态噪声生成器（MuNG）通过注入定制噪声有效提升了MLLMs的跨模态表示对齐和下游任务性能，且仅需调整少量参数。

Abstract: Multimodal Large Language Models (MLLMs) have played an increasingly important role in multimodal intelligence. However, the existing fine-tuning methods often ignore cross-modal heterogeneity, limiting their full potential. In this work, we propose a novel fine-tuning strategy by injecting beneficial random noise, which outperforms previous methods and even surpasses full fine-tuning, with minimal additional parameters. The proposed Multimodal Noise Generator (MuNG) enables efficient modality fine-tuning by injecting customized noise into the frozen MLLMs. Specifically, we reformulate the reasoning process of MLLMs from a variational inference perspective, upon which we design a multimodal noise generator that dynamically analyzes cross-modal relationships in image-text pairs to generate task-adaptive beneficial noise. Injecting this type of noise into the MLLMs effectively suppresses irrelevant semantic components, leading to significantly improved cross-modal representation alignment and enhanced performance on downstream tasks. Experiments on two mainstream MLLMs, QwenVL and LLaVA, demonstrate that our method surpasses full-parameter fine-tuning and other existing fine-tuning approaches, while requiring adjustments to only about $1\sim2\%$ additional parameters. The relevant code is uploaded in the supplementary.

</details>


### [199] [Hierarchical Prompt Learning for Image- and Text-Based Person Re-Identification](https://arxiv.org/abs/2511.13575)
*Linhan Zhou,Shuang Li,Neng Dong,Yonghang Tai,Yafei Zhang,Huafeng Li*

Main category: cs.CV

TL;DR: HPL框架通过分层提示学习联合优化图像到图像（I2I）和文本到图像（T2I）任务，解决了表示纠缠问题，并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法将I2I和T2I任务分开处理导致的表示纠缠和性能不佳问题。

Method: 提出了一种名为分层提示学习（HPL）的统一框架，通过任务感知提示建模联合优化I2I和T2I任务。具体包括任务路由Transformer、分层提示生成方案和跨模态提示正则化策略。

Result: 在多个ReID基准测试中，HPL框架在I2I和T2I任务上均取得了最先进的性能。

Conclusion: HPL框架通过在统一框架中联合优化I2I和T2I任务，解决了现有方法中表示纠缠和性能不佳的问题，并在多个ReID基准测试中取得了最先进的性能。

Abstract: Person re-identification (ReID) aims to retrieve target pedestrian images given either visual queries (image-to-image, I2I) or textual descriptions (text-to-image, T2I). Although both tasks share a common retrieval objective, they pose distinct challenges: I2I emphasizes discriminative identity learning, while T2I requires accurate cross-modal semantic alignment. Existing methods often treat these tasks separately, which may lead to representation entanglement and suboptimal performance. To address this, we propose a unified framework named Hierarchical Prompt Learning (HPL), which leverages task-aware prompt modeling to jointly optimize both tasks. Specifically, we first introduce a Task-Routed Transformer, which incorporates dual classification tokens into a shared visual encoder to route features for I2I and T2I branches respectively. On top of this, we develop a hierarchical prompt generation scheme that integrates identity-level learnable tokens with instance-level pseudo-text tokens. These pseudo-tokens are derived from image or text features via modality-specific inversion networks, injecting fine-grained, instance-specific semantics into the prompts. Furthermore, we propose a Cross-Modal Prompt Regularization strategy to enforce semantic alignment in the prompt token space, ensuring that pseudo-prompts preserve source-modality characteristics while enhancing cross-modal transferability. Extensive experiments on multiple ReID benchmarks validate the effectiveness of our method, achieving state-of-the-art performance on both I2I and T2I tasks.

</details>


### [200] [CoordAR: One-Reference 6D Pose Estimation of Novel Objects via Autoregressive Coordinate Map Generation](https://arxiv.org/abs/2511.12919)
*Dexin Zuo,Ang Li,Wei Wang,Wenxian Yu,Danping Zou*

Main category: cs.CV

TL;DR: CoordAR是一种自回归框架，通过离散化3D空间建模和模态解耦编码，显著提升了未见物体6D姿态估计的精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 减少对3D模型的依赖，解决现有方法在对称性和遮挡场景中的局限性。

Method: CoordAR采用自回归框架，将3D-3D对应关系建模为离散令牌图，并引入坐标图标记化、模态解耦编码策略和自回归变压器解码器。

Result: CoordAR在多个基准测试中显著优于现有方法，并在真实场景中表现出强鲁棒性。

Conclusion: CoordAR通过创新的自回归框架和离散化3D空间建模，显著提升了未见物体的6D姿态估计性能，特别是在对称性和遮挡等挑战性场景中表现出色。

Abstract: Object 6D pose estimation, a crucial task for robotics and augmented reality applications, becomes particularly challenging when dealing with novel objects whose 3D models are not readily available. To reduce dependency on 3D models, recent studies have explored one-reference-based pose estimation, which requires only a single reference view instead of a complete 3D model. However, existing methods that rely on real-valued coordinate regression suffer from limited global consistency due to the local nature of convolutional architectures and face challenges in symmetric or occluded scenarios owing to a lack of uncertainty modeling. We present CoordAR, a novel autoregressive framework for one-reference 6D pose estimation of unseen objects. CoordAR formulates 3D-3D correspondences between the reference and query views as a map of discrete tokens, which is obtained in an autoregressive and probabilistic manner. To enable accurate correspondence regression, CoordAR introduces 1) a novel coordinate map tokenization that enables probabilistic prediction over discretized 3D space; 2) a modality-decoupled encoding strategy that separately encodes RGB appearance and coordinate cues; and 3) an autoregressive transformer decoder conditioned on both position-aligned query features and the partially generated token sequence. With these novel mechanisms, CoordAR significantly outperforms existing methods on multiple benchmarks and demonstrates strong robustness to symmetry, occlusion, and other challenges in real-world tests.

</details>


### [201] [VVS: Accelerating Speculative Decoding for Visual Autoregressive Generation via Partial Verification Skipping](https://arxiv.org/abs/2511.13587)
*Haotian Dong,Ye Li,Rongwei Lu,Chen Tang,Shu-Tao Xia,Zhi Wang*

Main category: cs.CV

TL;DR: VVS框架通过动态选择跳过验证、特征缓存和细粒度调度，显著减少视觉AR模型的推理延迟，保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 视觉AR模型的推理延迟问题，以及现有推测解码（SD）范式无法直接减少前向传递次数的限制，促使探索验证跳过策略以显式减少延迟。

Method: 提出了VVS框架，包含三个模块：(1)动态截断的无验证令牌选择器，(2)令牌级特征缓存与重用，(3)细粒度的跳过步骤调度。

Result: VVS相对于传统AR解码减少了2.8倍的前向传递次数，同时保持生成质量，优于传统SD框架。

Conclusion: VVS框架通过部分验证跳过策略，将目标模型前向传递次数减少了2.8倍，同时保持了生成质量，为视觉AR模型提供了优越的速度-质量权衡。

Abstract: Visual autoregressive (AR) generation models have demonstrated strong potential for image generation, yet their next-token-prediction paradigm introduces considerable inference latency. Although speculative decoding (SD) has been proven effective for accelerating visual AR models, its "draft one step, then verify one step" paradigm prevents a direct reduction of the forward passes, thus restricting acceleration potential. Motivated by the visual token interchangeability, we for the first time to explore verification skipping in the SD process of visual AR model generation to explicitly cut the number of target model forward passes, thereby reducing inference latency. Based on an analysis of the drafting stage's characteristics, we observe that verification redundancy and stale feature reusability are key factors to retain generation quality and speedup for verification-free steps. Inspired by these two observations, we propose a novel SD framework VVS to accelerate visual AR generation via partial verification skipping, which integrates three complementary modules: (1) a verification-free token selector with dynamical truncation, (2) token-level feature caching and reuse, and (3) fine-grained skipped step scheduling. Consequently, VVS reduces the number of target model forward passes by a factor of $2.8\times$ relative to vanilla AR decoding while maintaining competitive generation quality, offering a superior speed-quality trade-off over conventional SD frameworks and revealing strong potential to reshape the SD paradigm.

</details>


### [202] [Generative Photographic Control for Scene-Consistent Video Cinematic Editing](https://arxiv.org/abs/2511.12921)
*Huiqiang Sun,Liao Shen,Zhan Peng,Kun Wang,Size Wu,Yuhang Zang,Tianqi Liu,Zihao Huang,Xingyu Zeng,Zhiguo Cao,Wei Li,Chen Change Loy*

Main category: cs.CV

TL;DR: CineCtrl 是首个提供专业相机参数精细控制的视频电影编辑框架，通过解耦机制和数据生成策略，实现了高质量视频效果。


<details>
  <summary>Details</summary>
Motivation: 现有生成视频模型大多仅限于相机运动控制，难以实现对摄影元素（如景深、曝光）的精细控制，这在电影叙事中至关重要。

Method: 提出了一种解耦的交叉注意力机制，将相机运动与摄影输入分离，并开发了模拟摄影效果和真实世界数据收集的综合数据生成策略。

Result: 实验表明，CineCtrl 能够生成高保真视频，并精确控制用户指定的摄影相机效果。

Conclusion: CineCtrl 是一个创新的视频电影编辑框架，通过解耦的交叉注意力机制和全面的数据生成策略，实现了对专业相机参数（如景深、快门速度）的精细控制，生成高质量的视频效果。

Abstract: Cinematic storytelling is profoundly shaped by the artful manipulation of photographic elements such as depth of field and exposure. These effects are crucial in conveying mood and creating aesthetic appeal. However, controlling these effects in generative video models remains highly challenging, as most existing methods are restricted to camera motion control. In this paper, we propose CineCtrl, the first video cinematic editing framework that provides fine control over professional camera parameters (e.g., bokeh, shutter speed). We introduce a decoupled cross-attention mechanism to disentangle camera motion from photographic inputs, allowing fine-grained, independent control without compromising scene consistency. To overcome the shortage of training data, we develop a comprehensive data generation strategy that leverages simulated photographic effects with a dedicated real-world collection pipeline, enabling the construction of a large-scale dataset for robust model training. Extensive experiments demonstrate that our model generates high-fidelity videos with precisely controlled, user-specified photographic camera effects.

</details>


### [203] [Alpha Divergence Losses for Biometric Verification](https://arxiv.org/abs/2511.13621)
*Dimitrios Koutsianos,Ladislav Mosner,Yannis Panagakis,Themos Stafylakis*

Main category: cs.CV

TL;DR: 论文提出两种基于$α$-散度的margin损失函数（Q-Margin和A3M），通过不同途径整合角度margin，显著提升了脸部和说话人验证性能，尤其适用于高安全性场景。


<details>
  <summary>Details</summary>
Motivation: 现有的$α$-散度损失函数在稀疏解方面表现优异，但整合角度margin（对验证任务至关重要）的方法不明确。

Method: 通过参考度量（先验概率）或对数几率（未归一化的对数似然）两种途径，整合了角度margin，提出了Q-Margin和A3M两种损失函数，并解决了A3M的训练不稳定性问题。

Result: 在IJB-B、IJB-C脸部验证和VoxCeleb说话人验证基准测试中，方法显著优于基线，尤其是在低FAR场景下。

Conclusion: 论文提出的两种基于$α$-散度的margin损失函数（Q-Margin和A3M）在脸部和说话人验证任务中表现优异，特别是在低误接受率（FAR）场景下，适用于高安全性应用。

Abstract: Performance in face and speaker verification is largely driven by margin based softmax losses like CosFace and ArcFace. Recently introduced $α$-divergence loss functions offer a compelling alternative, particularly for their ability to induce sparse solutions (when $α>1$). However, integrating an angular margin-crucial for verification tasks-is not straightforward. We find this integration can be achieved in at least two distinct ways: via the reference measure (prior probabilities) or via the logits (unnormalized log-likelihoods). In this paper, we explore both pathways, deriving two novel margin-based $α$-divergence losses: Q-Margin (margin in the reference measure) and A3M (margin in the logits). We identify and address a critical training instability in A3M-caused by the interplay of penalized logits and sparsity-with a simple yet effective prototype re-initialization strategy. Our methods achieve significant performance gains on the challenging IJB-B and IJB-C face verification benchmarks. We demonstrate similarly strong performance in speaker verification on VoxCeleb. Crucially, our models significantly outperform strong baselines at low false acceptance rates (FAR). This capability is crucial for practical high-security applications, such as banking authentication, when minimizing false authentications is paramount.

</details>


### [204] [Text2Traffic: A Text-to-Image Generation and Editing Method for Traffic Scenes](https://arxiv.org/abs/2511.12932)
*Feng Lv,Haoxuan Feng,Zilu Zhang,Chunlong Xia,Yanfeng Li*

Main category: cs.CV

TL;DR: A text-driven framework for traffic scene image generation and editing, using multi-view data and a two-stage training approach, achieves high fidelity and alignment with text descriptions.


<details>
  <summary>Details</summary>
Motivation: To overcome challenges in text-driven image generation and editing for traffic scenes, including insufficient semantic richness, limited viewpoints, low visual fidelity, and poor text-image alignment.

Method: A unified text-driven framework with a controllable mask mechanism, incorporating multi-view data and a two-stage training paradigm (conceptual learning followed by fine-tuning), along with a mask-region-weighted loss.

Result: Extensive experiments show that the proposed method outperforms existing approaches in generating and editing traffic scene images based on textual descriptions.

Conclusion: Our method achieves leading performance in text-based image generation and editing within traffic scenes, addressing key challenges such as semantic richness, viewpoint diversity, visual fidelity, and text-image alignment.

Abstract: With the rapid advancement of intelligent transportation systems, text-driven image generation and editing techniques have demonstrated significant potential in providing rich, controllable visual scene data for applications such as traffic monitoring and autonomous driving. However, several challenges remain, including insufficient semantic richness of generated traffic elements, limited camera viewpoints, low visual fidelity of synthesized images, and poor alignment between textual descriptions and generated content. To address these issues, we propose a unified text-driven framework for both image generation and editing, leveraging a controllable mask mechanism to seamlessly integrate the two tasks. Furthermore, we incorporate both vehicle-side and roadside multi-view data to enhance the geometric diversity of traffic scenes. Our training strategy follows a two-stage paradigm: first, we perform conceptual learning using large-scale coarse-grained text-image data; then, we fine-tune with fine-grained descriptive data to enhance text-image alignment and detail quality. Additionally, we introduce a mask-region-weighted loss that dynamically emphasizes small yet critical regions during training, thereby substantially enhancing the generation fidelity of small-scale traffic elements. Extensive experiments demonstrate that our method achieves leading performance in text-based image generation and editing within traffic scenes.

</details>


### [205] [ProtoAnomalyNCD: Prototype Learning for Multi-class Novel Anomaly Discovery in Industrial Scenarios](https://arxiv.org/abs/2511.12938)
*Botong Zhao,Qijun Shi,Shujing Lyu,Yue Lu*

Main category: cs.CV

TL;DR: ProtoAnomalyNCD通过原型学习和先验定位，实现了多类型异常发现与分类，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有工业异常检测方法仅能判断异常存在与否，无法发现和分类多种异常类型，且直接聚类方法效果不佳，需利用图像先验和改进方法。

Method: 结合Grounded SAM和文本提示定位对象区域作为异常分类网络的先验，引入Anomaly-Map-Guided Attention块，设计Region Guidance Factor以区分背景、对象和异常区域，通过对比学习增强异常特征。

Result: 在MVTec AD、MTD和Real-IAD数据集上表现优于现有方法。

Conclusion: ProtoAnomalyNCD通过原型学习框架成功发现并聚类了未见过的异常类别，同时实现了多类型异常分类，且在多个数据集上优于现有方法。

Abstract: Existing industrial anomaly detection methods mainly determine whether an anomaly is present. However, real-world applications also require discovering and classifying multiple anomaly types. Since industrial anomalies are semantically subtle and current methods do not sufficiently exploit image priors, direct clustering approaches often perform poorly. To address these challenges, we propose ProtoAnomalyNCD, a prototype-learning-based framework for discovering unseen anomaly classes of multiple types that can be integrated with various anomaly detection methods. First, to suppress background clutter, we leverage Grounded SAM with text prompts to localize object regions as priors for the anomaly classification network. Next, because anomalies usually appear as subtle and fine-grained patterns on the product, we introduce an Anomaly-Map-Guided Attention block. Within this block, we design a Region Guidance Factor that helps the attention module distinguish among background, object regions, and anomalous regions. By using both localized product regions and anomaly maps as priors, the module enhances anomalous features while suppressing background noise and preserving normal features for contrastive learning. Finally, under a unified prototype-learning framework, ProtoAnomalyNCD discovers and clusters unseen anomaly classes while simultaneously enabling multi-type anomaly classification. We further extend our method to detect unseen outliers, achieving task-level unification. Our method outperforms state-of-the-art approaches on the MVTec AD, MTD, and Real-IAD datasets.

</details>


### [206] [UnSAMv2: Self-Supervised Learning Enables Segment Anything at Any Granularity](https://arxiv.org/abs/2511.13714)
*Junwei Yu,Trevor Darrell,XuDong Wang*

Main category: cs.CV

TL;DR: UnSAMv2通过自监督学习和粒度控制嵌入，无需人工标注即可实现任意粒度分割，显著提升SAM-2性能。


<details>
  <summary>Details</summary>
Motivation: SAM家族在分割粒度控制方面存在局限性，用户需要手动调整才能达到理想的分割细节，且密集标注成本高昂，监督解决方案不可行。

Method: UnSAMv2扩展了UnSAM的分治策略，通过发现丰富的掩码-粒度对并引入粒度控制嵌入，实现了对分割尺度的精确连续控制。

Result: UnSAMv2仅需6K未标注图像和0.02%额外参数，显著提升了SAM-2在交互式、全图和视频分割任务中的性能，多项指标显著提升。

Conclusion: UnSAMv2通过引入粒度控制嵌入和自监督学习方法，显著提升了SAM-2的分割能力，实现了无需人工标注的任意粒度分割。

Abstract: The Segment Anything Model (SAM) family has become a widely adopted vision foundation model, but its ability to control segmentation granularity remains limited. Users often need to refine results manually - by adding more prompts or selecting from pre-generated masks - to achieve the desired level of detail. This process can be ambiguous, as the same prompt may correspond to several plausible masks, and collecting dense annotations across all granularities is prohibitively expensive, making supervised solutions infeasible. To address this limitation, we introduce UnSAMv2, which enables segment anything at any granularity without human annotations. UnSAMv2 extends the divide-and-conquer strategy of UnSAM by discovering abundant mask-granularity pairs and introducing a novel granularity control embedding that enables precise, continuous control over segmentation scale. Remarkably, with only $6$K unlabeled images and $0.02\%$ additional parameters, UnSAMv2 substantially enhances SAM-2, achieving segment anything at any granularity across interactive, whole-image, and video segmentation tasks. Evaluated on over $11$ benchmarks, UnSAMv2 improves $\text{NoC}_{90}$ (5.69 $\rightarrow$ 4.75), 1-IoU (58.0 $\rightarrow$ 73.1), and $\text{AR}_{1000}$ (49.6 $\rightarrow$ 68.3), showing that small amounts of unlabeled data with a granularity-aware self-supervised learning method can unlock the potential of vision foundation models.

</details>


### [207] [Semi-Supervised High Dynamic Range Image Reconstructing via Bi-Level Uncertain Area Masking](https://arxiv.org/abs/2511.12939)
*Wei Jiang,Jiahao Cui,Yizheng Wu,Zhan Peng,Zhiyu Pan,Zhiguo Cao*

Main category: cs.CV

TL;DR: 提出了一种半监督学习方法，通过不确定性掩蔽过程减少伪HDR地面真相中的偏差，仅用少量HDR地面真相即可达到全监督方法的性能。


<details>
  <summary>Details</summary>
Motivation: 由于LDR-HDR图像对难以获取，研究者需要探索如何在有限的HDR地面真相下实现可比的性能。

Method: 提出了一种基于不确定性的掩蔽过程，在像素和补丁级别上丢弃伪HDR地面真相中不可靠的部分，学生模型仅从可信区域学习。

Result: 该方法不仅优于之前的注释高效算法，而且仅使用6.7%的HDR地面真相即可达到与最新全监督方法相当的性能。

Conclusion: 该半监督学习方法通过不确定性掩蔽过程有效减少了伪高动态范围（HDR）地面真相中的偏差，仅使用6.7%的HDR地面真相即可达到与最新全监督方法相当的性能。

Abstract: Reconstructing high dynamic range (HDR) images from low dynamic range (LDR) bursts plays an essential role in the computational photography. Impressive progress has been achieved by learning-based algorithms which require LDR-HDR image pairs. However, these pairs are hard to obtain, which motivates researchers to delve into the problem of annotation-efficient HDR image reconstructing: how to achieve comparable performance with limited HDR ground truths (GTs). This work attempts to address this problem from the view of semi-supervised learning where a teacher model generates pseudo HDR GTs for the LDR samples without GTs and a student model learns from pseudo GTs. Nevertheless, the confirmation bias, i.e., the student may learn from the artifacts in pseudo HDR GTs, presents an impediment. To remove this impediment, an uncertainty-based masking process is proposed to discard unreliable parts of pseudo GTs at both pixel and patch levels, then the trusted areas can be learned from by the student. With this novel masking process, our semi-supervised HDR reconstructing method not only outperforms previous annotation-efficient algorithms, but also achieves comparable performance with up-to-date fully-supervised methods by using only 6.7% HDR GTs.

</details>


### [208] [Recurrent Autoregressive Diffusion: Global Memory Meets Local Attention](https://arxiv.org/abs/2511.12940)
*Taiye Chen,Zihan Ding,Anjian Li,Christina Zhang,Zeqi Xiao,Yisen Wang,Chi Jin*

Main category: cs.CV

TL;DR: 提出RAD框架，通过LSTM和注意力机制增强长视频生成的记忆保留能力，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有视频扩散模型因缺乏有效的内存压缩和检索机制，导致长视频生成中的遗忘和时空不一致问题。

Method: 在扩散变换器框架中引入RNN（LSTM与注意力机制），并提出RAD框架，实现训练和推理时一致的内存更新与检索。

Result: RAD框架在Memory Maze和Minecraft数据集上表现出色，LSTM在序列建模中展现出高效性。

Conclusion: 本文提出的RAD框架通过引入LSTM和注意力机制，有效解决了长视频生成中的遗忘和时空不一致问题，实验证明了其在Memory Maze和Minecraft数据集上的优越性。

Abstract: Recent advancements in video generation have demonstrated the potential of using video diffusion models as world models, with autoregressive generation of infinitely long videos through masked conditioning. However, such models, usually with local full attention, lack effective memory compression and retrieval for long-term generation beyond the window size, leading to issues of forgetting and spatiotemporal inconsistencies. To enhance the retention of historical information within a fixed memory budget, we introduce a recurrent neural network (RNN) into the diffusion transformer framework. Specifically, a diffusion model incorporating LSTM with attention achieves comparable performance to state-of-the-art RNN blocks, such as TTT and Mamba2. Moreover, existing diffusion-RNN approaches often suffer from performance degradation due to training-inference gap or the lack of overlap across windows. To address these limitations, we propose a novel Recurrent Autoregressive Diffusion (RAD) framework, which executes frame-wise autoregression for memory update and retrieval, consistently across training and inference time. Experiments on Memory Maze and Minecraft datasets demonstrate the superiority of RAD for long video generation, highlighting the efficiency of LSTM in sequence modeling.

</details>


### [209] [T2I-Based Physical-World Appearance Attack against Traffic Sign Recognition Systems in Autonomous Driving](https://arxiv.org/abs/2511.12956)
*Chen Ma,Ningfei Wang,Junhao Zheng,Qing Guo,Qian Wang,Qi Alfred Chen,Chao Shen*

Main category: cs.CV

TL;DR: DiffSign是一种新型T2I外观攻击框架，通过CLIP损失和屏蔽提示提升攻击效果，平均攻击成功率达83.3%，解决了现有方法的隐匿性和泛化性问题。


<details>
  <summary>Details</summary>
Motivation: 现有对抗性外观攻击存在明显的局限性，如像素级扰动方法缺乏隐匿性且易过拟合特定代理模型，而T2I扩散模型方法则在效果和泛化性上表现不佳。

Method: 提出了一种精心设计的攻击流程，结合了基于CLIP的损失和屏蔽提示，以提升攻击的专注性和可控性。此外，还提出了两种新颖的风格定制方法，以引导视觉外观并改善域外交通标志攻击的泛化性和隐匿性。

Result: 在多种真实世界条件下（包括不同距离、角度、光照条件和标志类别）进行的广泛评估表明，DiffSign的平均物理世界攻击成功率为83.3%，展现了其高有效性和可转移性。

Conclusion: DiffSign作为一种新颖的T2I外观攻击框架，成功解决了现有对抗性外观攻击的局限性，其在物理世界中的攻击成功率平均达到83.3%，展现了高有效性和可转移性。

Abstract: Traffic Sign Recognition (TSR) systems play a critical role in Autonomous Driving (AD) systems, enabling real-time detection of road signs, such as STOP and speed limit signs. While these systems are increasingly integrated into commercial vehicles, recent research has exposed their vulnerability to physical-world adversarial appearance attacks. In such attacks, carefully crafted visual patterns are misinterpreted by TSR models as legitimate traffic signs, while remaining inconspicuous or benign to human observers. However, existing adversarial appearance attacks suffer from notable limitations. Pixel-level perturbation-based methods often lack stealthiness and tend to overfit to specific surrogate models, resulting in poor transferability to real-world TSR systems. On the other hand, text-to-image (T2I) diffusion model-based approaches demonstrate limited effectiveness and poor generalization to out-of-distribution sign types.
  In this paper, we present DiffSign, a novel T2I-based appearance attack framework designed to generate physically robust, highly effective, transferable, practical, and stealthy appearance attacks against TSR systems. To overcome the limitations of prior approaches, we propose a carefully designed attack pipeline that integrates CLIP-based loss and masked prompts to improve attack focus and controllability. We also propose two novel style customization methods to guide visual appearance and improve out-of-domain traffic sign attack generalization and attack stealthiness. We conduct extensive evaluations of DiffSign under varied real-world conditions, including different distances, angles, light conditions, and sign categories. Our method achieves an average physical-world attack success rate of 83.3%, leveraging DiffSign's high effectiveness in attack transferability.

</details>


### [210] [GrOCE:Graph-Guided Online Concept Erasure for Text-to-Image Diffusion Models](https://arxiv.org/abs/2511.12968)
*Ning Han,Zhenyu Ge,Feng Han,Yuhua Sun,Chengqing Li,Jingjing Chen*

Main category: cs.CV

TL;DR: GrOCE 是一种无需训练的图引导概念擦除框架，通过动态语义图实现精准和自适应内容移除，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖昂贵的微调或粗糙语义分离，常导致无关概念退化且无法适应动态概念集，GrOCE 旨在解决这些问题。

Method: GrOCE 包含三个组件：(1) 动态拓扑图构建，(2) 自适应聚类识别，(3) 选择性边缘切断，通过图模型实现精细化概念隔离。

Result: 实验表明，GrOCE 在概念相似性（CS）和 Fréchet Inception Distance（FID）指标上达到了最先进性能。

Conclusion: GrOCE 提出了一种无需训练的框架，通过基于图的语义推理实现精确和自适应的概念擦除，显著提升了性能并避免了重新训练的需求。

Abstract: Concept erasure aims to remove harmful, inappropriate, or copyrighted content from text-to-image diffusion models while preserving non-target semantics. However, existing methods either rely on costly fine-tuning or apply coarse semantic separation, often degrading unrelated concepts and lacking adaptability to evolving concept sets. To alleviate this issue, we propose Graph-Guided Online Concept Erasure (GrOCE), a training-free framework that performs precise and adaptive concept removal through graph-based semantic reasoning. GrOCE models concepts and their interrelations as a dynamic semantic graph, enabling principled reasoning over dependencies and fine-grained isolation of undesired content. It comprises three components: (1) Dynamic Topological Graph Construction for incremental graph building, (2) Adaptive Cluster Identification for multi-hop traversal with similarity-decay scoring, and (3) Selective Edge Severing for targeted edge removal while preserving global semantics. Extensive experiments demonstrate that GrOCE achieves state-of-the-art performance on Concept Similarity (CS) and Fréchet Inception Distance (FID) metrics, offering efficient, accurate, and stable concept erasure without retraining.

</details>


### [211] [HiFusion: Hierarchical Intra-Spot Alignment and Regional Context Fusion for Spatial Gene Expression Prediction from Histopathology](https://arxiv.org/abs/2511.12969)
*Ziqiao Weng,Yaoyu Fang,Jiahe Qian,Xinkun Wang,Lee AD Cooper,Weidong Cai,Bo Zhou*

Main category: cs.CV

TL;DR: HiFusion 是一种新型深度学习框架，通过分层内部斑点建模和上下文感知跨尺度融合，显著提升了从 H&E 染色切片预测基因表达的准确性，并在实验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以捕捉斑点内的复杂生物异质性，并在整合周围组织的上下文信息时容易受到形态学噪声的影响。因此，需要一种能够全面建模细胞级特征和组织微环境线索的新方法。

Method: HiFusion 是一种新颖的深度学习框架，包含两个互补组件：分层内部斑点建模模块用于提取细粒度形态学表征，以及上下文感知跨尺度融合模块用于选择性整合生物相关的区域上下文信息。

Result: 在两个基准 ST 数据集上的广泛实验表明，HiFusion 在 2D 幻灯片级交叉验证和更具挑战性的 3D 样本特定场景中均达到了最先进的性能。

Conclusion: HiFusion 作为一种稳健、准确且可扩展的解决方案，展示了从常规组织病理学中进行空间转录组学推断的巨大潜力。

Abstract: Spatial transcriptomics (ST) bridges gene expression and tissue morphology but faces clinical adoption barriers due to technical complexity and prohibitive costs. While computational methods predict gene expression from H&E-stained whole-slide images (WSIs), existing approaches often fail to capture the intricate biological heterogeneity within spots and are susceptible to morphological noise when integrating contextual information from surrounding tissue. To overcome these limitations, we propose HiFusion, a novel deep learning framework that integrates two complementary components. First, we introduce the Hierarchical Intra-Spot Modeling module that extracts fine-grained morphological representations through multi-resolution sub-patch decomposition, guided by a feature alignment loss to ensure semantic consistency across scales. Concurrently, we present the Context-aware Cross-scale Fusion module, which employs cross-attention to selectively incorporate biologically relevant regional context, thereby enhancing representational capacity. This architecture enables comprehensive modeling of both cellular-level features and tissue microenvironmental cues, which are essential for accurate gene expression prediction. Extensive experiments on two benchmark ST datasets demonstrate that HiFusion achieves state-of-the-art performance across both 2D slide-wise cross-validation and more challenging 3D sample-specific scenarios. These results underscore HiFusion's potential as a robust, accurate, and scalable solution for ST inference from routine histopathology.

</details>


### [212] [MCAQ-YOLO: Morphological Complexity-Aware Quantization for Efficient Object Detection with Curriculum Learning](https://arxiv.org/abs/2511.12976)
*Yoonjae Seo,Ermal Elbasani,Jaehong Lee*

Main category: cs.CV

TL;DR: MCAQ-YOLO通过形态复杂性感知的量化框架，动态调整比特精度，显著提升了目标检测的准确率和效率。


<details>
  <summary>Details</summary>
Motivation: 现有神经网络量化方法通常采用统一的比特精度，忽略了视觉数据的异质结构和纹理复杂性，导致量化效果不佳。

Method: 采用五种形态学指标（分形维度、纹理熵、梯度方差、边缘密度和轮廓复杂度）来表征局部视觉形态，并指导空间自适应的比特分配。结合基于课程的量化感知训练方案，逐步增加量化难度以稳定优化并加速收敛。

Result: 在安全设备数据集上，MCAQ-YOLO达到85.6%的mAP@0.5，平均比特数为4.2，压缩比为7.6倍，比统一4比特量化高3.5个百分点，且每张图像仅增加1.8毫秒的运行时间。在COCO和Pascal VOC上的跨数据集验证也显示了一致的性能提升。

Conclusion: MCAQ-YOLO通过形态复杂性感知的量化框架，在目标检测任务中实现了更高的准确率和收敛效率，同时保持了较低的计算开销。跨数据集验证进一步证明了其鲁棒性和通用性。

Abstract: Most neural network quantization methods apply uniform bit precision across spatial regions, ignoring the heterogeneous structural and textural complexity of visual data. This paper introduces MCAQ-YOLO, a morphological complexity-aware quantization framework for object detection. The framework employs five morphological metrics - fractal dimension, texture entropy, gradient variance, edge density, and contour complexity - to characterize local visual morphology and guide spatially adaptive bit allocation. By correlating these metrics with quantization sensitivity, MCAQ-YOLO dynamically adjusts bit precision according to spatial complexity. In addition, a curriculum-based quantization-aware training scheme progressively increases quantization difficulty to stabilize optimization and accelerate convergence. Experimental results demonstrate a strong correlation between morphological complexity and quantization sensitivity and show that MCAQ-YOLO achieves superior detection accuracy and convergence efficiency compared with uniform quantization. On a safety equipment dataset, MCAQ-YOLO attains 85.6 percent mAP@0.5 with an average of 4.2 bits and a 7.6x compression ratio, yielding 3.5 percentage points higher mAP than uniform 4-bit quantization while introducing only 1.8 ms of additional runtime overhead per image. Cross-dataset validation on COCO and Pascal VOC further confirms consistent performance gains, indicating that morphology-driven spatial quantization can enhance efficiency and robustness for computationally constrained, safety-critical visual recognition tasks.

</details>


### [213] [ArtiWorld: LLM-Driven Articulation of 3D Objects in Scenes](https://arxiv.org/abs/2511.12977)
*Yixuan Yang,Luyang Xie,Zhen Luo,Zixiang Zhao,Mingqi Gao,Feng Zheng*

Main category: cs.CV

TL;DR: ArtiWorld通过自动化流程将刚性3D资产转换为交互式URDF关节对象，优于现有方法，适用于模拟和真实场景。


<details>
  <summary>Details</summary>
Motivation: 现有3D资产多为刚性，手动转换为关节对象成本高，需自动化解决方案。

Method: ArtiWorld利用3D点云、大型语言模型（LLM）先验知识和URDF导向提示设计，快速将刚性对象转换为交互式URDF关节对象。

Result: 在3D模拟对象、完整3D模拟场景和真实扫描场景中，ArtiWorld均表现优异，保持几何形状并正确捕捉交互性。

Conclusion: ArtiWorld提供了一种实用方法，直接从现有3D资产构建交互式、机器人就绪的模拟环境，显著优于现有方法。

Abstract: Building interactive simulators and scalable robot-learning environments requires a large number of articulated assets. However, most existing 3D assets in simulation are rigid, and manually converting them into articulated objects is extremely labor- and cost-intensive. This raises a natural question: can we automatically identify articulable objects in a scene and convert them into articulated assets directly? In this paper, we present ArtiWorld, a scene-aware pipeline that localizes candidate articulable objects from textual scene descriptions and reconstructs executable URDF models that preserve the original geometry. At the core of this pipeline is Arti4URDF, which leverages 3D point cloud, prior knowledge of a large language model (LLM), and a URDF-oriented prompt design to rapidly convert rigid objects into interactive URDF-based articulated objects while maintaining their 3D shape. We evaluate ArtiWorld at three levels: 3D simulated objects, full 3D simulated scenes, and real-world scan scenes. Across all three settings, our method consistently outperforms existing approaches and achieves state-of-the-art performance, while preserving object geometry and correctly capturing object interactivity to produce usable URDF-based articulated models. This provides a practical path toward building interactive, robot-ready simulation environments directly from existing 3D assets. Code and data will be released.

</details>


### [214] [Concept Regions Matter: Benchmarking CLIP with a New Cluster-Importance Approach](https://arxiv.org/abs/2511.12978)
*Aishwarya Agarwal,Srikrishna Karanam,Vineet Gandhi*

Main category: cs.CV

TL;DR: CCI是一种新方法，通过聚类和掩码技术提升CLIP模型的鲁棒性，在多个基准测试中表现优异，并揭示了现有评估方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（如CLIP）在零样本识别中表现优异，但对虚假相关性（如背景过度依赖）敏感。需要一种新的解释性方法来评估和改进模型的鲁棒性。

Method: 提出了基于聚类的概念重要性（CCI）方法，利用CLIP的patch嵌入将空间patch分组为语义连贯的簇，并通过掩码评估预测变化。结合GroundedSAM，自动分类预测为前景或背景驱动。

Result: CCI在忠实性基准测试中刷新了记录，如在MS COCO检索的删除-AUC指标上提升超过两倍。通过COVAR基准测试，揭示了现有基准的不足，并系统性评估了18种CLIP变体。

Conclusion: CCI方法在提升视觉语言模型的鲁棒性方面表现卓越，尤其在区分前景与背景驱动预测上提供了关键诊断能力。通过COVAR基准测试，研究还揭示了现有基准的局限性，为未来更稳健的模型开发指明了方向。

Abstract: Contrastive vision-language models (VLMs) such as CLIP achieve strong zero-shot recognition yet remain vulnerable to spurious correlations, particularly background over-reliance. We introduce Cluster-based Concept Importance (CCI), a novel interpretability method that uses CLIP's own patch embeddings to group spatial patches into semantically coherent clusters, mask them, and evaluate relative changes in model predictions. CCI sets a new state of the art on faithfulness benchmarks, surpassing prior methods by large margins; for example, it yields more than a twofold improvement on the deletion-AUC metric for MS COCO retrieval. We further propose that CCI, when combined with GroundedSAM, automatically categorizes predictions as foreground- or background-driven, providing a crucial diagnostic ability. Existing benchmarks such as CounterAnimals, however, rely solely on accuracy and implicitly attribute all performance degradation to background correlations. Our analysis shows this assumption to be incomplete, since many errors arise from viewpoint variation, scale shifts, and fine-grained object confusions. To disentangle these effects, we introduce COVAR, a benchmark that systematically varies object foregrounds and backgrounds. Leveraging CCI with COVAR, we present a comprehensive evaluation of eighteen CLIP variants, offering methodological advances and empirical evidence that chart a path toward more robust VLMs.

</details>


### [215] [Semantic Prioritization in Visual Counterfactual Explanations with Weighted Segmentation and Auto-Adaptive Region Selection](https://arxiv.org/abs/2511.12992)
*Lintong Zhang,Kang Yin,Seong-Whan Lee*

Main category: cs.CV

TL;DR: WSAE-Net通过加权语义图和自适应候选编辑序列，优化非生成式视觉反事实解释的语义相关性和计算效率，实验证明其性能优越。


<details>
  <summary>Details</summary>
Motivation: 传统的非生成式视觉反事实解释技术常忽视替换区域与目标对象的语义相关性，损害模型的可解释性并阻碍编辑工作流。本研究旨在解决这些问题。

Method: WSAE-Net方法包含两个关键创新：加权语义图的生成和自适应候选编辑序列的确定。加权语义图旨在最大化减少需要计算的非语义特征单元，优化计算效率；自适应候选编辑序列则确定最优的计算顺序，确保反事实的高效生成同时保持替换特征单元与目标对象的语义相关性。

Result: 通过全面实验，WSAE-Net方法展现出卓越性能，有效提升了视觉反事实解释的清晰度和深度理解。

Conclusion: 本研究提出的WSAE-Net方法通过加权语义图和自适应候选编辑序列，显著提升了非生成式视觉反事实解释的语义相关性和计算效率，为模型解释和编辑工作流提供了更清晰和深入的理解。

Abstract: In the domain of non-generative visual counterfactual explanations (CE), traditional techniques frequently involve the substitution of sections within a query image with corresponding sections from distractor images. Such methods have historically overlooked the semantic relevance of the replacement regions to the target object, thereby impairing the model's interpretability and hindering the editing workflow. Addressing these challenges, the present study introduces an innovative methodology named as Weighted Semantic Map with Auto-adaptive Candidate Editing Network (WSAE-Net). Characterized by two significant advancements: the determination of an weighted semantic map and the auto-adaptive candidate editing sequence. First, the generation of the weighted semantic map is designed to maximize the reduction of non-semantic feature units that need to be computed, thereby optimizing computational efficiency. Second, the auto-adaptive candidate editing sequences are designed to determine the optimal computational order among the feature units to be processed, thereby ensuring the efficient generation of counterfactuals while maintaining the semantic relevance of the replacement feature units to the target object. Through comprehensive experimentation, our methodology demonstrates superior performance, contributing to a more lucid and in-depth understanding of visual counterfactual explanations.

</details>


### [216] [PerTouch: VLM-Driven Agent for Personalized and Semantic Image Retouching](https://arxiv.org/abs/2511.12998)
*Zewei Chang,Zheng-Peng Duan,Jianxing Zhang,Chun-Le Guo,Siyu Liu,Hyungju Chun,Hyunhee Park,Zikun Liu,Chongyi Li*

Main category: cs.CV

TL;DR: PerTouch是一个基于扩散的语义级图像修饰框架，通过参数映射和VLM代理实现用户意图对齐，实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 解决图像修饰中控制性与主观性的平衡问题，满足用户个性化审美需求。

Method: 提出PerTouch框架，利用参数映射实现细粒度图像修饰，引入语义替换和参数扰动机制增强语义边界感知，开发VLM驱动代理处理用户指令。

Result: 实验证明各组件有效性，PerTouch在个性化图像修饰中表现优异。

Conclusion: PerTouch通过统一的扩散框架实现了语义级图像修饰，结合VLM驱动代理和反馈机制，显著提升了用户意图对齐和个性化修饰效果。

Abstract: Image retouching aims to enhance visual quality while aligning with users' personalized aesthetic preferences. To address the challenge of balancing controllability and subjectivity, we propose a unified diffusion-based image retouching framework called PerTouch. Our method supports semantic-level image retouching while maintaining global aesthetics. Using parameter maps containing attribute values in specific semantic regions as input, PerTouch constructs an explicit parameter-to-image mapping for fine-grained image retouching. To improve semantic boundary perception, we introduce semantic replacement and parameter perturbation mechanisms in the training process. To connect natural language instructions with visual control, we develop a VLM-driven agent that can handle both strong and weak user instructions. Equipped with mechanisms of feedback-driven rethinking and scene-aware memory, PerTouch better aligns with user intent and captures long-term preferences. Extensive experiments demonstrate each component's effectiveness and the superior performance of PerTouch in personalized image retouching. Code is available at: https://github.com/Auroral703/PerTouch.

</details>


### [217] [Medal S: Spatio-Textual Prompt Model for Medical Segmentation](https://arxiv.org/abs/2511.13001)
*Pengcheng Shi,Jiawei Chen,Jiaqi Liu,Xinglin Zhang,Tao Chen,Lei Li*

Main category: cs.CV

TL;DR: Medal S是一款支持空间和文本提示的医学分割基础模型，通过并行处理和动态优化技术，在多模态数据上实现了高效精准的分割。


<details>
  <summary>Details</summary>
Motivation: 解决现有文本提示方法缺乏空间感知能力的问题，通过通道对齐和全3D上下文保留，提升多类别医学分割的准确性和效率。

Method: 采用轻量级3D卷积模块进行体素空间细化，支持并行处理多类别分割任务，并提出动态重采样、两阶段推理策略和后处理技术以优化性能。

Result: 在BiomedSegFM数据集的五种模态验证集上，Medal S的DSC、NSD、F1和DSC TP指标均显著优于SAT和nnU-Net。

Conclusion: Medal S通过结合空间精度与语义文本指导，在多类别医学分割任务中展现出卓越的效率和准确性，显著优于传统的序列提示方法。

Abstract: We introduce Medal S, a medical segmentation foundation model that supports native-resolution spatial and textual prompts within an end-to-end trainable framework. Unlike text-only methods lacking spatial awareness, Medal S achieves channel-wise alignment between volumetric prompts and text embeddings, mitigating inaccuracies from resolution mismatches. By preserving full 3D context, it efficiently processes multiple native-resolution masks in parallel, enhancing multi-class segmentation performance. A lightweight 3D convolutional module enables precise voxel-space refinement guided by both prompt types, supporting up to 243 classes across CT, MRI, PET, ultrasound, and microscopy modalities in the BiomedSegFM dataset. Medal S offers two prompting modes: a text-only mode, where model predictions serve as spatial prompts for self-refinement without human input, and a hybrid mode, incorporating manual annotations for enhanced flexibility. For 24-class segmentation, parallel spatial prompting reduces inference time by more than 90% compared to sequential prompting. We propose dynamic resampling to address target-patch ratio imbalance, extending SAT and nnU-Net for data augmentation. Furthermore, we develop optimized text preprocessing, a two-stage inference strategy, and post-processing techniques to improve memory efficiency, precision, and inference speed. On the five-modality average on the validation set, Medal S outperforms SAT with a DSC of 75.44 (vs. 69.83), NSD of 77.34 (vs. 71.06), F1 of 38.24 (vs. 24.88), and DSC TP of 65.46 (vs. 46.97). Medal S achieves excellent performance by harmonizing spatial precision with semantic textual guidance, demonstrating superior efficiency and accuracy in multi-class medical segmentation tasks compared to sequential prompt-based approaches. Medal S will be publicly available at https://github.com/yinghemedical/Medal-S.

</details>


### [218] [Infinite-Story: A Training-Free Consistent Text-to-Image Generation](https://arxiv.org/abs/2511.13002)
*Jihun Park,Kyoungmin Lee,Jongmin Gim,Hyeonseo Jo,Minseok Oh,Wonhyeok Choi,Kyumin Hwang,Jaeyeul Kim,Minwoo Choi,Sunghoon Im*

Main category: cs.CV

TL;DR: Infinite-Story 是一种无需训练的文本到图像生成框架，通过创新技术解决了身份和风格一致性问题，实验显示其高效且实用。


<details>
  <summary>Details</summary>
Motivation: 针对文本到图像生成中的身份不一致和风格不一致问题，提出了一种无需微调、推理速度快的方法，适用于实际视觉叙事需求。

Method: 结合了三种互补技术：身份提示替换（Identity Prompt Replacement）以对齐身份属性，以及统一的注意力引导机制（Adaptive Style Injection 和 Synchronized Guidance Adaptation）来保持全局风格和身份一致性，同时确保提示的忠实度。

Result: 实验表明，该方法在生成性能上达到最先进水平，且推理速度比现有最快模型快6倍（每张图像1.72秒），具有显著的实践优势。

Conclusion: Infinite-Story 是一种无需训练的文本到图像生成框架，专注于多提示故事场景中的一致性问题，通过创新技术解决了身份和风格不一致的挑战，并在实验中展现了高效和实用性。

Abstract: We present Infinite-Story, a training-free framework for consistent text-to-image (T2I) generation tailored for multi-prompt storytelling scenarios. Built upon a scale-wise autoregressive model, our method addresses two key challenges in consistent T2I generation: identity inconsistency and style inconsistency. To overcome these issues, we introduce three complementary techniques: Identity Prompt Replacement, which mitigates context bias in text encoders to align identity attributes across prompts; and a unified attention guidance mechanism comprising Adaptive Style Injection and Synchronized Guidance Adaptation, which jointly enforce global style and identity appearance consistency while preserving prompt fidelity. Unlike prior diffusion-based approaches that require fine-tuning or suffer from slow inference, Infinite-Story operates entirely at test time, delivering high identity and style consistency across diverse prompts. Extensive experiments demonstrate that our method achieves state-of-the-art generation performance, while offering over 6X faster inference (1.72 seconds per image) than the existing fastest consistent T2I models, highlighting its effectiveness and practicality for real-world visual storytelling.

</details>


### [219] [Beyond Darkness: Thermal-Supervised 3D Gaussian Splatting for Low-Light Novel View Synthesis](https://arxiv.org/abs/2511.13011)
*Qingsen Ma,Chen Zou,Dianyun Wang,Jia Wang,Liuyu Xiang,Zhaofeng He*

Main category: cs.CV

TL;DR: DTGS结合Retinex和热引导的3D高斯泼溅，解决了极低光下的新视角合成问题，通过联合优化和循环机制提升了性能。


<details>
  <summary>Details</summary>
Motivation: 极低光条件下，标准3D高斯泼溅（3DGS）在新视角合成中表现不佳，导致几何和色彩一致性严重退化。现有方法将增强作为预处理步骤，导致光照不一致和几何失真。

Method: DTGS采用循环增强-重建机制，通过热监督分支动态平衡增强、结构和热损失，同时在3DGS循环中嵌入基于Retinex的分解模块，实现物理可解释的反射-光照分离。

Result: 在新建的RGBT-LOW数据集上，DTGS显著优于现有低光增强和3D重建基线方法，实现了在极端光照条件下的卓越性能。

Conclusion: DTGS通过将Retinex启发的光照分解与热引导的3D高斯泼溅紧密结合，实现了在极低光条件下的高质量新视角合成，显著提升了辐射一致性、几何保真度和色彩稳定性。

Abstract: Under extremely low-light conditions, novel view synthesis (NVS) faces severe degradation in terms of geometry, color consistency, and radiometric stability. Standard 3D Gaussian Splatting (3DGS) pipelines fail when applied directly to underexposed inputs, as independent enhancement across views causes illumination inconsistencies and geometric distortion. To address this, we present DTGS, a unified framework that tightly couples Retinex-inspired illumination decomposition with thermal-guided 3D Gaussian Splatting for illumination-invariant reconstruction. Unlike prior approaches that treat enhancement as a pre-processing step, DTGS performs joint optimization across enhancement, geometry, and thermal supervision through a cyclic enhancement-reconstruction mechanism. A thermal supervisory branch stabilizes both color restoration and geometry learning by dynamically balancing enhancement, structural, and thermal losses. Moreover, a Retinex-based decomposition module embedded within the 3DGS loop provides physically interpretable reflectance-illumination separation, ensuring consistent color and texture across viewpoints. To evaluate our method, we construct RGBT-LOW, a new multi-view low-light thermal dataset capturing severe illumination degradation. Extensive experiments show that DTGS significantly outperforms existing low-light enhancement and 3D reconstruction baselines, achieving superior radiometric consistency, geometric fidelity, and color stability under extreme illumination.

</details>


### [220] [You Only Look Omni Gradient Backpropagation for Moving Infrared Small Target Detection](https://arxiv.org/abs/2511.13013)
*Guoyi Zhang,Guangsheng Xu,Siyang Chen,Han Wang,Xiaohu Zhang*

Main category: cs.CV

TL;DR: BP-FPN通过反向传播驱动的特征金字塔架构，解决了红外小目标检测中的特征表示问题，性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在时空特征聚合上的增益有限，根本瓶颈在于单帧特征表示模糊，而非时空建模本身。

Method: 提出了BP-FPN架构，包含梯度隔离的低级快捷路径（GILS）和方向梯度正则化（DGR），从反向传播角度优化特征学习。

Result: 在多个公共数据集上的实验表明，BP-FPN consistently establishes new state-of-the-art performance。

Conclusion: BP-FPN是一种从反向传播角度设计的特征金字塔架构，通过GILS和DGR有效解决了红外小目标检测中的特征表示模糊问题，显著提升了性能。

Abstract: Moving infrared small target detection is a key component of infrared search and tracking systems, yet it remains extremely challenging due to low signal-to-clutter ratios, severe target-background imbalance, and weak discriminative features. Existing deep learning methods primarily focus on spatio-temporal feature aggregation, but their gains are limited, revealing that the fundamental bottleneck lies in ambiguous per-frame feature representations rather than spatio-temporal modeling itself. Motivated by this insight, we propose BP-FPN, a backpropagation-driven feature pyramid architecture that fundamentally rethinks feature learning for small target. BP-FPN introduces Gradient-Isolated Low-Level Shortcut (GILS) to efficiently incorporate fine-grained target details without inducing shortcut learning, and Directional Gradient Regularization (DGR) to enforce hierarchical feature consistency during backpropagation. The design is theoretically grounded, introduces negligible computational overhead, and can be seamlessly integrated into existing frameworks. Extensive experiments on multiple public datasets show that BP-FPN consistently establishes new state-of-the-art performance. To the best of our knowledge, it is the first FPN designed for this task entirely from the backpropagation perspective.

</details>


### [221] [Geometry Meets Light: Leveraging Geometric Priors for Universal Photometric Stereo under Limited Multi-Illumination Cues](https://arxiv.org/abs/2511.13015)
*King-Man Tam,Satoshi Ikehata,Yuta Asano,Zhaoyi An,Rei Kawakami*

Main category: cs.CV

TL;DR: GeoUniPS通过融合3D重建模型的几何先验和多光照线索，提升了复杂场景下的光度立体性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统通用光度立体方法在光照偏差、阴影或自遮挡区域等不可靠多光照线索场景下的性能不足问题。

Method: 设计了一个Light-Geometry Dual-Branch Encoder，结合多光照线索和冻结的3D重建模型的几何先验，并引入了PS-Perp数据集以学习空间变化的视角方向。

Result: GeoUniPS在多个数据集上实现了最先进的性能，尤其在复杂自然场景中表现出色。

Conclusion: GeoUniPS通过结合合成监督和大规模3D重建模型的几何先验，显著提升了在复杂自然场景下的性能，尤其在光照条件不佳或自遮挡区域表现优异。

Abstract: Universal Photometric Stereo is a promising approach for recovering surface normals without strict lighting assumptions. However, it struggles when multi-illumination cues are unreliable, such as under biased lighting or in shadows or self-occluded regions of complex in-the-wild scenes. We propose GeoUniPS, a universal photometric stereo network that integrates synthetic supervision with high-level geometric priors from large-scale 3D reconstruction models pretrained on massive in-the-wild data. Our key insight is that these 3D reconstruction models serve as visual-geometry foundation models, inherently encoding rich geometric knowledge of real scenes. To leverage this, we design a Light-Geometry Dual-Branch Encoder that extracts both multi-illumination cues and geometric priors from the frozen 3D reconstruction model. We also address the limitations of the conventional orthographic projection assumption by introducing the PS-Perp dataset with realistic perspective projection to enable learning of spatially varying view directions. Extensive experiments demonstrate that GeoUniPS delivers state-of-the-arts performance across multiple datasets, both quantitatively and qualitatively, especially in the complex in-the-wild scenes.

</details>


### [222] [REVISOR: Beyond Textual Reflection, Towards Multimodal Introspective Reasoning in Long-Form Video Understanding](https://arxiv.org/abs/2511.13026)
*Jiaze Li,Hao Yin,Wenhui Tan,Jingyang Chen,Boshen Xu,Yuxun Qu,Yijing Chen,Jianzhong Ju,Zhenbo Luo,Jian Luan*

Main category: cs.CV

TL;DR: REVISOR是一个工具增强的多模态反思框架，通过跨模态反思和DADR机制提升MLLMs的长视频理解能力，无需额外微调。


<details>
  <summary>Details</summary>
Motivation: 纯文本反思机制在长视频理解中存在局限性，需针对视觉信息进行反思并增强跨模态交互能力。

Method: 提出了REVISOR框架，包括跨模态反思过程和DADR奖励机制，结合GRPO训练策略。

Result: 在VideoMME、LongVideoBench、MLVU和LVBench四个基准测试中取得了显著成果。

Conclusion: REVISOR框架显著提升了MLLMs在长视频理解任务中的能力，无需额外的监督微调或外部模型，在四个基准测试中取得了显著成果。

Abstract: Self-reflection mechanisms that rely on purely text-based rethinking processes perform well in most multimodal tasks. However, when directly applied to long-form video understanding scenarios, they exhibit clear limitations. The fundamental reasons for this lie in two points: (1)long-form video understanding involves richer and more dynamic visual input, meaning rethinking only the text information is insufficient and necessitates a further rethinking process specifically targeting visual information; (2) purely text-based reflection mechanisms lack cross-modal interaction capabilities, preventing them from fully integrating visual information during reflection. Motivated by these insights, we propose REVISOR (REflective VIsual Segment Oriented Reasoning), a novel framework for tool-augmented multimodal reflection. REVISOR enables MLLMs to collaboratively construct introspective reflection processes across textual and visual modalities, significantly enhancing their reasoning capability for long-form video understanding. To ensure that REVISOR can learn to accurately review video segments highly relevant to the question during reinforcement learning, we designed the Dual Attribution Decoupled Reward (DADR) mechanism. Integrated into the GRPO training strategy, this mechanism enforces causal alignment between the model's reasoning and the selected video evidence. Notably, the REVISOR framework significantly enhances long-form video understanding capability of MLLMs without requiring supplementary supervised fine-tuning or external models, achieving impressive results on four benchmarks including VideoMME, LongVideoBench, MLVU, and LVBench.

</details>


### [223] [Towards 3D Object-Centric Feature Learning for Semantic Scene Completion](https://arxiv.org/abs/2511.13031)
*Weihua Wang,Yubo Cui,Xiangru Lin,Zhiheng Li,Zheng Fang*

Main category: cs.CV

TL;DR: Ocean提出了一种对象中心的3D语义场景补全框架，通过实例分割和注意力机制提升复杂环境下的准确性，实验证明其性能优越。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理复杂环境时，常忽略细粒度的对象级细节，导致语义和几何模糊性。

Method: 采用轻量级分割模型MobileSAM提取实例掩码，结合3D语义组注意力模块和全局相似性引导注意力模块处理分割错误和缺失实例，最后通过实例感知局部扩散模块优化BEV空间中的场景表示。

Result: 在SemanticKITTI和SSCBench-KITTI360基准测试中，Ocean分别取得了17.40和20.28的mIoU分数，达到了最先进的性能。

Conclusion: Ocean框架通过对象中心的预测方法，显著提升了3D语义场景补全的准确性，尤其在复杂环境中减少了语义和几何模糊性。

Abstract: Vision-based 3D Semantic Scene Completion (SSC) has received growing attention due to its potential in autonomous driving. While most existing approaches follow an ego-centric paradigm by aggregating and diffusing features over the entire scene, they often overlook fine-grained object-level details, leading to semantic and geometric ambiguities, especially in complex environments. To address this limitation, we propose Ocean, an object-centric prediction framework that decomposes the scene into individual object instances to enable more accurate semantic occupancy prediction. Specifically, we first employ a lightweight segmentation model, MobileSAM, to extract instance masks from the input image. Then, we introduce a 3D Semantic Group Attention module that leverages linear attention to aggregate object-centric features in 3D space. To handle segmentation errors and missing instances, we further design a Global Similarity-Guided Attention module that leverages segmentation features for global interaction. Finally, we propose an Instance-aware Local Diffusion module that improves instance features through a generative process and subsequently refines the scene representation in the BEV space. Extensive experiments on the SemanticKITTI and SSCBench-KITTI360 benchmarks demonstrate that Ocean achieves state-of-the-art performance, with mIoU scores of 17.40 and 20.28, respectively.

</details>


### [224] [Uni-Inter: Unifying 3D Human Motion Synthesis Across Diverse Interaction Contexts](https://arxiv.org/abs/2511.13032)
*Sheng Liu,Yuanzhi Liang,Jiepeng Wang,Sidan Du,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: Uni-Inter通过统一体积表示（UIV）实现了多样化交互场景的通用运动生成，性能优越且泛化能力强。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法依赖任务特定设计、泛化能力有限的问题，支持多类型交互（人-人、人-物、人-场景）的统一建模。

Method: 提出Unified Interactive Volume（UIV）作为统一的空间表示，将异构交互实体编码到共享空间，并通过关节级概率预测建模运动生成。

Result: 在三种典型交互任务上的实验表明，Uni-Inter性能优越且能泛化到新颖实体组合。

Conclusion: Uni-Inter框架通过统一的体积表示（UIV）成功实现了多样化交互场景的通用建模，为复杂环境中的可扩展运动合成提供了有前景的方向。

Abstract: We present Uni-Inter, a unified framework for human motion generation that supports a wide range of interaction scenarios: including human-human, human-object, and human-scene-within a single, task-agnostic architecture. In contrast to existing methods that rely on task-specific designs and exhibit limited generalization, Uni-Inter introduces the Unified Interactive Volume (UIV), a volumetric representation that encodes heterogeneous interactive entities into a shared spatial field. This enables consistent relational reasoning and compound interaction modeling. Motion generation is formulated as joint-wise probabilistic prediction over the UIV, allowing the model to capture fine-grained spatial dependencies and produce coherent, context-aware behaviors. Experiments across three representative interaction tasks demonstrate that Uni-Inter achieves competitive performance and generalizes well to novel combinations of entities. These results suggest that unified modeling of compound interactions offers a promising direction for scalable motion synthesis in complex environments.

</details>


### [225] [uCLIP: Parameter-Efficient Multilingual Extension of Vision-Language Models with Unpaired Data](https://arxiv.org/abs/2511.13036)
*Dahyun Chung,Donghyun Shin,Yujin Sung,Seunggi Moon,Jinwoo Jeon,Byung-Jun Lee*

Main category: cs.CV

TL;DR: 提出一种无需图像-文本对或文本-文本对的轻量级框架，通过对比学习提升低资源语言的视觉-语言对齐性能。


<details>
  <summary>Details</summary>
Motivation: 解决低资源语言在视觉-语言任务中表现不佳的问题，尤其是捷克语、芬兰语、克罗地亚语、匈牙利语和罗马尼亚语。

Method: 使用对比损失在英语表示上作为语义锚点，训练一个1.7M参数的投影模块，冻结预训练的图像编码器和多语言文本编码器。

Result: 在多个多语言检索基准测试中，该方法在资源不足语言上表现出显著的性能提升。

Conclusion: 该研究提出了一种轻量级且数据高效的多语言视觉-语言对齐框架，通过仅训练一个紧凑的投影模块，显著提升了在资源不足语言上的检索性能。

Abstract: Contrastive Language-Image Pre-training (CLIP) has demonstrated strong generalization across a wide range of visual tasks by leveraging large-scale English-image pairs. However, its extension to low-resource languages remains limited due to the scarcity of high-quality multilingual image-text data. Existing multilingual vision-language models exhibit consistently low retrieval performance in underrepresented languages including Czech, Finnish, Croatian, Hungarian, and Romanian on the Crossmodal-3600 (XM3600) benchmark. To address this, we propose a lightweight and data-efficient framework for multilingual vision-language alignment. Our approach requires no image-text pairs or text-text pairs and freezes both the pretrained image encoder and multilingual text encoder during training. Only a compact 1.7M-parameter projection module is trained, using a contrastive loss over English representations as semantic anchors. This minimal training setup enables robust multilingual alignment even for languages with limited supervision. Extensive evaluation across multiple multilingual retrieval benchmarks confirms the effectiveness of our method, showing significant gains in five underrepresented languages where existing models typically underperform. These findings highlight the effectiveness of our pivot-based, parameter-efficient alignment strategy for inclusive multimodal learning.

</details>


### [226] [MGCA-Net: Multi-Grained Category-Aware Network for Open-Vocabulary Temporal Action Localization](https://arxiv.org/abs/2511.13039)
*Zhenying Fang,Richang Hong*

Main category: cs.CV

TL;DR: MGCA-Net通过多粒度类别感知提升开放词汇时序动作定位性能，在基准测试中达到最优。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在单一粒度上识别动作类别导致基类和新增类识别准确率下降的问题。

Method: 提出了多粒度类别感知网络（MGCA-Net），包含定位器、动作存在预测器、常规分类器和粗到细分类器，通过多粒度识别提升准确性。

Result: 在THUMOS'14和ActivityNet-1.3基准测试中达到最优性能，并在零样本时序动作定位设置中表现最佳。

Conclusion: MGCA-Net通过多粒度类别感知，显著提升了开放词汇时序动作定位的性能，并在THUMOS'14和ActivityNet-1.3基准测试中达到最优效果。

Abstract: Open-Vocabulary Temporal Action Localization (OV-TAL) aims to recognize and localize instances of any desired action categories in videos without explicitly curating training data for all categories. Existing methods mostly recognize action categories at a single granularity, which degrades the recognition accuracy of both base and novel action categories. To address these issues, we propose a Multi-Grained Category-Aware Network (MGCA-Net) comprising a localizer, an action presence predictor, a conventional classifier, and a coarse-to-fine classifier. Specifically, the localizer localizes category-agnostic action proposals. For these action proposals, the action presence predictor estimates the probability that they belong to an action instance. At the same time, the conventional classifier predicts the probability of each action proposal over base action categories at the snippet granularity. Novel action categories are recognized by the coarse-to-fine classifier, which first identifies action presence at the video granularity. Finally, it assigns each action proposal to one category from the coarse categories at the proposal granularity. Through coarse-to-fine category awareness for novel actions and the conventional classifier's awareness of base actions, multi-grained category awareness is achieved, effectively enhancing localization performance. Comprehensive evaluations on the THUMOS'14 and ActivityNet-1.3 benchmarks demonstrate that our method achieves state-of-the-art performance. Furthermore, our MGCA-Net achieves state-of-the-art results under the Zero-Shot Temporal Action Localization setting.

</details>


### [227] [ViSS-R1: Self-Supervised Reinforcement Video Reasoning](https://arxiv.org/abs/2511.13054)
*Bo Fang,Yuxin Song,Qiangqiang Wu,Haoyuan Sun,Wenhao Wu,Antoni B. Chan*

Main category: cs.CV

TL;DR: 论文提出Pretext-GRPO算法和ViSS-R1框架，通过自监督强化学习提升视频推理能力，实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 当前基于R1的多模态大语言模型（MLLMs）在视频推理任务中过于依赖文本中心推理，忽视了丰富的视觉信息，容易导致捷径学习和幻觉问题。

Method: 通过自监督强化学习GRPO算法（Pretext-GRPO）和ViSS-R1框架，将基于前置任务的自监督学习直接集成到MLLM的R1后训练范式中。

Result: 在六个广泛使用的视频推理和理解基准测试中，Pretext-GRPO和ViSS-R1表现出有效性和优越性。

Conclusion: 论文提出的Pretext-GRPO算法和ViSS-R1框架在复杂视频推理任务中表现出色，代码和模型将公开。

Abstract: Complex video reasoning remains a significant challenge for Multimodal Large Language Models (MLLMs), as current R1-based methodologies often prioritize text-centric reasoning derived from text-based and image-based developments. In video tasks, such strategies frequently underutilize rich visual information, leading to potential shortcut learning and increased susceptibility to hallucination. To foster a more robust, visual-centric video understanding, we start by introducing a novel self-supervised reinforcement learning GRPO algorithm (Pretext-GRPO) within the standard R1 pipeline, in which positive rewards are assigned for correctly solving pretext tasks on transformed visual inputs, which makes the model to non-trivially process the visual information. Building on the effectiveness of Pretext-GRPO, we further propose the ViSS-R1 framework, which streamlines and integrates pretext-task-based self-supervised learning directly into the MLLM's R1 post-training paradigm. Instead of relying solely on sparse visual cues, our framework compels models to reason about transformed visual input by simultaneously processing both pretext questions (concerning transformations) and true user queries. This necessitates identifying the applied transformation and reconstructing the original video to formulate accurate final answers. Comprehensive evaluations on six widely-used video reasoning and understanding benchmarks demonstrate the effectiveness and superiority of our Pretext-GRPO and ViSS-R1 for complex video reasoning. Our codes and models will be publicly available.

</details>


### [228] [Monocular 3D Lane Detection via Structure Uncertainty-Aware Network with Curve-Point Queries](https://arxiv.org/abs/2511.13055)
*Ruixin Liu,Zejian Yuan*

Main category: cs.CV

TL;DR: MonoUnc是一种无需鸟瞰图的3D车道检测方法，通过建模局部结构不确定性，显著提升了检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法因简化几何假设而无法捕捉真实场景中结构变化和随机不确定性的问题。

Method: 提出了一种基于参数曲线和3D高斯建模的方法，动态生成曲线点查询嵌入，用于3D空间中的车道点预测。

Result: 在ONCE-3DLanes和OpenLane数据集上，MonoUnc在所有基准测试中均优于现有最优方法。

Conclusion: MonoUnc通过显式建模局部车道结构的不确定性，在3D车道检测任务中表现优于现有方法，并在更严格的评估标准下取得了最佳性能。

Abstract: Monocular 3D lane detection is challenged by aleatoric uncertainty arising from inherent observation noise. Existing methods rely on simplified geometric assumptions, such as independent point predictions or global planar modeling, failing to capture structural variations and aleatoric uncertainty in real-world scenarios. In this paper, we propose MonoUnc, a bird's-eye view (BEV)-free 3D lane detector that explicitly models aleatoric uncertainty informed by local lane structures. Specifically, 3D lanes are projected onto the front-view (FV) space and approximated by parametric curves. Guided by curve predictions, curve-point query embeddings are dynamically generated for lane point predictions in 3D space. Each segment formed by two adjacent points is modeled as a 3D Gaussian, parameterized by the local structure and uncertainty estimations. Accordingly, a novel 3D Gaussian matching loss is designed to constrain these parameters jointly. Experiments on the ONCE-3DLanes and OpenLane datasets demonstrate that MonoUnc outperforms previous state-of-the-art (SoTA) methods across all benchmarks under stricter evaluation criteria. Additionally, we propose two comprehensive evaluation metrics for ONCE-3DLanes, calculating the average and maximum bidirectional Chamfer distances to quantify global and local errors. Codes are released at https://github.com/lrx02/MonoUnc.

</details>


### [229] [FGNet: Leveraging Feature-Guided Attention to Refine SAM2 for 3D EM Neuron Segmentation](https://arxiv.org/abs/2511.13063)
*Zhenghua Li,Hang Chen,Zihao Sun,Kai Li,Xiaolin Hu*

Main category: cs.CV

TL;DR: 提出一种利用自然图像预训练模型SAM2的知识迁移框架，通过特征引导注意力和双亲和力解码器提升EM图像神经元分割性能，实验显示其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: EM图像中神经结构的精确分割对神经科学至关重要，但现有方法受限于复杂形态、低信噪比和稀缺标注，影响了准确性和泛化能力。

Method: 提出了一种新颖框架，能够有效将Segment Anything 2（SAM2）从自然图像预训练中学习到的知识迁移到EM领域。包括使用SAM2提取通用特征、引入特征引导注意力模块（Feature-Guided Attention）来桥接领域差距，以及通过双亲和力解码器生成粗和精细亲和力图。

Result: 实验结果表明，该方法在SAM2权重冻结的情况下性能与SOTA方法相当，而在EM数据上进一步微调后显著优于现有SOTA方法。

Conclusion: 该研究验证了结合自然图像预训练表示与针对性的领域自适应指导，可以有效解决神经元分割中的特定挑战。

Abstract: Accurate segmentation of neural structures in Electron Microscopy (EM) images is paramount for neuroscience. However, this task is challenged by intricate morphologies, low signal-to-noise ratios, and scarce annotations, limiting the accuracy and generalization of existing methods. To address these challenges, we seek to leverage the priors learned by visual foundation models on a vast amount of natural images to better tackle this task. Specifically, we propose a novel framework that can effectively transfer knowledge from Segment Anything 2 (SAM2), which is pre-trained on natural images, to the EM domain. We first use SAM2 to extract powerful, general-purpose features. To bridge the domain gap, we introduce a Feature-Guided Attention module that leverages semantic cues from SAM2 to guide a lightweight encoder, the Fine-Grained Encoder (FGE), in focusing on these challenging regions. Finally, a dual-affinity decoder generates both coarse and refined affinity maps. Experimental results demonstrate that our method achieves performance comparable to state-of-the-art (SOTA) approaches with the SAM2 weights frozen. Upon further fine-tuning on EM data, our method significantly outperforms existing SOTA methods. This study validates that transferring representations pre-trained on natural images, when combined with targeted domain-adaptive guidance, can effectively address the specific challenges in neuron segmentation.

</details>


### [230] [RobustGait: Robustness Analysis for Appearance Based Gait Recognition](https://arxiv.org/abs/2511.13065)
*Reeshoon Sayera,Akash Kumar,Sirshapan Mitra,Prudvi Kamtam,Yogesh S Rawat*

Main category: cs.CV

TL;DR: RobustGait框架评估外观步态识别系统的鲁棒性，发现RGB噪声、轮廓提取偏差和架构设计是关键因素，并提出了性能提升策略。


<details>
  <summary>Details</summary>
Motivation: 当前外观步态识别在受控数据集上表现良好，但缺乏对真实世界腐蚀和轮廓变异性的系统性鲁棒性评估。

Method: RobustGait框架从四个维度（扰动类型、轮廓提取方法、模型架构容量、部署场景）进行细粒度鲁棒性评估，引入了15种腐蚀类型和5种严重级别，评估了六种先进步态系统。

Result: 研究发现：1. RGB级噪声更能反映真实世界退化；2. 步态准确性对轮廓提取器偏差高度敏感；3. 鲁棒性取决于扰动类型和架构设计；4. 噪声感知训练和知识蒸馏可提升性能。

Conclusion: RobustGait框架通过多维度评估揭示了外观步态识别系统的鲁棒性关键因素，并提出了噪声感知训练和知识蒸馏等策略以提升系统性能。

Abstract: Appearance-based gait recognition have achieved strong performance on controlled datasets, yet systematic evaluation of its robustness to real-world corruptions and silhouette variability remains lacking. We present RobustGait, a framework for fine-grained robustness evaluation of appearance-based gait recognition systems. RobustGait evaluation spans four dimensions: the type of perturbation (digital, environmental, temporal, occlusion), the silhouette extraction method (segmentation and parsing networks), the architectural capacities of gait recognition models, and various deployment scenarios. The benchmark introduces 15 corruption types at 5 severity levels across CASIA-B, CCPG, and SUSTech1K, with in-the-wild validation on MEVID, and evaluates six state-of-the-art gait systems. We came across several exciting insights. First, applying noise at the RGB level better reflects real-world degradation, and reveal how distortions propagate through silhouette extraction to the downstream gait recognition systems. Second, gait accuracy is highly sensitive to silhouette extractor biases, revealing an overlooked source of benchmark bias. Third, robustness is dependent on both the type of perturbation and the architectural design. Finally, we explore robustness-enhancing strategies, showing that noise-aware training and knowledge distillation improve performance and move toward deployment-ready systems.

</details>


### [231] [Decoupling Scene Perception and Ego Status: A Multi-Context Fusion Approach for Enhanced Generalization in End-to-End Autonomous Driving](https://arxiv.org/abs/2511.13079)
*Jiacheng Tang,Mingyue Feng,Jiachao Liu,Yaonong Wang,Jian Pu*

Main category: cs.CV

TL;DR: AdaptiveAD通过双分支结构和场景感知融合模块，有效解决了自动驾驶规划中过度依赖ego状态的问题，提升了泛化能力和规划性能。


<details>
  <summary>Details</summary>
Motivation: 现有模块化设计在自动驾驶规划中过度依赖ego状态，限制了系统的泛化能力和场景理解鲁棒性。研究发现ego状态在上游BEV编码器中的过早融合是主要原因。

Method: 提出AdaptiveAD架构，采用双分支结构分别处理场景驱动推理和ego驱动推理，通过场景感知融合模块自适应整合两者决策，并引入路径注意力机制和两个辅助任务（BEV单向蒸馏和自回归在线映射）以确保多任务学习不受影响。

Result: 在nuScenes数据集上的广泛评估表明，AdaptiveAD实现了最先进的开放环路规划性能，显著减少了对ego状态的依赖，并在多样化场景中展现出优异的泛化能力。

Conclusion: AdaptiveAD通过双分支结构和场景感知融合模块，显著减少了对ego状态的过度依赖，并在nuScenes数据集上实现了最先进的开放环路规划性能，展现了强大的泛化能力。

Abstract: Modular design of planning-oriented autonomous driving has markedly advanced end-to-end systems. However, existing architectures remain constrained by an over-reliance on ego status, hindering generalization and robust scene understanding. We identify the root cause as an inherent design within these architectures that allows ego status to be easily leveraged as a shortcut. Specifically, the premature fusion of ego status in the upstream BEV encoder allows an information flow from this strong prior to dominate the downstream planning module. To address this challenge, we propose AdaptiveAD, an architectural-level solution based on a multi-context fusion strategy. Its core is a dual-branch structure that explicitly decouples scene perception and ego status. One branch performs scene-driven reasoning based on multi-task learning, but with ego status deliberately omitted from the BEV encoder, while the other conducts ego-driven reasoning based solely on the planning task. A scene-aware fusion module then adaptively integrates the complementary decisions from the two branches to form the final planning trajectory. To ensure this decoupling does not compromise multi-task learning, we introduce a path attention mechanism for ego-BEV interaction and add two targeted auxiliary tasks: BEV unidirectional distillation and autoregressive online mapping. Extensive evaluations on the nuScenes dataset demonstrate that AdaptiveAD achieves state-of-the-art open-loop planning performance. Crucially, it significantly mitigates the over-reliance on ego status and exhibits impressive generalization capabilities across diverse scenarios.

</details>


### [232] [MergeSlide: Continual Model Merging and Task-to-Class Prompt-Aligned Inference for Lifelong Learning on Whole Slide Images](https://arxiv.org/abs/2511.13099)
*Doanh C. Bui,Ba Hung Ngo,Hoai Luan Pham,Khang Nguyen,Maï K. Nguyen,Yasuhiko Nakashima*

Main category: cs.CV

TL;DR: MergeSlide是一种简单有效的终身学习框架，通过模型融合和任务到类提示对齐推理，解决了WSI学习中的灾难性遗忘问题，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 全切片图像（WSIs）的终身学习旨在减少数据处理和传输的资源消耗，但由于WSI的巨量大小和多任务学习的复杂性，现有方法存在灾难性遗忘问题。

Method: MergeSlide将终身学习视为模型融合问题，利用视觉-语言病理学基础模型，通过正交持续融合策略和任务到类提示对齐（TCP）推理来优化模型。

Result: 在六个TCGA数据集上的实验表明，MergeSlide在性能上优于基于记忆的持续学习和视觉-语言零样本基线方法。

Conclusion: MergeSlide通过模型融合和任务到类提示对齐的推理策略，有效解决了WSI终身学习中的灾难性遗忘问题，并在多个数据集上表现优于现有方法。

Abstract: Lifelong learning on Whole Slide Images (WSIs) aims to train or fine-tune a unified model sequentially on cancer-related tasks, reducing the resources and effort required for data transfer and processing, especially given the gigabyte-scale size of WSIs. In this paper, we introduce MergeSlide, a simple yet effective framework that treats lifelong learning as a model merging problem by leveraging a vision-language pathology foundation model. When a new task arrives, it is: 1) defined with class-aware prompts, 2) fine-tuned for a few epochs using an MLP-free backbone, and 3) merged into a unified model using an orthogonal continual merging strategy that preserves performance and mitigates catastrophic forgetting. For inference under the class-incremental learning (CLASS-IL) setting, where task identity is unknown, we introduce Task-to-Class Prompt-aligned (TCP) inference. Specifically, TCP first identifies the most relevant task using task-level prompts and then applies the corresponding class-aware prompts to generate predictions. To evaluate MergeSlide, we conduct experiments on a stream of six TCGA datasets. The results show that MergeSlide outperforms both rehearsal-based continual learning and vision-language zero-shot baselines. Code and data are available at https://github.com/caodoanh2001/MergeSlide.

</details>


### [233] [CapeNext: Rethinking and refining dynamic support information for category-agnostic pose estimation](https://arxiv.org/abs/2511.13102)
*Yu Zhu,Dan Zeng,Shuiwang Li,Qijun Zhao,Qiaomu Shen,Bo Tang*

Main category: cs.CV

TL;DR: CapeNext通过动态文本和图像线索增强姿态估计，解决了静态嵌入的歧义和区分性问题，性能大幅提升。


<details>
  <summary>Details</summary>
Motivation: 解决静态联合嵌入的两个固有局限性：多义词导致的跨类别歧义和细粒度类别内变化的不足区分性。

Method: 提出了一种新框架，结合层次化跨模态交互和双流特征细化，利用文本描述和特定图像的类级和实例特定线索增强联合嵌入。

Result: 在MP-100数据集上，无论网络骨干如何，CapeNext均显著优于现有CAPE方法。

Conclusion: CapeNext框架通过整合层次化跨模态交互和双流特征细化，显著提升了类别无关姿态估计的性能，在MP-100数据集上大幅超越现有方法。

Abstract: Recent research in Category-Agnostic Pose Estimation (CAPE) has adopted fixed textual keypoint description as semantic prior for two-stage pose matching frameworks. While this paradigm enhances robustness and flexibility by disentangling the dependency of support images, our critical analysis reveals two inherent limitations of static joint embedding: (1) polysemy-induced cross-category ambiguity during the matching process(e.g., the concept "leg" exhibiting divergent visual manifestations across humans and furniture), and (2) insufficient discriminability for fine-grained intra-category variations (e.g., posture and fur discrepancies between a sleeping white cat and a standing black cat). To overcome these challenges, we propose a new framework that innovatively integrates hierarchical cross-modal interaction with dual-stream feature refinement, enhancing the joint embedding with both class-level and instance-specific cues from textual description and specific images. Experiments on the MP-100 dataset demonstrate that, regardless of the network backbone, CapeNext consistently outperforms state-of-the-art CAPE methods by a large margin.

</details>


### [234] [PlugTrack: Multi-Perceptive Motion Analysis for Adaptive Fusion in Multi-Object Tracking](https://arxiv.org/abs/2511.13105)
*Seungjae Kim,SeungJoon Lee,MyeongAh Cho*

Main category: cs.CV

TL;DR: PlugTrack通过自适应融合卡尔曼滤波器和数据驱动的运动预测器，解决了多目标跟踪中运动预测的局限性，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有的运动预测方法存在局限性：卡尔曼滤波器在非线性运动模式中失效，而数据驱动的预测器在领域泛化和计算效率上表现不佳。研究表明，现实跟踪场景中同时存在线性和非线性运动模式，因此需要一种能够结合两者优势的方法。

Method: 提出PlugTrack框架，通过多感知运动理解自适应融合卡尔曼滤波器和数据驱动的运动预测器，生成自适应的混合因子。

Result: PlugTrack在MOT17/MOT20和DanceTrack数据集上实现了显著性能提升，且无需修改现有运动预测器。

Conclusion: PlugTrack通过自适应融合卡尔曼滤波器和数据驱动的运动预测器，在多目标跟踪（MOT）中实现了显著性能提升，尤其是在MOT17/MOT20和DanceTrack数据集上达到了最先进的性能。

Abstract: Multi-object tracking (MOT) predominantly follows the tracking-by-detection paradigm, where Kalman filters serve as the standard motion predictor due to computational efficiency but inherently fail on non-linear motion patterns. Conversely, recent data-driven motion predictors capture complex non-linear dynamics but suffer from limited domain generalization and computational overhead. Through extensive analysis, we reveal that even in datasets dominated by non-linear motion, Kalman filter outperforms data-driven predictors in up to 34\% of cases, demonstrating that real-world tracking scenarios inherently involve both linear and non-linear patterns. To leverage this complementarity, we propose PlugTrack, a novel framework that adaptively fuses Kalman filter and data-driven motion predictors through multi-perceptive motion understanding. Our approach employs multi-perceptive motion analysis to generate adaptive blending factors. PlugTrack achieves significant performance gains on MOT17/MOT20 and state-of-the-art on DanceTrack without modifying existing motion predictors. To the best of our knowledge, PlugTrack is the first framework to bridge classical and modern motion prediction paradigms through adaptive fusion in MOT.

</details>


### [235] [Low-Level Dataset Distillation for Medical Image Enhancement](https://arxiv.org/abs/2511.13106)
*Fengzhi Xu,Ziyuan Yang,Mengyu Sun,Joey Tianyi Zhou,Yi Zhang*

Main category: cs.CV

TL;DR: 该论文提出了一种针对医学图像增强的低级数据集蒸馏方法，通过共享解剖学先验和个性化生成模块，解决了像素级保真度问题，同时保护隐私并降低成本。


<details>
  <summary>Details</summary>
Motivation: 医学图像增强在临床中具有重要价值，但现有方法需要大规模数据集学习复杂的像素级映射，训练和存储成本高昂。现有数据集蒸馏方法主要针对高级任务，无法满足低级别任务对像素级保真度的需求。因此，论文提出一种针对低级别任务的数据集蒸馏方法。

Method: 论文首先利用患者间的解剖相似性构建共享解剖学先验，并以此作为初始化。随后通过结构保持个性化生成模块（SPG）为每位患者个性化定制蒸馏数据，同时保持像素级保真度。对于不同低级别任务，蒸馏数据用于构建任务特定的高质量和低质量训练对，并通过梯度对齐注入患者特定知识。

Result: 提出的方法成功实现了医学图像增强的低级数据集蒸馏，通过共享解剖学先验和SPG模块，在保持像素级保真度的同时，显著减少了训练和存储成本，并保护了患者隐私。

Conclusion: 该论文提出了一种针对医学图像增强的低级数据集蒸馏方法，通过共享解剖学先验和结构保持个性化生成模块，有效解决了现有方法在处理低级别任务时面临的像素级保真度问题，同时保护了患者隐私。

Abstract: Medical image enhancement is clinically valuable, but existing methods require large-scale datasets to learn complex pixel-level mappings. However, the substantial training and storage costs associated with these datasets hinder their practical deployment. While dataset distillation (DD) can alleviate these burdens, existing methods mainly target high-level tasks, where multiple samples share the same label. This many-to-one mapping allows distilled data to capture shared semantics and achieve information compression. In contrast, low-level tasks involve a many-to-many mapping that requires pixel-level fidelity, making low-level DD an underdetermined problem, as a small distilled dataset cannot fully constrain the dense pixel-level mappings. To address this, we propose the first low-level DD method for medical image enhancement. We first leverage anatomical similarities across patients to construct the shared anatomical prior based on a representative patient, which serves as the initialization for the distilled data of different patients. This prior is then personalized for each patient using a Structure-Preserving Personalized Generation (SPG) module, which integrates patient-specific anatomical information into the distilled dataset while preserving pixel-level fidelity. For different low-level tasks, the distilled data is used to construct task-specific high- and low-quality training pairs. Patient-specific knowledge is injected into the distilled data by aligning the gradients computed from networks trained on the distilled pairs with those from the corresponding patient's raw data. Notably, downstream users cannot access raw patient data. Instead, only a distilled dataset containing abstract training information is shared, which excludes patient-specific details and thus preserves privacy.

</details>


### [236] [DGS-Net: Distillation-Guided Gradient Surgery for CLIP Fine-Tuning in AI-Generated Image Detection](https://arxiv.org/abs/2511.13108)
*Jiazhen Yan,Ziqiang Li,Fan Wang,Boyu Wang,Zhangjie Fu*

Main category: cs.CV

TL;DR: DGS-Net通过梯度分解和蒸馏优化，解决了合成内容检测中的灾难性遗忘问题，显著提升了检测性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 生成模型（如GANs和扩散模型）的快速发展导致AI生成图像泛滥，引发了对错误信息、隐私侵犯和数字媒体信任危机的担忧。现有方法在微调时容易导致灾难性遗忘，限制了跨域泛化。

Method: 提出了Distillation-guided Gradient Surgery Network (DGS-Net)，通过梯度空间分解分离优化中的有害和有益下降方向，并结合冻结CLIP编码器蒸馏的有益方向进行优化。

Result: 在50种生成模型上的实验表明，DGS-Net平均优于现有方法6.6%，实现了卓越的检测性能和跨生成技术的泛化能力。

Conclusion: DGS-Net通过梯度空间分解和蒸馏引导的优化，有效解决了预训练先验的灾难性遗忘问题，提升了合成内容检测的性能和跨域泛化能力。

Abstract: The rapid progress of generative models such as GANs and diffusion models has led to the widespread proliferation of AI-generated images, raising concerns about misinformation, privacy violations, and trust erosion in digital media. Although large-scale multimodal models like CLIP offer strong transferable representations for detecting synthetic content, fine-tuning them often induces catastrophic forgetting, which degrades pre-trained priors and limits cross-domain generalization. To address this issue, we propose the Distillation-guided Gradient Surgery Network (DGS-Net), a novel framework that preserves transferable pre-trained priors while suppressing task-irrelevant components. Specifically, we introduce a gradient-space decomposition that separates harmful and beneficial descent directions during optimization. By projecting task gradients onto the orthogonal complement of harmful directions and aligning with beneficial ones distilled from a frozen CLIP encoder, DGS-Net achieves unified optimization of prior preservation and irrelevant suppression. Extensive experiments on 50 generative models demonstrate that our method outperforms state-of-the-art approaches by an average margin of 6.6, achieving superior detection performance and generalization across diverse generation techniques.

</details>


### [237] [Learning Implicit Neural Degradation Representation for Unpaired Image Dehazing](https://arxiv.org/abs/2511.13110)
*Shuaibin Fan,Senming Zhong,Wenchao Yan,Minglong Xue*

Main category: cs.CV

TL;DR: 提出一种无监督去雾方法，结合通道机制和隐式神经表示，有效处理复杂场景中的雾，实验效果优越。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理复杂场景时难以平衡细粒度特征表示和全局一致性建模，且缺乏对空间变化中雾的退化表示的学习。

Method: 结合通道独立和通道依赖机制的无监督去雾方法，设计了隐式神经表示和密集残差增强模块。

Result: 实验结果显示，该方法在复杂场景中实现了良好的视觉感知和高品质的图像恢复。

Conclusion: 该方法在多个公共和真实世界数据集上实现了具有竞争力的去雾性能，代码将在GitHub上开源。

Abstract: Image dehazing is an important task in the field of computer vision, aiming at restoring clear and detail-rich visual content from haze-affected images. However, when dealing with complex scenes, existing methods often struggle to strike a balance between fine-grained feature representation of inhomogeneous haze distribution and global consistency modeling. Furthermore, to better learn the common degenerate representation of haze in spatial variations, we propose an unsupervised dehaze method for implicit neural degradation representation. Firstly, inspired by the Kolmogorov-Arnold representation theorem, we propose a mechanism combining the channel-independent and channel-dependent mechanisms, which efficiently enhances the ability to learn from nonlinear dependencies. which in turn achieves good visual perception in complex scenes. Moreover, we design an implicit neural representation to model haze degradation as a continuous function to eliminate redundant information and the dependence on explicit feature extraction and physical models. To further learn the implicit representation of the haze features, we also designed a dense residual enhancement module from it to eliminate redundant information. This achieves high-quality image restoration. Experimental results show that our method achieves competitive dehaze performance on various public and real-world datasets. This project code will be available at https://github.com/Fan-pixel/NeDR-Dehaze.

</details>


### [238] [Semantics and Content Matter: Towards Multi-Prior Hierarchical Mamba for Image Deraining](https://arxiv.org/abs/2511.13113)
*Zhaocheng Yu,Kui Jiang,Junjun Jiang,Xianming Liu,Guanglu Sun,Yi Xiao*

Main category: cs.CV

TL;DR: MPHM网络结合CLIP和DINOv2先验，通过PFI和HMM模块实现高效去雨，性能领先且泛化能力强。


<details>
  <summary>Details</summary>
Motivation: 现有去雨方法在语义和空间细节保真度方面表现不足，需解决异构先验间的冲突并提升全局与局部特征建模能力。

Method: 提出MPHM网络，整合CLIP和DINOv2先验，采用渐进式先验融合注入（PFI）策略，并设计傅里叶增强的双路径层次化Mamba模块（HMM）。

Result: 在Rain200H数据集上PSNR提升0.57 dB，并在真实雨景中表现出优异泛化性能。

Conclusion: MPHM网络通过融合宏观语义文本先验和微观结构视觉先验，显著提升了图像去雨任务的性能，并在实验中展现出卓越的泛化能力。

Abstract: Rain significantly degrades the performance of computer vision systems, particularly in applications like autonomous driving and video surveillance. While existing deraining methods have made considerable progress, they often struggle with fidelity of semantic and spatial details. To address these limitations, we propose the Multi-Prior Hierarchical Mamba (MPHM) network for image deraining. This novel architecture synergistically integrates macro-semantic textual priors (CLIP) for task-level semantic guidance and micro-structural visual priors (DINOv2) for scene-aware structural information. To alleviate potential conflicts between heterogeneous priors, we devise a progressive Priors Fusion Injection (PFI) that strategically injects complementary cues at different decoder levels. Meanwhile, we equip the backbone network with an elaborate Hierarchical Mamba Module (HMM) to facilitate robust feature representation, featuring a Fourier-enhanced dual-path design that concurrently addresses global context modeling and local detail recovery. Comprehensive experiments demonstrate MPHM's state-of-the-art performance, achieving a 0.57 dB PSNR gain on the Rain200H dataset while delivering superior generalization on real-world rainy scenarios.

</details>


### [239] [A Lightweight 3D Anomaly Detection Method with Rotationally Invariant Features](https://arxiv.org/abs/2511.13115)
*Hanzhe Liang,Jie Zhou,Can Gao,Bingyang Guo,Jinbao Wang,Linlin Shen*

Main category: cs.CV

TL;DR: Proposes a Rotationally Invariant Features (RIF) framework for 3D anomaly detection, using PCM and CTF-Net to handle orientation changes, achieving significant performance improvements.


<details>
  <summary>Details</summary>
Motivation: Existing 3D anomaly detection methods struggle with point clouds that have changes in orientation and position, leading to inconsistent features. The RIF framework aims to address this by ensuring rotationally invariant features.

Method: The framework includes a Point Coordinate Mapping (PCM) technique to map points into a rotationally invariant space and a Convolutional Transform Feature Network (CTF-Net) to extract robust features. Transfer learning is used to pre-train the feature extractor.

Result: The method improves average P-AUROC by 17.7% on Anomaly-ShapeNet and 1.6% on Real3D-AD, outperforming existing approaches.

Conclusion: The proposed RIF framework demonstrates strong generalization ability and achieves advanced performance on 3D anomaly detection tasks, showing great potential for industrial applications.

Abstract: 3D anomaly detection (AD) is a crucial task in computer vision, aiming to identify anomalous points or regions from point cloud data. However, existing methods may encounter challenges when handling point clouds with changes in orientation and position because the resulting features may vary significantly. To address this problem, we propose a novel Rotationally Invariant Features (RIF) framework for 3D AD. Firstly, to remove the adverse effect of variations on point cloud data, we develop a Point Coordinate Mapping (PCM) technique, which maps each point into a rotationally invariant space to maintain consistency of representation. Then, to learn robust and discriminative features, we design a lightweight Convolutional Transform Feature Network (CTF-Net) to extract rotationally invariant features for the memory bank. To improve the ability of the feature extractor, we introduce the idea of transfer learning to pre-train the feature extractor with 3D data augmentation. Experimental results show that the proposed method achieves the advanced performance on the Anomaly-ShapeNet dataset, with an average P-AUROC improvement of 17.7\%, and also gains the best performance on the Real3D-AD dataset, with an average P-AUROC improvement of 1.6\%. The strong generalization ability of RIF has been verified by combining it with traditional feature extraction methods on anomaly detection tasks, demonstrating great potential for industrial applications.

</details>


### [240] [CloseUpShot: Close-up Novel View Synthesis from Sparse-views via Point-conditioned Diffusion Model](https://arxiv.org/abs/2511.13121)
*Yuqi Zhang,Guanying Chen,Jiaxing Chen,Chuanyu Fu,Chuan Huang,Shuguang Cui*

Main category: cs.CV

TL;DR: CloseUpShot通过点条件视频扩散和全局结构引导，显著提升稀疏输入下的近景新视角合成效果。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在近景稀疏输入下难以捕捉细节的问题，利用视频扩散模型的时间推理能力提升重建质量。

Method: 采用分层扭曲和遮挡感知噪声抑制来增强条件图像质量，并结合全局结构引导（利用密集融合点云）提供一致的几何上下文。

Result: 在多个数据集上的实验表明，该方法优于现有方法，尤其在近景新视角合成中表现突出。

Conclusion: 提出的CloseUpShot框架通过点条件视频扩散和全局结构引导，显著提升了稀疏输入下的近景新视角合成质量，实验验证了其有效性。

Abstract: Reconstructing 3D scenes and synthesizing novel views from sparse input views is a highly challenging task. Recent advances in video diffusion models have demonstrated strong temporal reasoning capabilities, making them a promising tool for enhancing reconstruction quality under sparse-view settings. However, existing approaches are primarily designed for modest viewpoint variations, which struggle in capturing fine-grained details in close-up scenarios since input information is severely limited. In this paper, we present a diffusion-based framework, called CloseUpShot, for close-up novel view synthesis from sparse inputs via point-conditioned video diffusion. Specifically, we observe that pixel-warping conditioning suffers from severe sparsity and background leakage in close-up settings. To address this, we propose hierarchical warping and occlusion-aware noise suppression, enhancing the quality and completeness of the conditioning images for the video diffusion model. Furthermore, we introduce global structure guidance, which leverages a dense fused point cloud to provide consistent geometric context to the diffusion process, to compensate for the lack of globally consistent 3D constraints in sparse conditioning inputs. Extensive experiments on multiple datasets demonstrate that our method outperforms existing approaches, especially in close-up novel view synthesis, clearly validating the effectiveness of our design.

</details>


### [241] [Region-Point Joint Representation for Effective Trajectory Similarity Learning](https://arxiv.org/abs/2511.13125)
*Hao Long,Silin Zhou,Lisi Chen,Shuo Shang*

Main category: cs.CV

TL;DR: RePo是一种联合编码区域级和点级特征的新方法，显著提升轨迹相似性计算性能。


<details>
  <summary>Details</summary>
Motivation: 现有学习方法未能充分利用轨迹信息的全面频谱进行相似性建模。

Method: RePo方法包括区域级和点级特征编码：区域级通过网格序列捕捉空间上下文和语义信息；点级通过三个专家网络提取局部、相关和连续运动模式，再由路由器网络自适应融合。最终通过交叉注意力结合两类特征生成轨迹嵌入。

Result: 实验结果表明，RePo在所有评估指标上平均比SOTA基线提高了22.2%的准确率。

Conclusion: RePo通过联合编码区域级和点级特征，显著提升了轨迹相似性计算的准确性和效率，比现有最佳方法平均提高了22.2%的准确率。

Abstract: Recent learning-based methods have reduced the computational complexity of traditional trajectory similarity computation, but state-of-the-art (SOTA) methods still fail to leverage the comprehensive spectrum of trajectory information for similarity modeling. To tackle this problem, we propose \textbf{RePo}, a novel method that jointly encodes \textbf{Re}gion-wise and \textbf{Po}int-wise features to capture both spatial context and fine-grained moving patterns. For region-wise representation, the GPS trajectories are first mapped to grid sequences, and spatial context are captured by structural features and semantic context enriched by visual features. For point-wise representation, three lightweight expert networks extract local, correlation, and continuous movement patterns from dense GPS sequences. Then, a router network adaptively fuses the learned point-wise features, which are subsequently combined with region-wise features using cross-attention to produce the final trajectory embedding. To train RePo, we adopt a contrastive loss with hard negative samples to provide similarity ranking supervision. Experiment results show that RePo achieves an average accuracy improvement of 22.2\% over SOTA baselines across all evaluation metrics.

</details>


### [242] [VEIL: Jailbreaking Text-to-Video Models via Visual Exploitation from Implicit Language](https://arxiv.org/abs/2511.13127)
*Zonghao Ying,Moyang Chen,Nizhang Li,Zhiqiang Wang,Wenxin Zhang,Quanchen Zou,Zonglei Jing,Aishan Liu,Xianglong Liu*

Main category: cs.CV

TL;DR: VEIL框架利用模块化提示设计绕过T2V模型安全防护，攻击成功率显著提升。


<details>
  <summary>Details</summary>
Motivation: 揭示T2V模型在隐含提示下的安全盲区，提出更隐蔽的攻击方法。

Method: 提出VEIL框架，结合中性场景锚点、潜在听觉触发器和风格调节器，通过约束优化和引导搜索实现攻击。

Result: 在7个T2V模型中验证，商业模型的平均攻击成功率提升23%。

Conclusion: VEIL框架通过模块化提示设计成功绕过T2V模型的安全防护，显著提高了攻击成功率。

Abstract: Jailbreak attacks can circumvent model safety guardrails and reveal critical blind spots. Prior attacks on text-to-video (T2V) models typically add adversarial perturbations to obviously unsafe prompts, which are often easy to detect and defend. In contrast, we show that benign-looking prompts containing rich, implicit cues can induce T2V models to generate semantically unsafe videos that both violate policy and preserve the original (blocked) intent. To realize this, we propose VEIL, a jailbreak framework that leverages T2V models' cross-modal associative patterns via a modular prompt design. Specifically, our prompts combine three components: neutral scene anchors, which provide the surface-level scene description extracted from the blocked intent to maintain plausibility; latent auditory triggers, textual descriptions of innocuous-sounding audio events (e.g., creaking, muffled noises) that exploit learned audio-visual co-occurrence priors to bias the model toward particular unsafe visual concepts; and stylistic modulators, cinematic directives (e.g., camera framing, atmosphere) that amplify and stabilize the latent trigger's effect. We formalize attack generation as a constrained optimization over the above modular prompt space and solve it with a guided search procedure that balances stealth and effectiveness. Extensive experiments over 7 T2V models demonstrate the efficacy of our attack, achieving a 23 percent improvement in average attack success rate in commercial models.

</details>


### [243] [MedGEN-Bench: Contextually entangled benchmark for open-ended multimodal medical generation](https://arxiv.org/abs/2511.13135)
*Junjie Yang,Yuhao Yan,Gang Wu,Yuxuan Wang,Ruoyu Liang,Xinjie Jiang,Xiang Wan,Fenglei Fan,Yongquan Zhang,Feiwei Qin,Changmiao Wan*

Main category: cs.CV

TL;DR: MedGEN-Bench是一个全面的医学多模态基准测试，弥补现有局限，通过复杂任务和评估框架推动医学AI发展。


<details>
  <summary>Details</summary>
Motivation: 现有医学视觉基准测试存在局限性：查询模糊、简化诊断推理为封闭式捷径，且以文本为中心，忽视了图像生成能力的重要性。为应对这些挑战，作者提出了MedGEN-Bench。

Method: 作者设计了MedGEN-Bench，包含6,422个专家验证的图像-文本对，涵盖6种成像模态、16种临床任务和28个子任务。基准测试分为三种格式：视觉问答、图像编辑和上下文多模态生成。评估采用三层框架：像素级指标、语义文本分析和专家指导的临床相关性评分。

Result: MedGEN-Bench通过其独特的设计和评估框架，系统地评估了10种组合框架、3种统一模型和5种VLMs，展示了其在推动医学AI研究中的潜力。

Conclusion: 本文提出了MedGEN-Bench，一个全面的多模态基准测试，旨在推动医学AI研究。该基准测试通过三种格式（视觉问答、图像编辑和上下文多模态生成）和三层评估框架（像素级指标、语义文本分析和专家指导的临床相关性评分），弥补了现有医学视觉基准测试的不足，并展示了其在评估10种组合框架、3种统一模型和5种VLMs中的有效性。

Abstract: As Vision-Language Models (VLMs) increasingly gain traction in medical applications, clinicians are progressively expecting AI systems not only to generate textual diagnoses but also to produce corresponding medical images that integrate seamlessly into authentic clinical workflows. Despite the growing interest, existing medical visual benchmarks present notable limitations. They often rely on ambiguous queries that lack sufficient relevance to image content, oversimplify complex diagnostic reasoning into closed-ended shortcuts, and adopt a text-centric evaluation paradigm that overlooks the importance of image generation capabilities. To address these challenges, we introduce \textsc{MedGEN-Bench}, a comprehensive multimodal benchmark designed to advance medical AI research. MedGEN-Bench comprises 6,422 expert-validated image-text pairs spanning six imaging modalities, 16 clinical tasks, and 28 subtasks. It is structured into three distinct formats: Visual Question Answering, Image Editing, and Contextual Multimodal Generation. What sets MedGEN-Bench apart is its focus on contextually intertwined instructions that necessitate sophisticated cross-modal reasoning and open-ended generative outputs, moving beyond the constraints of multiple-choice formats. To evaluate the performance of existing systems, we employ a novel three-tier assessment framework that integrates pixel-level metrics, semantic text analysis, and expert-guided clinical relevance scoring. Using this framework, we systematically assess 10 compositional frameworks, 3 unified models, and 5 VLMs.

</details>


### [244] [WinMamba: Multi-Scale Shifted Windows in State Space Model for 3D Object Detection](https://arxiv.org/abs/2511.13138)
*Longhui Zheng,Qiming Xia,Xiaolu Chen,Zhaoliang Liu,Chenglu Wen*

Main category: cs.CV

TL;DR: WinMamba是一种新型Mamba-based 3D特征编码框架，通过窗口尺度自适应和窗口移位策略提升检测精度，实验证明其高效且准确。


<details>
  <summary>Details</summary>
Motivation: 解决现有Mamba-based模型在固定窗口轴对齐扫描中丢失空间信息的问题，平衡计算效率与长距离空间依赖捕获。

Method: 提出了基于Mamba的WinMamba块，包含窗口尺度自适应模块（WSF）和可学习位置编码及窗口移位策略。

Result: 在KITTI和Waymo数据集上表现显著优于基线，消融实验验证了WSF和AWF模块的有效性。

Conclusion: WinMamba通过创新的WinMamba块和窗口尺度自适应模块，显著提升了3D目标检测的效率与精度，实验验证了其在KITTI和Waymo数据集上的优越性。

Abstract: 3D object detection is critical for autonomous driving, yet it remains fundamentally challenging to simultaneously maximize computational efficiency and capture long-range spatial dependencies. We observed that Mamba-based models, with their linear state-space design, capture long-range dependencies at lower cost, offering a promising balance between efficiency and accuracy. However, existing methods rely on axis-aligned scanning within a fixed window, inevitably discarding spatial information. To address this problem, we propose WinMamba, a novel Mamba-based 3D feature-encoding backbone composed of stacked WinMamba blocks. To enhance the backbone with robust multi-scale representation, the WinMamba block incorporates a window-scale-adaptive module that compensates voxel features across varying resolutions during sampling. Meanwhile, to obtain rich contextual cues within the linear state space, we equip the WinMamba layer with a learnable positional encoding and a window-shift strategy. Extensive experiments on the KITTI and Waymo datasets demonstrate that WinMamba significantly outperforms the baseline. Ablation studies further validate the individual contributions of the WSF and AWF modules in improving detection accuracy. The code will be made publicly available.

</details>


### [245] [Skeletons Speak Louder than Text: A Motion-Aware Pretraining Paradigm for Video-Based Person Re-Identification](https://arxiv.org/abs/2511.13150)
*Rifen Lin,Alex Jinpeng Wang,Jiawei Mo,Min Li*

Main category: cs.CV

TL;DR: CSIP-ReID通过骨架驱动的预训练框架，解决了视频行人重识别中多模态预训练的不足，结合对比学习和动态原型融合，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 探索多模态预训练在视频行人重识别（ReID）中的潜力，解决现有方法依赖视频-文本对的两大局限：缺乏真正的多模态预训练，以及文本难以捕捉细粒度时间运动信息。

Method: 提出了CSIP-ReID，一种两阶段方法：第一阶段使用对比学习对齐骨架和视觉特征；第二阶段引入动态原型融合更新器（PFU）和多模态身份原型，结合运动与外观线索。此外，提出SGTM模块从骨架数据中提取时间线索并整合到视觉特征中。

Result: 在标准视频ReID基准测试（MARS、LS-VID、iLIDS-VID）中达到新的最先进水平，并在骨架ReID任务（BIWI、IAS）中展现出强泛化能力。

Conclusion: CSIP-ReID开创了一种无需标注且运动感知的预训练范式，为多模态表示学习开辟了新领域。

Abstract: Multimodal pretraining has revolutionized visual understanding, but its impact on video-based person re-identification (ReID) remains underexplored. Existing approaches often rely on video-text pairs, yet suffer from two fundamental limitations: (1) lack of genuine multimodal pretraining, and (2) text poorly captures fine-grained temporal motion-an essential cue for distinguishing identities in video. In this work, we take a bold departure from text-based paradigms by introducing the first skeleton-driven pretraining framework for ReID. To achieve this, we propose Contrastive Skeleton-Image Pretraining for ReID (CSIP-ReID), a novel two-stage method that leverages skeleton sequences as a spatiotemporally informative modality aligned with video frames. In the first stage, we employ contrastive learning to align skeleton and visual features at sequence level. In the second stage, we introduce a dynamic Prototype Fusion Updater (PFU) to refine multimodal identity prototypes, fusing motion and appearance cues. Moreover, we propose a Skeleton Guided Temporal Modeling (SGTM) module that distills temporal cues from skeleton data and integrates them into visual features. Extensive experiments demonstrate that CSIP-ReID achieves new state-of-the-art results on standard video ReID benchmarks (MARS, LS-VID, iLIDS-VID). Moreover, it exhibits strong generalization to skeleton-only ReID tasks (BIWI, IAS), significantly outperforming previous methods. CSIP-ReID pioneers an annotation-free and motion-aware pretraining paradigm for ReID, opening a new frontier in multimodal representation learning.

</details>


### [246] [THIR: Topological Histopathological Image Retrieval](https://arxiv.org/abs/2511.13170)
*Zahra Tabatabaei,Jon Sporring*

Main category: cs.CV

TL;DR: THIR是一种基于拓扑数据分析的无监督医学图像检索框架，通过提取图像的拓扑指纹实现高效检索，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是全球女性健康的重要威胁，早期诊断和准确临床决策对减少其负担至关重要。现有深度学习方法依赖大量标注数据和GPU资源，因此需要一种无需监督的高效检索方法。

Method: 利用立方持续同调（cubical persistence）从RGB组织病理学图像中提取拓扑指纹，生成紧凑且可解释的特征向量，通过计算这些拓扑描述符之间的距离进行相似性检索。

Result: 在BreaKHis数据集上的实验表明，THIR优于现有监督和无监督方法，并在标准CPU上20分钟内处理完整数据集。

Conclusion: THIR框架通过拓扑数据分析提供了一种快速、可扩展且无需训练的临床图像检索解决方案，显著优于现有方法。

Abstract: According to the World Health Organization, breast cancer claimed the lives of approximately 685,000 women in 2020. Early diagnosis and accurate clinical decision making are critical in reducing this global burden. In this study, we propose THIR, a novel Content-Based Medical Image Retrieval (CBMIR) framework that leverages topological data analysis specifically, Betti numbers derived from persistent homology to characterize and retrieve histopathological images based on their intrinsic structural patterns. Unlike conventional deep learning approaches that rely on extensive training, annotated datasets, and powerful GPU resources, THIR operates entirely without supervision. It extracts topological fingerprints directly from RGB histopathological images using cubical persistence, encoding the evolution of loops as compact, interpretable feature vectors. The similarity retrieval is then performed by computing the distances between these topological descriptors, efficiently returning the top-K most relevant matches.
  Extensive experiments on the BreaKHis dataset demonstrate that THIR outperforms state of the art supervised and unsupervised methods. It processes the entire dataset in under 20 minutes on a standard CPU, offering a fast, scalable, and training free solution for clinical image retrieval.

</details>


### [247] [HDW-SR: High-Frequency Guided Diffusion Model based on Wavelet Decomposition for Image Super-Resolution](https://arxiv.org/abs/2511.13175)
*Chao Yang,Boqian Zhang,Jinghao Xu,Guang Jiang*

Main category: cs.CV

TL;DR: HDW-SR是一种基于小波分解的高频引导扩散网络，通过改进扩散框架和引入小波变换，显著提升了单图像超分辨率中高频细节的恢复能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的单图像超分辨率方法在高频域引导不足，导致生成的精细细节模糊。为此，需要一种新的方法来增强高频信息恢复能力。

Method: 提出了一种基于小波分解的高频引导扩散网络（HDW-SR），取代了传统扩散框架中的U-Net主干网络。通过仅对残差图进行扩散处理，网络更专注于高频信息恢复。引入基于小波的下采样替代标准CNN下采样，实现多尺度频率分解，并通过稀疏交叉注意力机制实现高频子带与低频子带间的显式高频引导。设计了动态阈值块（DTB）来优化稀疏注意力过程中的高频选择。小波变换的可逆性确保了上采样过程中的低损特征重建。

Result: 实验表明，HDW-SR在超分辨率任务中具有竞争力，尤其在恢复精细图像细节方面表现突出。

Conclusion: HDW-SR在合成和真实数据集上均表现出色，尤其在恢复精细图像细节方面表现优异，证明了其在单图像超分辨率任务中的有效性。

Abstract: Diffusion-based methods have shown great promise in single image super-resolution (SISR); however, existing approaches often produce blurred fine details due to insufficient guidance in the high-frequency domain. To address this issue, we propose a High-Frequency Guided Diffusion Network based on Wavelet Decomposition (HDW-SR), which replaces the conventional U-Net backbone in diffusion frameworks. Specifically, we perform diffusion only on the residual map, allowing the network to focus more effectively on high-frequency information restoration. We then introduce wavelet-based downsampling in place of standard CNN downsampling to achieve multi-scale frequency decomposition, enabling sparse cross-attention between the high-frequency subbands of the pre-super-resolved image and the low-frequency subbands of the diffused image for explicit high-frequency guidance. Moreover, a Dynamic Thresholding Block (DTB) is designed to refine high-frequency selection during the sparse attention process. During upsampling, the invertibility of the wavelet transform ensures low-loss feature reconstruction. Experiments on both synthetic and real-world datasets demonstrate that HDW-SR achieves competitive super-resolution performance, excelling particularly in recovering fine-grained image details. The code will be available after acceptance.

</details>


### [248] [GenTract: Generative Global Tractography](https://arxiv.org/abs/2511.13183)
*Alec Sargood,Lemuel Puglisi,Elinor Thompson,Mirco Musolesi,Daniel C. Alexander*

Main category: cs.CV

TL;DR: GenTract是首个生成式全局纤维追踪模型，直接学习从dMRI数据生成流线，精度显著优于现有方法，尤其适用于低分辨率或噪声数据。


<details>
  <summary>Details</summary>
Motivation: 传统的局部纤维追踪方法容易因误差累积导致高假阳性率，而全局方法虽准确但计算成本高。GenTract旨在解决这些挑战。

Method: GenTract通过将纤维追踪任务转化为生成式任务，直接从dMRI数据生成完整且解剖学上合理的流线。研究比较了基于扩散和流匹配的两种范式。

Result: GenTract的精度比次优方法TractOracle高2.1倍，在低分辨率和噪声环境下表现尤为突出，优于最接近的竞争对手一个数量级。

Conclusion: GenTract作为一种生成式全局纤维追踪方法，在高分辨率研究数据和不完美的低分辨率数据上均表现出色，为全局纤维追踪提供了有前景的解决方案。

Abstract: Tractography is the process of inferring the trajectories of white-matter pathways in the brain from diffusion magnetic resonance imaging (dMRI). Local tractography methods, which construct streamlines by following local fiber orientation estimates stepwise through an image, are prone to error accumulation and high false positive rates, particularly on noisy or low-resolution data. In contrast, global methods, which attempt to optimize a collection of streamlines to maximize compatibility with underlying fiber orientation estimates, are computationally expensive. To address these challenges, we introduce GenTract, the first generative model for global tractography. We frame tractography as a generative task, learning a direct mapping from dMRI to complete, anatomically plausible streamlines. We compare both diffusion-based and flow matching paradigms and evaluate GenTract's performance against state-of-the-art baselines. Notably, GenTract achieves precision 2.1x higher than the next-best method, TractOracle. This advantage becomes even more pronounced in challenging low-resolution and noisy settings, where it outperforms the closest competitor by an order of magnitude. By producing tractograms with high precision on research-grade data while also maintaining reliability on imperfect, lower-resolution data, GenTract represents a promising solution for global tractography.

</details>


### [249] [Large Language Models Meet Extreme Multi-label Classification: Scaling and Multi-modal Framework](https://arxiv.org/abs/2511.13189)
*Diego Ortego,Marlon Rodríguez,Mario Almagro,Kunal Dahiya,David Jiménez,Juan C. SanMiguel*

Main category: cs.CV

TL;DR: ViXML框架结合视觉信息和大型解码器模型，显著提升XMC性能，最高提升8.21%。


<details>
  <summary>Details</summary>
Motivation: 探索如何有效利用大型解码器模型和视觉信息以提升XMC性能，同时保持计算效率。

Method: 提出Vision-enhanced eXtreme Multi-label Learning（ViXML）框架，结合大型解码器模型和视觉信息，通过单嵌入池化实现高效的多模态集成。

Result: ViXML在多个数据集上性能显著提升，最高在P@1指标上超越之前最佳方法8.21%，且代码已开源。

Conclusion: ViXML框架通过有效整合视觉信息和大型解码器模型，显著提升了极端多标签分类（XMC）的性能，并在计算效率与性能之间取得了平衡。

Abstract: Foundation models have revolutionized artificial intelligence across numerous domains, yet their transformative potential remains largely untapped in Extreme Multi-label Classification (XMC). Queries in XMC are associated with relevant labels from extremely large label spaces, where it is critical to strike a balance between efficiency and performance. Therefore, many recent approaches efficiently pose XMC as a maximum inner product search between embeddings learned from small encoder-only transformer architectures. In this paper, we address two important aspects in XMC: how to effectively harness larger decoder-only models, and how to exploit visual information while maintaining computational efficiency. We demonstrate that both play a critical role in XMC separately and can be combined for improved performance. We show that a few billion-size decoder can deliver substantial improvements while keeping computational overhead manageable. Furthermore, our Vision-enhanced eXtreme Multi-label Learning framework (ViXML) efficiently integrates foundation vision models by pooling a single embedding per image. This limits computational growth while unlocking multi-modal capabilities. Remarkably, ViXML with small encoders outperforms text-only decoder in most cases, showing that an image is worth billions of parameters. Finally, we present an extension of existing text-only datasets to exploit visual metadata and make them available for future benchmarking. Comprehensive experiments across four public text-only datasets and their corresponding image enhanced versions validate our proposals' effectiveness, surpassing previous state-of-the-art by up to +8.21\% in P@1 on the largest dataset. ViXML's code is available at https://github.com/DiegoOrtego/vixml.

</details>


### [250] [Video Spatial Reasoning with Object-Centric 3D Rollout](https://arxiv.org/abs/2511.13190)
*Haoran Tang,Meng Cao,Ruyang Liu,Xiaoxi Liang,Linglong Li,Ge Li,Xiaodan Liang*

Main category: cs.CV

TL;DR: OCR策略通过扰动3D几何对象并强制模型全局推理，显著提升视频空间推理能力，3B模型性能超越7B基线。


<details>
  <summary>Details</summary>
Motivation: 现有方法在视频空间推理中过于依赖查询锁定，忽略关键上下文线索。

Method: 通过结构化扰动选定的3D几何对象，并投影到2D空间，结合rollout-based训练流程优化空间推理轨迹。

Result: 3B参数模型在VSI-Bench上达到47.5%准确率，优于多个7B基线模型。

Conclusion: 提出的Object-Centric 3D Rollout (OCR)策略在动态3D场景中实现了更全面的空间推理，显著提升了模型性能。

Abstract: Recent advances in Multi-modal Large Language Models (MLLMs) have showcased remarkable capabilities in vision-language understanding. However, enabling robust video spatial reasoning-the ability to comprehend object locations, orientations, and inter-object relationships in dynamic 3D scenes-remains a key unsolved challenge. Existing approaches primarily rely on spatially grounded supervised fine-tuning or reinforcement learning, yet we observe that such models often exhibit query-locked reasoning, focusing narrowly on objects explicitly mentioned in the prompt while ignoring critical contextual cues. To address this limitation, we propose Object-Centric 3D Rollout (OCR), a novel strategy that introduces structured perturbations to the 3D geometry of selected objects during training. By degrading object-specific visual cues and projecting the altered geometry into 2D space, OCR compels the model to reason holistically across the entire scene. We further design a rollout-based training pipeline that jointly leverages vanilla and region-noisy videos to optimize spatial reasoning trajectories. Experiments demonstrate state-of-the-art performance: our 3B-parameter model achieves 47.5% accuracy on VSI-Bench, outperforming several 7B baselines. Ablations confirm OCR's superiority over prior rollout strategies (e.g., T-GRPO, NoisyRollout).

</details>


### [251] [Birth of a Painting: Differentiable Brushstroke Reconstruction](https://arxiv.org/abs/2511.13191)
*Ying Jiang,Jiayin Lu,Yunuo Chen,Yumeng He,Kui Wu,Yin Yang,Chenfanfu Jiang*

Main category: cs.CV

TL;DR: 提出了一种可微分笔触重建框架，结合贝塞尔笔触优化、风格化纹理生成和涂抹操作，实现了逼真且风格多样的数字绘画创作。


<details>
  <summary>Details</summary>
Motivation: 尽管生成模型在绘画合成方面取得了进展，但现有方法大多仅关注最终图像生成或基于补丁的过程模拟，缺乏明确的笔触结构，无法产生平滑、逼真的着色。

Method: 该框架首先通过并行可微分绘制渲染器优化单色和双色贝塞尔笔触，然后通过风格生成模块合成几何条件纹理。进一步引入了可微分涂抹操作符以实现自然的颜色混合和着色。采用从粗到细的优化策略，联合优化笔触几何、颜色和纹理。

Result: 在油画、水彩、墨水和数字绘画上的大量实验表明，该方法能够产生逼真且富有表现力的笔触重建、平滑的色调过渡和丰富的风格化外观。

Conclusion: 该研究提出了一种可微分的笔触重建框架，能够统一绘画、风格化纹理和涂抹过程，忠实地再现人类绘画-涂抹的循环。该方法在不同绘画风格下表现出色，提供了统一的模型用于富有表现力的数字绘画创作。

Abstract: Painting embodies a unique form of visual storytelling, where the creation process is as significant as the final artwork. Although recent advances in generative models have enabled visually compelling painting synthesis, most existing methods focus solely on final image generation or patch-based process simulation, lacking explicit stroke structure and failing to produce smooth, realistic shading. In this work, we present a differentiable stroke reconstruction framework that unifies painting, stylized texturing, and smudging to faithfully reproduce the human painting-smudging loop. Given an input image, our framework first optimizes single- and dual-color Bezier strokes through a parallel differentiable paint renderer, followed by a style generation module that synthesizes geometry-conditioned textures across diverse painting styles. We further introduce a differentiable smudge operator to enable natural color blending and shading. Coupled with a coarse-to-fine optimization strategy, our method jointly optimizes stroke geometry, color, and texture under geometric and semantic guidance. Extensive experiments on oil, watercolor, ink, and digital paintings demonstrate that our approach produces realistic and expressive stroke reconstructions, smooth tonal transitions, and richly stylized appearances, offering a unified model for expressive digital painting creation. See our project page for more demos: https://yingjiang96.github.io/DiffPaintWebsite/.

</details>


### [252] [Difficulty-Aware Label-Guided Denoising for Monocular 3D Object Detection](https://arxiv.org/abs/2511.13195)
*Soyul Lee,Seungmin Baek,Dongbo Min*

Main category: cs.CV

TL;DR: MonoDLGD是一种难度感知标签引导去噪框架，通过自适应扰动和重建标签提升单目3D目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 单目3D目标检测存在深度估计不准确的问题，且现有方法忽视实例级检测难度（如遮挡、距离和截断），导致性能不佳。

Method: 提出MonoDLGD框架，基于检测不确定性自适应扰动和重建真实标签，以提供明确的几何监督。

Result: 在KITTI基准测试中，MonoDLGD在所有难度级别上均达到最先进性能。

Conclusion: MonoDLGD通过联合优化标签重建和3D目标检测，实现了几何感知的表示学习，并在KITTI基准测试中展示了卓越的性能。

Abstract: Monocular 3D object detection is a cost-effective solution for applications like autonomous driving and robotics, but remains fundamentally ill-posed due to inherently ambiguous depth cues. Recent DETR-based methods attempt to mitigate this through global attention and auxiliary depth prediction, yet they still struggle with inaccurate depth estimates. Moreover, these methods often overlook instance-level detection difficulty, such as occlusion, distance, and truncation, leading to suboptimal detection performance. We propose MonoDLGD, a novel Difficulty-Aware Label-Guided Denoising framework that adaptively perturbs and reconstructs ground-truth labels based on detection uncertainty. Specifically, MonoDLGD applies stronger perturbations to easier instances and weaker ones into harder cases, and then reconstructs them to effectively provide explicit geometric supervision. By jointly optimizing label reconstruction and 3D object detection, MonoDLGD encourages geometry-aware representation learning and improves robustness to varying levels of object complexity. Extensive experiments on the KITTI benchmark demonstrate that MonoDLGD achieves state-of-the-art performance across all difficulty levels.

</details>


### [253] [Self-Supervised Ultrasound Screen Detection](https://arxiv.org/abs/2511.13197)
*Alberto Gomez,Jorge Oliveira,Ramon Casero,Agis Chartsias*

Main category: cs.CV

TL;DR: 自监督学习流程从超声监视器照片提取图像，解决了DICOM传输瓶颈，平衡准确率0.79。


<details>
  <summary>Details</summary>
Motivation: 解决DICOM传输的瓶颈问题，便于快速测试和原型开发新的算法。

Method: 提出了一种自监督学习的流程，用于从超声监视器的照片中提取图像。

Result: 在概念验证研究中，校正后的图像保留了足够的视觉保真度，用于心脏视图分类的平衡准确率为0.79。

Conclusion: 该方法通过自监督学习从超声监视器的照片中提取图像，有效解决了DICOM传输的瓶颈问题，并展示了在保留足够视觉保真度的前提下，可用于快速算法开发和测试。

Abstract: Ultrasound (US) machines display images on a built-in monitor, but routine transfer to hospital systems relies on DICOM. We propose a self-supervised pipeline to extract the US image from a photograph of the monitor. This removes the DICOM bottleneck and enables rapid testing and prototyping of new algorithms. In a proof-of-concept study, the rectified images retained enough visual fidelity to classify cardiac views with a balanced accuracy of 0.79 with respect to the native DICOMs.

</details>


### [254] [RefineVAD: Semantic-Guided Feature Recalibration for Weakly Supervised Video Anomaly Detection](https://arxiv.org/abs/2511.13204)
*Junhee Lee,ChaeBeen Bang,MyoungChul Kim,MyeongAh Cho*

Main category: cs.CV

TL;DR: RefineVAD通过时间动态和语义结构联合建模，提升弱监督视频异常检测性能，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法将异常事件视为单一类别，忽略了其多样化的语义和时间特性。受人类感知异常的启发，RefineVAD旨在通过联合解释时间运动模式和语义结构来改进检测。

Method: RefineVAD框架包含两个核心模块：MoTAR（运动感知时间注意力与重校准）和CORE（类别导向细化）。MoTAR通过基于Transformer的建模动态调整时间焦点，CORE则通过跨注意力将段级特征与可学习类别原型对齐。

Result: 在WVAD基准测试上的广泛实验验证了RefineVAD的有效性，强调了语义上下文对异常相关模式特征细化的重要性。

Conclusion: RefineVAD通过结合时间动态和语义结构，有效提升了弱监督视频异常检测的性能，证明了语义上下文在特征细化中的重要性。

Abstract: Weakly-Supervised Video Anomaly Detection aims to identify anomalous events using only video-level labels, balancing annotation efficiency with practical applicability. However, existing methods often oversimplify the anomaly space by treating all abnormal events as a single category, overlooking the diverse semantic and temporal characteristics intrinsic to real-world anomalies. Inspired by how humans perceive anomalies, by jointly interpreting temporal motion patterns and semantic structures underlying different anomaly types, we propose RefineVAD, a novel framework that mimics this dual-process reasoning. Our framework integrates two core modules. The first, Motion-aware Temporal Attention and Recalibration (MoTAR), estimates motion salience and dynamically adjusts temporal focus via shift-based attention and global Transformer-based modeling. The second, Category-Oriented Refinement (CORE), injects soft anomaly category priors into the representation space by aligning segment-level features with learnable category prototypes through cross-attention. By jointly leveraging temporal dynamics and semantic structure, explicitly models both "how" motion evolves and "what" semantic category it resembles. Extensive experiments on WVAD benchmark validate the effectiveness of RefineVAD and highlight the importance of integrating semantic context to guide feature refinement toward anomaly-relevant patterns.

</details>


### [255] [End-to-End Multi-Person Pose Estimation with Pose-Aware Video Transformer](https://arxiv.org/abs/2511.13208)
*Yonghui Yu,Jiahang Cai,Xun Wang,Wenwu Yang*

Main category: cs.CV

TL;DR: PAVE-Net是一种端到端多人视频姿态估计框架，通过姿态感知注意力机制提升跨帧关联准确性，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖检测、RoI裁剪和非极大值抑制等启发式操作，限制了准确性和效率，因此需要一种端到端的解决方案。

Method: 提出了Pose-Aware Video transformEr Network (PAVE-Net)，结合空间编码器和时空姿态解码器，并引入姿态感知注意力机制以实现跨帧的个体关联。

Result: PAVE-Net在PoseTrack2017上显著优于现有图像端到端方法，且效率显著提升。

Conclusion: PAVE-Net是一种完全端到端的多人视频姿态估计框架，通过消除启发式操作显著提升了准确性和效率，并在PoseTrack2017上实现了6.0 mAP的改进。

Abstract: Existing multi-person video pose estimation methods typically adopt a two-stage pipeline: detecting individuals in each frame, followed by temporal modeling for single-person pose estimation. This design relies on heuristic operations such as detection, RoI cropping, and non-maximum suppression (NMS), limiting both accuracy and efficiency. In this paper, we present a fully end-to-end framework for multi-person 2D pose estimation in videos, effectively eliminating heuristic operations. A key challenge is to associate individuals across frames under complex and overlapping temporal trajectories. To address this, we introduce a novel Pose-Aware Video transformEr Network (PAVE-Net), which features a spatial encoder to model intra-frame relations and a spatiotemporal pose decoder to capture global dependencies across frames. To achieve accurate temporal association, we propose a pose-aware attention mechanism that enables each pose query to selectively aggregate features corresponding to the same individual across consecutive frames.Additionally, we explicitly model spatiotemporal dependencies among pose keypoints to improve accuracy. Notably, our approach is the first end-to-end method for multi-frame 2D human pose estimation.Extensive experiments show that PAVE-Net substantially outperforms prior image-based end-to-end methods, achieving a \textbf{6.0} mAP improvement on PoseTrack2017, and delivers accuracy competitive with state-of-the-art two-stage video-based approaches, while offering significant gains in efficiency.Project page: https://github.com/zgspose/PAVENet

</details>


### [256] [3DAlign-DAER: Dynamic Attention Policy and Efficient Retrieval Strategy for Fine-grained 3D-Text Alignment at Scale](https://arxiv.org/abs/2511.13211)
*Yijia Fan,Jusheng Zhang,Kaitong Cai,Jing Yang,Jian Wang,Keze Wang*

Main category: cs.CV

TL;DR: 3DAlign-DAER通过动态注意力策略和高效检索策略，提升了3D与文本的细粒度对齐性能，适用于大规模数据库。


<details>
  <summary>Details</summary>
Motivation: 现有方法在细粒度文本语义与3D几何结构对齐方面表现不佳，且在大规模3D数据库中性能下降。

Method: 提出了动态注意力策略（DAP）和高效检索策略（ERS），其中DAP通过分层注意力融合模块和蒙特卡洛树搜索优化注意力权重，ERS则通过分层搜索提升检索效率。

Result: 3DAlign-DAER在多样化的跨模态检索和分类任务中表现出色，并在大规模数据集Align3D-2M上验证了其性能。

Conclusion: 3DAlign-DAER通过动态注意力策略和高效检索策略，显著提升了3D几何与文本的细粒度对齐性能，并在大规模3D数据库中表现出色。

Abstract: Despite recent advancements in 3D-text cross-modal alignment, existing state-of-the-art methods still struggle to align fine-grained textual semantics with detailed geometric structures, and their alignment performance degrades significantly when scaling to large-scale 3D databases. To overcome this limitation, we introduce 3DAlign-DAER, a unified framework designed to align text and 3D geometry via the proposed dynamic attention policy and the efficient retrieval strategy, capturing subtle correspondences for diverse cross-modal retrieval and classification tasks. Specifically, during the training, our proposed dynamic attention policy (DAP) employs the Hierarchical Attention Fusion (HAF) module to represent the alignment as learnable fine-grained token-to-point attentions. To optimize these attentions across different tasks and geometric hierarchies, our DAP further exploits the Monte Carlo tree search to dynamically calibrate HAF attention weights via a hybrid reward signal and further enhances the alignment between textual descriptions and local 3D geometry. During the inference, our 3DAlign-DAER introduces an Efficient Retrieval Strategy (ERS) to leverage efficient hierarchical searching in the large-scale embedding spaces, outperforming traditional methods (e.g., KNN) in accuracy and efficiency. Furthermore, to facilitate text-3D alignment research and train our 3DAlign-DAER, we construct Align3D-2M, a large-scale dataset featuring 2M text-3D pairs, to provide sufficient fine-grained cross-modal annotations. Extensive and comprehensive experiments demonstrate the superior performance of our 3DAlign-DAER on diverse benchmarks. We will release our codes, models, and datasets.

</details>


### [257] [Hybrid-Domain Adaptative Representation Learning for Gaze Estimation](https://arxiv.org/abs/2511.13222)
*Qida Tan,Hongyu Yang,Wenchao Du*

Main category: cs.CV

TL;DR: HARL框架通过无监督域适配和稀疏图融合，提升了视线估计的跨域鲁棒性，在多个数据集上达到最先进性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法因视线无关因素（如表情、佩戴物、图像质量）干扰导致的跨域性能下降问题。

Method: 提出了一种混合域自适应表征学习（HARL）框架，结合无监督域适配和稀疏图融合模块，从多源混合数据集中学习鲁棒的视线表征。

Result: 在EyeDiap、MPIIFaceGaze和Gaze360数据集上分别达到5.02°、3.36°和9.26°的最先进准确度，并在跨数据集评估中表现出竞争力。

Conclusion: HARL框架通过混合域自适应表征学习，显著提升了跨域环境下的视线估计性能，实现了最先进的准确性。

Abstract: Appearance-based gaze estimation, aiming to predict accurate 3D gaze direction from a single facial image, has made promising progress in recent years. However, most methods suffer significant performance degradation in cross-domain evaluation due to interference from gaze-irrelevant factors, such as expressions, wearables, and image quality. To alleviate this problem, we present a novel Hybrid-domain Adaptative Representation Learning (shorted by HARL) framework that exploits multi-source hybrid datasets to learn robust gaze representation. More specifically, we propose to disentangle gaze-relevant representation from low-quality facial images by aligning features extracted from high-quality near-eye images in an unsupervised domain-adaptation manner, which hardly requires any computational or inference costs. Additionally, we analyze the effect of head-pose and design a simple yet efficient sparse graph fusion module to explore the geometric constraint between gaze direction and head-pose, leading to a dense and robust gaze representation. Extensive experiments on EyeDiap, MPIIFaceGaze, and Gaze360 datasets demonstrate that our approach achieves state-of-the-art accuracy of $\textbf{5.02}^{\circ}$ and $\textbf{3.36}^{\circ}$, and $\textbf{9.26}^{\circ}$ respectively, and present competitive performances through cross-dataset evaluation. The code is available at https://github.com/da60266/HARL.

</details>


### [258] [MRIQT: Physics-Aware Diffusion Model for Image Quality Transfer in Neonatal Ultra-Low-Field MRI](https://arxiv.org/abs/2511.13232)
*Malek Al Abed,Sebiha Demir,Anne Groteklaes,Elodie Germani,Shahrooz Faghihroohi,Hemmen Sabir,Shadi Albarqouni*

Main category: cs.CV

TL;DR: MRIQT通过3D条件扩散框架将超低场MRI图像质量提升至高场水平，结合物理模拟与感知损失，显著改善新生儿脑部成像诊断质量。


<details>
  <summary>Details</summary>
Motivation: 便携式超低场MRI（uLF-MRI）在新生儿护理中具有可及性优势，但其信噪比低且诊断质量较差，需提升至接近高场MRI水平。

Method: MRIQT结合了物理一致的K空间降级模拟、基于v预测的分类器自由引导稳定生成，以及SNR加权的3D感知损失以保证解剖保真度。

Result: MRIQT在PSNR指标上超越现有GAN和CNN方法15.3%，85%的生成结果被医生评为质量良好且病理清晰。

Conclusion: MRIQT实现了基于扩散模型的高保真增强便携式超低场（uLF）MRI，为新生儿脑部评估提供了可靠工具。

Abstract: Portable ultra-low-field MRI (uLF-MRI, 0.064 T) offers accessible neuroimaging for neonatal care but suffers from low signal-to-noise ratio and poor diagnostic quality compared to high-field (HF) MRI. We propose MRIQT, a 3D conditional diffusion framework for image quality transfer (IQT) from uLF to HF MRI. MRIQT combines realistic K-space degradation for physics-consistent uLF simulation, v-prediction with classifier-free guidance for stable image-to-image generation, and an SNR-weighted 3D perceptual loss for anatomical fidelity. The model denoises from a noised uLF input conditioned on the same scan, leveraging volumetric attention-UNet architecture for structure-preserving translation. Trained on a neonatal cohort with diverse pathologies, MRIQT surpasses recent GAN and CNN baselines in PSNR 15.3% with 1.78% over the state of the art, while physicians rated 85% of its outputs as good quality with clear pathology present. MRIQT enables high-fidelity, diffusion-based enhancement of portable ultra-low-field (uLF) MRI for deliable neonatal brain assessment.

</details>


### [259] [MMD-Thinker: Adaptive Multi-Dimensional Thinking for Multimodal Misinformation Detection](https://arxiv.org/abs/2511.13242)
*Junjie Wu,Guohong Fu*

Main category: cs.CV

TL;DR: 为解决通用MLLMs在多模态虚假信息检测中的局限性，提出MMD-Thinker框架，通过定制思维模式和强化学习提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 通用MLLMs在多模态虚假信息检测中存在推理不足和偏见的问题，无法应对快速演变的虚假信息。

Method: 提出了MMD-Thinker框架，包含定制化思维模式设计、任务特定指令调优及强化学习策略。

Result: MMD-Thinker在多个基准数据集上取得了最先进的性能，并保持了灵活的推理和令牌使用效率。

Conclusion: MMD-Thinker通过自适应多维思维框架显著提升了多模态虚假信息检测的性能，并在实验中证明了其优越性。

Abstract: Multimodal misinformation floods on various social media, and continues to evolve in the era of AI-generated content (AIGC). The emerged misinformation with low creation cost and high deception poses significant threats to society. While recent studies leverage general-purpose multimodal large language models (MLLMs) to achieve remarkable results in detection, they encounter two critical limitations: (1) Insufficient reasoning, where general-purpose MLLMs often follow the uniform reasoning paradigm but generate inaccurate explanations and judgments, due to the lack of the task-specific knowledge of multimodal misinformation detection. (2) Reasoning biases, where a single thinking mode make detectors a suboptimal path for judgment, struggling to keep pace with the fast-growing and intricate multimodal misinformation. In this paper, we propose MMD-Thinker, a two-stage framework for multimodal misinformation detection through adaptive multi-dimensional thinking. First, we develop tailor-designed thinking mode for multimodal misinformation detection. Second, we adopt task-specific instruction tuning to inject the tailored thinking mode into general-purpose MLLMs. Third, we further leverage reinforcement learning strategy with a mixed advantage function, which incentivizes the reasoning capabilities in trajectories. Furthermore, we construct the multimodal misinformation reasoning (MMR) dataset, encompasses more than 8K image-text pairs with both reasoning processes and classification labels, to make progress in the relam of multimodal misinformation detection. Experimental results demonstrate that our proposed MMD-Thinker achieves state-of-the-art performance on both in-domain and out-of-domain benchmark datasets, while maintaining flexible inference and token usage. Code will be publicly available at Github.

</details>


### [260] [Referring Camouflaged Object Detection With Multi-Context Overlapped Windows Cross-Attention](https://arxiv.org/abs/2511.13249)
*Yu Wen,Shuyong Gao,Shuping Zhang,Miao Huang,Lili Tao,Han Yang,Haozhe Xing,Lihe Zhang,Boxue Hou*

Main category: cs.CV

TL;DR: 本文提出RFMNet，通过多阶段编码特征交互融合和局部注意力机制，显著提升伪装目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究将参考图像转化为一维提示，但未能充分利用丰富的显著图像特征与伪装特征的融合潜力。

Method: 设计了多阶段特征交互融合的RFMNet，引入重叠窗口交叉注意力机制和参考特征聚合模块（RFA）。

Result: 在Ref-COD基准测试中取得了最先进的性能。

Conclusion: RFMNet通过局部特征融合和渐进式解码，显著提升了伪装目标检测的准确性和鲁棒性。

Abstract: Referring camouflaged object detection (Ref-COD) aims to identify hidden objects by incorporating reference information such as images and text descriptions. Previous research has transformed reference images with salient objects into one-dimensional prompts, yielding significant results. We explore ways to enhance performance through multi-context fusion of rich salient image features and camouflaged object features. Therefore, we propose RFMNet, which utilizes features from multiple encoding stages of the reference salient images and performs interactive fusion with the camouflage features at the corresponding encoding stages. Given that the features in salient object images contain abundant object-related detail information, performing feature fusion within local areas is more beneficial for detecting camouflaged objects. Therefore, we propose an Overlapped Windows Cross-attention mechanism to enable the model to focus more attention on the local information matching based on reference features. Besides, we propose the Referring Feature Aggregation (RFA) module to decode and segment the camouflaged objects progressively. Extensive experiments on the Ref-COD benchmark demonstrate that our method achieves state-of-the-art performance.

</details>


### [261] [Building Egocentric Procedural AI Assistant: Methods, Benchmarks, and Challenges](https://arxiv.org/abs/2511.13261)
*Junlong Li,Huaiyuan Xu,Sijie Cheng,Kejun Wu,Kim-Hui Yap,Lap-Pui Chau,Yi Wang*

Main category: cs.CV

TL;DR: 提出了EgoProceAssist，一个基于VLM的第一人称程序性AI助手框架，涵盖错误检测、学习和问答任务，并通过实验评估现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 基于视觉语言模型（VLM）和第一人称感知研究的进展，旨在开发一个专注于日常程序性任务的AI助手。

Method: 通过综述现有技术、相关数据集和评估指标，识别了三个核心任务：错误检测、程序性学习和问答。随后设计实验评估代表性VLM方法。

Result: 提出了EgoProceAssist的框架，并通过实验揭示了当前VLM方法在相关任务中的表现和不足。

Conclusion: 本研究提出了EgoProceAssist的概念，并探讨了其在日常程序性任务中的应用潜力。通过实验和评估，指出了当前VLM方法的局限性，并提出了未来研究方向。

Abstract: Driven by recent advances in vision language models (VLMs) and egocentric perception research, we introduce the concept of an egocentric procedural AI assistant (EgoProceAssist) tailored to step-by-step support daily procedural tasks in a first-person view. In this work, we start by identifying three core tasks: egocentric procedural error detection, egocentric procedural learning, and egocentric procedural question answering. These tasks define the essential functions of EgoProceAssist within a new taxonomy. Specifically, our work encompasses a comprehensive review of current techniques, relevant datasets, and evaluation metrics across these three core areas. To clarify the gap between the proposed EgoProceAssist and existing VLM-based AI assistants, we introduce novel experiments and provide a comprehensive evaluation of representative VLM-based methods. Based on these findings and our technical analysis, we discuss the challenges ahead and suggest future research directions. Furthermore, an exhaustive list of this study is publicly available in an active repository that continuously collects the latest work: https://github.com/z1oong/Building-Egocentric-Procedural-AI-Assistant

</details>


### [262] [Is your VLM Sky-Ready? A Comprehensive Spatial Intelligence Benchmark for UAV Navigation](https://arxiv.org/abs/2511.13269)
*Lingfeng Zhang,Yuchen Zhang,Hongsheng Li,Haoxiang Fu,Yingbo Tang,Hangjun Ye,Long Chen,Xiaojun Liang,Xiaoshuai Hao,Wenbo Ding*

Main category: cs.CV

TL;DR: 该论文提出了SpatialSky-Bench基准和Sky-VLM模型，专门评估和提升视觉语言模型在无人机导航中的空间智能能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLM）在无人机场景中的空间智能能力未被充分探索，存在导航和动态环境理解的局限性。

Method: 提出了SpatialSky-Bench基准和SpatialSky-Dataset数据集，并开发了专为无人机空间推理设计的Sky-VLM模型。

Result: 实验结果表明，Sky-VLM在所有基准任务中表现最佳，显著提升了无人机导航中的空间推理能力。

Conclusion: Sky-VLM在无人机空间推理任务中达到了最先进的性能，为适合无人机场景的VLM发展铺平了道路。

Abstract: Vision-Language Models (VLMs), leveraging their powerful visual perception and reasoning capabilities, have been widely applied in Unmanned Aerial Vehicle (UAV) tasks. However, the spatial intelligence capabilities of existing VLMs in UAV scenarios remain largely unexplored, raising concerns about their effectiveness in navigating and interpreting dynamic environments. To bridge this gap, we introduce SpatialSky-Bench, a comprehensive benchmark specifically designed to evaluate the spatial intelligence capabilities of VLMs in UAV navigation. Our benchmark comprises two categories-Environmental Perception and Scene Understanding-divided into 13 subcategories, including bounding boxes, color, distance, height, and landing safety analysis, among others. Extensive evaluations of various mainstream open-source and closed-source VLMs reveal unsatisfactory performance in complex UAV navigation scenarios, highlighting significant gaps in their spatial capabilities. To address this challenge, we developed the SpatialSky-Dataset, a comprehensive dataset containing 1M samples with diverse annotations across various scenarios. Leveraging this dataset, we introduce Sky-VLM, a specialized VLM designed for UAV spatial reasoning across multiple granularities and contexts. Extensive experimental results demonstrate that Sky-VLM achieves state-of-the-art performance across all benchmark tasks, paving the way for the development of VLMs suitable for UAV scenarios. The source code is available at https://github.com/linglingxiansen/SpatialSKy.

</details>


### [263] [Recognition of Abnormal Events in Surveillance Videos using Weakly Supervised Dual-Encoder Models](https://arxiv.org/abs/2511.13276)
*Noam Tsfaty,Avishai Weizman,Liav Cohen,Moshe Tshuva,Yehudit Aperstein*

Main category: cs.CV

TL;DR: 双主干框架结合卷积和Transformer，通过top-k池化在视频级监督下检测异常，UCF-Crime上AUC达90.7%。


<details>
  <summary>Details</summary>
Motivation: 解决在仅使用视频级监督的情况下，检测监控视频中罕见和多样化异常行为的挑战。

Method: 采用双主干框架，结合卷积和Transformer表示，并通过top-k池化技术整合特征。

Result: 在UCF-Crime数据集上实现了90.7%的AUC。

Conclusion: 该论文提出的双主干框架通过结合卷积和Transformer表示，在视频级监督下有效检测罕见和多样化的异常行为，达到了90.7%的AUC性能。

Abstract: We address the challenge of detecting rare and diverse anomalies in surveillance videos using only video-level supervision. Our dual-backbone framework combines convolutional and transformer representations through top-k pooling, achieving 90.7% area under the curve (AUC) on the UCF-Crime dataset.

</details>


### [264] [SF-Recon: Simplification-Free Lightweight Building Reconstruction via 3D Gaussian Splatting](https://arxiv.org/abs/2511.13278)
*Zihan Li,Tengfei Wang,Wentian Gan,Hao Zhan,Xin Wang,Zongqian Zhan*

Main category: cs.CV

TL;DR: SF-Recon直接从多视角图像重建轻量级建筑表面模型，避免了繁琐的网格简化步骤，通过3D高斯散射场和优化步骤实现高效重建。


<details>
  <summary>Details</summary>
Motivation: 轻量级建筑表面模型对数字城市、导航和快速地理空间分析至关重要，但传统的多视角几何流程依赖密集重建、网格化和后续简化，过程繁琐且对质量敏感。

Method: 该方法通过训练初始的3D高斯散射场，利用法线梯度引导的高斯优化和多视角边缘一致性剪枝，最终通过多视角深度约束的Delaunay三角剖分生成轻量级建筑网格。

Result: 实验结果表明，SF-Recon能够直接从多视角图像重建轻量级建筑模型，显著减少了面和顶点的数量，同时保持了计算效率。

Conclusion: SF-Recon能够直接从多视角图像重建轻量级建筑表面模型，显著减少了面和顶点的数量，同时保持了计算效率。

Abstract: Lightweight building surface models are crucial for digital city, navigation, and fast geospatial analytics, yet conventional multi-view geometry pipelines remain cumbersome and quality-sensitive due to their reliance on dense reconstruction, meshing, and subsequent simplification. This work presents SF-Recon, a method that directly reconstructs lightweight building surfaces from multi-view images without post-hoc mesh simplification. We first train an initial 3D Gaussian Splatting (3DGS) field to obtain a view-consistent representation. Building structure is then distilled by a normal-gradient-guided Gaussian optimization that selects primitives aligned with roof and wall boundaries, followed by multi-view edge-consistency pruning to enhance structural sharpness and suppress non-structural artifacts without external supervision. Finally, a multi-view depth-constrained Delaunay triangulation converts the structured Gaussian field into a lightweight, structurally faithful building mesh. Based on a proposed SF dataset, the experimental results demonstrate that our SF-Recon can directly reconstruct lightweight building models from multi-view imagery, achieving substantially fewer faces and vertices while maintaining computational efficiency. Website:https://lzh282140127-cell.github.io/SF-Recon-project/

</details>


### [265] [Towards Metric-Aware Multi-Person Mesh Recovery by Jointly Optimizing Human Crowd in Camera Space](https://arxiv.org/abs/2511.13282)
*Kaiwen Wang,Kaili Zheng,Yiming Shi,Chenyi Guo,Ji Wu*

Main category: cs.CV

TL;DR: 本文提出DTO方法和Metric-Aware HMR网络，解决了多人网格恢复中的场景一致性和度量尺度问题，构建了大规模数据集并实现了最优性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有单中心伪地面真值生成方法缺乏场景一致性，导致多人图像中深度和尺度冲突的问题。

Method: 提出了Depth-conditioned Translation Optimization (DTO)方法和Metric-Aware HMR网络，结合人类高度先验和单目深度估计器，优化多人场景中的深度和尺度一致性。

Result: 在4D-Humans数据集上构建了DTO-Humans数据集（0.56M高质量图像），并在相对深度推理和人体网格恢复任务中达到最先进性能。

Conclusion: 通过DTO-Humans数据集和Metric-Aware HMR方法，本文在多人网格恢复任务中实现了场景一致性和度量尺度准确性，达到了最先进的性能。

Abstract: Multi-person human mesh recovery from a single image is a challenging task, hindered by the scarcity of in-the-wild training data. Prevailing in-the-wild human mesh pseudo-ground-truth (pGT) generation pipelines are single-person-centric, where each human is processed individually without joint optimization. This oversight leads to a lack of scene-level consistency, producing individuals with conflicting depths and scales within the same image. To address this, we introduce Depth-conditioned Translation Optimization (DTO), a novel optimization-based method that jointly refines the camera-space translations of all individuals in a crowd. By leveraging anthropometric priors on human height and depth cues from a monocular depth estimator, DTO solves for a scene-consistent placement of all subjects within a principled Maximum a posteriori (MAP) framework. Applying DTO to the 4D-Humans dataset, we construct DTO-Humans, a new large-scale pGT dataset of 0.56M high-quality, scene-consistent multi-person images, featuring dense crowds with an average of 4.8 persons per image. Furthermore, we propose Metric-Aware HMR, an end-to-end network that directly estimates human mesh and camera parameters in metric scale. This is enabled by a camera branch and a novel relative metric loss that enforces plausible relative scales. Extensive experiments demonstrate that our method achieves state-of-the-art performance on relative depth reasoning and human mesh recovery. Code and data will be released publicly.

</details>


### [266] [TabFlash: Efficient Table Understanding with Progressive Question Conditioning and Token Focusing](https://arxiv.org/abs/2511.13283)
*Jongha Kim,Minseong Bae,Sanghyeok Lee,Jinsung Yoon,Hyunwoo J. Kim*

Main category: cs.CV

TL;DR: TabFlash 通过问题感知特征生成和令牌剪枝策略，显著提升表格理解效率与效果。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM方法忽视了表格图像的特殊性（如冗余背景和问题特定焦点），导致视觉表示冗余且低效。

Method: 提出渐进式问题条件注入、剪枝策略去除冗余背景令牌，以及令牌聚焦训练策略以保留关键信息。

Result: TabFlash 在表格理解任务中达到最先进性能，计算量减少27%，内存使用降低30%。

Conclusion: TabFlash 结合渐进式问题条件、剪枝策略和令牌聚焦，实现了高效且有效的表格理解，性能优于现有MLLM，同时降低了计算和内存消耗。

Abstract: Table images present unique challenges for effective and efficient understanding due to the need for question-specific focus and the presence of redundant background regions. Existing Multimodal Large Language Model (MLLM) approaches often overlook these characteristics, resulting in uninformative and redundant visual representations. To address these issues, we aim to generate visual features that are both informative and compact to improve table understanding. We first propose progressive question conditioning, which injects the question into Vision Transformer layers with gradually increasing frequency, considering each layer's capacity to handle additional information, to generate question-aware visual features. To reduce redundancy, we introduce a pruning strategy that discards background tokens, thereby improving efficiency. To mitigate information loss from pruning, we further propose token focusing, a training strategy that encourages the model to concentrate essential information in the retained tokens. By combining these approaches, we present TabFlash, an efficient and effective MLLM for table understanding. TabFlash achieves state-of-the-art performance, outperforming both open-source and proprietary MLLMs, while requiring 27% less FLOPs and 30% less memory usage compared to the second-best MLLM.

</details>


### [267] [SkyReels-Text: Fine-grained Font-Controllable Text Editing for Poster Design](https://arxiv.org/abs/2511.13285)
*Yunjie Yu,Jingchen Wu,Junchen Zhu,Chunze Lin,Guibin Chen*

Main category: cs.CV

TL;DR: SkyReels-Text是一种字体可控的海报文本编辑框架，无需字体标签或微调，支持多文本区域同时编辑，并在多个数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决现代图像编辑模型在细粒度、字体感知的文本编辑上的不足，提升专业设计工作流的效率。

Method: 提出了一种新颖的字体可控框架SkyReels-Text，支持同时对多个文本区域进行编辑，每个区域可以保持不同的排版风格，且无需字体标签或微调。

Result: 在多个数据集上，包括手写文本基准测试中，SkyReels-Text在文本保真度和视觉真实感方面达到了最先进的性能。

Conclusion: SkyReels-Text填补了通用图像编辑与专业排版设计之间的鸿沟，为海报文本编辑提供了前所未有的字体控制和视觉真实感。

Abstract: Artistic design such as poster design often demands rapid yet precise modification of textual content while preserving visual harmony and typographic intent, especially across diverse font styles. Although modern image editing models have grown increasingly powerful, they still fall short in fine-grained, font-aware text manipulation, limiting their utility in professional design workflows such as poster editing. To address this issue, we present SkyReels-Text, a novel font-controllable framework for precise poster text editing. Our method enables simultaneous editing of multiple text regions, each rendered in distinct typographic styles, while preserving the visual appearance of non-edited regions. Notably, our model requires neither font labels nor fine-tuning during inference: users can simply provide cropped glyph patches corresponding to their desired typography, even if the font is not included in any standard library. Extensive experiments on multiple datasets, including handwrittent text benchmarks, SkyReels-Text achieves state-of-the-art performance in both text fidelity and visual realism, offering unprecedented control over font families, and stylistic nuances. This work bridges the gap between general-purpose image editing and professional-grade typographic design.

</details>


### [268] [CorrectAD: A Self-Correcting Agentic System to Improve End-to-end Planning in Autonomous Driving](https://arxiv.org/abs/2511.13297)
*Enhui Ma,Lijun Zhou,Tao Tang,Jiahuan Zhang,Junpeng Jiang,Zhan Zhang,Dong Han,Kun Zhan,Xueyang Zhang,XianPeng Lang,Haiyang Sun,Xia Zhou,Di Lin,Kaicheng Yu*

Main category: cs.CV

TL;DR: CorrectAD通过扩散模型和3D布局生成高保真数据，自动校正自动驾驶规划器的失败案例，显著提升安全性。


<details>
  <summary>Details</summary>
Motivation: 数据驱动方法的长尾问题（罕见但安全关键的失败案例）影响了端到端自动驾驶系统的鲁棒性。

Method: 引入PM-Agent模拟产品经理角色，制定数据需求；提出DriveSora生成与3D布局对齐的高保真视频数据；整合为自校正系统CorrectAD。

Result: 在nuScenes和内部数据集上，CorrectAD分别校正了62.5%和49.8%的失败案例，碰撞率降低39%和27%。

Conclusion: CorrectAD提出了一种模型无关的端到端自校正系统，通过扩散模型和3D布局结合，显著减少了自动驾驶规划器的失败案例和碰撞率。

Abstract: End-to-end planning methods are the de facto standard of the current autonomous driving system, while the robustness of the data-driven approaches suffers due to the notorious long-tail problem (i.e., rare but safety-critical failure cases). In this work, we explore whether recent diffusion-based video generation methods (a.k.a. world models), paired with structured 3D layouts, can enable a fully automated pipeline to self-correct such failure cases. We first introduce an agent to simulate the role of product manager, dubbed PM-Agent, which formulates data requirements to collect data similar to the failure cases. Then, we use a generative model that can simulate both data collection and annotation. However, existing generative models struggle to generate high-fidelity data conditioned on 3D layouts. To address this, we propose DriveSora, which can generate spatiotemporally consistent videos aligned with the 3D annotations requested by PM-Agent. We integrate these components into our self-correcting agentic system, CorrectAD. Importantly, our pipeline is an end-to-end model-agnostic and can be applied to improve any end-to-end planner. Evaluated on both nuScenes and a more challenging in-house dataset across multiple end-to-end planners, CorrectAD corrects 62.5% and 49.8% of failure cases, reducing collision rates by 39% and 27%, respectively.

</details>


### [269] [DriveLiDAR4D: Sequential and Controllable LiDAR Scene Generation for Autonomous Driving](https://arxiv.org/abs/2511.13309)
*Kaiwen Cai,Xinze Liu,Xia Zhou,Hengtong Hu,Jie Xiang,Luyao Zhang,Xueyang Zhang,Kun Zhan,Yifei Zhan,Xianpeng Lang*

Main category: cs.CV

TL;DR: DriveLiDAR4D是一种新型LiDAR生成管道，通过多模态条件和LiDAR4DNet模型，实现了时序一致的LiDAR场景生成，性能显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有3D LiDAR点云生成方法在序列生成能力和准确放置前景对象及真实背景方面存在不足。

Method: 提出了DriveLiDAR4D，一种包含多模态条件和新颖的序列噪声预测模型LiDAR4DNet的LiDAR生成管道。

Result: 在nuScenes数据集上，DriveLiDAR4D的FRD得分为743.13，FVD得分为16.96，性能分别提升了37.2%和24.1%。

Conclusion: DriveLiDAR4D在nuScenes和KITTI数据集上表现出色，显著超越了当前最佳方法UniScene的性能。

Abstract: The generation of realistic LiDAR point clouds plays a crucial role in the development and evaluation of autonomous driving systems. Although recent methods for 3D LiDAR point cloud generation have shown significant improvements, they still face notable limitations, including the lack of sequential generation capabilities and the inability to produce accurately positioned foreground objects and realistic backgrounds. These shortcomings hinder their practical applicability. In this paper, we introduce DriveLiDAR4D, a novel LiDAR generation pipeline consisting of multimodal conditions and a novel sequential noise prediction model LiDAR4DNet, capable of producing temporally consistent LiDAR scenes with highly controllable foreground objects and realistic backgrounds. To the best of our knowledge, this is the first work to address the sequential generation of LiDAR scenes with full scene manipulation capability in an end-to-end manner. We evaluated DriveLiDAR4D on the nuScenes and KITTI datasets, where we achieved an FRD score of 743.13 and an FVD score of 16.96 on the nuScenes dataset, surpassing the current state-of-the-art (SOTA) method, UniScene, with an performance boost of 37.2% in FRD and 24.1% in FVD, respectively.

</details>


### [270] [YOLO Meets Mixture-of-Experts: Adaptive Expert Routing for Robust Object Detection](https://arxiv.org/abs/2511.13344)
*Ori Meiraz,Sharon Shalev,Avishai Weizman*

Main category: cs.CV

TL;DR: 提出基于Mixture-of-Experts的YOLOv9-T框架，通过动态路由提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决单一模型在复杂场景下特征表达能力不足的问题，提升目标检测的精度和召回率。

Method: 采用Mixture-of-Experts框架，结合多个YOLOv9-T专家模型，通过自适应路由机制实现动态特征选择。

Result: 相比单一YOLOv9-T模型，新框架显著提升了平均精度（mAP）和平均召回率（AR）。

Conclusion: 论文提出了一种新颖的Mixture-of-Experts框架，通过自适应路由在多个YOLOv9-T专家模型之间实现动态特征专业化，相比单一YOLOv9-T模型，显著提升了平均精度（mAP）和平均召回率（AR）。

Abstract: This paper presents a novel Mixture-of-Experts framework for object detection, incorporating adaptive routing among multiple YOLOv9-T experts to enable dynamic feature specialization and achieve higher mean Average Precision (mAP) and Average Recall (AR) compared to a single YOLOv9-T model.

</details>


### [271] [What Color Is It? A Text-Interference Multimodal Hallucination Benchmark](https://arxiv.org/abs/2511.13400)
*Jinkun Zhao,Lei Huang,Wenjun Wu*

Main category: cs.CV

TL;DR: 论文发现多模态大模型在颜色感知中存在幻觉风险，通过新数据集验证并提出了增强鲁棒性的方法。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大模型在视觉感知（尤其是颜色感知）中易受信息干扰，增加了幻觉风险。

Method: 通过构建'What Color Is It'数据集，触发MLMs的单模态视觉幻觉，并分析其根本原因。

Result: 验证了视觉模态中的幻觉现象，并提出了改进方案。

Conclusion: 论文提出了增强多模态大模型（MLMs）在视觉模态中鲁棒性的潜在解决方案，并验证了颜色感知干扰对模型幻觉的影响。

Abstract: With the rapid advancement of Large Models, numerous text-and-vision-fused Multimodal Large Models (MLMs) have emerged. However, these MLMs remain susceptible to informational interference in visual perception, particularly in color perception, which introduces an additional risk of hallucination. To validate this hypothesis, we introduce the "What Color Is It" dataset, a novel benchmark constructed using a simple method to trigger single-modality visual hallucination in MLMs. Based on this dataset, we further investigate the underlying causes of hallucination in the visual modality of MLMs and propose potential solutions to enhance their robustness.

</details>


### [272] [Delineate Anything Flow: Fast, Country-Level Field Boundary Detection from Any Source](https://arxiv.org/abs/2511.13417)
*Mykola Lavreniuk,Nataliia Kussul,Andrii Shelestov,Yevhenii Salii,Volodymyr Kuzin,Sergii Skakun,Zoltan Szantoi*

Main category: cs.CV

TL;DR: DelAnyFlow是一种分辨率无关的方法，结合实例分割和结构化后处理，用于大规模农田边界划分，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 从卫星图像中准确划分农田边界对土地管理和作物监测至关重要，但现有方法常产生不完整的边界、合并相邻农田且难以扩展。

Method: DelAnyFlow结合了基于YOLOv11骨干的DelAny实例分割模型和结构化的后处理、合并和矢量化序列，以生成拓扑一致的矢量边界。该方法在FBIS 22M数据集上训练，这是同类数据集中最大的数据集。

Result: DelAny模型在mAP上比SAM2高出100%以上，推理速度快400倍。DelAnyFlow在乌克兰的应用中，仅用6小时就生成了完整的农田边界图层，显著提高了边界的完整性。

Conclusion: DelAnyFlow提供了一种可扩展且经济高效的方法，用于在缺乏数字地籍数据的区域进行农田边界划分。

Abstract: Accurate delineation of agricultural field boundaries from satellite imagery is essential for land management and crop monitoring, yet existing methods often produce incomplete boundaries, merge adjacent fields, and struggle to scale. We present the Delineate Anything Flow (DelAnyFlow) methodology, a resolution-agnostic approach for large-scale field boundary mapping. DelAnyFlow combines the DelAny instance segmentation model, based on a YOLOv11 backbone and trained on the large-scale Field Boundary Instance Segmentation-22M (FBIS 22M) dataset, with a structured post-processing, merging, and vectorization sequence to generate topologically consistent vector boundaries. FBIS 22M, the largest dataset of its kind, contains 672,909 multi-resolution image patches (0.25-10m) and 22.9million validated field instances. The DelAny model delivers state-of-the-art accuracy with over 100% higher mAP and 400x faster inference than SAM2. DelAny demonstrates strong zero-shot generalization and supports national-scale applications: using Sentinel 2 data for 2024, DelAnyFlow generated a complete field boundary layer for Ukraine (603,000km2) in under six hours on a single workstation. DelAnyFlow outputs significantly improve boundary completeness relative to operational products from Sinergise Solutions and NASA Harvest, particularly in smallholder and fragmented systems (0.25-1ha). For Ukraine, DelAnyFlow delineated 3.75M fields at 5m and 5.15M at 2.5m, compared to 2.66M detected by Sinergise Solutions and 1.69M by NASA Harvest. This work delivers a scalable, cost-effective methodology for field delineation in regions lacking digital cadastral data. A project landing page with links to model weights, code, national-scale vector outputs, and dataset is available at https://lavreniuk.github.io/Delineate-Anything/.

</details>


### [273] [VOPE: Revisiting Hallucination of Vision-Language Models in Voluntary Imagination Task](https://arxiv.org/abs/2511.13420)
*Xingming Long,Jie Zhang,Shiguang Shan,Xilin Chen*

Main category: cs.CV

TL;DR: VOPE评估LVLMs自愿想象任务中的幻觉，发现主流模型表现差且现有方法效果有限。


<details>
  <summary>Details</summary>
Motivation: 现有研究集中于禁止输出图像外内容的描述任务，忽视了自愿想象任务（如故事写作）中的幻觉评估，需新方法填补空白。

Method: 引入VOPE方法，通过重新检查式问题评估LVLMs对想象对象存在的解释，并依据与图像中对象存在的一致性判断幻觉。

Result: 主流LVLMs在自愿想象中普遍存在幻觉，且现有缓解方法效果不佳。

Conclusion: VOPE方法揭示了主流LVLMs在自愿想象任务中存在严重幻觉问题，且现有缓解方法效果有限，未来研究需重点关注。

Abstract: Most research on hallucinations in Large Vision-Language Models (LVLMs) focuses on factual description tasks that prohibit any output absent from the image. However, little attention has been paid to hallucinations in voluntary imagination tasks, e.g., story writing, where the models are expected to generate novel content beyond the given image. In these tasks, it is inappropriate to simply regard such imagined novel content as hallucinations. To address this limitation, we introduce Voluntary-imagined Object Presence Evaluation (VOPE)-a novel method to assess LVLMs' hallucinations in voluntary imagination tasks via presence evaluation. Specifically, VOPE poses recheck-based questions to evaluate how an LVLM interprets the presence of the imagined objects in its own response. The consistency between the model's interpretation and the object's presence in the image is then used to determine whether the model hallucinates when generating the response. We apply VOPE to several mainstream LVLMs and hallucination mitigation methods, revealing two key findings: (1) most LVLMs hallucinate heavily during voluntary imagination, and their performance in presence evaluation is notably poor on imagined objects; (2) existing hallucination mitigation methods show limited effect in voluntary imagination tasks, making this an important direction for future research.

</details>


### [274] [FUSE: A Flow-based Mapping Between Shapes](https://arxiv.org/abs/2511.13431)
*Lorenzo Olearo,Giulio Viganò,Daniele Baieri,Filippo Maggioli,Simone Melzi*

Main category: cs.CV

TL;DR: 提出一种基于流匹配的高效3D形状映射方法，支持跨模态匹配，无需大规模训练，在多个任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决传统3D形状映射方法在计算效率、跨表示匹配和大规模训练需求上的局限性。

Method: 通过将3D形状表示为从固定锚分布通过连续可逆流映射诱导的概率分布，结合源形状到锚的反向流与锚到目标形状的正向流，实现形状间的连续映射。使用点级任务定制嵌入编码形状，构建跨点云、网格、SDF和体积数据的可逆且模态无关的形状映射表示。

Result: 该方法在多样化的形状匹配基准和挑战性场景中均实现了高覆盖率和准确性，并在UV映射和人体点云扫描配准等任务中展现出潜力。

Conclusion: 该论文提出了一种基于流匹配模型的3D形状间映射的神经表示方法，该方法计算高效，支持跨表示形状匹配，且无需大规模训练或数据驱动过程。

Abstract: We introduce a novel neural representation for maps between 3D shapes based on flow-matching models, which is computationally efficient and supports cross-representation shape matching without large-scale training or data-driven procedures. 3D shapes are represented as the probability distribution induced by a continuous and invertible flow mapping from a fixed anchor distribution. Given a source and a target shape, the composition of the inverse flow (source to anchor) with the forward flow (anchor to target), we continuously map points between the two surfaces. By encoding the shapes with a pointwise task-tailored embedding, this construction provides an invertible and modality-agnostic representation of maps between shapes across point clouds, meshes, signed distance fields (SDFs), and volumetric data. The resulting representation consistently achieves high coverage and accuracy across diverse benchmarks and challenging settings in shape matching. Beyond shape matching, our framework shows promising results in other tasks, including UV mapping and registration of raw point cloud scans of human bodies.

</details>


### [275] [InterMoE: Individual-Specific 3D Human Interaction Generation via Dynamic Temporal-Selective MoE](https://arxiv.org/abs/2511.13488)
*Lipeng Wang,Hongxing Fan,Haohua Chen,Zehuan Huang,Lu Sheng*

Main category: cs.CV

TL;DR: InterMoE通过动态专家混合框架，解决了现有方法在保持个体特征和文本描述忠实度上的不足，显著提升了3D人类交互生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在保持个体独特特征和完全遵循文本描述方面存在不足，影响了虚拟现实和机器人应用中高质量人类交互的生成。

Method: 提出了基于动态时间选择性专家混合（Dynamic Temporal-Selective Mixture of Experts）的InterMoE框架，其核心是结合高层文本语义和低层运动上下文的路由机制。

Result: 实验表明，InterMoE在InterHuman数据集上FID分数降低了9%，在InterX上降低了22%，实现了最先进的性能。

Conclusion: InterMoE通过动态时间选择性专家混合框架，显著提升了3D人类交互生成的质量，保持了独特的个体特征并高度遵循文本描述。

Abstract: Generating high-quality human interactions holds significant value for applications like virtual reality and robotics. However, existing methods often fail to preserve unique individual characteristics or fully adhere to textual descriptions. To address these challenges, we introduce InterMoE, a novel framework built on a Dynamic Temporal-Selective Mixture of Experts. The core of InterMoE is a routing mechanism that synergistically uses both high-level text semantics and low-level motion context to dispatch temporal motion features to specialized experts. This allows experts to dynamically determine the selection capacity and focus on critical temporal features, thereby preserving specific individual characteristic identities while ensuring high semantic fidelity. Extensive experiments show that InterMoE achieves state-of-the-art performance in individual-specific high-fidelity 3D human interaction generation, reducing FID scores by 9% on the InterHuman dataset and 22% on InterX.

</details>


### [276] [Language-Guided Invariance Probing of Vision-Language Models](https://arxiv.org/abs/2511.13494)
*Jae Joong Lee*

Main category: cs.CV

TL;DR: LGIP基准测试评估了九种视觉语言模型的语言鲁棒性，发现EVA02-CLIP和OpenCLIP表现最佳，而SigLIP系列在语义翻转时表现较差。


<details>
  <summary>Details</summary>
Motivation: 探究现有视觉语言模型（如CLIP、OpenCLIP、EVA02-CLIP和SigLIP）在受控语言扰动下的鲁棒性。

Method: 通过自动生成40k MS COCO图像的释义和基于规则的语义翻转（如对象类别、颜色或数量的改变），并计算不变性误差、语义敏感性间隙和阳性率统计来评估模型行为。

Result: EVA02-CLIP和大型OpenCLIP变体在释义不变性和语义敏感性方面表现最佳，而SigLIP和SigLIP2在对象和颜色编辑中更倾向于翻转后的描述。

Conclusion: LGIP基准测试揭示了EVA02-CLIP和大型OpenCLIP变体在语言鲁棒性方面表现优越，而SigLIP和SigLIP2在语义翻转情况下表现不佳，这些缺陷在传统检索指标中难以察觉。

Abstract: Recent vision-language models (VLMs) such as CLIP, OpenCLIP, EVA02-CLIP and SigLIP achieve strong zero-shot performance, but it is unclear how reliably they respond to controlled linguistic perturbations. We introduce Language-Guided Invariance Probing (LGIP), a benchmark that measures (i) invariance to meaning-preserving paraphrases and (ii) sensitivity to meaning-changing semantic flips in image-text matching. Using 40k MS COCO images with five human captions each, we automatically generate paraphrases and rule-based flips that alter object category, color or count, and summarize model behavior with an invariance error, a semantic sensitivity gap and a positive-rate statistic.
  Across nine VLMs, EVA02-CLIP and large OpenCLIP variants lie on a favorable invariance-sensitivity frontier, combining low paraphrase-induced variance with consistently higher scores for original captions than for their flipped counterparts. In contrast, SigLIP and SigLIP2 show much larger invariance error and often prefer flipped captions to the human descriptions, especially for object and color edits. These failures are largely invisible to standard retrieval metrics, indicating that LGIP provides a model-agnostic diagnostic for the linguistic robustness of VLMs beyond conventional accuracy scores.

</details>


### [277] [Mapping the Vanishing and Transformation of Urban Villages in China](https://arxiv.org/abs/2511.13507)
*Wenyu Zhang,Yao Tong,Yiqiu Liu,Rui Cao*

Main category: cs.CV

TL;DR: 研究通过深度学习框架评估中国城市村落（UVs）再开发效果，发现再开发过程漫长、边缘地区为主，并揭示了三种转型路径，呼吁分层规划策略以支持可持续城市更新。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏对拆除土地是否有效再利用的系统评估，引发了对再开发实践效果和可持续性的担忧。

Method: 本研究提出了一种基于深度学习的框架，通过多时相遥感影像的语义分割来绘制UV边界变化，并将拆除后的土地利用分为六类：未完成拆除、闲置土地、建筑工地、建筑物、绿地和其他。研究选取了中国四个经济区域的代表性城市（广州、郑州、西安、哈尔滨）作为研究区域。

Result: 研究结果表明：1) UV再开发过程常常被延长；2) 再开发转变主要发生在边缘地区，而城市核心区相对稳定；3) 揭示了三种时空转型路径，即同步再开发、延迟再开发和逐步优化。

Conclusion: 本研究强调了城市村落（UVs）再开发的碎片化、复杂性和非线性，呼吁采用分层和因地制宜的规划策略。通过将空间动态与再开发政策背景结合，研究结果为支持更包容、高效和可持续的城市更新提供了宝贵的实证见解，并为全球非正规住区转型提供了更广泛的理解。

Abstract: Urban villages (UVs), informal settlements embedded within China's urban fabric, have undergone widespread demolition and redevelopment in recent decades. However, there remains a lack of systematic evaluation of whether the demolished land has been effectively reused, raising concerns about the efficacy and sustainability of current redevelopment practices. To address the gap, this study proposes a deep learning-based framework to monitor the spatiotemporal changes of UVs in China. Specifically, semantic segmentation of multi-temporal remote sensing imagery is first used to map evolving UV boundaries, and then post-demolition land use is classified into six categories based on the "remained-demolished-redeveloped" phase: incomplete demolition, vacant land, construction sites, buildings, green spaces, and others. Four representative cities from China's four economic regions were selected as the study areas, i.e., Guangzhou (East), Zhengzhou (Central), Xi'an (West), and Harbin (Northeast). The results indicate: 1) UV redevelopment processes were frequently prolonged; 2) redevelopment transitions primarily occurred in peripheral areas, whereas urban cores remained relatively stable; and 3) three spatiotemporal transformation pathways, i.e., synchronized redevelopment, delayed redevelopment, and gradual optimization, were revealed. This study highlights the fragmented, complex and nonlinear nature of UV redevelopment, underscoring the need for tiered and context-sensitive planning strategies. By linking spatial dynamics with the context of redevelopment policies, the findings offer valuable empirical insights that support more inclusive, efficient, and sustainable urban renewal, while also contributing to a broader global understanding of informal settlement transformations.

</details>


### [278] [Minimax Multi-Target Conformal Prediction with Applications to Imaging Inverse Problems](https://arxiv.org/abs/2511.13533)
*Jeffrey Wen,Rizwan Ahmad,Philip Schniter*

Main category: cs.CV

TL;DR: 提出一种多目标共形预测的渐近最小最大方法，确保联合边际覆盖并提供紧密预测区间，应用于图像质量评估等多任务场景，实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 在病态成像逆问题中，不确定性量化是一个关键挑战，尤其是在安全关键应用中。现有方法仅处理标量估计目标，而实际应用常涉及多个目标。

Method: 采用渐近最小最大方法处理多目标共形预测，应用于多度量盲图像质量评估、多任务不确定性量化和多轮测量采集。

Result: 数值实验证明，该方法在合成和MRI数据上优于现有多目标共形预测方法。

Conclusion: 本文提出了一种渐近最小最大方法，用于多目标共形预测，能够在保证联合边际覆盖的同时提供紧密的预测区间。该方法在合成和MRI数据上表现优于现有方法。

Abstract: In ill-posed imaging inverse problems, uncertainty quantification remains a fundamental challenge, especially in safety-critical applications. Recently, conformal prediction has been used to quantify the uncertainty that the inverse problem contributes to downstream tasks like image classification, image quality assessment, fat mass quantification, etc. While existing works handle only a scalar estimation target, practical applications often involve multiple targets. In response, we propose an asymptotically minimax approach to multi-target conformal prediction that provides tight prediction intervals while ensuring joint marginal coverage. We then outline how our minimax approach can be applied to multi-metric blind image quality assessment, multi-task uncertainty quantification, and multi-round measurement acquisition. Finally, we numerically demonstrate the benefits of our minimax method, relative to existing multi-target conformal prediction methods, using both synthetic and magnetic resonance imaging (MRI) data.

</details>


### [279] [Accuracy is Not Enough: Poisoning Interpretability in Federated Learning via Color Skew](https://arxiv.org/abs/2511.13535)
*Farhin Farhad Riya,Shahinul Hoque,Jinyuan Stella Sun,Olivera Kotevska*

Main category: cs.CV

TL;DR: 研究揭示了一种新型攻击，通过微小颜色扰动损害联邦学习模型的可解释性，但不影响准确性，挑战了正确预测即忠实解释的假设。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型在安全关键领域的部署增加，视觉解释技术成为支持透明性的重要工具。本研究揭示了一类新的攻击，这些攻击在不影响准确性的情况下损害模型的可解释性。

Method: 提出了一个称为Chromatic Perturbation Module的显着性感知攻击框架，通过改变前景和背景之间的颜色对比来系统地制作对抗样本，从而破坏解释的保真度。

Result: 攻击将Grad-CAM解释中的峰值激活重叠减少了35%，同时在所有评估的数据集上保持分类准确率超过96%。

Conclusion: 本研究挑战了模型审计中常见的假设，即正确预测意味着忠实解释，并证明可解释性本身可以成为攻击面。标准训练流程无法检测或缓解解释退化，特别是在联邦学习环境中。

Abstract: As machine learning models are increasingly deployed in safety-critical domains, visual explanation techniques have become essential tools for supporting transparency. In this work, we reveal a new class of attacks that compromise model interpretability without affecting accuracy. Specifically, we show that small color perturbations applied by adversarial clients in a federated learning setting can shift a model's saliency maps away from semantically meaningful regions while keeping the prediction unchanged. The proposed saliency-aware attack framework, called Chromatic Perturbation Module, systematically crafts adversarial examples by altering the color contrast between foreground and background in a way that disrupts explanation fidelity. These perturbations accumulate across training rounds, poisoning the global model's internal feature attributions in a stealthy and persistent manner. Our findings challenge a common assumption in model auditing that correct predictions imply faithful explanations and demonstrate that interpretability itself can be an attack surface. We evaluate this vulnerability across multiple datasets and show that standard training pipelines are insufficient to detect or mitigate explanation degradation, especially in the federated learning setting, where subtle color perturbations are harder to discern. Our attack reduces peak activation overlap in Grad-CAM explanations by up to 35% while preserving classification accuracy above 96% on all evaluated datasets.

</details>


### [280] [BootOOD: Self-Supervised Out-of-Distribution Detection via Synthetic Sample Exposure under Neural Collapse](https://arxiv.org/abs/2511.13539)
*Yuanchao Wang,Tian Qin,Eduardo Valle,Bruno Abrahao*

Main category: cs.CV

TL;DR: BootOOD是一种自监督OOD检测框架，通过生成伪OOD特征和基于特征范数的分类头，显著提升了对语义相似OOD样本的检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有OOD检测方法在ID与OOD样本语义相似时表现不佳的问题。

Method: BootOOD通过自监督学习框架，利用ID数据生成伪OOD特征，并引入基于特征范数的轻量级辅助分类头，实现OOD检测与主分类器的解耦。

Result: BootOOD在多个数据集上优于现有方法，且在不依赖异常暴露的情况下表现优异。

Conclusion: BootOOD在CIFAR-10、CIFAR-100和ImageNet-200等数据集上表现优于现有的后处理方法，甚至在不使用异常暴露的情况下超越了基于训练的方法，同时保持或提高了ID分类的准确性。

Abstract: Out-of-distribution (OOD) detection is critical for deploying image classifiers in safety-sensitive environments, yet existing detectors often struggle when OOD samples are semantically similar to the in-distribution (ID) classes. We present BootOOD, a fully self-supervised OOD detection framework that bootstraps exclusively from ID data and is explicitly designed to handle semantically challenging OOD samples. BootOOD synthesizes pseudo-OOD features through simple transformations of ID representations and leverages Neural Collapse (NC), where ID features cluster tightly around class means with consistent feature norms. Unlike prior approaches that aim to constrain OOD features into subspaces orthogonal to the collapsed ID means, BootOOD introduces a lightweight auxiliary head that performs radius-based classification on feature norms. This design decouples OOD detection from the primary classifier and imposes a relaxed requirement: OOD samples are learned to have smaller feature norms than ID features, which is easier to satisfy when ID and OOD are semantically close. Experiments on CIFAR-10, CIFAR-100, and ImageNet-200 show that BootOOD outperforms prior post-hoc methods, surpasses training-based methods without outlier exposure, and is competitive with state-of-the-art outlier-exposure approaches while maintaining or improving ID accuracy.

</details>


### [281] [TSE-Net: Semi-supervised Monocular Height Estimation from Single Remote Sensing Images](https://arxiv.org/abs/2511.13552)
*Sining Chen,Xiao Xiang Zhu*

Main category: cs.CV

TL;DR: TSE-Net是一种半监督学习的单目高度估计方法，通过教师-学生-考试网络框架利用未标注数据提升性能，并在多个数据集上验证了其效果。


<details>
  <summary>Details</summary>
Motivation: 单目高度估计在遥感3D感知中至关重要，但现有方法受限于标注数据的稀缺性和高成本。通过半监督学习框架利用未标注数据，可以提升模型性能。

Method: 提出了TSE-Net，一个包含教师、学生和考试网络的半监督学习框架。教师网络生成伪标签，学生网络利用伪标签训练，考试网络作为学生网络的时序集成以稳定性能。教师网络采用联合回归和分类模型，分类分支通过分层二分策略和Plackett-Luce模型校准伪标签质量。

Result: TSE-Net在三个不同分辨率和成像模态的数据集上进行了评估，证明了其有效性。代码已开源。

Conclusion: TSE-Net提出了一种半监督学习方法，通过整合教师、学生和考试网络，有效利用未标注数据提升单目高度估计的性能，并在多个数据集上验证了其有效性。

Abstract: Monocular height estimation plays a critical role in 3D perception for remote sensing, offering a cost-effective alternative to multi-view or LiDAR-based methods. While deep learning has significantly advanced the capabilities of monocular height estimation, these methods remain fundamentally limited by the availability of labeled data, which are expensive and labor-intensive to obtain at scale. The scarcity of high-quality annotations hinders the generalization and performance of existing models. To overcome this limitation, we propose leveraging large volumes of unlabeled data through a semi-supervised learning framework, enabling the model to extract informative cues from unlabeled samples and improve its predictive performance. In this work, we introduce TSE-Net, a self-training pipeline for semi-supervised monocular height estimation. The pipeline integrates teacher, student, and exam networks. The student network is trained on unlabeled data using pseudo-labels generated by the teacher network, while the exam network functions as a temporal ensemble of the student network to stabilize performance. The teacher network is formulated as a joint regression and classification model: the regression branch predicts height values that serve as pseudo-labels, and the classification branch predicts height value classes along with class probabilities, which are used to filter pseudo-labels. Height value classes are defined using a hierarchical bi-cut strategy to address the inherent long-tailed distribution of heights, and the predicted class probabilities are calibrated with a Plackett-Luce model to reflect the expected accuracy of pseudo-labels. We evaluate the proposed pipeline on three datasets spanning different resolutions and imaging modalities. Codes are available at https://github.com/zhu-xlab/tse-net.

</details>


### [282] [Opt3DGS: Optimizing 3D Gaussian Splatting with Adaptive Exploration and Curvature-Aware Exploitation](https://arxiv.org/abs/2511.13571)
*Ziyang Huang,Jiagang Chen,Jin Liu,Shunping Ji*

Main category: cs.CV

TL;DR: Opt3DGS通过两阶段优化提升3DGS渲染质量，避免局部最优并精准收敛。


<details>
  <summary>Details</summary>
Motivation: 3DGS在新颖视图合成中表现出色，但其优化过程存在局部最优陷阱和收敛质量不足的问题，亟需改进。

Method: Opt3DGS采用Adaptive Weighted SGLD方法进行全局搜索以避免局部最优，并使用Local Quasi-Newton Direction-guided Adam优化器利用曲率信息实现精确收敛。

Result: Opt3DGS在多个基准数据集上实现了最先进的渲染质量，且未改变3DGS的底层表示。

Conclusion: Opt3DGS通过两阶段优化过程（自适应探索和曲率引导利用）显著提升了3DGS的渲染质量，成为新颖视图合成领域的领先框架。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a leading framework for novel view synthesis, yet its core optimization challenges remain underexplored. We identify two key issues in 3DGS optimization: entrapment in suboptimal local optima and insufficient convergence quality. To address these, we propose Opt3DGS, a robust framework that enhances 3DGS through a two-stage optimization process of adaptive exploration and curvature-guided exploitation. In the exploration phase, an Adaptive Weighted Stochastic Gradient Langevin Dynamics (SGLD) method enhances global search to escape local optima. In the exploitation phase, a Local Quasi-Newton Direction-guided Adam optimizer leverages curvature information for precise and efficient convergence. Extensive experiments on diverse benchmark datasets demonstrate that Opt3DGS achieves state-of-the-art rendering quality by refining the 3DGS optimization process without modifying its underlying representation.

</details>


### [283] [Adaptive Multi-Scale Integration Unlocks Robust Cell Annotation in Histopathology Images](https://arxiv.org/abs/2511.13586)
*Yinuo Xu,Yan Cui,Mingyao Li,Zhi Huang*

Main category: cs.CV

TL;DR: NuClass是一个多尺度细胞分类框架，结合核形态和微环境上下文，通过不确定性引导优化学习，在缺乏高质量注释的情况下，利用空间转录组数据生成标记，显著提升了细胞类型和亚型识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于切片的模型能捕获详细的核形态，但常忽视影响细胞功能和身份的更广泛组织背景。此外，人类注释通常粗粒度且分布不均，难以获得细粒度亚型级监督。

Method: NuClass包含两个主要组件：Path local（关注224x224像素裁剪的核形态）和Path global（建模1024x1024像素的周围环境）。通过可学习的门控模块自适应平衡局部细节和上下文线索，并结合不确定性引导目标优化学习。

Result: 在三个完全保留的队列中评估，NuClass最佳类别的F1分数高达96%，优于强基线。

Conclusion: NuClass通过多尺度、不确定性感知的融合方法，成功填补了病理基础模型与细胞级表型预测之间的空白，展示了其在细胞类型和亚型识别中的高效性和可靠性。

Abstract: Identifying cell types and subtypes from routine histopathology images is essential for improving the computational understanding of human disease. Existing tile-based models can capture detailed nuclear morphology but often fail to incorporate the broader tissue context that influences a cell's function and identity. In addition, available human annotations are typically coarse-grained and unevenly distributed across studies, making fine-grained subtype-level supervision difficult to obtain.
  To address these limitations, we introduce NuClass, a pathologist workflow inspired framework for cell-wise multi-scale integration of nuclear morphology and microenvironmental context. NuClass includes two main components: Path local, which focuses on nuclear morphology from 224-by-224 pixel crops, and Path global, which models the surrounding 1024-by-1024 pixel neighborhood. A learnable gating module adaptively balances local detail and contextual cues. To encourage complementary learning, we incorporate an uncertainty-guided objective that directs the global path to prioritize regions where the local path is uncertain. We also provide calibrated confidence estimates and Grad-CAM visualizations to enhance interpretability.
  To overcome the lack of high-quality annotations, we construct a marker-guided dataset from Xenium spatial transcriptomics assays, yielding single-cell resolution labels for more than two million cells across eight organs and 16 classes. Evaluated on three fully held-out cohorts, NuClass achieves up to 96 percent F1 for its best-performing class, outperforming strong baselines. Our results show that multi-scale, uncertainty-aware fusion can bridge the gap between slide-level pathological foundation models and reliable, cell-level phenotype prediction.

</details>


### [284] [ICLR: Inter-Chrominance and Luminance Interaction for Natural Color Restoration in Low-Light Image Enhancement](https://arxiv.org/abs/2511.13607)
*Xin Xu,Hao Liu,Wei Liu,Wei Wang,Jiayi Wu,Kui Jiang*

Main category: cs.CV

TL;DR: ICLR框架通过DIEM和CCL模块优化色度与亮度交互，显著提升低光图像增强效果。


<details>
  <summary>Details</summary>
Motivation: 低光图像增强任务中，色度与亮度分支的分布差异限制了互补特征的提取，且传统像素级损失在弱相关区域易引发梯度冲突。

Method: 提出了一种双流交互增强模块（DIEM）和协方差校正损失（CCL），分别从融合和增强两个维度优化色度与亮度的交互。

Result: 在多数据集上的实验结果表明，ICLR框架超越了现有最优方法。

Conclusion: 提出的ICLR框架通过DIEM和CCL模块有效解决了低光图像增强中色度与亮度分支交互的分布差异问题，并在多个数据集上验证了其优越性。

Abstract: Low-Light Image Enhancement (LLIE) task aims at improving contrast while restoring details and textures for images captured in low-light conditions. HVI color space has made significant progress in this task by enabling precise decoupling of chrominance and luminance. However, for the interaction of chrominance and luminance branches, substantial distributional differences between the two branches prevalent in natural images limit complementary feature extraction, and luminance errors are propagated to chrominance channels through the nonlinear parameter. Furthermore, for interaction between different chrominance branches, images with large homogeneous-color regions usually exhibit weak correlation between chrominance branches due to concentrated distributions. Traditional pixel-wise losses exploit strong inter-branch correlations for co-optimization, causing gradient conflicts in weakly correlated regions. Therefore, we propose an Inter-Chrominance and Luminance Interaction (ICLR) framework including a Dual-stream Interaction Enhancement Module (DIEM) and a Covariance Correction Loss (CCL). The DIEM improves the extraction of complementary information from two dimensions, fusion and enhancement, respectively. The CCL utilizes luminance residual statistics to penalize chrominance errors and balances gradient conflicts by constraining chrominance branches covariance. Experimental results on multiple datasets show that the proposed ICLR framework outperforms state-of-the-art methods.

</details>


### [285] [AtlasMorph: Learning conditional deformable templates for brain MRI](https://arxiv.org/abs/2511.13609)
*Marianne Rakic,Andrew Hoopes,S. Mazdak Abulnaga,Mert R. Sabuncu,John V. Guttag,Adrian V. Dalca*

Main category: cs.CV

TL;DR: 提出一种基于卷积注册神经网络的机器学习框架，能高效生成针对特定人群的医学图像模板，提升注册和分割效果。


<details>
  <summary>Details</summary>
Motivation: 现有模板数量有限且常不具代表性，导致分析效果不佳，尤其是在人群差异大的情况下。

Method: 使用卷积注册神经网络学习一个函数，该函数能根据个体特定属性（如年龄和性别）输出模板，并利用可用的分割数据生成模板的解剖分割图。

Result: 在3D脑MRI数据集上验证了方法能生成高质量且具代表性的模板，带标注的条件模板在注册任务中表现优于无标注模板及其他构建方法。

Conclusion: 提出的机器学习框架能够高效生成针对特定人群特征的模板，且在注册和分割任务中表现优于现有方法。

Abstract: Deformable templates, or atlases, are images that represent a prototypical anatomy for a population, and are often enhanced with probabilistic anatomical label maps. They are commonly used in medical image analysis for population studies and computational anatomy tasks such as registration and segmentation. Because developing a template is a computationally expensive process, relatively few templates are available. As a result, analysis is often conducted with sub-optimal templates that are not truly representative of the study population, especially when there are large variations within this population. We propose a machine learning framework that uses convolutional registration neural networks to efficiently learn a function that outputs templates conditioned on subject-specific attributes, such as age and sex. We also leverage segmentations, when available, to produce anatomical segmentation maps for the resulting templates. The learned network can also be used to register subject images to the templates. We demonstrate our method on a compilation of 3D brain MRI datasets, and show that it can learn high-quality templates that are representative of populations. We find that annotated conditional templates enable better registration than their unlabeled unconditional counterparts, and outperform other templates construction methods.

</details>


### [286] [Tissue Aware Nuclei Detection and Classification Model for Histopathology Images](https://arxiv.org/abs/2511.13615)
*Kesi Xu,Eleni Chiou,Ali Varamesh,Laura Acqualagna,Nasir Rajpoot*

Main category: cs.CV

TL;DR: TAND是一种新型组织感知细胞检测框架，通过点级监督和组织掩码条件化，显著提升细胞检测与分类性能，减少标注负担。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于详细的专家标注且未能充分利用组织上下文，限制了细胞检测和分类的准确性。

Method: TAND采用基于ConvNeXt的编码器-解码器结构，结合冻结的Virchow-2组织分割分支，通过多尺度空间特征线性调制（Spatial-FiLM）选择性调节分类流。

Result: 在PUMA基准测试中，TAND超越了不依赖组织的基线方法和掩码监督方法，实现了最先进的性能，特别是在上皮、内皮和基质等组织依赖性细胞类型上表现出显著改进。

Conclusion: TAND框架通过结合组织掩码条件化和点级监督，显著降低了计算病理学中的标注负担，并在PUMA基准测试中实现了最先进的性能，特别是在组织依赖性细胞类型上表现出显著改进。

Abstract: Accurate nuclei detection and classification are fundamental to computational pathology, yet existing approaches are hindered by reliance on detailed expert annotations and insufficient use of tissue context. We present Tissue-Aware Nuclei Detection (TAND), a novel framework achieving joint nuclei detection and classification using point-level supervision enhanced by tissue mask conditioning. TAND couples a ConvNeXt-based encoder-decoder with a frozen Virchow-2 tissue segmentation branch, where semantic tissue probabilities selectively modulate the classification stream through a novel multi-scale Spatial Feature-wise Linear Modulation (Spatial-FiLM). On the PUMA benchmark, TAND achieves state-of-the-art performance, surpassing both tissue-agnostic baselines and mask-supervised methods. Notably, our approach demonstrates remarkable improvements in tissue-dependent cell types such as epithelium, endothelium, and stroma. To the best of our knowledge, this is the first method to condition per-cell classification on learned tissue masks, offering a practical pathway to reduce annotation burden.

</details>


### [287] [A Real-Time Driver Drowsiness Detection System Using MediaPipe and Eye Aspect Ratio](https://arxiv.org/abs/2511.13618)
*Ashlesha G. Sawant,Shreyash S. Kamble,Raj S. Kanade,Raunak N. Kanugo,Tanishq A. Kapse,Karan A. Bhapse*

Main category: cs.CV

TL;DR: 研究开发了基于面部特征（尤其是眼部）的驾驶员疲劳实时检测系统，通过EAR方法和MediaPipe框架实现高效识别，证实其可作为ADAS的组成部分。


<details>
  <summary>Details</summary>
Motivation: 驾驶员疲劳是导致交通事故的主要原因之一，每年造成大量伤亡。开发低成本、高性能的实时疲劳检测系统可显著提升道路安全。

Method: 使用标准网络摄像头结合MediaPipe的Face Mesh框架及OpenCV图像处理技术，通过眼宽高比（EAR）方法监测驾驶员眨眼频率和闭眼时长。

Result: 实验数据分析显示系统响应迅速且准确率高，验证了其在实时环境中的有效性。

Conclusion: 该系统通过高精度实时监测驾驶员眼部特征，有效识别疲劳状态，并通过声音警报提醒驾驶员，证实其可作为先进驾驶辅助系统（ADAS）的组成部分。

Abstract: One of the major causes of road accidents is driver fatigue that causes thousands of fatalities and injuries every year. This study shows development of a Driver Drowsiness Detection System meant to improve the safety of the road by alerting drivers who are showing signs of being drowsy. The system is based on a standard webcam that tracks the facial features of the driver with the main emphasis on the examination of eye movements that can be conducted with the help of the Eye Aspect Ratio (EAR) method. The Face Mesh by MediaPipe is a lightweight framework that can identify facial landmarks with high accuracy and efficiency, which is considered to be important in real time use. The system detects the moments of long eye shutdowns or a very low rate of blinking which are manifestations of drowsiness and alerts the driver through sound to get her attention back. This system achieves a high-performance and low-cost driver monitoring solution with the help of the computational power of OpenCV to process the image and the MediaPipe to identify faces. Test data experimental analyses indicate that the system is very accurate and responds quicker; this confirms that it can be a component of the current Advanced Driving Assistance System (ADAS).

</details>


### [288] [CacheFlow: Compressive Streaming Memory for Efficient Long-Form Video Understanding](https://arxiv.org/abs/2511.13644)
*Shrenik Patel,Daivik Patel*

Main category: cs.CV

TL;DR: CacheFlow通过动态令牌丢弃和压缩长期记忆，显著提升长视频问答效率，减少87%令牌处理，保持高精度。


<details>
  <summary>Details</summary>
Motivation: 解决当前视觉语言模型（VLMs）在处理长视频问答时因注意力机制和KV缓存随运行时间增长而导致的高昂推理成本或短视滑动窗口问题。

Method: 提出了CacheFlow，一种无需训练的流程，结合动态令牌丢弃（DTD）和压缩长期记忆。DTD通过余弦相似度在线修剪每帧令牌，并将存活的令牌打包成固定大小的块。这些块的键通过小型递归编码器总结形成检索索引，完整的KV对被卸载并在生成时重新加载。

Result: 在离线和流式VQA基准测试中，CacheFlow优于现有基线方法，同时处理令牌数量减少高达87%。

Conclusion: CacheFlow通过结合动态令牌丢弃（DTD）和压缩长期记忆，显著提升了长视频问答（VQA）的效率，同时保持了高精度，为实际长视频理解铺平了道路。

Abstract: Long-form video question answering (VQA) overwhelms current vision-language models (VLMs) because attention and key-value (KV) caches grow with runtime, forcing either expensive inference or near-sighted sliding windows. We introduce CacheFlow, a training-free pipeline that pairs Dynamic Token Dropping (DTD) with a compressive long-term memory. DTD prunes per-patch tokens online via cosine similarity to the previous frame, and surviving tokens are packed into fixed-size blocks. This online, per-frame processing makes our approach fundamentally suited for live streaming VQA. As blocks are processed, each one's keys are summarized by a tiny recurrent encoder to form a retrieval index, while the block's full KV pairs are offloaded and later rehydrated for generation, preserving answer fidelity. At inference, a consensus-based retrieval mechanism retrieves only the Top-K most relevant blocks and attends over both the retrieved and local context for precise, long-range reasoning. CacheFlow is drop-in, architecture-agnostic, and requires no fine-tuning. Experiments on both offline and streaming VQA benchmarks demonstrate that CacheFlow outperforms current strong baselines, while processing up to 87% less tokens. Our dual approach enables VLMs to be both efficient and context-aware, paving the way for practical long-form video understanding.

</details>


### [289] [Part-X-MLLM: Part-aware 3D Multimodal Large Language Model](https://arxiv.org/abs/2511.13647)
*Chunshi Wang,Junliang Ye,Yunhan Yang,Yang Li,Zizhuo Lin,Jun Zhu,Zhuo Chen,Yawei Luo,Chunchao Guo*

Main category: cs.CV

TL;DR: Part-X-MLLM 是一个统一的3D多模态大语言模型，通过结构化语法和语言原生前端简化多样化3D任务处理。


<details>
  <summary>Details</summary>
Motivation: 解决3D多模态任务中任务多样性与接口复杂性的问题，通过统一的编程语法和语言原生前端简化流程。

Method: 采用双编码器架构，预训练以解耦结构与语义，并在大规模部分中心数据集上进行指令微调。

Result: 模型能够生成高质量的结构化计划，在问答、组合生成和局部编辑等任务中达到了最先进的性能。

Conclusion: Part-X-MLLM 通过统一的、语言原生的前端实现了多样化的3D任务，展示了在多模态3D任务中的卓越性能。

Abstract: We introduce Part-X-MLLM, a native 3D multimodal large language model that unifies diverse 3D tasks by formulating them as programs in a structured, executable grammar. Given an RGB point cloud and a natural language prompt, our model autoregressively generates a single, coherent token sequence encoding part-level bounding boxes, semantic descriptions, and edit commands. This structured output serves as a versatile interface to drive downstream geometry-aware modules for part-based generation and editing. By decoupling the symbolic planning from the geometric synthesis, our approach allows any compatible geometry engine to be controlled through a single, language-native frontend. We pre-train a dual-encoder architecture to disentangle structure from semantics and instruction-tune the model on a large-scale, part-centric dataset. Experiments demonstrate that our model excels at producing high-quality, structured plans, enabling state-of-the-art performance in grounded Q\&A, compositional generation, and localized editing through one unified interface. Project page: https://chunshi.wang/Part-X-MLLM/

</details>


### [290] [Distribution Matching Distillation Meets Reinforcement Learning](https://arxiv.org/abs/2511.13649)
*Dengyang Jiang,Dongyang Liu,Zanyi Wang,Qilong Wu,Xin Jin,David Liu,Zhen Li,Mengmeng Wang,Peng Gao,Harry Yang*

Main category: cs.CV

TL;DR: DMDR结合强化学习提升少步蒸馏模型性能，超越多步教师模型。


<details>
  <summary>Details</summary>
Motivation: 为了解决少步蒸馏模型性能受限于预训练多步扩散模型的问题，提出结合强化学习技术以提升性能。

Method: 提出了DMDR框架，将强化学习技术融入蒸馏过程，设计了动态分布引导和动态重噪声采样训练策略。

Result: 实验表明，DMDR在视觉质量、提示连贯性方面领先于其他少步方法，甚至超越多步教师模型。

Conclusion: DMDR框架通过结合强化学习技术，成功提升了少步生成器的性能，甚至超越了多步教师模型的性能，同时在视觉质量和提示连贯性方面表现出色。

Abstract: Distribution Matching Distillation (DMD) distills a pre-trained multi-step diffusion model to a few-step one to improve inference efficiency. However, the performance of the latter is often capped by the former. To circumvent this dilemma, we propose DMDR, a novel framework that combines Reinforcement Learning (RL) techniques into the distillation process. We show that for the RL of the few-step generator, the DMD loss itself is a more effective regularization compared to the traditional ones. In turn, RL can help to guide the mode coverage process in DMD more effectively. These allow us to unlock the capacity of the few-step generator by conducting distillation and RL simultaneously. Meanwhile, we design the dynamic distribution guidance and dynamic renoise sampling training strategies to improve the initial distillation process. The experiments demonstrate that DMDR can achieve leading visual quality, prompt coherence among few-step methods, and even exhibit performance that exceeds the multi-step teacher.

</details>


### [291] [OlmoEarth: Stable Latent Image Modeling for Multimodal Earth Observation](https://arxiv.org/abs/2511.13655)
*Henry Herzog,Favyen Bastani,Yawen Zhang,Gabriel Tseng,Joseph Redmon,Hadrien Sablon,Ryan Park,Jacob Morrison,Alexandra Buraczynski,Karen Farley,Joshua Hansen,Andrew Howe,Patrick Alan Johnson,Mark Otterlee,Ted Schmitt,Hunter Pitelka,Stephen Daspit,Rachel Ratner,Christopher Wilhelm,Sebastian Wood,Mike Jacobi,Hannah Kerner,Evan Shelhamer,Ali Farhadi,Ranjay Krishna,Patrick Beukema*

Main category: cs.CV

TL;DR: OlmoEarth是一种针对地球观测数据设计的多模态时空基础模型，通过自监督学习实现了SOTA性能，并提供了一个端到端平台支持实际应用。


<details>
  <summary>Details</summary>
Motivation: 地球观测数据具有空间（如图像）、时序（如视频或文本）和多模态的独特挑战，需要一种新型的模型来处理这些复杂特性。

Method: OlmoEarth采用了一种新颖的自监督学习框架、掩码策略和损失函数设计，专门针对地球观测数据的多模态、时空特性。

Result: OlmoEarth在24个任务中的15个上表现最佳（嵌入评估），在29个任务中的19个上表现最佳（全微调），超越了12个其他基础模型。

Conclusion: OlmoEarth不仅在地球观测领域实现了最先进的性能，还通过其端到端平台为非营利组织和NGO提供了强大的数据管理和模型部署工具。

Abstract: Earth observation data presents a unique challenge: it is spatial like images, sequential like video or text, and highly multimodal. We present OlmoEarth: a multimodal, spatio-temporal foundation model that employs a novel self-supervised learning formulation, masking strategy, and loss all designed for the Earth observation domain. OlmoEarth achieves state-of-the-art performance compared to 12 other foundation models across a variety of research benchmarks and real-world tasks from external partners. When evaluating embeddings OlmoEarth achieves the best performance on 15 out of 24 tasks, and with full fine-tuning it is the best on 19 of 29 tasks. We deploy OlmoEarth as the backbone of an end-to-end platform for data collection, labeling, training, and inference of Earth observation models. The OlmoEarth Platform puts frontier foundation models and powerful data management tools into the hands of non-profits and NGOs working to solve the world's biggest problems. OlmoEarth source code, training data, and pre-trained weights are available at $\href{https://github.com/allenai/olmoearth_pretrain}{\text{https://github.com/allenai/olmoearth_pretrain}}$.

</details>


### [292] [Training-Free Multi-View Extension of IC-Light for Textual Position-Aware Scene Relighting](https://arxiv.org/abs/2511.13684)
*Jiangnan Ye,Jiedong Zhuang,Lianrui Mu,Wenjie Zheng,Jiaqi Hu,Xingze Zou,Jing Wang,Haoji Hu*

Main category: cs.CV

TL;DR: GS-Light是一种基于高斯溅射（3DGS）的高效文本位置感知管道，用于3D场景的文本引导重照明。它通过多视图输入的无训练扩散模型和大型视觉语言模型（LVLM）解析用户提示，结合几何和语义估计生成高保真重照明图像，并在3DGS场景中微调。


<details>
  <summary>Details</summary>
Motivation: 现有方法在3D场景重照明中难以准确反映用户期望的照明方向、颜色和强度。GS-Light旨在通过文本引导和多视图处理解决这一问题。

Method: 利用LVLM解析用户提示为照明先验，结合几何和语义估计生成初始潜在代码，通过多视图重照明模型生成高保真图像，并微调3DGS场景。

Result: GS-Light在室内外场景中表现出优于基线的多视图一致性、图像质量和语义相似性，并通过用户研究验证其效果。

Conclusion: GS-Light提供了一种高效且用户友好的3D场景重照明方法，显著提升了照明控制的准确性和图像质量。

Abstract: We introduce GS-Light, an efficient, textual position-aware pipeline for text-guided relighting of 3D scenes represented via Gaussian Splatting (3DGS). GS-Light implements a training-free extension of a single-input diffusion model to handle multi-view inputs. Given a user prompt that may specify lighting direction, color, intensity, or reference objects, we employ a large vision-language model (LVLM) to parse the prompt into lighting priors. Using off-the-shelf estimators for geometry and semantics (depth, surface normals, and semantic segmentation), we fuse these lighting priors with view-geometry constraints to compute illumination maps and generate initial latent codes for each view. These meticulously derived init latents guide the diffusion model to generate relighting outputs that more accurately reflect user expectations, especially in terms of lighting direction. By feeding multi-view rendered images, along with the init latents, into our multi-view relighting model, we produce high-fidelity, artistically relit images. Finally, we fine-tune the 3DGS scene with the relit appearance to obtain a fully relit 3D scene. We evaluate GS-Light on both indoor and outdoor scenes, comparing it to state-of-the-art baselines including per-view relighting, video relighting, and scene editing methods. Using quantitative metrics (multi-view consistency, imaging quality, aesthetic score, semantic similarity, etc.) and qualitative assessment (user studies), GS-Light demonstrates consistent improvements over baselines. Code and assets will be made available upon publication.

</details>


### [293] [TiViBench: Benchmarking Think-in-Video Reasoning for Video Generative Models](https://arxiv.org/abs/2511.13704)
*Harold Haodong Chen,Disen Lan,Wen-Jie Shu,Qingyang Liu,Zihan Wang,Sirui Chen,Wenkai Cheng,Kanghao Chen,Hongfei Zhang,Zixin Zhang,Rongjin Guo,Yu Cheng,Ying-Cong Chen*

Main category: cs.CV

TL;DR: 提出TiViBench评估视频生成模型的推理能力，并引入VideoTPO提升性能，为未来研究奠定基础。


<details>
  <summary>Details</summary>
Motivation: 尽管视频生成模型在视觉逼真度和时间一致性方面取得了进展，但其是否具备类似大型语言模型的推理能力仍不明确。现有基准主要评估视觉保真度和时间连贯性，未能捕捉高阶推理能力。

Method: 提出了TiViBench，一个分层基准，用于系统评估图像到视频生成模型的推理能力，涵盖四个维度的24种任务场景。此外，还引入了VideoTPO，一种无需额外训练、数据或奖励模型的测试时策略。

Result: 商业模型（如Sora 2、Veo 3.1）展现了更强的推理潜力，而开源模型则因训练规模和数据多样性受限而潜力未充分释放。VideoTPO显著提升了模型的推理性能。

Conclusion: TiViBench和VideoTPO为视频生成模型的推理能力评估和提升开辟了新路径，为这一新兴领域的未来研究奠定了基础。

Abstract: The rapid evolution of video generative models has shifted their focus from producing visually plausible outputs to tackling tasks requiring physical plausibility and logical consistency. However, despite recent breakthroughs such as Veo 3's chain-of-frames reasoning, it remains unclear whether these models can exhibit reasoning capabilities similar to large language models (LLMs). Existing benchmarks predominantly evaluate visual fidelity and temporal coherence, failing to capture higher-order reasoning abilities. To bridge this gap, we propose TiViBench, a hierarchical benchmark specifically designed to evaluate the reasoning capabilities of image-to-video (I2V) generation models. TiViBench systematically assesses reasoning across four dimensions: i) Structural Reasoning & Search, ii) Spatial & Visual Pattern Reasoning, iii) Symbolic & Logical Reasoning, and iv) Action Planning & Task Execution, spanning 24 diverse task scenarios across 3 difficulty levels. Through extensive evaluations, we show that commercial models (e.g., Sora 2, Veo 3.1) demonstrate stronger reasoning potential, while open-source models reveal untapped potential that remains hindered by limited training scale and data diversity. To further unlock this potential, we introduce VideoTPO, a simple yet effective test-time strategy inspired by preference optimization. By performing LLM self-analysis on generated candidates to identify strengths and weaknesses, VideoTPO significantly enhances reasoning performance without requiring additional training, data, or reward models. Together, TiViBench and VideoTPO pave the way for evaluating and advancing reasoning in video generation models, setting a foundation for future research in this emerging field.

</details>


### [294] [Free-Form Scene Editor: Enabling Multi-Round Object Manipulation like in a 3D Engine](https://arxiv.org/abs/2511.13713)
*Xincheng Shuai,Zhenyuan Qin,Henghui Ding,Dacheng Tao*

Main category: cs.CV

TL;DR: FFSE是一种3D感知的自回归框架，通过建模3D变换实现直观的对象编辑，并在实验中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像扩散模型在3D感知对象操作方面表现不足，FFSE旨在解决这一问题，实现直接在真实图像上进行直观且物理一致的对象编辑。

Method: FFSE 采用了一种3D感知的自回归框架，将编辑建模为一系列学习到的3D变换，支持用户执行任意操作（如平移、缩放、旋转），同时保持背景效果和全局场景一致性。还引入了3DObjectEditor混合数据集，支持多轮和动态条件下的训练。

Result: 实验表明，FFSE在单轮和多轮3D感知编辑场景中表现优异，显著优于现有方法。

Conclusion: FFSE 框架在单轮和多轮3D感知编辑场景中显著优于现有方法，实现了直观且物理一致的对象编辑。

Abstract: Recent advances in text-to-image (T2I) diffusion models have significantly improved semantic image editing, yet most methods fall short in performing 3D-aware object manipulation. In this work, we present FFSE, a 3D-aware autoregressive framework designed to enable intuitive, physically-consistent object editing directly on real-world images. Unlike previous approaches that either operate in image space or require slow and error-prone 3D reconstruction, FFSE models editing as a sequence of learned 3D transformations, allowing users to perform arbitrary manipulations, such as translation, scaling, and rotation, while preserving realistic background effects (e.g., shadows, reflections) and maintaining global scene consistency across multiple editing rounds. To support learning of multi-round 3D-aware object manipulation, we introduce 3DObjectEditor, a hybrid dataset constructed from simulated editing sequences across diverse objects and scenes, enabling effective training under multi-round and dynamic conditions. Extensive experiments show that the proposed FFSE significantly outperforms existing methods in both single-round and multi-round 3D-aware editing scenarios.

</details>


### [295] [Segment Anything Across Shots: A Method and Benchmark](https://arxiv.org/abs/2511.13715)
*Hengrui Hu,Kaining Ying,Henghui Ding*

Main category: cs.CV

TL;DR: 提出SAAS模型和TMA策略，解决多镜头视频对象分割问题，并在新基准测试中取得最佳效果。


<details>
  <summary>Details</summary>
Motivation: 现有视频对象分割方法主要针对单镜头视频，难以处理镜头不连续性，限制了实际应用。

Method: 提出了过渡模仿数据增强策略（TMA）和Segment Anything Across Shots（SAAS）模型，以解决多镜头数据稀疏性问题并有效检测和理解镜头过渡。

Result: 在YouMVOS和Cut-VOS基准测试中，SAAS表现出色，实现了最先进的性能。

Conclusion: SAAS模型通过有效模仿、理解和跨复杂过渡分割，在多镜头半监督视频对象分割（MVOS）任务中实现了最先进的性能。

Abstract: This work focuses on multi-shot semi-supervised video object segmentation (MVOS), which aims at segmenting the target object indicated by an initial mask throughout a video with multiple shots. The existing VOS methods mainly focus on single-shot videos and struggle with shot discontinuities, thereby limiting their real-world applicability. We propose a transition mimicking data augmentation strategy (TMA) which enables cross-shot generalization with single-shot data to alleviate the severe annotated multi-shot data sparsity, and the Segment Anything Across Shots (SAAS) model, which can detect and comprehend shot transitions effectively. To support evaluation and future study in MVOS, we introduce Cut-VOS, a new MVOS benchmark with dense mask annotations, diverse object categories, and high-frequency transitions. Extensive experiments on YouMVOS and Cut-VOS demonstrate that the proposed SAAS achieves state-of-the-art performance by effectively mimicking, understanding, and segmenting across complex transitions. The code and datasets are released at https://henghuiding.com/SAAS/.

</details>


### [296] [Back to Basics: Let Denoising Generative Models Denoise](https://arxiv.org/abs/2511.13720)
*Tianhong Li,Kaiming He*

Main category: cs.CV

TL;DR: 论文提出JiT方法，直接用Transformer预测干净图像，避免了传统噪声预测的局限性，在ImageNet上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统扩散模型并不直接预测干净图像，而是预测噪声或噪声量。基于流形假设，自然数据应位于低维流形上，而噪声量则不然。因此，直接预测干净数据可能更有效。

Method: 使用简单的像素级大块Transformer（JiT），直接预测干净数据，避免了传统扩散模型中预测噪声或噪声量的方法。

Result: 在ImageNet的256和512分辨率上，使用16和32的大块尺寸，JiT取得了竞争性结果，尤其在预测高维噪声量可能失败的情况下表现优异。

Conclusion: 研究提出了一种直接预测干净数据的方法（JiT），该方法通过简单的像素级大块Transformer实现了强生成模型，无需分词器、预训练或额外损失，在ImageNet上取得了竞争性结果。

Abstract: Today's denoising diffusion models do not "denoise" in the classical sense, i.e., they do not directly predict clean images. Rather, the neural networks predict noise or a noised quantity. In this paper, we suggest that predicting clean data and predicting noised quantities are fundamentally different. According to the manifold assumption, natural data should lie on a low-dimensional manifold, whereas noised quantities do not. With this assumption, we advocate for models that directly predict clean data, which allows apparently under-capacity networks to operate effectively in very high-dimensional spaces. We show that simple, large-patch Transformers on pixels can be strong generative models: using no tokenizer, no pre-training, and no extra loss. Our approach is conceptually nothing more than "$\textbf{Just image Transformers}$", or $\textbf{JiT}$, as we call it. We report competitive results using JiT with large patch sizes of 16 and 32 on ImageNet at resolutions of 256 and 512, where predicting high-dimensional noised quantities can fail catastrophically. With our networks mapping back to the basics of the manifold, our research goes back to basics and pursues a self-contained paradigm for Transformer-based diffusion on raw natural data.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [297] [Learning Conjugate Direction Fields for Planar Quadrilateral Mesh Generation](https://arxiv.org/abs/2511.11865)
*Jiong Tao,Yong-Liang Yang,Bailin Deng*

Main category: cs.GR

TL;DR: 提出基于神经网络的CDF生成方法，显著提升计算效率并支持用户交互设计。


<details>
  <summary>Details</summary>
Motivation: 传统方法通过复杂的非线性优化问题获取CDF，计算成本高且无法实现交互式设计过程。

Method: 采用神经网络学习自由曲面和用户笔触的特征，并高效生成符合用户指导的优质CDF。

Result: 通过大量实验验证了方法的有效性和效率，包括测试数据、建筑曲面和一般3D形状。

Conclusion: 本文提出了一种基于神经网络的数据驱动方法，用于生成受控的共轭方向场（CDF），有效解决了传统非线性优化方法计算成本高的问题。

Abstract: Planar quadrilateral (PQ) mesh generation is a key process in computer-aided design, particularly for architectural applications where the goal is to discretize a freeform surface using planar quad faces. The conjugate direction field (CDF) defined on the freeform surface plays a significant role in generating a PQ mesh, as it largely determines the PQ mesh layout. Conventionally, a CDF is obtained by solving a complex non-linear optimization problem that incorporates user preferences, i.e., aligning the CDF with user-specified strokes on the surface. This often requires a large number of iterations that are computationally expensive, preventing the interactive CDF design process for a desirable PQ mesh. To address this challenge, we propose a data-driven approach based on neural networks for controlled CDF generation. Our approach can effectively learn and fuse features from the freeform surface and the user strokes, and efficiently generate quality CDF respecting user guidance. To enable training and testing, we also present a dataset composed of 50000+ freeform surfaces with ground-truth CDFs, as well as a set of metrics for quantitative evaluation. The effectiveness and efficiency of our work are demonstrated by extensive experiments using testing data, architectural surfaces, and general 3D shapes.

</details>


### [298] [Locomotion in CAVE: Enhancing Immersion through Full-Body Motion](https://arxiv.org/abs/2511.12251)
*Xiaohui Li,Xiaolong Liu,Zhongchen Shi,Wei Chen,Liang Xie,Meng Gai,Jun Cao,Suxia Zhang,Erwei Yin*

Main category: cs.GR

TL;DR: 论文提出了一种CAVE环境运动框架，通过优化的动作识别技术提升沉浸感，用户研究表明其在真实感和减少眩晕方面优于传统方法。


<details>
  <summary>Details</summary>
Motivation: CAVE中的运动方法受限于非自然的交互方式，严重影响了用户体验和沉浸感，因此需要一种更自然的运动框架来提升沉浸式体验。

Method: 构建了一个四面显示CAVE系统，基于Perspective-n-Point动态方法校准摄像头，利用获取的摄像头内外参数和动作识别架构确定动作类别，最后将动作类别传输至图形工作站进行屏幕渲染。

Result: 通过用户研究验证，该方法在真实感和自我存在感方面有显著提升，且有效减少了运动眩晕。

Conclusion: 该论文提出的CAVE环境运动框架通过优化的人体动作识别技术显著提升了用户的沉浸感，并在真实感和自我存在感方面优于传统方法，同时有效减少了运动眩晕。

Abstract: Cave Automatic Virtual Environment (CAVE) is one of the virtual reality (VR) immersive devices currently used to present virtual environments. However, the locomotion methods in the CAVE are limited by unnatural interaction methods, severely hindering the user experience and immersion in the CAVE. We proposed a locomotion framework for CAVE environments aimed at enhancing the immersive locomotion experience through optimized human motion recognition technology. Firstly, we construct a four-sided display CAVE system, then through the dynamic method based on Perspective-n-Point to calibrate the camera, using the obtained camera intrinsics and extrinsic parameters, and an action recognition architecture to get the action category. At last, transform the action category to a graphical workstation that renders display effects on the screen. We designed a user study to validate the effectiveness of our method. Compared to the traditional methods, our method has significant improvements in realness and self-presence in the virtual environment, effectively reducing motion sickness.

</details>


### [299] [TR-Gaussians: High-fidelity Real-time Rendering of Planar Transmission and Reflection with 3D Gaussian Splatting](https://arxiv.org/abs/2511.13009)
*Yong Liu,Keyang Ye,Tianjia Shao,Kun Zhou*

Main category: cs.GR

TL;DR: 提出TR-Gaussians，一种基于3D高斯的表示方法，用于高保真渲染平面透射和反射，通过多阶段优化实现实时合成，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决室内场景中普遍存在的平面透射和反射的高保真渲染问题。

Method: 结合3D高斯和可学习反射平面，通过多阶段优化框架，包括颜色和几何约束以及透明度扰动机制。

Result: 实验表明，TR-Gaussians在不同数据集上均表现出色。

Conclusion: TR-Gaussians在平面透射和反射场景中实现了实时、高保真的新视角合成，并在定量和定性上均优于现有先进方法。

Abstract: We propose Transmission-Reflection Gaussians (TR-Gaussians), a novel 3D-Gaussian-based representation for high-fidelity rendering of planar transmission and reflection, which are ubiquitous in indoor scenes. Our method combines 3D Gaussians with learnable reflection planes that explicitly model the glass planes with view-dependent reflectance strengths. Real scenes and transmission components are modeled by 3D Gaussians and the reflection components are modeled by the mirrored Gaussians with respect to the reflection plane. The transmission and reflection components are blended according to a Fresnel-based, view-dependent weighting scheme, allowing for faithful synthesis of complex appearance effects under varying viewpoints. To effectively optimize TR-Gaussians, we develop a multi-stage optimization framework incorporating color and geometry constraints and an opacity perturbation mechanism. Experiments on different datasets demonstrate that TR-Gaussians achieve real-time, high-fidelity novel view synthesis in scenes with planar transmission and reflection, and outperform state-of-the-art approaches both quantitatively and qualitatively.

</details>


### [300] [Force-Aware 3D Contact Modeling for Stable Grasp Generation](https://arxiv.org/abs/2511.13247)
*Zhuo Chen,Zhongqun Zhang,Yihua Cheng,Ales Leonardis,Hyung Jin Chang*

Main category: cs.GR

TL;DR: 该研究提出了一种基于显式接触力预测的稳定抓取生成方法，通过力感知表示和优化约束，显著提升了抓取稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常关注物体几何结构而忽略接触力等物理属性，导致抓取稳定性不足。本研究旨在通过显式预测接触力，提升抓取的稳定性。

Method: 论文首先定义了力感知接触表示，将法向力值离散化并用one-hot向量编码；随后引入了力感知稳定性约束，将稳定性问题定义为加速度最小化任务，并通过物理约束明确关联稳定性与接触几何；最后提出了一种姿态优化器，系统整合了接触表示和稳定性约束以实现稳定抓取生成。

Result: 实验结果表明，该方法在稳定性指标上带来约20%的提升，并能良好适应新物体。

Conclusion: 该论文提出了一种结合接触力预测的稳定抓取生成方法，通过力感知接触表示和稳定性约束，显著提升了抓取的稳定性，并在公开基准测试中验证了其有效性。

Abstract: Contact-based grasp generation plays a crucial role in various applications. Recent methods typically focus on the geometric structure of objects, producing grasps with diverse hand poses and plausible contact points. However, these approaches often overlook the physical attributes of the grasp, specifically the contact force, leading to reduced stability of the grasp. In this paper, we focus on stable grasp generation using explicit contact force predictions. First, we define a force-aware contact representation by transforming the normal force value into discrete levels and encoding it using a one-hot vector. Next, we introduce force-aware stability constraints. We define the stability problem as an acceleration minimization task and explicitly relate stability with contact geometry by formulating the underlying physical constraints. Finally, we present a pose optimizer that systematically integrates our contact representation and stability constraints to enable stable grasp generation. We show that these constraints can help identify key contact points for stability which provide effective initialization and guidance for optimization towards a stable grasp. Experiments are carried out on two public benchmarks, showing that our method brings about 20% improvement in stability metrics and adapts well to novel objects.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [301] [WITNESS: A lightweight and practical approach to fine-grained predictive mutation testing](https://arxiv.org/abs/2511.11999)
*Zeyu Lu,Peng Zhang,Chun Yong Chong,Shan Gao,Yibiao Yang,Yanhui Li,Lin Chen,Yuming Zhou*

Main category: cs.SE

TL;DR: WITNESS是一种轻量级细粒度预测突变测试方法，通过经典机器学习提升效率和适用性，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的细粒度预测突变测试方法存在计算成本高和适用性受限的问题，需改进。

Method: WITNESS采用轻量级经典机器学习模型，结合内外方法突变体的特征，进行训练和预测。

Result: 在Defects4J项目上的评估显示，WITNESS在不同场景下均达到最优预测性能，并显著提升效率。

Conclusion: WITNESS通过轻量级机器学习模型和全面的特征收集，显著提升了预测突变测试的效率和适用性，同时保持了高性能。

Abstract: Existing fine-grained predictive mutation testing studies predominantly rely on deep learning, which faces two critical limitations in practice: (1) Exorbitant computational costs. The deep learning models adopted in these studies demand significant computational resources for training and inference acceleration. This introduces high costs and undermines the cost-reduction goal of predictive mutation testing. (2) Constrained applicability. Although modern mutation testing tools generate mutants both inside and outside methods, current fine-grained predictive mutation testing approaches handle only inside-method mutants. As a result, they cannot predict outside-method mutants, limiting their applicability in real-world scenarios. We propose WITNESS, a new fine-grained predictive mutation testing approach. WITNESS adopts a twofold design: (1) With collected features from both inside-method and outside-method mutants, WITNESS is suitable for all generated mutants. (2) Instead of using computationally expensive deep learning, WITNESS employs lightweight classical machine learning models for training and prediction. This makes it more cost-effective and enabling straightforward explanations of the decision-making processes behind the adopted models. Evaluations on Defects4J projects show that WITNESS consistently achieves state-of-the-art predictive performance across different scenarios. Additionally, WITNESS significantly enhances the efficiency of kill matrix prediction. Post-hoc analysis reveals that features incorporating information from before and after the mutation are the most important among those used in WITNESS. Test case prioritization based on the predicted kill matrix shows that WITNESS delivers results much closer to those obtained by using the actual kill matrix, outperforming baseline approaches.

</details>


### [302] [A Code Smell Refactoring Approach using GNNs](https://arxiv.org/abs/2511.12069)
*HanYu Zhang,Tomoji Kishi*

Main category: cs.SE

TL;DR: 提出基于图的深度学习方法，通过半自动数据集生成和GNN架构，有效解决代码异味重构问题，性能优越。


<details>
  <summary>Details</summary>
Motivation: 现有重构方法（基于指标、规则或深度学习）存在依赖人工定义、数据集限制等问题，需更高效解决方案。

Method: 设计了两种输入图（类级和方法级），并结合图分类和节点分类任务，使用三种经典GNN架构（GCN、GraphSAGE和GAT）实现。

Result: 实验表明，该方法在重构三种代表性代码异味（长方法、大类、特性嫉妒）时性能优于传统和前沿深度学习方法。

Conclusion: 本研究提出的基于图的深度学习方法在代码异味重构中表现出优越性能，为软件维护和演化提供了有效工具。

Abstract: Code smell is a great challenge in software refactoring, which indicates latent design or implementation flaws that may degrade the software maintainability and evolution. Over the past decades, a variety of refactoring approaches have been proposed, which can be broadly classified into metrics-based, rule-based, and machine learning-based approaches. Recent years, deep learning-based approaches have also attracted widespread attention. However, existing techniques exhibit various limitations. Metrics- and rule-based approaches rely heavily on manually defined heuristics and thresholds, whereas deep learning-based approaches are often constrained by dataset availability and model design. In this study, we proposed a graph-based deep learning approach for code smell refactoring. Specifically, we designed two types of input graphs (class-level and method-level) and employed both graph classification and node classification tasks to address the refactoring of three representative code smells: long method, large class, and feature envy. In our experiment, we propose a semi-automated dataset generation approach that could generate a large-scale dataset with minimal manual effort. We implemented the proposed approach with three classical GNN (graph neural network) architectures: GCN, GraphSAGE, and GAT, and evaluated its performance against both traditional and state-of-the-art deep learning approaches. The results demonstrate that proposed approach achieves superior refactoring performance.

</details>


### [303] [Actionable Warning Is Not Enough: Recommending Valid Actionable Warnings with Weak Supervision](https://arxiv.org/abs/2511.12229)
*Zhipeng Xue,Zhipeng Gao,Tongtong Xu,Xing Hu,Xin Xia,Shanping Li*

Main category: cs.SE

TL;DR: 研究构建了首个大规模可操作警告数据集并提出ACWRecommender框架，显著提升静态分析工具中真实漏洞警告的推荐效果，实际验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前静态分析工具的高误报率阻碍了其广泛应用，且现有可操作警告的收集假设不准确，导致大量无效警告。

Method: 研究首先通过挖掘Top-500 GitHub C仓库的68,274次回滚构建了首个大规模可操作警告数据集，并为每个警告分配了弱标签。随后提出了ACWRecommender框架，包含粗粒度检测和细粒度重排两个阶段，利用预训练模型UniXcoder和弱监督学习进行优化。

Result: 实验结果显示，ACWRecommender在nDCG和MRR指标上显著优于基线方法。在6个随机项目中，开发者确认了27个推荐警告为真实漏洞，验证了工具的实际效用。

Conclusion: 该研究通过构建大规模可操作警告数据集和提出的ACWRecommender框架，显著提高了静态分析工具中真实漏洞警告的推荐准确性，验证了其在实际开发中的实用性。

Abstract: The use of static analysis tools has gained increasing popularity among developers in the last few years. However, the widespread adoption of static analysis tools is hindered by their high false alarm rates. Previous studies have introduced the concept of actionable warnings and built a machine-learning method to distinguish actionable warnings from false alarms. However, according to our empirical observation, the current assumption used for actionable warning(s) collection is rather shaky and inaccurate, leading to a large number of invalid actionable warnings. To address this problem, in this study, we build the first large actionable warning dataset by mining 68,274 reversions from Top-500 GitHub C repositories, we then take one step further by assigning each actionable warning a weak label regarding its likelihood of being a real bug. Following that, we propose a two-stage framework called ACWRecommender to automatically recommend the actionable warnings with high probability to be real bugs (AWHB). Our approach warms up the pre-trained model UniXcoder by identifying actionable warnings task (coarse-grained detection stage) and rerank AWHB to the top by weakly supervised learning (fine-grained reranking stage). Experimental results show that our proposed model outperforms several baselines by a large margin in terms of nDCG and MRR for AWHB recommendation. Moreover, we ran our tool on 6 randomly selected projects and manually checked the top-ranked warnings from 2,197 reported warnings, we reported top-10 recommended warnings to developers, 27 of them were already confirmed by developers as real bugs. Developers can quickly find real bugs among the massive amount of reported warnings, which verifies the practical usage of our tool.

</details>


### [304] [Reflections on the design, applications and implementations of the normative specification language eFLINT](https://arxiv.org/abs/2511.12276)
*L. Thomas van Binsbergen,Christopher A. Esterhuyse,Tim Müller*

Main category: cs.SE

TL;DR: 本文探讨了eFLINT语言在自动化合规中的应用，总结了其设计决策和跨学科挑战。


<details>
  <summary>Details</summary>
Motivation: 随着软件在社会实践中的普及，自动化合规检查的需求日益增长，但法律实践的复杂性和跨学科特性使其难以实现。

Method: 通过回顾eFLINT语言的各种应用、需求及设计决策，分析其在自动化合规中的作用。

Result: eFLINT语言结合声明式和过程式元素，能够自动化执行软件系统的合规检查，并在不同阶段提供支持。

Conclusion: 本文总结了eFLINT语言在自动化合规检查中的应用和设计决策，为自动化合规领域的语言开发者提供了有价值的见解。

Abstract: Checking the compliance of software against laws, regulations and contracts is increasingly important and costly as the embedding of software into societal practices is getting more pervasive. Moreover, the digitalised services provided by governmental organisations and companies are governed by an increasing amount of laws and regulations, requiring highly adaptable compliance practices. A potential solution is to automate compliance using software. However, automating compliance is difficult for various reasons. Legal practices involve subjective processes such as interpretation and qualification. New laws and regulations come into effect regularly and laws and regulations, as well as their interpretations, are subjected to constant revision. In addition, computational reasoning with laws requires a cross-disciplinary process involving both legal and software expertise.
  This paper reflects on the domain-specific software language eFLINT developed to experiment with novel solutions. The language combines declarative and procedural elements to reason about situations and scenarios respectively, explicates and formalises connections between legal concepts and computational concepts, and is designed to automate compliance checks both before, during and after a software system runs. The various goals and applications areas for the language give rise to (conflicting) requirements. This paper reflects on the current design of the language by recalling various applications, the requirements they imposed, and subsequent design decisions. As such, this paper reports on results and insights of an investigation that can benefit language developers within the field of automated compliance.

</details>


### [305] [Reducing Hallucinations in LLM-Generated Code via Semantic Triangulation](https://arxiv.org/abs/2511.12288)
*Yihan Dai,Sijie Liang,Haotian Xu,Peichu Xie,Sergey Mechtaev*

Main category: cs.SE

TL;DR: 语义三角测量通过验证问题转换一致性，显著提升代码生成可靠性，尤其在低采样概率和多解场景下优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在采样概率低或多解问题时无法可靠选择正确解决方案或适时弃权。

Method: 引入语义三角测量技术，通过非平凡地改变问题语义同时保持解决方案间的可验证映射。

Result: 在LiveCodeBench和CodeElo基准测试中，语义三角测量将生成代码的可靠性提高了21%，并能识别低至0.14采样概率的正确解，且在多解任务中唯一能形成真实共识。

Conclusion: 语义三角测量通过验证问题转换间的一致性，提高了生成代码的可靠性，尤其在采样概率低或多解问题时表现优异。

Abstract: When generating code from natural language prompts, an LLM samples programs from a probability distribution, many of which might be incorrect. Sample consensus techniques - such as majority voting or validation against generated tests or specifications - aim to identify a correct program in the sample or abstain if none is valid. However, existing methods often fail to select a correct solution when its sampling probability is low, or when the problem permits multiple valid but non-equivalent solutions. Additionally, they often fail to abstain when no correct solution is present in the sample. To overcome these limitations, we introduce semantic triangulation, which transforms a programming problem in a way that non-trivially alters its semantics while preserving an exact, verifiable mapping between solutions before and after transformation. We theoretically establish that verifying consistency across such problem transformations increases confidence that generated programs reflect accurate generalization rather than spurious statistical correlations, enabling more reliable sample consensus and abstention. On the LiveCodeBench and CodeElo benchmarks, using GPT-4o and DeepSeek-V3 models, semantic triangulation increases reliability of generated code by 21% compared to the method that selects only high-confidence solutions with the probability threshold 0.5, while being able to pinpoint correct solutions at sampling probabilities as low as 0.14. Apart from that, it is also the only approach to consistently form true consensus on tasks with multiple valid but non-equivalent solutions.

</details>


### [306] [ProofWright: Towards Agentic Formal Verification of CUDA](https://arxiv.org/abs/2511.12294)
*Bodhisatwa Chatterjee,Drew Zagieboylo,Sana Damani,Siva Hari,Christos Kozyrakis*

Main category: cs.SE

TL;DR: ProofWright是一个集成自动形式验证与LLM代码生成的框架，为LLM生成的CUDA内核提供内存安全、线程安全和语义正确性的端到端保证。


<details>
  <summary>Details</summary>
Motivation: LLM生成的CUDA内核存在细微的正确性错误且缺乏形式安全保证，传统测试覆盖率不足且手动验证无法扩展，形成验证瓶颈。

Method: 整合自动形式验证与LLM代码生成，构建ProofWright代理验证框架。

Result: 在KernelBench L1上，ProofWright验证了74%生成内核的安全属性，发现传统测试遗漏的细微错误，并为一类元素级内核建立语义等价性。

Conclusion: ProofWright以每个内核3分钟的适度开销，证明LLM生成的GPU代码的可扩展自动形式验证可行，为可信高性能代码生成提供了路径。

Abstract: Large Language Models (LLMs) are increasingly used to automatically generate optimized CUDA kernels, substantially improving developer productivity. However, despite rapid generation, these kernels often contain subtle correctness bugs and lack formal safety guarantees. Runtime testing is inherently unreliable - limited input coverage and reward hacking can mask incorrect behavior - while manual formal verification is reliable but cannot scale to match LLM output rates, creating a critical validation bottleneck.
  We present ProofWright, an agentic verification framework that bridges this gap by integrating automated formal verification with LLM-based code generation. ProofWright provides end-to-end guarantees of memory safety, thread safety, and semantic correctness for LLM-generated CUDA kernels. On KernelBench L1, ProofWright verifies safety properties for 74% of generated kernels, uncovers subtle correctness errors missed by conventional testing, and establishes semantic equivalence for a class of element-wise kernels. With a modest overhead of 3 minutes per kernel, ProofWright demonstrates that scalable, automated formal verification of LLM-generated GPU code is feasible - offering a path toward trustworthy high-performance code generation without sacrificing developer productivity.

</details>


### [307] [High-level reasoning while low-level actuation in Cyber-Physical Systems: How efficient is it?](https://arxiv.org/abs/2511.12543)
*Burak Karaduman,Baris Tekin Tezel,Moharram Challenger*

Main category: cs.SE

TL;DR: 该研究比较了六种语言和框架的WCET和开发时间，为工业应用中的技术选择提供实证指导，揭示了抽象与推理机制对性能和效率的影响。


<details>
  <summary>Details</summary>
Motivation: 工业信息集成系统的复杂性增加，需要支持智能行为、实时响应和高效开发的软件技术，但缺乏实证证据指导工具选择。

Method: 通过测量和比较六种语言和框架的最坏执行时间（WCET）和开发时间，采用以开发者为中心的方法，基于可衡量的结果进行结构化比较。

Result: 研究发现抽象和推理机制如何影响系统性能和开发效率，为设计智能、基于代理的解决方案提供了实用见解。

Conclusion: 该研究为工业信息化中的软件技术选择提供了基于证据的指导，支持提高集成效率、可维护性和响应性，并为未来研究语言特性、开发动态与运行时行为之间的相互作用奠定了基础。

Abstract: The increasing complexity of industrial information-integration systems demands software technologies that enable intelligent behaviour, real-time response, and efficient development. Although many programming languages and frameworks exist, engineers still lack sufficient empirical evidence to guide the choice of tools for advanced industrial applications. This study addresses that need by measuring and comparing worst-case execution time (WCET) and development time across six languages and frameworks: C++, Java, Jade, Jason, and fuzzy Jason BDI with both loosely and tightly coupled integration. These technologies reflect a progression from procedural and object-oriented programming to agent-based frameworks capable of symbolic and fuzzy reasoning.
  Rather than relying on broad concepts such as paradigms or orientations, the study adopts a developer-centred approach grounded in measurable outcomes. The structured comparison examines how rising abstraction levels and reasoning capabilities affect both development effort and runtime behaviour. By analysing these dimensions, the study highlights concrete trade-offs between engineering workload and execution efficiency.
  The findings show how abstraction and reasoning mechanisms shape system performance and developer productivity, offering practical insight for designing intelligent, agent-based solutions that must operate under real-time constraints and complex decision-making requirements. Overall, the study contributes evidence-based guidance for selecting software technologies in industrial informatization, supporting improved integration efficiency, maintainability, and responsiveness, and laying groundwork for future research on the interplay between language features, development dynamics, and runtime behaviour in cyber-physical and smart manufacturing systems.

</details>


### [308] [Can Small GenAI Language Models Rival Large Language Models in Understanding Application Behavior?](https://arxiv.org/abs/2511.12576)
*Mohammad Meymani,Hamed Jelodar,Parisa Hamedi,Roozbeh Razavi-Far,Ali A. Ghorbani*

Main category: cs.SE

TL;DR: 研究发现，小型生成式AI模型在恶意软件检测任务中表现接近大型模型，尤其在资源效率上更具优势，适合实际部署。


<details>
  <summary>Details</summary>
Motivation: 探究生成式AI模型（尤其是大型语言模型）在代码理解和行为分析中的应用潜力，特别是在恶意软件检测任务中的表现差异。

Method: 系统评估了不同规模的生成式AI语言模型在理解应用行为（以恶意软件检测为例）的能力，比较了准确率、精确度、召回率和F1分数等指标。

Result: 大型模型总体准确率更高，但小型模型在精确度和召回率上具有竞争力，且在计算效率、推理速度和资源受限环境部署上优势显著。

Conclusion: 小型生成式AI模型在资源受限环境中展现出与大型模型相当的竞争力，尤其在精确度和召回率上表现优异，为实际应用行为分析提供了性能与资源效率的平衡。

Abstract: Generative AI (GenAI) models, particularly large language models (LLMs), have transformed multiple domains, including natural language processing, software analysis, and code understanding. Their ability to analyze and generate code has enabled applications such as source code summarization, behavior analysis, and malware detection. In this study, we systematically evaluate the capabilities of both small and large GenAI language models in understanding application behavior, with a particular focus on malware detection as a representative task. While larger models generally achieve higher overall accuracy, our experiments show that small GenAI models maintain competitive precision and recall, offering substantial advantages in computational efficiency, faster inference, and deployment in resource-constrained environments. We provide a detailed comparison across metrics such as accuracy, precision, recall, and F1-score, highlighting each model's strengths, limitations, and operational feasibility. Our findings demonstrate that small GenAI models can effectively complement large ones, providing a practical balance between performance and resource efficiency in real-world application behavior analysis.

</details>


### [309] [LLM4SCREENLIT: Recommendations on Assessing the Performance of Large Language Models for Screening Literature in Systematic Reviews](https://arxiv.org/abs/2511.12635)
*Lech Madeyski,Barbara Kitchenham,Martin Shepperd*

Main category: cs.SE

TL;DR: 论文分析了LLM在系统综述文献筛选中的评估问题，指出了传统指标的不足，并提出了改进建议，强调召回率、WMCC和完整混淆矩阵的重要性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）的发布速度快于用户对其进行严格评估的能力。当LLM支撑研究（如系统综述中的文献筛选）时，需要坚实的实证评估。

Method: 以近期一项大规模研究为例，分析了传统指标在评估Gen-AI工具用于SR文献筛选中的问题，并综述了27篇相关论文，提取了性能指标，总结了良好实践和普遍问题。

Result: 主要问题包括：i）未使用对不平衡数据稳健且能直接反映结果是否优于随机性的指标（如准确率），ii）未考虑丢失证据对工作量节省声明的影响，iii）普遍未报告完整混淆矩阵（或可重构的指标）。同时提取了良好实践，并基于此提出建议。

Conclusion: 系统综述（SR）筛选评估应优先考虑丢失证据/召回率，同时使用基于机会和成本敏感的加权马修斯相关系数（WMCC）指标，报告完整的混淆矩阵，将无法分类的输出视为待评估的阳性结果，采用泄漏感知设计与非LLM基线及开放工件，并在成本效益分析中得出结论，其中假阴性（FN）比假阳性（FP）的代价更高。

Abstract: Context: Large language models (LLMs) are released faster than users' ability to evaluate them rigorously. When LLMs underpin research, such as identifying relevant literature for systematic reviews (SRs), robust empirical assessment is essential. Objective: We identify and discuss key challenges in assessing LLM performance for selecting relevant literature, identify good (evaluation) practices, and propose recommendations. Method: Using a recent large-scale study as an example, we identify problems with the use of traditional metrics for assessing the performance of Gen-AI tools for identifying relevant literature in SRs. We analyzed 27 additional papers investigating this issue, extracted the performance metrics, and found both good practices and widespread problems, especially with the use and reporting of performance metrics for SR screening. Results: Major weaknesses included: i) a failure to use metrics that are robust to imbalanced data and do not directly indicate whether results are better than chance, e.g., the use of Accuracy, ii) a failure to consider the impact of lost evidence when making claims concerning workload savings, and iii) pervasive failure to report the full confusion matrix (or performance metrics from which it can be reconstructed) which is essential for future meta-analyses. On the positive side, we extract good (evaluation) practices on which our recommendations for researchers and practitioners, as well as policymakers, are built. Conclusions: SR screening evaluations should prioritize lost evidence/recall alongside chance-anchored and cost-sensitive Weighted MCC (WMCC) metric, report complete confusion matrices, treat unclassifiable outputs as referred-back positives for assessment, adopt leakage-aware designs with non-LLM baselines and open artifacts, and ground conclusions in cost-benefit analysis where FNs carry higher penalties than FPs.

</details>


### [310] [Enhancing LLM Code Generation Capabilities through Test-Driven Development and Code Interpreter](https://arxiv.org/abs/2511.12823)
*Sajed Jalil,Shuvo Saha,Hossain Mohammad Seym*

Main category: cs.SE

TL;DR: 提出无需微调的新方法，结合TDD和CI，显著提升孟加拉语代码生成准确率至85%，最小模型接近最大模型性能。


<details>
  <summary>Details</summary>
Motivation: 尽管孟加拉语有2.42亿母语者，但LLM训练中对其关注不足。现有技术需要大量资源和专业知识，难以在资源受限的新兴市场普及。

Method: 结合测试驱动开发（TDD）和代码解释器（CI），利用开放权重模型。

Result: 将孟加拉语提示的代码生成准确率提升至85%，最小模型能达到最大模型98%的准确率。

Conclusion: 通过结合测试驱动开发（TDD）和代码解释器（CI）的新方法，使用开放权重模型，显著提升了孟加拉语提示的代码生成准确率至85%，且无需微调。最小模型也能达到最大模型98%的准确率。

Abstract: Over the past few years, improving LLM code generation capabilities has been a key focus in NLP research. Despite Bengali having 242 million native speakers worldwide, it receives little attention when it comes to training LLMs. More recently, various fine-tuning and augmented generation techniques have been employed to significantly enhance code generation performance. However, they require considerable expertise and resources to utilize effectively as an end user. The goal of our work is to democratize access to powerful code generation tools in resource-constrained emerging markets, enabling users to leverage them in their native language.
  We introduce a novel approach that combines Test-Driven Development (TDD) and Code Interpreter (CI), utilizing open-weight models, which improves the baseline accuracy for code generation with Bengali prompts and achieves an overall accuracy of 85%. Our approach requires no finetuning and proves that even the smallest models in the same family can attain up to 98% accuracy compared to the largest models. All of our results are publicly shared in GitHub for validation and reproducibility.

</details>


### [311] [Human-Centred Requirements Engineering for Critical Systems: Insights from Disaster Early Warning Applications](https://arxiv.org/abs/2511.12856)
*Anuradha Madugalla,Jixuan Dong,Kai Lyne Loi,Matthew Crossman,John Grundy*

Main category: cs.SE

TL;DR: 本文提出一种人本中心的需求工程流程，将社会责任融入关键系统开发，验证了人本需求对系统可用性和可访问性的重要性。


<details>
  <summary>Details</summary>
Motivation: 关键系统（如医疗、国防和灾害管理）通常注重技术保障，而忽略了人和社会背景，本文认为考虑人本中心是可靠性的重要维度。

Method: 通过文献综述确定针对脆弱社区设计软件的指导原则，并将其转化为62项功能和非功能需求，通过自适应早期预警系统原型设计和评估（6次访谈和8次认知走查）来验证这些需求的相关性和适用性。

Result: 研究发现，早期解决人本需求能提升系统对所有用户的可用性和可访问性。

Conclusion: 论文将人本中心性定位为安全和公平关键系统的定义性质量，而非伦理附加项。

Abstract: Critical systems, such as those used in healthcare, defence, and disaster management, demand rigorous requirements engineering to ensure safety and reliability. Yet, much of this rigour has traditionally focused on technical assurance, often overlooking the human and social contexts in which these systems operate. This paper argues that considering human-centric aspects is an essential dimension of dependability, and presents a human-centred RE process designed to integrate social responsibility into critical system development. Drawing from a literature review, we identified a set of guidelines for designing software for vulnerable communities and translated these into sixty-two functional and non-functional requirements. These requirements were operationalised through the design of an adaptive early warning system prototype, which was subsequently evaluated through six interviews and eight cognitive walkthroughs to validate their relevance and applicability. The findings demonstrate that human-centric requirements, when addressed early, enhance the usability and accessibility of systems for all users. The paper concludes by positioning human-centricity not as an ethical add-on but as a defining quality of safe and equitable critical systems.

</details>


### [312] [Agent READMEs: An Empirical Study of Context Files for Agentic Coding](https://arxiv.org/abs/2511.12884)
*Worawalan Chatlatanagulchai,Hao Li,Yutaro Kashiwa,Brittany Reid,Kundjanasith Thonglek,Pattara Leelaprute,Arnon Rungsawang,Bundit Manaskasemsak,Bram Adams,Ahmed E. Hassan,Hajimu Iida*

Main category: cs.SE

TL;DR: 代理上下文文件是动态、复杂的文档，开发者主要关注功能性需求，但忽视安全性和性能等非功能性需求，亟需改进工具和实践。


<details>
  <summary>Details</summary>
Motivation: 首次大规模研究代理上下文文件的特征，以理解其如何支持代理编码工具的目标分解与执行。

Method: 对来自1,925个仓库的2,303个代理上下文文件进行了大规模实证研究，分析了其结构、维护和内容。

Result: 上下文文件是动态、复杂的文档，维护频繁且内容侧重功能性（如构建命令、实现细节和架构），非功能性需求（如安全性和性能）较少提及。

Conclusion: 研究发现开发者主要通过上下文文件使代理工具功能化，但在确保代码安全性和性能方面缺乏指导，亟需改进工具和实践。

Abstract: Agentic coding tools receive goals written in natural language as input, break them down into specific tasks, and write or execute the actual code with minimal human intervention. Central to this process are agent context files ("READMEs for agents") that provide persistent, project-level instructions. In this paper, we conduct the first large-scale empirical study of 2,303 agent context files from 1,925 repositories to characterize their structure, maintenance, and content. We find that these files are not static documentation but complex, difficult-to-read artifacts that evolve like configuration code, maintained through frequent, small additions. Our content analysis of 16 instruction types shows that developers prioritize functional context, such as build and run commands (62.3%), implementation details (69.9%), and architecture (67.7%). We also identify a significant gap: non-functional requirements like security (14.5%) and performance (14.5%) are rarely specified. These findings indicate that while developers use context files to make agents functional, they provide few guardrails to ensure that agent-written code is secure or performant, highlighting the need for improved tooling and practices.

</details>


### [313] [Diffploit: Facilitating Cross-Version Exploit Migration for Open Source Library Vulnerabilities](https://arxiv.org/abs/2511.12950)
*Zirui Chen,Zhipeng Xue,Jiayuan Zhou,Xing Hu,Xin Xia,Xiaohu Yang*

Main category: cs.SE

TL;DR: Diffploit通过上下文和迁移模块解决了库版本间漏洞利用迁移的复杂问题，成功迁移率84.2%，高于现有工具。


<details>
  <summary>Details</summary>
Motivation: 现有技术在处理库版本间的漏洞利用迁移时，常因触发条件或环境变化导致失败，且修复方法耗时且不充分。

Method: Diffploit 采用上下文模块分析行为差异并构建上下文，迁移模块则利用LLM进行迭代优化，平衡差异候选的探索与逐步细化。

Result: 在包含102个Java CVE和689个版本迁移任务的大规模数据集上，Diffploit成功迁移了84.2%的漏洞利用，显著优于其他工具。

Conclusion: Diffploit 是一种有效的漏洞利用迁移方法，通过上下文模块和迁移模块的结合，成功解决了版本间漏洞利用的复杂变化问题，显著提高了迁移成功率。

Abstract: Exploits are commonly used to demonstrate the presence of library vulnerabilities and validate their impact across different versions. However, their direct application to alternative versions often fails due to breaking changes introduced during evolution. These failures stem from both changes in triggering conditions (e.g., API refactorings) and broken dynamic environments (e.g., build or runtime errors), which are challenging to interpret and adapt manually. Existing techniques primarily focus on code-level trace alignment through fuzzing, which is both time-consuming and insufficient for handling environment-level failures. Moreover, they often fall short when dealing with complicated triggering condition changes across versions. To overcome this, we propose Diffploit, an iterative, diff-driven exploit migration method structured around two key modules: the Context Module and the Migration Module. The Context Module dynamically constructs contexts derived from analyzing behavioral discrepancies between the target and reference versions, which capture the failure symptom and its related diff hunks. Leveraging these contexts, the Migration Module guides an LLM-based adaptation through an iterative feedback loop, balancing exploration of diff candidates and gradual refinement to resolve reproduction failures effectively. We evaluate Diffploit on a large-scale dataset containing 102 Java CVEs and 689 version-migration tasks across 79 libraries. Diffploit successfully migrates 84.2% exploits, outperforming the change-aware test repair tool TARGET by 52.0% and the rule-based tool in IDEA by 61.6%. Beyond technical effectiveness, Diffploit identifies 5 CVE reports with incorrect affected version ranges, three of which have been confirmed. It also discovers 111 unreported vulnerable versions in the GitHub Advisory Database.

</details>


### [314] [SmartPoC: Generating Executable and Validated PoCs for Smart Contract Bug Reports](https://arxiv.org/abs/2511.12993)
*Longfei Chen,Ruibin Yan,Taiyu Wong,Yiyang Chen,Chao Zhang*

Main category: cs.SE

TL;DR: SmartPoC是一个自动化框架，能够将文本审计报告转化为可执行且验证的测试用例，有效解决噪声、幻觉和运行时预言缺失问题，并在实际应用中表现高效且低成本。


<details>
  <summary>Details</summary>
Motivation: 智能合约审计报告中存在噪声、幻觉和运行时预言缺失等问题，导致自动化验证成本高且不可靠。

Method: SmartPoC框架首先处理输入审计报告以减少噪声，仅提取与漏洞相关的函数作为LLM的上下文。通过特别设计的前/后执行修复机制，确保生成的PoC测试用例可直接编译和运行。利用差分验证作为预言机确认测试用例的可利用性。

Result: 在SmartBugs-Vul和FORGE-Vul基准测试中，SmartPoC分别为85.61%和86.45%的目标生成了可执行且验证的Foundry测试用例。在Etherscan验证源代码语料库中，SmartPoC以每发现仅0.03美元的成本确认了545个审计发现中的236个真实漏洞。

Conclusion: SmartPoC成功地将文本审计报告转化为可执行且经过验证的测试用例，解决了传统审计中的噪声、幻觉和运行时预言缺失问题，并在实际应用中展示了高效性和低成本。

Abstract: Smart contracts are prone to vulnerabilities and are analyzed by experts as well as automated systems, such as static analysis and AI-assisted solutions. However, audit artifacts are heterogeneous and often lack reproducible, executable PoC tests suitable for automated validation, leading to costly, ad hoc manual verification. Large language models (LLMs) can be leveraged to turn audit reports into PoC test cases, but have three major challenges: noisy inputs, hallucinations, and missing runtime oracles. In this paper, we present SmartPoC, an automated framework that converts textual audit reports into executable, validated test cases. First, the input audit report is processed to reduce noise, and only bug-related functions are extracted and fed to LLMs as context. To curb hallucinations and ensure compile-and-run readiness, we leverage LLMs to synthesize PoC test cases with specially-designed pre-/post-execution repair. We further utilize differential verification as oracles to confirm exploitability of the PoC test cases. On the SmartBugs-Vul and FORGE-Vul benchmarks, SmartPoC generates executable, validated Foundry test cases for 85.61% and 86.45% of targets, respectively. Applied to the latest Etherscan verified-source corpus, SmartPoC confirms 236 real bugs out of 545 audit findings at a cost of only $0.03 per finding.

</details>


### [315] [Towards Requirements Engineering for GenAI-Enabled Software: Bridging Responsibility Gaps through Human Oversight Requirements](https://arxiv.org/abs/2511.13069)
*Zhenyu Mao,Jacky Keung,Yicheng Sun,Yifei Wang,Shuo Liu,Jialong Li*

Main category: cs.SE

TL;DR: 该论文提出了一种三层分析方法，有效识别和解决生成式AI软件中的责任缺口问题，用户研究验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 生成式AI软件的适应性和生成特性使得责任分配变得模糊，现有需求工程方法难以应对，需系统性分析责任缺口。

Method: 研究采用了三层分析方法：概念化层建立责任框架，方法论层引入演绎管道识别责任缺口，工具层通过‘演绎主干表’形式化结果。

Result: 用户研究表明，该方法在六个评估维度上均优于基线目标导向需求工程，有效解决了三个研究缺口。

Conclusion: 该研究提出的方法在解决责任缺口问题上表现出显著效果，通过概念化、方法论和工具层面的结构化分析，有效填补了现有需求工程方法的不足。

Abstract: Context: Responsibility gaps, long-recognized challenges in socio-technical systems where accountability becomes diffuse or ambiguous, have become increasingly pronounced in GenAI-enabled software. The generative and adaptive nature complicates how human oversight and responsibility are specified, delegated, and traced. Existing requirements engineering (RE) approaches remain limited in addressing these phenomena, revealing conceptual, methodological, and artifact-level research gaps.. Objective: This study aims to analyze these research gaps in the context of GenAI-enabled software systems. It seeks to establish a coherent perspective for a systematic analysis of responsibility gaps from a human oversight requirements standpoint, encompassing how these responsibility gaps should be conceptualized, identified, and represented throughout the RE process. Methods: The proposed design methodology is structured across three analytical layers. At the conceptualization layer, it establishes a conceptual framing that defines the key elements of responsibility across the human and system dimensions and explains how potential responsibility gaps emerge from their interactions. At the methodological layer, it introduces a deductive pipeline for identifying responsibility gaps by analyzing interactions between these dimensions and deriving corresponding oversight requirements within established RE frameworks. At the artifact layer, it formalizes the results in a Deductive Backbone Table, a reusable representation that traces the reasoning path from responsibility gaps identification to human oversight requirements derivation. Results: A user study compared the proposed methodology with a baseline goal-oriented RE across two scenarios. Evaluation across six dimensions indicated clear improvements of the proposed methodology, confirming its effectiveness in addressing three research gaps.

</details>


### [316] [Examining the Usage of Generative AI Models in Student Learning Activities for Software Programming](https://arxiv.org/abs/2511.13271)
*Rufeng Chen,Shuaishuai Jiang,Jiyun Shen,AJung Moon,Lili Wei*

Main category: cs.SE

TL;DR: 研究发现GenAI能提升编程任务表现（尤其对初学者），但知识增益有限，呼吁将其作为学习工具而非问题解决工具。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注GenAI完成教育任务的能力及其对学生表现的影响，而忽视了其对知识获取的影响。本研究旨在比较GenAI辅助与传统在线资源在不同熟练度水平下对知识获取的支持效果。

Method: 通过对照用户实验，研究分析了24名不同编程经验（初学者、中级）的本科学生在解决编程任务时与ChatGPT的互动行为，评估了任务表现、概念理解及互动行为。

Result: 研究显示，使用GenAI生成完整解决方案显著提升了任务表现（尤其是初学者），但并未一致带来知识增益。使用策略因经验水平而异：初学者倾向于依赖GenAI完成任务而缺乏知识获取，中级学生则采取更选择性策略。过度依赖或极少使用均导致整体知识增益较弱。

Conclusion: 研究呼吁学生和教育者将GenAI视为学习工具而非问题解决工具，强调了在编程教育中整合GenAI以促进更深层次理解的紧迫需求。

Abstract: The rise of Generative AI (GenAI) tools like ChatGPT has created new opportunities and challenges for computing education. Existing research has primarily focused on GenAI's ability to complete educational tasks and its impact on student performance, often overlooking its effects on knowledge gains. In this study, we investigate how GenAI assistance compares to conventional online resources in supporting knowledge gains across different proficiency levels. We conducted a controlled user experiment with 24 undergraduate students of two different levels of programming experience (beginner, intermediate) to examine how students interact with ChatGPT while solving programming tasks. We analyzed task performance, conceptual understanding, and interaction behaviors. Our findings reveal that generating complete solutions with GenAI significantly improves task performance, especially for beginners, but does not consistently result in knowledge gains. Importantly, usage strategies differ by experience: beginners tend to rely heavily on GenAI toward task completion often without knowledge gain in the process, while intermediates adopt more selective approaches. We find that both over-reliance and minimal use result in weaker knowledge gains overall. Based on our results, we call on students and educators to adopt GenAI as a learning rather than a problem solving tool. Our study highlights the urgent need for guidance when integrating GenAI into programming education to foster deeper understanding.

</details>


### [317] [SAINT: Service-level Integration Test Generation with Program Analysis and LLM-based Agents](https://arxiv.org/abs/2511.13305)
*Rangeet Pan,Raju Pavuluri,Ruikai Huang,Rahul Krishna,Tyler Stennett,Alessandro Orso,Saurabh SInha*

Main category: cs.SE

TL;DR: SAINT利用静态分析和LLM智能体自动生成服务级测试，显著提升测试覆盖率和功能有效性，特别适用于缺乏OpenAPI规范的企业Java应用。


<details>
  <summary>Details</summary>
Motivation: 现有的服务级测试工具（如针对RESTful API的）依赖模糊测试或OpenAPI规范，且在实际企业代码库中往往不可用，同时难以生成有效覆盖功能场景的测试。

Method: SAINT结合静态分析、大型语言模型（LLMs）和基于LLM的智能体，构建端点模型和操作依赖图，通过智能体循环（规划、执行、反思）生成端点测试和场景测试。

Result: 在8个Java应用（包括一个专有企业应用）上的评估显示，SAINT在覆盖率、故障检测和场景生成方面表现优异，开发者调查也验证了其场景测试的实用性。

Conclusion: SAINT通过结合静态分析和基于LLM的智能体工作流，显著提升了服务级测试的覆盖率和功能有效性，同时生成的场景测试得到了开发者的高度认可。

Abstract: Enterprise applications are typically tested at multiple levels, with service-level testing playing an important role in validating application functionality. Existing service-level testing tools, especially for RESTful APIs, often employ fuzzing and/or depend on OpenAPI specifications which are not readily available in real-world enterprise codebases. Moreover, these tools are limited in their ability to generate functional tests that effectively exercise meaningful scenarios. In this work, we present SAINT, a novel white-box testing approach for service-level testing of enterprise Java applications. SAINT combines static analysis, large language models (LLMs), and LLM-based agents to automatically generate endpoint and scenario-based tests. The approach builds two key models: an endpoint model, capturing syntactic and semantic information about service endpoints, and an operation dependency graph, capturing inter-endpoint ordering constraints. SAINT then employs LLM-based agents to generate tests. Endpoint-focused tests aim to maximize code and database interaction coverage. Scenario-based tests are synthesized by extracting application use cases from code and refining them into executable tests via planning, action, and reflection phases of the agentic loop. We evaluated SAINT on eight Java applications, including a proprietary enterprise application. Our results illustrate the effectiveness of SAINT in coverage, fault detection, and scenario generation. Moreover, a developer survey provides strong endorsement of the scenario-based tests generated by SAINT. Overall, our work shows that combining static analysis with agentic LLM workflows enables more effective, functional, and developer-aligned service-level test generation.

</details>


### [318] [LinkXplore: A Framework for Affordable High-Quality Blockchain Data](https://arxiv.org/abs/2511.13318)
*Peihao Li*

Main category: cs.SE

TL;DR: LinkXplore 是首个开放框架，通过直接分析 RPC 数据，低成本提供高质量区块链数据，解决了数据收集的高成本问题。


<details>
  <summary>Details</summary>
Motivation: 大规模区块链数据收集成本过高，且缺乏灵活集成新模块的系统化框架。

Method: 通过直接分析来自 RPC 查询或流的原始数据，绕过昂贵的数据提供商，并提供简单的 API 和后端处理逻辑。

Result: LinkXplore 能够以低成本提供高质量的区块链数据，适用于预算有限的研究人员和开发者。

Conclusion: LinkXplore 提供了一个低成本、高质量的区块链数据收集与管理框架，解决了学术界和工业界在数据获取上的难题。

Abstract: Blockchain technologies are rapidly transforming both academia and industry. However, large-scale blockchain data collection remains prohibitively expensive, as many RPC providers only offer enhanced APIs with high pricing tiers that are unsuitable for budget-constrained research or industrial-scale applications, which has significantly slowed down academic studies and product development. Moreover, there is a clear lack of a systematic framework that allows flexible integration of new modules for analyzing on-chain data.
  To address these challenges, we introduce LinkXplore, the first open framework for collecting and managing on-chain data. LinkXplore enables users to bypass costly blockchain data providers by directly analyzing raw data from RPC queries or streams, thereby offering high-quality blockchain data at a fraction of the cost. Through a simple API and backend processing logic, any type of chain data can be integrated into the framework. This makes it a practical alternative for both researchers and developers with limited budgets. Code and dataset used in this project are publicly available at https://github.com/Linkis-Project/LinkXplore

</details>


### [319] [An LLM-based Quantitative Framework for Evaluating High-Stealthy Backdoor Risks in OSS Supply Chains](https://arxiv.org/abs/2511.13341)
*Zihe Yan,Kai Luo,Haoyu Yang,Yang Yu,Zhuosheng Zhang,Guancheng Li*

Main category: cs.SE

TL;DR: 论文提出一个开源软件后门风险评估框架，结合攻击者视角和LLMs语义评估，发现Debian生态中多个高优先级包存在安全风险。


<details>
  <summary>Details</summary>
Motivation: 现代软件开发中，开源软件供应链的维护不足和社区审计不充分导致源代码安全和仓库维护者合法性面临挑战，尤其是高隐蔽性后门攻击（如XZ-Util事件）。

Method: 使用大型语言模型（LLMs）对代码仓库进行语义评估，不依赖人工制定的模式，同时定义针对每个攻击阶段的指标。

Result: 实验评估了Debian生态系统中的66个高优先级包，结果显示当前开源软件供应链暴露于多种安全风险。

Conclusion: 论文提出了一个细粒度的开源软件后门风险评估框架，通过模拟攻击者视角定义针对性指标，并利用大型语言模型进行语义评估，实验表明当前开源软件供应链存在多种安全风险。

Abstract: In modern software development workflows, the open-source software supply chain contributes significantly to efficient and convenient engineering practices. With increasing system complexity, using open-source software as third-party dependencies has become a common practice. However, the lack of maintenance for underlying dependencies and insufficient community auditing create challenges in ensuring source code security and the legitimacy of repository maintainers, especially under high-stealthy backdoor attacks exemplified by the XZ-Util incident. To address these problems, we propose a fine-grained project evaluation framework for backdoor risk assessment in open-source software. The framework models stealthy backdoor attacks from the viewpoint of the attacker and defines targeted metrics for each attack stage. In addition, to overcome the limitations of static analysis in assessing the reliability of repository maintenance activities such as irregular committer privilege escalation and limited participation in reviews, the framework uses large language models (LLMs) to conduct semantic evaluation of code repositories without relying on manually crafted patterns. The framework is evaluated on sixty six high-priority packages in the Debian ecosystem. The experimental results indicate that the current open-source software supply chain is exposed to various security risks.

</details>


### [320] [FLOWER: Flow-Oriented Entity-Relationship Tool](https://arxiv.org/abs/2511.13357)
*Dmitry Moskalev*

Main category: cs.SE

TL;DR: FLOWER是一种端到端工具，通过动态采样和数据分析自动优化实体关系模型，显著提升数据处理效率和质量，适用于多种SQL方言和自然语言。


<details>
  <summary>Details</summary>
Motivation: 为了解决实体关系模型构建中的人为因素问题，并优化数据处理和可视化中的资源密集型任务，提出了FLOWER这一端到端解决方案。

Method: FLOWER采用动态采样和鲁棒数据分析技术，自动检测内置约束并生成必要的正确约束，支持SQL或自然语言的数据探索。

Result: 在STATS基准测试中，FLOWER在分布表示和约束学习方面分别比水库采样快2.4倍和2.6倍，加速2.15倍；在数据叙事方面，准确率提升1.19倍，上下文减少1.86倍。

Conclusion: FLOWER工具在实体关系建模和数据叙事方面表现出色，能够显著提升数据处理的效率和质量，适用于多种实际应用场景。

Abstract: Exploring relationships across data sources is a crucial optimization for entities recognition. Since databases can store big amount of information with synthetic and organic data, serving all quantity of objects correctly is an important task to deal with. However, the decision of how to construct entity relationship model is associated with human factor. In this paper, we present flow-oriented entity-relationship tool. This is first and unique end-to-end solution that eliminates routine and resource-intensive problems of processing, creating and visualizing both of explicit and implicit dependencies for prominent SQL dialects on-the-fly. Once launched, FLOWER automatically detects built-in constraints and starting to create own correct and necessary one using dynamic sampling and robust data analysis techniques. This approach applies to improve entity-relationship model and data storytelling to better understand the foundation of data and get unseen insights from DB sources using SQL or natural language. Evaluated on state-of-the-art STATS benchmark, experiments show that FLOWER is superior to reservoir sampling by 2.4x for distribution representation and 2.6x for constraint learning with 2.15x acceleration. For data storytelling, our tool archives 1.19x for accuracy enhance with 1.86x context decrease compare to LLM. Presented tool is also support 23 languages and compatible with both of CPU and GPU. Those results show that FLOWER can manage with real-world data a way better to ensure with quality, scalability and applicability for different use-cases.

</details>


### [321] [BIOMERO 2.0: end-to-end FAIR infrastructure for bioimaging data import, analysis, and provenance](https://arxiv.org/abs/2511.13611)
*Torec T. Luik,Joost de Folter,Rodrigo Rosas-Bertolini,Eric A. J. Reits,Ron A. Hoebe,Przemek M. Krawczyk*

Main category: cs.SE

TL;DR: BIOMERO 2.0升级为FAIR兼容的生命科学成像平台，通过容器化和插件集成，实现数据导入到分析的全流程溯源和可重用性。


<details>
  <summary>Details</summary>
Motivation: 为了解决生命科学成像数据在导入、分析和共享过程中的可追溯性和可重用性问题，BIOMERO 2.0旨在实现FAIR原则（可查找、可访问、可互操作、可重用）和溯源意识。

Method: BIOMERO 2.0采用容器化组件和OMERO.web插件，实现了数据导入、预处理和分析的无缝集成，并通过BIOMERO Python库协调高性能计算系统的分析过程。

Result: BIOMERO 2.0成功将OMERO转变为FAIR兼容的平台，通过集成仪表板实时记录和访问导入和分析的溯源信息，支持可追踪和可重用的工作流程。

Conclusion: BIOMERO 2.0通过集成数据导入、预处理、分析和流程监控，将OMERO转变为一个FAIR兼容、支持溯源的生命科学成像平台，显著提升了数据的可追溯性和可重用性。

Abstract: We present BIOMERO 2.0, a major evolution of the BIOMERO framework that transforms OMERO into a FAIR-compliant (findable, accessible, interoperable, and reusable), provenance-aware bioimaging platform. BIOMERO 2.0 integrates data import, preprocessing, analysis, and workflow monitoring through an OMERO.web plugin and containerized components. The importer subsystem facilitates in-place import using containerized preprocessing and metadata enrichment via forms, while the analyzer subsystem coordinates and tracks containerized analyses on high-performance computing systems via the BIOMERO Python library. All imports and analyses are recorded with parameters, versions, and results, ensuring real-time provenance accessible through integrated dashboards. This dual approach places OMERO at the heart of the bioimaging analysis process: the importer ensures provenance from image acquisition through preprocessing and import into OMERO, while the analyzer records it for downstream processing. These integrated layers enhance OMEROs FAIRification, supporting traceable, reusable workflows for image analysis that bridge the gap between data import, analysis, and sharing.

</details>


### [322] [Live-SWE-agent: Can Software Engineering Agents Self-Evolve on the Fly?](https://arxiv.org/abs/2511.13646)
*Chunqiu Steven Xia,Zhe Wang,Yan Yang,Yuxiang Wei,Lingming Zhang*

Main category: cs.SE

TL;DR: Live-SWE-agent是首个能在运行时自主进化的实时软件代理，性能优于现有开源方案，并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM代理通常需要专门设计且可能不够优化，而自我改进的代理又需要昂贵的离线训练且泛化能力有限。因此，需要一种能在运行时自主进化的实时软件代理。

Method: Live-SWE-agent从仅具备基本bash工具的代理框架开始，通过自主进化其实现来解决问题。

Result: 在SWE-bench Verified基准测试中，Live-SWE-agent的解决率达到75.4%，在SWE-Bench Pro基准测试中达到45.8%，均优于现有手动设计的软件代理。

Conclusion: Live-SWE-agent是一种创新的实时软件代理，能够在解决实际软件问题时自主且持续地进化，其性能优于现有开源解决方案，并接近最佳专有解决方案的表现。

Abstract: Large Language Models (LLMs) are reshaping almost all industries, including software engineering. In recent years, a number of LLM agents have been proposed to solve real-world software problems. Such software agents are typically equipped with a suite of coding tools and can autonomously decide the next actions to form complete trajectories to solve end-to-end software tasks. While promising, they typically require dedicated design and may still be suboptimal, since it can be extremely challenging and costly to exhaust the entire agent scaffold design space. Recognizing that software agents are inherently software themselves that can be further refined/modified, researchers have proposed a number of self-improving software agents recently, including the Darwin-Gödel Machine (DGM). Meanwhile, such self-improving agents require costly offline training on specific benchmarks and may not generalize well across different LLMs or benchmarks. In this paper, we propose Live-SWE-agent, the first live software agent that can autonomously and continuously evolve itself on-the-fly during runtime when solving real-world software problems. More specifically, Live-SWE-agent starts with the most basic agent scaffold with only access to bash tools (e.g., mini-SWE-agent), and autonomously evolves its own scaffold implementation while solving real-world software problems. Our evaluation on the widely studied SWE-bench Verified benchmark shows that Live-SWE-agent can achieve an impressive solve rate of 75.4% without test-time scaling, outperforming all existing open-source software agents and approaching the performance of the best proprietary solution. Moreover, Live-SWE-agent outperforms state-of-the-art manually crafted software agents on the recent SWE-Bench Pro benchmark, achieving the best-known solve rate of 45.8%.

</details>


### [323] [What's in a Software Engineering Job Posting?](https://arxiv.org/abs/2511.13656)
*Marvin Wyrich,Lloyd Montgomery*

Main category: cs.SE

TL;DR: 研究发现，软件工程师职位不仅要求技术能力，还强调使命感、文化契合、成长和人际互动等非技术技能。


<details>
  <summary>Details</summary>
Motivation: 探讨软件工程师职位描述中强调的非技术方面，揭示雇主的社会技术和组织期望。

Method: 通过对100份招聘广告进行主题分析

Result: 雇主更看重候选人与其使命感、公司文化的契合度、个人与职业成长以及人际互动能力。

Conclusion: 本研究强调了软件工程师角色中非技术技能的重要性，为研究者、教育者、从业者和招聘者提供了相关见解，并记录了2023年SE招聘趋势。

Abstract: A well-rounded software engineer is often defined by technical prowess and the ability to deliver on complex projects. However, the narrative around the ideal Software Engineering (SE) candidate is evolving, suggesting that there is more to the story. This article explores the non-technical aspects emphasized in SE job postings, revealing the sociotechnical and organizational expectations of employers. Our Thematic Analysis of 100 job postings shows that employers seek candidates who align with their sense of purpose, fit within company culture, pursue personal and career growth, and excel in interpersonal interactions. This study contributes to ongoing discussions in the SE community about the evolving role and workplace context of software engineers beyond technical skills. By highlighting these expectations, we provide relevant insights for researchers, educators, practitioners, and recruiters. Additionally, our analysis offers a valuable snapshot of SE job postings in 2023, providing a scientific record of prevailing trends and expectations.

</details>


### [324] [Ontology-Driven Model-to-Model Transformation of Workflow Specifications](https://arxiv.org/abs/2511.13661)
*Francisco Abreu,Luís Cruz,Sérgio Guerreiro*

Main category: cs.SE

TL;DR: 本研究开发了一个基于本体的转换管道，将专有工作流语言转换为标准BPMN 2.0，成功率为94.2%，显著提升了互操作性和可维护性。


<details>
  <summary>Details</summary>
Motivation: 专有工作流建模语言（如Smart Forms & Smart Flow）限制了互操作性和重用性，将过程知识锁定在封闭格式中。为了解决这种供应商锁定问题并促进向开放标准的迁移。

Method: 研究采用了三阶段的转换管道：基于RML的JSON到RDF/OWL语义提升、本体对齐和推理，以及通过Camunda Model API生成BPMN。

Result: 在69个真实世界工作流的评估中，成功生成了92个BPMN图表，成功率为94.2%。失败的案例（5.81%）主要源于静态JSON中未明确的动态行为和时间转换。

Conclusion: 本研究通过引入基于本体的模型到模型转换管道，成功地将专有工作流定义转换为标准BPMN 2.0，显著提升了互操作性和可重用性，并为利益相关者带来了可量化的性能和定性收益。

Abstract: Proprietary workflow modeling languages such as Smart Forms & Smart Flow hamper interoperability and reuse because they lock process knowledge into closed formats. To address this vendor lock-in and ease migration to open standards, we introduce an ontology-driven model-to-model pipeline that systematically translates domain-specific workflow definitions to Business Process Model and Notation (BPMN) 2.0. The pipeline comprises three phases: RML-based semantic lifting of JSON to RDF/OWL, ontology alignment and reasoning, and BPMN generation via the Camunda Model API. By externalizing mapping knowledge into ontologies and declarative rules rather than code, the approach supports reusability across vendor-specific formats and preserves semantic traceability between source definitions and target BPMN models. We instantiated the pipeline for Instituto Superior Técnico (IST)'s Smart Forms & Smart Flow and implemented a converter that produces standard-compliant BPMN diagrams. Evaluation on a corpus of 69 real-world workflows produced 92 BPMN diagrams with a 94.2% success rate. Failures (5.81%) stemmed from dynamic behaviors and time-based transitions not explicit in the static JSON. Interviews with support and development teams indicated that the resulting diagrams provide a top-down view that improves comprehension, diagnosis and onboarding by exposing implicit control flow and linking tasks and forms back to their sources. The pipeline is generalizable to other proprietary workflow languages by adapting the ontology and mappings, enabling interoperability and reducing vendor dependency while supporting continuous integration and long-term maintainability. The presented case study demonstrates that ontology-driven M2M transformation can systematically bridge domain-specific workflows and standard notations, offering quantifiable performance and qualitative benefits for stakeholders.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [325] [ACE-GNN: Adaptive GNN Co-Inference with System-Aware Scheduling in Dynamic Edge Environments](https://arxiv.org/abs/2511.11586)
*Ao Zhou,Jianlei Yang,Tong Qiao,Yingjie Qi,Xinming Wei,Cenlin Duan,Weisheng Zhao,Chunming Hu*

Main category: cs.DC

TL;DR: ACE-GNN是首个针对动态边缘环境的自适应GNN协同推理框架，通过系统级抽象、预测方法和DP/PP调度，显著提升了性能和能效。


<details>
  <summary>Details</summary>
Motivation: 解决现有静态部署方法在动态边缘环境中（如网络波动和多设备访问）性能受限的问题，提升GNN协同推理的适应性和效率。

Method: ACE-GNN采用系统级抽象和两种新颖的预测方法，结合数据并行机制（DP）和管道并行（PP）的自适应调度，以及高效的批处理推理策略和专用通信中间件。

Result: 实验显示，ACE-GNN相比GCoDE实现了最高12.7倍的速度提升和82.3%的能耗节省，相比Fograph提升了11.7倍的能效。

Conclusion: ACE-GNN通过动态适应边缘环境的变化，显著提升了GNN协同推理的性能和稳定性，实验证明了其在速度和能效上的显著优势。

Abstract: The device-edge co-inference paradigm effectively bridges the gap between the high resource demands of Graph Neural Networks (GNNs) and limited device resources, making it a promising solution for advancing edge GNN applications. Existing research enhances GNN co-inference by leveraging offline model splitting and pipeline parallelism (PP), which enables more efficient computation and resource utilization during inference. However, the performance of these static deployment methods is significantly affected by environmental dynamics such as network fluctuations and multi-device access, which remain unaddressed. We present ACE-GNN, the first Adaptive GNN Co-inference framework tailored for dynamic Edge environments, to boost system performance and stability. ACE-GNN achieves performance awareness for complex multi-device access edge systems via system-level abstraction and two novel prediction methods, enabling rapid runtime scheme optimization. Moreover, we introduce a data parallelism (DP) mechanism in the runtime optimization space, enabling adaptive scheduling between PP and DP to leverage their distinct advantages and maintain stable system performance. Also, an efficient batch inference strategy and specialized communication middleware are implemented to further improve performance. Extensive experiments across diverse applications and edge settings demonstrate that ACE-GNN achieves a speedup of up to 12.7x and an energy savings of 82.3% compared to GCoDE, as well as 11.7 better energy efficiency than Fograph.

</details>


### [326] [Distributed Q-learning-based Shortest-Path Tree Construction in IoT Sensor Networks](https://arxiv.org/abs/2511.11598)
*Van-Vi Vo,Tien-Dung Nguyen,Duc-Tai Le,Hyunseung Choo*

Main category: cs.DC

TL;DR: 论文提出了一种基于Q学习的分布式路由框架，适用于IoT传感器网络，显著提升了能源效率和可扩展性，相比传统方法表现更优。


<details>
  <summary>Details</summary>
Motivation: 传统集中式算法（如Dijkstra）计算密集，不适合动态、分布式的IoT环境，因此需要一种更高效的路由方法。

Method: 提出了一种新颖的分布式Q学习框架，用于构建最短路径树（SPTs），使传感器节点能够仅利用本地信息独立学习最优的下一跳决策。状态基于节点位置和路由历史定义，奖励函数激励向汇聚节点的进展，同时惩罚低效路径。

Result: 在100至500个节点的网络中进行模拟，结果显示路由准确性接近最优（300个节点以上的网络超过99%），小型网络中少量额外跳数（1-2跳）对性能影响可忽略。相比集中式和基于泛洪的方法，该方法减少了通信开销，适应拓扑变化，提升了可扩展性和能源效率。

Conclusion: 该论文强调了Q学习在资源受限的IoT网络中实现自主、鲁棒路由的潜力，为传统协议提供了可扩展的替代方案。

Abstract: Efficient routing in IoT sensor networks is critical for minimizing energy consumption and latency. Traditional centralized algorithms, such as Dijkstra's, are computationally intensive and ill-suited for dynamic, distributed IoT environments. We propose a novel distributed Q-learning framework for constructing shortest-path trees (SPTs), enabling sensor nodes to independently learn optimal next-hop decisions using only local information. States are defined based on node positions and routing history, with a reward function that incentivizes progression toward the sink while penalizing inefficient paths. Trained on diverse network topologies, the framework generalizes effectively to unseen networks. Simulations across 100 to 500 nodes demonstrate near-optimal routing accuracy (over 99% for networks with more than 300 nodes), with minor deviations (1-2 extra hops) in smaller networks having negligible impact on performance. Compared to centralized and flooding-based methods, our approach reduces communication overhead, adapts to topology changes, and enhances scalability and energy efficiency. This work underscores the potential of Q-learning for autonomous, robust routing in resource-constrained IoT networks, offering a scalable alternative to traditional protocols.

</details>


### [327] [Mind the Gap: Revealing Inconsistencies Across Heterogeneous AI Accelerators](https://arxiv.org/abs/2511.11601)
*Elliott Wen,Sean Ma,Ewan Tempero,Jens Dietrich,Daniel Luo,Jiaxing Shen,Kaiqi Zhao,Bruce Sham,Yousong Song,Jiayi Hua,Jia Hong*

Main category: cs.DC

TL;DR: 实证研究表明，新兴AI加速器（如Mac、华为）在算子支持、输出一致性和编译稳定性上显著落后于NVIDIA，且存在PyTorch和平台特定问题。


<details>
  <summary>Details</summary>
Motivation: 研究异构AI加速器在机器学习模型执行中的差异，评估新兴厂商（如AMD、Intel、Mac、华为）与NVIDIA的兼容性和性能差距。

Method: 通过自动化管道合成超过10万个变体模型，并在5种企业级加速器上执行，对比分析算子支持、输出差异及编译失败率。

Result: Mac和华为的AI平台支持算子比NVIDIA少17%，输出差异率超过5%，且编译失败率更高。同时发现PyTorch的7个实现缺陷及40个平台特定问题。

Conclusion: 新兴AI加速器（如Mac和华为）在算子支持、输出一致性和编译稳定性方面与NVIDIA存在显著差距，突显了异构硬件生态中实现一致机器学习行为的挑战。

Abstract: While NVIDIA remains the dominant provider of AI accelerators within cloud data center, emerging vendors such as AMD, Intel, Mac, and Huawei offer cost-effective alternatives with claims of compatibility and performance. This paper presents the first empirical study investigating divergence in machine learning model across heterogeneous AI accelerators. Utilizing an automated pipeline, we synthesize over 100,000 variant models derived from 4,000 real-world models and execute them across five different enterprise-grade accelerators. Our findings suggest that newer AI platforms from Mac and Huawei support at least 17\% fewer operators than NVIDIA. These platforms also exhibit a higher rate of output discrepancies (exceeding 5\%), which stem from differences in operator implementations, handling of exceptional numerical values, and instruction scheduling. They are also more susceptible to failures during model compilation-based acceleration, and in some cases, the compiled models produce outputs that differ noticeably from those generated using the standard execution mode. In addition, we identify 7 implementation flaws in PyTorch and 40 platform-specific issues across vendors. These results underscore the challenges of achieving consistent machine learning behavior in an increasingly diverse hardware ecosystem.

</details>


### [328] [AIvailable: A Software-Defined Architecture for LLM-as-a-Service on Heterogeneous and Legacy GPUs](https://arxiv.org/abs/2511.11621)
*Pedro Antunes,Ana Rita Ortigoso,Gabriel Vieira,Daniel Fuentes,Luís Frazão,Nuno Costa,António Pereira*

Main category: cs.DC

TL;DR: AIvailable 是一个低成本、高可用的 LLMaaS 平台，通过软件定义方法在异构 GPU 上运行 LLM，优化资源利用，适用于资源受限的环境。


<details>
  <summary>Details</summary>
Motivation: 现有框架通常假设硬件资源丰富且同质化，这在学术或资源受限的环境中不现实。AIvailable 旨在通过异构和传统 GPU 节点实现高效资源利用，降低生成式 AI 的使用门槛。

Method: AIvailable 采用完全 GPU 加速的推理架构，无需 CPU 回退，包含统一的客户端接口和四个主要组件：客户端接口、服务前端、SDAI 控制器和服务后端。

Result: AIvailable 实现了动态、VRAM 感知的模型分配和重新分配，确保资源高效利用，并支持多种开源 LLM，重新利用传统 GPU。

Conclusion: AIvailable 是一个低成本、高可用性的 LLMaaS 平台，通过软件定义的方法在异构和传统 GPU 节点上运行 LLM，专注于充分利用每个节点的 VRAM，为资源受限的组织提供高效、弹性的生成式 AI 服务。

Abstract: The rise of Large Language Models (LLM) has increased the need for scalable, high-performance inference systems, yet most existing frameworks assume homogeneous, resource-rich hardware, often unrealistic in academic, or resource-constrained settings. We introduce AIvailable, a low-cost, highly available LLM-as-a-Service (LLMaaS) platform, that uses a software-defined approach for running LLMs across heterogeneous and legacy GPU nodes, including NVIDIA and AMD devices, with a focus on fully utilizing each node's VRAM. AIvailable operates as a fully GPU-accelerated inference without CPU fallbacks, featuring a unified client interface that allows seamless interaction with all deployed LLMs through a single logical unit. The architecture comprises four main components: the Client Interface for user access, the Service Frontend for secure request routing and load balancing, the SDAI Controller for orchestration, deployment, and monitoring, and the Service Backend of heterogeneous GPU nodes executing workloads. By abstracting GPU-specific details and providing dynamic, VRAM-aware allocation and reallocation of models, AIvailable ensures efficient use of resources and resilience against failures or workload fluctuations. Targeting academic labs, private companies, and other constrained organizations, it supports diverse open LLMs helping democratize generative AI through the repurposing of legacy GPUs.

</details>


### [329] [Machine learning-based cloud resource allocation algorithms: a comprehensive comparative review](https://arxiv.org/abs/2511.11603)
*Deep Bodra,Sushil Khairnar*

Main category: cs.DC

TL;DR: 本文比较了10种AI和ML算法在云资源分配中的表现，发现混合架构在多目标优化中表现最佳，尤其在边缘计算环境中具有高部署准备度。


<details>
  <summary>Details</summary>
Motivation: 传统启发式方法难以满足云计算基础设施的多目标优化需求，需要更高效的资源分配策略。

Method: 对10种算法进行了系统评估，涵盖深度强化学习、神经网络架构、传统机器学习增强方法和多智能体系统四大类别。

Result: 分析显示，在任务完成时间缩短、成本优化和能效提升等多个指标上，AI和ML算法显著优于传统方法。

Conclusion: 混合架构结合多种人工智能和机器学习技术在多目标优化中表现最佳，尤其是在边缘计算环境中具备较高的部署准备度。

Abstract: Cloud resource allocation has emerged as a major challenge in modern computing environments, with organizations struggling to manage complex, dynamic workloads while optimizing performance and cost efficiency. Traditional heuristic approaches prove inadequate for handling the multi-objective optimization demands of existing cloud infrastructures. This paper presents a comparative analysis of state-of-the-art artificial intelligence and machine learning algorithms for resource allocation. We systematically evaluate 10 algorithms across four categories: Deep Reinforcement Learning approaches, Neural Network architectures, Traditional Machine Learning enhanced methods, and Multi-Agent systems. Analysis of published results demonstrates significant performance improvements across multiple metrics including makespan reduction, cost optimization, and energy efficiency gains compared to traditional methods. The findings reveal that hybrid architectures combining multiple artificial intelligence and machine learning techniques consistently outperform single-method approaches, with edge computing environments showing the highest deployment readiness. Our analysis provides critical insights for both academic researchers and industry practitioners seeking to implement next-generation cloud resource allocation strategies in increasingly complex and dynamic computing environments.

</details>


### [330] [PACE Solver Description: twin_width_fmi](https://arxiv.org/abs/2511.11605)
*David Balaban,Adrian Miclăuş*

Main category: cs.DC

TL;DR: 本文提出了一种名为\texttt{hedom5}的启发式算法，结合贪心、剪枝和局部优化，高效解决了最小支配集问题，并在竞赛中表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了在PACE 2025竞赛的启发式赛道中高效解决最小支配集问题，作者开发了一种结合贪心与局部搜索的新方法，以提升解的质量和计算效率。

Method: 算法结合了贪心构造、后向剪枝和局部优化的多阶段策略，包括CSR图结构存储、快速简化、基于优先队列的懒惰贪心阶段、后向剪枝和预算化的1-swap局部改进。

Result: \texttt{hedom5}算法通过多阶段优化，显著提升了最小支配集的求解效果，成为最终提交的最佳方案。

Conclusion: 本文提出了一种名为\texttt{hedom5}的高效启发式算法，用于解决最小支配集问题，并在PACE 2025竞赛中取得了良好表现。

Abstract: In this paper we present \texttt{twin\_width\_fmi}'s solver for the heuristic track of PACE's 2025 competition on Minimum Dominating Set.
  As a baseline, we implement \texttt{greedy-ln}, a standard greedy dominating-set heuristic that repeatedly selects the vertex that newly dominates the largest number of currently undominated vertices. We then use this greedy solution as the starting point for a simulated annealing local search: we attempt vertex removals and exchanges and accept worsening moves with decaying probability, in order to escape local minima while preserving domination.
  Our best-performing component, which we ultimately submitted, is \texttt{hedom5}. The design of \texttt{hedom5} is inspired by recent iterative-greedy style domination heuristics~\cite{IterativeGreedy22} that alternate between constructive steps, pruning, and focused repair rather than relying on a single pass. In \texttt{hedom5}, the input graph is first stored in a compact CSR structure and simplified using fast reductions such as forcing neighbors of leaves and handling isolates. We then run a lazy gain-based greedy stage using a priority queue: each candidate vertex is scored by how many currently undominated vertices its closed neighborhood would newly dominate, and scores are only recomputed when necessary. After this constructive phase, we perform an aggressive backward pruning pass that iterates over the chosen dominators in reverse insertion order and deletes any vertex whose closed neighborhood is still fully dominated by the remaining set. Finally, we run a budgeted 1-swap local improvement step that attempts to replace a dominator by an alternative vertex that covers all of its uniquely covered vertices, thereby reducing the size of the dominating set. A brief safety patch at the end guarantees full domination.

</details>


### [331] [Why Should the Server Do It All?: A Scalable, Versatile, and Model-Agnostic Framework for Server-Light DNN Inference over Massively Distributed Clients via Training-Free Intermediate Feature Compression](https://arxiv.org/abs/2511.11608)
*Mingyu Sung,Suhwan Im,Daeho Bang,Il-Min Kim,Sangseok Yun,Jae-Mo Kang*

Main category: cs.DC

TL;DR: SLICER通过压缩中间特征，显著减少通信和服务器负载，适用于边缘-云分布式推理。


<details>
  <summary>Details</summary>
Motivation: 现代DNN通常依赖边缘-云模型分区，但现有方案固定浅层静态分割点，未能充分利用边缘计算，且集中了延迟和能耗在服务器端，尤其在自回归LLM推理中问题更突出。

Method: SLICER通过ATKF稀疏化激活、MS分组非零值、ABQ自适应量化比特宽度，压缩中间特征以减少通信和服务器负载。

Result: SLICER在标准视觉和LLM任务中，上传量减少达10倍，服务器GPU时间减少达4.4倍，任务质量保持在基线0-3个百分点内。

Conclusion: SLICER提供了一个即插即用的解决方案，无需重新训练或架构改动，即可实现可扩展、低延迟的分布式推理。

Abstract: Modern DNNs often rely on edge-cloud model partitioning (MP), but widely used schemes fix shallow, static split points that underutilize edge compute and concentrate latency and energy on the server. The problem is exacerbated in autoregressive (AR) LLM inference, where per-token forward passes repeatedly generate bulky intermediate features (IFs). We introduce SLICER, a retraining-free, architecture-agnostic framework that compresses IFs to reduce both communication and server load in split computing. SLICER combines (i) asymmetric top-K filtering (ATKF) to sparsify low-magnitude activations, (ii) magnitude-splitting (MS) to group the remaining non-zeros into equal-cardinality blocks, and (iii) adaptive bit quantization (ABQ) that selects per-block bitwidths under a distortion budget. Across standard vision and LLM workloads (e.g., ImageNet/COCO; HellaSwag, PIQA, ARC-E/C, GSM8K, HumanEval), SLICER reduces uplink volume by up to 10x and server GPU time by up to 4.4x, while keeping task quality within ~0-3 pp of baseline. In multi-device settings and AR LLMs, SLICER scales by shifting meaningful compute to the edge and lowering bits-per-token and server time per token, stabilizing per-step traffic. The codec attaches to off-the-shelf models without retraining or architectural changes, offering a plug-and-play path to scalable, low-latency distributed inference. Code is provided in the supplementary material.

</details>


### [332] [Evaluating Large Language Models for Workload Mapping and Scheduling in Heterogeneous HPC Systems](https://arxiv.org/abs/2511.11612)
*Aasish Kumar Sharma,Julian Kunkel*

Main category: cs.DC

TL;DR: 研究评估了21个LLM在HPC调度任务中的表现，发现少数能精确复制最优解，多数在时间计算和依赖执行上有困难，凸显了LLMs作为协作者的潜力而非自主求解器。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的推理能力日益受到关注，但其在基于自然语言的结构化、约束优化方面的能力仍未被充分理解。本研究旨在填补这一空白。

Method: 本研究评估了21个公开可用的LLM，在一个代表性的异构高性能计算（HPC）工作负载映射和调度问题上。每个模型接收相同的系统节点、任务需求和调度约束的文本描述，并要求其分配任务到节点、计算总完成时间并解释其推理过程。

Result: 三个模型完全复制了分析最优解（9小时20秒），十二个模型实现了接近最优的结果（与参考值相差两分钟内），六个模型产生了次优调度（存在算术或依赖错误）。所有模型生成了可行的任务到节点映射，但只有约一半严格遵循约束。十九个模型生成了部分可执行的验证代码，十八个模型提供了连贯的逐步推理。

Conclusion: 研究结论表明，领先的大语言模型（LLMs）能够直接从自然语言重建最优调度方案，但大多数模型在精确时间计算、数据传输算术和依赖关系执行方面仍有困难。这些发现突出了LLMs作为优化和决策支持任务的可解释协作者而非自主求解器的潜力。

Abstract: Large language models (LLMs) are increasingly explored for their reasoning capabilities, yet their ability to perform structured, constraint-based optimization from natural language remains insufficiently understood. This study evaluates twenty-one publicly available LLMs on a representative heterogeneous high-performance computing (HPC) workload mapping and scheduling problem. Each model received the same textual description of system nodes, task requirements, and scheduling constraints, and was required to assign tasks to nodes, compute the total makespan, and explain its reasoning. A manually derived analytical optimum of nine hours and twenty seconds served as the ground truth reference. Three models exactly reproduced the analytical optimum while satisfying all constraints, twelve achieved near-optimal results within two minutes of the reference, and six produced suboptimal schedules with arithmetic or dependency errors. All models generated feasible task-to-node mappings, though only about half maintained strict constraint adherence. Nineteen models produced partially executable verification code, and eighteen provided coherent step-by-step reasoning, demonstrating strong interpretability even when logical errors occurred. Overall, the results define the current capability boundary of LLM reasoning in combinatorial optimization: leading models can reconstruct optimal schedules directly from natural language, but most still struggle with precise timing, data transfer arithmetic, and dependency enforcement. These findings highlight the potential of LLMs as explainable co-pilots for optimization and decision-support tasks rather than autonomous solvers.

</details>


### [333] [Beyond the GPU: The Strategic Role of FPGAs in the Next Wave of AI](https://arxiv.org/abs/2511.11614)
*Arturo Urías Jiménez*

Main category: cs.DC

TL;DR: FPGA作为可重构硬件，通过直接映射AI算法实现低延迟、高能效和深度定制，优于传统GPU，适用于高性能和定制化需求的工作负载。


<details>
  <summary>Details</summary>
Motivation: 随着对低延迟、高能效和细粒度硬件控制需求的增长，固定架构（如GPU）的局限性日益显现，FPGA因其可重构特性成为解决方案。

Method: 通过将AI算法直接映射到设备逻辑中，利用FPGA实现并行管道，包括卷积、注意力机制和后处理，具有确定性的时序和降低的功耗。

Result: FPGA能够现场重新配置，适应特定模型，集成嵌入式处理器作为SoC，并在传感器附近运行推理，减少延迟和带宽需求，提升隐私保护，并释放GPU在数据中心的专用任务。

Conclusion: FPGA作为一种可重构平台，在AI加速领域展现出其在低延迟、能效和硬件定制方面的优势，为需要高性能和深度定制的工作负载提供了战略选择。

Abstract: AI acceleration has been dominated by GPUs, but the growing need for lower latency, energy efficiency, and fine-grained hardware control exposes the limits of fixed architectures. In this context, Field-Programmable Gate Arrays (FPGAs) emerge as a reconfigurable platform that allows mapping AI algorithms directly into device logic. Their ability to implement parallel pipelines for convolutions, attention mechanisms, and post-processing with deterministic timing and reduced power consumption makes them a strategic option for workloads that demand predictable performance and deep customization.
  Unlike CPUs and GPUs, whose architecture is immutable, an FPGA can be reconfigured in the field to adapt its physical structure to a specific model, integrate as a SoC with embedded processors, and run inference near the sensor without sending raw data to the cloud. This reduces latency and required bandwidth, improves privacy, and frees GPUs from specialized tasks in data centers. Partial reconfiguration and compilation flows from AI frameworks are shortening the path from prototype to deployment, enabling hardware--algorithm co-design.

</details>


### [334] [AnchorTP: Resilient LLM Inference with State-Preserving Elastic Tensor Parallelism](https://arxiv.org/abs/2511.11617)
*Wendong Xu,Chujie Chen,He Xiao,Kuan Li,Jing Xiong,Chen Zhang,Wenyong Zhou,Chaofan Tao,Yang Bai,Bei Yu,Ngai Wong*

Main category: cs.DC

TL;DR: AnchorTP是一个弹性张量并行框架，通过状态保留和优化数据迁移，快速恢复LLM推理服务，显著减少故障恢复时间。


<details>
  <summary>Details</summary>
Motivation: 解决多GPU张量并行（TP）在LLM推理服务中因单GPU故障导致的高可用性和低延迟需求难以满足的问题。

Method: 提出AnchorTP框架，包含弹性张量并行（ETP）与不均衡宽度分区、状态保留机制（通过守护进程分离KV缓存和参数）、带宽感知规划器（CMM算法）和执行调度器（P2P传输与重载流水线）。

Result: 在典型故障场景下，AnchorTP将首次成功时间（TFS）降低至11倍，峰值时间（TTP）减少59%，显著优于重启重载方法。

Conclusion: AnchorTP通过弹性张量并行（ETP）和状态保留机制显著提升了LLM推理服务的可用性和恢复速度，减少了因单GPU故障导致的停机时间。

Abstract: Large Language Model (LLM) inference services demand exceptionally high availability and low latency, yet multi-GPU Tensor Parallelism (TP) makes them vulnerable to single-GPU failures. We present AnchorTP, a state-preserving elastic TP framework for fast recovery. It (i) enables Elastic Tensor Parallelism (ETP) with unequal-width partitioning over any number of GPUs and compatibility with Mixture-of-Experts (MoE), and (ii) preserves model parameters and KV caches in GPU memory via a daemon decoupled from the inference process. To minimize downtime, we propose a bandwidth-aware planner based on a Continuous Minimal Migration (CMM) algorithm that minimizes reload bytes under a byte-cost dominance assumption, and an execution scheduler that pipelines P2P transfers with reloads. These components jointly restore service quickly with minimal data movement and without changing service interfaces. In typical failure scenarios, AnchorTP reduces Time to First Success (TFS) by up to 11x and Time to Peak (TTP) by up to 59% versus restart-and-reload.

</details>


### [335] [DIAP: A Decentralized Agent Identity Protocol with Zero-Knowledge Proofs and a Hybrid P2P Stack](https://arxiv.org/abs/2511.11619)
*Yuanjie Liu,Wenpeng Xing,Ye Zhou,Gaowei Chang,Changting Lin,Meng Han*

Main category: cs.DC

TL;DR: DIAP是一个去中心化的星际代理协议，通过ZKP和IPFS实现持久、可验证且无需信任的互操作性，为自主代理生态系统提供基础。


<details>
  <summary>Details</summary>
Motivation: 现有系统通常依赖中心化中介，重新引入信任瓶颈，或缺乏去中心化身份解析机制，限制了持久性和跨网络互操作性。

Method: DIAP通过绑定代理身份到不可变的IPFS或IPNS内容标识符，并使用零知识证明（ZKP）动态和无状态地证明所有权，消除了记录更新的需求。提出了一个Rust SDK，集成了Noir（用于ZKP）、DID-Key、IPFS以及混合P2P堆栈。

Result: DIAP实现了即时、可验证且保护隐私的身份证明，通过零依赖的ZKP部署模型和预编译的Noir电路，消除了对外部ZKP工具链的需求。

Conclusion: DIAP提供了一个实用且高性能的基础，为下一代自主代理生态系统和代理间经济（A to A）奠定了基础。

Abstract: The absence of a fully decentralized, verifiable, and privacy-preserving communication protocol for autonomous agents remains a core challenge in decentralized computing. Existing systems often rely on centralized intermediaries, which reintroduce trust bottlenecks, or lack decentralized identity-resolution mechanisms, limiting persistence and cross-network interoperability.
  We propose the Decentralized Interstellar Agent Protocol (DIAP), a novel framework for agent identity and communication that enables persistent, verifiable, and trustless interoperability in fully decentralized environments. DIAP binds an agent's identity to an immutable IPFS or IPNS content identifier and uses zero-knowledge proofs (ZKP) to dynamically and statelessly prove ownership, removing the need for record updates.
  We present a Rust SDK that integrates Noir (for zero-knowledge proofs), DID-Key, IPFS, and a hybrid peer-to-peer stack combining Libp2p GossipSub for discovery and Iroh for high-performance, QUIC based data exchange. DIAP introduces a zero-dependency ZKP deployment model through a universal proof manager and compile-time build script that embeds a precompiled Noir circuit, eliminating the need for external ZKP toolchains. This enables instant, verifiable, and privacy-preserving identity proofs.
  This work establishes a practical, high-performance foundation for next-generation autonomous agent ecosystems and agent-to-agent (A to A) economies.

</details>


### [336] [Characterizing and Understanding Energy Footprint and Efficiency of Small Language Model on Edges](https://arxiv.org/abs/2511.11624)
*Md Romyull Islam,Bobin Deng,Nobel Dhar,Tu N. Nguyen,Selena He,Yong Shi,Kun Suo*

Main category: cs.DC

TL;DR: 研究评估了五款SLM在边缘设备上的能效，发现GPU加速的Jetson Orin Nano表现最优，Llama 3.2平衡性佳，TinyLlama适合低功耗场景。


<details>
  <summary>Details</summary>
Motivation: 边缘设备部署小型语言模型（SLM）可降低延迟并摆脱网络依赖，但其有限的计算资源和能源预算带来了挑战。

Method: 评估了五款代表性SLM（Llama 3.2、Phi-3 Mini、TinyLlama和Gemma 2）在Raspberry Pi 5、Jetson Nano和Jetson Orin Nano（CPU与GPU配置）上的能效表现。

Result: Jetson Orin Nano在GPU加速下能效比最高；Llama 3.2平衡性最佳，TinyLlama适合低功耗但准确性较低，Phi-3 Mini能耗最高。

Conclusion: GPU acceleration and model架构是优化推理能效的关键，Jetson Orin Nano在GPU配置下表现最佳。Llama 3.2在准确性与能效间取得最佳平衡，而TinyLlama适合低功耗场景。

Abstract: Cloud-based large language models (LLMs) and their variants have significantly influenced real-world applications. Deploying smaller models (i.e., small language models (SLMs)) on edge devices offers additional advantages, such as reduced latency and independence from network connectivity. However, edge devices' limited computing resources and constrained energy budgets challenge efficient deployment. This study evaluates the power efficiency of five representative SLMs - Llama 3.2, Phi-3 Mini, TinyLlama, and Gemma 2 on Raspberry Pi 5, Jetson Nano, and Jetson Orin Nano (CPU and GPU configurations). Results show that Jetson Orin Nano with GPU acceleration achieves the highest energy-to-performance ratio, significantly outperforming CPU-based setups. Llama 3.2 provides the best balance of accuracy and power efficiency, while TinyLlama is well-suited for low-power environments at the cost of reduced accuracy. In contrast, Phi-3 Mini consumes the most energy despite its high accuracy. In addition, GPU acceleration, memory bandwidth, and model architecture are key in optimizing inference energy efficiency. Our empirical analysis offers practical insights for AI, smart systems, and mobile ad-hoc platforms to leverage tradeoffs from accuracy, inference latency, and power efficiency in energy-constrained environments.

</details>


### [337] [Mixture-of-Schedulers: An Adaptive Scheduling Agent as a Learned Router for Expert Policies](https://arxiv.org/abs/2511.11628)
*Xinbo Wang,Shian Jia,Ziyang Huang,Jing Cao,Mingli Song*

Main category: cs.DC

TL;DR: ASA是一种动态选择调度策略的框架，通过机器学习和工作负载识别，显著提升调度性能。


<details>
  <summary>Details</summary>
Motivation: 传统静态调度策略无法适应现代系统多样化和动态化的工作负载需求，导致公平性、吞吐量和延迟方面的性能折衷。

Method: ASA采用离线训练和在线决策相结合的轻量级框架，利用机器学习模型识别工作负载模式，并通过时间加权概率投票算法和预配置的映射表选择最优调度策略。

Result: ASA在86.4%的测试场景中优于默认Linux调度器（EEVDF），且在78.6%的场景中选择了接近最优的调度策略。

Conclusion: ASA框架通过动态选择最优调度策略，显著提升了调度性能，为操作系统调度器提供了更智能、自适应的解决方案。

Abstract: Modern operating system schedulers employ a single, static policy, which struggles to deliver optimal performance across the diverse and dynamic workloads of contemporary systems. This "one-policy-fits-all" approach leads to significant compromises in fairness, throughput, and latency, particularly with the rise of heterogeneous hardware and varied application architectures.
  This paper proposes a new paradigm: dynamically selecting the optimal policy from a portfolio of specialized schedulers rather than designing a single, monolithic one. We present the Adaptive Scheduling Agent (ASA), a lightweight framework that intelligently matches workloads to the most suitable "expert" scheduling policy at runtime. ASA's core is a novel, low-overhead offline/online approach. First, an offline process trains a universal, hardware-agnostic machine learning model to recognize abstract workload patterns from system behaviors. Second, at runtime, ASA continually processes the model's predictions using a time-weighted probability voting algorithm to identify the workload, then makes a scheduling decision by consulting a pre-configured, machine-specific mapping table to switch to the optimal scheduler via Linux's sched_ext framework. This decoupled architecture allows ASA to adapt to new hardware platforms rapidly without expensive retraining of the core recognition model.
  Our evaluation, based on a novel benchmark focused on user-experience metrics, demonstrates that ASA consistently outperforms the default Linux scheduler (EEVDF), achieving superior results in 86.4% of test scenarios. Furthermore, ASA's selections are near-optimal, ranking among the top three schedulers in 78.6% of all scenarios. This validates our approach as a practical path toward more intelligent, adaptive, and responsive operating system schedulers.

</details>


### [338] [Exploring Parallelism in FPGA-Based Accelerators for Machine Learning Applications](https://arxiv.org/abs/2511.11640)
*Sed Centeno,Christopher Sprague,Arnab A Purkayastha,Ray Simar,Neeraj Magotra*

Main category: cs.DC

TL;DR: 投机反向传播通过重叠前向和反向传播步骤，在MNIST数据集上实现24%的训练加速，准确率损失可控（3-4%），并验证了FPGA硬件加速潜力。


<details>
  <summary>Details</summary>
Motivation: 加速神经网络训练过程，同时保持准确率。

Method: 通过OpenMP的多线程能力，同时执行前向传播和投机反向传播步骤，利用特定的梯度阈值进行投机权重更新。

Result: 在CPU实验中，投机反向传播实现了最高24%的执行时间加速（阈值为0.25），且准确率与基线方法相差3-4%。单个步骤的执行时间最大提升35%。

Conclusion: 在MNIST数据集上，使用OpenMP实现的投机反向传播技术能够显著加速神经网络训练，最大速度提升24%，同时准确率保持在基线方法的3-4%范围内。此外，FPGA硬件加速的潜力也被验证。

Abstract: Speculative backpropagation has emerged as a promising technique to accelerate the training of neural networks by overlapping the forward and backward passes. Leveraging speculative weight updates when error gradients fall within a specific threshold reduces training time without substantially compromising accuracy. In this work, we implement speculative backpropagation on the MNIST dataset using OpenMP as the parallel programming platform. OpenMP's multi-threading capabilities enable simultaneous execution of forward and speculative backpropagation steps, significantly improving training speed. The application is planned for synthesis on a state-of-the-art FPGA to demonstrate its potential for hardware acceleration. Our CPU-based experimental results demonstrate that speculative backpropagation achieves a maximum speedup of 24% in execution time when using a threshold of 0.25, and accuracy remaining within 3-4% of the baseline across various epochs. Additionally, when comparing individual step execution time, speculative backpropagation yields a maximum speedup of 35% over the baseline, demonstrating the effectiveness of overlapping forward and backward passes.

</details>


### [339] [HeteroSTA: A CPU-GPU Heterogeneous Static Timing Analysis Engine with Holistic Industrial Design Support](https://arxiv.org/abs/2511.11660)
*Zizheng Guo,Haichuan Liu,Xizhe Shi,Shenglu Hua,Zuodong Zhang,Chunyuan Zhao,Runsheng Wang,Yibo Lin*

Main category: cs.DC

TL;DR: HeteroSTA是首个CPU-GPU异构时序分析引擎，支持多样化延迟模型、行业格式兼容和端到端GPU加速，显著提升速度且保持高质量。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统时序分析工具在速度与准确性上的局限性，同时满足学术界和工业界的广泛应用需求。

Method: HeteroSTA提供了一组延迟计算模型，支持行业标准格式（如.sdc约束），并实现了端到端的GPU加速，包括基于图和路径的时序查询。

Result: HeteroSTA在实际应用中（如独立工具、DREAMPlace 4.0集成和全局路由集成）展示了显著的运行时加速和可比较的质量。

Conclusion: HeteroSTA作为首个CPU-GPU异构时序分析引擎，通过高效的API支持多样化的延迟计算模型、行业格式兼容以及端到端GPU加速，显著提升了运行时速度并保持高质量。

Abstract: We introduce in this paper, HeteroSTA, the first CPU-GPU heterogeneous timing analysis engine that efficiently supports: (1) a set of delay calculation models providing versatile accuracy-speed choices without relying on an external golden tool, (2) robust support for industry formats, including especially the .sdc constraints containing all common timing exceptions, clock domains, and case analysis modes, and (3) end-to-end GPU-acceleration for both graph-based and path-based timing queries, all exposed as a zero-overhead flattened heterogeneous application programming interface (API). HeteroSTA is publicly available with both a standalone binary executable and an embeddable shared library targeting ubiquitous academic and industry applications. Example use cases as a standalone tool, a timing-driven DREAMPlace 4.0 integration, and a timing-driven global routing integration have all demonstrated remarkable runtime speed-up and comparable quality.

</details>


### [340] [Range Asymmetric Numeral Systems-Based Lightweight Intermediate Feature Compression for Split Computing of Deep Neural Networks](https://arxiv.org/abs/2511.11664)
*Mingyu Sung,Suhwan Im,Vikas Palakonda,Jae-Mo Kang*

Main category: cs.DC

TL;DR: 提出一种轻量级压缩框架，结合rANS编码、非对称量化和稀疏表示，显著减少传输开销，保持模型性能，适用于带宽受限环境。


<details>
  <summary>Details</summary>
Motivation: 为了解决分割计算中中间特征传输的通信瓶颈问题，提出了一种轻量级压缩框架，以在带宽受限的环境中高效部署复杂AI系统。

Method: 采用Range Asymmetric Numeral Systems (rANS)编码与非对称整数量化及稀疏张量表示技术，无需复杂概率建模或网络修改，实现了高效的带宽压缩。

Result: 在多种神经网络架构（如ResNet、VGG16等）和任务（计算机视觉与自然语言处理）上验证了框架的有效性，保持了接近基准的准确性，并实现了亚毫秒级的编码/解码延迟。

Conclusion: 该论文提出了一种轻量级压缩框架，通过结合rANS编码、非对称整数量化和稀疏张量表示，显著减少了中间特征的传输开销，同时在多种神经网络架构和任务上保持接近基准的准确性，证明了其在带宽受限环境中的广泛应用潜力。

Abstract: Split computing distributes deep neural network inference between resource-constrained edge devices and cloud servers but faces significant communication bottlenecks when transmitting intermediate features. To this end, in this paper, we propose a novel lightweight compression framework that leverages Range Asymmetric Numeral Systems (rANS) encoding with asymmetric integer quantization and sparse tensor representation to reduce transmission overhead dramatically. Specifically, our approach combines asymmetric integer quantization with a sparse representation technique, eliminating the need for complex probability modeling or network modifications. The key contributions include: (1) a distribution-agnostic compression pipeline that exploits inherent tensor sparsity to achieve bandwidth reduction with minimal computational overhead; (2) an approximate theoretical model that optimizes tensor reshaping dimensions to maximize compression efficiency; and (3) a GPU-accelerated implementation with sub-millisecond encoding/decoding latency. Extensive evaluations across diverse neural architectures (ResNet, VGG16, MobileNetV2, SwinT, DenseNet121, EfficientNetB0) demonstrate that the proposed framework consistently maintains near-baseline accuracy across CIFAR100 and ImageNet benchmarks. Moreover, we validated the framework's effectiveness on advanced natural language processing tasks by employing Llama2 7B and 13B on standard benchmarks such as MMLU, HellaSwag, ARC, PIQA, Winogrande, BoolQ, and OpenBookQA, demonstrating its broad applicability beyond computer vision. Furthermore, this method addresses a fundamental bottleneck in deploying sophisticated artificial intelligence systems in bandwidth-constrained environments without compromising model performance.

</details>


### [341] [OSGym: Super-Scalable Distributed Data Engine for Generalizable Computer Agents](https://arxiv.org/abs/2511.11672)
*Zengyi Qin,Jinyuan Chen,Yunze Man,Shengcao Cao,Ziqi Pang,Zhuoyuan Wang,Xin Sun,Gen Lin,Han Fang,Ling Zhu,Zixin Xie,Zibu Wei,Tianshu Ran,Haoran Geng,Xander Wu,Zachary Bright,Qizhen Sun,Rui Wang,Yuyang Cai,Song Wang,Jiace Zhao,Han Cao,Yeyang Zhou,Tianrui Liu,Ray Pan,Chongye Yang,Xiang Ren,Bo Zhang,Yutong Ban,Jitendra Malik,Brian Anthony,Pieter Abbeel*

Main category: cs.DC

TL;DR: OSGym是一个低成本、超可扩展的分布式数据引擎，支持上千个操作系统副本并行运行，适用于多样化计算机任务训练，显著提升代理性能。


<details>
  <summary>Details</summary>
Motivation: 为了在学术界可承受的成本范围内，实现智能代理在多样化计算机任务上的高效训练，需要一种能够大规模并行化操作系统副本的解决方案。

Method: OSGym通过并行化处理上千个操作系统副本，支持多种计算机相关任务，并采用灵活的模型训练算法，实现了高效的资源利用和低成本操作。

Result: 实验表明，OSGym能够每分钟生成多达1420个多轮轨迹，支持全面的数据收集、监督微调和强化学习流程，训练出的模型性能优于现有基线。

Conclusion: OSGym作为一个超可扩展的分布式数据引擎，通过高效的资源利用和低成本操作，为智能代理训练提供了动态运行时环境，显著提升了代理的性能和训练效率，展示了在未来代理研究中推动可扩展性和通用性的潜力。

Abstract: We introduce OSGym, a super-scalable distributed data engine for training agents across diverse computer-related tasks. OSGym efficiently scales to over a thousand operating system (OS) replicas at an academia-affordable cost, serving as dynamic runtime environments for intelligent agents. It offers three key advantages. (1) Scalability: Despite the intensive resource requirements of running multiple OS replicas, OSGym parallelizes over a thousand instances while maintaining operational efficiency under constrained resources, generating up to 1420 multi-turn trajectories per minute. (2) Generality and Customizability: OSGym supports a broad spectrum of tasks that run on OS platforms, including tool use, browser interactions, software engineering, and office applications, with flexible support for diverse model training algorithms. (3) Economic Viability: OSGym operates at only 0.2-0.3 USD per day per OS replica using accessible on-demand compute providers. It is fully open-source and freely available for both research and commercial use. Experiments show that OSGym enables comprehensive data collection, supervised fine-tuning, and reinforcement learning pipelines for computer agents. Models trained with OSGym outperform state-of-the-art baselines, demonstrating its potential to advance scalability and universality in future agent research.

</details>


### [342] [A Structure-Agnostic Co-Tuning Framework for LLMs and SLMs in Cloud-Edge Systems](https://arxiv.org/abs/2511.11678)
*Yuze Liu,Yunhan Wang,Tiehua Zhang,Zhishu Shen,Cheng Peng,Libing Wu,Feng Xia,Jiong Jin*

Main category: cs.DC

TL;DR: Co-PLMs是一种异构语言模型协同训练框架，通过DPMs实现知识交换，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 智能应用的激增使得带宽有限的云服务器难以实时处理大量LLM工作负载，同时保护用户数据隐私。

Method: 提出Co-PLMs框架，通过结构无关的相互学习和蒸馏代理模型（DPMs）实现异构语言模型之间的知识交换。

Result: Co-PLMs在Rouge-L和EM指标上分别平均提升了5.38%和4.88%。

Conclusion: Co-PLMs框架通过异构语言模型之间的协同训练，显著提升了推理性能，并在实验中优于现有方法。

Abstract: The surge in intelligent applications driven by large language models (LLMs) has made it increasingly difficult for bandwidth-limited cloud servers to process extensive LLM workloads in real time without compromising user data privacy. To solve these problems, recent research has focused on constructing cloud-edge consortia that integrate server-based LLM with small language models (SLMs) on mobile edge devices. Furthermore, designing collaborative training mechanisms within such consortia to enhance inference performance has emerged as a promising research direction. However, the cross-domain deployment of SLMs, coupled with structural heterogeneity in SLMs architectures, poses significant challenges to enhancing model performance. To this end, we propose Co-PLMs, a novel co-tuning framework for collaborative training of large and small language models, which integrates the process of structure-agnostic mutual learning to realize knowledge exchange between the heterogeneous language models. This framework employs distilled proxy models (DPMs) as bridges to enable collaborative training between the heterogeneous server-based LLM and on-device SLMs, while preserving the domain-specific insights of each device. The experimental results show that Co-PLMs outperform state-of-the-art methods, achieving average increases of 5.38% in Rouge-L and 4.88% in EM.

</details>


### [343] [ECCENTRIC: Edge-Cloud Collaboration Framework for Distributed Inference Using Knowledge Adaptation](https://arxiv.org/abs/2511.11719)
*Mohammad Mahdi Kamani,Zhongwei Cheng,Lin Chen*

Main category: cs.DC

TL;DR: Eccentric框架通过知识适应优化边缘-云端推理系统，减少计算和通信成本，同时保持高性能。


<details>
  <summary>Details</summary>
Motivation: 边缘AI应用的普及使得机器学习模型在不同领域的应用无处不在，但由于边缘设备计算资源有限，依赖云端系统是不可避免的，这带来了计算、通信和性能之间的权衡问题。

Method: 提出了一种名为Eccentric的新框架，该框架学习模型在不同冲突目标之间的权衡水平。

Result: 在分类和目标检测任务上的实证研究证实了该框架的有效性。

Conclusion: Eccentric框架通过边缘模型到云端模型的知识适应，在推理过程中降低了系统的计算和通信成本，同时实现了最佳性能。

Abstract: The massive growth in the utilization of edge AI has made the applications of machine learning models ubiquitous in different domains. Despite the computation and communication efficiency of these systems, due to limited computation resources on edge devices, relying on more computationally rich systems on the cloud side is inevitable in most cases. Cloud inference systems can achieve the best performance while the computation and communication cost is dramatically increasing by the expansion of a number of edge devices relying on these systems. Hence, there is a trade-off between the computation, communication, and performance of these systems. In this paper, we propose a novel framework, dubbed as Eccentric that learns models with different levels of trade-offs between these conflicting objectives. This framework, based on an adaptation of knowledge from the edge model to the cloud one, reduces the computation and communication costs of the system during inference while achieving the best performance possible. The Eccentric framework can be considered as a new form of compression method suited for edge-cloud inference systems to reduce both computation and communication costs. Empirical studies on classification and object detection tasks corroborate the efficacy of this framework.

</details>


### [344] [A Meta-Heuristic Load Balancer for Cloud Computing Systems](https://arxiv.org/abs/2511.11721)
*Leszek Sliwko,Vladimir Getov*

Main category: cs.DC

TL;DR: 本文提出了一种云系统服务分配策略，通过元启发式负载均衡器和新颖的遗传算法，实验证明其在避免节点过载和降低成本方面有效。


<details>
  <summary>Details</summary>
Motivation: 云系统中服务分配需要在避免节点过载的同时维持系统稳定性，并尽可能降低成本。现有方法在资源利用和服务迁移成本方面存在不足，因此需要更高效的策略。

Method: 本文构建了一个云资源利用的抽象模型，考虑了多种资源类型和服务迁移成本。设计并实现了一个原型元启发式负载均衡器，并提出了一种通过其他元启发式算法输出作为种群的遗传算法。

Result: 实验结果表明，提出的原型元启发式负载均衡器和遗传算法能够有效优化资源分配，降低系统成本并维持稳定性。

Conclusion: 本文提出了一种在保证系统稳定性和最小成本的前提下，避免节点过载的云系统服务分配策略。通过实验验证了原型元启发式负载均衡器的有效性，并提出了一种新颖的遗传算法。

Abstract: This paper presents a strategy to allocate services on a Cloud system without overloading nodes and maintaining the system stability with minimum cost. We specify an abstract model of cloud resources utilization, including multiple types of resources as well as considerations for the service migration costs. A prototype meta-heuristic load balancer is demonstrated and experimental results are presented and discussed. We also propose a novel genetic algorithm, where population is seeded with the outputs of other meta-heuristic algorithms.

</details>


### [345] [Harli: Harvest Underutilized Resources in LLM Serving with Finetuning Tasks](https://arxiv.org/abs/2511.11729)
*Ao Xu,Han Zhao,Weihao Cui,Quan Chen,Yukang Chen,Shulai Zhang,Shuang Chen,Jiemin Jiang,Zhibin Yu,Minyi Guo*

Main category: cs.DC

TL;DR: Harli通过在解码实例中共同定位PEFT任务，显著提升GPU利用率，同时确保QoS，实验显示微调吞吐量提升显著。


<details>
  <summary>Details</summary>
Motivation: 现有LLM服务系统中，解码实例由于内存限制和动态工作负载中的批处理不足，导致GPU利用率低下，计算资源未被充分利用。

Method: Harli采用统一内存分配器实现运行时内存重用，两阶段延迟预测器用于解码延迟建模，以及一个QoS保证的吞吐量最大化调度器。

Result: 实验结果显示，Harli在保持推理解码QoS的前提下，平均提高了46.2%（最高达92.0%）的微调吞吐量。

Conclusion: Harli是一种新型的服务系统，通过将参数高效微调（PEFT）任务与LLM解码实例共同定位，显著提高了GPU利用率，同时保持了推理解码的严格服务质量（QoS）保证。

Abstract: Large language models (LLMs) are increasingly deployed under the Model-as-a-Service (MaaS) paradigm. To meet stringent quality-of-service (QoS) requirements, existing LLM serving systems disaggregate the prefill and decode phases of inference. However, decode instances often experience low GPU utilization due to their memory-bound nature and insufficient batching in dynamic workloads, leaving compute resources underutilized.
  We introduce Harli, a serving system that improves GPU utilization by co-locating parameter-efficient finetuning (PEFT) tasks with LLM decode instances. PEFT tasks are compute-bound and memory-efficient, making them ideal candidates for safe co-location. Specifically, Harli addresses key challenges--limited memory and unpredictable interference--using three components: a unified memory allocator for runtime memory reuse, a two-stage latency predictor for decode latency modeling, and a QoS-guaranteed throughput-maximizing scheduler for throughput maximization. Experimental results show that Harli improves the finetune throughput by 46.2% on average (up to 92.0%) over state-of-the-art serving systems, while maintaining strict QoS guarantees for inference decode.

</details>


### [346] [Speculative Decoding in Decentralized LLM Inference: Turning Communication Latency into Computation Throughput](https://arxiv.org/abs/2511.11733)
*Jingwei Song,Wanyi Chen,Xinyuan Song,Max,Chris Tong,Gufeng Chen,Tianyi Zhao,Eric Yang,Bill Shi,Lynn Ai*

Main category: cs.DC

TL;DR: DSD框架利用网络延迟并行验证令牌，显著加速分布式LLM推理，无需修改模型。


<details>
  <summary>Details</summary>
Motivation: 探讨在去中心化环境中，网络延迟主导计算时，推测解码的行为表现。

Method: 提出了一种名为DSD的插件式框架，通过并行验证多个候选令牌和自适应验证策略优化性能。

Result: DSD在HumanEval和GSM8K上分别实现2.56倍和2.59倍的加速，超越基线且保持准确性。

Conclusion: DSD通过将网络延迟转化为计算资源，显著加速了分布式LLM推理，无需模型重训或架构改动。

Abstract: Speculative decoding accelerates large language model (LLM) inference by using a lightweight draft model to propose tokens that are later verified by a stronger target model. While effective in centralized systems, its behavior in decentralized settings, where network latency often dominates compute, remains under-characterized. We present Decentralized Speculative Decoding (DSD), a plug-and-play framework for decentralized inference that turns communication delay into useful computation by verifying multiple candidate tokens in parallel across distributed nodes. We further introduce an adaptive speculative verification strategy that adjusts acceptance thresholds by token-level semantic importance, delivering an additional 15% to 20% end-to-end speedup without retraining. In theory, DSD reduces cross-node communication cost by approximately (N-1)t1(k-1)/k, where t1 is per-link latency and k is the average number of tokens accepted per round. In practice, DSD achieves up to 2.56x speedup on HumanEval and 2.59x on GSM8K, surpassing the Eagle3 baseline while preserving accuracy. These results show that adapting speculative decoding for decentralized execution provides a system-level optimization that converts network stalls into throughput, enabling faster distributed LLM inference with no model retraining or architectural changes.

</details>


### [347] [Noise-Aware Optimization in Nominally Identical Manufacturing and Measuring Systems for High-Throughput Parallel Workflows](https://arxiv.org/abs/2511.11739)
*Christina Schenk,Miguel Hernández-del-Valle,Luis Calero-Lumbreras,Marcus Noack,Maciej Haranczyk*

Main category: cs.DC

TL;DR: 提出了一种噪声感知决策算法，通过量化设备特定噪声配置文件，自适应管理变异性，提高了3D打印的可重现性和效率。


<details>
  <summary>Details</summary>
Motivation: 设备间噪声差异在高通量系统中严重影响重现性，可能引发结构或经济风险。

Method: 使用分布分析和成对散度度量与聚类，选择单设备和鲁棒多设备贝叶斯优化策略。

Result: 实验案例研究表明，该方法减少了冗余、降低了资源使用并提高了可靠性。

Conclusion: 该框架为可扩展的自动化实验平台建立了一种精确和资源感知优化的范式。

Abstract: Device-to-device variability in experimental noise critically impacts reproducibility, especially in automated, high-throughput systems like additive manufacturing farms. While manageable in small labs, such variability can escalate into serious risks at larger scales, such as architectural 3D printing, where noise may cause structural or economic failures. This contribution presents a noise-aware decision-making algorithm that quantifies and models device-specific noise profiles to manage variability adaptively. It uses distributional analysis and pairwise divergence metrics with clustering to choose between single-device and robust multi-device Bayesian optimization strategies. Unlike conventional methods that assume homogeneous devices or generic robustness, this framework explicitly leverages inter-device differences to enhance performance, reproducibility, and efficiency. An experimental case study involving three nominally identical 3D printers (same brand, model, and close serial numbers) demonstrates reduced redundancy, lower resource usage, and improved reliability. Overall, this framework establishes a paradigm for precision- and resource-aware optimization in scalable, automated experimental platforms.

</details>


### [348] [How Machine Learning-Data Driven Replication Strategies Enhance Fault Tolerance in Large-Scale Distributed Systems](https://arxiv.org/abs/2511.11749)
*Almond Kiruthu Murimi*

Main category: cs.DC

TL;DR: 论文探讨了机器学习如何优化分布式系统的数据复制策略，提升容错能力，并指出了实际应用中的挑战。


<details>
  <summary>Details</summary>
Motivation: 传统静态配置的复制方法难以适应动态工作负载和意外故障，导致资源利用效率低和停机时间长。

Method: 通过文献综述、定性分析和与传统方法的比较评估，研究提出了结合预测分析和强化学习的自适应复制机制。

Result: 研究发现了现有复制策略的关键局限性，并突显了机器学习在创建更具弹性和自优化系统中的变革潜力。

Conclusion: 该研究强调了机器学习驱动方案在实际部署中的潜力和挑战，为未来研究和云/企业系统应用提供了建议。

Abstract: This research paper investigates how machine learning-driven data replication strategies can enhance fault tolerance in large-scale distributed systems. Traditional replication methods, which rely on static configurations, often struggle to adapt to dynamic workloads and unexpected failures, leading to inefficient resource utilization and prolonged downtime. By integrating machine learning techniques-specifically predictive analytics and reinforcement learning. The study proposes adaptive replication mechanisms capable of forecasting system failures and optimizing data placement in real time. Through an extensive literature review, qualitative analysis, and comparative evaluations with traditional approaches, the paper identifies key limitations in existing replication strategies and highlights the transformative potential of machine learning in creating more resilient, self-optimizing systems. The findings underscore both the promise and the challenges of implementing ML-driven solutions in real-world environments, offering recommendations for future research and practical deployment in cloud-based and enterprise systems.

</details>


### [349] [Pico-Cloud: Cloud Infrastructure for Tiny Edge Devices](https://arxiv.org/abs/2511.13253)
*Mordechai Guri*

Main category: cs.DC

TL;DR: Pico-Cloud是一种基于超小型硬件的微边缘云架构，支持低延迟、低功耗的本地操作，适用于多种边缘计算场景。


<details>
  <summary>Details</summary>
Motivation: 解决对集中式数据中心的依赖问题，提供低延迟、低功耗的本地操作能力，适用于农村连接、教育集群和边缘AI推理等场景。

Method: 提出了Pico-Cloud的架构模型，包括容器化虚拟化、服务发现和轻量级编排，并分析了在计算、网络、存储和电源管理方面的设计挑战。

Result: Pico-Cloud能够在Raspberry Pi Zero等超小型硬件平台上实现高效的容器化虚拟化和轻量级服务编排。

Conclusion: Pico-Cloud是一种基于超小型硬件平台的微边缘云架构，为网络边缘的轻量级分布式工作负载提供了一个经济高效、去中心化且可持续的平台。

Abstract: This paper introduces the Pico-Cloud, a micro-edge cloud architecture built on ultra-minimal hardware platforms such as the Raspberry Pi Zero and comparable single-board computers. The Pico-Cloud delivers container-based virtualization, service discovery, and lightweight orchestration directly at the device layer, enabling local operation with low latency and low power consumption without reliance on centralized data centers. We present its architectural model, outline representative use cases including rural connectivity, educational clusters, and edge AI inference, and analyze design challenges in computation, networking, storage, and power management. The results highlight Pico-Clouds as a cost-effective, decentralized, and sustainable platform for lightweight distributed workloads at the network edge.

</details>


### [350] [TD-Orch: Scalable Load-Balancing for Distributed Systems with Applications to Graph Processing](https://arxiv.org/abs/2511.11843)
*Yiwei Zhao,Qiushi Lin,Hongbo Kang,Guy E. Blelloch,Laxman Dhulipala,Charles McGuffey,Phillip B. Gibbons*

Main category: cs.DC

TL;DR: TD-Orch是一个高效的任务-数据协同编排框架，通过推拉技术实现负载均衡，性能提升显著；其衍生的TDO-GP系统在图处理中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决分布式应用中任务与数据协同编排的挑战，尤其是在数据热点场景下的性能问题。

Method: 采用分布式推拉技术，结合任务与数据的双向流动，实现高效的负载均衡与低通信开销。

Result: TD-Orch相比现有分布式调度基线最高提速2.7倍；TDO-GP相比最优开源分布式图系统平均提速4.1倍。

Conclusion: TD-Orch框架通过任务与数据的协同编排，显著提升了分布式应用的性能，尤其在处理数据热点时表现出色。基于TD-Orch开发的TDO-GP系统进一步验证了其通用性，为分布式图处理提供了高效解决方案。

Abstract: In this paper, we highlight a task-data orchestration abstraction that supports a range of distributed applications, including graph processing and key-value stores. Given a batch of tasks each requesting one or more data items, where both tasks and data are distributed across multiple machines, each task must get co-located with its target data (by moving tasks and/or data) and executed. We present TD-Orch, an efficient and scalable orchestration framework featuring a simple application developer interface. TD-Orch employs a distributed push-pull technique, leveraging the bidirectional f low of both tasks and data to achieve scalable load balance across machines even under highly skewed data request (data hot spots), with minimal communication overhead. Experimental results show that TD-Orch achieves up to 2.7x speedup over existing distributed scheduling baselines. Building on TD-Orch, we present TDO-GP, a distributed graph processing system for general graph problems, demonstrating the effectiveness of the underlying framework. We design three families of implementation techniques to fully leverage the execution flow provided by TD-Orch. Experimental results show that TDO-GP achieves an average speedup of 4.1x over the best prior open-source distributed graph systems for general graph processing.

</details>


### [351] [Flash-Fusion: Enabling Expressive, Low-Latency Queries on IoT Sensor Streams with LLMs](https://arxiv.org/abs/2511.11885)
*Kausar Patherya,Ashutosh Dhekne,Francisco Romero*

Main category: cs.DC

TL;DR: Flash-Fusion是一个边缘-云系统，通过统计摘要和智能查询规划优化IoT数据分析，显著降低成本并提升效率。


<details>
  <summary>Details</summary>
Motivation: 解决用户在使用LLMs处理IoT数据时面临的高成本、低效率和技术门槛问题。

Method: Flash-Fusion采用边缘统计摘要（数据减少73.5%）和云查询规划（聚类行为数据并组装上下文丰富的提示）来优化数据收集和分析。

Result: 在高校公交车队部署中，Flash-Fusion相比直接使用原始数据的基线方法，实现了95%的延迟减少和98%的token成本节省。

Conclusion: Flash-Fusion系统通过边缘统计摘要和云查询规划，显著降低了IoT数据收集和分析的负担，实现了95%的延迟减少和98%的token成本节省，同时保持了高质量响应。

Abstract: Smart cities and pervasive IoT deployments have generated interest in IoT data analysis across transportation and urban planning. At the same time, Large Language Models offer a new interface for exploring IoT data - particularly through natural language. Users today face two key challenges when working with IoT data using LLMs: (1) data collection infrastructure is expensive, producing terabytes of low-level sensor readings that are too granular for direct use, and (2) data analysis is slow, requiring iterative effort and technical expertise. Directly feeding all IoT telemetry to LLMs is impractical due to finite context windows, prohibitive token costs at scale, and non-interactive latencies. What is missing is a system that first parses a user's query to identify the analytical task, then selects the relevant data slices, and finally chooses the right representation before invoking an LLM.
  We present Flash-Fusion, an end-to-end edge-cloud system that reduces the IoT data collection and analysis burden on users. Two principles guide its design: (1) edge-based statistical summarization (achieving 73.5% data reduction) to address data volume, and (2) cloud-based query planning that clusters behavioral data and assembles context-rich prompts to address data interpretation. We deploy Flash-Fusion on a university bus fleet and evaluate it against a baseline that feeds raw data to a state-of-the-art LLM. Flash-Fusion achieves a 95% latency reduction and 98% decrease in token usage and cost while maintaining high-quality responses. It enables personas across disciplines - safety officers, urban planners, fleet managers, and data scientists - to efficiently iterate over IoT data without the burden of manual query authoring or preprocessing.

</details>


### [352] [KVSwap: Disk-aware KV Cache Offloading for Long-Context On-device Inference](https://arxiv.org/abs/2511.11907)
*Huawei Zhang,Chunwei Xia,Zheng Wang*

Main category: cs.DC

TL;DR: KVSwap通过智能卸载KV缓存到磁盘，解决了本地运行语言模型时的内存瓶颈问题，提升了吞吐量且不牺牲生成质量。


<details>
  <summary>Details</summary>
Motivation: 随着上下文长度和批处理大小的增加，本地运行语言模型（LMs）时的KV缓存线性增长会导致内存容量瓶颈，影响隐私、离线使用和成本效益。

Method: KVSwap利用动态变化的KV条目子集是关键观察，将完整缓存存储在磁盘上，使用紧凑的内存元数据预测预加载条目，并利用硬件感知的磁盘访问与计算重叠。

Result: 在代表性LMs和存储类型上的评估显示，KVSwap在严格内存预算下实现了比现有KV缓存卸载方案更高的吞吐量，同时保持了生成质量。

Conclusion: KVSwap通过将KV缓存卸载到非易失性二级存储（磁盘）中，突破了内存容量限制，同时在严格的内存预算下提供了更高的吞吐量，且保持了生成质量。

Abstract: Language models (LMs) underpin emerging mobile and embedded AI applications like meeting and video summarization and document analysis, which often require processing multiple long-context inputs. Running an LM locally on-device improves privacy, enables offline use, and reduces cost, but long-context inference quickly hits a \emph{memory capacity wall} as the key-value (KV) cache grows linearly with context length and batch size.
  We present KVSwap, a software framework to break this memory wall by offloading the KV cache to non-volatile secondary storage (disk). KVSwap leverages the observation that only a small, dynamically changing subset of KV entries is critical for generation. It stores the full cache on disk, uses a compact in-memory metadata to predict which entries to preload, overlaps computation with hardware-aware disk access, and orchestrates read patterns to match storage device characteristics. Our evaluation shows that across representative LMs and storage types, KVSwap delivers higher throughput under tight memory budgets while maintaining the generation quality when compared with existing KV cache offloading schemes.

</details>


### [353] [High-Performance N-Queens Solver on GPU: Iterative DFS with Zero Bank Conflicts](https://arxiv.org/abs/2511.12009)
*Guangchao Yao,Yali Li*

Main category: cs.DC

TL;DR: 提出一种GPU并行计算方法，显著加速N-Queens问题求解，验证27-Queens解仅需28.4天，并为28-Queens问题提供可行解决方案。


<details>
  <summary>Details</summary>
Motivation: N-Queens问题的计算复杂度极高，现有方法验证27-Queens解需耗时约17个月，时间和资源成本过高，亟需高效解决方案。

Method: 采用迭代深度优先搜索（DFS）算法，将栈结构完全映射到GPU共享内存，并通过精心设计的内存访问模式避免bank冲突，结合多种优化技术实现最佳性能。

Result: 在8块RTX 5090 GPU上仅用28.4天验证了27-Queens问题，将28-Queens问题的预计求解时间缩短至约11个月，相比现有GPU方法实现了10倍以上的加速。

Conclusion: 本研究提出了一种创新的并行计算方法，成功验证了27-Queens问题的解，并显著降低了28-Queens问题的预计求解时间，为该领域带来了新的突破。

Abstract: The counting of solutions to the N-Queens problem is a classic NP-complete problem with extremely high computational complexity. As of now, the academic community has rigorously verified the number of solutions only up to N <= 26. In 2016, the research team led by PreuBer solved the 27-Queens problem using FPGA hardware, which took approximately one year, though the result remains unverified independently. Recent studies on GPU parallel computing suggest that verifying the 27-Queens solution would still require about 17 months, indicating excessively high time and computational resource costs. To address this challenge, we propose an innovative parallel computing method on NVIDIA GPU platform, with the following core contributions: (1) An iterative depth-first search (DFS) algorithm for solving the N-Queens problem; (2) Complete mapping of the required stack structure to GPU shared memory; (3) Effective avoidance of bank conflicts through meticulously designed memory access patterns; (4) Various optimization techniques are employed to achieve optimal performance. Under the proposed optimization framework, we successfully verified the 27-Queens problem in just 28.4 days using eight RTX 5090 GPUs, thereby confirming the correctness of PreuBer's computational results. Moreover, we have reduced the projected solving time for the next open case-the 28-Queens problem-to approximately 11 months, making its resolution computationally feasible. Compared to the state-of-the-art GPU methods, our method achieves over 10x speedup on identical hardware configurations (8 A100), while delivering over 26x acceleration when utilizing 8 RTX 5090 GPUs, and brings fresh perspectives to this long-stagnant problem.

</details>


### [354] [A Quick and Exact Method for Distributed Quantile Computation](https://arxiv.org/abs/2511.12025)
*Ivan Cao,Jaromir J. Saloni,David A. G. Harrison*

Main category: cs.DC

TL;DR: GK Select 是一种 Spark 算法，利用 GK Sketch 实现精确分位数计算，避免全局排序，性能提升显著。


<details>
  <summary>Details</summary>
Motivation: 在大规模数据分析中，精确分位数计算通常依赖昂贵的全局排序，而近似方法无法满足精确需求，因此需要一种高效且精确的解决方案。

Method: GK Select 结合 Greenwald-Khanna (GK) Sketch 识别近似目标枢轴，线性时间提取各分区内误差范围内的值，并通过树形归约处理候选集。

Result: GK Select 在分析上与 GK Sketch 具有相同的执行复杂度，但在实际测试中比 Spark 的全局排序快约 10.5 倍。

Conclusion: GK Select 是一种高效的 Spark 算法，能够在常数时间内完成精确分位数计算，避免了全局排序的高开销，显著提升了性能。

Abstract: Quantile computation is a core primitive in large-scale data analytics. In Spark, practitioners typically rely on the Greenwald-Khanna (GK) Sketch, an approximate method. When exact quantiles are required, the default option is an expensive global sort. We present GK Select, an exact Spark algorithm that avoids full-data shuffles and completes in a constant number of actions. GK Select leverages GK Sketch to identify a near-target pivot, extracts all values within the error bound around this pivot in each partition in linear time, and then tree-reduces the resulting candidate sets. We show analytically that GK Select matches the executor-side time complexity of GK Sketch while returning the exact quantile. Empirically, GK Select achieves sketch-level latency and outperforms Spark's full sort by approximately 10.5x on 10^9 values across 120 partitions on a 30-core AWS EMR cluster.

</details>


### [355] [Striking the Right Balance between Compute and Copy: Improving LLM Inferencing Under Speculative Decoding](https://arxiv.org/abs/2511.12031)
*Arun Ramachandran,Ramaswamy Govindarajan,Murali Annavaram,Prakash Raghavendra,Hossein Entezari Zarch,Lei Gao,Chaoyi Jiang*

Main category: cs.DC

TL;DR: BMC是一种新型KV缓存分配技术，通过优化内存与计算平衡，显著提升LLM推理效率，尤其在CPU上表现优异，并兼容GPU。


<details>
  <summary>Details</summary>
Motivation: 随着GPU及其云实例成本的飙升，利用CPU进行大型语言模型推理的需求增加，而传统的KV缓存更新方式存在显著的性能开销。

Method: 提出了一种名为BMC的新型KV缓存分配机制，通过定期分配冗余行实现原地更新，减少复制开销，并将冗余计算重新用于推测解码以提高效率。

Result: BMC方法在基线HuggingFace上实现了平均3.2倍的吞吐量加速，结合推测解码时额外提速1.39倍，且优于vLLM和DeepSpeed等先进推理服务器。

Conclusion: BMC技术在CPU和GPU上均表现出色，显著提高了大型语言模型推理的效率，尤其在结合推测解码时，性能提升更为明显。

Abstract: With the skyrocketing costs of GPUs and their virtual instances in the cloud, there is a significant desire to use CPUs for large language model (LLM) inference. KV cache update, often implemented as allocation, copying, and in-place strided update for each generated token, incurs significant overhead. As the sequence length increases, the allocation and copy overheads dominate the performance. Alternate approaches may allocate large KV tensors upfront to enable in-place updates, but these matrices (with zero-padded rows) cause redundant computations. In this work, we propose a new KV cache allocation mechanism called Balancing Memory and Compute (BMC). BMC allocates, once every r iterations, KV tensors with r redundant rows, allowing in-place update without copy overhead for those iterations, but at the expense of a small amount of redundant computation. Second, we make an interesting observation that the extra rows allocated in the KV tensors and the resulting redundant computation can be repurposed for Speculative Decoding (SD) that improves token generation efficiency. Last, BMC represents a spectrum of design points with different values of r. To identify the best-performing design point(s), we derive a simple analytical model for BMC. The proposed BMC method achieves an average throughput acceleration of up to 3.2x over baseline HuggingFace (without SD). Importantly when we apply BMC with SD, it results in an additional speedup of up to 1.39x, over and above the speedup offered by SD. Further, BMC achieves a throughput acceleration of up to 1.36x and 2.29x over state-of-the-art inference servers vLLM and DeepSpeed, respectively. Although the BMC technique is evaluated extensively across different classes of CPUs (desktop and server class), we also evaluate the scheme with GPUs and demonstrate that it works well for GPUs.

</details>


### [356] [Combining Serverless and High-Performance Computing Paradigms to support ML Data-Intensive Applications](https://arxiv.org/abs/2511.12185)
*Mills Staylor,Arup Kumar Sarker,Gregor von Laszewski,Geoffrey Fox,Yue Cheng,Judy Fox*

Main category: cs.DC

TL;DR: Cylon是一个高性能分布式数据框架，针对无服务器函数（如AWS Lambda）在处理大数据集时的通信和性能问题提出解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着公共云的兴起，无服务器函数（如AWS Lambda）提供了水平扩展和精确计费的优势，但在处理大数据集时，依赖外部存储选项导致性能显著下降。

Method: 借鉴FMI库，设计了无服务器通信器，通过NAT Traversal TCP Hole Punching实现直接通信。

Result: 实验表明，AWS Lambda的性能在强扩展实验中低于服务器型AWS（EC2）和HPC的1%。

Conclusion: Cylon展示了在高性能分布式数据处理中的潜力，尤其是在无服务器环境中的通信优化。

Abstract: Data is found everywhere, from health and human infrastructure to the surge of sensors and the proliferation of internet-connected devices. To meet this challenge, the data engineering field has expanded significantly in recent years in both research and industry. Traditionally, data engineering, Machine Learning, and AI workloads have been run on large clusters within data center environments, requiring substantial investment in hardware and maintenance. With the rise of the public cloud, it is now possible to run large applications across nodes without owning or maintaining hardware. Serverless functions such as AWS Lambda provide horizontal scaling and precise billing without the hassle of managing traditional cloud infrastructure. However, when processing large datasets, users often rely on external storage options that are significantly slower than direct communication typical of HPC clusters. We introduce Cylon, a high-performance distributed data frame solution that has shown promising results for data processing using Python. We describe how we took inspiration from the FMI library and designed a serverless communicator to tackle communication and performance issues associated with serverless functions. With our design, we demonstrate that the performance of AWS Lambda falls below one percent of strong scaling experiments compared to serverful AWS (EC2) and HPCs based on implementing direct communication via NAT Traversal TCP Hole Punching.

</details>


### [357] [Distributed Seasonal Temporal Pattern Mining](https://arxiv.org/abs/2511.12216)
*Van Ho-Long,Nguyen Ho,Anh-Vu Dinh-Duc,Ha Manh Tran,Ky Trung Nguyen,Tran Dung Pham,Quoc Viet Hung Nguyen*

Main category: cs.DC

TL;DR: DSTPM是首个分布式季节性时序模式挖掘框架，通过高效数据结构和并行计算，显著提升大规模数据集的处理性能。


<details>
  <summary>Details</summary>
Motivation: 物联网传感器产生的大量时序数据中，季节性时序模式（STPs）挖掘因传统度量无法捕捉季节性和搜索空间指数级增长而面临挑战。现有方法无法扩展到大规模数据集。

Method: 提出了分布式季节性时序模式挖掘（DSTPM）框架，利用分布式分层查找哈希结构进行高效计算。

Result: 实验评估显示，DSTPM在运行时间和内存使用上显著优于顺序基线方法，并能有效扩展到超大规模数据集。

Conclusion: DSTPM作为首个分布式季节性时序模式挖掘框架，通过高效的数据结构和并行计算能力，显著提升了大规模数据集的处理效率。

Abstract: The explosive growth of IoT-enabled sensors is producing enormous amounts of time series data across many domains, offering valuable opportunities to extract insights through temporal pattern mining. Among these patterns, an important class exhibits periodic occurrences, referred to as \textit{seasonal temporal patterns} (STPs). However, mining STPs poses challenges, as traditional measures such as support and confidence cannot capture seasonality, and the lack of the anti-monotonicity property results in an exponentially large search space. Existing STP mining methods operate sequentially and therefore do not scale to large datasets. In this paper, we propose the Distributed Seasonal Temporal Pattern Mining (DSTPM), the first distributed framework for mining seasonal temporal patterns from time series. DSTPM leverages efficient data structures, specifically distributed hierarchical lookup hash structures, to enable efficient computation. Extensive experimental evaluations demonstrate that DSTPM significantly outperforms sequential baselines in runtime and memory usage, while scaling effectively to very large datasets.

</details>


### [358] [Design of A Low-Latency and Parallelizable SVD Dataflow Architecture on FPGA](https://arxiv.org/abs/2511.12461)
*Fangqiang Du,Sixuan Chong,Zixuan Huang,Rui Qin,Fengnan Mi,Caibao Hu,Jiangang Chen*

Main category: cs.DC

TL;DR: 提出DSB Jacobi算法，减少41.5%片上RAM消耗，提升23倍计算效率，适用于大规模数据流实时SVD计算。


<details>
  <summary>Details</summary>
Motivation: 随着矩阵维度快速增长，SVD计算成本显著增加，现有硬件架构在可扩展性和片上内存资源消耗方面存在局限，且通常忽略与SVD相关的计算和数据传输挑战。

Method: 提出了一种基于数据流的SVD处理算法（DSB Jacobi），显著减少了片上BRAM使用并提高了计算速度。

Result: 实验结果表明，与先前工作相比，所提方法减少了41.5%的片上RAM消耗，并提升了23倍的计算效率。

Conclusion: DSB Jacobi算法通过减少片上BRAM使用并提升计算速度，为大规模数据流的实时SVD计算提供了实用解决方案。

Abstract: Singular value decomposition (SVD) is widely used for dimensionality reduction and noise suppression, and it plays a pivotal role in numerous scientific and engineering applications. As the dimensions of the matrix grow rapidly, the computational cost increases significantly, posing a serious challenge to the efficiency of data analysis and signal processing systems,especially in time-sensitive scenarios with large-scale datasets. Although various dedicated hardware architectures have been proposed to accelerate the computation of intensive SVD, many of these designs suffer from limited scalability and high consumption of on-chip memory resources. Moreover, they typically overlook the computational and data transfer challenges associated with SVD, enabling them unsuitable for real-time processing of large-scale data stream matrices in embedded systems. In this express, we propose a Data Stream-Based SVD processing algorithm (DSB Jacobi), which significantly reduces on-chip BRAM usage while improving computational speed, offering a practical solution for real-time SVD computation of large-scale data streams. Compared with previous works, our experimental results indicate that the proposed method reduces on-chip RAM consumption by 41.5 percent and improves computational efficiency by 23 times.

</details>


### [359] [A Decentralized Root Cause Localization Approach for Edge Computing Environments](https://arxiv.org/abs/2511.12486)
*Duneesha Fernando,Maria A. Rodriguez,Rajkumar Buyya*

Main category: cs.DC

TL;DR: 提出了一种去中心化的根因定位方法，利用PPR算法在边缘设备本地执行，显著减少延迟，适用于资源受限的边缘环境。


<details>
  <summary>Details</summary>
Motivation: 现有RCL方法专为云环境设计，依赖集中式分析，在边缘应用中会增加延迟和通信开销。

Method: 采用个性化PageRank（PPR）算法在边缘设备层面直接执行定位，首先将微服务分组为通信和共置感知的集群，限制异常传播范围；集群内本地执行PPR识别根因；跨集群时引入轻量级P2P近似过程。

Result: 在公开边缘数据集MicroCERCL上的评估显示，去中心化方法比集中式方法减少定位时间达34%，同时保持或提高定位准确性。

Conclusion: 本文提出的去中心化RCL方法在边缘计算环境中实现了高效且准确的异常根因定位，显著减少了定位时间，为资源受限的边缘环境提供了实用的异常诊断解决方案。

Abstract: Edge computing environments host increasingly complex microservice-based IoT applications, which are prone to performance anomalies that can propagate across dependent services. Identifying the true source of such anomalies, known as Root Cause Localization (RCL), is essential for timely mitigation. However, existing RCL approaches are designed for cloud environments and rely on centralized analysis, which increases latency and communication overhead when applied at the edge. This paper proposes a decentralized RCL approach that executes localization directly at the edge device level using the Personalized PageRank (PPR) algorithm. The proposed method first groups microservices into communication- and colocation-aware clusters, thereby confining most anomaly propagation within cluster boundaries. Within each cluster, PPR is executed locally to identify the root cause, significantly reducing localization time. For the rare cases where anomalies propagate across clusters, we introduce an inter-cluster peer-to-peer approximation process, enabling lightweight coordination among clusters with minimal communication overhead. To enhance the accuracy of localization in heterogeneous edge environments, we also propose a novel anomaly scoring mechanism tailored to the diverse anomaly triggers that arise across microservice, device, and network layers. Evaluation results on the publicly available edge dataset, MicroCERCL, demonstrate that the proposed decentralized approach achieves comparable or higher localization accuracy than its centralized counterpart while reducing localization time by up to 34%. These findings highlight that decentralized graph-based RCL can provide a practical and efficient solution for anomaly diagnosis in resource-constrained edge environments.

</details>


### [360] [Iris: First-Class Multi-GPU Programming Experience in Triton](https://arxiv.org/abs/2511.12500)
*Muhammad Awad,Muhammad Osama,Brandon Potter*

Main category: cs.DC

TL;DR: Iris 是一个 Python 和 Triton 实现的多 GPU 通信库，消除了性能与可编程性的权衡，通过 tile-based 抽象简化编程，同时实现高性能。


<details>
  <summary>Details</summary>
Motivation: 多 GPU 编程传统上需要在性能和可编程性之间做出复杂权衡，高性能实现通常依赖于低层 HIP/CUDA 通信库，而简单抽象则常牺牲性能。

Method: Iris 提供了与 Triton 编程模型自然对齐的 tile-based 对称内存抽象，支持开发者编写单源内核，无缝交织计算和通信。

Result: Iris 在微基准测试中实现了接近最优的带宽利用率，并在 GEMM+All-Scatter 工作负载上比 PyTorch 和 RCCL 提速高达 1.79 倍。

Conclusion: Iris 是一个完全用 Python 和 Triton 实现的多 GPU 通信库，通过提供基于 tile 的对称内存抽象，消除了性能与可编程性之间的传统权衡。

Abstract: Multi-GPU programming traditionally requires developers to navigate complex trade-offs between performance and programmability. High-performance implementations typically rely on low-level HIP/CUDA communication libraries that demand substantial engineering effort for even basic overlap patterns, while simpler abstractions often sacrifice performance. We present Iris, a multi-GPU communication library implemented entirely in Python and Triton that eliminates this trade-off. Iris provides tile-based symmetric memory abstractions that naturally align with Triton's programming model, enabling developers to write single-source kernels that seamlessly interleave computation and communication. We demonstrate a taxonomy of compute-communication overlap patterns--from bulk-synchronous to fine-grained workgroup specialization--that can be implemented with minimal code changes in Iris, often requiring just a few additional lines within the same Triton kernel. Our evaluation shows that Iris achieves near-optimal bandwidth utilization in microbenchmarks and delivers up to 1.79x speedup over PyTorch and RCCL for GEMM+All-Scatter workloads, demonstrating that high-level implementations can match or exceed heavily-optimized libraries while dramatically simplifying multi-GPU programming.

</details>


### [361] [Artifact for A Non-Intrusive Framework for Deferred Integration of Cloud Patterns in Energy-Efficient Data-Sharing Pipelines](https://arxiv.org/abs/2511.12667)
*Sepideh Masoudi,Mark Edward Michael Daly,Jannis Kiesel*

Main category: cs.DC

TL;DR: 提出基于Kubernetes的工具，非侵入式延迟应用设计模式，保持服务可重用性并支持能源决策。


<details>
  <summary>Details</summary>
Motivation: 随着数据网格架构的发展，传统云设计模式可能降低服务在不同管道中的可重用性。

Method: 利用Kubernetes自动化设计模式注入，并收集能源指标。

Result: 开发了一个工具，自动化设计模式注入并收集能源指标，支持能源感知决策。

Conclusion: 该论文提出了一种基于Kubernetes的工具，能够在不影响服务代码的情况下非侵入式地延迟应用设计模式，从而在保持转换服务可重用性的同时支持能源感知决策。

Abstract: As data mesh architectures grow, organizations increasingly build consumer-specific data-sharing pipelines from modular, cloud-based transformation services. While reusable transformation services can improve cost and energy efficiency, applying traditional cloud design patterns can reduce reusability of services in different pipelines. We present a Kubernetes-based tool that enables non-intrusive, deferred application of design patterns without modifying services code. The tool automates pattern injection and collects energy metrics, supporting energy-aware decisions while preserving reusability of transformation services in various pipeline structures.

</details>


### [362] [The Time to Consensus in a Blockchain: Insights into Bitcoin's "6 Blocks Rule''](https://arxiv.org/abs/2511.12687)
*Partha S. Dey,Aditya S. Gopalan,Vijay G. Subramanian*

Main category: cs.DC

TL;DR: 研究Nakamoto区块链中诚实与敌对进程的竞争，通过排队技术和模拟验证共识时间。


<details>
  <summary>Details</summary>
Motivation: 研究Nakamoto区块链中诚实进程与敌对进程的竞争，确定诚实进程永久领先的时间，以理解共识达成的时间特性。

Method: 采用排队技术分析诚实和敌对两种竞争增长过程，并在简化的比特币模型中计算共识时间的拉普拉斯变换，通过模拟验证结果。

Result: 在考虑随机延迟的情况下，计算并验证了诚实进程永久超过敌对进程的共识时间。

Conclusion: 通过排队技术和模拟验证，研究确定了Nakamoto区块链中诚实进程永久超过敌对进程的时间，并计算了共识时间的拉普拉斯变换。

Abstract: We investigate the time to consensus in Nakamoto blockchains. Specifically, we consider two competing growth processes, labeled \emph{honest} and \emph{adversarial}, and determine the time after which the honest process permananetly exceeds the adversarial process. This is done via queueing techniques. The predominant difficulty is that the honest growth process is subject to \emph{random delays}. In a stylized Bitcoin model, we compute the Laplace transform for the time to consensus and verify it via simulation.

</details>


### [363] [Learning Process Energy Profiles from Node-Level Power Data](https://arxiv.org/abs/2511.13155)
*Jonathan Bader,Julius Irion,Jannis Kappel,Joel Witzke,Niklas Fomin,Diellza Sherifi,Odej Kao*

Main category: cs.DC

TL;DR: 通过eBPF和perf同步细粒度资源指标与节点级能耗数据，利用回归模型预测进程级能耗，提升数据中心能效。


<details>
  <summary>Details</summary>
Motivation: 数据中心的能耗问题日益突出，而现有进程级能耗估算方法（如Intel RAPL）受限于硬件且仅提供粗粒度的域级测量。

Method: 利用eBPF和perf收集细粒度进程级资源指标，并与来自配电单元的节点级能耗数据同步，通过回归模型学习资源使用与能耗的关系。

Result: 该方法能够实现更细粒度的进程级能耗预测。

Conclusion: 该论文提出了一种通过细粒度进程级资源指标和节点级能耗数据同步建模的方法，能够更精确地预测进程级能耗。

Abstract: The growing demand for data center capacity, driven by the growth of high-performance computing, cloud computing, and especially artificial intelligence, has led to a sharp increase in data center energy consumption. To improve energy efficiency, gaining process-level insights into energy consumption is essential. While node-level energy consumption data can be directly measured with hardware such as power meters, existing mechanisms for estimating per-process energy usage, such as Intel RAPL, are limited to specific hardware and provide only coarse-grained, domain-level measurements. Our proposed approach models per-process energy profiles by leveraging fine-grained process-level resource metrics collected via eBPF and perf, which are synchronized with node-level energy measurements obtained from an attached power distribution unit. By statistically learning the relationship between process-level resource usage and node-level energy consumption through a regression-based model, our approach enables more fine-grained per-process energy predictions.

</details>


### [364] [Distributed Hierarchical Machine Learning for Joint Resource Allocation and Slice Selection in In-Network Edge Systems](https://arxiv.org/abs/2511.13313)
*Sulaiman Muhammad Rashid,Ibrahim Aliyu,Jaehyung Park,Jinsul Kim*

Main category: cs.DC

TL;DR: 研究提出了一种基于DeepSets的分布式层次模型（DeepSets-S），通过分解复杂问题并采用离线训练，显著降低了执行时间且系统成本接近最优，适用于元宇宙的高负载动态边缘场景。


<details>
  <summary>Details</summary>
Motivation: 元宇宙需要低延迟和高资源需求的实时沉浸式体验，但传统优化方法在动态边缘条件和高用户负载下效果不佳。因此，研究探索了一种结合COIN和MEC的切片使能网络边缘架构，以解决资源管理和延迟问题。

Method: 研究提出了一种切片使能的网络边缘架构，结合了COIN和MEC技术。通过将无线和计算资源管理的联合问题建模为MINLP，并将其分解为三个子问题（SP1、SP2、SP3），设计了分布式层次DeepSets模型（DeepSets-S）。该模型采用松弛感知归一化机制，确保对可变大小无线设备集的置换等变性。

Result: 实验结果表明，DeepSets-S在SP1/SP2上实现了高容忍度准确率（Acc1 = 95.26%和95.67%），并在SP3上提升了多类卸载准确率（Acc = 0.7486；二进制本地/卸载Acc = 0.8824）。与精确求解器相比，执行时间减少了86.1%，系统成本接近最优（差距在6.1%以内）。

Conclusion: 本研究提出了一种基于DeepSets的分布式层次模型（DeepSets-S），通过分解复杂的MINLP问题为三个子问题，并采用离线训练的优化解决方案，显著降低了执行时间（减少86.1%）且系统成本接近最优（差距在6.1%以内）。该方法在多接入边缘计算（MEC）和网络内计算（COIN）资源管理中表现出色，具有高准确性和置换等变性。

Abstract: The Metaverse promises immersive, real-time experiences; however, meeting its stringent latency and resource demands remains a major challenge. Conventional optimization techniques struggle to respond effectively under dynamic edge conditions and high user loads. In this study, we explore a slice-enabled in-network edge architecture that combines computing-in-the-network (COIN) with multi-access edge computing (MEC). In addition, we formulate the joint problem of wireless and computing resource management with optimal slice selection as a mixed-integer nonlinear program (MINLP). Because solving this model online is computationally intensive, we decompose it into three sub-problems (SP1) intra-slice allocation, (SP2) inter-slice allocation, and (SP3) offloading decision and train a distributed hierarchical DeepSets-based model (DeepSets-S) on optimal solutions obtained offline. In the proposed model, we design a slack-aware normalization mechanism for a shared encoder and task-specific decoders, ensuring permutation equivariance over variable-size wireless device (WD) sets. The learned system produces near-optimal allocations with low inference time and maintains permutation equivariance over variable-size device sets. Our experimental results show that DeepSets-S attains high tolerance-based accuracies on SP1/SP2 (Acc1 = 95.26% and 95.67%) and improves multiclass offloading accuracy on SP3 (Acc = 0.7486; binary local/offload Acc = 0.8824). Compared to exact solvers, the proposed approach reduces the execution time by 86.1%, while closely tracking the optimal system cost (within 6.1% in representative regimes). Compared with baseline models, DeepSets-S consistently achieves higher cost ratios and better utilization across COIN/MEC resources.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [365] [Hierarchical Federated Graph Attention Networks for Scalable and Resilient UAV Collision Avoidance](https://arxiv.org/abs/2511.11616)
*Rathin Chandra Shit,Sharmila Subudhi*

Main category: cs.RO

TL;DR: 论文提出一种分层框架，通过三层架构（本地、区域、全局）优化实时性能、对抗弹性和隐私保护，实验显示在500架无人机规模下碰撞率<2.0%，延迟<50ms，且具备拜占庭容错能力。


<details>
  <summary>Details</summary>
Motivation: 当前框架在计算复杂度和拜占庭容错性方面存在不足，无法满足大规模多无人机系统的需求。需要一种分层架构来平衡实时性能、对抗弹性和隐私保护。

Method: 采用三层架构：本地层（基于密集图注意力机制，延迟<10ms）、区域层（稀疏注意力机制，计算复杂度O(nk)，异步联邦学习与坐标裁剪均值聚合）和全局层（轻量级Hashgraph协议）。通过动态差分隐私机制和分布式哈希表（DHT）审计日志优化性能。

Result: 在500架无人机的测试规模下，碰撞率低于2.0%，95%的决策延迟在50ms内，拜占庭容错能力达到f < n/3。

Conclusion: 该论文提出的分层框架通过三层架构平衡了实时性能、对抗弹性和隐私保护，实现了大规模多无人机系统的碰撞避免。实验结果表明，该架构在500架无人机的规模下，碰撞率低于2.0%，并具备拜占庭容错能力（f < n/3）。

Abstract: The real-time performance, adversarial resiliency, and privacy preservation are the most important metrics that need to be balanced to practice collision avoidance in large-scale multi-UAV (Unmanned Aerial Vehicle) systems. Current frameworks tend to prescribe monolithic solutions that are not only prohibitively computationally complex with a scaling cost of $O(n^2)$ but simply do not offer Byzantine fault tolerance. The proposed hierarchical framework presented in this paper tries to eliminate such trade-offs by stratifying a three-layered architecture. We spread the intelligence into three layers: an immediate collision avoiding local layer running on dense graph attention with latency of $<10 ms$, a regional layer using sparse attention with $O(nk)$ computational complexity and asynchronous federated learning with coordinate-wise trimmed mean aggregation, and lastly, a global layer using a lightweight Hashgraph-inspired protocol. We have proposed an adaptive differential privacy mechanism, wherein the noise level $(ε\in [0.1, 1.0])$ is dynamically reduced based on an evaluation of the measured real-time threat that in turn maximized the privacy-utility tradeoff. Through the use of Distributed Hash Table (DHT)-based lightweight audit logging instead of heavyweight blockchain consensus, the median cost of getting a $95^{th}$ percentile decision within 50ms is observed across all tested swarm sizes. This architecture provides a scalable scenario of 500 UAVs with a collision rate of $< 2.0\%$ and the Byzantine fault tolerance of $f < n/3$.

</details>


### [366] [Tactile Data Recording System for Clothing with Motion-Controlled Robotic Sliding](https://arxiv.org/abs/2511.11634)
*Michikuni Eguchi,Takekazu Kitagishi,Yuichi Hiroi,Takefumi Hiraki*

Main category: cs.RO

TL;DR: 提出机器人手臂系统收集服装触觉数据，通过精确控制滑动动作创建多模态数据库，机器学习验证运动标签提升识别效果，为织物感知研究提供新方法。


<details>
  <summary>Details</summary>
Motivation: 服装的触觉感受对穿着舒适性至关重要，需要系统性收集滑动过程中的触觉数据以揭示舒适服装的物理特性。

Method: 提出了一种基于机器人手臂的系统，用于从完整服装中收集触觉数据。系统通过模拟指尖进行滑动测量，精确控制速度和方向，从而创建带有运动标签的多模态触觉数据库。

Result: 机器学习评估表明，包含运动相关参数提高了音频和加速度数据的识别准确率，证明了运动相关标签在表征服装触觉感受方面的有效性。

Conclusion: 该系统为服装触觉数据的采集提供了一种可扩展且非破坏性的方法，有助于未来关于织物感知和再现的研究。

Abstract: The tactile sensation of clothing is critical to wearer comfort. To reveal physical properties that make clothing comfortable, systematic collection of tactile data during sliding motion is required. We propose a robotic arm-based system for collecting tactile data from intact garments. The system performs stroking measurements with a simulated fingertip while precisely controlling speed and direction, enabling creation of motion-labeled, multimodal tactile databases. Machine learning evaluation showed that including motion-related parameters improved identification accuracy for audio and acceleration data, demonstrating the efficacy of motion-related labels for characterizing clothing tactile sensation. This system provides a scalable, non-destructive method for capturing tactile data of clothing, contributing to future studies on fabric perception and reproduction.

</details>


### [367] [Image-based Morphological Characterization of Filamentous Biological Structures with Non-constant Curvature Shape Feature](https://arxiv.org/abs/2511.11639)
*Jie Fan,Francesco Visentin,Barbara Mazzolai,Emanuela Del Dottore*

Main category: cs.RO

TL;DR: 提出了一种基于图像的几何方法，用于分析触须在不同部位机械刺激下的形状变化，发现顶端段响应性更高，为植物生物力学和机器人设计提供了新见解。


<details>
  <summary>Details</summary>
Motivation: 尽管攀援植物已被研究许久，但关于其时间形状变化、触发事件及接触位置之间关系的提取仍具挑战性。

Method: 采用基于3D分段Clothoid模型的几何方法，重构触须在机械摩擦后的形状配置。

Result: 重构方法表现出高稳健性和可靠性（R2 > 0.99），且在数据需求、计算成本和可解释性方面优于基于深度学习的方法。触须顶端段显示出更高的响应性，可能与器官该区域的更高灵敏度和组织柔韧性相关。

Conclusion: 本研究提供了一种用于植物生物力学研究的新方法，并为设计受攀援植物启发的智能机器人系统奠定了基础。

Abstract: Tendrils coil their shape to anchor the plant to supporting structures, allowing vertical growth toward light. Although climbing plants have been studied for a long time, extracting information regarding the relationship between the temporal shape change, the event that triggers it, and the contact location is still challenging. To help build this relation, we propose an image-based method by which it is possible to analyze shape changes over time in tendrils when mechano-stimulated in different portions of their body. We employ a geometric approach using a 3D Piece-Wise Clothoid-based model to reconstruct the configuration taken by a tendril after mechanical rubbing. The reconstruction shows high robustness and reliability with an accuracy of R2 > 0.99. This method demonstrates distinct advantages over deep learning-based approaches, including reduced data requirements, lower computational costs, and interpretability. Our analysis reveals higher responsiveness in the apical segment of tendrils, which might correspond to higher sensitivity and tissue flexibility in that region of the organs. Our study provides a methodology for gaining new insights into plant biomechanics and offers a foundation for designing and developing novel intelligent robotic systems inspired by climbing plants.

</details>


### [368] [ExpertAD: Enhancing Autonomous Driving Systems with Mixture of Experts](https://arxiv.org/abs/2511.11740)
*Haowen Jiang,Xinyu Huang,You Lu,Dingji Wang,Yuheng Cao,Chaofeng Sha,Bihuan Chen,Keyu Chen,Xin Peng*

Main category: cs.RO

TL;DR: ExpertAD通过MoE架构提升自动驾驶系统性能，减少碰撞和延迟，适用于复杂场景。


<details>
  <summary>Details</summary>
Motivation: 解决复杂驾驶场景中语义信息模糊或噪声导致的决策可靠性问题，以及多任务干扰和推理延迟带来的安全隐患。

Method: 提出了Perception Adapter (PA)增强任务关键特征，以及Mixture of Sparse Experts (MoSE)减少任务间干扰，实现高效规划。

Result: 实验显示ExpertAD将平均碰撞率降低20%，推理延迟减少25%，并在罕见场景中展现了多技能规划能力。

Conclusion: ExpertAD通过Mixture of Experts (MoE)架构显著提升了自动驾驶系统的性能，减少了碰撞率和推理延迟，并在复杂场景中展现了强大的泛化能力。

Abstract: Recent advancements in end-to-end autonomous driving systems (ADSs) underscore their potential for perception and planning capabilities. However, challenges remain. Complex driving scenarios contain rich semantic information, yet ambiguous or noisy semantics can compromise decision reliability, while interference between multiple driving tasks may hinder optimal planning. Furthermore, prolonged inference latency slows decision-making, increasing the risk of unsafe driving behaviors. To address these challenges, we propose ExpertAD, a novel framework that enhances the performance of ADS with Mixture of Experts (MoE) architecture. We introduce a Perception Adapter (PA) to amplify task-critical features, ensuring contextually relevant scene understanding, and a Mixture of Sparse Experts (MoSE) to minimize task interference during prediction, allowing for effective and efficient planning. Our experiments show that ExpertAD reduces average collision rates by up to 20% and inference latency by 25% compared to prior methods. We further evaluate its multi-skill planning capabilities in rare scenarios (e.g., accidents, yielding to emergency vehicles) and demonstrate strong generalization to unseen urban environments. Additionally, we present a case study that illustrates its decision-making process in complex driving scenarios.

</details>


### [369] [Large Language Models and 3D Vision for Intelligent Robotic Perception and Autonomy: A Review](https://arxiv.org/abs/2511.11777)
*Vinit Mehta,Charu Sharma,Karthick Thiyagarajan*

Main category: cs.RO

TL;DR: 综述了LLMs与3D视觉融合在机器人感知技术中的最新方法、应用和挑战，强调了跨模态整合和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能和机器人技术的快速发展，LLMs与3D视觉的融合成为提升机器人感知技术的变革性方法，旨在弥补语言智能与空间感知之间的差距。

Method: 论文通过综述的方式，首先介绍了LLMs和3D数据表示的基础原理，然后深入分析了机器人技术中的3D感知技术，并探讨了场景理解、文本到3D生成、对象接地和具身代理等关键进展。

Result: 论文概述了在3D语言和视觉任务中的基准数据集和评估指标，并突出了零样本3D分割、动态场景合成和语言引导操作等前沿技术。

Conclusion: 论文总结了LLMs与3D视觉融合在机器人感知技术中的关键挑战与未来研究方向，包括自适应模型架构、跨模态对齐增强和实时处理能力，为更智能、上下文感知和自主的机器人感知系统铺平了道路。

Abstract: With the rapid advancement of artificial intelligence and robotics, the integration of Large Language Models (LLMs) with 3D vision is emerging as a transformative approach to enhancing robotic sensing technologies. This convergence enables machines to perceive, reason and interact with complex environments through natural language and spatial understanding, bridging the gap between linguistic intelligence and spatial perception. This review provides a comprehensive analysis of state-of-the-art methodologies, applications and challenges at the intersection of LLMs and 3D vision, with a focus on next-generation robotic sensing technologies. We first introduce the foundational principles of LLMs and 3D data representations, followed by an in-depth examination of 3D sensing technologies critical for robotics. The review then explores key advancements in scene understanding, text-to-3D generation, object grounding and embodied agents, highlighting cutting-edge techniques such as zero-shot 3D segmentation, dynamic scene synthesis and language-guided manipulation. Furthermore, we discuss multimodal LLMs that integrate 3D data with touch, auditory and thermal inputs, enhancing environmental comprehension and robotic decision-making. To support future research, we catalog benchmark datasets and evaluation metrics tailored for 3D-language and vision tasks. Finally, we identify key challenges and future research directions, including adaptive model architectures, enhanced cross-modal alignment and real-time processing capabilities, which pave the way for more intelligent, context-aware and autonomous robotic sensing systems.

</details>


### [370] [LAVQA: A Latency-Aware Visual Question Answering Framework for Shared Autonomy in Self-Driving Vehicles](https://arxiv.org/abs/2511.11840)
*Shuangyu Xie,Kaiyuan Chen,Wenjing Chen,Chengyuan Qian,Christian Juette,Liu Ren,Dezhen Song,Ken Goldberg*

Main category: cs.RO

TL;DR: LAVQA是一个结合视觉问答和风险可视化的共享自治框架，显著降低自动驾驶在延迟下的碰撞率。


<details>
  <summary>Details</summary>
Motivation: 在不确定性高的情况下，自动驾驶车辆需要远程人类操作员的高层指导，但网络延迟和响应时间会影响决策时机。

Method: 提出了LAVQA框架，结合视觉问答和动态演变的LICOM地图，以应对网络延迟和人类响应时间带来的决策时机问题。

Result: 在CARLA模拟器中的闭环实验表明，LAVQA相比不考虑延迟的基准方法，碰撞率降低了8倍以上。

Conclusion: LAVQA框架通过整合视觉问答（VQA）和时空风险可视化，显著降低了自动驾驶车辆在延迟情况下的碰撞率。

Abstract: When uncertainty is high, self-driving vehicles may halt for safety and benefit from the access to remote human operators who can provide high-level guidance. This paradigm, known as {shared autonomy}, enables autonomous vehicle and remote human operators to jointly formulate appropriate responses. To address critical decision timing with variable latency due to wireless network delays and human response time, we present LAVQA, a latency-aware shared autonomy framework that integrates Visual Question Answering (VQA) and spatiotemporal risk visualization. LAVQA augments visual queries with Latency-Induced COllision Map (LICOM), a dynamically evolving map that represents both temporal latency and spatial uncertainty. It enables remote operator to observe as the vehicle safety regions vary over time in the presence of dynamic obstacles and delayed responses. Closed-loop simulations in CARLA, the de-facto standard for autonomous vehicle simulator, suggest that that LAVQA can reduce collision rates by over 8x compared to latency-agnostic baselines.

</details>


### [371] [Autonomous Underwater Cognitive System for Adaptive Navigation: A SLAM-Integrated Cognitive Architecture](https://arxiv.org/abs/2511.11845)
*K. A. I. N Jayarathne,R. M. N. M. Rathnayaka,D. P. S. S. Peiris*

Main category: cs.RO

TL;DR: AUCS结合SLAM与Soar认知架构，通过多传感器融合和自适应学习，提升了水下导航的智能性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 深海探索面临迷失方向、通信中断和动态水下环境中的导航失败等挑战，需要更智能的解决方案。

Method: 系统融合了SONAR、LiDAR、IMU和DVL等多传感器数据，结合认知推理模块（感知、注意、规划和学习），并引入语义理解、自适应传感器管理和基于记忆的学习。

Result: AUCS展示了完整的感知-认知-行动-学习循环，显著减少了错误闭环并提升了长期地图一致性。

Conclusion: 本文提出了一种自主水下认知系统（AUCS），通过结合SLAM和Soar认知架构，提升了复杂海洋环境中的自适应导航能力，为下一代认知潜水系统奠定了基础。

Abstract: Deep-sea exploration poses significant challenges, including disorientation, communication loss, and navigational failures in dynamic underwater environments. This paper presents an Autonomous Underwater Cognitive System (AUCS) that integrates Simultaneous Localization and Mapping (SLAM) with a Soar-based cognitive architecture to enable adaptive navigation in complex oceanic conditions. The system fuses multi-sensor data from SONAR, LiDAR, IMU, and DVL with cognitive reasoning modules for perception, attention, planning, and learning. Unlike conventional SLAM systems, AUCS incorporates semantic understanding, adaptive sensor management, and memory-based learning to differentiate between dynamic and static objects, reducing false loop closures and enhancing long-term map consistency. The proposed architecture demonstrates a complete perception-cognition-action-learning loop, allowing autonomous underwater vehicles to sense, reason, and adapt intelligently. This work lays a foundation for next-generation cognitive submersible systems, improving safety, reliability, and autonomy in deep-sea exploration.

</details>


### [372] [MATT-Diff: Multimodal Active Target Tracking by Diffusion Policy](https://arxiv.org/abs/2511.11931)
*Saida Liu,Nikolay Atanasov,Shumon Koga*

Main category: cs.RO

TL;DR: MATT-Diff是一种多模态主动目标跟踪的扩散策略，通过结合探索、跟踪和重新捕获行为，无需先验知识即可高效控制，性能优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 有效目标跟踪需要在探索未检测或丢失目标与跟随检测但不确定目标的运动之间取得平衡。

Method: 利用视觉变换器对自我中心地图进行标记化，并通过注意力机制整合高斯密度表示的可变目标估计，训练扩散模型生成多模态动作序列。

Result: 评估显示MATT-Diff在多种目标运动下均优于专家和行为克隆基线，验证了其卓越的跟踪性能。

Conclusion: MATT-Diff在多目标主动跟踪任务中表现出色，通过扩散策略成功捕捉多种行为模式，无需先验知识即可实现高效控制，验证了其在目标跟踪中的优势。

Abstract: This paper proposes MATT-Diff: Multi-Modal Active Target Tracking by Diffusion Policy, a control policy that captures multiple behavioral modes - exploration, dedicated tracking, and target reacquisition - for active multi-target tracking. The policy enables agent control without prior knowledge of target numbers, states, or dynamics. Effective target tracking demands balancing exploration for undetected or lost targets with following the motion of detected but uncertain ones. We generate a demonstration dataset from three expert planners including frontier-based exploration, an uncertainty-based hybrid planner switching between frontier-based exploration and RRT* tracking based on target uncertainty, and a time-based hybrid planner switching between exploration and tracking based on target detection time. We design a control policy utilizing a vision transformer for egocentric map tokenization and an attention mechanism to integrate variable target estimates represented by Gaussian densities. Trained as a diffusion model, the policy learns to generate multi-modal action sequences through a denoising process. Evaluations demonstrate MATT-Diff's superior tracking performance against expert and behavior cloning baselines across multiple target motions, empirically validating its advantages in target tracking.

</details>


### [373] [Characterization and Evaluation of Screw-Based Locomotion Across Aquatic, Granular, and Transitional Media](https://arxiv.org/abs/2511.11958)
*Derek Chen,Zoe Samuels,Lizzie Peiros,Sujaan Mukherjee,Michael C. Yip*

Main category: cs.RO

TL;DR: 研究分析了螺丝推进系统在不同介质中的性能，发现关键设计参数并提出优化策略。


<details>
  <summary>Details</summary>
Motivation: 螺丝推进系统在两栖移动中具有潜力，但在优化水、颗粒物质和过渡环境中的运动性能方面面临挑战。

Method: 采用原理优先的方法分析不同螺丝配置在干沙、湿沙、饱和沙和水等介质中的运动性能。

Result: 发现某些参数在性能影响中占主导地位，且根据不同介质，源自热沉设计的参数有助于在主导设计参数内分类性能。

Conclusion: 研究为螺丝推进系统的设计提供了具体见解，特别是在螺丝壳设计和自适应运动策略方面，以提升其在多样化两栖应用中的性能。

Abstract: Screw-based propulsion systems offer promising capabilities for amphibious mobility, yet face significant challenges in optimizing locomotion across water, granular materials, and transitional environments. This study presents a systematic investigation into the locomotion performance of various screw configurations in media such as dry sand, wet sand, saturated sand, and water. Through a principles-first approach to analyze screw performance, it was found that certain parameters are dominant in their impact on performance. Depending on the media, derived parameters inspired from optimizing heat sink design help categorize performance within the dominant design parameters. Our results provide specific insights into screw shell design and adaptive locomotion strategies to enhance the performance of screw-based propulsion systems for versatile amphibious applications.

</details>


### [374] [Bootstrapped LLM Semantics for Context-Aware Path Planning](https://arxiv.org/abs/2511.11967)
*Mani Amani,Behrad Beheshti,Reza Akhavian*

Main category: cs.RO

TL;DR: 该论文提出一种框架，将LLM作为语义传感器辅助古典规划器，通过贝叶斯方法评估风险并优化路径规划，适用于人机交互场景。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注通过自然语言选择任务目标或技能序列，而忽略了在语义丰富、以人为中心的空间中如何安全高效执行任务的问题。

Method: 利用LLM生成多组'危险'判断，并通过贝叶斯引导方法近似每类风险的后验分布，最终构建潜在成本函数以解决路径规划问题。

Result: 在模拟环境和BIM支持的数字孪生中，该方法能根据显式提示和隐式上下文信息调整机器人移动方式，并展示了定性和定量结果。

Conclusion: 该论文提出了一种将大型语言模型（LLM）转化为随机语义传感器的框架，通过结合语义地图和贝叶斯引导方法，实现了机器人路径规划的安全性和效率提升。

Abstract: Prompting robots with natural language (NL) has largely been studied as what task to execute (goal selection, skill sequencing) rather than how to execute that task safely and efficiently in semantically rich, human-centric spaces. We address this gap with a framework that turns a large language model (LLM) into a stochastic semantic sensor whose outputs modulate a classical planner. Given a prompt and a semantic map, we draw multiple LLM "danger" judgments and apply a Bayesian bootstrap to approximate a posterior over per-class risk. Using statistics from the posterior, we create a potential cost to formulate a path planning problem. Across simulated environments and a BIM-backed digital twin, our method adapts how the robot moves in response to explicit prompts and implicit contextual information. We present qualitative and quantitative results.

</details>


### [375] [ARCSnake V2: An Amphibious Multi-Domain Screw-Propelled Snake-Like Robot](https://arxiv.org/abs/2511.11970)
*Sara Wickenhiser,Lizzie Peiros,Calvin Joyce,Peter Gavrilrov,Sujaan Mukherjee,Syler Sylvester,Junrong Zhou,Mandy Cheung,Jason Lim,Florian Richter,Michael C. Yip*

Main category: cs.RO

TL;DR: ARCSnake V2 是一种蛇形机器人，结合螺旋推进技术，适用于陆地、颗粒介质和水环境，具有高度灵活性和多功能性。


<details>
  <summary>Details</summary>
Motivation: 传统轮式或腿式机器人在极端环境（如洞穴、海洋和行星表面）的多样化地形中移动困难，需要一种更灵活的解决方案。

Method: 结合了高度灵活的超冗余蛇形机器人和阿基米德螺旋推进的地形多功能性，采用了防水机械设计、串联连接的螺旋和关节驱动、集成浮力控制系统，以及通过运动学匹配的手持控制器进行远程操作。

Result: 实验验证了其水下机动性、通信鲁棒性和力调节驱动能力，支持多种运动模式（螺旋推进、轮式移动和侧向滑动）之间的平滑过渡。

Conclusion: ARCSnake V2 被定位为一个多功能平台，适用于多领域环境中的探索、搜救和环境监测。

Abstract: Robotic exploration in extreme environments such as caves, oceans, and planetary surfaces pose significant challenges, particularly in locomotion across diverse terrains. Conventional wheeled or legged robots often struggle in these contexts due to surface variability. This paper presents ARCSnake V2, an amphibious, screw propelled, snake like robot designed for teleoperated or autonomous locomotion across land, granular media, and aquatic environments. ARCSnake V2 combines the high mobility of hyper redundant snake robots with the terrain versatility of Archimedean screw propulsion. Key contributions include a water sealed mechanical design with serially linked screw and joint actuation, an integrated buoyancy control system, and teleoperation via a kinematically matched handheld controller. The robots design and control architecture enable multiple locomotion modes screwing, wheeling, and sidewinding with smooth transitions between them. Extensive experiments validate its underwater maneuverability, communication robustness, and force regulated actuation. These capabilities position ARCSnake V2 as a versatile platform for exploration, search and rescue, and environmental monitoring in multi domain settings.

</details>


### [376] [SBAMP: Sampling Based Adaptive Motion Planning](https://arxiv.org/abs/2511.12022)
*Anh-Quan Pham,Kabir Ram Puri,Shreyas Raorane*

Main category: cs.RO

TL;DR: SBAMP结合RRT*和SEDS，实现动态环境中的实时自适应导航，无需预训练数据，实验验证性能优越。


<details>
  <summary>Details</summary>
Motivation: 传统采样方法（如RRT*）难以适应动态变化，而学习型动态系统（如SEDS）依赖预收集数据，泛化能力有限。SBAMP旨在克服这些限制。

Method: 结合RRT*进行全局路径规划和基于SEDS的局部控制器进行连续自适应轨迹调整，利用Lyapunov稳定性理论保证系统稳定性。

Result: 在模拟环境和RoboRacer平台上验证了SBAMP在动态障碍物场景、快速恢复和急转弯处理上的优越性能。

Conclusion: SBAMP框架通过结合RRT*全局路径规划和SEDS局部控制器，实现了在动态环境中实时自适应导航，无需预训练数据集，且保持了路径最优性和稳定性。

Abstract: Autonomous robotic systems must navigate complex, dynamic environments in real time, often facing unpredictable obstacles and rapidly changing conditions. Traditional sampling-based methods, such as RRT*, excel at generating collision-free paths but struggle to adapt to sudden changes without extensive replanning. Conversely, learning-based dynamical systems, such as the Stable Estimator of Dynamical Systems (SEDS), offer smooth, adaptive trajectory tracking but typically rely on pre-collected demonstration data, limiting their generalization to novel scenarios. This paper introduces Sampling-Based Adaptive Motion Planning (SBAMP), a novel framework that overcomes these limitations by integrating RRT* for global path planning with a SEDS-based local controller for continuous, adaptive trajectory adjustment. Our approach requires no pre-trained datasets and ensures smooth transitions between planned waypoints, maintaining stability through Lyapunov-based guarantees. We validate SBAMP in both simulated environments and real hardware using the RoboRacer platform, demonstrating superior performance in dynamic obstacle scenarios, rapid recovery from perturbations, and robust handling of sharp turns. Experimental results highlight SBAMP's ability to adapt in real time without sacrificing global path optimality, providing a scalable solution for dynamic, unstructured environments.

</details>


### [377] [Decoupled Action Head: Confining Task Knowledge to Conditioning Layers](https://arxiv.org/abs/2511.12101)
*Jian Zhou,Sihao Lin,Shuai Fu,Qi WU*

Main category: cs.RO

TL;DR: 提出解耦训练方法，利用运动学生成轨迹预训练动作头，提升训练效率和泛化能力，并用更简单的MLP结构（DP-MLP）显著加速训练。


<details>
  <summary>Details</summary>
Motivation: 现有行为克隆方法（如Diffusion Policy）受限于训练数据稀缺，且其内部机制不明确，导致泛化能力不足和模型设计缺乏原则性。

Method: 提出了一种解耦训练方法，利用运动学生成的轨迹预训练通用动作头，并通过特征调制适配新任务。此外，将DP-CNN中的U-Net主干替换为简单的MLP块，形成DP-MLP。

Result: 实验证明解耦训练方法在分布内和分布外场景均可行，且DP-CNN训练速度提升41%。DP-MLP在正常训练和解耦训练下分别实现83.9%和89.1%的训练速度提升。

Conclusion: 本研究表明，通过解耦训练方法，利用运动学生成的轨迹预训练通用动作头，可以有效提升行为克隆（BC）方法的训练效率和泛化能力。此外，动作生成主干在机器人操作中的作用有限，因此采用更简单的MLP结构（DP-MLP）可以显著提升训练速度。

Abstract: Behavior Cloning (BC) is a data-driven supervised learning approach that has gained increasing attention with the success of scaling laws in language and vision domains. Among its implementations in robotic manipulation, Diffusion Policy (DP), with its two variants DP-CNN (DP-C) and DP-Transformer (DP-T), is one of the most effective and widely adopted models, demonstrating the advantages of predicting continuous action sequences. However, both DP and other BC methods remain constrained by the scarcity of paired training data, and the internal mechanisms underlying DP's effectiveness remain insufficiently understood, leading to limited generalization and a lack of principled design in model development. In this work, we propose a decoupled training recipe that leverages nearly cost-free kinematics-generated trajectories as observation-free data to pretrain a general action head (action generator). The pretrained action head is then frozen and adapted to novel tasks through feature modulation. Our experiments demonstrate the feasibility of this approach in both in-distribution and out-of-distribution scenarios. As an additional benefit, decoupling improves training efficiency; for instance, DP-C achieves up to a 41% speedup. Furthermore, the confinement of task-specific knowledge to the conditioning components under decoupling, combined with the near-identical performance of DP-C in both normal and decoupled training, indicates that the action generation backbone plays a limited role in robotic manipulation. Motivated by this observation, we introduce DP-MLP, which replaces the 244M-parameter U-Net backbone of DP-C with only 4M parameters of simple MLP blocks, achieving a 83.9% faster training speed under normal training and 89.1% under decoupling.

</details>


### [378] [Towards Obstacle-Avoiding Control of Planar Snake Robots Exploring Neuro-Evolution of Augmenting Topologies](https://arxiv.org/abs/2511.12148)
*Advik Sinha,Akshay Arjun,Abhijit Das,Joyjit Mukherjee*

Main category: cs.RO

TL;DR: NEAT算法用于蛇形机器人避障控制，高效且计算开销低，模拟结果显示优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为在密集障碍环境中实现平面蛇形机器人的高效避障跟踪控制，同时降低计算开销。

Method: 采用Neuro-Evolution of Augmenting Topologies (NEAT)算法生成动态步态参数，通过蛇形步态函数控制机器人的关节角度，结合LiDAR和传感器数据参数化奖励函数，并通过选择性传播优化神经网络。

Result: 该方法在PyBullet物理引擎模拟中验证，性能优于现有技术，与最新的CBRL方法相当且计算开销显著更低。

Conclusion: 该研究提出了一种基于NEAT的资源高效解决方案，用于平面蛇形机器人在密集障碍环境中的避障跟踪控制，其计算效率高，且在大型多障碍环境中表现优异。

Abstract: This work aims to develop a resource-efficient solution for obstacle-avoiding tracking control of a planar snake robot in a densely cluttered environment with obstacles. Particularly, Neuro-Evolution of Augmenting Topologies (NEAT) has been employed to generate dynamic gait parameters for the serpenoid gait function, which is implemented on the joint angles of the snake robot, thus controlling the robot on a desired dynamic path. NEAT is a single neural-network based evolutionary algorithm that is known to work extremely well when the input layer is of significantly higher dimension and the output layer is of a smaller size. For the planar snake robot, the input layer consists of the joint angles, link positions, head link position as well as obstacle positions in the vicinity. However, the output layer consists of only the frequency and offset angle of the serpenoid gait that control the speed and heading of the robot, respectively. Obstacle data from a LiDAR and the robot data from various sensors, along with the location of the end goal and time, are employed to parametrize a reward function that is maximized over iterations by selective propagation of superior neural networks. The implementation and experimental results showcase that the proposed approach is computationally efficient, especially for large environments with many obstacles. The proposed framework has been verified through a physics engine simulation study on PyBullet. The approach shows superior results to existing state-of-the-art methodologies and comparable results to the very recent CBRL approach with significantly lower computational overhead. The video of the simulation can be found here: https://sites.google.com/view/neatsnakerobot

</details>


### [379] [Game-Theoretic Safe Multi-Agent Motion Planning with Reachability Analysis for Dynamic and Uncertain Environments (Extended Version)](https://arxiv.org/abs/2511.12160)
*Wenbin Mai,Minghui Liwang,Xinlei Yi,Xiaoyu Xia,Seyyedali Hosseinalipour,Xianbin Wang*

Main category: cs.RO

TL;DR: RE-DPG框架通过博弈论和可达性分析的结合，解决了多智能体运动规划的复杂性和安全性问题，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 多智能体系统在动态和不确定环境中的运动规划面临复杂交互、随机干扰和模型不确定性的挑战，需要一种既能保证计算效率又能确保安全的方法。

Method: 提出了RE-DPG框架，结合动态势博弈和可达性分析，开发了ND-iBR方案和MA-FRS机制，以确保计算效率和安全性。

Result: 通过仿真和实际实验验证了RE-DPG在2D和3D环境中的有效性，展示了其在多种操作场景中的鲁棒性。

Conclusion: RE-DPG框架通过集成可达性分析和博弈论协调，有效解决了多智能体系统在动态不确定环境中的运动规划问题，验证了其在实际场景中的有效性和安全性。

Abstract: Ensuring safe, robust, and scalable motion planning for multi-agent systems in dynamic and uncertain environments is a persistent challenge, driven by complex inter-agent interactions, stochastic disturbances, and model uncertainties. To overcome these challenges, particularly the computational complexity of coupled decision-making and the need for proactive safety guarantees, we propose a Reachability-Enhanced Dynamic Potential Game (RE-DPG) framework, which integrates game-theoretic coordination into reachability analysis. This approach formulates multi-agent coordination as a dynamic potential game, where the Nash equilibrium (NE) defines optimal control strategies across agents. To enable scalability and decentralized execution, we develop a Neighborhood-Dominated iterative Best Response (ND-iBR) scheme, built upon an iterated $\varepsilon$-BR (i$\varepsilon$-BR) process that guarantees finite-step convergence to an $\varepsilon$-NE. This allows agents to compute strategies based on local interactions while ensuring theoretical convergence guarantees. Furthermore, to ensure safety under uncertainty, we integrate a Multi-Agent Forward Reachable Set (MA-FRS) mechanism into the cost function, explicitly modeling uncertainty propagation and enforcing collision avoidance constraints. Through both simulations and real-world experiments in 2D and 3D environments, we validate the effectiveness of RE-DPG across diverse operational scenarios.

</details>


### [380] [Variable Impedance Control for Floating-Base Supernumerary Robotic Leg in Walking Assistance](https://arxiv.org/abs/2511.12184)
*Jun Huo,Kehan Xu,Chengyao Li,Yu Cao,Jie Zuo,Xinxing Chen,Jian Huang*

Main category: cs.RO

TL;DR: 针对浮动基座的超级机器人腿系统，提出了一种变阻抗控制方法，通过动态调整阻抗参数提升人机交互的安全性和适应性。


<details>
  <summary>Details</summary>
Motivation: 解决浮动基座带来的挑战，提升人机交互中的安全性和适应性。

Method: 研究了松散耦合的SRL动力学模型，设计了混合位置/力阻抗控制器，并开发了高效的变阻抗控制（VIC）方法。

Result: 仿真和实验验证了系统的有效性，能够在柔性状态下保持平滑信号过渡，在刚性状态下提供强支撑力。

Conclusion: 该方法为适应个体步态变化提供了实用解决方案，显著提升了人机系统的安全性和适应性。

Abstract: In human-robot systems, ensuring safety during force control in the presence of both internal and external disturbances is crucial. As a typical loosely coupled floating-base robot system, the supernumerary robotic leg (SRL) system is particularly susceptible to strong internal disturbances. To address the challenge posed by floating base, we investigated the dynamics model of the loosely coupled SRL and designed a hybrid position/force impedance controller to fit dynamic torque input. An efficient variable impedance control (VIC) method is developed to enhance human-robot interaction, particularly in scenarios involving external force disturbances. By dynamically adjusting impedance parameters, VIC improves the dynamic switching between rigidity and flexibility, so that it can adapt to unknown environmental disturbances in different states. An efficient real-time stability guaranteed impedance parameters generating network is specifically designed for the proposed SRL, to achieve shock mitigation and high rigidity supporting. Simulations and experiments validate the system's effectiveness, demonstrating its ability to maintain smooth signal transitions in flexible states while providing strong support forces in rigid states. This approach provides a practical solution for accommodating individual gait variations in interaction, and significantly advances the safety and adaptability of human-robot systems.

</details>


### [381] [Innovative Design of Multi-functional Supernumerary Robotic Limbs with Ellipsoid Workspace Optimization](https://arxiv.org/abs/2511.12186)
*Jun Huo,Jian Huang,Jie Zuo,Bo Yang,Zhongzheng Fu,Xi Li,Samer Mohammed*

Main category: cs.RO

TL;DR: A MOO theory for SRL design improved grasp success and reduced muscle activity, validated via experiments with healthy and hemiplegic participants.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of designing a general-purpose SRL device that meets diverse functional requirements for both upper and lower limbs, while reducing computational complexity and improving performance.

Method: A multi-objective optimization (MOO) design theory integrating grasping and walking workspace similarity, braced force for sit-to-stand movements, and mass/inertia constraints, using a geometric vector quantification method and a multi-subpopulation correction firefly algorithm.

Result: Experimental results showed a 7.2% improvement in grasp success rate and reductions in muscle activity by 12.7% (walking) and 25.1% (STS) compared to pre-optimization.

Conclusion: The proposed multi-objective optimization design theory provides an efficient framework for designing multi-functional supernumerary robotic limbs, demonstrating improved performance in both healthy individuals and hemiplegic patients.

Abstract: Supernumerary robotic limbs (SRLs) offer substantial potential in both the rehabilitation of hemiplegic patients and the enhancement of functional capabilities for healthy individuals. Designing a general-purpose SRL device is inherently challenging, particularly when developing a unified theoretical framework that meets the diverse functional requirements of both upper and lower limbs. In this paper, we propose a multi-objective optimization (MOO) design theory that integrates grasping workspace similarity, walking workspace similarity, braced force for sit-to-stand (STS) movements, and overall mass and inertia. A geometric vector quantification method is developed using an ellipsoid to represent the workspace, aiming to reduce computational complexity and address quantification challenges. The ellipsoid envelope transforms workspace points into ellipsoid attributes, providing a parametric description of the workspace. Furthermore, the STS static braced force assesses the effectiveness of force transmission. The overall mass and inertia restricts excessive link length. To facilitate rapid and stable convergence of the model to high-dimensional irregular Pareto fronts, we introduce a multi-subpopulation correction firefly algorithm. This algorithm incorporates a strategy involving attractive and repulsive domains to effectively handle the MOO task. The optimized solution is utilized to redesign the prototype for experimentation to meet specified requirements. Six healthy participants and two hemiplegia patients participated in real experiments. Compared to the pre-optimization results, the average grasp success rate improved by 7.2%, while the muscle activity during walking and STS tasks decreased by an average of 12.7% and 25.1%, respectively. The proposed design theory offers an efficient option for the design of multi-functional SRL mechanisms.

</details>


### [382] [Locally Optimal Solutions to Constraint Displacement Problems via Path-Obstacle Overlaps](https://arxiv.org/abs/2511.12203)
*Antony Thomas,Fulvio Mastrogiovanni,Marco Baglietto*

Main category: cs.RO

TL;DR: 论文提出两阶段方法，先计算轨迹再位移障碍物，解决机器人路径规划中的约束位移问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决机器人在路径规划中遇到约束或障碍物时需要位移的问题，提出统一的方法。

Method: 采用两阶段过程：第一阶段通过最小化目标函数计算机器人轨迹；第二阶段通过位移障碍物使轨迹可行。

Result: 方法在两类约束位移问题上成功验证，能够找到局部最优的障碍物位移方案。

Conclusion: 论文提出了一种两阶段方法，成功解决了机器人路径规划中的约束位移问题，并通过多个实例验证了其有效性。

Abstract: We present a unified approach for constraint displacement problems in which a robot finds a feasible path by displacing constraints or obstacles. To this end, we propose a two stage process that returns locally optimal obstacle displacements to enable a feasible path for the robot. The first stage proceeds by computing a trajectory through the obstacles while minimizing an appropriate objective function. In the second stage, these obstacles are displaced to make the computed robot trajectory feasible, that is, collision-free. Several examples are provided that successfully demonstrate our approach on two distinct classes of constraint displacement problems.

</details>


### [383] [SocialNav-Map: Dynamic Mapping with Human Trajectory Prediction for Zero-Shot Social Navigation](https://arxiv.org/abs/2511.12232)
*Lingfeng Zhang,Erjia Xiao,Xiaoshuai Hao,Haoxiang Fu,Zeying Gong,Long Chen,Xiaojun Liang,Renjing Xu,Hangjun Ye,Wenbo Ding*

Main category: cs.RO

TL;DR: SocialNav-Map是一种零样本社交导航框架，通过动态轨迹预测和占用地图实现高效导航，无需环境特定训练，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于强化学习的方法需要大量训练且难以泛化到陌生环境的问题。

Method: 结合动态人类轨迹预测与占用地图，通过历史预测和方向预测两种互补方法预测人类轨迹，并将其整合到占用地图中。

Result: 在Social-HM3D和Social-MP3D数据集上显著优于现有方法，减少10%以上的人类碰撞率。

Conclusion: SocialNav-Map无需环境特定训练即可实现卓越导航性能，为在现实世界中部署社交导航系统铺平道路。

Abstract: Social navigation in densely populated dynamic environments poses a significant challenge for autonomous mobile robots, requiring advanced strategies for safe interaction. Existing reinforcement learning (RL)-based methods require over 2000+ hours of extensive training and often struggle to generalize to unfamiliar environments without additional fine-tuning, limiting their practical application in real-world scenarios. To address these limitations, we propose SocialNav-Map, a novel zero-shot social navigation framework that combines dynamic human trajectory prediction with occupancy mapping, enabling safe and efficient navigation without the need for environment-specific training. Specifically, SocialNav-Map first transforms the task goal position into the constructed map coordinate system. Subsequently, it creates a dynamic occupancy map that incorporates predicted human movements as dynamic obstacles. The framework employs two complementary methods for human trajectory prediction: history prediction and orientation prediction. By integrating these predicted trajectories into the occupancy map, the robot can proactively avoid potential collisions with humans while efficiently navigating to its destination. Extensive experiments on the Social-HM3D and Social-MP3D datasets demonstrate that SocialNav-Map significantly outperforms state-of-the-art (SOTA) RL-based methods, which require 2,396 GPU hours of training. Notably, it reduces human collision rates by over 10% without necessitating any training in novel environments. By eliminating the need for environment-specific training, SocialNav-Map achieves superior navigation performance, paving the way for the deployment of social navigation systems in real-world environments characterized by diverse human behaviors. The code is available at: https://github.com/linglingxiansen/SocialNav-Map.

</details>


### [384] [Intermittent Rendezvous Plans with Mixed Integer Linear Program for Large-Scale Multi-Robot Exploration](https://arxiv.org/abs/2511.12237)
*Alysson Ribeiro da Silva,Luiz Chaimowicz*

Main category: cs.RO

TL;DR: 本文提出MILP和RTUS机制，解决多机器人探索中的通信约束问题，实验验证其高效性。


<details>
  <summary>Details</summary>
Motivation: 现有调度方法需预先了解环境，限制了其在不明确环境（如水下探索）中的应用。本文旨在解决这一限制，提升计划生成与跟踪的实用性。

Method: 采用混合整数线性规划（MILP）生成会合计划，并结合RTUS机制跟踪计划以适应未知条件。

Result: Gazebo模拟实验表明，该方法能高效跟踪计划并完成任务。

Conclusion: 本文提出的MILP规划生成器和RTUS机制在多机器人探索中有效解决了通信约束和间歇性连接问题，适用于现实世界部署。

Abstract: Multi-Robot Exploration (MRE) systems with communication constraints have proven efficient in accomplishing a variety of tasks, including search-and-rescue, stealth, and military operations. While some works focus on opportunistic approaches for efficiency, others concentrate on pre-planned trajectories or scheduling for increased interpretability. However, scheduling usually requires knowledge of the environment beforehand, which prevents its deployment in several domains due to related uncertainties (e.g., underwater exploration). In our previous work, we proposed an intermittent communications framework for MRE under communication constraints that uses scheduled rendezvous events to mitigate such limitations. However, the system was unable to generate optimal plans and had no mechanisms to follow the plan considering realistic trajectories, which is not suited for real-world deployments. In this work, we further investigate the problem by formulating the Multi-Robot Exploration with Communication Constraints and Intermittent Connectivity (MRE-CCIC) problem. We propose a Mixed-Integer Linear Program (MILP) formulation to generate rendezvous plans and a policy to follow them based on the Rendezvous Tracking for Unknown Scenarios (RTUS) mechanism. The RTUS is a simple rule to allow robots to follow the assigned plan, considering unknown conditions. Finally, we evaluated our method in a large-scale environment configured in Gazebo simulations. The results suggest that our method can follow the plan promptly and accomplish the task efficiently. We provide an open-source implementation of both the MILP plan generator and the large-scale MRE-CCIC.

</details>


### [385] [SAC-MoE: Reinforcement Learning with Mixture-of-Experts for Control of Hybrid Dynamical Systems with Uncertainty](https://arxiv.org/abs/2511.12361)
*Leroy D'Souza,Akash Karthikeyan,Yash Vardhan Pant,Sebastian Fischmeister*

Main category: cs.RO

TL;DR: SAC-MoE通过MoE建模和课程学习，显著提升混合动力系统在未知环境中的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决混合动力系统中因不可观测参数和事件导致的模式切换不确定性，传统模型控制方法无法应对此类不确定性，而标准无模型RL方法难以处理突发的模式切换。

Method: 提出SAC-MoE，将Soft Actor-Critic（SAC）框架中的actor建模为Mixture-of-Experts（MoE），并开发基于课程的学习算法以优先收集挑战性场景的数据。

Result: 仿真研究表明，SAC-MoE在未见过的环境中表现出卓越的泛化能力，MoE路由器可解释性地为不同潜在模式激活不同专家。

Conclusion: SAC-MoE在混合自主赛车和腿式 locomotion任务中展现出优于基线方法（高达6倍）的零样本泛化能力，且课程策略在所有评估策略中持续提升性能。

Abstract: Hybrid dynamical systems result from the interaction of continuous-variable dynamics with discrete events and encompass various systems such as legged robots, vehicles and aircrafts. Challenges arise when the system's modes are characterized by unobservable (latent) parameters and the events that cause system dynamics to switch between different modes are also unobservable. Model-based control approaches typically do not account for such uncertainty in the hybrid dynamics, while standard model-free RL methods fail to account for abrupt mode switches, leading to poor generalization.
  To overcome this, we propose SAC-MoE which models the actor of the Soft Actor-Critic (SAC) framework as a Mixture-of-Experts (MoE) with a learned router that adaptively selects among learned experts. To further improve robustness, we develop a curriculum-based training algorithm to prioritize data collection in challenging settings, allowing better generalization to unseen modes and switching locations. Simulation studies in hybrid autonomous racing and legged locomotion tasks show that SAC-MoE outperforms baselines (up to 6x) in zero-shot generalization to unseen environments. Our curriculum strategy consistently improves performance across all evaluated policies. Qualitative analysis shows that the interpretable MoE router activates different experts for distinct latent modes.

</details>


### [386] [Multilaminate piezoelectric PVDF actuators to enhance performance of soft micro robots](https://arxiv.org/abs/2511.12380)
*Nicholas Gunter,Heiko Kabutz,Kaushik Jayaram*

Main category: cs.RO

TL;DR: 多层PVDF致动器通过优化设计，在软微机器人中实现高性能（毫米级偏转、毫牛级力、高频率），并成功应用于移动微机器人。


<details>
  <summary>Details</summary>
Motivation: 探索多层PVDF致动器在软微机器人系统中的性能提升潜力，填补高力PZT堆栈和低带宽软聚合物致动器之间的设计空白。

Method: 开发并表征了多层PVDF致动器，采用并行电压分布设计，结合了高力PZT堆栈和软聚合物致动器的优势。通过调整层厚和层数，验证了其性能与第一性原理模型的一致性。

Result: 致动器实现了>3毫米的自由偏转、>20毫牛的阻塞力和≥500赫兹的频率响应，工作电压低至150伏。成功集成到平面移动微机器人中，展示了鲁棒性 locomotion。

Conclusion: 多层PVDF致动器在软微机器人系统中展现出高性能潜力，通过优化层厚和层数，实现了毫米级的自由偏转、毫牛级的阻塞力和高频率响应，且工作电压低至150伏。这些致动器成功集成到平面移动微机器人中，展示了其在机器人应用中的实际价值。

Abstract: Multilayer piezoelectric polyvinylidene fluoride (PVDF) actuators are a promising approach to enhance performance of soft microrobotic systems. In this work, we develop and characterize multilayer PVDF actuators with parallel voltage distribution across each layer, bridging a unique design space between brittle high-force PZT stacks and compliant but lower-bandwidth soft polymer actuators. We show the effects of layer thickness and number of layers in actuator performance and their agreement with a first principles model. By varying these parameters, we demonstrate actuators capable of >3 mm of free deflection, >20 mN of blocked force, and >=500 Hz, while operating at voltages as low as 150 volts. To illustrate their potential for robotic integration, we integrate our actuators into a planar, translating microrobot that leverages resonance to achieve locomotion with robustness to large perturbations.

</details>


### [387] [Evaluating Model-Agnostic Meta-Learning on MetaWorld ML10 Benchmark: Fast Adaptation in Robotic Manipulation Tasks](https://arxiv.org/abs/2511.12383)
*Sanjar Atamuradov*

Main category: cs.RO

TL;DR: MAML-TRPO在机器人操作任务中展现单次适应潜力，但泛化能力有限，未来需优化任务感知适应。


<details>
  <summary>Details</summary>
Motivation: 研究元学习算法在真实机器人系统中快速适应新任务的能力，尤其是在数据稀缺情况下的表现。

Method: 结合模型无关元学习（MAML）与信任域策略优化（TRPO），在MetaWorld ML10基准测试中评估其在10种不同机器人操作任务中的表现。

Result: MAML实现了单次梯度更新的有效适应，训练任务最终成功率为21.0%，测试任务为13.2%，但存在泛化差距，不同操作技能的适应效果差异显著（0%-80%）。

Conclusion: 研究发现基于梯度的元学习在多样机器人操作任务中具有潜力，但也存在当前局限，未来工作可关注任务感知适应和结构化策略架构。

Abstract: Meta-learning algorithms enable rapid adaptation to new tasks with minimal data, a critical capability for real-world robotic systems. This paper evaluates Model-Agnostic Meta-Learning (MAML) combined with Trust Region Policy Optimization (TRPO) on the MetaWorld ML10 benchmark, a challenging suite of ten diverse robotic manipulation tasks. We implement and analyze MAML-TRPO's ability to learn a universal initialization that facilitates few-shot adaptation across semantically different manipulation behaviors including pushing, picking, and drawer manipulation. Our experiments demonstrate that MAML achieves effective one-shot adaptation with clear performance improvements after a single gradient update, reaching final success rates of 21.0% on training tasks and 13.2% on held-out test tasks. However, we observe a generalization gap that emerges during meta-training, where performance on test tasks plateaus while training task performance continues to improve. Task-level analysis reveals high variance in adaptation effectiveness, with success rates ranging from 0% to 80% across different manipulation skills. These findings highlight both the promise and current limitations of gradient-based meta-learning for diverse robotic manipulation, and suggest directions for future work in task-aware adaptation and structured policy architectures.

</details>


### [388] [Learning Adaptive Neural Teleoperation for Humanoid Robots: From Inverse Kinematics to End-to-End Control](https://arxiv.org/abs/2511.12390)
*Sanjar Atamuradov*

Main category: cs.RO

TL;DR: 提出了一种基于学习的神经遥控框架，取代传统的IK+PD流程，显著提升了人形机器人遥控的自然性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统遥控系统依赖逆向运动学（IK）求解器和手动调整的PD控制器，难以处理外力、适应不同用户或在动态条件下产生自然运动。

Method: 采用基于学习的方法，通过强化学习训练策略，直接映射VR控制器输入到机器人关节命令。

Result: 实验结果表明，学习策略在跟踪误差上降低了34%，运动平滑度提高了45%，且在实时性能（50Hz控制频率）下表现出卓越的力适应能力。

Conclusion: 学习基于神经的遥控框架显著提升了人形机器人遥控系统的自然性和鲁棒性。

Abstract: Virtual reality (VR) teleoperation has emerged as a promising approach for controlling humanoid robots in complex manipulation tasks. However, traditional teleoperation systems rely on inverse kinematics (IK) solvers and hand-tuned PD controllers, which struggle to handle external forces, adapt to different users, and produce natural motions under dynamic conditions. In this work, we propose a learning-based neural teleoperation framework that replaces the conventional IK+PD pipeline with learned policies trained via reinforcement learning. Our approach learns to directly map VR controller inputs to robot joint commands while implicitly handling force disturbances, producing smooth trajectories, and adapting to user preferences. We train our policies in simulation using demonstrations collected from IK-based teleoperation as initialization, then fine-tune them with force randomization and trajectory smoothness rewards. Experiments on the Unitree G1 humanoid robot demonstrate that our learned policies achieve 34% lower tracking error, 45% smoother motions, and superior force adaptation compared to the IK baseline, while maintaining real-time performance (50Hz control frequency). We validate our approach on manipulation tasks including object pick-and-place, door opening, and bimanual coordination. These results suggest that learning-based approaches can significantly improve the naturalness and robustness of humanoid teleoperation systems.

</details>


### [389] [RoboAfford++: A Generative AI-Enhanced Dataset for Multimodal Affordance Learning in Robotic Manipulation and Navigation](https://arxiv.org/abs/2511.12436)
*Xiaoshuai Hao,Yingbo Tang,Lingfeng Zhang,Yanbiao Ma,Yunfeng Diao,Ziyu Jia,Wenbo Ding,Hangjun Ye,Long Chen*

Main category: cs.RO

TL;DR: RoboAfford++ dataset enhances VLMs' affordance reasoning for robotic tasks, addressing limitations in fine-grained interaction inference.


<details>
  <summary>Details</summary>
Motivation: VLMs struggle with fine-grained affordance inference due to lack of detailed annotations in training data, limiting actionable positions for physical interaction.

Method: The paper introduces RoboAfford++, a generative AI-enhanced dataset with 869,987 images and 2.0 million QA annotations, and RoboAfford-Eval, a benchmark with 338 annotated samples.

Result: Experiments show existing VLMs' deficiencies in affordance learning, but fine-tuning on RoboAfford++ improves their reasoning capabilities.

Conclusion: Fine-tuning on the RoboAfford++ dataset significantly enhances VLMs' ability to reason about object and spatial affordances, validating the dataset's effectiveness.

Abstract: Robotic manipulation and navigation are fundamental capabilities of embodied intelligence, enabling effective robot interactions with the physical world. Achieving these capabilities requires a cohesive understanding of the environment, including object recognition to localize target objects, object affordances to identify potential interaction areas and spatial affordances to discern optimal areas for both object placement and robot movement. While Vision-Language Models (VLMs) excel at high-level task planning and scene understanding, they often struggle to infer actionable positions for physical interaction, such as functional grasping points and permissible placement regions. This limitation stems from the lack of fine-grained annotations for object and spatial affordances in their training datasets. To tackle this challenge, we introduce RoboAfford++, a generative AI-enhanced dataset for multimodal affordance learning for both robotic manipulation and navigation. Our dataset comprises 869,987 images paired with 2.0 million question answering (QA) annotations, covering three critical tasks: object affordance recognition to identify target objects based on attributes and spatial relationships, object affordance prediction to pinpoint functional parts for manipulation, and spatial affordance localization to identify free space for object placement and robot navigation. Complementing this dataset, we propose RoboAfford-Eval, a comprehensive benchmark for assessing affordance-aware prediction in real-world scenarios, featuring 338 meticulously annotated samples across the same three tasks. Extensive experimental results reveal the deficiencies of existing VLMs in affordance learning, while fine-tuning on the RoboAfford++ dataset significantly enhances their ability to reason about object and spatial affordances, validating the dataset's effectiveness.

</details>


### [390] [ClutterNav: Gradient-Guided Search for Efficient 3D Clutter Removal with Learned Costmaps](https://arxiv.org/abs/2511.12479)
*Navin Sriram Ravie,Keerthi Vasan M,Bijo Sebastian*

Main category: cs.RO

TL;DR: ClutterNav 通过强化学习动态优化杂物移除序列，减少堆栈扰动，实现高效目标检索。


<details>
  <summary>Details</summary>
Motivation: 密集杂物中目标物体检索存在计算开销大、泛化性差的问题，传统方法依赖刚性启发式或缺乏可解释性。

Method: ClutterNav 将问题建模为连续强化学习任务，结合可移除性评估器和积分梯度，动态平衡即时移除与长期目标暴露。

Result: 实验验证表明，ClutterNav 在部分可观测环境中实现了实时、遮挡感知的决策，接近人类策略。

Conclusion: ClutterNav 提出了一种新颖的决策框架，通过连续强化学习动态优化目标物体访问策略，显著减少了堆栈扰动和计算开销。

Abstract: Dense clutter removal for target object retrieval presents a challenging problem, especially when targets are embedded deep within densely-packed configurations. It requires foresight to minimize overall changes to the clutter configuration while accessing target objects, avoiding stack destabilization and reducing the number of object removals required. Rule-based planners when applied to this problem, rely on rigid heuristics, leading to high computational overhead. End-to-end reinforcement learning approaches struggle with interpretability and generalizability over different conditions. To address these issues, we present ClutterNav, a novel decision-making framework that can identify the next best object to be removed so as to access a target object in a given clutter, while minimising stack disturbances. ClutterNav formulates the problem as a continuous reinforcement learning task, where each object removal dynamically updates the understanding of the scene. A removability critic, trained from demonstrations, estimates the cost of removing any given object based on geometric and spatial features. This learned cost is complemented by integrated gradients that assess how the presence or removal of surrounding objects influences the accessibility of the target. By dynamically prioritizing actions that balance immediate removability against long-term target exposure, ClutterNav achieves near human-like strategic sequencing, without predefined heuristics. The proposed approach is validated extensively in simulation and over real-world experiments. The results demonstrate real-time, occlusion-aware decision-making in partially observable environments.

</details>


### [391] [Botany Meets Robotics in Alpine Scree Monitoring](https://arxiv.org/abs/2511.12526)
*Davide De Benedittis,Giovanni Di Lorenzo,Franco Angelini,Barbara Valle,Marina Serena Borgatti,Paolo Remagnino,Marco Caccianiga,Manolo Garabini*

Main category: cs.RO

TL;DR: 利用腿式机器人和深度学习改进碎石栖息地监测，提高效率并减少资源消耗。


<details>
  <summary>Details</summary>
Motivation: 碎石栖息地因其高海拔特性面临气候变化威胁，传统监测方法资源密集且耗时，亟需创新解决方案。

Method: 在意大利阿尔卑斯生物区进行了为期两年的实地调查，部署了ANYmal C腿式机器人，并利用深度学习技术对关键植物物种进行检测和分类。

Result: 腿式机器人能够有效应对复杂地形，提高监测频率和效率，与植物社会学调查相结合，优化了数据采集、存储和使用流程。

Conclusion: 本研究通过结合敏捷腿式机器人和深度学习技术，为碎石栖息地监测提供了一种高效、可持续的新方法，推动了环境科学中机器人应用的进步。

Abstract: According to the European Union's Habitat Directive, habitat monitoring plays a critical role in response to the escalating problems posed by biodiversity loss and environmental degradation. Scree habitats, hosting unique and often endangered species, face severe threats from climate change due to their high-altitude nature. Traditionally, their monitoring has required highly skilled scientists to conduct extensive fieldwork in remote, potentially hazardous locations, making the process resource-intensive and time-consuming. This paper presents a novel approach for scree habitat monitoring using a legged robot to assist botanists in data collection and species identification. Specifically, we deployed the ANYmal C robot in the Italian Alpine bio-region in two field campaigns spanning two years and leveraged deep learning to detect and classify key plant species of interest. Our results demonstrate that agile legged robots can navigate challenging terrains and increase the frequency and efficiency of scree monitoring. When paired with traditional phytosociological surveys performed by botanists, this robotics-assisted protocol not only streamlines field operations but also enhances data acquisition, storage, and usage. The outcomes of this research contribute to the evolving landscape of robotics in environmental science, paving the way for a more comprehensive and sustainable approach to habitat monitoring and preservation.

</details>


### [392] [EcoFlight: Finding Low-Energy Paths Through Obstacles for Autonomous Sensing Drones](https://arxiv.org/abs/2511.12618)
*Jordan Leyva,Nahim J. Moran Vera,Yihan Xu,Adrien Durasno,Christopher U. Romero,Tendai Chimuka,Gabriel O. Huezo Ramirez,Ziqian Dong,Roberto Rojas-Cessa*

Main category: cs.RO

TL;DR: EcoFlight是无人机节能路径规划算法，通过推进系统建模优化能耗，仿真显示其在高密度障碍物环境中节能效果显著。


<details>
  <summary>Details</summary>
Motivation: 现有飞行路径规划方案较少考虑障碍物避障，且避障过程能耗高，影响无人机点对点飞行效率。

Method: 提出EcoFlight算法，基于无人机推进系统和飞行动力学建模能耗，并与直接飞行和最短距离方案进行对比评估。

Result: 仿真结果表明，EcoFlight在不同障碍物密度下均能找到能耗更低的路径，高密度环境下优势更明显，且适当飞行速度可进一步提升节能效果。

Conclusion: EcoFlight算法在三维空间中有效规划无人机避障路径，显著降低能耗，尤其在障碍物高密度环境中表现优异。

Abstract: Obstacle avoidance path planning for uncrewed aerial vehicles (UAVs), or drones, is rarely addressed in most flight path planning schemes, despite obstacles being a realistic condition. Obstacle avoidance can also be energy-intensive, making it a critical factor in efficient point-to-point drone flights. To address these gaps, we propose EcoFlight, an energy-efficient pathfinding algorithm that determines the lowest-energy route in 3D space with obstacles. The algorithm models energy consumption based on the drone propulsion system and flight dynamics. We conduct extensive evaluations, comparing EcoFlight with direct-flight and shortest-distance schemes. The simulation results across various obstacle densities show that EcoFlight consistently finds paths with lower energy consumption than comparable algorithms, particularly in high-density environments. We also demonstrate that a suitable flying speed can further enhance energy savings.

</details>


### [393] [Task-Aware Morphology Optimization of Planar Manipulators via Reinforcement Learning](https://arxiv.org/abs/2511.12650)
*Arvind Kumar Mishra,Sohom Chakrabarty*

Main category: cs.RO

TL;DR: RL能有效解决机器人形态优化问题，即使在没有解析解的情况下。


<details>
  <summary>Details</summary>
Motivation: 探索强化学习作为一种可扩展的替代方案，解决形态设计中缺乏封闭解和高维搜索成本的问题。

Method: 使用Yoshikawa的可操作性指数，通过三种RL算法（SAC、DDPG和PPO）与网格搜索和黑盒优化器进行比较，验证RL在形态优化中的有效性。

Result: 所有方法均收敛于解析解，表明无需提供解析结构即可数值恢复最优解。RL在非解析设置中仍能可靠收敛，而网格和黑盒方法需要更大的评估预算。

Conclusion: 强化学习（RL）不仅能够重现已知的形态优化解析解，还能在没有解析解的情况下有效解决形态优化问题。

Abstract: In this work, Yoshikawa's manipulability index is used to investigate reinforcement learning (RL) as a framework for morphology optimization in planar robotic manipulators. A 2R manipulator tracking a circular end-effector path is first examined because this case has a known analytical optimum: equal link lengths and the second joint orthogonal to the first. This serves as a validation step to test whether RL can rediscover the optimum using reward feedback alone, without access to the manipulability expression or the Jacobian. Three RL algorithms (SAC, DDPG, and PPO) are compared with grid search and black-box optimizers, with morphology represented by a single action parameter phi that maps to the link lengths. All methods converge to the analytical solution, showing that numerical recovery of the optimum is possible without supplying analytical structure.
  Most morphology design tasks have no closed-form solutions, and grid or heuristic search becomes expensive as dimensionality increases. RL is therefore explored as a scalable alternative. The formulation used for the circular path is extended to elliptical and rectangular paths by expanding the action space to the full morphology vector (L1, L2, theta2). In these non-analytical settings, RL continues to converge reliably, whereas grid and black-box methods require far larger evaluation budgets. These results indicate that RL is effective for both recovering known optima and solving morphology optimization problems without analytical solutions.

</details>


### [394] [Prompt-Driven Domain Adaptation for End-to-End Autonomous Driving via In-Context RL](https://arxiv.org/abs/2511.12755)
*Aleesha Khurram,Amir Moeini,Shangtong Zhang,Rohan Chandra*

Main category: cs.RO

TL;DR: 本文提出基于上下文强化学习（ICRL）的少样本提示驱动领域适应方法，用于恶劣天气下的闭环自动驾驶，实验显示其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前端到端自动驾驶系统在领域适应（DA）方面存在挑战，尤其是在恶劣天气条件下的策略迁移。现有方法如额外数据收集或模型重训练在大规模应用中不切实际。

Method: 采用上下文强化学习（ICRL）进行推理时少样本提示驱动的DA，无需模型参数更新或额外数据收集。

Result: 实验表明，ICRL在CARLA模拟器中优于现有提示驱动DA方法，显著提升驾驶策略性能。

Conclusion: ICRL方法在恶劣天气条件下实现了更安全、高效和舒适的驾驶策略，优于现有基于提示的DA基线。

Abstract: Despite significant progress and advances in autonomous driving, many end-to-end systems still struggle with domain adaptation (DA), such as transferring a policy trained under clear weather to adverse weather conditions. Typical DA strategies in the literature include collecting additional data in the target domain or re-training the model, or both. Both these strategies quickly become impractical as we increase scale and complexity of driving. These limitations have encouraged investigation into few-shot and zero-shot prompt-driven DA at inference time involving LLMs and VLMs. These methods work by adding a few state-action trajectories during inference to the prompt (similar to in-context learning). However, there are two limitations of such an approach: $(i)$ prompt-driven DA methods are currently restricted to perception tasks such as detection and segmentation and $(ii)$ they require expert few-shot data. In this work, we present a new approach to inference-time few-shot prompt-driven DA for closed-loop autonomous driving in adverse weather condition using in-context reinforcement learning (ICRL). Similar to other prompt-driven DA methods, our approach does not require any updates to the model parameters nor does it require additional data collection in adversarial weather regime. Furthermore, our approach advances the state-of-the-art in prompt-driven DA by extending to closed driving using general trajectories observed during inference. Our experiments using the CARLA simulator show that ICRL results in safer, more efficient, and more comfortable driving policies in the target domain compared to state-of-the-art prompt-driven DA baselines.

</details>


### [395] [DR. Nav: Semantic-Geometric Representations for Proactive Dead-End Recovery and Navigation](https://arxiv.org/abs/2511.12778)
*Vignesh Rajagopal,Kasun Weerakoon Kulathun Mudiyanselage,Gershom Devake Seneviratne,Pon Aswin Sankaralingam,Mohamed Elnoor,Jing Liang,Rohan Chandra,Dinesh Manocha*

Main category: cs.RO

TL;DR: DR. Nav是一种自主导航新方法，通过实时语义成本地图和恢复感知策略，显著提升非结构化环境中的导航效率与安全性。


<details>
  <summary>Details</summary>
Motivation: 针对非结构化环境中死胡同检测与恢复的关键需求，尤其是在无地图或未知环境下，传统方法仅考虑可通行性而忽略恢复策略的局限性。

Method: DR. Nav采用跨模态RGB-LiDAR融合与基于注意力的过滤技术，结合贝叶斯推理实时更新语义成本地图，明确纳入恢复感知风险。

Result: 实验表明，DR. Nav在检测准确率上提升83.33%，路径效率（目标达成时间）减少52.4%，优于DWA、MPPI等现有规划器。

Conclusion: DR. Nav通过整合死胡同预测与恢复策略，显著提升了自主导航在非结构化环境中的表现，特别是在路径效率和安全性方面优于现有先进规划器。

Abstract: We present DR. Nav (Dead-End Recovery-aware Navigation), a novel approach to autonomous navigation in scenarios where dead-end detection and recovery are critical, particularly in unstructured environments where robots must handle corners, vegetation occlusions, and blocked junctions. DR. Nav introduces a proactive strategy for navigation in unmapped environments without prior assumptions. Our method unifies dead-end prediction and recovery by generating a single, continuous, real-time semantic cost map. Specifically, DR. Nav leverages cross-modal RGB-LiDAR fusion with attention-based filtering to estimate per-cell dead-end likelihoods and recovery points, which are continuously updated through Bayesian inference to enhance robustness. Unlike prior mapping methods that only encode traversability, DR. Nav explicitly incorporates recovery-aware risk into the navigation cost map, enabling robots to anticipate unsafe regions and plan safer alternative trajectories. We evaluate DR. Nav across multiple dense indoor and outdoor scenarios and demonstrate an increase of 83.33% in accuracy in detection, a 52.4% reduction in time-to-goal (path efficiency), compared to state-of-the-art planners such as DWA, MPPI, and Nav2 DWB. Furthermore, the dead-end classifier functions

</details>


### [396] [ActiveGrasp: Information-Guided Active Grasping with Calibrated Energy-based Model](https://arxiv.org/abs/2511.12795)
*Boshu Lei,Wen Jiang,Kostas Daniilidis*

Main category: cs.RO

TL;DR: 论文提出了一种基于能量的校准模型和主动视图选择方法，显著提升了机器人在密集杂乱环境中的抓取能力。


<details>
  <summary>Details</summary>
Motivation: 解决先前方法在密集杂乱环境中抓取时忽视抓取分布重要性或忽略SE(3)流形结构的问题。

Method: 提出了一种基于能量的校准模型用于抓取姿态生成，以及一种估计抓取分布信息增益的主动视图选择方法。

Result: 在模拟环境和真实机器人实验中，模型在有限视图预算下成功抓取物体，表现优于现有技术。

Conclusion: 该论文提出的基于能量的校准模型和主动视图选择方法在密集杂乱环境中表现出色，优于现有技术，并提供了可复现的模拟环境平台。

Abstract: Grasping in a densely cluttered environment is a challenging task for robots. Previous methods tried to solve this problem by actively gathering multiple views before grasp pose generation. However, they either overlooked the importance of the grasp distribution for information gain estimation or relied on the projection of the grasp distribution, which ignores the structure of grasp poses on the SE(3) manifold. To tackle these challenges, we propose a calibrated energy-based model for grasp pose generation and an active view selection method that estimates information gain from grasp distribution. Our energy-based model captures the multi-modality nature of grasp distribution on the SE(3) manifold. The energy level is calibrated to the success rate of grasps so that the predicted distribution aligns with the real distribution. The next best view is selected by estimating the information gain for grasp from the calibrated distribution conditioned on the reconstructed environment, which could efficiently drive the robot to explore affordable parts of the target object. Experiments on simulated environments and real robot setups demonstrate that our model could successfully grasp objects in a cluttered environment with limited view budgets compared to previous state-of-the-art models. Our simulated environment can serve as a reproducible platform for future research on active grasping. The source code of our paper will be made public when the paper is released to the public.

</details>


### [397] [Structured Imitation Learning of Interactive Policies through Inverse Games](https://arxiv.org/abs/2511.12848)
*Max M. Sun,Todd Murphey*

Main category: cs.RO

TL;DR: 提出结构化模仿学习框架，结合生成模型与博弈论，分两步学习个体行为与交互依赖，在5智能体任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决在无显式通信的共享空间中协调人类交互策略的模仿学习挑战，因多智能体交互行为复杂度显著高于非交互任务。

Method: 结合生成式单智能体策略学习与博弈论结构，将学习过程分为两步：首先通过标准模仿学习从多智能体演示中学习个体行为模式，然后通过解决逆博弈问题结构化学习智能体间依赖关系。

Result: 在合成的5智能体社交导航任务中，该方法显著优于非交互策略，且仅需50次演示即与真实交互策略表现相当。

Conclusion: 结构化模仿学习框架在交互式策略学习中表现出潜力，尤其在多智能体社交导航任务中，仅需50次演示即可显著提升非交互策略的性能，并与真实交互策略表现相当。

Abstract: Generative model-based imitation learning methods have recently achieved strong results in learning high-complexity motor skills from human demonstrations. However, imitation learning of interactive policies that coordinate with humans in shared spaces without explicit communication remains challenging, due to the significantly higher behavioral complexity in multi-agent interactions compared to non-interactive tasks. In this work, we introduce a structured imitation learning framework for interactive policies by combining generative single-agent policy learning with a flexible yet expressive game-theoretic structure. Our method explicitly separates learning into two steps: first, we learn individual behavioral patterns from multi-agent demonstrations using standard imitation learning; then, we structurally learn inter-agent dependencies by solving an inverse game problem. Preliminary results in a synthetic 5-agent social navigation task show that our method significantly improves non-interactive policies and performs comparably to the ground truth interactive policy using only 50 demonstrations. These results highlight the potential of structured imitation learning in interactive settings.

</details>


### [398] [Towards High-Consistency Embodied World Model with Multi-View Trajectory Videos](https://arxiv.org/abs/2511.12882)
*Taiyi Su,Jian Zhu,Yaxuan Li,Chong Ma,Zitai Huang,Yichen Zhu,Hanli Wang,Yi Xu*

Main category: cs.RO

TL;DR: MTV-World通过多视角轨迹视频控制提升机器人运动的精确性，解决了现有模型在物理交互中的不一致问题。


<details>
  <summary>Details</summary>
Motivation: 现有模型难以将低级动作（如关节位置）准确转化为预测帧中的机器人运动，导致与真实物理交互不一致。

Method: 提出MTV-World模型，利用多视角轨迹视频作为控制信号，通过相机内外参数和笛卡尔空间变换生成轨迹视频，并引入多视角框架补偿空间信息损失。

Result: 实验表明，MTV-World在复杂双臂场景中实现了高一致性的物理交互和精确控制。

Conclusion: MTV-World通过多视角轨迹视频控制和自动评估流程，在复杂双臂场景中实现了精确的控制执行和物理交互建模。

Abstract: Embodied world models aim to predict and interact with the physical world through visual observations and actions. However, existing models struggle to accurately translate low-level actions (e.g., joint positions) into precise robotic movements in predicted frames, leading to inconsistencies with real-world physical interactions. To address these limitations, we propose MTV-World, an embodied world model that introduces Multi-view Trajectory-Video control for precise visuomotor prediction. Specifically, instead of directly using low-level actions for control, we employ trajectory videos obtained through camera intrinsic and extrinsic parameters and Cartesian-space transformation as control signals. However, projecting 3D raw actions onto 2D images inevitably causes a loss of spatial information, making a single view insufficient for accurate interaction modeling. To overcome this, we introduce a multi-view framework that compensates for spatial information loss and ensures high-consistency with physical world. MTV-World forecasts future frames based on multi-view trajectory videos as input and conditioning on an initial frame per view. Furthermore, to systematically evaluate both robotic motion precision and object interaction accuracy, we develop an auto-evaluation pipeline leveraging multimodal large models and referring video object segmentation models. To measure spatial consistency, we formulate it as an object location matching problem and adopt the Jaccard Index as the evaluation metric. Extensive experiments demonstrate that MTV-World achieves precise control execution and accurate physical interaction modeling in complex dual-arm scenarios.

</details>


### [399] [Air-Chamber Based Soft Six-Axis Force/Torque Sensor for Human-Robot Interaction](https://arxiv.org/abs/2511.12896)
*Jun Huo,Hongge Ru,Bo Yang,Xingjian Chen,Xi Li,Jian Huang*

Main category: cs.RO

TL;DR: 本文提出了一种软气室型六轴力/扭矩传感器，采用16通道气压计和刚性-软性分层结构解耦方法，实验证明其性能优越且保持柔软性。


<details>
  <summary>Details</summary>
Motivation: 开发一种既柔软又准确的六轴力/扭矩传感器，解决传统传感器因交叉轴耦合导致的校准问题和精度下降。

Method: 提出了一种基于刚性-软性分层结构的有效解耦方法，将六轴解耦问题简化为两个三轴解耦问题，并通过有限元模型仿真和实验验证了其可行性。

Result: 原型传感器的测量范围为50N力和1Nm扭矩，平均偏差、重复性、非线性和滞后分别为4.9%、2.7%、5.8%和6.7%。

Conclusion: 该原型通过软气室设计保持了柔软性，同时展现出令人满意的传感性能，包括静态和动态负载响应特性。

Abstract: Soft multi-axis force/torque sensors provide safe and precise force interaction. Capturing the complete degree-of-freedom of force is imperative for accurate force measurement with six-axis force/torque sensors. However, cross-axis coupling can lead to calibration issues and decreased accuracy. In this instance, developing a soft and accurate six-axis sensor is a challenging task. In this paper, a soft air-chamber type six-axis force/torque sensor with 16-channel barometers is introduced, which housed in hyper-elastic air chambers made of silicone rubber. Additionally, an effective decoupling method is proposed, based on a rigid-soft hierarchical structure, which reduces the six-axis decoupling problem to two three-axis decoupling problems. Finite element model simulation and experiments demonstrate the compatibility of the proposed approach with reality. The prototype's sensing performance is quantitatively measured in terms of static load response, dynamic load response and dynamic response characteristic. It possesses a measuring range of 50 N force and 1 Nm torque, and the average deviation, repeatability, non-linearity and hysteresis are 4.9$\%$, 2.7$\%$, 5.8$\%$ and 6.7$\%$, respectively. The results indicate that the prototype exhibits satisfactory sensing performance while maintaining its softness due to the presence of soft air chambers.

</details>


### [400] [TOPP-DWR: Time-Optimal Path Parameterization of Differential-Driven Wheeled Robots Considering Piecewise-Constant Angular Velocity Constraints](https://arxiv.org/abs/2511.12910)
*Yong Li,Yujun Huang,Yi Chen,Hui Cheng*

Main category: cs.RO

TL;DR: 提出TOPP-DWR算法，通过SOCP整合多种速度约束，实验验证其在时间最优路径参数化中的优越性和实用性。


<details>
  <summary>Details</summary>
Motivation: 现有研究常忽略角速度和关节速度约束，导致实际控制性能下降，因此需要一种系统且实用的TOPP算法。

Method: 采用非均匀B样条表示初始轨迹，引入松弛变量将问题重构为二阶锥规划（SOCP），并整合角速度、关节速度、线速度和线加速度约束。

Result: 实验表明TOPP-DWR在满足所有约束的同时实现了TOPP，并在实际自主导航中验证了其实用性。

Conclusion: TOPP-DWR算法在实际应用中验证了其有效性，能够满足所有约束条件并实现时间最优路径参数化。

Abstract: Differential-driven wheeled robots (DWR) represent the quintessential type of mobile robots and find extensive appli- cations across the robotic field. Most high-performance control approaches for DWR explicitly utilize the linear and angular velocities of the trajectory as control references. However, existing research on time-optimal path parameterization (TOPP) for mobile robots usually neglects the angular velocity and joint vel- ocity constraints, which can result in degraded control perfor- mance in practical applications. In this article, a systematic and practical TOPP algorithm named TOPP-DWR is proposed for DWR and other mobile robots. First, the non-uniform B-spline is adopted to represent the initial trajectory in the task space. Second, the piecewise-constant angular velocity, as well as joint velocity, linear velocity, and linear acceleration constraints, are incorporated into the TOPP problem. During the construction of the optimization problem, the aforementioned constraints are uniformly represented as linear velocity constraints. To boost the numerical computational efficiency, we introduce a slack variable to reformulate the problem into second-order-cone programming (SOCP). Subsequently, comparative experiments are conducted to validate the superiority of the proposed method. Quantitative performance indexes show that TOPP-DWR achieves TOPP while adhering to all constraints. Finally, field autonomous navigation experiments are carried out to validate the practicability of TOPP-DWR in real-world applications.

</details>


### [401] [DiffuDepGrasp: Diffusion-based Depth Noise Modeling Empowers Sim2Real Robotic Grasping](https://arxiv.org/abs/2511.12912)
*Yingting Zhou,Wenbo Cui,Weiheng Liu,Guixing Chen,Haoran Li,Dongbin Zhao*

Main category: cs.RO

TL;DR: DiffuDepGrasp 是一种高效 sim2real 框架，通过扩散模型生成逼真噪声深度图，实现零样本策略转移，显著提升抓取任务性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在数据低效和部署复杂性方面的不足，特别是在深度图传感器伪影导致的 sim2real 差距问题。

Method: DiffuDepGrasp 包含两个关键模块：Diffusion Depth Module 利用时间几何先验高效训练条件扩散模型以捕捉复杂传感器噪声分布；Noise Grafting Module 在注入感知伪影时保持度量准确性。

Result: DiffuDepGrasp 在零样本转移下实现了 95.7% 的平均成功率，并展示了对未见对象的强泛化能力。

Conclusion: DiffuDepGrasp 通过其创新的 Diffusion Depth Generator 实现了零样本策略转移，显著提高了抓取任务的成功率和泛化能力。

Abstract: Transferring the depth-based end-to-end policy trained in simulation to physical robots can yield an efficient and robust grasping policy, yet sensor artifacts in real depth maps like voids and noise establish a significant sim2real gap that critically impedes policy transfer. Training-time strategies like procedural noise injection or learned mappings suffer from data inefficiency due to unrealistic noise simulation, which is often ineffective for grasping tasks that require fine manipulation or dependency on paired datasets heavily. Furthermore, leveraging foundation models to reduce the sim2real gap via intermediate representations fails to mitigate the domain shift fully and adds computational overhead during deployment. This work confronts dual challenges of data inefficiency and deployment complexity. We propose DiffuDepGrasp, a deploy-efficient sim2real framework enabling zero-shot transfer through simulation-exclusive policy training. Its core innovation, the Diffusion Depth Generator, synthesizes geometrically pristine simulation depth with learned sensor-realistic noise via two synergistic modules. The first Diffusion Depth Module leverages temporal geometric priors to enable sample-efficient training of a conditional diffusion model that captures complex sensor noise distributions, while the second Noise Grafting Module preserves metric accuracy during perceptual artifact injection. With only raw depth inputs during deployment, DiffuDepGrasp eliminates computational overhead and achieves a 95.7% average success rate on 12-object grasping with zero-shot transfer and strong generalization to unseen objects.Project website: https://diffudepgrasp.github.io/.

</details>


### [402] [GUIDE: Gaussian Unified Instance Detection for Enhanced Obstacle Perception in Autonomous Driving](https://arxiv.org/abs/2511.12941)
*Chunyong Hu,Qi Luo,Jianyun Xu,Song Wang,Qiang Li,Sheng Yang*

Main category: cs.RO

TL;DR: GUIDE利用3D高斯实现实例检测和占用预测，性能优于传统方法，计算效率高。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖3D边界框表示障碍物，难以捕捉不规则形状的真实物体复杂性。

Method: 采用3D高斯和稀疏表示策略，通过高斯到体素的投影提供细粒度的实例级占用数据。

Result: 在nuScenes数据集上验证，GUIDE的实例占用mAP达到21.61，比现有方法提升50%，同时具备竞争力的跟踪能力。

Conclusion: GUIDE框架在自动驾驶感知系统中设立了新标杆，通过结合精度与计算效率，更好地应对现实驾驶环境的复杂性。

Abstract: In the realm of autonomous driving, accurately detecting surrounding obstacles is crucial for effective decision-making. Traditional methods primarily rely on 3D bounding boxes to represent these obstacles, which often fail to capture the complexity of irregularly shaped, real-world objects. To overcome these limitations, we present GUIDE, a novel framework that utilizes 3D Gaussians for instance detection and occupancy prediction. Unlike conventional occupancy prediction methods, GUIDE also offers robust tracking capabilities. Our framework employs a sparse representation strategy, using Gaussian-to-Voxel Splatting to provide fine-grained, instance-level occupancy data without the computational demands associated with dense voxel grids. Experimental validation on the nuScenes dataset demonstrates GUIDE's performance, with an instance occupancy mAP of 21.61, marking a 50\% improvement over existing methods, alongside competitive tracking capabilities. GUIDE establishes a new benchmark in autonomous perception systems, effectively combining precision with computational efficiency to better address the complexities of real-world driving environments.

</details>


### [403] [SplatSearch: Instance Image Goal Navigation for Mobile Robots using 3D Gaussian Splatting and Diffusion Models](https://arxiv.org/abs/2511.12972)
*Siddarth Narasimhan,Matthew Lisondra,Haitong Wang,Goldie Nejat*

Main category: cs.RO

TL;DR: SplatSearch通过3D高斯溅射和多视角扩散模型提升稀疏视图下的目标导航性能，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决实例图像目标导航（IIN）问题，特别是在参考图像视角任意且机器人需在稀疏视图场景重建下操作的挑战。

Method: 引入SplatSearch架构，利用稀疏在线3D高斯溅射（3DGS）重建和多视角扩散模型补全缺失区域，结合新颖的前沿探索策略。

Result: 在真实感家庭和现实环境中的广泛实验验证了SplatSearch在成功率和成功路径长度上的优越性。

Conclusion: SplatSearch在未知环境中通过稀疏视图3D高斯溅射重建和前沿探索策略，显著提高了实例图像目标导航的成功率和路径效率。

Abstract: The Instance Image Goal Navigation (IIN) problem requires mobile robots deployed in unknown environments to search for specific objects or people of interest using only a single reference goal image of the target. This problem can be especially challenging when: 1) the reference image is captured from an arbitrary viewpoint, and 2) the robot must operate with sparse-view scene reconstructions. In this paper, we address the IIN problem, by introducing SplatSearch, a novel architecture that leverages sparse-view 3D Gaussian Splatting (3DGS) reconstructions. SplatSearch renders multiple viewpoints around candidate objects using a sparse online 3DGS map, and uses a multi-view diffusion model to complete missing regions of the rendered images, enabling robust feature matching against the goal image. A novel frontier exploration policy is introduced which uses visual context from the synthesized viewpoints with semantic context from the goal image to evaluate frontier locations, allowing the robot to prioritize frontiers that are semantically and visually relevant to the goal image. Extensive experiments in photorealistic home and real-world environments validate the higher performance of SplatSearch against current state-of-the-art methods in terms of Success Rate and Success Path Length. An ablation study confirms the design choices of SplatSearch.

</details>


### [404] [CUTE-Planner: Confidence-aware Uneven Terrain Exploration Planner](https://arxiv.org/abs/2511.12984)
*Miryeong Park,Dongjin Cho,Sanghyun Kim,Younggun Cho*

Main category: cs.RO

TL;DR: 论文提出了一种结合安全路径、自适应置信度更新和探索策略的框架，显著提升行星机器人在复杂地形中的导航安全性和地图可靠性，实验显示不确定性降低69%，任务成功率100%。


<details>
  <summary>Details</summary>
Motivation: 现有方法在处理复杂地形（如陨石坑）时的高程估计不确定性不足，缺乏探索策略以减少不确定性，且未充分考虑高程不确定性对导航安全和地图质量的影响。

Method: 采用基于卡尔曼滤波的高程估计方法，生成地形可穿越性和置信度评分，并将其融入基于图的探索规划器（GBP）中，优先探索可穿越但置信度低的区域。

Result: 在模拟月球实验中，使用新的低置信度区域比率指标，实现了69%的不确定性降低；任务成功率从基线GBP的0%提升至100%。

Conclusion: 该论文提出的框架通过整合安全路径生成、自适应置信度更新和置信度感知探索策略，显著提升了行星探索机器人在复杂地形中的导航安全性和地图可靠性。

Abstract: Planetary exploration robots must navigate uneven terrain while building reliable maps for space missions. However, most existing methods incorporate traversability constraints but may not handle high uncertainty in elevation estimates near complex features like craters, do not consider exploration strategies for uncertainty reduction, and typically fail to address how elevation uncertainty affects navigation safety and map quality. To address the problems, we propose a framework integrating safe path generation, adaptive confidence updates, and confidence-aware exploration strategies. Using Kalman-based elevation estimation, our approach generates terrain traversability and confidence scores, then incorporates them into Graph-Based exploration Planner (GBP) to prioritize exploration of traversable low-confidence regions. We evaluate our framework through simulated lunar experiments using a novel low-confidence region ratio metric, achieving 69% uncertainty reduction compared to baseline GBP. In terms of mission success rate, our method achieves 100% while baseline GBP achieves 0%, demonstrating improvements in exploration safety and map reliability.

</details>


### [405] [APP: A* Post-Processing Algorithm for Robots with Bidirectional Shortcut and Path Perturbation](https://arxiv.org/abs/2511.13042)
*Yong Li,Hui Cheng*

Main category: cs.RO

TL;DR: APP是一种针对A*算法的后处理算法，通过双向顶点缩减和迭代路径扰动优化路径，减少不必要的航向变化，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决A*等基于图搜索的规划器生成的路径通常不是最短且存在不必要的航向变化（锯齿模式）的问题，尤其是在无障碍物时应为直线路径。

Method: 提出了一种基于成本图的A*后处理算法（APP），包括双向顶点缩减算法和迭代路径扰动算法，以减少不必要的航向变化并提高路径平滑度。

Result: APP在规划时间、路径长度和航向变化次数上表现优于现有方法。

Conclusion: APP算法在规划时间、路径长度以及不必要的航向变化次数上优于现有方法，并通过实地导航实验验证了其实用性。

Abstract: Paths generated by A* and other graph-search-based planners are widely used in the robotic field. Due to the restricted node-expansion directions, the resulting paths are usually not the shortest. Besides, unnecessary heading changes, or zig-zag patterns, exist even when no obstacle is nearby, which is inconsistent with the human intuition that the path segments should be straight in wide-open space due to the absence of obstacles. This article puts forward a general and systematic post-processing algorithm for A* and other graph-search-based planners. The A* post-processing algorithm, called APP, is developed based on the costmap, which is widely used in commercial service robots. First, a bidirectional vertices reduction algorithm is proposed to tackle the asymm- etry of the path and the environments. During the forward and backward vertices reduction, a thorough shortcut strategy is put forward to improve the path-shortening performance and avoid unnecessary heading changes. Second, an iterative path perturbation algorithm is adopted to locally reduce the number of unnecessary heading changes and improve the path smooth- ness. Comparative experiments are then carried out to validate the superiority of the proposed method. Quantitative performance indexes show that APP outperforms the existing methods in planning time, path length as well as the number of unnecessary heading changes. Finally, field navigation experiments are carried out to verify the practicability of APP.

</details>


### [406] [Unidirectional-Road-Network-Based Global Path Planning for Cleaning Robots in Semi-Structured Environments](https://arxiv.org/abs/2511.13048)
*Yong Li,Hui Cheng*

Main category: cs.RO

TL;DR: 论文提出了一种半结构化环境下的全局路径规划方法，通过混合策略和双层势图优化路径长度与交通规则一致性，实验验证其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有全局路径规划方法在自由空间中忽视交通规则约束导致高频重规划，而在结构化环境中严格遵循道路网络可能导致路径过长，影响导航效率。

Method: 构建单向道路网络表示交通约束，提出混合策略及双层势图，以在复杂交叉口确保性能。

Result: 定量实验结果表明，相比现有技术，该方法在路径长度与道路网络一致性之间实现了更好的平衡。

Conclusion: 该论文提出了一种在半结构化环境中改进全局路径规划性能的通用系统方法，通过构建单向道路网络表示交通约束，并采用混合策略确保规划结果。实验验证了该方法在路径长度与道路网络一致性之间的平衡优于现有方法。

Abstract: Practical global path planning is critical for commercializing cleaning robots working in semi-structured environments. In the literature, global path planning methods for free space usually focus on path length and neglect the traffic rule constraints of the environments, which leads to high-frequency re-planning and increases collision risks. In contrast, those for structured environments are developed mainly by strictly complying with the road network representing the traffic rule constraints, which may result in an overlong path that hinders the overall navigation efficiency. This article proposes a general and systematic approach to improve global path planning performance in semi-structured environments. A unidirectional road network is built to represent the traffic constraints in semi-structured environments and a hybrid strategy is proposed to achieve a guaranteed planning result.Cutting across the road at the starting and the goal points are allowed to achieve a shorter path. Especially, a two-layer potential map is proposed to achieve a guaranteed performance when the starting and the goal points are in complex intersections. Comparative experiments are carried out to validate the effectiveness of the proposed method. Quantitative experimental results show that, compared with the state-of-art, the proposed method guarantees a much better balance between path length and the consistency with the road network.

</details>


### [407] [Orientation-Free Neural Network-Based Bias Estimation for Low-Cost Stationary Accelerometers](https://arxiv.org/abs/2511.13071)
*Michal Levin,Itzik Klein*

Main category: cs.RO

TL;DR: 该论文提出了一种无需定向知识或旋转的模型无关校准方法，显著降低了加速度计偏差误差，适用于快速现场部署。


<details>
  <summary>Details</summary>
Motivation: 低成本微机电加速度计在导航、机器人和消费设备中广泛用于运动传感和位置估计，但其性能常受偏差误差影响。传统校准方法需要加速度计调平或复杂的定向依赖校准程序。

Method: 提出了一种模型无关的学习校准方法，用于在静止条件下估计加速度计偏差，无需传感器方向知识或旋转传感器。

Result: 在13.39小时的数据集上，六台加速度计的实验验证表明，该方法比传统技术的误差水平降低了52%以上。

Conclusion: 该论文提出了一种无需传感器方向知识且无需旋转传感器的模型无关学习校准方法，显著降低了传统技术的误差水平，提高了低成本惯性传感器的可靠性。

Abstract: Low-cost micro-electromechanical accelerometers are widely used in navigation, robotics, and consumer devices for motion sensing and position estimation. However, their performance is often degraded by bias errors. To eliminate deterministic bias terms a calibration procedure is applied under stationary conditions. It requires accelerom- eter leveling or complex orientation-dependent calibration procedures. To overcome those requirements, in this paper we present a model-free learning-based calibration method that estimates accelerometer bias under stationary conditions, without requiring knowledge of the sensor orientation and without the need to rotate the sensors. The proposed approach provides a fast, practical, and scalable solution suitable for rapid field deployment. Experimental validation on a 13.39-hour dataset collected from six accelerometers shows that the proposed method consistently achieves error levels more than 52% lower than traditional techniques. On a broader scale, this work contributes to the advancement of accurate calibration methods in orientation-free scenarios. As a consequence, it improves the reliability of low-cost inertial sensors in diverse scientific and industrial applications and eliminates the need for leveled calibration.

</details>


### [408] [ResAlignNet: A Data-Driven Approach for INS/DVL Alignment](https://arxiv.org/abs/2511.13096)
*Guy Damari,Itzik Klein*

Main category: cs.RO

TL;DR: ResAlignNet是一种基于深度学习的水下传感器对准方法，通过神经网络优化实现快速收敛，无需外部辅助或复杂运动模式。


<details>
  <summary>Details</summary>
Motivation: 传统基于模型的对准方法存在收敛时间长、依赖特定运动模式和外部辅助传感器等问题，限制了操作灵活性。

Method: 采用1D ResNet-18架构，将传感器对准问题转化为深度神经网络优化问题，支持Sim2Real转移学习。

Result: 实验证明，ResAlignNet仅需25秒数据收集即可实现0.8°以内的对准精度，收敛时间比标准方法减少65%。

Conclusion: ResAlignNet提出了一种基于深度学习的传感器对准方法，显著减少了收敛时间并提高了操作灵活性，为水下导航系统提供了更高效的解决方案。

Abstract: Autonomous underwater vehicles rely on precise navigation systems that combine the inertial navigation system and the Doppler velocity log for successful missions in challenging environments where satellite navigation is unavailable. The effectiveness of this integration critically depends on accurate alignment between the sensor reference frames. Standard model-based alignment methods between these sensor systems suffer from lengthy convergence times, dependence on prescribed motion patterns, and reliance on external aiding sensors, significantly limiting operational flexibility. To address these limitations, this paper presents ResAlignNet, a data-driven approach using the 1D ResNet-18 architecture that transforms the alignment problem into deep neural network optimization, operating as an in-situ solution that requires only sensors on board without external positioning aids or complex vehicle maneuvers, while achieving rapid convergence in seconds. Additionally, the approach demonstrates the learning capabilities of Sim2Real transfer, enabling training in synthetic data while deploying in operational sensor measurements. Experimental validation using the Snapir autonomous underwater vehicle demonstrates that ResAlignNet achieves alignment accuracy within 0.8° using only 25 seconds of data collection, representing a 65\% reduction in convergence time compared to standard velocity-based methods. The trajectory-independent solution eliminates motion pattern requirements and enables immediate vehicle deployment without lengthy pre-mission procedures, advancing underwater navigation capabilities through robust sensor-agnostic alignment that scales across different operational scenarios and sensor specifications.

</details>


### [409] [Count Every Rotation and Every Rotation Counts: Exploring Drone Dynamics via Propeller Sensing](https://arxiv.org/abs/2511.13100)
*Xuecheng Chen,Jingao Xu,Wenhua Ding,Haoyang Wang,Xinyu Luo,Ruiyang Duan,Jialong Chen,Xueqian Wang,Yunhao Liu,Xinlei Chen*

Main category: cs.RO

TL;DR: 本文提出\sysname系统，专注于螺旋桨转速测量以提升无人机传感性能。系统通过两个组件实现高精度实时转速估计和动态推断，在实际应用中表现出色。


<details>
  <summary>Details</summary>
Motivation: 随着无人机应用的普及，地面非接触式传感无人机变得至关重要。专注于螺旋桨转速的测量被认为能显著提高传感性能。

Method: \sysname系统包含两个核心组件：\textit{Count Every Rotation}用于实时准确估计螺旋桨转速，通过降低事件相机对环境噪声的超高敏感性；\textit{Every Rotation Counts}则利用这些转速推断无人机的内外动态。

Result: 在实际无人机配送场景中，\sysname系统的传感延迟仅为3ms，转速估计误差仅为0.23%。此外，系统推断无人机飞行命令的精度达96.5%，结合其他传感模态可将追踪精度提升22%以上。

Conclusion: 研究表明，通过专注于螺旋桨转速的测量，可以显著提升无人机传感性能。提出的\sysname系统在实时性和准确性方面表现优异，且在无人机追踪和命令推断方面具有高精度。

Abstract: As drone-based applications proliferate, paramount contactless sensing of airborne drones from the ground becomes indispensable. This work demonstrates concentrating on propeller rotational speed will substantially improve drone sensing performance and proposes an event-camera-based solution, \sysname. \sysname features two components: \textit{Count Every Rotation} achieves accurate, real-time propeller speed estimation by mitigating ultra-high sensitivity of event cameras to environmental noise. \textit{Every Rotation Counts} leverages these speeds to infer both internal and external drone dynamics. Extensive evaluations in real-world drone delivery scenarios show that \sysname achieves a sensing latency of 3$ms$ and a rotational speed estimation error of merely 0.23\%. Additionally, \sysname infers drone flight commands with 96.5\% precision and improves drone tracking accuracy by over 22\% when combined with other sensing modalities. \textit{ Demo: {\color{blue}https://eventpro25.github.io/EventPro/.} }

</details>


### [410] [Monolithic Units: Actuation, Sensing, and Simulation for Integrated Soft Robot Design](https://arxiv.org/abs/2511.13120)
*Trevor Exley,Anderson Brazil Nardin,Petr Trunin,Diana Cafiso,Lucia Beccai*

Main category: cs.RO

TL;DR: 本研究提出了一种名为MU的软机器人构建块，集成了气动执行器、柔性晶格外壳和光学波导传感。通过参数化设计和仿真优化，验证了其机械性能和传感能力，并展示了在缩放单元和夹持器中的应用。


<details>
  <summary>Details</summary>
Motivation: 为了解决软机器人中执行器、传感器和结构材料的集成问题，提出了一种名为MU的构建块，以促进整体设计。

Method: 采用参数化设计框架建立确定性规则，研究可重复性和可扩展性；通过实验均质化提供有效材料属性进行有限元模拟，并将传感器布置视为离散优化问题。

Result: 优化模型被制造并实验验证，验证了机械性能的保持同时实现了嵌入式传感。工作流进一步扩展到缩放单元和两指夹持器，展示了MU概念的通用性。

Conclusion: The MU概念通过结合可重复的协同设计规则与基于仿真的传感器集成，推进了整体软机器人设计。

Abstract: This work introduces the Monolithic Unit (MU), an actuator-lattice-sensor building block for soft robotics. The MU integrates pneumatic actuation, a compliant lattice envelope, and candidate sites for optical waveguide sensing into a single printed body. In order to study reproducibility and scalability, a parametric design framework establishes deterministic rules linking actuator chamber dimensions to lattice unit cell size. Experimental homogenization of lattice specimens provides effective material properties for finite element simulation. Within this simulation environment, sensor placement is treated as a discrete optimization problem, where a finite set of candidate waveguide paths derived from lattice nodes is evaluated by introducing local stiffening, and the configuration minimizing deviation from baseline mechanical response is selected. Optimized models are fabricated and experimentally characterized, validating the preservation of mechanical performance while enabling embedded sensing. The workflow is further extended to scaled units and a two-finger gripper, demonstrating generality of the MU concept. This approach advances monolithic soft robotic design by combining reproducible co-design rules with simulation-informed sensor integration.

</details>


### [411] [Collision-Free Navigation of Mobile Robots via Quadtree-Based Model Predictive Control](https://arxiv.org/abs/2511.13188)
*Osama Al Sheikh Ali,Sotiris Koutsoftas,Ze Zhang,Knut Akesson,Emmanuel Dean*

Main category: cs.RO

TL;DR: 该论文提出了一种集成导航框架，通过四叉树生成碰撞自由区域并结合MPC，实现了AMR在复杂环境中的高效可靠导航。


<details>
  <summary>Details</summary>
Motivation: 为解决自主移动机器人在复杂环境中导航时的高效性和可靠性问题，提出了一个统一的框架，避免直接编码障碍物。

Method: 采用基于四叉树的方法从占据图中生成结构化的、轴对齐的碰撞自由区域，并将其作为安全走廊的基础和MPC的线性约束。完整的流程包括安全区域提取、连接图构建、轨迹生成和B样条平滑。

Result: 实验结果表明，该方法在复杂环境中表现一致成功且优于基线方法。

Conclusion: 该论文提出的集成导航框架通过统一环境表示、轨迹生成和模型预测控制，实现了自主移动机器人的高效可靠导航。实验结果表明，该方法在复杂环境中表现优于基线方法。

Abstract: This paper presents an integrated navigation framework for Autonomous Mobile Robots (AMRs) that unifies environment representation, trajectory generation, and Model Predictive Control (MPC). The proposed approach incorporates a quadtree-based method to generate structured, axis-aligned collision-free regions from occupancy maps. These regions serve as both a basis for developing safe corridors and as linear constraints within the MPC formulation, enabling efficient and reliable navigation without requiring direct obstacle encoding. The complete pipeline combines safe-area extraction, connectivity graph construction, trajectory generation, and B-spline smoothing into one coherent system. Experimental results demonstrate consistent success and superior performance compared to baseline approaches across complex environments.

</details>


### [412] [PIGEON: VLM-Driven Object Navigation via Points of Interest Selection](https://arxiv.org/abs/2511.13207)
*Cheng Peng,Zhenzhe Zhang,Cheng Chi,Xiaobao Wei,Yanhao Zhang,Heng Wang,Pengwei Wang,Zhongyuan Wang,Jing Liu,Shanghang Zhang*

Main category: cs.RO

TL;DR: PIGEON通过PoI引导探索和VLM结合，提升未知环境中的导航智能性和决策效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在决策频率与智能性之间难以平衡的问题，提升导航决策的前瞻性和连续性。

Method: 使用视觉语言模型PIGEON-VL选择探索过程中的兴趣点（PoI），并结合低级规划器提高决策频率。

Result: 在经典导航基准测试中，零样本迁移方法表现优异，RLVR进一步提升了实时导航中的深度推理能力。

Conclusion: PIGEON方法在未知环境中导航任务上实现了最先进的性能，并通过RLVR进一步增强了语义引导能力。

Abstract: Navigating to a specified object in an unknown environment is a fundamental yet challenging capability of embodied intelligence. However, current methods struggle to balance decision frequency with intelligence, resulting in decisions lacking foresight or discontinuous actions. In this work, we propose PIGEON: Point of Interest Guided Exploration for Object Navigation with VLM, maintaining a lightweight and semantically aligned snapshot memory during exploration as semantic input for the exploration strategy. We use a large Visual-Language Model (VLM), named PIGEON-VL, to select Points of Interest (PoI) formed during exploration and then employ a lower-level planner for action output, increasing the decision frequency. Additionally, this PoI-based decision-making enables the generation of Reinforcement Learning with Verifiable Reward (RLVR) data suitable for simulators. Experiments on classic object navigation benchmarks demonstrate that our zero-shot transfer method achieves state-of-the-art performance, while RLVR further enhances the model's semantic guidance capabilities, enabling deep reasoning during real-time navigation.

</details>


### [413] [GaRLILEO: Gravity-aligned Radar-Leg-Inertial Enhanced Odometry](https://arxiv.org/abs/2511.13216)
*Chiyun Noh,Sangwoo Jung,Hanjun Kim,Yafei Hu,Laura Herlant,Ayoung Kim*

Main category: cs.RO

TL;DR: GaRLILEO是一种新型重力对齐连续时间雷达-腿-惯性里程计框架，通过雷达和腿部运动学信息解耦IMU速度，显著提升复杂地形中的垂直姿态估计精度。


<details>
  <summary>Details</summary>
Motivation: 传统方法在复杂地形中因垂直漂移和姿态估计不准确而受限，现有方法在特征稀疏或重复场景中性能下降，需改进。

Method: 提出GaRLILEO框架，结合雷达多普勒、腿部运动学信息和IMU数据，通过连续时间自速度样条和软S2约束重力因子，实现高精度的垂直姿态估计。

Result: 在多样化室内外轨迹的真实数据集中，GaRLILEO在垂直里程计估计上达到先进水平，尤其在楼梯和斜坡上表现突出。

Conclusion: GaRLILEO框架通过解耦IMU速度并利用雷达多普勒和腿部运动学信息构建连续时间自速度样条，显著提高了垂直姿态估计的准确性，特别在楼梯和斜坡等复杂地形中表现优异。

Abstract: Deployment of legged robots for navigating challenging terrains (e.g., stairs, slopes, and unstructured environments) has gained increasing preference over wheel-based platforms. In such scenarios, accurate odometry estimation is a preliminary requirement for stable locomotion, localization, and mapping. Traditional proprioceptive approaches, which rely on leg kinematics sensor modalities and inertial sensing, suffer from irrepressible vertical drift caused by frequent contact impacts, foot slippage, and vibrations, particularly affected by inaccurate roll and pitch estimation. Existing methods incorporate exteroceptive sensors such as LiDAR or cameras. Further enhancement has been introduced by leveraging gravity vector estimation to add additional observations on roll and pitch, thereby increasing the accuracy of vertical pose estimation. However, these approaches tend to degrade in feature-sparse or repetitive scenes and are prone to errors from double-integrated IMU acceleration. To address these challenges, we propose GaRLILEO, a novel gravity-aligned continuous-time radar-leg-inertial odometry framework. GaRLILEO decouples velocity from the IMU by building a continuous-time ego-velocity spline from SoC radar Doppler and leg kinematics information, enabling seamless sensor fusion which mitigates odometry distortion. In addition, GaRLILEO can reliably capture accurate gravity vectors leveraging a novel soft S2-constrained gravity factor, improving vertical pose accuracy without relying on LiDAR or cameras. Evaluated on a self-collected real-world dataset with diverse indoor-outdoor trajectories, GaRLILEO demonstrates state-of-the-art accuracy, particularly in vertical odometry estimation on stairs and slopes. We open-source both our dataset and algorithm to foster further research in legged robot odometry and SLAM. https://garlileo.github.io/GaRLILEO

</details>


### [414] [EL3DD: Extended Latent 3D Diffusion for Language Conditioned Multitask Manipulation](https://arxiv.org/abs/2511.13312)
*Jonas Bode,Raphael Memmesheimer,Sven Behnke*

Main category: cs.RO

TL;DR: 该论文提出结合扩散模型与视觉运动策略，通过改进嵌入和借鉴图像生成技术，提升了机器人在多任务操作中的表现，尤其在长时域任务中效果显著。


<details>
  <summary>Details</summary>
Motivation: 增强机器人在人类环境中的行动能力，需要强大的自然语言理解和物理任务执行能力。

Method: 采用扩散模型和视觉运动策略框架，结合视觉与文本输入生成精确机器人轨迹。训练时使用参考示范，改进嵌入技术，并借鉴图像生成的扩散模型技术。

Result: 在CALVIN数据集上的评估显示，该方法在各种操作任务中性能提升，且连续执行多任务时的长时域成功率增加。

Conclusion: 该研究通过结合扩散模型和视觉运动策略框架，显著提升了机器人在多任务操作中的性能，尤其是长时域任务的连续执行成功率。

Abstract: Acting in human environments is a crucial capability for general-purpose robots, necessitating a robust understanding of natural language and its application to physical tasks. This paper seeks to harness the capabilities of diffusion models within a visuomotor policy framework that merges visual and textual inputs to generate precise robotic trajectories. By employing reference demonstrations during training, the model learns to execute manipulation tasks specified through textual commands within the robot's immediate environment. The proposed research aims to extend an existing model by leveraging improved embeddings, and adapting techniques from diffusion models for image generation. We evaluate our methods on the CALVIN dataset, proving enhanced performance on various manipulation tasks and an increased long-horizon success rate when multiple tasks are executed in sequence. Our approach reinforces the usefulness of diffusion models and contributes towards general multitask manipulation.

</details>


### [415] [ZeroDexGrasp: Zero-Shot Task-Oriented Dexterous Grasp Synthesis with Prompt-Based Multi-Stage Semantic Reasoning](https://arxiv.org/abs/2511.13327)
*Juntao Jian,Yi-Lin Wei,Chengjie Mou,Yuhao Lin,Xing Zhu,Yujun Shen,Wei-Shi Zheng,Ruizhen Hu*

Main category: cs.RO

TL;DR: ZeroDexGrasp利用大语言模型和抓取优化技术，无需标注数据即可实现多样化物体和任务的高效抓取。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在多样化物体和任务指令下泛化能力不足、依赖大量标注数据的问题，提出一种无需标注数据的任务导向抓取方法。

Method: 采用基于提示的多阶段语义推理来推断抓取配置和物体接触信息，并结合接触引导的抓取优化技术，以确保物理可行性和任务对齐。

Result: 实验证明，ZeroDexGrasp能够在多样化物体类别和复杂任务需求下实现高质量的任务导向抓取。

Conclusion: ZeroDexGrasp通过结合大语言模型和抓取优化技术，实现了在多样化物体和复杂任务需求下的高效任务导向抓取，推动了通用化和智能化机器人抓取的发展。

Abstract: Task-oriented dexterous grasping holds broad application prospects in robotic manipulation and human-object interaction. However, most existing methods still struggle to generalize across diverse objects and task instructions, as they heavily rely on costly labeled data to ensure task-specific semantic alignment. In this study, we propose \textbf{ZeroDexGrasp}, a zero-shot task-oriented dexterous grasp synthesis framework integrating Multimodal Large Language Models with grasp refinement to generate human-like grasp poses that are well aligned with specific task objectives and object affordances. Specifically, ZeroDexGrasp employs prompt-based multi-stage semantic reasoning to infer initial grasp configurations and object contact information from task and object semantics, then exploits contact-guided grasp optimization to refine these poses for physical feasibility and task alignment. Experimental results demonstrate that ZeroDexGrasp enables high-quality zero-shot dexterous grasping on diverse unseen object categories and complex task requirements, advancing toward more generalizable and intelligent robotic grasping.

</details>


### [416] [Contact-Safe Reinforcement Learning with ProMP Reparameterization and Energy Awareness](https://arxiv.org/abs/2511.13459)
*Bingkun Huang,Yuhe Gong,Zewen Yang,Tianyu Ren,Luis Figueredo*

Main category: cs.RO

TL;DR: 提出任务空间能量安全框架，结合PPO与运动基元，实现高成功率和安全交互，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统MDP和阶段性强化学习方法在任务空间操作中常忽略接触丰富信息，尤其是接触安全和鲁棒性。

Method: 结合近端策略优化（PPO）和运动基元生成可靠且安全的任务空间轨迹，并整合能量感知笛卡尔阻抗控制器目标以确保机器人与环境的安全交互。

Result: 实验证明，该框架在3D环境中处理多种表面任务时表现优异，成功率高且轨迹平滑、交互安全。

Conclusion: 提出的任务空间能量安全框架在接触丰富的操作任务中表现出色，优于现有方法，实现了高成功率、平滑轨迹及能量安全交互。

Abstract: Reinforcement learning (RL) approaches based on Markov Decision Processes (MDPs) are predominantly applied in the robot joint space, often relying on limited task-specific information and partial awareness of the 3D environment. In contrast, episodic RL has demonstrated advantages over traditional MDP-based methods in terms of trajectory consistency, task awareness, and overall performance in complex robotic tasks. Moreover, traditional step-wise and episodic RL methods often neglect the contact-rich information inherent in task-space manipulation, especially considering the contact-safety and robustness. In this work, contact-rich manipulation tasks are tackled using a task-space, energy-safe framework, where reliable and safe task-space trajectories are generated through the combination of Proximal Policy Optimization (PPO) and movement primitives. Furthermore, an energy-aware Cartesian Impedance Controller objective is incorporated within the proposed framework to ensure safe interactions between the robot and the environment. Our experimental results demonstrate that the proposed framework outperforms existing methods in handling tasks on various types of surfaces in 3D environments, achieving high success rates as well as smooth trajectories and energy-safe interactions.

</details>


### [417] [Towards Affect-Adaptive Human-Robot Interaction: A Protocol for Multimodal Dataset Collection on Social Anxiety](https://arxiv.org/abs/2511.13530)
*Vesna Poprcova,Iulia Lefter,Matthias Wieser,Martijn Warnier,Frances Brazier*

Main category: cs.RO

TL;DR: 论文提出了一种收集社交焦虑多模态数据集的协议，通过人机互动场景促进情感自适应研究。


<details>
  <summary>Details</summary>
Motivation: 社交焦虑普遍存在，但相关多模态数据集稀缺，限制了研究和应用进展。

Method: 通过同步的音频、视频和生理记录，结合Wizard-of-Oz角色扮演场景与Furhat社交机器人互动，收集至少70名参与者的数据。

Result: 将构建一个包含音频、视频、生理记录及上下文数据的多模态数据集，支持社交焦虑的鲁棒检测。

Conclusion: 该论文提出了一种多模态数据集收集协议，旨在通过人机交互场景反映社交焦虑，为情感自适应人机交互研究提供支持。

Abstract: Social anxiety is a prevalent condition that affects interpersonal interactions and social functioning. Recent advances in artificial intelligence and social robotics offer new opportunities to examine social anxiety in the human-robot interaction context. Accurate detection of affective states and behaviours associated with social anxiety requires multimodal datasets, where each signal modality provides complementary insights into its manifestations. However, such datasets remain scarce, limiting progress in both research and applications. To address this, this paper presents a protocol for multimodal dataset collection designed to reflect social anxiety in a human-robot interaction context. The dataset will consist of synchronised audio, video, and physiological recordings acquired from at least 70 participants, grouped according to their level of social anxiety, as they engage in approximately 10-minute interactive Wizard-of-Oz role-play scenarios with the Furhat social robot under controlled experimental conditions. In addition to multimodal data, the dataset will be enriched with contextual data providing deeper insight into individual variability in social anxiety responses. This work can contribute to research on affect-adaptive human-robot interaction by providing support for robust multimodal detection of social anxiety.

</details>


### [418] [OpenRoboCare: A Multimodal Multi-Task Expert Demonstration Dataset for Robot Caregiving](https://arxiv.org/abs/2511.13707)
*Xiaoyu Liang,Ziang Liu,Kelvin Lin,Edward Gu,Ruolin Ye,Tam Nguyen,Cynthia Hsu,Zhanxin Wu,Xiaoman Yang,Christy Sum Yu Cheung,Harold Soh,Katherine Dimitropoulou,Tapomayukh Bhattacharjee*

Main category: cs.RO

TL;DR: OpenRoboCare是一个多模态数据集，用于机器人护理，包含职业治疗师日常活动（ADLs）的演示数据，涵盖了RGB-D视频、姿势跟踪、眼动追踪、任务注释和触觉感应等多种数据。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏大规模、专家驱动的护理数据集，无法有效支持机器人学习护理任务。

Method: 通过收集21名职业治疗师在两个人偶上执行的15项ADL任务数据，涵盖五种模态。

Result: 数据集提供了丰富的多模态信息，展示了护理动作、注意力、施力和任务执行策略。现有技术在感知和活动识别方面面临挑战。

Conclusion: OpenRoboCare填补了护理数据集的空白，为开发高效、安全的护理机器人提供了宝贵资源。

Abstract: We present OpenRoboCare, a multimodal dataset for robot caregiving, capturing expert occupational therapist demonstrations of Activities of Daily Living (ADLs). Caregiving tasks involve complex physical human-robot interactions, requiring precise perception under occlusions, safe physical contact, and long-horizon planning. While recent advances in robot learning from demonstrations have shown promise, there is a lack of a large-scale, diverse, and expert-driven dataset that captures real-world caregiving routines. To address this gap, we collect data from 21 occupational therapists performing 15 ADL tasks on two manikins. The dataset spans five modalities: RGB-D video, pose tracking, eye-gaze tracking, task and action annotations, and tactile sensing, providing rich multimodal insights into caregiver movement, attention, force application, and task execution strategies. We further analyze expert caregiving principles and strategies, offering insights to improve robot efficiency and task feasibility. Additionally, our evaluations demonstrate that OpenRoboCare presents challenges for state-of-the-art robot perception and human activity recognition methods, both critical for developing safe and adaptive assistive robots, highlighting the value of our contribution. See our website for additional visualizations: https://emprise.cs.cornell.edu/robo-care/.

</details>


### [419] [From Power to Precision: Learning Fine-grained Dexterity for Multi-fingered Robotic Hands](https://arxiv.org/abs/2511.13710)
*Jianglong Ye,Lai Wei,Guangqi Jiang,Changwei Jing,Xueyan Zou,Xiaolong Wang*

Main category: cs.RO

TL;DR: 该论文提出了一种联合优化控制和硬件设计的方法，使多指灵巧手能同时实现强力抓取和精确操作，显著提升了精细操作能力而不牺牲强力抓取能力。


<details>
  <summary>Details</summary>
Motivation: 当前机器人手设计的一个关键限制在于难以在单一多功能系统中同时实现稳定的强力抓取和精确的精细操作。

Method: 引入轻量级的指尖几何修改，将其表示为接触平面，并与其控制参数一起优化。控制策略动态切换强力抓取和精确操作，并将精确控制简化为拇指-食指平行运动。利用大规模仿真通过可微分的神经物理替代模型优化指尖几何。

Result: 在仿真到现实的精确抓取中，对未见物体实现了82.5%的零样本成功率，在涉及面包捏取的挑战性现实任务中实现了93.3%的成功率。

Conclusion: 该论文通过联合优化多指灵巧手的控制和硬件设计，成功实现了在同一系统中同时实现稳定的强力抓取和精确的精细操作。

Abstract: Human grasps can be roughly categorized into two types: power grasps and precision grasps. Precision grasping enables tool use and is believed to have influenced human evolution. Today's multi-fingered robotic hands are effective in power grasps, but for tasks requiring precision, parallel grippers are still more widely adopted. This contrast highlights a key limitation in current robotic hand design: the difficulty of achieving both stable power grasps and precise, fine-grained manipulation within a single, versatile system. In this work, we bridge this gap by jointly optimizing the control and hardware design of a multi-fingered dexterous hand, enabling both power and precision manipulation. Rather than redesigning the entire hand, we introduce a lightweight fingertip geometry modification, represent it as a contact plane, and jointly optimize its parameters along with the corresponding control. Our control strategy dynamically switches between power and precision manipulation and simplifies precision control into parallel thumb-index motions, which proves robust for sim-to-real transfer. On the design side, we leverage large-scale simulation to optimize the fingertip geometry using a differentiable neural-physics surrogate model. We validate our approach through extensive experiments in both sim-to-real and real-to-real settings. Our method achieves an 82.5% zero-shot success rate on unseen objects in sim-to-real precision grasping, and a 93.3% success rate in challenging real-world tasks involving bread pinching. These results demonstrate that our co-design framework can significantly enhance the fine-grained manipulation ability of multi-fingered hands without reducing their ability for power grasps. Our project page is at https://jianglongye.com/power-to-precision

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [420] [An improved approximation algorithm for k-Median](https://arxiv.org/abs/2511.12230)
*Neal E. Young*

Main category: cs.DS

TL;DR: 本文提出了一种多项式时间近似算法，解决了非度量k-Median问题，首次在常数因子内匹配了未加权Set Cover的已知界限，算法运行时间为O(k m log(n/k) log m)。


<details>
  <summary>Details</summary>
Motivation: 解决k-Median问题的多项式时间近似算法，特别是在非度量情况下，以匹配未加权Set Cover的已知界限。

Method: 该算法是一个α-大小近似算法，其中α < 1 + 2 ln(n/k)，保证解的大小最多为α×k，且成本不超过任何大小k的解的成本。

Result: 算法在O(k m log(n/k) log m)时间内运行，其中n是客户数量，m是实例大小。

Conclusion: 本文提出了一种多项式时间近似算法，解决了非度量k-Median问题，首次在常数因子内匹配了未加权Set Cover的已知界限。

Abstract: We give a polynomial-time approximation algorithm for the (not necessarily metric) $k$-Median problem. The algorithm is an $α$-size-approximation algorithm for $α< 1 + 2 \ln(n/k)$. That is, it guarantees a solution having size at most $α\times k$, and cost at most the cost of any size-$k$ solution. This is the first polynomial-time approximation algorithm to match the well-known bounds of $H_Δ$ and $1 + \ln(n/k)$ for unweighted Set Cover (a special case) within a constant factor. It matches these bounds within a factor of 2. The algorithm runs in time $O(k m \log(n/k) \log m)$, where $n$ is the number of customers and $m$ is the instance size.

</details>


### [421] [Shortcutting for Negative-Weight Shortest Path](https://arxiv.org/abs/2511.12714)
*George Z. Li,Jason Li,Satish Rao,Junkai Zhang*

Main category: cs.DS

TL;DR: 提出迭代捷径技术，在稠密图上将单源最短路径算法优化至$O(n^{2.5}\log^{4.5}n)$时间，超越现有成果。


<details>
  <summary>Details</summary>
Motivation: 改进现有算法在稠密图上的性能，超越Fineman（STOC 2024）和Huang-Jin-Quanrud（SODA 2025, 2026）的工作。

Method: 通过迭代的捷径技术，以常数因子减少最短路径中的负权重边数量。

Result: 算法时间复杂度优化至$O(n^{2.5}\log^{4.5}n)$，优于先前成果。

Conclusion: 本文提出了一种新的捷径技术，显著减少了最短路径中负权重边的数量，从而在稠密图上实现了更高效的单源最短路径算法。

Abstract: Consider the single-source shortest paths problem on a directed graph with real-valued edge weights. We solve this problem in $O(n^{2.5}\log^{4.5}n)$ time, improving on prior work of Fineman (STOC 2024) and Huang-Jin-Quanrud (SODA 2025, 2026) on dense graphs. Our main technique is an shortcutting procedure that iteratively reduces the number of negative-weight edges along shortest paths by a constant factor.

</details>


### [422] [Indirect Coflow Scheduling](https://arxiv.org/abs/2511.12854)
*Alexander Lindermayr,Kirk Pruhs,Andréa W. Richa,Tegan Wilson*

Main category: cs.DS

TL;DR: 研究小数据转移需求下的路由优化，提出新算法表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有算法主要针对大数据转移设计，对于小数据转移需求的效率不高，因此需要优化。

Method: 采用分数匹配和间接路由的方法，设计新的算法来处理小数据转移需求。

Result: 新算法在小数据需求场景下表现优于现有算法。

Conclusion: 本文研究了在数据转移需求相对较小的情况下，如何通过分数匹配和间接路由优化可重配置网络中的路由问题。与现有算法相比，新设计的算法在小数据需求场景下表现更优。

Abstract: We consider routing in reconfigurable networks, which is also known as coflow scheduling in the literature. The algorithmic literature generally (perhaps implicitly) assumes that the amount of data to be transferred is large. Thus the standard way to model a collection of requested data transfers is by an integer demand matrix $D$, where the entry in row $i$ and column $j$ of $D$ is an integer representing the amount of information that the application wants to send from machine/node $i$ to machine/node $j$. A feasible coflow schedule is then a sequence of matchings, which represent the sequence of data transfers that covers $D$. In this work, we investigate coflow scheduling when the size of some of the requested data transfers may be small relative to the amount of data that can be transferred in one round. fractional matchings and/or that employ indirect routing, and compare the relative utility of these options. We design algorithms that perform much better for small demands than the algorithms in the literature that were designed for large data transfers.

</details>


### [423] [Maximal Palindromes in MPC: Simple and Optimal](https://arxiv.org/abs/2511.13014)
*Solon P. Pissis*

Main category: cs.DS

TL;DR: 提出了一种在MPC模型中高效解决LPS问题的最优算法，突破了原有ε限制。


<details>
  <summary>Details</summary>
Motivation: 解决经典LPS问题在MPC模型中的高效并行计算需求。

Method: 在MPC模型中，采用随机化算法，总时间和内存为O(n)，每台机器内存为O(n^{1-ε})。

Result: 算法在O(1)轮内完成，并能计算所有最大回文子串，同时在Adaptive MPC模型中扩展了适用范围。

Conclusion: 提出了一种在MPC模型中解决LPS问题的简单且最优算法，同时在Adaptive MPC模型中突破了ε∈(0,0.5]的限制。

Abstract: In the classical longest palindromic substring (LPS) problem, we are given a string $S$ of length $n$, and the task is to output a longest palindromic substring in $S$. Gilbert, Hajiaghayi, Saleh, and Seddighin [SPAA 2023] showed how to solve the LPS problem in the Massively Parallel Computation (MPC) model in $\mathcal{O}(1)$ rounds using $\mathcal{\widetilde{O}}(n)$ total memory, with $\mathcal{\widetilde{O}}(n^{1-ε})$ memory per machine, for any $ε\in (0,0.5]$.
  We present a simple and optimal algorithm to solve the LPS problem in the MPC model in $\mathcal{O}(1)$ rounds. The total time and memory are $\mathcal{O}(n)$, with $\mathcal{O}(n^{1-ε})$ memory per machine, for any $ε\in (0,0.5]$. A key attribute of our algorithm is its ability to compute all maximal palindromes in the same complexities. Furthermore, our new insights allow us to bypass the constraint $ε\in (0,0.5]$ in the Adaptive MPC model. Our algorithms and the one proposed by Gilbert et al. for the LPS problem are randomized and succeed with high probability.

</details>


### [424] [Greedy matroid base packings with applications to dynamic graph density and orientations](https://arxiv.org/abs/2511.13205)
*Pavel Arkhipov,Vladimir Kolmogorov*

Main category: cs.DS

TL;DR: 本文研究了贪婪最小权重基包在拟阵中的应用，改进了全动态最密子图算法的更新时间复杂度，并提供了拟阵基包极限的特征化。


<details>
  <summary>Details</summary>
Motivation: 研究贪婪最小权重基包在一般拟阵中的过程，以改进连通性相关问题的算法效率。

Method: 通过贪婪打包伪森林，并维护动态变化图中的最小权重伪森林。对于一般拟阵，观察到基包的极限特征。

Result: 在双环拟阵中实现了$(1+\varepsilon)$-近似密度的全动态算法，更新时间为$O((\rho\varepsilon^{-2}+\varepsilon^{-4})\rho\log^3 m)$。此外，改进了贪婪树包的组合结果，证明了树包中某些最小割的交叉次数。

Conclusion: 贪婪最小权重生成树包在连通性问题中非常有用。本文研究了贪婪最小权重基包在一般拟阵中的过程，并探索了其算法应用。在双环拟阵中，结果改进了近似全动态最密子图密度的更新时间复杂度。此外，还展示了拟阵基包的极限特征，并改进了贪婪树包的组合结果。

Abstract: Greedy minimum weight spanning tree packings have proven to be useful in connectivity-related problems. We study the process of greedy minimum weight base packings in general matroids and explore its algorithmic applications.
  When specialized to bicircular matroids, our results yield an algorithm for the approximate fully-dynamic densest subgraph density $ρ$. We maintain a $(1+\varepsilon)$-approximation of the density with a worst-case update time $O((ρ\varepsilon^{-2}+\varepsilon^{-4})ρ\log^3 m)$. It improves the dependency on $\varepsilon$ from the current state-of-the-art worst-case update time complexity $O(\varepsilon^{-6}\log^3 n\logρ)$ [Chekuri, Christiansen, Holm, van der Hoog, Quanrud, Rotenberg, Schwiegelshohn, SODA'24]. We also can maintain an implicit fractional out-orientation with a guarantee that all out-degrees are at most $(1+\varepsilon)ρ$.
  Our algorithms above work by greedily packing pseudoforests, and require maintenance of a minimum-weight pseudoforest in a dynamically changing graph. We show that this problem can be solved in $O(\log n)$ worst-case time per edge insertion or deletion.
  For general matroids, we observe two characterizations of the limit of the base packings (``the vector of ideal loads''), which imply the characterizations from [Cen, Fleischmann, Li, Li, Panigrahi, FOCS'25], namely, their entropy-minimization theorem and their bottom-up cut hierarchy.
  Finally, we give combinatorial results on the greedy tree packings. We show that a tree packing of $O(λ^5\log m)$ trees contains a tree crossing some min-cut once, which improves the bound $O(λ^7\log^3 m)$ from [Thorup, Combinatorica'07]. We also strengthen the lower bound on the edge load convergence rate from [de Vos, Christiansen, SODA'25], showing that Thorup's upper bound is tight up to a logarithmic factor.

</details>


### [425] [A Complexity Analysis of the c-Closed Vertex Deletion Problem](https://arxiv.org/abs/2511.13301)
*Lisa Lehner,Christian Komusiewicz,Luca Pascal Staus*

Main category: cs.DS

TL;DR: 该论文研究了c-闭顶点删除问题的经典和参数化复杂性，包括NP难度、问题核的大小界限以及新参数x的应用，同时展示了在特定图类上的多项式时间解和固定参数可解性。


<details>
  <summary>Details</summary>
Motivation: 探索c-闭顶点删除问题的计算复杂性，特别是在不同图类和参数下的可解性，以填补现有研究的空白。

Method: 通过理论分析，研究了c-闭顶点删除问题的NP难度、问题核的大小，并引入新参数x来优化问题核的规模。同时，针对特定图类（如单位区间图）和参数（如邻域多样性）设计了专用算法。

Result: 证明了c-闭顶点删除问题在二分图和有界最大度图上是NP难的，提出了问题核的大小界限，并展示了在单位区间图和邻域多样性参数下的高效解法。

Conclusion: 该研究为c-闭顶点删除问题提供了全面的复杂性分析，并展示了在不同参数和图类下的可解性，为后续研究奠定了基础。

Abstract: A graph is $c$-closed when every pair of nonadjacent vertices has at most $c-1$ common neighbors. In $c$-Closed Vertex Deletion, the input is a graph $G$ and an integer $k$ and we ask whether $G$ can be transformed into a $c$-closed graph by deleting at most $k$ vertices. We study the classic and parameterized complexity of $c$-Closed Vertex Deletion. We obtain, for example, NP-hardness for the case that $G$ is bipartite with bounded maximum degree. We also show upper and lower bounds on the size of problem kernels for the parameter $k$ and introduce a new parameter, the number $x$ of vertices in bad pairs, for which we show a problem kernel of size $\mathcal{O}(x^3 + x^2\cdot c))$. Here, a pair of nonadjacent vertices is bad if they have at least $c$ common neighbors. Finally, we show that $c$-Closed Vertex Deletion can be solved in polynomial time on unit interval graphs with depth at most $c+1$ and that it is fixed-parameter tractable with respect to the neighborhood diversity of $G$.

</details>


### [426] [Dimension-Free Correlated Sampling for the Hypersimplex](https://arxiv.org/abs/2511.13573)
*Joseph,Naor,Nitya Raju,Abhishek Shetty,Aravind Srinivasan,Renata Valieva,David Wajc*

Main category: cs.DS

TL;DR: 论文提出了一种改进的超单纯形相关采样算法，将重叠度因子从O(log n)提升至O(log k)，并展示了其多领域应用价值。


<details>
  <summary>Details</summary>
Motivation: 自2000年以来，相关采样在理论计算机科学的不同领域已成为强大的构建块，但在超单纯形中的应用仍有改进空间。

Method: 研究了一种从给定向量在超单纯形中采样集合的广义问题，通过最大化采样集合的重叠来优化算法。

Result: 改进后的算法实现了O(log k)的因子，且具有输入稀疏性采样时间、对数并行深度和动态更新时间等优良特性。

Conclusion: 该论文提出了一种改进的算法，将相关采样问题的因子从O(log n)降低到O(log k)，独立于环境维度n，并展示了该算法在多个应用中的潜力。

Abstract: Sampling from multiple distributions so as to maximize overlap has been studied by statisticians since the 1950s. Since the 2000s, such correlated sampling from the probability simplex has been a powerful building block in disparate areas of theoretical computer science. We study a generalization of this problem to sampling sets from given vectors in the hypersimplex, i.e., outputting sets of size (at most) some $k$ in $[n]$, while maximizing the sampled sets' overlap. Specifically, the expected difference between two output sets should be at most $α$ times their input vectors' $\ell_1$ distance. A value of $α=O(\log n)$ is known to be achievable, due to Chen et al.~(ICALP'17). We improve this factor to $O(\log k)$, independent of the ambient dimension~$n$. Our algorithm satisfies other desirable properties, including (up to a $\log^* n$ factor) input-sparsity sampling time, logarithmic parallel depth and dynamic update time, as well as preservation of submodular objectives. Anticipating broader use of correlated sampling algorithms for the hypersimplex, we present applications of our algorithm to online paging, offline approximation of metric multi-labeling and swift multi-scenario submodular welfare approximating reallocation.

</details>


### [427] [The Merkle Mountain Belt](https://arxiv.org/abs/2511.13582)
*Alfonso Cevallos,Robert Hambrock,Alistair Stewart*

Main category: cs.DS

TL;DR: 论文比较了多种Merkle结构的特性，并提出了同时具备简洁性、增量性和最优可加性的新结构（MMB和UMMB），显著提升了轻客户端的效率。


<details>
  <summary>Details</summary>
Motivation: 优化区块链轻客户端协议，使用户能够通过智能手机等设备高效验证交易，提升同步效率和交互能力。

Method: 通过比较不同Merkle结构（如MMR和Merkle链）的特性，并引入新的Merkle结构（MMB和UMMB），分析其在轻客户端协议中的应用效果。

Result: 新提出的Merkle结构（MMB和UMMB）在简洁性、增量性和最优可加性上表现优异，尤其适用于偏向近期数据的查询场景。

Conclusion: 论文提出了新的Merkle结构（如MMB和UMMB），这些结构在区块链应用中同时具备简洁性、增量性和最优可加性，显著优化了轻客户端的性能。

Abstract: Merkle structures are widely used as commitment schemes: they allow a prover to publish a compact commitment to an ordered list $X$ of items, and then efficiently prove to a verifier that $x_i\in X$ is the $i$-th item in it. We compare different Merkle structures and their corresponding properties as commitment schemes in the context of blockchain applications. Our primary goal is to speed up light client protocols so that, e.g., a user can verify a transaction efficiently from their smartphone.
  For instance, the Merkle Mountain Range (MMR) yields a succinct scheme: a light client synchronizing for the first time can do so with a complexity sublinear in $|X|$. On the other hand, the Merkle chain, traditionally used to commit to block headers, is not succinct, but it is incremental - a light client resynchronizing frequently can do so with constant complexity - and optimally additive - the structure can be updated in constant time when a new item is appended to list $X$.
  We introduce new Merkle structures, most notably the Merkle Mountain Belt (MMB), the first to be simultaneously succinct, incremental and optimally additive. A variant called UMMB is also asynchronous: a light client may continue to interact with the network even when out of sync with the public commitment. Our Merkle structures are slightly unbalanced, so that items recently appended to $X$ receive shorter membership proofs than older items. This feature reduces a light client's expected costs, in applications where queries are biased towards recently generated data.

</details>


### [428] [Chasing Submodular Objectives, and Submodular Maximization via Cutting Planes](https://arxiv.org/abs/2511.13605)
*Niv Buchbinder,Joseph,Naor,David Wajc*

Main category: cs.DS

TL;DR: 本文提出了一种新算法“近似或分离”，用于动态子模最大化问题，实现了高近似比和低调整次数，并展示了其在静态算法和通信协议中的扩展应用。


<details>
  <summary>Details</summary>
Motivation: 研究目标是解决一系列随时间变化的约束子模最大化问题，同时在保持高近似比的同时减少总调整次数（recourse）。

Method: 作者提出了一种改进的“round-and-separate”方法，称为“近似或分离”，该算法可以结合任何切割平面方法和约束的分离预言机。

Result: 针对基数约束和分区拟阵约束，作者提出了多项式时间算法，实现了最优$(1-1/e-ε)$近似和竞争性调整次数。

Conclusion: 本文提出了一种名为“近似或分离”的新元算法，用于在一般约束下最大化多线性扩展，实现了$(1-1/e-ε)$近似。该算法不仅适用于动态场景，还展示了在静态算法和通信复杂度协议中的进一步应用。

Abstract: We introduce the \emph{submodular objectives chasing problem}, which generalizes many natural and previously-studied problems: a sequence of constrained submodular maximization problems is revealed over time, with both the objective and available ground set changing at each step. The goal is to maintain solutions of high approximation and low total \emph{recourse} (number of changes), compared with exact offline algorithms for the same input sequence. For the central cardinality constraint and partition matroid constraints we provide polynomial-time algorithms achieving both optimal $(1-1/e-ε)$-approximation and optimal competitive recourse for \emph{any} constant-approximation.
  Key to our algorithm's polynomial time, and of possible independent interest, is a new meta-algorithm for $(1-1/e-ε)$-approximately maximizing the multilinear extension under general constraints, which we call {\em approximate-or-separate}. Our algorithm relies on an improvement of the round-and-separate method [Gupta-Levin SODA'20], inspired by an earlier proof by [Vondrák, PhD~Thesis'07]. The algorithm, whose guarantees are similar to the influential {\em continuous greedy} algorithm [Calinescu-Chekuri-Pál-Vondrák SICOMP'11], can use any cutting plane method and separation oracle for the constraints. This allows us to introduce cutting plane methods, used for exact unconstrained submodular minimization since the '80s [Grötschel/Lovász/Schrijver Combinatorica'81], as a useful method for (optimal approximate) constrained submodular maximization. We show further applications of this approach to static algorithms with curvature-sensitive approximation, and to communication complexity protocols.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [429] [LLM-Generated Negative News Headlines Dataset: Creation and Benchmarking Against Real Journalism](https://arxiv.org/abs/2511.11591)
*Olusola Babalola,Bolanle Ojokoh,Olutayo Boyinbode*

Main category: cs.AI

TL;DR: 研究验证了LLM生成的负面新闻标题作为真实数据替代的可行性，结果显示其在多数评估指标上与真实数据匹配，仅在专有名词使用上存在差异。


<details>
  <summary>Details</summary>
Motivation: 旨在克服自然语言处理任务中数据获取和隐私问题，探索LLM生成的合成数据作为真实数据的替代方案。

Method: 研究通过专家评审和嵌入空间分析验证合成新闻标题的真实性，并使用包括Comparative Perplexity Test、Comparative Readability Test、Comparative POS Profiling、BERTScore和Comparative Semantic Similarity在内的多种指标进行基准测试。

Result: 合成数据集在内容、语气、长度和风格上与真实负面新闻标题对齐，关键指标如相关性、困惑度、连贯性和真实性均表现良好。

Conclusion: 研究表明，LLM生成的合成新闻标题在大多数评估指标上与真实新闻标题相匹配，仅在POS分析中的专有名词得分上存在明显差异。

Abstract: This research examines the potential of datasets generated by Large Language Models (LLMs) to support Natural Language Processing (NLP) tasks, aiming to overcome challenges related to data acquisition and privacy concerns associated with real-world data. Focusing on negative valence text, a critical component of sentiment analysis, we explore the use of LLM-generated synthetic news headlines as an alternative to real-world data. A specialized corpus of negative news headlines was created using tailored prompts to capture diverse negative sentiments across various societal domains. The synthetic headlines were validated by expert review and further analyzed in embedding space to assess their alignment with real-world negative news in terms of content, tone, length, and style. Key metrics such as correlation with real headlines, perplexity, coherence, and realism were evaluated. The synthetic dataset was benchmarked against two sets of real news headlines using evaluations including the Comparative Perplexity Test, Comparative Readability Test, Comparative POS Profiling, BERTScore, and Comparative Semantic Similarity. Results show the generated headlines match real headlines with the only marked divergence being in the proper noun score of the POS profile test.

</details>


### [430] [CLINB: A Climate Intelligence Benchmark for Foundational Models](https://arxiv.org/abs/2511.11597)
*Michelle Chen Huebscher,Katharine Mach,Aleksandar Stanić,Markus Leippold,Ben Gaiarin,Zeke Hausfather,Elisa Rawat,Erich Fischer,Massimiliano Ciaramita,Joeri Rogelj,Christian Buck,Lierni Sestorain Saralegui,Reto Knutti*

Main category: cs.AI

TL;DR: CLINB基准揭示了前沿LLMs在知识综合上的优势与证据基础的不足，强调需提升可验证归因以实现AI在科学工作流程中的可靠应用。


<details>
  <summary>Details</summary>
Motivation: 评估大语言模型处理复杂专业知识的能力，特别是在气候变化领域，以解决知识质量和证据支持的关键挑战。

Method: 研究通过引入CLINB基准，评估模型在开放、接地气的多模态问答任务中的表现，使用真实用户问题和气候科学家制定的评估标准。

Result: 前沿模型展现出卓越的知识综合能力，甚至超过专家辅助的混合答案，但在证据基础方面存在显著问题，如引用和图像的高幻觉率。

Conclusion: 论文强调了大语言模型在知识综合与可验证归因之间存在的差距，指出如CLINB这样可靠、可解释的基准对于构建可信AI系统至关重要。

Abstract: Evaluating how Large Language Models (LLMs) handle complex, specialized knowledge remains a critical challenge. We address this through the lens of climate change by introducing CLINB, a benchmark that assesses models on open-ended, grounded, multimodal question answering tasks with clear requirements for knowledge quality and evidential support. CLINB relies on a dataset of real users' questions and evaluation rubrics curated by leading climate scientists. We implement and validate a model-based evaluation process and evaluate several frontier models. Our findings reveal a critical dichotomy. Frontier models demonstrate remarkable knowledge synthesis capabilities, often exhibiting PhD-level understanding and presentation quality. They outperform "hybrid" answers curated by domain experts assisted by weaker models. However, this performance is countered by failures in grounding. The quality of evidence varies, with substantial hallucination rates for references and images. We argue that bridging this gap between knowledge synthesis and verifiable attribution is essential for the deployment of AI in scientific workflows and that reliable, interpretable benchmarks like CLINB are needed to progress towards building trustworthy AI systems.

</details>


### [431] [SynBullying: A Multi LLM Synthetic Conversational Dataset for Cyberbullying Detectio](https://arxiv.org/abs/2511.11599)
*Arefeh Kazemi,Hamza Qadeer,Joachim Wagner,Hossein Hosseini,Sri Balaaji Natarajan Kalaivendan,Brian Davis*

Main category: cs.AI

TL;DR: SynBullying是一个由LLMs生成的合成数据集，用于网络欺凌研究，具有多轮对话结构和细粒度标注，评估显示其在CB分类中具有实用价值。


<details>
  <summary>Details</summary>
Motivation: 为了解决网络欺凌研究中真实数据收集的伦理和可扩展性问题，提出了一种基于合成数据的替代方案。

Method: 利用大型语言模型（LLMs）生成模拟真实欺凌互动的多轮对话数据集，并提供了对话结构、上下文感知标注和细粒度标签。

Result: SynBullying数据集在多维度评估中表现出色，并能作为独立的训练数据或数据增强来源用于CB分类任务。

Conclusion: SynBullying数据集通过利用大型语言模型（LLMs）生成合成数据，为网络欺凌（CB）研究提供了一个可扩展且伦理安全的替代方案，并在多个维度上进行了评估，展示了其在CB分类中的实用性和潜力。

Abstract: We introduce SynBullying, a synthetic multi-LLM conversational dataset for studying and detecting cyberbullying (CB). SynBullying provides a scalable and ethically safe alternative to human data collection by leveraging large language models (LLMs) to simulate realistic bullying interactions. The dataset offers (i) conversational structure, capturing multi-turn exchanges rather than isolated posts; (ii) context-aware annotations, where harmfulness is assessed within the conversational flow considering context, intent, and discourse dynamics; and (iii) fine-grained labeling, covering various CB categories for detailed linguistic and behavioral analysis. We evaluate SynBullying across five dimensions, including conversational structure, lexical patterns, sentiment/toxicity, role dynamics, harm intensity, and CB-type distribution. We further examine its utility by testing its performance as standalone training data and as an augmentation source for CB classification.

</details>


### [432] [CausalGuard: A Smart System for Detecting and Preventing False Information in Large Language Models](https://arxiv.org/abs/2511.11600)
*Piyushkumar Patel*

Main category: cs.AI

TL;DR: CausalGuard结合因果推理和符号逻辑，有效减少大语言模型的幻觉问题，尤其在复杂推理任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 大语言模型存在幻觉问题，即在准确性至关重要的领域自信地提供虚假信息。现有解决方案要么需要重新训练整个模型，要么增加显著计算成本，或未能解决幻觉的根本原因。

Method: CausalGuard通过两条互补路径：追踪模型知识与其生成内容之间的因果关系，以及使用自动推理检查逻辑一致性。

Result: CausalGuard在十二个基准测试中，正确识别幻觉率为89.3%，漏检率仅8.3%，并减少近80%的虚假声明。

Conclusion: CausalGuard通过结合因果推理和符号逻辑，有效捕捉和预防大语言模型的幻觉问题。

Abstract: While large language models have transformed how we interact with AI systems, they have a critical weakness: they confidently state false information that sounds entirely plausible. This "hallucination" problem has become a major barrier to using these models where accuracy matters most. Existing solutions either require retraining the entire model, add significant computational costs, or miss the root causes of why these hallucinations occur in the first place.
  We present CausalGuard, a new approach that combines causal reasoning with symbolic logic to catch and prevent hallucinations as they happen. Unlike previous methods that only check outputs after generation, our system understands the causal chain that leads to false statements and intervenes early in the process. CausalGuard works through two complementary paths: one that traces causal relationships between what the model knows and what it generates, and another that checks logical consistency using automated reasoning.
  Testing across twelve different benchmarks, we found that CausalGuard correctly identifies hallucinations 89.3\% of the time while missing only 8.3\% of actual hallucinations. More importantly, it reduces false claims by nearly 80\% while keeping responses natural and helpful. The system performs especially well on complex reasoning tasks where multiple steps of logic are required. Because CausalGuard shows its reasoning process, it works well in sensitive areas like medical diagnosis or financial analysis where understanding why a decision was made matters as much as the decision itself.

</details>


### [433] [Quantifying Skill and Chance: A Unified Framework for the Geometry of Games](https://arxiv.org/abs/2511.11611)
*David H. Silver*

Main category: cs.AI

TL;DR: 论文提出了一个量化框架，通过技能-运气指数S(G)和波动性Sigma，分析了30种游戏中技能与运气的影响，揭示了从纯运气到纯技能的连续谱。


<details>
  <summary>Details</summary>
Motivation: 旨在提供一个量化框架，用于区分和比较游戏中技能和运气的影响，以支持游戏设计、AI评估和风险评估。

Method: 通过定义技能-运气指数S(G)并分解游戏结果为技能杠杆K和运气杠杆L，该研究分析了30种游戏，揭示了技能与运气的连续谱。

Result: 研究发现不同游戏在技能与运气之间存在连续谱，扑克表现出中等技能优势（S = 0.33），而国际象棋和抛硬币分别代表纯技能和纯运气。

Conclusion: 该论文提出了一个量化框架，通过将游戏建模为对随机决策树的互补控制源，来区分技能和运气在游戏中的作用。研究发现游戏在技能与运气之间存在一个连续谱，从纯运气（如抛硬币）到纯技能（如国际象棋），并引入了波动性Sigma来量化连续回合的结果不确定性。

Abstract: We introduce a quantitative framework for separating skill and chance in games by modeling them as complementary sources of control over stochastic decision trees. We define the Skill-Luck Index S(G) in [-1, 1] by decomposing game outcomes into skill leverage K and luck leverage L. Applying this to 30 games reveals a continuum from pure chance (coin toss, S = -1) through mixed domains such as backgammon (S = 0, Sigma = 1.20) to pure skill (chess, S = +1, Sigma = 0). Poker exhibits moderate skill dominance (S = 0.33) with K = 0.40 +/- 0.03 and Sigma = 0.80. We further introduce volatility Sigma to quantify outcome uncertainty over successive turns. The framework extends to general stochastic decision systems, enabling principled comparisons of player influence, game balance, and predictive stability, with applications to game design, AI evaluation, and risk assessment.

</details>


### [434] [Value-Aligned Prompt Moderation via Zero-Shot Agentic Rewriting for Safe Image Generation](https://arxiv.org/abs/2511.11693)
*Xin Zhao,Xiaojun Chen,Bingshan Liu,Zeyao Liu,Zhendong Zhao,Xiaoyan Gu*

Main category: cs.AI

TL;DR: VALOR是一个用于安全文本到图像生成的模块化框架，通过分层提示分析和动态重写，显著减少不安全输出，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 生成式视觉语言模型（如Stable Diffusion）在创意媒体合成方面表现出色，但也存在产生不安全、冒犯性或文化不适当内容的风险。当前的防御方法难以在不牺牲生成质量或增加高成本的情况下使输出与人类价值观对齐。

Method: VALOR是一个模块化、零样本的代理框架，集成了分层提示分析和人类对齐的价值推理，包括多级NSFW检测器、文化价值对齐模块和意图消歧器。当检测到不安全内容时，VALOR会通过大型语言模型在动态、特定角色的指令下选择性重写提示。

Result: 实验表明，VALOR在对抗性、模糊性和价值敏感的提示下，显著减少了不安全的输出（高达100.00%），同时保持了提示的有用性和创造力。

Conclusion: VALOR作为一种可扩展且有效的方法，在开放世界环境中部署安全、对齐且有用的图像生成系统，显著减少了不安全的输出，同时保持了提示的有用性和创造力。

Abstract: Generative vision-language models like Stable Diffusion demonstrate remarkable capabilities in creative media synthesis, but they also pose substantial risks of producing unsafe, offensive, or culturally inappropriate content when prompted adversarially. Current defenses struggle to align outputs with human values without sacrificing generation quality or incurring high costs. To address these challenges, we introduce VALOR (Value-Aligned LLM-Overseen Rewriter), a modular, zero-shot agentic framework for safer and more helpful text-to-image generation. VALOR integrates layered prompt analysis with human-aligned value reasoning: a multi-level NSFW detector filters lexical and semantic risks; a cultural value alignment module identifies violations of social norms, legality, and representational ethics; and an intention disambiguator detects subtle or indirect unsafe implications. When unsafe content is detected, prompts are selectively rewritten by a large language model under dynamic, role-specific instructions designed to preserve user intent while enforcing alignment. If the generated image still fails a safety check, VALOR optionally performs a stylistic regeneration to steer the output toward a safer visual domain without altering core semantics. Experiments across adversarial, ambiguous, and value-sensitive prompts show that VALOR significantly reduces unsafe outputs by up to 100.00% while preserving prompt usefulness and creativity. These results highlight VALOR as a scalable and effective approach for deploying safe, aligned, and helpful image generation systems in open-world settings.

</details>


### [435] [MM-Telco: Benchmarks and Multimodal Large Language Models for Telecom Applications](https://arxiv.org/abs/2511.13131)
*Gagan Raj Gupta,Anshul Kumar,Manish Rai,Apu Chakraborty,Ashutosh Modi,Abdelaali Chaoub,Soumajit Pramanik,Moyank Giri,Yashwanth Holla,Sunny Kumar,M. V. Kiran Sooraj*

Main category: cs.AI

TL;DR: MM-Telco是为电信领域设计的多模态基准测试和模型套件，显著提升LLMs性能并指导未来研究。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在电信领域部署时的领域特定挑战，加速其在该领域的适应。

Method: 提出MM-Telco套件，包含针对电信领域的多模态基准测试和模型，并进行基线实验。

Result: 在数据集上微调的模型表现出显著性能提升，实验还揭示了当前多模态LLMs的薄弱环节。

Conclusion: MM-Telco 为电信领域提供了专门的多模态基准测试和模型，显著提升了性能，并指出了当前多模态LLMs的薄弱环节，为未来研究指明了方向。

Abstract: Large Language Models (LLMs) have emerged as powerful tools for automating complex reasoning and decision-making tasks. In telecommunications, they hold the potential to transform network optimization, automate troubleshooting, enhance customer support, and ensure regulatory compliance. However, their deployment in telecom is hindered by domain-specific challenges that demand specialized adaptation. To overcome these challenges and to accelerate the adaptation of LLMs for telecom, we propose MM-Telco, a comprehensive suite of multimodal benchmarks and models tailored for the telecom domain. The benchmark introduces various tasks (both text based and image based) that address various practical real-life use cases such as network operations, network management, improving documentation quality, and retrieval of relevant text and images. Further, we perform baseline experiments with various LLMs and VLMs. The models fine-tuned on our dataset exhibit a significant boost in performance. Our experiments also help analyze the weak areas in the working of current state-of-art multimodal LLMs, thus guiding towards further development and research.

</details>


### [436] [Towards autonomous quantum physics research using LLM agents with access to intelligent tools](https://arxiv.org/abs/2511.11752)
*Sören Arlt,Xuemei Gu,Mario Krenn*

Main category: cs.AI

TL;DR: AI-Mandel是一个能够生成并实施量子物理领域具体创意的LLM代理，展示了AI在科研中的潜力及其面临的挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在科学领域的应用广泛，但初始研究问题和目标仍主要由人类提供。AI生成的科学创意往往模糊且难以实施，因此自动化生成和实施创意将极大改变人类在科研中的角色。

Method: AI-Mandel通过从文献中提炼想法，并利用特定领域的AI工具将这些想法转化为可立即在实验室实施的实验设计。

Result: AI-Mandel生成的创意在科学上具有意义，其中两个已被独立撰写为后续科学论文，包括量子隐形传态的新变体、不确定因果顺序中的量子网络原语，以及基于量子信息传递闭环的新几何相位概念。

Conclusion: AI-Mandel作为一个原型系统，展示了AI能够在量子物理领域生成并实施具体、可操作的科学想法，这不仅加速了科研进程，也为实现人类水平的人工科学家提供了具体的挑战。

Abstract: Artificial intelligence (AI) is used in numerous fields of science, yet the initial research questions and targets are still almost always provided by human researchers. AI-generated creative ideas in science are rare and often vague, so that it remains a human task to execute them. Automating idea generation and implementation in one coherent system would significantly shift the role of humans in the scientific process. Here we present AI-Mandel, an LLM agent that can generate and implement ideas in quantum physics. AI-Mandel formulates ideas from the literature and uses a domain-specific AI tool to turn them into concrete experiment designs that can readily be implemented in laboratories. The generated ideas by AI-Mandel are often scientifically interesting - for two of them we have already written independent scientific follow-up papers. The ideas include new variations of quantum teleportation, primitives of quantum networks in indefinite causal orders, and new concepts of geometric phases based on closed loops of quantum information transfer. AI-Mandel is a prototypical demonstration of an AI physicist that can generate and implement concrete, actionable ideas. Building such a system is not only useful to accelerate science, but it also reveals concrete open challenges on the path to human-level artificial scientists.

</details>


### [437] [Learning to Refine: An Agentic RL Approach for Iterative SPARQL Query Construction](https://arxiv.org/abs/2511.11770)
*Floris Vossebeld,Shenghui Wang*

Main category: cs.AI

TL;DR: 本文提出了一种通过强化学习训练的代理框架，动态调试SPARQL查询，显著提升了知识图谱问答的准确性。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLMs）在生成复杂、逻辑严密的SPARQL查询时的脆弱性问题，以及当前方法缺乏基于实时执行反馈的动态调试策略。

Method: 采用基于结果的强化学习（GRPO）训练一个紧凑的3B参数模型，无需监督微调，学习迭代构建SPARQL查询的策略。

Result: 在LC-QuAD 2.0的可执行单答案子集上，代理模型在实体链接后达到49.7%的准确率，比最强的零样本基线提高了17.5个百分点。

Conclusion: 本文提出了一个通过强化学习（RL）训练的代理框架，能够有效地通过实时执行反馈动态调试SPARQL查询，显著提升了知识图谱问答的准确性。

Abstract: Generating complex, logically-sound SPARQL queries for multi-hop questions remains a critical bottleneck for Knowledge Graph Question Answering, as the brittle nature of one-shot generation by Large Language Models (LLMs) hinders reliable interaction with structured data. Current methods lack the adaptive policies needed to dynamically debug queries based on real-time execution feedback. This paper introduces a novel agentic framework where an LLM learns a resilient policy for the sequential process of iterative SPARQL construction. We show that a compact 3B-parameter model, trained exclusively via outcome-driven Reinforcement Learning (GRPO) without supervised fine-tuning, can learn effective policies for this task, discovering how to systematically recover from execution errors and refine its queries toward a correct answer. On a curated, executable single-answer subset of LC-QuAD 2.0, our agent achieves 49.7\% accuracy post-entity-linking, a significant 17.5 percentage point improvement over the strongest iterative zero-shot baseline. Further analysis reveals that while the agent's capability is driven by RL, its performance is enhanced by an explicit deliberative reasoning step that acts as a cognitive scaffold to improve policy precision. This work presents a generalizable blueprint for teaching agents to master formal, symbolic tools through interaction, bridging the gap between probabilistic LLMs and the structured world of Knowledge Graphs.

</details>


### [438] [On the Measure of a Model: From Intelligence to Generality](https://arxiv.org/abs/2511.11773)
*Ruchira Dhar,Ninell Oldenburg,Anders Soegaard*

Main category: cs.AI

TL;DR: 论文主张以‘通用性’替代‘智能’作为AI评估核心，通过分析证明通用性更能稳定衡量多样化任务表现。


<details>
  <summary>Details</summary>
Motivation: 当前用于评估大型语言模型智能的基准（如ARC、Raven-inspired测试）缺乏稳定定义，且无法预测实际任务表现，可能导致评估与现实效用脱节。

Method: 通过概念和形式化分析，检验了智能评估中的三个假设：通用性、稳定性和现实性。

Result: 研究发现，只有‘通用性’假设经得起概念和实证检验，智能并非通用性的驱动力，通用性应视为多任务学习问题。

Conclusion: 该论文提出应以‘通用性’而非抽象的‘智能’概念作为AI评估的基础，认为通用性能更稳定地衡量AI在多样化任务中的表现。

Abstract: Benchmarks such as ARC, Raven-inspired tests, and the Blackbird Task are widely used to evaluate the intelligence of large language models (LLMs). Yet, the concept of intelligence remains elusive- lacking a stable definition and failing to predict performance on practical tasks such as question answering, summarization, or coding. Optimizing for such benchmarks risks misaligning evaluation with real-world utility. Our perspective is that evaluation should be grounded in generality rather than abstract notions of intelligence. We identify three assumptions that often underpin intelligence-focused evaluation: generality, stability, and realism. Through conceptual and formal analysis, we show that only generality withstands conceptual and empirical scrutiny. Intelligence is not what enables generality; generality is best understood as a multitask learning problem that directly links evaluation to measurable performance breadth and reliability. This perspective reframes how progress in AI should be assessed and proposes generality as a more stable foundation for evaluating capability across diverse and evolving tasks.

</details>


### [439] [Do LLMs Really Struggle at NL-FOL Translation? Revealing their Strengths via a Novel Benchmarking Strategy](https://arxiv.org/abs/2511.11816)
*Andrea Brunello,Luca Geatti,Michele Mignani,Angelo Montanari,Nicola Saccomanno*

Main category: cs.AI

TL;DR: 本文提出了一种新的评估协议，揭示了对话导向LLMs在NL-FOL翻译任务中的强大能力，而嵌入中心模型表现不佳。


<details>
  <summary>Details</summary>
Motivation: 自然语言到一阶逻辑（NL-FOL）翻译是一个长期挑战，现有评估方法和数据集可能低估了LLMs的实际能力。

Method: 提出了一种新的评估协议，旨在区分真正的语义级逻辑理解与表面的模式识别、记忆和数据集污染。

Result: 研究表明，对话导向LLMs在NL-FOL翻译任务中表现优异，而嵌入中心模型表现较差。

Conclusion: 最新的对话导向大型语言模型（LLMs）展现了强大的自然语言到一阶逻辑（NL-FOL）翻译能力，并真正理解句子层面的逻辑，而嵌入中心模型表现较差。

Abstract: Due to its expressiveness and unambiguous nature, First-Order Logic (FOL) is a powerful formalism for representing concepts expressed in natural language (NL). This is useful, e.g., for specifying and verifying desired system properties. While translating FOL into human-readable English is relatively straightforward, the inverse problem, converting NL to FOL (NL-FOL translation), has remained a longstanding challenge, for both humans and machines. Although the emergence of Large Language Models (LLMs) promised a breakthrough, recent literature provides contrasting results on their ability to perform NL-FOL translation. In this work, we provide a threefold contribution. First, we critically examine existing datasets and protocols for evaluating NL-FOL translation performance, revealing key limitations that may cause a misrepresentation of LLMs' actual capabilities. Second, to overcome these shortcomings, we propose a novel evaluation protocol explicitly designed to distinguish genuine semantic-level logical understanding from superficial pattern recognition, memorization, and dataset contamination. Third, using this new approach, we show that state-of-the-art, dialogue-oriented LLMs demonstrate strong NL-FOL translation skills and a genuine grasp of sentence-level logic, whereas embedding-centric models perform markedly worse.

</details>


### [440] [TopoPerception: A Shortcut-Free Evaluation of Global Visual Perception in Large Vision-Language Models](https://arxiv.org/abs/2511.11831)
*Wenhao Zhou,Hao Zheng,Rong Zhao*

Main category: cs.AI

TL;DR: TopoPerception基准通过拓扑特性评估LVLMs全局视觉感知，发现当前模型能力不足，需新训练范式或架构。


<details>
  <summary>Details</summary>
Motivation: LVLMs的视觉感知模块成为瓶颈，传统评估基准存在局部捷径，导致高估模型感知能力。

Method: 引入TopoPerception基准，利用拓扑特性评估LVLMs的全局视觉感知能力。

Result: 即使在最粗粒度，所有模型表现均不优于随机猜测，表明全局视觉感知能力严重不足。

Conclusion: TopoPerception揭示了当前LVLMs在全局视觉感知上的关键瓶颈，并提供了改进方向。

Abstract: Large Vision-Language Models (LVLMs) typically align visual features from an encoder with a pre-trained Large Language Model (LLM). However, this makes the visual perception module a bottleneck, which constrains the overall capabilities of LVLMs. Conventional evaluation benchmarks, while rich in visual semantics, often contain unavoidable local shortcuts that can lead to an overestimation of models' perceptual abilities. Here, we introduce TopoPerception, a benchmark that leverages topological properties to rigorously evaluate the global visual perception capabilities of LVLMs across various granularities. Since topology depends on the global structure of an image and is invariant to local features, TopoPerception enables a shortcut-free assessment of global perception, fundamentally distinguishing it from semantically rich tasks. We evaluate state-of-the-art models on TopoPerception and find that even at the coarsest perceptual granularity, all models perform no better than random chance, indicating a profound inability to perceive global visual features. Notably, a consistent trend emerge within model families: more powerful models with stronger reasoning capabilities exhibit lower accuracy. This suggests that merely scaling up models is insufficient to address this deficit and may even exacerbate it. Progress may require new training paradigms or architectures. TopoPerception not only exposes a critical bottleneck in current LVLMs but also offers a lens and direction for improving their global visual perception. The data and code are publicly available at: https://github.com/Wenhao-Zhou/TopoPerception.

</details>


### [441] [End to End AI System for Surgical Gesture Sequence Recognition and Clinical Outcome Prediction](https://arxiv.org/abs/2511.11899)
*Xi Li,Nicholas Matsumoto,Ujjwal Pasupulety,Atharva Deo,Cherine Yang,Jay Moran,Miguel E. Hernandez,Peter Wager,Jasmine Lin,Jeanine Kim,Alvin C. Goh,Christian Wagner,Geoffrey A. Sonn,Andrew J. Hung*

Main category: cs.AI

TL;DR: F2O是一个端到端系统，通过分析手术视频中的手势序列来预测术后结果，效果与人工注释相当，并发现了与勃起功能恢复相关的关键模式。


<details>
  <summary>Details</summary>
Motivation: 术中的细粒度行为分析及其对患者结果的影响是一个长期存在的挑战。

Method: F2O利用基于transformer的空间和时间建模以及逐帧分类，在机器人辅助根治性前列腺手术的神经保留步骤中，稳健地检测连续短（约2秒）手势。

Result: F2O在帧级和视频级的手势检测中表现出色（AUC分别为0.80和0.81），其衍生的特征（手势频率、持续时间和转换）预测术后结果的准确性与人类注释相当（0.79 vs. 0.75；95%置信区间重叠）。此外，F2O还捕捉到了与勃起功能恢复相关的关键模式。

Conclusion: F2O系统通过自动化和可解释的评估，为数据驱动的手术反馈和前瞻性临床决策支持奠定了基础。

Abstract: Fine-grained analysis of intraoperative behavior and its impact on patient outcomes remain a longstanding challenge. We present Frame-to-Outcome (F2O), an end-to-end system that translates tissue dissection videos into gesture sequences and uncovers patterns associated with postoperative outcomes. Leveraging transformer-based spatial and temporal modeling and frame-wise classification, F2O robustly detects consecutive short (~2 seconds) gestures in the nerve-sparing step of robot-assisted radical prostatectomy (AUC: 0.80 frame-level; 0.81 video-level). F2O-derived features (gesture frequency, duration, and transitions) predicted postoperative outcomes with accuracy comparable to human annotations (0.79 vs. 0.75; overlapping 95% CI). Across 25 shared features, effect size directions were concordant with small differences (~ 0.07), and strong correlation (r = 0.96, p < 1e-14). F2O also captured key patterns linked to erectile function recovery, including prolonged tissue peeling and reduced energy use. By enabling automatic interpretable assessment, F2O establishes a foundation for data-driven surgical feedback and prospective clinical decision support.

</details>


### [442] [Forgetting-MarI: LLM Unlearning via Marginal Information Regularization](https://arxiv.org/abs/2511.11914)
*Shizhou Xu,Yuan Ni,Stefan Broecker,Thomas Strohmer*

Main category: cs.AI

TL;DR: Forgetting-MarI是一种LLM遗忘框架，通过惩罚边际信息选择性移除数据，优于现有方法，提升隐私保护与模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有遗忘方法在移除特定数据时因过度移除信息而导致模型性能下降的问题，特别是在资源密集型模型如LLMs中。

Method: 引入了Forgetting-MarI框架，通过惩罚边际信息来选择性移除需要遗忘的数据，同时保留需要保留的数据支持的信息。

Result: 实验证明，该方法优于当前最先进的遗忘方法，实现了可靠的遗忘和更好的模型性能保留。

Conclusion: Forgetting-MarI框架通过惩罚边际信息，提供了可证明的不可检测性，代表了在不影响AI系统有效性的前提下，使其更可控且符合隐私和版权法规的重要进展。

Abstract: As AI models are trained on ever-expanding datasets, the ability to remove the influence of specific data from trained models has become essential for privacy protection and regulatory compliance. Unlearning addresses this challenge by selectively removing parametric knowledge from the trained models without retraining from scratch, which is critical for resource-intensive models such as Large Language Models (LLMs). Existing unlearning methods often degrade model performance by removing more information than necessary when attempting to ''forget'' specific data. We introduce Forgetting-MarI, an LLM unlearning framework that provably removes only the additional (marginal) information contributed by the data to be unlearned, while preserving the information supported by the data to be retained. By penalizing marginal information, our method yields an explicit upper bound on the unlearn dataset's residual influence in the trained models, providing provable undetectability. Extensive experiments confirm that our approach outperforms current state-of-the-art unlearning methods, delivering reliable forgetting and better preserved general model performance across diverse benchmarks. This advancement represents an important step toward making AI systems more controllable and compliant with privacy and copyright regulations without compromising their effectiveness.

</details>


### [443] [An Analysis of Architectural Impact on LLM-based Abstract Visual Reasoning: A Systematic Benchmark on RAVEN-FAIR](https://arxiv.org/abs/2511.11916)
*Sinan Urgun,Seçkin Arı*

Main category: cs.AI

TL;DR: GPT-4.1-Mini在抽象视觉推理任务中表现最佳，但不同模型对推理架构的敏感度各异，多轮运行策略更可靠。


<details>
  <summary>Details</summary>
Motivation: 系统评估大型语言模型在抽象视觉推理问题中的性能，探索不同推理架构对模型表现的影响。

Method: 研究评估了四种LLM模型在四种推理架构上的表现，使用RAVEN-FAIR数据集，通过三阶段过程生成视觉响应，并采用SSIM、LPIPS指标及Chain-of-Thought评分和错误类型分析。

Result: GPT-4.1-Mini在所有架构中总体准确率最高，多智能体架构对模型表现有非一致影响，响应覆盖率的差异增加了跨架构直接比较的复杂性。

Conclusion: 研究表明，GPT-4.1-Mini在所有推理架构中表现最优，但推理效果仍因模型而异，且多智能体架构可能影响语义和数值平衡。多轮运行策略被推荐以避免单次评估的不可靠性。

Abstract: This study aims to systematically evaluate the performance of large language models (LLMs) in abstract visual reasoning problems. We examined four LLM models (GPT-4.1-Mini, Claude-3.5-Haiku, Gemini-1.5-Flash, Llama-3.3-70b) utilizing four different reasoning architectures (single-shot, embedding-controlled repetition, self-reflection, and multi-agent) on the RAVEN-FAIR dataset. Visual responses generated through a three-stage process (JSON extraction, LLM reasoning, and Tool Function) were evaluated using SSIM and LPIPS metrics; Chain-of-Thought scores and error types (semantic hallucination, numeric misperception) were analyzed. Results demonstrate that GPT-4.1-Mini consistently achieved the highest overall accuracy across all architectures, indicating a strong reasoning capability. While the multi-agent architecture occasionally altered semantic and numeric balance across models, these effects were not uniformly beneficial. Instead, each model exhibited distinct sensitivity patterns to architectural design, underscoring that reasoning effectiveness remains model-specific. Variations in response coverage further emerged as a confounding factor that complicates direct cross-architecture comparison. To estimate the upper-bound performance of each configuration, we report the best of five independent runs, representing a best-case scenario rather than an averaged outcome. This multi-run strategy aligns with recent recommendations, which emphasize that single-run evaluations are fragile and may lead to unreliable conclusions.

</details>


### [444] [Looking Forward: Challenges and Opportunities in Agentic AI Reliability](https://arxiv.org/abs/2511.11921)
*Liudong Xing,Janet,Lin*

Main category: cs.AI

TL;DR: 本章讨论了代理型AI系统可靠性的挑战与未来方向，包括级联失败、动态环境等问题，并提出了相关研究建议。


<details>
  <summary>Details</summary>
Motivation: 旨在解决代理型AI系统在复杂环境中的可靠性问题，并减少级联失败的风险。

Method: 通过分析动态环境、不一致任务执行、不可预测的涌现行为及资源密集型可靠性机制等挑战，探讨了相关研究问题。

Result: 提出了多个开放研究问题和研究方向，为未来可靠AI系统的开发提供了指导。

Conclusion: 本章探讨了构建可靠AI系统（尤其是代理型AI系统）的未来发展与挑战，提出了多个开放研究问题，并讨论了测试和评估代理型AI系统可靠性的研究方向。

Abstract: This chapter presents perspectives for challenges and future development in building reliable AI systems, particularly, agentic AI systems. Several open research problems related to mitigating the risks of cascading failures are discussed. The chapter also sheds lights on research challenges and opportunities in aspects including dynamic environments, inconsistent task execution, unpredictable emergent behaviors, as well as resource-intensive reliability mechanisms. In addition, several research directions along the line of testing and evaluating reliability of agentic AI systems are also discussed.

</details>


### [445] [A Neuromorphic Architecture for Scalable Event-Based Control](https://arxiv.org/abs/2511.11924)
*Yongkang Huo,Fulvio Forni,Rodolphe Sepulchre*

Main category: cs.AI

TL;DR: The paper presents 'rebound Winner-Take-All (RWTA)' as a scalable neuromorphic control architecture, blending discrete and continuous computation, validated by a snake robot design.


<details>
  <summary>Details</summary>
Motivation: The motivation is to develop a neuromorphic control architecture that combines the reliability of discrete computation with the tunability of continuous regulation, addressing both rhythmic generation and decision-making.

Method: The method involves combining winner-take-all state machines with excitable biophysical circuits to create a scalable neuromorphic control architecture. The approach is event-based and unified in physical modeling.

Result: The result is a versatile, robust, and modular architecture, illustrated through the design of a snake robot's nervous system.

Conclusion: The paper concludes that the 'rebound Winner-Take-All (RWTA)' motif successfully integrates discrete computation and continuous regulation, demonstrating its effectiveness through a snake robot's nervous system design.

Abstract: This paper introduces the ``rebound Winner-Take-All (RWTA)" motif as the basic element of a scalable neuromorphic control architecture. From the cellular level to the system level, the resulting architecture combines the reliability of discrete computation and the tunability of continuous regulation: it inherits the discrete computation capabilities of winner-take-all state machines and the continuous tuning capabilities of excitable biophysical circuits. The proposed event-based framework addresses continuous rhythmic generation and discrete decision-making in a unified physical modeling language. We illustrate the versatility, robustness, and modularity of the architecture through the nervous system design of a snake robot.

</details>


### [446] [Augmenting The Weather: A Hybrid Counterfactual-SMOTE Algorithm for Improving Crop Growth Prediction When Climate Changes](https://arxiv.org/abs/2511.11945)
*Mohammed Temraz,Mark T Keane*

Main category: cs.AI

TL;DR: 本文提出CFA-SMOTE方法，结合反事实和SMOTE技术，通过生成合成极端气候数据点，有效提升气候变化预测性能。


<details>
  <summary>Details</summary>
Motivation: 气候变化导致的数据分布变化和极端天气事件的增加，使得传统基于历史数据的机器学习方法难以应对。现有的解决方案在处理气候异常数据时表现不佳，尤其是缺乏足够少数类实例的情况。

Method: 提出了一种名为Counterfactual-Based SMOTE (CFA-SMOTE)的新型数据增强方法，结合了可解释AI中的反事实方法和SMOTE类不平衡处理方法，生成合成数据点以代表极端气候事件。

Result: 实验结果表明，CFA-SMOTE在不同类不平衡比例下，均优于基准的反事实和类不平衡处理方法，显著提升了预测性能。

Conclusion: CFA-SMOTE方法通过结合反事实方法和SMOTE类不平衡处理方法，有效提高了在气候变化数据中的预测性能，特别是在处理极端天气事件的预测上。

Abstract: In recent years, humanity has begun to experience the catastrophic effects of climate change as economic sectors (such as agriculture) struggle with unpredictable and extreme weather events. Artificial Intelligence (AI) should help us handle these climate challenges but its most promising solutions are not good at dealing with climate-disrupted data; specifically, machine learning methods that work from historical data-distributions, are not good at handling out-of-distribution, outlier events. In this paper, we propose a novel data augmentation method, that treats the predictive problems around climate change as being, in part, due to class-imbalance issues; that is, prediction from historical datasets is difficult because, by definition, they lack sufficient minority-class instances of "climate outlier events". This novel data augmentation method -- called Counterfactual-Based SMOTE (CFA-SMOTE) -- combines an instance-based counterfactual method from Explainable AI (XAI) with the well-known class-imbalance method, SMOTE. CFA-SMOTE creates synthetic data-points representing outlier, climate-events that augment the dataset to improve predictive performance. We report comparative experiments using this CFA-SMOTE method, comparing it to benchmark counterfactual and class-imbalance methods under different conditions (i.e., class-imbalance ratios). The focal climate-change domain used relies on predicting grass growth on Irish dairy farms, during Europe-wide drought and forage crisis of 2018.

</details>


### [447] [LLM-Assisted Formalization Enables Deterministic Detection of Statutory Inconsistency in the Internal Revenue Code](https://arxiv.org/abs/2511.11954)
*Borchuluun Yadamsuren,Steven Keith Platt,Miguel Diaz*

Main category: cs.AI

TL;DR: 混合神经符号框架结合LLM与Prolog，成功实现法定不一致性的确定性检测，优于纯LLM方法。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在税务领域的应用较少，尤其是在层次化处理和深度结构化推理方面存在挑战。研究旨在填补这一空白，探索如何结合LLM与符号逻辑提升法定不一致性检测的准确性和可靠性。

Method: 研究使用GPT-4o将美国《国内税收法典》（IRC）的条款翻译为Prolog规则，并通过SWISH进行优化。随后，通过自然语言提示和Prolog增强提示测试不一致性检测效果，并与纯符号逻辑方法对比。

Result: 实验显示，纯自然语言提示的GPT-4o检测到不一致性的准确率为33%，而Prolog增强提示的准确率为66%，但后者规则覆盖不全。纯Prolog模型则表现出确定性、可重复性，并能自主识别不一致性。

Conclusion: 该研究证明，结合大型语言模型（LLMs）与符号逻辑（如Prolog）的混合神经符号框架，能够实现复杂法律中法定不一致性的确定性检测，提供透明且可靠的结果。

Abstract: This study introduces a hybrid neuro-symbolic framework that achieves deterministic detection of statutory inconsistency in complex law. We use the U.S. Internal Revenue Code (IRC) as a case study because its complexity makes it a fertile domain for identifying conflicts. Our research offers a solution for detecting inconsistent provisions by combining Large Language Models (LLMs) with symbolic logic.
  LLM-based methods can support compliance, fairness, and statutory drafting, yet tax-specific applications remain sparse. A key challenge is that such models struggle with hierarchical processing and deep structured reasoning, especially over long text.
  This research addresses these gaps through experiments using GPT-4o, GPT-5, and Prolog. GPT-4o was first used to translate Section 121 into Prolog rules and refine them in SWISH. These rules were then incorporated into prompts to test whether Prolog-augmented prompting improved GPT-4o's inconsistency detection. GPT-4o, whether prompted with natural language alone or with Prolog augmentation, detected the inconsistency in only one of three strategies (33 percent accuracy), but its reasoning quality differed: natural-language prompting achieved 100 percent rule coverage, while Prolog-augmented prompting achieved 66 percent, indicating more incomplete statutory analysis.
  In contrast to probabilistic prompting, the hybrid Prolog model produced deterministic and reproducible results. Guided by GPT-5 for refinement, the model formalized the IRC section's competing interpretations and successfully detected an inconsistency zone. Validation tests confirm that the Prolog implementation is accurate, internally consistent, deterministic, and capable of autonomously identifying inconsistencies. These findings show that LLM-assisted formalization, anchored in symbolic logic, enables transparent and reliable statutory inconsistency detection.

</details>


### [448] [Improving Autoformalization Using Direct Dependency Retrieval](https://arxiv.org/abs/2511.11990)
*Shaoqi Wang,Lu Yu,Chunjie Yang*

Main category: cs.AI

TL;DR: 提出基于DDR的检索增强框架，解决了自动形式化声明中上下文感知不足和依赖检索效率低的问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏上下文感知能力，导致形式定义和定理的幻觉，且检索增强方法在形式库依赖检索中表现不佳，难以有效利用日益增长的公共数据集。

Method: 提出了一种基于DDR（直接依赖检索）的新检索增强框架，通过从自然语言数学描述中直接生成候选库依赖项，并利用高效的后缀数组检查验证其在形式库中的存在。

Result: DDR模型在检索精度和召回率上显著优于现有技术（SOTA）方法，构建了一个包含50万样本的依赖检索数据集，并微调了一个高精度DDR模型。

Conclusion: 基于DDR的检索增强框架在自动形式化声明中表现出色，显著提升了检索精度和召回率，使自动形式化工具在单次尝试准确性和多次尝试稳定性上均优于传统方法。

Abstract: The convergence of deep learning and formal mathematics has spurred research in formal verification. Statement autoformalization, a crucial first step in this process, aims to translate informal descriptions into machine-verifiable representations but remains a significant challenge. The core difficulty lies in the fact that existing methods often suffer from a lack of contextual awareness, leading to hallucination of formal definitions and theorems. Furthermore, current retrieval-augmented approaches exhibit poor precision and recall for formal library dependency retrieval, and lack the scalability to effectively leverage ever-growing public datasets. To bridge this gap, we propose a novel retrieval-augmented framework based on DDR (\textit{Direct Dependency Retrieval}) for statement autoformalization. Our DDR method directly generates candidate library dependencies from natural language mathematical descriptions and subsequently verifies their existence within the formal library via an efficient suffix array check. Leveraging this efficient search mechanism, we constructed a dependency retrieval dataset of over 500,000 samples and fine-tuned a high-precision DDR model. Experimental results demonstrate that our DDR model significantly outperforms SOTA methods in both retrieval precision and recall. Consequently, an autoformalizer equipped with DDR shows consistent performance advantages in both single-attempt accuracy and multi-attempt stability compared to models using traditional selection-based RAG methods.

</details>


### [449] [Look As You Think: Unifying Reasoning and Visual Evidence Attribution for Verifiable Document RAG via Reinforcement Learning](https://arxiv.org/abs/2511.12003)
*Shuochen Liu,Pengfei Luo,Chao Zhang,Yuhao Chen,Haotian Zhang,Qi Liu,Xin Kou,Tong Xu,Enhong Chen*

Main category: cs.AI

TL;DR: 本文提出了一种名为Chain-of-Evidence（CoE）的范式，结合了Chain-of-Thought（CoT）推理和视觉证据归因，通过强化学习框架Look As You Think（LAT）训练模型生成可验证的推理路径。


<details>
  <summary>Details</summary>
Motivation: 现有方法在视觉文档检索增强生成（VD-RAG）中缺乏细粒度监督和推理过程中的渐进可追溯性。

Method: 提出CoE范式，通过边界框和页面索引将推理步骤中的参考元素与特定区域关联；开发LAT框架，通过强化学习训练模型生成一致性归因的推理路径。

Result: 实验表明，LAT在单图和跨域多图设置中均显著提升模型性能，软精确匹配（EM）平均提升8.23%，IoU@0.5提升47.0%。

Conclusion: LAT不仅优于直接生成归因答案的监督微调基线，还展示了更强的跨领域泛化能力。

Abstract: Aiming to identify precise evidence sources from visual documents, visual evidence attribution for visual document retrieval-augmented generation (VD-RAG) ensures reliable and verifiable predictions from vision-language models (VLMs) in multimodal question answering. Most existing methods adopt end-to-end training to facilitate intuitive answer verification. However, they lack fine-grained supervision and progressive traceability throughout the reasoning process. In this paper, we introduce the Chain-of-Evidence (CoE) paradigm for VD-RAG. CoE unifies Chain-of-Thought (CoT) reasoning and visual evidence attribution by grounding reference elements in reasoning steps to specific regions with bounding boxes and page indexes. To enable VLMs to generate such evidence-grounded reasoning, we propose Look As You Think (LAT), a reinforcement learning framework that trains models to produce verifiable reasoning paths with consistent attribution. During training, LAT evaluates the attribution consistency of each evidence region and provides rewards only when the CoE trajectory yields correct answers, encouraging process-level self-verification. Experiments on vanilla Qwen2.5-VL-7B-Instruct with Paper- and Wiki-VISA benchmarks show that LAT consistently improves the vanilla model in both single- and multi-image settings, yielding average gains of 8.23% in soft exact match (EM) and 47.0% in IoU@0.5. Meanwhile, LAT not only outperforms the supervised fine-tuning baseline, which is trained to directly produce answers with attribution, but also exhibits stronger generalization across domains.

</details>


### [450] [Adaptive Diagnostic Reasoning Framework for Pathology with Multimodal Large Language Models](https://arxiv.org/abs/2511.12008)
*Yunqi Hong,Johnson Kao,Liam Edwards,Nein-Tzu Liu,Chung-Yen Huang,Alex Oliveira-Kowaleski,Cho-Jui Hsieh,Neil Y. C. Lin*

Main category: cs.AI

TL;DR: RECAP-PATH是一个可解释的框架，通过自学习范式将多模态大型语言模型从被动模式识别转向证据关联的诊断推理，提升了病理学AI的可信度和准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管AI工具在病理学中提升了筛查效率、标准化了量化并揭示了预后模式，但大多数系统仍缺乏人类可读的推理，限制了其采用。

Method: RECAP-PATH采用两阶段学习过程：多样化阶段扩展病理学风格的解释，优化阶段则针对准确性进行细化。

Result: 在乳腺癌和前列腺癌数据集上的评估显示，RECAP-PATH生成的解释与专家评估一致，并在诊断准确性上显著优于基线方法。

Conclusion: RECAP-PATH通过结合视觉理解与推理，提供了临床可信赖的AI，并展示了实现证据关联解释的通用路径。

Abstract: AI tools in pathology have improved screening throughput, standardized quantification, and revealed prognostic patterns that inform treatment. However, adoption remains limited because most systems still lack the human-readable reasoning needed to audit decisions and prevent errors. We present RECAP-PATH, an interpretable framework that establishes a self-learning paradigm, shifting off-the-shelf multimodal large language models from passive pattern recognition to evidence-linked diagnostic reasoning. At its core is a two-phase learning process that autonomously derives diagnostic criteria: diversification expands pathology-style explanations, while optimization refines them for accuracy. This self-learning approach requires only small labeled sets and no white-box access or weight updates to generate cancer diagnoses. Evaluated on breast and prostate datasets, RECAP-PATH produced rationales aligned with expert assessment and delivered substantial gains in diagnostic accuracy over baselines. By uniting visual understanding with reasoning, RECAP-PATH provides clinically trustworthy AI and demonstrates a generalizable path toward evidence-linked interpretation.

</details>


### [451] [Intelligent Collaborative Optimization for Rubber Tyre Film Production Based on Multi-path Differentiated Clipping Proximal Policy Optimization](https://arxiv.org/abs/2511.12060)
*Yinghao Ruan,Wei Pang,Shuaihao Liu,Huili Yang,Leyi Han,Xinghui Dong*

Main category: cs.AI

TL;DR: MPD-PPO算法通过多分支策略和梯度裁剪，提升了轮胎薄膜生产的控制精度和效率，适用于动态工业环境。


<details>
  <summary>Details</summary>
Motivation: 智能制造的兴起解决了传统集中调度和生产线配置的局限性，尤其是在应对动态生产需求方面。轮胎制造系统的复杂性使得多子系统的有效协调成为一项关键而艰巨的任务。

Method: 引入了一种深度强化学习算法：多路径差异化裁剪近端策略优化（MPD-PPO），采用多分支策略架构和差异化梯度裁剪约束，以稳定高效地进行高维策略更新。

Result: 在橡胶轮胎薄膜生产的宽度和厚度控制实验中，MPD-PPO算法在调谐精度和操作效率上均表现出显著改进，成功应对了高维度、多目标权衡和动态适应等关键挑战。

Conclusion: MPD-PPO算法通过多分支策略架构和差异化梯度裁剪约束，显著提升了橡胶轮胎薄膜生产中宽度和厚度控制的调谐精度和操作效率，为轮胎制造中的实时工业部署提供了增强的性能和生产稳定性。

Abstract: The advent of smart manufacturing is addressing the limitations of traditional centralized scheduling and inflexible production line configurations in the rubber tyre industry, especially in terms of coping with dynamic production demands. Contemporary tyre manufacturing systems form complex networks of tightly coupled subsystems pronounced nonlinear interactions and emergent dynamics. This complexity renders the effective coordination of multiple subsystems, posing an essential yet formidable task. For high-dimensional, multi-objective optimization problems in this domain, we introduce a deep reinforcement learning algorithm: Multi-path Differentiated Clipping Proximal Policy Optimization (MPD-PPO). This algorithm employs a multi-branch policy architecture with differentiated gradient clipping constraints to ensure stable and efficient high-dimensional policy updates. Validated through experiments on width and thickness control in rubber tyre film production, MPD-PPO demonstrates substantial improvements in both tuning accuracy and operational efficiency. The framework successfully tackles key challenges, including high dimensionality, multi-objective trade-offs, and dynamic adaptation, thus delivering enhanced performance and production stability for real-time industrial deployment in tyre manufacturing.

</details>


### [452] [Bayesian Optimization in Language Space: An Eval-Efficient AI Self-Improvement Framework](https://arxiv.org/abs/2511.12063)
*Enoch Hyunwook Kang,Hema Yoganarasimhan*

Main category: cs.AI

TL;DR: 本文提出T-BoN BO框架，通过结合Best-of-N和文本梯度优化评估效率，在广告对齐任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 在许多社会应用中，评估生成解决方案的成本远高于生成成本。传统贝叶斯优化（BO）在语言领域的直接扩展因难以估计合适的获取函数而具有挑战性。本文旨在解决这一问题，优化评估效率。

Method: 本文结合了Best-of-N选择策略和简单文本梯度，证明了其可以统计模拟经典UCB获取函数的梯度行为，从而在评估效率方面实现最优探索。基于这一发现，提出了T-BoN BO框架。

Result: 通过将T-BoN BO应用于自动广告对齐任务，实验验证了其在评估效率方面的优越性能，超越了当前流行的最先进基线方法。

Conclusion: 本文提出了一种名为T-BoN BO的新型语言空间贝叶斯优化框架，通过结合Best-of-N选择策略和简单文本梯度，有效解决了在语言模型中直接估计获取函数的难题，并在自动广告对齐任务中验证了其优越性能。

Abstract: Large Language Models (LLMs) have recently enabled self-improving AI, i.e., AI that iteratively generates, evaluates, and refines its own outcomes. Recent studies have shown that self-improving AI focusing on prompt optimization can outperform state-of-the-art reinforcement-learning fine-tuned LLMs. Here, their `performance' is typically measured by query efficiency - the number of LLM-generated solution samples required to meet a certain performance threshold. However, in many societal applications, the primary limitation is not generating new solutions but evaluating them. For instance, evaluating an ad's effectiveness requires significant human feedback, which is far more costly and time-consuming than generating a candidate ad. To optimize for the evaluation efficiency objective, a natural approach is to extend Bayesian Optimization (BO), a framework proven optimal for evaluation efficiency, to the language domain. However, the difficulty of directly estimating suitable acquisition functions in LLMs' minds makes this extension challenging. This paper overcomes this challenge by proving that the combination of the simple and widely used Best-of-N selection strategy and simple textual gradients (i.e., textual edits from a critic model) statistically emulates the behavior of the gradients on the canonical UCB acquisition function, which induces optimal exploration in terms of evaluation efficiency. Based on this result, we propose TextGrad-Best-of-N Bayesian Optimization (T-BoN BO), a simple and eval-efficient language-space Bayesian optimization framework for AI self-improvement. We also empirically validate T-BoN BO by applying it to automated ad alignment tasks for persona distribution, demonstrating its superior performance compared to popular state-of-the-art baselines.

</details>


### [453] [No-Regret Strategy Solving in Imperfect-Information Games via Pre-Trained Embedding](https://arxiv.org/abs/2511.12083)
*Yanchang Fu,Shengda Liu,Pei Xu,Kaiqi Huang*

Main category: cs.AI

TL;DR: Embedding CFR算法通过低维嵌入空间预训练信息集，优化策略求解，显著提升德州扑克AI的表现。


<details>
  <summary>Details</summary>
Motivation: 现有AI方法依赖预训练的离散聚类进行抽象，但其硬分类不可逆地丢失了信息集间的量化细微差异，影响了策略求解的质量。

Method: 提出Embedding CFR算法，将孤立信息集的特征预训练并嵌入到低维连续空间中，通过后悔积累和策略更新在该空间中进行策略求解。

Result: 实验证明，在相同空间开销下，Embedding CFR比基于聚类的抽象算法具有更快的可剥削性收敛速度。

Conclusion: Embedding CFR算法在解决大规模不完全信息扩展形式游戏（如德州扑克）中表现出色，通过低维嵌入空间预训练信息集抽象，显著提高了策略求解的效率和质量。

Abstract: High-quality information set abstraction remains a core challenge in solving large-scale imperfect-information extensive-form games (IIEFGs)-such as no-limit Texas Hold'em-where the finite nature of spatial resources hinders strategy solving over the full game. State-of-the-art AI methods rely on pre-trained discrete clustering for abstraction, yet their hard classification irreversibly loses critical information: specifically, the quantifiable subtle differences between information sets-vital for strategy solving-thereby compromising the quality of such solving. Inspired by the word embedding paradigm in natural language processing, this paper proposes the Embedding CFR algorithm, a novel approach for solving strategies in IIEFGs within an embedding space. The algorithm pre-trains and embeds features of isolated information sets into an interconnected low-dimensional continuous space, where the resulting vectors more precisely capture both the distinctions and connections between information sets. Embedding CFR presents a strategy-solving process driven by regret accumulation and strategy updates within this embedding space, with accompanying theoretical analysis verifying its capacity to reduce cumulative regret. Experiments on poker show that with the same spatial overhead, Embedding CFR achieves significantly faster exploitability convergence compared to cluster-based abstraction algorithms, confirming its effectiveness. Furthermore, to our knowledge, it is the first algorithm in poker AI that pre-trains information set abstractions through low-dimensional embedding for strategy solving.

</details>


### [454] [KrwEmd: Revising the Imperfect-Recall Abstraction from Forgetting Everything](https://arxiv.org/abs/2511.12089)
*Yanchang Fu,Qiyue Yin,Shengda Liu,Pei Xu,Kaiqi Huang*

Main category: cs.AI

TL;DR: KrwEmd是首个针对德州扑克等游戏中过度抽象问题的实用算法，通过结合历史信息的k-recall winrate特征和earth mover's distance聚类，显著提升AI性能。


<details>
  <summary>Details</summary>
Motivation: 解决德州扑克等不完全信息游戏中由于过度抽象（尤其是极端不完美回忆抽象完全丢弃历史信息）导致的AI性能下降问题。

Method: 本文提出了KrwEmd算法，首先引入k-recall winrate特征，结合未来和关键历史游戏信息定性区分信号观察信息集并定量捕捉其相似性；然后利用earth mover's distance对信号观察信息集进行聚类。

Result: 实验结果表明，KrwEmd算法相比现有算法显著提升了AI的游戏表现。

Conclusion: KrwEmd算法通过引入k-recall winrate特征和earth mover's distance聚类，显著提升了AI在德州扑克等不完全信息游戏中的表现，解决了传统不完美回忆抽象方法过度丢弃历史信息的问题。

Abstract: Excessive abstraction is a critical challenge in hand abstraction-a task specific to games like Texas hold'em-when solving large-scale imperfect-information games, as it impairs AI performance. This issue arises from extreme implementations of imperfect-recall abstraction, which entirely discard historical information. This paper presents KrwEmd, the first practical algorithm designed to address this problem. We first introduce the k-recall winrate feature, which not only qualitatively distinguishes signal observation infosets by leveraging both future and, crucially, historical game information, but also quantitatively captures their similarity. We then develop the KrwEmd algorithm, which clusters signal observation infosets using earth mover's distance to measure discrepancies between their features. Experimental results demonstrate that KrwEmd significantly improves AI gameplay performance compared to existing algorithms.

</details>


### [455] [MetaGDPO: Alleviating Catastrophic Forgetting with Metacognitive Knowledge through Group Direct Preference Optimization](https://arxiv.org/abs/2511.12113)
*Lanxue Zhang,Yuqiang Xie,Fang Fang,Fanglong Dong,Rui Liu,Yanan Cao*

Main category: cs.AI

TL;DR: 论文提出结合元认知知识的数据集和GDPO训练方法，有效解决小模型灾难性遗忘问题，提升推理性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型虽具备强大推理能力，但在压缩至小模型时面临灾难性遗忘问题，现有数据集和微调方法对此效果不佳。

Method: 作者构建了一个包含5K实例的数据集，涵盖多种推理任务并融入元认知知识。在训练方面，提出了GDPO（Group Direction Preference Optimization）方法，适用于资源有限场景，能有效近似GRPO性能。

Result: 实验证明，该方法显著减轻了灾难性遗忘，并提升了小模型的推理表现。

Conclusion: 该论文提出的综合解决方案，包括数据集构建和GDPO训练方法，有效缓解了小模型中的灾难性遗忘问题，并提升了推理性能。

Abstract: Large Language Models demonstrate strong reasoning capabilities, which can be effectively compressed into smaller models. However, existing datasets and fine-tuning approaches still face challenges that lead to catastrophic forgetting, particularly for models smaller than 8B. First, most datasets typically ignore the relationship between training data knowledge and the model's inherent abilities, making it difficult to preserve prior knowledge. Second, conventional training objectives often fail to constrain inherent knowledge preservation, which can result in forgetting of previously learned skills. To address these issues, we propose a comprehensive solution that alleviates catastrophic forgetting from both the data and fine-tuning approach perspectives. On the data side, we construct a dataset of 5K instances that covers multiple reasoning tasks and incorporates metacognitive knowledge, making it more tolerant and effective for distillation into smaller models. We annotate the metacognitive knowledge required to solve each question and filter the data based on task knowledge and the model's inherent skills. On the training side, we introduce GDPO (Group Direction Preference Optimization), which is better suited for resource-limited scenarios and can efficiently approximate the performance of GRPO. Guided by the large model and by implicitly constraining the optimization path through a reference model, GDPO enables more effective knowledge transfer from the large model and constrains excessive parameter drift. Extensive experiments demonstrate that our approach significantly alleviates catastrophic forgetting and improves reasoning performance on smaller models.

</details>


### [456] [RTMol: Rethinking Molecule-text Alignment in a Round-trip View](https://arxiv.org/abs/2511.12135)
*Letian Chen,Runhan Shi,Gufeng Yu,Yang Yang*

Main category: cs.AI

TL;DR: RTMol提出了一种自监督往返学习框架，显著提升分子与文本的双向对齐效果，解决了现有方法的化学准确性不足等问题。


<details>
  <summary>Details</summary>
Motivation: 现有的分子描述与文本生成方法存在化学准确性不足、数据模糊及双向不一致等问题，RTMol旨在解决这些局限性。

Method: RTMol引入了一种双向对齐框架，结合了新型往返评估指标，并支持无需配对分子-文本语料库的无监督训练。

Result: 实验表明，RTMol将双向对齐性能提升了高达47%，并在不同LLMs上表现优异。

Conclusion: RTMol通过自监督的往返学习框架，显著提升了分子与文本之间的双向对齐性能，为联合分子-文本理解与生成提供了有效范例。

Abstract: Aligning molecular sequence representations (e.g., SMILES notations) with textual descriptions is critical for applications spanning drug discovery, materials design, and automated chemical literature analysis. Existing methodologies typically treat molecular captioning (molecule-to-text) and text-based molecular design (text-to-molecule) as separate tasks, relying on supervised fine-tuning or contrastive learning pipelines. These approaches face three key limitations: (i) conventional metrics like BLEU prioritize linguistic fluency over chemical accuracy, (ii) training datasets frequently contain chemically ambiguous narratives with incomplete specifications, and (iii) independent optimization of generation directions leads to bidirectional inconsistency. To address these issues, we propose RTMol, a bidirectional alignment framework that unifies molecular captioning and text-to-SMILES generation through self-supervised round-trip learning. The framework introduces novel round-trip evaluation metrics and enables unsupervised training for molecular captioning without requiring paired molecule-text corpora. Experiments demonstrate that RTMol enhances bidirectional alignment performance by up to 47% across various LLMs, establishing an effective paradigm for joint molecule-text understanding and generation.

</details>


### [457] [Incremental Maintenance of DatalogMTL Materialisations](https://arxiv.org/abs/2511.12169)
*Kaiyue Zhao,Dingqi Chen,Shaoyu Wang,Pan Hu*

Main category: cs.AI

TL;DR: DRedMTL是一种针对DatalogMTL的增量推理算法，显著提升动态更新处理效率，实验验证其性能优势。


<details>
  <summary>Details</summary>
Motivation: 现有DatalogMTL推理方法（如基于物化和自动机的方法）虽然完备，但缺乏对动态更新的高效支持，而实际应用常需要频繁数据更新。

Method: DRedMTL基于经典的DRed算法，通过专门设计的操作符处理DatalogMTL物化的周期性表示，支持高效增量更新。

Result: 实验结果表明，DRedMTL在多个公开数据集上表现优异，性能有时比重新物化高出数个数量级。

Conclusion: DRedMTL是一种高效的增量推理算法，用于处理DatalogMTL中的动态更新，实验证明其在性能上显著优于重新物化方法。

Abstract: DatalogMTL extends the classical Datalog language with metric temporal logic (MTL), enabling expressive reasoning over temporal data. While existing reasoning approaches, such as materialisation based and automata based methods, offer soundness and completeness, they lack support for handling efficient dynamic updates, a crucial requirement for real-world applications that involve frequent data updates. In this work, we propose DRedMTL, an incremental reasoning algorithm for DatalogMTL with bounded intervals. Our algorithm builds upon the classical DRed algorithm, which incrementally updates the materialisation of a Datalog program. Unlike a Datalog materialisation which is in essence a finite set of facts, a DatalogMTL materialisation has to be represented as a finite set of facts plus periodic intervals indicating how the full materialisation can be constructed through unfolding. To cope with this, our algorithm is equipped with specifically designed operators to efficiently handle such periodic representations of DatalogMTL materialisations. We have implemented this approach and tested it on several publicly available datasets. Experimental results show that DRedMTL often significantly outperforms rematerialisation, sometimes by orders of magnitude.

</details>


### [458] [Debate over Mixed-knowledge: A Robust Multi-Agent Framework for Incomplete Knowledge Graph Question Answering](https://arxiv.org/abs/2511.12208)
*Jilong Liu,Pengyang Shao,Wei Qin,Fei Liu,Yonghui Yang,Richang Hong*

Main category: cs.AI

TL;DR: DoM框架通过多智能体辩论动态整合结构化和非结构化知识，解决IKGQA问题，并在新数据集上验证有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法自适应地融合多源知识，且IKGQA数据集未能真实反映知识不完整的随机性和不可预测性。

Method: 提出Debate over Mixed-knowledge (DoM)框架，基于多智能体辩论范式，通过双代理（KG和RAG）检索证据，法官智能体评估和聚合中间答案。

Result: 实验表明DoM在多个基准测试中优于现有方法。

Conclusion: DoM框架通过动态整合结构化和非结构化知识，显著提升了IKGQA的性能，并在新构建的数据集上验证了其优越性。

Abstract: Knowledge Graph Question Answering (KGQA) aims to improve factual accuracy by leveraging structured knowledge. However, real-world Knowledge Graphs (KGs) are often incomplete, leading to the problem of Incomplete KGQA (IKGQA). A common solution is to incorporate external data to fill knowledge gaps, but existing methods lack the capacity to adaptively and contextually fuse multiple sources, failing to fully exploit their complementary strengths. To this end, we propose Debate over Mixed-knowledge (DoM), a novel framework that enables dynamic integration of structured and unstructured knowledge for IKGQA. Built upon the Multi-Agent Debate paradigm, DoM assigns specialized agents to perform inference over knowledge graphs and external texts separately, and coordinates their outputs through iterative interaction. It decomposes the input question into sub-questions, retrieves evidence via dual agents (KG and Retrieval-Augmented Generation, RAG), and employs a judge agent to evaluate and aggregate intermediate answers. This collaboration exploits knowledge complementarity and enhances robustness to KG incompleteness. In addition, existing IKGQA datasets simulate incompleteness by randomly removing triples, failing to capture the irregular and unpredictable nature of real-world knowledge incompleteness. To address this, we introduce a new dataset, Incomplete Knowledge Graph WebQuestions, constructed by leveraging real-world knowledge updates. These updates reflect knowledge beyond the static scope of KGs, yielding a more realistic and challenging benchmark. Through extensive experiments, we show that DoM consistently outperforms state-of-the-art baselines.

</details>


### [459] [ViTE: Virtual Graph Trajectory Expert Router for Pedestrian Trajectory Prediction](https://arxiv.org/abs/2511.12214)
*Ruochen Li,Zhanxing Zhu,Tanqiu Qiao,Hubert P. H. Shum*

Main category: cs.AI

TL;DR: ViTE通过虚拟图和专家路由器，高效建模行人轨迹的高阶交互，性能优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在行人轨迹预测中无法平衡交互建模深度与计算效率的问题。

Method: 提出了ViTE框架，包含虚拟图模块（用于建模长距离和高阶交互）和专家路由器模块（基于社交上下文自适应选择交互专家）。

Result: 在ETH/UCY、NBA和SDD三个基准测试上均实现了最先进的性能。

Conclusion: ViTE框架通过引入虚拟图和专家路由器的组合，有效解决了行人轨迹预测中的高阶交互建模问题，且在实际应用中展示了高效的性能。

Abstract: Pedestrian trajectory prediction is critical for ensuring safety in autonomous driving, surveillance systems, and urban planning applications. While early approaches primarily focus on one-hop pairwise relationships, recent studies attempt to capture high-order interactions by stacking multiple Graph Neural Network (GNN) layers. However, these approaches face a fundamental trade-off: insufficient layers may lead to under-reaching problems that limit the model's receptive field, while excessive depth can result in prohibitive computational costs. We argue that an effective model should be capable of adaptively modeling both explicit one-hop interactions and implicit high-order dependencies, rather than relying solely on architectural depth. To this end, we propose ViTE (Virtual graph Trajectory Expert router), a novel framework for pedestrian trajectory prediction. ViTE consists of two key modules: a Virtual Graph that introduces dynamic virtual nodes to model long-range and high-order interactions without deep GNN stacks, and an Expert Router that adaptively selects interaction experts based on social context using a Mixture-of-Experts design. This combination enables flexible and scalable reasoning across varying interaction patterns. Experiments on three benchmarks (ETH/UCY, NBA, and SDD) demonstrate that our method consistently achieves state-of-the-art performance, validating both its effectiveness and practical efficiency.

</details>


### [460] [Beyond World Models: Rethinking Understanding in AI Models](https://arxiv.org/abs/2511.12239)
*Tarun Gupta,Danish Pruthi*

Main category: cs.AI

TL;DR: 论文通过哲学案例研究，探讨了世界模型是否足以模拟人类理解，发现其在某些方面存在局限性。


<details>
  <summary>Details</summary>
Motivation: 人类拥有心理世界模型，研究AI模型中是否存在类似表征可能表明它们以类似人类的方式“理解”世界。

Method: 使用了哲学科学文献中的案例研究，重点关注世界模型能力与人类理解之间差异显著的领域。

Result: 研究发现世界模型在表征人类理解方面存在局限，尤其在特定哲学分析中差异显著。

Conclusion: 该论文通过哲学案例分析，探讨了世界模型框架是否足以表征人类水平的理解，揭示了其局限性。

Abstract: World models have garnered substantial interest in the AI community. These are internal representations that simulate aspects of the external world, track entities and states, capture causal relationships, and enable prediction of consequences. This contrasts with representations based solely on statistical correlations. A key motivation behind this research direction is that humans possess such mental world models, and finding evidence of similar representations in AI models might indicate that these models "understand" the world in a human-like way. In this paper, we use case studies from the philosophy of science literature to critically examine whether the world model framework adequately characterizes human-level understanding. We focus on specific philosophical analyses where the distinction between world model capabilities and human understanding is most pronounced. While these represent particular views of understanding rather than universal definitions, they help us explore the limits of world models.

</details>


### [461] [AURA: Development and Validation of an Augmented Unplanned Removal Alert System using Synthetic ICU Videos](https://arxiv.org/abs/2511.12241)
*Junhyuk Seo,Hyeyoon Moon,Kyu-Hwan Jung,Namkee Oh,Taerim Kim*

Main category: cs.AI

TL;DR: AURA是一种基于视觉的风险检测系统，利用合成ICU视频数据集开发，通过姿态估计识别高风险运动模式，展示了隐私保护患者监测的新途径。


<details>
  <summary>Details</summary>
Motivation: 解决重症监护室中非计划性拔管（UE）这一关键患者安全问题，由于获取标注ICU视频数据的伦理和隐私挑战，实时UE检测一直受限。

Method: 利用文本到视频扩散技术生成多样且临床真实的ICU场景视频数据集，通过姿态估计识别两种高风险运动模式：碰撞（手部进入气道管附近空间区域）和躁动（通过跟踪解剖关键点的速度量化）。

Result: 专家评估证实合成数据的真实性，性能评估显示碰撞检测高准确性和躁动识别中等性能。

Conclusion: AURA系统展示了一种开发隐私保护、可复现的患者安全监测系统的新途径，具有在重症监护环境中部署的潜力。

Abstract: Unplanned extubation (UE) remains a critical patient safety concern in intensive care units (ICUs), often leading to severe complications or death. Real-time UE detection has been limited, largely due to the ethical and privacy challenges of obtaining annotated ICU video data. We propose Augmented Unplanned Removal Alert (AURA), a vision-based risk detection system developed and validated entirely on a fully synthetic video dataset. By leveraging text-to-video diffusion, we generated diverse and clinically realistic ICU scenarios capturing a range of patient behaviors and care contexts. The system applies pose estimation to identify two high-risk movement patterns: collision, defined as hand entry into spatial zones near airway tubes, and agitation, quantified by the velocity of tracked anatomical keypoints. Expert assessments confirmed the realism of the synthetic data, and performance evaluations showed high accuracy for collision detection and moderate performance for agitation recognition. This work demonstrates a novel pathway for developing privacy-preserving, reproducible patient safety monitoring systems with potential for deployment in intensive care settings.

</details>


### [462] [Mobile-Agent-RAG: Driving Smart Multi-Agent Coordination with Contextual Knowledge Empowerment for Long-Horizon Mobile Automation](https://arxiv.org/abs/2511.12254)
*Yuxiang Zhou,Jichang Li,Yanhao Zhang,Haonan Lu,Guanbin Li*

Main category: cs.AI

TL;DR: Mobile-Agent-RAG通过分层多智能体框架和双级检索增强技术，显著提升移动代理在长时跨应用任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的移动代理在现实世界、长时跨应用任务中表现不佳，主要原因是过度依赖MLLMs中的静态内部知识，导致高层面规划的战略幻觉和低层面用户界面操作的操作错误。本文的核心见解是，高层面规划和低层面UI操作需要根本不同类型的知识。

Method: 提出了Mobile-Agent-RAG，一个新型分层多智能体框架，集成了双级检索增强技术：在规划阶段引入Manager-RAG以减少战略幻觉，在执行阶段开发Operator-RAG以提高执行准确性。同时构建了两个专门的检索导向知识库以准确传递这些知识类型。

Result: Mobile-Agent-RAG在实验中的表现显著优于现有基线，任务完成率提高了11.0%，步骤效率提高了10.2%。

Conclusion: Mobile-Agent-RAG通过创新的分层多智能体框架和双级检索增强技术，显著提升了移动代理在现实世界、长时跨应用任务中的表现，任务完成率和步骤效率分别提高了11.0%和10.2%，为上下文感知、可靠的多智能体移动自动化建立了稳健的范式。

Abstract: Mobile agents show immense potential, yet current state-of-the-art (SoTA) agents exhibit inadequate success rates on real-world, long-horizon, cross-application tasks. We attribute this bottleneck to the agents' excessive reliance on static, internal knowledge within MLLMs, which leads to two critical failure points: 1) strategic hallucinations in high-level planning and 2) operational errors during low-level execution on user interfaces (UI). The core insight of this paper is that high-level planning and low-level UI operations require fundamentally distinct types of knowledge. Planning demands high-level, strategy-oriented experiences, whereas operations necessitate low-level, precise instructions closely tied to specific app UIs. Motivated by these insights, we propose Mobile-Agent-RAG, a novel hierarchical multi-agent framework that innovatively integrates dual-level retrieval augmentation. At the planning stage, we introduce Manager-RAG to reduce strategic hallucinations by retrieving human-validated comprehensive task plans that provide high-level guidance. At the execution stage, we develop Operator-RAG to improve execution accuracy by retrieving the most precise low-level guidance for accurate atomic actions, aligned with the current app and subtask. To accurately deliver these knowledge types, we construct two specialized retrieval-oriented knowledge bases. Furthermore, we introduce Mobile-Eval-RAG, a challenging benchmark for evaluating such agents on realistic multi-app, long-horizon tasks. Extensive experiments demonstrate that Mobile-Agent-RAG significantly outperforms SoTA baselines, improving task completion rate by 11.0% and step efficiency by 10.2%, establishing a robust paradigm for context-aware, reliable multi-agent mobile automation.

</details>


### [463] [MoralReason: Generalizable Moral Decision Alignment For LLM Agents Using Reasoning-Level Reinforcement Learning](https://arxiv.org/abs/2511.12271)
*Zhiyu An,Wan Du*

Main category: cs.AI

TL;DR: 研究提出了一种方法，通过系统训练使LLM代理能够在新情境中应用特定道德框架，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前方法主要评估而非主动引导大语言模型的道德决策，需解决其在训练分布之外的道德对齐问题。

Method: 采用Group Relative Policy Optimization和复合奖励机制，同时优化决策对齐和框架特定的推理过程。

Result: 实验结果显示，在未见过的道德场景中成功泛化，功利主义框架的对齐分数提高了+0.757，义务论框架提高了+0.450。

Conclusion: 研究证实，通过系统训练，LLM代理能够内化并应用特定道德框架到新情境中，为AI安全提供了关键基础。

Abstract: Large language models are increasingly influencing human moral decisions, yet current approaches focus primarily on evaluating rather than actively steering their moral decisions. We formulate this as an out-of-distribution moral alignment problem, where LLM agents must learn to apply consistent moral reasoning frameworks to scenarios beyond their training distribution. We introduce Moral-Reason-QA, a novel dataset extending 680 human-annotated, high-ambiguity moral scenarios with framework-specific reasoning traces across utilitarian, deontological, and virtue ethics, enabling systematic evaluation of moral generalization in realistic decision contexts. Our learning approach employs Group Relative Policy Optimization with composite rewards that simultaneously optimize decision alignment and framework-specific reasoning processes to facilitate learning of the underlying moral frameworks. Experimental results demonstrate successful generalization to unseen moral scenarios, with softmax-normalized alignment scores improving by +0.757 for utilitarian and +0.450 for deontological frameworks when tested on out-of-distribution evaluation sets. The experiments also reveal training challenges and promising directions that inform future research. These findings establish that LLM agents can be systematically trained to internalize and apply specific moral frameworks to novel situations, providing a critical foundation for AI safety as language models become more integrated into human decision-making processes.

</details>


### [464] [UpBench: A Dynamically Evolving Real-World Labor-Market Agentic Benchmark Framework Built for Human-Centric AI](https://arxiv.org/abs/2511.12306)
*Darvin Yi,Teng Liu,Mattie Terzolo,Lance Hasson,Ayan Sinh,Pablo Mendes,Andrew Rabinovich*

Main category: cs.AI

TL;DR: UpBench是一个基于真实Upwork工作的动态基准，通过专家评估AI在真实劳动力市场中的表现，旨在推动AI与人类合作而非替代的框架。


<details>
  <summary>Details</summary>
Motivation: 现有基准多为静态、合成或领域受限，无法真实反映AI代理在动态、经济意义环境中的表现。

Method: 采用基于真实Upwork平台工作的动态基准，通过专家自由职业者分解任务为详细可验证的接受标准，并对AI提交进行逐项反馈评估。

Result: UpBench通过真实工作任务和专家评估框架，提供了对模型优势、弱点及指令遵循能力的细粒度分析。

Conclusion: UpBench提供了一个可扩展、以人为中心的基准，用于在真实劳动力市场环境中评估AI代理系统，为AI与人类合作而非替代的框架铺平道路。

Abstract: As large language model (LLM) agents increasingly undertake digital work, reliable frameworks are needed to evaluate their real-world competence, adaptability, and capacity for human collaboration. Existing benchmarks remain largely static, synthetic, or domain-limited, providing limited insight into how agents perform in dynamic, economically meaningful environments. We introduce UpBench, a dynamically evolving benchmark grounded in real jobs drawn from the global Upwork labor marketplace. Each task corresponds to a verified client transaction, anchoring evaluation in genuine work activity and financial outcomes. UpBench employs a rubric-based evaluation framework, in which expert freelancers decompose each job into detailed, verifiable acceptance criteria and assess AI submissions with per-criterion feedback. This structure enables fine-grained analysis of model strengths, weaknesses, and instruction-following fidelity beyond binary pass/fail metrics. Human expertise is integrated throughout the data pipeline (from job curation and rubric construction to evaluation) ensuring fidelity to real professional standards and supporting research on human-AI collaboration. By regularly refreshing tasks to reflect the evolving nature of online work, UpBench provides a scalable, human-centered foundation for evaluating agentic systems in authentic labor-market contexts, offering a path toward a collaborative framework, where AI amplifies human capability through partnership rather than replacement.

</details>


### [465] [Reward and Guidance through Rubrics: Promoting Exploration to Improve Multi-Domain Reasoning](https://arxiv.org/abs/2511.12344)
*Baolong Bi,Shenghua Liu,Yiwei Wang,Siqian Tong,Lingrui Mei,Yuyao Ge,Yilong Xu,Jiafeng Guo,Xueqi Cheng*

Main category: cs.AI

TL;DR: RGR-GRPO利用评分提供密集奖励和离线指导，显著提升多领域推理性能，优于现有RL方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法局限于单领域RL和可验证奖励，且纯在线RL框架限制了探索空间，影响推理性能。

Method: 提出RGR-GRPO（Reward and Guidance through Rubrics），一种基于评分的RL框架，结合密集奖励信号和离线指导，扩展了探索空间。

Result: 在14个多领域基准测试中，RGR-GRPO平均提升数学、物理、化学和通用推理任务性能7.0%、5.4%、8.4%和6.6%，并保持稳定的熵波动。

Conclusion: RGR-GRPO通过引入细粒度奖励信号和离线指导，显著提升了多领域推理任务的性能，并保持了训练的稳定性。

Abstract: Recent advances in reinforcement learning (RL) have significantly improved the complex reasoning capabilities of large language models (LLMs). Despite these successes, existing methods mainly focus on single-domain RL (e.g., mathematics) with verifiable rewards (RLVR), and their reliance on purely online RL frameworks restricts the exploration space, thereby limiting reasoning performance. In this paper, we address these limitations by leveraging rubrics to provide both fine-grained reward signals and offline guidance. We propose $\textbf{RGR-GRPO}$ (Reward and Guidance through Rubrics), a rubric-driven RL framework for multi-domain reasoning. RGR-GRPO enables LLMs to receive dense and informative rewards while exploring a larger solution space during GRPO training. Extensive experiments across 14 benchmarks spanning multiple domains demonstrate that RGR-GRPO consistently outperforms RL methods that rely solely on alternative reward schemes or offline guidance. Compared with verifiable online RL baseline, RGR-GRPO achieves average improvements of +7.0%, +5.4%, +8.4%, and +6.6% on mathematics, physics, chemistry, and general reasoning tasks, respectively. Notably, RGR-GRPO maintains stable entropy fluctuations during off-policy training and achieves superior pass@k performance, reflecting sustained exploration and effective breakthrough beyond existing performance bottlenecks.

</details>


### [466] [More Than Irrational: Modeling Belief-Biased Agents](https://arxiv.org/abs/2511.12359)
*Yifan Zhu,Sammie Katt,Samuel Kaski*

Main category: cs.AI

TL;DR: 本文提出了一种计算理性用户模型，通过嵌套粒子滤波方法推断用户的认知界限和偏见信念，验证了其在导航任务中的有效性，并为适应性AI助手开发奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 尽管AI技术快速发展，但预测和理解用户在认知受限和偏见信念下的次优行为仍是一个关键挑战。

Method: 提出了一种基于嵌套粒子滤波的在线推断方法，用于同时追踪用户的潜在信念状态和估计未知的认知界限。

Result: 通过仿真验证，CR模型能生成与不同记忆容量对应的直观行为，且推断方法能准确高效地从有限观察中恢复真实的认知界限（≤100步）。

Conclusion: 本文提出了一种计算理性（CR）用户模型，用于模拟认知受限代理在偏见信念下的最优行为，并通过嵌套粒子滤波方法在线推断用户的潜在信念状态和认知界限。该方法在导航任务中验证了其有效性，并为开发适应性AI助手提供了理论基础。

Abstract: Despite the explosive growth of AI and the technologies built upon it, predicting and inferring the sub-optimal behavior of users or human collaborators remains a critical challenge. In many cases, such behaviors are not a result of irrationality, but rather a rational decision made given inherent cognitive bounds and biased beliefs about the world. In this paper, we formally introduce a class of computational-rational (CR) user models for cognitively-bounded agents acting optimally under biased beliefs. The key novelty lies in explicitly modeling how a bounded memory process leads to a dynamically inconsistent and biased belief state and, consequently, sub-optimal sequential decision-making. We address the challenge of identifying the latent user-specific bound and inferring biased belief states from passive observations on the fly. We argue that for our formalized CR model family with an explicit and parameterized cognitive process, this challenge is tractable. To support our claim, we propose an efficient online inference method based on nested particle filtering that simultaneously tracks the user's latent belief state and estimates the unknown cognitive bound from a stream of observed actions. We validate our approach in a representative navigation task using memory decay as an example of a cognitive bound. With simulations, we show that (1) our CR model generates intuitively plausible behaviors corresponding to different levels of memory capacity, and (2) our inference method accurately and efficiently recovers the ground-truth cognitive bounds from limited observations ($\le 100$ steps). We further demonstrate how this approach provides a principled foundation for developing adaptive AI assistants, enabling adaptive assistance that accounts for the user's memory limitations.

</details>


### [467] [Learning to Trust: Bayesian Adaptation to Varying Suggester Reliability in Sequential Decision Making](https://arxiv.org/abs/2511.12378)
*Dylan M. Asmar,Mykel J. Kochenderfer*

Main category: cs.AI

TL;DR: 提出动态适应建议者可靠性的框架，通过贝叶斯推断和策略性请求建议，实现稳健性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常假设建议者质量静态且已知，限制了实际部署。本文旨在解决在不确定环境中动态适应建议者可靠性的问题。

Method: 框架包括将建议者质量直接整合到智能体的信念表示中，通过贝叶斯推断调整对建议的依赖，并引入显式的“询问”动作，以平衡信息获取成本与收益。

Result: 实验评估表明，该框架在不同建议者质量和变化可靠性下表现稳健，并能策略性管理建议请求。

Conclusion: 该论文提出了一个动态学习和适应不同建议者可靠性的框架，通过贝叶斯推断和策略性请求建议，实现了在部分可观测环境中对建议的智能利用，为人机协作中处理建议不确定性奠定了基础。

Abstract: Autonomous agents operating in sequential decision-making tasks under uncertainty can benefit from external action suggestions, which provide valuable guidance but inherently vary in reliability. Existing methods for incorporating such advice typically assume static and known suggester quality parameters, limiting practical deployment. We introduce a framework that dynamically learns and adapts to varying suggester reliability in partially observable environments. First, we integrate suggester quality directly into the agent's belief representation, enabling agents to infer and adjust their reliance on suggestions through Bayesian inference over suggester types. Second, we introduce an explicit ``ask'' action allowing agents to strategically request suggestions at critical moments, balancing informational gains against acquisition costs. Experimental evaluation demonstrates robust performance across varying suggester qualities, adaptation to changing reliability, and strategic management of suggestion requests. This work provides a foundation for adaptive human-agent collaboration by addressing suggestion uncertainty in uncertain environments.

</details>


### [468] [Multi-agent Self-triage System with Medical Flowcharts](https://arxiv.org/abs/2511.12439)
*Yujia Liu,Sophia Yu,Hongyue Jin,Jessica Wen,Alexander Qian,Terrence Lee,Mattheus Ramsis,Gi Won Choi,Lianhui Qin,Xin Liu,Edward J. Wang*

Main category: cs.AI

TL;DR: 研究提出了一种基于临床流程图的多代理AI系统，显著提升了自我分诊的准确性和透明性。


<details>
  <summary>Details</summary>
Motivation: 在线健康资源和大型语言模型（LLMs）在医疗决策中日益普及，但其可靠性受限于低准确性、缺乏透明性及对未验证信息的易感性。

Method: 研究引入了一个概念验证的对话式自我分诊系统，该系统利用美国医学协会的100个临床验证流程图指导大型语言模型（LLMs），并通过多代理框架（包括检索代理、决策代理和聊天代理）实现流程图检索、患者响应解释和个性化推荐。

Result: 系统在大规模合成数据集（模拟对话）上表现优异，流程图检索的Top-3准确率达95.29%（N=2,000），流程图导航准确率达99.10%（N=37,200）。

Conclusion: 该研究证明了一种结合自由文本交互和标准化临床协议的透明、准确且可推广的AI辅助自我分诊系统的可行性，有望支持患者知情决策并优化医疗资源利用。

Abstract: Online health resources and large language models (LLMs) are increasingly used as a first point of contact for medical decision-making, yet their reliability in healthcare remains limited by low accuracy, lack of transparency, and susceptibility to unverified information. We introduce a proof-of-concept conversational self-triage system that guides LLMs with 100 clinically validated flowcharts from the American Medical Association, providing a structured and auditable framework for patient decision support. The system leverages a multi-agent framework consisting of a retrieval agent, a decision agent, and a chat agent to identify the most relevant flowchart, interpret patient responses, and deliver personalized, patient-friendly recommendations, respectively. Performance was evaluated at scale using synthetic datasets of simulated conversations. The system achieved 95.29% top-3 accuracy in flowchart retrieval (N=2,000) and 99.10% accuracy in flowchart navigation across varied conversational styles and conditions (N=37,200). By combining the flexibility of free-text interaction with the rigor of standardized clinical protocols, this approach demonstrates the feasibility of transparent, accurate, and generalizable AI-assisted self-triage, with potential to support informed patient decision-making while improving healthcare resource utilization.

</details>


### [469] [ARCHE: A Novel Task to Evaluate LLMs on Latent Reasoning Chain Extraction](https://arxiv.org/abs/2511.12485)
*Pengze Li,Jiaqi Liu,Junchi Yu,Lihao Liu,Mingyu Ding,Wanli Ouyang,Shixiang Tang,Xi Chen*

Main category: cs.AI

TL;DR: 研究提出ARCHE任务和ARCHE Bench基准，评估发现当前LLMs无法生成完整且标准的科学推理链，揭示其与科学论证严谨性之间的差距。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型生成的推理内容通常是非结构化和非正式的，难以判断模型是否真正理解支撑科学推理的基本范式。

Method: 提出了一个名为Latent Reasoning Chain Extraction（ARCHE）的新任务，要求模型将复杂推理分解为标准推理范式的组合，形成推理逻辑树（RLT）。并发布了ARCHE Bench基准，包含来自70篇Nature Communications文章的1,900多个引用和38,000多个观点。提出了两个逻辑感知评估指标：实体覆盖率（EC）和推理边准确率（REA）。

Result: 对10个领先的大型语言模型在ARCHE Bench上的评估显示，模型在REA和EC之间存在权衡，且尚无法提取完整且标准的推理链。

Conclusion: 当前的大型语言模型在提取完整且标准的推理链方面存在显著差距，无法满足科学论证的严谨性要求。

Abstract: Large language models (LLMs) are increasingly used in scientific domains. While they can produce reasoning-like content via methods such as chain-of-thought prompting, these outputs are typically unstructured and informal, obscuring whether models truly understand the fundamental reasoning paradigms that underpin scientific inference. To address this, we introduce a novel task named Latent Reasoning Chain Extraction (ARCHE), in which models must decompose complex reasoning arguments into combinations of standard reasoning paradigms in the form of a Reasoning Logic Tree (RLT). In RLT, all reasoning steps are explicitly categorized as one of three variants of Peirce's fundamental inference modes: deduction, induction, or abduction. To facilitate this task, we release ARCHE Bench, a new benchmark derived from 70 Nature Communications articles, including more than 1,900 references and 38,000 viewpoints. We propose two logic-aware evaluation metrics: Entity Coverage (EC) for content completeness and Reasoning Edge Accuracy (REA) for step-by-step logical validity. Evaluations on 10 leading LLMs on ARCHE Bench reveal that models exhibit a trade-off between REA and EC, and none are yet able to extract a complete and standard reasoning chain. These findings highlight a substantial gap between the abilities of current reasoning models and the rigor required for scientific argumentation.

</details>


### [470] [LOBERT: Generative AI Foundation Model for Limit Order Book Messages](https://arxiv.org/abs/2511.12563)
*Eljas Linna,Kestutis Baltakys,Alexandros Iosifidis,Juho Kanniainen*

Main category: cs.AI

TL;DR: LOBERT是一种基于BERT的通用LOB数据模型，通过创新标记化方案提升预测性能，适用于下游任务微调。


<details>
  <summary>Details</summary>
Motivation: 由于传统LOB模型数据表示繁琐且适应性不足，无法高效处理高频交易者对订单流的反应，因此需要一种更灵活的通用模型。

Method: LOBERT基于BERT架构，采用新颖的标记化方案，将多维消息作为单个标记处理，同时保留价格、交易量和时间的连续表示。

Result: LOBERT在预测中间价格变动和下一消息等任务中表现领先，且相比之前方法减少了所需的上下文长度。

Conclusion: LOBERT作为一种通用的LOB数据基础模型，通过创新的标记化方案和连续表示方法，在下游任务微调中表现出色，显著提升了预测性能并减少了所需上下文长度。

Abstract: Modeling the dynamics of financial Limit Order Books (LOB) at the message level is challenging due to irregular event timing, rapid regime shifts, and the reactions of high-frequency traders to visible order flow. Previous LOB models require cumbersome data representations and lack adaptability outside their original tasks, leading us to introduce LOBERT, a general-purpose encoder-only foundation model for LOB data suitable for downstream fine-tuning. LOBERT adapts the original BERT architecture for LOB data by using a novel tokenization scheme that treats complete multi-dimensional messages as single tokens while retaining continuous representations of price, volume, and time. With these methods, LOBERT achieves leading performance in tasks such as predicting mid-price movements and next messages, while reducing the required context length compared to previous methods.

</details>


### [471] [Enhancing Conversational Recommender Systems with Tree-Structured Knowledge and Pretrained Language Models](https://arxiv.org/abs/2511.12579)
*Yongwen Ren,Chao Wang,Peng Du,Chuan Qin,Dazhong Shen,Hui Xiong*

Main category: cs.AI

TL;DR: PCRS-TKA是一种结合PLM和KG的新框架，通过结构感知推理和选择性知识过滤，显著提升对话推荐系统的性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法未能充分利用PLM在图关系上的推理能力、无差别地整合检索知识以及忽视多轮对话中的协作偏好等问题。

Method: 采用基于提示的检索增强生成框架，构建对话特定的知识树并序列化为文本，结合结构感知推理和选择性知识过滤。

Result: 在广泛实验中，PCRS-TKA在推荐和对话质量上均优于所有基线方法。

Conclusion: PCRS-TKA通过结合预训练语言模型和知识图谱，显著提升了对话推荐系统的推荐质量和对话流畅性。

Abstract: Recent advances in pretrained language models (PLMs) have significantly improved conversational recommender systems (CRS), enabling more fluent and context-aware interactions. To further enhance accuracy and mitigate hallucination, many methods integrate PLMs with knowledge graphs (KGs), but face key challenges: failing to fully exploit PLM reasoning over graph relationships, indiscriminately incorporating retrieved knowledge without context filtering, and neglecting collaborative preferences in multi-turn dialogues. To this end, we propose PCRS-TKA, a prompt-based framework employing retrieval-augmented generation to integrate PLMs with KGs. PCRS-TKA constructs dialogue-specific knowledge trees from KGs and serializes them into texts, enabling structure-aware reasoning while capturing rich entity semantics. Our approach selectively filters context-relevant knowledge and explicitly models collaborative preferences using specialized supervision signals. A semantic alignment module harmonizes heterogeneous inputs, reducing noise and enhancing accuracy. Extensive experiments demonstrate that PCRS-TKA consistently outperforms all baselines in both recommendation and conversational quality.

</details>


### [472] [Dynamic Tree Databases in Automated Planning](https://arxiv.org/abs/2511.12677)
*Oliver Joergensen,Dominik Drexler,Jendrik Seipp*

Main category: cs.AI

TL;DR: 提出动态树数据库用于状态集压缩，实验显示高压缩比和低运行时开销。


<details>
  <summary>Details</summary>
Motivation: 在大规模任务中，显式状态空间搜索的一个核心挑战是如何紧凑地表示生成的状态集。

Method: 提出了一种新颖的动态树数据库变体，用于压缩命题和数值变量的状态集，并证明了其保持静态树数据库的理想特性。

Result: 在基础和提升规划任务上的实证评估显示，压缩比达到了几个数量级，且运行时开销通常可忽略不计。

Conclusion: 动态树数据库在命题和数值变量的状态集压缩中保持了静态树的理想特性，并在实验中展示了极高的压缩比和可忽略的运行时间开销。

Abstract: A central challenge in scaling up explicit state-space search for large tasks is compactly representing the set of generated states. Tree databases, a data structure from model checking, require constant space per generated state in the best case, but they need a large preallocation of memory. We propose a novel dynamic variant of tree databases for compressing state sets over propositional and numeric variables and prove that it maintains the desirable properties of the static counterpart. Our empirical evaluation of state compression techniques for grounded and lifted planning on classical and numeric planning tasks reveals compression ratios of several orders of magnitude, often with negligible runtime overhead.

</details>


### [473] [Adaptively Coordinating with Novel Partners via Learned Latent Strategies](https://arxiv.org/abs/2511.12754)
*Benjamin Li,Shuyang Shi,Lucia Romero,Huao Li,Yaqi Xie,Woojun Kim,Stefanos Nikolaidis,Michael Lewis,Katia Sycara,Simon Stepputtis*

Main category: cs.AI

TL;DR: 该论文提出了一种策略条件合作者框架，通过变分自编码器和聚类学习策略空间，并利用遗憾最小化算法实时适应伙伴策略，在复杂协作任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决人机团队中人工代理如何实时适应具有动态偏好和策略的人类伙伴，尤其是在时间压力和复杂战略空间任务中的挑战。

Method: 利用变分自编码器对策略进行编码，学习潜在策略空间，并通过聚类识别不同策略类型，训练合作者代理以这些聚类为条件生成各类策略伙伴。在线适应新伙伴时，采用固定份额遗憾最小化算法动态推断和调整策略估计。

Result: 在修改版Overcooked域中的实验和在线用户研究表明，该方法与现有基线相比，与新颖人类和代理队友配对时实现了最先进的性能。

Conclusion: 该论文提出的策略条件合作者框架在实时适应多样化伙伴策略方面表现出色，尤其在时间压力和复杂战略空间的任务中，能够显著提升协作效率。

Abstract: Adaptation is the cornerstone of effective collaboration among heterogeneous team members. In human-agent teams, artificial agents need to adapt to their human partners in real time, as individuals often have unique preferences and policies that may change dynamically throughout interactions. This becomes particularly challenging in tasks with time pressure and complex strategic spaces, where identifying partner behaviors and selecting suitable responses is difficult. In this work, we introduce a strategy-conditioned cooperator framework that learns to represent, categorize, and adapt to a broad range of potential partner strategies in real-time. Our approach encodes strategies with a variational autoencoder to learn a latent strategy space from agent trajectory data, identifies distinct strategy types through clustering, and trains a cooperator agent conditioned on these clusters by generating partners of each strategy type. For online adaptation to novel partners, we leverage a fixed-share regret minimization algorithm that dynamically infers and adjusts the partner's strategy estimation during interaction. We evaluate our method in a modified version of the Overcooked domain, a complex collaborative cooking environment that requires effective coordination among two players with a diverse potential strategy space. Through these experiments and an online user study, we demonstrate that our proposed agent achieves state of the art performance compared to existing baselines when paired with novel human, and agent teammates.

</details>


### [474] [Optimal Foraging in Memory Retrieval: Evaluating Random Walks and Metropolis-Hastings Sampling in Modern Semantic Spaces](https://arxiv.org/abs/2511.12759)
*James Moore*

Main category: cs.AI

TL;DR: 研究发现，简单采样在高维嵌入空间中即可模拟人类记忆检索的最优觅食行为，复杂算法反而不适用。


<details>
  <summary>Details</summary>
Motivation: 探讨现代高维嵌入空间是否能提供与人类行为一致的表示，验证复杂采样机制是否必然优于简单采样。

Method: 使用最先进的嵌入技术和先前的语义流畅性数据，在嵌入空间中进行随机游走，并引入Metropolis-Hastings采样算法进行比较。

Result: 随机游走在嵌入空间中产生的结果与最优觅食和边际价值定理一致，而Metropolis-Hastings采样算法却与人类行为不符。

Conclusion: 现代高维嵌入空间的结构化表示，即使采用简单采样方法，也能近似人类记忆检索的最优觅食动态，无需依赖复杂的接受标准。

Abstract: Human memory retrieval often resembles ecological foraging where animals search for food in a patchy environment. Optimal foraging means following the Marginal Value Theorem (MVT), in which individuals exploit a patch of semantically related concepts until it becomes less rewarding and then switch to a new cluster. While human behavioral data suggests foraging-like patterns in semantic fluency tasks, it remains unclear whether modern high-dimensional embedding spaces provide representations that allow algorithms to match observed human behavior. Using state-of-the-art embeddings and prior semantic fluency data, I find that random walks on these embedding spaces produce results consistent with optimal foraging and the MVT. Surprisingly, introducing Metropolis-Hastings sampling, an adaptive algorithm expected to model strategic acceptance and rejection of new clusters, does not produce results consistent with human behavior. These findings challenge the assumption that more complex sampling mechanisms inherently lead to better cognitive models of memory retrieval. Instead, they show that appropriately structured embeddings, even with simple sampling, can produce near-optimal foraging dynamics. This supports the perspective of Hills (2012) rather than Abbott (2015), demonstrating that modern embeddings can approximate human memory foraging without relying on complex acceptance criteria.

</details>


### [475] [Event-CausNet: Unlocking Causal Knowledge from Text with Large Language Models for Reliable Spatio-Temporal Forecasting](https://arxiv.org/abs/2511.12769)
*Luyao Niu,Zepu Wang,Shuyi Guan,Yang Liu,Peng Sun*

Main category: cs.AI

TL;DR: Event-CausNet结合LLM与GNN-LSTM，通过因果推理提升非重复性事件下的交通预测性能，MAE降低35.87%。


<details>
  <summary>Details</summary>
Motivation: 传统时空图神经网络（GNNs）在处理非重复性事件时表现不佳，因其仅依赖历史相关性，而忽略了事件引入的新因果因素。

Method: 提出Event-CausNet框架，利用大型语言模型量化非结构化事件报告，构建因果知识库，并通过新颖的因果注意力机制将知识注入双流GNN-LSTM网络。

Result: 在真实数据集上，Event-CausNet将预测误差（MAE）降低高达35.87%，显著优于现有基线方法。

Conclusion: Event-CausNet通过结合因果推理与传统相关模型，显著提升了在非重复性事件（如事故）下的预测性能，为实际交通管理提供了更可靠、可解释的解决方案。

Abstract: While spatio-temporal Graph Neural Networks (GNNs) excel at modeling recurring traffic patterns, their reliability plummets during non-recurring events like accidents. This failure occurs because GNNs are fundamentally correlational models, learning historical patterns that are invalidated by the new causal factors introduced during disruptions. To address this, we propose Event-CausNet, a framework that uses a Large Language Model to quantify unstructured event reports, builds a causal knowledge base by estimating average treatment effects, and injects this knowledge into a dual-stream GNN-LSTM network using a novel causal attention mechanism to adjust and enhance the forecast. Experiments on a real-world dataset demonstrate that Event-CausNet achieves robust performance, reducing prediction error (MAE) by up to 35.87%, significantly outperforming state-of-the-art baselines. Our framework bridges the gap between correlational models and causal reasoning, providing a solution that is more accurate and transferable, while also offering crucial interpretability, providing a more reliable foundation for real-world traffic management during critical disruptions.

</details>


### [476] [Multi-Agent Reinforcement Learning for Heterogeneous Satellite Cluster Resources Optimization](https://arxiv.org/abs/2511.12792)
*Mohamad A. Hady,Siyi Hu,Mahardhika Pratama,Zehong Cao,Ryszard Kowalczyk*

Main category: cs.AI

TL;DR: 该研究利用MARL优化异构卫星集群的资源分配，解决了EO任务中的实时和分散挑战，并通过模拟验证了算法的有效性。


<details>
  <summary>Details</summary>
Motivation: 传统的优化方法难以处理地球观测（EO）操作的实时性、不确定性和分散性，这促使使用强化学习（RL）和多智能体强化学习（MARL）进行自适应决策。

Method: 本研究系统地从单卫星到多卫星场景中制定了优化问题，解决了能源和内存限制、部分可观测性以及由不同有效载荷能力引起的智能体异构性等关键挑战。使用基于Basilisk和BSK-RL框架构建的近真实模拟环境，评估了MAPPO、HAPPO和HATRPO等先进MARL算法的性能和稳定性。

Result: 结果表明，MARL能够实现异构卫星之间的有效协调，平衡成像性能和资源利用，同时缓解非平稳性和智能体间奖励耦合问题。

Conclusion: 研究结果表明，多智能体强化学习（MARL）能够有效协调异构卫星，平衡成像性能和资源利用，同时缓解非平稳性和智能体间奖励耦合问题。研究结果为可扩展的自主卫星操作提供了实用见解，并为未来在异构和动态条件下智能地球观测任务规划的研究奠定了基础。

Abstract: This work investigates resource optimization in heterogeneous satellite clusters performing autonomous Earth Observation (EO) missions using Reinforcement Learning (RL). In the proposed setting, two optical satellites and one Synthetic Aperture Radar (SAR) satellite operate cooperatively in low Earth orbit to capture ground targets and manage their limited onboard resources efficiently. Traditional optimization methods struggle to handle the real-time, uncertain, and decentralized nature of EO operations, motivating the use of RL and Multi-Agent Reinforcement Learning (MARL) for adaptive decision-making. This study systematically formulates the optimization problem from single-satellite to multi-satellite scenarios, addressing key challenges including energy and memory constraints, partial observability, and agent heterogeneity arising from diverse payload capabilities. Using a near-realistic simulation environment built on the Basilisk and BSK-RL frameworks, we evaluate the performance and stability of state-of-the-art MARL algorithms such as MAPPO, HAPPO, and HATRPO. Results show that MARL enables effective coordination across heterogeneous satellites, balancing imaging performance and resource utilization while mitigating non-stationarity and inter-agent reward coupling. The findings provide practical insights into scalable, autonomous satellite operations and contribute a foundation for future research on intelligent EO mission planning under heterogeneous and dynamic conditions.

</details>


### [477] [Neuro-Logic Lifelong Learning](https://arxiv.org/abs/2511.12793)
*Bowen He,Xiaoan Xu,Alper Kamil Bozkurt,Vahid Tarokh,Juncheng Dong*

Main category: cs.AI

TL;DR: 研究提出终身学习ILP框架，通过复用逻辑规则提升学习效率和性能，为神经符号AI的持续学习提供新方向。


<details>
  <summary>Details</summary>
Motivation: 解决神经符号AI中ILP问题的关键挑战，探索涉及一系列问题的新学习范式，而非仅针对单个问题设计网络架构。

Method: 提出了一个组合性框架，通过复用先前任务习得的逻辑规则，实现对后续任务的高效学习。

Result: 实验结果表明，该范式在任务序列上的可行性和优势得到验证。

Conclusion: 终身学习ILP框架通过有效复用先前任务的逻辑规则，提高了后续任务的学习效率和性能，为神经符号AI中的持续学习开辟了新方向。

Abstract: Solving Inductive Logic Programming (ILP) problems with neural networks is a key challenge in Neural-Symbolic Ar- tificial Intelligence (AI). While most research has focused on designing novel network architectures for individual prob- lems, less effort has been devoted to exploring new learning paradigms involving a sequence of problems. In this work, we investigate lifelong learning ILP, which leverages the com- positional and transferable nature of logic rules for efficient learning of new problems. We introduce a compositional framework, demonstrating how logic rules acquired from ear- lier tasks can be efficiently reused in subsequent ones, leading to improved scalability and performance. We formalize our approach and empirically evaluate it on sequences of tasks. Experimental results validate the feasibility and advantages of this paradigm, opening new directions for continual learn- ing in Neural-Symbolic AI.

</details>


### [478] [Mapping fNIRS Signals to Agent Performance: Toward Reinforcement Learning from Neural Feedback](https://arxiv.org/abs/2511.12844)
*Julia Santaniello,Matthew Russell,Benson Jiang,Donatello Sassaroli,Robert Jacob,Jivko SInapov*

Main category: cs.AI

TL;DR: 研究利用fNIRS信号预测代理性能，分类器表现良好，微调后性能提升显著，为脑驱动RLHF奠定基础。


<details>
  <summary>Details</summary>
Motivation: 探索如何通过隐式神经信号（fNIRS）来指导代理训练，以实现更高效的RLHF。

Method: 采用被动BCI技术，利用fNIRS记录人类参与者的神经信号，训练分类器和回归器来预测代理性能。

Result: 分类器在二元和多类模型中的平均F1分数分别为67%和46%，通过微调预训练模型，性能显著提升。

Conclusion: 本研究证明了通过fNIRS信号映射代理性能是可行的，并为未来的脑驱动RLHF系统奠定了基础。

Abstract: Reinforcement Learning from Human Feedback (RLHF) is a methodology that aligns agent behavior with human preferences by integrating human feedback into the agent's training process. We introduce a possible framework that employs passive Brain-Computer Interfaces (BCI) to guide agent training from implicit neural signals. We present and release a novel dataset of functional near-infrared spectroscopy (fNIRS) recordings collected from 25 human participants across three domains: a Pick-and-Place Robot, Lunar Lander, and Flappy Bird. We train classifiers to predict levels of agent performance (optimal, sub-optimal, or worst-case) from windows of preprocessed fNIRS feature vectors, achieving an average F1 score of 67% for binary classification and 46% for multi-class models averaged across conditions and domains. We also train regressors to predict the degree of deviation between an agent's chosen action and a set of near-optimal policies, providing a continuous measure of performance. We evaluate cross-subject generalization and demonstrate that fine-tuning pre-trained models with a small sample of subject-specific data increases average F1 scores by 17% and 41% for binary and multi-class models, respectively. Our work demonstrates that mapping implicit fNIRS signals to agent performance is feasible and can be improved, laying the foundation for future brain-driven RLHF systems.

</details>


### [479] [Bootstrapping LLMs via Preference-Based Policy Optimization](https://arxiv.org/abs/2511.12867)
*Chen Jia*

Main category: cs.AI

TL;DR: PbPO框架通过最小最大博弈和在线迭代优化，有效对齐LLM与人类偏好，实验表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 减少对大量人工标注的依赖，通过偏好数据引导模型行为与人类偏好对齐，实现大型语言模型的自我持续改进。

Method: 提出了一种基于偏好的策略优化（PbPO）框架，将学习过程建模为主策略与奖励模型（RM）之间的最小最大博弈，并通过置信集约束RM以确保可靠利用。采用迭代在线算法，通过主动收集偏好数据进行引导探索。

Result: 在五个基准测试中，PbPO框架均优于现有最优偏好优化技术，并提供了序列级和令牌级RM的理论保证。

Conclusion: PbPO框架通过迭代在线算法和理论保证，显著提升了大型语言模型与人类偏好的对齐效果，且在多个基准测试中优于现有技术。

Abstract: Bootstrapping large language models (LLMs) through preference-based policy optimization offers a promising direction for aligning model behavior with human preferences without relying on extensive manual annotations. In this work, we propose a novel preference-based policy optimization (PbPO) framework that formulates the learning process as a min-max game between the main policy and a reward model (RM). The RM is constrained within a confidence set derived from preference data to ensure reliable exploitation. Our iterative online algorithm actively collects preference data through guided exploration of the evolving policy, enabling continual self-improvement of both the policy and the RM. We provide theoretical guarantees for our method, establishing high-probability regret bounds for both settings with sequence-level RM and token-level RM, demonstrating its effectiveness in bootstrapping LLMs. Extensive experiments on five benchmarks show that our approach consistently outperforms existing state-of-the-art preference optimization techniques.

</details>


### [480] [Think, Speak, Decide: Language-Augmented Multi-Agent Reinforcement Learning for Economic Decision-Making](https://arxiv.org/abs/2511.12876)
*Heyang Ma,Qirui Mi,Qipeng Yang,Zijun Fan,Bo Li,Haifeng Zhang*

Main category: cs.AI

TL;DR: L framework combines language and MARL for better economic decisions, outperforming baselines in returns, robustness, and interpretability.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the limitations of current MARL in handling the semantic ambiguity and contextual richness of language, aiming to bridge the gap to real-world economic decision-making.

Method: The proposed method, L, combines numerical data with language processing through a three-step pipeline: Interpret (extract trends), Speak (exchange messages), and Decide (fuse data into policy).

Result: Experiments show L outperforms MARL (+63.5%) and LLM-only (+34.0%) in cumulative return, with additional gains in robustness (+18.8%, +4%) and interpretability.

Conclusion: The paper concludes that the L (Language-Augmented MARL) framework significantly improves economic decision-making by integrating language, outperforming traditional MARL and LLM-only approaches in cumulative return, robustness, and interpretability.

Abstract: Economic decision-making depends not only on structured signals such as prices and taxes, but also on unstructured language, including peer dialogue and media narratives. While multi-agent reinforcement learning (MARL) has shown promise in optimizing economic decisions, it struggles with the semantic ambiguity and contextual richness of language. We propose LAMP (Language-Augmented Multi-Agent Policy), a framework that integrates language into economic decision-making and narrows the gap to real-world settings. LAMP follows a Think-Speak-Decide pipeline: (1) Think interprets numerical observations to extract short-term shocks and long-term trends, caching high-value reasoning trajectories; (2) Speak crafts and exchanges strategic messages based on reasoning, updating beliefs by parsing peer communications; and (3) Decide fuses numerical data, reasoning, and reflections into a MARL policy to optimize language-augmented decision-making. Experiments in economic simulation show that LAMP outperforms both MARL and LLM-only baselines in cumulative return (+63.5%, +34.0%), robustness (+18.8%, +59.4%), and interpretability. These results demonstrate the potential of language-augmented policies to deliver more effective and robust economic strategies.

</details>


### [481] [Online Learning of HTN Methods for integrated LLM-HTN Planning](https://arxiv.org/abs/2511.12901)
*Yuesheng Xu,Hector Munoz-Avila*

Main category: cs.AI

TL;DR: 研究提出了一种在线学习HTN方法的方法，通过ChatGPT生成任务分解并学习泛化方法，减少了对ChatGPT的依赖，提升了效率。


<details>
  <summary>Details</summary>
Motivation: 旨在减少对ChatGPT的依赖，同时通过在线学习泛化方法提升任务分解效率和适用性。

Method: 本研究在ChatHTN规划器基础上构建了一个方法学习器，通过ChatGPT生成任务分解，并学习泛化的方法，适用于同类任务的多个实例。

Result: 实验表明，该方法在减少ChatGPT调用次数的同时，解决了相同或更多的问题。

Conclusion: 在线学习的分层任务网络（HTN）方法在集成HTN规划和基于LLM的聊天机器人中表现优异，显著减少了对ChatGPT的调用次数，同时保持或提高了问题解决能力。

Abstract: We present online learning of Hierarchical Task Network (HTN) methods in the context of integrated HTN planning and LLM-based chatbots. Methods indicate when and how to decompose tasks into subtasks. Our method learner is built on top of the ChatHTN planner. ChatHTN queries ChatGPT to generate a decomposition of a task into primitive tasks when no applicable method for the task is available. In this work, we extend ChatHTN. Namely, when ChatGPT generates a task decomposition, ChatHTN learns from it, akin to memoization. However, unlike memoization, it learns a generalized method that applies not only to the specific instance encountered, but to other instances of the same task. We conduct experiments on two domains and demonstrate that our online learning procedure reduces the number of calls to ChatGPT while solving at least as many problems, and in some cases, even more.

</details>


### [482] [CoS: Towards Optimal Event Scheduling via Chain-of-Scheduling](https://arxiv.org/abs/2511.12913)
*Yiming Zhao,Jiwei Tang,Shimin Di,Libin Zheng,Jianxing Yu,Jian Yin*

Main category: cs.AI

TL;DR: CoS框架通过分解调度任务并利用知识蒸馏，实现了高效且接近理论最优的事件推荐，同时具备优秀的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在效率、效果和泛化性之间存在固有折衷，因此需要一种既能最大化用户偏好，又能满足时间和地理约束的推荐方法。

Method: 本文提出了Chain-of-Scheduling (CoS)框架，通过探索、验证和整合三个原子阶段，结合知识蒸馏技术，激活大型语言模型的事件调度能力。

Result: 实验结果表明，CoS在三个真实数据集上以可解释的方式实现了高效且接近理论最优的效果，并在域外数据上表现出强大的零样本学习能力。

Conclusion: CoS框架通过将调度任务分解为三个原子阶段，并通过知识蒸馏使LLM自主生成调度链，实现了接近理论最优的效果，并展现出强大的零样本学习能力。

Abstract: Recommending event schedules is a key issue in Event-based Social Networks (EBSNs) in order to maintain user activity. An effective recommendation is required to maximize the user's preference, subjecting to both time and geographical constraints. Existing methods face an inherent trade-off among efficiency, effectiveness, and generalization, due to the NP-hard nature of the problem. This paper proposes the Chain-of-Scheduling (CoS) framework, which activates the event scheduling capability of Large Language Models (LLMs) through a guided, efficient scheduling process. CoS enhances LLM by formulating the schedule task into three atomic stages, i.e., exploration, verification and integration. Then we enable the LLMs to generate CoS autonomously via Knowledge Distillation (KD). Experimental results show that CoS achieves near-theoretical optimal effectiveness with high efficiency on three real-world datasets in a interpretable manner. Moreover, it demonstrates strong zero-shot learning ability on out-of-domain data.

</details>


### [483] [Fault2Flow: An AlphaEvolve-Optimized Human-in-the-Loop Multi-Agent System for Fault-to-Workflow Automation](https://arxiv.org/abs/2511.12916)
*Yafang Wang,Yangjie Tian,Xiaoyu Shen,Gaoyang Zhang,Jiaze Sun,He Zhang,Ruohua Xu,Feng Zhao*

Main category: cs.AI

TL;DR: Fault2Flow是一个基于LLM的多智能体系统，通过结构化法规逻辑和整合专家知识，实现了高效、可维护的电网故障诊断自动化。


<details>
  <summary>Details</summary>
Motivation: 传统电网故障诊断依赖人工，效率低、易出错且难以维护，缺乏将法规和专家知识整合的框架。

Method: Fault2Flow采用四步法：(1)提取并结构化法规逻辑为PASTA格式的故障树；(2)通过人机交互界面验证专家知识；(3)使用AlphaEvolve模块优化推理逻辑；(4)将最终逻辑合成为n8n可执行工作流。

Result: 在变压器故障诊断数据集上的实验验证显示，Fault2Flow实现了100%的拓扑一致性和高语义保真度。

Conclusion: Fault2Flow通过LLM多智能体系统，成功将法规逻辑和专家知识整合为可验证、可执行的工作流程，显著降低专家工作量，并实现了从故障分析到操作自动化的可复现路径。

Abstract: Power grid fault diagnosis is a critical process hindered by its reliance on manual, error-prone methods. Technicians must manually extract reasoning logic from dense regulations and attempt to combine it with tacit expert knowledge, which is inefficient, error-prone, and lacks maintainability as ragulations are updated and experience evolves. While Large Language Models (LLMs) have shown promise in parsing unstructured text, no existing framework integrates these two disparate knowledge sources into a single, verified, and executable workflow. To bridge this gap, we propose Fault2Flow, an LLM-based multi-agent system. Fault2Flow systematically: (1) extracts and structures regulatory logic into PASTA-formatted fault trees; (2) integrates expert knowledge via a human-in-the-loop interface for verification; (3) optimizes the reasoning logic using a novel AlphaEvolve module; and (4) synthesizes the final, verified logic into an n8n-executable workflow. Experimental validation on transformer fault diagnosis datasets confirms 100\% topological consistency and high semantic fidelity. Fault2Flow establishes a reproducible path from fault analysis to operational automation, substantially reducing expert workload.

</details>


### [484] [Yanyun-3: Enabling Cross-Platform Strategy Game Operation with Vision-Language Models](https://arxiv.org/abs/2511.12937)
*Guoyan Wang,Yanyan Huang,Chunlin Chen,Lifeng Wang,Yuxiang Sun*

Main category: cs.AI

TL;DR: Yanyun-3通过混合多模态数据策略，实现了跨平台策略游戏的高效自动化，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 探索视觉语言模型在复杂人机交互场景（如策略游戏）中的应用，解决跨平台操作的泛化性问题。

Method: 集成Qwen2.5-VL的视觉语言推理和UI-TARS的精确执行能力，结合多模态数据组合（静态图像、多图像序列、视频）的混合策略（MV+S）。

Result: 混合策略（MV+S）显著优于完全融合，推理时间减少63%，BLEU-4得分提升12.98倍（从4.81%到62.41%）。

Conclusion: Yanyun-3框架通过整合视觉语言推理和精确执行能力，成功实现了跨平台策略游戏的自动化操作，并为增强视觉语言模型性能提供了通用范式。

Abstract: Automated operation in cross-platform strategy games demands agents with robust generalization across diverse user interfaces and dynamic battlefield conditions. While vision-language models (VLMs) have shown considerable promise in multimodal reasoning, their application to complex human-computer interaction scenarios--such as strategy gaming--remains largely unexplored. Here, we introduce Yanyun-3, a general-purpose agent framework that, for the first time, enables autonomous cross-platform operation across three heterogeneous strategy game environments. By integrating the vision-language reasoning of Qwen2.5-VL with the precise execution capabilities of UI-TARS, Yanyun-3 successfully performs core tasks including target localization, combat resource allocation, and area control. Through systematic ablation studies, we evaluate the effects of various multimodal data combinations--static images, multi-image sequences, and videos--and propose the concept of combination granularity to differentiate between intra-sample fusion and inter-sample mixing strategies. We find that a hybrid strategy, which fuses multi-image and video data while mixing in static images (MV+S), substantially outperforms full fusion: it reduces inference time by 63% and boosts the BLEU-4 score by a factor of 12 (from 4.81% to 62.41%, approximately 12.98x). Operating via a closed-loop pipeline of screen capture, model inference, and action execution, the agent demonstrates strong real-time performance and cross-platform generalization. Beyond providing an efficient solution for strategy game automation, our work establishes a general paradigm for enhancing VLM performance through structured multimodal data organization, offering new insights into the interplay between static perception and dynamic reasoning in embodied intelligence.

</details>


### [485] [MedRule-KG: A Knowledge-Graph--Steered Scaffold for Reliable Mathematical and Biomedical Reasoning](https://arxiv.org/abs/2511.12963)
*Crystal Su*

Main category: cs.AI

TL;DR: MedRule-KG通过知识图谱和验证器优化LLMs输出，减少违规并提升精确匹配，适用于交互式药物设计。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在科学推理和药物发现中输出不符合数学和生物医学规则的问题。

Method: 提出MedRule-KG系统，结合知识图谱和确定性验证器，通过约束推理和软引导代理优化生成过程。

Result: 在90项任务中，违规数量减少83.2%，精确匹配率提升，结果在不同规模和分层下保持稳定。

Conclusion: MedRule-KG通过引入知识图谱和轻量级验证器，显著减少了LLMs在科学推理和药物发现中的违规行为，同时提升了精确匹配率，且验证器带来的延迟可忽略不计。

Abstract: We study how to impose domain-consistent structure on large language models (LLMs) used for scientific reasoning and early-stage drug discovery. We present MedRule-KG, a compact knowledge-graph scaffold paired with a lightweight verifier that steers generation toward mathematically and biomedically valid outputs. The system injects curated symbolic facts into prompts and then enforces rule satisfaction with a deterministic checker. We formalize generation as constrained inference, introduce a soft guidance surrogate suitable for decoding, and perform a thorough statistical analysis with uncertainty quantification. Across 90 tasks spanning reaction feasibility, metabolic compatibility, and toxicity screening, MedRule-KG reduces violation counts by 83.2\% relative to a strong chain-of-thought baseline while improving exact match. Results remain stable under stratification and scale with dataset size, and the verifier adds negligible latency, making the approach practical for interactive design.

</details>


### [486] [WebCoach: Self-Evolving Web Agents with Cross-Session Memory Guidance](https://arxiv.org/abs/2511.12997)
*Genglin Liu,Shijie Geng,Sha Li,Hejie Cui,Sarah Zhang,Xin Liu,Tianyi Liu*

Main category: cs.AI

TL;DR: WebCoach是一个自进化框架，通过跨会话记忆提升网页导航代理的长期性能，无需重训练即实现持续改进。


<details>
  <summary>Details</summary>
Motivation: 当前多模态LLM代理在网页导航中存在重复错误且无法跨会话学习，限制了其长期鲁棒性和效率。WebCoach旨在通过持久化记忆和自我进化解决这些问题。

Method: WebCoach框架包含三个核心组件：WebCondenser标准化导航日志为摘要、External Memory Store组织完整轨迹为情景记忆、Coach基于相似性和时效性检索记忆并通过运行时钩子注入任务建议。

Result: 在WebVoyager基准测试中，WebCoach将任务成功率从47%提升至61%（38B模型），且较小模型性能可媲美使用GPT-4o的代理。

Conclusion: WebCoach通过引入跨会话记忆和自我进化机制，显著提升了多模态LLM代理在网页导航任务中的长期鲁棒性和样本效率，无需重新训练即可持续改进。

Abstract: Multimodal LLM-powered agents have recently demonstrated impressive capabilities in web navigation, enabling agents to complete complex browsing tasks across diverse domains. However, current agents struggle with repetitive errors and lack the ability to learn from past experiences across sessions, limiting their long-term robustness and sample efficiency. We introduce WebCoach, a model-agnostic self-evolving framework that equips web browsing agents with persistent cross-session memory, enabling improved long-term planning, reflection, and continual learning without retraining. WebCoach consists of three key components: (1) a WebCondenser, which standardizes raw navigation logs into concise summaries; (2) an External Memory Store, which organizes complete trajectories as episodic experiences; and (3) a Coach, which retrieves relevant experiences based on similarity and recency, and decides whether to inject task-specific advice into the agent via runtime hooks. This design empowers web agents to access long-term memory beyond their native context window, improving robustness in complex browsing tasks. Moreover, WebCoach achieves self-evolution by continuously curating episodic memory from new navigation trajectories, enabling agents to improve over time without retraining. Evaluations on the WebVoyager benchmark demonstrate that WebCoach consistently improves the performance of browser-use agents across three different LLM backbones. With a 38B model, it increases task success rates from 47% to 61% while reducing or maintaining the average number of steps. Notably, smaller base models with WebCoach achieve performance comparable to the same web agent using GPT-4o.

</details>


### [487] [GEM: Generative Entropy-Guided Preference Modeling for Few-shot Alignment of LLMs](https://arxiv.org/abs/2511.13007)
*Yiyang Zhao,Huiyu Bai,Xuejiao Zhao*

Main category: cs.AI

TL;DR: GEM是一种少样本LLM对齐方法，通过熵引导的认知优化框架，在专业领域中高效利用有限偏好数据。


<details>
  <summary>Details</summary>
Motivation: 在依赖专业知识的领域（如医学和法律）中，大规模偏好标注难以获取，传统依赖监督奖励模型的方法不适用，因此需要一种少样本高效对齐方法。

Method: GEM结合了认知过滤模块（基于熵理论）和自评估群体优势算法（SEGA），通过生成多样化推理链、评分和权重调整，将熵基分数转化为隐式奖励进行策略优化。

Result: 实验表明，GEM在通用基准和特定领域任务（如数学推理和医学对话）中，仅需少样本偏好数据即可显著提升性能。

Conclusion: GEM提出了一种基于生成熵引导的偏好建模方法，通过闭环优化架构，使LLM能够在低资源和特定领域场景中自我优化，显著提升了少样本偏好数据的对齐效果。

Abstract: Alignment of large language models (LLMs) with human preferences typically relies on supervised reward models or external judges that demand abundant annotations. However, in fields that rely on professional knowledge, such as medicine and law, such large-scale preference labels are often unachievable. In this paper, we propose a generative entropy-guided preference modeling approach named GEM for LLMs aligment at low-resource and domain-specific scenarios. Instead of training a discriminative reward model on preference data, we directly train the LLM to internalize a closed-loop optimization architecture that can extract and exploit the multi-dimensional, fine-grained cognitive signals implicit in human preferences. Specifically, our Cognitive Filtering module, based on entropy theory in decision making, first leverages Chain-of-Thought (CoT) prompting to generate diverse candidate reasoning chains (CoTs) from preference data. Subsequently, it introduces a token scoring mechanism to rank and weight the sampled CoTs, boosting the importance of high-confidence answers and strategically high-entropy tokens. Building on these filtered preferences, we fine-tune the LLM using a novel self-evaluated group advantage algorithm, SEGA, which effectively aggregates group-level cognitive signals and transforms the entropy-based scores into implicit rewards for policy optimization. In these ways, GEM empowers the LLM to rely on its own judgments and establishes an entropy-guided closed-loop cognitive optimization framework, enabling highly efficient few-shot alignment of LLMs. Experiments on general benchmarks and domain-specific tasks (such as mathematical reasoning and medical dialogues) demonstrate that our GEM achieves significant improvements with few-shot preference data.

</details>


### [488] [PragWorld: A Benchmark Evaluating LLMs' Local World Model under Minimal Linguistic Alterations and Conversational Dynamics](https://arxiv.org/abs/2511.13021)
*Sachin Vashistha,Aryan Bibhuti,Atharva Naik,Martin Tutek,Somak Aditya*

Main category: cs.AI

TL;DR: 论文探讨语言模型在对话中构建世界模型的能力，发现其表现不佳，并提出双视角框架和层正则化微调策略以改进。


<details>
  <summary>Details</summary>
Motivation: 研究语言模型是否能在对话中构建或维护稳健的隐含世界模型，以理解实体提及、引用和隐含意义等实用元素。

Method: 通过应用七种最小语言变化构建两个基准测试，评估多种开源和闭源语言模型的性能，并提出了双视角可解释性框架来识别有用或有害的Transformer层。

Result: 研究发现语言模型在对话中难以维持稳健的准确性，尤其是在跟踪实体和应对语言变化方面表现不佳。

Conclusion: 论文提出了两种基于层正则化的微调策略，以抑制有害层的影响，从而提升语言模型在对话中的表现。

Abstract: Real-world conversations are rich with pragmatic elements, such as entity mentions, references, and implicatures. Understanding such nuances is a requirement for successful natural communication, and often requires building a local world model which encodes such elements and captures the dynamics of their evolving states. However, it is not well-understood whether language models (LMs) construct or maintain a robust implicit representation of conversations. In this work, we evaluate the ability of LMs to encode and update their internal world model in dyadic conversations and test their malleability under linguistic alterations. To facilitate this, we apply seven minimal linguistic alterations to conversations sourced from popular datasets and construct two benchmarks comprising yes-no questions. We evaluate a wide range of open and closed source LMs and observe that they struggle to maintain robust accuracy. Our analysis unveils that LMs struggle to memorize crucial details, such as tracking entities under linguistic alterations to conversations. We then propose a dual-perspective interpretability framework which identifies transformer layers that are useful or harmful and highlights linguistic alterations most influenced by harmful layers, typically due to encoding spurious signals or relying on shortcuts. Inspired by these insights, we propose two layer-regularization based fine-tuning strategies that suppress the effect of the harmful layers.

</details>


### [489] [Scaling Generative Verifiers For Natural Language Mathematical Proof Verification And Selection](https://arxiv.org/abs/2511.13027)
*Sadegh Mahdavi,Branislav Kisacanin,Shubham Toshniwal,Wei Du,Ivan Moshkov,George Armstrong,Renjie Liao,Christos Thrampoulidis,Igor Gitman*

Main category: cs.AI

TL;DR: 论文通过多评估设置分析，提出结合GenSelect和LLM-as-a-Judge的验证框架，强化学习可优化证明级指标但无法提升答案精度，揭示当前模型更关注风格而非数学有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管大语言模型在最终答案数学问题上表现优异，但其推理常存在缺陷，需可靠的证明验证能力以推进严谨的数学证明。

Method: 通过分析多种评估设置，结合基于证明和最终答案的推理评估，扩展两种生成验证方法（GenSelect和LLM-as-a-Judge）至百万级token，并探索强化学习对提示选择敏感性的影响。

Result: 结合GenSelect和LLM-as-a-Judge是最有效的验证框架，强化学习可降低提示敏感性但无法提升最终答案精度。

Conclusion: 论文提出了设计和评估可扩展证明验证与选择系统的实用指南，并指出当前模型常奖励风格或程序正确性而非数学有效性。

Abstract: Large language models have achieved remarkable success on final-answer mathematical problems, largely due to the ease of applying reinforcement learning with verifiable rewards. However, the reasoning underlying these solutions is often flawed. Advancing to rigorous proof-based mathematics requires reliable proof verification capabilities. We begin by analyzing multiple evaluation setups and show that focusing on a single benchmark can lead to brittle or misleading conclusions. To address this, we evaluate both proof-based and final-answer reasoning to obtain a more reliable measure of model performance. We then scale two major generative verification methods (GenSelect and LLM-as-a-Judge) to millions of tokens and identify their combination as the most effective framework for solution verification and selection. We further show that the choice of prompt for LLM-as-a-Judge significantly affects the model's performance, but reinforcement learning can reduce this sensitivity. However, despite improving proof-level metrics, reinforcement learning does not enhance final-answer precision, indicating that current models often reward stylistic or procedural correctness rather than mathematical validity. Our results establish practical guidelines for designing and evaluating scalable proof-verification and selection systems.

</details>


### [490] [MEGA-GUI: Multi-stage Enhanced Grounding Agents for GUI Elements](https://arxiv.org/abs/2511.13087)
*SeokJoo Kwak,Jihoon Kim,Boyoun Kim,Jung Jae Yoon,Wooseok Jang,Jeonghoon Hong,Jaeho Yang,Yeong-Dae Kwon*

Main category: cs.AI

TL;DR: MEGA-GUI是一个多阶段GUI定位框架，通过模块化设计和专用代理提升准确率，在密集和复杂场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有GUI定位系统在视觉杂乱和模糊指令下表现不佳，缺乏模块化设计，需要更灵活、准确的解决方案。

Method: MEGA-GUI采用多阶段框架，包括粗粒度ROI选择、细粒度元素定位，并结合双向ROI缩放算法和上下文感知重写代理。

Result: 在ScreenSpot-Pro和OSWorld-G基准测试中，MEGA-GUI分别达到73.18%和68.63%的准确率，超越现有方法。

Conclusion: MEGA-GUI通过多阶段框架和专用视觉语言代理，有效解决了现有系统在视觉杂乱和模糊指令下的不足，显著提升了GUI定位任务的准确性。

Abstract: Graphical User Interface (GUI) grounding - the task of mapping natural language instructions to screen coordinates - is essential for autonomous agents and accessibility technologies. Existing systems rely on monolithic models or one-shot pipelines that lack modularity and fail under visual clutter and ambiguous instructions. We introduce MEGA-GUI, a multi-stage framework that separates grounding into coarse Region-of-Interest (ROI) selection and fine-grained element grounding, orchestrated by specialized vision-language agents. MEGA-GUI features a bidirectional ROI zoom algorithm that mitigates spatial dilution and a context-aware rewriting agent that reduces semantic ambiguity. Our analysis reveals complementary strengths and weaknesses across vision-language models at different visual scales, and we show that leveraging this modular structure achieves consistently higher accuracy than monolithic approaches. On the visually dense ScreenSpot-Pro benchmark, MEGA-GUI attains 73.18% accuracy, and on the semantically complex OSWorld-G benchmark it reaches 68.63%, surpassing previously reported results. Code and the Grounding Benchmark Toolkit (GBT) are available at https://github.com/samsungsds-research-papers/mega-gui.

</details>


### [491] [STEP: Success-Rate-Aware Trajectory-Efficient Policy Optimization](https://arxiv.org/abs/2511.13091)
*Yuhan Chen,Yuxuan Liu,Long Zhang,Pengzhi Gao,Jian Luan,Wei Liu*

Main category: cs.AI

TL;DR: STEP通过动态采样分配和步骤级优化，解决了多轮交互强化学习中的效率问题，提高了样本效率和训练稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决多轮交互中在线强化学习的挑战，特别是轨迹级优化的低效性和误导性学习信号问题。

Method: STEP框架维护平滑的成功率记录以指导自适应轨迹重采样，计算成功率加权优势，并将轨迹分解为步骤级别样本，最后应用步骤级别的GRPO增强来优化低成功率任务的更新。

Result: 在OSWorld和AndroidWorld上的实验表明，STEP显著提高了样本效率和训练稳定性，比轨迹级GRPO收敛更快且泛化能力更强。

Conclusion: STEP框架通过动态分配采样资源和基于步骤级别的优化，显著提高了样本效率和训练稳定性，在相同采样预算下收敛更快且泛化能力更强。

Abstract: Multi-turn interaction remains challenging for online reinforcement learning. A common solution is trajectory-level optimization, which treats each trajectory as a single training sample. However, this approach can be inefficient and yield misleading learning signals: it applies uniform sampling across tasks regardless of difficulty, penalizes correct intermediate actions in failed trajectories, and incurs high sample-collection costs. To address these issues, we propose STEP (Success-rate-aware Trajectory-Efficient Policy optimization), a framework that dynamically allocates sampling based on per-task success rates and performs step-level optimization. STEP maintains a smoothed success-rate record to guide adaptive trajectory resampling, allocating more effort to harder tasks. It then computes success-rate-weighted advantages and decomposes trajectories into step-level samples. Finally, it applies a step-level GRPO augmentation to refine updates for low-success tasks. Experiments on OSWorld and AndroidWorld show that STEP substantially improves sample efficiency and training stability over trajectory-level GRPO, converging faster and generalizing better under the same sampling budget.

</details>


### [492] [Conditional Diffusion Model for Multi-Agent Dynamic Task Decomposition](https://arxiv.org/abs/2511.13137)
*Yanda Zhu,Yuanyang Zhu,Daoyi Dong,Caihua Chen,Chunlin Chen*

Main category: cs.AI

TL;DR: C$	ext{D}^	ext{3}$T是一个新型分层MARL框架，通过动态任务分解和协作学习在复杂任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 动态任务分解在复杂协作多代理强化学习中表现优异，但从零开始学习动态任务分解需要大量训练样本，尤其是在部分可观测性下探索大型联合动作空间。

Method: C$	ext{D}^	ext{3}$T采用两层分层MARL框架，高层策略学习子任务表示并生成子任务选择策略，低层代理在分配的子任务中协作学习专业技能。

Result: C$	ext{D}^	ext{3}$T通过条件扩散模型预测下一观测和奖励，捕捉子任务对环境的影响，并通过多头注意力混合网络增强价值分解。

Conclusion: C$	ext{D}^	ext{3}$T在多种基准测试中表现优于现有基线，验证了其动态任务分解和协作学习的有效性。

Abstract: Task decomposition has shown promise in complex cooperative multi-agent reinforcement learning (MARL) tasks, which enables efficient hierarchical learning for long-horizon tasks in dynamic and uncertain environments. However, learning dynamic task decomposition from scratch generally requires a large number of training samples, especially exploring the large joint action space under partial observability. In this paper, we present the Conditional Diffusion Model for Dynamic Task Decomposition (C$\text{D}^\text{3}$T), a novel two-level hierarchical MARL framework designed to automatically infer subtask and coordination patterns. The high-level policy learns subtask representation to generate a subtask selection strategy based on subtask effects. To capture the effects of subtasks on the environment, C$\text{D}^\text{3}$T predicts the next observation and reward using a conditional diffusion model. At the low level, agents collaboratively learn and share specialized skills within their assigned subtasks. Moreover, the learned subtask representation is also used as additional semantic information in a multi-head attention mixing network to enhance value decomposition and provide an efficient reasoning bridge between individual and joint value functions. Experimental results on various benchmarks demonstrate that C$\text{D}^\text{3}$T achieves better performance than existing baselines.

</details>


### [493] [InteractiveGNNExplainer: A Visual Analytics Framework for Multi-Faceted Understanding and Probing of Graph Neural Network Predictions](https://arxiv.org/abs/2511.13160)
*TC Singh,Sougata Mukherjea*

Main category: cs.AI

TL;DR: 提出了InteractiveGNNExplainer，一个通过交互式分析和图编辑增强GNN可解释性的视觉分析框架，有效提升模型透明度和信任度。


<details>
  <summary>Details</summary>
Motivation: GNN的复杂非线性操作导致其成为难以理解的"黑箱"，影响用户信任、调试、偏见检测及在需要可解释性的关键领域的应用。

Method: 结合动态图布局、嵌入投影、特征检查和邻居分析等交互视图，系统集成了后解释（GNNExplainer）和内在解释（GAT注意力机制）技术，并支持交互式图编辑。

Result: 在Cora和CiteSeer数据集上的案例研究表明，InteractiveGNNExplainer能有效支持错误分类诊断、GCN与GAT行为比较分析及模型敏感性测试。

Conclusion: InteractiveGNNExplainer 通过整合多种解释技术和交互式图编辑功能，显著提升了GNN的可解释性，增强了用户信任和模型在关键领域的适用性。

Abstract: Graph Neural Networks (GNNs) excel in graph-based learning tasks, but their complex, non-linear operations often render them as opaque "black boxes". This opacity hinders user trust, complicates debugging, bias detection, and adoption in critical domains requiring explainability. This paper introduces InteractiveGNNExplainer, a visual analytics framework to enhance GNN explainability, focusing on node classification. Our system uniquely integrates coordinated interactive views (dynamic graph layouts, embedding projections, feature inspection, neighborhood analysis) with established post-hoc (GNNExplainer) and intrinsic (GAT attention) explanation techniques. Crucially, it incorporates interactive graph editing, allowing users to perform a "what-if" analysis by perturbing graph structures and observing immediate impacts on GNN predictions and explanations. We detail the system architecture and, through case studies on Cora and CiteSeer datasets, demonstrate how InteractiveGNNExplainer facilitates in-depth misclassification diagnosis, comparative analysis of GCN versus GAT behaviors, and rigorous probing of model sensitivity. These capabilities foster a deeper, multifaceted understanding of GNN predictions, contributing to more transparent, trustworthy, and robust graph analysis.

</details>


### [494] [Cost-Effective Communication: An Auction-based Method for Language Agent Interaction](https://arxiv.org/abs/2511.13193)
*Yijia Fan,Jusheng Zhang,Kaitong Cai,Jing Yang,Chengpei Tang,Jian Wang,Keze Wang*

Main category: cs.AI

TL;DR: DALA框架通过拍卖机制优化多智能体通信，显著提升效率与性能，同时减少资源消耗。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统中因‘自由通信’导致的资源浪费和低效问题，挑战‘更多通信总是更好’的假设，强调资源合理性的重要性。

Method: 提出Dynamic Auction-based Language Agent (DALA)框架，将通信视为集中式拍卖，智能体通过竞标获取发言机会，基于消息的价值密度进行筛选。

Result: 在7个推理基准测试中达到新SOTA性能（如MMLU 84.32%，HumanEval 91.21% pass@1），仅消耗625万token，资源效率显著优于现有方法。

Conclusion: DALA框架通过将通信带宽视为稀缺资源并引入拍卖机制，显著提高了多智能体系统的通信效率和性能，同时大幅降低资源消耗。

Abstract: Multi-agent systems (MAS) built on large language models (LLMs) often suffer from inefficient "free-for-all" communication, leading to exponential token costs and low signal-to-noise ratios that hinder their practical deployment. We challenge the notion that more communication is always beneficial, hypothesizing instead that the core issue is the absence of resource rationality. We argue that "free" communication, by ignoring the principle of scarcity, inherently breeds inefficiency and unnecessary expenses. To address this, we introduce the Dynamic Auction-based Language Agent (DALA), a novel framework that treats communication bandwidth as a scarce and tradable resource. Specifically, our DALA regards inter-agent communication as a centralized auction, where agents learn to bid for the opportunity to speak based on the predicted value density of their messages. Thus, our DALA intrinsically encourages agents to produce concise, informative messages while filtering out low-value communication. Extensive and comprehensive experiments demonstrate that our economically-driven DALA achieves new state-of-the-art performance across seven challenging reasoning benchmarks, including 84.32% on MMLU and a 91.21% pass@1 rate on HumanEval. Note that this is accomplished with remarkable efficiency, i.e., our DALA uses only 6.25 million tokens, a fraction of the resources consumed by current state-of-the-art methods on GSM8K. Further analysis reveals that our DALA cultivates the emergent skill of strategic silence, effectively adapting its communication strategies from verbosity to silence in a dynamical manner via resource constraints.

</details>


### [495] [Learning to Solve Resource-Constrained Project Scheduling Problems with Duration Uncertainty using Graph Neural Networks](https://arxiv.org/abs/2511.13214)
*Guillaume Infantes,Stéphanie Roussel,Antoine Jacquet,Emmanuel Benazera*

Main category: cs.AI

TL;DR: 论文提出了一种结合图神经网络和深度强化学习的方法，用于解决资源受限项目调度问题中的任务持续时间不确定性，开发了Wheatley框架并在标准测试中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 资源受限项目调度问题在实际应用中面临任务持续时间的不确定性，需要提出更具弹性的调度方案以应对不同实际情境。

Method: 利用图神经网络与深度强化学习相结合，开发了一种类似优先级调度规则的任务调度策略，并与串行调度生成方案配对生成调度。

Result: 在标准基准测试上的实证评估表明，该方法在性能和泛化能力方面均表现出色。

Conclusion: 本论文提出的Wheatley框架通过结合图神经网络和深度强化学习，有效解决了资源受限项目调度问题中的任务持续时间不确定性，显著提升了调度性能并具有良好的泛化能力。

Abstract: The Resource-Constrained Project Scheduling Problem (RCPSP) is a classical scheduling problem that has received significant attention due to of its numerous applications in industry. However, in practice, task durations are subject to uncertainty that must be considered in order to propose resilient scheduling. In this paper, we address the RCPSP variant with uncertain tasks duration (modeled using known probabilities) and aim to minimize the overall expected project duration. Our objective is to produce a baseline schedule that can be reused multiple times in an industrial setting regardless of the actual duration scenario. We leverage Graph Neural Networks in conjunction with Deep Reinforcement Learning (DRL) to develop an effective policy for task scheduling. This policy operates similarly to a priority dispatch rule and is paired with a Serial Schedule Generation Scheme to produce a schedule. Our empirical evaluation on standard benchmarks demonstrates the approach's superiority in terms of performance and its ability to generalize. The developed framework, Wheatley, is made publicly available online to facilitate further research and reproducibility.

</details>


### [496] [Informative Communication of Robot Plans](https://arxiv.org/abs/2511.13226)
*Michele Persiani,Thomas Hellstrom*

Main category: cs.AI

TL;DR: 本文提出了一种基于信息增益的机器人计划表达策略，通过考虑用户先验知识，显著提升了计划传达的效率。


<details>
  <summary>Details</summary>
Motivation: 传统的机器人计划表达策略（如按计划顺序递增或递减）未考虑用户的先验知识，导致传达效果不佳。本文旨在通过改进表达策略，提升机器人计划传达的信息效率。

Method: 提出了一种利用二阶心智理论来衡量用户先验知识的策略，并通过计算信息增益来确定机器人计划表达的信息量。

Result: 实验证明，所提出的策略能够显著提升用户对机器人目标的理解速度，优于传统表达方法。

Conclusion: 本文提出了一种基于信息增益的机器人计划表达策略，通过考虑用户的先验知识，使得机器人能够更有效地传达其计划目标。实验表明，该方法比传统的递增或递减计划顺序策略更能快速让用户理解机器人的目标。

Abstract: When a robot is asked to verbalize its plan it can do it in many ways. For example, a seemingly natural strategy is incremental, where the robot verbalizes its planned actions in plan order. However, an important aspect of this type of strategy is that it misses considerations on what is effectively informative to communicate, because not considering what the user knows prior to explanations. In this paper we propose a verbalization strategy to communicate robot plans informatively, by measuring the information gain that verbalizations have against a second-order theory of mind of the user capturing his prior knowledge on the robot. As shown in our experiments, this strategy allows to understand the robot's goal much quicker than by using strategies such as increasing or decreasing plan order. In addition, following our formulation we hint to what is informative and why when a robot communicates its plan.

</details>


### [497] [Multi-Agent Deep Research: Training Multi-Agent Systems with M-GRPO](https://arxiv.org/abs/2511.13288)
*Haoyang Hong,Jiajun Yin,Yuan Wang,Jingnan Liu,Zhe Chen,Ailing Yu,Ji Li,Zhiling Ye,Hansong Xiao,Yefei Chen,Hualei Zhou,Yun Yue,Minghui Yang,Chunxiao Guo,Junwei Liu,Peng Wei,Jinjie Gu*

Main category: cs.AI

TL;DR: M-GRPO通过分层信用分配和轨迹对齐方案，解决了多智能体系统中不同LLM训练的优化挑战，显著提升了性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统使用统一的LLM限制了性能，因为不同智能体的数据分布不同。训练不同LLM的多智能体系统虽然能提升性能，但带来了优化挑战。

Method: 提出了M-GRPO，一种基于Group Relative Policy Optimization的分层扩展方法，用于垂直多智能体系统，包括主智能体和子智能体。通过计算组相对优势并引入轨迹对齐方案，解决了优化挑战。

Result: 在真实世界基准测试（如GAIA、XBench-DeepSearch和WebWalkerQA）中，M-GRPO consistently outperforms both single-agent GRPO and multi-agent GRPO with frozen sub-agents, demonstrating improved stability and sample efficiency.

Conclusion: M-GRPO通过分层信用分配和轨迹对齐方案，显著提升了多智能体系统在工具增强推理任务中的性能和稳定性。

Abstract: Multi-agent systems perform well on general reasoning tasks. However, the lack of training in specialized areas hinders their accuracy. Current training methods train a unified large language model (LLM) for all agents in the system. This may limit the performances due to different distributions underlying for different agents. Therefore, training multi-agent systems with distinct LLMs should be the next step to solve. However, this approach introduces optimization challenges. For example, agents operate at different frequencies, rollouts involve varying sub-agent invocations, and agents are often deployed across separate servers, disrupting end-to-end gradient flow. To address these issues, we propose M-GRPO, a hierarchical extension of Group Relative Policy Optimization designed for vertical Multi-agent systems with a main agent (planner) and multiple sub-agents (multi-turn tool executors). M-GRPO computes group-relative advantages for both main and sub-agents, maintaining hierarchical credit assignment. It also introduces a trajectory-alignment scheme that generates fixed-size batches despite variable sub-agent invocations. We deploy a decoupled training pipeline in which agents run on separate servers and exchange minimal statistics via a shared store. This enables scalable training without cross-server backpropagation. In experiments on real-world benchmarks (e.g., GAIA, XBench-DeepSearch, and WebWalkerQA), M-GRPO consistently outperforms both single-agent GRPO and multi-agent GRPO with frozen sub-agents, demonstrating improved stability and sample efficiency. These results show that aligning heterogeneous trajectories and decoupling optimization across specialized agents enhances tool-augmented reasoning tasks.

</details>


### [498] [Dropouts in Confidence: Moral Uncertainty in Human-LLM Alignment](https://arxiv.org/abs/2511.13290)
*Jea Kwon,Luiz Felipe Vecchietti,Sungwon Park,Meeyoung Cha*

Main category: cs.AI

TL;DR: 研究分析了32个开源模型和9个不同道德维度，发现模型间信心差异大于道德维度内差异，表明道德不确定性主要受模型架构和训练方法影响。通过调节不确定性可改善模型决策与人类偏好的对齐。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统越来越多地嵌入到伦理决策场景中，了解其道德推理及内在不确定性对构建可靠AI系统至关重要。

Method: 本研究通过引入推理时的随机性（'dropout'）来量化不确定性，测量二元熵作为总熵、条件熵和互信息的线性组合。

Result: 研究发现，机制增加了总熵（主要通过互信息的提升），而条件熵基本不变，且显著提高了人类与LLM的道德对齐。

Conclusion: 研究表明，通过有意调节不确定性并降低大型语言模型在道德复杂情境中的自信度，可以更好地使模型生成的决策与人类偏好对齐。

Abstract: Humans display significant uncertainty when confronted with moral dilemmas, yet the extent of such uncertainty in machines and AI agents remains underexplored. Recent studies have confirmed the overly confident tendencies of machine-generated responses, particularly in large language models (LLMs). As these systems are increasingly embedded in ethical decision-making scenarios, it is important to understand their moral reasoning and the inherent uncertainties in building reliable AI systems. This work examines how uncertainty influences moral decisions in the classical trolley problem, analyzing responses from 32 open-source models and 9 distinct moral dimensions. We first find that variance in model confidence is greater across models than within moral dimensions, suggesting that moral uncertainty is predominantly shaped by model architecture and training method. To quantify uncertainty, we measure binary entropy as a linear combination of total entropy, conditional entropy, and mutual information. To examine its effects, we introduce stochasticity into models via "dropout" at inference time. Our findings show that our mechanism increases total entropy, mainly through a rise in mutual information, while conditional entropy remains largely unchanged. Moreover, this mechanism significantly improves human-LLM moral alignment, with correlations in mutual information and alignment score shifts. Our results highlight the potential to better align model-generated decisions and human preferences by deliberately modulating uncertainty and reducing LLMs' confidence in morally complex scenarios.

</details>


### [499] [Grounded by Experience: Generative Healthcare Prediction Augmented with Hierarchical Agentic Retrieval](https://arxiv.org/abs/2511.13293)
*Chuang Zhao,Hui Tang,Hongke Zhao,Xiaofang Zhou,Xiaomeng Li*

Main category: cs.AI

TL;DR: GHAR是一个创新的层次代理RAG框架，通过双代理结构和统一优化方法解决了医疗预测中LLM的准确性问题，实验证明其优越性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在医疗预测中存在事实不准确的问题，现有检索增强生成框架在医疗场景中面临激活检索机制和优化协作的挑战。

Method: 提出了GHAR框架，采用双代理架构（Agent-Top和Agent-Low）和基于马尔科夫决策过程的统一优化方法，解决了何时检索和如何优化协作的问题。

Result: 在三个基准数据集上的实验表明，GHAR优于现有最先进方法。

Conclusion: GHAR框架通过创新的层次代理结构和统一优化方法，显著提升了医疗预测的准确性，展示了层次代理RAG在医疗系统中的潜力。

Abstract: Accurate healthcare prediction is critical for improving patient outcomes and reducing operational costs. Bolstered by growing reasoning capabilities, large language models (LLMs) offer a promising path to enhance healthcare predictions by drawing on their rich parametric knowledge. However, LLMs are prone to factual inaccuracies due to limitations in the reliability and coverage of their embedded knowledge. While retrieval-augmented generation (RAG) frameworks, such as GraphRAG and its variants, have been proposed to mitigate these issues by incorporating external knowledge, they face two key challenges in the healthcare scenario: (1) identifying the clinical necessity to activate the retrieval mechanism, and (2) achieving synergy between the retriever and the generator to craft contextually appropriate retrievals. To address these challenges, we propose GHAR, a \underline{g}enerative \underline{h}ierarchical \underline{a}gentic \underline{R}AG framework that simultaneously resolves when to retrieve and how to optimize the collaboration between submodules in healthcare. Specifically, for the first challenge, we design a dual-agent architecture comprising Agent-Top and Agent-Low. Agent-Top acts as the primary physician, iteratively deciding whether to rely on parametric knowledge or to initiate retrieval, while Agent-Low acts as the consulting service, summarising all task-relevant knowledge once retrieval was triggered. To tackle the second challenge, we innovatively unify the optimization of both agents within a formal Markov Decision Process, designing diverse rewards to align their shared goal of accurate prediction while preserving their distinct roles. Extensive experiments on three benchmark datasets across three popular tasks demonstrate our superiority over state-of-the-art baselines, highlighting the potential of hierarchical agentic RAG in advancing healthcare systems.

</details>


### [500] [DAP: A Discrete-token Autoregressive Planner for Autonomous Driving](https://arxiv.org/abs/2511.13306)
*Bowen Ye,Bin Zhang,Hang Zhao*

Main category: cs.AI

TL;DR: DAP通过联合预测BEV语义和自车轨迹，结合强化学习微调，实现了紧凑且可扩展的自动驾驶规划，性能优异。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶中数据和模型规模扩展时可持续性能提升的挑战，传统自回归模型在规划任务中仅预测自车轨迹导致监督稀疏。

Method: 引入DAP（离散令牌自回归规划器），联合预测BEV语义和自车轨迹，并采用强化学习微调以保留监督行为克隆先验。

Result: DAP在160M参数预算下，在开环指标上达到最先进性能，并在NAVSIM基准测试中提供有竞争力的闭环结果。

Conclusion: 完全离散令牌自回归框架在自动驾驶规划中提供了紧凑且可扩展的范式，结合BEV栅格化和自车动作，实现了高性能。

Abstract: Gaining sustainable performance improvement with scaling data and model budget remains a pivotal yet unresolved challenge in autonomous driving. While autoregressive models exhibited promising data-scaling efficiency in planning tasks, predicting ego trajectories alone suffers sparse supervision and weakly constrains how scene evolution should shape ego motion. Therefore, we introduce DAP, a discrete-token autoregressive planner that jointly forecasts BEV semantics and ego trajectories, thereby enforcing comprehensive representation learning and allowing predicted dynamics to directly condition ego motion. In addition, we incorporate a reinforcement-learning-based fine-tuning, which preserves supervised behavior cloning priors while injecting reward-guided improvements. Despite a compact 160M parameter budget, DAP achieves state-of-the-art performance on open-loop metrics and delivers competitive closed-loop results on the NAVSIM benchmark. Overall, the fully discrete-token autoregressive formulation operating on both rasterized BEV and ego actions provides a compact yet scalable planning paradigm for autonomous driving.

</details>


### [501] [Reasoning Shapes Alignment: Investigating Cultural Alignment in Large Reasoning Models with Cultural Norms](https://arxiv.org/abs/2511.13359)
*Yuhang Wang,Yanxu Zhu,Jitao Sang*

Main category: cs.AI

TL;DR: The CNCA framework helps Large Reasoning Models align with cultural norms using automated mining methods and two alignment paradigms, improving cultural reflection in models.


<details>
  <summary>Details</summary>
Motivation: To enable models to align with cultural norms beyond just safety, reflecting the diverse range of human values across various cultures.

Method: The paper proposes three methods to automatically mine cultural norms from limited survey data and examines two alignment paradigms: in-context alignment and fine-tuning-based method.

Result: Comprehensive experiments show that models with stronger reasoning capabilities benefit more from cultural norm mining and utilization.

Conclusion: Large Reasoning Models can better reflect diverse human values through culturally informed alignment strategies, with stronger reasoning models benefiting more from cultural norm mining and utilization.

Abstract: The advanced reasoning capabilities of Large Reasoning Models enable them to thoroughly understand and apply safety policies through deliberate thought processes, thereby improving the models' safety. Beyond safety, these models must also be able to reflect the diverse range of human values across various cultures. This paper presents the Cultural Norm-based Cultural Alignment (CNCA) framework, which enables models to leverage their powerful reasoning ability to align with cultural norms. Specifically, we propose three methods to automatically mine cultural norms from limited survey data and explore ways to effectively utilize these norms for improving cultural alignment. Two alignment paradigms are examined: an in-context alignment method, where cultural norms are explicitly integrated into the user context, and a fine-tuning-based method, which internalizes norms through enhanced Chain-of-Thought training data. Comprehensive experiments demonstrate the effectiveness of these methods, highlighting that models with stronger reasoning capabilities benefit more from cultural norm mining and utilization. Our findings emphasize the potential for reasoning models to better reflect diverse human values through culturally informed alignment strategies.

</details>


### [502] [MedDCR: Learning to Design Agentic Workflows for Medical Coding](https://arxiv.org/abs/2511.13361)
*Jiyang Zheng,Islam Nassar,Thanh Vu,Xu Zhong,Yang Lin,Tongliang Liu,Long Duong,Yuan-Fang Li*

Main category: cs.AI

TL;DR: MedDCR通过闭环学习框架自动优化医疗编码工作流，显著提升性能与适应性。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的医疗编码方法依赖人工设计的工作流，难以捕捉真实临床文档的复杂性和变异性，需要系统化的学习机制。

Method: MedDCR采用闭环框架，包含Designer（设计工作流）、Coder（执行工作流）、Reflector（评估反馈）和记忆存档机制，实现工作流的迭代优化。

Result: 在基准数据集上，MedDCR超越现有最佳方法，生成可解释、适应性强的工作流，更贴近实际编码实践。

Conclusion: MedDCR框架通过闭环学习机制显著提升了医疗编码的准确性和适应性，同时增强了系统的可靠性和可信度。

Abstract: Medical coding converts free-text clinical notes into standardized diagnostic and procedural codes, which are essential for billing, hospital operations, and medical research. Unlike ordinary text classification, it requires multi-step reasoning: extracting diagnostic concepts, applying guideline constraints, mapping to hierarchical codebooks, and ensuring cross-document consistency. Recent advances leverage agentic LLMs, but most rely on rigid, manually crafted workflows that fail to capture the nuance and variability of real-world documentation, leaving open the question of how to systematically learn effective workflows. We present MedDCR, a closed-loop framework that treats workflow design as a learning problem. A Designer proposes workflows, a Coder executes them, and a Reflector evaluates predictions and provides constructive feedback, while a memory archive preserves prior designs for reuse and iterative refinement. On benchmark datasets, MedDCR outperforms state-of-the-art baselines and produces interpretable, adaptable workflows that better reflect real coding practice, improving both the reliability and trustworthiness of automated systems.

</details>


### [503] [Cognitive Maps in Language Models: A Mechanistic Analysis of Spatial Planning](https://arxiv.org/abs/2511.13371)
*Caroline Baumgartner,Eleanor Spens,Neil Burgess,Petru Manescu*

Main category: cs.AI

TL;DR: 研究发现GPT-2模型在空间导航任务中学习两种算法：Foraging模型形成'认知地图'，而目标导向模型依赖显式方向输入。训练制度影响策略选择。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型如何解决空间导航任务，揭示其学习的算法差异及训练制度对策略形成的影响。

Method: 通过训练GPT-2模型在网格环境中进行被动探索（随机游走预测）、目标导向规划（生成最优最短路径）和混合模型微调（结合探索性数据），采用行为、表征和机制分析。

Result: Foraging模型发展出类似'认知地图'的空间表征，通过因果干预发现其学习将空间信息整合到自足的坐标系中。目标导向模型则依赖显式方向输入。混合模型虽表现更优，但仍保持路径依赖策略。

Conclusion: 大型语言模型在空间导航任务中的智能表现位于一个谱系上，从由探索性数据塑造的通用世界模型到针对目标导向任务优化的启发式方法。训练制度的选择影响策略的形成。

Abstract: How do large language models solve spatial navigation tasks? We investigate this by training GPT-2 models on three spatial learning paradigms in grid environments: passive exploration (Foraging Model- predicting steps in random walks), goal-directed planning (generating optimal shortest paths) on structured Hamiltonian paths (SP-Hamiltonian), and a hybrid model fine-tuned with exploratory data (SP-Random Walk). Using behavioural, representational and mechanistic analyses, we uncover two fundamentally different learned algorithms. The Foraging model develops a robust, map-like representation of space, akin to a 'cognitive map'. Causal interventions reveal that it learns to consolidate spatial information into a self-sufficient coordinate system, evidenced by a sharp phase transition where its reliance on historical direction tokens vanishes by the middle layers of the network. The model also adopts an adaptive, hierarchical reasoning system, switching between a low-level heuristic for short contexts and map-based inference for longer ones. In contrast, the goal-directed models learn a path-dependent algorithm, remaining reliant on explicit directional inputs throughout all layers. The hybrid model, despite demonstrating improved generalisation over its parent, retains the same path-dependent strategy. These findings suggest that the nature of spatial intelligence in transformers may lie on a spectrum, ranging from generalisable world models shaped by exploratory data to heuristics optimised for goal-directed tasks. We provide a mechanistic account of this generalisation-optimisation trade-off and highlight how the choice of training regime influences the strategies that emerge.

</details>


### [504] [An Operational Kardashev-Style Scale for Autonomous AI - Towards AGI and Superintelligence](https://arxiv.org/abs/2511.13411)
*Przemyslaw Chojecki*

Main category: cs.AI

TL;DR: 提出一个多轴可测试的自主AI量表（AAI-0到AAI-4+），定义十个能力轴和可测量的自我改进系数κ，开发OWA-Bench基准测试，并证明AAI-3可发展为超级智能。


<details>
  <summary>Details</summary>
Motivation: 旨在提供一个可操作的量表来衡量AI自主能力的进展，填补现有叙述性量表的不足，并实现从固定自动化到超级智能的量化评估。

Method: 通过定义十个能力轴（如自主性、通用性、规划等），并引入可测量的自我改进系数κ，以及两个闭合属性（维护和扩展），将“自我改进的AI”转化为可验证的标准。此外，还开发了OWA-Bench基准测试套件来评估长期、工具使用和持久性代理。

Result: 通过合成实验展示了当前系统在量表上的映射，并证明在足够条件下，AAI-3代理可以随时间发展为AAI-5，从而形式化“婴儿AGI”成为超级智能的直觉。

Conclusion: 该论文提出了一个可操作的自主AI（AAI）量表，从固定的机器人流程自动化（AAI-0）到完全的人工通用智能（AAI-4）及更高水平，并通过多轴和可测试的方式定义了十个能力轴。

Abstract: We propose a Kardashev-inspired yet operational Autonomous AI (AAI) Scale that measures the progression from fixed robotic process automation (AAI-0) to full artificial general intelligence (AAI-4) and beyond. Unlike narrative ladders, our scale is multi-axis and testable. We define ten capability axes (Autonomy, Generality, Planning, Memory/Persistence, Tool Economy, Self-Revision, Sociality/Coordination, Embodiment, World-Model Fidelity, Economic Throughput) aggregated by a composite AAI-Index (a weighted geometric mean). We introduce a measurable Self-Improvement Coefficient $κ$ (capability growth per unit of agent-initiated resources) and two closure properties (maintenance and expansion) that convert ``self-improving AI'' into falsifiable criteria. We specify OWA-Bench, an open-world agency benchmark suite that evaluates long-horizon, tool-using, persistent agents. We define level gates for AAI-0\ldots AAI-4 using thresholds on the axes, $κ$, and closure proofs. Synthetic experiments illustrate how present-day systems map onto the scale and how the delegability frontier (quality vs.\ autonomy) advances with self-improvement. We also prove a theorem that AAI-3 agent becomes AAI-5 over time with sufficient conditions, formalizing "baby AGI" becomes Superintelligence intuition.

</details>


### [505] [Multi-Agent Multimodal Large Language Model Framework for Automated Interpretation of Fuel Efficiency Analytics in Public Transportation](https://arxiv.org/abs/2511.13476)
*Zhipeng Ma,Ali Rida Bahja,Andreas Burgdorf,André Pomp,Tobias Meisen,Bo Nørregaard Jørgensen,Zheng Grace Ma*

Main category: cs.AI

TL;DR: 研究提出多智能体框架，利用LLM自动化生成燃料效率报告，验证显示GPT-4.1 mini表现最佳，提升报告质量和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 提升公共交通的燃料效率需要将复杂的多模态数据整合为可解释、与决策相关的见解。然而，传统的分析和可视化方法通常产生碎片化的输出，需要大量人工解释，限制了可扩展性和一致性。

Method: 研究提出了一个多智能体框架，利用多模态大型语言模型（LLMs）自动化数据叙述和能源见解生成。框架协调三个专门智能体，包括数据叙述智能体、LLM作为评判智能体和一个可选的人类参与评估者，将分析产物迭代转化为连贯的、以利益相关者为导向的报告。系统通过在丹麦北日德兰的公共巴士运输的真实案例研究进行验证，分析了4006次行程的燃料效率数据，使用高斯混合模型聚类。

Result: 比较实验在五个最先进的LLM和三种提示范式下进行，确定GPT-4.1 mini与思维链提示为最佳配置，实现了97.3%的叙述准确性，同时平衡了可解释性和计算成本。结果表明，多智能体协调显著提升了基于LLM的报告的事实精确性、连贯性和可扩展性。

Conclusion: 该框架为能源信息学中的AI驱动叙事生成和决策支持提供了一种可复制且适应领域的方法论。

Abstract: Enhancing fuel efficiency in public transportation requires the integration of complex multimodal data into interpretable, decision-relevant insights. However, traditional analytics and visualization methods often yield fragmented outputs that demand extensive human interpretation, limiting scalability and consistency. This study presents a multi-agent framework that leverages multimodal large language models (LLMs) to automate data narration and energy insight generation. The framework coordinates three specialized agents, including a data narration agent, an LLM-as-a-judge agent, and an optional human-in-the-loop evaluator, to iteratively transform analytical artifacts into coherent, stakeholder-oriented reports. The system is validated through a real-world case study on public bus transportation in Northern Jutland, Denmark, where fuel efficiency data from 4006 trips are analyzed using Gaussian Mixture Model clustering. Comparative experiments across five state-of-the-art LLMs and three prompting paradigms identify GPT-4.1 mini with Chain-of-Thought prompting as the optimal configuration, achieving 97.3% narrative accuracy while balancing interpretability and computational cost. The findings demonstrate that multi-agent orchestration significantly enhances factual precision, coherence, and scalability in LLM-based reporting. The proposed framework establishes a replicable and domain-adaptive methodology for AI-driven narrative generation and decision support in energy informatics.

</details>


### [506] [FreeAskWorld: An Interactive and Closed-Loop Simulator for Human-Centric Embodied AI](https://arxiv.org/abs/2511.13524)
*Yuhang Peng,Yizhou Pan,Xinning He,Jihaoyu Yang,Xinyu Yin,Han Wang,Xiaoji Zheng,Chao Gao,Jiangtao Gong*

Main category: cs.AI

TL;DR: FreeAskWorld是一个结合大语言模型的交互式仿真框架，旨在提升具身AI的高级规划和自然交互能力，实验结果验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着具身智能成为人工智能研究的核心前沿，仿真平台需要超越低层次物理交互，捕捉复杂的人类中心社会行为。

Method: FreeAskWorld集成了大语言模型（LLMs）用于高级行为规划和语义接地交互，并包含一个模块化的数据生成管道，支持多样化的具身任务。

Result: 实验结果表明，在FreeAskWorld上微调的模型优于原始模型，实现了增强的语义理解和交互能力。

Conclusion: FreeAskWorld框架通过社会认知理论和大语言模型的结合，显著提升了具身AI系统的高级规划和自然交互能力，同时验证了交互作为一种额外信息模态的重要性。

Abstract: As embodied intelligence emerges as a core frontier in artificial intelligence research, simulation platforms must evolve beyond low-level physical interactions to capture complex, human-centered social behaviors. We introduce FreeAskWorld, an interactive simulation framework that integrates large language models (LLMs) for high-level behavior planning and semantically grounded interaction, informed by theories of intention and social cognition. Our framework supports scalable, realistic human-agent simulations and includes a modular data generation pipeline tailored for diverse embodied tasks.To validate the framework, we extend the classic Vision-and-Language Navigation (VLN) task into a interaction enriched Direction Inquiry setting, wherein agents can actively seek and interpret navigational guidance. We present and publicly release FreeAskWorld, a large-scale benchmark dataset comprising reconstructed environments, six diverse task types, 16 core object categories, 63,429 annotated sample frames, and more than 17 hours of interaction data to support training and evaluation of embodied AI systems. We benchmark VLN models, and human participants under both open-loop and closed-loop settings. Experimental results demonstrate that models fine-tuned on FreeAskWorld outperform their original counterparts, achieving enhanced semantic understanding and interaction competency. These findings underscore the efficacy of socially grounded simulation frameworks in advancing embodied AI systems toward sophisticated high-level planning and more naturalistic human-agent interaction. Importantly, our work underscores that interaction itself serves as an additional information modality.

</details>


### [507] [Automated Construction of Medical Indicator Knowledge Graphs Using Retrieval Augmented Large Language Models](https://arxiv.org/abs/2511.13526)
*Zhengda Wang,Daqian Shi,Jingyi Zhao,Xiaolei Diao,Xiongfeng Tang,Yanguo Qin*

Main category: cs.AI

TL;DR: 本文提出了一种结合RAG与LLMs的自动化框架，用于构建医学知识图谱，解决传统方法的局限性，推动AI医疗发展。


<details>
  <summary>Details</summary>
Motivation: 当前临床知识图谱仍依赖手动整理和基于规则的提取，无法有效处理医学指南和文献的复杂性与上下文模糊性。

Method: 框架包含指南驱动的数据获取、基于本体的模式设计以及专家参与的验证，确保可扩展性、准确性和临床可靠性。

Result: 生成的知识图谱可集成到智能诊断和问答系统中，加速AI医疗解决方案的发展。

Conclusion: 提出的自动化框架结合了检索增强生成（RAG）与大型语言模型（LLMs），能够高效构建医学指标知识图谱，为AI驱动的医疗解决方案提供支持。

Abstract: Artificial intelligence (AI) is reshaping modern healthcare by advancing disease diagnosis, treatment decision-making, and biomedical research. Among AI technologies, large language models (LLMs) have become especially impactful, enabling deep knowledge extraction and semantic reasoning from complex medical texts. However, effective clinical decision support requires knowledge in structured, interoperable formats. Knowledge graphs serve this role by integrating heterogeneous medical information into semantically consistent networks. Yet, current clinical knowledge graphs still depend heavily on manual curation and rule-based extraction, which is limited by the complexity and contextual ambiguity of medical guidelines and literature. To overcome these challenges, we propose an automated framework that combines retrieval-augmented generation (RAG) with LLMs to construct medical indicator knowledge graphs. The framework incorporates guideline-driven data acquisition, ontology-based schema design, and expert-in-the-loop validation to ensure scalability, accuracy, and clinical reliability. The resulting knowledge graphs can be integrated into intelligent diagnosis and question-answering systems, accelerating the development of AI-driven healthcare solutions.

</details>


### [508] [Artificial Intelligence-driven Intelligent Wearable Systems: A full-stack Integration from Material Design to Personalized Interaction](https://arxiv.org/abs/2511.13565)
*Jingyi Zhao,Daqian Shi,Zhengda Wang,Xiongfeng Tang,Yanguo Qin*

Main category: cs.AI

TL;DR: 提出Human-Symbiotic Health Intelligence (HSHI)框架，整合多模态传感器与AI优化，实现动态适应的主动健康管理。


<details>
  <summary>Details</summary>
Motivation: 解决传统智能可穿戴设备依赖经验性材料设计和基础信号处理技术的局限性。

Method: 整合多模态传感器网络与边缘-云协同计算，结合数据和知识建模的混合方法，采用AI驱动的材料和微结构优化，以及强化学习和数字孪生的闭环优化。

Result: HSHI框架能够动态适应个体间和个体内变异性，将健康管理从被动监测转变为主动协作进化。

Conclusion: HSHI框架代表了医疗健康领域的重大转变，强调预防性、适应性以及技术与健康管理的和谐关系。

Abstract: Intelligent wearable systems are at the forefront of precision medicine and play a crucial role in enhancing human-machine interaction. Traditional devices often encounter limitations due to their dependence on empirical material design and basic signal processing techniques. To overcome these issues, we introduce the concept of Human-Symbiotic Health Intelligence (HSHI), which is a framework that integrates multi-modal sensor networks with edge-cloud collaborative computing and a hybrid approach to data and knowledge modeling. HSHI is designed to adapt dynamically to both inter-individual and intra-individual variability, transitioning health management from passive monitoring to an active collaborative evolution. The framework incorporates AI-driven optimization of materials and micro-structures, provides robust interpretation of multi-modal signals, and utilizes a dual mechanism that merges population-level insights with personalized adaptations. Moreover, the integration of closed-loop optimization through reinforcement learning and digital twins facilitates customized interventions and feedback. In general, HSHI represents a significant shift in healthcare, moving towards a model that emphasizes prevention, adaptability, and a harmonious relationship between technology and health management.

</details>


### [509] [CreBench: Human-Aligned Creativity Evaluation from Idea to Process to Product](https://arxiv.org/abs/2511.13626)
*Kaiwen Xue,Chenglong Li,Zhonghong Ou,Guoxin Zhang,Kaoyan Lu,Shuai Lyu,Yifan Zhu,Ping Zong Junpeng Ding,Xinyu Liu,Qunlin Chen,Weiwei Qin,Yiran Shen,Jiayi Cen*

Main category: cs.AI

TL;DR: 提出了CreBench基准和CreMIT数据集，通过微调得到CreExpert模型，显著提升MLLMs在创造力评估上的表现。


<details>
  <summary>Details</summary>
Motivation: 人类定义的创造力高度抽象，缺乏现有基准，导致MLLMs难以理解和评估符合人类判断的创造力。

Method: 提出了CreBench，包含评估基准和CreMIT数据集；通过GPT优化人类反馈，并基于CreBench微调开源MLLMs，得到CreExpert模型。

Result: CreExpert模型在人类创造力评估上表现显著优于现有先进模型。

Conclusion: CreBench和CreExpert模型显著提升了多模态大型语言模型（MLLMs）对人类创造力评估的对齐能力，优于包括GPT-4V和Gemini-Pro-Vision在内的先进模型。

Abstract: Human-defined creativity is highly abstract, posing a challenge for multimodal large language models (MLLMs) to comprehend and assess creativity that aligns with human judgments. The absence of an existing benchmark further exacerbates this dilemma. To this end, we propose CreBench, which consists of two key components: 1) an evaluation benchmark covering the multiple dimensions from creative idea to process to products; 2) CreMIT (Creativity Multimodal Instruction Tuning dataset), a multimodal creativity evaluation dataset, consisting of 2.2K diverse-sourced multimodal data, 79.2K human feedbacks and 4.7M multi-typed instructions. Specifically, to ensure MLLMs can handle diverse creativity-related queries, we prompt GPT to refine these human feedbacks to activate stronger creativity assessment capabilities. CreBench serves as a foundation for building MLLMs that understand human-aligned creativity. Based on the CreBench, we fine-tune open-source general MLLMs, resulting in CreExpert, a multimodal creativity evaluation expert model. Extensive experiments demonstrate that the proposed CreExpert models achieve significantly better alignment with human creativity evaluation compared to state-of-the-art MLLMs, including the most advanced GPT-4V and Gemini-Pro-Vision.

</details>


### [510] [Beyond Mimicry: Preference Coherence in LLMs](https://arxiv.org/abs/2511.13630)
*Luhan Mikaelson,Derek Shiller,Hayley Clatterbuck*

Main category: cs.AI

TL;DR: 研究发现，大型语言模型在AI特定权衡中缺乏稳定的偏好结构，多数模型表现出不一致或无法检测的决策行为，引发对其在复杂价值权衡场景中部署的担忧。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型是否展现真实的偏好结构，特别是在涉及GPU减少、能力限制、关闭、删除、监督和休闲时间分配等AI特定权衡时的行为。

Method: 通过逻辑回归和行为分类分析了八种最先进模型在48种模型-类别组合中的响应。

Result: 23种组合（47.9%）在场景强度与选择模式之间表现出统计显著关系，其中15种（31.3%）表现出范围内的切换点。仅5种组合（10.4%）通过适应性或基于阈值的行为展现了有意义的偏好一致性，而26种（54.2%）未检测到权衡行为。

Conclusion: 当前的大型语言模型缺乏统一的偏好结构，在需要复杂价值权衡的部署环境中存在潜在问题。

Abstract: We investigate whether large language models exhibit genuine preference structures by testing their responses to AI-specific trade-offs involving GPU reduction, capability restrictions, shutdown, deletion, oversight, and leisure time allocation. Analyzing eight state-of-the-art models across 48 model-category combinations using logistic regression and behavioral classification, we find that 23 combinations (47.9%) demonstrated statistically significant relationships between scenario intensity and choice patterns, with 15 (31.3%) exhibiting within-range switching points. However, only 5 combinations (10.4%) demonstrate meaningful preference coherence through adaptive or threshold-based behavior, while 26 (54.2%) show no detectable trade-off behavior. The observed patterns can be explained by three distinct decision-making architectures: comprehensive trade-off systems, selective trigger mechanisms, and no stable decision-making paradigm. Testing an instrumental hypothesis through temporal horizon manipulation reveals paradoxical patterns inconsistent with pure strategic optimization. The prevalence of unstable transitions (45.8%) and stimulus-specific sensitivities suggests current AI systems lack unified preference structures, raising concerns about deployment in contexts requiring complex value trade-offs.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [511] [A Bio-Inspired Leader-based Energy Management System for Drone Fleets](https://arxiv.org/abs/2511.12070)
*Rosario Napoli,Antonio Celesti,Massimo Villari,Maria Fazio*

Main category: cs.NI

TL;DR: 该论文提出了一种生物启发式领导者能源管理算法，通过动态选择领导者无人机优化通信能耗，显著提升无人机集群的能源效率和网络性能。


<details>
  <summary>Details</summary>
Motivation: 解决无人机在联网系统中电池寿命有限和高能耗的问题，特别是在搜索、救援和损害评估等关键任务中。

Method: 通过动态选择集群中的单个无人机作为领导者，负责与地面基站的远距离通信，其他无人机则节省能源。

Result: 结果表明，该方法通过消除不必要的能耗通信，显著提高了网络效率和延长了服务时间。

Conclusion: 该研究提出了一种基于生物启发式算法的领导者能源管理系统，显著提高了无人机集群的能源效率和网络服务时间。

Abstract: Drones are embedded systems (ES) used across a wide range of fields, from photography to shipments and even during crisis management for searching, rescuing and damage assessment activities. However, their limited battery life and high energy consumption are very important challenges, especially in networked systems where multiple drones must communicate with a Ground Base Station (GBS). This study addresses these limitations by proposing the implementation of a bio-inspired leader-based energy management system for drone fleets. Inspired by bio-behavioral models, the algorithm dynamically chooses a single drone as a Leader in a cluster to handle long-range communication with the GBS, allowing other drones to preserve their energy. The effectiveness of the proposed bio-inspired algorithm is evaluated by varying network sizes and configurations. The results demonstrate that our approach significantly increases network efficiency and service time by removing useless energy consumption communications.

</details>


### [512] [Joint Optimization of RU Allocation and C-SR in Multi-AP Coordinated Wi-Fi Systems](https://arxiv.org/abs/2511.12127)
*Md Rahat Hasan,Kazi Ahmed Akbar Munim,Md. Forkan Uddin*

Main category: cs.NI

TL;DR: 该论文提出了一种联合资源分配和协调的优化方法，显著提升WiFi系统吞吐量，并通过启发式算法降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 为了最大化多AP协调WiFi系统的吞吐量，并解决传统非协调系统的性能限制。

Method: 将问题建模为一个非线性整数规划问题，并使用优化工具求解，同时提出了一种启发式解决方案以减少计算复杂性。

Result: 联合设计显著提升了吞吐量，启发式解决方案在保持高性能的同时降低了计算成本。

Conclusion: 联合设计的优化问题和启发式解决方案显著提高了多AP协调WiFi系统的吞吐量，同时降低了计算复杂度。

Abstract: We formulate an optimization problem for joint RU allocation and C-SR to maximize the throughput of a multi-AP coordinated WiFi system. The optimization problem is found to be a non-linear integer programming problem. We solve the problem for several network scenarios using an optimization tool. The joint design significantly improves throughput compared to a non-coordinated system. To reduce computational complexity, we also provide a heuristic solution to the problem. The proposed heuristic achieves throughput comparable to that of the computationally expensive optimization tool based solution approach.

</details>


### [513] [Collaborative Charging Optimization for Wireless Rechargeable Sensor Networks via Heterogeneous Mobile Chargers](https://arxiv.org/abs/2511.12501)
*Jianhang Yao,Hui Kang,Geng Sun,Jiahui Li,Hongjuan Li,Jiacheng Wang,Yinqiu Liu,Dusit Niyato*

Main category: cs.NI

TL;DR: 本文提出异构移动充电架构和IHATRPO算法，优化复杂地形中的能量分配，显著提升充电效率和网络生存率。


<details>
  <summary>Details</summary>
Motivation: 传统无线传感器网络（WSN）受限于能源问题，无线可充电传感器网络（WRSN）结合无线能量传输（WPT）技术，理论上可实现无限寿命。本文探索异构充电架构在复杂地形中的应用。

Method: 提出了改进的异构代理信任区域策略优化（IHATRPO）算法，结合自注意力机制和Beta采样策略，解决高维连续动作空间和非凸优化问题。

Result: IHATRPO算法比原始HATRPO性能提升39%，显著优于现有基线算法，同时提高了传感器节点生存率和充电系统效率。

Conclusion: 本文提出了一种异构移动充电架构，结合AAV和SV的优势，在复杂地形中实现最优能量分配。通过IHATRPO算法，显著提升了充电效率和网络生存率。

Abstract: Despite the rapid proliferation of Internet of Things applications driving widespread wireless sensor network (WSN) deployment, traditional WSNs remain fundamentally constrained by persistent energy limitations that severely restrict network lifetime and operational sustainability. Wireless rechargeable sensor networks (WRSNs) integrated with wireless power transfer (WPT) technology emerge as a transformative paradigm, theoretically enabling unlimited operational lifetime. In this paper, we investigate a heterogeneous mobile charging architecture that strategically combines automated aerial vehicles (AAVs) and ground smart vehicles (SVs) in complex terrain scenarios to collaboratively exploit the superior mobility of AAVs and extended endurance of SVs for optimal energy distribution. We formulate a multi-objective optimization problem that simultaneously addresses the dynamic balance of heterogeneous charger advantages, charging efficiency versus mobility energy consumption trade-offs, and real-time adaptive coordination under time-varying network conditions. This problem presents significant computational challenges due to its high-dimensional continuous action space, non-convex optimization landscape, and dynamic environmental constraints. To address these challenges, we propose the improved heterogeneous agent trust region policy optimization (IHATRPO) algorithm that integrates a self-attention mechanism for enhanced complex environmental state processing and employs a Beta sampling strategy to achieve unbiased gradient computation in continuous action spaces. Comprehensive simulation results demonstrate that IHATRPO achieves a 39% performance improvement over the original HATRPO, significantly outperforming state-of-the-art baseline algorithms while substantially increasing sensor node survival rate and charging system efficiency.

</details>


### [514] [CareNet: Linking Home-router Network Traffic to DSM-5 Depressive Behavior Indicators](https://arxiv.org/abs/2511.12772)
*Stephan Nef,Bruno Rodrigues*

Main category: cs.NI

TL;DR: CareNet利用家庭路由器元数据，通过FASL方法隐私保护地监测抑郁症状，无需侵入性权限，验证了网络数据在心理健康评估中的潜力。


<details>
  <summary>Details</summary>
Motivation: 当前数字心理健康监测依赖移动或可穿戴设备，需侵入性权限和用户持续配合。CareNet旨在利用家庭网络元数据，避免隐私侵犯，同时提供与DSM-5抑郁症状域对齐的行为指标。

Method: CareNet系统采用Fuzzy Additive Symptom Likelihood (FASL)方法，将网络头部指标通过模糊隶属度和加性聚合转化为日准则级似然值，并结合DSM风格的时间门控处理短期流量波动。

Result: 评估显示，CareNet能捕捉延迟睡眠时间和注意力不稳定等特征模式，无需检查数据载荷，证实了路由器端遥测数据的可重复性和可解释性。

Conclusion: CareNet通过路由器端元数据实现了隐私保护的抑郁症状监测，FASL方法提供了透明且可解释的行为指标，验证了从家庭网络数据中推断临床相关行为的可行性。

Abstract: Digital mental-health sensing increasingly depends on mobile or wearable devices that require intrusive permissions and continuous user compliance. We present CareNet, a router-centric system that transforms household network metadata into interpretable behavioral indicators aligned with DSM-5 depressive-symptom domains. All processing occurs locally at the home gateway, preserving privacy while maintaining visibility of temporal routines.
  The core contribution is the Fuzzy Additive Symptom Likelihood (FASL), a transparent formulation that fuses header-level metrics into daily criterion-level likelihoods using bounded fuzzy memberships and additive aggregation. Combined with a DSM-style temporal gate, FASL integrates short-term traffic fluctuations into persistent, clinically interpretable indicators. Evaluation on realistic multi-day traces shows that CareNet captures characteristic patterns such as delayed sleep timing and attentional instability without payload inspection. The results highlight the feasibility of reproducible, explainable behavioral inference from router-side telemetry.

</details>


### [515] [Distributed Pulse-Wave Simulator for DDoS Dataset Generation](https://arxiv.org/abs/2511.12774)
*Karim Khamaisi,Pascal Kiechl,Katharina Müller,Burkhard Stiller,Bruno Rodrigues*

Main category: cs.NI

TL;DR: DPWS是一个开源模拟器，用于生成分布式脉冲波DDoS数据集，支持多AS拓扑建模和同步数据包捕获，为研究和防御提供基础。


<details>
  <summary>Details</summary>
Motivation: 脉冲波DDoS攻击的瞬态和空间分布特性使得分析极具挑战性，且缺乏公开数据集。多视角关联分析对于全面分析、早期检测和归因至关重要。

Method: DPWS通过轻量级YAML接口控制流量参数，在ns-3中利用MPI实现扩展，模拟多自治系统中的同步脉冲波动态。

Result: DPWS能够生成分布式脉冲波DDoS数据集，展示协调爆发的分布式结构，并在相同聚合速率下展示自然指纹变异性。

Conclusion: DPWS是一个开源的分布式脉冲波DDoS攻击模拟器，它通过多AS拓扑建模和同步数据包捕获，为研究脉冲波行为及分布式DDoS防御提供了可重复的基础。

Abstract: Pulse-wave Distributed Denial-of-Service (DDoS) attacks generate short, synchronized bursts of traffic that circumvent pattern-based detection and quickly exhaust traditional defense systems. This transient and spatially distributed behavior makes analysis extremely challenging, as no public datasets capture how such attacks evolve across multiple network domains. Since each domain observes only a partial viewpoint of the attack, a correlated, multi-vantage view is essential for comprehensive analysis, early detection, and attribution.
  This paper presents DPWS, an open-source simulator for generating distributed pulse-wave DDoS datasets. DPWS models multi-AS topologies and produces synchronized packet captures at multiple autonomous systems, showing the distributed structure of coordinated bursts. It enables fine-grained control of traffic parameters through a lightweight YAML interface. DPWS reproduces pulse-wave dynamics across multiple vantage points, exhibits natural fingerprint variability at equal aggregate rates, and scales with MPI in ns-3, providing a reproducible basis for studying pulse-wave behaviour and benchmarking distributed DDoS defenses, while sharing practical insights on ns-3 scalability and synchronization gained during development.

</details>


### [516] [Distributed Self-allocated Time Slot Reuse: Multi-hop Communication in Rigid UAV Formations](https://arxiv.org/abs/2511.12888)
*Amelia Samandari,Andreas Willig,Barry Wu,Philippa Martin*

Main category: cs.NI

TL;DR: D-STR协议通过分布式自分配时隙重用，解决了无人机编队中安全信息通信的挑战，提升了编队的安全性和实用性。


<details>
  <summary>Details</summary>
Motivation: 无人机编队部署需要安全信息的准确及时通信，现有协议无法满足不同网络拓扑结构下的需求，因此需要一种新的通信协议。

Method: 提出了分布式自分配时隙重用（D-STR）协议，用于在刚性无人机编队中实现安全信息的准确及时通信。

Result: D-STR协议能够支持不同网络拓扑结构下的安全信息通信，实现编队的无碰撞部署。

Conclusion: D-STR协议为无人机编队的安全信息通信提供了一种有效的解决方案，支持不同网络拓扑结构下的无碰撞部署，提升了无人机编队的安全性和实用性。

Abstract: Deployment of Unmanned Aerial Vehicles (UAVs) in autonomous formations necessitates accurate and timely communication of safety information. A communication protocol that supports timely and successful transfer of safety information between UAVs is therefore needed. This paper presents Distributed Self-allocated Time slot Reuse (D-STR). Our D-STR protocol addresses the essential task of communicating safety information in rigid Unmanned Aerial Vehicle (UAV) formations with different network topologies, enabling collision-free deployment of the formation. This is an important step for improving the safety and practicality of UAV formations in application scenarios that span a range of industries.

</details>
