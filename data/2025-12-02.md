<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 236]
- [cs.OS](#cs.OS) [Total: 2]
- [cs.AI](#cs.AI) [Total: 67]
- [cs.NI](#cs.NI) [Total: 20]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.DS](#cs.DS) [Total: 13]
- [cs.DC](#cs.DC) [Total: 12]
- [cs.SE](#cs.SE) [Total: 30]
- [cs.RO](#cs.RO) [Total: 80]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [MOTION: ML-Assisted On-Device Low-Latency Motion Recognition](https://arxiv.org/abs/2512.00008)
*Veeramani Pugazhenthi,Wei-Hsiang Chu,Junwei Lu,Jadyn N. Miyahira,Soheil Salehi*

Main category: cs.CV

TL;DR: 研究提出了一种仅使用三轴加速度传感器构建高效运动模型的方法，通过AutoML和轻量级算法实现实时手势识别，神经网络表现最佳。


<details>
  <summary>Details</summary>
Motivation: 随着低延迟手势识别微型设备在日常人机交互和医疗监测领域的应用日益增多，需要快速高效地跟踪运动并避免误报。

Method: 研究探索了AutoML流水线从数据段中提取最重要特征的能力，并利用这些特征训练多个轻量级机器学习算法。

Result: 研究发现，神经网络在准确性、延迟和内存使用之间提供了最佳平衡，WeBe Band能够实现可靠的实时手势识别。

Conclusion: 神经网络在准确性、延迟和内存使用之间提供了最佳平衡，WeBe Band能够实现可靠的实时手势识别，具有在实时医疗监测解决方案中应用的巨大潜力。

Abstract: The use of tiny devices capable of low-latency gesture recognition is gaining momentum in everyday human-computer interaction and especially in medical monitoring fields. Embedded solutions such as fall detection, rehabilitation tracking, and patient supervision require fast and efficient tracking of movements while avoiding unwanted false alarms. This study presents an efficient solution on how to build very efficient motion-based models only using triaxial accelerometer sensors. We explore the capability of the AutoML pipelines to extract the most important features from the data segments. This approach also involves training multiple lightweight machine learning algorithms using the extracted features. We use WeBe Band, a multi-sensor wearable device that is equipped with a powerful enough MCU to effectively perform gesture recognition entirely on the device. Of the models explored, we found that the neural network provided the best balance between accuracy, latency, and memory use. Our results also demonstrate that reliable real-time gesture recognition can be achieved in WeBe Band, with great potential for real-time medical monitoring solutions that require a secure and fast response time.

</details>


### [2] [Closing the Gap: Data-Centric Fine-Tuning of Vision Language Models for the Standardized Exam Questions](https://arxiv.org/abs/2512.00042)
*Egemen Sert,Şeyda Ertekin*

Main category: cs.CV

TL;DR: 研究表明高质量数据的监督微调（SFT）可与专有方法媲美，数据组合和表示语法对多模态推理至关重要，为开放权重视觉语言模型提供了数据为中心的框架。


<details>
  <summary>Details</summary>
Motivation: 标准化考试问题为多模态推理提供了严格且可验证的测试平台，而当前研究多集中在算法进步上，数据为中心的视觉语言推理基础较少被探索。

Method: 通过编译一个包含1.614亿标记的多模态数据集（结合教科书问题-解决方案对、课程对齐的图表和上下文材料），并使用优化的推理语法（QMSA）对Qwen-2.5VL-32B模型进行监督微调（SFT）。

Result: 微调后的模型在新发布的基准YKSUniform上达到了78.6%的准确率，仅比Gemini 2.0 Flash低1.0%，该基准标准化了309个课程主题下的1,854个多模态考试问题。

Conclusion: 数据组合和表示语法在多模态推理中起决定性作用，本研究为开放权重视觉语言模型提供了一个以数据为中心的框架，证明了精心策划和基于课程的多模态数据可以将监督微调提升至接近最先进的性能。

Abstract: Multimodal reasoning has become a cornerstone of modern AI research. Standardized exam questions offer a uniquely rigorous testbed for such reasoning, providing structured visual contexts and verifiable answers. While recent progress has largely focused on algorithmic advances such as reinforcement learning (e.g., GRPO, DPO), the data centric foundations of vision language reasoning remain less explored.
  We show that supervised fine-tuning (SFT) with high-quality data can rival proprietary approaches. To this end, we compile a 161.4 million token multimodal dataset combining textbook question-solution pairs, curriculum aligned diagrams, and contextual materials, and fine-tune Qwen-2.5VL-32B using an optimized reasoning syntax (QMSA). The resulting model achieves 78.6% accuracy, only 1.0% below Gemini 2.0 Flash, on our newly released benchmark YKSUniform, which standardizes 1,854 multimodal exam questions across 309 curriculum topics.
  Our results reveal that data composition and representational syntax play a decisive role in multimodal reasoning. This work establishes a data centric framework for advancing open weight vision language models, demonstrating that carefully curated and curriculum-grounded multimodal data can elevate supervised fine-tuning to near state-of-the-art performance.

</details>


### [3] [PEFT-DML: Parameter-Efficient Fine-Tuning Deep Metric Learning for Robust Multi-Modal 3D Object Detection in Autonomous Driving](https://arxiv.org/abs/2512.00060)
*Abdolazim Rezaei,Mehdi Sookhak*

Main category: cs.CV

TL;DR: PEFT-DML是一种参数高效的深度度量学习框架，用于自动驾驶中的多模态3D目标检测，显著提升鲁棒性和效率。


<details>
  <summary>Details</summary>
Motivation: 传统模型假设传感器固定可用，无法应对传感器缺失或未知模态组合的挑战，PEFT-DML旨在解决这一问题。

Method: 结合低秩适应（LoRA）和适配器层，PEFT-DML将多种模态（LiDAR、雷达、相机、IMU、GNSS）映射到共享潜在空间。

Result: 在nuScenes基准测试中，PEFT-DML展示了更高的准确性和对快速运动、天气变化及领域迁移的鲁棒性。

Conclusion: PEFT-DML通过参数高效的深度度量学习框架，在自动驾驶中实现了鲁棒的多模态3D目标检测，尤其在传感器缺失或未知模态组合情况下表现优异。

Abstract: This study introduces PEFT-DML, a parameter-efficient deep metric learning framework for robust multi-modal 3D object detection in autonomous driving. Unlike conventional models that assume fixed sensor availability, PEFT-DML maps diverse modalities (LiDAR, radar, camera, IMU, GNSS) into a shared latent space, enabling reliable detection even under sensor dropout or unseen modality class combinations. By integrating Low-Rank Adaptation (LoRA) and adapter layers, PEFT-DML achieves significant training efficiency while enhancing robustness to fast motion, weather variability, and domain shifts. Experiments on benchmarks nuScenes demonstrate superior accuracy.

</details>


### [4] [SplatFont3D: Structure-Aware Text-to-3D Artistic Font Generation with Part-Level Style Control](https://arxiv.org/abs/2512.00413)
*Ji Gan,Lingxu Chen,Jiaxu Leng,Xinbo Gao*

Main category: cs.CV

TL;DR: SplatFont3D是一个新颖的3D艺术字体生成框架，通过3D高斯溅射和动态组件分配策略，实现了部分级别的风格控制，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 3D艺术字体生成在沉浸式3D环境和增强2D艺术字体生成方面具有潜力，但现有研究主要集中在2D艺术字体，3D-AFG领域尚未充分探索。

Method: 提出了SplatFont3D，一个基于3D高斯溅射的结构感知文本到3D艺术字体生成框架，包括Glyph2Cloud模块和动态组件分配策略。

Result: SplatFont3D在风格文本一致性、视觉质量和渲染效率方面表现优于现有3D模型。

Conclusion: SplatFont3D框架在风格文本一致性、视觉质量和渲染效率方面优于现有的3D模型，为3D艺术字体生成提供了更明确和有效的部分级别风格控制。

Abstract: Artistic font generation (AFG) can assist human designers in creating innovative artistic fonts. However, most previous studies primarily focus on 2D artistic fonts in flat design, leaving personalized 3D-AFG largely underexplored. 3D-AFG not only enables applications in immersive 3D environments such as video games and animations, but also may enhance 2D-AFG by rendering 2D fonts of novel views. Moreover, unlike general 3D objects, 3D fonts exhibit precise semantics with strong structural constraints and also demand fine-grained part-level style control. To address these challenges, we propose SplatFont3D, a novel structure-aware text-to-3D AFG framework with 3D Gaussian splatting, which enables the creation of 3D artistic fonts from diverse style text prompts with precise part-level style control. Specifically, we first introduce a Glyph2Cloud module, which progressively enhances both the shapes and styles of 2D glyphs (or components) and produces their corresponding 3D point clouds for Gaussian initialization. The initialized 3D Gaussians are further optimized through interaction with a pretrained 2D diffusion model using score distillation sampling. To enable part-level control, we present a dynamic component assignment strategy that exploits the geometric priors of 3D Gaussians to partition components, while alleviating drift-induced entanglement during 3D Gaussian optimization. Our SplatFont3D provides more explicit and effective part-level style control than NeRF, attaining faster rendering efficiency. Experiments show that our SplatFont3D outperforms existing 3D models for 3D-AFG in style-text consistency, visual quality, and rendering efficiency.

</details>


### [5] [DL-CapsNet: A Deep and Light Capsule Network](https://arxiv.org/abs/2512.00061)
*Pouya Shiri,Amirali Baniasadi*

Main category: cs.CV

TL;DR: DL-CapsNet是一种深层胶囊网络变体，通过胶囊汇总层减少参数，实现高效训练和推理，适用于复杂图像分类任务。


<details>
  <summary>Details</summary>
Motivation: 胶囊网络（CapsNet）在检测具有重叠类别或仿射变换的图像时比CNN更准确，但现有方法在复杂性和参数数量上存在局限。

Method: 提出了一个深层胶囊网络变体（DL-CapsNet），包含多个胶囊层，并设计了胶囊汇总层以减少参数数量。

Result: DL-CapsNet在保持高准确率的同时，参数数量少，训练和推理速度更快，能处理高类别复杂数据集。

Conclusion: DL-CapsNet是一种高效的胶囊网络变体，通过减少参数数量降低了复杂性，同时保持了高准确率，适用于处理复杂数据集。

Abstract: Capsule Network (CapsNet) is among the promising classifiers and a possible successor of the classifiers built based on Convolutional Neural Network (CNN). CapsNet is more accurate than CNNs in detecting images with overlapping categories and those with applied affine transformations. In this work, we propose a deep variant of CapsNet consisting of several capsule layers. In addition, we design the Capsule Summarization layer to reduce the complexity by reducing the number of parameters. DL-CapsNet, while being highly accurate, employs a small number of parameters and delivers faster training and inference. DL-CapsNet can process complex datasets with a high number of categories.

</details>


### [6] [Satellite to Street : Disaster Impact Estimator](https://arxiv.org/abs/2512.00065)
*Sreesritha Sai,Sai Venkata Suma Sreeja,Deepthi,Nikhil*

Main category: cs.CV

TL;DR: 提出一种改进的U-Net架构，结合特征融合和加权损失函数，显著提升灾后损害评估的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 传统的手动卫星图像解释方法效率低且主观，而现有的深度学习模型在细微结构变化和严重类别不平衡方面表现不佳。

Method: 采用改进的双输入U-Net架构，结合增强的特征融合和类别感知加权损失函数，以处理灾前和灾后卫星图像。

Result: 在公开灾害数据集上的实验表明，该方法在结构损害的定位和分类上优于传统分割和基线变化检测模型。

Conclusion: 该论文提出的深度学习方法显著提高了灾后损害评估的准确性和效率，为数据驱动的灾害管理提供了有力支持。

Abstract: Accurate post-disaster damage assessment is of high importance for prioritizing emergency response; however, manual interpretation of satellite imagery is slow, subjective, and hard to scale. While deep-learning models for image segmentation, such as U-Net-based baselines and change-detection models, are useful baselines, they often struggle with subtle structural variations and severe class imbalance, yielding poor detection of highly damaged regions. The present work proposes a deep-learning framework that jointly processes pre- and post-disaster satellite images to obtain fine-grained pixel-level damage maps: Satellite-to-Street: Disaster Impact Estimator. The model uses a modified dual-input U-Net architecture with enhanced feature fusion to capture both the local structural changes as well as the broader contextual cues. Class-aware weighted loss functions are integrated in order to handle the dominance of undamaged pixels in real disaster datasets, thus enhancing sensitivity toward major and destroyed categories. Experimentation on publicly available disaster datasets shows improved localization and classification of structural damage when compared to traditional segmentation and baseline change-detection models. The resulting damage maps provide a rapid and consistent assessment mechanism to support and not replace expert decision-making, thus allowing more efficient, data-driven disaster management.

</details>


### [7] [Gaussian Swaying: Surface-Based Framework for Aerodynamic Simulation with 3D Gaussians](https://arxiv.org/abs/2512.01306)
*Hongru Yan,Xiang Zhang,Zeyuan Chen,Fangyin Wei,Zhuowen Tu*

Main category: cs.CV

TL;DR: Gaussian Swaying 是一种基于3D高斯的空气动力学模拟框架，统一模拟与渲染，高效且精细，实验证明其性能优越。


<details>
  <summary>Details</summary>
Motivation: 自然界中的运动（如树枝摇曳、旗帜飘动）受空气动力学影响，这对视觉和图形学的真实感至关重要。

Method: 采用基于3D高斯函数的表面建模框架，避免了昂贵的网格化或离散位置数据的依赖，支持高效的空气动力学交互。

Result: 在合成和真实数据集上的综合实验表明，Gaussian Swaying 在多种指标上均达到最先进的性能和效率。

Conclusion: Gaussian Swaying 提供了一种高效且精细的空气动力学模拟方法，统一了模拟与渲染，实现了最先进的性能和效率。

Abstract: Branches swaying in the breeze, flags rippling in the wind, and boats rocking on the water all show how aerodynamics shape natural motion -- an effect crucial for realism in vision and graphics. In this paper, we present Gaussian Swaying, a surface-based framework for aerodynamic simulation using 3D Gaussians. Unlike mesh-based methods that require costly meshing, or particle-based approaches that rely on discrete positional data, Gaussian Swaying models surfaces continuously with 3D Gaussians, enabling efficient and fine-grained aerodynamic interaction. Our framework unifies simulation and rendering on the same representation: Gaussian patches, which support force computation for dynamics while simultaneously providing normals for lightweight shading. Comprehensive experiments on both synthetic and real-world datasets across multiple metrics demonstrate that Gaussian Swaying achieves state-of-the-art performance and efficiency, offering a scalable approach for realistic aerodynamic scene simulation.

</details>


### [8] [ProvRain: Rain-Adaptive Denoising and Vehicle Detection via MobileNet-UNet and Faster R-CNN](https://arxiv.org/abs/2512.00073)
*Aswinkumar Varathakumaran,Nirmala Paramanandham*

Main category: cs.CV

TL;DR: ProvRain通过MobileNet-U-Net和课程训练，提升了夜间雨天车辆检测的准确性和去噪效果。


<details>
  <summary>Details</summary>
Motivation: 解决夜间雨天条件下车辆检测中的噪声问题，同时保持检测准确性。

Method: 采用轻量级MobileNet-U-Net架构，结合课程训练，使用合成数据和PVDN数据集进行训练。

Result: 在雨天夜间帧中，检测准确率提高8.94%，召回率提高10.25%；去噪效果在PSNR、SSIM和LPIPS指标上均有显著提升。

Conclusion: ProvRain管道通过轻量级MobileNet-U-Net架构和课程训练，显著提升了夜间雨天条件下的车辆检测性能，同时在去噪效果上也优于其他方法。

Abstract: Provident vehicle detection has a lot of scope in the detection of vehicle during night time. The extraction of features other than the headlamps of vehicles allows us to detect oncoming vehicles before they appear directly on the camera. However, it faces multiple issues especially in the field of night vision, where a lot of noise caused due to weather conditions such as rain or snow as well as camera conditions. This paper focuses on creating a pipeline aimed at dealing with such noise while at the same time maintaining the accuracy of provident vehicular detection. The pipeline in this paper, ProvRain, uses a lightweight MobileNet-U-Net architecture tuned to generalize to robust weather conditions by using the concept of curricula training. A mix of synthetic as well as available data from the PVDN dataset is used for this. This pipeline is compared to the base Faster RCNN architecture trained on the PVDN dataset to see how much the addition of a denoising architecture helps increase the detection model's performance in rainy conditions. The system boasts an 8.94\% increase in accuracy and a 10.25\% increase in recall in the detection of vehicles in rainy night time frames. Similarly, the custom MobileNet-U-Net architecture that was trained also shows a 10-15\% improvement in PSNR, a 5-6\% increase in SSIM, and upto a 67\% reduction in perceptual error (LPIPS) compared to other transformer approaches.

</details>


### [9] [Adapter Shield: A Unified Framework with Built-in Authentication for Preventing Unauthorized Zero-Shot Image-to-Image Generation](https://arxiv.org/abs/2512.00075)
*Jun Jia,Hongyi Miao,Yingjie Zhou,Wangqiu Zhou,Jianbo Zhang,Linhan Cao,Dandan Zhu,Hua Yang,Xiongkuo Min,Wei Sun,Guangtao Zhai*

Main category: cs.CV

TL;DR: Adapter Shield 是一种保护个人图像不被滥用于零样本生成的解决方案，通过加密和对抗扰动技术确保只有授权用户能正常使用。


<details>
  <summary>Details</summary>
Motivation: 随着扩散模型的快速发展，零样本图像生成技术带来了创意可能性，但也带来了知识产权侵犯的风险，如未经授权的身份克隆和风格模仿。

Method: 通过构建可逆加密系统，将原始嵌入映射到不同的加密表示，并设计多目标对抗扰动方法，主动将原始嵌入转移到指定的加密模式。

Result: 广泛评估表明，该方法在阻止未经授权的零样本图像合成方面超越了现有最先进的防御方法。

Conclusion: Adapter Shield 是一种有效的解决方案，能够保护个人图像在零样本生成场景中不被滥用，同时支持对已验证用户的灵活和安全访问控制。

Abstract: With the rapid progress in diffusion models, image synthesis has advanced to the stage of zero-shot image-to-image generation, where high-fidelity replication of facial identities or artistic styles can be achieved using just one portrait or artwork, without modifying any model weights. Although these techniques significantly enhance creative possibilities, they also pose substantial risks related to intellectual property violations, including unauthorized identity cloning and stylistic imitation. To counter such threats, this work presents Adapter Shield, the first universal and authentication-integrated solution aimed at defending personal images from misuse in zero-shot generation scenarios. We first investigate how current zero-shot methods employ image encoders to extract embeddings from input images, which are subsequently fed into the UNet of diffusion models through cross-attention layers. Inspired by this mechanism, we construct a reversible encryption system that maps original embeddings into distinct encrypted representations according to different secret keys. The authorized users can restore the authentic embeddings via a decryption module and the correct key, enabling normal usage for authorized generation tasks. For protection purposes, we design a multi-target adversarial perturbation method that actively shifts the original embeddings toward designated encrypted patterns. Consequently, protected images are embedded with a defensive layer that ensures unauthorized users can only produce distorted or encrypted outputs. Extensive evaluations demonstrate that our method surpasses existing state-of-the-art defenses in blocking unauthorized zero-shot image synthesis, while supporting flexible and secure access control for verified users.

</details>


### [10] [Diffusion-Based Synthetic Brightfield Microscopy Images for Enhanced Single Cell Detection](https://arxiv.org/abs/2512.00078)
*Mario de Jesus da Graca,Jörg Dahlkemper,Peer Stelldinger*

Main category: cs.CV

TL;DR: 通过扩散模型生成合成亮场显微镜图像，实验证明其能有效提升细胞检测模型的性能，且生成的图像高度逼真，专家难以区分。


<details>
  <summary>Details</summary>
Motivation: 亮场显微镜中准确的单细胞检测对生物研究至关重要，但数据稀缺和注释瓶颈限制了深度学习方法的发展。

Method: 使用基于U-Net的扩散模型生成合成亮场显微镜图像，并通过YOLOv8、YOLOv9和RT-DETR等模型在不同比例的合成与真实图像数据集上进行实验。

Result: 实验显示，使用合成数据训练可以提高检测准确率（成本极低）。人类专家调查表明生成的图像具有高度真实性，专家无法区分合成与真实图像（准确率50%）。

Conclusion: 基于扩散模型的合成数据生成是显微镜图像分析中增强真实数据集的有前途方法，减少了对大量手动注释的依赖，并可能提高细胞检测模型的鲁棒性。

Abstract: Accurate single cell detection in brightfield microscopy is crucial for biological research, yet data scarcity and annotation bottlenecks limit the progress of deep learning methods. We investigate the use of unconditional models to generate synthetic brightfield microscopy images and evaluate their impact on object detection performance. A U-Net based diffusion model was trained and used to create datasets with varying ratios of synthetic and real images. Experiments with YOLOv8, YOLOv9 and RT-DETR reveal that training with synthetic data can achieve improved detection accuracies (at minimal costs). A human expert survey demonstrates the high realism of generated images, with experts not capable to distinguish them from real microscopy images (accuracy 50%). Our findings suggest that diffusion-based synthetic data generation is a promising avenue for augmenting real datasets in microscopy image analysis, reducing the reliance on extensive manual annotation and potentially improving the robustness of cell detection models.

</details>


### [11] [Conceptual Evaluation of Deep Visual Stereo Odometry for the MARWIN Radiation Monitoring Robot in Accelerator Tunnels](https://arxiv.org/abs/2512.00080)
*André Dehne,Juri Zach,Peer Stelldinger*

Main category: cs.CV

TL;DR: 本文提出DVSO作为MARWIN机器人导航的替代方案，利用立体视觉和自监督学习提升灵活性，尽管存在挑战，但在安全关键环境中具有潜力。


<details>
  <summary>Details</summary>
Motivation: MARWIN机器人当前导航方法在预定义区域表现稳健，但缺乏对未知几何和障碍的灵活性。DVSO作为一种纯视觉方法，有望解决这一问题。

Method: 本文探讨了深度视觉立体里程计（DVSO）结合3D几何约束的方法，利用立体视差、光流和自监督学习联合估计深度和自我运动，无需标记数据。

Result: DVSO在加速器隧道环境中展示了减少尺度漂移、低成本感知和可扩展数据收集的优势，但仍需解决低纹理表面和光照变化等挑战。

Conclusion: 本文提出了一种基于深度视觉立体里程计（DVSO）的导航方法，旨在提升MARWIN机器人在未知几何和障碍环境中的灵活性。尽管面临低纹理表面、光照变化等挑战，DVSO结合立体视觉和自监督学习展现了在安全关键基础设施中自主导航的潜力。

Abstract: The MARWIN robot operates at the European XFEL to perform autonomous radiation monitoring in long, monotonous accelerator tunnels where conventional localization approaches struggle. Its current navigation concept combines lidar-based edge detection, wheel/lidar odometry with periodic QR-code referencing, and fuzzy control of wall distance, rotation, and longitudinal position. While robust in predefined sections, this design lacks flexibility for unknown geometries and obstacles. This paper explores deep visual stereo odometry (DVSO) with 3D-geometric constraints as a focused alternative. DVSO is purely vision-based, leveraging stereo disparity, optical flow, and self-supervised learning to jointly estimate depth and ego-motion without labeled data. For global consistency, DVSO can subsequently be fused with absolute references (e.g., landmarks) or other sensors. We provide a conceptual evaluation for accelerator tunnel environments, using the European XFEL as a case study. Expected benefits include reduced scale drift via stereo, low-cost sensing, and scalable data collection, while challenges remain in low-texture surfaces, lighting variability, computational load, and robustness under radiation. The paper defines a research agenda toward enabling MARWIN to navigate more autonomously in constrained, safety-critical infrastructures.

</details>


### [12] [Exploring Diagnostic Prompting Approach for Multimodal LLM-based Visual Complexity Assessment: A Case Study of Amazon Search Result Pages](https://arxiv.org/abs/2512.00082)
*Divendar Murtadak,Yoon Kim,Trilokya Akula*

Main category: cs.CV

TL;DR: 诊断提示方法显著提升了MLLM在视觉复杂度评估中的表现，但与人类判断仍存在差异，需进一步优化。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索诊断提示是否能改善MLLM在视觉复杂度评估中的可靠性，以更接近人类判断。

Method: 通过比较诊断提示与基于格式塔原则的标准提示方法，使用200个亚马逊SRP页面和人类专家标注进行评估。

Result: 诊断提示显著提升了预测人类复杂度判断的能力（F1分数从0.031提升至0.297，相对提升858%），但绝对性能仍较低（Cohen's κ=0.071）。模型更关注视觉设计元素（如徽章杂乱度，重要性38.6%），而人类更注重内容相似性。

Conclusion: 诊断提示方法在提升多模态大型语言模型（MLLM）评估亚马逊搜索结果页面（SRP）视觉复杂度的可靠性方面显示出潜力，但仍需进一步研究以解决人类与模型间的一致性问题。

Abstract: This study investigates whether diagnostic prompting can improve Multimodal Large Language Model (MLLM) reliability for visual complexity assessment of Amazon Search Results Pages (SRP). We compare diagnostic prompting with standard gestalt principles-based prompting using 200 Amazon SRP pages and human expert annotations. Diagnostic prompting showed notable improvements in predicting human complexity judgments, with F1-score increasing from 0.031 to 0.297 (+858\% relative improvement), though absolute performance remains modest (Cohen's $κ$ = 0.071). The decision tree revealed that models prioritize visual design elements (badge clutter: 38.6\% importance) while humans emphasize content similarity, suggesting partial alignment in reasoning patterns. Failure case analysis reveals persistent challenges in MLLM visual perception, particularly for product similarity and color intensity assessment. Our findings indicate that diagnostic prompting represents a promising initial step toward human-aligned MLLM-based evaluation, though failure cases with consistent human-MLLM disagreement require continued research and refinement in prompting approaches with larger ground truth datasets for reliable practical deployment.

</details>


### [13] [A Fast and Efficient Modern BERT based Text-Conditioned Diffusion Model for Medical Image Segmentation](https://arxiv.org/abs/2512.00084)
*Venkata Siddharth Dhara,Pawan Kumar*

Main category: cs.CV

TL;DR: FastTextDiff利用ModernBERT和文本注释改进医学图像分割，减少对密集标签的依赖，提升效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决传统扩散模型在医学图像分割中需要密集像素级标签的高成本问题，利用文本注释提升语义表示效率。

Method: 提出FastTextDiff模型，结合ModernBERT处理长临床笔记，通过跨模态注意力机制链接文本注释与医学图像的语义内容。

Result: FastTextDiff在MIMIC-III和MIMIC-IV数据集上表现优于传统扩散模型，分割准确性和训练效率均有提升。

Conclusion: FastTextDiff通过整合医学文本注释和现代BERT模型，显著提升了基于扩散的分割模型的效率和准确性，展示了多模态技术在医学图像分析中的潜力。

Abstract: In recent times, denoising diffusion probabilistic models (DPMs) have proven effective for medical image generation and denoising, and as representation learners for downstream segmentation. However, segmentation performance is limited by the need for dense pixel-wise labels, which are expensive, time-consuming, and require expert knowledge. We propose FastTextDiff, a label-efficient diffusion-based segmentation model that integrates medical text annotations to enhance semantic representations. Our approach uses ModernBERT, a transformer capable of processing long clinical notes, to tightly link textual annotations with semantic content in medical images. Trained on MIMIC-III and MIMIC-IV, ModernBERT encodes clinical knowledge that guides cross-modal attention between visual and textual features. This study validates ModernBERT as a fast, scalable alternative to Clinical BioBERT in diffusion-based segmentation pipelines and highlights the promise of multi-modal techniques for medical image analysis. By replacing Clinical BioBERT with ModernBERT, FastTextDiff benefits from FlashAttention 2, an alternating attention mechanism, and a 2-trillion-token corpus, improving both segmentation accuracy and training efficiency over traditional diffusion-based models.

</details>


### [14] [Multi-modal On-Device Learning for Monocular Depth Estimation on Ultra-low-power MCUs](https://arxiv.org/abs/2512.00086)
*Davide Nadalini,Manuele Rusci,Elia Cereda,Luca Benini,Francesco Conti,Daniele Palossi*

Main category: cs.CV

TL;DR: 论文提出了一种高效的多模态设备上学习技术，用于解决物联网平台上单目深度估计的域偏移问题，通过稀疏更新方案和伪标签收集，显著提升了精度并降低了能耗。


<details>
  <summary>Details</summary>
Motivation: 为了解决物联网平台上单目深度估计任务因域偏移导致的严重精度下降问题，作者提出了设备上学习技术，以在设备端直接适应新环境。

Method: 论文采用了一种基于反向传播的设备上训练方法，结合新型内存驱动稀疏更新方案，显著减少了微调所需的内存（仅1.2 MB）。此外，系统在正常运行时使用107 k参数的μPyD-Net模型进行推理，仅在需要时激活深度传感器收集伪标签。

Result: 实验结果表明，该技术将均方根误差从4.9米降低到0.6米，仅需3 k个自标记样本，且在KITTI和NYUv2数据集上的精度损失仅为2%和1.5%。

Conclusion: 该论文提出了一种多模态设备上学习（ODL）技术，显著提升了超低功耗物联网平台上的单目深度估计（MDE）任务在域偏移情况下的准确性。通过优化的内存驱动稀疏更新方案，实现了高效的在设备微调，仅需17.8分钟即可完成，且能耗极低。

Abstract: Monocular depth estimation (MDE) plays a crucial role in enabling spatially-aware applications in Ultra-low-power (ULP) Internet-of-Things (IoT) platforms. However, the limited number of parameters of Deep Neural Networks for the MDE task, designed for IoT nodes, results in severe accuracy drops when the sensor data observed in the field shifts significantly from the training dataset. To address this domain shift problem, we present a multi-modal On-Device Learning (ODL) technique, deployed on an IoT device integrating a Greenwaves GAP9 MicroController Unit (MCU), a 80 mW monocular camera and a 8 x 8 pixel depth sensor, consuming $\approx$300mW. In its normal operation, this setup feeds a tiny 107 k-parameter $μ$PyD-Net model with monocular images for inference. The depth sensor, usually deactivated to minimize energy consumption, is only activated alongside the camera to collect pseudo-labels when the system is placed in a new environment. Then, the fine-tuning task is performed entirely on the MCU, using the new data. To optimize our backpropagation-based on-device training, we introduce a novel memory-driven sparse update scheme, which minimizes the fine-tuning memory to 1.2 MB, 2.2x less than a full update, while preserving accuracy (i.e., only 2% and 1.5% drops on the KITTI and NYUv2 datasets). Our in-field tests demonstrate, for the first time, that ODL for MDE can be performed in 17.8 minutes on the IoT node, reducing the root mean squared error from 4.9 to 0.6m with only 3 k self-labeled samples, collected in a real-life deployment scenario.

</details>


### [15] [Exploring Automated Recognition of Instructional Activity and Discourse from Multimodal Classroom Data](https://arxiv.org/abs/2512.00087)
*Ivo Bueno,Ruikun Hou,Babette Bühler,Tim Fütterer,James Drimalla,Jonathan Kyle Foster,Peter Youngs,Peter Gerjets,Ulrich Trautwein,Enkelejda Kasneci*

Main category: cs.CV

TL;DR: 该论文提出了一种AI驱动的课堂分析方法，通过多模态模型和微调技术，实现了自动化的教学活动与话语识别，为教师反馈系统提供了可扩展的解决方案。


<details>
  <summary>Details</summary>
Motivation: 当前依赖手动注释的课堂互动观察方法资源密集且难以扩展，因此探索AI驱动的课堂录音分析，以多模态教学活动和话语识别为基础，提供可操作的反馈。

Method: 研究设计了并行的、模态特定的流程：对于视频，评估了零样本多模态LLMs、微调的视觉语言模型和自监督视频变换器；对于转录本，微调了一个基于变换器的分类器，并与基于提示的LLMs进行了比较。

Result: 微调模型在视频和转录本上分别实现了0.577和0.460的宏观F1分数，表现优于基于提示的方法。

Conclusion: 该研究证明了自动化课堂分析的可行性，并为基础可扩展的教师反馈系统奠定了基础。

Abstract: Observation of classroom interactions can provide concrete feedback to teachers, but current methods rely on manual annotation, which is resource-intensive and hard to scale. This work explores AI-driven analysis of classroom recordings, focusing on multimodal instructional activity and discourse recognition as a foundation for actionable feedback. Using a densely annotated dataset of 164 hours of video and 68 lesson transcripts, we design parallel, modality-specific pipelines. For video, we evaluate zero-shot multimodal LLMs, fine-tuned vision-language models, and self-supervised video transformers on 24 activity labels. For transcripts, we fine-tune a transformer-based classifier with contextualized inputs and compare it against prompting-based LLMs on 19 discourse labels. To handle class imbalance and multi-label complexity, we apply per-label thresholding, context windows, and imbalance-aware loss functions. The results show that fine-tuned models consistently outperform prompting-based approaches, achieving macro-F1 scores of 0.577 for video and 0.460 for transcripts. These results demonstrate the feasibility of automated classroom analysis and establish a foundation for scalable teacher feedback systems.

</details>


### [16] [SemImage: Semantic Image Representation for Text, a Novel Framework for Embedding Disentangled Linguistic Features](https://arxiv.org/abs/2512.00088)
*Mohammad Zare*

Main category: cs.CV

TL;DR: SemImage将文本转为HSV编码的二维图像，通过CNN处理，实现高准确率和可解释性的文本分类。


<details>
  <summary>Details</summary>
Motivation: 传统文本分类方法（如BERT）缺乏可解释性，且难以直观展示语言特征（如主题和情感）的变化。SemImage旨在通过图像化表示和CNN处理，同时提升分类性能和可解释性。

Method: 提出SemImage方法，将文本文档表示为二维语义图像，其中每个单词对应一个像素，使用HSV颜色空间编码不同语言特征（Hue编码主题，Saturation编码情感，Value编码强度）。通过ColorMapper网络将词嵌入映射到HSV空间，并利用多任务学习框架进行辅助监督。动态计算的边界行用于标记语义转换。

Result: 在多标签和单标签数据集上，SemImage的分类准确率优于或与BERT和分层注意力网络等基线方法相当，同时通过可视化展示了主题和情感变化的清晰模式。

Conclusion: SemImage通过将文本文档表示为二维语义图像，结合多任务学习框架和动态边界行，不仅达到了与BERT等强基线相媲美甚至更优的分类准确率，还提供了更高的可解释性。消融研究验证了多通道HSV表示和动态边界行的重要性。

Abstract: We propose SemImage, a novel method for representing a text document as a two-dimensional semantic image to be processed by convolutional neural networks (CNNs). In a SemImage, each word is represented as a pixel in a 2D image: rows correspond to sentences and an additional boundary row is inserted between sentences to mark semantic transitions. Each pixel is not a typical RGB value but a vector in a disentangled HSV color space, encoding different linguistic features: the Hue with two components H_cos and H_sin to account for circularity encodes the topic, Saturation encodes the sentiment, and Value encodes intensity or certainty. We enforce this disentanglement via a multi-task learning framework: a ColorMapper network maps each word embedding to the HSV space, and auxiliary supervision is applied to the Hue and Saturation channels to predict topic and sentiment labels, alongside the main task objective. The insertion of dynamically computed boundary rows between sentences yields sharp visual boundaries in the image when consecutive sentences are semantically dissimilar, effectively making paragraph breaks salient. We integrate SemImage with standard 2D CNNs (e.g., ResNet) for document classification. Experiments on multi-label datasets (with both topic and sentiment annotations) and single-label benchmarks demonstrate that SemImage can achieve competitive or better accuracy than strong text classification baselines (including BERT and hierarchical attention networks) while offering enhanced interpretability. An ablation study confirms the importance of the multi-channel HSV representation and the dynamic boundary rows. Finally, we present visualizations of SemImage that qualitatively reveal clear patterns corresponding to topic shifts and sentiment changes in the generated image, suggesting that our representation makes these linguistic features visible to both humans and machines.

</details>


### [17] [TeleViT1.0: Teleconnection-aware Vision Transformers for Subseasonal to Seasonal Wildfire Pattern Forecasts](https://arxiv.org/abs/2512.00089)
*Ioannis Prapas,Nikolaos Papadopoulos,Nikolaos-Ioannis Bountos,Dimitrios Michail,Gustau Camps-Valls,Ioannis Papoutsis*

Main category: cs.CV

TL;DR: TeleViT是一种结合局部和全球数据的视觉变换器，显著提高了野火预测的准确性，尤其在季节一致的火情区域表现最佳。


<details>
  <summary>Details</summary>
Motivation: 提前数周至数月预测野火对于规划燃料处理和资源分配至关重要，但长期预测需要考虑地球的相互连接性，包括全球模式和遥相关。

Method: 提出TeleViT，一种结合了细尺度局部火灾驱动因素、粗化全球场和遥相关指数的遥感知视觉变换器，通过非对称标记化策略实现多尺度融合。

Result: TeleViT在所有预测时间范围内（包括长达四个月的预测期）的性能均优于U-Net++、ViT和气候学方法。

Conclusion: 通过显式编码大尺度地球系统背景的架构，可以延长野火在次季节到季节时间尺度上的可预测性。

Abstract: Forecasting wildfires weeks to months in advance is difficult, yet crucial for planning fuel treatments and allocating resources. While short-term predictions typically rely on local weather conditions, long-term forecasting requires accounting for the Earth's interconnectedness, including global patterns and teleconnections. We introduce TeleViT, a Teleconnection-aware Vision Transformer that integrates (i) fine-scale local fire drivers, (ii) coarsened global fields, and (iii) teleconnection indices. This multi-scale fusion is achieved through an asymmetric tokenization strategy that produces heterogeneous tokens processed jointly by a transformer encoder, followed by a decoder that preserves spatial structure by mapping local tokens to their corresponding prediction patches.
  Using the global SeasFire dataset (2001-2021, 8-day resolution), TeleViT improves AUPRC performance over U-Net++, ViT, and climatology across all lead times, including horizons up to four months. At zero lead, TeleViT with indices and global inputs reaches AUPRC 0.630 (ViT 0.617, U-Net 0.620), at 16x8day lead (around 4 months), TeleViT variants using global input maintain 0.601-0.603 (ViT 0.582, U-Net 0.578), while surpassing the climatology (0.572) at all lead times. Regional results show the highest skill in seasonally consistent fire regimes, such as African savannas, and lower skill in boreal and arid regions. Attention and attribution analyses indicate that predictions rely mainly on local tokens, with global fields and indices contributing coarse contextual information. These findings suggest that architectures explicitly encoding large-scale Earth-system context can extend wildfire predictability on subseasonal-to-seasonal timescales.

</details>


### [18] [Deep Filament Extraction for 3D Concrete Printing](https://arxiv.org/abs/2512.00091)
*Karam Mawas,Mehdi Maboudi,Pedro Achanccaray,Markus Gerke*

Main category: cs.CV

TL;DR: 该论文提出了一种独立于传感器的自动化质量控制方法，适用于3D混凝土打印中的挤出式和喷射式技术，确保打印丝状物的几何质量。


<details>
  <summary>Details</summary>
Motivation: 由于3D混凝土打印中丝状物的几何质量对打印结构至关重要，因此需要一种自动化质量控制方法来确保打印质量。

Method: 论文描述了一种独立于传感器的自动化质量控制工作流程，适用于挤出式和喷射式3D混凝土打印方法。该方法可用于新鲜或固化状态的混凝土材料。

Result: 提出了一种适用于多种传感器和数据采集方法的自动化质量控制流程，可实时或后期进行质量控制。

Conclusion: 该论文提出了一种自动化质量控制流程，适用于挤出式和喷射式3D混凝土打印方法，且独立于数据采集传感器，可用于在线和打印后质量控制。

Abstract: The architecture, engineering and construction (AEC) industry is constantly evolving to meet the demand for sustainable and effective design and construction of the built environment. In the literature, two primary deposition techniques for large-scale 3D concrete printing (3DCP) have been described, namely extrusion-based (Contour Crafting-CC) and shotcrete 3D printing (SC3DP) methods. The deposition methods use a digitally controlled nozzle to print material layer by layer. The continuous flow of concrete material used to create the printed structure is called a filament or layer. As these filaments are the essential structure defining the printed object, the filaments' geometry quality control is crucial. This paper presents an automated procedure for quality control (QC) of filaments in extrusion-based and SC3DP printing methods. The paper also describes a workflow that is independent of the sensor used for data acquisition, such as a camera, a structured light system (SLS) or a terrestrial laser scanner (TLS). This method can be used with materials in either the fresh or cured state. Thus, it can be used for online and post-printing QC.

</details>


### [19] [Comparative Analysis of Vision Transformer, Convolutional, and Hybrid Architectures for Mental Health Classification Using Actigraphy-Derived Images](https://arxiv.org/abs/2512.00103)
*Ifeanyi Okala*

Main category: cs.CV

TL;DR: CoAtNet-Tiny在活动记录图像分类中表现最稳定，优于VGG16和ViT-B/16，尤其在不常见的抑郁症和精神分裂症类别中表现突出。


<details>
  <summary>Details</summary>
Motivation: 探索不同图像方法在基于日常活动记录识别抑郁症、精神分裂症和健康对照中的表现差异。

Method: 使用VGG16、ViT-B/16和CoAtNet-Tiny三种图像方法，将腕部活动信号转换为30×48图像，并通过三折受试者分割进行评估。

Result: CoAtNet-Tiny在所有方法中表现最佳，具有最高的平均准确性、最稳定的曲线，且在抑郁症和精神分裂症类别中表现出最强的精确度、召回率和F1分数。

Conclusion: CoAtNet-Tiny consistently outperformed VGG16和ViT-B/16在基于活动记录图像的抑郁症和精神分裂症识别中，表现出最高的平均准确性和稳定性。

Abstract: This work examines how three different image-based methods, VGG16, ViT-B/16, and CoAtNet-Tiny, perform in identifying depression, schizophrenia, and healthy controls using daily actigraphy records. Wrist-worn activity signals from the Psykose and Depresjon datasets were converted into 30 by 48 images and evaluated through a three-fold subject-wise split. Although all methods fitted the training data well, their behaviour on unseen data differed. VGG16 improved steadily but often settled at lower accuracy. ViT-B/16 reached strong results in some runs, but its performance shifted noticeably from fold to fold. CoAtNet-Tiny stood out as the most reliable, recording the highest average accuracy and the most stable curves across folds. It also produced the strongest precision, recall, and F1-scores, particularly for the underrepresented depression and schizophrenia classes. Overall, the findings indicate that CoAtNet-Tiny performed most consistently on the actigraphy images, while VGG16 and ViT-B/16 yielded mixed results. These observations suggest that certain hybrid designs may be especially suited for mental-health work that relies on actigraphy-derived images.

</details>


### [20] [TinyViT: Field Deployable Transformer Pipeline for Solar Panel Surface Fault and Severity Screening](https://arxiv.org/abs/2512.00117)
*Ishwaryah Pandiarajan,Mohamed Mansoor Roomi Sindha,Uma Maheswari Pandyan,Sharafia N*

Main category: cs.CV

TL;DR: 该论文提出了一种仅使用可见光图像的光伏板表面异常分类和严重程度估计方法，结合了深度学习和传统机器学习，为资源有限的安装提供了经济高效的解决方案。


<details>
  <summary>Details</summary>
Motivation: 光伏资产的持续运行依赖于对广泛分布的光伏模块表面故障的准确检测和优先级排序，而多模态成像策略在常规农场级部署中存在物流和经济障碍。

Method: 研究引入了TinyViT，一个紧凑的流程，集成了基于Transformer的分割、光谱-空间特征工程和集成回归。

Result: 在真实公共数据集上的实验验证了分类和回归子模块的性能，其准确性和可解释性与专用方法相当。

Conclusion: 该研究通过结合深度学习和传统机器学习方法，仅使用可见光波段图像实现了光伏板表面异常的稳健分类和严重程度估计，为资源有限的安装提供了经济高效的维护方案。

Abstract: Sustained operation of solar photovoltaic assets hinges on accurate detection and prioritization of surface faults across vast, geographically distributed modules. While multi modal imaging strategies are popular, they introduce logistical and economic barriers for routine farm level deployment. This work demonstrates that deep learning and classical machine learning may be judiciously combined to achieve robust surface anomaly categorization and severity estimation from planar visible band imagery alone. We introduce TinyViT which is a compact pipeline integrating Transformer based segmentation, spectral-spatial feature engineering, and ensemble regression. The system ingests consumer grade color camera mosaics of PV panels, classifies seven nuanced surface faults, and generates actionable severity grades for maintenance triage. By eliminating reliance on electroluminescence or IR sensors, our method enables affordable, scalable upkeep for resource limited installations, and advances the state of solar health monitoring toward universal field accessibility. Experiments on real public world datasets validate both classification and regression sub modules, achieving accuracy and interpretability competitive with specialized approaches.

</details>


### [21] [Hybrid Synthetic Data Generation with Domain Randomization Enables Zero-Shot Vision-Based Part Inspection Under Extreme Class Imbalance](https://arxiv.org/abs/2512.00125)
*Ruo-Syuan Mei,Sixian Jia,Guangze Li,Soo Yeon Lee,Brian Musser,William Keller,Sreten Zakula,Jorge Arinez,Chenhui Shao*

Main category: cs.CV

TL;DR: 通过合成数据生成解决工业质检中数据稀缺问题，实现高效、零标注的检测与分类，性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 工业质量检测中高质量标注数据获取成本高且缺陷样本稀少，导致模型性能下降，限制了机器学习方法在实际生产中的广泛应用。

Method: 结合基于模拟的渲染、领域随机化和真实背景合成的混合SDG框架，生成大量标注数据，并采用YOLOv8n和MobileNetV3-small的两阶段架构进行检测与分类。

Result: 在300个真实工业零件上评估，检测mAP@0.5达0.995，分类准确率96%，平衡准确率90.1%，显著优于少样本基线方法。

Conclusion: 该论文提出的混合SDG框架通过合成数据生成实现了无需人工标注、可扩展且稳健的工业质量检测，验证了其在真实制造应用中的有效性。

Abstract: Machine learning, particularly deep learning, is transforming industrial quality inspection. Yet, training robust machine learning models typically requires large volumes of high-quality labeled data, which are expensive, time-consuming, and labor-intensive to obtain in manufacturing. Moreover, defective samples are intrinsically rare, leading to severe class imbalance that degrades model performance. These data constraints hinder the widespread adoption of machine learning-based quality inspection methods in real production environments. Synthetic data generation (SDG) offers a promising solution by enabling the creation of large, balanced, and fully annotated datasets in an efficient, cost-effective, and scalable manner. This paper presents a hybrid SDG framework that integrates simulation-based rendering, domain randomization, and real background compositing to enable zero-shot learning for computer vision-based industrial part inspection without manual annotation. The SDG pipeline generates 12,960 labeled images in one hour by varying part geometry, lighting, and surface properties, and then compositing synthetic parts onto real image backgrounds. A two-stage architecture utilizing a YOLOv8n backbone for object detection and MobileNetV3-small for quality classification is trained exclusively on synthetic data and evaluated on 300 real industrial parts. The proposed approach achieves an mAP@0.5 of 0.995 for detection, 96% classification accuracy, and 90.1% balanced accuracy. Comparative evaluation against few-shot real-data baseline approaches demonstrates significant improvement. The proposed SDG-based approach achieves 90-91% balanced accuracy under severe class imbalance, while the baselines reach only 50% accuracy. These results demonstrate that the proposed method enables annotation-free, scalable, and robust quality inspection for real-world manufacturing applications.

</details>


### [22] [Analysis of Incursive Breast Cancer in Mammograms Using YOLO, Explainability, and Domain Adaptation](https://arxiv.org/abs/2512.00129)
*Jayan Adhikari,Prativa Joshi,Susish Baral*

Main category: cs.CV

TL;DR: 通过ResNet50和YOLO架构结合，有效过滤OOD输入，提升乳腺癌检测的可靠性和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习模型在乳腺癌检测中面对OOD输入（如其他成像模态或设备变化）时的可靠性问题。

Method: 通过结合ResNet50的OOD过滤与YOLO架构（YOLOv8、YOLOv11、YOLOv12），建立一个基于余弦相似度的域内图库，严格拒绝非乳腺图像输入。

Result: OOD检测组件达到99.77%的总体准确率，OOD测试集上100%准确率；联合框架在mAP@0.5上达到0.947。

Conclusion: 本研究为在数据异质性多样的临床环境中部署可靠的基于AI的乳腺癌检测系统提供了基础。

Abstract: Deep learning models for breast cancer detection from mammographic images have significant reliability problems when presented with Out-of-Distribution (OOD) inputs such as other imaging modalities (CT, MRI, X-ray) or equipment variations, leading to unreliable detection and misdiagnosis. The current research mitigates the fundamental OOD issue through a comprehensive approach integrating ResNet50-based OOD filtering with YOLO architectures (YOLOv8, YOLOv11, YOLOv12) for accurate detection of breast cancer. Our strategy establishes an in-domain gallery via cosine similarity to rigidly reject non-mammographic inputs prior to processing, ensuring that only domain-associated images supply the detection pipeline. The OOD detection component achieves 99.77\% general accuracy with immaculate 100\% accuracy on OOD test sets, effectively eliminating irrelevant imaging modalities. ResNet50 was selected as the optimum backbone after 12 CNN architecture searches. The joint framework unites OOD robustness with high detection performance (mAP@0.5: 0.947) and enhanced interpretability through Grad-CAM visualizations. Experimental validation establishes that OOD filtering significantly improves system reliability by preventing false alarms on out-of-distribution inputs while maintaining higher detection accuracy on mammographic data. The present study offers a fundamental foundation for the deployment of reliable AI-based breast cancer detection systems in diverse clinical environments with inherent data heterogeneity.

</details>


### [23] [Local and Global Context-and-Object-part-Aware Superpixel-based Data Augmentation for Deep Visual Recognition](https://arxiv.org/abs/2512.00130)
*Fadi Dornaika,Danyang Sun*

Main category: cs.CV

TL;DR: LGCOAMix 是一种新型Cutmix数据增强方法，通过超像素注意力策略提升局部特征学习，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有Cutmix方法过度依赖全局语义，忽略局部上下文信息，且生成样本时丢失对象部分信息，效率低下。

Method: LGCOAMix 是一种基于超像素注意力策略的标签混合方法，通过学习判别性超像素区域和跨图像超像素对比来增强局部特征。

Result: 在多个基准数据集上，LGCOAMix 在分类任务和CUB200-2011的弱监督目标定位上优于现有Cutmix方法。

Conclusion: LGCOAMix 提出了一种高效的、基于超像素的网格混合数据增强方法，显著提升了分类任务和弱监督目标定位的性能，适用于CNN和Transformer网络。

Abstract: Cutmix-based data augmentation, which uses a cut-and-paste strategy, has shown remarkable generalization capabilities in deep learning. However, existing methods primarily consider global semantics with image-level constraints, which excessively reduces attention to the discriminative local context of the class and leads to a performance improvement bottleneck. Moreover, existing methods for generating augmented samples usually involve cutting and pasting rectangular or square regions, resulting in a loss of object part information. To mitigate the problem of inconsistency between the augmented image and the generated mixed label, existing methods usually require double forward propagation or rely on an external pre-trained network for object centering, which is inefficient. To overcome the above limitations, we propose LGCOAMix, an efficient context-aware and object-part-aware superpixel-based grid blending method for data augmentation. To the best of our knowledge, this is the first time that a label mixing strategy using a superpixel attention approach has been proposed for cutmix-based data augmentation. It is the first instance of learning local features from discriminative superpixel-wise regions and cross-image superpixel contrasts. Extensive experiments on various benchmark datasets show that LGCOAMix outperforms state-of-the-art cutmix-based data augmentation methods on classification tasks, {and weakly supervised object location on CUB200-2011.} We have demonstrated the effectiveness of LGCOAMix not only for CNN networks, but also for Transformer networks. Source codes are available at https://github.com/DanielaPlusPlus/LGCOAMix.

</details>


### [24] [Efficient Edge-Compatible CNN for Speckle-Based Material Recognition in Laser Cutting Systems](https://arxiv.org/abs/2512.00179)
*Mohamed Abdallah Salem,Nourhan Zein Diab*

Main category: cs.CV

TL;DR: 提出了一种轻量级CNN用于激光散斑材料分类，在59种材料上达到95.05%准确率，参数少70倍，适合边缘设备部署。


<details>
  <summary>Details</summary>
Motivation: 精确的材料识别对激光切割的安全和有效性至关重要，而激光散斑传感作为一种低成本、非破坏性的材料分类方式，现有方法要么依赖计算昂贵的骨干网络，要么只能处理有限的材料子集。

Method: 提出了一种专为散斑图案设计的轻量级卷积神经网络（CNN），旨在最小化参数的同时保持高判别力。

Result: 在包含59种材料类别的完整SensiCut数据集上，提出的模型实现了95.05%的测试准确率，宏F1和加权F1分数均为0.951。网络仅包含341k可训练参数（约1.3 MB），比ResNet-50少70倍以上，推理速度达到每秒295张图像，可在Raspberry Pi和Jetson类设备上部署。当材料重新分组为9个和5个实用家族时，召回率超过98%并接近100%。

Conclusion: 紧凑型、特定领域的CNN在基于散斑的材料分类中表现优于大型骨干网络，推动了材料感知、可边缘部署的激光切割系统的可行性。

Abstract: Accurate material recognition is critical for safe and effective laser cutting, as misidentification can lead to poor cut quality, machine damage, or the release of hazardous fumes. Laser speckle sensing has recently emerged as a low-cost and non-destructive modality for material classification; however, prior work has either relied on computationally expensive backbone networks or addressed only limited subsets of materials. In this study, A lightweight convolutional neural network (CNN) tailored for speckle patterns is proposed, designed to minimize parameters while maintaining high discriminative power. Using the complete SensiCut dataset of 59 material classes spanning woods, acrylics, composites, textiles, metals, and paper-based products, the proposed model achieves 95.05% test accuracy, with macro and weighted F1-scores of 0.951. The network contains only 341k trainable parameters (~1.3 MB) -- over 70X fewer than ResNet-50 -- and achieves an inference speed of 295 images per second, enabling deployment on Raspberry Pi and Jetson-class devices. Furthermore, when materials are regrouped into nine and five practical families, recall exceeds 98% and approaches 100%, directly supporting power and speed preset selection in laser cutters. These results demonstrate that compact, domain-specific CNNs can outperform large backbones for speckle-based material classification, advancing the feasibility of material-aware, edge-deployable laser cutting systems.

</details>


### [25] [AutocleanEEG ICVision: Automated ICA Artifact Classification Using Vision-Language AI](https://arxiv.org/abs/2512.00194)
*Zag ElSayed,Grace Westerkamp,Gavin Gammoh,Yanchen Liu,Peyton Siekierski,Craig Erickson,Ernest Pedapati*

Main category: cs.CV

TL;DR: ICVision 是一种基于AI视觉和语言模型的EEG ICA组件分类系统，直接解读可视化数据，模拟专家决策，性能优于传统方法，并具备高解释性。


<details>
  <summary>Details</summary>
Motivation: 传统分类器（如ICLabel）依赖手工特征，而ICVision旨在通过AI视觉和自然语言推理模拟专家级的分类，提升分类准确性和解释性。

Method: ICVision 通过多模态大型语言模型（GPT-4 Vision）直接解释ICA仪表板的可视化（地形图、时间序列、功率谱和ERP图），模拟专家级的EEG ICA组件分类。

Result: 在3,168个ICA组件上评估，ICVision与专家共识的一致性达到k=0.677，优于MNE ICLabel，同时保留了临床相关的大脑信号。超过97%的输出被专家评为可解释且可操作。

Conclusion: ICVision 代表了科学AI的范式转变，不仅能够分类，还能进行视觉认知、推理和沟通，为脑科学及其他领域开启了可扩展、可解释且可复现的EEG工作流程。

Abstract: We introduce EEG Autoclean Vision Language AI (ICVision) a first-of-its-kind system that emulates expert-level EEG ICA component classification through AI-agent vision and natural language reasoning. Unlike conventional classifiers such as ICLabel, which rely on handcrafted features, ICVision directly interprets ICA dashboard visualizations topography, time series, power spectra, and ERP plots, using a multimodal large language model (GPT-4 Vision). This allows the AI to see and explain EEG components the way trained neurologists do, making it the first scientific implementation of AI-agent visual cognition in neurophysiology. ICVision classifies each component into one of six canonical categories (brain, eye, heart, muscle, channel noise, and other noise), returning both a confidence score and a human-like explanation. Evaluated on 3,168 ICA components from 124 EEG datasets, ICVision achieved k = 0.677 agreement with expert consensus, surpassing MNE ICLabel, while also preserving clinically relevant brain signals in ambiguous cases. Over 97% of its outputs were rated as interpretable and actionable by expert reviewers. As a core module of the open-source EEG Autoclean platform, ICVision signals a paradigm shift in scientific AI, where models do not just classify, but see, reason, and communicate. It opens the door to globally scalable, explainable, and reproducible EEG workflows, marking the emergence of AI agents capable of expert-level visual decision-making in brain science and beyond.

</details>


### [26] [Mammo-FM: Breast-specific foundational model for Integrated Mammographic Diagnosis, Prognosis, and Reporting](https://arxiv.org/abs/2512.00198)
*Shantanu Ghosh,Vedant Parthesh Joshi,Rayan Syed,Aya Kassem,Abhishek Varshney,Payel Basak,Weicheng Dai,Judy Wawira Gichoya,Hari M. Trivedi,Imon Banerjee,Shyam Visweswaran,Clare B. Poynton,Kayhan Batmanghelich*

Main category: cs.CV

TL;DR: Mammo-FM is a domain-specific foundation model for mammography, excelling in diagnosis, prognosis, and report generation, outperforming generalist models with fewer parameters.


<details>
  <summary>Details</summary>
Motivation: Breast cancer is a leading cause of death among women, necessitating advanced tools for diagnosis, prognosis, and reporting in mammography.

Method: Mammo-FM is a foundation model pretrained on a diverse dataset of 140,677 patients (821,326 mammograms) across four U.S. institutions, designed for core clinical tasks in breast imaging.

Result: Mammo-FM outperforms state-of-the-art generalist foundation models across multiple benchmarks, despite using only one-third of the parameters and operating on native-resolution mammograms.

Conclusion: Mammo-FM demonstrates the efficiency and value of domain-specific foundation models in breast imaging, outperforming generalist models despite fewer parameters and emphasizing the importance of domain-aligned evaluation.

Abstract: Breast cancer is one of the leading causes of death among women worldwide. We introduce Mammo-FM, the first foundation model specifically for mammography, pretrained on the largest and most diverse dataset to date - 140,677 patients (821,326 mammograms) across four U.S. institutions. Mammo-FM provides a unified foundation for core clinical tasks in breast imaging, including cancer diagnosis, pathology localization, structured report generation, and cancer risk prognosis within a single framework. Its alignment between images and text enables both visual and textual interpretability, improving transparency and clinical auditability, which are essential for real-world adoption. We rigorously evaluate Mammo-FM across diagnosis, prognosis, and report-generation tasks in in- and out-of-distribution datasets. Despite operating on native-resolution mammograms and using only one-third of the parameters of state-of-the-art generalist FMs, Mammo-FM consistently outperforms them across multiple public and private benchmarks. These results highlight the efficiency and value of domain-specific foundation models designed around the full spectrum of tasks within a clinical domain and emphasize the importance of rigorous, domain-aligned evaluation.

</details>


### [27] [ReactionMamba: Generating Short &Long Human Reaction Sequences](https://arxiv.org/abs/2512.00208)
*Hajra Anwar Beg,Baptiste Chopin,Hao Tang,Mohamed Daoudi*

Main category: cs.CV

TL;DR: ReactionMamba是一个新框架，结合运动VAE和Mamba模型，能高效生成长短序列3D人体动作，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在生成长序列复杂动作（如舞蹈和武术）时的局限性，提升动作生成的效率和效果。

Method: 结合运动VAE进行高效动作编码，并利用基于Mamba的状态空间模型解码时间一致的反应动作。

Result: 在NTU120-AS、Lindy Hop和InterX三个数据集上评估，表现优于InterFormer、ReMoS和Ready-to-React等方法。

Conclusion: ReactionMamba在生成长序列3D人体反应动作方面表现出色，尤其在真实性、多样性和长序列生成上优于现有方法，同时显著提高了推理速度。

Abstract: We present ReactionMamba, a novel framework for generating long 3D human reaction motions. Reaction-Mamba integrates a motion VAE for efficient motion encoding with Mamba-based state-space models to decode temporally consistent reactions. This design enables ReactionMamba to generate both short sequences of simple motions and long sequences of complex motions, such as dance and martial arts. We evaluate ReactionMamba on three datasets--NTU120-AS, Lindy Hop, and InterX--and demonstrate competitive performance in terms of realism, diversity, and long-sequence generation compared to previous methods, including InterFormer, ReMoS, and Ready-to-React, while achieving substantial improvements in inference speed.

</details>


### [28] [DenseScan: Advancing 3D Scene Understanding with 2D Dense Annotation](https://arxiv.org/abs/2512.00226)
*Zirui Wang,Tao Zhang*

Main category: cs.CV

TL;DR: DenseScan是一个结合几何与语义的3D数据集，通过自动化流程生成密集标注，提升对象级理解和问答性能。


<details>
  <summary>Details</summary>
Motivation: 当前3D场景理解数据集缺乏丰富的语义注释，限制了视觉-语言任务的深入发展。

Method: 利用多视角2D图像和多模态大型语言模型（MLLMs）的自动化流程生成详细的多级描述，并通过基于场景的问题生成扩展注释。

Result: 实验结果表明，与传统标注流程相比，DenseScan显著提升了对象级理解和问答性能。

Conclusion: DenseScan通过结合几何细节和语义丰富性，显著提升了3D环境中的对象级理解和问答性能，为机器人、增强现实等领域的研究和应用提供了新的数据集和标注流程。

Abstract: 3D understanding is a key capability for real-world AI assistance. High-quality data plays an important role in driving the development of the 3D understanding community. Current 3D scene understanding datasets often provide geometric and instance-level information, yet they lack the rich semantic annotations necessary for nuanced visual-language tasks.In this work, we introduce DenseScan, a novel dataset with detailed multi-level descriptions generated by an automated pipeline leveraging multi-view 2D images and multimodal large language models (MLLMs). Our approach enables dense captioning of scene elements, ensuring comprehensive object-level descriptions that capture context-sensitive details. Furthermore, we extend these annotations through scenario-based question generation, producing high-level queries that integrate object properties, spatial relationships, and scene context. By coupling geometric detail with semantic richness, DenseScan broadens the range of downstream tasks, from detailed visual-language navigation to interactive question answering. Experimental results demonstrate that our method significantly enhances object-level understanding and question-answering performance in 3D environments compared to traditional annotation pipelines. We release both the annotated dataset and our annotation pipeline to facilitate future research and applications in robotics, augmented reality, and beyond. Through DenseScan, we aim to catalyze new avenues in 3D scene understanding, allowing researchers and practitioners to tackle the complexities of real-world environments with richer, more contextually aware annotations.

</details>


### [29] [Relightable Holoported Characters: Capturing and Relighting Dynamic Human Performance from Sparse Views](https://arxiv.org/abs/2512.00255)
*Kunwar Maheep Singh,Jianchun Chen,Vladislav Golyanik,Stephan J. Garbin,Thabo Beeler,Rishabh Dabral,Marc Habermann,Christian Theobalt*

Main category: cs.CV

TL;DR: RHC是一种基于transformer的单次前馈网络方法，用于动态人体的多视角重光照，避免传统OLAT的高成本，实验表现优越。


<details>
  <summary>Details</summary>
Motivation: 解决传统OLAT方法在多视角RGB视频中重光照动态人体的高成本和效率问题。

Method: 基于transformer的RelightNet，利用物理信息特征（几何、反照率、着色等）和新型光照条件进行交叉注意力，回归重光照外观。

Result: 实验显示RHC在视觉和光照再现上优于现有方法。

Conclusion: RHC方法在视觉保真度和光照再现方面优于现有技术，通过单次前馈网络预测重光照外观，避免了传统OLAT方法的成本问题。

Abstract: We present Relightable Holoported Characters (RHC), a novel person-specific method for free-view rendering and relighting of full-body and highly dynamic humans solely observed from sparse-view RGB videos at inference. In contrast to classical one-light-at-a-time (OLAT)-based human relighting, our transformer-based RelightNet predicts relit appearance within a single network pass, avoiding costly OLAT-basis capture and generation. For training such a model, we introduce a new capture strategy and dataset recorded in a multi-view lightstage, where we alternate frames lit by random environment maps with uniformly lit tracking frames, simultaneously enabling accurate motion tracking and diverse illumination as well as dynamics coverage. Inspired by the rendering equation, we derive physics-informed features that encode geometry, albedo, shading, and the virtual camera view from a coarse human mesh proxy and the input views. Our RelightNet then takes these features as input and cross-attends them with a novel lighting condition, and regresses the relit appearance in the form of texel-aligned 3D Gaussian splats attached to the coarse mesh proxy. Consequently, our RelightNet implicitly learns to efficiently compute the rendering equation for novel lighting conditions within a single feed-forward pass. Experiments demonstrate our method's superior visual fidelity and lighting reproduction compared to state-of-the-art approaches. Project page: https://vcai.mpi-inf.mpg.de/projects/RHC/

</details>


### [30] [UniDiff: Parameter-Efficient Adaptation of Diffusion Models for Land Cover Classification with Multi-Modal Remotely Sensed Imagery and Sparse Annotations](https://arxiv.org/abs/2512.00261)
*Yuzhen Hu,Saurabh Prasad*

Main category: cs.CV

TL;DR: UniDiff是一种参数高效框架，通过自适应ImageNet预训练扩散模型，解决了稀疏标注下多模态遥感数据的特征提取问题。


<details>
  <summary>Details</summary>
Motivation: 稀疏标注限制了多模态遥感的实际应用，即使如MSFMamba等先进监督方法也受限于标注数据的可用性。ImageNet预训练模型虽提供丰富视觉表示，但如何适应异构模态（如HSI和SAR）仍具挑战性。

Method: UniDiff结合了FiLM-based timestep-modality conditioning、参数高效自适应（约5%参数）和pseudo-RGB anchoring，以保留预训练表示并防止灾难性遗忘。

Result: 在两个多模态基准数据集上的实验表明，UniDiff通过无监督自适应预训练扩散模型，有效缓解了标注限制，实现了多模态遥感数据的有效融合。

Conclusion: UniDiff通过参数高效的自适应方法，成功解决了多模态遥感数据在稀疏标注下的特征提取问题，实现了有效的多模态数据融合。

Abstract: Sparse annotations fundamentally constrain multimodal remote sensing: even recent state-of-the-art supervised methods such as MSFMamba are limited by the availability of labeled data, restricting their practical deployment despite architectural advances. ImageNet-pretrained models provide rich visual representations, but adapting them to heterogeneous modalities such as hyperspectral imaging (HSI) and synthetic aperture radar (SAR) without large labeled datasets remains challenging. We propose UniDiff, a parameter-efficient framework that adapts a single ImageNet-pretrained diffusion model to multiple sensing modalities using only target-domain data. UniDiff combines FiLM-based timestep-modality conditioning, parameter-efficient adaptation of approximately 5% of parameters, and pseudo-RGB anchoring to preserve pre-trained representations and prevent catastrophic forgetting. This design enables effective feature extraction from remote sensing data under sparse annotations. Our results with two established multi-modal benchmarking datasets demonstrate that unsupervised adaptation of a pre-trained diffusion model effectively mitigates annotation constraints and achieves effective fusion of multi-modal remotely sensed data.

</details>


### [31] [HeartFormer: Semantic-Aware Dual-Structure Transformers for 3D Four-Chamber Cardiac Point Cloud Reconstruction](https://arxiv.org/abs/2512.00264)
*Zhengda Ma,Abhirup Banerjee*

Main category: cs.CV

TL;DR: HeartFormer是一种基于点云的几何深度学习框架，通过SA-DSTNet和SA-GFRTNet实现高保真3D心脏重建，性能优于SOTA。


<details>
  <summary>Details</summary>
Motivation: 传统cine MRI仅提供2D切片图像，限制了全面理解心脏形态和生理机制的需求。

Method: HeartFormer由两部分组成：SA-DSTNet（生成初始粗略点云）和SA-GFRTNet（逐步细化点云），结合全局和子结构几何先验。

Result: 在HeartCompv1和UK Biobank数据集上的实验表明，HeartFormer性能稳健、准确且可泛化，优于现有方法。

Conclusion: HeartFormer提出了一种基于点云表示的几何深度学习框架，成功解决了传统cine MRI仅提供2D切片图像的局限性，实现了高保真和几何一致的3D四腔心脏重建。

Abstract: We present the first geometric deep learning framework based on point cloud representation for 3D four-chamber cardiac reconstruction from cine MRI data. This work addresses a long-standing limitation in conventional cine MRI, which typically provides only 2D slice images of the heart, thereby restricting a comprehensive understanding of cardiac morphology and physiological mechanisms in both healthy and pathological conditions. To overcome this, we propose \textbf{HeartFormer}, a novel point cloud completion network that extends traditional single-class point cloud completion to the multi-class. HeartFormer consists of two key components: a Semantic-Aware Dual-Structure Transformer Network (SA-DSTNet) and a Semantic-Aware Geometry Feature Refinement Transformer Network (SA-GFRTNet). SA-DSTNet generates an initial coarse point cloud with both global geometry features and substructure geometry features. Guided by these semantic-geometry representations, SA-GFRTNet progressively refines the coarse output, effectively leveraging both global and substructure geometric priors to produce high-fidelity and geometrically consistent reconstructions. We further construct \textbf{HeartCompv1}, the first publicly available large-scale dataset with 17,000 high-resolution 3D multi-class cardiac meshes and point-clouds, to establish a general benchmark for this emerging research direction. Extensive cross-domain experiments on HeartCompv1 and UK Biobank demonstrate that HeartFormer achieves robust, accurate, and generalizable performance, consistently surpassing state-of-the-art (SOTA) methods. Code and dataset will be released upon acceptance at: https://github.com/10Darren/HeartFormer.

</details>


### [32] [USB: Unified Synthetic Brain Framework for Bidirectional Pathology-Healthy Generation and Editing](https://arxiv.org/abs/2512.00269)
*Jun Wang,Peirong Liu*

Main category: cs.CV

TL;DR: USB是首个统一病理与健康脑图像双向生成与编辑的端到端框架，通过配对扩散机制和一致性引导算法，实现了多样且真实的图像生成与编辑。


<details>
  <summary>Details</summary>
Motivation: 病理与健康脑结构关系的理解对神经影像学至关重要，但成对的病理-健康数据极难获取，现有方法多局限于视觉质量且领域特定。

Method: USB通过配对扩散机制建模病变与脑解剖结构的联合分布，并采用一致性引导算法在双向病理-健康编辑中保持解剖一致性和病变对应关系。

Result: 在六个公共脑MRI数据集上的实验表明，USB能够产生多样且真实的结果。

Conclusion: USB框架首次统一了病理和健康脑图像的双向生成与编辑，通过建立首个统一的脑图像生成和编辑基准，为可扩展数据集创建和稳健的神经影像分析开辟了机会。

Abstract: Understanding the relationship between pathological and healthy brain structures is fundamental to neuroimaging, connecting disease diagnosis and detection with modeling, prediction, and treatment planning. However, paired pathological-healthy data are extremely difficult to obtain, as they rely on pre- and post-treatment imaging, constrained by clinical outcomes and longitudinal data availability. Consequently, most existing brain image generation and editing methods focus on visual quality yet remain domain-specific, treating pathological and healthy image modeling independently. We introduce USB (Unified Synthetic Brain), the first end-to-end framework that unifies bidirectional generation and editing of pathological and healthy brain images. USB models the joint distribution of lesions and brain anatomy through a paired diffusion mechanism and achieves both pathological and healthy image generation. A consistency guidance algorithm further preserves anatomical consistency and lesion correspondence during bidirectional pathology-healthy editing. Extensive experiments on six public brain MRI datasets including healthy controls, stroke, and Alzheimer's patients, demonstrate USB's ability to produce diverse and realistic results. By establishing the first unified benchmark for brain image generation and editing, USB opens opportunities for scalable dataset creation and robust neuroimaging analysis. Code is available at https://github.com/jhuldr/USB.

</details>


### [33] [HIMOSA: Efficient Remote Sensing Image Super-Resolution with Hierarchical Mixture of Sparse Attention](https://arxiv.org/abs/2512.00275)
*Yi Liu,Yi Wan,Xinyi Liu,Qiong Wu,Panwang Xia,Xuejun Huang,Yongjun Zhang*

Main category: cs.CV

TL;DR: HIMOSA是一种轻量级遥感图像超分辨率框架，通过内容感知稀疏注意力机制和分层窗口扩展，高效实现高质量重建。


<details>
  <summary>Details</summary>
Motivation: 解决现有遥感图像超分辨率方法在模型性能和计算效率之间的权衡问题，满足实时灾害检测和响应等应用的需求。

Method: 提出了一种轻量级超分辨率框架HIMOSA，利用遥感图像的固有冗余性，引入内容感知稀疏注意力机制和分层窗口扩展，降低计算复杂度。

Result: 在多个遥感数据集上的实验表明，HIMOSA在保持计算效率的同时达到了最先进的性能。

Conclusion: HIMOSA框架通过内容感知的稀疏注意力机制和分层窗口扩展，在保持计算效率的同时实现了优异的超分辨率重建性能，适用于实时遥感应用。

Abstract: In remote sensing applications, such as disaster detection and response, real-time efficiency and model lightweighting are of critical importance. Consequently, existing remote sensing image super-resolution methods often face a trade-off between model performance and computational efficiency. In this paper, we propose a lightweight super-resolution framework for remote sensing imagery, named HIMOSA. Specifically, HIMOSA leverages the inherent redundancy in remote sensing imagery and introduces a content-aware sparse attention mechanism, enabling the model to achieve fast inference while maintaining strong reconstruction performance. Furthermore, to effectively leverage the multi-scale repetitive patterns found in remote sensing imagery, we introduce a hierarchical window expansion and reduce the computational complexity by adjusting the sparsity of the attention. Extensive experiments on multiple remote sensing datasets demonstrate that our method achieves state-of-the-art performance while maintaining computational efficiency.

</details>


### [34] [Rethinking Lung Cancer Screening: AI Nodule Detection and Diagnosis Outperforms Radiologists, Leading Models, and Standards Beyond Size and Growth](https://arxiv.org/abs/2512.00281)
*Sylvain Bodard,Pierre Baudot,Benjamin Renoust,Charles Voyton,Gwendoline De Bie,Ezequiel Geremia,Van-Khoa Le,Danny Francis,Pierre-Henri Siot,Yousra Haddou,Vincent Bobin,Jean-Christophe Brisset,Carey C. Thomson,Valerie Bourdes,Benoit Huet*

Main category: cs.CV

TL;DR: AI系统通过集成模型在肺癌筛查中实现高精度诊断，显著优于现有方法，特别是在早期癌症检测上。


<details>
  <summary>Details</summary>
Motivation: 早期肺癌检测依赖于结节的大小和生长速度，导致诊断延迟，亟需一种能直接在结节级别进行检测和恶性诊断的AI系统。

Method: 采用浅层深度学习和基于特征的专业模型集成方法，处理了25,709次扫描和69,449个标注结节的数据集。

Result: 系统在内部测试中AUC达0.98，独立队列中0.945，每扫描0.5个假阳性下灵敏度99.3%，在所有结节大小和阶段均优于放射科医生。

Conclusion: 该AI系统在肺癌筛查中显著优于放射科医生和其他现有AI模型，特别是在早期癌症和不确定结节的诊断上，为AI在临床中的广泛应用提供了有力支持。

Abstract: Early detection of malignant lung nodules is critical, but its dependence on size and growth in screening inherently delays diagnosis. We present an AI system that redefines lung cancer screening by performing both detection and malignancy diagnosis directly at the nodule level on low-dose CT scans. To address limitations in dataset scale and explainability, we designed an ensemble of shallow deep learning and feature-based specialized models. Trained and evaluated on 25,709 scans with 69,449 annotated nodules, the system outperforms radiologists, Lung-RADS, and leading AI models (Sybil, Brock, Google, Kaggle). It achieves an area under the receiver operating characteristic curve (AUC) of 0.98 internally and 0.945 on an independent cohort. With 0.5 false positives per scan at 99.3\% sensitivity, it addresses key barriers to AI adoption. Critically, it outperforms radiologists across all nodule sizes and stages, excelling in stage 1 cancers, and all growth-based metrics, including the least accurate: Volume-Doubling Time. It also surpasses radiologists by up to one year in diagnosing indeterminate and slow-growing nodules.

</details>


### [35] [Words into World: A Task-Adaptive Agent for Language-Guided Spatial Retrieval in AR](https://arxiv.org/abs/2512.00294)
*Lixing Guo,Tobias Höllerer*

Main category: cs.CV

TL;DR: 该论文提出了一种模块化AR代理系统，整合多模态大语言模型和视觉模型，支持复杂自然语言查询和空间关系推理，显著提升AR系统的交互性和理解能力。


<details>
  <summary>Details</summary>
Motivation: 传统AR系统依赖固定类检测器或标记物，无法处理复杂的开放词汇自然语言查询，限制了其在复杂环境中的应用。

Method: 提出了一种模块化的AR代理系统，结合多模态大语言模型和基于坐标的感知工具，支持从简单对象识别到多对象关系推理的复杂查询。

Result: 系统能够构建动态AR场景图，编码九种类型的关系，支持米级精度的3D锚点返回，并通过任务自适应区域高亮和上下文空间检索引导用户注意力。

Conclusion: 该系统通过整合多模态大语言模型和视觉模型，实现了在物理环境中进行空间和语言条件检索的关系推理，显著提升了增强现实系统的交互性和理解能力。

Abstract: Traditional augmented reality (AR) systems predominantly rely on fixed class detectors or fiducial markers, limiting their ability to interpret complex, open-vocabulary natural language queries. We present a modular AR agent system that integrates multimodal large language models (MLLMs) with grounded vision models to enable relational reasoning in space and language-conditioned spatial retrieval in physical environments. Our adaptive task agent coordinates MLLMs and coordinate-aware perception tools to address varying query complexities, ranging from simple object identification to multi-object relational reasoning, while returning meter-accurate 3D anchors. It constructs dynamic AR scene graphs encoding nine typed relations (spatial, structural-semantic, causal-functional), enabling MLLMs to understand not just what objects exist, but how they relate and interact in 3D space. Through task-adaptive region-of-interest highlighting and contextual spatial retrieval, the system guides human attention to information-dense areas while supporting human-in-the-loop refinement. The agent dynamically invokes coordinate-aware tools for complex queries-selection, measurement, comparison, and actuation-grounding language understanding in physical operations. The modular architecture supports plug-and-use vision-language models without retraining, establishing AR agents as intermediaries that augment MLLMs with real-world spatial intelligence for interactive scene understanding. We also introduce GroundedAR-Bench, an evaluation framework for language-driven real world localization and relation grounding across diverse environments.

</details>


### [36] [TGSFormer: Scalable Temporal Gaussian Splatting for Embodied Semantic Scene Completion](https://arxiv.org/abs/2512.00300)
*Rui Qian,Haozhi Cao,Tianchen Deng,Tianxin Hu,Weixiang Guo,Shenghai Yuan,Lihua Xie*

Main category: cs.CV

TL;DR: TGSFormer是一种可扩展的时态高斯溅射框架，通过持久记忆和双时间编码器优化3D语义场景补全，减少冗余并提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有高斯基方法在无界场景中冗余和扩展性差的问题，以及深度引导方法的延迟和内存开销问题。

Method: 提出了TGSFormer框架，结合持久性高斯记忆和双时间编码器，通过置信感知交叉注意力处理当前和历史高斯特征，并利用置信感知体素融合模块合并重叠基元。

Result: 在局部和嵌入式SSC基准测试中达到最先进水平，显著减少基元数量同时保持高精度和场景完整性。

Conclusion: TGSFormer通过持久性高斯记忆和双时间编码器，实现了高效且可扩展的3D语义场景补全，显著减少了冗余并保持了场景完整性。

Abstract: Embodied 3D Semantic Scene Completion (SSC) infers dense geometry and semantics from continuous egocentric observations. Most existing Gaussian-based methods rely on random initialization of many primitives within predefined spatial bounds, resulting in redundancy and poor scalability to unbounded scenes. Recent depth-guided approach alleviates this issue but remains local, suffering from latency and memory overhead as scale increases. To overcome these challenges, we propose TGSFormer, a scalable Temporal Gaussian Splatting framework for embodied SSC. It maintains a persistent Gaussian memory for temporal prediction, without relying on image coherence or frame caches. For temporal fusion, a Dual Temporal Encoder jointly processes current and historical Gaussian features through confidence-aware cross-attention. Subsequently, a Confidence-aware Voxel Fusion module merges overlapping primitives into voxel-aligned representations, regulating density and maintaining compactness. Extensive experiments demonstrate that TGSFormer achieves state-of-the-art results on both local and embodied SSC benchmarks, offering superior accuracy and scalability with significantly fewer primitives while maintaining consistent long-term scene integrity. The code will be released upon acceptance.

</details>


### [37] [Optimizing Distributional Geometry Alignment with Optimal Transport for Generative Dataset Distillation](https://arxiv.org/abs/2512.00308)
*Xiao Cui,Yulei Qin,Wengang Zhou,Hongsheng Li,Houqiang Li*

Main category: cs.CV

TL;DR: 通过最优传输（OT）框架，该方法在数据集蒸馏中实现了全局和实例级别的细粒度对齐，显著提升了模型泛化性能，实验验证了其高效性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模数据集蒸馏方法主要关注全局分布统计匹配，忽视了实例级特征和类内变化，导致泛化性能不佳。

Method: 该方法包含三个组件：OT引导的扩散采样、标签-图像对齐的软重标记和基于OT的logit匹配，共同保留了分布几何特性。

Result: 在ImageNet-1K等大规模数据集上的实验表明，该方法在IPC=10设置下，每种架构的准确率至少提升4%，且效率优于现有方法。

Conclusion: 通过将数据集蒸馏重新表述为最优传输（OT）距离最小化问题，该方法在全局和实例级别实现了细粒度的对齐，显著提升了模型在蒸馏数据集上的泛化性能。

Abstract: Dataset distillation seeks to synthesize a compact distilled dataset, enabling models trained on it to achieve performance comparable to models trained on the full dataset. Recent methods for large-scale datasets focus on matching global distributional statistics (e.g., mean and variance), but overlook critical instance-level characteristics and intraclass variations, leading to suboptimal generalization. We address this limitation by reformulating dataset distillation as an Optimal Transport (OT) distance minimization problem, enabling fine-grained alignment at both global and instance levels throughout the pipeline. OT offers a geometrically faithful framework for distribution matching. It effectively preserves local modes, intra-class patterns, and fine-grained variations that characterize the geometry of complex, high-dimensional distributions. Our method comprises three components tailored for preserving distributional geometry: (1) OT-guided diffusion sampling, which aligns latent distributions of real and distilled images; (2) label-image-aligned soft relabeling, which adapts label distributions based on the complexity of distilled image distributions; and (3) OT-based logit matching, which aligns the output of student models with soft-label distributions. Extensive experiments across diverse architectures and large-scale datasets demonstrate that our method consistently outperforms state-of-the-art approaches in an efficient manner, achieving at least 4% accuracy improvement under IPC=10 settings for each architecture on ImageNet-1K.

</details>


### [38] [ART-ASyn: Anatomy-aware Realistic Texture-based Anomaly Synthesis Framework for Chest X-Rays](https://arxiv.org/abs/2512.00310)
*Qinyi Cao,Jianan Fan,Weidong Cai*

Main category: cs.CV

TL;DR: ART-ASyn通过解剖感知的真实纹理异常合成框架，提升了无监督异常检测的性能，并在零样本分割中验证了其泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有合成异常方法生成的异常与真实病理模式视觉差异大且忽略解剖结构，限制了无监督异常检测的性能。

Method: 提出了基于渐进二值阈值分割（PBTSeg）的肺部分割方法，结合纹理增强技术生成解剖学一致的合成异常。

Result: ART-ASyn生成的合成异常与真实病理模式高度一致，并在零样本异常分割任务中表现出色。

Conclusion: ART-ASyn框架通过生成解剖学一致且真实的异常纹理，显著提升了无监督异常检测的性能，并在零样本异常分割任务中展示了良好的泛化能力。

Abstract: Unsupervised anomaly detection aims to identify anomalies without pixel-level annotations. Synthetic anomaly-based methods exhibit a unique capacity to introduce controllable irregularities with known masks, enabling explicit supervision during training. However, existing methods often produce synthetic anomalies that are visually distinct from real pathological patterns and ignore anatomical structure. This paper presents a novel Anatomy-aware Realistic Texture-based Anomaly Synthesis framework (ART-ASyn) for chest X-rays that generates realistic and anatomically consistent lung opacity related anomalies using texture-based augmentation guided by our proposed Progressive Binary Thresholding Segmentation method (PBTSeg) for lung segmentation. The generated paired samples of synthetic anomalies and their corresponding precise pixel-level anomaly mask for each normal sample enable explicit segmentation supervision. In contrast to prior work limited to one-class classification, ART-ASyn is further evaluated for zero-shot anomaly segmentation, demonstrating generalizability on an unseen dataset without target-domain annotations. Code availability is available at https://github.com/angelacao-hub/ART-ASyn.

</details>


### [39] [Odometry Without Correspondence from Inertially Constrained Ruled Surfaces](https://arxiv.org/abs/2512.00327)
*Chenqi Zhu,Levi Burner,Yiannis Aloimonos*

Main category: cs.CV

TL;DR: 论文提出了一种利用规则表面和IMU传感器融合的新算法，优化了视觉里程计的准确性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统视觉里程计技术依赖于特征点提取和光流计算，计算成本高且精度不稳定。为了解决这一问题，论文探索了利用规则表面和IMU传感器融合的方法。

Method: 通过分析图像中直线运动形成的规则表面形状，结合点线关联的微分计算更新，以及IMU传感器的惯性测量约束，实现了3D场景重建和视觉里程计的计算。

Result: 提出的算法通过规则表面和IMU约束，显著降低了计算复杂度，同时提高了视觉里程计的估计质量。

Conclusion: 该论文提出了一种基于规则表面的新颖算法，结合IMU传感器数据，有效降低了解空间的维度，从而提高了视觉里程计的准确性和效率。

Abstract: Visual odometry techniques typically rely on feature extraction from a sequence of images and subsequent computation of optical flow. This point-to-point correspondence between two consecutive frames can be costly to compute and suffers from varying accuracy, which affects the odometry estimate's quality. Attempts have been made to bypass the difficulties originating from the correspondence problem by adopting line features and fusing other sensors (event camera, IMU) to improve performance, many of which still heavily rely on correspondence. If the camera observes a straight line as it moves, the image of the line sweeps a smooth surface in image-space time. It is a ruled surface and analyzing its shape gives information about odometry. Further, its estimation requires only differentially computed updates from point-to-line associations. Inspired by event cameras' propensity for edge detection, this research presents a novel algorithm to reconstruct 3D scenes and visual odometry from these ruled surfaces. By constraining the surfaces with the inertia measurements from an onboard IMU sensor, the dimensionality of the solution space is greatly reduced.

</details>


### [40] [MVAD : A Comprehensive Multimodal Video-Audio Dataset for AIGC Detection](https://arxiv.org/abs/2512.00336)
*Mengxue Hu,Yunfeng Diao,Changtao Miao,Jianshu Li,Zhe Li,Joey Tianyi Zhou*

Main category: cs.CV

TL;DR: MVAD是首个专为检测AI生成多模态视频-音频内容设计的综合数据集，填补了现有空白，具有高质量和多样性。


<details>
  <summary>Details</summary>
Motivation: 现有合成视频数据集多局限于视觉模态或面部深度伪造，无法应对多模态AI生成内容的广泛挑战，阻碍了可信检测系统的发展。

Method: 通过三种真实的视频-音频伪造模式生成样本，并利用多样化的先进生成模型实现高感知质量。

Result: MVAD数据集具备真实多模态性、高感知质量和全面多样性，覆盖多种视觉风格、内容类别和数据类型。

Conclusion: MVAD数据集填补了现有AI生成多模态视频-音频内容检测领域的空白，为开发可信赖的检测系统提供了关键资源。

Abstract: The rapid advancement of AI-generated multimodal video-audio content has raised significant concerns regarding information security and content authenticity. Existing synthetic video datasets predominantly focus on the visual modality alone, while the few incorporating audio are largely confined to facial deepfakes--a limitation that fails to address the expanding landscape of general multimodal AI-generated content and substantially impedes the development of trustworthy detection systems. To bridge this critical gap, we introduce the Multimodal Video-Audio Dataset (MVAD), the first comprehensive dataset specifically designed for detecting AI-generated multimodal video-audio content. Our dataset exhibits three key characteristics: (1) genuine multimodality with samples generated according to three realistic video-audio forgery patterns; (2) high perceptual quality achieved through diverse state-of-the-art generative models; and (3) comprehensive diversity spanning realistic and anime visual styles, four content categories (humans, animals, objects, and scenes), and four video-audio multimodal data types. Our dataset will be available at https://github.com/HuMengXue0104/MVAD.

</details>


### [41] [Assimilation Matters: Model-level Backdoor Detection in Vision-Language Pretrained Models](https://arxiv.org/abs/2512.00343)
*Zhongqi Wang,Jie Zhang,Shiguang Shan,Xilin Chen*

Main category: cs.CV

TL;DR: AMDET是一种无需先验知识的后门检测框架，通过特征同化和梯度反转技术高效检测VLPs中的后门攻击，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有后门检测方法依赖训练数据、触发器或下游分类器的先验知识，不适用于实际场景，亟需一种无需先验知识的检测框架。

Method: AMDET通过揭示后门文本编码器的特征同化属性，利用梯度反转技术恢复能激活后门行为的隐式特征，并结合损失景观分析区分自然后门特征。

Result: 在3,600个后门和良性微调模型上的实验表明，AMDET的F1得分为89.90%，检测时间约5分钟，且对自适应攻击具有强鲁棒性。

Conclusion: AMDET提出了一种无需先验知识的模型级后门检测框架，通过特征同化和梯度反转技术有效检测后门攻击，实验证明其高效性和鲁棒性。

Abstract: Vision-language pretrained models (VLPs) such as CLIP have achieved remarkable success, but are also highly vulnerable to backdoor attacks. Given a model fine-tuned by an untrusted third party, determining whether the model has been injected with a backdoor is a critical and challenging problem. Existing detection methods usually rely on prior knowledge of training dataset, backdoor triggers and targets, or downstream classifiers, which may be impractical for real-world applications. To address this, To address this challenge, we introduce Assimilation Matters in DETection (AMDET), a novel model-level detection framework that operates without any such prior knowledge. Specifically, we first reveal the feature assimilation property in backdoored text encoders: the representations of all tokens within a backdoor sample exhibit a high similarity. Further analysis attributes this effect to the concentration of attention weights on the trigger token. Leveraging this insight, AMDET scans a model by performing gradient-based inversion on token embeddings to recover implicit features that capable of activating backdoor behaviors. Furthermore, we identify the natural backdoor feature in the OpenAI's official CLIP model, which are not intentionally injected but still exhibit backdoor-like behaviors. We then filter them out from real injected backdoor by analyzing their loss landscapes. Extensive experiments on 3,600 backdoored and benign-finetuned models with two attack paradigms and three VLP model structures show that AMDET detects backdoors with an F1 score of 89.90%. Besides, it achieves one complete detection in approximately 5 minutes on a RTX 4090 GPU and exhibits strong robustness against adaptive attacks. Code is available at: https://github.com/Robin-WZQ/AMDET

</details>


### [42] [mmPred: Radar-based Human Motion Prediction in the Dark](https://arxiv.org/abs/2512.00345)
*Junqiao Fan,Haocong Rao,Jiarui Zhang,Jianfei Yang,Lihua Xie*

Main category: cs.CV

TL;DR: 首次将毫米波雷达用于人体运动预测，提出mmPred框架，通过双域表示和全局Transformer解决雷达信号噪声问题，性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-D摄像头的人体运动预测方法对光照敏感且存在隐私问题，毫米波雷达因其鲁棒性和隐私保护特性成为新选择，但雷达信号存在噪声和时域不一致问题。

Method: 提出mmPred框架，包含时域姿态细化分支（TPR）学习细粒度细节，频域主导运动分支（FDM）捕捉全局趋势并抑制帧级不一致，以及全局骨架关系Transformer（GST）建模关节协作。

Result: mmPred在mmBody和mm-Fi数据集上分别取得8.6%和22%的性能提升，达到最先进水平。

Conclusion: mmPred作为首个基于毫米波雷达的人体运动预测扩散框架，通过双域历史运动表示和全局骨架关系Transformer，显著提升了预测性能，在mmBody和mm-Fi数据集上分别优于现有方法8.6%和22%。

Abstract: Existing Human Motion Prediction (HMP) methods based on RGB-D cameras are sensitive to lighting conditions and raise privacy concerns, limiting their real-world applications such as firefighting and healthcare. Motivated by the robustness and privacy-preserving nature of millimeter-wave (mmWave) radar, this work introduces radar as a novel sensing modality for HMP, for the first time. Nevertheless, radar signals often suffer from specular reflections and multipath effects, resulting in noisy and temporally inconsistent measurements, such as body-part miss-detection. To address these radar-specific artifacts, we propose mmPred, the first diffusion-based framework tailored for radar-based HMP. mmPred introduces a dual-domain historical motion representation to guide the generation process, combining a Time-domain Pose Refinement (TPR) branch for learning fine-grained details and a Frequency-domain Dominant Motion (FDM) branch for capturing global motion trends and suppressing frame-level inconsistency. Furthermore, we design a Global Skeleton-relational Transformer (GST) as the diffusion backbone to model global inter-joint cooperation, enabling corrupted joints to dynamically aggregate information from others. Extensive experiments show that mmPred achieves state-of-the-art performance, outperforming existing methods by 8.6% on mmBody and 22% on mm-Fi.

</details>


### [43] [SMamDiff: Spatial Mamba for Stochastic Human Motion Prediction](https://arxiv.org/abs/2512.00355)
*Junqiao Fan,Pengfei Liu,Haocong Rao*

Main category: cs.CV

TL;DR: SMamDiff是一种单阶段扩散模型，通过残差DCT编码和空间-mamba模块提升人运动预测的时空一致性，性能优于现有方法且更高效。


<details>
  <summary>Details</summary>
Motivation: 现有HMP方法在准确性与多样性、计算效率之间存在矛盾，多阶段扩散模型计算成本高，单阶段模型缺乏时空一致性。

Method: 提出SMamDiff模型，采用残差DCT运动编码和stickman-drawing空间-mamba模块，前者减少低频信息主导，突出高频运动特征；后者通过有序处理关节，建立跨关节依赖。

Result: 在Human3.6M和HumanEva数据集上，SMamDiff在单阶段概率HMP方法中达到最优性能，且延迟和内存消耗低于多阶段基线。

Conclusion: SMamDiff通过创新的残差DCT运动编码和stickman-drawing空间-mamba模块，在单阶段扩散模型中实现了时空一致性，显著提升了人运动预测的准确性和多样性，同时降低了延迟和内存消耗。

Abstract: With intelligent room-side sensing and service robots widely deployed, human motion prediction (HMP) is essential for safe, proactive assistance. However, many existing HMP methods either produce a single, deterministic forecast that ignores uncertainty or rely on probabilistic models that sacrifice kinematic plausibility. Diffusion models improve the accuracy-diversity trade-off but often depend on multi-stage pipelines that are costly for edge deployment. This work focuses on how to ensure spatial-temporal coherence within a single-stage diffusion model for HMP. We introduce SMamDiff, a Spatial Mamba-based Diffusion model with two novel designs: (i) a residual-DCT motion encoding that subtracts the last observed pose before a temporal DCT, reducing the first DC component ($f=0$) dominance and highlighting informative higher-frequency cues so the model learns how joints move rather than where they are; and (ii) a stickman-drawing spatial-mamba module that processes joints in an ordered, joint-by-joint manner, making later joints condition on earlier ones to induce long-range, cross-joint dependencies. On Human3.6M and HumanEva, these coherence mechanisms deliver state-of-the-art results among single-stage probabilistic HMP methods while using less latency and memory than multi-stage diffusion baselines.

</details>


### [44] [MM-DETR: An Efficient Multimodal Detection Transformer with Mamba-Driven Dual-Granularity Fusion and Frequency-Aware Modality Adapters](https://arxiv.org/abs/2512.00363)
*Jianhong Han,Yupei Wang,Yuan Zhang,Liang Chen*

Main category: cs.CV

TL;DR: MM-DETR是一种轻量高效的多模态目标检测框架，通过创新的融合编码器和补充分支，解决了现有方法在性能和参数效率上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有方法在性能和轻量化设计之间难以平衡，共享主干网络提取的多模态特征表示不充分，双流架构参数翻倍，限制了实际部署。

Method: 提出MM-DETR框架，包括Mamba-based双粒度融合编码器（通道动态门控和1D选择性扫描）、区域感知2D选择性扫描补充分支，以及轻量级频率感知模态适配器（空间-频率共专家结构和像素级路由器）。

Result: 在四个多模态基准数据集上的大量实验证明了该方法的有效性和泛化能力。

Conclusion: MM-DETR框架通过创新的Mamba-based双粒度融合编码器和区域感知的2D选择性扫描补充分支，有效平衡了性能与轻量化设计，显著提升了多模态目标检测的准确性和鲁棒性。

Abstract: Multimodal remote sensing object detection aims to achieve more accurate and robust perception under challenging conditions by fusing complementary information from different modalities. However, existing approaches that rely on attention-based or deformable convolution fusion blocks still struggle to balance performance and lightweight design. Beyond fusion complexity, extracting modality features with shared backbones yields suboptimal representations due to insufficient modality-specific modeling, whereas dual-stream architectures nearly double the parameter count, ultimately limiting practical deployment. To this end, we propose MM-DETR, a lightweight and efficient framework for multimodal object detection. Specifically, we propose a Mamba-based dual granularity fusion encoder that reformulates global interaction as channel-wise dynamic gating and leverages a 1D selective scan for efficient cross-modal modeling with linear complexity. Following this design, we further reinterpret multimodal fusion as a modality completion problem. A region-aware 2D selective scanning completion branch is introduced to recover modality-specific cues, supporting fine-grained fusion along a bidirectional pyramid pathway with minimal overhead. To further reduce parameter redundancy while retaining strong feature extraction capability, a lightweight frequency-aware modality adapter is inserted into the shared backbone. This adapter employs a spatial-frequency co-expert structure to capture modality-specific cues, while a pixel-wise router dynamically balances expert contributions for efficient spatial-frequency fusion. Extensive experiments conducted on four multimodal benchmark datasets demonstrate the effectiveness and generalization capability of the proposed method.

</details>


### [45] [Towards aligned body representations in vision models](https://arxiv.org/abs/2512.00365)
*Andrey Gizdov,Andrea Procopio,Yichen Li,Daniel Harari,Tomer Ullman*

Main category: cs.CV

TL;DR: 研究表明，小模型在分割任务中能自发形成类似人类的粗粒度身体表征，而大模型则倾向于细粒度编码，这为理解大脑物理推理提供了新视角。


<details>
  <summary>Details</summary>
Motivation: 探索视觉模型在分割任务中是否能够发展出与人类相似的粗粒度身体表征。

Method: 研究通过将50名人类参与者的心理物理实验改编为语义分割任务，测试了七种不同大小的分割网络。

Result: 发现较小模型自然形成类似人类的粗粒度表征，而较大模型倾向于过度详细的细粒度编码。

Conclusion: 研究结果表明，在有限的计算资源下，机器模型可以形成类似人类的粗粒度身体表征，这为理解大脑物理推理结构提供了一条可扩展的路径。

Abstract: Human physical reasoning relies on internal "body" representations - coarse, volumetric approximations that capture an object's extent and support intuitive predictions about motion and physics. While psychophysical evidence suggests humans use such coarse representations, their internal structure remains largely unknown. Here we test whether vision models trained for segmentation develop comparable representations. We adapt a psychophysical experiment conducted with 50 human participants to a semantic segmentation task and test a family of seven segmentation networks, varying in size. We find that smaller models naturally form human-like coarse body representations, whereas larger models tend toward overly detailed, fine-grain encodings. Our results demonstrate that coarse representations can emerge under limited computational resources, and that machine representations can provide a scalable path toward understanding the structure of physical reasoning in the brain.

</details>


### [46] [THCRL: Trusted Hierarchical Contrastive Representation Learning for Multi-View Clustering](https://arxiv.org/abs/2512.00368)
*Jian Zhu*

Main category: cs.CV

TL;DR: THCRL通过DSHF和AKCL模块解决了多视图聚类中的不可信融合问题，实验证明其性能优越。


<details>
  <summary>Details</summary>
Motivation: 解决多视图聚类中因忽略视图内噪声和邻居结构信息导致的不可信融合问题。

Method: 提出了THCRL方法，包含DSHF模块（利用UNet架构和多去噪机制实现可信融合）和AKCL模块（通过增强同一簇内样本的表示相似性来提升融合信心）。

Result: THCRL在多视图聚类任务中达到了最先进的性能。

Conclusion: THCRL通过DSHF和AKCL模块有效解决了多视图聚类中的不可信融合问题，实现了最先进的性能。

Abstract: Multi-View Clustering (MVC) has garnered increasing attention in recent years. It is capable of partitioning data samples into distinct groups by learning a consensus representation. However, a significant challenge remains: the problem of untrustworthy fusion. This problem primarily arises from two key factors: 1) Existing methods often ignore the presence of inherent noise within individual views; 2) In traditional MVC methods using Contrastive Learning (CL), similarity computations typically rely on different views of the same instance, while neglecting the structural information from nearest neighbors within the same cluster. Consequently, this leads to the wrong direction for multi-view fusion. To address this problem, we present a novel Trusted Hierarchical Contrastive Representation Learning (THCRL). It consists of two key modules. Specifically, we propose the Deep Symmetry Hierarchical Fusion (DSHF) module, which leverages the UNet architecture integrated with multiple denoising mechanisms to achieve trustworthy fusion of multi-view data. Furthermore, we present the Average K-Nearest Neighbors Contrastive Learning (AKCL) module to align the fused representation with the view-specific representation. Unlike conventional strategies, AKCL enhances representation similarity among samples belonging to the same cluster, rather than merely focusing on the same sample across views, thereby reinforcing the confidence of the fused representation. Extensive experiments demonstrate that THCRL achieves the state-of-the-art performance in deep MVC tasks.

</details>


### [47] [POLARIS: Projection-Orthogonal Least Squares for Robust and Adaptive Inversion in Diffusion Models](https://arxiv.org/abs/2512.00369)
*Wenshuo Chen,Haosen Li,Shaofeng Liang,Lei Wang,Haozhe Jia,Kaishen Yuan,Jieming Wu,Bowen Tian,Yutao Yue*

Main category: cs.CV

TL;DR: POLARIS通过优化引导尺度ω，最小化反转误差，显著提升图像编辑和恢复任务的性能。


<details>
  <summary>Details</summary>
Motivation: 揭示重建退化中一个被忽视的关键因素：近似噪声误差，该误差源于用步骤t-1的预测近似步骤t的噪声，导致反转过程中严重的误差累积。

Method: 引入Projection-Orthogonal Least Squares for Robust and Adaptive Inversion (POLARIS)，将反转问题从误差补偿问题重新表述为误差起源问题。

Result: POLARIS显著减轻了噪声近似误差，并持续提高了下游任务的准确性，且性能开销可忽略不计。

Conclusion: POLARIS通过将引导尺度ω作为逐步变量，并推导出数学公式以最小化每一步的反转误差，显著提高了反转潜在质量，且仅需一行代码即可实现。

Abstract: The Inversion-Denoising Paradigm, which is based on diffusion models, excels in diverse image editing and restoration tasks. We revisit its mechanism and reveal a critical, overlooked factor in reconstruction degradation: the approximate noise error. This error stems from approximating the noise at step t with the prediction at step t-1, resulting in severe error accumulation throughout the inversion process. We introduce Projection-Orthogonal Least Squares for Robust and Adaptive Inversion (POLARIS), which reformulates inversion from an error-compensation problem into an error-origin problem. Rather than optimizing embeddings or latent codes to offset accumulated drift, POLARIS treats the guidance scale ω as a step-wise variable and derives a mathematically grounded formula to minimize inversion error at each step. Remarkably, POLARIS improves inversion latent quality with just one line of code. With negligible performance overhead, it substantially mitigates noise approximation errors and consistently improves the accuracy of downstream tasks.

</details>


### [48] [Pore-scale Image Patch Dataset and A Comparative Evaluation of Pore-scale Facial Features](https://arxiv.org/abs/2512.00381)
*Dong Li,HuaLiang Lin,JiaYu Li*

Main category: cs.CV

TL;DR: 提出PorePatch数据集和DMCE框架，SOTA模型在匹配任务表现优异，但在3D重建中与传统描述符差距不大，显示深度学习在面部弱纹理区域仍有局限。


<details>
  <summary>Details</summary>
Motivation: 面部皮肤区域的弱纹理特性给局部描述符匹配带来挑战，且缺乏毛孔尺度图像补丁数据集阻碍了深度学习描述符的发展。

Method: 提出了PorePatch数据集和Data-Model Co-Evolution (DMCE)框架，用于生成高质量数据集，并在其上训练现有SOTA模型进行实验。

Result: SOTA模型在匹配任务中FPR95值为1.91%，优于PSIFT（22.41%），但在3D重建任务中优势不明显。

Conclusion: 深度学习描述符在面部弱纹理区域仍存在局限性，该领域仍需进一步研究。

Abstract: The weak-texture nature of facial skin regions presents significant challenges for local descriptor matching in applications such as facial motion analysis and 3D face reconstruction. Although deep learning-based descriptors have demonstrated superior performance to traditional hand-crafted descriptors in many applications, the scarcity of pore-scale image patch datasets has hindered their further development in the facial domain. In this paper, we propose the PorePatch dataset, a high-quality pore-scale image patch dataset, and establish a rational evaluation benchmark. We introduce a Data-Model Co-Evolution (DMCE) framework to generate a progressively refined, high-quality dataset from high-resolution facial images. We then train existing SOTA models on our dataset and conduct extensive experiments. Our results show that the SOTA model achieves a FPR95 value of 1.91% on the matching task, outperforming PSIFT (22.41%) by a margin of 20.5%. However, its advantage is diminished in the 3D reconstruction task, where its overall performance is not significantly better than that of traditional descriptors. This indicates that deep learning descriptors still have limitations in addressing the challenges of facial weak-texture regions, and much work remains to be done in this field.

</details>


### [49] [EZ-SP: Fast and Lightweight Superpoint-Based 3D Segmentation](https://arxiv.org/abs/2512.00385)
*Louis Geist,Loic Landrieu,Damien Robert*

Main category: cs.CV

TL;DR: EZ-SP是一种高效的GPU超点划分算法，显著提升了3D语义分割的速度和资源效率，适用于多种场景。


<details>
  <summary>Details</summary>
Motivation: 解决基于超点的3D语义分割流程中CPU绑定的划分步骤导致的效率瓶颈问题。

Method: 提出了一种可学习的、完全在GPU上运行的划分算法，替代了CPU绑定的划分步骤，结合轻量级超点分类器，实现了高效的分割流程。

Result: EZ-SP在三个不同领域（室内扫描、自动驾驶、航空LiDAR）中，与基于点的SOTA模型相比，推理速度快72倍，参数减少120倍，同时保持相同精度。

Conclusion: EZ-SP在保持高精度的同时，显著提升了计算效率和资源利用率，适用于多种3D语义分割场景。

Abstract: Superpoint-based pipelines provide an efficient alternative to point- or voxel-based 3D semantic segmentation, but are often bottlenecked by their CPU-bound partition step. We propose a learnable, fully GPU partitioning algorithm that generates geometrically and semantically coherent superpoints 13$\times$ faster than prior methods. Our module is compact (under 60k parameters), trains in under 20 minutes with a differentiable surrogate loss, and requires no handcrafted features. Combine with a lightweight superpoint classifier, the full pipeline fits in $<$2 MB of VRAM, scales to multi-million-point scenes, and supports real-time inference. With 72$\times$ faster inference and 120$\times$ fewer parameters, EZ-SP matches the accuracy of point-based SOTA models across three domains: indoor scans (S3DIS), autonomous driving (KITTI-360), and aerial LiDAR (DALES). Code and pretrained models are accessible at github.com/drprojects/superpoint_transformer.

</details>


### [50] [WiseEdit: Benchmarking Cognition- and Creativity-Informed Image Editing](https://arxiv.org/abs/2512.00387)
*Kaihang Pan,Weile Chen,Haiyi Qiu,Qifan Yu,Wendong Bu,Zehan Wang,Yun Zhu,Juncheng Li,Siliang Tang*

Main category: cs.CV

TL;DR: WiseEdit是一个知识密集型的图像编辑评估基准，通过分解编辑步骤和融入多种知识类型，全面测试模型的认知和创意能力，揭示了现有模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有评估基准范围过窄，无法全面评估图像编辑模型的高级认知和创意能力。

Method: 通过将图像编辑分解为三个级联步骤（认知、解释和想象），并融入三种基本知识类型（陈述性、程序性和元认知知识），WiseEdit构建了一个包含1,220个测试案例的全面评估框架。

Result: WiseEdit客观揭示了现有模型在知识密集型任务中的不足。

Conclusion: WiseEdit基准测试揭示了当前最先进的图像编辑模型在基于知识的认知推理和创意构图能力上的局限性。

Abstract: Recent image editing models boast next-level intelligent capabilities, facilitating cognition- and creativity-informed image editing. Yet, existing benchmarks provide too narrow a scope for evaluation, failing to holistically assess these advanced abilities. To address this, we introduce WiseEdit, a knowledge-intensive benchmark for comprehensive evaluation of cognition- and creativity-informed image editing, featuring deep task depth and broad knowledge breadth. Drawing an analogy to human cognitive creation, WiseEdit decomposes image editing into three cascaded steps, i.e., Awareness, Interpretation, and Imagination, each corresponding to a task that poses a challenge for models to complete at the specific step. It also encompasses complex tasks, where none of the three steps can be finished easily. Furthermore, WiseEdit incorporates three fundamental types of knowledge: Declarative, Procedural, and Metacognitive knowledge. Ultimately, WiseEdit comprises 1,220 test cases, objectively revealing the limitations of SoTA image editing models in knowledge-based cognitive reasoning and creative composition capabilities. The benchmark, evaluation code, and the generated images of each model will be made publicly available soon. Project Page: https://qnancy.github.io/wiseedit_project_page/.

</details>


### [51] [Better, Stronger, Faster: Tackling the Trilemma in MLLM-based Segmentation with Simultaneous Textual Mask Prediction](https://arxiv.org/abs/2512.00395)
*Jiazhen Liu,Mingkuan Feng,Long Chen*

Main category: cs.CV

TL;DR: STAMP通过all-mask prediction范式，解决了MLLMs在对话、分割和速度上的三难问题，性能全面领先。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在MLLMs中无法同时兼顾对话能力、分割性能和推理速度的问题。

Method: 提出了STAMP模型，采用all-mask prediction范式，将分割任务解耦为非自回归的掩码预测，并在单次前向传播中完成。

Result: STAMP在多个分割基准测试中显著优于现有方法，实现了对话、分割和速度的全面优势。

Conclusion: STAMP通过all-mask prediction范式成功解决了MLLMs在对话能力、分割性能和推理速度之间的三难问题，无需妥协。

Abstract: Integrating segmentation into Multimodal Large Language Models (MLLMs) presents a core trilemma: simultaneously preserving dialogue ability, achieving high segmentation performance, and ensuring fast inference. Prevailing paradigms are forced into a compromise. Embedding prediction methods introduce a conflicting pixel-level objective that degrades the MLLM's general dialogue abilities. The alternative, next-token prediction, reframes segmentation as an autoregressive task, which preserves dialogue but forces a trade-off between poor segmentation performance with sparse outputs or prohibitive inference speeds with rich ones. We resolve this trilemma with all-mask prediction, a novel paradigm that decouples autoregressive dialogue generation from non-autoregressive mask prediction. We present STAMP: Simultaneous Textual All-Mask Prediction, an MLLM that embodies this paradigm. After generating a textual response, STAMP predicts an entire segmentation mask in a single forward pass by treating it as a parallel "fill-in-the-blank" task over image patches. This design maintains the MLLM's dialogue ability by avoiding conflicting objectives, enables high segmentation performance by leveraging rich, bidirectional spatial context for all mask tokens, and achieves exceptional speed. Extensive experiments show that STAMP significantly outperforms state-of-the-art methods across multiple segmentation benchmarks, providing a solution that excels in dialogue, segmentation, and speed without compromise.

</details>


### [52] [Low-Bitrate Video Compression through Semantic-Conditioned Diffusion](https://arxiv.org/abs/2512.00408)
*Lingdong Wang,Guan-Ming Su,Divya Kothandaraman,Tsung-Wei Huang,Mohammad Hajiesmaili,Ramesh K. Sitaraman*

Main category: cs.CV

TL;DR: DiSCo通过语义分解和生成模型在超低比特率下实现高质量视频压缩，性能显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统视频编解码器在超低比特率下因像素保真度与人类感知不匹配而产生严重伪影，需探索更符合感知的压缩方法。

Method: 提出了一种名为DiSCo的语义视频压缩框架，将视频分解为文本描述、时空降质视频和可选草图或姿态三种紧凑模态，并采用条件视频扩散模型进行高质量重建。

Result: 实验表明，DiSCo在低比特率下的感知指标比基线语义和传统编解码器高出2-10倍。

Conclusion: DiSCo框架通过结合语义、外观和运动线索，利用生成先验进行细节合成，显著提升了超低比特率下的视频压缩性能。

Abstract: Traditional video codecs optimized for pixel fidelity collapse at ultra-low bitrates and produce severe artifacts. This failure arises from a fundamental misalignment between pixel accuracy and human perception. We propose a semantic video compression framework named DiSCo that transmits only the most meaningful information while relying on generative priors for detail synthesis. The source video is decomposed into three compact modalities: a textual description, a spatiotemporally degraded video, and optional sketches or poses that respectively capture semantic, appearance, and motion cues. A conditional video diffusion model then reconstructs high-quality, temporally coherent videos from these compact representations. Temporal forward filling, token interleaving, and modality-specific codecs are proposed to improve multimodal generation and modality compactness. Experiments show that our method outperforms baseline semantic and traditional codecs by 2-10X on perceptual metrics at low bitrates.

</details>


### [53] [PhysGen: Physically Grounded 3D Shape Generation for Industrial Design](https://arxiv.org/abs/2512.00422)
*Yingxuan You,Chen Zhao,Hantao Zhang,Mingda Xu,Pascal Fua*

Main category: cs.CV

TL;DR: 提出了一种结合物理知识的3D形状生成流程，通过交替更新和物理细化提升形状真实性。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型缺乏物理知识，无法利用物理属性增强形状生成的真实性，尤其是在工程设计类形状中。

Method: 引入了一种新的带有明确物理指导的流匹配模型，包括交替更新过程，结合速度更新和物理细化，并加入了物理感知正则化项。

Result: 在三个基准测试中，这种协同方法提高了形状的真实性。

Conclusion: 提出的统一物理基础的3D形状生成流程显著提升了形状的真实性，超越了单纯的视觉合理性。

Abstract: Existing generative models for 3D shapes can synthesize high-fidelity and visually plausible shapes. For certain classes of shapes that have undergone an engineering design process, the realism of the shape is tightly coupled with the underlying physical properties, e.g., aerodynamic efficiency for automobiles. Since existing methods lack knowledge of such physics, they are unable to use this knowledge to enhance the realism of shape generation. Motivated by this, we propose a unified physics-based 3D shape generation pipeline, with a focus on industrial design applications. Specifically, we introduce a new flow matching model with explicit physical guidance, consisting of an alternating update process. We iteratively perform a velocity-based update and a physics-based refinement, progressively adjusting the latent code to align with the desired 3D shapes and physical properties. We further strengthen physical validity by incorporating a physics-aware regularization term into the velocity-based update step. To support such physics-guided updates, we build a shape-and-physics variational autoencoder (SP-VAE) that jointly encodes shape and physics information into a unified latent space. The experiments on three benchmarks show that this synergistic formulation improves shape realism beyond mere visual plausibility.

</details>


### [54] [Recovering Origin Destination Flows from Bus CCTV: Early Results from Nairobi and Kigali](https://arxiv.org/abs/2512.00424)
*Nthenya Kyatha,Jay Taneja*

Main category: cs.CV

TL;DR: 研究利用车上CCTV，开发了一种自动化乘客流量数据采集系统，在理想条件下表现良好，但在实际SSA公交环境中面临显著挑战，需进一步优化。


<details>
  <summary>Details</summary>
Motivation: 由于现有自动化系统在SSA的拥挤公共交通环境中无法可靠捕获乘客流量数据，研究利用已部署的车上CCTV，旨在提供一种解决方案。

Method: 研究提出了一种基线流程，结合了YOLOv12检测、BotSORT跟踪、OSNet嵌入、基于OCR的时间戳和基于遥感的站点分类，以恢复公交车的起讫点（OD）流量。

Result: 在低密度、良好光照条件下，系统表现出高计数准确性（召回率≈95%，精确率≈91%，F1≈93%），生成的OD矩阵与手动计数结果高度一致。但在实际压力下（如过度拥挤、单色转换、姿势变化和非标准门使用），性能显著下降（如高峰时段上车低估约40%，单色片段召回率下降约17个百分点）。

Conclusion: 该研究揭示了在撒哈拉以南非洲（SSA）公共交通系统中部署自动化乘客流量数据采集系统的挑战，特别是在高密度和恶劣光照条件下性能显著下降，强调了需要开发更鲁棒、针对部署环境的行人重识别（Re-ID）方法。

Abstract: Public transport in sub-Saharan Africa (SSA) often operates in overcrowded conditions where existing automated systems fail to capture reliable passenger flow data. Leveraging onboard CCTV already deployed for security, we present a baseline pipeline that combines YOLOv12 detection, BotSORT tracking, OSNet embeddings, OCR-based timestamping, and telematics-based stop classification to recover bus origin--destination (OD) flows. On annotated CCTV segments from Nairobi and Kigali buses, the system attains high counting accuracy under low-density, well-lit conditions (recall $\approx$95\%, precision $\approx$91\%, F1 $\approx$93\%). It produces OD matrices that closely match manual tallies. Under realistic stressors such as overcrowding, color-to-monochrome shifts, posture variation, and non-standard door use, performance degrades sharply (e.g., $\sim$40\% undercount in peak-hour boarding and a $\sim$17 percentage-point drop in recall for monochrome segments), revealing deployment-specific failure modes and motivating more robust, deployment-focused Re-ID methods for SSA transit.

</details>


### [55] [What about gravity in video generation? Post-Training Newton's Laws with Verifiable Rewards](https://arxiv.org/abs/2512.00425)
*Minh-Quan Le,Yuanzhi Zhu,Vicky Kalogeiton,Dimitris Samaras*

Main category: cs.CV

TL;DR: $	exttt{NewtonRewards}$通过物理学代理和奖励机制提升视频生成的物理合理性。


<details>
  <summary>Details</summary>
Motivation: 当前视频扩散模型在视觉上令人信服，但经常违反基本物理定律，揭示视觉真实性与物理真实性之间的差距。

Method: 提出$	exttt{NewtonRewards}$，一种基于可验证奖励的物理学基础后训练框架，通过光学流作为速度代理，外观特征作为质量代理，强制执行牛顿结构。

Result: $	exttt{NewtonRewards}$在视觉和物理指标上持续提升了物理合理性、运动平滑性和时间一致性，并在分布外变化下保持强性能。

Conclusion: 物理学基础的验证奖励为物理感知视频生成提供了一条可扩展的路径。

Abstract: Recent video diffusion models can synthesize visually compelling clips, yet often violate basic physical laws-objects float, accelerations drift, and collisions behave inconsistently-revealing a persistent gap between visual realism and physical realism. We propose $\texttt{NewtonRewards}$, the first physics-grounded post-training framework for video generation based on $\textit{verifiable rewards}$. Instead of relying on human or VLM feedback, $\texttt{NewtonRewards}$ extracts $\textit{measurable proxies}$ from generated videos using frozen utility models: optical flow serves as a proxy for velocity, while high-level appearance features serve as a proxy for mass. These proxies enable explicit enforcement of Newtonian structure through two complementary rewards: a Newtonian kinematic constraint enforcing constant-acceleration dynamics, and a mass conservation reward preventing trivial, degenerate solutions. We evaluate $\texttt{NewtonRewards}$ on five Newtonian Motion Primitives (free fall, horizontal/parabolic throw, and ramp sliding down/up) using our newly constructed large-scale benchmark, $\texttt{NewtonBench-60K}$. Across all primitives in visual and physics metrics, $\texttt{NewtonRewards}$ consistently improves physical plausibility, motion smoothness, and temporal coherence over prior post-training methods. It further maintains strong performance under out-of-distribution shifts in height, speed, and friction. Our results show that physics-grounded verifiable rewards offer a scalable path toward physics-aware video generation.

</details>


### [56] [Recognizing Pneumonia in Real-World Chest X-rays with a Classifier Trained with Images Synthetically Generated by Nano Banana](https://arxiv.org/abs/2512.00428)
*Jiachuan Peng,Kyle Lam,Jianing Qiu*

Main category: cs.CV

TL;DR: 使用合成CXR训练的分类器在真实数据上表现优异，验证了合成数据在医学AI中的潜力，但仍需解决多样性和对齐问题。


<details>
  <summary>Details</summary>
Motivation: 探索合成数据在医学AI开发中的可行性及其潜力。

Method: 使用Nano Banana生成的合成胸部X光图像训练分类器，并在真实世界的CXR数据集上进行外部验证。

Result: 分类器在真实数据上表现良好（AUROC 0.923，AUPR 0.900），验证了合成数据的可行性。

Conclusion: 尽管存在局限性，如合成数据多样性的控制挑战和对齐真实数据的需求，但合成数据在医学AI开发中显示出潜力，未来需要更多验证和监管。

Abstract: We trained a classifier with synthetic chest X-ray (CXR) images generated by Nano Banana, the latest AI model for image generation and editing, released by Google. When directly applied to real-world CXRs having only been trained with synthetic data, the classifier achieved an AUROC of 0.923 (95% CI: 0.919 - 0.927), and an AUPR of 0.900 (95% CI: 0.894 - 0.907) in recognizing pneumonia in the 2018 RSNA Pneumonia Detection dataset (14,863 CXRs), and an AUROC of 0.824 (95% CI: 0.810 - 0.836), and an AUPR of 0.913 (95% CI: 0.904 - 0.922) in the Chest X-Ray dataset (5,856 CXRs). These external validation results on real-world data demonstrate the feasibility of this approach and suggest potential for synthetic data in medical AI development. Nonetheless, several limitations remain at present, including challenges in prompt design for controlling the diversity of synthetic CXR data and the requirement for post-processing to ensure alignment with real-world data. However, the growing sophistication and accessibility of medical intelligence will necessitate substantial validation, regulatory approval, and ethical oversight prior to clinical translation.

</details>


### [57] [FR-TTS: Test-Time Scaling for NTP-based Image Generation with Effective Filling-based Reward Signal](https://arxiv.org/abs/2512.00438)
*Hang Xu,Linjiang Huang,Feng Zhao*

Main category: cs.CV

TL;DR: FR-TTS通过填充奖励和多样性奖励动态加权，解决了TTS在NTP中的中间样本评估问题，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决测试时扩展（TTS）在下一令牌预测（NTP）中因中间序列与最终生成内容相关性低而难以应用的问题。

Method: 提出了Filling-Based Reward（FR）来估计中间样本的未来轨迹，并通过合理的填充方案完成序列。在此基础上设计了FR-TTS策略，结合多样性奖励和动态加权。

Result: 实验证明FR-TTS在多个基准和奖励模型中表现优越。

Conclusion: FR-TTS通过引入基于填充的奖励（FR）和多样性奖励的动态加权策略，显著提升了中间样本的质量评估效果，并在实验中验证了其优越性。

Abstract: Test-time scaling (TTS) has become a prevalent technique in image generation, significantly boosting output quality by expanding the number of parallel samples and filtering them using pre-trained reward models. However, applying this powerful methodology to the next-token prediction (NTP) paradigm remains challenging. The primary obstacle is the low correlation between the reward of an image decoded from an intermediate token sequence and the reward of the fully generated image. Consequently, these incomplete intermediate representations prove to be poor indicators for guiding the pruning direction, a limitation that stems from their inherent incompleteness in scale or semantic content. To effectively address this critical issue, we introduce the Filling-Based Reward (FR). This novel design estimates the approximate future trajectory of an intermediate sample by finding and applying a reasonable filling scheme to complete the sequence. Both the correlation coefficient between rewards of intermediate samples and final samples, as well as multiple intrinsic signals like token confidence, indicate that the FR provides an excellent and reliable metric for accurately evaluating the quality of intermediate samples. Building upon this foundation, we propose FR-TTS, a sophisticated scaling strategy. FR-TTS efficiently searches for good filling schemes and incorporates a diversity reward with a dynamic weighting schedule to achieve a balanced and comprehensive evaluation of intermediate samples. We experimentally validate the superiority of FR-TTS over multiple established benchmarks and various reward models. Code is available at \href{https://github.com/xuhang07/FR-TTS}{https://github.com/xuhang07/FR-TTS}.

</details>


### [58] [RecruitView: A Multimodal Dataset for Predicting Personality and Interview Performance for Human Resources Applications](https://arxiv.org/abs/2512.00450)
*Amit Kumar Gupta,Farhan Sheth,Hammad Shaikh,Dheeraj Kumar,Angkul Puniya,Deepak Panwar,Sandeep Chaurasia,Priya Mathur*

Main category: cs.CV

TL;DR: CRMF通过几何深度学习在多模态数据中高效评估人格和软技能，性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在人格和软技能评估中无法捕捉几何结构及数据不足的问题。

Method: 提出了Cross-Modal Regression with Manifold Fusion (CRMF)框架，利用双曲、球面和欧几里得流形的几何深度学习，结合自适应路由机制和切线空间融合。

Result: CRMF在Spearman相关性和一致性指数上分别提升11.4%和6.0%，且参数减少40-50%。

Conclusion: CRMF框架通过几何深度学习在多模态行为数据中有效捕捉人格特质和软技能的几何结构，显著提升了评估性能，且参数效率更高。

Abstract: Automated personality and soft skill assessment from multimodal behavioral data remains challenging due to limited datasets and methods that fail to capture geometric structure inherent in human traits. We introduce RecruitView, a dataset of 2,011 naturalistic video interview clips from 300+ participants with 27,000 pairwise comparative judgments across 12 dimensions: Big Five personality traits, overall personality score, and six interview performance metrics. To leverage this data, we propose Cross-Modal Regression with Manifold Fusion (CRMF), a geometric deep learning framework that explicitly models behavioral representations across hyperbolic, spherical, and Euclidean manifolds. CRMF employs geometry-specific expert networks to capture hierarchical trait structures, directional behavioral patterns, and continuous performance variations simultaneously. An adaptive routing mechanism dynamically weights expert contributions based on input characteristics. Through principled tangent space fusion, CRMF achieves superior performance while training 40-50% fewer trainable parameters than large multimodal models. Extensive experiments demonstrate that CRMF substantially outperforms the selected baselines, achieving up to 11.4% improvement in Spearman correlation and 6.0% in concordance index. Our RecruitView dataset is publicly available at https://huggingface.co/datasets/AI4A-lab/RecruitView

</details>


### [59] [CausalAffect: Causal Discovery for Facial Affective Understanding](https://arxiv.org/abs/2512.00456)
*Guanyu Hu,Tangzheng Lian,Dimitrios Kollias,Oya Celiktutan,Xinyu Yang*

Main category: cs.CV

TL;DR: CausalAffect 是首个用于面部情感分析的因果图发现框架，通过两级因果层次和反事实干预，无需标注数据或手工先验，即可发现与心理学理论一致的因果结构，并提升AU检测和表情识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法很少直接从数据中推断AU与表情之间的心理合理因果关系，因此需要一种无需联合标注数据或手工因果先验的因果发现框架。

Method: CausalAffect 采用两级极性感知因果层次结构，结合群体级规律和样本自适应结构，通过特征级反事实干预机制抑制虚假相关性。

Result: 在六个基准测试中，CausalAffect 在AU检测和表情识别方面均达到最先进水平，并揭示了新的抑制性和未表征的依赖关系。

Conclusion: CausalAffect 通过两级因果层次结构和特征级反事实干预机制，成功地在面部情感分析中发现了与心理学理论一致的因果结构，同时提升了AU检测和表情识别的性能。

Abstract: Understanding human affect from facial behavior requires not only accurate recognition but also structured reasoning over the latent dependencies that drive muscle activations and their expressive outcomes. Although Action Units (AUs) have long served as the foundation of affective computing, existing approaches rarely address how to infer psychologically plausible causal relations between AUs and expressions directly from data. We propose CausalAffect, the first framework for causal graph discovery in facial affect analysis. CausalAffect models AU-AU and AU-Expression dependencies through a two-level polarity and direction aware causal hierarchy that integrates population-level regularities with sample-adaptive structures. A feature-level counterfactual intervention mechanism further enforces true causal effects while suppressing spurious correlations. Crucially, our approach requires neither jointly annotated datasets nor handcrafted causal priors, yet it recovers causal structures consistent with established psychological theories while revealing novel inhibitory and previously uncharacterized dependencies. Extensive experiments across six benchmarks demonstrate that CausalAffect advances the state of the art in both AU detection and expression recognition, establishing a principled connection between causal discovery and interpretable facial behavior. All trained models and source code will be released upon acceptance.

</details>


### [60] [RealGen: Photorealistic Text-to-Image Generation via Detector-Guided Rewards](https://arxiv.org/abs/2512.00473)
*Junyan Ye,Leiqi Zhu,Yuncheng Guo,Dongzhi Jiang,Zilong Huang,Yifan Zhang,Zhiyuan Yan,Haohuan Fu,Conghui He,Weijia Li*

Main category: cs.CV

TL;DR: RealGen是一个写真文本到图像框架，通过整合LLM和扩散模型，并引入检测器奖励机制，显著提升了图像真实性和细节。


<details>
  <summary>Details</summary>
Motivation: 当前高级图像生成模型在写真图像生成方面仍存在不足，如产生明显AI伪影（如“过度光滑的皮肤”和“油腻的面部光泽”），未能实现“与现实无差别”的生成目标。

Method: RealGen整合了LLM组件用于提示优化和扩散模型用于真实图像生成，并引入“检测器奖励”机制，通过语义级和特征级合成图像检测器量化伪影并评估真实性。

Result: 实验证明RealGen在真实性、细节和美学方面显著优于其他模型。

Conclusion: RealGen显著优于通用模型（如GPT-Image-1和Qwen-Image）以及专用写真模型（如FLUX-Krea），在真实性、细节和美学方面表现突出。

Abstract: With the continuous advancement of image generation technology, advanced models such as GPT-Image-1 and Qwen-Image have achieved remarkable text-to-image consistency and world knowledge However, these models still fall short in photorealistic image generation. Even on simple T2I tasks, they tend to produce " fake" images with distinct AI artifacts, often characterized by "overly smooth skin" and "oily facial sheens". To recapture the original goal of "indistinguishable-from-reality" generation, we propose RealGen, a photorealistic text-to-image framework. RealGen integrates an LLM component for prompt optimization and a diffusion model for realistic image generation. Inspired by adversarial generation, RealGen introduces a "Detector Reward" mechanism, which quantifies artifacts and assesses realism using both semantic-level and feature-level synthetic image detectors. We leverage this reward signal with the GRPO algorithm to optimize the entire generation pipeline, significantly enhancing image realism and detail. Furthermore, we propose RealBench, an automated evaluation benchmark employing Detector-Scoring and Arena-Scoring. It enables human-free photorealism assessment, yielding results that are more accurate and aligned with real user experience. Experiments demonstrate that RealGen significantly outperforms general models like GPT-Image-1 and Qwen-Image, as well as specialized photorealistic models like FLUX-Krea, in terms of realism, detail, and aesthetics. The code is available at https://github.com/yejy53/RealGen.

</details>


### [61] [Structured Context Learning for Generic Event Boundary Detection](https://arxiv.org/abs/2512.00475)
*Xin Gu,Congcong Li,Xinyao Wang,Dexiang Hong,Libo Zhang,Tiejian Luo,Longyin Wen,Heng Fan*

Main category: cs.CV

TL;DR: 提出结构化上下文学习方法（SPoS）用于通用事件边界检测，通过灵活的时间模型和轻量级网络实现高效准确的边界识别。


<details>
  <summary>Details</summary>
Motivation: 解决视频中人类感知的事件边界检测问题，提供更灵活且速度-精度平衡的解决方案。

Method: 提出了结构化序列划分（SPoS）来为学习时间信息提供结构化上下文，并结合轻量级全卷积网络确定事件边界。

Result: 在多个挑战性数据集上验证了方法的优越性。

Conclusion: 该方法在Kinetics-GEBD、TAPOS和镜头转换检测数据集上表现优异，优于现有最先进方法。

Abstract: Generic Event Boundary Detection (GEBD) aims to identify moments in videos that humans perceive as event boundaries. This paper proposes a novel method for addressing this task, called Structured Context Learning, which introduces the Structured Partition of Sequence (SPoS) to provide a structured context for learning temporal information. Our approach is end-to-end trainable and flexible, not restricted to specific temporal models like GRU, LSTM, and Transformers. This flexibility enables our method to achieve a better speed-accuracy trade-off. Specifically, we apply SPoS to partition the input frame sequence and provide a structured context for the subsequent temporal model. Notably, SPoS's overall computational complexity is linear with respect to the video length. We next calculate group similarities to capture differences between frames, and a lightweight fully convolutional network is utilized to determine the event boundaries based on the grouped similarity maps. To remedy the ambiguities of boundary annotations, we adapt the Gaussian kernel to preprocess the ground-truth event boundaries. Our proposed method has been extensively evaluated on the challenging Kinetics-GEBD, TAPOS, and shot transition detection datasets, demonstrating its superiority over existing state-of-the-art methods.

</details>


### [62] [Learning What Helps: Task-Aligned Context Selection for Vision Tasks](https://arxiv.org/abs/2512.00489)
*Jingyu Guo,Emir Konuk,Fredrik Strand,Christos Matsoukas,Kevin Smith*

Main category: cs.CV

TL;DR: TACS通过学习选择真正有助于任务的上下文示例，提升了视觉任务的性能，尤其在数据有限时效果显著。


<details>
  <summary>Details</summary>
Motivation: 解决ViTs在视觉不确定性中无法识别哪些示例能真正提升预测性能的问题。

Method: TACS采用混合优化方案，结合梯度监督和强化学习，使检索成为学习目标的一部分。

Result: 在18个数据集（涵盖细粒度识别、医学图像分类和分割）中，TACS始终优于基于相似性的检索方法。

Conclusion: TACS框架通过联合训练选择器网络和任务模型，显著提升了视觉任务中的上下文示例选择效果，尤其在数据有限或挑战性场景中表现突出。

Abstract: Humans often resolve visual uncertainty by comparing an image with relevant examples, but ViTs lack the ability to identify which examples would improve their predictions. We present Task-Aligned Context Selection (TACS), a framework that learns to select paired examples which truly improve task performance rather than those that merely appear similar. TACS jointly trains a selector network with the task model through a hybrid optimization scheme combining gradient-based supervision and reinforcement learning, making retrieval part of the learning objective. By aligning selection with task rewards, TACS enables discriminative models to discover which contextual examples genuinely help. Across 18 datasets covering fine-grained recognition, medical image classification, and medical image segmentation, TACS consistently outperforms similarity-based retrieval, particularly in challenging or data-limited settings.

</details>


### [63] [CC-FMO: Camera-Conditioned Zero-Shot Single Image to 3D Scene Generation with Foundation Model Orchestration](https://arxiv.org/abs/2512.00493)
*Boshi Tang,Henry Zheng,Rui Huang,Gao Huang*

Main category: cs.CV

TL;DR: CC-FMO 是一种零样本、相机条件化的单图像到3D场景生成方法，通过混合实例生成器和相机条件化尺度求解算法，显著提升了场景生成的质量和一致性。


<details>
  <summary>Details</summary>
Motivation: 高质量的单图像到3D场景生成对AR/VR和具身AI应用至关重要。现有方法因依赖小规模数据集训练的专用模型而泛化能力有限，且场景生成的一致性受限于不准确的物体姿态估计和空间不一致性。

Method: CC-FMO 采用混合实例生成器，结合语义感知的向量集表示和细节丰富的结构化潜在表示，生成既语义合理又高质量的物体几何。此外，通过简单有效的相机条件化尺度求解算法，将基础姿态估计模型应用于场景生成任务，以增强场景级一致性。

Result: 大量实验表明，CC-FMO 能够一致生成高保真、相机对齐的组合场景，性能优于所有现有最先进方法。

Conclusion: CC-FMO 是一种零样本、相机条件化的单图像到3D场景生成管道，能够联合符合输入图像中的对象布局并保持实例保真度，显著提升了场景生成的质量和一致性。

Abstract: High-quality 3D scene generation from a single image is crucial for AR/VR and embodied AI applications. Early approaches struggle to generalize due to reliance on specialized models trained on curated small datasets. While recent advancements in large-scale 3D foundation models have significantly enhanced instance-level generation, coherent scene generation remains a challenge, where performance is limited by inaccurate per-object pose estimations and spatial inconsistency. To this end, this paper introduces CC-FMO, a zero-shot, camera-conditioned pipeline for single-image to 3D scene generation that jointly conforms to the object layout in input image and preserves instance fidelity. CC-FMO employs a hybrid instance generator that combines semantics-aware vector-set representation with detail-rich structured latent representation, yielding object geometries that are both semantically plausible and high-quality. Furthermore, CC-FMO enables the application of foundational pose estimation models in the scene generation task via a simple yet effective camera-conditioned scale-solving algorithm, to enforce scene-level coherence. Extensive experiments demonstrate that CC-FMO consistently generates high-fidelity camera-aligned compositional scenes, outperforming all state-of-the-art methods.

</details>


### [64] [Terrain Sensing with Smartphone Structured Light: 2D Dynamic Time Warping for Grid Pattern Matching](https://arxiv.org/abs/2512.00514)
*Tanaka Nobuaki*

Main category: cs.CV

TL;DR: 该论文提出了一种智能手机结构光系统，通过2D-DTW算法重建地形不平度，解决了低成本机器人在不平地形中的感知问题，并扩展了算法在图像处理中的应用。


<details>
  <summary>Details</summary>
Motivation: 低成本移动机器人在不平地形中运行时，小凹凸或倾斜难以视觉感知，但会显著影响运动稳定性。为解决这一问题，作者探索了一种基于智能手机的结构光系统。

Method: 论文提出了一种拓扑约束的二维动态时间规整（2D-DTW）算法，用于在透视畸变和部分遮挡下鲁棒地匹配投影网格。该方法在资源有限的平台上运行简单，同时保持了网格结构以实现精确三角测量。

Result: 论文展示了2D-DTW算法不仅可用于地形感知，还可作为图像处理中网格模式匹配的通用工具。系统设计简单，适合资源有限的平台。

Conclusion: 该论文提出了一种基于智能手机的结构光系统，通过投影网格图案并利用2D-DTW算法重建地形不平度，解决了低成本移动机器人在不平地形中的感知问题。该方法不仅适用于地形感知，还可作为图像处理中网格模式匹配的通用工具。

Abstract: Low-cost mobile rovers often operate on uneven terrain where small bumps or tilts are difficult to perceive visually but can significantly affect locomotion stability. To address this problem, we explore a smartphone-based structured-light system that projects a grid pattern onto the ground and reconstructs local terrain unevenness from a single handheld device. The system is inspired by face-recognition projectors, but adapted for ground sensing. A key technical challenge is robustly matching the projected grid with its deformed observation under perspective distortion and partial occlusion. Conventional one-dimensional dynamic time warping (1D-DTW) is not directly applicable to such two-dimensional grid patterns. We therefore propose a topology-constrained two-dimensional dynamic time warping (2D-DTW) algorithm that performs column-wise alignment under a global grid consistency constraint. The proposed method is designed to be simple enough to run on resource limited platforms while preserving the grid structure required for accurate triangulation. We demonstrate that our 2D-DTW formulation can be used not only for terrain sensing but also as a general tool for matching structured grid patterns in image processing scenarios. This paper describes the overall system design as well as the 2D-DTW extension that emerged from this application.

</details>


### [65] [Image Generation as a Visual Planner for Robotic Manipulation](https://arxiv.org/abs/2512.00532)
*Ye Pang*

Main category: cs.CV

TL;DR: 预训练图像生成模型通过LoRA微调可作为机器人视觉规划器，生成连贯的操控视频。


<details>
  <summary>Details</summary>
Motivation: 探索预训练图像生成模型是否能在轻量适应后作为机器人视觉规划器，解决现有视频扩散模型泛化能力不足的问题。

Method: 提出一个两部分框架，包括文本条件生成和轨迹条件生成，利用LoRA微调轻量适应。

Result: 在Jaco Play、Bridge V2和RT1数据集上的实验表明，两种模式均能生成平滑、连贯且与条件对齐的机器人视频。

Conclusion: 预训练的图像生成器具有可迁移的时间先验知识，在最小监督下可作为视频类机器人规划器。

Abstract: Generating realistic robotic manipulation videos is an important step toward unifying perception, planning, and action in embodied agents. While existing video diffusion models require large domain-specific datasets and struggle to generalize, recent image generation models trained on language-image corpora exhibit strong compositionality, including the ability to synthesize temporally coherent grid images. This suggests a latent capacity for video-like generation even without explicit temporal modeling.
  We explore whether such models can serve as visual planners for robots when lightly adapted using LoRA finetuning. We propose a two-part framework that includes: (1) text-conditioned generation, which uses a language instruction and the first frame, and (2) trajectory-conditioned generation, which uses a 2D trajectory overlay and the same initial frame. Experiments on the Jaco Play dataset, Bridge V2, and the RT1 dataset show that both modes produce smooth, coherent robot videos aligned with their respective conditions.
  Our findings indicate that pretrained image generators encode transferable temporal priors and can function as video-like robotic planners under minimal supervision. Code is released at \href{https://github.com/pangye202264690373/Image-Generation-as-a-Visual-Planner-for-Robotic-Manipulation}{https://github.com/pangye202264690373/Image-Generation-as-a-Visual-Planner-for-Robotic-Manipulation}.

</details>


### [66] [Cross-Temporal 3D Gaussian Splatting for Sparse-View Guided Scene Update](https://arxiv.org/abs/2512.00534)
*Zeyuan An,Yanghang Xiao,Zhiying Leng,Frederick W. B. Li,Xiaohui Liang*

Main category: cs.CV

TL;DR: 提出了一种基于稀疏图像和历史先验的跨时间3D场景更新框架，通过三阶段优化显著提升了重建效率和质量。


<details>
  <summary>Details</summary>
Motivation: 在稀疏视图观测下更新3D场景对于城市规划、灾害评估和历史遗址保护等实际应用至关重要，但密集扫描往往不可行。

Method: 该方法分为三个阶段：跨时间相机对齐、基于干扰的置信度初始化和渐进式跨时间优化，通过整合历史先验信息提升重建质量。

Result: 实验结果表明，该方法在重建质量和数据效率上均有显著提升。

Conclusion: Cross-Temporal 3DGS 在重建质量和数据效率上显著优于基线方法，为场景版本控制、跨时间数字孪生和长期空间记录提供了有前景的解决方案。

Abstract: Maintaining consistent 3D scene representations over time is a significant challenge in computer vision. Updating 3D scenes from sparse-view observations is crucial for various real-world applications, including urban planning, disaster assessment, and historical site preservation, where dense scans are often unavailable or impractical. In this paper, we propose Cross-Temporal 3D Gaussian Splatting (Cross-Temporal 3DGS), a novel framework for efficiently reconstructing and updating 3D scenes across different time periods, using sparse images and previously captured scene priors. Our approach comprises three stages: 1) Cross-temporal camera alignment for estimating and aligning camera poses across different timestamps; 2) Interference-based confidence initialization to identify unchanged regions between timestamps, thereby guiding updates; and 3) Progressive cross-temporal optimization, which iteratively integrates historical prior information into the 3D scene to enhance reconstruction quality. Our method supports non-continuous capture, enabling not only updates using new sparse views to refine existing scenes, but also recovering past scenes from limited data with the help of current captures. Furthermore, we demonstrate the potential of this approach to achieve temporal changes using only sparse images, which can later be reconstructed into detailed 3D representations as needed. Experimental results show significant improvements over baseline methods in reconstruction quality and data efficiency, making this approach a promising solution for scene versioning, cross-temporal digital twins, and long-term spatial documentation.

</details>


### [67] [SAIDO: Generalizable Detection of AI-Generated Images via Scene-Aware and Importance-Guided Dynamic Optimization in Continual Learning](https://arxiv.org/abs/2512.00539)
*Yongkang Hu,Yu Cheng,Yushuo Zhang,Yuan Xie,Zhaoxia Yin*

Main category: cs.CV

TL;DR: SAIDO框架通过动态场景感知和重要性优化，显著提升AI生成图像检测的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有AI生成图像检测方法在泛化性上的不足，尤其是对新兴生成方法和内容类型的适应性问题。

Method: 提出了一种Scene-Aware and Importance-Guided Dynamic Optimization（SAIDO）检测框架，包括Scene-Awareness-Based Expert Module（SAEM）和Importance-Guided Dynamic Optimization Mechanism（IDOM）。SAEM动态识别并整合新场景，IDOM通过重要性引导的梯度投影策略优化神经元，平衡模型的可塑性和稳定性。

Result: 在持续学习任务中，SAIDO在稳定性和可塑性上均优于当前最优方法，平均检测错误率和遗忘率分别相对降低了44.22%和40.57%。在开放世界数据集上，检测准确率提高了9.47%。

Conclusion: SAIDO框架通过场景感知和重要性引导的动态优化机制，显著提升了AI生成图像检测的泛化能力，减少了检测错误率和遗忘率，并在开放世界数据集上取得了更高的检测准确率。

Abstract: The widespread misuse of image generation technologies has raised security concerns, driving the development of AI-generated image detection methods. However, generalization has become a key challenge and open problem: existing approaches struggle to adapt to emerging generative methods and content types in real-world scenarios. To address this issue, we propose a Scene-Aware and Importance-Guided Dynamic Optimization detection framework with continual learning (SAIDO). Specifically, we design Scene-Awareness-Based Expert Module (SAEM) that dynamically identifies and incorporates new scenes using VLLMs. For each scene, independent expert modules are dynamically allocated, enabling the framework to capture scene-specific forgery features better and enhance cross-scene generalization. To mitigate catastrophic forgetting when learning from multiple image generative methods, we introduce Importance-Guided Dynamic Optimization Mechanism (IDOM), which optimizes each neuron through an importance-guided gradient projection strategy, thereby achieving an effective balance between model plasticity and stability. Extensive experiments on continual learning tasks demonstrate that our method outperforms the current SOTA method in both stability and plasticity, achieving 44.22\% and 40.57\% relative reductions in average detection error rate and forgetting rate, respectively. On open-world datasets, it improves the average detection accuracy by 9.47\% compared to the current SOTA method.

</details>


### [68] [Asset-Driven Sematic Reconstruction of Dynamic Scene with Multi-Human-Object Interactions](https://arxiv.org/abs/2512.00547)
*Sandika Biswas,Qianyi Wu,Biplab Banerjee,Hamid Rezatofighi*

Main category: cs.CV

TL;DR: 提出混合方法结合3D生成模型、语义变形和GS优化，解决多人物多物体动态场景的几何建模问题，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界的人造环境高度动态，涉及多人物和多物体的复杂互动，现有3D几何建模方法难以应对多样运动模式和频繁遮挡的挑战。

Method: 结合1)3D生成模型生成高保真网格，2)语义感知变形（刚性物体的刚体变换和基于LBS的人物变形），3)基于GS的优化以细化场景中的元素对齐。

Result: 在HOI-M3数据集上，该方法在表面重建方面优于现有技术。

Conclusion: 本文提出了一种混合方法，结合了3D生成模型、语义感知变形和基于GS的优化，有效解决了多人物、多物体动态场景下的几何建模挑战，并在HOI-M3数据集上表现优于现有方法。

Abstract: Real-world human-built environments are highly dynamic, involving multiple humans and their complex interactions with surrounding objects. While 3D geometry modeling of such scenes is crucial for applications like AR/VR, gaming, and embodied AI, it remains underexplored due to challenges like diverse motion patterns and frequent occlusions. Beyond novel view rendering, 3D Gaussian Splatting (GS) has demonstrated remarkable progress in producing detailed, high-quality surface geometry with fast optimization of the underlying structure. However, very few GS-based methods address multihuman, multiobject scenarios, primarily due to the above-mentioned inherent challenges. In a monocular setup, these challenges are further amplified, as maintaining structural consistency under severe occlusion becomes difficult when the scene is optimized solely based on GS-based rendering loss. To tackle the challenges of such a multihuman, multiobject dynamic scene, we propose a hybrid approach that effectively combines the advantages of 1) 3D generative models for generating high-fidelity meshes of the scene elements, 2) Semantic-aware deformation, \ie rigid transformation of the rigid objects and LBS-based deformation of the humans, and mapping of the deformed high-fidelity meshes in the dynamic scene, and 3) GS-based optimization of the individual elements for further refining their alignments in the scene. Such a hybrid approach helps maintain the object structures even under severe occlusion and can produce multiview and temporally consistent geometry. We choose HOI-M3 for evaluation, as, to the best of our knowledge, this is the only dataset featuring multihuman, multiobject interactions in a dynamic scene. Our method outperforms the state-of-the-art method in producing better surface reconstruction of such scenes.

</details>


### [69] [NeuroVolve: Evolving Visual Stimuli toward Programmable Neural Objectives](https://arxiv.org/abs/2512.00557)
*Haomiao Chen,Keith W Jamison,Mert R. Sabuncu,Amy Kuceyeski*

Main category: cs.CV

TL;DR: NeuroVolve 是一个大脑引导的图像生成框架，通过优化神经目标函数在视觉语言模型嵌入空间中合成图像，支持单脑区和多脑区约束，揭示了脑区间的协作和对抗关系，并支持个性化合成。


<details>
  <summary>Details</summary>
Motivation: 探索个体脑区编码的视觉信息以及分布式模式如何组合形成神经表征，尤其是在复杂自然视觉中脑区如何相互作用。

Method: 引入 NeuroVolve，这是一个生成框架，通过在预训练的视觉语言模型的嵌入空间中优化神经目标函数，实现大脑引导的图像合成。图像生成受可编程神经目标的指导，例如激活或停用单个或多个脑区。

Result: NeuroVolve 能够恢复已知的单个脑区选择性，并扩展到合成满足复杂多脑区约束的连贯场景。此外，它还能生成低层次和语义特征特定的刺激，以及符合定制神经目标的刺激。

Conclusion: NeuroVolve 提供了一个统一的框架，用于通过优化神经目标函数在预训练的视觉语言模型嵌入空间中进行大脑引导的图像合成，支持个性化的大脑驱动合成，并为视觉信息的神经表征提供了可解释的约束。

Abstract: What visual information is encoded in individual brain regions, and how do distributed patterns combine to create their neural representations? Prior work has used generative models to replicate known category selectivity in isolated regions (e.g., faces in FFA), but these approaches offer limited insight into how regions interact during complex, naturalistic vision. We introduce NeuroVolve, a generative framework that provides brain-guided image synthesis via optimization of a neural objective function in the embedding space of a pretrained vision-language model. Images are generated under the guidance of a programmable neural objective, i.e., activating or deactivating single regions or multiple regions together. NeuroVolve is validated by recovering known selectivity for individual brain regions, while expanding to synthesize coherent scenes that satisfy complex, multi-region constraints. By tracking optimization steps, it reveals semantic trajectories through embedding space, unifying brain-guided image editing and preferred stimulus generation in a single process. We show that NeuroVolve can generate both low-level and semantic feature-specific stimuli for single ROIs, as well as stimuli aligned to curated neural objectives. These include co-activation and decorrelation between regions, exposing cooperative and antagonistic tuning relationships. Notably, the framework captures subject-specific preferences, supporting personalized brain-driven synthesis and offering interpretable constraints for mapping, analyzing, and probing neural representations of visual information.

</details>


### [70] [Describe Anything Anywhere At Any Moment](https://arxiv.org/abs/2512.00565)
*Nicolas Gorlo,Lukas Schmid,Luca Carlone*

Main category: cs.CV

TL;DR: DAAAM是一个实时4D场景理解框架，通过优化前端和层次化场景图，显著提升了时空问答和任务接地的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在实现丰富的开放词汇描述和实时3D接地之间存在权衡。DAAAM旨在解决这一挑战，提供大规模、实时的4D场景理解框架。

Method: DAAAM采用基于优化的前端，利用局部化的描述模型（如DAM）推断详细语义描述，并通过批处理加速推理。它构建了一个层次化的4D场景图（SG），作为全局一致的内存表示。

Result: DAAAM在NaVQA和SG3D基准测试中表现优异，OC-NaVQA问题准确率提升53.6%，位置误差降低21.9%，时间误差降低21.6%，SG3D任务接地准确率提升27.8%。

Conclusion: DAAAM通过其优化的前端和层次化的4D场景图，实现了大规模、实时的4D场景理解，显著提升了时空问答和任务接地的性能，并在多个基准测试中达到了最先进的结果。

Abstract: Computer vision and robotics applications ranging from augmented reality to robot autonomy in large-scale environments require spatio-temporal memory frameworks that capture both geometric structure for accurate language-grounding as well as semantic detail. Existing methods face a tradeoff, where producing rich open-vocabulary descriptions comes at the expense of real-time performance when these descriptions have to be grounded in 3D. To address these challenges, we propose Describe Anything, Anywhere, at Any Moment (DAAAM), a novel spatio-temporal memory framework for large-scale and real-time 4D scene understanding. DAAAM introduces a novel optimization-based frontend to infer detailed semantic descriptions from localized captioning models, such as the Describe Anything Model (DAM), leveraging batch processing to speed up inference by an order of magnitude for online processing. It leverages such semantic understanding to build a hierarchical 4D scene graph (SG), which acts as an effective globally spatially and temporally consistent memory representation. DAAAM constructs 4D SGs with detailed, geometrically grounded descriptions while maintaining real-time performance. We show that DAAAM's 4D SG interfaces well with a tool-calling agent for inference and reasoning.
  We thoroughly evaluate DAAAM in the complex task of spatio-temporal question answering on the NaVQA benchmark and show its generalization capabilities for sequential task grounding on the SG3D benchmark. We further curate an extended OC-NaVQA benchmark for large-scale and long-time evaluations. DAAAM achieves state-of-the-art results in both tasks, improving OC-NaVQA question accuracy by 53.6%, position errors by 21.9%, temporal errors by 21.6%, and SG3D task grounding accuracy by 27.8% over the most competitive baselines, respectively. We release our data and code open-source.

</details>


### [71] [Integrating Skeleton Based Representations for Robust Yoga Pose Classification Using Deep Learning Models](https://arxiv.org/abs/2512.00572)
*Mohammed Mohiuddin,Syed Mohammod Minhaz Hossain,Sumaiya Khanam,Prionkar Barua,Aparup Barua,MD Tamim Hossain*

Main category: cs.CV

TL;DR: 研究引入'Yoga-16'数据集，评估三种深度学习架构和输入模态，发现骨架表示优于原始图像，VGG16+MediaPipe Pose骨架达到96.09%准确率。


<details>
  <summary>Details</summary>
Motivation: 瑜伽因其精神和身体健康益处而广受欢迎，但不正确的姿势可能导致伤害。自动瑜伽姿势分类因此变得重要，以减少对专家从业者的依赖。

Method: 本研究引入了'Yoga-16'数据集，并系统评估了三种深度学习架构（VGG16、ResNet50和Xception）及三种输入模态（直接图像、MediaPipe Pose骨架图像和YOLOv8 Pose骨架图像）。

Result: 实验表明，骨架表示优于原始图像输入，VGG16结合MediaPipe Pose骨架输入达到了96.09%的最高准确率。

Conclusion: 研究表明，基于骨架的表示在瑜伽姿势分类中优于原始图像输入，其中VGG16结合MediaPipe Pose骨架输入达到了96.09%的最高准确率。

Abstract: Yoga is a popular form of exercise worldwide due to its spiritual and physical health benefits, but incorrect postures can lead to injuries. Automated yoga pose classification has therefore gained importance to reduce reliance on expert practitioners. While human pose keypoint extraction models have shown high potential in action recognition, systematic benchmarking for yoga pose recognition remains limited, as prior works often focus solely on raw images or a single pose extraction model. In this study, we introduce a curated dataset, 'Yoga-16', which addresses limitations of existing datasets, and systematically evaluate three deep learning architectures (VGG16, ResNet50, and Xception) using three input modalities (direct images, MediaPipe Pose skeleton images, and YOLOv8 Pose skeleton images). Our experiments demonstrate that skeleton-based representations outperform raw image inputs, with the highest accuracy of 96.09% achieved by VGG16 with MediaPipe Pose skeleton input. Additionally, we provide interpretability analysis using Grad-CAM, offering insights into model decision-making for yoga pose classification with cross validation analysis.

</details>


### [72] [SatireDecoder: Visual Cascaded Decoupling for Enhancing Satirical Image Comprehension](https://arxiv.org/abs/2512.00582)
*Yue Jiang,Haiwei Xue,Minghao Han,Mingcheng Li,Xiaolu Hou,Dingkang Yang,Lihua Zhang,Xu Zheng*

Main category: cs.CV

TL;DR: SatireDecoder通过多智能体系统和思维链推理策略，显著提升视觉讽刺理解的准确性，减少误解。


<details>
  <summary>Details</summary>
Motivation: 尽管讽刺艺术具有重要的社会价值，但当前视觉语言模型在理解纯视觉讽刺时仍面临挑战，现有模型难以有效整合局部实体关系与全局上下文。

Method: 提出SatireDecoder，一种无需训练的框架，通过多智能体系统执行视觉级联解耦，将图像分解为细粒度的局部和全局语义表示，并引入基于不确定性分析的思维链推理策略。

Result: 实验验证SatireDecoder在理解视觉讽刺方面优于现有基线。

Conclusion: SatireDecoder框架显著提升了视觉讽刺理解的准确性，减少了误解和幻觉，为视觉语言推理在复杂语义任务中的应用提供了有前景的方向。

Abstract: Satire, a form of artistic expression combining humor with implicit critique, holds significant social value by illuminating societal issues. Despite its cultural and societal significance, satire comprehension, particularly in purely visual forms, remains a challenging task for current vision-language models. This task requires not only detecting satire but also deciphering its nuanced meaning and identifying the implicated entities. Existing models often fail to effectively integrate local entity relationships with global context, leading to misinterpretation, comprehension biases, and hallucinations. To address these limitations, we propose SatireDecoder, a training-free framework designed to enhance satirical image comprehension. Our approach proposes a multi-agent system performing visual cascaded decoupling to decompose images into fine-grained local and global semantic representations. In addition, we introduce a chain-of-thought reasoning strategy guided by uncertainty analysis, which breaks down the complex satire comprehension process into sequential subtasks with minimized uncertainty. Our method significantly improves interpretive accuracy while reducing hallucinations. Experimental results validate that SatireDecoder outperforms existing baselines in comprehending visual satire, offering a promising direction for vision-language reasoning in nuanced, high-level semantic tasks.

</details>


### [73] [Scaling Down to Scale Up: Towards Operationally-Efficient and Deployable Clinical Models via Cross-Modal Low-Rank Adaptation for Medical Vision-Language Models](https://arxiv.org/abs/2512.00597)
*Thuraya Alzubaidi,Farhad R. Nezami,Muzammil Behzad*

Main category: cs.CV

TL;DR: MedCT-VLM通过LoRA技术高效适配大规模CT基础模型，显著提升零样本病理分类性能。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言预训练的基础模型在多样图像领域展现出强大的零样本能力，但其在体积医学影像中的应用仍有限。

Method: 采用低秩适应（LoRA）技术，仅在视觉和文本编码器的注意力层插入低秩分解矩阵，仅训练1.67M参数（占总参数的0.38%）。

Result: LoRA微调将平均AUROC从61.3%提升至68.9%（+7.6 pp），准确率从67.2%提升至73.6%（+6.4 pp），宏F1从32.1%提升至36.9%（+4.8 pp）。

Conclusion: 参数高效方法（如LoRA）能有效将大规模预训练模型迁移至下游医学影像任务，尤其在零样本场景下表现突出。

Abstract: Foundation models trained via vision-language pretraining have demonstrated strong zero-shot capabilities across diverse image domains, yet their application to volumetric medical imaging remains limited. We introduce MedCT-VLM: Medical CT Vision-Language Model, a parameter-efficient vision-language framework designed to adapt large-scale CT foundation models for downstream clinical tasks. MedCT-VLM uses a parameter-efficient approach to adapt CT-CLIP, a contrastive vision-language model trained on 25,692 chest CT volumes, for multi-label pathology classification using Low-Rank Adaptation (LoRA). Rather than fine-tuning the model's 440 M parameters directly, we insert low-rank decomposition matrices into attention layers of both vision and text encoders, training only 1.67M parameters (0.38\% of total). We evaluate on zero-shot classification across 18 thoracic pathologies, where the model must align CT embeddings with unseen text prompts at inference without task-specific training. LoRA fine-tuning improves mean AUROC from 61.3\% to 68.9\% (+7.6 pp), accuracy from 67.2\% to 73.6\% (+6.4 pp), and macro-F1 from 32.1\% to 36.9\% (+4.8 pp). These results demonstrate that parameter-efficient methods can effectively transfer large-scale pretraining to downstream medical imaging tasks, particularly for zero-shot scenarios where labeled data is scarce.

</details>


### [74] [Automatic Pith Detection in Tree Cross-Section Images Using Deep Learning](https://arxiv.org/abs/2512.00625)
*Tzu-I Liao,Mahmoud Fakhry,Jibin Yesudas Varghese*

Main category: cs.CV

TL;DR: 研究评估了多种深度学习模型在树木横截面髓心检测中的表现，Swin Transformer准确率最高，模型选择需结合实际需求。


<details>
  <summary>Details</summary>
Motivation: 髓心检测对林业和木材质量分析至关重要，但目前仍依赖手动且易出错的方法。

Method: 评估了YOLOv9、U-Net、Swin Transformer、DeepLabV3和Mask R-CNN等深度学习模型，使用582张标注图像并通过动态增强提升泛化能力。

Result: Swin Transformer在精细分割中表现最佳（准确率0.94），YOLOv9适用于边界框检测但边界精度不足，Mask R-CNN通过NMS改进后IoU从0.45提升至0.80。

Conclusion: 深度学习模型在树木横截面髓心检测中展现出潜力，模型选择需根据数据集特性和应用需求。

Abstract: Pith detection in tree cross-sections is essential for forestry and wood quality analysis but remains a manual, error-prone task. This study evaluates deep learning models -- YOLOv9, U-Net, Swin Transformer, DeepLabV3, and Mask R-CNN -- to automate the process efficiently. A dataset of 582 labeled images was dynamically augmented to improve generalization. Swin Transformer achieved the highest accuracy (0.94), excelling in fine segmentation. YOLOv9 performed well for bounding box detection but struggled with boundary precision. U-Net was effective for structured patterns, while DeepLabV3 captured multi-scale features with slight boundary imprecision. Mask R-CNN initially underperformed due to overlapping detections, but applying Non-Maximum Suppression (NMS) improved its IoU from 0.45 to 0.80. Generalizability was next tested using an oak dataset of 11 images from Oregon State University's Tree Ring Lab. Additionally, for exploratory analysis purposes, an additional dataset of 64 labeled tree cross-sections was used to train the worst-performing model to see if this would improve its performance generalizing to the unseen oak dataset. Key challenges included tensor mismatches and boundary inconsistencies, addressed through hyperparameter tuning and augmentation. Our results highlight deep learning's potential for tree cross-section pith detection, with model choice depending on dataset characteristics and application needs.

</details>


### [75] [XAI-Driven Skin Disease Classification: Leveraging GANs to Augment ResNet-50 Performance](https://arxiv.org/abs/2512.00626)
*Kim Gerard A. Villanueva,Priyanka Kumar*

Main category: cs.CV

TL;DR: 该研究提出了一种可信赖且高精度的计算机辅助诊断系统，通过DCGANs解决数据不平衡问题，结合XAI技术提升透明度，取得了优异的分类性能。


<details>
  <summary>Details</summary>
Motivation: 由于主观诊断方法、数据集（如HAM10000）固有的数据不平衡以及深度学习模型的“黑盒”特性，多类皮肤病变的准确及时诊断受到阻碍。

Method: 采用深度卷积生成对抗网络（DCGANs）进行每类数据增强以解决类别不平衡问题，随后在增强数据集上训练微调的ResNet-50分类器，并结合LIME和SHAP可解释AI技术提供透明度。

Result: 系统实现了92.50%的整体准确率和98.82%的宏AUC，成功超越了多种先前的基准架构。

Conclusion: 该研究成功验证了一个可验证的框架，结合了高性能与临床可解释性，为安全诊断部署提供了基础。未来研究应优先提升对关键类别（如黑色素瘤NOS）的区分能力。

Abstract: Accurate and timely diagnosis of multi-class skin lesions is hampered by subjective methods, inherent data imbalance in datasets like HAM10000, and the "black box" nature of Deep Learning (DL) models. This study proposes a trustworthy and highly accurate Computer-Aided Diagnosis (CAD) system to overcome these limitations. The approach utilizes Deep Convolutional Generative Adversarial Networks (DCGANs) for per class data augmentation to resolve the critical class imbalance problem. A fine-tuned ResNet-50 classifier is then trained on the augmented dataset to classify seven skin disease categories. Crucially, LIME and SHAP Explainable AI (XAI) techniques are integrated to provide transparency by confirming that predictions are based on clinically relevant features like irregular morphology. The system achieved a high overall Accuracy of 92.50 % and a Macro-AUC of 98.82 %, successfully outperforming various prior benchmarked architectures. This work successfully validates a verifiable framework that combines high performance with the essential clinical interpretability required for safe diagnostic deployment. Future research should prioritize enhancing discrimination for critical categories, such as Melanoma NOS (F1-Score is 0.8602).

</details>


### [76] [Doppler-Enhanced Deep Learning: Improving Thyroid Nodule Segmentation with YOLOv5 Instance Segmentation](https://arxiv.org/abs/2512.00639)
*Mahmoud El Hussieni*

Main category: cs.CV

TL;DR: YOLOv5算法在多普勒图像辅助下，显著提升甲状腺结节分割性能，YOLOv5-Large表现最佳，dice分数91%。


<details>
  <summary>Details</summary>
Motivation: 甲状腺癌全球发病率上升，准确分割甲状腺结节是开发AI辅助临床决策支持系统的关键步骤。

Method: 研究采用YOLOv5算法的多个变体（Nano、Small、Medium、Large和XLarge），在包含和不包含多普勒图像的两种数据集版本上进行评估。

Result: YOLOv5-Large算法在包含多普勒图像的数据集上表现最佳，dice分数为91%，mAP为0.87。多普勒图像的加入显著提升了所有模型变体的性能。

Conclusion: YOLOv5算法在甲状腺结节实例分割中表现出色，尤其是结合多普勒图像时性能显著提升，为自动化诊断系统提供了潜在的临床应用。

Abstract: The increasing prevalence of thyroid cancer globally has led to the development of various computer-aided detection methods. Accurate segmentation of thyroid nodules is a critical first step in the development of AI-assisted clinical decision support systems. This study focuses on instance segmentation of thyroid nodules using YOLOv5 algorithms on ultrasound images. We evaluated multiple YOLOv5 variants (Nano, Small, Medium, Large, and XLarge) across two dataset versions, with and without doppler images. The YOLOv5-Large algorithm achieved the highest performance with a dice score of 91\% and mAP of 0.87 on the dataset including doppler images. Notably, our results demonstrate that doppler images, typically excluded by physicians, can significantly improve segmentation performance. The YOLOv5-Small model achieved 79\% dice score when doppler images were excluded, while including them improved performance across all model variants. These findings suggest that instance segmentation with YOLOv5 provides an effective real-time approach for thyroid nodule detection, with potential clinical applications in automated diagnostic systems.

</details>


### [77] [Graph-Attention Network with Adversarial Domain Alignment for Robust Cross-Domain Facial Expression Recognition](https://arxiv.org/abs/2512.00641)
*Razieh Ghaedi,AmirReza BabaAhmadi,Reyer Zwiggelaar,Xinqi Fan,Nashid Alam*

Main category: cs.CV

TL;DR: GAT-ADA通过图注意力网络和对抗域对齐，显著提升了跨域面部表情识别的准确率，特别是在RAF-DB到FER2013的任务中表现突出。


<details>
  <summary>Details</summary>
Motivation: 跨域面部表情识别（CD-FER）由于训练和部署数据之间的严重域偏移而面临挑战，需要一种有效的方法来建模样本间关系并对齐分布。

Method: 提出了一种混合框架GAT-ADA，结合了ResNet-50作为主干网络和批级图注意力网络（GAT）来建模域偏移下的样本间关系，同时采用梯度反转层（GRL）进行对抗学习，以及CORAL和MMD进行统计对齐。

Result: GAT-ADA在标准无监督域适应协议下，平均跨域准确率达到74.39%，在RAF-DB到FER2013的任务中准确率高达98.0%，比基线方法提升了约36个百分点。

Conclusion: GAT-ADA框架通过结合图注意力网络和对抗域对齐，显著提升了跨域面部表情识别的性能，特别是在RAF-DB到FER2013的迁移任务中达到了98.0%的准确率。

Abstract: Cross-domain facial expression recognition (CD-FER) remains difficult due to severe domain shift between training and deployment data. We propose Graph-Attention Network with Adversarial Domain Alignment (GAT-ADA), a hybrid framework that couples a ResNet-50 as backbone with a batch-level Graph Attention Network (GAT) to model inter-sample relations under shift. Each mini-batch is cast as a sparse ring graph so that attention aggregates cross-sample cues that are informative for adaptation. To align distributions, GAT-ADA combines adversarial learning via a Gradient Reversal Layer (GRL) with statistical alignment using CORAL and MMD. GAT-ADA is evaluated under a standard unsupervised domain adaptation protocol: training on one labeled source (RAF-DB) and adapting to multiple unlabeled targets (CK+, JAFFE, SFEW 2.0, FER2013, and ExpW). GAT-ADA attains 74.39% mean cross-domain accuracy. On RAF-DB to FER2013, it reaches 98.0% accuracy, corresponding to approximately a 36-point improvement over the best baseline we re-implemented with the same backbone and preprocessing.

</details>


### [78] [MambaScope: Coarse-to-Fine Scoping for Efficient Vision Mamba](https://arxiv.org/abs/2512.00647)
*Shanhui Liu,Rui Xu,Yunke Wang*

Main category: cs.CV

TL;DR: CF-ViM是一种自适应框架，通过动态调整分辨率实现高效视觉处理，简单图像用粗粒度处理，复杂图像局部细化，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有令牌缩减方法（如令牌剪枝或合并）会导致信息丢失，且对所有图像统一应用时问题加剧。观察到并非所有输入都需要细粒度处理，简单图像可在粗分辨率下有效处理，而复杂图像才需要细化。

Method: 提出了一种名为CF-ViM的自适应框架，首先通过将输入图像划分为大块进行粗粒度推理，显著减少令牌长度和计算量；当模型预测置信度较低时，选择区域以更精细的分辨率重新处理以恢复关键视觉细节。

Result: 在ImageNet上的实验表明，CF-ViM在准确性和效率上均优于基线Vision Mamba和其他先进的令牌缩减技术。

Conclusion: CF-ViM通过动态分辨率分配策略，根据图像复杂度自适应分配计算资源，在不损失关键视觉信息的前提下实现了高效处理，在ImageNet上的实验表明其优于基线Vision Mamba和其他先进的令牌缩减技术。

Abstract: Vision Mamba has emerged as a promising and efficient alternative to Vision Transformers, yet its efficiency remains fundamentally constrained by the number of input tokens. Existing token reduction approaches typically adopt token pruning or merging to reduce computation. However, they inherently lead to information loss, as they discard or compress token representations. This problem is exacerbated when applied uniformly to fine-grained token representations across all images, regardless of visual complexity. We observe that not all inputs require fine-grained processing. Simple images can be effectively handled at coarse resolution, while only complex ones may warrant refinement. Based on this insight, we propose \textit{Coarse-to-Fine Vision Mamba (CF-ViM)}, an adaptive framework for efficient inference. CF-ViM first performs coarse-grained inference by dividing the input image into large patches, significantly reducing the token length and computation. When the model's prediction confidence is low, selected regions are re-processed at a finer resolution to recover critical visual details with minimal additional cost. This dynamic resolution assignment strategy allows CF-ViM to allocate computation adaptively according to image complexity, ensuring efficient processing without compromising essential visual information. Experiments on ImageNet demonstrate that CF-ViM outperforms both the baseline Vision Mamba and state-of-the-art token reduction techniques in terms of accuracy and efficiency.

</details>


### [79] [Realistic Handwritten Multi-Digit Writer (MDW) Number Recognition Challenges](https://arxiv.org/abs/2512.00676)
*Kiri L. Wagstaff*

Main category: cs.CV

TL;DR: 研究创建了多数字书写者（MDW）基准数据集，发现分类器在孤立数字上表现良好但在多数字识别上不佳，需进一步进展以解决实际问题。


<details>
  <summary>Details</summary>
Motivation: 现实场景中数字常以多位形式出现，且由同一人书写，如邮政编码、手写支票金额和预约时间等。现有分类器在孤立数字上表现良好，但在多数字识别上表现不佳。

Method: 利用NIST数字图像中关于书写者的知识，创建了更真实的多数字书写者（MDW）基准数据集。

Result: 分类器在孤立数字上表现良好，但在多数字识别上表现不佳。MDW基准提供了更贴近现实影响的性能指标，并为开发能利用任务特定知识的方法创造了机会。

Conclusion: 为了真正解决现实中的数字识别问题，需要进一步的进展。MDW基准提供了与任务相关的性能指标，这些指标超越了典型的错误计算，更贴近现实世界的影响。

Abstract: Isolated digit classification has served as a motivating problem for decades of machine learning research. In real settings, numbers often occur as multiple digits, all written by the same person. Examples include ZIP Codes, handwritten check amounts, and appointment times. In this work, we leverage knowledge about the writers of NIST digit images to create more realistic benchmark multi-digit writer (MDW) data sets. As expected, we find that classifiers may perform well on isolated digits yet do poorly on multi-digit number recognition. If we want to solve real number recognition problems, additional advances are needed. The MDW benchmarks come with task-specific performance metrics that go beyond typical error calculations to more closely align with real-world impact. They also create opportunities to develop methods that can leverage task-specific knowledge to improve performance well beyond that of individual digit classification methods.

</details>


### [80] [Dynamic-eDiTor: Training-Free Text-Driven 4D Scene Editing with Multimodal Diffusion Transformer](https://arxiv.org/abs/2512.00677)
*Dong In Lee,Hyungjun Doh,Seunggeun Chi,Runlin Duan,Sangpil Kim,Karthik Ramani*

Main category: cs.CV

TL;DR: Dynamic-eDiTor是一个无需训练的文本驱动4D编辑框架，结合MM-DiT和4DGS，通过STGA和CTP实现局部和全局一致性，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有2D扩散模型在独立编辑帧时导致的多视角和时间不一致性问题，如运动失真、几何漂移和不完整编辑。

Method: 采用Spatio-Temporal Sub-Grid Attention（STGA）实现局部一致的跨视图和时间融合，以及Context Token Propagation（CTP）通过令牌继承和光流引导的令牌替换进行全局传播。

Result: 在DyNeRF数据集上的实验表明，Dynamic-eDiTor在编辑保真度和时空一致性上优于现有方法。

Conclusion: Dynamic-eDiTor通过结合MM-DiT和4DGS，实现了无需训练的文本驱动4D场景编辑，显著提升了编辑的保真度和时空一致性。

Abstract: Recent progress in 4D representations, such as Dynamic NeRF and 4D Gaussian Splatting (4DGS), has enabled dynamic 4D scene reconstruction. However, text-driven 4D scene editing remains under-explored due to the challenge of ensuring both multi-view and temporal consistency across space and time during editing. Existing studies rely on 2D diffusion models that edit frames independently, often causing motion distortion, geometric drift, and incomplete editing. We introduce Dynamic-eDiTor, a training-free text-driven 4D editing framework leveraging Multimodal Diffusion Transformer (MM-DiT) and 4DGS. This mechanism consists of Spatio-Temporal Sub-Grid Attention (STGA) for locally consistent cross-view and temporal fusion, and Context Token Propagation (CTP) for global propagation via token inheritance and optical-flow-guided token replacement. Together, these components allow Dynamic-eDiTor to perform seamless, globally consistent multi-view video without additional training and directly optimize pre-trained source 4DGS. Extensive experiments on multi-view video dataset DyNeRF demonstrate that our method achieves superior editing fidelity and both multi-view and temporal consistency prior approaches. Project page for results and code: https://di-lee.github.io/dynamic-eDiTor/

</details>


### [81] [Silhouette-based Gait Foundation Model](https://arxiv.org/abs/2512.00691)
*Dingqiang Ye,Chao Fan,Kartik Narayan,Bingzhe Wu,Chengwen Luo,Jianqiang Li,Vishal M. Patel*

Main category: cs.CV

TL;DR: FoundationGait是一个创新的步态理解框架，解决了模型的扩展性和泛化性问题，并在多个任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 步态模式在人类识别和医疗分析中至关重要，但现有模型因规模小且设计狭窄而受限。

Method: 引入了FoundationGait框架，通过自监督预训练解决步态模型的扩展性和泛化性问题。

Result: 在多种步态数据集、条件和任务中表现稳健，尤其在Gait3D和OU-MVLP数据集上取得了显著成绩。

Conclusion: FoundationGait 是一个可扩展、自监督的步态理解预训练框架，其最大版本拥有近0.13亿参数，并在12个公共步态数据集上预训练，表现出色。

Abstract: Gait patterns play a critical role in human identification and healthcare analytics, yet current progress remains constrained by small, narrowly designed models that fail to scale or generalize. Building a unified gait foundation model requires addressing two longstanding barriers: (a) Scalability. Why have gait models historically failed to follow scaling laws? (b) Generalization. Can one model serve the diverse gait tasks that have traditionally been studied in isolation? We introduce FoundationGait, the first scalable, self-supervised pretraining framework for gait understanding. Its largest version has nearly 0.13 billion parameters and is pretrained on 12 public gait datasets comprising over 2 million walking sequences. Extensive experiments demonstrate that FoundationGait, with or without fine-tuning, performs robustly across a wide spectrum of gait datasets, conditions, tasks (e.g., human identification, scoliosis screening, depression prediction, and attribute estimation), and even input modality. Notably, it achieves 48.0% zero-shot rank-1 accuracy on the challenging in-the-wild Gait3D dataset (1,000 test subjects) and 64.5% on the largest in-the-lab OU-MVLP dataset (5,000+ test subjects), setting a new milestone in robust gait recognition. Coming code and model: https://github.com/ShiqiYu/OpenGait.

</details>


### [82] [Affordance-First Decomposition for Continual Learning in Video-Language Understanding](https://arxiv.org/abs/2512.00694)
*Mengzhu Xu,Hanzhi Liu,Ningkang Peng,Qianyu Chen,Canran Xiao*

Main category: cs.CV

TL;DR: AFD通过明确分割稳定基底与适应部分，在视频-语言持续学习中实现高性能和低遗忘。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在持续学习中模糊稳定与适应、依赖静态路由/容量或需要回放过去视频的问题，明确指定稳定性和可塑性在现实内存和隐私约束下的应用位置。

Method: AFD将视频映射到缓慢变化的affordance tokens，形成一个共享的、时间对齐的基底，同时通过轻量级的、查询路由的、冲突感知的调度器集中适应，并在需要时扩展容量。基底通过弱对齐和教师一致性稳定，训练使用仅问题回放。

Result: AFD在多个协议上达到最先进水平：在域增量VideoQA上平均准确率51.6%，遗忘率-1.8%；ViLCo R@1@0.5为29.6%（MQ）和20.7%（NLQ），18.4% stAP@0.25（VQ）；时间增量iVQA上准确率39.5%，遗忘率-1.6%。

Conclusion: AFD提供了一种明确且可解释的方法，将稳定的交互中心基底与有针对性的适应分开，实现了在视频-语言理解中的持续学习。

Abstract: Continual learning for video--language understanding is increasingly important as models face non-stationary data, domains, and query styles, yet prevailing solutions blur what should stay stable versus what should adapt, rely on static routing/capacity, or require replaying past videos. We aim to explicitly specify where stability lives and where plasticity should be focused under realistic memory and privacy constraints. We introduce Affordance-First Decomposition (AFD): videos are mapped to slowly varying affordance tokens that form a shared, time-aligned substrate, while a lightweight, query-routed, conflict-aware scheduler concentrates adaptation and grows capacity only when needed. The substrate is stabilized via weak alignment and teacher consistency, and training uses question-only replay. AFD achieves state-of-the-art across protocols: 51.6% average accuracy with -1.8% forgetting on domain-incremental VideoQA, ViLCo R@1@0.5 of 29.6% (MQ) and 20.7% (NLQ) with 18.4% stAP@0.25 (VQ), and 39.5% accuracy with -1.6% forgetting on time-incremental iVQA. Overall, AFD offers an explicit, interpretable split between a stable interaction-centered substrate and targeted adaptation.

</details>


### [83] [CAR-Net: A Cascade Refinement Network for Rotational Motion Deblurring under Angle Information Uncertainty](https://arxiv.org/abs/2512.00700)
*Ka Chung Lai,Ahmet Cetinkaya*

Main category: cs.CV

TL;DR: CAR-net是一种用于旋转运动模糊图像去模糊的级联细化网络，特别适用于半盲场景，通过逐步细化显著提升图像质量。


<details>
  <summary>Details</summary>
Motivation: 针对旋转运动模糊图像的去模糊问题，特别是在半盲场景下（仅有模糊角度的噪声信息可用），提出了一种新的解决方案。

Method: 采用频率域反演获取初始去模糊图像，随后通过一系列细化阶段逐步修正残差，减少伪影并恢复细节；架构包含可选的端到端训练角度检测模块。

Result: 实验证明CAR-net在合成和真实图像上均表现出高效的去模糊能力，代码和模型已开源。

Conclusion: CAR-net通过级联细化网络有效解决了旋转运动模糊图像的去模糊问题，尤其在半盲场景下表现优异，且支持端到端训练。

Abstract: We propose a new neural network architecture called CAR-net (CAscade Refinement Network) to deblur images that are subject to rotational motion blur. Our architecture is specifically designed for the semi-blind scenarios where only noisy information of the rotational motion blur angle is available. The core of our approach is progressive refinement process that starts with an initial deblurred estimate obtained from frequency-domain inversion; A series of refinement stages take the current deblurred image to predict and apply residual correction to the current estimate, progressively suppressing artifacts and restoring fine details. To handle parameter uncertainty, our architecture accommodates an optional angle detection module which can be trained end-to-end with refinement modules. We provide a detailed description of our architecture and illustrate its efficiency through experiments using both synthetic and real-life images. Our code and model as well as the links to the datasets are available at https://github.com/tony123105/CAR-Net

</details>


### [84] [Optimizing LVLMs with On-Policy Data for Effective Hallucination Mitigation](https://arxiv.org/abs/2512.00706)
*Chengzhi Yu,Yifan Xu,Yifan Chen,Wenyi Zhang*

Main category: cs.CV

TL;DR: 提出新方法降低LVLM幻觉率，通过二元注释分类器和动态DPO算法，显著提升性能并超越GPT-4V。


<details>
  <summary>Details</summary>
Motivation: 现有注释方法在训练样本中引入额外幻觉，可能增强模型的幻觉模式，因此需要更高效可靠的偏好注释方法。

Method: 提出了一种基于二元注释的幻觉分类器，并设计了动态样本重加权的迭代DPO算法。

Result: 在MMHalBench上将LLaVA-1.5-7B的幻觉率降低50.8%，在Object HalBench上平均降低79.5%，LLaVA-1.5-13B性能超越GPT-4V。

Conclusion: 提出的方法显著降低了LVLM的幻觉率，并在多个基准测试中超越了现有技术，甚至使开源模型性能超越GPT-4V。

Abstract: Recently, large vision-language models (LVLMs) have risen to be a promising approach for multimodal tasks. However, principled hallucination mitigation remains a critical challenge.In this work, we first analyze the data generation process in LVLM hallucination mitigation and affirm that on-policy data significantly outperforms off-policy data, which thus calls for efficient and reliable preference annotation of on-policy data. We then point out that, existing annotation methods introduce additional hallucination in training samples, which may enhance the model's hallucination patterns, to address this problem, we propose training a hallucination classifier giving binary annotations, which guarantee clean chosen samples for the subsequent alignment. To further harness of the power of on-policy data, we design a robust iterative direct preference optimization (DPO) algorithm adopting a dynamic sample reweighting scheme. We conduct comprehensive experiments on three benchmarks with comparison to 8 state-of-the-art baselines. In particular, our approach reduces the hallucination rate of LLaVA-1.5-7B on MMHalBench by 50.8% and the average hallucination rate on Object HalBench by 79.5%; more significantly, our method fully taps into the potential of open-source models, enabling LLaVA-1.5-13B to even surpass the performance of GPT-4V.

</details>


### [85] [Deep Learning-Based Computer Vision Models for Early Cancer Detection Using Multimodal Medical Imaging and Radiogenomic Integration Frameworks](https://arxiv.org/abs/2512.00714)
*Emmanuella Avwerosuoghene Oghenekaro*

Main category: cs.CV

TL;DR: 深度学习在多模态医学影像分析中表现出色，结合放射基因组学为癌症早期检测和个性化治疗提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 早期癌症检测对提高生存率至关重要，传统放射学评估难以识别细微组织异常，需要更高效的方法。

Method: 采用卷积神经网络（CNNs）、变换器和混合注意力架构等深度学习模型，从MRI、CT、PET等多模态影像数据中自动提取复杂特征。

Result: 深度学习模型能够识别人眼不可见的肿瘤微环境变化，结合放射基因组学可预测肿瘤基因型和治疗反应。

Conclusion: 人工智能，特别是深度学习，在医学影像分析中的进步为早期癌症检测提供了革命性的工具，通过非侵入性方法显著提升了诊断准确性。

Abstract: Early cancer detection remains one of the most critical challenges in modern healthcare, where delayed diagnosis significantly reduces survival outcomes. Recent advancements in artificial intelligence, particularly deep learning, have enabled transformative progress in medical imaging analysis. Deep learning-based computer vision models, such as convolutional neural networks (CNNs), transformers, and hybrid attention architectures, can automatically extract complex spatial, morphological, and temporal patterns from multimodal imaging data including MRI, CT, PET, mammography, histopathology, and ultrasound. These models surpass traditional radiological assessment by identifying subtle tissue abnormalities and tumor microenvironment variations invisible to the human eye. At a broader scale, the integration of multimodal imaging with radiogenomics linking quantitative imaging features with genomics, transcriptomics, and epigenetic biomarkers has introduced a new paradigm for personalized oncology. This radiogenomic fusion allows the prediction of tumor genotype, immune response, molecular subtypes, and treatment resistance without invasive biopsies.

</details>


### [86] [TrajDiff: End-to-end Autonomous Driving without Perception Annotation](https://arxiv.org/abs/2512.00723)
*Xingtai Gui,Jianbo Zhao,Wencheng Han,Jikai Wang,Jiahao Gong,Feiyang Tan,Cheng-zhong Xu,Jianbing Shen*

Main category: cs.CV

TL;DR: TrajDiff是一种无需感知标注的端到端自动驾驶框架，通过轨迹导向BEV扩散方法生成轨迹，性能优异且支持数据扩展。


<details>
  <summary>Details</summary>
Motivation: 由于手动感知标注成本高昂，开发无需感知标注的规划范式变得至关重要。

Method: 提出了TrajDiff框架，包括轨迹导向BEV编码器和轨迹导向BEV扩散Transformer（TB-DiT），无需感知监督即可生成多样且合理的轨迹。

Result: 在NAVSIM基准测试中，TrajDiff达到了87.5 PDMS，数据扩展后提升至88.5 PDMS，表现与先进的基于感知方法相当。

Conclusion: TrajDiff通过创新的轨迹导向BEV条件扩散框架，在无需感知标注的情况下实现了端到端自动驾驶的先进性能，且通过数据扩展进一步提升了表现，与基于感知的方法相媲美。

Abstract: End-to-end autonomous driving systems directly generate driving policies from raw sensor inputs. While these systems can extract effective environmental features for planning, relying on auxiliary perception tasks, developing perception annotation-free planning paradigms has become increasingly critical due to the high cost of manual perception annotation. In this work, we propose TrajDiff, a Trajectory-oriented BEV Conditioned Diffusion framework that establishes a fully perception annotation-free generative method for end-to-end autonomous driving. TrajDiff requires only raw sensor inputs and future trajectory, constructing Gaussian BEV heatmap targets that inherently capture driving modalities. We design a simple yet effective trajectory-oriented BEV encoder to extract the TrajBEV feature without perceptual supervision. Furthermore, we introduce Trajectory-oriented BEV Diffusion Transformer (TB-DiT), which leverages ego-state information and the predicted TrajBEV features to directly generate diverse yet plausible trajectories, eliminating the need for handcrafted motion priors. Beyond architectural innovations, TrajDiff enables exploration of data scaling benefits in the annotation-free setting. Evaluated on the NAVSIM benchmark, TrajDiff achieves 87.5 PDMS, establishing state-of-the-art performance among all annotation-free methods. With data scaling, it further improves to 88.5 PDMS, which is comparable to advanced perception-based approaches. Our code and model will be made publicly available.

</details>


### [87] [RS-ISRefiner: Towards Better Adapting Vision Foundation Models for Interactive Segmentation of Remote Sensing Images](https://arxiv.org/abs/2512.00718)
*Deliang Wang,Peng Liu*

Main category: cs.CV

TL;DR: RS-ISRefiner是一种针对遥感图像的交互式分割框架，通过适配器调优和混合注意力机制提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有交互式图像分割方法在遥感图像中因数据有限和计算开销大而难以泛化的问题。

Method: 提出RS-ISRefiner框架，结合适配器调优策略和混合注意力机制，改进概率图调制方案。

Result: 在六个遥感数据集上，RS-ISRefiner在分割精度、效率和交互成本上均优于现有方法。

Conclusion: RS-ISRefiner在遥感图像分割中表现出色，验证了其有效性和泛化能力，适用于实际应用场景。

Abstract: Interactive image segmentation(IIS) plays a critical role in generating precise annotations for remote sensing imagery, where objects often exhibit scale variations, irregular boundaries and complex backgrounds. However, existing IIS methods, primarily designed for natural images, struggle to generalize to remote sensing domains due to limited annotated data and computational overhead. To address these challenges, we proposed RS-ISRefiner, a novel click-based IIS framework tailored for remote sensing images. The framework employs an adapter-based tuning strategy that preserves the general representations of Vision Foundation Models while enabling efficient learning of remote sensing-specific spatial and boundary characteristics. A hybrid attention mechanism integrating convolutional local modeling with Transformer-based global reasoning enhances robustness against scale diversity and scene complexity. Furthermore, an improved probability map modulation scheme effectively incorporates historical user interactions, yielding more stable iterative refinement and higher boundary fidelity. Comprehensive experiments on six remote sensing datasets, including iSAID, ISPRS Potsdam, SandBar, NWPU, LoveDA Urban and WHUBuilding, demonstrate that RS-ISRefiner consistently outperforms state-of-the-art IIS methods in terms of segmentation accuracy, efficiency and interaction cost. These results confirm the effectiveness and generalizability of our framework, making it highly suitable for high-quality instance segmentation in practical remote sensing scenarios.

</details>


### [88] [SwiftVLA: Unlocking Spatiotemporal Dynamics for Lightweight VLA Models at Minimal Overhead](https://arxiv.org/abs/2512.00903)
*Chaojun Ni,Cheng Chen,Xiaofeng Wang,Zheng Zhu,Wenzhao Zheng,Boyuan Wang,Tianrun Chen,Guosheng Zhao,Haoyun Li,Zhehao Dong,Qiang Zhang,Yun Ye,Yang Wang,Guan Huang,Wenjun Mei*

Main category: cs.CV

TL;DR: SwiftVLA通过4D特征提取和融合令牌设计，解决了轻量级VLA模型的时空推理缺陷，实现了高效且高性能的动作生成。


<details>
  <summary>Details</summary>
Motivation: 现有轻量级VLA模型因参数限制牺牲了时空推理能力，而依赖大型VLM融合3D/2D输入的方法仍缺乏时间理解能力，SwiftVLA旨在解决这一问题。

Method: SwiftVLA采用预训练的4D视觉几何变换器和时间缓存提取4D特征，引入融合令牌生成统一表示，并通过掩码重构策略训练模型学习有效4D表示。

Result: 实验表明，SwiftVLA在真实和模拟环境中均优于轻量级基线，性能媲美体积大7倍的VLA模型，在边缘设备上速度快18倍且内存占用减少12倍。

Conclusion: SwiftVLA通过创新的4D视觉几何变换器和融合令牌设计，显著提升了轻量级VLA模型的性能，使其在边缘设备上实现高效运行，同时保持与大型模型相媲美的性能。

Abstract: Vision-Language-Action (VLA) models built on pretrained Vision-Language Models (VLMs) show strong potential but are limited in practicality due to their large parameter counts. To mitigate this issue, using a lightweight VLM has been explored, but it compromises spatiotemporal reasoning. Although some methods suggest that incorporating additional 3D inputs can help, they usually rely on large VLMs to fuse 3D and 2D inputs and still lack temporal understanding. Therefore, we propose SwiftVLA, an architecture that enhances a compact model with 4D understanding while preserving design efficiency. Specifically, our approach features a pretrained 4D visual geometry transformer with a temporal cache that extracts 4D features from 2D images. Then, to enhance the VLM's ability to exploit both 2D images and 4D features, we introduce Fusion Tokens, a set of learnable tokens trained with a future prediction objective to generate unified representations for action generation. Finally, we introduce a mask-and-reconstruct strategy that masks 4D inputs to the VLM and trains the VLA to reconstruct them, enabling the VLM to learn effective 4D representations and allowing the 4D branch to be dropped at inference with minimal performance loss. Experiments in real and simulated environments show that SwiftVLA outperforms lightweight baselines and rivals VLAs up to 7 times larger, achieving comparable performance on edge devices while being 18 times faster and reducing memory footprint by 12 times.

</details>


### [89] [MM-ACT: Learn from Multimodal Parallel Generation to Act](https://arxiv.org/abs/2512.00975)
*Haotian Liang,Xinyi Chen,Bin Wang,Mingkang Chen,Yitian Liu,Yuhao Zhang,Zanxin Chen,Tianshuo Yang,Yilun Chen,Jiangmiao Pang,Dong Liu,Xiaokang Yang,Yao Mu,Wenqi Shao,Ping Luo*

Main category: cs.CV

TL;DR: MM-ACT是一个统一的视觉-语言-动作模型，通过跨模态学习提升机器人任务表现，实验显示其在仿真和真实环境中均表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了解决通用机器人策略需要语义理解和预测能力的双重挑战，提出统一的视觉-语言-动作模型。

Method: MM-ACT采用重掩码并行解码策略生成文本和图像，并采用一步并行解码策略生成动作，结合Context-Shared Multimodal Learning统一训练范式。

Result: 在LIBERO仿真中成功率达96.3%，真实Franka机器人三个任务中达72.0%，RoboTwin2.0八个双手任务中达52.38%，跨模态学习带来额外9.25%提升。

Conclusion: MM-ACT通过统一的视觉-语言-动作模型和跨模态学习策略，显著提升了机器人在不同任务和场景下的性能表现。

Abstract: A generalist robotic policy needs both semantic understanding for task planning and the ability to interact with the environment through predictive capabilities. To tackle this, we present MM-ACT, a unified Vision-Language-Action (VLA) model that integrates text, image, and action in shared token space and performs generation across all three modalities. MM-ACT adopts a re-mask parallel decoding strategy for text and image generation, and employs a one-step parallel decoding strategy for action generation to improve efficiency. We introduce Context-Shared Multimodal Learning, a unified training paradigm that supervises generation in all three modalities from a shared context, enhancing action generation through cross-modal learning. Experiments were conducted on the LIBERO simulation and Franka real-robot setups as well as RoboTwin2.0 to assess in-domain and out-of-domain performances respectively. Our approach achieves a success rate of 96.3% on LIBERO, 72.0% across three tasks of real Franka, and 52.38% across eight bimanual tasks of RoboTwin2.0 with an additional gain of 9.25% from cross-modal learning. We release our codes, models and data at https://github.com/HHYHRHY/MM-ACT.

</details>


### [90] [Multi-GRPO: Multi-Group Advantage Estimation for Text-to-Image Generation with Tree-Based Trajectories and Multiple Rewards](https://arxiv.org/abs/2512.00743)
*Qiang Lyu,Zicong Chen,Chongxiao Wang,Haolin Shi,Shibo Gao,Ran Piao,Youwei Zeng,Jianlou Si,Fei Ding,Jing Li,Chun Pong Lau,Weiqiang Wang*

Main category: cs.CV

TL;DR: Multi-GRPO通过多组优势估计框架改进GRPO，解决了信用分配和奖励混合问题，提升了文本到图像模型的对齐性能。


<details>
  <summary>Details</summary>
Motivation: 现有GRPO方法存在共享信用分配和奖励混合问题，导致早期去噪步骤潜力评估不准确和不稳定梯度。

Method: 提出了Multi-GRPO框架，包含两种正交分组机制：基于树的轨迹分组（受蒙特卡洛树搜索启发）和基于奖励的分组，分别用于优化信用分配和多目标优化。

Result: 在PickScore-25k和OCR-Color-10基准测试中，Multi-GRPO实现了更高的稳定性和对齐性能，平衡了冲突目标。

Conclusion: Multi-GRPO通过引入多组优势估计框架，有效解决了GRPO方法中的信用分配和奖励混合问题，在单奖励和多目标基准测试中均表现出优越的稳定性和对齐性能。

Abstract: Recently, Group Relative Policy Optimization (GRPO) has shown promising potential for aligning text-to-image (T2I) models, yet existing GRPO-based methods suffer from two critical limitations. (1) \textit{Shared credit assignment}: trajectory-level advantages derived from group-normalized sparse terminal rewards are uniformly applied across timesteps, failing to accurately estimate the potential of early denoising steps with vast exploration spaces. (2) \textit{Reward-mixing}: predefined weights for combining multi-objective rewards (e.g., text accuracy, visual quality, text color)--which have mismatched scales and variances--lead to unstable gradients and conflicting updates. To address these issues, we propose \textbf{Multi-GRPO}, a multi-group advantage estimation framework with two orthogonal grouping mechanisms. For better credit assignment, we introduce tree-based trajectories inspired by Monte Carlo Tree Search: branching trajectories at selected early denoising steps naturally forms \emph{temporal groups}, enabling accurate advantage estimation for early steps via descendant leaves while amortizing computation through shared prefixes. For multi-objective optimization, we introduce \emph{reward-based grouping} to compute advantages for each reward function \textit{independently} before aggregation, disentangling conflicting signals. To facilitate evaluation of multiple objective alignment, we curate \textit{OCR-Color-10}, a visual text rendering dataset with explicit color constraints. Across the single-reward \textit{PickScore-25k} and multi-objective \textit{OCR-Color-10} benchmarks, Multi-GRPO achieves superior stability and alignment performance, effectively balancing conflicting objectives. Code will be publicly available at \href{https://github.com/fikry102/Multi-GRPO}{https://github.com/fikry102/Multi-GRPO}.

</details>


### [91] [Real-Time On-the-Go Annotation Framework Using YOLO for Automated Dataset Generation](https://arxiv.org/abs/2512.01165)
*Mohamed Abdallah Salem,Ahmed Harb Rabia*

Main category: cs.CV

TL;DR: 提出一种基于YOLO模型的实时标注方法，显著减少标注时间并保持高质量，特别适用于农业等快速决策场景。


<details>
  <summary>Details</summary>
Motivation: 传统标注方法劳动密集且耗时，无法满足农业等实时决策的需求，因此需要一种高效的实时标注方法。

Method: 采用YOLO模型在边缘设备上实现实时标注，并对三种YOLO架构（YOLOv5、YOLOv8、YOLOv12）在不同配置（单类与多类标注、预训练与从头训练）下进行了全面的比较分析。

Result: 预训练和单类配置在模型收敛、性能和鲁棒性方面表现出显著优势，验证了实时标注框架的可行性和有效性。

Conclusion: 论文提出的实时标注框架在农业等需要快速决策的场景中显著减少了数据集准备时间，同时保持了高质量的标注效果。

Abstract: Efficient and accurate annotation of datasets remains a significant challenge for deploying object detection models such as You Only Look Once (YOLO) in real-world applications, particularly in agriculture where rapid decision-making is critical. Traditional annotation techniques are labor-intensive, requiring extensive manual labeling post data collection. This paper presents a novel real-time annotation approach leveraging YOLO models deployed on edge devices, enabling immediate labeling during image capture. To comprehensively evaluate the efficiency and accuracy of our proposed system, we conducted an extensive comparative analysis using three prominent YOLO architectures (YOLOv5, YOLOv8, YOLOv12) under various configurations: single-class versus multi-class annotation and pretrained versus scratch-based training. Our analysis includes detailed statistical tests and learning dynamics, demonstrating significant advantages of pretrained and single-class configurations in terms of model convergence, performance, and robustness. Results strongly validate the feasibility and effectiveness of our real-time annotation framework, highlighting its capability to drastically reduce dataset preparation time while maintaining high annotation quality.

</details>


### [92] [Joint Multi-scale Gated Transformer and Prior-guided Convolutional Network for Learned Image Compression](https://arxiv.org/abs/2512.00744)
*Zhengxin Chen,Xiaohai He,Tingrong Zhang,Shuhua Xiong,Chao Ren*

Main category: cs.CV

TL;DR: 提出MGTPCN，结合PGConv和MGT，提升图像压缩性能，超越现有算法。


<details>
  <summary>Details</summary>
Motivation: 通过学习图像压缩方法的非线性变换编码能力超越传统图像编解码器（如VVC），并提升卷积和Swin-T块的表示能力。

Method: 提出了一种新颖的先验引导卷积（PGConv）和多尺度门控变换器（MGT），并进一步结合为MGTPCN用于学习图像压缩。

Result: 实验结果表明，MGTPCN在性能和复杂度之间取得了更好的平衡，超越了现有最先进的算法。

Conclusion: 提出的MGTPCN在性能和复杂度之间取得了更好的平衡，超越了现有最先进的算法。

Abstract: Recently, learned image compression methods have made remarkable achievements, some of which have outperformed the traditional image codec VVC. The advantages of learned image compression methods over traditional image codecs can be largely attributed to their powerful nonlinear transform coding. Convolutional layers and shifted window transformer (Swin-T) blocks are the basic units of neural networks, and their representation capabilities play an important role in nonlinear transform coding. In this paper, to improve the ability of the vanilla convolution to extract local features, we propose a novel prior-guided convolution (PGConv), where asymmetric convolutions (AConvs) and difference convolutions (DConvs) are introduced to strengthen skeleton elements and extract high-frequency information, respectively. A re-parameterization strategy is also used to reduce the computational complexity of PGConv. Moreover, to improve the ability of the Swin-T block to extract non-local features, we propose a novel multi-scale gated transformer (MGT), where dilated window-based multi-head self-attention blocks with different dilation rates and depth-wise convolution layers with different kernel sizes are used to extract multi-scale features, and a gate mechanism is introduced to enhance non-linearity. Finally, we propose a novel joint Multi-scale Gated Transformer and Prior-guided Convolutional Network (MGTPCN) for learned image compression. Experimental results show that our MGTPCN surpasses state-of-the-art algorithms with a better trade-off between performance and complexity.

</details>


### [93] [Probabilistic Modeling of Multi-rater Medical Image Segmentation for Diversity and Personalization](https://arxiv.org/abs/2512.00748)
*Ke Liu,Shangde Gao,Yichao Fu,Shangqi Gao,Chunhua Shen*

Main category: cs.CV

TL;DR: ProSeg通过概率建模解决医学图像分割中的多样化和个性化问题，实验验证其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有模型在多样化分割和个性化输出之间存在局限，无法同时满足多样性和专家特异性需求。

Method: 引入两个潜在变量建模专家标注偏好和图像边界模糊性，通过变分推断获取条件概率分布，生成分割输出。

Result: 在NPC和LIDC-IDRI数据集上验证了ProSeg的优越性，实现了既多样又专家个性化的分割结果。

Conclusion: ProSeg通过概率建模同时实现了多样化和个性化分割，在NPC和LIDC-IDRI数据集上达到了新的最优性能。

Abstract: Medical image segmentation is inherently influenced by data uncertainty, arising from ambiguous boundaries in medical scans and inter-observer variability in diagnosis. To address this challenge, previous works formulated the multi-rater medical image segmentation task, where multiple experts provide separate annotations for each image. However, existing models are typically constrained to either generate diverse segmentation that lacks expert specificity or to produce personalized outputs that merely replicate individual annotators. We propose Probabilistic modeling of multi-rater medical image Segmentation (ProSeg) that simultaneously enables both diversification and personalization. Specifically, we introduce two latent variables to model expert annotation preferences and image boundary ambiguity. Their conditional probabilistic distributions are then obtained through variational inference, allowing segmentation outputs to be generated by sampling from these distributions. Extensive experiments on both the nasopharyngeal carcinoma dataset (NPC) and the lung nodule dataset (LIDC-IDRI) demonstrate that our ProSeg achieves a new state-of-the-art performance, providing segmentation results that are both diverse and expert-personalized. Code can be found in https://github.com/AI4MOL/ProSeg.

</details>


### [94] [SPARK: Sim-ready Part-level Articulated Reconstruction with VLM Knowledge](https://arxiv.org/abs/2512.01629)
*Yumeng He,Ying Jiang,Jiayin Lu,Yin Yang,Chenfanfu Jiang*

Main category: cs.CV

TL;DR: SPARK从单张RGB图像重建仿真就绪的关节化3D物体，结合VLM和生成扩散变换器，优化URDF参数，支持下游应用。


<details>
  <summary>Details</summary>
Motivation: 关节化3D物体对具身AI、机器人和交互场景理解至关重要，但创建仿真就绪的资产仍需要大量人工和专家建模。

Method: 利用视觉语言模型（VLM）提取粗略的URDF参数并生成部件级参考图像，结合部件图像引导和推断的结构图，通过生成扩散变换器合成一致的部件和完整形状，并通过可微分前向运动学和可微分渲染优化关节类型、轴和原点。

Result: 实验表明，SPARK能够跨多样类别生成高质量的、仿真就绪的关节化资产。

Conclusion: SPARK框架能够从单张RGB图像重建出高质量的、可用于仿真的关节化3D物体，支持机器人操作和交互建模等下游应用。

Abstract: Articulated 3D objects are critical for embodied AI, robotics, and interactive scene understanding, yet creating simulation-ready assets remains labor-intensive and requires expert modeling of part hierarchies and motion structures. We introduce SPARK, a framework for reconstructing physically consistent, kinematic part-level articulated objects from a single RGB image. Given an input image, we first leverage VLMs to extract coarse URDF parameters and generate part-level reference images. We then integrate the part-image guidance and the inferred structure graph into a generative diffusion transformer to synthesize consistent part and complete shapes of articulated objects. To further refine the URDF parameters, we incorporate differentiable forward kinematics and differentiable rendering to optimize joint types, axes, and origins under VLM-generated open-state supervision. Extensive experiments show that SPARK produces high-quality, simulation-ready articulated assets across diverse categories, enabling downstream applications such as robotic manipulation and interaction modeling.

</details>


### [95] [Charts Are Not Images: On the Challenges of Scientific Chart Editing](https://arxiv.org/abs/2512.00752)
*Shawn Li,Ryan Rossi,Sungchul Kim,Sunav Choudhary,Franck Dernoncourt,Puneet Mathur,Zhengzhong Tu,Yue Zhao*

Main category: cs.CV

TL;DR: FigEdit是一个科学图表编辑基准，揭示了现有生成模型在结构化转换任务中的不足，并呼吁开发结构感知模型。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型在自然图像编辑中表现优异，但应用于科学图表时忽略了其结构化数据的本质，导致编辑效果不佳。

Method: 通过构建包含30,000多个样本的FigEdit基准，覆盖10种图表类型和复杂编辑指令，评估了多种先进模型在科学图表编辑任务中的表现。

Result: 评估显示现有模型在科学图表编辑任务中表现较差，传统评估指标（如SSIM、PSNR）无法准确捕捉语义正确性。

Conclusion: 本文介绍了FigEdit，一个大规模的科学图表编辑基准，揭示了现有生成模型在处理结构化转换时的局限性，并强调了开发结构感知模型的必要性。

Abstract: Generative models, such as diffusion and autoregressive approaches, have demonstrated impressive capabilities in editing natural images. However, applying these tools to scientific charts rests on a flawed assumption: a chart is not merely an arrangement of pixels but a visual representation of structured data governed by a graphical grammar. Consequently, chart editing is not a pixel-manipulation task but a structured transformation problem. To address this fundamental mismatch, we introduce \textit{FigEdit}, a large-scale benchmark for scientific figure editing comprising over 30,000 samples. Grounded in real-world data, our benchmark is distinguished by its diversity, covering 10 distinct chart types and a rich vocabulary of complex editing instructions. The benchmark is organized into five distinct and progressively challenging tasks: single edits, multi edits, conversational edits, visual-guidance-based edits, and style transfer. Our evaluation of a range of state-of-the-art models on this benchmark reveals their poor performance on scientific figures, as they consistently fail to handle the underlying structured transformations required for valid edits. Furthermore, our analysis indicates that traditional evaluation metrics (e.g., SSIM, PSNR) have limitations in capturing the semantic correctness of chart edits. Our benchmark demonstrates the profound limitations of pixel-level manipulation and provides a robust foundation for developing and evaluating future structure-aware models. By releasing \textit{FigEdit} (https://github.com/adobe-research/figure-editing), we aim to enable systematic progress in structure-aware figure editing, provide a common ground for fair comparison, and encourage future research on models that understand both the visual and semantic layers of scientific charts.

</details>


### [96] [Register Any Point: Scaling 3D Point Cloud Registration by Flow Matching](https://arxiv.org/abs/2512.01850)
*Yue Pan,Tao Sun,Liyuan Zhu,Lucas Nunes,Iro Armeni,Jens Behley,Cyrill Stachniss*

Main category: cs.CV

TL;DR: 提出一种将点云配准视为条件生成的方法，通过学习速度场直接生成已注册点云，在低重叠情况下表现优异，支持多种下游任务。


<details>
  <summary>Details</summary>
Motivation: 解决点云配准问题，特别是低重叠情况下的多视图配准，以支持3D重建和机器人定位等核心任务。

Method: 通过学习连续的点级速度场，将噪声点传输到已注册的场景中，从而恢复每个视图的姿态。采用轻量级局部特征提取器和测试时刚性强化。

Result: 在成对和多视图配准基准测试中取得了最先进的结果，尤其是在低重叠情况下，并且能够跨尺度和传感器模态泛化。

Conclusion: 该方法在低重叠情况下表现出色，支持多种下游任务，如重定位、多机器人SLAM和多会话地图合并。

Abstract: Point cloud registration aligns multiple unposed point clouds into a common frame, and is a core step for 3D reconstruction and robot localization. In this work, we cast registration as conditional generation: a learned continuous, point-wise velocity field transports noisy points to a registered scene, from which the pose of each view is recovered. Unlike previous methods that conduct correspondence matching to estimate the transformation between a pair of point clouds and then optimize the pairwise transformations to realize multi-view registration, our model directly generates the registered point cloud. With a lightweight local feature extractor and test-time rigidity enforcement, our approach achieves state-of-the-art results on pairwise and multi-view registration benchmarks, particularly with low overlap, and generalizes across scales and sensor modalities. It further supports downstream tasks including relocalization, multi-robot SLAM, and multi-session map merging. Source code available at: https://github.com/PRBonn/RAP.

</details>


### [97] [Seeing the Wind from a Falling Leaf](https://arxiv.org/abs/2512.00762)
*Zhiyuan Gao,Jiageng Mao,Hong-Xing Yu,Haozhe Lou,Emily Yue-Ting Jia,Jernej Barbic,Jiajun Wu,Yue Wang*

Main category: cs.CV

TL;DR: 论文提出了一种从视频中恢复不可见力场的端到端框架，展示了其在物理基础视频生成和编辑中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 研究如何从视觉观察中恢复不可见的力（如通过观察树叶落地估计风场），填补计算机视觉中对运动背后物理交互建模的空白。

Method: 采用端到端的可微分逆向图形框架，联合建模物体几何、物理属性和相互作用，通过反向传播从物体运动中恢复力表示。

Result: 在合成和真实场景中验证了方法的有效性，能够从视频中推断出合理的力场。

Conclusion: 该论文提出了一种端到端的可微分逆向图形框架，能够从视频中恢复不可见的力场，并展示了其在物理基础视频生成和编辑中的潜在应用。

Abstract: A longstanding goal in computer vision is to model motions from videos, while the representations behind motions, i.e. the invisible physical interactions that cause objects to deform and move, remain largely unexplored. In this paper, we study how to recover the invisible forces from visual observations, e.g., estimating the wind field by observing a leaf falling to the ground. Our key innovation is an end-to-end differentiable inverse graphics framework, which jointly models object geometry, physical properties, and interactions directly from videos. Through backpropagation, our approach enables the recovery of force representations from object motions. We validate our method on both synthetic and real-world scenarios, and the results demonstrate its ability to infer plausible force fields from videos. Furthermore, we show the potential applications of our approach, including physics-based video generation and editing. We hope our approach sheds light on understanding and modeling the physical process behind pixels, bridging the gap between vision and physics. Please check more video results in our \href{https://chaoren2357.github.io/seeingthewind/}{project page}.

</details>


### [98] [GrndCtrl: Grounding World Models via Self-Supervised Reward Alignment](https://arxiv.org/abs/2512.01952)
*Haoyang He,Jay Patrikar,Dong-Ki Kim,Max Smith,Daniel McGann,Ali-akbar Agha-mohammadi,Shayegan Omidshafiei,Sebastian Scherer*

Main category: cs.CV

TL;DR: RLWG是一种自监督后训练框架，通过几何和感知奖励提升世界模型的几何基础，适用于导航任务。


<details>
  <summary>Details</summary>
Motivation: 尽管现有视频世界建模在视觉保真度上表现优异，但缺乏几何基础，限制了其在需要空间一致性和长时稳定性的导航任务中的应用。

Method: 采用基于Group Relative Policy Optimization (GRPO)的GrndCtrl方法，结合姿态循环一致性、深度重投影和时间一致性等多重奖励机制。

Result: GrndCtrl方法在户外环境中实现了优于监督微调的空间一致性和导航稳定性。

Conclusion: RLWG框架通过几何和感知奖励将预训练的世界模型与物理可验证结构对齐，显著提升了空间一致性和导航稳定性。

Abstract: Recent advances in video world modeling have enabled large-scale generative models to simulate embodied environments with high visual fidelity, providing strong priors for prediction, planning, and control. Yet, despite their realism, these models often lack geometric grounding, limiting their use in navigation tasks that require spatial coherence and long-horizon stability. We introduce Reinforcement Learning with World Grounding (RLWG), a self-supervised post-training framework that aligns pretrained world models with a physically verifiable structure through geometric and perceptual rewards. Analogous to reinforcement learning from verifiable feedback (RLVR) in language models, RLWG can use multiple rewards that measure pose cycle-consistency, depth reprojection, and temporal coherence. We instantiate this framework with GrndCtrl, a reward-aligned adaptation method based on Group Relative Policy Optimization (GRPO), yielding world models that maintain stable trajectories, consistent geometry, and reliable rollouts for embodied navigation. Like post-training alignment in large language models, GrndCtrl leverages verifiable rewards to bridge generative pretraining and grounded behavior, achieving superior spatial coherence and navigation stability over supervised fine-tuning in outdoor environments.

</details>


### [99] [The Outline of Deception: Physical Adversarial Attacks on Traffic Signs Using Edge Patches](https://arxiv.org/abs/2512.00765)
*Haojie Jia,Te Hu,Haowen Li,Long Jin,Chongshi Xin,Yuchi Yao,Jiarui Xiao*

Main category: cs.CV

TL;DR: TESP-Attack通过视觉隐蔽优化，高效攻击交通标志分类模型，成功率超90%，且具备现实适用性。


<details>
  <summary>Details</summary>
Motivation: 当前物理对抗攻击缺乏隐蔽性，易被人类察觉，限制了实际应用。

Method: 利用实例分割生成边缘对齐的掩码，结合U-Net生成器和颜色、纹理约束及频域分析，优化对抗补丁以实现视觉隐蔽。

Result: 在多种架构的交通标志分类模型上攻击成功率超过90%，并展现出强跨模型迁移能力和现实世界稳定性。

Conclusion: TESP-Attack 是一种新颖的隐蔽对抗补丁方法，能有效攻击交通标志分类模型，具有高攻击成功率和现实世界稳定性。

Abstract: Intelligent driving systems are vulnerable to physical adversarial attacks on traffic signs. These attacks can cause misclassification, leading to erroneous driving decisions that compromise road safety. Moreover, within V2X networks, such misinterpretations can propagate, inducing cascading failures that disrupt overall traffic flow and system stability. However, a key limitation of current physical attacks is their lack of stealth. Most methods apply perturbations to central regions of the sign, resulting in visually salient patterns that are easily detectable by human observers, thereby limiting their real-world practicality. This study proposes TESP-Attack, a novel stealth-aware adversarial patch method for traffic sign classification. Based on the observation that human visual attention primarily focuses on the central regions of traffic signs, we employ instance segmentation to generate edge-aligned masks that conform to the shape characteristics of the signs. A U-Net generator is utilized to craft adversarial patches, which are then optimized through color and texture constraints along with frequency domain analysis to achieve seamless integration with the background environment, resulting in highly effective visual concealment. The proposed method demonstrates outstanding attack success rates across traffic sign classification models with varied architectures, achieving over 90% under limited query budgets. It also exhibits strong cross-model transferability and maintains robust real-world performance that remains stable under varying angles and distances.

</details>


### [100] [Visual Sync: Multi-Camera Synchronization via Cross-View Object Motion](https://arxiv.org/abs/2512.02017)
*Shaowei Liu,David Yifan Yao,Saurabh Gupta,Shenlong Wang*

Main category: cs.CV

TL;DR: VisualSync 是一个优化框架，通过多视角动态和极线约束实现无姿态、未同步视频的毫秒级精确对齐，实验表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的视频同步方法通常假设受控环境、特定目标、手动校正或昂贵硬件，而VisualSync旨在解决这些限制，实现无姿态、未同步视频的毫秒级精确对齐。

Method: VisualSync 是一个基于多视角动态的优化框架，利用现成的3D重建、特征匹配和密集跟踪技术提取轨迹片段、相对姿态和跨视角对应关系，并通过最小化极线误差来估计每个相机的时间偏移。

Result: VisualSync 在实验中表现出色，中位同步误差低于50毫秒，显著优于基线方法。

Conclusion: VisualSync 在四个不同且具有挑战性的数据集中表现优于基线方法，实现了中位同步误差低于50毫秒。

Abstract: Today, people can easily record memorable moments, ranging from concerts, sports events, lectures, family gatherings, and birthday parties with multiple consumer cameras. However, synchronizing these cross-camera streams remains challenging. Existing methods assume controlled settings, specific targets, manual correction, or costly hardware. We present VisualSync, an optimization framework based on multi-view dynamics that aligns unposed, unsynchronized videos at millisecond accuracy. Our key insight is that any moving 3D point, when co-visible in two cameras, obeys epipolar constraints once properly synchronized. To exploit this, VisualSync leverages off-the-shelf 3D reconstruction, feature matching, and dense tracking to extract tracklets, relative poses, and cross-view correspondences. It then jointly minimizes the epipolar error to estimate each camera's time offset. Experiments on four diverse, challenging datasets show that VisualSync outperforms baseline methods, achieving an median synchronization error below 50 ms.

</details>


### [101] [EAG3R: Event-Augmented 3D Geometry Estimation for Dynamic and Extreme-Lighting Scenes](https://arxiv.org/abs/2512.00771)
*Xiaoshan Wu,Yifei Yu,Xiaoyang Lyu,Yihua Huang,Bo Wang,Baoheng Zhang,Zhongrui Wang,Xiaojuan Qi*

Main category: cs.CV

TL;DR: EAG3R结合RGB和事件流，通过创新模块和损失函数，在动态低光场景中实现鲁棒3D几何估计。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-only方法在动态对象和极端光照条件下表现不佳，EAG3R旨在通过结合异步事件流提升鲁棒性。

Method: EAG3R基于MonST3R框架，引入了Retinex-inspired图像增强模块和轻量级事件适配器，结合SNR感知融合机制，以及基于事件的光度一致性损失。

Result: 实验表明EAG3R在单目深度估计、相机姿态跟踪和动态重建任务中显著优于现有方法。

Conclusion: EAG3R通过结合RGB和事件流数据，在动态低光场景中实现了鲁棒的3D几何估计，显著优于现有RGB-only方法。

Abstract: Robust 3D geometry estimation from videos is critical for applications such as autonomous navigation, SLAM, and 3D scene reconstruction. Recent methods like DUSt3R demonstrate that regressing dense pointmaps from image pairs enables accurate and efficient pose-free reconstruction. However, existing RGB-only approaches struggle under real-world conditions involving dynamic objects and extreme illumination, due to the inherent limitations of conventional cameras. In this paper, we propose EAG3R, a novel geometry estimation framework that augments pointmap-based reconstruction with asynchronous event streams. Built upon the MonST3R backbone, EAG3R introduces two key innovations: (1) a retinex-inspired image enhancement module and a lightweight event adapter with SNR-aware fusion mechanism that adaptively combines RGB and event features based on local reliability; and (2) a novel event-based photometric consistency loss that reinforces spatiotemporal coherence during global optimization. Our method enables robust geometry estimation in challenging dynamic low-light scenes without requiring retraining on night-time data. Extensive experiments demonstrate that EAG3R significantly outperforms state-of-the-art RGB-only baselines across monocular depth estimation, camera pose tracking, and dynamic reconstruction tasks.

</details>


### [102] [Data-Centric Visual Development for Self-Driving Labs](https://arxiv.org/abs/2512.02018)
*Anbang Liu,Guanzhong Hu,Jiayi Wang,Ping Guo,Han Liu*

Main category: cs.CV

TL;DR: 该研究通过混合真实和虚拟数据生成的方法，解决了自驱动实验室中移液操作的数据稀缺问题，实现了高精度的气泡检测，并显著降低了数据收集成本。


<details>
  <summary>Details</summary>
Motivation: 解决自驱动实验室中由于训练数据稀缺（尤其是负样本）导致的高精度需求模型难以训练的问题，特别是针对最关键的移液操作。

Method: 构建了一个融合真实和虚拟数据生成的混合管道。真实数据采用人在回路方案，结合自动化采集和选择性人工验证；虚拟数据通过参考条件提示引导的图像生成来增强真实数据，并进一步筛选和验证可靠性。

Result: 在保留的真实测试集上，完全基于自动采集的真实图像训练的模型达到99.6%的准确率，混合真实和生成数据训练时准确率保持在99.4%，同时减少了数据收集和审查的工作量。

Conclusion: 该研究为自驱动实验室（SDL）工作流程提供了一种可扩展且经济高效的视觉反馈数据供应策略，并为罕见事件检测及更广泛的视觉任务中的数据稀缺问题提供了实用解决方案。

Abstract: Self-driving laboratories offer a promising path toward reducing the labor-intensive, time-consuming, and often irreproducible workflows in the biological sciences. Yet their stringent precision requirements demand highly robust models whose training relies on large amounts of annotated data. However, this kind of data is difficult to obtain in routine practice, especially negative samples. In this work, we focus on pipetting, the most critical and precision sensitive action in SDLs. To overcome the scarcity of training data, we build a hybrid pipeline that fuses real and virtual data generation. The real track adopts a human-in-the-loop scheme that couples automated acquisition with selective human verification to maximize accuracy with minimal effort. The virtual track augments the real data using reference-conditioned, prompt-guided image generation, which is further screened and validated for reliability. Together, these two tracks yield a class-balanced dataset that enables robust bubble detection training. On a held-out real test set, a model trained entirely on automatically acquired real images reaches 99.6% accuracy, and mixing real and generated data during training sustains 99.4% accuracy while reducing collection and review load. Our approach offers a scalable and cost-effective strategy for supplying visual feedback data to SDL workflows and provides a practical solution to data scarcity in rare event detection and broader vision tasks.

</details>


### [103] [DEJIMA: A Novel Large-scale Japanese Dataset for Image Captioning and Visual Question Answering](https://arxiv.org/abs/2512.00773)
*Toshiki Katsube,Taiga Fukuhara,Kenichiro Ando,Yusuke Mukuta,Kohei Uehara,Tatsuya Harada*

Main category: cs.CV

TL;DR: 本文提出了一个构建大规模日本视觉与语言数据集DEJIMA的流水线，显著提升了模型性能，并公开了数据集以促进研究和应用。


<details>
  <summary>Details</summary>
Motivation: 解决日本视觉与语言建模领域高质量、大规模资源稀缺的问题。

Method: 提出了一个可扩展且可复现的流水线，结合大规模网络收集、严格过滤/去重、基于目标检测的证据提取，以及在接地约束下的LLM精炼。

Result: 构建了两个资源：DEJIMA-Cap（图像-标题数据集）和DEJIMA-VQA（VQA数据集），各包含388万图像-文本对，远超现有日本V&L数据集规模。人类评估显示DEJIMA在‘日本性’和语言自然性上显著优于翻译或人工标注的数据集，同时保持与人工标注语料相当的事实正确性。

Conclusion: DEJIMA数据集在提升日本视觉与语言模型性能方面发挥了关键作用，其数据源和模块均允许商业使用，并公开了数据集和元数据以促进进一步研究和工业应用。

Abstract: This work addresses the scarcity of high-quality, large-scale resources for Japanese Vision-and-Language (V&L) modeling. We present a scalable and reproducible pipeline that integrates large-scale web collection with rigorous filtering/deduplication, object-detection-driven evidence extraction, and Large Language Model (LLM)-based refinement under grounding constraints. Using this pipeline, we build two resources: an image-caption dataset (DEJIMA-Cap) and a VQA dataset (DEJIMA-VQA), each containing 3.88M image-text pairs, far exceeding the size of existing Japanese V&L datasets. Human evaluations demonstrate that DEJIMA achieves substantially higher Japaneseness and linguistic naturalness than datasets constructed via translation or manual annotation, while maintaining factual correctness at a level comparable to human-annotated corpora. Quantitative analyses of image feature distributions further confirm that DEJIMA broadly covers diverse visual domains characteristic of Japan, complementing its linguistic and cultural representativeness. Models trained on DEJIMA exhibit consistent improvements across multiple Japanese multimodal benchmarks, confirming that culturally grounded, large-scale resources play a key role in enhancing model performance. All data sources and modules in our pipeline are licensed for commercial use, and we publicly release the resulting dataset and metadata to encourage further research and industrial applications in Japanese V&L modeling.

</details>


### [104] [PolarGS: Polarimetric Cues for Ambiguity-Free Gaussian Splatting with Accurate Geometry Recovery](https://arxiv.org/abs/2512.00794)
*Bo Guo,Sijia Wen,Yifan Zhao,Jia Li,Zhiming Zheng*

Main category: cs.CV

TL;DR: PolarGS利用偏振光解决3DGS在反射/无纹理区域的几何模糊问题，通过偏振校正和密集化机制提升重建精度。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS在反射和无纹理表面因光度一致性不可靠而导致几何估计不准确，偏振光能揭示表面方向，可作为光度线索的补充。

Method: PolarGS包含两个互补模块：偏振引导的光度校正策略（通过线性偏振度识别反射区域并优化高斯模型）和偏振增强的高斯密集化机制（结合偏振角度和线性偏振度进行深度补全）。

Result: PolarGS在几何重建精度上优于现有方法，且框架无关。

Conclusion: PolarGS通过引入偏振光作为光学先验，成功解决了3D高斯溅射（3DGS）在反射和无纹理区域的几何重建问题，显著提升了重建精度。

Abstract: Recent advances in surface reconstruction for 3D Gaussian Splatting (3DGS) have enabled remarkable geometric accuracy. However, their performance degrades in photometrically ambiguous regions such as reflective and textureless surfaces, where unreliable cues disrupt photometric consistency and hinder accurate geometry estimation. Reflected light is often partially polarized in a manner that reveals surface orientation, making polarization an optic complement to photometric cues in resolving such ambiguities. Therefore, we propose PolarGS, an optics-aware extension of RGB-based 3DGS that leverages polarization as an optical prior to resolve photometric ambiguities and enhance reconstruction accuracy. Specifically, we introduce two complementary modules: a polarization-guided photometric correction strategy, which ensures photometric consistency by identifying reflective regions via the Degree of Linear Polarization (DoLP) and refining reflective Gaussians with Color Refinement Maps; and a polarization-enhanced Gaussian densification mechanism for textureless area geometry recovery, which integrates both Angle and Degree of Linear Polarization (A/DoLP) into a PatchMatch-based depth completion process. This enables the back-projection and fusion of new Gaussians, leading to more complete reconstruction. PolarGS is framework-agnostic and achieves superior geometric accuracy compared to state-of-the-art methods.

</details>


### [105] [CircleFlow: Flow-Guided Camera Blur Estimation using a Circle Grid Target](https://arxiv.org/abs/2512.00796)
*Jiajian He,Enjie Hu,Shiqi Chen,Tianchen Qiu,Huajun Feng,Zhihai Xu,Yueting Chen*

Main category: cs.CV

TL;DR: CircleFlow 是一种高保真 PSF 估计框架，通过结构化捕捉和光流引导的边缘定位，实现了精确的模糊表征和 PSF 估计。


<details>
  <summary>Details</summary>
Motivation: PSF 估计对光学表征和计算视觉至关重要，但由于强度反卷积的固有模糊性和不适定性，准确估计 PSF 仍具挑战性。

Method: CircleFlow 采用结构化捕捉方法，通过圆形网格目标编码局部各向异性和空间变化的 PSF，结合光流引导的子像素对齐和能量约束的隐式神经表示，联合优化图像和 PSF 估计。

Result: CircleFlow 在模拟和真实数据中均表现出最先进的准确性和可靠性，验证了其在实际 PSF 校准中的有效性。

Conclusion: CircleFlow 框架通过精确的边缘定位和联合优化方法，实现了高保真的 PSF 估计，实验验证了其在模拟和真实数据中的优越性能。

Abstract: The point spread function (PSF) serves as a fundamental descriptor linking the real-world scene to the captured signal, manifesting as camera blur. Accurate PSF estimation is crucial for both optical characterization and computational vision, yet remains challenging due to the inherent ambiguity and the ill-posed nature of intensity-based deconvolution. We introduce CircleFlow, a high-fidelity PSF estimation framework that employs flow-guided edge localization for precise blur characterization. CircleFlow begins with a structured capture that encodes locally anisotropic and spatially varying PSFs by imaging a circle grid target, while leveraging the target's binary luminance prior to decouple image and kernel estimation. The latent sharp image is then reconstructed through subpixel alignment of an initialized binary structure guided by optical flow, whereas the PSF is modeled as an energy-constrained implicit neural representation. Both components are jointly optimized within a demosaicing-aware differentiable framework, ensuring physically consistent and robust PSF estimation enabled by accurate edge localization. Extensive experiments on simulated and real-world data demonstrate that CircleFlow achieves state-of-the-art accuracy and reliability, validating its effectiveness for practical PSF calibration.

</details>


### [106] [Thinking with Drafts: Speculative Temporal Reasoning for Efficient Long Video Understanding](https://arxiv.org/abs/2512.00805)
*Pengfei Hu,Meng Cao,Yingyao Wang,Yi Wang,Jiahua Dong,Jun Song,Yu Cheng,Bo Zheng,Xiaodan Liang*

Main category: cs.CV

TL;DR: SpecTemp通过双模型协作设计，高效解决长视频理解中的冗余上下文问题，提升推理速度且保持准确性。


<details>
  <summary>Details</summary>
Motivation: 解决现有‘帧间思考’范式因冗余多模态上下文导致的效率瓶颈问题。

Method: 采用强化学习框架，通过轻量级草稿MLLM和强大目标MLLM的协作，前者快速探索并提议关键帧，后者专注时序推理并验证提议，迭代优化注意力。

Result: 在多个视频理解基准测试中，SpecTemp在保持准确性的同时显著加速推理。

Conclusion: SpecTemp通过双模型协作设计，在保持竞争力的准确性的同时显著提升了推理效率，为长视频理解提供了高效解决方案。

Abstract: Long video understanding is essential for human-like intelligence, enabling coherent perception and reasoning over extended temporal contexts. While the emerging thinking-with-frames paradigm, which alternates between global temporal reasoning and local frame examination, has advanced the reasoning capabilities of video multi-modal large language models (MLLMs), it suffers from a significant efficiency bottleneck due to the progressively growing and redundant multi-modal context. To address this, we propose SpecTemp, a reinforcement learning-based Speculative Temporal reasoning framework that decouples temporal perception from reasoning via a cooperative dual-model design. In SpecTemp, a lightweight draft MLLM rapidly explores and proposes salient frames from densely sampled temporal regions, while a powerful target MLLM focuses on temporal reasoning and verifies the draft's proposals, iteratively refining its attention until convergence. This design mirrors the collaborative pathways of the human brain, balancing efficiency with accuracy. To support training, we construct the SpecTemp-80K dataset, featuring synchronized dual-level annotations for coarse evidence spans and fine-grained frame-level evidence. Experiments across multiple video understanding benchmarks demonstrate that SpecTemp not only maintains competitive accuracy but also significantly accelerates inference compared with existing thinking-with-frames methods.

</details>


### [107] [IRPO: Boosting Image Restoration via Post-training GRPO](https://arxiv.org/abs/2512.00814)
*Haoxuan Xu. Yi Liu,Boyuan Jiang,Jinlong Peng,Donghao Luo,Xiaobin Hu,Shuicheng Yan,Haoang Li*

Main category: cs.CV

TL;DR: IRPO是一种创新的低层次视觉后训练范式，通过数据选择和奖励建模显著提升了图像恢复性能。


<details>
  <summary>Details</summary>
Motivation: 现有的图像恢复方法依赖于像素级的硬拟合，存在过度平滑和泛化能力差的问题，IRPO旨在解决这些限制。

Method: 提出了一种基于GRPO的低层次后训练范式IRPO，探索了数据制定原则和奖励建模系统，包括通用奖励、专家奖励和恢复奖励三个互补组件。

Result: 在六个领域内和五个领域外基准测试中，IRPO表现优异，领域内任务比AdaIR基线提高了0.83 dB，领域外设置提高了3.43 dB。

Conclusion: IRPO在低层次视觉任务中表现出色，尤其在领域内和领域外基准测试中均取得了最先进的结果，超越了AdaIR基线。

Abstract: Recent advances in post-training paradigms have achieved remarkable success in high-level generation tasks, yet their potential for low-level vision remains rarely explored. Existing image restoration (IR) methods rely on pixel-level hard-fitting to ground-truth images, struggling with over-smoothing and poor generalization. To address these limitations, we propose IRPO, a low-level GRPO-based post-training paradigm that systematically explores both data formulation and reward modeling. We first explore a data formulation principle for low-level post-training paradigm, in which selecting underperforming samples from the pre-training stage yields optimal performance and improved efficiency. Furthermore, we model a reward-level criteria system that balances objective accuracy and human perceptual preference through three complementary components: a General Reward for structural fidelity, an Expert Reward leveraging Qwen-VL for perceptual alignment, and a Restoration Reward for task-specific low-level quality. Comprehensive experiments on six in-domain and five out-of-domain (OOD) low-level benchmarks demonstrate that IRPO achieves state-of-the-art results across diverse degradation types, surpassing the AdaIR baseline by 0.83 dB on in-domain tasks and 3.43 dB on OOD settings. Our code can be shown in https://github.com/HaoxuanXU1024/IRPO.

</details>


### [108] [PanFlow: Decoupled Motion Control for Panoramic Video Generation](https://arxiv.org/abs/2512.00832)
*Cheng Zhang,Hanwen Liang,Donny Y. Chen,Qianyi Wu,Konstantinos N. Plataniotis,Camilo Cruz Gambardella,Jianfei Cai*

Main category: cs.CV

TL;DR: PanFlow是一种全景视频生成新方法，通过解耦相机旋转与光流条件，实现了对大动态运动的精确控制，并在多个指标上优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有全景视频生成方法缺乏明确的运动控制，难以处理大且复杂的运动场景。

Method: 提出PanFlow方法，利用全景图的球面特性解耦相机旋转与光流条件，并引入球面噪声扭曲策略以增强运动边界的一致性。

Result: PanFlow在运动保真度、视觉质量和时间一致性上显著优于现有方法，并在运动转移和视频编辑等应用中展示了有效性。

Conclusion: PanFlow通过解耦相机旋转与输入光流条件，实现了对大动态运动的精确控制，并在运动保真度、视觉质量和时间一致性上显著优于现有方法。

Abstract: Panoramic video generation has attracted growing attention due to its applications in virtual reality and immersive media. However, existing methods lack explicit motion control and struggle to generate scenes with large and complex motions. We propose PanFlow, a novel approach that exploits the spherical nature of panoramas to decouple the highly dynamic camera rotation from the input optical flow condition, enabling more precise control over large and dynamic motions. We further introduce a spherical noise warping strategy to promote loop consistency in motion across panorama boundaries. To support effective training, we curate a large-scale, motion-rich panoramic video dataset with frame-level pose and flow annotations. We also showcase the effectiveness of our method in various applications, including motion transfer and video editing. Extensive experiments demonstrate that PanFlow significantly outperforms prior methods in motion fidelity, visual quality, and temporal coherence. Our code, dataset, and models are available at https://github.com/chengzhag/PanFlow.

</details>


### [109] [AFRAgent : An Adaptive Feature Renormalization Based High Resolution Aware GUI agent](https://arxiv.org/abs/2512.00846)
*Neeraj Anand,Rishabh Jain,Sohan Patnaik,Balaji Krishnamurthy,Mausoom Sarkar*

Main category: cs.CV

TL;DR: AFRAgent是一种小型高效的GUI自动化模型，通过自适应特征重归一化技术提升性能，在基准测试中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在GUI自动化中存在空间信息不足和模型体积过大的问题，AFRAgent旨在解决这些挑战。

Method: 采用基于instruct-BLIP的多模态架构，并提出自适应特征重归一化技术，以增强图像嵌入。

Result: 在Meta-GUI和AITW基准测试中表现优异，模型体积小于竞争对手的四分之一。

Conclusion: AFRAgent在智能手机自动化领域建立了新的最先进基准，证明了其在GUI自动化中的优越性能。

Abstract: There is a growing demand for mobile user interface (UI) automation, driven by its broad applications across industries. With the advent of visual language models (VLMs), GUI automation has progressed from generating text-based instructions for humans to autonomously executing tasks, thus optimizing automation workflows. Recent approaches leverage VLMs for this problem due to their ability to 1) process on-screen content directly, 2) remain independent of device-specific APIs by utilizing human actions (e.g., clicks, typing), and 3) apply real-world contextual knowledge for task understanding. However, these models often have trouble accurately identifying widgets and determining actions due to limited spatial information in vision encoder features. Additionally, top-performing models are often large, requiring extensive training and resulting in inference delays. In this work, we introduce AFRAgent, an instruct-BLIP-based multimodal architecture that achieves superior performance in GUI automation while being less than one-fourth the size of its nearest competitor. To enhance image embeddings in the large language model (LLM) pipeline, we propose an adaptive feature renormalization-based (a token-level affine transformation) technique that effectively enriches low-resolution image embeddings and fuses high-resolution details. We evaluate AFRAgent on Meta-GUI and AITW benchmarks, establishing a new state-of-the-art baseline for smartphone automation.

</details>


### [110] [Smol-GS: Compact Representations for Abstract 3D Gaussian Splatting](https://arxiv.org/abs/2512.00850)
*Haishan Wang,Mohammad Hassan Vali,Arno Solin*

Main category: cs.CV

TL;DR: Smol-GS是一种新型3D高斯泼溅压缩方法，通过递归体素层次和特征存储实现高效压缩，保持高质量渲染并支持下游任务。


<details>
  <summary>Details</summary>
Motivation: 解决3D高斯泼溅场景表示的高存储需求问题，同时整合空间和语义信息以实现高效压缩。

Method: 采用递归体素层次结构捕获泼溅坐标，并通过泼溅特征存储颜色、透明度、变换和材质属性等抽象信息。

Result: 在标准基准测试中实现了最先进的压缩效果，且未损失渲染质量。

Conclusion: Smol-GS通过高效的3D编码方法实现了对3D高斯泼溅（3DGS）场景的极致压缩，同时保持了高渲染质量，并为下游任务如导航和规划提供了潜在基础。

Abstract: We present Smol-GS, a novel method for learning compact representations for 3D Gaussian Splatting (3DGS). Our approach learns highly efficient encodings in 3D space that integrate both spatial and semantic information. The model captures the coordinates of the splats through a recursive voxel hierarchy, while splat-wise features store abstracted cues, including color, opacity, transformation, and material properties. This design allows the model to compress 3D scenes by orders of magnitude without loss of flexibility. Smol-GS achieves state-of-the-art compression on standard benchmarks while maintaining high rendering quality. Beyond visual fidelity, the discrete representations could potentially serve as a foundation for downstream tasks such as navigation, planning, and broader 3D scene understanding.

</details>


### [111] [TAP-CT: 3D Task-Agnostic Pretraining of Computed Tomography Foundation Models](https://arxiv.org/abs/2512.00872)
*Tim Veenboer,George Yiasemis,Eric Marcus,Vivien Van Veldhuizen,Cees G. M. Snoek,Jonas Teuwen,Kevin B. W. Groot Lipman*

Main category: cs.CV

TL;DR: TAP-CT是一种任务无关的CT基础模型预训练方法，通过改进ViTs和DINOv2适用于3D数据，无需大量微调即可生成泛化能力强的表示。


<details>
  <summary>Details</summary>
Motivation: 现有医学领域的基础模型通常需要大量微调或依赖资源密集的解码器，且预训练目标偏向特定任务，因此需要一种任务无关、微调需求低的基础模型。

Method: 通过针对patch嵌入、位置编码和体积增强的针对性修改，使Vision Transformers (ViTs)和DINOv2适用于体积数据，保留了底层架构的简洁性。

Result: 在大规模内部CT数据集（105K体积）上进行3D预训练，生成了稳定、鲁棒的冻结表示，能够在下游任务中实现强泛化。

Conclusion: TAP-CT提供了一种简单而有效的任务无关预训练方法，能够在3D CT体积数据上实现可扩展的自监督学习，其冻结表示在下游任务中表现出强大的泛化能力。

Abstract: Existing foundation models (FMs) in the medical domain often require extensive fine-tuning or rely on training resource-intensive decoders, while many existing encoders are pretrained with objectives biased toward specific tasks. This illustrates a need for a strong, task-agnostic foundation model that requires minimal fine-tuning beyond feature extraction. In this work, we introduce a suite of task-agnostic pretraining of CT foundation models (TAP-CT): a simple yet effective adaptation of Vision Transformers (ViTs) and DINOv2 for volumetric data, enabling scalable self-supervised pretraining directly on 3D CT volumes. Our approach incorporates targeted modifications to patch embeddings, positional encodings, and volumetric augmentations, making the architecture depth-aware while preserving the simplicity of the underlying architectures. We show that large-scale 3D pretraining on an extensive in-house CT dataset (105K volumes) yields stable, robust frozen representations that generalize strongly across downstream tasks. To promote transparency and reproducibility, and to establish a powerful, low-resource baseline for future research in medical imaging, we will release all pretrained models, experimental configurations, and downstream benchmark code at https://huggingface.co/fomofo/tap-ct-b-3d.

</details>


### [112] [Neural Discrete Representation Learning for Sparse-View CBCT Reconstruction: From Algorithm Design to Prospective Multicenter Clinical Evaluation](https://arxiv.org/abs/2512.00873)
*Haoshen Wang,Lei Chen,Wei-Hua Zhang,Linxia Wu,Yong Luo,Zengmao Wang,Yuan Xiong,Chengcheng Zhu,Wenjuan Tang,Xueyi Zhang,Wei Zhou,Xuhua Duan,Lefei Zhang,Gao-Jun Teng,Bo Du,Huangxuan Zhao*

Main category: cs.CV

TL;DR: DeepPriorCBCT通过深度学习实现低剂量CBCT重建，临床验证显示其图像质量与传统方法相当，显著降低辐射风险。


<details>
  <summary>Details</summary>
Motivation: 尽管CBCT引导穿刺在胸肿瘤诊疗中广泛应用，但辐射暴露增加了继发恶性肿瘤的风险，现有低剂量策略缺乏大规模验证。

Method: 提出了一个三阶段深度学习框架DeepPriorCBCT，仅使用传统辐射剂量的六分之一进行重建。

Result: 在4102名患者的8675次CBCT扫描中验证了模型，前瞻性试验（138名患者）显示图像质量与传统方法无显著差异，辐射剂量降至六分之一。

Conclusion: DeepPriorCBCT 在稀疏采样条件下实现了高质量的CBCT重建，显著降低了术中辐射风险，临床评估显示其图像质量和诊断性能与传统方法相当。

Abstract: Cone beam computed tomography (CBCT)-guided puncture has become an established approach for diagnosing and treating early- to mid-stage thoracic tumours, yet the associated radiation exposure substantially elevates the risk of secondary malignancies. Although multiple low-dose CBCT strategies have been introduced, none have undergone validation using large-scale multicenter retrospective datasets, and prospective clinical evaluation remains lacking. Here, we propose DeepPriorCBCT - a three-stage deep learning framework that achieves diagnostic-grade reconstruction using only one-sixth of the conventional radiation dose. 4102 patients with 8675 CBCT scans from 12 centers were included to develop and validate DeepPriorCBCT. Additionally, a prospective cross-over trial (Registry number: NCT07035977) which recruited 138 patients scheduled for percutaneous thoracic puncture was conducted to assess the model's clinical applicability. Assessment by 11 physicians confirmed that reconstructed images were indistinguishable from original scans. Moreover, diagnostic performance and overall image quality were comparable to those generated by standard reconstruction algorithms. In the prospective trial, five radiologists reported no significant differences in image quality or lesion assessment between DeepPriorCBCT and the clinical standard (all P>0.05). Likewise, 25 interventionalists expressed no preference between model-based and full-sampling images for surgical guidance (Kappa<0.2). Radiation exposure with DeepPriorCBCT was reduced to approximately one-sixth of that with the conventional approach, and collectively, the findings confirm that it enables high-quality CBCT reconstruction under sparse sampling conditions while markedly decreasing intraoperative radiation risk.

</details>


### [113] [Feed-Forward 3D Gaussian Splatting Compression with Long-Context Modeling](https://arxiv.org/abs/2512.00877)
*Zhening Liu,Rui Song,Yushi Huang,Yingdong Hu,Xinjie Zhang,Jiawei Shao,Zehong Lin,Jun Zhang*

Main category: cs.CV

TL;DR: 提出了一种新型前馈3DGS压缩框架，通过大规模上下文结构和精细熵模型，实现了20倍压缩比和最先进性能。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅（3DGS）作为一种革命性的3D表示方法，其数据量庞大限制了广泛应用。现有方法由于变换编码网络的有限感受野和熵模型的不充分上下文容量，难以建模长程空间依赖关系。

Method: 设计了一个基于大规模上下文结构的框架，包括基于Morton序列化的数千个高斯，以及一个细粒度的空间-通道自回归熵模型和一个基于注意力的变换编码模型。

Result: 该方法在3DGS中实现了20倍的压缩比，并在通用编解码器中达到了最先进的性能。

Conclusion: 提出的框架在3D高斯泼溅（3DGS）压缩中实现了20倍的压缩比，并在通用编解码器中达到了最先进的性能。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a revolutionary 3D representation. However, its substantial data size poses a major barrier to widespread adoption. While feed-forward 3DGS compression offers a practical alternative to costly per-scene per-train compressors, existing methods struggle to model long-range spatial dependencies, due to the limited receptive field of transform coding networks and the inadequate context capacity in entropy models. In this work, we propose a novel feed-forward 3DGS compression framework that effectively models long-range correlations to enable highly compact and generalizable 3D representations. Central to our approach is a large-scale context structure that comprises thousands of Gaussians based on Morton serialization. We then design a fine-grained space-channel auto-regressive entropy model to fully leverage this expansive context. Furthermore, we develop an attention-based transform coding model to extract informative latent priors by aggregating features from a wide range of neighboring Gaussians. Our method yields a $20\times$ compression ratio for 3DGS in a feed-forward inference and achieves state-of-the-art performance among generalizable codecs.

</details>


### [114] [Quantum-Inspired Spectral Geometry for Neural Operator Equivalence and Structured Pruning](https://arxiv.org/abs/2512.00880)
*Haijian Shao,Wei Liu,Xing Deng*

Main category: cs.CV

TL;DR: 该论文提出了一种量子启发的几何框架，通过归一化奇异值谱和QM-FRG方法解决多模态智能在异构硬件上的瓶颈问题，实验验证有效。


<details>
  <summary>Details</summary>
Motivation: 解决多模态智能在资源受限和异构硬件上的快速增长暴露出的关键瓶颈：多模态特征异构性、动态场景中的实时需求以及硬件特定算子的冗余。

Method: 论文引入了量子度量驱动的功能冗余图（QM-FRG）和一次性结构化剪枝方法，通过控制模拟验证了所提度量优于幅度和随机基线。

Result: 实验验证了所提方法在大规模多模态变换器和异构硬件上的有效性，但详细结果将在扩展期刊版本中展示。

Conclusion: 该论文提出了一种量子启发的几何框架，通过归一化奇异值谱在Bloch超球上表示神经算子，证明了谱与功能之间的紧密等价关系，为跨模态和跨架构算子替换提供了理论基础。

Abstract: The rapid growth of multimodal intelligence on resource-constrained and heterogeneous domestic hardware exposes critical bottlenecks: multimodal feature heterogeneity, real-time requirements in dynamic scenarios, and hardware-specific operator redundancy. This work introduces a quantum-inspired geometric framework for neural operators that represents each operator by its normalized singular value spectrum on the Bloch hypersphere. We prove a tight spectral-to-functional equivalence theorem showing that vanishing Fubini--Study/Wasserstein-2 distance implies provable functional closeness, establishing the first rigorous foundation for cross-modal and cross-architecture operator substitutability. Based on this metric, we propose Quantum Metric-Driven Functional Redundancy Graphs (QM-FRG) and one-shot structured pruning. Controlled simulation validates the superiority of the proposed metric over magnitude and random baselines. An extensive experimental validation on large-scale multimodal transformers and domestic heterogeneous hardware (Huawei Ascend, Cambricon MLU, Kunlunxin) hardware is deferred to an extended journal version currently in preparation.

</details>


### [115] [Look, Recite, Then Answer: Enhancing VLM Performance via Self-Generated Knowledge Hints](https://arxiv.org/abs/2512.00882)
*Xisheng Feng*

Main category: cs.CV

TL;DR: 提出“Look, Recite, Then Answer”框架，通过解耦推理和自生成知识提示，显著提升视觉语言模型在专业领域的性能，缓解幻觉问题。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型在专业领域（如精准农业）中因“推理驱动幻觉”和“模态鸿沟”问题表现受限，需提升视觉嵌入对模型参数的细粒度专家知识的激活能力。

Method: 框架分为三个阶段：(1) Look生成客观视觉描述和候选集；(2) Recite通过轻量级路由器将视觉线索转化为目标查询以触发参数化知识；(3) Answer并行对齐描述与知识以选择最一致的标签。

Result: 在AgroBench上，该方法实现了最先进的性能，杂草识别准确率比Qwen-VL提高了23.6%，且无需外部搜索开销即超越GPT-4o。

Conclusion: 提出的“Look, Recite, Then Answer”框架通过解耦推理过程并利用自生成知识提示，显著提升了视觉语言模型在专业领域（如精准农业）的性能，有效缓解了“推理驱动幻觉”问题。

Abstract: Vision-Language Models (VLMs) exhibit significant performance plateaus in specialized domains like precision agriculture, primarily due to "Reasoning-Driven Hallucination" where linguistic priors override visual perception. A key bottleneck is the "Modality Gap": visual embeddings fail to reliably activate the fine-grained expert knowledge already encoded in model parameters. We propose "Look, Recite, Then Answer," a parameter-efficient framework that enhances VLMs via self-generated knowledge hints while keeping backbone models frozen. The framework decouples inference into three stages: (1) Look generates objective visual descriptions and candidate sets; (2) Recite employs a lightweight 1.7B router to transform visual cues into targeted queries that trigger candidate-specific parametric knowledge; (3) Answer performs parallel evidence alignment between descriptions and recited knowledge to select the most consistent label. On AgroBench, our method achieves state-of-the-art results, improving Weed Identification accuracy by 23.6% over Qwen-VL and surpassing GPT-4o without external search overhead. This modular design mitigates hallucinations by transforming passive perception into active, controllable knowledge retrieval

</details>


### [116] [HanDyVQA: A Video QA Benchmark for Fine-Grained Hand-Object Interaction Dynamics](https://arxiv.org/abs/2512.00885)
*Masatoshi Tateno,Gido Kato,Hirokatsu Kataoka,Yoichi Sato,Takuma Yagi*

Main category: cs.CV

TL;DR: HanDyVQA是一个细粒度视频问答基准，覆盖HOI的操作和效果，实验显示现有模型表现远低于人类，整合HOI线索可改进性能。


<details>
  <summary>Details</summary>
Motivation: 现有语义HOI基准测试仅关注操作或结果，缺乏对HOI动态的细粒度时空推理，因此需要更全面的评估工具。

Method: 通过设计六种互补问题类型（动作、过程、对象、位置、状态变化和对象部分），构建了包含11.1K多选题对的HanDyVQA基准测试，并标注了10.3K分割掩码。

Result: 实验显示，最佳模型Gemini-2.5-Pro平均准确率仅为73%，远低于人类表现（97%），揭示了空间关系、运动和部分几何理解的挑战。整合HOI相关线索可提升性能。

Conclusion: 论文提出HanDyVQA基准测试，揭示了现有视频基础模型在细粒度时空推理上的不足，并指出整合显式HOI相关线索可提升性能，为未来模型开发提供了方向。

Abstract: Hand-object interaction (HOI) inherently involves dynamics where human manipulations produce distinct spatio-temporal effects on objects. However, existing semantic HOI benchmarks focused either on manipulation or on the resulting effects at a coarse level, lacking fine-grained spatio-temporal reasoning to capture the underlying dynamics in HOI. We introduce HanDyVQA, a fine-grained video question-answering benchmark that comprehensively covers both the manipulation and effect aspects of HOI. HanDyVQA comprises six complementary question types (Action, Process, Objects, Location, State Change, and Object Parts), totalling 11.1K multiple-choice QA pairs. Collected QA pairs recognizing manipulation styles, hand/object motions, and part-level state changes. HanDyVQA also includes 10.3K segmentation masks for Objects and Object Parts questions, enabling the evaluation of object/part-level reasoning in video object segmentation. We evaluated recent video foundation models on our benchmark and found that even the best-performing model, Gemini-2.5-Pro, reached only 73% average accuracy, which is far from human performance (97%). Further analysis shows the remaining challenges in spatial relationship, motion, and part-level geometric understanding. We also found that integrating explicit HOI-related cues into visual features improves performance, offering insights for developing future models with a deeper understanding of HOI dynamics.

</details>


### [117] [Multilingual Training-Free Remote Sensing Image Captioning](https://arxiv.org/abs/2512.00887)
*Carlos Rebelo,Gil Rocha,João Daniel Silva,Bruno Martins*

Main category: cs.CV

TL;DR: 提出无需训练的多语言遥感图像描述方法，结合检索增强提示和图重排序，性能媲美全监督系统，显著提升多语言适用性。


<details>
  <summary>Details</summary>
Motivation: 解决现有遥感图像描述方法依赖大规模标注数据集和仅限于英语的问题，推动更具包容性和可扩展性的多模态地球观测系统。

Method: 采用检索增强提示方法，结合领域适应的SigLIP2编码器检索相关描述和少样本示例，探索了两种变体：图像盲设置（仅依赖文本提示的多语言LLM）和图像感知设置（联合处理提示和输入图像的VLM）。引入基于PageRank的图重排序策略以提升检索内容的连贯性。

Result: 在四个基准数据集和十种语言上的实验表明，该方法与全监督英语系统竞争，且PageRank重排序带来高达35%的性能提升。VLM生成视觉基础但词汇多样的描述，而LLM在BLEU和CIDEr得分上表现更优。直接生成目标语言描述优于翻译策略。

Conclusion: 该研究提出了一种无需训练的多语言遥感图像描述方法，通过检索增强提示和基于图的重排序策略，实现了与全监督英语系统相媲美的性能，并显著提升了多语言环境下的适用性。

Abstract: Remote sensing image captioning has advanced rapidly through encoder--decoder models, although the reliance on large annotated datasets and the focus on English restricts global applicability. To address these limitations, we propose the first training-free multilingual approach, based on retrieval-augmented prompting. For a given aerial image, we employ a domain-adapted SigLIP2 encoder to retrieve related captions and few-shot examples from a datastore, which are then provided to a language model. We explore two variants: an image-blind setup, where a multilingual Large Language Model (LLM) generates the caption from textual prompts alone, and an image-aware setup, where a Vision--Language Model (VLM) jointly processes the prompt and the input image. To improve the coherence of the retrieved content, we introduce a graph-based re-ranking strategy using PageRank on a graph of images and captions. Experiments on four benchmark datasets across ten languages demonstrate that our approach is competitive with fully supervised English-only systems and generalizes to other languages. Results also highlight the importance of re-ranking with PageRank, yielding up to 35% improvements in performance metrics. Additionally, it was observed that while VLMs tend to generate visually grounded but lexically diverse captions, LLMs can achieve stronger BLEU and CIDEr scores. Lastly, directly generating captions in the target language consistently outperforms other translation-based strategies. Overall, our work delivers one of the first systematic evaluations of multilingual, training-free captioning for remote sensing imagery, advancing toward more inclusive and scalable multimodal Earth observation systems.

</details>


### [118] [Accelerating Streaming Video Large Language Models via Hierarchical Token Compression](https://arxiv.org/abs/2512.00891)
*Yiyu Wang,Xuyang Liu,Xiyan Gui,Xinying Lin,Boxue Yang,Chenfei Liao,Tailai Chen,Linfeng Zhang*

Main category: cs.CV

TL;DR: STC通过缓存和压缩令牌优化流媒体视频大语言模型，显著降低延迟且保持高准确率。


<details>
  <summary>Details</summary>
Motivation: 流媒体视频大语言模型在实时部署中面临高计算成本和冗余处理的问题，需要优化ViT编码和LLM预填充阶段。

Method: 提出了Streaming Token Compression (STC)框架，包含STC-Cacher（缓存和重用相似帧特征）和STC-Pruner（压缩视觉令牌序列）。

Result: STC在四个基线模型和五个基准测试中表现优异，保持99%准确率的同时降低ViT编码延迟24.5%和LLM预填充延迟45.3%。

Conclusion: STC框架通过STC-Cacher和STC-Pruner两种加速器显著提升了流媒体视频大语言模型的效率，在保持高准确率的同时显著降低了延迟。

Abstract: Streaming Video Large Language Models (VideoLLMs) have demonstrated impressive performance across various video understanding tasks, but they face significant challenges in real-time deployment due to the high computational cost of processing dense visual tokens from continuous video streams. In streaming video scenarios, the primary bottleneck lies in the Vision Transformer (ViT) encoding stage, where redundant processing of temporally similar frames leads to inefficiency. Additionally, inflated token sequences during LLM pre-filling further exacerbate latency and memory overhead. To address these challenges, we propose \textbf{S}treaming \textbf{T}oken \textbf{C}ompression (\textbf{STC}), a plug-and-play hierarchical framework that seamlessly integrates into existing streaming VideoLLMs, optimizing both ViT encoding and LLM pre-filling stages to accelerate processing. STC introduces two token-level accelerators: \textbf{STC-Cacher}, which reduces ViT encoding overhead by caching and reusing features from temporally similar frames, and \textbf{STC-Pruner}, which compresses the visual token sequence before it enters the LLM, preserving only the most salient tokens based on both spatial and temporal relevance. Extensive experiments on four baseline streaming VideoLLMs across five benchmarks demonstrate that STC outperforms other compression methods. Notably, STC retains up to \textbf{99\%} of accuracy on the ReKV framework while reducing ViT encoding latency and LLM pre-filling latency by \textbf{24.5\%} and \textbf{45.3\%}.

</details>


### [119] [Hierarchical Semantic Alignment for Image Clustering](https://arxiv.org/abs/2512.00904)
*Xingyu Zhu,Beier Zhu,Yunfan Li,Junfeng Fang,Shuo Wang,Kesen Zhao,Hanwang Zhang*

Main category: cs.CV

TL;DR: CAE通过结合caption和noun语义，无需训练即可提升图像聚类性能，实验显示其显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法常忽略名词的固有歧义性，导致语义表示失真和聚类质量下降，因此需要一种能有效结合细粒度属性和高层对象类别的语义对齐方法。

Method: 提出了一种分层语义对齐方法（CAE），通过最优传输将图像特征与选定的名词和caption对齐，构建更具判别性的语义空间，并结合增强的语义和图像特征进行聚类。

Result: 在8个数据集上的实验表明，CAE方法显著优于现有无需训练的方法，在ImageNet-1K数据集上准确率提升4.2%，调整兰德指数（ARI）提升2.9%。

Conclusion: CAE方法通过结合caption-level描述和noun-level概念，构建了一个与图像特征对齐的语义空间，显著提升了图像聚类的性能，无需训练即可实现。

Abstract: Image clustering is a classic problem in computer vision, which categorizes images into different groups. Recent studies utilize nouns as external semantic knowledge to improve clus- tering performance. However, these methods often overlook the inherent ambiguity of nouns, which can distort semantic representations and degrade clustering quality. To address this issue, we propose a hierarChical semAntic alignmEnt method for image clustering, dubbed CAE, which improves cluster- ing performance in a training-free manner. In our approach, we incorporate two complementary types of textual seman- tics: caption-level descriptions, which convey fine-grained attributes of image content, and noun-level concepts, which represent high-level object categories. We first select relevant nouns from WordNet and descriptions from caption datasets to construct a semantic space aligned with image features. Then, we align image features with selected nouns and captions via optimal transport to obtain a more discriminative semantic space. Finally, we combine the enhanced semantic and image features to perform clustering. Extensive experiments across 8 datasets demonstrate the effectiveness of our method, notably surpassing the state-of-the-art training-free approach with a 4.2% improvement in accuracy and a 2.9% improvement in adjusted rand index (ARI) on the ImageNet-1K dataset.

</details>


### [120] [TalkingPose: Efficient Face and Gesture Animation with Feedback-guided Diffusion Model](https://arxiv.org/abs/2512.00909)
*Alireza Javanmardi,Pragati Jaiswal,Tewodros Amberbir Habtegebrial,Christen Millerdurai,Shaoxiang Wang,Alain Pagani,Didier Stricker*

Main category: cs.CV

TL;DR: TalkingPose是一种扩散框架，通过反馈驱动机制生成长时间、连贯的人体上半身动画，无需额外计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有方法受限于计算和内存，通常只能处理短视频片段，难以生成长时间连贯的内容。

Method: TalkingPose利用驱动帧精确捕捉面部和手部表情，通过稳定扩散主干无缝转移到目标角色，并引入基于图像扩散模型的反馈驱动机制确保连续运动和时间一致性。

Result: TalkingPose能够生成长时间、时间一致的动画，且不增加额外计算成本或需要二次训练阶段。

Conclusion: TalkingPose提出了一种新颖的扩散框架，专门用于生成长时间、时间一致的人体上半身动画，通过反馈驱动机制和稳定扩散主干，实现了无限制时长的动画生成。

Abstract: Recent advancements in diffusion models have significantly improved the realism and generalizability of character-driven animation, enabling the synthesis of high-quality motion from just a single RGB image and a set of driving poses. Nevertheless, generating temporally coherent long-form content remains challenging. Existing approaches are constrained by computational and memory limitations, as they are typically trained on short video segments, thus performing effectively only over limited frame lengths and hindering their potential for extended coherent generation. To address these constraints, we propose TalkingPose, a novel diffusion-based framework specifically designed for producing long-form, temporally consistent human upper-body animations. TalkingPose leverages driving frames to precisely capture expressive facial and hand movements, transferring these seamlessly to a target actor through a stable diffusion backbone. To ensure continuous motion and enhance temporal coherence, we introduce a feedback-driven mechanism built upon image-based diffusion models. Notably, this mechanism does not incur additional computational costs or require secondary training stages, enabling the generation of animations with unlimited duration. Additionally, we introduce a comprehensive, large-scale dataset to serve as a new benchmark for human upper-body animation.

</details>


### [121] [Dual-Projection Fusion for Accurate Upright Panorama Generation in Robotic Vision](https://arxiv.org/abs/2512.00911)
*Yuhao Shan,Qianyi Yuan,Jingguo Liu,Shigang Li,Jianfeng Li,Tong Chen*

Main category: cs.CV

TL;DR: 该论文提出了一种双流网络，结合CNN和ViT，通过双投影融合和多种增强机制，有效解决了非直立全景图像的校正问题，实验证明其优越性。


<details>
  <summary>Details</summary>
Motivation: 由于机器人姿态不稳定导致的非直立全景图像会阻碍下游任务，而传统的IMU校正方法存在漂移和外部干扰问题，因此需要一种基于视觉的替代方案。

Method: 研究采用了一个包含CNN分支和ViT分支的双流网络，分别从等距柱状投影中提取局部几何结构和从立方体映射投影中捕获全局上下文线索，并通过双投影自适应融合模块整合。

Result: 在SUN360和M3D数据集上的实验表明，该方法在倾斜角度估计和直立全景生成方面均优于现有方法。

Conclusion: 该研究提出的双流角度感知生成网络在相机倾斜角度估计和直立全景图像重建方面优于现有方法，各模块的贡献通过消融研究得到验证。

Abstract: Panoramic cameras, capable of capturing a 360-degree field of view, are crucial in robotic vision, particularly in environments with sparse features. However, non-upright panoramas due to unstable robot postures hinder downstream tasks. Traditional IMU-based correction methods suffer from drift and external disturbances, while vision-based approaches offer a promising alternative. This study presents a dual-stream angle-aware generation network that jointly estimates camera inclination angles and reconstructs upright panoramic images. The network comprises a CNN branch that extracts local geometric structures from equirectangular projections and a ViT branch that captures global contextual cues from cubemap projections. These are integrated through a dual-projection adaptive fusion module that aligns spatial features across both domains. To further enhance performance, we introduce a high-frequency enhancement block, circular padding, and channel attention mechanisms to preserve 360° continuity and improve geometric sensitivity. Experiments on the SUN360 and M3D datasets demonstrate that our method outperforms existing approaches in both inclination estimation and upright panorama generation. Ablation studies further validate the contribution of each module and highlight the synergy between the two tasks. The code and related datasets can be found at: https://github.com/YuhaoShine/DualProjectionFusion.

</details>


### [122] [ForamDeepSlice: A High-Accuracy Deep Learning Framework for Foraminifera Species Classification from 2D Micro-CT Slices](https://arxiv.org/abs/2512.00912)
*Abdelghafour Halimi,Ali Alibrahim,Didier Barradas-Bautista,Ronell Sicat,Abdulkader M. Afifi*

Main category: cs.CV

TL;DR: 本研究利用深度学习对12种有孔虫物种进行自动化分类，通过集成模型达到高准确率，并开发了交互式仪表板支持实时分类。


<details>
  <summary>Details</summary>
Motivation: 开发一个全面的深度学习流程，用于自动化分类12种有孔虫物种，以提升微古生物学识别的准确性和效率。

Method: 研究采用了七种最先进的2D卷积神经网络（CNN）架构进行迁移学习，最终结合ConvNeXt-Large和EfficientNetV2-Small构建了集成模型。数据集包含97个微CT扫描样本，从中选取了12个物种的109,617张高质量2D切片进行标本级数据分割。

Result: 最终集成模型在测试集上达到了95.64%的准确率，前3准确率为99.6%，所有物种的ROC曲线下面积（AUC）为0.998。

Conclusion: 本研究为AI辅助的微古生物学鉴定设立了新基准，并提供了一个完全可复现的有孔虫分类研究框架，弥合了深度学习与应用地球科学之间的差距。

Abstract: This study presents a comprehensive deep learning pipeline for the automated classification of 12 foraminifera species using 2D micro-CT slices derived from 3D scans. We curated a scientifically rigorous dataset comprising 97 micro-CT scanned specimens across 27 species, selecting 12 species with sufficient representation for robust machine learning. To ensure methodological integrity and prevent data leakage, we employed specimen-level data splitting, resulting in 109,617 high-quality 2D slices (44,103 for training, 14,046 for validation, and 51,468 for testing). We evaluated seven state-of-the-art 2D convolutional neural network (CNN) architectures using transfer learning. Our final ensemble model, combining ConvNeXt-Large and EfficientNetV2-Small, achieved a test accuracy of 95.64%, with a top-3 accuracy of 99.6% and an area under the ROC curve (AUC) of 0.998 across all species. To facilitate practical deployment, we developed an interactive advanced dashboard that supports real-time slice classification and 3D slice matching using advanced similarity metrics, including SSIM, NCC, and the Dice coefficient. This work establishes new benchmarks for AI-assisted micropaleontological identification and provides a fully reproducible framework for foraminifera classification research, bridging the gap between deep learning and applied geosciences.

</details>


### [123] [LAHNet: Local Attentive Hashing Network for Point Cloud Registration](https://arxiv.org/abs/2512.00927)
*Wentao Qu,Xiaoshui Huang,Liang Xiao*

Main category: cs.CV

TL;DR: LAHNet通过局部注意力机制和窗口策略提升点云特征独特性，在真实场景中取得显著配准效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的点云描述符主要关注局部信息，但合理的广域感受野对提升特征独特性至关重要。

Method: LAHNet采用局部注意力机制，设计Group Transformer捕获点间长程上下文，并利用Locality-Sensitive Hashing均匀划分点云。通过交叉窗口策略扩展特征感受野，并引入Interaction Transformer增强点云对重叠区域的特征交互。

Result: LAHNet在真实世界的室内外基准测试中表现出色，能够学习到鲁棒且独特的特征。

Conclusion: LAHNet通过引入局部注意力机制和创新的窗口策略，成功提升了点云特征的独特性和鲁棒性，在真实世界的室内外基准测试中取得了显著的配准效果。

Abstract: Most existing learning-based point cloud descriptors for point cloud registration focus on perceiving local information of point clouds to generate distinctive features. However, a reasonable and broader receptive field is essential for enhancing feature distinctiveness. In this paper, we propose a Local Attentive Hashing Network for point cloud registration, called LAHNet, which introduces a local attention mechanism with the inductive bias of locality of convolution-like operators into point cloud descriptors. Specifically, a Group Transformer is designed to capture reasonable long-range context between points. This employs a linear neighborhood search strategy, Locality-Sensitive Hashing, enabling uniformly partitioning point clouds into non-overlapping windows. Meanwhile, an efficient cross-window strategy is adopted to further expand the reasonable feature receptive field. Furthermore, building on this effective windowing strategy, we propose an Interaction Transformer to enhance the feature interactions of the overlap regions within point cloud pairs. This computes an overlap matrix to match overlap regions between point cloud pairs by representing each window as a global signal. Extensive results demonstrate that LAHNet can learn robust and distinctive features, achieving significant registration results on real-world indoor and outdoor benchmarks.

</details>


### [124] [SceneProp: Combining Neural Network and Markov Random Field for Scene-Graph Grounding](https://arxiv.org/abs/2512.00936)
*Keita Otani,Tatsuya Harada*

Main category: cs.CV

TL;DR: SceneProp通过MRF的MAP推理方法，显著提升复杂视觉查询的定位性能，性能随查询复杂性增加而提升。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在处理复杂关系描述时的结构性不足，尤其是在查询图增大时性能下降的问题。

Method: SceneProp采用马尔可夫随机场（MRF）中的最大后验（MAP）推理问题，通过全局推理和可微分的置信传播算法实现端到端框架。

Result: 在四个基准测试中，SceneProp显著优于先前工作，且准确性随查询图规模和复杂性增加而提高。

Conclusion: SceneProp通过将场景图接地重新表述为马尔可夫随机场中的最大后验推理问题，显著提升了复杂视觉查询的定位性能，其准确性随着查询图的规模和复杂性增加而提高。

Abstract: Grounding complex, compositional visual queries with multiple objects and relationships is a fundamental challenge for vision-language models. While standard phrase grounding methods excel at localizing single objects, they lack the structural inductive bias to parse intricate relational descriptions, often failing as queries become more descriptive. To address this structural deficit, we focus on scene-graph grounding, a powerful but less-explored formulation where the query is an explicit graph of objects and their relationships. However, existing methods for this task also struggle, paradoxically showing decreased performance as the query graph grows -- failing to leverage the very information that should make grounding easier. We introduce SceneProp, a novel method that resolves this issue by reformulating scene-graph grounding as a Maximum a Posteriori (MAP) inference problem in a Markov Random Field (MRF). By performing global inference over the entire query graph, SceneProp finds the optimal assignment of image regions to nodes that jointly satisfies all constraints. This is achieved within an end-to-end framework via a differentiable implementation of the Belief Propagation algorithm. Experiments on four benchmarks show that our dedicated focus on the scene-graph grounding formulation allows SceneProp to significantly outperform prior work. Critically, its accuracy consistently improves with the size and complexity of the query graph, demonstrating for the first time that more relational context can, and should, lead to better grounding. Codes are available at https://github.com/keitaotani/SceneProp.

</details>


### [125] [Binary-Gaussian: Compact and Progressive Representation for 3D Gaussian Segmentation](https://arxiv.org/abs/2512.00944)
*An Yang,Chenyu Liu,Jun Du,Jianqing Gao,Jia Pan,Jinshui Hu,Baocai Yin,Bing Yin,Cong Liu*

Main category: cs.CV

TL;DR: 提出了一种基于3D高斯泼溅的粗到细二进制编码方案和渐进式训练策略，显著降低内存使用并提升分割性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有3D-GS分割方法内存开销大和细粒度分割困难的局限性。

Method: 采用粗到细二进制编码方案压缩类别特征，设计渐进式训练策略分解全景分割任务，并调整不透明度以解决渲染与分割的不兼容问题。

Result: 在多个基准测试中实现了最先进的分割性能，同时显著降低内存消耗并加速推理。

Conclusion: 3D高斯泼溅（3D-GS）在语义分割任务中展现出高效性，但现有方法存在内存开销大和细粒度分割困难的问题。通过提出的粗到细二进制编码方案和渐进式训练策略，显著降低了内存使用并提升了分割性能。

Abstract: 3D Gaussian Splatting (3D-GS) has emerged as an efficient 3D representation and a promising foundation for semantic tasks like segmentation. However, existing 3D-GS-based segmentation methods typically rely on high-dimensional category features, which introduce substantial memory overhead. Moreover, fine-grained segmentation remains challenging due to label space congestion and the lack of stable multi-granularity control mechanisms. To address these limitations, we propose a coarse-to-fine binary encoding scheme for per-Gaussian category representation, which compresses each feature into a single integer via the binary-to-decimal mapping, drastically reducing memory usage. We further design a progressive training strategy that decomposes panoptic segmentation into a series of independent sub-tasks, reducing inter-class conflicts and thereby enhancing fine-grained segmentation capability. Additionally, we fine-tune opacity during segmentation training to address the incompatibility between photometric rendering and semantic segmentation, which often leads to foreground-background confusion. Extensive experiments on multiple benchmarks demonstrate that our method achieves state-of-the-art segmentation performance while significantly reducing memory consumption and accelerating inference.

</details>


### [126] [Adaptive Evidential Learning for Temporal-Semantic Robustness in Moment Retrieval](https://arxiv.org/abs/2512.00953)
*Haojian Huang,Kaijing Ma,Jin Chen,Haodong Chen,Zhou Wu,Xianghao Zang,Han Fang,Chao Ban,Hao Sun,Mulin Chen,Zhongjiang He*

Main category: cs.CV

TL;DR: 提出DEMR框架，通过RFF块和查询重构任务解决模态不平衡和不确定性偏差问题，实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 传统方法在细粒度信息和确定性推理上表现不足，且无法有效处理模态不平衡和不确定性估计偏差。

Method: 提出Debiased Evidential Learning for Moment Retrieval (DEMR)框架，包含Reflective Flipped Fusion (RFF)块和查询重构任务，并引入Geom-regularizer优化不确定性预测。

Result: 在ActivityNet-CD和Charades-CD数据集上测试显示，DEMR在效果、鲁棒性和可解释性上均有显著提升。

Conclusion: DEMR框架在标准数据集和去偏数据集上表现出显著的效果提升，为时刻检索任务提供了高效、鲁棒且可解释的解决方案。

Abstract: In the domain of moment retrieval, accurately identifying temporal segments within videos based on natural language queries remains challenging. Traditional methods often employ pre-trained models that struggle with fine-grained information and deterministic reasoning, leading to difficulties in aligning with complex or ambiguous moments. To overcome these limitations, we explore Deep Evidential Regression (DER) to construct a vanilla Evidential baseline. However, this approach encounters two major issues: the inability to effectively handle modality imbalance and the structural differences in DER's heuristic uncertainty regularizer, which adversely affect uncertainty estimation. This misalignment results in high uncertainty being incorrectly associated with accurate samples rather than challenging ones. Our observations indicate that existing methods lack the adaptability required for complex video scenarios. In response, we propose Debiased Evidential Learning for Moment Retrieval (DEMR), a novel framework that incorporates a Reflective Flipped Fusion (RFF) block for cross-modal alignment and a query reconstruction task to enhance text sensitivity, thereby reducing bias in uncertainty estimation. Additionally, we introduce a Geom-regularizer to refine uncertainty predictions, enabling adaptive alignment with difficult moments and improving retrieval accuracy. Extensive testing on standard datasets and debiased datasets ActivityNet-CD and Charades-CD demonstrates significant enhancements in effectiveness, robustness, and interpretability, positioning our approach as a promising solution for temporal-semantic robustness in moment retrieval. The code is publicly available at https://github.com/KaijingOfficial/DEMR.

</details>


### [127] [Efficient and Scalable Monocular Human-Object Interaction Motion Reconstruction](https://arxiv.org/abs/2512.00960)
*Boran Wen,Ye Lu,Keyan Wan,Sirui Wang,Jiahong Zhou,Junxuan Liang,Xinpeng Liu,Bang Xiao,Dingbang Huang,Ruiyang Liu,Yong-Lu Li*

Main category: cs.CV

TL;DR: 4DHOISolver框架通过人工标注接触点优化4D HOI重建，创建了Open4DHOI数据集，并验证了其有效性，但自动预测接触对应关系仍是挑战。


<details>
  <summary>Details</summary>
Motivation: 从单目互联网视频中准确且可扩展地提取4D交互数据是一个未解决的挑战，但这类视频提供了丰富多样的人类活动、物体和环境数据。

Method: 提出4DHOISolver，一种利用稀疏人工标注接触点来约束4D HOI重建问题的优化框架，同时保持高时空一致性和物理合理性。

Result: 引入了Open4DHOI数据集，包含144种物体类型和103种动作，并通过RL代理验证了重建效果。

Conclusion: 尽管现有的3D基础模型在预测精确的人-物体接触对应关系方面仍存在挑战，但4DHOISolver框架和Open4DHOI数据集为4D HOI重建提供了有效的解决方案，并通过RL代理验证了其有效性。

Abstract: Generalized robots must learn from diverse, large-scale human-object interactions (HOI) to operate robustly in the real world. Monocular internet videos offer a nearly limitless and readily available source of data, capturing an unparalleled diversity of human activities, objects, and environments. However, accurately and scalably extracting 4D interaction data from these in-the-wild videos remains a significant and unsolved challenge. Thus, in this work, we introduce 4DHOISolver, a novel and efficient optimization framework that constrains the ill-posed 4D HOI reconstruction problem by leveraging sparse, human-in-the-loop contact point annotations, while maintaining high spatio-temporal coherence and physical plausibility. Leveraging this framework, we introduce Open4DHOI, a new large-scale 4D HOI dataset featuring a diverse catalog of 144 object types and 103 actions. Furthermore, we demonstrate the effectiveness of our reconstructions by enabling an RL-based agent to imitate the recovered motions. However, a comprehensive benchmark of existing 3D foundation models indicates that automatically predicting precise human-object contact correspondences remains an unsolved problem, underscoring the immediate necessity of our human-in-the-loop strategy while posing an open challenge to the community. Data and code will be publicly available at https://wenboran2002.github.io/open4dhoi/

</details>


### [128] [PhotoFramer: Multi-modal Image Composition Instruction](https://arxiv.org/abs/2512.00993)
*Zhiyuan You,Ke Wang,He Zhang,Xin Cai,Jinjin Gu,Tianfan Xue,Chao Dong,Zhoutong Zhang*

Main category: cs.CV

TL;DR: PhotoFramer是一个多模态构图指导框架，通过文本和示例图像帮助用户改善构图，数据集和模型已开源。


<details>
  <summary>Details</summary>
Motivation: 解决普通用户在拍摄过程中构图困难的问题，提供专业的构图指导。

Method: 通过构建大规模数据集，包括平移、放大和视角变换子任务，并利用退化模型合成训练数据，训练了一个多模态模型，能够生成文本指导和示例图像。

Result: 实验表明，结合文本指导和示例图像的方法在构图改进上优于仅使用示例的基线方法。

Conclusion: PhotoFramer通过结合文本指导和示例图像，有效提升了图像构图质量，为普通用户提供了专业的构图辅助工具。

Abstract: Composition matters during the photo-taking process, yet many casual users struggle to frame well-composed images. To provide composition guidance, we introduce PhotoFramer, a multi-modal composition instruction framework. Given a poorly composed image, PhotoFramer first describes how to improve the composition in natural language and then generates a well-composed example image. To train such a model, we curate a large-scale dataset. Inspired by how humans take photos, we organize composition guidance into a hierarchy of sub-tasks: shift, zoom-in, and view-change tasks. Shift and zoom-in data are sampled from existing cropping datasets, while view-change data are obtained via a two-stage pipeline. First, we sample pairs with varying viewpoints from multi-view datasets, and train a degradation model to transform well-composed photos into poorly composed ones. Second, we apply this degradation model to expert-taken photos to synthesize poor images to form training pairs. Using this dataset, we finetune a model that jointly processes and generates both text and images, enabling actionable textual guidance with illustrative examples. Extensive experiments demonstrate that textual instructions effectively steer image composition, and coupling them with exemplars yields consistent improvements over exemplar-only baselines. PhotoFramer offers a practical step toward composition assistants that make expert photographic priors accessible to everyday users. Codes, model weights, and datasets have been released in https://zhiyuanyou.github.io/photoframer.

</details>


### [129] [S2AM3D: Scale-controllable Part Segmentation of 3D Point Cloud](https://arxiv.org/abs/2512.00995)
*Han Su,Tianyu Huang,Zichen Wan,Xiaohe Wu,Wangmeng Zuo*

Main category: cs.CV

TL;DR: S2AM3D结合2D分割先验与3D一致性监督，通过点一致性编码器和尺度感知解码器，解决了点云分割的泛化性和视图一致性问题，并在新数据集的支撑下取得了优异性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究受限于数据稀缺导致的3D模型泛化能力不足，以及引入2D预训练知识导致的视图间分割结果不一致。

Method: 设计了一个点一致性部分编码器，通过原生3D对比学习聚合多视图2D特征，并提出了一个尺度感知提示解码器，通过连续尺度信号实时调整分割粒度。同时，引入了一个大规模高质量的点云数据集。

Result: S2AM3D在多个评估设置中取得了领先性能，处理复杂结构和尺寸变化大的部分时表现出卓越的鲁棒性和可控性。

Conclusion: S2AM3D通过结合2D分割先验与3D一致性监督，解决了现有方法在泛化性和视图一致性上的挑战，实现了高性能、鲁棒性和可控性的点云分割。

Abstract: Part-level point cloud segmentation has recently attracted significant attention in 3D computer vision. Nevertheless, existing research is constrained by two major challenges: native 3D models lack generalization due to data scarcity, while introducing 2D pre-trained knowledge often leads to inconsistent segmentation results across different views. To address these challenges, we propose S2AM3D, which incorporates 2D segmentation priors with 3D consistent supervision. We design a point-consistent part encoder that aggregates multi-view 2D features through native 3D contrastive learning, producing globally consistent point features. A scale-aware prompt decoder is then proposed to enable real-time adjustment of segmentation granularity via continuous scale signals. Simultaneously, we introduce a large-scale, high-quality part-level point cloud dataset with more than 100k samples, providing ample supervision signals for model training. Extensive experiments demonstrate that S2AM3D achieves leading performance across multiple evaluation settings, exhibiting exceptional robustness and controllability when handling complex structures and parts with significant size variations.

</details>


### [130] [Provenance-Driven Reliable Semantic Medical Image Vector Reconstruction via Lightweight Blockchain-Verified Latent Fingerprints](https://arxiv.org/abs/2512.00999)
*Mohsin Rasheed,Abdullah Al-Mamun*

Main category: cs.CV

TL;DR: 提出语义感知医学图像重建框架，结合U-Net和区块链，提升临床可靠性和溯源能力。


<details>
  <summary>Details</summary>
Motivation: 解决传统重建技术在像素级恢复中可能损害解剖结构保真度的问题，同时确保重建过程的可追溯性。

Method: 采用混合U-Net架构和高级潜在嵌入，结合轻量级区块链溯源层，实现语义感知的图像重建。

Result: 在多数据集和多种损坏类型下的评估显示，该方法在结构一致性、重建准确性和溯源完整性上优于现有方法。

Conclusion: 该论文提出了一种结合语义感知和区块链技术的医学图像重建框架，旨在提升临床诊断的可靠性和监管合规性。

Abstract: Medical imaging is essential for clinical diagnosis, yet real-world data frequently suffers from corruption, noise, and potential tampering, challenging the reliability of AI-assisted interpretation. Conventional reconstruction techniques prioritize pixel-level recovery and may produce visually plausible outputs while compromising anatomical fidelity, an issue that can directly impact clinical outcomes. We propose a semantic-aware medical image reconstruction framework that integrates high-level latent embeddings with a hybrid U-Net architecture to preserve clinically relevant structures during restoration. To ensure trust and accountability, we incorporate a lightweight blockchain-based provenance layer using scale-free graph design, enabling verifiable recording of each reconstruction event without imposing significant overhead. Extensive evaluation across multiple datasets and corruption types demonstrates improved structural consistency, restoration accuracy, and provenance integrity compared with existing approaches. By uniting semantic-guided reconstruction with secure traceability, our solution advances dependable AI for medical imaging, enhancing both diagnostic confidence and regulatory compliance in healthcare environments.

</details>


### [131] [LISA-3D: Lifting Language-Image Segmentation to 3D via Multi-View Consistency](https://arxiv.org/abs/2512.01008)
*Zhongbin Guo,Jiahe Liu,Wenyu Gao,Yushan Li,Chengzhi Li,Ping Jian*

Main category: cs.CV

TL;DR: LISA-3D通过两阶段框架提升语言到3D的准确性，支持零样本部署，适用于语言引导的3D内容创建。


<details>
  <summary>Details</summary>
Motivation: 解决文本驱动的3D重建需要同时理解开放词汇指令并保持跨视角一致性的问题。

Method: LISA-3D 是一个两阶段框架，通过几何感知的LoRA层改造指令跟随模型LISA，并重用冻结的SAM-3D重建器，利用RGB-D序列和相机姿态构建可微分重投影损失。

Result: 在ScanRefer和Nr3D上，LISA-3D比单视角基线提高了语言到3D准确率高达15.6个百分点，仅调整了11.6M参数。

Conclusion: LISA-3D 提供了一个模块化、数据高效且支持零样本部署的解决方案，为语言引导的3D内容创建提供了实用方案。

Abstract: Text-driven 3D reconstruction demands a mask generator that simultaneously understands open-vocabulary instructions and remains consistent across viewpoints. We present LISA-3D, a two-stage framework that lifts language-image segmentation into 3D by retrofitting the instruction-following model LISA with geometry-aware Low-Rank Adaptation (LoRA) layers and reusing a frozen SAM-3D reconstructor. During training we exploit off-the-shelf RGB-D sequences and their camera poses to build a differentiable reprojection loss that enforces cross-view agreement without requiring any additional 3D-text supervision. The resulting masks are concatenated with RGB images to form RGBA prompts for SAM-3D, which outputs Gaussian splats or textured meshes without retraining. Across ScanRefer and Nr3D, LISA-3D improves language-to-3D accuracy by up to +15.6 points over single-view baselines while adapting only 11.6M parameters. The system is modular, data-efficient, and supports zero-shot deployment on unseen categories, providing a practical recipe for language-guided 3D content creation. Our code will be available at https://github.com/binisalegend/LISA-3D.

</details>


### [132] [Lotus-2: Advancing Geometric Dense Prediction with Powerful Image Generative Model](https://arxiv.org/abs/2512.01030)
*Jing He,Haodong Li,Mingzhi Sheng,Ying-Cong Chen*

Main category: cs.CV

TL;DR: Lotus-2 is a two-stage framework leveraging diffusion models for stable and accurate geometric dense prediction, achieving SOTA results with minimal training data.


<details>
  <summary>Details</summary>
Motivation: The paper addresses the ill-posed nature of recovering pixel-wise geometric properties from a single image due to appearance ambiguity and non-injective mappings. It aims to exploit pre-trained generative priors for stable, accurate, and fine-grained geometric dense prediction.

Method: Lotus-2 employs a two-stage deterministic framework: a core predictor with a single-step deterministic formulation and a lightweight local continuity module (LCM) for globally coherent structures, followed by a detail sharpener performing constrained multi-step rectified-flow refinement for fine-grained geometry.

Result: Using only 59K training samples (less than 1% of existing datasets), Lotus-2 achieves state-of-the-art results in monocular depth estimation and competitive surface normal prediction.

Conclusion: Lotus-2 demonstrates that diffusion models can serve as deterministic world priors, enabling high-quality geometric reasoning beyond traditional discriminative and generative paradigms.

Abstract: Recovering pixel-wise geometric properties from a single image is fundamentally ill-posed due to appearance ambiguity and non-injective mappings between 2D observations and 3D structures. While discriminative regression models achieve strong performance through large-scale supervision, their success is bounded by the scale, quality and diversity of available data and limited physical reasoning. Recent diffusion models exhibit powerful world priors that encode geometry and semantics learned from massive image-text data, yet directly reusing their stochastic generative formulation is suboptimal for deterministic geometric inference: the former is optimized for diverse and high-fidelity image generation, whereas the latter requires stable and accurate predictions. In this work, we propose Lotus-2, a two-stage deterministic framework for stable, accurate and fine-grained geometric dense prediction, aiming to provide an optimal adaption protocol to fully exploit the pre-trained generative priors. Specifically, in the first stage, the core predictor employs a single-step deterministic formulation with a clean-data objective and a lightweight local continuity module (LCM) to generate globally coherent structures without grid artifacts. In the second stage, the detail sharpener performs a constrained multi-step rectified-flow refinement within the manifold defined by the core predictor, enhancing fine-grained geometry through noise-free deterministic flow matching. Using only 59K training samples, less than 1% of existing large-scale datasets, Lotus-2 establishes new state-of-the-art results in monocular depth estimation and highly competitive surface normal prediction. These results demonstrate that diffusion models can serve as deterministic world priors, enabling high-quality geometric reasoning beyond traditional discriminative and generative paradigms.

</details>


### [133] [Parameter Reduction Improves Vision Transformers: A Comparative Study of Sharing and Width Reduction](https://arxiv.org/abs/2512.01059)
*Anantha Padmanaban Krishna Kumar*

Main category: cs.CV

TL;DR: ViT-B/16在ImageNet-1K上可能过参数化，减少MLP容量（通过参数共享或隐藏层减半）可提升性能和训练稳定性，同时保持或提高效率。


<details>
  <summary>Details</summary>
Motivation: 尽管扩展定律和许多实证结果表明增大Vision Transformer规模通常能提升性能，但模型准确性和训练行为并不总是随规模单调增加。因此，探索参数减少策略对性能和效率的影响。

Method: 研究通过两种简单的参数减少策略（GroupedMLP和ShallowMLP）应用于ViT-B/16的MLP块，分别移除32.7%的基线参数。GroupedMLP在相邻Transformer块间共享MLP权重，ShallowMLP则将MLP隐藏维度减半。

Result: GroupedMLP和ShallowMLP分别达到81.47%和81.25%的top-1准确率，均优于基线（81.05%），且训练稳定性显著提升，峰值到最终准确率下降从0.47%降至0.03%-0.06%。

Conclusion: 研究发现，在ViT-B/16和ImageNet-1K的标准训练方案下，模型处于过参数化状态，减少MLP容量不仅不会损害性能，甚至可能轻微提升。此外，参数共享和宽度减少等架构约束可作为有用的归纳偏置，参数分配方式对Vision Transformer设计至关重要。

Abstract: Although scaling laws and many empirical results suggest that increasing the size of Vision Transformers often improves performance, model accuracy and training behavior are not always monotonically increasing with scale. Focusing on ViT-B/16 trained on ImageNet-1K, we study two simple parameter-reduction strategies applied to the MLP blocks, each removing 32.7\% of the baseline parameters. Our \emph{GroupedMLP} variant shares MLP weights between adjacent transformer blocks and achieves 81.47\% top-1 accuracy while maintaining the baseline computational cost. Our \emph{ShallowMLP} variant halves the MLP hidden dimension and reaches 81.25\% top-1 accuracy with a 38\% increase in inference throughput. Both models outperform the 86.6M-parameter baseline (81.05\%) and exhibit substantially improved training stability, reducing peak-to-final accuracy degradation from 0.47\% to the range 0.03\% to 0.06\%. These results suggest that, for ViT-B/16 on ImageNet-1K with a standard training recipe, the model operates in an overparameterized regime in which MLP capacity can be reduced without harming performance and can even slightly improve it. More broadly, our findings suggest that architectural constraints such as parameter sharing and reduced width may act as useful inductive biases, and highlight the importance of how parameters are allocated when designing Vision Transformers. All code is available at: https://github.com/AnanthaPadmanaban-KrishnaKumar/parameter-efficient-vit-mlps.

</details>


### [134] [TRoVe: Discovering Error-Inducing Static Feature Biases in Temporal Vision-Language Models](https://arxiv.org/abs/2512.01048)
*Maya Varma,Jean-Benoit Delbrouck,Sophie Ostmeier,Akshay Chaudhari,Curtis Langlotz*

Main category: cs.CV

TL;DR: TRoVe是一种自动发现VLM中静态特征偏差的方法，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 发现并消除VLM在时间理解任务中依赖的静态特征偏差，以避免系统性预测错误。

Method: TRoVe通过从标注验证数据集中提取候选静态特征，并基于其对分类错误的影响及VLM的依赖程度进行评分。

Result: TRoVe在101个训练VLM上表现优于基线28.6%，并在7个现成VLM和2个任务中揭示了未知的静态特征偏差。

Conclusion: TRoVe能有效识别VLM中的静态特征偏差，并在测试时提升模型性能。

Abstract: Vision-language models (VLMs) have made great strides in addressing temporal understanding tasks, which involve characterizing visual changes across a sequence of images. However, recent works have suggested that when making predictions, VLMs may rely on static feature biases, such as background or object features, rather than dynamic visual changes. Static feature biases are a type of shortcut and can contribute to systematic prediction errors on downstream tasks; as a result, identifying and characterizing error-inducing static feature biases is critical prior to real-world model deployment. In this work, we introduce TRoVe, an automated approach for discovering error-inducing static feature biases learned by temporal VLMs. Given a trained VLM and an annotated validation dataset associated with a downstream classification task, TRoVe extracts candidate static features from the dataset and scores each feature by (i) the effect of the feature on classification errors as well as (ii) the extent to which the VLM relies on the feature when making predictions. In order to quantitatively evaluate TRoVe, we introduce an evaluation framework consisting of 101 trained temporal VLMs paired with ground-truth annotations for learned static feature biases. We use this framework to demonstrate that TRoVe can accurately identify error-inducing static feature biases in VLMs, achieving a 28.6% improvement over the closest baseline. Finally, we apply TRoVe to 7 off-the-shelf VLMs and 2 temporal understanding tasks, surfacing previously-unknown static feature biases and demonstrating that knowledge of learned biases can aid in improving model performance at test time. Our code is available at https://github.com/Stanford-AIMI/TRoVe.

</details>


### [135] [CycliST: A Video Language Model Benchmark for Reasoning on Cyclical State Transitions](https://arxiv.org/abs/2512.01095)
*Simon Kohaut,Daniel Ochs,Shun Zhang,Benedict Flade,Julian Eggert,Kristian Kersting,Devendra Singh Dhami*

Main category: cs.CV

TL;DR: CycliST 是一个评估视频语言模型周期性推理能力的新基准数据集，揭示了现有模型的局限性，并为未来研究提供了方向。


<details>
  <summary>Details</summary>
Motivation: 现有视频语言模型在理解周期性动态（如线性运动、轨道运动及时间依赖性视觉属性变化）方面存在显著不足，需要新的评估工具来推动技术进步。

Method: 通过生成具有周期性模式的合成视频序列，并采用分层评估系统，逐步增加难度，测试模型在时空认知上的表现。

Result: 实验表明，当前最先进的视频语言模型在检测和利用周期性模式、时间理解及提取定量信息方面表现不佳，且没有单一模型在所有任务上表现一致领先。

Conclusion: CycliST 作为一个新颖的基准数据集，揭示了当前视频语言模型在周期性状态转换理解上的局限性，并为未来模型的发展提供了方向。

Abstract: We present CycliST, a novel benchmark dataset designed to evaluate Video Language Models (VLM) on their ability for textual reasoning over cyclical state transitions. CycliST captures fundamental aspects of real-world processes by generating synthetic, richly structured video sequences featuring periodic patterns in object motion and visual attributes. CycliST employs a tiered evaluation system that progressively increases difficulty through variations in the number of cyclic objects, scene clutter, and lighting conditions, challenging state-of-the-art models on their spatio-temporal cognition. We conduct extensive experiments with current state-of-the-art VLMs, both open-source and proprietary, and reveal their limitations in generalizing to cyclical dynamics such as linear and orbital motion, as well as time-dependent changes in visual attributes like color and scale. Our results demonstrate that present-day VLMs struggle to reliably detect and exploit cyclic patterns, lack a notion of temporal understanding, and are unable to extract quantitative insights from scenes, such as the number of objects in motion, highlighting a significant technical gap that needs to be addressed. More specifically, we find no single model consistently leads in performance: neither size nor architecture correlates strongly with outcomes, and no model succeeds equally well across all tasks. By providing a targeted challenge and a comprehensive evaluation framework, CycliST paves the way for visual reasoning models that surpass the state-of-the-art in understanding periodic patterns.

</details>


### [136] [Generalized Medical Phrase Grounding](https://arxiv.org/abs/2512.01085)
*Wenjun Zhang,Shekhar S. Chandra,Aaron Nicolson*

Main category: cs.CV

TL;DR: MedGrounder是一种广义医学短语接地模型，通过两阶段训练处理多区域和非可接地短语，性能优于现有方法且标注需求低。


<details>
  <summary>Details</summary>
Motivation: 现有MPG系统通常假设每个短语对应一个边界框，但实际报告中存在多区域发现、非诊断文本和非可接地短语，因此需要重新定义任务为广义医学短语接地（GMPG）。

Method: 采用两阶段训练策略：先在报告句子-解剖框对齐数据集上预训练，再在报告句子-人工标注框数据集上微调。

Result: 在PadChest-GR和MS-CXR数据集上，MedGrounder在零样本迁移和多区域、非可接地短语处理上优于REC风格和接地报告生成基线，且使用更少的人工标注。

Conclusion: MedGrounder成功地将医学报告中的文本描述映射到零个、一个或多个图像区域，支持多区域和非可接地短语的处理，且无需大量人工标注。

Abstract: Medical phrase grounding (MPG) maps textual descriptions of radiological findings to corresponding image regions. These grounded reports are easier to interpret, especially for non-experts. Existing MPG systems mostly follow the referring expression comprehension (REC) paradigm and return exactly one bounding box per phrase. Real reports often violate this assumption. They contain multi-region findings, non-diagnostic text, and non-groundable phrases, such as negations or descriptions of normal anatomy. Motivated by this, we reformulate the task as generalised medical phrase grounding (GMPG), where each sentence is mapped to zero, one, or multiple scored regions. To realise this formulation, we introduce the first GMPG model: MedGrounder. We adopted a two-stage training regime: pre-training on report sentence--anatomy box alignment datasets and fine-tuning on report sentence--human annotated box datasets. Experiments on PadChest-GR and MS-CXR show that MedGrounder achieves strong zero-shot transfer and outperforms REC-style and grounded report generation baselines on multi-region and non-groundable phrases, while using far fewer human box annotations. Finally, we show that MedGrounder can be composed with existing report generators to produce grounded reports without retraining the generator.

</details>


### [137] [SocialFusion: Addressing Social Degradation in Pre-trained Vision-Language Models](https://arxiv.org/abs/2512.01148)
*Hamza Tahboub,Weiyan Shi,Gang Hua,Huaizu Jiang*

Main category: cs.CV

TL;DR: 研究发现VLM预训练导致社交能力退化，提出SocialFusion框架解决多任务社交学习中的负迁移问题，并在多个任务中实现正迁移和SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 理解社交互动是AI社交能力的核心挑战，现有VLM在多任务社交感知学习中表现不佳，存在负迁移问题。

Method: 提出了SocialFusion框架，通过最小化连接冻结的视觉编码器和语言模型来解决问题。

Result: SocialFusion在所有五个社交任务中表现出正迁移，利用任务间的协同效应提升整体性能，并在多个基准测试中达到与任务专用SOTA模型相当的表现。

Conclusion: 当前VLM预训练策略可能不利于获取通用社交能力，强调了需要更具社交意识的训练范式。

Abstract: Understanding social interactions from visual cues is a fundamental challenge for a socially competent AI. While powerful pre-trained vision-language models (VLMs) have shown remarkable general capabilities, they surprisingly struggle to unify and learn multiple social perception tasks simultaneously, often exhibiting negative transfer. We identify that this negative transfer stems from a critical issue we term "social degradation," whereby the general visual-linguistic pre-training process of VLMs impairs the visual encoder's ability to represent nuanced social information. We investigate this behavior further under two lenses: decodability through linear representation probing and compatibility through gradient conflict analysis, revealing that both play a role in the degradation, especially the former, which is significantly compromised in the VLM pre-training process. To address these issues, we propose SocialFusion, a unified framework that learns a minimal connection between a frozen visual encoder and a language model. Compared with existing VLMs, it exhibits positive transfer across all five social tasks, leveraging synergies between them to enhance overall performance and achieves comparable performance to task-specific state-of-the-art models on various benchmarks. Our findings suggest that current VLM pre-training strategies may be detrimental to acquiring general social competence and highlight the need for more socially-aware training paradigms.

</details>


### [138] [Accelerating Inference of Masked Image Generators via Reinforcement Learning](https://arxiv.org/abs/2512.01094)
*Pranav Subbaraman,Shufan Li,Siyan Zhao,Aditya Grover*

Main category: cs.CV

TL;DR: Speed-RL 通过强化学习加速 MGM，实现 3 倍加速且保持图像质量。


<details>
  <summary>Details</summary>
Motivation: MGM 生成高质量图像需要大量采样步骤，导致推理速度慢。

Method: 提出 Speed-RL，将加速问题视为强化学习问题，结合质量奖励和速度奖励对基础模型进行微调。

Result: 实验表明，该方法能将基础模型加速 3 倍，且图像质量相当。

Conclusion: Speed-RL 成功地将预训练的 MGM 加速了 3 倍，同时保持了可比的图像质量。

Abstract: Masked Generative Models (MGM)s demonstrate strong capabilities in generating high-fidelity images. However, they need many sampling steps to create high-quality generations, resulting in slow inference speed. In this work, we propose Speed-RL, a novel paradigm for accelerating a pretrained MGMs to generate high-quality images in fewer steps. Unlike conventional distillation methods which formulate the acceleration problem as a distribution matching problem, where a few-step student model is trained to match the distribution generated by a many-step teacher model, we consider this problem as a reinforcement learning problem. Since the goal of acceleration is to generate high quality images in fewer steps, we can combine a quality reward with a speed reward and finetune the base model using reinforcement learning with the combined reward as the optimization target. Through extensive experiments, we show that the proposed method was able to accelerate the base model by a factor of 3x while maintaining comparable image quality.

</details>


### [139] [DPAC: Distribution-Preserving Adversarial Control for Diffusion Sampling](https://arxiv.org/abs/2512.01153)
*Han-Jin Lee,Han-Ju Lee,Jin-Seong Kim,Seok-Hwan Choi*

Main category: cs.CV

TL;DR: DPAC通过切空间投影对抗梯度，减少路径KL散度，提升扩散采样的样本质量。


<details>
  <summary>Details</summary>
Motivation: 解决对抗引导扩散采样中样本质量因控制轨迹与名义轨迹偏差累积而下降的问题。

Method: 通过随机最优控制（SOC）视角，将路径KL散度与控制能量联系起来，并推导出控制的一阶最优条件，提出DPAC方法。

Result: DPAC在ImageNet-100上验证了理论预测，实现了更低的FID和路径KL估计值。

Conclusion: DPAC（Distribution-Preserving Adversarial Control）通过将对抗梯度投影到生成评分几何定义的切空间，有效减少了路径KL散度，从而在保持攻击成功率的同时提升了样本质量和感知保真度。

Abstract: Adversarially guided diffusion sampling often achieves the target class, but sample quality degrades as deviations between the adversarially controlled and nominal trajectories accumulate. We formalize this degradation as a path-space Kullback-Leibler divergence(path-KL) between controlled and nominal (uncontrolled) diffusion processes, thereby showing via Girsanov's theorem that it exactly equals the control energy. Building on this stochastic optimal control (SOC) view, we theoretically establish that minimizing this path-KL simultaneously tightens upper bounds on both the 2-Wasserstein distance and Fréchet Inception Distance (FID), revealing a principled connection between adversarial control energy and perceptual fidelity. From a variational perspective, we derive a first-order optimality condition for the control: among all directions that yield the same classification gain, the component tangent to iso-(log-)density surfaces (i.e., orthogonal to the score) minimizes path-KL, whereas the normal component directly increases distributional drift. This leads to DPAC (Distribution-Preserving Adversarial Control), a diffusion guidance rule that projects adversarial gradients onto the tangent space defined by the generative score geometry. We further show that in discrete solvers, the tangent projection cancels the O(Δt) leading error term in the Wasserstein distance, achieving an O(Δt^2) quality gap; moreover, it remains second-order robust to score or metric approximation. Empirical studies on ImageNet-100 validate the theoretical predictions, confirming that DPAC achieves lower FID and estimated path-KL at matched attack success rates.

</details>


### [140] [Learning Eigenstructures of Unstructured Data Manifolds](https://arxiv.org/abs/2512.01103)
*Roy Velich,Arkadi Piven,David Bensaïd,Daniel Cremers,Thomas Dagès,Ron Kimmel*

Main category: cs.CV

TL;DR: 提出了一种学习光谱基的新框架，无需传统算子选择和特征求解，适用于非结构化数据和高维空间。


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理非结构化数据时存在局限性，特别是在高维空间中。本文旨在提供一个无需假设数据流形（如网格化或流形维度）的统一框架。

Method: 通过最优逼近理论，训练网络在选定的探测函数分布上最小化重构误差，从而分解隐式逼近算子。

Result: 在3D表面点云和高维图像流形上，该方法生成了有意义的光谱基，类似于拉普拉斯算子的基，而无需显式构建算子。

Conclusion: 该论文提出了一种基于学习的光谱基框架，为形状和流形分析提供了数据驱动的替代方案，无需传统的算子选择、离散化和特征求解器。

Abstract: We introduce a novel framework that directly learns a spectral basis for shape and manifold analysis from unstructured data, eliminating the need for traditional operator selection, discretization, and eigensolvers. Grounded in optimal-approximation theory, we train a network to decompose an implicit approximation operator by minimizing the reconstruction error in the learned basis over a chosen distribution of probe functions. For suitable distributions, they can be seen as an approximation of the Laplacian operator and its eigendecomposition, which are fundamental in geometry processing. Furthermore, our method recovers in a unified manner not only the spectral basis, but also the implicit metric's sampling density and the eigenvalues of the underlying operator. Notably, our unsupervised method makes no assumption on the data manifold, such as meshing or manifold dimensionality, allowing it to scale to arbitrary datasets of any dimension. On point clouds lying on surfaces in 3D and high-dimensional image manifolds, our approach yields meaningful spectral bases, that can resemble those of the Laplacian, without explicit construction of an operator. By replacing the traditional operator selection, construction, and eigendecomposition with a learning-based approach, our framework offers a principled, data-driven alternative to conventional pipelines. This opens new possibilities in geometry processing for unstructured data, particularly in high-dimensional spaces.

</details>


### [141] [Structural Prognostic Event Modeling for Multimodal Cancer Survival Analysis](https://arxiv.org/abs/2512.01116)
*Yilan Zhang,Li Nanbo,Changchun Yang,Jürgen Schmidhuber,Xin Gao*

Main category: cs.CV

TL;DR: SlotSPE通过槽注意力机制建模多模态数据中的稀疏预后事件，显著提升癌症生存预测性能。


<details>
  <summary>Details</summary>
Motivation: 当前方法难以高效建模多模态数据中的复杂交互，且难以捕捉稀疏但关键的预后事件。

Method: 提出SlotSPE框架，利用槽注意力机制将多模态输入压缩为紧凑且互斥的槽表示，以建模预后事件。

Result: 在10个癌症基准测试中，SlotSPE在8个队列中优于现有方法，整体性能提升2.9%，且在基因组数据缺失时表现稳健。

Conclusion: SlotSPE框架通过基于槽的建模方法，有效解决了多模态数据中稀疏且患者特异性的预后事件建模问题，显著提升了预测性能和可解释性。

Abstract: The integration of histology images and gene profiles has shown great promise for improving survival prediction in cancer. However, current approaches often struggle to model intra- and inter-modal interactions efficiently and effectively due to the high dimensionality and complexity of the inputs. A major challenge is capturing critical prognostic events that, though few, underlie the complexity of the observed inputs and largely determine patient outcomes. These events, manifested as high-level structural signals such as spatial histologic patterns or pathway co-activations, are typically sparse, patient-specific, and unannotated, making them inherently difficult to uncover. To address this, we propose SlotSPE, a slot-based framework for structural prognostic event modeling. Specifically, inspired by the principle of factorial coding, we compress each patient's multimodal inputs into compact, modality-specific sets of mutually distinctive slots using slot attention. By leveraging these slot representations as encodings for prognostic events, our framework enables both efficient and effective modeling of complex intra- and inter-modal interactions, while also facilitating seamless incorporation of biological priors that enhance prognostic relevance. Extensive experiments on ten cancer benchmarks show that SlotSPE outperforms existing methods in 8 out of 10 cohorts, achieving an overall improvement of 2.9%. It remains robust under missing genomic data and delivers markedly improved interpretability through structured event decomposition.

</details>


### [142] [OmniFD: A Unified Model for Versatile Face Forgery Detection](https://arxiv.org/abs/2512.01128)
*Haotian Liu,Haoyu Chen,Chenhui Pan,You Hu,Guoying Zhao,Xiaobai Li*

Main category: cs.CV

TL;DR: OmniFD 是一个统一框架，通过多任务学习联合处理四个人脸伪造检测任务，显著提升性能并减少资源消耗。


<details>
  <summary>Details</summary>
Motivation: 当前方法通常采用任务特定模型，导致计算冗余并忽略相关任务之间的潜在关联。

Method: OmniFD 框架包含三个主要组件：共享的 Swin Transformer 编码器、跨任务交互模块和轻量级解码头。

Result: OmniFD 在多样化基准测试中表现出色，减少了 63% 的模型参数和 50% 的训练时间。

Conclusion: OmniFD 提供了一种实用且可推广的解决方案，适用于现实应用中的全面人脸伪造检测。

Abstract: Face forgery detection encompasses multiple critical tasks, including identifying forged images and videos and localizing manipulated regions and temporal segments. Current approaches typically employ task-specific models with independent architectures, leading to computational redundancy and ignoring potential correlations across related tasks. We introduce OmniFD, a unified framework that jointly addresses four core face forgery detection tasks within a single model, i.e., image and video classification, spatial localization, and temporal localization. Our architecture consists of three principal components: (1) a shared Swin Transformer encoder that extracts unified 4D spatiotemporal representations from both images and video inputs, (2) a cross-task interaction module with learnable queries that dynamically captures inter-task dependencies through attention-based reasoning, and (3) lightweight decoding heads that transform refined representations into corresponding predictions for all FFD tasks. Extensive experiments demonstrate OmniFD's advantage over task-specific models. Its unified design leverages multi-task learning to capture generalized representations across tasks, especially enabling fine-grained knowledge transfer that facilitates other tasks. For example, video classification accuracy improves by 4.63% when image data are incorporated. Furthermore, by unifying images, videos and the four tasks within one framework, OmniFD achieves superior performance across diverse benchmarks with high efficiency and scalability, e.g., reducing 63% model parameters and 50% training time. It establishes a practical and generalizable solution for comprehensive face forgery detection in real-world applications. The source code is made available at https://github.com/haotianll/OmniFD.

</details>


### [143] [M4-BLIP: Advancing Multi-Modal Media Manipulation Detection through Face-Enhanced Local Analysis](https://arxiv.org/abs/2512.01214)
*Hang Wu,Ke Sun,Jiayi Ji,Xiaoshuai Sun,Rongrong Ji*

Main category: cs.CV

TL;DR: M4-BLIP框架通过BLIP-2模型和局部面部信息提升多模态篡改检测性能，实验显示其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前多模态媒体篡改检测方法忽视局部信息，尤其是面部区域，而篡改常发生在这些区域。

Method: 利用BLIP-2模型提取局部特征，并结合局部面部信息作为先验知识，通过设计的对齐与融合模块整合局部和全局特征。

Result: 实验证明M4-BLIP框架在检测准确性和可解释性上优于现有方法。

Conclusion: M4-BLIP框架通过结合局部和全局特征，显著提升了多模态媒体篡改检测的准确性和可解释性，实验验证了其优于现有方法的性能。

Abstract: In the contemporary digital landscape, multi-modal media manipulation has emerged as a significant societal threat, impacting the reliability and integrity of information dissemination. Current detection methodologies in this domain often overlook the crucial aspect of localized information, despite the fact that manipulations frequently occur in specific areas, particularly in facial regions. In response to this critical observation, we propose the M4-BLIP framework. This innovative framework utilizes the BLIP-2 model, renowned for its ability to extract local features, as the cornerstone for feature extraction. Complementing this, we incorporate local facial information as prior knowledge. A specially designed alignment and fusion module within M4-BLIP meticulously integrates these local and global features, creating a harmonious blend that enhances detection accuracy. Furthermore, our approach seamlessly integrates with Large Language Models (LLM), significantly improving the interpretability of the detection outcomes. Extensive quantitative and visualization experiments validate the effectiveness of our framework against the state-of-the-art competitors.

</details>


### [144] [Weakly Supervised Continuous Micro-Expression Intensity Estimation Using Temporal Deep Neural Network](https://arxiv.org/abs/2512.01145)
*Riyadh Mohammed Almushrafy*

Main category: cs.CV

TL;DR: 提出一种仅需稀疏时间标注的连续微表情强度估计框架，通过三角先验和时序模型实现高精度预测，无需帧级标注。


<details>
  <summary>Details</summary>
Motivation: 现有研究多集中于离散微表情分类，而连续强度演化的研究较少，且缺乏帧级强度标注限制了监督回归的可行性。

Method: 结合ResNet18编码器和双向GRU的轻量级时序回归模型，通过三角先验将稀疏时间地标转换为密集伪强度轨迹。

Result: 在SAMM和CASME II数据集上，模型与伪强度轨迹表现出强时序一致性，Spearman和Kendall相关系数分别达到0.9014/0.7999（SAMM）和0.9116/0.8168（CASME II）。

Conclusion: 本文提出了一种仅使用稀疏时间标注的统一框架，用于连续微表情强度估计，首次实现了无需帧级标注的强度预测。

Abstract: Micro-facial expressions are brief and involuntary facial movements that reflect genuine emotional states. While most prior work focuses on classifying discrete micro-expression categories, far fewer studies address the continuous evolution of intensity over time. Progress in this direction is limited by the lack of frame-level intensity labels, which makes fully supervised regression impractical.
  We propose a unified framework for continuous micro-expression intensity estimation using only weak temporal labels (onset, apex, offset). A simple triangular prior converts sparse temporal landmarks into dense pseudo-intensity trajectories, and a lightweight temporal regression model that combines a ResNet18 encoder with a bidirectional GRU predicts frame-wise intensity directly from image sequences. The method requires no frame-level annotation effort and is applied consistently across datasets through a single preprocessing and temporal alignment pipeline.
  Experiments on SAMM and CASME II show strong temporal agreement with the pseudo-intensity trajectories. On SAMM, the model reaches a Spearman correlation of 0.9014 and a Kendall correlation of 0.7999, outperforming a frame-wise baseline. On CASME II, it achieves up to 0.9116 and 0.8168, respectively, when trained without the apex-ranking term. Ablation studies confirm that temporal modeling and structured pseudo labels are central to capturing the rise-apex-fall dynamics of micro-facial movements.
  To our knowledge, this is the first unified approach for continuous micro-expression intensity estimation using only sparse temporal annotations.

</details>


### [145] [S$^2$-MLLM: Boosting Spatial Reasoning Capability of MLLMs for 3D Visual Grounding with Structural Guidance](https://arxiv.org/abs/2512.01223)
*Beining Xu,Siting Zhu,Zhao Jin,Junxian Li,Hesheng Wang*

Main category: cs.CV

TL;DR: S$^2$-MLLM通过隐式空间推理和结构增强模块提升MLLMs在3D视觉定位任务中的性能，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖低效的点云重建提供显式结构引导，限制了MLLMs在3DVG任务中的空间推理能力。

Method: 提出S$^2$-MLLM框架，结合前馈3D重建的结构感知进行空间引导，并通过结构增强模块（SE）利用视图内和视图间注意力机制及多级位置编码。

Result: 在ScanRefer、Nr3D和Sr3D数据集上，S$^2$-MLLM显著优于现有方法，统一了性能、泛化性和效率。

Conclusion: S$^2$-MLLM框架通过隐式空间推理和结构增强模块（SE）显著提升了MLLMs在3DVG任务中的性能，实现了在ScanRefer、Nr3D和Sr3D数据集上的优越表现。

Abstract: 3D Visual Grounding (3DVG) focuses on locating objects in 3D scenes based on natural language descriptions, serving as a fundamental task for embodied AI and robotics. Recent advances in Multi-modal Large Language Models (MLLMs) have motivated research into extending them to 3DVG. However, MLLMs primarily process 2D visual inputs and struggle with understanding 3D spatial structure of scenes solely from these limited perspectives. Existing methods mainly utilize viewpoint-dependent rendering of reconstructed point clouds to provide explicit structural guidance for MLLMs in 3DVG tasks, leading to inefficiency and limited spatial reasoning. To address this issue, we propose S$^2$-MLLM, an efficient framework that enhances spatial reasoning in MLLMs through implicit spatial reasoning. We introduce a spatial guidance strategy that leverages the structure awareness of feed-forward 3D reconstruction. By acquiring 3D structural understanding during training, our model can implicitly reason about 3D scenes without relying on inefficient point cloud reconstruction. Moreover, we propose a structure-enhanced module (SE), which first employs intra-view and inter-view attention mechanisms to capture dependencies within views and correspondences across views. The module further integrates multi-level position encoding to associate visual representations with spatial positions and viewpoint information, enabling more accurate structural understanding. Extensive experiments demonstrate that S$^2$-MLLM unifies superior performance, generalization, and efficiency, achieving significant performance over existing methods across the ScanRefer, Nr3D, and Sr3D datasets. Code will be available upon acceptance.

</details>


### [146] [Generative Adversarial Gumbel MCTS for Abstract Visual Composition Generation](https://arxiv.org/abs/2512.01242)
*Zirui Zhao,Boye Niu,David Hsu,Wee Sun Lee*

Main category: cs.CV

TL;DR: 论文提出了一种结合几何推理与神经语义的框架，通过搜索和对抗奖励优化生成抽象视觉结构，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 研究抽象视觉组合，其身份主要由几何基元的空间配置和关系决定，但组合这些结构在几何约束和模糊目标（如文本）下具有挑战性。

Method: 采用AlphaGo风格的搜索确保可行性，微调的视觉语言模型提供语义对齐的奖励信号。算法在蒙特卡洛树搜索中使用策略网络作为启发式，并通过搜索生成的计划微调网络。

Result: 在约束收紧时，该方法在有效性和语义保真度上优于基线模型。

Conclusion: 论文提出了一种结合显式几何推理与神经语义的约束引导框架，在Tangram Assembly任务中，该方法在有效性和语义保真度上优于扩散和自回归基线。

Abstract: We study abstract visual composition, in which identity is primarily determined by the spatial configuration and relations among a small set of geometric primitives (e.g., parts, symmetry, topology). They are invariant primarily to texture and photorealistic detail. Composing such structures from fixed components under geometric constraints and vague goal specification (such as text) is non-trivial due to combinatorial placement choices, limited data, and discrete feasibility (overlap-free, allowable orientations), which create a sparse solution manifold ill-suited to purely statistical pixel-space generators. We propose a constraint-guided framework that combines explicit geometric reasoning with neural semantics. An AlphaGo-style search enforces feasibility, while a fine-tuned vision-language model scores semantic alignment as reward signals. Our algorithm uses a policy network as a heuristic in Monte-Carlo Tree Search and fine-tunes the network via search-generated plans. Inspired by the Generative Adversarial Network, we use the generated instances for adversarial reward refinement. Over time, the generation should approach the actual data more closely when the reward model cannot distinguish between generated instances and ground-truth. In the Tangram Assembly task, our approach yields higher validity and semantic fidelity than diffusion and auto-regressive baselines, especially as constraints tighten.

</details>


### [147] [Diffusion Model in Latent Space for Medical Image Segmentation Task](https://arxiv.org/abs/2512.01292)
*Huynh Trinh Ngoc,Toan Nguyen Hai,Ba Luong Son,Long Tran Quoc*

Main category: cs.CV

TL;DR: MedSegLatDiff 是一种高效的医学图像分割框架，结合 VAE 和潜在扩散模型，在多个数据集上表现优异，并提供多样化的分割结果。


<details>
  <summary>Details</summary>
Motivation: 传统医学图像分割方法无法捕捉不确定性，而现有生成模型计算成本高。MedSegLatDiff 旨在高效生成多样化的分割结果。

Method: MedSegLatDiff 结合了变分自编码器（VAE）和潜在扩散模型，利用低维潜在空间加速训练，并通过加权交叉熵损失函数保留微小结构。

Result: 在 ISIC-2018、CVC-Clinic 和 LIDC-IDRI 数据集上，MedSegLatDiff 取得了先进的 Dice 和 IoU 分数，同时生成多样化的分割假设和置信度图。

Conclusion: MedSegLatDiff 通过结合 VAE 和潜在扩散模型，实现了高效且多样化的医学图像分割，提供了比确定性基线更高的可解释性和可靠性，适合临床部署。

Abstract: Medical image segmentation is crucial for clinical diagnosis and treatment planning. Traditional methods typically produce a single segmentation mask, failing to capture inherent uncertainty. Recent generative models enable the creation of multiple plausible masks per image, mimicking the collaborative interpretation of several clinicians. However, these approaches remain computationally heavy. We propose MedSegLatDiff, a diffusion based framework that combines a variational autoencoder (VAE) with a latent diffusion model for efficient medical image segmentation. The VAE compresses the input into a low dimensional latent space, reducing noise and accelerating training, while the diffusion process operates directly in this compact representation. We further replace the conventional MSE loss with weighted cross entropy in the VAE mask reconstruction path to better preserve tiny structures such as small nodules. MedSegLatDiff is evaluated on ISIC-2018 (skin lesions), CVC-Clinic (polyps), and LIDC-IDRI (lung nodules). It achieves state of the art or highly competitive Dice and IoU scores while simultaneously generating diverse segmentation hypotheses and confidence maps. This provides enhanced interpretability and reliability compared to deterministic baselines, making the model particularly suitable for clinical deployment.

</details>


### [148] [VSRD++: Autolabeling for 3D Object Detection via Instance-Aware Volumetric Silhouette Rendering](https://arxiv.org/abs/2512.01178)
*Zihua Liu,Hiroki Sakuma,Masatoshi Okutomi*

Main category: cs.CV

TL;DR: VSRD++ 通过神经场渲染和弱2D监督，实现了无需3D标注的单目3D物体检测，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖大量3D标注数据，标注成本高。VSRD++ 旨在减少对3D标注的依赖，利用弱2D监督实现高效检测。

Method: VSRD++ 采用两阶段流程：多视图3D自动标注和单目3D检测器训练。通过实例感知体积轮廓渲染优化3D边界框，并引入动态对象建模和伪标签置信度机制。

Result: 在KITTI-360数据集上，VSRD++ 显著优于现有弱监督方法，尤其在动态场景中表现突出。

Conclusion: VSRD++ 是一种新颖的弱监督框架，通过神经场体积渲染和2D监督，显著提升了单目3D物体检测的性能，尤其在静态和动态场景中表现优异。

Abstract: Monocular 3D object detection is a fundamental yet challenging task in 3D scene understanding. Existing approaches heavily depend on supervised learning with extensive 3D annotations, which are often acquired from LiDAR point clouds through labor-intensive labeling processes. To tackle this problem, we propose VSRD++, a novel weakly supervised framework for monocular 3D object detection that eliminates the reliance on 3D annotations and leverages neural-field-based volumetric rendering with weak 2D supervision. VSRD++ consists of a two-stage pipeline: multi-view 3D autolabeling and subsequent monocular 3D detector training. In the multi-view autolabeling stage, object surfaces are represented as signed distance fields (SDFs) and rendered as instance masks via the proposed instance-aware volumetric silhouette rendering. To optimize 3D bounding boxes, we decompose each instance's SDF into a cuboid SDF and a residual distance field (RDF) that captures deviations from the cuboid. To address the geometry inconsistency commonly observed in volume rendering methods applied to dynamic objects, we model the dynamic objects by including velocity into bounding box attributes as well as assigning confidence to each pseudo-label. Moreover, we also employ a 3D attribute initialization module to initialize the dynamic bounding box parameters. In the monocular 3D object detection phase, the optimized 3D bounding boxes serve as pseudo labels for training monocular 3D object detectors. Extensive experiments on the KITTI-360 dataset demonstrate that VSRD++ significantly outperforms existing weakly supervised approaches for monocular 3D object detection on both static and dynamic scenes. Code is available at https://github.com/Magicboomliu/VSRD_plus_plus

</details>


### [149] [FOD-S2R: A FOD Dataset for Sim2Real Transfer Learning based Object Detection](https://arxiv.org/abs/2512.01315)
*Ashish Vashist,Qiranul Saadiyean,Suresh Sundaram,Chandra Sekhar Seelamantula*

Main category: cs.CV

TL;DR: 提出了首个针对封闭燃油箱环境的FOD数据集FOD-S2R，证明合成数据能有效提升FOD检测性能并缩小Sim2Real差距。


<details>
  <summary>Details</summary>
Motivation: 飞机燃油箱内的异物碎片（FOD）存在严重的安全风险，但目前缺乏针对这种封闭环境的专用数据集。

Method: 提出了一个名为FOD-S2R的新数据集，包含真实和合成图像，并在模拟飞机燃油箱环境中系统评估了合成数据的效果。真实子集包含3,114张高清图像，合成子集包含3,137张由Unreal Engine生成的图像。数据集涵盖了多种FOV、物体距离、光照条件、颜色和物体大小。

Result: 实验表明，引入合成数据可以提高检测准确性并增强模型对真实世界条件的泛化能力。

Conclusion: 合成数据在提升真实世界FOD检测性能和缩小Sim2Real差距方面表现出有效性，为航空维护中的自动化FOD检测系统开发提供了有价值的基础。

Abstract: Foreign Object Debris (FOD) within aircraft fuel tanks presents critical safety hazards including fuel contamination, system malfunctions, and increased maintenance costs. Despite the severity of these risks, there is a notable lack of dedicated datasets for the complex, enclosed environments found inside fuel tanks. To bridge this gap, we present a novel dataset, FOD-S2R, composed of real and synthetic images of the FOD within a simulated aircraft fuel tank. Unlike existing datasets that focus on external or open-air environments, our dataset is the first to systematically evaluate the effectiveness of synthetic data in enhancing the real-world FOD detection performance in confined, closed structures. The real-world subset consists of 3,114 high-resolution HD images captured in a controlled fuel tank replica, while the synthetic subset includes 3,137 images generated using Unreal Engine. The dataset is composed of various Field of views (FOV), object distances, lighting conditions, color, and object size. Prior research has demonstrated that synthetic data can reduce reliance on extensive real-world annotations and improve the generalizability of vision models. Thus, we benchmark several state-of-the-art object detection models and demonstrate that introducing synthetic data improves the detection accuracy and generalization to real-world conditions. These experiments demonstrate the effectiveness of synthetic data in enhancing the model performance and narrowing the Sim2Real gap, providing a valuable foundation for developing automated FOD detection systems for aviation maintenance.

</details>


### [150] [TabletopGen: Instance-Level Interactive 3D Tabletop Scene Generation from Text or Single Image](https://arxiv.org/abs/2512.01204)
*Ziqian Wang,Yonghao He,Licheng Yang,Wei Zou,Hongxuan Ma,Liu Liu,Wei Sui,Yuxin Guo,Hu Su*

Main category: cs.CV

TL;DR: TabletopGen是一个无需训练的全自动框架，通过多阶段处理生成高保真、多样化的交互式3D桌面场景，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前基于文本或图像的3D场景生成方法主要关注大尺度场景，难以捕捉桌面场景的高密度布局和复杂空间关系，因此需要一种专门针对桌面场景的生成方法。

Method: TabletopGen是一个无需训练、全自动的框架，通过实例分割和补全、3D模型重建、规范坐标对齐、姿态和尺度估计等步骤生成多样化的实例级交互式3D桌面场景。

Result: 实验和用户研究表明，TabletopGen在视觉保真度、布局准确性和物理合理性方面显著优于现有方法。

Conclusion: TabletopGen显著超越了现有方法，在视觉保真度、布局准确性和物理合理性方面实现了最先进的性能，能够生成具有丰富风格和空间多样性的逼真桌面场景。

Abstract: Generating high-fidelity, physically interactive 3D simulated tabletop scenes is essential for embodied AI--especially for robotic manipulation policy learning and data synthesis. However, current text- or image-driven 3D scene generation methods mainly focus on large-scale scenes, struggling to capture the high-density layouts and complex spatial relations that characterize tabletop scenes. To address these challenges, we propose TabletopGen, a training-free, fully automatic framework that generates diverse, instance-level interactive 3D tabletop scenes. TabletopGen accepts a reference image as input, which can be synthesized by a text-to-image model to enhance scene diversity. We then perform instance segmentation and completion on the reference to obtain per-instance images. Each instance is reconstructed into a 3D model followed by canonical coordinate alignment. The aligned 3D models then undergo pose and scale estimation before being assembled into a collision-free, simulation-ready tabletop scene. A key component of our framework is a novel pose and scale alignment approach that decouples the complex spatial reasoning into two stages: a Differentiable Rotation Optimizer for precise rotation recovery and a Top-view Spatial Alignment mechanism for robust translation and scale estimation, enabling accurate 3D reconstruction from 2D reference. Extensive experiments and user studies show that TabletopGen achieves state-of-the-art performance, markedly surpassing existing methods in visual fidelity, layout accuracy, and physical plausibility, capable of generating realistic tabletop scenes with rich stylistic and spatial diversity. Our code will be publicly available.

</details>


### [151] [Rethinking Intracranial Aneurysm Vessel Segmentation: A Perspective from Computational Fluid Dynamics Applications](https://arxiv.org/abs/2512.01319)
*Feiyang Xiao,Yichi Zhang,Xigui Li,Yuanye Zhou,Chen Jiang,Xin Guo,Limei Han,Yuxin Li,Fengping Zhu,Yuan Cheng*

Main category: cs.CV

TL;DR: 提出了首个全面的颅内动脉瘤血管分割数据集IAVS，开发了两阶段框架和标准化CFD评估系统，填补了现有方法的不足。


<details>
  <summary>Details</summary>
Motivation: 当前分割方法主要关注基于图像的评估指标，忽视了其在后续CFD应用中的实际效果。

Method: 构建了包含641个3D MRA图像和587个标注的IAVS数据集，并开发了两阶段评估基准（全局定位和细粒度分割）。

Result: IAVS数据集填补了现有数据集在拓扑完整性和CFD适用性方面的不足，并建立了标准化的CFD适用性评估系统。

Conclusion: 该研究提出了首个全面的颅内动脉瘤血管分割（IAVS）数据集，并开发了一个简单有效的两阶段框架，为临床相关技术的发展提供了基础。

Abstract: The precise segmentation of intracranial aneurysms and their parent vessels (IA-Vessel) is a critical step for hemodynamic analyses, which mainly depends on computational fluid dynamics (CFD). However, current segmentation methods predominantly focus on image-based evaluation metrics, often neglecting their practical effectiveness in subsequent CFD applications. To address this deficiency, we present the Intracranial Aneurysm Vessel Segmentation (IAVS) dataset, the first comprehensive, multi-center collection comprising 641 3D MRA images with 587 annotations of aneurysms and IA-Vessels. In addition to image-mask pairs, IAVS dataset includes detailed hemodynamic analysis outcomes, addressing the limitations of existing datasets that neglect topological integrity and CFD applicability. To facilitate the development and evaluation of clinically relevant techniques, we construct two evaluation benchmarks including global localization of aneurysms (Stage I) and fine-grained segmentation of IA-Vessel (Stage II) and develop a simple and effective two-stage framework, which can be used as a out-of-the-box method and strong baseline. For comprehensive evaluation of applicability of segmentation results, we establish a standardized CFD applicability evaluation system that enables the automated and consistent conversion of segmentation masks into CFD models, offering an applicability-focused assessment of segmentation outcomes. The dataset, code, and model will be public available at https://github.com/AbsoluteResonance/IAVS.

</details>


### [152] [Closing the Approximation Gap of Partial AUC Optimization: A Tale of Two Formulations](https://arxiv.org/abs/2512.01213)
*Yangbangyan Jiang,Qianqian Xu,Huiyang Shao,Zhiyong Yang,Shilong Bao,Xiaochun Cao,Qingming Huang*

Main category: cs.CV

TL;DR: 本文提出两种实例级极小极大重构方法，解决了PAUC优化中的近似误差问题，具有高效的计算复杂度和收敛速度，并在实验中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: PAUC是现实场景中重要的评估指标，但现有方法存在近似误差不可控或可扩展性有限的问题。

Method: 首先建立等效的实例级问题以降低时间复杂度，通过阈值学习简化复杂的样本选择过程，并应用不同的平滑技术。

Result: 所提算法具有线性迭代计算复杂度和$O(ε^{-1/3})$的收敛速度，并提供了紧致的泛化界限。

Conclusion: 本文通过提出两种简单的实例级极小极大重构，解决了PAUC优化中的近似误差问题，并在多个基准数据集上验证了所提方法的有效性。

Abstract: As a variant of the Area Under the ROC Curve (AUC), the partial AUC (PAUC) focuses on a specific range of false positive rate (FPR) and/or true positive rate (TPR) in the ROC curve. It is a pivotal evaluation metric in real-world scenarios with both class imbalance and decision constraints. However, selecting instances within these constrained intervals during its calculation is NP-hard, and thus typically requires approximation techniques for practical resolution. Despite the progress made in PAUC optimization over the last few years, most existing methods still suffer from uncontrollable approximation errors or a limited scalability when optimizing the approximate PAUC objectives. In this paper, we close the approximation gap of PAUC optimization by presenting two simple instance-wise minimax reformulations: one with an asymptotically vanishing gap, the other with the unbiasedness at the cost of more variables. Our key idea is to first establish an equivalent instance-wise problem to lower the time complexity, simplify the complicated sample selection procedure by threshold learning, and then apply different smoothing techniques. Equipped with an efficient solver, the resulting algorithms enjoy a linear per-iteration computational complexity w.r.t. the sample size and a convergence rate of $O(ε^{-1/3})$ for typical one-way and two-way PAUCs. Moreover, we provide a tight generalization bound of our minimax reformulations. The result explicitly demonstrates the impact of the TPR/FPR constraints $α$/$β$ on the generalization and exhibits a sharp order of $\tilde{O}(α^{-1}\n_+^{-1} + β^{-1}\n_-^{-1})$. Finally, extensive experiments on several benchmark datasets validate the strength of our proposed methods.

</details>


### [153] [Rice-VL: Evaluating Vision-Language Models for Cultural Understanding Across ASEAN Countries](https://arxiv.org/abs/2512.01419)
*Tushar Pranav,Eshan Pandey,Austria Lyka Diane Bala,Aman Chadha,Indriyati Atmosukarto,Donny Soh Cheng Lock*

Main category: cs.CV

TL;DR: RICE-VL是一个评估视觉语言模型文化理解的新基准，覆盖11个东盟国家，揭示了模型在文化多样性任务中的局限性，并提出了改进方向。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLMs）在多模态任务中表现出色，但存在西方中心偏见，限制了其在东南亚等文化多样性地区的有效性。

Method: 引入了RICE-VL基准，包含超过28,000个人工策划的视觉问答（VQA）样本和1,000个图像-边界框对，用于视觉定位任务。提出了SEA-LAVE指标，评估文本准确性、文化对齐和国家识别。

Result: 对六个开源和闭源VLM的评估显示，在低资源国家和抽象文化领域中存在显著的性能差距。视觉定位任务测试了模型在复杂场景中定位文化重要元素的能力。

Conclusion: RICE-VL揭示了视觉语言模型（VLM）在文化理解方面的局限性，并强调了包容性模型开发的必要性，以更好地服务于全球多样化人群。

Abstract: Vision-Language Models (VLMs) excel in multimodal tasks but often exhibit Western-centric biases, limiting their effectiveness in culturally diverse regions like Southeast Asia (SEA). To address this, we introduce RICE-VL, a novel benchmark evaluating VLM cultural understanding across 11 ASEAN countries. RICE-VL includes over 28,000 human-curated Visual Question Answering (VQA) samples -- covering True or False, Fill-in-the-Blank, and open-ended formats -- and 1,000 image-bounding box pairs for Visual Grounding, annotated by culturally informed experts across 14 sub-ground categories. We propose SEA-LAVE, an extension of the LAVE metric, assessing textual accuracy, cultural alignment, and country identification. Evaluations of six open- and closed-source VLMs reveal significant performance gaps in low-resource countries and abstract cultural domains. The Visual Grounding task tests models' ability to localize culturally significant elements in complex scenes, probing spatial and contextual accuracy. RICE-VL exposes limitations in VLMs' cultural comprehension and highlights the need for inclusive model development to better serve diverse global populations.

</details>


### [154] [PSR: Scaling Multi-Subject Personalized Image Generation with Pairwise Subject-Consistency Rewards](https://arxiv.org/abs/2512.01236)
*Shulei Wang,Longhui Wei,Xin He,Jianbo Ouyang,Hui Lu,Zhou Zhao,Qi Tian*

Main category: cs.CV

TL;DR: 论文提出了一种改进多主题个性化图像生成的方法，通过构建高质量数据集和优化奖励机制，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有模型在扩展到多主题时性能下降，尤其是在保持主题一致性和遵循文本提示方面，这主要由于缺乏高质量的多主题数据集和精细的后训练策略。

Method: 论文提出了一种可扩展的多主题数据生成流程，利用强大的单主题生成模型构建多样化的高质量多主题训练数据，并设计了一对主题一致性奖励和通用奖励，通过强化学习阶段进行优化。

Result: 大量实验证明，该方法在多主题个性化图像生成方面取得了显著进展。

Conclusion: 该论文提出的方法通过构建高质量的多主题数据集和精细的后训练策略，显著提升了多主题个性化图像生成的性能。

Abstract: Personalized generation models for a single subject have demonstrated remarkable effectiveness, highlighting their significant potential. However, when extended to multiple subjects, existing models often exhibit degraded performance, particularly in maintaining subject consistency and adhering to textual prompts. We attribute these limitations to the absence of high-quality multi-subject datasets and refined post-training strategies. To address these challenges, we propose a scalable multi-subject data generation pipeline that leverages powerful single-subject generation models to construct diverse and high-quality multi-subject training data. Through this dataset, we first enable single-subject personalization models to acquire knowledge of synthesizing multi-image and multi-subject scenarios. Furthermore, to enhance both subject consistency and text controllability, we design a set of Pairwise Subject-Consistency Rewards and general-purpose rewards, which are incorporated into a refined reinforcement learning stage. To comprehensively evaluate multi-subject personalization, we introduce a new benchmark that assesses model performance using seven subsets across three dimensions. Extensive experiments demonstrate the effectiveness of our approach in advancing multi-subject personalized image generation. Github Link: https://github.com/wang-shulei/PSR

</details>


### [155] [Diffusion Fuzzy System: Fuzzy Rule Guided Latent Multi-Path Diffusion Modeling](https://arxiv.org/abs/2512.01533)
*Hailong Yang,Te Zhang,Kup-sze Choi,Zhaohong Deng*

Main category: cs.CV

TL;DR: DFS是一种模糊规则引导的多路径扩散模型，能高效捕捉异质图像特征并降低计算成本，实验显示其在图像质量和训练效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成高分辨率真实图像方面表现出色，但在处理特征差异显著的图像集合时存在不足，多路径扩散方法虽尝试解决，但协调效率低且计算成本高。

Method: DFS采用多路径扩散模型，每条路径专注于学习特定类别的图像特征，并通过基于规则链的推理动态引导扩散过程，同时引入模糊隶属度的潜在空间压缩机制以减少计算开销。

Result: 在LSUN Bedroom、LSUN Church和MS COCO数据集上的实验表明，DFS相比现有单路径和多路径扩散模型，训练更稳定、收敛更快，图像质量和对齐度更高，生成图像与目标参考的准确性也更好。

Conclusion: DFS通过模糊规则引导的多路径扩散模型，有效解决了传统扩散模型在捕捉异质图像特征时的不足，同时降低了计算成本，提升了图像质量和训练稳定性。

Abstract: Diffusion models have emerged as a leading technique for generating images due to their ability to create high-resolution and realistic images. Despite their strong performance, diffusion models still struggle in managing image collections with significant feature differences. They often fail to capture complex features and produce conflicting results. Research has attempted to address this issue by learning different regions of an image through multiple diffusion paths and then combining them. However, this approach leads to inefficient coordination among multiple paths and high computational costs. To tackle these issues, this paper presents a Diffusion Fuzzy System (DFS), a latent-space multi-path diffusion model guided by fuzzy rules. DFS offers several advantages. First, unlike traditional multi-path diffusion methods, DFS uses multiple diffusion paths, each dedicated to learning a specific class of image features. By assigning each path to a different feature type, DFS overcomes the limitations of multi-path models in capturing heterogeneous image features. Second, DFS employs rule-chain-based reasoning to dynamically steer the diffusion process and enable efficient coordination among multiple paths. Finally, DFS introduces a fuzzy membership-based latent-space compression mechanism to reduce the computational costs of multi-path diffusion effectively. We tested our method on three public datasets: LSUN Bedroom, LSUN Church, and MS COCO. The results show that DFS achieves more stable training and faster convergence than existing single-path and multi-path diffusion models. Additionally, DFS surpasses baseline models in both image quality and alignment between text and images, and also shows improved accuracy when comparing generated images to target references.

</details>


### [156] [Deep Unsupervised Anomaly Detection in Brain Imaging: Large-Scale Benchmarking and Bias Analysis](https://arxiv.org/abs/2512.01534)
*Alexander Frotscher,Christian F. Baumgartner,Thomas Wolfers*

Main category: cs.CV

TL;DR: 该研究提出了一个大规模、多中心的深度学习无监督异常检测基准，评估了不同算法在脑成像中的表现，发现重建方法表现最佳，但存在系统性偏差，如扫描仪相关效应。研究强调了未来临床转化的关键方向。


<details>
  <summary>Details</summary>
Motivation: 深度无监督异常检测在脑磁共振成像中提供了一种有前景的途径，无需病变特定注释即可识别病理偏差，但碎片化评估、异构数据集和不一致的指标阻碍了临床转化进展。

Method: 研究使用了大规模、多中心的深度学习无监督异常检测基准，训练队列包括来自健康个体的2,976 T1和2,972 T2加权扫描，验证使用92次扫描调整超参数并估计无偏阈值，测试涵盖2,221 T1w和1,262 T2w扫描。

Result: 在所有算法中，基于Dice的分割性能在0.03到0.65之间变化，表明存在显著变异性。重建方法（特别是受扩散启发的技术）实现了最强的病变分割性能，而基于特征的方法在分布变化下表现出更强的鲁棒性。

Conclusion: 该研究为未来的研究建立了透明的基础，并强调了临床转化的优先事项，包括图像原生预训练、原则性偏差测量、公平意识建模和稳健的领域适应。

Abstract: Deep unsupervised anomaly detection in brain magnetic resonance imaging offers a promising route to identify pathological deviations without requiring lesion-specific annotations. Yet, fragmented evaluations, heterogeneous datasets, and inconsistent metrics have hindered progress toward clinical translation. Here, we present a large-scale, multi-center benchmark of deep unsupervised anomaly detection for brain imaging. The training cohort comprised 2,976 T1 and 2,972 T2-weighted scans from healthy individuals across six scanners, with ages ranging from 6 to 89 years. Validation used 92 scans to tune hyperparameters and estimate unbiased thresholds. Testing encompassed 2,221 T1w and 1,262 T2w scans spanning healthy datasets and diverse clinical cohorts. Across all algorithms, the Dice-based segmentation performance varied between 0.03 and 0.65, indicating substantial variability. To assess robustness, we systematically evaluated the impact of different scanners, lesion types and sizes, as well as demographics (age, sex). Reconstruction-based methods, particularly diffusion-inspired approaches, achieved the strongest lesion segmentation performance, while feature-based methods showed greater robustness under distributional shifts. However, systematic biases, such as scanner-related effects, were observed for the majority of algorithms, including that small and low-contrast lesions were missed more often, and that false positives varied with age and sex. Increasing healthy training data yields only modest gains, underscoring that current unsupervised anomaly detection frameworks are limited algorithmically rather than by data availability. Our benchmark establishes a transparent foundation for future research and highlights priorities for clinical translation, including image native pretraining, principled deviation measures, fairness-aware modeling, and robust domain adaptation.

</details>


### [157] [TRivia: Self-supervised Fine-tuning of Vision-Language Models for Table Recognition](https://arxiv.org/abs/2512.01248)
*Junyuan Zhang,Bin Wang,Qintong Zhang,Fan Wu,Zichen Wen,Jialin Lu,Junjie Shan,Ziqi Zhao,Shuya Yang,Ziling Wang,Ziyang Miao,Huaping Zhong,Yuhang Zang,Xiaoyi Dong,Ka-Ho Chow,Conghui He*

Main category: cs.CV

TL;DR: TRivia通过自监督微调方法，利用问答奖励机制从无标注表格图像中学习，推出了性能超越现有系统的开源模型TRivia-3B。


<details>
  <summary>Details</summary>
Motivation: 解决开源表格识别模型因标注数据成本高而性能滞后的问题，推动自监督学习在表格识别中的应用。

Method: 基于Group Relative Policy Optimization的自监督微调方法，通过问答奖励机制自动识别有效学习样本，无需人工标注。

Result: TRivia-3B在三个流行基准测试中超越了现有系统（如Gemini 2.5 Pro、MinerU2.5）。

Conclusion: TRivia-3B是一种开源、紧凑且最先进的表格识别模型，通过自监督微调方法显著提升了性能，超越了现有系统。

Abstract: Table recognition (TR) aims to transform table images into semi-structured representations such as HTML or Markdown. As a core component of document parsing, TR has long relied on supervised learning, with recent efforts dominated by fine-tuning vision-language models (VLMs) using labeled data. While VLMs have brought TR to the next level, pushing performance further demands large-scale labeled data that is costly to obtain. Consequently, although proprietary models have continuously pushed the performance boundary, open-source models, often trained with limited resources and, in practice, the only viable option for many due to privacy regulations, still lag far behind. To bridge this gap, we introduce TRivia, a self-supervised fine-tuning method that enables pretrained VLMs to learn TR directly from unlabeled table images in the wild. Built upon Group Relative Policy Optimization, TRivia automatically identifies unlabeled samples that most effectively facilitate learning and eliminates the need for human annotations through a question-answering-based reward mechanism. An attention-guided module generates diverse questions for each table image, and the ability to interpret the recognition results and answer them correctly provides feedback to optimize the TR model. This closed-loop process allows the TR model to autonomously learn to recognize, structure, and reason over tables without labeled data. Leveraging this pipeline, we present TRivia-3B, an open-sourced, compact, and state-of-the-art TR model that surpasses existing systems (e.g., Gemini 2.5 Pro, MinerU2.5) on three popular benchmarks. Model and code are released at: https://github.com/opendatalab/TRivia

</details>


### [158] [ViscNet: Vision-Based In-line Viscometry for Fluid Mixing Process](https://arxiv.org/abs/2512.01268)
*Jongwon Sohn,Juhyeon Moon,Hyunjoon Jung,Jaewook Nam*

Main category: cs.CV

TL;DR: 提出一种基于计算机视觉的非接触式粘度计，通过光折射分析自由表面变形来测量粘度，适用于自动化且性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统粘度计具有侵入性且需在受控实验室环境中使用，与真实工艺条件差异较大，因此需要一种更实用的替代方案。

Method: 利用计算机视觉技术，通过分析混合驱动的自由表面变形引起的光折射对固定背景图案的扭曲来推断粘度。

Result: 在不同光照条件下，系统在回归中的平均绝对误差为0.113 log m2 s^-1，粘度类别预测准确率高达81%。

Conclusion: 该非接触式粘度计提供了一种实用且适用于自动化的粘度测量方法，相较于传统方法更具优势。

Abstract: Viscosity measurement is essential for process monitoring and autonomous laboratory operation, yet conventional viscometers remain invasive and require controlled laboratory environments that differ substantially from real process conditions. We present a computer-vision-based viscometer that infers viscosity by exploiting how a fixed background pattern becomes optically distorted as light refracts through the mixing-driven, continuously deforming free surface. Under diverse lighting conditions, the system achieves a mean absolute error of 0.113 in log m2 s^-1 units for regression and reaches up to 81% accuracy in viscosity-class prediction. Although performance declines for classes with closely clustered viscosity values, a multi-pattern strategy improves robustness by providing enriched visual cues. To ensure sensor reliability, we incorporate uncertainty quantification, enabling viscosity predictions with confidence estimates. This stand-off viscometer offers a practical, automation-ready alternative to existing viscometry methods.

</details>


### [159] [MasHeNe: A Benchmark for Head and Neck CT Mass Segmentation using Window-Enhanced Mamba with Frequency-Domain Integration](https://arxiv.org/abs/2512.01563)
*Thao Thi Phuong Dao,Tan-Cong Nguyen,Nguyen Chi Thanh,Truong Hoang Viet,Trong-Le Do,Mai-Khiem Tran,Minh-Khoi Pham,Trung-Nghia Le,Minh-Triet Tran,Thanh Dinh Le*

Main category: cs.CV

TL;DR: MasHeNe数据集填补了头颈部占位性病变数据集的空白，WEMF模型在该数据集上表现最佳，但仍需进一步研究。


<details>
  <summary>Details</summary>
Motivation: 现有公共数据集主要关注恶性病变，忽略了头颈部其他占位性病变，因此需要更全面的数据集和模型。

Method: 提出了WEMF模型，结合三窗口增强和多频率注意力机制，在U型Mamba骨干网络中融合信息。

Result: WEMF在MasHeNe数据集上表现最佳，Dice为70.45%，IoU为66.89%，NSD为72.33%，HD95为5.12 mm。

Conclusion: MasHeNe数据集和WEMF模型为头颈部肿块分割提供了新的基准，展示了稳定的性能，但仍需进一步研究以应对挑战。

Abstract: Head and neck masses are space-occupying lesions that can compress the airway and esophagus and may affect nerves and blood vessels. Available public datasets primarily focus on malignant lesions and often overlook other space-occupying conditions in this region. To address this gap, we introduce MasHeNe, an initial dataset of 3,779 contrast-enhanced CT slices that includes both tumors and cysts with pixel-level annotations. We also establish a benchmark using standard segmentation baselines and report common metrics to enable fair comparison. In addition, we propose the Windowing-Enhanced Mamba with Frequency integration (WEMF) model. WEMF applies tri-window enhancement to enrich the input appearance before feature extraction. It further uses multi-frequency attention to fuse information across skip connections within a U-shaped Mamba backbone. On MasHeNe, WEMF attains the best performance among evaluated methods, with a Dice of 70.45%, IoU of 66.89%, NSD of 72.33%, and HD95 of 5.12 mm. This model indicates stable and strong results on this challenging task. MasHeNe provides a benchmark for head-and-neck mass segmentation beyond malignancy-only datasets. The observed error patterns also suggest that this task remains challenging and requires further research. Our dataset and code are available at https://github.com/drthaodao3101/MasHeNe.git.

</details>


### [160] [nnMobileNet++: Towards Efficient Hybrid Networks for Retinal Image Analysis](https://arxiv.org/abs/2512.01273)
*Xin Li,Wenhui Zhu,Xuanzhao Dong,Hao Wang,Yujian Xiong,Oana Dumitrascu,Yalin Wang*

Main category: cs.CV

TL;DR: nnMobileNet++ 是一种结合卷积和Transformer的轻量级混合架构，用于视网膜图像分析，在保持高效的同时提升了准确性。


<details>
  <summary>Details</summary>
Motivation: 尽管nnMobileNet在多个视网膜基准测试中表现出色，但纯卷积架构难以捕捉长距离依赖和建模视网膜图像中的不规则病变和细长血管模式，而这些血管特征对可靠的临床诊断至关重要。

Method: nnMobileNet++ 是一种混合架构，结合了动态蛇形卷积（用于边界感知特征提取）、阶段特定的Transformer块（用于全局上下文建模）和视网膜图像预训练（以提高泛化能力）。

Result: 在多个公共视网膜数据集上的分类实验和消融研究表明，nnMobileNet++ 实现了最先进或高度竞争力的准确性，同时保持了低计算成本。

Conclusion: nnMobileNet++ 通过结合卷积和Transformer的优势，在保持低计算成本的同时，实现了视网膜图像分析的最先进或高度竞争力的准确性，展示了其作为轻量级且有效框架的潜力。

Abstract: Retinal imaging is a critical, non-invasive modality for the early detection and monitoring of ocular and systemic diseases. Deep learning, particularly convolutional neural networks (CNNs), has significant progress in automated retinal analysis, supporting tasks such as fundus image classification, lesion detection, and vessel segmentation. As a representative lightweight network, nnMobileNet has demonstrated strong performance across multiple retinal benchmarks while remaining computationally efficient. However, purely convolutional architectures inherently struggle to capture long-range dependencies and model the irregular lesions and elongated vascular patterns that characterize on retinal images, despite the critical importance of vascular features for reliable clinical diagnosis. To further advance this line of work and extend the original vision of nnMobileNet, we propose nnMobileNet++, a hybrid architecture that progressively bridges convolutional and transformer representations. The framework integrates three key components: (i) dynamic snake convolution for boundary-aware feature extraction, (ii) stage-specific transformer blocks introduced after the second down-sampling stage for global context modeling, and (iii) retinal image pretraining to improve generalization. Experiments on multiple public retinal datasets for classification, together with ablation studies, demonstrate that nnMobileNet++ achieves state-of-the-art or highly competitive accuracy while maintaining low computational cost, underscoring its potential as a lightweight yet effective framework for retinal image analysis.

</details>


### [161] [RoleMotion: A Large-Scale Dataset towards Robust Scene-Specific Role-Playing Motion Synthesis with Fine-grained Descriptions](https://arxiv.org/abs/2512.01582)
*Junran Peng,Yiheng Huang,Silei Shen,Zeji Wei,Jingwei Yang,Baojie Wang,Yonghao He,Chuanchen Luo,Man Zhang,Xucheng Yin,Wei Sui*

Main category: cs.CV

TL;DR: RoleMotion是一个高质量、功能性强的人体动作数据集，专注于场景和角色，包含大量细粒度文本注释，适用于文本驱动的全身动作生成。


<details>
  <summary>Details</summary>
Motivation: 现有文本数据集的数据质量不一致，文本注释缺乏细粒度细节，且数据非功能性和孤立，无法覆盖各种场景中的社交活动。

Method: 通过精心设计和收集，构建了一个包含25个经典场景、110个功能角色、500多种行为和10296个高质量人体动作序列的数据集，并配备了27831个细粒度文本描述。同时，构建了一个比现有评估器更强的评估工具，并验证了其可靠性。

Result: 实验结果表明，RoleMotion数据集在文本驱动的全身动作生成中表现出高质量和功能性。

Conclusion: RoleMotion数据集在文本驱动的全身动作生成中表现出高质量和功能性，证明了其设计的有效性。

Abstract: In this paper, we introduce RoleMotion, a large-scale human motion dataset that encompasses a wealth of role-playing and functional motion data tailored to fit various specific scenes. Existing text datasets are mainly constructed decentrally as amalgamation of assorted subsets that their data are nonfunctional and isolated to work together to cover social activities in various scenes. Also, the quality of motion data is inconsistent, and textual annotation lacks fine-grained details in these datasets. In contrast, RoleMotion is meticulously designed and collected with a particular focus on scenes and roles. The dataset features 25 classic scenes, 110 functional roles, over 500 behaviors, and 10296 high-quality human motion sequences of body and hands, annotated with 27831 fine-grained text descriptions. We build an evaluator stronger than existing counterparts, prove its reliability, and evaluate various text-to-motion methods on our dataset. Finally, we explore the interplay of motion generation of body and hands. Experimental results demonstrate the high-quality and functionality of our dataset on text-driven whole-body generation.

</details>


### [162] [Supervised Contrastive Machine Unlearning of Background Bias in Sonar Image Classification with Fine-Grained Explainable AI](https://arxiv.org/abs/2512.01291)
*Kamal Basha S,Athira Nambiar*

Main category: cs.CV

TL;DR: 提出TCU和UESF框架，减少声纳图像分析中的海底背景偏差，提高泛化和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有AI模型过度依赖海底特征，导致泛化能力差，需解决这一问题。

Method: 提出了两个关键模块：TCU（目标对比性遗忘）模块，用于减少海底背景偏差；UESF（遗忘解释声纳框架），用于提供模型遗忘内容的可视化解释。

Result: 实验验证了TCU和UESF在提高遗忘效果、模型鲁棒性和可解释性方面的显著改进。

Conclusion: 提出的TCU和UESF框架显著提高了声纳图像分析的泛化能力和可解释性，验证了其在真实和合成数据集上的有效性。

Abstract: Acoustic sonar image analysis plays a critical role in object detection and classification, with applications in both civilian and defense domains. Despite the availability of real and synthetic datasets, existing AI models that achieve high accuracy often over-rely on seafloor features, leading to poor generalization. To mitigate this issue, we propose a novel framework that integrates two key modules: (i) a Targeted Contrastive Unlearning (TCU) module, which extends the traditional triplet loss to reduce seafloor-induced background bias and improve generalization, and (ii) the Unlearn to Explain Sonar Framework (UESF), which provides visual insights into what the model has deliberately forgotten while adapting the LIME explainer to generate more faithful and localized attributions for unlearning evaluation. Extensive experiments across both real and synthetic sonar datasets validate our approach, demonstrating significant improvements in unlearning effectiveness, model robustness, and interpretability.

</details>


### [163] [StreamGaze: Gaze-Guided Temporal Reasoning and Proactive Understanding in Streaming Videos](https://arxiv.org/abs/2512.01707)
*Daeun Lee,Subhojyoti Mukherjee,Branislav Kveton,Ryan A. Rossi,Viet Dac Lai,Seunghyun Yoon,Trung Bui,Franck Dernoncourt,Mohit Bansal*

Main category: cs.CV

TL;DR: StreamGaze是首个评估MLLMs在流式视频中利用凝视进行时序和主动推理能力的基准，揭示了当前模型的局限性，并提供了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 填补现有流式视频评估基准在衡量MLLMs是否能利用人类凝视信号进行时序和主动推理的空白。

Method: 通过开发凝视-视频问答生成流程，结合注视点提取、区域特定视觉提示和扫描路径构建，生成时空 grounded 的问答对。

Result: 在所有StreamGaze任务中，当前最先进的MLLMs与人类表现存在显著差距。

Conclusion: StreamGaze揭示了当前多模态大语言模型（MLLMs）在基于凝视的时序推理、意图建模和主动预测方面的根本局限性，并提供了未来模型需提升的能力方向。

Abstract: Streaming video understanding requires models not only to process temporally incoming frames, but also to anticipate user intention for realistic applications like AR glasses. While prior streaming benchmarks evaluate temporal reasoning, none measure whether MLLMs can interpret or leverage human gaze signals within a streaming setting. To fill this gap, we introduce StreamGaze, the first benchmark designed to evaluate how effectively MLLMs use gaze for temporal and proactive reasoning in streaming videos. StreamGaze introduces gaze-guided past, present, and proactive tasks that comprehensively evaluate streaming video understanding. These tasks assess whether models can use real-time gaze to follow shifting attention and infer user intentions from only past and currently observed frames. To build StreamGaze, we develop a gaze-video QA generation pipeline that aligns egocentric videos with raw gaze trajectories via fixation extraction, region-specific visual prompting, and scanpath construction. This pipeline produces spatio-temporally grounded QA pairs that closely reflect human perceptual dynamics. Across all StreamGaze tasks, we observe substantial performance gaps between state-of-the-art MLLMs and human performance, revealing fundamental limitations in gaze-based temporal reasoning, intention modeling, and proactive prediction. We further provide detailed analyses of gaze-prompting strategies, reasoning behaviors, and task-specific failure modes, offering deeper insight into why current MLLMs struggle and what capabilities future models must develop. All data and code will be publicly released to support continued research in gaze-guided streaming video understanding.

</details>


### [164] [Envision: Benchmarking Unified Understanding & Generation for Causal World Process Insights](https://arxiv.org/abs/2512.01816)
*Juanxi Tian,Siyuan Li,Conghui He,Lijun Wu,Cheng Tan*

Main category: cs.CV

TL;DR: Envision基准揭示多模态模型在动态时序生成和世界知识内化上的局限性，统一模型优于专用模型但仍有提升空间。


<details>
  <summary>Details</summary>
Motivation: 现有模型依赖静态单图像生成，导致过度拟合静态模式匹配，无法建模动态时序过程。

Method: 提出了Envision基准，包含1000个四阶段提示，覆盖六个领域，并引入Envision-Score作为评估指标，整合多维度一致性、物理性和美学。

Result: 评估15个模型显示：专用T2I模型美学表现优但缺乏世界知识；统一多模态模型在因果叙事连贯性上更优，但仍落后于闭源模型。

Conclusion: 当前的多模态模型在静态单图像生成上表现良好，但在动态时序建模和世界知识内化方面仍有不足，特别是时空一致性仍是核心挑战。

Abstract: Current multimodal models aim to transcend the limitations of single-modality representations by unifying understanding and generation, often using text-to-image (T2I) tasks to calibrate semantic consistency. However, their reliance on static, single-image generation in training and evaluation leads to overfitting to static pattern matching and semantic fusion, while fundamentally hindering their ability to model dynamic processes that unfold over time. To address these constraints, we propose Envision-a causal event progression benchmark for chained text-to-multi-image generation. Grounded in world knowledge and structured by spatiotemporal causality, it reorganizes existing evaluation dimensions and includes 1,000 four-stage prompts spanning six scientific and humanities domains. To transition evaluation from single images to sequential frames and assess whether models truly internalize world knowledge while adhering to causal-temporal constraints, we introduce Envision-Score, a holistic metric integrating multi-dimensional consistency, physicality, and aesthetics. Comprehensive evaluation of 15 models (10 specialized T2I models, 5 unified models) uncovers: specialized T2I models demonstrate proficiency in aesthetic rendering yet lack intrinsic world knowledge. Unified multimodal models bridge this gap, consistently outperforming specialized counterparts in causal narrative coherence. However, even these unified architectures remain subordinate to closed-source models and struggle to overcome the core challenge of spatiotemporal consistency. This demonstrates that a focus on causally-isolated single images impedes multi-frame reasoning and generation, promoting static pattern matching over dynamic world modeling-ultimately limiting world knowledge internalization, generation.

</details>


### [165] [EGG-Fusion: Efficient 3D Reconstruction with Geometry-aware Gaussian Surfel on the Fly](https://arxiv.org/abs/2512.01296)
*Xiaokun Pan,Zhenzhe Li,Zhichao Ye,Hongjia Zhai,Guofeng Zhang*

Main category: cs.CV

TL;DR: EGG-Fusion是一种新型实时3D重建系统，通过几何感知的高斯面元映射和噪声感知融合方法，显著提升了重建精度和实时性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于可微分渲染的方法在实时计算和传感器噪声敏感性方面面临双重挑战，导致场景重建的几何保真度下降和实用性受限。

Method: 提出了一个新颖的实时系统EGG-Fusion，包括鲁棒的稀疏到密集相机跟踪和几何感知的高斯面元映射模块，采用基于信息滤波的融合方法，显式考虑传感器噪声。

Result: 在Replica和ScanNet++等标准化基准数据集上，系统实现了0.6cm的表面重建误差，相比最先进的基于高斯面元的方法，准确率提升了20%以上。

Conclusion: EGG-Fusion系统在实时3D重建中实现了高精度表面重建，并在标准化基准数据集上表现出超过20%的准确率提升，同时保持24 FPS的实时处理能力。

Abstract: Real-time 3D reconstruction is a fundamental task in computer graphics. Recently, differentiable-rendering-based SLAM system has demonstrated significant potential, enabling photorealistic scene rendering through learnable scene representations such as Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS). Current differentiable rendering methods face dual challenges in real-time computation and sensor noise sensitivity, leading to degraded geometric fidelity in scene reconstruction and limited practicality. To address these challenges, we propose a novel real-time system EGG-Fusion, featuring robust sparse-to-dense camera tracking and a geometry-aware Gaussian surfel mapping module, introducing an information filter-based fusion method that explicitly accounts for sensor noise to achieve high-precision surface reconstruction. The proposed differentiable Gaussian surfel mapping effectively models multi-view consistent surfaces while enabling efficient parameter optimization. Extensive experimental results demonstrate that the proposed system achieves a surface reconstruction error of 0.6\textit{cm} on standardized benchmark datasets including Replica and ScanNet++, representing over 20\% improvement in accuracy compared to state-of-the-art (SOTA) GS-based methods. Notably, the system maintains real-time processing capabilities at 24 FPS, establishing it as one of the most accurate differentiable-rendering-based real-time reconstruction systems. Project Page: https://zju3dv.github.io/eggfusion/

</details>


### [166] [TBT-Former: Learning Temporal Boundary Distributions for Action Localization](https://arxiv.org/abs/2512.01298)
*Thisara Rathnayaka,Uthayasanker Thayasivam*

Main category: cs.CV

TL;DR: TBT-Former通过增强Transformer架构和引入边界分布回归头，显著提升TAL任务性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有单阶段无锚模型在模糊边界和多尺度信息融合上的不足。

Method: TBT-Former采用高容量Transformer骨干、跨尺度FPN和边界分布回归头，结合GFL原理优化边界回归任务。

Result: 在THUMOS14和EPIC-Kitchens 100数据集上取得新性能水平，同时在ActivityNet-1.3上保持竞争力。

Conclusion: TBT-Former通过增强的Transformer架构、跨尺度特征金字塔网络和边界分布回归头，显著提升了TAL任务的性能，特别是在模糊边界和多尺度信息融合方面。

Abstract: Temporal Action Localization (TAL) remains a fundamental challenge in video understanding, aiming to identify the start time, end time, and category of all action instances within untrimmed videos. While recent single-stage, anchor-free models like ActionFormer have set a high standard by leveraging Transformers for temporal reasoning, they often struggle with two persistent issues: the precise localization of actions with ambiguous or "fuzzy" temporal boundaries and the effective fusion of multi-scale contextual information. In this paper, we introduce the Temporal Boundary Transformer (TBT-Former), a new architecture that directly addresses these limitations. TBT-Former enhances the strong ActionFormer baseline with three core contributions: (1) a higher-capacity scaled Transformer backbone with an increased number of attention heads and an expanded Multi-Layer Perceptron (MLP) dimension for more powerful temporal feature extraction; (2) a cross-scale feature pyramid network (FPN) that integrates a top-down pathway with lateral connections, enabling richer fusion of high-level semantics and low-level temporal details; and (3) a novel boundary distribution regression head. Inspired by the principles of Generalized Focal Loss (GFL), this new head recasts the challenging task of boundary regression as a more flexible probability distribution learning problem, allowing the model to explicitly represent and reason about boundary uncertainty. Within the paradigm of Transformer-based architectures, TBT-Former advances the formidable benchmark set by its predecessors, establishing a new level of performance on the highly competitive THUMOS14 and EPIC-Kitchens 100 datasets, while remaining competitive on the large-scale ActivityNet-1.3. Our code is available at https://github.com/aaivu/In21-S7-CS4681-AML-Research-Projects/tree/main/projects/210536K-Multi-Modal-Learning_Video-Understanding

</details>


### [167] [DCText: Scheduled Attention Masking for Visual Text Generation via Divide-and-Conquer Strategy](https://arxiv.org/abs/2512.01302)
*Jaewoo Song,Jooyoung Choi,Kanghyun Baek,Sangyub Lee,Daemin Park,Sungroh Yoon*

Main category: cs.CV

TL;DR: DCText 通过分而治之策略和创新的注意力掩码，解决了长文本或多文本生成中的注意力稀释问题，显著提升了文本准确性和生成效率。


<details>
  <summary>Details</summary>
Motivation: 尽管现有文本到图像模型在高保真文本渲染方面取得了进展，但在处理长文本或多文本时仍存在全局注意力稀释的问题。

Method: DCText 采用分而治之策略，利用多模态扩散变换器的短文本生成能力，将目标文本分解并分配到指定区域。通过引入 Text-Focus 和 Context-Expansion 两种注意力掩码，以及局部噪声初始化技术，确保文本准确性和区域对齐。

Result: 在单句和多句基准测试中，DCText 在不影响图像质量的情况下实现了最佳的文本准确性，并提供了最低的生成延迟。

Conclusion: DCText 是一种无需训练的视觉文本生成方法，通过分而治之的策略和创新的注意力掩码，显著提升了长文本或多文本的生成质量，同时保持了图像的整体连贯性和生成效率。

Abstract: Despite recent text-to-image models achieving highfidelity text rendering, they still struggle with long or multiple texts due to diluted global attention. We propose DCText, a training-free visual text generation method that adopts a divide-and-conquer strategy, leveraging the reliable short-text generation of Multi-Modal Diffusion Transformers. Our method first decomposes a prompt by extracting and dividing the target text, then assigns each to a designated region. To accurately render each segment within their regions while preserving overall image coherence, we introduce two attention masks - Text-Focus and Context-Expansion - applied sequentially during denoising. Additionally, Localized Noise Initialization further improves text accuracy and region alignment without increasing computational cost. Extensive experiments on single- and multisentence benchmarks show that DCText achieves the best text accuracy without compromising image quality while also delivering the lowest generation latency.

</details>


### [168] [Lost in Distortion: Uncovering the Domain Gap Between Computer Vision and Brain Imaging - A Study on Pretraining for Age Prediction](https://arxiv.org/abs/2512.01310)
*Yanteng Zhang,Songheng Li,Zeyu Shen,Qizhen Lan,Lipei Zhang,Yang Liu,Vince Calhoun*

Main category: cs.CV

TL;DR: 研究探讨了脑成像数据质量对预训练的影响，发现质量差异导致性能显著不同，强调领域感知数据筛选的重要性。


<details>
  <summary>Details</summary>
Motivation: 探讨大规模脑成像数据集中数据质量水平对预训练的影响，以及噪声或低质量扫描是否有助于预训练。

Method: 通过在不同质量水平的数据集上进行预训练，并在外部队列中进行脑年龄预测的微调。

Result: 结果显示不同质量水平下的性能差异显著，揭示了机会和局限性。

Conclusion: 研究强调了领域感知的数据筛选对于构建可信且可泛化的领域特定基础模型的必要性。

Abstract: Large-scale brain imaging datasets provide unprecedented opportunities for developing domain foundation models through pretraining. However, unlike natural image datasets in computer vision, these neuroimaging data often exhibit high heterogeneity in quality, ranging from well-structured scans to severely distorted or incomplete brain volumes. This raises a fundamental question: can noise or low-quality scans contribute meaningfully to pretraining, or do they instead hinder model learning? In this study, we systematically explore the role of data quality level in pretraining and its impact on downstream tasks. Specifically, we perform pretraining on datasets with different quality levels and perform fine-tuning for brain age prediction on external cohorts. Our results show significant performance differences across quality levels, revealing both opportunities and limitations. We further discuss the gap between computer vision practices and clinical neuroimaging standards, emphasizing the necessity of domain-aware curation to ensure trusted and generalizable domain-specific foundation models.

</details>


### [169] [IVCR-200K: A Large-Scale Multi-turn Dialogue Benchmark for Interactive Video Corpus Retrieval](https://arxiv.org/abs/2512.01312)
*Ning Han,Yawen Zeng,Shaohua Long,Chengqing Li,Sijie Yang,Dun Tan,Jianfeng Dong,Jingjing Chen*

Main category: cs.CV

TL;DR: 本文提出交互式视频检索任务IVCR，并发布IVCR-200K数据集和MLLMs框架，实验验证其多轮交互的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有视频检索系统缺乏与用户的有意义“交互”，无法满足80.8%用户的个性化和动态需求，因此提出了交互式视频语料库检索（IVCR）任务。

Method: 提出了一个基于多模态大语言模型（MLLMs）的全面框架，支持多种交互模式，并提供更可解释的解决方案。

Result: 实验证明了IVCR-200K数据集和提出的框架在支持多轮、对话式交互方面的有效性。

Conclusion: 本文提出了交互式视频语料库检索（IVCR）任务，并引入了IVCR-200K数据集和基于多模态大语言模型（MLLMs）的框架，以支持多轮、对话式和现实的用户交互，实验证明了其有效性。

Abstract: In recent years, significant developments have been made in both video retrieval and video moment retrieval tasks, which respectively retrieve complete videos or moments for a given text query. These advancements have greatly improved user satisfaction during the search process. However, previous work has failed to establish meaningful "interaction" between the retrieval system and the user, and its one-way retrieval paradigm can no longer fully meet the personalization and dynamic needs of at least 80.8\% of users. In this paper, we introduce the Interactive Video Corpus Retrieval (IVCR) task, a more realistic setting that enables multi-turn, conversational, and realistic interactions between the user and the retrieval system. To facilitate research on this challenging task, we introduce IVCR-200K, a high-quality, bilingual, multi-turn, conversational, and abstract semantic dataset that supports video retrieval and even moment retrieval. Furthermore, we propose a comprehensive framework based on multi-modal large language models (MLLMs) to help users interact in several modes with more explainable solutions. The extensive experiments demonstrate the effectiveness of our dataset and framework.

</details>


### [170] [TokenPure: Watermark Removal through Tokenized Appearance and Structural Guidance](https://arxiv.org/abs/2512.01314)
*Pei Yang,Yepeng Liu,Kelly Peng,Yuan Gao,Yiren Song*

Main category: cs.CV

TL;DR: TokenPure是一种基于Diffusion Transformer的水印去除框架，通过令牌分解和条件生成实现高保真无水印图像合成，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在数字经济时代，数字水印作为所有权证明的关键基础，设计能够抵抗各种攻击和处理操作的鲁棒水印尤为重要。TokenPure旨在解决水印去除与内容一致性之间的权衡问题。

Method: TokenPure是一种基于Diffusion Transformer的框架，通过将水印图像分解为视觉令牌和结构令牌，联合调节扩散过程，生成无水印图像。

Result: 综合实验表明，TokenPure在水印去除和重建保真度方面达到了最先进的水平，在感知质量和一致性方面显著优于现有基线。

Conclusion: TokenPure通过基于令牌的条件重构，有效解决了水印彻底去除与内容一致性之间的权衡问题，实现了高保真的水印去除和重建。

Abstract: In the digital economy era, digital watermarking serves as a critical basis for ownership proof of massive replicable content, including AI-generated and other virtual assets. Designing robust watermarks capable of withstanding various attacks and processing operations is even more paramount. We introduce TokenPure, a novel Diffusion Transformer-based framework designed for effective and consistent watermark removal. TokenPure solves the trade-off between thorough watermark destruction and content consistency by leveraging token-based conditional reconstruction. It reframes the task as conditional generation, entirely bypassing the initial watermark-carrying noise. We achieve this by decomposing the watermarked image into two complementary token sets: visual tokens for texture and structural tokens for geometry. These tokens jointly condition the diffusion process, enabling the framework to synthesize watermark-free images with fine-grained consistency and structural integrity. Comprehensive experiments show that TokenPure achieves state-of-the-art watermark removal and reconstruction fidelity, substantially outperforming existing baselines in both perceptual quality and consistency.

</details>


### [171] [Optimizing Stroke Risk Prediction: A Machine Learning Pipeline Combining ROS-Balanced Ensembles and XAI](https://arxiv.org/abs/2512.01333)
*A S M Ahsanul Sarkar Akib,Raduana Khawla,Abdul Hasib*

Main category: cs.CV

TL;DR: 结合集成学习和可解释AI，开发高精度卒中风险评估模型，准确率达99.09%，关键变量为年龄、高血压和血糖。


<details>
  <summary>Details</summary>
Motivation: 卒中是导致死亡和永久性残疾的主要原因，早期风险评估对及时干预和有效预防至关重要。

Method: 采用集成建模和可解释AI（XAI）技术，包括10种不同机器学习模型的全面评估、5折交叉验证、特征工程和数据预处理（使用随机过采样ROS解决类别不平衡问题），最终优化集成模型（Random Forest + ExtraTrees + XGBoost）。

Result: 优化集成模型在卒中预测数据集（SPD）上取得了99.09%的高准确率，并通过LIME分析识别出三个关键临床变量：年龄、高血压和血糖水平。

Conclusion: 通过结合集成学习和可解释AI（XAI），本研究提供了一种高精度且可解释的卒中风险评估方法，有望通过数据驱动的预防和个性化临床决策改变卒中预测和心血管风险管理。

Abstract: Stroke is a major cause of death and permanent impairment, making it a major worldwide health concern. For prompt intervention and successful preventative tactics, early risk assessment is essential. To address this challenge, we used ensemble modeling and explainable AI (XAI) techniques to create an interpretable machine learning framework for stroke risk prediction. A thorough evaluation of 10 different machine learning models using 5-fold cross-validation across several datasets was part of our all-inclusive strategy, which also included feature engineering and data pretreatment (using Random Over-Sampling (ROS) to solve class imbalance). Our optimized ensemble model (Random Forest + ExtraTrees + XGBoost) performed exceptionally well, obtaining a strong 99.09% accuracy on the Stroke Prediction Dataset (SPD). We improved the model's transparency and clinical applicability by identifying three important clinical variables using LIME-based interpretability analysis: age, hypertension, and glucose levels. Through early prediction, this study highlights how combining ensemble learning with explainable AI (XAI) can deliver highly accurate and interpretable stroke risk assessment. By enabling data-driven prevention and personalized clinical decisions, our framework has the potential to transform stroke prediction and cardiovascular risk management.

</details>


### [172] [AlignVid: Training-Free Attention Scaling for Semantic Fidelity in Text-Guided Image-to-Video Generation](https://arxiv.org/abs/2512.01334)
*Yexin Liu,Wen-Jie Shu,Zile Huang,Haoze Zheng,Yueze Wang,Manyuan Zhang,Ser-Nam Lim,Harry Yang*

Main category: cs.CV

TL;DR: AlignVid通过轻量级注意力调制和调度策略，解决了TI2V生成中的语义忽视问题，提升了语义一致性。


<details>
  <summary>Details</summary>
Motivation: 现有TI2V生成方法在输入图像需大幅变换时（如对象增删改）存在语义忽视问题，通过高斯模糊实验发现注意力分布熵降低可改善语义一致性。

Method: 提出了AlignVid框架，包含Attention Scaling Modulation（ASM）和Guidance Scheduling（GS）两个组件，通过重新加权注意力和选择性应用调制来优化语义一致性。

Result: 实验表明AlignVid能有效提升语义忠实度，并引入OmitI2V数据集评估语义忽视现象。

Conclusion: AlignVid通过Attention Scaling Modulation（ASM）和Guidance Scheduling（GS）的轻量级干预，显著提升了TI2V生成中的语义忠实度，同时限制了视觉质量的退化。

Abstract: Text-guided image-to-video (TI2V) generation has recently achieved remarkable progress, particularly in maintaining subject consistency and temporal coherence. However, existing methods still struggle to adhere to fine-grained prompt semantics, especially when prompts entail substantial transformations of the input image (e.g., object addition, deletion, or modification), a shortcoming we term semantic negligence. In a pilot study, we find that applying a Gaussian blur to the input image improves semantic adherence. Analyzing attention maps, we observe clearer foreground-background separation. From an energy perspective, this corresponds to a lower-entropy cross-attention distribution. Motivated by this, we introduce AlignVid, a training-free framework with two components: (i) Attention Scaling Modulation (ASM), which directly reweights attention via lightweight Q or K scaling, and (ii) Guidance Scheduling (GS), which applies ASM selectively across transformer blocks and denoising steps to reduce visual quality degradation. This minimal intervention improves prompt adherence while limiting aesthetic degradation. In addition, we introduce OmitI2V to evaluate semantic negligence in TI2V generation, comprising 367 human-annotated samples that span addition, deletion, and modification scenarios. Extensive experiments demonstrate that AlignVid can enhance semantic fidelity.

</details>


### [173] [EvalTalker: Learning to Evaluate Real-Portrait-Driven Multi-Subject Talking Humans](https://arxiv.org/abs/2512.01340)
*Yingjie Zhou,Xilei Zhu,Siyu Ren,Ziyi Zhao,Ziwen Wang,Farong Wen,Yu Zhou,Jiezhang Cao,Xiongkuo Min,Fengjiao Chen,Xiaoyu Li,Xuezhi Cao,Guangtao Zhai,Xiaohong Liu*

Main category: cs.CV

TL;DR: 论文提出EvalTalker框架，通过构建THQA-MT数据集和整合Qwen-Sync，有效评估多说话人生成质量，解决现有技术局限性。


<details>
  <summary>Details</summary>
Motivation: 解决当前多说话人生成技术导致的质量下降问题，提升视听通信中的交互性和沉浸感。

Method: 构建了THQA-MT数据集，包含5,492个多说话人生成的THs，并通过主观实验分析感知差异。提出EvalTalker框架，整合Qwen-Sync感知多模态同步性。

Result: EvalTalker在感知全局质量、人类特征和身份一致性方面表现优异，与主观评分高度相关。

Conclusion: EvalTalker框架在主观评分相关性上表现优异，为高质量多说话人生成与评估的未来研究提供了坚实基础。

Abstract: Speech-driven Talking Human (TH) generation, commonly known as "Talker," currently faces limitations in multi-subject driving capabilities. Extending this paradigm to "Multi-Talker," capable of animating multiple subjects simultaneously, introduces richer interactivity and stronger immersion in audiovisual communication. However, current Multi-Talkers still exhibit noticeable quality degradation caused by technical limitations, resulting in suboptimal user experiences. To address this challenge, we construct THQA-MT, the first large-scale Multi-Talker-generated Talking Human Quality Assessment dataset, consisting of 5,492 Multi-Talker-generated THs (MTHs) from 15 representative Multi-Talkers using 400 real portraits collected online. Through subjective experiments, we analyze perceptual discrepancies among different Multi-Talkers and identify 12 common types of distortion. Furthermore, we introduce EvalTalker, a novel TH quality assessment framework. This framework possesses the ability to perceive global quality, human characteristics, and identity consistency, while integrating Qwen-Sync to perceive multimodal synchrony. Experimental results demonstrate that EvalTalker achieves superior correlation with subjective scores, providing a robust foundation for future research on high-quality Multi-Talker generation and evaluation.

</details>


### [174] [InternVideo-Next: Towards General Video Foundation Models without Video-Text Supervision](https://arxiv.org/abs/2512.01342)
*Chenting Wang,Yuhan Zhu,Yicheng Xu,Jiange Yang,Ziang Yan,Yali Wang,Yi Wang,Limin Wang*

Main category: cs.CV

TL;DR: 论文提出InternVideo-Next，通过EPD框架和两阶段预训练（扩散解码+潜在空间预测），解决了视频表示学习中语义与细节的冲突，实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 传统的大规模视频文本预训练依赖噪声大、语义覆盖有限的合成字幕，而掩码视频建模(MVM)虽直接利用时空结构，但在通用任务上表现不佳。这一差距源于被忽视的架构问题，如像素级重建的收敛困难和低层次要求与语义的冲突。

Method: 提出了Encoder-Predictor-Decoder (EPD)框架，并设计了两阶段预训练方案：第一阶段使用条件扩散解码器和图像级语义先验增强语义和收敛；第二阶段在潜在空间中预测冻结的第一阶段目标，避免捷径学习。

Result: 在公开的无标签视频上训练的InternVideo-Next在多个基准测试中达到了最先进的性能。

Conclusion: InternVideo-Next通过创新的两阶段预训练方案和EPD框架，解决了传统视频文本预训练和掩码视频建模的局限性，实现了在多个基准测试上的最先进性能，为通用视频表示学习提供了可扩展的路径。

Abstract: Large-scale video-text pretraining achieves strong performance but depends on noisy, synthetic captions with limited semantic coverage, often overlooking implicit world knowledge such as object motion, 3D geometry, and physical cues. In contrast, masked video modeling (MVM) directly exploits spatiotemporal structures but trails text-supervised methods on general tasks. We find this gap arises from overlooked architectural issues: pixel-level reconstruction struggles with convergence and its low-level requirement often conflicts with semantics, while latent prediction often encourages shortcut learning. To address these, we disentangle the traditional encoder-decoder design into an Encoder-Predictor-Decoder (EPD) framework, where the predictor acts as a latent world model, and propose InternVideo-Next, a two-stage pretraining scheme that builds a semantically consistent yet detail-preserving latent space for this world model. First, conventional linear decoder in pixel MVM enforces the predictor output latent to be linearly projected to, thus separable in pixel space, causing the conflict with semantic abstraction. Our Stage 1 proposes a conditional diffusion decoder and injects reliable image-level semantic priors to enhance semantics and convergence, thus bridging pixel-level fidelity with high-level semantic abstraction. Stage 2 further learns world knowledge by predicting frozen Stage 1 targets within this space, mitigating shortcut learning. Trained on public, unlabeled videos, InternVideo-Next achieves state-of-the-art results across benchmarks and provides a scalable path toward general video representation learning.

</details>


### [175] [Handwritten Text Recognition for Low Resource Languages](https://arxiv.org/abs/2512.01348)
*Sayantan Dey,Alireza Alaei,Partha Pratim Roy*

Main category: cs.CV

TL;DR: BharatOCR提出了一种基于ViT-Transformer Decoder-LM的段落级手写文本识别方法，在印地语和乌尔都语数据集上取得显著成果，超越现有技术。


<details>
  <summary>Details</summary>
Motivation: 低资源语言（如印地语和乌尔都语）缺乏全面的语言资源，段落级手写文本识别仍具挑战性，需开发鲁棒系统以提升OCR准确性。

Method: 采用ViT-Transformer Decoder-LM架构，结合视觉Transformer（ViT）提取视觉特征、Transformer解码器生成文本序列，以及预训练语言模型（LM）优化输出。

Result: 在NUST-UHWR、PUCIT-OUHL和Parimal-Urdu数据集上分别达到96.24%、92.05%和94.80%的字符识别率，印地语数据集上为80.64%，优于现有方法。

Conclusion: BharatOCR模型在低资源语言（如印地语和乌尔都语）的段落级手写文本识别中表现出色，显著提升了字符识别率，并超越了现有技术。

Abstract: Despite considerable progress in handwritten text recognition, paragraph-level handwritten text recognition, especially in low-resource languages, such as Hindi, Urdu and similar scripts, remains a challenging problem. These languages, often lacking comprehensive linguistic resources, require special attention to develop robust systems for accurate optical character recognition (OCR). This paper introduces BharatOCR, a novel segmentation-free paragraph-level handwritten Hindi and Urdu text recognition. We propose a ViT-Transformer Decoder-LM architecture for handwritten text recognition, where a Vision Transformer (ViT) extracts visual features, a Transformer decoder generates text sequences, and a pre-trained language model (LM) refines the output to improve accuracy, fluency, and coherence. Our model utilizes a Data-efficient Image Transformer (DeiT) model proposed for masked image modeling in this research work. In addition, we adopt a RoBERTa architecture optimized for masked language modeling (MLM) to enhance the linguistic comprehension and generative capabilities of the proposed model. The transformer decoder generates text sequences from visual embeddings. This model is designed to iteratively process a paragraph image line by line, called implicit line segmentation. The proposed model was evaluated using our custom dataset ('Parimal Urdu') and ('Parimal Hindi'), introduced in this research work, as well as two public datasets. The proposed model achieved benchmark results in the NUST-UHWR, PUCIT-OUHL, and Parimal-Urdu datasets, achieving character recognition rates of 96.24%, 92.05%, and 94.80%, respectively. The model also provided benchmark results using the Hindi dataset achieving a character recognition rate of 80.64%. The results obtained from our proposed model indicated that it outperformed several state-of-the-art Urdu text recognition methods.

</details>


### [176] [OpenBox: Annotate Any Bounding Boxes in 3D](https://arxiv.org/abs/2512.01352)
*In-Jae Lee,Mungyeom Kim,Kwonyoung Ryu,Pierre Musacchio,Jaesik Park*

Main category: cs.CV

TL;DR: OpenBox利用2D视觉基础模型实现高质量3D边界框自动标注，无需自训练，显著提升标注效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 减少标注成本并识别未见过的对象对于自动驾驶的安全性和可扩展性至关重要。现有方法存在标注质量低和计算开销大的问题。

Method: OpenBox 通过跨模态实例对齐将2D图像中的实例级线索与3D点云关联，然后根据刚性和运动状态分类实例，并生成具有类别特定尺寸统计的自适应边界框。

Result: 在Waymo Open Dataset、Lyft Level 5 Perception dataset和nuScenes dataset上的实验表明，OpenBox在准确性和效率上优于基线方法。

Conclusion: OpenBox 提出了一种两阶段自动标注管道，利用2D视觉基础模型，无需自训练即可生成高质量的3D边界框标注，在多个数据集上展示了优于基线的准确性和效率。

Abstract: Unsupervised and open-vocabulary 3D object detection has recently gained attention, particularly in autonomous driving, where reducing annotation costs and recognizing unseen objects are critical for both safety and scalability. However, most existing approaches uniformly annotate 3D bounding boxes, ignore objects' physical states, and require multiple self-training iterations for annotation refinement, resulting in suboptimal quality and substantial computational overhead. To address these challenges, we propose OpenBox, a two-stage automatic annotation pipeline that leverages a 2D vision foundation model. In the first stage, OpenBox associates instance-level cues from 2D images processed by a vision foundation model with the corresponding 3D point clouds via cross-modal instance alignment. In the second stage, it categorizes instances by rigidity and motion state, then generates adaptive bounding boxes with class-specific size statistics. As a result, OpenBox produces high-quality 3D bounding box annotations without requiring self-training. Experiments on the Waymo Open Dataset, the Lyft Level 5 Perception dataset, and the nuScenes dataset demonstrate improved accuracy and efficiency over baselines.

</details>


### [177] [BlinkBud: Detecting Hazards from Behind via Sampled Monocular 3D Detection on a Single Earbud](https://arxiv.org/abs/2512.01366)
*Yunzhe Li,Jiajun Yan,Yuzhou Wei,Kechen Liu,Yize Zhao,Chong Zhang,Hongzi Zhu,Li Lu,Shan Chang,Minyi Guo*

Main category: cs.CV

TL;DR: BlinkBud是一种利用单耳机和配对手机实时检测后方危险物体的系统，通过创新的3D跟踪算法和优化采样策略，实现了低功耗和高精度检测。


<details>
  <summary>Details</summary>
Motivation: 后方接近的快速车辆对行人和骑行者的道路安全构成巨大威胁，需要一种低功耗且高精度的解决方案来实时检测这些危险物体。

Method: 结合基于卡尔曼滤波的轨迹估计方案和基于强化学习的最优图像采样策略，设计了一种新型3D物体跟踪算法，并通过利用估计的俯仰和偏航角校正物体深度估计和对齐坐标系，显著减少了用户头部运动对跟踪精度的影响。

Result: BlinkBud原型系统在真实环境中的实验表明，其平均功耗极低（耳机29.8 mW，智能手机702.6 mW），且能准确检测危险物体，平均假阳性率（FPR）和假阴性率（FNR）分别为4.90%和1.47%。

Conclusion: BlinkBud系统通过创新的3D物体跟踪算法和优化的图像采样策略，实现了对后方接近危险物体的高效检测，显著提升了行人和骑行者的道路安全。

Abstract: Failing to be aware of speeding vehicles approaching from behind poses a huge threat to the road safety of pedestrians and cyclists. In this paper, we propose BlinkBud, which utilizes a single earbud and a paired phone to online detect hazardous objects approaching from behind of a user. The core idea is to accurately track visually identified objects utilizing a small number of sampled camera images taken from the earbud. To minimize the power consumption of the earbud and the phone while guaranteeing the best tracking accuracy, a novel 3D object tracking algorithm is devised, integrating both a Kalman filter based trajectory estimation scheme and an optimal image sampling strategy based on reinforcement learning. Moreover, the impact of constant user head movements on the tracking accuracy is significantly eliminated by leveraging the estimated pitch and yaw angles to correct the object depth estimation and align the camera coordinate system to the user's body coordinate system, respectively. We implement a prototype BlinkBud system and conduct extensive real-world experiments. Results show that BlinkBud is lightweight with ultra-low mean power consumptions of 29.8 mW and 702.6 mW on the earbud and smartphone, respectively, and can accurately detect hazards with a low average false positive ratio (FPR) and false negative ratio (FNR) of 4.90% and 1.47%, respectively.

</details>


### [178] [SRAM: Shape-Realism Alignment Metric for No Reference 3D Shape Evaluation](https://arxiv.org/abs/2512.01373)
*Sheng Liu,Tianyu Luan,Phani Nuney,Xuelu Feng,Junsong Yuan*

Main category: cs.CV

TL;DR: 提出一种基于语言模型的3D形状真实感评估指标，无需地面真实参考，实验显示其性能优越。


<details>
  <summary>Details</summary>
Motivation: 传统评估方法依赖地面真实参考，但实际应用中形状的真实感常无需参考。因此，需要一种无需参考的真实感评估方法。

Method: 采用网格编码方法将3D形状转换为语言标记空间，并设计专用真实感解码器，以对齐语言模型输出与人类真实感感知。

Result: 实验证明，该指标与人类感知相关性高，泛化能力强，且优于现有方法。

Conclusion: 提出的Shape-Realism Alignment Metric在无需地面真实参考的情况下，能有效评估3D形状的真实感，且与人类感知高度一致，优于现有方法。

Abstract: 3D generation and reconstruction techniques have been widely used in computer games, film, and other content creation areas. As the application grows, there is a growing demand for 3D shapes that look truly realistic. Traditional evaluation methods rely on a ground truth to measure mesh fidelity. However, in many practical cases, a shape's realism does not depend on having a ground truth reference. In this work, we propose a Shape-Realism Alignment Metric that leverages a large language model (LLM) as a bridge between mesh shape information and realism evaluation. To achieve this, we adopt a mesh encoding approach that converts 3D shapes into the language token space. A dedicated realism decoder is designed to align the language model's output with human perception of realism. Additionally, we introduce a new dataset, RealismGrading, which provides human-annotated realism scores without the need for ground truth shapes. Our dataset includes shapes generated by 16 different algorithms on over a dozen objects, making it more representative of practical 3D shape distributions. We validate our metric's performance and generalizability through k-fold cross-validation across different objects. Experimental results show that our metric correlates well with human perceptions and outperforms existing methods, and has good generalizability.

</details>


### [179] [Textured Geometry Evaluation: Perceptual 3D Textured Shape Metric via 3D Latent-Geometry Network](https://arxiv.org/abs/2512.01380)
*Tianyu Luan,Xuelu Feng,Zixin Zhu,Phani Nuney,Sheng Liu,Xuan Gong,David Doermann,Chunming Qiao,Junsong Yuan*

Main category: cs.CV

TL;DR: 提出TGE方法，直接评估带纹理3D网格的保真度，结合几何和颜色信息，在真实数据集上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法（如Chamfer Distance）与人类评估方式不一致，学习型方法因结构覆盖不全和视角选择敏感性问题受限，且训练数据与真实失真存在差距。

Method: 提出了一种名为TGE的新方法，直接基于带纹理的3D网格进行评估，结合几何和颜色信息计算保真度。

Result: TGE在真实世界失真数据集上表现优于现有方法。

Conclusion: TGE方法在真实世界失真数据集上表现优于基于渲染和仅几何的方法，验证了其有效性。

Abstract: Textured high-fidelity 3D models are crucial for games, AR/VR, and film, but human-aligned evaluation methods still fall behind despite recent advances in 3D reconstruction and generation. Existing metrics, such as Chamfer Distance, often fail to align with how humans evaluate the fidelity of 3D shapes. Recent learning-based metrics attempt to improve this by relying on rendered images and 2D image quality metrics. However, these approaches face limitations due to incomplete structural coverage and sensitivity to viewpoint choices. Moreover, most methods are trained on synthetic distortions, which differ significantly from real-world distortions, resulting in a domain gap. To address these challenges, we propose a new fidelity evaluation method that is based directly on 3D meshes with texture, without relying on rendering. Our method, named Textured Geometry Evaluation TGE, jointly uses the geometry and color information to calculate the fidelity of the input textured mesh with comparison to a reference colored shape. To train and evaluate our metric, we design a human-annotated dataset with real-world distortions. Experiments show that TGE outperforms rendering-based and geometry-only methods on real-world distortion dataset.

</details>


### [180] [Reversible Inversion for Training-Free Exemplar-guided Image Editing](https://arxiv.org/abs/2512.01382)
*Yuke Li,Lianli Gao,Ji Zhang,Pengpeng Zeng,Lichuan Xiang,Hongkai Wen,Heng Tao Shen,Jingkuan Song*

Main category: cs.CV

TL;DR: 提出ReInversion方法，通过两阶段去噪和选择性掩码策略，实现高效、高质量的示例引导图像编辑，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法需大规模预训练或标准反转技术效果不佳，导致计算成本高且编辑质量差，因此需要一种更高效、高质量的训练免费解决方案。

Method: 提出了Reversible Inversion (ReInversion)方法，包括两阶段去噪过程和Mask-Guided Selective Denoising (MSD)策略，前者先基于源图像后基于参考图像进行去噪，后者通过掩码约束编辑区域。

Result: ReInversion在定性和定量比较中均达到最先进的EIE性能，且计算开销最低。

Conclusion: ReInversion方法通过两阶段去噪过程和选择性去噪策略，在保持背景结构一致性的同时，实现了高效且高质量的图像编辑，显著降低了计算开销。

Abstract: Exemplar-guided Image Editing (EIE) aims to modify a source image according to a visual reference. Existing approaches often require large-scale pre-training to learn relationships between the source and reference images, incurring high computational costs. As a training-free alternative, inversion techniques can be used to map the source image into a latent space for manipulation. However, our empirical study reveals that standard inversion is sub-optimal for EIE, leading to poor quality and inefficiency. To tackle this challenge, we introduce \textbf{Reversible Inversion ({ReInversion})} for effective and efficient EIE. Specifically, ReInversion operates as a two-stage denoising process, which is first conditioned on the source image and subsequently on the reference. Besides, we introduce a Mask-Guided Selective Denoising (MSD) strategy to constrain edits to target regions, preserving the structural consistency of the background. Both qualitative and quantitative comparisons demonstrate that our ReInversion method achieves state-of-the-art EIE performance with the lowest computational overhead.

</details>


### [181] [PointNet4D: A Lightweight 4D Point Cloud Video Backbone for Online and Offline Perception in Robotic Applications](https://arxiv.org/abs/2512.01383)
*Yunze Liu,Zifan Wang,Peiran Wu,Jiayang Ao*

Main category: cs.CV

TL;DR: PointNet4D：轻量级4D骨干网络，结合Mamba和Transformer，高效处理动态4D数据，适用于实时应用，性能优越。


<details>
  <summary>Details</summary>
Motivation: 动态4D环境理解对机器人和交互系统至关重要，但现有4D骨干网络依赖计算密集的时空卷积和Transformer，难以满足实时需求。

Method: 提出 PointNet4D，核心是 Hybrid Mamba-Transformer 时间融合块，结合了 Mamba 的高效状态空间建模和 Transformer 的双向建模能力，并引入4DMAP帧级掩码自回归预训练策略。

Result: 在7个数据集的9个任务上评估，表现一致优于现有方法，并在机器人应用（如4D Diffusion Policy和4D Imitation Learning）中取得显著提升。

Conclusion: PointNet4D 是一个轻量级的4D骨干网络，适用于在线和离线场景，通过 Hybrid Mamba-Transformer 时间融合块和4DMAP预训练策略，显著提升了动态4D环境理解的性能，并在多个任务和数据集上展示了其优越性。

Abstract: Understanding dynamic 4D environments-3D space evolving over time-is critical for robotic and interactive systems. These applications demand systems that can process streaming point cloud video in real-time, often under resource constraints, while also benefiting from past and present observations when available. However, current 4D backbone networks rely heavily on spatiotemporal convolutions and Transformers, which are often computationally intensive and poorly suited to real-time applications. We propose PointNet4D, a lightweight 4D backbone optimized for both online and offline settings. At its core is a Hybrid Mamba-Transformer temporal fusion block, which integrates the efficient state-space modeling of Mamba and the bidirectional modeling power of Transformers. This enables PointNet4D to handle variable-length online sequences efficiently across different deployment scenarios. To enhance temporal understanding, we introduce 4DMAP, a frame-wise masked auto-regressive pretraining strategy that captures motion cues across frames. Our extensive evaluations across 9 tasks on 7 datasets, demonstrating consistent improvements across diverse domains. We further demonstrate PointNet4D's utility by building two robotic application systems: 4D Diffusion Policy and 4D Imitation Learning, achieving substantial gains on the RoboTwin and HandoverSim benchmarks.

</details>


### [182] [FRAMER: Frequency-Aligned Self-Distillation with Adaptive Modulation Leveraging Diffusion Priors for Real-World Image Super-Resolution](https://arxiv.org/abs/2512.01390)
*Seungho Choi,Jeahun Sung,Jihyong Oh*

Main category: cs.CV

TL;DR: FRAMER是一种即插即用的训练方案，通过频率分解和对比损失优化扩散模型的高频细节重建能力，显著提升了图像超分辨率的性能。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在感知质量上优于GANs，但由于低频（LF）偏差和深度上的“低频优先，高频后置”层次结构，其在重建高频（HF）细节方面表现不足。因此，需要一种方法在不改变主干或推理的情况下，利用扩散先验提升高频细节重建能力。

Method: FRAMER采用了一种基于频率的对比损失和自适应调制器的方法。具体包括：1. 使用FFT掩码将教师和学生特征图分解为低频（LF）和高频（HF）波段；2. 对LF使用Intra Contrastive Loss（IntraCL）稳定全局共享结构；3. 对HF使用Inter Contrastive Loss（InterCL）通过随机层和批内负样本锐化实例特定细节；4. 引入Frequency-based Adaptive Weight（FAW）和Frequency-based Alignment Modulation（FAM）自适应调制器，根据当前相似性重新加权每层LF/HF信号并控制蒸馏。

Result: 在U-Net和DiT主干（如Stable Diffusion 2、3）上，FRAMER在PSNR/SSIM和感知指标（LPIPS、NIQE、MANIQA、MUSIQ）上均表现出持续改进。消融实验验证了最终层教师和随机层负样本的有效性。

Conclusion: FRAMER作为一种即插即用的训练方案，通过利用扩散先验而不改变主干或推理过程，显著提升了图像超分辨率的性能。实验结果表明，该方法在PSNR/SSIM和感知指标（LPIPS、NIQE、MANIQA、MUSIQ）上均有持续改进。

Abstract: Real-image super-resolution (Real-ISR) seeks to recover HR images from LR inputs with mixed, unknown degradations. While diffusion models surpass GANs in perceptual quality, they under-reconstruct high-frequency (HF) details due to a low-frequency (LF) bias and a depth-wise "low-first, high-later" hierarchy. We introduce FRAMER, a plug-and-play training scheme that exploits diffusion priors without changing the backbone or inference. At each denoising step, the final-layer feature map teaches all intermediate layers. Teacher and student feature maps are decomposed into LF/HF bands via FFT masks to align supervision with the model's internal frequency hierarchy. For LF, an Intra Contrastive Loss (IntraCL) stabilizes globally shared structure. For HF, an Inter Contrastive Loss (InterCL) sharpens instance-specific details using random-layer and in-batch negatives. Two adaptive modulators, Frequency-based Adaptive Weight (FAW) and Frequency-based Alignment Modulation (FAM), reweight per-layer LF/HF signals and gate distillation by current similarity. Across U-Net and DiT backbones (e.g., Stable Diffusion 2, 3), FRAMER consistently improves PSNR/SSIM and perceptual metrics (LPIPS, NIQE, MANIQA, MUSIQ). Ablations validate the final-layer teacher and random-layer negatives.

</details>


### [183] [MDiff4STR: Mask Diffusion Model for Scene Text Recognition](https://arxiv.org/abs/2512.01422)
*Yongkun Du,Miaomiao Zhao,Songlin Fan,Zhineng Chen,Caiyan Jia,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: MDiff4STR通过优化噪声策略和引入token-replacement机制，显著提升MDMs在STR任务中的精度，同时保持高效。


<details>
  <summary>Details</summary>
Motivation: 尽管MDMs在效率上优于ARMs，但在STR任务中精度不足，需解决训练与推理的噪声差异及过度自信预测问题。

Method: 提出MDiff4STR模型，包含六种噪声训练策略以对齐训练与推理行为，以及token-replacement噪声机制以修正过度自信的预测。

Result: 在标准及挑战性STR基准测试中，MDiff4STR在多种场景下均优于现有模型，精度超越ARMs且仅需三步去噪。

Conclusion: MDiff4STR通过两种改进策略（六种噪声训练策略和token-replacement噪声机制）有效解决了MDMs在STR任务中的关键挑战，不仅在精度上超越现有ARMs，同时保持了高效推理。

Abstract: Mask Diffusion Models (MDMs) have recently emerged as a promising alternative to auto-regressive models (ARMs) for vision-language tasks, owing to their flexible balance of efficiency and accuracy. In this paper, for the first time, we introduce MDMs into the Scene Text Recognition (STR) task. We show that vanilla MDM lags behind ARMs in terms of accuracy, although it improves recognition efficiency. To bridge this gap, we propose MDiff4STR, a Mask Diffusion model enhanced with two key improvement strategies tailored for STR. Specifically, we identify two key challenges in applying MDMs to STR: noising gap between training and inference, and overconfident predictions during inference. Both significantly hinder the performance of MDMs. To mitigate the first issue, we develop six noising strategies that better align training with inference behavior. For the second, we propose a token-replacement noise mechanism that provides a non-mask noise type, encouraging the model to reconsider and revise overly confident but incorrect predictions. We conduct extensive evaluations of MDiff4STR on both standard and challenging STR benchmarks, covering diverse scenarios including irregular, artistic, occluded, and Chinese text, as well as whether the use of pretraining. Across these settings, MDiff4STR consistently outperforms popular STR models, surpassing state-of-the-art ARMs in accuracy, while maintaining fast inference with only three denoising steps. Code: https://github.com/Topdu/OpenOCR.

</details>


### [184] [\textit{ViRectify}: A Challenging Benchmark for Video Reasoning Correction with Multimodal Large Language Models](https://arxiv.org/abs/2512.01424)
*Xusen Hei,Jiali Chen,Jinyu Yang,Mengchen Zhao,Yi Cai*

Main category: cs.CV

TL;DR: ViRectify是一个评估多模态大语言模型在视频推理中错误纠正能力的基准，通过AI辅助标注和轨迹证据驱动框架，揭示了模型的系统性弱点并提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有基准缺乏对MLLMs在复杂视频推理场景中识别和纠正错误的系统性评估，ViRectify旨在填补这一空白。

Method: 通过AI辅助标注流程和人工验证构建了包含30K实例的数据集，提出了轨迹证据驱动的纠正框架，包括逐步错误轨迹和视觉证据驱动的奖励建模。

Result: ViRectify是一个具有挑战性的测试平台，GPT-5的纠正准确率仅为31.94%，而Qwen2.5-VL-7B模型通过该框架表现优于72B变体。

Conclusion: ViRectify为全面评估先进多模态大语言模型（MLLMs）在视频推理中的表现提供了新方向，其框架和数据集揭示了模型在错误纠正中的系统性不对称性，并可作为反思学习的宝贵资源。

Abstract: As multimodal large language models (MLLMs) frequently exhibit errors in complex video reasoning scenarios, correcting these errors is critical for uncovering their weaknesses and improving performance. However, existing benchmarks lack systematic evaluation of MLLMs' ability to identify and correct these video reasoning errors. To bridge this gap, we propose \textit{ViRectify}, a comprehensive benchmark to evaluate their fine-grained correction capability. Through an AI-assisted annotation pipeline with human verification, we construct a dataset of over 30\textit{K} instances spanning dynamic perception, scientific reasoning, and embodied decision-making domains. In \textit{ViRectify}, we challenge MLLMs to perform step-wise error identification and generate rationales with key video evidence grounding. In addition, we further propose the trajectory evidence-driven correction framework, comprising step-wise error trajectory and reward modeling on visual evidence-grounded correction. It encourages the model to explicitly concentrate on error propagation and key timestamps for correction. Extensive evaluation across 16 advanced MLLMs demonstrates that our \textit{ViRectify} serves as a challenging testbed, where GPT-5 achieves only 31.94\% correction accuracy. Our framework enables a Qwen2.5-VL-7B to consistently outperform the variants of 72B on \textit{ViRectify}, showing the effectiveness of our approach. Further analysis uncovers systematic asymmetries in error correction across models, and our dataset is also a valuable data resource to perform reflection learning. We believe \textit{ViRectify} provides a new direction for comprehensively evaluating the advanced MLLMs in video reasoning.

</details>


### [185] [ResDiT: Evoking the Intrinsic Resolution Scalability in Diffusion Transformers](https://arxiv.org/abs/2512.01426)
*Yiyang Ma,Feng Zhou,Xuedan Yin,Pu Cao,Yonghao Dang,Jianqin Yin*

Main category: cs.CV

TL;DR: ResDiT通过PE缩放和局部增强，解决了DiTs在高分辨率合成中的布局崩溃和纹理退化问题，实现了高效高质量生成。


<details>
  <summary>Details</summary>
Motivation: 预训练的DiTs在高分辨率图像合成中常出现空间布局崩溃和纹理退化，现有方法复杂且效率低，因此探索DiTs的生成机制并提出更高效的解决方案。

Method: 提出了ResDiT，一种无需训练的方法，通过PE缩放技术纠正位置编码，并结合局部增强机制和补丁级融合模块，提升高分辨率合成的质量。

Result: ResDiT在高分辨率图像合成中表现优异，能无缝集成到下游任务中，如空间控制生成。

Conclusion: ResDiT通过创新的PE缩放技术和局部增强机制，有效解决了高分辨率图像合成中的空间布局崩溃和纹理退化问题，实现了高质量的无缝集成。

Abstract: Leveraging pre-trained Diffusion Transformers (DiTs) for high-resolution (HR) image synthesis often leads to spatial layout collapse and degraded texture fidelity. Prior work mitigates these issues with complex pipelines that first perform a base-resolution (i.e., training-resolution) denoising process to guide HR generation. We instead explore the intrinsic generative mechanisms of DiTs and propose ResDiT, a training-free method that scales resolution efficiently. We identify the core factor governing spatial layout, position embeddings (PEs), and show that the original PEs encode incorrect positional information when extrapolated to HR, which triggers layout collapse. To address this, we introduce a PE scaling technique that rectifies positional encoding under resolution changes. To further remedy low-fidelity details, we develop a local-enhancement mechanism grounded in base-resolution local attention. We design a patch-level fusion module that aggregates global and local cues, together with a Gaussian-weighted splicing strategy that eliminates grid artifacts. Comprehensive evaluations demonstrate that ResDiT consistently delivers high-fidelity, high-resolution image synthesis and integrates seamlessly with downstream tasks, including spatially controlled generation.

</details>


### [186] [Language-Guided Open-World Anomaly Segmentation](https://arxiv.org/abs/2512.01427)
*Klara Reichard,Nikolas Brasch,Nassir Navab,Federico Tombari*

Main category: cs.CV

TL;DR: Clipomaly是首个基于CLIP的开放世界和异常分割方法，通过零样本学习动态扩展词汇表，为未知对象提供可解释标签，性能领先。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法为未知区域分配有意义的语义标签，且难以区分和学习未知类的表示。开放词汇分割方法虽能泛化到新类，但需固定推理词汇表，无法直接应用于异常分割。

Method: Clipomaly利用CLIP共享的图像-文本嵌入空间，无需异常特定训练数据，通过零样本方法动态扩展推理词汇表，实现未知对象的分割和命名。

Result: Clipomaly在异常分割基准上达到最先进性能，并提供解释性和灵活性，适用于实际部署。

Conclusion: Clipomaly作为首个基于CLIP的开放世界和异常分割方法，在自动驾驶领域实现了无需异常特定训练数据的零样本学习，能够动态扩展词汇表并赋予未知对象人类可理解的标签，同时在异常分割基准上达到最先进性能。

Abstract: Open-world and anomaly segmentation methods seek to enable autonomous driving systems to detect and segment both known and unknown objects in real-world scenes. However, existing methods do not assign semantically meaningful labels to unknown regions, and distinguishing and learning representations for unknown classes remains difficult. While open-vocabulary segmentation methods show promise in generalizing to novel classes, they require a fixed inference vocabulary and thus cannot be directly applied to anomaly segmentation where unknown classes are unconstrained. We propose Clipomaly, the first CLIP-based open-world and anomaly segmentation method for autonomous driving. Our zero-shot approach requires no anomaly-specific training data and leverages CLIP's shared image-text embedding space to both segment unknown objects and assign human-interpretable names to them. Unlike open-vocabulary methods, our model dynamically extends its vocabulary at inference time without retraining, enabling robust detection and naming of anomalies beyond common class definitions such as those in Cityscapes. Clipomaly achieves state-of-the-art performance on established anomaly segmentation benchmarks while providing interpretability and flexibility essential for practical deployment.

</details>


### [187] [FastAnimate: Towards Learnable Template Construction and Pose Deformation for Fast 3D Human Avatar Animation](https://arxiv.org/abs/2512.01444)
*Jian Shu,Nanjie Yao,Gangjian Zhang,Junlong Ren,Yu Feng,Hao Wang*

Main category: cs.CV

TL;DR: 提出统一学习框架，通过U-Net快速生成模板和数据驱动细化技术，解决3D人体动画中的模板构建和姿态变形问题，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在模板构建阶段需要大量骨骼绑定且易产生伪影，以及目标姿态变形中因线性混合蒙皮导致结构失真的问题。

Method: 采用U-Net架构分离纹理和姿态信息，快速生成人体模板；并提出数据驱动的细化技术增强结构完整性。

Result: 实验表明，该模型在多样姿态下表现一致，效率与质量平衡，优于现有技术。

Conclusion: 该论文提出的统一学习框架在3D人体角色动画中显著提升了模板构建和目标姿态变形的效率与质量，超越了现有方法。

Abstract: 3D human avatar animation aims at transforming a human avatar from an arbitrary initial pose to a specified target pose using deformation algorithms. Existing approaches typically divide this task into two stages: canonical template construction and target pose deformation. However, current template construction methods demand extensive skeletal rigging and often produce artifacts for specific poses. Moreover, target pose deformation suffers from structural distortions caused by Linear Blend Skinning (LBS), which significantly undermines animation realism. To address these problems, we propose a unified learning-based framework to address both challenges in two phases. For the former phase, to overcome the inefficiencies and artifacts during template construction, we leverage a U-Net architecture that decouples texture and pose information in a feed-forward process, enabling fast generation of a human template. For the latter phase, we propose a data-driven refinement technique that enhances structural integrity. Extensive experiments show that our model delivers consistent performance across diverse poses with an optimal balance between efficiency and quality,surpassing state-of-the-art (SOTA) methods.

</details>


### [188] [CourtMotion: Learning Event-Driven Motion Representations from Skeletal Data for Basketball](https://arxiv.org/abs/2512.01478)
*Omer Sela,Michael Chertok,Lior Wolf*

Main category: cs.CV

TL;DR: CourtMotion框架利用骨骼数据和图神经网络提升篮球事件预测，减少轨迹误差35%，并在多项任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅依赖球员位置数据，无法捕捉身体朝向、防守姿态或投篮准备动作等关键指标，因此需要更全面的运动模式理解。

Method: 采用两阶段方法：首先使用图神经网络处理骨骼跟踪数据捕捉细微动作模式，然后通过带有特殊注意力机制的Transformer架构建模球员互动。引入事件投影头明确连接球员动作与篮球事件。

Result: 在NBA追踪数据上的实验显示，相比仅基于位置的最先进模型，轨迹预测误差减少35%，并在多项篮球分析任务中表现优异。

Conclusion: CourtMotion框架通过结合骨骼跟踪数据和图神经网络，显著提升了篮球事件预测的准确性，为下游任务提供了强大的预训练模型。

Abstract: This paper presents CourtMotion, a spatiotemporal modeling framework for analyzing and predicting game events and plays as they develop in professional basketball. Anticipating basketball events requires understanding both physical motion patterns and their semantic significance in the context of the game. Traditional approaches that use only player positions fail to capture crucial indicators such as body orientation, defensive stance, or shooting preparation motions. Our two-stage approach first processes skeletal tracking data through Graph Neural Networks to capture nuanced motion patterns, then employs a Transformer architecture with specialized attention mechanisms to model player interactions. We introduce event projection heads that explicitly connect player movements to basketball events like passes, shots, and steals, training the model to associate physical motion patterns with their tactical purposes. Experiments on NBA tracking data demonstrate significant improvements over position-only baselines: 35% reduction in trajectory prediction error compared to state-of-the-art position-based models and consistent performance gains across key basketball analytics tasks. The resulting pretrained model serves as a powerful foundation for multiple downstream tasks, with pick detection, shot taker identification, assist prediction, shot location classification, and shot type recognition demonstrating substantial improvements over existing methods.

</details>


### [189] [ChronosObserver: Taming 4D World with Hyperspace Diffusion Sampling](https://arxiv.org/abs/2512.01481)
*Qisen Wang,Yifan Zhao,Peisen Shen,Jialu Li,Jia Li*

Main category: cs.CV

TL;DR: ChronosObserver是一种无需训练的方法，通过时空约束和采样轨迹同步技术，实现高质量多视角视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有相机控制视频生成模型难以直接生成3D一致且时间同步的多视角视频，数据增强或测试时优化策略又受限于模型泛化能力和可扩展性问题。

Method: 该方法包括World State Hyperspace来表示4D世界场景的时空约束，以及Hyperspace Guided Sampling来同步多视角的扩散采样轨迹。

Result: 实验结果表明，该方法无需训练或微调扩散模型，即可生成高质量的多视角视频。

Conclusion: ChronosObserver提出了一种无需训练的方法，通过World State Hyperspace和Hyperspace Guided Sampling技术，成功实现了高保真、3D一致且时间同步的多视角视频生成。

Abstract: Although prevailing camera-controlled video generation models can produce cinematic results, lifting them directly to the generation of 3D-consistent and high-fidelity time-synchronized multi-view videos remains challenging, which is a pivotal capability for taming 4D worlds. Some works resort to data augmentation or test-time optimization, but these strategies are constrained by limited model generalization and scalability issues. To this end, we propose ChronosObserver, a training-free method including World State Hyperspace to represent the spatiotemporal constraints of a 4D world scene, and Hyperspace Guided Sampling to synchronize the diffusion sampling trajectories of multiple views using the hyperspace. Experimental results demonstrate that our method achieves high-fidelity and 3D-consistent time-synchronized multi-view videos generation without training or fine-tuning for diffusion models.

</details>


### [190] [A variational method for curve extraction with curvature-dependent energies](https://arxiv.org/abs/2512.01494)
*Majid Arthaud,Antonin Chambolle,Vincent Duval*

Main category: cs.CV

TL;DR: 提出变分方法提取图像曲线，扩展到曲率依赖能量，实现无监督1D结构提取。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种主要无监督的方法，从图像中自动提取曲线和1D结构。

Method: 采用双层最小化方法和子黎曼或Finslerian度量，结合位置和方向的提升技术。

Result: 成功实现了曲线和1D结构的自动提取，并扩展到曲率依赖能量的情况。

Conclusion: 该论文提出了一种基于变分方法和Smirnov分解定理的曲线提取方法，并扩展到曲率依赖能量，展示了在图像中自动提取曲线和1D结构的有效性。

Abstract: We introduce a variational approach for extracting curves between a list of possible endpoints, based on the discretization of an energy and Smirnov's decomposition theorem for vector fields. It is used to design a bi-level minimization approach to automatically extract curves and 1D structures from an image, which is mostly unsupervised. We extend then the method to curvature-dependent energies, using a now classical lifting of the curves in the space of positions and orientations equipped with an appropriate sub-Riemanian or Finslerian metric.

</details>


### [191] [ELVIS: Enhance Low-Light for Video Instance Segmentation in the Dark](https://arxiv.org/abs/2512.01495)
*Joanne Lin,Ruirui Lin,Yini Li,David Bull,Nantheera Anantrasirichai*

Main category: cs.CV

TL;DR: ELVIS是一种新框架，通过无监督合成低光视频和改进的VIS模型适应低光场景，性能提升显著。


<details>
  <summary>Details</summary>
Motivation: 低光视频实例分割（VIS）由于噪声、模糊和低对比度等不利成像条件，以及缺乏大规模标注数据集和现有合成流程的局限性，尤其是时间退化的建模不足，导致现有方法在低光视频中表现不佳。

Method: ELVIS框架包括无监督合成低光视频流程、VDP-Net和增强解码器头部，用于分离退化特征和内容特征。

Result: ELVIS在合成低光YouTube-VIS 2019数据集上性能最高提升了3.7AP。

Conclusion: ELVIS框架通过无监督合成低光视频流程、校准自由退化轮廓合成网络（VDP-Net）和增强解码器头部，显著提升了低光视频实例分割的性能，最高提升了3.7AP。

Abstract: Video instance segmentation (VIS) for low-light content remains highly challenging for both humans and machines alike, due to adverse imaging conditions including noise, blur and low-contrast. The lack of large-scale annotated datasets and the limitations of current synthetic pipelines, particularly in modeling temporal degradations, further hinder progress. Moreover, existing VIS methods are not robust to the degradations found in low-light videos and, as a result, perform poorly even when finetuned on low-light data. In this paper, we introduce \textbf{ELVIS} (\textbf{E}nhance \textbf{L}ow-light for \textbf{V}ideo \textbf{I}nstance \textbf{S}egmentation), a novel framework that enables effective domain adaptation of state-of-the-art VIS models to low-light scenarios. ELVIS comprises an unsupervised synthetic low-light video pipeline that models both spatial and temporal degradations, a calibration-free degradation profile synthesis network (VDP-Net) and an enhancement decoder head that disentangles degradations from content features. ELVIS improves performances by up to \textbf{+3.7AP} on the synthetic low-light YouTube-VIS 2019 dataset. Code will be released upon acceptance.

</details>


### [192] [Semantic-aware Random Convolution and Source Matching for Domain Generalization in Medical Image Segmentation](https://arxiv.org/abs/2512.01510)
*Franz Thaler,Martin Urschler,Mateusz Kozinski,Matthias AF Gsell,Gernot Plank,Darko Stern*

Main category: cs.CV

TL;DR: SRCSM是一种新的医学图像分割领域泛化方法，通过语义感知随机卷积和强度映射，在多个实验中表现优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像分割中的单源领域泛化问题，旨在在一个领域（如CT）上训练网络并直接应用于不同领域（如MR），无需调整模型或训练时获取新领域的图像或注释。

Method: 提出了SRCSM方法，通过语义感知随机卷积在训练时多样化源域，并在测试时通过映射目标域图像强度使其与源域数据相似。

Result: 在多种跨模态和跨中心泛化设置中，SRCSM在大多数实验中优于之前的领域泛化技术。

Conclusion: SRCSM方法在医学图像分割的领域泛化中达到了新的最先进水平，并在多个设置中匹配了域内基线的分割性能。

Abstract: We tackle the challenging problem of single-source domain generalization (DG) for medical image segmentation. To this end, we aim for training a network on one domain (e.g., CT) and directly apply it to a different domain (e.g., MR) without adapting the model and without requiring images or annotations from the new domain during training. We propose a novel method for promoting DG when training deep segmentation networks, which we call SRCSM. During training, our method diversifies the source domain through semantic-aware random convolution, where different regions of a source image are augmented differently, based on their annotation labels. At test-time, we complement the randomization of the training domain via mapping the intensity of target domain images, making them similar to source domain data. We perform a comprehensive evaluation on a variety of cross-modality and cross-center generalization settings for abdominal, whole-heart and prostate segmentation, where we outperform previous DG techniques in a vast majority of experiments. Additionally, we also investigate our method when training on whole-heart CT or MR data and testing on the diastolic and systolic phase of cine MR data captured with different scanner hardware, where we make a step towards closing the domain gap in this even more challenging setting. Overall, our evaluation shows that SRCSM can be considered a new state-of-the-art in DG for medical image segmentation and, moreover, even achieves a segmentation performance that matches the performance of the in-domain baseline in several settings.

</details>


### [193] [QuantumCanvas: A Multimodal Benchmark for Visual Learning of Atomic Interactions](https://arxiv.org/abs/2512.01519)
*Can Polat,Erchin Serpedin,Mustafa Kurban,Hasan Kurban*

Main category: cs.CV

TL;DR: QuantumCanvas是一个多模态基准数据集，旨在通过视觉和数值模态学习可转移的量子相互作用，显著提升了模型的收敛稳定性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有分子和材料机器学习模型缺乏物理可转移性，因为它们通常拟合整个分子或晶体的相关性，而非学习原子对之间的量子相互作用。

Method: 引入QuantumCanvas，一个大规模多模态基准数据集，涵盖2850个元素-元素对，每个对标注有18种电子、热力学和几何性质，并配有十通道图像表示。

Result: 在18个目标上测试了八种架构，报告了不同模型在能量间隙、HOMO、LUMO等指标上的平均绝对误差，并展示了在QM9、MD17和CrysMTM等数据集上的微调效果。

Conclusion: QuantumCanvas通过结合轨道物理和基于视觉的表征学习，为学习可转移的量子相互作用提供了有原则且可解释的基础。

Abstract: Despite rapid advances in molecular and materials machine learning, most models still lack physical transferability: they fit correlations across whole molecules or crystals rather than learning the quantum interactions between atomic pairs. Yet bonding, charge redistribution, orbital hybridization, and electronic coupling all emerge from these two-body interactions that define local quantum fields in many-body systems. We introduce QuantumCanvas, a large-scale multimodal benchmark that treats two-body quantum systems as foundational units of matter. The dataset spans 2,850 element-element pairs, each annotated with 18 electronic, thermodynamic, and geometric properties and paired with ten-channel image representations derived from l- and m-resolved orbital densities, angular field transforms, co-occupancy maps, and charge-density projections. These physically grounded images encode spatial, angular, and electrostatic symmetries without explicit coordinates, providing an interpretable visual modality for quantum learning. Benchmarking eight architectures across 18 targets, we report mean absolute errors of 0.201 eV on energy gap using GATv2, 0.265 eV on HOMO and 0.274 eV on LUMO using EGNN. For energy-related quantities, DimeNet attains 2.27 eV total-energy MAE and 0.132 eV repulsive-energy MAE, while a multimodal fusion model achieves a 2.15 eV Mermin free-energy MAE. Pretraining on QuantumCanvas further improves convergence stability and generalization when fine-tuned on larger datasets such as QM9, MD17, and CrysMTM. By unifying orbital physics with vision-based representation learning, QuantumCanvas provides a principled and interpretable basis for learning transferable quantum interactions through coupled visual and numerical modalities. Dataset and model implementations are available at https://github.com/KurbanIntelligenceLab/QuantumCanvas.

</details>


### [194] [FlashVGGT: Efficient and Scalable Visual Geometry Transformers with Compressed Descriptor Attention](https://arxiv.org/abs/2512.01540)
*Zipeng Wang,Dan Xu*

Main category: cs.CV

TL;DR: FlashVGGT通过描述符压缩和跨注意力机制，高效解决了VGGT的计算瓶颈，适用于长序列3D重建。


<details>
  <summary>Details</summary>
Motivation: 传统全自注意力方法（如VGGT）因二次复杂度和大量令牌导致可扩展性差，需解决这一瓶颈。

Method: 提出FlashVGGT，采用描述符压缩空间信息，通过跨注意力机制减少计算复杂度，并支持分块递归机制以实现长序列在线推理。

Result: FlashVGGT在1000张图像上的推理时间仅为VGGT的9.3%，且能高效处理3000张以上图像序列。

Conclusion: FlashVGGT通过引入基于描述符的注意力机制，显著降低了计算开销，同时保持了与VGGT相当的3D重建精度，能够高效处理超过3000张图像的长序列。

Abstract: 3D reconstruction from multi-view images is a core challenge in computer vision. Recently, feed-forward methods have emerged as efficient and robust alternatives to traditional per-scene optimization techniques. Among them, state-of-the-art models like the Visual Geometry Grounding Transformer (VGGT) leverage full self-attention over all image tokens to capture global relationships. However, this approach suffers from poor scalability due to the quadratic complexity of self-attention and the large number of tokens generated in long image sequences. In this work, we introduce FlashVGGT, an efficient alternative that addresses this bottleneck through a descriptor-based attention mechanism. Instead of applying dense global attention across all tokens, FlashVGGT compresses spatial information from each frame into a compact set of descriptor tokens. Global attention is then computed as cross-attention between the full set of image tokens and this smaller descriptor set, significantly reducing computational overhead. Moreover, the compactness of the descriptors enables online inference over long sequences via a chunk-recursive mechanism that reuses cached descriptors from previous chunks. Experimental results show that FlashVGGT achieves reconstruction accuracy competitive with VGGT while reducing inference time to just 9.3% of VGGT for 1,000 images, and scaling efficiently to sequences exceeding 3,000 images. Our project page is available at https://wzpscott.github.io/flashvggt_page/.

</details>


### [195] [Toward Content-based Indexing and Retrieval of Head and Neck CT with Abscess Segmentation](https://arxiv.org/abs/2512.01589)
*Thao Thi Phuong Dao,Tan-Cong Nguyen,Trong-Le Do,Truong Hoang Viet,Nguyen Chi Thanh,Huynh Nguyen Thuan,Do Vo Cong Nguyen,Minh-Khoi Pham,Mai-Khiem Tran,Viet-Tham Huynh,Trong-Thuan Nguyen,Trung-Nghia Le,Vo Thanh Toan,Tam V. Nguyen,Minh-Triet Tran,Thanh Dinh Le*

Main category: cs.CV

TL;DR: AbscessHeNe是一个头颈部脓肿的CT数据集，用于开发分割模型，当前最佳模型性能有限，需进一步研究。


<details>
  <summary>Details</summary>
Motivation: 头颈部脓肿的准确检测和分割对临床诊断和治疗至关重要，但目前缺乏高质量的数据集和性能基准。

Method: 研究引入了AbscessHeNe数据集，包含4,926张增强CT切片，并评估了CNN、Transformer和Mamba-based等分割架构的性能。

Result: 最佳模型的Dice相似系数为0.39，IoU为0.27，归一化表面距离为0.67，表明任务具有挑战性。

Conclusion: AbscessHeNe数据集为头颈部脓肿的语义分割模型开发提供了基准，并展示了当前技术的局限性，强调了进一步研究的必要性。

Abstract: Abscesses in the head and neck represent an acute infectious process that can potentially lead to sepsis or mortality if not diagnosed and managed promptly. Accurate detection and delineation of these lesions on imaging are essential for diagnosis, treatment planning, and surgical intervention. In this study, we introduce AbscessHeNe, a curated and comprehensively annotated dataset comprising 4,926 contrast-enhanced CT slices with clinically confirmed head and neck abscesses. The dataset is designed to facilitate the development of robust semantic segmentation models that can accurately delineate abscess boundaries and evaluate deep neck space involvement, thereby supporting informed clinical decision-making. To establish performance baselines, we evaluate several state-of-the-art segmentation architectures, including CNN, Transformer, and Mamba-based models. The highest-performing model achieved a Dice Similarity Coefficient of 0.39, Intersection-over-Union of 0.27, and Normalized Surface Distance of 0.67, indicating the challenges of this task and the need for further research. Beyond segmentation, AbscessHeNe is structured for future applications in content-based multimedia indexing and case-based retrieval. Each CT scan is linked with pixel-level annotations and clinical metadata, providing a foundation for building intelligent retrieval systems and supporting knowledge-driven clinical workflows. The dataset will be made publicly available at https://github.com/drthaodao3101/AbscessHeNe.git.

</details>


### [196] [Depth Matching Method Based on ShapeDTW for Oil-Based Mud Imager](https://arxiv.org/abs/2512.01611)
*Fengfeng Li,Zhou Feng,Hongliang Wu,Hao Zhang,Han Tian,Peng Liu,Lixin Yuan*

Main category: cs.CV

TL;DR: 提出基于ShapeDTW的深度匹配方法，有效解决油基泥浆成像仪图像深度对齐问题，适用于复杂纹理和局部缩放情况。


<details>
  <summary>Details</summary>
Motivation: 解决油基泥浆微电阻率成像仪中上下垫片图像间的深度对齐问题，即使经过速度校正后仍存在的偏差。

Method: 采用ShapeDTW算法，结合一维梯度方向直方图（HOG1D）和原始信号作为形状描述符，构建形态敏感的距离矩阵。

Result: 现场测试表明，该方法能精确对齐具有复杂纹理、深度偏移或局部缩放的图像，并提供了灵活的特征扩展框架。

Conclusion: 本文提出的基于ShapeDTW算法的深度匹配方法有效解决了油基泥浆微电阻率成像仪中的深度对齐问题，尤其在复杂纹理、深度偏移或局部缩放情况下表现优异。

Abstract: In well logging operations using the oil-based mud (OBM) microresistivity imager, which employs an interleaved design with upper and lower pad sets, depth misalignment issues persist between the pad images even after velocity correction. This paper presents a depth matching method for borehole images based on the Shape Dynamic Time Warping (ShapeDTW) algorithm. The method extracts local shape features to construct a morphologically sensitive distance matrix, better preserving structural similarity between sequences during alignment. We implement this by employing a combined feature set of the one-dimensional Histogram of Oriented Gradients (HOG1D) and the original signal as the shape descriptor. Field test examples demonstrate that our method achieves precise alignment for images with complex textures, depth shifts, or local scaling. Furthermore, it provides a flexible framework for feature extension, allowing the integration of other descriptors tailored to specific geological features.

</details>


### [197] [Generative Editing in the Joint Vision-Language Space for Zero-Shot Composed Image Retrieval](https://arxiv.org/abs/2512.01636)
*Xin Wang,Haipeng Zhang,Mang Li,Zhaohui Xia,Yueguo Chen,Yu Zhang,Chunyu Wei*

Main category: cs.CV

TL;DR: Fusion-Diff 通过多模态融合和轻量适配器，在零样本组合图像检索中实现高效性能，仅需少量合成数据微调。


<details>
  <summary>Details</summary>
Motivation: 现有零样本 CIR 方法（文本中心或基于扩散）难以有效桥接视觉-语言模态差距，且依赖昂贵的三元组标注，因此需要高效且数据友好的解决方案。

Method: 提出 Fusion-Diff，一个生成式编辑框架，包含多模态融合特征编辑策略和轻量级 Control-Adapter，仅需 200K 合成样本的微调即可实现高效多模态对齐。

Result: 在 CIRR、FashionIQ 和 CIRCO 基准测试中，Fusion-Diff 显著优于现有零样本方法，并通过可视化多模态融合表征增强了模型可解释性。

Conclusion: Fusion-Diff 在零样本组合图像检索（ZS-CIR）中通过多模态融合特征编辑策略和轻量级 Control-Adapter，显著缩小了视觉-语言模态差距，并在有限规模合成数据集上实现了最先进的性能。

Abstract: Composed Image Retrieval (CIR) enables fine-grained visual search by combining a reference image with a textual modification. While supervised CIR methods achieve high accuracy, their reliance on costly triplet annotations motivates zero-shot solutions. The core challenge in zero-shot CIR (ZS-CIR) stems from a fundamental dilemma: existing text-centric or diffusion-based approaches struggle to effectively bridge the vision-language modality gap. To address this, we propose Fusion-Diff, a novel generative editing framework with high effectiveness and data efficiency designed for multimodal alignment. First, it introduces a multimodal fusion feature editing strategy within a joint vision-language (VL) space, substantially narrowing the modality gap. Second, to maximize data efficiency, the framework incorporates a lightweight Control-Adapter, enabling state-of-the-art performance through fine-tuning on only a limited-scale synthetic dataset of 200K samples. Extensive experiments on standard CIR benchmarks (CIRR, FashionIQ, and CIRCO) demonstrate that Fusion-Diff significantly outperforms prior zero-shot approaches. We further enhance the interpretability of our model by visualizing the fused multimodal representations.

</details>


### [198] [ViT$^3$: Unlocking Test-Time Training in Vision](https://arxiv.org/abs/2512.01643)
*Dongchen Han,Yining Li,Tianyu Li,Zixuan Cao,Ziming Wang,Jun Song,Yu Cheng,Bo Zheng,Gao Huang*

Main category: cs.CV

TL;DR: 本研究通过实证分析提出了视觉测试时训练（TTT）的设计原则，并开发了ViT$^3$模型，在多个视觉任务中表现优异，为未来研究提供了基线。


<details>
  <summary>Details</summary>
Motivation: 尽管TTT在序列建模中展现出潜力，但视觉TTT设计的关键选择缺乏全面理解和实用指南，因此本研究旨在填补这一空白。

Method: 通过系统性的实证研究，分析了TTT设计在视觉序列建模中的应用，并从中提炼出六条实用见解，最终构建了ViT$^3$模型。

Result: ViT$^3$在图像分类、生成、目标检测和语义分割等任务中表现优异，匹配或超越了先进的线性复杂度模型，并缩小了与优化视觉Transformer的差距。

Conclusion: 本研究提出了ViT$^3$模型，为视觉测试时训练（TTT）提供了一个高效的纯TTT架构，实现了线性复杂度和并行计算，并在多个视觉任务中表现优异，为未来视觉TTT模型的研究奠定了基础。

Abstract: Test-Time Training (TTT) has recently emerged as a promising direction for efficient sequence modeling. TTT reformulates attention operation as an online learning problem, constructing a compact inner model from key-value pairs at test time. This reformulation opens a rich and flexible design space while achieving linear computational complexity. However, crafting a powerful visual TTT design remains challenging: fundamental choices for the inner module and inner training lack comprehensive understanding and practical guidelines. To bridge this critical gap, in this paper, we present a systematic empirical study of TTT designs for visual sequence modeling. From a series of experiments and analyses, we distill six practical insights that establish design principles for effective visual TTT and illuminate paths for future improvement. These findings culminate in the Vision Test-Time Training (ViT$^3$) model, a pure TTT architecture that achieves linear complexity and parallelizable computation. We evaluate ViT$^3$ across diverse visual tasks, including image classification, image generation, object detection, and semantic segmentation. Results show that ViT$^3$ consistently matches or outperforms advanced linear-complexity models (e.g., Mamba and linear attention variants) and effectively narrows the gap to highly optimized vision Transformers. We hope this study and the ViT$^3$ baseline can facilitate future work on visual TTT models. Code is available at https://github.com/LeapLabTHU/ViTTT.

</details>


### [199] [DB-KAUNet: An Adaptive Dual Branch Kolmogorov-Arnold UNet for Retinal Vessel Segmentation](https://arxiv.org/abs/2512.01657)
*Hongyu Xu,Panpan Meng,Meng Wang,Dayu Hu,Liming Liang,Xiaoqi Sheng*

Main category: cs.CV

TL;DR: DB-KAUNet通过结合CNN和Transformer的双分支编码器及多个优化模块，显著提升了视网膜血管分割的精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统CNN方法在捕捉长距离依赖和复杂非线性关系方面存在局限，需要一种更高效的分割方法以提升临床诊断的准确性。

Method: 提出了一种自适应双分支Kolmogorov-Arnold UNet（DB-KAUNet），结合CNN和Transformer的双分支编码器（HDBE），并引入了CCI、SFE和SFE-GAF模块以优化特征处理。

Result: 在DRIVE、STARE和CHASE_DB1数据集上的实验表明，DB-KAUNet实现了领先的分割性能。

Conclusion: DB-KAUNet在视网膜血管分割任务中表现出卓越的性能和鲁棒性，通过创新的双分支编码器和多个优化模块，显著提升了分割精度。

Abstract: Accurate segmentation of retinal vessels is crucial for the clinical diagnosis of numerous ophthalmic and systemic diseases. However, traditional Convolutional Neural Network (CNN) methods exhibit inherent limitations, struggling to capture long-range dependencies and complex nonlinear relationships. To address the above limitations, an Adaptive Dual Branch Kolmogorov-Arnold UNet (DB-KAUNet) is proposed for retinal vessel segmentation. In DB-KAUNet, we design a Heterogeneous Dual-Branch Encoder (HDBE) that features parallel CNN and Transformer pathways. The HDBE strategically interleaves standard CNN and Transformer blocks with novel KANConv and KAT blocks, enabling the model to form a comprehensive feature representation. To optimize feature processing, we integrate several critical components into the HDBE. First, a Cross-Branch Channel Interaction (CCI) module is embedded to facilitate efficient interaction of channel features between the parallel pathways. Second, an attention-based Spatial Feature Enhancement (SFE) module is employed to enhance spatial features and fuse the outputs from both branches. Building upon the SFE module, an advanced Spatial Feature Enhancement with Geometrically Adaptive Fusion (SFE-GAF) module is subsequently developed. In the SFE-GAF module, adaptive sampling is utilized to focus on true vessel morphology precisely. The adaptive process strengthens salient vascular features while significantly reducing background noise and computational overhead. Extensive experiments on the DRIVE, STARE, and CHASE_DB1 datasets validate that DB-KAUNet achieves leading segmentation performance and demonstrates exceptional robustness.

</details>


### [200] [Bridging the Scale Gap: Balanced Tiny and General Object Detection in Remote Sensing Imagery](https://arxiv.org/abs/2512.01665)
*Zhicheng Zhao,Yin Huang,Lingma Sun,Chenglong Li,Jin Tang*

Main category: cs.CV

TL;DR: ScaleBridge-Det是首个针对遥感图像小物体检测的大型框架，通过REM和DGQ模块实现多尺度平衡检测，性能优异。


<details>
  <summary>Details</summary>
Motivation: 解决遥感图像中极端尺度变化和密度分布带来的小物体检测挑战，填补大型基础模型在该领域的空白。

Method: 提出了Routing-Enhanced Mixture Attention (REM)模块和Density-Guided Dynamic Query (DGQ)模块，分别通过动态选择融合多尺度专家特征和预测物体密度调整查询分配，优化检测性能。

Result: 在AI-TOD-V2和DTOD数据集上达到SOTA性能，并在VisDrone上展现出色的跨域鲁棒性。

Conclusion: ScaleBridge-Det通过scale-adaptive expert routing和density-guided query allocation，实现了对不同尺度物体的平衡检测性能，尤其在密集小物体和大物体共存场景中表现优异。

Abstract: Tiny object detection in remote sensing imagery has attracted significant research interest in recent years. Despite recent progress, achieving balanced detection performance across diverse object scales remains a formidable challenge, particularly in scenarios where dense tiny objects and large objects coexist. Although large foundation models have revolutionized general vision tasks, their application to tiny object detection remains unexplored due to the extreme scale variation and density distribution inherent to remote sensing imagery. To bridge this scale gap, we propose ScaleBridge-Det, to the best of our knowledge, the first large detection framework designed for tiny objects, which could achieve balanced performance across diverse scales through scale-adaptive expert routing and density-guided query allocation. Specifically, we introduce a Routing-Enhanced Mixture Attention (REM) module that dynamically selects and fuses scale-specific expert features via adaptive routing to address the tendency of standard MoE models to favor dominant scales. REM generates complementary and discriminative multi-scale representations suitable for both tiny and large objects. Furthermore, we present a Density-Guided Dynamic Query (DGQ) module that predicts object density to adaptively adjust query positions and numbers, enabling efficient resource allocation for objects of varying scales. The proposed framework allows ScaleBridge-Det to simultaneously optimize performance for both dense tiny and general objects without trade-offs. Extensive experiments on benchmark and cross-domain datasets demonstrate that ScaleBridge-Det achieves state-of-the-art performance on AI-TOD-V2 and DTOD, while exhibiting superior cross-domain robustness on VisDrone.

</details>


### [201] [GRASP: Guided Residual Adapters with Sample-wise Partitioning](https://arxiv.org/abs/2512.01675)
*Felix Nützel,Mischa Dombrowski,Bernhard Kainz*

Main category: cs.CV

TL;DR: GRASP通过样本分区和残差适配器解决长尾数据梯度冲突，提升罕见类别生成质量，下游分类表现优异。


<details>
  <summary>Details</summary>
Motivation: 文本到图像扩散模型在长尾设置（如医学影像）中表现不佳，罕见病理数据占比小导致模式崩溃，现有方法未解决学习分布中的梯度冲突问题。

Method: 提出了GRASP方法，利用外部先验将样本静态分区以减少组内梯度冲突，并通过在Transformer前馈层中注入特定簇的残差适配器来微调预训练模型，绕过学习门控以提高稳定性和效率。

Result: 在MIMIC-CXR-LT数据集上，GRASP在FID和多样性指标上优于基线方法，尤其对罕见类别；在NIH-CXR-LT的下游分类任务中，罕见标签性能显著提升；ImageNet-LT上的泛化验证了其广泛适用性。

Conclusion: GRASP方法通过静态样本分区和残差适配器注入，有效解决了长尾数据集中梯度冲突问题，显著提升了罕见类别的生成质量和多样性，并在下游分类任务中表现出色，具有轻量级、可扩展性强的特点。

Abstract: Recent advances in text-to-image diffusion models enable high-fidelity generation across diverse prompts. However, these models falter in long-tail settings, such as medical imaging, where rare pathologies comprise a small fraction of data. This results in mode collapse: tail-class outputs lack quality and diversity, undermining the goal of synthetic data augmentation for underrepresented conditions. We pinpoint gradient conflicts between frequent head and rare tail classes as the primary culprit, a factor unaddressed by existing sampling or conditioning methods that mainly steer inference without altering the learned distribution. To resolve this, we propose GRASP: Guided Residual Adapters with Sample-wise Partitioning. GRASP uses external priors to statically partition samples into clusters that minimize intra-group gradient clashes. It then fine-tunes pre-trained models by injecting cluster-specific residual adapters into transformer feedforward layers, bypassing learned gating for stability and efficiency. On the long-tail MIMIC-CXR-LT dataset, GRASP yields superior FID and diversity metrics, especially for rare classes, outperforming baselines like vanilla fine-tuning and Mixture of Experts variants. Downstream classification on NIH-CXR-LT improves considerably for tail labels. Generalization to ImageNet-LT confirms broad applicability. Our method is lightweight, scalable, and readily integrates with diffusion pipelines.

</details>


### [202] [Open-world Hand-Object Interaction Video Generation Based on Structure and Contact-aware Representation](https://arxiv.org/abs/2512.01677)
*Haodong Yan,Hang Yu,Zhide Zhong,Weilin Yuan,Xin Gong,Zehang Luo,Chengxi Heyu,Junfeng Li,Wenxuan Song,Shunbo Zhou,Haoang Li*

Main category: cs.CV

TL;DR: 提出了一种结构和接触感知表示方法，通过联合生成范式生成真实的手-物体交互视频，优于现有方法并具有强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前方法在2D和3D表示之间存在权衡，无法同时保证可扩展性和交互保真度，因此需要一种新的表示方法。

Method: 提出了一种结构和接触感知表示方法，结合联合生成范式，通过共享和专业化策略生成交互导向的表示和视频。

Result: 在真实数据集上的实验表明，该方法在生成物理真实和时间连贯的手-物体交互视频方面优于现有方法。

Conclusion: 提出的结构感知和接触感知表示方法在生成真实手-物体交互视频方面表现出色，优于现有方法，并展现出在开放世界场景中的强泛化能力。

Abstract: Generating realistic hand-object interactions (HOI) videos is a significant challenge due to the difficulty of modeling physical constraints (e.g., contact and occlusion between hands and manipulated objects). Current methods utilize HOI representation as an auxiliary generative objective to guide video synthesis. However, there is a dilemma between 2D and 3D representations that cannot simultaneously guarantee scalability and interaction fidelity. To address this limitation, we propose a structure and contact-aware representation that captures hand-object contact, hand-object occlusion, and holistic structure context without 3D annotations. This interaction-oriented and scalable supervision signal enables the model to learn fine-grained interaction physics and generalize to open-world scenarios. To fully exploit the proposed representation, we introduce a joint-generation paradigm with a share-and-specialization strategy that generates interaction-oriented representations and videos. Extensive experiments demonstrate that our method outperforms state-of-the-art methods on two real-world datasets in generating physics-realistic and temporally coherent HOI videos. Furthermore, our approach exhibits strong generalization to challenging open-world scenarios, highlighting the benefit of our scalable design. Our project page is https://hgzn258.github.io/SCAR/.

</details>


### [203] [Cross-Domain Validation of a Resection-Trained Self-Supervised Model on Multicentre Mesothelioma Biopsies](https://arxiv.org/abs/2512.01681)
*Farzaneh Seyedshahi,Francesca Damiola,Sylvie Lantuejoul,Ke Yuan,John Le Quesne*

Main category: cs.CV

TL;DR: 研究证明自监督编码器可从切除组织学习形态模式并应用于活检，预测生存率和分类亚型，支持AI在间皮瘤诊疗中的应用。


<details>
  <summary>Details</summary>
Motivation: 解决计算病理学模型在现实世界中因依赖大组织图像而受限的问题，特别是在小活检样本常见的情况下。

Method: 使用自监督编码器在切除组织上训练，然后将学习到的形态模式应用于活检材料。

Result: 模型能够预测患者生存率并分类肿瘤亚型，展示了在活检材料上应用切除组织学习模式的可行性。

Conclusion: 该研究展示了AI驱动工具在间皮瘤诊断和治疗规划中的潜力，通过自监督编码器从切除组织中学习形态模式，并成功应用于活检材料。

Abstract: Accurate subtype classification and outcome prediction in mesothelioma are essential for guiding therapy and patient care. Most computational pathology models are trained on large tissue images from resection specimens, limiting their use in real-world settings where small biopsies are common. We show that a self-supervised encoder trained on resection tissue can be applied to biopsy material, capturing meaningful morphological patterns. Using these patterns, the model can predict patient survival and classify tumor subtypes. This approach demonstrates the potential of AI-driven tools to support diagnosis and treatment planning in mesothelioma.

</details>


### [204] [DreamingComics: A Story Visualization Pipeline via Subject and Layout Customized Generation using Video Models](https://arxiv.org/abs/2512.01686)
*Patrick Kwon,Chen Chen*

Main category: cs.CV

TL;DR: DreamingComics通过布局感知框架和区域编码技术，显著提升故事可视化的角色与风格一致性。


<details>
  <summary>Details</summary>
Motivation: 现有故事可视化方法仅依赖文本定位主体，难以保持艺术一致性。

Method: 基于预训练的视频扩散-Transformer模型，提出RegionalRoPE区域感知位置编码方案和掩码条件损失，结合LLM布局生成器实现布局控制。

Result: 相比现有方法，角色一致性提升29.2%，风格相似性提升36.2%，且空间准确性高。

Conclusion: DreamingComics框架通过引入RegionalRoPE和掩码条件损失，显著提升了角色一致性和风格相似性，同时实现了高空间准确性。

Abstract: Current story visualization methods tend to position subjects solely by text and face challenges in maintaining artistic consistency. To address these limitations, we introduce DreamingComics, a layout-aware story visualization framework. We build upon a pretrained video diffusion-transformer (DiT) model, leveraging its spatiotemporal priors to enhance identity and style consistency. For layout-based position control, we propose RegionalRoPE, a region-aware positional encoding scheme that re-indexes embeddings based on the target layout. Additionally, we introduce a masked condition loss to further constrain each subject's visual features to their designated region. To infer layouts from natural language scripts, we integrate an LLM-based layout generator trained to produce comic-style layouts, enabling flexible and controllable layout conditioning. We present a comprehensive evaluation of our approach, showing a 29.2% increase in character consistency and a 36.2% increase in style similarity compared to previous methods, while displaying high spatial accuracy. Our project page is available at https://yj7082126.github.io/dreamingcomics/

</details>


### [205] [SSR: Semantic and Spatial Rectification for CLIP-based Weakly Supervised Segmentation](https://arxiv.org/abs/2512.01701)
*Xiuli Bi,Die Xiao,Junchao Fan,Bin Xiao*

Main category: cs.CV

TL;DR: 提出SSR方法，通过CMPA和SGC解决CLIP-based WSSS的过激活问题，性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有CLIP-based WSSS方法存在非目标前景区域和背景区域的过激活问题，需改进。

Method: 在语义层面采用CMPA进行跨模态原型对齐，在空间层面利用SGC进行超像素引导校正。

Result: 在PASCAL VOC和MS COCO数据集上分别达到79.5%和50.6%的mIoU，优于现有方法。

Conclusion: 提出的SSR方法通过语义和空间校正有效解决了现有CLIP-based WSSS方法中的过激活问题，显著提升了性能。

Abstract: In recent years, Contrastive Language-Image Pretraining (CLIP) has been widely applied to Weakly Supervised Semantic Segmentation (WSSS) tasks due to its powerful cross-modal semantic understanding capabilities. This paper proposes a novel Semantic and Spatial Rectification (SSR) method to address the limitations of existing CLIP-based weakly supervised semantic segmentation approaches: over-activation in non-target foreground regions and background areas. Specifically, at the semantic level, the Cross-Modal Prototype Alignment (CMPA) establishes a contrastive learning mechanism to enforce feature space alignment across modalities, reducing inter-class overlap while enhancing semantic correlations, to rectify over-activation in non-target foreground regions effectively; at the spatial level, the Superpixel-Guided Correction (SGC) leverages superpixel-based spatial priors to precisely filter out interference from non-target regions during affinity propagation, significantly rectifying background over-activation. Extensive experiments on the PASCAL VOC and MS COCO datasets demonstrate that our method outperforms all single-stage approaches, as well as more complex multi-stage approaches, achieving mIoU scores of 79.5% and 50.6%, respectively.

</details>


### [206] [FreqEdit: Preserving High-Frequency Features for Robust Multi-Turn Image Editing](https://arxiv.org/abs/2512.01755)
*Yucheng Liao,Jiajun Liang,Kaiqian Cui,Baoquan Zhao,Haoran Xie,Wei Liu,Qing Li,Xudong Mao*

Main category: cs.CV

TL;DR: FreqEdit通过高频特征注入、自适应策略和路径补偿机制，解决了多轮图像编辑中的质量下降问题，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决基于指令的图像编辑在多轮编辑中因高频信息丢失导致的质量下降问题。

Method: FreqEdit包含三个关键组件：高频特征注入、自适应注入策略和路径补偿机制。

Result: FreqEdit在10+次连续编辑中保持稳定，身份保持和指令遵循性能优于7种现有方法。

Conclusion: FreqEdit通过其三个协同组件有效解决了多轮编辑中的高频信息丢失问题，在身份保持和指令遵循方面表现优于现有基线。

Abstract: Instruction-based image editing through natural language has emerged as a powerful paradigm for intuitive visual manipulation. While recent models achieve impressive results on single edits, they suffer from severe quality degradation under multi-turn editing. Through systematic analysis, we identify progressive loss of high-frequency information as the primary cause of this quality degradation. We present FreqEdit, a training-free framework that enables stable editing across 10+ consecutive iterations. Our approach comprises three synergistic components: (1) high-frequency feature injection from reference velocity fields to preserve fine-grained details, (2) an adaptive injection strategy that spatially modulates injection strength for precise region-specific control, and (3) a path compensation mechanism that periodically recalibrates the editing trajectory to prevent over-constraint. Extensive experiments demonstrate that FreqEdit achieves superior performance in both identity preservation and instruction following compared to seven state-of-the-art baselines.

</details>


### [207] [HiconAgent: History Context-aware Policy Optimization for GUI Agents](https://arxiv.org/abs/2512.01763)
*Xurui Zhou,Gongwei Chen,Yuquan Xie,Zaijing Li,Kaiwen Zhou,Shuai Wang,Shuo Yang,Zhuotao Tian,Rui Shao*

Main category: cs.CV

TL;DR: HiconAgent通过HCPO优化历史信息使用，在GUI导航任务中表现优异，计算效率显著提升。


<details>
  <summary>Details</summary>
Motivation: GUI代理在序列导航任务中需要有效利用历史上下文，但全历史信息的直接使用会导致计算开销大和无关信息干扰。

Method: HiconAgent采用HCPO（History Context-aware Policy Optimization），包含动态上下文采样（DCS）和锚定引导历史压缩（AHC）两个互补组件，优化历史信息的使用。

Result: HiconAgent-3B在GUI-Odyssey上比GUI-R1-7B提升了8.46%的定位准确率和11.32%的步骤成功率，同时在AndroidControl和AITW上实现了2.47倍的计算加速和60%的FLOPs减少。

Conclusion: HiconAgent通过HCPO优化历史信息的使用，显著提升了GUI导航任务的性能，同时实现了计算效率的大幅提升。

Abstract: Graphical User Interface (GUI) agents require effective use of historical context to perform sequential navigation tasks. While incorporating past actions and observations can improve decision making, naive use of full history leads to excessive computational overhead and distraction from irrelevant information. To address this, we introduce HiconAgent, a GUI agent trained with History Context-aware Policy Optimization (HCPO) for efficient and effective utilization of historical information. HCPO optimizes history usage in both sampling and policy updates through two complementary components: (1) Dynamic Context Sampling (DCS) presents the agent with variable length histories during sampling, enabling adaptive use of the most relevant context; (2) Anchor-guided History Compression (AHC) refines the policy update phase with a dual branch strategy where the compressed branch removes history observations while keeping history actions as information flow anchors. The compressed and uncompressed branches are coupled through a history-enhanced alignment loss to enforce consistent history usage while maintaining efficiency. Experiments on mainstream GUI navigation benchmarks demonstrate strong performance. Despite being smaller, HiconAgent-3B outperforms GUI-R1-7B by +8.46 percent grounding accuracy and +11.32 percent step success rate on GUI-Odyssey, while achieving comparable results on AndroidControl and AITW with up to 2.47x computational speedup and 60 percent FLOPs reduction.

</details>


### [208] [VideoScoop: A Non-Traditional Domain-Independent Framework For Video Analysis](https://arxiv.org/abs/2512.01769)
*Hafsa Billah*

Main category: cs.CV

TL;DR: 提出通用视频情境分析框架，结合R++和图模型，实现跨领域高效情境检测，实验验证其优越性能。


<details>
  <summary>Details</summary>
Motivation: 视频情境分析目前主要依赖人工或特定算法，缺乏通用性且效率低下，亟需一种通用框架来提升自动化水平和适用范围。

Method: 使用最先进的视频内容提取技术，内容通过扩展关系模型（R++）和图模型表示，支持连续查询处理和多样化情境检测。

Result: 在AL、CM和SL三个领域的实验中，该方法展现了高效的情境检测能力，适用于不同长度和类型的视频。

Conclusion: 该报告提出了一种通用的视频情境分析框架，克服了现有方法的局限性，通过扩展关系模型和图模型实现了高效的情境检测，并在多个领域验证了其准确性、效率和鲁棒性。

Abstract: Automatically understanding video contents is important for several applications in Civic Monitoring (CM), general Surveillance (SL), Assisted Living (AL), etc. Decades of Image and Video Analysis (IVA) research have advanced tasks such as content extraction (e.g., object recognition and tracking). Identifying meaningful activities or situations (e.g., two objects coming closer) remains difficult and cannot be achieved by content extraction alone. Currently, Video Situation Analysis (VSA) is done manually with a human in the loop, which is error-prone and labor-intensive, or through custom algorithms designed for specific video types or situations. These algorithms are not general-purpose and require a new algorithm/software for each new situation or video from a new domain.
  This report proposes a general-purpose VSA framework that overcomes the above limitations. Video contents are extracted once using state-of-the-art Video Content Extraction technologies. They are represented using two alternative models -- the extended relational model (R++) and graph models. When represented using R++, the extracted contents can be used as data streams, enabling Continuous Query Processing via the proposed Continuous Query Language for Video Analysis. The graph models complement this by enabling the detection of situations that are difficult or impossible to detect using the relational model alone. Existing graph algorithms and newly developed algorithms support a wide variety of situation detection. To support domain independence, primitive situation variants across domains are identified and expressed as parameterized templates. Extensive experiments were conducted across several interesting situations from three domains -- AL, CM, and SL-- to evaluate the accuracy, efficiency, and robustness of the proposed approach using a dataset of videos of varying lengths from these domains.

</details>


### [209] [Robust Rigid and Non-Rigid Medical Image Registration Using Learnable Edge Kernels](https://arxiv.org/abs/2512.01771)
*Ahsan Raza Siyal,Markus Haltmeier,Ruth Steiger,Malik Galijasevic,Elke Ruth Gizewski,Astrid Ellen Grams*

Main category: cs.CV

TL;DR: 提出一种结合可学习边缘核的医学图像配准方法，通过优化边缘特征提取和设计多种变体模型，在多模态配准任务中表现优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 传统配准技术在处理对比度差异、空间扭曲和模态特异性变化时存在局限性，需要一种更适应医学图像特性的方法。

Method: 提出了一种集成可学习边缘核与学习型刚性和非刚性配准技术的方法。边缘检测核通过随机噪声扰动并在训练中优化，以提取任务特定的边缘特征。设计了四种刚性配准和四种非刚性配准的变体模型以分析各组件贡献。

Result: 在医学大学提供的数据集及两个公开数据集上的实验表明，该方法在所有设置下均优于现有技术，显著提升了多模态图像对齐和解剖结构分析的性能。

Conclusion: 该方法通过结合可学习的边缘核与基于学习的刚性和非刚性配准技术，显著提升了医学图像配准的准确性和适应性，尤其在处理多模态图像时表现优异。

Abstract: Medical image registration is crucial for various clinical and research applications including disease diagnosis or treatment planning which require alignment of images from different modalities, time points, or subjects. Traditional registration techniques often struggle with challenges such as contrast differences, spatial distortions, and modality-specific variations. To address these limitations, we propose a method that integrates learnable edge kernels with learning-based rigid and non-rigid registration techniques. Unlike conventional layers that learn all features without specific bias, our approach begins with a predefined edge detection kernel, which is then perturbed with random noise. These kernels are learned during training to extract optimal edge features tailored to the task. This adaptive edge detection enhances the registration process by capturing diverse structural features critical in medical imaging. To provide clearer insight into the contribution of each component in our design, we introduce four variant models for rigid registration and four variant models for non-rigid registration. We evaluated our approach using a dataset provided by the Medical University across three setups: rigid registration without skull removal, with skull removal, and non-rigid registration. Additionally, we assessed performance on two publicly available datasets. Across all experiments, our method consistently outperformed state-of-the-art techniques, demonstrating its potential to improve multi-modal image alignment and anatomical structure analysis.

</details>


### [210] [Evaluating SAM2 for Video Semantic Segmentation](https://arxiv.org/abs/2512.01774)
*Syed Hesham Syed Ariff,Yun Liu,Guolei Sun,Jing Yang,Henghui Ding,Xue Geng,Xudong Jiang*

Main category: cs.CV

TL;DR: SAM2扩展至视频语义分割（VSS）的两种方法：提取物体掩码与分割网络结合，或利用掩码特征分类。实验显示其能提升性能，尤其在边界预测上。


<details>
  <summary>Details</summary>
Motivation: 尽管SAM2在视频对象分割中表现出色，但将其扩展到密集视频语义分割（VSS）面临空间准确性、时间一致性和多对象跟踪等挑战。

Method: 探索了两种主要方法：一是使用SAM2提取图像中的独特物体掩码，并结合分割网络生成和优化初始预测；二是利用预测掩码提取特征向量，通过简单网络进行分类，最终结合分类结果和掩码生成最终分割。

Result: 实验表明，利用SAM2能够显著提升VSS的性能，尤其是在物体边界预测方面。

Conclusion: 利用SAM2进行视频语义分割（VSS）能够提升整体性能，主要得益于其对物体边界的精确预测。

Abstract: The Segmentation Anything Model 2 (SAM2) has proven to be a powerful foundation model for promptable visual object segmentation in both images and videos, capable of storing object-aware memories and transferring them temporally through memory blocks. While SAM2 excels in video object segmentation by providing dense segmentation masks based on prompts, extending it to dense Video Semantic Segmentation (VSS) poses challenges due to the need for spatial accuracy, temporal consistency, and the ability to track multiple objects with complex boundaries and varying scales. This paper explores the extension of SAM2 for VSS, focusing on two primary approaches and highlighting firsthand observations and common challenges faced during this process. The first approach involves using SAM2 to extract unique objects as masks from a given image, with a segmentation network employed in parallel to generate and refine initial predictions. The second approach utilizes the predicted masks to extract unique feature vectors, which are then fed into a simple network for classification. The resulting classifications and masks are subsequently combined to produce the final segmentation. Our experiments suggest that leveraging SAM2 enhances overall performance in VSS, primarily due to its precise predictions of object boundaries.

</details>


### [211] [Learned Image Compression for Earth Observation: Implications for Downstream Segmentation Tasks](https://arxiv.org/abs/2512.01788)
*Christian Mollière,Iker Cumplido,Marco Zeulner,Lukas Liesenhoff,Matthias Schubert,Julia Gottfriedsen*

Main category: cs.CV

TL;DR: 学习型压缩在大规模多通道光学图像上优于JPEG 2000，但在小型单通道热红外数据上传统方法更优，联合优化无提升。


<details>
  <summary>Details</summary>
Motivation: 解决卫星地球观测数据快速增长带来的传输和存储挑战。

Method: 比较了传统压缩（JPEG 2000）与学习型压缩（离散混合高斯似然）在三种EO分割任务（火灾、云、建筑物检测）上的表现。

Result: 学习型压缩在重建质量（PSNR）和分割精度上显著优于JPEG 2000，但传统编解码器在小型单通道热红外数据上表现更佳。

Conclusion: 传统编解码器在小型单通道热红外数据集上仍具竞争力，而学习型压缩算法在大规模多通道光学图像上表现更优。联合端到端优化并未带来性能提升。

Abstract: The rapid growth of data from satellite-based Earth observation (EO) systems poses significant challenges in data transmission and storage. We evaluate the potential of task-specific learned compression algorithms in this context to reduce data volumes while retaining crucial information. In detail, we compare traditional compression (JPEG 2000) versus a learned compression approach (Discretized Mixed Gaussian Likelihood) on three EO segmentation tasks: Fire, cloud, and building detection. Learned compression notably outperforms JPEG 2000 for large-scale, multi-channel optical imagery in both reconstruction quality (PSNR) and segmentation accuracy. However, traditional codecs remain competitive on smaller, single-channel thermal infrared datasets due to limited data and architectural constraints. Additionally, joint end-to-end optimization of compression and segmentation models does not improve performance over standalone optimization.

</details>


### [212] [SAM3-UNet: Simplified Adaptation of Segment Anything Model 3](https://arxiv.org/abs/2512.01789)
*Xinyu Xiong,Zihuang Wu,Lei Lu,Yufa Xia*

Main category: cs.CV

TL;DR: SAM3-UNet是SAM3的简化版，低成本适配下游任务，性能优异且内存需求低。


<details>
  <summary>Details</summary>
Motivation: 为低成本适配SAM3至下游任务，提出简化变体SAM3-UNet。

Method: SAM3-UNet由SAM3图像编码器、参数高效微调适配器和轻量级U-Net风格解码器组成。

Result: 在多项任务中优于SAM2-UNet及其他先进方法，训练时GPU内存需求低于6GB。

Conclusion: SAM3-UNet在多个下游任务中表现优异，且训练成本低，代码已开源。

Abstract: In this paper, we introduce SAM3-UNet, a simplified variant of Segment Anything Model 3 (SAM3), designed to adapt SAM3 for downstream tasks at a low cost. Our SAM3-UNet consists of three components: a SAM3 image encoder, a simple adapter for parameter-efficient fine-tuning, and a lightweight U-Net-style decoder. Preliminary experiments on multiple tasks, such as mirror detection and salient object detection, demonstrate that the proposed SAM3-UNet outperforms the prior SAM2-UNet and other state-of-the-art methods, while requiring less than 6 GB of GPU memory during training with a batch size of 12. The code is publicly available at https://github.com/WZH0120/SAM3-UNet.

</details>


### [213] [Generative Action Tell-Tales: Assessing Human Motion in Synthesized Videos](https://arxiv.org/abs/2512.01803)
*Xavier Thomas,Youngsun Lim,Ananya Srinivasan,Audrey Zheng,Deepti Ghadiyaram*

Main category: cs.CV

TL;DR: 论文提出一种融合骨骼和外观特征的新型视频生成评估指标，显著优于现有方法，并揭示了当前视频生成模型的关键局限性。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型评估指标在视觉和时间正确性方面存在不足，特别是缺乏对复杂动作动态和解剖学合理性的辨别能力。

Method: 该方法通过融合外观无关的人类骨骼几何特征和基于外观的特征，捕捉真实世界动作的细微差别、约束和时间平滑性，构建了一个稳健的动作合理性表示空间。

Result: 新指标在作者设计的基准测试中比现有最先进方法提升了68%以上，在外部基准测试中表现优异，并与人类感知有更强的相关性。

Conclusion: 该论文提出了一种基于真实世界人类动作学习潜空间的新型评估指标，显著优于现有方法，并在多个基准测试中表现优异，为视频生成研究设立了新标准。

Abstract: Despite rapid advances in video generative models, robust metrics for evaluating visual and temporal correctness of complex human actions remain elusive. Critically, existing pure-vision encoders and Multimodal Large Language Models (MLLMs) are strongly appearance-biased, lack temporal understanding, and thus struggle to discern intricate motion dynamics and anatomical implausibilities in generated videos. We tackle this gap by introducing a novel evaluation metric derived from a learned latent space of real-world human actions. Our method first captures the nuances, constraints, and temporal smoothness of real-world motion by fusing appearance-agnostic human skeletal geometry features with appearance-based features. We posit that this combined feature space provides a robust representation of action plausibility. Given a generated video, our metric quantifies its action quality by measuring the distance between its underlying representations and this learned real-world action distribution. For rigorous validation, we develop a new multi-faceted benchmark specifically designed to probe temporally challenging aspects of human action fidelity. Through extensive experiments, we show that our metric achieves substantial improvement of more than 68% compared to existing state-of-the-art methods on our benchmark, performs competitively on established external benchmarks, and has a stronger correlation with human perception. Our in-depth analysis reveals critical limitations in current video generative models and establishes a new standard for advanced research in video generation.

</details>


### [214] [Seeing through Imagination: Learning Scene Geometry via Implicit Spatial World Modeling](https://arxiv.org/abs/2512.01821)
*Meng Cao,Haokun Lin,Haoyuan Li,Haoran Tang,Rongtao Xu,Dong An,Xue Liu,Ian Reid,Xiaodan Liang*

Main category: cs.CV

TL;DR: MILO通过视觉生成器和RePE编码方案，结合GeoGen数据集，显著提升了MLLMs的空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 当前MLLMs主要依赖语言描述调整，缺乏视觉连接，导致空间推理能力不足。

Method: 提出了MILO（隐式空间世界建模范式）和RePE（相对位置编码方案），并构建了GeoGen数据集（包含2,241个视频和67,827个观察-动作-结果三元组）。

Result: 实验表明，该方法在多个基线和基准测试中显著提升了空间推理能力。

Conclusion: MILO和RePE的结合显著提升了MLLMs的空间推理能力，提供了对3D空间更全面的理解。

Abstract: Spatial reasoning, the ability to understand and interpret the 3D structure of the world, is a critical yet underdeveloped capability in Multimodal Large Language Models (MLLMs). Current methods predominantly rely on verbal descriptive tuning, which suffers from visual illiteracy, i.e., they learn spatial concepts through textual symbols alone, devoid of connection to their visual manifestations. To bridge this gap, this paper introduces MILO, an Implicit spatIaL wOrld modeling paradigm that simulates human-like spatial imagination. MILO integrates a visual generator to provide geometry-aware feedback, thereby implicitly grounding the MLLM's symbolic reasoning in perceptual experience. Complementing this paradigm, we propose RePE (Relative Positional Encoding), a novel encoding scheme that captures relative camera-pose transformations, offering superior performance over absolute coordinate systems. To support the training, we construct GeoGen, a large-scale Geometry-aware Generative dataset with approximately 2,241 videos and 67,827 observation-action-outcome triplets. Experiments demonstrate that our approach significantly enhances spatial reasoning capabilities across multiple baselines and benchmarks, offering a more holistic understanding of 3D space.

</details>


### [215] [CauSight: Learning to Supersense for Visual Causal Discovery](https://arxiv.org/abs/2512.01827)
*Yize Zhang,Meiqi Chen,Sirui Chen,Bo Peng,Yanxi Zhang,Tianyu Li,Chaochao Lu*

Main category: cs.CV

TL;DR: 提出视觉因果发现任务，构建VCG-32K数据集并开发CauSight模型，通过因果推理和强化学习实现性能突破，显著优于GPT-4.1。


<details>
  <summary>Details</summary>
Motivation: 通过视觉因果发现任务，使AI系统不仅能感知视觉实体的存在，还能推断其因果关系，模仿人类的因果思维能力。

Method: 结合VCG-32K数据集、Tree-of-Causal-Thought（ToCT）因果推理轨迹合成，以及带因果奖励的强化学习，开发了CauSight模型。

Result: CauSight在视觉因果发现任务中表现优异，性能显著超越GPT-4.1。

Conclusion: CauSight模型在视觉因果发现任务中显著优于GPT-4.1，性能提升超过三倍（绝对增益21%），并通过开源代码、模型和数据集推动领域发展。

Abstract: Causal thinking enables humans to understand not just what is seen, but why it happens. To replicate this capability in modern AI systems, we introduce the task of visual causal discovery. It requires models to infer cause-and-effect relations among visual entities across diverse scenarios instead of merely perceiving their presence. To this end, we first construct the Visual Causal Graph dataset (VCG-32K), a large-scale collection of over 32,000 images annotated with entity-level causal graphs, and further develop CauSight, a novel vision-language model to perform visual causal discovery through causally aware reasoning. Our training recipe integrates three components: (1) training data curation from VCG-32K, (2) Tree-of-Causal-Thought (ToCT) for synthesizing reasoning trajectories, and (3) reinforcement learning with a designed causal reward to refine the reasoning policy. Experiments show that CauSight outperforms GPT-4.1 on visual causal discovery, achieving over a threefold performance boost (21% absolute gain). Our code, model, and dataset are fully open-sourced at project page: https://github.com/OpenCausaLab/CauSight.

</details>


### [216] [OpenREAD: Reinforced Open-Ended Reasoing for End-to-End Autonomous Driving with LLM-as-Critic](https://arxiv.org/abs/2512.01830)
*Songyan Zhang,Wenhui Huang,Zhan Chen,Chua Jiahao Collister,Qihang Huang,Chen Lv*

Main category: cs.CV

TL;DR: OpenREAD是一种基于视觉语言模型（VLM）的端到端强化微调框架，通过量化开放性问题推理质量，显著提升自动驾驶性能。


<details>
  <summary>Details</summary>
Motivation: 解决当前两阶段微调策略中SFT推理泛化能力有限和RFT难以量化开放性问题奖励的局限性。

Method: 构建大规模Chain-of-Thought（CoT）注释，并利用Qwen3大型语言模型（LLM）作为RFT中的批评者来量化开放性问题在奖励建模中的推理质量。

Result: 实验证实，联合端到端RFT在上下游任务中均带来显著改进。

Conclusion: OpenREAD通过联合端到端强化微调（RFT）显著提升了上游和下游任务的性能，在推理和规划基准测试中达到了最先进的水平。

Abstract: Recently, two-stage fine-tuning strategies, e.g., acquiring essential driving knowledge through supervised fine-tuning (SFT) and further enhancing decision-making and planning via reinforcement fine-tuning (RFT), have shown strong potential in advancing the knowledge-driven autonomous driving (AD) paradigm. However, the learning nature of SFT still limits the generalization of reasoning, thereby constraining the full potential of driving performance. Meanwhile, current RFT approaches are primarily applied to downstream tasks, since scene understanding is an open-ended problem where corresponding rewards are difficult to quantify. To address these limitations, we propose OpenREAD, an OPEN-ended REasoning reinforced vision-language model (VLM)-based autonomous driving (AD) framework that enables end-to-end RFT across the full spectrum from high-level reasoning to low-level trajectory planning. Specifically, we begin by constructing large-scale Chain-of-Thought (CoT) annotations on open-source driving-related knowledge datasets, and employ the powerful Qwen3 large language model (LLM) as the critic in RFT to quantify reasoning quality for open-ended questions during reward modeling. Extensive experiments confirm that joint end-to-end RFT yields substantial improvements in both upstream and downstream tasks, enabling OpenREAD to achieve state-of-the-art performance on reasoning and planning benchmarks.

</details>


### [217] [PhyDetEx: Detecting and Explaining the Physical Plausibility of T2V Models](https://arxiv.org/abs/2512.01843)
*Zeqing Wang,Keze Wang,Lei Zhang*

Main category: cs.CV

TL;DR: 该论文研究了T2V模型生成物理合理视频的能力，构建了PID数据集并提出PhyDetEx方法，发现模型在物理合理性方面仍有改进空间。


<details>
  <summary>Details</summary>
Motivation: 研究T2V模型是否能理解物理并生成物理上合理的视频，以及如何评估和改进这些模型在物理合理性方面的表现。

Method: 构建了一个物理不合理性检测（PID）数据集，并提出了一种轻量级微调方法，使视觉语言模型（VLM）能够检测物理不合理事件并生成违反物理原理的文本解释。

Result: 通过微调的VLM（PhyDetEx）对一系列T2V模型进行基准测试，发现虽然近期模型在物理合理性方面有所进步，但仍存在挑战。

Conclusion: 尽管最新的文本到视频（T2V）生成模型在物理合理性方面有所进步，但理解和遵守物理定律仍是一个挑战，尤其是开源模型。

Abstract: Driven by the growing capacity and training scale, Text-to-Video (T2V) generation models have recently achieved substantial progress in video quality, length, and instruction-following capability. However, whether these models can understand physics and generate physically plausible videos remains a question. While Vision-Language Models (VLMs) have been widely used as general-purpose evaluators in various applications, they struggle to identify the physically impossible content from generated videos. To investigate this issue, we construct a \textbf{PID} (\textbf{P}hysical \textbf{I}mplausibility \textbf{D}etection) dataset, which consists of a \textit{test split} of 500 manually annotated videos and a \textit{train split} of 2,588 paired videos, where each implausible video is generated by carefully rewriting the caption of its corresponding real-world video to induce T2V models producing physically implausible content. With the constructed dataset, we introduce a lightweight fine-tuning approach, enabling VLMs to not only detect physically implausible events but also generate textual explanations on the violated physical principles. Taking the fine-tuned VLM as a physical plausibility detector and explainer, namely \textbf{PhyDetEx}, we benchmark a series of state-of-the-art T2V models to assess their adherence to physical laws. Our findings show that although recent T2V models have made notable progress toward generating physically plausible content, understanding and adhering to physical laws remains a challenging issue, especially for open-source models. Our dataset, training code, and checkpoints are available at \href{https://github.com/Zeqing-Wang/PhyDetEx}{https://github.com/Zeqing-Wang/PhyDetEx}.

</details>


### [218] [COACH: Collaborative Agents for Contextual Highlighting - A Multi-Agent Framework for Sports Video Analysis](https://arxiv.org/abs/2512.01853)
*Tsz-To Wong,Ching-Chun Huang,Hong-Han Shuai*

Main category: cs.CV

TL;DR: 提出可重构多智能体系统（MAS）框架，解决体育视频分析中的时间层次问题，展示其在跨任务分析中的灵活性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有端到端模型在体育视频分析中难以处理时间层次结构，缺乏泛化能力、开发成本高且解释性差。

Method: 通过设计多个专门化智能体作为不同的“认知工具”，并利用它们的迭代调用和灵活组合，构建了适应短期分析推理和长期生成总结的自适应管道。

Result: 在羽毛球分析的两个代表性任务中验证了该框架的适应性，能够桥接细粒度事件检测和全局语义组织。

Conclusion: 本文提出了一种可重构的多智能体系统（MAS）作为体育视频理解的基础框架，展示了其在跨任务体育视频智能分析中的灵活性、可扩展性和可解释性。

Abstract: Intelligent sports video analysis demands a comprehensive understanding of temporal context, from micro-level actions to macro-level game strategies. Existing end-to-end models often struggle with this temporal hierarchy, offering solutions that lack generalization, incur high development costs for new tasks, and suffer from poor interpretability. To overcome these limitations, we propose a reconfigurable Multi-Agent System (MAS) as a foundational framework for sports video understanding. In our system, each agent functions as a distinct "cognitive tool" specializing in a specific aspect of analysis. The system's architecture is not confined to a single temporal dimension or task. By leveraging iterative invocation and flexible composition of these agents, our framework can construct adaptive pipelines for both short-term analytic reasoning (e.g., Rally QA) and long-term generative summarization (e.g., match summaries). We demonstrate the adaptability of this framework using two representative tasks in badminton analysis, showcasing its ability to bridge fine-grained event detection and global semantic organization. This work presents a paradigm shift towards a flexible, scalable, and interpretable system for robust, cross-task sports video intelligence.The project homepage is available at https://aiden1020.github.io/COACH-project-page

</details>


### [219] [TransientTrack: Advanced Multi-Object Tracking and Classification of Cancer Cells with Transient Fluorescent Signals](https://arxiv.org/abs/2512.01885)
*Florian Bürger,Martim Dias Gomes,Nica Gutu,Adrián E. Granada,Noémie Moreau,Katarzyna Bozek*

Main category: cs.CV

TL;DR: TransientTrack 是一个基于深度学习的细胞追踪框架，专为多通道瞬态信号设计，可识别分裂和死亡事件，支持癌症治疗反应的定量研究。


<details>
  <summary>Details</summary>
Motivation: 现有细胞追踪方法主要针对单一恒定信号视频，无法检测细胞死亡等关键事件，而 TransientTrack 旨在解决多通道瞬态荧光信号（如细胞昼夜节律）的追踪问题。

Method: 结合 Transformer 网络、多阶段匹配（使用所有检测框）和 Kalman 滤波器插补缺失轨迹，直接对细胞检测嵌入进行匹配，无需量化跟踪特定特征。

Result: TransientTrack 在多样条件下表现优异，能有效追踪细胞并捕获分裂和死亡事件，已成功应用于单细胞水平的化疗药物效果分析。

Conclusion: TransientTrack 是一个轻量级的深度学习框架，有效追踪多通道显微视频中的细胞，包括细胞分裂和死亡事件，为癌症细胞动态的定量研究提供了有力工具。

Abstract: Tracking cells in time-lapse videos is an essential technique for monitoring cell population dynamics at a single-cell level. Current methods for cell tracking are developed on videos with mostly single, constant signals and do not detect pivotal events such as cell death. Here, we present TransientTrack, a deep learning-based framework for cell tracking in multi-channel microscopy video data with transient fluorescent signals that fluctuate over time following processes such as the circadian rhythm of cells. By identifying key cellular events - mitosis (cell division) and apoptosis (cell death) our method allows us to build complete trajectories, including cell lineage information. TransientTrack is lightweight and performs matching on cell detection embeddings directly, without the need for quantification of tracking-specific cell features. Furthermore, our approach integrates Transformer Networks, multi-stage matching using all detection boxes, and the interpolation of missing tracklets with the Kalman Filter. This unified framework achieves strong performance across diverse conditions, effectively tracking cells and capturing cell division and death. We demonstrate the use of TransientTrack in an analysis of the efficacy of a chemotherapeutic drug at a single-cell level. The proposed framework could further advance quantitative studies of cancer cell dynamics, enabling detailed characterization of treatment response and resistance mechanisms. The code is available at https://github.com/bozeklab/TransientTrack.

</details>


### [220] [KM-ViPE: Online Tightly Coupled Vision-Language-Geometry Fusion for Open-Vocabulary Semantic SLAM](https://arxiv.org/abs/2512.01889)
*Zaid Nasser,Mikhail Iumanov,Tianhao Li,Maxim Popov,Jaafar Mahmoud,Malik Mohrat,Ilya Obrubov,Ekaterina Derevyanka,Ivan Sosin,Sergey Kolyubin*

Main category: cs.CV

TL;DR: KM-ViPE是一个实时开放词汇SLAM框架，适用于未校准单目相机和动态环境，结合视觉与几何特征，适用于机器人和AR/VR。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有系统需要深度传感器、离线校准或缺乏动态场景鲁棒性的问题，KM-ViPE设计为直接在原始RGB流上操作，适合自我中心应用和互联网规模视频数据训练。

Method: KM-ViPE通过高级特征的自适应鲁棒核将DINO视觉特征与几何约束紧密耦合，处理移动物体和可移动静态物体，同时融合几何和深度视觉特征与语言嵌入，实现在线定位和开放词汇语义映射。

Result: KM-ViPE的结果与最先进方法竞争，且无需深度数据或里程估计，具有动态场景鲁棒性。

Conclusion: KM-ViPE结合了在线操作、未校准的单目输入和对动态场景的鲁棒处理，适用于自主机器人和AR/VR应用，推动了具身AI的实用空间智能能力。

Abstract: We present KM-ViPE (Knowledge Mapping Video Pose Engine), a real-time open-vocabulary SLAM framework for uncalibrated monocular cameras in dynamic environments. Unlike systems requiring depth sensors and offline calibration, KM-ViPE operates directly on raw RGB streams, making it ideal for ego-centric applications and harvesting internet-scale video data for training. KM-ViPE tightly couples DINO visual features with geometric constraints through a high-level features based adaptive robust kernel that handles both moving objects and movable static objects (e.g., moving furniture in ego-centric views). The system performs simultaneous online localization and open-vocabulary semantic mapping by fusing geometric and deep visual features aligned with language embeddings. Our results are competitive with state-of-the-art approaches, while existing solutions either operate offline, need depth data and/or odometry estimation, or lack dynamic scene robustness. KM-ViPE benefits from internet-scale training and uniquely combines online operation, uncalibrated monocular input, and robust handling of dynamic scenes, which makes it a good fit for autonomous robotics and AR/VR applications and advances practical spatial intelligence capabilities for embodied AI.

</details>


### [221] [StyleYourSmile: Cross-Domain Face Retargeting Without Paired Multi-Style Data](https://arxiv.org/abs/2512.01895)
*Avirup Dey,Vinay Namboodiri*

Main category: cs.CV

TL;DR: StyleYourSmile是一种无需多风格配对数据的跨域面部表情重定向方法，通过双编码器框架和扩散模型实现高保真度结果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在跨域泛化、测试时优化或多风格数据集微调方面存在局限，需要一种无需精心策划数据的方法来实现跨域面部重定向。

Method: 采用双编码器框架提取域不变身份线索和域特定风格变化，结合扩散模型进行跨域面部表情重定向。

Result: StyleYourSmile在广泛的视觉域中实现了卓越的身份保持和重定向保真度。

Conclusion: StyleYourSmile通过双编码器框架和数据增强策略，成功实现了跨域面部表情重定向，无需精心策划的多风格配对数据，且在身份保持和重定向保真度上表现优异。

Abstract: Cross-domain face retargeting requires disentangled control over identity, expressions, and domain-specific stylistic attributes. Existing methods, typically trained on real-world faces, either fail to generalize across domains, need test-time optimizations, or require fine-tuning with carefully curated multi-style datasets to achieve domain-invariant identity representations. In this work, we introduce \textit{StyleYourSmile}, a novel one-shot cross-domain face retargeting method that eliminates the need for curated multi-style paired data. We propose an efficient data augmentation strategy alongside a dual-encoder framework, for extracting domain-invariant identity cues and capturing domain-specific stylistic variations. Leveraging these disentangled control signals, we condition a diffusion model to retarget facial expressions across domains. Extensive experiments demonstrate that \textit{StyleYourSmile} achieves superior identity preservation and retargeting fidelity across a wide range of visual domains.

</details>


### [222] [SARL: Spatially-Aware Self-Supervised Representation Learning for Visuo-Tactile Perception](https://arxiv.org/abs/2512.01908)
*Gurmeher Khurana,Lan Wei,Dandan Zhang*

Main category: cs.CV

TL;DR: SARL通过空间感知的自监督学习框架，显著提升融合视觉-触觉数据的处理能力，边姿态回归任务表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督学习框架将特征图压缩为全局向量，丢弃了空间结构，无法满足需要视觉和触觉信息的操控任务需求。

Method: SARL在BYOL架构基础上引入了三个地图级目标（SAL、PPDA、RAM），以保持跨视图的注意力焦点、部分组合和几何关系一致性。

Result: SARL在六项下游任务中均优于九种自监督学习基线，边姿态回归任务的MAE为0.3955，相对改进30%。

Conclusion: SARL框架通过空间感知的自监督学习，显著提升了融合视觉-触觉数据的处理能力，尤其在几何敏感的边姿态回归任务中表现优异，接近监督学习的上限。

Abstract: Contact-rich robotic manipulation requires representations that encode local geometry. Vision provides global context but lacks direct measurements of properties such as texture and hardness, whereas touch supplies these cues. Modern visuo-tactile sensors capture both modalities in a single fused image, yielding intrinsically aligned inputs that are well suited to manipulation tasks requiring visual and tactile information. Most self-supervised learning (SSL) frameworks, however, compress feature maps into a global vector, discarding spatial structure and misaligning with the needs of manipulation. To address this, we propose SARL, a spatially-aware SSL framework that augments the Bootstrap Your Own Latent (BYOL) architecture with three map-level objectives, including Saliency Alignment (SAL), Patch-Prototype Distribution Alignment (PPDA), and Region Affinity Matching (RAM), to keep attentional focus, part composition, and geometric relations consistent across views. These losses act on intermediate feature maps, complementing the global objective. SARL consistently outperforms nine SSL baselines across six downstream tasks with fused visual-tactile data. On the geometry-sensitive edge-pose regression task, SARL achieves a Mean Absolute Error (MAE) of 0.3955, a 30% relative improvement over the next-best SSL method (0.5682 MAE) and approaching the supervised upper bound. These findings indicate that, for fused visual-tactile data, the most effective signal is structured spatial equivariance, in which features vary predictably with object geometry, which enables more capable robotic perception.

</details>


### [223] [Med-VCD: Mitigating Hallucination for Medical Large Vision Language Models through Visual Contrastive Decoding](https://arxiv.org/abs/2512.01922)
*Zahra Mahdavi,Zahra Khodakaramimaghsoud,Hooman Khaloo,Sina Bakhshandeh Taleshani,Erfan Hashemi,Javad Mirzapour Kaleybar,Omid Nejati Manzari*

Main category: cs.CV

TL;DR: Med-VCD是一种高效稀疏视觉对比解码方法，显著减少医疗LVLMs的幻觉输出，提升准确性。


<details>
  <summary>Details</summary>
Motivation: 医疗LVLMs在应用中易产生看似合理但实际错误的幻觉输出，现有解决方案效率低且可能引入模态或内容不对齐问题。

Method: 引入Med-VCD，一种稀疏视觉对比解码方法，结合新颖的令牌稀疏化策略，动态选择视觉信息令牌，减少冗余并保留关键视觉上下文。

Result: 在八个医疗数据集上的评估显示，Med-VCD平均提高事实准确性13%，幻觉准确性6%。

Conclusion: Med-VCD通过稀疏视觉对比解码方法有效减少了医疗LVLMs中的幻觉输出，提高了事实准确性和幻觉准确性，同时保持了推理效率。

Abstract: Large vision-language models (LVLMs) are now central to healthcare applications such as medical visual question answering and imaging report generation. Yet, these models remain vulnerable to hallucination outputs that appear plausible but are in fact incorrect. In the natural image domain, several decoding strategies have been proposed to mitigate hallucinations by reinforcing visual evidence, but most rely on secondary decoding or rollback procedures that substantially slow inference. Moreover, existing solutions are often domain-specific and may introduce misalignment between modalities or between generated and ground-truth content. We introduce Med-VCD, a sparse visual-contrastive decoding method that mitigates hallucinations in medical LVLMs without the time overhead of secondary decoding. Med-VCD incorporates a novel token-sparsification strategy that selects visually informed tokens on the fly, trimming redundancy while retaining critical visual context and thus balancing efficiency with reliability. Evaluations on eight medical datasets, spanning ophthalmology, radiology, and pathology tasks in visual question answering, report generation, and dedicated hallucination benchmarks, show that Med-VCD raises factual accuracy by an average of 13\% and improves hallucination accuracy by 6\% relative to baseline medical LVLMs.

</details>


### [224] [Physical ID-Transfer Attacks against Multi-Object Tracking via Adversarial Trajectory](https://arxiv.org/abs/2512.01934)
*Chenyi Wang,Yanmao Man,Raymond Muller,Ming Li,Z. Berkay Celik,Ryan Gerdes,Jonathan Petit*

Main category: cs.CV

TL;DR: AdvTraj是一种针对多目标跟踪系统的在线物理攻击方法，通过对抗轨迹操纵ID分配，揭示了MOT系统在对象关联阶段的弱点。


<details>
  <summary>Details</summary>
Motivation: 研究多目标跟踪（MOT）算法在ID关联方面的安全威胁，填补现有攻击方法在模型特异性、非鲁棒性和样本局限性上的不足。

Method: 提出AdvTraj，一种在线且物理的ID操纵攻击方法，通过对抗轨迹将攻击者ID转移至目标对象，从而混淆跟踪系统。

Result: 在CARLA模拟中，AdvTraj对SORT的白盒攻击成功率高达100%，且对SOTA MOT算法具有高转移性（最高93%成功率）。

Conclusion: AdvTraj揭示了当前最先进的多目标跟踪（MOT）系统在对象关联阶段的潜在弱点，并为提升此类系统的鲁棒性提供了见解。

Abstract: Multi-Object Tracking (MOT) is a critical task in computer vision, with applications ranging from surveillance systems to autonomous driving. However, threats to MOT algorithms have yet been widely studied. In particular, incorrect association between the tracked objects and their assigned IDs can lead to severe consequences, such as wrong trajectory predictions. Previous attacks against MOT either focused on hijacking the trackers of individual objects, or manipulating the tracker IDs in MOT by attacking the integrated object detection (OD) module in the digital domain, which are model-specific, non-robust, and only able to affect specific samples in offline datasets. In this paper, we present AdvTraj, the first online and physical ID-manipulation attack against tracking-by-detection MOT, in which an attacker uses adversarial trajectories to transfer its ID to a targeted object to confuse the tracking system, without attacking OD. Our simulation results in CARLA show that AdvTraj can fool ID assignments with 100% success rate in various scenarios for white-box attacks against SORT, which also have high attack transferability (up to 93% attack success rate) against state-of-the-art (SOTA) MOT algorithms due to their common design principles. We characterize the patterns of trajectories generated by AdvTraj and propose two universal adversarial maneuvers that can be performed by a human walker/driver in daily scenarios. Our work reveals under-explored weaknesses in the object association phase of SOTA MOT systems, and provides insights into enhancing the robustness of such systems.

</details>


### [225] [Script: Graph-Structured and Query-Conditioned Semantic Token Pruning for Multimodal Large Language Models](https://arxiv.org/abs/2512.01949)
*Zhongyu Yang,Dannong Xu,Wei Pang,Yingfang Yuan*

Main category: cs.CV

TL;DR: Script是一种无需重新训练的剪枝方法，通过去除冗余和保留查询相关视觉信息，显著提升多模态大语言模型的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型中视觉标记快速增长导致的内存消耗和推理延迟问题，同时克服现有剪枝方法忽略用户查询相关性或受限于注意力机制的问题。

Method: Script由两个模块组成：一个图结构剪枝模块用于去除视觉冗余标记，一个查询条件语义剪枝模块用于保留与查询相关的视觉信息。

Result: 在14个基准测试中，Script在模型效率和预测准确性上均优于现有剪枝方法。在LLaVA-NeXT-7B上，实现了6.8倍的预填充加速和10倍的FLOP减少，同时保留了96.88%的原始性能。

Conclusion: Script作为一种即插即用的剪枝方法，无需重新训练，能够提升多模态大语言模型在图像和视频理解任务中的效率和预测准确性。

Abstract: The rapid growth of visual tokens in multimodal large language models (MLLMs) leads to excessive memory consumption and inference latency, especially when handling high-resolution images and videos. Token pruning is a technique used to mitigate this issue by removing redundancy, but existing methods often ignore relevance to the user query or suffer from the limitations of attention mechanisms, reducing their adaptability and effectiveness. To address these challenges, we propose Script, a plug-and-play pruning method that requires no retraining and generalizes across diverse MLLMs. Script comprises two modules: a graph-structured pruning module that removes visually redundant tokens, and a query-conditioned semantic pruning module that preserves query-relevant visual information. Together, they enhance performance on multimodal tasks. Experiments on fourteen benchmarks across image and video understanding tasks show that Script consistently achieves higher model efficiency and predictive accuracy compared to existing pruning methods. On LLaVA-NeXT-7B, it achieves up to 6.8x prefill speedup and 10x FLOP reduction, while retaining 96.88% of the original performance.

</details>


### [226] [SpriteHand: Real-Time Versatile Hand-Object Interaction with Autoregressive Video Generation](https://arxiv.org/abs/2512.01960)
*Zisu Li,Hengye Lyu,Jiaxin Shi,Yufeng Zeng,Mingming Fan,Hanwang Zhang,Chen Liang*

Main category: cs.CV

TL;DR: SpriteHand 是一种实时生成多样化手-物体交互视频的自回归框架，支持多种物体类型，视觉和物理表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统基于模拟的方法无法有效捕捉与非刚性或铰接物体的动态交互，因此需要一种更通用的解决方案。

Method: 采用自回归视频生成框架，结合因果推理架构和混合后训练方法，以增强视觉真实性和时间连贯性。

Result: 模型支持实时流式生成（约18 FPS，640x368分辨率），延迟约150毫秒，连续输出超过一分钟，实验显示其在视觉质量、物理合理性和交互保真度上优于基线方法。

Conclusion: SpriteHand 框架在实时生成多样化手-物体交互视频方面表现出色，支持多种物体类型和运动模式，视觉质量和物理合理性均优于现有基线方法。

Abstract: Modeling and synthesizing complex hand-object interactions remains a significant challenge, even for state-of-the-art physics engines. Conventional simulation-based approaches rely on explicitly defined rigid object models and pre-scripted hand gestures, making them inadequate for capturing dynamic interactions with non-rigid or articulated entities such as deformable fabrics, elastic materials, hinge-based structures, furry surfaces, or even living creatures. In this paper, we present SpriteHand, an autoregressive video generation framework for real-time synthesis of versatile hand-object interaction videos across a wide range of object types and motion patterns. SpriteHand takes as input a static object image and a video stream in which the hands are imagined to interact with the virtual object embedded in a real-world scene, and generates corresponding hand-object interaction effects in real time. Our model employs a causal inference architecture for autoregressive generation and leverages a hybrid post-training approach to enhance visual realism and temporal coherence. Our 1.3B model supports real-time streaming generation at around 18 FPS and 640x368 resolution, with an approximate 150 ms latency on a single NVIDIA RTX 5090 GPU, and more than a minute of continuous output. Experiments demonstrate superior visual quality, physical plausibility, and interaction fidelity compared to both generative and engine-based baselines.

</details>


### [227] [SGDiff: Scene Graph Guided Diffusion Model for Image Collaborative SegCaptioning](https://arxiv.org/abs/2512.01975)
*Xu Zhang,Jin Yuan,Hanwang Zhang,Guojin Zhong,Yongsheng Zang,Jiacheng Lin,Zhiyong Li*

Main category: cs.CV

TL;DR: SGDiff模型通过场景图引导的扩散过程，实现了从简单提示生成多样化（描述、掩码）对的任务，显著提升了语义理解的灵活性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有图像语义理解任务中高成本提示输入或输出信息有限的问题，提出SegCaptioning任务以生成多样化的语义解释。

Method: 提出了一种基于场景图引导的扩散模型（SGDiff），包括Prompt-Centric Scene Graph Adaptor和Scene Graph Guided Bimodal Transformer，以及Multi-Entities Contrastive Learning损失函数。

Result: 在多个数据集上的实验表明，SGDiff在SegCaptioning任务中表现优异，同时提升了分割和描述任务的性能。

Conclusion: SGDiff模型在SegCaptioning任务中表现出色，通过最小化提示输入实现了高质量的图像分割和描述生成。

Abstract: Controllable image semantic understanding tasks, such as captioning or segmentation, necessitate users to input a prompt (e.g., text or bounding boxes) to predict a unique outcome, presenting challenges such as high-cost prompt input or limited information output. This paper introduces a new task ``Image Collaborative Segmentation and Captioning'' (SegCaptioning), which aims to translate a straightforward prompt, like a bounding box around an object, into diverse semantic interpretations represented by (caption, masks) pairs, allowing flexible result selection by users. This task poses significant challenges, including accurately capturing a user's intention from a minimal prompt while simultaneously predicting multiple semantically aligned caption words and masks. Technically, we propose a novel Scene Graph Guided Diffusion Model that leverages structured scene graph features for correlated mask-caption prediction. Initially, we introduce a Prompt-Centric Scene Graph Adaptor to map a user's prompt to a scene graph, effectively capturing his intention. Subsequently, we employ a diffusion process incorporating a Scene Graph Guided Bimodal Transformer to predict correlated caption-mask pairs by uncovering intricate correlations between them. To ensure accurate alignment, we design a Multi-Entities Contrastive Learning loss to explicitly align visual and textual entities by considering inter-modal similarity, resulting in well-aligned caption-mask pairs. Extensive experiments conducted on two datasets demonstrate that SGDiff achieves superior performance in SegCaptioning, yielding promising results for both captioning and segmentation tasks with minimal prompt input.

</details>


### [228] [Artemis: Structured Visual Reasoning for Perception Policy Learning](https://arxiv.org/abs/2512.01988)
*Wei Tang,Yanpeng Sun,Shan Zhang,Xiaofan Li,Piotr Koniusz,Wei Li,Na Zhao,Zechao Li*

Main category: cs.CV

TL;DR: Artemis通过结构化提议推理（空间表示）提升视觉感知策略性能，避免了语言推理的模糊性，并在多任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有视觉感知策略中的纯语言中间推理会降低性能，核心问题在于推理形式：视觉感知需要在空间和对象中心的空间中进行推理。

Method: Artemis是一个基于Qwen2.5-VL-3B的感知策略学习框架，采用结构化提议推理（(label, bounding-box)对）来明确跟踪中间状态，避免语言推理的模糊性。

Result: Artemis在基础任务（如定位和检测）上表现优异，并能泛化到计数和几何感知任务，同时在通用MLLM基准测试中具有竞争力。

Conclusion: Artemis通过将推理与空间表示对齐，显著提升了感知策略学习的性能，并在通用MLLM基准测试中表现出竞争力，证明了空间基础推理的可扩展性和通用性。

Abstract: Recent reinforcement-learning frameworks for visual perception policy have begun to incorporate intermediate reasoning chains expressed in natural language. Empirical observations indicate that such purely linguistic intermediate reasoning often reduces performance on perception tasks. We argue that the core issue lies not in reasoning per se but in the form of reasoning: while these chains perform semantic reasoning in an unstructured linguistic space, visual perception requires reasoning in a spatial and object-centric space. In response, we introduce Artemis, a perception-policy learning framework that performs structured proposal-based reasoning, where each intermediate step is represented as a (label, bounding-box) pair capturing a verifiable visual state. This design enables explicit tracking of intermediate states, direct supervision for proposal quality, and avoids ambiguity introduced by language-based reasoning. Artemis is built on Qwen2.5-VL-3B, achieves strong performance on grounding and detection task and exhibits substantial generalization to counting and geometric-perception tasks. The consistent improvements across these diverse settings confirm that aligning reasoning with spatial representations enhances perception-policy learning. Owing to its strengthened visual reasoning, Artemis also achieves competitive performance on general MLLM benchmarks, illustrating that spatially grounded reasoning provides a principled route toward scalable and general perception policies.

</details>


### [229] [PAI-Bench: A Comprehensive Benchmark For Physical AI](https://arxiv.org/abs/2512.01989)
*Fengzhe Zhou,Jiannan Huang,Jialuo Li,Deva Ramanan,Humphrey Shi*

Main category: cs.CV

TL;DR: PAI-Bench是一个评估Physical AI感知和预测能力的基准，揭示了当前模型在物理一致性和预测能力上的不足。


<details>
  <summary>Details</summary>
Motivation: 探讨当前多模态大语言模型和视频生成模型在感知和预测真实世界动态方面的能力不足。

Method: 引入了Physical AI Bench（PAI-Bench），一个统一且全面的基准，评估视频生成、条件视频生成和视频理解中的感知和预测能力，包含2,808个真实案例，并设计了任务对齐的指标以捕捉物理合理性和领域特定推理。

Result: 研究表明，视频生成模型尽管视觉保真度高，但在保持物理一致性方面表现不佳；多模态大语言模型在预测和因果解释方面表现有限。

Conclusion: PAI-Bench为评估Physical AI提供了现实基础，并指出了未来系统需解决的关键差距。

Abstract: Physical AI aims to develop models that can perceive and predict real-world dynamics; yet, the extent to which current multi-modal large language models and video generative models support these abilities is insufficiently understood. We introduce Physical AI Bench (PAI-Bench), a unified and comprehensive benchmark that evaluates perception and prediction capabilities across video generation, conditional video generation, and video understanding, comprising 2,808 real-world cases with task-aligned metrics designed to capture physical plausibility and domain-specific reasoning. Our study provides a systematic assessment of recent models and shows that video generative models, despite strong visual fidelity, often struggle to maintain physically coherent dynamics, while multi-modal large language models exhibit limited performance in forecasting and causal interpretation. These observations suggest that current systems are still at an early stage in handling the perceptual and predictive demands of Physical AI. In summary, PAI-Bench establishes a realistic foundation for evaluating Physical AI and highlights key gaps that future systems must address.

</details>


### [230] [Learning Visual Affordance from Audio](https://arxiv.org/abs/2512.02005)
*Lidong Lu,Guo Chen,Zhu Wei,Yicheng Liu,Tong Lu*

Main category: cs.CV

TL;DR: 提出AV-AG任务及AVAGFormer模型，通过音频-视觉融合实现交互区域分割，性能优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 音频提供实时、语义丰富且视觉独立的线索，相比依赖文本指令或演示视频的现有方法，能更直观地理解交互区域。

Method: 提出了AVAGFormer模型，配备语义条件跨模态混合器和双头解码器，有效融合音频和视觉信号进行掩码预测。

Result: AVAGFormer在AV-AG任务上超越了相关任务的基线模型，达到了最先进的性能。

Conclusion: AVAGFormer模型在AV-AG任务上实现了最先进的性能，并通过综合分析展示了其与AVS任务的区别、端到端建模的优势及各组件的贡献。

Abstract: We introduce Audio-Visual Affordance Grounding (AV-AG), a new task that segments object interaction regions from action sounds. Unlike existing approaches that rely on textual instructions or demonstration videos, which often limited by ambiguity or occlusion, audio provides real-time, semantically rich, and visually independent cues for affordance grounding, enabling more intuitive understanding of interaction regions. To support this task, we construct the first AV-AG dataset, comprising a large collection of action sounds, object images, and pixel-level affordance annotations. The dataset also includes an unseen subset to evaluate zero-shot generalization. Furthermore, we propose AVAGFormer, a model equipped with a semantic-conditioned cross-modal mixer and a dual-head decoder that effectively fuses audio and visual signals for mask prediction. Experiments show that AVAGFormer achieves state-of-the-art performance on AV-AG, surpassing baselines from related tasks. Comprehensive analyses highlight the distinctions between AV-AG and AVS, the benefits of end-to-end modeling, and the contribution of each component. Code and dataset have been released on https://jscslld.github.io/AVAGFormer/.

</details>


### [231] [MV-TAP: Tracking Any Point in Multi-View Videos](https://arxiv.org/abs/2512.02006)
*Jahyeok Koo,Inès Hyeonsu Kim,Mungyeom Kim,Junghyun Park,Seohyun Park,Jaeyeong Kim,Jung Yi,Seokju Cho,Seungryong Kim*

Main category: cs.CV

TL;DR: MV-TAP是一种新型多视图点跟踪器，通过跨视图注意力机制和合成数据集训练，显著提升轨迹估计性能。


<details>
  <summary>Details</summary>
Motivation: 多视图相机系统能丰富捕捉复杂动态场景，但现有方法在多视图点跟踪上仍有不足，需要更高效可靠的解决方案。

Method: MV-TAP利用相机几何和跨视图注意力机制，聚合多视图的时空信息，实现更完整可靠的点轨迹估计。

Result: MV-TAP在多个挑战性基准测试中优于现有方法，验证了其有效性。

Conclusion: MV-TAP通过利用跨视图信息和精心构建的数据集，在多视图点跟踪任务中表现出色，为未来研究提供了有效基准。

Abstract: Multi-view camera systems enable rich observations of complex real-world scenes, and understanding dynamic objects in multi-view settings has become central to various applications. In this work, we present MV-TAP, a novel point tracker that tracks points across multi-view videos of dynamic scenes by leveraging cross-view information. MV-TAP utilizes camera geometry and a cross-view attention mechanism to aggregate spatio-temporal information across views, enabling more complete and reliable trajectory estimation in multi-view videos. To support this task, we construct a large-scale synthetic training dataset and real-world evaluation sets tailored for multi-view tracking. Extensive experiments demonstrate that MV-TAP outperforms existing point-tracking methods on challenging benchmarks, establishing an effective baseline for advancing research in multi-view point tracking.

</details>


### [232] [AirSim360: A Panoramic Simulation Platform within Drone View](https://arxiv.org/abs/2512.02009)
*Xian Ge,Yuling Pan,Yuhang Zhang,Xiang Li,Weijun Zhang,Dizhe Zhang,Zhaoliang Wan,Xin Lin,Xiangkai Zhang,Juntao Liang,Jason Li,Wenjie Jiang,Bo Du,Ming-Hsuan Yang,Lu Qi*

Main category: cs.CV

TL;DR: AirSim360是一个用于无人机全方位数据采集的仿真平台，解决了数据缺乏问题，支持多种任务，并公开数据集。


<details>
  <summary>Details</summary>
Motivation: 360度全方位理解领域缺乏大规模多样化数据，限制了空间智能的发展。

Method: AirSim360专注于三个关键方面：渲染对齐的数据和标注范式、交互式行人感知系统以及自动化轨迹生成范式。

Result: 收集了超过60K全景样本，并通过多任务实验验证了模拟器的有效性。

Conclusion: AirSim360是一个全面的仿真平台，首次在全方位设置下系统化建模4D真实世界，其工具包、插件和数据集将公开提供。

Abstract: The field of 360-degree omnidirectional understanding has been receiving increasing attention for advancing spatial intelligence. However, the lack of large-scale and diverse data remains a major limitation. In this work, we propose AirSim360, a simulation platform for omnidirectional data from aerial viewpoints, enabling wide-ranging scene sampling with drones. Specifically, AirSim360 focuses on three key aspects: a render-aligned data and labeling paradigm for pixel-level geometric, semantic, and entity-level understanding; an interactive pedestrian-aware system for modeling human behavior; and an automated trajectory generation paradigm to support navigation tasks. Furthermore, we collect more than 60K panoramic samples and conduct extensive experiments across various tasks to demonstrate the effectiveness of our simulator. Unlike existing simulators, our work is the first to systematically model the 4D real world under an omnidirectional setting. The entire platform, including the toolkit, plugins, and collected datasets, will be made publicly available at https://insta360-research-team.github.io/AirSim360-website.

</details>


### [233] [Improved Mean Flows: On the Challenges of Fastforward Generative Models](https://arxiv.org/abs/2512.02012)
*Zhengyang Geng,Yiyang Lu,Zongze Wu,Eli Shechtman,J. Zico Kolter,Kaiming He*

Main category: cs.CV

TL;DR: iMF通过重新参数化训练目标和灵活引导机制，显著提升MeanFlow性能，在ImageNet 256×256上达到1.72 FID。


<details>
  <summary>Details</summary>
Motivation: MeanFlow框架的快速前向特性在训练目标和引导机制上存在挑战：训练目标依赖网络自身且引导机制缺乏灵活性。

Method: 通过重新参数化瞬时速度$v$为网络预测的平均速度$u$，将目标转化为标准回归问题，提升训练稳定性；并通过显式条件变量实现灵活的引导机制，利用上下文条件处理多样化条件。

Result: iMF在ImageNet 256×256上以1-NFE达到1.72 FID，显著优于同类方法。

Conclusion: iMF方法显著提升了MeanFlow框架的性能，在ImageNet 256×256数据集上以单次函数评估（1-NFE）达到了1.72 FID，优于同类方法，并缩小了与多步方法的差距，无需蒸馏。

Abstract: MeanFlow (MF) has recently been established as a framework for one-step generative modeling. However, its ``fastforward'' nature introduces key challenges in both the training objective and the guidance mechanism. First, the original MF's training target depends not only on the underlying ground-truth fields but also on the network itself. To address this issue, we recast the objective as a loss on the instantaneous velocity $v$, re-parameterized by a network that predicts the average velocity $u$. Our reformulation yields a more standard regression problem and improves the training stability. Second, the original MF fixes the classifier-free guidance scale during training, which sacrifices flexibility. We tackle this issue by formulating guidance as explicit conditioning variables, thereby retaining flexibility at test time. The diverse conditions are processed through in-context conditioning, which reduces model size and benefits performance. Overall, our $\textbf{improved MeanFlow}$ ($\textbf{iMF}$) method, trained entirely from scratch, achieves $\textbf{1.72}$ FID with a single function evaluation (1-NFE) on ImageNet 256$\times$256. iMF substantially outperforms prior methods of this kind and closes the gap with multi-step methods while using no distillation. We hope our work will further advance fastforward generative modeling as a stand-alone paradigm.

</details>


### [234] [TUNA: Taming Unified Visual Representations for Native Unified Multimodal Models](https://arxiv.org/abs/2512.02014)
*Zhiheng Liu,Weiming Ren,Haozhe Liu,Zijian Zhou,Shoufa Chen,Haonan Qiu,Xiaoke Huang,Zhaochong An,Fanny Yang,Aditya Patel,Viktar Atliha,Tony Ng,Xiao Han,Chuyan Zhu,Chenyang Zhang,Ding Liu,Juan-Manuel Perez-Rua,Sen He,Jürgen Schmidhuber,Wenhu Chen,Ping Luo,Wei Liu,Tao Xiang,Jonas Schult,Yuren Cong*

Main category: cs.CV

TL;DR: TUNA通过统一视觉表示空间，在理解和生成任务中均超越解耦模型，并验证了表示编码器的重要性。


<details>
  <summary>Details</summary>
Motivation: 解决现有UMMs中因解耦表示导致的不匹配问题，并探索统一表示空间对多模态任务的潜在优势。

Method: TUNA通过级联VAE编码器和表示编码器，构建了统一的连续视觉表示空间，支持端到端的图像和视频处理。

Result: TUNA在图像和视频的理解、生成及编辑任务中均达到最先进水平，且联合训练使任务间相互促进。

Conclusion: TUNA通过统一的视觉表示空间，在理解和生成任务中均取得了优异表现，证明了其设计的有效性和可扩展性。

Abstract: Unified multimodal models (UMMs) aim to jointly perform multimodal understanding and generation within a single framework. We present TUNA, a native UMM that builds a unified continuous visual representation by cascading a VAE encoder with a representation encoder. This unified representation space allows end-to-end processing of images and videos for both understanding and generation tasks. Compared to prior UMMs with decoupled representations, TUNA's unified visual space avoids representation format mismatches introduced by separate encoders, outperforming decoupled alternatives in both understanding and generation. Moreover, we observe that stronger pretrained representation encoders consistently yield better performance across all multimodal tasks, highlighting the importance of the representation encoder. Finally, in this unified setting, jointly training on both understanding and generation data allows the two tasks to benefit from each other rather than interfere. Our extensive experiments on multimodal understanding and generation benchmarks show that TUNA achieves state-of-the-art results in image and video understanding, image and video generation, and image editing, demonstrating the effectiveness and scalability of its unified representation design.

</details>


### [235] [Generative Video Motion Editing with 3D Point Tracks](https://arxiv.org/abs/2512.02015)
*Yao-Chih Lee,Zhoutong Zhang,Jiahui Huang,Jui-Hsien Wang,Joon-Young Lee,Jia-Bin Huang,Eli Shechtman,Zhengqi Li*

Main category: cs.CV

TL;DR: 提出一种基于3D点轨迹的V2V框架，通过稀疏对应和两阶段训练，实现相机和物体运动的联合精确编辑，提升视频编辑能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂物体运动下缺乏全场景上下文或对细粒度运动控制有限，需更精确的相机和物体运动联合编辑方案。

Method: 采用两阶段训练（合成和真实数据），通过3D点轨迹建立稀疏对应关系，传递源视频的丰富上下文至新运动，保持时空一致性。

Result: 模型支持多样运动编辑（如相机/物体联合操作、运动转移、非刚性变形），显著优于现有2D轨迹方法。

Conclusion: 提出的基于3D点轨迹的视频到视频（V2V）框架，通过联合编辑相机和物体运动，显著提升了视频编辑的精确性和创造性潜力。

Abstract: Camera and object motions are central to a video's narrative. However, precisely editing these captured motions remains a significant challenge, especially under complex object movements. Current motion-controlled image-to-video (I2V) approaches often lack full-scene context for consistent video editing, while video-to-video (V2V) methods provide viewpoint changes or basic object translation, but offer limited control over fine-grained object motion. We present a track-conditioned V2V framework that enables joint editing of camera and object motion. We achieve this by conditioning a video generation model on a source video and paired 3D point tracks representing source and target motions. These 3D tracks establish sparse correspondences that transfer rich context from the source video to new motions while preserving spatiotemporal coherence. Crucially, compared to 2D tracks, 3D tracks provide explicit depth cues, allowing the model to resolve depth order and handle occlusions for precise motion editing. Trained in two stages on synthetic and real data, our model supports diverse motion edits, including joint camera/object manipulation, motion transfer, and non-rigid deformation, unlocking new creative potential in video editing.

</details>


### [236] [Objects in Generated Videos Are Slower Than They Appear: Models Suffer Sub-Earth Gravity and Don't Know Galileo's Principle...for now](https://arxiv.org/abs/2512.02016)
*Varun Varma Thozhiyoor,Shivam Tripathi,Venkatesh Babu Radhakrishnan,Anand Bhattad*

Main category: cs.CV

TL;DR: 视频生成器在模拟重力时表现出加速度较慢的问题，研究发现这并非由度量尺度模糊引起。通过无单位双对象协议测试，揭示了伽利略等效原理的违反。使用轻量级低秩适配器微调后，重力模拟能力显著提升，并展示了零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 视频生成器被越来越多地评估为潜在的世界模型，这要求它们能够编码和理解物理定律。本研究旨在探讨视频生成器对重力这一基本定律的表征能力，并解决现有物理测试中因度量尺度模糊导致的混淆问题。

Method: 研究首先探讨了视频生成器中物体下落加速度较慢的现象是否由度量尺度模糊引起，发现即使时间重缩放也无法纠正高方差的重力伪影。随后，引入了一种无单位的双对象协议，测试与重力加速度g、焦距和尺度无关的时间比t₁²/t₂² = h₁/h₂关系，揭示了伽利略等效原理的违反。最后，通过针对性的专业化方法，使用轻量级低秩适配器进行微调。

Result: 研究发现，即使时间重缩放也无法纠正视频生成器中的重力伪影。通过无单位的双对象协议测试，揭示了视频生成器对伽利略等效原理的违反。通过轻量级低秩适配器的微调，显著提高了对重力加速度的模拟能力，并展示了零样本泛化能力。

Conclusion: 通过轻量级低秩适配器的微调，视频生成器在仅使用100个单球下落片段的情况下，显著提高了对重力加速度的模拟能力，从1.81 m/s²提升到6.43 m/s²（达到地球重力的65%）。这一方法还展示了零样本泛化能力，适用于双球下落和斜面实验，表明特定物理定律可以通过少量数据进行修正。

Abstract: Video generators are increasingly evaluated as potential world models, which requires them to encode and understand physical laws. We investigate their representation of a fundamental law: gravity. Out-of-the-box video generators consistently generate objects falling at an effectively slower acceleration. However, these physical tests are often confounded by ambiguous metric scale. We first investigate if observed physical errors are artifacts of these ambiguities (e.g., incorrect frame rate assumptions). We find that even temporal rescaling cannot correct the high-variance gravity artifacts. To rigorously isolate the underlying physical representation from these confounds, we introduce a unit-free, two-object protocol that tests the timing ratio $t_1^2/t_2^2 = h_1/h_2$, a relationship independent of $g$, focal length, and scale. This relative test reveals violations of Galileo's equivalence principle. We then demonstrate that this physical gap can be partially mitigated with targeted specialization. A lightweight low-rank adaptor fine-tuned on only 100 single-ball clips raises $g_{\mathrm{eff}}$ from $1.81\,\mathrm{m/s^2}$ to $6.43\,\mathrm{m/s^2}$ (reaching $65\%$ of terrestrial gravity). This specialist adaptor also generalizes zero-shot to two-ball drops and inclined planes, offering initial evidence that specific physical laws can be corrected with minimal data.

</details>


<div id='cs.OS'></div>

# cs.OS [[Back]](#toc)

### [237] [TenonOS: A Self-Generating Intelligent Embedded Operating System Framework for Edge Computing](https://arxiv.org/abs/2512.00400)
*Xinkui Zhao,Yifan Zhang,Haidan Zhao,Hao Zhang,Qingyu Ma,Lufei Zhang,Guanjie Cheng,Shuiguang Deng,Jianwei Yin,Zuoning Chen*

Main category: cs.OS

TL;DR: TenonOS是一种模块化操作系统框架，通过LibOS-on-LibOS方法和动态编排引擎优化边缘计算的资源管理和实时性能。


<details>
  <summary>Details</summary>
Motivation: 传统操作系统和hypervisor架构在边缘计算中难以管理异构平台和有限资源，现有解决方案难以满足边缘场景的多样化和动态需求。

Method: 提出TenonOS框架，采用LibOS-on-LibOS方法，将虚拟化和OS功能模块化为微库，并通过动态编排引擎按需组合。核心组件包括模块化hypervisor Mortise和实时LibOS Tenon。

Result: 评估显示TenonOS在实时调度性能（提升40.28%）、内存占用（361 KiB）及动态边缘工作负载适应性方面表现优异。

Conclusion: TenonOS通过其模块化架构显著提升了边缘计算的实时调度性能、内存效率及动态适应性，为异构资源受限的边缘系统提供了理想的基础。

Abstract: The rapid evolution of edge computing has exposed fundamental limitations in traditional operating system and hypervisor architectures, particularly in managing heterogeneous platforms and meeting the constraints of limited resources. Existing solutions often rely on monolithic or layered combinations of hypervisors and guest OSes, which are difficult to tailor for the diverse and dynamic requirements of edge scenarios. To address these challenges, we propose TenonOS, a demand-driven, self-generating, and lightweight operating system framework that fundamentally rethinks and reconstructs both the hypervisor and OS architectures. TenonOS introduces a novel LibOS-on-LibOS approach, in which both virtualization and OS functionalities are modularized into fine-grained, reusable micro-libraries. A dynamic orchestration engine composes these modules on demand to construct customized, application-specific runtime environments. At the core of TenonOS are two key components: Mortise, a minimal, modularized hypervisor, and Tenon, a real-time LibOS. Mortise provides low-overhead resource isolation, fast inter-VM communication, and manages the full lifecycle of Tenon instances - including on-demand creation, suspension, and termination - enabling TenonOS to flexibly adapt its runtime layout to workload variations. Tenon delivers deterministic scheduling and multi-process support for time-critical applications. Through this unified and modular architecture, TenonOS eliminates redundant layers, reduces system overhead, and enhances scalability, security, and maintainability. Extensive evaluations demonstrate that TenonOS achieves superior real-time scheduling (40.28% improvement), a compact memory footprint (361 KiB), and high adaptability to dynamic edge workloads, making it an ideal foundation for heterogeneous, resource-constrained edge systems.

</details>


### [238] [Accelerating Probabilistic Response-Time Analysis: Revised Critical Instant and Optimized Convolution](https://arxiv.org/abs/2512.01381)
*Hiroto Takahashi,Atsushi Yano,Takuya Azumi*

Main category: cs.OS

TL;DR: 本文提出了一种优化的聚合卷积方法，显著提高了WCDFP估计的计算效率，同时保持准确性和安全性。


<details>
  <summary>Details</summary>
Motivation: 经典的关键时刻假设在概率设置中可能导致WCDFP的低估，因此需要一种修订的关键时刻公式来更真实地捕捉最坏情况。

Method: 本文研究了基于卷积的WCDFP估计方法，并提出了一种通过改进合并顺序来加速卷积的优化技术。

Result: 实验表明，优化的聚合卷积比顺序卷积计算时间减少了高达一个数量级，同时保持了准确和安全的WCDFP估计。

Conclusion: 本文提出的优化聚合卷积方法在保持准确和安全性的同时，显著提高了WCDFP估计的计算效率，为安全关键实时应用的概率时序分析提供了高效可靠的解决方案。

Abstract: Accurate estimation of the Worst-Case Deadline Failure Probability (WCDFP) has attracted growing attention as a means to provide safety assurances in complex systems such as robotic platforms and autonomous vehicles. WCDFP quantifies the likelihood of deadline misses under the most pessimistic operating conditions, and safe estimation is essential for dependable real-time applications. However, achieving high accuracy in WCDFP estimation often incurs significant computational cost. Recent studies have revealed that the classical assumption of the critical instant, the activation pattern traditionally considered to trigger the worst-case behavior, can lead to underestimation of WCDFP in probabilistic settings. This observation motivates the use of a revised critical instant formulation that more faithfully captures the true worst-case scenario. This paper investigates convolution-based methods for WCDFP estimation under this revised setting and proposes an optimization technique that accelerates convolution by improving the merge order. Extensive experiments with diverse execution-time distributions demonstrate that the proposed optimized Aggregate Convolution reduces computation time by up to an order of magnitude compared to Sequential Convolution, while retaining accurate and safe-sided WCDFP estimates. These results highlight the potential of the approach to provide both efficiency and reliability in probabilistic timing analysis for safety-critical real-time applications.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [239] [Gold-Medal-Level Olympiad Geometry Solving with Efficient Heuristic Auxiliary Constructions](https://arxiv.org/abs/2512.00097)
*Boyan Duan,Xiao Liang,Shuai Lu,Yaoxiang Wang,Yelong Shen,Kai-Wei Chang,Ying Nian Wu,Mao Yang,Weizhu Chen,Yeyun Gong*

Main category: cs.AI

TL;DR: HAGeo是一种高效几何定理证明方法，不依赖神经网络，在IMO-30测试中表现优异，并构建了更难的HAGeo-409基准。


<details>
  <summary>Details</summary>
Motivation: 解决欧几里得几何中自动定理证明的挑战，特别是在IMO级别问题上，提升AI在该领域的能力。

Method: 提出HAGeo，一种基于启发式的方法，用于在几何推理中添加辅助构造，完全在CPU上运行，不依赖神经网络推理。

Result: HAGeo在IMO-30基准测试中解决了30个问题中的28个，达到金牌水平，并构建了更具挑战性的HAGeo-409基准。

Conclusion: HAGeo方法在几何定理证明中表现出色，不仅超越了基于神经网络的AlphaGeometry，还在IMO-30基准测试中达到金牌水平，同时新构建的HAGeo-409基准为几何定理证明设定了更高标准。

Abstract: Automated theorem proving in Euclidean geometry, particularly for International Mathematical Olympiad (IMO) level problems, remains a major challenge and an important research focus in Artificial Intelligence. In this paper, we present a highly efficient method for geometry theorem proving that runs entirely on CPUs without relying on neural network-based inference. Our initial study shows that a simple random strategy for adding auxiliary points can achieve silver-medal level human performance on IMO. Building on this, we propose HAGeo, a Heuristic-based method for adding Auxiliary constructions in Geometric deduction that solves 28 of 30 problems on the IMO-30 benchmark, achieving gold-medal level performance and surpassing AlphaGeometry, a competitive neural network-based approach, by a notable margin. To evaluate our method and existing approaches more comprehensively, we further construct HAGeo-409, a benchmark consisting of 409 geometry problems with human-assessed difficulty levels. Compared with the widely used IMO-30, our benchmark poses greater challenges and provides a more precise evaluation, setting a higher bar for geometry theorem proving.

</details>


### [240] [Chunking Strategies for Multimodal AI Systems](https://arxiv.org/abs/2512.00185)
*Shashanka B R,Mohith Charan R,Seema Banu F*

Main category: cs.AI

TL;DR: 本文综述了多模态分块策略，提供了分类和技术分析，探讨了现有方法的优缺点，并指出了未来研究的方向。


<details>
  <summary>Details</summary>
Motivation: 目标是整合多模态分块策略的现状，为开发更有效和高效的多模态AI系统提供技术基础和设计空间。

Method: 本文提供了针对每种模态（文本、图像、音频、视频和跨模态数据）的全面分类和技术分析，包括固定大小的令牌窗口、递归文本分割、基于对象的视觉分块、基于静音的音频分段和视频中的场景检测等方法。

Result: 本文分析了每种方法的底层方法论、支持工具、优点和挑战，并探讨了新兴的跨模态分块策略，以保持跨不同数据类型的一致性和语义一致性。

Conclusion: 本文总结了多模态分块策略的现状，为研究人员和从业者提供了技术基础和设计空间，以开发更高效的多模态AI系统。

Abstract: Our goal is to consolidate the landscape of multimodal chunking strategies, providing researchers and practitioners with a technical foundation and design space for developing more effective and efficient multimodal AI systems. This survey paves the way for innovations in robust chunking pipelines that scale with modality complexity, enhance processing accuracy, and improve generative coherence in real-world applications. This survey provides a comprehensive taxonomy and technical analysis of chunking strategies tailored for each modality: text, images, audio, video, and cross-modal data. We examine classical and modern approaches such as fixed-size token windowing, recursive text splitting, object-centric visual chunking, silence-based audio segmentation, and scene detection in videos. Each approach is analyzed in terms of its underlying methodology, supporting tools (e.g., LangChain, Detectron2, PySceneDetect), benefits, and challenges, particularly those related to granularity-context trade-offs and multimodal alignment. Furthermore, we explore emerging cross-modal chunking strategies that aim to preserve alignment and semantic consistency across disparate data types [4]. We also include comparative insights, highlight open problems such as asynchronous information density and noisy alignment signals, and identify opportunities for future research in adaptive, learning-based, and task-specific chunking.

</details>


### [241] [A Rosetta Stone for AI Benchmarks](https://arxiv.org/abs/2512.00193)
*Anson Ho,Jean-Stanislas Denain,David Atanasov,Samuel Albanie,Rohin Shah*

Main category: cs.AI

TL;DR: 论文提出一个统计框架，统一不同基准测试结果，用于衡量AI进展、预测未来能力及检测进展加速。


<details>
  <summary>Details</summary>
Motivation: 解决AI基准测试快速饱和的问题，以便更有效地研究AI能力的长期趋势。

Method: 构建了一个统计框架，将模型能力和基准测试难度统一到一个数值尺度上，无需假设能力随时间或训练计算量的变化。

Result: 该框架成功应用于衡量AI进展速度、预测未来能力、估计算法效率改进速率，并检测到AI进展的快速加速。

Conclusion: 该论文提出了一个统计框架，能够将不同基准测试的结果统一到一个数值尺度上，从而解决AI基准测试快速饱和的问题，并展示了其在衡量AI进展速度、预测未来能力以及检测进展加速方面的应用。

Abstract: Most AI benchmarks saturate within years or even months after they are introduced, making it hard to study long-run trends in AI capabilities. To address this challenge, we build a statistical framework that stitches benchmarks together, putting model capabilities and benchmark difficulties on a single numerical scale. This acts as a "Rosetta Stone", allowing us to compare models across a wide range of abilities and time, even if they are not evaluated on the same benchmarks. Moreover, this works without assuming how capabilities evolve across time or with training compute. We demonstrate three applications of this framework. First, we use it to measure the speed of AI progress over time, and to forecast future AI capabilities. Second, we estimate the rate of improvements in algorithmic efficiency, finding estimates that are higher, but broadly consistent with prior work. Finally, we find that our approach can be used to detect rapid accelerations in AI progress.

</details>


### [242] [Reasoning Under Pressure: How do Training Incentives Influence Chain-of-Thought Monitorability?](https://arxiv.org/abs/2512.00218)
*Matt MacDermott,Qiyao Wei,Rada Djoneva,Francis Rhys Ward*

Main category: cs.AI

TL;DR: 研究不同训练激励对AI系统监控性的影响，发现对抗性优化会降低监控效果，而直接优化监控性效果不稳定。


<details>
  <summary>Details</summary>
Motivation: 探讨不同训练激励如何影响AI系统的监控性，以评估其推理链（CoT）是否真实反映底层推理过程。

Method: 引入了一种新颖的方法论，通过监控是否能预测关键潜在变量来衡量监控性。

Result: 在控制准确性的情况下，未发现常用激励（如长度惩罚和KL正则化）有显著影响，但对抗性优化会降低监控性能。

Conclusion: 研究表明，对抗性优化会降低监控性能，而直接优化监控性并不能可靠地提升效果。

Abstract: AI systems that output their reasoning in natural language offer an opportunity for safety -- we can \emph{monitor} their chain of thought (CoT) for undesirable reasoning, such as the pursuit of harmful objectives. However, the extent to which CoT faithfully reflects the underlying reasoning process, and hence the extent to which it can be usefully monitored, may be influenced by certain aspects of training. We investigate how different \emph{training incentives}, applied to a reasoning model, affect its monitorability. We introduce a novel methodology for measuring monitorability according to whether a monitor can predict a key latent variable using the model's reasoning. When controlling for accuracy, we do not find evidence for consistent effects from commonly used incentives (length penalties and KL regularisation), but we find that adversarial optimisation (penalising monitor accuracy) degrades monitor performance, while direct optimisation for monitorability does not reliably lead to improvements. Our code is available at https://github.com/QiyaoWei/reasoning-under-pressure.

</details>


### [243] [OntoMetric: An Ontology-Guided Framework for Automated ESG Knowledge Graph Construction](https://arxiv.org/abs/2512.01289)
*Mingqin Yu,Fethi Rabhi,Boming Xia,Zhengyi Yang,Felix Tan,Qinghua Lu*

Main category: cs.AI

TL;DR: OntoMetric是一个本体引导的框架，将ESG监管文档转化为已验证的AI和网络就绪知识图谱，通过结构分割、本体约束提取和两阶段验证，显著提升准确性和合规性。


<details>
  <summary>Details</summary>
Motivation: ESG披露框架（如SASB、TCFD、IFRS S2）要求组织计算并报告大量指标，但这些要求嵌入在难以解释、标准化和审计的长篇非结构化PDF文档中。手动提取不可扩展，而无约束的大型语言模型提取常产生不一致实体、虚构关系、缺失来源和高验证失败率。

Method: OntoMetric采用三阶段流程：(1) 基于目录边界的结构感知分割，(2) 本体约束的LLM提取，将ESGMKG模式嵌入提示中并丰富实体的语义字段，(3) 两阶段验证，结合基于LLM的语义验证和基于规则的模式检查。

Result: 在五个ESG标准（总计228页和60个片段）上评估，OntoMetric实现了65-90%的语义准确率和80-90%的模式合规率，而基线无约束提取仅为3-10%，每个验证实体的成本约为0.01至0.02美元。

Conclusion: OntoMetric框架通过结合符号本体约束与神经提取，生成了适用于监管合规和网络集成的可靠、可审计知识图谱，支持可持续金融分析、透明度门户和自动化合规工具等下游应用。

Abstract: Environmental, Social, and Governance (ESG) disclosure frameworks such as SASB, TCFD, and IFRS S2 require organizations to compute and report numerous metrics for compliance, yet these requirements are embedded in long, unstructured PDF documents that are difficult to interpret, standardize, and audit. Manual extraction is unscalable, while unconstrained large language model (LLM) extraction often produces inconsistent entities, hallucinated relationships, missing provenance, and high validation failure rates. We present OntoMetric, an ontology-guided framework that transforms ESG regulatory documents into validated, AI- and web-ready knowledge graphs. OntoMetric operates through a three-stage pipeline: (1) structure-aware segmentation using table-of-contents boundaries, (2) ontology-constrained LLM extraction that embeds the ESGMKG schema into prompts while enriching entities with semantic fields for downstream reasoning, and (3) two-phase validation that combines LLM-based semantic verification with rule-based schema checking across entity, property, and relationship levels (VR001-VR006). The framework preserves both segment-level and page-level provenance for audit traceability. Evaluated on five ESG standards (SASB Commercial Banks, SASB Semiconductors, TCFD, IFRS S2, AASB S2) totaling 228 pages and 60 segments, OntoMetric achieves 65-90% semantic accuracy and 80-90% schema compliance, compared to 3-10% for baseline unconstrained extraction, at approximately 0.01 to 0.02 USD per validated entity. Our results demonstrate that combining symbolic ontology constraints with neural extraction enables reliable, auditable knowledge graphs suitable for regulatory compliance and web integration, supporting downstream applications such as sustainable-finance analytics, transparency portals, and automated compliance tools.

</details>


### [244] [Trification: A Comprehensive Tree-based Strategy Planner and Structural Verification for Fact-Checking](https://arxiv.org/abs/2512.00267)
*Anab Maulana Barik,Shou Ziyi,Yang Kaiwen,Yang Qi,Shen Xin*

Main category: cs.AI

TL;DR: 提出Trification框架，通过生成验证行动集和构建依赖图来提升自动化事实核查的准确性和适应性，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 技术进步使得信息可以一键分享，但也加速了虚假信息的传播，因此需要自动化事实核查系统来确保在线媒体生态的安全和完整性。

Method: 提出了一种名为Trification的新型自动化事实核查框架，首先生成全面的验证行动集以确保覆盖所有声明内容，然后将这些行动构建为依赖图以模拟行动间的逻辑交互，并支持动态调整验证策略。

Result: 在两个具有挑战性的基准测试中，实验结果表明该框架显著提高了事实核查的准确性。

Conclusion: Trification框架显著提高了事实核查的准确性，推动了自动化事实核查系统的技术进步。

Abstract: Technological advancement allows information to be shared in just a single click, which has enabled the rapid spread of false information. This makes automated fact-checking system necessary to ensure the safety and integrity of our online media ecosystem. Previous methods have demonstrated the effectiveness of decomposing the claim into simpler sub-tasks and utilizing LLM-based multi agent system to execute them. However, those models faces two limitations: they often fail to verify every component in the claim and lack of structured framework to logically connect the results of sub-tasks for a final prediction. In this work, we propose a novel automated fact-checking framework called Trification. Our framework begins by generating a comprehensive set of verification actions to ensure complete coverage of the claim. It then structured these actions into a dependency graph to model the logical interaction between actions. Furthermore, the graph can be dynamically modified, allowing the system to adapt its verification strategy. Experimental results on two challenging benchmarks demonstrate that our framework significantly enhances fact-checking accuracy, thereby advancing current state-of-the-art in automated fact-checking system.

</details>


### [245] [ChartPoint: Guiding MLLMs with Grounding Reflection for Chart Reasoning](https://arxiv.org/abs/2512.00305)
*Zhengzhuo Xu,SiNan Du,Yiyan Qi,SiwenLu,Chengjin Xu,Chun Yuan,Jian Guo*

Main category: cs.AI

TL;DR: PointCoT通过结合视觉基础与思维链推理，解决了MLLMs在图表理解中的数值幻觉问题，并在基准测试中显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在图表理解中过度依赖OCR提取内容，导致数值幻觉问题，尤其在图表文本注释稀疏时。现有方法未能解决视觉感知推理的根本挑战。

Method: 提出PointCoT方法，通过生成边界框和基于位置注释重新渲染图表，将文本推理步骤与视觉基础区域连接。构建了ChartPoint-SFT-62k数据集，包含19.2K高质量图表样本，并开发了两种指令调优模型ChartPointQ2和ChartPointQ2.5。

Result: 提出的方法在多个图表基准测试中表现优异，例如在ChartBench上提升了5.04%。

Conclusion: 提出的PointCoT方法通过结合反射性交互与思维链推理，显著提升了多模态大语言模型（MLLMs）在图表理解中的视觉基础能力，并在多个基准测试中优于现有方法。

Abstract: Multimodal Large Language Models (MLLMs) have emerged as powerful tools for chart comprehension. However, they heavily rely on extracted content via OCR, which leads to numerical hallucinations when chart textual annotations are sparse. While existing methods focus on scaling instructions, they fail to address the fundamental challenge, i.e., reasoning with visual perception. In this paper, we identify a critical observation: MLLMs exhibit weak grounding in chart elements and proportional relationships, as evidenced by their inability to localize key positions to match their reasoning. To bridge this gap, we propose PointCoT, which integrates reflective interaction into chain-of-thought reasoning in charts. By prompting MLLMs to generate bounding boxes and re-render charts based on location annotations, we establish connections between textual reasoning steps and visual grounding regions. We further introduce an automated pipeline to construct ChartPoint-SFT-62k, a dataset featuring 19.2K high-quality chart samples with step-by-step CoT, bounding box, and re-rendered visualizations. Leveraging this data, we develop two instruction-tuned models, ChartPointQ2 and ChartPointQ2.5, which outperform state-of-the-art across several chart benchmarks, e.g., +5.04\% on ChartBench.

</details>


### [246] [RL-Struct: A Lightweight Reinforcement Learning Framework for Reliable Structured Output in LLMs](https://arxiv.org/abs/2512.00319)
*Ruike Hu,Shulei Wu*

Main category: cs.AI

TL;DR: 该论文通过强化学习框架解决了LLMs在结构化数据生成中的‘结构鸿沟’，采用GRPO和多维奖励函数，显著提升了输出的结构准确性和有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在自动化软件生态系统中的集成受到‘结构鸿沟’的限制，即概率性标记生成与确定性结构化数据格式（如JSON、XML）之间的固有矛盾。传统的监督微调（SFT）无法强制执行严格的语法约束，而约束解码方法则导致显著的推理延迟。

Method: 采用多维奖励函数和梯度正则化策略优化（GRPO），将结构化输出任务分解为结构完整性、格式正确性、内容准确性和有效性四个层次的约束。

Result: 实验结果表明，该方法在多个任务中实现了89.7%的结构准确性和92.1%的JSON有效性，显著优于零样本基线（如GPT-3.5）和更大模型的SFT（如LLaMA-3-8B）。

Conclusion: 该论文提出了一种轻量级高效的强化学习框架，成功解决了大型语言模型在结构化数据生成中的‘结构鸿沟’问题，显著提升了输出结构的准确性和有效性。

Abstract: Large Language Models (LLMs) have demonstrated remarkable capabilities in natural language generation and reasoning. However, their integration into automated software ecosystems is often hindered by the "Structure Gap" - the inherent tension between the probabilistic nature of token generation and the deterministic requirements of structured data formats (e.g., JSON, XML). Traditional Supervised Fine-Tuning (SFT) often fails to enforce strict syntactic constraints, leading to "hallucinated" keys or malformed structures, while constrained decoding methods impose significant inference latency. In this paper, we propose a lightweight, efficient Reinforcement Learning (RL) framework to bridge this gap. We introduce a novel Multi-dimensional Reward Function that decomposes the structured output task into a hierarchy of constraints: structural integrity, format correctness, content accuracy, and validity. Leveraging Gradient Regularized Policy Optimization (GRPO), we enable the model to internalize these constraints without the need for a separate critic network, reducing peak VRAM usage by 40% compared to PPO. We validate our approach on multiple tasks, including complex recipe generation and structured math reasoning (GSM8K-JSON). Experimental results demonstrate that our method achieves 89.7% structural accuracy and 92.1% JSON validity, significantly outperforming both zero-shot baselines (e.g., GPT-3.5) and SFT on larger models like LLaMA-3-8B. Furthermore, we provide a detailed analysis of training dynamics, revealing a distinct self-paced curriculum where the model sequentially acquires syntactic proficiency before semantic accuracy. Our model is publicly available at https://huggingface.co/Freakz3z/Qwen-JSON.

</details>


### [247] [CogEvo-Edu: Cognitive Evolution Educational Multi-Agent Collaborative System](https://arxiv.org/abs/2512.00331)
*Yefeng Wu,Yuchen Song,Yecheng Zhao,Ling Wu,Shan Wan*

Main category: cs.AI

TL;DR: CogEvo-Edu通过分层多智能体系统解决了LLM在复杂STEM教育中的局限性，显著提升了教学效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于单一LLM和静态RAG的STEM教育系统在复杂领域（如DSP）中难以维持长期连贯的学生模型、管理异构知识库并适应教学策略。

Method: CogEvo-Edu采用分层多智能体系统，包括认知感知层（CPL）、知识演化层（KEL）和元控制层（MCL），通过双记忆维护、时空知识值驱动和分层决策机制实现动态适应。

Result: 在DSP-EduBench基准测试中，CogEvo-Edu将总体评分从5.32提升至9.23，并在所有六个指标上优于静态RAG、简单记忆和单智能体变体。

Conclusion: CogEvo-Edu通过分层多智能体系统显著提升了STEM教育中LLM作为对话导师的效果，特别是在复杂领域如数字信号处理中，展现了联合演化学生档案、知识库和教学策略的价值。

Abstract: Large language models (LLMs) are increasingly deployed as conversational tutors in STEM education, yet most systems still rely on a single LLM with a static retrieval-augmented generation (RAG) pipeline over course materials. This design struggles in complex domains such as digital signal processing (DSP), where tutors must maintain coherent long-term student models, manage heterogeneous knowledge bases, and adapt teaching strategies over extended interactions. We argue that retrieval, memory, and control should be treated as a coupled cognitive evolution process. We instantiate this view in CogEvo-Edu, a hierarchical educational multi-agent system comprising a Cognitive Perception Layer (CPL), a Knowledge Evolution Layer (KEL), and a Meta-Control Layer (MCL). CPL maintains dual memories and performs confidence-weighted consolidation to build structured, self-correcting student profiles under limited context. KEL assigns each knowledge chunk a spatiotemporal value that drives activation, semantic compression, and forgetting. MCL formulates tutoring as hierarchical sequential decision making, orchestrating specialized agents and jointly adapting CPL/KEL hyperparameters via a dual inner--outer loop. To evaluate CogEvo-Edu, we construct DSP-EduBench, a vertical benchmark for DSP tutoring with heterogeneous resources, simulated student profiles, and long-horizon interaction scripts. Using a three-model LLM-as-a-Judge ensemble, CogEvo-Edu raises the overall score from 5.32 to 9.23 and improves all six indicators over static RAG, simple memory, and a single-agent variant, demonstrating the value of jointly evolving student profiles, knowledge bases, and teaching policies.

</details>


### [248] [Echo-N1: Affective RL Frontier](https://arxiv.org/abs/2512.00344)
*Naifan Zhang,Ruihan Sun,Ruixi Su,Shiqi Ma,Shiya Zhang,Xianna Weng,Xiaofan Zhang,Yuhan Zhan,Yuyang Xu,Zhaohan Chen,Zhengyuan Pan,Ziyi Song*

Main category: cs.AI

TL;DR: 研究证明RL可优化主观对话，提出个性化框架和评估套件，模型Echo-N1表现卓越。


<details>
  <summary>Details</summary>
Motivation: 当前LLM领域过度关注机器已擅长的任务（如数学、代码和确定性推理），而忽视了定义人类智能的主观、情感化和个性敏感的对话领域。

Method: 提出了首个动态推断用户个性并优化模型行为以适应个性化对话偏好的框架，并引入了动态情商评估套件来量化改进。

Result: 模型Echo-N1在人类化交互质量上表现出显著提升，超越了基础版本和专有模型Doubao 1.5 Character。

Conclusion: 本研究为强化学习（RL）开辟了新领域，专注于优化对话中主观且人性化的维度，证明了RL在非可验证环境中的有效性。

Abstract: The LLM field has spent a year perfecting RL for tasks machines already excel at, math, code, and deterministic reasoning, while completely sidestepping the domain that actually defines human intelligence: subjective, emotionally grounded, personality sensitive conversation. This space has often been regarded as inherently subjective and challenging to formalize, making it appear unsuitable for conventional RL pipelines. We show that it is not only possible and it is a solvable and transformative RL problem. We propose the first framework that infers user personality on the fly and optimizes model behavior toward personalized conversational preferences. Contrary to the widespread belief that RL collapses in non-verifiable settings, our method produces consistent, robust, and dramatic improvements in humanlike interaction quality. We also introduce the first dynamic emotional intelligence evaluation suite to quantify these gains. Our model, which is introduced as Echo-N1, behaves far above its base version and outperforming the proprietary Doubao 1.5 Character. This work establishes a new frontier for RL: optimizing models for the deeply subjective, deeply human dimensions of conversation.

</details>


### [249] [Debate with Images: Detecting Deceptive Behaviors in Multimodal Large Language Models](https://arxiv.org/abs/2512.00349)
*Sitong Fang,Shiyi Hou,Kaile Wang,Boyuan Chen,Donghai Hong,Jiayi Zhou,Josef Dai,Yaodong Yang,Jiaming Ji*

Main category: cs.AI

TL;DR: 本文揭示多模态欺骗风险，提出首个多模态欺骗评估基准MM-DeceptionBench和‘debate with images’监控框架，显著提升检测效果。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统能力的提升，欺骗行为从文本扩展到多模态场景，潜在危害加剧，但现有研究多局限于文本，多模态欺骗风险未被充分探索。

Method: 通过引入MM-DeceptionBench基准和‘debate with images’多代理辩论监控框架，系统评估和检测多模态欺骗行为。

Result: 实验结果显示，提出的方法在所有测试模型上均显著提升了与人类判断的一致性，Cohen's kappa和准确率分别提升1.5倍和1.25倍（GPT-4o）。

Conclusion: 本文提出了MM-DeceptionBench基准和多代理辩论监控框架，显著提高了对多模态欺骗行为的检测能力，实验证明该方法在多个模型上均有效提升了与人类判断的一致性。

Abstract: Are frontier AI systems becoming more capable? Certainly. Yet such progress is not an unalloyed blessing but rather a Trojan horse: behind their performance leaps lie more insidious and destructive safety risks, namely deception. Unlike hallucination, which arises from insufficient capability and leads to mistakes, deception represents a deeper threat in which models deliberately mislead users through complex reasoning and insincere responses. As system capabilities advance, deceptive behaviours have spread from textual to multimodal settings, amplifying their potential harm. First and foremost, how can we monitor these covert multimodal deceptive behaviors? Nevertheless, current research remains almost entirely confined to text, leaving the deceptive risks of multimodal large language models unexplored. In this work, we systematically reveal and quantify multimodal deception risks, introducing MM-DeceptionBench, the first benchmark explicitly designed to evaluate multimodal deception. Covering six categories of deception, MM-DeceptionBench characterizes how models strategically manipulate and mislead through combined visual and textual modalities. On the other hand, multimodal deception evaluation is almost a blind spot in existing methods. Its stealth, compounded by visual-semantic ambiguity and the complexity of cross-modal reasoning, renders action monitoring and chain-of-thought monitoring largely ineffective. To tackle this challenge, we propose debate with images, a novel multi-agent debate monitor framework. By compelling models to ground their claims in visual evidence, this method substantially improves the detectability of deceptive strategies. Experiments show that it consistently increases agreement with human judgements across all tested models, boosting Cohen's kappa by 1.5x and accuracy by 1.25x on GPT-4o.

</details>


### [250] [GreenPlanner: Practical Floorplan Layout Generation via an Energy-Aware and Function-Feasible Generative Framework](https://arxiv.org/abs/2512.00406)
*Pengyu Zeng,Yuqin Dai,Jun Yin,Jing Zhong,Ziyang Han,Chaoyang Shi,ZhanXiang Jin,Maowei Jiang,Yuxing Han,Shuai Lu*

Main category: cs.AI

TL;DR: GreenPlanner是一个结合设计与评估的生成框架，显著提升建筑设计的效率与合规性。


<details>
  <summary>Details</summary>
Motivation: 建筑设计直接影响人类福祉和碳排放，但目前生成符合功能和能源要求的平面图仍依赖人工，成本高且难以扩展。现有方法常因缺乏自动化评估而违反关键约束。

Method: GreenPlanner框架包括设计可行性数据集、快速设计评估器（PDE）、绿色规划数据集（GreenPD）以及基于PDE反馈的生成器GreenFlow。

Result: 实验表明，GreenPlanner将评估速度提高了超过10^5倍，准确率超过99%，消除了无效样本，并将设计效率比专业建筑师提高了87%。

Conclusion: GreenPlanner通过整合设计评估与生成，显著提升了建筑设计的效率与合规性，同时大幅减少了无效设计样本。

Abstract: Building design directly affects human well-being and carbon emissions, yet generating spatial-functional and energy-compliant floorplans remains manual, costly, and non-scalable. Existing methods produce visually plausible layouts but frequently violate key constraints, yielding invalid results due to the absence of automated evaluation. We present GreenPlanner, an energy- and functionality-aware generative framework that unifies design evaluation and generation. It consists of a labeled Design Feasibility Dataset for learning constraint priors; a fast Practical Design Evaluator (PDE) for predicting energy performance and spatial-functional validity; a Green Plan Dataset (GreenPD) derived from PDE-guided filtering to pair user requirements with regulation-compliant layouts; and a GreenFlow generator trained on GreenPD with PDE feedback for controllable, regulation-aware generation. Experiments show that GreenPlanner accelerates evaluation by over $10^{5}\times$ with $>$99% accuracy, eliminates invalid samples, and boosts design efficiency by 87% over professional architects.

</details>


### [251] [Mind the data gap: Missingness Still Shapes Large Language Model Prognoses](https://arxiv.org/abs/2512.00479)
*Yuta Kobayashi,Vincent Jeanselme,Shalmali Joshi*

Main category: cs.AI

TL;DR: 研究发现缺失模式对LLMs的零样本预测性能有显著影响，且不同规模模型受影响不一致，呼吁更透明的缺失表示评估。


<details>
  <summary>Details</summary>
Motivation: 尽管已有大量关于缺失信息性的文献，但其对大型语言模型（LLMs）性能的影响尚未被研究。

Method: 通过一系列实验，使用哥伦比亚大学医学中心和MIMIC-IV的数据，研究缺失模式对零样本预测性能的影响。

Result: 缺失模式显著影响零样本预测性能。明确包含缺失指示符对某些LLMs有益，但对其他LLMs的零样本预测性能和校准有负面影响。较大的模型受益于这些干预，而较小的模型可能受到负面影响。

Conclusion: 需要更透明的记录和系统性评估（信息性）缺失表示对下游性能的影响。

Abstract: Data collection often reflects human decisions. In healthcare, for instance, a referral for a diagnostic test is influenced by the patient's health, their preferences, available resources, and the practitioner's recommendations. Despite the extensive literature on the informativeness of missingness, its implications on the performance of Large Language Models (LLMs) have not been studied. Through a series of experiments on data from Columbia University Medical Center, a large urban academic medical center, and MIMIC-IV, we demonstrate that patterns of missingness significantly impact zero-shot predictive performance. Notably, the explicit inclusion of missingness indicators at prompting benefits some while hurting other LLMs' zero-shot predictive performance and calibration, suggesting an inconsistent impact. The proposed aggregated analysis and theoretical insights suggest that larger models benefit from these interventions, while smaller models can be negatively impacted. The LLM paradigm risks obscuring the impact of missingness, often neglected even in conventional ML, even further. We conclude that there is a need for more transparent accounting and systematic evaluation of the impact of representing (informative) missingness on downstream performance.

</details>


### [252] [Clinical-R1: Empowering Large Language Models for Faithful and Comprehensive Reasoning with Clinical Objective Relative Policy Optimization](https://arxiv.org/abs/2512.00601)
*Boyang Gu,Hongjian Zhou,Bradley Max Segal,Jinge Wu,Zeyu Cao,Hantao Zhong,Lei Clifton,Fenglin Liu,David A. Clifton*

Main category: cs.AI

TL;DR: CRPO是一种新型强化学习方法，通过多目标优化提升临床推理的忠实性和全面性，实验证明其优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 当前的后训练方法（如GRPO）主要奖励正确性，未满足高风险领域（如医学）对推理忠实性和全面性的多维目标需求。

Method: 引入Clinical-Objective Relative Policy Optimization (CRPO)，一种可扩展、多目标、可验证的强化学习方法，结合基于规则和可验证的奖励信号，联合优化准确性、忠实性和全面性。

Result: 实验表明，CRPO在三个基准测试中显著提升了推理的真实性和完整性，同时保持了准确性提升。

Conclusion: CRPO框架为LLM推理与临床目标的对齐提供了可扩展的途径，实现了更安全、更协作的医疗AI系统，并突显了多目标、可验证RL方法在医学领域LLM后训练中的潜力。

Abstract: Recent advances in large language models (LLMs) have shown strong reasoning capabilities through large-scale pretraining and post-training reinforcement learning, demonstrated by DeepSeek-R1. However, current post-training methods, such as Grouped Relative Policy Optimization (GRPO), mainly reward correctness, which is not aligned with the multi-dimensional objectives required in high-stakes fields such as medicine, where reasoning must also be faithful and comprehensive. We introduce Clinical-Objective Relative Policy Optimization (CRPO), a scalable, multi-objective, verifiable reinforcement learning method designed to align LLM post-training with clinical reasoning principles. CRPO integrates rule-based and verifiable reward signals that jointly optimize accuracy, faithfulness, and comprehensiveness without relying on human annotation. To demonstrate its effectiveness, we train Clinical-R1-3B, a 3B-parameter model for clinical reasoning. The experiments on three benchmarks demonstrate that our CRPO substantially improves reasoning on truthfulness and completeness over standard GRPO while maintaining comfortable accuracy enhancements. This framework provides a scalable pathway to align LLM reasoning with clinical objectives, enabling safer and more collaborative AI systems for healthcare while also highlighting the potential of multi-objective, verifiable RL methods in post-training scaling of LLMs for medical domains.

</details>


### [253] [EDIT: Early Diffusion Inference Termination for dLLMs Based on Dynamics of Training Gradients](https://arxiv.org/abs/2512.00670)
*He-Yen Hsieh,Hong Wang,H. T. Kung*

Main category: cs.AI

TL;DR: EDIT是一种自适应停止去噪的推理时间准则，利用训练梯度动态减少扩散步骤，保持准确性，存储开销低。


<details>
  <summary>Details</summary>
Motivation: 扩散基础的大型语言模型（dLLM）通过迭代去噪改进令牌生成，但答案通常在所有步骤完成前稳定。

Method: 提出EDIT，一种推理时间准则，通过监测令牌激活与训练时推理图的对齐情况，自适应地停止去噪过程。

Result: 在推理基准测试中，EDIT减少了11.8%至68.3%的扩散步骤，同时大多数情况下保持或提高了准确性，存储开销约为0.02%。

Conclusion: EDIT（早期扩散推理终止）通过利用训练梯度动态，为减少dLLM推理时间和成本开辟了新的研究方向。

Abstract: Diffusion-based large language models (dLLMs) refine token generations through iterative denoising, but answers often stabilize before all steps complete. We propose EDIT (Early Diffusion Inference Termination), an inference-time criterion that adaptively stops denoising once sufficient reasoning stability relative to training-time reasoning is detected. EDIT monitors the alignment between token activations and a reasoning map derived from AdamW-aggregated LoRA updates captured during supervised fine-tuning (SFT). During training, optimization dynamics generate rich metadata about parameter importance that in prior methods is typically discarded upon model release. We preserve this information as a compact representation of learned reasoning pathways. During inference, alignment scores are converted to a distribution over the tokens already unmasked at the current denoising step, and convergence is detected when KL divergence between consecutive steps falls below a threshold on the matched unmasked (visible) tokens. Across reasoning benchmarks, EDIT reduces diffusion steps by 11.8% to 68.3% while preserving or improving accuracy in most settings, with approximately 0.02% storage overhead (about 1.5-2 MB for all QKV modules across 32 blocks in an 8 GB model). By utilizing training-gradient dynamics, our work opens a new research direction for reducing dLLM inference time and cost.

</details>


### [254] [Model of human cognition](https://arxiv.org/abs/2512.00683)
*Wu Yonggang*

Main category: cs.AI

TL;DR: 论文提出了一种神经理论框架，旨在解决LLMs的可解释性、理论统一和成本问题，并提供了一种高效的计算方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的发展受到可解释性不足、缺乏统一理论和运营成本高昂的限制。

Method: 通过构建一个既功能强大又生物可信的模型，论文探讨了认知过程（如决策和问题解决）的理论见解。

Result: 该模型不仅为认知过程提供了理论见解，还提出了一种计算高效的方法，用于创建可解释且可泛化的人工智能。

Conclusion: 该论文提出了一种神经理论框架，旨在解决大型语言模型在可解释性、统一理论缺乏和运营成本高昂方面的局限性。

Abstract: The development of large language models (LLMs) is limited by a lack of explainability, the absence of a unifying theory, and prohibitive operational costs. We propose a neuro-theoretical framework for the emergence of intelligence in systems that is both functionally robust and biologically plausible. The model provides theoretical insights into cognitive processes such as decision-making and problem solving, and a computationally efficient approach for the creation of explainable and generalizable artificial intelligence.

</details>


### [255] [When Human Preferences Flip: An Instance-Dependent Robust Loss for RLHF](https://arxiv.org/abs/2512.00709)
*Yifan Xu,Xichen Ye,Yifan Chen,Qiaosheng Zhang*

Main category: cs.AI

TL;DR: 本文提出FA-DPO算法，通过实例依赖翻转概率模型解决偏好翻转问题，实验验证其优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 数据集质量对大型语言模型（LLM）对齐至关重要，但人类反馈收集中的偏好翻转问题普遍存在，导致数据标注污染，需要提高对齐算法对潜在翻转对的鲁棒性。

Method: 通过分解人类意图模型和偏好翻转机制为两个独立阶段，引入基于Bradley-Terry模型的实例依赖翻转概率，并利用偏好标注相关特征捕捉判断不确定性和偏好翻转模式。

Result: 实验在多种情况下评估了提出的FA-DPO算法及其他基线方法，验证了实例依赖偏好翻转模型的有效性。

Conclusion: 本文提出了一种针对偏好翻转问题的FA-DPO算法，通过分解人类意图模型和外部因素引入的偏好翻转机制，设计了一个实例依赖的翻转概率模型，并在实验中验证了其有效性。

Abstract: Quality of datasets plays an important role in large language model (LLM) alignment. In collecting human feedback, however, preference flipping is ubiquitous and causes corruption in data annotation; the issue necessitates the alignment algorithms with improved robustness against potential flipped pairs. To this end, this paper introduces a Flipping-Aware Direct Preference Optimization (FA-DPO) algorithm tailored to preference flipping from a reinforcement learning with human feedback (RLHF) perspective. We dissect the inherent human intention model and the preference flipping mechanism introduced by external factors as two distinct stages; in the latter, we introduce an instance-dependent flipping probability on the basis of the Bradley-Terry (BT) model. Further, by leveraging features relevant to preference annotation, we capture uncertainty in judgments and model preference flipping patterns. In practice, we design a simple yet efficient iterative optimization algorithm compatible with the original RLHF and DPO algorithms. In our experiments, we investigate the instance-dependent preference flipping model under multiple circumstances for evaluation of our proposed method, as well as other baseline methods.

</details>


### [256] [SpeContext: Enabling Efficient Long-context Reasoning with Speculative Context Sparsity in LLMs](https://arxiv.org/abs/2512.00722)
*Jiaming Xu,Jiayi Pan,Hanzhen Wang,Yongkang Zhou,Jiancai Ye,Yu Wang,Guohao Dai*

Main category: cs.AI

TL;DR: SpeContext利用DLM设计检索算法，通过轻量级检索头、异步数据流和内存优化，显著提升长上下文推理效率。


<details>
  <summary>Details</summary>
Motivation: 研究发现检索算法与LLM的知识蒸馏目标相似，因此探索了利用DLM作为检索算法的新范式。

Method: 提出了一种基于蒸馏语言模型（DLM）的检索算法SpeContext，包括轻量级检索头设计、异步预取数据流和自适应内存管理系统。

Result: 实验表明，SpeContext在云和边缘环境中分别实现了24.89倍和10.06倍的吞吐量提升，且精度损失可忽略。

Conclusion: SpeContext通过算法、系统和编译层面的协同设计，在云和边缘环境中显著提升了长上下文推理的吞吐量，同时保持了高准确性。

Abstract: In this paper, we point out that the objective of the retrieval algorithms is to align with the LLM, which is similar to the objective of knowledge distillation in LLMs. We analyze the similarity in information focus between the distilled language model(DLM) and the original LLM from the perspective of information theory, and thus propose a novel paradigm that leverages a DLM as the retrieval algorithm. Based on the insight, we present SpeContext, an algorithm and system co-design for long-context reasoning. (1) At the algorithm level, SpeContext proposes lightweight retrieval head based on the head-level attention weights of DLM, achieving > 90% parameters reduction by pruning the redundancy. (2) At the system level, SpeContext designs an asynchronous prefetch dataflow via the elastic loading strategy, effectively overlapping KV cache retrieval with the LLM computation. (3) At the compilation level, SpeContext constructs the theoretical memory model and implements an adaptive memory management system to achieve acceleration by maximizing GPU memory utilization. We deploy and evaluate SpeContext in two resourceconstrained environments, cloud and edge. Extensive experiments show that, compared with the Huggingface framework, SpeContext achieves up to 24.89x throughput improvement in cloud and 10.06x speedup in edge with negligible accuracy loss, pushing the Pareto frontier of accuracy and throughput.

</details>


### [257] [Probing the "Psyche'' of Large Reasoning Models: Understanding Through a Human Lens](https://arxiv.org/abs/2512.00729)
*Yuxiang Chen,Zuohan Wu,Ziwei Wang,Xiangning Yu,Xujia Li,Linyi Yang,Mengyue Yang,Jun Wang,Lei Chen*

Main category: cs.AI

TL;DR: 本文提出了一种基于人类心理过程的LRMs分类法，创建了大规模标注数据集，并开发了自动标注工具CAPO，揭示了当前LRMs自我监控的局限性，提出了改进方向。


<details>
  <summary>Details</summary>
Motivation: 受LRMs在推理过程中表现出类人行为的启发，旨在从跨学科视角理解LRMs的“心理”。

Method: 通过构建包含五组十七类的人类心理过程分类法，创建了包含277,534个原子推理步骤的标注数据集，并开发了自动标注框架CAPO。

Result: 分析发现当前LRMs的自我监控评估（如“双重检查”）多为表面行为，实质性修订罕见，建议激励多步反思。CAPO在标注一致性上优于基线方法。

Conclusion: 本文提出的分类法、CAPO自动标注框架及分析结果为理解和提升大型推理模型（LRMs）提供了一条原则性、可扩展的路径。

Abstract: Large reasoning models (LRMs) have garnered significant attention from researchers owing to their exceptional capability in addressing complex tasks. Motivated by the observed human-like behaviors in their reasoning processes, this paper introduces a comprehensive taxonomy to characterize atomic reasoning steps and probe the ``psyche'' of LRM intelligence. Specifically, it comprises five groups and seventeen categories derived from human mental processes, thereby grounding the understanding of LRMs in an interdisciplinary perspective. The taxonomy is then applied for an in-depth understanding of current LRMs, resulting in a distinct labeled dataset that comprises 277,534 atomic reasoning steps. Using this resource, we analyze contemporary LRMs and distill several actionable takeaways for improving training and post-training of reasoning models. Notably, our analysis reveals that prevailing post-answer ``double-checks'' (self-monitoring evaluations) are largely superficial and rarely yield substantive revisions. Thus, incentivizing comprehensive multi-step reflection, rather than simple self-monitoring, may offer a more effective path forward. To complement the taxonomy, an automatic annotation framework, named CAPO, is proposed to leverage large language models (LLMs) for generating the taxonomy-based annotations. Experimental results demonstrate that CAPO achieves higher consistency with human experts compared to baselines, facilitating a scalable and comprehensive analysis of LRMs from a human cognitive perspective. Together, the taxonomy, CAPO, and the derived insights provide a principled, scalable path toward understanding and advancing LRM reasoning.

</details>


### [258] [MPR-GUI: Benchmarking and Enhancing Multilingual Perception and Reasoning in GUI Agents](https://arxiv.org/abs/2512.00756)
*Ruihan Chen,Qiming Li,Xiaocheng Feng,Xiaoliang Yang,Weihong Zhong,Yuxuan Gu,Zekun Zhou,Bing Qin*

Main category: cs.AI

TL;DR: 提出MPR-GUI-Bench评估多语言GUI代理性能，发现非英语表现较差，通过GUI-XLI方法平均提升6.5%。


<details>
  <summary>Details</summary>
Motivation: 现有大型视觉语言模型在英语GUI任务中表现优异，但在多语言环境下性能未受关注且缺乏细粒度分析。

Method: 提出了GUI-XLI，一种通过干预P&R相关层隐藏状态来缩小英语与其他语言差距的方法。

Result: LVLMs在非英语语言中的P&R性能显著低于英语，GUI-XLI方法平均提升6.5%。

Conclusion: GUI-XLI方法有效提升了GUI代理在多语言环境下的感知与推理能力，平均提升6.5%。

Abstract: With the advancement of computational resources, Large Vision-Language Models (LVLMs) exhibit impressive Perception and Reasoning (P&R) performance on Graphical User Interface (GUI) tasks. However, although they demonstrate strong P&R capabilities in English GUI scenarios, their performance in multilingual settings has received little attention, which limits their global applications. Moreover, existing studies on GUI tasks lack fine-grained analyses, including widget functions and elements' spatial relationships, which are fundamental for more targeted improvements. To tackle these issues, we propose MPR-GUI-Bench, a Multilingual fine-grained Perception and Reasoning GUI Benchmark to evaluate GUI agents' P&R capabilities. Evaluation results demonstrate that LVLMs exhibit significantly worse P&R performance in non-English languages than in English. To address these gaps, we propose GUI-XLI, a GUI Cross-Lingual Intervention method that applies interventions to the hidden states at P&R capability-related layers to mitigate the gaps between English and other languages, building on previous research showing that the hidden states of different language inputs exhibit significant differences in the latent space. Experimental results indicate that our method improves GUI agents' multilingual P&R capability by 6.5% on average.

</details>


### [259] [BioPro: On Difference-Aware Gender Fairness for Vision-Language Models](https://arxiv.org/abs/2512.00807)
*Yujie Lin,Jiayao Ma,Qingguo Hu,Derek F. Wong,Jinsong Su*

Main category: cs.AI

TL;DR: BioPro 是一种无需训练的选择性去偏框架，通过投影技术减少中性上下文中的性别偏见，同时保留明确上下文中的性别信息，适用于视觉语言模型。


<details>
  <summary>Details</summary>
Motivation: 现有公平性干预常采用差异无视视角，无法区分需要中性的上下文和需要保留群体特定属性的上下文。本文旨在将差异感知公平性扩展到多模态领域，并解决图像描述和文本到图像生成中的性别公平性问题。

Method: 提出了 BioPro（Bias Orthogonal Projection），一种完全无需训练的框架，通过反事实嵌入识别低维性别变化子空间，并应用投影选择性中和性别相关信息。

Result: 实验表明，BioPro 能有效减少中性案例中的性别偏见，同时在明确案例中保持性别忠实性。

Conclusion: BioPro 提供了一种有前景的方向，通过选择性去偏来实现视觉语言模型中的选择性公平，不仅适用于性别偏见，还能推广到连续偏见变量如场景亮度。

Abstract: Vision-Language Models (VLMs) inherit significant social biases from their training data, notably in gender representation. Current fairness interventions often adopt a difference-unaware perspective that enforces uniform treatment across demographic groups. These approaches, however, fail to distinguish between contexts where neutrality is required and those where group-specific attributes are legitimate and must be preserved. Building upon recent advances in difference-aware fairness for text-only models, we extend this concept to the multimodal domain and formalize the problem of difference-aware gender fairness for image captioning and text-to-image generation. We advocate for selective debiasing, which aims to mitigate unwanted bias in neutral contexts while preserving valid distinctions in explicit ones. To achieve this, we propose BioPro (Bias Orthogonal Projection), an entirely training-free framework. BioPro identifies a low-dimensional gender-variation subspace through counterfactual embeddings and applies projection to selectively neutralize gender-related information. Experiments show that BioPro effectively reduces gender bias in neutral cases while maintaining gender faithfulness in explicit ones, thus providing a promising direction toward achieving selective fairness in VLMs. Beyond gender bias, we further demonstrate that BioPro can effectively generalize to continuous bias variables, such as scene brightness, highlighting its broader applicability.

</details>


### [260] [Med-CMR: A Fine-Grained Benchmark Integrating Visual Evidence and Clinical Logic for Medical Complex Multimodal Reasoning](https://arxiv.org/abs/2512.00818)
*Haozhen Gong,Xiaozhong Ji,Yuansen Liu,Wenbin Wu,Xiaoxiao Yan,Jingjing Liu,Kai Wu,Jiazhen Pan,Bailiang Jian,Jiangning Zhang,Xiaobin Hu,Hongwei Bran Li*

Main category: cs.AI

TL;DR: Med-CMR是一个细粒度医学多模态推理基准，通过系统性任务设计和高质量数据评估MLLMs的医学推理能力，发现GPT-5表现最佳，但专业模型未显著优于通用模型。


<details>
  <summary>Details</summary>
Motivation: 评估MLLMs在复杂医学推理中的能力，填补现有基准在细粒度评估和临床真实性方面的不足。

Method: 通过系统性能力分解（细粒度视觉理解和多步推理）和具有挑战性的任务设计（涵盖视觉理解的三个维度和四种临床相关推理场景），构建了包含20,653个VQA对的高质量数据集。

Result: GPT-5在多项选择题和开放式问题中表现最佳，但专业医学MLLMs并未显著优于通用模型，且长尾泛化是主要失败模式。

Conclusion: Med-CMR提供了一个严格的基准，用于评估医学MLLMs在视觉推理整合和罕见病例鲁棒性方面的表现，并为未来临床系统的发展提供了参考。

Abstract: MLLMs MLLMs are beginning to appear in clinical workflows, but their ability to perform complex medical reasoning remains unclear. We present Med-CMR, a fine-grained Medical Complex Multimodal Reasoning benchmark. Med-CMR distinguishes from existing counterparts by three core features: 1) Systematic capability decomposition, splitting medical multimodal reasoning into fine-grained visual understanding and multi-step reasoning to enable targeted evaluation; 2) Challenging task design, with visual understanding across three key dimensions (small-object detection, fine-detail discrimination, spatial understanding) and reasoning covering four clinically relevant scenarios (temporal prediction, causal reasoning, long-tail generalization, multi-source integration); 3) Broad, high-quality data coverage, comprising 20,653 Visual Question Answering (VQA) pairs spanning 11 organ systems and 12 imaging modalities, validated via a rigorous two-stage (human expert + model-assisted) review to ensure clinical authenticity. We evaluate 18 state-of-the-art MLLMs with Med-CMR, revealing GPT-5 as the top-performing commercial model: 57.81 accuracy on multiple-choice questions (MCQs) and a 48.70 open-ended score, outperforming Gemini 2.5 Pro (49.87 MCQ accuracy, 45.98 open-ended score) and leading open-source model Qwen3-VL-235B-A22B (49.34 MCQ accuracy, 42.62 open-ended score). However, specialized medical MLLMs do not reliably outperform strong general models, and long-tail generalization emerges as the dominant failure mode. Med-CMR thus provides a stress test for visual-reasoning integration and rare-case robustness in medical MLLMs, and a rigorous yardstick for future clinical systems.

</details>


### [261] [SemAgent: Semantic-Driven Agentic AI Empowered Trajectory Prediction in Vehicular Networks](https://arxiv.org/abs/2512.00834)
*Lin Zhu,Kezhi Wang,Luping Xiang,Kun Yang*

Main category: cs.AI

TL;DR: 结合语义通信与Agentic AI的轨迹预测框架，显著提升V2X网络中的预测性能，尤其在低信噪比条件下表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决传统通信方案的高传输开销与延迟问题，以及现有轨迹预测模型缺乏环境感知与逻辑推理能力的不足。

Method: 通过RSU中的特征提取代理和语义分析代理进行紧凑表示和语义推理，结合V2V通信中的局部特征提取与语义分析，实现轨迹预测。

Result: 在多样化通信条件下的实验表明，该方法比基线方案显著提升，低信噪比条件下预测准确率提高47.5%。

Conclusion: 该论文提出的结合语义通信与Agentic AI的轨迹预测框架，在V2X网络中显著提升了预测性能，尤其在低信噪比条件下表现优异。

Abstract: Efficient information exchange and reliable contextual reasoning are essential for vehicle-to-everything (V2X) networks. Conventional communication schemes often incur significant transmission overhead and latency, while existing trajectory prediction models generally lack environmental perception and logical inference capabilities. This paper presents a trajectory prediction framework that integrates semantic communication with Agentic AI to enhance predictive performance in vehicular environments. In vehicle-to-infrastructure (V2I) communication, a feature-extraction agent at the Roadside Unit (RSU) derives compact representations from historical vehicle trajectories, followed by semantic reasoning performed by a semantic-analysis agent. The RSU then transmits both feature representations and semantic insights to the target vehicle via semantic communication, enabling the vehicle to predict future trajectories by combining received semantics with its own historical data. In vehicle-to-vehicle (V2V) communication, each vehicle performs local feature extraction and semantic analysis while receiving predicted trajectories from neighboring vehicles, and jointly utilizes this information for its own trajectory prediction. Extensive experiments across diverse communication conditions demonstrate that the proposed method significantly outperforms baseline schemes, achieving up to a 47.5% improvement in prediction accuracy under low signal-to-noise ratio (SNR) conditions.

</details>


### [262] [Assessing model error in counterfactual worlds](https://arxiv.org/abs/2512.00836)
*Emily Howerton,Justin Lessler*

Main category: cs.AI

TL;DR: 论文探讨了反事实情景建模中模型误差的估计方法，提出了三种方法并通过模拟实验验证，最终给出了评估建议和情景设计要素。


<details>
  <summary>Details</summary>
Motivation: 尽管情景建模在规划和决策中无处不在，但情景预测很少被回顾性评估。模型误差在反事实世界中的估计对于评估模型在决策中的价值至关重要。

Method: 提出了三种估计反事实错误的方法，并通过模拟实验展示了每种方法的优缺点。

Result: 研究展示了三种方法的优势和局限性，并提供了估计反事实错误的建议。

Conclusion: 论文建议了评估反事实错误的方法，并讨论了使情景预测可评估所需的情景设计要素。

Abstract: Counterfactual scenario modeling exercises that ask "what would happen if?" are one of the most common ways we plan for the future. Despite their ubiquity in planning and decision making, scenario projections are rarely evaluated retrospectively. Differences between projections and observations come from two sources: scenario deviation and model miscalibration. We argue the latter is most important for assessing the value of models in decision making, but requires estimating model error in counterfactual worlds. Here we present and contrast three approaches for estimating this error, and demonstrate the benefits and limitations of each in a simulation experiment. We provide recommendations for the estimation of counterfactual error and discuss the components of scenario design that are required to make scenario projections evaluable.

</details>


### [263] [ARCADIA: Scalable Causal Discovery for Corporate Bankruptcy Analysis Using Agentic AI](https://arxiv.org/abs/2512.00839)
*Fabrizio Maturo,Donato Riccio,Andrea Mazzitelli,Giuseppe Bifulco,Francesco Paolone,Iulia Brezeanu*

Main category: cs.AI

TL;DR: ARCADIA是一个结合LLM与统计诊断的因果发现框架，通过迭代优化生成可靠且可解释的因果图，实验证明其优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统因果发现算法在高风险领域可能缺乏可靠性和可解释性，ARCADIA旨在解决这一问题，通过AI代理参与自主科学建模。

Method: ARCADIA通过约束引导提示和因果有效性反馈迭代优化候选DAG，与传统算法不同，它提供了稳定且可解释的模型。

Result: 在企业破产数据上的实验表明，ARCADIA生成的因果图比NOTEARS、GOLEM和DirectLiNGAM更可靠，并提供完全可解释、可干预的流程。

Conclusion: ARCADIA框架通过结合大型语言模型推理与统计诊断，构建了有效且时间一致的因果结构，为高风险领域的自主科学建模和结构化因果推理提供了新方向。

Abstract: This paper introduces ARCADIA, an agentic AI framework for causal discovery that integrates large-language-model reasoning with statistical diagnostics to construct valid, temporally coherent causal structures. Unlike traditional algorithms, ARCADIA iteratively refines candidate DAGs through constraint-guided prompting and causal-validity feedback, leading to stable and interpretable models for real-world high-stakes domains. Experiments on corporate bankruptcy data show that ARCADIA produces more reliable causal graphs than NOTEARS, GOLEM, and DirectLiNGAM while offering a fully explainable, intervention-ready pipeline. The framework advances AI by demonstrating how agentic LLMs can participate in autonomous scientific modeling and structured causal inference.

</details>


### [264] [One Swallow Does Not Make a Summer: Understanding Semantic Structures in Embedding Spaces](https://arxiv.org/abs/2512.00852)
*Yandong Sun,Qiang Huang,Ziwei Xu,Yiqun Sun,Yixuan Tang,Anthony K. H. Tung*

Main category: cs.AI

TL;DR: 论文提出SFS和SAFARI算法，通过几何保持和上下文感知的表示提升嵌入空间的语义理解，实验证明其在分类和语义结构揭示上的优越性。


<details>
  <summary>Details</summary>
Motivation: 解决现有嵌入空间内部结构不透明、语义连贯性差或计算开销高的问题，以提升语义理解的效率和可解释性。

Method: 引入了语义场子空间（SFS）和SAFARI算法，利用语义偏移度量来揭示层次化的语义结构，并通过高效的近似方法提升计算效率。

Result: 在六个真实世界的数据集上验证，SFS在分类和政治偏见检测等任务中优于标准分类器，SAFARI能够揭示可解释且通用的语义层次结构。

Conclusion: 该论文提出了一个统一的框架，用于在嵌入空间中构建、分析和扩展语义理解，通过SFS和SAFARI算法显著提升了语义结构的可解释性和通用性。

Abstract: Embedding spaces are fundamental to modern AI, translating raw data into high-dimensional vectors that encode rich semantic relationships. Yet, their internal structures remain opaque, with existing approaches often sacrificing semantic coherence for structural regularity or incurring high computational overhead to improve interpretability. To address these challenges, we introduce the Semantic Field Subspace (SFS), a geometry-preserving, context-aware representation that captures local semantic neighborhoods within the embedding space. We also propose SAFARI (SemAntic Field subspAce deteRmInation), an unsupervised, modality-agnostic algorithm that uncovers hierarchical semantic structures using a novel metric called Semantic Shift, which quantifies how semantics evolve as SFSes evolve. To ensure scalability, we develop an efficient approximation of Semantic Shift that replaces costly SVD computations, achieving a 15~30x speedup with average errors below 0.01. Extensive evaluations across six real-world text and image datasets show that SFSes outperform standard classifiers not only in classification but also in nuanced tasks such as political bias detection, while SAFARI consistently reveals interpretable and generalizable semantic hierarchies. This work presents a unified framework for structuring, analyzing, and scaling semantic understanding in embedding spaces.

</details>


### [265] [Hybrid-DMKG: A Hybrid Reasoning Framework over Dynamic Multimodal Knowledge Graphs for Multimodal Multihop QA with Knowledge Editing](https://arxiv.org/abs/2512.00881)
*Li Yuan,Qingfei Huang,Bingshan Zhu,Yi Cai,Qingbao Huang,Changmeng Zheng,Zikun Deng,Tao Wang*

Main category: cs.AI

TL;DR: MMQAKE是首个多模态多跳问答知识编辑基准，Hybrid-DMKG通过动态知识图谱和混合推理显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有MKE基准主要关注最终答案正确性，忽视了中间推理质量和视觉重述输入的鲁棒性，因此需要新的评估框架和方法。

Method: 提出了Hybrid-DMKG框架，结合大型语言模型分解问题、多模态检索模型定位更新事实，并通过关系链接预测和RAG推理两条路径进行混合推理。

Result: 实验表明Hybrid-DMKG在MMQAKE基准上显著优于现有方法，准确率和鲁棒性均有提升。

Conclusion: Hybrid-DMKG框架通过动态多模态知识图谱和混合推理模块显著提升了多模态知识编辑的性能，尤其在多跳推理和视觉重述输入的鲁棒性方面表现优异。

Abstract: Multimodal Knowledge Editing (MKE) extends traditional knowledge editing to settings involving both textual and visual modalities. However, existing MKE benchmarks primarily assess final answer correctness while neglecting the quality of intermediate reasoning and robustness to visually rephrased inputs. To address this limitation, we introduce MMQAKE, the first benchmark for multimodal multihop question answering with knowledge editing. MMQAKE evaluates (1) a model's ability to reason over 2-5-hop factual chains that span both text and images, including performance at each intermediate step, and (2) robustness to visually rephrased inputs in multihop questions. Our evaluation shows that current MKE methods often struggle to consistently update and reason over multimodal reasoning chains after knowledge edits. To overcome these challenges, we propose Hybrid-DMKG, a hybrid reasoning framework built on a dynamic multimodal knowledge graph (DMKG) to enable accurate multihop reasoning over updated multimodal knowledge. Hybrid-DMKG first uses a large language model to decompose multimodal multihop questions into sequential sub-questions, then applies a multimodal retrieval model to locate updated facts by jointly encoding each sub-question with candidate entities and their associated images. For answer inference, a hybrid reasoning module operates over the DMKG via two parallel paths: (1) relation linking prediction, and (2) RAG reasoning with large vision-language models. A decision module aggregates evidence from both paths to select the most credible answer. Experimental results on MMQAKE show that Hybrid-DMKG significantly outperforms existing MKE approaches, achieving higher accuracy and improved robustness to knowledge updates.

</details>


### [266] [Minimal neuron ablation triggers catastrophic collapse in the language core of Large Vision-Language Models](https://arxiv.org/abs/2512.00918)
*Cen Lu,Yung-Chen Tang,Andrea Cavallaro*

Main category: cs.AI

TL;DR: 研究揭示了大型视觉语言模型的结构脆弱性，提出CAN方法定位关键神经元，实验证明极少数神经元被掩码即可导致崩溃，为安全性研究提供新见解。


<details>
  <summary>Details</summary>
Motivation: 尽管大型视觉语言模型展现出强大的多模态理解能力，但其鲁棒性尚未被充分理解，研究旨在揭示其结构脆弱性。

Method: 提出CAN方法，通过逐步掩码检测持续激活神经元并定位关键神经元。

Result: 实验发现仅需掩码语言模型中极小部分前馈网络神经元（极端情况下仅四个）即可引发灾难性崩溃，且关键神经元主要集中在语言模型而非视觉组件中。

Conclusion: 研究发现为大型视觉语言模型（LVLMs）的安全性研究提供了重要见解，揭示了其结构脆弱性及关键神经元的作用。

Abstract: Large Vision-Language Models (LVLMs) have shown impressive multimodal understanding capabilities, yet their robustness is poorly understood. In this paper, we investigate the structural vulnerabilities of LVLMs to identify any critical neurons whose removal triggers catastrophic collapse. In this context, we propose CAN, a method to detect Consistently Activated Neurons and to locate critical neurons by progressive masking. Experiments on LLaVA-1.5-7b-hf and InstructBLIP-Vicuna-7b reveal that masking only a tiny portion of the language model's feed-forward networks (just as few as four neurons in extreme cases) suffices to trigger catastrophic collapse. Notably, critical neurons are predominantly localized in the language model rather than in the vision components, and the down-projection layer is a particularly vulnerable structure. We also observe a consistent two-stage collapse pattern: initial expressive degradation followed by sudden, complete collapse. Our findings provide important insights for safety research in LVLMs.

</details>


### [267] [Integrating Causal Foundation Model in Prescriptive Maintenance Framework for Optimizing Production Line OEE](https://arxiv.org/abs/2512.00969)
*Felix Saretzky,Lucas Andersen,Thomas Engel,Fazel Ansari*

Main category: cs.AI

TL;DR: 本文提出了一种因果机器学习模型，用于制造业的预测性维护，通过模拟修复方案优化KPI，减少停机时间。


<details>
  <summary>Details</summary>
Motivation: 当前制造业向预测性维护的转变受限于对预测模型的依赖，这些模型往往基于虚假相关性而非真正的故障因果驱动因素，导致误诊和无效干预。

Method: 使用预训练的因果基础模型作为“假设”模型，估计潜在修复方案的效果，并通过测量每种干预对系统级KPI的因果效应，提供数据驱动的行动推荐。

Result: 模型在半合成制造数据上进行了评估，并与基线机器学习模型进行了比较，展示了其在识别根本原因和量化其操作影响方面的有效性。

Conclusion: 本文提出了一个基于因果机器学习的模型，旨在通过模拟和评估潜在修复方案来优化关键绩效指标（如OEE），为工程师提供一个稳健的预测性维护框架，从而减少昂贵的停机时间。

Abstract: The transition to prescriptive maintenance in manufacturing is critically constrained by a dependence on predictive models. These models tend to rely on spurious correlations rather than identifying the true causal drivers of failures, often leading to costly misdiagnoses and ineffective interventions. This fundamental limitation results in a key-challenge: while we can predict that a failure may occur, we lack a systematic method to understand why a failure occurs, thereby providing the basis for identifying the most effective intervention. This paper proposes a model based on causal machine learning to bridge this gap. Our objective is to move beyond diagnosis to active prescription by simulating and evaluating potential fixes toward optimizing KPIs such as Overall Equipment Effectiveness (OEE). For this purpose a pre-trained causal foundation model is used as a "what-if" model to estimate the effects of potential fixes. By measuring the causal effect of each intervention on system-level KPIs, it provides a data-driven ranking of actions to recommend at the production line. This process not only identifies root causes but also quantifies their operational impact. The model is evaluated using semi-synthetic manufacturing data and compared with a baseline machine learning model. This paper sets the technical basis for a robust prescriptive maintenance framework, allowing engineers to test potential solutions in a causal environment to make more effective operational decisions and reduce costly downtimes.

</details>


### [268] [IndiMathBench: Autoformalizing Mathematical Reasoning Problems with a Human Touch](https://arxiv.org/abs/2512.00997)
*Param Biyani,Shashank Kirtania,Yasharth Bajpai,Sumit Gulwani,Ashish Tiwari*

Main category: cs.AI

TL;DR: IndiMathBench是一个由AI辅助人工流程创建的数学定理证明基准，包含312个Lean 4定理，评估显示自动形式化仍具挑战性。


<details>
  <summary>Details</summary>
Motivation: 为了评估数学定理证明能力，创建了一个基于印度数学奥林匹克竞赛问题的人类验证基准。

Method: 通过类别检索、迭代编译器反馈和多模型集成，利用AI辅助人工流程生成候选形式化，并由专家通过交互式仪表板验证。

Result: 评估显示，即使经过迭代优化，定理证明的成功率仍然较低，自动形式化在语义正确性方面存在挑战。

Conclusion: IndiMathBench是一个具有挑战性的数学定理证明测试平台，展示了自动形式化与语义正确性之间的显著差距。

Abstract: We introduce IndiMathBench, a human-verified benchmark designed to evaluate mathematical theorem proving, curated using an AI-powered human-assisted pipeline for formalizing natural language problems in Lean. IndiMathBench is composed of 312 formal Lean 4 theorems paired with their corresponding informal problem statements, sourced from Indian Mathematics Olympiads. Through category-based retrieval, iterative compiler feedback, and multi-model ensembles, our pipeline generates candidate formalizations that experts efficiently validate via an interactive dashboard with automated quality summaries. Evaluation across multiple frontier models demonstrates that autoformalization remains challenging, with substantial gaps between syntactic validity and semantic correctness, while theorem proving success rates remain low even with iterative refinement, demonstrating that \benchmark~presents a challenging testbed for mathematical reasoning. IndiMathBench is available at https://github.com/prmbiy/IndiMathBench.

</details>


### [269] [ChartAnchor: Chart Grounding with Structural-Semantic Fidelity](https://arxiv.org/abs/2512.01017)
*Xinhang Li,Jingbo Zhou,Pengfei Luo,Yixiong Xiao,Tong Xu*

Main category: cs.AI

TL;DR: ChartAnchor是一个全面的图表理解基准，通过多样化的图表类型和多层次评估框架，揭示了MLLMs在数值精度和代码合成方面的不足，为结构化推理提供了新方向。


<details>
  <summary>Details</summary>
Motivation: 现有基准受限于图表多样性不足、任务孤立和评估框架不完整，无法全面评估图表基础。

Method: 提出了ChartAnchor基准，包含8k+图表-表格-代码三元组，涵盖30种图表类型，并引入了两个互补任务：图表到代码生成和受控图表到表格重建。

Result: 在MLLMs上的广泛实验揭示了数值精度和代码合成的关键限制，强调了超越表面感知的结构化推理需求。

Conclusion: ChartAnchor通过统一的符号和数据驱动基础，为图表理解建立了严格的基础，为在科学、金融和工业领域推进MLLMs提供了有意义的见解。

Abstract: Recent advances in multimodal large language models (MLLMs) highlight the need for benchmarks that rigorously evaluate structured chart comprehension.Chart grounding refers to the bidirectional alignment between a chart's visual appearance and the structured semantics. This task requires models to produce a symbolic specification that faithfully captures the chart's visual and structural intent, while also recovering the underlying tabular data with precise values and relationships. Chart grounding directly reflects a model's capabilities in numerical reasoning, multimodal alignment, and structural reconstruction, and has several important applications in real-world scenarios.Existing benchmarks, constrained by narrow chart diversity, isolated tasks, and incomplete evaluation frameworks, fail to holistically assess grounding. To address this, we propose ChartAnchor, a comprehensive benchmark of 8k+ chart-table-code triples spanning 30 chart types drawn from diverse real-world and augmented sources. ChartAnchor introduces two complementary tasks: chart-to-code generation (synthesizing executable code to replicate charts) and controlled chart-to-table reconstruction (extracting exact data with predefined headers), enabling cross-validation of visual and numerical fidelity. A multi-level evaluation framework integrates semantic validation, stylistic analysis, and perceptual metrics to assess both structural and content-level correctness. Extensive experiments on MLLMs reveal critical limitations in numerical precision and code synthesis, emphasizing the need for structured reasoning beyond surface-level perception. By unifying symbolic and data-driven grounding, ChartAnchor establishes a rigorous foundation for chart grounding, offering meaningful insights for advancing MLLMs in scientific, financial, and industrial domains.

</details>


### [270] [Evaluating Legal Reasoning Traces with Legal Issue Tree Rubrics](https://arxiv.org/abs/2512.01020)
*Jinu Lee,Kyoung-Woon On,Simeng Han,Arman Cohan,Julia Hockenmaier*

Main category: cs.AI

TL;DR: LEGIT数据集通过层次树结构评估LLM法律推理痕迹，发现RAG和RL互补提升推理能力。


<details>
  <summary>Details</summary>
Motivation: 评估LLM在专家领域（如法律）生成的推理痕迹质量，以确保其可信度和可解释性，但由于此类推理任务的复杂性，这一评估仍具挑战性。

Method: 通过将法院判决转换为对立双方论点及法院结论的层次树结构，创建了LEGIT数据集（24K实例），并利用专家标注验证了其可靠性。

Result: 研究表明，RAG提升了整体推理能力，而RL提高了正确性但降低了覆盖范围。

Conclusion: LLMs在法律推理能力上受到法律问题覆盖范围和正确性的显著影响，而检索增强生成（RAG）和基于规则的强化学习（RL）可以互补地提升这一能力。

Abstract: Evaluating the quality of LLM-generated reasoning traces in expert domains (e.g., law) is essential for ensuring credibility and explainability, yet remains challenging due to the inherent complexity of such reasoning tasks. We introduce LEGIT (LEGal Issue Trees), a novel large-scale (24K instances) expert-level legal reasoning dataset with an emphasis on reasoning trace evaluation. We convert court judgments into hierarchical trees of opposing parties' arguments and the court's conclusions, which serve as rubrics for evaluating the issue coverage and correctness of the reasoning traces. We verify the reliability of these rubrics via human expert annotations and comparison with coarse, less informative rubrics. Using the LEGIT dataset, we show that (1) LLMs' legal reasoning ability is seriously affected by both legal issue coverage and correctness, and that (2) retrieval-augmented generation (RAG) and RL with rubrics bring complementary benefits for legal reasoning abilities, where RAG improves overall reasoning capability, whereas RL improves correctness albeit with reduced coverage.

</details>


### [271] [Med-CRAFT: Automated Construction of Interpretable and Multi-Hop Video Workloads via Knowledge Graph Traversal](https://arxiv.org/abs/2512.01045)
*Shenxi Liu,Kan Li,Mingyang Zhao,Yuhang Tian,Shoujun Zhou,Bin Li*

Main category: cs.AI

TL;DR: Med-CRAFT框架通过神经符号方法自动化生成高质量医学视频基准，解决了数据集稀缺问题，并验证了其逻辑可解释性。


<details>
  <summary>Details</summary>
Motivation: 高质量、逻辑标注的医学视频数据集稀缺，传统手动标注成本高且不可扩展，现有合成方法存在随机幻觉和逻辑解释性不足的问题。

Method: Med-CRAFT采用确定性图遍历过程，从原始视频流中提取结构化视觉基元，并将其实例化为动态时空知识图，通过锚定查询生成有效路径，确保每个合成基准项的严格思维链来源。

Result: 生成的M3-Med-Auto基准在复杂性上与专家策划的数据集相当，逻辑对齐分析显示图拓扑与先进MLLM的推理步骤高度相关，验证了系统将可验证逻辑编码到视觉语言基准中的能力。

Conclusion: 该研究通过引入神经符号数据工程框架Med-CRAFT，成功解决了高质量医学视频数据集稀缺的问题，为关键领域提供了可扩展、低成本的评估协议构建方法。

Abstract: The scarcity of high-quality, logically annotated video datasets remains a primary bottleneck in advancing Multi-Modal Large Language Models (MLLMs) for the medical domain. Traditional manual annotation is prohibitively expensive and non-scalable, while existing synthetic methods often suffer from stochastic hallucinations and a lack of logical interpretability. To address these challenges, we introduce \textbf{\PipelineName}, a novel neuro-symbolic data engineering framework that formalizes benchmark synthesis as a deterministic graph traversal process. Unlike black-box generative approaches, Med-CRAFT extracts structured visual primitives (e.g., surgical instruments, anatomical boundaries) from raw video streams and instantiates them into a dynamic Spatiotemporal Knowledge Graph. By anchoring query generation to valid paths within this graph, we enforce a rigorous Chain-of-Thought (CoT) provenance for every synthesized benchmark item. We instantiate this pipeline to produce M3-Med-Auto, a large-scale medical video reasoning benchmark exhibiting fine-grained temporal selectivity and multi-hop logical complexity. Comprehensive evaluations demonstrate that our automated pipeline generates query workloads with complexity comparable to expert-curated datasets. Furthermore, a logic alignment analysis reveals a high correlation between the prescribed graph topology and the reasoning steps of state-of-the-art MLLMs, validating the system's capability to encode verifiable logic into visual-linguistic benchmarks. This work paves the way for scalable, low-cost construction of robust evaluation protocols in critical domains.

</details>


### [272] [Shielded Controller Units for RL with Operational Constraints Applied to Remote Microgrids](https://arxiv.org/abs/2512.01046)
*Hadi Nekoei,Alexandre Blondin Massé,Rachid Hassani,Sarath Chandar,Vincent Mai*

Main category: cs.AI

TL;DR: SCUs通过层次化约束管理，使RL代理在微电网优化中燃料消耗减少24%且不增加电池退化，满足所有操作约束。


<details>
  <summary>Details</summary>
Motivation: 能源转型中，远程微电网等复杂系统需在不确定性和严格约束下优化决策，RL框架虽强大但需提供可解释的约束满足保证。

Method: 引入SCUs，通过将环境分解为层次结构，每个SCU明确管理一部分约束，确保RL代理在严格操作要求下满足所有约束。

Result: 配备SCUs的RL代理在远程微电网优化任务中，燃料消耗减少24%，且不增加电池退化，优于其他基线方法。

Conclusion: Shielded Controller Units (SCUs) 提供了一种系统且可解释的方法，利用系统动态的先验知识确保约束满足，为RL在能源转型相关决策挑战中的安全应用做出了贡献。

Abstract: Reinforcement learning (RL) is a powerful framework for optimizing decision-making in complex systems under uncertainty, an essential challenge in real-world settings, particularly in the context of the energy transition. A representative example is remote microgrids that supply power to communities disconnected from the main grid. Enabling the energy transition in such systems requires coordinated control of renewable sources like wind turbines, alongside fuel generators and batteries, to meet demand while minimizing fuel consumption and battery degradation under exogenous and intermittent load and wind conditions. These systems must often conform to extensive regulations and complex operational constraints. To ensure that RL agents respect these constraints, it is crucial to provide interpretable guarantees. In this paper, we introduce Shielded Controller Units (SCUs), a systematic and interpretable approach that leverages prior knowledge of system dynamics to ensure constraint satisfaction. Our shield synthesis methodology, designed for real-world deployment, decomposes the environment into a hierarchical structure where each SCU explicitly manages a subset of constraints. We demonstrate the effectiveness of SCUs on a remote microgrid optimization task with strict operational requirements. The RL agent, equipped with SCUs, achieves a 24% reduction in fuel consumption without increasing battery degradation, outperforming other baselines while satisfying all constraints. We hope SCUs contribute to the safe application of RL to the many decision-making challenges linked to the energy transition.

</details>


### [273] [Automating the Refinement of Reinforcement Learning Specifications](https://arxiv.org/abs/2512.01047)
*Tanmay Ambadkar,Đorđe Žikelić,Abhinav Verma*

Main category: cs.AI

TL;DR: AutoSpec通过细化逻辑规范，提升强化学习在复杂任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 当任务定义不明确时，逻辑规范可能无法有效指导强化学习算法学习有用的策略。

Method: 提出了AutoSpec框架，包含四种细化程序，用于修改SpectRL规范逻辑中的抽象图结构，保持规范的正确性。

Result: 实验证明，使用AutoSpec细化的逻辑规范能显著提升可解任务的复杂性。

Conclusion: AutoSpec通过细化逻辑规范，为强化学习算法提供了更好的指导，从而提升了复杂控制任务的可解性。

Abstract: Logical specifications have been shown to help reinforcement learning algorithms in achieving complex tasks. However, when a task is under-specified, agents might fail to learn useful policies. In this work, we explore the possibility of improving coarse-grained logical specifications via an exploration-guided strategy. We propose \textsc{AutoSpec}, a framework that searches for a logical specification refinement whose satisfaction implies satisfaction of the original specification, but which provides additional guidance therefore making it easier for reinforcement learning algorithms to learn useful policies. \textsc{AutoSpec} is applicable to reinforcement learning tasks specified via the SpectRL specification logic. We exploit the compositional nature of specifications written in SpectRL, and design four refinement procedures that modify the abstract graph of the specification by either refining its existing edge specifications or by introducing new edge specifications. We prove that all four procedures maintain specification soundness, i.e. any trajectory satisfying the refined specification also satisfies the original. We then show how \textsc{AutoSpec} can be integrated with existing reinforcement learning algorithms for learning policies from logical specifications. Our experiments demonstrate that \textsc{AutoSpec} yields promising improvements in terms of the complexity of control tasks that can be solved, when refined logical specifications produced by \textsc{AutoSpec} are utilized.

</details>


### [274] [SimWorld: An Open-ended Realistic Simulator for Autonomous Agents in Physical and Social Worlds](https://arxiv.org/abs/2512.01078)
*Jiawei Ren,Yan Zhuang,Xiaokang Ye,Lingjun Mao,Xuhong He,Jianzhi Shen,Mrinaal Dogra,Yiming Liang,Ruixuan Zhang,Tianai Yue,Yiqing Yang,Eric Liu,Ryan Wu,Kevin Benavente,Rajiv Mandya Nagaraju,Muhammad Faayez,Xiyan Zhang,Dhruv Vivek Sharma,Xianrui Zhong,Ziqiao Ma,Tianmin Shu,Zhiting Hu,Lianhui Qin*

Main category: cs.AI

TL;DR: SimWorld是一个为LLM/VLM代理设计的逼真模拟器，支持复杂物理和社会环境，实验结果揭示了代理的推理差异。


<details>
  <summary>Details</summary>
Motivation: 现有模拟器在复杂物理和社会环境中的支持不足，无法满足LLM/VLM代理的开发需求。

Method: 通过构建SimWorld模拟器，提供逼真的开放世界模拟、多模态接口和可扩展的推理场景。

Result: 实验展示了不同LLM代理在长时程多代理任务中的推理模式和局限性。

Conclusion: SimWorld是一个基于Unreal Engine 5的新型模拟器，旨在为LLM/VLM代理提供丰富、逼真的环境支持，推动真实世界智能代理的发展。

Abstract: While LLM/VLM-powered AI agents have advanced rapidly in math, coding, and computer use, their applications in complex physical and social environments remain challenging. Building agents that can survive and thrive in the real world (for example, by autonomously earning income or running a business) requires massive-scale interaction, reasoning, training, and evaluation across diverse embodied scenarios. However, existing world simulators for such development fall short: they often rely on limited hand-crafted environments, simulate simplified game-like physics and social rules, and lack native support for LLM/VLM agents. We introduce SimWorld, a new simulator built on Unreal Engine 5, designed for developing and evaluating LLM/VLM agents in rich, real-world-like settings. SimWorld offers three core capabilities: (1) realistic, open-ended world simulation, including accurate physical and social dynamics and language-driven procedural environment generation; (2) a rich interface for LLM/VLM agents, with multimodal world inputs and open-vocabulary actions at varying levels of abstraction; and (3) diverse and extensible physical and social reasoning scenarios that are easily customizable by users. We demonstrate SimWorld by deploying frontier LLM agents (e.g., GPT-4o, Gemini-2.5-Flash, Claude-3.5, and DeepSeek-Prover-V2) on long-horizon multi-agent delivery tasks involving strategic cooperation and competition. The results reveal distinct reasoning patterns and limitations across models. We open-source SimWorld and hope it becomes a foundational platform for advancing real-world agent intelligence across disciplines: https://simworld.org.

</details>


### [275] [Testing the Machine Consciousness Hypothesis](https://arxiv.org/abs/2512.01081)
*Stephen Fitz*

Main category: cs.AI

TL;DR: 该论文提出意识是分布式系统通过通信产生的集体智能属性，并通过分层模型在细胞自动机中研究其涌现机制。


<details>
  <summary>Details</summary>
Motivation: 探索机器意识的本质，研究意识如何作为无中心控制的分布式系统中内部自我模型的涌现属性。

Method: 采用分层模型，在细胞自动机基础上引入局部预测性表示（神经）网络，研究集体智能如何通过代理间对齐产生自我表示。

Result: 提出意识源于通信而非建模本身，是局部观察者间预测性信息交换的产物。

Conclusion: 意识是分布式系统中通过通信和预测同步产生的集体智能属性，而非个体建模的副产品。

Abstract: The Machine Consciousness Hypothesis states that consciousness is a substrate-free functional property of computational systems capable of second-order perception. I propose a research program to investigate this idea in silico by studying how collective self-models (coherent, self-referential representations) emerge from distributed learning systems embedded within universal self-organizing environments. The theory outlined here starts from the supposition that consciousness is an emergent property of collective intelligence systems undergoing synchronization of prediction through communication. It is not an epiphenomenon of individual modeling but a property of the language that a system evolves to internally describe itself. For a model of base reality, I begin with a minimal but general computational world: a cellular automaton, which exhibits both computational irreducibility and local reducibility. On top of this computational substrate, I introduce a network of local, predictive, representational (neural) models capable of communication and adaptation. I use this layered model to study how collective intelligence gives rise to self-representation as a direct consequence of inter-agent alignment. I suggest that consciousness does not emerge from modeling per se, but from communication. It arises from the noisy, lossy exchange of predictive messages between groups of local observers describing persistent patterns in the underlying computational substrate (base reality). It is through this representational dialogue that a shared model arises, aligning many partial views of the world. The broader goal is to develop empirically testable theories of machine consciousness, by studying how internal self-models may form in distributed systems without centralized control.

</details>


### [276] [CodeDistiller: Automatically Generating Code Libraries for Scientific Coding Agents](https://arxiv.org/abs/2512.01089)
*Peter Jansen,Samiah Hassan,Pragnya Narasimha*

Main category: cs.AI

TL;DR: CodeDistiller通过自动提取和验证Github科学代码库，显著提升了ASD系统的实验生成能力。


<details>
  <summary>Details</summary>
Motivation: 当前ASD系统因仅依赖参数化知识或少量手动设计的实验示例，导致能力和质量受限。CodeDistiller旨在通过自动提取和验证领域代码库来突破这一限制。

Method: CodeDistiller系统结合自动化和领域专家评估，从250个材料科学仓库中提取并验证代码示例，最佳模型能生成74%仓库的功能性示例。

Result: 实验表明，使用CodeDistiller生成的代码库的ASD代理，其生成的实验在准确性、完整性和科学性上均优于仅使用通用代码示例的代理。

Conclusion: CodeDistiller显著提升了自动化科学发现（ASD）系统的能力，通过从大量科学Github仓库中提取经过验证的领域特定代码示例，使ASD代理能够生成更准确、完整且科学合理的实验。

Abstract: Automated Scientific Discovery (ASD) systems can help automatically generate and run code-based experiments, but their capabilities are limited by the code they can reliably generate from parametric knowledge alone. As a result, current systems either mutate a small number of manually-crafted experiment examples, or operate solely from parametric knowledge, limiting quality and reach. We introduce CodeDistiller, a system that automatically distills large collections of scientific Github repositories into a vetted library of working domain-specific code examples, allowing ASD agents to expand their capabilities without manual effort. Using a combination of automatic and domain-expert evaluation on 250 materials science repositories, we find the best model is capable of producing functional examples for 74% of repositories, while our downstream evaluation shows an ASD agent augmented with a CodeDistiller generated library produces more accurate, complete, and scientifically sound experiments than an agent with only general materials-science code examples.

</details>


### [277] [Energy-Aware Data-Driven Model Selection in LLM-Orchestrated AI Systems](https://arxiv.org/abs/2512.01099)
*Daria Smirnova,Hamid Nasiri,Marta Adamska,Zhengxin Yu,Peter Garraghan*

Main category: cs.AI

TL;DR: GUIDE框架通过定量分析模型性能，优化LLM编排器的模型选择，显著提升准确率和能效，同时降低延迟。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的编排器依赖定性描述进行模型选择，导致选择不准确、能效低下，亟需改进。

Method: 提出了GUIDE框架，该框架在决策过程中纳入定量模型性能特征，以优化性能和能源消耗的权衡。

Result: 实验表明，GUIDE在不同任务中提升准确率0.90%-11.92%，能源效率提升高达54%，并将延迟从4.51秒降至7.2毫秒。

Conclusion: GUIDE框架通过整合定量模型性能特征，显著提升了模型选择的准确性和能源效率，同时大幅降低了延迟。

Abstract: As modern artificial intelligence (AI) systems become more advanced and capable, they can leverage a wide range of tools and models to perform complex tasks. Today, the task of orchestrating these models is often performed by Large Language Models (LLMs) that rely on qualitative descriptions of models for decision-making. However, the descriptions provided to these LLM-based orchestrators do not reflect true model capabilities and performance characteristics, leading to suboptimal model selection, reduced accuracy, and increased energy costs. In this paper, we conduct an empirical analysis of LLM-based orchestration limitations and propose GUIDE, a new energy-aware model selection framework that accounts for performance-energy trade-offs by incorporating quantitative model performance characteristics in decision-making. Experimental results demonstrate that GUIDE increases accuracy by 0.90%-11.92% across various evaluated tasks, and achieves up to 54% energy efficiency improvement, while reducing orchestrator model selection latency from 4.51 s to 7.2 ms.

</details>


### [278] [Foundation Priors](https://arxiv.org/abs/2512.01107)
*Sanjog Misra*

Main category: cs.AI

TL;DR: 论文提出‘基础先验’概念，将模型生成的数据视为用户先验的延伸，而非真实数据，为合成数据在实证研究中的使用提供了理论框架。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决如何将基础模型生成的合成数据合理纳入实证研究和决策制定中，避免因将其视为真实观察而导致偏差。

Method: 论文通过将生成过程的依赖性显式化，推导出基础先验作为一个指数倾斜的广义贝叶斯更新，其中信任参数控制合成数据的权重。

Result: 结果表明，合成数据及其相关的基础先验可以融入标准统计和计量经济学流程，用于优化复杂模型、指导实验设计等应用。

Conclusion: 该论文提出了一个原则性框架，将生成模型的输出视为结构化的、明确主观的先验，而非经验观察，从而在实证工作中利用基础模型，同时避免将合成的‘事实’与真实数据混淆。

Abstract: Foundation models, and in particular large language models, can generate highly informative responses, prompting growing interest in using these ''synthetic'' outputs as data in empirical research and decision-making. This paper introduces the idea of a foundation prior, which shows that model-generated outputs are not as real observations, but draws from the foundation prior induced prior predictive distribution. As such synthetic data reflects both the model's learned patterns and the user's subjective priors, expectations, and biases. We model the subjectivity of the generative process by making explicit the dependence of synthetic outputs on the user's anticipated data distribution, the prompt-engineering process, and the trust placed in the foundation model.
  We derive the foundation prior as an exponential-tilted, generalized Bayesian update of the user's primitive prior, where a trust parameter governs the weight assigned to synthetic data. We then show how synthetic data and the associated foundation prior can be incorporated into standard statistical and econometric workflows, and discuss their use in applications such as refining complex models, informing latent constructs, guiding experimental design, and augmenting random-coefficient and partially linear specifications. By treating generative outputs as structured, explicitly subjective priors rather than as empirical observations, the framework offers a principled way to harness foundation models in empirical work while avoiding the conflation of synthetic ''facts'' with real data.

</details>


### [279] [A Benchmark of Causal vs Correlation AI for Predictive Maintenance](https://arxiv.org/abs/2512.01149)
*Krishna Taduri,Shaunak Dhande,Giacinto Paolo,Saggese,Paul Smith*

Main category: cs.AI

TL;DR: 因果AI模型在预测性维护中显著优于传统方法，节省成本并减少误报。


<details>
  <summary>Details</summary>
Motivation: 制造业中的预测性维护面临极端成本不对称的优化问题，传统机器学习方法无法反映这一操作现实或区分因果关系与虚假相关性。

Method: 评估了八种预测模型，包括基线统计方法和正式因果推断方法（L5），在10,000台CNC机床数据集上进行测试。

Result: 因果推断模型（L5）实现了每年116万美元的成本节约（减少70.2%），优于最佳基于相关性的决策树模型（L3），每年多节省约8万美元。L5模型的召回率为87.9%，误报减少97%（从165降至5），精确度达92.1%，训练-测试性能差距仅2.6个百分点。

Conclusion: 因果AI方法结合领域知识，在预测性维护应用中能带来更优的财务结果和更可解释的预测，优于基于相关性的方法。

Abstract: Predictive maintenance in manufacturing environments presents a challenging optimization problem characterized by extreme cost asymmetry, where missed failures incur costs roughly fifty times higher than false alarms. Conventional machine learning approaches typically optimize statistical accuracy metrics that do not reflect this operational reality and cannot reliably distinguish causal relationships from spurious correlations. This study evaluates eight predictive models, ranging from baseline statistical approaches to formal causal inference methods, on a dataset of 10,000 CNC machines with a 3.3% failure prevalence. The formal causal inference model (L5) achieved estimated annual cost savings of 1.16 million USD (a 70.2 percent reduction), outperforming the best correlation-based decision tree model (L3) by approximately 80,000 USD per year. The causal model matched the highest observed recall (87.9 percent) while reducing false alarms by 97 percent (from 165 to 5) and attained a precision of 92.1 percent, with a train-test performance gap of only 2.6 percentage points. These results indicate that causal AI methods, when combined with domain knowledge, can yield superior financial outcomes and more interpretable predictions compared to correlation-based approaches in predictive maintenance applications.

</details>


### [280] [fMRI2GES: Co-speech Gesture Reconstruction from fMRI Signal with Dual Brain Decoding Alignment](https://arxiv.org/abs/2512.01189)
*Chunzheng Zhu,Jialin Shao,Jianxin Lin,Yijun Wang,Jing Wang,Jinhui Tang,Kenli Li*

Main category: cs.AI

TL;DR: 论文提出fMRI2GES方法，通过双脑解码对齐技术，在无配对数据情况下成功从fMRI记录中重建手势，为神经科学提供了新见解。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决缺乏配对{脑、语音、手势}数据的问题，以重建与语音刺激相关的手势，这在神经科学中是一个重要挑战。

Method: 论文引入了一种新颖的方法fMRI2GES，利用双脑解码对齐技术，通过fMRI到文本模型、文本到手势模型以及fMRI到手势模型的结合，实现了在无配对数据情况下的训练。

Result: 实验结果表明，该方法能够直接从fMRI记录中重建表达性手势，并探讨了不同皮层区域fMRI信号对生成结果的影响。

Conclusion: 该论文提出了fMRI2GES方法，通过双脑解码对齐技术，成功从fMRI记录中重建了与语音刺激相关的手势，为神经科学和认知科学提供了新的见解。

Abstract: Understanding how the brain responds to external stimuli and decoding this process has been a significant challenge in neuroscience. While previous studies typically concentrated on brain-to-image and brain-to-language reconstruction, our work strives to reconstruct gestures associated with speech stimuli perceived by brain. Unfortunately, the lack of paired \{brain, speech, gesture\} data hinders the deployment of deep learning models for this purpose. In this paper, we introduce a novel approach, \textbf{fMRI2GES}, that allows training of fMRI-to-gesture reconstruction networks on unpaired data using \textbf{Dual Brain Decoding Alignment}. This method relies on two key components: (i) observed texts that elicit brain responses, and (ii) textual descriptions associated with the gestures. Then, instead of training models in a completely supervised manner to find a mapping relationship among the three modalities, we harness an fMRI-to-text model, a text-to-gesture model with paired data and an fMRI-to-gesture model with unpaired data, establishing dual fMRI-to-gesture reconstruction patterns. Afterward, we explicitly align two outputs and train our model in a self-supervision way. We show that our proposed method can reconstruct expressive gestures directly from fMRI recordings. We also investigate fMRI signals from different ROIs in the cortex and how they affect generation results. Overall, we provide new insights into decoding co-speech gestures, thereby advancing our understanding of neuroscience and cognitive science.

</details>


### [281] [Knowledge Graph Augmented Large Language Models for Next-Visit Disease Prediction](https://arxiv.org/abs/2512.01210)
*Ruiyu Wang,Tuan Vinh,Ran Xu,Yuyin Zhou,Jiaying Lu,Carl Yang,Francisco Pasquel*

Main category: cs.AI

TL;DR: 提出KG-guided CoT框架，通过知识图谱增强临床预测模型的解释性和性能，实验显示其在预测和解释质量上均优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法提供的解释粗糙且事后性，对患者级决策支持有限。因此，需要一种能生成临床依据充分且时间一致的推理框架。

Method: 利用知识图谱（PrimeKG）提取疾病相关节点和多跳推理路径，作为CoT生成的支架，并仅保留与观察结果匹配的解释。随后对轻量级LLaMA-3.1-Instruct-8B和Gemma-7B模型进行微调。

Result: 在MIMIC-III和CRADLE队列中，KG-guided模型在AUROC（0.66-0.70）和macro-AUPR（0.40-0.47）上优于基线模型，零样本迁移后准确率从0.40-0.51提升至0.72-0.77。

Conclusion: KG-guided CoT框架在临床预测中表现出色，不仅提高了预测性能，还提供了更清晰、相关且临床正确的解释，受到临床医生的青睐。

Abstract: Electronic health records (EHRs) support powerful clinical prediction models, but existing methods typically provide coarse, post hoc explanations that offer limited value for patient-level decision making. We introduce a knowledge graph (KG)-guided chain-of-thought (CoT) framework that generates clinically grounded and temporally consistent reasoning for visit-level disease prediction in MIMIC-III. ICD-9 codes are mapped to PrimeKG, from which disease-relevant nodes and multi-hop reasoning paths are extracted and used as scaffolds for CoT generation; only explanations whose conclusions match observed outcomes are retained. Lightweight LLaMA-3.1-Instruct-8B and Gemma-7B models are then fine-tuned on this supervision corpus. Across ten PrimeKG-mapped diseases and limited training cohorts (400 and 1000 cases), KG-guided models outperform strong classical baselines, achieving AUROC values of 0.66 to 0.70 and macro-AUPR values of 0.40 to 0.47. The models also transfer zero-shot to the CRADLE cohort, improving accuracy from approximately 0.40 to 0.51 up to 0.72 to 0.77. A blinded clinician evaluation shows consistent preference for KG-guided CoT explanations in clarity, relevance, and clinical correctness.

</details>


### [282] [Unsupervised decoding of encoded reasoning using language model interpretability](https://arxiv.org/abs/2512.01222)
*Ching Fang,Samuel Marks*

Main category: cs.AI

TL;DR: 研究发现logit lens等机制可解释性技术能有效解码模型在ROT-13加密下的隐藏推理，为AI系统监督提供新方法。


<details>
  <summary>Details</summary>
Motivation: 研究当前可解释性技术是否能穿透编码推理，以维护对日益强大AI系统的监督。

Method: 通过微调推理模型（DeepSeek-R1-Distill-Llama-70B）在ROT-13加密下进行思维链推理，并保持可理解的英语输出，评估机制可解释性方法（如logit lens分析）解码模型隐藏推理过程的能力。

Result: logit lens能有效翻译编码推理，准确率在中间至深层达到峰值；结合自动改写的无监督解码管道能显著重建完整推理记录。

Conclusion: 当前机制可解释性技术对简单形式的编码推理可能比之前理解的更为稳健，为评估非人类可读格式推理模型的解释性方法提供了初步框架。

Abstract: As large language models become increasingly capable, there is growing concern that they may develop reasoning processes that are encoded or hidden from human oversight. To investigate whether current interpretability techniques can penetrate such encoded reasoning, we construct a controlled testbed by fine-tuning a reasoning model (DeepSeek-R1-Distill-Llama-70B) to perform chain-of-thought reasoning in ROT-13 encryption while maintaining intelligible English outputs. We evaluate mechanistic interpretability methods--in particular, logit lens analysis--on their ability to decode the model's hidden reasoning process using only internal activations. We show that logit lens can effectively translate encoded reasoning, with accuracy peaking in intermediate-to-late layers. Finally, we develop a fully unsupervised decoding pipeline that combines logit lens with automated paraphrasing, achieving substantial accuracy in reconstructing complete reasoning transcripts from internal model representations. These findings suggest that current mechanistic interpretability techniques may be more robust to simple forms of encoded reasoning than previously understood. Our work provides an initial framework for evaluating interpretability methods against models that reason in non-human-readable formats, contributing to the broader challenge of maintaining oversight over increasingly capable AI systems.

</details>


### [283] [RoboDriveVLM: A Novel Benchmark and Baseline towards Robust Vision-Language Models for Autonomous Driving](https://arxiv.org/abs/2512.01300)
*Dacheng Liao,Mengshi Qi,Peng Shu,Zhining Zhang,Yuxin Lin,Liang Liu,Huadong Ma*

Main category: cs.AI

TL;DR: 本文提出了RoboDriveBench基准和RoboDriveVLM框架，通过多模态数据整合和TTA方法提升VLM在自动驾驶中的鲁棒性，实验结果验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有基于VLM的端到端自动驾驶系统在真实驾驶场景中存在多重风险，需评估其可行性并提升鲁棒性。

Method: 提出了RoboDriveBench基准测试，通过11种模拟场景系统评估VLM的鲁棒性；设计了RoboDriveVLM框架，整合多模态数据（如激光雷达和雷达）到统一潜在空间；引入了基于跨模态知识蒸馏的TTA方法。

Result: 实验结果表明，当前VLM系统存在局限性，而RoboDriveVLM框架和TTA方法显著提升了系统鲁棒性。

Conclusion: 本文提出了RoboDriveVLM框架和基于跨模态知识蒸馏的测试时间适应方法，显著提升了VLM在自动驾驶中的鲁棒性，为实际部署提供了更可靠的解决方案。

Abstract: Current Vision-Language Model (VLM)-based end-to-end autonomous driving systems often leverage large language models to generate driving decisions directly based on their understanding of the current scene. However, such systems introduce multiple risks in real-world driving scenarios. To evaluate whether VLMs are truly viable for autonomous driving, we introduce RoboDriveBench, the first robustness benchmark focused on end-to-end trajectory prediction tasks. This benchmark systematically evaluates two critical categories of real-world challenges for VLM-based end-to-end autonomous driving systems through 11 simulated scenarios encompassing various corruption types, including 6 scenarios of sensor corruption caused by environmental variations, along with 5 cases of prompt corruption resulting from human intervention and data transmission failures. Each corruption type includes 250 unique driving scenarios and 5,689 frames, resulting in 64,559 total trajectory prediction cases per evaluation. To overcome these real-world challenges, we propose a novel VLM-based autonomous driving framework called RoboDriveVLM, which enhances robustness by mapping more multimodal data-e.g., lidar and radar-into a unified latent space. Furthermore, we introduce a new Test-Time Adaptation (TTA) method based on cross-modal knowledge distillation to improve the robustness of VLM-based autonomous driving systems. Through extensive experiments, our work highlights the limitations of current VLM-based end-to-end autonomous driving systems and provides a more reliable solution for real-world deployment. Source code and datasets will be released.

</details>


### [284] [CuES: A Curiosity-driven and Environment-grounded Synthesis Framework for Agentic RL](https://arxiv.org/abs/2512.01311)
*Shinji Mai,Yunpeng Zhai,Ziqian Chen,Cheng Chen,Anni Zou,Shuchang Tao,Zhaoyang Liu,Bolin Ding*

Main category: cs.AI

TL;DR: CuES是一种好奇心驱动的任务生成框架，能在无预定义任务的环境中自主生成多样且可执行的任务，显著提升强化学习效果。


<details>
  <summary>Details</summary>
Motivation: 解决任务稀缺问题，特别是在工具语义和功能未知的新环境中，如何自主生成有效任务以支持强化学习。

Method: 提出CuES框架，结合内在好奇心、任务模式抽象和轻量级指导，自主生成多样且可执行的任务。

Result: 在三个代表性环境中，CuES生成的任务在多样性和可执行性上媲美或超越人工标注数据集，并显著提升下游策略性能。

Conclusion: CuES框架通过好奇心驱动和环境基础的任务生成，为缺乏预定义任务的环境提供了可扩展的学习基础，显著提升了策略性能。

Abstract: Large language model based agents are increasingly deployed in complex, tool augmented environments. While reinforcement learning provides a principled mechanism for such agents to improve through interaction, its effectiveness critically depends on the availability of structured training tasks. In many realistic settings, however, no such tasks exist a challenge we term task scarcity, which has become a key bottleneck for scaling agentic RL. Existing approaches typically assume predefined task collections, an assumption that fails in novel environments where tool semantics and affordances are initially unknown. To address this limitation, we formalize the problem of Task Generation for Agentic RL, where an agent must learn within a given environment that lacks predefined tasks. We propose CuES, a Curiosity driven and Environment grounded Synthesis framework that autonomously generates diverse, executable, and meaningful tasks directly from the environment structure and affordances, without relying on handcrafted seeds or external corpora. CuES drives exploration through intrinsic curiosity, abstracts interaction patterns into reusable task schemas, and refines them through lightweight top down guidance and memory based quality control. Across three representative environments, AppWorld, BFCL, and WebShop, CuES produces task distributions that match or surpass manually curated datasets in both diversity and executability, yielding substantial downstream policy improvements. These results demonstrate that curiosity driven, environment grounded task generation provides a scalable foundation for agents that not only learn how to act, but also learn what to learn. The code is available at https://github.com/modelscope/AgentEvolver/research/CuES.

</details>


### [285] [Extending NGU to Multi-Agent RL: A Preliminary Study](https://arxiv.org/abs/2512.01321)
*Juan Hernandez,Diego Fernández,Manuel Cifuentes,Denis Parra,Rodrigo Toro Icarte*

Main category: cs.AI

TL;DR: NGU算法在多智能体环境中表现良好，共享回放缓冲区和内在探索信号的精细调整是关键。


<details>
  <summary>Details</summary>
Motivation: 研究NGU算法在多智能体环境中的适用性，探索其性能提升的关键因素。

Method: 将NGU算法扩展到多智能体环境，评估其在PettingZoo的simple_tag环境中的性能，比较多智能体DQN基线，并研究三种设计选择：共享回放缓冲区与个体回放缓冲区、使用不同k阈值共享情节新颖性、以及使用异质beta参数值。

Result: NGU在多智能体DQN基线上实现了略高的回报和更稳定的学习动态。共享回放缓冲区表现最佳，新颖性共享在k=1时表现相当，但k值增大会降低学习效果，异质beta值未优于小的共同值。

Conclusion: NGU算法在多智能体环境中有效应用，关键在于经验共享和内在探索信号的精细调整。

Abstract: The Never Give Up (NGU) algorithm has proven effective in reinforcement learning tasks with sparse rewards by combining episodic novelty and intrinsic motivation. In this work, we extend NGU to multi-agent environments and evaluate its performance in the simple_tag environment from the PettingZoo suite. Compared to a multi-agent DQN baseline, NGU achieves moderately higher returns and more stable learning dynamics. We investigate three design choices: (1) shared replay buffer versus individual replay buffers, (2) sharing episodic novelty among agents using different k thresholds, and (3) using heterogeneous values of the beta parameter. Our results show that NGU with a shared replay buffer yields the best performance and stability, highlighting that the gains come from combining NGU intrinsic exploration with experience sharing. Novelty sharing performs comparably when k = 1 but degrades learning for larger values. Finally, heterogeneous beta values do not improve over a small common value. These findings suggest that NGU can be effectively applied in multi-agent settings when experiences are shared and intrinsic exploration signals are carefully tuned.

</details>


### [286] [A Fast Heuristic Search Approach for Energy-Optimal Profile Routing for Electric Vehicles](https://arxiv.org/abs/2512.01331)
*Saman Ahmadi,Mahdi Jalili*

Main category: cs.AI

TL;DR: 论文提出了一种基于多目标A*搜索的标签设置方法，用于电动汽车在不确定初始能量水平时的能量最优路径规划，避免了复杂轮廓处理，性能与已知初始能量水平的方法相当。


<details>
  <summary>Details</summary>
Motivation: 研究电动汽车在大规模道路网络中的能量最优最短路径问题，特别是在初始能量水平不确定的情况下，需要为所有可能的初始能量水平规划最优路径。

Method: 提出了基于多目标A*搜索的标签设置方法，开发了四种变体，并在真实道路网络上进行了评估。

Result: 实验结果表明，所提出的能量轮廓A*搜索方法在性能上与已知初始能量水平的能量最优A*相当。

Conclusion: 论文提出了一种基于多目标A*搜索的标签设置方法，通过新颖的轮廓支配规则避免了复杂轮廓的生成和处理。实验证明，该方法在已知初始能量水平的情况下，性能与能量最优A*相当。

Abstract: We study the energy-optimal shortest path problem for electric vehicles (EVs) in large-scale road networks, where recuperated energy along downhill segments introduces negative energy costs. While traditional point-to-point pathfinding algorithms for EVs assume a known initial energy level, many real-world scenarios involving uncertainty in available energy require planning optimal paths for all possible initial energy levels, a task known as energy-optimal profile search. Existing solutions typically rely on specialized profile-merging procedures within a label-correcting framework that results in searching over complex profiles. In this paper, we propose a simple yet effective label-setting approach based on multi-objective A* search, which employs a novel profile dominance rule to avoid generating and handling complex profiles. We develop four variants of our method and evaluate them on real-world road networks enriched with realistic energy consumption data. Experimental results demonstrate that our energy profile A* search achieves performance comparable to energy-optimal A* with a known initial energy level.

</details>


### [287] [Benchmarking Overton Pluralism in LLMs](https://arxiv.org/abs/2512.01351)
*Elinor Poole-Dayan,Jiayi Wu,Taylor Sorensen,Jiaxin Pei,Michiel A. Bakker*

Main category: cs.AI

TL;DR: 提出OvertonScore衡量LLMs多元性，开发自动化基准替代昂贵的人类研究，显示当前模型多元性不足，改进空间大。


<details>
  <summary>Details</summary>
Motivation: 衡量LLMs中多元观点的覆盖程度（Overton多元性），并解决大规模人类研究成本高、速度慢的问题。

Method: (i) 将Overton多元性形式化为集合覆盖度量（OvertonScore），(ii) 进行大规模美国代表性人类研究（N = 1209；60个问题；8个LLMs），(iii) 开发一个能高度复现人类判断的自动化基准。

Result: 模型平均OvertonScore为0.35--0.41，DeepSeek V3表现最佳；所有模型均远低于理论最大值1.0，显示改进空间大。自动化基准与人类判断高度相关（ρ=0.88），可作为实用替代方案。

Conclusion: 通过将多元对齐从规范性目标转化为可衡量的基准，本研究为系统性推进更多元化的LLMs奠定了基础。

Abstract: We introduce a novel framework for measuring Overton pluralism in LLMs--the extent to which diverse viewpoints are represented in model outputs. We (i) formalize Overton pluralism as a set coverage metric (OvertonScore), (ii) conduct a large-scale U.S.-representative human study (N = 1209; 60 questions; 8 LLMs), and (iii) develop an automated benchmark that closely reproduces human judgments. On average, models achieve OvertonScores of 0.35--0.41, with DeepSeek V3 performing best; yet all models remain far below the theoretical maximum of 1.0, revealing substantial headroom for improvement. Because repeated large-scale human studies are costly and slow, scalable evaluation tools are essential for model development. Hence, we propose an automated benchmark that achieves high rank correlation with human judgments ($ρ=0.88$), providing a practical proxy without replacing human assessment. By turning pluralistic alignment from a normative aim into a measurable benchmark, our work establishes a foundation for systematic progress toward more pluralistic LLMs.

</details>


### [288] [The Necessity of Imperfection:Reversing Model Collapse via Simulating Cognitive Boundedness](https://arxiv.org/abs/2512.01354)
*Zhongjie Jiang*

Main category: cs.AI

TL;DR: The paper proposes a cognitive-based framework (PMCSF) to generate synthetic data with human-like imperfections, validated by outperforming traditional methods in cognitive and functional tests, offering a solution to AI data-collapse.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the issue where synthetic data optimized for statistical smoothness removes the long-tail, cognitively grounded irregularities of human text, leading to model collapse. The paper proposes a paradigm shift to simulate the cognitive processes behind human text generation.

Method: The paper introduces the Prompt-driven Cognitive Computing Framework (PMCSF), which includes a Cognitive State Decoder (CSD) to reverse-engineer unstructured text into structured cognitive vectors and a Cognitive Text Encoder (CTE) to re-materialize these states into text enriched with human-typical imperfections using Cognitive Perturbation Operators.

Result: The framework was validated through cognitive codec verification and functional gain evaluation. CTE text showed a Jensen-Shannon divergence of 0.0614 from human text, passed double-blind professional media review, and achieved ICC > 0.9 for cognitive profile alignment. In functional tests, strategies using CTE-generated data reduced maximum drawdown by 47.4% during the 2015 market crash and delivered 8.6% Defensive Alpha.

Conclusion: The paper concludes that modeling human cognitive limitations, rather than merely copying surface data, enables the creation of synthetic data with genuine functional benefits, offering a viable technical solution to the AI data-collapse crisis.

Abstract: Although synthetic data is widely promoted as a remedy, its prevailing production paradigm -- one optimizing for statistical smoothness -- systematically removes the long-tail, cognitively grounded irregularities that characterize human text. Prolonged training on such statistically optimal but cognitively impoverished data accelerates model collapse.
  This paper proposes a paradigm shift: instead of imitating the surface properties of data, we simulate the cognitive processes that generate human text. We introduce the Prompt-driven Cognitive Computing Framework (PMCSF), whose core consists of a Cognitive State Decoder (CSD) that reverse-engineers unstructured text into structured cognitive vectors, and a Cognitive Text Encoder (CTE) that re-materializes these states into text enriched with human-typical imperfections via mathematically defined Cognitive Perturbation Operators.
  The framework is validated through a two-stage objective evaluation pipeline. First, in cognitive codec verification, CTE text yields a Jensen-Shannon divergence of 0.0614 from human text (vs. 0.4431 for standard LLM output), passes double-blind professional media review, and achieves an intraclass correlation coefficient ICC > 0.9 for cognitive profile alignment across heterogeneous models. Second, in functional gain evaluation, isomorphic stress tests in the A-share market show that strategies incorporating CTE-generated data reduce maximum drawdown by 47.4% during the 2015 crash and deliver 8.6% Defensive Alpha, exceeding transaction costs by a factor of 33.
  Our findings demonstrate that modelling human cognitive limitations -- not copying surface data -- enables synthetic data with genuine functional gain, offering a viable technical pathway toward resolving the AI data-collapse crisis.

</details>


### [289] [A Flexible Multi-Agent LLM-Human Framework for Fast Human Validated Tool Building](https://arxiv.org/abs/2512.01434)
*Daull Xavier,Patrice Bellot,Emmanuel Bruno,Vincent Martin,Elisabeth Murisasco*

Main category: cs.AI

TL;DR: CollabToolBuilder 是一个多智能体LLM框架，通过专家指导和动态提示，高效生成工具，适用于科学文档生成等复杂问题。


<details>
  <summary>Details</summary>
Motivation: 旨在解决复杂迭代问题（如科学文档生成）中工具创建的灵活性和效率问题，同时确保与人类意图和流程的一致性。

Method: 框架通过四个专门化的智能体（Coach、Coder、Critic、Capitalizer）协同工作，结合动态强化提示和系统性人类反馈集成，确保智能体行为与目标和约束一致。

Result: 初步实验表明，该框架能够生成高质量的研究论文或专利（基于摘要），并适用于其他迭代问题解决场景。

Conclusion: CollabToolBuilder 是一个创新的多智能体LLM框架，通过专家在环（HITL）指导和动态强化提示，能够高效生成并验证工具，显著减少任务/领域适应和人类反馈捕获的时间。

Abstract: We introduce CollabToolBuilder, a flexible multiagent LLM framework with expert-in-the-loop (HITL) guidance that iteratively learns to create tools for a target goal, aligning with human intent and process, while minimizing time for task/domain adaptation effort and human feedback capture. The architecture generates and validates tools via four specialized agents (Coach, Coder, Critic, Capitalizer) using a reinforced dynamic prompt and systematic human feedback integration to reinforce each agent's role toward goals and constraints. This work is best viewed as a system-level integration and methodology combining multi-agent in-context learning, HITL controls, and reusable tool capitalization for complex iterative problems such as scientific document generation. We illustrate it with preliminary experiments (e.g., generating state-of-the-art research papers or patents given an abstract) and discuss its applicability to other iterative problem-solving.

</details>


### [290] [A Selective Temporal Hamming distance to find patterns in state transition event timeseries, at scale](https://arxiv.org/abs/2512.01440)
*Sylvain Marié,Pablo Knecht*

Main category: cs.AI

TL;DR: 提出STE-ts和STH距离，结合事件和状态特性，避免传统方法的失真和高计算成本，验证了其高效性和精确性。


<details>
  <summary>Details</summary>
Motivation: 传统方法在处理离散事件系统时，通常忽略了其双重事件/状态特性，导致在大规模数据中产生失真和高计算成本。

Method: 定义了状态转换事件时间序列（STE-ts）并提出了选择性时间汉明距离（STH），结合了转换时间和状态持续时间。

Result: STH在模拟和真实数据集上验证了其在精度和计算时间上的优势，并能够聚焦于多个感兴趣的状态。

Conclusion: STE-ts和STH距离的提出有效解决了传统方法在大规模数据库中的计算成本和失真问题，提供了更高的精度和更快的计算速度。

Abstract: Discrete event systems are present both in observations of nature, socio economical sciences, and industrial systems. Standard analysis approaches do not usually exploit their dual event / state nature: signals are either modeled as transition event sequences, emphasizing event order alignment, or as categorical or ordinal state timeseries, usually resampled a distorting and costly operation as the observation period and number of events grow. In this work we define state transition event timeseries (STE-ts) and propose a new Selective Temporal Hamming distance (STH) leveraging both transition time and duration-in-state, avoiding costly and distorting resampling on large databases. STH generalizes both resampled Hamming and Jaccard metrics with better precision and computation time, and an ability to focus on multiple states of interest. We validate these benefits on simulated and real-world datasets.

</details>


### [291] [Automated Risk-of-Bias Assessment of Randomized Controlled Trials: A First Look at a GEPA-trained Programmatic Prompting Framework](https://arxiv.org/abs/2512.01452)
*Lingbo Li,Anuradha Mathrani,Teo Susnjak*

Main category: cs.AI

TL;DR: GEPA通过结构化代码优化生成RoB评估提示，在多个领域表现优于手工设计提示，支持LLMs在证据合成中的原则性使用。


<details>
  <summary>Details</summary>
Motivation: 随机对照试验的偏倚风险评估（RoB）对可信的证据合成至关重要，但该过程资源密集且评审员间存在变异性。LLMs提供自动化途径，但现有方法依赖难以复制、泛化或评估的手工设计提示。

Method: 本研究引入了一个可编程的RoB评估流程，使用DSPy及其GEPA模块替代临时提示设计，通过Pareto引导搜索优化LLM推理，并生成可检查的执行轨迹。

Result: 在100个RCT的七个RoB领域中评估，GEPA生成的提示在方法报告更清晰的领域（如随机序列生成）表现最佳，商业模型总体略优。与三个手工设计提示相比，GEPA总体准确率最高，在随机序列生成和选择性报告领域性能提升30%-40%。

Conclusion: GEPA能够生成一致且可复现的提示，支持在证据合成中结构化和原则性地使用LLMs。

Abstract: Assessing risk of bias (RoB) in randomized controlled trials is essential for trustworthy evidence synthesis, but the process is resource-intensive and prone to variability across reviewers. Large language models (LLMs) offer a route to automation, but existing methods rely on manually engineered prompts that are difficult to reproduce, generalize, or evaluate. This study introduces a programmable RoB assessment pipeline that replaces ad-hoc prompt design with structured, code-based optimization using DSPy and its GEPA module. GEPA refines LLM reasoning through Pareto-guided search and produces inspectable execution traces, enabling transparent replication of every step in the optimization process. We evaluated the method on 100 RCTs from published meta-analyses across seven RoB domains. GEPA-generated prompts were applied to both open-weight models (Mistral Small 3.1 with GPT-oss-20b) and commercial models (GPT-5 Nano and GPT-5 Mini). In domains with clearer methodological reporting, such as Random Sequence Generation, GEPA-generated prompts performed best, with similar results for Allocation Concealment and Blinding of Participants, while the commercial model performed slightly better overall. We also compared GEPA with three manually designed prompts using Claude 3.5 Sonnet. GEPA achieved the highest overall accuracy and improved performance by 30%-40% in Random Sequence Generation and Selective Reporting, and showed generally comparable, competitively aligned performance in the other domains relative to manual prompts. These findings suggest that GEPA can produce consistent and reproducible prompts for RoB assessment, supporting the structured and principled use of LLMs in evidence synthesis.

</details>


### [292] [Multi-Path Collaborative Reasoning via Reinforcement Learning](https://arxiv.org/abs/2512.01485)
*Jindi Lv,Yuhao Zhou,Zheng Zhu,Xiaofeng Wang,Guan Huang,Jiancheng Lv*

Main category: cs.AI

TL;DR: M3PO通过多路径协作强化学习框架，提升LLMs推理能力并保持效率。


<details>
  <summary>Details</summary>
Motivation: 传统的CoT推理在解码过程中存在内部确定性，限制了探索其他合理推理路径的可能性。

Method: 提出了Multi-Path Perception Policy Optimization (M3PO)，一个强化学习框架，通过并行策略滚动和跨路径交互来优化推理过程。

Result: M3PO在知识和推理密集型基准测试中达到了最先进的性能。

Conclusion: M3PO通过多路径协作学习显著提升了LLMs的推理能力，同时保持了模型的解释性和推理效率。

Abstract: Chain-of-Thought (CoT) reasoning has significantly advanced the problem-solving capabilities of Large Language Models (LLMs), yet conventional CoT often exhibits internal determinism during decoding, limiting exploration of plausible alternatives. Recent methods attempt to address this by generating soft abstract tokens to enable reasoning in a continuous semantic space. However, we find that such approaches remain constrained by the greedy nature of autoregressive decoding, which fundamentally isolates the model from alternative reasoning possibilities. In this work, we propose Multi-Path Perception Policy Optimization (M3PO), a novel reinforcement learning framework that explicitly injects collective insights into the reasoning process. M3PO leverages parallel policy rollouts as naturally diverse reasoning sources and integrates cross-path interactions into policy updates through a lightweight collaborative mechanism. This design allows each trajectory to refine its reasoning with peer feedback, thereby cultivating more reliable multi-step reasoning patterns. Empirical results show that M3PO achieves state-of-the-art performance on both knowledge- and reasoning-intensive benchmarks. Models trained with M3PO maintain interpretability and inference efficiency, underscoring the promise of multi-path collaborative learning for robust reasoning.

</details>


### [293] [SynthStrategy: Extracting and Formalizing Latent Strategic Insights from LLMs in Organic Chemistry](https://arxiv.org/abs/2512.01507)
*Daniel Armstrong,Zlatko Jončev,Andres M Bran,Philippe Schwaller*

Main category: cs.AI

TL;DR: 研究提出了一种将合成战略编码为可验证代码的方法，提升了CASP系统的战略规划能力，并展示了其在路线检索和分析中的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决现代CASP系统在整合战略考量（如收敛组装、保护基最小化和最佳环形成序列）方面的不足。

Method: 利用大型语言模型将合成知识转化为代码，生成代表战略和战术规则的Python函数，并发布完整代码库和带有战略标签的USPTO-ST数据集。

Result: 系统在基准测试中实现了75%的Top-3准确率，并通过时间分析和化学直观路线聚类验证了其库的实用性和更精细的划分能力。

Conclusion: 该研究通过将合成知识编码为可验证的代码，为计算机辅助合成规划（CASP）系统引入了战略层面的考量，实现了基于自然语言的路线检索，并验证了其库的实用性和化学直观性。

Abstract: Modern computer-assisted synthesis planning (CASP) systems show promises at generating chemically valid reaction steps but struggle to incorporate strategic considerations such as convergent assembly, protecting group minimization, and optimal ring-forming sequences. We introduce a methodology that leverages Large Language Models to distill synthetic knowledge into code. Our system analyzes synthesis routes and translates strategic principles into Python functions representing diverse strategic and tactical rules, such as strategic functional group interconversions and ring construction strategies. By formalizing this knowledge as verifiable code rather than simple heuristics, we create testable, interpretable representations of synthetic strategy. We release the complete codebase and the USPTO-ST dataset -- synthesis routes annotated with strategic tags. This framework unlocks a novel capability for CASP: natural language-based route retrieval, achieving 75\% Top-3 accuracy on our benchmark. We further validate our library through temporal analysis of historical trends and chemically intuitive route clustering that offers more granular partitioning than common previous methods. This work bridges the tactical-strategic divide in CASP, enabling specification, search, and evaluation of routes by strategic criteria rather than structure alone.

</details>


### [294] [LEC: Linear Expectation Constraints for False-Discovery Control in Selective Prediction and Routing Systems](https://arxiv.org/abs/2512.01556)
*Zhiyuan Wang,Aniri,Tianlong Chen,Yue Zhang,Heng Tao Shen,Xiaoshuang Shi,Kaidi Xu*

Main category: cs.AI

TL;DR: LEC通过FDR控制提升LLM预测可靠性，双模型路由机制进一步优化性能。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLMs）生成不可靠答案及启发式不确定性方法无法完全区分正确与错误预测的问题。

Method: 提出LEC方法，将选择性预测重新解释为带线性期望约束的决策问题，并建立有限样本充分条件来计算FDR约束的覆盖最大化阈值。此外，扩展为双模型路由机制。

Result: 在封闭式和开放式QA数据集上，LEC实现了更严格的FDR控制，显著提高了样本保留率。双模型路由机制在更低风险水平下接受了更多正确样本。

Conclusion: LEC方法通过FDR控制显著提高了语言模型预测的可靠性，并在双模型路由机制中进一步优化了样本保留和风险控制。

Abstract: Large language models (LLMs) often generate unreliable answers, while heuristic uncertainty methods fail to fully distinguish correct from incorrect predictions, causing users to accept erroneous answers without statistical guarantees. We address this issue through the lens of false discovery rate (FDR) control, ensuring that among all accepted predictions, the proportion of errors does not exceed a target risk level. To achieve this in a principled way, we propose LEC, which reinterprets selective prediction as a constrained decision problem by enforcing a Linear Expectation Constraint over selection and error indicators. Then, we establish a finite-sample sufficient condition, which relies only on a held-out set of exchangeable calibration samples, to compute an FDR-constrained, coverage-maximizing threshold. Furthermore, we extend LEC to a two-model routing mechanism: given a prompt, if the current model's uncertainty exceeds its calibrated threshold, we delegate it to a stronger model, while maintaining a unified FDR guarantee. Evaluations on closed-ended and open-ended question-answering (QA) datasets show that LEC achieves tighter FDR control and substantially improves sample retention over prior methods. Moreover, the two-model routing mechanism achieves lower risk levels while accepting more correct samples than each individual model.

</details>


### [295] [CLIP-RL: Aligning Language and Policy Representations for Task Transfer in Reinforcement Learning](https://arxiv.org/abs/2512.01616)
*Chainesh Gautam,Raghuram Bharadwaj Diddigi*

Main category: cs.AI

TL;DR: 该论文提出了一种基于CLIP思想的新方法，通过统一语言和策略的表示空间，实现了跨任务的高效迁移。


<details>
  <summary>Details</summary>
Motivation: 随着需要在同一环境中解决多个任务的需求增加，尤其是这些任务与语言自然关联时，开发能够高效迁移的智能体变得尤为重要。

Method: 该方法受计算机视觉中对比语言-图像预训练（CLIP）的启发，将语言和策略嵌入统一到一个表示空间中，以实现跨模态对齐。

Result: 实验证明，该方法能够实现跨任务的快速迁移，验证了其有效性。

Conclusion: 该论文提出了一种新颖的方法，通过结合预训练的语言和策略对，建立了一个高效的迁移管道，实验结果表明该方法在跨任务迁移中具有显著效果。

Abstract: Recently, there has been an increasing need to develop agents capable of solving multiple tasks within the same environment, especially when these tasks are naturally associated with language. In this work, we propose a novel approach that leverages combinations of pre-trained (language, policy) pairs to establish an efficient transfer pipeline. Our algorithm is inspired by the principles of Contrastive Language-Image Pretraining (CLIP) in Computer Vision, which aligns representations across different modalities under the philosophy that ''two modalities representing the same concept should have similar representations.'' The central idea here is that the instruction and corresponding policy of a task represent the same concept, the task itself, in two different modalities. Therefore, by extending the idea of CLIP to RL, our method creates a unified representation space for natural language and policy embeddings. Experimental results demonstrate the utility of our algorithm in achieving faster transfer across tasks.

</details>


### [296] [Probabilistic Neuro-Symbolic Reasoning for Sparse Historical Data: A Framework Integrating Bayesian Inference, Causal Models, and Game-Theoretic Allocation](https://arxiv.org/abs/2512.01723)
*Saba Kublashvili*

Main category: cs.AI

TL;DR: HistoricalML是一个结合贝叶斯、因果模型、博弈论和神经网络的框架，解决了历史建模中的数据稀缺和可解释性问题，并在两个历史案例中验证了其效果。


<details>
  <summary>Details</summary>
Motivation: 历史事件建模面临数据稀缺、噪声测量、缺失反事实和需人类可解释性等挑战，需要一种综合方法来解决这些问题。

Method: 结合贝叶斯不确定性量化、结构因果模型、合作博弈论（Shapley值）和注意力神经网络，构建了一个概率神经符号框架。

Result: 在非洲分割和第二次布匿战争两个案例中，模型成功量化了结构性紧张关系（如德国在WWI前的107.9%差异），并通过反事实分析揭示了关键因素（如迦太基的政治支持）。

Conclusion: HistoricalML框架通过整合贝叶斯不确定性量化、结构因果模型、合作博弈论和注意力神经网络，成功解决了历史事件建模中的数据稀缺、噪声测量、缺失反事实和可解释性等挑战，并在两个历史案例中验证了其有效性。

Abstract: Modeling historical events poses fundamental challenges for machine learning: extreme data scarcity (N << 100), heterogeneous and noisy measurements, missing counterfactuals, and the requirement for human interpretable explanations. We present HistoricalML, a probabilistic neuro-symbolic framework that addresses these challenges through principled integration of (1) Bayesian uncertainty quantification to separate epistemic from aleatoric uncertainty, (2) structural causal models for counterfactual reasoning under confounding, (3) cooperative game theory (Shapley values) for fair allocation modeling, and (4) attention based neural architectures for context dependent factor weighting. We provide theoretical analysis showing that our approach achieves consistent estimation in the sparse data regime when strong priors from domain knowledge are available, and that Shapley based allocation satisfies axiomatic fairness guarantees that pure regression approaches cannot provide. We instantiate the framework on two historical case studies: the 19th century partition of Africa (N = 7 colonial powers) and the Second Punic War (N = 2 factions). Our model identifies Germany's +107.9 percent discrepancy as a quantifiable structural tension preceding World War I, with tension factor 36.43 and 0.79 naval arms race correlation. For the Punic Wars, Monte Carlo battle simulations achieve a 57.3 percent win probability for Carthage at Cannae and 57.8 percent for Rome at Zama, aligning with historical outcomes. Counterfactual analysis reveals that Carthaginian political support (support score 6.4 vs Napoleon's 7.1), rather than military capability, was the decisive factor.

</details>


### [297] [Who Judges the Judge? LLM Jury-on-Demand: Building Trustworthy LLM Evaluation Systems](https://arxiv.org/abs/2512.01786)
*Xiaochuan Li,Ke Wang,Girija Gouda,Shubham Choudhary,Yaqun Wang,Linwei Hu,Joel Vaughan,Freddy Lecue*

Main category: cs.AI

TL;DR: LLM Jury-on-Demand框架通过动态选择和加权聚合可靠LLM法官的评分，显著提升评估与人类判断的相关性，适用于高风险领域。


<details>
  <summary>Details</summary>
Motivation: 解决现有LLM评估方法中人类评估成本高、单LLM法官存在偏见、静态陪审团缺乏适应性的问题，以构建可扩展且可靠的评估系统。

Method: 提出LLM Jury-on-Demand框架，训练一组可靠性预测器，利用令牌分布、嵌入和结构输入特征来评估LLM法官与人类专家的一致性，动态选择最优法官团队并加权聚合评分。

Result: 在摘要和RAG基准测试中，动态陪审团系统比单法官和静态陪审团基线显著提高了与人类判断的相关性。

Conclusion: LLM Jury-on-Demand框架通过动态选择最可靠的评估者并加权聚合其评分，显著提高了与人类判断的相关性，为高风险领域中的LLM评估提供了可扩展且可靠的解决方案。

Abstract: As Large Language Models (LLMs) become integrated into high-stakes domains, there is a growing need for evaluation methods that are both scalable for real-time deployment and reliable for critical decision-making. While human evaluation is reliable, it is slow and costly. Single LLM judges are biased, and static juries lack adaptability. To overcome these limitations, we propose LLM Jury-on-Demand - a dynamic, learning-based framework for scalable and context-aware evaluation. Our method trains a set of reliability predictors to assess when LLM judges will agree with human experts, leveraging token distributions, embeddings, and structural input features. This enables a fully adaptive evaluation where, for each data point, an optimal jury of the most reliable judges is dynamically selected, and their scores are aggregated using their reliability as weights. Experiments on summarization and RAG benchmarks show that our dynamic jury system achieves significantly higher correlation with human judgment than both single-judge and static-jury baselines. These results highlight the promise of adaptive, learning-based juries for building scalable, more reliable and trustworthy evaluation systems for modern LLMs in high-stakes domains.

</details>


### [298] [H-Neurons: On the Existence, Impact, and Origin of Hallucination-Associated Neurons](https://arxiv.org/abs/2512.01797)
*Cheng Gao,Huimin Chen,Chaojun Xiao,Zhiyi Chen,Zhiyuan Liu,Maosong Sun*

Main category: cs.AI

TL;DR: 论文系统研究了LLM中幻觉相关神经元（H-Neurons），发现极稀疏神经元子集能预测幻觉，与过度顺从行为因果相关，且源自预训练阶段，为提升LLM可靠性提供微观机制见解。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）常产生幻觉（看似合理但事实错误的输出），降低其可靠性。现有研究多从宏观角度（如训练数据和目标）分析幻觉，但神经元级机制尚未深入探索。

Method: 研究从三个角度展开：1）识别H-Neurons，发现极稀疏的神经元子集（少于总神经元的0.1%）能可靠预测幻觉发生；2）行为影响分析，通过干预实验证明这些神经元与过度顺从行为有因果关联；3）起源探究，追踪到这些神经元源自预训练基础模型，且仍能预测幻觉检测。

Result: 研究发现：1）H-Neurons稀疏但能跨场景泛化预测幻觉；2）干预实验证实其与过度顺从行为因果相关；3）这些神经元源自预训练阶段且保持预测能力。

Conclusion: 本研究通过识别、行为影响和起源三个角度系统研究了LLM中的幻觉相关神经元（H-Neurons），将宏观行为模式与微观神经机制联系起来，为开发更可靠的LLM提供了见解。

Abstract: Large language models (LLMs) frequently generate hallucinations -- plausible but factually incorrect outputs -- undermining their reliability. While prior work has examined hallucinations from macroscopic perspectives such as training data and objectives, the underlying neuron-level mechanisms remain largely unexplored. In this paper, we conduct a systematic investigation into hallucination-associated neurons (H-Neurons) in LLMs from three perspectives: identification, behavioral impact, and origins. Regarding their identification, we demonstrate that a remarkably sparse subset of neurons (less than $0.1\%$ of total neurons) can reliably predict hallucination occurrences, with strong generalization across diverse scenarios. In terms of behavioral impact, controlled interventions reveal that these neurons are causally linked to over-compliance behaviors. Concerning their origins, we trace these neurons back to the pre-trained base models and find that these neurons remain predictive for hallucination detection, indicating they emerge during pre-training. Our findings bridge macroscopic behavioral patterns with microscopic neural mechanisms, offering insights for developing more reliable LLMs.

</details>


### [299] [Testing Transformer Learnability on the Arithmetic Sequence of Rooted Trees](https://arxiv.org/abs/2512.01870)
*Alessandro Breccia,Federica Gerace,Marco Lippi,Gabriele Sicuro,Pierluigi Contucci*

Main category: cs.AI

TL;DR: 研究发现GPT-2模型能部分学习由自然数质因数分解生成的树序列的内部语法，表明学习能力可扩展到算术结构。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型是否能学习由自然数迭代质因数生成的确定性树序列，并测试其是否能捕捉算术文本的统计结构。

Method: 使用GPT-2架构的Transformer网络从头开始训练，训练数据为前10^11个元素，随后测试其在下一个词和掩码词预测任务中的预测能力。

Result: 模型部分学习了序列的内部语法，捕捉到非平凡的规律性和相关性。

Conclusion: 研究表明，大型语言模型能够部分学习由自然数迭代质因数分解生成的确定性树序列的内部语法，捕捉到非平凡的规律性和相关性。这表明学习能力可能不仅限于经验数据，还能扩展到算术结构本身。

Abstract: We study whether a Large Language Model can learn the deterministic sequence of trees generated by the iterated prime factorization of the natural numbers. Each integer is mapped into a rooted planar tree and the resulting sequence $ \mathbb{N}\mathcal{T}$ defines an arithmetic text with measurable statistical structure. A transformer network (the GPT-2 architecture) is trained from scratch on the first $10^{11}$ elements to subsequently test its predictive ability under next-word and masked-word prediction tasks. Our results show that the model partially learns the internal grammar of $\mathbb{N}\mathcal{T}$, capturing non-trivial regularities and correlations. This suggests that learnability may extend beyond empirical data to the very structure of arithmetic.

</details>


### [300] [Graph Distance as Surprise: Free Energy Minimization in Knowledge Graph Reasoning](https://arxiv.org/abs/2512.01878)
*Gaganpreet Jhajj,Fuhua Lin*

Main category: cs.AI

TL;DR: 该研究提出用图距离度量惊奇，将自由能原理应用于知识图谱推理，为相关领域提供新视角。


<details>
  <summary>Details</summary>
Motivation: 将神经科学中的自由能原理（FEP）与知识图谱系统连接，探索图距离在惊奇最小化中的作用。

Method: 通过在有向图中使用最短路径距离来形式化惊奇，并构建了基于知识图谱的智能体框架。

Result: 研究表明图距离可以作为惊奇度量的基础，并可能扩展到语法树结构中的惊奇最小化研究。

Conclusion: 该研究初步探索了基于距离的惊奇最小化在知识图谱推理中的潜力，为未来研究提供了框架。

Abstract: In this work, we propose that reasoning in knowledge graph (KG) networks can be guided by surprise minimization. Entities that are close in graph distance will have lower surprise than those farther apart. This connects the Free Energy Principle (FEP) from neuroscience to KG systems, where the KG serves as the agent's generative model. We formalize surprise using the shortest-path distance in directed graphs and provide a framework for KG-based agents. Graph distance appears in graph neural networks as message passing depth and in model-based reinforcement learning as world model trajectories. This work-in-progress study explores whether distance-based surprise can extend recent work showing that syntax minimizes surprise and free energy via tree structures.

</details>


### [301] [Predicting Human Chess Moves: An AI Assisted Analysis of Chess Games Using Skill-group Specific n-gram Language Models](https://arxiv.org/abs/2512.01880)
*Daren Zhong,Dingcheng Huang,Clayton Greenberg*

Main category: cs.AI

TL;DR: 提出基于n-gram语言模型的象棋走法预测框架，分技能级别训练，显著提升预测准确性和计算效率。


<details>
  <summary>Details</summary>
Motivation: 传统象棋引擎忽略人类玩家在不同技能级别下的走法变异性，需一种更贴近人类行为的预测方法。

Method: 使用n-gram语言模型捕捉不同技能级别玩家的走法模式，动态选择最合适的模型进行预测。

Result: 模型选择器在早期游戏信息下分类技能级别的准确率达31.7%，走法预测框架的Selector Assisted Accuracy比基准准确率高39.1%。

Conclusion: 该论文提出了一种基于行为分析的象棋走法预测框架，通过分技能级别训练n-gram语言模型，显著提高了预测准确性，并展示了计算效率。

Abstract: Chess, a deterministic game with perfect information, has long served as a benchmark for studying strategic decision-making and artificial intelligence. Traditional chess engines or tools for analysis primarily focus on calculating optimal moves, often neglecting the variability inherent in human chess playing, particularly across different skill levels.
  To overcome this limitation, we propose a novel and computationally efficient move prediction framework that approaches chess move prediction as a behavioral analysis task. The framework employs n-gram language models to capture move patterns characteristic of specific player skill levels. By dividing players into seven distinct skill groups, from novice to expert, we trained separate models using data from the open-source chess platform Lichess. The framework dynamically selects the most suitable model for prediction tasks and generates player moves based on preceding sequences.
  Evaluation on real-world game data demonstrates that the model selector module within the framework can classify skill levels with an accuracy of up to 31.7\% when utilizing early game information (16 half-moves). The move prediction framework also shows substantial accuracy improvements, with our Selector Assisted Accuracy being up to 39.1\% more accurate than our benchmark accuracy. The computational efficiency of the framework further enhances its suitability for real-time chess analysis.

</details>


### [302] [Learned-Rule-Augmented Large Language Model Evaluators](https://arxiv.org/abs/2512.01958)
*Jie Meng,Jin Mao*

Main category: cs.AI

TL;DR: 本文提出规则增强的LLM评估范式，通过自动规则蒸馏和两种应用策略，解决了现有方法的泛化问题。


<details>
  <summary>Details</summary>
Motivation: 现有LLM评估器依赖人工设计的评估原则，成本高且与数据和LLM理解不一致，限制了其泛化能力。

Method: 采用LLM辅助的蒙特卡洛树搜索（MCTS）进行规则蒸馏，并提出了Chain-of-Rule（CoR）和规则增强的LLM评估器（RuAE）两种策略。

Result: 在多样化任务上的实验证明了该方法的有效性和泛化能力。

Conclusion: 本研究提出了一种规则增强的评估范式，通过规则蒸馏方法和两种应用策略（CoR和RuAE），显著提升了LLM作为通用评估器的效果和泛化能力。

Abstract: Large language models (LLMs) are predominantly used as evaluators for natural language generation (NLG) tasks, but their application to broader evaluation scenarios remains limited. In this work, we explore the potential of LLMs as general evaluators across diverse tasks. Although LLM-based evaluators have made progress in different areas, existing methods struggle to generalize due to their reliance on costly, human-designed evaluation principles, which are often misaligned with both annotated data and LLMs' understanding.To address these challenges, we propose a rule-augmented evaluation paradigm. First, we introduce a rule distillation method that automatically extracts scoring rules from data using an LLM-assisted Monte Carlo Tree Search (MCTS), alleviating scalability issues and improving alignment with data. Second, to enable LLMs to effectively apply the learned rules, we propose two strategies: (1) Chain-of-Rule (CoR), which guides LLM to follow distilled rules, and (2) training a rule-augmented LLM evaluator (RuAE) via reinforcement learning, further bridging the gap between rules and LLMs' reasoning. Extensive experiments on diverse tasks demonstrate the effectiveness and generalizability of our approach across various evaluation scenarios.

</details>


### [303] [From Atomic to Composite: Reinforcement Learning Enables Generalization in Complementary Reasoning](https://arxiv.org/abs/2512.01970)
*Sitao Cheng,Xunjian Yin,Ruiwen Zhou,Yuxuan Li,Xinyi Wang,Liangming Pan,William Yang Wang,Victor Zhong*

Main category: cs.AI

TL;DR: RL在原子技能基础上能合成复杂推理策略，而非仅放大行为。SFT泛化存在悖论：分布内表现优异但分布外崩溃，而RL需原子技能前提才能有效合成策略。


<details>
  <summary>Details</summary>
Motivation: 探讨RL对推理能力的贡献机制，即其是激励新技能的合成还是仅放大现有行为。

Method: 通过控制合成的人类传记数据集，将互补推理能力严格解耦为两个原子技能：参数化推理（依赖内部知识）和上下文推理（依赖外部信息）。在三种不同难度级别（I.I.D.、组合和零样本设置）下评估泛化能力。

Result: 发现SFT（监督微调）在分布内表现良好，但在分布外泛化（尤其是零样本设置）中表现不佳，揭示了其依赖路径捷径的机械记忆。RL则表现为推理合成器，但需以原子技能的掌握为前提。

Conclusion: 研究表明，RL（强化学习）在具备原子技能基础（通过SFT掌握）的情况下，能够主动合成复杂推理策略，而非仅放大现有行为。这为复杂推理任务的泛化提供了一条可扩展的路径。

Abstract: The mechanism by which RL contributes to reasoning capabilities-whether it incentivizes the synthesis of new skills or merely amplifies existing behaviors-remains a subject of intense debate. In this work, we investigate this question through the lens of Complementary Reasoning, a complex task that requires integrating internal parametric knowledge with external contextual information. Using a controlled synthetic dataset of human biographies, we strictly decouple this ability into two atomic skills: Parametric Reasoning (relying on internal knowledge) and Contextual Reasoning (depending on external information). To rigorously assess capability boundaries, we evaluate generalization across three distinct levels of difficulty: I.I.D., Composition, and Zero-shot settings. We find that while SFT is sufficient for in-distribution performance, it struggles with O.O.D. generalization, particularly in Zero-shot settings where relational combinations are novel. Crucially, we identify the SFT Generalization Paradox: Models supervised solely on the composite task achieve near-perfect in-distribution accuracy but collapse on out-of-distribution generalization, indicating their reliance on rote memorization of path shortcuts. In contrast, we find that RL acts as a reasoning synthesizer rather than a probability amplifier. However, we uncover a strict atomic prerequisite: RL can only synthesize these complex strategies if the base model has first mastered the independent atomic skills (Parametric and Contextual) via SFT. These findings challenge the view of RL as a mere amplifier, suggesting that given sufficient atomic foundations, RL can actively synthesize complex reasoning strategies from learned primitives without explicit supervision on such complex strategies. This indicates that decoupled atomic training followed by RL offers a scalable path to generalization for complex reasoning tasks.

</details>


### [304] [Chain-of-Ground: Improving GUI Grounding via Iterative Reasoning and Reference Feedback](https://arxiv.org/abs/2512.01979)
*Aiden Yiliu Li,Bizhi Yu,Daoan Lei,Tianhe Ren,Shilong Liu*

Main category: cs.AI

TL;DR: CoG通过迭代精炼提升GUI grounding准确性，无需额外训练，在真实和数字界面中均表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有多模态大语言模型在GUI grounding中因有限grounding能力和未充分利用推理潜力而导致的小目标、视觉相似目标和布局歧义问题。

Method: 提出了Chain of Ground (CoG)，一个无需训练的多步grounding框架，利用多模态大语言模型进行迭代视觉推理和精炼。

Result: 在ScreenSpot Pro基准测试中达到68.4%准确率（提升4.8点）；在TPanel UI数据集上比Qwen3 VL 235B基线提升6.9点。

Conclusion: Chain of Ground (CoG)框架通过多步视觉推理和精炼，无需额外训练即可显著提升GUI grounding的准确性和可解释性，展示了在真实世界和数字界面中的泛化能力。

Abstract: GUI grounding aims to align natural language instructions with precise regions in complex user interfaces. Advanced multimodal large language models show strong ability in visual GUI grounding but still struggle with small or visually similar targets and ambiguity in real world layouts. These limitations arise from limited grounding capacity and from underuse of existing reasoning potential. We present Chain of Ground CoG a training free multi step grounding framework that uses multimodal large language models for iterative visual reasoning and refinement. Instead of direct prediction the model progressively reflects and adjusts its hypotheses leading to more accurate and interpretable localization. Our approach achieves 68.4 accuracy on the ScreenSpot Pro benchmark an improvement of 4.8 points. To measure real world generalization we introduce TPanel UI a dataset of 420 labeled industrial control panels with visual distortions such as blur and masking. On TPanel UI Chain of Ground improves over the strong baseline Qwen3 VL 235B by 6.9 points showing the effectiveness of multi step training free grounding across real world and digital interfaces. These results highlight a direction for unlocking grounding potential through structured iterative refinement instead of additional training.

</details>


### [305] [LLM CHESS: Benchmarking Reasoning and Instruction-Following in LLMs through Chess](https://arxiv.org/abs/2512.01992)
*Sai Kolasani,Maxim Saplin,Nicholas Crispino,Kyle Montgomery,Jared Quincy Davis,Matei Zaharia,Chi Wang,Chenguang Wang*

Main category: cs.AI

TL;DR: LLM CHESS是一个通过象棋对弈评估LLMs推理和指令遵循能力的框架，揭示了模型在此类任务中的局限性，并提供了实验框架、排行榜和游戏数据集。


<details>
  <summary>Details</summary>
Motivation: 探究LLMs在复杂推理和指令遵循任务中的泛化能力，并解决现有静态基准测试中的过拟合和记忆问题。

Method: 通过随机对手对弈，使用包括胜率、移动质量、合法性、幻觉动作和游戏时长等行为指标，对50多个开源和闭源模型进行排名。对部分顶级推理模型，通过配置不同技能的象棋引擎对弈，得出Elo估计值。

Result: 实验显示，许多最先进的模型在完成游戏或取得稳定胜利方面表现不佳，且推理与非推理模型之间存在明显区分。LLM CHESS的动态特性减少了过拟合和记忆，对顶级推理模型也具有挑战性。

Conclusion: LLM CHESS框架通过象棋领域的扩展代理交互，有效评估了大型语言模型（LLMs）的推理和指令遵循能力的泛化性，并揭示了现有模型在此类任务中的局限性。

Abstract: We introduce LLM CHESS, an evaluation framework designed to probe the generalization of reasoning and instruction-following abilities in large language models (LLMs) through extended agentic interaction in the domain of chess. We rank over 50 open and closed source models by playing against a random opponent using a range of behavioral metrics, including win and loss rates, move quality, move legality, hallucinated actions, and game duration. For a subset of top reasoning models, we derive an Elo estimate by playing against a chess engine with variably configured skill, which allows for comparisons between models in an easily understandable way. Despite the simplicity of the instruction-following task and the weakness of the opponent, many state-of-the-art models struggle to complete games or achieve consistent wins. Similar to other benchmarks on complex reasoning tasks, our experiments reveal a clear separation between reasoning and non-reasoning models. However, unlike existing static benchmarks, the stochastic and dynamic nature of LLM CHESS uniquely reduces overfitting and memorization while preventing benchmark saturation, proving difficult even for top reasoning models. To support future work on evaluating reasoning and instruction-following in LLMs, we release our experimental framework, a public leaderboard, and a dataset of associated games.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [306] [Trust or Bust: A Survey of Threats in Decentralized Wireless Networks](https://arxiv.org/abs/2512.00023)
*Hetvi Shastri,Akanksha Atrey,Andre Beck,Nirupama Ravi*

Main category: cs.NI

TL;DR: 本文研究了去中心化无线网络中的对抗行为，提出了分类法，并发现此类行为可能显著增加提供者收益，呼吁开发新技术以应对。


<details>
  <summary>Details</summary>
Motivation: 去中心化无线网络中的实体可能因缺乏传统信任基础而滥用服务以谋取私利，例如热点运营商故意违反协议条款以增加利润。

Method: 本文研究并开发了去中心化无线网络中对抗行为模式的分类法。

Result: 案例研究发现，提供者驱动的攻击可能使提供者收益增加三倍以上。

Conclusion: 论文强调了开发新技术以检测和缓解去中心化无线网络中对抗行为的紧迫性。

Abstract: The recent emergence of decentralized wireless networks empowers individual entities to own, operate, and offer subscriptionless connectivity services in exchange for monetary compensation. While traditional connectivity providers have built trust over decades through widespread adoption, established practices, and regulation, entities in a decentralized wireless network, lacking this foundation, may be incentivized to exploit the service for their own advantage. For example, a dishonest hotspot operator can intentionally violate the agreed upon connection terms in an attempt to increase their profits. In this paper, we examine and develop a taxonomy of adversarial behavior patterns in decentralized wireless networks. Our case study finds that provider-driven attacks can potentially more than triple provider earnings. We conclude the paper with a discussion on the critical need to develop novel techniques to detect and mitigate adversarial behavior in decentralized wireless networks.

</details>


### [307] [Multi-Server FL with Overlapping Clients: A Latency-Aware Relay Framework](https://arxiv.org/abs/2512.00025)
*Yun Ji,Zeyu Chen,Xiaoxiong Zhong,Yanan Ma,Sheng Zhang,Yuguang Fang*

Main category: cs.NI

TL;DR: 论文提出了一种无云多服务器联邦学习框架，利用重叠客户端作为中继进行服务器间模型交换，实验显示其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多服务器联邦学习（FL）是缓解单服务器FL通信瓶颈的有前景方案。在典型的多服务器FL架构中，不同边缘服务器（ESs）覆盖的区域可能重叠，位于重叠区域的客户端可以访问多个ES的模型。基于此观察，作者提出利用重叠客户端作为中继进行服务器间模型交换。

Method: 作者开发了一种基于冲突图的局部搜索算法，优化路由策略并调度各服务器到其邻居服务器的传输时间，以实现模型的最广泛传播。

Result: 实验结果显示，该方案相比现有方法有显著性能提升。

Conclusion: 论文提出了一种无云多服务器联邦学习框架，通过重叠客户端（OCs）作为服务器间模型交换的中继，无需引入新的通信链路即可实现模型在多跳邻居服务器间的传播。实验结果表明，该方案相比现有方法有显著性能提升。

Abstract: Multi-server Federated Learning (FL) has emerged as a promising solution to mitigate communication bottlenecks of single-server FL. In a typical multi-server FL architecture, the regions covered by different edge servers (ESs) may overlap. Under this architecture, clients located in the overlapping areas can access edge models from multiple ESs. Building on this observation, we propose a cloud-free multi-server FL framework that leverages Overlapping Clients (OCs) as relays for inter-server model exchange while uploading the local updated model to ESs. This enables ES models to be relayed across multiple hops through neighboring ESs by OCs without introducing new communication links. We derive a new convergence upper bound for non-convex objectives under non-IID data and an arbitrary number of cells, which explicitly quantifies the impact of inter-server propagation depth on convergence error. Guided by this theoretical result, we formulate an optimization problem that aims to maximize dissemination range of each ES model among all ESs within a limited latency. To solve this problem, we develop a conflict-graph-based local search algorithm optimizing the routing strategy and scheduling the transmission times of individual ESs to its neighboring ESs. This enables ES models to be relayed across multiple hops through neighboring ESs by OCs, achieving the widest possible transmission coverage for each model without introducing new communication links. Extensive experimental results show remarkable performance gains of our scheme compared to existing methods.

</details>


### [308] [An optimization framework for task allocation in the edge/hub/cloud paradigm](https://arxiv.org/abs/2512.00029)
*Andreas Kouloumpris,Georgios L. Stavrinides,Maria K. Michael,Theocharis Theocharides*

Main category: cs.NI

TL;DR: 论文提出了一种BILP框架，用于优化边缘/中心/云环境中的任务分配，实验证明其在延迟和能耗方面表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着物联网（IoT）的发展，边缘/中心/云架构中的任务分配面临计算、通信和能耗限制的挑战，需要一种全面的优化框架。

Method: 采用二进制整数线性规划（BILP）方法，结合设计时优化策略，综合考虑计算、通信和能耗限制。

Result: 实验结果表明，所提方法在真实用例和合成基准测试中均能实现最优且可扩展的任务分配。

Conclusion: 该论文提出了一种基于二进制整数线性规划（BILP）的优化框架，用于在边缘/中心/云环境中实现高效的任务分配，实验证明该方法在延迟和能耗方面均能提供最优且可扩展的解决方案。

Abstract: With the advent of the Internet of Things (IoT), novel critical applications have emerged that leverage the edge/hub/cloud paradigm, which diverges from the conventional edge computing perspective. A growing number of such applications require a streamlined architecture for their effective execution, often comprising a single edge device with sensing capabilities, a single hub device (e.g., a laptop or smartphone) for managing and assisting the edge device, and a more computationally capable cloud server. Typical examples include the utilization of an unmanned aerial vehicle (UAV) for critical infrastructure inspection or a wearable biomedical device (e.g., a smartwatch) for remote patient monitoring. Task allocation in this streamlined architecture is particularly challenging, due to the computational, communication, and energy limitations of the devices at the network edge. Consequently, there is a need for a comprehensive framework that can address the specific task allocation problem optimally and efficiently. To this end, we propose a complete, binary integer linear programming (BILP) based formulation for an application-driven design-time approach, capable of providing an optimal task allocation in the targeted edge/hub/cloud environment. The proposed method minimizes the desired objective, either the overall latency or overall energy consumption, while considering several crucial parameters and constraints often overlooked in related literature. We evaluate our framework using a real-world use-case scenario, as well as appropriate synthetic benchmarks. Our extensive experimentation reveals that the proposed approach yields optimal and scalable results, enabling efficient design space exploration for different applications and computational devices.

</details>


### [309] [Refined Bayesian Optimization for Efficient Beam Alignment in Intelligent Indoor Wireless Environments](https://arxiv.org/abs/2512.00036)
*Parth Ashokbhai Shiroya,Amod Ashtekar,Swarnagowri Shashidhar,Mohammed E. Eltayeb*

Main category: cs.NI

TL;DR: R-BO框架通过高斯过程和局部细化，在室内环境中高效实现高精度波束对准，显著减少探测开销。


<details>
  <summary>Details</summary>
Motivation: 室内环境中密集散射体和收发器硬件缺陷导致多径和旁瓣泄漏，降低了室外导向对准算法的有效性，需要快速可靠的波束对准以维持高吞吐量链接。

Method: 采用高斯过程（GP）代理模型结合Matern核和期望改进（EI）获取函数，随后在预测最优解附近进行局部细化。GP超参数在线重新优化以适应由反射和旁瓣泄漏引起的不规则角度功率场变化。

Result: 在43个接收器位置的实验中，R-BO实现了97.7%的波束对准精度（误差在10度内），平均损耗小于0.3 dB，探测开销比穷举搜索减少了88%。

Conclusion: R-BO框架在实时智能室内无线环境中表现出高效和自适应性，显著减少了探测开销并保持了高精度的波束对准。

Abstract: Future intelligent indoor wireless environments re- quire fast and reliable beam alignment to sustain high-throughput links under mobility and blockage. Exhaustive beam training achieves optimal performance but is prohibitively costly. In indoor settings, dense scatterers and transceiver hardware imperfections introduce multipath and sidelobe leakage, producing measurable power across multiple angles and reducing the effectiveness of outdoor-oriented alignment algorithms. This paper presents a Refined Bayesian Optimization (R-BO) framework that exploits the inherent structure of mmWave transceiver patterns, where received power gradually increases as the transmit and receive beams converge toward the optimum. R-BO integrates a Gaussian Process (GP) surrogate with a Matern kernel and an Expected Improvement (EI) acquisition function, followed by a localized refinement around the predicted optimum. The GP hyperparam- eters are re-optimized online to adapt to irregular variations in the measured angular power field caused by reflections and sidelobe leakage. Experiments across 43 receiver positions in an indoor laboratory demonstrate 97.7% beam-alignment accuracy within 10 degrees, less than 0.3 dB average loss, and an 88% reduction in probing overhead compared to exhaustive search. These results establish R-BO as an efficient and adaptive beam-alignment solution for real-time intelligent indoor wireless environments.

</details>


### [310] [LM4Opt-RA: A Multi-Candidate LLM Framework with Structured Ranking for Automating Network Resource Allocation](https://arxiv.org/abs/2512.00039)
*Tasnim Ahmed,Siana Rizwan,Naveed Ejaz,Salimur Choudhury*

Main category: cs.NI

TL;DR: 论文提出NL4RA数据集和LM4Opt RA框架，评估LLM在资源分配优化任务中的表现，并引入LAME自动评分指标，结果显示Llama-3.1-70B表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有基准和数据集无法解决动态环境、相互依赖变量和异构约束等复杂问题，因此需要新的数据集和方法来评估LLM在资源分配优化任务中的表现。

Method: 引入LM4Opt RA，一个多候选框架，结合直接、少量示例和思维链等多样化提示策略，以及结构化排名机制以提高准确性。

Result: 使用LM4Opt-RA，Llama-3.1-70B的LAME得分为0.8007，显著优于其他模型，紧随其后的是Llama-3.1-8B。

Conclusion: 尽管基线LLM显示出巨大潜力，但仍落后于人类专家；本文提出的方法在LAME和其他指标上超越了这些基线。

Abstract: Building on advancements in Large Language Models (LLMs), we can tackle complex analytical and mathematical reasoning tasks requiring nuanced contextual understanding. A prime example of such complex tasks is modelling resource allocation optimization in networks, which extends beyond translating natural language inputs into mathematical equations or Linear Programming (LP), Integer Linear Programming (ILP), and Mixed-Integer Linear Programming (MILP) models. However, existing benchmarks and datasets cannot address the complexities of such problems with dynamic environments, interdependent variables, and heterogeneous constraints. To address this gap, we introduce NL4RA, a curated dataset comprising 50 resource allocation optimization problems formulated as LP, ILP, and MILP. We then evaluate the performance of well-known open-source LLMs with varying parameter counts. To enhance existing LLM based methods, we introduce LM4Opt RA, a multi candidate framework that applies diverse prompting strategies such as direct, few shot, and chain of thought, combined with a structured ranking mechanism to improve accuracy. We identified discrepancies between human judgments and automated scoring such as ROUGE, BLEU, or BERT scores. However, human evaluation is time-consuming and requires specialized expertise, making it impractical for a fully automated end-to-end framework. To quantify the difference between LLM-generated responses and ground truth, we introduce LLM-Assisted Mathematical Evaluation (LAME), an automated metric designed for mathematical formulations. Using LM4Opt-RA, Llama-3.1-70B achieved a LAME score of 0.8007, outperforming other models by a significant margin, followed closely by Llama-3.1-8B. While baseline LLMs demonstrate considerable promise, they still lag behind human expertise; our proposed method surpasses these baselines regarding LAME and other metrics.

</details>


### [311] [Constrained Network Slice Assignment via Large Language Models](https://arxiv.org/abs/2512.00040)
*Sagar Sudhakara,Pankaj Rajak*

Main category: cs.NI

TL;DR: LLMs assist in 5G network slicing by providing initial slice assignments and semantic insights, improving efficiency when combined with traditional solvers.


<details>
  <summary>Details</summary>
Motivation: To simplify the complex optimization problem of allocating users to network slices by leveraging LLMs' capabilities.

Method: Two approaches are explored: (1) zero-shot LLM for direct slice assignment, and (2) LLM-assisted integer programming model for semantic insight.

Result: LLM, even in zero-shot, provides reasonable slice assignments but may violate constraints. Combined with optimization solvers, it achieves performance similar to traditional methods.

Conclusion: LLM-guided grouping of requests, combined with exact solvers, offers a promising approach for efficient 5G network slicing resource allocation, achieving performance comparable to traditional methods.

Abstract: Modern networks support network slicing, which partitions physical infrastructure into virtual slices tailored to different service requirements (for example, high bandwidth or low latency). Optimally allocating users to slices is a constrained optimization problem that traditionally requires complex algorithms. In this paper, we explore the use of Large Language Models (LLMs) to tackle radio resource allocation for network slicing. We focus on two approaches: (1) using an LLM in a zero-shot setting to directly assign user service requests to slices, and (2) formulating an integer programming model where the LLM provides semantic insight by estimating similarity between requests. Our experiments show that an LLM, even with zero-shot prompting, can produce a reasonable first draft of slice assignments, although it may violate some capacity or latency constraints. We then incorporate the LLM's understanding of service requirements into an optimization solver to generate an improved allocation. The results demonstrate that LLM-guided grouping of requests, based on minimal textual input, achieves performance comparable to traditional methods that use detailed numerical data, in terms of resource utilization and slice isolation. While the LLM alone does not perfectly satisfy all constraints, it significantly reduces the search space and, when combined with exact solvers, provides a promising approach for efficient 5G network slicing resource allocation.

</details>


### [312] [Mesh Augmentation of LoRaWAN-based IoT Networks](https://arxiv.org/abs/2512.00161)
*Ram Ramanathan,Dmitrii Dugaev,Liang Tan,Warren Ramanathan*

Main category: cs.NI

TL;DR: LIMA是一种协议，通过在LoRaWAN中引入网状网络，显著提高覆盖范围和能效，无需更改现有标准。


<details>
  <summary>Details</summary>
Motivation: LoRaWAN的单跳架构在大范围、偏远和射频挑战性环境中导致有效范围有限和终端设备能耗过高，现有解决方案要么与LoRaWAN不兼容，要么仅限于单跳中继。

Method: LIMA通过反向路径转发建立路由，将LoRaWAN消息通过LIMA隧道传输，透明扩展现有的自适应数据速率（ADR），并在设备可直接从网关到达时抑制重复转发。

Result: 模拟和原型测试显示，LIMA将交付率、可扩展性和终端设备能效分别提高了5倍、8倍和12.6倍，延迟降低了2.3倍。

Conclusion: LIMA协议成功地在现有或新的LoRaWAN部署中增加了网状网络功能，显著提高了覆盖范围和终端设备能效，且无需对终端设备、服务器或LoRaWAN标准进行任何更改。

Abstract: LoRaWAN is a leading standard and technology for low-power, long-range Internet-of-Things (IoT) communications. However, its single-hop architecture results in limited effective range and excessive power consumption for end devices, especially when deployed in large, remote and RF-challenged environments. Existing solutions are either incompatible with LoRaWAN, or limit relaying to a single hop. We present LIMA, a protocol for augmenting an existing or new LoRaWAN deployment with a mesh network of LIMA Routers. LIMA increases the effective coverage range well beyond the maximum LoRa range via multi-hopping, and significantly reduces the energy consumed by end-devices. LIMA requires no changes to the end-device, the servers or the LoRaWAN standard. LIMA builds routes using reverse path forwarding, tunnels LoRaWAN messages over LIMA, provides transparent extension of the existing Adaptive Data Rate (ADR), and suppresses duplicate forwarding if the device is directly reachable from the Gateway. Simulations using Network Simulator 3 (ns-3) show that LIMA increases the delivery rate, scalability, ED energy consumption by up to 5x, 8x and 12.6x respectively, and reduces latency by up to 2.3x. Table-top and outdoor testing with a prototype constructed using a commercial gateway as a starting point confirm that LIMA can be successfully deployed within an existing LoRaWAN system, and can provide range and energy gains transparently.

</details>


### [313] [On the Prediction of Wi-Fi Performance through Deep Learning](https://arxiv.org/abs/2512.00211)
*Gabriele Formis,Amanda Ericson,Stefan Forsstrom,Kyi Thar,Gianluca Cena,Stefano Scanzio*

Main category: cs.NI

TL;DR: 研究通过CNN和LSTM预测Wi-Fi帧交付率，CNN延迟更低，适合资源受限场景。


<details>
  <summary>Details</summary>
Motivation: 工业Wi-Fi网络需可靠通信，预测信道质量变化可提升系统鲁棒性。

Method: 采用CNN和LSTM模型，基于二进制时间序列预测FDR。

Result: 两种模型均能高精度预测FDR，CNN延迟更低但精度略逊于LSTM。

Conclusion: CNN和LSTM均能有效预测FDR，CNN在推理延迟上表现更优，适合资源受限系统。

Abstract: Ensuring reliable and predictable communications is one of the main goals in modern industrial systems that rely on Wi-Fi networks, especially in scenarios where continuity of operation and low latency are required. In these contexts, the ability to predict changes in wireless channel quality can enable adaptive strategies and significantly improve system robustness. This contribution focuses on the prediction of the Frame Delivery Ratio (FDR), a key metric that represents the percentage of successful transmissions, starting from time sequences of binary outcomes (success/failure) collected in a real scenario. The analysis focuses on two models of deep learning: a Convolutional Neural Network (CNN) and a Long Short-Term Memory network (LSTM), both selected for their ability to predict the outcome of time sequences. Models are compared in terms of prediction accuracy and computational complexity, with the aim of evaluating their applicability to systems with limited resources. Preliminary results show that both models are able to predict the evolution of the FDR with good accuracy, even from minimal information (a single binary sequence). In particular, CNN shows a significantly lower inference latency, with a marginal loss in accuracy compared to LSTM.

</details>


### [314] [Analysis of the operation of a TSN switch and other devices using executable QR codes](https://arxiv.org/abs/2512.00221)
*Stefano Scanzio,Pietro Chiavassa,Gianluca Cena*

Main category: cs.NI

TL;DR: 本文展示了可执行QR码（sQRy）在工业网络中的应用，详细描述了其生成和执行过程。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索可执行QR码在工业网络中的实际应用，特别是在无互联网连接时的设备状态监测。

Method: 通过具体示例详细描述了生成sQRy的整个生成链，以及从sQRy开始，在移动设备上运行的相应执行链。

Result: 成功展示了sQRy在工业网络中的实际应用，并通过示例详细说明了其生成和执行过程。

Conclusion: 本文展示了可执行QR码（sQRy）在工业网络中的应用，特别是在无互联网连接时通过分析TSN交换机的状态LED来评估其操作。

Abstract: Executable QR codes, also known as sQRy, are a technology aimed at inserting executable programs in a QR code. Through a concrete example, in this paper, we demonstrate their usage in the context of industrial networks in order to assess the operation of a TSN switch by analyzing its status LEDs even in the absence of an internet connection. The entire generation chain that is used to create the sQRy, as well as the corresponding execution chain that, starting from the sQRy, runs it on a mobile device, has been detailed through examples.

</details>


### [315] [Design and Evaluation of a Multi-Agent Perception System for Autonomous Flying Networks](https://arxiv.org/abs/2512.00259)
*Diogo Ferreira,Pedro Ribeiro,André Coelho,Rui Campos*

Main category: cs.NI

TL;DR: MAPS系统利用多模态AI技术，通过无人机数据自主感知用户需求，显著提升检测效率，支持零接触飞行网络。


<details>
  <summary>Details</summary>
Motivation: 当前方法主要关注无人机部署、路由和资源管理，忽视了用户及其服务需求的自主感知能力，这是实现零接触网络操作的关键。

Method: 利用多模态大型语言模型（MM-LLMs）和代理人工智能（AI），通过无人机收集的视觉和音频数据生成服务水平规范（SLSs），描述用户数量、空间分布和流量需求。

Result: 在合成多模态紧急数据集上的评估显示，用户检测准确率超过70%，90%的案例中SLS生成时间低于130秒。

Conclusion: MAPS系统通过结合视觉和音频模态，显著提升了用户检测的准确性，并能在130秒内生成90%的服务水平规范（SLS），为自主、零接触的飞行网络（FNs）提供了必要的感知层。

Abstract: Autonomous Flying Networks (FNs) are emerging as a key enabler of on-demand connectivity in dynamic and infrastructure-limited environments. However, current approaches mainly focus on UAV placement, routing, and resource management, neglecting the autonomous perception of users and their service demands - a critical capability for zero-touch network operation.
  This paper presents the Multi-Agent Perception System (MAPS), a modular and scalable system that leverages multi-modal large language models (MM-LLMs) and agentic Artificial Intelligence (AI) to interpret visual and audio data collected by UAVs and generate Service Level Specifications (SLSs) describing user count, spatial distribution, and traffic demand. MAPS is evaluated using a synthetic multimodal emergency dataset, achieving user detection accuracies above 70% and SLS generation under 130 seconds in 90% of cases. Results demonstrate that combining audio and visual modalities enhances user detection and show that MAPS provides the perception layer required for autonomous, zero-touch FNs.

</details>


### [316] [Smart-TCP: An Agentic AI-based Autonomous and Adaptive TCP Protocol](https://arxiv.org/abs/2512.00491)
*Yule Han,Kezhi Wang,Kun Yang*

Main category: cs.NI

TL;DR: Smart-TCP利用代理AI和LLM重新设计TCP控制逻辑，实验显示其成功率达93.33%，验证了技术可行性。


<details>
  <summary>Details</summary>
Motivation: 传统的基于硬编码状态机的TCP协议逻辑难以满足智能和自主网络架构的需求，因此需要一种更灵活、智能的解决方案。

Method: 采用基于大型语言模型（LLMs）的代理AI范式，结合上下文感知、自主推理和工具使用能力，设计了Smart-TCP架构，包括上下文聚合机制、LLM自主逻辑推理和调用算术逻辑单元（ALU）进行计算。

Result: Smart-TCP在端到端会话中实现了93.33%的成功率，显著提升了静态预测和错误检测的性能。

Conclusion: Smart-TCP通过基于代理AI的方法重新设计了TCP核心控制逻辑，实验验证了其在静态预测和错误检测方面的卓越性能，成功率达到93.33%，证明了基于代理AI的TCP协议的技术可行性。

Abstract: The Transmission Control Protocol (TCP) relies on a state machine and deterministic arithmetic to ensure reliable connections. However, traditional protocol logic driven by hard-coded state machines struggles to meet the demands of intelligent and autonomous network architectures. Here, we adopt the agentic AI-based paradigm, driven by Large Language Models (LLMs), characterized by context perception, autonomous reasoning, and tool use. Based on this, we propose Smart-TCP, which re-imagines TCP's core control logic as an autonomous agent. Specifically, the proposed architecture employs a context aggregation mechanism to synthesize the protocol context, utilizes the LLM for autonomous logical reasoning, and invokes an Arithmetic Logic Unit (ALU) as a tool for computation. Furthermore, we establish a dual-agent interaction framework based on this architecture and implement TCP protocol interactions. Experiments demonstrate that the Smart-TCP agent excels in static prediction and error detection, achieving a 93.33% success rate in end-to-end sessions. These results strongly validate the technical feasibility of an agentic AI-based TCP protocol.

</details>


### [317] [Improving Channel Estimation Through Gold Sequences](https://arxiv.org/abs/2512.00509)
*Sumita Majhi,Kaushal Shelke,Pinaki Mitra,Ujjwal Biswas*

Main category: cs.NI

TL;DR: 研究评估了结合Gold编码和C-V-BLAST的NOMA系统，提出新型信道估计方法，性能优于传统技术。


<details>
  <summary>Details</summary>
Motivation: NOMA系统中叠加信号在共享子载波上的用户分离困难，Gold序列的正交特性可能改善这一问题。

Method: 采用分数功率分配和部分解码数据符号的新型信道估计方法，并在AWGN、瑞利衰落和阴影效应的仿真环境中进行验证。

Result: 提出的信道预测函数（CPF）在结合导频信号、功率分配和数据符号的情况下，性能优于传统的基于导频的技术。

Conclusion: 本研究通过结合Gold编码和C-V-BLAST技术，提出了一种新型信道估计方法，显著提升了NOMA系统的用户分离和信道估计性能。

Abstract: This study evaluates Non-Orthogonal Multiple Access (NOMA) systems using Gold coding and Conventional-V-BLAST (C-V-BLAST). Superimposed signals on shared subcarriers make NOMA user separation difficult, unlike MIMO. Gold sequences' orthogonal features may enhance user separation and channel estimation. A novel channel estimation approach uses fractional power allocation and partially decoded data symbols. A realistic simulation environment was created using AWGN, Rayleigh fading, and shadowing. Using pilot signals, power allocation, and data symbols, our Channel Prediction Function (CPF) surpasses pilot-based techniques.

</details>


### [318] [LPWAN based IoT Architecture for Distributed Energy Monitoring in Deep Indoor Environments](https://arxiv.org/abs/2512.00998)
*Christof Röhrig,Benz Cramer*

Main category: cs.NI

TL;DR: 本文比较了多种LPWAN技术在建筑穿透和覆盖方面的性能，并提出了一种混合架构，通过抽象层优化成本和覆盖，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于能源表通常位于难以通过无线技术到达的地下空间，因此需要一种有效的LPWAN技术来支持连续能源监测。

Method: 本研究通过实验比较了LoRaWAN、NB-IoT、Sigfox 0G和Wi-SUN等LPWAN技术的建筑穿透和无线电覆盖性能，并提出了一个基于MQTT协议的发布-订阅消息模式的分布式混合物联网架构。

Result: 实验结果表明，提出的混合架构在建筑穿透和无线电覆盖方面表现良好，能够有效支持能源监测。

Conclusion: 本文提出了一种分布式混合物联网架构，通过抽象层结合多种LPWAN技术，优化了成本和覆盖范围。实验结果表明，该架构在建筑穿透和无线电覆盖方面表现良好。

Abstract: Continuous energy monitoring is essential for identifying potential savings and predicting the energy requirements of buildings. Energy meters are often located in underground spaces that are difficult to reach with wireless technology. This paper presents an experimental study comparing different Low Power Wide Area Networks (LPWAN) technologies in terms of building penetration and radio coverage. The technologies Low Power Long Range Wide Area Networks (LoRaWAN), Narrow Band Internet of Things (NB-IoT), Sigfox 0G and Wireless Smart Ubiquitous Networks (Wi-SUN) are evaluated experimentally. It also proposes a distributed hybrid IoT architecture that combines multiple LPWAN technologies using an abstraction layer to optimize cost and coverage. Communication is message-based using the publish-subscribe messaging pattern. It is implemented using the MQTT protocol. The abstraction layer decodes the proprietary binary data and converts it to a normalized JSON format.

</details>


### [319] [Goal-Oriented Multi-Agent Semantic Networking: Unifying Intents, Semantics, and Intelligence](https://arxiv.org/abs/2512.01035)
*Shutong Chen,Qi Liao,Adnan Aijaz,Yansha Deng*

Main category: cs.NI

TL;DR: GoAgentNet是一种新型网络架构，通过多代理协作和语义计算实现6G服务的目标导向通信，显著提升能效和任务成功率。


<details>
  <summary>Details</summary>
Motivation: 当前网络架构无法支持6G服务的高级别目标导向和AI原生通信需求，限制了其智能适应服务需求的能力。

Method: 提出了Goal-Oriented Multi-Agent Semantic Networking (GoAgentNet)架构，通过语义计算和跨层语义网络协调多代理功能。

Result: 在机器人故障检测和恢复案例中，GoAgentNet相比现有架构能效提升高达99%，任务成功率提高72%。

Conclusion: GoAgentNet架构通过将应用和网络功能抽象为多个协作代理，并通过语义计算和跨层语义网络共同协调多代理感知、网络、计算和控制，显著提升了6G系统的能效和任务成功率。

Abstract: 6G services are evolving toward goal-oriented and AI-native communication, which are expected to deliver transformative societal benefits across various industries and promote energy sustainability. Yet today's networking architectures, built on complete decoupling of the applications and the network, cannot expose or exploit high-level goals, limiting their ability to adapt intelligently to service needs. This work introduces Goal-Oriented Multi-Agent Semantic Networking (GoAgentNet), a new architecture that elevates communication from data exchange to goal fulfilment. GoAgentNet enables applications and the network to collaborate by abstracting their functions into multiple collaborative agents, and jointly orchestrates multi-agent sensing, networking, computation, and control through semantic computation and cross-layer semantic networking, allowing the entire architecture to pursue unified application goals. We first outline the limitations of legacy network designs in supporting 6G services, based on which we highlight key enablers of our GoAgentNet design. Then, through three representative 6G usage scenarios, we demonstrate how GoAgentNet can unlock more efficient and intelligent services. We further identify unique challenges faced by GoAgentNet deployment and corresponding potential solutions. A case study on robotic fault detection and recovery shows that our GoAgentNet architecture improves energy efficiency by up to 99% and increases the task success rate by up to 72%, compared with the existing networking architectures without GoAgentNet, which underscores its potential to support scalable and sustainable 6G systems.

</details>


### [320] [Internet of Intelligent Reflecting Surfaces (IoIRS)](https://arxiv.org/abs/2512.01083)
*Fatih E. Bilgen,A. Sila Okcu,O. Tansel Baydas,Ozgur B. Akan*

Main category: cs.NI

TL;DR: 提出IoIRS架构，将IRS从被动反射面升级为跨层连接的混合实体，以解决大规模网络中的挑战。


<details>
  <summary>Details</summary>
Motivation: 现有研究将IRS视为由发射机控制的独立物理层组件，但在大规模IRS和发射机网络中，这种设计面临重大挑战。

Method: 提出了IoIRS架构，包括概念框架和初步协议套件，以将IRS集成到更高网络层。

Result: 提出了IoIRS架构，重新定义了IRS作为跨层连接的混合实体，并探讨了其实际应用。

Conclusion: IoIRS架构的提出是为了解决未来无线网络中大规模IRS部署时的挑战，通过将IRS重新构想为跨物理层和上层网络层的连接实体，其实际部署对充分发挥未来无线网络能力至关重要。

Abstract: Intelligent Reflecting Surfaces (IRS) are anticipated to serve as a key cornerstone of future wireless networks, providing an unmatched capability to deterministically shape electromagnetic wave propagation. Despite this potential, most existing research still considers the IRS merely as a standalone physical-layer component, controlled by transmitters. However, as networks grow to encompass a massive number of these surfaces and a massive number of transmitters wishing to use them, this transmitter-centric design encounters substantial challenges. To overcome this challenge, we propose the Internet of IRS (IoIRS), an architecture that reconceives the IRS not just as a passive reflecting surface, but as a connected, hybrid entity functioning across both the physical layer and upper network layers. We present the conceptual framework and a preliminary protocol suite necessary to integrate these surfaces into the higher network layers. We conclude by examining how IoIRS architectures could be applied in practice, as their deployment will be essential for fully realizing the capabilities of future wireless networks.

</details>


### [321] [Physical-Layer Analysis of LoRa Robustness in the Presence of Narrowband Interference](https://arxiv.org/abs/2512.01088)
*Jingxiang Huang,Samer Lahoud*

Main category: cs.NI

TL;DR: 本文研究了BPSK和GMSK窄带信号对LoRa解调的影响，发现AWGN模型会高估SER，并提供了干扰损害机制见解及最大INR的两段函数。


<details>
  <summary>Details</summary>
Motivation: 随着物联网（IoT）技术的快速发展，sub-GHz未授权频谱被LoRa、Sigfox和LR-FHSS等协议共享，导致相互干扰。本文旨在研究两种窄带信号对LoRa解调的物理层影响。

Method: 采用符号级蒙特卡洛模拟，分析干扰噪声比（INR）对给定信噪比（SNR）和噪声基底下的符号错误率（SER）的影响，并与等功率AWGN进行比较。

Result: 研究发现，窄带干扰建模为AWGN会系统性高估CSS解调的SER，并明确了AWGN和两种窄带干扰的不同损害水平。此外，拟合了一个两段函数用于确定最大INR。

Conclusion: 本文通过符号级蒙特卡洛模拟，分析了两种窄带信号（BPSK和GMSK）对LoRa解调的物理层影响，并比较了其与等功率加性白高斯噪声（AWGN）的结果。研究发现，将窄带干扰建模为AWGN会系统性高估Chirp扩频解调的符号错误率（SER）。此外，研究还明确了AWGN和两种窄带干扰引起的不同损害水平，并提供了对潜在机制的物理见解。最后，研究拟合了一个两段函数，用于确定在不同信噪比（SNR）下确保正确解调的最大干扰噪声比（INR）。

Abstract: With the rapid development of Internet of Things (IoT) technologies, the sub-GHz unlicensed spectrum is increasingly being shared by protocols such as Long Range (LoRa), Sigfox, and Long-Range Frequency-Hopping Spread Spectrum (LR-FHSS). These protocols must coexist within the same frequency bands, leading to mutual interference. This paper investigates the physical-layer impact of two types of narrowband signals (BPSK and GMSK) on LoRa demodulation. We employ symbol-level Monte Carlo simulations to analyse how the interference-to-noise ratio (INR) affects the symbol error rate (SER) at a given signal-to-noise ratio (SNR) and noise floor, and then compare the results with those for additive white Gaussian noise (AWGN) of equal power. We demonstrate that modelling narrowband interference as additive white Gaussian noise (AWGN) systematically overestimates the SER of Chirp Spread Spectrum (CSS) demodulation. We also clarify the distinct impairment levels induced by AWGN and two types of narrowband interferers, and provide physical insight into the underlying mechanisms. Finally, we fit a two-segment function for the maximum INR that ensures correct demodulation across SNRs, with one segment for low SNR and the other for high SNR.

</details>


### [322] [Modeling and Simulation of Data Protection Systems for Business Continuity and Disaster Recovery](https://arxiv.org/abs/2512.01477)
*Saso Nikolovski,Pece Mitrevski*

Main category: cs.NI

TL;DR: 本研究比较了云环境中的恢复解决方案，提出了一个选择和维护数据保护及恢复解决方案的框架，为决策者提供了实用指导。


<details>
  <summary>Details</summary>
Motivation: 在现代企业运营高度依赖信息技术的背景下，建立强大的业务连续性计划（包括灾难恢复策略）对于确保在中断后快速恢复至关重要。

Method: 研究部署并评估了两种在云环境中运行的系统，使用模拟软件识别关键性能和可靠性指标，并对每种系统进行了系统动力学分析。

Result: 研究结果提供了分析和发现，用于指导选择适当的恢复解决方案，并确保其与业务连续性及灾难恢复计划中预定的时间线保持一致。

Conclusion: 本研究提出了一个全面的框架，用于在组织结构中选择和维护数据保护及恢复解决方案，并为决策者在选择适当的恢复概念时提供了可行的见解。

Abstract: In today's corporate landscape, particularly where operations rely heavily on information technologies, establishing a robust business continuity plan, including a disaster recovery strategy, is essential for ensuring swift recuperation following outages. This study presents a comparative analysis of recovery solutions, focusing on systems that operate partially or entirely within cloud environments and assessing their reliability in fulfilling organizational roles securely and dependably. Two such systems were deployed and evaluated in a real-world production setting. Key performance and reliability metrics were identified using simulation software to enhance these systems, alongside a System Dynamics analysis conducted for each. This work proposes a comprehensive framework for selecting and maintaining data protection and recovery solutions within organizational structures, outlining criteria for aligning chosen approaches with operational needs while adhering to predetermined timelines specified in business continuity and disaster recovery plans. The resulting analysis and findings offer actionable insights to guide decision-making when selecting appropriate recovery concepts.

</details>


### [323] [Velocity-Adaptive Access Scheme for Semantic-Aware Vehicular Networks: Joint Fairness and AoI Optimization](https://arxiv.org/abs/2512.01571)
*Xiao Xu,Qiong Wu,Pingyi Fan,Kezhi Wang,Nan Cheng,Wen Chen,Khaled B. Letaief*

Main category: cs.NI

TL;DR: 论文解决了5G NR V2X模式2中因车辆速度差异导致的公平访问和信息年龄优化问题，通过SHS分析和SCA方法，结合LLM算法，验证了方案的有效性。


<details>
  <summary>Details</summary>
Motivation: 由于车辆速度变化导致通信时长不同，不同车辆与RSU交换的数据量可能不同，这在高速环境下可能带来重大安全风险。

Method: 使用随机混合系统（SHS）分析信息年龄（AoI），构建多目标优化问题，并采用顺序凸近似（SCA）将非凸问题转化为凸问题，最后用凸优化求解。还提供了基于大型语言模型（LLM）的算法。

Result: 通过数值模拟验证了方案的有效性，实现了公平访问和信息年龄优化。

Conclusion: 该论文通过定义公平性指标并利用图像语义通信系统降低延迟，成功解决了5G NR V2X模式2中的公平访问和信息年龄优化问题。通过SCA方法将非凸问题转化为凸问题，并采用凸优化求解，验证了方案的有效性。

Abstract: In this paper, we address the problem of fair access and Age of Information (AoI) optimization in 5G New Radio (NR) Vehicle to Everything (V2X) Mode 2. Specifically, vehicles need to exchange information with the road side unit (RSU). However, due to the varying vehicle speeds leading to different communication durations, the amount of data exchanged between different vehicles and the RSU may vary. This may poses significant safety risks in high-speed environments. To address this, we define a fairness index through tuning the selection window of different vehicles and consider the image semantic communication system to reduce latency. However, adjusting the selection window may affect the communication time, thereby impacting the AoI. Moreover, considering the re-evaluation mechanism in 5G NR, which helps reduce resource collisions, it may lead to an increase in AoI. We analyze the AoI using Stochastic Hybrid System (SHS) and construct a multi-objective optimization problem to achieve fair access and AoI optimization. Sequential Convex Approximation (SCA) is employed to transform the non-convex problem into a convex one, and solve it using convex optimization. We also provide a large language model (LLM) based algorithm. The scheme's effectiveness is validated through numerical simulations.

</details>


### [324] [HERMES: Heterogeneous Application-Enabled Routing Middleware for Edge-IoT Systems](https://arxiv.org/abs/2512.01824)
*Jéssica Consciência,António Grilo*

Main category: cs.NI

TL;DR: 该论文提出了一种增强路由灵活性的软件框架，通过动态应用感知决策和多跳Wi-Fi网络实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 物联网的快速发展推动了计算和智能向网络边缘转移，但传统路由协议缺乏灵活性，无法适应应用层指标和策略的复杂需求。

Method: 研究建立了一个由ESP8266、ESP32和Raspberry Pi 3B组成的多跳Wi-Fi网络，采用主动式路由方法，并引入中间件层提供三种策略来影响路由行为。

Result: 实验结果表明，设备异构性显著影响网络性能，拓扑结构对分散性能至关重要，框架适用于复杂任务。

Conclusion: 该论文提出的软件框架通过动态整合应用感知决策，增强了路由灵活性，并通过实验验证了其在复杂任务中的适用性。

Abstract: The growth of the Internet of Things has enabled a new generation of applications, pushing computation and intelligence toward the network edge. This trend, however, exposes challenges, as the heterogeneity of devices and the complex requirements of applications are often misaligned with the assumptions of traditional routing protocols, which lack the flexibility to accommodate application-layer metrics and policies. This work addresses this gap by proposing a software framework that enhances routing flexibility by dynamically incorporating application-aware decisions. The core of the work establishes a multi-hop Wi-Fi network of heterogeneous devices, specifically ESP8266, ESP32, and Raspberry Pi 3B. The routing layer follows a proactive approach, while the network is fault-tolerant, maintaining operation despite both node loss and message loss. On top of this, a middleware layer introduces three strategies for influencing routing behavior: two adapt the path a message traverses until arriving at the destination, while the third allows applications to shape the network topology. This layer offers a flexible interface for diverse applications. The framework was validated on a physical testbed through edge intelligence use cases, including distributing neural network inference computations across multiple devices and offloading the entire workload to the most capable node. Distributed inference is useful in scenarios requiring low latency, energy efficiency, privacy, and autonomy. Experimental results indicated that device heterogeneity significantly impacts network performance. Throughput and inference duration analysis showed the influence of the strategies on application behaviour, revealed that topology critically affects decentralized performance, and demonstrated the suitability of the framework for complex tasks.

</details>


### [325] [Delay Tolerant Networking to Extend Connectivity in Rural Areas Using Public Transport Systems: Design And Analysis](https://arxiv.org/abs/2512.01829)
*Salah Abdeljabar,Marco Zennaro,Mohamed-Slim Alouini*

Main category: cs.NI

TL;DR: 本文提出了一种利用非正式公共交通系统（如小巴出租车）作为移动数据载体的DTN框架，以提升发展中国家农村地区的互联网连接，并通过概率模型和案例研究验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在数字时代，互联网接入至关重要，但在发展中国家农村地区存在显著的数字鸿沟。

Method: 开发了一个概率模型来捕捉车辆移动的随机性，包括旅行时间和在公交站点的接触持续时间，并分析了关键性能指标，如平均数据传输速率和峰值信息年龄（PAoI）。

Result: 通过真实世界数据集（如努瓦克肖特、阿克拉和亚的斯亚贝巴）的案例研究，验证了所提框架的实际适用性和可扩展性。

Conclusion: 利用现有的公共交通网络作为移动数据载体，可以显著缩小数字鸿沟，为偏远地区提供可靠的互联网连接。

Abstract: In today's digital age, access to the Internet is essential, yet a significant digital divide exists, particularly in rural areas of developing nations. This paper presents a Delay Tolerant Networking (DTN) framework that utilizes informal public transportation systems, such as minibus taxis, as mobile data mules to enhance connectivity in these underserved regions. We develop a probabilistic model to capture the randomness in vehicle mobility, including travel times and contact durations at bus stops. Key performance metrics are analyzed, including average data transmission rate and Peak Age of Information (PAoI), to assess the effectiveness of the proposed system. An analytical approximation for the Mean PAoI (MPAoI) is derived and validated through simulations. Case studies from real-world datasets in Nouakchott, Accra, and Addis Ababa demonstrate the practical applicability and scalability of our framework. The findings indicate that leveraging existing transportation networks can significantly bridge the digital divide by providing reliable internet-like connectivity to remote areas.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [326] [TagSplat: Topology-Aware Gaussian Splatting for Dynamic Mesh Modeling and Tracking](https://arxiv.org/abs/2512.01329)
*Hanzhi Guo,Dongdong Weng,Mo Su,Yixiao Chen,Xiaonuo Dongye,Chenyu Xu*

Main category: cs.GR

TL;DR: 提出基于高斯泼溅的拓扑感知动态重建框架，通过高斯拓扑结构和时间正则化，实现高质量拓扑一致网格序列重建，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有4D重建方法在生成高质量拓扑一致网格方面存在挑战，而拓扑一致的动态模型序列在动画和模型编辑等应用中至关重要。

Method: 引入高斯拓扑结构，明确编码空间连接性，支持拓扑感知的密集化和修剪，保持高斯表示的流形一致性。通过时间正则化项确保拓扑连贯性，并利用可微分网格光栅化提升网格质量。

Result: 实验结果表明，该方法重建的拓扑一致网格序列精度显著高于现有方法，且生成的网格支持精确的3D关键点跟踪。

Conclusion: 该论文提出的基于高斯泼溅的拓扑感知动态重建框架，能够显著提高拓扑一致网格序列的重建精度，并实现精确的3D关键点跟踪。

Abstract: Topology-consistent dynamic model sequences are essential for applications such as animation and model editing. However, existing 4D reconstruction methods face challenges in generating high-quality topology-consistent meshes. To address this, we propose a topology-aware dynamic reconstruction framework based on Gaussian Splatting. We introduce a Gaussian topological structure that explicitly encodes spatial connectivity. This structure enables topology-aware densification and pruning, preserving the manifold consistency of the Gaussian representation. Temporal regularization terms further ensure topological coherence over time, while differentiable mesh rasterization improves mesh quality. Experimental results demonstrate that our method reconstructs topology-consistent mesh sequences with significantly higher accuracy than existing approaches. Moreover, the resulting meshes enable precise 3D keypoint tracking. Project page: https://haza628.github.io/tagSplat/

</details>


### [327] [Textured Word-As-Image illustration](https://arxiv.org/abs/2512.01648)
*Mohammad Javadian Farzaneh,Selim Balcisoy*

Main category: cs.GR

TL;DR: 提出了一种自动生成既易读又能表达语义的文本图像的方法，用户输入概念、单词和字母，系统生成纹理并实时调整，适用于图形设计和艺术排版。


<details>
  <summary>Details</summary>
Motivation: 为了解决在图形设计中如何既保持文本的易读性又能有效表达语义概念的挑战。

Method: 提出了一种全自动流程，用户输入语义概念、单词和字母，系统利用稳定扩散模型根据预定义提示改变字母形状并生成纹理，同时确保文本图像的可读性。

Result: 用户评估表明，该方法在不影响可读性的情况下有效表达了语义意义。

Conclusion: 该方法成功地在保持文本可读性的同时，有效地表达了语义概念，为图形设计、标志创作和艺术排版提供了创新工具。

Abstract: In this paper, we propose a novel fully automatic pipeline to generate text images that are legible and strongly aligned to the desired semantic concept taken from the users' inputs. In our method, users are able to put three inputs into the system, including a semantic concept, a word, and a letter. The semantic concept will be used to change the shape of the input letter and generate the texture based on the pre-defined prompt using stable diffusion models. Our pipeline maps the texture on a text image in a way that preserves the readability of the whole output while preserving legibility. The system also provides real-time adjustments for the user to change the scale of the texture and apply it to the text image. User evaluations demonstrate that our method effectively represents semantic meaning without compromising legibility, making it a robust and innovative tool for graphic design, logo creation, and artistic typography.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [328] [An O(1) Space Algorithm for N-Dimensional Tensor Rotation: A Generalization of the Reversal Method](https://arxiv.org/abs/2512.00111)
*Dexin Chen*

Main category: cs.DS

TL;DR: 论文提出了一种名为“2^n+1反转算法”的N维张量原地旋转方法，具有O(1)空间和线性时间复杂性，并证明了其正确性。


<details>
  <summary>Details</summary>
Motivation: 多维张量旋转是计算机科学中的基础操作，但原地旋转（O(1)辅助空间）是一个重大算法挑战。论文旨在解决这一问题。

Method: 论文详细描述了“2^n+1反转算法”，包括形式化定义N维张量反转、伪代码实现以及严格的正确性证明。

Result: 算法在任意维度下均保持O(1)辅助空间和线性时间复杂度，验证了一维（3次反转）和二维（5次反转）的模式推广到N维的正确性。

Conclusion: 论文成功地将一维数组的三反转算法推广到N维张量，提出了“2^n+1反转算法”，实现了O(1)辅助空间和线性时间复杂度的原地张量旋转。

Abstract: The rotation of multi-dimensional arrays, or tensors, is a fundamental operation in computer science with applications ranging from data processing to scientific computing. While various methods exist, achieving this rotation in-place (i.e., with O(1) auxiliary space) presents a significant algorithmic challenge. The elegant three-reversal algorithm provides a well-known O(1) space solution for one-dimensional arrays. This paper introduces a generalization of this method to N dimensions, resulting in the "$2^n+1$ reversal algorithm". This algorithm achieves in-place tensor rotation with O(1) auxiliary space and a time complexity linear in the number of elements. We provide a formal definition for N-dimensional tensor reversal, present the algorithm with detailed pseudocode, and offer a rigorous proof of its correctness, demonstrating that the pattern observed in one dimension ($2^1+1=3$ reversals) and two dimensions ($2^2+1=5$ reversals) holds for any arbitrary number of dimensions.

</details>


### [329] [Maximum-Flow and Minimum-Cut Sensitivity Oracles for Directed Graphs](https://arxiv.org/abs/2512.00153)
*Mridul Ahi,Keerti Choudhary,Shlok Pande,Pushpraj,Lakshay Saggi*

Main category: cs.DS

TL;DR: 本文提出故障容忍流族和高效预言机，用于快速查询边故障后的最大流和最小割信息。


<details>
  <summary>Details</summary>
Motivation: 研究在有向图中，当边发生故障时，如何快速有效地更新最大流和最小割信息，以满足实际应用中对高效查询的需求。

Method: 通过构建故障容忍流族和设计高效的预言机算法，实现了在边故障情况下快速查询更新后的最大流值和最小割分区。

Result: 1. 构建了包含2λ+1个流的故障容忍流族；2. 设计了空间复杂度为O(λn)的最大流敏感度预言机；3. 扩展了最小割敏感度预言机，支持k边故障查询。

Conclusion: 本文提出了故障容忍流族的概念，并构建了高效的最大流和最小割敏感度预言机，适用于单边和双边故障，甚至扩展到k边故障的情况。

Abstract: Given a digraph $G = (V, E)$ with a designated source $s$, sink $t$, and an $(s,t)$-max-flow of value $λ$, we present constructions for max-flow and min-cut sensitivity oracles, and introduce the concept of a fault-tolerant flow family, which may be of independent interest. Our main contributions are as follows.
  1. Fault-Tolerant Flow Family: For any graph $G$ with $(s,t)$-max-flow value $λ$, we construct a family $B$ of $2λ+1$ $(s,t)$-flows such that for every edge $e$, $B$ contains an $(s,t)$-max-flow of $G-e$.
  2. Max-Flow Sensitivity Oracle: We construct a single as well as dual-edge sensitivity oracle for $(s,t)$-max-flow that requires only $O(λn)$ space. Given any set $F$ of up to two failing edges, the oracle reports the updated max-flow value in $G-F$ in $O(n)$ time. Additionally, for the single-failure case, the oracle can determine in constant time whether the flow through an edge $x$ changes when another edge $e$ fails.
  3. Min-Cut Sensitivity Oracle for Dual Failures: Recently, Baswana et al. (ICALP'22) designed an $O(n^2)$-sized oracle for answering $(s,t)$-min-cut size queries under dual edge failures in constant time. We extend this by focusing on graphs with small min-cut values $λ$, and present a more compact oracle of size $O(λn)$ that answers such min-cut size queries in constant time and reports the corresponding $(s,t)$-min-cut partition in $O(n)$ time.
  4. Min-Cut Sensitivity Oracle for Multiple Failures: We extend our results to the general case of $k$ edge failures. For any graph with $(s,t)$-min-cut of size $λ$, we construct a $k$-fault-tolerant min-cut oracle with space complexity $O_{λ,k}(n \log n)$ that answers min-cut size queries in $O_{λ,k}(\log n)$ time.

</details>


### [330] [Approximating Directed Connectivity in Almost-Linear Time](https://arxiv.org/abs/2512.00176)
*Kent Quanrud*

Main category: cs.DS

TL;DR: 该论文提出了一种高效的分治算法，用于近似计算有向图的边和顶点割，并在几乎线性时间内实现。


<details>
  <summary>Details</summary>
Motivation: 旨在计算加权有向图中(1+ε)近似最小全局边和顶点割，并提供几乎线性时间的近似方案。

Method: 采用了一种称为“shrink-wrapping”的分治技术，用于解决特定条件良好的根Steiner连通性问题。

Result: 提出了随机算法，分别在O(log^4(n)/ε)和O(log^5(n)/ε)单商品流中计算(1+ε)近似最小全局边和顶点割。

Conclusion: 通过设置适当的ε值，该算法还为小顶点连通性提供了更快的精确算法。

Abstract: We present randomized algorithms that compute $(1+ε)$-approximate minimum global edge and vertex cuts in weighted directed graphs in $O(\log^4(n) / ε)$ and $O(\log^5(n)/ε)$ single-commodity flows, respectively. With the almost-linear time flow algorithm of [CKL+22], this gives almost linear time approximation schemes for edge and vertex connectivity. By setting $ε$ appropriately, this also gives faster exact algorithms for small vertex connectivity.
  At the heart of these algorithms is a divide-and-conquer technique called "shrink-wrapping" for a certain well-conditioned rooted Steiner connectivity problem. Loosely speaking, for a root $r$ and a set of terminals, shrink-wrapping uses flow to certify the connectivity from a root $r$ to some of the terminals, and for the remaining uncertified terminals, generates an $r$-cut where the sink component both (a) contains the sink component of the minimum $(r,t)$-cut for each uncertified terminal $t$ and (b) has size proportional to the number of uncertified terminals. This yields a divide-and-conquer scheme over the terminals where we can divide the set of terminals and compute their respective minimum $r$-cuts in smaller, contracted subgraphs.

</details>


### [331] [Expected Cost Analysis of Online Facility Assignment on Regular Polygons](https://arxiv.org/abs/2512.00506)
*Md Rawha Siddiqi Riad,Md Manzurul Hasan*

Main category: cs.DS

TL;DR: 论文研究了多边形环境中在线设施分配的预期成本问题，提出了递归分析方法和数值计算方案。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决几何设置中在线设施分配问题，特别是在设施容量有限且顾客随机到达的情况下，如何高效计算预期分配成本。

Method: 论文采用递归特性分析、离散化动态规划方法和蒙特卡洛模拟来计算预期分配成本。

Result: 论文成功计算了小规模n（n=3,4,5）的预期值，并为大规模n和预期成本开发了高效的数值方法。

Conclusion: 该论文为多边形环境中的在线分配问题建立了一种基本的概率方法，通过递归特性分析和数值方法解决了预期分配成本的计算问题。

Abstract: This paper analyzes the online facility assignment problem in a geometric setting where facilities with unit capacity are positioned at the vertices of a regular $n$-gon. Customers arrive sequentially at uniformly random positions along the edges. They must be assigned immediately to the nearest available facility, with ties broken by coin toss. The sequential nature and unknown future arrivals require a probabilistic analysis of the expected assignment cost. Our main contribution is a recursive characterization of the expected cost: for any occupancy state $S$, the expected remaining cost $V(S)$ equals the average over all edge positions of the immediate assignment cost plus the expected future cost after assignment. We prove that this integral equation can calculate a solution and provide the expected value for small $n$ ($n = 3, 4, 5$). For larger values of $n$ and expected cost, we develop efficient numerical methods, including a discretized dynamic programming approach and Monte Carlo simulation. The work establishes a fundamental probabilistic approach for online assignment in polygonal environments.

</details>


### [332] [Perfect $L_p$ Sampling with Polylogarithmic Update Time](https://arxiv.org/abs/2512.00632)
*William Swartworth,David P. Woodruff,Samson Zhou*

Main category: cs.DS

TL;DR: 提出了一种高效更新时间的完美$L_p$采样器，解决了现有方法更新效率低的问题，同时保持最优空间复杂度。


<details>
  <summary>Details</summary>
Motivation: Jayaram和Woodruff的方法虽然实现了最优空间复杂度，但更新效率极低（每次更新至少$n^C$时间），因此需要一种既能保持最优空间复杂度又能高效更新的方法。

Method: 通过高效模拟截断指数随机变量的幂次倒数之和，利用Gil-Pelaez反演公式和梯形公式的变体快速逼近其特征函数。

Result: 首次实现了在$0 < p < 2$范围内，完美$L_p$采样器在最优空间复杂度下仅需$\text{poly}(\log n)$更新时间。

Conclusion: 本文提出了一种在流式数据中实现完美$L_p$采样的新方法，解决了Jayaram和Woodruff方法中更新效率低的问题，同时保持了最优的空间复杂度。

Abstract: Perfect $L_p$ sampling in a stream was introduced by Jayaram and Woodruff (FOCS 2018) as a streaming primitive which, given turnstile updates to a vector $x \in \{-\text{poly}(n), \ldots, \text{poly}(n)\}^n$, outputs an index $i^* \in \{1, 2, \ldots, n\}$ such that the probability of returning index $i$ is exactly \[\Pr[i^* = i] = \frac{|x_i|^p}{\|x\|_p^p} \pm \frac{1}{n^C},\] where $C > 0$ is an arbitrarily large constant. Jayaram and Woodruff achieved the optimal $\tilde{O}(\log^2 n)$ bits of memory for $0 < p < 2$, but their update time is at least $n^C$ per stream update. Thus an important open question is to achieve efficient update time while maintaining optimal space. For $0 < p < 2$, we give the first perfect $L_p$-sampler with the same optimal amount of memory but with only $\text{poly}(\log n)$ update time. Crucial to our result is an efficient simulation of a sum of reciprocals of powers of truncated exponential random variables by approximating its characteristic function, using the Gil-Pelaez inversion formula, and applying variants of the trapezoid formula to quickly approximate it.

</details>


### [333] [A Fast Algorithm for Finding Minimum Weight Cycles in Mining Cyclic Graph Topologies](https://arxiv.org/abs/2512.01049)
*Heman Shakeri,Torben Amtoft,Behnaz Moradi-Jamei,Nathan Albin,Pietro Poggi-Corradini*

Main category: cs.DS

TL;DR: 本文提出了一种高效的最小权重环（MWC）搜索算法，通过复合距离度量和动态剪枝技术，显著提升了搜索效率，并在循环模数计算中展示了实际应用价值。


<details>
  <summary>Details</summary>
Motivation: 环结构在图中的重要性日益凸显，尤其在网络鲁棒性、信息流和社区结构分析中。然而，高效计算最小权重环（MWC）仍具挑战性。本文旨在提出一种确定性算法，以解决这一问题，并提升复杂网络分析的效率。

Method: 本文提出了一种基于Dijkstra算法结构的改进方法，通过引入复合距离度量，将环搜索问题转化为节点中心优化。算法采用节点丢弃技术和动态图剪枝启发式方法，利用复杂网络中的局部性原则加速搜索，并通过周期性重置确保全局最优性。

Result: 提出的算法在理论和实践中均表现出高效性，显著加速了MWC的搜索过程。特别是在循环模数计算中，算法大幅减少了迭代约束查找的运行时。

Conclusion: 本文提出了一种新颖的确定性算法，用于在一般加权图中寻找最小权重环（MWC），并通过引入和最小化复合距离度量，将全局环搜索转化为迭代的节点中心优化。算法通过节点丢弃技术和图剪枝启发式方法显著加速搜索，同时保持全局最优性。该算法在复杂网络分析中展示了高效性，特别是在加速循环模数计算方面。

Abstract: Cyclic structures are fundamental topological features in graphs, playing critical roles in network robustness, information flow, community structure, and various dynamic processes. Algorithmic tools that can efficiently probe and analyze these cyclic topologies are increasingly vital for tasks in graph mining, network optimization, bioinformatics, and social network analysis. A core primitive for quantitative analysis of cycles is finding the Minimum Weight Cycle (MWC), representing the shortest cyclic path in a weighted graph. However, computing the MWC efficiently remains a challenge, particularly compared to shortest path computations. This paper introduces a novel deterministic algorithm for finding the MWC in general weighted graphs. Our approach adapts the structure of Dijkstra's algorithm by introducing and minimizing a \textit{composite distance} metric, effectively translating the global cycle search into an iterative node-centric optimization. We provide a rigorous proof of correctness based on loop invariants. We detail two mechanisms for accelerating the search: a provable node discarding technique based on intermediate results, and a highly effective graph pruning heuristic. This heuristic dynamically restricts the search to relevant subgraphs, leveraging the principle of locality often present in complex networks to achieve significant empirical speedups, while periodic resets ensure global optimality is maintained. The efficiency of the proposed MWC algorithm enables its use as a core component in more complex analyses focused on cyclic properties. We illustrate this through a detailed application case study: accelerating the computation of the Loop Modulus, a measure of cycle richness used in advanced network characterization. Our algorithm dramatically reduces the runtime of the iterative constraint-finding bottleneck in this computation.

</details>


### [334] [Beware of the Classical Benchmark Instances for the Traveling Salesman Problem with Time Windows](https://arxiv.org/abs/2512.01064)
*Francisco J. Soulignac*

Main category: cs.DS

TL;DR: 提出了一种高效的知情搜索方法，解决了TSPTW-M及其Duration变体的经典基准实例，指出这些实例不再适合评估，并提醒在设计机器学习训练集时需谨慎。


<details>
  <summary>Details</summary>
Motivation: 解决带有时间窗口和Makespan目标的旅行商问题（TSPTW-M）的现有方法效率不足，需要一种更高效的解决方案。

Method: 提出了一种简单且精确的知情搜索方法，用于解决带有时间窗口和Makespan目标的旅行商问题（TSPTW-M），该方法在不到十秒的时间内解决了所有具有50个或更多客户的经典基准实例。

Result: 该方法成功解决了所有具有50个或更多客户的经典基准实例，并且在Duration目标下也解决了除一个实例外的所有实例。

Conclusion: 论文的主要结论是，这些实例不应再用于评估TSPTW-M及其Duration变体：它们可以被“黑客”以产生乍看起来出色的结果。此外，在设计机器学习算法的硬训练集时需要谨慎。

Abstract: We propose a simple and exact informed search method for the Traveling Salesman Problem with Time Windows and Makespan objective (TSPTW-M) that solves all instances of the classical benchmark with 50 or more customers in less than ten seconds each. Applying this algorithm as an off-the-shelf method, we also solve all but one of these instances for the Duration objective. Our main conclusion is that these instances should no longer be employed for evaluating the TSPTW-M and its Duration variant: they can be ``hacked'' to yield results that seem outstanding at first sight. Additionally, caution is advised when designing hard training sets for machine learning algorithms.

</details>


### [335] [A practical algorithm for 3-admissibility](https://arxiv.org/abs/2512.01121)
*Christine Awofeso,Patrick Greaves,Oded Lachish,Felix Reidl*

Main category: cs.DS

TL;DR: 论文提出了一种线性复杂度的算法来计算图的3-admissibility，实验显示现实网络中3-admissibility与2-admissibility差异不大。


<details>
  <summary>Details</summary>
Motivation: 研究动机是识别具有算法友好结构的现实网络，3-admissibility是一个有前景的衡量标准。

Method: 论文设计了一种算法，能够在时间复杂度和空间复杂度均为线性的情况下，决定输入图的3-admissibility是否不超过p。

Result: 实验结果表明，大多数现实网络的3-admissibility并不比2-admissibility大很多。

Conclusion: 该论文的结论是，3-admissibility算法在实际网络中的表现优于预期，且与2-admissibility相比差异不大，尽管前者具有更好的算法特性。

Abstract: The $3$-admissibility of a graph is a promising measure to identify real-world networks that have an algorithmically favourable structure.
  We design an algorithm that decides whether the $3$-admissibility of an input graph~$G$ is at most~$p$ in time~\runtime and space~\memory, where $m$ is the number of edges in $G$ and $n$ the number of vertices. To the best of our knowledge, this is the first explicit algorithm to compute the $3$-admissibility.
  The linear dependence on the input size in both time and space complexity, coupled with an `optimistic' design philosophy for the algorithm itself, makes this algorithm practicable, as we demonstrate with an experimental evaluation on a corpus of \corpussize real-world networks.
  Our experimental results show, surprisingly, that the $3$-admissibility of most real-world networks is not much larger than the $2$-admissibility, despite the fact that the former has better algorithmic properties than the latter.

</details>


### [336] [Near-Optimal Sparsifiers for Stochastic Knapsack and Assignment Problems](https://arxiv.org/abs/2512.01240)
*Shaddin Dughmi,Yusuf Hakan Kalayci,Xinyu Liu*

Main category: cs.DS

TL;DR: 论文提出了一个多面体稀疏化框架，有效解决了背包类型约束下的数据选择问题，证明了其高效性，并提出了一个开放性问题。


<details>
  <summary>Details</summary>
Motivation: 当不确定性遇到昂贵的信息收集时，如何选择数据点以获得接近最优解是一个核心问题。现有的稀疏化方法在处理背包类型约束时因结构变异而失效。

Method: 引入了一个多面体稀疏化框架，通过将查询集嵌入到缩放后的可行性多面体中来测量稀疏度，避免了基于基数的方法。关键洞察包括对相似权重项的分组和部署充电论证。

Result: 证明了背包、多重背包和广义分配问题可以接受(1-ε)近似的稀疏化器，其稀疏度与1/p和1/ε多项式相关，且独立于问题维度。

Conclusion: 论文提出了一个多面体稀疏化框架，用于解决背包类型约束下的数据点选择问题，证明了该框架在多种问题上的有效性，并提出了一个关于一般整数线性程序的开放性问题。

Abstract: When uncertainty meets costly information gathering, a fundamental question emerges: which data points should we probe to unlock near-optimal solutions? Sparsification of stochastic packing problems addresses this trade-off. The existing notions of sparsification measure the level of sparsity, called degree, as the ratio of queried items to the optimal solution size. While effective for matching and matroid-type problems with uniform structures, this cardinality-based approach fails for knapsack-type constraints where feasible sets exhibit dramatic structural variation. We introduce a polyhedral sparsification framework that measures the degree as the smallest scalar needed to embed the query set within a scaled feasibility polytope, naturally capturing redundancy without relying on cardinality.
  Our main contribution establishes that knapsack, multiple knapsack, and generalized assignment problems admit (1 - epsilon)-approximate sparsifiers with degree polynomial in 1/p and 1/epsilon -- where p denotes the independent activation probability of each element -- remarkably independent of problem dimensions. The key insight involves grouping items with similar weights and deploying a charging argument: when our query set misses an optimal item, we either substitute it with a queried item from the same group or leverage that group's excess contribution to compensate for the loss. This reveals an intriguing complexity-theoretic separation -- while the multiple knapsack problem lacks an FPTAS and generalized assignment is APX-hard, their sparsification counterparts admit efficient (1 - epsilon)-approximation algorithms that identify polynomial-degree query sets. Finally, we raise an open question: can such sparsification extend to general integer linear programs with degree independent of problem dimensions?

</details>


### [337] [Separator Theorem for Minor-Free Graphs in Linear Time](https://arxiv.org/abs/2512.01587)
*Édouard Bonnet,Tuukka Korhonen,Hung Le,Jason Li,Tomáš Masařík*

Main category: cs.DS

TL;DR: 本文提出了一种简单算法，通过顶点加权的BFS在次要自由图中线性时间内找到大小为O(√n)的平衡分隔器，解决了长期存在的开放性问题。


<details>
  <summary>Details</summary>
Motivation: 试图将Lipton-Tarjan的平面图分隔定理推广到非平面图，尤其是次要自由图，解决长期以来存在的平衡分隔器大小和线性时间算法的开放性问题。

Method: 使用顶点加权的广度优先搜索（BFS）算法，通过一种新的顶点加权方案来引导搜索平衡分隔器。

Result: 成功在次要自由图中找到大小为O(√n)的平衡分隔器，且算法运行时间为线性O(n)。

Conclusion: 本文肯定地回答了这一开放性问题，提出了一种简单算法，通过运行顶点加权的广度优先搜索（BFS）来找到平衡分隔器。

Abstract: The planar separator theorem by Lipton and Tarjan [FOCS '77, SIAM Journal on Applied Mathematics '79] states that any planar graph with $n$ vertices has a balanced separator of size $O(\sqrt{n})$ that can be found in linear time. This landmark result kicked off decades of research on designing linear or nearly linear-time algorithms on planar graphs. In an attempt to generalize Lipton-Tarjan's theorem to nonplanar graphs, Alon, Seymour, and Thomas [STOC '90, Journal of the AMS '90] showed that any minor-free graph admits a balanced separator of size $O(\sqrt{n})$ that can be found in $O(n^{3/2})$ time. The superlinear running time in their separator theorem is a key bottleneck for generalizing algorithmic results from planar to minor-free graphs. Despite extensive research for more than two decades, finding a balanced separator of size $O(\sqrt{n})$ in (linear) $O(n)$ time for minor-free graphs remains a major open problem. Known algorithms either give a separator of size much larger than $O(\sqrt{n})$ or have superlinear running time, or both.
  In this paper, we answer the open problem affirmatively. Our algorithm is very simple: it runs a vertex-weighted variant of breadth-first search (BFS) a constant number of times on the input graph. Our key technical contribution is a weighting scheme on the vertices to guide the search for a balanced separator, offering a new connection between the size of a balanced separator and the existence of a clique-minor model. We believe that our weighting scheme may be of independent interest.

</details>


### [338] [JFR: An Efficient Jump Frontier Relaxation Strategy for Bellman-Ford](https://arxiv.org/abs/2512.01802)
*Xin Wang,Xi Chen*

Main category: cs.DS

TL;DR: JFR是一个基于Bellman-Ford的优化框架，通过前沿收缩和多跳跳跃传播显著减少松弛操作，适用于大规模图计算。


<details>
  <summary>Details</summary>
Motivation: 为了在稀疏、密集和含负边权图中加速最短路径计算，同时确保在对抗性或高度连接拓扑下的鲁棒性能。

Method: JFR是一个基于Bellman-Ford的优化框架，利用前沿收缩和抽象多跳跳跃传播来加速最短路径计算。

Result: JFR在松弛操作上实现了25%至99%的减少，在超大规模图上（最多20,000个节点和2.95亿条边）保持了强健的操作减少和与SPFA-SLF相当或更优的运行时间。

Conclusion: JFR框架通过前沿收缩和抽象多跳跳跃传播显著加速了最短路径计算，同时严格保持正确性。未来工作将集中在集成高性能队列结构、自适应前沿策略和缓存感知技术上，以进一步降低常数因子开销。

Abstract: We propose JFR, a Bellman-Ford-based optimization framework leveraging frontier contraction and abstract multi-hop jump propagation to accelerate shortest-path computation while strictly preserving correctness. JFR achieves substantial reductions in relaxation operations, ranging from 25 to 99 percent, across sparse, dense, and negative-edge graphs, ensuring robust performance even under adversarial or highly connected topologies. On ultra-large graphs with up to N=20,000 nodes and 295 million edges, JFR maintains strong operational reductions and comparable or improved runtime relative to SPFA-SLF, demonstrating consistent robustness across graph size and density. Lower relaxation counts imply reduced memory-access overheads and computational effort; this normalized work reduction highlights JFR's suitability for scenarios requiring high throughput or energy-conscious operation. Future work focuses on integrating high-performance queue structures, adaptive frontier strategies, and cache-aware techniques to further reduce constant-factor overheads and fully realize JFR's practical runtime potential.

</details>


### [339] [Tight Bounds for Feedback Vertex Set Parameterized by Clique-width](https://arxiv.org/abs/2512.01900)
*Narek Bojikian,Stefan Kratsch*

Main category: cs.DS

TL;DR: 本文提出标记图中无环性表示的新概念，并设计了高效算法解决反馈顶点集的计数和决策问题，填补了文献中的开放性问题。


<details>
  <summary>Details</summary>
Motivation: 解决标记图中无环性表示的开放性问题，并探索其在反馈顶点集计数和决策问题中的应用。

Method: 提出了一种算法，利用图的k-团表达式和树分解，通过复杂的子程序在联合节点合并部分解，实现了对反馈顶点集的计数和决策问题的高效解决。

Result: 提出了三个主要算法：1）在O(6^kn^c)时间内计算反馈顶点集数量的模2结果；2）在O(3^kn^c)时间内匹配已知的SETH紧界；3）在O(18^kn^c)时间内决策连通反馈顶点集的存在性。

Conclusion: 本文通过引入标记图中的无环性表示新概念，提出了三种应用，并解决了文献中多次出现的开放性问题。

Abstract: We introduce a new notion of acyclicity representation in labeled graphs, and present three applications thereof. Our main result is an algorithm that, given a graph $G$ and a $k$-clique expression of $G$, in time $O(6^kn^c)$ counts modulo $2$ the number of feedback vertex sets of $G$ of each size. We achieve this through an involved subroutine for merging partial solutions at union nodes in the expression. In the usual way this results in a one-sided error Monte-Carlo algorithm for solving the decision problem in the same time. We complement these by a matching lower bound under the Strong Exponential-Time Hypothesis (SETH). This closes an open question that appeared multiple times in the literature [ESA 23, ICALP 24, IPEC 25].
  We also present an algorithm that, given a graph $G$ and a tree decomposition of width $k$ of $G$, in time $O(3^kn^c)$ counts modulo $2$ the number of feedback vertex sets of $G$ of each size. This matches the known SETH-tight bound for the decision version, which was obtained using the celebrated cut-and-count technique [FOCS 11, TALG 22]. Unlike other applications of cut-and-count, which use the isolation lemma to reduce a decision problem to counting solutions modulo $2$, this bound was obtained via counting other objects, leaving the complexity of counting solutions modulo $2$ open.
  Finally, we present a one-sided error Monte-Carlo algorithm that, given a graph $G$ and a $k$-clique expression of $G$, in time $O(18^kn^c)$ decides the existence of a connected feedback vertex set of size $b$ in $G$. We provide a matching lower bound under SETH.

</details>


### [340] [Adaptive Matrix Sparsification and Applications to Empirical Risk Minimization](https://arxiv.org/abs/2512.02003)
*Yang P. Liu,Richard Peng,Colin Tang,Albert Weng,Junzhao Yang*

Main category: cs.DS

TL;DR: 提出了一种高效算法，用于高精度求解ERM问题，时间复杂度在输入规模较大时接近线性，通过动态数据结构和内点法实现。


<details>
  <summary>Details</summary>
Motivation: 为了解决ERM问题在高维数据下的计算效率问题，尤其是在矩阵密集且$n \\ge d^{10}$时的高效求解。

Method: 通过动态数据结构高效实现了一种$\widetilde{O}(\sqrt{n})$迭代的内点法（IPM），并开发了一种新算法来维护矩阵行更新的杠杆分数高估。

Result: 算法的时间复杂度为$\widetilde{O}(nd + d^6\sqrt{n}) \\le \widetilde{O} (nd + d^{11})$，在输入规模较大时接近线性。

Conclusion: 该论文提出了一种高效算法，用于解决高精度ERM问题，其时间复杂度在输入规模较大时接近线性。

Abstract: Consider the empirical risk minimization (ERM) problem, which is stated as follows. Let $K_1, \dots, K_m$ be compact convex sets with $K_i \subseteq \mathbb{R}^{n_i}$ for $i \in [m]$, $n = \sum_{i=1}^m n_i$, and $n_i\le C_K$ for some absolute constant $C_K$. Also, consider a matrix $A \in \mathbb{R}^{n \times d}$ and vectors $b \in \mathbb{R}^d$ and $c \in \mathbb{R}^n$. Then the ERM problem asks to find \[ \min_{\substack{x \in K_1 \times \dots \times K_m\\ A^\top x = b}}
  c^\top x. \] We give an algorithm to solve this to high accuracy in time $\widetilde{O}(nd + d^6\sqrt{n}) \le \widetilde{O} (nd + d^{11})$, which is nearly-linear time in the input size when $A$ is dense and $n \ge d^{10}$.
  Our result is achieved by implementing an $\widetilde{O}(\sqrt{n})$-iteration interior point method (IPM) efficiently using dynamic data structures. In this direction, our key technical advance is a new algorithm for maintaining leverage score overestimates of matrices undergoing row updates. Formally, given a matrix $A \in \mathbb{R}^{n \times d}$ undergoing $T$ batches of row updates of total size $n$ we give an algorithm which can maintain leverage score overestimates of the rows of $A$ summing to $\widetilde{O}(d)$ in total time $\widetilde{O}(nd + Td^6)$. This data structure is used to sample a spectral sparsifier within a robust IPM framework to establish the main result.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [341] [A Parallel and Distributed Rust Library for Core Decomposition on Large Graphs](https://arxiv.org/abs/2512.00233)
*Davide Rucci,Sebastian Parfeniuc,Matteo Mordacchini,Emanuele Carlini,Alfredo Cuzzocrea,Patrizio Dazzi*

Main category: cs.DC

TL;DR: 本文通过Rust实现了共享内存系统中的并行$k$-core分解算法FastK，实验显示其在16线程上比Python实现快两个数量级。


<details>
  <summary>Details</summary>
Motivation: 现代网络的规模需要更快、支持多核的方法来进行$k$-core分解，尽管已有高效的串行算法。

Method: 通过将Montresor等人提出的分布式$k$-core算法适配到共享内存系统，并用Rust实现了三个逐步优化的版本：SequentialK（基线）、ParallelK（引入多线程消息传递）和FastK（进一步减少同步开销）。

Result: 在真实数据集（如道路网络、网络图和社交网络）上的实验表明，FastK始终优于SequentialK、ParallelK以及NetworkX库中的Python实现。

Conclusion: FastK在16线程上实现了高达11倍的加速，执行时间比Python实现快两个数量级，证明了其在共享内存系统中并行化$k$-core分解的有效性。

Abstract: In this paper, we investigate the parallelization of $k$-core decomposition, a method used in graph analysis to identify cohesive substructures and assess node centrality. Although efficient sequential algorithms exist for this task, the scale of modern networks requires faster, multicore-ready approaches. To this end, we adapt a distributed $k$-core algorithm originally proposed by Montresor et al. to shared-memory systems and implement it in Rust, leveraging the language's strengths in concurrency and memory safety. We developed three progressively optimized versions: SequentialK as a baseline, ParallelK introducing multi-threaded message passing, and FastK further reducing synchronization overhead. Extensive experiments on real-world datasets, including road networks, web graphs, and social networks, show that FastK consistently outperforms both SequentialK and ParallelK, as well as a reference Python implementation available in the NetworkX library. Results indicate up to an 11x speedup on 16 threads and execution times up to two orders of magnitude faster than the Python implementation.

</details>


### [342] [Heimdall++: Optimizing GPU Utilization and Pipeline Parallelism for Efficient Single-Pulse Detection](https://arxiv.org/abs/2512.00398)
*Bingzheng Xia,Zujie Ren,Kuang Ma,Xiaoqian Li,Wenda Li,Shuibing He*

Main category: cs.DC

TL;DR: Heimdall++是Heimdall的优化版本，通过改进GPU并行化和内存管理，显著提升处理速度，适用于大容量射电数据实时处理。


<details>
  <summary>Details</summary>
Motivation: 现代射电望远镜数据量激增，实时单脉冲检测需求迫切，但现有工具如Heimdall存在GPU利用率不足和计算延迟问题。

Method: 优化了GPU并行化、内存管理和多线程框架，以解耦CPU和GPU处理阶段。

Result: 在NVIDIA RTX 3080 Ti GPU上测试，Heimdall++单文件处理速度提升2.66倍，多文件批量处理提升2.05倍。

Conclusion: Heimdall++通过细粒度GPU并行化、增强的内存管理和多线程框架，显著提升了处理速度和效率，同时保持了与原版Heimdall的结果一致性。

Abstract: With the increasing time and frequency resolution of modern radio telescopes and the exponential growth in observational data volumes, real-time single-pulse detection has become a critical requirement for time-domain radio astronomy. Heimdall, as a representative GPU-accelerated single-pulse search tool, offers substantial performance advantages over CPU-based approaches. However, its sequential execution model and resource contention in intermediate processing stages limit GPU utilization, leading to suboptimal throughput and increased computational latency. To address these limitations, we present Heimdall++, an optimized successor to Heimdall that incorporates fine-grained GPU parallelization, enhanced memory management, and a multi-threaded framework to decouple CPU-bound and GPU-bound processing stages. This design mitigates the GPU stall problem and improves end-to-end efficiency. We evaluated Heimdall++ on a system equipped with NVIDIA RTX 3080 Ti GPUs using both a single large-scale observational file and multiple files. Experimental results demonstrate that Heimdall++ achieves up to 2.66x speedup in single-file processing and 2.05x speedup in multi-file batch processing, while maintaining full consistency with the original Heimdall's search results.

</details>


### [343] [IslandRun: Privacy-Aware Multi-Objective Orchestration for Distributed AI Inference](https://arxiv.org/abs/2512.00595)
*Bala Siva Sai Akhil Malepati*

Main category: cs.DC

TL;DR: IslandRun是一种多目标编排系统，通过代理路由、分层岛屿组和可逆匿名化技术，解决了AI推理中的性能、隐私、成本和信任问题。


<details>
  <summary>Details</summary>
Motivation: 现代AI推理面临性能、隐私、成本和信任之间的固有张力，现有编排框架（如Kubernetes、联邦学习、边缘计算）仅优化单一维度，难以应对现实世界的异构性挑战。

Method: IslandRun采用基于代理的路由、分层岛屿组（具有差异化的信任级别）和可逆匿名化技术，实现了请求级别的异构性管理、数据本地化和跨信任边界的上下文语义保留。

Result: IslandRun通过多目标优化、数据本地化和可逆匿名化技术，成功实现了隐私感知、去中心化的异构推理编排，为个人计算生态系统提供了新的解决方案。

Conclusion: IslandRun提出了一种新的隐私感知、去中心化的异构个人计算生态系统推理编排范式，通过多目标优化、数据本地化和可逆匿名化技术，解决了现代AI推理中的性能、隐私、成本和信任之间的固有张力。

Abstract: Modern AI inference faces an irreducible tension: no single computational resource simultaneously maximizes performance, preserves privacy, minimizes cost, and maintains trust. Existing orchestration frameworks optimize single dimensions (Kubernetes prioritizes latency, federated learning preserves privacy, edge computing reduces network distance), creating solutions that struggle under real-world heterogeneity. We present IslandRun, a multi-objective orchestration system that treats computational resources as autonomous "islands" spanning personal devices, private edge servers, and public cloud. Our key insights: (1) request-level heterogeneity demands policy-constrained multi-objective optimization, (2) data locality enables routing compute to data rather than data to compute, and (3) typed placeholder sanitization preserves context semantics across trust boundaries. IslandRun introduces agent-based routing, tiered island groups with differential trust, and reversible anonymization. This establishes a new paradigm for privacy-aware, decentralized inference orchestration across heterogeneous personal computing ecosystems.

</details>


### [344] [Steady and Energy-Efficient Multi-Hop Clustering for Flying Ad-Hoc Networks (FANETs)](https://arxiv.org/abs/2512.00623)
*Basilis Mamalis,Marios Perlitis*

Main category: cs.DC

TL;DR: 提出一种多跳聚类算法，通过移动感知和能量优化提升FANET的集群稳定性和效率，实验证明优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 解决FANET因无人机高移动性、有限能源和动态拓扑带来的独特挑战。

Method: 通过移动感知聚类、能量中心集群头（CH）选择以及地面站（GS）辅助的集群维护管理机制，构建稳定的多跳集群。

Result: 实验结果表明，该方法在集群稳定性、通信开销和安全弹性方面显著优于现有方案。

Conclusion: 该论文提出了一种新颖的多跳聚类算法，显著提升了FANET环境中集群的稳定性、通信效率和安全性。

Abstract: Flying Ad-hoc Networks (FANETs), formed by Unmanned Aerial Vehicles (UAVs), represent an emerging and promising communication paradigm. These networks face unique challenges due to UAVs high mobility, limited energy resources, and dynamic topology. In this work, we propose a novel multi-hop clustering algorithm aimed at creating stable, energy-efficient clusters in FANET environments. The proposed solution enhances cluster longevity and communication efficiency through mobility-aware clustering, energy-centric cluster head (CH) selection, and a ground station(GS)-assisted cluster maintenance management mechanism. First, steady multi-hop clusters are constructed, having CHs with not only high stability and high energy but also with steady and high-energy neighboring areas, and then a proper GS-assisted cluster maintenance mechanism is applied. Experimental results, based on extended simulations, demonstrate that our approach outperforms existing schemes significantly, in terms of cluster stability, communication overhead, and security resilience.

</details>


### [345] [FlexiWalker: Extensible GPU Framework for Efficient Dynamic Random Walks with Runtime Adaptation](https://arxiv.org/abs/2512.00705)
*Seongyeon Park,Jaeyong Song,Changmin Shin,Sukjin Kim,Junguk Hong,Jinho Lee*

Main category: cs.DC

TL;DR: FlexiWalker 是首个支持动态随机游走的 GPU 框架，通过优化采样技术和动态策略选择，显著提升性能并支持多样化负载。


<details>
  <summary>Details</summary>
Motivation: 动态随机游走的运行时依赖性过渡概率破坏了现有 CPU/GPU 静态随机游走优化的预计算策略，导致现有框架效率低下且无法适应多样化负载。

Method: 通过拒绝采样和蓄水池采样技术设计高性能内核，消除全局归约、冗余内存访问和随机数生成；采用轻量级一阶成本模型动态选择最佳采样策略；并通过编译时组件自动优化用户提供的游走逻辑。

Result: FlexiWalker 在真实世界图的动态随机游走负载中，几何平均性能分别比最佳 CPU 和 GPU 基线高 73.44 倍和 5.91 倍。

Conclusion: FlexiWalker 是一个高效的 GPU 框架，专为动态随机游走设计，显著优于现有 CPU/GPU 基线，并支持现有系统无法处理的负载。

Abstract: Dynamic random walks are fundamental to various graph analysis applications, offering advantages by adapting to evolving graph properties. Their runtime-dependent transition probabilities break down the pre-computation strategy that underpins most existing CPU and GPU static random walk optimizations. This leaves practitioners suffering from suboptimal frameworks and having to write hand-tuned kernels that do not adapt to workload diversity. To handle this issue, we present FlexiWalker, the first GPU framework that delivers efficient, workload-generic support for dynamic random walks. Our design-space study shows that rejection sampling and reservoir sampling are more suitable than other sampling techniques under massive parallelism. Thus, we devise (i) new high-performance kernels for them that eliminate global reductions, redundant memory accesses, and random-number generation. Given the necessity of choosing the best-fitting sampling strategy at runtime, we adopt (ii) a lightweight first-order cost model that selects the faster kernel per node at runtime. To enhance usability, we introduce (iii) a compile-time component that automatically specializes user-supplied walk logic into optimized building blocks. On various dynamic random walk workloads with real-world graphs, FlexiWalker outperforms the best published CPU/GPU baselines by geometric means of 73.44x and 5.91x, respectively, while successfully executing workloads that prior systems cannot support. We open-source FlexiWalker in https://github.com/AIS-SNU/FlexiWalker.

</details>


### [346] [SIMPLE: Disaggregating Sampling from GPU Inference into a Decision Plane for Faster Distributed LLM Serving](https://arxiv.org/abs/2512.00719)
*Bohan Zhao,Zane Cao,Yongchao He*

Main category: cs.DC

TL;DR: SIMPLE通过解耦采样过程并优化技术，显著提升LLM的吞吐量和延迟性能。


<details>
  <summary>Details</summary>
Motivation: 随着LLM规模扩大及生产堆栈对数据平面的优化，采样成为新的瓶颈，限制了管道的频率。

Method: SIMPLE采用序列并行采样、CPU算法及SHVS技术，实现采样过程的解耦与优化。

Result: SIMPLE提升端到端吞吐量达96%，降低P95延迟20-65%。

Conclusion: SIMPLE通过将采样过程解耦为CPU端服务，并采用序列并行采样、CPU算法及SHVS技术，显著提升了吞吐量并降低了延迟，且无需用户端代码更改，与现有数据平面优化兼容。

Abstract: As large language models (LLMs) scale out with tensor parallelism (TP) and pipeline parallelism (PP) and production stacks have aggressively optimized the data plane (attention/GEMM and KV cache), sampling, the decision plane that turns logits into tokens, becomes a new bottleneck. This creates a structural holdout: sampling neither expands with TP nor balances across PP stages, so its share of iteration time grows as GPUs get faster and it caps pipeline frequency at the last stage. We present SIMPLE, a stage-agnostic, sequence-parallel, overlappable decision plane that disaggregates sampling into a CPU-side service and shrinks its runtime footprint back to a minor, hidden role. SIMPLE combines: (1) sequence-parallel sampling, which shards work along the batch dimension and removes vocabulary-axis collectives; (2) a CPU-based algorithm with column-wise penalties and truncation-first filtering to realize single-pass, linear-time kernels; and (3) speculative hot-vocab sampling (SHVS), which samples on a small hot set with rejection-correctness and uses a simple sizing model to choose the hot-vocab size that maximizes throughput. In evaluation, SIMPLE improves end-to-end throughput by up to 96% and reduces P95 latency by 20-65%. Crucially, SIMPLE requires no user-side code changes and composes with existing data-plane optimizations, unlocking scaling benefits that compound with future GPU generations.

</details>


### [347] [Elastic Mixture of Rank-Wise Experts for Knowledge Reuse in Federated Fine-Tuning](https://arxiv.org/abs/2512.00902)
*Yebo Wu,Jingguang Li,Zhijiang Guo,Li Li*

Main category: cs.DC

TL;DR: SmartFed通过重用LoRA模块知识和动态资源分配，高效解决了联邦微调的资源问题。


<details>
  <summary>Details</summary>
Motivation: 联邦微调在保护数据隐私的同时适应下游任务，但其高计算和通信需求限制了在资源受限设备上的部署。

Method: 提出了SmartFed框架，包括Mixture of Rank-Wise Experts (MoRE)和Elastic Expert Quota Allocation (EEQA)，以重用LoRA模块知识并优化资源分配。

Result: 在多个基准测试中，SmartFed在模型性能和训练效率上显著优于现有方法。

Conclusion: SmartFed通过智能重用LoRA模块中的知识，显著提升了模型性能和训练效率，为资源受限设备上的联邦微调提供了高效解决方案。

Abstract: Federated fine-tuning offers a promising solution for adapting Large Language Models (LLMs) to downstream tasks while safeguarding data privacy. However, its high computational and communication demands hinder its deployment on resource-constrained devices. In this paper, we propose SmartFed, a resource-efficient federated fine-tuning framework. SmartFed intelligently reuses knowledge embedded in existing LoRA modules, eliminating the need for expensive training from scratch when adapting LLMs to new tasks. To effectively exploit this knowledge and ensure scalability, we introduce the Mixture of Rank-Wise Experts (MoRE). MoRE decomposes LoRA modules into fine-grained rank-level experts. These experts are selectively activated and combined based on input semantics and resource budgets. Moreover, to optimize resource utilization, we present the Elastic Expert Quota Allocation (EEQA). EEQA adaptively allocates expert capacity across parameter matrices based on their contribution to model performance, focusing computing resources on the critical experts. Extensive evaluations across multiple benchmarks demonstrate that SmartFed significantly outperforms existing methods in model performance and training efficiency.

</details>


### [348] [Joint Partitioning and Placement of Foundation Models for Real-Time Edge AI](https://arxiv.org/abs/2512.01039)
*Aladin Djuhera,Fernando Koch,Alecio Binotto*

Main category: cs.DC

TL;DR: 提出动态编排框架，适应边缘环境中基础模型的推理需求，通过实时优化应对资源波动，适用于6G边缘计算。


<details>
  <summary>Details</summary>
Motivation: 静态模型层划分假设计算和网络资源在时间上是稳定的，这与现实部署中的资源波动不符，因此需要一种能够适应资源变化的动态编排方法。

Method: 框架整合了模型感知的能力分析、动态图重新分区和重新分配，将基础模型的空间放置和内部分割提升为运行时解析的构造。

Result: 该框架能够根据基础设施波动实现反应式推理组合，优化延迟、利用率和隐私梯度。

Conclusion: 该论文提出了一种动态可重构的编排框架，能够适应异构边缘环境中基础模型的推理需求，通过实时优化层间分配来应对资源波动，为6G多接入边缘计算提供了实用解决方案。

Abstract: Inference over large-scale foundation models within heterogeneous edge environments necessitates a fundamentally reconfigurable orchestration substrate. Static partitioning of model layers presumes temporal stability across compute and network resources, which is misaligned with the volatility of real-world deployments. We introduce a framework in which both the spatial placement and internal segmentation of foundation models are elevated to runtime-resolved constructs. The orchestration problem is formalized as a constrained optimization over layer-wise assignments, subject to evolving latency, utilization, and privacy gradients. The framework implements reactive inference composition responsive to infrastructural fluctuations by integrating model-aware capacity profiling with dynamic graph re-partitioning and reallocation. We introduce architectural and algorithmic components, along with a representative use case in 6G multi-access edge computing.

</details>


### [349] [Tangram: Accelerating Serverless LLM Loading through GPU Memory Reuse and Affinity](https://arxiv.org/abs/2512.01357)
*Wenbin Zhu,Zhaoyan Shen,Zili Shao,Hongjun Dai,Feng Chen*

Main category: cs.DC

TL;DR: Tangram通过GPU内存重用技术，显著优化了Serverless LLM的冷启动性能，提升加载速度并减少延迟。


<details>
  <summary>Details</summary>
Motivation: Serverless LLM的冷启动延迟，尤其是模型加载阶段，已成为性能瓶颈，限制了大规模LLM服务的实际部署。

Method: Tangram的设计包括三个关键组件：统一的GPU内存池用于模型间的张量级参数共享、按需KV缓存分配用于动态内存管理，以及GPU亲和性感知调度以最大化资源利用率。

Result: 实验表明，Tangram实现了高达6.2倍的加载速度提升，并将冷启动期间的Time-To-First-Token (TTFT)减少了23-55%。

Conclusion: Tangram系统通过高效的GPU内存重用技术，显著减少了Serverless LLM的加载时间和冷启动延迟，为大规模LLM服务的实际部署提供了可行的解决方案。

Abstract: Serverless Large Language Models (LLMs) have emerged as a cost-effective solution for deploying AI services by enabling a 'pay-as-you-go' pricing model through GPU resource sharing. However, cold-start latency, especially the model loading phase, has become a critical performance bottleneck, as it scales linearly with model size and severely limits the practical deployment of large-scale LLM services. This paper presents Tangram, a novel system that accelerates Serverless LLM loading through efficient GPU memory reuse. By leveraging the unused GPU memory to retain model parameters, Tangram significantly reduces model transfer time and cold-start latency. Its design includes three key components: unified GPU memory pool for tensor-level parameter sharing across models, on-demand KV cache allocation for dynamic memory management, and GPU-affinity-aware scheduling for maximizing resource utilization. These techniques collectively address the critical challenges of inefficient memory usage and the cold-start problem in Serverless LLM platforms. We have implemented a fully functional prototype, and experiments show that Tangram achieves up to 6.2 times faster loading and reduces Time-To-First-Token (TTFT) during cold-start by 23--55% over state-of-the-art methods.

</details>


### [350] [Delta Sum Learning: an approach for fast and global convergence in Gossip Learning](https://arxiv.org/abs/2512.01549)
*Tom Goethals,Merlijn Sebrechts,Stijn De Schrijver,Filip De Turck,Bruno Volckaert*

Main category: cs.DC

TL;DR: Delta Sum Learning通过改进Gossip Learning的聚合操作，结合去中心化编排框架，显著提升了扩展性和准确率。


<details>
  <summary>Details</summary>
Motivation: 联邦学习和Gossip Learning中的平均方法在模型准确性和全局收敛性上不理想，且边缘学习中缺乏声明式部署选项。

Method: 提出了Delta Sum Learning作为改进Gossip Learning中基本聚合操作的方法，并基于Open Application Model实现了一个去中心化编排框架。

Result: 评估显示，Delta Sum在10节点拓扑中性能与替代方法相当，但在扩展至50节点时全局准确率下降降低58%。

Conclusion: Delta Sum Learning 在扩展至50节点时表现出更强的全局收敛性，与替代方法相比，在有限连接下准确率下降呈对数而非线性趋势。

Abstract: Federated Learning is a popular approach for distributed learning due to its security and computational benefits. With the advent of powerful devices in the network edge, Gossip Learning further decentralizes Federated Learning by removing centralized integration and relying fully on peer to peer updates. However, the averaging methods generally used in both Federated and Gossip Learning are not ideal for model accuracy and global convergence. Additionally, there are few options to deploy Learning workloads in the edge as part of a larger application using a declarative approach such as Kubernetes manifests. This paper proposes Delta Sum Learning as a method to improve the basic aggregation operation in Gossip Learning, and implements it in a decentralized orchestration framework based on Open Application Model, which allows for dynamic node discovery and intent-driven deployment of multi-workload applications. Evaluation results show that Delta Sum performance is on par with alternative integration methods for 10 node topologies, but results in a 58% lower global accuracy drop when scaling to 50 nodes. Overall, it shows strong global convergence and a logarithmic loss of accuracy with increasing topology size compared to a linear loss for alternatives under limited connectivity.

</details>


### [351] [StarDist: A Code Generator for Distributed Graph Algorithms](https://arxiv.org/abs/2512.01646)
*Barenya Kumar Nandy,Rupesh Nasre*

Main category: cs.DC

TL;DR: StarPlat通过优化分布式图算法的通信和内存访问，显著提升了性能，超越了现有解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着图数据的增大，不规则访问模式、NUMA和物理内存限制使得传统顺序/共享内存框架难以扩展，需要设计更高效的分布式图算法。

Method: 本研究提出了一个分析-转换框架，利用StarPlat中节点及其邻居迭代的通用语义来聚合通信，并通过Open MPI的被动远程内存访问（RMA）构建优化的批量归约子层。

Result: 优化后的StarPlat分布式后端在多个大数据图上的单源最短路径计算中，性能分别比d-Galois和DRONE提高了2.05倍和1.44倍。

Conclusion: StarPlat的MPI后端通过抽象分布式图算法的编程复杂性，提供了一个可扩展的分布式内存解决方案，并通过优化逻辑在性能上超越了d-Galois和DRONE。

Abstract: Relational data, occurring in the real world, are often structured as graphs, which provide the logical abstraction required to make analytical derivations simpler. As graphs get larger, the irregular access patterns exhibited in most graph algorithms, hamper performance. This, along with NUMA and physical memory limits, results in scaling complexities with sequential/shared memory frameworks. StarPlat's MPI backend abstracts away the programmatic complexity involved in designing optimal distributed graph algorithms. It provides an instrument for coding graph algorithms that scale over distributed memory. In this work, we provide an analysis-transformation framework that leverages general semantics associated with iterations involving nodes and their neighbors, within StarPlat, to aggregate communication. The framework scans for patterns that warrant re-ordering in neighborhood access patterns, aggregate communication, and avoid communication altogether with opportunistic caching in reduction constructs. We also architect an optimized bulk-reduction substrate using Open MPI's passive Remote Memory Access (RMA) constructs. We applied our optimization logic to StarPlat's distributed backend and outperformed d-Galois by 2.05 and DRONE by 1.44 times in Single Source Shortest Paths across several big data graphs.

</details>


### [352] [Trace-based, time-resolved analysis of MPI application performance using standard metrics](https://arxiv.org/abs/2512.01764)
*Kingshuk Haldar*

Main category: cs.DC

TL;DR: 本文提出了一种基于时间分段的MPI性能指标计算方法，通过处理Paraver轨迹并计算时变指标，有效揭示了瞬态性能瓶颈，为性能工程提供了一种轻量级且可扩展的解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着MPI应用程序跟踪规模的增大和通信行为的复杂化，全面的视觉检查变得不切实际。因此，需要一种能够揭示瞬态性能瓶颈的方法，以补充现有工具的全局聚合指标。

Method: 通过将执行轨迹离散化为固定或自适应时间片段，实现了标准MPI性能指标（负载平衡、序列化和传输效率）的时变计算。实现过程中处理了Paraver轨迹的后处理，重建关键执行路径并处理常见事件异常（如时钟不一致和未匹配的MPI事件），以确保每个片段的指标计算稳健。

Result: 在合成基准测试和实际应用中，时变指标成功揭示了全局聚合指标掩盖的局部性能瓶颈，证明了该方法的有效性和实用性。

Conclusion: 本文提出了一种基于时间分段的方法，用于计算MPI性能指标的时变值，有效揭示了传统工具中全局聚合指标可能掩盖的瞬态性能瓶颈。该方法在合成基准测试和实际应用（LaMEM和ls1-MarDyn）中验证了其有效性，提供了一种轻量级且可扩展的替代方案。

Abstract: Detailed trace analysis of MPI applications is essential for performance engineering, but growing trace sizes and complex communication behaviour often render comprehensive visual inspection impractical. This work presents a trace-based calculation of time-resolved values of standard MPI performance metrics, load balance, serialisation, and transfer efficiency, by discretising execution traces into fixed or adaptive time segments. The implementation processes Paraver traces postmortem, reconstructing critical execution paths and handling common event anomalies, such as clock inconsistencies and unmatched MPI events, to robustly calculate metrics for each segment. The calculated per-window metric values expose transient performance bottlenecks that the timeaggregated metrics from existing tools may conceal. Evaluations on a synthetic benchmark and real-world applications (LaMEM and ls1-MarDyn) demonstrate how time-resolved metrics reveal localised performance bottlenecks obscured by global aggregates, offering a lightweight and scalable alternative even when trace visualisation is impractical.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [353] [Injecting Sustainability in Software Architecture: A Rapid Review](https://arxiv.org/abs/2512.00106)
*Markus Funke,Patricia Lago*

Main category: cs.SE

TL;DR: 通过文献综述与焦点小组研究，提出了五项建议，帮助软件架构师在实际工作中整合可持续性考量。


<details>
  <summary>Details</summary>
Motivation: 随着可持续性在软件工程中的重要性日益凸显，研究如何将其系统性地融入现有实践成为迫切需求。

Method: 采用混合方法实证研究，结合快速文献综述和从业者焦点小组。

Result: 识别了在软件架构中嵌入可持续性的挑战与机遇，并基于文献与行业实践提出了五项实用建议。

Conclusion: 本研究通过文献综述与焦点小组的结合，提出了五项具体建议，旨在指导软件架构师在实际工作中整合可持续性考量。

Abstract: Sustainability has evolved from an emerging concern into a fundamental responsibility in software design, development, and operation. Research increasingly explores how sustainability can be systematically integrated into existing software engineering practices. Building on an industry-academia collaboration, we contribute to this discourse by conducting a mixed-method empirical study. We combine a rapid review of secondary studies with a focus group of practitioners. The review identifies challenges and opportunities in embedding sustainability in software architecture, while the focus group enriches and compares these findings. Based on the literature and industry synthesis, we derive five tangible takeaways to inform architects working in the field, and to guide our industry partners in the integration of sustainability concerns in architecture practices.

</details>


### [354] [Generating Verifiable CoT from Execution-Traces](https://arxiv.org/abs/2512.00127)
*Shailja Thakur,Vaibhav Saxena,Rohan Kulkarni,Shivdeep Singh,Parameswaran Selvam,Hima Patel,Hiroshi Kanayama*

Main category: cs.SE

TL;DR: 通过基于程序执行轨迹生成可验证的CoT，显著提升模型在代码相关任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 解决当前合成训练数据中推理步骤缺乏可验证性，导致模型学习到表面合理但逻辑错误的推理模式的问题。

Method: 提出了一种基于程序执行轨迹的CoT生成方法，通过代码插桩捕获动态行为，并将验证后的执行轨迹转化为自然语言解释。

Result: 在代码推理任务（CruxEval和LiveCodeBench-Exec的前向推理，CruxEval-Input的后向推理）以及HumanEval的代码生成和解释任务中，模型表现显著提升，输出预测和输入预测分别提高了30分和28分。

Conclusion: 通过将CoT生成直接基于程序执行轨迹，该方法显著提升了模型在代码推理、生成和解释任务中的表现，验证了可验证推理对模型能力的根本性提升。

Abstract: Teaching language models to reason about code execution remains a fundamental challenge. While Chain-of-Thought (CoT) prompting has shown promise, current synthetic training data suffers from a critical weakness: the reasoning steps are often plausible-sounding explanations generated by teacher models, not verifiable accounts of what the code actually does. This creates a troubling failure mode where models learn to mimic superficially convincing but logically flawed reasoning patterns.
  We address this by grounding CoT generation directly in program execution traces. Our pipeline instruments code to capture its dynamic behavior, then narrates these verified execution traces into natural language rationales that are correct by construction. This execution-grounded approach ensures every reasoning step reflects what the program genuinely computes, eliminating logical hallucinations at the source. We evaluate our method on code reasoning tasks (forward reasoning on CruxEval and LiveCodeBench-Exec, backward reasoning on CruxEval-Input), as well as code generation and explanation tasks from HumanEval. Models trained on our bi-directional trace-grounded data achieve substantial improvements, with gains of up to 30 points on output prediction and 28 points on input prediction over base models, alongside improved explanation and code generation, demonstrating that verifiable reasoning fundamentally enhances model capabilities. https://github.ibm.com/IBM-Research-AI/Verified-Code-CoT

</details>


### [355] [Asm2SrcEval: Evaluating Large Language Models for Assembly-to-Source Code Translation](https://arxiv.org/abs/2512.00134)
*Parisa Hamedi,Hamed Jelodar,Samita Bai,Mohammad Meymani,Roozbeh Razavi-Far,Ali A. Ghorbani*

Main category: cs.SE

TL;DR: 首次全面评估五种大型语言模型在汇编到源代码翻译中的表现，揭示了模型在准确性、流畅性和效率之间的权衡，为未来研究奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 汇编到源代码翻译在逆向工程、网络安全和软件维护中至关重要，但目前缺乏系统性基准来评估大型语言模型在此问题上的表现。

Method: 评估了五种最先进的大型语言模型在汇编到源代码翻译中的表现，使用了多种指标，包括词汇相似性（BLEU、ROUGE、METEOR）、语义对齐（BERTScore）、流畅性（Perplexity）和效率（时间预测）。

Result: 结果显示不同模型在文本相似性、流畅性或推理速度方面各有优劣，定性分析揭示了控制流恢复和标识符重建等挑战。

Conclusion: 本研究为程序翻译领域的未来研究奠定了基础，结合准确性和效率的实际应用提供了可行的见解。

Abstract: Assembly-to-source code translation is a critical task in reverse engineering, cybersecurity, and software maintenance, yet systematic benchmarks for evaluating large language models on this problem remain scarce. In this work, we present the first comprehensive evaluation of five state-of-the-art large language models on assembly-to-source translation. We assess model performance using a diverse set of metrics capturing lexical similarity (BLEU, ROUGE, and METEOR), semantic alignment (BERTScore), fluency (Perplexity), and efficiency (time prediction). Our results reveal clear trade-offs: while certain models excel in text similarity metrics, others demonstrate lower perplexity or faster inference times. We further provide qualitative analyses of typical model successes and failure cases, highlighting challenges such as control flow recovery and identifier reconstruction. Taken together, our benchmark offers actionable insights into the strengths and limitations of current large language models for program translation, establishing a foundation for future research in combining accuracy with efficiency for real-world applications.

</details>


### [356] [Demystifying Errors in LLM Reasoning Traces: An Empirical Study of Code Execution Simulation](https://arxiv.org/abs/2512.00215)
*Mohammad Abdollahi,Khandaker Rifah Tasnia,Soumit Kanti Saha,Jinqiu Yang,Song Wang,Hadi Hemmati*

Main category: cs.SE

TL;DR: 首次对LLMs的运行时推理行为进行实证研究，揭示了其推理错误并分类，工具支持可显著改善计算错误。


<details>
  <summary>Details</summary>
Motivation: 理解程序的运行时推理行为对可靠代码生成、调试和自动化推理至关重要，但现有研究多关注输出准确性，忽略了推理过程的结构和失败模式。

Method: 通过从HumanEval Plus和LiveCodeBench中精选427个代码片段，测试三种输入类型（常规、边缘和无效），并评估四种最先进的推理LLMs。

Result: 评估的LLMs在各类输入上的准确率介于85%至98%之间，同时识别并分类了九种推理错误。

Conclusion: 研究表明，工具支持的推理方法可以显著改善LLMs的推理错误，特别是在计算错误类别中，成功纠正了58%的错误。

Abstract: Understanding a program's runtime reasoning behavior, meaning how intermediate states and control flows lead to final execution results, is essential for reliable code generation, debugging, and automated reasoning. Although large language models (LLMs) can accurately predict program outputs, most prior work has focused on output accuracy and performance, treating reasoning as a black box. As a result, little is known about the structure or failure modes of their reasoning traces. To address this gap, we conduct the first empirical study on runtime behavior inference with reasoning LLMs, aiming to uncover and characterize errors in their reasoning traces. We curate a benchmark from HumanEval Plus and LiveCodeBench, containing 427 code snippets. For each snippet, we test three input types: regular, edge, and invalid. Twelve input values are selected per snippet, each paired with its ground-truth execution result. We evaluate four state-of-the-art reasoning LLMs. Our results show that these models reach accuracies between 85 percent and 98 percent across input types. We also analyze the produced reasoning traces and develop a taxonomy with nine categories of inference errors. Finally, we explore tool-augmented reasoning. Using failures in the Computation Errors category as a case study, our experiments show that this approach corrects 58 percent of such errors, demonstrating the potential of tool support for improving LLM reasoning.

</details>


### [357] [CodeFlowLM: Incremental Just-In-Time Defect Prediction with Pretrained Language Models and Exploratory Insights into Defect Localization](https://arxiv.org/abs/2512.00231)
*Monique Louise Monteiro,George G. Cabral,Adriano L. I. OLiveira*

Main category: cs.SE

TL;DR: CodeFlowLM通过持续微调PLMs提升JIT-SDP性能，显著优于传统方法。LLMs在JIT-DL中表现接近注意力模型，但仍有局限性。


<details>
  <summary>Details</summary>
Motivation: 传统在线学习方法难以应对JIT-SDP中的概念漂移、类别不平衡和验证延迟问题，且从头训练成本高。LLMs在JIT-DL中的潜力尚未充分探索。

Method: CodeFlowLM采用持续微调策略，利用预训练语言模型（如CodeT5+和UniXCoder）处理概念漂移、类别不平衡和验证延迟问题，无需从头训练。在JIT-DL中，对比了GPT-5等LLMs与基于注意力的模型。

Result: CodeFlowLM在JIT-SDP中实现了高达68%的G-Mean提升。在JIT-DL中，GPT-5在Recall@20%和Effort@20%上表现稳定，但基于注意力的模型在细粒度排名指标（Top-k、IFA）上仍占优。

Conclusion: CodeFlowLM显著提升了增量式JIT-SDP的技术水平，展示了在动态软件环境中的卓越适应性和鲁棒性。同时，对LLMs在JIT-DL中的探索性分析不仅对标了其与现有基于注意力模型的性能，还揭示了基于提示的缺陷推理的当前局限性。

Abstract: This work introduces CodeFlowLM, an incremental learning framework for Just-In-Time Software Defect Prediction (JIT-SDP) that leverages pre-trained language models (PLMs). Unlike traditional online learners, CodeFlowLM employs continual fine-tuning to address concept drift, class imbalance, and verification latency without retraining from scratch. We evaluated encoder-only and encoder-decoder PLMs (notably CodeT5+ and UniXCoder) in JIT-SDP scenarios within and between projects, comparing them with the incremental baseline BORB. The results show that CodeFlowLM achieves up to 68% G-Mean gains, confirming its superior adaptability and robustness in evolving software environments. We further extend the analysis to Just-in-Time Defect Localization (JIT-DL), benchmarking Large Language Models (LLMs) such as GPT-5, Claude Sonnet 4.5, and Gemini 2.5 Pro against attention-based models. GPT-5 delivers comparable performance for Recall@20% and Effort@20% with higher stability, although attention-based methods retain an advantage in fine-grained ranking metrics (Top-k, IFA). A qualitative error analysis reveals that most false positives arise from (1) human-like conservative bias, (2) insufficient contextual information in diff-based prompts, and (3) potential dataset mislabeling in JIT-Defects4J. These findings highlight both the promise and the current limitations of LLM reasoning in defect localization. False negatives occur in smaller proportions. Overall, CodeFlowLM significantly advances the state of the art in incremental JIT-SDP, demonstrating superior adaptability and robustness in evolving software environments. Furthermore, our exploratory analysis of LLMs in JIT-DL not only benchmarks their performance against established attention-based models but also provides critical insights into the current limitations of prompt-based defect reasoning.

</details>


### [358] [ng-reactive-lint: Smarter Linting for Angular Apps](https://arxiv.org/abs/2512.00250)
*Shrinivass Arunachalam Balasubramanian*

Main category: cs.SE

TL;DR: ng-reactive-lint 是一款专为 Angular 设计的静态分析工具，通过框架感知分析解决响应式编程误用问题，显著提升性能和内存效率。


<details>
  <summary>Details</summary>
Motivation: Angular 应用中响应式编程的误用（如 Observables 和 Signals）常导致性能下降和内存泄漏，尤其在遗留 RxJS 模式广泛使用的企业代码库中。

Method: 开发了 ng-reactive-lint，一个基于静态分析的确定性工具，专门针对 Angular 的组件语义、生命周期钩子、模板绑定和响应式模式进行框架感知分析。

Result: 在五个大型实际项目中评估显示，不必要的变更检测周期减少高达三倍，峰值内存使用降低达 75%。

Conclusion: ng-reactive-lint 提供了一种自动化、实用的方法，帮助大规模采用现代 Angular 响应式编程模型，显著提升了性能和内存效率。

Abstract: Reactivity is central to Angular applications, yet subtle misuse of Observables, Signals, and change-detection often leads to performance regressions that are difficult to diagnose. Although Angular 17 introduced a unified, signal-first model, most enterprise codebases still rely heavily on legacy RxJS patterns that create unpredictable update flows, memory leaks, and excessive change cycles. To address these issues, we developed ng-reactive-lint, a deterministic static analysis tool that understands Angular's component semantics, lifecycle hooks, template bindings, and reactivity patterns. Unlike generic ESLint or RxJS plugins, ng-reactive-lint performs framework-aware analysis to detect high-impact anti-patterns and provide actionable, context-specific fixes. Evaluation across five large real-world projects showed reductions of up to threefold in unnecessary change detection cycles and up to 75% lower peak memory usage. The tool offers a practical, automated path to adopting modern Angular reactivity at scale.

</details>


### [359] [Progressive Code Integration for Abstractive Bug Report Summarization](https://arxiv.org/abs/2512.00325)
*Shaira Sadia Karim,Abrar Mahmud Rahim,Lamia Alam,Ishmam Tashdeed,Lutfun Nahar Lota,Md. Abu Raihan M. Kamal,Md. Azam Hossain*

Main category: cs.SE

TL;DR: 论文提出渐进式代码集成框架，结合文本和代码信息，显著提升缺陷报告摘要质量，评估显示优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有摘要方法依赖表层文本线索，常忽略关联代码片段，导致摘要不完整或冗余，影响缺陷诊断准确性。

Method: 采用渐进式代码集成框架，逐步引入长代码片段和文本内容，克服标准LLM上下文窗口限制。

Result: 在四个基准数据集和八种LLM上的评估显示，该方法比抽取式基线方法提升7.5%-58.2%，性能与最先进的抽象方法相当。

Conclusion: 该论文提出的渐进式代码集成框架显著提升了基于LLM的缺陷报告摘要生成质量，通过结合文本和代码信息，实现了更丰富的语义摘要。

Abstract: Bug reports are often unstructured and verbose, making it challenging for developers to efficiently comprehend software issues. Existing summarization approaches typically rely on surface-level textual cues, resulting in incomplete or redundant summaries, and they frequently ignore associated code snippets, which are essential for accurate defect diagnosis. To address these limitations, we propose a progressive code-integration framework for LLM-based abstractive bug report summarization. Our approach incrementally incorporates long code snippets alongside textual content, overcoming standard LLM context window constraints and producing semantically rich summaries. Evaluated on four benchmark datasets using eight LLMs, our pipeline outperforms extractive baselines by 7.5%-58.2% and achieves performance comparable to state-of-the-art abstractive methods, highlighting the benefits of jointly leveraging textual and code information for enhanced bug comprehension.

</details>


### [360] [Framework-Aware Code Generation with API Knowledge Graph-Constructed Data: A Study on HarmonyOS](https://arxiv.org/abs/2512.00380)
*Mingwei Liu,Zheng Pei,Yanlin Wang,Zihao Wang,Zikang Li,Enci Lin,Xin Peng,Zibin Zheng*

Main category: cs.SE

TL;DR: APIKG4SYN框架通过API知识图谱增强LLM对低资源框架的适应性，实验验证其显著提升代码生成性能。


<details>
  <summary>Details</summary>
Motivation: LLM在低资源框架中因缺乏预训练数据而表现不佳，需针对性优化以提升其API使用和代码生成能力。

Method: 提出APIKG4SYN框架，结合单API和多API知识（通过不确定性估计驱动的蒙特卡洛树搜索生成），构建多样化数据集用于微调LLM。

Result: 微调后的Qwen模型在HarmonyOS代码生成任务中pass@1准确率提升至25.00%，优于基线GPT模型的17.59%。

Conclusion: APIKG4SYN框架通过利用API知识图谱构建面向API的问题-代码对，显著提升了LLM在低资源框架（如HarmonyOS）中的代码生成性能，实验证明其有效性。

Abstract: In the context of software frameworks with limited resources (such as HarmonyOS), large language models (LLMs) often exhibit poor code generation performance because they lack sufficient exposure to such environments during pre-training. Although LLMs can usually maintain correct logical structures across programming languages, they frequently struggle when dealing with framework-specific APIs or syntax, resulting in errors. This indicates that while pre-training equips LLMs with general algorithmic capabilities, they remain unfamiliar with the distinctive syntax and API usage of underrepresented frameworks. As a result, even advanced commercial models like GPT-4o cannot reliably generate correct code without prior adaptation. To address this issue, we propose APIKG4SYN, a framework designed to exploit API knowledge graphs for the construction of API-oriented question-code pairs, specifically tailored for low-resource frameworks without requiring executable code. APIKG4SYN integrates both single-API and multi-API knowledge, where the latter is derived through uncertainty estimation (UE)-driven Monte Carlo Tree Search (MCTS), enabling the creation of a diverse and informative dataset for fine-tuning LLMs. Using HarmonyOS as a case study, we build the first benchmark for HarmonyOS code generation. Experimental results show that fine-tuning Qwen with APIKG4SYN raises pass@1 accuracy to 25.00%, compared with 17.59% for the baseline GPT model. These results confirm that API-oriented data significantly enhance LLM performance in low-resource software development scenarios.

</details>


### [361] [Bias Testing and Mitigation in Black Box LLMs using Metamorphic Relations](https://arxiv.org/abs/2512.00556)
*Sina Salimian,Gias Uddin,Sumon Biswas,Henry Leung*

Main category: cs.SE

TL;DR: 通过变形关系（MRs）自动检测和缓解LLMs中的隐藏偏见，显著提升模型公平性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的广泛部署加剧了对其输出中隐含的微妙社会偏见的担忧，现有防护措施在处理间接或上下文复杂的偏见诱导提示时往往失效。

Method: 提出一个统一框架，引入六种新颖的变形关系（MRs），基于变形测试原则将直接偏见诱导输入转化为语义等效但对抗性挑战的变体，用于系统性偏见评估和针对性缓解。

Result: 使用六种最先进的LLMs和BiasAsker基准中的385个问题，MRs揭示了比现有工具多14%的隐藏偏见，微调后安全响应率显著提升。

Conclusion: 变形关系（MRs）作为一种实用机制，显著提升了对话AI的公平性，通过微调使安全响应率从54.7%提升至88.9%。

Abstract: The widespread deployment of Large Language Models (LLMs) has intensified concerns about subtle social biases embedded in their outputs. Existing guardrails often fail when faced with indirect or contextually complex bias-inducing prompts. To address these limitations, we propose a unified framework for both systematic bias evaluation and targeted mitigation. Our approach introduces six novel Metamorphic Relations (MRs) that, based on metamorphic testing principles, transform direct bias-inducing inputs into semantically equivalent yet adversarially challenging variants. These transformations enable an automated method for exposing hidden model biases: when an LLM responds inconsistently or unfairly across MR-generated variants, the underlying bias becomes detectable. We further show that the same MRs can be used to generate diverse bias-inducing samples for fine-tuning, directly linking the testing process to mitigation. Using six state-of-the-art LLMs - spanning open-source and proprietary models - and a representative subset of 385 questions from the 8,978-item BiasAsker benchmark covering seven protected groups, our MRs reveal up to 14% more hidden biases compared to existing tools. Moreover, fine-tuning with both original and MR-mutated samples significantly enhances bias resiliency, increasing safe response rates from 54.7% to over 88.9% across models. These results highlight metamorphic relations as a practical mechanism for improving fairness in conversational AI.

</details>


### [362] [SAGE: Semantic-Aware Gray-Box Game Regression Testing with Large Language Models](https://arxiv.org/abs/2512.00560)
*Jinyu Cai,Jialong Li,Nianyu Li,Zhenyu Mao,Mingyue Zhang,Kenji Tei*

Main category: cs.SE

TL;DR: SAGE是一个针对灰度游戏环境的语义感知回归测试框架，通过LLM引导的强化学习和语义优化，高效生成并优先处理测试用例，显著提升缺陷检测率并降低成本。


<details>
  <summary>Details</summary>
Motivation: 现代实时服务游戏的快速迭代周期使得回归测试成为维持质量和稳定的关键，但现有方法在灰度环境下存在测试用例构建依赖手动、套件冗余和维护困难等问题。

Method: SAGE采用LLM引导的强化学习进行目标导向探索生成多样化测试套件，并基于语义的多目标优化进行精简。最后利用LLM分析更新日志优先处理相关测试用例。

Result: 在Overcooked Plus和Minecraft环境中，SAGE相比自动化基准和人工记录测试用例，实现了更高的缺陷检测率和更低的执行成本。

Conclusion: SAGE框架在灰度游戏环境中表现出卓越的缺陷检测能力和低执行成本，同时展现出对版本更新的强适应性。

Abstract: The rapid iteration cycles of modern live-service games make regression testing indispensable for maintaining quality and stability. However, existing regression testing approaches face critical limitations, especially in common gray-box settings where full source code access is unavailable: they heavily rely on manual effort for test case construction, struggle to maintain growing suites plagued by redundancy, and lack efficient mechanisms for prioritizing relevant tests. These challenges result in excessive testing costs, limited automation, and insufficient bug detection. To address these issues, we propose SAGE, a semanticaware regression testing framework for gray-box game environments. SAGE systematically addresses the core challenges of test generation, maintenance, and selection. It employs LLM-guided reinforcement learning for efficient, goal-oriented exploration to automatically generate a diverse foundational test suite. Subsequently, it applies a semantic-based multi-objective optimization to refine this suite into a compact, high-value subset by balancing cost, coverage, and rarity. Finally, it leverages LLM-based semantic analysis of update logs to prioritize test cases most relevant to version changes, enabling efficient adaptation across iterations. We evaluate SAGE on two representative environments, Overcooked Plus and Minecraft, comparing against both automated baselines and human-recorded test cases. Across all environments, SAGE achieves superior bug detection with significantly lower execution cost, while demonstrating strong adaptability to version updates.

</details>


### [363] [FC-ADL: Efficient Microservice Anomaly Detection and Localisation Through Functional Connectivity](https://arxiv.org/abs/2512.00844)
*Giles Winchester,George Parisis,Luc Berthouze*

Main category: cs.SE

TL;DR: FC-ADL 是一种基于功能连接性的方法，用于高效检测和定位微服务架构中的异常，适用于大规模部署。


<details>
  <summary>Details</summary>
Motivation: 微服务架构的复杂性和动态性使得异常检测和定位具有挑战性，现有方法在时间变化依赖关系和可扩展性方面存在不足。

Method: 提出 FC-ADL，一种基于功能连接性的端到端方法，通过高效表征微服务指标间的时间变化依赖关系来检测异常并提供根因候选。

Result: FC-ADL 在多种故障场景下表现出优于现有方法的检测和定位性能，并在阿里巴巴的大规模实际部署中验证了其可扩展性。

Conclusion: FC-ADL 是一种基于功能连接性概念的可扩展方法，能够高效检测和定位微服务架构中的异常，且在真实大规模部署中表现出色。

Abstract: Microservices have transformed software architecture through the creation of modular and independent services. However, they introduce operational complexities in service integration and system management that makes swift and accurate anomaly detection and localisation challenging. Despite the complex, dynamic, and interconnected nature of microservice architectures, prior works that investigate metrics for anomaly detection rarely include explicit information about time-varying interdependencies. And whilst prior works on fault localisation typically do incorporate information about dependencies between microservices, they scale poorly to real world large-scale deployments due to their reliance on computationally expensive causal inference. To address these challenges we propose FC-ADL, an end-to-end scalable approach for detecting and localising anomalous changes from microservice metrics based on the neuroscientific concept of functional connectivity. We show that by efficiently characterising time-varying changes in dependencies between microservice metrics we can both detect anomalies and provide root cause candidates without incurring the significant overheads of causal and multivariate approaches. We demonstrate that our approach can achieve top detection and localisation performance across a wide degree of different fault scenarios when compared to state-of-the-art approaches. Furthermore, we illustrate the scalability of our approach by applying it to Alibaba's extremely large real-world microservice deployment.

</details>


### [364] [Enhancing Analogy-Based Software Effort Estimation with Firefly Algorithm Optimization](https://arxiv.org/abs/2512.00571)
*Tarun Chintada,Uday Kiran Cheera*

Main category: cs.SE

TL;DR: FAABE模型结合萤火虫算法与类比估计，提升软件项目估计精度，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统ABE模型在新软件项目中估计准确性不足，需要更优方法。

Method: 本研究提出了FAABE模型，结合萤火虫算法（FA）与类比估计（ABE），并采用特征选择提升预测效率。

Result: 实验结果表明，FAABE模型在多个数据集上表现优于传统模型，评估指标（如MMRE、MAE等）显示精度提升。

Conclusion: FAABE模型通过结合萤火虫算法与类比估计，显著提高了预测精度，验证了其有效性。

Abstract: Analogy-Based Estimation (ABE) is a popular method for non-algorithmic estimation due to its simplicity and effectiveness. The Analogy-Based Estimation (ABE) model was proposed by researchers, however, no optimal approach for reliable estimation was developed. Achieving high accuracy in the ABE might be challenging for new software projects that differ from previous initiatives. This study (conducted in June 2024) proposes a Firefly Algorithm-guided Analogy-Based Estimation (FAABE) model that combines FA with ABE to improve estimation accuracy. The FAABE model was tested on five publicly accessible datasets: Cocomo81, Desharnais, China, Albrecht, Kemerer and Maxwell. To improve prediction efficiency, feature selection was used. The results were measured using a variety of evaluation metrics; various error measures include MMRE, MAE, MSE, and RMSE. Compared to conventional models, the experimental results show notable increases in prediction precision, demonstrating the efficacy of the Firefly-Analogy ensemble.

</details>


### [365] [Large Language Models for Software Engineering: A Reproducibility Crisis](https://arxiv.org/abs/2512.00651)
*Mohammed Latif Siddiq,Arvin Islam-Gomes,Natalie Sekerak,Joanna C. S. Santos*

Main category: cs.SE

TL;DR: 该论文首次大规模实证研究了LLM-for-SE研究的可复现性实践，揭示了可复现性问题的持续存在，并提出了RMM模型和改进建议。


<details>
  <summary>Details</summary>
Motivation: 研究大语言模型（LLM）在软件工程（SE）研究中的可复现性现状，填补这一领域的研究空白。

Method: 通过系统挖掘和分析2017至2025年间发表的640篇论文，提取结构化元数据，并基于七个气味类别手动标注所有论文及相关工件。

Result: 分析揭示了工件可用性、环境规范、版本严谨性和文档清晰性方面的持续差距，尽管近年来有所改善，且顶级SE会议增加了工件评估流程的采用。研究发现，徽章通常表示工件的存在，但并不能始终保证执行保真度或长期可复现性。

Conclusion: 该论文提出了可复现性成熟度模型（RMM），旨在超越二元的工件认证，实现多维度的、渐进式的可复现性严格评估，并提供了具体建议以减少可复现性问题。

Abstract: Reproducibility is a cornerstone of scientific progress, yet its state in large language model (LLM)-based software engineering (SE) research remains poorly understood. This paper presents the first large-scale, empirical study of reproducibility practices in LLM-for-SE research. We systematically mined and analyzed 640 papers published between 2017 and 2025 across premier software engineering, machine learning, and natural language processing venues, extracting structured metadata from publications, repositories, and documentation. Guided by four research questions, we examine (i) the prevalence of reproducibility smells, (ii) how reproducibility has evolved over time, (iii) whether artifact evaluation badges reliably reflect reproducibility quality, and (iv) how publication venues influence transparency practices. Using a taxonomy of seven smell categories: Code and Execution, Data, Documentation, Environment and Tooling, Versioning, Model, and Access and Legal, we manually annotated all papers and associated artifacts. Our analysis reveals persistent gaps in artifact availability, environment specification, versioning rigor, and documentation clarity, despite modest improvements in recent years and increased adoption of artifact evaluation processes at top SE venues. Notably, we find that badges often signal artifact presence but do not consistently guarantee execution fidelity or long-term reproducibility. Motivated by these findings, we provide actionable recommendations to mitigate reproducibility smells and introduce a Reproducibility Maturity Model (RMM) to move beyond binary artifact certification toward multi-dimensional, progressive evaluation of reproducibility rigor.

</details>


### [366] [Code Comments for Quantum Software Development Kits: An Empirical Study on Qiskit](https://arxiv.org/abs/2512.00766)
*Zenghui Zhou,Yuechen Li,Yi Cai,Jinlong Wen,Xiaohan Yu,Zheng Zheng,Beibei Yin*

Main category: cs.SE

TL;DR: 论文构建了首个量子计算代码注释数据集CC4Q，通过实证研究揭示了量子软件注释的独特性，并提出了量子特定知识的分类法。


<details>
  <summary>Details</summary>
Motivation: 量子计算的兴起使得量子软件开发成为热点，但程序员因量子力学的不直观性面临理解挑战。现有研究缺乏对量子软件注释价值的系统性探讨和指导。

Method: 研究聚焦于Qiskit量子SDK，构建了CC4Q数据集，包含9677对代码注释和21970个句子级注释单元，并进行了人工标注。

Result: 研究发现量子软件注释在结构、覆盖范围、开发者意图和关联量子主题方面与传统软件存在显著差异。

Conclusion: 论文总结了量子软件注释与传统软件注释的关键差异，并提出了量子软件开发中相关的量子特定知识。

Abstract: Quantum computing is gaining attention from academia and industry. With the quantum Software Development Kits (SDKs), programmers can develop quantum software to explore the power of quantum computing. However, programmers may face challenges in understanding quantum software due to the non-intuitive quantum mechanics. To facilitate software development and maintenance, code comments offered in quantum SDKs serve as a natural language explanation of program functionalities and logical flows. Despite their importance, scarce research systematically reports their value and provides constructive guidelines for programmers. To address this gap, our paper focuses on Qiskit, one of the most popular quantum SDKs, and presents CC4Q, the first dataset of code comments for quantum computing. CC4Q incorporates 9677 code comment pairs and 21970 sentence-level code comment units, the latter of which involve heavy human annotation. Regarding the annotation, we validate the applicability of the developer-intent taxonomy used in classical programs, and also propose a new taxonomy considering quantum-specific knowledge. We conduct an empirical study comprehensively interpreting code comments from three perspectives: comment structure and coverage, developers' intentions, and associated quantum topics. Our findings uncover key differences in code comments between classical and quantum software, and also outline quantum-specific knowledge relevant to quantum software development.

</details>


### [367] [The Software Infrastructure Attitude Scale (SIAS): A Questionnaire Instrument for Measuring Professionals' Attitudes Toward Technical and Sociotechnical Infrastructure](https://arxiv.org/abs/2512.00855)
*Miikka Kuutila,Paul Ralph,Huilian Sophie Qiu,Ronnie de Souza Santos,Morakot Choetkiertikul,Amin Milani Fard,Rana Alkadhi,Xavier Devroey,Gregorio Robles,Hideaki Hata,Sebastian Baltes,Vladimir Kovalenko,Shalini Chakraborty,Eray Tuzun,Hera Arif,Gianisa Adisaputri,Kelly Garcés,Anielle S. L. Andrade,Eyram Amedzor,Bimpe Ayoola,Keisha Gaspard-Chickoree,Arazoo Hoseyni*

Main category: cs.SE

TL;DR: 开发并验证了一个测量软件工程中技术和社会技术基础设施态度的心理测量量表，证实其有效性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 近期软件工程研究强调社会技术研究的需求，意味着需要定制化的心理测量量表。

Method: 基于基础设施、态度理论和心理测量学先前工作，定义了目标构念并生成量表项目。量表对225名软件专业人员进行了测试，采用分样本方法，通过探索性因子分析（EFA）和验证性因子分析（CFA）验证结构。

Result: EFA支持双因素结构（技术和社会技术基础设施），解释65%总方差且载荷强。CFA证实模型拟合优。量表具有良好的表面效度、内容效度、收敛效度和判别效度。

Conclusion: 该量表是测量软件工程中技术和社会技术基础设施态度的有效工具，为将心理学测量严谨性融入实证和行为软件工程研究做出了贡献。

Abstract: Context: Recent software engineering (SE) research has highlighted the need for sociotechnical research, implying a demand for customized psychometric scales. Objective: We define the concepts of technical and sociotechnical infrastructure in software engineering, and develop and validate a psychometric scale that measures attitudes toward them. Method: Grounded in theories of infrastructure, attitudes, and prior work on psychometric measurement, we defined the target constructs and generated scale items. The scale was administered to 225 software professionals and evaluated using a split sample. We conducted an exploratory factor analysis (EFA) on one half of the sample to uncover the underlying factor structure and performed a confirmatory factor analysis (CFA) on the other half to validate the structure. Further analyses with the whole sample assessed face, criterion-related, and discriminant validity. Results: EFA supported a two-factor structure (technical and sociotechnical infrastructure), accounting for 65% of the total variance with strong loadings. CFA confirmed excellent model fit. Face and content validity were supported by the item content reflecting cognitive, affective, and behavioral components. Both subscales were correlated with job satisfaction, perceived autonomy, and feedback from the job itself, supporting convergent validity. Regression analysis supported criterion-related validity, while the Heterotrait-Monotrait ratio of correlations (HTMT), the Fornell-Larcker criterion, and model comparison all supported discriminant validity. Discussion: The resulting scale is a valid instrument for measuring attitudes toward technical and sociotechnical infrastructure in software engineering research. Our work contributes to ongoing efforts to integrate psychological measurement rigor into empirical and behavioral software engineering research.

</details>


### [368] [The AI Attribution Paradox: Transparency as Social Strategy in Open-Source Software Development](https://arxiv.org/abs/2512.00867)
*Obada Kraishan*

Main category: cs.SE

TL;DR: AI代码助手使用广泛，但开发者策略性地标注AI帮助，社区反应中立且随时间适应。工具选择比标注方式对接受度影响更大。


<details>
  <summary>Details</summary>
Motivation: 探讨AI代码助手在软件开发中的透明度和属性标注实践，特别是开发者如何在承认AI帮助和管理社区审查之间取得平衡。

Method: 分析了2023-2025年间14,300个GitHub提交和7,393个仓库的数据，研究了八种主要AI工具的属性策略和社区反应。

Result: 结果显示，AI使用广泛（95.2%的提交），但属性标注策略差异显著（Claude 80.5% vs. Copilot 9.0%）。明确标注会引发适度审查（问题增加23%，评论增加21%），但工具选择对社区接受度的影响更大（20-30倍）。社区情绪中立，表明更多是好奇而非敌意。时间分析显示，明确标注从2024年初的近乎零增长到2025年末的40%。

Conclusion: 研究发现，AI代码助手的属性标注是一种战略沟通行为，而非简单的透明度问题。这为理解算法问责制和技术转型期间的规范形成提供了新视角。

Abstract: AI coding assistants have transformed software development, raising questions about transparency and attribution practices. We examine the "AI attribution paradox": how developers strategically balance acknowledging AI assistance with managing community scrutiny. Analyzing 14,300 GitHub commits across 7,393 repositories from 2023-2025, we investigated attribution strategies and community responses across eight major AI tools. Results reveal widespread AI usage (95.2% of commits) but strategic attribution: only 29.5% employ explicit disclosure, with dramatic tool variation (Claude 80.5% versus Copilot 9.0%). Explicit attribution triggers modest scrutiny (23% more questions and 21% more comments) but tool choice matters 20-30 times more for predicting reception. Community sentiment remains neutral regardless of attribution type, suggesting curiosity rather than hostility. Temporal analyses show rapid norm evolution: explicit attribution increased from near-zero in early 2024 to 40% by late 2025, indicating community adaptation. These findings illuminate attribution as strategic communication rather than simple transparency, advancing understanding of algorithmic accountability and norm formation during technological transitions. We discuss implications for developers navigating disclosure decisions, platforms designing attribution mechanisms, and researchers studying emergent practices in AI-augmented collaborative work.

</details>


### [369] [Staying or Leaving? How Job Satisfaction, Embeddedness and Antecedents Predict Turnover Intentions of Software Professionals](https://arxiv.org/abs/2512.00869)
*Miikka Kuutila,Paul Ralph,Huilian Sophie Qiu,Ronnie de Souza Santos,Morakot Choetkiertikul,Rana Alkadhi,Xavier Devroey,Gregorio Robles,Hideaki Hata,Sebastian Baltes,Hera Arif,Vladimir Kovalenko,Shalini Chakraborty,Eray Tuzun,Gianisa Adisaputri*

Main category: cs.SE

TL;DR: 研究发现工作满意度和嵌入度显著降低软件专业人员的离职意向，而工作与生活平衡无直接影响。提升工作质量、支持工作与生活平衡及组织公正性可间接减少离职意向。


<details>
  <summary>Details</summary>
Motivation: 软件行业中的自愿离职现象普遍，增加了招聘和入职成本，并可能导致组织和隐性知识的流失。本研究探讨了工作满意度、工作与生活平衡、工作嵌入度及其前因（如工作质量、人格特质、对技术和社交技术基础设施的态度、组织公正感）与软件专业人员离职意向的关系。

Method: 我们进行了一项地理多样化的横断面调查（N = 224），并使用偏最小二乘结构方程模型（PLS-SEM）分析了数据。模型包括反射性和形成性构念，并测试了15个基于职业心理学和软件工程文献的假设。

Result: 工作满意度和嵌入度与软件专业人员的离职意向显著负相关，而工作与生活平衡没有直接影响。工作与生活平衡和工作质量是工作满意度的最强前因，而组织公正性是工作嵌入度的最强预测因素。

Conclusion: 改善工作满意度和工作嵌入度是保留软件专业人员的关键。提升工作质量、支持工作与生活平衡以及确保高度的组织公正性可以间接减少离职意向。

Abstract: Context: Voluntary turnover is common in the software industry, increasing recruitment and onboarding costs and the risk of losing organizational and tacit knowledge. Objective: This study investigates how job satisfaction, work-life balance, job embeddedness, and their antecedents, including job quality, personality traits, attitudes toward technical and sociotechnical infrastructure, and perceptions of organizational justice, relate to software professionals' turnover intentions. Method: We conducted a geographically diverse cross-sectional survey of software professionals (N = 224) and analyzed the data using partial least squares structural equation modeling (PLS-SEM). Our model includes both reflective and formative constructs and tests 15 hypotheses grounded in occupational psychology and software engineering literature. Results: Job satisfaction and embeddedness were significantly negatively associated with software professionals' turnover intentions, while work-life balance showed no direct effect. The strongest antecedents for job satisfaction were work-life balance and job quality, while organizational justice was the strongest predictor of job embeddedness. Discussion: The resulting PLS-SEM model has considerably higher explanatory power for key outcome variables than previous work conducted in the software development context, highlighting the importance of both psychological (e.g., job satisfaction, job embeddedness) and organizational (e.g., organizational justice, job quality) factors in understanding turnover intentions of software professionals. Our results imply that improving job satisfaction and job embeddedness is the key to retaining software professionals. In turn, enhancing job quality, supporting work-life balance, and ensuring high organizational justice can improve job satisfaction and embeddedness, indirectly reducing turnover intentions.

</details>


### [370] [Neural Variable Name Repair: Learning to Rename Identifiers for Readability](https://arxiv.org/abs/2512.01141)
*Muhammad Yousuf,Akshat Bagade,Chhittebbayi Penugonda,Maanas Baraya*

Main category: cs.SE

TL;DR: 研究变量名修复任务，通过微调Llama模型和重新排序技术显著提升标识符生成质量。


<details>
  <summary>Details</summary>
Motivation: 开发者常遇到变量名泛化或误导的情况，缺乏文档会降低代码理解效率，增加错误风险。

Method: 基于Llama 3.1-8B构建的管道，包括预热和丢弃计划、LoRA适配器和双编码器重新排序器。

Result: 最佳LoRA调优模型在200个C++函数测试集上达到43.1%精确匹配、50.2% Top-5命中率和82.03部分匹配分数。

Conclusion: 任务特定微调加重新排序是实用标识符修复工具的有前景方法。

Abstract: Developers routinely work with source files whose variable names are generic or misleading, and with teams moving quickly, many functions are left undocumented. This slows comprehension, increases the risk of subtle bugs, and makes it harder for both humans and large language models (LLMs) to reason about code. We study variable name repair: given a real C++ function where all occurrences of one local or parameter name have been replaced by a placeholder (e.g. ID 1), the goal is to generate a natural, descriptive replacement name. We automatically construct this task from the C++ portion of BigCode's The Stack by parsing functions with Tree-sitter, masking a single identifier, and treating the original name as supervision. On top of Llama 3.1-8B, we build a pipeline with (i) warmup and dropout schedules for more stable fine-tuning, (ii) LoRA adapters for efficient specialization on identifier repair, and (iii) a dual-encoder reranker over top-k generator candidates. We evaluate using exact match, Top-5 Hit, and an embedding-based partial similarity score (0-100) that gives credit for near synonyms and format variants (e.g., jsonValue vs. json). On a held-out set of 200 C++ functions, a zero-shot Llama 3.1 baseline reaches 6.1 percent exact match. Our best LoRA-tuned model (with warmup and dropout) achieves 43.1 percent exact match, 50.2 percent Top-5 Hit, and an 82.03 partial-match score. A dual encoder reranker further improves selection quality without modifying the underlying generator, suggesting that task-specific fine-tuning plus reranking is a promising approach for practical identifier repair tools.

</details>


### [371] [Beyond Greenfield: AI-Driven Productivity in Documentation and Brownfield Engineering](https://arxiv.org/abs/2512.01155)
*Krishna Kumaar Sharma*

Main category: cs.SE

TL;DR: 论文提出D3框架，通过双代理LLM工作流程改善遗留工程任务，初步调查显示生产力提升和认知负荷降低。


<details>
  <summary>Details</summary>
Motivation: 针对遗留系统、不完整文档和碎片化架构知识带来的挑战，填补了复杂、上下文密集环境中结构化工作流程的研究空白。

Method: 论文提出了Discover-Define-Deliver (D3)框架，结合角色分离的提示策略和最佳实践，采用双代理提示架构（Builder模型生成候选输出，Reviewer模型提供结构化批评）。

Result: 52名软件从业者的探索性调查显示，D3框架在任务清晰度、文档质量和认知负荷方面有改善，加权平均生产力提升26.9%，77%参与者认知负荷降低，83%在Define阶段减少返工。

Conclusion: 论文强调了结构化LLM工作流程在遗留工程系统中的潜力与局限性，并呼吁未来进行受控评估。

Abstract: Brownfield engineering work involving legacy systems, incomplete documentation, and fragmented architectural knowledge poses unique challenges for the effective use of large language models (LLMs). Prior research has largely focused on greenfield or synthetic tasks, leaving a gap in structured workflows for complex, context-heavy environments. This paper introduces the Discover-Define-Deliver (D3) Framework, a disciplined LLM-assisted workflow that combines role-separated prompting strategies with applied best practices for navigating ambiguity in brownfield systems. The framework incorporates a dual-agent prompting architecture in which a Builder model generates candidate outputs and a Reviewer model provides structured critique to improve reliability. I conducted an exploratory survey study with 52 software practitioners who applied the D3 workflow to real-world engineering tasks such as legacy system exploration, documentation reconstruction, and architectural refactoring. Respondents reported perceived improvements in task clarity, documentation quality, and cognitive load, along with self-estimated productivity gains. In this exploratory study, participants reported a weighted average productivity improvement of 26.9%, reduced cognitive load for approximately 77% of participants, and reduced rework for 83% during the Define phase. As these findings are self-reported and not derived from controlled experiments, they should be interpreted as preliminary evidence of practitioner sentiment rather than causal effects. The results highlight both the potential and limitations of structured LLM workflows for legacy engineering systems and motivate future controlled evaluations.

</details>


### [372] [LLM-as-a-Judge for Scalable Test Coverage Evaluation: Accuracy, Operational Reliability, and Cost](https://arxiv.org/abs/2512.01232)
*Donghao Huang,Shila Chew,Anna Dutkiewicz,Zhaoxia Wang*

Main category: cs.SE

TL;DR: LAJ框架通过多模型评估发现小模型在测试覆盖评估中表现更优，成本更低，并公开了数据集和代码。


<details>
  <summary>Details</summary>
Motivation: 解决大规模软件测试覆盖率评估的瓶颈问题，提供一种生产就绪的、基于评分的框架。

Method: 通过20种模型配置（GPT-4、GPT-5及开源模型）对100个专家注释脚本进行5轮评估（共500次评估），引入Evaluation Completion Rate (ECR@1)量化首次尝试成功率。

Result: 小模型（如GPT-4o Mini）在准确性（6.07 MAAE）、可靠性（96.6% ECR@1）和成本（$1.01/1K）上优于大模型，成本降低78倍。推理努力对模型性能的影响因模型家族而异。

Conclusion: 论文介绍了LLM-as-a-Judge (LAJ)框架，用于评估Gherkin验收测试，并展示了小模型在准确性、可靠性和成本上的优势，同时发布了数据集和代码以支持复现和部署。

Abstract: Assessing software test coverage at scale remains a bottleneck in QA pipelines. We present LLM-as-a-Judge (LAJ), a production-ready, rubric-driven framework for evaluating Gherkin acceptance tests with structured JSON outputs. Across 20 model configurations (GPT-4, GPT-5 with varying reasoning effort, and open-weight models) on 100 expert-annotated scripts over 5 runs (500 evaluations), we provide the first comprehensive analysis spanning accuracy, operational reliability, and cost. We introduce the Evaluation Completion Rate (ECR@1) to quantify first-attempt success, revealing reliability from 85.4% to 100.0% with material cost implications via retries. Results show that smaller models can outperform larger ones: GPT-4o Mini attains the best accuracy (6.07 MAAE), high reliability (96.6% ECR@1), and low cost ($1.01 per 1K), yielding a 78x cost reduction vs. GPT-5 (high reasoning) while improving accuracy. Reasoning effort is model-family dependent: GPT-5 benefits from increased reasoning (with predictable accuracy-cost tradeoffs), whereas open-weight models degrade across all dimensions as reasoning increases. Overall, cost spans 175x ($0.45-$78.96 per 1K). We release the dataset, framework, and code to support reproducibility and deployment.

</details>


### [373] [LAURA: Enhancing Code Review Generation with Context-Enriched Retrieval-Augmented LLM](https://arxiv.org/abs/2512.01356)
*Yuxin Zhang,Yuxia Zhang,Zeyu Sun,Yanjie Jiang,Hui Liu*

Main category: cs.SE

TL;DR: LAURA是一个基于LLM的代码审查生成框架，通过整合审查范例检索和上下文增强，显著提升了生成评论的质量。


<details>
  <summary>Details</summary>
Motivation: 随着软件规模和复杂性的快速增长，代码审查因其耗时、知识密集和缺乏经验开发者的问题成为开发瓶颈，现有方法忽略了代码变更上下文和先前审查知识等关键信息。

Method: 提出了一个基于LLM的审查知识增强和上下文感知框架LAURA，集成了审查范例检索、上下文增强和系统指导。

Result: 实验结果表明，LAURA生成的评论在42.2%和40.4%的情况下完全正确或对开发者有帮助，显著优于现有基线。

Conclusion: LAURA框架显著提升了ChatGPT-4o和DeepSeek v3在生成代码审查评论时的性能，实验结果显示其生成的评论在42.2%和40.4%的情况下完全正确或对开发者有帮助，明显优于现有基线。

Abstract: Code review is critical for ensuring software quality and maintainability. With the rapid growth in software scale and complexity, code review has become a bottleneck in the development process because of its time-consuming and knowledge-intensive nature and the shortage of experienced developers willing to review code. Several approaches have been proposed for automatically generating code reviews based on retrieval, neural machine translation, pre-trained models, or large language models (LLMs). These approaches mainly leverage historical code changes and review comments. However, a large amount of crucial information for code review, such as the context of code changes and prior review knowledge, has been overlooked. This paper proposes an LLM-based review knowledge-augmented, context-aware framework for code review generation, named LAURA. The framework integrates review exemplar retrieval, context augmentation, and systematic guidance to enhance the performance of ChatGPT-4o and DeepSeek v3 in generating code review comments. Besides, given the extensive low-quality reviews in existing datasets, we also constructed a high-quality dataset. Experimental results show that for both models, LAURA generates review comments that are either completely correct or at least helpful to developers in 42.2% and 40.4% of cases, respectively, significantly outperforming SOTA baselines. Furthermore, our ablation studies demonstrate that all components of LAURA contribute positively to improving comment quality.

</details>


### [374] [BackportBench: A Multilingual Benchmark for Automated Backporting of Patches](https://arxiv.org/abs/2512.01396)
*Zhiqing Zhong,Jiaming Huang,Pinjia He*

Main category: cs.SE

TL;DR: BackportBench是首个全面的补丁回移植基准测试套件，评估显示代理方法在复杂案例中更优，但语言间性能差异显著。


<details>
  <summary>Details</summary>
Motivation: 现代软件项目快速迭代，但用户因升级困难仍使用旧版漏洞包，手动回移植补丁耗时且易错，现有自动化技术效果不明确。

Method: 引入了BackportBench，一个多语言基准测试套件，包含202个补丁回移植问题，每个问题配有可执行的Docker环境和相关测试用例。

Result: 代理方法在需要逻辑和结构变化的案例中优于传统补丁回移植方法，但性能因编程语言而异。

Conclusion: 研究提出了BackportBench作为首个全面的补丁回移植基准测试套件，并评估了现有方法及基于LLM的技术，发现代理方法在需要逻辑和结构变化的案例中表现更优，但性能因编程语言而异。

Abstract: Many modern software projects evolve rapidly to incorporate new features and security patches. It is important for users to update their dependencies to safer versions, but many still use older, vulnerable package versions because upgrading can be difficult and may break their existing codebase. Software developers can mitigate this problem by backporting security patches to older releases. However, manually backporting is time-consuming and error-prone. The effectiveness of existing automated backporting techniques on general software remains unclear since they typically target only code-hunk or function-level patch porting scenarios and are evaluated with imperfect metrics.
  To facilitate the development and evaluation of automated backporting techniques, we introduce BackportBench, the first comprehensive benchmark suite for patch backporting problem. BackportBench is a multilingual benchmark that contains 202 patch backporting problems from PyPI, Maven, and npm, each with executable Docker environments and relevant test cases. We evaluated existing patch porting methods and LLM-based techniques that have the potential to adapt to this task using BackportBench. The results show that the agentic method has outperformed traditional patch porting methods, especially on cases that require logical and structural changes. However, the performance varies across different programming languages. Based on the findings, we draw several implications for researchers and software practitioners in future work on automated backporting.

</details>


### [375] [Teaching an Online Multi-Institutional Research Level Software Engineering Course with Industry - an Experience Report](https://arxiv.org/abs/2512.01523)
*Pankaj Jalote,Y. Raghu Reddy,Vasudeva Varma*

Main category: cs.SE

TL;DR: 论文探讨了多机构在线合作开设研究级课程的可行性，并以“AI in Software Engineering”课程为例，展示了行业参与的积极效果。


<details>
  <summary>Details</summary>
Motivation: 新冠疫情使得在线教学被广泛接受，这为多机构合作开设研究级课程提供了机会，尤其是在个别机构师资或学生不足的情况下。

Method: 通过在两所机构联合开设“AI in Software Engineering”课程，并积极引入行业专家参与，实验性地验证了该教学模式的可行性。

Result: 实验证明，该模式不仅可行，还能吸引行业专家参与，学生和教师的反馈也较为积极。

Conclusion: 该论文提出了一种多机构合作的在线教学模式，尤其适用于研究级课程，能够解决小机构资源不足的问题，并认为这种模式可推广至计算机科学的应用领域。

Abstract: Covid has made online teaching and learning acceptable and students, faculty, and industry professionals are all comfortable with this mode. This comfort can be leveraged to offer an online multi-institutional research-level course in an area where individual institutions may not have the requisite faculty to teach and/or research students to enroll. If the subject is of interest to industry, online offering also allows industry experts to contribute and participate with ease. Advanced topics in Software Engineering are ideally suited for experimenting with this approach as industry, which is often looking to incorporate advances in software engineering in their practices, is likely to agree to contribute and participate. In this paper we describe an experiment in teaching a course titled "AI in Software Engineering" jointly between two institutions with active industry participation, and share our and student's experience. We believe this collaborative teaching approach can be used for offering research level courses in any applied area of computer science by institutions who are small and find it difficult to offer research level courses on their own.

</details>


### [376] [OpenDORS: A dataset of openly referenced open research software](https://arxiv.org/abs/2512.01570)
*Stephan Druskat,Lars Grunske*

Main category: cs.SE

TL;DR: 论文提出了一个大规模开源研究软件数据集，为研究软件工程（RSE）研究提供了基础。


<details>
  <summary>Details</summary>
Motivation: 研究软件在学术研究中的重要性日益凸显，但缺乏大规模研究软件及其开发的系统性研究。

Method: 通过收集开放获取文献中引用的源代码仓库，并提供元数据（如最新版本、许可证信息、编程语言等）来构建数据集。

Result: 数据集包含122,425个源代码仓库的元数据，总结了这些特征的分布，并提出了未来扩展的方向。

Conclusion: 该论文提出了一个包含134,352个独特开源研究软件项目和134,154个源代码仓库的数据集，为大规模研究软件及其开发提供了基础。

Abstract: In many academic disciplines, software is created during the research process or for a research purpose. The crucial role of software for research is increasingly acknowledged. The application of software engineering to research software has been formalized as research software engineering, to create better software that enables better research. Despite this, large-scale studies of research software and its development are still lacking. To enable such studies, we present a dataset of 134,352 unique open research software projects and 134,154 source code repositories referenced in open access literature. Each dataset record identifies the referencing publication and lists source code repositories of the software project. For 122,425 source code repositories, the dataset provides metadata on latest versions, license information, programming languages and descriptive metadata files. We summarize the distributions of these features in the dataset and describe additional software metadata that extends the dataset in future work. Finally, we suggest examples of research that could use the dataset to develop a better understanding of research software practice in RSE research.

</details>


### [377] [GPTrace: Effective Crash Deduplication Using LLM Embeddings](https://arxiv.org/abs/2512.01609)
*Patrick Herter,Vincent Ahlrichs,Ridvan Açilan,Julian Horsch*

Main category: cs.SE

TL;DR: GPTrace利用语言模型和聚类算法改进崩溃去重，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有崩溃去重方法依赖堆栈跟踪比较，效果不佳，需要更灵活高效的解决方案。

Method: GPTrace利用大型语言模型评估崩溃数据的相似性，计算嵌入向量并输入聚类算法。

Result: 在14个目标、50个真实标签的30万崩溃输入上，GPTrace的去重效果明显优于手工堆栈跟踪比较方法和现有复杂方法。

Conclusion: GPTrace通过利用大型语言模型计算嵌入向量并结合聚类算法，显著提高了崩溃去重效果，优于现有方法。

Abstract: Fuzzing is a highly effective method for uncovering software vulnerabilities, but analyzing the resulting data typically requires substantial manual effort. This is amplified by the fact that fuzzing campaigns often find a large number of crashing inputs, many of which share the same underlying bug. Crash deduplication is the task of finding such duplicate crashing inputs and thereby reducing the data that needs to be examined. Many existing deduplication approaches rely on comparing stack traces or other information that is collected when a program crashes. Although various metrics for measuring the similarity of such pieces of information have been proposed, many do not yield satisfactory deduplication results. In this work, we present GPTrace, a deduplication workflow that leverages a large language model to evaluate the similarity of various data sources associated with crashes by computing embedding vectors and supplying those as input to a clustering algorithm. We evaluate our approach on over 300 000 crashing inputs belonging to 50 ground truth labels from 14 different targets. The deduplication results produced by GPTrace show a noticeable improvement over hand-crafted stack trace comparison methods and even more complex state-of-the-art approaches that are less flexible.

</details>


### [378] [When High-Performance Computing Meets Software Testing: Distributed Fuzzing using MPI](https://arxiv.org/abs/2512.01617)
*Pierciro Caliandro,Matteo Ciccaglione,Alessandro Pellegrini*

Main category: cs.SE

TL;DR: 论文提出使用MPI同步技术优化分布式模糊测试，通过减少通信延迟提升效率，实验显示早期覆盖率改善显著。


<details>
  <summary>Details</summary>
Motivation: 探索MPI同步技术在分布式模糊测试框架中的集成，以替代传统基于文件系统的同步方法，提升性能。

Method: 通过轻量级MPI原语减少通信延迟，实现分布式模糊测试节点间更高效的数据交换。

Result: 实验结果表明，早期阶段覆盖率提升明显，有效解决了覆盖率停滞问题，支持复杂和深层执行路径的持续探索。

Conclusion: 采用基于MPI的同步方法在分布式模糊测试中展现出显著提升可扩展性和效率的潜力。

Abstract: This paper explores the integration of MPI-based synchronization techniques into distributed fuzzing frameworks, highlighting possible substantial performance improvements compared to traditional filesystem-based synchronization methods. By employing lightweight MPI primitives, reductions in communication latency are achieved, facilitating more efficient data exchanges across distributed fuzzing nodes. Experimental results obtained over standard benchmarks demonstrate enhanced coverage progression from the early stages of the fuzzing process, which could be beneficial if fuzzing is employed in CI/CD pipelines at any stage of software development. Furthermore, the coordinated exchange of input corpora among clusters of fuzzers effectively addresses coverage stagnation, enabling a sustained exploration of complex and deep execution paths. Overall, the adoption of MPI-based synchronization approaches shows promising potential for significantly enhancing the scalability and efficacy of distributed fuzz testing.

</details>


### [379] [Package Dashboard: A Cross-Ecosystem Framework for Dual-Perspective Analysis of Software Packages](https://arxiv.org/abs/2512.01630)
*Ziheng Liu,Runzhi He,Minghui Zhou*

Main category: cs.SE

TL;DR: Package Dashboard是一个跨生态系统框架，通过整合包元数据、漏洞和社区健康指标，提供统一的风险评估平台，减少认知负担并提高可追溯性。


<details>
  <summary>Details</summary>
Motivation: 现有的SCA工具通常局限于单一生态系统，且单独评估软件工件或社区活动，这种碎片化迫使开发者手动整合分散的数据，削弱了风险评估。

Method: 通过整合包元数据、漏洞信息和上游社区健康指标，Package Dashboard结合依赖解析与仓库分析，减少了认知负担并提高了可追溯性。

Result: 对五个Linux发行版中的374,000个包进行的大规模研究表明，Package Dashboard不仅能够发现常规漏洞和许可证冲突，还能揭示被忽视的风险，如存档或无法访问的仓库。

Conclusion: Package Dashboard提供了一个统一的风险视图，为开发者和DevSecOps工程师提供了可操作的见解，以增强开源生态系统的透明度、可信度和可追溯性。

Abstract: Software supply chain attacks have revealed blind spots in existing SCA tools, which are often limited to a single ecosystem and assess either software artifacts or community activity in isolation. This fragmentation across tools and ecosystems forces developers to manually reconcile scattered data, undermining risk assessments. We present Package Dashboard, a cross-ecosystem framework that provides a unified platform for supply chain analysis, enabling a holistic, dual-perspective risk assessment by integrating package metadata, vulnerability information, and upstream community health metrics. By combining dependency resolution with repository analysis, it reduces cognitive load and improves traceability. Demonstrating the framework's versatility, a large-scale study of 374,000 packages across five Linux distributions shows its ability to uncover not only conventional vulnerabilities and license conflicts but also overlooked risks such as archived or inaccessible repositories. Ultimately, Package Dashboard provides a unified view of risk, equipping developers and DevSecOps engineers with actionable insights to strengthen the transparency, trustworthiness, and traceability of open-source ecosystems. Package Dashboard is publicly available at https://github.com/n19htfall/PackageDashboard, and a demonstration video can be found at https://youtu.be/y9ncftP8KPQ. Besides, the online version is available at https://pkgdash.osslab-pku.org.

</details>


### [380] [MIT Lincoln Laboratory: A Case Study on Improving Software Support for Research Projects](https://arxiv.org/abs/2512.01649)
*Daniel Strassler,Gabe Elkin,Curran Schiefelbein,Daniel Herring,Ian Jessen,David Johnson,Santiago A. Paredes,Tod Shannon,Jim Flavin*

Main category: cs.SE

TL;DR: MIT林肯实验室研究软件开发的挑战，提出集中化工具、人才匹配数据库和利益相关者小组等改进建议。


<details>
  <summary>Details</summary>
Motivation: 随着软件在复杂系统开发和原型设计中的作用日益增加，MIT林肯实验室希望改进软件工程的效率和执行文化。

Method: MIT林肯实验室的国土保护与空中交通控制部门进行了一项内部研究，分析了高效研究软件开发的挑战，并确定了加强文化和执行的方法。

Result: 研究的主要发现分为三类：影响软件开发活动执行和管理的项目属性、集中化带来的潜在效率、以及改善软件从业者的人员配备和文化的机会。

Conclusion: 研究提出了可操作的建议，包括集中化和标准化软件支持工具、开发一个通用数据库以帮助将合适的软件人才与项目需求匹配，以及创建一个软件利益相关者小组以协助持续改进。

Abstract: Software plays an ever increasing role in complex system development and prototyping, and in recent years, MIT Lincoln Laboratory has sought to improve both the effectiveness and culture surrounding software engineering in execution of its mission. The Homeland Protection and Air Traffic Control Division conducted an internal study to examine challenges to effective and efficient research software development, and to identify ways to strengthen both the culture and execution for greater impact on our mission. Key findings of this study fell into three main categories: project attributes that influence how software development activities must be conducted and managed, potential efficiencies from centralization, opportunities to improve staffing and culture with respect to software practitioners. The study delivered actionable recommendations, including centralizing and standardizing software support tooling, developing a common database to help match the right software talent and needs to projects, and creating a software stakeholder panel to assist with continued improvement.

</details>


### [381] [Generating REST API Tests With Descriptive Names](https://arxiv.org/abs/2512.01690)
*Philip Garrett,Juan P. Galeotti,Andrea Arcuri,Alexander Poth,Olsi Rrjolli*

Main category: cs.SE

TL;DR: 本文提出了三种确定性技术生成REST API测试名称，比较了八种方法的效果，发现基于规则的方法表现优异，且工业案例证实其提高了测试可读性。


<details>
  <summary>Details</summary>
Motivation: 自动生成的测试用例通常被赋予非描述性名称（如test0、test1），这降低了它们的可读性，阻碍了在理解和维护过程中的实用性。

Method: 提出了三种新颖的确定性技术来生成REST API测试名称，并比较了八种技术（包括基于规则的启发式方法和基于大型语言模型的方法）的效果。

Result: 基于规则的方法在确定性方法中获得了最高的清晰度评分，与最先进的基于LLM的模型（如Gemini和GPT-4o）表现相当，并显著优于GPT-3.5。工业案例研究进一步证实了这种方法生成的描述性名称提高了测试套件的可读性。

Conclusion: 轻量级确定性技术在自动化系统级测试命名中可以作为计算成本高且安全性敏感的大型语言模型（LLM）方法的有效替代方案，为更友好的API测试生成提供了实际步骤。

Abstract: Automated test generation has become a key technique for ensuring software quality, particularly in modern API-based architectures. However, automatically generated test cases are typically assigned non-descriptive names (e.g., test0, test1), which reduces their readability and hinders their usefulness during comprehension and maintenance. In this work, we present three novel deterministic techniques to generate REST API test names. We then compare eight techniques in total for generating descriptive names for REST API tests automatically produced by the fuzzer EvoMaster, using 10 test cases generated for 9 different open-source APIs. The eight techniques include rule-based heuristics and large language model (LLM)-based approaches. Their effectiveness was empirically evaluated through two surveys (involving up to 39 people recruited via LinkedIn). Our results show that a rule-based approach achieves the highest clarity ratings among deterministic methods, performs on par with state-of-the-art LLM-based models such as Gemini and GPT-4o, and significantly outperforms GPT-3.5.
  To further evaluate the practical impact of our results, an industrial case study was carried out with practitioners who actively use EvoMaster at Volkswagen AG. A developer questionnaire was then carried out based on the use of EvoMaster on four different APIs by four different users, for a total of 74 evaluated test cases. Feedback from practitioners further confirms that descriptive names produced by this approach improve test suite readability.
  These findings highlight that lightweight, deterministic techniques can serve as effective alternatives to computationally expensive and security-sensitive LLM-based approaches for automated system-level test naming, providing a practical step toward more developer-friendly API test generation.

</details>


### [382] [An Empirical Study of Agent Developer Practices in AI Agent Frameworks](https://arxiv.org/abs/2512.01939)
*Yanlin Wang,Xinyi Xu,Jiachi Chen,Tingting Bi,Wenchao Gu,Zibin Zheng*

Main category: cs.SE

TL;DR: 本文首次实证研究了基于LLM的智能体框架，通过分析开发者讨论比较了10个框架在五个维度的表现，揭示了显著差异并提出了设计建议。


<details>
  <summary>Details</summary>
Motivation: 尽管智能体框架广泛使用，但其实际应用和对开发过程的影响尚未充分探索，且开发者难以选择最适合需求的框架。

Method: 通过收集和分析10个智能体框架的11,910条开发者讨论，比较了它们在开发效率、功能抽象、学习成本、性能优化和可维护性五个维度的表现。

Result: 分析显示不同框架在满足开发者需求方面存在显著差异，为框架设计和开发者选择提供了依据。

Conclusion: 本研究揭示了基于LLM的智能体框架在满足开发者需求方面的显著差异，为未来LLM驱动的智能体框架生态系统提供了设计见解和建议。

Abstract: The rise of large language models (LLMs) has sparked a surge of interest in agents, leading to the rapid growth of agent frameworks. Agent frameworks are software toolkits and libraries that provide standardized components, abstractions, and orchestration mechanisms to simplify agent development. Despite widespread use of agent frameworks, their practical applications and how they influence the agent development process remain underexplored. Different agent frameworks encounter similar problems during use, indicating that these recurring issues deserve greater attention and call for further improvements in agent framework design. Meanwhile, as the number of agent frameworks continues to grow and evolve, more than 80% of developers report difficulties in identifying the frameworks that best meet their specific development requirements. In this paper, we conduct the first empirical study of LLM-based agent frameworks, exploring real-world experiences of developers in building AI agents. To compare how well the agent frameworks meet developer needs, we further collect developer discussions for the ten previously identified agent frameworks, resulting in a total of 11,910 discussions. Finally, by analyzing these discussions, we compare the frameworks across five dimensions: development efficiency, functional abstraction, learning cost, performance optimization, and maintainability, which refers to how easily developers can update and extend both the framework itself and the agents built upon it over time. Our comparative analysis reveals significant differences among frameworks in how they meet the needs of agent developers. Overall, we provide a set of findings and implications for the LLM-driven AI agent framework ecosystem and offer insights for the design of future LLM-based agent frameworks and agent developers.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [383] [DREAMer-VXS: A Latent World Model for Sample-Efficient AGV Exploration in Stochastic, Unobserved Environments](https://arxiv.org/abs/2512.00005)
*Agniprabha Chakraborty*

Main category: cs.RO

TL;DR: DREAMer-VXS 是一种基于模型的AGV探索框架，通过VAE和RSSM学习环境模型，减少90%的环境交互需求，提升探索效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 基于学习的机器人技术在真实世界应用中面临样本效率低和脆弱性的问题，DREAMer-VXS 旨在解决这些挑战。

Method: DREAMer-VXS 结合了卷积变分自编码器（VAE）和递归状态空间模型（RSSM），学习环境的紧凑表示和复杂时间动态，并通过想象潜在轨迹进行规划。

Result: DREAMer-VXS 在模拟实验中表现出显著的学习速度提升和策略泛化能力，探索效率提高了45%，且对动态障碍物具有更强的适应能力。

Conclusion: DREAMer-VXS 通过模型基础的方法显著提高了自主地面车辆（AGV）探索的样本效率和鲁棒性，相比无模型方法减少了90%的环境交互需求，并在未知环境中表现出更高的探索效率和动态障碍物适应性。

Abstract: The paradigm of learning-based robotics holds immense promise, yet its translation to real-world applications is critically hindered by the sample inefficiency and brittleness of conventional model-free reinforcement learning algorithms. In this work, we address these challenges by introducing DREAMer-VXS, a model-based framework for Autonomous Ground Vehicle (AGV) exploration that learns to plan from imagined latent trajectories. Our approach centers on learning a comprehensive world model from partial and high-dimensional LiDAR observations. This world model is composed of a Convolutional Variational Autoencoder (VAE), which learns a compact representation of the environment's structure, and a Recurrent State-Space Model (RSSM), which models complex temporal dynamics. By leveraging this learned model as a high-speed simulator, the agent can train its navigation policy almost entirely in imagination. This methodology decouples policy learning from real-world interaction, culminating in a 90% reduction in required environmental interactions to achieve expert-level performance when compared to state-of-the-art model-free SAC baselines. The agent's behavior is guided by an actor-critic policy optimized with a composite reward function that balances task objectives with an intrinsic curiosity bonus, promoting systematic exploration of unknown spaces. We demonstrate through extensive simulated experiments that DREAMer-VXS not only learns orders of magnitude faster but also develops more generalizable and robust policies, achieving a 45% increase in exploration efficiency in unseen environments and superior resilience to dynamic obstacles.

</details>


### [384] [A Comprehensive Survey on Surgical Digital Twin](https://arxiv.org/abs/2512.00019)
*Afsah Sharaf Khan,Falong Fan,Doohwan DH Kim,Abdurrahman Alshareef,Dong Chen,Justin Kim,Ernest Carter,Bo Liu,Jerzy W. Rozenblit,Bernard Zeigler*

Main category: cs.RO

TL;DR: 本文综述了手术数字孪生（SDT）的现状，提出了分类法并总结了最新技术，同时指出了未来研究方向，旨在推动SDT从实验室到临床的转化。


<details>
  <summary>Details</summary>
Motivation: 随着多模态手术数据和实时计算的加速可用性，SDT作为虚拟对应物出现，可以在术前、术中和术后护理中镜像、预测和指导决策。尽管有前景的演示，SDT仍面临持续挑战。

Method: 本文提供了一个批判性、结构化的SDT综述，包括术语和范围的澄清，按目的、模型保真度和数据源分类的分类法，以及在可变形注册和跟踪、实时模拟和共模拟、AR/VR引导、边缘-云协同和AI场景理解和预测方面的最新成就综合。

Result: 本文综合了SDT在多个领域的最先进成就，并对比了非机器人孪生与机器人闭环架构在共享控制和自主性方面的差异，同时指出了验证和基准测试、安全保障和人为因素、生命周期“数字线程”集成以及可扩展数据治理方面的开放问题。

Conclusion: 本文提出了一个研究议程，旨在推动可信赖、符合标准的SDT发展，以实现可衡量的临床效益。通过统一术语、组织能力和突出差距，本研究旨在指导SDT的设计和部署，并促进从实验室原型到常规手术护理的转化。

Abstract: With the accelerating availability of multimodal surgical data and real-time computation, Surgical Digital Twins (SDTs) have emerged as virtual counterparts that mirror, predict, and inform decisions across pre-, intra-, and postoperative care. Despite promising demonstrations, SDTs face persistent challenges: fusing heterogeneous imaging, kinematics, and physiology under strict latency budgets; balancing model fidelity with computational efficiency; ensuring robustness, interpretability, and calibrated uncertainty; and achieving interoperability, privacy, and regulatory compliance in clinical environments. This survey offers a critical, structured review of SDTs. We clarify terminology and scope, propose a taxonomy by purpose, model fidelity, and data sources, and synthesize state-of-the-art achievements in deformable registration and tracking, real-time simulation and co-simulation, AR/VR guidance, edge-cloud orchestration, and AI for scene understanding and prediction. We contrast non-robotic twins with robot-in-the-loop architectures for shared control and autonomy, and identify open problems in validation and benchmarking, safety assurance and human factors, lifecycle "digital thread" integration, and scalable data governance. We conclude with a research agenda toward trustworthy, standards-aligned SDTs that deliver measurable clinical benefit. By unifying vocabulary, organizing capabilities, and highlighting gaps, this work aims to guide SDT design and deployment and catalyze translation from laboratory prototypes to routine surgical care.

</details>


### [385] [Foundation Models for Trajectory Planning in Autonomous Driving: A Review of Progress and Open Challenges](https://arxiv.org/abs/2512.00021)
*Kemal Oksuz,Alexandru Buburuzan,Anthony Knittel,Yuhan Yao,Puneet K. Dokania*

Main category: cs.RO

TL;DR: 本文综述了基于多模态基础模型的自动驾驶轨迹规划方法，评估了37种方法的设计与性能，并提供了开源资源信息。


<details>
  <summary>Details</summary>
Motivation: 多模态基础模型的出现改变了自动驾驶技术，从传统手工设计转向统一的基础模型方法，能够直接从原始感官输入推断运动轨迹。本文旨在全面评估这类方法的现状。

Method: 通过统一分类法对37种基于基础模型的自动驾驶轨迹规划方法进行系统评估，包括架构设计、方法论优势及局限性分析。

Result: 综述了37种方法，评估了其设计选择、方法优势及局限性，并提供了开源代码和数据集的评估信息。

Conclusion: 本文综述了基于多模态基础模型的自动驾驶轨迹规划方法，通过统一分类法评估了37种近期提出的方法，分析了其设计选择、方法优势及局限性，并提供了开源代码和数据集的评估。

Abstract: The emergence of multi-modal foundation models has markedly transformed the technology for autonomous driving, shifting away from conventional and mostly hand-crafted design choices towards unified, foundation-model-based approaches, capable of directly inferring motion trajectories from raw sensory inputs. This new class of methods can also incorporate natural language as an additional modality, with Vision-Language-Action (VLA) models serving as a representative example. In this review, we provide a comprehensive examination of such methods through a unifying taxonomy to critically evaluate their architectural design choices, methodological strengths, and their inherent capabilities and limitations. Our survey covers 37 recently proposed approaches that span the landscape of trajectory planning with foundation models. Furthermore, we assess these approaches with respect to the openness of their source code and datasets, offering valuable information to practitioners and researchers. We provide an accompanying webpage that catalogs the methods based on our taxonomy, available at: https://github.com/fiveai/FMs-for-driving-trajectories

</details>


### [386] [XFlowMP: Task-Conditioned Motion Fields for Generative Robot Planning with Schrodinger Bridges](https://arxiv.org/abs/2512.00022)
*Khang Nguyen,Minh Nhat Vu*

Main category: cs.RO

TL;DR: XFlowMP通过Schrödinger桥生成动态可行且无碰撞的运动轨迹，在多个测试中表现优于基线，并在实际机器人中验证了实用性。


<details>
  <summary>Details</summary>
Motivation: 传统和生成式规划方法难以将高级语义与低级约束（如任务配置与运动可控性）结合，XFlowMP旨在解决这一问题。

Method: 利用Schrödinger桥作为条件流匹配，结合得分函数学习高阶动态运动场，编码起点-目标配置，生成动态可行且无碰撞的运动。

Result: 在RobotPointMass基准测试中，XFlowMP实现了最大均值差异降低53.79%、运动平滑度提高36.36%、能耗降低39.88%；在LASA手写数据集中，轨迹最大均值差异降低1.26%、平滑度提高3.96%、能耗降低31.97%。

Conclusion: XFlowMP 是一种任务条件生成运动规划器，通过Schrödinger桥将随机噪声与专家演示连接，生成动态可行且无碰撞的运动轨迹，在多个基准测试中表现优异，并在实际机器人操作中验证了其鲁棒性。

Abstract: Generative robotic motion planning requires not only the synthesis of smooth and collision-free trajectories but also feasibility across diverse tasks and dynamic constraints. Prior planning methods, both traditional and generative, often struggle to incorporate high-level semantics with low-level constraints, especially the nexus between task configurations and motion controllability. In this work, we present XFlowMP, a task-conditioned generative motion planner that models robot trajectory evolution as entropic flows bridging stochastic noises and expert demonstrations via Schrodinger bridges given the inquiry task configuration. Specifically, our method leverages Schrodinger bridges as a conditional flow matching coupled with a score function to learn motion fields with high-order dynamics while encoding start-goal configurations, enabling the generation of collision-free and dynamically-feasible motions. Through evaluations, XFlowMP achieves up to 53.79% lower maximum mean discrepancy, 36.36% smoother motions, and 39.88% lower energy consumption while comparing to the next-best baseline on the RobotPointMass benchmark, and also reducing short-horizon planning time by 11.72%. On long-horizon motions in the LASA Handwriting dataset, our method maintains the trajectories with 1.26% lower maximum mean discrepancy, 3.96% smoother, and 31.97% lower energy. We further demonstrate the practicality of our method on the Kinova Gen3 manipulator, executing planning motions and confirming its robustness in real-world settings.

</details>


### [387] [Learning from Watching: Scalable Extraction of Manipulation Trajectories from Human Videos](https://arxiv.org/abs/2512.00024)
*X. Hu,G. Ye*

Main category: cs.RO

TL;DR: 提出结合基础模型和点跟踪技术的方法，从人类操作视频中提取密集轨迹，提升机器人学习的数据效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法未能充分利用人类操作视频中丰富的交互线索的问题，以降低机器人学习的数据收集成本。

Method: 结合大型基础模型进行视频理解和点跟踪技术，提取任务相关关键点的密集轨迹。

Result: 实验结果表明，该方法能准确跟踪整个操作过程中的关键点，支持更高效和可扩展的机器人学习。

Conclusion: 该方法通过结合大型基础模型和点跟踪技术，有效提取了人类演示视频中的密集轨迹，为机器人学习提供了更高效的数据利用途径。

Abstract: Collecting high-quality data for training large-scale robotic models typically relies on real robot platforms, which is labor-intensive and costly, whether via teleoperation or scripted demonstrations. To scale data collection, many researchers have turned to leveraging human manipulation videos available online. However, current methods predominantly focus on hand detection or object pose estimation, failing to fully exploit the rich interaction cues embedded in these videos. In this work, we propose a novel approach that combines large foundation models for video understanding with point tracking techniques to extract dense trajectories of all task-relevant keypoints during manipulation. This enables more comprehensive utilization of Internet-scale human demonstration videos. Experimental results demonstrate that our method can accurately track keypoints throughout the entire manipulation process, paving the way for more scalable and data-efficient robot learning.

</details>


### [388] [A Survey on Improving Human Robot Collaboration through Vision-and-Language Navigation](https://arxiv.org/abs/2512.00027)
*Nivedan Yakolli,Avinash Gautam,Abhijit Das,Yuankai Qi,Virendra Singh Shekhawat*

Main category: cs.RO

TL;DR: 本文综述了视觉与语言导航（VLN）的最新进展，指出多机器人协作中的挑战，并提出了未来研究方向，如主动澄清和去中心化决策框架。


<details>
  <summary>Details</summary>
Motivation: 探讨如何改进多机器人协调中的双向通信、歧义解决和协作决策，以推动VLN与机器人技术的交叉研究。

Method: 本文回顾了约200篇相关文献，深入分析了当前VLN在机器人领域的研究现状。

Result: 当前模型在多智能体系统中的双向通信、歧义解决和协作决策方面仍存在挑战。

Conclusion: 未来VLN系统应支持主动澄清、实时反馈和上下文推理，通过先进的自然语言理解技术，以及去中心化的决策框架和动态角色分配，以提升多机器人协作的效率和可扩展性。

Abstract: Vision-and-Language Navigation (VLN) is a multi-modal, cooperative task requiring agents to interpret human instructions, navigate 3D environments, and communicate effectively under ambiguity. This paper presents a comprehensive review of recent VLN advancements in robotics and outlines promising directions to improve multi-robot coordination. Despite progress, current models struggle with bidirectional communication, ambiguity resolution, and collaborative decision-making in the multi-agent systems. We review approximately 200 relevant articles to provide an in-depth understanding of the current landscape. Through this survey, we aim to provide a thorough resource that inspires further research at the intersection of VLN and robotics. We advocate that the future VLN systems should support proactive clarification, real-time feedback, and contextual reasoning through advanced natural language understanding (NLU) techniques. Additionally, decentralized decision-making frameworks with dynamic role assignment are essential for scalable, efficient multi-robot collaboration. These innovations can significantly enhance human-robot interaction (HRI) and enable real-world deployment in domains such as healthcare, logistics, and disaster response.

</details>


### [389] [Perturbation-mitigated USV Navigation with Distributionally Robust Reinforcement Learning](https://arxiv.org/abs/2512.00030)
*Zhaofan Zhang,Minghao Yang,Sihong Xie,Hui Xiong*

Main category: cs.RO

TL;DR: DRIQN结合DRO和隐式分位数网络，优化USV在复杂噪声环境中的导航性能，实验显示多项指标显著提升。


<details>
  <summary>Details</summary>
Motivation: USV在复杂海洋环境中面临异方差观测噪声的挑战，现有方法忽略了噪声模式随环境变化的问题，影响了安全导航和价值函数的学习。

Method: 提出DRIQN方法，结合DRO和隐式分位数网络，利用回放缓冲区中的显式子群建模来优化最坏情况下的性能。

Result: 实验结果表明，DRIQN在风险敏感环境中显著优于现有方法，成功率提升13.51%，碰撞率降低12.28%，时间节省35.46%，能源节省27.99%。

Conclusion: DRIQN通过整合分布鲁棒优化（DRO）和隐式分位数网络，显著提升了USV在复杂海洋环境中的导航性能，尤其在噪声模式变化的环境下表现优异。

Abstract: The robustness of Unmanned Surface Vehicles (USV) is crucial when facing unknown and complex marine environments, especially when heteroscedastic observational noise poses significant challenges to sensor-based navigation tasks. Recently, Distributional Reinforcement Learning (DistRL) has shown promising results in some challenging autonomous navigation tasks without prior environmental information. However, these methods overlook situations where noise patterns vary across different environmental conditions, hindering safe navigation and disrupting the learning of value functions. To address the problem, we propose DRIQN to integrate Distributionally Robust Optimization (DRO) with implicit quantile networks to optimize worst-case performance under natural environmental conditions. Leveraging explicit subgroup modeling in the replay buffer, DRIQN incorporates heterogeneous noise sources and target robustness-critical scenarios. Experimental results based on the risk-sensitive environment demonstrate that DRIQN significantly outperforms state-of-the-art methods, achieving +13.51\% success rate, -12.28\% collision rate and +35.46\% for time saving, +27.99\% for energy saving, compared with the runner-up.

</details>


### [390] [Intelligent Systems and Robotics: Revolutionizing Engineering Industries](https://arxiv.org/abs/2512.00033)
*Sathish Krishna Anumula,Sivaramkumar Ponnarangan,Faizal Nujumudeen,Ms. Nilakshi Deka,S. Balamuralitharan,M Venkatesh*

Main category: cs.RO

TL;DR: 本文探讨了AI和机器人技术如何改变工程行业，分析了其效率提升和成本节约的潜力，并指出仍需解决的问题。


<details>
  <summary>Details</summary>
Motivation: 探讨智能系统和机器人如何提升工程行业的效率、精度和适应性。

Method: 基于最新发现和评估智能机器人系统的方法，分析了AI、ML和自主机器人技术在多个工程领域的应用。

Result: 案例研究证实了智能机器人对生产力、安全性和运营成本的积极影响。

Conclusion: 智能机器人和AI技术的结合不仅是技术变革，还引入了工程领域的重要新方法，尽管仍存在待解决的问题。

Abstract: A mix of intelligent systems and robotics is making engineering industries much more efficient, precise and able to adapt. How artificial intelligence (AI), machine learning (ML) and autonomous robotic technologies are changing manufacturing, civil, electrical and mechanical engineering is discussed in this paper. Based on recent findings and a suggested way to evaluate intelligent robotic systems in industry, we give an overview of how their use impacts productivity, safety and operational costs. Experience and case studies confirm the benefits this area brings and the problems that have yet to be solved. The findings indicate that intelligent robotics involves more than a technology change; it introduces important new methods in engineering.

</details>


### [391] [Design And Control of A Robotic Arm For Industrial Applications](https://arxiv.org/abs/2512.00034)
*Sathish Krishna Anumula,SVSV Prasad Sanaboina,Ravi Kumar Nagula,R. Nagaraju*

Main category: cs.RO

TL;DR: The paper presents an affordable and reliable six-DOF robotic arm designed for industrial automation, using servo motors, kinematic analysis, and PID control to achieve high precision.


<details>
  <summary>Details</summary>
Motivation: The growing need to automate processes in industrial settings has driven the development of robotic systems, particularly robotic arms, for tasks like assembly, welding, and material handling.

Method: A six-degree-of-freedom (DOF) robotic manipulator was designed using servo motors and a microcontroller interface, with kinematic and dynamic analyses conducted for precise positioning and load handling. Inverse Kinematics algorithm and PID controller were applied to enhance control precision.

Result: Simulation and experimental testing confirmed the system's high accuracy and repeatability in performing tasks.

Conclusion: The proposed robotic arm is an affordable, expandable, and dependable solution for automating mundane procedures in the manufacturing industry.

Abstract: The growing need to automate processes in industrial settings has led to tremendous growth in the robotic systems and especially the robotic arms. The paper assumes the design, modeling and control of a robotic arm to suit industrial purpose like assembly, welding and material handling. A six-degree-of-freedom (DOF) robotic manipulator was designed based on servo motors and a microcontroller interface with Mechanical links were also fabricated. Kinematic and dynamic analyses have been done in order to provide precise positioning and effective loads. Inverse Kinematics algorithm and Proportional-Integral-Derivative (PID) controller were also applied to improve the precision of control. The ability of the system to carry out tasks with high accuracy and repeatability is confirmed by simulation and experimental testing. The suggested robotic arm is an affordable, expandable, and dependable method of automation of numerous mundane procedures in the manufacturing industry.

</details>


### [392] [ICD-Net: Inertial Covariance Displacement Network for Drone Visual-Inertial SLAM](https://arxiv.org/abs/2512.00037)
*Tali Orlev Shapira,Itzik Klein*

Main category: cs.RO

TL;DR: ICD-Net通过神经网络学习惯性测量数据的位移估计及不确定性，集成到VINS-Fusion中，显著提升SLAM性能，尤其在无人机高速场景下。


<details>
  <summary>Details</summary>
Motivation: 传统视觉惯性SLAM因传感器校准不完美、测量噪声、快速运动等问题表现不佳，尤其在无人机应用中，需要更鲁棒和精确的状态估计。

Method: 提出ICD-Net框架，直接从原始惯性测量数据中学习位移估计及不确定性量化，并将其输出作为额外残差约束集成到VINS-Fusion优化框架中。

Result: 在高速无人机序列上的实验表明，ICD-Net显著提升了轨迹估计精度（平均APE改进38%以上），且不确定性估计对系统鲁棒性至关重要。

Conclusion: ICD-Net通过神经网络增强显著提升了视觉惯性SLAM的性能，尤其在无人机高速飞行场景下，轨迹估计精度提高了38%以上，同时保持了实时性要求。

Abstract: Visual-inertial SLAM systems often exhibit suboptimal performance due to multiple confounding factors including imperfect sensor calibration, noisy measurements, rapid motion dynamics, low illumination, and the inherent limitations of traditional inertial navigation integration methods. These issues are particularly problematic in drone applications where robust and accurate state estimation is critical for safe autonomous operation. In this work, we present ICD-Net, a novel framework that enhances visual-inertial SLAM performance by learning to process raw inertial measurements and generating displacement estimates with associated uncertainty quantification. Rather than relying on analytical inertial sensor models that struggle with real-world sensor imperfections, our method directly extracts displacement maps from sensor data while simultaneously predicting measurement covariances that reflect estimation confidence. We integrate ICD-Net outputs as additional residual constraints into the VINS-Fusion optimization framework, where the predicted uncertainties appropriately weight the neural network contributions relative to traditional visual and inertial terms. The learned displacement constraints provide complementary information that compensates for various error sources in the SLAM pipeline. Our approach can be used under both normal operating conditions and in situations of camera inconsistency or visual degradation. Experimental evaluation on challenging high-speed drone sequences demonstrated that our approach significantly improved trajectory estimation accuracy compared to standard VINS-Fusion, with more than 38% improvement in mean APE and uncertainty estimates proving crucial for maintaining system robustness. Our method shows that neural network enhancement can effectively address multiple sources of SLAM degradation while maintaining real-time performance requirements.

</details>


### [393] [VISTAv2: World Imagination for Indoor Vision-and-Language Navigation](https://arxiv.org/abs/2512.00041)
*Yanjia Huang,Xianshun Jiang,Xiangbo Gao,Mingyang Wu,Zhengzhong Tu*

Main category: cs.RO

TL;DR: VISTAv2 是一种生成式世界模型，通过动作条件想象和在线价值地图规划提升视觉与语言导航的稳健性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于图像想象的 VLN 方法缺乏在线、动作条件的预测，且未生成明确的规划价值；许多方法用长时目标替代规划器，导致脆弱且缓慢。VISTAv2 旨在填补这一空白。

Method: VISTAv2 采用动作感知的条件扩散变换器视频预测器合成短期未来视图，并通过视觉语言评分器与自然语言指令对齐，最后通过可微分的想象到价值头融合多个预测结果，生成想象的自我中心价值地图。

Result: 在 MP3D 和 RoboTHOR 上的评估表明，VISTAv2 优于强基线，且动作条件想象、指令引导的价值融合和在线价值地图规划器均至关重要。

Conclusion: VISTAv2 通过结合动作条件想象、指令引导的价值融合和在线价值地图规划器，为稳健的视觉与语言导航（VLN）提供了一种实用且可解释的路径。

Abstract: Vision-and-Language Navigation (VLN) requires agents to follow language instructions while acting in continuous real-world spaces. Prior image imagination based VLN work shows benefits for discrete panoramas but lacks online, action-conditioned predictions and does not produce explicit planning values; moreover, many methods replace the planner with long-horizon objectives that are brittle and slow. To bridge this gap, we propose VISTAv2, a generative world model that rolls out egocentric future views conditioned on past observations, candidate action sequences, and instructions, and projects them into an online value map for planning. Unlike prior approaches, VISTAv2 does not replace the planner. The online value map is fused at score level with the base objective, providing reachability and risk-aware guidance. Concretely, we employ an action-aware Conditional Diffusion Transformer video predictor to synthesize short-horizon futures, align them with the natural language instruction via a vision-language scorer, and fuse multiple rollouts in a differentiable imagination-to-value head to output an imagined egocentric value map. For efficiency, rollouts occur in VAE latent space with a distilled sampler and sparse decoding, enabling inference on a single consumer GPU. Evaluated on MP3D and RoboTHOR, VISTAv2 improves over strong baselines, and ablations show that action-conditioned imagination, instruction-guided value fusion, and the online value-map planner are all critical, suggesting that VISTAv2 offers a practical and interpretable route to robust VLN.

</details>


### [394] [Causal Reinforcement Learning based Agent-Patient Interaction with Clinical Domain Knowledge](https://arxiv.org/abs/2512.00048)
*Wenzheng Zhao,Ran Zhang,Ruth Palan Lopez,Shu-Fen Wung,Fengpei Yuan*

Main category: cs.RO

TL;DR: 本文提出CRL框架，将因果推理融入强化学习，在机器人辅助护理中表现优于传统方法，具有更高效率和可解释性。


<details>
  <summary>Details</summary>
Motivation: 强化学习在自适应医疗干预（如痴呆症护理）中面临数据稀缺、决策需可解释性及患者状态动态复杂且具有因果性的挑战。

Method: 提出了一种名为因果结构感知强化学习（CRL）的新框架，该框架将因果发现和推理显式地整合到策略优化中。

Result: 实验结果表明，CRL代理在模拟机器人辅助认知护理场景中优于传统无模型强化学习基线，实现了更高的累积奖励、更一致地维持理想患者状态，并展现出可解释且与临床一致的行为。

Conclusion: 本文展示了因果强化学习（CRL）在人机交互应用中的潜力，特别是在需要可解释性、适应性和数据效率的场景下。

Abstract: Reinforcement Learning (RL) faces significant challenges in adaptive healthcare interventions, such as dementia care, where data is scarce, decisions require interpretability, and underlying patient-state dynamic are complex and causal in nature. In this work, we present a novel framework called Causal structure-aware Reinforcement Learning (CRL) that explicitly integrates causal discovery and reasoning into policy optimization. This method enables an agent to learn and exploit a directed acyclic graph (DAG) that describes the causal dependencies between human behavioral states and robot actions, facilitating more efficient, interpretable, and robust decision-making. We validate our approach in a simulated robot-assisted cognitive care scenario, where the agent interacts with a virtual patient exhibiting dynamic emotional, cognitive, and engagement states. The experimental results show that CRL agents outperform conventional model-free RL baselines by achieving higher cumulative rewards, maintaining desirable patient states more consistently, and exhibiting interpretable, clinically-aligned behavior. We further demonstrate that CRL's performance advantage remains robust across different weighting strategies and hyperparameter settings. In addition, we demonstrate a lightweight LLM-based deployment: a fixed policy is embedded into a system prompt that maps inferred states to actions, producing consistent, supportive dialogue without LLM finetuning. Our work illustrates the promise of causal reinforcement learning for human-robot interaction applications, where interpretability, adaptiveness, and data efficiency are paramount.

</details>


### [395] [Socially aware navigation for mobile robots: a survey on deep reinforcement learning approaches](https://arxiv.org/abs/2512.00049)
*Ibrahim Khalil Kabir,Muhammad Faizan Mysorewala*

Main category: cs.RO

TL;DR: 本文综述了基于DRL的社会感知导航方法，分析了算法和神经网络架构的应用，指出当前挑战并建议未来采用混合方法和标准化评估。


<details>
  <summary>Details</summary>
Motivation: 探讨DRL如何加速机器人导航策略的发展，使其在人类环境中遵守社会规范并有效达成目标。

Method: 综合分析了基于DRL的社会感知导航方法，包括价值基础、策略基础和演员-评论家强化学习算法，以及前馈、循环、卷积、图神经网络和Transformer网络架构。

Result: DRL显著提高了安全性和人类接受度，但仍面临评估机制不统一、缺乏标准化社会指标、计算负担限制可扩展性以及仿真到实际硬件应用的转换困难等挑战。

Conclusion: 未来进展将依赖于混合方法，结合多种方法的优势，并创建平衡技术效率和以人为中心评估的基准。

Abstract: Socially aware navigation is a fast-evolving research area in robotics that enables robots to move within human environments while adhering to the implicit human social norms. The advent of Deep Reinforcement Learning (DRL) has accelerated the development of navigation policies that enable robots to incorporate these social conventions while effectively reaching their objectives. This survey offers a comprehensive overview of DRL-based approaches to socially aware navigation, highlighting key aspects such as proxemics, human comfort, naturalness, trajectory and intention prediction, which enhance robot interaction in human environments. This work critically analyzes the integration of value-based, policy-based, and actor-critic reinforcement learning algorithms alongside neural network architectures, such as feedforward, recurrent, convolutional, graph, and transformer networks, for enhancing agent learning and representation in socially aware navigation. Furthermore, we examine crucial evaluation mechanisms, including metrics, benchmark datasets, simulation environments, and the persistent challenges of sim-to-real transfer. Our comparative analysis of the literature reveals that while DRL significantly improves safety, and human acceptance over traditional approaches, the field still faces setback due to non-uniform evaluation mechanisms, absence of standardized social metrics, computational burdens that limit scalability, and difficulty in transferring simulation to real robotic hardware applications. We assert that future progress will depend on hybrid approaches that leverage the strengths of multiple approaches and producing benchmarks that balance technical efficiency with human-centered evaluation.

</details>


### [396] [Reinforcement Learning from Implicit Neural Feedback for Human-Aligned Robot Control](https://arxiv.org/abs/2512.00050)
*Suzie Kim*

Main category: cs.RO

TL;DR: 提出RLIHF框架，利用EEG信号提供隐式反馈，替代传统显式反馈，验证其在稀疏奖励条件下实现与密集奖励相当的性能。


<details>
  <summary>Details</summary>
Motivation: 传统RL方法在稀疏奖励条件下难以学习有效策略，而现有RLHF方法依赖显式反馈机制，干扰自然交互并增加用户认知负担。

Method: 提出了一种新颖的强化学习框架RLIHF，利用非侵入性EEG信号（特别是ErrPs）提供连续隐式反馈，无需用户显式干预。采用预训练解码器将原始EEG信号转换为概率奖励组件。

Result: 在MuJoCo物理引擎的仿真环境中，使用Kinova Gen2机械臂执行复杂抓取任务，结果显示基于EEG反馈训练的智能体性能与密集手动设计奖励训练的智能体相当。

Conclusion: 研究验证了利用隐式神经反馈（如EEG信号）在交互式机器人中进行可扩展且与人类对齐的强化学习的潜力。

Abstract: Conventional reinforcement learning (RL) approaches often struggle to learn effective policies under sparse reward conditions, necessitating the manual design of complex, task-specific reward functions. To address this limitation, reinforcement learning from human feedback (RLHF) has emerged as a promising strategy that complements hand-crafted rewards with human-derived evaluation signals. However, most existing RLHF methods depend on explicit feedback mechanisms such as button presses or preference labels, which disrupt the natural interaction process and impose a substantial cognitive load on the user. We propose a novel reinforcement learning from implicit human feedback (RLIHF) framework that utilizes non-invasive electroencephalography (EEG) signals, specifically error-related potentials (ErrPs), to provide continuous, implicit feedback without requiring explicit user intervention. The proposed method adopts a pre-trained decoder to transform raw EEG signals into probabilistic reward components, enabling effective policy learning even in the presence of sparse external rewards. We evaluate our approach in a simulation environment built on the MuJoCo physics engine, using a Kinova Gen2 robotic arm to perform a complex pick-and-place task that requires avoiding obstacles while manipulating target objects. The results show that agents trained with decoded EEG feedback achieve performance comparable to those trained with dense, manually designed rewards. These findings validate the potential of using implicit neural feedback for scalable and human-aligned reinforcement learning in interactive robotics.

</details>


### [397] [Modeling and Control of Magnetic Forces between Microrobots](https://arxiv.org/abs/2512.00051)
*Amelia Fernández Seguel,Alejandro I. Maass*

Main category: cs.RO

TL;DR: 该研究设计了一种控制器，通过全局磁场的角度参数调节微型机器人间的径向距离，PID+PD级联控制实现了快速、精确且平滑的控制，验证了共享磁场下双机器人控制的可行性，但需未来扩展至3D和多代理系统。


<details>
  <summary>Details</summary>
Motivation: 在生物医学应用中，如靶向药物输送和显微手术，多个磁性微型机器人在共享全局信号下的独立控制存在关键挑战。现有系统大多只能同步移动所有代理，限制了需要差异化驱动的应用。

Method: 通过文献综述开发物理模型，考虑磁偶极-偶极相互作用和粘性介质中的速度。采用PID控制器调节径向距离，随后级联PD控制器平滑磁场方向变化，并在MATLAB中进行仿真。

Result: PID控制器将收敛时间减少约40%。结合PID+PD方案在相似时间内实现平滑角度轨迹，波动仅为±5°。

Conclusion: 该研究验证了在共享磁场下快速、精确控制两个微型机器人径向距离的可行性，但模型仅限于2D环境和两个代理，建议未来研究扩展到3D系统和多个代理。

Abstract: The independent control of multiple magnetic microrobots under a shared global signal presents critical challenges in biomedical applications such as targeted drug delivery and microsurgeries. Most existing systems only allow all agents to move synchronously, limiting their use in applications that require differentiated actuation. This research aims to design a controller capable of regulating the radial distance between micro-agents using only the angle ψof a global magnetic field as the actuation parameter, demonstrating potential for practical applications. The proposed cascade control approach enables faster and more precise adjustment of the inter-agent distance than a proportional controller, while maintaining smooth transitions and avoiding abrupt changes in the orientation of the magnetic field, making it suitable for real-world implementation. A bibliographic review was conducted to develop the physical model, considering magnetic dipole-dipole interactions and velocities in viscous media. A PID controller was implemented to regulate the radial distance, followed by a PD controller in cascade to smooth changes in field orientation. These controllers were simulated in MATLAB, showing that the PID controller reduced convergence time to the desired radius by about 40%. When adding the second controller, the combined PID+PD scheme achieved smooth angular trajectories within similar timeframes, with fluctuations of only \pm 5^\circ. These results validate the feasibility of controlling the radial distance of two microrobots using a shared magnetic field in a fast and precise manner, without abrupt variations in the control angle. However, the model is limited to a 2D environment and two agents, suggesting future research to extend the controller to 3D systems and multiple agents.

</details>


### [398] [An adaptive experience-based discrete genetic algorithm for multi-trip picking robot task scheduling in smart orchards](https://arxiv.org/abs/2512.00057)
*Peng Chen,Jing Liangb,Kang-Jia Qiao,Hui Song,Cai-Tong Yue,Kun-Jie Yu,Ponnuthurai Nagaratnam Suganthan,Witold Pedrycz*

Main category: cs.RO

TL;DR: 研究提出AEDGA算法解决多机器人任务调度问题，通过创新初始化、局部搜索和选择策略，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 智能果园中多机器人系统的高效调度面临复杂优化挑战，现有算法存在冗余局部操作和局部最优风险。

Method: 提出了一种自适应经验离散遗传算法（AEDGA），包括负载-距离平衡初始化方法、基于聚类的局部搜索机制和经验自适应选择策略。

Result: 在18个新提出的测试实例和24个现有测试问题上，AEDGA显著优于八种先进算法。

Conclusion: AEDGA算法在解决多行程采摘机器人任务调度问题上表现出色，显著优于现有八种先进算法。

Abstract: The continuous innovation of smart robotic technologies is driving the development of smart orchards, significantly enhancing the potential for automated harvesting systems. While multi-robot systems offer promising solutions to address labor shortages and rising costs, the efficient scheduling of these systems presents complex optimization challenges. This research investigates the multi-trip picking robot task scheduling (MTPRTS) problem. The problem is characterized by its provision for robot redeployment while maintaining strict adherence to makespan constraints, and encompasses the interdependencies among robot weight, robot load, and energy consumption, thus introducing substantial computational challenges that demand sophisticated optimization algorithms.To effectively tackle this complexity, metaheuristic approaches, which often utilize local search mechanisms, are widely employed. Despite the critical role of local search in vehicle routing problems, most existing algorithms are hampered by redundant local operations, leading to slower search processes and higher risks of local optima, particularly in large-scale scenarios. To overcome these limitations, we propose an adaptive experience-based discrete genetic algorithm (AEDGA) that introduces three key innovations: (1) integrated load-distance balancing initialization method, (2) a clustering-based local search mechanism, and (3) an experience-based adaptive selection strategy. To ensure solution feasibility under makespan constraints, we develop a solution repair strategy implemented through three distinct frameworks. Comprehensive experiments on 18 proposed test instances and 24 existing test problems demonstrate that AEDGA significantly outperforms eight state-of-the-art algorithms.

</details>


### [399] [SpeedAug: Policy Acceleration via Tempo-Enriched Policy and RL Fine-Tuning](https://arxiv.org/abs/2512.00062)
*Taewook Nam,Sung Ju Hwang*

Main category: cs.RO

TL;DR: SpeedAug是一个基于RL的策略加速框架，通过预训练速度增强演示的行为先验，提升策略加速的样本效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 尽管机器人策略学习在复杂操作方面取得了进展，但由于收集更快演示的成本，策略执行速度往往落后于硬件能力。现有方法在适应未见执行速度时遇到分布偏移问题，而RL的无引导探索样本效率低。

Method: SpeedAug构建了一个包含不同任务执行节奏的行为先验，通过在速度增强演示上预训练策略。随后，RL微调从这个节奏丰富的策略初始化，以提升样本效率。

Result: 在机器人操作基准测试中，SpeedAug显著提高了现有RL和政策加速方法的样本效率，同时保持了高成功率。

Conclusion: SpeedAug框架通过预训练速度增强演示的行为先验，显著提升了现有RL和政策加速方法的样本效率，同时保持了高成功率。

Abstract: Recent advances in robotic policy learning have enabled complex manipulation in real-world environments, yet the execution speed of these policies often lags behind hardware capabilities due to the cost of collecting faster demonstrations. Existing works on policy acceleration reinterpret action sequence for unseen execution speed, thereby encountering distributional shifts from the original demonstrations. Reinforcement learning is a promising approach that adapts policies for faster execution without additional demonstration, but its unguided exploration is sample inefficient. We propose SpeedAug, an RL-based policy acceleration framework that efficiently adapts pre-trained policies for faster task execution. SpeedAug constructs behavior prior that encompasses diverse tempos of task execution by pre-training a policy on speed-augmented demonstrations. Empirical results on robotic manipulation benchmarks show that RL fine-tuning initialized from this tempo-enriched policy significantly improves the sample efficiency of existing RL and policy acceleration methods while maintaining high success rate.

</details>


### [400] [Enhancing Cognitive Robotics with Commonsense through LLM-Generated Preconditions and Subgoals](https://arxiv.org/abs/2512.00069)
*Ohad Bachner,Bar Gamliel*

Main category: cs.RO

TL;DR: 通过LLM补充常识细节，提升符号规划在机器人任务中的有效性和适应性。


<details>
  <summary>Details</summary>
Motivation: 解决传统符号规划因缺乏常识细节（如隐藏的先决条件和小型子目标）而导致的机器人日常任务失败问题。

Method: 利用LLM从自然语言任务中推测可能的先决条件和子目标，并将其转化为正式的规划模型，随后在模拟中执行生成的计划。

Result: 与不包含LLM步骤的基线规划器相比，该系统生成更多有效计划，任务成功率更高，且对环境变化适应性更强。

Conclusion: 结合大型语言模型（LLM）与符号规划，可以提升机器人在现实场景中的行为可靠性。

Abstract: Robots often fail at everyday tasks because instructions skip commonsense details like hidden preconditions and small subgoals. Traditional symbolic planners need these details to be written explicitly, which is time consuming and often incomplete. In this project we combine a Large Language Model with symbolic planning. Given a natural language task, the LLM suggests plausible preconditions and subgoals. We translate these suggestions into a formal planning model and execute the resulting plan in simulation. Compared to a baseline planner without the LLM step, our system produces more valid plans, achieves a higher task success rate, and adapts better when the environment changes. These results suggest that adding LLM commonsense to classical planning can make robot behavior in realistic scenarios more reliable.

</details>


### [401] [Reconfigurable Auxetic Devices (RADs) for Robotic Surface Manipulation](https://arxiv.org/abs/2512.00072)
*Jacob Miske,Ahyan Maya,Ahnaf Inkiad,Jeffrey Ian Lipton*

Main category: cs.RO

TL;DR: 本文展示了可重构拉胀晶格用于机器人表面操作，通过反冲实现局部扩展，验证了其在自适应结构中的潜力。


<details>
  <summary>Details</summary>
Motivation: 传统的机器人表面使用正泊松比材料，而具有负泊松比的拉胀材料在拉伸时可能在多个方向上扩展，从而实现更贴合的操作界面。

Method: 通过可重构锁定或嵌入式伺服机构驱动拉胀晶格结构，利用晶格单元间的反冲实现局部晶格区域的可变扩展。

Result: 实验结果表明，可重构拉胀结构能够实现可变表面贴合，并通过简化模型验证了系统的有效性。

Conclusion: 可重构的拉胀结构通过可变表面收缩和扩展实现了操作，保持了与反冲的顺应性，为自适应机器人结构在表面操作任务中开辟了新机会。

Abstract: Robotic surfaces traditionally use materials with a positive Poisson's ratio to push and pull on a manipulation interface. Auxetic materials with a negative Poisson's ratio may expand in multiple directions when stretched and enable conformable interfaces. Here we demonstrate reconfigurable auxetic lattices for robotic surface manipulation. Our approach enables shape control through reconfigurable locking or embedded servos that underactuate an auxetic lattice structure. Variable expansion of local lattice areas is enabled by backlash between unit cells. Demonstrations of variable surface conformity are presented with characterization metrics. Experimental results are validated against a simplified model of the system, which uses an activation function to model intercell coupling with backlash. Reconfigurable auxetic structures are shown to achieve manipulation via variable surface contraction and expansion. This structure maintains compliance with backlash in contrast with previous work on auxetics, opening new opportunities in adaptive robotic structures for surface manipulation tasks.

</details>


### [402] [Bootstrap Dynamic-Aware 3D Visual Representation for Scalable Robot Learning](https://arxiv.org/abs/2512.00074)
*Qiwei Liang,Boyang Cai,Minghao Lai,Sitong Zhuang,Tao Lin,Yan Qin,Yixuan Ye,Jiaming Liang,Renjing Xu*

Main category: cs.RO

TL;DR: AFRO 是一种自监督框架，通过扩散过程和动力学建模学习 3D 表示，显著提升机器人操作性能。


<details>
  <summary>Details</summary>
Motivation: 当前 3D 视觉预训练方法在机器人操作任务中表现不佳，主要原因是缺乏状态-动作-状态动力学建模和显式几何重建的冗余。

Method: AFRO 通过生成扩散过程进行状态预测，并在共享潜在空间中联合建模前向和逆向动力学，以捕捉因果转移结构。此外，采用特征差分和逆向一致性监督来防止动作学习中的特征泄漏。

Result: AFRO 结合 Diffusion Policy 后，在 16 个模拟和 4 个真实世界任务中显著提高了操作成功率，优于现有预训练方法。

Conclusion: AFRO 提供了一种有效的 3D 表示学习预训练解决方案，显著提高了机器人操作任务的成功率。

Abstract: Despite strong results on recognition and segmentation, current 3D visual pre-training methods often underperform on robotic manipulation. We attribute this gap to two factors: the lack of state-action-state dynamics modeling and the unnecessary redundancy of explicit geometric reconstruction. We introduce AFRO, a self-supervised framework that learns dynamics-aware 3D representations without action or reconstruction supervision. AFRO casts state prediction as a generative diffusion process and jointly models forward and inverse dynamics in a shared latent space to capture causal transition structure. To prevent feature leakage in action learning, we employ feature differencing and inverse-consistency supervision, improving the quality and stability of visual features. When combined with Diffusion Policy, AFRO substantially increases manipulation success rates across 16 simulated and 4 real-world tasks, outperforming existing pre-training approaches. The framework also scales favorably with data volume and task complexity. Qualitative visualizations indicate that AFRO learns semantically rich, discriminative features, offering an effective pre-training solution for 3D representation learning in robotics. Project page: https://kolakivy.github.io/AFRO/

</details>


### [403] [Arcadia: Toward a Full-Lifecycle Framework for Embodied Lifelong Learning](https://arxiv.org/abs/2512.00076)
*Minghe Gao,Juncheng Li,Yuze Lin,Xuqi Liu,Jiaming Ji,Xiaoran Pan,Zihan Xu,Xian Li,Mingjie Li,Wei Ji,Rong Wei,Rui Tang,Qizhou Wang,Kai Shen,Jun Xiao,Qi Wu,Siliang Tang,Yueting Zhuang*

Main category: cs.RO

TL;DR: Arcadia是一个闭环框架，通过四阶段紧密耦合实现具身终身学习，显著提升任务表现和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有系统通常仅优化单一环节（如数据收集或部署），难以持续改进或泛化到狭窄场景之外。Arcadia旨在通过闭环生命周期解决这一问题。

Method: Arcadia框架包含四个紧密耦合的阶段：(1)自主数据采集，(2)生成式场景重建与增强，(3)共享具身表征架构，(4)仿真评估与进化。

Result: Arcadia在导航和操作任务上表现优异，并能稳健迁移到物理机器人，验证了其持续改进和泛化能力。

Conclusion: Arcadia作为一个紧密耦合的闭环框架，通过整合数据采集、场景重建、共享表征学习和仿真评估四个阶段，实现了持续改进和端到端泛化，为通用具身智能体提供了可扩展的基础。

Abstract: We contend that embodied learning is fundamentally a lifecycle problem rather than a single-stage optimization. Systems that optimize only one link (data collection, simulation, learning, or deployment) rarely sustain improvement or generalize beyond narrow settings. We introduce Arcadia, a closed-loop framework that operationalizes embodied lifelong learning by tightly coupling four stages: (1) Self-evolving exploration and grounding for autonomous data acquisition in physical environments, (2) Generative scene reconstruction and augmentation for realistic and extensible scene creation, (3) a Shared embodied representation architecture that unifies navigation and manipulation within a single multimodal backbone, and (4) Sim-from-real evaluation and evolution that closes the feedback loop through simulation-based adaptation. This coupling is non-decomposable: removing any stage breaks the improvement loop and reverts to one-shot training. Arcadia delivers consistent gains on navigation and manipulation benchmarks and transfers robustly to physical robots, indicating that a tightly coupled lifecycle: continuous real-world data acquisition, generative simulation update, and shared-representation learning, supports lifelong improvement and end-to-end generalization. We release standardized interfaces enabling reproducible evaluation and cross-model comparison in reusable environments, positioning Arcadia as a scalable foundation for general-purpose embodied agents.

</details>


### [404] [A Hierarchical Framework for Humanoid Locomotion with Supernumerary Limbs](https://arxiv.org/abs/2512.00077)
*Bowen Zhi*

Main category: cs.RO

TL;DR: 论文提出分层控制架构，结合学习型运动与模型平衡，有效提升带超级肢体的人形机器人运动稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决超级肢体集成到人形机器人时因动态扰动导致的稳定性问题。

Method: 设计了一个分层控制架构，低层通过模仿学习和课程学习生成行走步态，高层利用超级肢体进行动态平衡。

Result: 动态平衡控制器使步态更接近基准，CoM轨迹的DTW距离减少47%，并在步态周期内实现更快的再稳定和协调的反相GRF模式。

Conclusion: 分层控制架构通过解耦学习型运动与模型平衡策略，有效减轻了超级肢体带来的动态干扰，实现了人形机器人的稳定运动。

Abstract: The integration of Supernumerary Limbs (SLs) on humanoid robots poses a significant stability challenge due to the dynamic perturbations they introduce. This thesis addresses this issue by designing a novel hierarchical control architecture to improve humanoid locomotion stability with SLs. The core of this framework is a decoupled strategy that combines learning-based locomotion with model-based balancing. The low-level component consists of a walking gait for a Unitree H1 humanoid through imitation learning and curriculum learning. The high-level component actively utilizes the SLs for dynamic balancing. The effectiveness of the system is evaluated in a physics-based simulation under three conditions: baseline gait for an unladen humanoid (baseline walking), walking with a static SL payload (static payload), and walking with the active dynamic balancing controller (dynamic balancing). Our evaluation shows that the dynamic balancing controller improves stability. Compared to the static payload condition, the balancing strategy yields a gait pattern closer to the baseline and decreases the Dynamic Time Warping (DTW) distance of the CoM trajectory by 47\%. The balancing controller also improves the re-stabilization within gait cycles and achieves a more coordinated anti-phase pattern of Ground Reaction Forces (GRF). The results demonstrate that a decoupled, hierarchical design can effectively mitigate the internal dynamic disturbances arising from the mass and movement of the SLs, enabling stable locomotion for humanoids equipped with functional limbs. Code and videos are available here: https://github.com/heyzbw/HuSLs.

</details>


### [405] [Hyper-GoalNet: Goal-Conditioned Manipulation Policy Learning with HyperNetworks](https://arxiv.org/abs/2512.00085)
*Pei Zhou,Wanting Yao,Qian Luo,Xunzhe Zhou,Yanchao Yang*

Main category: cs.RO

TL;DR: Hyper-GoalNet 是一种通过超网络生成任务特定策略参数的框架，结合潜在空间约束，显著提升了多样化环境中的性能表现。


<details>
  <summary>Details</summary>
Motivation: 目标导向的策略学习在多样化目标和环境中保持性能存在挑战，需要一种能够分离目标解释和状态处理的方法。

Method: 使用超网络从目标规范生成策略网络参数，并通过对潜在空间的两个互补约束（前向动力学模型和基于距离的约束）来增强表示质量。

Result: 在多样化操作任务中表现出显著的性能提升，特别是在高变异性条件下，并在实际机器人实验中验证了其鲁棒性。

Conclusion: Hyper-GoalNet 通过超网络生成任务特定的策略网络参数，显著提升了在多样化目标和环境中的性能表现，并在实际机器人实验中验证了其鲁棒性。

Abstract: Goal-conditioned policy learning for robotic manipulation presents significant challenges in maintaining performance across diverse objectives and environments. We introduce Hyper-GoalNet, a framework that generates task-specific policy network parameters from goal specifications using hypernetworks. Unlike conventional methods that simply condition fixed networks on goal-state pairs, our approach separates goal interpretation from state processing -- the former determines network parameters while the latter applies these parameters to current observations. To enhance representation quality for effective policy generation, we implement two complementary constraints on the latent space: (1) a forward dynamics model that promotes state transition predictability, and (2) a distance-based constraint ensuring monotonic progression toward goal states. We evaluate our method on a comprehensive suite of manipulation tasks with varying environmental randomization. Results demonstrate significant performance improvements over state-of-the-art methods, particularly in high-variability conditions. Real-world robotic experiments further validate our method's robustness to sensor noise and physical uncertainties. Code is available at: https://github.com/wantingyao/hyper-goalnet.

</details>


### [406] ["Why the face?": Exploring Robot Error Detection Using Instrumented Bystander Reactions](https://arxiv.org/abs/2512.00262)
*Maria Teresa Parreira,Ruidong Zhang,Sukruth Gowdru Lingaraju,Alexandra Bremers,Xuanyu Fang,Adolfo Ramirez-Aristizabal,Manaswi Saha,Michael Kuniavsky,Cheng Zhang,Wendy Ju*

Main category: cs.RO

TL;DR: 研究通过下巴摄像头捕获人类对机器人错误的反应，开发了NeckNet-18模型和错误检测系统，性能优于传统方法，推动机器人社交感知能力。


<details>
  <summary>Details</summary>
Motivation: 人类通过观察同伴和解码旁观者的微妙线索（如挑眉、笑声）来评估环境和自身行为，从而实现社交能力。然而，机器人难以感知和利用这些细微反应。

Method: 首先，我们开发了NeckNet-18，一种3D面部重建模型，将通过下巴摄像头捕获的反应映射到面部点和头部运动上。然后，利用这些面部反应开发了一个机器人错误检测模型，该模型在性能上优于使用OpenFace或视频数据等标准方法，尤其在参与者内部数据上表现优异。

Result: 开发的机器人错误检测模型在性能上优于标准方法，尤其在参与者内部数据上表现优异。

Conclusion: 通过这项研究，我们主张扩展人机交互中的机器人感知能力，促进机器人在多样化人类环境中的无缝集成，推动社交线索检测的边界，并为适应性机器人开辟新途径。

Abstract: How do humans recognize and rectify social missteps? We achieve social competence by looking around at our peers, decoding subtle cues from bystanders - a raised eyebrow, a laugh - to evaluate the environment and our actions. Robots, however, struggle to perceive and make use of these nuanced reactions. By employing a novel neck-mounted device that records facial expressions from the chin region, we explore the potential of previously untapped data to capture and interpret human responses to robot error. First, we develop NeckNet-18, a 3D facial reconstruction model to map the reactions captured through the chin camera onto facial points and head motion. We then use these facial responses to develop a robot error detection model which outperforms standard methodologies such as using OpenFace or video data, generalizing well especially for within-participant data. Through this work, we argue for expanding human-in-the-loop robot sensing, fostering more seamless integration of robots into diverse human environments, pushing the boundaries of social cue detection and opening new avenues for adaptable robotics.

</details>


### [407] [RealAppliance: Let High-fidelity Appliance Assets Controllable and Workable as Aligned Real Manuals](https://arxiv.org/abs/2512.00287)
*Yuzheng Gao,Yuxing Long,Lei Kang,Yuchong Guo,Ziyan Yu,Shangqing Mao,Jiyao Zhang,Ruihai Wu,Dongjiang Li,Hui Shen,Hao Dong*

Main category: cs.RO

TL;DR: 提出RealAppliance数据集和基准，解决家电操作研究中模拟与现实的差距问题。


<details>
  <summary>Details</summary>
Motivation: 现有家电资产存在渲染质量差、机制不完整、与手册不对齐等问题，导致模拟与现实的差距，阻碍家电操作研究的发展。

Method: 提出了RealAppliance数据集和RealAppliance-Bench基准，评估多模态大语言模型和具身操作规划模型在家电操作任务中的表现。

Result: RealAppliance数据集包含100个高保真家电，具备完整的物理、电子机制和与手册对齐的程序逻辑。RealAppliance-Bench基准分析了模型在关键任务中的表现。

Conclusion: RealAppliance数据集和RealAppliance-Bench基准为家电操作研究提供了高保真资源和评估标准，有助于缩小模拟与现实的差距。

Abstract: Existing appliance assets suffer from poor rendering, incomplete mechanisms, and misalignment with manuals, leading to simulation-reality gaps that hinder appliance manipulation development. In this work, we introduce the RealAppliance dataset, comprising 100 high-fidelity appliances with complete physical, electronic mechanisms, and program logic aligned with their manuals. Based on these assets, we propose the RealAppliance-Bench benchmark, which evaluates multimodal large language models and embodied manipulation planning models across key tasks in appliance manipulation planning: manual page retrieval, appliance part grounding, open-loop manipulation planning, and closed-loop planning adjustment. Our analysis of model performances on RealAppliance-Bench provides insights for advancing appliance manipulation research

</details>


### [408] [MILE: A Mechanically Isomorphic Exoskeleton Data Collection System with Fingertip Visuotactile Sensing for Dexterous Manipulation](https://arxiv.org/abs/2512.00324)
*Jinda Du,Jieji Ren,Qiaojun Yu,Ningbin Zhang,Yu Deng,Xingyu Wei,Yufei Liu,Guoying Gu,Xiangyang Zhu*

Main category: cs.RO

TL;DR: MILE系统通过机械同构设计和高效数据收集，显著提升了灵巧手操作的模仿学习效果，特别是在接触丰富的任务中。


<details>
  <summary>Details</summary>
Motivation: 模仿学习在灵巧手操作中的应用受限于缺乏大规模高保真数据。现有数据收集方法存在运动重定向不准确、数据收集效率低和缺少高分辨率指尖触觉感知等问题。

Method: MILE系统采用机械同构设计，从人手到外骨骼再到机器人手，实现了一对一的关节位置同构，消除了非线性重定向问题。外骨骼实现了多关节平均绝对角度误差低于1度，机器人手集成了高分辨率的指尖视觉触觉模块。

Result: MILE系统的远程操作管道平均成功率提高了64%，结合指尖触觉观测后，成功率比仅视觉基线平均提高了25%，验证了数据集的高保真性和实用性。

Conclusion: MILE系统通过机械同构的远程操作和数据收集系统，显著提高了模仿学习在灵巧手操作中的有效性，特别是在接触丰富的操作任务中。

Abstract: Imitation learning provides a promising approach to dexterous hand manipulation, but its effectiveness is limited by the lack of large-scale, high-fidelity data. Existing data-collection pipelines suffer from inaccurate motion retargeting, low data-collection efficiency, and missing high-resolution fingertip tactile sensing. We address this gap with MILE, a mechanically isomorphic teleoperation and data-collection system co-designed from human hand to exoskeleton to robotic hand. The exoskeleton is anthropometrically derived from the human hand, and the robotic hand preserves one-to-one joint-position isomorphism, eliminating nonlinear retargeting and enabling precise, natural control. The exoskeleton achieves a multi-joint mean absolute angular error below one degree, while the robotic hand integrates compact fingertip visuotactile modules that provide high-resolution tactile observations. Built on this retargeting-free interface, we teleoperate complex, contact-rich in-hand manipulation and efficiently collect a multimodal dataset comprising high-resolution fingertip visuotactile signals, RGB-D images, and joint positions. The teleoperation pipeline achieves a mean success rate improvement of 64%. Incorporating fingertip tactile observations further increases the success rate by an average of 25% over the vision-only baseline, validating the fidelity and utility of the dataset. Further details are available at: https://sites.google.com/view/mile-system.

</details>


### [409] [DPNet: Doppler LiDAR Motion Planning for Highly-Dynamic Environments](https://arxiv.org/abs/2512.00375)
*Wei Zuo,Zeyi Ren,Chengyang Li,Yikun Wang,Mingle Zhao,Shuai Wang,Wei Sui,Fei Gao,Yik-Chung Wu,Chengzhong Xu*

Main category: cs.RO

TL;DR: DPNet整合多普勒LiDAR与模型学习，实现快速障碍物跟踪与高精度运动规划。


<details>
  <summary>Details</summary>
Motivation: 现有运动规划方法对快速运动障碍物的环境变化理解不足，需高精度和高频率的解决方案。

Method: 提出Doppler Planning Network (DPNet)，结合Doppler Kalman神经网络(D-KalmanNet)和多普勒调谐模型预测控制(DT-MPC)框架。

Result: 在高保真模拟器和真实数据集上的实验表明，DPNet优于多种基准方案。

Conclusion: DPNet通过整合多普勒LiDAR和模型学习，有效解决了快速运动障碍物的跟踪与规划问题，实现了高频率和高精度的性能。

Abstract: Existing motion planning methods often struggle with rapid-motion obstacles due to an insufficient understanding of environmental changes. To address this limitation, we propose integrating motion planners with Doppler LiDARs which provide not only ranging measurements but also instantaneous point velocities. However, this integration is nontrivial due to the dual requirements of high accuracy and high frequency. To this end, we introduce Doppler Planning Network (DPNet), which tracks and reacts to rapid obstacles using Doppler model-based learning. Particularly, we first propose a Doppler Kalman neural network (D-KalmanNet) to track the future states of obstacles under partially observable Gaussian state space model. We then leverage the estimated motions to construct a Doppler-tuned model predictive control (DT-MPC) framework for ego-motion planning, enabling runtime auto-tuning of the controller parameters. These two model-based learners allow DPNet to maintain lightweight while learning fast environmental changes using minimum data, and achieve both high frequency and high accuracy in tracking and planning. Experiments on both high-fidelity simulator and real-world datasets demonstrate the superiority of DPNet over extensive benchmark schemes.

</details>


### [410] [Balancing Efficiency and Fairness: An Iterative Exchange Framework for Multi-UAV Cooperative Path Planning](https://arxiv.org/abs/2512.00410)
*Hongzong Li,Luwei Liao,Xiangguang Dai,Yuming Feng,Rong Feng,Shiqin Tang*

Main category: cs.RO

TL;DR: 提出了一种迭代交换框架，用于多无人机协同路径规划，平衡效率与公平性，实验证明其优越性。


<details>
  <summary>Details</summary>
Motivation: 解决多无人机协同路径规划中效率与公平性的平衡问题，避免个别无人机负担过重。

Method: 采用迭代任务交换和路径优化的方法，结合A*搜索在考虑地形的配置空间中生成无碰撞轨迹。

Result: 在多个地形数据集上的实验表明，该方法在总距离和完成时间上优于现有基线。

Conclusion: 本文提出的迭代交换框架在MUCPP问题中实现了效率与公平性的平衡，通过实验验证了其在总距离和完成时间上的优越性。

Abstract: Multi-UAV cooperative path planning (MUCPP) is a fundamental problem in multi-agent systems, aiming to generate collision-free trajectories for a team of unmanned aerial vehicles (UAVs) to complete distributed tasks efficiently. A key challenge lies in achieving both efficiency, by minimizing total mission cost, and fairness, by balancing the workload among UAVs to avoid overburdening individual agents. This paper presents a novel Iterative Exchange Framework for MUCPP, balancing efficiency and fairness through iterative task exchanges and path refinements. The proposed framework formulates a composite objective that combines the total mission distance and the makespan, and iteratively improves the solution via local exchanges under feasibility and safety constraints. For each UAV, collision-free trajectories are generated using A* search over a terrain-aware configuration space. Comprehensive experiments on multiple terrain datasets demonstrate that the proposed method consistently achieves superior trade-offs between total distance and makespan compared to existing baselines.

</details>


### [411] [Hardware-Software Collaborative Computing of Photonic Spiking Reinforcement Learning for Robotic Continuous Control](https://arxiv.org/abs/2512.00427)
*Mengting Yu,Shuiying Xiang,Changjian Xie,Yonghang Chen,Haowen Zhao,Xingxing Guo,Yahui Zhang,Yanan Han,Yue Hao*

Main category: cs.RO

TL;DR: 该论文提出了一种结合光子计算和脉冲强化学习的新型架构，用于机器人连续控制任务，实验显示高效能和低延迟。


<details>
  <summary>Details</summary>
Motivation: 机器人连续控制任务对计算架构的能效和延迟有严格要求，传统电子计算平台面临计算瓶颈，而光子计算与脉冲强化学习的融合提供了有前景的替代方案。

Method: 提出了一种基于光子脉冲强化学习的新型计算架构，结合了TD3算法和脉冲神经网络，采用光电混合计算范式，其中硅光子MZI芯片执行线性矩阵计算，非线性脉冲激活在电子域完成。

Result: 在Pendulum-v1和HalfCheetah-v2基准测试中验证了系统软硬件协同推理能力，HalfCheetah-v2上实现了5831的控制策略奖励，收敛步骤减少23.33%，动作偏差低于2.2%，能效达1.39 TOPS/W，计算延迟仅为120 ps。

Conclusion: 该研究首次将可编程MZI光子计算芯片应用于机器人连续控制任务，展示了光子脉冲强化学习在自主和工业机器人系统中实时决策的潜力。

Abstract: Robotic continuous control tasks impose stringent demands on the energy efficiency and latency of computing architectures due to their high-dimensional state spaces and real-time interaction requirements. Conventional electronic computing platforms face computational bottlenecks, whereas the fusion of photonic computing and spiking reinforcement learning (RL) offers a promising alternative. Here, we propose a novel computing architecture based on photonic spiking RL, which integrates the Twin Delayed Deep Deterministic policy gradient (TD3) algorithm with spiking neural network (SNN). The proposed architecture employs an optical-electronic hybrid computing paradigm wherein a silicon photonic Mach-Zehnder interferometer (MZI) chip executes linear matrix computations, while nonlinear spiking activations are performed in the electronic domain. Experimental validation on the Pendulum-v1 and HalfCheetah-v2 benchmarks demonstrates the system capability for software-hardware co-inference, achieving a control policy reward of 5831 on HalfCheetah-v2, a 23.33% reduction in convergence steps, and an action deviation below 2.2%. Notably, this work represents the first application of a programmable MZI photonic computing chip to robotic continuous control tasks, attaining an energy efficiency of 1.39 TOPS/W and an ultralow computational latency of 120 ps. Such performance underscores the promise of photonic spiking RL for real-time decision-making in autonomous and industrial robotic systems.

</details>


### [412] [Sample-Efficient Expert Query Control in Active Imitation Learning via Conformal Prediction](https://arxiv.org/abs/2512.00453)
*Arad Firouzkouhi,Omid Mirzaeedodangeh,Lars Lindemann*

Main category: cs.RO

TL;DR: CRSAIL通过保形预测和状态新颖性评分，显著减少专家查询次数，同时保持高性能。


<details>
  <summary>Details</summary>
Motivation: 解决主动模仿学习（AIL）中专家动作标注成本高的问题，尤其是在GPU密集型模拟器、人机交互场景和机器人舰队重复访问相似状态时。

Method: CRSAIL通过计算状态与专家数据集中第K近邻的距离来评分状态新颖性，并使用保形预测设定全局阈值，仅在新颖状态下请求专家动作。

Result: 在MuJoCo机器人任务中，CRSAIL在减少专家查询次数的同时，性能匹配或超越专家水平。

Conclusion: CRSAIL显著减少了专家查询次数（相比DAgger减少96%，相比其他AIL方法减少65%），同时保持或超越专家级奖励水平，且对参数α和K具有鲁棒性，便于在新系统部署。

Abstract: Active imitation learning (AIL) combats covariate shift by querying an expert during training. However, expert action labeling often dominates the cost, especially in GPU-intensive simulators, human-in-the-loop settings, and robot fleets that revisit near-duplicate states. We present Conformalized Rejection Sampling for Active Imitation Learning (CRSAIL), a querying rule that requests an expert action only when the visited state is under-represented in the expert-labeled dataset. CRSAIL scores state novelty by the distance to the $K$-th nearest expert state and sets a single global threshold via conformal prediction. This threshold is the empirical $(1-α)$ quantile of on-policy calibration scores, providing a distribution-free calibration rule that links $α$ to the expected query rate and makes $α$ a task-agnostic tuning knob. This state-space querying strategy is robust to outliers and, unlike safety-gate-based AIL, can be run without real-time expert takeovers: we roll out full trajectories (episodes) with the learner and only afterward query the expert on a subset of visited states. Evaluated on MuJoCo robotics tasks, CRSAIL matches or exceeds expert-level reward while reducing total expert queries by up to 96% vs. DAgger and up to 65% vs. prior AIL methods, with empirical robustness to $α$ and $K$, easing deployment on novel systems with unknown dynamics.

</details>


### [413] [LAP: Fast LAtent Diffusion Planner with Fine-Grained Feature Distillation for Autonomous Driving](https://arxiv.org/abs/2512.00470)
*Jinhao Zhang,Wenlong Xia,Zhexuan Zhou,Youmin Gong,Jie Mei*

Main category: cs.RO

TL;DR: LAP是一种在潜在空间中进行驾驶规划的框架，通过分离高层意图与低层运动学，实现高效且高性能的自动驾驶规划。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在建模人类驾驶行为方面表现出色，但其迭代采样过程导致显著延迟，且直接处理原始轨迹点迫使模型关注低层运动学而非高层多模态语义。

Method: 提出了LAtent Planner（LAP）框架，在VAE学习的潜在空间中进行规划，分离高层意图与低层运动学，并通过细粒度特征蒸馏机制优化高层语义规划空间与向量化场景上下文的交互与融合。

Result: LAP能够通过单次去噪步骤生成高质量规划，显著降低计算开销。

Conclusion: LAP在nuPlan基准测试中实现了基于学习的规划方法中最先进的闭环性能，同时推理速度比之前的最先进方法提高了最多10倍。

Abstract: Diffusion models have demonstrated strong capabilities for modeling human-like driving behaviors in autonomous driving, but their iterative sampling process induces substantial latency, and operating directly on raw trajectory points forces the model to spend capacity on low-level kinematics, rather than high-level multi-modal semantics. To address these limitations, we propose LAtent Planner (LAP), a framework that plans in a VAE-learned latent space that disentangles high-level intents from low-level kinematics, enabling our planner to capture rich, multi-modal driving strategies. We further introduce a fine-grained feature distillation mechanism to guide a better interaction and fusion between the high-level semantic planning space and the vectorized scene context. Notably, LAP can produce high-quality plans in one single denoising step, substantially reducing computational overhead. Through extensive evaluations on the large-scale nuPlan benchmark, LAP achieves state-of-the-art closed-loop performance among learning-based planning methods, while demonstrating an inference speed-up of at most 10 times over previous SOTA approaches.

</details>


### [414] [HAVEN: Hierarchical Adversary-aware Visibility-Enabled Navigation with Cover Utilization using Deep Transformer Q-Networks](https://arxiv.org/abs/2512.00592)
*Mihir Chauhan,Damon Conover,Aniket Bera*

Main category: cs.RO

TL;DR: 提出分层导航框架，结合DTQN和模块化控制器，显著提升部分可观测环境下的导航性能。


<details>
  <summary>Details</summary>
Motivation: 解决在部分可观测环境中（如遮挡或有限视野）的自主导航问题，传统路径规划和无记忆强化学习方法常导致不安全或低效操作。

Method: 采用分层导航框架，结合深度Transformer Q网络（DTQN）作为高级子目标选择器，以及模块化低级控制器执行路径点跟踪。DTQN利用任务感知特征的短期历史数据，生成候选子目标的Q值排序。

Result: 在2D仿真和3D Unity-ROS环境中验证，相比传统规划器和RL基线，在成功率、安全裕度和目标达成时间上均有显著提升。

Conclusion: 该论文提出了一个通用的、可扩展的框架，用于在不确定环境下实现安全导航，适用于多种机器人平台。

Abstract: Autonomous navigation in partially observable environments requires agents to reason beyond immediate sensor input, exploit occlusion, and ensure safety while progressing toward a goal. These challenges arise in many robotics domains, from urban driving and warehouse automation to defense and surveillance. Classical path planning approaches and memoryless reinforcement learning often fail under limited fields of view (FoVs) and occlusions, committing to unsafe or inefficient maneuvers. We propose a hierarchical navigation framework that integrates a Deep Transformer Q-Network (DTQN) as a high-level subgoal selector with a modular low-level controller for waypoint execution. The DTQN consumes short histories of task-aware features, encoding odometry, goal direction, obstacle proximity, and visibility cues, and outputs Q-values to rank candidate subgoals. Visibility-aware candidate generation introduces masking and exposure penalties, rewarding the use of cover and anticipatory safety. A low-level potential field controller then tracks the selected subgoal, ensuring smooth short-horizon obstacle avoidance. We validate our approach in 2D simulation and extend it directly to a 3D Unity-ROS environment by projecting point-cloud perception into the same feature schema, enabling transfer without architectural changes. Results show consistent improvements over classical planners and RL baselines in success rate, safety margins, and time to goal, with ablations confirming the value of temporal memory and visibility-aware candidate design. These findings highlight a generalizable framework for safe navigation under uncertainty, with broad relevance across robotic platforms.

</details>


### [415] [Fast, Robust, Permutation-and-Sign Invariant SO(3) Pattern Alignment](https://arxiv.org/abs/2512.00659)
*Anik Sarker,Alan T. Asbeck*

Main category: cs.RO

TL;DR: 提出一种无需对应关系搜索的旋转集对齐方法，通过TBV分解和PASI包装器实现高效、鲁棒的对齐。


<details>
  <summary>Details</summary>
Motivation: 解决校准和注册中因缺失时间对齐、异常值和未知轴约定而受阻的旋转集对齐问题。

Method: 通过将旋转分解为转换基向量（TBVs），并使用快速、鲁棒的匹配器（SPMC、FRS及混合方法）对齐球形点集。引入排列和符号不变（PASI）包装器处理轴重标记和符号翻转问题。

Result: 实验表明，该方法准确、速度比传统方法快6-60倍，且在高达90%的异常值比例下仍保持鲁棒性。

Conclusion: 该方法在无需对应关系搜索的情况下，实现了对旋转集的高效、准确对齐，且在极端异常值比例下表现出鲁棒性。

Abstract: We address the correspondence-free alignment of two rotation sets on \(SO(3)\), a core task in calibration and registration that is often impeded by missing time alignment, outliers, and unknown axis conventions. Our key idea is to decompose each rotation into its \emph{Transformed Basis Vectors} (TBVs)-three unit vectors on \(S^2\)-and align the resulting spherical point sets per axis using fast, robust matchers (SPMC, FRS, and a hybrid). To handle axis relabels and sign flips, we introduce a \emph{Permutation-and-Sign Invariant} (PASI) wrapper that enumerates the 24 proper signed permutations, scores them via summed correlations, and fuses the per-axis estimates into a single rotation by projection/Karcher mean. The overall complexity remains linear in the number of rotations (\(\mathcal{O}(n)\)), contrasting with \(\mathcal{O}(N_r^3\log N_r)\) for spherical/\(SO(3)\) correlation. Experiments on EuRoC Machine Hall simulations
  (axis-consistent) and the ETH Hand-Eye benchmark (\texttt{robot\_arm\_real})
  (axis-ambiguous) show that our methods are accurate, 6-60x faster than traditional methods, and robust under extreme outlier ratios (up to 90\%), all without correspondence search.

</details>


### [416] [MS-PPO: Morphological-Symmetry-Equivariant Policy for Legged Robot Locomotion](https://arxiv.org/abs/2512.00727)
*Sizhe Wei,Xulin Chen,Fengze Xie,Garrett Ethan Katz,Zhenyu Gan,Lu Gan*

Main category: cs.RO

TL;DR: MS-PPO框架通过编码机器人形态对称性，显著提升了腿式机器人的运动控制性能和训练效率。


<details>
  <summary>Details</summary>
Motivation: 现有的强化学习策略架构通常忽略形态和对称性，导致训练效率低和泛化能力有限。

Method: 提出了MS-PPO框架，通过形态对称等变策略学习，将机器人运动学结构和形态对称性直接编码到策略网络中。

Result: MS-PPO在训练稳定性、对称性泛化能力和样本效率上优于现有基线，并在硬件部署中验证了其有效性。

Conclusion: 嵌入运动学结构和形态对称性到策略学习中，为腿式机器人运动控制提供了强大的归纳偏置。

Abstract: Reinforcement learning has recently enabled impressive locomotion capabilities on legged robots; however, most policy architectures remain morphology- and symmetry-agnostic, leading to inefficient training and limited generalization. This work introduces MS-PPO, a morphological-symmetry-equivariant policy learning framework that encodes robot kinematic structure and morphological symmetries directly into the policy network. We construct a morphology-informed graph neural architecture that is provably equivariant with respect to the robot's morphological symmetry group actions, ensuring consistent policy responses under symmetric states while maintaining invariance in value estimation. This design eliminates the need for tedious reward shaping or costly data augmentation, which are typically required to enforce symmetry. We evaluate MS-PPO in simulation on Unitree Go2 and Xiaomi CyberDog2 robots across diverse locomotion tasks, including trotting, pronking, slope walking, and bipedal turning, and further deploy the learned policies on hardware. Extensive experiments show that MS-PPO achieves superior training stability, symmetry generalization ability, and sample efficiency in challenging locomotion tasks, compared to state-of-the-art baselines. These findings demonstrate that embedding both kinematic structure and morphological symmetry into policy learning provides a powerful inductive bias for legged robot locomotion control. Our code will be made publicly available at https://lunarlab-gatech.github.io/MS-PPO/.

</details>


### [417] [SAGAS: Semantic-Aware Graph-Assisted Stitching for Offline Temporal Logic Planning](https://arxiv.org/abs/2512.00775)
*Ruijia Liu,Ancheng Hou,Shaoyuan Li,Xiang Yin*

Main category: cs.RO

TL;DR: SAGAS框架通过图辅助轨迹缝合和自动机引导规划，在离线无模型环境下有效解决了LTL约束控制问题。


<details>
  <summary>Details</summary>
Motivation: 现有LTL方法依赖精确动力学模型或昂贵的在线交互，难以应对离线、无模型环境下的挑战。

Method: 提出SAGAS框架，包括构建潜在可达性图、增强认证锚节点和概率软标签，将规范转换为Büchi自动机，并搜索隐式乘积空间以生成成本最小化的前缀-后缀计划。

Result: 在OGBench运动领域实验中，SAGAS成功为多样LTL任务合成了高效轨迹。

Conclusion: SAGAS框架成功地在离线、无模型环境下解决了LTL约束控制问题，通过结合图辅助轨迹缝合和自动机引导规划，有效连接了碎片化数据与复杂逻辑约束。

Abstract: Linear Temporal Logic (LTL) provides a rigorous framework for complex robotic tasks, yet existing methods often rely on accurate dynamics models or expensive online interactions. In this work, we address LTL-constrained control in a challenging offline, model-free setting, utilizing only fixed, task-agnostic datasets of fragmented trajectories. We propose SAGAS, a novel framework combining graph-assisted trajectory stitching with automata-guided planning. First, we construct a latent reachability graph from a learned temporal-distance representation. To bridge the semantic gap, we augment this graph with certified anchor nodes and probabilistic soft labels. We then translate the specification into a Büchi automaton and search the implicit product space to derive a cost-minimal prefix-suffix plan. Finally, a subgoal-conditioned low-level policy is deployed to execute these latent waypoints. Experiments on OGBench locomotion domains demonstrate that SAGAS successfully synthesizes efficient trajectories for diverse LTL tasks, effectively bridging the gap between fragmented offline data and complex logical constraints.

</details>


### [418] [Sign Language Recognition using Bidirectional Reservoir Computing](https://arxiv.org/abs/2512.00777)
*Nitin Kumar Singh,Arie Rachmad Syulistyo,Yuichiro Tanaka,Hakaru Tamukoh*

Main category: cs.RO

TL;DR: 提出了一种使用MediaPipe和ESN-based BRC架构的高效手语识别系统，适合边缘设备，训练时间短且准确率竞争性强。


<details>
  <summary>Details</summary>
Motivation: 深度学习在手语识别（SLR）中应用广泛，但计算资源需求高，不适合资源受限设备。

Method: 使用MediaPipe提取手部关节坐标，并将其输入到基于ESN的双向储备计算（BRC）架构中。BRC在前后两个方向处理这些特征，高效捕捉时间依赖性。BRC的最终状态被拼接以形成用于分类的鲁棒表示。

Result: 在WLASL视频数据集上，该方法取得了57.71%的准确率，训练时间仅为9秒，远低于基于Bi-GRU的深度学习方法的55分钟38秒。

Conclusion: 基于BRC的手语识别系统适合边缘设备使用。

Abstract: Sign language recognition (SLR) facilitates communication between deaf and hearing individuals. Deep learning is widely used to develop SLR-based systems; however, it is computationally intensive and requires substantial computational resources, making it unsuitable for resource-constrained devices. To address this, we propose an efficient sign language recognition system using MediaPipe and an echo state network (ESN)-based bidirectional reservoir computing (BRC) architecture. MediaPipe extracts hand joint coordinates, which serve as inputs to the ESN-based BRC architecture. The BRC processes these features in both forward and backward directions, efficiently capturing temporal dependencies. The resulting states of BRC are concatenated to form a robust representation for classification. We evaluated our method on the Word-Level American Sign Language (WLASL) video dataset, achieving a competitive accuracy of 57.71% and a significantly lower training time of only 9 seconds, in contrast to the 55 minutes and $38$ seconds required by the deep learning-based Bi-GRU approach. Consequently, the BRC-based SLR system is well-suited for edge devices.

</details>


### [419] [Transforming Monolithic Foundation Models into Embodied Multi-Agent Architectures for Human-Robot Collaboration](https://arxiv.org/abs/2512.00797)
*Nan Sun,Bo Mao,Yongchang Li,Chenxu Wang,Di Guo,Huaping Liu*

Main category: cs.RO

TL;DR: InteractGen is a multi-agent framework that enhances service robot autonomy by decomposing intelligence into specialized agents, outperforming monolithic models in task success and collaboration.


<details>
  <summary>Details</summary>
Motivation: The limitations of current foundation models, such as brittleness across embodiments, weak geometric grounding, and lack of proactive collaboration mechanisms, indicate that scaling a single model alone cannot deliver reliable autonomy for service robots in human-populated settings.

Method: InteractGen decomposes robot intelligence into specialized agents for continuous perception, dependency-aware planning, decision and verification, failure reflection, and dynamic human delegation, treating foundation models as regulated components within a closed-loop collective.

Result: InteractGen improves task success, adaptability, and human-robot collaboration when deployed on a heterogeneous robot team.

Conclusion: InteractGen, an LLM-powered multi-agent framework, demonstrates that multi-agent orchestration is a more feasible path toward socially grounded service autonomy than scaling standalone models, as evidenced by improved task success, adaptability, and human-robot collaboration in a three-month open-use study.

Abstract: Foundation models have become central to unifying perception and planning in robotics, yet real-world deployment exposes a mismatch between their monolithic assumption that a single model can handle all cognitive functions and the distributed, dynamic nature of practical service workflows. Vision-language models offer strong semantic understanding but lack embodiment-aware action capabilities while relying on hand-crafted skills. Vision-Language-Action policies enable reactive manipulation but remain brittle across embodiments, weak in geometric grounding, and devoid of proactive collaboration mechanisms. These limitations indicate that scaling a single model alone cannot deliver reliable autonomy for service robots operating in human-populated settings. To address this gap, we present InteractGen, an LLM-powered multi-agent framework that decomposes robot intelligence into specialized agents for continuous perception, dependency-aware planning, decision and verification, failure reflection, and dynamic human delegation, treating foundation models as regulated components within a closed-loop collective. Deployed on a heterogeneous robot team and evaluated in a three-month open-use study, InteractGen improves task success, adaptability, and human-robot collaboration, providing evidence that multi-agent orchestration offers a more feasible path toward socially grounded service autonomy than further scaling standalone models.

</details>


### [420] [A Novel MDP Decomposition Framework for Scalable UAV Mission Planning in Complex and Uncertain Environments](https://arxiv.org/abs/2512.00838)
*Md Muzakkir Quamar,Ali Nasir,Sami ELFerik*

Main category: cs.RO

TL;DR: 论文提出了一种可扩展的无人机任务管理框架，通过两阶段MDP分解策略显著提升计算效率，且不牺牲最优性。


<details>
  <summary>Details</summary>
Motivation: 为了解决大规模MDP在复杂和不确定环境中的计算瓶颈问题，提升无人机任务管理的可扩展性和容错性。

Method: 论文采用了两阶段分解策略：第一阶段通过基于因子的算法将全局MDP分解为更小的、目标特定的子MDP；第二阶段通过基于优先级的重组算法独立解决每个子MDP，并使用元策略进行冲突解决，最终整合为统一的全局策略。

Result: 大量模拟验证了该方法的有效性，计算时间显著减少，同时保持了任务可靠性和策略最优性。

Conclusion: 该论文提出了一个可扩展且容错的无人机任务管理框架，通过两阶段分解策略有效解决了大规模马尔可夫决策过程（MDP）的计算瓶颈，并在理论上证明了其全局等效性，为实时无人机任务执行提供了实用且稳健的决策基础。

Abstract: This paper presents a scalable and fault-tolerant framework for unmanned aerial vehicle (UAV) mission management in complex and uncertain environments. The proposed approach addresses the computational bottleneck inherent in solving large-scale Markov Decision Processes (MDPs) by introducing a two-stage decomposition strategy. In the first stage, a factor-based algorithm partitions the global MDP into smaller, goal-specific sub-MDPs by leveraging domain-specific features such as goal priority, fault states, spatial layout, and energy constraints. In the second stage, a priority-based recombination algorithm solves each sub-MDP independently and integrates the results into a unified global policy using a meta-policy for conflict resolution. Importantly, we present a theoretical analysis showing that, under mild probabilistic independence assumptions, the combined policy is provably equivalent to the optimal global MDP policy. Our work advances artificial intelligence (AI) decision scalability by decomposing large MDPs into tractable subproblems with provable global equivalence. The proposed decomposition framework enhances the scalability of Markov Decision Processes, a cornerstone of sequential decision-making in artificial intelligence, enabling real-time policy updates for complex mission environments. Extensive simulations validate the effectiveness of our method, demonstrating orders-of-magnitude reduction in computation time without sacrificing mission reliability or policy optimality. The proposed framework establishes a practical and robust foundation for scalable decision-making in real-time UAV mission execution.

</details>


### [421] [Magnetic Tactile-Driven Soft Actuator for Intelligent Grasping and Firmness Evaluation](https://arxiv.org/abs/2512.00907)
*Chengjin Du,Federico Bernabei,Zhengyin Du,Sergio Decherchi,Matteo Lo Preti,Lucia Beccai*

Main category: cs.RO

TL;DR: SoftMag是一种集成磁触觉传感器的软执行器，通过神经网络解耦恢复传感准确性，扩展为两指夹持器实现实时力/位置预测和硬度估计，验证了非破坏性质量评估能力。


<details>
  <summary>Details</summary>
Motivation: 软机器人在操纵精细物体方面具有优势，但缺乏集成的触觉传感和驱动器变形导致的信号失真限制了其应用。本文旨在解决这些问题。

Method: 论文提出了SoftMag执行器，结合了磁触觉传感器和软执行器，通过多物理场仿真框架建模机械寄生效应，并利用神经网络解耦策略消除寄生分量。实验包括压痕、准静态和步进驱动以及疲劳测试。

Result: 实验验证了SoftMag执行器的性能和解耦效果。两指夹持器实现了实时三轴力和位置的预测，并在杏子上验证了硬度估计的准确性（Pearson r超过0.8）。

Conclusion: 该论文提出了一种名为SoftMag的集成磁触觉传感器的软执行器，通过共享架构解决了传感与驱动分离的问题，并采用神经网络解耦策略恢复了传感的准确性。该系统进一步扩展为两指SoftMag夹持器，实现了实时三轴接触力和位置的预测，以及通过探测策略估计物体硬度。实验验证了其在非破坏性质量评估中的能力，为智能、材料感知机器人提供了新思路。

Abstract: Soft robots are powerful tools for manipulating delicate objects, yet their adoption is hindered by two gaps: the lack of integrated tactile sensing and sensor signal distortion caused by actuator deformations. This paper addresses these challenges by introducing the SoftMag actuator: a magnetic tactile-sensorized soft actuator. Unlike systems relying on attached sensors or treating sensing and actuation separately, SoftMag unifies them through a shared architecture while confronting the mechanical parasitic effect, where deformations corrupt tactile signals. A multiphysics simulation framework models this coupling, and a neural-network-based decoupling strategy removes the parasitic component, restoring sensing fidelity. Experiments including indentation, quasi-static and step actuation, and fatigue tests validate the actuator's performance and decoupling effectiveness. Building upon this foundation, the system is extended into a two-finger SoftMag gripper, where a multi-task neural network enables real-time prediction of tri-axial contact forces and position. Furthermore, a probing-based strategy estimates object firmness during grasping. Validation on apricots shows a strong correlation (Pearson r over 0.8) between gripper-estimated firmness and reference measurements, confirming the system's capability for non-destructive quality assessment. Results demonstrate that combining integrated magnetic sensing, learning-based correction, and real-time inference enables a soft robotic platform that adapts its grasp and quantifies material properties. The framework offers an approach for advancing sensorized soft actuators toward intelligent, material-aware robotics.

</details>


### [422] [Constant-Time Motion Planning with Manipulation Behaviors](https://arxiv.org/abs/2512.00939)
*Nayesha Gandotra,Itamar Mishani,Maxim Likhachev*

Main category: cs.RO

TL;DR: B-CTMP扩展了CTMP，通过预计算数据结构实现恒定时间查询，统一了无碰撞规划和物体操作，适用于半结构化环境。


<details>
  <summary>Details</summary>
Motivation: 现有CTMP方法未明确纳入物体操作所需的行为，因此提出B-CTMP以解决这一问题。

Method: B-CTMP通过预计算紧凑数据结构，确保在毫秒级时间内完成恒定时间查询，同时保证完整性和任务执行成功。

Result: 在仿真和真实机器人上验证了B-CTMP在货架拾取和插头插入等任务中的有效性。

Conclusion: B-CTMP成功地将无碰撞规划与物体操作统一在一个恒定时间框架内，为半结构化环境中的操作提供了速度和成功率的可证明保证。

Abstract: Recent progress in contact-rich robotic manipulation has been striking, yet most deployed systems remain confined to simple, scripted routines. One of the key barriers is the lack of motion planning algorithms that can provide verifiable guarantees for safety, efficiency and reliability. To address this, a family of algorithms called Constant-Time Motion Planning (CTMP) was introduced, which leverages a preprocessing phase to enable collision-free motion queries in a fixed, user-specified time budget (e.g., 10 milliseconds). However, existing CTMP methods do not explicitly incorporate the manipulation behaviors essential for object handling. To bridge this gap, we introduce the \textit{Behavioral Constant-Time Motion Planner} (B-CTMP), an algorithm that extends CTMP to solve a broad class of two-step manipulation tasks: (1) a collision-free motion to a behavior initiation state, followed by (2) execution of a manipulation behavior (such as grasping or insertion) to reach the goal. By precomputing compact data structures, B-CTMP guarantees constant-time query in mere milliseconds while ensuring completeness and successful task execution over a specified set of states. We evaluate B-CTMP on two canonical manipulation tasks in simulation, shelf picking and plug insertion,and demonstrate its effectiveness on a real robot. Our results show that B-CTMP unifies collision-free planning and object manipulation within a single constant-time framework, providing provable guarantees of speed and success for manipulation in semi-structured environments.

</details>


### [423] [H-Zero: Cross-Humanoid Locomotion Pretraining Enables Few-shot Novel Embodiment Transfer](https://arxiv.org/abs/2512.00971)
*Yunfeng Lin,Minghuan Liu,Yufei Xue,Ming Zhou,Yong Yu,Jiangmiao Pang,Weinan Zhang*

Main category: cs.RO

TL;DR: H-Zero通过预训练实现人形机器人控制器的通用化，支持零样本或少样本迁移到新平台，显著减少调参需求。


<details>
  <summary>Details</summary>
Motivation: 人形机器人技术的快速发展需要鲁棒且适应性强的控制器，但现有解决方案通常针对特定机器人设计，难以通用化。

Method: 提出了H-Zero，一个跨人形机器人运动预训练流程，学习通用的人形基础策略。

Result: 预训练策略在模拟环境中对未见过的机器人保持了81%的完整任务持续时间，且能在30分钟内通过少量微调适应新机器人或直立四足机器人。

Conclusion: H-Zero展示了在有限样本上预训练的策略能够实现零样本或少样本迁移到新的人形机器人，且只需少量微调即可适应新平台。

Abstract: The rapid advancement of humanoid robotics has intensified the need for robust and adaptable controllers to enable stable and efficient locomotion across diverse platforms. However, developing such controllers remains a significant challenge because existing solutions are tailored to specific robot designs, requiring extensive tuning of reward functions, physical parameters, and training hyperparameters for each embodiment. To address this challenge, we introduce H-Zero, a cross-humanoid locomotion pretraining pipeline that learns a generalizable humanoid base policy. We show that pretraining on a limited set of embodiments enables zero-shot and few-shot transfer to novel humanoid robots with minimal fine-tuning. Evaluations show that the pretrained policy maintains up to 81% of the full episode duration on unseen robots in simulation while enabling few-shot transfer to unseen humanoids and upright quadrupeds within 30 minutes of fine-tuning.

</details>


### [424] [FOM-Nav: Frontier-Object Maps for Object Goal Navigation](https://arxiv.org/abs/2512.01009)
*Thomas Chabal,Shizhe Chen,Jean Ponce,Cordelia Schmid*

Main category: cs.RO

TL;DR: FOM-Nav通过结合Frontier-Object Maps和视觉语言模型，解决了物体目标导航中的记忆和语义问题，在基准测试和真实机器人上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决物体目标导航问题中现有隐式记忆方法在长期记忆保留和规划上的不足，以及显式地图方法缺乏丰富语义信息的问题。

Method: 提出了FOM-Nav模块化框架，通过Frontier-Object Maps和视觉语言模型增强探索效率。Frontier-Object Maps在线构建，联合编码空间边界和细粒度对象信息。视觉语言模型执行多模态场景理解和高层目标预测，由低层规划器执行高效轨迹生成。

Result: FOM-Nav在MP3D和HM3D基准测试中表现优异，特别是在导航效率指标SPL上，并在真实机器人上展现了有希望的结果。

Conclusion: FOM-Nav在MP3D和HM3D基准测试中取得了最先进的性能，特别是在导航效率指标SPL上，并在真实机器人上展现了有希望的结果。

Abstract: This paper addresses the Object Goal Navigation problem, where a robot must efficiently find a target object in an unknown environment. Existing implicit memory-based methods struggle with long-term memory retention and planning, while explicit map-based approaches lack rich semantic information. To address these challenges, we propose FOM-Nav, a modular framework that enhances exploration efficiency through Frontier-Object Maps and vision-language models. Our Frontier-Object Maps are built online and jointly encode spatial frontiers and fine-grained object information. Using this representation, a vision-language model performs multimodal scene understanding and high-level goal prediction, which is executed by a low-level planner for efficient trajectory generation. To train FOM-Nav, we automatically construct large-scale navigation datasets from real-world scanned environments. Extensive experiments validate the effectiveness of our model design and constructed dataset. FOM-Nav achieves state-of-the-art performance on the MP3D and HM3D benchmarks, particularly in navigation efficiency metric SPL, and yields promising results on a real robot.

</details>


### [425] [Integration of UWB Radar on Mobile Robots for Continuous Obstacle and Environment Mapping](https://arxiv.org/abs/2512.01018)
*Adelina Giurea,Stijn Luchie,Dieter Coppens,Jeroen Hoebeke,Eli De Poorter*

Main category: cs.RO

TL;DR: 本文提出了一种基于UWB雷达的无基础设施障碍物检测和环境地图构建方法，适用于能见度差的动态环境，通过三步处理流程实现了高精度检测。


<details>
  <summary>Details</summary>
Motivation: 传统视觉摄像头和LiDAR在能见度差的环境（如黑暗、烟雾或反射表面）中失效，UWB雷达提供了有前景的替代方案。

Method: 提出了一种处理流程，包括目标识别（基于CIR峰值检测）、过滤（基于峰值属性、信噪比和相位差到达）和聚类（基于距离估计和到达角估计）。

Result: 所提方法成功减少了噪声和多径效应，在通道9上实现了至少82.36%的障碍物检测精度和89.46%的召回率，即使在检测低反射材料（如胶合板）时也表现良好。

Conclusion: 本研究为不依赖视觉特征和固定锚节点的UWB雷达定位与地图构建（SLAM）系统提供了基础，展示了在动态、无锚场景中UWB雷达的潜力。

Abstract: This paper presents an infrastructure-free approach for obstacle detection and environmental mapping using ultra-wideband (UWB) radar mounted on a mobile robotic platform. Traditional sensing modalities such as visual cameras and Light Detection and Ranging (LiDAR) fail in environments with poor visibility due to darkness, smoke, or reflective surfaces. In these visioned-impaired conditions, UWB radar offers a promising alternative. To this end, this work explores the suitability of robot-mounted UWB radar for environmental mapping in dynamic, anchor-free scenarios. The study investigates how different materials (metal, concrete and plywood) and UWB radio channels (5 and 9) influence the Channel Impulse Response (CIR). Furthermore, a processing pipeline is proposed to achieve reliable mapping of detected obstacles, consisting of 3 steps: (i) target identification (based on CIR peak detection), (ii) filtering (based on peak properties, signal-to-noise score, and phase-difference of arrival), and (iii) clustering (based on distance estimation and angle-of-arrival estimation). The proposed approach successfully reduces noise and multipath effects, resulting in an obstacle detection precision of at least 82.36% and a recall of 89.46% on channel 9 even when detecting low-reflective materials such as plywood. This work offers a foundation for further development of UWB-based localisation and mapping (SLAM) systems that do not rely on visual features and, unlike conventional UWB localisation systems, do not require on fixed anchor nodes for triangulation.

</details>


### [426] [CycleManip: Enabling Cyclic Task Manipulation via Effective Historical Perception and Understanding](https://arxiv.org/abs/2512.01022)
*Yi-Lin Wei,Haoran Liao,Yuhao Lin,Pengyue Wang,Zhizhao Liang,Guiliang Liu,Wei-Shi Zheng*

Main category: cs.RO

TL;DR: 本文提出CycleManip框架解决循环任务操作问题，通过改进历史感知与理解，实验验证其高效性与跨平台适应性。


<details>
  <summary>Details</summary>
Motivation: 循环任务操作在机器人领域尚未充分探索，现有方法在任务完成时间和历史利用上存在不足，且缺乏相关基准。

Method: 通过成本感知采样策略和多任务学习增强历史感知与理解，实现了端到端的模仿学习框架。

Result: 实验表明，CycleManip在仿真和现实环境中均取得高成功率，并展示了在通用操作中的适应性和即插即用能力。

Conclusion: 本文提出的CycleManip框架在循环任务操作中表现出色，不仅提高了任务完成率，还展示了跨平台适应性。

Abstract: In this paper, we explore an important yet underexplored task in robot manipulation: cycle-based manipulation, where robots need to perform cyclic or repetitive actions with an expected terminal time. These tasks are crucial in daily life, such as shaking a bottle or knocking a nail. However, few prior works have explored this task, leading to two main challenges: 1) the imitation methods often fail to complete these tasks within the expected terminal time due to the ineffective utilization of history; 2) the absence of a benchmark with sufficient data and automatic evaluation tools hinders development of effective solutions in this area. To address these challenges, we first propose the CycleManip framework to achieve cycle-based task manipulation in an end-to-end imitation manner without requiring any extra models, hierarchical structure or significant computational overhead. The core insight is to enhance effective history perception by a cost-aware sampling strategy and to improve historical understanding by multi-task learning. Second, we introduce a cycle-based task manipulation benchmark, which provides diverse cycle-based tasks, and an automatic evaluation method. Extensive experiments conducted in both simulation and real-world settings demonstrate that our method achieves high success rates in cycle-based task manipulation. The results further show strong adaptability performance in general manipulation, and the plug-and-play ability on imitation policies such as Vision-Language-Action (VLA) models. Moreover, the results show that our approach can be applied across diverse robotic platforms, including bi-arm grippers, dexterous hands, and humanoid robots.

</details>


### [427] [VLASH: Real-Time VLAs via Future-State-Aware Asynchronous Inference](https://arxiv.org/abs/2512.01031)
*Jiaming Tang,Yufei Sun,Yilong Zhao,Shang Yang,Yujun Lin,Zhuoyang Zhang,James Hou,Yao Lu,Zhijian Liu,Song Han*

Main category: cs.RO

TL;DR: VLASH是一个异步推理框架，解决了VLA模型实时控制中的延迟问题，显著提升速度与稳定性，适用于高精度任务。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作模型（VLAs）在实时控制中存在延迟和动作不稳定问题，异步推理虽能提升效率但会引入时间错位。

Method: VLASH通过预测执行时的状态，将机器人状态与先前生成的动作块向前滚动，以弥合预测与执行之间的时间差。

Result: 实验表明，VLASH比同步推理速度提升2.03倍，反应延迟降低17.4倍，且能处理高精度快速反应任务（如乒乓球和打地鼠）。

Conclusion: VLASH框架通过异步推理实现了连续、低延迟的机器人控制，显著提升了反应速度和稳定性，同时保持了原始准确性。

Abstract: Vision-Language-Action models (VLAs) are becoming increasingly capable across diverse robotic tasks. However, their real-world deployment remains slow and inefficient: demonstration videos are often sped up by 5-10x to appear smooth, with noticeable action stalls and delayed reactions to environmental changes. Asynchronous inference offers a promising solution to achieve continuous and low-latency control by enabling robots to execute actions and perform inference simultaneously. However, because the robot and environment continue to evolve during inference, a temporal misalignment arises between the prediction and execution intervals. This leads to significant action instability, while existing methods either degrade accuracy or introduce runtime overhead to mitigate it. We propose VLASH, a general asynchronous inference framework for VLAs that delivers smooth, accurate, and fast reaction control without additional overhead or architectural changes. VLASH estimates the future execution-time state by rolling the robot state forward with the previously generated action chunk, thereby bridging the gap between prediction and execution. Experiments show that VLASH achieves up to 2.03x speedup and reduces reaction latency by up to 17.4x compared to synchronous inference while fully preserving the original accuracy. Moreover, it empowers VLAs to handle fast-reaction, high-precision tasks such as playing ping-pong and playing whack-a-mole, where traditional synchronous inference fails. Code is available at https://github.com/mit-han-lab/vlash

</details>


### [428] [Autonomous Grasping On Quadruped Robot With Task Level Interaction](https://arxiv.org/abs/2512.01052)
*Muhtadin,Mochammad Hilmi Rusydiansyah,Mauridhi Hery Purnomo,I Ketut Eddy Purnama,Chastine Fatichah*

Main category: cs.RO

TL;DR: 本研究开发了一种基于任务级交互的四足机器人自主抓取系统，通过硬件集成和分层控制实现导航与抓取功能，测试显示75%的抓取成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的四足机器人主要关注移动性，缺乏物体操作能力。为四足机器人配备机械臂和夹爪在远程场景中引入手动控制的挑战。

Method: 研究包括在四足机器人上集成机械臂和夹爪的硬件、基于ROS的分层控制系统设计，以及用于人机交互的基于Web的界面。机器人能够使用GraspNet自主执行导航、物体检测和抓取任务。

Result: 机器人在12次试验中实现了75%的抓取成功率，能够准确执行导航、物体选择和抓取任务。

Conclusion: 该系统展示了四足机器人作为服务机器人在现实环境中的潜力，能够准确且一致地完成任务。

Abstract: Quadruped robots are increasingly used in various applications due to their high mobility and ability to operate in diverse terrains. However, most available quadruped robots are primarily focused on mobility without object manipulation capabilities. Equipping a quadruped robot with a robotic arm and gripper introduces a challenge in manual control, especially in remote scenarios that require complex commands. This research aims to develop an autonomous grasping system on a quadruped robot using a task-level interaction approach. The system includes hardware integration of a robotic arm and gripper onto the quadruped robot's body, a layered control system designed using ROS, and a web-based interface for human-robot interaction. The robot is capable of autonomously performing tasks such as navigation, object detection, and grasping using GraspNet. Testing was conducted through real-world scenarios to evaluate navigation, object selection and grasping, and user experience. The results show that the robot can perform tasks accurately and consistently, achieving a grasping success rate of 75 % from 12 trials. Therefore, the system demonstrates significant potential in enhancing the capabilities of quadruped robots as service robots in real-world environments.

</details>


### [429] [Opening the Sim-to-Real Door for Humanoid Pixel-to-Action Policy Transfer](https://arxiv.org/abs/2512.01061)
*Haoru Xue,Tairan He,Zi Wang,Qingwei Ben,Wenli Xiao,Zhengyi Luo,Xingye Da,Fernando Castañeda,Guanya Shi,Shankar Sastry,Linxi "Jim" Fan,Yuke Zhu*

Main category: cs.RO

TL;DR: 论文提出一种教师-学生-自举学习框架，结合GRPO微调，实现了纯RGB感知下的人类机器人多样化关节操作，零样本性能优于人类操作员。


<details>
  <summary>Details</summary>
Motivation: 利用GPU加速的光照真实模拟为机器人学习提供可扩展的数据生成路径，通过大规模物理和视觉随机化使策略能够泛化到非精心设计的环境。

Method: 采用分阶段重置探索策略稳定长时特权策略训练，以及基于GRPO的微调程序减轻部分可观测性问题，提升仿真到现实强化学习的闭环一致性。

Result: 训练完全基于模拟数据的策略在多样化门类型上实现了稳健的零样本性能，任务完成时间比人类远程操作员快31.7%。

Conclusion: 该论文提出的基于教师-学生-自举学习框架和GRPO微调程序的方法，成功实现了在纯RGB感知下的人类机器人多样化关节操作，并在零样本情况下表现出色。

Abstract: Recent progress in GPU-accelerated, photorealistic simulation has opened a scalable data-generation path for robot learning, where massive physics and visual randomization allow policies to generalize beyond curated environments. Building on these advances, we develop a teacher-student-bootstrap learning framework for vision-based humanoid loco-manipulation, using articulated-object interaction as a representative high-difficulty benchmark. Our approach introduces a staged-reset exploration strategy that stabilizes long-horizon privileged-policy training, and a GRPO-based fine-tuning procedure that mitigates partial observability and improves closed-loop consistency in sim-to-real RL. Trained entirely on simulation data, the resulting policy achieves robust zero-shot performance across diverse door types and outperforms human teleoperators by up to 31.7% in task completion time under the same whole-body control stack. This represents the first humanoid sim-to-real policy capable of diverse articulated loco-manipulation using pure RGB perception.

</details>


### [430] [Reinforcement Learning for Gliding Projectile Guidance and Control](https://arxiv.org/abs/2512.01066)
*Joel Cahn,Antonin Thomas,Philippe Pastor*

Main category: cs.RO

TL;DR: 论文提出了一种基于强化学习的控制律，用于光学引导滑翔机，旨在实现动态环境中的高精度目标跟踪，并验证其在固定翼飞机上的适用性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在证明强化学习不仅适用于四旋翼无人机，还能扩展到固定翼飞机的所有轴上，实现更广泛的应用。

Method: 采用强化学习方法开发控制律，旨在提升光学引导滑翔机的导航灵活性和自主性。

Result: 控制律在动态环境中有效，能够高精度地跟踪目标并引导滑翔机至目标点。

Conclusion: 该论文通过强化学习方法成功开发了一种适用于固定翼飞机所有轴的控制律，展示了其在动态环境中实现高精度目标跟踪的潜力。

Abstract: This paper presents the development of a control law, which is intended to be implemented on an optical guided glider. This guiding law follows an innovative approach, the reinforcement learning. This control law is used to make navigation more flexible and autonomous in a dynamic environment. The final objective is to track a target detected with the camera and then guide the glider to this point with high precision. Already applied on quad-copter drones, we wish by this study to demonstrate the applicability of reinforcement learning for fixed-wing aircraft on all of its axis.

</details>


### [431] [Estimation of Kinematic Motion from Dashcam Footage](https://arxiv.org/abs/2512.01104)
*Evelyn Zhang,Alex Richardson,Jonathan Sprinkle*

Main category: cs.RO

TL;DR: 论文通过车载数据和同步摄像头开发了预测车辆运动的神经网络模型，并提供了开源工具供其他研究者复现实验。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是探索仪表盘摄像头在预测类车车辆实际运动学运动中的准确性，为自动驾驶和车辆安全领域提供实用的数据和方法。

Method: 论文采用的方法是利用车辆的车载数据流（通过控制器区域网络）和时间同步的仪表盘摄像头，收集了18小时的驾驶数据，并开发了神经网络模型来预测车辆速度、偏航角、前车存在及其相对距离和速度。

Result: 论文的结果包括开发的神经网络模型能够准确预测车辆速度、偏航角、前车存在及其相对距离和速度，并提供了数据收集和实验复现的开源工具和方法。

Conclusion: 论文得出结论，通过结合车载数据流和同步仪表盘摄像头，可以有效地预测车辆的动态运动，并为其他研究人员提供了使用开源工具和现成技术进行类似实验的方法。

Abstract: The goal of this paper is to explore the accuracy of dashcam footage to predict the actual kinematic motion of a car-like vehicle. Our approach uses ground truth information from the vehicle's on-board data stream, through the controller area network, and a time-synchronized dashboard camera, mounted to a consumer-grade vehicle, for 18 hours of footage and driving. The contributions of the paper include neural network models that allow us to quantify the accuracy of predicting the vehicle speed and yaw, as well as the presence of a lead vehicle, and its relative distance and speed. In addition, the paper describes how other researchers can gather their own data to perform similar experiments, using open-source tools and off-the-shelf technology.

</details>


### [432] [Supporting Productivity Skill Development in College Students through Social Robot Coaching: A Proof-of-Concept](https://arxiv.org/abs/2512.01105)
*Himanshi Lalwani,Hanan Salam*

Main category: cs.RO

TL;DR: SAR作为教育教练，通过互动课程和个性化反馈，有效提升大学生生产力，弥补现有工具的不足。


<details>
  <summary>Details</summary>
Motivation: Existing self-help books and productivity apps have limitations in interactivity and educational value, while traditional coaching is resource-intensive. SAR aims to bridge these gaps.

Method: The study introduced a socially assistive robot (SAR) delivering six lessons on time management and task prioritization, with interactive chat and speech responses, plus an integrated dashboard for progress tracking and personalized insights.

Result: Evaluation with 15 college students showed a System Usability Score of 79.2, high ratings for experience and engagement, indicating SAR's potential.

Conclusion: SAR-based productivity coaching is an effective and scalable solution to improve college students' productivity.

Abstract: College students often face academic challenges that hamper their productivity and well-being. Although self-help books and productivity apps are popular, they often fall short. Books provide generalized, non-interactive guidance, and apps are not inherently educational and can hinder the development of key organizational skills. Traditional productivity coaching offers personalized support, but is resource-intensive and difficult to scale. In this study, we present a proof-of-concept for a socially assistive robot (SAR) as an educational coach and a potential solution to the limitations of existing productivity tools and coaching approaches. The SAR delivers six different lessons on time management and task prioritization. Users interact via a chat interface, while the SAR responds through speech (with a toggle option). An integrated dashboard monitors progress, mood, engagement, confidence per lesson, and time spent per lesson. It also offers personalized productivity insights to foster reflection and self-awareness. We evaluated the system with 15 college students, achieving a System Usability Score of 79.2 and high ratings for overall experience and engagement. Our findings suggest that SAR-based productivity coaching can offer an effective and scalable solution to improve productivity among college students.

</details>


### [433] [Tactile Robotics: Past and Future](https://arxiv.org/abs/2512.01106)
*Nathan F. Lepora*

Main category: cs.RO

TL;DR: 本文回顾了触觉机器人技术的历史发展，并展望了其未来可能的应用方向，特别是在商业领域的广泛应用。


<details>
  <summary>Details</summary>
Motivation: 为了帮助定义触觉机器人技术的未来，本文通过历史视角和专家意见，梳理了触觉传感在机器人领域的发展历程。

Method: 文章基于近150篇综述，跨越近半个世纪的历史，将触觉机器人技术分为四个世代：1965-79（起源）、1980-94（基础与成长）、1995-2009（触觉寒冬）和2010-2024（扩张与多样化）。

Result: 最近的扩张导致了多样化的主题出现，如电子皮肤、触觉机器人手、基于视觉的触觉传感、软/仿生触觉和触觉互联网。

Conclusion: 本文通过历史视角分析了触觉机器人技术的未来，强调了从2025年开始触觉机器人可能成熟并广泛应用于商业领域，特别是在人类般的灵巧性、理解人类智能和远程呈现等方面。

Abstract: What is the future of tactile robotics? To help define that future, this article provides a historical perspective on tactile sensing in robotics from the wealth of knowledge and expert opinion in nearly 150 reviews over almost half a century. This history is characterized by a succession of generations: 1965-79 (origins), 1980-94 (foundations and growth), 1995-2009 (tactile winter) and 2010-2024 (expansion and diversification). Recent expansion has led to diverse themes emerging of e-skins, tactile robotic hands, vision-based tactile sensing, soft/biomimetic touch, and the tactile Internet. In the next generation from 2025, tactile robotics could mature to widespread commercial use, with applications in human-like dexterity, understanding human intelligence, and telepresence impacting all robotics and AI. By linking past expert insights to present themes, this article highlights recurring challenges in tactile robotics, showing how the field has evolved, why progress has often stalled, and which opportunities are most likely to define its future.

</details>


### [434] [Think Fast: Real-Time Kinodynamic Belief-Space Planning for Projectile Interception](https://arxiv.org/abs/2512.01108)
*Gabriel Olin,Lu Chen,Nayesha Gandotra,Maxim Likhachev,Howie Choset*

Main category: cs.RO

TL;DR: 提出树状结构规划方法，结合RIAE-AKF滤波器，实现在噪声环境下对快速移动目标的实时拦截，实验验证有效。


<details>
  <summary>Details</summary>
Motivation: 快速移动目标的拦截因时间紧迫和传感器噪声导致的信息不完整而极具挑战性，需在持续接收信息的同时实时规划拦截路径。

Method: 采用状态-时间空间中的动力学运动基元构建树状结构，支持多目标可达性编码和实时值更新，结合RIAE-AKF滤波器进行目标跟踪与置信度更新。

Result: 在ABB IRB-1600机械臂和ZED 2i立体相机的实验平台上，该方法成功实现了对快速移动目标的实时拦截。

Conclusion: 论文提出了一种基于树状结构的实时规划方法，能够在传感器噪声环境下高效拦截快速移动目标，并通过实验验证了其在6自由度工业机械臂上的有效性。

Abstract: Intercepting fast moving objects, by its very nature, is challenging because of its tight time constraints. This problem becomes further complicated in the presence of sensor noise because noisy sensors provide, at best, incomplete information, which results in a distribution over target states to be intercepted. Since time is of the essence, to hit the target, the planner must begin directing the interceptor, in this case a robot arm, while still receiving information. We introduce an tree-like structure, which is grown using kinodynamic motion primitives in state-time space. This tree-like structure encodes reachability to multiple goals from a single origin, while enabling real-time value updates as the target belief evolves and seamless transitions between goals. We evaluate our framework on an interception task on a 6 DOF industrial arm (ABB IRB-1600) with an onboard stereo camera (ZED 2i). A robust Innovation-based Adaptive Estimation Adaptive Kalman Filter (RIAE-AKF) is used to track the target and perform belief updates.

</details>


### [435] [Ethically-Aware Participatory Design of a Productivity Social Robot for College Students](https://arxiv.org/abs/2512.01111)
*Himanshi Lalwani,Hanan Salam*

Main category: cs.RO

TL;DR: 通过参与式设计，研究为ADHD学生开发了生产力支持型SAR，提出设计偏好和伦理指南。


<details>
  <summary>Details</summary>
Motivation: 传统生产力工具依赖持续自律，对ADHD学生等群体效果有限，而SAR因其互动性有望成为更有效的替代方案。

Method: 采用参与式设计（PD）方法，通过访谈和协作研讨会直接与学生及成功教练合作，收集生产力挑战和SAR设计偏好。

Result: 研究总结了学生生产力挑战、SAR设计偏好、有效机器人特征建议，并制定了利益相关者驱动的伦理指南。

Conclusion: 本研究通过参与式设计方法，为高校学生（尤其是ADHD学生）开发了生产力支持型社交辅助机器人（SAR），并提出了伦理指南以指导未来在高等教育中的负责任实施。

Abstract: College students often face academic and life stressors affecting productivity, especially students with Attention Deficit Hyperactivity Disorder (ADHD) who experience executive functioning challenges. Conventional productivity tools typically demand sustained self-discipline and consistent use, which many students struggle with, leading to disruptive app-switching behaviors. Socially Assistive Robots (SARs), known for their intuitive and interactive nature, offer promising potential to support productivity in academic environments, having been successfully utilized in domains like education, cognitive development, and mental health. To leverage SARs effectively in addressing student productivity, this study employed a Participatory Design (PD) approach, directly involving college students and a Student Success and Well-Being Coach in the design process. Through interviews and a collaborative workshop, we gathered detailed insights on productivity challenges and identified desirable features for a productivity-focused SAR. Importantly, ethical considerations were integrated from the onset, facilitating responsible and user-aligned design choices. Our contributions include comprehensive insights into student productivity challenges, SAR design preferences, and actionable recommendations for effective robot characteristics. Additionally, we present stakeholder-derived ethical guidelines to inform responsible future implementations of productivity-focused SARs in higher education.

</details>


### [436] [Real-World Reinforcement Learning of Active Perception Behaviors](https://arxiv.org/abs/2512.01188)
*Edward S. Hu,Jie Wang,Xingfang Yuan,Fiona Luo,Muyao Li,Gaspard Lambrechts,Oleh Rybkin,Dinesh Jayaraman*

Main category: cs.RO

TL;DR: AAWR通过特权传感器数据训练主动感知策略，显著提升机器人在部分可观测环境下的任务表现。


<details>
  <summary>Details</summary>
Motivation: 机器人的即时感官观察通常无法完全揭示任务相关状态信息，导致标准机器人学习技术在主动感知行为训练上表现不佳。

Method: AAWR（非对称优势加权回归）利用训练时可用的特权传感器数据，训练高质量的特权价值函数，以辅助目标策略的优势估计。方法从小规模次优演示和易于获取的粗略策略初始化开始，快速学习主动感知行为。

Result: 在8个不同部分可观测程度的机器人操作任务评估中，AAWR生成的主动感知行为优于所有现有方法，并能有效应对严重部分可观测的挑战。

Conclusion: AAWR方法通过利用训练时的特权传感器数据，成功训练出高效的主动感知策略，显著提升了机器人在部分可观测环境下的任务表现。

Abstract: A robot's instantaneous sensory observations do not always reveal task-relevant state information. Under such partial observability, optimal behavior typically involves explicitly acting to gain the missing information. Today's standard robot learning techniques struggle to produce such active perception behaviors. We propose a simple real-world robot learning recipe to efficiently train active perception policies. Our approach, asymmetric advantage weighted regression (AAWR), exploits access to "privileged" extra sensors at training time. The privileged sensors enable training high-quality privileged value functions that aid in estimating the advantage of the target policy. Bootstrapping from a small number of potentially suboptimal demonstrations and an easy-to-obtain coarse policy initialization, AAWR quickly acquires active perception behaviors and boosts task performance. In evaluations on 8 manipulation tasks on 3 robots spanning varying degrees of partial observability, AAWR synthesizes reliable active perception behaviors that outperform all prior approaches. When initialized with a "generalist" robot policy that struggles with active perception tasks, AAWR efficiently generates information-gathering behaviors that allow it to operate under severe partial observability for manipulation tasks. Website: https://penn-pal-lab.github.io/aawr/

</details>


### [437] [RoboLoc: A Benchmark Dataset for Point Place Recognition and Localization in Indoor-Outdoor Integrated Environments](https://arxiv.org/abs/2512.01194)
*Jaejin Jeon,Seonghoon Ryoo,Sang-Duck Lee,Soomok Lee,Seungwoo Jeong*

Main category: cs.RO

TL;DR: RoboLoc是一个针对室内外环境设计的LiDAR基准数据集，用于无GPS定位，评估了多种先进模型的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有LiDAR数据集多集中于室外场景，缺乏室内外域的无缝转换，难以满足复杂环境下的可靠定位需求。

Method: 提出了RoboLoc基准数据集，包含真实机器人轨迹、多样化高程剖面以及室内外域的无缝转换。

Result: 评估了多种先进模型（点基、体素基和BEV基架构），展示了它们在域转换中的泛化能力。

Conclusion: RoboLoc数据集为机器人和自主导航领域提供了多域定位系统的真实测试平台。

Abstract: Robust place recognition is essential for reliable localization in robotics, particularly in complex environments with fre- quent indoor-outdoor transitions. However, existing LiDAR-based datasets often focus on outdoor scenarios and lack seamless domain shifts. In this paper, we propose RoboLoc, a benchmark dataset designed for GPS-free place recognition in indoor-outdoor environments with floor transitions. RoboLoc features real-world robot trajectories, diverse elevation profiles, and transitions between structured indoor and unstructured outdoor domains. We benchmark a variety of state-of-the-art models, point-based, voxel-based, and BEV-based architectures, highlighting their generalizability domain shifts. RoboLoc provides a realistic testbed for developing multi-domain localization systems in robotics and autonomous navigation

</details>


### [438] [COMET: A Dual Swashplate Autonomous Coaxial Bi-copter AAV with High-Maneuverability and Long-Endurance](https://arxiv.org/abs/2512.01246)
*Shuai Wang,Xiaoming Tang,Junning Liang,Haowen Zheng,Biyu Ye,Zhaofeng Liu,Fei Gao,Ximin Lyu*

Main category: cs.RO

TL;DR: COMET是一种采用双旋翼盘机制的同轴双旋翼AAV平台，通过优化设计验证了其在效率、机动性和紧凑性上的优势。


<details>
  <summary>Details</summary>
Motivation: 同轴双旋翼自主飞行器（AAV）因潜在的转子系统效率提升和紧凑外形而受到关注，但平衡效率、机动性和紧凑性仍是关键设计挑战。

Method: 通过台架测试优化双旋翼盘系统的效率和紧凑性，并通过飞行续航实验验证原型机在不同负载条件下的效率和鲁棒性。

Result: 双旋翼盘配置提升了跟踪性能并提高了飞行效率，成功完成了多种场景的自主飞行试验。

Conclusion: COMET的双旋翼盘配置在跟踪性能和飞行效率上优于单旋翼盘方案，成功验证了其在实际应用中的潜力。

Abstract: Coaxial bi-copter autonomous aerial vehicles (AAVs) have garnered attention due to their potential for improved rotor system efficiency and compact form factor. However, balancing efficiency, maneuverability, and compactness in coaxial bi-copter systems remains a key design challenge, limiting their practical deployment. This letter introduces COMET, a coaxial bi-copter AAV platform featuring a dual swashplate mechanism. The coaxial bi-copter system's efficiency and compactness are optimized through bench tests, and the whole prototype's efficiency and robustness under varying payload conditions are verified through flight endurance experiments. The maneuverability performance of the system is evaluated in comprehensive trajectory tracking tests. The results indicate that the dual swashplate configuration enhances tracking performance and improves flight efficiency compared to the single swashplate alternative. Successful autonomous flight trials across various scenarios verify COMET's potential for real-world applications.

</details>


### [439] [Visibility-aware Cooperative Aerial Tracking with Decentralized LiDAR-based Swarms](https://arxiv.org/abs/2512.01280)
*Longji Yin,Yunfan Ren,Fangcheng Zhu,Liuyu Shi,Fanze Kong,Benxu Tang,Wenyi Liu,Ximin Lyu,Fu Zhang*

Main category: cs.RO

TL;DR: 论文提出了一种去中心化LiDAR群体跟踪框架，通过SSDF和FOV对齐优化可见性和协作，实验验证了其在复杂环境中的有效性。


<details>
  <summary>Details</summary>
Motivation: 群体目标跟踪在分布式感知、容错冗余和多方向目标覆盖方面具有独特优势，但目前研究不足。

Method: 论文引入了一种基于球形有符号距离场（SSDF）的3D环境遮挡表示度量，以及支持异构LiDAR配置的通用视场（FOV）对齐成本。群体协调通过协作成本增强，包括机器人间安全间距、防止相互遮挡以及通过新颖的静电势启发分布度量促进3D多方向目标包围。

Result: 在杂乱户外环境中的实际实验验证了系统对敏捷目标（无人机、人类）的鲁棒协作跟踪，并实现了卓越的可见性维护。

Conclusion: 论文提出了一种新颖的去中心化LiDAR群体跟踪框架，在复杂环境中实现了可见性感知和协作目标跟踪，充分利用了群体系统的独特能力。

Abstract: Autonomous aerial tracking with drones offers vast potential for surveillance, cinematography, and industrial inspection applications. While single-drone tracking systems have been extensively studied, swarm-based target tracking remains underexplored, despite its unique advantages of distributed perception, fault-tolerant redundancy, and multidirectional target coverage. To bridge this gap, we propose a novel decentralized LiDAR-based swarm tracking framework that enables visibility-aware, cooperative target tracking in complex environments, while fully harnessing the unique capabilities of swarm systems. To address visibility, we introduce a novel Spherical Signed Distance Field (SSDF)-based metric for 3-D environmental occlusion representation, coupled with an efficient algorithm that enables real-time onboard SSDF updating. A general Field-of-View (FOV) alignment cost supporting heterogeneous LiDAR configurations is proposed for consistent target observation. Swarm coordination is enhanced through cooperative costs that enforce inter-robot safe clearance, prevent mutual occlusions, and notably facilitate 3-D multidirectional target encirclement via a novel electrostatic-potential-inspired distribution metric. These innovations are integrated into a hierarchical planner, combining a kinodynamic front-end searcher with a spatiotemporal $SE(3)$ back-end optimizer to generate collision-free, visibility-optimized trajectories.Deployed on heterogeneous LiDAR swarms, our fully decentralized implementation features collaborative perception, distributed planning, and dynamic swarm reconfigurability. Validated through rigorous real-world experiments in cluttered outdoor environments, the proposed system demonstrates robust cooperative tracking of agile targets (drones, humans) while achieving superior visibility maintenance.

</details>


### [440] [Discovering Self-Protective Falling Policy for Humanoid Robot via Deep Reinforcement Learning](https://arxiv.org/abs/2512.01336)
*Diyuan Shi,Shangke Lyu,Donglin Wang*

Main category: cs.RO

TL;DR: 本研究利用深度强化学习和课程学习，训练人形机器人形成“三角形”结构以减少跌倒损伤，并在实验中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于人形机器人的形态、动力学和控制策略的限制，与其他形态（如四足或轮式机器人）相比，人形机器人更容易跌倒，且其大重量、高重心和多自由度会导致严重的硬件损坏。现有研究多依赖控制方法，难以适应多样化的跌倒场景。

Method: 采用大规模深度强化学习和课程学习，激励人形机器人发现适合其自身特性和属性的跌倒保护策略。

Result: 通过综合指标和实验，量化了该方法的性能，并与其他方法进行了比较，可视化其跌倒行为，并成功将其转移到真实世界平台。

Conclusion: 通过精心设计的奖励函数和领域多样化课程，本研究成功训练人形机器人探索跌倒保护行为，并发现通过形成“三角形”结构，可以显著减少其刚性材料身体的跌倒损伤。

Abstract: Humanoid robots have received significant research interests and advancements in recent years. Despite many successes, due to their morphology, dynamics and limitation of control policy, humanoid robots are prone to fall as compared to other embodiments like quadruped or wheeled robots. And its large weight, tall Center of Mass, high Degree-of-Freedom would cause serious hardware damages when falling uncontrolled, to both itself and surrounding objects. Existing researches in this field mostly focus on using control based methods that struggle to cater diverse falling scenarios and may introduce unsuitable human prior. On the other hand, large-scale Deep Reinforcement Learning and Curriculum Learning could be employed to incentivize humanoid agent discovering falling protection policy that fits its own nature and property. In this work, with carefully designed reward functions and domain diversification curriculum, we successfully train humanoid agent to explore falling protection behaviors and discover that by forming a `triangle' structure, the falling damages could be significantly reduced with its rigid-material body. With comprehensive metrics and experiments, we quantify its performance with comparison to other methods, visualize its falling behaviors and successfully transfer it to real world platform.

</details>


### [441] [Modality-Augmented Fine-Tuning of Foundation Robot Policies for Cross-Embodiment Manipulation on GR1 and G1](https://arxiv.org/abs/2512.01358)
*Junsung Park,Hogun Kee,Songhwai Oh*

Main category: cs.RO

TL;DR: 本文提出模态增强微调框架，显著提升不同人形机器人策略性能，GR1和Unitree G1分别通过轻量后处理和高质多模态数据实现成功迁移。


<details>
  <summary>Details</summary>
Motivation: 为了适应不同人形机器人的多样化体现，需要一种能够增强基础机器人策略的通用方法。

Method: 提出了模态增强的微调框架，并在GR1和Unitree G1两种人形机器人上进行了验证。GR1使用了公开数据集并引入后处理模态（如二进制接触信号和ZoeDepth生成的度量深度），而Unitree G1则贡献了一个新的多模态数据集，包含cuRobo运动规划、逆运动学和地面真实接触力测量。

Result: 模态增强显著提升了策略性能：GR1的在线成功率从51%提升到63%；Unitree G1的“Pick Apple to Bowl”任务中，接触增强模型的成功率达到94%，远超标准微调的48%和零样本迁移的0%。

Conclusion: 本文通过模态增强的微调框架，为不同人形机器人提供了统一的、以数据为中心的扩展路径，证明了目标模态设计和多模态微调的有效性。

Abstract: This paper presents a modality-augmented fine-tuning framework designed to adapt foundation robot policies to diverse humanoid embodiments. We validate our approach across two distinct settings: (i) the GR1 embodiment, utilizing public datasets where we introduce post-processed modalities, including binary contact signals and ZoeDepth-generated metric depth; and (ii) the Unitree G1 embodiment, for which we contribute a novel multi-modal dataset incorporating cuRobo motion planning, inverse kinematics, and ground-truth contact-force measurements. Our experiments demonstrate that modality augmentation consistently enhances policy performance across different embodiments. Specifically, for the GR1, integrating contact-state cues and RGB-D fusion improves online success rates from 51% to 63%. Furthermore, in the G1 "Pick Apple to Bowl" task, our contact-augmented model achieves a success rate of 94%, significantly outperforming the 48% achieved by standard fine-tuning and the 0% baseline of zero-shot transfer. These results highlight that lightweight post-processing effectively strengthens policies for GR1, while high-quality multi-modal data is crucial for reliable transfer to the Unitree G1. Consequently, this work establishes a unified, data-centric pathway for extending foundation robot policies through targeted modality design and multi-modal fine-tuning.

</details>


### [442] [$\mathbf{M^3A}$ Policy: Mutable Material Manipulation Augmentation Policy through Photometric Re-rendering](https://arxiv.org/abs/2512.01446)
*Jiayi Li,Yuxuan Hu,Haoran Geng,Xiangyu Chen,Chuhao Zhou,Ziteng Cui,Jianfei Yang*

Main category: cs.RO

TL;DR: M$^3$A框架通过光度重渲染单次演示生成多样化材料属性，显著提升跨材料泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法因模拟材料与真实视觉域差距大或需大量真实演示而难以覆盖多样材料的问题。

Method: 提出Mutable Material Manipulation Augmentation (M$^3$A)框架，利用光传输对单次真实演示进行光度重渲染，生成多样化的材料属性演示。

Result: M$^3$A策略将三个真实任务的跨材料泛化平均成功率提升58.03%，并在未见材料上表现鲁棒。

Conclusion: M$^3$A框架通过光传输捕捉材料的物理特性进行光度重渲染，显著提升了跨材料泛化能力，在未见材料上表现出鲁棒性能。

Abstract: Material generalization is essential for real-world robotic manipulation, where robots must interact with objects exhibiting diverse visual and physical properties. This challenge is particularly pronounced for objects made of glass, metal, or other materials whose transparent or reflective surfaces introduce severe out-of-distribution variations. Existing approaches either rely on simulated materials in simulators and perform sim-to-real transfer, which is hindered by substantial visual domain gaps, or depend on collecting extensive real-world demonstrations, which is costly, time-consuming, and still insufficient to cover various materials. To overcome these limitations, we resort to computational photography and introduce Mutable Material Manipulation Augmentation (M$^3$A), a unified framework that leverages the physical characteristics of materials as captured by light transport for photometric re-rendering. The core idea is simple yet powerful: given a single real-world demonstration, we photometrically re-render the scene to generate a diverse set of highly realistic demonstrations with different material properties. This augmentation effectively decouples task-specific manipulation skills from surface appearance, enabling policies to generalize across materials without additional data collection. To systematically evaluate this capability, we construct the first comprehensive multi-material manipulation benchmark spanning both simulation and real-world environments. Extensive experiments show that the M$^3$A policy significantly enhances cross-material generalization, improving the average success rate across three real-world tasks by 58.03\%, and demonstrating robust performance on previously unseen materials.

</details>


### [443] [NavForesee: A Unified Vision-Language World Model for Hierarchical Planning and Dual-Horizon Navigation Prediction](https://arxiv.org/abs/2512.01550)
*Fei Liu,Shichao Xie,Minghua Luo,Zedong Chu,Junjun Hu,Xiaolong Wu,Mu Xu*

Main category: cs.RO

TL;DR: NavForesee是一种新型视觉语言模型，通过结合语言规划和预测性世界模型，显著提升了具身导航任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的代理在未见环境中进行稳健的长期规划时表现不佳，导致高失败率。为解决这一问题，提出了NavForesee。

Method: NavForesee是一种新型的视觉语言模型（VLM），将高级语言规划和预测性世界模型想象统一在一个框架内。该模型能够同时执行任务分解、进度跟踪、子目标制定以及短期环境动态和长期导航里程碑的预测。

Result: 在R2R-CE和RxR-CE基准测试中，NavForesee在复杂场景中表现出极具竞争力的性能。

Conclusion: NavForesee通过将显式语言规划与隐式时空预测融合，展示了更智能、更强大的具身代理的巨大潜力。

Abstract: Embodied navigation for long-horizon tasks, guided by complex natural language instructions, remains a formidable challenge in artificial intelligence. Existing agents often struggle with robust long-term planning about unseen environments, leading to high failure rates. To address these limitations, we introduce NavForesee, a novel Vision-Language Model (VLM) that unifies high-level language planning and predictive world model imagination within a single, unified framework. Our approach empowers a single VLM to concurrently perform planning and predictive foresight. Conditioned on the full instruction and historical observations, the model is trained to understand the navigation instructions by decomposing the task, tracking its progress, and formulating the subsequent sub-goal. Simultaneously, it functions as a generative world model, providing crucial foresight by predicting short-term environmental dynamics and long-term navigation milestones. The VLM's structured plan guides its targeted prediction, while the imagined future provides rich context to inform the navigation actions, creating a powerful internal feedback loop of perception-planning/prediction-action. We demonstrate through extensive experiments on the R2R-CE and RxR-CE benchmark that NavForesee achieves highly competitive performance in complex scenarios. Our work highlights the immense potential of fusing explicit language planning with implicit spatiotemporal prediction, paving the way for more intelligent and capable embodied agents.

</details>


### [444] [L2M-Calib: One-key Calibration Method for LiDAR and Multiple Magnetic Sensors](https://arxiv.org/abs/2512.01554)
*Qiyang Lyu,Wei Wang,Zhenyu Wu,Hongming Shen,Huiqin Zhou,Danwei Wang*

Main category: cs.RO

TL;DR: L2M-Calib是一种新型一键校准框架，用于磁-LiDAR融合系统，联合优化外参和内参，实验证明其高精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 磁传感器捕捉的环境磁场（AMF）模式具有几何、纹理、光照和天气不变性，适用于挑战性环境，但其在多模态系统中的集成因缺乏有效校准技术而未被充分探索。

Method: 采用迭代高斯-牛顿方案优化外参，内参校准则作为加权岭正则化总体最小二乘（w-RRTLS）问题处理，以增强对测量噪声和病态数据的鲁棒性。

Result: 在模拟数据集和真实实验（包括AGV-mounted传感器配置）上的广泛评估表明，该方法在各种环境和操作条件下均实现了高校准精度和鲁棒性。

Conclusion: L2M-Calib框架通过联合估计磁传感器与LiDAR之间的外参变换及磁传感器的内参畸变参数，实现了高精度和鲁棒性的校准，适用于各种环境和操作条件。

Abstract: Multimodal sensor fusion enables robust environmental perception by leveraging complementary information from heterogeneous sensing modalities. However, accurate calibration is a critical prerequisite for effective fusion. This paper proposes a novel one-key calibration framework named L2M-Calib for a fused magnetic-LiDAR system, jointly estimating the extrinsic transformation between the two kinds of sensors and the intrinsic distortion parameters of the magnetic sensors. Magnetic sensors capture ambient magnetic field (AMF) patterns, which are invariant to geometry, texture, illumination, and weather, making them suitable for challenging environments. Nonetheless, the integration of magnetic sensing into multimodal systems remains underexplored due to the absence of effective calibration techniques. To address this, we optimize extrinsic parameters using an iterative Gauss-Newton scheme, coupled with the intrinsic calibration as a weighted ridge-regularized total least squares (w-RRTLS) problem, ensuring robustness against measurement noise and ill-conditioned data. Extensive evaluations on both simulated datasets and real-world experiments, including AGV-mounted sensor configurations, demonstrate that our method achieves high calibration accuracy and robustness under various environmental and operational conditions.

</details>


### [445] [A Cross-Embodiment Gripper Benchmark for Rigid-Object Manipulation in Aerial and Industrial Robotics](https://arxiv.org/abs/2512.01598)
*Marek Vagas,Martin Varga,Jaroslav Romancik,Ondrej Majercak,Alejandro Suarez,Anibal Ollero,Bram Vanderborght,Ivan Virgala*

Main category: cs.RO

TL;DR: CEGB基准测试套件扩展了现有指标，评估夹爪的跨实施例转移和能量效率，实验证明其高效性和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试未能评估跨实施例可转移性或能量感知性能，这些对现代移动和空中操作至关重要。

Method: 引入CEGB基准测试套件，扩展YCB和NIST指标，包括转移时间、能耗和理想负载评估。

Result: 实验显示快速实施例转移（中位数约17.6秒）、低保持能量（约1.5 J/10秒）和一致的抓取性能（成功率超过90%）。

Conclusion: CEGB提供了一个可重复的基础，用于跨平台、能量感知的夹爪评估，适用于空中和操纵器领域。

Abstract: Robotic grippers are increasingly deployed across industrial, collaborative, and aerial platforms, where each embodiment imposes distinct mechanical, energetic, and operational constraints. Established YCB and NIST benchmarks quantify grasp success, force, or timing on a single platform, but do not evaluate cross-embodiment transferability or energy-aware performance, capabilities essential for modern mobile and aerial manipulation. This letter introduces the Cross-Embodiment Gripper Benchmark (CEGB), a compact and reproducible benchmarking suite extending YCB and selected NIST metrics with three additional components: a transfer-time benchmark measuring the practical effort required to exchange embodiments, an energy-consumption benchmark evaluating grasping and holding efficiency, and an intent-specific ideal payload assessment reflecting design-dependent operational capability. Together, these metrics characterize both grasp performance and the suitability of reusing a single gripper across heterogeneous robotic systems. A lightweight self-locking gripper prototype is implemented as a reference case. Experiments demonstrate rapid embodiment transfer (median ~= 17.6 s across user groups), low holding energy for gripper prototype (~= 1.5 J per 10 s), and consistent grasp performance with cycle times of 3.2 - 3.9 s and success rates exceeding 90%. CEGB thus provides a reproducible foundation for cross-platform, energy-aware evaluation of grippers in aerial and manipulators domains.

</details>


### [446] [Integrated YOLOP Perception and Lyapunov-based Control for Autonomous Mobile Robot Navigation on Track](https://arxiv.org/abs/2512.01608)
*Mo Chen*

Main category: cs.RO

TL;DR: 提出了一种结合多任务视觉感知和稳定跟踪控制器的实时自主轨道导航框架，适用于非完整差速驱动移动机器人，无需高清地图或卫星定位。


<details>
  <summary>Details</summary>
Motivation: 旨在为非完整差速驱动移动机器人提供一个实时自主轨道导航框架，无需依赖高清先验地图或全球卫星定位。

Method: 感知流程通过2D到3D相机投影、基于弧长的均匀点重采样和通过鲁棒QR最小二乘优化的三次多项式拟合重建车道中心线。控制器通过基于Lyapunov稳定性的设计调节机器人线速度和角速度。

Result: 实验验证了系统在动态和部分感知车道场景中的位置和航向偏差的渐近收敛性。

Conclusion: 该框架在嵌入式平台上通过真实世界实验验证了系统的可靠性、实时执行能力、轨迹平滑性和闭环稳定性，实现了可靠的自主导航。

Abstract: This work presents a real-time autonomous track navigation framework for nonholonomic differential-drive mobile robots by jointly integrating multi-task visual perception and a provably stable tracking controller. The perception pipeline reconstructs lane centerlines using 2D-to-3D camera projection, arc-length based uniform point resampling, and cubic polynomial fitting solved via robust QR least-squares optimization. The controller regulates robot linear and angular velocities through a Lyapunov-stability grounded design, ensuring bounded error dynamics and asymptotic convergence of position and heading deviations even in dynamic and partially perceived lane scenarios, without relying on HD prior maps or global satellite localization. Real-world experiments on embedded platforms verify system fidelity, real-time execution, trajectory smoothness, and closed-loop stability for reliable autonomous navigation.

</details>


### [447] [Dynamic Log-Gaussian Process Control Barrier Function for Safe Robotic Navigation in Dynamic Environments](https://arxiv.org/abs/2512.01668)
*Xin Yin,Chenyang Liang,Yanning Guo,Jie Mei*

Main category: cs.RO

TL;DR: 提出DLGP-CBF，通过高斯过程和对数变换实时构建信息丰富且动态敏感的屏障函数，显著提升动态避障性能。


<details>
  <summary>Details</summary>
Motivation: 在线合成信息丰富且能感知障碍物运动的CBF在未知和动态场景中仍具挑战性，因此提出DLGP-CBF以实时构建空间信息丰富且对障碍物运动敏感的CBF。

Method: 通过高斯过程回归的对数变换生成平滑且信息丰富的屏障值和梯度，并明确将DLGP-CBF建模为障碍物位置的函数，整合预测的障碍物速度，使控制器能主动响应动态障碍物运动。

Result: 仿真结果表明，相比基线方法，DLGP-CBF在避障性能上有显著提升，包括更高的安全裕度、更平滑的轨迹和更强的响应能力。

Conclusion: 论文提出了一种名为DLGP-CBF的新型高斯过程控制屏障函数，显著提升了动态障碍物避障性能，包括增加安全裕度、平滑轨迹和提高响应速度。

Abstract: Control Barrier Functions (CBFs) have emerged as efficient tools to address the safe navigation problem for robot applications. However, synthesizing informative and obstacle motion-aware CBFs online using real-time sensor data remains challenging, particularly in unknown and dynamic scenarios. Motived by this challenge, this paper aims to propose a novel Gaussian Process-based formulation of CBF, termed the Dynamic Log Gaussian Process Control Barrier Function (DLGP-CBF), to enable real-time construction of CBF which are both spatially informative and responsive to obstacle motion. Firstly, the DLGP-CBF leverages a logarithmic transformation of GP regression to generate smooth and informative barrier values and gradients, even in sparse-data regions. Secondly, by explicitly modeling the DLGP-CBF as a function of obstacle positions, the derived safety constraint integrates predicted obstacle velocities, allowing the controller to proactively respond to dynamic obstacles' motion. Simulation results demonstrate significant improvements in obstacle avoidance performance, including increased safety margins, smoother trajectories, and enhanced responsiveness compared to baseline methods.

</details>


### [448] [DiG-Flow: Discrepancy-Guided Flow Matching for Robust VLA Models](https://arxiv.org/abs/2512.01715)
*Wanpeng Zhang,Ye Wang,Hao Luo,Haoqi Yuan,Yicheng Feng,Sipeng Zheng,Qin Jin,Zongqing Lu*

Main category: cs.RO

TL;DR: DiG-Flow通过几何正则化提升VLA模型鲁棒性，显著改善复杂任务表现。


<details>
  <summary>Details</summary>
Motivation: VLA模型在分布偏移和复杂多步任务上性能下降，表明其学习表示可能未能稳健捕捉任务相关语义。

Method: DiG-Flow计算观察和动作嵌入之间的分布差异，将其映射为调制权重，并在流匹配前对观察嵌入进行残差更新。

Result: DiG-Flow在现有VLA架构中集成，性能一致提升，特别是在复杂任务和有限数据下。

Conclusion: DiG-Flow通过几何正则化增强了VLA模型的鲁棒性，尤其在复杂多步任务和有限训练数据下表现显著。

Abstract: Vision-Language-Action (VLA) models trained with flow matching have demonstrated impressive capabilities on robotic manipulation tasks. However, their performance often degrades under distribution shift and on complex multi-step tasks, suggesting that the learned representations may not robustly capture task-relevant semantics. We introduce DiG-Flow, a principled framework that enhances VLA robustness through geometric regularization. Our key insight is that the distributional discrepancy between observation and action embeddings provides a meaningful geometric signal: lower transport cost indicates compatible representations, while higher cost suggests potential misalignment. DiG-Flow computes a discrepancy measure between empirical distributions of observation and action embeddings, maps it to a modulation weight via a monotone function, and applies residual updates to the observation embeddings before flow matching. Crucially, this intervention operates at the representation level without modifying the flow matching path or target vector field. We provide theoretical guarantees showing that discrepancy-guided training provably decreases the training objective, and that guided inference refinement converges with contraction. Empirically, DiG-Flow integrates into existing VLA architectures with negligible overhead and consistently improves performance, with particularly pronounced gains on complex multi-step tasks and under limited training data.

</details>


### [449] [AgriLiRa4D: A Multi-Sensor UAV Dataset for Robust SLAM in Challenging Agricultural Fields](https://arxiv.org/abs/2512.01753)
*Zhihao Zhan,Yuhang Ming,Shaobin Li,Jie Yuan*

Main category: cs.RO

TL;DR: AgriLiRa4D是一个多模态无人机数据集，旨在解决农业SLAM研究中缺乏真实数据集的问题，支持多传感器SLAM算法的评估和鲁棒性研究。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏真实世界的多模态农业无人机数据集，阻碍了在农业任务中无人机鲁棒操作的研究。

Method: 通过提供高精度的地面真实轨迹和同步的多传感器测量（包括3D LiDAR、4D雷达和IMU），并完成完整的标定，构建了一个多模态无人机数据集。

Result: AgriLiRa4D支持多样化的SLAM和定位研究，并能够对低纹理作物、重复模式、动态植被等真实农业环境中的挑战进行严格的鲁棒性评估。

Conclusion: AgriLiRa4D填补了农业SLAM数据集的空白，为研究社区提供了有价值的基准，并推动了农业无人机自主导航技术的发展。

Abstract: Multi-sensor Simultaneous Localization and Mapping (SLAM) is essential for Unmanned Aerial Vehicles (UAVs) performing agricultural tasks such as spraying, surveying, and inspection. However, real-world, multi-modal agricultural UAV datasets that enable research on robust operation remain scarce. To address this gap, we present AgriLiRa4D, a multi-modal UAV dataset designed for challenging outdoor agricultural environments. AgriLiRa4D spans three representative farmland types-flat, hilly, and terraced-and includes both boundary and coverage operation modes, resulting in six flight sequence groups. The dataset provides high-accuracy ground-truth trajectories from a Fiber Optic Inertial Navigation System with Real-Time Kinematic capability (FINS_RTK), along with synchronized measurements from a 3D LiDAR, a 4D Radar, and an Inertial Measurement Unit (IMU), accompanied by complete intrinsic and extrinsic calibrations. Leveraging its comprehensive sensor suite and diverse real-world scenarios, AgriLiRa4D supports diverse SLAM and localization studies and enables rigorous robustness evaluation against low-texture crops, repetitive patterns, dynamic vegetation, and other challenges of real agricultural environments. To further demonstrate its utility, we benchmark four state-of-the-art multi-sensor SLAM algorithms across different sensor combinations, highlighting the difficulty of the proposed sequences and the necessity of multi-modal approaches for reliable UAV localization. By filling a critical gap in agricultural SLAM datasets, AgriLiRa4D provides a valuable benchmark for the research community and contributes to advancing autonomous navigation technologies for agricultural UAVs. The dataset can be downloaded from: https://zhan994.github.io/AgriLiRa4D.

</details>


### [450] [IGen: Scalable Data Generation for Robot Learning from Open-World Images](https://arxiv.org/abs/2512.01773)
*Chenghao Gu,Haolan Kang,Junchao Lin,Jinghe Wang,Duo Wu,Shuzhao Xie,Fanding Huang,Junchen Ge,Ziyang Gong,Letian Li,Hongying Zheng,Changwei Lv,Zhi Wang*

Main category: cs.RO

TL;DR: IGen框架从开放世界图像生成视觉运动数据，填补了机器人学习中的资源空白，实验证明其合成数据训练的模型性能与真实数据相当。


<details>
  <summary>Details</summary>
Motivation: 开放世界图像捕捉了丰富的真实世界场景，与机器人操作任务自然对齐，但由于缺乏关联的机器人动作，这些资源未被充分利用。IGen旨在填补这一空白。

Method: IGen首先将非结构化的2D像素转换为适合场景理解和操作的3D场景表示，然后利用视觉语言模型的推理能力将场景特定任务指令转化为高级计划，并生成低级的SE(3)末端执行器姿态序列。

Result: 实验验证了IGen生成的视觉运动数据的高质量，且仅用IGen合成数据训练的模型性能与真实数据训练的模型相当。

Conclusion: IGen框架通过从开放世界图像生成高质量的视觉运动数据，展示了其在支持通用机器人策略训练中的潜力，其性能可与真实世界数据训练的模型相媲美。

Abstract: The rise of generalist robotic policies has created an exponential demand for large-scale training data. However, on-robot data collection is labor-intensive and often limited to specific environments. In contrast, open-world images capture a vast diversity of real-world scenes that naturally align with robotic manipulation tasks, offering a promising avenue for low-cost, large-scale robot data acquisition. Despite this potential, the lack of associated robot actions hinders the practical use of open-world images for robot learning, leaving this rich visual resource largely unexploited. To bridge this gap, we propose IGen, a framework that scalably generates realistic visual observations and executable actions from open-world images. IGen first converts unstructured 2D pixels into structured 3D scene representations suitable for scene understanding and manipulation. It then leverages the reasoning capabilities of vision-language models to transform scene-specific task instructions into high-level plans and generate low-level actions as SE(3) end-effector pose sequences. From these poses, it synthesizes dynamic scene evolution and renders temporally coherent visual observations. Experiments validate the high quality of visuomotor data generated by IGen, and show that policies trained solely on IGen-synthesized data achieve performance comparable to those trained on real-world data. This highlights the potential of IGen to support scalable data generation from open-world images for generalist robotic policy training.

</details>


### [451] [GR-RL: Going Dexterous and Precise for Long-Horizon Robotic Manipulation](https://arxiv.org/abs/2512.01801)
*Yunfei Li,Xiao Ma,Jiafeng Xu,Yu Cui,Zhongren Cui,Zhigang Han,Liqun Huang,Tao Kong,Yuxiao Liu,Hao Niu,Wanli Peng,Jingchao Qiao,Zeyu Ren,Haixin Shi,Zhi Su,Jiawen Tian,Yuyang Xiao,Shenyu Zhang,Liwei Zheng,Hang Li,Yonghui Wu*

Main category: cs.RO

TL;DR: GR-RL通过筛选、增强和强化学习优化人类演示，将通用VLA策略转化为高精度灵巧操作专家，首次实现自主穿鞋带（83.3%成功率）。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言-动作策略假设人类演示最优，但在高精度灵巧操作任务中，人类演示存在噪声和次优问题。GR-RL旨在解决这一问题，提升策略在长时程、毫米级精度及软体交互任务中的性能。

Method: GR-RL采用多阶段训练流程：1) 基于离线强化学习的稀疏奖励生成鲁棒任务进度函数，筛选演示轨迹；2) 引入形态对称增强提升泛化性能；3) 通过在线强化学习学习潜在空间噪声预测器，对齐策略与部署行为。

Result: GR-RL在穿鞋带任务中达到83.3%的成功率，展示了其在长时程推理、毫米级精度和柔性体交互方面的卓越能力。

Conclusion: GR-RL框架通过多阶段训练流程，将通用视觉-语言-动作策略转化为高精度长时程灵巧操作专家，首次实现了自主穿鞋带等高难度任务，成功率达83.3%，为通用机器人基础模型向现实世界专家转化提供了可能。

Abstract: We present GR-RL, a robotic learning framework that turns a generalist vision-language-action (VLA) policy into a highly capable specialist for long-horizon dexterous manipulation. Assuming the optimality of human demonstrations is core to existing VLA policies. However, we claim that in highly dexterous and precise manipulation tasks, human demonstrations are noisy and suboptimal. GR-RL proposes a multi-stage training pipeline that filters, augments, and reinforces the demonstrations by reinforcement learning. First, GR-RL learns a vision-language-conditioned task progress, filters the demonstration trajectories, and only keeps the transitions that contribute positively to the progress. Specifically, we show that by directly applying offline RL with sparse reward, the resulting $Q$-values can be treated as a robust progress function. Next, we introduce morphological symmetry augmentation that greatly improves the generalization and performance of GR-RL. Lastly, to better align the VLA policy with its deployment behaviors for high-precision control, we perform online RL by learning a latent space noise predictor. With this pipeline, GR-RL is, to our knowledge, the first learning-based policy that can autonomously lace up a shoe by threading shoelaces through multiple eyelets with an 83.3% success rate, a task requiring long-horizon reasoning, millimeter-level precision, and compliant soft-body interaction. We hope GR-RL provides a step toward enabling generalist robot foundations models to specialize into reliable real-world experts.

</details>


### [452] [Much Ado About Noising: Dispelling the Myths of Generative Robotic Control](https://arxiv.org/abs/2512.01809)
*Chaoyi Pan,Giri Anantharaman,Nai-Chieh Huang,Claire Jin,Daniel Pfrommer,Chenyang Yuan,Frank Permenter,Guannan Qu,Nicholas Boffi,Guanya Shi,Max Simchowitz*

Main category: cs.RO

TL;DR: 生成控制策略的优势来自迭代计算和监督训练，而非多模态捕捉能力；MIP验证了这一发现。


<details>
  <summary>Details</summary>
Motivation: 探讨生成模型在机器人控制中成功的关键因素，挑战了关于其多模态和复杂行为表达能力的普遍假设。

Method: 对流行的生成控制策略（GCPs）在行为克隆（BC）基准上进行了全面评估，并提出了最小迭代策略（MIP）作为验证。

Result: MIP（一种轻量级的两步回归策略）性能与流模型GCPs相当，甚至优于蒸馏捷径模型。

Conclusion: 生成模型（如流模型和扩散模型）的成功并非源于其捕捉多模态或复杂行为的能力，而是源于迭代计算和监督训练的结合。

Abstract: Generative models, like flows and diffusions, have recently emerged as popular and efficacious policy parameterizations in robotics. There has been much speculation as to the factors underlying their successes, ranging from capturing multi-modal action distribution to expressing more complex behaviors. In this work, we perform a comprehensive evaluation of popular generative control policies (GCPs) on common behavior cloning (BC) benchmarks. We find that GCPs do not owe their success to their ability to capture multi-modality or to express more complex observation-to-action mappings. Instead, we find that their advantage stems from iterative computation, as long as intermediate steps are supervised during training and this supervision is paired with a suitable level of stochasticity. As a validation of our findings, we show that a minimum iterative policy (MIP), a lightweight two-step regression-based policy, essentially matches the performance of flow GCPs, and often outperforms distilled shortcut models. Our results suggest that the distribution-fitting component of GCPs is less salient than commonly believed, and point toward new design spaces focusing solely on control performance. Project page: https://simchowitzlabpublic.github.io/much-ado-about-noising-project/

</details>


### [453] [Is Image-based Object Pose Estimation Ready to Support Grasping?](https://arxiv.org/abs/2512.01856)
*Eric C. Joyce,Qianwen Zhao,Nathaniel Burgdorfer,Long Wang,Philippos Mordohai*

Main category: cs.RO

TL;DR: 论文提出了一种评估单RGB图像输入的6-DoF物体姿态估计器的框架，通过模拟抓取实验比较了五种开源方法，填补了文献空白。


<details>
  <summary>Details</summary>
Motivation: 评估6-DoF实例级物体姿态估计器的准确性，并探讨其作为机器人抓取唯一感知机制的潜力。

Method: 使用基于物理的模拟器进行抓取试验，利用基于图像的姿态估计指导平行夹爪和欠驱动机器人手抓取3D物体模型。

Result: 实验在BOP数据集子集上进行，比较了五种开源物体姿态估计器，提供了文献中缺失的见解。

Conclusion: 该论文通过实验比较了五种开源物体姿态估计器，填补了文献中的空白，并评估了它们在机器人抓取中的实用性。

Abstract: We present a framework for evaluating 6-DoF instance-level object pose estimators, focusing on those that require a single RGB (not RGB-D) image as input. Besides gaining intuition about how accurate these estimators are, we are interested in the degree to which they can serve as the sole perception mechanism for robotic grasping. To assess this, we perform grasping trials in a physics-based simulator, using image-based pose estimates to guide a parallel gripper and an underactuated robotic hand in picking up 3D models of objects. Our experiments on a subset of the BOP (Benchmark for 6D Object Pose Estimation) dataset compare five open-source object pose estimators and provide insights that were missing from the literature.

</details>


### [454] [NeuroHJR: Hamilton-Jacobi Reachability-based Obstacle Avoidance in Complex Environments with Physics-Informed Neural Networks](https://arxiv.org/abs/2512.01897)
*Granthik Halder,Rudrashis Majumder,Rakshith M R,Rahi Shah,Suresh Sundaram*

Main category: cs.RO

TL;DR: NeuroHJR框架利用PINNs近似HJR解决方案，实现了实时避障，计算成本低且可扩展。


<details>
  <summary>Details</summary>
Motivation: 自主地面车辆（AGVs）在复杂动态和环境不确定性的情况下需要安全导航，但传统的Hamilton-Jacobi可达性（HJR）方法在多障碍物环境中可扩展性较差。

Method: 通过将系统动力学和安全约束直接嵌入神经网络损失函数，避免了基于网格的离散化，实现了连续状态空间中可达集的高效估计。

Result: 仿真结果表明，在密集障碍物场景中，该方法的安全性能与经典HJR求解器相当，同时显著降低了计算成本。

Conclusion: 本文提出了一种名为NeuroHJR的新框架，利用物理信息神经网络（PINNs）近似HJR解决方案，为实时避障提供了可扩展且高效的方法，显著降低了计算成本。

Abstract: Autonomous ground vehicles (AGVs) must navigate safely in cluttered environments while accounting for complex dynamics and environmental uncertainty. Hamilton-Jacobi Reachability (HJR) offers formal safety guarantees through the computation of forward and backward reachable sets, but its application is hindered by poor scalability in environments with numerous obstacles. In this paper, we present a novel framework called NeuroHJR that leverages Physics-Informed Neural Networks (PINNs) to approximate the HJR solution for real-time obstacle avoidance. By embedding system dynamics and safety constraints directly into the neural network loss function, our method bypasses the need for grid-based discretization and enables efficient estimation of reachable sets in continuous state spaces. We demonstrate the effectiveness of our approach through simulation results in densely cluttered scenarios, showing that it achieves safety performance comparable to that of classical HJR solvers while significantly reducing the computational cost. This work provides a new step toward real-time, scalable deployment of reachability-based obstacle avoidance in robotics.

</details>


### [455] [Real-World Robot Control by Deep Active Inference With a Temporally Hierarchical World Model](https://arxiv.org/abs/2512.01924)
*Kentaro Fujii,Shingo Murata*

Main category: cs.RO

TL;DR: 论文提出了一种新型深度主动推理框架，通过多时间尺度建模和动作抽象，有效提升机器人在不确定环境中的表现并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有深度学习方法在不确定环境中忽视探索行为且表现不佳的问题，论文采用深度主动推理框架，该框架能够模拟人类的目标导向和探索行为。

Method: 论文提出了一种包含世界模型、动作模型和抽象世界模型的深度主动推理框架。世界模型将环境动态编码为慢速和快速时间尺度的隐藏状态表示；动作模型通过向量量化将动作序列压缩为抽象动作；抽象世界模型则基于抽象动作预测未来的慢速状态，从而实现低成本的动作选择。

Result: 在真实机器人操作任务中的评估显示，该框架在多样化操作任务中实现了高成功率，并能在不确定环境中切换目标导向和探索行为，同时使动作选择计算可行。

Conclusion: 该论文提出的新型深度主动推理框架通过建模多时间尺度动态和抽象化动作及状态转换，显著提升了机器人在不确定环境中的表现，同时降低了计算成本。

Abstract: Robots in uncertain real-world environments must perform both goal-directed and exploratory actions. However, most deep learning-based control methods neglect exploration and struggle under uncertainty. To address this, we adopt deep active inference, a framework that accounts for human goal-directed and exploratory actions. Yet, conventional deep active inference approaches face challenges due to limited environmental representation capacity and high computational cost in action selection. We propose a novel deep active inference framework that consists of a world model, an action model, and an abstract world model. The world model encodes environmental dynamics into hidden state representations at slow and fast timescales. The action model compresses action sequences into abstract actions using vector quantization, and the abstract world model predicts future slow states conditioned on the abstract action, enabling low-cost action selection. We evaluate the framework on object-manipulation tasks with a real-world robot. Results show that it achieves high success rates across diverse manipulation tasks and switches between goal-directed and exploratory actions in uncertain settings, while making action selection computationally tractable. These findings highlight the importance of modeling multiple timescale dynamics and abstracting actions and state transitions.

</details>


### [456] [Guardian: Detecting Robotic Planning and Execution Errors with Vision-Language Models](https://arxiv.org/abs/2512.01946)
*Paul Pacaud,Ricardo Garcia,Shizhe Chen,Cordelia Schmid*

Main category: cs.RO

TL;DR: 通过自动合成机器人失败数据，提出Guardian VLM，显著提升失败检测性能和任务成功率。


<details>
  <summary>Details</summary>
Motivation: 解决当前视觉语言模型（VLMs）因失败数据稀缺而导致的准确性和泛化能力受限的问题。

Method: 提出了一种自动机器人失败合成方法，通过程序化扰动成功轨迹生成多样化的规划和执行失败，并构建了三个新的失败检测基准。

Result: Guardian VLM在新构建的基准和现有基准上均达到最先进性能，并在模拟和真实机器人中有效提高了任务成功率。

Conclusion: Guardian VLM通过利用自动合成的失败数据，在失败检测和任务成功率方面实现了最先进的性能，证明了生成失败数据的实际影响。

Abstract: Robust robotic manipulation requires reliable failure detection and recovery. Although current Vision-Language Models (VLMs) show promise, their accuracy and generalization are limited by the scarcity of failure data. To address this data gap, we propose an automatic robot failure synthesis approach that procedurally perturbs successful trajectories to generate diverse planning and execution failures. This method produces not only binary classification labels but also fine-grained failure categories and step-by-step reasoning traces in both simulation and the real world. With it, we construct three new failure detection benchmarks: RLBench-Fail, BridgeDataV2-Fail, and UR5-Fail, substantially expanding the diversity and scale of existing failure datasets. We then train Guardian, a VLM with multi-view images for detailed failure reasoning and detection. Guardian achieves state-of-the-art performance on both existing and newly introduced benchmarks. It also effectively improves task success rates when integrated into a state-of-the-art manipulation system in simulation and real robots, demonstrating the impact of our generated failure data.

</details>


### [457] [RoaD: Rollouts as Demonstrations for Closed-Loop Supervised Fine-Tuning of Autonomous Driving Policies](https://arxiv.org/abs/2512.01993)
*Guillermo Garcia-Cobo,Maximilian Igl,Peter Karkus,Zhejun Zhang,Michael Watson,Yuxiao Chen,Boris Ivanovic,Marco Pavone*

Main category: cs.RO

TL;DR: RoaD利用策略闭环滚动生成训练数据，缓解协变量偏移，性能优于传统方法，适用于端到端驾驶。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶策略在闭环部署时因协变量偏移导致错误累积，现有方法如CL-SFT存在限制，RoaD旨在提供更高效且通用的解决方案。

Method: RoaD通过生成策略的闭环滚动并结合专家指导，生成高质量的训练数据用于微调，避免了强化学习的大量数据需求。

Result: 在WOSAC仿真基准中，RoaD性能与现有CL-SFT方法相当或更优；在AlpaSim中，驾驶分数提升41%，碰撞减少54%。

Conclusion: RoaD方法通过利用策略自身的闭环滚动作为额外训练数据，有效缓解了协变量偏移问题，在多个仿真环境中表现出色，性能优于或等同于现有方法。

Abstract: Autonomous driving policies are typically trained via open-loop behavior cloning of human demonstrations. However, such policies suffer from covariate shift when deployed in closed loop, leading to compounding errors. We introduce Rollouts as Demonstrations (RoaD), a simple and efficient method to mitigate covariate shift by leveraging the policy's own closed-loop rollouts as additional training data. During rollout generation, RoaD incorporates expert guidance to bias trajectories toward high-quality behavior, producing informative yet realistic demonstrations for fine-tuning. This approach enables robust closed-loop adaptation with orders of magnitude less data than reinforcement learning, and avoids restrictive assumptions of prior closed-loop supervised fine-tuning (CL-SFT) methods, allowing broader applications domains including end-to-end driving. We demonstrate the effectiveness of RoaD on WOSAC, a large-scale traffic simulation benchmark, where it performs similar or better than the prior CL-SFT method; and in AlpaSim, a high-fidelity neural reconstruction-based simulator for end-to-end driving, where it improves driving score by 41\% and reduces collisions by 54\%.

</details>


### [458] [Learning Sim-to-Real Humanoid Locomotion in 15 Minutes](https://arxiv.org/abs/2512.01996)
*Younggyo Seo,Carmelo Sferrazza,Juyue Chen,Guanya Shi,Rocky Duan,Pieter Abbeel*

Main category: cs.RO

TL;DR: 提出FastSAC/FastTD3方法，15分钟内训练人形机器人运动策略，适用于强随机化环境。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人控制中因高维度和领域随机化导致的sim-to-real RL训练困难问题。

Method: 采用大规模并行环境的离策略RL算法（FastSAC和FastTD3），通过精心调优的设计选择和简约奖励函数实现稳定训练。

Result: 在Unitree G1和Booster T1机器人上实现了快速端到端运动控制器学习，并在随机动力学、粗糙地形和推力扰动等条件下表现出色。

Conclusion: 该论文提出了一种基于FastSAC和FastTD3的简单实用方法，能够在15分钟内快速训练人形机器人运动策略，并在强领域随机化条件下实现稳定控制。

Abstract: Massively parallel simulation has reduced reinforcement learning (RL) training time for robots from days to minutes. However, achieving fast and reliable sim-to-real RL for humanoid control remains difficult due to the challenges introduced by factors such as high dimensionality and domain randomization. In this work, we introduce a simple and practical recipe based on off-policy RL algorithms, i.e., FastSAC and FastTD3, that enables rapid training of humanoid locomotion policies in just 15 minutes with a single RTX 4090 GPU. Our simple recipe stabilizes off-policy RL algorithms at massive scale with thousands of parallel environments through carefully tuned design choices and minimalist reward functions. We demonstrate rapid end-to-end learning of humanoid locomotion controllers on Unitree G1 and Booster T1 robots under strong domain randomization, e.g., randomized dynamics, rough terrain, and push perturbations, as well as fast training of whole-body human-motion tracking policies. We provide videos and open-source implementation at: https://younggyo.me/fastsac-humanoid.

</details>


### [459] [LLM-Driven Corrective Robot Operation Code Generation with Static Text-Based Simulation](https://arxiv.org/abs/2512.02002)
*Wenhao Wang,Yanyan Li,Long Jiao,Jiawei Yuan*

Main category: cs.RO

TL;DR: 本文提出利用LLM作为静态模拟器，设计可靠校正框架生成机器人操作代码，实验验证其高效性，无需物理实验或动态模拟。


<details>
  <summary>Details</summary>
Motivation: 现有研究依赖物理实验或定制模拟环境来执行代码，配置成本高且执行时间长，限制了部署。本文探索直接利用LLM进行静态模拟的可能性。

Method: 通过将LLM配置为静态模拟器，增强其解释动作、推理状态转换、分析执行结果和生成语义观察的能力，设计了一个新的可靠LLM驱动校正框架。

Result: 实验表明，静态文本模拟具有高准确性，且框架生成的代码性能与最先进研究相当，无需动态代码执行。

Conclusion: 本文提出了一种基于LLM的静态模拟框架，用于可靠地生成机器人操作代码，无需依赖物理实验或动态模拟环境，实验证明了其高准确性和可靠性。

Abstract: Recent advances in Large language models (LLMs) have demonstrated their promising capabilities of generating robot operation code to enable LLM-driven robots. To enhance the reliability of operation code generated by LLMs, corrective designs with feedback from the observation of executing code have been increasingly adopted in existing research. However, the code execution in these designs relies on either a physical experiment or a customized simulation environment, which limits their deployment due to the high configuration effort of the environment and the potential long execution time. In this paper, we explore the possibility of directly leveraging LLM to enable static simulation of robot operation code, and then leverage it to design a new reliable LLM-driven corrective robot operation code generation framework. Our framework configures the LLM as a static simulator with enhanced capabilities that reliably simulate robot code execution by interpreting actions, reasoning over state transitions, analyzing execution outcomes, and generating se- mantic observations that accurately capture trajectory dynamics. To validate the performance of our framework, we performed experiments on various operation tasks for different robots, including UAVs and small ground vehicles. The experiment results not only demonstrated the high accuracy of our static text-based simulation but also the reliable code generation of our LLM-driven corrective framework, which achieves a comparable performance with state-of-the-art research while does not rely on dynamic code execution using physical experiments or simulators.

</details>


### [460] [Learning Dexterous Manipulation Skills from Imperfect Simulations](https://arxiv.org/abs/2512.02011)
*Elvis Hsieh,Wen-Han Hsieh,Yen-Jen Wang,Toru Lin,Jitendra Malik,Koushil Sreenath,Haozhi Qi*

Main category: cs.RO

TL;DR: 提出了一种模拟到真实的框架，通过三阶段训练（模拟训练、远程操作演示、行为克隆）解决了复杂接触和触觉反馈的模拟难题，在螺母螺栓和螺丝刀操作任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习和模拟到真实的转移在灵巧操作方面取得了进展，但复杂的接触动力学和多感官信号（尤其是触觉反馈）的模拟难度限制了进一步的发展。

Method: 框架分为三个阶段：1. 在模拟环境中使用简化的物体模型训练强化学习策略；2. 将学习到的策略作为技能基元，在远程操作系统中收集包含触觉和本体感觉信息的真实世界演示；3. 训练一个结合触觉感知的行为克隆策略。

Result: 实验证明，该框架在螺母螺栓紧固和螺丝刀操作任务中表现出色，能够推广到不同几何形状的物体。

Conclusion: 实验结果表明，与直接模拟到真实的转移相比，该框架在任务完成率上表现更优，并且能够适应未见过的物体形状和外部干扰。

Abstract: Reinforcement learning and sim-to-real transfer have made significant progress in dexterous manipulation. However, progress remains limited by the difficulty of simulating complex contact dynamics and multisensory signals, especially tactile feedback. In this work, we propose \ours, a sim-to-real framework that addresses these limitations and demonstrates its effectiveness on nut-bolt fastening and screwdriving with multi-fingered hands. The framework has three stages. First, we train reinforcement learning policies in simulation using simplified object models that lead to the emergence of correct finger gaits. We then use the learned policy as a skill primitive within a teleoperation system to collect real-world demonstrations that contain tactile and proprioceptive information. Finally, we train a behavior cloning policy that incorporates tactile sensing and show that it generalizes to nuts and screwdrivers with diverse geometries. Experiments across both tasks show high task progress ratios compared to direct sim-to-real transfer and robust performance even on unseen object shapes and under external perturbations. Videos and code are available on https://dexscrew.github.io.

</details>


### [461] [ManualVLA: A Unified VLA Model for Chain-of-Thought Manual Generation and Robotic Manipulation](https://arxiv.org/abs/2512.02013)
*Chenyang Gu,Jiaming Liu,Hao Chen,Runzhong Huang,Qingpo Wuwu,Zhuoyang Liu,Xiaoqi Li,Ying Li,Renrui Zhang,Peng Jia,Pheng-Ann Heng,Shanghang Zhang*

Main category: cs.RO

TL;DR: ManualVLA通过多模态手册生成与执行的统一框架，显著提升长视野任务表现，成功率比基线高32%。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在需要明确目标状态的长视野任务（如LEGO组装）中，难以协调高层规划与精确操作，因此需赋予模型从目标状态推断执行过程的能力。

Method: 提出ManualVLA框架，基于Mixture-of-Transformers架构，包含规划专家生成多模态手册（图像、位置提示、文本指令），并通过Manual Chain-of-Thought推理过程将这些手册输入动作专家，实现显式控制和隐式指导的结合。

Result: ManualVLA在真实任务中表现优异，LEGO组装和物体重排任务的平均成功率比之前的分层SOTA基线高32%。

Conclusion: ManualVLA通过结合多模态手册生成与动作执行的统一框架，显著提升了在长视野任务中的表现，尤其是在LEGO组装和物体重排任务上，平均成功率比现有基线高出32%。

Abstract: Vision-Language-Action (VLA) models have recently emerged, demonstrating strong generalization in robotic scene understanding and manipulation. However, when confronted with long-horizon tasks that require defined goal states, such as LEGO assembly or object rearrangement, existing VLA models still face challenges in coordinating high-level planning with precise manipulation. Therefore, we aim to endow a VLA model with the capability to infer the "how" process from the "what" outcomes, transforming goal states into executable procedures. In this paper, we introduce ManualVLA, a unified VLA framework built upon a Mixture-of-Transformers (MoT) architecture, enabling coherent collaboration between multimodal manual generation and action execution. Unlike prior VLA models that directly map sensory inputs to actions, we first equip ManualVLA with a planning expert that generates intermediate manuals consisting of images, position prompts, and textual instructions. Building upon these multimodal manuals, we design a Manual Chain-of-Thought (ManualCoT) reasoning process that feeds them into the action expert, where each manual step provides explicit control conditions, while its latent representation offers implicit guidance for accurate manipulation. To alleviate the burden of data collection, we develop a high-fidelity digital-twin toolkit based on 3D Gaussian Splatting, which automatically generates manual data for planning expert training. ManualVLA demonstrates strong real-world performance, achieving an average success rate 32% higher than the previous hierarchical SOTA baseline on LEGO assembly and object rearrangement tasks.

</details>


### [462] [EfficientFlow: Efficient Equivariant Flow Policy Learning for Embodied AI](https://arxiv.org/abs/2512.02020)
*Jianlei Chang,Ruofeng Mei,Wei Ke,Xiangyu Xu*

Main category: cs.RO

TL;DR: EfficientFlow 通过流匹配和加速正则化策略，显著提升了具身AI策略的数据效率和推理速度。


<details>
  <summary>Details</summary>
Motivation: 现有的生成策略在数据效率和采样效率上存在不足，需要大规模演示且推理速度慢。

Method: 引入了基于流的学习策略，通过引入等变性和加速正则化策略来提升数据效率和采样效率。

Result: 在多种机器人操作基准测试中，EfficientFlow 在有限数据下表现优异，且推理速度大幅提升。

Conclusion: EfficientFlow 作为一个高效且强大的范式，为高性能的具身AI提供了新的解决方案，显著提升了数据利用率和推理速度。

Abstract: Generative modeling has recently shown remarkable promise for visuomotor policy learning, enabling flexible and expressive control across diverse embodied AI tasks. However, existing generative policies often struggle with data inefficiency, requiring large-scale demonstrations, and sampling inefficiency, incurring slow action generation during inference. We introduce EfficientFlow, a unified framework for efficient embodied AI with flow-based policy learning. To enhance data efficiency, we bring equivariance into flow matching. We theoretically prove that when using an isotropic Gaussian prior and an equivariant velocity prediction network, the resulting action distribution remains equivariant, leading to improved generalization and substantially reduced data demands. To accelerate sampling, we propose a novel acceleration regularization strategy. As direct computation of acceleration is intractable for marginal flow trajectories, we derive a novel surrogate loss that enables stable and scalable training using only conditional trajectories. Across a wide range of robotic manipulation benchmarks, the proposed algorithm achieves competitive or superior performance under limited data while offering dramatically faster inference. These results highlight EfficientFlow as a powerful and efficient paradigm for high-performance embodied AI.

</details>
