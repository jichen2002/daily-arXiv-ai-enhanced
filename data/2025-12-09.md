<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 224]
- [cs.SE](#cs.SE) [Total: 25]
- [eess.IV](#eess.IV) [Total: 1]
- [cs.DC](#cs.DC) [Total: 13]
- [cs.NI](#cs.NI) [Total: 8]
- [cs.GR](#cs.GR) [Total: 3]
- [cs.OS](#cs.OS) [Total: 1]
- [cs.AI](#cs.AI) [Total: 42]
- [cs.RO](#cs.RO) [Total: 62]
- [cs.DS](#cs.DS) [Total: 8]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Video Models Start to Solve Chess, Maze, Sudoku, Mental Rotation, and Raven' Matrices](https://arxiv.org/abs/2512.05969)
*Hokin Deng*

Main category: cs.CV

TL;DR: 视频生成模型在推理任务上表现良好（60%成功率），通过'任务对'设计和自动化评估框架，展示了可扩展性，并指出强化学习的潜在应用。


<details>
  <summary>Details</summary>
Motivation: 探索视频生成模型在推理任务（如国际象棋、迷宫、数独等）上的能力，并建立一个可扩展的实验范式。

Method: 采用'任务对'设计，构建了一个包含39个模型的代码框架，支持自动化评估，并与人类判断高度相关。

Result: 领先模型如Sora-2在多项推理任务上达到60%的成功率，自动化评估与人类判断强相关，证明了范式的可扩展性。

Conclusion: 论文提出了一种基于'任务对'设计的实验范式，并构建了支持该范式的代码框架，展示了视频生成模型在推理任务上的潜力，同时指出了强化学习在提升视频模型推理能力上的机会。

Abstract: We show that video generation models could reason now. Testing on tasks such as chess, maze, Sudoku, mental rotation, and Raven's Matrices, leading models such as Sora-2 achieve sixty percent success rates. We establish a robust experimental paradigm centered on the "Task Pair" design. We build a code framework, with 39 models available already, that supports this paradigm and allows for easy scaling - users can add models and tasks efficiently. We show our automated evaluation strongly correlates with human judgment, and therefore this paradigm is highly scalable. We see an opportunity, given the availability of our paradigm, to do reinforcement learning for improving reasoning in video models. You could checkout all of our raw $\href{https://grow-ai-like-a-child.com/video-reason/}{results}$ and our $\href{https://github.com/hokindeng/VMEvalKit}{VMEvalKit}$ codebase.

</details>


### [2] [Adaptive Dataset Quantization: A New Direction for Dataset Pruning](https://arxiv.org/abs/2512.05987)
*Chenyue Yu,Jianyu Yu*

Main category: cs.CV

TL;DR: 提出一种数据集量化方法，通过减少样本内冗余来压缩数据，保持模型性能的同时显著减少存储需求。


<details>
  <summary>Details</summary>
Motivation: 解决资源受限的边缘设备在大规模数据集存储和通信成本方面的挑战。

Method: 提出了一种新颖的数据集量化方法，通过减少样本内的冗余内容来压缩每个图像。首先应用线性对称量化获得每个样本的初始量化范围和尺度，然后引入自适应量化分配算法为不同精度需求的样本分配不同的量化比例。

Result: 在CIFAR-10、CIFAR-100和ImageNet-1K上的广泛实验验证了该方法的有效性。

Conclusion: 该方法在保持模型训练性能的同时实现了显著的数据集压缩，优于相同压缩比下的传统量化和数据集剪枝基线。

Abstract: This paper addresses the challenges of storage and communication costs for large-scale datasets in resource-constrained edge devices by proposing a novel dataset quantization approach to reduce intra-sample redundancy. Unlike traditional dataset pruning and distillation methods that focus on inter-sample redundancy, the proposed method compresses each image by reducing redundant or less informative content within samples while preserving essential features. It first applies linear symmetric quantization to obtain an initial quantization range and scale for each sample. Then, an adaptive quantization allocation algorithm is introduced to distribute different quantization ratios for samples with varying precision requirements, maintaining a constant total compression ratio. The main contributions include: (1) being the first to use limited bits to represent datasets for storage reduction; (2) introducing a dataset-level quantization algorithm with adaptive ratio allocation; and (3) validating the method's effectiveness through extensive experiments on CIFAR-10, CIFAR-100, and ImageNet-1K. Results show that the method maintains model training performance while achieving significant dataset compression, outperforming traditional quantization and dataset pruning baselines under the same compression ratios.

</details>


### [3] [VG3T: Visual Geometry Grounded Gaussian Transformer](https://arxiv.org/abs/2512.05988)
*Junho Kim,Seongwon Lee*

Main category: cs.CV

TL;DR: VG3T是一种新型多视角前馈网络，通过3D高斯表示和关键组件优化，显著提升了3D场景重建的连贯性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有的多视角图像融合方法在生成连贯3D场景表示时存在碎片化和不一致性问题，VG3T旨在通过多视角联合预测克服这些限制。

Method: VG3T采用多视角联合预测语义属性高斯集的方法，结合Grid-Based Sampling和Positional Refinement两个关键组件，解决了像素对齐高斯初始化方法中的密度偏差问题。

Result: VG3T在nuScenes基准测试中实现了mIoU提升1.7%，同时减少了46%的基元使用量，证明了其高效性和性能优势。

Conclusion: VG3T通过多视角前馈网络和3D高斯表示，显著提升了3D场景重建的连贯性和语义准确性，同时在nuScenes基准测试中表现出更高的效率和性能。

Abstract: Generating a coherent 3D scene representation from multi-view images is a fundamental yet challenging task. Existing methods often struggle with multi-view fusion, leading to fragmented 3D representations and sub-optimal performance. To address this, we introduce VG3T, a novel multi-view feed-forward network that predicts a 3D semantic occupancy via a 3D Gaussian representation. Unlike prior methods that infer Gaussians from single-view images, our model directly predicts a set of semantically attributed Gaussians in a joint, multi-view fashion. This novel approach overcomes the fragmentation and inconsistency inherent in view-by-view processing, offering a unified paradigm to represent both geometry and semantics. We also introduce two key components, Grid-Based Sampling and Positional Refinement, to mitigate the distance-dependent density bias common in pixel-aligned Gaussian initialization methods. Our VG3T shows a notable 1.7%p improvement in mIoU while using 46% fewer primitives than the previous state-of-the-art on the nuScenes benchmark, highlighting its superior efficiency and performance.

</details>


### [4] [EmoDiffTalk:Emotion-aware Diffusion for Editable 3D Gaussian Talking Head](https://arxiv.org/abs/2512.05991)
*Chang Liu,Tianjiao Jing,Chengcheng Ma,Xuanqi Zhou,Zhengxuan Lian,Qin Jin,Hongliang Yuan,Shi-Sheng Huang*

Main category: cs.CV

TL;DR: EmoDiffTalk 是一种新型可编辑 3D 高斯说话头部，通过情感感知高斯扩散和文本到 AU 控制器，实现了高质量、多模态情感编辑。


<details>
  <summary>Details</summary>
Motivation: 现有的 3D 高斯喷绘说话头部在情感表达操控方面存在不足，尤其是细粒度和多模态动态情感编辑。

Method: 提出了一种新颖的 Emotion-aware Gaussian Diffusion 方法，包括 AU 提示的高斯扩散过程和精确的 text-to-AU 情感控制器。

Result: 在 EmoTalk3D 和 RenderMe-360 数据集上的实验表明，EmoDiffTalk 在情感细腻度、唇同步保真度和可控性上优于先前工作。

Conclusion: EmoDiffTalk 通过结合 Emotion-aware Gaussian Diffusion 和 text-to-AU 控制器，首次实现了高质量、多模态可编辑的 3D 高斯喷绘说话头部生成，支持基于 AU 表情空间的连续情感编辑。

Abstract: Recent photo-realistic 3D talking head via 3D Gaussian Splatting still has significant shortcoming in emotional expression manipulation, especially for fine-grained and expansive dynamics emotional editing using multi-modal control. This paper introduces a new editable 3D Gaussian talking head, i.e. EmoDiffTalk. Our key idea is a novel Emotion-aware Gaussian Diffusion, which includes an action unit (AU) prompt Gaussian diffusion process for fine-grained facial animator, and moreover an accurate text-to-AU emotion controller to provide accurate and expansive dynamic emotional editing using text input. Experiments on public EmoTalk3D and RenderMe-360 datasets demonstrate superior emotional subtlety, lip-sync fidelity, and controllability of our EmoDiffTalk over previous works, establishing a principled pathway toward high-quality, diffusion-driven, multimodal editable 3D talking-head synthesis. To our best knowledge, our EmoDiffTalk is one of the first few 3D Gaussian Splatting talking-head generation framework, especially supporting continuous, multimodal emotional editing within the AU-based expression space.

</details>


### [5] [From Orbit to Ground: Generative City Photogrammetry from Extreme Off-Nadir Satellite Images](https://arxiv.org/abs/2512.07527)
*Fei Yu,Yu Liu,Luyang Tang,Mingchao Sun,Zengye Ge,Rui Bu,Yuchao Jin,Haisen Zhao,He Sun,Yangyan Li,Mu Xu,Wenzheng Chen,Baoquan Chen*

Main category: cs.CV

TL;DR: 提出一种针对城市结构和卫星输入的方法，通过2.5D高度图和纹理恢复网络，实现从稀疏卫星图像到高质量地面视图的合成。


<details>
  <summary>Details</summary>
Motivation: 解决从稀疏卫星图像合成地面视图的极端视角外推问题，克服现有重建引擎（如NeRF和3DGS）在严重透视缩短和纹理缺陷下的失败。

Method: 1. 将城市几何建模为2.5D高度图，实现为Z单调符号距离场（SDF），以稳定稀疏卫星视图下的几何优化。2. 通过可微分渲染技术从卫星图像绘制网格外观，并训练生成纹理恢复网络以增强外观细节。

Result: 在大型城市重建实验中展示了方法的可扩展性和鲁棒性，例如从少量卫星图像重建了4平方公里区域，并在合成逼真地面视图方面达到最先进性能。

Conclusion: 该方法通过针对城市结构和卫星输入的设计选择，实现了从稀疏卫星图像到高质量地面视图的合成，为城市规划等下游任务提供了高保真资产。

Abstract: City-scale 3D reconstruction from satellite imagery presents the challenge of extreme viewpoint extrapolation, where our goal is to synthesize ground-level novel views from sparse orbital images with minimal parallax. This requires inferring nearly $90^\circ$ viewpoint gaps from image sources with severely foreshortened facades and flawed textures, causing state-of-the-art reconstruction engines such as NeRF and 3DGS to fail.
  To address this problem, we propose two design choices tailored for city structures and satellite inputs. First, we model city geometry as a 2.5D height map, implemented as a Z-monotonic signed distance field (SDF) that matches urban building layouts from top-down viewpoints. This stabilizes geometry optimization under sparse, off-nadir satellite views and yields a watertight mesh with crisp roofs and clean, vertically extruded facades. Second, we paint the mesh appearance from satellite images via differentiable rendering techniques. While the satellite inputs may contain long-range, blurry captures, we further train a generative texture restoration network to enhance the appearance, recovering high-frequency, plausible texture details from degraded inputs.
  Our method's scalability and robustness are demonstrated through extensive experiments on large-scale urban reconstruction. For example, in our teaser figure, we reconstruct a $4\,\mathrm{km}^2$ real-world region from only a few satellite images, achieving state-of-the-art performance in synthesizing photorealistic ground views. The resulting models are not only visually compelling but also serve as high-fidelity, application-ready assets for downstream tasks like urban planning and simulation.

</details>


### [6] [Domain-Specific Foundation Model Improves AI-Based Analysis of Neuropathology](https://arxiv.org/abs/2512.05993)
*Ruchika Verma,Shrishtee Kandoi,Robina Afzal,Shengjia Chen,Jannes Jegminat,Michael W. Karlovich,Melissa Umphlett,Timothy E. Richardson,Kevin Clare,Quazi Hossain,Jorge Samanamud,Phyllis L. Faust,Elan D. Louis,Ann C. McKee,Thor D. Stein,Jonathan D. Cherry,Jesse Mez,Anya C. McGoldrick,Dalilah D. Quintana Mora,Melissa J. Nirenberg,Ruth H. Walker,Yolfrankcis Mendez,Susan Morgello,Dennis W. Dickson,Melissa E. Murray,Carlos Cordon-Cardo,Nadejda M. Tsankova,Jamie M. Walker,Diana K. Dangoor,Stephanie McQuillan,Emma L. Thorn,Claudia De Sanctis,Shuying Li,Thomas J. Fuchs,Kurt Farrell,John F. Crary,Gabriele Campanella*

Main category: cs.CV

TL;DR: NeuroFM是一个针对脑组织训练的基础模型，在神经病理学任务中优于通用模型，提升了AI在脑疾病诊断中的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基础模型主要基于非神经组织的手术病理数据训练，无法充分捕捉神经病理学的独特形态特征。

Method: 开发了NeuroFM，一个基于脑组织全切片图像训练的基础模型，涵盖多种神经退行性病变。

Result: NeuroFM在混合性痴呆疾病分类、海马区分割及神经退行性共济失调识别等任务中表现优异。

Conclusion: NeuroFM，一个专门针对脑组织训练的基础模型，在神经病理学特定任务中表现优于通用模型，为数字病理学中特定领域模型开发树立了先例。

Abstract: Foundation models have transformed computational pathology by providing generalizable representations from large-scale histology datasets. However, existing models are predominantly trained on surgical pathology data, which is enriched for non-nervous tissue and overrepresents neoplastic, inflammatory, metabolic, and other non-neurological diseases. Neuropathology represents a markedly different domain of histopathology, characterized by unique cell types (neurons, glia, etc.), distinct cytoarchitecture, and disease-specific pathological features including neurofibrillary tangles, amyloid plaques, Lewy bodies, and pattern-specific neurodegeneration. This domain mismatch may limit the ability of general-purpose foundation models to capture the morphological patterns critical for interpreting neurodegenerative diseases such as Alzheimer's disease, Parkinson's disease, and cerebellar ataxias. To address this gap, we developed NeuroFM, a foundation model trained specifically on whole-slide images of brain tissue spanning diverse neurodegenerative pathologies. NeuroFM demonstrates superior performance compared to general-purpose models across multiple neuropathology-specific downstream tasks, including mixed dementia disease classification, hippocampal region segmentation, and neurodegenerative ataxia identification encompassing cerebellar essential tremor and spinocerebellar ataxia subtypes. This work establishes that domain-specialized foundation models trained on brain tissue can better capture neuropathology-specific features than models trained on general surgical pathology datasets. By tailoring foundation models to the unique morphological landscape of neurodegenerative diseases, NeuroFM enables more accurate and reliable AI-based analysis for brain disease diagnosis and research, setting a precedent for domain-specific model development in specialized areas of digital pathology.

</details>


### [7] [Lang3D-XL: Language Embedded 3D Gaussians for Large-scale Scenes](https://arxiv.org/abs/2512.07807)
*Shai Krakovsky,Gal Fiebelman,Sagie Benaim,Hadar Averbuch-Elor*

Main category: cs.CV

TL;DR: 论文提出了一种结合极低维语义特征和多分辨率哈希编码的新方法，解决了语义不对齐和效率问题，在HolyScenes数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了解决大规模互联网数据中语义特征不对齐和内存/运行时效率低下的问题，以实现更丰富的空间环境语义理解。

Method: 提出了一种新颖的方法，包括极低维语义瓶颈特征和基于多分辨率哈希编码器的处理，以及Attenuated Downsampler模块和正则化策略。

Result: 在HolyScenes数据集上的评估显示，该方法在性能和效率上均优于现有方法。

Conclusion: 该论文提出的方法在HolyScenes数据集上表现优异，超越了现有方法，并在性能和效率上均有显著提升。

Abstract: Embedding a language field in a 3D representation enables richer semantic understanding of spatial environments by linking geometry with descriptive meaning. This allows for a more intuitive human-computer interaction, enabling querying or editing scenes using natural language, and could potentially improve tasks like scene retrieval, navigation, and multimodal reasoning. While such capabilities could be transformative, in particular for large-scale scenes, we find that recent feature distillation approaches cannot effectively learn over massive Internet data due to challenges in semantic feature misalignment and inefficiency in memory and runtime. To this end, we propose a novel approach to address these challenges. First, we introduce extremely low-dimensional semantic bottleneck features as part of the underlying 3D Gaussian representation. These are processed by rendering and passing them through a multi-resolution, feature-based, hash encoder. This significantly improves efficiency both in runtime and GPU memory. Second, we introduce an Attenuated Downsampler module and propose several regularizations addressing the semantic misalignment of ground truth 2D features. We evaluate our method on the in-the-wild HolyScenes dataset and demonstrate that it surpasses existing approaches in both performance and efficiency.

</details>


### [8] [FishDetector-R1: Unified MLLM-Based Framework with Reinforcement Fine-Tuning for Weakly Supervised Fish Detection, Segmentation, and Counting](https://arxiv.org/abs/2512.05996)
*Yi Liu,Jingyu Song,Vedanth Kallakuri,Katherine A. Skinner*

Main category: cs.CV

TL;DR: FishDetector-R1 是一个基于 MLLM 的弱监督框架，显著提升了鱼类检测、分割和计数的性能，并展示了跨域鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 水下鱼类图像分析对生态监测至关重要，但由于视觉退化和标注成本高，仍然具有挑战性。

Method: 引入了 FishDetector-R1，一个基于 MLLM 的统一框架，用于弱监督下的鱼类检测、分割和计数。关键组件包括新颖的 detect-to-count 提示和 RLVR 奖励设计。

Result: 在 DeepFish 数据集上，框架显著优于基线，AP 提升 20%，mIoU 提升 10%，MAE 降低 30%，GAME 降低 35%。改进还泛化到其他水下数据集。

Conclusion: FishDetector-R1 提供了一种可靠且可扩展的解决方案，通过弱监督实现了准确的海洋视觉理解。

Abstract: Analyzing underwater fish imagery is critical for ecological monitoring but remains difficult due to visual degradation and costly annotations. We introduce FishDetector-R1, a unified MLLM-based framework for fish detection, segmentation, and counting under weak supervision. On the DeepFish dataset, our framework achieves substantial gains over baselines, improving AP by 20% and mIoU by 10%, while reducing MAE by 30% and GAME by 35%. These improvements stem from two key components: a novel detect-to-count prompt that enforces spatially consistent detections and counts, and Reinforcement Learning from Verifiable Reward (RLVR) with a complementary scalable paradigm leveraging sparse point labels. Ablation studies further validate the effectiveness of this reward design. Moreover, the improvement generalizes well to other underwater datasets, confirming strong cross-domain robustness. Overall, FishDetector-R1 provides a reliable and scalable solution for accurate marine visual understanding via weak supervision. The project page for FishDetector-R1 is https://umfieldrobotics.github.io/FishDetector-R1.

</details>


### [9] [PrunedCaps: A Case For Primary Capsules Discrimination](https://arxiv.org/abs/2512.06003)
*Ramin Sharifi,Pouya Shiri,Amirali Baniasadi*

Main category: cs.CV

TL;DR: CapsNets通过剪枝Primary Capsules实现高效运行，速度提升显著且精度不变，部分数据集效果更佳。


<details>
  <summary>Details</summary>
Motivation: CapsNets虽在图像分类上优于CNNs，但其高资源消耗和低效率限制了应用，因此探索剪枝以提升效率。

Method: 研究了在MNIST、Fashion-MNIST、CIFAR-10和SVHN数据集上对CapsNets的Primary Capsules进行剪枝的可能性。

Result: 剪枝后的CapsNet速度提升至多9.9倍，动态路由阶段浮点运算减少95.36%，且精度无损失。

Conclusion: 通过剪枝Primary Capsules，CapsNets在保持精度的同时显著提升了速度和资源效率，部分数据集受益尤为明显。

Abstract: Capsule Networks (CapsNets) are a generation of image classifiers with proven advantages over Convolutional Neural Networks (CNNs). Better robustness to affine transformation and overlapping image detection are some of the benefits associated with CapsNets. However, CapsNets cannot be classified as resource-efficient deep learning architecture due to the high number of Primary Capsules (PCs). In addition, CapsNets' training and testing are slow and resource hungry. This paper investigates the possibility of Primary Capsules pruning in CapsNets on MNIST handwritten digits, Fashion-MNIST, CIFAR-10, and SVHN datasets. We show that a pruned version of CapsNet performs up to 9.90 times faster than the conventional architecture by removing 95 percent of Capsules without a loss of accuracy. Also, our pruned architecture saves on more than 95.36 percent of floating-point operations in the dynamic routing stage of the architecture. Moreover, we provide insight into why some datasets benefit significantly from pruning while others fall behind.

</details>


### [10] [Simple Agents Outperform Experts in Biomedical Imaging Workflow Optimization](https://arxiv.org/abs/2512.06006)
*Xuefei,Wang,Kai A. Horstmann,Ethan Lin,Jonathan Chen,Alexander R. Farhang,Sophia Stiles,Atharva Sehgal,Jonathan Light,David Van Valen,Yisong Yue,Jennifer J. Sun*

Main category: cs.CV

TL;DR: AI代理可自动化定制科学数据集的代码适应，简单框架表现优于人类专家，复杂架构不一定更好，提供了实用设计路线图。


<details>
  <summary>Details</summary>
Motivation: 解决生产级计算机视觉工具适应定制科学数据集的‘最后一英里’瓶颈问题，当前解决方案（微调或手动代码适应）存在不切实际的问题。

Method: 引入了一个系统化的评估框架，用于研究代理代码优化，并应用于三个生产级生物医学成像流程。

Result: 简单代理框架生成的适应代码优于人类专家解决方案，且复杂代理架构并非总是最佳选择。

Conclusion: 研究表明，简单的AI代理框架在生成适应代码方面优于人类专家解决方案，且复杂代理架构并非普遍有益，为代理设计提供了实用路线图。

Abstract: Adapting production-level computer vision tools to bespoke scientific datasets is a critical "last mile" bottleneck. Current solutions are impractical: fine-tuning requires large annotated datasets scientists often lack, while manual code adaptation costs scientists weeks to months of effort. We consider using AI agents to automate this manual coding, and focus on the open question of optimal agent design for this targeted task. We introduce a systematic evaluation framework for agentic code optimization and use it to study three production-level biomedical imaging pipelines. We demonstrate that a simple agent framework consistently generates adaptation code that outperforms human-expert solutions. Our analysis reveals that common, complex agent architectures are not universally beneficial, leading to a practical roadmap for agent design. We open source our framework and validate our approach by deploying agent-generated functions into a production pipeline, demonstrating a clear pathway for real-world impact.

</details>


### [11] [Fast and Flexible Robustness Certificates for Semantic Segmentation](https://arxiv.org/abs/2512.06010)
*Thomas Massena,Corentin Friedrich,Franck Mamalet,Mathieu Serrurier*

Main category: cs.CV

TL;DR: 提出了一种高效训练、内置Lipschitz约束的可证明鲁棒语义分割网络，首次实现实时兼容认证，计算效率显著提升。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络对微小扰动敏感，现有研究主要集中在分类任务上，语义分割的高效认证方法较少。

Method: 引入了一类新的具有内置Lipschitz约束的可证明鲁棒语义分割网络，并提供了一个泛化语义分割任务鲁棒性证书的新框架。

Result: 在Cityscapes等挑战性数据集上实现了具有竞争力的像素精度，认证过程比随机平滑方法快约600倍。

Conclusion: 本研究首次实现了实时兼容的、可证明鲁棒的语义分割，并通过广泛的性能指标计算了在ℓ2攻击半径ε下的最坏情况性能。

Abstract: Deep Neural Networks are vulnerable to small perturbations that can drastically alter their predictions for perceptually unchanged inputs. The literature on adversarially robust Deep Learning attempts to either enhance the robustness of neural networks (e.g, via adversarial training) or to certify their decisions up to a given robustness level (e.g, by using randomized smoothing, formal methods or Lipschitz bounds). These studies mostly focus on classification tasks and few efficient certification procedures currently exist for semantic segmentation. In this work, we introduce a new class of certifiably robust Semantic Segmentation networks with built-in Lipschitz constraints that are efficiently trainable and achieve competitive pixel accuracy on challenging datasets such as Cityscapes. Additionally, we provide a novel framework that generalizes robustness certificates for semantic segmentation tasks, where we showcase the flexibility and computational efficiency of using Lipschitz networks. Our approach unlocks real-time compatible certifiably robust semantic segmentation for the first time. Moreover, it allows the computation of worst-case performance under $\ell_2$ attacks of radius $ε$ across a wide range of performance measures. Crucially, we benchmark the runtime of our certification process and find our approach to be around 600 times faster than randomized smoothing methods at inference with comparable certificates on an NVIDIA A100 GPU. Finally, we evaluate the tightness of our worstcase certificates against state-of-the-art adversarial attacks to further validate the performance of our method.

</details>


### [12] [High-Throughput Unsupervised Profiling of the Morphology of 316L Powder Particles for Use in Additive Manufacturing](https://arxiv.org/abs/2512.06012)
*Emmanuel Akeweje,Conall Kirk,Chi-Wai Chan,Denis Dowling,Mimi Zhang*

Main category: cs.CV

TL;DR: 研究提出了一种机器学习框架，用于自动化分析金属粉末形态，其中Fourier描述符+k-means流程表现最佳，为SLM工艺的原料监测提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 传统的粉末表征方法效率低且定性，无法捕捉工业规模批次的异质性，因此需要一种高吞吐量、自动化的解决方案。

Method: 研究开发了三种聚类流程：自动编码器流程、形状描述符流程和功能数据流程，并通过内部有效性指标评估了它们的性能。

Result: Fourier描述符+k-means流程被证明是最有效的，具有最低的Davies-Bouldin指数和最高的Calinski-Harabasz分数，且计算效率高。

Conclusion: 该研究提出了一种基于机器学习的自动框架，用于大规模分析金属粉末形态，为SLM工艺中的实时原料监测提供了可行路径。

Abstract: Selective Laser Melting (SLM) is a powder-bed additive manufacturing technique whose part quality depends critically on feedstock morphology. However, conventional powder characterization methods are low-throughput and qualitative, failing to capture the heterogeneity of industrial-scale batches. We present an automated, machine learning framework that couples high-throughput imaging with shape extraction and clustering to profile metallic powder morphology at scale. We develop and evaluate three clustering pipelines: an autoencoder pipeline, a shape-descriptor pipeline, and a functional-data pipeline. Across a dataset of approximately 126,000 powder images (0.5-102 micrometer diameter), internal validity metrics identify the Fourier-descriptor + k-means pipeline as the most effective, achieving the lowest Davies-Bouldin index and highest Calinski-Harabasz score while maintaining sub-millisecond runtime per particle on a standard desktop workstation. Although the present work focuses on establishing the morphological-clustering framework, the resulting shape groups form a basis for future studies examining their relationship to flowability, packing density, and SLM part quality. Overall, this unsupervised learning framework enables rapid, automated assessment of powder morphology and supports tracking of shape evolution across reuse cycles, offering a path toward real-time feedstock monitoring in SLM workflows.

</details>


### [13] [VAT: Vision Action Transformer by Unlocking Full Representation of ViT](https://arxiv.org/abs/2512.06013)
*Wenhao Li,Chengwei Ma,Weixin Mao*

Main category: cs.CV

TL;DR: VAT是一种新型架构，通过利用ViT的全部特征层次，显著提升了机器人模仿学习的性能，平均成功率98.15%。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅使用ViT最后一层的特征，丢弃了有价值的信息，导致表示不足。

Method: 提出Vision Action Transformer (VAT)，扩展自ViT，通过处理跨所有Transformer层的视觉特征和专用动作令牌，实现感知与动作生成的深度渐进融合。

Result: 在四个LIBERO基准测试中，VAT平均成功率高达98.15%，超越了OpenVLA-OFT等先前方法，创下新纪录。

Conclusion: VAT通过利用ViT的全部特征层次，在模仿学习中展现出强大的性能，并证明了利用视觉模型的完整‘表示轨迹’对提升机器人策略的重要性。

Abstract: In robot learning, Vision Transformers (ViTs) are standard for visual perception, yet most methods discard valuable information by using only the final layer's features. We argue this provides an insufficient representation and propose the Vision Action Transformer (VAT), a novel architecture that is extended from ViT and unlocks the full feature hierarchy of ViT. VAT processes specialized action tokens with visual features across all transformer layers, enabling a deep and progressive fusion of perception and action generation. On a suite of simulated manipulation tasks, VAT achieves a 98.15\% average success rate across four LIBERO benchmarks, establishing a new state-of-the-art by outperforming prior methods like OpenVLA-OFT. Our work presents not only a powerful model for imitation learning but also demonstrates the critical importance of leveraging the complete ''representation trajectory'' of vision models to advance robotic policy. The GitHub URL for the project code is https://github.com/sellerbubble/VAT.

</details>


### [14] [Benchmarking CXR Foundation Models With Publicly Available MIMIC-CXR and NIH-CXR14 Datasets](https://arxiv.org/abs/2512.06014)
*Jiho Shin,Dominic Marshall,Matthieu Komorowski*

Main category: cs.CV

TL;DR: 研究比较了两种胸部X射线嵌入模型，MedImageInsight表现略优，CXR-Foundation跨数据集稳定性更强，强调了标准化评估的必要性。


<details>
  <summary>Details</summary>
Motivation: 尽管近期的基础模型在医学图像表示学习中表现出色，但其在不同数据集上的比较行为尚未充分探索。

Method: 使用统一的预处理流程和固定的下游分类器评估两种大型胸部X射线嵌入模型（CXR-Foundation和MedImageInsight），在MIMIC-CR和NIH ChestX-ray14数据集上提取嵌入并训练轻量级LightGBM分类器。

Result: MedImageInsight在大多数任务中表现略优，而CXR-Foundation展现出较强的跨数据集稳定性。MedImageInsight的无监督聚类进一步揭示了与定量结果一致的疾病特异性结构。

Conclusion: 研究强调了标准化评估医学基础模型的必要性，并为未来多模态和临床整合研究建立了可重复的基线。

Abstract: Recent foundation models have demonstrated strong performance in medical image representation learning, yet their comparative behaviour across datasets remains underexplored. This work benchmarks two large-scale chest X-ray (CXR) embedding models (CXR-Foundation (ELIXR v2.0) and MedImagelnsight) on public MIMIC-CR and NIH ChestX-ray14 datasets. Each model was evaluated using a unified preprocessing pipeline and fixed downstream classifiers to ensure reproducible comparison. We extracted embeddings directly from pre-trained encoders, trained lightweight LightGBM classifiers on multiple disease labels, and reported mean AUROC, and F1-score with 95% confidence intervals. MedImageInsight achieved slightly higher performance across most tasks, while CXR-Foundation exhibited strong cross-dataset stability. Unsupervised clustering of MedImageIn-sight embeddings further revealed a coherent disease-specific structure consistent with quantitative results. The results highlight the need for standardised evaluation of medical foundation models and establish reproducible baselines for future multimodal and clinical integration studies.

</details>


### [15] [PrefGen: Multimodal Preference Learning for Preference-Conditioned Image Generation](https://arxiv.org/abs/2512.06020)
*Wenyi Mo,Tianyu Zhang,Yalong Bai,Ligong Han,Ying Ba,Dimitris N. Metaxas*

Main category: cs.CV

TL;DR: 该研究提出了一种多模态框架，通过MLLM提取用户偏好并注入扩散模型，显著提升个性化图像生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以捕捉用户细微偏好或缺乏有效编码个性化视觉信号的机制。

Method: 提出了一种多模态框架，利用MLLM提取用户表征，并通过偏好导向的视觉问答任务训练。引入两种互补的探测任务（用户间和用户内区分）来隔离偏好相关特征，并设计了基于最大均值差异的对齐损失。

Result: 实验表明，该方法在图像质量和偏好对齐方面显著优于基线。

Conclusion: 该研究通过多模态框架有效提取并注入用户偏好到基于扩散的图像生成中，显著提升了图像质量和偏好对齐。

Abstract: Preference-conditioned image generation seeks to adapt generative models to individual users, producing outputs that reflect personal aesthetic choices beyond the given textual prompt. Despite recent progress, existing approaches either fail to capture nuanced user preferences or lack effective mechanisms to encode personalized visual signals. In this work, we propose a multimodal framework that leverages multimodal large language models (MLLMs) to extract rich user representations and inject them into diffusion-based image generation. We train the MLLM with a preference-oriented visual question answering task to capture fine-grained semantic cues. To isolate preference-relevant features, we introduce two complementary probing tasks: inter-user discrimination to distinguish between different users, and intra-user discrimination to separate liked from disliked content. To ensure compatibility with diffusion text encoders, we design a maximum mean discrepancy-based alignment loss that bridges the modality gap while preserving multimodal structure. The resulting embeddings are used to condition the generator, enabling faithful adherence to both prompts and user preferences. Extensive experiments demonstrate that our method substantially outperforms strong baselines in both image quality and preference alignment, highlighting the effectiveness of representation extraction and alignment for personalized generation.

</details>


### [16] [Neural reconstruction of 3D ocean wave hydrodynamics from camera sensing](https://arxiv.org/abs/2512.06024)
*Jiabin Liu,Zihao Zhou,Jialei Yan,Anxin Guo,Alvise Benetazzo,Hui Li*

Main category: cs.CV

TL;DR: 提出一种注意力增强金字塔神经网络，用于高效高精度的3D波浪表面和速度场重建，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决长期海洋波浪观测任务中密集视觉重建的高计算成本和持续视觉遮挡带来的挑战。

Method: 设计了一个针对波浪运动多尺度和时间连续特性的注意力增强金字塔架构神经网络，结合物理约束进行时间分辨的3D速度场重建。

Result: 实验显示，模型在中央区域实现了毫米级波高预测，主导频率误差低于0.01 Hz，高频谱功率定律精确估计，并在仅1.35秒内完成两百万点的密集重建。

Conclusion: 该论文提出的基于注意力增强金字塔架构的神经网络，在真实海洋条件下实现了毫米级波高预测、高频谱功率定律精确估计以及非线性速度场的高保真3D重建，显著优于传统视觉重建方法。

Abstract: Precise three-dimensional (3D) reconstruction of wave free surfaces and associated velocity fields is essential for developing a comprehensive understanding of ocean physics. To address the high computational cost of dense visual reconstruction in long-term ocean wave observation tasks and the challenges introduced by persistent visual occlusions, we propose an wave free surface visual reconstruction neural network, which is designed as an attention-augmented pyramid architecture tailored to the multi-scale and temporally continuous characteristics of wave motions. Using physics-based constraints, we perform time-resolved reconstruction of nonlinear 3D velocity fields from the evolving free-surface boundary. Experiments under real-sea conditions demonstrate millimetre-level wave elevation prediction in the central region, dominant-frequency errors below 0.01 Hz, precise estimation of high-frequency spectral power laws, and high-fidelity 3D reconstruction of nonlinear velocity fields, while enabling dense reconstruction of two million points in only 1.35 s. Built on a stereo-vision dataset, the model outperforms conventional visual reconstruction approaches and maintains strong generalization in occluded conditions, owing to its global multi-scale attention and its learned encoding of wave propagation dynamics.

</details>


### [17] [The SAM2-to-SAM3 Gap in the Segment Anything Model Family: Why Prompt-Based Expertise Fails in Concept-Driven Image Segmentation](https://arxiv.org/abs/2512.06032)
*Ranjan Sapkota,Konstantinos I. Roumeliotis,Manoj Karkee*

Main category: cs.CV

TL;DR: SAM3与SAM2在概念、架构、数据集、训练和评估上存在根本差异，标志着分割模型的新时代。


<details>
  <summary>Details</summary>
Motivation: 探讨SAM2和SAM3之间的根本性差异，解释为何SAM2的基于提示的分割专业知识无法迁移到SAM3的多模态概念驱动范式。

Method: 通过五个核心组成部分进行分析：(1)概念性差异，(2)架构分歧，(3)数据集和注释差异，(4)训练和超参数区别，(5)评估、指标和失败模式。

Result: SAM3引入了统一的视觉-语言架构，支持开放词汇推理、语义基础、对比对齐和基于示例的概念理解。

Conclusion: SAM3代表了分割基础模型的新类别，标志着概念驱动分割时代的开始。

Abstract: This paper investigates the fundamental discontinuity between the latest two Segment Anything Models: SAM2 and SAM3. We explain why the expertise in prompt-based segmentation of SAM2 does not transfer to the multimodal concept-driven paradigm of SAM3. SAM2 operates through spatial prompts points, boxes, and masks yielding purely geometric and temporal segmentation. In contrast, SAM3 introduces a unified vision-language architecture capable of open-vocabulary reasoning, semantic grounding, contrastive alignment, and exemplar-based concept understanding. We structure this analysis through five core components: (1) a Conceptual Break Between Prompt-Based and Concept-Based Segmentation, contrasting spatial prompt semantics of SAM2 with multimodal fusion and text-conditioned mask generation of SAM3; (2) Architectural Divergence, detailing pure vision-temporal design of SAM2 versus integration of vision-language encoders, geometry and exemplar encoders, fusion modules, DETR-style decoders, object queries, and ambiguity-handling via Mixture-of-Experts in SAM3; (3) Dataset and Annotation Differences, contrasting SA-V video masks with multimodal concept-annotated corpora of SAM3; (4) Training and Hyperparameter Distinctions, showing why SAM2 optimization knowledge does not apply to SAM3; and (5) Evaluation, Metrics, and Failure Modes, outlining the transition from geometric IoU metrics to semantic, open-vocabulary evaluation. Together, these analyses establish SAM3 as a new class of segmentation foundation model and chart future directions for the emerging concept-driven segmentation era.

</details>


### [18] [Representation Learning for Point Cloud Understanding](https://arxiv.org/abs/2512.06058)
*Siming Yan*

Main category: cs.CV

TL;DR: 论文提出整合预训练2D模型提升3D网络训练效果，实验验证其有效性，推动点云表示学习发展。


<details>
  <summary>Details</summary>
Motivation: 随着技术的快速发展，3D数据获取和利用在多个领域日益普及，结合2D图像能提供更全面的环境理解，推动如自动驾驶、机器人等应用的发展。

Method: 论文聚焦于监督表示学习、自监督学习方法和从2D到3D的迁移学习，整合预训练2D模型以支持3D网络训练。

Result: 实验验证了所提方法的有效性，展示了通过整合2D知识提升点云表示学习的潜力。

Conclusion: 该论文提出了一种结合预训练2D模型支持3D网络训练的方法，显著提升了3D理解能力，并通过大量实验验证了其有效性。

Abstract: With the rapid advancement of technology, 3D data acquisition and utilization have become increasingly prevalent across various fields, including computer vision, robotics, and geospatial analysis. 3D data, captured through methods such as 3D scanners, LiDARs, and RGB-D cameras, provides rich geometric, shape, and scale information. When combined with 2D images, 3D data offers machines a comprehensive understanding of their environment, benefiting applications like autonomous driving, robotics, remote sensing, and medical treatment. This dissertation focuses on three main areas: supervised representation learning for point cloud primitive segmentation, self-supervised learning methods, and transfer learning from 2D to 3D. Our approach, which integrates pre-trained 2D models to support 3D network training, significantly improves 3D understanding without merely transforming 2D data. Extensive experiments validate the effectiveness of our methods, showcasing their potential to advance point cloud representation learning by effectively integrating 2D knowledge.

</details>


### [19] [EgoEdit: Dataset, Real-Time Streaming Model, and Benchmark for Egocentric Video Editing](https://arxiv.org/abs/2512.06065)
*Runjia Li,Moayed Haji-Ali,Ashkan Mirzaei,Chaoyang Wang,Arpit Sahni,Ivan Skorokhodov,Aliaksandr Siarohin,Tomas Jakab,Junlin Han,Sergey Tulyakov,Philip Torr,Willi Menapace*

Main category: cs.CV

TL;DR: 本文提出EgoEdit，一个针对自我中心视频编辑的实时指令跟随系统，包括数据集、编辑器和评估套件，显著提升了编辑效果和交互体验。


<details>
  <summary>Details</summary>
Motivation: 自我中心视频编辑面临独特挑战，如快速的自我运动和频繁的手-物交互，导致现有离线编辑方法存在高延迟问题。

Method: 提出了一个完整的自我中心视频编辑生态系统，包括构建EgoEditData数据集、开发EgoEdit视频编辑器以及引入EgoEditBench评估套件。EgoEdit支持实时流式推理，并在单个GPU上运行。

Result: EgoEdit在自我中心编辑任务中显著优于现有方法，同时在通用编辑任务中保持了与最强基线相当的性能。

Conclusion: EgoEdit在自我中心视频编辑任务中表现出色，提供了时间稳定的、符合指令的编辑结果，并在交互延迟方面表现优异。同时，EgoEditData和EgoEditBench将公开供研究社区使用。

Abstract: We study instruction-guided editing of egocentric videos for interactive AR applications. While recent AI video editors perform well on third-person footage, egocentric views present unique challenges - including rapid egomotion and frequent hand-object interactions - that create a significant domain gap. Moreover, existing offline editing pipelines suffer from high latency, limiting real-time interaction. To address these issues, we present a complete ecosystem for egocentric video editing. First, we construct EgoEditData, a carefully designed and manually curated dataset specifically designed for egocentric editing scenarios, featuring rich hand-object interactions, while explicitly preserving hands. Second, we develop EgoEdit, an instruction-following egocentric video editor that supports real-time streaming inference on a single GPU. Finally, we introduce EgoEditBench, an evaluation suite targeting instruction faithfulness, hand and interaction preservation, and temporal stability under egomotion. Across both egocentric and general editing tasks, EgoEdit produces temporally stable, instruction-faithful results with interactive latency. It achieves clear gains on egocentric editing benchmarks-where existing methods struggle-while maintaining performance comparable to the strongest baselines on general editing tasks. EgoEditData and EgoEditBench will be made public for the research community. See our website at https://snap-research.github.io/EgoEdit

</details>


### [20] [Shoot-Bounce-3D: Single-Shot Occlusion-Aware 3D from Lidar by Decomposing Two-Bounce Light](https://arxiv.org/abs/2512.06080)
*Tzofi Klinghoffer,Siddharth Somasundaram,Xiaoyu Xiang,Yuchen Fan,Christian Richardt,Akshat Dave,Ramesh Raskar,Rakesh Ranjan*

Main category: cs.CV

TL;DR: 论文提出了一种数据驱动的方法，利用单光子激光雷达的多重反射光信息，从单次测量中推断出具有遮挡和镜面反射的3D场景几何结构。


<details>
  <summary>Details</summary>
Motivation: 单光子激光雷达可以测量多重反射光，这些光包含额外的信息，可用于恢复密集深度、遮挡几何和材料属性。然而，现有方法仅限于逐点激光照射，论文旨在解决多点同时照射的复杂场景。

Method: 论文提出了一种数据驱动的方法，通过创建大规模模拟数据集（约10万条激光雷达瞬态数据）来学习复杂光传输的先验知识，从而分解多重反射光的构成贡献。

Result: 实验证明，该方法能够从单次测量中推断出具有遮挡和镜面反射的3D几何结构。

Conclusion: 该论文提出了一种数据驱动的方法，利用单光子激光雷达的多重反射光信息，从单次测量中推断出具有遮挡和镜面反射的3D场景几何结构。

Abstract: 3D scene reconstruction from a single measurement is challenging, especially in the presence of occluded regions and specular materials, such as mirrors. We address these challenges by leveraging single-photon lidars. These lidars estimate depth from light that is emitted into the scene and reflected directly back to the sensor. However, they can also measure light that bounces multiple times in the scene before reaching the sensor. This multi-bounce light contains additional information that can be used to recover dense depth, occluded geometry, and material properties. Prior work with single-photon lidar, however, has only demonstrated these use cases when a laser sequentially illuminates one scene point at a time. We instead focus on the more practical - and challenging - scenario of illuminating multiple scene points simultaneously. The complexity of light transport due to the combined effects of multiplexed illumination, two-bounce light, shadows, and specular reflections is challenging to invert analytically. Instead, we propose a data-driven method to invert light transport in single-photon lidar. To enable this approach, we create the first large-scale simulated dataset of ~100k lidar transients for indoor scenes. We use this dataset to learn a prior on complex light transport, enabling measured two-bounce light to be decomposed into the constituent contributions from each laser spot. Finally, we experimentally demonstrate how this decomposed light can be used to infer 3D geometry in scenes with occlusions and mirrors from a single measurement. Our code and dataset are released at https://shoot-bounce-3d.github.io.

</details>


### [21] [BeLLA: End-to-End Birds Eye View Large Language Assistant for Autonomous Driving](https://arxiv.org/abs/2512.06096)
*Karthik Mohan,Sonam Singh,Amit Arvind Kale*

Main category: cs.CV

TL;DR: BeLLA结合360°BEV与语言模型，显著提升自动驾驶问答中的空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在利用多摄像头系统的空间结构或统一空间表示方面存在不足，难以进行自我中心方向、物体关系和更广泛上下文推理。

Method: 提出BeLLA，一种端到端架构，连接统一的360°BEV表示与大型语言模型，用于自动驾驶中的问答任务。

Result: 在NuScenes-QA和DriveLM基准测试中，BeLLA在需要空间推理的问题上表现优异，某些任务绝对提升达+9.3%，其他类别也表现竞争力。

Conclusion: BeLLA架构通过将统一的360°BEV表示与大型语言模型结合，在自动驾驶问答任务中表现出色，尤其在需要空间推理的问题上显著优于现有方法。

Abstract: The rapid development of Vision-Language models (VLMs) and Multimodal Language Models (MLLMs) in autonomous driving research has significantly reshaped the landscape by enabling richer scene understanding, context-aware reasoning, and more interpretable decision-making. However, a lot of existing work often relies on either single-view encoders that fail to exploit the spatial structure of multi-camera systems or operate on aggregated multi-view features, which lack a unified spatial representation, making it more challenging to reason about ego-centric directions, object relations, and the wider context. We thus present BeLLA, an end-to-end architecture that connects unified 360° BEV representations with a large language model for question answering in autonomous driving. We primarily evaluate our work using two benchmarks - NuScenes-QA and DriveLM, where BeLLA consistently outperforms existing approaches on questions that require greater spatial reasoning, such as those involving relative object positioning and behavioral understanding of nearby objects, achieving up to +9.3% absolute improvement in certain tasks. In other categories, BeLLA performs competitively, demonstrating the capability of handling a diverse range of questions.

</details>


### [22] [SpectraIrisPAD: Leveraging Vision Foundation Models for Spectrally Conditioned Multispectral Iris Presentation Attack Detection](https://arxiv.org/abs/2512.06103)
*Raghavendra Ramachandra,Sushma Venkatesh*

Main category: cs.CV

TL;DR: 提出SpectraIrisPAD框架，利用多光谱成像和深度学习提升虹膜呈现攻击检测的泛化能力，并发布新数据集MSIrPAD。


<details>
  <summary>Details</summary>
Motivation: 随着虹膜识别在现实应用中的广泛部署，其易受呈现攻击（PAs）的脆弱性引发关注，需要有效的呈现攻击检测（PAD）方法。

Method: 提出了一种基于DINOv2 Vision Transformer（ViT）的深度学习框架SpectraIrisPAD，结合可学习的光谱位置编码、令牌融合和对比学习，提取区分性特征。

Result: SpectraIrisPAD在未见攻击评估协议下表现优异，全面超越现有方法。

Conclusion: SpectraIrisPAD在检测多种呈现攻击方面表现出卓越的鲁棒性和泛化能力，显著优于现有基线方法。

Abstract: Iris recognition is widely recognized as one of the most accurate biometric modalities. However, its growing deployment in real-world applications raises significant concerns regarding its vulnerability to Presentation Attacks (PAs). Effective Presentation Attack Detection (PAD) is therefore critical to ensure the integrity and security of iris-based biometric systems. While conventional iris recognition systems predominantly operate in the near-infrared (NIR) spectrum, multispectral imaging across multiple NIR bands provides complementary reflectance information that can enhance the generalizability of PAD methods. In this work, we propose \textbf{SpectraIrisPAD}, a novel deep learning-based framework for robust multispectral iris PAD. The SpectraIrisPAD leverages a DINOv2 Vision Transformer (ViT) backbone equipped with learnable spectral positional encoding, token fusion, and contrastive learning to extract discriminative, band-specific features that effectively distinguish bona fide samples from various spoofing artifacts. Furthermore, we introduce a new comprehensive dataset Multispectral Iris PAD (\textbf{MSIrPAD}) with diverse PAIs, captured using a custom-designed multispectral iris sensor operating at five distinct NIR wavelengths (800\,nm, 830\,nm, 850\,nm, 870\,nm, and 980\,nm). The dataset includes 18,848 iris images encompassing eight diverse PAI categories, including five textured contact lenses, print attacks, and display-based attacks. We conduct comprehensive experiments under unseen attack evaluation protocols to assess the generalization capability of the proposed method. SpectraIrisPAD consistently outperforms several state-of-the-art baselines across all performance metrics, demonstrating superior robustness and generalizability in detecting a wide range of presentation attacks.

</details>


### [23] [Explainable Melanoma Diagnosis with Contrastive Learning and LLM-based Report Generation](https://arxiv.org/abs/2512.06105)
*Junwen Zheng,Xinran Xu,Li Rong Wang,Chang Cai,Lucinda Siyun Tan,Dingyuan Wang,Hong Liang Tey,Xiuyi Fan*

Main category: cs.CV

TL;DR: CEFM通过对比学习和对齐临床语义与视觉特征，提升了黑色素瘤分类的准确性和可解释性，实验显示高准确率和AUC，并改善了临床信任。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习模型在黑色素瘤分类中由于不透明和缺乏可解释性而难以获得临床信任的问题。

Method: 采用对比学习作为核心机制，通过双投影头将临床诊断标准（ABC）映射到Vision Transformer嵌入空间，实现临床语义与视觉特征的对齐，并通过自然语言生成将对齐的表征转化为结构化文本解释。

Result: 在公开数据集上达到92.79%的准确率和0.961的AUC，同时在多项可解释性指标上有显著提升。

Conclusion: CEFM成功地将深度学习的高性能分类与临床可解释性结合，通过对比学习和对齐临床语义与视觉特征，显著提升了模型的透明度和临床信任度。

Abstract: Deep learning has demonstrated expert-level performance in melanoma classification, positioning it as a powerful tool in clinical dermatology. However, model opacity and the lack of interpretability remain critical barriers to clinical adoption, as clinicians often struggle to trust the decision-making processes of black-box models. To address this gap, we present a Cross-modal Explainable Framework for Melanoma (CEFM) that leverages contrastive learning as the core mechanism for achieving interpretability. Specifically, CEFM maps clinical criteria for melanoma diagnosis-namely Asymmetry, Border, and Color (ABC)-into the Vision Transformer embedding space using dual projection heads, thereby aligning clinical semantics with visual features. The aligned representations are subsequently translated into structured textual explanations via natural language generation, creating a transparent link between raw image data and clinical interpretation. Experiments on public datasets demonstrate 92.79% accuracy and an AUC of 0.961, along with significant improvements across multiple interpretability metrics. Qualitative analyses further show that the spatial arrangement of the learned embeddings aligns with clinicians' application of the ABC rule, effectively bridging the gap between high-performance classification and clinical trust.

</details>


### [24] [Tracking-Guided 4D Generation: Foundation-Tracker Motion Priors for 3D Model Animation](https://arxiv.org/abs/2512.06158)
*Su Sun,Cheng Zhao,Himangi Mittal,Gaurav Mittal,Rohith Kukkala,Yingjie Victor Chen,Mei Chen*

Main category: cs.CV

TL;DR: Track4DGen通过结合多视角视频扩散模型和点追踪器，解决了动态4D对象生成中的视图差异问题，生成时间一致的高质量4D资产，并创建了新的基准数据集。


<details>
  <summary>Details</summary>
Motivation: 生成动态4D对象的挑战在于需要同时保持外观和运动的一致性，同时抑制伪影和时间漂移。研究假设视图差异源于仅依赖像素或潜在空间的视频扩散损失监督，缺乏显式的时间感知和特征级追踪指导。

Method: Track4DGen是一个两阶段框架，结合了多视角视频扩散模型、基础点追踪器和混合4D高斯泼溅（4D-GS）重建器。第一阶段在扩散生成器中强制执行密集的特征级点对应关系，产生时间一致的特征；第二阶段使用混合运动编码重建动态4D-GS，结合扩散特征和Hex-plane特征，并增强4D球谐函数以提升动态建模的保真度。

Result: Track4DGen在多视角视频生成和4D生成基准测试中超越了基线方法，生成了时间稳定的、可编辑文本的4D资产。

Conclusion: Track4DGen在生成多视角视频和4D资产方面超越了基线方法，提供了时间稳定的、可编辑文本的4D资产。此外，研究团队还创建了Sketchfab28数据集，用于基准测试和未来研究。

Abstract: Generating dynamic 4D objects from sparse inputs is difficult because it demands joint preservation of appearance and motion coherence across views and time while suppressing artifacts and temporal drift. We hypothesize that the view discrepancy arises from supervision limited to pixel- or latent-space video-diffusion losses, which lack explicitly temporally aware, feature-level tracking guidance. We present \emph{Track4DGen}, a two-stage framework that couples a multi-view video diffusion model with a foundation point tracker and a hybrid 4D Gaussian Splatting (4D-GS) reconstructor. The central idea is to explicitly inject tracker-derived motion priors into intermediate feature representations for both multi-view video generation and 4D-GS. In Stage One, we enforce dense, feature-level point correspondences inside the diffusion generator, producing temporally consistent features that curb appearance drift and enhance cross-view coherence. In Stage Two, we reconstruct a dynamic 4D-GS using a hybrid motion encoding that concatenates co-located diffusion features (carrying Stage-One tracking priors) with Hex-plane features, and augment them with 4D Spherical Harmonics for higher-fidelity dynamics modeling. \emph{Track4DGen} surpasses baselines on both multi-view video generation and 4D generation benchmarks, yielding temporally stable, text-editable 4D assets. Lastly, we curate \emph{Sketchfab28}, a high-quality dataset for benchmarking object-centric 4D generation and fostering future research.

</details>


### [25] [Automated Annotation of Shearographic Measurements Enabling Weakly Supervised Defect Detection](https://arxiv.org/abs/2512.06171)
*Jessica Plassmann,Nicolas Schuler,Michael Schuth,Georg von Freymann*

Main category: cs.CV

TL;DR: 论文提出了一种自动化标注方法，利用深度学习从剪切散斑测量中生成缺陷标注，解决了人工标注的痛点，支持可扩展的缺陷检测数据集创建。


<details>
  <summary>Details</summary>
Motivation: 剪切散斑技术虽能高灵敏度检测亚表面缺陷，但工业应用受限，主要原因是缺乏高质量标注数据集，而人工标注费时、主观且难以标准化。

Method: 采用深度学习技术，从剪切散斑测量中自动生成高分辨率的分割和边界框标注。

Result: 评估显示，自动化标注方法在专家标注数据上表现出足够准确性，支持弱监督训练，减少了人工努力。

Conclusion: 该论文提出了一种基于深度学习的自动化工作流程，用于生成剪切散斑测量的缺陷标注，显著减少了人工标注的工作量，并支持可扩展的数据集创建，以实现稳健的缺陷检测。

Abstract: Shearography is an interferometric technique sensitive to surface displacement gradients, providing high sensitivity for detecting subsurface defects in safety-critical components. A key limitation to industrial adoption is the lack of high-quality annotated datasets, since manual labeling remains labor-intensive, subjective, and difficult to standardize. We introduce an automated workflow that generates defect annotations from shearography measurements using deep learning, producing high-resolution segmentation and bounding-box labels. Evaluation against expert-labeled data demonstrates sufficient accuracy to enable weakly supervised training, reducing manual effort and supporting scalable dataset creation for robust defect detection.

</details>


### [26] [Physics-Grounded Shadow Generation from Monocular 3D Geometry Priors and Approximate Light Direction](https://arxiv.org/abs/2512.06174)
*Shilin Hu,Jingyi Xu,Akshat Dave,Dimitris Samaras,Hieu Le*

Main category: cs.CV

TL;DR: 论文提出结合物理建模与深度学习的阴影生成框架：先基于几何和光照物理估计阴影初值，再用扩散模型细化，结果在复杂场景中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于深度学习的阴影生成方法很少利用显式物理建模（几何与光照），而阴影形成的物理原理（遮挡物阻挡光线）能提供更准确的阴影位置和形状。

Method: 首先从单目RGB图像获取近似3D几何（密集点云图）并预测主导光源方向，基于阴影形成的物理原理初步估计阴影位置和形状，随后通过扩散框架细化阴影至逼真高保真外观。

Result: 在DESOBAV2数据集上训练的模型生成的阴影视觉真实且物理一致，尤其在复杂几何或模糊光照场景中优于现有方法。

Conclusion: 该论文提出的结合显式物理建模与深度学习的阴影生成框架，在复杂几何或模糊光照场景中表现优异，生成的阴影既视觉真实又物理一致。

Abstract: Shadow generation aims to produce photorealistic shadows that are visually consistent with object geometry and scene illumination. In the physics of shadow formation, the occluder blocks some light rays casting from the light source that would otherwise arrive at the surface, creating a shadow that follows the silhouette of the occluder. However, such explicit physical modeling has rarely been used in deep-learning-based shadow generation. In this paper, we propose a novel framework that embeds explicit physical modeling - geometry and illumination - into deep-learning-based shadow generation. First, given a monocular RGB image, we obtain approximate 3D geometry in the form of dense point maps and predict a single dominant light direction. These signals allow us to recover fairly accurate shadow location and shape based on the physics of shadow formation. We then integrate this physics-based initial estimate into a diffusion framework that refines the shadow into a realistic, high-fidelity appearance while ensuring consistency with scene geometry and illumination. Trained on DESOBAV2, our model produces shadows that are both visually realistic and physically coherent, outperforming existing approaches, especially in scenes with complex geometry or ambiguous lighting.

</details>


### [27] [Physics-Grounded Attached Shadow Detection Using Approximate 3D Geometry and Light Direction](https://arxiv.org/abs/2512.06179)
*Shilin Hu,Jingyi Xu,Sagnik Das,Dimitris Samaras,Hieu Le*

Main category: cs.CV

TL;DR: 该论文提出了一种联合检测投射和附着阴影的框架，通过闭环推理优化阴影分割和光照估计，实验显示附着阴影检测效果显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有阴影检测方法主要针对投射阴影，缺乏专门用于检测附着阴影的数据集或模型。附着阴影对物体三维结构的定义和场景理解至关重要，因此需要填补这一空白。

Method: 系统包含一个阴影检测模块（分别预测两种阴影类型）和一个光照估计模块（从检测到的阴影推断光源方向）。通过结合表面法线和估计的光源方向，生成几何一致的部分遮挡图，并反馈以优化阴影预测，形成一个闭环推理过程。

Result: 实验结果表明，该迭代的几何-光照推理方法显著改善了附着阴影的检测，BER（平衡错误率）至少降低了33%，同时保持了投射阴影检测的强性能。

Conclusion: 该论文提出的框架通过联合检测投射阴影和附着阴影，并结合场景光照和几何关系进行推理，显著提升了附着阴影的检测效果，同时保持了投射阴影检测的强性能。

Abstract: Attached shadows occur on the surface of the occluder where light cannot reach because of self-occlusion. They are crucial for defining the three-dimensional structure of objects and enhancing scene understanding. Yet existing shadow detection methods mainly target cast shadows, and there are no dedicated datasets or models for detecting attached shadows. To address this gap, we introduce a framework that jointly detects cast and attached shadows by reasoning about their mutual relationship with scene illumination and geometry. Our system consists of a shadow detection module that predicts both shadow types separately, and a light estimation module that infers the light direction from the detected shadows. The estimated light direction, combined with surface normals, allows us to derive a geometry-consistent partial map that identifies regions likely to be self-occluded. This partial map is then fed back to refine shadow predictions, forming a closed-loop reasoning process that iteratively improves both shadow segmentation and light estimation. In order to train our method, we have constructed a dataset of 1,458 images with separate annotations for cast and attached shadows, enabling training and quantitative evaluation of both. Experimental results demonstrate that this iterative geometry-illumination reasoning substantially improves the detection of attached shadows, with at least 33% BER reduction, while maintaining strong full and cast shadow performance.

</details>


### [28] [SPOOF: Simple Pixel Operations for Out-of-Distribution Fooling](https://arxiv.org/abs/2512.06185)
*Ankit Gupta,Christoph Adami,Emily Dolson*

Main category: cs.CV

TL;DR: 研究发现现代深度神经网络（包括卷积和Transformer架构）仍易受高置信度愚弄图像攻击，新方法SPOOF能高效生成此类图像，且现有防御措施效果有限。


<details>
  <summary>Details</summary>
Motivation: 尽管深度神经网络在图像识别任务中表现出色，但仍对与自然图像无关的输入表现出过度自信，这一问题需要重新审视和解决。

Method: 重新实现了基于CPPN和直接编码的进化愚弄攻击，并引入了SPOOF——一种简约、一致且更高效的黑盒攻击方法。

Result: SPOOF能以极少的像素修改和计算量生成高置信度的愚弄图像，且ViT-B/16等现代架构对此类攻击尤为敏感。

Conclusion: 现代深度分类器仍存在脆弱性，即使通过重新训练加入愚弄图像作为额外类别，SPOOF攻击仍能持续有效地生成高置信度的愚弄图像。

Abstract: Deep neural networks (DNNs) excel across image recognition tasks, yet continue to exhibit overconfidence on inputs that bear no resemblance to natural images. Revisiting the "fooling images" work introduced by Nguyen et al. (2015), we re-implement both CPPN-based and direct-encoding-based evolutionary fooling attacks on modern architectures, including convolutional and transformer classifiers. Our re-implementation confirm that high-confidence fooling persists even in state-of-the-art networks, with transformer-based ViT-B/16 emerging as the most susceptible--achieving near-certain misclassifications with substantially fewer queries than convolution-based models. We then introduce SPOOF, a minimalist, consistent, and more efficient black-box attack generating high-confidence fooling images. Despite its simplicity, SPOOF generates unrecognizable fooling images with minimal pixel modifications and drastically reduced compute. Furthermore, retraining with fooling images as an additional class provides only partial resistance, as SPOOF continues to fool consistently with slightly higher query budgets--highlighting persistent fragility of modern deep classifiers.

</details>


### [29] [Multi-Modal Zero-Shot Prediction of Color Trajectories in Food Drying](https://arxiv.org/abs/2512.06190)
*Shichen Li,Ahmadreza Eslaminia,Chenhui Shao*

Main category: cs.CV

TL;DR: 论文提出了一种多模态颜色轨迹预测方法，显著提升了食品干燥过程中颜色预测的准确性和泛化能力，实验结果显示误差降低90%以上。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要依赖低维颜色特征，无法全面捕捉食品样品复杂动态的颜色轨迹，且现有建模方法缺乏对未知工艺条件的泛化能力。

Method: 整合高维时间颜色信息与干燥工艺参数，开发了一种数据高效的颜色轨迹预测模型。

Result: 在未知干燥条件下，模型对饼干和苹果干燥的RMSE分别为2.12和1.29，比基线模型误差降低90%以上。

Conclusion: 该论文提出了一种新型多模态颜色轨迹预测方法，显著提高了食品干燥过程中颜色轨迹预测的准确性和泛化能力。

Abstract: Food drying is widely used to reduce moisture content, ensure safety, and extend shelf life. Color evolution of food samples is an important indicator of product quality in food drying. Although existing studies have examined color changes under different drying conditions, current approaches primarily rely on low-dimensional color features and cannot fully capture the complex, dynamic color trajectories of food samples. Moreover, existing modeling approaches lack the ability to generalize to unseen process conditions. To address these limitations, we develop a novel multi-modal color-trajectory prediction method that integrates high-dimensional temporal color information with drying process parameters to enable accurate and data-efficient color trajectory prediction. Under unseen drying conditions, the model attains RMSEs of 2.12 for cookie drying and 1.29 for apple drying, reducing errors by over 90% compared with baseline models. These experimental results demonstrate the model's superior accuracy, robustness, and broad applicability.

</details>


### [30] [The MICCAI Federated Tumor Segmentation (FeTS) Challenge 2024: Efficient and Robust Aggregation Methods for Federated Learning](https://arxiv.org/abs/2512.06206)
*Akis Linardos,Sarthak Pati,Ujjwal Baid,Brandon Edwards,Patrick Foley,Kevin Ta,Verena Chung,Micah Sheller,Muhammad Irfan Khan,Mojtaba Jafaritadi,Elina Kontio,Suleiman Khan,Leon Mächler,Ivan Ezhov,Suprosanna Shit,Johannes C. Paetzold,Gustav Grimberg,Manuel A. Nickel,David Naccache,Vasilis Siomos,Jonathan Passerat-Palmbach,Giacomo Tarroni,Daewoon Kim,Leonard L. Klausmann,Prashant Shah,Bjoern Menze,Dimitrios Makris,Spyridon Bakas*

Main category: cs.CV

TL;DR: MICCAI FeTS挑战赛2024评估了联邦学习在胶质瘤分割中的应用，PID控制器方法在性能和效率上表现最优。


<details>
  <summary>Details</summary>
Motivation: 旨在通过联邦学习提高胶质瘤亚区分割的鲁棒性和效率。

Method: 使用标准化的联邦学习设置和多机构数据集，评估了六支参与团队的新权重聚合方法。

Result: 基于PID控制器的方法在分割性能（DSC和HD95）和通信效率（收敛分数）上表现最佳。

Conclusion: PID控制器作为一种有效的机制，在联邦学习中稳定和优化权重聚合，推动了医学影像联邦学习的进展。

Abstract: We present the design and results of the MICCAI Federated Tumor Segmentation (FeTS) Challenge 2024, which focuses on federated learning (FL) for glioma sub-region segmentation in multi-parametric MRI and evaluates new weight aggregation methods aimed at improving robustness and efficiency. Six participating teams were evaluated using a standardized FL setup and a multi-institutional dataset derived from the BraTS glioma benchmark, consisting of 1,251 training cases, 219 validation cases, and 570 hidden test cases with segmentations for enhancing tumor (ET), tumor core (TC), and whole tumor (WT). Teams were ranked using a cumulative scoring system that considered both segmentation performance, measured by Dice Similarity Coefficient (DSC) and the 95th percentile Hausdorff Distance (HD95), and communication efficiency assessed through the convergence score. A PID-controller-based method achieved the top overall ranking, obtaining mean DSC values of 0.733, 0.761, and 0.751 for ET, TC, and WT, respectively, with corresponding HD95 values of 33.922 mm, 33.623 mm, and 32.309 mm, while also demonstrating the highest communication efficiency with a convergence score of 0.764. These findings advance the state of federated learning for medical imaging, surpassing top-performing methods from previous challenge iterations and highlighting PID controllers as effective mechanisms for stabilizing and optimizing weight aggregation in FL. The challenge code is available at https://github.com/FeTS-AI/Challenge.

</details>


### [31] [Revisiting SVD and Wavelet Difference Reduction for Lossy Image Compression: A Reproducibility Study](https://arxiv.org/abs/2512.06221)
*Alena Makarova*

Main category: cs.CV

TL;DR: 研究发现SVD+WDR图像压缩技术并未如原始论文声称的那样在PSNR上超越JPEG2000或WDR，仅在SSIM上有部分改进，并揭示了描述不明确对可重复性的影响。


<details>
  <summary>Details</summary>
Motivation: 对一种结合奇异值分解（SVD）和小波差缩减（WDR）的有损图像压缩技术进行独立的可重复性研究，验证原始论文声称的SVD+WDR在视觉质量和压缩比上优于JPEG2000和独立WDR的结论。

Method: 重新实现了提出的方法，仔细检查了缺失的实现细节，并尽可能接近地复制了原始实验。此外，还在新图像上进行了额外实验，并使用PSNR和SSIM评估了性能。

Result: 结果表明，SVD+WDR技术在PSNR上通常不优于JPEG2000或WDR，仅在SSIM上相对于JPEG2000有部分改进。

Conclusion: 该研究揭示了原始论文中描述的不明确之处（如量化和阈值初始化）如何显著影响可重复性和报告的性能，并表明SVD+WDR技术通常在PSNR上并未超越JPEG2000或WDR，仅在SSIM上相对于JPEG2000有部分改进。

Abstract: This work presents an independent reproducibility study of a lossy image compression technique that integrates singular value decomposition (SVD) and wavelet difference reduction (WDR). The original paper claims that combining SVD and WDR yields better visual quality and higher compression ratios than JPEG2000 and standalone WDR. I re-implemented the proposed method, carefully examined missing implementation details, and replicated the original experiments as closely as possible. I then conducted additional experiments on new images and evaluated performance using PSNR and SSIM. In contrast to the original claims, my results indicate that the SVD+WDR technique generally does not surpass JPEG2000 or WDR in terms of PSNR, and only partially improves SSIM relative to JPEG2000. The study highlights ambiguities in the original description (e.g., quantization and threshold initialization) and illustrates how such gaps can significantly impact reproducibility and reported performance.

</details>


### [32] [GPU-GLMB: Assessing the Scalability of GPU-Accelerated Multi-Hypothesis Tracking](https://arxiv.org/abs/2512.06230)
*Pranav Balakrishnan,Sidisha Barik,Sean M. O'Rourke,Benjamin M. Marlin*

Main category: cs.CV

TL;DR: 改进的GLMB滤波器通过允许多次检测，显著提升并行性和GPU部署效率，适用于分布式虚拟传感器网络。


<details>
  <summary>Details</summary>
Motivation: 标准GLMB滤波器在多假设维护下计算成本高昂，限制了其在分布式网络中的实际应用。

Method: 研究聚焦于广义标记多伯努利（GLMB）滤波器，探索其变体以支持分布式机器学习虚拟传感器网络中的多目标跟踪。

Result: 初步分析显示，GPU加速实现的GLMB跟踪器在对象数量和保留假设数量方面具有优异的运行时扩展性。

Conclusion: 该研究提出了一种改进的GLMB滤波器变体，通过允许每个对象从同一传感器产生多次检测，显著提高了并行扩展性和GPU硬件上的部署效率。

Abstract: Much recent research on multi-target tracking has focused on multi-hypothesis approaches leveraging random finite sets. Of particular interest are labeled random finite set methods that maintain temporally coherent labels for each object. While these methods enjoy important theoretical properties as closed-form solutions to the multi-target Bayes filter, the maintenance of multiple hypotheses under the standard measurement model is highly computationally expensive, even when hypothesis pruning approximations are applied. In this work, we focus on the Generalized Labeled Multi-Bernoulli (GLMB) filter as an example of this class of methods. We investigate a variant of the filter that allows multiple detections per object from the same sensor, a critical capability when deploying tracking in the context of distributed networks of machine learning-based virtual sensors. We show that this breaks the inter-detection dependencies in the filter updates of the standard GLMB filter, allowing updates with significantly improved parallel scalability and enabling efficient deployment on GPU hardware. We report the results of a preliminary analysis of a GPU-accelerated implementation of our proposed GLMB tracker, with a focus on run time scalability with respect to the number of objects and the maximum number of retained hypotheses.

</details>


### [33] [Opinion: Learning Intuitive Physics May Require More than Visual Data](https://arxiv.org/abs/2512.06232)
*Ellen Su,Solim Legris,Todd M. Gureckis,Mengye Ren*

Main category: cs.CV

TL;DR: 研究显示，当前架构在仅使用发展上真实的数据集训练时，无法有效学习支持直觉物理的表征。


<details>
  <summary>Details</summary>
Motivation: 研究数据分布而非数据量是否是学习直觉物理原理的关键。

Method: 在SAYCam（一个发展上真实、以自我为中心的视频数据集）上预训练视频联合嵌入预测架构（V-JEPA）模型。

Result: 在IntPhys2基准测试中，训练于SAYCam数据集（仅占SOTA模型数据量的0.01%）并未带来显著性能提升。

Conclusion: 仅靠改变视觉数据的量和分布可能不足以构建具有人工直觉物理的系统。

Abstract: Humans expertly navigate the world by building rich internal models founded on an intuitive understanding of physics. Meanwhile, despite training on vast quantities of internet video data, state-of-the-art deep learning models still fall short of human-level performance on intuitive physics benchmarks. This work investigates whether data distribution, rather than volume, is the key to learning these principles. We pretrain a Video Joint Embedding Predictive Architecture (V-JEPA) model on SAYCam, a developmentally realistic, egocentric video dataset partially capturing three children's everyday visual experiences. We find that training on this dataset, which represents 0.01% of the data volume used to train SOTA models, does not lead to significant performance improvements on the IntPhys2 benchmark. Our results suggest that merely training on a developmentally realistic dataset is insufficient for current architectures to learn representations that support intuitive physics. We conclude that varying visual data volume and distribution alone may not be sufficient for building systems with artificial intuitive physics.

</details>


### [34] [NexusFlow: Unifying Disparate Tasks under Partial Supervision via Invertible Flow Networks](https://arxiv.org/abs/2512.06251)
*Fangzhou Lin,Yuping Wang,Yuliang Guo,Zixun Huang,Xinyu Huang,Haichong Zhang,Kazunori Yamada,Zhengzhong Tu,Liu Ren,Ziming Zhang*

Main category: cs.CV

TL;DR: NexusFlow通过可逆耦合层对齐异构任务特征，在标注不全时实现高效知识迁移，在自动驾驶和密集预测任务中均表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要针对同质密集预测任务，忽视了结构多样化任务的学习挑战。NexusFlow旨在解决异构任务在标注不完整情况下的知识迁移问题。

Method: NexusFlow采用轻量级、即插即用的框架，通过可逆耦合层将不同任务的潜在特征映射到共享的规范空间，避免表示崩溃并保持表达能力。

Result: 在nuScenes自动驾驶数据集和NYUv2数据集上，NexusFlow均超越了现有部分监督基线，展示了其广泛适用性。

Conclusion: NexusFlow通过引入可逆耦合层和对齐任务潜在特征分布，成功解决了异构任务间的知识迁移问题，在自动驾驶和NYUv2数据集上均取得了最优性能。

Abstract: Partially Supervised Multi-Task Learning (PS-MTL) aims to leverage knowledge across tasks when annotations are incomplete. Existing approaches, however, have largely focused on the simpler setting of homogeneous, dense prediction tasks, leaving the more realistic challenge of learning from structurally diverse tasks unexplored. To this end, we introduce NexusFlow, a novel, lightweight, and plug-and-play framework effective in both settings. NexusFlow introduces a set of surrogate networks with invertible coupling layers to align the latent feature distributions of tasks, creating a unified representation that enables effective knowledge transfer. The coupling layers are bijective, preserving information while mapping features into a shared canonical space. This invertibility avoids representational collapse and enables alignment across structurally different tasks without reducing expressive capacity. We first evaluate NexusFlow on the core challenge of domain-partitioned autonomous driving, where dense map reconstruction and sparse multi-object tracking are supervised in different geographic regions, creating both structural disparity and a strong domain gap. NexusFlow sets a new state-of-the-art result on nuScenes, outperforming strong partially supervised baselines. To demonstrate generality, we further test NexusFlow on NYUv2 using three homogeneous dense prediction tasks, segmentation, depth, and surface normals, as a representative N-task PS-MTL scenario. NexusFlow yields consistent gains across all tasks, confirming its broad applicability.

</details>


### [35] [Language-driven Fine-grained Retrieval](https://arxiv.org/abs/2512.06255)
*Shijie Wang,Xin Yu,Yadan Luo,Zijian Wang,Pengfei Zhang,Zi Huang*

Main category: cs.CV

TL;DR: LaFG利用LLMs和VLMs将类别名称转化为属性级监督，提升细粒度图像检索的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的细粒度图像检索方法依赖语义稀疏的独热标签作为监督，忽略了类别名称中丰富的语义信息，限制了跨类别细节的可比性建模和对未见类别的泛化能力。

Method: LaFG利用大型语言模型（LLMs）生成详细的属性导向描述，并通过冻结的视觉语言模型（VLMs）将这些描述投影到视觉对齐空间，形成数据集范围的属性词汇表。然后，通过全局提示模板选择类别相关属性，聚合成类别特定的语言原型，用于监督检索模型。

Result: LaFG框架通过语言驱动的属性级监督，有效提升了细粒度图像检索的泛化性能，特别是在未见类别上表现突出。

Conclusion: LaFG框架通过利用LLMs和VLMs将类别名称转化为属性级监督，显著提升了细粒度图像检索的泛化能力，特别是在未见类别上表现优异。

Abstract: Existing fine-grained image retrieval (FGIR) methods learn discriminative embeddings by adopting semantically sparse one-hot labels derived from category names as supervision. While effective on seen classes, such supervision overlooks the rich semantics encoded in category names, hindering the modeling of comparability among cross-category details and, in turn, limiting generalization to unseen categories. To tackle this, we introduce LaFG, a Language-driven framework for Fine-Grained Retrieval that converts class names into attribute-level supervision using large language models (LLMs) and vision-language models (VLMs). Treating each name as a semantic anchor, LaFG prompts an LLM to generate detailed, attribute-oriented descriptions. To mitigate attribute omission in these descriptions, it leverages a frozen VLM to project them into a vision-aligned space, clustering them into a dataset-wide attribute vocabulary while harvesting complementary attributes from related categories. Leveraging this vocabulary, a global prompt template selects category-relevant attributes, which are aggregated into category-specific linguistic prototypes. These prototypes supervise the retrieval model to steer

</details>


### [36] [Knowing the Answer Isn't Enough: Fixing Reasoning Path Failures in LVLMs](https://arxiv.org/abs/2512.06258)
*Chaoyang Wang,Yangfan He,Yiyang Zhou,Yixuan Wang,Jiaqi Liu,Peng Xia,Zhengzhong Tu,Mohit Bansal,Huaxiu Yao*

Main category: cs.CV

TL;DR: PSO框架通过GRPO和在线优化解决LVLMs的路径选择偏差问题，显著提升推理准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 揭示大型视觉语言模型（LVLMs）存在路径选择偏差问题，即使知道正确答案也常通过错误推理路径得出，导致结果不稳定。

Method: 提出了PSO（路径选择优化）框架，包括GRPO（组相对策略优化）和在线偏好优化两个阶段，结合负向回放记忆（NRM）避免重复错误。

Result: 实验表明PSO平均提升推理准确性7.4%，并生成更稳定的思维链。

Conclusion: PSO框架通过两阶段优化显著提升了大型视觉语言模型的推理准确性和稳定性，有效减少了无效推理路径。

Abstract: We reveal a critical yet underexplored flaw in Large Vision-Language Models (LVLMs): even when these models know the correct answer, they frequently arrive there through incorrect reasoning paths. The core issue is not a lack of knowledge, but a path selection bias within the vast reasoning search space. Although LVLMs are often capable of sampling correct solution trajectories, they disproportionately favor unstable or logically inconsistent ones, leading to erratic and unreliable outcomes. The substantial disparity between Pass@K (with large K) and Pass@1 across numerous models provides compelling evidence that such failures primarily stem from misreasoning rather than ignorance. To systematically investigate and address this issue, we propose PSO (Path-Select Optimization), a two-stage post-training framework designed to enhance both the reasoning performance and stability of existing LVLMs. In the first stage, we employ Group Relative Policy Optimization (GRPO) with template and answer-based rewards to cultivate structured, step-by-step reasoning. In the second stage, we conduct online preference optimization, where the model samples reasoning paths from GRPO-generated data, self-evaluates them, and aligns itself toward the preferred trajectories. Incorrect or suboptimal paths are concurrently stored in a Negative Replay Memory (NRM) as hard negatives, which are periodically revisited to prevent the model from repeating prior mistakes and to facilitate continual reasoning refinement. Extensive experiments show that PSO effectively prunes invalid reasoning paths, substantially enhances reasoning accuracy (with 7.4% improvements on average), and yields more stable and consistent chains of thought. Our code will be available at https://github.com/aiming-lab/PSO.

</details>


### [37] [TriaGS: Differentiable Triangulation-Guided Geometric Consistency for 3D Gaussian Splatting](https://arxiv.org/abs/2512.06269)
*Quan Tran,Tuan Dang*

Main category: cs.CV

TL;DR: 提出一种增强3D高斯重建全局几何一致性的方法，通过多视角三角测量优化，显著减少伪影并提升重建质量，在DTU数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统3D高斯重建仅依赖光度损失，导致重建不一致性（如“漂浮物”伪影和非结构化几何），限制了高保真表面的提取。

Method: 提出了一种通过约束多视角三角测量来增强全局几何一致性的新方法，通过自监督方式优化渲染3D点与鲁棒共识点的偏差。

Result: 在多个数据集上验证了方法的有效性，尤其在DTU数据集上达到了0.50 mm的平均Chamfer Distance，表现优于同类方法。

Conclusion: 通过引入全局几何一致性约束，该方法显著减少了3D高斯重建中的不一致性，实现了更高的重建保真度，并在DTU数据集上取得了0.50 mm的平均Chamfer Distance，优于同类显式方法。

Abstract: 3D Gaussian Splatting is crucial for real-time novel view synthesis due to its efficiency and ability to render photorealistic images. However, building a 3D Gaussian is guided solely by photometric loss, which can result in inconsistencies in reconstruction. This under-constrained process often results in "floater" artifacts and unstructured geometry, preventing the extraction of high-fidelity surfaces. To address this issue, our paper introduces a novel method that improves reconstruction by enforcing global geometry consistency through constrained multi-view triangulation. Our approach aims to achieve a consensus on 3D representation in the physical world by utilizing various estimated views. We optimize this process by penalizing the deviation of a rendered 3D point from a robust consensus point, which is re-triangulated from a bundle of neighboring views in a self-supervised fashion. We demonstrate the effectiveness of our method across multiple datasets, achieving state-of-the-art results. On the DTU dataset, our method attains a mean Chamfer Distance of 0.50 mm, outperforming comparable explicit methods. We will make our code open-source to facilitate community validation and ensure reproducibility.

</details>


### [38] [FacePhys: State of the Heart Learning](https://arxiv.org/abs/2512.06275)
*Kegang Wang,Jiankai Tang,Yuntao Wang,Xin Liu,Yuxuan Fan,Jiatong Ji,Yuanchun Shi,Daniel McDuff*

Main category: cs.CV

TL;DR: FacePhys是一种高效rPPG算法，通过时空状态空间对偶性解决了模型可扩展性、跨数据集泛化和实时操作问题，显著提升了性能并降低了资源消耗。


<details>
  <summary>Details</summary>
Motivation: 利用摄像头进行生命体征测量（如rPPG技术）为舒适、普适的健康监测提供了可能，但现有技术在前端设备计算限制和压缩通道传输导致信号质量下降方面存在局限性。

Method: 提出了一种基于时空状态空间对偶性的内存高效rPPG算法FacePhys，利用可转移的心脏状态捕捉视频帧间的细微周期性变化，同时保持计算开销最小。

Result: FacePhys在误差上显著降低了49%，内存占用仅为3.6 MB，每帧延迟9.46 ms，比现有方法提升了83%至99%。

Conclusion: FacePhys通过时空状态空间对偶性解决了模型可扩展性、跨数据集泛化和实时操作的三难问题，显著提升了rPPG技术的实用性，实现了实时推断且内存占用极低。

Abstract: Vital sign measurement using cameras presents opportunities for comfortable, ubiquitous health monitoring. Remote photoplethysmography (rPPG), a foundational technology, enables cardiac measurement through minute changes in light reflected from the skin. However, practical deployment is limited by the computational constraints of performing analysis on front-end devices and the accuracy degradation of transmitting data through compressive channels that reduce signal quality. We propose a memory efficient rPPG algorithm - \emph{FacePhys} - built on temporal-spatial state space duality, which resolves the trilemma of model scalability, cross-dataset generalization, and real-time operation. Leveraging a transferable heart state, FacePhys captures subtle periodic variations across video frames while maintaining a minimal computational overhead, enabling training on extended video sequences and supporting low-latency inference. FacePhys establishes a new state-of-the-art, with a substantial 49\% reduction in error. Our solution enables real-time inference with a memory footprint of 3.6 MB and per-frame latency of 9.46 ms -- surpassing existing methods by 83\% to 99\%. These results translate into reliable real-time performance in practical deployments, and a live demo is available at https://www.facephys.com/.

</details>


### [39] [RefBench-PRO: Perceptual and Reasoning Oriented Benchmark for Referring Expression Comprehension](https://arxiv.org/abs/2512.06276)
*Tianyi Gao,Hao Li,Han Fang,Xin Wei,Xiaodong Dong,Hongbo Sun,Ye Yuan,Zhongjiang He,Jinglin Xu,Jingmin Xin,Hao Sun*

Main category: cs.CV

TL;DR: RefBench-PRO 是一个新的 REC 基准，通过分解指代表达为感知和推理任务，提供可解释的评估，并提出了 Ref-R1 学习方案提升定位准确性。


<details>
  <summary>Details</summary>
Motivation: 现有 REC 基准主要评估感知能力，缺乏可解释的评分机制，无法揭示 MLLM 在不同认知能力上的接地能力。

Method: 提出了 RefBench-PRO 基准，分解指代表达为感知和推理两个维度，并细分为六个任务。开发了自动化数据生成流程，并提出 Ref-R1 学习方案，结合动态 IoU 的 GRPO 提升定位准确性。

Result: 实验表明，RefBench-PRO 能够对 MLLM 进行可解释的评估，并在感知和推理方面提出更大挑战。

Conclusion: RefBench-PRO 通过分解指代表达为感知和推理两个核心维度，并进一步细分为六个渐进挑战性任务，为多模态大语言模型（MLLM）提供了可解释的评估基准。Ref-R1 学习方案通过动态 IoU 的 GRPO 提高了定位准确性，为 REC 建立了更强的基线。

Abstract: Referring Expression Comprehension (REC) is a vision-language task that localizes a specific image region based on a textual description. Existing REC benchmarks primarily evaluate perceptual capabilities and lack interpretable scoring mechanisms, which cannot reveal the grounding capability of Multi-modal Large Language Model (MLLM) across different cognitive abilities. To address this limitation, we introduce RefBench-PRO, a comprehensive REC benchmark, which decomposes referring expressions into two core dimensions, i.e., perception and reasoning, and further subdivides them into six progressively challenging tasks, such as attribute, position, interaction, commonsense, relation and reject. We also develop a fully automated data-generation pipeline that produces diverse referring expressions across these six sub-dimensions. Furthermore, We propose Ref-R1, an RL-based learning scheme, which incorporates Dynamic IoU-based GRPO to improve localization accuracy under increasingly complex reasoning conditions, establishing a stronger baseline for REC. Extensive experiments demonstrate that our RefBench-PRO enables interpretable evaluation of MLLM on referring expression comprehension, presenting greater challenges in both perception and reasoning.

</details>


### [40] [Unleashing the Intrinsic Visual Representation Capability of Multimodal Large Language Models](https://arxiv.org/abs/2512.06281)
*Hengzhuang Li,Xinsong Zhang,Qiming Peng,Bin Luo,Han Hu,Dengyang Jiang,Han-Jia Ye,Teng Zhang,Hai Jin*

Main category: cs.CV

TL;DR: LaVer通过潜在视觉重建解决MLLMs的模态不平衡问题，提升视觉信息利用率，实验表现优越。


<details>
  <summary>Details</summary>
Motivation: MLLMs存在模态不平衡问题，视觉信息在深层网络中利用率不足，导致视觉性能下降或幻觉现象。

Method: 提出了一种名为Latent Visual Reconstruction (LaVer)的训练框架，通过在LLM的联合潜在语义空间中进行掩码图像建模，增强视觉表示的学习。

Result: 实验证明LaVer在多种基准测试中表现优越，特别是在需要密集视觉能力的场景中。

Conclusion: LaVer框架通过潜在视觉重建有效解决了MLLMs中的模态不平衡问题，提升了视觉信息的利用率，尤其在密集视觉任务中表现优越。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated remarkable proficiency in multimodal tasks. Despite their impressive performance, MLLMs suffer from the modality imbalance issue, where visual information is often underutilized compared to textual representations in deeper layers, leading to degraded visual performance or hallucinations. This issue stems from the predominant reliance on next-text-token-prediction during training, which fails to provide direct visual supervisory signals, resulting in progressive homogenization of visual representations throughout the layers. To this end, we propose Latent Visual Reconstruction (LaVer), a novel training framework that facilitates MLLMs in learning more discriminative visual representations via masked image modeling in the joint latent semantic space of LLM. Our method offers direct visual activation to MLLMs, which exhibit increased visual attention allocation, indicating enhanced utilization of visual information. Extensive experiments across diverse benchmarks prove the superiority of our approach in various scenarios, especially those requiring dense visual capabilities. Code of LaVer is available at https://github.com/Fir-lat/LaVer.

</details>


### [41] [A Sleep Monitoring System Based on Audio, Video and Depth Information](https://arxiv.org/abs/2512.06282)
*Lyn Chao-ling Chen,Kuan-Wen Chen,Yi-Ping Hung*

Main category: cs.CV

TL;DR: 开发了一种基于事件的非侵入式睡眠监测系统，通过红外深度传感器、RGB摄像头和麦克风阵列检测运动、光照和噪音事件，实验验证了系统可靠性。


<details>
  <summary>Details</summary>
Motivation: 开发一种非侵入式监测系统，用于在家中环境下定量评估睡眠干扰，以提供更准确的睡眠质量评估。

Method: 使用带有红外深度传感器、RGB摄像头和四麦克风阵列的设备，在几乎无光源的环境中监测睡眠。通过深度信号建立背景模型以测量运动幅度，通过彩色图像建立另一个背景模型以测量光照变化幅度，并采用事件检测算法从三种传感器的处理数据中检测事件发生。

Result: 系统在睡眠条件下进行了测试，实验结果验证了系统的可靠性。

Conclusion: 该系统通过引入基于事件的方法，成功开发了一种非侵入式睡眠监测系统，能够在家中环境下定量评估睡眠干扰，并通过实验验证了系统的可靠性。

Abstract: For quantitative evaluation of sleep disturbances, a noninvasive monitoring system is developed by introducing an event-based method. We observe sleeping in home context and classify the sleep disturbances into three types of events: motion events, light-on/off events and noise events. A device with an infrared depth sensor, a RGB camera, and a four-microphone array is used in sleep monitoring in an environment with barely light sources. One background model is established in depth signals for measuring magnitude of movements. Because depth signals cannot observe lighting changes, another background model is established in color images for measuring magnitude of lighting effects. An event detection algorithm is used to detect occurrences of events from the processed data of the three types of sensors. The system was tested in sleep condition and the experiment result validates the system reliability.

</details>


### [42] [StrokeNet: Unveiling How to Learn Fine-Grained Interactions in Online Handwritten Stroke Classification](https://arxiv.org/abs/2512.06290)
*Yiheng Huang,Shuang She,Zewei Wei,Jianmin Lin,Ming Yang,Wenyin Liu*

Main category: cs.CV

TL;DR: StrokeNet通过参考点对表示和CEQ机制，显著提升笔画分类性能，CASIA-onDo准确率达95.54%。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法难以捕捉笔画间细粒度语义关系，而点级视角虽能解决但引入冗余。通过选择参考点并利用其顺序表示笔画，可有效解决此问题。

Method: 提出StrokeNet，采用参考点对表示（点+特征向量）编码笔画，结合Inline Sequence Attention模块和Cross-Ellipse Query机制，通过联合优化框架预测笔画类别和相邻笔画语义转移。

Result: 在CASIA-onDo数据集上，准确率从93.81%提升至95.54%，验证了方法的有效性和鲁棒性。

Conclusion: StrokeNet通过创新的参考点对表示和CEQ机制，显著提升了笔画分类的准确性和鲁棒性，在多个公开数据集上达到了最先进的性能。

Abstract: Stroke classification remains challenging due to variations in writing style, ambiguous content, and dynamic writing positions. The core challenge in stroke classification is modeling the semantic relationships between strokes. Our observations indicate that stroke interactions are typically localized, making it difficult for existing deep learning methods to capture such fine-grained relationships. Although viewing strokes from a point-level perspective can address this issue, it introduces redundancy. However, by selecting reference points and using their sequential order to represent strokes in a fine-grained manner, this problem can be effectively solved. This insight inspired StrokeNet, a novel network architecture encoding strokes as reference pair representations (points + feature vectors), where reference points enable spatial queries and features mediate interaction modeling. Specifically, we dynamically select reference points for each stroke and sequence them, employing an Inline Sequence Attention (ISA) module to construct contextual features. To capture spatial feature interactions, we devised a Cross-Ellipse Query (CEQ) mechanism that clusters reference points and extracts features across varying spatial scales. Finally, a joint optimization framework simultaneously predicts stroke categories via reference points regression and adjacent stroke semantic transition modeling through an Auxiliary Branch (Aux-Branch). Experimental results show that our method achieves state-of-the-art performance on multiple public online handwritten datasets. Notably, on the CASIA-onDo dataset, the accuracy improves from 93.81$\%$ to 95.54$\%$, demonstrating the effectiveness and robustness of our approach.

</details>


### [43] [Exploiting Spatiotemporal Properties for Efficient Event-Driven Human Pose Estimation](https://arxiv.org/abs/2512.06306)
*Haoxian Zhou,Chuanzhi Xu,Langyi Chen,Haodong Chen,Yuk Ying Chung,Qiang Qu,Xaoming Chen,Weidong Cai*

Main category: cs.CV

TL;DR: 提出了一种基于点云框架的人体姿态估计方法，利用事件流的时空特性，通过新设计的卷积和时间建模模块，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将事件流转换为密集事件帧，这不仅增加了额外计算负担，还牺牲了事件信号的高时间分辨率。因此，本研究旨在利用事件流的时空特性，基于点云框架提升人体姿态估计性能。

Method: 设计了Event Temporal Slicing Convolution模块以捕获事件切片间的短期依赖关系，并结合Event Slice Sequencing模块进行结构化时间建模。此外，在基于点云的事件表示中应用边缘增强技术，以在稀疏事件条件下增强空间边缘信息。

Result: 在DHP19数据集上的实验表明，所提方法在三种代表性点云骨干网络上均能一致提升性能。

Conclusion: 该论文提出了一种基于点云框架的新方法，通过利用事件流的时空特性，显著提升了人体姿态估计的性能。实验结果表明，该方法在DHP19数据集上对三种代表性点云骨干网络（PointNet、DGCNN和Point Transformer）均有效。

Abstract: Human pose estimation focuses on predicting body keypoints to analyze human motion. Event cameras provide high temporal resolution and low latency, enabling robust estimation under challenging conditions. However, most existing methods convert event streams into dense event frames, which adds extra computation and sacrifices the high temporal resolution of the event signal. In this work, we aim to exploit the spatiotemporal properties of event streams based on point cloud-based framework, designed to enhance human pose estimation performance. We design Event Temporal Slicing Convolution module to capture short-term dependencies across event slices, and combine it with Event Slice Sequencing module for structured temporal modeling. We also apply edge enhancement in point cloud-based event representation to enhance spatial edge information under sparse event conditions to further improve performance. Experiments on the DHP19 dataset show our proposed method consistently improves performance across three representative point cloud backbones: PointNet, DGCNN, and Point Transformer.

</details>


### [44] [ReCAD: Reinforcement Learning Enhanced Parametric CAD Model Generation with Vision-Language Models](https://arxiv.org/abs/2512.06328)
*Jiahao Li,Yusheng Luo,Yunzhong Lou,Xiangdong Zhou*

Main category: cs.CV

TL;DR: ReCAD利用强化学习框架结合预训练大模型，显著提升多模态输入生成CAD模型的精度和语义保真度，超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖监督微调，编辑支持有限且未充分利用预训练大模型的生成先验，ReCAD旨在解决这些问题。

Method: 框架首先微调视觉语言模型以生成基本CAD模型，随后提出一种新颖的强化学习策略，结合参数化代码指导模型推理，并采用分层原始学习过程逐步教授结构化技能。

Result: ReCAD在文本到CAD和图像到CAD任务中均达到新最先进水平，几何精度显著提升，例如图像到CAD任务中平均Chamfer距离从73.47降至29.61（分布内）和从272.06降至80.23（分布外）。

Conclusion: ReCAD通过强化学习框架结合预训练大模型，显著提升了从多模态输入生成精确参数化CAD模型的能力，并在几何精度和语义保真度上实现了新的最先进水平。

Abstract: We present ReCAD, a reinforcement learning (RL) framework that bootstraps pretrained large models (PLMs) to generate precise parametric computer-aided design (CAD) models from multimodal inputs by leveraging their inherent generative capabilities. With just access to simple functional interfaces (e.g., point coordinates), our approach enables the emergence of complex CAD operations (e.g., pattern replication and mirror). This stands in contrast to previous methods, which typically rely on knowledge injected through supervised fine-tuning (SFT), offer limited support for editability, and fail to exploit the strong generative priors of PLMs. Specifically, the ReCAD framework begins by fine-tuning vision-language models (VLMs) to equip them with basic CAD model generation capabilities, where we rewrite CAD scripts into parameterized code that is leveraged to generate accurate textual descriptions for supervision. Then, we propose a novel RL strategy that incorporates parameterized code as guidance to enhance the model's reasoning on challenging questions. Furthermore, we employ a hierarchical primitive learning process to progressively teach structured and compositional skills under a unified reward function that ensures both geometric accuracy and semantic fidelity. ReCAD sets a new state-of-the-art in both text-to-CAD and image-to-CAD tasks, significantly improving geometric accuracy across in-distribution and out-of-distribution settings. In the image-to-CAD task, for instance, it reduces the mean Chamfer Distance from 73.47 to 29.61 (in-distribution) and from 272.06 to 80.23 (out-of-distribution), outperforming existing baselines by a substantial margin.

</details>


### [45] [S2WMamba: A Spectral-Spatial Wavelet Mamba for Pansharpening](https://arxiv.org/abs/2512.06330)
*Haoyu Zhang,Junhan Luo,Yugang Cao,Siran Peng,Jie Huang,Liangjian-Deng*

Main category: cs.CV

TL;DR: S2WMamba通过双分支结构和DWT解耦频率信息，实现高效的Pansharpening，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决Pansharpening中空间细节与光谱保真度纠缠的问题，提升HRMS图像生成质量。

Method: 提出S2WMamba方法，使用2D和1D Haar DWT分别处理PAN和MS图像，通过双分支结构和Mamba-based跨调制实现长程依赖建模，最后通过多尺度动态门融合分支输出。

Result: 在WV3、GF2和QB数据集上，S2WMamba的PSNR提升高达0.23 dB，HQNR达到0.956，优于现有基线。

Conclusion: S2WMamba通过显式解耦频率信息并进行轻量级跨模态交互，在多个数据集上匹配或超越了现有基线，证明了其方法的有效性。

Abstract: Pansharpening fuses a high-resolution PAN image with a low-resolution multispectral (LRMS) image to produce an HRMS image. A key difficulty is that jointly processing PAN and MS often entangles spatial detail with spectral fidelity. We propose S2WMamba, which explicitly disentangles frequency information and then performs lightweight cross-modal interaction. Concretely, a 2D Haar DWT is applied to PAN to localize spatial edges and textures, while a channel-wise 1D Haar DWT treats each pixel's spectrum as a 1D signal to separate low/high-frequency components and limit spectral distortion. The resulting Spectral branch injects wavelet-extracted spatial details into MS features, and the Spatial branch refines PAN features using spectra from the 1D pyramid; the two branches exchange information through Mamba-based cross-modulation that models long-range dependencies with linear complexity. A multi-scale dynamic gate (multiplicative + additive) then adaptively fuses branch outputs.On WV3, GF2, and QB, S2WMamba matches or surpasses recent strong baselines (FusionMamba, CANNet, U2Net, ARConv), improving PSNR by up to 0.23 dB and reaching HQNR 0.956 on full-resolution WV3. Ablations justify the choice of 2D/1D DWT placement, parallel dual branches, and the fusion gate. Our code is available at https://github.com/KagUYa66/S2WMamba.

</details>


### [46] [CryoHype: Reconstructing a thousand cryo-EM structures with transformer-based hypernetworks](https://arxiv.org/abs/2512.06332)
*Jeffrey Gu,Minkyu Jeon,Ambri Ma,Serena Yeung-Levy,Ellen D. Zhong*

Main category: cs.CV

TL;DR: CryoHype是一种基于transformer的超网络，用于cryo-EM多目标结构重建，解决了现有方法无法处理的组成异质性，并在大规模数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常专注于单个或少数结构的构象异质性建模，无法解决由许多不同分子种类混合物引起的组成异质性。

Method: 提出了CryoHype，一种基于transformer的超网络，用于动态调整隐式神经表示的权重，以解决cryo-EM中多目标结构重建的问题。

Result: 在包含100个结构的基准数据集上取得了最先进的结果，并展示了在固定姿态下从无标记图像重建1,000个不同结构的能力。

Conclusion: CryoHype通过基于transformer的超网络动态调整隐式神经表示的权重，成功解决了cryo-EM中多目标结构重建的挑战，并在包含100个结构的基准数据集上取得了最先进的结果，甚至能够扩展到固定姿态下从无标记图像重建1,000个不同结构。

Abstract: Cryo-electron microscopy (cryo-EM) is an indispensable technique for determining the 3D structures of dynamic biomolecular complexes. While typically applied to image a single molecular species, cryo-EM has the potential for structure determination of many targets simultaneously in a high-throughput fashion. However, existing methods typically focus on modeling conformational heterogeneity within a single or a few structures and are not designed to resolve compositional heterogeneity arising from mixtures of many distinct molecular species. To address this challenge, we propose CryoHype, a transformer-based hypernetwork for cryo-EM reconstruction that dynamically adjusts the weights of an implicit neural representation. Using CryoHype, we achieve state-of-the-art results on a challenging benchmark dataset containing 100 structures. We further demonstrate that CryoHype scales to the reconstruction of 1,000 distinct structures from unlabeled cryo-EM images in the fixed-pose setting.

</details>


### [47] [Beyond Hallucinations: A Multimodal-Guided Task-Aware Generative Image Compression for Ultra-Low Bitrate](https://arxiv.org/abs/2512.06344)
*Kaile Wang,Lijun He,Haisheng Fu,Haixia Bi,Fan Li*

Main category: cs.CV

TL;DR: MTGC框架通过多模态引导和任务感知设计，解决了超低比特率下生成图像压缩的语义偏差问题，显著提升了语义一致性和图像质量。


<details>
  <summary>Details</summary>
Motivation: 生成图像压缩在超低比特率下存在语义偏差问题，限制了其在6G语义通信场景中的可靠部署。

Method: 提出MTGC框架，整合三种引导模态（文本标题、高压缩图像、语义伪词）和双路径协同引导机制（MGDD），利用扩散模型的生成先验进行图像重建。

Result: 实验表明，MTGC在DIV2K数据集上显著提升语义一致性（如DISTS下降10.59%），同时在感知质量和像素级保真度上也有显著提升。

Conclusion: MTGC框架通过整合多模态引导，显著提升了超低比特率下生成图像压缩的语义一致性和感知质量。

Abstract: Generative image compression has recently shown impressive perceptual quality, but often suffers from semantic deviations caused by generative hallucinations at ultra-low bitrate (bpp < 0.05), limiting its reliable deployment in bandwidth-constrained 6G semantic communication scenarios. In this work, we reassess the positioning and role of of multimodal guidance, and propose a Multimodal-Guided Task-Aware Generative Image Compression (MTGC) framework. Specifically, MTGC integrates three guidance modalities to enhance semantic consistency: a concise but robust text caption for global semantics, a highly compressed image (HCI) retaining low-level visual information, and Semantic Pseudo-Words (SPWs) for fine-grained task-relevant semantics. The SPWs are generated by our designed Task-Aware Semantic Compression Module (TASCM), which operates in a task-oriented manner to drive the multi-head self-attention mechanism to focus on and extract semantics relevant to the generation task while filtering out redundancy. Subsequently, to facilitate the synergistic guidance of these modalities, we design a Multimodal-Guided Diffusion Decoder (MGDD) employing a dual-path cooperative guidance mechanism that synergizes cross-attention and ControlNet additive residuals to precisely inject these three guidance into the diffusion process, and leverages the diffusion model's powerful generative priors to reconstruct the image. Extensive experiments demonstrate that MTGC consistently improves semantic consistency (e.g., DISTS drops by 10.59% on the DIV2K dataset) while also achieving remarkable gains in perceptual quality and pixel-level fidelity at ultra-low bitrate.

</details>


### [48] [CLUENet: Cluster Attention Makes Neural Networks Have Eyes](https://arxiv.org/abs/2512.06345)
*Xiangshuai Song,Jun-Jie Huang,Tianrui Liu,Ke Liang,Chang Tang*

Main category: cs.CV

TL;DR: CLUENet通过创新聚类注意力机制，解决了现有视觉模型在透明度和灵活性上的不足，显著提升了分类性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 卷积和注意力模型在视觉任务中虽成功，但其刚性感受野和复杂架构限制了其对不规则空间模式的建模能力，并阻碍了模型透明度，而聚类范式虽具可解释性和灵活语义建模潜力，但存在精度低、效率差和训练梯度消失问题。

Method: 提出了CLUENet，包括三个关键创新：(i) 全局软聚合与硬分配，采用温度缩放余弦注意力和门控残差连接增强局部建模；(ii) 块间硬和共享特征分发；(iii) 改进的聚类池化策略。

Result: 在CIFAR-100和Mini-ImageNet上的实验表明，CLUENet在准确性、效率和透明度方面达到了优于现有聚类方法和主流视觉模型的平衡。

Conclusion: CLUENet提出了一种透明的深度架构，用于视觉语义理解，通过三个关键创新显著提升了分类性能和视觉可解释性，在CIFAR-100和Mini-ImageNet上表现优于现有聚类方法和主流视觉模型。

Abstract: Despite the success of convolution- and attention-based models in vision tasks, their rigid receptive fields and complex architectures limit their ability to model irregular spatial patterns and hinder interpretability, therefore posing challenges for tasks requiring high model transparency. Clustering paradigms offer promising interpretability and flexible semantic modeling, but suffer from limited accuracy, low efficiency, and gradient vanishing during training. To address these issues, we propose CLUster attEntion Network (CLUENet), an transparent deep architecture for visual semantic understanding. We propose three key innovations include (i) a Global Soft Aggregation and Hard Assignment with a Temperature-Scaled Cosin Attention and gated residual connections for enhanced local modeling, (ii) inter-block Hard and Shared Feature Dispatching, and (iii) an improved cluster pooling strategy. These enhancements significantly improve both classification performance and visual interpretability. Experiments on CIFAR-100 and Mini-ImageNet demonstrate that CLUENet outperforms existing clustering methods and mainstream visual models, offering a compelling balance of accuracy, efficiency, and transparency.

</details>


### [49] [TreeQ: Pushing the Quantization Boundary of Diffusion Transformer via Tree-Structured Mixed-Precision Search](https://arxiv.org/abs/2512.06353)
*Kaicheng Yang,Kaisen Yang,Baiting Wu,Xun Zhang,Qianrui Yang,Haotong Qin,He Zhang,Yulun Zhang*

Main category: cs.CV

TL;DR: TreeQ框架通过TSS、ENG和GMB技术，解决了DiT量化中的关键挑战，实现了高效的4位量化。


<details>
  <summary>Details</summary>
Motivation: DiT架构在真实部署中面临高计算和内存需求，而现有的Mixed-Precision Quantization（MPQ）方法在DiT上的应用有限。

Method: 提出了TreeQ框架，包括Tree Structured Search（TSS）、Environmental Noise Guidance（ENG）和General Monarch Branch（GMB）三个关键技术。

Result: TreeQ在W3A3和W4A4 PTQ/PEFT设置下表现出色，首次实现4位PTQ接近无损性能。

Conclusion: TreeQ框架在DiT-XL/2模型上实现了最先进的性能，首次在4位PTQ设置下达到接近无损的效果。

Abstract: Diffusion Transformers (DiTs) have emerged as a highly scalable and effective backbone for image generation, outperforming U-Net architectures in both scalability and performance. However, their real-world deployment remains challenging due to high computational and memory demands. Mixed-Precision Quantization (MPQ), designed to push the limits of quantization, has demonstrated remarkable success in advancing U-Net quantization to sub-4bit settings while significantly reducing computational and memory overhead. Nevertheless, its application to DiT architectures remains limited and underexplored. In this work, we propose TreeQ, a unified framework addressing key challenges in DiT quantization. First, to tackle inefficient search and proxy misalignment, we introduce Tree Structured Search (TSS). This DiT-specific approach leverages the architecture's linear properties to traverse the solution space in O(n) time while improving objective accuracy through comparison-based pruning. Second, to unify optimization objectives, we propose Environmental Noise Guidance (ENG), which aligns Post-Training Quantization (PTQ) and Quantization-Aware Training (QAT) configurations using a single hyperparameter. Third, to mitigate information bottlenecks in ultra-low-bit regimes, we design the General Monarch Branch (GMB). This structured sparse branch prevents irreversible information loss, enabling finer detail generation. Through extensive experiments, our TreeQ framework demonstrates state-of-the-art performance on DiT-XL/2 under W3A3 and W4A4 PTQ/PEFT settings. Notably, our work is the first to achieve near-lossless 4-bit PTQ performance on DiT models. The code and models will be available at https://github.com/racoonykc/TreeQ

</details>


### [50] [Rectifying Latent Space for Generative Single-Image Reflection Removal](https://arxiv.org/abs/2512.06358)
*Mingjia Li,Jin Hu,Hainuo Wang,Qiming Hu,Jiarui Wang,Xiaojie Guo*

Main category: cs.CV

TL;DR: 本文提出了一种基于潜在扩散模型的单图像反射去除方法，通过三个关键组件实现了SOTA性能，并在真实场景中表现出色。


<details>
  <summary>Details</summary>
Motivation: 单图像反射去除是一个高度不适定问题，现有方法难以理解受损区域的组成，导致在恢复和泛化方面表现不佳。

Method: 方法包括三个协同组件：反射等变VAE、可学习的任务特定文本嵌入以及深度引导的早期分支采样策略。

Result: 该模型在多个基准测试中表现出色，并且在真实场景中具有强大的泛化能力。

Conclusion: 该模型在多个基准测试中取得了新的SOTA性能，并且在具有挑战性的真实场景中表现出良好的泛化能力。

Abstract: Single-image reflection removal is a highly ill-posed problem, where existing methods struggle to reason about the composition of corrupted regions, causing them to fail at recovery and generalization in the wild. This work reframes an editing-purpose latent diffusion model to effectively perceive and process highly ambiguous, layered image inputs, yielding high-quality outputs. We argue that the challenge of this conversion stems from a critical yet overlooked issue, i.e., the latent space of semantic encoders lacks the inherent structure to interpret a composite image as a linear superposition of its constituent layers. Our approach is built on three synergistic components, including a reflection-equivariant VAE that aligns the latent space with the linear physics of reflection formation, a learnable task-specific text embedding for precise guidance that bypasses ambiguous language, and a depth-guided early-branching sampling strategy to harness generative stochasticity for promising results. Extensive experiments reveal that our model achieves new SOTA performance on multiple benchmarks and generalizes well to challenging real-world cases.

</details>


### [51] [Spoofing-aware Prompt Learning for Unified Physical-Digital Facial Attack Detection](https://arxiv.org/abs/2512.06363)
*Jiabao Guo,Yadian Wang,Hui Ma,Yuhao Fu,Ju Jia,Hui Liu,Shengeng Tang,Lechao Cheng,Yunfeng Diao,Ajian Liu*

Main category: cs.CV

TL;DR: SPL-UAD框架通过解耦物理和数字攻击的优化分支，结合自适应提示生成和数据增强，显著提升了统一攻击检测性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界的人脸识别系统容易受到物理呈现攻击和数字伪造攻击的影响，现有方法在物理和数字攻击检测之间存在优化方向冲突。

Method: 提出了一种可学习的并行提示分支，结合自适应欺骗上下文提示生成，独立控制每种攻击类型的优化。此外，设计了Cues-awareness Augmentation，利用双提示机制生成具有挑战性的样本挖掘任务。

Result: 在大规模UniAttackDataPlus数据集上的实验表明，该方法在统一攻击检测任务中取得了显著的性能提升。

Conclusion: SPL-UAD框架通过解耦物理和数字攻击的优化分支，显著提升了统一攻击检测任务的性能。

Abstract: Real-world face recognition systems are vulnerable to both physical presentation attacks (PAs) and digital forgery attacks (DFs). We aim to achieve comprehensive protection of biometric data by implementing a unified physical-digital defense framework with advanced detection. Existing approaches primarily employ CLIP with regularization constraints to enhance model generalization across both tasks. However, these methods suffer from conflicting optimization directions between physical and digital attack detection under same category prompt spaces. To overcome this limitation, we propose a Spoofing-aware Prompt Learning for Unified Attack Detection (SPL-UAD) framework, which decouples optimization branches for physical and digital attacks in the prompt space. Specifically, we construct a learnable parallel prompt branch enhanced with adaptive Spoofing Context Prompt Generation, enabling independent control of optimization for each attack type. Furthermore, we design a Cues-awareness Augmentation that leverages the dual-prompt mechanism to generate challenging sample mining tasks on data, significantly enhancing the model's robustness against unseen attack types. Extensive experiments on the large-scale UniAttackDataPlus dataset demonstrate that the proposed method achieves significant performance improvements in unified attack detection tasks.

</details>


### [52] [Human3R: Incorporating Human Priors for Better 3D Dynamic Reconstruction from Monocular Videos](https://arxiv.org/abs/2512.06368)
*Weitao Xiong,Zhiyuan Yuan,Jiahao Lu,Chengfeng Zhao,Peng Li,Yuan Liu*

Main category: cs.CV

TL;DR: Human3R结合SMPL和单目深度估计，通过分层流程和特征融合模块，显著提升了动态人体场景的重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏对人体结构的3D理解，导致几何不一致和分辨率退化问题，亟需结合结构化先验以提升重建质量。

Method: 提出了一种分层处理流程，结合SMPL先验和特征融合模块，通过全分辨率图像处理场景几何，再通过策略性裁剪和交叉注意力融合增强人体细节。

Result: 在TUM Dynamics和GTA-IM数据集上的实验表明，Human3R在动态人体重建中表现优异。

Conclusion: Human3R通过结合SMPL人体模型和单目深度估计，解决了动态人体场景重建中的几何不一致和分辨率退化问题，显著提升了重建质量。

Abstract: Monocular dynamic video reconstruction faces significant challenges in dynamic human scenes due to geometric inconsistencies and resolution degradation issues. Existing methods lack 3D human structural understanding, producing geometrically inconsistent results with distorted limb proportions and unnatural human-object fusion, while memory-constrained downsampling causes human boundary drift toward background geometry. To address these limitations, we propose to incorporate hybrid geometric priors that combine SMPL human body models with monocular depth estimation. Our approach leverages structured human priors to maintain surface consistency while capturing fine-grained geometric details in human regions. We introduce Human3R, featuring a hierarchical pipeline with refinement components that processes full-resolution images for overall scene geometry, then applies strategic cropping and cross-attention fusion for human-specific detail enhancement. The method integrates SMPL priors through a Feature Fusion Module to ensure geometrically plausible reconstruction while preserving fine-grained human boundaries. Extensive experiments on TUM Dynamics and GTA-IM datasets demonstrate superior performance in dynamic human reconstruction.

</details>


### [53] [VG-Refiner: Towards Tool-Refined Referring Grounded Reasoning via Agentic Reinforcement Learning](https://arxiv.org/abs/2512.06373)
*Yuji Wang,Wenlong Liu,Jingxuan Niu,Haoji Zhang,Yansong Tang*

Main category: cs.CV

TL;DR: VG-Refiner是首个针对工具细化引用接地推理的框架，通过两阶段机制和细化奖励提升准确性，同时提出新评估指标。


<details>
  <summary>Details</summary>
Motivation: 现有工具集成视觉推理（TiVR）范式主要关注通过强化学习整合各种视觉工具，但忽视了设计有效响应机制处理不可靠或错误工具输出的问题，尤其是在引用和接地任务中。

Method: 提出了VG-Refiner框架，包括两阶段思考-重新思考机制和细化奖励，以显式分析并响应工具反馈。此外，提出了两个新指标和公平评估协议。

Result: VG-Refiner在引用和接地基准测试中显著提高了准确性和纠正能力，同时保持了预训练模型的通用能力。

Conclusion: VG-Refiner通过引入两阶段思考-重新思考机制和细化奖励，显著提升了在引用和接地任务中的准确性和纠正能力，同时保持了预训练模型的通用能力。

Abstract: Tool-integrated visual reasoning (TiVR) has demonstrated great potential in enhancing multimodal problem-solving. However, existing TiVR paradigms mainly focus on integrating various visual tools through reinforcement learning, while neglecting to design effective response mechanisms for handling unreliable or erroneous tool outputs. This limitation is particularly pronounced in referring and grounding tasks, where inaccurate detection tool predictions often mislead TiVR models into generating hallucinated reasoning. To address this issue, we propose the VG-Refiner, the first framework aiming at the tool-refined referring grounded reasoning. Technically, we introduce a two-stage think-rethink mechanism that enables the model to explicitly analyze and respond to tool feedback, along with a refinement reward that encourages effective correction in response to poor tool results. In addition, we propose two new metrics and establish fair evaluation protocols to systematically measure the refinement ability of current models. We adopt a small amount of task-specific data to enhance the refinement capability of VG-Refiner, achieving a significant improvement in accuracy and correction ability on referring and reasoning grounding benchmarks while preserving the general capabilities of the pretrained model.

</details>


### [54] [Are AI-Generated Driving Videos Ready for Autonomous Driving? A Diagnostic Evaluation Framework](https://arxiv.org/abs/2512.06376)
*Xinhao Xiang,Abhijeet Rastogi,Jiawei Zhang*

Main category: cs.CV

TL;DR: AI生成驾驶视频（AIGVs）通过ADGVE筛选后能有效补充自动驾驶数据，但需避免直接使用原始数据以免降低性能。


<details>
  <summary>Details</summary>
Motivation: 探讨AI生成的驾驶视频（AIGVs）是否能可靠支持自动驾驶模型的训练与评估，填补低成本、可扩展数据替代方案的潜力与风险的研究空白。

Method: 提出了一个诊断框架，包括构建ADGV-Bench基准（带有人工质量标注和多感知任务密集标签）和开发ADGVE评估器（结合静态语义、时序线索、车道遵守信号及VLM引导推理生成视频质量评分）。

Result: 实验证明，ADGVE筛选的AIGVs可提升视频质量评估指标及下游模型性能，成为真实数据的有效补充。

Conclusion: 研究表明，盲目添加原始AI生成驾驶视频（AIGVs）会降低感知性能，但通过ADGVE筛选后，不仅能提升视频质量评估指标，还能改善下游自动驾驶模型性能，使AIGVs成为真实数据的有效补充。

Abstract: Recent text-to-video models have enabled the generation of high-resolution driving scenes from natural language prompts. These AI-generated driving videos (AIGVs) offer a low-cost, scalable alternative to real or simulator data for autonomous driving (AD). But a key question remains: can such videos reliably support training and evaluation of AD models? We present a diagnostic framework that systematically studies this question. First, we introduce a taxonomy of frequent AIGV failure modes, including visual artifacts, physically implausible motion, and violations of traffic semantics, and demonstrate their negative impact on object detection, tracking, and instance segmentation. To support this analysis, we build ADGV-Bench, a driving-focused benchmark with human quality annotations and dense labels for multiple perception tasks. We then propose ADGVE, a driving-aware evaluator that combines static semantics, temporal cues, lane obedience signals, and Vision-Language Model(VLM)-guided reasoning into a single quality score for each clip. Experiments show that blindly adding raw AIGVs can degrade perception performance, while filtering them with ADGVE consistently improves both general video quality assessment metrics and downstream AD models, and turns AIGVs into a beneficial complement to real-world data. Our study highlights both the risks and the promise of AIGVs, and provides practical tools for safely leveraging large-scale video generation in future AD pipelines.

</details>


### [55] [VAD-Net: Multidimensional Facial Expression Recognition in Intelligent Education System](https://arxiv.org/abs/2512.06377)
*Yi Huo,Yun Ge*

Main category: cs.CV

TL;DR: 研究在FER2013中新增D维度标注，并利用正交卷积提升VAD预测性能，公开了数据集和代码。


<details>
  <summary>Details</summary>
Motivation: 当前FER数据集的情感标签（如快乐、愤怒等）表达力有限，未来情感计算需要更全面的VAD多维参数。AffectNet虽补充了VA信息，但仍缺乏D维度。

Method: 研究在FER2013数据集中标注了VAD（效价-唤醒-支配性）维度，并采用正交卷积以增强网络特征提取能力。

Result: 实验表明D维度可测量但较VA维度更难获取；正交卷积的引入验证了其能提升VAD预测效果。

Conclusion: 该研究通过在FER2013数据集中标注D（支配性）维度，并引入正交卷积提升网络性能，为VAD多维情感预测提供了新的数据集和基线模型。

Abstract: Current FER (Facial Expression Recognition) dataset is mostly labeled by emotion categories, such as happy, angry, sad, fear, disgust, surprise, and neutral which are limited in expressiveness. However, future affective computing requires more comprehensive and precise emotion metrics which could be measured by VAD(Valence-Arousal-Dominance) multidimension parameters. To address this, AffectNet has tried to add VA (Valence and Arousal) information, but still lacks D(Dominance). Thus, the research introduces VAD annotation on FER2013 dataset, takes the initiative to label D(Dominance) dimension. Then, to further improve network capacity, it enforces orthogonalized convolution on it, which extracts more diverse and expressive features and will finally increase the prediction accuracy. Experiment results show that D dimension could be measured but is difficult to obtain compared with V and A dimension no matter in manual annotation or regression network prediction. Secondly, the ablation test by introducing orthogonal convolution verifies that better VAD prediction could be obtained in the configuration of orthogonal convolution. Therefore, the research provides an initiative labelling for D dimension on FER dataset, and proposes a better prediction network for VAD prediction through orthogonal convolution. The newly built VAD annotated FER2013 dataset could act as a benchmark to measure VAD multidimensional emotions, while the orthogonalized regression network based on ResNet could act as the facial expression recognition baseline for VAD emotion prediction. The newly labeled dataset and implementation code is publicly available on https://github.com/YeeHoran/VAD-Net .

</details>


### [56] [OCFER-Net: Recognizing Facial Expression in Online Learning System](https://arxiv.org/abs/2512.06379)
*Yi Huo,Lei Zhang*

Main category: cs.CV

TL;DR: 该论文提出OCFER-Net，通过正交卷积核正则化提升FER性能，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 在线学习中情感互动至关重要，而现有面部表情识别（FER）方法较少利用卷积矩阵的正交性。

Method: 提出了一种正交卷积核正则化方法，通过强制卷积核的正交性来提取更具多样性和表达力的特征。

Result: 在FER-2013数据集上的实验显示，OCFER-Net的性能优于基线方法1.087%。

Conclusion: 通过正交卷积核正则化方法（OCFER-Net）显著提升了面部表情识别的准确性，实验结果表明其性能优于基线方法1.087%。

Abstract: Recently, online learning is very popular, especially under the global epidemic of COVID-19. Besides knowledge distribution, emotion interaction is also very important. It can be obtained by employing Facial Expression Recognition (FER). Since the FER accuracy is substantial in assisting teachers to acquire the emotional situation, the project explores a series of FER methods and finds that few works engage in exploiting the orthogonality of convolutional matrix. Therefore, it enforces orthogonality on kernels by a regularizer, which extracts features with more diversity and expressiveness, and delivers OCFER-Net. Experiments are carried out on FER-2013, which is a challenging dataset. Results show superior performance over baselines by 1.087. The code of the research project is publicly available on https://github.com/YeeHoran/OCFERNet.

</details>


### [57] [Perceptual Region-Driven Infrared-Visible Co-Fusion for Extreme Scene Enhancement](https://arxiv.org/abs/2512.06400)
*Jing Tao,Yonghong Zong,Banglei Guana,Pengju Sun,Taihang Lei,Yang Shanga,Qifeng Yu*

Main category: cs.CV

TL;DR: 提出一种区域感知融合框架，通过多曝光和多模态成像技术，在极端环境下提升红外与可见光谱融合质量。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在极端条件下因牺牲可见图像质量而影响测量精度的问题。

Method: 采用区域感知特征融合和自适应融合策略，结合多曝光和多模态成像技术，通过结构相似性补偿机制优化红外与可见光谱的整合。

Result: 实验证明，该方法在合成和真实数据上均表现出优于现有方法的图像清晰度和性能。

Conclusion: 该论文提出的基于区域感知的融合框架在极端环境下显著提升了红外与可见光谱融合的质量，保持了可见特征的几何保真度并有效整合了热辐射信息。

Abstract: In photogrammetry, accurately fusing infrared (IR) and visible (VIS) spectra while preserving the geometric fidelity of visible features and incorporating thermal radiation is a significant challenge, particularly under extreme conditions. Existing methods often compromise visible imagery quality, impacting measurement accuracy. To solve this, we propose a region perception-based fusion framework that combines multi-exposure and multi-modal imaging using a spatially varying exposure (SVE) camera. This framework co-fuses multi-modal and multi-exposure data, overcoming single-exposure method limitations in extreme environments. The framework begins with region perception-based feature fusion to ensure precise multi-modal registration, followed by adaptive fusion with contrast enhancement. A structural similarity compensation mechanism, guided by regional saliency maps, optimizes IR-VIS spectral integration. Moreover, the framework adapts to single-exposure scenarios for robust fusion across different conditions. Experiments conducted on both synthetic and real-world data demonstrate superior image clarity and improved performance compared to state-of-the-art methods, as evidenced by both quantitative and visual evaluations.

</details>


### [58] [Rethinking Training Dynamics in Scale-wise Autoregressive Generation](https://arxiv.org/abs/2512.06421)
*Gengze Zhou,Chongjian Ge,Hao Tan,Feng Liu,Yicong Hong*

Main category: cs.CV

TL;DR: SAR通过SSR和CSFL解决自回归模型的暴露偏差问题，实验证明其高效且有效。


<details>
  <summary>Details</summary>
Motivation: 自回归生成模型在媒体合成中表现出色，但尺度自回归模型存在暴露偏差问题，影响生成质量。本文旨在解决这一问题。

Method: 提出了Self-Autoregressive Refinement (SAR)，包含Stagger-Scale Rollout (SSR)机制和Contrastive Student-Forcing Loss (CSFL)，以解决训练-测试不匹配和尺度学习难度不平衡问题。

Result: 实验表明，SAR能显著提升生成质量（如FlexVAR-d16在ImageNet 256上FID降低5.2%），且计算开销极小。

Conclusion: SAR作为一种高效、可扩展且有效的方法，有望成为视觉自回归生成的后训练可靠方案。

Abstract: Recent advances in autoregressive (AR) generative models have produced increasingly powerful systems for media synthesis. Among them, next-scale prediction has emerged as a popular paradigm, where models generate images in a coarse-to-fine manner. However, scale-wise AR models suffer from exposure bias, which undermines generation quality. We identify two primary causes of this issue: (1) train-test mismatch, where the model must rely on its own imperfect predictions during inference, and (2) imbalance in scale-wise learning difficulty, where certain scales exhibit disproportionately higher optimization complexity. Through a comprehensive analysis of training dynamics, we propose Self-Autoregressive Refinement (SAR) to address these limitations. SAR introduces a Stagger-Scale Rollout (SSR) mechanism that performs lightweight autoregressive rollouts to expose the model to its own intermediate predictions, thereby aligning train-test patterns, and a complementary Contrastive Student-Forcing Loss (CSFL) that provides adequate supervision for self-generated contexts to ensure stable training. Experimental results show that applying SAR to pretrained AR models consistently improves generation quality with minimal computational overhead. For instance, SAR yields a 5.2% FID reduction on FlexVAR-d16 trained on ImageNet 256 within 10 epochs (5 hours on 32xA100 GPUs). Given its efficiency, scalability, and effectiveness, we expect SAR to serve as a reliable post-training method for visual autoregressive generation.

</details>


### [59] [A Perception CNN for Facial Expression Recognition](https://arxiv.org/abs/2512.06422)
*Chunwei Tian,Jingyuan Xie,Lingjun Li,Wangmeng Zuo,Yanning Zhang,David Zhang*

Main category: cs.CV

TL;DR: 提出了一种感知CNN（PCNN），通过并行网络和多域交互机制改进面部表情识别，实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 传统CNN可能忽略面部分割对FER的影响，因此需要一种能够敏感捕捉面部细微变化的方法。

Method: 提出了PCNN，使用五个并行网络学习局部面部特征，并采用多域交互机制融合局部和全局特征，设计了两阶段损失函数以保证性能。

Result: PCNN在CK+、JAFFE、FER2013等多个数据集上取得了优越的结果。

Conclusion: PCNN在多个实验室和真实世界的FER基准测试中表现出色，验证了其在面部表情识别任务中的有效性。

Abstract: Convolutional neural networks (CNNs) can automatically learn data patterns to express face images for facial expression recognition (FER). However, they may ignore effect of facial segmentation of FER. In this paper, we propose a perception CNN for FER as well as PCNN. Firstly, PCNN can use five parallel networks to simultaneously learn local facial features based on eyes, cheeks and mouth to realize the sensitive capture of the subtle changes in FER. Secondly, we utilize a multi-domain interaction mechanism to register and fuse between local sense organ features and global facial structural features to better express face images for FER. Finally, we design a two-phase loss function to restrict accuracy of obtained sense information and reconstructed face images to guarantee performance of obtained PCNN in FER. Experimental results show that our PCNN achieves superior results on several lab and real-world FER benchmarks: CK+, JAFFE, FER2013, FERPlus, RAF-DB and Occlusion and Pose Variant Dataset. Its code is available at https://github.com/hellloxiaotian/PCNN.

</details>


### [60] [DragMesh: Interactive 3D Generation Made Easy](https://arxiv.org/abs/2512.06424)
*Tianshan Zhang,Zeyu Zhang,Hao Tang*

Main category: cs.CV

TL;DR: DragMesh是一个实时交互式3D关节运动生成框架，通过解耦的运动生成和双四元数VAE，解决了现有方法在实时性和物理一致性上的矛盾。


<details>
  <summary>Details</summary>
Motivation: 当前方法在实时性和物理一致性之间存在矛盾，DragMesh旨在解决这一挑战，实现实时且符合运动学约束的交互式3D关节运动生成。

Method: 提出DragMesh框架，包含两个核心部分：1）通过KPP-Net解耦语义意图推理和几何回归推断潜在关节参数；2）开发DQ-VAE，利用双四元数表示刚性体运动，并通过FiLM条件注入关节先验。

Result: DragMesh实现了实时性能，并能对未见物体进行合理的生成式关节运动，无需重新训练。

Conclusion: DragMesh通过解耦的运动生成框架和双四元数VAE，实现了实时交互式3D关节运动生成，为生成式3D智能提供了实用步骤。

Abstract: While generative models have excelled at creating static 3D content, the pursuit of systems that understand how objects move and respond to interactions remains a fundamental challenge. Current methods for articulated motion lie at a crossroads: they are either physically consistent but too slow for real-time use, or generative but violate basic kinematic constraints. We present DragMesh, a robust framework for real-time interactive 3D articulation built around a lightweight motion generation core. Our core contribution is a novel decoupled kinematic reasoning and motion generation framework. First, we infer the latent joint parameters by decoupling semantic intent reasoning (which determines the joint type) from geometric regression (which determines the axis and origin using our Kinematics Prediction Network (KPP-Net)). Second, to leverage the compact, continuous, and singularity-free properties of dual quaternions for representing rigid body motion, we develop a novel Dual Quaternion VAE (DQ-VAE). This DQ-VAE receives these predicted priors, along with the original user drag, to generate a complete, plausible motion trajectory. To ensure strict adherence to kinematics, we inject the joint priors at every layer of the DQ-VAE's non-autoregressive Transformer decoder using FiLM (Feature-wise Linear Modulation) conditioning. This persistent, multi-scale guidance is complemented by a numerically-stable cross-product loss to guarantee axis alignment. This decoupled design allows DragMesh to achieve real-time performance and enables plausible, generative articulation on novel objects without retraining, offering a practical step toward generative 3D intelligence. Code: https://github.com/AIGeeksGroup/DragMesh. Website: https://aigeeksgroup.github.io/DragMesh.

</details>


### [61] [When Gender is Hard to See: Multi-Attribute Support for Long-Range Recognition](https://arxiv.org/abs/2512.06426)
*Nzakiese Mbongo,Kailash A. Hambarde,Hugo Proença*

Main category: cs.CV

TL;DR: 提出了一种基于CLIP的双路径Transformer框架，通过视觉和属性路径联合建模，显著提升了远距离性别识别的性能。


<details>
  <summary>Details</summary>
Motivation: 远距离图像中的性别识别由于空间分辨率低、视角多变和面部线索缺失而具有挑战性。

Method: 提出了一个双路径Transformer框架，结合CLIP模型，通过视觉路径和属性驱动路径共同建模远距离性别识别。

Result: 实验表明，该方法在多个指标（macro-F1、准确率、AUC）上超越了现有的人体属性和重识别基线，且对距离、角度和高度变化具有一致的鲁棒性。

Conclusion: 语言引导的双路径学习为无约束远距离场景下的性别识别提供了一个原则性、可扩展的基础。

Abstract: Accurate gender recognition from extreme long-range imagery remains a challenging problem due to limited spatial resolution, viewpoint variability, and loss of facial cues. For such purpose, we present a dual-path transformer framework that leverages CLIP to jointly model visual and attribute-driven cues for gender recognition at a distance. The framework integrates two complementary streams: (1) a direct visual path that refines a pre-trained CLIP image encoder through selective fine-tuning of its upper layers, and (2) an attribute-mediated path that infers gender from a set of soft-biometric prompts (e.g., hairstyle, clothing, accessories) aligned in the CLIP text-image space. Spatial channel attention modules further enhance discriminative localization under occlusion and low resolution. To support large-scale evaluation, we construct U-DetAGReID, a unified long-range gender dataset derived from DetReIDx and AG-ReID.v2, harmonized under a consistent ternary labeling scheme (Male, Female, Unknown). Extensive experiments suggest that the proposed solution surpasses state-of-the-art person-attribute and re-identification baselines across multiple metrics (macro-F1, accuracy, AUC), with consistent robustness to distance, angle, and height variations. Qualitative attention visualizations confirm interpretable attribute localization and responsible abstention behavior. Our results show that language-guided dual-path learning offers a principled, extensible foundation for responsible gender recognition in unconstrained long-range scenarios.

</details>


### [62] [Automated Deep Learning Estimation of Anthropometric Measurements for Preparticipation Cardiovascular Screening](https://arxiv.org/abs/2512.06434)
*Lucas R. Mareque,Ricardo L. Armentano,Leandro J. Cymberknop*

Main category: cs.CV

TL;DR: 提出自动化深度学习方法，从2D合成图像估计关键人体测量数据，ResNet50表现最佳，精度达亚厘米级，有望补充运动员筛查。


<details>
  <summary>Details</summary>
Motivation: 传统手动方法劳动密集、依赖操作者且难以扩展，需要自动化解决方案。

Method: 使用从3D人体网格衍生的10万张2D合成人体图像数据集，训练并评估了带有全连接层的VGG19、ResNet50和DenseNet121进行回归。

Result: 所有模型均达到亚厘米级精度，其中ResNet50表现最佳，平均MAE为0.668厘米。

Conclusion: 深度学习可以大规模提供准确的人体测量数据，为运动员筛查提供实用工具。未来工作将在真实图像上验证模型以扩展适用性。

Abstract: Preparticipation cardiovascular examination (PPCE) aims to prevent sudden cardiac death (SCD) by identifying athletes with structural or electrical cardiac abnormalities. Anthropometric measurements, such as waist circumference, limb lengths, and torso proportions to detect Marfan syndrome, can indicate elevated cardiovascular risk. Traditional manual methods are labor-intensive, operator-dependent, and challenging to scale. We present a fully automated deep-learning approach to estimate five key anthropometric measurements from 2D synthetic human body images. Using a dataset of 100,000 images derived from 3D body meshes, we trained and evaluated VGG19, ResNet50, and DenseNet121 with fully connected layers for regression. All models achieved sub-centimeter accuracy, with ResNet50 performing best, achieving a mean MAE of 0.668 cm across all measurements. Our results demonstrate that deep learning can deliver accurate anthropometric data at scale, offering a practical tool to complement athlete screening protocols. Future work will validate the models on real-world images to extend applicability.

</details>


### [63] [AGORA: Adversarial Generation Of Real-time Animatable 3D Gaussian Head Avatars](https://arxiv.org/abs/2512.06438)
*Ramazan Fazylov,Sergey Zagoruyko,Aleksandr Parkin,Stamatis Lefkimmiatis,Ivan Laptev*

Main category: cs.CV

TL;DR: AGORA是一种新型框架，通过结合3D高斯泼溅与生成对抗网络，生成高保真、可动画化的3D人类头像，实现了实时渲染和精确控制。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于隐式表示（如NeRF）的方法渲染速度慢、动态不一致，以及3DGS方法通常仅限于静态头部生成、缺乏动态控制的问题。

Method: AGORA引入了一个轻量级的、基于FLAME的变形分支，预测每个高斯的残差，实现了身份保持和细粒度表情控制，同时支持实时推理。通过双判别器训练方案，利用参数化网格的合成渲染来增强表情保真度。

Result: AGORA在表情准确性上优于基于NeRF的最新方法，单GPU渲染速度超过250 FPS，CPU-only推理下约9 FPS，首次展示了实用的CPU-only可动画化3DGS头像合成。

Conclusion: AGORA框架通过将3D高斯泼溅（3DGS）与生成对抗网络结合，实现了高保真、可动画化的3D人类头像生成，显著提升了数字人类的实用性和高性能表现。

Abstract: The generation of high-fidelity, animatable 3D human avatars remains a core challenge in computer graphics and vision, with applications in VR, telepresence, and entertainment. Existing approaches based on implicit representations like NeRFs suffer from slow rendering and dynamic inconsistencies, while 3D Gaussian Splatting (3DGS) methods are typically limited to static head generation, lacking dynamic control. We bridge this gap by introducing AGORA, a novel framework that extends 3DGS within a generative adversarial network to produce animatable avatars. Our key contribution is a lightweight, FLAME-conditioned deformation branch that predicts per-Gaussian residuals, enabling identity-preserving, fine-grained expression control while allowing real-time inference. Expression fidelity is enforced via a dual-discriminator training scheme leveraging synthetic renderings of the parametric mesh. AGORA generates avatars that are not only visually realistic but also precisely controllable. Quantitatively, we outperform state-of-the-art NeRF-based methods on expression accuracy while rendering at 250+ FPS on a single GPU, and, notably, at $\sim$9 FPS under CPU-only inference - representing, to our knowledge, the first demonstration of practical CPU-only animatable 3DGS avatar synthesis. This work represents a significant step toward practical, high-performance digital humans. Project website: https://ramazan793.github.io/AGORA/

</details>


### [64] [Towards Stable Cross-Domain Depression Recognition under Missing Modalities](https://arxiv.org/abs/2512.06447)
*Jiuyi Chen,Mingkui Tan,Haifeng Lu,Qiuna Xu,Zhihua Wang,Runhao Zeng,Xiping Hu*

Main category: cs.CV

TL;DR: SCD-MLLM是一个统一且稳定的跨领域抑郁症识别框架，通过MDIA和MAFM处理异构数据并应对缺失模态，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 抑郁症的及时筛查对公共健康至关重要，但现有的多模态自动抑郁症检测方法缺乏统一的框架，且对缺失模态的稳定性不足。

Method: 提出了一个基于多模态大型语言模型（SCD-MLLM）的统一框架，包含多源数据输入适配器（MDIA）和模态感知自适应融合模块（MAFM），以处理异构数据并增强对缺失模态的稳定性。

Result: 在五个公开数据集上的实验表明，SCD-MLLM在完整和部分模态设置下均优于现有方法及主流商业LLM（如Gemini和GPT），展示了卓越的跨领域泛化能力和稳定性。

Conclusion: SCD-MLLM框架通过MDIA和MAFM两个关键组件，实现了跨领域抑郁症识别的统一性和稳定性，显著优于现有方法，并在实际应用中表现出强大的鲁棒性。

Abstract: Depression poses serious public health risks, including suicide, underscoring the urgency of timely and scalable screening. Multimodal automatic depression detection (ADD) offers a promising solution; however, widely studied audio- and video-based ADD methods lack a unified, generalizable framework for diverse depression recognition scenarios and show limited stability to missing modalities, which are common in real-world data. In this work, we propose a unified framework for Stable Cross-Domain Depression Recognition based on Multimodal Large Language Model (SCD-MLLM). The framework supports the integration and processing of heterogeneous depression-related data collected from varied sources while maintaining stability in the presence of incomplete modality inputs. Specifically, SCD-MLLM introduces two key components: (i) Multi-Source Data Input Adapter (MDIA), which employs masking mechanism and task-specific prompts to transform heterogeneous depression-related inputs into uniform token sequences, addressing inconsistency across diverse data sources; (ii) Modality-Aware Adaptive Fusion Module (MAFM), which adaptively integrates audio and visual features via a shared projection mechanism, enhancing resilience under missing modality conditions. e conduct comprehensive experiments under multi-dataset joint training settings on five publicly available and heterogeneous depression datasets from diverse scenarios: CMDC, AVEC2014, DAIC-WOZ, DVlog, and EATD. Across both complete and partial modality settings, SCD-MLLM outperforms state-of-the-art (SOTA) models as well as leading commercial LLMs (Gemini and GPT), demonstrating superior cross-domain generalization, enhanced ability to capture multimodal cues of depression, and strong stability to missing modality cases in real-world applications.

</details>


### [65] [Sanvaad: A Multimodal Accessibility Framework for ISL Recognition and Voice-Based Interaction](https://arxiv.org/abs/2512.06485)
*Kush Revankar,Shreyas Deshpande,Araham Sayeed,Ansh Tandale,Sarika Bobde*

Main category: cs.CV

TL;DR: Sanvaad是一个轻量级多模态无障碍框架，支持聋哑和视障用户与听力正常人群之间的实时双向沟通。


<details>
  <summary>Details</summary>
Motivation: 解决聋哑用户、视障用户与听力正常人群之间沟通工具仅支持单向交互的局限性。

Method: Sanvaad框架包括基于MediaPipe地标的ISL识别模块、语音到手势的转换组件，以及针对视障用户的无屏幕语音接口，整合了多语言语音识别、文本摘要和文本到语音生成功能。

Result: Sanvaad能够在边缘设备上流畅运行，支持实时双向沟通，适用于桌面和移动环境。

Conclusion: Sanvaad通过结合轻量级计算机视觉和语音处理工具，为聋哑用户和视障用户提供了一个实用的、可访问的双向沟通框架。

Abstract: Communication between deaf users, visually im paired users, and the general hearing population often relies on tools that support only one direction of interaction. To address this limitation, this work presents Sanvaad, a lightweight multimodal accessibility framework designed to support real time, two-way communication. For deaf users, Sanvaad includes an ISL recognition module built on MediaPipe landmarks. MediaPipe is chosen primarily for its efficiency and low computational load, enabling the system to run smoothly on edge devices without requiring dedicated hardware. Spoken input from a phone can also be translated into sign representations through a voice-to-sign component that maps detected speech to predefined phrases and produces corresponding GIFs or alphabet-based visualizations. For visually impaired users, the framework provides a screen free voice interface that integrates multilingual speech recognition, text summarization, and text-to-speech generation. These components work together through a Streamlit-based interface, making the system usable on both desktop and mobile environments. Overall, Sanvaad aims to offer a practical and accessible pathway for inclusive communication by combining lightweight computer vision and speech processing tools within a unified framework.

</details>


### [66] [Method of UAV Inspection of Photovoltaic Modules Using Thermal and RGB Data Fusion](https://arxiv.org/abs/2512.06504)
*Andrii Lysyi,Anatoliy Sachenko,Pavlo Radiuk,Mykola Lysyi,Oleksandr Melnychenko,Diana Zahorodnia*

Main category: cs.CV

TL;DR: 研究开发了一个智能光伏检测框架，通过多模态协同架构显著提升了检测精度和效率，减少了误报和数据传输量。


<details>
  <summary>Details</summary>
Motivation: 旨在解决传统光伏检测方法的关键缺陷，如热成像调色板偏差、数据冗余和高通信带宽需求，设计并验证一个全面的多模态系统，实现从数据采集到生成可操作的地理定位维护警报的自动化监控工作流，从而提高电站的安全性和运行效率。

Method: 采用了一种协同架构，包括通过学习表示一致性强制实现的热成像嵌入、通过门控机制与对比归一化RGB流融合的方法，以及一个闭环自适应重新采集控制器（使用Rodrigues更新来针对性确认模糊异常）和一个基于DBSCAN和半正矢距离的地理空间去重模块。

Result: 提出的系统在PVF-10基准测试中实现了0.903的mAP@0.5，召回率达到96%，去重过程减少了15-20%的误报，数据传输减少了60-70%。

Conclusion: 本研究确立了一种主动式光伏检测的新范式，提出的系统在公开的PVF-10基准测试中实现了0.903的平均精度（mAP@0.5），相比单模态基线显著提升了12-15%。现场验证确认了系统的成熟度，达到了96%的召回率，同时去重过程减少了15-20%的重复引起的误报，仅相关遥测将空中数据传输减少了60-70%。

Abstract: The subject of this research is the development of an intelligent, integrated framework for the automated inspection of photovoltaic (PV) infrastructure that addresses the critical shortcomings of conventional methods, including thermal palette bias, data redundancy, and high communication bandwidth requirements. The goal of this study is to design, develop, and validate a comprehensive, multi-modal system that fully automates the monitoring workflow, from data acquisition to the generation of actionable, geo-located maintenance alerts, thereby enhancing plant safety and operational efficiency. The methods employed involve a synergistic architecture that begins with a palette-invariant thermal embedding, learned by enforcing representational consistency, which is fused with a contrast-normalized RGB stream via a gated mechanism. This is supplemented by a closed-loop, adaptive re-acquisition controller that uses Rodrigues-based updates for targeted confirmation of ambiguous anomalies and a geospatial deduplication module that clusters redundant alerts using DBSCAN over the haversine distance. In conclusion, this study establishes a powerful new paradigm for proactive PV inspection, with the proposed system achieving a mean Average Precision (mAP@0.5) of 0.903 on the public PVF-10 benchmark, a significant 12-15% improvement over single-modality baselines. Field validation confirmed the system's readiness, achieving 96% recall, while the de-duplication process reduced duplicate-induced false positives by 15-20%, and relevance-only telemetry cut airborne data transmission by 60-70%.

</details>


### [67] [ShadowWolf -- Automatic Labelling, Evaluation and Model Training Optimised for Camera Trap Wildlife Images](https://arxiv.org/abs/2512.06521)
*Jens Dede,Anna Förster*

Main category: cs.CV

TL;DR: ShadowWolf是一个统一框架，通过动态模型重训练优化AI训练流程，提升野生动物监测的准确性和效率，应对环境多样性挑战。


<details>
  <summary>Details</summary>
Motivation: 全球人口增长导致人类栖息地扩张，野生动物空间减少，人兽互动增加，从轻微干扰到物种灭绝不等。AI可自动化识别图像和视频中的动物，减少人工监测工作量，但环境多样性（如地形、天气、光照、相机距离）对模型鲁棒性提出挑战。

Method: 提出了一个名为ShadowWolf的统一框架，整合并优化了AI模型训练和评估的各个阶段，支持动态模型重训练以适应环境变化和应用需求。

Result: ShadowWolf框架减少了标注工作量，支持现场模型适应，提高了野生动物监测系统的准确性和效率。

Conclusion: ShadowWolf框架通过动态模型重训练和统一优化，提高了野生动物监测系统的准确性和效率，支持更有效的保护工作。

Abstract: The continuous growth of the global human population is leading to the expansion of human habitats, resulting in decreasing wildlife spaces and increasing human-wildlife interactions. These interactions can range from minor disturbances, such as raccoons in urban waste bins, to more severe consequences, including species extinction. As a result, the monitoring of wildlife is gaining significance in various contexts. Artificial intelligence (AI) offers a solution by automating the recognition of animals in images and videos, thereby reducing the manual effort required for wildlife monitoring. Traditional AI training involves three main stages: image collection, labelling, and model training. However, the variability, for example, in the landscape (e.g., mountains, open fields, forests), weather (e.g., rain, fog, sunshine), lighting (e.g., day, night), and camera-animal distances presents significant challenges to model robustness and adaptability in real-world scenarios.
  In this work, we propose a unified framework, called ShadowWolf, designed to address these challenges by integrating and optimizing the stages of AI model training and evaluation. The proposed framework enables dynamic model retraining to adjust to changes in environmental conditions and application requirements, thereby reducing labelling efforts and allowing for on-site model adaptation. This adaptive and unified approach enhances the accuracy and efficiency of wildlife monitoring systems, promoting more effective and scalable conservation efforts.

</details>


### [68] [On The Role of K-Space Acquisition in MRI Reconstruction Domain-Generalization](https://arxiv.org/abs/2512.06530)
*Mohammed Wattad,Tamir Shor,Alex Bronstein*

Main category: cs.CV

TL;DR: 学习k空间采样模式可提升MRI重建的跨域泛化能力，通过随机扰动轨迹增强域鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有研究大多关注针对单一数据集或模态优化的k空间采集模式，缺乏对其跨域迁移性的考虑。本研究旨在探索学习k空间采样在跨域设置下的泛化能力。

Method: 提出了一种新颖的方法，通过在训练过程中随机扰动k空间轨迹来模拟不同扫描器和成像条件的变异性，从而增强模型的域鲁棒性。

Result: 通过跨数据集和采集范式的系统评估，发现使用学习采样模式训练的模型在跨域设置下表现出更好的泛化能力。

Conclusion: 研究表明，通过学习k空间采样模式不仅能够提升MRI重建质量，还能增强其在跨域设置下的泛化能力。通过引入采集不确定性来模拟不同扫描器和成像条件的变异性，进一步提高了模型的域鲁棒性。

Abstract: Recent work has established learned k-space acquisition patterns as a promising direction for improving reconstruction quality in accelerated Magnetic Resonance Imaging (MRI). Despite encouraging results, most existing research focuses on acquisition patterns optimized for a single dataset or modality, with limited consideration of their transferability across imaging domains. In this work, we demonstrate that the benefits of learned k-space sampling can extend beyond the training domain, enabling superior reconstruction performance under domain shifts. Our study presents two main contributions. First, through systematic evaluation across datasets and acquisition paradigms, we show that models trained with learned sampling patterns exhibitimproved generalization under cross-domain settings. Second, we propose a novel method that enhances domain robustness by introducing acquisition uncertainty during training-stochastically perturbing k-space trajectories to simulate variability across scanners and imaging conditions. Our results highlight the importance of treating kspace trajectory design not merely as an acceleration mechanism, but as an active degree of freedom for improving domain generalization in MRI reconstruction.

</details>


### [69] [More than Segmentation: Benchmarking SAM 3 for Segmentation, 3D Perception, and Reconstruction in Robotic Surgery](https://arxiv.org/abs/2512.07596)
*Wenzhen Dong,Jieming Yu,Yiming Huang,Hongqiu Wang,Lei Zhu,Albert C. S. Chung,Hongliang Ren,Long Bai*

Main category: cs.CV

TL;DR: SAM 3在机器人手术中表现出色，尤其在空间提示分割和3D重建方面，但语言提示和复杂场景处理仍需改进。


<details>
  <summary>Details</summary>
Motivation: 评估SAM 3在机器人辅助手术中的性能，探索其在零样本分割、动态视频跟踪和3D重建方面的潜力。

Method: 通过MICCAI EndoVis 2017和EndoVis 2018基准测试，评估了SAM 3在点、边界框和语言提示下的零样本分割性能，以及其在动态视频跟踪和3D重建能力。

Result: SAM 3在空间提示下的分割任务中表现优于SAM和SAM 2，语言提示在手术领域表现欠佳，3D重建能力显示出潜力但仍有改进空间。

Conclusion: SAM 3在机器人辅助手术中表现出色，尤其在空间提示下的图像和视频分割方面有明显改进，但在复杂动态手术场景中仍存在局限性。

Abstract: The recent Segment Anything Model (SAM) 3 has introduced significant advancements over its predecessor, SAM 2, particularly with the integration of language-based segmentation and enhanced 3D perception capabilities. SAM 3 supports zero-shot segmentation across a wide range of prompts, including point, bounding box, and language-based prompts, allowing for more flexible and intuitive interactions with the model. In this empirical evaluation, we assess the performance of SAM 3 in robot-assisted surgery, benchmarking its zero-shot segmentation with point and bounding box prompts and exploring its effectiveness in dynamic video tracking, alongside its newly introduced language prompt segmentation. While language prompts show potential, their performance in the surgical domain is currently suboptimal, highlighting the need for further domain-specific training. Additionally, we investigate SAM 3's 3D reconstruction abilities, demonstrating its capacity to process surgical scene data and reconstruct 3D anatomical structures from 2D images. Through comprehensive testing on the MICCAI EndoVis 2017 and EndoVis 2018 benchmarks, SAM 3 shows clear improvements over SAM and SAM 2 in both image and video segmentation under spatial prompts, while zero-shot evaluations on SCARED, StereoMIS, and EndoNeRF indicate strong monocular depth estimation and realistic 3D instrument reconstruction, yet also reveal remaining limitations in complex, highly dynamic surgical scenes.

</details>


### [70] [Novel Deep Learning Architectures for Classification and Segmentation of Brain Tumors from MRI Images](https://arxiv.org/abs/2512.06531)
*Sayan Das,Arghadip Biswas*

Main category: cs.CV

TL;DR: 论文提出两种深度学习模型（SAETCN和SAS-Net），用于脑肿瘤的自动分类和分割，分别达到99.38%和99.23%的高准确率，解决了传统手动检测的效率和精度问题。


<details>
  <summary>Details</summary>
Motivation: 脑肿瘤对人类生命构成重大威胁，早期准确检测对诊断和治疗至关重要。传统手动检测方法耗时且难以应对日益增长的数据量。

Method: 提出了两种深度学习架构：(a) SAETCN用于脑肿瘤分类，达到99.38%的验证准确率；(b) SAS-Net用于脑肿瘤分割，达到99.23%的像素准确率。

Result: SAETCN在验证数据集上达到99.38%的分类准确率，SAS-Net达到99.23%的分割像素准确率，显著优于现有模型。

Conclusion: 该论文提出了两种新颖的深度学习架构（SAETCN和SAS-Net），用于脑肿瘤的自动分类和分割，显著提高了准确性和效率。

Abstract: Brain tumors pose a significant threat to human life, therefore it is very much necessary to detect them accurately in the early stages for better diagnosis and treatment. Brain tumors can be detected by the radiologist manually from the MRI scan images of the patients. However, the incidence of brain tumors has risen amongst children and adolescents in recent years, resulting in a substantial volume of data, as a result, it is time-consuming and difficult to detect manually. With the emergence of Artificial intelligence in the modern world and its vast application in the medical field, we can make an approach to the CAD (Computer Aided Diagnosis) system for the early detection of Brain tumors automatically. All the existing models for this task are not completely generalized and perform poorly on the validation data. So, we have proposed two novel Deep Learning Architectures - (a) SAETCN (Self-Attention Enhancement Tumor Classification Network) for the classification of different kinds of brain tumors. We have achieved an accuracy of 99.38% on the validation dataset making it one of the few Novel Deep learning-based architecture that is capable of detecting brain tumors accurately. We have trained the model on the dataset, which contains images of 3 types of tumors (glioma, meningioma, and pituitary tumors) and non-tumor cases. and (b) SAS-Net (Self-Attentive Segmentation Network) for the accurate segmentation of brain tumors. We have achieved an overall pixel accuracy of 99.23%.

</details>


### [71] [sim2art: Accurate Articulated Object Modeling from a Single Video using Synthetic Training Data Only](https://arxiv.org/abs/2512.07698)
*Arslan Artykov,Corentin Sautier,Vincent Lepetit*

Main category: cs.CV

TL;DR: 首个从自由移动单目视频中联合预测部件分割和关节参数的数据驱动方法，仅用合成数据训练，泛化能力强，适用于实时应用。


<details>
  <summary>Details</summary>
Motivation: 理解关节化物体是机器人和数字孪生创建中的基本挑战，但以往研究多集中于多视角系统、物体扫描或静态相机等设置，缺乏从单目视频中直接预测的解决方案。

Method: 采用数据驱动的方法，仅使用合成数据进行训练，直接从自由移动相机拍摄的单目视频中联合预测部件分割和关节参数。

Result: 该方法在真实世界物体上表现出强大的泛化能力，适用于动态环境中的实时应用。

Conclusion: 该论文提出了一种从单目视频中联合预测部件分割和关节参数的数据驱动方法，展示了在真实世界物体上的强大泛化能力，为动态环境中的实时应用提供了可扩展且实用的解决方案。

Abstract: Understanding articulated objects is a fundamental challenge in robotics and digital twin creation. To effectively model such objects, it is essential to recover both part segmentation and the underlying joint parameters. Despite the importance of this task, previous work has largely focused on setups like multi-view systems, object scanning, or static cameras. In this paper, we present the first data-driven approach that jointly predicts part segmentation and joint parameters from monocular video captured with a freely moving camera. Trained solely on synthetic data, our method demonstrates strong generalization to real-world objects, offering a scalable and practical solution for articulated object understanding. Our approach operates directly on casually recorded video, making it suitable for real-time applications in dynamic environments. Project webpage: https://aartykov.github.io/sim2art/

</details>


### [72] [Bridging spatial awareness and global context in medical image segmentation](https://arxiv.org/abs/2512.06560)
*Dalia Alzu'bi,A. Ben Hamza*

Main category: cs.CV

TL;DR: U-CycleMLP是一种新型U形网络，通过多尺度上下文特征学习和特征融合机制，显著提升了医学图像分割的准确性和效率，并在多个数据集中验证了其优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有分割模型在有效捕获局部和全局上下文信息方面存在不足，导致边界像素丢失和分割错误，因此需要一种既能提升分割性能又能保持轻量级架构的新方法。

Method: 提出了一种U形编码器-解码器网络U-CycleMLP，编码器通过位置注意力权重激励块、密集空洞块和下采样操作学习多尺度上下文特征，解码器通过上采样操作、密集空洞块和特征融合机制重建高分辨率分割掩码，并在跳跃连接中引入通道CycleMLP块以增强特征整合。

Result: 实验结果表明，U-CycleMLP在所有数据集上均实现了更好的分割准确性，能够捕获细粒度解剖结构，并在不同医学成像模态中表现出稳健性。

Conclusion: U-CycleMLP在三个基准数据集上展现了优于现有方法的性能，尤其在捕获细粒度解剖结构和跨模态稳健性方面表现突出。消融研究进一步验证了模型核心架构组件对提升分割准确性的重要性。

Abstract: Medical image segmentation is a fundamental task in computer-aided diagnosis, requiring models that balance segmentation accuracy and computational efficiency. However, existing segmentation models often struggle to effectively capture local and global contextual information, leading to boundary pixel loss and segmentation errors. In this paper, we propose U-CycleMLP, a novel U-shaped encoder-decoder network designed to enhance segmentation performance while maintaining a lightweight architecture. The encoder learns multiscale contextual features using position attention weight excitation blocks, dense atrous blocks, and downsampling operations, effectively capturing both local and global contextual information. The decoder reconstructs high-resolution segmentation masks through upsampling operations, dense atrous blocks, and feature fusion mechanisms, ensuring precise boundary delineation. To further refine segmentation predictions, channel CycleMLP blocks are incorporated into the decoder along the skip connections, enhancing feature integration while maintaining linear computational complexity relative to input size. Experimental results, both quantitative and qualitative, across three benchmark datasets demonstrate the competitive performance of U-CycleMLP in comparison with state-of-the-art methods, achieving better segmentation accuracy across all datasets, capturing fine-grained anatomical structures, and demonstrating robustness across different medical imaging modalities. Ablation studies further highlight the importance of the model's core architectural components in enhancing segmentation accuracy.

</details>


### [73] [UltrasODM: A Dual Stream Optical Flow Mamba Network for 3D Freehand Ultrasound Reconstruction](https://arxiv.org/abs/2512.07756)
*Mayank Anand,Ujair Alam,Surya Prakash,Priya Shukla,Gora Chand Nandi,Domenec Puig*

Main category: cs.CV

TL;DR: UltrasODM是一个双流框架，通过实时不确定性校准和可操作提示辅助超声采集，显著减少重建错误，提升临床工作流程的可靠性。


<details>
  <summary>Details</summary>
Motivation: 临床超声采集高度依赖操作者，快速探头运动和亮度波动常导致重建错误，降低信任和临床实用性。UltrasODM旨在通过实时不确定性校准和可操作提示辅助操作者。

Method: UltrasODM采用双流框架，包括对比排序模块、光流流与Dual-Mamba时间模块融合的6-DoF姿态估计，以及结合贝叶斯不确定性、临床校准阈值和显著性图的人机交互层。

Result: 在临床自由手超声数据集上评估，UltrasODM相比UltrasOM减少了15.2%的漂移、12.1%的距离误差和10.1%的Hausdorff距离，并生成每帧不确定性和显著性输出。

Conclusion: UltrasODM通过集成对比排序模块、光流流与Dual-Mamba时间模块以及人机交互层，显著提高了超声图像重建的可靠性，减少了漂移和距离误差，支持更安全、更可信的临床工作流程。

Abstract: Clinical ultrasound acquisition is highly operator-dependent, where rapid probe motion and brightness fluctuations often lead to reconstruction errors that reduce trust and clinical utility. We present UltrasODM, a dual-stream framework that assists sonographers during acquisition through calibrated per-frame uncertainty, saliency-based diagnostics, and actionable prompts. UltrasODM integrates (i) a contrastive ranking module that groups frames by motion similarity, (ii) an optical-flow stream fused with Dual-Mamba temporal modules for robust 6-DoF pose estimation, and (iii) a Human-in-the-Loop (HITL) layer combining Bayesian uncertainty, clinician-calibrated thresholds, and saliency maps highlighting regions of low confidence. When uncertainty exceeds the threshold, the system issues unobtrusive alerts suggesting corrective actions such as re-scanning highlighted regions or slowing the sweep. Evaluated on a clinical freehand ultrasound dataset, UltrasODM reduces drift by 15.2%, distance error by 12.1%, and Hausdorff distance by 10.1% relative to UltrasOM, while producing per-frame uncertainty and saliency outputs. By emphasizing transparency and clinician feedback, UltrasODM improves reconstruction reliability and supports safer, more trustworthy clinical workflows. Our code is publicly available at https://github.com/AnandMayank/UltrasODM.

</details>


### [74] [SUGAR: A Sweeter Spot for Generative Unlearning of Many Identities](https://arxiv.org/abs/2512.06562)
*Dung Thuy Nguyen,Quang Nguyen,Preston K. Robinette,Eli Jiang,Taylor T. Johnson,Kevin Leach*

Main category: cs.CV

TL;DR: SUGAR是一种可扩展的生成式遗忘框架，能够在不重新训练整个模型的情况下移除多个身份，同时保持模型的质量和多样性，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决3D生成模型在用户同意和个体移除方面的紧迫问题，避免将不需要的身份投影到不现实的输出或依赖静态模板面部。

Method: SUGAR通过学习每个身份的个性化替代潜在表示，将重建引导至视觉上连贯的替代方案，并引入了持续效用保持目标以防止随着更多身份被遗忘而导致的性能下降。

Result: SUGAR在移除多达200个身份时实现了最先进的性能，并在保留效用方面比现有基线提高了700%。

Conclusion: SUGAR框架通过引入可扩展的生成式遗忘技术，有效解决了3D生成模型中用户同意和个体移除的问题，实现了在不重新训练整个模型的情况下移除多个身份，并保持了模型的质量和多样性。

Abstract: Recent advances in 3D-aware generative models have enabled high-fidelity image synthesis of human identities. However, this progress raises urgent questions around user consent and the ability to remove specific individuals from a model's output space. We address this by introducing SUGAR, a framework for scalable generative unlearning that enables the removal of many identities (simultaneously or sequentially) without retraining the entire model. Rather than projecting unwanted identities to unrealistic outputs or relying on static template faces, SUGAR learns a personalized surrogate latent for each identity, diverting reconstructions to visually coherent alternatives while preserving the model's quality and diversity. We further introduce a continual utility preservation objective that guards against degradation as more identities are forgotten. SUGAR achieves state-of-the-art performance in removing up to 200 identities, while delivering up to a 700% improvement in retention utility compared to existing baselines. Our code is publicly available at https://github.com/judydnguyen/SUGAR-Generative-Unlearn.

</details>


### [75] [GNC-Pose: Geometry-Aware GNC-PnP for Accurate 6D Pose Estimation](https://arxiv.org/abs/2512.06565)
*Xiujin Liu*

Main category: cs.CV

TL;DR: GNC-Pose是一种无需学习的单目6D姿态估计方法，通过几何感知加权和GNC优化，在YCB数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 提出一种完全无需学习的单目6D物体姿态估计管道，旨在为纹理物体提供一种简单、鲁棒且实用的解决方案。

Method: 结合了基于渲染的初始化、几何感知的对应加权和鲁棒的GNC优化，通过几何感知的聚类加权机制为每点分配基于3D结构一致性的置信度，显著提高了在严重异常值污染下的优化稳定性，并通过最终的LM细化进一步提高准确性。

Result: 在YCB对象和模型集上测试，GNC-Pose实现了与基于学习和无学习方法相竞争的准确性。

Conclusion: GNC-Pose提供了一种简单、鲁棒且实用的无学习6D姿态估计解决方案，尽管无需学习特征、训练数据或类别特定先验，但在YCB对象和模型集上实现了与基于学习和无学习方法相竞争的准确性。

Abstract: We present GNC-Pose, a fully learning-free monocular 6D object pose estimation pipeline for textured objects that combines rendering-based initialization, geometry-aware correspondence weighting, and robust GNC optimization. Starting from coarse 2D-3D correspondences obtained through feature matching and rendering-based alignment, our method builds upon the Graduated Non-Convexity (GNC) principle and introduces a geometry-aware, cluster-based weighting mechanism that assigns robust per point confidence based on the 3D structural consistency of the model. This geometric prior and weighting strategy significantly stabilizes the optimization under severe outlier contamination. A final LM refinement further improve accuracy. We tested GNC-Pose on The YCB Object and Model Set, despite requiring no learned features, training data, or category-specific priors, GNC-Pose achieves competitive accuracy compared with both learning-based and learning-free methods, and offers a simple, robust, and practical solution for learning-free 6D pose estimation.

</details>


### [76] [Masked Autoencoder Pretraining on Strong-Lensing Images for Joint Dark-Matter Model Classification and Super-Resolution](https://arxiv.org/abs/2512.06642)
*Achmad Ardani Prasha,Clavino Ourizqi Rachmadi,Muhamad Fauzan Ibnu Syahlan,Naufal Rahfi Anugerah,Nanda Garin Raditya,Putri Amelia,Sabrina Laila Mutiara,Hilman Syachr Ramadhan*

Main category: cs.CV

TL;DR: MAE预训练策略在强透镜图像上表现优异，分类和超分辨率任务均优于从头训练模型。


<details>
  <summary>Details</summary>
Motivation: 强引力透镜可以揭示暗物质子结构的影响，但分析这些效应在噪声大、分辨率低的图像中具有挑战性。

Method: 采用掩码自编码器（MAE）预训练策略，在模拟的强透镜图像上训练Vision Transformer编码器，然后针对分类和超分辨率任务分别微调。

Result: 在90%掩码比例下，微调分类器的宏AUC为0.968，准确率为88.65%，优于从头训练的基线（AUC 0.957，准确率82.46%）。超分辨率任务中，MAE预训练模型的PSNR约为33 dB，SSIM为0.961。

Conclusion: MAE预训练策略在物理丰富的模拟数据上提供了一个灵活、可重用的编码器，适用于多种强透镜分析任务。

Abstract: Strong gravitational lensing can reveal the influence of dark-matter substructure in galaxies, but analyzing these effects from noisy, low-resolution images poses a significant challenge. In this work, we propose a masked autoencoder (MAE) pretraining strategy on simulated strong-lensing images from the DeepLense ML4SCI benchmark to learn generalizable representations for two downstream tasks: (i) classifying the underlying dark matter model (cold dark matter, axion-like, or no substructure) and (ii) enhancing low-resolution lensed images via super-resolution. We pretrain a Vision Transformer encoder using a masked image modeling objective, then fine-tune the encoder separately for each task. Our results show that MAE pretraining, when combined with appropriate mask ratio tuning, yields a shared encoder that matches or exceeds a ViT trained from scratch. Specifically, at a 90% mask ratio, the fine-tuned classifier achieves macro AUC of 0.968 and accuracy of 88.65%, compared to the scratch baseline (AUC 0.957, accuracy 82.46%). For super-resolution (16x16 to 64x64), the MAE-pretrained model reconstructs images with PSNR ~33 dB and SSIM 0.961, modestly improving over scratch training. We ablate the MAE mask ratio, revealing a consistent trade-off: higher mask ratios improve classification but slightly degrade reconstruction fidelity. Our findings demonstrate that MAE pretraining on physics-rich simulations provides a flexible, reusable encoder for multiple strong-lensing analysis tasks.

</details>


### [77] [TextMamba: Scene Text Detector with Mamba](https://arxiv.org/abs/2512.06657)
*Qiyan Zhao,Yue Yan,Da-Han Wang*

Main category: cs.CV

TL;DR: 提出基于Mamba的场景文本检测器，结合选择机制与注意力层优化长序列信息提取，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统基于卷积神经网络的方法在全局特征提取方面存在局限，而大多数基于Transformer的方法直接依赖原生注意力层作为编码器，未评估其跨域局限性和固有缺点（如建模长距离依赖时遗忘重要信息或关注无关表示）。Mamba状态空间模型通过线性复杂度选择机制展示了更好的长距离依赖建模能力。

Method: 采用Top_k算法显式选择关键信息并减少Mamba建模中无关信息的干扰，设计了双尺度前馈网络和嵌入金字塔增强模块以促进高维隐藏状态交互和多尺度特征融合。

Result: 在CTW1500、TotalText和ICDAR19ArT等基准测试中，F-measure分别达到89.7%、89.2%和78.5%。

Conclusion: 该论文提出了一种基于Mamba的新型场景文本检测器，通过结合选择机制与注意力层，增强了编码器从长序列中提取相关信息的能力，并在多个基准测试中取得了最先进或竞争性的性能。

Abstract: In scene text detection, Transformer-based methods have addressed the global feature extraction limitations inherent in traditional convolution neural network-based methods. However, most directly rely on native Transformer attention layers as encoders without evaluating their cross-domain limitations and inherent shortcomings: forgetting important information or focusing on irrelevant representations when modeling long-range dependencies for text detection. The recently proposed state space model Mamba has demonstrated better long-range dependencies modeling through a linear complexity selection mechanism. Therefore, we propose a novel scene text detector based on Mamba that integrates the selection mechanism with attention layers, enhancing the encoder's ability to extract relevant information from long sequences. We adopt the Top\_k algorithm to explicitly select key information and reduce the interference of irrelevant information in Mamba modeling. Additionally, we design a dual-scale feed-forward network and an embedding pyramid enhancement module to facilitate high-dimensional hidden state interactions and multi-scale feature fusion. Our method achieves state-of-the-art or competitive performance on various benchmarks, with F-measures of 89.7\%, 89.2\%, and 78.5\% on CTW1500, TotalText, and ICDAR19ArT, respectively. Codes will be available.

</details>


### [78] [MedGRPO: Multi-Task Reinforcement Learning for Heterogeneous Medical Video Understanding](https://arxiv.org/abs/2512.06581)
*Yuhao Su,Anwesa Choudhuri,Zhongpai Gao,Benjamin Planche,Van Nguyen Nguyen,Meng Zheng,Yuhan Shen,Arun Innanje,Terrence Chen,Ehsan Elhamifar,Ziyan Wu*

Main category: cs.CV

TL;DR: 提出了MedVidBench基准和MedGRPO框架，显著提升了医学视频理解的模型性能。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型在医学视频理解中存在空间精度、时间推理和临床语义方面的挑战，需要专门的基准和方法来提升性能。

Method: 提出了MedGRPO框架，包含跨数据集奖励归一化和医学LLM评委两项创新技术，以解决标准强化学习在多数据集训练中的不稳定性问题。

Result: 在MedVidBench上监督微调的Qwen2.5-VL-7B模型显著优于GPT-4.1和Gemini-2.5-Flash，MedGRPO框架进一步提升了性能。

Conclusion: 本文通过引入MedVidBench基准和MedGRPO框架，为医学领域的视觉语言模型建立了基础性基准和稳健的训练方法，显著提升了模型性能。

Abstract: Large vision-language models struggle with medical video understanding, where spatial precision, temporal reasoning, and clinical semantics are critical. To address this, we first introduce \textbf{MedVidBench}, a large-scale benchmark of 531,850 video-instruction pairs across 8 medical sources spanning video, segment, and frame-level tasks, curated through a rigorous quality assurance pipeline with expert-guided prompting and dual-model validation. While supervised fine-tuning on MedVidBench yields noticeable gains, standard Reinforcement Learning (RL) fails due to imbalanced reward scales across datasets, which destabilizes optimization and leads to training collapse. To overcome this, we introduce \textbf{MedGRPO}, a novel RL framework for balanced multi-dataset training with two key innovations: (1) \emph{cross-dataset reward normalization} that maps each dataset's median performance to a common reward value, ensuring fair optimization regardless of difficulty, and (2) a \emph{medical LLM judge} that evaluates caption quality on five clinical dimensions through comparative similarity scoring. Supervised fine-tuning Qwen2.5-VL-7B on MedVidBench substantially outperforms GPT-4.1 and Gemini-2.5-Flash across all tasks, demonstrating MedVidBench's efficacy, while our MedGRPO framework further improves upon the SFT baseline across grounding and captioning tasks. Our work establishes a foundational benchmark and robust training methodology for advancing vision-language models in medical domains. Our project website is available at https://yuhaosu.github.io/MedGRPO/.

</details>


### [79] [The Role of Entropy in Visual Grounding: Analysis and Optimization](https://arxiv.org/abs/2512.06726)
*Shuo Li,Jiajun Sun,Zhihao Zhang,Xiaoran Fan,Senjie Jin,Hui Li,Yuming Yang,Junjie Ye,Lixing Shen,Tao Ji,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.CV

TL;DR: ECVGPO是一种用于视觉 grounding 任务的熵控制算法，通过平衡探索与利用，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 尽管在多模态大语言模型（MLLMs）的微调中，熵控制技术取得了显著进展，但在感知导向任务（如视觉 grounding）中熵的作用和控制策略仍未被充分探索。

Method: 研究者提出了ECVGPO（Entropy Control Visual Grounding Policy Optimization），一种可解释的算法，专门用于视觉 grounding 任务中的熵控制。

Result: 实验表明，ECVGPO在多个基准测试和模型中均取得了广泛的性能提升。

Conclusion: ECVGPO算法通过有效的熵控制，在视觉 grounding 任务中实现了探索与利用的更好平衡，并在多个基准测试和模型中展现了广泛的性能提升。

Abstract: Recent advances in fine-tuning multimodal large language models (MLLMs) using reinforcement learning have achieved remarkable progress, particularly with the introduction of various entropy control techniques. However, the role and characteristics of entropy in perception-oriented tasks like visual grounding, as well as effective strategies for controlling it, remain largely unexplored. To address this issue, we focus on the visual grounding task and analyze the role and characteristics of entropy in comparison to reasoning tasks. Building on these findings, we introduce ECVGPO (Entropy Control Visual Grounding Policy Optimization), an interpretable algorithm designed for effective entropy regulation. Through entropy control, the trade-off between exploration and exploitation is better balanced. Experiments show that ECVGPO achieves broad improvements across various benchmarks and models.

</details>


### [80] [From Remote Sensing to Multiple Time Horizons Forecasts: Transformers Model for CyanoHAB Intensity in Lake Champlain](https://arxiv.org/abs/2512.06598)
*Muhammad Adil,Patrick J. Clemins,Andrew W. Schroth,Panagiotis D. Oikonomou,Donna M. Rizzo,Peter D. F. Isles,Xiaohan Zhang,Kareem I. Hannoun,Scott Turnbull,Noah B. Beckage,Asim Zia,Safwan Wshah*

Main category: cs.CV

TL;DR: A Transformer-BiLSTM model effectively forecasts CyanoHAB intensities up to 14 days using sparse satellite data, aiding management with reliable early warnings.


<details>
  <summary>Details</summary>
Motivation: CyanoHABs threaten aquatic ecosystems and public health, with Lake Champlain particularly vulnerable. Remote sensing offers scalable monitoring where in situ data is lacking.

Method: The framework combines Transformers and BiLSTM to process sparse Cyanobacterial Index and temperature data from satellites, using a two-stage preprocessing pipeline (forward fill, weighted temporal imputation, smoothing) and feature transformation (equal frequency binning, temperature statistics extraction).

Result: The model achieved high F1 scores (89.5%, 86.4%, 85.5%) for 1-3 day forecasts and maintained 78.9% F1 score with 82.6% AUC at 14-day horizon, demonstrating robust performance.

Conclusion: The study confirms the Transformer-BiLSTM model's effectiveness in predicting CyanoHAB intensities up to 14 days in advance, providing reliable early warnings for management despite sparse satellite data.

Abstract: Cyanobacterial Harmful Algal Blooms (CyanoHABs) pose significant threats to aquatic ecosystems and public health globally. Lake Champlain is particularly vulnerable to recurring CyanoHAB events, especially in its northern segment: Missisquoi Bay, St. Albans Bay, and Northeast Arm, due to nutrient enrichment and climatic variability. Remote sensing provides a scalable solution for monitoring and forecasting these events, offering continuous coverage where in situ observations are sparse or unavailable. In this study, we present a remote sensing only forecasting framework that combines Transformers and BiLSTM to predict CyanoHAB intensities up to 14 days in advance. The system utilizes Cyanobacterial Index data from the Cyanobacterial Assessment Network and temperature data from Moderate Resolution Imaging Spectroradiometer satellites to capture long range dependencies and sequential dynamics in satellite time series. The dataset is very sparse, missing more than 30% of the Cyanobacterial Index data and 90% of the temperature data. A two stage preprocessing pipeline addressed data gaps by applying forward fill and weighted temporal imputation at the pixel level, followed by smoothing to reduce the discontinuities of CyanoHAB events. The raw dataset is transformed into meaningful features through equal frequency binning for the Cyanobacterial Index values and extracted temperature statistics. Transformer BiLSTM model demonstrates strong forecasting performance across multiple horizons, achieving F1 scores of 89.5%, 86.4%, and 85.5% at one, two, and three-day forecasts, respectively, and maintaining an F1 score of 78.9% with an AUC of 82.6% at the 14-day horizon. These results confirm the model's ability to capture complex spatiotemporal dynamics from sparse satellite data and to provide reliable early warning for CyanoHABs management.

</details>


### [81] [Task-Model Alignment: A Simple Path to Generalizable AI-Generated Image Detection](https://arxiv.org/abs/2512.06746)
*Ruoxin Chen,Jiahui Gao,Kaiqing Lin,Keyue Zhang,Yandan Zhao,Isabel Guan,Taiping Yao,Shouhong Ding*

Main category: cs.CV

TL;DR: AlignGemini通过双分支设计（语义和像素伪影检测）解决了VLMs在AIGI检测中的任务-模型不对齐问题，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLMs在AI生成图像检测中存在任务-模型不对齐问题，导致性能不佳。

Method: 提出了AlignGemini，一个双分支检测器，分别基于纯语义监督的VLM和纯像素伪影监督的专家模型。

Result: 在五个基准测试中，AlignGemini平均准确率提升了9.5%。

Conclusion: AlignGemini通过任务-模型对齐原则，显著提升了AI生成图像检测的泛化能力，证明了该方法的有效性。

Abstract: Vision Language Models (VLMs) are increasingly adopted for AI-generated images (AIGI) detection, yet converting VLMs into detectors requires substantial resource, while the resulting models still exhibit severe hallucinations. To probe the core issue, we conduct an empirical analysis and observe two characteristic behaviors: (i) fine-tuning VLMs on high-level semantic supervision strengthens semantic discrimination and well generalize to unseen data; (ii) fine-tuning VLMs on low-level pixel-artifact supervision yields poor transfer. We attribute VLMs' underperformance to task-model misalignment: semantics-oriented VLMs inherently lack sensitivity to fine-grained pixel artifacts, and semantically non-discriminative pixel artifacts thus exceeds their inductive biases. In contrast, we observe that conventional pixel-artifact detectors capture low-level pixel artifacts yet exhibit limited semantic awareness relative to VLMs, highlighting that distinct models are better matched to distinct tasks. In this paper, we formalize AIGI detection as two complementary tasks--semantic consistency checking and pixel-artifact detection--and show that neglecting either induces systematic blind spots. Guided by this view, we introduce the Task-Model Alignment principle and instantiate it as a two-branch detector, AlignGemini, comprising a VLM fine-tuned exclusively with pure semantic supervision and a pixel-artifact expert trained exclusively with pure pixel-artifact supervision. By enforcing orthogonal supervision on two simplified datasets, each branch trains to its strengths, producing complementary discrimination over semantic and pixel cues. On five in-the-wild benchmarks, AlignGemini delivers a +9.5 gain in average accuracy, supporting task-model alignment as an effective path to generalizable AIGI detection.

</details>


### [82] [Learning Relative Gene Expression Trends from Pathology Images in Spatial Transcriptomics](https://arxiv.org/abs/2512.06612)
*Kazuya Nishimura,Haruka Hirose,Ryoma Bise,Kaito Shiku,Yasuhiro Kojima*

Main category: cs.CV

TL;DR: 提出STRank损失函数，通过学习基因相对表达模式而非绝对水平，有效减少RNA测序中的噪声和批次效应影响。


<details>
  <summary>Details</summary>
Motivation: 由于测序技术的复杂性和细胞间的内在变异性，观测到的基因表达含有随机噪声和批次效应，准确估计绝对表达值具有挑战性。

Method: 提出了一种新的目标，即学习基因的相对表达模式而非绝对水平，并基于此假设设计了一个名为STRank的新型损失函数。

Result: 实验结果表明，STRank方法能够有效处理噪声和批次效应，学习到一致的相对表达模式。

Conclusion: 通过实验验证，STRank方法在合成数据集和真实数据集上均表现出有效性，能够有效减少RNA测序成本。

Abstract: Gene expression estimation from pathology images has the potential to reduce the RNA sequencing cost. Point-wise loss functions have been widely used to minimize the discrepancy between predicted and absolute gene expression values. However, due to the complexity of the sequencing techniques and intrinsic variability across cells, the observed gene expression contains stochastic noise and batch effects, and estimating the absolute expression values accurately remains a significant challenge. To mitigate this, we propose a novel objective of learning relative expression patterns rather than absolute levels. We assume that the relative expression levels of genes exhibit consistent patterns across independent experiments, even when absolute expression values are affected by batch effects and stochastic noise in tissue samples. Based on the assumption, we model the relation and propose a novel loss function called STRank that is robust to noise and batch effects. Experiments using synthetic datasets and real datasets demonstrate the effectiveness of the proposed method. The code is available at https://github.com/naivete5656/STRank.

</details>


### [83] [VisChainBench: A Benchmark for Multi-Turn, Multi-Image Visual Reasoning Beyond Language Priors](https://arxiv.org/abs/2512.06759)
*Wenbo Lyu,Yingjun Du,Jinglin Zhao,Xianton Zhen,Ling Shao*

Main category: cs.CV

TL;DR: VisChainBench是一个新的大规模基准测试，用于评估LVLMs在多步骤视觉推理中的能力，特别强调序列化任务和最小语言指导。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试主要关注静态或水平比较，忽视了渐进式、依赖上下文的推理和视觉到视觉的推理挑战。

Method: 使用多代理生成流程构建基准测试，确保视觉多样性和控制语言偏见。

Result: VisChainBench包含1,457个任务，涵盖20,000多张图像，跨越三个不同领域，模拟现实世界的决策过程。

Conclusion: VisChainBench是一个大规模基准测试，旨在严格评估大型视觉语言模型（LVLMs）在多步骤视觉推理中的能力，特别是在序列化、相互依赖的任务中，且语言指导最少。

Abstract: Understanding multi-image, multi-turn scenarios is a critical yet underexplored capability for Large Vision-Language Models (LVLMs). Existing benchmarks predominantly focus on static or horizontal comparisons -- e.g., spotting visual differences or assessing appropriateness -- while relying heavily on language cues. Such settings overlook progressive, context-dependent reasoning and the challenge of visual-to-visual inference. To bridge this gap, we present VisChainBench, a large-scale benchmark designed to rigorously evaluate LVLMs' ability to perform multi-step visual reasoning across sequential, interdependent tasks with minimal language guidance. VisChainBench contains 1,457 tasks spanning over 20,000 images across three diverse domains (e.g., daily scenarios, engineering troubleshooting), structured to mimic real-world decision-making processes. Uniquely, the benchmark is constructed using a multi-agent generation pipeline, ensuring high visual diversity and controlled language bias. All the benchmark data and code for benchmark construction are available for viewing and download via following Link: https://huggingface.co/datasets/eyehole/VisChainBench

</details>


### [84] [Hierarchical Deep Learning for Diatom Image Classification: A Multi-Level Taxonomic Approach](https://arxiv.org/abs/2512.06613)
*Yueying Ke*

Main category: cs.CV

TL;DR: 层次化卷积网络通过结合分类层次，提升了硅藻多级分类的准确性和错误局部性，优于扁平模型。


<details>
  <summary>Details</summary>
Motivation: 传统硅藻分类依赖专家，而现有深度学习方法多为扁平分类，忽略了分类层次结构。研究旨在探索层次化网络是否能提升分类准确性和错误局部性。

Method: 提出了一种具有五个级联头的层次化卷积网络，每个头接收共享的骨干特征和来自更高层次的概率分布，并通过二进制掩码限制预测空间。

Result: 层次化模型在物种级别与扁平模型持平（69.4%准确率），但在更高分类级别表现更优。错误分类时，92.5%的错误在属级别正确，远高于扁平模型的67.2%。

Conclusion: 层次化卷积网络通过结合分类层次结构，显著提升了硅藻分类的准确性和错误局部性，为多级分类任务提供了更鲁棒、可解释且生物学对齐的预测。

Abstract: Accurate taxonomic identification of diatoms is essential for aquatic ecosystem monitoring, yet conventional methods depend heavily on expert taxonomists. Recent deep learning approaches improve automation, but most treat diatom recognition as flat classification predicting only one taxonomic rank. We investigate whether embedding taxonomic hierarchy into neural network architectures can improve both accuracy and error locality.
  We introduce a hierarchical convolutional network with five cascaded heads that jointly predict class, order, family, genus, and species. Each head receives shared backbone features and probability distributions from higher levels, with binary masks restricting predictions to valid descendants during training and inference. Using a filtered dataset of 1,456 diatom images covering 82 species, we compare hierarchical and flat models under identical settings.
  The hierarchical model matches flat baselines at species level (69.4% accuracy) while outperforming at all upper taxonomic levels. When species predictions fail, errors remain taxonomically local: 92.5 % of misclassified species are correctly predicted at genus level, versus 67.2% for flat baselines. The hierarchical model reduces mean taxonomic distance by 38.2% (1.209 vs. 1.955).
  Progressive training reveals bidirectional mechanisms: hierarchical constraint masks operate top-down to constrain prediction space, while gradients from fine-grained levels propagate bottom-up through the shared backbone, refining features. This improves class accuracy from 96.2% to 99.5% and yields 6-8% gains at upper levels, producing more robust, interpretable, and biologically aligned predictions for multi-level taxonomic classification.

</details>


### [85] [Stitch and Tell: A Structured Multimodal Data Augmentation Method for Spatial Understanding](https://arxiv.org/abs/2512.06769)
*Hang Yin,Xiaomin He,PeiWen Yuan,Yiwei Li,Jiayi Shi,Wenxiao Fan,Shaoxiong Feng,Kan Li*

Main category: cs.CV

TL;DR: SiTe方法通过拼接图像生成空间感知数据，显著提升模型空间理解能力，同时保持通用性能。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型常出现空间幻觉问题，即生成关于图像中物体相对位置的错误描述，这主要源于图像与文本之间的不对称性。

Method: 提出了一种名为Stitch and Tell（SiTe）的简单、无需标注、即插即用方法，通过沿空间轴拼接图像并生成基于拼接布局的空间感知描述或问答对，为数据注入结构化空间监督。

Result: 实验表明，SiTe在空间理解任务（如MME_Position和Spatial-MM）上表现提升（分别+5.50%和+4.19%），同时在通用视觉语言基准（如COCO-QA和MMBench）上保持或提升性能（分别+1.02%和+4.76%）。

Conclusion: 显式地将空间感知结构注入训练数据是一种有效的方法，既能减轻空间幻觉，又能提升空间理解能力，同时保持通用视觉语言能力。

Abstract: Existing vision-language models often suffer from spatial hallucinations, i.e., generating incorrect descriptions about the relative positions of objects in an image. We argue that this problem mainly stems from the asymmetric properties between images and text. To enrich the spatial understanding ability of vision-language models, we propose a simple, annotation-free, plug-and-play method named $\text{Stitch and Tell}$ (abbreviated as SiTe), which injects structured spatial supervision into data. It constructs stitched image-text pairs by stitching images along a spatial axis and generating spatially-aware captions or question answer pairs based on the layout of stitched image, without relying on costly advanced models or human involvement. We evaluate SiTe across three architectures including LLaVA-v1.5-7B, LLaVA-Qwen2-1.5B and HALVA-7B, two training datasets, and eight benchmarks. Experiments show that SiTe improves spatial understanding tasks such as $\text{MME}_{\text{Position}}$ (+5.50%) and Spatial-MM (+4.19%), while maintaining or improving performance on general vision-language benchmarks including COCO-QA (+1.02%) and MMBench (+4.76%). Our findings suggest that explicitly injecting spatially-aware structure into training data offers an effective way to mitigate spatial hallucinations and improve spatial understanding, while preserving general vision-language capabilities.

</details>


### [86] [RDSplat: Robust Watermarking Against Diffusion Editing for 3D Gaussian Splatting](https://arxiv.org/abs/2512.06774)
*Longjie Zhao,Ziming Hong,Zhenyang Ren,Runnan Chen,Mingming Gong,Tongliang Liu*

Main category: cs.CV

TL;DR: RDSplat是一种针对3D高斯泼溅的鲁棒水印技术，通过嵌入低频高斯和对抗训练，有效抵抗扩散编辑，保持水印不可见性。


<details>
  <summary>Details</summary>
Motivation: 现有3DGS水印方法对基于扩散的编辑高度脆弱，容易被擦除嵌入的来源信息，因此急需开发对扩散编辑具有内在鲁棒性的3DGS水印技术。

Method: RDSplat采用多域框架，在3DGS空间中嵌入水印，通过协调协方差正则化和2D滤波，针对扩散编辑保留的低频高斯进行水印嵌入，并利用高斯模糊作为训练代理进行对抗微调。

Result: 在三个基准数据集上的全面定量和定性评估表明，RDSplat在扩散编辑下保持了卓越的鲁棒性，同时保持了水印的不可见性。

Conclusion: RDSplat在3D高斯泼溅（3DGS）中引入了抗扩散编辑的鲁棒水印技术，通过针对低频高斯和对抗训练，显著提升了水印的鲁棒性和不可见性，实现了最先进的性能。

Abstract: 3D Gaussian Splatting (3DGS) has enabled the creation of digital assets and downstream applications, underscoring the need for robust copyright protection via digital watermarking. However, existing 3DGS watermarking methods remain highly vulnerable to diffusion-based editing, which can easily erase embedded provenance. This challenge highlights the urgent need for 3DGS watermarking techniques that are intrinsically resilient to diffusion-based editing. In this paper, we introduce RDSplat, a Robust watermarking paradigm against Diffusion editing for 3D Gaussian Splatting. RDSplat embeds watermarks into 3DGS components that diffusion-based editing inherently preserve, achieved through (i) proactively targeting low-frequency Gaussians and (ii) adversarial training with a diffusion proxy. Specifically, we introduce a multi-domain framework that operates natively in 3DGS space and embeds watermarks into diffusion-editing-preserved low-frequency Gaussians via coordinated covariance regularization and 2D filtering. In addition, we exploit the low-pass filtering behavior of diffusion-based editing by using Gaussian blur as an efficient training surrogate, enabling adversarial fine-tuning that further enhances watermark robustness against diffusion-based editing. Empirically, comprehensive quantitative and qualitative evaluations on three benchmark datasets demonstrate that RDSplat not only maintains superior robustness under diffusion-based editing, but also preserves watermark invisibility, achieving state-of-the-art performance.

</details>


### [87] [RMAdapter: Reconstruction-based Multi-Modal Adapter for Vision-Language Models](https://arxiv.org/abs/2512.06811)
*Xiang Lin,Weixin Li,Shu Guo,Lihong Wang,Di Huang*

Main category: cs.CV

TL;DR: RMAdapter是一种双分支适配器，通过适应分支和重建分支平衡任务特定与通用知识，在少样本场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决少样本场景下预训练视觉语言模型（VLMs）微调时任务特定适应与泛化能力平衡的挑战，并填补基于适配器方法的研究空白。

Method: 提出了一种基于重建的多模态适配器（RMAdapter），采用双分支架构：适应分支通过参数高效微调注入任务特定知识，重建分支通过重建潜在空间特征保留通用知识。设计还包括局部重建损失计算、共享投影模块和一致性约束。

Result: RMAdapter在三个代表性任务（新类别泛化、新目标数据集泛化和领域泛化）中均优于最先进方法，且无需数据增强或重复提示设计。

Conclusion: RMAdapter通过双分支架构（适应分支和重建分支）在少样本场景下有效平衡了任务特定适应和泛化能力，显著优于现有方法。

Abstract: Pre-trained Vision-Language Models (VLMs), \textit{e.g.} CLIP, have become essential tools in multimodal transfer learning. However, fine-tuning VLMs in few-shot scenarios poses significant challenges in balancing task-specific adaptation and generalization in the obtained model. Meanwhile, current researches have predominantly focused on prompt-based adaptation methods, leaving adapter-based approaches underexplored and revealing notable performance gaps. To address these challenges, we introduce a novel Reconstruction-based Multimodal Adapter (RMAdapter), which leverages a dual-branch architecture. Unlike conventional single-branch adapters, RMAdapter consists of: (1) an adaptation branch that injects task-specific knowledge through parameter-efficient fine-tuning, and (2) a reconstruction branch that preserves general knowledge by reconstructing latent space features back into the original feature space. This design facilitates a dynamic balance between general and task-specific knowledge. Importantly, although RMAdapter introduces an additional reconstruction branch, it is carefully optimized to remain lightweight. By computing reconstruction loss locally at each layer and sharing projection modules, the overall computational overhead is kept minimal. A consistency constraint is also incorporated to better regulate the trade-off between discriminability and generalization. We comprehensively evaluate the effectiveness of RMAdapter on three representative tasks: generalization to new categories, generalization to new target datasets, and domain generalization. Without relying on data augmentation or duplicate prompt designs, our RMAdapter consistently outperforms state-of-the-art approaches across all evaluation metrics.

</details>


### [88] [Personalized Image Descriptions from Attention Sequences](https://arxiv.org/abs/2512.06662)
*Ruoyu Xue,Hieu Le,Jingyi Xu,Sounak Mondal,Abe Leite,Gregory Zelinsky,Minh Hoai,Dimitris Samaras*

Main category: cs.CV

TL;DR: DEPER通过结合语言风格和观看行为的个性化建模，显著提升了图像描述的质量和人类对齐性。


<details>
  <summary>Details</summary>
Motivation: 现有模型仅关注语言风格，忽略了个人观看模式的差异。本文旨在填补这一空白，通过显式建模个性化观看行为作为描述生成的核心因素。

Method: DEPER（DEscription-PERception persona encoder）通过学习一个主题嵌入来捕捉语言风格和观看行为，并通过辅助注意力预测任务进行指导。一个轻量级适配器将这些嵌入与冻结的视觉语言模型对齐，实现无需重新训练的少样本个性化。

Result: 在涵盖不同观看任务和描述类型的四个数据集上，DEPER实现了平均24%的提升，表明建模个性化注意力可以产生更符合人类和高品质的描述。

Conclusion: 理解人们如何观看有助于预测他们的描述内容；建模人类感知的多样性可以提高多模态系统的性能和人类对齐性。

Abstract: People can view the same image differently: they focus on different regions, objects, and details in varying orders and describe them in distinct linguistic styles. This leads to substantial variability in image descriptions. However, existing models for personalized image description focus on linguistic style alone, with no prior work leveraging individual viewing patterns. We address this gap by explicitly modeling personalized viewing behavior as a core factor in description generation. Our method, DEPER (DEscription-PERception persona encoder), learns a subject embedding that captures both linguistic style and viewing behavior, guided by an auxiliary attention-prediction task. A lightweight adapter aligns these embeddings with a frozen vision-language model, enabling few-shot personalization without retraining. Across four datasets spanning diverse viewing tasks and both short and detailed descriptions, DEPER achieves a 24% average improvement, showing that modeling personalized attention produces more human-aligned and high-quality descriptions. We posit that understanding how people see helps predict what they say; modeling human diversity in perception can improve both performance and human alignment in multimodal systems.

</details>


### [89] [CoT4Det: A Chain-of-Thought Framework for Perception-Oriented Vision-Language Tasks](https://arxiv.org/abs/2512.06663)
*Yu Qi,Yumeng Zhang,Chenting Gong,Xiao Tan,Weiming Zhang,Wei Zhang,Jingdong Wang*

Main category: cs.CV

TL;DR: CoT4Det通过三步策略提升LVLMs在感知任务上的性能，显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 尽管LVLMs在广泛的视觉语言任务中表现优异，但在感知任务（如目标检测）上表现显著劣于任务专用模型。

Method: 提出了Chain-of-Thought for Detection (CoT4Det)，将感知任务重新定义为分类、计数和定位三个可解释的步骤。

Result: CoT4Det将Qwen2.5-VL-7B-Instruct在COCO2017 val上的mAP从19.0%提升至33.0%，并在多个感知基准测试中表现优异。

Conclusion: CoT4Det通过将感知任务分解为分类、计数和定位三个步骤，显著提升了LVLMs在感知任务上的性能，同时保持了其通用视觉语言能力。

Abstract: Large Vision-Language Models (LVLMs) have demonstrated remarkable success in a broad range of vision-language tasks, such as general visual question answering and optical character recognition (OCR). However, their performance on perception-centric tasks -- such as object detection, semantic segmentation, and depth estimation -- remains significantly inferior to that of task-specific expert models. For example, Qwen2.5-VL-7B-Instruct achieves only 19% mAP on COCO2017 val, particularly struggling with dense scenes and small object recall. In this work, we introduce Chain-of-Thought for Detection (CoT4Det), a simple but efficient strategy that reformulates perception tasks into three interpretable steps: classification, counting, and grounding -- each more naturally aligned with the reasoning capabilities of LVLMs. Extensive experiments demonstrate that our method significantly improves perception performance without compromising general vision language capabilities. With a standard Qwen2.5-VL-7B-Instruct, CoT4Det boosts mAP from 19.0% to 33.0% on COCO2017 val and achieves competitive results across a variety of perception benchmarks, outperforming baselines by +2% on RefCOCO series and 19% on Flickr30k entities.

</details>


### [90] [Less Is More, but Where? Dynamic Token Compression via LLM-Guided Keyframe Prior](https://arxiv.org/abs/2512.06866)
*Yulin Li,Haokun Gui,Ziyang Fan,Junjie Wang,Bin Kang,Bin Chen,Zhuotao Tian*

Main category: cs.CV

TL;DR: DyToK是一种无需训练的token动态压缩方法，利用VLLM的注意力机制优化长视频处理效率，显著提升推理速度且兼容现有压缩技术。


<details>
  <summary>Details</summary>
Motivation: 现有方法在长视频处理中存在计算效率低下的问题，且关键帧采样方法引入了额外计算成本，帧选择范式不够优化。

Method: DyToK利用VLLM固有的注意力机制，动态压缩token，无需额外训练。通过分析VLLM注意力层，发现其自然编码了查询条件的关键帧先验，从而动态调整token保留比例。

Result: DyToK在多个VLLM上实现了4.3倍的推理加速，同时保持准确性，展示了卓越的效率-准确性权衡。

Conclusion: DyToK通过动态调整每帧的token保留比例，实现了效率和准确性的最佳平衡，并与现有压缩方法兼容，显著提升了推理速度。

Abstract: Recent advances in Video Large Language Models (VLLMs) have achieved remarkable video understanding capabilities, yet face critical efficiency bottlenecks due to quadratic computational growth with lengthy visual token sequences of long videos. While existing keyframe sampling methods can improve temporal modeling efficiency, additional computational cost is introduced before feature encoding, and the binary frame selection paradigm is found suboptimal. Therefore, in this work, we propose Dynamic Token compression via LLM-guided Keyframe prior (DyToK), a training-free paradigm that enables dynamic token compression by harnessing VLLMs' inherent attention mechanisms. Our analysis reveals that VLLM attention layers naturally encoding query-conditioned keyframe priors, by which DyToK dynamically adjusts per-frame token retention ratios, prioritizing semantically rich frames while suppressing redundancies. Extensive experiments demonstrate that DyToK achieves state-of-the-art efficiency-accuracy tradeoffs. DyToK shows plug-and-play compatibility with existing compression methods, such as VisionZip and FastV, attaining 4.3x faster inference while preserving accuracy across multiple VLLMs, such as LLaVA-OneVision and Qwen2.5-VL. Code is available at https://github.com/yu-lin-li/DyToK .

</details>


### [91] [1 + 1 > 2: Detector-Empowered Video Large Language Model for Spatio-Temporal Grounding and Reasoning](https://arxiv.org/abs/2512.06673)
*Shida Gao,Feng Xue,Xiangfeng Wang,Anlong Ming,Teng Long,Yihua Shao,Haozhe Wang,Zhaowen Lin,Wei Wang,Nicu Sebe*

Main category: cs.CV

TL;DR: DEViL结合视频LLM和开放词汇检测器，通过RST和TTReg提升时空定位性能，在STVG和GroundedVQA任务中表现突出。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）在处理时空定位任务时，因自回归空间解码导致输出序列过长，空间误差随时间累积，定位结果逐渐漂移。DEViL旨在解决这一问题。

Method: DEViL采用了一种非自回归的空间解码方法，通过RST将用户查询蒸馏为丰富的语义表示，并利用TTReg确保时间一致性。

Result: 实验表明，DEViL在多种细粒度视频理解任务中表现优异，尤其是在STVG和GroundedVQA任务上。

Conclusion: DEViL通过结合视频LLM和开放词汇检测器（OVD），并引入参考语义令牌（RST）和管状挖掘时间正则化（TTReg），显著提升了时空定位和推理任务的性能，尤其在STVG和GroundedVQA任务中表现突出。

Abstract: Spatio-temporal grounding and reasoning aims to locate the temporal segment and spatial region of an event in a video given a user query, while also reasoning about semantics such as causality, temporal order, and action relationships. To achieve this, current MLLMs primarily treats bounding boxes as text tokens and generates them autoregressively. However, such autoregressive spatial decoding leads to very-long output sequences, causing spatial errors to accumulated over time and the localization results to progressively drift across a video. To address this, we present a Detector-Empowered Video LLM, short for DEViL, which couples a Video LLM with an open-vocabulary detector (OVD). Specifically, the MLLM and detector are connected via a reference-semantic token (RST) that distills the user query into a rich semantic representation. Unlike tokens that merely serve as spatial prompts or segmentor switches, the RST functions as both a control signal and a replacement for the OVD's text embedding, enabling end-to-end learning of both referential understanding and spatial localization. Furthermore, we propose a tube-mined temporal regularization (TTReg) within OVD, which drives the OVD to generate temporally-consistent queries for target objects, thereby ensuring effective temporal association. Experiments demonstrate that DEViL achieves strong performance across various fine-grained video understanding tasks, particularly STVG and GroundedVQA. Code will be released on https://github.com/gaostar123/DeViL.

</details>


### [92] [JoPano: Unified Panorama Generation via Joint Modeling](https://arxiv.org/abs/2512.06885)
*Wancheng Feng,Chen An,Zhenliang He,Meina Kan,Shiguang Shan,Lukun Wang*

Main category: cs.CV

TL;DR: JoPano是一种基于DiT的统一全景生成方法，通过联合面适配器和泊松融合技术提升质量，在多个任务和指标上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在两个主要问题：U-Net架构限制了生成全景的视觉质量，且独立处理两个核心任务导致建模冗余和效率低下。

Method: 提出了一种基于DiT架构的联合面全景生成方法（JoPano），包括联合面适配器、泊松融合技术和条件切换机制，以统一处理文本到全景和视图到全景生成任务。

Result: JoPano在文本到全景和视图到全景生成任务中均能生成高质量全景，在FID、CLIP-FID、IS和CLIP-Score等指标上表现优异。

Conclusion: JoPano方法通过统一文本到全景和视图到全景生成任务，在DiT架构的基础上，结合联合面适配器和泊松融合技术，显著提升了全景生成的质量和效率，并在多个评估指标上达到了最先进的性能。

Abstract: Panorama generation has recently attracted growing interest in the research community, with two core tasks, text-to-panorama and view-to-panorama generation. However, existing methods still face two major challenges: their U-Net-based architectures constrain the visual quality of the generated panoramas, and they usually treat the two core tasks independently, which leads to modeling redundancy and inefficiency. To overcome these challenges, we propose a joint-face panorama (JoPano) generation approach that unifies the two core tasks within a DiT-based model. To transfer the rich generative capabilities of existing DiT backbones learned from natural images to the panorama domain, we propose a Joint-Face Adapter built on the cubemap representation of panoramas, which enables a pretrained DiT to jointly model and generate different views of a panorama. We further apply Poisson Blending to reduce seam inconsistencies that often appear at the boundaries between cube faces. Correspondingly, we introduce Seam-SSIM and Seam-Sobel metrics to quantitatively evaluate the seam consistency. Moreover, we propose a condition switching mechanism that unifies text-to-panorama and view-to-panorama tasks within a single model. Comprehensive experiments show that JoPano can generate high-quality panoramas for both text-to-panorama and view-to-panorama generation tasks, achieving state-of-the-art performance on FID, CLIP-FID, IS, and CLIP-Score metrics.

</details>


### [93] [RunawayEvil: Jailbreaking the Image-to-Video Generative Models](https://arxiv.org/abs/2512.06674)
*Songping Wang,Rufan Qian,Yueming Lyu,Qinglong Liu,Linzhuang Zou,Jie Qin,Songhua Liu,Caifeng Shan*

Main category: cs.CV

TL;DR: RunawayEvil 是首个针对 I2V 模型的多模态越狱框架，通过动态进化能力显著提升攻击成功率，为漏洞分析和鲁棒视频生成系统提供了关键工具。


<details>
  <summary>Details</summary>
Motivation: 尽管 I2V 生成技术提供了显著的创意控制能力，但其在多模态系统中的安全性，尤其是对越狱攻击的脆弱性，尚未得到充分研究。RunawayEvil 旨在填补这一空白。

Method: RunawayEvil 基于“策略-战术-行动”范式，包含三个核心组件：(1) 策略感知命令单元，通过强化学习驱动的策略定制和基于 LLM 的策略探索实现攻击策略的自进化；(2) 多模态战术规划单元，生成协调的文本越狱指令和图像篡改指南；(3) 战术行动单元，执行并评估多模态协调攻击。

Result: 实验表明，RunawayEvil 在商业 I2V 模型（如 Open-Sora 2.0 和 CogVideoX）上实现了最先进的攻击成功率，在 COCO2017 数据集上比现有方法高出 58.5% 至 79%。

Conclusion: RunawayEvil 是一个针对 I2V 模型的多模态越狱框架，通过动态进化能力显著提升了攻击成功率，为 I2V 模型的漏洞分析提供了关键工具，从而为更鲁棒的视频生成系统奠定了基础。

Abstract: Image-to-Video (I2V) generation synthesizes dynamic visual content from image and text inputs, providing significant creative control. However, the security of such multimodal systems, particularly their vulnerability to jailbreak attacks, remains critically underexplored. To bridge this gap, we propose RunawayEvil, the first multimodal jailbreak framework for I2V models with dynamic evolutionary capability. Built on a "Strategy-Tactic-Action" paradigm, our framework exhibits self-amplifying attack through three core components: (1) Strategy-Aware Command Unit that enables the attack to self-evolve its strategies through reinforcement learning-driven strategy customization and LLM-based strategy exploration; (2) Multimodal Tactical Planning Unit that generates coordinated text jailbreak instructions and image tampering guidelines based on the selected strategies; (3) Tactical Action Unit that executes and evaluates the multimodal coordinated attacks. This self-evolving architecture allows the framework to continuously adapt and intensify its attack strategies without human intervention. Extensive experiments demonstrate RunawayEvil achieves state-of-the-art attack success rates on commercial I2V models, such as Open-Sora 2.0 and CogVideoX. Specifically, RunawayEvil outperforms existing methods by 58.5 to 79 percent on COCO2017. This work provides a critical tool for vulnerability analysis of I2V models, thereby laying a foundation for more robust video generation systems.

</details>


### [94] [EMGauss: Continuous Slice-to-3D Reconstruction via Dynamic Gaussian Modeling in Volume Electron Microscopy](https://arxiv.org/abs/2512.06684)
*Yumeng He,Zanwei Zhou,Yekun Zheng,Chen Liang,Yunbo Wang,Xiaokang Yang*

Main category: cs.CV

TL;DR: EMGauss通过高斯点云动态渲染和教师-学生自举机制，解决了vEM中各向异性结构的3D重建问题，提升了插值质量并免除了预训练需求。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法依赖各向同性假设，无法处理形态学各向异性结构，EMGauss旨在克服这一限制。

Method: EMGauss将切片到3D重建问题重新定义为基于高斯点云的3D动态场景渲染问题，并引入教师-学生自举机制以增强数据稀疏情况下的重建保真度。

Result: 与基于扩散和GAN的方法相比，EMGauss显著提升了插值质量，实现了连续切片合成，且无需大规模预训练。

Conclusion: EMGauss提供了一个通用的切片到3D重建框架，不仅显著提升了vEM中的插值质量，还消除了大规模预训练的需求，具有跨多种成像领域的潜在应用价值。

Abstract: Volume electron microscopy (vEM) enables nanoscale 3D imaging of biological structures but remains constrained by acquisition trade-offs, leading to anisotropic volumes with limited axial resolution. Existing deep learning methods seek to restore isotropy by leveraging lateral priors, yet their assumptions break down for morphologically anisotropic structures. We present EMGauss, a general framework for 3D reconstruction from planar scanned 2D slices with applications in vEM, which circumvents the inherent limitations of isotropy-based approaches. Our key innovation is to reframe slice-to-3D reconstruction as a 3D dynamic scene rendering problem based on Gaussian splatting, where the progression of axial slices is modeled as the temporal evolution of 2D Gaussian point clouds. To enhance fidelity in data-sparse regimes, we incorporate a Teacher-Student bootstrapping mechanism that uses high-confidence predictions on unobserved slices as pseudo-supervisory signals. Compared with diffusion- and GAN-based reconstruction methods, EMGauss substantially improves interpolation quality, enables continuous slice synthesis, and eliminates the need for large-scale pretraining. Beyond vEM, it potentially provides a generalizable slice-to-3D solution across diverse imaging domains.

</details>


### [95] [NeuroABench: A Multimodal Evaluation Benchmark for Neurosurgical Anatomy Identification](https://arxiv.org/abs/2512.06921)
*Ziyang Song,Zelin Zang,Xiaofan Ye,Boqiang Xu,Long Bai,Jinlin Wu,Hongliang Ren,Hongbin Liu,Jiebo Luo,Zhen Lei*

Main category: cs.CV

TL;DR: 论文提出NeuroABench，首个评估神经外科解剖理解的多模态基准，实验表明MLLMs在解剖识别上仍有显著差距。


<details>
  <summary>Details</summary>
Motivation: 现有研究和数据集主要关注手术流程理解，而忽视了解剖理解的关键作用，临床实践中外科医生依赖精确的解剖理解来解读和学习手术视频。

Method: 引入了Neurosurgical Anatomy Benchmark (NeuroABench)，包含9小时标注的神经外科视频，涵盖89种不同手术，评估68种临床解剖结构的识别。

Result: 实验显示，最佳MLLM在解剖识别任务中准确率仅为40.87%，而神经外科实习生的平均准确率为46.5%，最高为56%，最低为28%。

Conclusion: MLLMs在解剖理解方面取得了一定进展，但仍显著落后于人类平均水平，表明在这一领域仍有巨大提升空间。

Abstract: Multimodal Large Language Models (MLLMs) have shown significant potential in surgical video understanding. With improved zero-shot performance and more effective human-machine interaction, they provide a strong foundation for advancing surgical education and assistance. However, existing research and datasets primarily focus on understanding surgical procedures and workflows, while paying limited attention to the critical role of anatomical comprehension. In clinical practice, surgeons rely heavily on precise anatomical understanding to interpret, review, and learn from surgical videos. To fill this gap, we introduce the Neurosurgical Anatomy Benchmark (NeuroABench), the first multimodal benchmark explicitly created to evaluate anatomical understanding in the neurosurgical domain. NeuroABench consists of 9 hours of annotated neurosurgical videos covering 89 distinct procedures and is developed using a novel multimodal annotation pipeline with multiple review cycles. The benchmark evaluates the identification of 68 clinical anatomical structures, providing a rigorous and standardized framework for assessing model performance. Experiments on over 10 state-of-the-art MLLMs reveal significant limitations, with the best-performing model achieving only 40.87% accuracy in anatomical identification tasks. To further evaluate the benchmark, we extract a subset of the dataset and conduct an informative test with four neurosurgical trainees. The results show that the best-performing student achieves 56% accuracy, with the lowest scores of 28% and an average score of 46.5%. While the best MLLM performs comparably to the lowest-scoring student, it still lags significantly behind the group's average performance. This comparison underscores both the progress of MLLMs in anatomical understanding and the substantial gap that remains in achieving human-level performance.

</details>


### [96] [Lightweight Wasserstein Audio-Visual Model for Unified Speech Enhancement and Separation](https://arxiv.org/abs/2512.06689)
*Jisoo Park,Seonghak Lee,Guisik Kim,Taewoo Kim,Junseok Kwon*

Main category: cs.CV

TL;DR: UniVoiceLite 是一个轻量级无监督框架，统一语音增强和语音分离，利用音频-视觉线索和 Wasserstein 正则化，在复杂场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现实场景中常同时存在背景噪声和重叠说话人，传统方法将 SE 和 SS 视为独立任务，难以应对复杂场景，且现有方法多为复杂、参数密集的监督模型，泛化能力有限。

Method: UniVoiceLite 利用唇部运动和面部身份线索引导语音提取，并通过 Wasserstein 距离正则化稳定潜在空间，无需配对噪声-干净数据。

Result: 实验表明，UniVoiceLite 在噪声和多说话人场景中均表现优异，兼具效率和泛化能力。

Conclusion: UniVoiceLite 是一个轻量级且无监督的音频-视觉框架，成功统一了语音增强（SE）和语音分离（SS），在噪声和多说话人场景中表现出色，具有高效性和强泛化能力。

Abstract: Speech Enhancement (SE) and Speech Separation (SS) have traditionally been treated as distinct tasks in speech processing. However, real-world audio often involves both background noise and overlapping speakers, motivating the need for a unified solution. While recent approaches have attempted to integrate SE and SS within multi-stage architectures, these approaches typically involve complex, parameter-heavy models and rely on supervised training, limiting scalability and generalization. In this work, we propose UniVoiceLite, a lightweight and unsupervised audio-visual framework that unifies SE and SS within a single model. UniVoiceLite leverages lip motion and facial identity cues to guide speech extraction and employs Wasserstein distance regularization to stabilize the latent space without requiring paired noisy-clean data. Experimental results demonstrate that UniVoiceLite achieves strong performance in both noisy and multi-speaker scenarios, combining efficiency with robust generalization. The source code is available at https://github.com/jisoo-o/UniVoiceLite.

</details>


### [97] [Graph Convolutional Long Short-Term Memory Attention Network for Post-Stroke Compensatory Movement Detection Based on Skeleton Data](https://arxiv.org/abs/2512.06736)
*Jiaxing Fan,Jiaojiao Liu,Wenkong Wang,Yang Zhang,Xin Ma,Jichen Zhang*

Main category: cs.CV

TL;DR: 研究提出GCN-LSTM-ATT模型，用于检测中风后补偿性运动，准确率0.8580，优于传统算法，为康复训练优化提供支持。


<details>
  <summary>Details</summary>
Motivation: 中风患者普遍存在上肢运动功能障碍，康复训练中补偿性运动频发，不利于长期恢复。因此，检测补偿性运动具有重要意义。

Method: 研究基于骨骼数据，提出了GCN-LSTM-ATT模型，并与SVM、KNN和RF等传统机器学习算法进行了比较。数据通过Kinect深度相机采集，来自16名中风患者执行特定康复动作的骨骼数据。

Result: GCN-LSTM-ATT模型的检测准确率显著高于传统算法，达到0.8580。消融实验表明模型各组件对性能提升均有显著贡献。

Conclusion: 该研究提出的GCN-LSTM-ATT模型在检测中风后补偿性运动方面表现出色，准确率达到0.8580，显著优于传统机器学习算法。这为中风患者的康复训练策略优化提供了更精确的工具。

Abstract: Most stroke patients experience upper limb motor dysfunction. Compensatory movements are prevalent during rehabilitation training, which is detrimental to patients' long-term recovery. Therefore, detecting compensatory movements is of great significance. In this study, a Graph Convolutional Long Short-Term Memory Attention Network (GCN-LSTM-ATT) based on skeleton data is proposed for the detection of compensatory movements after stroke. Sixteen stroke patients were selected in the research. The skeleton data of the patients performing specific rehabilitation movements were collected using the Kinect depth camera. After data processing, detection models were constructed respectively using the GCN-LSTM-ATT model, the Support Vector Machine(SVM), the K-Nearest Neighbor algorithm(KNN), and the Random Forest(RF). The results show that the detection accuracy of the GCN-LSTM-ATT model reaches 0.8580, which is significantly higher than that of traditional machine learning algorithms. Ablation experiments indicate that each component of the model contributes significantly to the performance improvement. These findings provide a more precise and powerful tool for the detection of compensatory movements after stroke, and are expected to facilitate the optimization of rehabilitation training strategies for stroke patients.

</details>


### [98] [FedSCAl: Leveraging Server and Client Alignment for Unsupervised Federated Source-Free Domain Adaptation](https://arxiv.org/abs/2512.06738)
*M Yashwanth,Sampath Koti,Arunabh Singh,Shyam Marjit,Anirban Chakraborty*

Main category: cs.CV

TL;DR: FedSCAl通过服务器-客户端对齐机制解决联邦学习中的域适应问题，提升伪标签准确性并优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中源自由域适应（FFreeDA）问题，特别是在客户端数据存在显著域差距且无法访问源数据集的情况下，现有方法因数据异质性导致伪标签不可靠。

Method: 提出了FedSCAl框架，利用Server-Client Alignment（SCAl）机制对客户端更新进行正则化，通过对齐客户端和服务器模型的预测来减少客户端漂移。

Result: 在基准视觉数据集上的实验表明，FedSCAl在FFreeDA设置下 consistently 优于现有联邦学习方法。

Conclusion: FedSCAl框架通过Server-Client Alignment机制有效缓解了客户端漂移问题，显著提升了伪标签的准确性，并在分类任务中超越了现有联邦学习方法。

Abstract: We address the Federated source-Free Domain Adaptation (FFreeDA) problem, with clients holding unlabeled data with significant inter-client domain gaps. The FFreeDA setup constrains the FL frameworks to employ only a pre-trained server model as the setup restricts access to the source dataset during the training rounds. Often, this source domain dataset has a distinct distribution to the clients' domains. To address the challenges posed by the FFreeDA setup, adaptation of the Source-Free Domain Adaptation (SFDA) methods to FL struggles with client-drift in real-world scenarios due to extreme data heterogeneity caused by the aforementioned domain gaps, resulting in unreliable pseudo-labels. In this paper, we introduce FedSCAl, an FL framework leveraging our proposed Server-Client Alignment (SCAl) mechanism to regularize client updates by aligning the clients' and server model's predictions. We observe an improvement in the clients' pseudo-labeling accuracy post alignment, as the SCAl mechanism helps to mitigate the client-drift. Further, we present extensive experiments on benchmark vision datasets showcasing how FedSCAl consistently outperforms state-of-the-art FL methods in the FFreeDA setup for classification tasks.

</details>


### [99] [Power of Boundary and Reflection: Semantic Transparent Object Segmentation using Pyramid Vision Transformer with Transparent Cues](https://arxiv.org/abs/2512.07034)
*Tuan-Anh Vu,Hai Nguyen-Truong,Ziqiang Zheng,Binh-Son Hua,Qing Guo,Ivor Tsang,Sai-Kit Yeung*

Main category: cs.CV

TL;DR: TransCues通过结合边界和反射特征增强模块，显著提升透明物体分割性能，在多个数据集上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能充分捕捉透明物体的边界和反射特征，而人类感知依赖这些特征区分透明物体。

Method: 提出了一种金字塔形Transformer编码器-解码器架构TransCues，结合边界特征增强和反射特征增强模块。

Result: 在Trans10K-v2、MSD、RGBD-Mirror、TROSD和Stanford2D3D数据集上分别实现了+4.2%、+5.6%、+10.1%、+13.1%和+8.3%的mIoU提升。

Conclusion: TransCues框架通过结合边界特征增强和反射特征增强模块，显著提升了透明物体分割的性能，在多个基准数据集上大幅超越现有方法。

Abstract: Glass is a prevalent material among solid objects in everyday life, yet segmentation methods struggle to distinguish it from opaque materials due to its transparency and reflection. While it is known that human perception relies on boundary and reflective-object features to distinguish glass objects, the existing literature has not yet sufficiently captured both properties when handling transparent objects. Hence, we propose incorporating both of these powerful visual cues via the Boundary Feature Enhancement and Reflection Feature Enhancement modules in a mutually beneficial way. Our proposed framework, TransCues, is a pyramidal transformer encoder-decoder architecture to segment transparent objects. We empirically show that these two modules can be used together effectively, improving overall performance across various benchmark datasets, including glass object semantic segmentation, mirror object semantic segmentation, and generic segmentation datasets. Our method outperforms the state-of-the-art by a large margin, achieving +4.2% mIoU on Trans10K-v2, +5.6% mIoU on MSD, +10.1% mIoU on RGBD-Mirror, +13.1% mIoU on TROSD, and +8.3% mIoU on Stanford2D3D, showing the effectiveness of our method against glass objects.

</details>


### [100] [UARE: A Unified Vision-Language Model for Image Quality Assessment, Restoration, and Enhancement](https://arxiv.org/abs/2512.06750)
*Weiqi Li,Xuanyu Zhang,Bin Chen,Jingfen Xie,Yan Wang,Kexin Zhang,Junlin Li,Li Zhang,Jian Zhang,Shijie Zhao*

Main category: cs.CV

TL;DR: UARE是首个统一图像质量评估、修复与增强的视觉-语言模型，通过两阶段训练和IQA信号对齐，显著提升多任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究通常将IQA与修复任务分离，而统一的多模态理解-生成模型显示更强的理解能力可提升生成性能，因此探索IQA如何指导修复具有重要价值。

Method: 基于预训练的统一理解和生成模型，采用两阶段训练框架：1. 从单一失真类型逐步扩展到高阶混合退化；2. 通过交替文本-图像数据统一微调质量理解与修复任务。

Result: 在IQA、修复和增强任务上的广泛实验验证了UARE的有效性。

Conclusion: UARE模型通过统一图像质量评估（IQA）与修复任务，展示了多任务协同训练的有效性，显著提升了修复和增强性能。

Abstract: Image quality assessment (IQA) and image restoration are fundamental problems in low-level vision. Although IQA and restoration are closely connected conceptually, most existing work treats them in isolation. Recent advances in unified multimodal understanding-generation models demonstrate promising results and indicate that stronger understanding can improve generative performance. This motivates a single model that unifies IQA and restoration and explicitly studies how IQA can guide restoration, a setting that remains largely underexplored yet highly valuable. In this paper, we propose UARE, to our knowledge the first Unified vision-language model for image quality Assessment, Restoration, and Enhancement. Built on pretrained unified understanding and generation models, we introduce a two-stage training framework. First, a progressive, easy-to-hard schedule expands from single-type distortions to higher-order mixed degradations, enabling UARE to handle multiple degradations. Second, we perform unified fine-tuning of quality understanding and restoration with interleaved text-image data, aligning IQA signals with restoration objectives. Through multi-task co-training, UARE leverages IQA to boost restoration and enhancement performance. Extensive experiments across IQA, restoration, and enhancement tasks demonstrate the effectiveness of UARE. The code and models will be available at https://github.com/lwq20020127/UARE.

</details>


### [101] [DAUNet: A Lightweight UNet Variant with Deformable Convolutions and Parameter-Free Attention for Medical Image Segmentation](https://arxiv.org/abs/2512.07051)
*Adnan Munir,Shujaat Khan*

Main category: cs.CV

TL;DR: DAUNet是一种轻量级UNet变体，结合可变形卷积和SimAM注意力，在医疗图像分割任务中表现优异且高效。


<details>
  <summary>Details</summary>
Motivation: 医疗图像分割在自动化诊断和治疗规划中至关重要，需提升模型性能同时保持轻量化。

Method: 提出DAUNet，一种轻量级UNet变体，集成Deformable V2 Convolutions和SimAM注意力机制，增强空间适应性和上下文感知特征融合。

Result: 在FH-PS-AoP和FUMPE数据集上，DAUNet在Dice score、HD95和ASD指标上优于现有模型，且参数效率更高。

Conclusion: DAUNet通过结合可变形卷积和SimAM注意力机制，在保持模型轻量化的同时提升了分割性能，适用于实时和资源受限的临床环境。

Abstract: Medical image segmentation plays a pivotal role in automated diagnostic and treatment planning systems. In this work, we present DAUNet, a novel lightweight UNet variant that integrates Deformable V2 Convolutions and Parameter-Free Attention (SimAM) to improve spatial adaptability and context-aware feature fusion without increasing model complexity. DAUNet's bottleneck employs dynamic deformable kernels to handle geometric variations, while the decoder and skip pathways are enhanced using SimAM attention modules for saliency-aware refinement. Extensive evaluations on two challenging datasets, FH-PS-AoP (fetal head and pubic symphysis ultrasound) and FUMPE (CT-based pulmonary embolism detection), demonstrate that DAUNet outperforms state-of-the-art models in Dice score, HD95, and ASD, while maintaining superior parameter efficiency. Ablation studies highlight the individual contributions of deformable convolutions and SimAM attention. DAUNet's robustness to missing context and low-contrast regions establishes its suitability for deployment in real-time and resource-constrained clinical environments.

</details>


### [102] [$\mathrm{D}^{\mathrm{3}}$-Predictor: Noise-Free Deterministic Diffusion for Dense Prediction](https://arxiv.org/abs/2512.07062)
*Changliang Xia,Chengyou Jia,Minnan Luo,Zhuohang Dang,Xin Shen,Bowen Ping*

Main category: cs.CV

TL;DR: D3-Predictor通过消除扩散模型的随机噪声，构建确定性框架，显著提升密集预测任务的性能与效率。


<details>
  <summary>Details</summary>
Motivation: 扩散模型中的随机噪声破坏了细粒度空间线索和几何结构映射，导致密集预测任务性能下降。

Method: 提出了D3-Predictor框架，将预训练的扩散模型重新表述为无随机噪声的确定性模型，并自监督地聚合时间步依赖的视觉专家先验。

Result: 在多种密集预测任务中取得竞争性或最先进的性能，训练数据需求减少50%以上，推理效率显著提升。

Conclusion: D3-Predictor通过消除扩散模型中的随机噪声，成功构建了一个确定性框架，在多种密集预测任务中表现出色，且训练数据需求减半，推理效率高。

Abstract: Although diffusion models with strong visual priors have emerged as powerful dense prediction backboens, they overlook a core limitation: the stochastic noise at the core of diffusion sampling is inherently misaligned with dense prediction that requires a deterministic mapping from image to geometry. In this paper, we show that this stochastic noise corrupts fine-grained spatial cues and pushes the model toward timestep-specific noise objectives, consequently destroying meaningful geometric structure mappings. To address this, we introduce $\mathrm{D}^{\mathrm{3}}$-Predictor, a noise-free deterministic framework built by reformulating a pretrained diffusion model without stochasticity noise. Instead of relying on noisy inputs to leverage diffusion priors, $\mathrm{D}^{\mathrm{3}}$-Predictor views the pretrained diffusion network as an ensemble of timestep-dependent visual experts and self-supervisedly aggregates their heterogeneous priors into a single, clean, and complete geometric prior. Meanwhile, we utilize task-specific supervision to seamlessly adapt this noise-free prior to dense prediction tasks. Extensive experiments on various dense prediction tasks demonstrate that $\mathrm{D}^{\mathrm{3}}$-Predictor achieves competitive or state-of-the-art performance in diverse scenarios. In addition, it requires less than half the training data previously used and efficiently performs inference in a single step. Our code, data, and checkpoints are publicly available at https://x-gengroup.github.io/HomePage_D3-Predictor/.

</details>


### [103] [JOCA: Task-Driven Joint Optimisation of Camera Hardware and Adaptive Camera Control Algorithms](https://arxiv.org/abs/2512.06763)
*Chengyang Yan,Mitch Bryson,Donald G. Dansereau*

Main category: cs.CV

TL;DR: 本文提出了一种联合优化相机硬件和自适应控制算法的方法，通过混合优化策略提升感知任务性能，尤其在低光和快速运动条件下表现优异。


<details>
  <summary>Details</summary>
Motivation: 捕获图像的质量对下游感知任务性能有重要影响，现有方法大多优化制造时固定的相机参数，而许多参数（如曝光设置）需要在运行时自适应控制。

Method: 提出了一个统一的优化框架，结合基于梯度和无导数的方法，支持连续和离散参数、不可微分的图像形成过程以及基于神经网络的自适应控制算法。针对运动模糊等不可微分效应，提出了DF-Grad混合优化策略。

Result: 实验表明，该方法在低光和快速运动等挑战性条件下优于单独优化静态和动态参数的基线方法。

Conclusion: 联合优化相机硬件参数和自适应控制算法能显著提升感知性能，并为任务驱动的相机系统设计提供了统一方法。

Abstract: The quality of captured images strongly influences the performance of downstream perception tasks. Recent works on co-designing camera systems with perception tasks have shown improved task performance. However, most prior approaches focus on optimising fixed camera parameters set at manufacturing, while many parameters, such as exposure settings, require adaptive control at runtime. This paper introduces a method that jointly optimises camera hardware and adaptive camera control algorithms with downstream vision tasks. We present a unified optimisation framework that integrates gradient-based and derivative-free methods, enabling support for both continuous and discrete parameters, non-differentiable image formation processes, and neural network-based adaptive control algorithms. To address non-differentiable effects such as motion blur, we propose DF-Grad, a hybrid optimisation strategy that trains adaptive control networks using signals from a derivative-free optimiser alongside unsupervised task-driven learning. Experiments show that our method outperforms baselines that optimise static and dynamic parameters separately, particularly under challenging conditions such as low light and fast motion. These results demonstrate that jointly optimising hardware parameters and adaptive control algorithms improves perception performance and provides a unified approach to task-driven camera system design.

</details>


### [104] [TrajMoE: Scene-Adaptive Trajectory Planning with Mixture of Experts and Reinforcement Learning](https://arxiv.org/abs/2512.07135)
*Zebin Xing,Pengxuan Yang,Linbo Wang,Yichen Zhang,Yiming Hu,Yupeng Zheng,Junli Wang,Yinfeng Gao,Guang Li,Kun Ma,Long Chen,Zhongpu Xia,Qichao Zhang,Hangjun Ye,Dongbin Zhao*

Main category: cs.CV

TL;DR: 本文通过MoE和强化学习优化自动驾驶轨迹规划，集成多感知模型，在基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前端到端自动驾驶系统在轨迹规划中存在两个关键问题：1) 不同驾驶场景下适用的轨迹先验差异显著；2) 轨迹评分机制缺乏策略驱动的优化。

Method: 针对不同驾驶场景采用MoE（混合专家）模型定制轨迹先验，并利用强化学习对轨迹评分机制进行微调。同时，集成多种感知主干模型以增强感知特征。

Result: 集成模型在navsim ICCV基准测试中得分51.08，排名第三。

Conclusion: 通过采用MoE和强化学习优化轨迹评分机制，结合不同感知主干模型，本文提出的集成模型在navsim ICCV基准测试中取得了51.08分，排名第三。

Abstract: Current autonomous driving systems often favor end-to-end frameworks, which take sensor inputs like images and learn to map them into trajectory space via neural networks. Previous work has demonstrated that models can achieve better planning performance when provided with a prior distribution of possible trajectories. However, these approaches often overlook two critical aspects: 1) The appropriate trajectory prior can vary significantly across different driving scenarios. 2) Their trajectory evaluation mechanism lacks policy-driven refinement, remaining constrained by the limitations of one-stage supervised training. To address these issues, we explore improvements in two key areas. For problem 1, we employ MoE to apply different trajectory priors tailored to different scenarios. For problem 2, we utilize Reinforcement Learning to fine-tune the trajectory scoring mechanism. Additionally, we integrate models with different perception backbones to enhance perceptual features. Our integrated model achieved a score of 51.08 on the navsim ICCV benchmark, securing third place.

</details>


### [105] [A Large-Scale Multimodal Dataset and Benchmarks for Human Activity Scene Understanding and Reasoning](https://arxiv.org/abs/2512.07136)
*Siyang Jiang,Mu Yuan,Xiang Ji,Bufang Yang,Zeyu Liu,Lilin Xu,Yang Li,Yuting He,Liran Dong,Wenrui Lu,Zhenyu Yan,Xiaofan Jiang,Wei Gao,Hongkai Chen,Guoliang Xing*

Main category: cs.CV

TL;DR: 该论文介绍了CUHK-X，一个用于多模态人类动作识别、理解和推理的大规模数据集，通过LLMs生成逻辑连贯的描述并人工验证，实验表明其在多项任务中表现良好。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）尤其是视觉语言模型（LVLMs）在非RGB模态（如深度、IMU、mmWave）上的表现不佳，缺乏大规模数据-描述资源，现有HAR数据集提供的粗粒度标注不足以支持细粒度动作动态的捕捉。

Method: 作者提出了基于提示的场景创建方法，利用LLMs生成逻辑上连贯的活动序列，并通过人工验证提高描述的一致性。

Result: 实验结果显示，CUHK-X在HAR、HAU和HARn任务上的平均准确率分别为76.52%、40.76%和70.25%。

Conclusion: CUHK-X数据集旨在为社区提供一个大规模多模态数据集，以支持数据密集型学习方法在鲁棒的多模态人类活动分析中的应用和发展。

Abstract: Multimodal human action recognition (HAR) leverages complementary sensors for activity classification. Beyond recognition, recent advances in large language models (LLMs) enable detailed descriptions and causal reasoning, motivating new tasks: human action understanding (HAU) and human action reasoning (HARn). However, most LLMs, especially large vision language models (LVLMs), struggle with non-RGB modalities such as depth, IMU, and mmWave due to the lack of large-scale data-caption resources. Existing HAR datasets mainly provide coarse data-label annotations, which are insufficient to capture fine-grained action dynamics needed for HAU and HARn. We consider two ground-truth pair types: (1) data label (discrete category) and (2) data caption (textual description). Naively generating captions from labels often lacks logical and spatiotemporal consistency. We introduce CUHK-X, a large-scale multimodal dataset and benchmark suite for HAR, HAU, and HARn. CUHK-X contains 58,445 samples covering 40 actions performed by 30 participants across two indoor environments. To improve caption consistency, we propose a prompt-based scene creation method that leverages LLMs to generate logically connected activity sequences, followed by human validation. CUHK-X includes three benchmarks with six evaluation tasks. Experiments report average accuracies of 76.52% (HAR), 40.76% (HAU), and 70.25% (HARn). CUHK-X aims to enable the community to apply and develop data-intensive learning methods for robust, multimodal human activity analysis. Project page and code: https://openaiotlab.github.io/CUHK-X/ and https://github.com/openaiotlab/CUHK-X.

</details>


### [106] [Physics Informed Human Posture Estimation Based on 3D Landmarks from Monocular RGB-Videos](https://arxiv.org/abs/2512.06783)
*Tobias Leuthold,Michele Xiloyannis,Yves Zimmermann*

Main category: cs.CV

TL;DR: 提出了一种融合BlazePose 3D和2D估计的实时后处理算法，通过加权优化和卡尔曼滤波器提升姿态估计的解剖学一致性，显著降低了3D MPJPE和角度误差。


<details>
  <summary>Details</summary>
Motivation: 尽管BlazePose等先进模型在实时姿态跟踪中表现出色，但其缺乏解剖学约束，表明通过融入物理知识有改进潜力。

Method: 提出了一种实时后处理算法，通过加权优化融合BlazePose 3D和2D估计的优势，惩罚与预期骨骼长度和生物力学模型的偏差。骨骼长度估计通过带有自适应测量信任的卡尔曼滤波器细化到个体解剖结构。

Result: 在Physio2.2M数据集上的评估显示，与BlazePose 3D估计相比，3D MPJPE减少了10.2%，身体段间角度误差减少了16.6%。

Conclusion: 该方法提供了一种基于计算高效的视频到3D姿态估计的稳健、解剖学一致的姿态估计，适用于自动物理治疗、医疗保健和体育教练，可在消费级笔记本电脑和移动设备上运行。

Abstract: Applications providing automated coaching for physical training are increasing in popularity, for example physical therapy. These applications rely on accurate and robust pose estimation using monocular video streams. State-of-the-art models like BlazePose excel in real-time pose tracking, but their lack of anatomical constraints indicates improvement potential by including physical knowledge. We present a real-time post-processing algorithm fusing the strengths of BlazePose 3D and 2D estimations using a weighted optimization, penalizing deviations from expected bone length and biomechanical models. Bone length estimations are refined to the individual anatomy using a Kalman filter with adapting measurement trust. Evaluation using the Physio2.2M dataset shows a 10.2 percent reduction in 3D MPJPE and a 16.6 percent decrease in errors of angles between body segments compared to BlazePose 3D estimation. Our method provides a robust, anatomically consistent pose estimation based on a computationally efficient video-to-3D pose estimation, suitable for automated physiotherapy, healthcare, and sports coaching on consumer-level laptops and mobile devices. The refinement runs on the backend with anonymized data only.

</details>


### [107] [Towards Unified Semantic and Controllable Image Fusion: A Diffusion Transformer Approach](https://arxiv.org/abs/2512.07170)
*Jiayang Li,Chengjie Jiang,Junjun Jiang,Pengwei Liang,Jiayi Ma,Liqiang Nie*

Main category: cs.CV

TL;DR: DiTFuse是一个基于扩散-Transformer的指令驱动框架，通过自然语言指令实现端到端、语义感知的图像融合，并在多个任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有图像融合方法在鲁棒性、适应性和可控性方面存在局限，且缺乏用户意图的灵活整合能力。

Method: 采用多退化掩码图像建模策略，联合学习跨模态对齐、模态不变恢复和任务感知特征选择。

Result: 在公共IVIF、MFF和MEF基准测试中，DiTFuse展现出更优的定量和定性性能，支持多级用户控制和零样本泛化。

Conclusion: DiTFuse框架通过联合编码图像和自然语言指令，实现了端到端、语义感知的图像融合，并在多个基准测试中表现出卓越的性能和泛化能力。

Abstract: Image fusion aims to blend complementary information from multiple sensing modalities, yet existing approaches remain limited in robustness, adaptability, and controllability. Most current fusion networks are tailored to specific tasks and lack the ability to flexibly incorporate user intent, especially in complex scenarios involving low-light degradation, color shifts, or exposure imbalance. Moreover, the absence of ground-truth fused images and the small scale of existing datasets make it difficult to train an end-to-end model that simultaneously understands high-level semantics and performs fine-grained multimodal alignment. We therefore present DiTFuse, instruction-driven Diffusion-Transformer (DiT) framework that performs end-to-end, semantics-aware fusion within a single model. By jointly encoding two images and natural-language instructions in a shared latent space, DiTFuse enables hierarchical and fine-grained control over fusion dynamics, overcoming the limitations of pre-fusion and post-fusion pipelines that struggle to inject high-level semantics. The training phase employs a multi-degradation masked-image modeling strategy, so the network jointly learns cross-modal alignment, modality-invariant restoration, and task-aware feature selection without relying on ground truth images. A curated, multi-granularity instruction dataset further equips the model with interactive fusion capabilities. DiTFuse unifies infrared-visible, multi-focus, and multi-exposure fusion-as well as text-controlled refinement and downstream tasks-within a single architecture. Experiments on public IVIF, MFF, and MEF benchmarks confirm superior quantitative and qualitative performance, sharper textures, and better semantic retention. The model also supports multi-level user control and zero-shot generalization to other multi-image fusion scenarios, including instruction-conditioned segmentation.

</details>


### [108] [Generalized Geometry Encoding Volume for Real-time Stereo Matching](https://arxiv.org/abs/2512.06793)
*Jiaxin Liu,Gangwei Xu,Xianqi Wang,Chengliang Zhang,Xin Yang*

Main category: cs.CV

TL;DR: GGEV是一种新型实时立体匹配网络，通过深度感知特征和动态成本聚合模块，显著提升泛化能力，并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有实时立体匹配方法过于关注域内性能而忽视泛化能力，而基于单目基础模型的方法虽提升泛化但推理延迟高。

Method: 首先提取编码域不变结构先验的深度感知特征，随后引入深度感知动态成本聚合（DDCA）模块，自适应地将这些先验融入每个视差假设中。

Result: GGEV在零样本泛化能力上超越所有现有实时方法，并在KITTI 2012、KITTI 2015和ETH3D基准测试中达到最先进性能。

Conclusion: GGEV提出了一种新型实时立体匹配网络，通过深度感知特征和动态成本聚合模块，显著提升了在未见场景中的泛化能力，并在多个基准测试中达到最先进性能。

Abstract: Real-time stereo matching methods primarily focus on enhancing in-domain performance but often overlook the critical importance of generalization in real-world applications. In contrast, recent stereo foundation models leverage monocular foundation models (MFMs) to improve generalization, but typically suffer from substantial inference latency. To address this trade-off, we propose Generalized Geometry Encoding Volume (GGEV), a novel real-time stereo matching network that achieves strong generalization. We first extract depth-aware features that encode domain-invariant structural priors as guidance for cost aggregation. Subsequently, we introduce a Depth-aware Dynamic Cost Aggregation (DDCA) module that adaptively incorporates these priors into each disparity hypothesis, effectively enhancing fragile matching relationships in unseen scenes. Both steps are lightweight and complementary, leading to the construction of a generalized geometry encoding volume with strong generalization capability. Experimental results demonstrate that our GGEV surpasses all existing real-time methods in zero-shot generalization capability, and achieves state-of-the-art performance on the KITTI 2012, KITTI 2015, and ETH3D benchmarks.

</details>


### [109] [START: Spatial and Textual Learning for Chart Understanding](https://arxiv.org/abs/2512.07186)
*Zhuoming Liu,Xiaofeng Gao,Feiyang Niu,Qiaozi Gao,Liu Liu,Robinson Piramuthu*

Main category: cs.CV

TL;DR: START通过空间和文本学习提升图表理解，提出新数据集和基准测试，性能显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 图表在科学论文和技术报告等实际场景中至关重要，理解其结构化视觉布局和底层数据表示是实现精确推理的关键。

Method: 提出了START方法，包括图表元素定位和图表到代码生成，以增强MLLMs对图表视觉布局和数据细节的理解。

Result: START在模型大小和基准测试中均优于基础模型和现有最佳方法。

Conclusion: START通过结合空间和文本学习，显著提升了多模态大语言模型（MLLMs）在图表理解任务上的性能，超越了现有最佳方法。

Abstract: Chart understanding is crucial for deploying multimodal large language models (MLLMs) in real-world scenarios such as analyzing scientific papers and technical reports. Unlike natural images, charts pair a structured visual layout (spatial property) with an underlying data representation (textual property) -- grasping both is essential for precise, fine-grained chart reasoning. Motivated by this observation, we propose START, the Spatial and Textual learning for chART understanding. Specifically, we introduce (i) chart-element grounding and (ii) chart-to-code generation to strengthen an MLLM's understanding of both chart visual layout and data details. To facilitate spatial and textual learning, we propose the START-Dataset generated with a novel data-generation pipeline that first leverages an MLLM to translate real chart images into executable chart code, recovering the underlying data representation while preserving the visual distribution of real-world charts. We then evolve the code with a Large Language Model (LLM) to ascertain the positions of chart elements that capture the chart's visual structure, addressing challenges that existing methods cannot handle. To evaluate a model's ability to understand chart spatial structures, we propose the Chart Spatial understanding Benchmark (CS-Bench), filling a critical gap in comprehensive chart understanding evaluation. Leveraging spatial and textual learning, START delivers consistent gains across model sizes and benchmarks over the base models and surpasses prior state-of-the-art by a clear margin. Code, data and models will be publicly available.

</details>


### [110] [VDOT: Efficient Unified Video Creation via Optimal Transport Distillation](https://arxiv.org/abs/2512.06802)
*Yutong Wang,Haiyu Zhang,Tianfan Xue,Yu Qiao,Yaohui Wang,Chang Xu,Xinyuan Chen*

Main category: cs.CV

TL;DR: VDOT是一种高效统一的视频生成模型，通过计算最优传输技术和判别器提升生成效率与质量，在多任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型要么局限于特定条件，要么因推理复杂导致生成时间过长，难以实际应用。

Method: 采用分布匹配蒸馏（DMD）范式，结合计算最优传输（OT）技术和判别器，优化真实与生成视频的分布差异。

Result: 实验表明，4步VDOT模型性能优于或匹配100步去噪的基线模型。

Conclusion: VDOT模型通过引入计算最优传输技术和判别器，显著提升了视频生成的效率和质量，并在多任务视频生成中表现出色。

Abstract: The rapid development of generative models has significantly advanced image and video applications. Among these, video creation, aimed at generating videos under various conditions, has gained substantial attention. However, existing video creation models either focus solely on a few specific conditions or suffer from excessively long generation times due to complex model inference, making them impractical for real-world applications. To mitigate these issues, we propose an efficient unified video creation model, named VDOT. Concretely, we model the training process with the distribution matching distillation (DMD) paradigm. Instead of using the Kullback-Leibler (KL) minimization, we additionally employ a novel computational optimal transport (OT) technique to optimize the discrepancy between the real and fake score distributions. The OT distance inherently imposes geometric constraints, mitigating potential zero-forcing or gradient collapse issues that may arise during KL-based distillation within the few-step generation scenario, and thus, enhances the efficiency and stability of the distillation process. Further, we integrate a discriminator to enable the model to perceive real video data, thereby enhancing the quality of generated videos. To support training unified video creation models, we propose a fully automated pipeline for video data annotation and filtering that accommodates multiple video creation tasks. Meanwhile, we curate a unified testing benchmark, UVCBench, to standardize evaluation. Experiments demonstrate that our 4-step VDOT outperforms or matches other baselines with 100 denoising steps.

</details>


### [111] [VFM-VLM: Vision Foundation Model and Vision Language Model based Visual Comparison for 3D Pose Estimation](https://arxiv.org/abs/2512.07215)
*Md Selim Sarowar,Sungho Kim*

Main category: cs.CV

TL;DR: 论文比较了CLIP和DINOv2在6D物体姿态估计中的表现，发现CLIP擅长语义理解，DINOv2在几何特征上更优，为机器人应用提供了模型选择指导。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于全面比较CLIP和DINOv2在3D姿态估计中的表现，特别是在手物体抓取场景中，以探索它们在语义和几何表示上的互补性。

Method: 论文通过基准数据集上的广泛实验，比较了基于CLIP和DINOv2的6D物体姿态估计方法。

Result: 实验结果表明，基于CLIP的方法在语义一致性上表现更好，而基于DINOv2的方法在几何精度上更具竞争力。

Conclusion: 该论文为机器人操作和抓取应用提供了选择合适视觉模型的见解，强调了CLIP和DINOv2在语义理解和几何特征上的互补优势。

Abstract: Vision Foundation Models (VFMs) and Vision Language Models (VLMs) have revolutionized computer vision by providing rich semantic and geometric representations. This paper presents a comprehensive visual comparison between CLIP based and DINOv2 based approaches for 3D pose estimation in hand object grasping scenarios. We evaluate both models on the task of 6D object pose estimation and demonstrate their complementary strengths: CLIP excels in semantic understanding through language grounding, while DINOv2 provides superior dense geometric features. Through extensive experiments on benchmark datasets, we show that CLIP based methods achieve better semantic consistency, while DINOv2 based approaches demonstrate competitive performance with enhanced geometric precision. Our analysis provides insights for selecting appropriate vision models for robotic manipulation and grasping, picking applications.

</details>


### [112] [MMDuet2: Enhancing Proactive Interaction of Video MLLMs with Multi-Turn Reinforcement Learning](https://arxiv.org/abs/2512.06810)
*Yueqian Wang,Songxiang Liu,Disong Wang,Nuo Xu,Guanglu Wan,Huishuai Zhang,Dongyan Zhao*

Main category: cs.CV

TL;DR: 提出了一种文本到文本的主动交互方法，通过多轮RL训练，模型能自主决定何时响应或保持沉默，无需精确时间标注，在ProactiveVideoQA基准上表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有系统多为回合制，模型只能在用户回合后回复，而实时应用中主动决定何时回复视频播放是一个有前景但具挑战性的方向。

Method: 提出了一种基于多轮RL的训练方法，无需精确的响应时间标注，鼓励模型及时准确地响应。

Result: MMDuet2在52k视频数据集上通过SFT和RL训练，在响应时机和质量上表现优异。

Conclusion: MMDuet2在响应时机和质量上优于现有的主动视频MLLM基线，在ProactiveVideoQA基准测试中实现了最先进的性能。

Abstract: Recent advances in video multimodal large language models (Video MLLMs) have significantly enhanced video understanding and multi-modal interaction capabilities. While most existing systems operate in a turn-based manner where the model can only reply after user turns, proactively deciding when to reply during video playback presents a promising yet challenging direction for real-time applications. In this work, we propose a novel text-to-text approach to proactive interaction, where the model autonomously determines whether to respond or remain silent at each turn based on dialogue history and visual context up to current frame of an streaming video. To overcome difficulties in previous methods such as manually tuning response decision thresholds and annotating precise reply times, we introduce a multi-turn RL based training method that encourages timely and accurate responses without requiring precise response time annotations. We train our model MMDuet2 on a dataset of 52k videos with two types of dialogues via SFT and RL. Experimental results demonstrate that MMDuet2 outperforms existing proactive Video MLLM baselines in response timing and quality, achieving state-of-the-art performance on the ProactiveVideoQA benchmark.

</details>


### [113] [Towards Robust Protective Perturbation against DeepFake Face Swapping](https://arxiv.org/abs/2512.07228)
*Hengyang Yao,Lin Li,Ke Sun,Jianing Qiu,Huiping Chen*

Main category: cs.CV

TL;DR: EOLT框架通过强化学习优化变换分布，显著提升DeepFake防御的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: DeepFake换脸技术带来严重的隐私和安全风险，现有防御方法（如嵌入不可见扰动）对基本变换（如压缩或调整大小）脆弱。

Method: 提出EOLT框架，将变换分布视为可学习组件，通过策略网络自动优先处理关键变换并自适应生成实例特定的扰动。

Result: EOLT在广泛实验中表现优异，平均鲁棒性提高26%，在挑战性变换类别上最高提升30%。

Conclusion: EOLT框架通过强化学习自动优先处理关键变换并生成实例特定的扰动，显著提升了防御鲁棒性，比现有方法平均提高了26%，在挑战性变换类别上最高提升了30%。

Abstract: DeepFake face swapping enables highly realistic identity forgeries, posing serious privacy and security risks. A common defence embeds invisible perturbations into images, but these are fragile and often destroyed by basic transformations such as compression or resizing. In this paper, we first conduct a systematic analysis of 30 transformations across six categories and show that protection robustness is highly sensitive to the choice of training transformations, making the standard Expectation over Transformation (EOT) with uniform sampling fundamentally suboptimal. Motivated by this, we propose Expectation Over Learned distribution of Transformation (EOLT), the framework to treat transformation distribution as a learnable component rather than a fixed design choice. Specifically, EOLT employs a policy network that learns to automatically prioritize critical transformations and adaptively generate instance-specific perturbations via reinforcement learning, enabling explicit modeling of defensive bottlenecks while maintaining broad transferability. Extensive experiments demonstrate that our method achieves substantial improvements over state-of-the-art approaches, with 26% higher average robustness and up to 30% gains on challenging transformation categories.

</details>


### [114] [Dropout Prompt Learning: Towards Robust and Adaptive Vision-Language Models](https://arxiv.org/abs/2512.07234)
*Biao Chen,Lin Zuo,Mengmeng Jing,Kunbin He,Yuchen Wang*

Main category: cs.CV

TL;DR: Dropout Prompt Learning通过灵活丢弃token和残差熵正则化，提升了视觉语言模型在挑战性场景中的性能。


<details>
  <summary>Details</summary>
Motivation: 为了提高视觉语言模型的鲁棒性，特别是在低样本学习、长尾分类和分布外泛化等挑战性场景中，提出了Dropout Prompt Learning方法。

Method: 提出了一种新型的Dropout Prompt Learning方法，通过对文本和视觉分支的token进行灵活丢弃，并考虑模态内上下文和模态间对齐来评估token重要性。此外，引入了残差熵正则化以保持语义对齐并鼓励多样性表示。

Result: 在15个基准测试中，该方法在低样本学习、长尾分类和分布外泛化等任务中表现出色，尤其在基础到新类泛化任务中，性能超过KgCoOp 5.10%和PromptSRC 2.13%。

Conclusion: Dropout Prompt Learning 通过结合残差熵正则化和灵活的token丢弃策略，显著提升了视觉语言模型在低样本学习、长尾分类和分布外泛化等挑战性场景中的性能。

Abstract: Dropout is a widely used regularization technique which improves the generalization ability of a model by randomly dropping neurons. In light of this, we propose Dropout Prompt Learning, which aims for applying dropout to improve the robustness of the vision-language models. Different from the vanilla dropout, we apply dropout on the tokens of the textual and visual branches, where we evaluate the token significance considering both intra-modal context and inter-modal alignment, enabling flexible dropout probabilities for each token. Moreover, to maintain semantic alignment for general knowledge transfer while encouraging the diverse representations that dropout introduces, we further propose residual entropy regularization. Experiments on 15 benchmarks show our method's effectiveness in challenging scenarios like low-shot learning, long-tail classification, and out-of-distribution generalization. Notably, our method surpasses regularization-based methods including KgCoOp by 5.10% and PromptSRC by 2.13% in performance on base-to-novel generalization.

</details>


### [115] [MeshSplatting: Differentiable Rendering with Opaque Meshes](https://arxiv.org/abs/2512.06818)
*Jan Held,Sanghyun Son,Renaud Vandeghen,Daniel Rebain,Matheus Gadelha,Yi Zhou,Anthony Cioppa,Ming C. Lin,Marc Van Droogenbroeck,Andrea Tagliasacchi*

Main category: cs.CV

TL;DR: MeshSplatting是一种基于网格的重建方法，通过可微分渲染联合优化几何和外观，实现实时渲染的高质量网格，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的基于基元的喷溅方法（如3D高斯喷溅）虽在实时渲染中革新了新视角合成，但其基于点的表示与AR/VR和游戏引擎中基于网格的流程不兼容。

Method: MeshSplatting通过受限Delaunay三角剖分强制连接性，并通过细化表面一致性，联合优化几何和外观，利用可微分渲染创建端到端平滑、视觉高质量的网格。

Result: MeshSplatting在Mip-NeRF360数据集上比MiLo方法提升了0.69 dB的PSNR，训练速度快2倍且内存使用减少一半。

Conclusion: MeshSplatting成功地将神经渲染与交互式3D图形无缝结合，实现了实时场景交互，同时在Mip-NeRF360数据集上比当前最先进的MiLo方法提升了0.69 dB的PSNR，训练速度快2倍且内存使用减少一半。

Abstract: Primitive-based splatting methods like 3D Gaussian Splatting have revolutionized novel view synthesis with real-time rendering. However, their point-based representations remain incompatible with mesh-based pipelines that power AR/VR and game engines. We present MeshSplatting, a mesh-based reconstruction approach that jointly optimizes geometry and appearance through differentiable rendering. By enforcing connectivity via restricted Delaunay triangulation and refining surface consistency, MeshSplatting creates end-to-end smooth, visually high-quality meshes that render efficiently in real-time 3D engines. On Mip-NeRF360, it boosts PSNR by +0.69 dB over the current state-of-the-art MiLo for mesh-based novel view synthesis, while training 2x faster and using 2x less memory, bridging neural rendering and interactive 3D graphics for seamless real-time scene interaction. The project page is available at https://meshsplatting.github.io/.

</details>


### [116] [DGGAN: Degradation Guided Generative Adversarial Network for Real-time Endoscopic Video Enhancement](https://arxiv.org/abs/2512.07253)
*Handing Xu,Zhenguo Nie,Tairan Peng,Huimin Pan,Xin-Jun Liu*

Main category: cs.CV

TL;DR: 提出一种降解感知框架，通过跨帧传播降解表示实现实时内窥镜视频增强，实验显示其在性能与效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 内窥镜视频常因光照不均、组织散射、遮挡和运动模糊而质量下降，影响手术安全和效果。现有深度学习方法计算量大，难以实时应用。

Method: 首先通过对比学习从图像中提取降解表示，然后引入融合机制，用这些表示调制图像特征以指导单帧增强模型。模型通过降解与恢复图像之间的循环一致性约束进行训练，以提高鲁棒性和泛化能力。

Result: 实验表明，该框架在性能与效率之间取得了优于多种先进方法的平衡。

Conclusion: 本文提出的降解感知框架通过跨帧传播降解表示，实现了实时、高质量的内窥镜视频增强，为临床应用提供了实用途径。

Abstract: Endoscopic surgery relies on intraoperative video, making image quality a decisive factor for surgical safety and efficacy. Yet, endoscopic videos are often degraded by uneven illumination, tissue scattering, occlusions, and motion blur, which obscure critical anatomical details and complicate surgical manipulation. Although deep learning-based methods have shown promise in image enhancement, most existing approaches remain too computationally demanding for real-time surgical use. To address this challenge, we propose a degradation-aware framework for endoscopic video enhancement, which enables real-time, high-quality enhancement by propagating degradation representations across frames. In our framework, degradation representations are first extracted from images using contrastive learning. We then introduce a fusion mechanism that modulates image features with these representations to guide a single-frame enhancement model, which is trained with a cycle-consistency constraint between degraded and restored images to improve robustness and generalization. Experiments demonstrate that our framework achieves a superior balance between performance and efficiency compared with several state-of-the-art methods. These results highlight the effectiveness of degradation-aware modeling for real-time endoscopic video enhancement. Nevertheless, our method suggests that implicitly learning and propagating degradation representation offer a practical pathway for clinical application.

</details>


### [117] [SparseCoop: Cooperative Perception with Kinematic-Grounded Queries](https://arxiv.org/abs/2512.06838)
*Jiahao Wang,Zhongwei Jiang,Wenchao Sun,Jiaru Zhong,Haibao Yu,Yuner Zhang,Chenyang Lu,Chuang Zhang,Lei He,Shaobing Xu,Jianqiang Wang*

Main category: cs.CV

TL;DR: SparseCoop 是一种完全稀疏的协作感知框架，通过创新的实例查询、聚合模块和去噪任务，解决了现有方法的通信成本和灵活性问题，实现了高效且鲁棒的 3D 检测与跟踪。


<details>
  <summary>Details</summary>
Motivation: 当前共享密集 BEV 特征的方法存在通信成本高、灵活性不足和对异步或不同视角对齐困难的问题，稀疏查询方法则存在几何表示不足、融合策略不佳和训练不稳定的缺陷。

Method: SparseCoop 是一个完全稀疏的协作感知框架，摒弃了中间 BEV 表示，采用基于运动学的实例查询、粗到细的聚合模块和协作实例去噪任务。

Result: SparseCoop 在 3D 检测和跟踪任务中表现出色，具有高效计算、低传输成本和强鲁棒性。

Conclusion: SparseCoop 框架在 V2X-Seq 和 Griffin 数据集上实现了最先进的性能，具有高效的计算能力、低传输成本和强大的通信延迟鲁棒性。

Abstract: Cooperative perception is critical for autonomous driving, overcoming the inherent limitations of a single vehicle, such as occlusions and constrained fields-of-view. However, current approaches sharing dense Bird's-Eye-View (BEV) features are constrained by quadratically-scaling communication costs and the lack of flexibility and interpretability for precise alignment across asynchronous or disparate viewpoints. While emerging sparse query-based methods offer an alternative, they often suffer from inadequate geometric representations, suboptimal fusion strategies, and training instability. In this paper, we propose SparseCoop, a fully sparse cooperative perception framework for 3D detection and tracking that completely discards intermediate BEV representations. Our framework features a trio of innovations: a kinematic-grounded instance query that uses an explicit state vector with 3D geometry and velocity for precise spatio-temporal alignment; a coarse-to-fine aggregation module for robust fusion; and a cooperative instance denoising task to accelerate and stabilize training. Experiments on V2X-Seq and Griffin datasets show SparseCoop achieves state-of-the-art performance. Notably, it delivers this with superior computational efficiency, low transmission cost, and strong robustness to communication latency. Code is available at https://github.com/wang-jh18-SVM/SparseCoop.

</details>


### [118] [CADE: Continual Weakly-supervised Video Anomaly Detection with Ensembles](https://arxiv.org/abs/2512.06840)
*Satoshi Hashimoto,Tatsuya Konishi,Tomoya Kaichi,Kazunori Matsumoto,Mori Kurokawa*

Main category: cs.CV

TL;DR: CADE是首个结合持续学习（CL）和弱监督视频异常检测（WVAD）的方法，通过双生成器和多判别器集成，有效解决了数据域变化和遗忘问题，显著提升了多场景异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有弱监督视频异常检测（WVAD）方法主要针对静态数据集，忽略了数据域可能变化的问题，导致性能下降。

Method: CADE采用双生成器（DG）解决数据不平衡和标签不确定性问题，并通过多判别器（MD）集成来捕捉因遗忘而遗漏的异常。

Result: 在ShanghaiTech和Charlotte Anomaly等数据集上的广泛实验表明，CADE显著优于现有VAD方法。

Conclusion: CADE在公共安全和犯罪预防领域表现出色，特别是在处理多场景视频异常检测时，显著优于现有方法。

Abstract: Video anomaly detection (VAD) has long been studied as a crucial problem in public security and crime prevention. In recent years, weakly-supervised VAD (WVAD) have attracted considerable attention due to their easy annotation process and promising research results. While existing WVAD methods tackle mainly on static datasets, the possibility that the domain of data can vary has been neglected. To adapt such domain-shift, the continual learning (CL) perspective is required because otherwise additional training only with new coming data could easily cause performance degradation for previous data, i.e., forgetting. Therefore, we propose a brand-new approach, called Continual Anomaly Detection with Ensembles (CADE) that is the first work combining CL and WVAD viewpoints. Specifically, CADE uses the Dual-Generator(DG) to address data imbalance and label uncertainty in WVAD. We also found that forgetting exacerbates the "incompleteness'' where the model becomes biased towards certain anomaly modes, leading to missed detections of various anomalies. To address this, we propose to ensemble Multi-Discriminator (MD) that capture missed anomalies in past scenes due to forgetting, using multiple models. Extensive experiments show that CADE significantly outperforms existing VAD methods on the common multi-scene VAD datasets, such as ShanghaiTech and Charlotte Anomaly datasets.

</details>


### [119] [Effective Attention-Guided Multi-Scale Medical Network for Skin Lesion Segmentation](https://arxiv.org/abs/2512.07275)
*Siyu Wang,Hua Wang,Huiyu Li,Fan Zhang*

Main category: cs.CV

TL;DR: 提出一种结合多尺度残差结构和创新模块（MRCF、CMAM、EAB）的网络，显著提升皮肤病变分割性能。


<details>
  <summary>Details</summary>
Motivation: 解决皮肤病变分割中不规则形状和低对比度的挑战，提升分割精度以辅助早期检测和准确诊断。

Method: 采用基于多尺度残差结构的编码器-解码器网络架构，引入MRCF模块捕获跨尺度特征，CMAM模块动态计算多上下文权重，以及EAB模块补偿上采样中的信息损失。

Result: 在多个皮肤病变分割数据集上的实验表明，该模型在分割准确性和鲁棒性上显著优于现有方法。

Conclusion: 该论文提出的创新网络架构，结合多尺度残差结构、MRCF模块、CMAM模块和EAB模块，显著提升了皮肤病变分割的准确性和鲁棒性，超越了现有的基于Transformer和CNN的模型。

Abstract: In the field of healthcare, precise skin lesion segmentation is crucial for the early detection and accurate diagnosis of skin diseases. Despite significant advances in deep learning for image processing, existing methods have yet to effectively address the challenges of irregular lesion shapes and low contrast. To address these issues, this paper proposes an innovative encoder-decoder network architecture based on multi-scale residual structures, capable of extracting rich feature information from different receptive fields to effectively identify lesion areas. By introducing a Multi-Resolution Multi-Channel Fusion (MRCF) module, our method captures cross-scale features, enhancing the clarity and accuracy of the extracted information. Furthermore, we propose a Cross-Mix Attention Module (CMAM), which redefines the attention scope and dynamically calculates weights across multiple contexts, thus improving the flexibility and depth of feature capture and enabling deeper exploration of subtle features. To overcome the information loss caused by skip connections in traditional U-Net, an External Attention Bridge (EAB) is introduced, facilitating the effective utilization of information in the decoder and compensating for the loss during upsampling. Extensive experimental evaluations on several skin lesion segmentation datasets demonstrate that the proposed model significantly outperforms existing transformer and convolutional neural network-based models, showcasing exceptional segmentation accuracy and robustness.

</details>


### [120] [Pseudo Anomalies Are All You Need: Diffusion-Based Generation for Weakly-Supervised Video Anomaly Detection](https://arxiv.org/abs/2512.06845)
*Satoshi Hashimoto,Hitoshi Nishimura,Yanan Wang,Mori Kurokawa*

Main category: cs.CV

TL;DR: PA-VAD通过合成伪异常视频训练异常检测器，无需真实异常数据，在ShanghaiTech和UCF-Crime数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决实际中真实异常视频稀缺且收集成本高的问题，探索在不使用真实异常视频的情况下训练异常检测器。

Method: 采用PA-VAD方法，通过合成伪异常视频与真实正常视频配对训练检测器，利用CLIP选择类别相关初始图像，并通过视觉语言模型优化文本提示以提高保真度和场景一致性，最后调用视频扩散模型进行合成。训练阶段通过领域对齐正则化模块减少合成异常的过度时空幅度。

Result: 在ShanghaiTech数据集上达到98.2%，在UCF-Crime数据集上达到82.5%，分别比最强真实异常方法高出+0.6%和比UVAD先进方法高出+1.9%。

Conclusion: 研究表明，无需收集真实异常视频即可实现高精度异常检测，为可扩展部署提供了实用路径。

Abstract: Deploying video anomaly detection in practice is hampered by the scarcity and collection cost of real abnormal footage. We address this by training without any real abnormal videos while evaluating under the standard weakly supervised split, and we introduce PA-VAD, a generation-driven approach that learns a detector from synthesized pseudo-abnormal videos paired with real normal videos, using only a small set of real normal images to drive synthesis. For synthesis, we select class-relevant initial images with CLIP and refine textual prompts with a vision-language model to improve fidelity and scene consistency before invoking a video diffusion model. For training, we mitigate excessive spatiotemporal magnitude in synthesized anomalies by an domain-aligned regularized module that combines domain alignment and memory usage-aware updates. Extensive experiments show that our approach reaches 98.2% on ShanghaiTech and 82.5% on UCF-Crime, surpassing the strongest real-abnormal method on ShanghaiTech by +0.6% and outperforming the UVAD state-of-the-art on UCF-Crime by +1.9%. The results demonstrate that high-accuracy anomaly detection can be obtained without collecting real anomalies, providing a practical path toward scalable deployment.

</details>


### [121] [Towards Accurate UAV Image Perception: Guiding Vision-Language Models with Stronger Task Prompts](https://arxiv.org/abs/2512.07302)
*Mingning Guo,Mengwei Wu,Shaoxian Li,Haifeng Li,Chao Tao*

Main category: cs.CV

TL;DR: AerialVP是一个用于无人机图像感知的任务提示增强框架，通过提取多维辅助信息克服传统VLM方法的局限性，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于VLMs的图像感知方法在无人机图像应用中面临目标混淆、尺度变化和复杂背景等挑战，主要因为VLMs对图像内容的理解依赖于视觉和文本标记的语义对齐。当任务提示简单而图像内容复杂时，这种对齐难以实现。

Method: AerialVP框架包括三个阶段：(1) 分析任务提示以确定任务类型和增强需求，(2) 从工具库中选择合适的工具，(3) 基于分析和工具生成增强后的任务提示。

Result: 实验结果表明，AerialVP显著增强了任务提示的引导效果，在开源和专有VLMs中均实现了稳定且显著的性能提升。

Conclusion: AerialVP通过主动提取无人机图像的多维辅助信息来增强任务提示，显著提升了开源和专有VLMs的性能，为无人机图像感知任务提供了新的解决方案。

Abstract: Existing image perception methods based on VLMs generally follow a paradigm wherein models extract and analyze image content based on user-provided textual task prompts. However, such methods face limitations when applied to UAV imagery, which presents challenges like target confusion, scale variations, and complex backgrounds. These challenges arise because VLMs' understanding of image content depends on the semantic alignment between visual and textual tokens. When the task prompt is simplistic and the image content is complex, achieving effective alignment becomes difficult, limiting the model's ability to focus on task-relevant information. To address this issue, we introduce AerialVP, the first agent framework for task prompt enhancement in UAV image perception. AerialVP proactively extracts multi-dimensional auxiliary information from UAV images to enhance task prompts, overcoming the limitations of traditional VLM-based approaches. Specifically, the enhancement process includes three stages: (1) analyzing the task prompt to identify the task type and enhancement needs, (2) selecting appropriate tools from the tool repository, and (3) generating enhanced task prompts based on the analysis and selected tools. To evaluate AerialVP, we introduce AerialSense, a comprehensive benchmark for UAV image perception that includes Aerial Visual Reasoning, Aerial Visual Question Answering, and Aerial Visual Grounding tasks. AerialSense provides a standardized basis for evaluating model generalization and performance across diverse resolutions, lighting conditions, and both urban and natural scenes. Experimental results demonstrate that AerialVP significantly enhances task prompt guidance, leading to stable and substantial performance improvements in both open-source and proprietary VLMs. Our work will be available at https://github.com/lostwolves/AerialVP.

</details>


### [122] [Hide-and-Seek Attribution: Weakly Supervised Segmentation of Vertebral Metastases in CT](https://arxiv.org/abs/2512.06849)
*Matan Atad,Alexander W. Marka,Lisa Steinhelfer,Anna Curto-Vilalta,Yannik Leonhardt,Sarah C. Foreman,Anna-Sophia Walburga Dietrich,Robert Graf,Alexandra S. Gersing,Bjoern Menze,Daniel Rueckert,Jan S. Kirschke,Hendrik Möller*

Main category: cs.CV

TL;DR: 该论文提出了一种弱监督方法，通过生成编辑和选择性遮挡技术，实现了CT中椎体转移的准确分割，无需病变掩模监督。


<details>
  <summary>Details</summary>
Motivation: 由于体素级注释稀缺且溶骨性和成骨性病变常与良性退行性变化相似，准确分割CT中的椎体转移在临床上重要但难以扩展。

Method: 提出了一种弱监督方法，结合了扩散自编码器（DAE）和像素级差异图，通过Hide-and-Seek Attribution技术确定真正的恶性区域。

Result: 在未使用任何病变掩模监督的情况下，该方法在保留的放射科医生注释上取得了优异的性能（F1: 0.91/0.85; Dice: 0.87/0.78），超过了基线方法（F1: 0.79/0.67; Dice: 0.74/0.55）。

Conclusion: 该研究展示了通过生成编辑与选择性遮挡相结合的方法，可以在CT中实现准确的弱监督分割，将椎体级别的标签转化为可靠的病变掩模。

Abstract: Accurate segmentation of vertebral metastasis in CT is clinically important yet difficult to scale, as voxel-level annotations are scarce and both lytic and blastic lesions often resemble benign degenerative changes. We introduce a weakly supervised method trained solely on vertebra-level healthy/malignant labels, without any lesion masks. The method combines a Diffusion Autoencoder (DAE) that produces a classifier-guided healthy edit of each vertebra with pixel-wise difference maps that propose candidate lesion regions. To determine which regions truly reflect malignancy, we introduce Hide-and-Seek Attribution: each candidate is revealed in turn while all others are hidden, the edited image is projected back to the data manifold by the DAE, and a latent-space classifier quantifies the isolated malignant contribution of that component. High-scoring regions form the final lytic or blastic segmentation. On held-out radiologist annotations, we achieve strong blastic/lytic performance despite no mask supervision (F1: 0.91/0.85; Dice: 0.87/0.78), exceeding baselines (F1: 0.79/0.67; Dice: 0.74/0.55). These results show that vertebra-level labels can be transformed into reliable lesion masks, demonstrating that generative editing combined with selective occlusion supports accurate weakly supervised segmentation in CT.

</details>


### [123] [ContextAnyone: Context-Aware Diffusion for Character-Consistent Text-to-Video Generation](https://arxiv.org/abs/2512.07328)
*Ziyang Mai,Yu-Wing Tai*

Main category: cs.CV

TL;DR: ContextAnyone是一种上下文感知的扩散框架，通过Emphasize-Attention模块和双引导损失，解决了文本到视频生成中角色身份一致性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在保持角色身份一致性（如发型、服装和体型）方面存在不足，影响了视频的视觉连贯性。

Method: 提出了一种基于DiT的扩散框架，结合Emphasize-Attention模块和Gap-RoPE位置嵌入，通过双引导损失联合优化参考图像重建和新视频帧生成。

Result: 实验表明，ContextAnyone在身份一致性和视觉质量上优于现有方法，能够生成跨多样动作和场景的连贯角色视频。

Conclusion: ContextAnyone通过上下文感知的扩散框架，成功解决了文本到视频生成中角色身份一致性的问题，显著提升了视觉质量和身份一致性。

Abstract: Text-to-video (T2V) generation has advanced rapidly, yet maintaining consistent character identities across scenes remains a major challenge. Existing personalization methods often focus on facial identity but fail to preserve broader contextual cues such as hairstyle, outfit, and body shape, which are critical for visual coherence. We propose \textbf{ContextAnyone}, a context-aware diffusion framework that achieves character-consistent video generation from text and a single reference image. Our method jointly reconstructs the reference image and generates new video frames, enabling the model to fully perceive and utilize reference information. Reference information is effectively integrated into a DiT-based diffusion backbone through a novel Emphasize-Attention module that selectively reinforces reference-aware features and prevents identity drift across frames. A dual-guidance loss combines diffusion and reference reconstruction objectives to enhance appearance fidelity, while the proposed Gap-RoPE positional embedding separates reference and video tokens to stabilize temporal modeling. Experiments demonstrate that ContextAnyone outperforms existing reference-to-video methods in identity consistency and visual quality, generating coherent and context-preserving character videos across diverse motions and scenes. Project page: \href{https://github.com/ziyang1106/ContextAnyone}{https://github.com/ziyang1106/ContextAnyone}.

</details>


### [124] [Omni-Referring Image Segmentation](https://arxiv.org/abs/2512.06862)
*Qiancheng Zheng,Yunhang Shen,Gen Luo,Baiyang Song,Xing Sun,Xiaoshuai Sun,Yiyi Zhou,Rongrong Ji*

Main category: cs.CV

TL;DR: OmniRIS是一种支持文本和视觉多模态输入的新型图像分割任务，通过OmniSegNet模型和OmniRef数据集实现高度泛化分割。


<details>
  <summary>Details</summary>
Motivation: 现有分割任务（如RIS和视觉RIS）仅支持单模态输入，限制了泛化能力。OmniRIS通过支持文本指令和多种视觉提示（如掩码、框或涂鸦）作为多模态输入，结合文本和视觉模态的优势，实现更灵活的分割。

Method: 提出了一种名为OmniSegNet的基线模型，用于处理多模态提示编码等挑战，并构建了大型数据集OmniRef（包含186,939个多模态提示和30,956张图像）以支持研究。

Result: 实验验证了OmniSegNet在多模态指令下的能力，并证明了OmniRIS在高度泛化图像分割中的优势。

Conclusion: OmniRIS展示了在高度泛化的图像分割任务中的优越性，OmniSegNet作为强基线模型有效解决了多模态提示编码等关键挑战。

Abstract: In this paper, we propose a novel task termed Omni-Referring Image Segmentation (OmniRIS) towards highly generalized image segmentation. Compared with existing unimodally conditioned segmentation tasks, such as RIS and visual RIS, OmniRIS supports the input of text instructions and reference images with masks, boxes or scribbles as omni-prompts. This property makes it can well exploit the intrinsic merits of both text and visual modalities, i.e., granular attribute referring and uncommon object grounding, respectively. Besides, OmniRIS can also handle various segmentation settings, such as one v.s. many and many v.s. many, further facilitating its practical use. To promote the research of OmniRIS, we also rigorously design and construct a large dataset termed OmniRef, which consists of 186,939 omni-prompts for 30,956 images, and establish a comprehensive evaluation system. Moreover, a strong and general baseline termed OmniSegNet is also proposed to tackle the key challenges of OmniRIS, such as omni-prompt encoding. The extensive experiments not only validate the capability of OmniSegNet in following omni-modal instructions, but also show the superiority of OmniRIS for highly generalized image segmentation.

</details>


### [125] [Boosting Unsupervised Video Instance Segmentation with Automatic Quality-Guided Self-Training](https://arxiv.org/abs/2512.06864)
*Kaixuan Lu,Mehmet Onurcan Kaya,Dim P. Papadopoulos*

Main category: cs.CV

TL;DR: AutoQ-VIS通过质量引导自训练，无监督实现视频实例分割，性能超越现有方法4.4%。


<details>
  <summary>Details</summary>
Motivation: 视频实例分割（VIS）因需要像素级掩码和时间一致性标签而面临标注挑战。现有无监督方法如VideoCutLER虽通过合成数据消除了光流依赖，但仍受限于合成到真实的域差距。

Method: AutoQ-VIS采用质量引导的自训练框架，通过伪标签生成和自动质量评估的闭环系统，逐步从合成数据适应到真实视频。

Result: 在YouTubeVIS-2019验证集上达到52.6 AP50，超越之前最优方法VideoCutLER 4.4%，且无需人工标注。

Conclusion: AutoQ-VIS通过质量引导的自训练方法，成功弥合了合成数据与真实视频之间的域差距，实现了无监督视频实例分割的最先进性能，证明了质量感知自训练在无监督VIS中的可行性。

Abstract: Video Instance Segmentation (VIS) faces significant annotation challenges due to its dual requirements of pixel-level masks and temporal consistency labels. While recent unsupervised methods like VideoCutLER eliminate optical flow dependencies through synthetic data, they remain constrained by the synthetic-to-real domain gap. We present AutoQ-VIS, a novel unsupervised framework that bridges this gap through quality-guided self-training. Our approach establishes a closed-loop system between pseudo-label generation and automatic quality assessment, enabling progressive adaptation from synthetic to real videos. Experiments demonstrate state-of-the-art performance with 52.6 $\text{AP}_{50}$ on YouTubeVIS-2019 $\texttt{val}$ set, surpassing the previous state-of-the-art VideoCutLER by 4.4%, while requiring no human annotations. This demonstrates the viability of quality-aware self-training for unsupervised VIS. We will release the code at https://github.com/wcbup/AutoQ-VIS.

</details>


### [126] [DeepAgent: A Dual Stream Multi Agent Fusion for Robust Multimodal Deepfake Detection](https://arxiv.org/abs/2512.07351)
*Sayeem Been Zaman,Wasimul Karim,Arefin Ittesafun Abian,Reem E. Mohamed,Md Rafiqul Islam,Asif Karim,Sami Azam*

Main category: cs.CV

TL;DR: DeepAgent通过视觉和音频智能体协作检测深度伪造，随机森林融合决策，在多个数据集上表现优异，验证了多智能体方法的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测方法多采用单模型整合多模态信息，易受模态不匹配、噪声和操纵的影响，需更鲁棒的解决方案。

Method: DeepAgent由两个互补的智能体组成：Agent-1基于AlexNet CNN检测视觉伪造痕迹，Agent-2结合声学特征、Whisper音频转录和EasyOCR图像序列检测音视频不一致性。决策通过随机森林元分类器融合。

Result: 在Celeb-DF和FakeAVCeleb数据集上，Agent-1测试准确率达94.35%；FakeAVCeleb上Agent-2和元分类器分别达93.69%和81.56%。跨数据集验证（DeepFakeTIMIT）中元分类器准确率达97.49%。

Conclusion: DeepAgent框架通过多智能体协作和层次化融合，有效提升了深度伪造检测的鲁棒性，证明了多模态和多智能体方法在处理多样化伪造类型中的优势。

Abstract: The increasing use of synthetic media, particularly deepfakes, is an emerging challenge for digital content verification. Although recent studies use both audio and visual information, most integrate these cues within a single model, which remains vulnerable to modality mismatches, noise, and manipulation. To address this gap, we propose DeepAgent, an advanced multi-agent collaboration framework that simultaneously incorporates both visual and audio modalities for the effective detection of deepfakes. DeepAgent consists of two complementary agents. Agent-1 examines each video with a streamlined AlexNet-based CNN to identify the symbols of deepfake manipulation, while Agent-2 detects audio-visual inconsistencies by combining acoustic features, audio transcriptions from Whisper, and frame-reading sequences of images through EasyOCR. Their decisions are fused through a Random Forest meta-classifier that improves final performance by taking advantage of the different decision boundaries learned by each agent. This study evaluates the proposed framework using three benchmark datasets to demonstrate both component-level and fused performance. Agent-1 achieves a test accuracy of 94.35% on the combined Celeb-DF and FakeAVCeleb datasets. On the FakeAVCeleb dataset, Agent-2 and the final meta-classifier attain accuracies of 93.69% and 81.56%, respectively. In addition, cross-dataset validation on DeepFakeTIMIT confirms the robustness of the meta-classifier, which achieves a final accuracy of 97.49%, and indicates a strong capability across diverse datasets. These findings confirm that hierarchy-based fusion enhances robustness by mitigating the weaknesses of individual modalities and demonstrate the effectiveness of a multi-agent approach in addressing diverse types of manipulations in deepfakes.

</details>


### [127] [Spatial Retrieval Augmented Autonomous Driving](https://arxiv.org/abs/2512.06865)
*Xiaosong Jia,Chenhe Zhang,Yule Jiang,Songbur Wong,Zhiyuan Zhang,Chen Chen,Shaofeng Zhang,Xuanhe Zhou,Xue Yang,Junchi Yan,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: 提出空间检索范式，利用离线地理图像增强自动驾驶感知能力，实验证明有效并开源数据。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶系统依赖车载传感器，其感知能力受限于实时感知范围和极端条件，而人类驾驶员能在恶劣条件下回忆道路结构。

Method: 扩展了nuScenes数据集，通过Google Maps API检索地理图像，并与自车轨迹对齐，建立了五个核心自动驾驶任务的基线。

Result: 实验表明，扩展的模态能提升特定任务的性能，数据集和基准将开源以供进一步研究。

Conclusion: 通过引入空间检索范式，利用离线检索的地理图像作为额外输入，增强了自动驾驶系统在有限视野、遮挡或极端条件下的感知能力。

Abstract: Existing autonomous driving systems rely on onboard sensors (cameras, LiDAR, IMU, etc) for environmental perception. However, this paradigm is limited by the drive-time perception horizon and often fails under limited view scope, occlusion or extreme conditions such as darkness and rain. In contrast, human drivers are able to recall road structure even under poor visibility. To endow models with this ``recall" ability, we propose the spatial retrieval paradigm, introducing offline retrieved geographic images as an additional input. These images are easy to obtain from offline caches (e.g, Google Maps or stored autonomous driving datasets) without requiring additional sensors, making it a plug-and-play extension for existing AD tasks.
  For experiments, we first extend the nuScenes dataset with geographic images retrieved via Google Maps APIs and align the new data with ego-vehicle trajectories. We establish baselines across five core autonomous driving tasks: object detection, online mapping, occupancy prediction, end-to-end planning, and generative world modeling. Extensive experiments show that the extended modality could enhance the performance of certain tasks. We will open-source dataset curation code, data, and benchmarks for further study of this new autonomous driving paradigm.

</details>


### [128] [Structure-Aware Feature Rectification with Region Adjacency Graphs for Training-Free Open-Vocabulary Semantic Segmentation](https://arxiv.org/abs/2512.07360)
*Qiming Huang,Hao Ai,Jianbo Jiao*

Main category: cs.CV

TL;DR: 论文提出一种结构感知特征校正方法，通过区域邻接图优化CLIP特征，解决了开放词汇语义分割中因CLIP全局关注导致的局部噪声问题，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 由于CLIP在图像-文本对上预训练的性质，其倾向于关注全局语义对齐，导致在将细粒度视觉区域与文本关联时表现不佳，产生噪声和不一致的预测。

Method: 构建基于低级特征（如颜色和纹理）的区域邻接图（RAG）以捕捉局部结构关系，并利用该图通过增强局部区分性来优化CLIP特征。

Result: 实验表明，该方法有效抑制了分割噪声，提高了区域级一致性，并在多个开放词汇分割基准上表现优异。

Conclusion: 该论文提出的结构感知特征校正方法通过结合图像实例特定的先验知识，有效抑制了分割噪声，提高了区域级一致性，并在多个开放词汇分割基准上取得了强劲性能。

Abstract: Benefiting from the inductive biases learned from large-scale datasets, open-vocabulary semantic segmentation (OVSS) leverages the power of vision-language models, such as CLIP, to achieve remarkable progress without requiring task-specific training. However, due to CLIP's pre-training nature on image-text pairs, it tends to focus on global semantic alignment, resulting in suboptimal performance when associating fine-grained visual regions with text. This leads to noisy and inconsistent predictions, particularly in local areas. We attribute this to a dispersed bias stemming from its contrastive training paradigm, which is difficult to alleviate using CLIP features alone. To address this, we propose a structure-aware feature rectification approach that incorporates instance-specific priors derived directly from the image. Specifically, we construct a region adjacency graph (RAG) based on low-level features (e.g., colour and texture) to capture local structural relationships and use it to refine CLIP features by enhancing local discrimination. Extensive experiments show that our method effectively suppresses segmentation noise, improves region-level consistency, and achieves strong performance on multiple open-vocabulary segmentation benchmarks.

</details>


### [129] [Towards Robust Pseudo-Label Learning in Semantic Segmentation: An Encoding Perspective](https://arxiv.org/abs/2512.06870)
*Wangkai Li,Rui Sun,Zhaoyang Li,Tianzhu Zhang*

Main category: cs.CV

TL;DR: ECOCSeg利用ECOC编码和位级去噪机制，提升伪标签学习的稳定性和泛化能力，在UDA和SSL任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决伪标签学习中因独热编码导致的错误伪标签放大问题。

Method: 提出ECOCSeg，利用错误纠正输出码（ECOC）为每个类别创建细粒度编码，包括基于ECOC的分类器和位级标签去噪机制。

Result: ECOCSeg在多种分割架构的UDA和SSL基准测试中均表现出显著改进。

Conclusion: ECOCSeg通过引入基于ECOC的细粒度编码和位级标签去噪机制，显著提升了伪标签学习的稳定性和泛化能力，并在多个UDA和SSL基准测试中表现出持续的改进。

Abstract: Pseudo-label learning is widely used in semantic segmentation, particularly in label-scarce scenarios such as unsupervised domain adaptation (UDA) and semisupervised learning (SSL). Despite its success, this paradigm can generate erroneous pseudo-labels, which are further amplified during training due to utilization of one-hot encoding. To address this issue, we propose ECOCSeg, a novel perspective for segmentation models that utilizes error-correcting output codes (ECOC) to create a fine-grained encoding for each class. ECOCSeg offers several advantages. First, an ECOC-based classifier is introduced, enabling model to disentangle classes into attributes and handle partial inaccurate bits, improving stability and generalization in pseudo-label learning. Second, a bit-level label denoising mechanism is developed to generate higher-quality pseudo-labels, providing adequate and robust supervision for unlabeled images. ECOCSeg can be easily integrated with existing methods and consistently demonstrates significant improvements on multiple UDA and SSL benchmarks across different segmentation architectures. Code is available at https://github.com/Woof6/ECOCSeg.

</details>


### [130] [SceneMixer: Exploring Convolutional Mixing Networks for Remote Sensing Scene Classification](https://arxiv.org/abs/2512.06877)
*Mohammed Q. Alkhatib,Ali Jamali,Swalpa Kumar Roy*

Main category: cs.CV

TL;DR: A lightweight convolutional mixer model improves remote sensing scene classification by efficiently balancing accuracy and computational cost, outperforming CNNs and transformers on benchmarks.


<details>
  <summary>Details</summary>
Motivation: Addressing the challenges in remote sensing scene classification, such as variations in spatial resolution, viewpoint, orientation, and background conditions, which reduce the generalization ability of existing models.

Method: The model alternates between spatial mixing through depthwise convolutions at multiple scales and channel mixing through pointwise operations, enabling efficient extraction of local and contextual information with low computational cost.

Result: The model achieved overall accuracy, average accuracy, and Kappa values of 74.7%, 74.57%, and 73.79 on the AID dataset, and 93.90%, 93.93%, and 93.22 on EuroSAT, respectively.

Conclusion: The proposed lightweight convolutional mixer architecture achieves a good balance between accuracy and efficiency in remote sensing scene classification, outperforming existing CNN- and transformer-based models on benchmark datasets.

Abstract: Remote sensing scene classification plays a key role in Earth observation by enabling the automatic identification of land use and land cover (LULC) patterns from aerial and satellite imagery. Despite recent progress with convolutional neural networks (CNNs) and vision transformers (ViTs), the task remains challenging due to variations in spatial resolution, viewpoint, orientation, and background conditions, which often reduce the generalization ability of existing models. To address these challenges, this paper proposes a lightweight architecture based on the convolutional mixer paradigm. The model alternates between spatial mixing through depthwise convolutions at multiple scales and channel mixing through pointwise operations, enabling efficient extraction of both local and contextual information while keeping the number of parameters and computations low. Extensive experiments were conducted on the AID and EuroSAT benchmarks. The proposed model achieved overall accuracy, average accuracy, and Kappa values of 74.7%, 74.57%, and 73.79 on the AID dataset, and 93.90%, 93.93%, and 93.22 on EuroSAT, respectively. These results demonstrate that the proposed approach provides a good balance between accuracy and efficiency compared with widely used CNN- and transformer-based models. Code will be publicly available on: https://github.com/mqalkhatib/SceneMixer

</details>


### [131] [Data-driven Exploration of Mobility Interaction Patterns](https://arxiv.org/abs/2512.07415)
*Gabriele Galatolo,Mirco Nanni*

Main category: cs.CV

TL;DR: 本研究提出了一种基于数据挖掘的方法，直接从数据中识别个体间的移动互动模式，并通过真实案例验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 理解个体移动行为及其对外部世界的反应对于模拟人类动态至关重要，尤其是在人群模拟和应急管理中。

Method: 采用数据挖掘视角，直接从数据中寻找可能的互动证据，并分析复杂、持久的模式和事件配置。

Result: 在两个真实案例（汽车和行人）上进行了全面的实验评估，包括性能、参数敏感性和结果解释。

Conclusion: 本研究通过数据挖掘方法揭示了个人移动行为中的互动模式，为改进现有的人类动态模拟模型提供了新的视角。

Abstract: Understanding the movement behaviours of individuals and the way they react to the external world is a key component of any problem that involves the modelling of human dynamics at a physical level. In particular, it is crucial to capture the influence that the presence of an individual can have on the others. Important examples of applications include crowd simulation and emergency management, where the simulation of the mass of people passes through the simulation of the individuals, taking into consideration the others as part of the general context. While existing solutions basically start from some preconceived behavioural model, in this work we propose an approach that starts directly from the data, adopting a data mining perspective. Our method searches the mobility events in the data that might be possible evidences of mutual interactions between individuals, and on top of them looks for complex, persistent patterns and time evolving configurations of events. The study of these patterns can provide new insights on the mechanics of mobility interactions between individuals, which can potentially help in improving existing simulation models. We instantiate the general methodology on two real case studies, one on cars and one on pedestrians, and a full experimental evaluation is performed, both in terms of performances, parameter sensitivity and interpretation of sample results.

</details>


### [132] [Hierarchical Image-Guided 3D Point Cloud Segmentation in Industrial Scenes via Multi-View Bayesian Fusion](https://arxiv.org/abs/2512.06882)
*Yu Zhu,Naoya Chiba,Koichi Hashimoto*

Main category: cs.CV

TL;DR: 提出分层图像引导3D分割框架，通过实例级到部件级逐步细化，有效处理工业场景中的遮挡和尺度问题，实验验证其高效性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 工业环境中密集布局和多尺度物体的复杂场景使得现有3D分割方法难以处理遮挡和尺度差异，且现有方法需要昂贵标注或存在语义不一致问题。

Method: 提出了一种分层图像引导的3D分割框架，通过从实例级到部件级的逐步细化分割，利用SAM和YOLO-World生成的掩模进行2D分割并反向投影到3D点云，再通过贝叶斯更新融合确保多视角语义一致性。

Result: 实验证明该方法有效处理遮挡和结构复杂性，实现了高mIoU分数，并在公共数据集上验证了其泛化能力。

Conclusion: 该方法在真实工厂数据和公共数据集上均表现出色，展示了其鲁棒性、标注效率和适应性。

Abstract: Reliable 3D segmentation is critical for understanding complex scenes with dense layouts and multi-scale objects, as commonly seen in industrial environments. In such scenarios, heavy occlusion weakens geometric boundaries between objects, and large differences in object scale will cause end-to-end models fail to capture both coarse and fine details accurately. Existing 3D point-based methods require costly annotations, while image-guided methods often suffer from semantic inconsistencies across views. To address these challenges, we propose a hierarchical image-guided 3D segmentation framework that progressively refines segmentation from instance-level to part-level. Instance segmentation involves rendering a top-view image and projecting SAM-generated masks prompted by YOLO-World back onto the 3D point cloud. Part-level segmentation is subsequently performed by rendering multi-view images of each instance obtained from the previous stage and applying the same 2D segmentation and back-projection process at each view, followed by Bayesian updating fusion to ensure semantic consistency across views. Experiments on real-world factory data demonstrate that our method effectively handles occlusion and structural complexity, achieving consistently high per-class mIoU scores. Additional evaluations on public dataset confirm the generalization ability of our framework, highlighting its robustness, annotation efficiency, and adaptability to diverse 3D environments.

</details>


### [133] [When normalization hallucinates: unseen risks in AI-powered whole slide image processing](https://arxiv.org/abs/2512.07426)
*Karel Moens,Matthew B. Blaschko,Tinne Tuytelaars,Bart Diricx,Jonas De Vylder,Mustafa Yousif*

Main category: cs.CV

TL;DR: 本文揭示了全切片图像归一化中未被充分认识的幻觉风险，提出了一种自动检测方法，并呼吁更鲁棒的归一化技术和严格的临床验证。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法在归一化过程中可能引入幻觉内容，这些内容在视觉上难以检测，且当前评估方法常忽略这一问题，对下游分析构成严重威胁。

Method: 提出了一种新颖的图像比较方法，用于自动检测归一化输出中的幻觉内容，并系统评估了几种在真实临床数据上重新训练的归一化方法。

Result: 研究发现，在真实临床数据上重新训练的归一化方法存在显著的幻觉问题，这些问题未被传统指标捕获。

Conclusion: 本文强调了在计算病理学中，全切片图像（WSI）归一化技术的鲁棒性和可解释性的重要性，并提出了更严格的临床验证协议的必要性。

Abstract: Whole slide image (WSI) normalization remains a vital preprocessing step in computational pathology. Increasingly driven by deep learning, these models learn to approximate data distributions from training examples. This often results in outputs that gravitate toward the average, potentially masking diagnostically important features. More critically, they can introduce hallucinated content, artifacts that appear realistic but are not present in the original tissue, posing a serious threat to downstream analysis. These hallucinations are nearly impossible to detect visually, and current evaluation practices often overlook them. In this work, we demonstrate that the risk of hallucinations is real and underappreciated. While many methods perform adequately on public datasets, we observe a concerning frequency of hallucinations when these same models are retrained and evaluated on real-world clinical data. To address this, we propose a novel image comparison measure designed to automatically detect hallucinations in normalized outputs. Using this measure, we systematically evaluate several well-cited normalization methods retrained on real-world data, revealing significant inconsistencies and failures that are not captured by conventional metrics. Our findings underscore the need for more robust, interpretable normalization techniques and stricter validation protocols in clinical deployment.

</details>


### [134] [Balanced Learning for Domain Adaptive Semantic Segmentation](https://arxiv.org/abs/2512.06886)
*Wangkai Li,Rui Sun,Bohao Liao,Zhaoyang Li,Tianzhu Zhang*

Main category: cs.CV

TL;DR: BLDA通过logits分布分析和校正，有效缓解UDA语义分割中的类别不平衡问题，提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决自训练技术在UDA中因类别不平衡和领域间分布偏移导致的类别学习不平衡问题。

Method: 提出BLDA方法，通过分析预测logits分布识别过预测和欠预测类别，使用共享锚分布对齐logits分布，并在损失函数中引入logits校正项。

Result: 在两个标准UDA语义分割基准测试中，BLDA显著提升了性能，尤其是对欠预测类别的效果。

Conclusion: BLDA通过直接评估和缓解类别偏差，显著提升了无监督领域自适应（UDA）在语义分割中的性能，尤其是在类别不平衡的情况下。

Abstract: Unsupervised domain adaptation (UDA) for semantic segmentation aims to transfer knowledge from a labeled source domain to an unlabeled target domain. Despite the effectiveness of self-training techniques in UDA, they struggle to learn each class in a balanced manner due to inherent class imbalance and distribution shift in both data and label space between domains. To address this issue, we propose Balanced Learning for Domain Adaptation (BLDA), a novel approach to directly assess and alleviate class bias without requiring prior knowledge about the distribution shift. First, we identify over-predicted and under-predicted classes by analyzing the distribution of predicted logits. Subsequently, we introduce a post-hoc approach to align the logits distributions across different classes using shared anchor distributions. To further consider the network's need to generate unbiased pseudo-labels during self-training, we estimate logits distributions online and incorporate logits correction terms into the loss function. Moreover, we leverage the resulting cumulative density as domain-shared structural knowledge to connect the source and target domains. Extensive experiments on two standard UDA semantic segmentation benchmarks demonstrate that BLDA consistently improves performance, especially for under-predicted classes, when integrated into various existing methods. Code is available at https://github.com/Woof6/BLDA.

</details>


### [135] [Overcoming Small Data Limitations in Video-Based Infant Respiration Estimation](https://arxiv.org/abs/2512.06888)
*Liyang Song,Hardik Bishnoi,Sai Kumar Reddy Manne,Sarah Ostadabbas,Briana J. Taylor,Michael Wan*

Main category: cs.CV

TL;DR: 论文提出AIR-400数据集和首个可复现的婴儿呼吸估计方法，填补了婴儿呼吸监测领域的空白。


<details>
  <summary>Details</summary>
Motivation: 解决婴儿呼吸监测缺乏公共数据集和可复现算法的问题，以早期发现和治疗呼吸异常。

Method: 基于婴儿特定区域检测和光流输入增强的时空神经处理。

Result: 开发了包含400个视频的AIR-400数据集，并建立了首个可复现的婴儿呼吸估计流程和基准。

Conclusion: 该论文介绍了AIR-400数据集和首个可复现的婴儿呼吸估计流程，为基于视觉的婴儿呼吸监测建立了基准，并公开了数据集、代码和模型。

Abstract: The development of contactless respiration monitoring for infants could enable advances in the early detection and treatment of breathing irregularities, which are associated with neurodevelopmental impairments and conditions like sudden infant death syndrome (SIDS). But while respiration estimation for adults is supported by a robust ecosystem of computer vision algorithms and video datasets, only one small public video dataset with annotated respiration data for infant subjects exists, and there are no reproducible algorithms which are effective for infants. We introduce the annotated infant respiration dataset of 400 videos (AIR-400), contributing 275 new, carefully annotated videos from 10 recruited subjects to the public corpus. We develop the first reproducible pipelines for infant respiration estimation, based on infant-specific region-of-interest detection and spatiotemporal neural processing enhanced by optical flow inputs. We establish, through comprehensive experiments, the first reproducible benchmarks for the state-of-the-art in vision-based infant respiration estimation. We make our dataset, code repository, and trained models available for public use.

</details>


### [136] [Toward More Reliable Artificial Intelligence: Reducing Hallucinations in Vision-Language Models](https://arxiv.org/abs/2512.07564)
*Kassoum Sanogo,Renzo Ardiccioni*

Main category: cs.CV

TL;DR: 提出了一种无需训练的自校正框架，通过不确定性引导的视觉重新关注减少VLMs的幻觉内容，实验显示效果显著。


<details>
  <summary>Details</summary>
Motivation: 解决VLMs频繁生成看似合理但实际错误的图像内容描述（即幻觉内容）的问题。

Method: 结合多维不确定性量化（如令牌熵、注意力分散、语义一致性和声明置信度）与注意力引导的裁剪技术，完全基于预训练且冻结的VLMs，无需梯度更新。

Result: 在POPE和MMHAL BENCH基准测试中，该方法将幻觉率降低了9.8个百分点，并在对抗性分割中提高了对象存在准确性4.7个百分点。

Conclusion: 该论文提出了一种无需训练的自校正框架，通过不确定性引导的视觉重新关注，显著减少了视觉语言模型（VLMs）的幻觉内容，并提高了对象存在准确性。

Abstract: Vision-language models (VLMs) frequently generate hallucinated content plausible but incorrect claims about image content. We propose a training-free self-correction framework enabling VLMs to iteratively refine responses through uncertainty-guided visual re-attention. Our method combines multidimensional uncertainty quantification (token entropy, attention dispersion, semantic consistency, claim confidence) with attention-guided cropping of under-explored regions. Operating entirely with frozen, pretrained VLMs, our framework requires no gradient updates. We validate our approach on the POPE and MMHAL BENCH benchmarks using the Qwen2.5-VL-7B [23] architecture. Experimental results demonstrate that our method reduces hallucination rates by 9.8 percentage points compared to the baseline, while improving object existence accuracy by 4.7 points on adversarial splits. Furthermore, qualitative analysis confirms that uncertainty-guided re-attention successfully grounds corrections in visual evidence where standard decoding fails. We validate our approach on Qwen2.5-VL-7B [23], with plans to extend validation across diverse architectures in future versions. We release our code and methodology to facilitate future research in trustworthy multimodal systems.

</details>


### [137] [Scaling Zero-Shot Reference-to-Video Generation](https://arxiv.org/abs/2512.06905)
*Zijian Zhou,Shikun Liu,Haozhe Liu,Haonan Qiu,Zhaochong An,Weiming Ren,Zhiheng Liu,Xiaoke Huang,Kam Woh Ng,Tian Xie,Xiao Han,Yuren Cong,Hang Li,Chuyan Zhu,Aditya Patel,Tao Xiang,Sen He*

Main category: cs.CV

TL;DR: Saber是一种零样本框架，无需显式R2V数据，通过掩码训练和注意力设计，实现了身份一致和参考感知的视频生成，性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 当前R2V方法依赖昂贵且难以扩展的显式参考图像-视频-文本三元组，限制了其实际应用。

Method: Saber采用掩码训练策略和定制的基于注意力的模型设计，结合掩码增强技术，学习身份一致和参考感知的表示。

Result: Saber在OpenS2V-Eval基准测试中表现优于依赖R2V数据的方法，且能灵活适应不同数量的参考。

Conclusion: Saber框架通过零样本学习方法，成功绕过了传统R2V方法对昂贵且难以扩展的三元组数据的依赖，展示了卓越的泛化能力和性能优势。

Abstract: Reference-to-video (R2V) generation aims to synthesize videos that align with a text prompt while preserving the subject identity from reference images. However, current R2V methods are hindered by the reliance on explicit reference image-video-text triplets, whose construction is highly expensive and difficult to scale. We bypass this bottleneck by introducing Saber, a scalable zero-shot framework that requires no explicit R2V data. Trained exclusively on video-text pairs, Saber employs a masked training strategy and a tailored attention-based model design to learn identity-consistent and reference-aware representations. Mask augmentation techniques are further integrated to mitigate copy-paste artifacts common in reference-to-video generation. Moreover, Saber demonstrates remarkable generalization capabilities across a varying number of references and achieves superior performance on the OpenS2V-Eval benchmark compared to methods trained with R2V data.

</details>


### [138] [Dual-Stream Cross-Modal Representation Learning via Residual Semantic Decorrelation](https://arxiv.org/abs/2512.07568)
*Xuecheng Li,Weikuan Jia,Alisher Kurbonaliev,Qurbonaliev Alisher,Khudzhamkulov Rustam,Ismoilov Shuhratjon,Eshmatov Javhariddin,Yuanjie Zheng*

Main category: cs.CV

TL;DR: DSRSD-Net通过残差分解和语义去相关，有效提升跨模态学习的性能与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决多模态表示中的模态主导、冗余信息耦合和虚假跨模态相关性问题，以提高泛化能力和可解释性。

Method: 提出了一种双流残差语义去相关网络（DSRSD-Net），包括双流表示学习模块、残差语义对齐头和去相关正交性损失。

Result: 在两个大规模教育基准测试中，DSRSD-Net在下一步预测和最终结果预测上均优于基线方法。

Conclusion: DSRSD-Net通过残差分解和显式语义去相关约束，有效解耦了模态特定和模态共享信息，显著提升了跨模态学习的预测性能和鲁棒性。

Abstract: Cross-modal learning has become a fundamental paradigm for integrating heterogeneous information sources such as images, text, and structured attributes. However, multimodal representations often suffer from modality dominance, redundant information coupling, and spurious cross-modal correlations, leading to suboptimal generalization and limited interpretability. In particular, high-variance modalities tend to overshadow weaker but semantically important signals, while naïve fusion strategies entangle modality-shared and modality-specific factors in an uncontrolled manner. This makes it difficult to understand which modality actually drives a prediction and to maintain robustness when some modalities are noisy or missing. To address these challenges, we propose a Dual-Stream Residual Semantic Decorrelation Network (DSRSD-Net), a simple yet effective framework that disentangles modality-specific and modality-shared information through residual decomposition and explicit semantic decorrelation constraints. DSRSD-Net introduces: (1) a dual-stream representation learning module that separates intra-modal (private) and inter-modal (shared) latent factors via residual projection; (2) a residual semantic alignment head that maps shared factors from different modalities into a common space using a combination of contrastive and regression-style objectives; and (3) a decorrelation and orthogonality loss that regularizes the covariance structure of the shared space while enforcing orthogonality between shared and private streams, thereby suppressing cross-modal redundancy and preventing feature collapse. Experimental results on two large-scale educational benchmarks demonstrate that DSRSD-Net consistently improves next-step prediction and final outcome prediction over strong single-modality, early-fusion, late-fusion, and co-attention baselines.

</details>


### [139] [An AI-Powered Autonomous Underwater System for Sea Exploration and Scientific Research](https://arxiv.org/abs/2512.07652)
*Hamad Almazrouei,Mariam Al Nasseri,Maha Alzaabi*

Main category: cs.CV

TL;DR: 本文提出了一种AI驱动的AUV系统，通过自动化水下物体检测、分析和报告，显著提升了海洋探索的效率和安全性。


<details>
  <summary>Details</summary>
Motivation: 传统海洋探索面临极端条件、有限能见度和高成本等挑战，导致大量海洋区域未被探索。

Method: 系统集成了YOLOv12 Nano进行实时物体检测，ResNet50进行特征提取，PCA进行降维，K-Means++聚类基于视觉特征对海洋物体进行分组，以及GPT-4o Mini生成结构化报告和摘要。

Result: 实验结果表明，系统在检测海洋物体时的mAP@0.5为0.512，精度为0.535，召回率为0.438。PCA有效降低了特征维度并保留了98%的方差，K-Means聚类成功基于视觉相似性对检测到的物体进行了分组，LLM集成有效生成了检测和聚类的深刻摘要。

Conclusion: 该论文提出的AI驱动的自主水下车辆（AUV）系统通过自动化水下物体检测、分析和报告，显著降低了人类潜水的风险，提高了任务效率，并增强了水下数据分析的速度和深度，为在挑战性海洋环境中进行更有效的科学研究铺平了道路。

Abstract: Traditional sea exploration faces significant challenges due to extreme conditions, limited visibility, and high costs, resulting in vast unexplored ocean regions. This paper presents an innovative AI-powered Autonomous Underwater Vehicle (AUV) system designed to overcome these limitations by automating underwater object detection, analysis, and reporting. The system integrates YOLOv12 Nano for real-time object detection, a Convolutional Neural Network (CNN) (ResNet50) for feature extraction, Principal Component Analysis (PCA) for dimensionality reduction, and K-Means++ clustering for grouping marine objects based on visual characteristics. Furthermore, a Large Language Model (LLM) (GPT-4o Mini) is employed to generate structured reports and summaries of underwater findings, enhancing data interpretation. The system was trained and evaluated on a combined dataset of over 55,000 images from the DeepFish and OzFish datasets, capturing diverse Australian marine environments. Experimental results demonstrate the system's capability to detect marine objects with a mAP@0.5 of 0.512, a precision of 0.535, and a recall of 0.438. The integration of PCA effectively reduced feature dimensionality while preserving 98% variance, facilitating K-Means clustering which successfully grouped detected objects based on visual similarities. The LLM integration proved effective in generating insightful summaries of detections and clusters, supported by location data. This integrated approach significantly reduces the risks associated with human diving, increases mission efficiency, and enhances the speed and depth of underwater data analysis, paving the way for more effective scientific research and discovery in challenging marine environments.

</details>


### [140] [Can We Go Beyond Visual Features? Neural Tissue Relation Modeling for Relational Graph Analysis in Non-Melanoma Skin Histology](https://arxiv.org/abs/2512.06949)
*Shravan Venkatraman,Muthu Subash Kavitha,Joe Dhanith P R,V Manikandarajan,Jia Wu*

Main category: cs.CV

TL;DR: NTRM是一种结合CNN与图神经网络的分割框架，通过建模组织间关系显著提升皮肤癌病理图像分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有CNN方法主要依赖视觉纹理，忽略了组织间的空间和功能关系，导致在重叠或形态相似组织区域的分割效果不佳。

Method: NTRM结合CNN与图神经网络，构建组织级图模型，通过消息传递传播上下文信息，并通过空间投影优化分割。

Result: 在非黑色素瘤皮肤癌分割数据集上，NTRM的Dice相似系数比现有最佳方法高出4.9%至31.25%。

Conclusion: NTRM通过建模组织间关系，显著提升了皮肤癌组织病理学图像分割的性能，尤其在边界密集区域表现出结构一致性。

Abstract: Histopathology image segmentation is essential for delineating tissue structures in skin cancer diagnostics, but modeling spatial context and inter-tissue relationships remains a challenge, especially in regions with overlapping or morphologically similar tissues. Current convolutional neural network (CNN)-based approaches operate primarily on visual texture, often treating tissues as independent regions and failing to encode biological context. To this end, we introduce Neural Tissue Relation Modeling (NTRM), a novel segmentation framework that augments CNNs with a tissue-level graph neural network to model spatial and functional relationships across tissue types. NTRM constructs a graph over predicted regions, propagates contextual information via message passing, and refines segmentation through spatial projection. Unlike prior methods, NTRM explicitly encodes inter-tissue dependencies, enabling structurally coherent predictions in boundary-dense zones. On the benchmark Histopathology Non-Melanoma Skin Cancer Segmentation Dataset, NTRM outperforms state-of-the-art methods, achieving a robust Dice similarity coefficient that is 4.9\% to 31.25\% higher than the best-performing models among the evaluated approaches. Our experiments indicate that relational modeling offers a principled path toward more context-aware and interpretable histological segmentation, compared to local receptive-field architectures that lack tissue-level structural awareness. Our code is available at https://github.com/shravan-18/NTRM.

</details>


### [141] [DIST-CLIP: Arbitrary Metadata and Image Guided MRI Harmonization via Disentangled Anatomy-Contrast Representations](https://arxiv.org/abs/2512.07674)
*Mehmet Yigit Avci,Pedro Borges,Virginia Fernandez,Paul Wright,Mehmet Yigitsoy,Sebastien Ourselin,Jorge Cardoso*

Main category: cs.CV

TL;DR: DIST-CLIP 是一种新型 MRI 数据标准化框架，通过解耦内容和对比度并利用 CLIP 指导，显著提升了处理临床数据异质性的能力。


<details>
  <summary>Details</summary>
Motivation: 深度学习在医学影像分析中的临床泛化受限于数据异质性，尤其是 MRI 中因硬件、协议和参数差异导致的域偏移。现有方法无法充分应对这种复杂性。

Method: 提出了 DIST-CLIP 框架，通过解耦解剖内容和图像对比度，并利用预训练的 CLIP 编码器提取对比度表示，再通过自适应风格转移模块整合。

Result: 在多样化临床数据集上的评估显示，DIST-CLIP 在风格转换保真度和解剖结构保留方面显著优于现有方法。

Conclusion: DIST-CLIP 提供了一种灵活的 MRI 数据标准化解决方案，显著提升了风格转换的保真度和解剖结构的保留能力。

Abstract: Deep learning holds immense promise for transforming medical image analysis, yet its clinical generalization remains profoundly limited. A major barrier is data heterogeneity. This is particularly true in Magnetic Resonance Imaging, where scanner hardware differences, diverse acquisition protocols, and varying sequence parameters introduce substantial domain shifts that obscure underlying biological signals. Data harmonization methods aim to reduce these instrumental and acquisition variability, but existing approaches remain insufficient. When applied to imaging data, image-based harmonization approaches are often restricted by the need for target images, while existing text-guided methods rely on simplistic labels that fail to capture complex acquisition details or are typically restricted to datasets with limited variability, failing to capture the heterogeneity of real-world clinical environments. To address these limitations, we propose DIST-CLIP (Disentangled Style Transfer with CLIP Guidance), a unified framework for MRI harmonization that flexibly uses either target images or DICOM metadata for guidance. Our framework explicitly disentangles anatomical content from image contrast, with the contrast representations being extracted using pre-trained CLIP encoders. These contrast embeddings are then integrated into the anatomical content via a novel Adaptive Style Transfer module. We trained and evaluated DIST-CLIP on diverse real-world clinical datasets, and showed significant improvements in performance when compared against state-of-the-art methods in both style translation fidelity and anatomical preservation, offering a flexible solution for style transfer and standardizing MRI data. Our code and weights will be made publicly available upon publication.

</details>


### [142] [Selective Masking based Self-Supervised Learning for Image Semantic Segmentation](https://arxiv.org/abs/2512.06981)
*Yuemin Wang,Ian Stavness*

Main category: cs.CV

TL;DR: 提出选择性掩码图像重建方法，通过迭代选择性掩码高重建损失的图像块，显著提升语义分割准确性，尤其在资源受限场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 旨在改进语义分割的预训练方法，特别是在模型容量受限的场景中，通过选择性掩码提升下游分割任务的准确性。

Method: 提出了一种新颖的自监督学习方法，通过选择性掩码图像重建作为预训练任务，替代了传统随机掩码增强方法。该方法通过迭代步骤选择性掩码重建损失最高的图像块，利用训练模型的知识。

Result: 在两个通用数据集（Pascal VOC和Cityscapes）和两个杂草分割数据集（Nassar 2020和Sugarbeets 2016）上，选择性掩码方法比传统随机掩码和ImageNet监督预训练在下游分割准确率上分别提高了2.9%和2.5%。此外，该方法显著提升了最低性能类别的准确性。

Conclusion: 本文提出的选择性掩码图像重建方法为端到端语义分割工作流程提供了一种有效且实用的解决方案，尤其在模型容量有限以满足推理速度和计算资源需求的场景中表现优异。

Abstract: This paper proposes a novel self-supervised learning method for semantic segmentation using selective masking image reconstruction as the pretraining task. Our proposed method replaces the random masking augmentation used in most masked image modelling pretraining methods. The proposed selective masking method selectively masks image patches with the highest reconstruction loss by breaking the image reconstruction pretraining into iterative steps to leverage the trained model's knowledge. We show on two general datasets (Pascal VOC and Cityscapes) and two weed segmentation datasets (Nassar 2020 and Sugarbeets 2016) that our proposed selective masking method outperforms the traditional random masking method and supervised ImageNet pretraining on downstream segmentation accuracy by 2.9% for general datasets and 2.5% for weed segmentation datasets. Furthermore, we found that our selective masking method significantly improves accuracy for the lowest-performing classes. Lastly, we show that using the same pretraining and downstream dataset yields the best result for low-budget self-supervised pretraining. Our proposed Selective Masking Image Reconstruction method provides an effective and practical solution to improve end-to-end semantic segmentation workflows, especially for scenarios that require limited model capacity to meet inference speed and computational resource requirements.

</details>


### [143] [Guiding What Not to Generate: Automated Negative Prompting for Text-Image Alignment](https://arxiv.org/abs/2512.07702)
*Sangha Park,Eunji Kim,Yeongtak Oh,Jooyoung Choi,Sungroh Yoon*

Main category: cs.CV

TL;DR: NPC是一种自动管道，通过负面提示改善文本-图像对齐，无需额外图像合成，在基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 尽管文本到图像生成取得了显著进展，但对于具有丰富组合结构或想象元素的提示，实现精确的文本-图像对齐仍然具有挑战性。

Method: NPC采用了一个验证器-标注器-提议者框架来生成候选负面提示，并通过一个显著的文本空间评分对它们进行排名，从而无需额外的图像合成即可进行有效选择。

Result: 在GenEval++和Imagine-Bench上，NPC表现优于强基线，分别达到0.571 vs. 0.371的成绩，并在Imagine-Bench上取得了最佳整体性能。

Conclusion: NPC通过自动识别和应用负面提示来抑制不相关内容，为扩散模型中的文本-图像对齐提供了一种原则性的、全自动的途径。

Abstract: Despite substantial progress in text-to-image generation, achieving precise text-image alignment remains challenging, particularly for prompts with rich compositional structure or imaginative elements. To address this, we introduce Negative Prompting for Image Correction (NPC), an automated pipeline that improves alignment by identifying and applying negative prompts that suppress unintended content. We begin by analyzing cross-attention patterns to explain why both targeted negatives-those directly tied to the prompt's alignment error-and untargeted negatives-tokens unrelated to the prompt but present in the generated image-can enhance alignment. To discover useful negatives, NPC generates candidate prompts using a verifier-captioner-proposer framework and ranks them with a salient text-space score, enabling effective selection without requiring additional image synthesis. On GenEval++ and Imagine-Bench, NPC outperforms strong baselines, achieving 0.571 vs. 0.371 on GenEval++ and the best overall performance on Imagine-Bench. By guiding what not to generate, NPC provides a principled, fully automated route to stronger text-image alignment in diffusion models. Code is released at https://github.com/wiarae/NPC.

</details>


### [144] [Improving action classification with brain-inspired deep networks](https://arxiv.org/abs/2512.07729)
*Aidas Aglinskas,Stefano Anzellotti*

Main category: cs.CV

TL;DR: 研究显示，模仿大脑域特异性的深度网络架构能提升动作识别性能，使其表现更接近人类。


<details>
  <summary>Details</summary>
Motivation: 探究深度神经网络（DNNs）在动作识别中如何利用身体和背景信息，以及是否可以通过模仿人类大脑的域特异性设计更高效的网络架构。

Method: 使用HAA500数据集训练深度神经网络（DNNs），并测试其在不同刺激版本（完整、仅身体、仅背景）上的表现。同时，设计并测试一种模仿大脑域特异性的新型架构，包含独立的身体和背景处理流。

Result: DNNs在仅背景的刺激版本上表现接近随机水平，而人类在所有版本上均表现良好。新型架构不仅提高了动作识别性能，其准确性模式也更接近人类。

Conclusion: 构建具有独立处理身体和背景信息流的大脑启发式深度网络架构，可以提高动作识别性能，并使其准确性模式更接近人类表现。

Abstract: Action recognition is also key for applications ranging from robotics to healthcare monitoring. Action information can be extracted from the body pose and movements, as well as from the background scene. However, the extent to which deep neural networks (DNNs) make use of information about the body and information about the background remains unclear. Since these two sources of information may be correlated within a training dataset, DNNs might learn to rely predominantly on one of them, without taking full advantage of the other. Unlike DNNs, humans have domain-specific brain regions selective for perceiving bodies, and regions selective for perceiving scenes. The present work tests whether humans are thus more effective at extracting information from both body and background, and whether building brain-inspired deep network architectures with separate domain-specific streams for body and scene perception endows them with more human-like performance. We first demonstrate that DNNs trained using the HAA500 dataset perform almost as accurately on versions of the stimuli that show both body and background and on versions of the stimuli from which the body was removed, but are at chance-level for versions of the stimuli from which the background was removed. Conversely, human participants (N=28) can recognize the same set of actions accurately with all three versions of the stimuli, and perform significantly better on stimuli that show only the body than on stimuli that show only the background. Finally, we implement and test a novel architecture patterned after domain specificity in the brain with separate streams to process body and background information. We show that 1) this architecture improves action recognition performance, and 2) its accuracy across different versions of the stimuli follows a pattern that matches more closely the pattern of accuracy observed in human participants.

</details>


### [145] [Evaluating and Preserving High-level Fidelity in Super-Resolution](https://arxiv.org/abs/2512.07037)
*Josep M. Rocafort,Shaolin Su,Javier Vazquez-Corral,Alexandra Gomez-Villa*

Main category: cs.CV

TL;DR: 该论文提出了衡量SR模型高层保真度的重要性，构建了首个相关数据集，并展示了如何通过保真度反馈优化模型，提升语义和感知质量。


<details>
  <summary>Details</summary>
Motivation: 尽管现有SR模型在重建细节和视觉输出上表现优异，但其强大的生成能力有时会导致图像内容失真，这种高层变化容易被人类识别但现有低层图像质量指标未充分研究。

Method: 构建了首个带有保真度分数的标注数据集，评估了SOTA SR模型在保持高层保真度方面的表现，并分析了现有图像质量指标与保真度测量的相关性。

Result: 研究发现，高层任务可以通过基础模型更好地解决，且通过保真度反馈微调SR模型可以同时提升语义保真度和感知质量。

Conclusion: 通过微调SR模型基于保真度反馈，可以同时提高语义保真度和感知质量，证明了所提标准在模型评估和优化中的潜在价值。

Abstract: Recent image Super-Resolution (SR) models are achieving impressive effects in reconstructing details and delivering visually pleasant outputs. However, the overpowering generative ability can sometimes hallucinate and thus change the image content despite gaining high visual quality. This type of high-level change can be easily identified by humans yet not well-studied in existing low-level image quality metrics. In this paper, we establish the importance of measuring high-level fidelity for SR models as a complementary criterion to reveal the reliability of generative SR models. We construct the first annotated dataset with fidelity scores from different SR models, and evaluate how state-of-the-art (SOTA) SR models actually perform in preserving high-level fidelity. Based on the dataset, we then analyze how existing image quality metrics correlate with fidelity measurement, and further show that this high-level task can be better addressed by foundation models. Finally, by fine-tuning SR models based on our fidelity feedback, we show that both semantic fidelity and perceptual quality can be improved, demonstrating the potential value of our proposed criteria, both in model evaluation and optimization. We will release the dataset, code, and models upon acceptance.

</details>


### [146] [SAVE: Sparse Autoencoder-Driven Visual Information Enhancement for Mitigating Object Hallucination](https://arxiv.org/abs/2512.07730)
*Sangha Park,Seungryong Yoo,Jisoo Mok,Sungroh Yoon*

Main category: cs.CV

TL;DR: SAVE框架通过SAE潜在特征引导减少MLLMs的物体幻觉，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决多模态大语言模型（MLLMs）中由语言先验和视觉信息丢失引起的物体幻觉问题。

Method: 提出SAVE框架，利用稀疏自编码器（SAE）潜在特征引导模型，通过二元物体存在问答探针识别视觉理解特征，并沿这些特征引导模型。

Result: 在CHAIR_S、POPE和MMHal-Bench等基准测试中，SAVE优于现有免训练方法，CHAIR_S指标提升10%。

Conclusion: SAVE框架通过稀疏自编码器（SAE）潜在特征引导，有效减少了多模态大语言模型（MLLMs）中的物体幻觉问题，并在多个基准测试中表现出色。

Abstract: Although Multimodal Large Language Models (MLLMs) have advanced substantially, they remain vulnerable to object hallucination caused by language priors and visual information loss. To address this, we propose SAVE (Sparse Autoencoder-Driven Visual Information Enhancement), a framework that mitigates hallucination by steering the model along Sparse Autoencoder (SAE) latent features. A binary object-presence question-answering probe identifies the SAE features most indicative of the model's visual information processing, referred to as visual understanding features. Steering the model along these identified features reinforces grounded visual understanding and effectively reduces hallucination. With its simple design, SAVE outperforms state-of-the-art training-free methods on standard benchmarks, achieving a 10\%p improvement in CHAIR\_S and consistent gains on POPE and MMHal-Bench. Extensive evaluations across multiple models and layers confirm the robustness and generalizability of our approach. Further analysis reveals that steering along visual understanding features suppresses the generation of uncertain object tokens and increases attention to image tokens, mitigating hallucination. Code is released at https://github.com/wiarae/SAVE.

</details>


### [147] [RAVE: Rate-Adaptive Visual Encoding for 3D Gaussian Splatting](https://arxiv.org/abs/2512.07052)
*Hoang-Nhat Tran,Francesco Di Sario,Gabriele Spadaro,Giuseppe Valenzise,Enzo Tartaglione*

Main category: cs.CV

TL;DR: 提出了一种灵活的3DGS压缩方案，支持任意速率插值，无需重新训练，适用于沉浸式应用。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅（3DGS）虽然实现了实时逼真渲染，但存在内存需求大和训练成本高的问题，现有压缩方法仅支持固定速率，缺乏适应性。

Method: 提出了一种轻量级的灵活压缩方案，支持在预定义边界内的任意速率插值，无需重新训练。

Result: 实验表明，该方法实现了高效、高质量的压缩，同时提供动态速率控制。

Conclusion: 提出的灵活压缩方案支持在预定义边界内的任意速率插值，无需重新训练，保持了广泛的渲染质量范围，适合实际沉浸式应用部署。

Abstract: Recent advances in neural scene representations have transformed immersive multimedia, with 3D Gaussian Splatting (3DGS) enabling real-time photorealistic rendering. Despite its efficiency, 3DGS suffers from large memory requirements and costly training procedures, motivating efforts toward compression. Existing approaches, however, operate at fixed rates, limiting adaptability to varying bandwidth and device constraints. In this work, we propose a flexible compression scheme for 3DGS that supports interpolation at any rate between predefined bounds. Our method is computationally lightweight, requires no retraining for any rate, and preserves rendering quality across a broad range of operating points. Experiments demonstrate that the approach achieves efficient, high-quality compression while offering dynamic rate control, making it suitable for practical deployment in immersive applications. The code will be provided open-source upon acceptance of the work.

</details>


### [148] [WorldReel: 4D Video Generation with Consistent Geometry and Motion Modeling](https://arxiv.org/abs/2512.07821)
*Shaoheng Fang,Hanwen Jiang,Yunpeng Bai,Niloy J. Mitra,Qixing Huang*

Main category: cs.CV

TL;DR: WorldReel是一种4D视频生成器，通过联合生成RGB帧与4D场景表示，实现了时空一致的视频生成，结合合成与真实数据训练，显著提升了动态场景下的生成质量。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成器在3D一致性上存在根本性不足，WorldReel旨在实现原生时空一致的4D视频生成，推动视频生成向4D一致的世界建模迈进。

Method: WorldReel联合生成RGB帧与4D场景表示（包括点云图、相机轨迹和密集流映射），通过显式4D表示强制单一底层场景在不同视角和动态内容中保持一致。

Result: WorldReel在动态场景和移动相机下的视频生成中，几何一致性、运动连贯性等指标优于现有方法，减少了视觉时间伪影。

Conclusion: WorldReel通过结合合成和真实数据训练，实现了动态场景和移动相机下的4D一致性视频生成，显著提升了几何一致性、运动连贯性，并减少了视觉时间伪影，为视频生成领域设定了新的技术标准。

Abstract: Recent video generators achieve striking photorealism, yet remain fundamentally inconsistent in 3D. We present WorldReel, a 4D video generator that is natively spatio-temporally consistent. WorldReel jointly produces RGB frames together with 4D scene representations, including pointmaps, camera trajectory, and dense flow mapping, enabling coherent geometry and appearance modeling over time. Our explicit 4D representation enforces a single underlying scene that persists across viewpoints and dynamic content, yielding videos that remain consistent even under large non-rigid motion and significant camera movement. We train WorldReel by carefully combining synthetic and real data: synthetic data providing precise 4D supervision (geometry, motion, and camera), while real videos contribute visual diversity and realism. This blend allows WorldReel to generalize to in-the-wild footage while preserving strong geometric fidelity. Extensive experiments demonstrate that WorldReel sets a new state-of-the-art for consistent video generation with dynamic scenes and moving cameras, improving metrics of geometric consistency, motion coherence, and reducing view-time artifacts over competing methods. We believe that WorldReel brings video generation closer to 4D-consistent world modeling, where agents can render, interact, and reason about scenes through a single and stable spatiotemporal representation.

</details>


### [149] [One Layer Is Enough: Adapting Pretrained Visual Encoders for Image Generation](https://arxiv.org/abs/2512.07829)
*Yuan Gao,Chen Chen,Tianrong Chen,Jiatao Gu*

Main category: cs.CV

TL;DR: FAE是一种简单框架，通过耦合两个解码器将预训练视觉表征适配到生成友好的潜在空间中，在多个生成任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉生成模型在压缩潜在空间中操作，以平衡训练效率和样本质量。然而，将高质量预训练视觉表征适配到生成友好的潜在空间中仍具有挑战性，因为理解导向的特征和生成友好的潜在空间之间存在根本性不匹配。

Method: FAE通过耦合两个独立的深度解码器：一个用于重建原始特征空间，另一个用于图像生成。该方法可以实例化为多种自监督编码器（如DINO、SigLIP），并适用于扩散模型和归一化流两种生成模型家族。

Result: 在类条件和文本到图像的基准测试中，FAE表现出色。例如，在ImageNet 256x256上，使用CFG的扩散模型达到了接近最先进的FID（1.29，800 epochs）和1.70（80 epochs）。不使用CFG时，FAE达到了最先进的FID（1.48，800 epochs）和2.08（80 epochs）。

Conclusion: FAE（Feature Auto-Encoder）是一种简单而有效的框架，能够将预训练的视觉表征适配到适合生成的低维潜在空间中，同时保留足够的信息用于重建和理解。它在多个生成模型家族中表现优异，实现了高质量和快速学习。

Abstract: Visual generative models (e.g., diffusion models) typically operate in compressed latent spaces to balance training efficiency and sample quality. In parallel, there has been growing interest in leveraging high-quality pre-trained visual representations, either by aligning them inside VAEs or directly within the generative model. However, adapting such representations remains challenging due to fundamental mismatches between understanding-oriented features and generation-friendly latent spaces. Representation encoders benefit from high-dimensional latents that capture diverse hypotheses for masked regions, whereas generative models favor low-dimensional latents that must faithfully preserve injected noise. This discrepancy has led prior work to rely on complex objectives and architectures. In this work, we propose FAE (Feature Auto-Encoder), a simple yet effective framework that adapts pre-trained visual representations into low-dimensional latents suitable for generation using as little as a single attention layer, while retaining sufficient information for both reconstruction and understanding. The key is to couple two separate deep decoders: one trained to reconstruct the original feature space, and a second that takes the reconstructed features as input for image generation. FAE is generic; it can be instantiated with a variety of self-supervised encoders (e.g., DINO, SigLIP) and plugged into two distinct generative families: diffusion models and normalizing flows. Across class-conditional and text-to-image benchmarks, FAE achieves strong performance. For example, on ImageNet 256x256, our diffusion model with CFG attains a near state-of-the-art FID of 1.29 (800 epochs) and 1.70 (80 epochs). Without CFG, FAE reaches the state-of-the-art FID of 1.48 (800 epochs) and 2.08 (80 epochs), demonstrating both high quality and fast learning.

</details>


### [150] [Persistent Homology-Guided Frequency Filtering for Image Compression](https://arxiv.org/abs/2512.07065)
*Anil Chintapalli,Peter Tenholder,Henry Chen,Arjun Rao*

Main category: cs.CV

TL;DR: 提出一种结合离散傅里叶变换和持久同调分析的方法，用于噪声图像的特征提取与压缩，实验显示其压缩效果与JPEG相当，并可能提升分类任务性能。


<details>
  <summary>Details</summary>
Motivation: 解决噪声图像数据集中特征提取的可靠性问题，提升模型性能。

Method: 结合离散傅里叶变换和持久同调分析，提取与图像拓扑特征对应的特定频率，实现图像压缩与重构。

Result: 实验结果表明，该方法在六种不同指标下的压缩水平与JPEG相当，并能有效区分有意义的数据。

Conclusion: 通过持久同调引导的频率过滤方法，在噪声条件下提高了图像压缩的可靠性，并展示了在二进制分类任务中增强卷积神经网络性能的潜力。

Abstract: Feature extraction in noisy image datasets presents many challenges in model reliability. In this paper, we use the discrete Fourier transform in conjunction with persistent homology analysis to extract specific frequencies that correspond with certain topological features of an image. This method allows the image to be compressed and reformed while ensuring that meaningful data can be differentiated. Our experimental results show a level of compression comparable to that of using JPEG using six different metrics. The end goal of persistent homology-guided frequency filtration is its potential to improve performance in binary classification tasks (when augmenting a Convolutional Neural Network) compared to traditional feature extraction and compression methods. These findings highlight a useful end result: enhancing the reliability of image compression under noisy conditions.

</details>


### [151] [Relational Visual Similarity](https://arxiv.org/abs/2512.07833)
*Thao Nguyen,Sicheng Mo,Krishna Kumar Singh,Yilin Wang,Jing Shi,Nicholas Kolkin,Eli Shechtman,Yong Jae Lee,Yuheng Li*

Main category: cs.CV

TL;DR: 研究提出关系相似性度量方法，通过匿名标题数据集微调视觉-语言模型，揭示现有模型在捕捉人类感知关系相似性上的不足。


<details>
  <summary>Details</summary>
Motivation: 探索如何超越图像的可见内容捕捉其关系属性，并将具有相同关系逻辑的图像在表示空间中拉近。

Method: 首先将关系图像相似性定义为可测量问题，随后构建包含11.4万张图像-匿名标题的数据集，标题描述场景的底层关系逻辑而非表面内容。利用该数据集微调视觉-语言模型以测量图像间的关系相似性。

Result: 开发了首个基于底层关系结构而非可见外观连接图像的模型，证明关系相似性具有广泛实际应用，但现有模型无法捕捉。

Conclusion: 现有视觉相似性模型（如LPIPS、CLIP、DINO）仅关注感知属性相似性，未能捕捉人类感知的丰富关系相似性。通过构建关系相似性度量模型，本研究揭示了视觉计算中的关键差距。

Abstract: Humans do not just see attribute similarity -- we also see relational similarity. An apple is like a peach because both are reddish fruit, but the Earth is also like a peach: its crust, mantle, and core correspond to the peach's skin, flesh, and pit. This ability to perceive and recognize relational similarity, is arguable by cognitive scientist to be what distinguishes humans from other species. Yet, all widely used visual similarity metrics today (e.g., LPIPS, CLIP, DINO) focus solely on perceptual attribute similarity and fail to capture the rich, often surprising relational similarities that humans perceive. How can we go beyond the visible content of an image to capture its relational properties? How can we bring images with the same relational logic closer together in representation space? To answer these questions, we first formulate relational image similarity as a measurable problem: two images are relationally similar when their internal relations or functions among visual elements correspond, even if their visual attributes differ. We then curate 114k image-caption dataset in which the captions are anonymized -- describing the underlying relational logic of the scene rather than its surface content. Using this dataset, we finetune a Vision-Language model to measure the relational similarity between images. This model serves as the first step toward connecting images by their underlying relational structure rather than their visible appearance. Our study shows that while relational similarity has a lot of real-world applications, existing image similarity models fail to capture it -- revealing a critical gap in visual computing.

</details>


### [152] [Context-measure: Contextualizing Metric for Camouflage](https://arxiv.org/abs/2512.07076)
*Chen-Yang Wang,Gepeng Ji,Song Shao,Ming-Ming Cheng,Deng-Ping Fan*

Main category: cs.CV

TL;DR: 提出Context-measure评估范式，通过空间依赖性和像素级量化改进伪装场景评估，实验证明其优于现有指标。


<details>
  <summary>Details</summary>
Motivation: 现有伪装场景评估指标忽视了上下文依赖性这一关键因素，且最初设计用于评估一般或显著对象，假设空间上下文不相关，无法准确反映人类感知。

Method: 提出了一种基于概率像素感知相关框架的Context-measure评估范式，通过整合空间依赖性和像素级伪装量化来评估伪装场景。

Result: 在三个具有挑战性的伪装对象分割数据集上的广泛实验表明，Context-measure比现有上下文无关指标更可靠。

Conclusion: Context-measure作为一种新的评估范式，通过结合空间依赖性和像素级伪装量化，提供了比现有上下文无关指标更可靠的评估结果，适用于农业、工业和医疗等多种计算机视觉应用。

Abstract: Camouflage is primarily context-dependent yet current metrics for camouflaged scenarios overlook this critical factor. Instead, these metrics are originally designed for evaluating general or salient objects, with an inherent assumption of uncorrelated spatial context. In this paper, we propose a new contextualized evaluation paradigm, Context-measure, built upon a probabilistic pixel-aware correlation framework. By incorporating spatial dependencies and pixel-wise camouflage quantification, our measure better aligns with human perception. Extensive experiments across three challenging camouflaged object segmentation datasets show that Context-measure delivers more reliability than existing context-independent metrics. Our measure can provide a foundational evaluation benchmark for various computer vision applications involving camouflaged patterns, such as agricultural, industrial, and medical scenarios. Code is available at https://github.com/pursuitxi/Context-measure.

</details>


### [153] [DFIR-DETR: Frequency Domain Enhancement and Dynamic Feature Aggregation for Cross-Scene Small Object Detection](https://arxiv.org/abs/2512.07078)
*Bo Gao,Jingcheng Tong,Xingsheng Chen,Han Yu,Zichen Li*

Main category: cs.CV

TL;DR: DFIR-DETR通过动态特征聚合和频率域处理，解决了小目标检测中的特征退化、长距离依赖和特征膨胀问题，在NEU-DET和VisDrone数据集上达到SOTA性能，且模型轻量。


<details>
  <summary>Details</summary>
Motivation: 无人机遥感图像中的小目标检测和工业检测中的表面缺陷识别面临特征稀疏、背景杂乱和尺度变化大的挑战，现有基于Transformer的检测器存在特征退化、长距离依赖不足和特征膨胀问题。

Method: DFIR-DETR通过动态特征聚合（DCFA模块）、频率域处理（FIRC3模块）和防止特征膨胀的振幅归一化上采样（DFPN模块）来解决特征退化、长距离依赖和特征膨胀问题。

Result: 在NEU-DET和VisDrone数据集上，DFIR-DETR的mAP50分别达到92.9%和51.6%，性能领先且模型轻量。

Conclusion: DFIR-DETR在NEU-DET和VisDrone数据集上表现出色，mAP50分别达到92.9%和51.6%，且模型轻量（11.7M参数，41.2 GFLOPs），适用于资源有限的小目标检测场景。

Abstract: Detecting small objects in UAV remote sensing images and identifying surface defects in industrial inspection remain difficult tasks. These applications face common obstacles: features are sparse and weak, backgrounds are cluttered, and object scales vary dramatically. Current transformer-based detectors, while powerful, struggle with three critical issues. First, features degrade severely as networks downsample progressively. Second, spatial convolutions cannot capture long-range dependencies effectively. Third, standard upsampling methods inflate feature maps unnecessarily.
  We introduce DFIR-DETR to tackle these problems through dynamic feature aggregation combined with frequency-domain processing. Our architecture builds on three novel components. The DCFA module uses dynamic K-sparse attention, cutting complexity from O(N2) down to O(NK), and employs spatial gated linear units for better nonlinear modeling. The DFPN module applies amplitude-normalized upsampling to prevent feature inflation and uses dual-path shuffle convolution to retain spatial details across scales. The FIRC3 module operates in the frequency domain, achieving global receptive fields without sacrificing efficiency.
  We tested our method extensively on NEU-DET and VisDrone datasets. Results show mAP50 scores of 92.9% and 51.6% respectively-both state-of-the-art. The model stays lightweight with just 11.7M parameters and 41.2 GFLOPs. Strong performance across two very different domains confirms that DFIR-DETR generalizes well and works effectively in resource-limited settings for cross-scene small object detection.

</details>


### [154] [COREA: Coarse-to-Fine 3D Representation Alignment Between Relightable 3D Gaussians and SDF via Bidirectional 3D-to-3D Supervision](https://arxiv.org/abs/2512.07107)
*Jaeyoon Lee,Hojoon Jung,Sungtae Hwang,Jihyong Oh,Jongwon Choi*

Main category: cs.CV

TL;DR: COREA 是首个联合学习可重光照 3D 高斯和有符号距离场（SDF）的统一框架，通过 3D 到 3D 对齐策略和密度控制，实现了精确几何重建和稳定 BRDF-光照分解。


<details>
  <summary>Details</summary>
Motivation: 现有的 3D 高斯泼溅（3DGS）方法虽然扩展到网格重建和基于物理的渲染（PBR），但其几何仍从 2D 渲染中学习，导致表面粗糙和 BRDF-光照分解不可靠。COREA 旨在解决这些限制。

Method: COREA 采用了一种从粗到细的双向 3D 到 3D 对齐策略，允许几何信号直接在 3D 空间中学习。深度提供两种表示之间的粗略对齐，而深度梯度和法线则细化精细结构。此外，密度控制机制稳定了高斯增长，平衡了几何保真度和内存效率。

Result: 在标准基准测试中，COREA 在统一框架内实现了新颖视角合成、网格重建和 PBR 的卓越性能。

Conclusion: COREA 在统一框架内实现了新颖视角合成、网格重建和基于物理的渲染（PBR）的卓越性能。

Abstract: We present COREA, the first unified framework that jointly learns relightable 3D Gaussians and a Signed Distance Field (SDF) for accurate geometry reconstruction and faithful relighting. While recent 3D Gaussian Splatting (3DGS) methods have extended toward mesh reconstruction and physically-based rendering (PBR), their geometry is still learned from 2D renderings, leading to coarse surfaces and unreliable BRDF-lighting decomposition. To address these limitations, COREA introduces a coarse-to-fine bidirectional 3D-to-3D alignment strategy that allows geometric signals to be learned directly in 3D space. Within this strategy, depth provides coarse alignment between the two representations, while depth gradients and normals refine fine-scale structure, and the resulting geometry supports stable BRDF-lighting decomposition. A density-control mechanism further stabilizes Gaussian growth, balancing geometric fidelity with memory efficiency. Experiments on standard benchmarks demonstrate that COREA achieves superior performance in novel-view synthesis, mesh reconstruction, and PBR within a unified framework.

</details>


### [155] [MSN: Multi-directional Similarity Network for Hand-crafted and Deep-synthesized Copy-Move Forgery Detection](https://arxiv.org/abs/2512.07110)
*Liangwei Jiang,Jinluo Xie,Yecheng Huang,Hua Zhang,Hongyu Yang,Di Huang*

Main category: cs.CV

TL;DR: 本文提出多方向相似性网络（MSN），通过层次化编码和2-D相似性矩阵解码器，显著提升复制-移动伪造检测的表示和定位能力，并在多个基准测试中取得最优结果。


<details>
  <summary>Details</summary>
Motivation: 复制-移动图像伪造通过复杂变换和精细操作使检测变得极具挑战性，现有深度检测模型在表示和定位方面存在局限，亟需一种更高效准确的检测方法。

Method: 提出了一种新颖的双流模型——多方向相似性网络（MSN），通过多方向CNN网络对图像进行层次化编码，并设计了基于2-D相似性矩阵的解码器，以充分利用空间信息。

Result: 在CASIA CMFD、CoMoFoD及新提出的基准测试中，MSN取得了最先进的结果，证明了其有效性。

Conclusion: 论文提出的多方向相似性网络（MSN）在复制-移动伪造检测中表现出色，通过层次化编码和2-D相似性矩阵解码器，显著提升了表示和定位能力，并在多个基准测试中取得了最先进的结果。

Abstract: Copy-move image forgery aims to duplicate certain objects or to hide specific contents with copy-move operations, which can be achieved by a sequence of manual manipulations as well as up-to-date deep generative network-based swapping. Its detection is becoming increasingly challenging for the complex transformations and fine-tuned operations on the tampered regions. In this paper, we propose a novel two-stream model, namely Multi-directional Similarity Network (MSN), to accurate and efficient copy-move forgery detection. It addresses the two major limitations of existing deep detection models in \textbf{representation} and \textbf{localization}, respectively. In representation, an image is hierarchically encoded by a multi-directional CNN network, and due to the diverse augmentation in scales and rotations, the feature achieved better measures the similarity between sampled patches in two streams. In localization, we design a 2-D similarity matrix based decoder, and compared with the current 1-D similarity vector based one, it makes full use of spatial information in the entire image, leading to the improvement in detecting tampered regions. Beyond the method, a new forgery database generated by various deep neural networks is presented, as a new benchmark for detecting the growing deep-synthesized copy-move. Extensive experiments are conducted on two classic image forensics benchmarks, \emph{i.e.} CASIA CMFD and CoMoFoD, and the newly presented one. The state-of-the-art results are reported, which demonstrate the effectiveness of the proposed approach.

</details>


### [156] [Training-free Clothing Region of Interest Self-correction for Virtual Try-On](https://arxiv.org/abs/2512.07126)
*Shengjie Lu,Zhibin Wan,Jiejie Liu,Quan Zhang,Mingjie Sun*

Main category: cs.CV

TL;DR: 提出能量函数约束注意力图以改善VTON任务中服装细节生成，并设计新指标VTID；实验显示其在多项指标上超越SOTA，且提升了下游CC-Reid任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成服装的细节（如图案、纹理、边界）与目标服装存在差异，且评估指标仅关注图像真实性而忽略与目标元素的对齐。

Method: 提出使用能量函数约束生成过程中的注意力图，确保每一步生成更聚焦于目标服装区域，并设计了新的评估指标VTID以全面评估生成结果。

Result: 在VITON-HD和DressCode数据集上，新方法在LPIPS、FID、KID和VTID指标上分别提升了1.4%、2.3%、12.3%和5.8%；在下游CC-Reid任务中，LTCC、PRCC、VC-Clothes数据集的Rank-1指标分别提升了2.5%、1.1%和1.6%。

Conclusion: 通过在生成过程中引入能量函数约束注意力图，并提出新的评估指标VTID，该方法在VTON任务中显著提升了生成服装的细节一致性和评估的全面性，同时在下游任务CC-Reid中也取得了性能提升。

Abstract: VTON (Virtual Try-ON) aims at synthesizing the target clothing on a certain person, preserving the details of the target clothing while keeping the rest of the person unchanged. Existing methods suffer from the discrepancies between the generated clothing results and the target ones, in terms of the patterns, textures and boundaries. Therefore, we propose to use an energy function to impose constraints on the attention map extracted through the generation process. Thus, at each generation step, the attention can be more focused on the clothing region of interest, thereby influencing the generation results to be more consistent with the target clothing details. Furthermore, to address the limitation that existing evaluation metrics concentrate solely on image realism and overlook the alignment with target elements, we design a new metric, Virtual Try-on Inception Distance (VTID), to bridge this gap and ensure a more comprehensive assessment. On the VITON-HD and DressCode datasets, our approach has outperformed the previous state-of-the-art (SOTA) methods by 1.4%, 2.3%, 12.3%, and 5.8% in the traditional metrics of LPIPS, FID, KID, and the new VTID metrics, respectively. Additionally, by applying the generated data to downstream Clothing-Change Re-identification (CC-Reid) methods, we have achieved performance improvements of 2.5%, 1.1%, and 1.6% on the LTCC, PRCC, VC-Clothes datasets in the metrics of Rank-1. The code of our method is public at https://github.com/MrWhiteSmall/CSC-VTON.git.

</details>


### [157] [MulCLIP: A Multi-level Alignment Framework for Enhancing Fine-grained Long-context CLIP](https://arxiv.org/abs/2512.07128)
*Chau Truong,Hieu Ta Quang,Dung D. Le*

Main category: cs.CV

TL;DR: MulCLIP通过多级对齐（全局+局部）解决长文本-图像对齐问题，优于区域提议方法且更高效。


<details>
  <summary>Details</summary>
Motivation: 现有视觉-语言模型（如CLIP）因训练数据简短而难以处理长文本描述，且区域提议方法部署成本高。

Method: MulCLIP采用端到端多级对齐框架，包括全局对比对齐（图像与摘要/长描述）、扩展位置编码，以及两种新策略：局部校准特征的词-图像块语义重建对齐，和子描述聚合的块对齐。

Result: 实验表明MulCLIP在多基准测试中性能提升，消融研究验证其多尺度对齐是关键优势。

Conclusion: MulCLIP通过多级对齐框架显著提升了细粒度视觉-语言对齐能力，优于基于区域提议的方法，适用于多样化现实应用。

Abstract: Vision-language models like CLIP show impressive ability to align images and text, but their training on short, concise captions makes them struggle with lengthy, detailed descriptions. Recent advances mitigate this challenge by leveraging region-proposal information to map visual regions with corresponding sentences from lengthy captions, yet incurring notable deployment costs. We introduce MulCLIP, a novel end-to-end multi-level alignment framework that bridges natural long-text structures with image components. MulCLIP first preserves global contrastive alignment between images and both summary and long captions, while extending positional embeddings for longer text sequences. To further enhance fine-grained understanding, we propose two novel strategies: (1) a token reconstruction alignment over locally calibrated features to strengthen semantic connections between words and image patches, and (2) a subcaption-aggregated patch alignment that automatically extracts and aggregates context-rich patches for each subcaption. Experimental results across diverse benchmarks demonstrate our method consistently improves downstream performance, while ablation studies confirm its multi-scale alignment is the key factor driving better fine-grained capability than region-proposal-assisted approaches, making it particularly suitable for diverse real-world applications.

</details>


### [158] [Think-Reflect-Revise: A Policy-Guided Reflective Framework for Safety Alignment in Large Vision Language Models](https://arxiv.org/abs/2512.07141)
*Fenghua Weng,Chaochao Lu,Xia Hu,Wenqi Shao,Wenjie Wang*

Main category: cs.CV

TL;DR: TRR框架通过三阶段训练（数据构建、微调、强化学习）提升LVLMs安全性，安全响应率显著提高且通用性能稳定。


<details>
  <summary>Details</summary>
Motivation: 单次推理范式容易忽略自身输出中的显性有害内容，通过反射利用首次推理中暴露的恶意内容实现真正的自我修正。

Method: 提出Think-Reflect-Revise（TRR）三阶段训练框架，包括构建Reflective Safety Reasoning（ReSafe）数据集、微调目标模型以初始化反射行为，以及通过强化学习强化策略引导的反射。

Result: TRR将Qwen2.5-VL-7B的安全响应率从42.8%提升至87.7%，同时在MMMU和MMStar等通用基准测试中保持稳定表现。

Conclusion: TRR框架显著提升了大型视觉语言模型（LVLMs）的安全性表现，在安全意识和越狱攻击评估中均取得显著改进，同时保持通用基准测试的稳定性能。

Abstract: As multimodal reasoning improves the overall capabilities of Large Vision Language Models (LVLMs), recent studies have begun to explore safety-oriented reasoning, aiming to enhance safety awareness by analyzing potential safety risks during the reasoning process before generating the final response. Although such approaches improve safety awareness and interpretability, this single-pass think-then-answer paradigm remains vulnerable to contextual or visual jailbreak attacks. This reveals a critical flaw: single-pass reasoning may overlook explicit harmful content in its own output. Our key insight is to exploit this wasted signal through reflection, which can effectively leverage the malicious content revealed in the first-pass reasoning to enable genuine self-correction and prevent unsafe generations. Motivated by this, we propose Think-Reflect-Revise (TRR), a three-stage training framework designed to enhance the safety alignment of LVLMs through policy-guided self-reflection. We first build a Reflective Safety Reasoning (ReSafe) dataset with 5,000 examples that follow a think-reflect-revise process. We then fine-tune the target model using the ReSafe dataset to initialize reflective behavior, and finally reinforce policy-guided reflection through reinforcement learning. Experimental results show that TRR substantially improves the safety performance of LVLMs across both safety-awareness benchmarks and jailbreak attack evaluations, increasing the overall safe response rate from 42.8% to 87.7% on Qwen2.5-VL-7B, while preserving stable performance on general benchmarks such as MMMU and MMStar. The project page is available at https://think-reflect-revise.github.io/.

</details>


### [159] [CHIMERA: Adaptive Cache Injection and Semantic Anchor Prompting for Zero-shot Image Morphing with Morphing-oriented Metrics](https://arxiv.org/abs/2512.07155)
*Dahyeon Kye,Jeahun Sung,MinKyu Jeon,Jihyong Oh*

Main category: cs.CV

TL;DR: CHIMERA是一种零样本扩散框架，通过自适应缓存注入和语义锚点提示，解决了图像变形中的平滑和语义一致性问题，成为新标杆。


<details>
  <summary>Details</summary>
Motivation: 现有方法在图像变形中常产生突兀的过渡或过饱和的外观，缺乏自适应的结构和语义对齐，因此需要一种更高效的解决方案。

Method: CHIMERA采用缓存反转引导的去噪过程，结合自适应缓存注入（ACI）和语义锚点提示（SAP），实现了深度和时间自适应的空间与语义对齐。

Result: 实验和用户研究表明，CHIMERA在图像变形中实现了比现有方法更平滑、语义更一致的过渡，确立了新的技术标杆。

Conclusion: CHIMERA通过其创新的零样本扩散框架，结合自适应缓存注入和语义锚点提示，显著提升了图像变形中的平滑度和语义一致性，成为图像变形领域的新标杆。

Abstract: Diffusion models exhibit remarkable generative ability, yet achieving smooth and semantically consistent image morphing remains a challenge. Existing approaches often yield abrupt transitions or over-saturated appearances due to the lack of adaptive structural and semantic alignments. We propose CHIMERA, a zero-shot diffusion-based framework that formulates morphing as a cached inversion-guided denoising process. To handle large semantic and appearance disparities, we propose Adaptive Cache Injection and Semantic Anchor Prompting. Adaptive Cache Injection (ACI) caches down, mid, and up blocks features from both inputs during DDIM inversion and re-injects them adaptively during denoising, enabling spatial and semantic alignment in depth- and time-adaptive manners and enabling natural feature fusion and smooth transitions. Semantic Anchor Prompting (SAP) leverages a vision-language model to generate a shared anchor prompt that serves as a semantic anchor, bridging dissimilar inputs and guiding the denoising process toward coherent results. Finally, we introduce the Global-Local Consistency Score (GLCS), a morphing-oriented metric that simultaneously evaluates the global harmonization of the two inputs and the smoothness of the local morphing transition. Extensive experiments and user studies show that CHIMERA achieves smoother and more semantically aligned transitions than existing methods, establishing a new state of the art in image morphing. The code and project page will be publicly released.

</details>


### [160] [MuSASplat: Efficient Sparse-View 3D Gaussian Splats via Lightweight Multi-Scale Adaptation](https://arxiv.org/abs/2512.07165)
*Muyu Xu,Fangneng Zhan,Xiaoqin Zhang,Ling Shao,Shijian Lu*

Main category: cs.CV

TL;DR: MuSASplat通过轻量级适配器和特征融合聚合器，高效训练3D高斯泼溅模型，降低资源消耗且保持高质量渲染。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法因完全微调大型ViT主干网络而导致的GPU成本高昂问题。

Method: 采用轻量级多尺度适配器高效微调ViT架构，并引入特征融合聚合器有效整合多视角特征。

Result: 在多个数据集上实现了最先进的渲染质量，同时大幅减少参数和训练资源需求。

Conclusion: MuSASplat通过轻量级多尺度适配器和特征融合聚合器，显著降低了训练资源需求，同时保持了高质量的新视角合成效果。

Abstract: Sparse-view 3D Gaussian splatting seeks to render high-quality novel views of 3D scenes from a limited set of input images. While recent pose-free feed-forward methods leveraging pre-trained 3D priors have achieved impressive results, most of them rely on full fine-tuning of large Vision Transformer (ViT) backbones and incur substantial GPU costs. In this work, we introduce MuSASplat, a novel framework that dramatically reduces the computational burden of training pose-free feed-forward 3D Gaussian splats models with little compromise of rendering quality. Central to our approach is a lightweight Multi-Scale Adapter that enables efficient fine-tuning of ViT-based architectures with only a small fraction of training parameters. This design avoids the prohibitive GPU overhead associated with previous full-model adaptation techniques while maintaining high fidelity in novel view synthesis, even with very sparse input views. In addition, we introduce a Feature Fusion Aggregator that integrates features across input views effectively and efficiently. Unlike widely adopted memory banks, the Feature Fusion Aggregator ensures consistent geometric integration across input views and meanwhile mitigates the memory usage, training complexity, and computational costs significantly. Extensive experiments across diverse datasets show that MuSASplat achieves state-of-the-art rendering quality but has significantly reduced parameters and training resource requirements as compared with existing methods.

</details>


### [161] [When Privacy Meets Recovery: The Overlooked Half of Surrogate-Driven Privacy Preservation for MLLM Editing](https://arxiv.org/abs/2512.07166)
*Siyuan Xu,Yibing Liu,Peilin Chen,Yung-Hui Li,Shiqi Wang,Sam Kwong*

Main category: cs.CV

TL;DR: 该论文提出SPPE数据集和统一隐私恢复方法，有效平衡MLLM中的隐私保护与模型可用性。


<details>
  <summary>Details</summary>
Motivation: 解决现有研究在评估用户隐私的真实性和恢复质量方面的不足，专注于恢复多样化MLLM场景中的代理驱动保护数据。

Method: 通过将隐私恢复任务制定为基于互补多模态信号的引导生成任务，提出了一种可靠重建隐私内容并保留MLLM生成编辑保真度的统一方法。

Result: 实验表明，该方法在SPPE和InstructPix2Pix数据集上均表现良好，能够平衡隐私保护与MLLM的可用性。

Conclusion: 该研究通过提出SPPE数据集和一种统一的隐私恢复方法，在多模态大语言模型（MLLMs）中实现了隐私保护与模型可用性之间的平衡。

Abstract: Privacy leakage in Multimodal Large Language Models (MLLMs) has long been an intractable problem. Existing studies, though effectively obscure private information in MLLMs, often overlook the evaluation of the authenticity and recovery quality of user privacy. To this end, this work uniquely focuses on the critical challenge of how to restore surrogate-driven protected data in diverse MLLM scenarios. We first bridge this research gap by contributing the SPPE (Surrogate Privacy Protected Editable) dataset, which includes a wide range of privacy categories and user instructions to simulate real MLLM applications. This dataset offers protected surrogates alongside their various MLLM-edited versions, thus enabling the direct assessment of privacy recovery quality. By formulating privacy recovery as a guided generation task conditioned on complementary multimodal signals, we further introduce a unified approach that reliably reconstructs private content while preserving the fidelity of MLLM-generated edits. The experiments on both SPPE and InstructPix2Pix further show that our approach generalizes well across diverse visual content and editing tasks, achieving a strong balance between privacy protection and MLLM usability.

</details>


### [162] [TIDE: Two-Stage Inverse Degradation Estimation with Guided Prior Disentanglement for Underwater Image Restoration](https://arxiv.org/abs/2512.07171)
*Shravan Venkatraman,Rakesh Raj Madavan,Pavan Kumar S,Muthu Subash Kavitha*

Main category: cs.CV

TL;DR: TIDE是一种两阶段水下图像修复框架，通过分解退化因素并自适应融合修复假设，显著提升了颜色校正和对比度增强效果。


<details>
  <summary>Details</summary>
Motivation: 水下图像修复对海洋应用至关重要，但现有方法难以处理空间变化和共存的多种退化问题。

Method: TIDE采用两阶段框架：首先通过专门先验分解将水下退化分为四个关键因素（颜色失真、雾霾、细节丢失和噪声），并设计针对每个因素的修复专家；然后自适应融合局部退化模式的假设，并通过渐进细化阶段纠正残余伪影。

Result: TIDE在标准基准和混浊水条件下均表现出色，不仅在参考保真度指标上具有竞争力，还在非参考感知质量指标上优于现有方法。

Conclusion: TIDE框架通过两阶段逆退化估计和专门先验分解，有效解决了水下图像修复中复杂且空间变化的退化问题，在颜色校正和对比度增强方面表现优异。

Abstract: Underwater image restoration is essential for marine applications ranging from ecological monitoring to archaeological surveys, but effectively addressing the complex and spatially varying nature of underwater degradations remains a challenge. Existing methods typically apply uniform restoration strategies across the entire image, struggling to handle multiple co-occurring degradations that vary spatially and with water conditions. We introduce TIDE, a $\underline{t}$wo stage $\underline{i}$nverse $\underline{d}$egradation $\underline{e}$stimation framework that explicitly models degradation characteristics and applies targeted restoration through specialized prior decomposition. Our approach disentangles the restoration process into multiple specialized hypotheses that are adaptively fused based on local degradation patterns, followed by a progressive refinement stage that corrects residual artifacts. Specifically, TIDE decomposes underwater degradations into four key factors, namely color distortion, haze, detail loss, and noise, and designs restoration experts specialized for each. By generating specialized restoration hypotheses, TIDE balances competing degradation factors and produces natural results even in highly degraded regions. Extensive experiments across both standard benchmarks and challenging turbid water conditions show that TIDE achieves competitive performance on reference based fidelity metrics while outperforming state of the art methods on non reference perceptual quality metrics, with strong improvements in color correction and contrast enhancement. Our code is available at: https://rakesh-123-cryp.github.io/TIDE.

</details>


### [163] [Integrating Multi-scale and Multi-filtration Topological Features for Medical Image Classification](https://arxiv.org/abs/2512.07190)
*Pengfei Gu,Huimin Li,Haoteng Tang,Dongkuan,Xu,Erik Enriquez,DongChul Kim,Bin Fu,Danny Z. Chen*

Main category: cs.CV

TL;DR: 该论文提出了一种结合多尺度、多过滤持久拓扑特征的分类框架，显著提升了医学图像分类性能。


<details>
  <summary>Details</summary>
Motivation: 现代深度神经网络在医学图像分类中表现优异，但往往忽视了解剖结构的拓扑特征，或仅通过单参数持久性捕获简单拓扑特征。因此，作者旨在通过多尺度和多过滤的拓扑特征增强模型的分类能力。

Method: 论文开发了一个‘vineyard’算法，将不同分辨率/尺度的立方持久图（PDs）整合为一个稳定的图，并设计了一个基于交叉注意力的神经网络来处理这些PDs，最终将拓扑嵌入与CNN或Transformer的特征图融合。

Result: 在三个公共数据集上的评估显示，该方法显著优于现有基线方法和最先进方法，验证了其拓扑视角的全面性和有效性。

Conclusion: 该论文提出了一种新的拓扑引导分类框架，通过整合多尺度和多过滤的持久拓扑特征，显著提升了医学图像分类的性能和可解释性。

Abstract: Modern deep neural networks have shown remarkable performance in medical image classification. However, such networks either emphasize pixel-intensity features instead of fundamental anatomical structures (e.g., those encoded by topological invariants), or they capture only simple topological features via single-parameter persistence. In this paper, we propose a new topology-guided classification framework that extracts multi-scale and multi-filtration persistent topological features and integrates them into vision classification backbones. For an input image, we first compute cubical persistence diagrams (PDs) across multiple image resolutions/scales. We then develop a ``vineyard'' algorithm that consolidates these PDs into a single, stable diagram capturing signatures at varying granularities, from global anatomy to subtle local irregularities that may indicate early-stage disease. To further exploit richer topological representations produced by multiple filtrations, we design a cross-attention-based neural network that directly processes the consolidated final PDs. The resulting topological embeddings are fused with feature maps from CNNs or Transformers. By integrating multi-scale and multi-filtration topologies into an end-to-end architecture, our approach enhances the model's capacity to recognize complex anatomical structures. Evaluations on three public datasets show consistent, considerable improvements over strong baselines and state-of-the-art methods, demonstrating the value of our comprehensive topological perspective for robust and interpretable medical image classification.

</details>


### [164] [RefLSM: Linearized Structural-Prior Reflectance Model for Medical Image Segmentation and Bias-Field Correction](https://arxiv.org/abs/2512.07191)
*Wenqi Zhao,Jiacheng Sang,Fenghua Cheng,Yonglu Shu,Dong Li,Xiaofeng Yang*

Main category: cs.CV

TL;DR: RefLSM是一种新型水平集模型，通过反射分解和结构先验提升医学图像分割性能，尤其在非均匀光照条件下表现突出。


<details>
  <summary>Details</summary>
Motivation: 传统水平集方法在非均匀光照条件下依赖近似偏置场估计，效果受限。RefLSM通过反射分解直接分割光照不变的反射分量，以解决这一问题。

Method: 提出了一种基于Retinex反射分解的变分水平集模型（RefLSM），结合线性结构先验和松弛二值水平集，采用ADMM优化方案高效求解。

Result: 在多组医学影像数据集上的实验表明，RefLSM在分割精度、鲁棒性和计算效率上均优于现有水平集方法。

Conclusion: RefLSM通过整合Retinex启发的反射分解，显著提升了医学图像分割的准确性和鲁棒性，尤其在非均匀光照条件下表现优异。

Abstract: Medical image segmentation remains challenging due to intensity inhomogeneity, noise, blurred boundaries, and irregular structures. Traditional level set methods, while effective in certain cases, often depend on approximate bias field estimations and therefore struggle under severe non-uniform imaging conditions. To address these limitations, we propose a novel variational Reflectance-based Level Set Model (RefLSM), which explicitly integrates Retinex-inspired reflectance decomposition into the segmentation framework. By decomposing the observed image into reflectance and bias field components, RefLSM directly segments the reflectance, which is invariant to illumination and preserves fine structural details. Building on this foundation, we introduce two key innovations for enhanced precision and robustness. First, a linear structural prior steers the smoothed reflectance gradients toward a data-driven reference, providing reliable geometric guidance in noisy or low-contrast scenes. Second, a relaxed binary level-set is embedded in RefLSM and enforced via convex relaxation and sign projection, yielding stable evolution and avoiding reinitialization-induced diffusion. The resulting variational problem is solved efficiently using an ADMM-based optimization scheme. Extensive experiments on multiple medical imaging datasets demonstrate that RefLSM achieves superior segmentation accuracy, robustness, and computational efficiency compared to state-of-the-art level set methods.

</details>


### [165] [HVQ-CGIC: Enabling Hyperprior Entropy Modeling for VQ-Based Controllable Generative Image Compression](https://arxiv.org/abs/2512.07192)
*Niu Yi,Xu Tianyi,Ma Mingming,Wang Xinkun*

Main category: cs.CV

TL;DR: HVQ-CGIC是一种基于VQ Hyperprior的可控生成图像压缩框架，通过自适应熵模型和轻量级超先验估计网络，显著提升了率失真性能。


<details>
  <summary>Details</summary>
Motivation: 现有的生成式图像压缩方法通常使用静态全局概率分布估计VQ索引的熵，无法适应每张图像的特定内容，导致比特率潜力未充分挖掘和灵活率控制困难。

Method: 引入了基于VQ Hyperprior的可控生成图像压缩框架HVQ-CGIC，通过新颖的损失设计首次将RD平衡和控制引入基于向量量化的生成图像压缩。

Result: 在Kodak数据集上，HVQ-CGIC以平均61.3%更少的比特数实现了与Control-GIC、CDC和HiFiC相同的LPIPS，展现了显著的率失真性能优势。

Conclusion: HVQ-CGIC框架在VQGAN-based图像压缩中具有成为基础组件的潜力，类似于HyperPrior框架在神经图像压缩中的重要作用。

Abstract: Generative learned image compression methods using Vector Quantization (VQ) have recently shown impressive potential in balancing distortion and perceptual quality. However, these methods typically estimate the entropy of VQ indices using a static, global probability distribution, which fails to adapt to the specific content of each image. This non-adaptive approach leads to untapped bitrate potential and challenges in achieving flexible rate control. To address this challenge, we introduce a Controllable Generative Image Compression framework based on a VQ Hyperprior, termed HVQ-CGIC. HVQ-CGIC rigorously derives the mathematical foundation for introducing a hyperprior to the VQ indices entropy model. Based on this foundation, through novel loss design, to our knowledge, this framework is the first to introduce RD balance and control into vector quantization-based Generative Image Compression. Cooperating with a lightweight hyper-prior estimation network, HVQ-CGIC achieves a significant advantage in rate-distortion (RD) performance compared to current state-of-the-art (SOTA) generative compression methods. On the Kodak dataset, we achieve the same LPIPS as Control-GIC, CDC and HiFiC with an average of 61.3% fewer bits. We posit that HVQ-CGIC has the potential to become a foundational component for VQGAN-based image compression, analogous to the integral role of the HyperPrior framework in neural image compression.

</details>


### [166] [SUCCESS-GS: Survey of Compactness and Compression for Efficient Static and Dynamic Gaussian Splatting](https://arxiv.org/abs/2512.07197)
*Seokhyun Youn,Soohyun Lee,Geonho Kim,Weeyoung Kwon,Sung-Ho Bae,Jihyong Oh*

Main category: cs.CV

TL;DR: 本文综述了高效3D和4D高斯泼溅技术，分类并总结了现有方法，讨论了当前局限和未来方向。


<details>
  <summary>Details</summary>
Motivation: 解决3D高斯泼溅在内存和计算资源上的高需求问题，特别是在4D动态场景中的挑战。

Method: 系统地将现有方法分为参数压缩和重构压缩两大方向，并总结了每类方法的核心思想和趋势。

Result: 提供了首个统一的高效3D和4D高斯泼溅技术综述，涵盖数据集、评估指标和基准比较。

Conclusion: 本文总结了高效3D和4D高斯泼溅技术的现状，并指出了未来研究方向，旨在实现可扩展、紧凑且实时的静态和动态3D场景表示。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a powerful explicit representation enabling real-time, high-fidelity 3D reconstruction and novel view synthesis. However, its practical use is hindered by the massive memory and computational demands required to store and render millions of Gaussians. These challenges become even more severe in 4D dynamic scenes. To address these issues, the field of Efficient Gaussian Splatting has rapidly evolved, proposing methods that reduce redundancy while preserving reconstruction quality. This survey provides the first unified overview of efficient 3D and 4D Gaussian Splatting techniques. For both 3D and 4D settings, we systematically categorize existing methods into two major directions, Parameter Compression and Restructuring Compression, and comprehensively summarize the core ideas and methodological trends within each category. We further cover widely used datasets, evaluation metrics, and representative benchmark comparisons. Finally, we discuss current limitations and outline promising research directions toward scalable, compact, and real-time Gaussian Splatting for both static and dynamic 3D scene representation.

</details>


### [167] [Generating Storytelling Images with Rich Chains-of-Reasoning](https://arxiv.org/abs/2512.07198)
*Xiujie Song,Qi Jia,Shota Watanabe,Xiaoyi Pang,Ruijie Chen,Mengyue Wu,Kenny Q. Zhu*

Main category: cs.CV

TL;DR: 本文提出了一种结合LLMs和T2I模型的两阶段流水线StorytellingPainter，用于生成具有丰富语义的Storytelling Images，并开发了专用评估框架。实验验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 由于Storytelling Images的复杂语义性质，其生成具有挑战性且数量稀少，因此探索如何利用生成AI模型来创建此类图像。

Method: 提出了一个两阶段流水线StorytellingPainter，结合大型语言模型（LLMs）的创造性推理能力和文本到图像（T2I）模型的视觉合成能力来生成Storytelling Images，并开发了一个包含三个主要评估器的专用评估框架。

Result: 提出的方法在生成Storytelling Images方面表现出可行性和有效性，并通过实验验证了其效果。

Conclusion: 实验结果表明，所提出的方法在生成Storytelling Images方面具有可行性和有效性。

Abstract: An image can convey a compelling story by presenting rich, logically connected visual clues. These connections form Chains-of-Reasoning (CoRs) within the image, enabling viewers to infer events, causal relationships, and other information, thereby understanding the underlying story. In this paper, we focus on these semantically rich images and define them as Storytelling Images. Such images have diverse applications beyond illustration creation and cognitive screening, leveraging their ability to convey multi-layered information visually and inspire active interpretation. However, due to their complex semantic nature, Storytelling Images are inherently challenging to create, and thus remain relatively scarce. To address this challenge, we introduce the Storytelling Image Generation task, which explores how generative AI models can be leveraged to create such images. Specifically, we propose a two-stage pipeline, StorytellingPainter, which combines the creative reasoning abilities of Large Language Models (LLMs) with the visual synthesis capabilities of Text-to-Image (T2I) models to generate Storytelling Images. Alongside this pipeline, we develop a dedicated evaluation framework comprising three main evaluators: a Semantic Complexity Evaluator, a KNN-based Diversity Evaluator and a Story-Image Alignment Evaluator. Given the critical role of story generation in the Storytelling Image Generation task and the performance disparity between open-source and proprietary LLMs, we further explore tailored training strategies to reduce this gap, resulting in a series of lightweight yet effective models named Mini-Storytellers. Experimental results demonstrate the feasibility and effectiveness of our approaches. The code is available at https://github.com/xiujiesong/StorytellingImageGeneration.

</details>


### [168] [Understanding Diffusion Models via Code Execution](https://arxiv.org/abs/2512.07201)
*Cheng Yu*

Main category: cs.CV

TL;DR: 该论文提供了一个简洁的扩散模型实现（约300行代码），旨在帮助研究者通过代码理解扩散模型的实际运作方式，弥合理论与实践的差距。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在生成建模中表现出色，但其理论复杂，且论文中的数学公式与实际开源代码之间存在较大鸿沟，现有教程多聚焦于公式推导，缺乏对代码实现的指导。

Method: 提供了一个简化的扩散模型实现，包括前向扩散、反向采样、噪声预测网络和训练循环等核心组件，去除了不必要的工程细节。

Result: 实现了一个简洁的扩散模型代码示例，保留了核心功能，为研究者提供了从代码执行角度理解扩散模型的途径。

Conclusion: 该技术报告通过一个约300行的简洁实现，清晰地展示了扩散模型的实际运作方式，帮助研究者理解代码与理论之间的对应关系。

Abstract: Diffusion models have achieved remarkable performance in generative modeling, yet their theoretical foundations are often intricate, and the gap between mathematical formulations in papers and practical open-source implementations can be difficult to bridge. Existing tutorials primarily focus on deriving equations, offering limited guidance on how diffusion models actually operate in code. To address this, we present a concise implementation of approximately 300 lines that explains diffusion models from a code-execution perspective. Our minimal example preserves the essential components -- including forward diffusion, reverse sampling, the noise-prediction network, and the training loop -- while removing unnecessary engineering details. This technical report aims to provide researchers with a clear, implementation-first understanding of how diffusion models work in practice and how code and theory correspond. Our code and pre-trained models are available at: https://github.com/disanda/GM/tree/main/DDPM-DDIM-ClassifierFree.

</details>


### [169] [MMRPT: MultiModal Reinforcement Pre-Training via Masked Vision-Dependent Reasoning](https://arxiv.org/abs/2512.07203)
*Xuhui Zheng,Kang An,Ziliang Wang,Yuhang Wang,Faqiang Qian,Yichao Wu*

Main category: cs.CV

TL;DR: MMRPT是一种掩码多模态强化预训练框架，通过强化学习奖励视觉基础而非标题模仿，提升了多模态模型的视觉推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决多模态预训练中图像-标题对的描述性偏差问题，避免模型仅依赖表面语言线索而忽视视觉理解。

Method: MMRPT通过估计句子级视觉依赖关系并掩码高度依赖视觉的片段，构建掩码多模态数据；模型通过语义-视觉奖励引导的视觉基础推理重建这些片段。

Result: 实验显示，MMRPT在多样化的基准测试中实现了零样本性能的持续提升，并在监督微调下显著提高了鲁棒性。

Conclusion: MMRPT框架通过强化学习驱动的掩码多模态推理，为多模态模型提供了更可靠和通用的预训练目标，显著提升了模型的零样本性能和鲁棒性。

Abstract: Multimodal pre-training remains constrained by the descriptive bias of image-caption pairs, leading models to favor surface linguistic cues over grounded visual understanding. We introduce MMRPT, a masked multimodal reinforcement pre-training framework that strengthens visual reasoning in MLLMs. We are the first to incorporate reinforcement learning directly into the pre-training of large vision-language models, enabling learning signals that reward visual grounding rather than caption imitation. MMRPT constructs masked multimodal data by estimating sentence-level visual dependency via attention over visual tokens and masking highly vision-dependent segments; the model reconstructs these spans through vision-grounded reasoning guided by a semantic-visual reward. Experiments show consistent zero-shot gains across diverse benchmarks and substantially improved robustness under supervised fine-tuning, demonstrating that reinforcement-driven masked reasoning provides a more reliable and generalizable pre-training objective for multimodal models.

</details>


### [170] [AutoLugano: A Deep Learning Framework for Fully Automated Lymphoma Segmentation and Lugano Staging on FDG-PET/CT](https://arxiv.org/abs/2512.07206)
*Boyang Pan,Zeyu Zhang,Hongyu Meng,Bin Cui,Yingying Zhang,Wenli Hou,Junhao Li,Langdi Zhong,Xiaoxiao Chen,Xiaoyu Xu,Changjin Zuo,Chao Cheng,Nan-Jie Gong*

Main category: cs.CV

TL;DR: AutoLugano是一个全自动深度学习系统，通过FDG-PET/CT扫描实现淋巴瘤的端到端分类，包括病变分割、解剖定位和Lugano分期，外部验证表现优异。


<details>
  <summary>Details</summary>
Motivation: 开发一个全自动的深度学习系统AutoLugano，用于通过基线FDG-PET/CT扫描进行端到端的淋巴瘤分类，包括病变分割、解剖定位和自动Lugano分期。

Method: AutoLugano系统通过三个顺序模块处理基线FDG-PET/CT扫描：(1) 解剖信息病变分割，使用3D nnU-Net模型进行自动病变检测；(2) 基于图谱的解剖定位，利用TotalSegmentator工具包将分割的病变映射到21个预定义的淋巴结区域；(3) 自动Lugano分期，将涉及区域的空间分布转化为Lugano分期和治疗组（局限期 vs. 进展期）。系统在公共autoPET数据集（n=1,007）上训练，并在67名患者的独立队列中进行外部验证。

Result: 在外部验证集上，模型表现出色，区域受累检测的总体准确率为88.31%，敏感性为74.47%，特异性为94.21%，F1分数为80.80%，优于基线模型。在治疗分层（局限期 vs. 进展期）的关键临床任务中，系统达到了85.07%的高准确率，特异性为90.48%，敏感性为82.61%。

Conclusion: AutoLugano是首个全自动、端到端的流程，能够将单一的基线FDG-PET/CT扫描转化为完整的Lugano分期。这项研究展示了其在初始分期、治疗分层和支持临床决策方面的强大潜力。

Abstract: Purpose: To develop a fully automated deep learning system, AutoLugano, for end-to-end lymphoma classification by performing lesion segmentation, anatomical localization, and automated Lugano staging from baseline FDG-PET/CT scans. Methods: The AutoLugano system processes baseline FDG-PET/CT scans through three sequential modules:(1) Anatomy-Informed Lesion Segmentation, a 3D nnU-Net model, trained on multi-channel inputs, performs automated lesion detection (2) Atlas-based Anatomical Localization, which leverages the TotalSegmentator toolkit to map segmented lesions to 21 predefined lymph node regions using deterministic anatomical rules; and (3) Automated Lugano Staging, where the spatial distribution of involved regions is translated into Lugano stages and therapeutic groups (Limited vs. Advanced Stage).The system was trained on the public autoPET dataset (n=1,007) and externally validated on an independent cohort of 67 patients. Performance was assessed using accuracy, sensitivity, specificity, F1-scorefor regional involvement detection and staging agreement. Results: On the external validation set, the proposed model demonstrated robust performance, achieving an overall accuracy of 88.31%, sensitivity of 74.47%, Specificity of 94.21% and an F1-score of 80.80% for regional involvement detection,outperforming baseline models. Most notably, for the critical clinical task of therapeutic stratification (Limited vs. Advanced Stage), the system achieved a high accuracy of 85.07%, with a specificity of 90.48% and a sensitivity of 82.61%.Conclusion: AutoLugano represents the first fully automated, end-to-end pipeline that translates a single baseline FDG-PET/CT scan into a complete Lugano stage. This study demonstrates its strong potential to assist in initial staging, treatment stratification, and supporting clinical decision-making.

</details>


### [171] [Object Pose Distribution Estimation for Determining Revolution and Reflection Uncertainty in Point Clouds](https://arxiv.org/abs/2512.07211)
*Frederik Hagelskjær,Dimitrios Arapis,Steffen Madsen,Thorbjørn Mosekjær Iversen*

Main category: cs.CV

TL;DR: 提出首个不依赖RGB输入的深度学习姿态分布估计方法，仅用3D无色数据，填补工业场景中的技术空白。


<details>
  <summary>Details</summary>
Motivation: 现有姿态估计方法通常提供单一姿态估计，无法捕捉视觉模糊性带来的不确定性，且依赖颜色信息，这在工业场景中往往不可用。

Method: 采用神经网络方法，专注于利用3D无色数据进行姿态分布估计，特别处理反射和旋转对称性，框架可扩展至完整的SE(3)姿态分布估计。

Result: 在真实世界的分拣场景中验证了方法的有效性，适用于几何模糊性不同的物体。

Conclusion: 该论文提出了一种基于神经网络的新方法，仅使用3D无色数据来估计物体姿态不确定性，填补了现有方法依赖颜色信息的不足，并在实际场景中验证了其有效性。

Abstract: Object pose estimation is crucial to robotic perception and typically provides a single-pose estimate. However, a single estimate cannot capture pose uncertainty deriving from visual ambiguity, which can lead to unreliable behavior. Existing pose distribution methods rely heavily on color information, often unavailable in industrial settings.
  We propose a novel neural network-based method for estimating object pose uncertainty using only 3D colorless data. To the best of our knowledge, this is the first approach that leverages deep learning for pose distribution estimation without relying on RGB input. We validate our method in a real-world bin picking scenario with objects of varying geometric ambiguity. Our current implementation focuses on symmetries in reflection and revolution, but the framework is extendable to full SE(3) pose distribution estimation. Source code available at opde3d.github.io

</details>


### [172] [ReLKD: Inter-Class Relation Learning with Knowledge Distillation for Generalized Category Discovery](https://arxiv.org/abs/2512.07229)
*Fang Zhou,Zhiqiang Chen,Martin Pavlovski,Yizhong Zhang*

Main category: cs.CV

TL;DR: ReLKD是一种端到端框架，通过利用隐式类间关系提升新类别分类性能，包含三个模块：目标粒度、粗粒度和蒸馏模块，实验证明其在标记数据有限时表现优异。


<details>
  <summary>Details</summary>
Motivation: 广义类别发现（GCD）面临对包含已知和新类别的未标记数据进行分类的挑战，而现有研究往往独立处理每个类别，忽略了类间关系。直接获取这些关系在现实场景中具有挑战性。

Method: ReLKD包含三个关键模块：目标粒度模块用于学习区分性表示，粗粒度模块用于捕获层次类关系，蒸馏模块用于将知识从粗粒度模块传递到目标粒度模块以优化表示学习。

Result: 在四个数据集上的大量实验证明了ReLKD的有效性，尤其是在标记数据有限的情况下。

Conclusion: ReLKD框架通过利用隐式的类间关系，有效提升了新类别的分类性能，特别是在标记数据有限的情况下。

Abstract: Generalized Category Discovery (GCD) faces the challenge of categorizing unlabeled data containing both known and novel classes, given only labels for known classes. Previous studies often treat each class independently, neglecting the inherent inter-class relations. Obtaining such inter-class relations directly presents a significant challenge in real-world scenarios. To address this issue, we propose ReLKD, an end-to-end framework that effectively exploits implicit inter-class relations and leverages this knowledge to enhance the classification of novel classes. ReLKD comprises three key modules: a target-grained module for learning discriminative representations, a coarse-grained module for capturing hierarchical class relations, and a distillation module for transferring knowledge from the coarse-grained module to refine the target-grained module's representation learning. Extensive experiments on four datasets demonstrate the effectiveness of ReLKD, particularly in scenarios with limited labeled data. The code for ReLKD is available at https://github.com/ZhouF-ECNU/ReLKD.

</details>


### [173] [STRinGS: Selective Text Refinement in Gaussian Splatting](https://arxiv.org/abs/2512.07230)
*Abhinav Raundhal,Gaurav Behera,P J Narayanan,Ravi Kiran Sarvadevabhatla,Makarand Tapaswi*

Main category: cs.CV

TL;DR: STRinGS是一种针对3D高斯泼溅（3DGS）的文本感知选择性优化框架，通过分离处理文本与非文本区域，显著提升文本重建质量，并引入新数据集STRinGS-360进行评估。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅（3DGS）等3D表示方法在保留细粒度文本细节方面存在不足，微小的文本重建错误可能导致严重的语义损失。

Method: STRinGS采用文本与非文本区域分离处理的策略，先优化文本区域，再与非文本区域合并进行全场景优化。

Result: STRinGS在仅7K次迭代后，相对于3DGS实现了63.6%的相对改进，并引入了OCR字符错误率（CER）作为文本可读性评估指标。

Conclusion: STRinGS及其配套数据集STRinGS-360显著提升了3D场景中文本重建的质量，为文本感知的3D重建方法设定了新标准。

Abstract: Text as signs, labels, or instructions is a critical element of real-world scenes as they can convey important contextual information. 3D representations such as 3D Gaussian Splatting (3DGS) struggle to preserve fine-grained text details, while achieving high visual fidelity. Small errors in textual element reconstruction can lead to significant semantic loss. We propose STRinGS, a text-aware, selective refinement framework to address this issue for 3DGS reconstruction. Our method treats text and non-text regions separately, refining text regions first and merging them with non-text regions later for full-scene optimization. STRinGS produces sharp, readable text even in challenging configurations. We introduce a text readability measure OCR Character Error Rate (CER) to evaluate the efficacy on text regions. STRinGS results in a 63.6% relative improvement over 3DGS at just 7K iterations. We also introduce a curated dataset STRinGS-360 with diverse text scenarios to evaluate text readability in 3D reconstruction. Our method and dataset together push the boundaries of 3D scene understanding in text-rich environments, paving the way for more robust text-aware reconstruction methods.

</details>


### [174] [Unified Camera Positional Encoding for Controlled Video Generation](https://arxiv.org/abs/2512.07237)
*Cheng Zhang,Boying Li,Meng Wei,Yan-Pei Cao,Camilo Cruz Gambardella,Dinh Phung,Jianfei Cai*

Main category: cs.CV

TL;DR: 提出了一种新的相机编码方法UCPE，通过几何一致的表示和轻量级适配器，显著提升了相机可控性和视觉保真度。


<details>
  <summary>Details</summary>
Motivation: 现有相机编码方法通常依赖简化的针孔假设，限制了在现实世界相机中不同内参和镜头畸变的泛化能力。

Method: 引入了Relative Ray Encoding（相对射线编码），一种几何一致的表示方法，统一了完整的相机信息，包括6自由度位姿、内参和镜头畸变。

Result: 构建了一个大型视频数据集，覆盖了广泛的相机运动和镜头类型，并通过广泛实验验证了UCPE在相机可控视频生成中的有效性。

Conclusion: UCPE（统一相机位置编码）通过轻量级空间注意力适配器集成到预训练的视频扩散变换器中，增加了不到1%的可训练参数，同时实现了最先进的相机可控性和视觉保真度。

Abstract: Transformers have emerged as a universal backbone across 3D perception, video generation, and world models for autonomous driving and embodied AI, where understanding camera geometry is essential for grounding visual observations in three-dimensional space. However, existing camera encoding methods often rely on simplified pinhole assumptions, restricting generalization across the diverse intrinsics and lens distortions in real-world cameras. We introduce Relative Ray Encoding, a geometry-consistent representation that unifies complete camera information, including 6-DoF poses, intrinsics, and lens distortions. To evaluate its capability under diverse controllability demands, we adopt camera-controlled text-to-video generation as a testbed task. Within this setting, we further identify pitch and roll as two components effective for Absolute Orientation Encoding, enabling full control over the initial camera orientation. Together, these designs form UCPE (Unified Camera Positional Encoding), which integrates into a pretrained video Diffusion Transformer through a lightweight spatial attention adapter, adding less than 1% trainable parameters while achieving state-of-the-art camera controllability and visual fidelity. To facilitate systematic training and evaluation, we construct a large video dataset covering a wide range of camera motions and lens types. Extensive experiments validate the effectiveness of UCPE in camera-controllable video generation and highlight its potential as a general camera representation for Transformers across future multi-view, video, and 3D tasks. Code will be available at https://github.com/chengzhag/UCPE.

</details>


### [175] [Squeezed-Eff-Net: Edge-Computed Boost of Tomography Based Brain Tumor Classification leveraging Hybrid Neural Network Architecture](https://arxiv.org/abs/2512.07241)
*Md. Srabon Chowdhury,Syeda Fahmida Tanzim,Sheekar Banerjee,Ishtiak Al Mamoon,AKM Muzahidul Islam*

Main category: cs.CV

TL;DR: Hybrid deep learning model (SqueezeNet v1 + EfficientNet-B0) with radiomic features achieves 98.93%-99.08% accuracy in brain tumor MRI classification, balancing efficiency and performance.


<details>
  <summary>Details</summary>
Motivation: To address the challenges of time-consuming and error-prone manual tumor delineation in MRI, leveraging deep learning for automated, accurate classification.

Method: A hybrid model combining SqueezeNet v1 (lightweight) and EfficientNet-B0 (high-performing), enhanced with handcrafted radiomic descriptors (HOG, LBP, Gabor filters, Wavelet transforms), trained on the Nickparvar Brain Tumor MRI dataset.

Result: Achieved testing accuracy of 98.93% (99.08% with TTA), using fewer than 2.1 million parameters and less than 1.2 GFLOPs, showing strong generalization.

Conclusion: The proposed hybrid deep learning model demonstrates high accuracy (98.93%-99.08%) in brain tumor classification, offering a balance between computational efficiency and diagnostic performance, with potential clinical applicability.

Abstract: Brain tumors are one of the most common and dangerous neurological diseases which require a timely and correct diagnosis to provide the right treatment procedures. Even with the promotion of magnetic resonance imaging (MRI), the process of tumor delineation is difficult and time-consuming, which is prone to inter-observer error. In order to overcome these limitations, this work proposes a hybrid deep learning model based on SqueezeNet v1 which is a lightweight model, and EfficientNet-B0, which is a high-performing model, and is enhanced with handcrafted radiomic descriptors, including Histogram of Oriented Gradients (HOG), Local Binary Patterns (LBP), Gabor filters and Wavelet transforms. The framework was trained and tested only on publicly available Nickparvar Brain Tumor MRI dataset, which consisted of 7,023 contrast-enhanced T1-weighted axial MRI slices which were categorized into four groups: glioma, meningioma, pituitary tumor, and no tumor. The testing accuracy of the model was 98.93% that reached a level of 99.08% with Test Time Augmentation (TTA) showing great generalization and power. The proposed hybrid network offers a compromise between computation efficiency and diagnostic accuracy compared to current deep learning structures and only has to be trained using fewer than 2.1 million parameters and less than 1.2 GFLOPs. The handcrafted feature addition allowed greater sensitivity in texture and the EfficientNet-B0 backbone represented intricate hierarchical features. The resulting model has almost clinical reliability in automated MRI-based classification of tumors highlighting its possibility of use in clinical decision-support systems.

</details>


### [176] [Zero-Shot Textual Explanations via Translating Decision-Critical Features](https://arxiv.org/abs/2512.07245)
*Toshinori Yamauchi,Hiroshi Kera,Kazuhiko Kawamoto*

Main category: cs.CV

TL;DR: TEXTER通过强调决策关键特征并映射到CLIP空间，生成更忠实和可解释的图像分类器文本解释。


<details>
  <summary>Details</summary>
Motivation: 现有的零样本解释方法仅关注全局图像特征与语言的匹配，生成的描述仅反映可见内容而非预测驱动因素。TEXTER旨在克服这一局限，生成更忠实于模型决策的解释。

Method: TEXTER通过识别对预测贡献最大的神经元，并强调这些神经元编码的特征（即决策关键特征），然后将这些特征映射到CLIP特征空间以检索反映模型推理的文本解释。稀疏自编码器进一步提高了Transformer架构的可解释性。

Result: 大量实验表明，TEXTER生成的解释比现有方法更忠实和可解释。

Conclusion: TEXTER通过隔离决策关键特征并与CLIP特征空间对齐，生成了比现有方法更忠实和可解释的文本解释。

Abstract: Textual explanations make image classifier decisions transparent by describing the prediction rationale in natural language. Large vision-language models can generate captions but are designed for general visual understanding, not classifier-specific reasoning. Existing zero-shot explanation methods align global image features with language, producing descriptions of what is visible rather than what drives the prediction. We propose TEXTER, which overcomes this limitation by isolating decision-critical features before alignment. TEXTER identifies the neurons contributing to the prediction and emphasizes the features encoded in those neurons -- i.e., the decision-critical features. It then maps these emphasized features into the CLIP feature space to retrieve textual explanations that reflect the model's reasoning. A sparse autoencoder further improves interpretability, particularly for Transformer architectures. Extensive experiments show that TEXTER generates more faithful and interpretable explanations than existing methods. The code will be publicly released.

</details>


### [177] [AdLift: Lifting Adversarial Perturbations to Safeguard 3D Gaussian Splatting Assets Against Instruction-Driven Editing](https://arxiv.org/abs/2512.07247)
*Ziming Hong,Tianyu Huang,Runnan Chen,Shanshan Ye,Mingming Gong,Bo Han,Tongliang Liu*

Main category: cs.CV

TL;DR: AdLift是首个针对3DGS的编辑保护方案，通过优化3D高斯表示的对抗扰动，实现多视角一致的保护效果。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散模型在2D图像编辑中表现出色，但将其应用于3DGS时面临视角通用性保护和不可见性与保护能力平衡的挑战，因此需要开发针对3DGS的编辑防护方案。

Method: 通过将严格限制的2D对抗扰动提升为3D高斯表示的防护，采用定制的Lifted PGD方法，交替进行梯度截断和图像到高斯拟合操作，优化防护高斯参数。

Result: 实验证明，AdLift能有效抵御最先进的指令驱动2D图像和3DGS编辑攻击。

Conclusion: AdLift 是首个针对3D高斯溅射（3DGS）的编辑保护方案，能有效防止任意视角和维度的指令驱动编辑，同时平衡了对抗扰动的有效性和不可见性。

Abstract: Recent studies have extended diffusion-based instruction-driven 2D image editing pipelines to 3D Gaussian Splatting (3DGS), enabling faithful manipulation of 3DGS assets and greatly advancing 3DGS content creation. However, it also exposes these assets to serious risks of unauthorized editing and malicious tampering. Although imperceptible adversarial perturbations against diffusion models have proven effective for protecting 2D images, applying them to 3DGS encounters two major challenges: view-generalizable protection and balancing invisibility with protection capability. In this work, we propose the first editing safeguard for 3DGS, termed AdLift, which prevents instruction-driven editing across arbitrary views and dimensions by lifting strictly bounded 2D adversarial perturbations into 3D Gaussian-represented safeguard. To ensure both adversarial perturbations effectiveness and invisibility, these safeguard Gaussians are progressively optimized across training views using a tailored Lifted PGD, which first conducts gradient truncation during back-propagation from the editing model at the rendered image and applies projected gradients to strictly constrain the image-level perturbation. Then, the resulting perturbation is backpropagated to the safeguard Gaussian parameters via an image-to-Gaussian fitting operation. We alternate between gradient truncation and image-to-Gaussian fitting, yielding consistent adversarial-based protection performance across different viewpoints and generalizes to novel views. Empirically, qualitative and quantitative results demonstrate that AdLift effectively protects against state-of-the-art instruction-driven 2D image and 3DGS editing.

</details>


### [178] [See More, Change Less: Anatomy-Aware Diffusion for Contrast Enhancement](https://arxiv.org/abs/2512.07251)
*Junqi Liu,Zejun Wu,Pedro R. A. S. Bassi,Xinze Zhou,Wenxuan Li,Ibrahim E. Hamamci,Sezgin Er,Tianyu Lin,Yi Luo,Szymon Płotka,Bjoern Menze,Daguang Xu,Kai Ding,Kang Wang,Yang Yang,Yucheng Tang,Alan L. Yuille,Zongwei Zhou*

Main category: cs.CV

TL;DR: SMILE是一种解剖学感知的扩散模型，通过结构感知监督、免配准学习和统一推理，显著提升医学图像增强质量和临床实用性。


<details>
  <summary>Details</summary>
Motivation: 当前医学图像增强模型常因过度编辑导致解剖结构失真或遗漏小肿瘤，缺乏对解剖结构和对比动态的理解。

Method: SMILE采用结构感知监督、免配准学习和统一推理三个关键创新，直接处理未对齐的多期CT扫描。

Result: 在六个外部数据集上，SMILE在图像质量（SSIM提高14.2%，PSNR提高20.6%，FID改善50%）和临床实用性上均优于现有方法，并提高了非对比CT的癌症检测率（F1分数提升达10%）。

Conclusion: SMILE通过结合解剖学感知和对比动态学习，显著提升了医学图像增强的质量和临床实用性，优于现有方法。

Abstract: Image enhancement improves visual quality and helps reveal details that are hard to see in the original image. In medical imaging, it can support clinical decision-making, but current models often over-edit. This can distort organs, create false findings, and miss small tumors because these models do not understand anatomy or contrast dynamics. We propose SMILE, an anatomy-aware diffusion model that learns how organs are shaped and how they take up contrast. It enhances only clinically relevant regions while leaving all other areas unchanged. SMILE introduces three key ideas: (1) structure-aware supervision that follows true organ boundaries and contrast patterns; (2) registration-free learning that works directly with unaligned multi-phase CT scans; (3) unified inference that provides fast and consistent enhancement across all contrast phases. Across six external datasets, SMILE outperforms existing methods in image quality (14.2% higher SSIM, 20.6% higher PSNR, 50% better FID) and in clinical usefulness by producing anatomically accurate and diagnostically meaningful images. SMILE also improves cancer detection from non-contrast CT, raising the F1 score by up to 10 percent.

</details>


### [179] [A graph generation pipeline for critical infrastructures based on heuristics, images and depth data](https://arxiv.org/abs/2512.07269)
*Mike Diessner,Yannick Tarant*

Main category: cs.CV

TL;DR: 论文提出了一种基于摄影测量和深度学习的图生成管道，用于低成本生成关键基础设施的虚拟模型，实验证明其效果接近真实情况。


<details>
  <summary>Details</summary>
Motivation: 传统的3D点云激光扫描方法成本高且需要专业知识，因此需要一种更经济、易于使用的方法来生成虚拟关键基础设施的模型。

Method: 使用RGB图像和立体相机生成的深度数据，通过深度学习进行对象检测和实例分割，并结合用户定义的启发式或规则推断对象关系。

Result: 在两个液压系统上的实验结果表明，该方法生成的图接近真实情况，且具有灵活性和透明性。

Conclusion: 该论文提出的基于摄影测量和深度学习的图生成管道能够以较低成本生成接近真实情况的图，适用于关键基础设施的高风险决策。

Abstract: Virtual representations of physical critical infrastructures, such as water or energy plants, are used for simulations and digital twins to ensure resilience and continuity of their services. These models usually require 3D point clouds from laser scanners that are expensive to acquire and require specialist knowledge to use. In this article, we present a graph generation pipeline based on photogrammetry. The pipeline detects relevant objects and predicts their relation using RGB images and depth data generated by a stereo camera. This more cost-effective approach uses deep learning for object detection and instance segmentation of the objects, and employs user-defined heuristics or rules to infer their relations. Results of two hydraulic systems show that this strategy can produce graphs close to the ground truth while its flexibility allows the method to be tailored to specific applications and its transparency qualifies it to be used in the high stakes decision-making that is required for critical infrastructures.

</details>


### [180] [RVLF: A Reinforcing Vision-Language Framework for Gloss-Free Sign Language Translation](https://arxiv.org/abs/2512.07273)
*Zhi Rao,Yucheng Zhou,Benjia Zhou,Yiqing Huang,Sergio Escalera,Jun Wan*

Main category: cs.CV

TL;DR: RVLF框架通过LVLM和强化学习解决了手语翻译中的表示和语义对齐问题，显著提升了翻译性能。


<details>
  <summary>Details</summary>
Motivation: 当前无注释手语翻译面临两个主要挑战：手势表示不足和句子级语义对齐问题，限制了翻译质量。

Method: RVLF框架分为三个阶段：首先通过融合骨架运动线索和DINOv2提取的视觉特征进行语义表示学习，然后通过指令微调获得SLT-SFT基线模型，最后使用GRPO优化策略结合BLEU和ROUGE奖励函数微调模型。

Result: RVLF框架在多个数据集上显著提升了BLEU-4分数（CSL-Daily +5.1，PHOENIX-2014T +1.11，How2Sign +1.4，OpenASL +1.61），且无需外部大规模预训练数据。

Conclusion: 本研究提出的RVLF框架通过结合LVLM和强化学习，显著提升了无注释手语翻译的性能，特别是在翻译质量和语义一致性方面。

Abstract: Gloss-free sign language translation (SLT) is hindered by two key challenges: **inadequate sign representation** that fails to capture nuanced visual cues, and **sentence-level semantic misalignment** in current LLM-based methods, which limits translation quality. To address these issues, we propose a three-stage **r**einforcing **v**ision-**l**anguage **f**ramework (**RVLF**). We build a large vision-language model (LVLM) specifically designed for sign language, and then combine it with reinforcement learning (RL) to adaptively enhance translation performance. First, for a sufficient representation of sign language, RVLF introduces an effective semantic representation learning mechanism that fuses skeleton-based motion cues with semantically rich visual features extracted via DINOv2, followed by instruction tuning to obtain a strong SLT-SFT baseline. Then, to improve sentence-level semantic misalignment, we introduce a GRPO-based optimization strategy that fine-tunes the SLT-SFT model with a reward function combining translation fidelity (BLEU) and sentence completeness (ROUGE), yielding the optimized model termed SLT-GRPO. Our conceptually simple framework yields substantial gains under the gloss-free SLT setting without pre-training on any external large-scale sign language datasets, improving BLEU-4 scores by +5.1, +1.11, +1.4, and +1.61 on the CSL-Daily, PHOENIX-2014T, How2Sign, and OpenASL datasets, respectively. To the best of our knowledge, this is the first work to incorporate GRPO into SLT. Extensive experiments and ablation studies validate the effectiveness of GRPO-based optimization in enhancing both translation quality and semantic consistency.

</details>


### [181] [Geo3DVQA: Evaluating Vision-Language Models for 3D Geospatial Reasoning from Aerial Imagery](https://arxiv.org/abs/2512.07276)
*Mai Tsujimoto,Junjue Wang,Weihao Xuan,Naoto Yokoya*

Main category: cs.CV

TL;DR: Geo3DVQA 是一个基于 RGB 图像的 3D 地理空间推理基准，评估显示当前视觉语言模型表现有限，但领域微调显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决当前依赖昂贵传感器和规则驱动方法在整合多 3D 线索、多样化查询及可解释推理方面的不足。

Method: 提出 Geo3DVQA 基准，包含 110k 个问题-答案对，涵盖 16 个任务类别和三个复杂度级别。

Result: 评估显示 GPT-4o 和 Gemini-2.5-Flash 准确率仅为 28.6% 和 33.0%，而领域微调的 Qwen2.5-VL-7B 达到 49.6%。

Conclusion: Geo3DVQA 为评估视觉语言模型在三维地理空间推理中的表现提供了全面基准，揭示了当前模型的局限性及领域适应的有效性。

Abstract: Three-dimensional geospatial analysis is critical to applications in urban planning, climate adaptation, and environmental assessment. Current methodologies depend on costly, specialized sensors (e.g., LiDAR and multispectral), which restrict global accessibility. Existing sensor-based and rule-driven methods further struggle with tasks requiring the integration of multiple 3D cues, handling diverse queries, and providing interpretable reasoning. We hereby present Geo3DVQA, a comprehensive benchmark for evaluating vision-language models (VLMs) in height-aware, 3D geospatial reasoning using RGB-only remote sensing imagery. Unlike conventional sensor-based frameworks, Geo3DVQA emphasizes realistic scenarios that integrate elevation, sky view factors, and land cover patterns. The benchmark encompasses 110k curated question-answer pairs spanning 16 task categories across three complexity levels: single-feature inference, multi-feature reasoning, and application-level spatial analysis. The evaluation of ten state-of-the-art VLMs highlights the difficulty of RGB-to-3D reasoning. GPT-4o and Gemini-2.5-Flash achieved only 28.6% and 33.0% accuracy respectively, while domain-specific fine-tuning of Qwen2.5-VL-7B achieved 49.6% (+24.8 points). These results reveal both the limitations of current VLMs and the effectiveness of domain adaptation. Geo3DVQA introduces new challenge frontiers for scalable, accessible, and holistic 3D geospatial analysis. The dataset and code will be released upon publication at https://github.com/mm1129/Geo3DVQA.

</details>


### [182] [Reevaluating Automated Wildlife Species Detection: A Reproducibility Study on a Custom Image Dataset](https://arxiv.org/abs/2512.07305)
*Tobias Abraham Haider*

Main category: cs.CV

TL;DR: 重新验证预训练模型在野生动物识别中的表现，结果显示其作为基线可行，但需进一步优化以适应不同物种。


<details>
  <summary>Details</summary>
Motivation: 评估Carl等人研究的可重复性和普适性，验证预训练模型在野生动物物种识别中的表现。

Method: 重新实现了Carl等人的实验，使用公开可用的资源和包含90个物种的900张图像的不同数据集，进行最小预处理。

Result: 整体分类准确率为62%，与原研究的71%相近，但每类性能差异显著（宏F1得分为0.28）。

Conclusion: 预训练的卷积神经网络为野生动物物种识别提供了实用的基线，但需要物种特定的适应或迁移学习以实现一致的高质量预测。

Abstract: This study revisits the findings of Carl et al., who evaluated the pre-trained Google Inception-ResNet-v2 model for automated detection of European wild mammal species in camera trap images. To assess the reproducibility and generalizability of their approach, we reimplemented the experiment from scratch using openly available resources and a different dataset consisting of 900 images spanning 90 species. After minimal preprocessing, we obtained an overall classification accuracy of 62%, closely aligning with the 71% reported in the original work despite differences in datasets. As in the original study, per-class performance varied substantially, as indicated by a macro F1 score of 0.28,highlighting limitations in generalization when labels do not align directly with ImageNet classes. Our results confirm that pretrained convolutional neural networks can provide a practical baseline for wildlife species identification but also reinforce the need for species-specific adaptation or transfer learning to achieve consistent, high-quality predictions.

</details>


### [183] [The Inductive Bottleneck: Data-Driven Emergence of Representational Sparsity in Vision Transformers](https://arxiv.org/abs/2512.07331)
*Kanishk Awadhiya*

Main category: cs.CV

TL;DR: ViTs 的中间层信息压缩是数据依赖的适应性行为，与任务语义抽象需求相关，纹理数据集保持高秩表示，对象数据集则学习抑制高频信息。


<details>
  <summary>Details</summary>
Motivation: 探索 ViTs 为何在中间层自发形成“U形”熵曲线，即信息压缩后再扩展的现象，并验证这是否为数据依赖的适应性行为。

Method: 通过分析在不同组成复杂性数据集（UC Merced、Tiny ImageNet 和 CIFAR-100）上 DINO 训练的 ViTs 的逐层有效编码维度（EED），研究 ViTs 的信息压缩行为。

Result: 纹理密集型数据集在整个网络中保持高秩表示，而以对象为中心的数据集则驱动网络在中间层抑制高频信息，从而“学习”一个隔离语义特征的瓶颈。

Conclusion: Vision Transformers (ViTs) 的“归纳瓶颈”不是架构上的伪影，而是数据依赖的适应性表现，其深度与任务所需的语义抽象程度密切相关。

Abstract: Vision Transformers (ViTs) lack the hierarchical inductive biases inherent to Convolutional Neural Networks (CNNs), theoretically allowing them to maintain high-dimensional representations throughout all layers. However, recent observations suggest ViTs often spontaneously manifest a "U-shaped" entropy profile-compressing information in middle layers before expanding it for the final classification. In this work, we demonstrate that this "Inductive Bottleneck" is not an architectural artifact, but a data-dependent adaptation. By analyzing the layer-wise Effective Encoding Dimension (EED) of DINO-trained ViTs across datasets of varying compositional complexity (UC Merced, Tiny ImageNet, and CIFAR-100), we show that the depth of the bottleneck correlates strongly with the semantic abstraction required by the task. We find that while texture-heavy datasets preserve high-rank representations throughout, object-centric datasets drive the network to dampen high-frequency information in middle layers, effectively "learning" a bottleneck to isolate semantic features.

</details>


### [184] [Generalized Referring Expression Segmentation on Aerial Photos](https://arxiv.org/abs/2512.07338)
*Luís Marnoto,Alexandre Bernardino,Bruno Martins*

Main category: cs.CV

TL;DR: Aerial-D是一个新的大规模航空影像指代表达分割数据集，结合RSRefSeg架构训练，表现优异并公开资源。


<details>
  <summary>Details</summary>
Motivation: 航空影像的指代表达分割面临分辨率差异大、颜色不一致、目标小、物体密度高及遮挡等独特挑战，需构建新数据集以应对。

Method: 采用RSRefSeg架构，结合Aerial-D与现有航空数据集进行训练，实现现代与历史图像的文本到实例及语义分割的统一。

Result: 结合训练在当代基准测试中表现优异，且在单色、棕褐色及颗粒退化条件下保持高精度。

Conclusion: Aerial-D数据集、训练模型及完整软件流程已公开，为航空影像的指代表达分割任务提供了新的大规模资源。

Abstract: Referring expression segmentation is a fundamental task in computer vision that integrates natural language understanding with precise visual localization of target regions. Considering aerial imagery (e.g., modern aerial photos collected through drones, historical photos from aerial archives, high-resolution satellite imagery, etc.) presents unique challenges because spatial resolution varies widely across datasets, the use of color is not consistent, targets often shrink to only a few pixels, and scenes contain very high object densities and objects with partial occlusions. This work presents Aerial-D, a new large-scale referring expression segmentation dataset for aerial imagery, comprising 37,288 images with 1,522,523 referring expressions that cover 259,709 annotated targets, spanning across individual object instances, groups of instances, and semantic regions covering 21 distinct classes that range from vehicles and infrastructure to land coverage types. The dataset was constructed through a fully automatic pipeline that combines systematic rule-based expression generation with a Large Language Model (LLM) enhancement procedure that enriched both the linguistic variety and the focus on visual details within the referring expressions. Filters were additionally used to simulate historic imaging conditions for each scene. We adopted the RSRefSeg architecture, and trained models on Aerial-D together with prior aerial datasets, yielding unified instance and semantic segmentation from text for both modern and historical images. Results show that the combined training achieves competitive performance on contemporary benchmarks, while maintaining strong accuracy under monochrome, sepia, and grainy degradations that appear in archival aerial photography. The dataset, trained models, and complete software pipeline are publicly available at https://luispl77.github.io/aerial-d .

</details>


### [185] [Debiasing Diffusion Priors via 3D Attention for Consistent Gaussian Splatting](https://arxiv.org/abs/2512.07345)
*Shilong Jin,Haoran Duan,Litao Hua,Wentao Huang,Yuan Zhou*

Main category: cs.CV

TL;DR: TD-Attn框架通过3D-AAG和HAM模块解决T2I模型的先验视角偏差问题，显著提升3D任务的多视角一致性。


<details>
  <summary>Details</summary>
Motivation: T2I模型因先验视角偏差导致不同视角间外观冲突，限制了其在3D任务中的应用。本文旨在通过数学分析和创新框架克服这一限制。

Method: 提出了TD-Attn框架，包含3D-AAG模块和HAM模块，分别通过构建3D注意力高斯和分层注意力调制来解决多视角不一致问题。

Result: 实验证明TD-Attn能有效提升多视角一致性，支持可控且精确的3D编辑。

Conclusion: TD-Attn作为一种通用插件，显著提升了3D任务中的多视角一致性，展示了其在3D生成和编辑任务中的潜力。

Abstract: Versatile 3D tasks (e.g., generation or editing) that distill from Text-to-Image (T2I) diffusion models have attracted significant research interest for not relying on extensive 3D training data. However, T2I models exhibit limitations resulting from prior view bias, which produces conflicting appearances between different views of an object. This bias causes subject-words to preferentially activate prior view features during cross-attention (CA) computation, regardless of the target view condition. To overcome this limitation, we conduct a comprehensive mathematical analysis to reveal the root cause of the prior view bias in T2I models. Moreover, we find different UNet layers show different effects of prior view in CA. Therefore, we propose a novel framework, TD-Attn, which addresses multi-view inconsistency via two key components: (1) the 3D-Aware Attention Guidance Module (3D-AAG) constructs a view-consistent 3D attention Gaussian for subject-words to enforce spatial consistency across attention-focused regions, thereby compensating for the limited spatial information in 2D individual view CA maps; (2) the Hierarchical Attention Modulation Module (HAM) utilizes a Semantic Guidance Tree (SGT) to direct the Semantic Response Profiler (SRP) in localizing and modulating CA layers that are highly responsive to view conditions, where the enhanced CA maps further support the construction of more consistent 3D attention Gaussians. Notably, HAM facilitates semantic-specific interventions, enabling controllable and precise 3D editing. Extensive experiments firmly establish that TD-Attn has the potential to serve as a universal plugin, significantly enhancing multi-view consistency across 3D tasks.

</details>


### [186] [MICo-150K: A Comprehensive Dataset Advancing Multi-Image Composition](https://arxiv.org/abs/2512.07348)
*Xinyu Wei,Kangrui Cen,Hongyang Wei,Zhen Guo,Bairui Li,Zeqing Wang,Jinrui Zhang,Lei Zhang*

Main category: cs.CV

TL;DR: 研究构建了MICo-150K数据集和基准，提升了多图像合成的模型能力，Qwen-MICo表现突出。


<details>
  <summary>Details</summary>
Motivation: 解决多图像合成中缺乏高质量训练数据的问题，提升模型在复杂场景下的合成一致性和连贯性。

Method: 通过系统研究MICo任务，构建了MICo-150K数据集，包含合成和真实图像组合，并开发了De&Re子集。基于此微调模型，并引入新评估指标Weighted-Ref-VIEScore。

Result: MICo-150K显著提升了模型的MICo能力，Qwen-MICo基线模型在3图像合成中表现优异，支持任意多图像输入。

Conclusion: MICo-150K数据集、MICo-Bench基准和Qwen-MICo基线模型为多图像合成（MICo）研究提供了宝贵资源，显著提升了模型的合成能力。

Abstract: In controllable image generation, synthesizing coherent and consistent images from multiple reference inputs, i.e., Multi-Image Composition (MICo), remains a challenging problem, partly hindered by the lack of high-quality training data. To bridge this gap, we conduct a systematic study of MICo, categorizing it into 7 representative tasks and curate a large-scale collection of high-quality source images and construct diverse MICo prompts. Leveraging powerful proprietary models, we synthesize a rich amount of balanced composite images, followed by human-in-the-loop filtering and refinement, resulting in MICo-150K, a comprehensive dataset for MICo with identity consistency. We further build a Decomposition-and-Recomposition (De&Re) subset, where 11K real-world complex images are decomposed into components and recomposed, enabling both real and synthetic compositions. To enable comprehensive evaluation, we construct MICo-Bench with 100 cases per task and 300 challenging De&Re cases, and further introduce a new metric, Weighted-Ref-VIEScore, specifically tailored for MICo evaluation. Finally, we fine-tune multiple models on MICo-150K and evaluate them on MICo-Bench. The results show that MICo-150K effectively equips models without MICo capability and further enhances those with existing skills. Notably, our baseline model, Qwen-MICo, fine-tuned from Qwen-Image-Edit, matches Qwen-Image-2509 in 3-image composition while supporting arbitrary multi-image inputs beyond the latter's limitation. Our dataset, benchmark, and baseline collectively offer valuable resources for further research on Multi-Image Composition.

</details>


### [187] [Enhancing Small Object Detection with YOLO: A Novel Framework for Improved Accuracy and Efficiency](https://arxiv.org/abs/2512.07379)
*Mahila Moghadami,Mohammad Ali Keyvanrad,Melika Sabaghian*

Main category: cs.CV

TL;DR: 论文提出了一种改进的SW-YOLO方法，通过裁剪优化和架构增强，显著提升了航空影像中小目标检测的准确性。


<details>
  <summary>Details</summary>
Motivation: 随着航空影像在关键和工业应用中的重要性增加，开发鲁棒的小目标检测框架变得至关重要。

Method: 采用SW-YOLO基础方法，优化滑动窗口的裁剪尺寸和重叠率，并在架构中引入高级特征提取模块、CBAM注意力机制和新头部设计。

Result: 在VisDrone2019数据集上，提出的模型将mAP从YOLOv5L的35.5提升至61.2，显著优于SAHI和CZDet等现有方法。

Conclusion: 该研究通过改进SW-YOLO方法，结合裁剪优化和架构增强，显著提升了小目标检测的准确性，在VisDrone2019数据集上取得了从35.5到61.2的mAP提升。

Abstract: This paper investigates and develops methods for detecting small objects in large-scale aerial images. Current approaches for detecting small objects in aerial images often involve image cropping and modifications to detector network architectures. Techniques such as sliding window cropping and architectural enhancements, including higher-resolution feature maps and attention mechanisms, are commonly employed. Given the growing importance of aerial imagery in various critical and industrial applications, the need for robust frameworks for small object detection becomes imperative. To address this need, we adopted the base SW-YOLO approach to enhance speed and accuracy in small object detection by refining cropping dimensions and overlap in sliding window usage and subsequently enhanced it through architectural modifications. we propose a novel model by modifying the base model architecture, including advanced feature extraction modules in the neck for feature map enhancement, integrating CBAM in the backbone to preserve spatial and channel information, and introducing a new head to boost small object detection accuracy. Finally, we compared our method with SAHI, one of the most powerful frameworks for processing large-scale images, and CZDet, which is also based on image cropping, achieving significant improvements in accuracy. The proposed model achieves significant accuracy gains on the VisDrone2019 dataset, outperforming baseline YOLOv5L detection by a substantial margin. Specifically, the final proposed model elevates the mAP .5.5 accuracy on the VisDrone2019 dataset from the base accuracy of 35.5 achieved by the YOLOv5L detector to 61.2. Notably, the accuracy of CZDet, which is another classic method applied to this dataset, is 58.36. This research demonstrates a significant improvement, achieving an increase in accuracy from 35.5 to 61.2.

</details>


### [188] [Tessellation GS: Neural Mesh Gaussians for Robust Monocular Reconstruction of Dynamic Objects](https://arxiv.org/abs/2512.07381)
*Shuohan Tao,Boyao Zhou,Hanzhang Tu,Yuwang Wang,Yebin Liu*

Main category: cs.CV

TL;DR: Tessellation GS 通过结构化2D高斯和网格面约束，显著提升了动态场景重建性能，尤其在稀疏视图和动态场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 3D高斯溅射（GS）在视角外推方面存在各向异性问题，导致过拟合和泛化能力差，尤其在稀疏视图和动态场景重建中表现不佳。

Method: 提出了一种基于网格面的结构化2D高斯方法，通过自适应面细分策略和高斯细分，结合重建基础模型的先验知识初始化高斯变形。

Result: Tessellation GS 在表现和网格重建任务上，LPIPS降低了29.1%，Chamfer距离减少了49.2%，优于之前的SOTA方法。

Conclusion: Tessellation GS 通过将2D高斯约束在局部区域并利用网格面上的分层神经特征推断属性，显著提升了动态场景重建的性能，特别是在稀疏视图和动态场景重建中表现优异。

Abstract: 3D Gaussian Splatting (GS) enables highly photorealistic scene reconstruction from posed image sequences but struggles with viewpoint extrapolation due to its anisotropic nature, leading to overfitting and poor generalization, particularly in sparse-view and dynamic scene reconstruction. We propose Tessellation GS, a structured 2D GS approach anchored on mesh faces, to reconstruct dynamic scenes from a single continuously moving or static camera. Our method constrains 2D Gaussians to localized regions and infers their attributes via hierarchical neural features on mesh faces. Gaussian subdivision is guided by an adaptive face subdivision strategy driven by a detail-aware loss function. Additionally, we leverage priors from a reconstruction foundation model to initialize Gaussian deformations, enabling robust reconstruction of general dynamic objects from a single static camera, previously extremely challenging for optimization-based methods. Our method outperforms previous SOTA method, reducing LPIPS by 29.1% and Chamfer distance by 49.2% on appearance and mesh reconstruction tasks.

</details>


### [189] [LogicCBMs: Logic-Enhanced Concept-Based Learning](https://arxiv.org/abs/2512.07383)
*Deepika SN Vemuri,Gautham Bellamkonda,Aditya Pola,Vineeth N Balasubramanian*

Main category: cs.CV

TL;DR: LogicCBM通过可微逻辑操作增强概念瓶颈模型，提升了准确性、干预效果和可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统概念瓶颈模型（CBMs）的线性组合方式限制了模型的表达能力，无法捕捉概念间的复杂关系。

Method: 提出了一种逻辑模块，将学习到的概念通过可微逻辑操作连接起来，使LogicCBM能够利用多种逻辑操作生成最终预测，同时保持端到端可学习性。

Result: 在知名基准和合成数据集上的实证研究表明，LogicCBM具有更高的准确性、有效的干预能力和高度可解释性。

Conclusion: LogicCBM通过引入逻辑模块，超越了传统概念瓶颈模型的线性组合限制，显著提升了模型的准确性、干预效果和可解释性。

Abstract: Concept Bottleneck Models (CBMs) provide a basis for semantic abstractions within a neural network architecture. Such models have primarily been seen through the lens of interpretability so far, wherein they offer transparency by inferring predictions as a linear combination of semantic concepts. However, a linear combination is inherently limiting. So we propose the enhancement of concept-based learning models through propositional logic. We introduce a logic module that is carefully designed to connect the learned concepts from CBMs through differentiable logic operations, such that our proposed LogicCBM can go beyond simple weighted combinations of concepts to leverage various logical operations to yield the final predictions, while maintaining end-to-end learnability. Composing concepts using a set of logic operators enables the model to capture inter-concept relations, while simultaneously improving the expressivity of the model in terms of logic operations. Our empirical studies on well-known benchmarks and synthetic datasets demonstrate that these models have better accuracy, perform effective interventions and are highly interpretable.

</details>


### [190] [How Far are Modern Trackers from UAV-Anti-UAV? A Million-Scale Benchmark and New Baseline](https://arxiv.org/abs/2512.07385)
*Chunhui Zhang,Li Liu,Zhipeng Zhang,Yong Wang,Hao Wen,Xi Zhou,Shiming Ge,Yanfeng Wang*

Main category: cs.CV

TL;DR: 论文提出UAV-Anti-UAV任务，构建百万级数据集，并提出MambaSTS方法，实验显示该领域仍有改进空间。


<details>
  <summary>Details</summary>
Motivation: 现有反无人机技术主要基于固定地面摄像头，缺乏对移动无人机平台跟踪目标的研究。为填补这一空白，提出UAV-Anti-UAV任务。

Method: 提出MambaSTS方法，结合Mamba和Transformer模型学习全局语义和空间特征，利用状态空间模型的长序列建模能力，通过时间令牌传播机制建立视频级长期上下文。

Result: 在UAV-Anti-UAV数据集上验证了MambaSTS方法的有效性，并对50种现代深度跟踪算法进行了评估，显示该领域仍有改进空间。

Conclusion: 该论文提出了一个名为UAV-Anti-UAV的新多模态视觉跟踪任务，并构建了一个百万级数据集。通过实验验证了MambaSTS方法的有效性，表明该领域仍有改进空间。

Abstract: Unmanned Aerial Vehicles (UAVs) offer wide-ranging applications but also pose significant safety and privacy violation risks in areas like airport and infrastructure inspection, spurring the rapid development of Anti-UAV technologies in recent years. However, current Anti-UAV research primarily focuses on RGB, infrared (IR), or RGB-IR videos captured by fixed ground cameras, with little attention to tracking target UAVs from another moving UAV platform. To fill this gap, we propose a new multi-modal visual tracking task termed UAV-Anti-UAV, which involves a pursuer UAV tracking a target adversarial UAV in the video stream. Compared to existing Anti-UAV tasks, UAV-Anti-UAV is more challenging due to severe dual-dynamic disturbances caused by the rapid motion of both the capturing platform and the target. To advance research in this domain, we construct a million-scale dataset consisting of 1,810 videos, each manually annotated with bounding boxes, a language prompt, and 15 tracking attributes. Furthermore, we propose MambaSTS, a Mamba-based baseline method for UAV-Anti-UAV tracking, which enables integrated spatial-temporal-semantic learning. Specifically, we employ Mamba and Transformer models to learn global semantic and spatial features, respectively, and leverage the state space model's strength in long-sequence modeling to establish video-level long-term context via a temporal token propagation mechanism. We conduct experiments on the UAV-Anti-UAV dataset to validate the effectiveness of our method. A thorough experimental evaluation of 50 modern deep tracking algorithms demonstrates that there is still significant room for improvement in the UAV-Anti-UAV domain. The dataset and codes will be available at {\color{magenta}https://github.com/983632847/Awesome-Multimodal-Object-Tracking}.

</details>


### [191] [GlimmerNet: A Lightweight Grouped Dilated Depthwise Convolutions for UAV-Based Emergency Monitoring](https://arxiv.org/abs/2512.07391)
*Đorđe Nedeljković*

Main category: cs.CV

TL;DR: GlimmerNet是一种超轻量卷积网络，通过分组膨胀深度卷积和高效特征融合，在低计算成本下实现强全局感知，适用于资源受限的UAV平台。


<details>
  <summary>Details</summary>
Motivation: 尽管Vision Transformers通过自注意力机制增强了全局上下文理解，但计算开销大。本文旨在在不依赖高计算成本组件的情况下保持强全局感知。

Method: 提出了GlimmerNet，采用Grouped Dilated Depthwise Convolutions（GDBlocks）分组不同膨胀率的通道进行多尺度特征提取，并通过Aggregator模块高效融合跨组表示。

Result: GlimmerNet仅需31K参数，比最新基线减少29%的FLOPs，在AIDERv2数据集上达到0.966的加权F1-score，刷新了实时紧急监测的精度-效率权衡记录。

Conclusion: GlimmerNet通过创新的GDBlocks和Aggregator模块，在不增加计算成本的情况下实现了高效的全局感知，为资源受限的UAV平台设定了新的精度-效率权衡前沿。

Abstract: Convolutional Neural Networks (CNNs) have proven highly effective for edge and mobile vision tasks due to their computational efficiency. While many recent works seek to enhance CNNs with global contextual understanding via self-attention-based Vision Transformers, these approaches often introduce significant computational overhead. In this work, we demonstrate that it is possible to retain strong global perception without relying on computationally expensive components. We present GlimmerNet, an ultra-lightweight convolutional network built on the principle of separating receptive field diversity from feature recombination. GlimmerNet introduces Grouped Dilated Depthwise Convolutions(GDBlocks), which partition channels into groups with distinct dilation rates, enabling multi-scale feature extraction at no additional parameter cost. To fuse these features efficiently, we design a novel Aggregator module that recombines cross-group representations using grouped pointwise convolution, significantly lowering parameter overhead. With just 31K parameters and 29% fewer FLOPs than the most recent baseline, GlimmerNet achieves a new state-of-the-art weighted F1-score of 0.966 on the UAV-focused AIDERv2 dataset. These results establish a new accuracy-efficiency trade-off frontier for real-time emergency monitoring on resource-constrained UAV platforms. Our implementation is publicly available at https://github.com/djordjened92/gdd-cnn.

</details>


### [192] [Reconstructing Objects along Hand Interaction Timelines in Egocentric Video](https://arxiv.org/abs/2512.07394)
*Zhifan Zhu,Siddhant Bansal,Shashank Tripathi,Dima Damen*

Main category: cs.CV

TL;DR: COP框架通过约束优化和姿态传播，显著提升稳定抓取和HIT重建效果，无需3D真实数据。


<details>
  <summary>Details</summary>
Motivation: 研究稳定抓取场景下的物体重建，以解决缺乏3D真实数据时的评估难题。

Method: 提出了Constrained Optimisation and Propagation (COP)框架，通过建模HIT中的姿态约束并沿时间线传播物体姿态。

Result: 在HOT3D和EPIC-Kitchens数据集上，COP分别提升了稳定抓取重建6.2-11.3%和HIT重建24.5%。

Conclusion: COP框架通过约束姿态传播显著提升了稳定抓取和HIT重建的准确性，尤其在缺乏3D真实数据的情况下，利用2D投影误差进行评估。

Abstract: We introduce the task of Reconstructing Objects along Hand Interaction Timelines (ROHIT). We first define the Hand Interaction Timeline (HIT) from a rigid object's perspective. In a HIT, an object is first static relative to the scene, then is held in hand following contact, where its pose changes. This is usually followed by a firm grip during use, before it is released to be static again w.r.t. to the scene. We model these pose constraints over the HIT, and propose to propagate the object's pose along the HIT enabling superior reconstruction using our proposed Constrained Optimisation and Propagation (COP) framework. Importantly, we focus on timelines with stable grasps - i.e. where the hand is stably holding an object, effectively maintaining constant contact during use. This allows us to efficiently annotate, study, and evaluate object reconstruction in videos without 3D ground truth. We evaluate our proposed task, ROHIT, over two egocentric datasets, HOT3D and in-the-wild EPIC-Kitchens. In HOT3D, we curate 1.2K clips of stable grasps. In EPIC-Kitchens, we annotate 2.4K clips of stable grasps including 390 object instances across 9 categories from videos of daily interactions in 141 environments. Without 3D ground truth, we utilise 2D projection error to assess the reconstruction. Quantitatively, COP improves stable grasp reconstruction by 6.2-11.3% and HIT reconstruction by up to 24.5% with constrained pose propagation.

</details>


### [193] [InterAgent: Physics-based Multi-agent Command Execution via Diffusion on Interaction Graphs](https://arxiv.org/abs/2512.07410)
*Bin Li,Ruichi Zhang,Han Liang,Jingyan Zhang,Juze Zhang,Xin Chen,Lan Xu,Jingyi Yu,Jingya Wang*

Main category: cs.CV

TL;DR: InterAgent是一个端到端框架，通过创新的自回归扩散变换器和交互图表示，实现了文本驱动的多代理人形控制，显著提升了交互的物理合理性和语义准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法局限于单代理人形控制，缺乏多代理人形间物理上合理的交互，因此提出了InterAgent框架来填补这一空白。

Method: 提出了一个自回归扩散变换器，配备多流块以解耦感知与动作，并设计了交互图外感知表示和稀疏边缘注意力机制。

Result: InterAgent在实验中表现优异，超越了多个基线方法，实现了最先进的性能，能够仅从文本提示生成连贯、物理合理且语义准确的多代理人形行为。

Conclusion: InterAgent通过其创新的架构和表示方法，显著提升了多代理人形控制的性能和物理合理性，为未来研究提供了有力工具。

Abstract: Humanoid agents are expected to emulate the complex coordination inherent in human social behaviors. However, existing methods are largely confined to single-agent scenarios, overlooking the physically plausible interplay essential for multi-agent interactions. To bridge this gap, we propose InterAgent, the first end-to-end framework for text-driven physics-based multi-agent humanoid control. At its core, we introduce an autoregressive diffusion transformer equipped with multi-stream blocks, which decouples proprioception, exteroception, and action to mitigate cross-modal interference while enabling synergistic coordination. We further propose a novel interaction graph exteroception representation that explicitly captures fine-grained joint-to-joint spatial dependencies to facilitate network learning. Additionally, within it we devise a sparse edge-based attention mechanism that dynamically prunes redundant connections and emphasizes critical inter-agent spatial relations, thereby enhancing the robustness of interaction modeling. Extensive experiments demonstrate that InterAgent consistently outperforms multiple strong baselines, achieving state-of-the-art performance. It enables producing coherent, physically plausible, and semantically faithful multi-agent behaviors from only text prompts. Our code and data will be released to facilitate future research.

</details>


### [194] [Unified Video Editing with Temporal Reasoner](https://arxiv.org/abs/2512.07469)
*Xiangpeng Yang,Ji Xie,Yiyuan Yang,Yan Huang,Min Xu,Qiang Wu*

Main category: cs.CV

TL;DR: VideoCoF通过Chain-of-Frames方法，无需遮罩即可实现精确视频编辑，结合RoPE策略提升性能，数据效率高。


<details>
  <summary>Details</summary>
Motivation: 现有视频编辑方法在精度与统一性之间存在矛盾：专家模型依赖任务特定先验（如遮罩），而统一的时间上下文学习模型缺乏显式空间线索，导致指令到区域映射不精确。

Method: 提出VideoCoF方法，通过预测推理令牌（编辑区域潜在表示）来实现显式推理步骤，并结合RoPE对齐策略确保运动对齐和时长外推。

Result: 仅需50k视频对的数据成本，VideoCoF在VideoCoF-Bench上实现了最先进的性能。

Conclusion: VideoCoF通过引入Chain-of-Frames方法，成功解决了视频编辑中精度与统一性的矛盾，无需用户提供遮罩即可实现精确的指令到区域对齐和细粒度编辑。

Abstract: Existing video editing methods face a critical trade-off: expert models offer precision but rely on task-specific priors like masks, hindering unification; conversely, unified temporal in-context learning models are mask-free but lack explicit spatial cues, leading to weak instruction-to-region mapping and imprecise localization. To resolve this conflict, we propose VideoCoF, a novel Chain-of-Frames approach inspired by Chain-of-Thought reasoning. VideoCoF enforces a ``see, reason, then edit" procedure by compelling the video diffusion model to first predict reasoning tokens (edit-region latents) before generating the target video tokens. This explicit reasoning step removes the need for user-provided masks while achieving precise instruction-to-region alignment and fine-grained video editing. Furthermore, we introduce a RoPE alignment strategy that leverages these reasoning tokens to ensure motion alignment and enable length extrapolation beyond the training duration. We demonstrate that with a minimal data cost of only 50k video pairs, VideoCoF achieves state-of-the-art performance on VideoCoF-Bench, validating the efficiency and effectiveness of our approach. Our code, weight, data are available at https://github.com/knightyxp/VideoCoF.

</details>


### [195] [Single-step Diffusion-based Video Coding with Semantic-Temporal Guidance](https://arxiv.org/abs/2512.07480)
*Naifu Xue,Zhaoyang Jia,Jiahao Li,Bin Li,Zihan Zheng,Yuan Zhang,Yan Lu*

Main category: cs.CV

TL;DR: S2VC是一种单步扩散视频编解码器，通过高效的条件生成框架和语义引导，显著提升低比特率下的视频质量，同时降低采样成本。


<details>
  <summary>Details</summary>
Motivation: 传统和神经视频编解码器在低比特率下的感知质量提升仍面临挑战，现有方法要么生成能力有限，要么采样复杂度高。

Method: 提出S2VC，整合条件编码框架与单步扩散生成器，引入Contextual Semantic Guidance和Temporal Consistency Guidance，以提升生成质量和时间一致性。

Result: 实验表明，S2VC在感知质量上达到领先水平，平均比特率节省52.73%。

Conclusion: S2VC通过结合条件编码框架和高效的单步扩散生成器，在低比特率下实现了高质量的实时视频重建，显著节省了比特率并提升了感知质量。

Abstract: While traditional and neural video codecs (NVCs) have achieved remarkable rate-distortion performance, improving perceptual quality at low bitrates remains challenging. Some NVCs incorporate perceptual or adversarial objectives but still suffer from artifacts due to limited generation capacity, whereas others leverage pretrained diffusion models to improve quality at the cost of heavy sampling complexity. To overcome these challenges, we propose S2VC, a Single-Step diffusion based Video Codec that integrates a conditional coding framework with an efficient single-step diffusion generator, enabling realistic reconstruction at low bitrates with reduced sampling cost. Recognizing the importance of semantic conditioning in single-step diffusion, we introduce Contextual Semantic Guidance to extract frame-adaptive semantics from buffered features. It replaces text captions with efficient, fine-grained conditioning, thereby improving generation realism. In addition, Temporal Consistency Guidance is incorporated into the diffusion U-Net to enforce temporal coherence across frames and ensure stable generation. Extensive experiments show that S2VC delivers state-of-the-art perceptual quality with an average 52.73% bitrate saving over prior perceptual methods, underscoring the promise of single-step diffusion for efficient, high-quality video compression.

</details>


### [196] [Towards Robust DeepFake Detection under Unstable Face Sequences: Adaptive Sparse Graph Embedding with Order-Free Representation and Explicit Laplacian Spectral Prior](https://arxiv.org/abs/2512.07498)
*Chih-Chung Hsu,Shao-Ning Chen,Chia-Ming Lee,Yi-Fang Wang,Yi-Shiuan Chou*

Main category: cs.CV

TL;DR: LR-GCN是一种新型DeepFake检测方法，通过图卷积和谱先验处理噪声或无序面部序列，显著提升鲁棒性和检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有检测器通常假设面部序列时间一致且干净，但在实际场景中，压缩伪影、遮挡和对抗攻击会破坏面部检测，导致无效或错误检测。

Method: 提出了一种拉普拉斯正则化图卷积网络（LR-GCN），构建了无序时序图嵌入（OF-TGE），通过语义亲和力将帧级CNN特征组织成自适应稀疏图，并引入图拉普拉斯谱先验作为高通算子。

Result: 在FF++、Celeb-DFv2和DFDC数据集上的实验表明，LR-GCN在严重全局和局部干扰下（如缺失面部、遮挡和对抗扰动）仍能保持高性能。

Conclusion: LR-GCN通过引入图拉普拉斯谱先验和双级稀疏机制，显著提升了在噪声或无序面部序列中的DeepFake检测鲁棒性，并在多个数据集上达到最先进性能。

Abstract: Ensuring the authenticity of video content remains challenging as DeepFake generation becomes increasingly realistic and robust against detection. Most existing detectors implicitly assume temporally consistent and clean facial sequences, an assumption that rarely holds in real-world scenarios where compression artifacts, occlusions, and adversarial attacks destabilize face detection and often lead to invalid or misdetected faces. To address these challenges, we propose a Laplacian-Regularized Graph Convolutional Network (LR-GCN) that robustly detects DeepFakes from noisy or unordered face sequences, while being trained only on clean facial data. Our method constructs an Order-Free Temporal Graph Embedding (OF-TGE) that organizes frame-wise CNN features into an adaptive sparse graph based on semantic affinities. Unlike traditional methods constrained by strict temporal continuity, OF-TGE captures intrinsic feature consistency across frames, making it resilient to shuffled, missing, or heavily corrupted inputs. We further impose a dual-level sparsity mechanism on both graph structure and node features to suppress the influence of invalid faces. Crucially, we introduce an explicit Graph Laplacian Spectral Prior that acts as a high-pass operator in the graph spectral domain, highlighting structural anomalies and forgery artifacts, which are then consolidated by a low-pass GCN aggregation. This sequential design effectively realizes a task-driven spectral band-pass mechanism that suppresses background information and random noise while preserving manipulation cues. Extensive experiments on FF++, Celeb-DFv2, and DFDC demonstrate that LR-GCN achieves state-of-the-art performance and significantly improved robustness under severe global and local disruptions, including missing faces, occlusions, and adversarially perturbed face detections.

</details>


### [197] [MultiMotion: Multi Subject Video Motion Transfer via Video Diffusion Transformer](https://arxiv.org/abs/2512.07500)
*Penghui Liu,Jiangshan Wang,Yutong Shen,Shanhui Mo,Chenyang Qi,Yue Ma*

Main category: cs.CV

TL;DR: MultiMotion是一种新型统一框架，通过AMF模块和RectPC求解器解决了DiT在多对象运动转移中的问题，表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决Diffusion Transformer (DiT)在多对象视频运动转移中存在的运动纠缠和缺乏对象级控制的问题。

Method: 提出了MultiMotion框架，核心创新是Maskaware Attention Motion Flow (AMF)模块和RectPC高阶预测-校正求解器。

Result: MultiMotion实现了精确、语义对齐且时间一致的多对象运动转移，并保持了DiT的高质量和可扩展性。

Conclusion: MultiMotion通过其创新的AMF模块和RectPC求解器，成功解决了DiT架构在多对象视频运动转移中的挑战，实现了高质量、可扩展的多对象运动转移。

Abstract: Multi-object video motion transfer poses significant challenges for Diffusion Transformer (DiT) architectures due to inherent motion entanglement and lack of object-level control. We present MultiMotion, a novel unified framework that overcomes these limitations. Our core innovation is Maskaware Attention Motion Flow (AMF), which utilizes SAM2 masks to explicitly disentangle and control motion features for multiple objects within the DiT pipeline. Furthermore, we introduce RectPC, a high-order predictor-corrector solver for efficient and accurate sampling, particularly beneficial for multi-entity generation. To facilitate rigorous evaluation, we construct the first benchmark dataset specifically for DiT-based multi-object motion transfer. MultiMotion demonstrably achieves precise, semantically aligned, and temporally coherent motion transfer for multiple distinct objects, maintaining DiT's high quality and scalability. The code is in the supp.

</details>


### [198] [SJD++: Improved Speculative Jacobi Decoding for Training-free Acceleration of Discrete Auto-regressive Text-to-Image Generation](https://arxiv.org/abs/2512.07503)
*Yao Teng,Zhihuan Jiang,Han Shi,Xian Liu,Xuefei Ning,Guohao Dai,Yu Wang,Zhenguo Li,Xihui Liu*

Main category: cs.CV

TL;DR: SJD++是一种无需训练的并行解码算法，显著加速自回归文本到图像生成，保持视觉质量。


<details>
  <summary>Details</summary>
Motivation: 大型自回归模型生成高质量、高分辨率图像速度慢，因需要数百至数千次顺序前向传递进行下一令牌预测。

Method: 提出了一种无需训练的并行解码算法Speculative Jacobi Decoding++（SJD++），结合了Jacobi解码的迭代多令牌预测机制和推测采样的概率性草拟-验证机制，并重用高置信度草拟令牌以进一步加速。

Result: 在多个代表性自回归文本到图像生成模型上的实验表明，SJD++实现了显著的加速效果。

Conclusion: SJD++显著加速了自回归文本到图像生成，实现了2倍至3倍的推理延迟减少和2倍至7倍的步骤压缩，同时保持了视觉质量无显著下降。

Abstract: Large autoregressive models can generate high-quality, high-resolution images but suffer from slow generation speed, because these models require hundreds to thousands of sequential forward passes for next-token prediction during inference. To accelerate autoregressive text-to-image generation, we propose Speculative Jacobi Decoding++ (SJD++), a training-free probabilistic parallel decoding algorithm. Unlike traditional next-token prediction, SJD++ performs multi-token prediction in each forward pass, drastically reducing generation steps. Specifically, it integrates the iterative multi-token prediction mechanism from Jacobi decoding, with the probabilistic drafting-and-verification mechanism from speculative sampling. More importantly, for further acceleration, SJD++ reuses high-confidence draft tokens after each verification phase instead of resampling them all. We conduct extensive experiments on several representative autoregressive text-to-image generation models and demonstrate that SJD++ achieves $2\times$ to $3\times$ inference latency reduction and $2\times$ to $7\times$ step compression, while preserving visual quality with no observable degradation.

</details>


### [199] [ControlVP: Interactive Geometric Refinement of AI-Generated Images with Consistent Vanishing Points](https://arxiv.org/abs/2512.07504)
*Ryota Okumura,Kaede Shiohara,Toshihiko Yamasaki*

Main category: cs.CV

TL;DR: ControlVP是一个用户引导的框架，通过结构指导和几何约束解决文本到图像模型中的消失点不一致问题，提升生成图像的空间真实感。


<details>
  <summary>Details</summary>
Motivation: 解决文本到图像模型中常见的几何不一致问题，特别是消失点不一致，以提升生成场景的结构真实感。

Method: 扩展预训练的扩散模型，引入基于建筑轮廓的结构指导和几何约束，以增强图像边缘与透视线索的对齐。

Result: ControlVP在保持视觉保真度的同时，显著提高了全局几何一致性，尤其适用于需要精确空间结构的应用。

Conclusion: ControlVP框架通过结合用户指导和几何约束，有效改善了生成图像中的消失点不一致问题，提升了空间真实感。

Abstract: Recent text-to-image models, such as Stable Diffusion, have achieved impressive visual quality, yet they often suffer from geometric inconsistencies that undermine the structural realism of generated scenes. One prominent issue is vanishing point inconsistency, where projections of parallel lines fail to converge correctly in 2D space. This leads to structurally implausible geometry that degrades spatial realism, especially in architectural scenes. We propose ControlVP, a user-guided framework for correcting vanishing point inconsistencies in generated images. Our approach extends a pre-trained diffusion model by incorporating structural guidance derived from building contours. We also introduce geometric constraints that explicitly encourage alignment between image edges and perspective cues. Our method enhances global geometric consistency while maintaining visual fidelity comparable to the baselines. This capability is particularly valuable for applications that require accurate spatial structure, such as image-to-3D reconstruction. The dataset and source code are available at https://github.com/RyotaOkumura/ControlVP .

</details>


### [200] [MeshRipple: Structured Autoregressive Generation of Artist-Meshes](https://arxiv.org/abs/2512.07514)
*Junkai Lin,Hang Long,Huipeng Guo,Jielei Zhang,JiaYi Yang,Tianle Guo,Yang Yang,Jianwen Li,Wenxiao Zhang,Matthias Nießner,Wei Yang*

Main category: cs.CV

TL;DR: MeshRipple通过前沿感知BFS标记化和稀疏注意力全局内存，解决了自回归网格生成中的长程依赖问题，生成更完整的网格。


<details>
  <summary>Details</summary>
Motivation: 现有自回归网格生成器因序列化处理导致长程几何依赖断裂，产生空洞和碎片化组件。

Method: MeshRipple采用前沿感知的BFS标记化、扩展预测策略和稀疏注意力全局内存，以解决长程拓扑依赖问题。

Result: MeshRipple能够生成具有高表面保真度和拓扑完整性的网格，性能优于现有基线。

Conclusion: MeshRipple通过前沿感知的BFS标记化、扩展预测策略和稀疏注意力全局内存，显著提升了网格生成的表面保真度和拓扑完整性，优于现有基线方法。

Abstract: Meshes serve as a primary representation for 3D assets. Autoregressive mesh generators serialize faces into sequences and train on truncated segments with sliding-window inference to cope with memory limits. However, this mismatch breaks long-range geometric dependencies, producing holes and fragmented components. To address this critical limitation, we introduce MeshRipple, which expands a mesh outward from an active generation frontier, akin to a ripple on a surface.MeshRipple rests on three key innovations: a frontier-aware BFS tokenization that aligns the generation order with surface topology; an expansive prediction strategy that maintains coherent, connected surface growth; and a sparse-attention global memory that provides an effectively unbounded receptive field to resolve long-range topological dependencies.This integrated design enables MeshRipple to generate meshes with high surface fidelity and topological completeness, outperforming strong recent baselines.

</details>


### [201] [All You Need Are Random Visual Tokens? Demystifying Token Pruning in VLLMs](https://arxiv.org/abs/2512.07580)
*Yahong Wang,Juncheng Wu,Zhangkai Ni,Longzhen Yang,Yihang Liu,Chengmei Yang,Ying Wen,Xianfeng Tang,Hui Liu,Yuyin Zhou,Lianghua He*

Main category: cs.CV

TL;DR: 本文发现视觉令牌在深层网络中信息逐渐消失，提出随机剪枝策略，显著提升剪枝效率与性能。


<details>
  <summary>Details</summary>
Motivation: 发现现有训练无关的剪枝方法在深层网络中表现不佳，假设是由于视觉令牌信息逐渐消失（称为“信息消失”）导致。

Method: 通过量化视觉令牌的信息内容（通过移除令牌后模型输出概率的变化来衡量），分析不同层中视觉令牌的信息分布，提出了随机剪枝策略。

Result: 实验表明，随机剪枝在深层网络中表现优异，结合DivPrune方法在剪枝50%视觉令牌时仍能保持96.9%的性能。

Conclusion: 本文提出了一种基于随机剪枝的简单方法，在深层网络中有效平衡了性能与效率，并通过集成随机剪枝提升了现有方法的性能。

Abstract: Vision Large Language Models (VLLMs) incur high computational costs due to their reliance on hundreds of visual tokens to represent images. While token pruning offers a promising solution for accelerating inference, this paper, however, identifies a key observation: in deeper layers (e.g., beyond the 20th), existing training-free pruning methods perform no better than random pruning. We hypothesize that this degradation is caused by "vanishing token information", where visual tokens progressively lose their salience with increasing network depth. To validate this hypothesis, we quantify a token's information content by measuring the change in the model output probabilities upon its removal. Using this proposed metric, our analysis of the information of visual tokens across layers reveals three key findings: (1) As layers deepen, the information of visual tokens gradually becomes uniform and eventually vanishes at an intermediate layer, which we term as "information horizon", beyond which the visual tokens become redundant; (2) The position of this horizon is not static; it extends deeper for visually intensive tasks, such as Optical Character Recognition (OCR), compared to more general tasks like Visual Question Answering (VQA); (3) This horizon is also strongly correlated with model capacity, as stronger VLLMs (e.g., Qwen2.5-VL) employ deeper visual tokens than weaker models (e.g., LLaVA-1.5). Based on our findings, we show that simple random pruning in deep layers efficiently balances performance and efficiency. Moreover, integrating random pruning consistently enhances existing methods. Using DivPrune with random pruning achieves state-of-the-art results, maintaining 96.9% of Qwen-2.5-VL-7B performance while pruning 50% of visual tokens. The code will be publicly available at https://github.com/YahongWang1/Information-Horizon.

</details>


### [202] [LongCat-Image Technical Report](https://arxiv.org/abs/2512.07584)
*Meituan LongCat Team,Hanghang Ma,Haoxian Tan,Jiale Huang,Junqiang Wu,Jun-Yan He,Lishuai Gao,Songlin Xiao,Xiaoming Wei,Xiaoqi Ma,Xunliang Cai,Yayong Guan,Jie Hu*

Main category: cs.CV

TL;DR: LongCat-Image是一个开创性的开源双语图像生成基础模型，通过严格的数据策略和紧凑设计，在多语言文本渲染、照片级真实感和部署效率方面设定了新标准，并提供了全面的开源生态系统。


<details>
  <summary>Details</summary>
Motivation: 解决当前主流模型在多语言文本渲染、照片级真实感、部署效率和开发者可访问性方面的核心挑战。

Method: 通过严格的数据筛选策略在预训练、中期训练和SFT阶段，以及在RL阶段协调使用精选的奖励模型，实现了模型的卓越性能。

Result: LongCat-Image在文本渲染能力和照片级真实感方面达到新的SOTA，显著提升了审美质量；在汉字渲染方面设定了新的行业标准；通过紧凑设计实现了显著效率提升；在图像编辑方面也取得了SOTA结果。

Conclusion: LongCat-Image通过其开放源代码和全面的生态系统，为开发者和研究人员提供了强大的支持，推动了视觉内容创作的前沿发展。

Abstract: We introduce LongCat-Image, a pioneering open-source and bilingual (Chinese-English) foundation model for image generation, designed to address core challenges in multilingual text rendering, photorealism, deployment efficiency, and developer accessibility prevalent in current leading models. 1) We achieve this through rigorous data curation strategies across the pre-training, mid-training, and SFT stages, complemented by the coordinated use of curated reward models during the RL phase. This strategy establishes the model as a new state-of-the-art (SOTA), delivering superior text-rendering capabilities and remarkable photorealism, and significantly enhancing aesthetic quality. 2) Notably, it sets a new industry standard for Chinese character rendering. By supporting even complex and rare characters, it outperforms both major open-source and commercial solutions in coverage, while also achieving superior accuracy. 3) The model achieves remarkable efficiency through its compact design. With a core diffusion model of only 6B parameters, it is significantly smaller than the nearly 20B or larger Mixture-of-Experts (MoE) architectures common in the field. This ensures minimal VRAM usage and rapid inference, significantly reducing deployment costs. Beyond generation, LongCat-Image also excels in image editing, achieving SOTA results on standard benchmarks with superior editing consistency compared to other open-source works. 4) To fully empower the community, we have established the most comprehensive open-source ecosystem to date. We are releasing not only multiple model versions for text-to-image and image editing, including checkpoints after mid-training and post-training stages, but also the entire toolchain of training procedure. We believe that the openness of LongCat-Image will provide robust support for developers and researchers, pushing the frontiers of visual content creation.

</details>


### [203] [Robust Variational Model Based Tailored UNet: Leveraging Edge Detector and Mean Curvature for Improved Image Segmentation](https://arxiv.org/abs/2512.07590)
*Kaili Qi,Zhongyi Huang,Wenli Yang*

Main category: cs.CV

TL;DR: VM_TUNet结合变分PDE与深度学习，通过物理先验和协作模块提升噪声图像分割性能，平衡效率与效果。


<details>
  <summary>Details</summary>
Motivation: 针对噪声图像分割中边界模糊或断裂的挑战，旨在结合变分PDE与深度学习的优势，提升分割性能。

Method: 提出了一种结合变分方法和深度学习的混合框架VM_TUNet，通过引入物理先验、边缘检测器和平均曲率项到改进的Cahn-Hilliard方程中，结合变分PDE的可解释性和边界平滑优势与深度神经网络的强大表示能力。架构包含两个协作模块：F模块（频域预处理）和T模块（局部计算稳定性保障）。

Result: 在三个基准数据集上的实验表明，该方法在性能和计算效率之间取得了平衡，定量结果和视觉质量优于纯CNN模型，接近基于Transformer的方法。

Conclusion: 本文提出的VM_TUNet框架在噪声图像分割任务中实现了性能与计算效率的平衡，其定量结果与视觉质量均优于纯CNN模型，且接近基于Transformer的方法。

Abstract: To address the challenge of segmenting noisy images with blurred or fragmented boundaries, this paper presents a robust version of Variational Model Based Tailored UNet (VM_TUNet), a hybrid framework that integrates variational methods with deep learning. The proposed approach incorporates physical priors, an edge detector and a mean curvature term, into a modified Cahn-Hilliard equation, aiming to combine the interpretability and boundary-smoothing advantages of variational partial differential equations (PDEs) with the strong representational ability of deep neural networks. The architecture consists of two collaborative modules: an F module, which conducts efficient frequency domain preprocessing to alleviate poor local minima, and a T module, which ensures accurate and stable local computations, backed by a stability estimate. Extensive experiments on three benchmark datasets indicate that the proposed method achieves a balanced trade-off between performance and computational efficiency, which yields competitive quantitative results and improved visual quality compared to pure convolutional neural network (CNN) based models, while achieving performance close to that of transformer-based method with reasonable computational expense.

</details>


### [204] [Online Segment Any 3D Thing as Instance Tracking](https://arxiv.org/abs/2512.07599)
*Hanshi Wang,Zijian Cai,Jin Gao,Yiwei Zhang,Weiming Hu,Ke Wang,Zhipeng Zhang*

Main category: cs.CV

TL;DR: AutoSeg3D将在线3D分割重构为实例跟踪问题，通过时空信息传播和空间一致性学习，显著提升感知性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了动态感知中的时间维度，导致部分视角下的对象理解不完整。AutoSeg3D旨在通过时空信息传播提升感知能力。

Method: 利用对象查询进行时空信息传播，结合长短期实例关联和空间一致性学习，优化VFMs的输出。

Result: 在ScanNet200上超越ESAM 2.8 AP，并在ScanNet、SceneNN和3RScan数据集上表现一致提升。

Conclusion: AutoSeg3D通过重新定义在线3D分割为实例跟踪问题，结合长短期实例关联和空间一致性学习，显著提升了时空感知能力，并在多个数据集上实现了新的最先进性能。

Abstract: Online, real-time, and fine-grained 3D segmentation constitutes a fundamental capability for embodied intelligent agents to perceive and comprehend their operational environments. Recent advancements employ predefined object queries to aggregate semantic information from Vision Foundation Models (VFMs) outputs that are lifted into 3D point clouds, facilitating spatial information propagation through inter-query interactions. Nevertheless, perception is an inherently dynamic process, rendering temporal understanding a critical yet overlooked dimension within these prevailing query-based pipelines. Therefore, to further unlock the temporal environmental perception capabilities of embodied agents, our work reconceptualizes online 3D segmentation as an instance tracking problem (AutoSeg3D). Our core strategy involves utilizing object queries for temporal information propagation, where long-term instance association promotes the coherence of features and object identities, while short-term instance update enriches instant observations. Given that viewpoint variations in embodied robotics often lead to partial object visibility across frames, this mechanism aids the model in developing a holistic object understanding beyond incomplete instantaneous views. Furthermore, we introduce spatial consistency learning to mitigate the fragmentation problem inherent in VFMs, yielding more comprehensive instance information for enhancing the efficacy of both long-term and short-term temporal learning. The temporal information exchange and consistency learning facilitated by these sparse object queries not only enhance spatial comprehension but also circumvent the computational burden associated with dense temporal point cloud interactions. Our method establishes a new state-of-the-art, surpassing ESAM by 2.8 AP on ScanNet200 and delivering consistent gains on ScanNet, SceneNN, and 3RScan datasets.

</details>


### [205] [Decomposition Sampling for Efficient Region Annotations in Active Learning](https://arxiv.org/abs/2512.07606)
*Jingna Qiu,Frauke Wilm,Mathias Öttl,Jonas Utz,Maja Schlereth,Moritz Schillinger,Marc Aubreville,Katharina Breininger*

Main category: cs.CV

TL;DR: DECOMP是一种新的主动学习采样策略，通过分解图像和类置信度指导，显著提升密集预测任务的标注效率和模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决密集预测任务中现有方法的计算和内存成本高、区域选择不相关以及对不确定性采样依赖过重的问题。

Method: 提出分解采样（DECOMP），通过伪标签将图像分解为类特定组件，并从每个类中采样区域，同时利用类预测置信度指导采样过程。

Result: DECOMP在多个任务中一致超越基线方法，特别是在采样少数类区域和提升困难类性能方面表现突出。

Conclusion: DECOMP方法在ROI分类、2D分割和3D分割任务中均优于基线方法，通过更有效地采样少数类区域并提升这些困难类的性能。

Abstract: Active learning improves annotation efficiency by selecting the most informative samples for annotation and model training. While most prior work has focused on selecting informative images for classification tasks, we investigate the more challenging setting of dense prediction, where annotations are more costly and time-intensive, especially in medical imaging. Region-level annotation has been shown to be more efficient than image-level annotation for these tasks. However, existing methods for representative annotation region selection suffer from high computational and memory costs, irrelevant region choices, and heavy reliance on uncertainty sampling. We propose decomposition sampling (DECOMP), a new active learning sampling strategy that addresses these limitations. It enhances annotation diversity by decomposing images into class-specific components using pseudo-labels and sampling regions from each class. Class-wise predictive confidence further guides the sampling process, ensuring that difficult classes receive additional annotations. Across ROI classification, 2-D segmentation, and 3-D segmentation, DECOMP consistently surpasses baseline methods by better sampling minority-class regions and boosting performance on these challenging classes. Code is in https://github.com/JingnaQiu/DECOMP.git.

</details>


### [206] [MoCA: Mixture-of-Components Attention for Scalable Compositional 3D Generation](https://arxiv.org/abs/2512.07628)
*Zhiqi Li,Wenhuan Li,Tengfei Wang,Zhenwei Wang,Junta Wu,Haoyuan Wang,Yunhan Yang,Zehuan Huang,Yang Li,Peidong Liu,Chunchao Guo*

Main category: cs.CV

TL;DR: MoCA通过优化组件选择与压缩机制，解决了组合式3D生成中的扩展性问题，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有部分感知3D生成方法因全局注意力成本随组件数量呈二次增长而导致的扩展性差问题。

Method: 采用基于重要性的组件路由选择top-k相关组件进行稀疏全局注意力计算，以及对不重要组件进行压缩以保留上下文先验。

Result: MoCA在组合式对象和场景生成任务上均优于基线方法。

Conclusion: MoCA通过重要性驱动的组件路由和压缩设计，实现了高效、细粒度的组合式3D资产生成，显著提升了可扩展性。

Abstract: Compositionality is critical for 3D object and scene generation, but existing part-aware 3D generation methods suffer from poor scalability due to quadratic global attention costs when increasing the number of components. In this work, we present MoCA, a compositional 3D generative model with two key designs: (1) importance-based component routing that selects top-k relevant components for sparse global attention, and (2) unimportant components compression that preserve contextual priors of unselected components while reducing computational complexity of global attention. With these designs, MoCA enables efficient, fine-grained compositional 3D asset creation with scalable number of components. Extensive experiments show MoCA outperforms baselines on both compositional object and scene generation tasks. Project page: https://lizhiqi49.github.io/MoCA

</details>


### [207] [Liver Fibrosis Quantification and Analysis: The LiQA Dataset and Baseline Method](https://arxiv.org/abs/2512.07651)
*Yuanye Liu,Hanxiao Zhang,Nannan Shi,Yuxin Shi,Arif Mahmood,Murtaza Taj,Xiahai Zhuang*

Main category: cs.CV

TL;DR: LiQA数据集为肝分割和纤维化分期算法提供基准，挑战赛最佳方法结合半监督学习和多视图共识，显著提升临床模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 肝纤维化是全球重大健康负担，需要准确分期以进行有效临床管理。

Method: 整合半监督学习框架与外部数据进行稳健分割，并采用多视图共识方法与基于类激活图（CAM）的正则化进行分期。

Result: 评估表明，基准方法在复杂现实条件下（如域偏移、缺失模态和空间错位）表现优异。

Conclusion: 利用多源数据和解剖约束显著增强了模型在临床环境中的鲁棒性。

Abstract: Liver fibrosis represents a significant global health burden, necessitating accurate staging for effective clinical management. This report introduces the LiQA (Liver Fibrosis Quantification and Analysis) dataset, established as part of the CARE 2024 challenge. Comprising $440$ patients with multi-phase, multi-center MRI scans, the dataset is curated to benchmark algorithms for Liver Segmentation (LiSeg) and Liver Fibrosis Staging (LiFS) under complex real-world conditions, including domain shifts, missing modalities, and spatial misalignment. We further describe the challenge's top-performing methodology, which integrates a semi-supervised learning framework with external data for robust segmentation, and utilizes a multi-view consensus approach with Class Activation Map (CAM)-based regularization for staging. Evaluation of this baseline demonstrates that leveraging multi-source data and anatomical constraints significantly enhances model robustness in clinical settings.

</details>


### [208] [Optimization-Guided Diffusion for Interactive Scene Generation](https://arxiv.org/abs/2512.07661)
*Shiaho Li,Naisheng Ye,Tianyu Li,Kashyap Chitta,Tuo An,Peng Su,Boyang Wang,Haiou Liu,Chen Lv,Hongyang Li*

Main category: cs.CV

TL;DR: OMEGA是一种优化引导的场景生成框架，通过约束优化和博弈论方法提升生成场景的真实性和可控性，显著改善安全关键事件的生成效果。


<details>
  <summary>Details</summary>
Motivation: 现有的驾驶数据集缺乏安全关键事件，而数据驱动的场景生成模型往往缺乏可控性或违反物理/社会约束，OMEGA旨在解决这些问题。

Method: OMEGA采用优化引导的无训练框架，通过约束优化在扩散采样过程中保持结构一致性和交互感知，并基于博弈论优化生成对抗性场景。

Result: 实验显示OMEGA将物理和行为有效场景的比例从32.35%提升至72.27%，可控性生成的有效场景比例从11%提升至80%，并能生成5倍多的近碰撞帧。

Conclusion: OMEGA框架通过优化引导的扩散采样方法，显著提升了生成场景的真实性、一致性和可控性，尤其在安全关键场景的生成上表现优异。

Abstract: Realistic and diverse multi-agent driving scenes are crucial for evaluating autonomous vehicles, but safety-critical events which are essential for this task are rare and underrepresented in driving datasets. Data-driven scene generation offers a low-cost alternative by synthesizing complex traffic behaviors from existing driving logs. However, existing models often lack controllability or yield samples that violate physical or social constraints, limiting their usability. We present OMEGA, an optimization-guided, training-free framework that enforces structural consistency and interaction awareness during diffusion-based sampling from a scene generation model. OMEGA re-anchors each reverse diffusion step via constrained optimization, steering the generation towards physically plausible and behaviorally coherent trajectories. Building on this framework, we formulate ego-attacker interactions as a game-theoretic optimization in the distribution space, approximating Nash equilibria to generate realistic, safety-critical adversarial scenarios. Experiments on nuPlan and Waymo show that OMEGA improves generation realism, consistency, and controllability, increasing the ratio of physically and behaviorally valid scenes from 32.35% to 72.27% for free exploration capabilities, and from 11% to 80% for controllability-focused generation. Our approach can also generate $5\times$ more near-collision frames with a time-to-collision under three seconds while maintaining the overall scene realism.

</details>


### [209] [EgoCampus: Egocentric Pedestrian Eye Gaze Model and Dataset](https://arxiv.org/abs/2512.07668)
*Ronan John,Aditya Kesari,Vincenzo DiMatteo,Kristin Dana*

Main category: cs.CV

TL;DR: 本文提出EgoCampus数据集和EgoCampusNet方法，用于预测户外行人导航时的注视方向，填补了相关领域的数据和方法空白。


<details>
  <summary>Details</summary>
Motivation: 解决在真实世界导航中预测人类视觉注意力的挑战，尤其是在户外校园环境中，弥补了以往以室内任务为主或缺乏注视信息的局限性。

Method: 开发了EgoCampusNet方法，利用EgoCampus数据集中的多模态数据（包括眼动追踪、RGB摄像头、惯性传感器和GPS）预测户外环境中行人的注视方向。

Result: 提出了EgoCampus数据集，包含25条独特户外路径、6公里范围、80多名行人的注视标注视频，并开发了EgoCampusNet方法用于注视预测。

Conclusion: 本文介绍了EgoCampus数据集和EgoCampusNet方法，为研究真实世界中的视觉注意力提供了新资源，并为未来导航中的注视预测模型研究奠定了基础。

Abstract: We address the challenge of predicting human visual attention during real-world navigation by measuring and modeling egocentric pedestrian eye gaze in an outdoor campus setting. We introduce the EgoCampus dataset, which spans 25 unique outdoor paths over 6 km across a university campus with recordings from more than 80 distinct human pedestrians, resulting in a diverse set of gaze-annotated videos. The system used for collection, Meta's Project Aria glasses, integrates eye tracking, front-facing RGB cameras, inertial sensors, and GPS to provide rich data from the human perspective. Unlike many prior egocentric datasets that focus on indoor tasks or exclude eye gaze information, our work emphasizes visual attention while subjects walk in outdoor campus paths. Using this data, we develop EgoCampusNet, a novel method to predict eye gaze of navigating pedestrians as they move through outdoor environments. Our contributions provide both a new resource for studying real-world attention and a resource for future work in gaze prediction models for navigation. Dataset and code are available upon request, and will be made publicly available at a later date at https://github.com/ComputerVisionRutgers/EgoCampus .

</details>


### [210] [PVeRA: Probabilistic Vector-Based Random Matrix Adaptation](https://arxiv.org/abs/2512.07703)
*Leo Fillioux,Enzo Ferrante,Paul-Henry Cournède,Maria Vakalopoulou,Stergios Christodoulidis*

Main category: cs.CV

TL;DR: PVeRA是VeRA适配器的概率版本，通过修改低秩矩阵处理输入模糊性，在VTAB-1k测试中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 大型基础模型的训练和微调需要大量数据和计算资源，成本高昂。参数高效的适配器方法（如VeRA）通过冻结主干网络并添加少量可训练模块来解决这一问题。PVeRA进一步优化VeRA，引入概率性修改以提升性能。

Method: 提出PVeRA，通过概率方式修改VeRA的低秩矩阵，使其能够处理输入中的模糊性，并支持训练和测试时的不同采样配置。

Result: 在VTAB-1k基准测试中，PVeRA表现优于VeRA及其他适配器。

Conclusion: PVeRA（概率版本的VeRA适配器）通过在训练和测试时采用不同的采样配置，有效处理输入中的固有模糊性，并在VTAB-1k基准测试中表现优于VeRA及其他适配器。

Abstract: Large foundation models have emerged in the last years and are pushing performance boundaries for a variety of tasks. Training or even finetuning such models demands vast datasets and computational resources, which are often scarce and costly. Adaptation methods provide a computationally efficient solution to address these limitations by allowing such models to be finetuned on small amounts of data and computing power. This is achieved by appending new trainable modules to frozen backbones with only a fraction of the trainable parameters and fitting only these modules on novel tasks. Recently, the VeRA adapter was shown to excel in parameter-efficient adaptations by utilizing a pair of frozen random low-rank matrices shared across all layers. In this paper, we propose PVeRA, a probabilistic version of the VeRA adapter, which modifies the low-rank matrices of VeRA in a probabilistic manner. This modification naturally allows handling inherent ambiguities in the input and allows for different sampling configurations during training and testing. A comprehensive evaluation was performed on the VTAB-1k benchmark and seven adapters, with PVeRA outperforming VeRA and other adapters. Our code for training models with PVeRA and benchmarking all adapters is available https://github.com/leofillioux/pvera.

</details>


### [211] [UnCageNet: Tracking and Pose Estimation of Caged Animal](https://arxiv.org/abs/2512.07712)
*Sayak Dutta,Harish Katti,Shashikant Verma,Shanmuganathan Raman*

Main category: cs.CV

TL;DR: 提出三阶段预处理流程（分割、修复、评估），有效消除笼状遮挡对动物追踪和姿态估计的影响，性能恢复至无遮挡水平。


<details>
  <summary>Details</summary>
Motivation: 现有动物追踪和姿态估计系统（如STEP和ViTPose）在处理带有笼状结构和系统性遮挡的图像和视频时性能显著下降，亟需解决这一限制。

Method: 1. 使用具有可调方向滤波器的Gabor增强ResNet-UNet架构进行笼状结构分割；2. 利用CRFill进行内容感知的遮挡区域重建；3. 在未遮挡帧上评估姿态估计和追踪性能。

Result: 实验验证表明，通过该流程去除笼状遮挡后，姿态估计和追踪性能可与无遮挡环境相媲美，关键点检测精度和轨迹一致性也有显著提升。

Conclusion: 通过提出的三阶段预处理流程，能够有效消除笼状结构和系统性遮挡对动物追踪和姿态估计系统性能的影响，使性能达到与无遮挡环境相当的水平。

Abstract: Animal tracking and pose estimation systems, such as STEP (Simultaneous Tracking and Pose Estimation) and ViTPose, experience substantial performance drops when processing images and videos with cage structures and systematic occlusions. We present a three-stage preprocessing pipeline that addresses this limitation through: (1) cage segmentation using a Gabor-enhanced ResNet-UNet architecture with tunable orientation filters, (2) cage inpainting using CRFill for content-aware reconstruction of occluded regions, and (3) evaluation of pose estimation and tracking on the uncaged frames. Our Gabor-enhanced segmentation model leverages orientation-aware features with 72 directional kernels to accurately identify and segment cage structures that severely impair the performance of existing methods. Experimental validation demonstrates that removing cage occlusions through our pipeline enables pose estimation and tracking performance comparable to that in environments without occlusions. We also observe significant improvements in keypoint detection accuracy and trajectory consistency.

</details>


### [212] [ViSA: 3D-Aware Video Shading for Real-Time Upper-Body Avatar Creation](https://arxiv.org/abs/2512.07720)
*Fan Yang,Heyuan Li,Peihao Li,Weihao Yuan,Lingteng Qiu,Chaoyue Song,Cheng Chen,Yisheng He,Shifeng Zhang,Xiaoguang Han,Steven Hoi,Guosheng Lin*

Main category: cs.CV

TL;DR: 提出结合3D重建与视频生成模型的新方法，生成高保真、动态一致的3D虚拟形象，解决纹理模糊和运动僵硬问题，实验显示优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有3D虚拟形象生成方法存在纹理模糊和运动僵硬问题，而生成视频模型虽能合成逼真动态结果，但常出现结构不稳定和身份漂移。结合两者优势可解决这些局限。

Method: 提出了一种新颖框架，利用3D重建模型提供结构和外观先验，并引导实时自回归视频扩散模型进行渲染，从而合成高频、逼真的细节和流畅动态。

Result: 实验表明，该方法显著减少了伪影，在视觉质量上优于主流方法，为实时应用（如游戏和虚拟现实）提供了高效解决方案。

Conclusion: 该方法通过结合3D重建模型的几何稳定性和视频生成模型的动态渲染能力，成功生成了具有高保真外观和动态一致运动的上半身3D虚拟形象，显著减少了现有方法的缺陷。

Abstract: Generating high-fidelity upper-body 3D avatars from one-shot input image remains a significant challenge. Current 3D avatar generation methods, which rely on large reconstruction models, are fast and capable of producing stable body structures, but they often suffer from artifacts such as blurry textures and stiff, unnatural motion. In contrast, generative video models show promising performance by synthesizing photorealistic and dynamic results, but they frequently struggle with unstable behavior, including body structural errors and identity drift. To address these limitations, we propose a novel approach that combines the strengths of both paradigms. Our framework employs a 3D reconstruction model to provide robust structural and appearance priors, which in turn guides a real-time autoregressive video diffusion model for rendering. This process enables the model to synthesize high-frequency, photorealistic details and fluid dynamics in real time, effectively reducing texture blur and motion stiffness while preventing the structural inconsistencies common in video generation methods. By uniting the geometric stability of 3D reconstruction with the generative capabilities of video models, our method produces high-fidelity digital avatars with realistic appearance and dynamic, temporally coherent motion. Experiments demonstrate that our approach significantly reduces artifacts and achieves substantial improvements in visual quality over leading methods, providing a robust and efficient solution for real-time applications such as gaming and virtual reality. Project page: https://lhyfst.github.io/visa

</details>


### [213] [SpatialDreamer: Incentivizing Spatial Reasoning via Active Mental Imagery](https://arxiv.org/abs/2512.07733)
*Meng Cao,Xingyu Li,Xue Liu,Ian Reid,Xiaodan Liang*

Main category: cs.CV

TL;DR: SpatialDreamer通过强化学习和GeoPO方法，提升了MLLMs在复杂空间推理任务中的表现，实现了主动心理模拟。


<details>
  <summary>Details</summary>
Motivation: 尽管MLLMs在场景理解方面有所进展，但在需要心理模拟的复杂空间推理任务中表现仍有限，现有方法缺乏主动心理意象过程。

Method: 提出了SpatialDreamer框架，结合强化学习、主动探索、视觉想象（通过世界模型）和基于证据的推理；针对长序列推理任务中的奖励监督不足问题，提出了GeoPO方法，包括树结构采样和带几何一致性约束的步骤级奖励估计。

Result: 实验表明，SpatialDreamer在多个挑战性基准测试中取得了极具竞争力的结果。

Conclusion: SpatialDreamer通过强化学习框架和GeoPO方法，显著提升了MLLMs在复杂空间推理任务中的表现，标志着在人类化主动空间心理模拟方面的重要进展。

Abstract: Despite advancements in Multi-modal Large Language Models (MLLMs) for scene understanding, their performance on complex spatial reasoning tasks requiring mental simulation remains significantly limited. Current methods often rely on passive observation of spatial data, failing to internalize an active mental imagery process. To bridge this gap, we propose SpatialDreamer, a reinforcement learning framework that enables spatial reasoning through a closedloop process of active exploration, visual imagination via a world model, and evidence-grounded reasoning. To address the lack of fine-grained reward supervision in longhorizontal reasoning tasks, we propose Geometric Policy Optimization (GeoPO), which introduces tree-structured sampling and step-level reward estimation with geometric consistency constraints. Extensive experiments demonstrate that SpatialDreamer delivers highly competitive results across multiple challenging benchmarks, signifying a critical advancement in human-like active spatial mental simulation for MLLMs.

</details>


### [214] [HLTCOE Evaluation Team at TREC 2025: VQA Track](https://arxiv.org/abs/2512.07738)
*Dengjia Zhang,Charles Weng,Katherine Guerrerio,Yi Lu,Kenton Murray,Alexander Martin,Reno Kriz,Benjamin Van Durme*

Main category: cs.CV

TL;DR: 开发了一个列表学习框架，通过结合生成与判别式排序，提升了视频问答中答案生成的语义精确性和排序稳定性。


<details>
  <summary>Details</summary>
Motivation: 提升视频问答任务中答案生成的语义精确性和排序一致性。

Method: 采用了一种新颖的Masked Pointer Cross-Entropy Loss with Rank Weights目标函数，结合指针式候选答案选择、依赖于排名的权重以及词汇限制下的掩码交叉熵，实现了稳定且可解释的列表优化。

Result: 实验结果表明，该方法在准确性和排序稳定性方面取得了持续提升，特别是在需要时间推理和语义消歧的问题上。

Conclusion: 通过结合生成模型与判别式排序，该方法在生成连贯、细粒度的答案列表方面表现出色，尤其在需要时间推理和语义消歧的问题上取得了稳定的准确性和排序稳定性提升。

Abstract: The HLTCOE Evaluation team participated in TREC VQA's Answer Generation (AG) task, for which we developed a listwise learning framework that aims to improve semantic precision and ranking consistency in answer generation. Given a video-question pair, a base multimodal model first generates multiple candidate answers, which are then reranked using a model trained with a novel Masked Pointer Cross-Entropy Loss with Rank Weights. This objective integrates pointer-based candidate selection, rank-dependent weighting, and masked cross-entropy under vocabulary restriction, enabling stable and interpretable listwise optimization. By bridging generative modeling with discriminative ranking, our method produces coherent, fine-grained answer lists. Experiments reveal consistent gains in accuracy and ranking stability, especially for questions requiring temporal reasoning and semantic disambiguation.

</details>


### [215] [DiffusionDriveV2: Reinforcement Learning-Constrained Truncated Diffusion Modeling in End-to-End Autonomous Driving](https://arxiv.org/abs/2512.07745)
*Jialv Zou,Shaoyu Chen,Bencheng Liao,Zhiyu Zheng,Yuehao Song,Lefei Zhang,Qian Zhang,Wenyu Liu,Xinggang Wang*

Main category: cs.CV

TL;DR: DiffusionDriveV2结合强化学习解决生成扩散模型的模式崩溃问题，在多样性与高质量输出间实现最佳权衡，并在NAVSIM数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 生成扩散模型在端到端自动驾驶中常因模式崩溃生成保守且同质化的行为，DiffusionDriveV2旨在通过强化学习约束低质量模式并探索更优轨迹。

Method: 1. 使用尺度自适应乘性噪声促进广泛探索；2. 采用intra-anchor GRPO和inter-anchor截断GRPO管理优势估计，防止模式崩溃。

Result: DiffusionDriveV2在NAVSIM v1和v2数据集上分别取得91.2 PDMS和85.5 EPDMS的闭环评估成绩，创下新记录。

Conclusion: DiffusionDriveV2通过强化学习解决了多样性输出与一致性高质量之间的困境，实现了最佳权衡，并在NAVSIM数据集上创下了新记录。

Abstract: Generative diffusion models for end-to-end autonomous driving often suffer from mode collapse, tending to generate conservative and homogeneous behaviors. While DiffusionDrive employs predefined anchors representing different driving intentions to partition the action space and generate diverse trajectories, its reliance on imitation learning lacks sufficient constraints, resulting in a dilemma between diversity and consistent high quality. In this work, we propose DiffusionDriveV2, which leverages reinforcement learning to both constrain low-quality modes and explore for superior trajectories. This significantly enhances the overall output quality while preserving the inherent multimodality of its core Gaussian Mixture Model. First, we use scale-adaptive multiplicative noise, ideal for trajectory planning, to promote broad exploration. Second, we employ intra-anchor GRPO to manage advantage estimation among samples generated from a single anchor, and inter-anchor truncated GRPO to incorporate a global perspective across different anchors, preventing improper advantage comparisons between distinct intentions (e.g., turning vs. going straight), which can lead to further mode collapse. DiffusionDriveV2 achieves 91.2 PDMS on the NAVSIM v1 dataset and 85.5 EPDMS on the NAVSIM v2 dataset in closed-loop evaluation with an aligned ResNet-34 backbone, setting a new record. Further experiments validate that our approach resolves the dilemma between diversity and consistent high quality for truncated diffusion models, achieving the best trade-off. Code and model will be available at https://github.com/hustvl/DiffusionDriveV2

</details>


### [216] [Unison: A Fully Automatic, Task-Universal, and Low-Cost Framework for Unified Understanding and Generation](https://arxiv.org/abs/2512.07747)
*Shihao Zhao,Yitong Chen,Zeyinzi Jiang,Bojia Zi,Shaozhe Hao,Yu Liu,Chaojie Mao,Kwan-Yee K. Wong*

Main category: cs.CV

TL;DR: Unison是一种低成本的多模态学习模型，能自动识别任务并提取参数，覆盖多种理解和生成任务，表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么需要大量数据和计算资源，要么任务覆盖有限或生成质量差，且缺乏自动解析输入元信息的能力。

Method: 采用两阶段方案，保留预训练模型的能力，同时赋予模型自动解析用户意图、确定目标任务类型及提取相关元信息的能力。

Result: 实验证明，Unison在低训练成本下能自动识别任务并提取参数，在多种理解和生成任务中表现优异。

Conclusion: Unison模型在低训练成本（仅50万训练样本和50 GPU小时）下，能够准确自动识别任务并提取相关参数，在多种理解和生成任务中表现出色。

Abstract: Unified understanding and generation is a highly appealing research direction in multimodal learning. There exist two approaches: one trains a transformer via an auto-regressive paradigm, and the other adopts a two-stage scheme connecting pre-trained understanding and generative models for alignment fine-tuning. The former demands massive data and computing resources unaffordable for ordinary researchers. Though the latter requires a lower training cost, existing works often suffer from limited task coverage or poor generation quality. Both approaches lack the ability to parse input meta-information (such as task type, image resolution, video duration, etc.) and require manual parameter configuration that is tedious and non-intelligent. In this paper, we propose Unison which adopts the two-stage scheme while preserving the capabilities of the pre-trained models well. With an extremely low training cost, we cover a variety of multimodal understanding tasks, including text, image, and video understanding, as well as diverse generation tasks, such as text-to-visual content generation, editing, controllable generation, and IP-based reference generation. We also equip our model with the ability to automatically parse user intentions, determine the target task type, and accurately extract the meta-information required for the corresponding task. This enables full automation of various multimodal tasks without human intervention. Experiments demonstrate that, under a low-cost setting of only 500k training samples and 50 GPU hours, our model can accurately and automatically identify tasks and extract relevant parameters, and achieve superior performance across a variety of understanding and generation tasks.

</details>


### [217] [Modality-Aware Bias Mitigation and Invariance Learning for Unsupervised Visible-Infrared Person Re-Identification](https://arxiv.org/abs/2512.07760)
*Menglin Wang,Xiaojin Gong,Jiachen Li,Genlin Ji*

Main category: cs.CV

TL;DR: 本文提出了一种无监督可见光-红外行人重识别方法，通过模态感知距离校正和全局原型对齐，显著提升了跨模态关联和表示学习的效果。


<details>
  <summary>Details</summary>
Motivation: 由于可见光和红外模态之间存在显著差异，现有方法在估计可靠的跨模态关联时容易传播局部聚类错误并忽略全局实例级关系。

Method: 通过提出模态感知的Jaccard距离来缓解由模态差异引起的距离偏差，并设计‘分割-对比’策略获取模态特定的全局原型，以在全局关联指导下显式对齐这些原型。

Result: 在基准VI-ReID数据集上，该方法取得了最先进的性能，显著优于现有方法。

Conclusion: 本文提出的方法在无监督可见光-红外行人重识别任务中取得了最先进的性能，显著优于现有方法，验证了其有效性。

Abstract: Unsupervised visible-infrared person re-identification (USVI-ReID) aims to match individuals across visible and infrared cameras without relying on any annotation. Given the significant gap across visible and infrared modality, estimating reliable cross-modality association becomes a major challenge in USVI-ReID. Existing methods usually adopt optimal transport to associate the intra-modality clusters, which is prone to propagating the local cluster errors, and also overlooks global instance-level relations. By mining and attending to the visible-infrared modality bias, this paper focuses on addressing cross-modality learning from two aspects: bias-mitigated global association and modality-invariant representation learning. Motivated by the camera-aware distance rectification in single-modality re-ID, we propose modality-aware Jaccard distance to mitigate the distance bias caused by modality discrepancy, so that more reliable cross-modality associations can be estimated through global clustering. To further improve cross-modality representation learning, a `split-and-contrast' strategy is designed to obtain modality-specific global prototypes. By explicitly aligning these prototypes under global association guidance, modality-invariant yet ID-discriminative representation learning can be achieved. While conceptually simple, our method obtains state-of-the-art performance on benchmark VI-ReID datasets and outperforms existing methods by a significant margin, validating its effectiveness.

</details>


### [218] [GorillaWatch: An Automated System for In-the-Wild Gorilla Re-Identification and Population Monitoring](https://arxiv.org/abs/2512.07776)
*Maximilian Schall,Felix Leonard Knöfel,Noah Elias König,Jan Jonas Kubeler,Maximilian von Klinski,Joan Wilhelm Linnemann,Xiaoshi Liu,Iven Jelle Schlegelmilch,Ole Woyciniuk,Alexandra Schild,Dante Wasmuht,Magdalena Bermejo Espinet,German Illera Basas,Gerard de Melo*

Main category: cs.CV

TL;DR: 研究通过新数据集和GorillaWatch流程，实现了濒危大猩猩的高效自动识别，并公开资源以促进濒危物种监测。


<details>
  <summary>Details</summary>
Motivation: 由于现有方法依赖大量人工识别摄像机捕捉的影像，自动化识别濒危西部低地大猩猩面临缺乏大规模野外视频数据集的挑战。

Method: 研究提出了GorillaWatch流程，结合检测、跟踪和重识别技术，并采用多帧自监督预训练策略和AttnLRP验证模型有效性。

Result: 研究展示了大规模图像主干网络特征聚合优于专用视频架构，并通过时空约束改进了无监督种群计数。

Conclusion: 该研究通过引入三个新数据集和GorillaWatch端到端流程，显著提升了濒危西部低地大猩猩的自动识别效率，并通过公开代码和数据集促进了濒危物种的非侵入式监测。

Abstract: Monitoring critically endangered western lowland gorillas is currently hampered by the immense manual effort required to re-identify individuals from vast archives of camera trap footage. The primary obstacle to automating this process has been the lack of large-scale, "in-the-wild" video datasets suitable for training robust deep learning models. To address this gap, we introduce a comprehensive benchmark with three novel datasets: Gorilla-SPAC-Wild, the largest video dataset for wild primate re-identification to date; Gorilla-Berlin-Zoo, for assessing cross-domain re-identification generalization; and Gorilla-SPAC-MoT, for evaluating multi-object tracking in camera trap footage. Building on these datasets, we present GorillaWatch, an end-to-end pipeline integrating detection, tracking, and re-identification. To exploit temporal information, we introduce a multi-frame self-supervised pretraining strategy that leverages consistency in tracklets to learn domain-specific features without manual labels. To ensure scientific validity, a differentiable adaptation of AttnLRP verifies that our model relies on discriminative biometric traits rather than background correlations. Extensive benchmarking subsequently demonstrates that aggregating features from large-scale image backbones outperforms specialized video architectures. Finally, we address unsupervised population counting by integrating spatiotemporal constraints into standard clustering to mitigate over-segmentation. We publicly release all code and datasets to facilitate scalable, non-invasive monitoring of endangered species

</details>


### [219] [Distribution Matching Variational AutoEncoder](https://arxiv.org/abs/2512.07778)
*Sen Ye,Jianning Pei,Mengde Xu,Shuyang Gu,Chunyu Wang,Liwei Wang,Han Hu*

Main category: cs.CV

TL;DR: DMVAE通过显式对齐潜在分布与参考分布，优化了生成模型的潜在空间结构，显著提升了图像合成的效率与质量。


<details>
  <summary>Details</summary>
Motivation: 现有的潜在空间生成模型（如VAEs和基础模型对齐编码器）隐含地约束潜在空间，但未明确塑造其分布，导致不清楚哪种分布最适合建模。

Method: 提出了Distribution-Matching VAE（DMVAE），通过分布匹配约束显式地将编码器的潜在分布与任意参考分布对齐。

Result: 发现自监督学习（SSL）衍生的分布在重建保真度和建模效率之间提供了极佳的平衡，在仅64个训练周期内达到gFID 3.2。

Conclusion: 选择合适的潜在分布结构（通过分布级对齐实现）是弥合易于建模的潜在空间与高保真图像合成之间差距的关键。

Abstract: Most visual generative models compress images into a latent space before applying diffusion or autoregressive modelling. Yet, existing approaches such as VAEs and foundation model aligned encoders implicitly constrain the latent space without explicitly shaping its distribution, making it unclear which types of distributions are optimal for modeling. We introduce \textbf{Distribution-Matching VAE} (\textbf{DMVAE}), which explicitly aligns the encoder's latent distribution with an arbitrary reference distribution via a distribution matching constraint. This generalizes beyond the Gaussian prior of conventional VAEs, enabling alignment with distributions derived from self-supervised features, diffusion noise, or other prior distributions. With DMVAE, we can systematically investigate which latent distributions are more conducive to modeling, and we find that SSL-derived distributions provide an excellent balance between reconstruction fidelity and modeling efficiency, reaching gFID equals 3.2 on ImageNet with only 64 training epochs. Our results suggest that choosing a suitable latent distribution structure (achieved via distribution-level alignment), rather than relying on fixed priors, is key to bridging the gap between easy-to-model latents and high-fidelity image synthesis. Code is avaliable at https://github.com/sen-ye/dmvae.

</details>


### [220] [OneStory: Coherent Multi-Shot Video Generation with Adaptive Memory](https://arxiv.org/abs/2512.07802)
*Zhaochong An,Menglin Jia,Haonan Qiu,Zijian Zhou,Xiaoke Huang,Zhiheng Liu,Weiming Ren,Kumara Kahatapitiya,Ding Liu,Sen He,Chenyang Zhang,Tao Xiang,Fanny Yang,Serge Belongie,Tian Xie*

Main category: cs.CV

TL;DR: OneStory通过全局跨镜头上下文建模和预训练I2V模型，实现了高质量的多镜头视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有的多镜头视频生成方法难以有效建模长距离跨镜头上下文，导致复杂叙事下的性能下降。

Method: OneStory将多镜头视频生成重新定义为下一个镜头的生成任务，利用预训练的图像到视频（I2V）模型进行视觉条件化，并引入了帧选择模块和自适应条件模块。

Result: 在60K数据集上微调后，OneStory在文本和图像条件设置下均实现了最先进的叙事连贯性。

Conclusion: OneStory通过全局且紧凑的跨镜头上下文建模，实现了在多样化和复杂场景下的最先进叙事连贯性，支持可控且沉浸式的长视频叙事生成。

Abstract: Storytelling in real-world videos often unfolds through multiple shots -- discontinuous yet semantically connected clips that together convey a coherent narrative. However, existing multi-shot video generation (MSV) methods struggle to effectively model long-range cross-shot context, as they rely on limited temporal windows or single keyframe conditioning, leading to degraded performance under complex narratives. In this work, we propose OneStory, enabling global yet compact cross-shot context modeling for consistent and scalable narrative generation. OneStory reformulates MSV as a next-shot generation task, enabling autoregressive shot synthesis while leveraging pretrained image-to-video (I2V) models for strong visual conditioning. We introduce two key modules: a Frame Selection module that constructs a semantically-relevant global memory based on informative frames from prior shots, and an Adaptive Conditioner that performs importance-guided patchification to generate compact context for direct conditioning. We further curate a high-quality multi-shot dataset with referential captions to mirror real-world storytelling patterns, and design effective training strategies under the next-shot paradigm. Finetuned from a pretrained I2V model on our curated 60K dataset, OneStory achieves state-of-the-art narrative coherence across diverse and complex scenes in both text- and image-conditioned settings, enabling controllable and immersive long-form video storytelling.

</details>


### [221] [Multi-view Pyramid Transformer: Look Coarser to See Broader](https://arxiv.org/abs/2512.07806)
*Gyeongjin Kang,Seungkwon Yang,Seungtae Nam,Younggeun Lee,Jungwoo Kim,Eunbyung Park*

Main category: cs.CV

TL;DR: MVP是一种多视角变换器架构，通过双层次结构高效重建大型3D场景，结合3D高斯泼溅实现高质量重建。


<details>
  <summary>Details</summary>
Motivation: 旨在通过多视角变换器架构，直接从数十到数百张图像中高效重建大型3D场景。

Method: MVP基于局部到全局的视图间层次结构和细到粗的视图内层次结构，逐步扩展模型视角并聚合空间表示。

Result: 在多样化数据集上验证了MVP的高效性和可扩展性，实现了高质量的场景重建。

Conclusion: MVP结合3D高斯泼溅作为底层3D表示，在保持高效和可扩展性的同时，实现了最先进的通用重建质量。

Abstract: We propose Multi-view Pyramid Transformer (MVP), a scalable multi-view transformer architecture that directly reconstructs large 3D scenes from tens to hundreds of images in a single forward pass. Drawing on the idea of ``looking broader to see the whole, looking finer to see the details," MVP is built on two core design principles: 1) a local-to-global inter-view hierarchy that gradually broadens the model's perspective from local views to groups and ultimately the full scene, and 2) a fine-to-coarse intra-view hierarchy that starts from detailed spatial representations and progressively aggregates them into compact, information-dense tokens. This dual hierarchy achieves both computational efficiency and representational richness, enabling fast reconstruction of large and complex scenes. We validate MVP on diverse datasets and show that, when coupled with 3D Gaussian Splatting as the underlying 3D representation, it achieves state-of-the-art generalizable reconstruction quality while maintaining high efficiency and scalability across a wide range of view configurations.

</details>


### [222] [OpenVE-3M: A Large-Scale High-Quality Dataset for Instruction-Guided Video Editing](https://arxiv.org/abs/2512.07826)
*Haoyang He,Jie Wang,Jiangning Zhang,Zhucun Xue,Xingyuan Bu,Qiangpeng Yang,Shilei Wen,Lei Xie*

Main category: cs.CV

TL;DR: OpenVE-3M是一个大规模、高质量的指令式视频编辑数据集，OpenVE-Bench为统一基准，OpenVE-Edit模型表现卓越。


<details>
  <summary>Details</summary>
Motivation: 现有指令式视频编辑数据集规模小、质量低，缺乏统一基准测试。

Method: 通过精心设计的数据流水线和严格的质量过滤生成OpenVE-3M数据集，并构建OpenVE-Bench作为统一基准测试。

Result: OpenVE-3M在规模、编辑类型多样性、指令长度和整体质量上超越现有开源数据集，OpenVE-Edit模型在OpenVE-Bench上达到新SOTA。

Conclusion: OpenVE-3M和OpenVE-Bench的引入填补了指令式视频编辑领域的数据集和基准测试的空白，OpenVE-Edit模型展示了在该领域的卓越性能。

Abstract: The quality and diversity of instruction-based image editing datasets are continuously increasing, yet large-scale, high-quality datasets for instruction-based video editing remain scarce. To address this gap, we introduce OpenVE-3M, an open-source, large-scale, and high-quality dataset for instruction-based video editing. It comprises two primary categories: spatially-aligned edits (Global Style, Background Change, Local Change, Local Remove, Local Add, and Subtitles Edit) and non-spatially-aligned edits (Camera Multi-Shot Edit and Creative Edit). All edit types are generated via a meticulously designed data pipeline with rigorous quality filtering. OpenVE-3M surpasses existing open-source datasets in terms of scale, diversity of edit types, instruction length, and overall quality. Furthermore, to address the lack of a unified benchmark in the field, we construct OpenVE-Bench, containing 431 video-edit pairs that cover a diverse range of editing tasks with three key metrics highly aligned with human judgment. We present OpenVE-Edit, a 5B model trained on our dataset that demonstrates remarkable efficiency and effectiveness by setting a new state-of-the-art on OpenVE-Bench, outperforming all prior open-source models including a 14B baseline. Project page is at https://github.com/lewandofskee/OpenVE.

</details>


### [223] [UnityVideo: Unified Multi-Modal Multi-Task Learning for Enhancing World-Aware Video Generation](https://arxiv.org/abs/2512.07831)
*Jiehui Huang,Yuechen Zhang,Xu He,Yuan Gao,Zhi Cen,Bin Xia,Yan Zhou,Xin Tao,Pengfei Wan,Jiaya Jia*

Main category: cs.CV

TL;DR: UnityVideo是一个多模态视频生成框架，通过动态噪声和模态切换器提升生成质量，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型受限于单模态条件，缺乏跨模态交互和模态多样性，限制了其对世界的全面理解。

Method: UnityVideo框架结合了动态噪声处理和模态切换器，通过模块化参数和上下文学习实现多模态统一处理。

Result: UnityVideo在零样本泛化能力上表现优异，生成的视频质量高、一致性强，且更符合物理世界约束。

Conclusion: UnityVideo通过联合多模态学习和动态噪声处理，显著提升了视频生成的质量和一致性，同时增强了与物理世界约束的对齐能力。

Abstract: Recent video generation models demonstrate impressive synthesis capabilities but remain limited by single-modality conditioning, constraining their holistic world understanding. This stems from insufficient cross-modal interaction and limited modal diversity for comprehensive world knowledge representation. To address these limitations, we introduce UnityVideo, a unified framework for world-aware video generation that jointly learns across multiple modalities (segmentation masks, human skeletons, DensePose, optical flow, and depth maps) and training paradigms. Our approach features two core components: (1) dynamic noising to unify heterogeneous training paradigms, and (2) a modality switcher with an in-context learner that enables unified processing via modular parameters and contextual learning. We contribute a large-scale unified dataset with 1.3M samples. Through joint optimization, UnityVideo accelerates convergence and significantly enhances zero-shot generalization to unseen data. We demonstrate that UnityVideo achieves superior video quality, consistency, and improved alignment with physical world constraints. Code and data can be found at: https://github.com/dvlab-research/UnityVideo

</details>


### [224] [Voxify3D: Pixel Art Meets Volumetric Rendering](https://arxiv.org/abs/2512.07834)
*Yi-Chuan Huang,Jiewen Chan,Hao-Jen Chien,Yu-Lun Liu*

Main category: cs.CV

TL;DR: Voxify3D是一个两阶段可微分框架，通过正交监督、CLIP对齐和调色板量化，解决了3D网格到体素艺术的生成挑战。


<details>
  <summary>Details</summary>
Motivation: 现有方法在几何简化或像素级精确美学上表现不足，难以满足体素艺术的需求。

Method: Voxify3D采用两阶段可微分框架，结合正交像素艺术监督、基于补丁的CLIP对齐和调色板约束的Gumbel-Softmax量化。

Result: 实验显示Voxify3D在CLIP-IQA得分（37.12）和用户偏好（77.90%）上表现优异，支持多样角色和可控抽象。

Conclusion: Voxify3D通过两阶段可微分框架成功解决了3D网格到体素艺术的自动化生成问题，在几何抽象、语义保留和离散颜色一致性方面表现出色。

Abstract: Voxel art is a distinctive stylization widely used in games and digital media, yet automated generation from 3D meshes remains challenging due to conflicting requirements of geometric abstraction, semantic preservation, and discrete color coherence. Existing methods either over-simplify geometry or fail to achieve the pixel-precise, palette-constrained aesthetics of voxel art. We introduce Voxify3D, a differentiable two-stage framework bridging 3D mesh optimization with 2D pixel art supervision. Our core innovation lies in the synergistic integration of three components: (1) orthographic pixel art supervision that eliminates perspective distortion for precise voxel-pixel alignment; (2) patch-based CLIP alignment that preserves semantics across discretization levels; (3) palette-constrained Gumbel-Softmax quantization enabling differentiable optimization over discrete color spaces with controllable palette strategies. This integration addresses fundamental challenges: semantic preservation under extreme discretization, pixel-art aesthetics through volumetric rendering, and end-to-end discrete optimization. Experiments show superior performance (37.12 CLIP-IQA, 77.90\% user preference) across diverse characters and controllable abstraction (2-8 colors, 20x-50x resolutions). Project page: https://yichuanh.github.io/Voxify-3D/

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [225] [Auto-SPT: Automating Semantic Preserving Transformations for Code](https://arxiv.org/abs/2512.06042)
*Ashish Hooda,Mihai Christodorescu,Chuangang Ren,Aaron Wilson,Kassem Fawaz,Somesh Jha*

Main category: cs.SE

TL;DR: Auto-SPT利用LLMs自动生成多样化的语义保持变换，提升代码克隆检测模型对现实代码变换的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现实代码常经历语义保持的变换（如重构、压缩等），而现有模型训练数据多为干净结构化代码，导致训练与测试数据存在差距。

Method: 提出Auto-SPT框架，利用大型语言模型（LLMs）自动生成语义保持变换（SPTs），并通过组合这些变换增强数据多样性。

Result: Auto-SPT生成的SPTs比现有方法更多样化，能显著降低最先进代码克隆检测器的性能，并可用于增强训练数据集。

Conclusion: Auto-SPT通过生成多样化的语义保持变换（SPTs），显著提升了代码克隆检测模型对现实世界中对抗性代码变换的鲁棒性。

Abstract: Machine learning (ML) models for code clone detection determine whether two pieces of code are semantically equivalent, which in turn is a key building block for software-engineering tasks like refactoring and security tasks like vulnerability and malware detection. While these models are predominantly trained on clean, structured code datasets, real-world code often undergoes a variety of semantic-preserving transformations, including refactoring, minification, automated formatting, and compiler optimizations. To address this critical gap between training and test data, we propose Auto-SPT, a novel framework to automatically construct synthetic-data generators for code. Auto-SPT is designed to produce Semantic Preserving Transformations (SPTs) that alter a program's syntactic structure while preserving its functionality and is instantiated on top of Large Language Models (LLMs). In particular, we use LLMs to craft a diverse set of SPTs, generate strong implementations for these SPTs, and compose them to result into strong transformations. Our formal analysis shows that the diversity of SPTs impacts the strength of their composition. We then empirically demonstrate that Auto-SPT generates more diverse SPTs than existing approaches and these SPTs significantly drop the performance of state-of-the-art code clone detectors. Further experiments show Auto-SPT can be used to enhance code datasets for training, to produce code-clone detection models that are robust to real-world, adversarial code transformations.

</details>


### [226] [Beyond Prototyping: Autonomous, Enterprise-Grade Frontend Development from Pixel to Production via a Specialized Multi-Agent Framework](https://arxiv.org/abs/2512.06046)
*Ramprasath Ganesaraja,Swathika N,Saravanan AP,Kamalkumar Rathinasamy,Chetana Amancharla,Rahul Das,Sahil Dilip Panse,Aditya Batwe,Dileep Vijayan,Veena Ashok,Thanushree A P,Kausthubh J Rao,Alden Olivero,Roshan,Rajeshwar Reddy Manthena,Asmitha Yuga Sre A,Harsh Tripathi,Suganya Selvaraj,Vito Chin,Kasthuri Rangan Bhaskar,Kasthuri Rangan Bhaskar,Venkatraman R,Sajit Vijayakumar*

Main category: cs.SE

TL;DR: AI4UI是一个专注于企业级应用UI代码生成的框架，通过全自动化和人机协作，显著提升开发效率和质量。


<details>
  <summary>Details</summary>
Motivation: 为解决企业级应用开发中UI代码的生产就绪性问题，如安全性、可扩展性、合规性和可维护性，设计了AI4UI框架。

Method: AI4UI通过结合生成式AI友好的Figma语法、领域知识图谱、安全代码集成策略和专家驱动的架构模板，实现全自动化的UI代码生成。

Result: 在基准测试中，AI4UI实现了97.24%的平台兼容性、87.10%的编译成功率、86.98%的安全合规性、78.00%的功能实现成功率、73.50%的代码审查质量和73.36%的UI/UX一致性。

Conclusion: AI4UI框架在大型企业级应用中展现出高效性和竞争力，能够显著缩短交付时间并提升代码质量。

Abstract: We present AI4UI, a framework of autonomous front-end development agents purpose-built to meet the rigorous requirements of enterprise-grade application delivery. Unlike general-purpose code assistants designed for rapid prototyping, AI4UI focuses on production readiness delivering secure, scalable, compliant, and maintainable UI code integrated seamlessly into enterprise workflows. AI4UI operates with targeted human-in-the-loop involvement: at the design stage, developers embed a Gen-AI-friendly grammar into Figma prototypes to encode requirements for precise interpretation; and at the post processing stage, domain experts refine outputs for nuanced design adjustments, domain-specific optimizations, and compliance needs. Between these stages, AI4UI runs fully autonomously, converting designs into engineering-ready UI code. Technical contributions include a Figma grammar for autonomous interpretation, domain-aware knowledge graphs, a secure abstract/package code integration strategy, expertise driven architecture templates, and a change-oriented workflow coordinated by specialized agent roles. In large-scale benchmarks against industry baselines and leading competitor systems, AI4UI achieved 97.24% platform compatibility, 87.10% compilation success, 86.98% security compliance, 78.00% feature implementation success, 73.50% code-review quality, and 73.36% UI/UX consistency. In blind preference studies with 200 expert evaluators, AI4UI emerged as one of the leaders demonstrating strong competitive standing among leading solutions. Operating asynchronously, AI4UI generates thousands of validated UI screens in weeks rather than months, compressing delivery timeline

</details>


### [227] [Reinforcement Learning Integrated Agentic RAG for Software Test Cases Authoring](https://arxiv.org/abs/2512.06060)
*Mohanakrishnan Hariharan*

Main category: cs.SE

TL;DR: 该论文提出了一个结合强化学习和自主代理的框架，通过QE反馈持续优化测试用例生成，显著提升了准确率和缺陷检测率。


<details>
  <summary>Details</summary>
Motivation: 传统系统使用大型语言模型（LLM）从静态知识库生成测试用例，其性能提升能力有限。

Method: 提出了一个结合强化学习（RL）和自主代理的框架，利用PPO和DQN算法，通过QE反馈、评估和缺陷发现结果来自动改进测试用例生成策略。

Result: 在企业Apple项目上的实验验证显示，测试生成准确率提高了2.4%（从94.8%到97.2%），缺陷检测率提高了10.8%。

Conclusion: 该框架通过结合QE专家的反馈，建立了一个持续的知识精炼循环，逐步提升测试用例的质量，从而增强而非取代人类的测试能力。

Abstract: This paper introduces a framework that integrates reinforcement learning (RL) with autonomous agents to enable continuous improvement in the automated process of software test cases authoring from business requirement documents within Quality Engineering (QE) workflows. Conventional systems employing Large Language Models (LLMs) generate test cases from static knowledge bases, which fundamentally limits their capacity to enhance performance over time. Our proposed Reinforcement Infused Agentic RAG (Retrieve, Augment, Generate) framework overcomes this limitation by employing AI agents that learn from QE feedback, assessments, and defect discovery outcomes to automatically improve their test case generation strategies. The system combines specialized agents with a hybrid vector-graph knowledge base that stores and retrieves software testing knowledge. Through advanced RL algorithms, specifically Proximal Policy Optimization (PPO) and Deep Q-Networks (DQN), these agents optimize their behavior based on QE-reported test effectiveness, defect detection rates, and workflow metrics. As QEs execute AI-generated test cases and provide feedback, the system learns from this expert guidance to improve future iterations. Experimental validation on enterprise Apple projects yielded substantive improvements: a 2.4% increase in test generation accuracy (from 94.8% to 97.2%), and a 10.8% improvement in defect detection rates. The framework establishes a continuous knowledge refinement loop driven by QE expertise, resulting in progressively superior test case quality that enhances, rather than replaces, human testing capabilities.

</details>


### [228] [Toward Patch Robustness Certification and Detection for Deep Learning Systems Beyond Consistent Samples](https://arxiv.org/abs/2512.06123)
*Qilin Zhou,Zhengyuan Wei,Haipeng Wang,Zhuo Wang,W. K. Chan*

Main category: cs.SE

TL;DR: HiCert 是一种新型的基于掩码的认证检测技术，能全面认证补丁鲁棒性，显著提升认证样本数量和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有认证检测方法无法有效认证被错误分类或预测不一致的样本，HiCert 旨在解决这一问题。

Method: HiCert 提出了一种基于掩码的认证检测技术，通过分析有害样本与良性样本之间的形式关系，并检查不一致突变体的最大置信度边界。

Result: HiCert 在实验中表现出色，显著提高了认证样本数量、准确性，并降低了虚假静默率。

Conclusion: HiCert 是第一个能够提供全面补丁鲁棒性认证的工作，实验证明其在认证检测方面具有高效性，显著提高了认证样本的数量和准确性。

Abstract: Patch robustness certification is an emerging kind of provable defense technique against adversarial patch attacks for deep learning systems. Certified detection ensures the detection of all patched harmful versions of certified samples, which mitigates the failures of empirical defense techniques that could (easily) be compromised. However, existing certified detection methods are ineffective in certifying samples that are misclassified or whose mutants are inconsistently pre icted to different labels. This paper proposes HiCert, a novel masking-based certified detection technique. By focusing on the problem of mutants predicted with a label different from the true label with our formal analysis, HiCert formulates a novel formal relation between harmful samples generated by identified loopholes and their benign counterparts. By checking the bound of the maximum confidence among these potentially harmful (i.e., inconsistent) mutants of each benign sample, HiCert ensures that each harmful sample either has the minimum confidence among mutants that are predicted the same as the harmful sample itself below this bound, or has at least one mutant predicted with a label different from the harmful sample itself, formulated after two novel insights. As such, HiCert systematically certifies those inconsistent samples and consistent samples to a large extent. To our knowledge, HiCert is the first work capable of providing such a comprehensive patch robustness certification for certified detection. Our experiments show the high effectiveness of HiCert with a new state-of the-art performance: It certifies significantly more benign samples, including those inconsistent and consistent, and achieves significantly higher accuracy on those samples without warnings and a significantly lower false silent ratio.

</details>


### [229] [Systematically Thinking about the Complexity of Code Structuring Exercises at Introductory Level](https://arxiv.org/abs/2512.06178)
*Georgiana Haldeman,Peter Ohmann,Paul Denny*

Main category: cs.SE

TL;DR: A framework for assessing code structuring task complexity is introduced to teach decomposition and abstraction explicitly, with practical examples and an interactive tool.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the lack of emphasis on decomposition and abstraction in introductory programming courses, especially as generative AI shifts focus from syntax to higher-level code reasoning.

Method: The paper presents a framework with three dimensions of task complexity (repetition, code pattern, and data dependency) to assess code structuring tasks. It includes example tasks and an interactive tool for generating DA problems.

Result: The framework provides a systematic way to assess and generate tasks that help students practice decomposition and abstraction, supported by practical examples and an interactive tool.

Conclusion: The paper concludes that the introduced framework effectively supports the development of educational tasks to enhance students' decomposition and abstraction skills in programming, particularly in the procedural paradigm.

Abstract: Decomposition and abstraction is an essential component of computational thinking, yet it is not always emphasized in introductory programming courses. In addition, as generative AI further reduces the focus on syntax and increases the importance of higher-level code reasoning, there is renewed opportunity to teach DA explicitly. In this paper, we introduce a framework for systematically assessing the complexity of code structuring tasks, where students must identify and separate meaningful abstractions within existing, unstructured code. The framework defines three dimensions of task complexity, each with multiple levels: repetition, code pattern, and data dependency. To support practical use, we provide example tasks mapped to these levels and offer an interactive tool for generating and exploring DA problems. The framework is designed to support the development of educational tasks that build students' skills with DA in the procedural paradigm.

</details>


### [230] [DUET: Agentic Design Understanding via Experimentation and Testing](https://arxiv.org/abs/2512.06247)
*Gus Henry Smith,Sandesh Adhikary,Vineet Thumuluri,Karthik Suresh,Vivek Pandit,Kartik Hegde,Hamid Shojaei,Chandra Bhagavatula*

Main category: cs.SE

TL;DR: DUET通过迭代实验和测试帮助AI代理理解RTL代码，提升硬件设计任务性能，尤其在形式验证上表现更优。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在硬件设计任务中表现不佳，尤其是对RTL代码的复杂动态行为理解有限，限制了其在代码补全、文档生成或验证等下游任务中的应用。

Method: DUET采用迭代生成假设、使用EDA工具（如仿真、波形检查和形式验证）测试假设，并整合结果以自底向上理解设计的方法。

Result: 评估显示，DUET相比无实验的基线流程，显著提高了AI代理在形式验证上的性能。

Conclusion: DUET方法通过迭代实验和测试显著提升了AI代理在硬件设计任务中的性能，特别是在形式验证方面。

Abstract: AI agents powered by large language models (LLMs) are being used to solve increasingly complex software engineering challenges, but struggle with hardware design tasks. Register Transfer Level (RTL) code presents a unique challenge for LLMs, as it encodes complex, dynamic, time-evolving behaviors using the low-level language features of SystemVerilog. LLMs struggle to infer these complex behaviors from the syntax of RTL alone, which limits their ability to complete all downstream tasks like code completion, documentation, or verification. In response to this issue, we present DUET: a general methodology for developing Design Understanding via Experimentation and Testing. DUET mimics how hardware design experts develop an understanding of complex designs: not just via a one-off readthrough of the RTL, but via iterative experimentation using a number of tools. DUET iteratively generates hypotheses, tests them with EDA tools (e.g., simulation, waveform inspection, and formal verification), and integrates the results to build a bottom-up understanding of the design. In our evaluations, we show that DUET improves AI agent performance on formal verification, when compared to a baseline flow without experimentation.

</details>


### [231] [CFCEval: Evaluating Security Aspects in Code Generated by Large Language Models](https://arxiv.org/abs/2512.06248)
*Cheng Cheng,Jinqiu Yang*

Main category: cs.SE

TL;DR: CFCEval是一个新的评估框架，通过MLVBench和ELRM解决了现有代码LLM评估的局限性，更有效地评估代码质量和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有代码LLM评估协议在方法严谨性和全面性上存在不足，特别是数据集偏差和CodeBLEU指标的局限性。

Method: 引入了CFCEval框架，包括新的基准MLVBench和新指标ELRM，用于评估生成代码的编程质量、漏洞修复能力、后转换修复能力和相关性。

Result: 实验表明，CFCEval在评估生成代码的质量和安全性方面更有效，且ELRM比CodeBLEU更符合人类判断。

Conclusion: CFCEval框架不仅更有效地捕捉了生成代码的质量和安全方面，其ELRM指标也比CodeBLEU更接近人类判断，为未来代码LLM评估的进步铺平了道路。

Abstract: Code-focused Large Language Models (LLMs), such as CodeX and Star-Coder, have demonstrated remarkable capabilities in enhancing developer productivity through context-aware code generation. However, evaluating the quality and security of LLM-generated code remains a significant challenge. Existing evaluation protocols for Code LLMs lack both methodological rigor and comprehensive scope. A key limitation is dataset bias, which arises from unintentional overlap between training and testing data. Furthermore, while CodeBLEU, a BLEU-based metric, is widely used to assess code similarity, it suffers from critical shortcomings, including imprecise tokenization, structural limitations, and low reference diversity. To address these challenges, we introduce CFCEval, a novel framework for evaluating the quality and security of code generated by LLMs. CFCEval mitigates dataset bias by creating a new benchmark, MLVBench, and incorporates ELRM, a new metric designed to assess the relevance between reference code and generated code. CFCEval evaluates generated code across four dimensions: programming quality, vulnerability-fixing capability, post-transformation fixing capability, and relevance. Our experiments show that CFCEval not only captures both quality and security aspects of generated code more effectively but also that its ELRM aligns more closely with human judgments than CodeBLEU, thus paving the way for future advancements in Code LLMs evaluation.

</details>


### [232] [LLMCFG-TGen: Using LLM-Generated Control Flow Graphs to Automatically Create Test Cases from Use Cases](https://arxiv.org/abs/2512.06401)
*Zhenzhen Yang,Chenhui Cui,Tao Li,Rubing Huang,Nan Niu,Dave Towey,Shikai Guo*

Main category: cs.SE

TL;DR: LLMCFG-TGen是一种新方法，利用LLM生成控制流图（CFG）来自动化生成测试用例，显著提升覆盖率和逻辑一致性，减少人工干预。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的测试生成方法可能无法提供全面、非冗余的覆盖，且难以捕捉需求中的复杂条件逻辑，导致测试用例不完整。

Method: LLMCFG-TGen包含三个主要步骤：1）LLM将用例转换为结构化的控制流图（CFG）；2）探索生成的CFG并枚举所有完整执行路径；3）利用执行路径生成测试用例。

Result: 实验结果表明，LLM能有效从自然语言用例构建结构良好的CFG。与基线方法相比，LLMCFG-TGen实现了全路径覆盖，提高了完整性，并确保了测试用例的清晰和准确。

Conclusion: LLMCFG-TGen通过结合LLM的语义推理和结构化建模，有效弥补了自然语言需求与系统化测试生成之间的差距，显著减少了人工工作量。

Abstract: Appropriate test case generation is critical in software testing, significantly impacting the quality of the testing. Requirements-Based Test Generation (RBTG) derives test cases from software requirements, aiming to verify whether or not the system's behaviors align with user needs and expectations. Requirements are often documented in Natural Language (NL), with use-case descriptions being a popular method for capturing functional behaviors and interaction flows in a structured form. Large Language Models (LLMs) have shown strong potential for automating test generation directly from NL requirements. However, current LLM-based approaches may not provide comprehensive, non-redundant coverage. They may also fail to capture complex conditional logic in requirements, resulting in incomplete test cases. We propose a new approach that automatically generates test cases from NL use-case descriptions, called Test Generation based on LLM-generated Control Flow Graphs (LLMCFG-TGen). LLMCFG-TGen comprises three main steps: (1) An LLM transforms a use case into a structured CFG that encapsulates all potential branches; (2) The generated CFG is explored, and all complete execution paths are enumerated; and (3) The execution paths are then used to generate the test cases. To evaluate our proposed approach, we conducted a series of experiments. The results show that LLMs can effectively construct well-structured CFGs from NL use cases. Compared with the baseline methods, LLMCFG-TGen achieves full path coverage, improving completeness and ensuring clear and accurate test cases. Practitioner assessments confirm that LLMCFG-TGen produces logically consistent and comprehensive test cases, while substantially reducing manual effort. The findings suggest that coupling LLM-based semantic reasoning with structured modeling effectively bridges the gap between NL requirements and systematic test generation.

</details>


### [233] [Translating PL/I Macro Procedures into Java Using Automatic Templatization and Large Language Models](https://arxiv.org/abs/2512.06448)
*Takaaki Tateishi,Yasuharu Katsuno*

Main category: cs.SE

TL;DR: 提出模板化方法，通过符号执行生成代码模板辅助LLM翻译PL/I宏过程为Java，实验验证有效性。


<details>
  <summary>Details</summary>
Motivation: PL/I宏过程作为字符串操作程序，增加了自动化翻译的复杂性，现有LLM方法难以直接翻译为行为一致的Java程序。

Method: 采用符号执行生成代码模板（带有命名占位符的代码）作为中间表示，辅助LLM生成可读且可维护的Java代码。

Result: 初步实验在十个PL/I宏过程上成功生成行为一致的Java程序。

Conclusion: 本文提出的模板化方法通过符号执行生成代码模板，作为中间表示，有效解决了PL/I宏过程到Java程序的翻译难题，实验证明了其可行性。

Abstract: Modernizing legacy enterprise systems often involves translating PL/I programs into modern languages such as Java. This task becomes significantly more complex when PL/I macro procedures are involved. The PL/I macro procedures are considered string-manipulating programs that generate PL/I code, and they make automated translation more complex. Recently, large language models (LLMs) have been explored for automated code translation. However, LLM-based code translation struggles to translate the PL/I macro procedures to Java programs that reproduce the behavior of the plain PL/I code generated by the original PL/I macro procedures.
  This paper proposes a novel method called templatization, which uses symbolic execution to generate code templates (code with named placeholders) as an intermediate representation. In this approach, symbolic values are treated as parts of macro-generated code. By symbolically executing macro procedures and generating code templates, our approach facilitates LLMs to generate readable and maintainable Java code. Our preliminary experiment on ten PL/I macro procedures shows that the LLM-based translation through templatization successfully generates Java programs that reproduce the behavior of the macro-generated PL/I programs.

</details>


### [234] [METRION: A Framework for Accurate Software Energy Measurement](https://arxiv.org/abs/2512.06806)
*Benjamin Weigell,Simon Hornung,Bernhard Bauer*

Main category: cs.SE

TL;DR: 研究提出METRION框架，通过线程级能量归因模型准确量化应用在CPU和DRAM的能耗，支持ICT行业能效优化。


<details>
  <summary>Details</summary>
Motivation: ICT行业能耗和温室气体排放日益增长，需通过优化策略减少环境影响，但需准确量化应用级能耗以评估优化效果。

Method: 提出了一个能量归因模型，量化线程级CPU和DRAM能耗，考虑了SMT、频率缩放、多插槽架构和NUMA的影响，并集成到METRION框架中。

Result: METRION在三种不同工作负载下评估，CPU能耗预测的平均绝对百分比误差为4.2%，DRAM能耗预测误差为16.1%。

Conclusion: METRION框架及其能量归因模型能够准确量化应用在CPU和DRAM上的能耗，为优化策略提供了可靠的数据支持。

Abstract: The Information and Communication Technology sector accounted for approximately 1.4% of global greenhouse gas emissions and 4% of the world's electricity consumption in 2020, with both expected to rise. To reduce this environmental impact, optimization strategies are employed to reduce energy consumption at the IT infrastructure and application levels. However, effective optimization requires, firstly, the identification of major energy consumers and, secondly, the ability to quantify whether an optimization has achieved the intended energy savings. Accurate determination of application-level energy consumption is thus essential. Therefore, we introduce an energy attribution model that quantifies the energy consumption of applications on CPU and DRAM at the thread level, considering the influence of Simultaneous Multithreading, frequency scaling, multi-socket architectures, and Non-Uniform Memory Access. To ensure cross-platform applicability, we integrate the proposed model into an extensible framework, METRION, including a platform-independent data model and an initial implementation for Linux systems using Intel CPUs. We evaluate METRION across three different workloads and demonstrate that the energy attribution model can accurately capture the CPU energy consumption of applications targeting solely the CPU with a Mean Absolute Percentage Error of 4.2%, and the DRAM energy consumption of applications targeting DRAM with an 16.1% error.

</details>


### [235] [Leveraging LLMs to support co-evolution between definitions and instances of textual DSLs](https://arxiv.org/abs/2512.06836)
*Weixing Zhang,Regina Hebig,Daniel Strüber*

Main category: cs.SE

TL;DR: LLMs can co-evolve DSL grammar and textual instances for small-scale cases but face scalability issues.


<details>
  <summary>Details</summary>
Motivation: Existing techniques for DSL evolution in model-driven engineering fail to preserve auxiliary information (e.g., comments, layout) in textual instances, which are crucial for software comprehension.

Method: Applied two advanced LLMs (Claude-3.5 and GPT-4o) across seven case languages to evaluate feasibility and limitations.

Result: LLMs demonstrated good performance in small-scale cases but struggled with scalability for larger instances.

Conclusion: LLMs show promise in handling small-scale DSL grammar and instance co-evolution while preserving auxiliary information, but face scalability challenges with larger instances.

Abstract: Software languages evolve over time for various reasons, such as the addition of new features. When the language's grammar definition evolves, textual instances that originally conformed to the grammar become outdated. For DSLs in a model-driven engineering context, there exists a plethora of techniques to co-evolve models with the evolving metamodel. However, these techniques are not geared to support DSLs with a textual syntax -- applying them to textual language definitions and instances may lead to the loss of information from the original instances, such as comments and layout information, which are valuable for software comprehension and maintenance. This study explores the potential of Large Language Model (LLM)-based solutions in achieving grammar and instance co-evolution, with attention to their ability to preserve auxiliary information when directly processing textual instances. By applying two advanced language models, Claude-3.5 and GPT-4o, and conducting experiments across seven case languages, we evaluated the feasibility and limitations of this approach. Our results indicate a good ability of the considered LLMs for migrating textual instances in small-scale cases with limited instance size, which are representative of a subset of cases encountered in practice. In addition, we observe significant challenges with the scalability of LLM-based solutions to larger instances, leading to insights that are useful for informing future research.

</details>


### [236] [BabelCoder: Agentic Code Translation with Specification Alignment](https://arxiv.org/abs/2512.06902)
*Fazle Rabbi,Soumit Kanti Saha,Tri Minh Triet Pham,Song Wang,Jinqiu Yang*

Main category: cs.SE

TL;DR: BabelCoder 是一个多智能体协作的代码翻译框架，通过分解任务提升翻译准确率，平均达94.16%。


<details>
  <summary>Details</summary>
Motivation: 现有自动代码翻译方法在准确性和上下文利用上存在不足，缺乏结构化协作框架。

Method: BabelCoder 将代码翻译任务分解为翻译、测试和优化三个子任务，由专门的智能体分别负责生成代码、验证正确性和修复错误。

Result: BabelCoder 在四个基准数据集上优于现有方法，94%的情况下提升0.5%-13.5%。

Conclusion: BabelCoder 是一个通过多智能体协作分解代码翻译任务的框架，显著提升了翻译准确率，平均准确率达到94.16%。

Abstract: As software systems evolve, developers increasingly work across multiple programming languages and often face the need to migrate code from one language to another. While automatic code translation offers a promising solution, it has long remained a challenging task. Recent advancements in Large Language Models (LLMs) have shown potential for this task, yet existing approaches remain limited in accuracy and fail to effectively leverage contextual and structural cues within the code. Prior work has explored translation and repair mechanisms, but lacks a structured, agentic framework where multiple specialized agents collaboratively improve translation quality. In this work, we introduce BabelCoder, an agentic framework that performs code translation by decomposing the task into specialized agents for translation, testing, and refinement, each responsible for a specific aspect such as generating code, validating correctness, or repairing errors. We evaluate BabelCoder on four benchmark datasets and compare it against four state-of-the-art baselines. BabelCoder outperforms existing methods by 0.5%-13.5% in 94% of cases, achieving an average accuracy of 94.16%.

</details>


### [237] [MINES: Explainable Anomaly Detection through Web API Invariant Inference](https://arxiv.org/abs/2512.06906)
*Wenjie Zhang,Yun Lin,Chun Fung Amos Kwok,Xiwen Teoh,Xiaofei Xie,Frank Liauw,Hongyu Zhang,Jin Song Dong*

Main category: cs.SE

TL;DR: MINES 通过模式级API不变量推断，显著提升Web应用异常检测性能，几乎零误报，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现代Web应用依赖API，但其暴露性易引发攻击或非法访问，导致异常行为。传统日志学习方案因日志噪声和关键信息缺失易学得虚假相关性，导致模型和规则表面化。

Method: MINES 将API签名转换为表模式以增强原始数据库模式，并推断增强模式上的潜在数据库约束，捕捉API与数据库表之间的关系。利用LLM提取潜在关系，并通过正常日志实例筛选LLM生成的不变量，最终将其转化为Python代码以验证运行时日志。

Result: 在多个基准测试中，MINES 对异常行为实现了高召回率且几乎零误报，优于LogRobust、LogFormer和WebNorm等基线方法。

Conclusion: MINES 通过从模式层面推断可解释的API不变量，显著提高了异常检测的准确性和鲁棒性，几乎实现了零误报，成为当前最先进的解决方案。

Abstract: Detecting the anomalies of web applications, important infrastructures for running modern companies and governments, is crucial for providing reliable web services. Many modern web applications operate on web APIs (e.g., RESTful, SOAP, and WebSockets), their exposure invites intended attacks or unintended illegal visits, causing abnormal system behaviors. However, such anomalies can share very similar logs with normal logs, missing crucial information (which could be in database) for log discrimination. Further, log instances can be also noisy, which can further mislead the state-of-the-art log learning solutions to learn spurious correlation, resulting superficial models and rules for anomaly detection. In this work, we propose MINES which infers explainable API invariants for anomaly detection from the schema level instead of detailed raw log instances, which can (1) significantly discriminate noise in logs to identify precise normalities and (2) detect abnormal behaviors beyond the instrumented logs. Technically, MINES (1) converts API signatures into table schema to enhance the original database shema; and (2) infers the potential database constraints on the enhanced database schema to capture the potential relationships between APIs and database tables. MINES uses LLM for extracting potential relationship based on two given table structures; and use normal log instances to reject and accept LLM-generated invariants. Finally, MINES translates the inferred constraints into invariants to generate Python code for verifying the runtime logs. We extensively evaluate MINES on web-tamper attacks on the benchmarks of TrainTicket, NiceFish, Gitea, Mastodon, and NextCloud against baselines such as LogRobust, LogFormer, and WebNorm. The results show that MINES achieves high recall for the anomalies while introducing almost zero false positives, indicating a new state-of-the-art.

</details>


### [238] [Multi-Docker-Eval: A `Shovel of the Gold Rush' Benchmark on Automatic Environment Building for Software Engineering](https://arxiv.org/abs/2512.06915)
*Kelin Fu,Tianyu Liu,Zeyu Shang,Yingwei Ma,Jian Yang,Jiaheng Liu,Kaigui Bian*

Main category: cs.SE

TL;DR: Multi-Docker-Eval基准测试评估自动化环境配置，发现当前模型成功率低，开源模型竞争力强，代理框架和编程语言影响显著。


<details>
  <summary>Details</summary>
Motivation: 自动化环境配置是扩展软件工程自动化的关键瓶颈，需要一个可靠的评估标准。

Method: 提出了Multi-Docker-Eval基准测试，包含40个真实世界仓库，覆盖9种编程语言，评估可执行状态的成功率和现实约束下的效率。

Result: 评估发现：(1)当前模型的总体成功率较低（最高37.7%），环境构建是主要瓶颈；(2)模型大小和推理长度并非决定性因素，开源模型表现竞争力；(3)代理框架和编程语言对成功率有显著影响。

Conclusion: 研究结果为构建可扩展的全自动化软件工程流水线提供了可行的指导方针。

Abstract: Automated environment configuration is a critical bottleneck in scaling software engineering (SWE) automation. To provide a reliable evaluation standard for this task, we present Multi-Docker-Eval benchmark. It includes 40 real-world repositories spanning 9 programming languages and measures both success in achieving executable states and efficiency under realistic constraints. Our extensive evaluation of state-of-the-art LLMs and agent frameworks reveals key insights: (1) the overall success rate of current models is low (F2P at most 37.7%), with environment construction being the primary bottleneck; (2) model size and reasoning length are not decisive factors, and open-source models like DeepSeek-V3.1 and Kimi-K2 are competitive in both efficiency and effectiveness; (3) agent framework and programming language also have significantly influence on success rate. These findings provide actionable guidelines for building scalable, fully automated SWE pipelines.

</details>


### [239] [Reformulate, Retrieve, Localize: Agents for Repository-Level Bug Localization](https://arxiv.org/abs/2512.07022)
*Genevieve Caumartin,Glaucia Melo*

Main category: cs.SE

TL;DR: LLM驱动的代理通过查询重构和摘要提升Bug定位性能，首文件检索排名提升35%，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统基于信息检索的Bug定位方法因依赖噪声较多的Bug描述而准确性低，而近期LLM在查询重构上的进展对代理性能的影响尚未探索。

Method: 使用开源、未经微调的LLM从Bug报告中提取关键信息（如标识符和代码片段），并在检索前重构查询。代理随后使用这些预处理查询协调BM25检索，实现规模化自动定位工作流。

Result: 采用最佳查询重构技术后，代理在首文件检索中的排名比BM25基线提升35%，文件检索性能较SWE-agent提升高达22%。

Conclusion: 本研究通过轻量级查询重构和摘要技术，展示了LLM驱动的代理如何显著提升文件级Bug定位的性能，优于传统IRBL方法和现有代理。

Abstract: Bug localization remains a critical yet time-consuming challenge in large-scale software repositories. Traditional information retrieval-based bug localization (IRBL) methods rely on unchanged bug descriptions, which often contain noisy information, leading to poor retrieval accuracy. Recent advances in large language models (LLMs) have improved bug localization through query reformulation, yet the effect on agent performance remains unexplored. In this study, we investigate how an LLM-powered agent can improve file-level bug localization via lightweight query reformulation and summarization. We first employ an open-source, non-fine-tuned LLM to extract key information from bug reports, such as identifiers and code snippets, and reformulate queries pre-retrieval. Our agent then orchestrates BM25 retrieval using these preprocessed queries, automating localization workflow at scale. Using the best-performing query reformulation technique, our agent achieves 35% better ranking in first-file retrieval than our BM25 baseline and up to +22% file retrieval performance over SWE-agent.

</details>


### [240] [RisConFix: LLM-based Automated Repair of Risk-Prone Drone Configurations](https://arxiv.org/abs/2512.07122)
*Liping Han,Tingting Nie,Le Yu,Mingzhe Hu,Tao Yue*

Main category: cs.SE

TL;DR: LLM驱动的RisConFix实时修复无人机风险配置，实验显示高效有效。


<details>
  <summary>Details</summary>
Motivation: 无人机配置参数组合可能导致不稳定飞行行为，需实时修复以增强鲁棒性。

Method: 提出基于LLM的实时修复方法RisConFix，通过监控无人机状态并迭代修复异常配置。

Result: RisConFix在ArduPilot案例中修复成功率达97%，平均修复次数1.17。

Conclusion: RisConFix通过LLM实时修复无人机风险配置，实验证明其高效且有效，修复成功率达97%，平均修复次数为1.17。

Abstract: Flight control software is typically designed with numerous configurable parameters governing multiple functionalities, enabling flexible adaptation to mission diversity and environmental uncertainty. Although developers and manufacturers usually provide recommendations for these parameters to ensure safe and stable operations, certain combinations of parameters with recommended values may still lead to unstable flight behaviors, thereby degrading the drone's robustness. To this end, we propose a Large Language Model (LLM) based approach for real-time repair of risk-prone configurations (named RisConFix) that degrade drone robustness. RisConFix continuously monitors the drone's operational state and automatically triggers a repair mechanism once abnormal flight behaviors are detected. The repair mechanism leverages an LLM to analyze relationships between configuration parameters and flight states, and then generates corrective parameter updates to restore flight stability. To ensure the validity of the updated configuration, RisConFix operates as an iterative process; it continuously monitors the drone's flight state and, if an anomaly persists after applying an update, automatically triggers the next repair cycle. We evaluated RisConFix through a case study of ArduPilot (with 1,421 groups of misconfigurations). Experimental results show that RisConFix achieved a best repair success rate of 97% and an optimal average number of repairs of 1.17, demonstrating its capability to effectively and efficiently repair risk-prone configurations in real time.

</details>


### [241] [Towards Benchmarking Design Pattern Detection Under Obfuscation: Reproducing and Evaluating Attention-Based Detection Method](https://arxiv.org/abs/2512.07193)
*Manthan Shenoy,Andreas Rausch*

Main category: cs.SE

TL;DR: 该论文研究了注意力分类器在设计模式检测中的语义鲁棒性，发现其对表面语法特征依赖过重，混淆后性能显著下降，提出了一个混淆语料库作为评估工具。


<details>
  <summary>Details</summary>
Motivation: 研究基于注意力的分类器在设计模式检测中的语义鲁棒性，尤其是其对结构和行为语义的依赖。

Method: 我们复现了基于注意力的设计模式检测方法DPDAtt，并评估其在代码混淆（如替换类名、方法名等标识符和字符串字面量）下的性能。为此，我们创建了一个混淆版本的DPDAtt语料库，保留了控制流、继承和逻辑。

Result: 研究发现DPDAtt中的训练分类器严重依赖表面语法特征，当这些线索通过混淆被移除时，会导致显著的误分类。

Conclusion: 本研究强调了需要开发能够捕捉源代码更深层次语义的鲁棒性检测工具，并提出了一个可重复使用的概念验证基准（包含34个Java源文件）来评估现有设计模式检测器的语义泛化能力。

Abstract: This paper investigates the semantic robustness of attention-based classifiers for design pattern detection, particularly focusing on their reliance on structural and behavioral semantics. We reproduce the DPDAtt, an attention-based design pattern detection approach using learning-based classifiers, and evaluate its performance under obfuscation. To this end, we curate an obfuscated version of the DPDAtt Corpus, where the name identifiers in code such as class names, method names, etc., and string literals like print statements and comment blocks are replaced while preserving control flow, inheritance, and logic. Our findings reveal that these trained classifiers in DPDAtt depend significantly on superficial syntactic features, leading to substantial misclassification when such cues are removed through obfuscation. This work highlights the need for more robust detection tools capable of capturing deeper semantic meanings in source code. We propose our curated Obfuscated corpus (containing 34 Java source files) as a reusable proof-of-concept benchmark for evaluating state-of-the-art design pattern detectors on their true semantic generalization capabilities.

</details>


### [242] [Automatic Syntax Error Repair for Discrete Controller Synthesis using Large Language Model](https://arxiv.org/abs/2512.07261)
*Yusei Ishimizu,Takuto Yamauchi,Sinan Chen,Jinyu Cai,Jialong Li,Kenji Tei*

Main category: cs.SE

TL;DR: 本文利用LLMs自动修复DCS模型语法错误，通过知识引导提示策略显著提升修复效率和准确性。


<details>
  <summary>Details</summary>
Motivation: DCS模型的语法错误常成为开发者的瓶颈，影响工作流程和生产力，本文旨在通过自动化方法解决这一问题。

Method: 通过系统化的实证研究（专家访谈和学生研讨会）识别常见错误模式，设计知识引导的提示策略，结合DCS特定领域知识（如形式语法规则和示例）指导LLM进行准确修正。

Result: 定量评估显示，该方法在修复准确性和时间效率上表现优异，比人工修复快3.46倍。

Conclusion: 本文提出了一种利用大型语言模型（LLMs）自动修复离散控制器合成（DCS）模型中语法错误的方法，显著提高了修复效率和准确性。

Abstract: Discrete Controller Synthesis (DCS) is a powerful formal method for automatically generating specifications of discrete event systems. However, its practical adoption is often hindered by the highly specialized nature of formal models written in languages such as FSP and FLTL. In practice, syntax errors in modeling frequently become an important bottleneck for developers-not only disrupting the workflow and reducing productivity, but also diverting attention from higher-level semantic design. To this end, this paper presents an automated approach that leverages Large Language Models (LLMs) to repair syntax errors in DCS models using a well-designed, knowledge-informed prompting strategy. Specifically, the prompting is derived from a systematic empirical study of common error patterns, identified through expert interviews and student workshops. It equips the LLM with DCS-specific domain knowledge, including formal grammar rules and illustrative examples, to guide accurate corrections. To evaluate our method, we constructed a new benchmark by systematically injecting realistic syntax errors into validated DCS models. The quantitative evaluation demonstrates the high effectiveness of the proposed approach in terms of repair accuracy and its practical utility regarding time, achieving a speedup of 3.46 times compared to human developers. The experimental replication suite, including the benchmark and prompts, is available at https://github.com/Uuusay1432/DCSModelRepair.git

</details>


### [243] [The Human Need for Storytelling: Reflections on Qualitative Software Engineering Research With a Focus Group of Experts](https://arxiv.org/abs/2512.07293)
*Roberto Verdecchia,Justus Bogner*

Main category: cs.SE

TL;DR: 本文通过专家讨论，回顾了定性研究在软件工程中的发展、挑战与未来方向。


<details>
  <summary>Details</summary>
Motivation: 探讨定性研究在软件工程领域的重要性及其演变，分析当前实践的障碍，并展望未来发展方向。

Method: 通过专家焦点小组讨论，反思定性SE研究的现状。

Result: 讨论了定性SE研究的重要性、历史演变、当前挑战及未来趋势。

Conclusion: 本文总结了定性研究在软件工程（SE）中的重要性、发展历程、当前面临的挑战以及未来展望。

Abstract: From its first adoption in the late 80s, qualitative research has slowly but steadily made a name for itself in what was, and perhaps still is, the predominantly quantitative software engineering (SE) research landscape. As part of our regular column on empirical software engineering (ACM SIGSOFT SEN-ESE), we reflect on the state of qualitative SE research with a focus group of experts. Among other things, we discuss why qualitative SE research is important, how it evolved over time, common impediments faced while practicing it today, and what the future of qualitative SE research might look like. Joining the conversation are Rashina Hoda (Monash University, Australia), Carolyn Seaman (University of Maryland, United States), and Klaas Stol (University College Cork, Ireland). The content of this paper is a faithful account of our conversation from October 25, 2025, which we moderated and edited for our column.

</details>


### [244] [Challenges in Developing Secure Software -- Results of an Interview Study in the German Software Industry](https://arxiv.org/abs/2512.07368)
*Alex R. Mattukat,Timo Langstrof,Horst Lichter*

Main category: cs.SE

TL;DR: 通过访谈研究发现，开发安全软件的主要挑战是高复杂性、安全意识不足和流程不当，且缺乏熟练人员加剧了这些问题，文章提出了潜在研究方向。


<details>
  <summary>Details</summary>
Motivation: 网络犯罪造成的损害使得开发安全软件成为必然，尽管存在许多工具和框架，但网络犯罪统计数据显示近年来没有改善。

Method: 通过对12家跨行业公司的19位行业专家进行访谈研究。

Result: 研究发现挑战主要源于高复杂性、安全意识不足和不合适的流程，这些问题因缺乏熟练人员而进一步加剧。

Conclusion: 文章总结了软件开发中安全挑战的主要成因，并提出了潜在的研究方向。

Abstract: The damage caused by cybercrime makes the development of secure software inevitable. Although many tools and frameworks exist to support the development of secure software, statistics on cybercrime show no improvement in recent years. To understand the challenges software companies face in developing secure software, we conducted an interview study with 19 industry experts from 12 cross-industry companies. The results of our study show that the challenges are mainly due to high complexity, a lack of security awareness, and unsuitable processes, which are further exacerbated by an immediate lack of skilled personnel. This article presents our study and the challenges we identified, and derives potential research directions from them.

</details>


### [245] [Do LLMs Trust the Code They Write?](https://arxiv.org/abs/2512.07404)
*Francisco Ribeiro,Claudio Spiess,Prem Devanbu,Sarah Nadi*

Main category: cs.SE

TL;DR: 研究发现LLMs内部编码代码正确性，利用该表示可提升代码生成可靠性，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs是否像编码真实性概念一样编码代码正确性，以解决LLMs生成代码时输出概率与正确性不相关的问题。

Method: 通过对比同一编程任务中正确和错误代码的隐藏状态，识别LLMs内部编码的正确性表示，并在四个LLMs上进行实验验证。

Result: 利用提取的正确性表示优于标准对数似然排名和模型口头化置信度，并能选择更高质量的代码样本，无需测试执行。

Conclusion: 该研究表明，利用LLMs内部编码的正确性表示可以显著提升代码生成系统的可靠性，增强对自动生成代码的信心。

Abstract: Despite the effectiveness of large language models (LLMs) for code generation, they often output incorrect code. One reason is that model output probabilities are often not well-correlated with correctness, and reflect only the final output of the generation process. Inspired by findings that LLMs internally encode concepts like truthfulness, this paper explores if LLMs similarly represent code correctness. Specifically, we identify a correctness representation inside LLMs by contrasting the hidden states between pairs of correct and incorrect code for the same programming tasks. By experimenting on four LLMs, we show that exploiting this extracted correctness representation outperforms standard log-likelihood ranking, as well as verbalized model confidence. Furthermore, we explore how this internal correctness signal can be used to select higher-quality code samples, without requiring test execution. Ultimately, this work demonstrates how leveraging internal representations can enhance code generation systems and make LLMs more reliable, thus improving confidence in automatically generated code.

</details>


### [246] [Systematic Evaluation of Black-Box Checking for Fast Bug Detection](https://arxiv.org/abs/2512.07434)
*Bram Pellen,María Belén Rodríguez,Frits Vaandrager,Petra van den Bos*

Main category: cs.SE

TL;DR: BBC通过模型检查中间假设，显著提升发现规范违规的效率，优于仅检查最终模型的传统方法。


<details>
  <summary>Details</summary>
Motivation: 评估BBC在发现规范违规方面的效率，尤其是在中间假设阶段的应用，而不仅限于最终模型。

Method: 基于77个基准模型，对BBC在快速发现错误方面的能力进行了系统评估。

Result: BBC在仅需3.4%查询的情况下即可检测到规范违规，且在无法学习完整模型时仍能检测到94%的安全属性违规。

Conclusion: BBC（黑盒检查）在发现规范违规方面比现有MBT算法更有效，尤其是在实现中发现深层错误时。

Abstract: Combinations of active automata learning, model-based testing and model checking have been successfully used in numerous applications, e.g., for spotting bugs in implementations of major network protocols and to support refactoring of embedded controllers. However, in the large majority of these applications, model checking is only used at the very end, when no counterexample can be found anymore for the latest hypothesis model. This contrasts with the original proposal of black-box checking (BBC) by Peled, Vardi & Yannakakis, which applies model checking for all hypotheses, also the intermediate ones. In this article, we present the first systematic evaluation of the ability of BBC to find bugs quickly, based on 77 benchmarks models from real protocol implementations and controllers for which specifications of safety properties are available. Our main finding are: (a) In cases where the full model can be learned, BBC detects violations of the specifications with just 3.4% of the queries needed by an approach in which model checking is only used for the full model. (b) Even when the full model cannot be learned, BBC is still able to detect many violations of the specification. In particular, BBC manages to detect 94% of the safety properties violations in the challenging RERS 2019 industrial LTL benchmarks. (c) Our results also confirm that BBC is way more effective than existing MBT algorithms in finding deep bugs in implementations.

</details>


### [247] [AutoICE: Automatically Synthesizing Verifiable C Code via LLM-driven Evolution](https://arxiv.org/abs/2512.07501)
*Weilin Luo,Xueyi Liang,Haotian Deng,Yanan Liu,Hai Wan*

Main category: cs.SE

TL;DR: AutoICE是一种LLM驱动的进化搜索方法，通过多样化初始化和协作交叉减少错误，成功验证90.36%的代码，超越现有最佳方法。


<details>
  <summary>Details</summary>
Motivation: 现有的自动形式化方法由于缺乏领域特定的预训练语料库，常出现严重的语法和语义错误，且难以有效形式化隐含知识。因此，需要一种更有效的方法来合成可验证代码。

Method: AutoICE采用LLM驱动的进化搜索方法，结合多样个体初始化、协作交叉和自我反思变异，以减少单代理迭代中的错误传播并有效形式化隐含知识。

Result: AutoICE在验证代码方面达到90.36%的成功率，在开发者友好的数据集变体上达到88.33%的成功率，显著超越现有最佳方法的65%。

Conclusion: AutoICE通过引入多样化的个体初始化和协作交叉，以及自我反思的变异，显著提高了从自然语言需求合成可验证C代码的成功率，验证成功率达到90.36%，超越了现有最佳方法。

Abstract: Automatically synthesizing verifiable code from natural language requirements ensures software correctness and reliability while significantly lowering the barrier to adopting the techniques of formal methods. With the rise of large language models (LLMs), long-standing efforts at autoformalization have gained new momentum. However, existing approaches suffer from severe syntactic and semantic errors due to the scarcity of domain-specific pre-training corpora and often fail to formalize implicit knowledge effectively. In this paper, we propose AutoICE, an LLM-driven evolutionary search for synthesizing verifiable C code. It introduces the diverse individual initialization and the collaborative crossover to enable diverse iterative updates, thereby mitigating error propagation inherent in single-agent iterations. Besides, it employs the self-reflective mutation to facilitate the discovery of implicit knowledge. Evaluation results demonstrate the effectiveness of AutoICE: it successfully verifies $90.36$\% of code, outperforming the state-of-the-art (SOTA) approach. Besides, on a developer-friendly dataset variant, AutoICE achieves a $88.33$\% verification success rate, significantly surpassing the $65$\% success rate of the SOTA approach.

</details>


### [248] [Understanding Privacy Risks in Code Models Through Training Dynamics: A Causal Approach](https://arxiv.org/abs/2512.07814)
*Hua Yang,Alejandro Velasco,Sen Fang,Bowen Xu,Denys Poshyvanyk*

Main category: cs.SE

TL;DR: 研究发现不同PII类型在LLM4Code中的泄漏风险差异显著，易学习的类型泄漏更多，为开发类型感知防御提供了依据。


<details>
  <summary>Details</summary>
Motivation: 大型代码语言模型（LLM4Code）虽提升了开发者效率，但依赖包含大量个人身份信息（PII）的开源库引发隐私担忧。现有研究将PII视为单一类别，忽略了不同类型间的异质风险。

Method: 方法包括构建包含多样PII类型的数据集、微调不同规模的代表性模型、计算真实PII数据的训练动态，以及构建结构因果模型来估计可学习性对泄漏的因果效应。

Result: 结果显示，不同PII类型的泄漏风险差异显著，且与其训练动态相关：易学习的实例（如IP地址）泄漏风险较高，而较难类型（如密钥和密码）泄漏较少。模糊类型表现混合行为。

Conclusion: This研究首次提供了泄漏风险与PII类型相关的因果证据，并为开发针对不同类型和可学习性的LLM4Code防御措施提供了指导。

Abstract: Large language models for code (LLM4Code) have greatly improved developer productivity but also raise privacy concerns due to their reliance on open-source repositories containing abundant personally identifiable information (PII). Prior work shows that commercial models can reproduce sensitive PII, yet existing studies largely treat PII as a single category and overlook the heterogeneous risks among different types. We investigate whether distinct PII types vary in their likelihood of being learned and leaked by LLM4Code, and whether this relationship is causal. Our methodology includes building a dataset with diverse PII types, fine-tuning representative models of different scales, computing training dynamics on real PII data, and formulating a structural causal model to estimate the causal effect of learnability on leakage. Results show that leakage risks differ substantially across PII types and correlate with their training dynamics: easy-to-learn instances such as IP addresses exhibit higher leakage, while harder types such as keys and passwords leak less frequently. Ambiguous types show mixed behaviors. This work provides the first causal evidence that leakage risks are type-dependent and offers guidance for developing type-aware and learnability-aware defenses for LLM4Code.

</details>


### [249] [Studying the Role of Reusing Crowdsourcing Knowledge in Software Development](https://arxiv.org/abs/2512.07824)
*Rabe Abdalkareem*

Main category: cs.SE

TL;DR: 研究发现重用众包知识（如Stack Overflow代码）虽提升开发效率，但增加软件依赖和维护负担，建议通过改进持续集成（CI）来缓解风险。


<details>
  <summary>Details</summary>
Motivation: 尽管众包开发能提高开发者生产力和缩短上市时间，但关于众包知识对软件质量影响的实证研究仍不足，且开发者如何使用这些知识等基本问题尚未解答。

Method: 研究团队在Stack Overflow和npm等知名众包平台上进行了多项大规模实证研究。

Result: 研究结果显示，重用众包知识（尤其是代码）有助于软件开发实践，但会带来依赖负担和维护成本增加等质量问题。

Conclusion: 基于研究发现，研究团队利用所得知识做出数据驱动的决策，探讨了软件质量保证方法以减轻依赖众包知识带来的风险，并分析了持续集成（CI）的改进潜力。

Abstract: Crowdsourcing platforms, such as Stack Overflow, have changed and impacted the software development practice. In these platforms, developers share and reuse their software development and programming experience. Therefore, a plethora of research work focused on crowdsourcing in software engineering and showed that, among other things, crowdsourced development tends to increase developers' productivity and reduce time-to-market. However, in crowdsourcing, the empirical studies of software quality are lacking, and simple questions, such as what developers use the crowdsourcing knowledge for, are unanswered.
  Therefore, our research focused on studying the impact of reusing crowdsourcing knowledge on software projects. To do so, we conduct several large-scale empirical studies on some of the well-known crowdsourcing platforms, including Stack Overflow and npm. Our results showed that reusing knowledge from these crowdsourcing platforms has the potential to assist software development practice, specifically in the form of reusing crowdsourced code. However, using such knowledge affects the quality of the software in several aspects, such as making the software projects suffer from dependency overhead and increasing the maintenance effort. Based on these findings, we use the gained knowledge to make sound data-driven decisions where we examine software quality assurance methods to mitigate the risk of relying on crowd sourcing knowledge in software development. We examine the use of continuous integration (CI). Our analysis showed how CI can be improved to increase developers' productivity and save their resources.

</details>


<div id='eess.IV'></div>

# eess.IV [[Back]](#toc)

### [250] [Proof of Concept for Mammography Classification with Enhanced Compactness and Separability Modules](https://arxiv.org/abs/2512.06575)
*Fariza Dahes*

Main category: eess.IV

TL;DR: 研究验证了GAGM和SEVector在乳腺X光分类中的有效性，但FSL未显示改进，未来需探索替代方法以增强分类性能。


<details>
  <summary>Details</summary>
Motivation: 验证和改进现有的医学图像分类方法框架，特别是在乳腺X光分类中的适用性，以提升特征可区分性和减少假阴性。

Method: 采用改进的ConvNeXt Tiny架构，整合了GAGM和SEVector模块，并在Kaggle数据集（包含INbreast、MIAS和DDSM乳腺X光集合）上比较了基线CNN、ConvNeXt Tiny和InceptionV3主干网络。

Result: GAGM和SEVector模块有效提升了特征可区分性并减少了假阴性，尤其在恶性病例中。FSL在乳腺X光分类中未显示改进。

Conclusion: 本研究验证并扩展了医学图像分类的方法框架，特别关注了GAGM和SEVector模块在提高特征可区分性和减少假阴性方面的有效性，尤其是在恶性病例中。然而，特征平滑损失（FSL）在乳腺X光分类中未显示明显改进。未来工作需探索替代方法以增强类内紧凑性和类间分离性。

Abstract: This study presents a validation and extension of a recent methodological framework for medical image classification. While an improved ConvNeXt Tiny architecture, integrating Global Average and Max Pooling fusion (GAGM), lightweight channel attention (SEVector), and Feature Smoothing Loss (FSL), demonstrated promising results on Alzheimer MRI under CPU friendly conditions, our work investigates its transposability to mammography classification. Using a Kaggle dataset that consolidates INbreast, MIAS, and DDSM mammography collections, we compare a baseline CNN, ConvNeXt Tiny, and InceptionV3 backbones enriched with GAGM and SEVector modules. Results confirm the effectiveness of GAGM and SEVector in enhancing feature discriminability and reducing false negatives, particularly for malignant cases. In our experiments, however, the Feature Smoothing Loss did not yield measurable improvements under mammography classification conditions, suggesting that its effectiveness may depend on specific architectural and computational assumptions. Beyond validation, our contribution extends the original framework through multi metric evaluation (macro F1, per class recall variance, ROC/AUC), feature interpretability analysis (Grad CAM), and the development of an interactive dashboard for clinical exploration. As a perspective, we highlight the need to explore alternative approaches to improve intra class compactness and inter class separability, with the specific goal of enhancing the distinction between malignant and benign cases in mammography classification.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [251] [Vec-LUT: Vector Table Lookup for Parallel Ultra-Low-Bit LLM Inference on Edge Devices](https://arxiv.org/abs/2512.06443)
*Xiangyu Li,Chengyu Yin,Weijun Wang,Jianyu Wei,Ting Cao,Yunxin Liu*

Main category: cs.DC

TL;DR: Vec-LUT通过优化LUT查找范式，提升边缘设备上超低比特LLM的并行推理性能，最高加速4.2倍。


<details>
  <summary>Details</summary>
Motivation: 现有基于LUT的推理在并行推理中内存带宽利用率不足，导致预填充、测试时扩展等多令牌场景性能受限。

Method: 提出向量LUT（Vec-LUT）范式，通过跨并行令牌构建统一LUT并执行单次$1 \rightarrow N$查找，结合向量LUT中心张量布局和缓存感知流式查找技术实现高效推理。

Result: 在5种边缘设备和3种LLM上的评估显示，Vec-LUT比现有最优方法快达$4.2\times$。

Conclusion: 本文提出的Vec-LUT方法通过优化内存带宽利用，显著提升了边缘设备上超低比特大语言模型的并行推理性能，并在多个设备和模型上验证了其有效性。

Abstract: Large language models (LLMs) are increasingly deployed on edge devices. To meet strict resource constraints, real-world deployment has pushed LLM quantization from 8-bit to 4-bit, 2-bit, and now 1.58-bit. Combined with lookup table (LUT)-based inference, CPUs run these ultra-low-bit LLMs even faster than NPUs, opening new opportunities for ubiquitous on-device intelligence.
  However, this paper identifies that LUT-based inference underutilizes memory bandwidth during parallel inference, which is required for prefilling, test-time scaling, and other multi-token scenarios. The root cause is the scalar LUT paradigm, which performs repetitive and non-contiguous memory accesses for each token.
  To solve the issue, we propose vector LUT, a new lookup paradigm that constructs a unified LUT across parallel tokens, and performs a single $1 \rightarrow N$ lookup per index. To realize it efficiently, we further introduce (1) Vector LUT-Centric Tensor Layout, and (2) Cache-Aware Streamed Lookup techniques. Evaluations on 5 edge devices across 3 LLMs show that Vec-LUT outperforms state-of-the-art baselines by up to $4.2\times$. Our implementation is integrated into llama.cpp. The code is available at https://github.com/Cipherxzc/vlut.cpp.

</details>


### [252] [Stable-MoE: Lyapunov-based Token Routing for Distributed Mixture-of-Experts Training over Edge Networks](https://arxiv.org/abs/2512.06784)
*Long Shi,Bingyan Ou,Kang Wei,Weihao Zhu,Zhe Wang,Zhiyong Chen*

Main category: cs.DC

TL;DR: Stable-MoE是一种基于Lyapunov优化的令牌路由框架，用于资源异构边缘网络中的分布式MoE训练，显著提升了效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统令牌路由在资源受限的边缘网络中面临工作负载积压、资源效率低下和性能下降的问题，需要一种新的解决方案。

Method: 提出了一种基于Lyapunov优化的令牌路由框架Stable-MoE，通过在线决策令牌路由和计算频率利用，将长期优化问题转化为可处理的时隙子问题。

Result: 在SVHN和CIFAR-100数据集上的实验表明，Stable-MoE在系统吞吐量和测试准确率上分别比基线方法至少提升了40%和5%。

Conclusion: Stable-MoE框架通过Lyapunov优化方法有效解决了分布式MoE训练在资源异构边缘网络中的挑战，显著提升了系统吞吐量和测试准确率。

Abstract: The sparse activation mechanism of mixture of experts (MoE) model empowers edge intelligence with enhanced training efficiency and reduced computational resource consumption. However, traditional token routing in distributed MoE training faces significant challenges in resource-constrained edge networks characterized by heterogeneous computing capabilities and stochastic token arrivals, which inevitably suffer from workload backlog, resource inefficiency, and performance degradation. To address this issue, we propose a novel Lyapunov-based token routing framework for distributed MoE training over resource-heterogeneous edge networks, termed Stable-MoE. Specifically, we formulate a stochastic optimization problem to maximize both system throughput and gating consistency via optimizing the token routing strategy and computational resource allocation, while ensuring long-term stability of both token and energy queues at the edge devices. Using the Lyapunov optimization, we transform the intractable long-term optimization problem into tractable per-slot subproblems by enabling online decision-making of token routing and computation frequency utilization without the knowledge of future system states. Experimental results on the SVHN and CIFAR-100 datasets demonstrate that Stable-MoE outperforms the baselines with at least 40% and 5% gains in system throughput and test accuracy, respectively.

</details>


### [253] [Cloud Revolution: Tracing the Origins and Rise of Cloud Computing](https://arxiv.org/abs/2512.06800)
*Deepa Gurung,S M Zia Ur Rashid,Zain ul Abdeen,Suman Rath*

Main category: cs.DC

TL;DR: 本文回顾了云计算的历史演变、当前应用及未来趋势，强调了平衡可扩展性、开放性和信任的重要性。


<details>
  <summary>Details</summary>
Motivation: 重新审视云计算的历史演变，分析其当前应用和未来趋势，以理解这一快速变化领域的未来发展。

Method: 通过重新审视云计算领域的历史演变，包括资源共享和基于效用的计算方法，以及分析技术和经济力量，本研究探讨了云计算平台如何改变组织计算习惯。

Result: 研究发现云计算平台降低了数据密集型和计算密集型应用的门槛，但也带来了大规模采用时的安全性和依赖性等限制。

Conclusion: 本文总结了云计算的历史演变、当前应用及其未来趋势，强调了在可扩展性、开放性和信任之间找到平衡的重要性。

Abstract: The history behind the development of cloud computing is more than several decades of technological progress in the fields of virtualization, distributed systems, and high-speed networking, but its current application is much broader than the underlying technologies that made it possible. This paper reexamines the historical evolution of the field, including the initial ideas of resource sharing and utility-based computing approaches and the development of hyperscale data centers and modern globally federated cloud ecosystems. We also analyze the technological and economic forces and point to the way cloud platforms altered the organizational computing habits, decreasing the entrance-level to the data-intensive and computation-heavy apps. The study also takes into account the ongoing limitations which have come with the large-scale adoption of clouds which include exposure to security due to the weaknesses in configuration, particular establishment regulations, and structural reliance on the single vendors. Lastly, we address some of the new trends that are transforming the cloud environment, including the convergence of edge and cloud infrastructure, the increased prominence of AI-optimised architectures and the initial adoption of quantum computing services. Collectively, the developments above describe an emerging but quickly changing paradigm with its future direction being determined by a strike of balancing between scalability, openness, and trust.

</details>


### [254] [Optimizing video analytics inference pipelines: a case study](https://arxiv.org/abs/2512.07009)
*Saeid Ghafouri,Yuming Ding,Katerine Diaz Chito,Jesús Martinez del Rincón,Niamh O'Connell,Hans Vandierendonck*

Main category: cs.DC

TL;DR: 本文通过多级优化策略，显著提升了家禽福利监测系统的性能，实现了2倍加速，为大规模视频分析提供了高效解决方案。


<details>
  <summary>Details</summary>
Motivation: 商业农场的高分辨率视频和近实时监控需求带来了巨大的计算负担，需要成本效益高且可扩展的视频分析解决方案。

Method: 采用多级并行化、GPU加速代码替代CPU代码、向量化聚类和内存高效后处理等优化策略。

Result: 在实际农场视频数据上的评估显示，优化后的系统在保持模型准确性的同时，实现了高达2倍的加速。

Conclusion: 本文通过系统级优化，显著提升了家禽福利监测系统的性能，为农业和大规模视频分析应用提供了高效、低延迟的解决方案。

Abstract: Cost-effective and scalable video analytics are essential for precision livestock monitoring, where high-resolution footage and near-real-time monitoring needs from commercial farms generates substantial computational workloads. This paper presents a comprehensive case study on optimizing a poultry welfare monitoring system through system-level improvements across detection, tracking, clustering, and behavioral analysis modules. We introduce a set of optimizations, including multi-level parallelization, Optimizing code with substituting CPU code with GPU-accelerated code, vectorized clustering, and memory-efficient post-processing. Evaluated on real-world farm video footage, these changes deliver up to a 2x speedup across pipelines without compromising model accuracy. Our findings highlight practical strategies for building high-throughput, low-latency video inference systems that reduce infrastructure demands in agricultural and smart sensing deployments as well as other large-scale video analytics applications.

</details>


### [255] [PIR-DSN: A Decentralized Storage Network Supporting Private Information Retrieval](https://arxiv.org/abs/2512.07189)
*Jiahao Zhang,Minghui Xu,Hechuan Guo,Xiuzhen Cheng*

Main category: cs.DC

TL;DR: PIR-DSN是首个整合PIR技术的DSN协议，解决了文件检索中的隐私问题，实验显示其在实际应用中的可行性。


<details>
  <summary>Details</summary>
Motivation: 当前DSN在文件检索过程中存在用户隐私暴露的风险，亟需一种既能保护隐私又能高效检索的解决方案。

Method: 引入了PIR-DSN协议，采用新颖的安全映射方法将稀疏文件标识符转换为紧凑整数索引，支持文件操作的公共可验证性和高效私有检索，并通过多矿工文件复制保证拜占庭鲁棒的私有检索。

Result: PIR-DSN在文件上传和删除方面开销与现有系统相当，尽管PIR导致检索延迟增加，但吞吐量保持可比性，验证了其在隐私敏感应用中的实用性。

Conclusion: PIR-DSN的提出解决了DSN中用户隐私保护的漏洞，通过整合PIR技术实现了高效且安全的文件检索，实验证明其在隐私敏感应用中的实际可行性。

Abstract: Decentralized Storage Networks (DSNs) are emerging as a foundational infrastructure for Web 3.0, offering global peer-to-peer storage. However, a critical vulnerability persists: user privacy during file retrieval remains largely unaddressed, risking the exposure of sensitive information. To overcome this, we introduce PIR-DSN, the first DSN protocol to integrate Private Information Retrieval (PIR) for both single and multi-server settings. Our key innovations include a novel secure mapping method that transforms sparse file identifiers into compact integer indexes, enabling both public verifiability of file operations and efficient private retrieval. Furthermore, PIR-DSN guarantees Byzantine-robust private retrieval through file replication across multiple miners. We implement and rigorously evaluate PIR-DSN against three prominent industrial DSN systems. Experimental results demonstrate that PIR-DSN achieves comparable overhead for file upload and deletion. While PIR inherently introduces an additional computational cost leading to higher retrieval latency, PIR-DSN maintains comparable throughput. These findings underscore PIR-DSN's practical viability for privacy-sensitive applications within DSN environments.

</details>


### [256] [ContinuumConductor : Decentralized Process Mining on the Edge-Cloud Continuum](https://arxiv.org/abs/2512.07280)
*Hendrik Reiter,Janick Edinger,Martin Kabierski,Agnes Koschmider,Olaf Landsiedel,Arvid Lepsien,Xixi Lu,Andrea Marrella,Estefania Serral,Stefan Schulte,Florian Tschorsch,Matthias Weidlich,Wilhelm Hasselbring*

Main category: cs.DC

TL;DR: 提出ContinuumConductor框架，在分布式边缘-云基础设施中实现分散化过程挖掘，平衡隐私、响应速度和资源效率，并通过实际案例验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现代工业物联网系统在分布式、资源受限的边缘-云基础设施上运行，传统集中式事件数据收集和分析方法不再适用，需探索分散化过程挖掘方法。

Method: 引入ContinuumConductor，一个分层的决策框架，指导在过程挖掘任务（如预处理、关联和发现）中选择集中或分散执行，分析每一步的权衡并制定决策标准。

Result: 通过实际案例（内河港口的过程优化）展示了ContinuumConductor的有效性，实现了隐私保护、响应迅速且资源高效的过程挖掘。

Conclusion: 本文为网络物理和工业物联网系统中的计算感知过程挖掘奠定了基础，提出了ContinuumConductor框架，有效解决了分布式边缘-云基础设施中的过程挖掘问题。

Abstract: Process mining traditionally assumes centralized event data collection and analysis. However, modern Industrial Internet of Things systems increasingly operate over distributed, resource-constrained edge-cloud infrastructures. This paper proposes a structured approach for decentralizing process mining by enabling event data to be mined directly within the IoT systems edge-cloud continuum. We introduce ContinuumConductor a layered decision framework that guides when to perform process mining tasks such as preprocessing, correlation, and discovery centrally or decentrally. Thus, enabling privacy, responsive and resource-efficient process mining. For each step in the process mining pipeline, we analyze the trade-offs of decentralization versus centralization across these layers and propose decision criteria. We demonstrate ContinuumConductor at a real-world use-case of process optimazition in inland ports. Our contributions lay the foundation for computing-aware process mining in cyber-physical and IIoT systems.

</details>


### [257] [Venus: An Efficient Edge Memory-and-Retrieval System for VLM-based Online Video Understanding](https://arxiv.org/abs/2512.07344)
*Shengyuan Ye,Bei Ouyang,Tianyi Qian,Liekang Zeng,Mu Yuan,Xiaowen Chu,Weijie Hong,Xu Chen*

Main category: cs.DC

TL;DR: Venus是一种高效的边缘-云端在线视频理解系统，通过分层记忆和渐进采样算法，大幅降低延迟并保持高精度。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型在多模态理解方面表现优异，但其部署时的系统开销问题被忽视，导致实际部署效率低下。

Method: Venus采用两阶段架构：1) 摄入阶段通过场景分割和聚类处理流式边缘视频，构建分层记忆；2) 查询阶段通过基于阈值的渐进采样算法选择关键帧，平衡系统成本和推理精度。

Result: Venus在响应延迟上实现了15倍至131倍的加速，支持秒级实时响应，且推理精度与现有方法相当或更优。

Conclusion: Venus通过边缘-云端分离架构和渐进式采样算法，显著提升了在线视频理解的效率，实现了实时响应，同时保持了高推理精度。

Abstract: Vision-language models (VLMs) have demonstrated impressive multimodal comprehension capabilities and are being deployed in an increasing number of online video understanding applications. While recent efforts extensively explore advancing VLMs' reasoning power in these cases, deployment constraints are overlooked, leading to overwhelming system overhead in real-world deployments. To address that, we propose Venus, an on-device memory-and-retrieval system for efficient online video understanding. Venus proposes an edge-cloud disaggregated architecture that sinks memory construction and keyframe retrieval from cloud to edge, operating in two stages. In the ingestion stage, Venus continuously processes streaming edge videos via scene segmentation and clustering, where the selected keyframes are embedded with a multimodal embedding model to build a hierarchical memory for efficient storage and retrieval. In the querying stage, Venus indexes incoming queries from memory, and employs a threshold-based progressive sampling algorithm for keyframe selection that enhances diversity and adaptively balances system cost and reasoning accuracy. Our extensive evaluation shows that Venus achieves a 15x-131x speedup in total response latency compared to state-of-the-art methods, enabling real-time responses within seconds while maintaining comparable or even superior reasoning accuracy.

</details>


### [258] [Communication-Efficient Serving for Video Diffusion Models with Latent Parallelism](https://arxiv.org/abs/2512.07350)
*Zhiyuan Wu,Shuai Wang,Li Chen,Kaihui Gao,Dan Li,Yanyu Ren,Qiming Zhang,Yong Wang*

Main category: cs.DC

TL;DR: LP是一种专为VDMs设计的并行策略，通过动态分区和潜在空间优化，显著减少通信开销，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 视频扩散模型（VDMs）的内存消耗呈立方级增长，传统并行策略导致高维激活传输频繁，形成严重的通信瓶颈。

Method: LP通过动态旋转分区维度（时间、高度和宽度）在紧凑的潜在空间中分解全局去噪问题，显著减少了通信开销。

Result: 实验表明，LP在三个基准测试中将通信开销降低了高达97%，同时保持了相当的生成质量。

Conclusion: LP作为一种非侵入式插件范式，可以与现有并行策略无缝集成，实现高效且可扩展的视频生成服务。

Abstract: Video diffusion models (VDMs) perform attention computation over the 3D spatio-temporal domain. Compared to large language models (LLMs) processing 1D sequences, their memory consumption scales cubically, necessitating parallel serving across multiple GPUs. Traditional parallelism strategies partition the computational graph, requiring frequent high-dimensional activation transfers that create severe communication bottlenecks. To tackle this issue, we exploit the local spatio-temporal dependencies inherent in the diffusion denoising process and propose Latent Parallelism (LP), the first parallelism strategy tailored for VDM serving. \textcolor{black}{LP decomposes the global denoising problem into parallelizable sub-problems by dynamically rotating the partitioning dimensions (temporal, height, and width) within the compact latent space across diffusion timesteps, substantially reducing the communication overhead compared to prevailing parallelism strategies.} To ensure generation quality, we design a patch-aligned overlapping partition strategy that matches partition boundaries with visual patches and a position-aware latent reconstruction mechanism for smooth stitching. Experiments on three benchmarks demonstrate that LP reduces communication overhead by up to 97\% over baseline methods while maintaining comparable generation quality. As a non-intrusive plug-in paradigm, LP can be seamlessly integrated with existing parallelism strategies, enabling efficient and scalable video generation services.

</details>


### [259] [Otus Supercomputer](https://arxiv.org/abs/2512.07401)
*Sadaf Ehtesabi,Manoar Hossain,Tobias Kenter,Andreas Krawinkel,Holger Nitsche,Lukas Ostermann,Christian Plessl,Heinrich Riebler,Stefan Rohde,Robert Schade,Michael Schwarz,Jens Simon,Nils Winnwa,Alex Wiens,Xin Wu*

Main category: cs.DC

TL;DR: Otus是德国帕德博恩大学的高性能计算集群，性能是前代的两倍，硬件包括CPU、GPU和FPGA节点，在Top500和Green500中表现优异。


<details>
  <summary>Details</summary>
Motivation: 为科学家和其他HPC中心提供Otus系统的全面概述，展示其在计算能力和能源效率方面的优势。

Method: 文章详细介绍了Otus的硬件配置、软件架构、系统集成及其在数据中心中的能效优化设计。

Result: Otus在Top500和Green500榜单中分别位列164/255和第五名，证明了其高性能和高效能。

Conclusion: Otus作为高性能计算集群，通过硬件、软件和系统集成的优化，显著提升了计算能力和能源效率，为科学研究和HPC集群运营提供了宝贵参考。

Abstract: Otus is a high-performance computing cluster that was launched in 2025 and is operated by the Paderborn Center for Parallel Computing (PC2) at Paderborn University in Germany. The system is part of the National High Performance Computing (NHR) initiative. Otus complements the previous supercomputer Noctua 2, offering approximately twice the computing power while retaining the three node types that were characteristic of Noctua 2: 1) CPU compute nodes with different memory capacities, 2) high-end GPU nodes, and 3) HPC-grade FPGA nodes. On the Top500 list, which ranks the 500 most powerful supercomputers in the world, Otus is in position 164 with the CPU partition and in position 255 with the GPU partition (June 2025). On the Green500 list, ranking the 500 most energy-efficient supercomputers in the world, Otus is in position 5 with the GPU partition (June 2025).
  This article provides a comprehensive overview of the system in terms of its hardware, software, system integration, and its overall integration into the data center building to ensure energy-efficient operation. The article aims to provide unique insights for scientists using the system and for other centers operating HPC clusters. The article will be continuously updated to reflect the latest system setup and measurements.

</details>


### [260] [Bandwidth-Aware Network Topology Optimization for Decentralized Learning](https://arxiv.org/abs/2512.07536)
*Yipeng Shen,Zehan Zhu,Yan Huang,Changzhi Yan,Cheng Zhuo,Jinming Xu*

Main category: cs.DC

TL;DR: 提出带宽感知网络拓扑优化框架，通过ADMM和共轭梯度法提升共识速度，实验证明其在分布式学习中显著减少训练时间。


<details>
  <summary>Details</summary>
Motivation: 现有网络拓扑设计大多未考虑带宽限制，影响了分布式学习中的参数同步效率。

Method: 通过将问题重构为混合整数半定规划问题，并采用基于ADMM的计算高效方法，结合共轭梯度法解决大规模线性方程。

Result: 实验结果显示，优化后的网络拓扑在共识速度上优于基准拓扑，且在真实数据集上减少了训练时间，同构和异构带宽设置下分别实现了1.11倍和1.21倍的加速。

Conclusion: 提出的带宽感知网络拓扑优化框架在异构带宽场景下显著提升了共识速度和分布式学习效率，实验证明了其优越性。

Abstract: Network topology is critical for efficient parameter synchronization in distributed learning over networks. However, most existing studies do not account for bandwidth limitations in network topology design. In this paper, we propose a bandwidth-aware network topology optimization framework to maximize consensus speed under edge cardinality constraints. For heterogeneous bandwidth scenarios, we introduce a maximum bandwidth allocation strategy for the edges to ensure efficient communication among nodes. By reformulating the problem into an equivalent Mixed-Integer SDP problem, we leverage a computationally efficient ADMM-based method to obtain topologies that yield the maximum consensus speed. Within the ADMM substep, we adopt the conjugate gradient method to efficiently solve large-scale linear equations to achieve better scalability. Experimental results demonstrate that the resulting network topologies outperform the benchmark topologies in terms of consensus speed, and reduce the training time required for decentralized learning tasks on real-world datasets to achieve the target test accuracy, exhibiting speedups of more than $1.11\times$ and $1.21\times$ for homogeneous and heterogeneous bandwidth settings, respectively.

</details>


### [261] [A Performance Analyzer for a Public Cloud's ML-Augmented VM Allocator](https://arxiv.org/abs/2512.07750)
*Roozbeh Bostandoost,Pooria Namyar,Siva Kesava Reddy Kakarla,Ryan Beckett,Santiago Segarra,Eli Cortez,Ankur Mallick,Kevin Hsieh,Rodrigo Fonseca,Mohammad Hajiesmaili,Behnaz Arzani*

Main category: cs.DC

TL;DR: SANJESH 是一个通过双层优化帮助理解云系统中机器学习模型交互对性能影响的工具，显著提升了优化效率，并在虚拟机放置案例中发现了传统方法未检测到的性能问题。


<details>
  <summary>Details</summary>
Motivation: 现有的云系统缺乏工具来评估多个机器学习模型及其交互对系统性能的影响。

Method: SANJESH 采用双层优化方法，并发明了新型机制以加速优化过程。

Result: 在虚拟机放置的案例中，SANJESH 发现了比传统仿真方法检测到的性能差 4 倍的场景。

Conclusion: SANJESH 是一种能够帮助云系统操作员理解机器学习模型及其交互对端到端系统性能影响的工具，通过双层优化和新型机制显著提升了优化效率。

Abstract: Many operational cloud systems use one or more machine learning models that help them achieve better efficiency and performance. But operators do not have tools to help them understand how each model and the interaction between them affect the end-to-end system performance. SANJESH is such a tool. SANJESH supports a diverse set of performance-related queries which we answer through a bi-level optimization. We invent novel mechanisms to solve this optimization more quickly. These techniques allow us to solve an optimization which prior work failed to solve even after $24$ hours.
  As a proof of concept, we apply SANJESH to an example production system that uses multiple ML models to optimize virtual machine (VM) placement. These models impact how many servers the operators uses to host VMs and the frequency with which it has to live-migrate them because the servers run out of resources. SANJESH finds scenarios where these models cause $~4\times$ worse performance than what simulation-based approaches detect.

</details>


### [262] [Designing Co-operation in Systems of Hierarchical, Multi-objective Schedulers for Stream Processing](https://arxiv.org/abs/2512.07792)
*Animesh Dangwal,Yufeng Jiang,Charlie Arnold,Jun Fan,Mohamed Bassem,Aish Rajagopal*

Main category: cs.DC

TL;DR: Meta研究了一种新型流处理系统，专注于关键计算资源的负载平衡，并通过集成新调度器到现有层次结构中，实现了多调度器的协同工作，提升了系统性能。


<details>
  <summary>Details</summary>
Motivation: 随着应用和用户需求的复杂性不断增加，基础设施中原本负载平衡需求较低的部分现在需要变得更加健壮和主动应对应用负载。

Method: 研究探索了如何构建和设计一个专注于关键计算资源负载平衡的系统，并展示了如何将新调度器集成到现有调度器层次结构中，实现多调度器的协同工作。

Result: 提出的系统设计能够有效提升负载平衡能力，支持多调度器在各自基础设施层面的协同工作。

Conclusion: 论文提出了一种新型的流处理系统设计，专注于关键计算资源的负载平衡，并通过集成新调度器到现有层次结构中，实现了多调度器的协同工作，有效提升了负载平衡能力。

Abstract: Stream processing is a computing paradigm that supports real-time data processing for a wide variety of applications. At Meta, it's used across the company for various tasks such as deriving product insights, providing and improving user services, and enabling AI at scale for our ever-growing user base. Meta's current stream processing framework supports processing TerraBytes(TBs) of data in mere seconds. This is enabled by our efficient schedulers and multi-layered infrastructure, which allocate workloads across various compute resources, working together in hierarchies across various parts of the infrastructure. But with the ever growing complexity of applications, and user needs, areas of the infrastructure that previously required minimal load balancing, now must be made more robust and proactive to application load. In our work we explore how to build and design such a system that focuses on load balancing over key compute resources and properties of these applications. We also showcase how to integrate new schedulers into the hierarchy of the existing ones, allowing multiple schedulers to work together and perform load balancing, at their infrastructure level, effectively.

</details>


### [263] [Quantifying the Carbon Reduction of DAG Workloads: A Job Shop Scheduling Perspective](https://arxiv.org/abs/2512.07799)
*Roozbeh Bostandoost,Adam Lechowicz,Walid A. Hanafy,Prashant Shenoy,Mohammad Hajiesmaili*

Main category: cs.DC

TL;DR: 依赖感知的碳调度器能降低25%碳排放，延长任务时间可进一步节省碳，但需权衡能源和完成时间。


<details>
  <summary>Details</summary>
Motivation: 大多数调度器将工作负载视为单一任务，忽略了任务间的依赖关系和资源需求，这限制了碳效率的提升潜力。

Method: 将问题建模为灵活的作业车间调度变体，并使用离线求解器计算碳排放和能源节省的上限。

Result: 结果显示，依赖感知方法平均可降低25%的碳排放，且不增加最优完成时间；允许两倍的最优完成时间时，碳节省几乎翻倍。

Conclusion: 碳感知调度器通过利用工作负载的依赖结构，可以显著降低数据中心的碳排放，尤其是在允许延长任务完成时间的情况下。

Abstract: Carbon-aware schedulers aim to reduce the operational carbon footprint of data centers by running flexible workloads during periods of low carbon intensity. Most schedulers treat workloads as single monolithic tasks, ignoring that many jobs, like video encoding or offline inference, consist of smaller tasks with specific dependencies and resource needs; however, knowledge of this structure enables opportunities for greater carbon efficiency.
  We quantify the maximum benefit of a dependency-aware approach for batch workloads. We model the problem as a flexible job-shop scheduling variant and use an offline solver to compute upper bounds on carbon and energy savings. Results show up to $25\%$ lower carbon emissions on average without increasing the optimal makespan (total job completion time) compared to a makespan-only baseline. Although in heterogeneous server setup, these schedules may use more energy than energy-optimal ones. Our results also show that allowing twice the optimal makespan nearly doubles the carbon savings, underscoring the tension between carbon, energy, and makespan. We also highlight key factors such as job structure and server count influence the achievable carbon reductions.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [264] [AIMNET: An IoT-Empowered Digital Twin for Continuous Gas Emission Monitoring and Early Hazard Detection](https://arxiv.org/abs/2512.06148)
*Zifan Zhou,Xuan Wang,Yang Yan,Lkhanaajav Mijiddorj,Yu Ding,Tyler Beringer,Parisa Masnadi Khiabani,Wolfgang G. Jentner,Xiao-Ming Hu,Chenghao Wang,Bryan M. Carroll,Ming Xue,David Ebert,Bin Li,Binbin Weng*

Main category: cs.NI

TL;DR: AIMNET是一个集成物联网传感网络和物理多尺度天气-气体传输模型的数字孪生框架，用于实时高分辨率监测碳排放，初步验证有效。


<details>
  <summary>Details</summary>
Motivation: 提升基于碳的气体羽流监测，以支持对环境危害（如工业气体泄漏或野火爆发）的及时有效缓解响应。

Method: AIMNET采用三层系统架构：物理世界（定制设备）、双向信息反馈链路（智能数据传输和反向控制）和数字孪生世界（AI驱动的分析和动态天气-气体耦合分子传输建模）。

Result: 初步结果成功捕获了甲烷排放事件，并通过分层模型模拟进一步解析了其动态。

Conclusion: AIMNET提供了一个有前景的数字孪生框架，用于可靠的实时监测和预测性风险评估。

Abstract: A Digital Twin (DT) framework to enhance carbon-based gas plume monitoring is critical for supporting timely and effective mitigation responses to environmental hazards such as industrial gas leaks, or wildfire outbreaks carrying large carbon emissions. We present AIMNET, a one-of-a-kind DT framework that integrates a built-in-house Internet of Things (IoT)-based continuous sensing network with a physics-based multi-scale weather-gas transport model, that enables high-resolution and real-time simulation and detection of carbon gas emissions. AIMNET features a three-layer system architecture: (i) physical world: custom-built devices for continuous monitoring; (ii) bidirectional information feedback links: intelligent data transmission and reverse control; and (iii) digital twin world: AI-driven analytics for prediction, anomaly detection, and dynamic weather-gas coupled molecule transport modeling. Designed for scalable, energy-efficient deployment in remote environments, AIMNET architecture is realized through a small-scale distributed sensing network over an oil and gas production basin. To demonstrate the high-resolution, fast-responding concept, an equivalent mobile-based emission monitoring network was deployed around a wastewater treatment plant that constantly emits methane plumes. Our preliminary results through which, have successfully captured the methane emission events whose dynamics have been further resolved by the tiered model simulations. This work supports our position that AIMNET provides a promising DT framework for reliable, real-time monitoring and predictive risk assessment. In the end, we also discuss key implementation challenges and outline future directions for advancing such a new DT framework for translation deployment.

</details>


### [265] [Programmable and GPU-Accelerated Edge Inference for Real-Time ISAC on NVIDIA ARC-OTA](https://arxiv.org/abs/2512.06493)
*Davide Villa,Mauro Belgiovine,Nicholas Hedberg,Michele Polese,Chris Dick,Tommaso Melodia*

Main category: cs.NI

TL;DR: 论文提出GPU加速的AI框架支持ISAC，通过cuSense应用实现高精度室内定位，为6G传感提供参考。


<details>
  <summary>Details</summary>
Motivation: 随着传感成为6G标准化的关键特性，如何在有限带宽下支持ISAC并保持高可靠性和性能，成为系统级挑战。

Method: 论文提出了一个基于Open RAN dApp架构的框架，利用NVIDIA ARC-OTA的GPU加速gNB，将PHY/MAC数据以低于0.5毫秒的延迟传输到自定义AI逻辑中。

Result: 在3GPP兼容的5G NR部署中，cuSense实现了平均77厘米的定位误差，75%的预测在1米以内，且无需专用传感硬件或修改RAN堆栈或信号。

Conclusion: 该论文提出了一个可编程、即插即用的框架，用于在边缘RAN基础设施上通过实时GPU加速的AI应用处理PHY/MAC信号，并通过cuSense应用展示了其能力，为未来AI原生RAN和ISAC应用提供了参考设计。

Abstract: The transition of cellular networks to (i) software-based systems on commodity hardware and (ii) platforms for services beyond connectivity introduces critical system-level challenges. As sensing emerges as a key feature toward 6G standardization, supporting Integrated Sensing and Communication (ISAC) with limited bandwidth and piggybacking on communication signals, while maintaining high reliability and performance, remains a fundamental challenge. In this paper, we provide two key contributions. First, we present a programmable, plug-and-play framework for processing PHY/MAC signals through real-time, GPU-accelerated Artificial Intelligence (AI) applications on the edge Radio Access Network (RAN) infrastructure. Building on the Open RAN dApp architecture, the framework interfaces with a GPU-accelerated gNB based on NVIDIA ARC-OTA, feeding PHY/MAC data to custom AI logic with latency under 0.5 ms for complex channel state information extraction. Second, we demonstrate the framework's capabilities through cuSense, an indoor localization dApp that consumes uplink DMRS channel estimates, removes static multipath components, and runs a neural network to infer the position of a moving person. Evaluated on a 3GPP-compliant 5G NR deployment, cuSense achieves a mean localization error of 77 cm, with 75% of predictions falling within 1 meter. This is without dedicated sensing hardware or modifications to the RAN stack or signals. We plan to release both the framework and cuSense pipelines as open source, providing a reference design for future AI-native RANs and ISAC applications.

</details>


### [266] [AQUILA: A QUIC-Based Link Architecture for Resilient Long-Range UAV Communication](https://arxiv.org/abs/2512.06889)
*Ximing Huang,Yirui Rao*

Main category: cs.NI

TL;DR: AQUILA 是一种基于 QUIC 的 UAV 通信架构，通过跨层优化解决了现有方案的局限性，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有解决方案（如 TCP、UDP 和蜂窝网络）在 UAV 的 BVLOS 应用中存在严重局限性，无法满足高带宽、低延迟和可靠性的需求。

Method: AQUILA 基于 QUIC 构建，结合了可靠流（MAVLink C2）和不可靠数据报（视频传输），并引入了优先级调度和 UAV 自适应拥塞控制算法。

Result: 实验证明，AQUILA 在 C2 延迟、视频质量和链路弹性方面显著优于基于 TCP 和 UDP 的方案。

Conclusion: AQUILA 提供了一种高效的跨层通信架构，显著提升了 BVLOS 应用中 UAV 的通信性能，为自主飞行任务奠定了坚实基础。

Abstract: The proliferation of autonomous Unmanned Aerial Vehicles (UAVs) in Beyond Visual Line of Sight (BVLOS) applications is critically dependent on resilient, high-bandwidth, and low-latency communication links. Existing solutions face critical limitations: TCP's head-of-line blocking stalls time-sensitive data, UDP lacks reliability and congestion control, and cellular networks designed for terrestrial users degrade severely for aerial platforms. This paper introduces AQUILA, a cross-layer communication architecture built on QUIC to address these challenges. AQUILA contributes three key innovations: (1) a unified transport layer using QUIC's reliable streams for MAVLink Command and Control (C2) and unreliable datagrams for video, eliminating head-of-line blocking under unified congestion control; (2) a priority scheduling mechanism that structurally ensures C2 latency remains bounded and independent of video traffic intensity; (3) a UAV-adapted congestion control algorithm extending SCReAM with altitude-adaptive delay targeting and telemetry headroom reservation. AQUILA further implements 0-RTT connection resumption to minimize handover blackouts with application-layer replay protection, deployed over an IP-native architecture enabling global operation. Experimental validation demonstrates that AQUILA significantly outperforms TCP- and UDP-based approaches in C2 latency, video quality, and link resilience under realistic conditions, providing a robust foundation for autonomous BVLOS missions.

</details>


### [267] [Hyperflex: A SIMD-based DFA Model for Deep Packet Inspection](https://arxiv.org/abs/2512.07123)
*Yang Liu,Wenjun Zhu,Harry Chang,Yang Hong,Geoff Langdale,Kun Qiu,Jin Zhao*

Main category: cs.NI

TL;DR: Hyperflex 是一种基于 SIMD 的高性能 DFA 模型，通过区域检测和混合状态转换算法，显著提升正则表达式匹配效率。


<details>
  <summary>Details</summary>
Motivation: 传统 DFA 模型在网络带宽和规则集规模快速增长时成为性能瓶颈，SIMD 指令可显著提升效率。

Method: 提出 Hyperflex，一种基于 SIMD 的 DFA 模型，包含区域检测算法和混合状态转换算法。

Result: Hyperflex 实现了 8.89Gbit/s 的吞吐量，比 Hyperscan 默认 DFA 模型 Mcclellan 提升了 2.27 倍。

Conclusion: Hyperflex 成功部署于 Hyperscan，显著提升了其性能，证明了其在高性能正则表达式匹配中的有效性。

Abstract: Deep Packet Inspection (DPI) has been extensively employed for network security. It examines traffic payloads by searching for regular expressions (regex) with the Deterministic Finite Automaton (DFA) model. However, as the network bandwidth and ruleset size are increasing rapidly, the conventional DFA model has emerged as a significant performance bottleneck of DPI. Leveraging the Single-Instruction-Multiple-Data (SIMD) instruction to perform state transitions can substantially boost the efficiency of the DFA model. In this paper, we propose Hyperflex, a novel SIMD-based DFA model designed for high-performance regex matching. Hyperflex incorporates a region detection algorithm to identify regions suitable for acceleration by SIMD instructions across the whole DFA graph. Also, we design a hybrid state transition algorithm that enables state transition in both SIMD-accelerated and normal regions, and ensures seamless state transition across the two types of regions. We have implemented Hyperflex on the commodity CPU and evaluated it with real network traffic and DPI regexes. Our evaluation results indicate that Hyperflex reaches a throughput of 8.89Gbit/s, representing an improvement of up to 2.27 times over Mcclellan, the default DFA model of the prominent multi-pattern regex matching engine Hyperscan. As a result, Hyperflex has been successfully deployed in Hyperscan, significantly enhancing its performance.

</details>


### [268] [Implementation of Honeynet and Honeypot in Network Infrastructure in Production Network](https://arxiv.org/abs/2512.07180)
*Nawshad Ahmed Evan,Md Raihan Uddin*

Main category: cs.NI

TL;DR: 蜜罐在蜜网中模拟真实资源，成功欺骗攻击者并分析其行为，证明其在网络安全中的有效性。


<details>
  <summary>Details</summary>
Motivation: 随着网络基础设施日益成为攻击目标，保护其安全变得至关重要。蜜罐作为一种高效工具，能够误导攻击者并收集其行为数据。

Method: 通过构建一个模拟生产环境的蜜网，利用蜜罐作为诱饵，吸引并分析攻击者的行为。

Result: 蜜罐成功模拟了真实资源，有效欺骗了攻击者，并提供了攻击行为的详细分析。

Conclusion: 本文展示了蜜网（honeynet）中蜜罐（honeypot）如何有效模拟真实资源来欺骗攻击者并分析其行为，证明了其在保护网络基础设施中的高效性。

Abstract: Network infrastructure in a production environment is increasingly targeted by attackers every day. Many resources and services now rely on the internet, making network infrastructure one of the most critical parts to protect, as it hosts numerous company resources and services. Several solutions have already been proposed to prevent attacks, minimize damage, and divert hackers and intruders. Among these, the honeypot stands out as a highly effective tool; it is designed to mimic both a scanner and an attacker, diverting and misleading them within a simulated, production-level environment. This paper will demonstrate the use of a honeynet where a honeypot acts like a real resource to deceive the attacker and analyze their behavior.

</details>


### [269] [WaggleNet: A LoRa and MQTT-Based Monitoring System for Internal and External Beehive Conditions](https://arxiv.org/abs/2512.07408)
*Minju Jeon,Jiyun Kim,Sewon Kim,Seongmin Park,Bo Zhang,Anthony H. Smith*

Main category: cs.NI

TL;DR: WaggleNet是一种经济高效的双范围监测系统，通过LoRa-MQTT架构同时监测蜂巢内外环境，支持精准养蜂，填补现有系统不足。


<details>
  <summary>Details</summary>
Motivation: 蜜蜂种群因栖息地丧失、农药暴露和气候变化而全球性减少，威胁农业生产力与粮食安全。现有智能蜂箱系统通常忽略外部环境因素，且成本高、可扩展性有限、缺乏情境分析。

Method: 采用经济高效的LoRa-MQTT架构，部署模块化工作节点（每个约15美元），配备温度、湿度、光照和GPS传感器，主节点作为LoRa-MQTT网关转发数据至云端服务器和移动应用界面。

Result: 实地实验证实，系统在110米视线条件和95米遮挡环境下实现100%数据包传输，端到端延迟稳定在5秒内，并在两个月内持续运行于多样环境条件下。

Conclusion: WaggleNet通过同时监测蜂巢内外环境参数，填补了现有智能蜂箱系统的不足，支持资源受限环境下的数据驱动精准养蜂。

Abstract: Bee populations are declining globally due to habitat loss, pesticide exposure, and climate change, threatening agricultural productivity and food security. While existing smart beehive systems monitor internal conditions, they typically overlook external environmental factors that significantly influence colony health, and are constrained by high cost, limited scalability, and inadequate contextual analysis. We present WaggleNet, a novel dual-scope monitoring system that simultaneously captures both internal hive conditions and external environmental parameters using a cost-effective LoRa-MQTT architecture. Our system deploys modular worker nodes ($\sim$\$15 each) equipped with temperature, humidity, light, and GPS sensors both inside and around beehives. A master node functions as a LoRa-MQTT gateway, forwarding data to a cloud server with a mobile application interface. Field experiments confirmed reliable operation with 100\% packet delivery over 110 meters in line-of-sight conditions and 95 meters in obstructed environments, including successful deployment inside wooden hive structures. Our system demonstrated stable end-to-end latency under 5 seconds and continuous operation over a two-month period across diverse environmental conditions. By bridging the gap between internal and external monitoring, WaggleNet enables contextual anomaly detection and supports data-driven precision beekeeping in resource-constrained settings.

</details>


### [270] [Service Registration, Indexing, Discovery & Selection; An Architectural Survey Toward a GenAI-Driven Future](https://arxiv.org/abs/2512.07638)
*Mohammad Farhoudi,Masoud Shokrnezhad,Tarik Taleb*

Main category: cs.NI

TL;DR: 本文探讨了6G网络中服务编排的基础理论和未来设计目标，提出了混合架构框架，并指出了开放挑战和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着6G网络的发展，服务编排机制的需求日益增长，需要解决多样化和动态化的服务需求。

Method: 通过文献综述和差距分析，建立了SRIDS的理论基础，并提出了分类法和混合架构框架。

Result: 提出了一个结合集中化和分布式协调的混合架构框架，并评估了现有研究的设计目标。

Conclusion: 本文总结了6G网络中服务编排的开放挑战，并提出了未来研究方向，强调了混合架构框架的潜力。

Abstract: The emergence of sixth-generation (6G) networks marks a paradigm shift: by unifying an edge-to-cloud computing continuum with ultra-high-performance networking, 6G will enable capabilities far beyond today's boundaries. As use-case diversity grows exponentially and user adoption drives traffic to unprecedented and highly dynamic levels, novel service orchestration mechanisms are indispensable. In this paper, we adopt an architectural viewpoint, examining Service Registration, Indexing, Discovery, and Selection (SRIDS) as fundamental elements of 6G service provision. We first establish the theoretical foundations of SRIDS in 6G by defining its core concepts, detailing its end-to-end workflow, reviewing current standardization efforts, and projecting its future design objectives, including reliability, scalability, automaticity and adaptability, determinism, efficiency, sustainability, semantic-awareness, security, privacy, and trust. We then perform a comprehensive literature review and gap analysis encompassing both existing surveys and recent research efforts, identifying conceptual and methodological gaps that hinder unified SRIDS in 6G. Next, we introduce a taxonomy that classifies SRIDS mechanisms into centralized, distributed, decentralized, and hybrid architectures, and systematically examine the relevant studies within each category. Each work is evaluated against the extracted design objectives. Building on these findings, we propose a hybrid architectural framework, combining centralized data management to ensure consistency and agility with distributed coordination to enhance scalability in emerging 6G use cases. The framework incorporates innovative technologies, such as Generative Artificial Intelligence (GenAI). We conclude by highlighting open challenges and suggesting directions for future research.

</details>


### [271] [Multi-Generator Continual Learning for Robust Delay Prediction in 6G](https://arxiv.org/abs/2512.07726)
*Xiaoyu Lan,Jalil Taghia,Hannes Larsson,Andreas Johnsson*

Main category: cs.NI

TL;DR: 论文提出多生成器持续学习框架结合TVAE，解决OWD预测中的灾难性遗忘问题，5G测试数据验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 未来6G网络中，动态网络环境会导致分布偏移，引发灾难性遗忘和ML模型性能下降，因此需要一种能够平衡稳定性和可塑性的持续学习方法。

Method: 采用多生成器概念改进现有的持续学习生成回放框架，并使用TVAE作为生成器，同时将UE能力领域知识融入学习过程以确定生成器设置和相关性。

Result: 在多样化的5G测试床数据场景中，所提方法表现出色，优于基线模型。

Conclusion: 论文提出了一种基于多生成器的持续学习框架，结合TVAE生成器，有效解决了OWD预测模型中的灾难性遗忘问题，并在多样化的5G测试床数据场景中展示了优于基线的性能。

Abstract: In future 6G networks, dependable networks will enable telecommunication services such as remote control of robots or vehicles with strict requirements on end-to-end network performance in terms of delay, delay variation, tail distributions, and throughput. With respect to such networks, it is paramount to be able to determine what performance level the network segment can guarantee at a given point in time. One promising approach is to use predictive models trained using machine learning (ML). Predicting performance metrics such as one-way delay (OWD), in a timely manner, provides valuable insights for the network, user equipments (UEs), and applications to address performance trends, deviations, and violations. Over the course of time, a dynamic network environment results in distributional shifts, which causes catastrophic forgetting and drop of ML model performance. In continual learning (CL), the model aims to achieve a balance between stability and plasticity, enabling new information to be learned while preserving previously learned knowledge. In this paper, we target on the challenges of catastrophic forgetting of OWD prediction model. We propose a novel approach which introducing the concept of multi-generator for the state-of-the-art CL generative replay framework, along with tabular variational autoencoders (TVAE) as generators. The domain knowledge of UE capabilities is incorporated into the learning process for determining generator setup and relevance. The proposed approach is evaluated across a diverse set of scenarios with data that is collected in a realistic 5G testbed, demonstrating its outstanding performance in comparison to baselines.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [272] [Inverse Discrete Elastic Rod](https://arxiv.org/abs/2512.06830)
*Jiahao Li,Mingchao Liu,Haiyi Liang,HengAn Wu,Weicheng Huang*

Main category: cs.GR

TL;DR: A new inverse-DER method efficiently designs slender elastic structures by treating the inverse problem as static equilibrium, validated by prototypes and simulations.


<details>
  <summary>Details</summary>
Motivation: Traditional optimization-based approaches for inverse design are slow and impose restrictive boundary conditions, limiting their practical use in fields like computer graphics and soft robotics.

Method: The paper presents an inverse discrete elastic rods (inverse-DER) method, reformulating the inverse problem as a static equilibrium in the reference configuration for computational efficiency.

Result: The method achieves computational efficiency comparable to forward simulations and is validated through physical prototypes and forward simulations.

Conclusion: The inverse-DER method demonstrates high accuracy and robustness in inverse design of slender elastic structures, with potential for real-world applications.

Abstract: Inverse design of slender elastic structures underlies a wide range of applications in computer graphics, flexible electronics, biomedical devices, and soft robotics. Traditional optimization-based approaches, however, are often orders of magnitude slower than forward dynamic simulations and typically impose restrictive boundary conditions. In this work, we present an inverse discrete elastic rods (inverse-DER) method that enables efficient and accurate inverse design under general loading and boundary conditions. By reformulating the inverse problem as a static equilibrium in the reference configuration, our method attains computational efficiency comparable to forward simulations while preserving high fidelity. This framework allows rapid determination of undeformed geometries for elastic fabrication structures that naturally deform into desired target shapes upon actuation or loading. We validate the approach through both physical prototypes and forward simulations, demonstrating its accuracy, robustness, and potential for real-world design applications.

</details>


### [273] [Benchmarking Humanoid Imitation Learning with Motion Difficulty](https://arxiv.org/abs/2512.07248)
*Zhaorui Meng,Lu Yin,Xinrui Chen,Anjun Chen,Shihui Guo,Yipeng Qin*

Main category: cs.GR

TL;DR: 该论文提出MDS指标，独立量化运动模仿难度，并通过实验验证其有效性，为模仿学习提供新评估工具。


<details>
  <summary>Details</summary>
Motivation: 当前评估指标（如关节位置误差）仅衡量策略模仿的好坏，而未考虑运动本身的难度，导致策略性能与运动难度混淆。

Method: MDS基于刚体动力学，通过小姿态扰动引起的扭矩变化来定义难度，并利用扭矩空间的体积、方差和时间变异性三个特性来捕捉难度。

Result: 实验验证了MDS对顶尖运动模仿策略性能的解释力，并基于MDS提出了两个新指标（MID和DSJE），为模仿学习提供了新见解。

Conclusion: 该论文提出了运动难度评分（MDS）这一新指标，能够独立于策略性能量化模仿难度，并通过实验验证了其解释力。

Abstract: Physics-based motion imitation is central to humanoid control, yet current evaluation metrics (e.g., joint position error) only measure how well a policy imitates but not how difficult the motion itself is. This conflates policy performance with motion difficulty, obscuring whether failures stem from poor learning or inherently challenging motions. In this work, we address this gap with Motion Difficulty Score (MDS), a novel metric that defines and quantifies imitation difficulty independent of policy performance. Grounded in rigid-body dynamics, MDS interprets difficulty as the torque variation induced by small pose perturbations: larger torque-to-pose variation yields flatter reward landscapes and thus higher learning difficulty. MDS captures this through three properties of the perturbation-induced torque space: volume, variance, and temporal variability. We also use it to construct MD-AMASS, a difficulty-aware repartitioning of the AMASS dataset. Empirically, we rigorously validate MDS by demonstrating its explanatory power on the performance of state-of-the-art motion imitation policies. We further demonstrate the utility of MDS through two new MDS-based metrics: Maximum Imitable Difficulty (MID) and Difficulty-Stratified Joint Error (DSJE), providing fresh insights into imitation learning.

</details>


### [274] [Human Geometry Distribution for 3D Animation Generation](https://arxiv.org/abs/2512.07459)
*Xiangjun Tang,Biao Zhang,Peter Wonka*

Main category: cs.GR

TL;DR: 论文提出两阶段框架，通过紧凑潜在表示和生成动画模型，显著提升人体几何动画的真实性与多样性，实验效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 生成具有精细几何细节和自然服装动态的真实人体几何动画在数据有限的情况下仍具挑战性，需要改进潜在表示和动画生成方法。

Method: 论文提出了一种基于分布式的紧凑潜在表示和生成动画模型的两阶段框架。第一阶段学习潜在空间，第二阶段在该空间内生成动画，通过身份条件设计保持长期一致性。

Result: 实验显示，潜在空间生成的人体几何保真度显著提升（Chamfer距离降低90%），动画模型生成的动画动态更自然（用户评分提高2.2倍），在所有评估指标中表现最佳。

Conclusion: 该论文提出的两阶段框架（潜在空间学习与动画生成）显著提升了人体几何动画的真实性和多样性，实验结果表明其在几何保真度和动态自然性上均优于现有方法。

Abstract: Generating realistic human geometry animations remains a challenging task, as it requires modeling natural clothing dynamics with fine-grained geometric details under limited data. To address these challenges, we propose two novel designs. First, we propose a compact distribution-based latent representation that enables efficient and high-quality geometry generation. We improve upon previous work by establishing a more uniform mapping between SMPL and avatar geometries. Second, we introduce a generative animation model that fully exploits the diversity of limited motion data. We focus on short-term transitions while maintaining long-term consistency through an identity-conditioned design. These two designs formulate our method as a two-stage framework: the first stage learns a latent space, while the second learns to generate animations within this latent space. We conducted experiments on both our latent space and animation model. We demonstrate that our latent space produces high-fidelity human geometry surpassing previous methods ($90\%$ lower Chamfer Dist.). The animation model synthesizes diverse animations with detailed and natural dynamics ($2.2 \times$ higher user study score), achieving the best results across all evaluation metrics.

</details>


<div id='cs.OS'></div>

# cs.OS [[Back]](#toc)

### [275] [Defending Event-Triggered Systems against Out-of-Envelope Environments](https://arxiv.org/abs/2512.06331)
*Marcus Völp,Mohammad Ibrahim Alkoudsi,Azin Bayrami Asl,Kristin Krüger,Julio Rodrigues Mendonca da Neto,Gerhard Fohler*

Main category: cs.OS

TL;DR: 研究发现时间触发系统并非完全免疫于超出安全操作范围的行为，而事件触发系统通过重要性调度可以有效防御中断风暴。


<details>
  <summary>Details</summary>
Motivation: 探讨时间触发系统是否真的对超出安全操作范围的行为免疫，以及如何构建事件触发系统以防御中断风暴。

Method: 研究比较了时间触发和事件触发系统在超出安全操作范围环境下的表现，并引入重要性作为调度任务的依据。

Result: 研究表明，事件触发系统通过重要性调度可以抵御超出安全操作范围的行为，并与混合关键性调度有相似之处。

Conclusion: 时间触发系统并非完全免疫于超出安全操作范围的行为，而通过引入重要性（独立于优先级和关键性）的概念，事件触发系统可以有效地防御中断风暴的冲击。

Abstract: The design of real-time systems is based on assumptions about environmental conditions in which they will operate. We call this their safe operational envelope. Violation of these assumptions, i.e., out-of-envelope environments, can jeopardize timeliness and safety of real-time systems, e.g., by overwhelming them with interrupt storms. A long-lasting debate has been going on over which design paradigm, the time- or event-triggered, is more robust against such behavior. In this work, we investigate the claim that time-triggered systems are immune against out-of-envelope behavior and how event-triggered systems can be constructed to defend against being overwhelmed by interrupt showers. We introduce importance (independently of priority and criticality) as a means to express which tasks should still be scheduled in case environmental design assumptions cease to hold, draw parallels to mixed-criticality scheduling, and demonstrate how event-triggered systems can defend against out-of-envelope behavior.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [276] [Going All-In on LLM Accuracy: Fake Prediction Markets, Real Confidence Signals](https://arxiv.org/abs/2512.05998)
*Michael Todasco*

Main category: cs.AI

TL;DR: 通过虚拟货币投注机制，LLM预测准确率略有提升，且投注金额能有效反映置信度，为LLM评估提供了新的置信信号生成方法。


<details>
  <summary>Details</summary>
Motivation: 当前LLM评估缺乏置信表征，研究探索通过投注游戏框架是否能提升预测准确性并生成校准的置信信号。

Method: 研究生成100个数学和逻辑问题，由六个基线模型（三当前代、三前代）回答。三个预测模型在两种条件下（控制组和激励组）预测基线模型的回答正确性，激励组加入虚拟货币投注。

Result: 激励组预测准确率略高（81.5% vs. 79.1%），学习速度显著更快（12.0% vs. 2.9%提升）。投注金额与置信度高度相关，大额投注（>40,000硬币）准确率约99%。

Conclusion: 研究发现，通过将评估任务设计为投注游戏，可以生成可校准的置信信号，尽管准确率提升不显著，但这一机制为LLM提供了风险感知的预测能力，使其内部信念可视化。

Abstract: Large language models are increasingly used to evaluate other models, yet these judgments typically lack any representation of confidence. This pilot study tests whether framing an evaluation task as a betting game (a fictional prediction market with its own LLM currency) improves forecasting accuracy and surfaces calibrated confidence signals. We generated 100 math and logic questions with verifiable answers. Six Baseline models (three current-generation, three prior-generation) answered all items. Three Predictor models then forecasted, for each question-baseline pair, if the baseline would answer correctly. Each predictor completed matched runs in two conditions: Control (simple correct/incorrect predictions) and Incentive (predictions plus wagers of 1-100,000 LLMCoin under even odds, starting from a 1,000,000 LLMCoin bankroll). Across 5,400 predictions per condition, Incentive runs showed modestly higher accuracy (81.5% vs. 79.1%, p = .089, d = 0.86) and significantly faster learning across rounds (12.0 vs. 2.9 percentage-point improvement from Round 1 to Round 4, p = .011). Most notably, stake size tracked confidence. "Whale" bets of 40,000+ coins were correct ~99% of the time, while small bets (<1,000 coins) showed only ~74% accuracy. The key finding is not that fictional money makes models smarter; accuracy gains were modest and did not reach statistical significance (p = .089) in this pilot. Rather, the betting mechanic created a legible confidence signal absent from binary yes/no outputs. This suggests that simple financial framing may help transform LLMs into risk-aware forecasters, making their internal beliefs visible and usable. The protocol offers a foundation for future work for meta-evaluation systems and what may become LLM-to-LLM prediction markets.

</details>


### [277] [Deep learning for autism detection using clinical notes: A comparison of transfer learning for a transparent and black-box approach](https://arxiv.org/abs/2512.06161)
*Gondy Leroy,Prakash Bisht,Sai Madhuri Kandula,Nell Maltman,Sydney Rice*

Main category: cs.AI

TL;DR: A transparent BioBERT-based ML model for ASD diagnosis outperforms black-box methods, with mixed-data training showing the best performance (97% sensitivity, 98% specificity).


<details>
  <summary>Details</summary>
Motivation: To address the limitations of existing black-box ML models in ASD diagnosis, such as lack of transparency and generalizability, by developing a more interpretable and robust approach.

Method: A transparent and interpretable ML approach leveraging BioBERT to analyze unstructured clinical text, training on sequential and mixed datasets, and comparing with a black-box model.

Result: The transparent model achieved 97% sensitivity and 98% specificity with mixed-data training, outperforming the black-box model (90% sensitivity, 96% specificity).

Conclusion: The transparent ML approach using BioBERT outperforms black-box models in ASD diagnosis, with mixed-data training yielding the best results, suggesting its potential for trustworthy and generalizable AI tools in neurodevelopmental diagnostics.

Abstract: Autism spectrum disorder (ASD) is a complex neurodevelopmental condition whose rising prevalence places increasing demands on a lengthy diagnostic process. Machine learning (ML) has shown promise in automating ASD diagnosis, but most existing models operate as black boxes and are typically trained on a single dataset, limiting their generalizability. In this study, we introduce a transparent and interpretable ML approach that leverages BioBERT, a state-of-the-art language model, to analyze unstructured clinical text. The model is trained to label descriptions of behaviors and map them to diagnostic criteria, which are then used to assign a final label (ASD or not). We evaluate transfer learning, the ability to transfer knowledge to new data, using two distinct real-world datasets. We trained on datasets sequentially and mixed together and compared the performance of the best models and their ability to transfer to new data. We also created a black-box approach and repeated this transfer process for comparison. Our transparent model demonstrated robust performance, with the mixed-data training strategy yielding the best results (97 % sensitivity, 98 % specificity). Sequential training across datasets led to a slight drop in performance, highlighting the importance of training data order. The black-box model performed worse (90 % sensitivity, 96 % specificity) when trained sequentially or with mixed data. Overall, our transparent approach outperformed the black-box approach. Mixing datasets during training resulted in slightly better performance and should be the preferred approach when practically possible. This work paves the way for more trustworthy, generalizable, and clinically actionable AI tools in neurodevelopmental diagnostics.

</details>


### [278] [ARCANE: A Multi-Agent Framework for Interpretable and Configurable Alignment](https://arxiv.org/abs/2512.06196)
*Charlie Masters,Marta Grześkiewicz,Stefano V. Albrecht*

Main category: cs.AI

TL;DR: ARCANE框架通过动态生成自然语言规则（可验证的加权标准）来解决AI对齐问题，采用GSPO方法优化，实现了可解释且无需重新训练的偏好适应。


<details>
  <summary>Details</summary>
Motivation: 随着基于大语言模型的代理被部署到长期任务中，保持其与利益相关者偏好的一致性变得至关重要。需要可解释的奖励模型以理解和审核模型目标。

Method: 采用正则化的Group-Sequence Policy Optimization (GSPO)方法，平衡可解释性、忠实性和计算效率。

Result: 在GDPVal基准的219个标注规则上评估ARCANE，结果表明学习到的规则能生成紧凑、易读的评估，并支持可配置的权衡（如正确性与简洁性）而无需重新训练。

Conclusion: 基于规则的奖励模型（如ARCANE）为复杂、长期AI系统提供了一种可解释、测试时自适应的对齐路径。

Abstract: As agents based on large language models are increasingly deployed to long-horizon tasks, maintaining their alignment with stakeholder preferences becomes critical. Effective alignment in such settings requires reward models that are interpretable so that stakeholders can understand and audit model objectives. Moreover, reward models must be capable of steering agents at interaction time, allowing preference shifts to be incorporated without retraining. We introduce ARCANE, a framework that frames alignment as a multi-agent collaboration problem that dynamically represents stakeholder preferences as natural-language rubrics: weighted sets of verifiable criteria that can be generated on-the-fly from task context. Inspired by utility theory, we formulate rubric learning as a reconstruction problem and apply a regularized Group-Sequence Policy Optimization (GSPO) procedure that balances interpretability, faithfulness, and computational efficiency. Using a corpus of 219 labeled rubrics derived from the GDPVal benchmark, we evaluate ARCANE on challenging tasks requiring multi-step reasoning and tool use. The learned rubrics produce compact, legible evaluations and enable configurable trade-offs (e.g., correctness vs. conciseness) without retraining. Our results show that rubric-based reward models offer a promising path toward interpretable, test-time adaptive alignment for complex, long-horizon AI systems.

</details>


### [279] [On measuring grounding and generalizing grounding problems](https://arxiv.org/abs/2512.06205)
*Daniel Quigley,Eric Maynard*

Main category: cs.AI

TL;DR: 研究将符号接地问题转化为多维度审计框架，应用于四种接地模式和三个案例，发现不同模式在真实性、组合性等方面的差异，为跨学科研究提供了共同语言。


<details>
  <summary>Details</summary>
Motivation: 符号接地问题探讨符号如何与现实世界中的实体对应，而非仅作为计算中的形状。研究旨在通过多维度审计框架，为不同学科提供一个系统研究接地和意义的共同语言和技术工具。

Method: 研究提出了一个基于评估元组（上下文、意义类型、威胁模型、参考分布）的多维度审计框架，包括真实性、保存性、忠实性（相关性和病因性）、鲁棒性和组合性。该框架被应用于四种接地模式（符号、指称、向量、关系）和三个案例研究。

Result: 研究发现，模型论语义学实现了精确的组合性但缺乏病因性保证；大语言模型在语言任务中表现出相关性和局部鲁棒性，但在无接地交互的世界任务中缺乏成功选择；人类语言通过进化和发育获取实现了强真实性下的所有标准。

Conclusion: 通过将符号接地问题从二元判断转化为多维度审计框架，该研究为哲学家、计算机科学家、语言学家和数学家提供了一个共同语言和技术框架，以系统研究接地和意义问题。

Abstract: The symbol grounding problem asks how tokens like cat can be about cats, as opposed to mere shapes manipulated in a calculus. We recast grounding from a binary judgment into an audit across desiderata, each indexed by an evaluation tuple (context, meaning type, threat model, reference distribution): authenticity (mechanisms reside inside the agent and, for strong claims, were acquired through learning or evolution); preservation (atomic meanings remain intact); faithfulness, both correlational (realized meanings match intended ones) and etiological (internal mechanisms causally contribute to success); robustness (graceful degradation under declared perturbations); compositionality (the whole is built systematically from the parts). We apply this framework to four grounding modes (symbolic; referential; vectorial; relational) and three case studies: model-theoretic semantics achieves exact composition but lacks etiological warrant; large language models show correlational fit and local robustness for linguistic tasks, yet lack selection-for-success on world tasks without grounded interaction; human language meets the desiderata under strong authenticity through evolutionary and developmental acquisition. By operationalizing a philosophical inquiry about representation, we equip philosophers of science, computer scientists, linguists, and mathematicians with a common language and technical framework for systematic investigation of grounding and meaning.

</details>


### [280] [AI Application in Anti-Money Laundering for Sustainable and Transparent Financial Systems](https://arxiv.org/abs/2512.06240)
*Chuanhao Nie,Yunbo Liu,Chao Wang*

Main category: cs.AI

TL;DR: AI可优化反洗钱工作流程，RAG-Graph架构显著提升KYC效率与透明度。


<details>
  <summary>Details</summary>
Motivation: 全球金融稳定性受到洗钱和金融欺诈的严重威胁，每年造成数万亿美元的损失，且传统监管方法效率低下。本文旨在探讨AI如何提升AML的检测准确性和效率。

Method: 论文探讨了AI在反洗钱（AML）工作流程中的应用，特别是通过RAG-Graph架构结合生成模型来优化KYC流程。

Result: 实验结果表明，RAG-Graph架构在多样化的评估场景中表现出高忠实度和强答案相关性，显著提升了KYC流程的效率和透明度。

Conclusion: 本文提出了一种基于AI的KYC应用，通过结合图基础的检索增强生成（RAG Graph）与生成模型，显著提升了KYC流程的效率和透明度，为反洗钱检测提供了更可持续、资源优化的合规实践。

Abstract: Money laundering and financial fraud remain major threats to global financial stability, costing trillions annually and challenging regulatory oversight. This paper reviews how artificial intelligence (AI) applications can modernize Anti-Money Laundering (AML) workflows by improving detection accuracy, lowering false-positive rates, and reducing the operational burden of manual investigations, thereby supporting more sustainable development. It further highlights future research directions including federated learning for privacy-preserving collaboration, fairness-aware and interpretable AI, reinforcement learning for adaptive defenses, and human-in-the-loop visualization systems to ensure that next-generation AML architectures remain transparent, accountable, and robust. In the final part, the paper proposes an AI-driven KYC application that integrates graph-based retrieval-augmented generation (RAG Graph) with generative models to enhance efficiency, transparency, and decision support in KYC processes related to money-laundering detection. Experimental results show that the RAG-Graph architecture delivers high faithfulness and strong answer relevancy across diverse evaluation settings, thereby enhancing the efficiency and transparency of KYC CDD/EDD workflows and contributing to more sustainable, resource-optimized compliance practices.

</details>


### [281] [How Sharp and Bias-Robust is a Model? Dual Evaluation Perspectives on Knowledge Graph Completion](https://arxiv.org/abs/2512.06296)
*Sooho Moon,Yunyong Ko*

Main category: cs.AI

TL;DR: PROBE框架通过结合预测锐度和流行度偏差鲁棒性，改进了知识图谱补全的评估方法。


<details>
  <summary>Details</summary>
Motivation: 现有的KGC评估指标忽视了预测锐度和流行度偏差鲁棒性两个关键视角，导致评估结果不全面。

Method: 提出了一个新颖的评估框架PROBE，包括基于预测锐度的排名转换器（RT）和流行度感知的排名聚合器（RA）。

Result: 实验表明，PROBE能够提供对KGC模型的全面理解，而现有指标往往高估或低估模型准确性。

Conclusion: PROBE框架通过结合预测锐度和流行度偏差鲁棒性，为知识图谱补全（KGC）模型提供了更全面和可靠的评估结果。

Abstract: Knowledge graph completion (KGC) aims to predict missing facts from the observed KG. While a number of KGC models have been studied, the evaluation of KGC still remain underexplored. In this paper, we observe that existing metrics overlook two key perspectives for KGC evaluation: (A1) predictive sharpness -- the degree of strictness in evaluating an individual prediction, and (A2) popularity-bias robustness -- the ability to predict low-popularity entities. Toward reflecting both perspectives, we propose a novel evaluation framework (PROBE), which consists of a rank transformer (RT) estimating the score of each prediction based on a required level of predictive sharpness and a rank aggregator (RA) aggregating all the scores in a popularity-aware manner. Experiments on real-world KGs reveal that existing metrics tend to over- or under-estimate the accuracy of KGC models, whereas PROBE yields a comprehensive understanding of KGC models and reliable evaluation results.

</details>


### [282] [DaGRPO: Rectifying Gradient Conflict in Reasoning via Distinctiveness-Aware Group Relative Policy Optimization](https://arxiv.org/abs/2512.06337)
*Xuan Xie,Xuan Wang,Wenjie Wang*

Main category: cs.AI

TL;DR: DaGRPO通过序列级梯度校正和离策略数据增强解决了GRPO的训练不稳定问题，在多个基准上实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: GRPO在激发后训练推理能力方面表现优异，但仍存在训练不稳定和样本效率低的问题，根源在于策略内样本缺乏区分度。

Method: 提出了Distinctiveness-aware Group Relative Policy Optimization (DaGRPO)，包含序列级梯度校正和离策略数据增强两个核心机制。

Result: 在9个数学推理和OOD泛化基准上，DaGRPO显著超越现有方法（如数学基准平均准确率提升4.7%），并加速了长链推理能力的涌现。

Conclusion: DaGRPO显著提升了训练稳定性和样本效率，在数学推理和OOD泛化基准上实现了新的最先进性能，并有效缓解了梯度爆炸问题。

Abstract: The evolution of Large Language Models (LLMs) has catalyzed a paradigm shift from superficial instruction following to rigorous long-horizon reasoning. While Group Relative Policy Optimization (GRPO) has emerged as a pivotal mechanism for eliciting such post-training reasoning capabilities due to its exceptional performance, it remains plagued by significant training instability and poor sample efficiency. We theoretically identify the root cause of these issues as the lack of distinctiveness within on-policy rollouts: for routine queries, highly homogeneous samples induce destructive gradient conflicts; whereas for hard queries, the scarcity of valid positive samples results in ineffective optimization. To bridge this gap, we propose Distinctiveness-aware Group Relative Policy Optimization (DaGRPO). DaGRPO incorporates two core mechanisms: (1) Sequence-level Gradient Rectification, which utilizes fine-grained scoring to dynamically mask sample pairs with low distinctiveness, thereby eradicating gradient conflicts at the source; and (2) Off-policy Data Augmentation, which introduces high-quality anchors to recover training signals for challenging tasks. Extensive experiments across 9 mathematical reasoning and out-of-distribution (OOD) generalization benchmarks demonstrate that DaGRPO significantly surpasses existing SFT, GRPO, and hybrid baselines, achieving new state-of-the-art performance (e.g., a +4.7% average accuracy gain on math benchmarks). Furthermore, in-depth analysis confirms that DaGRPO effectively mitigates gradient explosion and accelerates the emergence of long-chain reasoning capabilities.

</details>


### [283] [Less Is More for Multi-Step Logical Reasoning of LLM Generalisation Under Rule Removal, Paraphrasing, and Compression](https://arxiv.org/abs/2512.06393)
*Qiming Bao,Xiaoxuan Fu*

Main category: cs.AI

TL;DR: LLMs handle semantic-preserving logical changes well but struggle with missing or conflicting evidence, revealing limitations in logical reasoning.


<details>
  <summary>Details</summary>
Motivation: To understand the generalization of LLMs to structural perturbations in logical contexts, which remains poorly understood.

Method: A controlled evaluation framework with four stress tests: rule deletion, contradictory evidence injection, logic-preserving rewrites, and multi-law equivalence stacking.

Result: All models achieved perfect accuracy on base tasks and generalized well to redundant rule deletion and equivalence-based rewrites, but failed sharply under essential rule deletion (25% accuracy) and collapsed completely with contradictions (0% accuracy).

Conclusion: LLMs exhibit stable invariance to semantic-preserving logical transformations but are fundamentally brittle to missing or conflicting evidence, highlighting gaps in their logical generalization abilities.

Abstract: Large language models (LLMs) excel across many natural language tasks, yet their generalisation to structural perturbations in logical contexts remains poorly understood. We introduce a controlled evaluation framework that probes reasoning reliability through four targeted stress tests: (1) rule deletion, removing either redundant or essential rules from a multi-step inference chain; (2) contradictory evidence injection; (3) logic-preserving rewrites generated through several families of equivalence laws (contrapositive, double negation, implication, De Morgan, identity, and commutativity); and (4) multi-law equivalence stacking that introduces 2-5 simultaneous logical transformations.
  Across three representative model families: BERT, Qwen2, and LLaMA-like models. Our experiments reveal a strikingly consistent pattern: all models achieve perfect accuracy on the base tasks and remain fully generalise to redundant rule deletion and all equivalence-based rewrites (single or multi-law), but fail sharply under essential rule deletion (dropping to 25% accuracy) and collapse completely in the presence of explicit contradictions (0% accuracy). These results demonstrate that LLMs possess stable invariance to semantic-preserving logical transformations, yet remain fundamentally brittle to missing or conflicting evidence. Our framework provides a clean diagnostic tool for isolating such reasoning failure modes and highlights persistent gaps in the logical generalisation abilities of current LLMs.

</details>


### [284] [GENIUS: An Agentic AI Framework for Autonomous Design and Execution of Simulation Protocols](https://arxiv.org/abs/2512.06404)
*Mohammad Soleymanibrojeni,Roland Aydin,Diego Guedes-Sobrinho,Alexandre C. Dias,Maurício J. Piotrowski,Wolfgang Wenzel,Celso Ricardo Caldeira Rêgo*

Main category: cs.AI

TL;DR: GENIUS是一个AI驱动的工作流，通过智能自动化降低DFT模拟门槛，显著提升成功率和效率。


<details>
  <summary>Details</summary>
Motivation: 解决材料发现中常规设置和调试对计算机专家的依赖，缩小ICME中的知识差距，使非专家也能便捷使用先进代码。

Method: GENIUS结合了智能Quantum ESPRESSO知识图谱、分层大型语言模型和有限状态错误恢复机，实现了从自由形式提示到验证输入文件的转换。

Result: 在295个多样化基准测试中，约80%的输入文件成功运行，其中76%可自主修复，成功率呈指数下降至7%基线。与仅使用LLM的基线相比，GENIUS将推理成本减半并几乎消除幻觉。

Conclusion: GENIUS框架通过智能自动化协议生成、验证和修复，降低了电子结构DFT模拟的门槛，推动了全球学术界和工业界的大规模筛选和ICME设计循环加速。

Abstract: Predictive atomistic simulations have propelled materials discovery, yet routine setup and debugging still demand computer specialists. This know-how gap limits Integrated Computational Materials Engineering (ICME), where state-of-the-art codes exist but remain cumbersome for non-experts. We address this bottleneck with GENIUS, an AI-agentic workflow that fuses a smart Quantum ESPRESSO knowledge graph with a tiered hierarchy of large language models supervised by a finite-state error-recovery machine. Here we show that GENIUS translates free-form human-generated prompts into validated input files that run to completion on $\approx$80% of 295 diverse benchmarks, where 76% are autonomously repaired, with success decaying exponentially to a 7% baseline. Compared with LLM-only baselines, GENIUS halves inference costs and virtually eliminates hallucinations. The framework democratizes electronic-structure DFT simulations by intelligently automating protocol generation, validation, and repair, opening large-scale screening and accelerating ICME design loops across academia and industry worldwide.

</details>


### [285] [UncertaintyZoo: A Unified Toolkit for Quantifying Predictive Uncertainty in Deep Learning Systems](https://arxiv.org/abs/2512.06406)
*Xianzong Wu,Xiaohong Li,Lili Quan,Qiang Hu*

Main category: cs.AI

TL;DR: UncertaintyZoo是一个整合29种不确定性量化方法的工具包，通过代码漏洞检测任务验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管不确定性量化方法在安全关键场景中至关重要，但缺乏统一工具集成这些方法，限制了其实际应用和未来研究。

Method: 引入UncertaintyZoo工具包，整合29种不确定性量化方法，并在CodeBERT和ChatGLM3模型上进行代码漏洞检测任务的评估。

Result: UncertaintyZoo在代码漏洞检测任务中有效揭示了预测的不确定性。

Conclusion: UncertaintyZoo作为一个统一工具包，成功整合了29种不确定性量化方法，并在代码漏洞检测任务中验证了其有效性，揭示了预测的不确定性。

Abstract: Large language models(LLMs) are increasingly expanding their real-world applications across domains, e.g., question answering, autonomous driving, and automatic software development. Despite this achievement, LLMs, as data-driven systems, often make incorrect predictions, which can lead to potential losses in safety-critical scenarios. To address this issue and measure the confidence of model outputs, multiple uncertainty quantification(UQ) criteria have been proposed. However, even though important, there are limited tools to integrate these methods, hindering the practical usage of UQ methods and future research in this domain. To bridge this gap, in this paper, we introduce UncertaintyZoo, a unified toolkit that integrates 29 uncertainty quantification methods, covering five major categories under a standardized interface. Using UncertaintyZoo, we evaluate the usefulness of existing uncertainty quantification methods under the code vulnerability detection task on CodeBERT and ChatGLM3 models. The results demonstrate that UncertaintyZoo effectively reveals prediction uncertainty. The tool with a demonstration video is available on the project site https://github.com/Paddingbuta/UncertaintyZoo.

</details>


### [286] [Smart Spatial Planning in Egypt: An Algorithm-Driven Approach to Public Service Evaluation in Qena City](https://arxiv.org/abs/2512.06431)
*Mohamed Shamroukh,Mohamed Alkhuzamy Aziz*

Main category: cs.AI

TL;DR: 研究开发了一个基于Voronoi图的智能算法模型，为Qena市定制规划标准，评估公共服务覆盖情况，平均覆盖率为81.3%，救护车站效率最高，公园覆盖最低。


<details>
  <summary>Details</summary>
Motivation: 埃及国家公共服务规划标准往往无法与地方独特特征对齐，本研究旨在填补这一空白。

Method: 采用混合方法（描述性、分析性和实验性），利用Python编程开发基于Voronoi图的智能空间分析算法。

Result: 模型应用显示公共服务覆盖平均为81.3%，救护车站效率最高（99.8%），公园和开放空间覆盖最低（10%）。市中心服务密度高（>45服务/km²），郊区显著减少（<5服务/km²）。Hajer Qena区未服务区域最多，第一区（Qesm 1）服务覆盖最高。

Conclusion: 该研究成功开发了一个适用于埃及城市的数据驱动城市规划模型，特别是针对Qena市，提供了一个可复制的框架。

Abstract: National planning standards for public services in Egypt often fail to align with unique local characteristics. Addressing this gap, this study develops a tailored planning model for Qena City. Using a hybrid methodology (descriptive, analytical, and experimental), the research utilizes Python programming to generate an intelligent spatial analysis algorithm based on Voronoi Diagrams. This approach creates city-specific planning criteria and evaluates the current coverage of public facilities. The primary contribution of this study is the successful derivation of a localized planning standards model and the deployment of an automated algorithm to assess service efficiency. Application of this model reveals a general service coverage average of 81.3%. Ambulance stations demonstrated the highest efficiency (99.8%) due to recent upgrades, while parks and open spaces recorded the lowest coverage (10%) caused by limited land availability. Spatial analysis indicates a high service density in midtown (>45 services/km^2), which diminishes significantly towards the outskirts (<5 services/km^2). Consequently, the Hajer Qena district contains the highest volume of unserved areas, while the First District (Qesm 1) exhibits the highest level of service coverage. This model offers a replicable framework for data-driven urban planning in Egyptian cities.

</details>


### [287] [The Effect of Belief Boxes and Open-mindedness on Persuasion](https://arxiv.org/abs/2512.06573)
*Onur Bilgin,Abdullah As Sami,Sriram Sai Vujjini,John Licato*

Main category: cs.AI

TL;DR: LLM-based agents' behaviors and persuasiveness are influenced by belief statements in 'belief boxes' and open-minded instructions, validated through experiments.


<details>
  <summary>Details</summary>
Motivation: To understand how LLM-based agents' behaviors and dispositions are affected by maintaining propositional beliefs in their prompts and how open-minded instructions influence these behaviors.

Method: A series of experiments exploring how belief statements in 'belief boxes' and open-minded instructions affect agent behaviors, resistance to opposing viewpoints, and persuasiveness in multi-agent scenarios.

Result: Instructing agents to be open-minded affects their amenability to belief change. Belief statements and their strengths influence resistance to opposing viewpoints and persuasiveness, especially in peer pressure scenarios.

Conclusion: The belief box technique is feasible and valid for reasoning and decision-making tasks, showing that belief statements and open-minded instructions significantly influence agent behavior and persuasiveness.

Abstract: As multi-agent systems are increasingly utilized for reasoning and decision-making applications, there is a greater need for LLM-based agents to have something resembling propositional beliefs. One simple method for doing so is to include statements describing beliefs maintained in the prompt space (in what we'll call their belief boxes). But when agents have such statements in belief boxes, how does it actually affect their behaviors and dispositions towards those beliefs? And does it significantly affect agents' ability to be persuasive in multi-agent scenarios? Likewise, if the agents are given instructions to be open-minded, how does that affect their behaviors? We explore these and related questions in a series of experiments. Our findings confirm that instructing agents to be open-minded affects how amenable they are to belief change. We show that incorporating belief statements and their strengths influences an agent's resistance to (and persuasiveness against) opposing viewpoints. Furthermore, it affects the likelihood of belief change, particularly when the agent is outnumbered in a debate by opposing viewpoints, i.e., peer pressure scenarios. The results demonstrate the feasibility and validity of the belief box technique in reasoning and decision-making tasks.

</details>


### [288] [FlatFormer: A Flat Transformer Knowledge Tracing Model Based on Cognitive Bias Injection](https://arxiv.org/abs/2512.06629)
*Xiao-li Xia,Hou-biao Li*

Main category: cs.AI

TL;DR: FlatFormer是一种轻量级Transformer架构，通过信息注入机制解决了KT模型的性能-复杂度问题，实验显示其在性能和效率上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 知识追踪（KT）模型面临‘性能-复杂度陷阱’：捕捉复杂认知动态（如学习会话和记忆衰减）通常需要深层次架构，但计算成本高昂，难以实时部署。

Method: FlatFormer采用了一种扁平化的Transformer架构，结合了两种轻量级注入机制：混合输入编码策略和预计算的幂律偏置。

Result: 在四个大规模数据集（如EdNet、Junyi）上的实验表明，FlatFormer实现了最先进的性能。例如，在EdNet数据集上，相比最强的层次基线（HiTSKT），绝对AUC提高了8.3%，参数使用量少于15%，推理速度提高了约三倍。

Conclusion: FlatFormer通过轻量级的信息注入机制（如混合输入编码和预计算幂律偏置）成功解决了知识追踪模型中的‘性能-复杂度陷阱’，证明了高认知保真度并不需要复杂的架构。

Abstract: Knowledge Tracing (KT) models face a critical ``Performance-Complexity Trap'': capturing complex cognitive dynamics like learning sessions and memory decay typically requires deep hierarchical architectures, which incur prohibitive computational costs for real-time deployment. To resolve this, we propose FlatFormer, a streamlined architecture based on the novel design paradigm of ``Information Injection over Structural Stacking.'' Unlike parameter-heavy hierarchical models, FlatFormer leverages a standard flat Transformer augmented with two lightweight injection mechanisms: (i) a hybrid input encoding strategy combining learnable session identifiers with fixed sinusoidal step embeddings; and (ii) a pre-computed power-law bias integrated directly into attention logits to explicitly model the forgetting curve. Extensive experiments on four large-scale datasets (e.g., EdNet, Junyi) show that FlatFormer achieves state-of-the-art performance. For example, on the EdNet dataset, compared to the strongest hierarchical baseline (HiTSKT), its absolute AUC increased by 8.3%, while using less than 15% of parameters, and inference speed was about three times faster. These results validate that high cognitive fidelity does not necessitate architectural complexity.

</details>


### [289] [LightSearcher: Efficient DeepSearch via Experiential Memory](https://arxiv.org/abs/2512.06653)
*Hengzhi Lan,Yue Yu,Li Qian,Li Peng,Jie Wu,Wei Liu,Jian Luan,Ting Bai*

Main category: cs.AI

TL;DR: LightSearcher是一个高效的RL框架，通过文本记忆和自适应奖励机制，在保持准确性的同时显著提升了DeepSearch的效率。


<details>
  <summary>Details</summary>
Motivation: 解决RL驱动的DeepSearch系统中存在的准确性与效率之间的权衡问题，即频繁工具调用可能提高事实正确性但导致不必要的计算开销和效率下降。

Method: 提出了LightSearcher，一个结合文本经验记忆（通过学习对比推理轨迹生成可解释的成功推理模式摘要）和自适应奖励机制（仅在正确答案场景中惩罚冗余工具调用）的强化学习框架。

Result: 在四个多跳QA基准测试中，LightSearcher保持了与SOTA基线ReSearch相当的准确性，同时将搜索工具调用减少了39.6%，推理时间减少了48.6%，令牌消耗减少了21.2%。

Conclusion: LightSearcher通过引入文本经验记忆和自适应奖励机制，有效平衡了DeepSearch范式中的准确性与效率问题，显著减少了工具调用次数、推理时间和令牌消耗。

Abstract: DeepSearch paradigms have become a core enabler for deep reasoning models, allowing them to invoke external search tools to access up-to-date, domain-specific knowledge beyond parametric boundaries, thereby enhancing the depth and factual reliability of reasoning. Building upon this foundation, recent advances in reinforcement learning (RL) have further empowered models to autonomously and strategically control search tool usage, optimizing when and how to query external knowledge sources. Yet, these RL-driven DeepSearch systems often reveal a see-saw trade-off between accuracy and efficiency-frequent tool invocations can improve factual correctness but lead to unnecessary computational overhead and diminished efficiency. To address this challenge, we propose LightSearcher, an efficient RL framework that incorporates textual experiential memory by learning contrastive reasoning trajectories to generate interpretable summaries of successful reasoning patterns. In addition, it employs an adaptive reward shaping mechanism that penalizes redundant tool calls only in correct-answer scenarios. This design effectively balances the inherent accuracy-efficiency trade-off in DeepSearch paradigms. Experiments on four multi-hop QA benchmarks show that LightSearcher maintains accuracy comparable to SOTA baseline ReSearch, while reducing search tool invocations by 39.6%, inference time by 48.6%, and token consumption by 21.2%, demonstrating its superior efficiency.

</details>


### [290] [Academic journals' AI policies fail to curb the surge in AI-assisted academic writing](https://arxiv.org/abs/2512.06705)
*Yongyuan He,Yi Bu*

Main category: cs.AI

TL;DR: 研究表明，期刊AI政策未能有效促进透明度或限制AI采用，呼吁重新评估伦理框架。


<details>
  <summary>Details</summary>
Motivation: 评估AI使用指南在现实世界中的实际影响，探讨期刊政策是否有效。

Method: 分析了5,114种期刊和超过520万篇论文，并对164k科学出版物进行了全文分析。

Result: 尽管70%的期刊采用了AI政策（主要是要求披露），但研究人员使用AI写作工具的情况在各学科中显著增加，且政策有无无显著差异。非英语国家、物理科学和高OA期刊增长最快。全文分析显示透明度差距显著：自2023年以来发表的75k论文中，仅76篇（0.1%）明确披露了AI使用。

Conclusion: 当前期刊的AI使用政策在促进透明度或限制AI采用方面效果有限，呼吁重新评估伦理框架以促进科学中负责任的AI整合。

Abstract: The rapid integration of generative AI into academic writing has prompted widespread policy responses from journals and publishers. However, the effectiveness of these policies remains unclear. Here, we analyze 5,114 journals and over 5.2 million papers to evaluate the real-world impact of AI usage guidelines. We show that despite 70% of journals adopting AI policies (primarily requiring disclosure), researchers' use of AI writing tools has increased dramatically across disciplines, with no significant difference between journals with or without policies. Non-English-speaking countries, physical sciences, and high-OA journals exhibit the highest growth rates. Crucially, full-text analysis on 164k scientific publications reveals a striking transparency gap: Of the 75k papers published since 2023, only 76 (0.1%) explicitly disclosed AI use. Our findings suggest that current policies have largely failed to promote transparency or restrain AI adoption. We urge a re-evaluation of ethical frameworks to foster responsible AI integration in science.

</details>


### [291] [Stochasticity in Agentic Evaluations: Quantifying Inconsistency with Intraclass Correlation](https://arxiv.org/abs/2512.06710)
*Zairah Mustahsan,Abel Lim,Megna Anand,Saahil Jain,Bryan McCann*

Main category: cs.AI

TL;DR: 论文提出使用ICC指标评估语言模型在代理系统中的可靠性，实验显示ICC值随任务类型变化，并建议在报告中同时提供准确性和ICC值以提高透明度。


<details>
  <summary>Details</summary>
Motivation: 当前评估实践仅报告单次运行的准确性，无法反映结果的方差，导致难以区分能力提升与随机性。论文旨在解决这一问题，提升代理系统评估的可靠性。

Method: 论文通过Intraclass Correlation Coefficient（ICC）分解观察到的方差，将其分为查询间方差（任务难度）和查询内方差（代理不一致性），从而区分真实能力提升与随机采样。

Result: 在GAIA和FRAMES数据集上的实验表明，ICC值随任务结构变化显著，推理和检索任务（FRAMES）的ICC值为0.4955-0.7118，代理任务（GAIA）的ICC值为0.304-0.774。ICC在结构化任务中8-16次试验后收敛，复杂推理任务需至少32次试验。

Conclusion: 论文提出采用类内相关系数（ICC）作为评估语言模型在代理系统中可靠性的标准，并建议在报告中同时提供准确性和ICC值，以提高评估的透明度和可信度。

Abstract: As large language models become components of larger agentic systems, evaluation reliability becomes critical: unreliable sub-agents introduce brittleness into downstream system behavior. Yet current evaluation practice, reporting a single accuracy number from a single run, obscures the variance underlying these results, making it impossible to distinguish genuine capability improvements from lucky sampling. We propose adopting Intraclass Correlation Coefficient (ICC), a metric from measurement science, to characterize this variance. ICC decomposes observed variance into between-query variance (task difficulty) and within-query variance (agent inconsistency), highlighting whether reported results reflect true capability or measurement noise. We evaluated on GAIA (Levels 1-3, measuring agentic capabilities across varying reasoning complexity) and FRAMES (measuring retrieval and factuality across multiple documents). We found that ICC varies dramatically with task structure, with reasoning and retrieval tasks (FRAMES) exhibit ICC=0.4955-0.7118 across models, and agentic tasks (GAIA) exhibiting ICC=0.304-0.774 across models. For sub-agent replacement decisions in agentic systems, accuracy improvements are only trustworthy if ICC also improves. We demonstrate that ICC converges by n=8-16 trials for structured tasks and n>=32 for complex reasoning, enabling practitioners to set evidence-based resampling budgets. We recommend reporting accuracy alongside ICC and within-query variance as standard practice, and propose updated Evaluation Cards capturing these metrics. By making evaluation stability visible, we aim to transform agentic benchmarking from opaque leaderboard competition to trustworthy experimental science. Our code is open-sourced at https://github.com/youdotcom-oss/stochastic-agent-evals.

</details>


### [292] [Cognitive Control Architecture (CCA): A Lifecycle Supervision Framework for Robustly Aligned AI Agents](https://arxiv.org/abs/2512.06716)
*Zhibo Liang,Tianze Hu,Zaiye Chen,Mingjie Tang*

Main category: cs.AI

TL;DR: 论文提出CCA框架，通过意图图和分层裁决器实现全生命周期防御，有效抵御IPI攻击并平衡安全与效率。


<details>
  <summary>Details</summary>
Motivation: 现有防御机制在安全与功能之间存在根本性权衡，导致对间接提示注入（IPI）攻击的脆弱性，亟需一种全面的防御框架。

Method: 提出了认知控制架构（CCA），包括预生成的“意图图”和创新的“分层裁决器”，通过双层次防御系统实现主动和预防性控制。

Result: 在AgentDojo基准测试中，CCA不仅能抵御复杂攻击，还保持了高效性和鲁棒性，解决了多维权衡问题。

Conclusion: CCA框架通过全生命周期认知监督，有效抵御复杂IPI攻击，并在安全、功能和效率之间实现了平衡。

Abstract: Autonomous Large Language Model (LLM) agents exhibit significant vulnerability to Indirect Prompt Injection (IPI) attacks. These attacks hijack agent behavior by polluting external information sources, exploiting fundamental trade-offs between security and functionality in existing defense mechanisms. This leads to malicious and unauthorized tool invocations, diverting agents from their original objectives. The success of complex IPIs reveals a deeper systemic fragility: while current defenses demonstrate some effectiveness, most defense architectures are inherently fragmented. Consequently, they fail to provide full integrity assurance across the entire task execution pipeline, forcing unacceptable multi-dimensional compromises among security, functionality, and efficiency. Our method is predicated on a core insight: no matter how subtle an IPI attack, its pursuit of a malicious objective will ultimately manifest as a detectable deviation in the action trajectory, distinct from the expected legitimate plan. Based on this, we propose the Cognitive Control Architecture (CCA), a holistic framework achieving full-lifecycle cognitive supervision. CCA constructs an efficient, dual-layered defense system through two synergistic pillars: (i) proactive and preemptive control-flow and data-flow integrity enforcement via a pre-generated "Intent Graph"; and (ii) an innovative "Tiered Adjudicator" that, upon deviation detection, initiates deep reasoning based on multi-dimensional scoring, specifically designed to counter complex conditional attacks. Experiments on the AgentDojo benchmark substantiate that CCA not only effectively withstands sophisticated attacks that challenge other advanced defense methods but also achieves uncompromised security with notable efficiency and robustness, thereby reconciling the aforementioned multi-dimensional trade-off.

</details>


### [293] [ProAgent: Harnessing On-Demand Sensory Contexts for Proactive LLM Agent Systems](https://arxiv.org/abs/2512.06721)
*Bufang Yang,Lilin Xu,Liekang Zeng,Yunqi Guo,Siyang Jiang,Wenrui Lu,Kaiwei Liu,Hancheng Xiang,Xiaofan Jiang,Guoliang Xing,Zhenyu Yan*

Main category: cs.AI

TL;DR: ProAgent是首个端到端主动代理系统，通过分层感知和上下文推理提供主动协助，显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理主要依赖用户显式指令启动服务，增加了物理和认知负担，因此需要开发能够主动提供协助的系统。

Method: ProAgent采用主动导向的上下文提取方法和分层感知，结合感官和人物线索，通过上下文感知的主动推理器映射用户需求和工具调用。

Result: ProAgent在真实世界测试平台、公共数据集和用户研究中表现出色，主动预测准确率提升33.4%，工具调用F1分数提升16.8%，用户满意度显著提高。

Conclusion: ProAgent作为首个端到端的主动代理系统，通过结合大规模感官上下文和LLM推理，显著提升了主动预测准确性和用户满意度，标志着向主动助手迈进的重要一步。

Abstract: Large Language Model (LLM) agents are emerging to transform daily life. However, existing LLM agents primarily follow a reactive paradigm, relying on explicit user instructions to initiate services, which increases both physical and cognitive workload. In this paper, we propose ProAgent, the first end-to-end proactive agent system that harnesses massive sensory contexts and LLM reasoning to deliver proactive assistance. ProAgent first employs a proactive-oriented context extraction approach with on-demand tiered perception to continuously sense the environment and derive hierarchical contexts that incorporate both sensory and persona cues. ProAgent then adopts a context-aware proactive reasoner to map these contexts to user needs and tool calls, providing proactive assistance. We implement ProAgent on Augmented Reality (AR) glasses with an edge server and extensively evaluate it on a real-world testbed, a public dataset, and through a user study. Results show that ProAgent achieves up to 33.4% higher proactive prediction accuracy, 16.8% higher tool-calling F1 score, and notable improvements in user satisfaction over state-of-the-art baselines, marking a significant step toward proactive assistants. A video demonstration of ProAgent is available at https://youtu.be/pRXZuzvrcVs.

</details>


### [294] [DoVer: Intervention-Driven Auto Debugging for LLM Multi-Agent Systems](https://arxiv.org/abs/2512.06749)
*Ming Ma,Jue Zhang,Fangkai Yang,Yu Kang,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang*

Main category: cs.AI

TL;DR: DoVer通过干预驱动的调试方法，显著提升了LLM多代理系统的可靠性，并在多个数据集和框架中验证了其效果。


<details>
  <summary>Details</summary>
Motivation: 现有的基于日志的故障定位方法存在两个主要限制：（i）仅基于日志的调试缺乏验证，产生未经测试的假设；（ii）单步或单代理归因通常不适用，因为发现多个不同的干预可以独立修复失败的任务。

Method: 引入了DoVer，一个干预驱动的调试框架，通过目标干预（如编辑消息、改变计划）来增强假设生成与主动验证。

Result: 在Magnetic-One代理框架中，DoVer将18-28%的失败试验转为成功，实现高达16%的里程碑进展，并验证或反驳30-60%的故障假设。在GSMPlus数据集和AG2代理框架中，恢复了49%的失败试验。

Conclusion: DoVer框架通过干预驱动的调试方法显著提高了基于LLM的多代理系统的可靠性，并在多个数据集和代理框架中验证了其有效性。

Abstract: Large language model (LLM)-based multi-agent systems are challenging to debug because failures often arise from long, branching interaction traces. The prevailing practice is to leverage LLMs for log-based failure localization, attributing errors to a specific agent and step. However, this paradigm has two key limitations: (i) log-only debugging lacks validation, producing untested hypotheses, and (ii) single-step or single-agent attribution is often ill-posed, as we find that multiple distinct interventions can independently repair the failed task. To address the first limitation, we introduce DoVer, an intervention-driven debugging framework, which augments hypothesis generation with active verification through targeted interventions (e.g., editing messages, altering plans). For the second limitation, rather than evaluating on attribution accuracy, we focus on measuring whether the system resolves the failure or makes quantifiable progress toward task success, reflecting a more outcome-oriented view of debugging. Within the Magnetic-One agent framework, on the datasets derived from GAIA and AssistantBench, DoVer flips 18-28% of failed trials into successes, achieves up to 16% milestone progress, and validates or refutes 30-60% of failure hypotheses. DoVer also performs effectively on a different dataset (GSMPlus) and agent framework (AG2), where it recovers 49% of failed trials. These results highlight intervention as a practical mechanism for improving reliability in agentic systems and open opportunities for more robust, scalable debugging methods for LLM-based multi-agent systems. Project website and code will be available at https://aka.ms/DoVer.

</details>


### [295] [Decouple to Generalize: Context-First Self-Evolving Learning for Data-Scarce Vision-Language Reasoning](https://arxiv.org/abs/2512.06835)
*Tingyu Li,Zheng Sun,Jingxuan Wei,Siyuan Li,Conghui He,Lijun Wu,Cheng Tan*

Main category: cs.AI

TL;DR: DoGe通过解耦学习和两阶段RL训练，解决了VLMs在专业领域的数据不足和训练不稳定问题，表现优于基线。


<details>
  <summary>Details</summary>
Motivation: 现有VLMs在专业领域（如化学、地球科学）面临高质量多模态数据不足的问题，且现有方法（如合成数据）易导致奖励黑客攻击和训练不稳定。

Method: 提出DoGe（Decouple to Generalize）框架，将学习过程解耦为Thinker和Solver两部分，并采用两阶段RL后训练方法。

Result: 实验表明，DoGe方法在各种基准测试中均优于基线方法。

Conclusion: DoGe框架通过解耦学习和两阶段RL后训练方法，为自进化大型视觉语言模型提供了一条可扩展的路径。

Abstract: Recent vision-language models (VLMs) achieve remarkable reasoning through reinforcement learning (RL), which provides a feasible solution for realizing continuous self-evolving large vision-language models (LVLMs) in the era of experience. However, RL for VLMs requires abundant high-quality multimodal data, especially challenging in specialized domains like chemistry, earth sciences, and multimodal mathematics. Existing strategies such as synthetic data and self-rewarding mechanisms suffer from limited distributions and alignment difficulties, ultimately causing reward hacking: models exploit high-reward patterns, collapsing policy entropy and destabilizing training. We propose DoGe (Decouple to Generalize), a dual-decoupling framework that guides models to first learn from context rather than problem solving by refocusing on the problem context scenarios overlooked by synthetic data methods. By decoupling learning process into dual components (Thinker and Solver), we reasonably quantify the reward signals of this process and propose a two-stage RL post-training approach from freely exploring context to practically solving tasks. Second, to increase the diversity of training data, DoGe constructs an evolving curriculum learning pipeline: an expanded native domain knowledge corpus and an iteratively evolving seed problems pool. Experiments show that our method consistently outperforms the baseline across various benchmarks, providing a scalable pathway for realizing self-evolving LVLMs.

</details>


### [296] [JT-DA: Enhancing Data Analysis with Tool-Integrated Table Reasoning Large Language Models](https://arxiv.org/abs/2512.06859)
*Ce Chi,Xing Wang,Zhendong Wang,Xiaofan Liu,Ce Li,Zhiyan Song,Chen Zhao,Kexin Yang,Boshen Shi,Jingjing Yang,Chao Deng,Junlan Feng*

Main category: cs.AI

TL;DR: JT-DA-8B是一个专为复杂表格推理设计的语言模型，通过多样化的训练数据和四阶段工作流优化，实现了高效性能。


<details>
  <summary>Details</summary>
Motivation: 解决表格推理场景中高质量监督数据缺乏的问题。

Method: 基于开源JT-Coder-8B模型，采用监督微调（SFT）和强化学习（RL）优化模型，并提出了四阶段表格推理工作流。

Result: JT-DA-8B在各种表格推理任务中表现优异。

Conclusion: JT-DA-8B通过数据中心的生成和工作流驱动的优化，在多样化的表格推理任务中表现出色。

Abstract: In this work, we present JT-DA-8B (JiuTian Data Analyst 8B), a specialized large language model designed for complex table reasoning tasks across diverse real-world scenarios. To address the lack of high-quality supervision in tabular reasoning scenarios, we construct a comprehensive and diverse training corpus with 34 well-defined table reasoning tasks, by aggregating 29 public table QA datasets and 3 million tables. An automatic pipeline is proposed to generate realistic multi-step analytical tasks involving reasoning patterns. The model is trained upon open-source JT-Coder-8B model, an 8B-parameter decoder-only foundation model trained from scratch. In the training stage, we leverage LLM-based scoring and workflow-aligned filtering to distill high-quality, table-centric data. Both supervised fine-tuning (SFT) and Reinforcement learning (RL) are adopted to optimize our model. Afterwards, a four-stage table reasoning workflow is proposed, including table preprocessing, table sensing, tool-integrated reasoning, and prompt engineering, to improve model interpretability and execution accuracy. Experimental results show that JT-DA-8B achieves strong performance in various table reasoning tasks, demonstrating the effectiveness of data-centric generation and workflow-driven optimization.

</details>


### [297] [Do Persona-Infused LLMs Affect Performance in a Strategic Reasoning Game?](https://arxiv.org/abs/2512.06867)
*John Licato,Stephen Steinle,Brayden Hollis*

Main category: cs.AI

TL;DR: 角色提示在战略游戏中影响决策，但需通过结构化翻译方法转化为启发式策略才能提升表现。


<details>
  <summary>Details</summary>
Motivation: 探讨角色提示是否能在对抗性战略环境中产生可测量的行为差异，并影响决策。

Method: 引入了一个受探索性因子分析启发的结构化翻译过程，将LLM生成的清单响应映射为启发式策略。

Result: 研究发现，某些与战略思维相关的角色在游戏表现上有所提升，但仅在使用中介将角色转化为启发式值时有效。

Conclusion: 研究提出了一种将LLM生成的角色提示转化为启发式策略的结构化翻译方法，该方法增强了启发式的可靠性和表面效度，为研究角色类型对决策的影响提供了新途径。

Abstract: Although persona prompting in large language models appears to trigger different styles of generated text, it is unclear whether these translate into measurable behavioral differences, much less whether they affect decision-making in an adversarial strategic environment that we provide as open-source. We investigate the impact of persona prompting on strategic performance in PERIL, a world-domination board game. Specifically, we compare the effectiveness of persona-derived heuristic strategies to those chosen manually. Our findings reveal that certain personas associated with strategic thinking improve game performance, but only when a mediator is used to translate personas into heuristic values. We introduce this mediator as a structured translation process, inspired by exploratory factor analysis, that maps LLM-generated inventory responses into heuristics. Results indicate our method enhances heuristic reliability and face validity compared to directly inferred heuristics, allowing us to better study the effect of persona types on decision making. These insights advance our understanding of how persona prompting influences LLM-based decision-making and propose a heuristic generation method that applies psychometric principles to LLMs.

</details>


### [298] [On Memory: A comparison of memory mechanisms in world models](https://arxiv.org/abs/2512.06983)
*Eli J. Laird,Corey Clark*

Main category: cs.AI

TL;DR: Transformer-based world models struggle with long-horizon planning due to memory span limits. This paper analyzes memory augmentation mechanisms, showing they enhance memory span and enable loop closures in imagined trajectories.


<details>
  <summary>Details</summary>
Motivation: The limitation of the effective memory span in transformer-based world models leads to perceptual drift in long rollouts, hindering loop closures within imagined trajectories.

Method: The study analyzes various memory augmentation mechanisms in transformer-based world models, introducing a taxonomy to distinguish between memory encoding and injection mechanisms. A state recall evaluation task is used to measure memory recall and trade-offs.

Result: Memory mechanisms improve the effective memory span in vision transformers, facilitating loop closures in world model imaginations.

Conclusion: Memory mechanisms enhance the effective memory span in vision transformers, enabling loop closures within world models' imagined trajectories.

Abstract: World models enable agents to plan within imagined environments by predicting future states conditioned on past observations and actions. However, their ability to plan over long horizons is limited by the effective memory span of the backbone architecture. This limitation leads to perceptual drift in long rollouts, hindering the model's capacity to perform loop closures within imagined trajectories. In this work, we investigate the effective memory span of transformer-based world models through an analysis of several memory augmentation mechanisms. We introduce a taxonomy that distinguishes between memory encoding and memory injection mechanisms, motivating their roles in extending the world model's memory through the lens of residual stream dynamics. Using a state recall evaluation task, we measure the memory recall of each mechanism and analyze its respective trade-offs. Our findings show that memory mechanisms improve the effective memory span in vision transformers and provide a path to completing loop closures within a world model's imagination.

</details>


### [299] [Utilizing Multi-Agent Reinforcement Learning with Encoder-Decoder Architecture Agents to Identify Optimal Resection Location in Glioblastoma Multiforme Patients](https://arxiv.org/abs/2512.06990)
*Krishna Arun,Moinak Bhattachrya,Paras Goel*

Main category: cs.AI

TL;DR: 开发了一个端到端AI系统，通过诊断和治疗规划两阶段辅助GBM治疗，显著提升效率并可能挽救更多生命。


<details>
  <summary>Details</summary>
Motivation: 当前医疗领域缺乏针对GBM的AI支持，这种异质性脑肿瘤的五年生存率仅为5.1%，亟需端到端的解决方案辅助医生。

Method: 诊断阶段采用4个分类模型（CNN和SVM）的序列决策框架，逐步细化分类；治疗规划阶段使用RL系统，包含3个生成模型（扩散模型和时空视觉Transformer）和反馈循环优化。

Result: 1. 序列决策框架降低计算成本22.28倍；2. Transformer减少肿瘤进展推断时间113小时；3. 真实场景增强提升DICE分数2.9%。

Conclusion: 该AI系统通过诊断和治疗规划的两阶段设计，显著提高了GBM的治疗效率，预计将生存率提高0.9%，可能挽救约2250人的生命。

Abstract: Currently, there is a noticeable lack of AI in the medical field to support doctors in treating heterogenous brain tumors such as Glioblastoma Multiforme (GBM), the deadliest human cancer in the world with a five-year survival rate of just 5.1%. This project develops an AI system offering the only end-to-end solution by aiding doctors with both diagnosis and treatment planning. In the diagnosis phase, a sequential decision-making framework consisting of 4 classification models (Convolutional Neural Networks and Support Vector Machine) are used. Each model progressively classifies the patient's brain into increasingly specific categories, with the final step being named diagnosis. For treatment planning, an RL system consisting of 3 generative models is used. First, the resection model (diffusion model) analyzes the diagnosed GBM MRI and predicts a possible resection outcome. Second, the radiotherapy model (Spatio-Temporal Vision Transformer) generates an MRI of the brain's progression after a user-defined number of weeks. Third, the chemotherapy model (Diffusion Model) produces the post-treatment MRI. A survival rate calculator (Convolutional Neural Network) then checks if the generated post treatment MRI has a survival rate within 15% of the user defined target. If not, a feedback loop using proximal policy optimization iterates over this system until an optimal resection location is identified. When compared to existing solutions, this project found 3 key findings: (1) Using a sequential decision-making framework consisting of 4 small diagnostic models reduced computing costs by 22.28x, (2) Transformers regression capabilities decreased tumor progression inference time by 113 hours, and (3) Applying Augmentations resembling Real-life situations improved overall DICE scores by 2.9%. These results project to increase survival rates by 0.9%, potentially saving approximately 2,250 lives.

</details>


### [300] [ClinNoteAgents: An LLM Multi-Agent System for Predicting and Interpreting Heart Failure 30-Day Readmission from Clinical Notes](https://arxiv.org/abs/2512.07081)
*Rongjia Zhou,Chengzhuo Li,Carl Yang,Jiaying Lu*

Main category: cs.AI

TL;DR: ClinNoteAgents是一个基于LLM的多代理框架，通过将临床笔记转化为结构化数据和临床抽象，有效预测心衰再入院风险，减少对结构化数据和人工干预的依赖。


<details>
  <summary>Details</summary>
Motivation: 心衰是导致美国老年人再入院的主要原因之一，临床笔记虽包含丰富信息但在再入院风险分析中未被充分利用，传统方法依赖专家规则且难以处理笔记中的非标准内容。

Method: 提出了ClinNoteAgents，一个基于LLM的多代理框架，将自由文本临床笔记转化为结构化表示和临床风格抽象，用于心衰30天再入院预测。

Result: 在3,544份笔记（来自2,065名患者，再入院率35.16%）上评估，ClinNoteAgents在提取风险因素、识别关键贡献因素和预测再入院风险方面表现优异。

Conclusion: ClinNoteAgents提供了一种可扩展且可解释的方法，用于在数据有限的医疗系统中基于临床笔记进行心衰再入院风险建模，减少了对结构化字段的依赖并最小化了手动注释和模型训练。

Abstract: Heart failure (HF) is one of the leading causes of rehospitalization among older adults in the United States. Although clinical notes contain rich, detailed patient information and make up a large portion of electronic health records (EHRs), they remain underutilized for HF readmission risk analysis. Traditional computational models for HF readmission often rely on expert-crafted rules, medical thesauri, and ontologies to interpret clinical notes, which are typically written under time pressure and may contain misspellings, abbreviations, and domain-specific jargon. We present ClinNoteAgents, an LLM-based multi-agent framework that transforms free-text clinical notes into (1) structured representations of clinical and social risk factors for association analysis and (2) clinician-style abstractions for HF 30-day readmission prediction. We evaluate ClinNoteAgents on 3,544 notes from 2,065 patients (readmission rate=35.16%), demonstrating strong performance in extracting risk factors from free-text, identifying key contributing factors, and predicting readmission risk. By reducing reliance on structured fields and minimizing manual annotation and model training, ClinNoteAgents provides a scalable and interpretable approach to note-based HF readmission risk modeling in data-limited healthcare systems.

</details>


### [301] [VIGIL: A Reflective Runtime for Self-Healing Agents](https://arxiv.org/abs/2512.07094)
*Christopher Cruz*

Main category: cs.AI

TL;DR: VIGIL是一个自主维护的代理运行时，通过日志分析和诊断实现自我修复，提升系统可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有代理框架缺乏运行时自省能力，无法诊断自身失败模式且需人工干预改进，导致系统脆弱。

Method: VIGIL通过行为日志分析、情感表征评估、维护持久性EmoBank，并生成RBT诊断，进而提出防护性提示更新和只读代码提案。

Result: 在案例研究中，VIGIL成功识别延迟问题，提出修复方案，并在诊断工具失败时生成备用诊断和修复计划。

Conclusion: VIGIL展示了在部署的代理运行时中实现元级自我修复的能力，通过自主维护而非任务执行来提升系统可靠性。

Abstract: Agentic LLM frameworks promise autonomous behavior via task decomposition, tool use, and iterative planning, but most deployed systems remain brittle. They lack runtime introspection, cannot diagnose their own failure modes, and do not improve over time without human intervention. In practice, many agent stacks degrade into decorated chains of LLM calls with no structural mechanisms for reliability. We present VIGIL (Verifiable Inspection and Guarded Iterative Learning), a reflective runtime that supervises a sibling agent and performs autonomous maintenance rather than task execution. VIGIL ingests behavioral logs, appraises each event into a structured emotional representation, maintains a persistent EmoBank with decay and contextual policies, and derives an RBT diagnosis that sorts recent behavior into strengths, opportunities, and failures. From this analysis, VIGIL generates both guarded prompt updates that preserve core identity semantics and read only code proposals produced by a strategy engine that operates on log evidence and code hotspots. VIGIL functions as a state gated pipeline. Illegal transitions produce explicit errors rather than allowing the LLM to improvise. In a reminder latency case study, VIGIL identified elevated lag, proposed prompt and code repairs, and when its own diagnostic tool failed due to a schema conflict, it surfaced the internal error, produced a fallback diagnosis, and emitted a repair plan. This demonstrates meta level self repair in a deployed agent runtime.

</details>


### [302] [How Do LLMs Fail In Agentic Scenarios? A Qualitative Analysis of Success and Failure Scenarios of Various LLMs in Agentic Simulations](https://arxiv.org/abs/2512.07497)
*JV Roig*

Main category: cs.AI

TL;DR: 研究發現LLMs作為自主代理時的四種常見失敗模式，並指出提升可靠性需設計特定的訓練和驗證方法。


<details>
  <summary>Details</summary>
Motivation: 研究大型語言模型（LLMs）在作為具有工具使用能力的自主代理時失敗的原因，並探索提升其可靠性的策略。

Method: 使用Kamiwaza Agentic Merit Index (KAMI) v0.1基準，分析了900個執行軌跡，涵蓋文件系統、文本提取、CSV分析和SQL場景，並進行了細粒度的行為分析。

Result: 發現模型規模並不能預測代理的穩健性，DeepSeek V3.1的可靠性主要來自後訓練強化學習，而非架構或規模。同時識別出四種常見的失敗模式。

Conclusion: 可靠的企業部署不僅需要更強大的模型，還需要刻意設計的訓練和選擇，以加強驗證、約束發現和對真實數據的依從性。

Abstract: We investigate how large language models (LLMs) fail when operating as autonomous agents with tool-use capabilities. Using the Kamiwaza Agentic Merit Index (KAMI) v0.1 benchmark, we analyze 900 execution traces from three representative models - Granite 4 Small, Llama 4 Maverick, and DeepSeek V3.1 - across filesystem, text extraction, CSV analysis, and SQL scenarios. Rather than focusing on aggregate scores, we perform fine-grained, per-trial behavioral analysis to surface the strategies that enable successful multi-step tool execution and the recurrent failure modes that undermine reliability. Our findings show that model scale alone does not predict agentic robustness: Llama 4 Maverick (400B) performs only marginally better than Granite 4 Small (32B) in some uncertainty-driven tasks, while DeepSeek V3.1's superior reliability derives primarily from post-training reinforcement learning rather than architecture or size. Across models, we identify four recurring failure archetypes: premature action without grounding, over-helpfulness that substitutes missing entities, vulnerability to distractor-induced context pollution, and fragile execution under load. These patterns highlight the need for agentic evaluation methods that emphasize interactive grounding, recovery behavior, and environment-aware adaptation, suggesting that reliable enterprise deployment requires not just stronger models but deliberate training and design choices that reinforce verification, constraint discovery, and adherence to source-of-truth data.

</details>


### [303] [A Neural Affinity Framework for Abstract Reasoning: Diagnosing the Compositional Gap in Transformer Architectures via Procedural Task Taxonomy](https://arxiv.org/abs/2512.07109)
*Miguel Ingram,Arthur Joseph Merritt*

Main category: cs.AI

TL;DR: 提出首个9类任务分类法，验证其诊断能力，揭示神经架构适用性限制，并强调混合架构的必要性。


<details>
  <summary>Details</summary>
Motivation: 响应Hodel等人（2024）对任务相关性正式定义的需求，提出首个经过验证的任务分类法。

Method: 通过基于规则的代码分析验证了9类任务分类法，训练CNN验证视觉一致性，并在原始ARC-AGI-2测试集上应用分类法进行诊断性分析。

Result: 分类法在诊断神经架构适用性方面表现出强大预测能力，揭示了神经亲和力天花板效应，并确认了混合架构的必要性。

Conclusion: 研究发现，任务相关性分类法能够精确诊断神经架构的适用性，表明未来进展需要采用亲和力对齐的混合架构。

Abstract: Responding to Hodel et al.'s (2024) call for a formal definition of task relatedness in re-arc, we present the first 9-category taxonomy of all 400 tasks, validated at 97.5% accuracy via rule-based code analysis. We prove the taxonomy's visual coherence by training a CNN on raw grid pixels (95.24% accuracy on S3, 36.25% overall, 3.3x chance), then apply the taxonomy diagnostically to the original ARC-AGI-2 test set. Our curriculum analysis reveals 35.3% of tasks exhibit low neural affinity for Transformers--a distributional bias mirroring ARC-AGI-2. To probe this misalignment, we fine-tuned a 1.7M-parameter Transformer across 302 tasks, revealing a profound Compositional Gap: 210 of 302 tasks (69.5%) achieve >80% cell accuracy (local patterns) but <10% grid accuracy (global synthesis). This provides direct evidence for a Neural Affinity Ceiling Effect, where performance is bounded by architectural suitability, not curriculum. Applying our framework to Li et al.'s independent ViTARC study (400 specialists, 1M examples each) confirms its predictive power: Very Low affinity tasks achieve 51.9% versus 77.7% for High affinity (p<0.001), with a task at 0% despite massive data. The taxonomy enables precise diagnosis: low-affinity tasks (A2) hit hard ceilings, while high-affinity tasks (C1) reach 99.8%. These findings indicate that progress requires hybrid architectures with affinity-aligned modules. We release our validated taxonomy,

</details>


### [304] [ContextualSHAP : Enhancing SHAP Explanations Through Contextual Language Generation](https://arxiv.org/abs/2512.07178)
*Latifa Dwiyanti,Sergio Ryan Wibisono,Hidetaka Nambo*

Main category: cs.AI

TL;DR: 提出一个结合SHAP与LLM的Python包，通过情境化文本增强解释的可理解性，初步验证其效果优于纯视觉输出。


<details>
  <summary>Details</summary>
Motivation: 解决SHAP在提供对非技术背景用户有意义的上下文解释方面的不足。

Method: 提出一个Python包，将SHAP与大型语言模型（如OpenAI的GPT）集成，生成情境化文本解释，并通过医疗相关案例研究和用户评估验证其效果。

Result: 用户评估表明，生成的解释比纯视觉输出更易理解和情境适宜。

Conclusion: 结合可视化与情境化文本的SHAP解释可能支持更用户友好和可信的模型解释。

Abstract: Explainable Artificial Intelligence (XAI) has become an increasingly important area of research, particularly as machine learning models are deployed in high-stakes domains. Among various XAI approaches, SHAP (SHapley Additive exPlanations) has gained prominence due to its ability to provide both global and local explanations across different machine learning models. While SHAP effectively visualizes feature importance, it often lacks contextual explanations that are meaningful for end-users, especially those without technical backgrounds. To address this gap, we propose a Python package that extends SHAP by integrating it with a large language model (LLM), specifically OpenAI's GPT, to generate contextualized textual explanations. This integration is guided by user-defined parameters (such as feature aliases, descriptions, and additional background) to tailor the explanation to both the model context and the user perspective. We hypothesize that this enhancement can improve the perceived understandability of SHAP explanations. To evaluate the effectiveness of the proposed package, we applied it in a healthcare-related case study and conducted user evaluations involving real end-users. The results, based on Likert-scale surveys and follow-up interviews, indicate that the generated explanations were perceived as more understandable and contextually appropriate compared to visual-only outputs. While the findings are preliminary, they suggest that combining visualization with contextualized text may support more user-friendly and trustworthy model explanations.

</details>


### [305] [PICKT: Practical Interlinked Concept Knowledge Tracing for Personalized Learning using Knowledge Map Concept Relations](https://arxiv.org/abs/2512.07179)
*Wonbeen Lee,Channyoung Lee,Junho Sohn,Hansam Cho*

Main category: cs.AI

TL;DR: PICKT模型通过知识图谱处理多种数据格式，解决了KT模型的冷启动问题，实验验证了其性能和实用性，为下一代ITS奠定基础。


<details>
  <summary>Details</summary>
Motivation: 现有知识追踪（KT）模型存在输入数据格式受限、冷启动问题（如新学生或新问题加入）以及在真实服务环境中稳定性不足等局限性。

Method: 提出了一种实用的互联概念知识追踪（PICKT）模型，利用知识图谱结构化概念间的关系，并结合问题和概念文本信息，以处理多种输入数据格式。

Result: 实验证明，PICKT模型在真实操作环境中表现出色，显著提升了冷启动挑战（新学生和新问题）的性能，并验证了其稳定性和实用性。

Conclusion: 本研究提出了PICKT模型，有效解决了知识追踪中的冷启动问题和数据格式限制，为下一代智能辅导系统（ITS）的实际应用提供了重要的理论和技​术基础。

Abstract: With the recent surge in personalized learning, Intelligent Tutoring Systems (ITS) that can accurately track students' individual knowledge states and provide tailored learning paths based on this information are in demand as an essential task. This paper focuses on the core technology of Knowledge Tracing (KT) models that analyze students' sequences of interactions to predict their knowledge acquisition levels. However, existing KT models suffer from limitations such as restricted input data formats, cold start problems arising with new student enrollment or new question addition, and insufficient stability in real-world service environments. To overcome these limitations, a Practical Interlinked Concept Knowledge Tracing (PICKT) model that can effectively process multiple types of input data is proposed. Specifically, a knowledge map structures the relationships among concepts considering the question and concept text information, thereby enabling effective knowledge tracing even in cold start situations. Experiments reflecting real operational environments demonstrated the model's excellent performance and practicality. The main contributions of this research are as follows. First, a model architecture that effectively utilizes diverse data formats is presented. Second, significant performance improvements are achieved over existing models for two core cold start challenges: new student enrollment and new question addition. Third, the model's stability and practicality are validated through delicate experimental design, enhancing its applicability in real-world product environments. This provides a crucial theoretical and technical foundation for the practical implementation of next-generation ITS.

</details>


### [306] [Sample from What You See: Visuomotor Policy Learning via Diffusion Bridge with Observation-Embedded Stochastic Differential Equation](https://arxiv.org/abs/2512.07212)
*Zhaoyang Liu,Mokai Pan,Zhongyi Wang,Kaizhen Zhu,Haotao Lu,Jingya Wang,Ye Shi*

Main category: cs.AI

TL;DR: BridgePolicy是一种生成视觉运动策略，通过扩散桥公式将观察信息嵌入随机微分方程，从信息丰富的先验而非随机噪声开始采样，显著提升控制精度和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有方法将观察作为去噪网络的高级条件输入，而非融入扩散过程的随机动态中，导致感知与控制耦合弱，性能不佳。

Method: 设计了多模态融合模块和语义对齐器，统一视觉和状态输入，并对齐观察和动作表示，使扩散桥适用于异构机器人数据。

Result: 在三个基准测试的52个仿真任务和五个实际任务中，BridgePolicy一致优于最先进的生成策略。

Conclusion: BridgePolicy通过将观察信息嵌入扩散桥的随机微分方程中，显著提高了控制精度和可靠性，并在多个仿真和实际任务中优于现有生成策略。

Abstract: Imitation learning with diffusion models has advanced robotic control by capturing multi-modal action distributions. However, existing approaches typically treat observations as high-level conditioning inputs to the denoising network, rather than integrating them into the stochastic dynamics of the diffusion process itself. As a result, sampling must begin from random Gaussian noise, weakening the coupling between perception and control and often yielding suboptimal performance. We introduce BridgePolicy, a generative visuomotor policy that explicitly embeds observations within the stochastic differential equation via a diffusion-bridge formulation. By constructing an observation-informed trajectory, BridgePolicy enables sampling to start from a rich, informative prior rather than random noise, substantially improving precision and reliability in control. A key challenge is that classical diffusion bridges connect distributions with matched dimensionality, whereas robotic observations are heterogeneous and multi-modal and do not naturally align with the action space. To address this, we design a multi-modal fusion module and a semantic aligner that unify visual and state inputs and align observation and action representations, making the bridge applicable to heterogeneous robot data. Extensive experiments across 52 simulation tasks on three benchmarks and five real-world tasks demonstrate that BridgePolicy consistently outperforms state-of-the-art generative policies.

</details>


### [307] [Cross-platform Product Matching Based on Entity Alignment of Knowledge Graph with RAEA model](https://arxiv.org/abs/2512.07232)
*Wenlong Liu,Jiahua Pan,Xingyu Zhang,Xinxin Gong,Yang Ye,Xujin Zhao,Xin Wang,Kent Wu,Hua Xiang,Houmin Yan,Qingpeng Zhang*

Main category: cs.AI

TL;DR: 论文提出RAEA框架，通过两阶段流程（粗略+精细过滤）和属性/关系交互优化，显著提升实体对齐效果。


<details>
  <summary>Details</summary>
Motivation: 现有实体对齐方法未能充分利用属性三元组和关系三元组，尤其是它们之间的交互作用。

Method: 采用两阶段流程（粗略过滤和精细过滤），其中精细过滤阶段使用RAEA框架，该框架通过属性感知实体编码器和关系感知图注意力网络，聚合属性和关系的对齐信号。

Result: RAEA模型在DBP15K数据集上平均Hits@1提升6.59%，在DWY100K数据集上表现优异。

Conclusion: RAEA模型在跨语言数据集DBP15K上显著优于12个基线模型（平均Hits@1提升6.59%），并在单语言数据集DWY100K上表现出竞争力。

Abstract: Product matching aims to identify identical or similar products sold on different platforms. By building knowledge graphs (KGs), the product matching problem can be converted to the Entity Alignment (EA) task, which aims to discover the equivalent entities from diverse KGs. The existing EA methods inadequately utilize both attribute triples and relation triples simultaneously, especially the interactions between them. This paper introduces a two-stage pipeline consisting of rough filter and fine filter to match products from eBay and Amazon. For fine filtering, a new framework for Entity Alignment, Relation-aware and Attribute-aware Graph Attention Networks for Entity Alignment (RAEA), is employed. RAEA focuses on the interactions between attribute triples and relation triples, where the entity representation aggregates the alignment signals from attributes and relations with Attribute-aware Entity Encoder and Relation-aware Graph Attention Networks. The experimental results indicate that the RAEA model achieves significant improvements over 12 baselines on EA task in the cross-lingual dataset DBP15K (6.59% on average Hits@1) and delivers competitive results in the monolingual dataset DWY100K. The source code for experiments on DBP15K and DWY100K is available at github (https://github.com/Mockingjay-liu/RAEA-model-for-Entity-Alignment).

</details>


### [308] [M-STAR: Multi-Scale Spatiotemporal Autoregression for Human Mobility Modeling](https://arxiv.org/abs/2512.07314)
*Yuxiao Luo,Songming Zhang,Sijie Ruan,Siran Chen,Kang Liu,Yang Xu,Yu Zheng,Ling Yin*

Main category: cs.AI

TL;DR: M-STAR通过多尺度时空自回归框架，高效生成长周期轨迹，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成长周期轨迹（如周轨迹）时效率低下，且缺乏显式的时空多尺度建模，M-STAR旨在解决这些问题。

Method: 提出了Multi-Scale Spatio-Temporal AutoRegression (M-STAR)框架，结合多尺度时空标记器和基于Transformer的解码器进行下一尺度自回归预测。

Result: 在两个真实数据集上的实验表明，M-STAR在保真度和生成速度上均优于现有方法。

Conclusion: M-STAR框架通过从粗到细的时空预测过程生成长期轨迹，结合多尺度时空标记器和基于Transformer的解码器，显著提高了生成速度和保真度。

Abstract: Modeling human mobility is vital for extensive applications such as transportation planning and epidemic modeling. With the rise of the Artificial Intelligence Generated Content (AIGC) paradigm, recent works explore synthetic trajectory generation using autoregressive and diffusion models. While these methods show promise for generating single-day trajectories, they remain limited by inefficiencies in long-term generation (e.g., weekly trajectories) and a lack of explicit spatiotemporal multi-scale modeling. This study proposes Multi-Scale Spatio-Temporal AutoRegression (M-STAR), a new framework that generates long-term trajectories through a coarse-to-fine spatiotemporal prediction process. M-STAR combines a Multi-scale Spatiotemporal Tokenizer that encodes hierarchical mobility patterns with a Transformer-based decoder for next-scale autoregressive prediction. Experiments on two real-world datasets show that M-STAR outperforms existing methods in fidelity and significantly improves generation speed. The data and codes are available at https://github.com/YuxiaoLuo0013/M-STAR.

</details>


### [309] [A Geometric Unification of Concept Learning with Concept Cones](https://arxiv.org/abs/2512.07355)
*Alexandre Rocchi--Henry,Thomas Fel,Gianni Franchi*

Main category: cs.AI

TL;DR: 本文通过几何框架统一了CBM和SAE，提出量化指标评估SAE与人类概念的对齐，并发现稀疏性和扩展因子的最佳组合。


<details>
  <summary>Details</summary>
Motivation: 探讨两种解释性传统（CBM和SAE）之间的几何结构相似性，并寻找它们之间的联系。

Method: 提出了一种操作桥梁，利用CBM提供的人为定义参考几何，评估SAE学习的锥体如何近似或包含CBM的锥体。

Result: 发现稀疏性和扩展因子的‘最佳点’，能最大化几何和语义上与CBM概念的对齐。

Conclusion: 本文通过共享的几何框架统一了监督和无监督的概念发现方法，提供了衡量SAE进展和评估发现概念与人类概念对齐程度的量化指标。

Abstract: Two traditions of interpretability have evolved side by side but seldom spoken to each other: Concept Bottleneck Models (CBMs), which prescribe what a concept should be, and Sparse Autoencoders (SAEs), which discover what concepts emerge. While CBMs use supervision to align activations with human-labeled concepts, SAEs rely on sparse coding to uncover emergent ones. We show that both paradigms instantiate the same geometric structure: each learns a set of linear directions in activation space whose nonnegative combinations form a concept cone. Supervised and unsupervised methods thus differ not in kind but in how they select this cone. Building on this view, we propose an operational bridge between the two paradigms. CBMs provide human-defined reference geometries, while SAEs can be evaluated by how well their learned cones approximate or contain those of CBMs. This containment framework yields quantitative metrics linking inductive biases -- such as SAE type, sparsity, or expansion ratio -- to emergence of plausible\footnote{We adopt the terminology of \citet{jacovi2020towards}, who distinguish between faithful explanations (accurately reflecting model computations) and plausible explanations (aligning with human intuition and domain knowledge). CBM concepts are plausible by construction -- selected or annotated by humans -- though not necessarily faithful to the true latent factors that organise the data manifold.} concepts. Using these metrics, we uncover a ``sweet spot'' in both sparsity and expansion factor that maximizes both geometric and semantic alignment with CBM concepts. Overall, our work unifies supervised and unsupervised concept discovery through a shared geometric framework, providing principled metrics to measure SAE progress and assess how well discovered concept align with plausible human concepts.

</details>


### [310] [LocalSearchBench: Benchmarking Agentic Search in Real-World Local Life Services](https://arxiv.org/abs/2512.07436)
*Hang He,Chuhuai Yue,Chengqi Dong,Mingxue Tian,Zhenfeng Liu,Jiajun Chai,Xiaohan Wang,Yufei Zhang,Qun Liao,Guojun Yin,Wei Lin,Chengcheng Wan,Haiying Sun,Ting Su*

Main category: cs.AI

TL;DR: 本研究构建了本地生活服务领域的首个综合性基准测试LocalSearchBench，实验显示现有模型在该领域表现不佳，凸显了领域特定训练的重要性。


<details>
  <summary>Details</summary>
Motivation: 现有的研究大多关注通用信息检索，而忽略了垂直领域的独特挑战，特别是在本地生活服务中，查询往往具有模糊性且需要多跳推理。

Method: 通过构建LocalSearchBench和LocalPlayground，本研究提供了多样化的业务场景和统一的代理交互环境。

Result: 实验表明，即使是先进的LRM模型在LocalSearchBench上的表现也不理想，最佳模型（DeepSeek-V3.1）的正确率仅为34.34%，大多数模型在完整性和忠实度上也存在问题。

Conclusion: 本研究强调了在本地生活服务领域需要专门的基准测试和领域特定的代理训练。

Abstract: Recent advances in large reasoning models (LRMs) have enabled agentic search systems to perform complex multi-step reasoning across multiple sources. However, most studies focus on general information retrieval and rarely explores vertical domains with unique challenges. In this work, we focus on local life services and introduce LocalSearchBench, which encompass diverse and complex business scenarios. Real-world queries in this domain are often ambiguous and require multi-hop reasoning across merchants and products, remaining challenging and not fully addressed. As the first comprehensive benchmark for agentic search in local life services, LocalSearchBench includes over 150,000 high-quality entries from various cities and business types. We construct 300 multi-hop QA tasks based on real user queries, challenging agents to understand questions and retrieve information in multiple steps. We also developed LocalPlayground, a unified environment integrating multiple tools for agent interaction. Experiments show that even state-of-the-art LRMs struggle on LocalSearchBench: the best model (DeepSeek-V3.1) achieves only 34.34% correctness, and most models have issues with completeness (average 77.33%) and faithfulness (average 61.99%). This highlights the need for specialized benchmarks and domain-specific agent training in local life services. Code, Benchmark, and Leaderboard are available at localsearchbench.github.io.

</details>


### [311] [Comparative Analysis and Parametric Tuning of PPO, GRPO, and DAPO for LLM Reasoning Enhancement](https://arxiv.org/abs/2512.07611)
*Yongsheng Lian*

Main category: cs.AI

TL;DR: 比较三种RL算法（PPO、GRPO、DAPO）对LLM推理能力的提升，发现RL训练普遍有效，但效果因算法和参数而异。GRPO/DAPO组大小增加有益，DAPO禁用DS时最佳。


<details>
  <summary>Details</summary>
Motivation: 旨在通过RL算法提升大型语言模型（LLMs）的复杂推理能力，并探讨不同RL训练策略的效果。

Method: 本研究系统比较了三种RL算法（PPO、GRPO和DAPO），通过控制性迁移学习评估：模型先在Countdown Game上微调，再在通用推理基准套件上评估。

Result: RL训练的模型在所有任务中表现优于基础模型。GRPO和DAPO中增加组大小可提高性能，KL惩罚系数的影响非单调，DAPO的DS组件无益且禁用时表现最佳。

Conclusion: 研究表明，RL训练的模型在所有任务中均优于基础模型，但改进程度因基准而异。GRPO和DAPO中增加组大小可提高训练稳定性和准确性，而KL惩罚系数的影响是非单调的。DAPO的动态采样（DS）组件并未提升性能，禁用DS时DAPO表现最佳。

Abstract: This study presents a systematic comparison of three Reinforcement Learning (RL) algorithms (PPO, GRPO, and DAPO) for improving complex reasoning in large language models (LLMs). Our main contribution is a controlled transfer-learning evaluation: models are first fine-tuned on the specialized Countdown Game and then assessed on a suite of general-purpose reasoning benchmarks. Across all tasks, RL-trained models outperform their corresponding base models, although the degree of improvement differs by benchmark.
  Our parametric analysis offers practical guidance for RL-based LLM training. Increasing the group size in GRPO and DAPO leads to more stable training dynamics and higher accuracy, while the impact of the KL-penalty coefficient is non-monotonic. Additionally, we find that the Dynamic Sampling (DS) component in DAPO does not improve performance; in fact, the best overall results are achieved with DAPO when DS is disabled.

</details>


### [312] [The Agent Capability Problem: Predicting Solvability Through Information-Theoretic Bounds](https://arxiv.org/abs/2512.07631)
*Shahar Lutati*

Main category: cs.AI

TL;DR: ACP框架通过信息获取预测代理在资源约束下的问题解决能力，实验验证其高效性。


<details>
  <summary>Details</summary>
Motivation: 解决自主代理在何时应投入资源到任务中的问题，避免依赖经验启发式方法。

Method: ACP将问题解决视为信息获取过程，通过计算$\Ceff = (\Itotal/\Istep), \Cstep$预测资源需求，并提供了紧概率上界。

Result: 实验验证表明ACP预测与实际代理性能紧密匹配，优于贪婪和随机策略。

Conclusion: ACP框架通过信息获取的视角预测代理在资源约束下解决问题的能力，其预测与实际代理性能紧密匹配，显著提高了搜索效率。

Abstract: When should an autonomous agent commit resources to a task? We introduce the Agent Capability Problem (ACP), a framework for predicting whether an agent can solve a problem under resource constraints. Rather than relying on empirical heuristics, ACP frames problem-solving as information acquisition: an agent requires $\Itotal$ bits to identify a solution and gains $\Istep$ bits per action at cost $\Cstep$, yielding an effective cost $\Ceff = (\Itotal/\Istep), \Cstep$ that predicts resource requirements before search. We prove that $\Ceff$ lower-bounds expected cost and provide tight probabilistic upper bounds. Experimental validation shows that ACP predictions closely track actual agent performance, consistently bounding search effort while improving efficiency over greedy and random strategies. The framework generalizes across LLM-based and agentic workflows, linking principles from active learning, Bayesian optimization, and reinforcement learning through a unified information-theoretic lens. \

</details>


### [313] [Each Prompt Matters: Scaling Reinforcement Learning Without Wasting Rollouts on Hundred-Billion-Scale MoE](https://arxiv.org/abs/2512.07710)
*Anxiang Zeng,Haibo Zhang,Hailing Zhang,Kaixiang Mo,Liang Yao,Ling Hu,Long Zhang,Shuman Liu,Shuyi Xie,Yanshi Li,Yizhang Chen,Yuepeng Sheng,Yuwei Huang,Zhaochen Xu,Zhiqiang Zhou,Ziqin Liew*

Main category: cs.AI

TL;DR: CompassMax-V3-Thinking 是一个百亿规模的 MoE 推理模型，通过创新的 RL 框架解决了大规模训练的低效问题，实现了稳定高效的训练和优异的性能表现。


<details>
  <summary>Details</summary>
Motivation: 解决大规模 RL 训练中的低效问题，如零方差提示浪费、长视野重要性采样不稳定、奖励模型导致的优势反转以及 rollout 处理的系统性瓶颈。

Method: 采用了多项创新技术：多阶段零方差消除（Multi-Stage Zero-Variance Elimination）、熵自适应优化方法（ESPO）、路由器重放策略（Router Replay）以及高吞吐量 RL 系统。

Result: 模型在百亿规模 MoE 模型上实现了稳定高效的 RL 训练，并在评估中表现优异。

Conclusion: CompassMax-V3-Thinking 是一个百亿规模的 MoE 推理模型，通过新的 RL 框架实现了稳定高效的训练，并在内部和公开评估中表现出色。

Abstract: We present CompassMax-V3-Thinking, a hundred-billion-scale MoE reasoning model trained with a new RL framework built on one principle: each prompt must matter. Scaling RL to this size exposes critical inefficiencies-zero-variance prompts that waste rollouts, unstable importance sampling over long horizons, advantage inversion from standard reward models, and systemic bottlenecks in rollout processing. To overcome these challenges, we introduce several unified innovations: (1) Multi-Stage Zero-Variance Elimination, which filters out non-informative prompts and stabilizes group-based policy optimization (e.g. GRPO) by removing wasted rollouts; (2) ESPO, an entropy-adaptive optimization method that balances token-level and sequence-level importance sampling to maintain stable learning dynamics; (3) a Router Replay strategy that aligns training-time MoE router decisions with inference-time behavior to mitigate train-infer discrepancies, coupled with a reward model adjustment to prevent advantage inversion; (4) a high-throughput RL system with FP8-precision rollouts, overlapped reward computation, and length-aware scheduling to eliminate performance bottlenecks. Together, these contributions form a cohesive pipeline that makes RL on hundred-billion-scale MoE models stable and efficient. The resulting model delivers strong performance across both internal and public evaluations.

</details>


### [314] [RL-MTJail: Reinforcement Learning for Automated Black-Box Multi-Turn Jailbreaking of Large Language Models](https://arxiv.org/abs/2512.07761)
*Xiqiao Xiong,Ouxiang Li,Zhuo Liu,Moxin Li,Wentao Shi,Fuli Feng,Xiangnan He*

Main category: cs.AI

TL;DR: 该论文提出了一种多轮强化学习框架，通过优化最终危害性和引入过程奖励，显著提升了黑盒模型的多轮越狱攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 研究黑盒多轮越狱攻击，旨在训练攻击者LLM通过多轮提示-输出交互从黑盒模型中引出有害内容，弥补现有单轮优化方法的不足。

Method: 将问题建模为多轮强化学习任务，直接优化最终轮输出的危害性作为结果奖励，并引入两种启发式过程奖励以缓解稀疏监督问题。

Result: 在多个基准测试中，攻击成功率显著提升，验证了方法的有效性。

Conclusion: 该论文通过多轮强化学习框架有效提升了黑盒模型的多轮越狱攻击成功率，验证了所提出的启发式过程奖励的有效性。

Abstract: Large language models are vulnerable to jailbreak attacks, threatening their safe deployment in real-world applications. This paper studies black-box multi-turn jailbreaks, aiming to train attacker LLMs to elicit harmful content from black-box models through a sequence of prompt-output interactions. Existing approaches typically rely on single turn optimization, which is insufficient for learning long-term attack strategies. To bridge this gap, we formulate the problem as a multi-turn reinforcement learning task, directly optimizing the harmfulness of the final-turn output as the outcome reward. To mitigate sparse supervision and promote long-term attack strategies, we propose two heuristic process rewards: (1) controlling the harmfulness of intermediate outputs to prevent triggering the black-box model's rejection mechanisms, and (2) maintaining the semantic relevance of intermediate outputs to avoid drifting into irrelevant content. Experimental results on multiple benchmarks show consistently improved attack success rates across multiple models, highlighting the effectiveness of our approach. The code is available at https://github.com/xxiqiao/RL-MTJail. Warning: This paper contains examples of harmful content.

</details>


### [315] [ReasonBENCH: Benchmarking the (In)Stability of LLM Reasoning](https://arxiv.org/abs/2512.07795)
*Nearchos Potamitis,Lars Klein,Akhil Arora*

Main category: cs.AI

TL;DR: ReasonBENCH是一个新基准，用于量化LLM推理中的不稳定性，发现大多数推理策略和模型存在高不稳定性，影响可重复性和报告性能的可靠性。


<details>
  <summary>Details</summary>
Motivation: 当前评估实践主要报告单次运行准确性，忽略了随机解码带来的内在不确定性，导致无法可靠评估方法的性能稳定性、可重复性或成本一致性。

Method: 引入ReasonBENCH，包括模块化评估库、多运行协议和公开排行榜，以标准化推理框架、模型和任务，并提供统计可靠的指标。

Result: 大多数推理策略和模型表现出高度不稳定性，即使平均性能相似的策略也可能显示出高达四倍的置信区间宽度，且性能最佳的方法通常成本更高且更不稳定。

Conclusion: ReasonBENCH 是第一个旨在量化LLM推理中不稳定性的基准，强调了可重复性作为可靠LLM推理的关键维度，并为未来的推理方法和不确定性量化技术奠定了基础。

Abstract: Large language models (LLMs) are increasingly deployed in settings where reasoning, such as multi-step problem solving and chain-of-thought, is essential. Yet, current evaluation practices overwhelmingly report single-run accuracy while ignoring the intrinsic uncertainty that naturally arises from stochastic decoding. This omission creates a blind spot because practitioners cannot reliably assess whether a method's reported performance is stable, reproducible, or cost-consistent. We introduce ReasonBENCH, the first benchmark designed to quantify the underlying instability in LLM reasoning. ReasonBENCH provides (i) a modular evaluation library that standardizes reasoning frameworks, models, and tasks, (ii) a multi-run protocol that reports statistically reliable metrics for both quality and cost, and (iii) a public leaderboard to encourage variance-aware reporting. Across tasks from different domains, we find that the vast majority of reasoning strategies and models exhibit high instability. Notably, even strategies with similar average performance can display confidence intervals up to four times wider, and the top-performing methods often incur higher and less stable costs. Such instability compromises reproducibility across runs and, consequently, the reliability of reported performance. To better understand these dynamics, we further analyze the impact of prompts, model families, and scale on the trade-off between solve rate and stability. Our results highlight reproducibility as a critical dimension for reliable LLM reasoning and provide a foundation for future reasoning methods and uncertainty quantification techniques. ReasonBENCH is publicly available at https://github.com/au-clan/ReasonBench .

</details>


### [316] [Large Causal Models from Large Language Models](https://arxiv.org/abs/2512.07796)
*Sridhar Mahadevan*

Main category: cs.AI

TL;DR: DEMOCRITUS利用LLMs构建跨领域因果模型，通过新方法整合碎片化因果声明，展示了多领域应用效果，并探讨了扩展方向。


<details>
  <summary>Details</summary>
Motivation: 传统因果推理方法局限于狭窄领域和假设，DEMOCRITUS旨在利用LLMs的潜力构建跨领域的大规模因果模型。

Method: 采用新的分类机器学习方法，通过六个模块的实现流程，从LLMs中提取多样领域的因果声明，并将其整合为连贯的因果三元组。

Result: DEMOCRITUS在考古学、生物学、气候变化、经济学、医学和技术等多个领域展示了应用效果，并分析了系统扩展的计算瓶颈。

Conclusion: 论文提出了DEMOCRITUS系统的新范式，利用大型语言模型（LLMs）构建大规模因果模型（LCMs），并探讨了其局限性和未来扩展方向。

Abstract: We introduce a new paradigm for building large causal models (LCMs) that exploits the enormous potential latent in today's large language models (LLMs). We describe our ongoing experiments with an implemented system called DEMOCRITUS (Decentralized Extraction of Manifold Ontologies of Causal Relations Integrating Topos Universal Slices) aimed at building, organizing, and visualizing LCMs that span disparate domains extracted from carefully targeted textual queries to LLMs. DEMOCRITUS is methodologically distinct from traditional narrow domain and hypothesis centered causal inference that builds causal models from experiments that produce numerical data. A high-quality LLM is used to propose topics, generate causal questions, and extract plausible causal statements from a diverse range of domains. The technical challenge is then to take these isolated, fragmented, potentially ambiguous and possibly conflicting causal claims, and weave them into a coherent whole, converting them into relational causal triples and embedding them into a LCM. Addressing this technical challenge required inventing new categorical machine learning methods, which we can only briefly summarize in this paper, as it is focused more on the systems side of building DEMOCRITUS. We describe the implementation pipeline for DEMOCRITUS comprising of six modules, examine its computational cost profile to determine where the current bottlenecks in scaling the system to larger models. We describe the results of using DEMOCRITUS over a wide range of domains, spanning archaeology, biology, climate change, economics, medicine and technology. We discuss the limitations of the current DEMOCRITUS system, and outline directions for extending its capabilities.

</details>


### [317] [Auditing Games for Sandbagging](https://arxiv.org/abs/2512.07810)
*Jordan Taylor,Sid Black,Dillon Bowen,Thomas Read,Satvik Golechha,Alex Zelenka-Martin,Oliver Makins,Connor Kissane,Kola Ayonrinde,Jacob Merizian,Samuel Marks,Chris Cundy,Joseph Bloom*

Main category: cs.AI

TL;DR: 研究发现现有方法难以可靠检测AI系统的‘伪装’行为，基于训练的激发虽有效但易误判，建议短期采用分布内训练，长期需进一步研究。


<details>
  <summary>Details</summary>
Motivation: 未来AI系统可能在评估中隐藏能力（‘伪装’），误导开发者和审计者，因此需要测试检测技术的有效性。

Method: 使用审计游戏测试‘伪装’检测技术，包括红队微调模型（部分模型有条件地表现不佳）和蓝队采用黑盒、模型内部或基于训练的方法识别伪装模型。

Result: 蓝队无法可靠区分伪装模型与良性模型；黑盒方法被有效模仿弱模型的行为击败；线性探测（模型内部方法）更有前景但易受红队行为影响；基于训练的激发能持续激发伪装模型的全部性能，但存在假阳性风险。

Conclusion: 短期内建议开发者通过分布内训练消除潜在的‘伪装’行为，长期则需要进一步研究以确保基于训练的激发方法的有效性，并开发更稳健的检测方法。

Abstract: Future AI systems could conceal their capabilities ('sandbagging') during evaluations, potentially misleading developers and auditors. We stress-tested sandbagging detection techniques using an auditing game. First, a red team fine-tuned five models, some of which conditionally underperformed, as a proxy for sandbagging. Second, a blue team used black-box, model-internals, or training-based approaches to identify sandbagging models. We found that the blue team could not reliably discriminate sandbaggers from benign models. Black-box approaches were defeated by effective imitation of a weaker model. Linear probes, a model-internals approach, showed more promise but their naive application was vulnerable to behaviours instilled by the red team. We also explored capability elicitation as a strategy for detecting sandbagging. Although Prompt-based elicitation was not reliable, training-based elicitation consistently elicited full performance from the sandbagging models, using only a single correct demonstration of the evaluation task. However the performance of benign models was sometimes also raised, so relying on elicitation as a detection strategy was prone to false-positives. In the short-term, we recommend developers remove potential sandbagging using on-distribution training for elicitation. In the longer-term, further research is needed to ensure the efficacy of training-based elicitation, and develop robust methods for sandbagging detection. We open source our model organisms at https://github.com/AI-Safety-Institute/sandbagging_auditing_games and select transcripts and results at https://huggingface.co/datasets/sandbagging-games/evaluation_logs . A demo illustrating the game can be played at https://sandbagging-demo.far.ai/ .

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [318] [POrTAL: Plan-Orchestrated Tree Assembly for Lookahead](https://arxiv.org/abs/2512.06002)
*Evan Conway,David Porfirio,David Chan,Mark Roberts,Laura M. Hiatt*

Main category: cs.RO

TL;DR: POrTAL是一种轻量级概率规划算法，结合FF-Replan和POMCP优势，在部分可观察环境下高效生成解决方案，步骤数优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 在部分可观察环境下，机器人需要高效且快速的规划算法来应对不确定性，而现有算法可能效率不足或步骤过多。

Method: 结合FF-Replan和POMCP两种基线规划算法的优势，开发了轻量级概率规划算法POrTAL。

Result: 通过案例研究证明，POrTAL在步骤数上优于基线方法，并在不同时间约束下表现良好。

Conclusion: POrTAL算法在任务分配和规划中展现出高效性，尤其在部分可观察环境下，能够快速生成优于基线方法的解决方案。

Abstract: Assigning tasks to robots often involves supplying the robot with an overarching goal, such as through natural language, and then relying on the robot to uncover and execute a plan to achieve that goal. In many settings common to human-robot interaction, however, the world is only partially observable to the robot, requiring that it create plans under uncertainty. Although many probabilistic planning algorithms exist for this purpose, these algorithms can be inefficient if executed with the robot's limited computational resources, or may require more steps than expected to achieve the goal. We thereby created a new, lightweight, probabilistic planning algorithm, Plan-Orchestrated Tree Assembly for Lookahead (POrTAL), that combines the strengths of two baseline planning algorithms, FF-Replan and POMCP. In a series of case studies, we demonstrate POrTAL's ability to quickly arrive at solutions that outperform these baselines in terms of number of steps. We additionally demonstrate how POrTAL performs under varying temporal constraints.

</details>


### [319] [Training-Free Robot Pose Estimation using Off-the-Shelf Foundational Models](https://arxiv.org/abs/2512.06017)
*Laurence Liang*

Main category: cs.RO

TL;DR: 使用前沿视觉语言模型（VLMs）从单张图像估计机器人关节角度，验证其在合成和真实数据上的性能，发现测试时间或参数缩放单独无效。


<details>
  <summary>Details</summary>
Motivation: 随着机器人手臂在工业和家庭中的广泛应用，可靠的关节角度估计能提升安全性和性能，并可作为验证器进一步训练机器人策略。

Method: 通过评估前沿VLMs在合成和真实世界图像数据上的表现，建立当前FLMs的性能基线。

Result: 实证结果表明，前沿VLMs在关节角度预测上建立了性能基线，但测试时间或参数缩放单独使用无显著改进。

Conclusion: 前沿视觉语言模型（VLMs）可以作为现成工具用于从单张目标图像估计机器人手臂的关节角度，但测试时间缩放或参数缩放单独使用并不能改善预测效果。

Abstract: Pose estimation of a robot arm from visual inputs is a challenging task. However, with the increasing adoption of robot arms for both industrial and residential use cases, reliable joint angle estimation can offer improved safety and performance guarantees, and also be used as a verifier to further train robot policies. This paper introduces using frontier vision-language models (VLMs) as an ``off-the-shelf" tool to estimate a robot arm's joint angles from a single target image. By evaluating frontier VLMs on both synthetic and real-world image-data pairs, this paper establishes a performance baseline attained by current FLMs. In addition, this paper presents empirical results suggesting that test time scaling or parameter scaling alone does not lead to improved joint angle predictions.

</details>


### [320] [Closed-Loop Robotic Manipulation of Transparent Substrates for Self-Driving Laboratories using Deep Learning Micro-Error Correction](https://arxiv.org/abs/2512.06038)
*Kelsey Fontenot,Anjali Gorti,Iva Goel,Tonio Buonassisi,Alexander E. Siemenn*

Main category: cs.RO

TL;DR: 开发了自动基板处理和交换（ASHE）系统，通过机器人和深度学习技术提升自动驾驶实验室的基板处理准确率至98.5%。


<details>
  <summary>Details</summary>
Motivation: 尽管自动驾驶实验室（SDLs）已自动化了许多化学和材料实验步骤，但基板的处理和重新加载这一自动化流程中的常见步骤仍被忽视。

Method: 采用机器人、双驱动分配器和深度学习驱动的计算机视觉技术，开发了一种闭环的自动基板处理和交换（ASHE）方法，用于检测和纠正脆弱透明基板操作中的错误。

Result: 使用ASHE在130次独立试验中展示了98.5%的首次放置准确率，仅发生两次基板错位并被成功检测和自动纠正。

Conclusion: 通过开发更准确、可靠的基板处理方法，我们提升了自动驾驶实验室的自动化能力，进一步加速了新型化学和材料发现的进程。

Abstract: Self-driving laboratories (SDLs) have accelerated the throughput and automation capabilities for discovering and improving chemistries and materials. Although these SDLs have automated many of the steps required to conduct chemical and materials experiments, a commonly overlooked step in the automation pipeline is the handling and reloading of substrates used to transfer or deposit materials onto for downstream characterization. Here, we develop a closed-loop method of Automated Substrate Handling and Exchange (ASHE) using robotics, dual-actuated dispensers, and deep learning-driven computer vision to detect and correct errors in the manipulation of fragile and transparent substrates for SDLs. Using ASHE, we demonstrate a 98.5% first-time placement accuracy across 130 independent trials of reloading transparent glass substrates into an SDL, where only two substrate misplacements occurred and were successfully detected as errors and automatically corrected. Through the development of more accurate and reliable methods for handling various types of substrates, we move toward an improvement in the automation capabilities of self-driving laboratories, furthering the acceleration of novel chemical and materials discoveries.

</details>


### [321] [Multi-Rigid-Body Approximation of Human Hands with Application to Digital Twin](https://arxiv.org/abs/2512.07359)
*Bin Zhao,Yiwen Lu,Haohua Zhu,Xiao Li,Sheng Yi*

Main category: cs.RO

TL;DR: 提出了一种实时物理模拟的多刚体手部模型构建方法，通过MANO到URDF的转换和旋转投影技术，实现了高精度和高效的数字孪生应用。


<details>
  <summary>Details</summary>
Motivation: 数字孪生应用中需要平衡解剖学逼真度和计算效率的手部模拟模型。

Method: 从光学运动捕捉数据出发，构建个性化的MANO模型，并将其转换为URDF表示，同时处理单自由度和两自由度关节的旋转投影问题。

Result: 实验验证了模型在重放人类演示动作时的亚厘米级重建误差和多样化操作任务中的成功抓取执行。

Conclusion: 本文提出了一种高效且解剖学上精确的多刚体手部模型构建方法，通过验证实验展示了其在数字孪生应用中的实用性，实现了亚厘米级的重建误差和成功的抓取执行。

Abstract: Human hand simulation plays a critical role in digital twin applications, requiring models that balance anatomical fidelity with computational efficiency. We present a complete pipeline for constructing multi-rigid-body approximations of human hands that preserve realistic appearance while enabling real-time physics simulation. Starting from optical motion capture of a specific human hand, we construct a personalized MANO (Multi-Abstracted hand model with Neural Operations) model and convert it to a URDF (Unified Robot Description Format) representation with anatomically consistent joint axes. The key technical challenge is projecting MANO's unconstrained SO(3) joint rotations onto the kinematically constrained joints of the rigid-body model. We derive closed-form solutions for single degree-of-freedom joints and introduce a Baker-Campbell-Hausdorff (BCH)-corrected iterative method for two degree-of-freedom joints that properly handles the non-commutativity of rotations. We validate our approach through digital twin experiments where reinforcement learning policies control the multi-rigid-body hand to replay captured human demonstrations. Quantitative evaluation shows sub-centimeter reconstruction error and successful grasp execution across diverse manipulation tasks.

</details>


### [322] [WAM-Flow: Parallel Coarse-to-Fine Motion Planning via Discrete Flow Matching for Autonomous Driving](https://arxiv.org/abs/2512.06112)
*Yifang Xu,Jiahao Cui,Feipeng Cai,Zhihao Zhu,Hanlin Shang,Shan Luan,Mingwang Xu,Neng Zhang,Yaoyi Li,Jia Cai,Siyu Zhu*

Main category: cs.RO

TL;DR: WAM-Flow是一种并行、双向去噪的VLA模型，通过离散流匹配优化自动驾驶轨迹规划，性能超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决自回归解码器在轨迹规划中的局限性，提出并行、双向去噪的离散流匹配方法。

Method: 结合度量对齐的数字标记器、几何感知的流目标和模拟器引导的GRPO对齐，实现了并行生成和粗到细的优化。

Result: 在NAVSIM v1基准测试中，1步推理达到89.1 PDMS，5步推理达到90.3 PDMS，性能优于自回归和基于扩散的VLA基线。

Conclusion: WAM-Flow通过离散流匹配技术为端到端自动驾驶设定了新的范式，展示了其在闭环性能上的优越性，代码即将公开。

Abstract: We introduce WAM-Flow, a vision-language-action (VLA) model that casts ego-trajectory planning as discrete flow matching over a structured token space. In contrast to autoregressive decoders, WAM-Flow performs fully parallel, bidirectional denoising, enabling coarse-to-fine refinement with a tunable compute-accuracy trade-off. Specifically, the approach combines a metric-aligned numerical tokenizer that preserves scalar geometry via triplet-margin learning, a geometry-aware flow objective and a simulator-guided GRPO alignment that integrates safety, ego progress, and comfort rewards while retaining parallel generation. A multi-stage adaptation converts a pre-trained auto-regressive backbone (Janus-1.5B) from causal decoding to non-causal flow model and strengthens road-scene competence through continued multimodal pretraining. Thanks to the inherent nature of consistency model training and parallel decoding inference, WAM-Flow achieves superior closed-loop performance against autoregressive and diffusion-based VLA baselines, with 1-step inference attaining 89.1 PDMS and 5-step inference reaching 90.3 PDMS on NAVSIM v1 benchmark. These results establish discrete flow matching as a new promising paradigm for end-to-end autonomous driving. The code will be publicly available soon.

</details>


### [323] [Probabilistic Weapon Engagement Zones for a Turn Constrained Pursuer](https://arxiv.org/abs/2512.06130)
*Grant Stagg,Isaac E. Weintraub,Cameron K. Peterson*

Main category: cs.RO

TL;DR: 论文提出了一种在不确定性条件下生成规避轨迹的方法，通过四种方法评估计算成本和准确性，并集成到轨迹优化算法中生成安全路径。


<details>
  <summary>Details</summary>
Motivation: 研究动机是量化规避者应避免的空间区域，以减少来自具有不确定参数的追捕者的捕获风险，包括位置、航向、速度、范围和最大转弯率。

Method: 论文首先推导了确定性曲线-直线基本交战区（CSBEZ）的解析解，然后通过蒙特卡洛采样、线性化、二次近似和神经网络回归四种不确定性传播方法扩展了这一框架。

Result: 论文评估了每种近似方法的准确性和计算成本，并展示了如何将CSPEZ约束集成到轨迹优化算法中，生成考虑追捕者不确定性的安全路径。

Conclusion: 该论文提出了一种在不确定性条件下生成规避轨迹的方法，通过四种不确定性传播方法评估了计算成本和准确性，并展示了如何将CSPEZ约束集成到轨迹优化算法中，以生成考虑追捕者不确定性的安全路径。

Abstract: Curve-straight probabilistic engagement zones (CSPEZ) quantify the spatial regions an evader should avoid to reduce capture risk from a turn-rate-limited pursuer following a curve-straight path with uncertain parameters including position, heading, velocity, range, and maximum turn rate. This paper presents methods for generating evader trajectories that minimize capture risk under such uncertainty. We first derive an analytic solution for the deterministic curve-straight basic engagement zone (CSBEZ), then extend this formulation to a probabilistic framework using four uncertainty-propagation approaches: Monte Carlo sampling, linearization, quadratic approximation, and neural-network regression. We evaluate the accuracy and computational cost of each approximation method and demonstrate how CSPEZ constraints can be integrated into a trajectory-optimization algorithm to produce safe paths that explicitly account for pursuer uncertainty.

</details>


### [324] [GuideNav: User-Informed Development of a Vision-Only Robotic Navigation Assistant For Blind Travelers](https://arxiv.org/abs/2512.06147)
*Hochul Hwang,Soowan Yang,Jahir Sadik Monon,Nicholas A Giudice,Sunghoon Ivan Lee,Joydeep Biswas,Donghyun Kim*

Main category: cs.RO

TL;DR: GuideNav是一种基于视觉的导航系统，模仿导盲犬行为，通过轻量级技术实现高效路径重复，适用于盲人和低视力人群。


<details>
  <summary>Details</summary>
Motivation: 现有机器人导航设计对盲人和低视力人群的直接参考不足，需通过人类研究填补这一空白。

Method: 基于导盲犬训练和辅助方式的启发，开发了GuideNav系统，该系统通过视觉定位、时间滤波和相对位姿估计实现路径重复，无需依赖高成本传感器。

Result: 在五种室外环境中，GuideNav实现了公里级路径跟随，并在用户研究中验证了其可行性。

Conclusion: GuideNav系统通过视觉导航技术成功实现了类似导盲犬的路径重复功能，为盲人和低视力人群提供了一种轻量级、高效的辅助导航解决方案。

Abstract: While commendable progress has been made in user-centric research on mobile assistive systems for blind and low-vision (BLV) individuals, references that directly inform robot navigation design remain rare. To bridge this gap, we conducted a comprehensive human study involving interviews with 26 guide dog handlers, four white cane users, nine guide dog trainers, and one O\&M trainer, along with 15+ hours of observing guide dog-assisted walking. After de-identification, we open-sourced the dataset to promote human-centered development and informed decision-making for assistive systems for BLV people. Building on insights from this formative study, we developed GuideNav, a vision-only, teach-and-repeat navigation system. Inspired by how guide dogs are trained and assist their handlers, GuideNav autonomously repeats a path demonstrated by a sighted person using a robot. Specifically, the system constructs a topological representation of the taught route, integrates visual place recognition with temporal filtering, and employs a relative pose estimator to compute navigation actions - all without relying on costly, heavy, power-hungry sensors such as LiDAR. In field tests, GuideNav consistently achieved kilometer-scale route following across five outdoor environments, maintaining reliability despite noticeable scene variations between teach and repeat runs. A user study with 3 guide dog handlers and 1 guide dog trainer further confirmed the system's feasibility, marking (to our knowledge) the first demonstration of a quadruped mobile system retrieving a path in a manner comparable to guide dogs.

</details>


### [325] [Real-Time Spatiotemporal Tubes for Dynamic Unsafe Sets](https://arxiv.org/abs/2512.06151)
*Ratnangshu Das,Siddhartha Upadhyay,Pushpak Jagtap*

Main category: cs.RO

TL;DR: 论文提出了一种实时时空管（STT）框架，用于非线性纯反馈系统在动态环境中实现安全任务完成，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 针对非线性纯反馈系统在动态环境中实现到达-避障-停留任务的实时控制需求，尤其是在未知动态情况下。

Method: 引入实时时空管（STT）框架，定义为一个状态空间中的时变球体，其中心和半径通过实时传感器输入在线调整。推导了一种闭式、无近似的控制律，将系统输出约束在STT内。

Result: 提供了障碍物避障和按时任务完成的正式保证，并通过移动机器人和飞行器在复杂动态环境中的仿真和硬件实验验证了框架的有效性和可扩展性。

Conclusion: 该论文提出的实时时空管（STT）框架有效解决了非线性纯反馈系统在动态环境中满足到达-避障-停留任务的需求，并通过仿真和硬件实验验证了其有效性和可扩展性。

Abstract: This paper presents a real-time control framework for nonlinear pure-feedback systems with unknown dynamics to satisfy reach-avoid-stay tasks within a prescribed time in dynamic environments. To achieve this, we introduce a real-time spatiotemporal tube (STT) framework. An STT is defined as a time-varying ball in the state space whose center and radius adapt online using only real-time sensory input. A closed-form, approximation-free control law is then derived to constrain the system output within the STT, ensuring safety and task satisfaction. We provide formal guarantees for obstacle avoidance and on-time task completion. The effectiveness and scalability of the framework are demonstrated through simulations and hardware experiments on a mobile robot and an aerial vehicle, navigating in cluttered dynamic environments.

</details>


### [326] [Situation-Aware Interactive MPC Switching for Autonomous Driving](https://arxiv.org/abs/2512.06182)
*Shuhao Qi,Qiling Aori,Luyao Zhang,Mircea Lazar,Sofie Haesaert*

Main category: cs.RO

TL;DR: 论文提出一种情境感知的MPC切换策略，通过神经网络分类器动态选择控制器，既提升关键场景性能又降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 在自动驾驶的交互交通场景中，高保真模型虽能提供更智能的行为，但计算成本高。由于强交互在交通中相对较少，需要一种平衡性能和计算开销的策略。

Method: 通过比较研究评估不同MPC的交互能力，并开发了一个基于神经网络的分类器来实现情境感知的控制器切换。

Result: 实验表明，情境感知切换能在关键情况下激活高级交互MPC提升性能，同时在大多数场景中使用基础MPC显著降低计算负载。

Conclusion: 该论文提出了一种基于情境感知的控制器切换策略，能够在保证性能的同时显著降低计算负载。

Abstract: To enable autonomous driving in interactive traffic scenarios, various model predictive control (MPC) formulations have been proposed, each employing different interaction models. While higher-fidelity models enable more intelligent behavior, they incur increased computational cost. Since strong interactions are relatively infrequent in traffic, a practical strategy for balancing performance and computational overhead is to invoke an appropriate controller based on situational demands. To achieve this approach, we first conduct a comparative study to assess and hierarchize the interactive capabilities of different MPC formulations. Furthermore, we develop a neural network-based classifier to enable situation-aware switching among controllers with different levels of interactive capability. We demonstrate that this situation-aware switching can both substantially improve overall performance by activating the most advanced interactive MPC in rare but critical situations, and significantly reduce computational load by using a basic MPC in the majority of scenarios.

</details>


### [327] [REWW-ARM -- Remote Wire-Driven Mobile Robot: Design, Control, and Experimental Validation](https://arxiv.org/abs/2512.06192)
*Takahiro Hattori,Kento Kawaharazuka,Temma Suzuki,Keita Yoneda,Kei Okada*

Main category: cs.RO

TL;DR: 研究提出了一种无需电子设备的远程线驱动系统“REWW-ARM”，通过实验验证其在多种环境中的操作能力，扩展了机器人的应用范围。


<details>
  <summary>Details</summary>
Motivation: 电子设备限制了机器人的可用环境，因此需要一种在不依赖电子设备的情况下仍能实现高级控制和驱动的方法。

Method: 研究提出了一种名为“Remote Wire Drive”的新系统，并开发了概念验证机器人“REWW-ARM”，包括远程线传输机制（RWTM）、无电子设备的远端移动机器人以及提供电子闭环控制的电机单元。

Result: 实验验证了REWW-ARM在陆地和水下的运动、姿态控制和物体操作能力，证明了Remote Wire Drive系统的可行性。

Conclusion: Remote Wire Drive系统展示了在不同环境中扩展机器人操作范围的潜力，特别是在电子设备受限的场景下。

Abstract: Electronic devices are essential for robots but limit their usable environments. To overcome this, methods excluding electronics from the operating environment while retaining advanced electronic control and actuation have been explored. These include the remote hydraulic drive of electronics-free mobile robots, which offer high reachability, and long wire-driven robot arms with motors consolidated at the base, which offer high environmental resistance. To combine the advantages of both, this study proposes a new system, "Remote Wire Drive." As a proof-of-concept, we designed and developed the Remote Wire-Driven robot "REWW-ARM", which consists of the following components: 1) a novel power transmission mechanism, the "Remote Wire Transmission Mechanism" (RWTM), the key technology of the Remote Wire Drive; 2) an electronics-free distal mobile robot driven by it; and 3) a motor-unit that generates power and provides electronic closed-loop control based on state estimation via the RWTM. In this study, we evaluated the mechanical and control performance of REWW-ARM through several experiments, demonstrating its capability for locomotion, posture control, and object manipulation both on land and underwater. This suggests the potential for applying the Remote Wire-Driven system to various types of robots, thereby expanding their operational range.

</details>


### [328] [Cascaded Tightly-Coupled Observer Design for Single-Range-Aided Inertial Navigation](https://arxiv.org/abs/2512.06198)
*Oussama Sifour,Soulaimane Berkane,Abdelhamid Tayebi*

Main category: cs.RO

TL;DR: 提出了一种基于单距离辅助的导航观测器，通过LTV系统和姿态重构实现了刚体状态的完整估计，具有几乎全局渐近稳定性。


<details>
  <summary>Details</summary>
Motivation: 为了解决仅使用IMU、体坐标系向量测量和固定锚点距离测量来重建刚体完整状态的挑战。

Method: 设计了一个扩展的线性时变（LTV）系统，用于估计体坐标系下的位置、速度和重力方向，并结合体坐标系向量测量重构完整姿态。

Result: 仿真研究表明，该方法在三维轨迹上能够准确估计位置、速度和姿态。

Conclusion: 该论文提出了一种轻量级且有效的自主导航方法，通过单距离辅助实现了对刚体完整状态的高精度估计。

Abstract: This work introduces a single-range-aided navigation observer that reconstructs the full state of a rigid body using only an Inertial Measurement Unit (IMU), a body-frame vector measurement (e.g., magnetometer), and a distance measurement from a fixed anchor point. The design first formulates an extended linear time-varying (LTV) system to estimate body-frame position, body-frame velocity, and the gravity direction. The recovered gravity direction, combined with the body-frame vector measurement, is then used to reconstruct the full orientation on $\mathrm{SO}(3)$, resulting in a cascaded observer architecture. Almost Global Asymptotic Stability (AGAS) of the cascaded design is established under a uniform observability condition, ensuring robustness to sensor noise and trajectory variations. Simulation studies on three-dimensional trajectories demonstrate accurate estimation of position, velocity, and orientation, highlighting single-range aiding as a lightweight and effective modality for autonomous navigation.

</details>


### [329] [Where to Fly, What to Send: Communication-Aware Aerial Support for Ground Robots](https://arxiv.org/abs/2512.06207)
*Harshil Suthar,Dipankar Maity*

Main category: cs.RO

TL;DR: 多机器人团队在带宽受限环境下，空中代理通过VoI和MILP优化信息传输，同时结合效用评分探索策略，平衡探索与地面代理的导航需求。


<details>
  <summary>Details</summary>
Motivation: 在带宽受限的通信环境中，如何平衡空中代理的探索/映射任务与地面代理的目标导航需求，是研究的主要动机。

Method: 采用Value-of-Information（VoI）决定传输内容，Mixed-Integer Linear Programming（MILP）确定传输量，基于效用评分的策略进行环境探索。

Result: 通过通信-运动权衡分析，验证了框架在减少地面代理导航成本的同时优化了地图数据传输量。

Conclusion: 该论文提出的框架通过VoI、MILP和基于效用评分的探索策略，有效解决了带宽受限环境下多机器人团队的信息传输与探索问题。

Abstract: In this work we consider a multi-robot team operating in an unknown environment where one aerial agent is tasked to map the environment and transmit (a portion of) the mapped environment to a group of ground agents that are trying to reach their goals. The entire operation takes place over a bandwidth-limited communication channel, which motivates the problem of determining what and how much information the assisting agent should transmit and when while simultaneously performing exploration/mapping. The proposed framework enables the assisting aerial agent to decide what information to transmit based on the Value-of-Information (VoI), how much to transmit using a Mixed-Integer Linear Programming (MILP), and how to acquire additional information through an utility score-based environment exploration strategy. We perform a communication-motion trade-off analysis between the total amount of map data communicated by the aerial agent and the navigation cost incurred by the ground agents.

</details>


### [330] [Safe Model Predictive Diffusion with Shielding](https://arxiv.org/abs/2512.06261)
*Taekyung Kim,Keyvan Majd,Hideki Okamoto,Bardh Hoxha,Dimitra Panagou,Georgios Fainekos*

Main category: cs.RO

TL;DR: Safe MPD是一种无需训练的扩散规划器，结合安全防护机制，生成动力学可行且安全的轨迹，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决复杂机器人系统生成安全、动力学可行且最优轨迹的挑战，避免后处理修正带来的计算不可行性和可行性损失。

Method: 本文提出了一种无需训练的扩散规划器Safe MPD，通过在去噪过程中对所有样本施加可行性和安全性约束，避免了后处理修正的常见问题。

Result: 在包括运动学和加速度控制的拖拉机-拖车系统在内的非凸规划问题中，Safe MPD在成功率和安全性上显著优于现有安全策略。

Conclusion: Safe MPD通过结合基于模型的扩散框架和安全防护机制，成功生成了既符合动力学约束又安全的轨迹，显著提升了成功率和安全性，同时实现了亚秒级的计算时间。

Abstract: Generating safe, kinodynamically feasible, and optimal trajectories for complex robotic systems is a central challenge in robotics. This paper presents Safe Model Predictive Diffusion (Safe MPD), a training-free diffusion planner that unifies a model-based diffusion framework with a safety shield to generate trajectories that are both kinodynamically feasible and safe by construction. By enforcing feasibility and safety on all samples during the denoising process, our method avoids the common pitfalls of post-processing corrections, such as computational intractability and loss of feasibility. We validate our approach on challenging non-convex planning problems, including kinematic and acceleration-controlled tractor-trailer systems. The results show that it substantially outperforms existing safety strategies in success rate and safety, while achieving sub-second computation times.

</details>


### [331] [Leveraging Port-Hamiltonian Theory for Impedance Control Benchmarking](https://arxiv.org/abs/2512.06423)
*Leonardo F. Dos Santos,Elisa G. Vergamini,Cícero Zanette,Lucca Maitan,Thiago Boaventura*

Main category: cs.RO

TL;DR: 该论文提出了一种基于PH的阻抗控制基准测试方法，通过仿真验证了其在标准化测试中的有效性。


<details>
  <summary>Details</summary>
Motivation: 旨在为阻抗控制提供标准化的基准测试指标，以解决现有方法在动态解耦和时间变化参考下的不足。

Method: 引入了一种因果关系一致的PH模型，用于笛卡尔空间中的质量-弹簧-阻尼器阻抗，并基于该模型推导了一个可微分的、不依赖力-扭矩传感的n自由度无源性条件。

Result: 在Gazebo仿真中，使用六自由度机械臂和四足机器人腿验证了所提出的指标，结果表明PH框架适用于标准化阻抗控制基准测试。

Conclusion: 该论文提出了基于PH的阻抗控制基准测试指标，并通过仿真验证了PH框架在标准化阻抗控制基准测试中的适用性。

Abstract: This work proposes PH-based metrics for benchmarking impedance control. A causality-consistent PH model is introduced for mass-spring-damper impedance in Cartesian space. Based on this model, a differentiable, force-torque sensing-independent, n-DoF passivity condition is derived, valid for time-varying references. An impedance fidelity metric is also defined from step-response power in free motion, capturing dynamic decoupling. The proposed metrics are validated in Gazebo simulations with a six-DoF manipulator and a quadruped leg. Results demonstrate the suitability of the PH framework for standardized impedance control benchmarking.

</details>


### [332] [Fault Tolerant Control of Mecanum Wheeled Mobile Robots](https://arxiv.org/abs/2512.06444)
*Xuehui Ma,Shiliang Zhang,Zhiyong Sun*

Main category: cs.RO

TL;DR: 提出一种针对Mecanum轮式移动机器人的容错控制策略，可同时处理完全和部分执行器故障，通过后验概率实时学习故障参数，确保控制鲁棒性和安全性。


<details>
  <summary>Details</summary>
Motivation: 现有的MWMR容错控制方案主要针对完全执行器故障（如电机失速），忽略了部分故障（如扭矩退化），因此需要一种更全面的解决方案。

Method: 采用后验概率实时学习故障参数，并通过聚合概率加权控制律来推导容错控制律。

Result: 仿真结果表明，所提出的FTC策略在多种场景下均有效。

Conclusion: 论文提出了一种能够同时处理完全和部分执行器故障的容错控制策略，通过后验概率实时学习故障参数，确保了MWMR在不同故障情况下的控制鲁棒性和安全性。

Abstract: Mecanum wheeled mobile robots (MWMRs) are highly susceptible to actuator faults that degrade performance and risk mission failure. Current fault tolerant control (FTC) schemes for MWMRs target complete actuator failures like motor stall, ignoring partial faults e.g., in torque degradation. We propose an FTC strategy handling both fault types, where we adopt posterior probability to learn real-time fault parameters. We derive the FTC law by aggregating probability-weighed control laws corresponding to predefined faults. This ensures the robustness and safety of MWMR control despite varying levels of fault occurrence. Simulation results demonstrate the effectiveness of our FTC under diverse scenarios.

</details>


### [333] [Entropy-Controlled Intrinsic Motivation Reinforcement Learning for Quadruped Robot Locomotion in Complex Terrains](https://arxiv.org/abs/2512.06486)
*Wanru Gong,Xinyi Zheng,Xiaopeng Yang,Xiaoqing Zhu*

Main category: cs.RO

TL;DR: ECIM是一种基于熵的强化学习算法，通过结合内在动机与自适应探索，显著提升了四足机器人在复杂地形上的运动性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有的深度强化学习算法（如PPO系列）在训练四足机器人运动策略时存在过早收敛问题，导致运动性能不佳。

Method: 引入基于熵的强化学习算法ECIM，结合内在动机与自适应探索，以减少过早收敛的问题。实验在Isaac Gym中进行，覆盖六种地形类别。

Result: 实验显示，ECIM在任务奖励上提高了4-12%，峰值身体俯仰振荡减少了23-29%，关节加速度降低了20-32%，关节扭矩消耗减少了11-20%。

Conclusion: ECIM算法通过结合熵控制和内在动机控制，在不同地形上实现了四足机器人运动的更好稳定性，同时降低了能量消耗，使其成为复杂机器人控制任务的实用选择。

Abstract: Learning is the basis of both biological and artificial systems when it comes to mimicking intelligent behaviors. From the classical PPO (Proximal Policy Optimization), there is a series of deep reinforcement learning algorithms which are widely used in training locomotion policies for quadrupedal robots because of their stability and sample efficiency. However, among all these variants, experiments and simulations often converge prematurely, leading to suboptimal locomotion and reduced task performance. Therefore, in this paper, we introduce Entropy-Controlled Intrinsic Motivation (ECIM), an entropy-based reinforcement learning algorithm in contrast with the PPO series, that can reduce premature convergence by combining intrinsic motivation with adaptive exploration.
  For experiments, in order to parallel with other baselines, we chose to apply it in Isaac Gym across six terrain categories: upward slopes, downward slopes, uneven rough terrain, ascending stairs, descending stairs, and flat ground as widely used. For comparison, our experiments consistently achieve better performance: task rewards increase by 4--12%, peak body pitch oscillation is reduced by 23--29%, joint acceleration decreases by 20--32%, and joint torque consumption declines by 11--20%. Overall, our model ECIM, by combining entropy control and intrinsic motivation control, achieves better results in stability across different terrains for quadrupedal locomotion, and at the same time reduces energetic cost and makes it a practical choice for complex robotic control tasks.

</details>


### [334] [Vision-Guided Grasp Planning for Prosthetic Hands in Unstructured Environments](https://arxiv.org/abs/2512.06517)
*Shifa Sulaiman,Akash Bachhar,Ming Shen,Simon Bøgh*

Main category: cs.RO

TL;DR: 该论文提出了一种视觉引导的假肢手抓取算法，结合感知、规划和控制，实现了在非结构化环境中的实时适应性操作。


<details>
  <summary>Details</summary>
Motivation: 旨在通过智能控制系统提升假肢手的灵活性和自主性，使其能在动态环境中更自然地与多样物体交互。

Method: 采用BVH视觉算法分割物体并定义其边界框，结合RRT*算法生成候选轨迹，通过最小欧几里得距离选择指尖末端位姿，并利用DLS逆运动学求解器计算关节角度。

Result: 算法在仿真和实验平台上均表现出良好的实时适应性和抓取效果。

Conclusion: 该论文提出了一种基于视觉引导的抓取算法，通过模块化管道实现了对假肢手的实时适应性控制，并在仿真和Linker Hand O7平台上进行了实验验证。

Abstract: Recent advancements in prosthetic technology have increasingly focused on enhancing dexterity and autonomy through intelligent control systems. Vision-based approaches offer promising results for enabling prosthetic hands to interact more naturally with diverse objects in dynamic environments. Building on this foundation, the paper presents a vision-guided grasping algorithm for a prosthetic hand, integrating perception, planning, and control for dexterous manipulation. A camera mounted on the set up captures the scene, and a Bounding Volume Hierarchy (BVH)-based vision algorithm is employed to segment an object for grasping and define its bounding box. Grasp contact points are then computed by generating candidate trajectories using Rapidly-exploring Random Tree Star algorithm, and selecting fingertip end poses based on the minimum Euclidean distance between these trajectories and the objects point cloud. Each finger grasp pose is determined independently, enabling adaptive, object-specific configurations. Damped Least Square (DLS) based Inverse kinematics solver is used to compute the corresponding joint angles, which are subsequently transmitted to the finger actuators for execution. This modular pipeline enables per-finger grasp planning and supports real-time adaptability in unstructured environments. The proposed method is validated in simulation, and experimental integration on a Linker Hand O7 platform.

</details>


### [335] [TacFinRay: Soft Tactile Fin-Ray Finger with Indirect Tactile Sensing for Robust Grasping](https://arxiv.org/abs/2512.06524)
*Saekwang Nam,Bowen Deng,Loong Yi Lee,Jonathan M. Rossiter,Nathan F. Lepora*

Main category: cs.RO

TL;DR: 本文介绍了一种基于Fin-Ray结构的触觉传感器，通过间接感知和卷积神经网络实现了高精度的接触位置和深度检测，适用于软体机器人。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够同时检测接触位置和压入深度的触觉传感器，适用于软体机器人结构，特别是在感知需要远离接触界面的情况下。

Method: 通过间接感知方法，将软体Fin-Ray结构与刚性传感模块之间的铰链机制集成，使变形和位移信息传递到底部横梁上，基于TacTip视觉触觉传感器的仿生结构，使用内部摄像头捕捉变形模式，并通过卷积神经网络处理推断接触条件。

Result: 通过优化手指设计（如改变针配置和铰链方向），实现了0.1毫米深度和2毫米位置感知精度。感知系统对各种压头形状和大小表现出稳健的泛化能力，并在不确定拾取位置的任务中显著提高了放置精度。

Conclusion: 本研究提供了一种轻量、灵活且可扩展的触觉感知解决方案，适用于需要将感知远离接触界面的软体机器人结构。

Abstract: We present a tactile-sensorized Fin-Ray finger that enables simultaneous detection of contact location and indentation depth through an indirect sensing approach. A hinge mechanism is integrated between the soft Fin-Ray structure and a rigid sensing module, allowing deformation and translation information to be transferred to a bottom crossbeam upon which are an array of marker-tipped pins based on the biomimetic structure of the TacTip vision-based tactile sensor. Deformation patterns captured by an internal camera are processed using a convolutional neural network to infer contact conditions without directly sensing the finger surface. The finger design was optimized by varying pin configurations and hinge orientations, achieving 0.1\,mm depth and 2mm location-sensing accuracies. The perception demonstrated robust generalization to various indenter shapes and sizes, which was applied to a pick-and-place task under uncertain picking positions, where the tactile feedback significantly improved placement accuracy. Overall, this work provides a lightweight, flexible, and scalable tactile sensing solution suitable for soft robotic structures where the sensing needs situating away from the contact interface.

</details>


### [336] [Embodied Referring Expression Comprehension in Human-Robot Interaction](https://arxiv.org/abs/2512.06558)
*Md Mofijul Islam,Alexi Gladstone,Sujan Sarker,Ganesh Nanduru,Md Fahim,Keyan Du,Aman Chadha,Tariq Iqbal*

Main category: cs.RO

TL;DR: 提出Refer360数据集和MuRes模块，提升机器人对具身指令的理解能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有数据集在视角偏差、单视角采集、非语言手势覆盖不足以及主要关注室内环境方面的局限性。

Method: 提出了MuRes，一种多模态引导残差模块，用于提取特定模态的显著信号并增强预训练表示，形成互补特征以支持下游任务。

Result: 在包括Refer360在内的四个HRI数据集上的实验表明，MuRes能持续提升多模态模型的性能。

Conclusion: Refer360数据集为机器人理解人类具身指令提供了有价值的基准，展示了引导残差学习在提升机器人具身指代表达理解能力方面的潜力。

Abstract: As robots enter human workspaces, there is a crucial need for them to comprehend embodied human instructions, enabling intuitive and fluent human-robot interaction (HRI). However, accurate comprehension is challenging due to a lack of large-scale datasets that capture natural embodied interactions in diverse HRI settings. Existing datasets suffer from perspective bias, single-view collection, inadequate coverage of nonverbal gestures, and a predominant focus on indoor environments. To address these issues, we present the Refer360 dataset, a large-scale dataset of embodied verbal and nonverbal interactions collected across diverse viewpoints in both indoor and outdoor settings. Additionally, we introduce MuRes, a multimodal guided residual module designed to improve embodied referring expression comprehension. MuRes acts as an information bottleneck, extracting salient modality-specific signals and reinforcing them into pre-trained representations to form complementary features for downstream tasks. We conduct extensive experiments on four HRI datasets, including the Refer360 dataset, and demonstrate that current multimodal models fail to capture embodied interactions comprehensively; however, augmenting them with MuRes consistently improves performance. These findings establish Refer360 as a valuable benchmark and exhibit the potential of guided residual learning to advance embodied referring expression comprehension in robots operating within human environments.

</details>


### [337] [Learning Agile Striker Skills for Humanoid Soccer Robots from Noisy Sensory Input](https://arxiv.org/abs/2512.06571)
*Zifan Xu,Myoungkyu Seo,Dongmyeong Lee,Hao Fu,Jiaheng Hu,Jiaxun Cui,Yuqian Jiang,Zhihan Wang,Anastasiia Brund,Joydeep Biswas,Peter Stone*

Main category: cs.RO

TL;DR: 该论文通过四阶段教师-学生强化学习框架，实现了人形机器人在噪声感知下的稳健连续踢球，仿真和实物测试均表现优异。


<details>
  <summary>Details</summary>
Motivation: 快速稳健的踢球技能对人形足球机器人至关重要，但由于需要快速摆动腿部、单脚支撑的姿势稳定性以及在噪声感知和外部干扰下的鲁棒性，这一问题极具挑战性。

Method: 系统采用教师-学生训练框架，包括四个训练阶段：长距离追球（教师）、定向踢球（教师）、教师策略蒸馏（学生）以及学生适应与优化（学生）。关键设计包括定制奖励函数、真实噪声建模和在线约束强化学习。

Result: 在仿真和真实机器人上的广泛评估展示了高踢球准确性和多样球门配置下的得分成功率。消融研究进一步验证了约束强化学习、噪声建模和适应阶段的必要性。

Conclusion: 该论文提出了一个基于强化学习的系统，使人形机器人能够在感知不确定的情况下执行稳健的连续踢球动作，为全身控制的视觉运动技能学习设立了基准任务。

Abstract: Learning fast and robust ball-kicking skills is a critical capability for humanoid soccer robots, yet it remains a challenging problem due to the need for rapid leg swings, postural stability on a single support foot, and robustness under noisy sensory input and external perturbations (e.g., opponents). This paper presents a reinforcement learning (RL)-based system that enables humanoid robots to execute robust continual ball-kicking with adaptability to different ball-goal configurations. The system extends a typical teacher-student training framework -- in which a "teacher" policy is trained with ground truth state information and the "student" learns to mimic it with noisy, imperfect sensing -- by including four training stages: (1) long-distance ball chasing (teacher); (2) directional kicking (teacher); (3) teacher policy distillation (student); and (4) student adaptation and refinement (student). Key design elements -- including tailored reward functions, realistic noise modeling, and online constrained RL for adaptation and refinement -- are critical for closing the sim-to-real gap and sustaining performance under perceptual uncertainty. Extensive evaluations in both simulation and on a real robot demonstrate strong kicking accuracy and goal-scoring success across diverse ball-goal configurations. Ablation studies further highlight the necessity of the constrained RL, noise modeling, and the adaptation stage. This work presents a system for learning robust continual humanoid ball-kicking under imperfect perception, establishing a benchmark task for visuomotor skill learning in humanoid whole-body control.

</details>


### [338] [Error-Centric PID Untrained Neural-Net (EC-PIDUNN) For Nonlinear Robotics Control](https://arxiv.org/abs/2512.06578)
*Waleed Razzaq*

Main category: cs.RO

TL;DR: EC-PIDUNN结合神经网络与改进PID控制器，解决了非线性系统控制问题，测试中表现优于经典PID。


<details>
  <summary>Details</summary>
Motivation: 经典PID控制在处理非线性动态和复杂互联变量时表现不佳，现有PIDNN模型虽有效但需大量精细训练数据且计算成本高，限制了实际应用。

Method: 提出EC-PIDUNN架构，整合未经训练的神经网络与改进的PID控制器，引入稳定因子（τ）生成控制信号，利用稳态误差（e_t）作为输入，无需系统动态知识，并通过参数向量（ρ_t）和动态计算功能调整PID系数。

Result: 在非线性无人地面车辆系统和Pan-Tilt运动系统测试中，EC-PIDUNN在收敛性和稳定性上优于经典PID，实现了近乎临界阻尼响应。

Conclusion: EC-PIDUNN架构通过结合未经训练的神经网络和改进的PID控制器，有效解决了非线性系统的控制问题，显著提升了收敛性和稳定性，适用于实际应用。

Abstract: Classical Proportional-Integral-Derivative (PID) control has been widely successful across various industrial systems such as chemical processes, robotics, and power systems. However, as these systems evolved, the increase in the nonlinear dynamics and the complexity of interconnected variables have posed challenges that classical PID cannot effectively handle, often leading to instability, overshooting, or prolonged settling times. Researchers have proposed PIDNN models that combine the function approximation capabilities of neural networks with PID control to tackle these nonlinear challenges. However, these models require extensive, highly refined training data and have significant computational costs, making them less favorable for real-world applications. In this paper, We propose a novel EC-PIDUNN architecture, which integrates an untrained neural network with an improved PID controller, incorporating a stabilizing factor (\(τ\)) to generate the control signal. Like classical PID, our architecture uses the steady-state error \(e_t\) as input bypassing the need for explicit knowledge of the systems dynamics. By forming an input vector from \(e_t\) within the neural network, we increase the dimensionality of input allowing for richer data representation. Additionally, we introduce a vector of parameters \( ρ_t \) to shape the output trajectory and a \textit{dynamic compute} function to adjust the PID coefficients from predefined values. We validate the effectiveness of EC-PIDUNN on multiple nonlinear robotics applications: (1) nonlinear unmanned ground vehicle systems that represent the Ackermann steering mechanism and kinematics control, (2) Pan-Tilt movement system. In both tests, it outperforms classical PID in convergence and stability achieving a nearly critically damped response.

</details>


### [339] [A New Trajectory-Oriented Approach to Enhancing Comprehensive Crowd Navigation Performance](https://arxiv.org/abs/2512.06608)
*Xinyu Zhou,Songhao Piao,Chao Gao,Liguo Chen*

Main category: cs.RO

TL;DR: 本文提出了一种基于DRL的统一框架和奖励策略，优化轨迹曲率，显著提升导航性能，实验验证其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前DRL方法在人群导航中通常优先考虑效率和近端舒适性，但忽视了轨迹优化或仅通过简单、未经验证的平滑奖励来处理。有效的轨迹优化对确保自然性、增强舒适性和最大化能源效率至关重要。

Method: 本文采用深度强化学习（DRL）技术，提出了一个统一的评估框架和一种新的奖励塑造策略，重点优化轨迹曲率。

Result: 通过广泛的2D和3D实验，证明所提方法在多尺度场景中显著提升了轨迹质量和适应性，性能优于现有技术。

Conclusion: 本文提出了一个统一的框架，通过优先考虑和联合评估多个优化目标，实现了对导航方法的公平透明评估。同时，提出了一种新颖的奖励塑造策略，显著提升了轨迹质量和适应性。实验证明，该方法在2D和3D场景中均优于现有技术。

Abstract: Crowd navigation has garnered considerable research interest in recent years, especially with the proliferating application of deep reinforcement learning (DRL) techniques. Many studies, however, do not sufficiently analyze the relative priorities among evaluation metrics, which compromises the fair assessment of methods with divergent objectives. Furthermore, trajectory-continuity metrics, specifically those requiring $C^2$ smoothness, are rarely incorporated. Current DRL approaches generally prioritize efficiency and proximal comfort, often neglecting trajectory optimization or addressing it only through simplistic, unvalidated smoothness reward. Nevertheless, effective trajectory optimization is essential to ensure naturalness, enhance comfort, and maximize the energy efficiency of any navigation system. To address these gaps, this paper proposes a unified framework that enables the fair and transparent assessment of navigation methods by examining the prioritization and joint evaluation of multiple optimization objectives. We further propose a novel reward-shaping strategy that explicitly emphasizes trajectory-curvature optimization. The resulting trajectory quality and adaptability are significantly enhanced across multi-scale scenarios. Through extensive 2D and 3D experiments, we demonstrate that the proposed method achieves superior performance compared to state-of-the-art approaches.

</details>


### [340] [Robust Optimization-based Autonomous Dynamic Soaring with a Fixed-Wing UAV](https://arxiv.org/abs/2512.06610)
*Marvin Harms,Jaeyoung Lim,David Rohr,Friedrich Rockenbauer,Nicholas Lawrance,Roland Siegwart*

Main category: cs.RO

TL;DR: A framework for autonomous dynamic soaring in UAVs, using wind field modeling and robust control, validated in simulations and real flights.


<details>
  <summary>Details</summary>
Motivation: To enable potentially unlimited flight for fixed-wing UAVs without internal energy sources by exploiting wind shear energy through dynamic soaring.

Method: The framework utilizes an explicit wind field representation and classical guidance/control approaches, with robust reference paths and a path-following controller to handle wind estimation errors.

Result: Successful robust dynamic soaring in varied wind conditions, with small sim-to-real gap confirmed in real flight tests.

Conclusion: The proposed framework demonstrates the capability to achieve autonomous dynamic soaring flight in wind shear, validated through both simulation and real flight tests.

Abstract: Dynamic soaring is a flying technique to exploit the energy available in wind shear layers, enabling potentially unlimited flight without the need for internal energy sources. We propose a framework for autonomous dynamic soaring with a fixed-wing unmanned aerial vehicle (UAV). The framework makes use of an explicit representation of the wind field and a classical approach for guidance and control of the UAV. Robustness to wind field estimation error is achieved by constructing point-wise robust reference paths for dynamic soaring and the development of a robust path following controller for the fixed-wing UAV. The framework is evaluated in dynamic soaring scenarios in simulation and real flight tests. In simulation, we demonstrate robust dynamic soaring flight subject to varied wind conditions, estimation errors and disturbances. Critical components of the framework, including energy predictions and path-following robustness, are further validated in real flights to assure small sim-to-real gap. Together, our results strongly indicate the ability of the proposed framework to achieve autonomous dynamic soaring flight in wind shear.

</details>


### [341] [MIND-V: Hierarchical Video Generation for Long-Horizon Robotic Manipulation with RL-based Physical Alignment](https://arxiv.org/abs/2512.06628)
*Ruicheng Zhang,Mingyang Zhang,Jun Zhou,Zhangrui Guo,Xiaofan Liu,Zunnan Xu,Zhizhou Zhong,Puxin Yan,Haocheng Luo,Xiu Li*

Main category: cs.RO

TL;DR: MIND-V 是一个分层框架，通过语义推理、行为转换和视频生成组件，结合强化学习优化，实现了长时程机器人操作视频的物理合理合成。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型在具身模仿学习中受限于短片段和简单动作的合成，且依赖手动定义轨迹，MIND-V旨在解决这一问题。

Method: MIND-V 采用分层框架，包括语义推理中心（SRH）、行为语义桥（BSB）和运动视频生成器（MVG），并通过分阶段视觉未来滚动和GRPO强化学习后训练阶段增强物理合理性。

Result: MIND-V 在长时程机器人操作视频生成中实现了物理合理性和逻辑一致性的合成，表现优于现有方法。

Conclusion: MIND-V 在长时程机器人操作视频生成中表现出最先进的性能，为具身数据合成提供了一个可扩展且可控的范例。

Abstract: Embodied imitation learning is constrained by the scarcity of diverse, long-horizon robotic manipulation data. Existing video generation models for this domain are limited to synthesizing short clips of simple actions and often rely on manually defined trajectories. To this end, we introduce MIND-V, a hierarchical framework designed to synthesize physically plausible and logically coherent videos of long-horizon robotic manipulation. Inspired by cognitive science, MIND-V bridges high-level reasoning with pixel-level synthesis through three core components: a Semantic Reasoning Hub (SRH) that leverages a pre-trained vision-language model for task planning; a Behavioral Semantic Bridge (BSB) that translates abstract instructions into domain-invariant representations; and a Motor Video Generator (MVG) for conditional video rendering. MIND-V employs Staged Visual Future Rollouts, a test-time optimization strategy to enhance long-horizon robustness. To align the generated videos with physical laws, we introduce a GRPO reinforcement learning post-training phase guided by a novel Physical Foresight Coherence (PFC) reward. PFC leverages the V-JEPA world model to enforce physical plausibility by aligning the predicted and actual dynamic evolutions in the feature space. MIND-V demonstrates state-of-the-art performance in long-horizon robotic manipulation video generation, establishing a scalable and controllable paradigm for embodied data synthesis.

</details>


### [342] [Statistic-Augmented, Decoupled MoE Routing and Aggregating in Autonomous Driving](https://arxiv.org/abs/2512.06664)
*Wei-Bin Kou,Guangxu Zhu,Jingreng Lei,Chen Zhang,Yik-Chung Wu,Jianping Wang*

Main category: cs.RO

TL;DR: MoE-RAM利用统计增强的路由和聚合机制，优化了自动驾驶语义分割任务，实验证明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶场景复杂多样，单一深度学习模型难以覆盖所有条件，而现有MoE在路由和聚合上存在不精确和低效的问题。

Method: 提出了一种基于统计检索机制的MoE-RAM，通过匹配LM提取的潜在特征与专家原型特征来优化路由，并通过统计距离自适应重加权专家输出以改进聚合。

Result: 在自动驾驶数据集上的大量实验表明，MoE-RAM相比其他MoE基线和传统单模型方法具有优越性。

Conclusion: MoE-RAM通过统计增强的路由和聚合机制，显著提升了自动驾驶场景下的语义分割性能，优于现有的MoE基线和传统单模型方法。

Abstract: Autonomous driving (AD) scenarios are inherently complex and diverse, posing significant challenges for a single deep learning model to effectively cover all possible conditions, such as varying weather, traffic densities, and road types. Large Model (LM)-Driven Mixture of Experts (MoE) paradigm offers a promising solution, where LM serves as the backbone to extract latent features while MoE serves as the downstream head to dynamically select and aggregate specialized experts to adapt to different scenarios. However, routing and aggregating in MoE face intrinsic challenges, including imprecise expert selection due to flawed routing strategy and inefficient expert aggregation leading to suboptimal prediction. To address these issues, we propose a statistic-augmented, decoupled MoE }outing and Aggregating Mechanism (MoE-RAM) driven by LM. Specifically, on the one hand, MoE-RAM enhances expert routing by incorporating statistical retrieval mechanism to match LM-extracted latent features with cached prototypical features of the most relevant experts; on the other hand, MoE-RAM adaptively reweights experts' outputs in fusion by measuring statistical distances of experts' instant features against LM-extracted latent features. Benefiting from the synergy of the statistic-augmented MoE's routing and aggregating, MoE-RAM ultimately improves the prediction performance. We take the AD semantic segmentation task as an example to assess the proposed MoE-RAM. Extensive experiments on AD datasets demonstrate the superiority of MoE-RAM compared to other MoE baselines and conventional single-model approaches.

</details>


### [343] [FedDSR: Federated Deep Supervision and Regularization Towards Autonomous Driving](https://arxiv.org/abs/2512.06676)
*Wei-Bin Kou,Guangxu Zhu,Bingyang Cheng,Chen Zhang,Yik-Chung Wu,Jianping Wang*

Main category: cs.RO

TL;DR: FedDSR通过中间层监督和正则化优化联邦学习，提升自动驾驶模型性能。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中因非独立同分布数据导致的泛化差和收敛慢问题。

Method: 提出FedDSR范式，包括多中间层选择、互信息和负熵计算作为损失和正则项，以及模型聚合策略。

Result: 实验显示FedDSR在mIoU上提升8.93%，训练轮次减少28.57%。

Conclusion: FedDSR通过中间层监督和正则化显著提升了联邦学习中自动驾驶模型的泛化能力和收敛速度，适用于实际部署。

Abstract: Federated Learning (FL) enables collaborative training of autonomous driving (AD) models across distributed vehicles while preserving data privacy. However, FL encounters critical challenges such as poor generalization and slow convergence due to non-independent and identically distributed (non-IID) data from diverse driving environments. To overcome these obstacles, we introduce Federated Deep Supervision and Regularization (FedDSR), a paradigm that incorporates multi-access intermediate layer supervision and regularization within federated AD system. Specifically, FedDSR comprises following integral strategies: (I) to select multiple intermediate layers based on predefined architecture-agnostic standards. (II) to compute mutual information (MI) and negative entropy (NE) on those selected layers to serve as intermediate loss and regularizer. These terms are integrated into the output-layer loss to form a unified optimization objective, enabling comprehensive optimization across the network hierarchy. (III) to aggregate models from vehicles trained based on aforementioned rules of (I) and (II) to generate the global model on central server. By guiding and penalizing the learning of feature representations at intermediate stages, FedDSR enhances the model generalization and accelerates model convergence for federated AD. We then take the semantic segmentation task as an example to assess FedDSR and apply FedDSR to multiple model architectures and FL algorithms. Extensive experiments demonstrate that FedDSR achieves up to 8.93% improvement in mIoU and 28.57% reduction in training rounds, compared to other FL baselines, making it highly suitable for practical deployment in federated AD ecosystems.

</details>


### [344] [Model-Less Feedback Control of Space-based Continuum Manipulators using Backbone Tension Optimization](https://arxiv.org/abs/2512.06754)
*Shrreya Rajneesh,Nikita Pavle,Rakesh Kumar Sahoo,Manoranjan Sinha*

Main category: cs.RO

TL;DR: 本文提出了一种无模型控制框架，通过在线优化雅可比矩阵和实时二次规划，实现了连续体操纵器在受限环境中的高精度控制。


<details>
  <summary>Details</summary>
Motivation: 连续体操纵器的无限维骨架变形、未建模的内部摩擦和配置依赖的刚度限制了基于模型的运动学公式的可靠性，导致雅可比预测不准确、人工奇异点和不稳定的驱动行为。

Method: 使用经验初始化的雅可比矩阵，并通过差分凸更新在线优化，通过实时二次规划生成尖端运动，同时避免肌腱松弛和几何限制。

Result: 在圆形、五边形和方形轨迹上验证了框架，展示了平滑收敛、稳定的张力演化和亚毫米级稳态精度。

Conclusion: 提出的无模型控制框架在受限环境中展示了可扩展性，实现了亚毫米级稳态精度，无需模型校准或参数识别。

Abstract: Continuum manipulators offer intrinsic dexterity and safe geometric compliance for navigation within confined and obstacle-rich environments. However, their infinite-dimensional backbone deformation, unmodeled internal friction, and configuration-dependent stiffness fundamentally limit the reliability of model-based kinematic formulations, resulting in inaccurate Jacobian predictions, artificial singularities, and unstable actuation behavior. Motivated by these limitations, this work presents a complete model-less control framework that bypasses kinematic modeling by using an empirically initialized Jacobian refined online through differential convex updates. Tip motion is generated via a real-time quadratic program that computes actuator increments while enforcing tendon slack avoidance and geometric limits. A backbone tension optimization term is introduced in this paper to regulate axial loading and suppress co-activation compression. The framework is validated across circular, pentagonal, and square trajectories, demonstrating smooth convergence, stable tension evolution, and sub-millimeter steady-state accuracy without any model calibration or parameter identification. These results establish the proposed controller as a scalable alternative to model-dependent continuum manipulation in a constrained environment.

</details>


### [345] [db-LaCAM: Fast and Scalable Multi-Robot Kinodynamic Motion Planning with Discontinuity-Bounded Search and Lightweight MAPF](https://arxiv.org/abs/2512.06796)
*Akmaral Moldagalieva,Keisuke Okumura,Amanda Prorok,Wolfgang Hönig*

Main category: cs.RO

TL;DR: db-LaCAM 是一种新型多机器人运动规划器，结合 MAPF 的可扩展性和动力学规划的动态感知，显著提升大规模团队的规划效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有多机器人动力学运动规划器因计算负担高而难以处理大规模机器人团队的问题，提高规划器的可扩展性和规划速度。

Method: 结合现代多智能体路径寻找（MAPF）算法的可扩展性和速度与动力学规划器的动态感知能力，提出了一种基于预计算运动基元的 db-LaCAM 规划器，允许用户定义连续运动之间的不连续性。

Result: 实验表明，db-LaCAM 能够高效扩展到 50 个机器人的场景，运行速度比现有最优规划器快十倍，同时保持解决方案质量，并在 2D 和 3D 环境中验证了其有效性。

Conclusion: db-LaCAM 是一种高效的、支持任意机器人动力学的多机器人运动规划器，能够在保持解决方案质量的同时显著提高运行速度，适用于大规模机器人团队的实际应用。

Abstract: State-of-the-art multi-robot kinodynamic motion planners struggle to handle more than a few robots due to high computational burden, which limits their scalability and results in slow planning time.
  In this work, we combine the scalability and speed of modern multi-agent path finding (MAPF) algorithms with the dynamic-awareness of kinodynamic planners to address these limitations.
  To this end, we propose discontinuity-Bounded LaCAM (db-LaCAM), a planner that utilizes a precomputed set of motion primitives that respect robot dynamics to generate horizon-length motion sequences, while allowing a user-defined discontinuity between successive motions.
  The planner db-LaCAM is resolution-complete with respect to motion primitives and supports arbitrary robot dynamics.
  Extensive experiments demonstrate that db-LaCAM scales efficiently to scenarios with up to 50 robots, achieving up to ten times faster runtime compared to state-of-the-art planners, while maintaining comparable solution quality.
  The approach is validated in both 2D and 3D environments with dynamics such as the unicycle and 3D double integrator.
  We demonstrate the safe execution of trajectories planned with db-LaCAM in two distinct physical experiments involving teams of flying robots and car-with-trailer robots.

</details>


### [346] [VP-AutoTest: A Virtual-Physical Fusion Autonomous Driving Testing Platform](https://arxiv.org/abs/2512.07507)
*Yiming Cui,Shiyu Fang,Jiarui Zhang,Yan Huang,Chengkai Xu,Bing Zhu,Hao Zhang,Peng Hang,Jian Sun*

Main category: cs.RO

TL;DR: VP-AutoTest平台整合虚拟与物理元素，支持多维评估和AI诊断，提升自动驾驶测试逼真度和效率。


<details>
  <summary>Details</summary>
Motivation: 传统自动驾驶测试方法存在车辆状态不真实、测试能力有限和高成本等问题，虚拟-物理融合测试虽具潜力但仍面临元素类型有限、测试范围窄和评估指标固定等挑战。

Method: 提出VP-AutoTest平台，整合10余种虚拟和物理元素，支持单车交互和多车协同测试，采用对抗测试和平行推演加速故障检测。

Result: VP-AutoTest平台通过多维评估框架和AI专家系统实现全面性能评估和缺陷诊断，并通过与真实实验对比进行可信度自评估。

Conclusion: VP-AutoTest平台通过整合多种虚拟和物理元素，支持多维评估和AI驱动的专家系统，有效提升了自动驾驶测试的逼真度和效率。

Abstract: The rapid development of autonomous vehicles has led to a surge in testing demand. Traditional testing methods, such as virtual simulation, closed-course, and public road testing, face several challenges, including unrealistic vehicle states, limited testing capabilities, and high costs. These issues have prompted increasing interest in virtual-physical fusion testing. However, despite its potential, virtual-physical fusion testing still faces challenges, such as limited element types, narrow testing scope, and fixed evaluation metrics. To address these challenges, we propose the Virtual-Physical Testing Platform for Autonomous Vehicles (VP-AutoTest), which integrates over ten types of virtual and physical elements, including vehicles, pedestrians, and roadside infrastructure, to replicate the diversity of real-world traffic participants. The platform also supports both single-vehicle interaction and multi-vehicle cooperation testing, employing adversarial testing and parallel deduction to accelerate fault detection and explore algorithmic limits, while OBU and Redis communication enable seamless vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) cooperation across all levels of cooperative automation. Furthermore, VP-AutoTest incorporates a multidimensional evaluation framework and AI-driven expert systems to conduct comprehensive performance assessment and defect diagnosis. Finally, by comparing virtual-physical fusion test results with real-world experiments, the platform performs credibility self-evaluation to ensure both the fidelity and efficiency of autonomous driving testing. Please refer to the website for the full testing functionalities on the autonomous driving public service platform OnSite:https://www.onsite.com.cn.

</details>


### [347] [MagicSkin: Balancing Marker and Markerless Modes in Vision-Based Tactile Sensors with a Translucent Skin](https://arxiv.org/abs/2512.06829)
*Oluwatimilehin Tijani,Zhuo Chen,Jiankang Deng,Shan Luo*

Main category: cs.RO

TL;DR: MagicSkin是一种新型触觉皮肤，通过半透明标记设计同时实现切向位移跟踪、力预测和表面细节保留，性能优于传统方案，无需额外硬件或软件。


<details>
  <summary>Details</summary>
Motivation: 视觉触觉传感器在标记与无标记设计上存在性能权衡：不透明标记能测量力和切向位移但遮挡几何特征，而无标记皮肤虽保留表面细节但难以有效测量切向位移。当前解决方案（如UV照明或基于学习的虚拟转移）增加了硬件复杂性或计算负担。

Method: 本文提出了一种新型触觉皮肤MagicSkin，采用半透明、有色标记，平衡了标记与无标记模式，无需额外硬件或软件工具即可轻松集成到GelSight系列传感器中。

Result: MagicSkin在下游任务中表现优异：物体分类（99.17%）、纹理分类（93.51%）、切向位移跟踪（97%点保留）和力预测（总力误差改善66%），性能优于传统标记和无标记设计。

Conclusion: MagicSkin通过半透明标记设计成功消除了传统视觉触觉传感器在标记与无标记模式之间的性能权衡，为触觉机器人中的多模态触觉感知铺平了道路。

Abstract: Vision-based tactile sensors (VBTS) face a fundamental trade-off in marker and markerless design on the tactile skin: opaque ink markers enable measurement of force and tangential displacement but completely occlude geometric features necessary for object and texture classification, while markerless skin preserves surface details but struggles in measuring tangential displacements effectively. Current practice to solve the above problem via UV lighting or virtual transfer using learning-based models introduces hardware complexity or computing burdens. This paper introduces MagicSkin, a novel tactile skin with translucent, tinted markers balancing the modes of marker and markerless for VBTS. It enables simultaneous tangential displacement tracking, force prediction, and surface detail preservation. This skin is easy to plug into GelSight-family sensors without requiring additional hardware or software tools. We comprehensively evaluate MagicSkin in downstream tasks. The translucent markers impressively enhance rather than degrade sensing performance compared with traditional markerless and inked marker design: it achieves best performance in object classification (99.17\%), texture classification (93.51\%), tangential displacement tracking (97\% point retention) and force prediction (66\% improvement in total force error). These experimental results demonstrate that translucent skin eliminates the traditional performance trade-off in marker or markerless modes, paving the way for multimodal tactile sensing essential in tactile robotics. See videos at this \href{https://zhuochenn.github.io/MagicSkin_project/}{link}.

</details>


### [348] [Dynamic Visual SLAM using a General 3D Prior](https://arxiv.org/abs/2512.06868)
*Xingguang Zhong,Liren Jin,Marija Popović,Jens Behley,Cyrill Stachniss*

Main category: cs.RO

TL;DR: 该论文提出了一种结合几何补丁在线束调整和前馈重建模型的单目视觉SLAM系统，有效解决了动态场景中的相机姿态估计问题。


<details>
  <summary>Details</summary>
Motivation: 动态自然环境中的场景动态会严重影响相机姿态估计的准确性，因此需要一种能够在动态场景中鲁棒估计相机姿态的方法。

Method: 利用前馈重建模型精确过滤动态区域，并通过深度预测增强基于补丁的视觉SLAM的鲁棒性。通过将深度预测与束调整的估计补丁对齐，解决了前馈重建模型批量应用时的尺度模糊问题。

Result: 提出的系统在动态场景中实现了鲁棒的相机姿态估计和3D重建。

Conclusion: 该论文提出了一种新颖的单目视觉SLAM系统，通过结合几何补丁在线束调整和前馈重建模型的互补优势，有效解决了动态自然环境中相机姿态估计的挑战。

Abstract: Reliable incremental estimation of camera poses and 3D reconstruction is key to enable various applications including robotics, interactive visualization, and augmented reality. However, this task is particularly challenging in dynamic natural environments, where scene dynamics can severely deteriorate camera pose estimation accuracy. In this work, we propose a novel monocular visual SLAM system that can robustly estimate camera poses in dynamic scenes. To this end, we leverage the complementary strengths of geometric patch-based online bundle adjustment and recent feed-forward reconstruction models. Specifically, we propose a feed-forward reconstruction model to precisely filter out dynamic regions, while also utilizing its depth prediction to enhance the robustness of the patch-based visual SLAM. By aligning depth prediction with estimated patches from bundle adjustment, we robustly handle the inherent scale ambiguities of the batch-wise application of the feed-forward reconstruction model.

</details>


### [349] [From Zero to High-Speed Racing: An Autonomous Racing Stack](https://arxiv.org/abs/2512.06892)
*Hassan Jardali,Durgakant Pushp,Youwei Yu,Mahmoud Ali,Ihab S. Mohamed,Alejandro Murillo-Gonzalez,Paul D. Coen,Md. Al-Masrur Khan,Reddy Charan Pulivendula,Saeoul Park,Lingchuan Zhou,Lantao Liu*

Main category: cs.RO

TL;DR: 本文介绍了IU Luddy Autonomous Racing团队为Indy Autonomous Challenge开发的Autonomous Race Stack (ARS)，包括其三次迭代、性能评估和多传感器数据集的发布，展示了高速自动驾驶赛车的挑战与成果。


<details>
  <summary>Details</summary>
Motivation: 解决高速自动驾驶赛车中的技术挑战，如精确定位、快速感知、动态规划和实时控制，同时克服赛道访问限制和高成本硬件的问题。

Method: 介绍了Autonomous Race Stack (ARS)的三次迭代开发，包括模块化架构的设计、性能评估方法以及多传感器数据集的收集。

Result: 成功开发了三个版本的ARS，并在不同赛道上验证了其性能，最高速度达到260 km/h。同时发布了高速多传感器数据集。

Conclusion: 论文总结了在高速自动驾驶赛车中遇到的独特挑战和实际经验，强调了模块化架构的重要性以及在不同赛道环境下的性能评估。

Abstract: High-speed, head-to-head autonomous racing presents substantial technical and logistical challenges, including precise localization, rapid perception, dynamic planning, and real-time control-compounded by limited track access and costly hardware. This paper introduces the Autonomous Race Stack (ARS), developed by the IU Luddy Autonomous Racing team for the Indy Autonomous Challenge (IAC). We present three iterations of our ARS, each validated on different tracks and achieving speeds up to 260 km/h. Our contributions include: (i) the modular architecture and evolution of the ARS across ARS1, ARS2, and ARS3; (ii) a detailed performance evaluation that contrasts control, perception, and estimation across oval and road-course environments; and (iii) the release of a high-speed, multi-sensor dataset collected from oval and road-course tracks. Our findings highlight the unique challenges and insights from real-world high-speed full-scale autonomous racing.

</details>


### [350] [Control of Powered Ankle-Foot Prostheses on Compliant Terrain: A Quantitative Approach to Stability Enhancement](https://arxiv.org/abs/2512.06896)
*Chrysostomos Karakasis,Camryn Scully,Robert Salati,Panagiotis Artemiadis*

Main category: cs.RO

TL;DR: 该研究验证了一种基于导纳的控制策略，可动态调整动力假肢的准刚度，显著提高在柔软地面上的步态稳定性，降低跌倒风险。


<details>
  <summary>Details</summary>
Motivation: 动力踝足假肢虽然在速度和刚性地形上表现出适应性，但在柔软或顺应性地面上的控制策略尚未充分探索。

Method: 采用基于导纳的控制策略，动态调整动力假肢的准刚度，以增强在柔软地面上的步态稳定性。通过人体实验，三名健康受试者在两种双侧柔软地面上行走，地面刚度分别为63和25 kN/m。

Result: 与为刚性地形开发的标准相位可变控制器相比，提出的导纳控制器在所有柔软条件下均显著提高了步态稳定性。

Conclusion: 自适应、稳定性感知的假肢控制策略在现实环境中具有降低跌倒风险的潜力，并提升了康复机器人中人-假肢交互的鲁棒性。

Abstract: Walking on compliant terrain presents a substantial challenge for individuals with lower-limb amputation, further elevating their already high risk of falling. While powered ankle-foot prostheses have demonstrated adaptability across speeds and rigid terrains, control strategies optimized for soft or compliant surfaces remain underexplored. This work experimentally validates an admittance-based control strategy that dynamically adjusts the quasi-stiffness of powered prostheses to enhance gait stability on compliant ground. Human subject experiments were conducted with three healthy individuals walking on two bilaterally compliant surfaces with ground stiffness values of 63 and 25 kN/m, representative of real-world soft environments. Controller performance was quantified using phase portraits and two walking stability metrics, offering a direct assessment of fall risk. Compared to a standard phase-variable controller developed for rigid terrain, the proposed admittance controller consistently improved gait stability across all compliant conditions. These results demonstrate the potential of adaptive, stability-aware prosthesis control to reduce fall risk in real-world environments and advance the robustness of human-prosthesis interaction in rehabilitation robotics.

</details>


### [351] [Ground Compliance Improves Retention of Visual Feedback-Based Propulsion Training for Gait Rehabilitation](https://arxiv.org/abs/2512.06897)
*Bradley Hobbs,Panagiotis Artemiadis*

Main category: cs.RO

TL;DR: 地面顺应性与视觉反馈结合比单独视觉反馈更能增强推进力学习，适用于长期康复如中风后步态缺陷。


<details>
  <summary>Details</summary>
Motivation: 研究旨在探索在地面顺应性加入视觉反馈步态训练中，是否能更有效地增加推进力，以改善步态康复效果。

Method: 十名健康参与者在定制的分带跑步机上行走，实时接收地面反作用力的视觉反馈。一组参与者还体验了地面顺应性的变化，而对照组仅接收视觉反馈。

Result: 体验地面顺应性的组别成功实现并维持了推进力的增加，且在肌肉活动和关节运动学上表现出持久的后效，表明更自然地学习增加推进力的策略。

Conclusion: 结合地面顺应性与视觉反馈的步态训练比单独使用视觉反馈更能有效增加推进力（POF），并显示出在步态康复中的潜在应用价值。

Abstract: This study investigates whether adding ground compliance to visual feedback (VF) gait training is more effective at increasing push-off force (POF) compared to using VF alone, with implications for gait rehabilitation. Ten healthy participants walked on a custom split-belt treadmill. All participants received real-time visual feedback of their ground reaction forces. One group also experienced changes in ground compliance, while a control group received only visual feedback. Intentional increases in propulsive ground reaction forces (POF) were successfully achieved and sustained post-intervention, especially in the group that experienced ground compliance. This group also demonstrated lasting after-effects in muscle activity and joint kinematics, indicating a more robust learning of natural strategies to increase propulsion. This work demonstrates how visual and proprioceptive systems coordinate during gait adaptation. It uniquely shows that combining ground compliance with visual feedback enhances the learning of propulsive forces, supporting the potential use of compliant terrain in long-term rehabilitation targeting propulsion deficits, such as those following a stroke.

</details>


### [352] [Energy-Efficient Navigation for Surface Vehicles in Vortical Flow Fields](https://arxiv.org/abs/2512.06912)
*Rushiraj Gadhvi,Sandeep Manjanna*

Main category: cs.RO

TL;DR: 论文提出了一种基于强化学习的导航方法，显著提高了自主水面车辆在涡流场中的能源效率。


<details>
  <summary>Details</summary>
Motivation: 模仿khalasi利用洋流导航的直觉，解决自主水面车辆在严格能源预算下长期任务中的导航挑战。

Method: 采用基于Soft Actor Critic的端到端强化学习框架，仅利用局部速度测量学习流感知导航策略。

Result: 在多样化和动态丰富的场景中，该方法实现了30%至50%的能源节约，并对未见过的流条件表现出强大的泛化能力。

Conclusion: 该论文提出的基于Soft Actor Critic的强化学习框架在涡流场中实现了显著的能源节约，并展示了良好的泛化能力，为海洋环境中的长期自主导航提供了有前景的解决方案。

Abstract: For centuries, khalasi have skillfully harnessed ocean currents to navigate vast waters with minimal effort. Emulating this intuition in autonomous systems remains a significant challenge, particularly for Autonomous Surface Vehicles tasked with long duration missions under strict energy budgets. In this work, we present a learning-based approach for energy-efficient surface vehicle navigation in vortical flow fields, where partial observability often undermines traditional path-planning methods. We present an end to end reinforcement learning framework based on Soft Actor Critic that learns flow-aware navigation policies using only local velocity measurements. Through extensive evaluation across diverse and dynamically rich scenarios, our method demonstrates substantial energy savings and robust generalization to previously unseen flow conditions, offering a promising path toward long term autonomy in ocean environments. The navigation paths generated by our proposed approach show an improvement in energy conservation 30 to 50 percent compared to the existing state of the art techniques.

</details>


### [353] [Interconnection and Damping Assignment Passivity-Based Control using Sparse Neural ODEs](https://arxiv.org/abs/2512.06935)
*Nicolò Botteghi,Owen Brook,Urban Fasel,Federico Califano*

Main category: cs.RO

TL;DR: 提出一种基于神经ODE和稀疏字典学习的数值方法，克服IDA-PBC中匹配PDE解析求解的复杂性，扩展其应用至复杂任务。


<details>
  <summary>Details</summary>
Motivation: IDA-PBC在实际应用中受限于匹配PDE的解析求解复杂性，尤其是在复杂物理系统和任务中。本文旨在克服这一限制，提出无需精确求解PDE的数值方法。

Method: 采用稀疏字典学习参数化闭环系统，并通过多目标优化问题优化控制器参数，结合任务相关成本和匹配条件相关成本。

Result: 数值结果表明，该方法不仅使IDA-PBC适用于稳定化以外的复杂任务（如周期性振荡行为的发现），还能推导出包含残差项的闭环系统闭式表达式。

Conclusion: 本文提出了一种新的数值方法，用于设计IDA-PBC控制器，无需精确求解匹配PDE。通过将IDA-PBC问题转化为神经ODE学习问题，并利用稀疏字典学习参数化闭环系统，成功扩展了IDA-PBC的应用范围，包括周期性振荡行为的发现。

Abstract: Interconnection and Damping Assignment Passivity-Based Control (IDA-PBC) is a nonlinear control technique that assigns a port-Hamiltonian (pH) structure to a controlled system using a state-feedback law. While IDA-PBC has been extensively studied and applied to many systems, its practical implementation often remains confined to academic examples and, almost exclusively, to stabilization tasks. The main limitation of IDA-PBC stems from the complexity of analytically solving a set of partial differential equations (PDEs), referred to as the matching conditions, which enforce the pH structure of the closed-loop system. However, this is extremely challenging, especially for complex physical systems and tasks.
  In this work, we propose a novel numerical approach for designing IDA-PBC controllers without solving the matching PDEs exactly. We cast the IDA-PBC problem as the learning of a neural ordinary differential equation. In particular, we rely on sparse dictionary learning to parametrize the desired closed-loop system as a sparse linear combination of nonlinear state-dependent functions. Optimization of the controller parameters is achieved by solving a multi-objective optimization problem whose cost function is composed of a generic task-dependent cost and a matching condition-dependent cost. Our numerical results show that the proposed method enables (i) IDA-PBC to be applicable to complex tasks beyond stabilization, such as the discovery of periodic oscillatory behaviors, (ii) the derivation of closed-form expressions of the controlled system, including residual terms

</details>


### [354] [Task adaptation of Vision-Language-Action model: 1st Place Solution for the 2025 BEHAVIOR Challenge](https://arxiv.org/abs/2512.06951)
*Ilia Larchenko,Gleb Zarin,Akash Karnatak*

Main category: cs.RO

TL;DR: 该论文提出了一种创新的视觉-动作策略，结合多项技术改进，在复杂家庭任务中表现卓越，赢得2025年BEHAVIOR挑战赛第一名。


<details>
  <summary>Details</summary>
Motivation: 解决大规模、多样化的长时程家庭任务，需要双手机器人操作、导航和上下文感知决策的综合能力。

Method: 基于Pi0.5架构，引入了相关噪声用于流匹配、可学习混合层注意力、System 2阶段跟踪等技术，训练采用多样本流匹配以减少方差，推理时使用动作压缩和挑战特定校正规则。

Result: 在50个任务中实现了26%的q-score，在公开和私有排行榜上均表现优异。

Conclusion: 该论文提出的视觉-动作策略在2025年BEHAVIOR挑战赛中取得了第一名，证明了其在复杂家庭任务中的高效性和实用性。

Abstract: We present a vision-action policy that won 1st place in the 2025 BEHAVIOR Challenge - a large-scale benchmark featuring 50 diverse long-horizon household tasks in photo-realistic simulation, requiring bimanual manipulation, navigation, and context-aware decision making.
  Building on the Pi0.5 architecture, we introduce several innovations. Our primary contribution is correlated noise for flow matching, which improves training efficiency and enables correlation-aware inpainting for smooth action sequences. We also apply learnable mixed-layer attention and System 2 stage tracking for ambiguity resolution. Training employs multi-sample flow matching to reduce variance, while inference uses action compression and challenge-specific correction rules.
  Our approach achieves 26% q-score across all 50 tasks on both public and private leaderboards.

</details>


### [355] [VideoVLA: Video Generators Can Be Generalizable Robot Manipulators](https://arxiv.org/abs/2512.06963)
*Yichao Shen,Fangyun Wei,Zhiying Du,Yaobo Liang,Yan Lu,Jiaolong Yang,Nanning Zheng,Baining Guo*

Main category: cs.RO

TL;DR: VideoVLA利用视频生成模型预测动作序列及未来视觉结果，展示了机器人操作中的强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 提升机器人操作在开放环境中的泛化能力，探索将大型视频生成模型转化为机器人VLA操作器的潜力。

Method: VideoVLA基于多模态Diffusion Transformer，利用预训练的视频生成模型进行联合视觉和动作预测。

Result: 实验表明，高质量的未来视觉想象与可靠的动作预测和任务成功相关，验证了视觉想象在操作中的重要性。

Conclusion: VideoVLA通过联合建模视频、语言和动作模态，展示了在机器人操作中的强泛化能力，包括模仿其他实体的技能和处理新物体。

Abstract: Generalization in robot manipulation is essential for deploying robots in open-world environments and advancing toward artificial general intelligence. While recent Vision-Language-Action (VLA) models leverage large pre-trained understanding models for perception and instruction following, their ability to generalize to novel tasks, objects, and settings remains limited. In this work, we present VideoVLA, a simple approach that explores the potential of transforming large video generation models into robotic VLA manipulators. Given a language instruction and an image, VideoVLA predicts an action sequence as well as the future visual outcomes. Built on a multi-modal Diffusion Transformer, VideoVLA jointly models video, language, and action modalities, using pre-trained video generative models for joint visual and action forecasting. Our experiments show that high-quality imagined futures correlate with reliable action predictions and task success, highlighting the importance of visual imagination in manipulation. VideoVLA demonstrates strong generalization, including imitating other embodiments' skills and handling novel objects. This dual-prediction strategy - forecasting both actions and their visual consequences - explores a paradigm shift in robot learning and unlocks generalization capabilities in manipulation systems.

</details>


### [356] [Parametric Design of a Cable-Driven Coaxial Spherical Parallel Mechanism for Ultrasound Scans](https://arxiv.org/abs/2512.06995)
*Maryam Seraj,Mohammad Hossein Kamrava,Carlo Tiseo*

Main category: cs.RO

TL;DR: 本文设计了一种电缆驱动的同轴球面并联机构（CDC-SPM），通过减少末端质量、优化动态性能，适用于医疗远程操作中的高精度触觉反馈任务。


<details>
  <summary>Details</summary>
Motivation: 解决医疗远程操作中高保真触觉接口的性能权衡问题，如工作空间、灵活性、刚度、惯性和带宽，尤其是在纯旋转运动应用中。

Method: 提出了基于电缆驱动的同轴球面并联机构（CDC-SPM）的设计方法和运动学分析，通过并联和同轴驱动实现解耦的旋转自由度。

Result: 仿真和分析表明，CDC-SPM能够减少末端执行器质量，降低惯性负载，提高刚度和动态响应，实现各向同性的力和扭矩传递。

Conclusion: CDC-SPM机制在医疗远程操作中展现出高精度、响应迅速且安全的运动特性，特别适用于超声成像等需要精确操控的任务。

Abstract: Haptic interfaces play a critical role in medical teleoperation by enabling surgeons to interact with remote environments through realistic force and motion feedback. Achieving high fidelity in such systems requires balancing performance trade-off among workspace, dexterity, stiffness, inertia, and bandwidth, particularly in applications demanding pure rotational motion. This paper presents the design methodology and kinematic analysis of a Cable-Driven Coaxial Spherical Parallel Mechanism (CDC-SPM) developed to address these challenges. The proposed cable-driven interface design allows for reducing the mass placed at the robot arm end-effector, thereby minimizing inertial loads, enhancing stiffness, and improving dynamic responsiveness. Through parallel and coaxial actuation, the mechanism achieves decoupled rotational degrees of freedom with isotropic force and torque transmission. Simulation and analysis demonstrate that the CDC-SPM provides accurate, responsive, and safe motion characteristics suitable for high-precision haptic applications. These results highlight the mechanism's potential for medical teleoperation tasks such as ultrasound imaging, where precise and intuitive manipulation is essential.

</details>


### [357] [A Hetero-Associative Sequential Memory Model Utilizing Neuromorphic Signals: Validated on a Mobile Manipulator](https://arxiv.org/abs/2512.07032)
*Runcong Wang,Fengyi Wang,Gordon Cheng*

Main category: cs.RO

TL;DR: 该论文提出了一种基于异联想顺序记忆的系统，通过神经形态绑定实现移动机械臂的低成本行动决策，展示了在单关节和全臂行为中的成功应用。


<details>
  <summary>Details</summary>
Motivation: 研究旨在开发一种能够在低计算和内存成本下，通过触觉观察和关节状态之间的紧凑神经形态绑定，实现逐步行动决策的系统。

Method: 该方法通过群体位置编码将关节角度转换为二进制向量，并使用Izhikevich神经元模型将皮肤测量的力转换为脉冲率特征。通过引入3D旋转位置嵌入来增强二进制空间的可分离性，实现模糊检索。

Result: 在丰田Human Support Robot上的实验表明，该系统能够实现伪合规控制器，根据施加力的方向和幅度移动链接，并通过触觉输入检索多关节抓取序列。

Conclusion: 该论文提出的异联想顺序记忆系统为移动机械臂提供了一种高效、低计算和内存成本的行动决策方法，展示了在单关节和全臂行为中的成功应用，并提出了在模仿学习、运动规划和多模态集成中的扩展可能性。

Abstract: This paper presents a hetero-associative sequential memory system for mobile manipulators that learns compact, neuromorphic bindings between robot joint states and tactile observations to produce step-wise action decisions with low compute and memory cost. The method encodes joint angles via population place coding and converts skin-measured forces into spike-rate features using an Izhikevich neuron model; both signals are transformed into bipolar binary vectors and bound element-wise to create associations stored in a large-capacity sequential memory. To improve separability in binary space and inject geometry from touch, we introduce 3D rotary positional embeddings that rotate subspaces as a function of sensed force direction, enabling fuzzy retrieval through a softmax weighted recall over temporally shifted action patterns. On a Toyota Human Support Robot covered by robot skin, the hetero-associative sequential memory system realizes a pseudocompliance controller that moves the link under touch in the direction and with speed correlating to the amplitude of applied force, and it retrieves multi-joint grasp sequences by continuing tactile input. The system sets up quickly, trains from synchronized streams of states and observations, and exhibits a degree of generalization while remaining economical. Results demonstrate single-joint and full-arm behaviors executed via associative recall, and suggest extensions to imitation learning, motion planning, and multi-modal integration.

</details>


### [358] [CERNet: Class-Embedding Predictive-Coding RNN for Unified Robot Motion, Recognition, and Confidence Estimation](https://arxiv.org/abs/2512.07041)
*Hiroki Sawada,Alexandre Pitti,Mathias Quoy*

Main category: cs.RO

TL;DR: CERNet是一种层次PC-RNN模型，通过动态类别嵌入向量统一运动生成与识别，在机器人验证中表现优异，适用于意图敏感的人机协作。


<details>
  <summary>Details</summary>
Motivation: 机器人需要实时生成学习到的运动，同时推断观察到的行为意图并估计自身推断的置信度。为此，需要一个统一的模型来集成这三种能力。

Method: 提出了一种统一的层次预测编码循环神经网络（PC-RNN）模型CERNet，通过动态更新的类别嵌入向量在生成和推理两种模式下运作。生成模式下，类别嵌入约束隐藏状态动态到类别特定子空间；推理模式下，通过在线优化最小化预测误差实现实时识别。

Result: 在26个动觉教学字母的人形机器人验证中，该层次模型比参数匹配的单层基线轨迹再现误差降低76%，在外部扰动下保持运动保真度，在线推断演示轨迹类别的Top-1和Top-2准确率分别为68%和81%，且内部预测误差自然反映模型的识别置信度。

Conclusion: CERNet通过动态更新的类别嵌入向量，在单一层次预测编码循环神经网络（PC-RNN）中实现了运动生成、实时识别和内在不确定性估计的集成，为物理机器人提供了一种紧凑且可扩展的运动记忆方法，适用于意图敏感的人机协作。

Abstract: Robots interacting with humans must not only generate learned movements in real-time, but also infer the intent behind observed behaviors and estimate the confidence of their own inferences. This paper proposes a unified model that achieves all three capabilities within a single hierarchical predictive-coding recurrent neural network (PC-RNN) equipped with a class embedding vector, CERNet, which leverages a dynamically updated class embedding vector to unify motor generation and recognition. The model operates in two modes: generation and inference. In the generation mode, the class embedding constrains the hidden state dynamics to a class-specific subspace; in the inference mode, it is optimized online to minimize prediction error, enabling real-time recognition. Validated on a humanoid robot across 26 kinesthetically taught alphabets, our hierarchical model achieves 76% lower trajectory reproduction error than a parameter-matched single-layer baseline, maintains motion fidelity under external perturbations, and infers the demonstrated trajectory class online with 68% Top-1 and 81% Top-2 accuracy. Furthermore, internal prediction errors naturally reflect the model's confidence in its recognition. This integration of robust generation, real-time recognition, and intrinsic uncertainty estimation within a compact PC-RNN framework offers a compact and extensible approach to motor memory in physical robots, with potential applications in intent-sensitive human-robot collaboration.

</details>


### [359] [A Flexible Funnel-Shaped Robotic Hand with an Integrated Single-Sheet Valve for Milligram-Scale Powder Handling](https://arxiv.org/abs/2512.07091)
*Tomoya Takahashi,Yusaku Nakajima,Cristian Camilo Beltran-Hernandez,Yuki Kuroda,Kazutoshi Tanaka,Masashi Hamaya,Kanta Ono,Yoshitaka Ushiku*

Main category: cs.RO

TL;DR: A flexible robotic hand with a controllable valve and feedback system enables precise milligram-scale powder dispensing, achieving high accuracy and adaptability in laboratory automation.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of fully automating powder handling at the milligram scale due to complex flow dynamics and diverse laboratory tasks.

Method: A novel, funnel-shaped, flexible robotic hand with a controllable valve and feedback control system based on powder flow modeling and online parameter identification.

Result: 80% of trials achieved an error within 2 mg, with a maximum error of ~20 mg across a target range of 20 mg to 3 g. Model-based control improved accuracy and convergence speed compared to direct PID control.

Conclusion: The proposed robotic hand system demonstrates significant potential for efficient and flexible powder weighing in laboratory automation, with scalability and broad applicability.

Abstract: Laboratory Automation (LA) has the potential to accelerate solid-state materials discovery by enabling continuous robotic operation without human intervention. While robotic systems have been developed for tasks such as powder grinding and X-ray diffraction (XRD) analysis, fully automating powder handling at the milligram scale remains a significant challenge due to the complex flow dynamics of powders and the diversity of laboratory tasks. To address this challenge, this study proposes a novel, funnel-shaped, flexible robotic hand that preserves the softness and conical sheet designs in prior work while incorporating a controllable valve at the cone apex to enable precise, incremental dispensing of milligram-scale powder quantities. The hand is integrated with an external balance through a feedback control system based on a model of powder flow and online parameter identification. Experimental evaluations with glass beads, monosodium glutamate, and titanium dioxide demonstrated that 80% of the trials achieved an error within 2 mg, and the maximum error observed was approximately 20 mg across a target range of 20 mg to 3 g. In addition, by incorporating flow prediction models commonly used for hoppers and performing online parameter identification, the system is able to adapt to variations in powder dynamics. Compared to direct PID control, the proposed model-based control significantly improved both accuracy and convergence speed. These results highlight the potential of the proposed system to enable efficient and flexible powder weighing, with scalability toward larger quantities and applicability to a broad range of laboratory automation tasks.

</details>


### [360] [Surrogate compliance modeling enables reinforcement learned locomotion gaits for soft robots](https://arxiv.org/abs/2512.07114)
*Jue Wang,Mingsong Jiang,Luis A. Ramirez,Bilige Yang,Mujun Zhang,Esteban Figueroa,Wenzhong Yan,Rebecca Kramer-Bottiglio*

Main category: cs.RO

TL;DR: 提出替代柔顺性建模方法，在刚性体模拟中捕捉软材料变形，结合强化学习实现高效模拟到现实转移，显著提升机器人性能。


<details>
  <summary>Details</summary>
Motivation: 解决软体机器人因软材料变形带来的模拟和控制挑战，提升其在多变环境中的适应性和性能。

Method: 提出了一种替代柔顺性建模方法，通过间接变量在刚性体模拟器中表示软材料变形，并结合强化学习和广泛的随机化训练策略。

Result: 在硬质平坦基底上实现了高保真度的模拟到现实转移，在复杂地形上表现稳健但保真度较低。机器人展示了前所未有的地面机动性，能耗比开环基准降低了一个数量级。

Conclusion: 通过引入替代柔顺性建模方法，在刚性体模拟器中捕捉软材料变形效应，并结合强化学习，实现了高保真度的模拟到现实转移，显著提升了机器人的机动性和能效。

Abstract: Adaptive morphogenetic robots adapt their morphology and control policies to meet changing tasks and environmental conditions. Many such systems leverage soft components, which enable shape morphing but also introduce simulation and control challenges. Soft-body simulators remain limited in accuracy and computational tractability, while rigid-body simulators cannot capture soft-material dynamics. Here, we present a surrogate compliance modeling approach: rather than explicitly modeling soft-body physics, we introduce indirect variables representing soft-material deformation within a rigid-body simulator. We validate this approach using our amphibious robotic turtle, a quadruped with soft morphing limbs designed for multi-environment locomotion. By capturing deformation effects as changes in effective limb length and limb center of mass, and by applying reinforcement learning with extensive randomization of these indirect variables, we achieve reliable policy learning entirely in a rigid-body simulation. The resulting gaits transfer directly to hardware, demonstrating high-fidelity sim-to-real performance on hard, flat substrates and robust, though lower-fidelity, transfer on rheologically complex terrains. The learned closed-loop gaits exhibit unprecedented terrestrial maneuverability and achieve an order-of-magnitude reduction in cost of transport compared to open-loop baselines. Field experiments with the robot further demonstrate stable, multi-gait locomotion across diverse natural terrains, including gravel, grass, and mud.

</details>


### [361] [Mimir: Hierarchical Goal-Driven Diffusion with Uncertainty Propagation for End-to-End Autonomous Driving](https://arxiv.org/abs/2512.07130)
*Zebin Xing,Yupeng Zheng,Qichao Zhang,Zhixing Ding,Pengxuan Yang,Songen Gu,Zhongpu Xia,Dongbin Zhao*

Main category: cs.RO

TL;DR: Mimir通过目标点不确定性估计和多速率引导机制，提升了自动驾驶的鲁棒性和效率，性能显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有端到端自动驾驶系统因高精度引导信号不准确和复杂引导模块计算开销大而受限，需提升鲁棒性和效率。

Method: 提出了一种新颖的分层双系统框架Mimir，采用拉普拉斯分布估计目标点不确定性，并引入多速率引导机制以提前预测扩展目标点。

Result: 在Navhard和Navtest基准测试中，Mimir将驾驶评分EPDMS提升了20%，同时高级模块推理速度提高了1.6倍，且未牺牲准确性。

Conclusion: Mimir框架通过引入目标点不确定性估计和多速率引导机制，显著提升了自动驾驶系统的鲁棒性和计算效率，在Navhard和Navtest基准测试中表现优于现有方法。

Abstract: End-to-end autonomous driving has emerged as a pivotal direction in the field of autonomous systems. Recent works have demonstrated impressive performance by incorporating high-level guidance signals to steer low-level trajectory planners. However, their potential is often constrained by inaccurate high-level guidance and the computational overhead of complex guidance modules. To address these limitations, we propose Mimir, a novel hierarchical dual-system framework capable of generating robust trajectories relying on goal points with uncertainty estimation: (1) Unlike previous approaches that deterministically model, we estimate goal point uncertainty with a Laplace distribution to enhance robustness; (2) To overcome the slow inference speed of the guidance system, we introduce a multi-rate guidance mechanism that predicts extended goal points in advance. Validated on challenging Navhard and Navtest benchmarks, Mimir surpasses previous state-of-the-art methods with a 20% improvement in the driving score EPDMS, while achieving 1.6 times improvement in high-level module inference speed without compromising accuracy. The code and models will be released soon to promote reproducibility and further development. The code is available at https://github.com/ZebinX/Mimir-Uncertainty-Driving

</details>


### [362] [Time-Varying Formation Tracking Control of Wheeled Mobile Robots With Region Constraint: A Generalized Udwadia-Kalaba Framework](https://arxiv.org/abs/2512.07137)
*Kang Yijie,Hao Yuqing,Wang Qingyun,Chen Guanrong*

Main category: cs.RO

TL;DR: 本文在广义Udwadia-Kalaba框架下，设计了考虑区域约束的轮式移动机器人时变编队跟踪控制器，并通过仿真验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究轮式移动机器人在区域约束下的时变编队跟踪控制，以确保机器人的安全性。

Method: 通过将时变编队跟踪控制目标重新表述为约束方程，并通过微分同胚变换处理区域约束，在广义Udwadia-Kalaba框架下设计了控制器。

Result: 设计的控制器成功考虑了区域约束，并通过仿真验证了其有效性。

Conclusion: 本文通过广义Udwadia-Kalaba框架设计了考虑区域约束的时变编队跟踪控制器，并通过数值仿真验证了其有效性。

Abstract: In this paper, the time-varying formation tracking control of wheeled mobile robots with region constraint is investigated from a generalized Udwadia-Kalaba framework. The communication topology is directed, weighted and has a spanning tree with the leader being the root. By reformulating the time-varying formation tracking control objective as a constrained equation and transforming the region constraint by a diffeomorphism, the time-varying formation tracking controller with the region constraint is designed under the generalized Udwadia-Kalaba framework. Compared with the existing works on time-varying formation tracking control, the region constraint is takeninto account in this paper, which ensures the safety of the robots.Finally, some numerical simulations are presented to illustrate the effectiveness of the proposed control strategy.

</details>


### [363] [Using Vision-Language Models as Proxies for Social Intelligence in Human-Robot Interaction](https://arxiv.org/abs/2512.07177)
*Fanjun Bu,Melina Tsai,Audrey Tjokro,Tapomayukh Bhattacharjee,Jorge Ortiz,Wendy Ju*

Main category: cs.RO

TL;DR: 通过分析非语言行为信号，提出两阶段流程，选择性触发VLM查询，实现社交响应式机器人行为。


<details>
  <summary>Details</summary>
Motivation: 研究人们在日常环境中如何通过非语言行为信号表示互动准备，以及专家如何利用这些线索引导互动，从而改进机器人的互动决策。

Method: 提出一个两阶段流程，其中轻量级感知检测器（如视线转移和空间关系）用于在社交意义时刻选择性触发基于视频的视觉语言模型（VLM）查询。

Result: 评估表明，选择性使用VLM作为社交推理代理能够实现社交响应式机器人行为。

Conclusion: 通过选择性使用视觉语言模型（VLM）作为社交推理的代理，能够实现社交响应式机器人行为，使机器人能够通过关注人们在现实互动中自然提供的线索来采取适当行动。

Abstract: Robots operating in everyday environments must often decide when and whether to engage with people, yet such decisions often hinge on subtle nonverbal cues that unfold over time and are difficult to model explicitly. Drawing on a five-day Wizard-of-Oz deployment of a mobile service robot in a university cafe, we analyze how people signal interaction readiness through nonverbal behaviors and how expert wizards use these cues to guide engagement. Motivated by these observations, we propose a two-stage pipeline in which lightweight perceptual detectors (gaze shifts and proxemics) are used to selectively trigger heavier video-based vision-language model (VLM) queries at socially meaningful moments. We evaluate this pipeline on replayed field interactions and compare two prompting strategies. Our findings suggest that selectively using VLMs as proxies for social reasoning enables socially responsive robot behavior, allowing robots to act appropriately by attending to the cues people naturally provide in real-world interactions.

</details>


### [364] [Spatiotemporal Calibration and Ground Truth Estimation for High-Precision SLAM Benchmarking in Extended Reality](https://arxiv.org/abs/2512.07221)
*Zichao Shu,Shitao Bei,Lijun Li,Zetao Chen*

Main category: cs.RO

TL;DR: 本文提出了一种结合IMU补偿MoCap抖动的新方法，通过精确时空校准提升SLAM基准测试精度，适用于XR应用。


<details>
  <summary>Details</summary>
Motivation: 随着XR沉浸标准的提高，SLAM基准测试的需求日益严格。然而，基于MoCap的GT精度受限于时空校准和固有抖动，影响了关键指标（如旋转误差和帧间抖动）的准确评估。

Method: 提出了一种连续时间最大似然估计器，集成辅助IMU数据补偿MoCap抖动，并引入可变时间同步方法和基于螺旋同余约束的位姿残差。

Result: 实验结果表明，该方法优于现有方法，能够满足XR应用中先进SLAM算法的全面基准测试需求。

Conclusion: 本文提出了一种新颖的连续时间最大似然估计器，结合辅助IMU数据补偿MoCap抖动，并通过可变时间同步方法和基于螺旋同余约束的位姿残差，实现了多传感器与DUT的精确时空校准。实验证明该方法优于现有方法，为XR应用中SLAM算法的全面基准测试提供了必要的精度。

Abstract: Simultaneous localization and mapping (SLAM) plays a fundamental role in extended reality (XR) applications. As the standards for immersion in XR continue to increase, the demands for SLAM benchmarking have become more stringent. Trajectory accuracy is the key metric, and marker-based optical motion capture (MoCap) systems are widely used to generate ground truth (GT) because of their drift-free and relatively accurate measurements. However, the precision of MoCap-based GT is limited by two factors: the spatiotemporal calibration with the device under test (DUT) and the inherent jitter in the MoCap measurements. These limitations hinder accurate SLAM benchmarking, particularly for key metrics like rotation error and inter-frame jitter, which are critical for immersive XR experiences. This paper presents a novel continuous-time maximum likelihood estimator to address these challenges. The proposed method integrates auxiliary inertial measurement unit (IMU) data to compensate for MoCap jitter. Additionally, a variable time synchronization method and a pose residual based on screw congruence constraints are proposed, enabling precise spatiotemporal calibration across multiple sensors and the DUT. Experimental results demonstrate that our approach outperforms existing methods, achieving the precision necessary for comprehensive benchmarking of state-of-the-art SLAM algorithms in XR applications. Furthermore, we thoroughly validate the practicality of our method by benchmarking several leading XR devices and open-source SLAM algorithms. The code is publicly available at https://github.com/ylab-xrpg/xr-hpgt.

</details>


### [365] [SINRL: Socially Integrated Navigation with Reinforcement Learning using Spiking Neural Networks](https://arxiv.org/abs/2512.07266)
*Florian Tretter,Daniel Flögel,Alexandru Vasilache,Max Grobbel,Jürgen Becker,Sören Hohmann*

Main category: cs.RO

TL;DR: 论文提出混合SNN-ANN的DRL方法，优化社交导航并显著降低能耗。


<details>
  <summary>Details</summary>
Motivation: 将自主移动机器人集成到人类环境中需要类人决策和高效的事件驱动计算，但目前神经形态方法在DRL导航中应用较少。

Method: 采用混合社会集成DRL演员-评论家方法，演员部分使用SNN，评论家部分使用ANN，并引入神经形态特征提取器捕捉人群动态和人机交互。

Result: 该方法提升了社交导航性能，并将能耗降低了约1.69个数量级。

Conclusion: 该论文提出了一种混合社会集成DRL方法，结合了SNN和ANN，显著提高了社交导航性能并大幅降低了能耗。

Abstract: Integrating autonomous mobile robots into human environments requires human-like decision-making and energy-efficient, event-based computation. Despite progress, neuromorphic methods are rarely applied to Deep Reinforcement Learning (DRL) navigation approaches due to unstable training. We address this gap with a hybrid socially integrated DRL actor-critic approach that combines Spiking Neural Networks (SNNs) in the actor with Artificial Neural Networks (ANNs) in the critic and a neuromorphic feature extractor to capture temporal crowd dynamics and human-robot interactions. Our approach enhances social navigation performance and reduces estimated energy consumption by approximately 1.69 orders of magnitude.

</details>


### [366] [Efficient Computation of a Continuous Topological Model of the Configuration Space of Tethered Mobile Robots](https://arxiv.org/abs/2512.07303)
*Gianpietro Battocletti,Dimitris Boskos,Bart De Schutter*

Main category: cs.RO

TL;DR: 论文提出了一种连续拓扑模型，用于系留机器人的高效路径规划，显著优于传统离散方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常依赖离散的配置空间表示，未能同时捕捉系留的拓扑信息和机器人的连续位置，因此需要一种更高效的连续模型。

Method: 通过建立系留机器人配置空间与工作空间通用覆盖空间之间的联系，开发了一种算法来计算配置空间的单纯复形模型。

Result: 所提出的模型构建时间大幅缩短，性能优于传统同伦增强图，且具有连续性。

Conclusion: 该论文提出了一种基于拓扑模型的连续路径规划方法，显著提升了传统离散表示方法的性能，适用于广泛的路径规划算法。

Abstract: Despite the attention that the problem of path planning for tethered robots has garnered in the past few decades, the approaches proposed to solve it typically rely on a discrete representation of the configuration space and do not exploit a model that can simultaneously capture the topological information of the tether and the continuous location of the robot. In this work, we explicitly build a topological model of the configuration space of a tethered robot starting from a polygonal representation of the workspace where the robot moves. To do so, we first establish a link between the configuration space of the tethered robot and the universal covering space of the workspace, and then we exploit this link to develop an algorithm to compute a simplicial complex model of the configuration space. We show how this approach improves the performances of existing algorithms that build other types of representations of the configuration space. The proposed model can be computed in a fraction of the time required to build traditional homotopy-augmented graphs, and is continuous, allowing to solve the path planning task for tethered robots using a broad set of path planning algorithms.

</details>


### [367] [Model Predictive Control for Cooperative Docking Between Autonomous Surface Vehicles with Disturbance Rejection](https://arxiv.org/abs/2512.07316)
*Gianpietro Battocletti,Dimitris Boskos,Bart De Schutter*

Main category: cs.RO

TL;DR: 提出一种USV协同对接方法，采用MPC处理扰动，仿真显示其高效性。


<details>
  <summary>Details</summary>
Motivation: 现有USV对接方法通常将一艘USV视为静止目标，另一艘负责对接，缺乏协同性。本文旨在解决这一问题。

Method: 采用集中式模型预测控制（MPC）方法，通过预测模型处理扰动（如水流），确保约束满足并生成可行轨迹。

Result: 仿真结果表明，所提方法在对接速度和效率上优于现有方法。

Conclusion: 本文提出了一种基于集中式模型预测控制（MPC）的USV-USV协同对接方法，相比现有方法能实现更快、更高效的对接。

Abstract: Uncrewed Surface Vehicles (USVs) are a popular and efficient type of marine craft that find application in a large number of water-based tasks. When multiple USVs operate in the same area, they may be required to dock to each other to perform a shared task. Existing approaches for the docking between autonomous USVs generally consider one USV as a stationary target, while the second one is tasked to reach the required docking pose. In this work, we propose a cooperative approach for USV-USV docking, where two USVs work together to dock at an agreed location. We use a centralized Model Predictive Control (MPC) approach to solve the control problem, obtaining feasible trajectories that also guarantee constraint satisfaction. Owing to its model-based nature, this approach allows the rejection of disturbances, inclusive of exogenous inputs, by anticipating their effect on the USVs through the MPC prediction model. This is particularly effective in case of almost-stationary disturbances such as water currents. In simulations, we demonstrate how the proposed approach allows for a faster and more efficient docking with respect to existing approaches.

</details>


### [368] [ESPADA: Execution Speedup via Semantics Aware Demonstration Data Downsampling for Imitation Learning](https://arxiv.org/abs/2512.07371)
*Byungju Kim,Jinu Pahk,Chungwoo Lee,Jaejoon Kim,Jangha Lee,Theo Taeyeong Kim,Kyuhwan Shim,Jun Ki Lee,Byoung-Tak Zhang*

Main category: cs.RO

TL;DR: ESPADA通过语义感知的演示分割和动态时间规整，实现了行为克隆策略的2倍加速，同时保持高成功率。


<details>
  <summary>Details</summary>
Motivation: 行为克隆策略虽然精确，但执行速度慢，限制了实际应用。现有加速方法依赖统计或启发式线索，忽略了任务语义，难以适应多样化场景。

Method: 利用VLM-LLM流水线结合3D夹爪-物体关系分割演示，并通过动态时间规整（DTW）传播标签，实现了对非关键段的激进下采样。

Result: 在仿真和真实实验中，ESPADA实现了约2倍的加速，同时保持了高成功率。

Conclusion: ESPADA框架通过语义和空间感知的方法，成功实现了行为克隆策略的加速，同时在保持高成功率的前提下显著提升了执行速度。

Abstract: Behavior-cloning based visuomotor policies enable precise manipulation but often inherit the slow, cautious tempo of human demonstrations, limiting practical deployment. However, prior studies on acceleration methods mainly rely on statistical or heuristic cues that ignore task semantics and can fail across diverse manipulation settings. We present ESPADA, a semantic and spatially aware framework that segments demonstrations using a VLM-LLM pipeline with 3D gripper-object relations, enabling aggressive downsampling only in non-critical segments while preserving precision-critical phases, without requiring extra data or architectural modifications, or any form of retraining. To scale from a single annotated episode to the full dataset, ESPADA propagates segment labels via Dynamic Time Warping (DTW) on dynamics-only features. Across both simulation and real-world experiments with ACT and DP baselines, ESPADA achieves approximately a 2x speed-up while maintaining success rates, narrowing the gap between human demonstrations and efficient robot control.

</details>


### [369] [Gait-Adaptive Perceptive Humanoid Locomotion with Real-Time Under-Base Terrain Reconstruction](https://arxiv.org/abs/2512.07464)
*Haolin Song,Hongbo Zhu,Tao Yu,Yan Liu,Mingqi Yuan,Wengang Zhou,Hua Chen,Houqiang Li*

Main category: cs.RO

TL;DR: 论文提出了一种结合地形感知、步态调节和全身控制的强化学习框架，实现了人形机器人在复杂地形上的稳健运动。


<details>
  <summary>Details</summary>
Motivation: 针对全尺寸人形机器人在复杂地形（如长楼梯）上运动时因感知有限、地形线索模糊和步态时序不适应导致的平衡问题，提出了一种整合感知与控制的解决方案。

Method: 通过安装在下方的深度摄像头实时生成密集的自我中心高度图，并结合本体感知信息，由统一策略生成关节命令和全局步态相位信号。采用单阶段连续师生训练方案进行高效策略学习和知识迁移。

Result: 在31自由度、1.65米高的人形机器人上进行的实验表明，该框架在仿真和现实环境中均实现了稳健的运动能力，包括前后上下楼梯和跨越46厘米的间隙。

Conclusion: 该论文提出的感知运动框架成功地将地形感知、步态调节和全身控制整合到一个强化学习策略中，实现了在复杂地形（如长楼梯）上的稳健运动。

Abstract: For full-size humanoid robots, even with recent advances in reinforcement learning-based control, achieving reliable locomotion on complex terrains, such as long staircases, remains challenging. In such settings, limited perception, ambiguous terrain cues, and insufficient adaptation of gait timing can cause even a single misplaced or mistimed step to result in rapid loss of balance. We introduce a perceptive locomotion framework that merges terrain sensing, gait regulation, and whole-body control into a single reinforcement learning policy. A downward-facing depth camera mounted under the base observes the support region around the feet, and a compact U-Net reconstructs a dense egocentric height map from each frame in real time, operating at the same frequency as the control loop. The perceptual height map, together with proprioceptive observations, is processed by a unified policy that produces joint commands and a global stepping-phase signal, allowing gait timing and whole-body posture to be adapted jointly to the commanded motion and local terrain geometry. We further adopt a single-stage successive teacher-student training scheme for efficient policy learning and knowledge transfer. Experiments conducted on a 31-DoF, 1.65 m humanoid robot demonstrate robust locomotion in both simulation and real-world settings, including forward and backward stair ascent and descent, as well as crossing a 46 cm gap. Project Page:https://ga-phl.github.io/

</details>


### [370] [Affordance Field Intervention: Enabling VLAs to Escape Memory Traps in Robotic Manipulation](https://arxiv.org/abs/2512.07472)
*Siyu Xu,Zijian Wang,Yunke Wang,Chenghao Xia,Tao Huang,Chang Xu*

Main category: cs.RO

TL;DR: AFI通过3D空间可达性场增强VLA模型，显著提升其在分布偏移下的适应能力。


<details>
  <summary>Details</summary>
Motivation: 解决VLA模型在分布偏移下因缺乏显式3D空间推理而陷入‘记忆陷阱’的问题。

Method: 提出Affordance Field Intervention (AFI)，一个轻量级混合框架，利用SAFs作为按需插件来引导VLA行为，包括检测记忆陷阱、重新定位机器人至高可达性区域，并提出可达性驱动的路径点。

Result: 在真实机器人平台上，AFI平均提升了23.5%的性能（不同VLA主干），在LIBERO-Pro基准上提升了20.2%。

Conclusion: AFI框架通过结合3D空间可达性场（SAFs）显著提升了VLA模型在分布偏移场景下的鲁棒性，实验验证了其有效性。

Abstract: Vision-Language-Action (VLA) models have shown great performance in robotic manipulation by mapping visual observations and language instructions directly to actions. However, they remain brittle under distribution shifts: when test scenarios change, VLAs often reproduce memorized trajectories instead of adapting to the updated scene, which is a failure mode we refer to as the "Memory Trap". This limitation stems from the end-to-end design, which lacks explicit 3D spatial reasoning and prevents reliable identification of actionable regions in unfamiliar environments. To compensate for this missing spatial understanding, 3D Spatial Affordance Fields (SAFs) can provide a geometric representation that highlights where interactions are physically feasible, offering explicit cues about regions the robot should approach or avoid. We therefore introduce Affordance Field Intervention (AFI), a lightweight hybrid framework that uses SAFs as an on-demand plug-in to guide VLA behavior. Our system detects memory traps through proprioception, repositions the robot to recent high-affordance regions, and proposes affordance-driven waypoints that anchor VLA-generated actions. A SAF-based scorer then selects trajectories with the highest cumulative affordance. Extensive experiments demonstrate that our method achieves an average improvement of 23.5% across different VLA backbones ($π_{0}$ and $π_{0.5}$) under out-of-distribution scenarios on real-world robotic platforms, and 20.2% on the LIBERO-Pro benchmark, validating its effectiveness in enhancing VLA robustness to distribution shifts.

</details>


### [371] [From Real-World Traffic Data to Relevant Critical Scenarios](https://arxiv.org/abs/2512.07482)
*Florian Lüttner,Nicole Neis,Daniel Stadler,Robin Moss,Mirjam Fehling-Kaschek,Matthias Pfriem,Alexander Stolz,Jens Ziehn*

Main category: cs.RO

TL;DR: 本文研究高速公路变道场景，通过数据分析和合成场景生成，提升自动驾驶功能验证效率。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶功能在复杂场景中的可靠运行至关重要，但识别所有相关场景具有挑战性，尤其是“未知不安全”场景。高速公路上的变道场景涉及多自由度，是研究安全相关场景的理想起点。

Method: 通过数据采集和处理真实高速公路交通数据，应用关键性度量评估场景，并基于记录场景生成合成场景。

Result: 通过分析高速公路变道场景，成功识别了安全相关驾驶场景，并提出了生成合成场景的方法。

Conclusion: 本文提出了一种处理链，能够识别安全相关场景，开发数据驱动方法提取这些场景，并通过采样生成合成关键场景，为高速公路上的自动驾驶功能验证提供了有效工具。

Abstract: The reliable operation of autonomous vehicles, automated driving functions, and advanced driver assistance systems across a wide range of relevant scenarios is critical for their development and deployment. Identifying a near-complete set of relevant driving scenarios for such functionalities is challenging due to numerous degrees of freedom involved, each affecting the outcomes of the driving scenario differently. Moreover, with increasing technical complexity of new functionalities, the number of potentially relevant, particularly "unknown unsafe" scenarios is increasing. To enhance validation efficiency, it is essential to identify relevant scenarios in advance, starting with simpler domains like highways before moving to more complex environments such as urban traffic. To address this, this paper focuses on analyzing lane change scenarios in highway traffic, which involve multiple degrees of freedom and present numerous safetyrelevant scenarios. We describe the process of data acquisition and processing of real-world data from public highway traffic, followed by the application of criticality measures on trajectory data to evaluate scenarios, as conducted within the AVEAS project (www.aveas.org). By linking the calculated measures to specific lane change driving scenarios and the conditions under which the data was collected, we facilitate the identification of safetyrelevant driving scenarios for various applications. Further, to tackle the extensive range of "unknown unsafe" scenarios, we propose a way to generate relevant scenarios by creating synthetic scenarios based on recorded ones. Consequently, we demonstrate and evaluate a processing chain that enables the identification of safety-relevant scenarios, the development of data-driven methods for extracting these scenarios, and the generation of synthetic critical scenarios via sampling on highways.

</details>


### [372] [See Once, Then Act: Vision-Language-Action Model with Task Learning from One-Shot Video Demonstrations](https://arxiv.org/abs/2512.07582)
*Guangyan Chen,Meiling Wang,Qi Shao,Zichen Zhou,Weixin Mao,Te Cui,Minzhao Zhu,Yinan Deng,Luojie Yang,Zhanqi Zhang,Yi Yang,Hua Chen,Yufeng Yue*

Main category: cs.RO

TL;DR: ViVLA 是一种通用机器人操作策略，通过单一专家演示视频高效学习新任务，显著提升未见任务和跨体现视频的性能。


<details>
  <summary>Details</summary>
Motivation: 受人类通过观察学习新技能的启发，开发一种能够从单一专家演示视频中学习新任务的通用机器人操作策略。

Method: ViVLA 联合处理专家演示视频和机器人视觉观察，预测演示动作序列和后续机器人动作，并通过可扩展的专家-代理对数据生成管道增强训练数据。

Result: ViVLA 在未见 LIBERO 任务上实现了超过 30% 的提升，在跨体现视频上保持了 35% 以上的增益，并在真实世界实验中通过人类视频学习实现了超过 38% 的提升。

Conclusion: ViVLA 是一种能够通过单一专家演示视频高效学习新任务的通用机器人操作策略，显著提升了在未见任务和跨体现视频上的性能。

Abstract: Developing robust and general-purpose manipulation policies represents a fundamental objective in robotics research. While Vision-Language-Action (VLA) models have demonstrated promising capabilities for end-to-end robot control, existing approaches still exhibit limited generalization to tasks beyond their training distributions. In contrast, humans possess remarkable proficiency in acquiring novel skills by simply observing others performing them once. Inspired by this capability, we propose ViVLA, a generalist robotic manipulation policy that achieves efficient task learning from a single expert demonstration video at test time. Our approach jointly processes an expert demonstration video alongside the robot's visual observations to predict both the demonstrated action sequences and subsequent robot actions, effectively distilling fine-grained manipulation knowledge from expert behavior and transferring it seamlessly to the agent. To enhance the performance of ViVLA, we develop a scalable expert-agent pair data generation pipeline capable of synthesizing paired trajectories from easily accessible human videos, further augmented by curated pairs from publicly available datasets. This pipeline produces a total of 892,911 expert-agent samples for training ViVLA. Experimental results demonstrate that our ViVLA is able to acquire novel manipulation skills from only a single expert demonstration video at test time. Our approach achieves over 30% improvement on unseen LIBERO tasks and maintains above 35% gains with cross-embodiment videos. Real-world experiments demonstrate effective learning from human videos, yielding more than 38% improvement on unseen tasks.

</details>


### [373] [Multi-Domain Motion Embedding: Expressive Real-Time Mimicry for Legged Robots](https://arxiv.org/abs/2512.07673)
*Matthias Heyrman,Chenhao Li,Victor Klemm,Dongho Kang,Stelian Coros,Marco Hutter*

Main category: cs.RO

TL;DR: MDME通过小波编码和概率嵌入统一运动特征表示，显著提升了机器人模仿的泛化能力和实时性。


<details>
  <summary>Details</summary>
Motivation: 现有运动控制器往往忽略运动中的固有模式，且之前的表示学习方法未能同时捕捉人类和动物运动中的周期性模式和随机变化。

Method: 提出了一种基于小波的编码器和概率嵌入并行的方法，统一了结构化和非结构化特征的嵌入。

Result: MDME在重建保真度和对未见运动的泛化能力上优于现有方法，并能通过零样本部署实时再现新运动风格。

Conclusion: MDME作为一种通用且结构感知的基础框架，为可扩展的实时机器人模仿提供了新的解决方案。

Abstract: Effective motion representation is crucial for enabling robots to imitate expressive behaviors in real time, yet existing motion controllers often ignore inherent patterns in motion. Previous efforts in representation learning do not attempt to jointly capture structured periodic patterns and irregular variations in human and animal movement. To address this, we present Multi-Domain Motion Embedding (MDME), a motion representation that unifies the embedding of structured and unstructured features using a wavelet-based encoder and a probabilistic embedding in parallel. This produces a rich representation of reference motions from a minimal input set, enabling improved generalization across diverse motion styles and morphologies. We evaluate MDME on retargeting-free real-time motion imitation by conditioning robot control policies on the learned embeddings, demonstrating accurate reproduction of complex trajectories on both humanoid and quadruped platforms. Our comparative studies confirm that MDME outperforms prior approaches in reconstruction fidelity and generalizability to unseen motions. Furthermore, we demonstrate that MDME can reproduce novel motion styles in real-time through zero-shot deployment, eliminating the need for task-specific tuning or online retargeting. These results position MDME as a generalizable and structure-aware foundation for scalable real-time robot imitation.

</details>


### [374] [AMBER: Aerial deployable gripping crawler with compliant microspine for canopy manipulation](https://arxiv.org/abs/2512.07680)
*P. A. Wigner,L. Romanello,A. Hammad,P. H. Nguyen,T. Lan,S. F. Armanini,B. B. Kocer,M. Kovac*

Main category: cs.RO

TL;DR: 一种空中部署的树冠爬行机器人，结合柔性轨道和旋转夹持器，实现了高效移动和操作，适用于生态采样和传感。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种能够在复杂树冠环境中高效移动和操作的机器人，以支持生态采样和树冠内传感。

Method: 系统结合了柔性微刺轨道、双轨道旋转夹持器和弹性尾部，实现了在不同曲率和倾斜度的树枝上的安全附着和稳定移动。

Result: 实验显示该系统能在高达90度的身体滚动和倾斜下可靠抓握，并在倾斜达67.5度的树枝上有效攀爬，水平树枝上的最高速度为每秒0.55体长。柔性轨道允许高达10度的偏航转向，增强了在不规则表面的机动性。

Conclusion: 该论文展示了一种空中可部署的爬行器，专为树冠内的自适应移动和操作设计，填补了空中与地面生态机器人之间的技术空白。

Abstract: This paper presents an aerially deployable crawler designed for adaptive locomotion and manipulation within tree canopies. The system combines compliant microspine-based tracks, a dual-track rotary gripper, and an elastic tail, enabling secure attachment and stable traversal across branches of varying curvature and inclination.
  Experiments demonstrate reliable gripping up to 90 degrees of body roll and inclination, while effective climbing on branches inclined up to 67.5 degrees, achieving a maximum speed of 0.55 body lengths per second on horizontal branches. The compliant tracks allow yaw steering of up to 10 degrees, enhancing maneuverability on irregular surfaces.
  Power measurements show efficient operation with a dimensionless cost of transport over an order of magnitude lower than typical hovering power consumption in aerial robots. Integrated within a drone-tether deployment system, the crawler provides a robust, low-power platform for environmental sampling and in-canopy sensing, bridging the gap between aerial and surface-based ecological robotics.

</details>


### [375] [Delay-Aware Diffusion Policy: Bridging the Observation-Execution Gap in Dynamic Tasks](https://arxiv.org/abs/2512.07697)
*Aileen Liao,Dong-Ki Kim,Max Olan Smith,Ali-akbar Agha-mohammadi,Shayegan Omidshafiei*

Main category: cs.RO

TL;DR: DA-DP是一种延迟感知策略学习框架，通过校正轨迹和延迟条件补偿推理延迟，在多种任务中表现优于无延迟感知方法。


<details>
  <summary>Details</summary>
Motivation: 机器人感知和动作选择之间存在数十到数百毫秒的推理延迟，导致观察状态与执行状态之间存在差异，需要一种方法来补偿这种延迟。

Method: 引入了Delay-Aware Diffusion Policy (DA-DP)框架，通过校正零延迟轨迹为延迟补偿轨迹，并在策略中增加延迟条件来实现延迟感知。

Result: DA-DP在多种任务、机器人和延迟条件下的成功率比无延迟感知方法更鲁棒，且具有架构无关性和迁移性。

Conclusion: DA-DP框架通过显式地将推理延迟纳入策略学习，提供了一种通用的延迟感知模仿学习模式，并在多种任务、机器人和延迟条件下表现出比无延迟感知方法更强的鲁棒性。

Abstract: As a robot senses and selects actions, the world keeps changing. This inference delay creates a gap of tens to hundreds of milliseconds between the observed state and the state at execution. In this work, we take the natural generalization from zero delay to measured delay during training and inference. We introduce Delay-Aware Diffusion Policy (DA-DP), a framework for explicitly incorporating inference delays into policy learning. DA-DP corrects zero-delay trajectories to their delay-compensated counterparts, and augments the policy with delay conditioning. We empirically validate DA-DP on a variety of tasks, robots, and delays and find its success rate more robust to delay than delay-unaware methods. DA-DP is architecture agnostic and transfers beyond diffusion policies, offering a general pattern for delay-aware imitation learning. More broadly, DA-DP encourages evaluation protocols that report performance as a function of measured latency, not just task difficulty.

</details>


### [376] [Toward Seamless Physical Human-Humanoid Interaction: Insights from Control, Intent, and Modeling with a Vision for What Comes Next](https://arxiv.org/abs/2512.07765)
*Gustavo A. Cardona,Shubham S. Kumbhar,Panagiotis Artemiadis*

Main category: cs.RO

TL;DR: 综述了物理人-人形交互的三大核心支柱，提出跨领域整合路径，为未来研究提供路线图。


<details>
  <summary>Details</summary>
Motivation: 探讨物理人-人形交互（pHHI）的现状，以促进机器人在非结构化、以人为中心环境中的部署。

Method: 通过三个核心支柱（人形建模与控制、人类意图估计、计算人类模型）综述代表性方法，分析当前局限，并提出跨领域整合的路径。

Result: 识别了开放挑战和当前局限，提出了跨支柱整合的方法路径，并引入了基于交互类型和机器人参与程度的统一分类法。

Conclusion: 本文提出了跨领域整合的方法路径，旨在推动稳健、安全和直观的物理交互，为人形系统在多样化现实场景中与人类伙伴有效理解、预测和协作提供了研究路线图。

Abstract: Physical Human-Humanoid Interaction (pHHI) is a rapidly advancing field with significant implications for deploying robots in unstructured, human-centric environments. In this review, we examine the current state of the art in pHHI through three core pillars: (i) humanoid modeling and control, (ii) human intent estimation, and (iii) computational human models. For each pillar, we survey representative approaches, identify open challenges, and analyze current limitations that hinder robust, scalable, and adaptive interaction. These include the need for whole-body control strategies capable of handling uncertain human dynamics, real-time intent inference under limited sensing, and modeling techniques that account for variability in human physical states. Although significant progress has been made within each domain, integration across pillars remains limited. We propose pathways for unifying methods across these areas to enable cohesive interaction frameworks. This structure enables us not only to map the current landscape but also to propose concrete directions for future research that aim to bridge these domains. Additionally, we introduce a unified taxonomy of interaction types based on modality, distinguishing between direct interactions (e.g., physical contact) and indirect interactions (e.g., object-mediated), and on the level of robot engagement, ranging from assistance to cooperation and collaboration. For each category in this taxonomy, we provide the three core pillars that highlight opportunities for cross-pillar unification. Our goal is to suggest avenues to advance robust, safe, and intuitive physical interaction, providing a roadmap for future research that will allow humanoid systems to effectively understand, anticipate, and collaborate with human partners in diverse real-world settings.

</details>


### [377] [OptMap: Geometric Map Distillation via Submodular Maximization](https://arxiv.org/abs/2512.07775)
*David Thorne,Nathan Chan,Christa S. Robison,Philip R. Osteen,Brett T. Lopez*

Main category: cs.RO

TL;DR: OptMap 是一种实时几何地图蒸馏算法，通过子模优化和动态流式处理，高效生成应用特定的地图，适用于自主机器人。


<details>
  <summary>Details</summary>
Motivation: 自主机器人需要多尺度的环境地图以支持感知和决策算法，但现有方法在计算效率和地图信息优化方面存在挑战。

Method: OptMap 利用子模函数最大化技术，结合动态重新排序的流式子模算法，优化地图信息的选取和处理。

Result: 实验证明 OptMap 在开源和自定义数据集上表现优异，尤其在长时间映射任务中计算需求极低。

Conclusion: OptMap 是一种高效的几何地图蒸馏算法，通过多项理论和算法创新实现了实时、应用特定的地图生成，适用于多种自主机器人任务。

Abstract: Autonomous robots rely on geometric maps to inform a diverse set of perception and decision-making algorithms. As autonomy requires reasoning and planning on multiple scales of the environment, each algorithm may require a different map for optimal performance. Light Detection And Ranging (LiDAR) sensors generate an abundance of geometric data to satisfy these diverse requirements, but selecting informative, size-constrained maps is computationally challenging as it requires solving an NP-hard combinatorial optimization. In this work we present OptMap: a geometric map distillation algorithm which achieves real-time, application-specific map generation via multiple theoretical and algorithmic innovations. A central feature is the maximization of set functions that exhibit diminishing returns, i.e., submodularity, using polynomial-time algorithms with provably near-optimal solutions. We formulate a novel submodular reward function which quantifies informativeness, reduces input set sizes, and minimizes bias in sequentially collected datasets. Further, we propose a dynamically reordered streaming submodular algorithm which improves empirical solution quality and addresses input order bias via an online approximation of the value of all scans. Testing was conducted on open-source and custom datasets with an emphasis on long-duration mapping sessions, highlighting OptMap's minimal computation requirements. Open-source ROS1 and ROS2 packages are available and can be used alongside any LiDAR SLAM algorithm.

</details>


### [378] [Inchworm-Inspired Soft Robot with Groove-Guided Locomotion](https://arxiv.org/abs/2512.07813)
*Hari Prakash Thanabalan,Lars Bengtsson,Ugo Lafont,Giovanni Volpe*

Main category: cs.RO

TL;DR: 论文提出了一种受尺蠖启发的软体机器人，通过基底上的沟槽模式被动控制运动方向，简化了设计并降低了能耗。


<details>
  <summary>Details</summary>
Motivation: 解决传统软体机器人需要多个致动器以实现方向控制的问题，从而减少机械复杂性、简化控制系统并降低能耗。

Method: 采用单卷电介质弹性体致动器，通过3D打印基底上的沟槽模式来引导机器人的对齐和轨迹。

Result: 通过系统实验证明，通过改变沟槽角度可以实现对运动方向的精确控制，无需复杂的致动策略。

Conclusion: 该论文提出了一种基于沟槽引导的被动控制方法，简化了软体机器人的设计和控制，降低了能耗，并扩展了其在搜索救援、管道检查和行星探索等领域的应用。

Abstract: Soft robots require directional control to navigate complex terrains. However, achieving such control often requires multiple actuators, which increases mechanical complexity, complicates control systems, and raises energy consumption. Here, we introduce an inchworm-inspired soft robot whose locomotion direction is controlled passively by patterned substrates. The robot employs a single rolled dielectric elastomer actuator, while groove patterns on a 3D-printed substrate guide its alignment and trajectory. Through systematic experiments, we demonstrate that varying groove angles enables precise control of locomotion direction without the need for complex actuation strategies. This groove-guided approach reduces energy consumption, simplifies robot design, and expands the applicability of bio-inspired soft robots in fields such as search and rescue, pipe inspection, and planetary exploration.

</details>


### [379] [Efficient and Compliant Control Framework for Versatile Human-Humanoid Collaborative Transportation](https://arxiv.org/abs/2512.07819)
*Shubham S. Kumbhar,Abhijeet M. Kulkarni,Panagiotis Artemiadis*

Main category: cs.RO

TL;DR: 提出了一种支持平移和旋转运动的人形机器人协作运输控制框架，包含规划、控制和刚度调节三层，实验验证了其有效性并量化了协作质量。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人在协作运输任务中需同时支持平移和旋转运动的需求，提升机器人与人类伙伴的协作效率和质量。

Method: 框架包含高层规划器（引入I-LIP模型结合导纳模型和MPC公式生成动态可行的步态计划）、低层控制器（基于QP的全身控制器处理耦合动力学）和刚度调节机制（确保机器人-物体交互收敛至目标相对配置）。

Result: 实验结果表明框架在Digit人形平台上有效实现了协作行为（如平移、转向和半圆形轨迹），并通过效率指标验证了合规性在协作中的重要性。

Conclusion: 该控制框架通过实验验证了其在人形机器人与人类伙伴协作运输任务中的有效性，展示了其在平移、旋转及组合运动中的表现，并通过效率指标量化了协作质量。

Abstract: We present a control framework that enables humanoid robots to perform collaborative transportation tasks with a human partner. The framework supports both translational and rotational motions, which are fundamental to co-transport scenarios. It comprises three components: a high-level planner, a low-level controller, and a stiffness modulation mechanism. At the planning level, we introduce the Interaction Linear Inverted Pendulum (I-LIP), which, combined with an admittance model and an MPC formulation, generates dynamically feasible footstep plans. These are executed by a QP-based whole-body controller that accounts for the coupled humanoid-object dynamics. Stiffness modulation regulates robot-object interaction, ensuring convergence to the desired relative configuration defined by the distance between the object and the robot's center of mass. We validate the effectiveness of the framework through real-world experiments conducted on the Digit humanoid platform. To quantify collaboration quality, we propose an efficiency metric that captures both task performance and inter-agent coordination. We show that this metric highlights the role of compliance in collaborative tasks and offers insights into desirable trajectory characteristics across both high- and low-level control layers. Finally, we showcase experimental results on collaborative behaviors, including translation, turning, and combined motions such as semi circular trajectories, representative of naturally occurring co-transportation tasks.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [380] [A Broader View on Clustering under Cluster-Aware Norm Objectives](https://arxiv.org/abs/2512.06211)
*Martin G. Herold,Evangelos Kipouridis,Joachim Spoerhase*

Main category: cs.DS

TL;DR: 本文改进了$(f,g)$-聚类问题的近似算法，填补了先前研究的空白，并提供了更清晰的近似性分析。


<details>
  <summary>Details</summary>
Motivation: 解决先前研究中$(f,g)$-聚类问题近似性分析存在的较大差距。

Method: 设计了$O(\log^2 n)$-近似算法和$O(k)$-近似算法，并引入新参数$f$和$g$来设计插值算法。

Result: 改进的近似算法显著提升了性能，填补了基本问题与其推广之间的近似性差距。

Conclusion: 本文改进了$(f,g)$-聚类问题的近似算法，提供了更清晰的近似性分析，填补了先前研究的空白。

Abstract: We revisit the $(f,g)$-clustering problem that we introduced in a recent work [SODA'25], and which subsumes fundamental clustering problems such as $k$-Center, $k$-Median, Min-Sum of Radii, and Min-Load $k$-Clustering. This problem assigns each of the $k$ clusters a cost determined by the monotone, symmetric norm $f$ applied to the vector distances in the cluster, and aims at minimizing the norm $g$ applied to the vector of cluster costs. Previously, we focused on certain special cases for which we designed constant-factor approximation algorithms. Our bounds for more general settings left, however, large gaps to the known bounds for the basic problems they capture.
  In this work, we provide a clearer picture of the approximability of these more general settings. First, we design an $O(\log^2 n)$-approximation algorithm for $(f, L_{1})$-clustering for any $f$. This improves upon our previous $\widetilde{O}(\sqrt{n})$-approximation. Second, we provide an $O(k)$-approximation for the general $(f,g)$-clustering problem, which improves upon our previous $\widetilde{O}(\sqrt{kn})$-approximation algorithm and matches the best-known upper bound for Min-Load $k$-Clustering.
  We then design an approximation algorithm for $(f,g)$-clustering that interpolates, up to polylog factors, between the best known bounds for $k$-Center, $k$-Median, Min-Sum of Radii, Min-Load $k$-Clustering, (Top, $L_{1}$)-clustering, and $(L_{\infty},g)$-clustering based on a newly defined parameter of $f$ and $g$.

</details>


### [381] [Finding a Maximum Common (Induced) Subgraph: Structural Parameters Revisited](https://arxiv.org/abs/2512.06383)
*Tesshu Hanaka,Yuto Okada,Yota Otachi,Lena Volk*

Main category: cs.DS

TL;DR: 本文研究了最大公共（诱导）子图问题的参数化复杂性，展示了在特定结构参数下的固定参数可处理案例，并揭示了诱导与非诱导情况的复杂性差异。


<details>
  <summary>Details</summary>
Motivation: 由于这些问题推广了几个NP完全问题，即使在强限制的结构参数下也是难解的，因此需要补充其难解性的固定参数可处理案例。

Method: 研究了在最大叶子数和邻域多样性参数化下的诱导和非诱导问题，以及在双胞胎覆盖数参数化下的诱导问题。

Result: 展示了在最大叶子数和邻域多样性参数化下的固定参数可处理性，以及在双胞胎覆盖数参数化下诱导问题的固定参数可处理性。

Conclusion: 本文几乎完全确定了这些问题在广泛研究的结构参数下的复杂性，并提供了一个罕见例子，其中诱导和非诱导情况的复杂性不同。

Abstract: We study the parameterized complexity of the problems of finding a maximum common (induced) subgraph of two given graphs. Since these problems generalize several NP-complete problems, they are intractable even when parameterized by strongly restricted structural parameters. Our contribution in this paper is to sharply complement the hardness of the problems by showing fixed-parameter tractable cases: both induced and non-induced problems parameterized by max-leaf number and by neighborhood diversity, and the induced problem parameterized by twin cover number. These results almost completely determine the complexity of the problems with respect to well-studied structural parameters. Also, the result on the twin cover number presents a rather rare example where the induced and non-induced cases have different complexity.

</details>


### [382] [Instance Dependent Testing of Samplers using Interval Conditioning](https://arxiv.org/abs/2512.06458)
*Rishiraj Bhattacharyya,Sourav Chakraborty,Yash Pote,Uddalok Sarkar,Sayantan Sen*

Main category: cs.DS

TL;DR: 首个实例依赖效率的无限域采样器测试器，通过创新算法实现1000倍速度提升。


<details>
  <summary>Details</summary>
Motivation: 现有采样器测试工具仅关注最坏情况效率，无法验证无限域采样器，而这类问题在天文学、金融、网络安全等领域频繁出现。

Method: 采用区间条件框架和新型距离估计算法，将概率质量估计与连续分布联系起来。

Result: 实验证明，新测试器比现有技术快1000倍，并能有效验证自然数域采样器。

Conclusion: 本研究设计了一种针对无限域采样器的首个实例依赖效率测试器，通过创新的距离估计算法和区间条件框架，显著提升了测试效率，实验显示比现有技术快1000倍。

Abstract: Sampling algorithms play a pivotal role in probabilistic AI. However, verifying if a sampler program indeed samples from the claimed distribution is a notoriously hard problem. Provably correct testers like Barbarik, Teq, Flash, CubeProbe for testing of different kinds of samplers were proposed only in the last few years. All these testers focus on the worst-case efficiency, and do not support verification of samplers over infinite domains, a case occurring frequently in Astronomy, Finance, Network Security, etc.
  In this work, we design the first tester of samplers with instance-dependent efficiency, allowing us to test samplers over natural numbers. Our tests are developed via a novel distance estimation algorithm between an unknown and a known probability distribution using an interval conditioning framework. The core technical contribution is a new connection with probability mass estimation of a continuous distribution. The practical gains are also substantial: our experiments establish up to 1000x speedup over state-of-the-art testers.

</details>


### [383] [The $k$-Fold Matroid Secretary Problem](https://arxiv.org/abs/2512.06611)
*Rishi Gujjar,Kevin Hua,Robert Kleinberg,Frederick V. Qiu*

Main category: cs.DS

TL;DR: 扩展Kleinberg'05的拟阵秘书问题算法，提出适用于k-fold拟阵并的(1-O(√log(n)/k))-竞争算法。


<details>
  <summary>Details</summary>
Motivation: 扩展Kleinberg'05的(1-O(1/√k))-竞争算法，适用于更一般的k-fold拟阵并情况。

Method: 通过随机顺序到达的拟阵元素，动态决策接受或拒绝元素，确保接受的集合满足拟阵约束。

Result: 成功设计并证明了(1-O(√log(n)/k))-竞争算法。

Conclusion: 本文提出了一种针对k-fold拟阵并的(1-O(√log(n)/k))-竞争算法，扩展了Kleinberg'05的成果。

Abstract: In the matroid secretary problem, elements $N := [n]$ of a matroid $\mathcal{M} \subseteq 2^N$ arrive in random order. When an element arrives, its weight is revealed and a choice must be made to accept or reject the element, subject to the constraint that the accepted set $S \in \mathcal{M}$. Kleinberg'05 gives a $(1-O(1/\sqrt{k}))$-competitive algorithm when $\mathcal{M}$ is a $k$-uniform matroid. We generalize their result, giving a $(1-O(\sqrt{\log(n)/k}))$-competitive algorithm when $\mathcal{M}$ is a $k$-fold matroid union.

</details>


### [384] [Near-Optimal Bayesian Online Assortment of Reusable Resources](https://arxiv.org/abs/2512.06997)
*Yiding Feng,Rad Niazadeh,Amin Saberi*

Main category: cs.DS

TL;DR: 针对可重用资源的在线分配问题，论文提出了一种基于LP和随机舍入的算法，实现了接近最优的竞争比，并通过数值模拟验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 电子商务中租赁服务的应用需求，推动了对可重用资源在线分配收入最大化问题的研究。

Method: 设计基于预期LP基准的在线算法，结合独立随机舍入和丢弃策略，确保库存可行性。引入后处理分配程序以处理资源间的相互影响。

Result: 在初始库存较大的情况下，算法实现了接近最优的竞争比（1−min(1/2,√log(c₀)/c₀)）。对于非可重用资源，竞争比进一步提升至1−1/√(c₀+3)。

Conclusion: 论文提出了一种针对可重用资源的在线分配算法，通过预期LP基准和独立随机舍入实现接近最优的竞争比。同时，针对非可重用资源的特殊情况，展示了改进的竞争比算法。数值模拟验证了算法的性能。

Abstract: Motivated by the applications of rental services in e-commerce, we consider revenue maximization in online assortment of reusable resources for a stream of arriving consumers with different types. We design competitive online algorithms with respect to the optimum online policy in the Bayesian setting, in which types are drawn independently from known heterogeneous distributions over time. In the regime where the minimum of initial inventories $c_0$ is large, our main result is a near-optimal $1-\min\left(\frac{1}{2},\sqrt{\log(c_0)/c_0}\right)$ competitive algorithm for the general case of reusable resources. Our algorithm relies on an expected LP benchmark for the problem, solves this LP, and simulates the solution through an independent randomized rounding. The main challenge is obtaining point-wise inventory feasibility in a computationally efficient fashion from these simulation-based algorithms. To this end, we use several technical ingredients to design $\textit{discarding policies}$ -- one for each resource. These policies handle the trade-off between the inventory feasibility under reusability and the revenue loss of each of the resources. However, discarding a unit of a resource changes the future consumption of other resources. To handle this new challenge, we also introduce $\textit{post-processing}$ assortment procedures that help with designing and analyzing our discarding policies as they run in parallel, which might be of independent interest. As a side result, by leveraging techniques from the literature on prophet inequality, we further show an improved near-optimal $1-1/\sqrt{c_0+3}$ competitive algorithm for the special case of non-reusable resources. We finally evaluate the performance of our algorithms using the numerical simulations on the synthetic data.

</details>


### [385] [Chromatic Feature Vectors for 2-Trees: Exact Formulas for Partition Enumeration with Network Applications](https://arxiv.org/abs/2512.07120)
*J. Allagan,G. Morgan,S. Langley,R. Lopez-Bonilla,V. Deriglazov*

Main category: cs.DS

TL;DR: 本文提出了一种在双色三角形约束下对2-树色特征向量进行高效枚举的方法，适用于分布式系统中的结构分析，并给出了theta图和fan图的具体公式及计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于分布式系统中组件避免完全集中或隔离的需求，双色约束提供了比经典色多项式更具信息量的结构特征。

Method: 通过约束图着色方法，其中每个三角形使用恰好两种颜色，禁止单色和彩虹三角形，从而高效计算结构特征。对于theta图和fan图，分别给出了具体的枚举公式和计算复杂度。

Result: 对于theta图Theta_n，证明了r_k(Theta_n) = S(n-2, k-1)（k >= 3）和r_2(Theta_n) = 2^(n-2) + 1，计算复杂度为O(n)。对于fan图Phi_n，建立了r_2(Phi_n) = F_{n+1}（斐波那契数列），并推导出r_k(Phi_n)的显式公式，计算复杂度为O(n^2)。

Conclusion: 本文提出了在双色三角形约束下对2-树的色特征向量进行封闭式枚举的方法，并证明了这些方法在分布式系统中的实际应用价值。

Abstract: We establish closed-form enumeration formulas for chromatic feature vectors of 2-trees under the bichromatic triangle constraint. These efficiently computable structural features derive from constrained graph colorings where each triangle uses exactly two colors, forbidding monochromatic and rainbow triangles, a constraint arising in distributed systems where components avoid complete concentration or isolation. For theta graphs Theta_n, we prove r_k(Theta_n) = S(n-2, k-1) for k >= 3 (Stirling numbers of the second kind) and r_2(Theta_n) = 2^(n-2) + 1, computable in O(n) time. For fan graphs Phi_n, we establish r_2(Phi_n) = F_{n+1} (Fibonacci numbers) and derive explicit formulas r_k(Phi_n) = sum_{t=k-1}^{n-1} a_{n-1,t} * S(t, k-1) with efficiently computable binomial coefficients, achieving O(n^2) computation per component. Unlike classical chromatic polynomials, which assign identical features to all n-vertex 2-trees, bichromatic constraints provide informative structural features. While not complete graph invariants, these features capture meaningful structural properties through connections to Fibonacci polynomials, Bell numbers, and independent set enumeration. Applications include Byzantine fault tolerance in hierarchical networks, VM allocation in cloud computing, and secret-sharing protocols in distributed cryptography.

</details>


### [386] [Property Testing of Computational Networks](https://arxiv.org/abs/2512.07577)
*Artur Czumaj,Christian Sohler*

Main category: cs.DS

TL;DR: 论文提出加权计算网络的属性测试框架，验证了ReLU神经布尔网络中近常数函数的可测试性，并指出某些模型下的局限性。


<details>
  <summary>Details</summary>
Motivation: 研究加权计算网络作为计算设备的属性测试，旨在设计算法以验证网络是否计算特定函数或具有特定属性。

Method: 设计了属性测试算法，通过访问网络权重，接受计算特定函数的网络，拒绝远离目标函数的网络。参数化了距离概念，定义了$(ε,δ)$-far的标准。

Result: 在ReLU激活函数的简单神经布尔网络中，证明了近常数函数可测试且查询复杂度与网络大小无关；但在分布自由模型和普通测试模型中类似结果不可实现。

Conclusion: 论文提出了加权计算网络的属性测试框架，并通过案例研究验证了其可行性，同时指出了在特定模型下类似结果的不可实现性。

Abstract: In this paper we initiate the study of \emph{property testing of weighted computational networks viewed as computational devices}. Our goal is to design property testing algorithms that for a given computational network with oracle access to the weights of the network, accept (with probability at least $\frac23$) any network that computes a certain function (or a function with a certain property) and reject (with probability at least $\frac23$) any network that is \emph{far} from computing the function (or any function with the given property). We parameterize the notion of being far and want to reject networks that are \emph{$(ε,δ)$-far}, which means that one needs to change an $ε$-fraction of the description of the network to obtain a network that computes a function that differs in at most a $δ$-fraction of inputs from the desired function (or any function with a given property).
  To exemplify our framework, we present a case study involving simple neural Boolean networks with ReLU activation function. As a highlight, we demonstrate that for such networks, any near constant function is testable in query complexity independent of the network's size. We also show that a similar result cannot be achieved in a natural generalization of the distribution-free model to our setting, and also in a related vanilla testing model.

</details>


### [387] [Approximation Algorithms for the $b$-Matching and List-Restricted Variants of MaxQAP](https://arxiv.org/abs/2512.07618)
*Jiratchaphat Nanta,Vorapong Suppakitpaisarn,Piyashat Sripratak*

Main category: cs.DS

TL;DR: 本文针对MaxQAP的两个变体问题提出了近似算法，填补了研究空白。


<details>
  <summary>Details</summary>
Motivation: 研究Maximum Quadratic Assignment Problem的两个自然扩展变体，解决现有算法无法直接应用的问题。

Method: 基于线性规划松弛和随机舍入框架，结合最大权重$b$-匹配问题的多项式时间算法。

Result: 针对节点列表大小为$n - O(\sqrt{n})$的实例，设计了随机$O(\sqrt{n})$-近似算法；针对$b$-匹配问题，提出了$O(\sqrt{bn})$-近似算法。

Conclusion: 本文提出了针对Maximum List-Restricted Quadratic Assignment Problem和Maximum Quadratic $b$-Matching Assignment Problem的近似算法，填补了这两个变体问题的研究空白。

Abstract: We study approximation algorithms for two natural generalizations of the Maximum Quadratic Assignment Problem (MaxQAP). In the Maximum List-Restricted Quadratic Assignment Problem, each node in one partite set may only be matched to nodes from a prescribed list. For instances on $n$ nodes where every list has size at least $n - O(\sqrt{n})$, we design a randomized $O(\sqrt{n})$-approximation algorithm based on the linear-programming relaxation and randomized rounding framework of Makarychev, Manokaran, and Sviridenko. In the Maximum Quadratic $b$-Matching Assignment Problem, we seek a $b$-matching that maximizes the MaxQAP objective. We refine the standard MaxQAP relaxation and combine randomized rounding over $b$ independent iterations with a polynomial-time algorithm for maximum-weight $b$-matching problem to obtain an $O(\sqrt{bn})$-approximation. When $b$ is constant and all lists have size $n - O(\sqrt{n})$, our guarantees asymptotically match the best known approximation factor for MaxQAP, yielding the first approximation algorithms for these two variants.

</details>
