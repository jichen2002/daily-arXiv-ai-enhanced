<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 204]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.AI](#cs.AI) [Total: 55]
- [cs.SE](#cs.SE) [Total: 30]
- [cs.DS](#cs.DS) [Total: 7]
- [cs.DC](#cs.DC) [Total: 17]
- [cs.NI](#cs.NI) [Total: 8]
- [cs.OS](#cs.OS) [Total: 1]
- [cs.RO](#cs.RO) [Total: 62]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Explainable Adversarial-Robust Vision-Language-Action Model for Robotic Manipulation](https://arxiv.org/abs/2512.11865)
*Ju-Young Kim,Ji-Hong Park,Myeongjun Kim,Gun-Woo Kim*

Main category: cs.CV

TL;DR: 提出一种可解释的对抗鲁棒视觉-语言-动作模型，显著降低动作预测误差并提升可解释性。


<details>
  <summary>Details</summary>
Motivation: 智能农业系统中依赖RGB摄像头和机械臂的感知控制系统易受光度扰动（如色调、光照和噪声变化）的影响，导致在对抗攻击下失效。

Method: 模型集成了Evidence-3模块，用于检测光度扰动并生成自然语言解释其成因和影响。

Result: 实验表明，与基线相比，该模型将当前动作L1损失降低了21.7%，下一动作L1损失降低了18.4%。

Conclusion: 提出的基于OpenVLA-OFT框架的可解释对抗鲁棒视觉-语言-动作模型，有效提升了智能农业系统在对抗条件下的动作预测准确性和可解释性。

Abstract: Smart farming has emerged as a key technology for advancing modern agriculture through automation and intelligent control. However, systems relying on RGB cameras for perception and robotic manipulators for control, common in smart farming, are vulnerable to photometric perturbations such as hue, illumination, and noise changes, which can cause malfunction under adversarial attacks. To address this issue, we propose an explainable adversarial-robust Vision-Language-Action model based on the OpenVLA-OFT framework. The model integrates an Evidence-3 module that detects photometric perturbations and generates natural language explanations of their causes and effects. Experiments show that the proposed model reduces Current Action L1 loss by 21.7% and Next Actions L1 loss by 18.4% compared to the baseline, demonstrating improved action prediction accuracy and explainability under adversarial conditions.

</details>


### [2] [Temporal-Anchor3DLane: Enhanced 3D Lane Detection with Multi-Task Losses and LSTM Fusion](https://arxiv.org/abs/2512.11869)
*D. Shainu Suhas,G. Rahul,K. Muni*

Main category: cs.CV

TL;DR: Temporal-Anchor3DLane通过损失函数和时间融合改进，显著提升3D车道检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决Anchor3DLane在回归异常值敏感性、全局曲线几何弱监督、多损失项平衡困难及时间连续性利用不足等问题。

Method: 提出了Temporal-Anchor3DLane框架，包括多任务损失改进（Balanced L1回归、Chamfer点集距离、不确定性加权损失）、轻量级Temporal LSTM Fusion模块和ESCOP式训练优化。

Result: 在OpenLane数据集上，F1分数提升+6.2，时间轨迹更平滑。

Conclusion: Temporal-Anchor3DLane通过改进损失函数和引入轻量级时间融合模块，显著提升了3D车道检测的鲁棒性和时间连续性，无需额外传感器或扩展。

Abstract: Monocular 3D lane detection remains challenging due to depth ambiguity, occlusion, and temporal instability across frames. Anchor-based approaches such as Anchor3DLane have demonstrated strong performance by regressing continuous 3D lane curves from multi-camera surround views. However, the baseline model still exhibits (i) sensitivity to regression outliers, (ii) weak supervision of global curve geometry, (iii) difficulty in balancing multiple loss terms, and (iv) limited exploitation of temporal continuity. We propose Temporal-Anchor3DLane, an enhanced 3D lane detection framework that extends Anchor3DLane with three key contributions: (1) a set of multi-task loss improvements, including Balanced L1 regression, Chamfer point-set distance, and uncertainty-based loss weighting, together with focal and Dice components for classification and visibility; (2) a lightweight Temporal LSTM Fusion module that aggregates per-anchor features across frames, replacing a heavier Transformer-style temporal fusion; and (3) ESCOP-style training refinements that couple curve-level supervision with temporal consistency. On OpenLane, Temporal-Anchor3DLane improves F1 by +6.2 and yields smoother temporal trajectories, showing that small architectural and loss refinements significantly enhance 3D lane robustness without extra sensors or scaling.

</details>


### [3] [Automated Plant Disease and Pest Detection System Using Hybrid Lightweight CNN-MobileViT Models for Diagnosis of Indigenous Crops](https://arxiv.org/abs/2512.11871)
*Tekleab G. Gebremedhin,Hailom S. Asegede,Bruh W. Tesheme,Tadesse B. Gebremichael,Kalayu G. Redae*

Main category: cs.CV

TL;DR: 研究开发了针对埃塞俄比亚提格雷地区仙人掌无花果病害的离线检测系统，测试三种移动高效模型，MobileViT-XS表现最佳，系统已部署于本地化应用中。


<details>
  <summary>Details</summary>
Motivation: 提格雷地区农业人口占比高，但基础设施限制导致作物病害诊断专家资源不足，因此需要开发离线优先的本地化检测系统。

Method: 研究采用了三种移动高效的架构：自定义轻量级CNN、EfficientNet-Lite1和CNN-Transformer混合模型MobileViT-XS，并在新整理的3,587张田间图像数据集上进行了基准测试。

Result: EfficientNet-Lite1达到90.7%测试准确率，轻量级CNN在部署效率上最优（42毫秒推理延迟，4.8 MB模型大小），MobileViT-XS则以97.3%的平均交叉验证准确率表现最佳，展示了全局推理的优势。

Conclusion: 该研究开发了一个离线优先的作物病害检测系统，特别针对埃塞俄比亚提格雷地区的本土仙人掌无花果，展示了在资源有限环境下高效移动架构的实用性，并通过本地化应用增强了食品安全诊断的包容性。

Abstract: Agriculture supports over 80% of the population in the Tigray region of Ethiopia, where infrastructural disruptions limit access to expert crop disease diagnosis. We present an offline-first detection system centered on a newly curated indigenous cactus-fig (Opuntia ficus-indica) dataset consisting of 3,587 field images across three core symptom classes. Given deployment constraints in post-conflict edge environments, we benchmark three mobile-efficient architectures: a custom lightweight CNN, EfficientNet-Lite1, and the CNN-Transformer hybrid MobileViT-XS. While the broader system contains independent modules for potato, apple, and corn, this study isolates cactus-fig model performance to evaluate attention sensitivity and inductive bias transfer on indigenous morphology alone. Results establish a clear Pareto trade-off: EfficientNet-Lite1 achieves 90.7% test accuracy, the lightweight CNN reaches 89.5% with the most favorable deployment profile (42 ms inference latency, 4.8 MB model size), and MobileViT-XS delivers 97.3% mean cross-validation accuracy, demonstrating that MHSA-based global reasoning disambiguates pest clusters from two dimensional fungal lesions more reliably than local texture CNN kernels. The ARM compatible models are deployed in a Tigrigna and Amharic localized Flutter application supporting fully offline inference on Cortex-A53 class devices, strengthening inclusivity for food security critical diagnostics.

</details>


### [4] [Pseudo-Label Refinement for Robust Wheat Head Segmentation via Two-Stage Hybrid Training](https://arxiv.org/abs/2512.11874)
*Jiahao Jiang,Zhangrui Yang,Xuanhan Wang,Jingkuan Song*

Main category: cs.CV

TL;DR: 开发了一个结合两阶段混合训练策略和广泛数据增强的自训练框架，采用SegFormer和MiT-B4骨干，通过师生循环迭代提升模型性能，在竞赛中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决全球小麦全语义分割竞赛中的挑战。

Method: 我们开发了一个系统的自训练框架，结合了两阶段混合训练策略和广泛的数据增强。核心模型是带有Mix Transformer（MiT-B4）骨干的SegFormer，并采用了迭代的师生循环。

Result: 在开发阶段和测试阶段数据集上取得了竞争性性能。

Conclusion: 我们的方法在开发阶段和测试阶段数据集上均表现出竞争力。

Abstract: This extended abstract details our solution for the Global Wheat Full Semantic Segmentation Competition. We developed a systematic self-training framework. This framework combines a two-stage hybrid training strategy with extensive data augmentation. Our core model is SegFormer with a Mix Transformer (MiT-B4) backbone. We employ an iterative teacher-student loop. This loop progressively refines model accuracy. It also maximizes data utilization. Our method achieved competitive performance. This was evident on both the Development and Testing Phase datasets.

</details>


### [5] [Generalization vs. Specialization: Evaluating Segment Anything Model (SAM3) Zero-Shot Segmentation Against Fine-Tuned YOLO Detectors](https://arxiv.org/abs/2512.11884)
*Ranjan Sapkota,Konstantinos I. Roumeliotis,Manoj Karkee,Nikolaos D. Tselikas*

Main category: cs.CV

TL;DR: SAM3在边界稳定性上优于YOLO11，但YOLO在检测完整性上更佳。研究提供了开源工具和方法建议。


<details>
  <summary>Details</summary>
Motivation: 比较专用微调模型和通用基础模型在实例分割任务中的性能差异，特别是在高密度和遮挡场景下的表现。

Method: 在MinneApple数据集上比较了SAM3（零样本模式）和三种YOLO11变体（nano、medium、large）的实例分割性能，分析了不同IoU阈值下的表现。

Result: YOLO模型在IoU=0.15时F1得分为68.9%、72.2%和71.9%，SAM3为59.8%。SAM3边界稳定性比YOLO高12倍。

Conclusion: SAM3在边界稳定性上表现优异，而YOLO11在检测完整性上更为专业。研究提供了开源代码和评估流程，帮助理解在密集实例分割任务中何时选择专用微调模型或通用基础模型更为合适。

Abstract: Deep learning has advanced two fundamentally different paradigms for instance segmentation: specialized models optimized through task-specific fine-tuning and generalist foundation models capable of zero-shot segmentation. This work presents a comprehensive comparison between SAM3 (Segment Anything Model, also called SAMv3) operating in zero-shot mode and three variants of Ultralytics YOLO11 (nano, medium, and large) fine-tuned for instance segmentation. The evaluation is conducted on the MinneApple dataset, a dense benchmark comprising 670 orchard images with 28,179 annotated apple instances, enabling rigorous validation of model behavior under high object density and occlusion. Our analysis shows IoU choices can inflate performance gaps by up to 30%. At the appropriate IoU = 0.15 threshold, YOLO models achieve 68.9%, 72.2%, and 71.9% F1, while SAM3 reaches 59.8% in pure zero-shot mode. However, YOLO exhibits steep degradation 48-50 points across IoU ranges whereas SAM3 drops only 4 points, revealing 12 times superior boundary stability of SAM3. This highlights the strength of SAMv3 in mask precision versus specialization in detection completeness of YOLO11. We provide open-source code, evaluation pipelines, and methodological recommendations, contributing to a deeper understanding of when specialized fine-tuned models or generalist foundation models are preferable for dense instance segmentation tasks. This project repository is available on GitHub as https://github.com/Applied-AI-Research-Lab/Segment-Anything-Model-SAM3-Zero-Shot-Segmentation-Against-Fine-Tuned-YOLO-Detectors

</details>


### [6] [MRD: Using Physically Based Differentiable Rendering to Probe Vision Models for 3D Scene Understanding](https://arxiv.org/abs/2512.12307)
*Benjamin Beilharz,Thomas S. A. Wallis*

Main category: cs.CV

TL;DR: MRD利用可微分渲染技术，通过物理场景参数分析视觉模型的隐式3D理解，为模型解释提供新视角。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在视觉任务中表现优异，但其内部表示和决策机制仍难以解释。MRD旨在通过物理场景描述来评估模型对生成性3D场景属性的理解。

Method: 使用基于物理的可微分渲染技术（MRD），寻找在物理上不同但产生相同模型激活的3D场景参数（即模型元音）。

Result: 实验证明，MRD能有效评估模型对几何形状和材料属性的敏感性，目标场景与优化场景在模型激活上高度相似，但视觉结果多样。

Conclusion: MRD方法通过可微分渲染技术，为理解和分析视觉模型对3D场景属性的隐式理解提供了新途径，有助于推动计算机和人类视觉的研究。

Abstract: While deep learning methods have achieved impressive success in many vision benchmarks, it remains difficult to understand and explain the representations and decisions of these models. Though vision models are typically trained on 2D inputs, they are often assumed to develop an implicit representation of the underlying 3D scene (for example, showing tolerance to partial occlusion, or the ability to reason about relative depth). Here, we introduce MRD (metamers rendered differentiably), an approach that uses physically based differentiable rendering to probe vision models' implicit understanding of generative 3D scene properties, by finding 3D scene parameters that are physically different but produce the same model activation (i.e. are model metamers). Unlike previous pixel-based methods for evaluating model representations, these reconstruction results are always grounded in physical scene descriptions. This means we can, for example, probe a model's sensitivity to object shape while holding material and lighting constant. As a proof-of-principle, we assess multiple models in their ability to recover scene parameters of geometry (shape) and bidirectional reflectance distribution function (material). The results show high similarity in model activation between target and optimized scenes, with varying visual results. Qualitatively, these reconstructions help investigate the physical scene attributes to which models are sensitive or invariant. MRD holds promise for advancing our understanding of both computer and human vision by enabling analysis of how physical scene parameters drive changes in model responses.

</details>


### [7] [mmWEAVER: Environment-Specific mmWave Signal Synthesis from a Photo and Activity Description](https://arxiv.org/abs/2512.11894)
*Mahathir Monjur,Shahriar Nirjon*

Main category: cs.CV

TL;DR: mmWeaver 是一种基于隐式神经表示和超网络的毫米波信号合成框架，显著提升了信号生成的效率和真实性，同时优化了下游任务的性能。


<details>
  <summary>Details</summary>
Motivation: 毫米波信号具有复杂、稀疏和高维特性，物理模拟计算成本高，限制了数据集的多样性和环境特异性。mmWeaver 旨在解决这一问题，提升信号生成的效率和真实性。

Method: mmWeaver 利用隐式神经表示（INRs）将毫米波信号建模为连续函数，并结合超网络动态生成 INR 参数，通过环境上下文（RGB-D 图像）和人体运动特征（MotionGPT 生成的姿态）进行条件化，实现多分辨率 I/Q 信号生成。

Result: mmWeaver 在信号保真度（SSIM 0.88，PSNR 35 dB）和下游任务性能（活动识别准确率提升 7%，姿态估计误差降低 15%）上优于现有方法，同时速度比模拟方法快 6-35 倍。

Conclusion: mmWeaver 通过使用隐式神经表示（INRs）和超网络，成功合成了高保真、环境特定的毫米波信号，显著提升了信号生成的效率和下游任务的性能。

Abstract: Realistic signal generation and dataset augmentation are essential for advancing mmWave radar applications such as activity recognition and pose estimation, which rely heavily on diverse, and environment-specific signal datasets. However, mmWave signals are inherently complex, sparse, and high-dimensional, making physical simulation computationally expensive. This paper presents mmWeaver, a novel framework that synthesizes realistic, environment-specific complex mmWave signals by modeling them as continuous functions using Implicit Neural Representations (INRs), achieving up to 49-fold compression. mmWeaver incorporates hypernetworks that dynamically generate INR parameters based on environmental context (extracted from RGB-D images) and human motion features (derived from text-to-pose generation via MotionGPT), enabling efficient and adaptive signal synthesis. By conditioning on these semantic and geometric priors, mmWeaver generates diverse I/Q signals at multiple resolutions, preserving phase information critical for downstream tasks such as point cloud estimation and activity classification. Extensive experiments show that mmWeaver achieves a complex SSIM of 0.88 and a PSNR of 35 dB, outperforming existing methods in signal realism while improving activity recognition accuracy by up to 7% and reducing human pose estimation error by up to 15%, all while operating 6-35 times faster than simulation-based approaches.

</details>


### [8] [From Particles to Fields: Reframing Photon Mapping with Continuous Gaussian Photon Fields](https://arxiv.org/abs/2512.12459)
*Jiachen Tao,Benjamin Planche,Van Nguyen Nguyen,Junyi Wu,Yuchun Liu,Haoxuan Wang,Zhongpai Gao,Gengyu Zhang,Meng Zheng,Feiran Wang,Anwesa Choudhuri,Zhenghao Zhao,Weitai Kang,Terrence Chen,Yan Yan,Ziyan Wu*

Main category: cs.CV

TL;DR: 论文提出高斯光子场（GPF），通过可学习的3D高斯基元编码光子分布，显著提升了多视角渲染效率，同时保持了光子级精度。


<details>
  <summary>Details</summary>
Motivation: 传统光子映射在多视角渲染中存在计算效率低下的问题，因为每个视角都需要独立的光子追踪和随机核估计，导致冗余计算。论文旨在通过一种连续且可重用的辐射度函数来加速多视角渲染。

Method: 论文提出了高斯光子场（GPF），一种可学习的表示方法，将光子分布编码为各向异性的3D高斯基元，并通过多视角监督优化这些参数。GPF从第一次SPPM迭代的物理追踪光子初始化，并通过最终辐射度的多视角监督进行优化。

Result: 实验表明，GPF在复杂光传输场景（如焦散和镜面-漫反射交互）中实现了光子级精度，同时将计算量减少了几个数量级。

Conclusion: GPF（高斯光子场）通过将光子分布编码为可学习的3D高斯基元，成功将基于光子的渲染的物理严谨性与神经场景表示的高效性相结合，显著提升了多视角渲染的计算效率。

Abstract: Accurately modeling light transport is essential for realistic image synthesis. Photon mapping provides physically grounded estimates of complex global illumination effects such as caustics and specular-diffuse interactions, yet its per-view radiance estimation remains computationally inefficient when rendering multiple views of the same scene. The inefficiency arises from independent photon tracing and stochastic kernel estimation at each viewpoint, leading to inevitable redundant computation. To accelerate multi-view rendering, we reformulate photon mapping as a continuous and reusable radiance function. Specifically, we introduce the Gaussian Photon Field (GPF), a learnable representation that encodes photon distributions as anisotropic 3D Gaussian primitives parameterized by position, rotation, scale, and spectrum. GPF is initialized from physically traced photons in the first SPPM iteration and optimized using multi-view supervision of final radiance, distilling photon-based light transport into a continuous field. Once trained, the field enables differentiable radiance evaluation along camera rays without repeated photon tracing or iterative refinement. Extensive experiments on scenes with complex light transport, such as caustics and specular-diffuse interactions, demonstrate that GPF attains photon-level accuracy while reducing computation by orders of magnitude, unifying the physical rigor of photon-based rendering with the efficiency of neural scene representations.

</details>


### [9] [Hot Hém: Sài Gòn Giũa Cái Nóng Hông Còng Bàng -- Saigon in Unequal Heat](https://arxiv.org/abs/2512.11896)
*Tessa Vu*

Main category: cs.CV

TL;DR: Hot Hém是一种GeoAI工作流程，结合街景图像和机器学习预测胡志明市行人热暴露，支持热感知路径规划。


<details>
  <summary>Details</summary>
Motivation: 热带密集城市中行人热暴露是重要的健康风险，但标准路径规划算法常忽略微观尺度的热变化。

Method: 该研究使用两个XGBoost模型，基于Google街景图像训练数据集预测地表温度，并在所有OSMnx衍生的行人网络节点上以拼布方式部署。

Result: 模型能够识别并预测城市走廊中温度异常高的区域，为理解基础设施尺度的热分布提供了工具。

Conclusion: Hot Hém工作流程通过结合Google街景图像、语义图像分割和遥感技术，成功预测了胡志明市行人网络节点的地表温度，为热感知路径规划提供了基础。

Abstract: Pedestrian heat exposure is a critical health risk in dense tropical cities, yet standard routing algorithms often ignore micro-scale thermal variation. Hot Hém is a GeoAI workflow that estimates and operationalizes pedestrian heat exposure in Hô Chí Minh City (HCMC), Vi\d{e}t Nam, colloquially known as Sài Gòn. This spatial data science pipeline combines Google Street View (GSV) imagery, semantic image segmentation, and remote sensing. Two XGBoost models are trained to predict land surface temperature (LST) using a GSV training dataset in selected administrative wards, known as phŏng, and are deployed in a patchwork manner across all OSMnx-derived pedestrian network nodes to enable heat-aware routing. This is a model that, when deployed, can provide a foundation for pinpointing where and further understanding why certain city corridors may experience disproportionately higher temperatures at an infrastructural scale.

</details>


### [10] [Animus3D: Text-driven 3D Animation via Motion Score Distillation](https://arxiv.org/abs/2512.12534)
*Qi Sun,Can Wang,Jiaxiang Shang,Wensen Feng,Jing Liao*

Main category: cs.CV

TL;DR: Animus3D是一个文本驱动的3D动画框架，通过新颖的MSD方法生成高质量运动，解决了现有SDS方法的运动微弱和抖动问题。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法使用SDS目标从预训练的文本到视频扩散模型中提取运动时，导致动画运动微弱或抖动明显的问题。

Method: 提出了一种新颖的Motion Score Distillation (MSD)方法，替代传统的Score Distillation Sampling (SDS)。该方法包括一个LoRA增强的视频扩散模型、基于反转的噪声估计技术、时空正则化项以及运动细化模块。

Result: 实验表明，Animus3D能够从多样化的文本提示中成功生成静态3D资产的动画，运动效果显著且细节丰富，同时保持视觉完整性。

Conclusion: Animus3D成功地从多样化的文本提示中生成了静态3D资产的动画，其运动效果比现有基线方法更显著且细节更丰富，同时保持了高度的视觉完整性。

Abstract: We present Animus3D, a text-driven 3D animation framework that generates motion field given a static 3D asset and text prompt. Previous methods mostly leverage the vanilla Score Distillation Sampling (SDS) objective to distill motion from pretrained text-to-video diffusion, leading to animations with minimal movement or noticeable jitter. To address this, our approach introduces a novel SDS alternative, Motion Score Distillation (MSD). Specifically, we introduce a LoRA-enhanced video diffusion model that defines a static source distribution rather than pure noise as in SDS, while another inversion-based noise estimation technique ensures appearance preservation when guiding motion. To further improve motion fidelity, we incorporate explicit temporal and spatial regularization terms that mitigate geometric distortions across time and space. Additionally, we propose a motion refinement module to upscale the temporal resolution and enhance fine-grained details, overcoming the fixed-resolution constraints of the underlying video model. Extensive experiments demonstrate that Animus3D successfully animates static 3D assets from diverse text prompts, generating significantly more substantial and detailed motion than state-of-the-art baselines while maintaining high visual integrity. Code will be released at https://qiisun.github.io/animus3d_page.

</details>


### [11] [Microscopic Vehicle Trajectory Datasets from UAV-collected Video for Heterogeneous, Area-Based Urban Traffic](https://arxiv.org/abs/2512.11898)
*Yawar Ali,K. Ramachandra Rao,Ashish Bhaskar,Niladri Chatterjee*

Main category: cs.CV

TL;DR: 论文公开了无人机采集的微观车辆轨迹数据集，支持复杂城市交通环境的研究和建模。


<details>
  <summary>Details</summary>
Motivation: 传统路边视频采集在密集混合交通中因遮挡、视角限制和不规则车辆运动而效果不佳，无人机记录提供了俯视视角以减少这些问题并捕捉丰富的时空动态。

Method: 使用无人机（UAVs）在印度首都地区的六个中段位置收集数据，通过Data from Sky（DFS）平台提取并验证，数据包含时间戳的车辆位置、速度、纵向和横向加速度及车辆分类。

Result: 数据集展示了关键行为模式，如车道保持偏好、速度分布和横向操纵，适用于异质和区域交通环境的研究。

Conclusion: 该论文通过公开可用的微观车辆轨迹数据集，为全球研究社区提供了支持复杂城市交通环境模拟建模、安全评估和行为研究的独特资源。

Abstract: This paper offers openly available microscopic vehicle trajectory (MVT) datasets collected using unmanned aerial vehicles (UAVs) in heterogeneous, area-based urban traffic conditions. Traditional roadside video collection often fails in dense mixed traffic due to occlusion, limited viewing angles, and irregular vehicle movements. UAV-based recording provides a top-down perspective that reduces these issues and captures rich spatial and temporal dynamics. The datasets described here were extracted using the Data from Sky (DFS) platform and validated against manual counts, space mean speeds, and probe trajectories in earlier work. Each dataset contains time-stamped vehicle positions, speeds, longitudinal and lateral accelerations, and vehicle classifications at a resolution of 30 frames per second. Data were collected at six mid-block locations in the national capital region of India, covering diverse traffic compositions and density levels. Exploratory analyses highlight key behavioural patterns, including lane-keeping preferences, speed distributions, and lateral manoeuvres typical of heterogeneous and area-based traffic settings. These datasets are intended as a resource for the global research community to support simulation modelling, safety assessment, and behavioural studies under area-based traffic conditions. By making these empirical datasets openly available, this work offers researchers a unique opportunity to develop, test, and validate models that more accurately represent complex urban traffic environments.

</details>


### [12] [Qonvolution: Towards Learning High-Frequency Signals with Queried Convolution](https://arxiv.org/abs/2512.12898)
*Abhinav Kumar,Tristan Aumentado-Armstrong,Lazar Valkov,Gopal Sharma,Alex Levinshtein,Radek Grzeszczuk,Suren Kumar*

Main category: cs.CV

TL;DR: Qonvolutions通过卷积与查询结合，有效提升高频信号学习性能，在多个任务中表现优异，尤其在NVS中达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 当前技术如傅里叶编码在提升高频信号学习性能方面仍有改进空间，特别是在处理高频信息时。

Method: 提出了一种名为Qonvolution的改进方法，通过将低频信号与查询（如坐标）进行卷积来增强高频信号的学习能力。

Result: Qonvolutions在1D回归、2D超分辨率、2D图像回归和新视角合成（NVS）等多种高频学习任务中表现优异，结合高斯喷溅在NVS中实现了最先进的性能。

Conclusion: Qonvolutions通过结合卷积的邻域特性和查询机制，显著提升了高频信号学习的性能，在多个任务中展示了优越性，特别是在复杂场景的新视角合成中达到了最先进的水平。

Abstract: Accurately learning high-frequency signals is a challenge in computer vision and graphics, as neural networks often struggle with these signals due to spectral bias or optimization difficulties. While current techniques like Fourier encodings have made great strides in improving performance, there remains scope for improvement when presented with high-frequency information. This paper introduces Queried-Convolutions (Qonvolutions), a simple yet powerful modification using the neighborhood properties of convolution. Qonvolution convolves a low-frequency signal with queries (such as coordinates) to enhance the learning of intricate high-frequency signals. We empirically demonstrate that Qonvolutions enhance performance across a variety of high-frequency learning tasks crucial to both the computer vision and graphics communities, including 1D regression, 2D super-resolution, 2D image regression, and novel view synthesis (NVS). In particular, by combining Gaussian splatting with Qonvolutions for NVS, we showcase state-of-the-art performance on real-world complex scenes, even outperforming powerful radiance field models on image quality.

</details>


### [13] [Read or Ignore? A Unified Benchmark for Typographic-Attack Robustness and Text Recognition in Vision-Language Models](https://arxiv.org/abs/2512.11899)
*Futa Waseda,Shojiro Yamabe,Daiki Shiono,Kento Sasaki,Tsubasa Takahashi*

Main category: cs.CV

TL;DR: 该论文提出了RIO-VQA任务和RIO-Bench数据集，揭示了LVLMs在排版攻击下的脆弱性，并提出了一种自适应选择性使用文本的防御方法。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）易受排版攻击的影响，现有评估和防御方法主要集中在对象识别上，忽视了现实场景中需要同时对对象和文本进行联合推理的需求。

Method: 研究者引入了名为Read-or-Ignore VQA（RIO-VQA）的新任务，并开发了Read-or-Ignore Benchmark（RIO-Bench）作为标准化数据集和评估协议。

Result: 研究发现，现有的LVLMs和防御方法无法平衡排版鲁棒性和文本阅读能力，并展示了一种新型数据驱动的防御方法，能够自适应地选择性使用文本。

Conclusion: 该研究揭示了现有评估范围与现实需求之间的根本性不一致，并提出了一种原则性的方法，以推动更可靠的大型视觉语言模型（LVLMs）的发展。

Abstract: Large vision-language models (LVLMs) are vulnerable to typographic attacks, where misleading text within an image overrides visual understanding. Existing evaluation protocols and defenses, largely focused on object recognition, implicitly encourage ignoring text to achieve robustness; however, real-world scenarios often require joint reasoning over both objects and text (e.g., recognizing pedestrians while reading traffic signs). To address this, we introduce a novel task, Read-or-Ignore VQA (RIO-VQA), which formalizes selective text use in visual question answering (VQA): models must decide, from context, when to read text and when to ignore it. For evaluation, we present the Read-or-Ignore Benchmark (RIO-Bench), a standardized dataset and protocol that, for each real image, provides same-scene counterfactuals (read / ignore) by varying only the textual content and question type. Using RIO-Bench, we show that strong LVLMs and existing defenses fail to balance typographic robustness and text-reading capability, highlighting the need for improved approaches. Finally, RIO-Bench enables a novel data-driven defense that learns adaptive selective text use, moving beyond prior non-adaptive, text-ignoring defenses. Overall, this work reveals a fundamental misalignment between the existing evaluation scope and real-world requirements, providing a principled path toward reliable LVLMs. Our Project Page is at https://turingmotors.github.io/rio-vqa/.

</details>


### [14] [CLARGA: Multimodal Graph Representation Learning over Arbitrary Sets of Modalities](https://arxiv.org/abs/2512.11901)
*Santosh Patapati*

Main category: cs.CV

TL;DR: CLARGA 是一种通用多模态融合框架，通过注意力加权图和混合损失函数，实现高效跨模态学习，适用于多样任务且对缺失模态鲁棒。


<details>
  <summary>Details</summary>
Motivation: 解决多模态表示学习中模态数量与类型不固定、模态间信息交互复杂的问题，同时提升对缺失模态的适应能力。

Method: CLARGA 通过构建注意力加权图，利用多头图注意力网络传递信息，实现模态间的高效融合，并采用混合目标函数（监督任务损失和对比 InfoNCE 损失）进行训练。

Result: 在 7 个数据集上的实验表明，CLARGA 在多种任务中均优于基线模型和当前最优模型，且对缺失输入具有鲁棒性。

Conclusion: CLARGA 是一种通用多模态融合架构，能够高效学习跨模态表示，适用于多种任务，且在缺失模态输入时表现稳健。

Abstract: We introduce CLARGA, a general-purpose multimodal fusion architecture for multimodal representation learning that works with any number and type of modalities without changing the underlying framework. Given a supervised dataset, CLARGA can be applied to virtually any machine learning task to fuse different multimodal representations for processing by downstream layers. On a sample-by-sample basis, CLARGA learns how modalities should inform one another by building an attention weighted graph over their features and passing messages along this graph with a multi-head Graph Attention Network. Not only does this make CLARGA highly adaptive, as it constructs unique graphs for different samples, it makes for efficient fusion with sub-quadratic complexity as the number of modalities grows. Through a learnable mask, it can also adapt to missing modality inputs. The model is trained with a hybrid objective that combines a supervised task loss with contrastive InfoNCE loss, improving cross-modal consistency and robustness to noisy inputs. We demonstrate CLARGA's effectiveness in diverse multimodal representation learning tasks across 7 datasets spanning finance, human-computer interaction, general multimedia classification, and affective computing. It consistently outperforms baselines, state-of-the-art models, and ablations. Additional experiments also demonstrate its robustness to missing inputs and ability to excel on niche tasks. Overall, CLARGA can be easily plugged into machine learning models for effective and efficient learning of representations across a wide variety of tasks.

</details>


### [15] [Computer vision training dataset generation for robotic environments using Gaussian splatting](https://arxiv.org/abs/2512.13411)
*Patryk Niżeniec,Marcin Iwanowski*

Main category: cs.CV

TL;DR: 提出一种利用3DGS和游戏引擎生成高真实感合成数据的方法，结合少量真实数据训练模型效果最佳。


<details>
  <summary>Details</summary>
Motivation: 解决合成与现实图像之间的领域差距及手动标注耗时的问题。

Method: 利用3D高斯泼溅（3DGS）创建逼真的环境和物体表示，结合游戏引擎中的物理模拟和两遍渲染技术生成高真实感图像。

Result: 实验表明，混合训练策略在检测和分割任务中表现最佳。

Conclusion: 混合训练策略（结合少量真实图像和大量合成数据）是实现稳健且准确模型的最佳策略。

Abstract: This paper introduces a novel pipeline for generating large-scale, highly realistic, and automatically labeled datasets for computer vision tasks in robotic environments. Our approach addresses the critical challenges of the domain gap between synthetic and real-world imagery and the time-consuming bottleneck of manual annotation. We leverage 3D Gaussian Splatting (3DGS) to create photorealistic representations of the operational environment and objects. These assets are then used in a game engine where physics simulations create natural arrangements. A novel, two-pass rendering technique combines the realism of splats with a shadow map generated from proxy meshes. This map is then algorithmically composited with the image to add both physically plausible shadows and subtle highlights, significantly enhancing realism. Pixel-perfect segmentation masks are generated automatically and formatted for direct use with object detection models like YOLO. Our experiments show that a hybrid training strategy, combining a small set of real images with a large volume of our synthetic data, yields the best detection and segmentation performance, confirming this as an optimal strategy for efficiently achieving robust and accurate models.

</details>


### [16] [Smartphone monitoring of smiling as a behavioral proxy of well-being in everyday life](https://arxiv.org/abs/2512.11905)
*Ming-Zher Poh,Shun Liao,Marco Andreetto,Daniel McDuff,Jonathan Wang,Paolo Di Achille,Jiang Wu,Yun Liu,Lawrence Cai,Eric Teasley,Mark Malhotra,Anupam Pathak,Shwetak Patel*

Main category: cs.CV

TL;DR: 通过智能手机被动捕捉的微笑强度可以作为积极情感的客观行为指标，与幸福感和日常活动显著相关。


<details>
  <summary>Details</summary>
Motivation: 主观幸福感的科学测量传统上依赖于自我报告方法，容易受到回忆偏差和高参与者负担的影响，这导致对日常生活中幸福感表达的理解存在空白。

Method: 使用深度学习模型分析405,448个被动记录的智能手机视频片段，量化微笑强度，并识别昼夜和每日模式。

Result: 微笑强度的每日模式与全国幸福调查数据高度相关（r=0.92），昼夜节律与日重建方法的结果高度一致（r=0.80）。更高的每日平均微笑强度与更多体力活动（Beta系数=0.043）和更大光照暴露（Beta系数=0.038）显著相关。

Conclusion: 被动智能手机传感可以作为一种强大且生态有效的方法来研究情感行为的动态，并为在人口规模上理解这种行为打开了大门。

Abstract: Subjective well-being is a cornerstone of individual and societal health, yet its scientific measurement has traditionally relied on self-report methods prone to recall bias and high participant burden. This has left a gap in our understanding of well-being as it is expressed in everyday life. We hypothesized that candid smiles captured during natural smartphone interactions could serve as a scalable, objective behavioral correlate of positive affect. To test this, we analyzed 405,448 video clips passively recorded from 233 consented participants over one week. Using a deep learning model to quantify smile intensity, we identified distinct diurnal and daily patterns. Daily patterns of smile intensity across the week showed strong correlation with national survey data on happiness (r=0.92), and diurnal rhythms documented close correspondence with established results from the day reconstruction method (r=0.80). Higher daily mean smile intensity was significantly associated with more physical activity (Beta coefficient = 0.043, 95% CI [0.001, 0.085]) and greater light exposure (Beta coefficient = 0.038, [0.013, 0.063]), whereas no significant effects were found for smartphone use. These findings suggest that passive smartphone sensing could serve as a powerful, ecologically valid methodology for studying the dynamics of affective behavior and open the door to understanding this behavior at a population scale.

</details>


### [17] [Towards Interactive Intelligence for Digital Humans](https://arxiv.org/abs/2512.13674)
*Yiyi Cai,Xuangeng Chu,Xiwei Gao,Sitong Gong,Yifei Huang,Caixin Kang,Kunhang Li,Haiyang Liu,Ruicong Liu,Yun Liu,Dianwen Ng,Zixiong Su,Erwin Wu,Yuhan Wu,Dingkun Yan,Tianyu Yan,Chang Zeng,Bo Zheng,You Zhou*

Main category: cs.CV

TL;DR: Mio框架通过五个模块实现数字人的智能交互，性能超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了推动数字人从表面模仿向智能交互发展，实现个性对齐表达、自适应交互和自我进化。

Method: 提出了Mio（多模态交互全能化身）框架，包含五个模块：Thinker、Talker、Face Animator、Body Animator和Renderer，整合认知推理与实时多模态体现。

Result: 实验表明，Mio框架在所有评估维度上均优于现有最先进方法。

Conclusion: 本文提出的交互智能范式及Mio框架将数字人从表面模仿推向智能交互，展示了卓越的性能。

Abstract: We introduce Interactive Intelligence, a novel paradigm of digital human that is capable of personality-aligned expression, adaptive interaction, and self-evolution. To realize this, we present Mio (Multimodal Interactive Omni-Avatar), an end-to-end framework composed of five specialized modules: Thinker, Talker, Face Animator, Body Animator, and Renderer. This unified architecture integrates cognitive reasoning with real-time multimodal embodiment to enable fluid, consistent interaction. Furthermore, we establish a new benchmark to rigorously evaluate the capabilities of interactive intelligence. Extensive experiments demonstrate that our framework achieves superior performance compared to state-of-the-art methods across all evaluated dimensions. Together, these contributions move digital humans beyond superficial imitation toward intelligent interaction.

</details>


### [18] [MPath: Multimodal Pathology Report Generation from Whole Slide Images](https://arxiv.org/abs/2512.11906)
*Noorul Wahab,Nasir Rajpoot*

Main category: cs.CV

TL;DR: MPath是一个轻量级多模态框架，通过视觉前缀提示机制将WSI特征注入预训练语言模型，用于自动化病理报告生成，在RED 2025挑战中表现优异。


<details>
  <summary>Details</summary>
Motivation: 自动化从全切片图像（WSIs）生成诊断病理报告是计算病理学的一个新兴方向，但由于组织形态的高度变异性和病理叙述的复杂结构，将高分辨率组织模式转化为临床连贯文本仍然具有挑战性。

Method: MPath是一个轻量级多模态框架，通过学习的视觉前缀提示机制，将预训练的生物医学语言模型（BioBART）与WSI衍生的视觉嵌入条件化。它利用基础模型WSI特征（CONCH + Titan），并通过紧凑的投影模块将其注入BioBART，同时保持语言主干冻结以提高稳定性和数据效率。

Result: MPath在RED 2025 Grand Challenge数据集的开发和评估中，尽管提交机会有限，但在测试阶段2中排名第4。

Conclusion: MPath展示了基于提示的多模态条件作为一种可扩展且可解释的病理报告生成策略的潜力。

Abstract: Automated generation of diagnostic pathology reports directly from whole slide images (WSIs) is an emerging direction in computational pathology. Translating high-resolution tissue patterns into clinically coherent text remains difficult due to large morphological variability and the complex structure of pathology narratives. We introduce MPath, a lightweight multimodal framework that conditions a pretrained biomedical language model (BioBART) on WSI-derived visual embeddings through a learned visual-prefix prompting mechanism. Instead of end-to-end vision-language pretraining, MPath leverages foundation-model WSI features (CONCH + Titan) and injects them into BioBART via a compact projection module, keeping the language backbone frozen for stability and data efficiency. MPath was developed and evaluated on the RED 2025 Grand Challenge dataset and ranked 4th in Test Phase 2, despite limited submission opportunities. The results highlight the potential of prompt-based multimodal conditioning as a scalable and interpretable strategy for pathology report generation.

</details>


### [19] [DiffusionBrowser: Interactive Diffusion Previews via Multi-Branch Decoders](https://arxiv.org/abs/2512.13690)
*Susung Hong,Chongjian Ge,Zhifei Zhang,Jui-Hsien Wang*

Main category: cs.CV

TL;DR: DiffusionBrowser 是一个轻量级解码器框架，支持在视频生成过程中实时生成多模态预览，提升交互性和透明度。


<details>
  <summary>Details</summary>
Motivation: 现有视频扩散模型在生成过程中存在不精确、速度慢和透明度低的问题，用户无法实时预览生成内容。

Method: 提出了 DiffusionBrowser，一个模型无关的轻量级解码器框架，支持在去噪过程的任意时间点生成 RGB 和场景内在属性的多模态预览。

Result: DiffusionBrowser 能以超过 4 倍实时速度生成预览（4 秒视频少于 1 秒），并通过随机性重注入和模态引导实现交互式控制。

Conclusion: DiffusionBrowser 提供了一种轻量级的解码器框架，能够在去噪过程中的任意时间点生成多模态预览，显著提升了视频生成的交互性和透明度。

Abstract: Video diffusion models have revolutionized generative video synthesis, but they are imprecise, slow, and can be opaque during generation -- keeping users in the dark for a prolonged period. In this work, we propose DiffusionBrowser, a model-agnostic, lightweight decoder framework that allows users to interactively generate previews at any point (timestep or transformer block) during the denoising process. Our model can generate multi-modal preview representations that include RGB and scene intrinsics at more than 4$\times$ real-time speed (less than 1 second for a 4-second video) that convey consistent appearance and motion to the final video. With the trained decoder, we show that it is possible to interactively guide the generation at intermediate noise steps via stochasticity reinjection and modal steering, unlocking a new control capability. Moreover, we systematically probe the model using the learned decoders, revealing how scene, object, and other details are composed and assembled during the otherwise black-box denoising process.

</details>


### [20] [FloraForge: LLM-Assisted Procedural Generation of Editable and Analysis-Ready 3D Plant Geometric Models For Agricultural Applications](https://arxiv.org/abs/2512.11925)
*Mozhgan Hadadi,Talukder Z. Jubery,Patrick S. Schnable,Arti Singh,Bedrich Benes,Adarsh Krishnamurthy,Baskar Ganapathysubramanian*

Main category: cs.CV

TL;DR: FloraForge是一个LLM辅助框架，通过自然语言交互生成参数化3D植物模型，降低了技术门槛并保持生物准确性。


<details>
  <summary>Details</summary>
Motivation: 当前基于学习的重建方法需要大量物种特定训练数据且缺乏可编辑性，而程序化建模需要专业几何建模知识，限制了领域科学家的使用。FloraForge旨在解决这些问题。

Method: FloraForge利用LLM辅助的协同设计，通过迭代的自然语言植物细化（PR）生成参数化的植物几何模型，采用分层B样条曲面表示，并结合植物学约束。

Result: 框架在玉米、大豆和绿豆上进行了验证，通过手动细化植物描述符（PD）生成了参数化模型，支持功能结构植物分析工作流。

Conclusion: FloraForge框架通过结合LLM辅助设计和自然语言交互，成功降低了植物3D建模的技术门槛，同时保持了模型的生物准确性和数学严谨性。

Abstract: Accurate 3D plant models are crucial for computational phenotyping and physics-based simulation; however, current approaches face significant limitations. Learning-based reconstruction methods require extensive species-specific training data and lack editability. Procedural modeling offers parametric control but demands specialized expertise in geometric modeling and an in-depth understanding of complex procedural rules, making it inaccessible to domain scientists. We present FloraForge, an LLM-assisted framework that enables domain experts to generate biologically accurate, fully parametric 3D plant models through iterative natural language Plant Refinements (PR), minimizing programming expertise. Our framework leverages LLM-enabled co-design to refine Python scripts that generate parameterized plant geometries as hierarchical B-spline surface representations with botanical constraints with explicit control points and parametric deformation functions. This representation can be easily tessellated into polygonal meshes with arbitrary precision, ensuring compatibility with functional structural plant analysis workflows such as light simulation, computational fluid dynamics, and finite element analysis. We demonstrate the framework on maize, soybean, and mung bean, fitting procedural models to empirical point cloud data through manual refinement of the Plant Descriptor (PD), human-readable files. The pipeline generates dual outputs: triangular meshes for visualization and triangular meshes with additional parametric metadata for quantitative analysis. This approach uniquely combines LLM-assisted template creation, mathematically continuous representations enabling both phenotyping and rendering, and direct parametric control through PD. The framework democratizes sophisticated geometric modeling for plant science while maintaining mathematical rigor.

</details>


### [21] [TransBridge: Boost 3D Object Detection by Scene-Level Completion with Transformer Decoder](https://arxiv.org/abs/2512.11926)
*Qinghao Meng,Chenming Wu,Liangjun Zhang,Jianbing Shen*

Main category: cs.CV

TL;DR: 提出TransBridge框架，结合Transformer和动态-静态重建模块，提升稀疏LiDAR点云的3D物体检测性能，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决远距离区域因LiDAR点云稀疏导致的3D物体检测难题，通过特征融合和点云稠密化提升检测性能。

Method: 提出了一种基于Transformer的上采样模块（TransBridge），结合动态-静态重建模块（DSRecon）生成密集LiDAR数据，利用Transformer机制建立通道和空间关系，生成高分辨率特征图用于完成任务。

Result: 在nuScenes和Waymo数据集上的实验表明，该框架能显著提升端到端3D物体检测性能（mAP提升0.7-1.5），对两阶段检测框架的mAP提升高达5.78。

Conclusion: 该论文提出的联合完成与检测框架（TransBridge）通过融合检测和完成网络的特征，显著提升了稀疏区域的检测性能，并在多个数据集上验证了其泛化能力。

Abstract: 3D object detection is essential in autonomous driving, providing vital information about moving objects and obstacles. Detecting objects in distant regions with only a few LiDAR points is still a challenge, and numerous strategies have been developed to address point cloud sparsity through densification.This paper presents a joint completion and detection framework that improves the detection feature in sparse areas while maintaining costs unchanged. Specifically, we propose TransBridge, a novel transformer-based up-sampling block that fuses the features from the detection and completion networks.The detection network can benefit from acquiring implicit completion features derived from the completion network. Additionally, we design the Dynamic-Static Reconstruction (DSRecon) module to produce dense LiDAR data for the completion network, meeting the requirement for dense point cloud ground truth.Furthermore, we employ the transformer mechanism to establish connections between channels and spatial relations, resulting in a high-resolution feature map used for completion purposes.Extensive experiments on the nuScenes and Waymo datasets demonstrate the effectiveness of the proposed framework.The results show that our framework consistently improves end-to-end 3D object detection, with the mean average precision (mAP) ranging from 0.7 to 1.5 across multiple methods, indicating its generalization ability. For the two-stage detection framework, it also boosts the mAP up to 5.78 points.

</details>


### [22] [MONET -- Virtual Cell Painting of Brightfield Images and Time Lapses Using Reference Consistent Diffusion](https://arxiv.org/abs/2512.11928)
*Alexander Peysakhovich,William Berman,Joseph Rufo,Felix Wong,Maxwell Z. Wilson*

Main category: cs.CV

TL;DR: 摘要：研究通过扩散模型（MONET）从明场图像预测细胞染色通道，解决了传统细胞染色的劳动密集和无法动态研究的问题，并展示了模型的扩展性和上下文学习能力。


<details>
  <summary>Details</summary>
Motivation: 细胞染色是一种流行的技术，用于生成人类可解释、高对比度的细胞形态图像。但存在两大问题：(1) 劳动密集型，(2) 需要化学固定，无法研究细胞动力学。

Method: 我们训练了一个扩散模型（Morphological Observation Neural Enhancement Tool，简称MONET），利用大型数据集从明场图像预测细胞染色通道。模型采用一致性架构生成延时视频，尽管无法获得细胞染色视频训练数据。

Result: 模型质量随规模提升而改善。此外，该架构支持一种上下文学习形式，使模型能够部分迁移到分布外的细胞系和成像协议。

Conclusion: 虚拟细胞染色（Virtual cell painting）并非旨在完全取代物理细胞染色，而是作为一种补充工具，为生物学研究开启新的工作流程。

Abstract: Cell painting is a popular technique for creating human-interpretable, high-contrast images of cell morphology. There are two major issues with cell paint: (1) it is labor-intensive and (2) it requires chemical fixation, making the study of cell dynamics impossible. We train a diffusion model (Morphological Observation Neural Enhancement Tool, or MONET) on a large dataset to predict cell paint channels from brightfield images. We show that model quality improves with scale. The model uses a consistency architecture to generate time-lapse videos, despite the impossibility of obtaining cell paint video training data. In addition, we show that this architecture enables a form of in-context learning, allowing the model to partially transfer to out-of-distribution cell lines and imaging protocols. Virtual cell painting is not intended to replace physical cell painting completely, but to act as a complementary tool enabling novel workflows in biological research.

</details>


### [23] [Contextual Peano Scan and Fast Image Segmentation Using Hidden and Evidential Markov Chains](https://arxiv.org/abs/2512.11939)
*Clément Fernandes,Wojciech Pieczynski*

Main category: cs.CV

TL;DR: 提出结合上下文Peano扫描和隐证据马尔可夫链的新模型HEMC-CPS，用于无监督图像分割，效果优于传统方法，适用于复杂图像及其他空间数据。


<details>
  <summary>Details</summary>
Motivation: 扩展Peano扫描（PS）至上下文PS（CPS），并利用隐证据马尔可夫链（HEMC）提升基于HMC的贝叶斯分割效果。

Method: 采用上下文Peano扫描（CPS）和隐证据马尔可夫链（HEMC）结合的新模型HEMC-CPS，通过随机期望最大化（SEM）方法进行无监督参数估计。

Result: HEMC-CPS模型在合成和真实图像的MPM分割中表现有效。

Conclusion: HEMC-CPS模型在贝叶斯最大后验模式（MPM）分割中表现出色，适用于复杂图像（如三维或多传感器多分辨率图像）的建模与分割，且不仅限于图像分割，还可用于其他空间相关数据。

Abstract: Transforming bi-dimensional sets of image pixels into mono-dimensional sequences with a Peano scan (PS) is an established technique enabling the use of hidden Markov chains (HMCs) for unsupervised image segmentation. Related Bayesian segmentation methods can compete with hidden Markov fields (HMFs)-based ones and are much faster. PS has recently been extended to the contextual PS, and some initial experiments have shown the value of the associated HMC model, denoted as HMC-CPS, in image segmentation. Moreover, HMCs have been extended to hidden evidential Markov chains (HEMCs), which are capable of improving HMC-based Bayesian segmentation. In this study, we introduce a new HEMC-CPS model by simultaneously considering contextual PS and evidential HMC. We show its effectiveness for Bayesian maximum posterior mode (MPM) segmentation using synthetic and real images. Segmentation is performed in an unsupervised manner, with parameters being estimated using the stochastic expectation--maximization (SEM) method. The new HEMC-CPS model presents potential for the modeling and segmentation of more complex images, such as three-dimensional or multi-sensor multi-resolution images. Finally, the HMC-CPS and HEMC-CPS models are not limited to image segmentation and could be used for any kind of spatially correlated data.

</details>


### [24] [DynaPURLS: Dynamic Refinement of Part-aware Representations for Skeleton-based Zero-Shot Action Recognition](https://arxiv.org/abs/2512.11941)
*Jingmin Zhu,Anqi Zhu,James Bailey,Jun Liu,Hossein Rahmani,Mohammed Bennamoun,Farid Boussaid,Qiuhong Ke*

Main category: cs.CV

TL;DR: DynaPURLS通过动态细化和多尺度视觉-语义对应，解决了零样本骨架动作识别中的领域偏移问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于骨架特征与静态类别级语义的对齐，这种粗粒度对齐难以弥合可见与未见类之间的领域偏移，限制了细粒度视觉知识的有效迁移。

Method: 利用大型语言模型生成层次化文本描述，结合自适应分区模块产生细粒度视觉表示，并通过动态细化模块在推理时调整文本特征。

Result: 在NTU RGB+D 60/120和PKU-MMD等大规模基准数据集上的实验表明，DynaPURLS显著优于现有方法，创下了新的最优记录。

Conclusion: DynaPURLS通过动态细化和多尺度视觉-语义对应，显著提升了零样本骨架动作识别的性能，并在多个基准数据集上达到了新的最优结果。

Abstract: Zero-shot skeleton-based action recognition (ZS-SAR) is fundamentally constrained by prevailing approaches that rely on aligning skeleton features with static, class-level semantics. This coarse-grained alignment fails to bridge the domain shift between seen and unseen classes, thereby impeding the effective transfer of fine-grained visual knowledge. To address these limitations, we introduce \textbf{DynaPURLS}, a unified framework that establishes robust, multi-scale visual-semantic correspondences and dynamically refines them at inference time to enhance generalization. Our framework leverages a large language model to generate hierarchical textual descriptions that encompass both global movements and local body-part dynamics. Concurrently, an adaptive partitioning module produces fine-grained visual representations by semantically grouping skeleton joints. To fortify this fine-grained alignment against the train-test domain shift, DynaPURLS incorporates a dynamic refinement module. During inference, this module adapts textual features to the incoming visual stream via a lightweight learnable projection. This refinement process is stabilized by a confidence-aware, class-balanced memory bank, which mitigates error propagation from noisy pseudo-labels. Extensive experiments on three large-scale benchmark datasets, including NTU RGB+D 60/120 and PKU-MMD, demonstrate that DynaPURLS significantly outperforms prior art, setting new state-of-the-art records. The source code is made publicly available at https://github.com/Alchemist0754/DynaPURLS

</details>


### [25] [A Comparative Analysis of Semiconductor Wafer Map Defect Detection with Image Transformer](https://arxiv.org/abs/2512.11977)
*Sushmita Nath*

Main category: cs.CV

TL;DR: DeiT在数据受限条件下优于传统CNN模型，适用于半导体晶圆缺陷检测，支持预测性维护。


<details>
  <summary>Details</summary>
Motivation: 卷积神经网络（CNN）在半导体晶圆行业的图像分类中表现良好，但在数据有限和不平衡的情况下效果下降。

Method: 本研究调查了数据高效图像Transformer（DeiT）在数据受限条件下对晶圆图缺陷分类的应用。

Result: 实验结果显示，DeiT模型实现了90.83%的最高分类准确率，优于VGG-19（65%）、SqueezeNet（82%）、Xception（66%）和Hybrid（67%）等CNN模型。DeiT还表现出更高的F1分数（90.78%）和更快的训练收敛速度，对少数缺陷类别的检测具有更强的鲁棒性。

Conclusion: 该研究强调了基于Transformer的模型（如DeiT）在半导体晶圆缺陷检测中的潜力，并支持半导体制造过程中的预测性维护策略。

Abstract: Predictive maintenance is an important sector in modern industries which improves fault detection and cost reduction processes. By using machine learning algorithms in the whole process, the defects detection process can be implemented smoothly. Semiconductor is a sensitive maintenance field that requires predictability in work. While convolutional neural networks (CNNs) such as VGG-19, Xception and Squeeze-Net have demonstrated solid performance in image classification for semiconductor wafer industry, their effectiveness often declines in scenarios with limited and imbalanced data. This study investigates the use of the Data-Efficient Image Transformer (DeiT) for classifying wafer map defects under data-constrained conditions. Experimental results reveal that the DeiT model achieves highest classification accuracy of 90.83%, outperforming CNN models such as VGG-19(65%), SqueezeNet(82%), Xception(66%) and Hybrid(67%). DeiT also demonstrated superior F1-score (90.78%) and faster training convergence, with enhanced robustness in detecting minority defect classes. These findings highlight the potential of transformer-based models like DeiT in semiconductor wafer defect detection and support predictive maintenance strategies within semiconductor fabrication processes.

</details>


### [26] [CARI4D: Category Agnostic 4D Reconstruction of Human-Object Interaction](https://arxiv.org/abs/2512.11988)
*Xianghui Xie,Bowen Wen,Yan Chang,Hesam Rabeti,Jiefeng Li,Ye Yuan,Gerard Pons-Moll,Stan Birchfield*

Main category: cs.CV

TL;DR: CARI4D是首个类别无关的单目RGB视频4D人-物交互重建方法，通过姿态假设选择和渲染-比较优化，显著提升重建精度，并支持零样本应用。


<details>
  <summary>Details</summary>
Motivation: 从单目RGB视图推断4D人-物交互具有挑战性，因未知物体和人信息、深度模糊、遮挡及复杂运动等问题，现有方法需简化设置。

Method: 提出了一种姿态假设选择算法，通过基础模型的预测集成，并通过学习渲染-比较范式进行联合优化，确保空间、时间和像素对齐，最后基于物理约束进行精细接触推理。

Result: 在已知数据集和未见数据集上，重建误差分别降低38%和36%，且能零样本泛化到训练类别之外的视频。

Conclusion: CARI4D方法在单目RGB视频中实现了类别无关的4D人-物交互重建，显著优于现有方法，并能零样本应用于真实场景视频。

Abstract: Accurate capture of human-object interaction from ubiquitous sensors like RGB cameras is important for applications in human understanding, gaming, and robot learning. However, inferring 4D interactions from a single RGB view is highly challenging due to the unknown object and human information, depth ambiguity, occlusion, and complex motion, which hinder consistent 3D and temporal reconstruction. Previous methods simplify the setup by assuming ground truth object template or constraining to a limited set of object categories. We present CARI4D, the first category-agnostic method that reconstructs spatially and temporarily consistent 4D human-object interaction at metric scale from monocular RGB videos. To this end, we propose a pose hypothesis selection algorithm that robustly integrates the individual predictions from foundation models, jointly refine them through a learned render-and-compare paradigm to ensure spatial, temporal and pixel alignment, and finally reasoning about intricate contacts for further refinement satisfying physical constraints. Experiments show that our method outperforms prior art by 38% on in-distribution dataset and 36% on unseen dataset in terms of reconstruction error. Our model generalizes beyond the training categories and thus can be applied zero-shot to in-the-wild internet videos. Our code and pretrained models will be publicly released.

</details>


### [27] [V-REX: Benchmarking Exploratory Visual Reasoning via Chain-of-Questions](https://arxiv.org/abs/2512.11995)
*Chenrui Fan,Yijun Liang,Shweta Bhardwaj,Kwesi Cobbina,Ming Li,Tianyi Zhou*

Main category: cs.CV

TL;DR: V-REX是一个评估视觉语言模型多步探索推理能力的套件，揭示了当前模型在规划和跟随任务中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型在复杂开放任务中表现不佳，缺乏对多步探索推理能力的有效评估方法。

Method: 开发了一个名为V-REX的评估套件，包含挑战性视觉推理任务的基准和评估协议，将多步探索推理分解为Chain-of-Questions（CoQ），并通过有限选项实现定量分析。

Result: 评估显示，SOTA专有和开源VLMs在多步探索推理中表现出一致的扩展趋势，规划和跟随能力存在显著差异，且有较大改进空间。

Conclusion: V-REX评估套件揭示了当前视觉语言模型在多步探索推理能力上的显著差异和提升空间，尤其在规划和跟随能力方面。

Abstract: While many vision-language models (VLMs) are developed to answer well-defined, straightforward questions with highly specified targets, as in most benchmarks, they often struggle in practice with complex open-ended tasks, which usually require multiple rounds of exploration and reasoning in the visual space. Such visual thinking paths not only provide step-by-step exploration and verification as an AI detective but also produce better interpretations of the final answers. However, these paths are challenging to evaluate due to the large exploration space of intermediate steps. To bridge the gap, we develop an evaluation suite, ``Visual Reasoning with multi-step EXploration (V-REX)'', which is composed of a benchmark of challenging visual reasoning tasks requiring native multi-step exploration and an evaluation protocol. V-REX covers rich application scenarios across diverse domains. V-REX casts the multi-step exploratory reasoning into a Chain-of-Questions (CoQ) and disentangles VLMs' capability to (1) Planning: breaking down an open-ended task by selecting a chain of exploratory questions; and (2) Following: answering curated CoQ sequentially to collect information for deriving the final answer. By curating finite options of questions and answers per step, V-REX achieves a reliable quantitative and fine-grained analysis of the intermediate steps. By assessing SOTA proprietary and open-sourced VLMs, we reveal consistent scaling trends, significant differences between planning and following abilities, and substantial room for improvement in multi-step exploratory reasoning.

</details>


### [28] [Semantic-Drive: Democratizing Long-Tail Data Curation via Open-Vocabulary Grounding and Neuro-Symbolic VLM Consensus](https://arxiv.org/abs/2512.12012)
*Antonio Guillen-Perez*

Main category: cs.CV

TL;DR: Semantic-Drive是一种本地优先的神经符号框架，通过两阶段感知和推理时对齐策略，显著提升了对罕见安全关键事件的识别能力，且能在消费级硬件上高效运行。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶车辆（AVs）的开发受限于“长尾”训练数据的稀缺，现有解决方案要么精度不足，要么隐私侵入性强且成本高昂。

Method: 采用神经符号框架，分为两个阶段：符号接地（使用YOLOE实时开放词汇检测器）和认知分析（通过推理VLM进行场景分析），并引入“System 2”推理时对齐策略以减少幻觉。

Result: 在nuScenes数据集上，Semantic-Drive的召回率达到0.966（CLIP为0.475），并将风险评估错误降低了40%。

Conclusion: Semantic-Drive 提供了一个本地优先、隐私保护的解决方案，显著提高了对罕见安全关键事件的识别能力，并在消费级硬件上实现了高效运行。

Abstract: The development of robust Autonomous Vehicles (AVs) is bottlenecked by the scarcity of "Long-Tail" training data. While fleets collect petabytes of video logs, identifying rare safety-critical events (e.g., erratic jaywalking, construction diversions) remains a manual, cost-prohibitive process. Existing solutions rely on coarse metadata search, which lacks precision, or cloud-based VLMs, which are privacy-invasive and expensive. We introduce Semantic-Drive, a local-first, neuro-symbolic framework for semantic data mining. Our approach decouples perception into two stages: (1) Symbolic Grounding via a real-time open-vocabulary detector (YOLOE) to anchor attention, and (2) Cognitive Analysis via a Reasoning VLM that performs forensic scene analysis. To mitigate hallucination, we implement a "System 2" inference-time alignment strategy, utilizing a multi-model "Judge-Scout" consensus mechanism. Benchmarked on the nuScenes dataset against the Waymo Open Dataset (WOD-E2E) taxonomy, Semantic-Drive achieves a Recall of 0.966 (vs. 0.475 for CLIP) and reduces Risk Assessment Error by 40\% compared to single models. The system runs entirely on consumer hardware (NVIDIA RTX 3090), offering a privacy-preserving alternative to the cloud.

</details>


### [29] [Exploring Spatial-Temporal Representation via Star Graph for mmWave Radar-based Human Activity Recognition](https://arxiv.org/abs/2512.12013)
*Senhao Gao,Junqing Zhang,Luoyu Mei,Shuai Wang,Xuyu Wang*

Main category: cs.CV

TL;DR: 提出DDGNN和星图表示法，解决毫米波雷达点云稀疏和变尺寸问题，HAR分类准确率达94.27%，接近视觉骨架数据性能，适用于资源受限平台。


<details>
  <summary>Details</summary>
Motivation: 毫米波雷达点云在HAR中因信号物理特性导致稀疏和变尺寸问题，现有视觉系统预处理算法不适用，需专用解决方案。

Method: 提出了一种基于离散动态图神经网络（DDGNN）的星图表示方法，用于捕捉高维时空特征，解决了点云稀疏和变尺寸问题。

Result: 实验显示该方法在真实HAR数据集上优于基线方法，分类准确率达94.27%，接近视觉骨架数据的97.25%，且在资源受限平台（如Raspberry Pi 4）上有效。

Conclusion: 该系统通过DDGNN和星图表示显著提升了毫米波雷达点云在HAR中的性能，接近基于视觉的骨架数据准确性，并在资源受限平台上验证了其有效性。

Abstract: Human activity recognition (HAR) requires extracting accurate spatial-temporal features with human movements. A mmWave radar point cloud-based HAR system suffers from sparsity and variable-size problems due to the physical features of the mmWave signal. Existing works usually borrow the preprocessing algorithms for the vision-based systems with dense point clouds, which may not be optimal for mmWave radar systems. In this work, we proposed a graph representation with a discrete dynamic graph neural network (DDGNN) to explore the spatial-temporal representation of human movement-related features. Specifically, we designed a star graph to describe the high-dimensional relative relationship between a manually added static center point and the dynamic mmWave radar points in the same and consecutive frames. We then adopted DDGNN to learn the features residing in the star graph with variable sizes. Experimental results demonstrated that our approach outperformed other baseline methods using real-world HAR datasets. Our system achieved an overall classification accuracy of 94.27\%, which gets the near-optimal performance with a vision-based skeleton data accuracy of 97.25\%. We also conducted an inference test on Raspberry Pi~4 to demonstrate its effectiveness on resource-constraint platforms. \sh{ We provided a comprehensive ablation study for variable DDGNN structures to validate our model design. Our system also outperformed three recent radar-specific methods without requiring resampling or frame aggregators.

</details>


### [30] [Adaptive federated learning for ship detection across diverse satellite imagery sources](https://arxiv.org/abs/2512.12053)
*Tran-Vu La,Minh-Tan Pham,Yu Li,Patrick Matgen,Marco Chini*

Main category: cs.CV

TL;DR: 联邦学习（FL）在船舶检测中表现优异，既保护隐私又提升检测精度，接近全局训练效果。


<details>
  <summary>Details</summary>
Motivation: 研究联邦学习在船舶检测中的应用，提供一种保护隐私的解决方案，避免数据共享或集中收集的需求，特别适用于商业卫星图像或敏感船舶标注。

Method: 评估并比较了四种FL模型（FedAvg、FedProx、FedOpt、FedMedian）与本地训练基线，使用YOLOv8船舶检测模型。

Result: FL模型在小规模本地数据集上的检测准确性显著提升，性能接近全局训练水平。

Conclusion: 联邦学习（FL）模型在船舶检测任务中显著提升了小规模本地数据集的检测准确性，并接近使用所有数据集的全局训练性能。选择合适的FL配置对优化检测精度和计算效率至关重要。

Abstract: We investigate the application of Federated Learning (FL) for ship detection across diverse satellite datasets, offering a privacy-preserving solution that eliminates the need for data sharing or centralized collection. This approach is particularly advantageous for handling commercial satellite imagery or sensitive ship annotations. Four FL models including FedAvg, FedProx, FedOpt, and FedMedian, are evaluated and compared to a local training baseline, where the YOLOv8 ship detection model is independently trained on each dataset without sharing learned parameters. The results reveal that FL models substantially improve detection accuracy over training on smaller local datasets and achieve performance levels close to global training that uses all datasets during the training. Furthermore, the study underscores the importance of selecting appropriate FL configurations, such as the number of communication rounds and local training epochs, to optimize detection precision while maintaining computational efficiency.

</details>


### [31] [Enhancing deep learning performance on burned area delineation from SPOT-6/7 imagery for emergency management](https://arxiv.org/abs/2512.12056)
*Maria Rodriguez,Minh-Tan Pham,Martin Sudmanns,Quentin Poterek,Oscar Narvaez*

Main category: cs.CV

TL;DR: 研究提出监督语义分割工作流程，提升烧毁区域划分效率，U-Net与SegFormer表现相当但后者资源需求高，土地覆盖数据增强鲁棒性，测试时间增强需优化。


<details>
  <summary>Details</summary>
Motivation: 当前烧毁区域划分方法依赖后事件遥感影像训练的计算机视觉模型，但忽视了其在时间紧迫的紧急管理场景中的适用性。本研究旨在提升划分的性能和效率，以支持灾害评估和生态恢复。

Method: 研究采用监督语义分割工作流程，针对SPOT-6/7影像进行烧毁区域划分。实验评估基于Dice分数、交并比和推理时间，比较了U-Net和SegFormer模型的表现，并探索了土地覆盖数据作为辅助任务及测试时间增强的效果。

Result: U-Net和SegFormer在有限训练数据下表现相似，但SegFormer资源需求更高。土地覆盖数据作为辅助任务增强了模型鲁棒性且不增加推理时间。测试时间提升性能但增加推理时间，可通过混合精度优化。

Conclusion: 该研究通过引入监督语义分割工作流程，显著提升了烧毁区域（BAs）划分的性能和效率，尤其是在紧急管理场景下。虽然SegFormer模型表现与U-Net相当，但其资源需求较高，限制了实际应用。结合土地覆盖数据作为辅助任务可增强模型鲁棒性，而测试时间增强虽提升性能但增加推理时间，可通过混合精度等方法优化。

Abstract: After a wildfire, delineating burned areas (BAs) is crucial for quantifying damages and supporting ecosystem recovery. Current BA mapping approaches rely on computer vision models trained on post-event remote sensing imagery, but often overlook their applicability to time-constrained emergency management scenarios. This study introduces a supervised semantic segmentation workflow aimed at boosting both the performance and efficiency of BA delineation. It targets SPOT-6/7 imagery due to its very high resolution and on-demand availability. Experiments are evaluated based on Dice score, Intersection over Union, and inference time. The results show that U-Net and SegFormer models perform similarly with limited training data. However, SegFormer requires more resources, challenging its practical use in emergencies. Incorporating land cover data as an auxiliary task enhances model robustness without increasing inference time. Lastly, Test-Time Augmentation improves BA delineation performance but raises inference time, which can be mitigated with optimization methods like Mixed Precision.

</details>


### [32] [CreativeVR: Diffusion-Prior-Guided Approach for Structure and Motion Restoration in Generative and Real Videos](https://arxiv.org/abs/2512.12060)
*Tejas Panambur,Ishan Rajendrakumar Dave,Chongjian Ge,Ersin Yumer,Xue Bai*

Main category: cs.CV

TL;DR: CreativeVR 是一个针对AI生成和真实视频中严重结构和时间伪影的修复框架，通过深度适配器方法和时间一致性退化模块，实现了在标准退化和挑战性内容之间的平滑权衡，取得了最先进的结果。


<details>
  <summary>Details</summary>
Motivation: 现代文本到视频（T2V）扩散模型在细尺度结构上表现脆弱，生成视频常出现扭曲的面部和手部、变形的背景及时间不一致的运动，现有修复方法难以有效处理这些严重结构伪影。

Method: 采用深度适配器方法和时间一致性退化模块，通过训练时应用精心设计的变换来模拟真实的结构失效。

Result: CreativeVR 在严重伪影视频上取得了最先进的结果，并在标准视频修复基准上表现优异，同时保持了实用的吞吐量（单块80GB A100上720p约13 FPS）。

Conclusion: CreativeVR 是一个针对AI生成和真实视频中严重结构和时间伪影的修复框架，通过深度适配器方法和时间一致性退化模块，实现了在标准退化和挑战性内容之间的平滑权衡。

Abstract: Modern text-to-video (T2V) diffusion models can synthesize visually compelling clips, yet they remain brittle at fine-scale structure: even state-of-the-art generators often produce distorted faces and hands, warped backgrounds, and temporally inconsistent motion. Such severe structural artifacts also appear in very low-quality real-world videos. Classical video restoration and super-resolution (VR/VSR) methods, in contrast, are tuned for synthetic degradations such as blur and downsampling and tend to stabilize these artifacts rather than repair them, while diffusion-prior restorers are usually trained on photometric noise and offer little control over the trade-off between perceptual quality and fidelity.
  We introduce CreativeVR, a diffusion-prior-guided video restoration framework for AI-generated (AIGC) and real videos with severe structural and temporal artifacts. Our deep-adapter-based method exposes a single precision knob that controls how strongly the model follows the input, smoothly trading off between precise restoration on standard degradations and stronger structure- and motion-corrective behavior on challenging content. Our key novelty is a temporally coherent degradation module used during training, which applies carefully designed transformations that produce realistic structural failures.
  To evaluate AIGC-artifact restoration, we propose the AIGC54 benchmark with FIQA, semantic and perceptual metrics, and multi-aspect scoring. CreativeVR achieves state-of-the-art results on videos with severe artifacts and performs competitively on standard video restoration benchmarks, while running at practical throughput (about 13 FPS at 720p on a single 80-GB A100). Project page: https://daveishan.github.io/creativevr-webpage/.

</details>


### [33] [BAgger: Backwards Aggregation for Mitigating Drift in Autoregressive Video Diffusion Models](https://arxiv.org/abs/2512.12080)
*Ryan Po,Eric Ryan Chan,Changan Chen,Gordon Wetzstein*

Main category: cs.CV

TL;DR: BAgger是一种自监督方案，通过纠正自生成帧的轨迹，有效解决了自回归视频模型的曝光偏差问题。


<details>
  <summary>Details</summary>
Motivation: 自回归视频模型在训练和推理阶段存在曝光偏差，导致误差累积和质量漂移。

Method: BAgger采用标准分数或流匹配目标进行训练，避免了依赖大模型和长链时间反向传播的方法。

Result: 在文本到视频、视频扩展和多提示生成任务中，BAgger表现出更稳定的长时程运动和减少的漂移现象。

Conclusion: BAgger通过自监督方案有效解决了自回归视频模型中的曝光偏差问题，提升了长时程运动的稳定性和视觉一致性。

Abstract: Autoregressive video models are promising for world modeling via next-frame prediction, but they suffer from exposure bias: a mismatch between training on clean contexts and inference on self-generated frames, causing errors to compound and quality to drift over time. We introduce Backwards Aggregation (BAgger), a self-supervised scheme that constructs corrective trajectories from the model's own rollouts, teaching it to recover from its mistakes. Unlike prior approaches that rely on few-step distillation and distribution-matching losses, which can hurt quality and diversity, BAgger trains with standard score or flow matching objectives, avoiding large teachers and long-chain backpropagation through time. We instantiate BAgger on causal diffusion transformers and evaluate on text-to-video, video extension, and multi-prompt generation, observing more stable long-horizon motion and better visual consistency with reduced drift.

</details>


### [34] [RePack: Representation Packing of Vision Foundation Model Features Enhances Diffusion Transformer](https://arxiv.org/abs/2512.12083)
*Guanfang Dong,Luke Schultz,Negar Hassanpour,Chao Gao*

Main category: cs.CV

TL;DR: RePack通过低维流形投影优化VFM表示，加速DiT收敛并提升图像重建性能。


<details>
  <summary>Details</summary>
Motivation: 高维VFM表示可能导致信息过载，特别是在VFM特征尺寸超过原始图像解码尺寸时。RePack旨在解决这一问题，同时保留VFM特征的实用性。

Method: RePack通过将VFM表示投影到低维流形上，将其转换为更紧凑、解码器友好的表示，有效过滤非语义噪声并保留高保真重建所需的核心结构信息。

Result: 在DiT-XL/2上，RePack仅用64个epoch就达到了3.66的FID，比现有技术方法快35%。

Conclusion: RePack成功提取了VFM表示的核心语义，同时避免了其高维度副作用，显著加速了DiT的收敛速度，并在图像重建任务中优于直接注入原始VFM特征的方法。

Abstract: The superior representation capability of pre-trained vision foundation models (VFMs) has been harnessed for enhancing latent diffusion models (LDMs). These approaches inject the rich semantics from high-dimensional VFM representations (e.g., DINOv3) into LDMs at different phases, resulting in accelerated learning and better generation performance. However, the high-dimensionality of VFM representations may also lead to Information Overload, particularly when the VFM features exceed the size of the original image for decoding. To address this issue while preserving the utility of VFM features, we propose RePack (Representation Packing), a simple yet effective framework for improving Diffusion Transformers (DiTs). RePack transforms the VFM representation into a more compact, decoder-friendly representation by projecting onto low-dimensional manifolds. We find that RePack can effectively filter out non-semantic noise while preserving the core structural information needed for high-fidelity reconstruction. Experimental results show that RePack significantly accelerates DiT convergence and outperforms recent methods that directly inject raw VFM features into the decoder for image reconstruction. On DiT-XL/2, RePack achieves an FID of 3.66 in only 64 epochs, which is 35% faster than the state-of-the-art method. This demonstrates that RePack successfully extracts the core semantics of VFM representations while bypassing their high-dimensionality side effects.

</details>


### [35] [VEGAS: Mitigating Hallucinations in Large Vision-Language Models via Vision-Encoder Attention Guided Adaptive Steering](https://arxiv.org/abs/2512.12089)
*Zihu Wang,Boxun Xu,Yuxuan Xia,Peng Li*

Main category: cs.CV

TL;DR: VEGAS通过整合视觉编码器的注意力图到语言模型中间层，有效减少大型视觉语言模型的幻觉现象。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）在视觉和文本输入联合推理方面表现出色，但常产生与视觉证据事实不一致的输出（即幻觉）。研究旨在探索何种视觉注意力形式能有效抑制解码过程中的幻觉。

Method: 提出VEGAS方法，即在推理时将视觉编码器的注意力图整合到语言模型的中间层，并自适应地引导未能集中关注关键图像对象的标记。

Result: 实验表明，VEGAS能显著减少幻觉，并在多个基准测试中表现优异。

Conclusion: VEGAS通过将视觉编码器的注意力图注入语言模型的中间层，有效减少了大型视觉语言模型中的幻觉现象，并在多个基准测试中取得了最先进的性能。

Abstract: Large vision-language models (LVLMs) exhibit impressive ability to jointly reason over visual and textual inputs. However, they often produce outputs that are linguistically fluent but factually inconsistent with the visual evidence, i.e., they hallucinate. Despite growing efforts to mitigate such hallucinations, a key question remains: what form of visual attention can effectively suppress hallucinations during decoding? In this work, we provide a simple answer: the vision encoder's own attention map. We show that LVLMs tend to hallucinate when their final visual-attention maps fail to concentrate on key image objects, whereas the vision encoder's more concentrated attention maps substantially reduce hallucinations. To further investigate the cause, we analyze vision-text conflicts during decoding and find that these conflicts peak in the language model's middle layers. Injecting the vision encoder's attention maps into these layers effectively suppresses hallucinations. Building on these insights, we introduce VEGAS, a simple yet effective inference-time method that integrates the vision encoder's attention maps into the language model's mid-layers and adaptively steers tokens which fail to concentrate on key image objects. Extensive experiments across multiple benchmarks demonstrate that VEGAS consistently achieves state-of-the-art performance in reducing hallucinations.

</details>


### [36] [SPDMark: Selective Parameter Displacement for Robust Video Watermarking](https://arxiv.org/abs/2512.12090)
*Samar Fares,Nurbek Tastan,Karthik Nandakumar*

Main category: cs.CV

TL;DR: SPDMark是一种新型视频水印框架，通过选择性参数位移和LoRA技术，在生成视频中嵌入不可感知且鲁棒的水印。


<details>
  <summary>Details</summary>
Motivation: 现有视频水印方法无法同时满足不可感知性、鲁棒性和计算效率的需求，需要一种新的框架来解决这一问题。

Method: 通过选择性参数位移（SPDMark）和低秩适应（LoRA）技术，在视频扩散模型中嵌入水印。训练阶段联合优化水印提取器、感知相似性和时间一致性损失。

Result: SPDMark在文本到视频和图像到视频生成模型中均能生成不可感知的水印，并能在多种常见视频修改后高精度恢复。

Conclusion: SPDMark框架成功实现了在视频生成过程中嵌入水印，同时保证了不可感知性、鲁棒性和计算效率。

Abstract: The advent of high-quality video generation models has amplified the need for robust watermarking schemes that can be used to reliably detect and track the provenance of generated videos. Existing video watermarking methods based on both post-hoc and in-generation approaches fail to simultaneously achieve imperceptibility, robustness, and computational efficiency. This work introduces a novel framework for in-generation video watermarking called SPDMark (pronounced `SpeedMark') based on selective parameter displacement of a video diffusion model. Watermarks are embedded into the generated videos by modifying a subset of parameters in the generative model. To make the problem tractable, the displacement is modeled as an additive composition of layer-wise basis shifts, where the final composition is indexed by the watermarking key. For parameter efficiency, this work specifically leverages low-rank adaptation (LoRA) to implement the basis shifts. During the training phase, the basis shifts and the watermark extractor are jointly learned by minimizing a combination of message recovery, perceptual similarity, and temporal consistency losses. To detect and localize temporal modifications in the watermarked videos, we use a cryptographic hashing function to derive frame-specific watermark messages from the given base watermarking key. During watermark extraction, maximum bipartite matching is applied to recover the correct frame order, even from temporally tampered videos. Evaluations on both text-to-video and image-to-video generation models demonstrate the ability of SPDMark to generate imperceptible watermarks that can be recovered with high accuracy and also establish its robustness against a variety of common video modifications.

</details>


### [37] [AI-Augmented Pollen Recognition in Optical and Holographic Microscopy for Veterinary Imaging](https://arxiv.org/abs/2512.12101)
*Swarn S. Warshaneyan,Maksims Ivanovs,Blaž Cugmas,Inese Bērziņa,Laura Goldberga,Mindaugas Tamosiunas,Roberts Kadiķis*

Main category: cs.CV

TL;DR: Study on automated pollen recognition using optical and DIHM images, showing GAN-based augmentation improves DIHM performance, narrowing the gap with optical data.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of visually recognizing pollen in unreconstructed holographic images due to speckle noise, twin-image artifacts, and divergence from bright-field appearances.

Method: Training YOLOv8s for object detection and MobileNetV3L for classification on a dual-modality dataset, and employing a Wasserstein GAN with spectral normalization (WGAN-SN) to create synthetic DIHM images.

Result: On optical data, detection mAP50 reaches 91.3% and classification accuracy reaches 97%, whereas on DIHM data, detection mAP50 is 8.15% and classification accuracy is 50%. Expanding bounding boxes improves DIHM detection mAP50 to 13.3% and classification accuracy to 54%. Mixing real-world and synthetic data improves object detection up to 15.4%.

Conclusion: GAN-based augmentation can reduce the performance divide between optical and DIHM images, bringing fully automated DIHM workflows for veterinary imaging closer to practice.

Abstract: We present a comprehensive study on fully automated pollen recognition across both conventional optical and digital in-line holographic microscopy (DIHM) images of sample slides. Visually recognizing pollen in unreconstructed holographic images remains challenging due to speckle noise, twin-image artifacts and substantial divergence from bright-field appearances. We establish the performance baseline by training YOLOv8s for object detection and MobileNetV3L for classification on a dual-modality dataset of automatically annotated optical and affinely aligned DIHM images. On optical data, detection mAP50 reaches 91.3% and classification accuracy reaches 97%, whereas on DIHM data, we achieve only 8.15% for detection mAP50 and 50% for classification accuracy. Expanding the bounding boxes of pollens in DIHM images over those acquired in aligned optical images achieves 13.3% for detection mAP50 and 54% for classification accuracy. To improve object detection in DIHM images, we employ a Wasserstein GAN with spectral normalization (WGAN-SN) to create synthetic DIHM images, yielding an FID score of 58.246. Mixing real-world and synthetic data at the 1.0 : 1.5 ratio for DIHM images improves object detection up to 15.4%. These results demonstrate that GAN-based augmentation can reduce the performance divide, bringing fully automated DIHM workflows for veterinary imaging a small but important step closer to practice.

</details>


### [38] [EchoVLM: Measurement-Grounded Multimodal Learning for Echocardiography](https://arxiv.org/abs/2512.12107)
*Yuheng Li,Yue Zhang,Abdoul Aziz Amadou,Yuxiang Lai,Jike Zhong,Tiziano Passerini,Dorin Comaniciu,Puneet Sharma*

Main category: cs.CV

TL;DR: 提出了首个测量基础的多模态超声心动图数据集EchoGround-MIMIC和视觉语言模型EchoVLM，在多种临床任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 超声心动图解释需要多模态处理，但现有视觉语言模型在该领域的应用受限于缺乏大规模临床基础的数据集和测量推理。

Method: 提出了EchoVLM，一种视觉语言模型，包含两种新的预训练目标：视图感知对比损失和否定感知对比损失。

Result: EchoVLM在36项任务中实现了最先进的性能（零样本疾病分类AUC为86.5%，视图分类准确率为95.1%）。

Conclusion: EchoVLM被确立为一种端到端超声心动图解释的基础模型，其临床基础的多模态预训练能产生可转移的视觉表示。

Abstract: Echocardiography is the most widely used imaging modality in cardiology, yet its interpretation remains labor-intensive and inherently multimodal, requiring view recognition, quantitative measurements, qualitative assessments, and guideline-based reasoning. While recent vision-language models (VLMs) have achieved broad success in natural images and certain medical domains, their potential in echocardiography has been limited by the lack of large-scale, clinically grounded image-text datasets and the absence of measurement-based reasoning central to echo interpretation. We introduce EchoGround-MIMIC, the first measurement-grounded multimodal echocardiography dataset, comprising 19,065 image-text pairs from 1,572 patients with standardized views, structured measurements, measurement-grounded captions, and guideline-derived disease labels. Building on this resource, we propose EchoVLM, a vision-language model that incorporates two novel pretraining objectives: (i) a view-informed contrastive loss that encodes the view-dependent structure of echocardiographic imaging, and (ii) a negation-aware contrastive loss that distinguishes clinically critical negative from positive findings. Across five types of clinical applications with 36 tasks spanning multimodal disease classification, image-text retrieval, view classification, chamber segmentation, and landmark detection, EchoVLM achieves state-of-the-art performance (86.5% AUC in zero-shot disease classification and 95.1% accuracy in view classification). We demonstrate that clinically grounded multimodal pretraining yields transferable visual representations and establish EchoVLM as a foundation model for end-to-end echocardiography interpretation. We will release EchoGround-MIMIC and the data curation code, enabling reproducibility and further research in multimodal echocardiography interpretation.

</details>


### [39] [A Novel Patch-Based TDA Approach for Computed Tomography](https://arxiv.org/abs/2512.12108)
*Dashti A. Ali,Aras T. Asaad,Jacob J. Peoples,Mohammad Hamghalam,Alex Robins,Mane Piliposyan,Richard K. G. Do,Natalie Gangai,Yun S. Chun,Ahmad Bashir Barekzai,Jayasree Chakraborty,Hala Khasawneh,Camila Vilela,Natally Horvat,João Miranda,Alice C. Wei,Amber L. Simpson*

Main category: cs.CV

TL;DR: 提出了一种针对CT图像的补丁持久同调方法，性能优于传统方法，并开源了Python工具包。


<details>
  <summary>Details</summary>
Motivation: 传统3D立方体复形过滤方法在计算复杂性和性能上存在局限，需开发更高效的拓扑数据分析（TDA）方法。

Method: 采用基于补丁的持久同调构建方法，针对体积医学成像数据（尤其是CT模态）进行了优化，并通过多数据集实验验证其性能。

Result: 提出的方法在分类性能和时间效率上均优于立方体复形算法，各项指标平均提升显著（如准确率提升10.38%）。

Conclusion: 该研究提出了一种基于补丁的持久同调（PH）构建方法，显著提升了3D CT图像的分类性能和时间效率，并提供了便捷的Python工具包Patch-TDA。

Abstract: The development of machine learning (ML) models based on computed tomography (CT) imaging modality has been a major focus of recent research in the medical imaging domain. Incorporating robust feature engineering approach can highly improve the performance of these models. Topological data analysis (TDA), a recent development based on the mathematical field of algebraic topology, mainly focuses on the data from a topological perspective, extracting deeper insight and higher dimensional structures from the data. Persistent homology (PH), a fundamental tool in the area of TDA, can extract topological features such as connected components, cycles and voids from the data. A popular approach to construct PH from 3D CT images is to utilize the 3D cubical complex filtration, a method adapted for grid-structured data. However, this approach may not always yield the best performance and can suffer from computational complexity with higher resolution CT images. This study introduces a novel patch-based PH construction approach tailored for volumetric medical imaging data, in particular CT modality. A wide range of experiments has been conducted on several datasets of 3D CT images to comprehensively analyze the performance of the proposed method with various parameters and benchmark it against the 3D cubical complex algorithm. Our results highlight the dominance of the patch-based TDA approach in terms of both classification performance and time-efficiency. The proposed approach outperformed the cubical complex method, achieving average improvement of 10.38%, 6.94%, 2.06%, 11.58%, and 8.51% in accuracy, AUC, sensitivity, specificity, and F1 score, respectively, across all datasets. Finally, we provide a convenient python package, Patch-TDA, to facilitate the utilization of the proposed approach.

</details>


### [40] [A Benchmark Dataset for Spatially Aligned Road Damage Assessment in Small Uncrewed Aerial Systems Disaster Imagery](https://arxiv.org/abs/2512.12128)
*Thomas Manzini,Priyankari Perali,Raisa Karnik,Robin R. Murphy*

Main category: cs.CV

TL;DR: 本文构建了最大灾害道路损伤评估数据集和18个基线模型，验证了实际应用效果，并指出空间对齐对性能的关键影响。


<details>
  <summary>Details</summary>
Motivation: 现有灾害道路损伤评估数据集规模小或依赖低分辨率影像，无法满足应急管理需求，且缺乏经过操作验证的ML系统。本文旨在填补这些空白。

Method: 利用CRASAR-U-DRIODs数据集的sUAS影像，标注了657.25公里的道路数据（采用10类标签体系），并训练了18个基线模型。在实际灾害响应中部署模型，并提供了9,184条道路线的空间对齐调整。

Result: 模型在真实灾害响应中表现良好，但若忽略空间对齐，模型性能平均下降5.596% Macro IoU，且可能导致11公里道路条件误标和59公里道路线错位。

Conclusion: 本文通过构建最大规模的基准数据集和18个基线模型，解决了现有灾害后道路损伤评估数据集的不足，并验证了模型在实际灾害响应中的有效性。同时，强调了空间对齐对模型性能的关键影响，呼吁ML、CV和机器人社区关注这一问题以提升灾害决策效率。

Abstract: This paper presents the largest known benchmark dataset for road damage assessment and road alignment, and provides 18 baseline models trained on the CRASAR-U-DRIODs dataset's post-disaster small uncrewed aerial systems (sUAS) imagery from 10 federally declared disasters, addressing three challenges within prior post-disaster road damage assessment datasets. While prior disaster road damage assessment datasets exist, there is no current state of practice, as prior public datasets have either been small-scale or reliant on low-resolution imagery insufficient for detecting phenomena of interest to emergency managers. Further, while machine learning (ML) systems have been developed for this task previously, none are known to have been operationally validated. These limitations are overcome in this work through the labeling of 657.25km of roads according to a 10-class labeling schema, followed by training and deploying ML models during the operational response to Hurricanes Debby and Helene in 2024. Motivated by observed road line misalignment in practice, 9,184 road line adjustments were provided for spatial alignment of a priori road lines, as it was found that when the 18 baseline models are deployed against real-world misaligned road lines, model performance degraded on average by 5.596\% Macro IoU. If spatial alignment is not considered, approximately 8\% (11km) of adverse conditions on road lines will be labeled incorrectly, with approximately 9\% (59km) of road lines misaligned off the actual road. These dynamics are gaps that should be addressed by the ML, CV, and robotics communities to enable more effective and informed decision-making during disasters.

</details>


### [41] [MeltwaterBench: Deep learning for spatiotemporal downscaling of surface meltwater](https://arxiv.org/abs/2512.12142)
*Björn Lütjens,Patrick Alexander,Raf Antwerpen,Til Widmann,Guido Cervone,Marco Tedesco*

Main category: cs.CV

TL;DR: 深度学习模型融合多源数据，生成每日100米分辨率的格陵兰冰盖融水地图，准确率提升至95%。


<details>
  <summary>Details</summary>
Motivation: 当前融水地图在时间和空间分辨率上存在权衡，无法同时满足高时空分辨率需求，限制了融水分布对冰盖融化过程的理解。

Method: 开发了一种深度学习模型，融合了合成孔径雷达（SAR）、被动微波（PMW）和数字高程模型（DEM）数据，对区域气候模型（RCM）输出进行时空降尺度处理。

Result: 深度学习模型在Helheim冰川区域的准确率达到95%，显著优于仅依赖区域气候模型（83%）或被动微波观测（72%）的方法。

Conclusion: 通过融合多源遥感数据和物理模型，深度学习模型显著提高了格陵兰冰盖表面融水地图的时空分辨率（每日100米分辨率），准确率比现有非深度学习方法高出10个百分点以上。

Abstract: The Greenland ice sheet is melting at an accelerated rate due to processes that are not fully understood and hard to measure. The distribution of surface meltwater can help understand these processes and is observable through remote sensing, but current maps of meltwater face a trade-off: They are either high-resolution in time or space, but not both. We develop a deep learning model that creates gridded surface meltwater maps at daily 100m resolution by fusing data streams from remote sensing observations and physics-based models. In particular, we spatiotemporally downscale regional climate model (RCM) outputs using synthetic aperture radar (SAR), passive microwave (PMW), and a digital elevation model (DEM) over the Helheim Glacier in Eastern Greenland from 2017-2023. Using SAR-derived meltwater as "ground truth", we show that a deep learning-based method that fuses all data streams is over 10 percentage points more accurate over our study area than existing non deep learning-based approaches that only rely on a regional climate model (83% vs. 95% Acc.) or passive microwave observations (72% vs. 95% Acc.). Alternatively, creating a gridded product through a running window calculation with SAR data underestimates extreme melt events, but also achieves notable accuracy (90%) and does not rely on deep learning. We evaluate standard deep learning methods (UNet and DeepLabv3+), and publish our spatiotemporally aligned dataset as a benchmark, MeltwaterBench, for intercomparisons with more complex data-driven downscaling methods. The code and data are available at $\href{https://github.com/blutjens/hrmelt}{github.com/blutjens/hrmelt}$.

</details>


### [42] [Open Horizons: Evaluating Deep Models in the Wild](https://arxiv.org/abs/2512.12146)
*Ayush Vaibhav Bhatti,Deniz Karakay,Debottama Das,Nilotpal Rajbongshi,Yuito Sugimoto*

Main category: cs.CV

TL;DR: CLIP在开放集识别中表现最佳，ConCM在少样本增量学习中效果最好，所有方法在5-shot后趋于饱和。


<details>
  <summary>Details</summary>
Motivation: 研究开放世界部署中模型对已知类别的识别能力及对未知类别的可靠性。

Method: 在OSR中比较了三种预训练视觉编码器（ResNet-50、ConvNeXt-Tiny、CLIP ViT-B/16）和四种评分函数（MSP、Energy、Mahalanobis、kNN）；在FSCIL中对比了SPPR、OrCo和ConCM方法。

Result: CLIP在OSR中表现最优，Energy评分函数最稳定；ConCM在FSCIL中10-shot场景下准确率达84.7%。

Conclusion: 研究发现，CLIP在开放集识别（OSR）中表现最优，而ConCM在少样本类增量学习（FSCIL）中表现最佳。此外，所有方法在5-shot后表现趋于饱和。

Abstract: Open-world deployment requires models to recognize both known categories and remain reliable when novel classes appear. We present a unified experimental study spanning open-set recognition (OSR) and few-shot class-incremental learning (FSCIL) on CIFAR-10. For OSR, we compare three pretrained frozen visual encoders: ResNet-50, ConvNeXt-Tiny and CLIP ViT-B/16,using a linear probe and four post-hoc scoring functions, namely MSP, Energy, Mahalanobis and kNN. Across metrics,such as, AUROC, AUPR, FPR@95, and OSCR, CLIP consistently yields the strongest separability between known and unknown samples, with Energy providing the most stable performance across backbones. For FSCIL, we compare modified SPPR, OrCo, and ConCM using partially frozen ResNet-50 across 1-, 5-, and 10-shot scenarios. ConCM achieves 84.7% accuracy in the 10-shot setting with the cleanest confusion matrix, while all methods show saturation beyond 5 shots. Our controlled evaluation reveals how the backbone architecture and scoring mechanisms affect unknown detection and how prototype-based methods mitigate catastrophic forgetting during incremental adaptation.

</details>


### [43] [Audio-Visual Camera Pose Estimationn with Passive Scene Sounds and In-the-Wild Video](https://arxiv.org/abs/2512.12165)
*Daniel Adebi,Sagnik Majumder,Kristen Grauman*

Main category: cs.CV

TL;DR: 通过音频-视觉融合框架，利用场景声音辅助相机姿态估计，提升了在视觉退化条件下的性能。


<details>
  <summary>Details</summary>
Motivation: 视觉方法在视觉退化条件下（如运动模糊或遮挡）表现不佳，而被动场景声音提供了互补的线索。

Method: 提出了一个简单但有效的音频-视觉框架，将到达方向（DOA）频谱和双耳化嵌入集成到最先进的纯视觉姿态估计模型中。

Result: 在两个大型数据集上的实验表明，该方法在视觉信息受损时仍保持稳健性，并显著优于纯视觉基线。

Conclusion: 本研究首次成功利用音频信号辅助相对相机姿态估计，证明了日常音频在经典空间挑战中的潜在价值。

Abstract: Understanding camera motion is a fundamental problem in embodied perception and 3D scene understanding. While visual methods have advanced rapidly, they often struggle under visually degraded conditions such as motion blur or occlusions. In this work, we show that passive scene sounds provide complementary cues for relative camera pose estimation for in-the-wild videos. We introduce a simple but effective audio-visual framework that integrates direction-ofarrival (DOA) spectra and binauralized embeddings into a state-of-the-art vision-only pose estimation model. Our results on two large datasets show consistent gains over strong visual baselines, plus robustness when the visual information is corrupted. To our knowledge, this represents the first work to successfully leverage audio for relative camera pose estimation in real-world videos, and it establishes incidental, everyday audio as an unexpected but promising signal for a classic spatial challenge. Project: http://vision.cs.utexas.edu/projects/av_camera_pose.

</details>


### [44] [SMRABooth: Subject and Motion Representation Alignment for Customized Video Generation](https://arxiv.org/abs/2512.12193)
*Xuancheng Xu,Yaning Li,Sisi You,Bing-Kun Bao*

Main category: cs.CV

TL;DR: SMRABooth通过自监督和光流编码器提供对象级别的主题和运动表示，采用三阶段方法有效解决定制视频生成中的主题和运动一致性问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在定制视频生成中难以同时保证主题外观相似性和运动模式一致性，缺乏对象级别的主题和运动指导。

Method: SMRABooth采用三阶段方法：(1)通过自监督编码器提取主题表示以指导主题对齐；(2)利用光流编码器捕获结构一致的对象级别运动轨迹；(3)提出主题-运动关联解耦策略，通过稀疏LoRA注入减少干扰。

Result: 实验证明SMRABooth在主题和运动定制方面表现优异，能保持一致的视频生成效果。

Conclusion: SMRABooth通过自监督编码器和光流编码器提供对象级别的主题和运动表示，并通过LoRA微调过程对齐这些表示，有效解决了现有方法在保持主题外观相似性和运动模式一致性方面的不足。

Abstract: Customized video generation aims to produce videos that faithfully preserve the subject's appearance from reference images while maintaining temporally consistent motion from reference videos. Existing methods struggle to ensure both subject appearance similarity and motion pattern consistency due to the lack of object-level guidance for subject and motion. To address this, we propose SMRABooth, which leverages the self-supervised encoder and optical flow encoder to provide object-level subject and motion representations. These representations are aligned with the model during the LoRA fine-tuning process. Our approach is structured in three core stages: (1) We exploit subject representations via a self-supervised encoder to guide subject alignment, enabling the model to capture overall structure of subject and enhance high-level semantic consistency. (2) We utilize motion representations from an optical flow encoder to capture structurally coherent and object-level motion trajectories independent of appearance. (3) We propose a subject-motion association decoupling strategy that applies sparse LoRAs injection across both locations and timing, effectively reducing interference between subject and motion LoRAs. Extensive experiments show that SMRABooth excels in subject and motion customization, maintaining consistent subject appearance and motion patterns, proving its effectiveness in controllable text-to-video generation.

</details>


### [45] [Thermal RGB Fusion for Micro-UAV Wildfire Perimeter Tracking with Minimal Comms](https://arxiv.org/abs/2512.12199)
*Ercan Erkalkan,Vedat Topuz,Ayça Ak*

Main category: cs.CV

TL;DR: 轻量级周界跟踪方法，结合热成像和RGB处理，优化计算和通信需求，适用于野火环境中的微型无人机团队，实现快速部署和稳定跟踪。


<details>
  <summary>Details</summary>
Motivation: 针对野火环境中微型无人机团队在有限带宽条件下的快速部署和稳定跟踪需求，开发轻量级周界跟踪方法。

Method: 结合热成像和RGB图像处理，采用自适应阈值和形态学细化生成热区域掩码，利用梯度滤波抑制误检，并通过规则级合并策略和Ramer Douglas Peucker算法简化边界候选。系统还集成了周期性信标和惯性反馈环以保持轨迹稳定性。

Result: 小规模模拟显示，与纯边缘跟踪基线相比，平均路径长度和边界抖动减少，同时保持环境覆盖。电池消耗和计算利用率证实了在标准微型平台上实现10-15 m/s前向运动的可行性。

Conclusion: 该研究提出了一种轻量级周界跟踪方法，适用于带宽受限的野火环境中的微型无人机团队，通过优化计算和通信需求，实现了快速部署和稳定跟踪。

Abstract: This study introduces a lightweight perimeter tracking method designed for micro UAV teams operating over wildfire environments under limited bandwidth conditions. Thermal image frames generate coarse hot region masks through adaptive thresholding and morphological refinement, while RGB frames contribute edge cues and suppress texture related false detections using gradient based filtering. A rule level merging strategy selects boundary candidates and simplifies them via the Ramer Douglas Peucker algorithm. The system incorporates periodic beacons and an inertial feedback loop that maintains trajectory stability in the presence of GPS degradation. The guidance loop targets sub 50 ms latency on embedded System on Chip (SoC) platforms by constraining per frame pixel operations and precomputing gradient tables. Small scale simulations demonstrate reductions in average path length and boundary jitter compared to a pure edge tracking baseline, while maintaining environmental coverage measured through intersection merge analysis. Battery consumption and computational utilization confirm the feasibility of achieving 10, 15 m/s forward motion on standard micro platforms. This approach enables rapid deployment in the field, requiring robust sensing and minimal communications for emergency reconnaissance applications.

</details>


### [46] [A Multi-Year Urban Streetlight Imagery Dataset for Visual Monitoring and Spatio-Temporal Drift Detection](https://arxiv.org/abs/2512.12205)
*Peizheng Li,Ioannis Mavromatis,Ajith Sahadevan,Tim Farnham,Adnan Aijaz,Aftab Khan*

Main category: cs.CV

TL;DR: 一个大规模、纵向的城市街灯视觉数据集，包含52.6万张图像，附带元数据，支持视觉漂移和MLOps研究，并提供了自监督学习框架。


<details>
  <summary>Details</summary>
Motivation: 为智能城市部署中的视觉漂移、异常检测和MLOps策略的详细研究提供独特的真实世界数据集。

Method: 提供了一个基于卷积变分自编码器（CNN-VAEs）的自监督框架，模型针对每个摄像头节点和白天/夜间图像集分别训练。定义了两种样本漂移度量：相对质心漂移和相对重建误差。

Result: 数据集包含超过526,000张图像，涵盖多样化的光照、天气和季节条件，并附带丰富的元数据。

Conclusion: 该数据集为评估长期模型稳定性、漂移感知学习和部署就绪的视觉系统提供了一个现实、细粒度的基准。图像和结构化元数据以JPEG和CSV格式公开发布，支持可重复性和下游应用。

Abstract: We present a large-scale, longitudinal visual dataset of urban streetlights captured by 22 fixed-angle cameras deployed across Bristol, U.K., from 2021 to 2025. The dataset contains over 526,000 images, collected hourly under diverse lighting, weather, and seasonal conditions. Each image is accompanied by rich metadata, including timestamps, GPS coordinates, and device identifiers. This unique real-world dataset enables detailed investigation of visual drift, anomaly detection, and MLOps strategies in smart city deployments. To promtoe seconardary analysis, we additionally provide a self-supervised framework based on convolutional variational autoencoders (CNN-VAEs). Models are trained separately for each camera node and for day/night image sets. We define two per-sample drift metrics: relative centroid drift, capturing latent space deviation from a baseline quarter, and relative reconstruction error, measuring normalized image-domain degradation. This dataset provides a realistic, fine-grained benchmark for evaluating long-term model stability, drift-aware learning, and deployment-ready vision systems. The images and structured metadata are publicly released in JPEG and CSV formats, supporting reproducibility and downstream applications such as streetlight monitoring, weather inference, and urban scene understanding. The dataset can be found at https://doi.org/10.5281/zenodo.17781192 and https://doi.org/10.5281/zenodo.17859120.

</details>


### [47] [ALERT Open Dataset and Input-Size-Agnostic Vision Transformer for Driver Activity Recognition using IR-UWB](https://arxiv.org/abs/2512.12206)
*Jeongjun Park,Sunwook Hwang,Hyeonho Noh,Jin Mo Yang,Hyun Jong Yang,Saewoong Bahk*

Main category: cs.CV

TL;DR: 研究提出ALERT数据集和ISA-ViT框架，解决了UWB雷达在DAR中的数据集和ViT适应性问题，显著提升了分类性能。


<details>
  <summary>Details</summary>
Motivation: 分心驾驶导致全球致命事故，而现有IR-UWB雷达在DAR应用中面临两大挑战：缺乏大规模真实世界UWB数据集和固定输入ViT难以适应非标准维度UWB雷达数据。

Method: 提出了输入大小无关的Vision Transformer（ISA-ViT）框架，通过调整补丁配置和利用预训练的位置嵌入向量（PEVs）来克服朴素调整方法的限制，并结合范围域和频域特征的领域融合策略。

Result: ISA-ViT在基于UWB的DAR任务中比现有ViT方法提高了22.68%的准确率。

Conclusion: 本研究通过公开ALERT数据集和详细说明输入大小无关策略，促进了更健壮和可扩展的分心驾驶检测系统的开发，适用于实际部署。

Abstract: Distracted driving contributes to fatal crashes worldwide. To address this, researchers are using driver activity recognition (DAR) with impulse radio ultra-wideband (IR-UWB) radar, which offers advantages such as interference resistance, low power consumption, and privacy preservation. However, two challenges limit its adoption: the lack of large-scale real-world UWB datasets covering diverse distracted driving behaviors, and the difficulty of adapting fixed-input Vision Transformers (ViTs) to UWB radar data with non-standard dimensions.
  This work addresses both challenges. We present the ALERT dataset, which contains 10,220 radar samples of seven distracted driving activities collected in real driving conditions. We also propose the input-size-agnostic Vision Transformer (ISA-ViT), a framework designed for radar-based DAR. The proposed method resizes UWB data to meet ViT input requirements while preserving radar-specific information such as Doppler shifts and phase characteristics. By adjusting patch configurations and leveraging pre-trained positional embedding vectors (PEVs), ISA-ViT overcomes the limitations of naive resizing approaches. In addition, a domain fusion strategy combines range- and frequency-domain features to further improve classification performance.
  Comprehensive experiments demonstrate that ISA-ViT achieves a 22.68% accuracy improvement over an existing ViT-based approach for UWB-based DAR. By publicly releasing the ALERT dataset and detailing our input-size-agnostic strategy, this work facilitates the development of more robust and scalable distracted driving detection systems for real-world deployment.

</details>


### [48] [A Hybrid Deep Learning Framework for Emotion Recognition in Children with Autism During NAO Robot-Mediated Interaction](https://arxiv.org/abs/2512.12208)
*Indranil Bhattacharjee,Vartika Narayani Srinet,Anirudha Bhattacharjee,Braj Bhushan,Bishakh Bhattacharya*

Main category: cs.CV

TL;DR: 该研究开发了一种深度学习管道，用于识别自闭症儿童与机器人互动时的情感反应，填补了研究空白并展示了实际应用潜力。


<details>
  <summary>Details</summary>
Motivation: 理解自闭症谱系障碍（ASD）儿童在社交互动中的情感反应是发展心理学和人机交互领域的关键挑战。

Method: 采用结合微调ResNet-50的卷积神经网络（CNN）和三层图卷积网络（GCN）的混合模型，训练于从MediaPipe FaceMesh地标提取的视觉和几何特征。情感通过DeepFace和FER模型的加权集成进行概率标记，最终分类利用通过Kullback-Leibler散度优化的融合嵌入。

Result: 所提出的方法在建模微妙情感反应方面表现出色，为临床和治疗性人机交互中的自闭症儿童情感分析提供了重要前景。

Conclusion: 该研究提出了一种新颖的深度学习管道，用于在自闭症儿童与机器人互动时识别其情感反应，填补了自闭症特定人机交互研究的空白，并为未来个性化辅助技术奠定了基础。

Abstract: Understanding emotional responses in children with Autism Spectrum Disorder (ASD) during social interaction remains a critical challenge in both developmental psychology and human-robot interaction. This study presents a novel deep learning pipeline for emotion recognition in autistic children in response to a name-calling event by a humanoid robot (NAO), under controlled experimental settings. The dataset comprises of around 50,000 facial frames extracted from video recordings of 15 children with ASD. A hybrid model combining a fine-tuned ResNet-50-based Convolutional Neural Network (CNN) and a three-layer Graph Convolutional Network (GCN) trained on both visual and geometric features extracted from MediaPipe FaceMesh landmarks. Emotions were probabilistically labeled using a weighted ensemble of two models: DeepFace's and FER, each contributing to soft-label generation across seven emotion classes. Final classification leveraged a fused embedding optimized via Kullback-Leibler divergence. The proposed method demonstrates robust performance in modeling subtle affective responses and offers significant promise for affective profiling of ASD children in clinical and therapeutic human-robot interaction contexts, as the pipeline effectively captures micro emotional cues in neurodivergent children, addressing a major gap in autism-specific HRI research. This work represents the first such large-scale, real-world dataset and pipeline from India on autism-focused emotion analysis using social robotics, contributing an essential foundation for future personalized assistive technologies.

</details>


### [49] [CineLOG: A Training Free Approach for Cinematic Long Video Generation](https://arxiv.org/abs/2512.12209)
*Zahra Dehghanian,Morteza Abolghasemi,Hamid Beigy,Hamid R. Rabiee*

Main category: cs.CV

TL;DR: CineLOG是一个高质量、平衡的视频数据集，结合新颖的流水线，显著提升了可控视频合成的能力。


<details>
  <summary>Details</summary>
Motivation: 解决当前视频合成模型在细粒度控制（如相机轨迹和电影类型）方面的不足，以及现有数据集的数据不平衡、噪声标签和模拟与真实差距的问题。

Method: 提出了一种新颖的流水线，将复杂的文本到视频生成任务分解为四个更简单的阶段，并引入了轨迹引导过渡模块以实现平滑的时空插值。

Result: 人类评估表明，该流水线在遵循特定相机和剧本指令方面显著优于现有的端到端文本到视频模型。

Conclusion: CineLOG数据集和新提出的流水线显著提升了可控视频合成的质量，特别是在遵循特定相机和剧本指令方面，同时保持了专业视觉质量。

Abstract: Controllable video synthesis is a central challenge in computer vision, yet current models struggle with fine grained control beyond textual prompts, particularly for cinematic attributes like camera trajectory and genre. Existing datasets often suffer from severe data imbalance, noisy labels, or a significant simulation to real gap. To address this, we introduce CineLOG, a new dataset of 5,000 high quality, balanced, and uncut video clips. Each entry is annotated with a detailed scene description, explicit camera instructions based on a standard cinematic taxonomy, and genre label, ensuring balanced coverage across 17 diverse camera movements and 15 film genres. We also present our novel pipeline designed to create this dataset, which decouples the complex text to video (T2V) generation task into four easier stages with more mature technology. To enable coherent, multi shot sequences, we introduce a novel Trajectory Guided Transition Module that generates smooth spatio-temporal interpolation. Extensive human evaluations show that our pipeline significantly outperforms SOTA end to end T2V models in adhering to specific camera and screenplay instructions, while maintaining professional visual quality. All codes and data are available at https://cine-log.pages.dev.

</details>


### [50] [Journey Before Destination: On the importance of Visual Faithfulness in Slow Thinking](https://arxiv.org/abs/2512.12218)
*Rheeya Uppaal,Phu Mon Htut,Min Bai,Nikolaos Pappas,Zheng Qi*

Main category: cs.CV

TL;DR: 提出新框架评估和提升视觉语言模型推理链的视觉忠实性，通过无训练方法减少不忠实感知，保持答案准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLMs）在生成显式推理链时，可能存在视觉不忠实的中间步骤或推理正确但最终预测失败的问题。标准评估仅关注最终答案准确性，无法区分这些行为。

Method: 提出了一个无训练和参考的框架，将推理链分解为感知与推理步骤，并利用现成的VLM评估器进行步骤级忠实性验证。此外，设计了一个轻量级自我反思程序，用于检测并局部重建不忠实的感知步骤。

Result: 在多个经过推理训练的VLMs和感知密集型基准测试中，该方法降低了不忠实感知率，同时保持了最终答案的准确性。

Conclusion: 通过提出的无训练和参考框架，以及轻量级自我反思程序，显著降低了视觉语言模型（VLMs）中的不忠实感知率，同时保持了最终答案的准确性，从而提高了多模态推理的可靠性。

Abstract: Reasoning-augmented vision language models (VLMs) generate explicit chains of thought that promise greater capability and transparency but also introduce new failure modes: models may reach correct answers via visually unfaithful intermediate steps, or reason faithfully yet fail on the final prediction. Standard evaluations that only measure final-answer accuracy cannot distinguish these behaviors. We introduce the visual faithfulness of reasoning chains as a distinct evaluation dimension, focusing on whether the perception steps of a reasoning chain are grounded in the image. We propose a training- and reference-free framework that decomposes chains into perception versus reasoning steps and uses off-the-shelf VLM judges for step-level faithfulness, additionally verifying this approach through a human meta-evaluation. Building on this metric, we present a lightweight self-reflection procedure that detects and locally regenerates unfaithful perception steps without any training. Across multiple reasoning-trained VLMs and perception-heavy benchmarks, our method reduces Unfaithful Perception Rate while preserving final-answer accuracy, improving the reliability of multimodal reasoning.

</details>


### [51] [Fine-Grained Zero-Shot Learning with Attribute-Centric Representations](https://arxiv.org/abs/2512.12219)
*Zhi Chen,Jingcai Guo,Taotao Cai,Yuxiang Cai*

Main category: cs.CV

TL;DR: ACR框架通过属性解耦和专家混合组件，解决了零样本学习中的属性纠缠问题，并在多个数据集上实现了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 解决零样本学习中属性纠缠的核心挑战，即传统模型将不同属性（如颜色、形状、纹理）压缩到单一视觉嵌入中，导致关键差异被掩盖。

Method: 提出了AttributeCentric Representations (ACR)框架，包含两个专家混合组件：Mixture of Patch Experts (MoPE)和Mixture of Attribute Experts (MoAE)。MoPE通过双级路由机制将图像块分配给专用专家，MoAE则将专家精炼的特征投影为稀疏的、部分感知的属性映射。

Result: 在CUB、AwA2和SUN等零样本学习基准数据集上，ACR框架取得了最先进的性能。

Conclusion: ACR框架通过在表示学习中强制属性解耦，有效解决了属性纠缠问题，并在多个零样本学习基准数据集上实现了最先进的性能。

Abstract: Recognizing unseen fine-grained categories demands a model that can distinguish subtle visual differences. This is typically achieved by transferring visual-attribute relationships from seen classes to unseen classes. The core challenge is attribute entanglement, where conventional models collapse distinct attributes like color, shape, and texture into a single visual embedding. This causes interference that masks these critical distinctions. The post-hoc solutions of previous work are insufficient, as they operate on representations that are already mixed. We propose a zero-shot learning framework that learns AttributeCentric Representations (ACR) to tackle this problem by imposing attribute disentanglement during representation learning. ACR is achieved with two mixture-of-experts components, including Mixture of Patch Experts (MoPE) and Mixture of Attribute Experts (MoAE). First, MoPE is inserted into the transformer using a dual-level routing mechanism to conditionally dispatch image patches to specialized experts. This ensures coherent attribute families are processed by dedicated experts. Finally, the MoAE head projects these expert-refined features into sparse, partaware attribute maps for robust zero-shot classification. On zero-shot learning benchmark datasets CUB, AwA2, and SUN, our ACR achieves consistent state-of-the-art results.

</details>


### [52] [ProImage-Bench: Rubric-Based Evaluation for Professional Image Generation](https://arxiv.org/abs/2512.12220)
*Minheng Ni,Zhengyuan Yang,Yaowen Zhang,Linjie Li,Chung-Ching Lin,Kevin Lin,Zhendong Wang,Xiaofei Wang,Shujie Liu,Lei Zhang,Wangmeng Zuo,Lijuan Wang*

Main category: cs.CV

TL;DR: ProImage-Bench是一个针对专业图像生成的基准测试，通过详细评分标准和迭代编辑显著提升生成图像的科学精确性。


<details>
  <summary>Details</summary>
Motivation: 研究专业图像生成，旨在从技术描述中合成信息密集、科学精确的插图，而非仅生成视觉上合理的图片。

Method: 引入ProImage-Bench基准，基于654个真实教材和技术报告中的图像，构建详细的图像指令和评分标准，利用大型多模态模型生成评分标准，并通过自动化LMM评估模型性能。

Result: 基准测试显示，最佳基础模型的评分准确率为0.791，标准得分为0.553，表明在细粒度科学保真度上存在显著差距。通过迭代编辑，生成器的评分准确率从0.653提升至0.865，标准得分从0.388提升至0.697。

Conclusion: ProImage-Bench不仅为专业图像生成提供了严格的诊断工具，还通过可扩展的信号改进了符合规范的科学插图。

Abstract: We study professional image generation, where a model must synthesize information-dense, scientifically precise illustrations from technical descriptions rather than merely produce visually plausible pictures. To quantify the progress, we introduce ProImage-Bench, a rubric-based benchmark that targets biology schematics, engineering/patent drawings, and general scientific diagrams. For 654 figures collected from real textbooks and technical reports, we construct detailed image instructions and a hierarchy of rubrics that decompose correctness into 6,076 criteria and 44,131 binary checks. Rubrics are derived from surrounding text and reference figures using large multimodal models, and are evaluated by an automated LMM-based judge with a principled penalty scheme that aggregates sub-question outcomes into interpretable criterion scores. We benchmark several representative text-to-image models on ProImage-Bench and find that, despite strong open-domain performance, the best base model reaches only 0.791 rubric accuracy and 0.553 criterion score overall, revealing substantial gaps in fine-grained scientific fidelity. Finally, we show that the same rubrics provide actionable supervision: feeding failed checks back into an editing model for iterative refinement boosts a strong generator from 0.653 to 0.865 in rubric accuracy and from 0.388 to 0.697 in criterion score. ProImage-Bench thus offers both a rigorous diagnostic for professional image generation and a scalable signal for improving specification-faithful scientific illustrations.

</details>


### [53] [Comparison of different segmentation algorithms on brain volume and fractal dimension in infant brain MRIs](https://arxiv.org/abs/2512.12222)
*Nathalie Alexander,Arnaud Gucciardi,Umberto Michelucci*

Main category: cs.CV

TL;DR: SynthSeg在婴儿脑MRI分割中表现更优，但分割不确定性可能影响体积和FD的小差异解释。


<details>
  <summary>Details</summary>
Motivation: 婴儿脑MRI的准确分割对于量化结构和复杂性的发育变化至关重要，但由于髓鞘化和组织对比度降低，自动分割尤为困难。

Method: 使用Baby Open Brains (BOB)数据集（71次扫描，1-9个月），比较了SynthSeg和SamSeg两种方法的分割准确性及其对体积和分形维度（FD）估计的影响，评估指标包括Dice、IoU、95th-percentile Hausdorff距离和归一化互信息。

Result: SynthSeg在所有质量指标上均优于SamSeg（主要区域平均Dice > 0.8），其体积估计与手动参考接近（平均+4% [-28% - 71%]）。SamSeg系统性高估脑室和全脑体积（平均+76% [-12% - 190%]）。分割准确性随年龄提高，与髓鞘化过程中组织对比度增加一致。分形维度分析显示SynthSeg与专家分割存在显著区域差异，且分割相关的FD变异性超过大多数发育队列中报告的组间差异。

Conclusion: SynthSeg在婴儿脑MRI分割中表现优于SamSeg，提供了更可靠的体积和分形维度结果，但需注意分割相关的不确定性对小形态差异的影响。

Abstract: Accurate segmentation of infant brain MRI is essential for quantifying developmental changes in structure and complexity. However, ongoing myelination and reduced tissue contrast make automated segmentation particularly challenging. This study systematically compared segmentation accuracy and its impact on volumetric and fractal dimension (FD) estimates in infant brain MRI using the Baby Open Brains (BOB) dataset (71 scans, 1-9 months). Two methods, SynthSeg and SamSeg, were evaluated against expert annotations using Dice, Intersection over Union, 95th-percentile Hausdorff distance, and Normalised Mutual Information. SynthSeg outperformed SamSeg across all quality metrics (mean Dice > 0.8 for major regions) and provided volumetric estimates closely matching the manual reference (mean +4% [-28% - 71%]). SamSeg systematically overestimated ventricular and whole-brain volumes (mean +76% [-12% - 190%]). Segmentation accuracy improved with age, consistent with increasing tissue contrast during myelination. Fractal dimension a(FD) nalyses revealed significant regional differences between SynthSeg and expert segmentations, and Bland-Altman limits of agreement indicated that segmentation-related FD variability exceeded most group differences reported in developmental cohorts. Volume and FD deviations were positively correlated across structures, indicating that segmentation bias directly affects FD estimation. Overall, SynthSeg provided the most reliable volumetric and FD results for paediatric MRI, yet small morphological differences in volume and FD should be interpreted with caution due to segmentation-related uncertainty.

</details>


### [54] [Ultra-Low Bitrate Perceptual Image Compression with Shallow Encoder](https://arxiv.org/abs/2512.12229)
*Tianyu Zhang,Dong Liu,Chang Wen Chen*

Main category: cs.CV

TL;DR: 提出AEIC框架，使用浅层编码器和扩散解码器，实现高效超低比特率图像压缩。


<details>
  <summary>Details</summary>
Motivation: 解决现有框架依赖重型编码器网络，不适合在弱发送设备上部署的问题。

Method: 采用浅层编码器网络和一步扩散解码器，设计了双端特征蒸馏方案。

Result: AEIC在超低比特率下表现出色，编码效率高达35.8 FPS（1080P输入），解码速度与现有方法相当。

Conclusion: AEIC框架在超低比特率下不仅优于现有方法，还在保持解码速度的同时实现了高效的编码效率。

Abstract: Ultra-low bitrate image compression (below 0.05 bits per pixel) is increasingly critical for bandwidth-constrained and computation-limited encoding scenarios such as edge devices. Existing frameworks typically rely on large pretrained encoders (e.g., VAEs or tokenizer-based models) and perform transform coding within their generative latent space. While these approaches achieve impressive perceptual fidelity, their reliance on heavy encoder networks makes them unsuitable for deployment on weak sender devices. In this work, we explore the feasibility of applying shallow encoders for ultra-low bitrate compression and propose a novel Asymmetric Extreme Image Compression (AEIC) framework that pursues simultaneously encoding simplicity and decoding quality. Specifically, AEIC employs moderate or even shallow encoder networks, while leveraging an one-step diffusion decoder to maintain high-fidelity and high-realism reconstructions under extreme bitrates. To further enhance the efficiency of shallow encoders, we design a dual-side feature distillation scheme that transfers knowledge from AEIC with moderate encoders to its shallow encoder variants. Experiments demonstrate that AEIC not only outperforms existing methods on rate-distortion-perception performance at ultra-low bitrates, but also delivers exceptional encoding efficiency for 35.8 FPS on 1080P input images, while maintaining competitive decoding speed compared to existing methods.

</details>


### [55] [Moment and Highlight Detection via MLLM Frame Segmentation](https://arxiv.org/abs/2512.12246)
*I Putu Andika Bagas Jiwanta,Ayu Purwarianti*

Main category: cs.CV

TL;DR: 提出一种直接在LLM输出令牌上应用分割目标的新方法，解决了文本生成无法提供直接梯度的问题，并在少量帧采样下实现了高效的视频亮点检测和时刻检索。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本生成的MLLM方法无法为帧级预测提供直接梯度，尽管RL方法尝试解决，但仍存在不足。

Method: 采用分割损失对LLM输出的连续“0”和“1”字符序列进行训练，结合因果LM损失，推断时通过束搜索生成序列和逻辑值。

Result: 在仅采样25帧的情况下，方法在QVHighlights上实现了56.74 HIT@1的亮点检测和35.28 MAP的时刻检索。

Conclusion: 该方法通过直接在LLM的输出令牌上应用分割目标，成功解决了基于文本生成无法提供直接梯度的问题，并在QVHighlights上实现了强效的亮点检测（56.74 HIT@1）和高效的时刻检索（35.28 MAP）。

Abstract: Detecting video moments and highlights from natural-language queries have been unified by transformer-based methods. Other works use generative Multimodal LLM (MLLM) to predict moments and/or highlights as text timestamps, utilizing its reasoning capability. While effective, text-based generation cannot provide direct gradients for frame-level predictions because the model only emits language tokens. Although recent Reinforcement Learning (RL) methods attempt to address the issue, we propose a novel approach by applying segmentation objectives directly on the LLM's output tokens. The LLM is fed with a fixed number of frames alongside a prompt that enforces it to output a sequence of continuous "0" and/or "1" characters, with one character per frame. The "0"/"1" characters benefit from the LLM's inherent language capability while also acting as background and foreground probabilities, respectively. Training employs segmentation losses on the probabilities alongside a normal causal LM loss. At inference, beam search generates sequence and logits, acting as moments and saliency scores, respectively. Despite sampling only 25 frames -- less than half of comparable methods -- our method achieved strong highlight detection (56.74 HIT@1) on QVHighlights. Additionally, our efficient method scores above the baseline (35.28 MAP) for moment retrieval. Empirically, segmentation losses provide a stable complementary learning signal even when the causal LM loss plateaus.

</details>


### [56] [MetaTPT: Meta Test-time Prompt Tuning for Vision-Language Models](https://arxiv.org/abs/2512.12268)
*Yuqing Lei,Yingjun Du,Yawen Huang,Xiantong Zhen,Ling Shao*

Main category: cs.CV

TL;DR: MetaTPT是一种元学习框架，通过动态学习自监督辅助任务和增强，提升了视觉语言模型在测试时的适应能力。


<details>
  <summary>Details</summary>
Motivation: 现有测试时提示调优（TPT）方法在固定增强下可能无法应对更具挑战性的领域转移，因此需要更灵活的方法来动态学习增强。

Method: MetaTPT采用双循环优化范式：内循环学习自监督任务以生成信息丰富的视图，外循环通过强制这些视图之间的一致性进行提示调优。

Result: MetaTPT在领域泛化和跨数据集基准测试中表现出色，实现了最先进的性能。

Conclusion: MetaTPT通过结合元学习和测试时提示调优，显著提升了视觉语言模型在领域转移下的适应能力，并在多个基准测试中达到了最先进的性能。

Abstract: Vision-language models (VLMs) such as CLIP exhibit strong zero-shot generalization but remain sensitive to domain shifts at test time. Test-time prompt tuning (TPT) mitigates this issue by adapting prompts with fixed augmentations, which may falter in more challenging settings. In this work, we propose Meta Test-Time Prompt Tuning (MetaTPT), a meta-learning framework that learns a self-supervised auxiliary task to guide test-time prompt tuning. The auxiliary task dynamically learns parameterized augmentations for each sample, enabling more expressive transformations that capture essential features in target domains. MetaTPT adopts a dual-loop optimization paradigm: an inner loop learns a self-supervised task that generates informative views, while the outer loop performs prompt tuning by enforcing consistency across these views. By coupling augmentation learning with prompt tuning, MetaTPT improves test-time adaptation under domain shifts. Extensive experiments demonstrate that MetaTPT achieves state-of-the-art performance on domain generalization and cross-dataset benchmarks.

</details>


### [57] [Feature Aggregation for Efficient Continual Learning of Complex Facial Expressions](https://arxiv.org/abs/2512.12277)
*Thibault Geoffroy,Myriam Maumy,Lionel Prevost*

Main category: cs.CV

TL;DR: 提出了一种结合深度卷积特征和面部动作单元的混合框架，通过贝叶斯高斯混合模型在持续学习环境中有效减轻遗忘，提升了情感识别准确性。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统在日常生活中的普及，识别和适应人类情感的能力对有效的人机交互至关重要。面部表情识别（FER）是推断情感状态的主要渠道，但情感的动态性和文化多样性要求模型能够持续学习而不遗忘先验知识。

Method: 提出了一种混合框架，整合了深度卷积特征和面部动作单元（AUs），通过贝叶斯高斯混合模型（BGMMs）建模，实现了轻量级且概率化的解决方案。

Result: 在CFEE数据集上的实验表明，该模型能够先学习基本表情，然后逐步识别复合表情，表现出更高的准确性、更强的知识保留能力和更少的遗忘。

Conclusion: 该框架通过结合深度卷积特征和面部动作单元（AUs），利用贝叶斯高斯混合模型（BGMMs）在持续学习环境中有效减轻了灾难性遗忘，提升了情感智能AI系统的应用潜力。

Abstract: As artificial intelligence (AI) systems become increasingly embedded in our daily life, the ability to recognize and adapt to human emotions is essential for effective human-computer interaction. Facial expression recognition (FER) provides a primary channel for inferring affective states, but the dynamic and culturally nuanced nature of emotions requires models that can learn continuously without forgetting prior knowledge. In this work, we propose a hybrid framework for FER in a continual learning setting that mitigates catastrophic forgetting. Our approach integrates two complementary modalities: deep convolutional features and facial Action Units (AUs) derived from the Facial Action Coding System (FACS). The combined representation is modelled through Bayesian Gaussian Mixture Models (BGMMs), which provide a lightweight, probabilistic solution that avoids retraining while offering strong discriminative power. Using the Compound Facial Expression of Emotion (CFEE) dataset, we show that our model can first learn basic expressions and then progressively recognize compound expressions. Experiments demonstrate improved accuracy, stronger knowledge retention, and reduced forgetting. This framework contributes to the development of emotionally intelligent AI systems with applications in education, healthcare, and adaptive user interfaces.

</details>


### [58] [Cognitive-YOLO: LLM-Driven Architecture Synthesis from First Principles of Data for Object Detection](https://arxiv.org/abs/2512.12281)
*Jiahao Zhao*

Main category: cs.CV

TL;DR: Cognitive-YOLO利用LLM直接从数据特征生成目标检测架构，性能优越且参数高效。


<details>
  <summary>Details</summary>
Motivation: 传统手动设计耗时且劳动密集，NAS计算成本高，现有LLM方法缺乏对数据的整体理解，因此提出Cognitive-YOLO以直接从数据特征生成架构。

Method: 方法包括三个阶段：1) 分析模块提取数据集的关键元特征；2) LLM基于这些特征和RAG检索的最先进组件，合成结构化NADL；3) 编译器将描述实例化为可部署模型。

Result: 在五个不同目标检测数据集上的实验表明，Cognitive-YOLO生成的架构性能优越，且在性能与参数权衡上优于基线模型。

Conclusion: Cognitive-YOLO通过直接从数据内在特征生成网络配置，显著提升了目标检测架构的性能，证明了数据驱动推理在架构设计中的关键作用。

Abstract: Designing high-performance object detection architectures is a complex task, where traditional manual design is time-consuming and labor-intensive, and Neural Architecture Search (NAS) is computationally prohibitive. While recent approaches using Large Language Models (LLMs) show promise, they often function as iterative optimizers within a search loop, rather than generating architectures directly from a holistic understanding of the data. To address this gap, we propose Cognitive-YOLO, a novel framework for LLM-driven architecture synthesis that generates network configurations directly from the intrinsic characteristics of the dataset. Our method consists of three stages: first, an analysis module extracts key meta-features (e.g., object scale distribution and scene density) from the target dataset; second, the LLM reasons upon these features, augmented with state-of-the-art components retrieved via Retrieval-Augmented Generation (RAG), to synthesize the architecture into a structured Neural Architecture Description Language (NADL); finally, a compiler instantiates this description into a deployable model. Extensive experiments on five diverse object detection datasets demonstrate that our proposed Cognitive-YOLO consistently generates superior architectures, achieving highly competitive performance and demonstrating a superior performance-per-parameter trade-off compared to strong baseline models across multiple benchmarks. Crucially, our ablation studies prove that the LLM's data-driven reasoning is the primary driver of performance, demonstrating that a deep understanding of data "first principles" is more critical for achieving a superior architecture than simply retrieving SOTA components.

</details>


### [59] [RealDrag: The First Dragging Benchmark with Real Target Image](https://arxiv.org/abs/2512.12287)
*Ahmad Zafarani,Zahra Dehghanian,Mohammadreza Davoodi,Mohsen Shadroo,MohammadAmin Fazli,Hamid R. Rabiee*

Main category: cs.CV

TL;DR: RealDrag是首个包含真实目标图像的基于拖拽图像编辑基准，提出了四个新指标，评估了17种模型，揭示了方法间的权衡。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏标准化基准和指标，基于拖拽的图像编辑模型评估不可靠，导致方法间难以客观比较。

Method: 引入了RealDrag基准数据集，包含400多个带有人工标注的样本，并提出了四个任务特定指标：SeD、OMPS、IPPS和DiS。

Result: 通过RealDrag基准对17种SOTA模型进行了大规模系统分析，揭示了现有方法的权衡，并建立了可复现的基线。

Conclusion: RealDrag基准和提出的四个新指标为基于拖拽的图像编辑模型提供了可靠的评估标准，揭示了现有方法的权衡，并为未来研究奠定了坚实的基础。

Abstract: The evaluation of drag based image editing models is unreliable due to a lack of standardized benchmarks and metrics. This ambiguity stems from inconsistent evaluation protocols and, critically, the absence of datasets containing ground truth target images, making objective comparisons between competing methods difficult. To address this, we introduce \textbf{RealDrag}, the first comprehensive benchmark for point based image editing that includes paired ground truth target images. Our dataset contains over 400 human annotated samples from diverse video sources, providing source/target images, handle/target points, editable region masks, and descriptive captions for both the image and the editing action.
  We also propose four novel, task specific metrics: Semantical Distance (SeD), Outer Mask Preserving Score (OMPS), Inner Patch Preserving Score (IPPS), and Directional Similarity (DiS). These metrics are designed to quantify pixel level matching fidelity, check preservation of non edited (out of mask) regions, and measure semantic alignment with the desired task. Using this benchmark, we conduct the first large scale systematic analysis of the field, evaluating 17 SOTA models. Our results reveal clear trade offs among current approaches and establish a robust, reproducible baseline to guide future research. Our dataset and evaluation toolkit will be made publicly available.

</details>


### [60] [GrowTAS: Progressive Expansion from Small to Large Subnets for Efficient ViT Architecture Search](https://arxiv.org/abs/2512.12296)
*Hyunju Lee,Youngmin Oh,Jeimin Jeon,Donghyeon Baek,Bumsub Ham*

Main category: cs.CV

TL;DR: GrowTAS通过渐进式训练减少子网干扰，GrowTAS+进一步微调权重，提升性能，优于现有TAS方法。


<details>
  <summary>Details</summary>
Motivation: 现有TAS方法中所有子网共享权重导致小型子网性能严重下降，而训练良好的小型子网可作为训练大型子网的良好基础。

Method: 提出渐进式训练框架GrowTAS，从小型子网开始逐步引入大型子网，并引入GrowTAS+对部分权重进行微调。

Result: 在ImageNet及多个迁移学习基准测试（如CIFAR-10/100、Flowers等）上验证了方法的有效性。

Conclusion: GrowTAS和GrowTAS+通过渐进式训练框架和权重微调策略，显著减少了子网间的干扰，提升了大型子网的性能，在多个基准测试中表现优于现有TAS方法。

Abstract: Transformer architecture search (TAS) aims to automatically discover efficient vision transformers (ViTs), reducing the need for manual design. Existing TAS methods typically train an over-parameterized network (i.e., a supernet) that encompasses all candidate architectures (i.e., subnets). However, all subnets share the same set of weights, which leads to interference that degrades the smaller subnets severely. We have found that well-trained small subnets can serve as a good foundation for training larger ones. Motivated by this, we propose a progressive training framework, dubbed GrowTAS, that begins with training small subnets and incorporate larger ones gradually. This enables reducing the interference and stabilizing a training process. We also introduce GrowTAS+ that fine-tunes a subset of weights only to further enhance the performance of large subnets. Extensive experiments on ImageNet and several transfer learning benchmarks, including CIFAR-10/100, Flowers, CARS, and INAT-19, demonstrate the effectiveness of our approach over current TAS methods

</details>


### [61] [From Human Intention to Action Prediction: A Comprehensive Benchmark for Intention-driven End-to-End Autonomous Driving](https://arxiv.org/abs/2512.12302)
*Huan Zheng,Yucheng Zhou,Tianyi Yan,Jiayi Su,Hongjun Chen,Dubing Chen,Wencheng Han,Runzhou Tao,Zhongying Qiu,Jianfei Yang,Jianbing Shen*

Main category: cs.CV

TL;DR: Intention-Drive是首个评估自动驾驶系统将高级人类意图转化为安全精确驾驶动作能力的基准，包含数据集和ISR评估协议，揭示了现有模型的不足。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶系统缺乏衡量和推动高级意图理解能力的标准化基准，阻碍了从指令跟随到意图满足的范式转变。

Method: 提出了Intention-Drive基准，包含复杂场景与自然语言意图配对的数据集，以及以意图成功率（ISR）为核心的评估协议。

Result: 通过对多种基线模型的广泛评估，发现它们在场景和意图理解方面表现不佳，难以满足高级任务需求。

Conclusion: 当前端到端自动驾驶系统在智能水平上仅能执行简单的转向指令，而实现真正智能的自主性需要从执行低级指令转向理解和满足高级、抽象的人类意图。本文通过引入Intention-Drive基准，填补了这一关键空白，揭示了现有模型在高级意图理解上的不足。

Abstract: Current end-to-end autonomous driving systems operate at a level of intelligence akin to following simple steering commands. However, achieving genuinely intelligent autonomy requires a paradigm shift: moving from merely executing low-level instructions to understanding and fulfilling high-level, abstract human intentions. This leap from a command-follower to an intention-fulfiller, as illustrated in our conceptual framework, is hindered by a fundamental challenge: the absence of a standardized benchmark to measure and drive progress on this complex task. To address this critical gap, we introduce Intention-Drive, the first comprehensive benchmark designed to evaluate the ability to translate high-level human intent into safe and precise driving actions. Intention-Drive features two core contributions: (1) a new dataset of complex scenarios paired with corresponding natural language intentions, and (2) a novel evaluation protocol centered on the Intent Success Rate (ISR), which assesses the semantic fulfillment of the human's goal beyond simple geometric accuracy. Through an extensive evaluation of a spectrum of baseline models on Intention-Drive, we reveal a significant performance deficit, showing that the baseline model struggle to achieve the comprehensive scene and intention understanding required for this advanced task.

</details>


### [62] [OMUDA: Omni-level Masking for Unsupervised Domain Adaptation in Semantic Segmentation](https://arxiv.org/abs/2512.12303)
*Yang Ou,Xiongwei Zhao,Xinye Yang,Yihan Wang,Yicheng Di,Rong Yuan,Xieyuanli Chen,Xu Zhu*

Main category: cs.CV

TL;DR: OMUDA通过分层掩码策略（CAM、FDM、CDM）解决UDA中的领域差距问题，在语义分割任务中实现7%的平均性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有UDA方法因跨领域上下文模糊、特征表示不一致及类级伪标签噪声，难以有效缩小领域差距。

Method: 提出OMUDA框架，包含三种分层掩码策略：1) CAM平衡全局与局部上下文；2) FDM通过预训练模型知识转移增强特征学习；3) CDM通过类级不确定性建模减少伪标签噪声。

Result: 在SYNTHIA->Cityscapes和GTA5->Cityscapes任务中，OMUDA平均提升7%，并可无缝集成现有UDA方法。

Conclusion: OMUDA通过分层掩码策略（CAM、FDM、CDM）在多层面减少领域偏移，显著提升了无监督领域自适应（UDA）在语义分割任务中的性能，并在多个基准测试中达到最优结果。

Abstract: Unsupervised domain adaptation (UDA) enables semantic segmentation models to generalize from a labeled source domain to an unlabeled target domain. However, existing UDA methods still struggle to bridge the domain gap due to cross-domain contextual ambiguity, inconsistent feature representations, and class-wise pseudo-label noise. To address these challenges, we propose Omni-level Masking for Unsupervised Domain Adaptation (OMUDA), a unified framework that introduces hierarchical masking strategies across distinct representation levels. Specifically, OMUDA comprises: 1) a Context-Aware Masking (CAM) strategy that adaptively distinguishes foreground from background to balance global context and local details; 2) a Feature Distillation Masking (FDM) strategy that enhances robust and consistent feature learning through knowledge transfer from pre-trained models; and 3) a Class Decoupling Masking (CDM) strategy that mitigates the impact of noisy pseudo-labels by explicitly modeling class-wise uncertainty. This hierarchical masking paradigm effectively reduces the domain shift at the contextual, representational, and categorical levels, providing a unified solution beyond existing approaches. Extensive experiments on multiple challenging cross-domain semantic segmentation benchmarks validate the effectiveness of OMUDA. Notably, on the SYNTHIA->Cityscapes and GTA5->Cityscapes tasks, OMUDA can be seamlessly integrated into existing UDA methods and consistently achieving state-of-the-art results with an average improvement of 7%.

</details>


### [63] [WeDetect: Fast Open-Vocabulary Object Detection as Retrieval](https://arxiv.org/abs/2512.12309)
*Shenghao Fu,Yukun Su,Fengyun Rao,Jing Lyu,Xiaohua Xie,Wei-Shi Zheng*

Main category: cs.CV

TL;DR: WeDetect是一个基于检索哲学的开放词汇对象检测模型家族，通过双塔架构实现实时检测，支持提案生成、对象检索和REC，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 探索检索哲学在开放词汇对象检测中的独特优势，包括效率和多功能性。

Method: WeDetect采用双塔架构，作为实时检测器，通过精心策划的数据和完整训练，非融合的WeDetect超越了其他融合模型。WeDetect-Uni基于WeDetect，冻结整个检测器并仅微调一个对象性提示以检索跨类别的通用对象提案。WeDetect-Ref是一个基于LMM的对象分类器，用于处理复杂的引用表达式。

Result: WeDetect系列在15个基准测试中实现了最先进的性能，并展示了高推理效率。

Conclusion: WeDetect系列模型通过一致的检索框架统一了检测、提案生成、对象检索和REC，在15个基准测试中实现了最先进的性能和高推理效率。

Abstract: Open-vocabulary object detection aims to detect arbitrary classes via text prompts. Methods without cross-modal fusion layers (non-fusion) offer faster inference by treating recognition as a retrieval problem, \ie, matching regions to text queries in a shared embedding space. In this work, we fully explore this retrieval philosophy and demonstrate its unique advantages in efficiency and versatility through a model family named WeDetect: (1) State-of-the-art performance. WeDetect is a real-time detector with a dual-tower architecture. We show that, with well-curated data and full training, the non-fusion WeDetect surpasses other fusion models and establishes a strong open-vocabulary foundation. (2) Fast backtrack of historical data. WeDetect-Uni is a universal proposal generator based on WeDetect. We freeze the entire detector and only finetune an objectness prompt to retrieve generic object proposals across categories. Importantly, the proposal embeddings are class-specific and enable a new application, object retrieval, supporting retrieval objects in historical data. (3) Integration with LMMs for referring expression comprehension (REC). We further propose WeDetect-Ref, an LMM-based object classifier to handle complex referring expressions, which retrieves target objects from the proposal list extracted by WeDetect-Uni. It discards next-token prediction and classifies objects in a single forward pass. Together, the WeDetect family unifies detection, proposal generation, object retrieval, and REC under a coherent retrieval framework, achieving state-of-the-art performance across 15 benchmarks with high inference efficiency.

</details>


### [64] [Unified Control for Inference-Time Guidance of Denoising Diffusion Models](https://arxiv.org/abs/2512.12339)
*Maurya Goyal,Anuj Singh,Hadi Jamali-Rad*

Main category: cs.CV

TL;DR: UniCoDe是一个结合采样和梯度引导的通用算法，提升了扩散模型的任务对齐效率和性能。


<details>
  <summary>Details</summary>
Motivation: 为了提高扩散模型在下游任务中的性能，需要对齐模型输出与任务目标。现有方法分为采样和梯度引导两类，各有优缺点。

Method: 提出了一个通用算法UniCoDe，将采样方法和梯度引导方法结合到一个统一框架中，通过整合局部梯度信号来提升采样效率。

Result: 实验结果表明，UniCoDe在多个任务中与最先进的基线方法竞争激烈。

Conclusion: UniCoDe通过结合采样和梯度引导方法的优势，在保持与扩散无条件先验的平衡的同时，实现了更高效的采样和更好的奖励对齐效果。

Abstract: Aligning diffusion model outputs with downstream objectives is essential for improving task-specific performance. Broadly, inference-time training-free approaches for aligning diffusion models can be categorized into two main strategies: sampling-based methods, which explore multiple candidate outputs and select those with higher reward signals, and gradient-guided methods, which use differentiable reward approximations to directly steer the generation process. In this work, we propose a universal algorithm, UniCoDe, which brings together the strengths of sampling and gradient-based guidance into a unified framework. UniCoDe integrates local gradient signals during sampling, thereby addressing the sampling inefficiency inherent in complex reward-based sampling approaches. By cohesively combining these two paradigms, UniCoDe enables more efficient sampling while offering better trade-offs between reward alignment and divergence from the diffusion unconditional prior. Empirical results demonstrate that UniCoDe remains competitive with state-of-the-art baselines across a range of tasks. The code is available at https://github.com/maurya-goyal10/UniCoDe

</details>


### [65] [TCLeaf-Net: a transformer-convolution framework with global-local attention for robust in-field lesion-level plant leaf disease detection](https://arxiv.org/abs/2512.12357)
*Zishen Song,Yongjian Zhu,Dong Wang,Hongzhan Liu,Lingyu Jiang,Yongxing Duan,Zehua Zhang,Sihan Li,Jiarui Li*

Main category: cs.CV

TL;DR: TCLeaf-Net是一种结合Transformer和卷积的混合检测器，用于叶片病害检测，在复杂背景下表现优异，并在多个数据集中验证了其鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 实时准确地检测叶片病害对作物生长至关重要，但复杂背景、域偏移和有限的数据集阻碍了模型的鲁棒性。

Method: 提出了TCLeaf-Net，一种结合Transformer和卷积的混合检测器，包含TCM模块（抑制非叶片区域）、RSFRS块（保留空间细节）和DFPN（增强多尺度融合）。

Result: 在Daylily-Leaf数据集的田间分割中，TCLeaf-Net优于基线模型和其他先进模型（如YOLO和RT-DETR系列），并在其他植物病害检测数据集中表现优异。

Conclusion: TCLeaf-Net在Daylily-Leaf数据集上表现出色，mAP@50提升了5.4个百分点，达到78.2%，同时减少了计算量和GPU内存使用。模型在PlantDoc、Tomato-Leaf和Rice-Leaf数据集上也表现出强大的鲁棒性和泛化能力。

Abstract: Timely and accurate detection of foliar diseases is vital for safeguarding crop growth and reducing yield losses. Yet, in real-field conditions, cluttered backgrounds, domain shifts, and limited lesion-level datasets hinder robust modeling. To address these challenges, we release Daylily-Leaf, a paired lesion-level dataset comprising 1,746 RGB images and 7,839 lesions captured under both ideal and in-field conditions, and propose TCLeaf-Net, a transformer-convolution hybrid detector optimized for real-field use. TCLeaf-Net is designed to tackle three major challenges. To mitigate interference from complex backgrounds, the transformer-convolution module (TCM) couples global context with locality-preserving convolution to suppress non-leaf regions. To reduce information loss during downsampling, the raw-scale feature recalling and sampling (RSFRS) block combines bilinear resampling and convolution to preserve fine spatial detail. To handle variations in lesion scale and feature shifts, the deformable alignment block with FPN (DFPN) employs offset-based alignment and multi-receptive-field perception to strengthen multi-scale fusion. Experimental results show that on the in-field split of the Daylily-Leaf dataset, TCLeaf-Net improves mAP@50 by 5.4 percentage points over the baseline model, reaching 78.2\%, while reducing computation by 7.5 GFLOPs and GPU memory usage by 8.7\%. Moreover, the model outperforms recent YOLO and RT-DETR series in both precision and recall, and demonstrates strong performance on the PlantDoc, Tomato-Leaf, and Rice-Leaf datasets, validating its robustness and generalizability to other plant disease detection scenarios.

</details>


### [66] [VideoARM: Agentic Reasoning over Hierarchical Memory for Long-Form Video Understanding](https://arxiv.org/abs/2512.12360)
*Yufei Yin,Qianke Meng,Minghao Chen,Jiajun Ding,Zhenwei Shao,Zhou Yu*

Main category: cs.CV

TL;DR: VideoARM通过动态代理推理和分层记忆机制，高效解决长视频理解问题，性能优于现有方法且token消耗更低。


<details>
  <summary>Details</summary>
Motivation: 长视频理解因时间结构长、多模态线索密集而具有挑战性。现有方法多依赖手工推理流程或高token消耗的预处理，VideoARM旨在克服这些限制。

Method: VideoARM采用了一种自适应、连续的观察-思考-行动-记忆循环机制，通过控制器自主调用工具以粗到细的方式解析视频，并利用分层多模态记忆捕获和更新多级线索。

Result: 在主流基准测试中，VideoARM表现优于当前最先进的DVD方法，并显著减少了长视频处理的token消耗。

Conclusion: VideoARM通过自适应、动态的代理推理和分层记忆构建，显著提升了长视频理解的性能，同时大幅降低了token消耗。

Abstract: Long-form video understanding remains challenging due to the extended temporal structure and dense multimodal cues. Despite recent progress, many existing approaches still rely on hand-crafted reasoning pipelines or employ token-consuming video preprocessing to guide MLLMs in autonomous reasoning. To overcome these limitations, we introduce VideoARM, an Agentic Reasoning-over-hierarchical-Memory paradigm for long-form video understanding. Instead of static, exhaustive preprocessing, VideoARM performs adaptive, on-the-fly agentic reasoning and memory construction. Specifically, VideoARM performs an adaptive and continuous loop of observing, thinking, acting, and memorizing, where a controller autonomously invokes tools to interpret the video in a coarse-to-fine manner, thereby substantially reducing token consumption. In parallel, a hierarchical multimodal memory continuously captures and updates multi-level clues throughout the operation of the agent, providing precise contextual information to support the controller in decision-making. Experiments on prevalent benchmarks demonstrate that VideoARM outperforms the state-of-the-art method, DVD, while significantly reducing token consumption for long-form videos.

</details>


### [67] [STAGE: Storyboard-Anchored Generation for Cinematic Multi-shot Narrative](https://arxiv.org/abs/2512.12372)
*Peixuan Zhang,Zijian Jia,Kaiqi Liu,Shuchen Weng,Si Li,Boxin Shi*

Main category: cs.CV

TL;DR: STAGE通过结构化故事板和多镜头记忆包等创新方法，显著提升了多镜头视频生成的叙事连贯性和控制性。


<details>
  <summary>Details</summary>
Motivation: 解决现有关键帧方法在跨镜头一致性和电影语言捕捉上的不足，提升多镜头叙事视频生成的连贯性和控制性。

Method: 提出了STEP2预测结构化故事板，采用多镜头记忆包确保长距离实体一致性，双编码策略保证镜头内连贯性，以及两阶段训练方案学习镜头间电影化过渡。

Result: 实验证明STAGE在结构化叙事控制和跨镜头一致性上表现优异。

Conclusion: STAGE通过引入结构化故事板和创新的记忆包、双编码策略以及两阶段训练方案，显著提升了多镜头视频生成中的叙事控制和跨镜头一致性。

Abstract: While recent advancements in generative models have achieved remarkable visual fidelity in video synthesis, creating coherent multi-shot narratives remains a significant challenge. To address this, keyframe-based approaches have emerged as a promising alternative to computationally intensive end-to-end methods, offering the advantages of fine-grained control and greater efficiency. However, these methods often fail to maintain cross-shot consistency and capture cinematic language. In this paper, we introduce STAGE, a SToryboard-Anchored GEneration workflow to reformulate the keyframe-based multi-shot video generation task. Instead of using sparse keyframes, we propose STEP2 to predict a structural storyboard composed of start-end frame pairs for each shot. We introduce the multi-shot memory pack to ensure long-range entity consistency, the dual-encoding strategy for intra-shot coherence, and the two-stage training scheme to learn cinematic inter-shot transition. We also contribute the large-scale ConStoryBoard dataset, including high-quality movie clips with fine-grained annotations for story progression, cinematic attributes, and human preferences. Extensive experiments demonstrate that STAGE achieves superior performance in structured narrative control and cross-shot coherence.

</details>


### [68] [V-Warper: Appearance-Consistent Video Diffusion Personalization via Value Warping](https://arxiv.org/abs/2512.12375)
*Hyunkoo Lee,Wooseok Jang,Jini Yang,Taehwan Kim,Sangoh Kim,Sangwon Jung,Seungryong Kim*

Main category: cs.CV

TL;DR: V-Warper 是一种无需训练的视频个性化框架，通过两阶段方法提升外观保真度，无需大规模视频微调。


<details>
  <summary>Details</summary>
Motivation: 现有视频个性化方法依赖高成本的视频微调或大规模视频数据集，且难以保持帧间细粒度外观一致性。V-Warper 旨在解决这些限制，提供高效且高保真的解决方案。

Method: V-Warper 采用两阶段方法：1) 轻量级的粗外观适应阶段，利用少量参考图像通过图像 LoRA 和主题嵌入适应编码全局身份；2) 推理时的细外观注入阶段，通过 RoPE-free 中层查询-键特征计算语义对应，引导外观丰富的值表示到生成过程的语义对齐区域。

Result: V-Warper 显著提升了外观保真度，同时保持了提示对齐和运动动态，且无需大规模视频微调。

Conclusion: V-Warper 是一种无需训练的视频个性化框架，通过粗到细的外观适应和注入阶段，显著提升了外观保真度，同时保持了提示对齐和运动动态，且无需大规模视频微调。

Abstract: Video personalization aims to generate videos that faithfully reflect a user-provided subject while following a text prompt. However, existing approaches often rely on heavy video-based finetuning or large-scale video datasets, which impose substantial computational cost and are difficult to scale. Furthermore, they still struggle to maintain fine-grained appearance consistency across frames. To address these limitations, we introduce V-Warper, a training-free coarse-to-fine personalization framework for transformer-based video diffusion models. The framework enhances fine-grained identity fidelity without requiring any additional video training. (1) A lightweight coarse appearance adaptation stage leverages only a small set of reference images, which are already required for the task. This step encodes global subject identity through image-only LoRA and subject-embedding adaptation. (2) A inference-time fine appearance injection stage refines visual fidelity by computing semantic correspondences from RoPE-free mid-layer query--key features. These correspondences guide the warping of appearance-rich value representations into semantically aligned regions of the generation process, with masking ensuring spatial reliability. V-Warper significantly improves appearance fidelity while preserving prompt alignment and motion dynamics, and it achieves these gains efficiently without large-scale video finetuning.

</details>


### [69] [M4Human: A Large-Scale Multimodal mmWave Radar Benchmark for Human Mesh Reconstruction](https://arxiv.org/abs/2512.12378)
*Junqiao Fan,Yunjiao Zhou,Yizhuo Yang,Xinyuan Cui,Jiarui Zhang,Lihua Xie,Jianfei Yang,Chris Xiaoxuan Lu,Fangqiang Ding*

Main category: cs.CV

TL;DR: M4Human是一个大规模多模态数据集，用于基于雷达的人体网格重建研究，解决了现有数据集的局限性，并提供了丰富的动作和高质量注释。


<details>
  <summary>Details</summary>
Motivation: 现有的基于视觉的人体网格重建数据集受限于遮挡、光照变化和隐私问题，而雷达数据集则受限于稀疏的骨架标签、有限的规模和简单的原地动作。

Method: 引入了M4Human，一个大规模多模态基准数据集，包含高分辨率毫米波雷达、RGB和深度数据，并提供原始雷达张量和处理后的雷达点云。数据集还包括高质量的运动捕捉注释，涵盖20名受试者和50种多样动作。

Result: M4Human是目前最大规模的多模态基准数据集（661K帧），在雷达张量和雷达点云模态上建立了基准，并通过多模态融合展示了其重要性。

Conclusion: M4Human数据集和代码将在论文发表后发布，为基于雷达的人体建模研究提供了重要资源，同时揭示了在快速、无约束运动下的持续挑战。

Abstract: Human mesh reconstruction (HMR) provides direct insights into body-environment interaction, which enables various immersive applications. While existing large-scale HMR datasets rely heavily on line-of-sight RGB input, vision-based sensing is limited by occlusion, lighting variation, and privacy concerns. To overcome these limitations, recent efforts have explored radio-frequency (RF) mmWave radar for privacy-preserving indoor human sensing. However, current radar datasets are constrained by sparse skeleton labels, limited scale, and simple in-place actions. To advance the HMR research community, we introduce M4Human, the current largest-scale (661K-frame) ($9\times$ prior largest) multimodal benchmark, featuring high-resolution mmWave radar, RGB, and depth data. M4Human provides both raw radar tensors (RT) and processed radar point clouds (RPC) to enable research across different levels of RF signal granularity. M4Human includes high-quality motion capture (MoCap) annotations with 3D meshes and global trajectories, and spans 20 subjects and 50 diverse actions, including in-place, sit-in-place, and free-space sports or rehabilitation movements. We establish benchmarks on both RT and RPC modalities, as well as multimodal fusion with RGB-D modalities. Extensive results highlight the significance of M4Human for radar-based human modeling while revealing persistent challenges under fast, unconstrained motion. The dataset and code will be released after the paper publication.

</details>


### [70] [Speedrunning ImageNet Diffusion](https://arxiv.org/abs/2512.12386)
*Swayam Bhanded*

Main category: cs.CV

TL;DR: SR-DiT整合多种技术，在小型模型上实现高效训练，性能媲美大型模型。


<details>
  <summary>Details</summary>
Motivation: 探索多种技术组合的潜在协同效应，以提升扩散变压器的训练效率。

Method: SR-DiT系统性地整合了token路由、架构改进和训练修改，并基于表示对齐进行优化。

Result: 在ImageNet-256上，仅用140M参数模型和400K次迭代（无需分类器自由引导）即达到FID 3.49和KDD 0.319，性能媲美更大模型。

Conclusion: SR-DiT框架通过整合多种技术，在小型模型上实现了与大型模型相当的性能，为未来研究提供了计算友好的基线。

Abstract: Recent advances have significantly improved the training efficiency of diffusion transformers. However, these techniques have largely been studied in isolation, leaving unexplored the potential synergies from combining multiple approaches. We present SR-DiT (Speedrun Diffusion Transformer), a framework that systematically integrates token routing, architectural improvements, and training modifications on top of representation alignment. Our approach achieves FID 3.49 and KDD 0.319 on ImageNet-256 using only a 140M parameter model at 400K iterations without classifier-free guidance - comparable to results from 685M parameter models trained significantly longer. To our knowledge, this is a state-of the-art result at this model size. Through extensive ablation studies, we identify which technique combinations are most effective and document both synergies and incompatibilities. We release our framework as a computationally accessible baseline for future research.

</details>


### [71] [ArtGen: Conditional Generative Modeling of Articulated Objects in Arbitrary Part-Level States](https://arxiv.org/abs/2512.12395)
*Haowen Wang,Xiaoping Yuan,Fugang Zhang,Rui Jian,Yuanwei Zhu,Xiuquan Qiao,Yakun Huang*

Main category: cs.CV

TL;DR: ArtGen是一种基于条件扩散的框架，能从单视图或文本生成具有准确几何和运动学的3D物体，通过跨状态采样和推理模块解决现有模型的模糊性问题。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型依赖单视图输入，导致几何形状与关节动力学纠缠，产生模糊或不现实的运动学结构。

Method: ArtGen采用跨状态蒙特卡洛采样来明确强制执行全局运动学一致性，并集成Chain-of-Thought推理模块推断结构先验，指导稀疏专家扩散变换器处理多样化运动学交互。

Result: 在PartNet-Mobility基准测试中，ArtGen表现显著优于现有方法。

Conclusion: ArtGen显著优于现有方法，能够从单视图图像或文本描述中生成具有准确几何和连贯运动学的3D物体。

Abstract: Generating articulated assets is crucial for robotics, digital twins, and embodied intelligence. Existing generative models often rely on single-view inputs representing closed states, resulting in ambiguous or unrealistic kinematic structures due to the entanglement between geometric shape and joint dynamics. To address these challenges, we introduce ArtGen, a conditional diffusion-based framework capable of generating articulated 3D objects with accurate geometry and coherent kinematics from single-view images or text descriptions at arbitrary part-level states. Specifically, ArtGen employs cross-state Monte Carlo sampling to explicitly enforce global kinematic consistency, reducing structural-motion entanglement. Additionally, we integrate a Chain-of-Thought reasoning module to infer robust structural priors, such as part semantics, joint types, and connectivity, guiding a sparse-expert Diffusion Transformer to specialize in diverse kinematic interactions. Furthermore, a compositional 3D-VAE latent prior enhanced with local-global attention effectively captures fine-grained geometry and global part-level relationships. Extensive experiments on the PartNet-Mobility benchmark demonstrate that ArtGen significantly outperforms state-of-the-art methods.

</details>


### [72] [A Graph Attention Network-Based Framework for Reconstructing Missing LiDAR Beams](https://arxiv.org/abs/2512.12410)
*Khalfalla Awedat,Mohamed Abidalrekab,Mohammad El-Yabroudi*

Main category: cs.CV

TL;DR: 该论文提出了一种基于图注意力网络的框架，仅使用当前LiDAR帧重建丢失的垂直通道，无需相机或时间信息，在模拟数据上表现优异。


<details>
  <summary>Details</summary>
Motivation: 垂直光束丢失（由硬件老化、灰尘、雪、雾或强反射触发）会严重降低自动驾驶车辆的3D感知能力，因此需要一种无需相机图像或时间信息的实时解决方案。

Method: 提出了一种基于图注意力网络（GAT）的框架，将每个LiDAR扫描表示为非结构化空间图，点作为节点，边连接邻近点并保留原始光束索引顺序。多层GAT学习局部几何邻域的自适应注意力权重，并直接回归缺失的高程（z）值。

Result: 在1,065个模拟通道丢失的原始KITTI序列上训练和评估，方法实现了平均高度RMSE为11.67厘米，87.98%的重建点落在10厘米误差阈值内，单GPU上每帧推理时间为14.65秒。

Conclusion: 该研究证明，纯图注意力模型仅基于原始点云几何数据即可有效恢复因传感器退化而丢失的垂直光束，为自动驾驶车辆的3D感知提供了稳定的解决方案。

Abstract: Vertical beam dropout in spinning LiDAR sensors triggered by hardware aging, dust, snow, fog, or bright reflections removes entire vertical slices from the point cloud and severely degrades 3D perception in autonomous vehicles. This paper proposes a Graph Attention Network (GAT)-based framework that reconstructs these missing vertical channels using only the current LiDAR frame, with no camera images or temporal information required. Each LiDAR sweep is represented as an unstructured spatial graph: points are nodes and edges connect nearby points while preserving the original beam-index ordering. A multi-layer GAT learns adaptive attention weights over local geometric neighborhoods and directly regresses the missing elevation (z) values at dropout locations. Trained and evaluated on 1,065 raw KITTI sequences with simulated channel dropout, the method achieves an average height RMSE of 11.67 cm, with 87.98% of reconstructed points falling within a 10 cm error threshold. Inference takes 14.65 seconds per frame on a single GPU, and reconstruction quality remains stable for different neighborhood sizes k. These results show that a pure graph attention model operating solely on raw point-cloud geometry can effectively recover dropped vertical beams under realistic sensor degradation.

</details>


### [73] [ViInfographicVQA: A Benchmark for Single and Multi-image Visual Question Answering on Vietnamese Infographics](https://arxiv.org/abs/2512.12424)
*Tue-Thu Van-Dinh,Hoang-Duy Tran,Truong-Binh Duong,Mai-Hanh Pham,Binh-Nam Le-Nguyen,Quoc-Thai Nguyen*

Main category: cs.CV

TL;DR: ViInfographicVQA是首个越南语信息图表VQA基准测试，包含单图像和多图像任务，揭示了当前模型在跨图像推理上的不足。


<details>
  <summary>Details</summary>
Motivation: 评估模型在数据丰富、布局复杂的信息图表上的阅读和推理能力，填补越南语信息图表VQA的空白，并探索跨图像推理的挑战。

Method: 引入了ViInfographicVQA基准测试，包含6747张真实世界信息图表和20409个人工验证的问答对，涵盖经济、医疗、教育等领域。测试包括单图像和多图像两种评估设置。

Result: 评估了多种最新的视觉语言模型，发现性能差距显著，尤其是在涉及跨图像整合和非跨度推理的多图像问题上。

Conclusion: ViInfographicVQA为越南语信息图表VQA提供了首个基准测试结果，揭示了当前多模态模型在低资源环境中的局限性，并鼓励未来对布局感知和跨图像推理方法的探索。

Abstract: Infographic Visual Question Answering (InfographicVQA) evaluates a model's ability to read and reason over data-rich, layout-heavy visuals that combine text, charts, icons, and design elements. Compared with scene-text or natural-image VQA, infographics require stronger integration of OCR, layout understanding, and numerical and semantic reasoning. We introduce ViInfographicVQA, the first benchmark for Vietnamese InfographicVQA, comprising over 6747 real-world infographics and 20409 human-verified question-answer pairs across economics, healthcare, education, and more. The benchmark includes two evaluation settings. The Single-image task follows the traditional setup in which each question is answered using a single infographic. The Multi-image task requires synthesizing evidence across multiple semantically related infographics and is, to our knowledge, the first Vietnamese evaluation of cross-image reasoning in VQA. We evaluate a range of recent vision-language models on this benchmark, revealing substantial performance disparities, with the most significant errors occurring on Multi-image questions that involve cross-image integration and non-span reasoning. ViInfographicVQA contributes benchmark results for Vietnamese InfographicVQA and sheds light on the limitations of current multimodal models in low-resource contexts, encouraging future exploration of layout-aware and cross-image reasoning methods.

</details>


### [74] [BokehDepth: Enhancing Monocular Depth Estimation through Bokeh Generation](https://arxiv.org/abs/2512.12425)
*Hangwei Zhang,Armando Teles Fortes,Tianyi Wei,Xingang Pan*

Main category: cs.CV

TL;DR: BokehDepth通过两阶段框架，结合散焦作为无监督几何线索，提升了散焦渲染和单目深度估计的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在散焦渲染和深度估计之间的关联利用不充分，导致渲染质量受限于深度图的噪声，而深度估计在关键区域表现不佳。

Method: 第一阶段使用物理引导的可控散焦生成器从单张清晰输入生成无深度信息的散焦堆栈；第二阶段通过轻量级的散焦感知聚合模块融合特征，增强现有单目深度编码器的性能。

Result: BokehDepth在多个挑战性基准测试中，显著提升了散焦渲染的视觉保真度，并增强了单目深度基础模型的准确性和鲁棒性。

Conclusion: BokehDepth通过两阶段框架有效提升了散焦渲染的质量和单目深度估计的准确性，尤其在纹理弱、距离远和几何模糊区域表现优异。

Abstract: Bokeh and monocular depth estimation are tightly coupled through the same lens imaging geometry, yet current methods exploit this connection in incomplete ways. High-quality bokeh rendering pipelines typically depend on noisy depth maps, which amplify estimation errors into visible artifacts, while modern monocular metric depth models still struggle on weakly textured, distant and geometrically ambiguous regions where defocus cues are most informative. We introduce BokehDepth, a two-stage framework that decouples bokeh synthesis from depth prediction and treats defocus as an auxiliary supervision-free geometric cue. In Stage-1, a physically guided controllable bokeh generator, built on a powerful pretrained image editing backbone, produces depth-free bokeh stacks with calibrated bokeh strength from a single sharp input. In Stage-2, a lightweight defocus-aware aggregation module plugs into existing monocular depth encoders, fuses features along the defocus dimension, and exposes stable depth-sensitive variations while leaving downstream decoder unchanged. Across challenging benchmarks, BokehDepth improves visual fidelity over depth-map-based bokeh baselines and consistently boosts the metric accuracy and robustness of strong monocular depth foundation models.

</details>


### [75] [Endless World: Real-Time 3D-Aware Long Video Generation](https://arxiv.org/abs/2512.12430)
*Ke Zhang,Yiqun Mei,Jiacong Xu,Vishal M. Patel*

Main category: cs.CV

TL;DR: Endless World是一个实时生成无限3D一致视频的框架，通过自回归训练和3D感知注意力实现长序列稳定性和实时性。


<details>
  <summary>Details</summary>
Motivation: 解决长视频序列中3D结构不稳定及实时生成的挑战。

Method: 采用条件自回归训练策略和全局3D感知注意力机制，结合3D注入机制确保几何一致性和物理合理性。

Result: 实验表明，Endless World能生成长、稳定且视觉连贯的视频，性能优于现有方法。

Conclusion: Endless World 框架通过实时生成无限、3D一致的视频序列，解决了长视频序列中3D结构稳定的挑战，并在视觉保真度和空间一致性上表现优异。

Abstract: Producing long, coherent video sequences with stable 3D structure remains a major challenge, particularly in streaming scenarios. Motivated by this, we introduce Endless World, a real-time framework for infinite, 3D-consistent video generation.To support infinite video generation, we introduce a conditional autoregressive training strategy that aligns newly generated content with existing video frames. This design preserves long-range dependencies while remaining computationally efficient, enabling real-time inference on a single GPU without additional training overhead.Moreover, our Endless World integrates global 3D-aware attention to provide continuous geometric guidance across time. Our 3D injection mechanism enforces physical plausibility and geometric consistency throughout extended sequences, addressing key challenges in long-horizon and dynamic scene synthesis.Extensive experiments demonstrate that Endless World produces long, stable, and visually coherent videos, achieving competitive or superior performance to existing methods in both visual fidelity and spatial consistency. Our project has been available on https://bwgzk-keke.github.io/EndlessWorld/.

</details>


### [76] [D3D-VLP: Dynamic 3D Vision-Language-Planning Model for Embodied Grounding and Navigation](https://arxiv.org/abs/2512.12622)
*Zihan Wang,Seungjun Lee,Guangzhao Dai,Gim Hee Lee*

Main category: cs.CV

TL;DR: D3D-VLP模型通过动态3D思维链和协同学习策略，解决了端到端模型和模块化系统的局限性，并在多个任务中实现了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 解决端到端模型缺乏可解释性和显式3D推理，而模块化系统忽略跨组件依赖性和协同作用的问题。

Method: 提出动态3D视觉-语言-规划模型（D3D-VLP），包括动态3D思维链（3D CoT）和协同学习策略（SLFS），利用掩码自回归损失从混合数据中学习。

Result: 在多个基准测试中（如R2R-CE、REVERIE-CE、NavRAG-CE等）达到最先进性能，并在实际移动操作实验中验证了有效性。

Conclusion: D3D-VLP模型通过动态3D思维链和协同学习策略，在多个基准测试中实现了最先进的性能，并在实际移动操作实验中验证了其有效性。

Abstract: Embodied agents face a critical dilemma that end-to-end models lack interpretability and explicit 3D reasoning, while modular systems ignore cross-component interdependencies and synergies. To bridge this gap, we propose the Dynamic 3D Vision-Language-Planning Model (D3D-VLP). Our model introduces two key innovations: 1) A Dynamic 3D Chain-of-Thought (3D CoT) that unifies planning, grounding, navigation, and question answering within a single 3D-VLM and CoT pipeline; 2) A Synergistic Learning from Fragmented Supervision (SLFS) strategy, which uses a masked autoregressive loss to learn from massive and partially-annotated hybrid data. This allows different CoT components to mutually reinforce and implicitly supervise each other. To this end, we construct a large-scale dataset with 10M hybrid samples from 5K real scans and 20K synthetic scenes that are compatible with online learning methods such as RL and DAgger. Our D3D-VLP achieves state-of-the-art results on multiple benchmarks, including Vision-and-Language Navigation (R2R-CE, REVERIE-CE, NavRAG-CE), Object-goal Navigation (HM3D-OVON), and Task-oriented Sequential Grounding and Navigation (SG3D). Real-world mobile manipulation experiments further validate the effectiveness.

</details>


### [77] [More Than the Final Answer: Improving Visual Extraction and Logical Consistency in Vision-Language Models](https://arxiv.org/abs/2512.12487)
*Hoang Anh Just,Yifei Fan,Handong Zhao,Jiuxiang Gu,Ruiyi Zhang,Simon Jenni,Kushal Kafle,Ruoxi Jia,Jing Shi*

Main category: cs.CV

TL;DR: PeRL-VL通过分离视觉感知和文本推理训练，显著提升多模态任务表现，准确率提升5.5%。


<details>
  <summary>Details</summary>
Motivation: 解决RLVR-trained VLMs在视觉提取和逻辑推理上的两大失败模式，即细节缺失或幻觉以及逻辑不一致的思维链。

Method: 提出PeRL-VL框架，分别通过VLM-based描述奖励和改进的文本推理SFT阶段优化视觉感知和逻辑一致性。

Result: PeRL-VL将平均Pass@1准确率从63.3%提升至68.8%，优于标准RLVR等方法。

Conclusion: PeRL-VL通过分离视觉感知和文本推理的训练，显著提升了视觉语言模型在多模态任务中的表现，超越了现有方法。

Abstract: Reinforcement learning from verifiable rewards (RLVR) has recently been extended from text-only LLMs to vision-language models (VLMs) to elicit long-chain multimodal reasoning. However, RLVR-trained VLMs still exhibit two persistent failure modes: inaccurate visual extraction (missing or hallucinating details) and logically inconsistent chains-of-thought, largely because verifiable signals supervise only the final answer. We propose PeRL-VL (Perception and Reasoning Learning for Vision-Language Models), a decoupled framework that separately improves visual perception and textual reasoning on top of RLVR. For perception, PeRL-VL introduces a VLM-based description reward that scores the model's self-generated image descriptions for faithfulness and sufficiency. For reasoning, PeRL-VL adds a text-only Reasoning SFT stage on logic-rich chain-of-thought data, enhancing coherence and logical consistency independently of vision. Across diverse multimodal benchmarks, PeRL-VL improves average Pass@1 accuracy from 63.3% (base Qwen2.5-VL-7B) to 68.8%, outperforming standard RLVR, text-only reasoning SFT, and naive multimodal distillation from GPT-4o.

</details>


### [78] [Cross-Level Sensor Fusion with Object Lists via Transformer for 3D Object Detection](https://arxiv.org/abs/2512.12884)
*Xiangzhong Liu,Jiajie Zhang,Hao Shen*

Main category: cs.CV

TL;DR: 提出一种端到端的跨级别融合方法，用Transformer集成对象列表和原始图像，提升3D检测性能，并在nuScenes数据集上验证了其效果。


<details>
  <summary>Details</summary>
Motivation: 在汽车传感器融合系统中，智能传感器和V2X模块常用，但其数据通常仅以处理后的对象列表形式提供，而非传统传感器的原始数据。传统方法需分别处理原始数据后再在对象级别融合，效率较低。

Method: 提出了一种端到端的跨级别融合概念，使用Transformer将高度抽象的对象列表信息与原始相机图像集成，用于3D对象检测。对象列表作为去噪查询输入Transformer，并通过可学习查询在后期的特征聚合过程中传播。此外，还集成了基于对象列表位置和尺寸先验的可变形高斯掩码，以引导注意力集中在目标区域并加速训练收敛。

Result: 该方法在nuScenes数据集上表现出优于基于视觉的基线的性能提升，并对模拟对象列表和真实检测器的不同噪声水平具有泛化能力。

Conclusion: 该论文提出的跨级别融合方法在nuScenes数据集上显著提升了基于视觉的基线性能，并展示了其对模拟对象列表和真实检测器不同噪声水平的泛化能力。

Abstract: In automotive sensor fusion systems, smart sensors and Vehicle-to-Everything (V2X) modules are commonly utilized. Sensor data from these systems are typically available only as processed object lists rather than raw sensor data from traditional sensors. Instead of processing other raw data separately and then fusing them at the object level, we propose an end-to-end cross-level fusion concept with Transformer, which integrates highly abstract object list information with raw camera images for 3D object detection. Object lists are fed into a Transformer as denoising queries and propagated together with learnable queries through the latter feature aggregation process. Additionally, a deformable Gaussian mask, derived from the positional and size dimensional priors from the object lists, is explicitly integrated into the Transformer decoder. This directs attention toward the target area of interest and accelerates model training convergence. Furthermore, as there is no public dataset containing object lists as a standalone modality, we propose an approach to generate pseudo object lists from ground-truth bounding boxes by simulating state noise and false positives and negatives. As the first work to conduct cross-level fusion, our approach shows substantial performance improvements over the vision-based baseline on the nuScenes dataset. It demonstrates its generalization capability over diverse noise levels of simulated object lists and real detectors.

</details>


### [79] [Adaptive Detector-Verifier Framework for Zero-Shot Polyp Detection in Open-World Settings](https://arxiv.org/abs/2512.12492)
*Shengkai Xu,Hsiang Lun Kao,Tianxiang Xu,Honghui Zhang,Junqiao Wang,Runmeng Ding,Guanyu Liu,Tianyu Shi,Zhenyu Yu,Guofeng Pan,Ziqian Bi,Yuqi Ouyang*

Main category: cs.CV

TL;DR: AdaptiveDetector结合自适应阈值和成本敏感强化学习，显著提升息肉检测召回率，减少假阴性，适用于临床环境。


<details>
  <summary>Details</summary>
Motivation: 解决现有息肉检测器在真实内窥镜环境下因光照变化、运动模糊和遮挡等图像质量下降而表现不佳的问题。

Method: 提出了一种新颖的两阶段检测器-验证器框架，包括YOLOv11检测器和视觉语言模型（VLM）验证器，采用GRPO进行微调，并设计了不对称成本敏感奖励函数。

Result: 在合成退化的CVC-ClinicDB和Kvasir-SEG图像上，零样本评估显示召回率比单独使用YOLO提高了14至22个百分点，精度保持在基线0.7点以下至1.7点以上。

Conclusion: AdaptiveDetector通过自适应阈值调整和成本敏感的强化学习，显著减少了假阴性，提升了临床对齐的息肉检测效果，改善了患者预后。

Abstract: Polyp detectors trained on clean datasets often underperform in real-world endoscopy, where illumination changes, motion blur, and occlusions degrade image quality. Existing approaches struggle with the domain gap between controlled laboratory conditions and clinical practice, where adverse imaging conditions are prevalent. In this work, we propose AdaptiveDetector, a novel two-stage detector-verifier framework comprising a YOLOv11 detector with a vision-language model (VLM) verifier. The detector adaptively adjusts per-frame confidence thresholds under VLM guidance, while the verifier is fine-tuned with Group Relative Policy Optimization (GRPO) using an asymmetric, cost-sensitive reward function specifically designed to discourage missed detections -- a critical clinical requirement. To enable realistic assessment under challenging conditions, we construct a comprehensive synthetic testbed by systematically degrading clean datasets with adverse conditions commonly encountered in clinical practice, providing a rigorous benchmark for zero-shot evaluation. Extensive zero-shot evaluation on synthetically degraded CVC-ClinicDB and Kvasir-SEG images demonstrates that our approach improves recall by 14 to 22 percentage points over YOLO alone, while precision remains within 0.7 points below to 1.7 points above the baseline. This combination of adaptive thresholding and cost-sensitive reinforcement learning achieves clinically aligned, open-world polyp detection with substantially fewer false negatives, thereby reducing the risk of missed precancerous polyps and improving patient outcomes.

</details>


### [80] [SignRAG: A Retrieval-Augmented System for Scalable Zero-Shot Road Sign Recognition](https://arxiv.org/abs/2512.12885)
*Minghao Zhu,Zhihao Zhang,Anmol Sidhu,Keith Redmill*

Main category: cs.CV

TL;DR: 论文提出了一种基于RAG的零样本路标识别框架，结合VLM和LLM，无需任务特定训练即可实现高精度识别。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习方法在路标识别任务中面临类别繁多和标注数据不足的挑战，因此需要一种无需大量标注数据的创新方法。

Method: 论文提出了一种结合视觉语言模型（VLM）和大型语言模型（LLM）的零样本识别框架，通过生成文本描述并检索候选设计，最终实现细粒度识别。

Result: 实验结果表明，该方法在理想参考图像上达到95.58%的准确率，在真实道路数据上达到82.45%的准确率。

Conclusion: 该论文展示了基于RAG架构的零样本识别框架在路标识别任务中的可行性和高效性，无需特定任务训练即可实现高精度识别。

Abstract: Automated road sign recognition is a critical task for intelligent transportation systems, but traditional deep learning methods struggle with the sheer number of sign classes and the impracticality of creating exhaustive labeled datasets. This paper introduces a novel zero-shot recognition framework that adapts the Retrieval-Augmented Generation (RAG) paradigm to address this challenge. Our method first uses a Vision Language Model (VLM) to generate a textual description of a sign from an input image. This description is used to retrieve a small set of the most relevant sign candidates from a vector database of reference designs. Subsequently, a Large Language Model (LLM) reasons over the retrieved candidates to make a final, fine-grained recognition. We validate this approach on a comprehensive set of 303 regulatory signs from the Ohio MUTCD. Experimental results demonstrate the framework's effectiveness, achieving 95.58% accuracy on ideal reference images and 82.45% on challenging real-world road data. This work demonstrates the viability of RAG-based architectures for creating scalable and accurate systems for road sign recognition without task-specific training.

</details>


### [81] [Advancing Cache-Based Few-Shot Classification via Patch-Driven Relational Gated Graph Attention](https://arxiv.org/abs/2512.12498)
*Tasweer Ahmad,Arindam Sikdar,Sandip Pradhan,Ardhendu Behera*

Main category: cs.CV

TL;DR: 提出补丁驱动的关系细化方法，通过图注意力网络增强补丁交互，提升少样本分类性能，保持零样本效率。


<details>
  <summary>Details</summary>
Motivation: 解决少样本图像分类在有限监督和视觉域偏移下的挑战，弥补现有缓存适配器方法（如Tip-Adapter）因继承CLIP全局表示而缺乏判别性的不足。

Method: 提出了一种关系门控图注意力网络，构建补丁图并执行边缘感知注意力，强调信息性补丁间交互，生成上下文丰富的补丁嵌入。通过可学习的多聚合池化将其组合为紧凑的任务判别表示。

Result: 在11个基准测试中均优于最先进的CLIP适配器和基于缓存的基线方法，同时保持了零样本效率。

Conclusion: 论文提出了一种基于补丁驱动的关系细化方法，通过图注意力网络增强补丁间交互，生成更具判别性的表示，显著提升了少样本图像分类性能，同时保持了零样本推理效率。

Abstract: Few-shot image classification remains difficult under limited supervision and visual domain shift. Recent cache-based adaptation approaches (e.g., Tip-Adapter) address this challenge to some extent by learning lightweight residual adapters over frozen features, yet they still inherit CLIP's tendency to encode global, general-purpose representations that are not optimally discriminative to adapt the generalist to the specialist's domain in low-data regimes. We address this limitation with a novel patch-driven relational refinement that learns cache adapter weights from intra-image patch dependencies rather than treating an image embedding as a monolithic vector. Specifically, we introduce a relational gated graph attention network that constructs a patch graph and performs edge-aware attention to emphasize informative inter-patch interactions, producing context-enriched patch embeddings. A learnable multi-aggregation pooling then composes these into compact, task-discriminative representations that better align cache keys with the target few-shot classes. Crucially, the proposed graph refinement is used only during training to distil relational structure into the cache, incurring no additional inference cost beyond standard cache lookup. Final predictions are obtained by a residual fusion of cache similarity scores with CLIP zero-shot logits. Extensive evaluations on 11 benchmarks show consistent gains over state-of-the-art CLIP adapter and cache-based baselines while preserving zero-shot efficiency. We further validate battlefield relevance by introducing an Injured vs. Uninjured Soldier dataset for casualty recognition. It is motivated by the operational need to support triage decisions within the "platinum minutes" and the broader "golden hour" window in time-critical UAV-driven search-and-rescue and combat casualty care.

</details>


### [82] [Motus: A Unified Latent Action World Model](https://arxiv.org/abs/2512.13030)
*Hongzhe Bi,Hengkai Tan,Shenghao Xie,Zeyuan Wang,Shuhe Huang,Haitian Liu,Ruowen Zhao,Yao Feng,Chendong Xiang,Yinze Rong,Hongyan Zhao,Hanyu Liu,Zhizhong Su,Lei Ma,Hang Su,Jun Zhu*

Main category: cs.CV

TL;DR: Motus提出统一潜在动作世界模型，整合多模态生成能力，通过MoT架构和光流学习显著提升模拟和现实场景性能。


<details>
  <summary>Details</summary>
Motivation: 当前方法基于孤立的理解、世界建模和控制模型，导致多模态生成能力无法统一，且难以从大规模异构数据中学习。Motus旨在解决这一碎片化问题。

Method: Motus采用Mixture-of-Transformer（MoT）架构整合理解、视频生成和动作三个专家模块，并利用UniDiffuser-style调度器实现不同建模模式的灵活切换。此外，通过光流学习潜在动作，采用三阶段训练流程和六层数据金字塔进行大规模动作预训练。

Result: 实验表明，Motus在模拟场景中比X-VLA和Pi0.5分别提升15%和45%，在现实场景中提升11%~48%，验证了统一建模的优势。

Conclusion: Motus通过统一的潜在动作世界模型和Mixture-of-Transformer架构，显著提升了模拟和现实场景中的性能，证明了多功能统一建模对下游机器人任务的重要性。

Abstract: While a general embodied agent must function as a unified system, current methods are built on isolated models for understanding, world modeling, and control. This fragmentation prevents unifying multimodal generative capabilities and hinders learning from large-scale, heterogeneous data. In this paper, we propose Motus, a unified latent action world model that leverages existing general pretrained models and rich, sharable motion information. Motus introduces a Mixture-of-Transformer (MoT) architecture to integrate three experts (i.e., understanding, video generation, and action) and adopts a UniDiffuser-style scheduler to enable flexible switching between different modeling modes (i.e., world models, vision-language-action models, inverse dynamics models, video generation models, and video-action joint prediction models). Motus further leverages the optical flow to learn latent actions and adopts a recipe with three-phase training pipeline and six-layer data pyramid, thereby extracting pixel-level "delta action" and enabling large-scale action pretraining. Experiments show that Motus achieves superior performance against state-of-the-art methods in both simulation (a +15% improvement over X-VLA and a +45% improvement over Pi0.5) and real-world scenarios(improved by +11~48%), demonstrating unified modeling of all functionalities and priors significantly benefits downstream robotic tasks.

</details>


### [83] [Generative Spatiotemporal Data Augmentation](https://arxiv.org/abs/2512.12508)
*Jinfan Zhou,Lixin Luo,Sungmin Eum,Heesung Kwon,Jeong Joon Park*

Main category: cs.CV

TL;DR: 利用视频扩散模型生成时空变化数据，增强低数据场景下的模型训练效果。


<details>
  <summary>Details</summary>
Motivation: 解决传统几何变换或外观扰动方法在多样性和真实性上的不足，特别是在无人机捕获图像等标注稀缺的低数据场景中。

Method: 利用现成的视频扩散模型从给定图像数据集中生成真实的3D空间和时间变化，作为补充训练数据。

Result: 在COCO子集和无人机捕获数据集上的实验表明，时空增强能够显著提升模型性能。

Conclusion: 通过视频基础模型进行时空数据增强，能够有效扩展数据分布，提升在数据稀缺场景下的模型性能。

Abstract: We explore spatiotemporal data augmentation using video foundation models to diversify both camera viewpoints and scene dynamics. Unlike existing approaches based on simple geometric transforms or appearance perturbations, our method leverages off-the-shelf video diffusion models to generate realistic 3D spatial and temporal variations from a given image dataset. Incorporating these synthesized video clips as supplemental training data yields consistent performance gains in low-data settings, such as UAV-captured imagery where annotations are scarce. Beyond empirical improvements, we provide practical guidelines for (i) choosing an appropriate spatiotemporal generative setup, (ii) transferring annotations to synthetic frames, and (iii) addressing disocclusion - regions newly revealed and unlabeled in generated views. Experiments on COCO subsets and UAV-captured datasets show that, when applied judiciously, spatiotemporal augmentation broadens the data distribution along axes underrepresented by traditional and prior generative methods, offering an effective lever for improving model performance in data-scarce regimes.

</details>


### [84] [MMDrive: Interactive Scene Understanding Beyond Vision with Multi-representational Fusion](https://arxiv.org/abs/2512.13177)
*Minghui Hou,Wei-Hsing Huang,Shaofeng Liang,Daizong Liu,Tai-Hao Wen,Gang Wang,Runwei Guan,Weiping Ding*

Main category: cs.CV

TL;DR: MMDrive 是一种多模态视觉语言模型框架，通过融合占用图、LiDAR 点云和文本描述，提升自动驾驶场景的三维理解和语义融合能力，显著优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型受限于二维平面的图像理解范式，难以感知三维空间信息并进行深度语义融合，导致在复杂自动驾驶环境中表现不佳。

Method: MMDrive 引入了两种新颖组件：面向文本的多模态调制器和跨模态抽象器，分别用于动态加权多模态贡献和生成紧凑的跨模态摘要。

Result: 在 DriveLM 和 NuScenes-QA 基准测试中，MMDrive 表现优异，BLEU-4 得分 54.56，METEOR 得分 41.78（DriveLM），准确率 62.7%（NuScenes-QA）。

Conclusion: MMDrive 突破了传统仅基于图像理解的限制，为复杂驾驶环境中的多模态推理提供了新基础，推动了可解释的自动驾驶场景理解。

Abstract: Vision-language models enable the understanding and reasoning of complex traffic scenarios through multi-source information fusion, establishing it as a core technology for autonomous driving. However, existing vision-language models are constrained by the image understanding paradigm in 2D plane, which restricts their capability to perceive 3D spatial information and perform deep semantic fusion, resulting in suboptimal performance in complex autonomous driving environments. This study proposes MMDrive, an multimodal vision-language model framework that extends traditional image understanding to a generalized 3D scene understanding framework. MMDrive incorporates three complementary modalities, including occupancy maps, LiDAR point clouds, and textual scene descriptions. To this end, it introduces two novel components for adaptive cross-modal fusion and key information extraction. Specifically, the Text-oriented Multimodal Modulator dynamically weights the contributions of each modality based on the semantic cues in the question, guiding context-aware feature integration. The Cross-Modal Abstractor employs learnable abstract tokens to generate compact, cross-modal summaries that highlight key regions and essential semantics. Comprehensive evaluations on the DriveLM and NuScenes-QA benchmarks demonstrate that MMDrive achieves significant performance gains over existing vision-language models for autonomous driving, with a BLEU-4 score of 54.56 and METEOR of 41.78 on DriveLM, and an accuracy score of 62.7% on NuScenes-QA. MMDrive effectively breaks the traditional image-only understanding barrier, enabling robust multimodal reasoning in complex driving environments and providing a new foundation for interpretable autonomous driving scene understanding.

</details>


### [85] [MindDrive: A Vision-Language-Action Model for Autonomous Driving via Online Reinforcement Learning](https://arxiv.org/abs/2512.13636)
*Haoyu Fu,Diankun Zhang,Zongchuang Zhao,Jianfeng Cui,Hongwei Xie,Bing Wang,Guang Chen,Dingkang Liang,Xiang Bai*

Main category: cs.CV

TL;DR: MindDrive通过LLM和LoRA参数组合，首次实现了在线强化学习在自动驾驶VLA模型中的应用，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶中的VLA范式主要依赖模仿学习，存在分布偏移和因果混淆等问题，在线强化学习为解决这些问题提供了可能，但在连续动作空间中探索效率低。

Method: MindDrive采用了一个大型语言模型（LLM）配备两组不同的LoRA参数，分别作为决策专家和动作专家，将语言决策动态映射为可行轨迹。

Result: MindDrive在Bench2Drive基准上取得了驾驶评分（DS）78.04和成功率（SR）55.09%的优异成绩。

Conclusion: MindDrive成功展示了在线强化学习在自动驾驶VLA模型中的有效性，首次实现了在Bench2Drive基准上的闭环性能表现。

Abstract: Current Vision-Language-Action (VLA) paradigms in autonomous driving primarily rely on Imitation Learning (IL), which introduces inherent challenges such as distribution shift and causal confusion. Online Reinforcement Learning offers a promising pathway to address these issues through trial-and-error learning. However, applying online reinforcement learning to VLA models in autonomous driving is hindered by inefficient exploration in continuous action spaces. To overcome this limitation, we propose MindDrive, a VLA framework comprising a large language model (LLM) with two distinct sets of LoRA parameters. The one LLM serves as a Decision Expert for scenario reasoning and driving decision-making, while the other acts as an Action Expert that dynamically maps linguistic decisions into feasible trajectories. By feeding trajectory-level rewards back into the reasoning space, MindDrive enables trial-and-error learning over a finite set of discrete linguistic driving decisions, instead of operating directly in a continuous action space. This approach effectively balances optimal decision-making in complex scenarios, human-like driving behavior, and efficient exploration in online reinforcement learning. MindDrive achieves strong closed-loop performance on the challenging Bench2Drive benchmark, with a Driving Score (DS) of 78.04 and a Success Rate (SR) of 55.09%. To the best of our knowledge, this is the first work to demonstrate the effectiveness of online reinforcement learning for the VLA model in autonomous driving.

</details>


### [86] [Anatomy Guided Coronary Artery Segmentation from CCTA Using Spatial Frequency Joint Modeling](https://arxiv.org/abs/2512.12539)
*Huan Huang,Michele Esposito,Chen Zhao*

Main category: cs.CV

TL;DR: 提出了一种整合心肌先验和小波变换的冠状动脉分割方法，在复杂条件下表现优异，优于主流模型。


<details>
  <summary>Details</summary>
Motivation: 准确的冠状动脉分割对于定量分析和临床决策支持至关重要，但由于小血管口径、复杂分支、模糊边界和心肌干扰，可靠分割仍具挑战性。

Method: 提出了一个冠状动脉分割框架，整合了心肌解剖先验、结构感知特征编码和三维小波逆小波变换。在编码阶段加入心肌先验和基于残差注意力的特征增强，以加强冠状动脉结构表示。小波逆小波基于下采样和上采样实现了联合空间频率建模，并保留了多尺度结构一致性，而多尺度特征融合模块在解码阶段整合了语义和几何信息。

Result: 在公开的ImageCAS数据集上，该方法实现了Dice系数0.8082、敏感性0.7946、精确度0.8471和HD95为9.77 mm，优于多个主流分割模型。消融研究进一步证实了各组成部分的互补贡献。

Conclusion: 该方法在复杂几何条件下实现了更稳定和一致的冠状动脉分割，为后续冠状动脉结构分析任务提供了可靠的分割结果。

Abstract: Accurate coronary artery segmentation from coronary computed tomography angiography is essential for quantitative coronary analysis and clinical decision support. Nevertheless, reliable segmentation remains challenging because of small vessel calibers, complex branching, blurred boundaries, and myocardial interference. We propose a coronary artery segmentation framework that integrates myocardial anatomical priors, structure aware feature encoding, and three dimensional wavelet inverse wavelet transformations. Myocardial priors and residual attention based feature enhancement are incorporated during encoding to strengthen coronary structure representation. Wavelet inverse wavelet based downsampling and upsampling enable joint spatial frequency modeling and preserve multi scale structural consistency, while a multi scale feature fusion module integrates semantic and geometric information in the decoding stage. The model is trained and evaluated on the public ImageCAS dataset using a 3D overlapping patch based strategy with a 7:1:2 split for training, validation, and testing. Experimental results demonstrate that the proposed method achieves a Dice coefficient of 0.8082, Sensitivity of 0.7946, Precision of 0.8471, and an HD95 of 9.77 mm, outperforming several mainstream segmentation models. Ablation studies further confirm the complementary contributions of individual components. The proposed method enables more stable and consistent coronary artery segmentation under complex geometric conditions, providing reliable segmentation results for subsequent coronary structure analysis tasks.

</details>


### [87] [Supervised Contrastive Frame Aggregation for Video Representation Learning](https://arxiv.org/abs/2512.12549)
*Shaif Chowdhury,Mushfika Rahman,Greg Hamerly*

Main category: cs.CV

TL;DR: A supervised contrastive learning framework for video representation learning using frame aggregation and pre-trained CNNs, achieving higher accuracy with less computation than ViVIT.


<details>
  <summary>Details</summary>
Motivation: To address the computational inefficiency of complex video transformer models and improve video representation learning by leveraging global temporal context and reducing overfitting through diverse positive samples.

Method: The method employs a video-to-image aggregation strategy, spatially arranging multiple frames into a single input image, and uses a contrastive learning objective to compare pairwise projections. It leverages pre-trained CNNs like ResNet50 to avoid computational overhead.

Result: The method achieves 76% classification accuracy on Penn Action (vs. 43% by ViVIT) and 48% on HMDB51 (vs. 37% by ViVIT), outperforming existing approaches.

Conclusion: The proposed Supervised Contrastive Frame Aggregation method demonstrates superior performance in video representation learning, achieving higher classification accuracy with fewer computational resources compared to existing methods like ViVIT.

Abstract: We propose a supervised contrastive learning framework for video representation learning that leverages temporally global context. We introduce a video to image aggregation strategy that spatially arranges multiple frames from each video into a single input image. This design enables the use of pre trained convolutional neural network backbones such as ResNet50 and avoids the computational overhead of complex video transformer models. We then design a contrastive learning objective that directly compares pairwise projections generated by the model. Positive pairs are defined as projections from videos sharing the same label while all other projections are treated as negatives. Multiple natural views of the same video are created using different temporal frame samplings from the same underlying video. Rather than relying on data augmentation these frame level variations produce diverse positive samples with global context and reduce overfitting. Experiments on the Penn Action and HMDB51 datasets demonstrate that the proposed method outperforms existing approaches in classification accuracy while requiring fewer computational resources. The proposed Supervised Contrastive Frame Aggregation method learns effective video representations in both supervised and self supervised settings and supports video based tasks such as classification and captioning. The method achieves seventy six percent classification accuracy on Penn Action compared to forty three percent achieved by ViVIT and forty eight percent accuracy on HMDB51 compared to thirty seven percent achieved by ViVIT.

</details>


### [88] [StreamingAssistant: Efficient Visual Token Pruning for Accelerating Online Video Understanding](https://arxiv.org/abs/2512.12560)
*Xinqi Jin,Hanxun Yu,Bohan Yu,Kebin Liu,Jian Liu,Keda Tao,Yixuan Pei,Huan Wang,Fan Dang,Jiangchuan Liu,Weiqiang Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种令牌修剪方法，通过新冗余度量标准和掩码修剪策略，显著减少视频理解的计算负担，同时提升准确性。


<details>
  <summary>Details</summary>
Motivation: 在线视频理解在公共监控和AI眼镜等应用中至关重要，但多模态大语言模型（MLLMs）在此领域的应用面临视频帧数量多导致的高GPU内存使用和计算延迟挑战。

Method: 论文提出了一种令牌修剪方法，包括引入MSSAVT冗余度量标准和掩码修剪策略，以解决视频帧数量多导致的GPU内存和计算延迟问题。此外，还整合了现有的基于时间冗余的修剪方法。

Result: 实验结果表明，该方法在多个在线和离线视频理解基准测试中显著提高了准确性（最多提高4%），且修剪延迟极低（小于1ms）。

Conclusion: 该论文提出了一种基于令牌修剪的方法，通过引入新的冗余度量标准MSSAVT和掩码修剪策略，有效减少了视频理解中的计算延迟和GPU内存使用，同时保持了关键信息。实验证明该方法在多个视频理解基准测试中显著提高了准确性。

Abstract: Online video understanding is essential for applications like public surveillance and AI glasses. However, applying Multimodal Large Language Models (MLLMs) to this domain is challenging due to the large number of video frames, resulting in high GPU memory usage and computational latency. To address these challenges, we propose token pruning as a means to reduce context length while retaining critical information. Specifically, we introduce a novel redundancy metric, Maximum Similarity to Spatially Adjacent Video Tokens (MSSAVT), which accounts for both token similarity and spatial position. To mitigate the bidirectional dependency between pruning and redundancy, we further design a masked pruning strategy that ensures only mutually unadjacent tokens are pruned. We also integrate an existing temporal redundancy-based pruning method to eliminate temporal redundancy of the video modality. Experimental results on multiple online and offline video understanding benchmarks demonstrate that our method significantly improves the accuracy (i.e., by 4\% at most) while incurring a negligible pruning latency (i.e., less than 1ms). Our full implementation will be made publicly available.

</details>


### [89] [From Tokens to Photons: Test-Time Physical Prompting for Vison-Language Models](https://arxiv.org/abs/2512.12571)
*Boyeong Im,Wooseok Lee,Yoojin Kwon,Hyung-Sin Kim*

Main category: cs.CV

TL;DR: MVP框架利用相机曝光三角作为物理提示，通过选择和组合真实物理视图显著提升视觉语言模型在物理环境中的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 扩展视觉语言模型从网络图像到传感器介导物理环境的应用，通过物理提示提升测试时适应性。

Method: MVP框架通过获取场景的物理视图库，使用源亲和性评分选择前k个传感器设置，对保留视图进行轻量级数字增强，过滤低熵增强视图子集，并通过零温度softmax（硬投票）聚合预测。

Result: 在ImageNet-ES和ImageNet-ES-Diverse数据集上，MVP比仅数字TTA方法性能提升高达25.6个百分点，且在实际参数候选集减少时仍有效。

Conclusion: MVP框架通过物理提示（相机曝光三角）显著提升了视觉语言模型在传感器介导物理环境中的鲁棒性，证明了测量时控制（选择和组合真实物理视图）的重要性。

Abstract: To extend the application of vision-language models (VLMs) from web images to sensor-mediated physical environments, we propose Multi-View Physical-prompt for Test-Time Adaptation (MVP), a forward-only framework that moves test-time adaptation (TTA) from tokens to photons by treating the camera exposure triangle--ISO, shutter speed, and aperture--as physical prompts. At inference, MVP acquires a library of physical views per scene, selects the top-k sensor settings using a source-affinity score, evaluates each retained view under lightweight digital augmentations, filters the lowest-entropy subset of augmented views, and aggregates predictions with Zero-temperature softmax (i.e., hard voting). This selection-then-vote design is simple, calibration-friendly, and requires no gradients or model modifications. On ImageNet-ES and ImageNet-ES-Diverse, MVP consistently outperforms digital-only TTA on single Auto-Exposure captures, by up to 25.6 percentage points (pp), and delivers up to 3.4 pp additional gains over pipelines that combine conventional sensor control with TTA. MVP remains effective under reduced parameter candidate sets that lower capture latency, demonstrating practicality. These results support the main claim that, beyond post-capture prompting, measurement-time control--selecting and combining real physical views--substantially improves robustness for VLMs.

</details>


### [90] [StegaVAR: Privacy-Preserving Video Action Recognition via Steganographic Domain Analysis](https://arxiv.org/abs/2512.12586)
*Lixin Chen,Chaomeng Chen,Jiale Zhou,Zhijian Wu,Xun Lin*

Main category: cs.CV

TL;DR: StegaVAR 是一种新型隐私保护框架，通过隐写技术嵌入动作视频并直接在隐写域中进行VAR，解决了传统方法的隐蔽性和时空破坏问题。


<details>
  <summary>Details</summary>
Motivation: 当前隐私保护方法存在低隐蔽性和时空破坏问题，需要一种既能保护隐私又不影响VAR性能的解决方案。

Method: 提出了 Secret Spatio-Temporal Promotion (STeP) 和 Cross-Band Difference Attention (CroDA) 方法，用于在隐写域中进行特征提取和干扰抑制。

Result: 实验证明 StegaVAR 在广泛使用的数据集上实现了优越的VAR和隐私保护性能，且适用于多种隐写模型。

Conclusion: StegaVAR 框架通过将动作视频嵌入普通封面视频并在隐写域中直接执行视频动作识别（VAR），有效解决了隐私泄露问题，同时保持了时空信息的完整性。

Abstract: Despite the rapid progress of deep learning in video action recognition (VAR) in recent years, privacy leakage in videos remains a critical concern. Current state-of-the-art privacy-preserving methods often rely on anonymization. These methods suffer from (1) low concealment, where producing visually distorted videos that attract attackers' attention during transmission, and (2) spatiotemporal disruption, where degrading essential spatiotemporal features for accurate VAR. To address these issues, we propose StegaVAR, a novel framework that embeds action videos into ordinary cover videos and directly performs VAR in the steganographic domain for the first time. Throughout both data transmission and action analysis, the spatiotemporal information of hidden secret video remains complete, while the natural appearance of cover videos ensures the concealment of transmission. Considering the difficulty of steganographic domain analysis, we propose Secret Spatio-Temporal Promotion (STeP) and Cross-Band Difference Attention (CroDA) for analysis within the steganographic domain. STeP uses the secret video to guide spatiotemporal feature extraction in the steganographic domain during training. CroDA suppresses cover interference by capturing cross-band semantic differences. Experiments demonstrate that StegaVAR achieves superior VAR and privacy-preserving performance on widely used datasets. Moreover, our framework is effective for multiple steganographic models.

</details>


### [91] [Automatic Wire-Harness Color Sequence Detector](https://arxiv.org/abs/2512.12590)
*Indiwara Nanayakkara,Dehan Jayawickrama,Mervyn Parakrama B. Ekanayake*

Main category: cs.CV

TL;DR: 论文提出了一种半自动化机器视觉系统，用于电线束检测，实现了100%准确率和44%的时间节省。


<details>
  <summary>Details</summary>
Motivation: 现代电子制造服务（EMS）行业中，电线束检测过程仍为劳动密集型且易出错，因此需要一种更高效的自动化解决方案。

Method: 系统集成了五个工业标准CMOS摄像头，采用基于HSV和RGB颜色域值比较的颜色序列分类器，用户可通过至少五个参考样本训练系统。

Result: 系统在实际部署中实现了100%的检测准确率，检测时间减少了44%，并具备用户管理、可调照明、会话数据存储和安全登录等附加功能。

Conclusion: 该论文提出的半自动化机器视觉系统在电线束检测中实现了100%的检测准确率，并将检测时间减少了44%，证明了其可靠性和高效性。

Abstract: Wire harness inspection process remains a labor-intensive process prone to errors in the modern Electronics Manufacturing Services (EMS) industry. This paper introduces a semiautomated machine vision system capable of verifying correct wire positioning, correctness of the connector polarity and correctness of color sequences for both linear and circular wire harness configurations. Five industrial standard CMOS cameras are integrated into a modularized mechanical framework in the physical structure of the solution and a HSV and RGB color domain value comparison based color sequence classifier is used in the operation. For each harness batch, a user can train the system using at least five reference samples; the trained file is stored and reused for similar harness types. The Solution is deployed at GPV Lanka Pvt. Ltd. (Fig. 2) and the system achieved 100% detection accuracy and reduced inspection time by 44% compared to manual methods. Additional features include user management, adjustable lighting, session data storage, and secure login. Results of this product usage in the real world situation demonstrate that this approach delivers reliable and efficient inspection capabilities.

</details>


### [92] [Vision-Enhanced Large Language Models for High-Resolution Image Synthesis and Multimodal Data Interpretation](https://arxiv.org/abs/2512.12595)
*Karthikeya KV*

Main category: cs.CV

TL;DR: A vision-enhanced LLM framework with rectified flow and bidirectional tokenization improves image synthesis and multimodal understanding, showing 25% better resolution and 20% lower computational costs.


<details>
  <summary>Details</summary>
Motivation: To address challenges in high-resolution image synthesis and multimodal data interpretation by integrating vision-enhanced LLMs with advanced transformer-based architectures.

Method: The proposed model uses a rectified flow mechanism for efficient generation, bidirectional tokenization for merging multimodal inputs, and a hybrid text-image sequence modeling approach, optimized with a noise-aware learning algorithm.

Result: The model achieves a 25% increase in image resolution clarity and a 20% reduction in computational requirements compared to diffusion-based methods, with robust scalability and adaptability.

Conclusion: This work highlights the transformative potential of vision-enhanced LLMs in advancing computer vision and multimodal AI, demonstrating significant improvements in image synthesis and multimodal data interpretation.

Abstract: This research introduces a transformative framework for integrating Vision-Enhanced Large Language Models (LLMs) with advanced transformer-based architectures to tackle challenges in high-resolution image synthesis and multimodal data interpretation. The proposed model incorporates a rectified flow mechanism that connects noise and data with linear paths, enabling efficient and high-quality generation. A bidirectional tokenization strategy is employed to seamlessly merge inputs from text, image, and video modalities, fostering a unified understanding across diverse data types. By embedding spatial-temporal features and leveraging a hybrid text-image sequence modeling approach, the framework achieves unparalleled fidelity in synthesized images and coherent multimodal representations. The architecture is optimized with a noise-aware learning algorithm, addressing discrepancies in noisy data distributions and improving generative performance under varying input conditions. Rigorous evaluations on benchmark datasets demonstrate a 25% increase in image resolution clarity and a 20% reduction in computational requirements compared to diffusion-based methods. Furthermore, the model exhibits robust scalability and adaptability, showcasing its potential in applications like autonomous systems, creative content generation, and advanced video analysis. This work underscores the role of vision-centric LLMs in redefining capabilities in computer vision and multimodal artificial intelligence.

</details>


### [93] [Content-Aware Ad Banner Layout Generation with Two-Stage Chain-of-Thought in Vision Language Models](https://arxiv.org/abs/2512.12596)
*Kei Yoshitake,Kento Hosono,Ken Kobayashi,Kazuhide Nakata*

Main category: cs.CV

TL;DR: 提出了一种基于视觉语言模型（VLM）的广告布局生成方法，通过分析图像内容生成布局，实验证明其优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统的广告布局技术主要依赖显著性映射，但这种方法往往无法充分考虑图像的详细构成和语义内容。

Method: 利用视觉语言模型（VLM）分析图像中的对象类型及其空间关系，生成基于文本的“放置计划”，并将其渲染为HTML格式的最终布局。

Result: 通过定量和定性比较实验验证了该方法的有效性，证明其能生成更高质量的广告布局。

Conclusion: 通过明确考虑背景图像的内容，该方法生成了明显更高质量的广告布局。

Abstract: In this paper, we propose a method for generating layouts for image-based advertisements by leveraging a Vision-Language Model (VLM). Conventional advertisement layout techniques have predominantly relied on saliency mapping to detect salient regions within a background image, but such approaches often fail to fully account for the image's detailed composition and semantic content. To overcome this limitation, our method harnesses a VLM to recognize the products and other elements depicted in the background and to inform the placement of text and logos. The proposed layout-generation pipeline consists of two steps. In the first step, the VLM analyzes the image to identify object types and their spatial relationships, then produces a text-based "placement plan" based on this analysis. In the second step, that plan is rendered into the final layout by generating HTML-format code. We validated the effectiveness of our approach through evaluation experiments, conducting both quantitative and qualitative comparisons against existing methods. The results demonstrate that by explicitly considering the background image's content, our method produces noticeably higher-quality advertisement layouts.

</details>


### [94] [DiG: Differential Grounding for Enhancing Fine-Grained Perception in Multimodal Large Language Model](https://arxiv.org/abs/2512.12633)
*Zhou Tao,Shida Wang,Yongxiang Hua,Haoyu Cao,Linli Xu*

Main category: cs.CV

TL;DR: DiG框架通过差异定位任务和课程学习，提升MLLMs的细粒度视觉感知能力，并在多个基准测试中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决MLLMs在细粒度视觉感知和精确空间推理方面的局限性。

Method: 提出DiG（Differential Grounding）代理任务框架，通过自动化的3D渲染数据生成管道和课程学习策略，逐步从单一差异到多差异训练模型。

Result: DiG在多个视觉感知基准测试中显著提升模型性能，并有效迁移至标准下游任务。

Conclusion: DiG框架显著提升了MLLMs在细粒度视觉感知任务上的性能，并展示了其在下游任务中的有效迁移能力，为推进MLLMs的细粒度视觉推理提供了一种可扩展且稳健的方法。

Abstract: Multimodal Large Language Models have achieved impressive performance on a variety of vision-language tasks, yet their fine-grained visual perception and precise spatial reasoning remain limited. In this work, we introduce DiG (Differential Grounding), a novel proxy task framework where MLLMs learn fine-grained perception by identifying and localizing all differences between similar image pairs without prior knowledge of their number. To support scalable training, we develop an automated 3D rendering-based data generation pipeline that produces high-quality paired images with fully controllable discrepancies. To address the sparsity of difference signals, we further employ curriculum learning that progressively increases complexity from single to multiple differences, enabling stable optimization. Extensive experiments demonstrate that DiG significantly improves model performance across a variety of visual perception benchmarks and that the learned fine-grained perception skills transfer effectively to standard downstream tasks, including RefCOCO, RefCOCO+, RefCOCOg, and general multimodal perception benchmarks. Our results highlight differential grounding as a scalable and robust approach for advancing fine-grained visual reasoning in MLLMs.

</details>


### [95] [Geometry-Aware Scene-Consistent Image Generation](https://arxiv.org/abs/2512.12598)
*Cong Xie,Che Wang,Yan Zhang,Zheng Pan,Han Zou,Zhenpeng Zhan*

Main category: cs.CV

TL;DR: 提出一种几何感知的场景一致图像生成方法，通过数据构建和注意力损失优化，平衡场景保持与提示响应，生成更一致的图像。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在场景保持与提示响应之间的权衡问题，即要么高保真复制场景但响应提示差，要么优先提示合规而牺牲场景一致性。

Method: 引入两个关键贡献：(i) 场景一致的数据构建流程，生成多样化的几何基础训练对；(ii) 新颖的几何引导注意力损失，利用跨视图线索规范模型的空间推理。

Result: 在场景一致基准测试中，该方法在自动指标和人类偏好研究中均优于现有基线。

Conclusion: 该方法在场景对齐和文本-图像一致性方面优于现有基线，生成几何一致且多样化的图像，忠实于文本指令和场景结构。

Abstract: We study geometry-aware scene-consistent image generation: given a reference scene image and a text condition specifying an entity to be generated in the scene and its spatial relation to the scene, the goal is to synthesize an output image that preserves the same physical environment as the reference scene while correctly generating the entity according to the spatial relation described in the text. Existing methods struggle to balance scene preservation with prompt adherence: they either replicate the scene with high fidelity but poor responsiveness to the prompt, or prioritize prompt compliance at the expense of scene consistency. To resolve this trade-off, we introduce two key contributions: (i) a scene-consistent data construction pipeline that generates diverse, geometrically-grounded training pairs, and (ii) a novel geometry-guided attention loss that leverages cross-view cues to regularize the model's spatial reasoning. Experiments on our scene-consistent benchmark show that our approach achieves better scene alignment and text-image consistency than state-of-the-art baselines, according to both automatic metrics and human preference studies. Our method produces geometrically coherent images with diverse compositions that remain faithful to the textual instructions and the underlying scene structure.

</details>


### [96] [Anatomy-Guided Representation Learning Using a Transformer-Based Network for Thyroid Nodule Segmentation in Ultrasound Images](https://arxiv.org/abs/2512.12662)
*Muhammad Umar Farooq,Abd Ur Rehman,Azka Rehman,Muhammad Usman,Dong-Kyu Chae,Junaid Qadir*

Main category: cs.CV

TL;DR: SSMT-Net通过半监督多任务Transformer网络，显著提升甲状腺结节分割的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决超声图像中甲状腺结节分割的模糊边界、尺寸变化和标注数据稀缺等挑战，提升自动化分割的准确性和泛化能力。

Method: 提出SSMT-Net，一种半监督多任务Transformer网络，结合无监督和有监督阶段，联合优化结节分割、腺体分割和结节大小估计。

Result: 在TN3K和DDTI数据集上的广泛评估显示，SSMT-Net优于现有最先进方法。

Conclusion: SSMT-Net在甲状腺结节分割任务中表现出色，具有较高的准确性和鲁棒性，展现了其在真实临床应用中的潜力。

Abstract: Accurate thyroid nodule segmentation in ultrasound images is critical for diagnosis and treatment planning. However, ambiguous boundaries between nodules and surrounding tissues, size variations, and the scarcity of annotated ultrasound data pose significant challenges for automated segmentation. Existing deep learning models struggle to incorporate contextual information from the thyroid gland and generalize effectively across diverse cases. To address these challenges, we propose SSMT-Net, a Semi-Supervised Multi-Task Transformer-based Network that leverages unlabeled data to enhance Transformer-centric encoder feature extraction capability in an initial unsupervised phase. In the supervised phase, the model jointly optimizes nodule segmentation, gland segmentation, and nodule size estimation, integrating both local and global contextual features. Extensive evaluations on the TN3K and DDTI datasets demonstrate that SSMT-Net outperforms state-of-the-art methods, with higher accuracy and robustness, indicating its potential for real-world clinical applications.

</details>


### [97] [No Cache Left Idle: Accelerating diffusion model via Extreme-slimming Caching](https://arxiv.org/abs/2512.12604)
*Tingyan Wen,Haoyu Li,Yihuang Chen,Xing Zhou,Lifei Zhu,Xueqian Wang*

Main category: cs.CV

TL;DR: X-Slim是一种新型缓存加速框架，通过分层缓存和双阈值控制，显著提升扩散模型速度且保持质量，适用于多种任务。


<details>
  <summary>Details</summary>
Motivation: 扩散模型的计算开销随步数、模型深度和序列长度增加而显著上升，现有缓存方法在速度与质量之间存在固有权衡。

Method: X-Slim是一种无需训练的缓存加速器，采用双阈值控制器和分层缓存策略（时间步、块、令牌级别），通过“推后抛光”过程优化缓存使用。

Result: 在FLUX.1-dev和HunyuanVideo上，X-Slim分别实现了4.97倍和3.52倍的延迟降低；在DiT-XL/2上达到3.13倍加速，且FID提升2.42。

Conclusion: X-Slim通过创新的双阈值控制器和上下文感知缓存策略，显著提升了扩散模型的效率与质量平衡，实现了在多个任务上的高效加速。

Abstract: Diffusion models achieve remarkable generative quality, but computational overhead scales with step count, model depth, and sequence length. Feature caching is effective since adjacent timesteps yield highly similar features. However, an inherent trade-off remains: aggressive timestep reuse offers large speedups but can easily cross the critical line, hurting fidelity, while block- or token-level reuse is safer but yields limited computational savings. We present X-Slim (eXtreme-Slimming Caching), a training-free, cache-based accelerator that, to our knowledge, is the first unified framework to exploit cacheable redundancy across timesteps, structure (blocks), and space (tokens). Rather than simply mixing levels, X-Slim introduces a dual-threshold controller that turns caching into a push-then-polish process: it first pushes reuse at the timestep level up to an early-warning line, then switches to lightweight block- and token-level refresh to polish the remaining redundancy, and triggers full inference once the critical line is crossed to reset accumulated error. At each level, context-aware indicators decide when and where to cache. Across diverse tasks, X-Slim advances the speed-quality frontier. On FLUX.1-dev and HunyuanVideo, it reduces latency by up to 4.97x and 3.52x with minimal perceptual loss. On DiT-XL/2, it reaches 3.13x acceleration and improves FID by 2.42 over prior methods.

</details>


### [98] [Scone: Bridging Composition and Distinction in Subject-Driven Image Generation via Unified Understanding-Generation Modeling](https://arxiv.org/abs/2512.12675)
*Yuran Wang,Bohan Zeng,Chengzhuo Tong,Wenxuan Liu,Yang Shi,Xiaochen Ma,Hao Liang,Yuanxing Zhang,Wentao Zhang*

Main category: cs.CV

TL;DR: Scone是一种结合复合与区分能力的图像生成方法，通过两阶段训练提升性能，并在基准测试中优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有主题驱动图像生成方法在多主题复合时忽视了区分能力，限制了在复杂现实视觉场景中的有效性。

Method: 提出了Scone，一种统一的理解-生成方法，结合了复合与区分能力。采用两阶段训练方案，先学习复合，再通过语义对齐和基于注意力的掩码增强区分能力。

Result: Scone在两项基准测试中，在复合与区分任务上均优于现有开源模型。

Conclusion: Scone模型在复合与区分任务上表现优于现有开源模型，提供了模型、基准和训练数据的公开访问。

Abstract: Subject-driven image generation has advanced from single- to multi-subject composition, while neglecting distinction, the ability to identify and generate the correct subject when inputs contain multiple candidates. This limitation restricts effectiveness in complex, realistic visual settings. We propose Scone, a unified understanding-generation method that integrates composition and distinction. Scone enables the understanding expert to act as a semantic bridge, conveying semantic information and guiding the generation expert to preserve subject identity while minimizing interference. A two-stage training scheme first learns composition, then enhances distinction through semantic alignment and attention-based masking. We also introduce SconeEval, a benchmark for evaluating both composition and distinction across diverse scenarios. Experiments demonstrate that Scone outperforms existing open-source models in composition and distinction tasks on two benchmarks. Our model, benchmark, and training data are available at: https://github.com/Ryann-Ran/Scone.

</details>


### [99] [Patch-wise Retrieval: A Bag of Practical Techniques for Instance-level Matching](https://arxiv.org/abs/2512.12610)
*Wonseok Choi,Sohwi Lim,Nam Hyeon-Woo,Moon Ye-Bin,Dong-Ju Jeong,Jinyoung Hwang,Tae-Hyun Oh*

Main category: cs.CV

TL;DR: Patchify是一个无需微调的块级检索框架，通过局部特征匹配提升图像检索性能，并引入LocScore评估空间正确性，实验证明其高效且可扩展。


<details>
  <summary>Details</summary>
Motivation: 解决实例级图像检索中因对象大小、位置或外观变化带来的挑战，同时提升检索性能、可扩展性和可解释性。

Method: 提出Patchify框架，将数据库图像划分为结构化的小块，通过局部特征与全局查询描述符的对比进行检索。同时引入LocScore作为定位感知指标，评估检索结果的空间正确性。

Result: Patchify在多个基准测试中表现优异，结合Product Quantization技术，显著提升了大规模检索的效率。

Conclusion: Patchify框架在多个基准测试中表现出色，不仅超越了全局方法，还能与最先进的重新排序流程互补。通过引入LocScore这一定位感知指标，研究还强调了空间正确性在图像检索中的重要性。

Abstract: Instance-level image retrieval aims to find images containing the same object as a given query, despite variations in size, position, or appearance. To address this challenging task, we propose Patchify, a simple yet effective patch-wise retrieval framework that offers high performance, scalability, and interpretability without requiring fine-tuning. Patchify divides each database image into a small number of structured patches and performs retrieval by comparing these local features with a global query descriptor, enabling accurate and spatially grounded matching. To assess not just retrieval accuracy but also spatial correctness, we introduce LocScore, a localization-aware metric that quantifies whether the retrieved region aligns with the target object. This makes LocScore a valuable diagnostic tool for understanding and improving retrieval behavior. We conduct extensive experiments across multiple benchmarks, backbones, and region selection strategies, showing that Patchify outperforms global methods and complements state-of-the-art reranking pipelines. Furthermore, we apply Product Quantization for efficient large-scale retrieval and highlight the importance of using informative features during compression, which significantly boosts performance. Project website: https://wons20k.github.io/PatchwiseRetrieval/

</details>


### [100] [Robust Motion Generation using Part-level Reliable Data from Videos](https://arxiv.org/abs/2512.12703)
*Boyuan Li,Sipeng Zheng,Bin Cao,Ruihua Song,Zongqing Lu*

Main category: cs.CV

TL;DR: 提出一种部分感知掩码自回归模型，利用视频中的可信部分数据提升运动生成质量，实验证明优于基线。


<details>
  <summary>Details</summary>
Motivation: 解决从大规模网络视频中提取人体运动时，由于离屏捕捉或遮挡导致部分数据缺失的问题，既不能简单丢弃这些数据以限制规模和多样性，也不能保留它们以牺牲数据质量和模型性能。

Method: 首先将人体分解为五个部分，检测视频帧中清晰可见的部分作为“可信”部分；然后通过提出的部分感知变分自编码器将可信部分编码为潜在标记；最后提出鲁棒的部分级掩码生成模型来预测掩码可信部分，同时忽略噪声部分。

Result: 实验结果表明，该方法在运动质量、语义一致性和多样性方面均优于基线，并在K700-M新基准上取得了成功。

Conclusion: 该方法通过利用视频中可信的部分级数据，提出了一种鲁棒的部分感知掩码自回归模型，成功提升了运动生成的质量、语义一致性和多样性，并在干净和噪声数据集上均优于基线。

Abstract: Extracting human motion from large-scale web videos offers a scalable solution to the data scarcity issue in character animation. However, some human parts in many video frames cannot be seen due to off-screen captures or occlusions. It brings a dilemma: discarding the data missing any part limits scale and diversity, while retaining it compromises data quality and model performance.
  To address this problem, we propose leveraging credible part-level data extracted from videos to enhance motion generation via a robust part-aware masked autoregression model. First, we decompose a human body into five parts and detect the parts clearly seen in a video frame as "credible". Second, the credible parts are encoded into latent tokens by our proposed part-aware variational autoencoder. Third, we propose a robust part-level masked generation model to predict masked credible parts, while ignoring those noisy parts.
  In addition, we contribute K700-M, a challenging new benchmark comprising approximately 200k real-world motion sequences, for evaluation. Experimental results indicate that our method successfully outperforms baselines on both clean and noisy datasets in terms of motion quality, semantic consistency and diversity. Project page: https://boyuaner.github.io/ropar-main/

</details>


### [101] [CoRe3D: Collaborative Reasoning as a Foundation for 3D Intelligence](https://arxiv.org/abs/2512.12768)
*Tianjiao Yu,Xinzhuo Li,Yifan Shen,Yuanzhe Liu,Ismini Lourentzou*

Main category: cs.CV

TL;DR: CoRe3D提出结合语义与空间推理的3D生成框架，显著提升输出一致性和语言对齐。


<details>
  <summary>Details</summary>
Motivation: 大型多模态模型的进展表明显式推理机制对提升模型可靠性、可解释性和跨模态对齐至关重要，但3D领域的此类方法尚未充分发展。

Method: CoRe3D提出了一种统一的3D理解和生成推理框架，通过语义和空间抽象联合操作，利用空间基础推理表示将3D潜在空间分解为局部区域。

Result: CoRe3D生成的3D输出展现出强局部一致性和与语言描述的高度对齐。

Conclusion: CoRe3D通过结合语义推理和结构化空间推理，显著提升了3D内容生成的局部一致性和语言描述的忠实对齐。

Abstract: Recent advances in large multimodal models suggest that explicit reasoning mechanisms play a critical role in improving model reliability, interpretability, and cross-modal alignment. While such reasoning-centric approaches have been proven effective in language and vision tasks, their extension to 3D remains underdeveloped. CoRe3D introduces a unified 3D understanding and generation reasoning framework that jointly operates over semantic and spatial abstractions, enabling high-level intent inferred from language to directly guide low-level 3D content formation. Central to this design is a spatially grounded reasoning representation that decomposes 3D latent space into localized regions, allowing the model to reason over geometry in a compositional and procedural manner. By tightly coupling semantic chain-of-thought inference with structured spatial reasoning, CoRe3D produces 3D outputs that exhibit strong local consistency and faithful alignment with linguistic descriptions.

</details>


### [102] [Reasoning Within the Mind: Dynamic Multimodal Interleaving in Latent Space](https://arxiv.org/abs/2512.12623)
*Chengzhi Liu,Yuzhe Yang,Yue Fan,Qingyue Wei,Sheng Liu,Xin Eric Wang*

Main category: cs.CV

TL;DR: DMLR框架通过动态视觉-文本交织和潜在思维令牌优化，高效提升多模态推理性能。


<details>
  <summary>Details</summary>
Motivation: 受人类非线性认知过程启发，旨在解决现有方法依赖逐步推理、感知-推理交互不稳定及计算开销大的问题。

Method: 采用基于置信度引导的潜在策略梯度优化来细化潜在思维令牌，并结合动态视觉注入策略，实现视觉与文本的动态交织。

Result: 在七个多模态推理基准测试和多种模型架构上，DMLR显著提升了推理和感知性能。

Conclusion: DMLR框架通过动态视觉注入策略和潜在思维令牌优化，显著提升了多模态推理和感知性能，同时保持了高效的推理效率。

Abstract: Recent advancements in Multimodal Large Language Models (MLLMs) have significantly enhanced cross-modal understanding and reasoning by incorporating Chain-of-Thought (CoT) reasoning in the semantic space. Building upon this, recent studies extend the CoT mechanism to the visual modality, enabling models to integrate visual information during reasoning through external tools or explicit image generation. However, these methods remain dependent on explicit step-by-step reasoning, unstable perception-reasoning interaction and notable computational overhead. Inspired by human cognition, we posit that thinking unfolds not linearly but through the dynamic interleaving of reasoning and perception within the mind. Motivated by this perspective, we propose DMLR, a test-time Dynamic Multimodal Latent Reasoning framework that employs confidence-guided latent policy gradient optimization to refine latent think tokens for in-depth reasoning. Furthermore, a Dynamic Visual Injection Strategy is introduced, which retrieves the most relevant visual features at each latent think token and updates the set of best visual patches. The updated patches are then injected into latent think token to achieve dynamic visual-textual interleaving. Experiments across seven multimodal reasoning benchmarks and various model architectures demonstrate that DMLR significantly improves reasoning and perception performance while maintaining high inference efficiency.

</details>


### [103] [Lemon: A Unified and Scalable 3D Multimodal Model for Universal Spatial Understanding](https://arxiv.org/abs/2512.12822)
*Yongyuan Liang,Xiyao Wang,Yuanchen Ju,Jianwei Yang,Furong Huang*

Main category: cs.CV

TL;DR: Lemon是一个统一的Transformer架构，通过联合处理3D点云和语言，解决了现有3D理解模型的碎片化和扩展性问题，并在多项任务中达到最优性能。


<details>
  <summary>Details</summary>
Motivation: 解决大型多模态模型（LMMs）在3D理解中的挑战：点云数据稀疏且不规则，现有模型依赖碎片化架构和模态特定编码器，训练流程存在不稳定性和扩展性差的问题。

Method: Lemon采用统一的Transformer架构，通过将3D点云块和语言标记作为单一序列联合处理，实现了早期空间-语言融合。此外，开发了结构化块化和标记化方案以保留空间上下文，并采用三阶段训练课程逐步提升能力。

Result: Lemon在全面的3D理解和推理任务中实现了最先进的性能，包括物体识别、描述和3D场景中的空间推理。

Conclusion: Lemon提供了一个统一的架构，为现实世界中的3D空间智能应用奠定了基础，并在模型规模和数据增加时展现出强大的扩展性。

Abstract: Scaling large multimodal models (LMMs) to 3D understanding poses unique challenges: point cloud data is sparse and irregular, existing models rely on fragmented architectures with modality-specific encoders, and training pipelines often suffer from instability and poor scalability. We introduce Lemon, a unified transformer architecture that addresses these challenges by jointly processing 3D point cloud patches and language tokens as a single sequence. Unlike prior work that relies on modality-specific encoders and cross-modal alignment modules, this design enables early spatial-linguistic fusion, eliminates redundant encoders, improves parameter efficiency, and supports more effective model scaling. To handle the complexity of 3D data, we develop a structured patchification and tokenization scheme that preserves spatial context, and a three-stage training curriculum that progressively builds capabilities from object-level recognition to scene-level spatial reasoning. Lemon establishes new state-of-the-art performance across comprehensive 3D understanding and reasoning tasks, from object recognition and captioning to spatial reasoning in 3D scenes, while demonstrating robust scaling properties as model size and training data increase. Our work provides a unified foundation for advancing 3D spatial intelligence in real-world applications.

</details>


### [104] [Adapting Multimodal Foundation Models for Few-Shot Learning: A Comprehensive Study on Contrastive Captioners](https://arxiv.org/abs/2512.12824)
*N. K. B. M. P. K. B. Narasinghe,Uthayasanker Thayasivam*

Main category: cs.CV

TL;DR: 研究CoCa在少样本图像分类中的适应策略，发现数据增强对LoRA微调至关重要，提出混合目标提升性能。


<details>
  <summary>Details</summary>
Motivation: 探索生成-对比混合模型（如CoCa）在极端数据稀缺（少样本学习）下的适应能力，填补现有文献对CLIP等双编码器架构的偏重。

Method: 系统评估了从训练无关的混合原型到通过低秩适应（LoRA）进行深度参数适应的策略层次。

Result: 发现数据增强在LoRA微调中的重要性，提出混合目标（结合监督对比损失）在少样本场景中的性能提升，并为训练配置的敏感性提供实证参考。

Conclusion: 本研究全面评估了CoCa视觉主干在少样本图像分类中的适应策略，揭示了数据增强在LoRA微调中的关键作用，并提出了结合监督对比损失的混合目标以提升性能。

Abstract: Large-scale multimodal foundation models, particularly Contrastive Captioners (CoCa), have achieved state-of-the-art results by unifying contrastive alignment with generative captioning. While zero-shot transfer capabilities are well-documented, the adaptation of these generative-contrastive hybrids to downstream tasks with extreme data scarcity (few-shot learning) remains under-explored. Existing literature predominantly focuses on dual-encoder architectures like CLIP, leaving a gap in understanding how CoCa's distinct latent space responds to parameter-efficient fine-tuning (PEFT). This paper presents a comprehensive empirical study on adapting the CoCa visual backbone for few-shot image classification. We systematically evaluate a hierarchy of strategies, ranging from training-free hybrid prototyping to deep parameter adaptation via Low-Rank Adaptation (LoRA). First, we identify an "augmentation divergence": while strong data augmentation degrades the performance of linear probing in low-shot settings, it is essential for stabilizing LoRA fine-tuning. We also demonstrate that hybrid objectives incorporating Supervised Contrastive (SupCon) loss yield consistent performance improvements over standard Cross-Entropy across varying shot counts. Crucially, we characterize the sensitivity of training configurations to data scarcity, providing empirical reference settings for scaling regularization, rank, and sampling strategies to facilitate the efficient adaptation of generative-contrastive foundation models.

</details>


### [105] [Cross-modal Fundus Image Registration under Large FoV Disparity](https://arxiv.org/abs/2512.12657)
*Hongyang Li,Junyi Tao,Qijie Wei,Ningzhi Yang,Meng Wang,Weihong Yu,Xirong Li*

Main category: cs.CV

TL;DR: CARe通过裁剪和对齐模块解决大视场差异的跨模态眼底图像配准问题，实验证明有效。


<details>
  <summary>Details</summary>
Motivation: 现有方法假设跨模态视场差异较小，无法应对大视场差异的挑战场景。

Method: 提出Crop和Alignment模块，利用视网膜生理结构裁剪目标图像，并通过RANSAC算法和多项式坐标拟合进行双拟合对齐。

Result: 在60对OCTA-wfCFP测试集上验证了CARe的有效性。

Conclusion: CARe方法通过Crop和Alignment模块有效解决了大视场差异下的跨模态眼底图像配准问题，实验验证了其可行性。

Abstract: Previous work on cross-modal fundus image registration (CMFIR) assumes small cross-modal Field-of-View (FoV) disparity. By contrast, this paper is targeted at a more challenging scenario with large FoV disparity, to which directly applying current methods fails. We propose Crop and Alignment for cross-modal fundus image Registration(CARe), a very simple yet effective method. Specifically, given an OCTA with smaller FoV as a source image and a wide-field color fundus photograph (wfCFP) as a target image, our Crop operation exploits the physiological structure of the retina to crop from the target image a sub-image with its FoV roughly aligned with that of the source. This operation allows us to re-purpose the previous small-FoV-disparity oriented methods for subsequent image registration. Moreover, we improve spatial transformation by a double-fitting based Alignment module that utilizes the classical RANSAC algorithm and polynomial-based coordinate fitting in a sequential manner. Extensive experiments on a newly developed test set of 60 OCTA-wfCFP pairs verify the viability of CARe for CMFIR.

</details>


### [106] [CogDoc: Towards Unified thinking in Documents](https://arxiv.org/abs/2512.12658)
*Qixin Xu,Haozhe Wang,Che Liu,Fangzhen Lin,Wenhu Chen*

Main category: cs.CV

TL;DR: CogDoc框架通过模仿人类认知过程，结合快速阅读和聚焦思考，使用直接强化学习策略，在7B参数规模下实现了优于更大模型的文档推理性能。


<details>
  <summary>Details</summary>
Motivation: 当前文档推理范式在可扩展性（处理长文本）和保真度（捕捉细粒度多模态细节）之间存在根本性权衡，需要一种新的方法来弥合这一差距。

Method: 提出了一个统一的粗到细思考框架CogDoc，包括低分辨率的“快速阅读”阶段和高分辨率的“聚焦思考”阶段，并研究了直接强化学习（RL）与监督微调（SFT）初始化的对比。

Result: 7B模型在其参数类别中实现了最先进的性能，显著超越了更大的专有模型（如GPT-4o）在视觉丰富的文档基准测试中的表现。

Conclusion: CogDoc框架通过模仿人类认知过程，在长文本处理和细粒度多模态细节捕捉之间取得了平衡，其7B模型在视觉丰富的文档基准测试中表现优异，甚至超过了更大的专有模型。

Abstract: Current document reasoning paradigms are constrained by a fundamental trade-off between scalability (processing long-context documents) and fidelity (capturing fine-grained, multimodal details). To bridge this gap, we propose CogDoc, a unified coarse-to-fine thinking framework that mimics human cognitive processes: a low-resolution "Fast Reading" phase for scalable information localization,followed by a high-resolution "Focused Thinking" phase for deep reasoning. We conduct a rigorous investigation into post-training strategies for the unified thinking framework, demonstrating that a Direct Reinforcement Learning (RL) approach outperforms RL with Supervised Fine-Tuning (SFT) initialization. Specifically, we find that direct RL avoids the "policy conflict" observed in SFT. Empirically, our 7B model achieves state-of-the-art performance within its parameter class, notably surpassing significantly larger proprietary models (e.g., GPT-4o) on challenging, visually rich document benchmarks.

</details>


### [107] [MADTempo: An Interactive System for Multi-Event Temporal Video Retrieval with Query Augmentation](https://arxiv.org/abs/2512.12929)
*Huu-An Vu,Van-Khanh Mai,Trong-Tam Nguyen,Quang-Duc Dam,Tien-Huy Nguyen,Thanh-Huong Le*

Main category: cs.CV

TL;DR: MADTempo是一个结合时间搜索和网络图像备用模块的视频检索框架，旨在解决现有方法在时间依赖性和罕见概念查询上的不足，提升检索系统的时间推理和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 在线平台上视频内容的快速增长需要检索系统不仅能理解孤立的视觉时刻，还能处理复杂事件的时间结构。现有方法在建模多个事件之间的时间依赖性和处理未见或罕见视觉概念的查询方面表现不足。

Method: MADTempo框架包括两个主要组件：时间搜索机制和基于Google图像搜索的备用模块。时间搜索机制通过聚合连续视频片段的相似性分数来捕捉事件级连续性，而备用模块则利用外部网络图像扩展查询表示，弥补预训练视觉嵌入的不足。

Result: MADTempo框架通过其时间搜索和备用模块的组合，显著提高了视频检索系统的时间推理和泛化能力，特别是在处理分布外查询时表现更为鲁棒。

Conclusion: MADTempo框架通过结合时间搜索和基于网络图像的备用模块，显著提升了视频检索系统的时间推理和泛化能力，为大规模视频库的语义感知和自适应检索铺平了道路。

Abstract: The rapid expansion of video content across online platforms has accelerated the need for retrieval systems capable of understanding not only isolated visual moments but also the temporal structure of complex events. Existing approaches often fall short in modeling temporal dependencies across multiple events and in handling queries that reference unseen or rare visual concepts. To address these challenges, we introduce MADTempo, a video retrieval framework developed by our team, AIO_Trinh, that unifies temporal search with web-scale visual grounding. Our temporal search mechanism captures event-level continuity by aggregating similarity scores across sequential video segments, enabling coherent retrieval of multi-event queries. Complementarily, a Google Image Search-based fallback module expands query representations with external web imagery, effectively bridging gaps in pretrained visual embeddings and improving robustness against out-of-distribution (OOD) queries. Together, these components advance the temporal reasoning and generalization capabilities of modern video retrieval systems, paving the way for more semantically aware and adaptive retrieval across large-scale video corpora.

</details>


### [108] [InteracTalker: Prompt-Based Human-Object Interaction with Co-Speech Gesture Generation](https://arxiv.org/abs/2512.12664)
*Sreehari Rajan,Kunal Bhosikar,Charu Sharma*

Main category: cs.CV

TL;DR: InteracTalker通过多阶段训练和自适应融合策略，统一了语音手势和物体交互生成，显著提升真实感和控制性。


<details>
  <summary>Details</summary>
Motivation: 现有方法独立处理语音驱动手势或物体交互，缺乏综合数据集，限制了实际应用。

Method: 采用多阶段训练过程学习统一的动作、语音和提示嵌入空间，并结合广义运动适应模块和自适应融合策略。

Result: InteracTalker在语音手势生成和物体交互合成中均优于现有方法，生成更具真实感的全身动作。

Conclusion: InteracTalker成功地将语音驱动的手势生成与物体交互任务统一起来，显著提升了真实感、灵活性和控制性，超越了现有方法。

Abstract: Generating realistic human motions that naturally respond to both spoken language and physical objects is crucial for interactive digital experiences. Current methods, however, address speech-driven gestures or object interactions independently, limiting real-world applicability due to a lack of integrated, comprehensive datasets. To overcome this, we introduce InteracTalker, a novel framework that seamlessly integrates prompt-based object-aware interactions with co-speech gesture generation. We achieve this by employing a multi-stage training process to learn a unified motion, speech, and prompt embedding space. To support this, we curate a rich human-object interaction dataset, formed by augmenting an existing text-to-motion dataset with detailed object interaction annotations. Our framework utilizes a Generalized Motion Adaptation Module that enables independent training, adapting to the corresponding motion condition, which is then dynamically combined during inference. To address the imbalance between heterogeneous conditioning signals, we propose an adaptive fusion strategy, which dynamically reweights the conditioning signals during diffusion sampling. InteracTalker successfully unifies these previously separate tasks, outperforming prior methods in both co-speech gesture generation and object-interaction synthesis, outperforming gesture-focused diffusion methods, yielding highly realistic, object-aware full-body motions with enhanced realism, flexibility, and control.

</details>


### [109] [Unified Interactive Multimodal Moment Retrieval via Cascaded Embedding-Reranking and Temporal-Aware Score Fusion](https://arxiv.org/abs/2512.12935)
*Toan Le Ngo Thanh,Phat Ha Huu,Tan Nguyen Dang Duy,Thong Nguyen Le Minh,Anh Nguyen Nhu Tinh*

Main category: cs.CV

TL;DR: 提出了一种统一多模态时刻检索系统，通过级联嵌入、时间感知评分和Agent引导查询分解解决了现有方法的挑战。


<details>
  <summary>Details</summary>
Motivation: 视频内容的指数增长迫切需要高效的多模态时刻检索系统，但现有方法面临固定权重融合策略失效、时间建模难以捕捉连贯事件序列以及需要手动模态选择等问题。

Method: 1. 级联双嵌入管道结合BEIT-3和SigLIP进行广泛检索，并通过BLIP-2重新排名平衡召回率和精确率；2. 时间感知评分机制通过束搜索对大的时间间隙应用指数衰减惩罚，构建连贯事件序列；3. Agent引导的查询分解（GPT-4o）自动解释模糊查询，分解为特定模态子查询，并执行自适应分数融合。

Result: 定性分析表明，该系统有效处理模糊查询，检索时间连贯序列，并动态调整融合策略。

Conclusion: 提出的统一多模态时刻检索系统通过三个关键创新有效解决了现有方法的局限性，提升了交互式时刻搜索能力。

Abstract: The exponential growth of video content has created an urgent need for efficient multimodal moment retrieval systems. However, existing approaches face three critical challenges: (1) fixed-weight fusion strategies fail across cross modal noise and ambiguous queries, (2) temporal modeling struggles to capture coherent event sequences while penalizing unrealistic gaps, and (3) systems require manual modality selection, reducing usability. We propose a unified multimodal moment retrieval system with three key innovations. First, a cascaded dual-embedding pipeline combines BEIT-3 and SigLIP for broad retrieval, refined by BLIP-2 based reranking to balance recall and precision. Second, a temporal-aware scoring mechanism applies exponential decay penalties to large temporal gaps via beam search, constructing coherent event sequences rather than isolated frames. Third, Agent-guided query decomposition (GPT-4o) automatically interprets ambiguous queries, decomposes them into modality specific sub-queries (visual/OCR/ASR), and performs adaptive score fusion eliminating manual modality selection. Qualitative analysis demonstrates that our system effectively handles ambiguous queries, retrieves temporally coherent sequences, and dynamically adapts fusion strategies, advancing interactive moment search capabilities.

</details>


### [110] [Open-World Deepfake Attribution via Confidence-Aware Asymmetric Learning](https://arxiv.org/abs/2512.12667)
*Haiyang Zheng,Nan Pu,Wenjing Li,Teng Long,Nicu Sebe,Zhun Zhong*

Main category: cs.CV

TL;DR: CAL框架通过动态调整样本损失和选择性学习高置信度样本，解决了现有OW-DFA方法的置信度偏差和未知伪造类型数量假设问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有OW-DFA方法存在两个关键限制：1）置信度偏差导致对未知伪造类型的伪标签不可靠；2）不切实际地假设未知伪造类型的数量已知。CAL框架旨在解决这些问题。

Method: CAL框架包含两个主要组件：Confidence-Aware Consistency Regularization（CCR）和Asymmetric Confidence Reinforcement（ACR）。CCR通过动态调整样本损失来减轻伪标签偏差，ACR则通过选择性学习高置信度样本来分别校准已知和未知类别的置信度。此外，DPP策略以粗到细的方式自动估计未知伪造类型的数量。

Result: 在标准OW-DFA基准和新扩展的基准上，CAL consistently outperforms previous methods，实现了在已知和未知伪造类型上的最先进性能。

Conclusion: CAL框架通过其Confidence-Aware Asymmetric Learning（CAL）和Dynamic Prototype Pruning（DPP）策略，显著提升了Open-World DeepFake Attribution（OW-DFA）的性能，无需预先知道未知伪造类型的数量，实现了在已知和未知伪造类型上的最先进性能。

Abstract: The proliferation of synthetic facial imagery has intensified the need for robust Open-World DeepFake Attribution (OW-DFA), which aims to attribute both known and unknown forgeries using labeled data for known types and unlabeled data containing a mixture of known and novel types. However, existing OW-DFA methods face two critical limitations: 1) A confidence skew that leads to unreliable pseudo-labels for novel forgeries, resulting in biased training. 2) An unrealistic assumption that the number of unknown forgery types is known *a priori*. To address these challenges, we propose a Confidence-Aware Asymmetric Learning (CAL) framework, which adaptively balances model confidence across known and novel forgery types. CAL mainly consists of two components: Confidence-Aware Consistency Regularization (CCR) and Asymmetric Confidence Reinforcement (ACR). CCR mitigates pseudo-label bias by dynamically scaling sample losses based on normalized confidence, gradually shifting the training focus from high- to low-confidence samples. ACR complements this by separately calibrating confidence for known and novel classes through selective learning on high-confidence samples, guided by their confidence gap. Together, CCR and ACR form a mutually reinforcing loop that significantly improves the model's OW-DFA performance. Moreover, we introduce a Dynamic Prototype Pruning (DPP) strategy that automatically estimates the number of novel forgery types in a coarse-to-fine manner, removing the need for unrealistic prior assumptions and enhancing the scalability of our methods to real-world OW-DFA scenarios. Extensive experiments on the standard OW-DFA benchmark and a newly extended benchmark incorporating advanced manipulations demonstrate that CAL consistently outperforms previous methods, achieving new state-of-the-art performance on both known and novel forgery attribution.

</details>


### [111] [Content Adaptive based Motion Alignment Framework for Learned Video Compression](https://arxiv.org/abs/2512.12936)
*Tiange Zhang,Xiandong Meng,Siwei Ma*

Main category: cs.CV

TL;DR: CAMA enhances video compression by adapting encoding strategies to content, using advanced motion alignment and quality-aware techniques, achieving notable performance gains.


<details>
  <summary>Details</summary>
Motivation: Existing end-to-end video compression frameworks lack content-specific adaptation, leading to suboptimal performance. The paper aims to address this by adapting encoding strategies to diverse content characteristics.

Method: The paper introduces a two-stage flow-guided deformable warping mechanism for precise motion compensation, a multi-reference quality aware strategy for distortion weight adjustment, and a training-free module for smooth motion estimation.

Result: Experimental results show that CAMA achieves significant improvements, outperforming state-of-the-art models like DCVC-DC and traditional codec HM-16.25.

Conclusion: The proposed CAMA framework significantly improves video compression performance by introducing content-specific adaptation, achieving a 24.95% BD-rate savings over the baseline model DCVC-TCM and outperforming other state-of-the-art models.

Abstract: Recent advances in end-to-end video compression have shown promising results owing to their unified end-to-end learning optimization. However, such generalized frameworks often lack content-specific adaptation, leading to suboptimal compression performance. To address this, this paper proposes a content adaptive based motion alignment framework that improves performance by adapting encoding strategies to diverse content characteristics. Specifically, we first introduce a two-stage flow-guided deformable warping mechanism that refines motion compensation with coarse-to-fine offset prediction and mask modulation, enabling precise feature alignment. Second, we propose a multi-reference quality aware strategy that adjusts distortion weights based on reference quality, and applies it to hierarchical training to reduce error propagation. Third, we integrate a training-free module that downsamples frames by motion magnitude and resolution to obtain smooth motion estimation. Experimental results on standard test datasets demonstrate that our framework CAMA achieves significant improvements over state-of-the-art Neural Video Compression models, achieving a 24.95% BD-rate (PSNR) savings over our baseline model DCVC-TCM, while also outperforming reproduced DCVC-DC and traditional codec HM-16.25.

</details>


### [112] [Progressive Conditioned Scale-Shift Recalibration of Self-Attention for Online Test-time Adaptation](https://arxiv.org/abs/2512.12673)
*Yushun Tang,Ziqiong Liu,Jiyuan Jia,Yi Zhang,Zhihai He*

Main category: cs.CV

TL;DR: 提出PCSR方法，通过在线学习域分离和因子生成网络，动态调整Transformer自注意力模块，显著提升跨域性能。


<details>
  <summary>Details</summary>
Motivation: 研究发现，当将Transformer网络模型应用于新目标域时，其自注意力模块的Query、Key和Value特征与源域相比变化显著，导致模型性能大幅下降。

Method: 通过在每个Transformer网络层学习一个域分离网络来提取域偏移特征，并利用因子生成器网络预测尺度与移位参数，以实现自注意力的重新校准。这两个轻量级网络在推理过程中在线适应。

Result: 在基准数据集上的实验结果表明，PCSR方法能够显著提升在线测试时域适应性能。

Conclusion: 提出的渐进条件尺度-移位重新校准（PCSR）方法显著提升了在线测试时域适应性能，在ImageNet-C数据集上分类准确率最高提升了3.9%。

Abstract: Online test-time adaptation aims to dynamically adjust a network model in real-time based on sequential input samples during the inference stage. In this work, we find that, when applying a transformer network model to a new target domain, the Query, Key, and Value features of its self-attention module often change significantly from those in the source domain, leading to substantial performance degradation of the transformer model. To address this important issue, we propose to develop a new approach to progressively recalibrate the self-attention at each layer using a local linear transform parameterized by conditioned scale and shift factors. We consider the online model adaptation from the source domain to the target domain as a progressive domain shift separation process. At each transformer network layer, we learn a Domain Separation Network to extract the domain shift feature, which is used to predict the scale and shift parameters for self-attention recalibration using a Factor Generator Network. These two lightweight networks are adapted online during inference. Experimental results on benchmark datasets demonstrate that the proposed progressive conditioned scale-shift recalibration (PCSR) method is able to significantly improve the online test-time domain adaptation performance by a large margin of up to 3.9\% in classification accuracy on the ImageNet-C dataset.

</details>


### [113] [Calibrating Uncertainty for Zero-Shot Adversarial CLIP](https://arxiv.org/abs/2512.12997)
*Wenjing lu,Zerui Tao,Dongping Zhang,Yuning Qiu,Yang Yang,Qibin Zhao*

Main category: cs.CV

TL;DR: 本文提出了一种针对CLIP的对抗性微调方法，通过统一表示预测置信度和语义结构，有效恢复了不确定性校准，提升了对抗鲁棒性。


<details>
  <summary>Details</summary>
Motivation: CLIP在零样本分类中表现强劲，但对对抗性攻击高度脆弱。以往的研究主要关注清洁和对抗性示例之间的预测对数匹配，忽视了不确定性校准，可能损害零样本泛化能力。

Method: 通过将CLIP的输出重新参数化为Dirichlet分布的浓度参数，提出了一种统一的表示方法，捕捉了相对语义结构和预测置信度的大小。

Result: 在多个零样本分类基准测试中，该方法有效恢复了校准的不确定性，并实现了竞争力的对抗鲁棒性，同时保持了清洁准确性。

Conclusion: 本文提出了一种新的对抗性微调目标，旨在同时考虑预测准确性和不确定性对齐，有效恢复了校准的不确定性，并在保持清洁准确性的同时实现了竞争力的对抗鲁棒性。

Abstract: CLIP delivers strong zero-shot classification but remains highly vulnerable to adversarial attacks. Previous work of adversarial fine-tuning largely focuses on matching the predicted logits between clean and adversarial examples, which overlooks uncertainty calibration and may degrade the zero-shot generalization. A common expectation in reliable uncertainty estimation is that predictive uncertainty should increase as inputs become more difficult or shift away from the training distribution. However, we frequently observe the opposite in the adversarial setting: perturbations not only degrade accuracy but also suppress uncertainty, leading to severe miscalibration and unreliable over-confidence. This overlooked phenomenon highlights a critical reliability gap beyond robustness. To bridge this gap, we propose a novel adversarial fine-tuning objective for CLIP considering both prediction accuracy and uncertainty alignments. By reparameterizing the output of CLIP as the concentration parameter of a Dirichlet distribution, we propose a unified representation that captures relative semantic structure and the magnitude of predictive confidence. Our objective aligns these distributions holistically under perturbations, moving beyond single-logit anchoring and restoring calibrated uncertainty. Experiments on multiple zero-shot classification benchmarks demonstrate that our approach effectively restores calibrated uncertainty and achieves competitive adversarial robustness while maintaining clean accuracy.

</details>


### [114] [$β$-CLIP: Text-Conditioned Contrastive Learning for Multi-Granular Vision-Language Alignment](https://arxiv.org/abs/2512.12678)
*Fatimah Zohra,Chen Zhao,Hani Itani,Bernard Ghanem*

Main category: cs.CV

TL;DR: $\beta$-CLIP通过多粒度对比学习框架，显著提升细粒度视觉-语言对齐任务表现。


<details>
  <summary>Details</summary>
Motivation: CLIP在细粒度任务上表现不佳，即使经过长而详细的字幕微调。因此，需要一种能够实现多层次文本与视觉对齐的方法。

Method: 提出$\beta$-CLIP框架，利用跨注意力动态池化图像块，生成上下文视觉嵌入，并引入$\beta$-CAL损失函数平衡严格查询匹配与宽松图像内上下文化。

Result: 在Urban1K和FG-OVD（Hard）数据集上，$\beta$-CLIP分别达到91.8% T2I和92.3% I2T的R@1，以及30.9%的准确率，表现优异。

Conclusion: $\beta$-CLIP通过多粒度文本条件对比学习框架，实现了视觉与语言的多层次对齐，显著提升了密集对齐任务的表现，并成为无硬负样本训练方法中的最先进技术。

Abstract: CLIP achieves strong zero-shot image-text retrieval by aligning global vision and text representations, yet it falls behind on fine-grained tasks even when fine-tuned on long, detailed captions. In this work, we propose $β$-CLIP, a multi-granular text-conditioned contrastive learning framework designed to achieve hierarchical alignment between multiple textual granularities-from full captions to sentences and phrases-and their corresponding visual regions. For each level of granularity, $β$-CLIP utilizes cross-attention to dynamically pool image patches, producing contextualized visual embeddings. To address the semantic overlap inherent in this hierarchy, we introduce the $β$-Contextualized Contrastive Alignment Loss ($β$-CAL). This objective parameterizes the trade-off between strict query-specific matching and relaxed intra-image contextualization, supporting both soft Cross-Entropy and hard Binary Cross-Entropy formulations. Through extensive experiments, we demonstrate that $β$-CLIP significantly improves dense alignment: achieving 91.8% T2I 92.3% I2T at R@1 on Urban1K and 30.9% on FG-OVD (Hard), setting state-of-the-art among methods trained without hard negatives. $β$-CLIP establishes a robust, adaptive baseline for dense vision-language correspondence. The code and models are released at https://github.com/fzohra/B-CLIP.

</details>


### [115] [GTR-Turbo: Merged Checkpoint is Secretly a Free Teacher for Agentic VLM Training](https://arxiv.org/abs/2512.13043)
*Tong Wei,Yijun Yang,Changhao Zhang,Junliang Xing,Yuanchun Shi,Zongqing Lu,Deheng Ye*

Main category: cs.CV

TL;DR: GTR-Turbo 是一种高效的多模态代理 RL 训练方法，通过合并检查点权重作为‘免费’教师，显著提升性能并降低成本。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法依赖昂贵且特权教师模型的问题，同时缓解‘熵崩溃’现象并保持训练稳定性。

Method: GTR-Turbo 合并了 RL 训练过程中生成的检查点权重，并将合并后的模型用作教师模型，通过监督微调或软 logit 蒸馏指导后续 RL 训练。

Result: 在多种视觉代理任务中，GTR-Turbo 将基线模型的准确率提高了 10-30%，同时将训练时间减少了 50%，计算成本降低了 60%。

Conclusion: GTR-Turbo 通过合并 RL 训练中产生的检查点权重，并利用合并后的模型作为‘免费’教师指导后续 RL 训练，显著提升了多模态代理的性能和训练效率。

Abstract: Multi-turn reinforcement learning (RL) for multi-modal agents built upon vision-language models (VLMs) is hampered by sparse rewards and long-horizon credit assignment. Recent methods densify the reward by querying a teacher that provides step-level feedback, e.g., Guided Thought Reinforcement (GTR) and On-Policy Distillation, but rely on costly, often privileged models as the teacher, limiting practicality and reproducibility. We introduce GTR-Turbo, a highly efficient upgrade to GTR, which matches the performance without training or querying an expensive teacher model. Specifically, GTR-Turbo merges the weights of checkpoints produced during the ongoing RL training, and then uses this merged model as a "free" teacher to guide the subsequent RL via supervised fine-tuning or soft logit distillation. This design removes dependence on privileged VLMs (e.g., GPT or Gemini), mitigates the "entropy collapse" observed in prior work, and keeps training stable. Across diverse visual agentic tasks, GTR-Turbo improves the accuracy of the baseline model by 10-30% while reducing wall-clock training time by 50% and compute cost by 60% relative to GTR.

</details>


### [116] [Efficient Vision-Language Reasoning via Adaptive Token Pruning](https://arxiv.org/abs/2512.12701)
*Xue Li,Xiaonan Song,Henry Hu*

Main category: cs.CV

TL;DR: ATP通过动态剪枝token提升VLMs效率，减少40%计算量且几乎不影响精度，适用于边缘计算。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLMs）因统一处理所有token导致计算效率低下，阻碍了实际部署。

Method: 引入自适应token剪枝（ATP）机制，结合ViT CLS注意力和CLIP文本-图像相似性评分，动态选择top-K token供LLM处理。

Result: ATP在VQAv2、GQA和COCO等任务上减少约40%的FLOPs，端到端延迟提升1.5倍，准确率损失低于1%，且增强了模型的解释性和鲁棒性。

Conclusion: ATP通过动态保留最具信息量的token，显著降低了计算需求，同时保持了模型的准确性和鲁棒性，证明了资源受限的推理和模型可靠性可以共存。

Abstract: Real-world deployment of Vision-Language Models (VLMs) is hindered by high computational demands, as existing architectures inefficiently process all tokens uniformly. We introduce Adaptive Token Pruning (ATP), a dynamic inference mechanism that retains only the most informative tokens based on contextual relevance. ATP operates at the vision-language interface, assigning a hybrid importance score combining ViT CLS attention (intra-modal saliency) and CLIP text-image similarity (inter-modal relevance) to keep top-K tokens for the LLM. Unlike static compression, ATP adapts to each input without modifying the backbone. Proposed as a lightweight gating module, ATP is compatible with popular backbones like BLIP-2, LLaVA, and Flamingo. Preliminary evaluations across VQAv2, GQA, and COCO indicate that ATP reduces inference FLOPs by around 40% and achieves roughly 1.5x speedups in end-to-end latency with negligible accuracy loss (less than 1%). Qualitative analyses suggest ATP preserves visual grounding and enhances interpretability. Beyond efficiency, we investigate robustness under corruptions; observations suggest adaptive pruning suppresses spurious correlations, improving stability. These findings imply that resource-constrained inference and model reliability are not competing objectives. Finally, we discuss ATP's role in efficient multimodal edge computing pipelines.

</details>


### [117] [UniVCD: A New Method for Unsupervised Change Detection in the Open-Vocabulary Era](https://arxiv.org/abs/2512.13089)
*Ziqiang Zhu,Bowei Yang*

Main category: cs.CV

TL;DR: UniVCD is an unsupervised, open-vocabulary change detection method using frozen SAM2 and CLIP, achieving strong performance without labeled data.


<details>
  <summary>Details</summary>
Motivation: Existing CD methods rely on supervised learning, which is dataset-dependent, costly to annotate, and limited to predefined categories. UniVCD aims to overcome these limitations by enabling unsupervised, open-vocabulary change detection.

Method: UniVCD leverages frozen SAM2 and CLIP models, introducing a lightweight feature alignment module to combine SAM2's detailed spatial representations with CLIP's semantic priors. A post-processing pipeline is added to reduce noise and pseudo-changes.

Result: UniVCD matches or surpasses existing open-vocabulary CD methods in metrics like F1 and IoU on public BCD and SCD benchmarks.

Conclusion: UniVCD demonstrates that unsupervised change detection using frozen vision foundation models (SAM2 and CLIP) with lightweight multi-modal alignment is a practical and effective approach for open-vocabulary CD, achieving strong performance on public benchmarks.

Abstract: Change detection (CD) identifies scene changes from multi-temporal observations and is widely used in urban development and environmental monitoring. Most existing CD methods rely on supervised learning, making performance strongly dataset-dependent and incurring high annotation costs; they typically focus on a few predefined categories and generalize poorly to diverse scenes. With the rise of vision foundation models such as SAM2 and CLIP, new opportunities have emerged to relax these constraints. We propose Unified Open-Vocabulary Change Detection (UniVCD), an unsupervised, open-vocabulary change detection method built on frozen SAM2 and CLIP. UniVCD detects category-agnostic changes across diverse scenes and imaging geometries without any labeled data or paired change images. A lightweight feature alignment module is introduced to bridge the spatially detailed representations from SAM2 and the semantic priors from CLIP, enabling high-resolution, semantically aware change estimation while keeping the number of trainable parameters small. On top of this, a streamlined post-processing pipeline is further introduced to suppress noise and pseudo-changes, improving the detection accuracy for objects with well-defined boundaries. Experiments on several public BCD (Binary Change Detection) and SCD (Semantic Change Detection) benchmarks show that UniVCD achieves consistently strong performance and matches or surpasses existing open-vocabulary CD methods in key metrics such as F1 and IoU. The results demonstrate that unsupervised change detection with frozen vision foundation models and lightweight multi-modal alignment is a practical and effective paradigm for open-vocabulary CD. Code and pretrained models will be released at https://github.com/Die-Xie/UniVCD.

</details>


### [118] [Spinal Line Detection for Posture Evaluation through Train-ing-free 3D Human Body Reconstruction with 2D Depth Images](https://arxiv.org/abs/2512.12718)
*Sehyun Kim,Hye Jun Lee,Jiwoo Lee,Changgyun Kim,Taemin Lee*

Main category: cs.CV

TL;DR: 本研究开发了一种3D身体姿势分析系统，通过整合多方向深度图像和先进注册技术，克服了现有方法的限制，实现了高精度的脊柱中心线估计。


<details>
  <summary>Details</summary>
Motivation: 现有基于多图像的人体恢复方法需要昂贵设备和复杂流程，而基于单图像的方法由于遮挡和视角限制难以准确估计脊柱中心线等内部结构。本研究旨在弥补多图像方法的不足并解决单图像方法的局限性。

Method: 通过整合四个方向的深度图像恢复3D人体模型并自动估计脊柱中心线，采用全局和精细注册的层次匹配，应用自适应顶点减少技术保持网格分辨率和形状可靠性，并使用细节层次集成确保脊柱角度估计的准确性和稳定性。

Result: 提出的方法实现了高精度的3D脊柱注册估计，验证了匹配质量的改进。

Conclusion: 本研究提出了一种高精度的3D脊柱注册估计方法，不依赖训练数据或复杂神经网络模型，验证了匹配质量的提升。

Abstract: The spinal angle is an important indicator of body balance. It is important to restore the 3D shape of the human body and estimate the spine center line. Existing mul-ti-image-based body restoration methods require expensive equipment and complex pro-cedures, and single image-based body restoration methods have limitations in that it is difficult to accurately estimate the internal structure such as the spine center line due to occlusion and viewpoint limitation. This study proposes a method to compensate for the shortcomings of the multi-image-based method and to solve the limitations of the sin-gle-image method. We propose a 3D body posture analysis system that integrates depth images from four directions to restore a 3D human model and automatically estimate the spine center line. Through hierarchical matching of global and fine registration, restora-tion to noise and occlusion is performed. Also, the Adaptive Vertex Reduction is applied to maintain the resolution and shape reliability of the mesh, and the accuracy and stabil-ity of spinal angle estimation are simultaneously secured by using the Level of Detail en-semble. The proposed method achieves high-precision 3D spine registration estimation without relying on training data or complex neural network models, and the verification confirms the improvement of matching quality.

</details>


### [119] [GenieDrive: Towards Physics-Aware Driving World Model with 4D Occupancy Guided Video Generation](https://arxiv.org/abs/2512.12751)
*Zhenya Yang,Zhe Liu,Yuxiang Lu,Liping Hou,Chenxuan Miao,Siyi Peng,Bailan Feng,Xiang Bai,Hengshuang Zhao*

Main category: cs.CV

TL;DR: GenieDrive 通过4D占用生成和VAE压缩等技术，实现了物理感知的高质量驾驶视频生成，显著提升了预测和视频质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖单一扩散模型直接映射驾驶动作为视频，导致学习困难且输出物理不一致。为解决这些问题，提出了物理感知的驾驶视频生成框架。

Method: GenieDrive 采用4D占用生成作为基础，提出VAE压缩高分辨率占用至潜在三平面表示，并引入MCA建模控制对占用演化的影响，以及端到端训练VAE与预测模块。

Result: GenieDrive 在推理速度41 FPS下实现了7.2%的预测mIoU提升，仅使用3.47 M参数，视频生成质量提升20.7%（FVD降低）。

Conclusion: GenieDrive 提出了一种新型框架，用于物理感知的驾驶视频生成，通过生成4D占用作为物理信息基础，并结合VAE和MCA等技术，显著提升了视频质量和预测准确性。

Abstract: Physics-aware driving world model is essential for drive planning, out-of-distribution data synthesis, and closed-loop evaluation. However, existing methods often rely on a single diffusion model to directly map driving actions to videos, which makes learning difficult and leads to physically inconsistent outputs. To overcome these challenges, we propose GenieDrive, a novel framework designed for physics-aware driving video generation. Our approach starts by generating 4D occupancy, which serves as a physics-informed foundation for subsequent video generation. 4D occupancy contains rich physical information, including high-resolution 3D structures and dynamics. To facilitate effective compression of such high-resolution occupancy, we propose a VAE that encodes occupancy into a latent tri-plane representation, reducing the latent size to only 58% of that used in previous methods. We further introduce Mutual Control Attention (MCA) to accurately model the influence of control on occupancy evolution, and we jointly train the VAE and the subsequent prediction module in an end-to-end manner to maximize forecasting accuracy. Together, these designs yield a 7.2% improvement in forecasting mIoU at an inference speed of 41 FPS, while using only 3.47 M parameters. Additionally, a Normalized Multi-View Attention is introduced in the video generation model to generate multi-view driving videos with guidance from our 4D occupancy, significantly improving video quality with a 20.7% reduction in FVD. Experiments demonstrate that GenieDrive enables highly controllable, multi-view consistent, and physics-aware driving video generation.

</details>


### [120] [Harmonizing Generalization and Specialization: Uncertainty-Informed Collaborative Learning for Semi-supervised Medical Image Segmentation](https://arxiv.org/abs/2512.13101)
*Wenjing Lu,Yi Hong,Yang Yang*

Main category: cs.CV

TL;DR: UnCoL框架通过双教师模型和不确定性调节，在半监督医学图像分割中平衡通用与特定任务知识，显著提升性能并减少标注需求。


<details>
  <summary>Details</summary>
Motivation: 解决基础模型在有限标注或罕见病理变化下泛化能力不足的问题，平衡通用先验与特定任务需求。

Method: 提出Uncertainty-informed Collaborative Learning (UnCoL)框架，采用双教师模型：一个冻结的基础模型用于传递通用知识，另一个逐步适应的教师模型用于捕捉特定任务的细节。通过预测不确定性自适应调节伪标签学习。

Result: 在多种2D和3D分割基准测试中，UnCoL consistently outperforms state-of-the-art semi-supervised methods and foundation model baselines，且标注需求显著减少。

Conclusion: UnCoL框架通过结合通用基础模型的知识和特定任务的适应性学习，显著提升了半监督医学图像分割的性能，尤其是在标注数据有限的情况下。

Abstract: Vision foundation models have demonstrated strong generalization in medical image segmentation by leveraging large-scale, heterogeneous pretraining. However, they often struggle to generalize to specialized clinical tasks under limited annotations or rare pathological variations, due to a mismatch between general priors and task-specific requirements. To address this, we propose Uncertainty-informed Collaborative Learning (UnCoL), a dual-teacher framework that harmonizes generalization and specialization in semi-supervised medical image segmentation. Specifically, UnCoL distills both visual and semantic representations from a frozen foundation model to transfer general knowledge, while concurrently maintaining a progressively adapting teacher to capture fine-grained and task-specific representations. To balance guidance from both teachers, pseudo-label learning in UnCoL is adaptively regulated by predictive uncertainty, which selectively suppresses unreliable supervision and stabilizes learning in ambiguous regions. Experiments on diverse 2D and 3D segmentation benchmarks show that UnCoL consistently outperforms state-of-the-art semi-supervised methods and foundation model baselines. Moreover, our model delivers near fully supervised performance with markedly reduced annotation requirements.

</details>


### [121] [FysicsWorld: A Unified Full-Modality Benchmark for Any-to-Any Understanding, Generation, and Reasoning](https://arxiv.org/abs/2512.12756)
*Yue Jiang,Dingkang Yang,Minghao Han,Jinghang Han,Zizhi Chen,Yizhou Liu,Mingcheng Li,Peng Zhai,Lihua Zhang*

Main category: cs.CV

TL;DR: FysicsWorld是首个支持图像、视频、音频和文本双向输入输出的统一全模态基准，涵盖16个主要任务和3,268个样本，通过CMCS策略生成全模态数据，评估了30多个模型，为下一代全模态架构评估奠定基础。


<details>
  <summary>Details</summary>
Motivation: 当前基准在范围和集成上存在局限，包括不完整的模态覆盖、仅限于文本中心输出的交互以及模态间弱互依赖和互补性。

Method: 提出了跨模态互补筛选（CMCS）策略，并整合到系统数据构建框架中，生成用于口语交互和融合依赖的跨模态推理的全模态数据。

Result: FysicsWorld揭示了超过30个最先进基线模型在理解、生成和推理方面的性能差异和局限性。

Conclusion: FysicsWorld为评估和推进下一代全模态架构建立了统一基础和强基准。

Abstract: Despite rapid progress in multimodal large language models (MLLMs) and emerging omni-modal architectures, current benchmarks remain limited in scope and integration, suffering from incomplete modality coverage, restricted interaction to text-centric outputs, and weak interdependence and complementarity among modalities. To bridge these gaps, we introduce FysicsWorld, the first unified full-modality benchmark that supports bidirectional input-output across image, video, audio, and text, enabling comprehensive any-to-any evaluation across understanding, generation, and reasoning. FysicsWorld encompasses 16 primary tasks and 3,268 curated samples, aggregated from over 40 high-quality sources and covering a rich set of open-domain categories with diverse question types. We also propose the Cross-Modal Complementarity Screening (CMCS) strategy integrated in a systematic data construction framework that produces omni-modal data for spoken interaction and fusion-dependent cross-modal reasoning. Through a comprehensive evaluation of over 30 state-of-the-art baselines, spanning MLLMs, modality-specific models, unified understanding-generation models, and omni-modal language models, FysicsWorld exposes the performance disparities and limitations across models in understanding, generation, and reasoning. Our benchmark establishes a unified foundation and strong baselines for evaluating and advancing next-generation full-modality architectures.

</details>


### [122] [Diffusion-Based Restoration for Multi-Modal 3D Object Detection in Adverse Weather](https://arxiv.org/abs/2512.13107)
*Zhijian He,Feifei Liu,Yuwei Li,Zhanpeng Liu,Jintao Cheng,Xieyuanli Chen,Xiaoyu Tang*

Main category: cs.CV

TL;DR: DiffFusion是一个通过扩散模型增强恶劣天气下多模态3D检测鲁棒性的框架，结合图像和LiDAR数据恢复及自适应融合，实现了优异性能。


<details>
  <summary>Details</summary>
Motivation: 多模态3D物体检测在恶劣天气条件下的有效性受限于天气引起的失真和多模态数据间的错位。

Method: DiffFusion通过Diffusion-IR恢复受天气影响的图像，通过PCR利用图像对象线索补偿受损的LiDAR数据，并开发了BAFAM模块以解决多模态间的错位问题。

Result: 在三个公共数据集上的广泛实验表明，DiffFusion在恶劣天气条件下表现出色，同时在清洁数据上保持强劲性能。

Conclusion: DiffFusion框架在恶劣天气条件下实现了最先进的鲁棒性，同时保持了良好的清洁数据性能，并在真实世界数据集上验证了其泛化能力。

Abstract: Multi-modal 3D object detection is important for reliable perception in robotics and autonomous driving. However, its effectiveness remains limited under adverse weather conditions due to weather-induced distortions and misalignment between different data modalities. In this work, we propose DiffFusion, a novel framework designed to enhance robustness in challenging weather through diffusion-based restoration and adaptive cross-modal fusion. Our key insight is that diffusion models possess strong capabilities for denoising and generating data that can adapt to various weather conditions. Building on this, DiffFusion introduces Diffusion-IR restoring images degraded by weather effects and Point Cloud Restoration (PCR) compensating for corrupted LiDAR data using image object cues. To tackle misalignments between two modalities, we develop Bidirectional Adaptive Fusion and Alignment Module (BAFAM). It enables dynamic multi-modal fusion and bidirectional bird's-eye view (BEV) alignment to maintain consistent spatial correspondence. Extensive experiments on three public datasets show that DiffFusion achieves state-of-the-art robustness under adverse weather while preserving strong clean-data performance. Zero-shot results on the real-world DENSE dataset further validate its generalization. The implementation of our DiffFusion will be released as open-source.

</details>


### [123] [DePT3R: Joint Dense Point Tracking and 3D Reconstruction of Dynamic Scenes in a Single Forward Pass](https://arxiv.org/abs/2512.13122)
*Vivek Alumootil,Tuan-Anh Vu,M. Khalid Jawed*

Main category: cs.CV

TL;DR: DePT3R 是一种无需相机姿态即可同时进行密集点跟踪和3D重建的动态场景处理框架，性能优越且高效。


<details>
  <summary>Details</summary>
Motivation: 现有方法在动态场景中的密集3D点跟踪存在灵活性不足的问题，而大规模无姿态图像集合的3D重建成功启发了统一动态场景理解的思路。

Method: 通过强大的骨干网络提取深度时空特征，并使用密集预测头回归像素级地图，实现多任务学习。

Result: 在多个动态场景基准测试中表现强劲，内存效率显著优于现有最先进方法。

Conclusion: DePT3R 是一种无需相机姿态即可同时进行密集点跟踪和动态场景3D重建的新框架，显著提高了适应性和效率，在动态场景中表现出色。

Abstract: Current methods for dense 3D point tracking in dynamic scenes typically rely on pairwise processing, require known camera poses, or assume a temporal ordering to input frames, constraining their flexibility and applicability. Additionally, recent advances have successfully enabled efficient 3D reconstruction from large-scale, unposed image collections, underscoring opportunities for unified approaches to dynamic scene understanding. Motivated by this, we propose DePT3R, a novel framework that simultaneously performs dense point tracking and 3D reconstruction of dynamic scenes from multiple images in a single forward pass. This multi-task learning is achieved by extracting deep spatio-temporal features with a powerful backbone and regressing pixel-wise maps with dense prediction heads. Crucially, DePT3R operates without requiring camera poses, substantially enhancing its adaptability and efficiency-especially important in dynamic environments with rapid changes. We validate DePT3R on several challenging benchmarks involving dynamic scenes, demonstrating strong performance and significant improvements in memory efficiency over existing state-of-the-art methods. Data and codes are available via the open repository: https://github.com/StructuresComp/DePT3R

</details>


### [124] [Fast 2DGS: Efficient Image Representation with Deep Gaussian Prior](https://arxiv.org/abs/2512.12774)
*Hao Wang,Ashish Bastola,Chaoyi Zhou,Wenhui Zhu,Xiwen Chen,Xuanzhao Dong,Siyu Huang,Abolfazl Razi*

Main category: cs.CV

TL;DR: Fast-2DGS是轻量级2D高斯泼溅框架，通过深度高斯先验和属性回归网络，高效实现高质量图像表示，降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 现有2D高斯泼溅（2DGS）方法在初始高斯配置预测上存在计算和架构复杂性高的问题，需高效、可解释且可编辑的图像表示方案。

Method: 提出Deep Gaussian Prior作为条件网络捕捉高斯基元空间分布，并设计属性回归网络预测密集高斯属性，采用解耦架构实现高质量重建。

Result: 实验表明，Fast-2DGS在单次前向传播后经少量微调即可实现高质量重建，显著降低计算成本。

Conclusion: Fast-2DGS通过轻量级框架和深度高斯先验，显著降低了计算成本且不牺牲视觉质量，使2DGS更接近工业级部署。

Abstract: As generative models become increasingly capable of producing high-fidelity visual content, the demand for efficient, interpretable, and editable image representations has grown substantially. Recent advances in 2D Gaussian Splatting (2DGS) have emerged as a promising solution, offering explicit control, high interpretability, and real-time rendering capabilities (>1000 FPS). However, high-quality 2DGS typically requires post-optimization. Existing methods adopt random or heuristics (e.g., gradient maps), which are often insensitive to image complexity and lead to slow convergence (>10s). More recent approaches introduce learnable networks to predict initial Gaussian configurations, but at the cost of increased computational and architectural complexity. To bridge this gap, we present Fast-2DGS, a lightweight framework for efficient Gaussian image representation. Specifically, we introduce Deep Gaussian Prior, implemented as a conditional network to capture the spatial distribution of Gaussian primitives under different complexities. In addition, we propose an attribute regression network to predict dense Gaussian properties. Experiments demonstrate that this disentangled architecture achieves high-quality reconstruction in a single forward pass, followed by minimal fine-tuning. More importantly, our approach significantly reduces computational cost without compromising visual quality, bringing 2DGS closer to industry-ready deployment.

</details>


### [125] [Intrinsic Image Fusion for Multi-View 3D Material Reconstruction](https://arxiv.org/abs/2512.13157)
*Peter Kocsis,Lukas Höllein,Matthias Nießner*

Main category: cs.CV

TL;DR: Intrinsic Image Fusion通过结合单视角先验和鲁棒优化框架，实现了高质量物理材质重建，优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 解决多视角图像中高质量物理材质重建的挑战，传统方法依赖昂贵且噪声严重的路径追踪，优化过程高度受限。

Method: 该方法结合了单视角先验和扩散式材质估计器，通过显式低维参数函数拟合预测，并采用鲁棒优化框架，包括软每视角预测选择和基于置信度的软多视角内点集，最终通过逆路径追踪优化低维参数。

Result: 在合成和真实场景中，该方法在材质解缠方面表现优于现有技术，实现了清晰且干净的材质重建。

Conclusion: Intrinsic Image Fusion方法在材质解缠方面优于现有技术，能够生成适合高质量重新照明的清晰、干净的材质重建结果。

Abstract: We introduce Intrinsic Image Fusion, a method that reconstructs high-quality physically based materials from multi-view images. Material reconstruction is highly underconstrained and typically relies on analysis-by-synthesis, which requires expensive and noisy path tracing. To better constrain the optimization, we incorporate single-view priors into the reconstruction process. We leverage a diffusion-based material estimator that produces multiple, but often inconsistent, candidate decompositions per view. To reduce the inconsistency, we fit an explicit low-dimensional parametric function to the predictions. We then propose a robust optimization framework using soft per-view prediction selection together with confidence-based soft multi-view inlier set to fuse the most consistent predictions of the most confident views into a consistent parametric material space. Finally, we use inverse path tracing to optimize for the low-dimensional parameters. Our results outperform state-of-the-art methods in material disentanglement on both synthetic and real scenes, producing sharp and clean reconstructions suitable for high-quality relighting.

</details>


### [126] [L-STEC: Learned Video Compression with Long-term Spatio-Temporal Enhanced Context](https://arxiv.org/abs/2512.12790)
*Tiange Zhang,Zhimeng Huang,Xiandong Meng,Kai Zhang,Zhipin Deng,Siwei Ma*

Main category: cs.CV

TL;DR: L-STEC通过结合长期时空依赖和像素级上下文，显著提升视频压缩性能，比特率节省达37.01%（PSNR）和31.65%（MS-SSIM）。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅依赖前一帧的特征预测时空上下文，导致长期依赖和精细纹理细节缺失，且误差累积问题严重。

Method: 提出L-STEC方法，通过LSTM扩展参考链以捕捉长期依赖，并结合像素级的空间上下文信息，通过多感受野网络融合时空信息。

Result: L-STEC在PSNR和MS-SSIM指标上分别实现37.01%和31.65%的比特率节省，优于VTM-17.0和DCVC-FM。

Conclusion: L-STEC方法通过结合长期时空依赖和像素级空间上下文，显著提升了视频压缩性能，在PSNR和MS-SSIM指标上分别实现了37.01%和31.65%的比特率节省，超越了现有最佳方法。

Abstract: Neural Video Compression has emerged in recent years, with condition-based frameworks outperforming traditional codecs. However, most existing methods rely solely on the previous frame's features to predict temporal context, leading to two critical issues. First, the short reference window misses long-term dependencies and fine texture details. Second, propagating only feature-level information accumulates errors over frames, causing prediction inaccuracies and loss of subtle textures. To address these, we propose the Long-term Spatio-Temporal Enhanced Context (L-STEC) method. We first extend the reference chain with LSTM to capture long-term dependencies. We then incorporate warped spatial context from the pixel domain, fusing spatio-temporal information through a multi-receptive field network to better preserve reference details. Experimental results show that L-STEC significantly improves compression by enriching contextual information, achieving 37.01% bitrate savings in PSNR and 31.65% in MS-SSIM compared to DCVC-TCM, outperforming both VTM-17.0 and DCVC-FM and establishing new state-of-the-art performance.

</details>


### [127] [A Semantically Enhanced Generative Foundation Model Improves Pathological Image Synthesis](https://arxiv.org/abs/2512.13164)
*Xianchao Guan,Zhiyuan Fan,Yifeng Wang,Fuqiang Chen,Yanjiang Zhou,Zengyang Che,Hongxue Meng,Xin Li,Yaowei Wang,Hongpeng Wang,Min Zhang,Heng Tao Shen,Zheng Zhang,Yongbing Zhang*

Main category: cs.CV

TL;DR: CRAFTS是首个病理学专用的生成基础模型，通过双阶段训练和对齐机制生成高质量病理图像，解决数据稀缺问题，提升临床任务性能。


<details>
  <summary>Details</summary>
Motivation: 病理学中临床级人工智能的发展受限于高质量注释数据集的稀缺性，生成模型虽有潜力但存在语义不稳定和形态学幻觉问题。

Method: 采用双阶段训练策略，结合约280万图像-标题对，引入新的对齐机制以抑制语义漂移，确保生物准确性。

Result: CRAFTS能生成涵盖30种癌症类型的多样化病理图像，质量通过客观指标和病理学家评估严格验证，增强的数据集提升了多项临床任务的性能。

Conclusion: CRAFTS通过克服数据稀缺和隐私问题，为病理学提供了多样化的注释组织学数据，支持罕见和复杂癌症表型的诊断工具开发。

Abstract: The development of clinical-grade artificial intelligence in pathology is limited by the scarcity of diverse, high-quality annotated datasets. Generative models offer a potential solution but suffer from semantic instability and morphological hallucinations that compromise diagnostic reliability. To address this challenge, we introduce a Correlation-Regulated Alignment Framework for Tissue Synthesis (CRAFTS), the first generative foundation model for pathology-specific text-to-image synthesis. By leveraging a dual-stage training strategy on approximately 2.8 million image-caption pairs, CRAFTS incorporates a novel alignment mechanism that suppresses semantic drift to ensure biological accuracy. This model generates diverse pathological images spanning 30 cancer types, with quality rigorously validated by objective metrics and pathologist evaluations. Furthermore, CRAFTS-augmented datasets enhance the performance across various clinical tasks, including classification, cross-modal retrieval, self-supervised learning, and visual question answering. In addition, coupling CRAFTS with ControlNet enables precise control over tissue architecture from inputs such as nuclear segmentation masks and fluorescence images. By overcoming the critical barriers of data scarcity and privacy concerns, CRAFTS provides a limitless source of diverse, annotated histology data, effectively unlocking the creation of robust diagnostic tools for rare and complex cancer phenotypes.

</details>


### [128] [DrivePI: Spatial-aware 4D MLLM for Unified Autonomous Driving Understanding, Perception, Prediction and Planning](https://arxiv.org/abs/2512.12799)
*Zhe Liu,Runhui Huang,Rui Yang,Siming Yan,Zining Wang,Lu Hou,Di Lin,Xiang Bai,Hengshuang Zhao*

Main category: cs.CV

TL;DR: DrivePI是一种空间感知4D MLLM框架，整合多模态输入，在自动驾驶任务中表现优异，超越现有模型。


<details>
  <summary>Details</summary>
Motivation: 尽管MLLM在多领域表现出强大能力，但在自动驾驶中生成细粒度3D感知和预测输出的应用仍未被充分探索。

Method: DrivePI通过端到端优化，整合点云、多视角图像和语言指令，并行执行空间理解、3D感知、预测和规划。开发了数据引擎生成文本-occupancy和文本-flow QA对以增强4D空间理解。

Result: DrivePI在多个基准测试中表现优异，如nuScenes-QA上准确率提升2.5%，碰撞率降低70%，并在3D occupancy、occupancy flow和规划任务上显著优于专用VA模型。

Conclusion: DrivePI作为一种统一的空间感知4D MLLM框架，在自动驾驶中的3D感知、预测和规划任务上表现出色，不仅匹配甚至超越了现有的VLA和VA模型。

Abstract: Although multi-modal large language models (MLLMs) have shown strong capabilities across diverse domains, their application in generating fine-grained 3D perception and prediction outputs in autonomous driving remains underexplored. In this paper, we propose DrivePI, a novel spatial-aware 4D MLLM that serves as a unified Vision-Language-Action (VLA) framework that is also compatible with vision-action (VA) models. Our method jointly performs spatial understanding, 3D perception (i.e., 3D occupancy), prediction (i.e., occupancy flow), and planning (i.e., action outputs) in parallel through end-to-end optimization. To obtain both precise geometric information and rich visual appearance, our approach integrates point clouds, multi-view images, and language instructions within a unified MLLM architecture. We further develop a data engine to generate text-occupancy and text-flow QA pairs for 4D spatial understanding. Remarkably, with only a 0.5B Qwen2.5 model as MLLM backbone, DrivePI as a single unified model matches or exceeds both existing VLA models and specialized VA models. Specifically, compared to VLA models, DrivePI outperforms OpenDriveVLA-7B by 2.5% mean accuracy on nuScenes-QA and reduces collision rate by 70% over ORION (from 0.37% to 0.11%) on nuScenes. Against specialized VA models, DrivePI surpasses FB-OCC by 10.3 RayIoU for 3D occupancy on OpenOcc, reduces the mAVE from 0.591 to 0.509 for occupancy flow on OpenOcc, and achieves 32% lower L2 error than VAD (from 0.72m to 0.49m) for planning on nuScenes. Code will be available at https://github.com/happinesslz/DrivePI

</details>


### [129] [LINA: Learning INterventions Adaptively for Physical Alignment and Generalization in Diffusion Models](https://arxiv.org/abs/2512.13290)
*Shu Yu,Chaochao Lu*

Main category: cs.CV

TL;DR: LINA框架通过因果感知干预和针对性引导，解决了扩散模型在物理对齐和OOD指令跟随方面的挑战，取得了最优性能。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在图像和视频生成中表现出色，但在物理对齐和OOD指令跟随方面存在困难，这些问题源于模型未能学习因果方向和分离因果因素。

Method: 引入了Causal Scene Graph (CSG)和Physical Alignment Probe (PAP)数据集，并提出了LINA框架，该框架学习预测特定提示的干预措施，包括在提示和视觉潜在空间中的针对性引导，以及重新分配的因果感知去噪调度。

Result: LINA在具有挑战性的因果生成任务和Winoground数据集上实现了最先进的性能。

Conclusion: LINA框架通过针对性的引导和因果感知的去噪调度，在图像和视频扩散模型中实现了物理对齐和OOD指令跟随，达到了最先进的性能。

Abstract: Diffusion models (DMs) have achieved remarkable success in image and video generation. However, they still struggle with (1) physical alignment and (2) out-of-distribution (OOD) instruction following. We argue that these issues stem from the models' failure to learn causal directions and to disentangle causal factors for novel recombination. We introduce the Causal Scene Graph (CSG) and the Physical Alignment Probe (PAP) dataset to enable diagnostic interventions. This analysis yields three key insights. First, DMs struggle with multi-hop reasoning for elements not explicitly determined in the prompt. Second, the prompt embedding contains disentangled representations for texture and physics. Third, visual causal structure is disproportionately established during the initial, computationally limited denoising steps. Based on these findings, we introduce LINA (Learning INterventions Adaptively), a novel framework that learns to predict prompt-specific interventions, which employs (1) targeted guidance in the prompt and visual latent spaces, and (2) a reallocated, causality-aware denoising schedule. Our approach enforces both physical alignment and OOD instruction following in image and video DMs, achieving state-of-the-art performance on challenging causal generation tasks and the Winoground dataset. Our project page is at https://opencausalab.github.io/LINA.

</details>


### [130] [Learning Common and Salient Generative Factors Between Two Image Datasets](https://arxiv.org/abs/2512.12800)
*Yunlong He,Gwilherm Lesné,Ziqian Liu,Michaël Soumm,Pietro Gori*

Main category: cs.CV

TL;DR: 论文提出了一种对比分析框架，用于分离两个数据集间的共享和特定生成因素，通过新学习策略和损失函数实现高质量生成，实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法主要关注条件操作或解耦表示学习的问题，探索较少研究的对比分析（CA）问题，即分离两个数据集间的共享和特定生成因素。

Method: 通过定义新的学习策略和损失函数，确保共享和特定因素的有效分离，同时保持高质量的图像生成。

Result: 在涵盖人脸、动物图像和医学扫描的多样化数据集上，提出的框架展现出比现有方法更优的分离能力和图像合成质量。

Conclusion: 该论文提出了一种新的对比分析（CA）框架，能够有效分离共享和特定生成因素，并在多种数据集上验证了其优越的分离能力和图像生成质量。

Abstract: Recent advancements in image synthesis have enabled high-quality image generation and manipulation. Most works focus on: 1) conditional manipulation, where an image is modified conditioned on a given attribute, or 2) disentangled representation learning, where each latent direction should represent a distinct semantic attribute. In this paper, we focus on a different and less studied research problem, called Contrastive Analysis (CA). Given two image datasets, we want to separate the common generative factors, shared across the two datasets, from the salient ones, specific to only one dataset. Compared to existing methods, which use attributes as supervised signals for editing (e.g., glasses, gender), the proposed method is weaker, since it only uses the dataset signal. We propose a novel framework for CA, that can be adapted to both GAN and Diffusion models, to learn both common and salient factors. By defining new and well-adapted learning strategies and losses, we ensure a relevant separation between common and salient factors, preserving a high-quality generation. We evaluate our approach on diverse datasets, covering human faces, animal images and medical scans. Our framework demonstrates superior separation ability and image quality synthesis compared to prior methods.

</details>


### [131] [Face Identity Unlearning for Retrieval via Embedding Dispersion](https://arxiv.org/abs/2512.13317)
*Mikhail Zakharov*

Main category: cs.CV

TL;DR: 本文研究了人脸检索系统中的身份遗忘问题，提出了一种基于分散的去学习方法，实验证明该方法在遗忘效果和检索性能上均表现优异。


<details>
  <summary>Details</summary>
Motivation: 人脸识别系统在隐私保护方面存在严重问题，尤其是现代基于嵌入的识别模型的身份检索。本文旨在探索如何使特定身份在检索系统中不可检索，同时保持其余身份的检索性能。

Method: 评估了几种现有的近似类别去学习方法（如随机标记、梯度上升、边界去学习等），并提出了一种基于分散的去学习方法。

Result: 在标准基准测试（VGGFace2、CelebA）上的广泛实验表明，该方法在实现遗忘效果的同时，保持了检索性能。

Conclusion: 本文提出了一种简单而有效的基于分散的去学习方法，用于人脸检索系统中的身份遗忘。该方法在标准基准测试（VGGFace2、CelebA）上表现出色，既能实现高效的遗忘效果，又能保持检索性能。

Abstract: Face recognition systems rely on learning highly discriminative and compact identity clusters to enable accurate retrieval. However, as with other surveillance-oriented technologies, such systems raise serious privacy concerns due to their potential for unauthorized identity tracking. While several works have explored machine unlearning as a means of privacy protection, their applicability to face retrieval - especially for modern embedding-based recognition models - remains largely unexplored. In this work, we study the problem of face identity unlearning for retrieval systems and present its inherent challenges. The goal is to make selected identities unretrievable by dispersing their embeddings on the hypersphere and preventing the formation of compact identity clusters that enable re-identification in the gallery. The primary challenge is to achieve this forgetting effect while preserving the discriminative structure of the embedding space and the retrieval performance of the model for the remaining identities. To address this, we evaluate several existing approximate class unlearning methods (e.g., Random Labeling, Gradient Ascent, Boundary Unlearning, and other recent approaches) in the context of face retrieval and propose a simple yet effective dispersion-based unlearning approach. Extensive experiments on standard benchmarks (VGGFace2, CelebA) demonstrate that our method achieves superior forgetting behavior while preserving retrieval utility.

</details>


### [132] [Schrodinger Audio-Visual Editor: Object-Level Audiovisual Removal](https://arxiv.org/abs/2512.12875)
*Weihan Xu,Kan Jen Cheng,Koichi Saito,Muhammad Jehanzeb Mirza,Tingle Li,Yisi Liu,Alexander H. Liu,Liming Wang,Masato Ishii,Takashi Shibuya,Yuki Mitsufuji,Gopala Anumanchipalli,Paul Pu Liang*

Main category: cs.CV

TL;DR: SAVE是一种端到端的视听联合编辑模型，通过Schrodinger Bridge实现高效编辑，优于传统组合方法。


<details>
  <summary>Details</summary>
Motivation: 联合编辑音频和视觉内容对于精确可控的内容创作至关重要，但由于缺乏成对的视听编辑数据和模态间的异质性，这一任务具有挑战性。

Method: 通过SAVEBench数据集训练Schrodinger Audio-Visual Editor (SAVE)，这是一种端到端的流匹配模型，利用Schrodinger Bridge直接学习从源到目标视听混合的传输。

Result: SAVE模型在移除目标对象的同时保持了内容的完整性，并在时间同步和视听语义对应方面表现优于组合编辑器。

Conclusion: SAVE模型能够有效移除音频和视觉内容中的目标对象，同时保持剩余内容的完整性，且在时间同步和视听语义对应方面优于音频和视频编辑器的组合。

Abstract: Joint editing of audio and visual content is crucial for precise and controllable content creation. This new task poses challenges due to the limitations of paired audio-visual data before and after targeted edits, and the heterogeneity across modalities. To address the data and modeling challenges in joint audio-visual editing, we introduce SAVEBench, a paired audiovisual dataset with text and mask conditions to enable object-grounded source-to-target learning. With SAVEBench, we train the Schrodinger Audio-Visual Editor (SAVE), an end-to-end flow-matching model that edits audio and video in parallel while keeping them aligned throughout processing. SAVE incorporates a Schrodinger Bridge that learns a direct transport from source to target audiovisual mixtures. Our evaluation demonstrates that the proposed SAVE model is able to remove the target objects in audio and visual content while preserving the remaining content, with stronger temporal synchronization and audiovisual semantic correspondence compared with pairwise combinations of an audio editor and a video editor.

</details>


### [133] [End2Reg: Learning Task-Specific Segmentation for Markerless Registration in Spine Surgery](https://arxiv.org/abs/2512.13402)
*Lorenzo Pettinari,Sidaty El Hadramy,Michael Wehrli,Philippe C. Cattin,Daniel Studer,Carol C. Hasler,Maria Licci*

Main category: cs.CV

TL;DR: End2Reg是一种端到端深度学习框架，联合优化分割和配准，显著提高无标记脊柱手术导航的精度，消除对弱标签和手动步骤的依赖。


<details>
  <summary>Details</summary>
Motivation: 当前基于术中放射成像和骨锚标记的脊柱手术导航系统具有侵入性、辐射密集且工作流程中断。现有无标记RGB-D配准方法依赖弱分割标签隔离相关解剖结构，可能导致误差传播。

Method: 提出End2Reg，一种端到端深度学习框架，联合优化分割和配准，无需弱分割标签和手动步骤。网络学习专门为配准优化的分割掩码，仅通过配准目标引导，无需直接分割监督。

Result: 该框架在体外和体内基准测试中达到最先进性能，中位数目标配准误差降低32%至1.83mm，均方根误差降低45%至3.95mm。消融研究证实端到端优化显著提高配准精度。

Conclusion: 该论文提出的端到端RGB-D配准流程消除了对弱标签和手动步骤的依赖，推动了全自动、无标记术中导航的发展。

Abstract: Purpose: Intraoperative navigation in spine surgery demands millimeter-level accuracy. Current systems based on intraoperative radiographic imaging and bone-anchored markers are invasive, radiation-intensive and workflow disruptive. Recent markerless RGB-D registration methods offer a promising alternative, but existing approaches rely on weak segmentation labels to isolate relevant anatomical structures, which can propagate errors throughout registration. Methods: We present End2Reg an end-to-end deep learning framework that jointly optimizes segmentation and registration, eliminating the need for weak segmentation labels and manual steps. The network learns segmentation masks specifically optimized for registration, guided solely by the registration objective without direct segmentation supervision. Results: The proposed framework achieves state-of-the-art performance on ex- and in-vivo benchmarks, reducing median Target Registration Error by 32% to 1.83mm and mean Root Mean Square Error by 45% to 3.95mm, respectively. An ablation study confirms that end-to-end optimization significantly improves registration accuracy. Conclusion: The presented end-to-end RGB-D registration pipeline removes dependency on weak labels and manual steps, advancing towards fully automatic, markerless intraoperative navigation. Code and interactive visualizations are available at: https://lorenzopettinari.github.io/end-2-reg/.

</details>


### [134] [DA-SSL: self-supervised domain adaptor to leverage foundational models in turbt histopathology slides](https://arxiv.org/abs/2512.13600)
*Haoyue Zhang,Meera Chappidi,Erolcan Sayar,Helen Richards,Zhijun Chen,Lucas Liu,Roxanne Wadia,Peter A Humphrey,Fady Ghali,Alberto Contreras-Sanz,Peter Black,Jonathan Wright,Stephanie Harmon,Michael Haffner*

Main category: cs.CV

TL;DR: 提出DA-SSL方法，通过域自适应提升PFM在TURBT样本中的性能，临床验证表现优异。


<details>
  <summary>Details</summary>
Motivation: 针对TURBT样本中存在的组织碎片和电灼伪影等域偏移问题，这些样本在公开可用的PFMs中未被广泛使用，导致现有模型性能受限。

Method: 提出了一种简单而有效的域自适应自监督适配器（DA-SSL），无需微调基础模型本身即可将预训练的PFM特征重新对齐到TURBT领域。

Result: 在多中心研究中，DA-SSL在五折交叉验证中实现了AUC为0.77±0.04，外部测试准确率为0.84，敏感性为0.71，特异性为0.91。

Conclusion: 轻量级的域自适应结合自监督学习能有效提升基于病理基础模型（PFM）的多实例学习（MIL）流程在临床挑战性病理任务中的表现。

Abstract: Recent deep learning frameworks in histopathology, particularly multiple instance learning (MIL) combined with pathology foundational models (PFMs), have shown strong performance. However, PFMs exhibit limitations on certain cancer or specimen types due to domain shifts - these cancer types were rarely used for pretraining or specimens contain tissue-based artifacts rarely seen within the pretraining population. Such is the case for transurethral resection of bladder tumor (TURBT), which are essential for diagnosing muscle-invasive bladder cancer (MIBC), but contain fragmented tissue chips and electrocautery artifacts and were not widely used in publicly available PFMs. To address this, we propose a simple yet effective domain-adaptive self-supervised adaptor (DA-SSL) that realigns pretrained PFM features to the TURBT domain without fine-tuning the foundational model itself. We pilot this framework for predicting treatment response in TURBT, where histomorphological features are currently underutilized and identifying patients who will benefit from neoadjuvant chemotherapy (NAC) is challenging. In our multi-center study, DA-SSL achieved an AUC of 0.77+/-0.04 in five-fold cross-validation and an external test accuracy of 0.84, sensitivity of 0.71, and specificity of 0.91 using majority voting. Our results demonstrate that lightweight domain adaptation with self-supervision can effectively enhance PFM-based MIL pipelines for clinically challenging histopathology tasks. Code is Available at https://github.com/zhanghaoyue/DA_SSL_TURBT.

</details>


### [135] [Revisiting 2D Foundation Models for Scalable 3D Medical Image Classification](https://arxiv.org/abs/2512.12887)
*Han Liu,Bogdan Georgescu,Yanbo Zhang,Youngjin Yoo,Michael Baumgartner,Riqiang Gao,Jianing Wang,Gengyan Zhao,Eli Gibson,Dorin Comaniciu,Sasa Grbic*

Main category: cs.CV

TL;DR: AnyMC3D是一种可扩展的3D分类器，通过轻量级插件和单一冻结主干网络，在多样化医学图像分类任务中实现最先进性能，解决了当前医学基础模型的三大缺陷。


<details>
  <summary>Details</summary>
Motivation: 当前医学基础模型研究存在数据制度偏差、次优适应和任务覆盖不足三大缺陷，AnyMC3D旨在解决这些问题。

Method: AnyMC3D是一种从2D基础模型（FMs）扩展而来的可扩展3D分类器，通过添加轻量级插件（每个任务约1M参数）并支持多视图输入、辅助像素级监督和可解释热图生成。

Result: 在涵盖12个多样化任务的综合基准测试中，AnyMC3D首次证明了单一可扩展框架可以在多样化应用中实现最先进性能（包括VLM3D挑战赛第一名）。

Conclusion: AnyMC3D通过轻量级插件和单一冻结主干网络，实现了在多样化3D医学图像分类任务中的最先进性能，证明了通用基础模型在适当适应后可以超越医学专用模型。

Abstract: 3D medical image classification is essential for modern clinical workflows. Medical foundation models (FMs) have emerged as a promising approach for scaling to new tasks, yet current research suffers from three critical pitfalls: data-regime bias, suboptimal adaptation, and insufficient task coverage. In this paper, we address these pitfalls and introduce AnyMC3D, a scalable 3D classifier adapted from 2D FMs. Our method scales efficiently to new tasks by adding only lightweight plugins (about 1M parameters per task) on top of a single frozen backbone. This versatile framework also supports multi-view inputs, auxiliary pixel-level supervision, and interpretable heatmap generation. We establish a comprehensive benchmark of 12 tasks covering diverse pathologies, anatomies, and modalities, and systematically analyze state-of-the-art 3D classification techniques. Our analysis reveals key insights: (1) effective adaptation is essential to unlock FM potential, (2) general-purpose FMs can match medical-specific FMs if properly adapted, and (3) 2D-based methods surpass 3D architectures for 3D classification. For the first time, we demonstrate the feasibility of achieving state-of-the-art performance across diverse applications using a single scalable framework (including 1st place in the VLM3D challenge), eliminating the need for separate task-specific models.

</details>


### [136] [Feedforward 3D Editing via Text-Steerable Image-to-3D](https://arxiv.org/abs/2512.13678)
*Ziqi Ma,Hongqiao Chen,Yisong Yue,Georgia Gkioxari*

Main category: cs.CV

TL;DR: Steer3D是一种通过文本指令编辑图像生成3D资产的前馈方法，结合流匹配和DPO训练，显著提升编辑效率和一致性。


<details>
  <summary>Details</summary>
Motivation: 为了在真实应用中更便捷地编辑AI生成的3D资产，需要一种能够通过语言指令进行编辑的方法。

Method: 采用基于ControlNet的改进方法，结合流匹配训练和直接偏好优化（DPO）的两阶段训练策略，并构建了自动数据生成引擎。

Result: Steer3D在语言指令遵循和3D资产一致性上优于竞品，速度提升2.4倍至28.5倍。

Conclusion: Steer3D成功地将文本引导能力整合到图像到3D生成模型中，显著提升了3D资产的编辑效率和一致性。

Abstract: Recent progress in image-to-3D has opened up immense possibilities for design, AR/VR, and robotics. However, to use AI-generated 3D assets in real applications, a critical requirement is the capability to edit them easily. We present a feedforward method, Steer3D, to add text steerability to image-to-3D models, which enables editing of generated 3D assets with language. Our approach is inspired by ControlNet, which we adapt to image-to-3D generation to enable text steering directly in a forward pass. We build a scalable data engine for automatic data generation, and develop a two-stage training recipe based on flow-matching training and Direct Preference Optimization (DPO). Compared to competing methods, Steer3D more faithfully follows the language instruction and maintains better consistency with the original 3D asset, while being 2.4x to 28.5x faster. Steer3D demonstrates that it is possible to add a new modality (text) to steer the generation of pretrained image-to-3D generative models with 100k data. Project website: https://glab-caltech.github.io/steer3d/

</details>


### [137] [Predictive Sample Assignment for Semantically Coherent Out-of-Distribution Detection](https://arxiv.org/abs/2512.12906)
*Zhimao Peng,Enguang Wang,Xialei Liu,Ming-Ming Cheng*

Main category: cs.CV

TL;DR: 提出了一种新的SCOOD框架PSA，通过双重阈值样本分配和对比学习，显著提升了OOD检测性能。


<details>
  <summary>Details</summary>
Motivation: 当前SCOOD方法通过聚类筛选ID样本时不可避免地引入大量噪声样本，影响了训练效果。

Method: 提出了一种基于预测样本分配（PSA）的SCOOD框架，包括双重阈值三元样本分配策略和概念对比表示学习损失，以及一个重新训练策略以优化模型拟合。

Result: 在两个标准SCOOD基准测试中，该方法显著优于现有最先进方法。

Conclusion: 提出的基于预测样本分配（PSA）的SCOOD框架在标准基准测试中显著优于现有方法，通过双重阈值三元样本分配策略和概念对比表示学习损失，有效提升了ID和OOD样本集的纯度，并扩大了它们在表示空间中的距离。

Abstract: Semantically coherent out-of-distribution detection (SCOOD) is a recently proposed realistic OOD detection setting: given labeled in-distribution (ID) data and mixed in-distribution and out-of-distribution unlabeled data as the training data, SCOOD aims to enable the trained model to accurately identify OOD samples in the testing data. Current SCOOD methods mainly adopt various clustering-based in-distribution sample filtering (IDF) strategies to select clean ID samples from unlabeled data, and take the remaining samples as auxiliary OOD data, which inevitably introduces a large number of noisy samples in training. To address the above issue, we propose a concise SCOOD framework based on predictive sample assignment (PSA). PSA includes a dual-threshold ternary sample assignment strategy based on the predictive energy score that can significantly improve the purity of the selected ID and OOD sample sets by assigning unconfident unlabeled data to an additional discard sample set, and a concept contrastive representation learning loss to further expand the distance between ID and OOD samples in the representation space to assist ID/OOD discrimination. In addition, we also introduce a retraining strategy to help the model fully fit the selected auxiliary ID/OOD samples. Experiments on two standard SCOOD benchmarks demonstrate that our approach outperforms the state-of-the-art methods by a significant margin.

</details>


### [138] [Sharpness-aware Dynamic Anchor Selection for Generalized Category Discovery](https://arxiv.org/abs/2512.12925)
*Zhimao Peng,Enguang Wang,Fei Yang,Xialei Liu,Ming-Ming Cheng*

Main category: cs.CV

TL;DR: 提出LSP和DAS方法，减少伪标签噪声，提升GCD任务性能。


<details>
  <summary>Details</summary>
Motivation: 解决当前GCD方法中预训练模型对特定视觉模式的偏好导致的伪标签噪声问题。

Method: 提出了一种包含损失锐度惩罚（LSP）和动态锚点选择（DAS）的新方法。LSP通过最小化模型的最坏情况损失锐度来增强参数对小扰动的鲁棒性，DAS则基于KNN密度和类概率选择未知类的代表性样本并分配硬伪标签。

Result: 实验证明，该方法能有效减少伪标签噪声，并在多个GCD基准测试中表现优异。

Conclusion: 所提出的方法通过LSP和DAS模块有效减少了伪标签的噪声，并在多个GCD基准测试中取得了最先进的结果。

Abstract: Generalized category discovery (GCD) is an important and challenging task in open-world learning. Specifically, given some labeled data of known classes, GCD aims to cluster unlabeled data that contain both known and unknown classes. Current GCD methods based on parametric classification adopt the DINO-like pseudo-labeling strategy, where the sharpened probability output of one view is used as supervision information for the other view. However, large pre-trained models have a preference for some specific visual patterns, resulting in encoding spurious correlation for unlabeled data and generating noisy pseudo-labels. To address this issue, we propose a novel method, which contains two modules: Loss Sharpness Penalty (LSP) and Dynamic Anchor Selection (DAS). LSP enhances the robustness of model parameters to small perturbations by minimizing the worst-case loss sharpness of the model, which suppressing the encoding of trivial features, thereby reducing overfitting of noise samples and improving the quality of pseudo-labels. Meanwhile, DAS selects representative samples for the unknown classes based on KNN density and class probability during the model training and assigns hard pseudo-labels to them, which not only alleviates the confidence difference between known and unknown classes but also enables the model to quickly learn more accurate feature distribution for the unknown classes, thus further improving the clustering accuracy. Extensive experiments demonstrate that the proposed method can effectively mitigate the noise of pseudo-labels, and achieve state-of-the-art results on multiple GCD benchmarks.

</details>


### [139] [UAGLNet: Uncertainty-Aggregated Global-Local Fusion Network with Cooperative CNN-Transformer for Building Extraction](https://arxiv.org/abs/2512.12941)
*Siyuan Yao,Dongxiu Liu,Taotao Li,Shengjie Li,Wenqi Ren,Xiaochun Cao*

Main category: cs.CV

TL;DR: UAGLNet通过混合CNN和Transformer层、协作交互块及不确定性聚合解码器，提升了建筑提取的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在特征金字塔和全局-局部特征融合方面存在不足，导致建筑提取结果不准确。

Method: 提出了一种不确定性聚合的全局-局部融合网络（UAGLNet），包括混合CNN和Transformer层的协同编码器、中间协作交互块（CIB）、全局-局部融合模块（GLF）以及不确定性聚合解码器（UAD）。

Result: 实验表明，UAGLNet在性能上优于其他最先进方法。

Conclusion: UAGLNet通过不确定性建模指导下的高质量全局-局部视觉语义融合，显著提升了建筑提取的准确性。

Abstract: Building extraction from remote sensing images is a challenging task due to the complex structure variations of the buildings. Existing methods employ convolutional or self-attention blocks to capture the multi-scale features in the segmentation models, while the inherent gap of the feature pyramids and insufficient global-local feature integration leads to inaccurate, ambiguous extraction results. To address this issue, in this paper, we present an Uncertainty-Aggregated Global-Local Fusion Network (UAGLNet), which is capable to exploit high-quality global-local visual semantics under the guidance of uncertainty modeling. Specifically, we propose a novel cooperative encoder, which adopts hybrid CNN and transformer layers at different stages to capture the local and global visual semantics, respectively. An intermediate cooperative interaction block (CIB) is designed to narrow the gap between the local and global features when the network becomes deeper. Afterwards, we propose a Global-Local Fusion (GLF) module to complementarily fuse the global and local representations. Moreover, to mitigate the segmentation ambiguity in uncertain regions, we propose an Uncertainty-Aggregated Decoder (UAD) to explicitly estimate the pixel-wise uncertainty to enhance the segmentation accuracy. Extensive experiments demonstrate that our method achieves superior performance to other state-of-the-art methods. Our code is available at https://github.com/Dstate/UAGLNet

</details>


### [140] [SCAdapter: Content-Style Disentanglement for Diffusion Style Transfer](https://arxiv.org/abs/2512.12963)
*Luan Thanh Trinh,Kenji Doi,Atsuki Osanai*

Main category: cs.CV

TL;DR: SCAdapter是一种新型风格迁移技术，通过CLIP空间分离内容和风格，结合CSAdaIN等方法，实现高效真实的迁移，速度提升2倍。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在风格迁移中难以实现照片级真实效果，常产生类似绘画的结果或遗漏细节风格元素。

Method: SCAdapter采用Controllable Style Adaptive Instance Normalization (CSAdaIN)、KVS Injection和风格迁移一致性目标三个组件，系统提取纯内容和风格元素。

Result: SCAdapter在传统和基于扩散的基线方法中均显著优于现有技术，且无需DDIM反转和推理阶段优化。

Conclusion: SCAdapter通过CLIP图像空间有效分离和整合内容与风格特征，显著提升了风格迁移的真实性和效率，且推理速度至少是其他基于扩散方法的2倍。

Abstract: Diffusion models have emerged as the leading approach for style transfer, yet they struggle with photo-realistic transfers, often producing painting-like results or missing detailed stylistic elements. Current methods inadequately address unwanted influence from original content styles and style reference content features. We introduce SCAdapter, a novel technique leveraging CLIP image space to effectively separate and integrate content and style features. Our key innovation systematically extracts pure content from content images and style elements from style references, ensuring authentic transfers. This approach is enhanced through three components: Controllable Style Adaptive Instance Normalization (CSAdaIN) for precise multi-style blending, KVS Injection for targeted style integration, and a style transfer consistency objective maintaining process coherence. Comprehensive experiments demonstrate SCAdapter significantly outperforms state-of-the-art methods in both conventional and diffusion-based baselines. By eliminating DDIM inversion and inference-stage optimization, our method achieves at least $2\times$ faster inference than other diffusion-based approaches, making it both more effective and efficient for practical applications.

</details>


### [141] [VLCache: Computing 2% Vision Tokens and Reusing 98% for Vision-Language Inference](https://arxiv.org/abs/2512.12977)
*Shengling Qin,Hao Yu,Chenxin Wu,Zheng Li,Yizhong Cao,Zhengyang Zhuge,Yuxin Zhou,Wentao Yao,Yi Zhang,Zhengheng Wang,Shuai Bai,Jianwei Zhang,Junyang Lin*

Main category: cs.CV

TL;DR: VLCache通过重用KV和编码器缓存，显著减少多模态输入重复计算，提升推理速度，同时保持高准确性。


<details>
  <summary>Details</summary>
Motivation: 为了消除多模态输入重复出现时的昂贵重新计算成本，利用先前的缓存来优化效率。

Method: 提出了一个动态、分层感知的重计算策略，以平衡准确性和效率，并最小化非前缀缓存重用误差。

Result: 实验结果表明，VLCache仅需计算2-5%的token，即可达到与完全重新计算相当的准确性，实现了1.2x-16x的TTFT加速。

Conclusion: VLCache通过结合KV缓存和编码器缓存，有效减少了多模态输入重复计算的开销，同时保持了与完全重新计算相当的准确性，显著提升了推理速度。

Abstract: This paper presents VLCache, a cache reuse framework that exploits both Key-Value (KV) cache and encoder cache from prior multimodal inputs to eliminate costly recomputation when the same multimodal inputs recur. Unlike previous heuristic approaches, we formally identify the cumulative reuse error effect and demonstrate how to minimize the non-prefix cache reuse error effectively. We further analyze the varying importance of model layers and propose a dynamic, layer-aware recomputation strategy to balance accuracy and efficiency. Experimental results show that VLCache achieves an accuracy on par with full recomputation, while requiring only 2-5% of the tokens to compute, yielding 1.2x-16x TTFT speedups. The proposed VLCache pipeline has been integrated into SGLang, enabling significantly faster inference in practical deployments.

</details>


### [142] [Scaling Up AI-Generated Image Detection via Generator-Aware Prototypes](https://arxiv.org/abs/2512.12982)
*Ziheng Qin,Yuheng Ji,Renshuai Tao,Yuxuan Tian,Yuyang Liu,Yipu Wang,Xiaolong Zheng*

Main category: cs.CV

TL;DR: GAPL框架通过结构化学习和两阶段训练，解决了AIGI检测中的数据和模型问题，实现了高性能检测。


<details>
  <summary>Details</summary>
Motivation: 识别了通用AIGI检测器在源多样性扩展时性能停滞甚至下降的悖论现象（Benefit then Conflict困境），并分析了数据异质性和模型瓶颈两大核心问题。

Method: 提出了Generator-Aware Prototype Learning (GAPL)框架，包括学习一组紧凑的伪造原型以创建低方差特征空间，以及采用Low-Rank Adaptation的两阶段训练方案。

Result: GAPL在广泛的GAN和基于扩散的生成器上展示了最先进的检测准确率。

Conclusion: GAPL框架通过结构化学习范式和两阶段训练方案，有效解决了数据异质性和模型瓶颈问题，实现了最先进的检测性能。

Abstract: The pursuit of a universal AI-generated image (AIGI) detector often relies on aggregating data from numerous generators to improve generalization. However, this paper identifies a paradoxical phenomenon we term the Benefit then Conflict dilemma, where detector performance stagnates and eventually degrades as source diversity expands. Our systematic analysis, diagnoses this failure by identifying two core issues: severe data-level heterogeneity, which causes the feature distributions of real and synthetic images to increasingly overlap, and a critical model-level bottleneck from fixed, pretrained encoders that cannot adapt to the rising complexity. To address these challenges, we propose Generator-Aware Prototype Learning (GAPL), a framework that constrain representation with a structured learning paradigm. GAPL learns a compact set of canonical forgery prototypes to create a unified, low-variance feature space, effectively countering data heterogeneity.To resolve the model bottleneck, it employs a two-stage training scheme with Low-Rank Adaptation, enhancing its discriminative power while preserving valuable pretrained knowledge. This approach establishes a more robust and generalizable decision boundary. Through extensive experiments, we demonstrate that GAPL achieves state-of-the-art performance, showing superior detection accuracy across a wide variety of GAN and diffusion-based generators. Code is available at https://github.com/UltraCapture/GAPL

</details>


### [143] [Few-Step Distillation for Text-to-Image Generation: A Practical Guide](https://arxiv.org/abs/2512.13006)
*Yifan Pu,Yizeng Han,Zhiwei Tang,Jiasheng Tang,Fan Wang,Bohan Zhuang,Gao Huang*

Main category: cs.CV

TL;DR: 该研究系统评估了扩散蒸馏在文本到图像生成中的适用性，提出了统一框架和实用指南，为高效扩散生成器的实际应用奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 研究扩散蒸馏在开放文本到图像生成中的适用性，并解决从离散类别标签转向自由形式语言提示时的关键障碍。

Method: 通过将现有方法统一到一个框架中，分析了输入缩放、网络架构和超参数等关键因素，并提供了开源实现和预训练学生模型。

Result: 研究识别了从类别标签转向语言提示时的关键障碍，并提供了实用指南和开源实现。

Conclusion: 该研究为在实际文本到图像（T2I）应用中部署快速、高保真且资源高效的扩散生成器奠定了坚实基础。

Abstract: Diffusion distillation has dramatically accelerated class-conditional image synthesis, but its applicability to open-ended text-to-image (T2I) generation is still unclear. We present the first systematic study that adapts and compares state-of-the-art distillation techniques on a strong T2I teacher model, FLUX.1-lite. By casting existing methods into a unified framework, we identify the key obstacles that arise when moving from discrete class labels to free-form language prompts. Beyond a thorough methodological analysis, we offer practical guidelines on input scaling, network architecture, and hyperparameters, accompanied by an open-source implementation and pretrained student models. Our findings establish a solid foundation for deploying fast, high-fidelity, and resource-efficient diffusion generators in real-world T2I applications. Code is available on github.com/alibaba-damo-academy/T2I-Distill.

</details>


### [144] [Light Field Based 6DoF Tracking of Previously Unobserved Objects](https://arxiv.org/abs/2512.13007)
*Nikolai Goncharov,James L. Gray,Donald G. Dansereau*

Main category: cs.CV

TL;DR: 提出了一种基于光场图像的对象跟踪方法，不依赖预训练模型，对复杂视觉行为（如反射）鲁棒，性能与现有方法相当。


<details>
  <summary>Details</summary>
Motivation: 现有高性能方法依赖于预先捕获的对象视图构建显式参考模型，限制了其只能处理已知对象集，且在复杂外观下表现不佳。

Method: 利用视觉基础模型从光场输入中提取语义和几何特征，并将其转换为依赖于视图的高斯样条，作为统一的对象表示，支持可微分渲染和姿态优化。

Result: 实验表明，该方法在具有挑战性的反射对象上表现优异，与最先进的基于模型的跟踪器竞争。

Conclusion: 该方法在复杂视觉行为（如反射）下表现出色，与现有基于模型的跟踪器性能相当，为机器人系统中的通用对象跟踪铺平了道路。

Abstract: Object tracking is an important step in robotics and reautonomous driving pipelines, which has to generalize to previously unseen and complex objects. Existing high-performing methods often rely on pre-captured object views to build explicit reference models, which restricts them to a fixed set of known objects. However, such reference models can struggle with visually complex appearance, reducing the quality of tracking. In this work, we introduce an object tracking method based on light field images that does not depend on a pre-trained model, while being robust to complex visual behavior, such as reflections. We extract semantic and geometric features from light field inputs using vision foundation models and convert them into view-dependent Gaussian splats. These splats serve as a unified object representation, supporting differentiable rendering and pose optimization. We further introduce a light field object tracking dataset containing challenging reflective objects with precise ground truth poses. Experiments demonstrate that our method is competitive with state-of-the-art model-based trackers in these difficult cases, paving the way toward universal object tracking in robotic systems. Code/data available at https://github.com/nagonch/LiFT-6DoF.

</details>


### [145] [TWLR: Text-Guided Weakly-Supervised Lesion Localization and Severity Regression for Explainable Diabetic Retinopathy Grading](https://arxiv.org/abs/2512.13008)
*Xi Luo,Shixin Xu,Ying Xie,JianZhong Hu,Yuwei He,Yuhui Deng,Huaxiong Huang*

Main category: cs.CV

TL;DR: TWLR是一种两阶段框架，结合视觉语言模型和弱监督语义分割，实现了高效且可解释的糖尿病视网膜病变评估。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像分析中高质量标注成本高、深度学习方法缺乏可解释性的问题。

Method: TWLR是一个两阶段框架：第一阶段通过视觉语言模型将眼科专业知识融入文本嵌入，联合执行DR分级和病变分类；第二阶段基于弱监督语义分割的迭代严重性回归框架，通过渐进修复机制消除病理特征。

Result: 在FGADR、DDR和私有数据集上的实验结果表明，TWLR在DR分类和病变分割方面具有竞争力。

Conclusion: TWLR框架在糖尿病视网膜病变（DR）分类和病变分割方面表现出色，提供了一种更可解释且标注高效的自动化视网膜图像分析解决方案。

Abstract: Accurate medical image analysis can greatly assist clinical diagnosis, but its effectiveness relies on high-quality expert annotations Obtaining pixel-level labels for medical images, particularly fundus images, remains costly and time-consuming. Meanwhile, despite the success of deep learning in medical imaging, the lack of interpretability limits its clinical adoption. To address these challenges, we propose TWLR, a two-stage framework for interpretable diabetic retinopathy (DR) assessment. In the first stage, a vision-language model integrates domain-specific ophthalmological knowledge into text embeddings to jointly perform DR grading and lesion classification, effectively linking semantic medical concepts with visual features. The second stage introduces an iterative severity regression framework based on weakly-supervised semantic segmentation. Lesion saliency maps generated through iterative refinement direct a progressive inpainting mechanism that systematically eliminates pathological features, effectively downgrading disease severity toward healthier fundus appearances. Critically, this severity regression approach achieves dual benefits: accurate lesion localization without pixel-level supervision and providing an interpretable visualization of disease-to-healthy transformations. Experimental results on the FGADR, DDR, and a private dataset demonstrate that TWLR achieves competitive performance in both DR classification and lesion segmentation, offering a more explainable and annotation-efficient solution for automated retinal image analysis.

</details>


### [146] [JoDiffusion: Jointly Diffusing Image with Pixel-Level Annotations for Semantic Segmentation Promotion](https://arxiv.org/abs/2512.13014)
*Haoyu Wang,Lei Zhang,Wenrui Liu,Dengyang Jiang,Wei Wei,Chen Ding*

Main category: cs.CV

TL;DR: JoDiffusion是一种新型扩散框架，可同时生成图像和语义一致的标注掩码，显著提升语义分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成合成数据集时存在图像-标注语义不一致或可扩展性问题，JoDiffusion旨在同时解决这两个问题。

Method: JoDiffusion结合独立的标注变分自编码器（VAE）网络，将标注掩码映射到与图像共享的潜在空间，并调整扩散模型以捕获图像和标注掩码的联合分布。

Result: 在Pascal VOC、COCO和ADE20K数据集上的实验表明，JoDiffusion生成的标注数据集在语义分割任务中优于现有方法。

Conclusion: JoDiffusion通过联合生成图像和语义一致的标注掩码，显著提升了语义分割模型的性能，并解决了现有方法的可扩展性问题。

Abstract: Given the inherently costly and time-intensive nature of pixel-level annotation, the generation of synthetic datasets comprising sufficiently diverse synthetic images paired with ground-truth pixel-level annotations has garnered increasing attention recently for training high-performance semantic segmentation models. However, existing methods necessitate to either predict pseudo annotations after image generation or generate images conditioned on manual annotation masks, which incurs image-annotation semantic inconsistency or scalability problem. To migrate both problems with one stone, we present a novel dataset generative diffusion framework for semantic segmentation, termed JoDiffusion. Firstly, given a standard latent diffusion model, JoDiffusion incorporates an independent annotation variational auto-encoder (VAE) network to map annotation masks into the latent space shared by images. Then, the diffusion model is tailored to capture the joint distribution of each image and its annotation mask conditioned on a text prompt. By doing these, JoDiffusion enables simultaneously generating paired images and semantically consistent annotation masks solely conditioned on text prompts, thereby demonstrating superior scalability. Additionally, a mask optimization strategy is developed to mitigate the annotation noise produced during generation. Experiments on Pascal VOC, COCO, and ADE20K datasets show that the annotated dataset generated by JoDiffusion yields substantial performance improvements in semantic segmentation compared to existing methods.

</details>


### [147] [What Happens Next? Next Scene Prediction with a Unified Video Model](https://arxiv.org/abs/2512.13015)
*Xinjie Li,Zhimin Chen,Rui Zhao,Florian Schiffers,Zhenyu Liao,Vimal Bhat*

Main category: cs.CV

TL;DR: 论文提出了Next Scene Prediction任务和一个统一框架，结合理解和合成模块，通过三阶段训练实现了最先进的性能，推动了多模态系统在时间和因果推理方面的发展。


<details>
  <summary>Details</summary>
Motivation: 当前统一模型在视觉生成能力上取得了显著进展，但主要集中在传统任务如文本到视频生成上，对时间推理潜力的探索不足。因此，引入Next Scene Prediction任务以推动统一模型在时间和因果推理方面的发展。

Method: 提出了一个结合Qwen-VL（理解）和LTX（合成）的统一框架，通过潜在查询嵌入和连接模块进行桥接，并在新构建的大规模NSP数据集上进行三阶段训练：文本到视频预训练、监督微调和带有因果一致性奖励的强化学习（通过GRPO）。

Result: 实验证明，该模型在基准测试中达到了最先进的性能。

Conclusion: 论文提出的统一框架在Next Scene Prediction任务上实现了最先进的性能，提升了通用多模态系统预测未来场景的能力。

Abstract: Recent unified models for joint understanding and generation have significantly advanced visual generation capabilities. However, their focus on conventional tasks like text-to-video generation has left the temporal reasoning potential of unified models largely underexplored. To address this gap, we introduce Next Scene Prediction (NSP), a new task that pushes unified video models toward temporal and causal reasoning. Unlike text-to-video generation, NSP requires predicting plausible futures from preceding context, demanding deeper understanding and reasoning. To tackle this task, we propose a unified framework combining Qwen-VL for comprehension and LTX for synthesis, bridged by a latent query embedding and a connector module. This model is trained in three stages on our newly curated, large-scale NSP dataset: text-to-video pre-training, supervised fine-tuning, and reinforcement learning (via GRPO) with our proposed causal consistency reward. Experiments demonstrate our model achieves state-of-the-art performance on our benchmark, advancing the capability of generalist multimodal systems to anticipate what happens next.

</details>


### [148] [Comprehensive Deployment-Oriented Assessment for Cross-Environment Generalization in Deep Learning-Based mmWave Radar Sensing](https://arxiv.org/abs/2512.13018)
*Tomoya Tanaka,Tomonori Ikeda,Ryo Yonemoto*

Main category: cs.CV

TL;DR: 本研究评估了多种空间泛化技术，发现Sigmoid幅度加权和迁移学习在提升雷达传感系统跨环境性能方面效果显著。


<details>
  <summary>Details</summary>
Motivation: 评估空间泛化技术，这对于基于深度学习的射频（RF）传感的实际部署至关重要。

Method: 系统地研究了多种方法，包括基于幅度的统计预处理（Sigmoid加权和阈值归零）、频域滤波、基于自动编码器的背景抑制、数据增强策略和迁移学习。

Result: 实验结果表明，基于Sigmoid的幅度加权在跨环境性能上表现最佳，与基线方法相比，均方根误差（RMSE）和平均绝对误差（MAE）分别降低了50.1%和55.2%。数据增强提供了额外的适度收益，MAE最高提高了8.8%。迁移学习对于大空间位移至关重要，使用540个目标域样本时，RMSE和MAE分别降低了82.1%和91.3%。

Conclusion: 该研究为开发能够在空间变化下保持稳健准确性的雷达传感系统提供了高度实用的方向，通过将深度学习模型与基于幅度的预处理和高效的迁移学习相结合。

Abstract: This study presents the first comprehensive evaluation of spatial generalization techniques, which are essential for the practical deployment of deep learning-based radio-frequency (RF) sensing. Focusing on people counting in indoor environments using frequency-modulated continuous-wave (FMCW) multiple-input multiple-output (MIMO) radar, we systematically investigate a broad set of approaches, including amplitude-based statistical preprocessing (sigmoid weighting and threshold zeroing), frequency-domain filtering, autoencoder-based background suppression, data augmentation strategies, and transfer learning. Experimental results collected across two environments with different layouts demonstrate that sigmoid-based amplitude weighting consistently achieves superior cross-environment performance, yielding 50.1% and 55.2% reductions in root-mean-square error (RMSE) and mean absolute error (MAE), respectively, compared with baseline methods. Data augmentation provides additional though modest benefits, with improvements up to 8.8% in MAE. By contrast, transfer learning proves indispensable for large spatial shifts, achieving 82.1% and 91.3% reductions in RMSE and MAE, respectively, with 540 target-domain samples. Taken together, these findings establish a highly practical direction for developing radar sensing systems capable of maintaining robust accuracy under spatial variations by integrating deep learning models with amplitude-based preprocessing and efficient transfer learning.

</details>


### [149] [SneakPeek: Future-Guided Instructional Streaming Video Generation](https://arxiv.org/abs/2512.13019)
*Cheeun Hong,German Barquero,Fadime Sener,Markos Georgopoulos,Edgar Schönfeld,Stefan Popov,Yuming Du,Oscar Mañas,Albert Pumarola*

Main category: cs.CV

TL;DR: SneakPeek是一种基于扩散的自回归框架，通过预测因果适应、未来引导自强迫和多提示条件，生成连贯且可控的教学视频。


<details>
  <summary>Details</summary>
Motivation: 教学视频生成在内容创作、教育和人机交互领域有广泛应用，但现有视频扩散模型难以在长时间序列中保持时间一致性和可控性。

Method: 提出了一种基于扩散的自回归框架SneakPeek，包含三个关键创新：预测因果适应、未来引导自强迫（采用双区域KV缓存方案）和多提示条件。

Result: 实验结果表明，该方法生成的视频在时间上连贯且语义上忠实，能够准确遵循复杂的多步骤任务描述。

Conclusion: SneakPeek方法通过预测因果适应、未来引导自强迫和多提示条件，有效解决了现有视频扩散模型在长时间序列中保持时间一致性和可控性的问题，生成了符合复杂多步骤任务描述的连贯教学视频。

Abstract: Instructional video generation is an emerging task that aims to synthesize coherent demonstrations of procedural activities from textual descriptions. Such capability has broad implications for content creation, education, and human-AI interaction, yet existing video diffusion models struggle to maintain temporal consistency and controllability across long sequences of multiple action steps. We introduce a pipeline for future-driven streaming instructional video generation, dubbed SneakPeek, a diffusion-based autoregressive framework designed to generate precise, stepwise instructional videos conditioned on an initial image and structured textual prompts. Our approach introduces three key innovations to enhance consistency and controllability: (1) predictive causal adaptation, where a causal model learns to perform next-frame prediction and anticipate future keyframes; (2) future-guided self-forcing with a dual-region KV caching scheme to address the exposure bias issue at inference time; (3) multi-prompt conditioning, which provides fine-grained and procedural control over multi-step instructions. Together, these components mitigate temporal drift, preserve motion consistency, and enable interactive video generation where future prompt updates dynamically influence ongoing streaming video generation. Experimental results demonstrate that our method produces temporally coherent and semantically faithful instructional videos that accurately follow complex, multi-step task descriptions.

</details>


### [150] [Comprehensive Evaluation of Rule-Based, Machine Learning, and Deep Learning in Human Estimation Using Radio Wave Sensing: Accuracy, Spatial Generalization, and Output Granularity Trade-offs](https://arxiv.org/abs/2512.13031)
*Tomoya Tanaka,Tomonori Ikeda,Ryo Yonemoto*

Main category: cs.CV

TL;DR: 研究比较了不同方法在无线电波传感中的性能，发现深度学习模型在相同环境下表现最佳但对领域偏移敏感，基于规则的方法则更稳定但输出粒度较低，揭示了性能与输出粒度之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 首次全面比较基于规则的方法、传统机器学习模型和深度学习模型在无线电波传感中的性能，特别是在频率调制连续波多输入多输出雷达中的应用。

Method: 本研究系统评估了五种方法：基于规则的连通组件方法、三种传统机器学习模型（k近邻、随机森林、支持向量机）以及结合卷积神经网络和长短期记忆的深度学习模型。

Result: 在训练环境中，卷积神经网络长短期记忆模型准确率最高，传统机器学习模型表现中等；在新布局中，所有基于学习的方法性能显著下降，而基于规则的方法保持稳定。对于人员存在与否的二元检测，所有模型在不同布局中均保持高准确率。

Conclusion: 研究表明，高容量模型在相同环境下能提供高精度的细粒度输出，但对领域偏移脆弱；而基于规则的方法虽不具备细粒度输出能力，却表现出对领域偏移的鲁棒性。此外，无论模型类型如何，空间泛化性能与输出粒度之间存在明显的权衡。

Abstract: This study presents the first comprehensive comparison of rule-based methods, traditional machine learning models, and deep learning models in radio wave sensing with frequency modulated continuous wave multiple input multiple output radar. We systematically evaluated five approaches in two indoor environments with distinct layouts: a rule-based connected component method; three traditional machine learning models, namely k-nearest neighbors, random forest, and support vector machine; and a deep learning model combining a convolutional neural network and long short term memory. In the training environment, the convolutional neural network long short term memory model achieved the highest accuracy, while traditional machine learning models provided moderate performance. In a new layout, however, all learning based methods showed significant degradation, whereas the rule-based method remained stable. Notably, for binary detection of presence versus absence of people, all models consistently achieved high accuracy across layouts. These results demonstrate that high capacity models can produce fine grained outputs with high accuracy in the same environment, but they are vulnerable to domain shift. In contrast, rule-based methods cannot provide fine grained outputs but exhibit robustness against domain shift. Moreover, regardless of the model type, a clear trade off was revealed between spatial generalization performance and output granularity.

</details>


### [151] [Bi-Erasing: A Bidirectional Framework for Concept Removal in Diffusion Models](https://arxiv.org/abs/2512.13039)
*Hao Chen,Yiwei Wang,Songze Li*

Main category: cs.CV

TL;DR: Bi-Erasing框架通过双向图像引导的概念擦除，平衡了概念移除和生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有的概念擦除方法通常采用单向擦除策略，难以在概念移除和生成质量之间取得平衡。

Method: 基于文本提示和对应图像的联合表示，Bi-Erasing引入了两个解耦的图像分支：负分支负责抑制有害语义，正分支为安全替代提供视觉指导。通过联合优化这两个互补方向，实现了擦除效果和生成可用性的平衡。

Result: Bi-Erasing在平衡概念移除效果和视觉保真度方面优于基线方法。

Conclusion: 提出的Bi-Erasing框架在平衡概念擦除效果和生成质量方面优于基线方法。

Abstract: Concept erasure, which fine-tunes diffusion models to remove undesired or harmful visual concepts, has become a mainstream approach to mitigating unsafe or illegal image generation in text-to-image models.However, existing removal methods typically adopt a unidirectional erasure strategy by either suppressing the target concept or reinforcing safe alternatives, making it difficult to achieve a balanced trade-off between concept removal and generation quality. To address this limitation, we propose a novel Bidirectional Image-Guided Concept Erasure (Bi-Erasing) framework that performs concept suppression and safety enhancement simultaneously. Specifically, based on the joint representation of text prompts and corresponding images, Bi-Erasing introduces two decoupled image branches: a negative branch responsible for suppressing harmful semantics and a positive branch providing visual guidance for safe alternatives. By jointly optimizing these complementary directions, our approach achieves a balance between erasure efficacy and generation usability. In addition, we apply mask-based filtering to the image branches to prevent interference from irrelevant content during the erasure process. Across extensive experiment evaluations, the proposed Bi-Erasing outperforms baseline methods in balancing concept removal effectiveness and visual fidelity.

</details>


### [152] [Towards Test-time Efficient Visual Place Recognition via Asymmetric Query Processing](https://arxiv.org/abs/2512.13055)
*Jaeyoon Kim,Yoonki Cho,Sung-Eui Yoon*

Main category: cs.CV

TL;DR: 提出了一种高效的异步VPR框架，通过地理记忆库和隐式嵌入增强技术，在降低计算成本的同时提升了性能。


<details>
  <summary>Details</summary>
Motivation: 尽管DINOv2等高容量基础模型在VPR中表现优异，但其高计算成本使其难以在资源受限设备上部署，因此需要一种更高效的解决方案。

Method: 采用高容量画廊模型进行离线特征提取，结合轻量级查询网络进行在线处理，利用地理记忆库结构化画廊特征，并通过隐式嵌入增强技术提升查询网络的性能。

Result: 实验表明，该方法不仅大幅降低了计算成本，还在性能上超越了现有的异步检索技术。

Conclusion: 该论文提出了一种高效的异步视觉地点识别（VPR）框架，通过地理记忆库和隐式嵌入增强技术，显著降低了计算成本，并在资源受限环境中优于现有方法。

Abstract: Visual Place Recognition (VPR) has advanced significantly with high-capacity foundation models like DINOv2, achieving remarkable performance. Nonetheless, their substantial computational cost makes deployment on resource-constrained devices impractical. In this paper, we introduce an efficient asymmetric VPR framework that incorporates a high-capacity gallery model for offline feature extraction with a lightweight query network for online processing. A key challenge in this setting is ensuring compatibility between these heterogeneous networks, which conventional approaches address through computationally expensive k-NN-based compatible training. To overcome this, we propose a geographical memory bank that structures gallery features using geolocation metadata inherent in VPR databases, eliminating the need for exhaustive k-NN computations. Additionally, we introduce an implicit embedding augmentation technique that enhances the query network to model feature variations despite its limited capacity. Extensive experiments demonstrate that our method not only significantly reduces computational costs but also outperforms existing asymmetric retrieval techniques, establishing a new aspect for VPR in resource-limited environments. The code is available at https://github.com/jaeyoon1603/AsymVPR

</details>


### [153] [Forging a Dynamic Memory: Retrieval-Guided Continual Learning for Generalist Medical Foundation Models](https://arxiv.org/abs/2512.13072)
*Zizhi Chen,Yizhen Gao,Minghao Han,Yizhou Liu,Zhaoyu Chen,Dingkang Yang,Lihua Zhang*

Main category: cs.CV

TL;DR: 提出了一个结合RAG和动态知识蒸馏的框架，解决了多模态生物医学VLMs在持续学习中的核心难题，并在新设计的MGTIL基准上实现了SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 解决多模态生物医学视觉语言模型在持续学习中如何保持细粒度模态内特征并跨越显著领域差距的核心难题。

Method: 提出了一个结合检索增强生成（RAG）和动态知识蒸馏的综合框架。

Result: 实验结果表明，该方法在所有指标上均达到最先进性能。

Conclusion: 提出的方法在多项指标上达到了最先进的性能，证明了其在持续学习中的有效性。

Abstract: Multimodal biomedical Vision-Language Models (VLMs) exhibit immense potential in the field of Continual Learning (CL). However, they confront a core dilemma: how to preserve fine-grained intra-modality features while bridging the significant domain gap across different modalities. To address this challenge, we propose a comprehensive framework. Leveraging our 18-million multimodal and comprehensive medical retrieval database derived from PubMed scientific papers, we pioneer the integration of Retrieval-Augmented Generation (RAG) into CL. Specifically, we employ a multi-modal, multi-layer RAG system that provides real-time guidance for model fine-tuning through dynamic, on-demand knowledge retrieval. Building upon this, we introduce a dynamic knowledge distillation framework. This framework precisely resolves the aforementioned core dilemma by dynamically modulating the importance of the parameter space, the granularity of the distilled knowledge, and the data distribution of the reference dataset in accordance with the required level of detail. To thoroughly validate the clinical value of our strategy, we have designed a more rigorous \textbf{M}edical Generalist Task Incremental Learning (MGTIL) benchmark. This benchmark is engineered to simultaneously evaluate the model's capacity for adaptation to significant domain shifts, retention of subtle intra-domain features, and real-time learning of novel and complex medical tasks. Extensive experimental results demonstrate that our proposed method achieves state-of-the-art (SOTA) performance across all metrics. The code is provided in the supplementary materials.

</details>


### [154] [Heart Disease Prediction using Case Based Reasoning (CBR)](https://arxiv.org/abs/2512.13078)
*Mohaiminul Islam Bhuiyan,Chan Hue Wah,Nur Shazwani Kamarudin,Nur Hafieza Ismail,Ahmad Fakhri Ab Nasir*

Main category: cs.CV

TL;DR: 智能系统（尤其是CBR）在心脏病预测中表现优异，准确率近98%，男性风险更高，吸烟和饮酒是主要诱因。


<details>
  <summary>Details</summary>
Motivation: 传统依赖医生经验的疾病预测方法精度不足，智能系统可提供更准确的替代方案。

Method: 研究比较了Fuzzy Logic、Neural Networks和Case-Based Reasoning (CBR)三种智能系统方法，最终选择CBR进行预测。数据预处理包括清洗和分割为训练集与测试集。

Result: CBR预测准确率为97.95%，男性患病概率高于女性，吸烟和饮酒是主要风险因素。

Conclusion: Case-Based Reasoning (CBR) 在心脏病预测中表现出色，准确率达到97.95%，且男性患病概率（57.76%）高于女性（42.24%）。吸烟和饮酒是重要影响因素。

Abstract: This study provides an overview of heart disease prediction using an intelligent system. Predicting disease accurately is crucial in the medical field, but traditional methods relying solely on a doctor's experience often lack precision. To address this limitation, intelligent systems are applied as an alternative to traditional approaches. While various intelligent system methods exist, this study focuses on three: Fuzzy Logic, Neural Networks, and Case-Based Reasoning (CBR). A comparison of these techniques in terms of accuracy was conducted, and ultimately, Case-Based Reasoning (CBR) was selected for heart disease prediction. In the prediction phase, the heart disease dataset underwent data pre-processing to clean the data and data splitting to separate it into training and testing sets. The chosen intelligent system was then employed to predict heart disease outcomes based on the processed data. The experiment concluded with Case-Based Reasoning (CBR) achieving a notable accuracy rate of 97.95% in predicting heart disease. The findings also revealed that the probability of heart disease was 57.76% for males and 42.24% for females. Further analysis from related studies suggests that factors such as smoking and alcohol consumption are significant contributors to heart disease, particularly among males.

</details>


### [155] [DiRe: Diversity-promoting Regularization for Dataset Condensation](https://arxiv.org/abs/2512.13083)
*Saumyaranjan Mohanty,Aravind Reddy,Konda Reddy Mopuri*

Main category: cs.CV

TL;DR: 提出DiRe正则化器，通过余弦相似度和欧氏距离提升数据集压缩的多样性，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有数据集压缩方法合成的数据集冗余度高，亟需提升多样性。

Method: 结合余弦相似度和欧几里得距离设计多样性正则化器（DiRe），可即插即用地应用于现有压缩方法。

Result: 实验表明，DiRe显著提升了CIFAR-10至ImageNet-1K等基准数据集上的压缩方法性能。

Conclusion: 提出的DiRe正则化器有效提升了数据集压缩方法的多样性和泛化性能。

Abstract: In Dataset Condensation, the goal is to synthesize a small dataset that replicates the training utility of a large original dataset. Existing condensation methods synthesize datasets with significant redundancy, so there is a dire need to reduce redundancy and improve the diversity of the synthesized datasets. To tackle this, we propose an intuitive Diversity Regularizer (DiRe) composed of cosine similarity and Euclidean distance, which can be applied off-the-shelf to various state-of-the-art condensation methods. Through extensive experiments, we demonstrate that the addition of our regularizer improves state-of-the-art condensation methods on various benchmark datasets from CIFAR-10 to ImageNet-1K with respect to generalization and diversity metrics.

</details>


### [156] [ADHint: Adaptive Hints with Difficulty Priors for Reinforcement Learning](https://arxiv.org/abs/2512.13095)
*Feng Zhang,Zezhong Tan,Xinhong Ma,Ziqiang Dong,Xi Leng,Jianfei Zhao,Xin Sun,Yang Yang*

Main category: cs.CV

TL;DR: ADHint通过难度感知的提示调度和优势估计，优化了强化学习中的探索与模仿平衡，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于提示的强化学习方法在调度提示比例和估计相对优势时通常忽略难度因素，导致学习不稳定和过度模仿离策略提示。

Method: 提出了自适应提示（Adaptive Hint with Sample Difficulty Prior）、基于一致性的梯度调制（Consistency-based Gradient Modulation）、选择性掩码（Selective Masking for Hint Preservation）以及基于后验难度的优势估计（Advantage Estimation with Rollout Difficulty Posterior）。

Result: 实验表明，ADHint在多种模态、模型规模和领域上均表现出卓越的推理能力和分布外泛化性能，显著优于现有方法。

Conclusion: ADHint通过将难度作为关键因素融入提示比例调度和相对优势估计，实现了探索与模仿的更好平衡，显著提升了推理能力和分布外泛化性能。

Abstract: To combine the advantages of Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL), recent methods have integrated ''hints'' into post-training, which are prefix segments of complete reasoning trajectories, aiming for powerful knowledge expansion and reasoning generalization. However, existing hint-based RL methods typically ignore difficulty when scheduling hint ratios and estimating relative advantages, leading to unstable learning and excessive imitation of off-policy hints. In this work, we propose ADHint, which treats difficulty as a key factor in both hint-ratio schedule and relative-advantage estimation to achieve a better trade-off between exploration and imitation. Specifically, we propose Adaptive Hint with Sample Difficulty Prior, which evaluates each sample's difficulty under the policy model and accordingly schedules an appropriate hint ratio to guide its rollouts. We also introduce Consistency-based Gradient Modulation and Selective Masking for Hint Preservation to modulate token-level gradients within hints, preventing biased and destructive updates. Additionally, we propose Advantage Estimation with Rollout Difficulty Posterior, which leverages the relative difficulty of rollouts with and without hints to estimate their respective advantages, thereby achieving more balanced updates. Extensive experiments across diverse modalities, model scales, and domains demonstrate that ADHint delivers superior reasoning ability and out-of-distribution generalization, consistently surpassing existing methods in both pass@1 and avg@8. Our code and dataset will be made publicly available upon paper acceptance.

</details>


### [157] [FID-Net: A Feature-Enhanced Deep Learning Network for Forest Infestation Detection](https://arxiv.org/abs/2512.13104)
*Yan Zhang,Baoxin Li,Han Sun,Yuhang Gao,Mingtai Zhang,Pei Wang*

Main category: cs.CV

TL;DR: FID-Net是一种深度学习模型，通过无人机可见光影像检测虫害树木，并结合空间指标分析虫害模式，性能优于主流模型。


<details>
  <summary>Details</summary>
Motivation: 传统方法在大规模、细粒度检测中存在局限性，本研究旨在准确识别受感染的树木并分析虫害模式。

Method: 基于YOLOv8n，FID-Net引入了轻量级特征增强模块（FEM）、自适应多尺度特征融合模块（AMFM）和高效通道注意力（ECA）机制。

Result: FID-Net在32个森林地块的无人机影像上实现了86.10%的精确率、75.44%的召回率、82.29%的mAP@0.5和64.30%的mAP@0.5:0.95，优于主流YOLO模型。

Conclusion: FID-Net结合空间指标为智能害虫监测、早期预警和精准管理提供了可靠数据。

Abstract: Forest pests threaten ecosystem stability, requiring efficient monitoring. To overcome the limitations of traditional methods in large-scale, fine-grained detection, this study focuses on accurately identifying infected trees and analyzing infestation patterns. We propose FID-Net, a deep learning model that detects pest-affected trees from UAV visible-light imagery and enables infestation analysis via three spatial metrics. Based on YOLOv8n, FID-Net introduces a lightweight Feature Enhancement Module (FEM) to extract disease-sensitive cues, an Adaptive Multi-scale Feature Fusion Module (AMFM) to align and fuse dual-branch features (RGB and FEM-enhanced), and an Efficient Channel Attention (ECA) mechanism to enhance discriminative information efficiently. From detection results, we construct a pest situation analysis framework using: (1) Kernel Density Estimation to locate infection hotspots; (2) neighborhood evaluation to assess healthy trees' infection risk; (3) DBSCAN clustering to identify high-density healthy clusters as priority protection zones. Experiments on UAV imagery from 32 forest plots in eastern Tianshan, China, show that FID-Net achieves 86.10% precision, 75.44% recall, 82.29% mAP@0.5, and 64.30% mAP@0.5:0.95, outperforming mainstream YOLO models. Analysis confirms infected trees exhibit clear clustering, supporting targeted forest protection. FID-Net enables accurate tree health discrimination and, combined with spatial metrics, provides reliable data for intelligent pest monitoring, early warning, and precise management.

</details>


### [158] [LeafTrackNet: A Deep Learning Framework for Robust Leaf Tracking in Top-Down Plant Phenotyping](https://arxiv.org/abs/2512.13130)
*Shanghua Liu,Majharulislam Babor,Christoph Verduyn,Breght Vandenberghe,Bruno Betoni Parodi,Cornelia Weltzien,Marina M. -C. Höhne*

Main category: cs.CV

TL;DR: 研究提出LeafTrackNet框架和CanolaTrack数据集，显著提升复杂作物叶片跟踪性能，推动植物表型研究。


<details>
  <summary>Details</summary>
Motivation: 现有叶片跟踪方法在复杂作物或真实条件下表现不佳，缺乏大规模数据集阻碍了准确模型的开发。

Method: 结合YOLOv10叶片检测器和MobileNetV3嵌入网络，采用基于嵌入的记忆关联策略保持叶片身份。

Result: LeafTrackNet在CanolaTrack上表现优于现有植物专用跟踪器和多目标跟踪基线，HOTA指标提升9%。

Conclusion: 该研究通过引入CanolaTrack数据集和LeafTrackNet框架，为复杂作物（如油菜）的叶片跟踪设立了新标准，并推动了植物表型研究的未来发展。

Abstract: High resolution phenotyping at the level of individual leaves offers fine-grained insights into plant development and stress responses. However, the full potential of accurate leaf tracking over time remains largely unexplored due to the absence of robust tracking methods-particularly for structurally complex crops such as canola. Existing plant-specific tracking methods are typically limited to small-scale species or rely on constrained imaging conditions. In contrast, generic multi-object tracking (MOT) methods are not designed for dynamic biological scenes. Progress in the development of accurate leaf tracking models has also been hindered by a lack of large-scale datasets captured under realistic conditions. In this work, we introduce CanolaTrack, a new benchmark dataset comprising 5,704 RGB images with 31,840 annotated leaf instances spanning the early growth stages of 184 canola plants. To enable accurate leaf tracking over time, we introduce LeafTrackNet, an efficient framework that combines a YOLOv10-based leaf detector with a MobileNetV3-based embedding network. During inference, leaf identities are maintained over time through an embedding-based memory association strategy. LeafTrackNet outperforms both plant-specific trackers and state-of-the-art MOT baselines, achieving a 9% HOTA improvement on CanolaTrack. With our work we provide a new standard for leaf-level tracking under realistic conditions and we provide CanolaTrack - the largest dataset for leaf tracking in agriculture crops, which will contribute to future research in plant phenotyping. Our code and dataset are publicly available at https://github.com/shl-shawn/LeafTrackNet.

</details>


### [159] [Weight Space Correlation Analysis: Quantifying Feature Utilization in Deep Learning Models](https://arxiv.org/abs/2512.13144)
*Chun Kit Wong,Paraskevas Pegios,Nina Weng,Emilie Pi Fogtmann Sejer,Martin Grønnebæk Tolsgaard,Anders Nymark Christensen,Aasa Feragen*

Main category: cs.CV

TL;DR: 该论文提出了一种解释性方法，通过权重空间相关性分析验证医学影像模型是否依赖无关元数据进行预测，结果表明模型能选择性利用临床相关特征。


<details>
  <summary>Details</summary>
Motivation: 医学影像中的深度学习模型容易受到捷径学习的影响，依赖混杂的元数据（如扫描仪型号），这些信息通常被编码在图像嵌入中。关键问题是模型是否主动利用这些编码信息进行最终预测。

Method: 引入权重空间相关性分析（Weight Space Correlation Analysis），通过测量主要临床任务和辅助元数据任务的分类头之间的对齐来量化特征利用。

Result: 分析证实，虽然嵌入包含大量元数据，但sPTB分类器的权重向量与临床相关因素（如出生体重）高度相关，而与临床无关的采集因素（如扫描仪）解耦。

Conclusion: 该论文的方法论提供了一种验证模型可信度的工具，表明在没有诱导偏差的情况下，临床模型会选择性地利用与真实临床信号相关的特征。

Abstract: Deep learning models in medical imaging are susceptible to shortcut learning, relying on confounding metadata (e.g., scanner model) that is often encoded in image embeddings. The crucial question is whether the model actively utilizes this encoded information for its final prediction. We introduce Weight Space Correlation Analysis, an interpretable methodology that quantifies feature utilization by measuring the alignment between the classification heads of a primary clinical task and auxiliary metadata tasks. We first validate our method by successfully detecting artificially induced shortcut learning. We then apply it to probe the feature utilization of an SA-SonoNet model trained for Spontaneous Preterm Birth (sPTB) prediction. Our analysis confirmed that while the embeddings contain substantial metadata, the sPTB classifier's weight vectors were highly correlated with clinically relevant factors (e.g., birth weight) but decoupled from clinically irrelevant acquisition factors (e.g. scanner). Our methodology provides a tool to verify model trustworthiness, demonstrating that, in the absence of induced bias, the clinical model selectively utilizes features related to the genuine clinical signal.

</details>


### [160] [StarryGazer: Leveraging Monocular Depth Estimation Models for Domain-Agnostic Single Depth Image Completion](https://arxiv.org/abs/2512.13147)
*Sangmin Hong,Suyoung Lee,Kyoung Mu Lee*

Main category: cs.CV

TL;DR: StarryGazer是一种无需真实深度数据的深度补全框架，结合MDE模型和稀疏深度信息，通过合成数据训练细化网络，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有无监督深度补全方法依赖辅助数据，而单目深度估计模型虽能生成相对深度图，但缺乏与稀疏深度图的合理结合方式。

Method: 首先使用预训练的MDE模型生成相对深度图像，然后通过分割和随机缩放生成合成数据对，最后训练一个细化网络结合相对深度图和RGB图像以提高模型性能。

Result: StarryGazer在多个数据集上优于现有无监督方法和转换后的MDE结果，证明了其有效性和泛化能力。

Conclusion: StarryGazer框架通过结合单目深度估计（MDE）模型和稀疏深度信息，无需依赖真实深度数据，显著提升了深度补全的准确性和鲁棒性。

Abstract: The problem of depth completion involves predicting a dense depth image from a single sparse depth map and an RGB image. Unsupervised depth completion methods have been proposed for various datasets where ground truth depth data is unavailable and supervised methods cannot be applied. However, these models require auxiliary data to estimate depth values, which is far from real scenarios. Monocular depth estimation (MDE) models can produce a plausible relative depth map from a single image, but there is no work to properly combine the sparse depth map with MDE for depth completion; a simple affine transformation to the depth map will yield a high error since MDE are inaccurate at estimating depth difference between objects. We introduce StarryGazer, a domain-agnostic framework that predicts dense depth images from a single sparse depth image and an RGB image without relying on ground-truth depth by leveraging the power of large MDE models. First, we employ a pre-trained MDE model to produce relative depth images. These images are segmented and randomly rescaled to form synthetic pairs for dense pseudo-ground truth and corresponding sparse depths. A refinement network is trained with the synthetic pairs, incorporating the relative depth maps and RGB images to improve the model's accuracy and robustness. StarryGazer shows superior results over existing unsupervised methods and transformed MDE results on various datasets, demonstrating that our framework exploits the power of MDE models while appropriately fixing errors using sparse depth information.

</details>


### [161] [Seeing the Whole Picture: Distribution-Guided Data-Free Distillation for Semantic Segmentation](https://arxiv.org/abs/2512.13175)
*Hongxuan Sun,Tao Wu*

Main category: cs.CV

TL;DR: DFSS是一种专为语义分割设计的数据无知识蒸馏框架，通过ADS和WDPD方法提升性能，无需依赖教师模型的预测或辅助数据。


<details>
  <summary>Details</summary>
Motivation: 现有数据无知识蒸馏方法主要为分类任务设计，忽视了语义分割中对象的空间连续性和结构一致性，导致性能下降。

Method: DFSS利用教师模型的Batch Normalization（BN）统计信息来指导近似分布采样（ADS），并提出了加权分布渐进蒸馏（WDPD）方法，动态优先处理与原始数据分布更接近的可靠样本。

Result: DFSS在标准基准测试中 consistently 优于现有数据无知识蒸馏方法，显著减少了对辅助数据的依赖。

Conclusion: DFSS通过尊重真实场景的结构和上下文连续性，显著提升了语义分割任务中数据无知识蒸馏的性能，并在标准基准测试中取得了最先进的结果。

Abstract: Semantic segmentation requires a holistic understanding of the physical world, as it assigns semantic labels to spatially continuous and structurally coherent objects rather than to isolated pixels. However, existing data-free knowledge distillation (DFKD) methods-primarily designed for classification-often disregard this continuity, resulting in significant performance degradation when applied directly to segmentation tasks. In this paper, we introduce DFSS, a novel data-free distillation framework tailored for semantic segmentation. Unlike prior approaches that treat pixels independently, DFSS respects the structural and contextual continuity of real-world scenes. Our key insight is to leverage Batch Normalization (BN) statistics from a teacher model to guide Approximate Distribution Sampling (ADS), enabling the selection of data that better reflects the original training distribution-without relying on potentially misleading teacher predictions. Additionally, we propose Weighted Distribution Progressive Distillation (WDPD), which dynamically prioritizes reliable samples that are more closely aligned with the original data distribution early in training and gradually incorporates more challenging cases, mirroring the natural progression of learning in human perception. Extensive experiments on standard benchmarks demonstrate that DFSS consistently outperforms existing data-free distillation methods for semantic segmentation, achieving state-of-the-art results with significantly reduced reliance on auxiliary data.

</details>


### [162] [CoRA: A Collaborative Robust Architecture with Hybrid Fusion for Efficient Perception](https://arxiv.org/abs/2512.13191)
*Gong Chen,Chaokun Zhang,Pengcheng Lv,Xiaohui Xie*

Main category: cs.CV

TL;DR: CoRA是一种新型协作感知架构，通过混合特征级和对象级融合，在低通信条件下提升性能与鲁棒性，实验显示其在极端场景下表现优越。


<details>
  <summary>Details</summary>
Motivation: 现有的中间融合方法在恶劣通信条件下性能下降，阻碍了实际部署。本文重新审视不同融合范式，发现中间和后期融合的优势是互补的，而非权衡。

Method: CoRA由两个组件组成：特征级融合分支和对象级校正分支。特征级融合分支选择关键特征并高效融合，确保性能和可扩展性；对象级校正分支利用语义相关性校正空间位移，保证对姿态错误的鲁棒性。

Result: 在极端场景下，CoRA在AP@0.7上比基线性能提高了约19%，同时通信量减少了5倍以上。

Conclusion: CoRA作为一种新颖的协作感知架构，通过混合方法在低通信条件下解耦性能与鲁棒性，展现了在极端场景下的优越性能，是一种有前景的解决方案。

Abstract: Collaborative perception has garnered significant attention as a crucial technology to overcome the perceptual limitations of single-agent systems. Many state-of-the-art (SOTA) methods have achieved communication efficiency and high performance via intermediate fusion. However, they share a critical vulnerability: their performance degrades under adverse communication conditions due to the misalignment induced by data transmission, which severely hampers their practical deployment. To bridge this gap, we re-examine different fusion paradigms, and recover that the strengths of intermediate and late fusion are not a trade-off, but a complementary pairing. Based on this key insight, we propose CoRA, a novel collaborative robust architecture with a hybrid approach to decouple performance from robustness with low communication. It is composed of two components: a feature-level fusion branch and an object-level correction branch. Its first branch selects critical features and fuses them efficiently to ensure both performance and scalability. The second branch leverages semantic relevance to correct spatial displacements, guaranteeing resilience against pose errors. Experiments demonstrate the superiority of CoRA. Under extreme scenarios, CoRA improves upon its baseline performance by approximately 19% in AP@0.7 with more than 5x less communication volume, which makes it a promising solution for robust collaborative perception.

</details>


### [163] [POLAR: A Portrait OLAT Dataset and Generative Framework for Illumination-Aware Face Modeling](https://arxiv.org/abs/2512.13192)
*Zhuo Chen,Chengqun Yang,Zhuo Su,Zheng Lv,Jingnan Gao,Xiaoyuan Zhang,Xiaokang Yang,Yichao Yan*

Main category: cs.CV

TL;DR: POLAR是一个大规模物理校准的OLAT数据集，POLARNet是基于流的生成模型，用于从单张肖像预测照明效果，实现了可扩展和可控的面部重新照明。


<details>
  <summary>Details</summary>
Motivation: 解决大规模、物理一致的照明数据有限的问题，以推动面部重新照明技术的发展。

Method: 基于POLAR数据集，开发了一个基于流的生成模型POLARNet，该模型从单张肖像预测每光的OLAT响应，捕捉细粒度和方向感知的照明效果，同时保留面部身份。

Result: POLARNet能够预测细粒度和方向感知的照明效果，同时保留面部身份，实现了可扩展和可控的重新照明。

Conclusion: POLAR和POLARNet共同构成了一个统一的照明学习框架，通过真实数据、生成合成和物理基础的重新照明，建立了一个可扩展且可复制的肖像照明系统。

Abstract: Face relighting aims to synthesize realistic portraits under novel illumination while preserving identity and geometry. However, progress remains constrained by the limited availability of large-scale, physically consistent illumination data. To address this, we introduce POLAR, a large-scale and physically calibrated One-Light-at-a-Time (OLAT) dataset containing over 200 subjects captured under 156 lighting directions, multiple views, and diverse expressions. Building upon POLAR, we develop a flow-based generative model POLARNet that predicts per-light OLAT responses from a single portrait, capturing fine-grained and direction-aware illumination effects while preserving facial identity. Unlike diffusion or background-conditioned methods that rely on statistical or contextual cues, our formulation models illumination as a continuous, physically interpretable transformation between lighting states, enabling scalable and controllable relighting. Together, POLAR and POLARNet form a unified illumination learning framework that links real data, generative synthesis, and physically grounded relighting, establishing a self-sustaining "chicken-and-egg" cycle for scalable and reproducible portrait illumination.

</details>


### [164] [Ego-EXTRA: video-language Egocentric Dataset for EXpert-TRAinee assistance](https://arxiv.org/abs/2512.13238)
*Francesco Ragusa,Michele Mazzamuto,Rosario Forte,Irene D'Ambra,James Fort,Jakob Engel,Antonino Furnari,Giovanni Maria Farinella*

Main category: cs.CV

TL;DR: Ego-EXTRA是一个50小时的自我中心视频-语言数据集，用于专家-受训者辅助研究，包含15k视觉问答对，挑战当前多模态模型。


<details>
  <summary>Details</summary>
Motivation: 构建高质量的视频-语言自我中心数据集，以支持专家与受训者之间的自然语言交互研究。

Method: 采用“Wizard of OZ”数据收集范式，专家通过穿戴式智能助手从自我中心视角提供指导和回答受训者问题，记录并转录双向对话。

Result: 创建了包含超过15k高质量视觉问答对的新基准，用于评估多模态大语言模型。

Conclusion: Ego-EXTRA数据集为评估多模态大语言模型提供了挑战性的基准，并揭示了当前模型在提供专家级辅助方面的局限性。

Abstract: We present Ego-EXTRA, a video-language Egocentric Dataset for EXpert-TRAinee assistance. Ego-EXTRA features 50 hours of unscripted egocentric videos of subjects performing procedural activities (the trainees) while guided by real-world experts who provide guidance and answer specific questions using natural language. Following a ``Wizard of OZ'' data collection paradigm, the expert enacts a wearable intelligent assistant, looking at the activities performed by the trainee exclusively from their egocentric point of view, answering questions when asked by the trainee, or proactively interacting with suggestions during the procedures. This unique data collection protocol enables Ego-EXTRA to capture a high-quality dialogue in which expert-level feedback is provided to the trainee. Two-way dialogues between experts and trainees are recorded, transcribed, and used to create a novel benchmark comprising more than 15k high-quality Visual Question Answer sets, which we use to evaluate Multimodal Large Language Models. The results show that Ego-EXTRA is challenging and highlight the limitations of current models when used to provide expert-level assistance to the user. The Ego-EXTRA dataset is publicly available to support the benchmark of egocentric video-language assistants: https://fpv-iplab.github.io/Ego-EXTRA/.

</details>


### [165] [STARCaster: Spatio-Temporal AutoRegressive Video Diffusion for Identity- and View-Aware Talking Portraits](https://arxiv.org/abs/2512.13247)
*Foivos Paraperas Papantoniou,Stathis Galanakis,Rolandos Alexandros Potamias,Bernhard Kainz,Stefanos Zafeiriou*

Main category: cs.CV

TL;DR: STARCaster是一个身份感知的时空视频扩散模型，通过软身份约束和2D视频域内的隐式3D感知，统一解决了语音驱动动画和自由视角合成问题，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有2D语音到视频扩散模型过度依赖参考指导，导致运动多样性有限；3D感知动画通常依赖预训练的三平面生成器，导致重建不完美和身份漂移。

Method: 采用组合方法，从ID感知运动建模开始，通过基于唇读的监督实现视听同步，最后通过时空适应实现新颖视角动画。提出解耦学习方法和自强制训练方案。

Result: STARCaster在任务和身份上表现出良好的泛化能力，在多个基准测试中优于现有方法。

Conclusion: STARCaster通过统一的框架有效解决了语音驱动肖像动画和自由视角说话肖像合成的问题，并在多个基准测试中超越了现有方法。

Abstract: This paper presents STARCaster, an identity-aware spatio-temporal video diffusion model that addresses both speech-driven portrait animation and free-viewpoint talking portrait synthesis, given an identity embedding or reference image, within a unified framework. Existing 2D speech-to-video diffusion models depend heavily on reference guidance, leading to limited motion diversity. At the same time, 3D-aware animation typically relies on inversion through pre-trained tri-plane generators, which often leads to imperfect reconstructions and identity drift. We rethink reference- and geometry-based paradigms in two ways. First, we deviate from strict reference conditioning at pre-training by introducing softer identity constraints. Second, we address 3D awareness implicitly within the 2D video domain by leveraging the inherent multi-view nature of video data. STARCaster adopts a compositional approach progressing from ID-aware motion modeling, to audio-visual synchronization via lip reading-based supervision, and finally to novel view animation through temporal-to-spatial adaptation. To overcome the scarcity of 4D audio-visual data, we propose a decoupled learning approach in which view consistency and temporal coherence are trained independently. A self-forcing training scheme enables the model to learn from longer temporal contexts than those generated at inference, mitigating the overly static animations common in existing autoregressive approaches. Comprehensive evaluations demonstrate that STARCaster generalizes effectively across tasks and identities, consistently surpassing prior approaches in different benchmarks.

</details>


### [166] [Toward Ambulatory Vision: Learning Visually-Grounded Active View Selection](https://arxiv.org/abs/2512.13250)
*Juil Koo,Daehyeon Choi,Sangwoo Youn,Phillip Y. Lee,Minhyuk Sung*

Main category: cs.CV

TL;DR: VG-AVS任务通过主动选择最有信息量的视角，提升了视觉问答性能，并适用于合成和真实场景。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉语言模型（VLMs）局限于静态图像推理的问题，提出主动视觉选择任务（VG-AVS）。

Method: 通过监督微调（SFT）和基于强化学习（RL）的策略优化，对预训练的VLM进行微调。

Result: 在未见过的合成和真实场景中，VG-AVS框架展现出强大的问答性能和鲁棒性。

Conclusion: 将VG-AVS框架集成到现有场景探索的EQA系统中，提升了下游问答的准确性。

Abstract: Vision Language Models (VLMs) excel at visual question answering (VQA) but remain limited to snapshot vision, reasoning from static images. In contrast, embodied agents require ambulatory vision, actively moving to obtain more informative views. We introduce Visually Grounded Active View Selection (VG-AVS), a task that selects the most informative next viewpoint using only the visual information in the current image, without relying on scene memory or external knowledge. To support this task, we construct a synthetic dataset with automatically generated paired query-target views and question-answer prompts. We also propose a framework that fine-tunes pretrained VLMs through supervised fine-tuning (SFT) followed by RL-based policy optimization. Our approach achieves strong question answering performance based on viewpoint selection and generalizes robustly to unseen synthetic and real scenes. Furthermore, incorporating our learned VG-AVS framework into existing scene-exploration-based EQA systems improves downstream question-answering accuracy.

</details>


### [167] [CogniEdit: Dense Gradient Flow Optimization for Fine-Grained Image Editing](https://arxiv.org/abs/2512.13276)
*Yan Li,Lin Liu,Xiaopeng Zhang,Wei Xue,Wenhan Luo,Yike Guo,Qi Tian*

Main category: cs.CV

TL;DR: CogniEdit通过多模态推理和密集奖励优化，实现了对细粒度指令的精准编辑，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于指令的图像编辑方法在遵循细粒度指令（如颜色、位置、数量）时表现不佳，且GRPO优化仅在单个采样步骤提供稀疏反馈，限制了轨迹级控制。

Method: CogniEdit框架包含三个关键组件：1) 多模态大型语言模型用于分解复杂指令；2) 动态令牌焦点重定位以自适应强调细粒度属性；3) 基于密集GRPO的优化，通过连续步骤传播梯度以实现轨迹级监督。

Result: 在基准数据集上的大量实验表明，CogniEdit在平衡细粒度指令遵循与视觉质量和可编辑性保持方面达到了最先进的性能。

Conclusion: CogniEdit框架通过结合多模态推理和密集奖励优化，在保持视觉质量和可编辑性的同时，实现了对细粒度指令的精准遵循，达到了最先进的性能。

Abstract: Instruction-based image editing with diffusion models has achieved impressive results, yet existing methods struggle with fine-grained instructions specifying precise attributes such as colors, positions, and quantities. While recent approaches employ Group Relative Policy Optimization (GRPO) for alignment, they optimize only at individual sampling steps, providing sparse feedback that limits trajectory-level control. We propose a unified framework CogniEdit, combining multi-modal reasoning with dense reward optimization that propagates gradients across consecutive denoising steps, enabling trajectory-level gradient flow through the sampling process. Our method comprises three components: (1) Multi-modal Large Language Models for decomposing complex instructions into actionable directives, (2) Dynamic Token Focus Relocation that adaptively emphasizes fine-grained attributes, and (3) Dense GRPO-based optimization that propagates gradients across consecutive steps for trajectory-level supervision. Extensive experiments on benchmark datasets demonstrate that our CogniEdit achieves state-of-the-art performance in balancing fine-grained instruction following with visual quality and editability preservation

</details>


### [168] [Video Reality Test: Can AI-Generated ASMR Videos fool VLMs and Humans?](https://arxiv.org/abs/2512.13281)
*Jiaqi Wang,Weijia Wu,Yi Zhan,Rui Zhao,Ming Hu,James Cheng,Wei Liu,Philip Torr,Kevin Qinghong Lin*

Main category: cs.CV

TL;DR: 该研究通过Video Reality Test基准评估视频生成模型的真实性，发现当前模型在音频配对视频中能欺骗视觉语言模型，但人类专家识别能力更强，揭示了模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 鉴于视频生成技术的进步使得AI生成视频与真实视频难以区分，需要评估现有视频生成模型是否能产生具有沉浸感的音频配对视频，并能可靠地欺骗人类和视觉语言模型。

Method: 通过引入Video Reality Test基准套件，采用ASMR来源的视频音频对，设计了一个对抗性的创作者-评审者协议，其中视频生成模型作为创作者试图欺骗评审者，而视觉语言模型作为评审者尝试识别虚假内容。

Result: 实验结果显示，最佳创作者Veo3.1-Fast甚至能欺骗大多数视觉语言模型，最强评审者Gemini 2.5-Pro的准确率仅为56%（随机50%），远低于人类专家的81.25%。添加音频提高了真假辨别能力，但水印等表面线索仍会显著误导模型。

Conclusion: 当前视频生成技术的真实性边界已明确，同时揭示了视觉语言模型在感知保真度和视听一致性方面的局限性。

Abstract: Recent advances in video generation have produced vivid content that are often indistinguishable from real videos, making AI-generated video detection an emerging societal challenge. Prior AIGC detection benchmarks mostly evaluate video without audio, target broad narrative domains, and focus on classification solely. Yet it remains unclear whether state-of-the-art video generation models can produce immersive, audio-paired videos that reliably deceive humans and VLMs. To this end, we introduce Video Reality Test, an ASMR-sourced video benchmark suite for testing perceptual realism under tight audio-visual coupling, featuring the following dimensions: \textbf{(i) Immersive ASMR video-audio sources.} Built on carefully curated real ASMR videos, the benchmark targets fine-grained action-object interactions with diversity across objects, actions, and backgrounds. \textbf{(ii) Peer-Review evaluation.} An adversarial creator-reviewer protocol where video generation models act as creators aiming to fool reviewers, while VLMs serve as reviewers seeking to identify fakeness. Our experimental findings show: The best creator Veo3.1-Fast even fools most VLMs: the strongest reviewer (Gemini 2.5-Pro) achieves only 56\% accuracy (random 50\%), far below that of human experts (81.25\%). Adding audio improves real-fake discrimination, yet superficial cues such as watermarks can still significantly mislead models. These findings delineate the current boundary of video generation realism and expose limitations of VLMs in perceptual fidelity and audio-visual consistency. Our code is available at https://github.com/video-reality-test/video-reality-test.

</details>


### [169] [CausalCLIP: Causally-Informed Feature Disentanglement and Filtering for Generalizable Detection of Generated Images](https://arxiv.org/abs/2512.13285)
*Bo Liu,Qiao Qin,Qinghui He*

Main category: cs.CV

TL;DR: CausalCLIP通过因果特征解耦和过滤，提升了生成图像检测的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法生成的表示高度纠缠，混入了无关的虚假模式，限制了泛化能力。

Method: 利用结构因果模型建模生成过程，通过Gumbel-Softmax特征掩码和HSIC约束实现统计独立性，分离稳定的因果特征。

Result: 在未见过的生成模型上，CausalCLIP在准确率和平均精度上分别提升了6.83%和4.06%。

Conclusion: CausalCLIP通过明确解耦因果与非因果特征，并结合因果推理原则进行有针对性的过滤，显著提升了生成图像检测器的泛化能力。

Abstract: The rapid advancement of generative models has increased the demand for generated image detectors capable of generalizing across diverse and evolving generation techniques. However, existing methods, including those leveraging pre-trained vision-language models, often produce highly entangled representations, mixing task-relevant forensic cues (causal features) with spurious or irrelevant patterns (non-causal features), thus limiting generalization. To address this issue, we propose CausalCLIP, a framework that explicitly disentangles causal from non-causal features and employs targeted filtering guided by causal inference principles to retain only the most transferable and discriminative forensic cues. By modeling the generation process with a structural causal model and enforcing statistical independence through Gumbel-Softmax-based feature masking and Hilbert-Schmidt Independence Criterion (HSIC) constraints, CausalCLIP isolates stable causal features robust to distribution shifts. When tested on unseen generative models from different series, CausalCLIP demonstrates strong generalization ability, achieving improvements of 6.83% in accuracy and 4.06% in average precision over state-of-the-art methods.

</details>


### [170] [ShowTable: Unlocking Creative Table Visualization with Collaborative Reflection and Refinement](https://arxiv.org/abs/2512.13303)
*Zhihang Liu,Xiaoyi Bao,Pandeng Li,Junjie Zhou,Zhaohe Liao,Yefei He,Kaixun Jiang,Chen-Wei Xie,Yun Zheng,Hongtao Xie*

Main category: cs.CV

TL;DR: ShowTable管道结合MLLMs和扩散模型，通过自校正过程实现创意表格可视化，显著优于基线。


<details>
  <summary>Details</summary>
Motivation: 现有生成和统一模型在通用图像生成方面表现优异，但在需要深度推理、规划和精确数据到视觉映射的任务中表现不佳。为突破这些限制，引入创意表格可视化这一新挑战性任务。

Method: 提出ShowTable管道，结合MLLMs和扩散模型通过渐进式自校正过程。MLLM作为视觉规划和错误判断的中心协调器，扩散模型执行MLLM指令以实现高保真结果。

Result: 提出TableVisBench基准，包含800个挑战性实例和5个评估维度。实验显示ShowTable管道显著优于基线。

Conclusion: 实验证明，ShowTable管道在不同模型实例化下显著优于基线，突显了其有效的多模态推理、生成和错误纠正能力。

Abstract: While existing generation and unified models excel at general image generation, they struggle with tasks requiring deep reasoning, planning, and precise data-to-visual mapping abilities beyond general scenarios. To push beyond the existing limitations, we introduce a new and challenging task: creative table visualization, requiring the model to generate an infographic that faithfully and aesthetically visualizes the data from a given table. To address this challenge, we propose ShowTable, a pipeline that synergizes MLLMs with diffusion models via a progressive self-correcting process. The MLLM acts as the central orchestrator for reasoning the visual plan and judging visual errors to provide refined instructions, the diffusion execute the commands from MLLM, achieving high-fidelity results. To support this task and our pipeline, we introduce three automated data construction pipelines for training different modules. Furthermore, we introduce TableVisBench, a new benchmark with 800 challenging instances across 5 evaluation dimensions, to assess performance on this task. Experiments demonstrate that our pipeline, instantiated with different models, significantly outperforms baselines, highlighting its effective multi-modal reasoning, generation, and error correction capabilities.

</details>


### [171] [KlingAvatar 2.0 Technical Report](https://arxiv.org/abs/2512.13313)
*Kling Team,Jialu Chen,Yikang Ding,Zhixue Fang,Kun Gai,Yuan Gao,Kang He,Jingyun Hua,Boyuan Jiang,Mingming Lao,Xiaohan Li,Hui Liu,Jiwen Liu,Xiaoqiang Liu,Yuan Liu,Shun Lu,Yongsen Mao,Yingchao Shao,Huafeng Shi,Xiaoyu Shi,Peiqin Sun,Songlin Tang,Pengfei Wan,Chao Wang,Xuebo Wang,Haoxian Zhang,Yuanxing Zhang,Yan Zhou*

Main category: cs.CV

TL;DR: KlingAvatar 2.0 通过时空级联和多模态对齐机制，解决了长视频生成的效率和质量问题，提升了视觉和指令跟随效果。


<details>
  <summary>Details</summary>
Motivation: 现有模型在生成长时长高分辨率视频时存在效率低、时间漂移、质量下降和指令跟随弱的问题，亟需改进。

Method: 采用时空级联框架，首先生成低分辨率关键帧捕捉全局语义和运动，然后通过首尾帧策略细化为高分辨率、时间连贯的子片段。引入由三个模态特定LLM专家组成的Co-Reasoning Director和Negative Director，增强跨模态指令融合和对齐。

Result: 实验表明，该模型在高效、多模态对齐的长时长高分辨率视频生成中表现出色，提升了视觉清晰度、唇齿同步准确性、身份保持和多模态指令跟随的连贯性。

Conclusion: KlingAvatar 2.0 通过时空级联框架和多模态对齐机制，有效解决了长时长高分辨率视频生成的效率和质量问题，实现了视觉清晰度、唇齿同步、身份保持和多模态指令跟随的显著提升。

Abstract: Avatar video generation models have achieved remarkable progress in recent years. However, prior work exhibits limited efficiency in generating long-duration high-resolution videos, suffering from temporal drifting, quality degradation, and weak prompt following as video length increases. To address these challenges, we propose KlingAvatar 2.0, a spatio-temporal cascade framework that performs upscaling in both spatial resolution and temporal dimension. The framework first generates low-resolution blueprint video keyframes that capture global semantics and motion, and then refines them into high-resolution, temporally coherent sub-clips using a first-last frame strategy, while retaining smooth temporal transitions in long-form videos. To enhance cross-modal instruction fusion and alignment in extended videos, we introduce a Co-Reasoning Director composed of three modality-specific large language model (LLM) experts. These experts reason about modality priorities and infer underlying user intent, converting inputs into detailed storylines through multi-turn dialogue. A Negative Director further refines negative prompts to improve instruction alignment. Building on these components, we extend the framework to support ID-specific multi-character control. Extensive experiments demonstrate that our model effectively addresses the challenges of efficient, multimodally aligned long-form high-resolution video generation, delivering enhanced visual clarity, realistic lip-teeth rendering with accurate lip synchronization, strong identity preservation, and coherent multimodal instruction following.

</details>


### [172] [Automated User Identification from Facial Thermograms with Siamese Networks](https://arxiv.org/abs/2512.13361)
*Elizaveta Prozorova,Anton Konev,Vladimir Faerman*

Main category: cs.CV

TL;DR: 热成像结合Siamese神经网络在面部生物识别中表现良好，混合系统效果更佳。


<details>
  <summary>Details</summary>
Motivation: 探索热成像技术在生物识别中的应用潜力，解决单一模态的局限性。

Method: 使用Siamese神经网络对热成像面部图谱进行自动识别，并在自建数据集上测试不同红外光谱范围（NIR、SWIR、MWIR、LWIR）的性能。

Result: 提出的方法在实验中达到约80%的准确率，混合系统表现更优。

Conclusion: 热成像技术结合Siamese神经网络在生物识别系统中展现出潜力，尤其是结合可见光与红外光谱的混合系统能提升识别可靠性。

Abstract: The article analyzes the use of thermal imaging technologies for biometric identification based on facial thermograms. It presents a comparative analysis of infrared spectral ranges (NIR, SWIR, MWIR, and LWIR). The paper also defines key requirements for thermal cameras used in biometric systems, including sensor resolution, thermal sensitivity, and a frame rate of at least 30 Hz. Siamese neural networks are proposed as an effective approach for automating the identification process. In experiments conducted on a proprietary dataset, the proposed method achieved an accuracy of approximately 80%. The study also examines the potential of hybrid systems that combine visible and infrared spectra to overcome the limitations of individual modalities. The results indicate that thermal imaging is a promising technology for developing reliable security systems.

</details>


### [173] [Unlocking Generalization in Polyp Segmentation with DINO Self-Attention "keys"](https://arxiv.org/abs/2512.13376)
*Carla Monteiro,Valentina Corbetta,Regina Beets-Tan,Luís F. Teixeira,Wilson Silva*

Main category: cs.CV

TL;DR: 利用DINO自注意力关键特征和卷积解码器，简化架构并提升息肉分割的泛化性能，在数据稀缺场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习方法在泛化能力和数据受限场景下表现不佳，且依赖复杂架构。本文旨在通过自注意力机制提升泛化性和简化架构。

Method: 采用DINO自注意力模块的关键特征，结合卷积解码器预测息肉掩码，避免了复杂的任务特定架构。

Result: 在多中心数据集上验证，该框架在领域泛化（DG）和极端单领域泛化（ESDG）协议下达到SOTA性能，超越nnU-Net和UM-Net等模型。

Conclusion: 该论文提出的框架通过利用DINO自注意力机制的关键特征，结合简单的卷积解码器，显著提升了息肉分割的性能和泛化能力，尤其在数据稀缺和挑战性场景下表现优异。

Abstract: Automatic polyp segmentation is crucial for improving the clinical identification of colorectal cancer (CRC). While Deep Learning (DL) techniques have been extensively researched for this problem, current methods frequently struggle with generalization, particularly in data-constrained or challenging settings. Moreover, many existing polyp segmentation methods rely on complex, task-specific architectures. To address these limitations, we present a framework that leverages the intrinsic robustness of DINO self-attention "key" features for robust segmentation. Unlike traditional methods that extract tokens from the deepest layers of the Vision Transformer (ViT), our approach leverages the key features of the self-attention module with a simple convolutional decoder to predict polyp masks, resulting in enhanced performance and better generalizability. We validate our approach using a multi-center dataset under two rigorous protocols: Domain Generalization (DG) and Extreme Single Domain Generalization (ESDG). Our results, supported by a comprehensive statistical analysis, demonstrate that this pipeline achieves state-of-the-art (SOTA) performance, significantly enhancing generalization, particularly in data-scarce and challenging scenarios. While avoiding a polyp-specific architecture, we surpass well-established models like nnU-Net and UM-Net. Additionally, we provide a systematic benchmark of the DINO framework's evolution, quantifying the specific impact of architectural advancements on downstream polyp segmentation performance.

</details>


### [174] [Beyond the Visible: Disocclusion-Aware Editing via Proxy Dynamic Graphs](https://arxiv.org/abs/2512.13392)
*Anran Qi,Changjian Li,Adrien Bousseau,Niloy J. Mitra*

Main category: cs.CV

TL;DR: 提出了一种结合用户控制与生成控制的图像到视频生成方法，通过代理动态图和扩散模型实现可控运动与外观合成。


<details>
  <summary>Details</summary>
Motivation: 解决当前图像到视频生成方法在生成可预测、关节运动及用户指定遮挡区域内容时的不足。

Method: 提出了一种轻量级、用户可编辑的代理动态图（PDG）来驱动部分运动，同时利用冻结扩散先验合成外观。训练自由的流程中，用户通过PDG标注和调整姿态，生成密集运动流以引导扩散模型作为运动引导着色器。

Result: 在关节物体、家具、车辆和可变形物体的图像到短视频生成中，展示了相对于现有技术的明显优势。

Conclusion: 该方法通过分离运动规范与外观合成，结合用户可编辑的代理动态图和冻结扩散先验，实现了对图像到视频生成的可控性，尤其在最终帧的遮挡区域提供了用户指定的内容。

Abstract: We address image-to-video generation with explicit user control over the final frame's disoccluded regions. Current image-to-video pipelines produce plausible motion but struggle to generate predictable, articulated motions while enforcing user-specified content in newly revealed areas. Our key idea is to separate motion specification from appearance synthesis: we introduce a lightweight, user-editable Proxy Dynamic Graph (PDG) that deterministically yet approximately drives part motion, while a frozen diffusion prior is used to synthesize plausible appearance that follows that motion. In our training-free pipeline, the user loosely annotates and reposes a PDG, from which we compute a dense motion flow to leverage diffusion as a motion-guided shader. We then let the user edit appearance in the disoccluded areas of the image, and exploit the visibility information encoded by the PDG to perform a latent-space composite that reconciles motion with user intent in these areas. This design yields controllable articulation and user control over disocclusions without fine-tuning. We demonstrate clear advantages against state-of-the-art alternatives towards images turned into short videos of articulated objects, furniture, vehicles, and deformables. Our method mixes generative control, in the form of loose pose and structure, with predictable controls, in the form of appearance specification in the final frame in the disoccluded regions, unlocking a new image-to-video workflow. Code will be released on acceptance. Project page: https://anranqi.github.io/beyondvisible.github.io/

</details>


### [175] [rNCA: Self-Repairing Segmentation Masks](https://arxiv.org/abs/2512.13397)
*Malte Silbernagel,Albert Alonso,Jens Petersen,Bulat Ibragimov,Marleen de Bruijne,Madeleine K. Wyburd*

Main category: cs.CV

TL;DR: NCA通过局部迭代更新修复分割掩码的拓扑错误，在视网膜血管和心肌分割任务中显著提升指标。


<details>
  <summary>Details</summary>
Motivation: 解决通用分割模型常产生的碎片化或不连贯输出问题，避免依赖手工细化规则或特定任务架构。

Method: 通过训练NCA在局部信息指导下进行迭代更新，学习目标形状的结构特性，逐步修复不连贯的区域和松散片段。

Result: 在视网膜血管分割中，Dice/clDice指标提升2-3%，Betti错误显著减少（β₀降低60%，β₁降低20%）；在心肌分割中，零样本设置下修复了61.5%的断裂案例，ASSD和HD分别降低19%和16%。

Conclusion: NCA作为一种有效的细化机制，能够修复分割掩码中的拓扑错误，展示了其在多种任务中的广泛适用性。

Abstract: Accurately predicting topologically correct masks remains a difficult task for general segmentation models, which often produce fragmented or disconnected outputs. Fixing these artifacts typically requires hand-crafted refinement rules or architectures specialized to a particular task. Here, we show that Neural Cellular Automata (NCA) can be directly re-purposed as an effective refinement mechanism, using local, iterative updates guided by image context to repair segmentation masks. By training on imperfect masks and ground truths, the automaton learns the structural properties of the target shape while relying solely on local information. When applied to coarse, globally predicted masks, the learned dynamics progressively reconnect broken regions, prune loose fragments and converge towards stable, topologically consistent results. We show how refinement NCA (rNCA) can be easily applied to repair common topological errors produced by different base segmentation models and tasks: for fragmented retinal vessels, it yields 2-3% gains in Dice/clDice and improves Betti errors, reducing $β_0$ errors by 60% and $β_1$ by 20%; for myocardium, it repairs 61.5% of broken cases in a zero-shot setting while lowering ASSD and HD by 19% and 16%, respectively. This showcases NCA as effective and broadly applicable refiners.

</details>


### [176] [USTM: Unified Spatial and Temporal Modeling for Continuous Sign Language Recognition](https://arxiv.org/abs/2512.13415)
*Ahmed Abul Hasanaath,Hamzah Luqman*

Main category: cs.CV

TL;DR: USTM框架通过Swin Transformer和TAPE结合，解决了连续手语识别中细粒度时空建模的难题，并在多个数据集上达到最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以捕捉细粒度的手部和面部线索，且无法建模长程时间依赖，因此需要更有效的时空建模方法。

Method: 提出了统一时空建模（USTM）框架，结合Swin Transformer骨干网络和轻量级时间适配器（TAPE），有效捕捉细粒度空间特征和长短期时间依赖。

Result: 在PHOENIX14、PHOENIX14T和CSL-Daily等基准数据集上，USTM实现了最先进的性能，优于RGB和多模态方法。

Conclusion: USTM框架在连续手语识别任务中表现出色，不仅优于基于RGB的方法，还与多模态和多流方法竞争，证明了其强大的时空建模能力。

Abstract: Continuous sign language recognition (CSLR) requires precise spatio-temporal modeling to accurately recognize sequences of gestures in videos. Existing frameworks often rely on CNN-based spatial backbones combined with temporal convolution or recurrent modules. These techniques fail in capturing fine-grained hand and facial cues and modeling long-range temporal dependencies. To address these limitations, we propose the Unified Spatio-Temporal Modeling (USTM) framework, a spatio-temporal encoder that effectively models complex patterns using a combination of a Swin Transformer backbone enhanced with lightweight temporal adapter with positional embeddings (TAPE). Our framework captures fine-grained spatial features alongside short and long-term temporal context, enabling robust sign language recognition from RGB videos without relying on multi-stream inputs or auxiliary modalities. Extensive experiments on benchmarked datasets including PHOENIX14, PHOENIX14T, and CSL-Daily demonstrate that USTM achieves state-of-the-art performance against RGB-based as well as multi-modal CSLR approaches, while maintaining competitive performance against multi-stream approaches. These results highlight the strength and efficacy of the USTM framework for CSLR. The code is available at https://github.com/gufranSabri/USTM

</details>


### [177] [Learning to Generate Cross-Task Unexploitable Examples](https://arxiv.org/abs/2512.13416)
*Haoxuan Qu,Qiuchi Xiang,Yujun Cai,Yirui Wu,Majid Mirmehdi,Hossein Rahmani,Jun Liu*

Main category: cs.CV

TL;DR: 提出MCT-UEG框架，通过元跨任务训练生成广泛不可利用的示例，提升隐私保护效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成广泛不可利用的示例方面存在局限性，影响实际应用。

Method: 设计了基于平坦最小值的元训练和测试方案，优化生成器以产生广泛不可利用的示例。

Result: 大量实验证明框架的有效性。

Conclusion: 提出的MCT-UEG框架通过元跨任务训练方案，有效生成了广泛不可利用的示例，显著提升了实际应用性。

Abstract: Unexploitable example generation aims to transform personal images into their unexploitable (unlearnable) versions before they are uploaded online, thereby preventing unauthorized exploitation of online personal images. Recently, this task has garnered significant research attention due to its critical relevance to personal data privacy. Yet, despite recent progress, existing methods for this task can still suffer from limited practical applicability, as they can fail to generate examples that are broadly unexploitable across different real-world computer vision tasks. To deal with this problem, in this work, we propose a novel Meta Cross-Task Unexploitable Example Generation (MCT-UEG) framework. At the core of our framework, to optimize the unexploitable example generator for effectively producing broadly unexploitable examples, we design a flat-minima-oriented meta training and testing scheme. Extensive experiments show the efficacy of our framework.

</details>


### [178] [RecTok: Reconstruction Distillation along Rectified Flow](https://arxiv.org/abs/2512.13421)
*Qingyu Shi,Size Wu,Jinbin Bai,Kaidong Yu,Yujing Wang,Yunhai Tong,Xiangtai Li,Xuelong Li*

Main category: cs.CV

TL;DR: RecTok通过流语义蒸馏和重建对齐蒸馏，解决了高维视觉标记器的性能问题，在图像重建和生成质量上表现卓越。


<details>
  <summary>Details</summary>
Motivation: 高维视觉标记器在生成质量上表现不佳，限制了现有方法在低维潜在空间的应用。

Method: 提出了RecTok，通过流语义蒸馏和重建对齐蒸馏两种关键创新，将视觉基础模型（VFM）的语义信息蒸馏到流匹配的前向流轨迹中，并引入掩码特征重建损失进一步增强语义。

Result: RecTok在gFID-50K上实现了最先进的结果，同时保持了语义丰富的潜在空间结构，且随着潜在维度的增加，性能持续提升。

Conclusion: RecTok通过流语义蒸馏和重建对齐蒸馏的创新方法，克服了高维视觉标记器的限制，实现了卓越的图像重建、生成质量和判别性能，并在gFID-50K上取得了最先进的结果。

Abstract: Visual tokenizers play a crucial role in diffusion models. The dimensionality of latent space governs both reconstruction fidelity and the semantic expressiveness of the latent feature. However, a fundamental trade-off is inherent between dimensionality and generation quality, constraining existing methods to low-dimensional latent spaces. Although recent works have leveraged vision foundation models to enrich the semantics of visual tokenizers and accelerate convergence, high-dimensional tokenizers still underperform their low-dimensional counterparts. In this work, we propose RecTok, which overcomes the limitations of high-dimensional visual tokenizers through two key innovations: flow semantic distillation and reconstruction--alignment distillation. Our key insight is to make the forward flow in flow matching semantically rich, which serves as the training space of diffusion transformers, rather than focusing on the latent space as in previous works. Specifically, our method distills the semantic information in VFMs into the forward flow trajectories in flow matching. And we further enhance the semantics by introducing a masked feature reconstruction loss. Our RecTok achieves superior image reconstruction, generation quality, and discriminative performance. It achieves state-of-the-art results on the gFID-50K under both with and without classifier-free guidance settings, while maintaining a semantically rich latent space structure. Furthermore, as the latent dimensionality increases, we observe consistent improvements. Code and model are available at https://shi-qingyu.github.io/rectok.github.io.

</details>


### [179] [MineTheGap: Automatic Mining of Biases in Text-to-Image Models](https://arxiv.org/abs/2512.13427)
*Noa Cohen,Nurit Spingarn-Eliezer,Inbar Huberman-Spiegelglas,Tomer Michaeli*

Main category: cs.CV

TL;DR: MineTheGap是一种自动挖掘TTI模型偏见提示的方法，通过遗传算法和偏见评分优化提示，减少模型偏见。


<details>
  <summary>Details</summary>
Motivation: TTI模型在处理模糊文本提示时表现出偏见，可能对社会和用户体验产生负面影响，因此需要自动挖掘这些偏见的方法。

Method: 利用遗传算法迭代优化提示池，寻找暴露偏见的提示，并通过比较生成图像分布与LLM生成文本分布的差异来计算偏见评分。

Result: MineTheGap方法能够有效识别和量化TTI模型的偏见，验证了偏见评分的有效性。

Conclusion: MineTheGap方法通过遗传算法自动挖掘导致TTI模型生成偏见的提示，并通过新颖的偏见评分量化偏见的严重性，为减少模型偏见提供了有效工具。

Abstract: Text-to-Image (TTI) models generate images based on text prompts, which often leave certain aspects of the desired image ambiguous. When faced with these ambiguities, TTI models have been shown to exhibit biases in their interpretations. These biases can have societal impacts, e.g., when showing only a certain race for a stated occupation. They can also affect user experience when creating redundancy within a set of generated images instead of spanning diverse possibilities. Here, we introduce MineTheGap - a method for automatically mining prompts that cause a TTI model to generate biased outputs. Our method goes beyond merely detecting bias for a given prompt. Rather, it leverages a genetic algorithm to iteratively refine a pool of prompts, seeking for those that expose biases. This optimization process is driven by a novel bias score, which ranks biases according to their severity, as we validate on a dataset with known biases. For a given prompt, this score is obtained by comparing the distribution of generated images to the distribution of LLM-generated texts that constitute variations on the prompt. Code and examples are available on the project's webpage.

</details>


### [180] [A Domain-Adapted Lightweight Ensemble for Resource-Efficient Few-Shot Plant Disease Classification](https://arxiv.org/abs/2512.13428)
*Anika Islam,Tasfia Tahsin,Zaarin Anjum,Md. Bakhtiar Hasan,Md. Hasanul Kabir*

Main category: cs.CV

TL;DR: 轻量级少样本学习框架结合MobileNet和Bi-LSTM，在数据稀缺环境中高效识别植物叶片病害，实验室和实地数据均表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习方法依赖大量标注数据和计算密集型模型，不适用于数据稀缺和资源受限的环境，因此需要开发轻量级且高效的解决方案。

Method: 采用域适应的MobileNetV2和MobileNetV3模型作为特征提取器，结合特征融合技术生成鲁棒特征表示，并通过带有注意力机制的Bi-LSTM分类器进行分类。

Result: 在PlantVillage数据集上达到98.23%的准确率（15-shot），接近SOTA的99.98%；在Dhan Shomadhan数据集上达到69.28%（15-shot），并在复杂背景下表现稳健。模型大小约40 MB，计算复杂度约1.12 GFLOPs。

Conclusion: 该研究提出了一种轻量级且高效的少样本学习框架，结合了MobileNetV2和MobileNetV3作为特征提取器，并通过特征融合和Bi-LSTM分类器增强注意力机制，在数据稀缺和资源受限的环境中实现了高精度的植物叶片病害识别。

Abstract: Accurate and timely identification of plant leaf diseases is essential for resilient and sustainable agriculture, yet most deep learning approaches rely on large annotated datasets and computationally intensive models that are unsuitable for data-scarce and resource-constrained environments. To address these challenges we present a few-shot learning approach within a lightweight yet efficient framework that combines domain-adapted MobileNetV2 and MobileNetV3 models as feature extractors, along with a feature fusion technique to generate robust feature representation. For the classification task, the fused features are passed through a Bi-LSTM classifier enhanced with attention mechanisms to capture sequential dependencies and focus on the most relevant features, thereby achieving optimal classification performance even in complex, real-world environments with noisy or cluttered backgrounds. The proposed framework was evaluated across multiple experimental setups, including both laboratory-controlled and field-captured datasets. On tomato leaf diseases from the PlantVillage dataset, it consistently improved performance across 1 to 15 shot scenarios, reaching 98.23+-0.33% at 15 shot, closely approaching the 99.98% SOTA benchmark achieved by a Transductive LSTM with attention, while remaining lightweight and mobile-friendly. Under real-world conditions using field images from the Dhan Shomadhan dataset, it maintained robust performance, reaching 69.28+-1.49% at 15-shot and demonstrating strong resilience to complex backgrounds. Notably, it also outperformed the previous SOTA accuracy of 96.0% on six diseases from PlantVillage, achieving 99.72% with only 15-shot learning. With a compact model size of approximately 40 MB and inference complexity of approximately 1.12 GFLOPs, this work establishes a scalable, mobile-ready foundation for precise plant disease diagnostics in data-scarce regions.

</details>


### [181] [IMILIA: interpretable multiple instance learning for inflammation prediction in IBD from H&E whole slide images](https://arxiv.org/abs/2512.13440)
*Thalyssa Baiocco-Rodrigues,Antoine Olivier,Reda Belbahri,Thomas Duboudin,Pierre-Antoine Bannier,Benjamin Adjadj,Katharina Von Loga,Nathan Noiry,Maxime Touzot,Hector Roux de Bezieux*

Main category: cs.CV

TL;DR: IMILIA是一个用于IBD炎症预测和解释的端到端框架，结合MIL模型和可解释性模块，在多个数据集中表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着IBD治疗目标转向组织学缓解，准确评估微观炎症对疾病活动和治疗反应的评估变得至关重要。

Method: IMILIA是一个端到端框架，包含炎症预测模块（基于多实例学习模型）和可解释性模块（HistoPLUS用于细胞实例检测、分割和分类；EpiSeg用于上皮分割）。

Result: IMILIA在发现队列中ROC-AUC为0.83，在两个外部验证队列中分别为0.99和0.84。可解释性模块显示高预测分数区域免疫细胞密度增加，低分数区域主要为正常上皮细胞。

Conclusion: IMILIA框架在预测炎症存在和自动化计算组织区域标记方面表现出色，其预测模块和可解释性模块的结合为IBD的微观炎症评估提供了有力工具。

Abstract: As the therapeutic target for Inflammatory Bowel Disease (IBD) shifts toward histologic remission, the accurate assessment of microscopic inflammation has become increasingly central for evaluating disease activity and response to treatment. In this work, we introduce IMILIA (Interpretable Multiple Instance Learning for Inflammation Analysis), an end-to-end framework designed for the prediction of inflammation presence in IBD digitized slides stained with hematoxylin and eosin (H&E), followed by the automated computation of markers characterizing tissue regions driving the predictions. IMILIA is composed of an inflammation prediction module, consisting of a Multiple Instance Learning (MIL) model, and an interpretability module, divided in two blocks: HistoPLUS, for cell instance detection, segmentation and classification; and EpiSeg, for epithelium segmentation. IMILIA achieves a cross-validation ROC-AUC of 0.83 on the discovery cohort, and a ROC-AUC of 0.99 and 0.84 on two external validation cohorts. The interpretability module yields biologically consistent insights: tiles with higher predicted scores show increased densities of immune cells (lymphocytes, plasmocytes, neutrophils and eosinophils), whereas lower-scored tiles predominantly contain normal epithelial cells. Notably, these patterns were consistent across all datasets. Code and models to partially replicate the results on the public IBDColEpi dataset can be found at https://github.com/owkin/imilia.

</details>


### [182] [Test-Time Modification: Inverse Domain Transformation for Robust Perception](https://arxiv.org/abs/2512.13454)
*Arpit Jadon,Joshua Niemeijer,Yuki M. Asano*

Main category: cs.CV

TL;DR: 利用扩散模型在测试时将目标图像映射回源分布，显著提升域泛化任务性能，无需大规模数据生成。


<details>
  <summary>Details</summary>
Motivation: 生成基础模型虽能用于训练数据增强，但合成全面的目标域变体仍缓慢、昂贵且不完整，因此寻求替代方案。

Method: 提出一种利用扩散模型在测试时将目标图像映射回源分布的方法，仅需源域描述，保留任务模型。

Result: 在真实到真实域泛化场景中，方法在BDD100K-Night、ImageNet-R和DarkZurich上分别实现了137%、68%和62%的相对增益。

Conclusion: 该方法通过在测试时使用扩散模型将目标图像映射回源分布，显著提升了分割、检测和分类任务在未知目标分布下的性能，且无需大规模合成数据生成。

Abstract: Generative foundation models contain broad visual knowledge and can produce diverse image variations, making them particularly promising for advancing domain generalization tasks. While they can be used for training data augmentation, synthesizing comprehensive target-domain variations remains slow, expensive, and incomplete. We propose an alternative: using diffusion models at test time to map target images back to the source distribution where the downstream model was trained. This approach requires only a source domain description, preserves the task model, and eliminates large-scale synthetic data generation. We demonstrate consistent improvements across segmentation, detection, and classification tasks under challenging environmental shifts in real-to-real domain generalization scenarios with unknown target distributions. Our analysis spans multiple generative and downstream models, including an ensemble variant for enhanced robustness. The method achieves substantial relative gains: 137% on BDD100K-Night, 68% on ImageNet-R, and 62% on DarkZurich.

</details>


### [183] [PoseAnything: Universal Pose-guided Video Generation with Part-aware Temporal Coherence](https://arxiv.org/abs/2512.13465)
*Ruiyan Wang,Teng Hu,Kaihui Huang,Zihan Su,Ran Yi,Lizhuang Ma*

Main category: cs.CV

TL;DR: PoseAnything 是一个通用姿势引导视频生成框架，支持人类和非人类角色，通过创新模块实现运动一致性和独立相机控制，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前姿势引导视频生成方法仅适用于人类姿势，泛化能力差，无法处理非人类角色。

Method: 提出了 Part-aware Temporal Coherence Module 和 Subject and Camera Motion Decoupled CFG 两种创新方法，分别用于增强运动一致性和独立控制相机运动。

Result: 实验表明，PoseAnything 在效果和泛化能力上均显著优于现有方法。

Conclusion: PoseAnything 是一个通用的姿势引导视频生成框架，能够处理人类和非人类角色，支持任意骨骼输入，显著优于现有方法。

Abstract: Pose-guided video generation refers to controlling the motion of subjects in generated video through a sequence of poses. It enables precise control over subject motion and has important applications in animation. However, current pose-guided video generation methods are limited to accepting only human poses as input, thus generalizing poorly to pose of other subjects. To address this issue, we propose PoseAnything, the first universal pose-guided video generation framework capable of handling both human and non-human characters, supporting arbitrary skeletal inputs. To enhance consistency preservation during motion, we introduce Part-aware Temporal Coherence Module, which divides the subject into different parts, establishes part correspondences, and computes cross-attention between corresponding parts across frames to achieve fine-grained part-level consistency. Additionally, we propose Subject and Camera Motion Decoupled CFG, a novel guidance strategy that, for the first time, enables independent camera movement control in pose-guided video generation, by separately injecting subject and camera motion control information into the positive and negative anchors of CFG. Furthermore, we present XPose, a high-quality public dataset containing 50,000 non-human pose-video pairs, along with an automated pipeline for annotation and filtering. Extensive experiments demonstrate that Pose-Anything significantly outperforms state-of-the-art methods in both effectiveness and generalization.

</details>


### [184] [Transform Trained Transformer: Accelerating Naive 4K Video Generation Over 10$\times$](https://arxiv.org/abs/2512.13492)
*Jiangning Zhang,Junwei Zhu,Teng Hu,Yabiao Wang,Donghao Luo,Weijian Cao,Zhenye Gan,Xiaobin Hu,Zhucun Xue,Chengjie Wang*

Main category: cs.CV

TL;DR: T3-Video通过优化Transformer前向逻辑，高效生成高质量4K视频，性能提升显著且计算加速10倍。


<details>
  <summary>Details</summary>
Motivation: 解决4K视频生成中因全注意力机制导致的二次计算爆炸问题，平衡效率与质量。

Method: 提出T3（Transform Trained Transformer）策略，引入多尺度权重共享窗口注意力机制和层次化分块设计，优化前向逻辑。

Result: 在4K-VBench上，T3-Video性能提升（+4.29 VQA和+0.08 VTC），且加速4K视频生成超过10倍。

Conclusion: T3-Video通过创新的Transformer改造策略，显著提升了4K视频生成的效率和质量，同时保持了预训练模型的核心架构。

Abstract: Native 4K (2160$\times$3840) video generation remains a critical challenge due to the quadratic computational explosion of full-attention as spatiotemporal resolution increases, making it difficult for models to strike a balance between efficiency and quality. This paper proposes a novel Transformer retrofit strategy termed $\textbf{T3}$ ($\textbf{T}$ransform $\textbf{T}$rained $\textbf{T}$ransformer) that, without altering the core architecture of full-attention pretrained models, significantly reduces compute requirements by optimizing their forward logic. Specifically, $\textbf{T3-Video}$ introduces a multi-scale weight-sharing window attention mechanism and, via hierarchical blocking together with an axis-preserving full-attention design, can effect an "attention pattern" transformation of a pretrained model using only modest compute and data. Results on 4K-VBench show that $\textbf{T3-Video}$ substantially outperforms existing approaches: while delivering performance improvements (+4.29$\uparrow$ VQA and +0.08$\uparrow$ VTC), it accelerates native 4K video generation by more than 10$\times$. Project page at https://zhangzjn.github.io/projects/T3-Video

</details>


### [185] [Soul: Breathe Life into Digital Human for High-fidelity Long-term Multimodal Animation](https://arxiv.org/abs/2512.13495)
*Jiangning Zhang,Junwei Zhu,Zhenye Gan,Donghao Luo,Chuming Lin,Feifan Xu,Xu Peng,Jianlong Hu,Yuansen Liu,Yijia Hong,Weijian Cao,Han Feng,Xu Chen,Chencan Fu,Keke He,Xiaobin Hu,Chengjie Wang*

Main category: cs.CV

TL;DR: Soul是一个多模态驱动的框架，用于从单帧肖像、文本和音频生成高保真数字人动画，显著优于现有模型，适用于虚拟主播和电影制作。


<details>
  <summary>Details</summary>
Motivation: 解决高保真长期数字人动画的数据稀缺问题，并生成语义连贯的视频。

Method: 基于Wan2.2-5B主干，集成了音频注入层、多种训练策略和阈值感知码本替换，以确保长期生成一致性。同时，采用步长/CFG蒸馏和轻量级VAE优化推理效率。

Result: 构建了Soul-1M数据集和Soul-Bench评估基准，模型在推理效率上实现了11.4倍的加速且质量损失可忽略不计。

Conclusion: Soul框架在视频质量、视频-文本对齐、身份保持和唇同步准确性方面显著优于当前领先的开源和商业模型，展示了在虚拟主播和电影制作等实际场景中的广泛应用潜力。

Abstract: We propose a multimodal-driven framework for high-fidelity long-term digital human animation termed $\textbf{Soul}$, which generates semantically coherent videos from a single-frame portrait image, text prompts, and audio, achieving precise lip synchronization, vivid facial expressions, and robust identity preservation. We construct Soul-1M, containing 1 million finely annotated samples with a precise automated annotation pipeline (covering portrait, upper-body, full-body, and multi-person scenes) to mitigate data scarcity, and we carefully curate Soul-Bench for comprehensive and fair evaluation of audio-/text-guided animation methods. The model is built on the Wan2.2-5B backbone, integrating audio-injection layers and multiple training strategies together with threshold-aware codebook replacement to ensure long-term generation consistency. Meanwhile, step/CFG distillation and a lightweight VAE are used to optimize inference efficiency, achieving an 11.4$\times$ speedup with negligible quality loss. Extensive experiments show that Soul significantly outperforms current leading open-source and commercial models on video quality, video-text alignment, identity preservation, and lip-synchronization accuracy, demonstrating broad applicability in real-world scenarios such as virtual anchors and film production. Project page at https://zhangzjn.github.io/projects/Soul/

</details>


### [186] [Seedance 1.5 pro: A Native Audio-Visual Joint Generation Foundation Model](https://arxiv.org/abs/2512.13507)
*Siyan Chen,Yanfei Chen,Ying Chen,Zhuo Chen,Feng Cheng,Xuyan Chi,Jian Cong,Qinpeng Cui,Qide Dong,Junliang Fan,Jing Fang,Zetao Fang,Chengjian Feng,Han Feng,Mingyuan Gao,Yu Gao,Qiushan Guo,Boyang Hao,Qingkai Hao,Bibo He,Qian He,Tuyen Hoang,Ruoqing Hu,Xi Hu,Weilin Huang,Zhaoyang Huang,Zhongyi Huang,Siqi Jiang,Wei Jiang,Yunpu Jiang,Zhuo Jiang,Ashley Kim,Jianan Kong,Zhichao Lai,Shanshan Lao,Ai Li,Feiya Li,Gen Li,Huixia Li,JiaShi Li,Liang Li,Ming Li,Tao Li,Xian Li,Xiaojie Li,Xiaoyang Li,Xingxing Li,Yameng Li,Yifu Li,Yiying Li,Chao Liang,Ying Liang,Zhiqiang Liang,Wang Liao,Yalin Liao,Heng Lin,Kengyu Lin,Shanchuan Lin,Xi Lin,Zhijie Lin,Feng Ling,Fangfang Liu,Gaohong Liu,Jiawei Liu,Jie Liu,Shouda Liu,Shu Liu,Sichao Liu,Songwei Liu,Xin Liu,Xue Liu,Yibo Liu,Zikun Liu,Zuxi Liu,Junlin Lyu,Lecheng Lyu,Qian Lyu,Han Mu,Xiaonan Nie,Jingzhe Ning,Xitong Pan,Yanghua Peng,Lianke Qin,Xueqiong Qu,Yuxi Ren,Yuchen Shen,Guang Shi,Lei Shi,Yan Song,Yinglong Song,Fan Sun,Li Sun,Renfei Sun,Zeyu Sun,Wenjing Tang,Zirui Tao,Feng Wang,Furui Wang,Jinran Wang,Junkai Wang,Ke Wang,Kexin Wang,Qingyi Wang,Rui Wang,Sen Wang,Shuai Wang,Tingru Wang,Weichen Wang,Xin Wang,Yanhui Wang,Yue Wang,Yuping Wang,Yuxuan Wang,Ziyu Wang,Guoqiang Wei,Wanru Wei,Di Wu,Guohong Wu,Hanjie Wu,Jian Wu,Jie Wu,Ruolan Wu,Xinglong Wu,Yonghui Wu,Ruiqi Xia,Liang Xiang,Fei Xiao,XueFeng Xiao,Pan Xie,Shuangyi Xie,Shuang Xu,Jinlan Xue,Bangbang Yang,Ceyuan Yang,Jiaqi Yang,Runkai Yang,Tao Yang,Yang Yang,Yihang Yang,ZhiXian Yang,Ziyan Yang,Yifan Yao,Zilyu Ye,Bowen Yu,Chujie Yuan,Linxiao Yuan,Sichun Zeng,Weihong Zeng,Xuejiao Zeng,Yan Zeng,Chuntao Zhang,Heng Zhang,Jingjie Zhang,Kuo Zhang,Liang Zhang,Liying Zhang,Manlin Zhang,Ting Zhang,Weida Zhang,Xiaohe Zhang,Xinyan Zhang,Yan Zhang,Yuan Zhang,Zixiang Zhang,Fengxuan Zhao,Huating Zhao,Yang Zhao,Hao Zheng,Jianbin Zheng,Xiaozheng Zheng,Yangyang Zheng,Yijie Zheng,Jiexin Zhou,Kuan Zhu,Shenhan Zhu,Wenjia Zhu,Benhui Zou,Feilong Zuo*

Main category: cs.CV

TL;DR: Seedance 1.5 pro是一款先进的音频-视频生成模型，通过双分支扩散变换器架构和优化技术，实现了高质量的同步生成和快速推理。


<details>
  <summary>Details</summary>
Motivation: 推动音频-视频生成的统一化，提升生成质量和同步性，以满足专业内容创作的需求。

Method: 采用双分支扩散变换器架构，结合跨模态联合模块和多阶段数据管道，并通过监督微调（SFT）和基于人类反馈的强化学习（RLHF）进行优化。

Result: 实现了卓越的音频-视频同步和生成质量，推理速度提升超过10倍，支持多语言和方言的唇形同步等功能。

Conclusion: Seedance 1.5 pro通过其先进的架构和优化技术，成为专业级音频-视频生成领域的强大工具，支持多语言和方言的唇形同步，动态电影级摄像机控制，以及增强的叙事连贯性。

Abstract: Recent strides in video generation have paved the way for unified audio-visual generation. In this work, we present Seedance 1.5 pro, a foundational model engineered specifically for native, joint audio-video generation. Leveraging a dual-branch Diffusion Transformer architecture, the model integrates a cross-modal joint module with a specialized multi-stage data pipeline, achieving exceptional audio-visual synchronization and superior generation quality. To ensure practical utility, we implement meticulous post-training optimizations, including Supervised Fine-Tuning (SFT) on high-quality datasets and Reinforcement Learning from Human Feedback (RLHF) with multi-dimensional reward models. Furthermore, we introduce an acceleration framework that boosts inference speed by over 10X. Seedance 1.5 pro distinguishes itself through precise multilingual and dialect lip-syncing, dynamic cinematic camera control, and enhanced narrative coherence, positioning it as a robust engine for professional-grade content creation. Seedance 1.5 pro is now accessible on Volcano Engine at https://console.volcengine.com/ark/region:ark+cn-beijing/experience/vision?type=GenVideo.

</details>


### [187] [TARA: Simple and Efficient Time Aware Retrieval Adaptation of MLLMs for Video Understanding](https://arxiv.org/abs/2512.13511)
*Piyush Bagad,Andrew Zisserman*

Main category: cs.CV

TL;DR: TARA是一种无需视频数据的时间感知视频-文本嵌入模型，在多个任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 构建一个通用的时间感知视频-文本嵌入模型，以提升视频检索的准确性和多样性。

Method: 提出TARA（Time Aware Retrieval Adaptation）方法，通过调整多模态大型语言模型（MLLMs）来构建时间感知的视频-文本嵌入模型，且无需使用任何视频数据。

Result: TARA在时间感知检索基准测试中超越现有所有视频-文本模型，同时在标准基准测试中表现优异，还在否定感知、动词和副词理解等任务中达到最先进水平。

Conclusion: TARA模型不仅在时间感知检索方面表现优异，还在否定感知、动词和副词理解等多个方面展现出卓越性能，成为一款强大且多功能的视频-文本嵌入模型。

Abstract: Our objective is to build a general time-aware video-text embedding model for retrieval. To that end, we propose a simple and efficient recipe, dubbed TARA (Time Aware Retrieval Adaptation), to adapt Multimodal LLMs (MLLMs) to a time-aware video-text embedding model without using any video data at all. For evaluating time-awareness in retrieval, we propose a new benchmark with temporally opposite (chiral) actions as hard negatives and curated splits for chiral and non-chiral actions. We show that TARA outperforms all existing video-text models on this chiral benchmark while also achieving strong results on standard benchmarks. Furthermore, we discover additional benefits of TARA beyond time-awareness: (i) TARA embeddings are negation-aware as shown in NegBench benchmark that evaluates negation in video retrieval, (ii) TARA achieves state of the art performance on verb and adverb understanding in videos. Overall, TARA yields a strong, versatile, time-aware video-text embedding model with state of the art zero-shot performance.

</details>


### [188] [Pancakes: Consistent Multi-Protocol Image Segmentation Across Biomedical Domains](https://arxiv.org/abs/2512.13534)
*Marianne Rakic,Siyu Gai,Etienne Chollet,John V. Guttag,Adrian V. Dalca*

Main category: cs.CV

TL;DR: Pancakes框架自动生成多标签分割图，支持多种协议且语义一致，实验表现优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 解决现有自动分割模型仅支持单一协议或需手动提示的局限性，实现多协议、语义一致的分割。

Method: 引入Pancakes框架，通过新问题公式化实现多协议自动分割，无需手动提示。

Result: 在七个数据集上的实验表明，Pancakes能生成多个语义一致的分割结果，显著优于现有模型。

Conclusion: Pancakes框架能够自动生成多标签分割图，支持多种分割协议，且在语义一致性上表现优异，显著优于现有基础模型。

Abstract: A single biomedical image can be meaningfully segmented in multiple ways, depending on the desired application. For instance, a brain MRI can be segmented according to tissue types, vascular territories, broad anatomical regions, fine-grained anatomy, or pathology, etc. Existing automatic segmentation models typically either (1) support only a single protocol, the one they were trained on, or (2) require labor-intensive manual prompting to specify the desired segmentation. We introduce Pancakes, a framework that, given a new image from a previously unseen domain, automatically generates multi-label segmentation maps for multiple plausible protocols, while maintaining semantic consistency across related images. Pancakes introduces a new problem formulation that is not currently attainable by existing foundation models. In a series of experiments on seven held-out datasets, we demonstrate that our model can significantly outperform existing foundation models in producing several plausible whole-image segmentations, that are semantically coherent across images.

</details>


### [189] [3D Human-Human Interaction Anomaly Detection](https://arxiv.org/abs/2512.13560)
*Shun Maeda,Chunzhi Gu,Koichiro Kamide,Katsuya Hotta,Shangce Gao,Chao Zhang*

Main category: cs.CV

TL;DR: 提出IADNet模型，通过时空动态捕捉人-人交互异常，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的单个人为中心的异常检测模型无法有效捕捉人-人交互中的复杂和非对称动态，导致检测准确性低。

Method: 提出了Interaction Anomaly Detection Network (IADNet)，包含Temporal Attention Sharing Module (TASM)和Distance-Based Relational Encoding Module (DREM)，用于捕捉交互的时空动态。

Result: 在多人运动基准测试中，IADNet表现优于现有的人为中心异常检测基线。

Conclusion: IADNet通过结合时间注意力共享模块和距离关系编码模块，显著提升了人-人交互异常检测的性能，优于现有的人为中心异常检测基线。

Abstract: Human-centric anomaly detection (AD) has been primarily studied to specify anomalous behaviors in a single person. However, as humans by nature tend to act in a collaborative manner, behavioral anomalies can also arise from human-human interactions. Detecting such anomalies using existing single-person AD models is prone to low accuracy, as these approaches are typically not designed to capture the complex and asymmetric dynamics of interactions. In this paper, we introduce a novel task, Human-Human Interaction Anomaly Detection (H2IAD), which aims to identify anomalous interactive behaviors within collaborative 3D human actions. To address H2IAD, we then propose Interaction Anomaly Detection Network (IADNet), which is formalized with a Temporal Attention Sharing Module (TASM). Specifically, in designing TASM, we share the encoded motion embeddings across both people such that collaborative motion correlations can be effectively synchronized. Moreover, we notice that in addition to temporal dynamics, human interactions are also characterized by spatial configurations between two people. We thus introduce a Distance-Based Relational Encoding Module (DREM) to better reflect social cues in H2IAD. The normalizing flow is eventually employed for anomaly scoring. Extensive experiments on human-human motion benchmarks demonstrate that IADNet outperforms existing Human-centric AD baselines in H2IAD.

</details>


### [190] [MMhops-R1: Multimodal Multi-hop Reasoning](https://arxiv.org/abs/2512.13573)
*Tao Zhang,Ziqi Zhang,Zongyang Ma,Yuxin Chen,Bing Li,Chunfeng Yuan,Guangting Wang,Fengyun Rao,Ying Shan,Weiming Hu*

Main category: cs.CV

TL;DR: 研究提出MMhops基准和MMhops-R1模型，通过动态规划和多模态知识整合提升多跳推理能力，实验证明其显著优于基线并具有强泛化性。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大型语言模型（MLLMs）主要局限于单步推理，缺乏评估和推动多跳推理能力的复杂基准。

Method: 提出了MMhops-R1，一种多模态检索增强生成（mRAG）框架，利用强化学习优化模型的动态推理路径规划、目标查询制定和多级信息合成能力。

Result: MMhops-R1在MMhops基准上显著优于基线模型，展示了动态规划和多模态知识整合对复杂推理的重要性，并在固定跳数推理任务中表现出强泛化能力。

Conclusion: 该研究提出了一个新的基准MMhops和一个强大的基线模型MMhops-R1，并计划发布相关代码、数据和权重以推动未来研究。

Abstract: The ability to perform multi-modal multi-hop reasoning by iteratively integrating information across various modalities and external knowledge is critical for addressing complex real-world challenges. However, existing Multi-modal Large Language Models (MLLMs) are predominantly limited to single-step reasoning, as existing benchmarks lack the complexity needed to evaluate and drive multi-hop abilities. To bridge this gap, we introduce MMhops, a novel, large-scale benchmark designed to systematically evaluate and foster multi-modal multi-hop reasoning. MMhops dataset comprises two challenging task formats, Bridging and Comparison, which necessitate that models dynamically construct complex reasoning chains by integrating external knowledge. To tackle the challenges posed by MMhops, we propose MMhops-R1, a novel multi-modal Retrieval-Augmented Generation (mRAG) framework for dynamic reasoning. Our framework utilizes reinforcement learning to optimize the model for autonomously planning reasoning paths, formulating targeted queries, and synthesizing multi-level information. Comprehensive experiments demonstrate that MMhops-R1 significantly outperforms strong baselines on MMhops, highlighting that dynamic planning and multi-modal knowledge integration are crucial for complex reasoning. Moreover, MMhops-R1 demonstrates strong generalization to tasks requiring fixed-hop reasoning, underscoring the robustness of our dynamic planning approach. In conclusion, our work contributes a challenging new benchmark and a powerful baseline model, and we will release the associated code, data, and weights to catalyze future research in this critical area.

</details>


### [191] [Lighting in Motion: Spatiotemporal HDR Lighting Estimation](https://arxiv.org/abs/2512.13597)
*Christophe Bolduc,Julien Philip,Li Ma,Mingming He,Paul Debevec,Jean-François Lalonde*

Main category: cs.CV

TL;DR: LiMo是一种基于扩散模型的时空照明估计方法，通过生成多曝光球体和引入几何条件，实现了高精度预测，成为该领域的SOTA。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在高频细节预测和准确照度估计上的不足，提升时空照明估计的精度和控制能力。

Method: 提出LiMo方法，利用扩散模型生成不同曝光下的镜像和漫反射球体，结合新的几何条件进行空间调节，并通过可微分渲染整合为单一HDRI图。

Result: LiMo在空间控制和预测精度上均达到最先进水平，通过实验验证了其方法的有效性。

Conclusion: LiMo通过结合扩散模型和几何条件，实现了在时空照明估计中的高精度预测和细节控制，成为该领域的先进方法。

Abstract: We present Lighting in Motion (LiMo), a diffusion-based approach to spatiotemporal lighting estimation. LiMo targets both realistic high-frequency detail prediction and accurate illuminance estimation. To account for both, we propose generating a set of mirrored and diffuse spheres at different exposures, based on their 3D positions in the input. Making use of diffusion priors, we fine-tune powerful existing diffusion models on a large-scale customized dataset of indoor and outdoor scenes, paired with spatiotemporal light probes. For accurate spatial conditioning, we demonstrate that depth alone is insufficient and we introduce a new geometric condition to provide the relative position of the scene to the target 3D position. Finally, we combine diffuse and mirror predictions at different exposures into a single HDRI map leveraging differentiable rendering. We thoroughly evaluate our method and design choices to establish LiMo as state-of-the-art for both spatial control and prediction accuracy.

</details>


### [192] [LongVie 2: Multimodal Controllable Ultra-Long Video World Model](https://arxiv.org/abs/2512.13604)
*Jianxiong Gao,Zhaoxi Chen,Xian Liu,Junhao Zhuang,Chengming Xu,Jianfeng Feng,Yu Qiao,Yanwei Fu,Chenyang Si,Ziwei Liu*

Main category: cs.CV

TL;DR: LongVie 2通过三阶段训练框架，显著提升视频世界模型的可控性、视觉质量和时间一致性，支持五分钟连续生成，是统一视频世界建模的重要进展。


<details>
  <summary>Details</summary>
Motivation: 构建基于预训练视频生成系统的视频世界模型是迈向通用时空智能的重要但具有挑战性的步骤，需要具备可控性、长期视觉质量和时间一致性三大特性。

Method: LongVie 2采用三阶段训练框架：多模态引导、退化感知训练和历史上下文引导，分别提升可控性、视觉质量和时间一致性。

Result: LongVie 2在长程可控性、时间一致性和视觉保真度方面达到最先进性能，支持长达五分钟的连续视频生成。

Conclusion: LongVie 2通过三阶段训练框架，显著提升了视频世界模型的可控性、长期视觉质量和时间一致性，支持长达五分钟的连续视频生成，标志着统一视频世界建模的重要进展。

Abstract: Building video world models upon pretrained video generation systems represents an important yet challenging step toward general spatiotemporal intelligence. A world model should possess three essential properties: controllability, long-term visual quality, and temporal consistency. To this end, we take a progressive approach-first enhancing controllability and then extending toward long-term, high-quality generation. We present LongVie 2, an end-to-end autoregressive framework trained in three stages: (1) Multi-modal guidance, which integrates dense and sparse control signals to provide implicit world-level supervision and improve controllability; (2) Degradation-aware training on the input frame, bridging the gap between training and long-term inference to maintain high visual quality; and (3) History-context guidance, which aligns contextual information across adjacent clips to ensure temporal consistency. We further introduce LongVGenBench, a comprehensive benchmark comprising 100 high-resolution one-minute videos covering diverse real-world and synthetic environments. Extensive experiments demonstrate that LongVie 2 achieves state-of-the-art performance in long-range controllability, temporal coherence, and visual fidelity, and supports continuous video generation lasting up to five minutes, marking a significant step toward unified video world modeling.

</details>


### [193] [DBT-DINO: Towards Foundation model based analysis of Digital Breast Tomosynthesis](https://arxiv.org/abs/2512.13608)
*Felix J. Dorfner,Manon A. Dorster,Ryan Connolly,Oscar Gentilhomme,Edward Gibbs,Steven Graham,Seth Wander,Thomas Schultz,Manisha Bahl,Dania Daye,Albert E. Kim,Christopher P. Bridge*

Main category: cs.CV

TL;DR: 开发了首个DBT基础模型DBT-DINO，在乳腺密度和癌症风险预测中表现优异，但病灶检测任务需进一步优化。


<details>
  <summary>Details</summary>
Motivation: 尽管DBT用于乳腺癌筛查，但目前尚无针对该三维成像模式的基础模型，因此开发并评估DBT-DINO模型及其领域特定预训练的影响。

Method: 采用DINOv2方法对487,975个DBT体积的2500万张2D切片进行自监督预训练，评估了三个下游任务：乳腺密度分类、5年乳腺癌风险预测和病灶检测。

Result: DBT-DINO在乳腺密度分类（准确率0.79）和癌症风险预测（AUROC 0.78）中优于基线模型，但在病灶检测中表现不一（平均灵敏度0.62）。

Conclusion: DBT-DINO是首个针对数字乳腺断层合成（DBT）的基础模型，在乳腺密度分类和癌症风险预测任务中表现优异，但在病灶检测任务中表现不一，表明局部检测任务需进一步方法改进。

Abstract: Foundation models have shown promise in medical imaging but remain underexplored for three-dimensional imaging modalities. No foundation model currently exists for Digital Breast Tomosynthesis (DBT), despite its use for breast cancer screening.
  To develop and evaluate a foundation model for DBT (DBT-DINO) across multiple clinical tasks and assess the impact of domain-specific pre-training.
  Self-supervised pre-training was performed using the DINOv2 methodology on over 25 million 2D slices from 487,975 DBT volumes from 27,990 patients. Three downstream tasks were evaluated: (1) breast density classification using 5,000 screening exams; (2) 5-year risk of developing breast cancer using 106,417 screening exams; and (3) lesion detection using 393 annotated volumes.
  For breast density classification, DBT-DINO achieved an accuracy of 0.79 (95\% CI: 0.76--0.81), outperforming both the MetaAI DINOv2 baseline (0.73, 95\% CI: 0.70--0.76, p<.001) and DenseNet-121 (0.74, 95\% CI: 0.71--0.76, p<.001). For 5-year breast cancer risk prediction, DBT-DINO achieved an AUROC of 0.78 (95\% CI: 0.76--0.80) compared to DINOv2's 0.76 (95\% CI: 0.74--0.78, p=.57). For lesion detection, DINOv2 achieved a higher average sensitivity of 0.67 (95\% CI: 0.60--0.74) compared to DBT-DINO with 0.62 (95\% CI: 0.53--0.71, p=.60). DBT-DINO demonstrated better performance on cancerous lesions specifically with a detection rate of 78.8\% compared to Dinov2's 77.3\%.
  Using a dataset of unprecedented size, we developed DBT-DINO, the first foundation model for DBT. DBT-DINO demonstrated strong performance on breast density classification and cancer risk prediction. However, domain-specific pre-training showed variable benefits on the detection task, with ImageNet baseline outperforming DBT-DINO on general lesion detection, indicating that localized detection tasks require further methodological development.

</details>


### [194] [Do-Undo: Generating and Reversing Physical Actions in Vision-Language Models](https://arxiv.org/abs/2512.13609)
*Shweta Mahajan,Shreya Kadambi,Hoang Le,Munawar Hayat,Fatih Porikli*

Main category: cs.CV

TL;DR: Do-Undo任务和基准旨在填补视觉语言模型在物理动作理解和逆转方面的空白，通过大规模数据集和训练策略评估模型的物理推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决视觉语言模型在理解和生成由真实世界动作驱动的物理可信场景转换方面的关键空白，特别是模拟物理动作的结果并准确逆转它。

Method: 通过从真实世界视频中策划大规模可逆动作数据集，并设计一种训练策略以强制一致性，从而实现稳健的动作接地。

Result: 实验表明，当前模型在物理可逆性方面表现不佳，凸显了这一任务的重要性。

Conclusion: Do-Undo任务和基准为评估和推进多模态系统中的物理推理提供了一个直观的测试平台，强调了其在具身AI、机器人和物理感知生成建模中的重要性。

Abstract: We introduce the Do-Undo task and benchmark to address a critical gap in vision-language models: understanding and generating physically plausible scene transformations driven by real-world actions. Unlike prior work focused on object-level edits, Do-Undo requires models to simulate the outcome of a physical action and then accurately reverse it, reflecting true cause-and-effect in the visual world. We curate a large-scale dataset of reversible actions from real-world videos and design a training strategy enforcing consistency for robust action grounding. Our experiments reveal that current models struggle with physical reversibility, underscoring the importance of this task for embodied AI, robotics, and physics-aware generative modeling. Do-Undo establishes an intuitive testbed for evaluating and advancing physical reasoning in multimodal systems.

</details>


### [195] [SCR2-ST: Combine Single Cell with Spatial Transcriptomics for Efficient Active Sampling via Reinforcement Learning](https://arxiv.org/abs/2512.13635)
*Junchao Zhu,Ruining Deng,Junlin Guo,Tianyuan Yao,Chongyu Qu,Juming Xiong,Siqi Lu,Zhengyi Lu,Yanfan Zhu,Marilyn Lionts,Yuechen Yang,Yalin Zheng,Yu Wang,Shilin Zhao,Haichun Yang,Yuankai Huo*

Main category: cs.CV

TL;DR: SCR2-ST框架利用单细胞先验知识优化空间转录组数据采集与预测，显著提升效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 空间转录组学（ST）数据获取成本高且传统固定网格采样策略导致冗余测量，单细胞测序领域的数据可作为有效辅助来源来缓解这一限制。

Method: SCR2-ST结合了基于单细胞引导的强化学习主动采样（SCRL）和混合回归-检索预测网络（SCR2Net）。SCRL利用单细胞基础模型嵌入和空间密度信息构建生物奖励信号，SCR2Net则通过回归建模和检索增强推断的混合架构利用主动采样数据。

Result: 在三个公共ST数据集上的评估表明，SCR2-ST在采样效率和预测准确性上均达到SOTA性能，尤其在低预算场景下表现突出。

Conclusion: SCR2-ST通过整合单细胞先验知识，提出了一种高效的数据采集和表达预测框架，显著提升了空间转录组学数据的获取效率和预测准确性。

Abstract: Spatial transcriptomics (ST) is an emerging technology that enables researchers to investigate the molecular relationships underlying tissue morphology. However, acquiring ST data remains prohibitively expensive, and traditional fixed-grid sampling strategies lead to redundant measurements of morphologically similar or biologically uninformative regions, thus resulting in scarce data that constrain current methods. The well-established single-cell sequencing field, however, could provide rich biological data as an effective auxiliary source to mitigate this limitation. To bridge these gaps, we introduce SCR2-ST, a unified framework that leverages single-cell prior knowledge to guide efficient data acquisition and accurate expression prediction. SCR2-ST integrates a single-cell guided reinforcement learning-based (SCRL) active sampling and a hybrid regression-retrieval prediction network SCR2Net. SCRL combines single-cell foundation model embeddings with spatial density information to construct biologically grounded reward signals, enabling selective acquisition of informative tissue regions under constrained sequencing budgets. SCR2Net then leverages the actively sampled data through a hybrid architecture combining regression-based modeling with retrieval-augmented inference, where a majority cell-type filtering mechanism suppresses noisy matches and retrieved expression profiles serve as soft labels for auxiliary supervision. We evaluated SCR2-ST on three public ST datasets, demonstrating SOTA performance in both sampling efficiency and prediction accuracy, particularly under low-budget scenarios. Code is publicly available at: https://github.com/hrlblab/SCR2ST

</details>


### [196] [Charge: A Comprehensive Novel View Synthesis Benchmark and Dataset to Bind Them All](https://arxiv.org/abs/2512.13639)
*Michal Nazarczuk,Thomas Tanay,Arthur Moreau,Zhensong Zhang,Eduardo Pérez-Pellitero*

Main category: cs.CV

TL;DR: 本文介绍了一个用于新视角合成的高质量动态场景数据集，包含多种模态和三种基准测试场景，适用于4D重建和视图合成研究。


<details>
  <summary>Details</summary>
Motivation: 为训练和评估前沿的4D场景重建和新视角生成模型提供高质量、动态场景的数据集。

Method: 通过高保真RGB图像及多种互补模态（深度、表面法线、物体分割和光流）构建数据集，并分为三种不同的基准测试场景：密集多视角相机设置、稀疏相机排列和单目视频序列。

Result: 数据集具有视觉丰富性、高质量标注和多样化的实验设置，适用于不同数据稀疏程度的实验和比较。

Conclusion: 该数据集为4D场景重建和新视角生成模型提供了独特的资源，推动了视图合成和3D视觉的边界。

Abstract: This paper presents a new dataset for Novel View Synthesis, generated from a high-quality, animated film with stunning realism and intricate detail. Our dataset captures a variety of dynamic scenes, complete with detailed textures, lighting, and motion, making it ideal for training and evaluating cutting-edge 4D scene reconstruction and novel view generation models. In addition to high-fidelity RGB images, we provide multiple complementary modalities, including depth, surface normals, object segmentation and optical flow, enabling a deeper understanding of scene geometry and motion. The dataset is organised into three distinct benchmarking scenarios: a dense multi-view camera setup, a sparse camera arrangement, and monocular video sequences, enabling a wide range of experimentation and comparison across varying levels of data sparsity. With its combination of visual richness, high-quality annotations, and diverse experimental setups, this dataset offers a unique resource for pushing the boundaries of view synthesis and 3D vision.

</details>


### [197] [Grab-3D: Detecting AI-Generated Videos from 3D Geometric Temporal Consistency](https://arxiv.org/abs/2512.13665)
*Wenhan Chen,Sezer Karaoglu,Theo Gevers*

Main category: cs.CV

TL;DR: Grab-3D是一种基于3D几何时间一致性的Transformer框架，用于检测AI生成视频，性能优越且泛化能力强。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法对AI生成视频中的3D几何模式探索有限，需要更可靠的检测机制。

Method: 提出了Grab-3D框架，包括几何位置编码、时间-几何注意力机制和基于EMA的几何分类器头，以显式地将3D几何感知注入时间建模。

Result: 实验表明Grab-3D在检测性能上显著优于现有先进方法，并能泛化到未见过的生成器。

Conclusion: Grab-3D通过3D几何时间一致性显著提升了AI生成视频的检测性能，并展现出强大的跨域泛化能力。

Abstract: Recent advances in diffusion-based generation techniques enable AI models to produce highly realistic videos, heightening the need for reliable detection mechanisms. However, existing detection methods provide only limited exploration of the 3D geometric patterns present in generated videos. In this paper, we use vanishing points as an explicit representation of 3D geometry patterns, revealing fundamental discrepancies in geometric consistency between real and AI-generated videos. We introduce Grab-3D, a geometry-aware transformer framework for detecting AI-generated videos based on 3D geometric temporal consistency. To enable reliable evaluation, we construct an AI-generated video dataset of static scenes, allowing stable 3D geometric feature extraction. We propose a geometry-aware transformer equipped with geometric positional encoding, temporal-geometric attention, and an EMA-based geometric classifier head to explicitly inject 3D geometric awareness into temporal modeling. Experiments demonstrate that Grab-3D significantly outperforms state-of-the-art detectors, achieving robust cross-domain generalization to unseen generators.

</details>


### [198] [AgentIAD: Tool-Augmented Single-Agent for Industrial Anomaly Detection](https://arxiv.org/abs/2512.13671)
*Junwen Miao,Penghui Du,Yi Liu,Yu Wang,Yan Wang*

Main category: cs.CV

TL;DR: AgentIAD提出工具驱动的多阶段视觉检查框架，结合两阶段训练和奖励设计，显著提升工业异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 工业异常检测面临正常样本稀缺和缺陷局部细微的挑战，现有单次视觉语言模型缺乏明确机制对比正常模式。

Method: 采用两阶段训练方法：监督微调后接强化学习，结合感知奖励和行为奖励设计，驱动模型通过逐步观察、放大和验证优化判断。

Result: 在MMAD数据集上实现了97.62%的分类准确率，超越现有MLLM方法，并生成透明可解释的检查轨迹。

Conclusion: AgentIAD通过多阶段视觉检查框架，结合感知放大器和比较检索器，显著提升了工业异常检测的准确性和可解释性，达到了97.62%的分类准确率。

Abstract: Industrial anomaly detection (IAD) is difficult due to the scarcity of normal reference samples and the subtle, localized nature of many defects. Single-pass vision-language models (VLMs) often overlook small abnormalities and lack explicit mechanisms to compare against canonical normal patterns. We propose AgentIAD, a tool-driven agentic framework that enables multi-stage visual inspection. The agent is equipped with a Perceptive Zoomer (PZ) for localized fine-grained analysis and a Comparative Retriever (CR) for querying normal exemplars when evidence is ambiguous. To teach these inspection behaviors, we construct structured perceptive and comparative trajectories from the MMAD dataset and train the model in two stages: supervised fine-tuning followed by reinforcement learning. A two-part reward design drives this process: a perception reward that supervises classification accuracy, spatial alignment, and type correctness, and a behavior reward that encourages efficient tool use. Together, these components enable the model to refine its judgment through step-wise observation, zooming, and verification. AgentIAD achieves a new state-of-the-art 97.62% classification accuracy on MMAD, surpassing prior MLLM-based approaches while producing transparent and interpretable inspection traces.

</details>


### [199] [JoVA: Unified Multimodal Learning for Joint Video-Audio Generation](https://arxiv.org/abs/2512.13677)
*Xiaohu Huang,Hao Zhou,Qiangpeng Yang,Shilei Wen,Kai Han*

Main category: cs.CV

TL;DR: JoVA是一个联合视频-音频生成框架，通过联合自注意力和嘴部区域损失，实现了高效跨模态交互和高质唇同步，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在两个关键局限：1）大多只能生成环境音，缺乏生成与唇动同步的人类语音的能力；2）统一的人类视频-音频生成方法通常依赖显式融合或模态特定对齐模块，增加了架构复杂性。

Method: JoVA采用联合自注意力机制，在视频和音频标记之间实现直接高效的跨模态交互，无需额外对齐模块；并引入基于面部关键点检测的嘴部区域损失函数，增强训练中对关键嘴部区域的监督。

Result: 在基准测试中，JoVA在唇同步准确性、语音质量和整体视频-音频生成保真度上优于或与现有最先进方法竞争。

Conclusion: JoVA被证明是一个优雅的高质量多模态生成框架，在唇同步准确性、语音质量和整体视频-音频生成保真度上优于或与现有最先进方法竞争。

Abstract: In this paper, we present JoVA, a unified framework for joint video-audio generation. Despite recent encouraging advances, existing methods face two critical limitations. First, most existing approaches can only generate ambient sounds and lack the capability to produce human speech synchronized with lip movements. Second, recent attempts at unified human video-audio generation typically rely on explicit fusion or modality-specific alignment modules, which introduce additional architecture design and weaken the model simplicity of the original transformers. To address these issues, JoVA employs joint self-attention across video and audio tokens within each transformer layer, enabling direct and efficient cross-modal interaction without the need for additional alignment modules. Furthermore, to enable high-quality lip-speech synchronization, we introduce a simple yet effective mouth-area loss based on facial keypoint detection, which enhances supervision on the critical mouth region during training without compromising architectural simplicity. Extensive experiments on benchmarks demonstrate that JoVA outperforms or is competitive with both unified and audio-driven state-of-the-art methods in lip-sync accuracy, speech quality, and overall video-audio generation fidelity. Our results establish JoVA as an elegant framework for high-quality multimodal generation.

</details>


### [200] [LASER: Layer-wise Scale Alignment for Training-Free Streaming 4D Reconstruction](https://arxiv.org/abs/2512.13680)
*Tianye Ding,Yiming Xie,Yiqing Liang,Moitreya Chatterjee,Pedro Miraldo,Huaizu Jiang*

Main category: cs.CV

TL;DR: LASER是一种无需训练的框架，通过层间尺度对齐将离线重建模型转换为流式系统，实现高效流式视频处理。


<details>
  <summary>Details</summary>
Motivation: 现有流式方法需大量重新训练且难以充分利用离线模型的几何先验，而LASER旨在无需训练即可将离线模型转换为流式系统。

Method: LASER采用层间尺度对齐技术，将深度预测分割为离散层，计算每层尺度因子，并在相邻窗口和时间戳间传播，解决了简单相似变换对齐的局限性。

Result: 实验表明，LASER在相机姿态估计和点云重建质量上达到最先进水平，同时在RTX A6000 GPU上以14 FPS和6 GB峰值内存运行，适用于公里级流式视频。

Conclusion: LASER框架通过层间尺度对齐技术，成功将离线重建模型转换为流式系统，实现了在保持高质量重建的同时，显著降低了内存需求，适用于大规模流式视频处理。

Abstract: Recent feed-forward reconstruction models like VGGT and $π^3$ achieve impressive reconstruction quality but cannot process streaming videos due to quadratic memory complexity, limiting their practical deployment. While existing streaming methods address this through learned memory mechanisms or causal attention, they require extensive retraining and may not fully leverage the strong geometric priors of state-of-the-art offline models. We propose LASER, a training-free framework that converts an offline reconstruction model into a streaming system by aligning predictions across consecutive temporal windows. We observe that simple similarity transformation ($\mathrm{Sim}(3)$) alignment fails due to layer depth misalignment: monocular scale ambiguity causes relative depth scales of different scene layers to vary inconsistently between windows. To address this, we introduce layer-wise scale alignment, which segments depth predictions into discrete layers, computes per-layer scale factors, and propagates them across both adjacent windows and timestamps. Extensive experiments show that LASER achieves state-of-the-art performance on camera pose estimation and point map reconstruction %quality with offline models while operating at 14 FPS with 6 GB peak memory on a RTX A6000 GPU, enabling practical deployment for kilometer-scale streaming videos. Project website: $\href{https://neu-vi.github.io/LASER/}{\texttt{https://neu-vi.github.io/LASER/}}$

</details>


### [201] [I-Scene: 3D Instance Models are Implicit Generalizable Spatial Learners](https://arxiv.org/abs/2512.13683)
*Lu Ling,Yunhao Ge,Yichen Sheng,Aniket Bera*

Main category: cs.CV

TL;DR: 该论文提出一种方法，通过重新编程预训练的3D实例生成器，实现对新布局和物体组合的泛化，展示了其作为隐式空间学习器的潜力。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于学习的方法在空间理解上的局限性，即依赖有限场景数据集，难以泛化到新布局。

Method: 通过重新编程预训练的3D实例生成器，将其转变为场景级学习器，并采用模型为中心的空间监督，替代传统的数据集监督。

Result: 实验结果显示，该方法能够泛化到未见过的布局和新物体组合，且仅通过几何线索即可推断接近性、支撑和对称性。

Conclusion: 该论文表明，预训练的3D实例生成器可以作为隐式的空间学习器和推理器，为交互式3D场景理解和生成提供了基础模型。

Abstract: Generalization remains the central challenge for interactive 3D scene generation. Existing learning-based approaches ground spatial understanding in limited scene dataset, restricting generalization to new layouts. We instead reprogram a pre-trained 3D instance generator to act as a scene level learner, replacing dataset-bounded supervision with model-centric spatial supervision. This reprogramming unlocks the generator transferable spatial knowledge, enabling generalization to unseen layouts and novel object compositions. Remarkably, spatial reasoning still emerges even when the training scenes are randomly composed objects. This demonstrates that the generator's transferable scene prior provides a rich learning signal for inferring proximity, support, and symmetry from purely geometric cues. Replacing widely used canonical space, we instantiate this insight with a view-centric formulation of the scene space, yielding a fully feed-forward, generalizable scene generator that learns spatial relations directly from the instance model. Quantitative and qualitative results show that a 3D instance generator is an implicit spatial learner and reasoner, pointing toward foundation models for interactive 3D scene understanding and generation. Project page: https://luling06.github.io/I-Scene-project/

</details>


### [202] [Recurrent Video Masked Autoencoders](https://arxiv.org/abs/2512.13684)
*Daniel Zoran,Nikhil Parthasarathy,Yi Yang,Drew A Hudson,Joao Carreira,Andrew Zisserman*

Main category: cs.CV

TL;DR: RVM是一种新型视频表示学习方法，通过循环神经网络和掩码预测任务高效学习视频时空结构，在小模型规模下实现高性能且参数效率显著提升。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种高效通用的视频表示学习方法，克服现有时空注意力架构的局限性，同时提升参数效率。

Method: RVM采用基于Transformer的循环神经网络，通过非对称掩码预测任务学习视频的时空结构，仅需标准像素重建目标。

Result: RVM在视频级别任务（如动作识别、目标跟踪）上达到与最先进模型（如VideoMAE、V-JEPA）竞争的性能，并在几何和密集空间理解任务上优于图像模型（如DINOv2），参数效率提升高达30倍。

Conclusion: RVM通过其循环架构在长时域特征传播上表现出色，且无需知识蒸馏即可在小模型规模下实现高效性能，展现了在视频表示学习中的潜力。

Abstract: We present Recurrent Video Masked-Autoencoders (RVM): a novel video representation learning approach that uses a transformer-based recurrent neural network to aggregate dense image features over time, effectively capturing the spatio-temporal structure of natural video data. RVM learns via an asymmetric masked prediction task requiring only a standard pixel reconstruction objective. This design yields a highly efficient ``generalist'' encoder: RVM achieves competitive performance with state-of-the-art video models (e.g. VideoMAE, V-JEPA) on video-level tasks like action recognition and point/object tracking, while also performing favorably against image models (e.g. DINOv2) on tasks that test geometric and dense spatial understanding. Notably, RVM achieves strong performance in the small-model regime without requiring knowledge distillation, exhibiting up to 30x greater parameter efficiency than competing video masked autoencoders. Moreover, we demonstrate that RVM's recurrent nature allows for stable feature propagation over long temporal horizons with linear computational cost, overcoming some of the limitations of standard spatio-temporal attention-based architectures. Finally, we use qualitative visualizations to highlight that RVM learns rich representations of scene semantics, structure, and motion.

</details>


### [203] [Towards Scalable Pre-training of Visual Tokenizers for Generation](https://arxiv.org/abs/2512.13687)
*Jingfeng Yao,Yuda Song,Yucong Zhou,Xinggang Wang*

Main category: cs.CV

TL;DR: VTP通过联合优化多任务损失，解决了视觉分词器预训练的扩展性问题，显著提升生成性能。


<details>
  <summary>Details</summary>
Motivation: 标准基于重建的训练范式导致潜在空间偏向低层信息，无法有效提升生成质量，因此需要转向高层语义表示。

Method: 提出了VTP框架，联合优化图像-文本对比、自监督和重建损失，进行大规模预训练。

Result: VTP在零样本准确率和生成效率上表现优异（78.2%准确率和0.36 rFID），且生成性能随计算资源增加而显著提升（65.8% FID改进）。

Conclusion: VTP框架通过联合优化图像-文本对比、自监督和重建损失，显著提升了视觉分词器的生成性能，并展示了良好的扩展性。

Abstract: The quality of the latent space in visual tokenizers (e.g., VAEs) is crucial for modern generative models. However, the standard reconstruction-based training paradigm produces a latent space that is biased towards low-level information, leading to a foundation flaw: better pixel-level accuracy does not lead to higher-quality generation. This implies that pouring extensive compute into visual tokenizer pre-training translates poorly to improved performance in generation. We identify this as the ``pre-training scaling problem`` and suggest a necessary shift: to be effective for generation, a latent space must concisely represent high-level semantics. We present VTP, a unified visual tokenizer pre-training framework, pioneering the joint optimization of image-text contrastive, self-supervised, and reconstruction losses. Our large-scale study reveals two principal findings: (1) understanding is a key driver of generation, and (2) much better scaling properties, where generative performance scales effectively with compute, parameters, and data allocated to the pretraining of the visual tokenizer. After large-scale pre-training, our tokenizer delivers a competitive profile (78.2 zero-shot accuracy and 0.36 rFID on ImageNet) and 4.1 times faster convergence on generation compared to advanced distillation methods. More importantly, it scales effectively: without modifying standard DiT training specs, solely investing more FLOPS in pretraining VTP achieves 65.8\% FID improvement in downstream generation, while conventional autoencoder stagnates very early at 1/10 FLOPS. Our pre-trained models are available at https://github.com/MiniMax-AI/VTP.

</details>


### [204] [LitePT: Lighter Yet Stronger Point Transformer](https://arxiv.org/abs/2512.13689)
*Yuanwen Yue,Damien Robert,Jianyuan Wang,Sunghwan Hong,Jan Dirk Wegner,Christian Rupprecht,Konrad Schindler*

Main category: cs.CV

TL;DR: LitePT结合卷积和注意力机制，通过PointROPE保持空间信息，性能优、速度快、内存省。


<details>
  <summary>Details</summary>
Motivation: 探讨卷积和注意力块在3D点云网络中的最佳组合方式，发现卷积适合早期高分辨率低层几何特征提取，而注意力更适合深层低分辨率高层语义捕获。

Method: 提出了一种新的3D点云处理架构LitePT，早期阶段采用卷积提取低层几何特征，深层切换至注意力机制捕获高层语义和上下文，并引入训练无关的3D位置编码PointROPE。

Result: LitePT相比Point Transformer V3参数减少3.6倍，速度提升2倍，内存消耗降低2倍，性能匹配或超越。

Conclusion: LitePT模型通过早期使用卷积和深层切换至注意力机制，结合PointROPE位置编码，在减少参数、提升速度和降低内存消耗的同时，性能优于或匹配现有最佳模型。

Abstract: Modern neural architectures for 3D point cloud processing contain both convolutional layers and attention blocks, but the best way to assemble them remains unclear. We analyse the role of different computational blocks in 3D point cloud networks and find an intuitive behaviour: convolution is adequate to extract low-level geometry at high-resolution in early layers, where attention is expensive without bringing any benefits; attention captures high-level semantics and context in low-resolution, deep layers more efficiently. Guided by this design principle, we propose a new, improved 3D point cloud backbone that employs convolutions in early stages and switches to attention for deeper layers. To avoid the loss of spatial layout information when discarding redundant convolution layers, we introduce a novel, training-free 3D positional encoding, PointROPE. The resulting LitePT model has $3.6\times$ fewer parameters, runs $2\times$ faster, and uses $2\times$ less memory than the state-of-the-art Point Transformer V3, but nonetheless matches or even outperforms it on a range of tasks and datasets. Code and models are available at: https://github.com/prs-eth/LitePT.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [205] [Robust and Efficient Penetration-Free Elastodynamics without Barriers](https://arxiv.org/abs/2512.12151)
*Juntian Zheng,Zhaofeng Luo,Minchen Li*

Main category: cs.GR

TL;DR: 提出无屏障优化框架，解决IPC的效率和鲁棒性问题，GPU加速达103倍。


<details>
  <summary>Details</summary>
Motivation: 解决增量势能接触（IPC）方法的两大效率瓶颈：对数屏障函数导致的系统病态和时间锁定问题。

Method: 采用自定义增强拉格朗日求解器的二阶约束优化框架，结合约束过滤和衰减机制，避免时间锁定问题。

Result: 实验证明该方法在效率、鲁棒性和准确性上表现优异，GPU优化后速度提升显著。

Conclusion: 该论文提出了一种无屏障优化框架，显著提升了非穿透弹性动力学模拟的效率和鲁棒性，通过GPU优化设计实现了高达103倍的加速，适用于接触密集的场景。

Abstract: We introduce a barrier-free optimization framework for non-penetration elastodynamic simulation that matches the robustness of Incremental Potential Contact (IPC) while overcoming its two primary efficiency bottlenecks: (1) reliance on logarithmic barrier functions to enforce non-penetration constraints, which leads to ill-conditioned systems and significantly slows down the convergence of iterative linear solvers; and (2) the time-of-impact (TOI) locking issue, which restricts active-set exploration in collision-intensive scenes and requires a large number of Newton iterations. We propose a novel second-order constrained optimization framework featuring a custom augmented Lagrangian solver that avoids TOI locking by immediately incorporating all requisite contact pairs detected via CCD, enabling more efficient active-set exploration and leading to significantly fewer Newton iterations. By adaptively updating Lagrange multipliers rather than increasing penalty stiffness, our method prevents stagnation at zero TOI while maintaining a well-conditioned system. We further introduce a constraint filtering and decay mechanism to keep the active set compact and stable, along with a theoretical justification of our method's finite-step termination and first-order time integration accuracy under a cumulative TOI-based termination criterion. A comprehensive set of experiments demonstrates the efficiency, robustness, and accuracy of our method. With a GPU-optimized simulator design, our method achieves an up to 103x speedup over GIPC on challenging, contact-rich benchmarks - scenarios that were previously tractable only with barrier-based methods. Our code and data will be open-sourced.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [206] [A Monad-Based Clause Architecture for Artificial Age Score (AAS) in Large Language Models](https://arxiv.org/abs/2512.11835)
*Seyma Yaman Kayadibi*

Main category: cs.AI

TL;DR: 本研究开发了一个基于AAS的条款框架，通过莱布尼茨单子论的可执行规范约束LLM内部动态，实验证明其行为有界且可解释。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型（LLMs）内部记忆和‘自我类’行为缺乏原则性、可审计治理的问题。

Method: 通过将莱布尼茨《单子论》中的二十个选定单子分为六组，并在AAS内核上实现为可执行规范，采用四步模式进行最小化Python实现和数值实验。

Result: 条款系统展示了有界且可解释的行为，包括AAS轨迹的连续性和速率限制、矛盾触发明确惩罚、层次化细化揭示有机结构等。

Conclusion: 基于AAS核心的条款框架为人工代理的内部动态提供了透明且可代码化的约束与分析蓝图，展示了有界且可解释的行为。

Abstract: Large language models (LLMs) are often deployed as powerful yet opaque systems, leaving open how their internal memory and "self-like" behavior should be governed in a principled and auditable way. The Artificial Age Score (AAS) was previously introduced and mathematically justified through three theorems that characterise it as a metric of artificial memory aging. Building on this foundation, the present work develops an engineering-oriented, clause-based architecture that imposes law-like constraints on LLM memory and control. Twenty selected monads from Leibniz's Monadology are grouped into six bundles: ontology, dynamics, representation and consciousness, harmony and reason, body and organisation, and teleology, and each bundle is realised as an executable specification on top of the AAS kernel. Across six minimal Python implementations, these clause families are instantiated in numerical experiments acting on channel-level quantities such as recall scores, redundancy, and weights. Each implementation follows a four-step pattern: inputs and setup, clause implementation, numerical results, and implications for LLM design, emphasising that the framework is not only philosophically motivated but also directly implementable. The experiments show that the clause system exhibits bounded and interpretable behavior: AAS trajectories remain continuous and rate-limited, contradictions and unsupported claims trigger explicit penalties, and hierarchical refinement reveals an organic structure in a controlled manner. Dual views and goal-action pairs are aligned by harmony terms, and windowed drift in perfection scores separates sustained improvement from sustained degradation. Overall, the monad-based clause framework uses AAS as a backbone and provides a transparent, code-level blueprint for constraining and analyzing internal dynamics in artificial agents.

</details>


### [207] [Solving Parallel Machine Scheduling With Precedences and Cumulative Resource Constraints With Calendars](https://arxiv.org/abs/2512.11864)
*Christoph Einspieler,Matthias Horn,Marie-Louise Lackner,Patrick Malik,Nysret Musliu,Felix Winter*

Main category: cs.AI

TL;DR: 本文针对工业中的复杂并行机器调度问题，提出约束建模和元启发式方法，成功应用于实际生产。


<details>
  <summary>Details</summary>
Motivation: 现代工厂中的并行机器调度问题存在复杂的优先约束和基于日历的资源限制，现有方法难以高效处理，亟需开发新方法。

Method: 采用约束建模作为小规模场景的精确解法，同时提出了一种构造启发式算法和基于局部搜索的定制元启发式算法来处理大规模问题实例。

Result: 提出的元启发式方法已在工业环境中实际应用，证明了其有效性。

Conclusion: 本文提出了一种结合约束建模和元启发式的方法，有效解决了实际工业生产中的并行机器调度问题，并在工业环境中成功部署。

Abstract: The task of finding efficient production schedules for parallel machines is a challenge that arises in most industrial manufacturing domains. There is a large potential to minimize production costs through automated scheduling techniques, due to the large-scale requirements of modern factories. In the past, solution approaches have been studied for many machine scheduling variations, where even basic variants have been shown to be NP-hard. However, in today's real-life production environments, additional complex precedence constraints and resource restrictions with calendars arise that must be fulfilled. These additional constraints cannot be tackled efficiently by existing solution techniques. Thus, there is a strong need to develop and analyze automated methods that can solve such real-life parallel machine scheduling scenarios. In this work, we introduce a novel variant of parallel machine scheduling with job precedences and calendar-based cumulative resource constraints that arises in real-life industrial use cases. A constraint modeling approach is proposed as an exact solution method for small scheduling scenarios together with state-of-the-art constraint-solving technology. Further, we propose a construction heuristic as well as a tailored metaheuristic using local search to efficiently tackle large-scale problem instances. This metaheuristic approach has been deployed and is currently being used in an industrial setting.

</details>


### [208] [Mirror Mode in Fire Emblem: Beating Players at their own Game with Imitation and Reinforcement Learning](https://arxiv.org/abs/2512.11902)
*Yanna Elizabeth Smid,Peter van der Putten,Aske Plaat*

Main category: cs.AI

TL;DR: 研究提出“镜像模式”，通过AI模仿玩家策略来增加游戏挑战性。实验结合多种学习方法，结果显示防御行为模仿成功，玩家满意度高。


<details>
  <summary>Details</summary>
Motivation: 为了让敌人在回合制游戏中表现出令人惊讶且不可预测的策略，本研究引入了“镜像模式”，即敌人AI模仿玩家的个人策略，挑战玩家不断改变玩法。

Method: 结合生成对抗模仿学习（GAIL）、行为克隆（BC）和近端策略优化（PPO）来模仿玩家演示。

Result: 实验表明，模型在防御行为上模仿效果良好，但在进攻策略上表现不佳。玩家调查显示他们能识别自己的撤退战术，并对镜像模式整体满意度较高。

Conclusion: 通过改进模型可以进一步提升模仿质量并增加玩家满意度，尤其是在玩家面对自己的策略时。完整代码和调查结果已公开。

Abstract: Enemy strategies in turn-based games should be surprising and unpredictable. This study introduces Mirror Mode, a new game mode where the enemy AI mimics the personal strategy of a player to challenge them to keep changing their gameplay. A simplified version of the Nintendo strategy video game Fire Emblem Heroes has been built in Unity, with a Standard Mode and a Mirror Mode. Our first set of experiments find a suitable model for the task to imitate player demonstrations, using Reinforcement Learning and Imitation Learning: combining Generative Adversarial Imitation Learning, Behavioral Cloning, and Proximal Policy Optimization. The second set of experiments evaluates the constructed model with player tests, where models are trained on demonstrations provided by participants. The gameplay of the participants indicates good imitation in defensive behavior, but not in offensive strategies. Participant's surveys indicated that they recognized their own retreating tactics, and resulted in an overall higher player-satisfaction for Mirror Mode. Refining the model further may improve imitation quality and increase player's satisfaction, especially when players face their own strategies. The full code and survey results are stored at: https://github.com/YannaSmid/MirrorMode

</details>


### [209] [Structured Personalization: Modeling Constraints as Matroids for Data-Minimal LLM Agents](https://arxiv.org/abs/2512.11907)
*Daniel Platnick,Marjan Alirezaie,Hossein Rahnama*

Main category: cs.AI

TL;DR: 论文提出一种方法，将LLM个性化中的复杂约束建模为层状拟阵，实现高效且理论保证的数据选择。


<details>
  <summary>Details</summary>
Motivation: 解决LLM代理个性化中因结构化约束（如逻辑依赖、类别配额和分层规则）导致的传统子集选择算法失效问题。

Method: 通过编译过程将用户知识图转化为抽象的宏观面，并利用层状拟阵理论建模约束条件，实现子模最大化下的贪婪优化。

Result: 证明了常见分层和配额约束构成有效的层状拟阵，从而在子模最大化下实现常数因子近似（连续贪婪下可达1-1/e）。

Conclusion: 论文提出了一种基于层状拟阵的方法，用于解决LLM代理个性化中的结构化约束问题，并通过理论证明和实验验证了其有效性。

Abstract: Personalizing Large Language Model (LLM) agents requires conditioning them on user-specific data, creating a critical trade-off between task utility and data disclosure. While the utility of adding user data often exhibits diminishing returns (i.e., submodularity), enabling near-optimal greedy selection, real-world personalization is complicated by structural constraints. These include logical dependencies (e.g., selecting fact A requires fact B), categorical quotas (e.g., select at most one writing style), and hierarchical rules (e.g., select at most two social media preferences, of which at most one can be for a professional network). These constraints violate the assumptions of standard subset selection algorithms. We propose a principled method to formally model such constraints. We introduce a compilation process that transforms a user's knowledge graph with dependencies into a set of abstract macro-facets. Our central result is a proof that common hierarchical and quota-based constraints over these macro-facets form a valid laminar matroid. This theoretical characterization lets us cast structured personalization as submodular maximization under a matroid constraint, enabling greedy with constant-factor guarantees (and (1-1/e) via continuous greedy) for a much richer and more realistic class of problems.

</details>


### [210] [Causal Strengths and Leaky Beliefs: Interpreting LLM Reasoning via Noisy-OR Causal Bayes Nets](https://arxiv.org/abs/2512.11909)
*Hanna Dettki*

Main category: cs.AI

TL;DR: 研究比较了LLMs和人类在因果推理任务上的表现，发现两者有一致性但也有独特推理特征。


<details>
  <summary>Details</summary>
Motivation: 探讨LLMs和人类在相同因果推理任务上的表现，以更全面地理解两者的优势和弱点。

Method: 通过评估20多个LLM在11个语义上有意义的因果任务上，使用直接和思维链（CoT）两种方法，并利用泄漏噪声-OR因果贝叶斯网络（CBN）建模判断。

Result: LLMs和人类在任务层面上表现出一致性，但推理特征存在差异。

Conclusion: LLMs和人类在因果推理任务上存在一致性，但也展现出不同的推理特征。

Abstract: The nature of intelligence in both humans and machines is a longstanding question. While there is no universally accepted definition, the ability to reason causally is often regarded as a pivotal aspect of intelligence (Lake et al., 2017). Evaluating causal reasoning in LLMs and humans on the same tasks provides hence a more comprehensive understanding of their respective strengths and weaknesses. Our study asks: (Q1) Are LLMs aligned with humans given the \emph{same} reasoning tasks? (Q2) Do LLMs and humans reason consistently at the task level? (Q3) Do they have distinct reasoning signatures?
  We answer these by evaluating 20+ LLMs on eleven semantically meaningful causal tasks formalized by a collider graph ($C_1\!\to\!E\!\leftarrow\!C_2$ ) under \emph{Direct} (one-shot number as response = probability judgment of query node being one and \emph{Chain of Thought} (CoT; think first, then provide answer).
  Judgments are modeled with a leaky noisy-OR causal Bayes net (CBN) whose parameters $θ=(b,m_1,m_2,p(C)) \in [0,1]$ include a shared prior $p(C)$;
  we select the winning model via AIC between a 3-parameter symmetric causal strength ($m_1{=}m_2$) and 4-parameter asymmetric ($m_1{\neq}m_2$) variant.

</details>


### [211] [Towards Unified Co-Speech Gesture Generation via Hierarchical Implicit Periodicity Learning](https://arxiv.org/abs/2512.13131)
*Xin Guo,Yifan Zhao,Jia Li*

Main category: cs.AI

TL;DR: 本文提出分层隐式周期性（HIP）方法，通过建模运动单元间的相关性，显著提升了音频驱动的3D手势生成的自然性和协调性。


<details>
  <summary>Details</summary>
Motivation: 现有端到端生成方案未能建模不同运动单元（如头、身体和手）之间的关键互相关和内部相关，导致动作不自然和协调性差。

Method: 采用分层隐式周期性（HIP）学习，通过周期性自编码器探索手势运动相位流形，并结合非周期性特征实现实例级多样性，同时利用级联引导建模面部、身体和手部的分层关系。

Result: 实验证明HIP方法在3D虚拟形象上的表现优于现有语音手势生成方法。

Conclusion: 本文提出的统一分层隐式周期性（HIP）学习方法在音频驱动的3D手势生成中表现出色，通过定量和定性评估均优于现有技术。

Abstract: Generating 3D-based body movements from speech shows great potential in extensive downstream applications, while it still suffers challenges in imitating realistic human movements. Predominant research efforts focus on end-to-end generation schemes to generate co-speech gestures, spanning GANs, VQ-VAE, and recent diffusion models. As an ill-posed problem, in this paper, we argue that these prevailing learning schemes fail to model crucial inter- and intra-correlations across different motion units, i.e. head, body, and hands, thus leading to unnatural movements and poor coordination. To delve into these intrinsic correlations, we propose a unified Hierarchical Implicit Periodicity (HIP) learning approach for audio-inspired 3D gesture generation. Different from predominant research, our approach models this multi-modal implicit relationship by two explicit technique insights: i) To disentangle the complicated gesture movements, we first explore the gesture motion phase manifolds with periodic autoencoders to imitate human natures from realistic distributions while incorporating non-period ones from current latent states for instance-level diversities. ii) To model the hierarchical relationship of face motions, body gestures, and hand movements, driving the animation with cascaded guidance during learning. We exhibit our proposed approach on 3D avatars and extensive experiments show our method outperforms the state-of-the-art co-speech gesture generation methods by both quantitative and qualitative evaluations. Code and models will be publicly available.

</details>


### [212] [Robustness of Probabilistic Models to Low-Quality Data: A Multi-Perspective Analysis](https://arxiv.org/abs/2512.11912)
*Liu Peng,Yaochu Jin*

Main category: cs.AI

TL;DR: 研究发现自回归语言模型对低质量数据最稳健，扩散模型最脆弱，差异源于条件信息丰富性和数据信息量。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于探索现代概率模型在面对低质量数据时的鲁棒性差异，以及解释这些差异背后的原理。

Method: 研究采用系统性比较方法，通过信息论、PAC学习和梯度动力学等多视角分析，评估了不同模型在数据损坏情况下的表现。

Result: 结果显示，自回归语言模型（如GPT-2）在50%令牌损坏情况下仅轻微受影响（测试NLL从2.87增至3.59），而分类条件扩散模型在相同条件下性能急剧下降（图像标签一致性相对基线下降56.81%）。分类器的影响适中，且随数据集规模扩大而减弱。

Conclusion: 论文得出结论，现代概率模型对低质量数据的鲁棒性存在显著差异，其中自回归语言模型表现最为稳健，而分类条件扩散模型则表现最差。这种差异主要由两个关键原则决定：条件信息的丰富性和训练数据的绝对信息量。

Abstract: A systematic, comparative investigation into the effects of low-quality data reveals a stark spectrum of robustness across modern probabilistic models. We find that autoregressive language models, from token prediction to sequence-to-sequence tasks, are remarkably resilient (for GPT-2, test NLL increases modestly from 2.87 to 3.59 despite 50% token corruption). By contrast, under the same levels of data corruption, class-conditional diffusion models degrade catastrophically (image-label consistency plummets by 56.81% relative to baseline), while classifiers show a moderate impact that diminishes with dataset scale. To explain these discrepancies, we analyze the results through a multi-perspective lens, integrating information theory, PAC learning, and gradient dynamics. These analyses suggest that robustness is heavily influenced by two key principles: the richness of conditioning information, which constrains the learning problem, and the absolute information content of the training data, which allows the signal from correct information to dominate statistical noise.

</details>


### [213] [CXL-SpecKV: A Disaggregated FPGA Speculative KV-Cache for Datacenter LLM Serving](https://arxiv.org/abs/2512.11920)
*Dong Liu,Yanxuan Yu*

Main category: cs.AI

TL;DR: CXL-SpecKV利用CXL和FPGA技术，通过内存解耦和推测执行优化LLM的KV缓存，显著提升吞吐量并降低成本。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在数据中心部署时，由于KV缓存占用大量GPU内存，限制了批处理大小和系统吞吐量。

Method: 提出了一种基于CXL的解耦KV缓存架构，结合FPGA加速器，实现了远程内存卸载、推测性KV缓存预取以及KV缓存压缩/解压缩。

Result: 在先进LLM模型上评估，CXL-SpecKV相比纯GPU基线实现了3.2倍吞吐量提升，内存成本降低2.8倍，同时保持准确性。

Conclusion: CXL-SpecKV通过智能内存解耦和推测执行有效解决了大规模LLM服务中的内存墙挑战，实现了高吞吐量和低成本。

Abstract: Large Language Models (LLMs) have revolutionized natural language processing tasks, but their deployment in datacenter environments faces significant challenges due to the massive memory requirements of key-value (KV) caches. During the autoregressive decoding process, KV caches consume substantial GPU memory, limiting batch sizes and overall system throughput. To address these challenges, we propose \textbf{CXL-SpecKV}, a novel disaggregated KV-cache architecture that leverages Compute Express Link (CXL) interconnects and FPGA accelerators to enable efficient speculative execution and memory disaggregation. Our approach introduces three key innovations: (i) a CXL-based memory disaggregation framework that offloads KV-caches to remote FPGA memory with low latency, (ii) a speculative KV-cache prefetching mechanism that predicts and preloads future tokens' cache entries, and (iii) an FPGA-accelerated KV-cache compression and decompression engine that reduces memory bandwidth requirements by up to 4$\times$. When evaluated on state-of-the-art LLM models, CXL-SpecKV achieves up to 3.2$\times$ higher throughput compared to GPU-only baselines, while reducing memory costs by 2.8$\times$ and maintaining accuracy. Our system demonstrates that intelligent memory disaggregation combined with speculative execution can effectively address the memory wall challenge in large-scale LLM serving. Our code implementation has been open-sourced at https://github.com/FastLM/CXL-SpecKV.

</details>


### [214] [AGAPI-Agents: An Open-Access Agentic AI Platform for Accelerated Materials Design on AtomGPT.org](https://arxiv.org/abs/2512.11935)
*Jaehyung Lee,Justin Ely,Kent Zhang,Akshaya Ajith,Charles Rhys Campbell,Kamal Choudhary*

Main category: cs.AI

TL;DR: AGAPI是一个开源AI平台，整合了多种工具和模型，用于加速材料发现，已在实际应用中验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决材料研究中计算生态系统碎片化、可重复性挑战及对商业大语言模型的依赖问题。

Method: AGAPI采用Agent-Planner-Executor-Summarizer架构，自主构建和执行多步骤工作流，涵盖材料数据检索、图神经网络属性预测、机器学习力场优化等。

Result: 通过端到端工作流展示了AGAPI的能力，包括异质结构构建、X射线衍射分析等，并评估了30多个测试案例。

Conclusion: AGAPI提供了一个可扩展且透明的平台，支持可重复、AI加速的材料发现，已有超过1,000名活跃用户。

Abstract: Artificial intelligence is reshaping scientific discovery, yet its use in materials research remains limited by fragmented computational ecosystems, reproducibility challenges, and dependence on commercial large language models (LLMs). Here we introduce AGAPI (AtomGPT.org API), an open-access agentic AI platform that integrates more than eight open-source LLMs with over twenty materials-science API endpoints, unifying databases, simulation tools, and machine-learning models through a common orchestration framework. AGAPI employs an Agent-Planner-Executor-Summarizer architecture that autonomously constructs and executes multi-step workflows spanning materials data retrieval, graph neural network property prediction, machine-learning force-field optimization, tight-binding calculations, diffraction analysis, and inverse design. We demonstrate AGAPI through end-to-end workflows, including heterostructure construction, powder X-ray diffraction analysis, and semiconductor defect engineering requiring up to ten sequential operations. In addition, we evaluate AGAPI using 30+ example prompts as test cases and compare agentic predictions with and without tool access against experimental data. With more than 1,000 active users, AGAPI provides a scalable and transparent foundation for reproducible, AI-accelerated materials discovery. AGAPI-Agents codebase is available at https://github.com/atomgptlab/agapi.

</details>


### [215] [Hypergame Rationalisability: Solving Agent Misalignment In Strategic Play](https://arxiv.org/abs/2512.11942)
*Vince Trencsenyi*

Main category: cs.AI

TL;DR: 本文提出了一种基于逻辑的语言和自动化流程，填补了超博弈理论在多智能体系统研究中的实践空白，为异构推理提供了形式化基础。


<details>
  <summary>Details</summary>
Motivation: 解决超博弈理论在多智能体系统研究中缺乏统一、形式化和实用表示语言以及可扩展算法的问题。

Method: 利用答案集编程开发自动化流程，包括实例化超博弈结构和运行新颖的超博弈合理化程序。

Result: 提出了一种声明式、基于逻辑的领域特定语言，用于编码超博弈结构和解决方案概念，并建立了超博弈理论与多智能体系统及战略AI之间的联系。

Conclusion: 本文通过引入一种基于逻辑的领域特定语言和自动化流程，填补了超博弈理论在多智能体系统研究中的实践空白，为开发基于信念的异构推理器提供了统一的形式化基础。

Abstract: Differences in perception, information asymmetries, and bounded rationality lead game-theoretic players to derive a private, subjective view of the game that may diverge from the underlying ground-truth scenario and may be misaligned with other players' interpretations. While typical game-theoretic assumptions often overlook such heterogeneity, hypergame theory provides the mathematical framework to reason about mismatched mental models. Although hypergames have recently gained traction in dynamic applications concerning uncertainty, their practical adoption in multi-agent system research has been hindered by the lack of a unifying, formal, and practical representation language, as well as scalable algorithms for managing complex hypergame structures and equilibria. Our work addresses this gap by introducing a declarative, logic-based domain-specific language for encoding hypergame structures and hypergame solution concepts. Leveraging answer-set programming, we develop an automated pipeline for instantiating hypergame structures and running our novel hypergame rationalisation procedure, a mechanism for finding belief structures that justify seemingly irrational outcomes. The proposed language establishes a unifying formalism for hypergames and serves as a foundation for developing nuanced, belief-based heterogeneous reasoners, offering a verifiable context with logical guarantees. Together, these contributions establish the connection between hypergame theory, multi-agent systems, and strategic AI.

</details>


### [216] [Log Anomaly Detection with Large Language Models via Knowledge-Enriched Fusion](https://arxiv.org/abs/2512.11997)
*Anfeng Peng,Ajesh Koyatan Chathoth,Stephen Lee*

Main category: cs.AI

TL;DR: EnrichLog 是一种无需训练的日志异常检测框架，结合上下文知识提升检测准确性和可解释性，实验证明其优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统日志分析技术常丢失重要语义信息或难以处理模糊日志模式，因此需要一种更准确且可解释的异常检测方法。

Method: EnrichLog 利用检索增强生成技术整合相关上下文知识，无需重新训练，同时结合历史示例和语料库推理。

Result: 在四个大规模系统日志基准数据集上的实验表明，EnrichLog 在异常检测性能上优于五种基线方法，能有效处理模糊日志条目并保持高效推理。

Conclusion: EnrichLog 是一个无需训练的基于条目的异常检测框架，通过结合语料库特定和样本特定的知识，显著提升了异常检测的性能和可解释性，适用于实际部署。

Abstract: System logs are a critical resource for monitoring and managing distributed systems, providing insights into failures and anomalous behavior. Traditional log analysis techniques, including template-based and sequence-driven approaches, often lose important semantic information or struggle with ambiguous log patterns. To address this, we present EnrichLog, a training-free, entry-based anomaly detection framework that enriches raw log entries with both corpus-specific and sample-specific knowledge. EnrichLog incorporates contextual information, including historical examples and reasoning derived from the corpus, to enable more accurate and interpretable anomaly detection. The framework leverages retrieval-augmented generation to integrate relevant contextual knowledge without requiring retraining. We evaluate EnrichLog on four large-scale system log benchmark datasets and compare it against five baseline methods. Our results show that EnrichLog consistently improves anomaly detection performance, effectively handles ambiguous log entries, and maintains efficient inference. Furthermore, incorporating both corpus- and sample-specific knowledge enhances model confidence and detection accuracy, making EnrichLog well-suited for practical deployments.

</details>


### [217] [Context-Aware Agentic Power Resources Optimisation in EV using Smart2ChargeApp](https://arxiv.org/abs/2512.12048)
*Muddsair Sharif,Huseyin Seker*

Main category: cs.AI

TL;DR: CAMAC-DRA框架通过多智能体协调优化EV充电，实现高效、低成本且可持续的解决方案。


<details>
  <summary>Details</summary>
Motivation: 优化智能电动汽车充电生态系统，通过Smart2Charge应用实现动态资源分配。

Method: 采用协调的Deep Q-Networks与Graph Neural Networks和注意力机制集成，处理20个上下文特征。

Result: 实现了92%的协调成功率、15%的能效提升、10%的成本降低、20%的电网压力减少和2.3倍的更快收敛速度。

Conclusion: CAMAC-DRA框架通过上下文感知的多利益相关者协调，成功平衡了竞争目标并适应实时变量，成为智能EV充电协调和可持续交通电气化的突破性解决方案。

Abstract: This paper presents a novel context-sensitive multi\-agent coordination for dynamic resource allocation (CAMAC-DRA) framework for optimizing smart electric vehicle (EV) charging ecosystems through the Smart2Charge application. The proposed system coordinates autonomous charging agents across networks of 250 EVs and 45 charging stations while adapting to dynamic environmental conditions through context-aware decision-making. Our multi-agent approach employs coordinated Deep Q\-Networks integrated with Graph Neural Networks and attention mechanisms, processing 20 contextual features including weather patterns, traffic conditions, grid load fluctuations, and electricity pricing.The framework balances five ecosystem stakeholders i.e. EV users (25\%), grid operators (20\%), charging station operators (20\%), fleet operators (20%), and environmental factors (15\%) through weighted coordination mechanisms and consensus protocols. Comprehensive validation using real-world datasets containing 441,077 charging transactions demonstrates superior performance compared to baseline algorithms including DDPG, A3C, PPO, and GNN approaches. The CAMAC\-DRA framework achieves 92\% coordination success rate, 15\% energy efficiency improvement, 10\% cost reduction, 20% grid strain decrease, and \2.3x faster convergence while maintaining 88\% training stability and 85\% sample efficiency. Real-world validation confirms commercial viability with Net Present Cost of -\$122,962 and 69\% cost reduction through renewable energy integration. The framework's unique contribution lies in developing context-aware multi-stakeholder coordination that successfully balances competing objectives while adapting to real-time variables, positioning it as a breakthrough solution for intelligent EV charging coordination and sustainable transportation electrification.

</details>


### [218] [The Forecast Critic: Leveraging Large Language Models for Poor Forecast Identification](https://arxiv.org/abs/2512.12059)
*Luke Bhan,Hanyu Zhang,Andrew Gordon Wilson,Michael W. Mahoney,Chuck Arvin*

Main category: cs.AI

TL;DR: LLMs show promise for automated forecast monitoring, achieving near-human performance in detecting poor forecasts and incorporating contextual signals effectively.


<details>
  <summary>Details</summary>
Motivation: Monitoring forecasting systems is critical for customer satisfaction, profitability, and operational efficiency in large-scale retail businesses.

Method: The paper systematically evaluates the ability of LLMs to assess time series forecast quality through three experiments on synthetic and real-world forecasting data.

Result: LLMs can reliably detect and critique poor forecasts, with the best-performing model achieving an F1 score of 0.88. Multi-modal LLMs effectively incorporate unstructured contextual signals, and techniques succeed in identifying inaccurate forecasts on the real-world M5 dataset.

Conclusion: LLMs, even without domain-specific fine-tuning, may provide a viable and scalable option for automated forecast monitoring and evaluation.

Abstract: Monitoring forecasting systems is critical for customer satisfaction, profitability, and operational efficiency in large-scale retail businesses. We propose The Forecast Critic, a system that leverages Large Language Models (LLMs) for automated forecast monitoring, taking advantage of their broad world knowledge and strong ``reasoning'' capabilities. As a prerequisite for this, we systematically evaluate the ability of LLMs to assess time series forecast quality, focusing on three key questions. (1) Can LLMs be deployed to perform forecast monitoring and identify obviously unreasonable forecasts? (2) Can LLMs effectively incorporate unstructured exogenous features to assess what a reasonable forecast looks like? (3) How does performance vary across model sizes and reasoning capabilities, measured across state-of-the-art LLMs? We present three experiments, including on both synthetic and real-world forecasting data. Our results show that LLMs can reliably detect and critique poor forecasts, such as those plagued by temporal misalignment, trend inconsistencies, and spike errors. The best-performing model we evaluated achieves an F1 score of 0.88, somewhat below human-level performance (F1 score: 0.97). We also demonstrate that multi-modal LLMs can effectively incorporate unstructured contextual signals to refine their assessment of the forecast. Models correctly identify missing or spurious promotional spikes when provided with historical context about past promotions (F1 score: 0.84). Lastly, we demonstrate that these techniques succeed in identifying inaccurate forecasts on the real-world M5 time series dataset, with unreasonable forecasts having an sCRPS at least 10% higher than that of reasonable forecasts. These findings suggest that LLMs, even without domain-specific fine-tuning, may provide a viable and scalable option for automated forecast monitoring and evaluation.

</details>


### [219] [Reliable Policy Iteration: Performance Robustness Across Architecture and Environment Perturbations](https://arxiv.org/abs/2512.12088)
*S. R. Eshwar,Aniruddha Mukherjee,Kintan Saha,Krishna Agarwal,Gugan Thoppe,Aditya Gopalan,Gal Dalal*

Main category: cs.AI

TL;DR: RPI在经典控制任务中表现优于其他深度强化学习方法，具有更高的可靠性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 恢复策略迭代在函数逼近设置中的单调性价值估计特性，并评估其在实际任务中的鲁棒性。

Method: 通过评估RPI在CartPole和Inverted Pendulum两个经典控制任务中的表现，比较了其与DQN、Double DQN、DDPG、TD3和PPO的性能。

Result: RPI在训练早期即达到接近最优的性能，并能在训练过程中保持这一策略。

Conclusion: RPI展现了作为更可靠替代方案的潜力，解决了深度强化学习方法中常见的样本效率低、训练不稳定和超参数敏感性问题。

Abstract: In a recent work, we proposed Reliable Policy Iteration (RPI), that restores policy iteration's monotonicity-of-value-estimates property to the function approximation setting. Here, we assess the robustness of RPI's empirical performance on two classical control tasks -- CartPole and Inverted Pendulum -- under changes to neural network and environmental parameters. Relative to DQN, Double DQN, DDPG, TD3, and PPO, RPI reaches near-optimal performance early and sustains this policy as training proceeds. Because deep RL methods are often hampered by sample inefficiency, training instability, and hyperparameter sensitivity, our results highlight RPI's promise as a more reliable alternative.

</details>


### [220] [Rethinking Label Consistency of In-Context Learning: An Implicit Transductive Label Propagation Perspective](https://arxiv.org/abs/2512.12175)
*Haoyang Chen,Richong Zhang,Junfan Chen*

Main category: cs.AI

TL;DR: 本文提出TopK-SD方法，通过结合语义和标签信息选择一致标签的演示，提升ICL性能，为理解其机制提供新视角。


<details>
  <summary>Details</summary>
Motivation: 现有方法在演示选择中未能保证标签一致性，基于贝叶斯视角和转导标签传播的重新思考，认为相似演示应引导查询概念，且标签一致性是关键。

Method: 提出了一种数据合成方法，结合语义和标签信息，使用TopK-SD采样选择具有一致标签的演示。

Result: TopK-SD在多个基准测试中优于原始TopK采样方法。

Conclusion: 本文提出了TopK-SD方法，通过结合语义和标签信息选择具有一致标签的演示，优于传统TopK采样方法，为理解ICL的工作机制提供了新视角。

Abstract: Large language models (LLMs) perform in-context learning (ICL) with minimal supervised examples, which benefits various natural language processing (NLP) tasks. One of the critical research focus is the selection of prompt demonstrations. Current approaches typically employ retrieval models to select the top-K most semantically similar examples as demonstrations. However, we argue that existing methods are limited since the label consistency is not guaranteed during demonstration selection. Our cognition derives from the Bayesian view of ICL and our rethinking of ICL from the transductive label propagation perspective. We treat ICL as a transductive learning method and incorporate latent concepts from Bayesian view and deduce that similar demonstrations guide the concepts of query, with consistent labels serving as estimates. Based on this understanding, we establish a label propagation framework to link label consistency with propagation error bounds. To model label consistency, we propose a data synthesis method, leveraging both semantic and label information, and use TopK sampling with Synthetic Data (TopK-SD) to acquire demonstrations with consistent labels. TopK-SD outperforms original TopK sampling on multiple benchmarks. Our work provides a new perspective for understanding the working mechanisms within ICL.

</details>


### [221] [Floorplan2Guide: LLM-Guided Floorplan Parsing for BLV Indoor Navigation](https://arxiv.org/abs/2512.12177)
*Aydin Ayanzadeh,Tim Oates*

Main category: cs.AI

TL;DR: Floorplan2Guide利用基础模型和LLM，将平面图转换为知识图谱并生成导航指令，显著提升视障用户的室内导航准确率。


<details>
  <summary>Details</summary>
Motivation: 解决视障用户在动态环境中室内导航的挑战，克服现有基础设施依赖型系统的局限性。

Method: 利用基础模型将平面图转换为可导航的知识图谱，并结合LLM提取空间信息，减少手动预处理的需求。实验采用少样本学习（few-shot learning）进行模拟和真实环境评估。

Result: Claude 3.7 Sonnet在短、中、长路径上的导航准确率分别为92.31%、76.92%和61.54%。基于图的空间结构成功率比直接视觉推理高15.4%。

Conclusion: Floorplan2Guide通过结合基础模型和大型语言模型（LLM），显著提升了室内导航的准确性和实用性，特别是在动态环境中为视障用户提供了更精确的导航解决方案。

Abstract: Indoor navigation remains a critical challenge for people with visual impairments. The current solutions mainly rely on infrastructure-based systems, which limit their ability to navigate safely in dynamic environments. We propose a novel navigation approach that utilizes a foundation model to transform floor plans into navigable knowledge graphs and generate human-readable navigation instructions. Floorplan2Guide integrates a large language model (LLM) to extract spatial information from architectural layouts, reducing the manual preprocessing required by earlier floorplan parsing methods. Experimental results indicate that few-shot learning improves navigation accuracy in comparison to zero-shot learning on simulated and real-world evaluations. Claude 3.7 Sonnet achieves the highest accuracy among the evaluated models, with 92.31%, 76.92%, and 61.54% on the short, medium, and long routes, respectively, under 5-shot prompting of the MP-1 floor plan. The success rate of graph-based spatial structure is 15.4% higher than that of direct visual reasoning among all models, which confirms that graphical representation and in-context learning enhance navigation performance and make our solution more precise for indoor navigation of Blind and Low Vision (BLV) users.

</details>


### [222] [TA-KAND: Two-stage Attention Triple Enhancement and U-KAN based Diffusion For Few-shot Knowledge Graph Completion](https://arxiv.org/abs/2512.12182)
*Xinyu Gao*

Main category: cs.AI

TL;DR: 提出一种少样本知识图谱补全框架，结合两阶段注意力三元增强器和U-KAN扩散模型，实验显示其性能最优。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据的异构性和多面性导致关系分布长尾，现有方法未能充分利用图的邻域信息或忽略对比信号的分布特征。

Method: 采用生成表示视角，结合两阶段注意力三元增强器和基于U-KAN的扩散模型。

Result: 在两个公开数据集上的实验表明，该方法达到了最新的最优性能。

Conclusion: 本文提出的集成两阶段注意力三元增强器与U-KAN扩散模型的少样本知识图谱补全框架，在公开数据集上取得了最先进的结果。

Abstract: Knowledge Graphs (KGs), thanks to their concise and efficient triple-based structure, have been widely applied in intelligent question answering, recommender systems and other domains. However, the heterogeneous and multifaceted nature of real-world data inevitably renders the distribution of relations long-tailed, making it crucial to complete missing facts with limited samples. Previous studies mainly based on metric matching or meta learning, yet they either fail to fully exploit neighborhood information in graph or overlook the distributional characteristics of contrastive signals. In this paper, we re-examine the problem from a perspective of generative representation and propose a few-shot knowledge graph completion framework that integrates two-stage attention triple enhancer with U-KAN based diffusion model. Extensive experiments on two public datasets show that our method achieve new state-of-the-art results.

</details>


### [223] [A Geometric Theory of Cognition](https://arxiv.org/abs/2512.12225)
*Laha Ale*

Main category: cs.AI

TL;DR: 论文提出了一个统一的几何框架，通过黎曼流形和梯度流解释了多样化的认知过程，为认知科学和人工智能提供了新的理论基础。


<details>
  <summary>Details</summary>
Motivation: 为了解决认知科学中不同认知能力通常由不同计算理论解释的问题，论文试图建立一个统一的数学框架。

Method: 论文使用了一个可微分流形上的黎曼度量来表示认知状态，结合了预测准确性、结构简约性、任务效用和规范性要求，通过黎曼梯度流来描述认知的动态过程。

Result: 论文展示了经典的双过程效应（快速直觉反应和慢速审慎推理）如何从度量诱导的各向异性中自然产生，并通过模拟验证了这些行为的特征。

Conclusion: 该论文提出了一个统一的几何框架，通过单一的几何原则解释了多样化的认知过程，为认知科学和人工智能的发展提供了新的理论基础。

Abstract: Human cognition spans perception, memory, intuitive judgment, deliberative reasoning, action selection, and social inference, yet these capacities are often explained through distinct computational theories. Here we present a unified mathematical framework in which diverse cognitive processes emerge from a single geometric principle. We represent the cognitive state as a point on a differentiable manifold endowed with a learned Riemannian metric that encodes representational constraints, computational costs, and structural relations among cognitive variables. A scalar cognitive potential combines predictive accuracy, structural parsimony, task utility, and normative or logical requirements. Cognition unfolds as the Riemannian gradient flow of this potential, providing a universal dynamical law from which a broad range of psychological phenomena arise. Classical dual-process effects--rapid intuitive responses and slower deliberative reasoning--emerge naturally from metric-induced anisotropies that generate intrinsic time-scale separations and geometric phase transitions, without invoking modular or hybrid architectures. We derive analytical conditions for these regimes and demonstrate their behavioural signatures through simulations of canonical cognitive tasks. Together, these results establish a geometric foundation for cognition and suggest guiding principles for the development of more general and human-like artificial intelligence systems.

</details>


### [224] [A Multi-Axial Mindset for Ontology Design Lessons from Wikidata's Polyhierarchical Structure](https://arxiv.org/abs/2512.12260)
*Ege Atacan Doğan,Peter F. Patel-Schneider*

Main category: cs.AI

TL;DR: Wikidata采用多元层次和多轴设计，替代传统的单一分类法，支持协作和动态演进的知识图谱。


<details>
  <summary>Details</summary>
Motivation: 探讨Wikidata如何通过不强制单一基础分类法，而是允许多种分类轴共存于实体根类下，来影响知识图谱的结构。

Method: 分析了Wikidata的多层次和多轴结构设计。

Result: Wikidata的设计支持了协作和动态演进的知识图谱构建。

Conclusion: Wikidata的多元层次和多轴设计为知识图谱提供了一种可扩展和模块化的构建方法，特别适合协作和不断演进的知识体系。

Abstract: Traditional ontology design emphasizes disjoint and exhaustive top-level distinctions such as continuant vs. occurrent, abstract vs. concrete, or type vs. instance. These distinctions are used to structure unified hierarchies where every entity is classified under a single upper-level category. Wikidata, by contrast, does not enforce a singular foundational taxonomy. Instead, it accommodates multiple classification axes simultaneously under the shared root class entity. This paper analyzes the structural implications of Wikidata's polyhierarchical and multi-axial design. The Wikidata architecture enables a scalable and modular approach to ontology construction, especially suited to collaborative and evolving knowledge graphs.

</details>


### [225] [Quantum-Aware Generative AI for Materials Discovery: A Framework for Robust Exploration Beyond DFT Biases](https://arxiv.org/abs/2512.12288)
*Mahule Roy,Guillaume Lambard*

Main category: cs.AI

TL;DR: 本文提出了一种量子感知的生成AI框架，通过多保真度学习和主动验证，克服了传统模型在强关联系统中的局限性，显著提高了材料发现的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 传统生成模型在材料发现中主要依赖于密度泛函理论（DFT）的近似交换相关泛函，这导致模型继承了DFT在强关联系统中的系统性失败，从而产生探索偏差和无法发现DFT预测定性错误的材料。

Method: 采用基于扩散的生成器，结合量子力学描述符，以及使用等变神经网络势的验证器，训练于跨越多个理论层次（PBE、SCAN、HSE06、CCSD(T)）的分层数据集。通过实施稳健的主动学习循环，量化并针对低保真度和高保真度预测之间的分歧。

Result: 与仅基于DFT的基线相比，该框架在高分歧区域（如关联氧化物）中成功识别潜在稳定候选材料的能力提高了3-5倍，同时保持了计算可行性。

Conclusion: 本文提出了一个量子感知的生成AI框架，通过多保真度学习和主动验证的紧密结合，系统地解决了传统生成模型在强关联系统中的局限性。该框架显著提高了在高分歧区域（如关联氧化物）中成功识别潜在稳定候选材料的能力，同时保持了计算可行性。

Abstract: Conventional generative models for materials discovery are predominantly trained and validated using data from Density Functional Theory (DFT) with approximate exchange-correlation functionals. This creates a fundamental bottleneck: these models inherit DFT's systematic failures for strongly correlated systems, leading to exploration biases and an inability to discover materials where DFT predictions are qualitatively incorrect. We introduce a quantum-aware generative AI framework that systematically addresses this limitation through tight integration of multi-fidelity learning and active validation. Our approach employs a diffusion-based generator conditioned on quantum-mechanical descriptors and a validator using an equivariant neural network potential trained on a hierarchical dataset spanning multiple levels of theory (PBE, SCAN, HSE06, CCSD(T)). Crucially, we implement a robust active learning loop that quantifies and targets the divergence between low- and high-fidelity predictions. We conduct comprehensive ablation studies to deconstruct the contribution of each component, perform detailed failure mode analysis, and benchmark our framework against state-of-the-art generative models (CDVAE, GNoME, DiffCSP) across several challenging material classes. Our results demonstrate significant practical gains: a 3-5x improvement in successfully identifying potentially stable candidates in high-divergence regions (e.g., correlated oxides) compared to DFT-only baselines, while maintaining computational feasibility. This work provides a rigorous, transparent framework for extending the effective search space of computational materials discovery beyond the limitations of single-fidelity models.

</details>


### [226] [Entropy Collapse: A Universal Failure Mode of Intelligent Systems](https://arxiv.org/abs/2512.12381)
*Truong Xuan Khanh,Truong Quynh Hoa*

Main category: cs.AI

TL;DR: 论文提出熵崩溃是智能系统的普遍动态失败模式，分析其临界阈值和动态特性，并强调熵感知设计对维持适应性的重要性。


<details>
  <summary>Details</summary>
Motivation: 论文动机源于观察到智能系统在提高智能时常常导致适应性下降和意外失败，旨在识别熵崩溃作为普遍动态失败模式。

Method: 论文方法包括在最小领域无关假设下，展示智能系统从高熵适应状态到低熵崩溃状态的急剧转变，并通过最小模拟验证更新机制的普遍性。

Result: 论文结果表明，智能系统会经历从高熵适应状态到低熵崩溃状态的急剧转变，并通过分析建立了临界阈值、动态不可逆性和吸引子结构。

Conclusion: 论文结论指出，智能系统的崩溃是智能的结构性成本，强调了熵感知设计原则对于维持长期适应性的重要性。

Abstract: Intelligent systems are widely assumed to improve through learning, coordination, and optimization. However, across domains -- from artificial intelligence to economic institutions and biological evolution -- increasing intelligence often precipitates paradoxical degradation: systems become rigid, lose adaptability, and fail unexpectedly.
  We identify \emph{entropy collapse} as a universal dynamical failure mode arising when feedback amplification outpaces bounded novelty regeneration. Under minimal domain-agnostic assumptions, we show that intelligent systems undergo a sharp transition from high-entropy adaptive regimes to low-entropy collapsed regimes. Collapse is formalized as convergence toward a stable low-entropy manifold, not a zero-entropy state, implying a contraction of effective adaptive dimensionality rather than loss of activity or scale.
  We analytically establish critical thresholds, dynamical irreversibility, and attractor structure and demonstrate universality across update mechanisms through minimal simulations. This framework unifies diverse phenomena -- model collapse in AI, institutional sclerosis in economics, and genetic bottlenecks in evolution -- as manifestations of the same underlying process.
  By reframing collapse as a structural cost of intelligence, our results clarify why late-stage interventions systematically fail and motivate entropy-aware design principles for sustaining long-term adaptability in intelligent systems.
  \noindent\textbf{Keywords:} entropy collapse; intelligent systems; feedback amplification; phase transitions; effective dimensionality; complex systems; model collapse; institutional sclerosis

</details>


### [227] [Feeling the Strength but Not the Source: Partial Introspection in LLMs](https://arxiv.org/abs/2512.12411)
*Ely Hahami,Lavik Jain,Ishaan Sinha*

Main category: cs.AI

TL;DR: 研究验证了语言模型的自省能力，发现其虽然能有效计算内部表示，但自省结果对提示敏感且适用范围有限。


<details>
  <summary>Details</summary>
Motivation: 测试Anthropic关于前沿模型能够检测和命名注入“概念”的稳健性，并探索自省能力的范围和局限性。

Method: 首先复现了Anthropic的多轮“涌现自省”结果，然后在Meta-Llama-3.1-8B-Instruct模型上系统性地改变了推理提示，并测试了部分自省的不同任务。

Result: 模型在Anthropic原始流程下识别并命名注入概念的概率为20%，与Anthropic报告的数据完全匹配；在部分自省任务中，模型对注入概念向量强度的分类准确率高达70%，远高于25%的随机基线。

Conclusion: 研究结果支持了Anthropic的观点，即语言模型在自省过程中有效地计算了其基线内部表示的函数，但这些自我报告关于表示的内容是狭窄且对提示敏感的。

Abstract: Recent work from Anthropic claims that frontier models can sometimes detect and name injected "concepts" represented as activation directions. We test the robustness of these claims. First, we reproduce Anthropic's multi-turn "emergent introspection" result on Meta-Llama-3.1-8B-Instruct, finding that the model identifies and names the injected concept 20 percent of the time under Anthropic's original pipeline, exactly matching their reported numbers and thus showing that introspection is not exclusive to very large or capable models. Second, we systematically vary the inference prompt and find that introspection is fragile: performance collapses on closely related tasks such as multiple-choice identification of the injected concept or different prompts of binary discrimination of whether a concept was injected at all. Third, we identify a contrasting regime of partial introspection: the same model can reliably classify the strength of the coefficient of a normalized injected concept vector (as weak / moderate / strong / very strong) with up to 70 percent accuracy, far above the 25 percent chance baseline. Together, these results provide more evidence for Anthropic's claim that language models effectively compute a function of their baseline, internal representations during introspection; however, these self-reports about those representations are narrow and prompt-sensitive. Our code is available at https://github.com/elyhahami18/CS2881-Introspection.

</details>


### [228] [Understanding Critical Thinking in Generative Artificial Intelligence Use: Development, Validation, and Correlates of the Critical Thinking in AI Use Scale](https://arxiv.org/abs/2512.12413)
*Gabriel R. Lau,Wei Yan Low,Louis Tay,Ysabel Guevarra,Dragan Gašević,Andree Hartanto*

Main category: cs.AI

TL;DR: 研究开发了AI使用批判性思维量表，验证了其有效性，并发现批判性思维与人格特质和AI使用行为相关。


<details>
  <summary>Details</summary>
Motivation: 生成式AI工具日益融入日常工作和学习，但其流畅性、不透明性和易产生幻觉的特性要求用户必须批判性评估AI输出，而非盲目接受。

Method: 通过六项研究（N = 1365），开发并验证了13项的AI使用批判性思维量表，并绘制了其法理网络。研究1生成并内容验证了量表项目。研究2支持了三因素结构（验证、动机和反思）。研究3、4和5确认了这一高阶模型，展示了内部一致性和重测信度、强因子载荷、性别不变性以及收敛和区分效度。研究3和4进一步揭示，AI使用中的批判性思维与开放性、外向性、积极特质情感和AI使用频率呈正相关。研究6展示了量表的准则效度。

Result: AI使用中的批判性思维与开放性、外向性、积极特质情感和AI使用频率呈正相关。更高的批判性思维分数预测了更频繁和多样化的验证策略、在新颖且自然的ChatGPT驱动的事实核查任务中更高的真实性判断准确性，以及对负责任AI的更深反思。

Conclusion: 本研究澄清了人们为何及如何对生成式AI输出进行监督，并提供了一个经过验证的量表和生态基础的任务范式，以支持理论测试、跨群体和纵向研究。

Abstract: Generative AI tools are increasingly embedded in everyday work and learning, yet their fluency, opacity, and propensity to hallucinate mean that users must critically evaluate AI outputs rather than accept them at face value. The present research conceptualises critical thinking in AI use as a dispositional tendency to verify the source and content of AI-generated information, to understand how models work and where they fail, and to reflect on the broader implications of relying on AI. Across six studies (N = 1365), we developed and validated the 13-item critical thinking in AI use scale and mapped its nomological network. Study 1 generated and content-validated scale items. Study 2 supported a three-factor structure (Verification, Motivation, and Reflection). Studies 3, 4, and 5 confirmed this higher-order model, demonstrated internal consistency and test-retest reliability, strong factor loadings, sex invariance, and convergent and discriminant validity. Studies 3 and 4 further revealed that critical thinking in AI use was positively associated with openness, extraversion, positive trait affect, and frequency of AI use. Lastly, Study 6 demonstrated criterion validity of the scale, with higher critical thinking in AI use scores predicting more frequent and diverse verification strategies, greater veracity-judgement accuracy in a novel and naturalistic ChatGPT-powered fact-checking task, and deeper reflection about responsible AI. Taken together, the current work clarifies why and how people exercise oversight over generative AI outputs and provides a validated scale and ecologically grounded task paradigm to support theory testing, cross-group, and longitudinal research on critical engagement with generative AI outputs.

</details>


### [229] [AI Transparency Atlas: Framework, Scoring, and Real-Time Model Card Evaluation Pipeline](https://arxiv.org/abs/2512.12443)
*Akhmadillo Mamirov,Faiaz Azmain,Hanyu Wang*

Main category: cs.AI

TL;DR: 论文分析了AI模型文档的碎片化和不一致问题，提出了加权透明度框架和自动化评估方法，发现前沿实验室合规性较高，但安全关键领域存在显著缺陷。


<details>
  <summary>Details</summary>
Motivation: AI模型文档分散在各个平台且结构不一致，导致政策制定者、审计员和用户无法可靠评估安全声明、数据来源和版本级变更。

Method: 使用欧盟AI法案附件IV和斯坦福透明度指数作为基准，开发了一个加权透明度框架，并实施了自动化多智能体管道来提取文档并通过基于LLM的共识评分完整性。

Result: 评估显示，前沿实验室（xAI、Microsoft、Anthropic）的合规性约为80%，而大多数提供者低于60%。安全关键类别（如欺骗行为、幻觉和儿童安全评估）的缺陷最为显著。

Conclusion: 该论文提出了一个加权透明度框架，并通过自动化多智能体管道评估了50个模型的文档完整性，揭示了系统性差距。前沿实验室的合规性约为80%，而大多数提供者低于60%。安全关键类别显示出最大的缺陷。

Abstract: AI model documentation is fragmented across platforms and inconsistent in structure, preventing policymakers, auditors, and users from reliably assessing safety claims, data provenance, and version-level changes. We analyzed documentation from five frontier models (Gemini 3, Grok 4.1, Llama 4, GPT-5, and Claude 4.5) and 100 Hugging Face model cards, identifying 947 unique section names with extreme naming variation. Usage information alone appeared under 97 distinct labels. Using the EU AI Act Annex IV and the Stanford Transparency Index as baselines, we developed a weighted transparency framework with 8 sections and 23 subsections that prioritizes safety-critical disclosures (Safety Evaluation: 25%, Critical Risk: 20%) over technical specifications. We implemented an automated multi-agent pipeline that extracts documentation from public sources and scores completeness through LLM-based consensus. Evaluating 50 models across vision, multimodal, open-source, and closed-source systems cost less than $3 in total and revealed systematic gaps. Frontier labs (xAI, Microsoft, Anthropic) achieve approximately 80% compliance, while most providers fall below 60%. Safety-critical categories show the largest deficits: deception behaviors, hallucinations, and child safety evaluations account for 148, 124, and 116 aggregate points lost, respectively, across all evaluated models.

</details>


### [230] [MetaHGNIE: Meta-Path Induced Hypergraph Contrastive Learning in Heterogeneous Knowledge Graphs](https://arxiv.org/abs/2512.12477)
*Jiawen Chen,Yanyan He,Qi Shao,Mengli Wei,Duxin Chen,Wenwu Yu,Yanlong Zhao*

Main category: cs.AI

TL;DR: MetaHGNIE是一种基于元路径的超图对比学习框架，通过高阶建模和跨模态对齐提升异构知识图谱节点重要性估计效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽略多实体间的高阶依赖关系，且独立处理结构和语义信号，导致跨模态整合效果不佳。MetaHGNIE旨在解决这些问题。

Method: MetaHGNIE通过元路径序列构建高阶知识图谱，利用类型化超边捕捉多实体关系上下文，结合局部注意力聚合结构依赖，并通过超图变换器编码语义表示，最后通过对比学习和辅助监督实现跨模态融合。

Result: 在基准NIE数据集上的实验表明，MetaHGNIE consistently outperforms state-of-the-art baselines。

Conclusion: MetaHGNIE通过显式建模高阶交互和跨模态对齐，在异构知识图谱中表现出色，超越了现有基线方法。

Abstract: Node importance estimation (NIE) in heterogeneous knowledge graphs is a critical yet challenging task, essential for applications such as recommendation, knowledge reasoning, and question answering. Existing methods often rely on pairwise connections, neglecting high-order dependencies among multiple entities and relations, and they treat structural and semantic signals independently, hindering effective cross-modal integration. To address these challenges, we propose MetaHGNIE, a meta-path induced hypergraph contrastive learning framework for disentangling and aligning structural and semantic information. MetaHGNIE constructs a higher-order knowledge graph via meta-path sequences, where typed hyperedges capture multi-entity relational contexts. Structural dependencies are aggregated with local attention, while semantic representations are encoded through a hypergraph transformer equipped with sparse chunking to reduce redundancy. Finally, a multimodal fusion module integrates structural and semantic embeddings under contrastive learning with auxiliary supervision, ensuring robust cross-modal alignment. Extensive experiments on benchmark NIE datasets demonstrate that MetaHGNIE consistently outperforms state-of-the-art baselines. These results highlight the effectiveness of explicitly modeling higher-order interactions and cross-modal alignment in heterogeneous knowledge graphs. Our code is available at https://github.com/SEU-WENJIA/DualHNIE

</details>


### [231] [SafeGen: Embedding Ethical Safeguards in Text-to-Image Generation](https://arxiv.org/abs/2512.12501)
*Dang Phuong Nam,Nguyen Kieu,Pham Thanh Hieu*

Main category: cs.AI

TL;DR: SafeGen是一个将伦理保障嵌入文本到图像生成流程的框架，通过BGE-M3和Hyper-SD组件，平衡创意自由与伦理责任，并在定量和案例研究中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在创意表达、教育和研究中提供了前所未有的机会，但也带来了双重用途困境，如放大社会偏见、产生高保真虚假信息和侵犯知识产权。

Method: SafeGen整合了两个互补组件：BGE-M3（一个微调的文本分类器，用于过滤有害或误导性提示）和Hyper-SD（一个优化的扩散模型，用于生成高保真、语义对齐的图像）。

Result: 定量评估显示，Hyper-SD实现了IS=3.52、FID=22.08和SSIM=0.79，BGE-M3的F1-Score为0.81。案例研究展示了SafeGen在阻止不安全提示、生成包容性教学材料和加强学术诚信方面的实际影响。

Conclusion: SafeGen框架成功地将伦理保障嵌入文本到图像的生成流程中，证明了创意自由与伦理责任可以在单一工作流中协调。

Abstract: Generative Artificial Intelligence (AI) has created unprecedented opportunities for creative expression, education, and research. Text-to-image systems such as DALL.E, Stable Diffusion, and Midjourney can now convert ideas into visuals within seconds, but they also present a dual-use dilemma, raising critical ethical concerns: amplifying societal biases, producing high-fidelity disinformation, and violating intellectual property. This paper introduces SafeGen, a framework that embeds ethical safeguards directly into the text-to-image generation pipeline, grounding its design in established principles for Trustworthy AI. SafeGen integrates two complementary components: BGE-M3, a fine-tuned text classifier that filters harmful or misleading prompts, and Hyper-SD, an optimized diffusion model that produces high fidelity, semantically aligned images. Built on a curated multilingual (English- Vietnamese) dataset and a fairness-aware training process, SafeGen demonstrates that creative freedom and ethical responsibility can be reconciled within a single workflow. Quantitative evaluations confirm its effectiveness, with Hyper-SD achieving IS = 3.52, FID = 22.08, and SSIM = 0.79, while BGE-M3 reaches an F1-Score of 0.81. An ablation study further validates the importance of domain-specific fine-tuning for both modules. Case studies illustrate SafeGen's practical impact in blocking unsafe prompts, generating inclusive teaching materials, and reinforcing academic integrity.

</details>


### [232] [KidsArtBench: Multi-Dimensional Children's Art Evaluation with Attribute-Aware MLLMs](https://arxiv.org/abs/2512.12503)
*Mingrui Ye,Chanjin Zheng,Zengyi Yu,Chenyu Xiang,Zhixue Zhao,Zheng Yuan,Helen Yannakoudakis*

Main category: cs.AI

TL;DR: KidsArtBench是一个针对儿童艺术作品的评估基准，结合多维度标注和专家反馈，提出属性特定的多LoRA方法，显著提升MLLMs的评估性能。


<details>
  <summary>Details</summary>
Motivation: 现有的MLLMs在艺术表达评估方面能力有限，美学概念抽象且开放，多模态艺术作品标注稀缺。KidsArtBench旨在填补这一空白，专注于儿童艺术作品，提供多维度标注和专家反馈。

Method: 提出了属性特定的多LoRA方法，每个属性对应评分标准中的不同评估维度（如现实主义、想象力），并采用回归感知微调（RAFT）使预测与有序尺度对齐。

Result: 在Qwen2.5-VL-7B模型上，该方法将相关性从0.468提升至0.653，尤其在感知维度上提升显著，缩小了高阶属性的差距。

Conclusion: 通过KidsArtBench基准和属性特定的多LoRA方法，结合回归感知微调（RAFT），显著提升了MLLMs在儿童艺术作品评估中的表现，为教育AI的持续进步提供了严谨的测试平台。

Abstract: Multimodal Large Language Models (MLLMs) show remarkable progress across many visual-language tasks; however, their capacity to evaluate artistic expression remains limited. Aesthetic concepts are inherently abstract and open-ended, and multimodal artwork annotations are scarce. We introduce KidsArtBench, a new benchmark of over 1k children's artworks (ages 5-15) annotated by 12 expert educators across 9 rubric-aligned dimensions, together with expert comments for feedback. Unlike prior aesthetic datasets that provide single scalar scores on adult imagery, KidsArtBench targets children's artwork and pairs multi-dimensional annotations with comment supervision to enable both ordinal assessment and formative feedback. Building on this resource, we propose an attribute-specific multi-LoRA approach, where each attribute corresponds to a distinct evaluation dimension (e.g., Realism, Imagination) in the scoring rubric, with Regression-Aware Fine-Tuning (RAFT) to align predictions with ordinal scales. On Qwen2.5-VL-7B, our method increases correlation from 0.468 to 0.653, with the largest gains on perceptual dimensions and narrowed gaps on higher-order attributes. These results show that educator-aligned supervision and attribute-aware training yield pedagogically meaningful evaluations and establish a rigorous testbed for sustained progress in educational AI. We release data and code with ethics documentation.

</details>


### [233] [World Models Unlock Optimal Foraging Strategies in Reinforcement Learning Agents](https://arxiv.org/abs/2512.12548)
*Yesid Fonseca,Manuel S. Ríos,Nicanor Quijano,Luis F. Giraldo*

Main category: cs.AI

TL;DR: 研究表明，具备学习世界模型的人工觅食者会自然收敛到与边际价值定理一致的战略，基于模型的强化学习代理通过预测能力而非单纯的奖励最大化驱动高效的补丁离开行为。


<details>
  <summary>Details</summary>
Motivation: 探索生物觅食者中促进最优补丁觅食决策的计算机制。

Method: 使用基于模型的强化学习代理，该代理获取环境的简约预测表示。

Result: 基于模型的代理展现出与许多生物对应物相似的决策模式，表明预测世界模型可以作为AI系统中更可解释和生物学基础决策的基础。

Conclusion: 研究强调了生态最优原则在推动可解释和自适应AI发展中的价值。

Abstract: Patch foraging involves the deliberate and planned process of determining the optimal time to depart from a resource-rich region and investigate potentially more beneficial alternatives. The Marginal Value Theorem (MVT) is frequently used to characterize this process, offering an optimality model for such foraging behaviors. Although this model has been widely used to make predictions in behavioral ecology, discovering the computational mechanisms that facilitate the emergence of optimal patch-foraging decisions in biological foragers remains under investigation. Here, we show that artificial foragers equipped with learned world models naturally converge to MVT-aligned strategies. Using a model-based reinforcement learning agent that acquires a parsimonious predictive representation of its environment, we demonstrate that anticipatory capabilities, rather than reward maximization alone, drive efficient patch-leaving behavior. Compared with standard model-free RL agents, these model-based agents exhibit decision patterns similar to many of their biological counterparts, suggesting that predictive world models can serve as a foundation for more explainable and biologically grounded decision-making in AI systems. Overall, our findings highlight the value of ecological optimality principles for advancing interpretable and adaptive AI.

</details>


### [234] [Large Language Newsvendor: Decision Biases and Cognitive Mechanisms](https://arxiv.org/abs/2512.12552)
*Jifei Liu,Zhi Chen,Yuanguang Zhong*

Main category: cs.AI

TL;DR: LLMs在高风险决策中会放大认知偏差，GPT-4因过度思考表现最差，管理者需选择合适模型并加强监督。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在高风险运营决策中复制和放大人类认知偏差的风险。

Method: 通过动态多轮实验测试GPT-4、GPT-4o和LLaMA-8B的五种决策偏差。

Result: LLMs显著放大了需求追逐等偏差，GPT-4因过度思考表现最不理性，而GPT-4o接近最优。

Conclusion: LLMs的认知偏差源于架构限制而非知识缺口，管理者应选择适合特定任务的模型，并采用结构化提示策略以提高决策可靠性。

Abstract: Problem definition: Although large language models (LLMs) are increasingly integrated into business decision making, their potential to replicate and even amplify human cognitive biases cautions a significant, yet not well-understood, risk. This is particularly critical in high-stakes operational contexts like supply chain management. To address this, we investigate the decision-making patterns of leading LLMs using the canonical newsvendor problem in a dynamic setting, aiming to identify the nature and origins of their cognitive biases. Methodology/results: Through dynamic, multi-round experiments with GPT-4, GPT-4o, and LLaMA-8B, we tested for five established decision biases. We found that LLMs consistently replicated the classic ``Too Low/Too High'' ordering bias and significantly amplified other tendencies like demand-chasing behavior compared to human benchmarks. Our analysis uncovered a ``paradox of intelligence'': the more sophisticated GPT-4 demonstrated the greatest irrationality through overthinking, while the efficiency-optimized GPT-4o performed near-optimally. Because these biases persist even when optimal formulas are provided, we conclude they stem from architectural constraints rather than knowledge gaps. Managerial implications: First, managers should select models based on the specific task, as our results show that efficiency-optimized models can outperform more complex ones on certain optimization problems. Second, the significant amplification of bias by LLMs highlights the urgent need for robust human-in-the-loop oversight in high-stakes decisions to prevent costly errors. Third, our findings suggest that designing structured, rule-based prompts is a practical and effective strategy for managers to constrain models' heuristic tendencies and improve the reliability of AI-assisted decisions.

</details>


### [235] [AgentSHAP: Interpreting LLM Agent Tool Importance with Monte Carlo Shapley Value Estimation](https://arxiv.org/abs/2512.12597)
*Miriam Horovicz*

Main category: cs.AI

TL;DR: AgentSHAP是首个基于Shapley值的工具重要性解释框架，适用于任何LLM代理，无需访问内部权重或梯度。


<details>
  <summary>Details</summary>
Motivation: 现有XAI方法无法解释工具层面的贡献，需要一种模型无关的框架来理解工具在LLM代理中的作用。

Method: 采用蒙特卡洛Shapley值方法，通过测试不同工具子集的代理响应来计算公平的重要性分数。

Result: 实验表明AgentSHAP能稳定生成重要性分数，准确识别关键工具，并区分相关与无关工具。

Conclusion: AgentSHAP 是首个基于博弈论Shapley值的工具重要性解释框架，为LLM代理中的工具使用提供了透明度和可解释性。

Abstract: LLM agents that use external tools can solve complex tasks, but understanding which tools actually contributed to a response remains a blind spot. No existing XAI methods address tool-level explanations. We introduce AgentSHAP, the first framework for explaining tool importance in LLM agents. AgentSHAP is model-agnostic: it treats the agent as a black box and works with any LLM (GPT, Claude, Llama, etc.) without needing access to internal weights or gradients. Using Monte Carlo Shapley values, AgentSHAP tests how an agent responds with different tool subsets and computes fair importance scores based on game theory. Our contributions are: (1) the first explainability method for agent tool attribution, grounded in Shapley values from game theory; (2) Monte Carlo sampling that reduces cost from O(2n) to practical levels; and (3) comprehensive experiments on API-Bank showing that AgentSHAP produces consistent scores across runs, correctly identifies which tools matter, and distinguishes relevant from irrelevant tools. AgentSHAP joins TokenSHAP (for tokens) and PixelSHAP (for image regions) to complete a family of Shapley-based XAI tools for modern generative AI. Code: https://github.com/GenAISHAP/TokenSHAP.

</details>


### [236] [Modular and Multi-Path-Aware Offline Benchmarking for Mobile GUI Agents](https://arxiv.org/abs/2512.12634)
*Youngmin Im,Byeongung Jo,Jaeyoung Wi,Seungwoo Baek,Tae Hoon Min,Joo Hyung Lee,Sangeun Oh,Insik Shin,Sunjae Lee*

Main category: cs.AI

TL;DR: MobiBench 是一个模块化、多路径感知的离线基准测试框架，解决了现有 GUI 代理评估的局限性，实验显示其高保真和可扩展性，并提供了关键设计指南。


<details>
  <summary>Details</summary>
Motivation: 当前 GUI 代理评估存在单路径离线基准测试和在线动态基准测试的局限性，无法公平评估替代操作或分析组件性能瓶颈。

Method: 提出了 MobiBench，首个模块化且多路径感知的离线基准测试框架，支持高保真、可扩展和可重复的评估。

Result: MobiBench 在实验中达到 94.72% 与人类评估者的一致性，同时揭示了模块级分析的关键见解，如技术多样性评估和最优模块配置。

Conclusion: MobiBench 提供了一个模块化、多路径感知的离线基准测试框架，显著提升了移动 GUI 代理评估的保真度、可扩展性和可重复性，同时揭示了当前技术的局限性和优化方向。

Abstract: Mobile GUI Agents, AI agents capable of interacting with mobile applications on behalf of users, have the potential to transform human computer interaction. However, current evaluation practices for GUI agents face two fundamental limitations. First, they either rely on single path offline benchmarks or online live benchmarks. Offline benchmarks using static, single path annotated datasets unfairly penalize valid alternative actions, while online benchmarks suffer from poor scalability and reproducibility due to the dynamic and unpredictable nature of live evaluation. Second, existing benchmarks treat agents as monolithic black boxes, overlooking the contributions of individual components, which often leads to unfair comparisons or obscures key performance bottlenecks. To address these limitations, we present MobiBench, the first modular and multi path aware offline benchmarking framework for mobile GUI agents that enables high fidelity, scalable, and reproducible evaluation entirely in offline settings. Our experiments demonstrate that MobiBench achieves 94.72 percent agreement with human evaluators, on par with carefully engineered online benchmarks, while preserving the scalability and reproducibility of static offline benchmarks. Furthermore, our comprehensive module level analysis uncovers several key insights, including a systematic evaluation of diverse techniques used in mobile GUI agents, optimal module configurations across model scales, the inherent limitations of current LFMs, and actionable guidelines for designing more capable and cost efficient mobile agents.

</details>


### [237] [Value-Aware Multiagent Systems](https://arxiv.org/abs/2512.12652)
*Nardine Osman*

Main category: cs.AI

TL;DR: 本文提出了价值感知AI的简化工程路线图，围绕学习人类价值观、价值对齐和可解释行为三大支柱，并展示了实际应用案例。


<details>
  <summary>Details</summary>
Motivation: 超越传统的价值对齐问题，提出更全面的价值感知AI概念，以指导AI系统的设计和应用。

Method: 通过形式语义学学习和表示人类价值观，确保个体代理和多代理系统的价值对齐，并提供基于价值的可解释行为。

Result: 展示了在现实生活领域中的应用实例，验证了价值感知AI路线图的可行性。

Conclusion: 本文提出了价值感知AI的概念，并提供了一个简化的工程路线图，围绕三个核心支柱展开，为未来AI系统的价值感知设计提供了方向。

Abstract: This paper introduces the concept of value awareness in AI, which goes beyond the traditional value-alignment problem. Our definition of value awareness presents us with a concise and simplified roadmap for engineering value-aware AI. The roadmap is structured around three core pillars: (1) learning and representing human values using formal semantics, (2) ensuring the value alignment of both individual agents and multiagent systems, and (3) providing value-based explainability on behaviour. The paper presents a selection of our ongoing work on some of these topics, along with applications to real-life domains.

</details>


### [238] [Synergizing Code Coverage and Gameplay Intent: Coverage-Aware Game Playtesting with LLM-Guided Reinforcement Learning](https://arxiv.org/abs/2512.12706)
*Enhong Mu,Minami Yoda,Yan Zhang,Mingyue Zhang,Yutaka Matsuno,Jialong Li*

Main category: cs.AI

TL;DR: SMART框架结合结构验证和功能验证，利用LLMs和强化学习，显著提升游戏自动化测试的覆盖率和任务完成率。


<details>
  <summary>Details</summary>
Motivation: 现有的自动化游戏测试方法存在结构覆盖与游戏上下文理解之间的割裂，无法有效应对频繁的内容更新需求。

Method: SMART利用大型语言模型（LLMs）解析抽象语法树（AST）差异并提取功能意图，构建上下文感知的混合奖励机制，指导强化学习代理逐步实现游戏目标并自适应探索修改的代码分支。

Result: 在Overcooked和Minecraft环境中，SMART实现了94%以上的修改代码分支覆盖率，是传统强化学习方法的两倍，同时保持98%的任务完成率。

Conclusion: SMART框架通过结合结构验证和功能验证，显著提升了自动化游戏测试的效率和效果，特别是在代码分支覆盖率和任务完成率方面表现优异。

Abstract: The widespread adoption of the "Games as a Service" model necessitates frequent content updates, placing immense pressure on quality assurance. In response, automated game testing has been viewed as a promising solution to cope with this demanding release cadence. However, existing automated testing approaches typically create a dichotomy: code-centric methods focus on structural coverage without understanding gameplay context, while player-centric agents validate high-level intent but often fail to cover specific underlying code changes. To bridge this gap, we propose SMART (Structural Mapping for Augmented Reinforcement Testing), a novel framework that synergizes structural verification and functional validation for game update testing. SMART leverages large language models (LLMs) to interpret abstract syntax tree (AST) differences and extract functional intent, constructing a context-aware hybrid reward mechanism. This mechanism guides reinforcement learning agents to sequentially fulfill gameplay goals while adaptively exploring modified code branches. We evaluate SMART on two environments, Overcooked and Minecraft. The results demonstrate that SMART significantly outperforms state-of-the-art baselines; it achieves over 94% branch coverage of modified code, nearly double that of traditional reinforcement learning methods, while maintaining a 98% task completion rate, effectively balancing structural comprehensiveness with functional correctness.

</details>


### [239] [Memoria: A Scalable Agentic Memory Framework for Personalized Conversational AI](https://arxiv.org/abs/2512.12686)
*Samarth Sarin,Lovepreet Singh,Bhaskarjit Sarmah,Dhagash Mehta*

Main category: cs.AI

TL;DR: Memoria是一个模块化记忆框架，通过动态摘要和知识图用户建模增强LLM的持久记忆能力，支持个性化对话AI。


<details>
  <summary>Details</summary>
Motivation: 代理记忆是大型语言模型（LLM）在扩展用户交互中保持连续性、个性化和长期上下文的关键能力，对部署真正交互式和自适应代理至关重要。

Method: Memoria框架整合了两个互补组件：动态会话级摘要和基于加权知识图（KG）的用户建模引擎，以增量方式捕获用户特征、偏好和行为模式作为结构化实体和关系。

Result: Memoria框架实现了短期对话连贯性和长期个性化，同时在现代LLM的令牌限制内运行，展示了如何通过桥接无状态LLM接口与代理记忆系统来实现可扩展、个性化的对话AI。

Conclusion: Memoria框架通过结合动态会话级摘要和基于加权知识图的用户建模引擎，为LLM提供了持久、可解释且上下文丰富的记忆能力，填补了无状态LLM接口与代理记忆系统之间的差距，为需要自适应和演进用户体验的行业应用提供了实用解决方案。

Abstract: Agentic memory is emerging as a key enabler for large language models (LLM) to maintain continuity, personalization, and long-term context in extended user interactions, critical capabilities for deploying LLMs as truly interactive and adaptive agents. Agentic memory refers to the memory that provides an LLM with agent-like persistence: the ability to retain and act upon information across conversations, similar to how a human would. We present Memoria, a modular memory framework that augments LLM-based conversational systems with persistent, interpretable, and context-rich memory. Memoria integrates two complementary components: dynamic session-level summarization and a weighted knowledge graph (KG)-based user modelling engine that incrementally captures user traits, preferences, and behavioral patterns as structured entities and relationships. This hybrid architecture enables both short-term dialogue coherence and long-term personalization while operating within the token constraints of modern LLMs. We demonstrate how Memoria enables scalable, personalized conversational artificial intelligence (AI) by bridging the gap between stateless LLM interfaces and agentic memory systems, offering a practical solution for industry applications requiring adaptive and evolving user experiences.

</details>


### [240] [WebOperator: Action-Aware Tree Search for Autonomous Agents in Web Environment](https://arxiv.org/abs/2512.12692)
*Mahir Labib Dihan,Tanzima Hashem,Mohammed Eunus Ali,Md Rizwan Parvez*

Main category: cs.AI

TL;DR: WebOperator是一个结合战略搜索和安全回溯的树搜索框架，显著提升LLM代理在Web任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理在部分可观测的Web环境中缺乏前瞻性，错误难以纠正，且现有树搜索方法缺乏安全回溯机制，无法处理不可逆动作。

Method: WebOperator采用最佳优先搜索策略，结合奖励估计和安全考量对动作进行排序，并引入健壮的回溯机制验证路径可行性。此外，通过多推理上下文生成动作候选集，过滤无效动作并合并语义等效动作。

Result: 在WebArena和WebVoyager上的实验表明，WebOperator（使用gpt-4o）在WebArena上达到54.6%的成功率。

Conclusion: WebOperator通过结合战略前瞻和安全执行，显著提升了LLM代理在部分可观测的Web环境中的表现，实现了54.6%的成功率。

Abstract: LLM-based agents often operate in a greedy, step-by-step manner, selecting actions solely based on the current observation without considering long-term consequences or alternative paths. This lack of foresight is particularly problematic in web environments, which are only partially observable-limited to browser-visible content (e.g., DOM and UI elements)-where a single misstep often requires complex and brittle navigation to undo. Without an explicit backtracking mechanism, agents struggle to correct errors or systematically explore alternative paths. Tree-search methods provide a principled framework for such structured exploration, but existing approaches lack mechanisms for safe backtracking, making them prone to unintended side effects. They also assume that all actions are reversible, ignoring the presence of irreversible actions-limitations that reduce their effectiveness in realistic web tasks. To address these challenges, we introduce WebOperator, a tree-search framework that enables reliable backtracking and strategic exploration. Our method incorporates a best-first search strategy that ranks actions by both reward estimates and safety considerations, along with a robust backtracking mechanism that verifies the feasibility of previously visited paths before replaying them, preventing unintended side effects. To further guide exploration, WebOperator generates action candidates from multiple, varied reasoning contexts to ensure diverse and robust exploration, and subsequently curates a high-quality action set by filtering out invalid actions pre-execution and merging semantically equivalent ones. Experimental results on WebArena and WebVoyager demonstrate the effectiveness of WebOperator. On WebArena, WebOperator achieves a state-of-the-art 54.6% success rate with gpt-4o, underscoring the critical advantage of integrating strategic foresight with safe execution.

</details>


### [241] [Personalized QoE Prediction: A Demographic-Augmented Machine Learning Framework for 5G Video Streaming Networks](https://arxiv.org/abs/2512.12736)
*Syeda Zunaira Ahmed,Hejab Tahira Beg,Maryam Khalid*

Main category: cs.AI

TL;DR: 论文提出了一种人口统计感知的机器学习框架，通过数据增强和多种模型评估，显著提升了5G视频流中QoE预测的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有QoE预测方法主要依赖有限的数据集并假设用户感知一致，这限制了其在异构现实环境中的适用性。

Method: 论文提出了一种人口统计感知的机器学习框架，用于个性化QoE预测。通过行为现实的基于人口统计的数据增强策略，将小型QoE数据集扩展了六倍，并评估了包括基于注意力的MLP和TabNet在内的多种机器学习模型。

Result: 实验结果表明，与基线模型相比，预测准确度在RMSE、MAE和R指标上有显著提升。TabNet在所有评估方法中表现最佳。

Conclusion: 该论文证实了基于人口统计的数据增强策略显著提升了QoE预测的鲁棒性，并为5G视频流网络中的个性化QoE感知智能提供了可扩展的方向。

Abstract: Quality of Experience (QoE) prediction is a critical component of modern multimedia systems, particularly for adaptive video streaming in 5G networks. Accurate QoE estimation enables intelligent resource management and supports user centric service delivery. Existing QoE prediction approaches primarily rely on limited datasets and assume uniform user perception, which restricts their applicability in heterogeneous real world environments.
  This paper proposes a demographic aware machine learning framework for personalized QoE prediction. We introduce a behaviorally realistic demographic based data augmentation strategy that expands a small QoE dataset six fold by modeling varying user sensitivities to streaming impairments such as rebuffering, bitrate variation, and quality degradation. Using the augmented dataset, we evaluate a comprehensive set of classical machine learning models alongside advanced deep learning architectures, including an attention-based MLP and TabNet.
  Experimental results demonstrate significant improvements in prediction accuracy across RMSE, MAE, and R metrics compared to baseline models. Among all evaluated approaches, TabNet achieves the strongest performance, benefiting from its inherent feature selection and attention mechanisms. The results confirm that demographic-aware augmentation substantially enhances QoE prediction robustness and provides a scalable direction for personalized QoE-aware intelligence in 5G video streaming networks.

</details>


### [242] [Causal Counterfactuals Reconsidered](https://arxiv.org/abs/2512.12804)
*Sander Beckers*

Main category: cs.AI

TL;DR: 本文提出了一种新的反事实概率语义，适用于Pearl语义无法处理的概率因果模型，并在Markov条件等限制下证明了其与其他提议的等价性。


<details>
  <summary>Details</summary>
Motivation: 现有的Pearl反事实语义无法处理某些概率因果模型，而这些模型在简单场景中也会出现。作者旨在填补这一空白，同时在Pearl与Dawid关于反事实的长期争论中寻求折衷。

Method: 作者通过限制因果模型满足Markov条件、仅包含现实变量且因果完备，提出了一种不使用响应变量的新语义。通过数学证明，展示了其语义与其他两种提议的等价性。

Result: 提出的新语义不仅适用于更广泛的概率因果模型，还与两种最新提议等价，且与文献中的随机反事实观点一致。

Conclusion: 本文提出了一种新的反事实概率语义，适用于无法扩展为现实结构因果模型的概率因果模型，填补了Pearl语义的空白。作者在Markov条件、现实变量和因果完备性的限制下，证明了其语义与两种不涉及结构因果模型的最新提议等价，并与文献中的随机反事实评论一致。

Abstract: I develop a novel semantics for probabilities of counterfactuals that generalizes the standard Pearlian semantics: it applies to probabilistic causal models that cannot be extended into realistic structural causal models and are therefore beyond the scope of Pearl's semantics. This generalization is needed because, as I show, such probabilistic causal models arise even in simple settings. My semantics offer a natural compromize in the long-standing debate between Pearl and Dawid over counterfactuals: I agree with Dawid that universal causal determinism and unrealistic variables should be rejected, but I agree with Pearl that a general semantics of counterfactuals is nonetheless possible. I restrict attention to causal models that satisfy the Markov condition, only contain realistic variables, and are causally complete. Although I formulate my proposal using structural causal models, as does Pearl, I refrain from using so-called response variables. Moreover, I prove that my semantics is equivalent to two other recent proposals that do not involve structural causal models, and that it is in line with various comments on stochastic counterfactuals that have appeared in the literature more broadly. Throughout I also reflect on the universality of the Markov condition and explore a novel generalization of causal abstractions

</details>


### [243] [Fault-Tolerant Sandboxing for AI Coding Agents: A Transactional Approach to Safe Autonomous Execution](https://arxiv.org/abs/2512.12806)
*Boyang Yan*

Main category: cs.AI

TL;DR: 该论文提出了一种Fault-Tolerant Sandboxing框架，通过原子事务和快照机制确保LLM自主代理的安全性，实验证明其高效且低延迟。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）从被动代码生成器转变为自主代理时，存在破坏性命令和系统状态不一致的安全风险，现有商业解决方案无法满足无头自主代理的需求。

Method: 采用基于策略的拦截层和事务性文件系统快照机制，将代理行为封装在原子事务中，确保安全性。

Result: 实验结果显示，高风险命令拦截率和失败状态回滚率均达到100%，每笔事务的性能开销仅为14.5%（约1.8秒）。

Conclusion: Fault-Tolerant Sandboxing框架通过基于策略的拦截层和事务性文件系统快照机制，有效降低了LLM作为自主代理时的安全风险，实现了高风险命令的100%拦截率和失败状态的100%回滚率，且性能开销仅为14.5%。

Abstract: The transition of Large Language Models (LLMs) from passive code generators to autonomous agents introduces significant safety risks, specifically regarding destructive commands and inconsistent system states. Existing commercial solutions often prioritize interactive user safety, enforcing authentication barriers that break the headless loops required for true autonomy. This paper presents a Fault-Tolerant Sandboxing framework designed to mitigate these risks through a policy-based interception layer and a transactional filesystem snapshot mechanism. We hypothesize that wrapping agent actions in atomic transactions can guarantee safety with acceptable latency, outperforming the heavy initialization overhead of containers or the interactive friction of commercial CLIs. We validated this approach by deploying the Minimind-MoE LLM served via nano-vllm on a custom Proxmox-based testbed utilizing EVPN/VXLAN isolation. Experimental results demonstrate a 100\% interception rate for high-risk commands and a 100\% success rate in rolling back failed states. Crucially, our prototype incurs only a 14.5\% performance overhead (approx. 1.8s) per transaction. In contrast, benchmarking against the Gemini CLI sandbox revealed that it requires interactive authentication ("Sign in"), rendering it unusable for headless, autonomous agent workflows.

</details>


### [244] [Forgetful but Faithful: A Cognitive Memory Architecture and Benchmark for Privacy-Aware Generative Agents](https://arxiv.org/abs/2512.12856)
*Saad Alqithami*

Main category: cs.AI

TL;DR: 本文提出MaRS框架和六种遗忘策略，通过FiFA基准测试验证混合策略在性能、隐私和效率上的优势，为生成代理的内存管理提供了新基准和实用指南。


<details>
  <summary>Details</summary>
Motivation: 生成代理在长期交互场景中，内存管理成为性能和隐私的关键瓶颈，现有方法要么内存无限导致计算不可行和隐私问题，要么简单遗忘机制损害代理一致性和功能。

Method: 本文介绍了MaRS框架和六种遗忘策略，并开发了FiFA基准测试框架，通过300次实验评估不同内存预算和代理配置下的性能。

Result: 实验证明混合遗忘策略在综合得分（0.911）上表现优越，同时保持计算可行性和隐私保障。

Conclusion: 本文提出了Memory-Aware Retention Schema（MaRS）框架和六种理论基础的遗忘策略，通过FiFA基准测试验证了混合遗忘策略在性能、隐私和计算效率上的优越性，为资源受限和隐私敏感环境中的生成代理部署提供了实用指南。

Abstract: As generative agents become increasingly sophisticated and deployed in long-term interactive scenarios, their memory management capabilities emerge as a critical bottleneck for both performance and privacy. Current approaches either maintain unlimited memory stores, leading to computational intractability and privacy concerns, or employ simplistic forgetting mechanisms that compromise agent coherence and functionality. This paper introduces the Memory-Aware Retention Schema (MaRS), a novel framework for human-centered memory management in generative agents, coupled with six theoretically-grounded forgetting policies that balance performance, privacy, and computational efficiency. We present the Forgetful but Faithful Agent (FiFA) benchmark, a comprehensive evaluation framework that assesses agent performance across narrative coherence, goal completion, social recall accuracy, privacy preservation, and cost efficiency. Through extensive experimentation involving 300 evaluation runs across multiple memory budgets and agent configurations, we demonstrate that our hybrid forgetting policy achieves superior performance (composite score: 0.911) while maintaining computational tractability and privacy guarantees. Our work establishes new benchmarks for memory-budgeted agent evaluation and provides practical guidelines for deploying generative agents in resource-constrained, privacy-sensitive environments. The theoretical foundations, implementation framework, and empirical results contribute to the emerging field of human-centered AI by addressing fundamental challenges in agent memory management that directly impact user trust, system scalability, and regulatory compliance.

</details>


### [245] [Satisfiability Modulo Theory Meets Inductive Logic Programming](https://arxiv.org/abs/2512.12918)
*Nijesh Upreti,Vaishak Belle*

Main category: cs.AI

TL;DR: 论文提出结合PyGol与Z3的SMT-ILP架构，扩展符号规则学习，支持混合规则归纳，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决传统ILP在数值约束学习和推理上的局限性，如难以推断阈值或跨示例的算术关系。

Method: 论文采用模块化方法，将ILP系统PyGol与SMT求解器Z3结合，候选子句被解释为背景理论上的无量化公式，支持混合规则的归纳。

Result: 在合成数据集上的实验表明，该架构能有效支持线性、关系、非线性和多跳推理的混合规则学习。

Conclusion: 该论文提出了一种模块化的SMT-ILP架构，通过将PyGol与Z3结合，扩展了符号规则学习的表达能力，为未来更丰富的理论感知归纳提供了灵活基础。

Abstract: Inductive Logic Programming (ILP) provides interpretable rule learning in relational domains, yet remains limited in its ability to induce and reason with numerical constraints. Classical ILP systems operate over discrete predicates and typically rely on discretisation or hand-crafted numerical predicates, making it difficult to infer thresholds or arithmetic relations that must hold jointly across examples. Recent work has begun to address these limitations through tighter integrations of ILP with Satisfiability Modulo Theories (SMT) or specialised numerical inference mechanisms. In this paper we investigate a modular alternative that couples the ILP system PyGol with the SMT solver Z3. Candidate clauses proposed by PyGol are interpreted as quantifier-free formulas over background theories such as linear or nonlinear real arithmetic, allowing numerical parameters to be instantiated and verified by the SMT solver while preserving ILP's declarative relational bias. This supports the induction of hybrid rules that combine symbolic predicates with learned numerical constraints, including thresholds, intervals, and multi-literal arithmetic relations. We formalise this SMT-ILP setting and evaluate it on a suite of synthetic datasets designed to probe linear, relational, nonlinear, and multi-hop reasoning. The results illustrate how a modular SMT-ILP architecture can extend the expressivity of symbolic rule learning, complementing prior numerical ILP approaches while providing a flexible basis for future extensions toward richer theory-aware induction.

</details>


### [246] [Towards Open Standards for Systemic Complexity in Digital Forensics](https://arxiv.org/abs/2512.12970)
*Paola Di Maio*

Main category: cs.AI

TL;DR: 论文提出通过人类可读工件和开放标准减轻数字取证错误，并基于最新技术设计了AI模型框架。


<details>
  <summary>Details</summary>
Motivation: 尽管数字取证技术取得了巨大进展，但仍存在错误和脆弱性，需要解决系统复杂性以提升可靠性。

Method: 提出了一个基于最新技术的数字取证AI模型框架，并采用人类可读的工件和开放标准来应对系统复杂性。

Result: 提出了一个数字取证AI模型框架，并强调了人类可读工件和开放标准的重要性。

Conclusion: 通过采用人类可读的工件和开放标准，可以减轻数字取证中的错误限制，并提出了基于最新技术的数字取证AI模型框架。

Abstract: The intersection of artificial intelligence (AI) and digital forensics (DF) is becoming increasingly complex, ubiquitous, and pervasive, with overlapping techniques and technologies being adopted in all types of scientific and technical inquiry. Despite incredible advances, forensic sciences are not exempt from errors and remain vulnerable to fallibility. To mitigate the limitations of errors in DF, the systemic complexity is identified and addressed with the adoption of human-readable artifacts and open standards. A DF AI model schema based on the state of the art is outlined.

</details>


### [247] [M-GRPO: Stabilizing Self-Supervised Reinforcement Learning for Large Language Models with Momentum-Anchored Policy Optimization](https://arxiv.org/abs/2512.13070)
*Bizhe Bai,Hongming Wu,Peng Ye,Tao Chen*

Main category: cs.AI

TL;DR: 论文提出M-GRPO和IQR过滤器，解决了自监督强化学习中的策略崩溃问题，提升了稳定性和性能。


<details>
  <summary>Details</summary>
Motivation: 解决自监督强化学习中长期训练导致的'策略崩溃'问题。

Method: 引入了M-GRPO框架和基于IQR的自适应过滤方法。

Result: 实验证明M-GRPO稳定了训练过程，IQR过滤器防止了过早收敛。

Conclusion: 结合M-GRPO和IQR过滤器的创新方法显著提升了训练稳定性，并实现了最先进的性能。

Abstract: Self-supervised reinforcement learning (RL) presents a promising approach for enhancing the reasoning capabilities of Large Language Models (LLMs) without reliance on expensive human-annotated data. However, we find that existing methods suffer from a critical failure mode under long-horizon training: a "policy collapse" where performance precipitously degrades. We diagnose this instability and demonstrate that simply scaling the number of rollouts -- a common strategy to improve performance -- only delays, but does not prevent, this collapse. To counteract this instability, we first introduce M-GRPO (Momentum-Anchored Group Relative Policy Optimization), a framework that leverages a slowly evolving momentum model to provide a stable training target. In addition, we identify that this process is often accompanied by a rapid collapse in policy entropy, resulting in a prematurely confident and suboptimal policy. To specifically address this issue, we propose a second contribution: an adaptive filtering method based on the interquartile range (IQR) that dynamically prunes low-entropy trajectories, preserving essential policy diversity. Our extensive experiments on multiple reasoning benchmarks demonstrate that M-GRPO stabilizes the training process while the IQR filter prevents premature convergence. The combination of these two innovations leads to superior training stability and state-of-the-art performance.

</details>


### [248] [Socratic Students: Teaching Language Models to Learn by Asking Questions](https://arxiv.org/abs/2512.13102)
*Rajeev Bhatt Ambati,Tianyi Niu,Aashu Singh,Shlok Mishra,Shashank Srivastava,Snigdha Chaturvedi*

Main category: cs.AI

TL;DR: 研究提出学生主导的主动查询策略，通过DPO训练提升问题质量，在数学和编程任务中显著优于静态基线模型。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在静态交互中表现优异，但在需要动态获取信息的场景（如教育辅导或医疗辅助）中表现不足。研究旨在探索学生如何主动向教师查询有用信息的策略。

Method: 研究采用学生主导的主动查询策略，使用直接偏好优化（DPO）训练学生模型，以自我或更强学生为引导，提升问题质量。

Result: 在数学和编程基准测试中，学生主导的方法相比静态基线模型，绝对Pass@k改进至少0.5。通过DPO训练，较小模型的问题质量得到提升，进一步提高了学习效率。

Conclusion: 学生主导的主动查询策略在数学和编程基准测试中显著提升了性能，尤其是在初始性能接近零的情况下，绝对Pass@k改进至少0.5。通过直接偏好优化（DPO）训练，较小模型也能学会提出更高质量的问题，从而进一步提高学习效率。

Abstract: Large Language Models (LLMs) excel at static interactions, where they answer user queries by retrieving knowledge encoded in their parameters. However, in many real-world settings, such as educational tutoring or medical assistance, relevant information is not directly available and must be actively acquired through dynamic interactions. An interactive agent would recognize its own uncertainty, ask targeted questions, and retain new knowledge efficiently. Prior work has primarily explored effective ways for a teacher to instruct the student, where the teacher identifies student gaps and provides guidance. In this work, we shift the focus to the student and investigate effective strategies to actively query the teacher in seeking useful information. Across math and coding benchmarks, where baseline student models begin with near-zero performance, we show that student-led approaches consistently yield absolute Pass@k improvements of at least 0.5 over static baselines. To improve question quality, we train students using Direct Preference Optimization (DPO) with guidance from either self or stronger students. We find that this guided training enables smaller models to learn how to ask better questions, further enhancing learning efficiency.

</details>


### [249] [Can AI Understand What We Cannot Say? Measuring Multilevel Alignment Through Abortion Stigma Across Cognitive, Interpersonal, and Structural Levels](https://arxiv.org/abs/2512.13142)
*Anika Sharma,Malavika Mampally,Chidaksh Ravuru,Kandyce Brennan,Neil Gaikwad*

Main category: cs.AI

TL;DR: 研究发现当前LLM在多层次理解心理和生理构造方面缺乏连贯性，尤其在堕胎污名等高风险领域。模型表现不一致，存在偏见，且未能捕捉关键关系，呼吁改进设计、评估和监管。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型越来越多地介入具有污名化的健康决策，评估其是否真正理解复杂的心理和生理现象变得至关重要。研究旨在探讨LLM是否能在认知、人际和结构层面上连贯地表示堕胎污名。

Method: 研究使用经过验证的个体水平堕胎污名量表（ILAS）对五个领先的LLM进行了系统性测试，共测试了627个不同人口统计特征的角色。多层次分析评估了模型在认知层面（自我评判）、人际层面（预期评判与孤立）、结构层面（社区谴责与披露模式）以及整体污名上的表现。

Result: 模型在所有层面上均未能通过真实理解的测试。它们高估了人际污名，低估了认知污名，假设社区谴责是统一的，引入了人类验证数据中不存在的 demographic 偏见，忽略了经验验证的污名-保密关系，并在理论构建中自相矛盾。

Conclusion: 当前的大语言模型（LLM）在多层次理解心理和生理构造方面缺乏连贯性，尤其是在高风险的医疗决策中。AI安全性需要新的设计（多层次连贯性）、评估（持续审计）、治理与监管（强制审计、问责制、部署限制）方法，以及在理解人们无法言说的领域提高AI素养。

Abstract: As large language models increasingly mediate stigmatized health decisions, their capacity to genuinely understand complex psychological and physiological phenomena remains poorly evaluated. Can AI understand what we cannot say? We investigate whether LLMs coherently represent abortion stigma across the cognitive, interpersonal, and structural levels where it operates. We systematically tested 627 demographically diverse personas across five leading LLMs using the validated Individual Level Abortion Stigma Scale (ILAS). Our multilevel analysis examined whether models coherently represent stigma at the cognitive level (self-judgment), interpersonal level (anticipated judgment and isolation), and structural level (community condemnation and disclosure patterns), as well as overall stigma. Models fail tests of genuine understanding across all levels. They overestimate interpersonal stigma while underestimating cognitive stigma, assume uniform community condemnation, introduce demographic biases absent from human validation data, miss the empirically validated stigma-secrecy relationship, and contradict themselves within theoretical constructs. These patterns reveal that current alignment approaches ensure appropriate language but not coherent multilevel understanding. This work provides empirical evidence that current LLMs lack coherent multilevel understanding of psychological and physiological constructs. AI safety in high-stakes contexts demands new approaches to design (multilevel coherence), evaluation (continuous auditing), governance and regulation (mandatory audits, accountability, deployment restrictions), and AI literacy in domains where understanding what people cannot say determines whether support helps or harms.

</details>


### [250] [MAC: A Multi-Agent Framework for Interactive User Clarification in Multi-turn Conversations](https://arxiv.org/abs/2512.13154)
*Emre Can Acikgoz,Jinoh Oh,Joo Hyuk Jeon,Jie Hao,Heng Ji,Dilek Hakkani-Tür,Gokhan Tur,Xiang Li,Chengyuan Ma,Xing Fan*

Main category: cs.AI

TL;DR: 提出MAC框架，通过多智能体协同解决用户模糊性，显著提高任务成功率和减少对话轮数。


<details>
  <summary>Details</summary>
Motivation: 多智能体架构在处理复杂对话场景时效率高，但模糊性解决仍是一个关键且未充分探索的挑战，尤其是在确定哪个智能体应发起澄清以及如何协调行动时。

Method: 提出了MAC（多智能体澄清）框架，通过战略性地管理澄清对话来解决用户模糊性。首先引入了一种新的分类法来系统化指导澄清策略，然后展示了MAC如何自主协调多个智能体与用户协同互动。

Result: 在MultiWOZ 2.4上的实证评估显示，启用两级澄清可将任务成功率提高7.8%（从54.5到62.3），并通过提前获取所有必要用户信息和最小化重复，将平均对话轮数从6.53减少到4.86。

Conclusion: 研究发现，主动的用户互动和角色感知的澄清对于更可靠的人机通信至关重要。

Abstract: Conversational agents often encounter ambiguous user requests, requiring an effective clarification to successfully complete tasks. While recent advancements in real-world applications favor multi-agent architectures to manage complex conversational scenarios efficiently, ambiguity resolution remains a critical and underexplored challenge--particularly due to the difficulty of determining which agent should initiate a clarification and how agents should coordinate their actions when faced with uncertain or incomplete user input. The fundamental questions of when to interrupt a user and how to formulate the optimal clarification query within the most optimal multi-agent settings remain open. In this paper, we propose MAC (Multi-Agent Clarification), an interactive multi-agent framework specifically optimized to resolve user ambiguities by strategically managing clarification dialogues. We first introduce a novel taxonomy categorizing user ambiguities to systematically guide clarification strategies. Then, we present MAC that autonomously coordinates multiple agents to interact synergistically with users. Empirical evaluations on MultiWOZ 2.4 demonstrate that enabling clarification at both levels increases task success rate 7.8\% (54.5 to 62.3) and reduces the average number of dialogue turns (6.53 to 4.86) by eliciting all required user information up front and minimizing repetition. Our findings highlight the importance of active user interaction and role-aware clarification for more reliable human-agent communication.

</details>


### [251] [SpeakRL: Synergizing Reasoning, Speaking, and Acting in Language Models with Reinforcement Learning](https://arxiv.org/abs/2512.13159)
*Emre Can Acikgoz,Jinoh Oh,Jie Hao,Joo Hyuk Jeon,Heng Ji,Dilek Hakkani-Tür,Gokhan Tur,Xiang Li,Chengyuan Ma,Xing Fan*

Main category: cs.AI

TL;DR: SpeakRL通过强化学习训练智能体主动提问澄清用户意图，显著提升任务完成率。


<details>
  <summary>Details</summary>
Motivation: 现有的人机协作多为单向指令式，智能体缺乏主动澄清意图的能力，限制了协作效率。

Method: 采用强化学习方法（SpeakRL），通过设计合理的奖励机制来鼓励智能体主动与用户互动，如适时提出澄清问题。

Result: SpeakRL在任务完成率上实现了20.14%的绝对提升，且未增加对话轮次，甚至优于更大的专有模型。

Conclusion: SpeakRL通过强化学习提升了智能体的对话能力，使其能够在必要时主动澄清用户意图，显著提高了任务完成率。

Abstract: Effective human-agent collaboration is increasingly prevalent in real-world applications. Current trends in such collaborations are predominantly unidirectional, with users providing instructions or posing questions to agents, where agents respond directly without seeking necessary clarifications or confirmations. However, the evolving capabilities of these agents require more proactive engagement, where agents should dynamically participate in conversations to clarify user intents, resolve ambiguities, and adapt to changing circumstances. Existing prior work under-utilize the conversational capabilities of language models (LMs), thereby optimizing agents as better followers rather than effective speakers. In this work, we introduce SpeakRL, a reinforcement learning (RL) method that enhances agents' conversational capabilities by rewarding proactive interactions with users, such as asking right clarification questions when necessary. To support this, we curate SpeakER, a synthetic dataset that includes diverse scenarios from task-oriented dialogues, where tasks are resolved through interactive clarification questions. We present a systematic analysis of reward design for conversational proactivity and propose a principled reward formulation for teaching agents to balance asking with acting. Empirical evaluations demonstrate that our approach achieves a 20.14% absolute improvement in task completion over base models without increasing conversation turns even surpassing even much larger proprietary models, demonstrating the promise of clarification-centric user-agent interactions.

</details>


### [252] [Finch: Benchmarking Finance & Accounting across Spreadsheet-Centric Enterprise Workflows](https://arxiv.org/abs/2512.13168)
*Haoyu Dong,Pengkun Zhang,Yan Gao,Xuanyu Dong,Yilin Cheng,Mingzhe Lu,Adina Yakefu,Shuxin Zheng*

Main category: cs.AI

TL;DR: Finch是一个财务与会计基准测试，评估AI代理在真实企业工作流中的表现，结果显示当前AI系统在处理复杂任务时表现有限。


<details>
  <summary>Details</summary>
Motivation: 为评估AI代理在真实企业级专业工作流（如数据录入、计算、建模等）上的表现，需一个包含多模态、多领域、协作性任务的基准测试。

Method: 结合LLM辅助发现与专家标注的工作流构建过程，包括从真实电子邮件线程和电子表格版本历史中推导工作流，并进行详细专家标注。

Result: GPT 5.1 Pro仅通过38.4%的工作流，Claude Sonnet 4.5通过25.0%，凸显AI在复杂企业工作流中的挑战。

Conclusion: Finch基准测试揭示了当前前沿AI系统在处理真实企业级财务与会计工作流时的局限性，尤其是面对复杂、多模态、协作性任务时的表现不佳。

Abstract: We introduce a finance & accounting benchmark (Finch) for evaluating AI agents on real-world, enterprise-grade professional workflows -- interleaving data entry, structuring, formatting, web search, cross-file retrieval, calculation, modeling, validation, translation, visualization, and reporting. Finch is sourced from authentic enterprise workspaces at Enron (15,000 spreadsheets and 500,000 emails from 150 employees) and other financial institutions, preserving in-the-wild messiness across multimodal artifacts (text, tables, formulas, charts, code, and images) and spanning diverse domains such as budgeting, trading, and asset management.
  We propose a workflow construction process that combines LLM-assisted discovery with expert annotation: (1) LLM-assisted, expert-verified derivation of workflows from real-world email threads and version histories of spreadsheet files, and (2) meticulous expert annotation for workflows, requiring over 700 hours of domain-expert effort. This yields 172 composite workflows with 384 tasks, involving 1,710 spreadsheets with 27 million cells, along with PDFs and other artifacts, capturing the intrinsically messy, long-horizon, knowledge-intensive, and collaborative nature of real-world enterprise work.
  We conduct both human and automated evaluations of frontier AI systems including GPT 5.1, Claude Sonnet 4.5, Gemini 3 Pro, Grok 4, and Qwen 3 Max, and GPT 5.1 Pro spends 48 hours in total yet passes only 38.4% of workflows, while Claude Sonnet 4.5 passes just 25.0%. Comprehensive case studies further surface the challenges that real-world enterprise workflows pose for AI agents.

</details>


### [253] [Reflective Preference Optimization (RPO): Enhancing On-Policy Alignment via Hint-Guided Reflection](https://arxiv.org/abs/2512.13240)
*Zihui Zhao,Zechang Li*

Main category: cs.AI

TL;DR: RPO通过外部模型生成的反思提示增强DPO学习信号，提升效率和性能。


<details>
  <summary>Details</summary>
Motivation: 标准DPO因生成策略相同导致学习信号弱，收敛慢且不稳定。RPO旨在通过引入反思提示增强学习信号。

Method: RPO在DPO框架中加入了由外部模型生成的反思提示，构建更具对比性的偏好对。

Result: RPO在减少训练样本和迭代次数的同时，显著降低了幻觉率，并在多模态基准测试中表现优异。

Conclusion: RPO通过引入外部模型生成的反思提示，显著提升了DPO框架的学习效率和稳定性，在多模态基准测试中实现了最先进的性能。

Abstract: Direct Preference Optimization (DPO) has emerged as a lightweight and effective alternative to Reinforcement Learning from Human Feedback (RLHF) and Reinforcement Learning with AI Feedback (RLAIF) for aligning large language and vision-language models. However, the standard DPO formulation, in which both the chosen and rejected responses are generated by the same policy, suffers from a weak learning signal because the two responses often share similar errors and exhibit small Kullback-Leibler (KL) divergence. This leads to slow and unstable convergence. To address this limitation, we introduce Reflective Preference Optimization (RPO), a new framework that incorporates hint-guided reflection into the DPO paradigm. RPO uses external models to identify hallucination sources and generate concise reflective hints, enabling the construction of on-policy preference pairs with stronger contrastiveness and clearer preference signals. We theoretically show that conditioning on hints increases the expected preference margin through mutual information and improves sample efficiency while remaining within the policy distribution family. Empirically, RPO achieves superior alignment with fewer training samples and iterations, substantially reducing hallucination rates and delivering state-of-the-art performance across multimodal benchmarks.

</details>


### [254] [MedInsightBench: Evaluating Medical Analytics Agents Through Multi-Step Insight Discovery in Multimodal Medical Data](https://arxiv.org/abs/2512.13297)
*Zhenghao Zhu,Chuxue Cao,Sirui Han,Yuanfeng Song,Xing Chen,Caleb Chen Cao,Yike Guo*

Main category: cs.AI

TL;DR: 提出了首个医学多模态数据集MedInsightBench和自动化分析框架MedInsightAgent，用于评估和提升LMMs的医学洞察能力。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏高质量的多模态医学数据集来评估大型多模态模型（LMMs）的医学洞察能力。

Method: 提出了MedInsightAgent框架，包含视觉根因分析器、分析洞察代理和后续问题生成器三个模块。

Result: 实验表明，现有LMMs在MedInsightBench上表现有限，而MedInsightAgent能显著提升其性能。

Conclusion: MedInsightAgent框架能够提升通用大型多模态模型在医学数据洞察发现中的性能，但仍存在挑战。

Abstract: In medical data analysis, extracting deep insights from complex, multi-modal datasets is essential for improving patient care, increasing diagnostic accuracy, and optimizing healthcare operations. However, there is currently a lack of high-quality datasets specifically designed to evaluate the ability of large multi-modal models (LMMs) to discover medical insights. In this paper, we introduce MedInsightBench, the first benchmark that comprises 332 carefully curated medical cases, each annotated with thoughtfully designed insights. This benchmark is intended to evaluate the ability of LMMs and agent frameworks to analyze multi-modal medical image data, including posing relevant questions, interpreting complex findings, and synthesizing actionable insights and recommendations. Our analysis indicates that existing LMMs exhibit limited performance on MedInsightBench, which is primarily attributed to their challenges in extracting multi-step, deep insights and the absence of medical expertise. Therefore, we propose MedInsightAgent, an automated agent framework for medical data analysis, composed of three modules: Visual Root Finder, Analytical Insight Agent, and Follow-up Question Composer. Experiments on MedInsightBench highlight pervasive challenges and demonstrate that MedInsightAgent can improve the performance of general LMMs in medical data insight discovery.

</details>


### [255] [Error-Driven Prompt Optimization for Arithmetic Reasoning](https://arxiv.org/abs/2512.13323)
*Árpád Pándy,Róbert Lakatos,András Hajdu*

Main category: cs.AI

TL;DR: 错误驱动优化框架提升小型语言模型的算术能力，使其在隐私合规环境下超越大型模型。


<details>
  <summary>Details</summary>
Motivation: 工业领域需要能在安全环境中处理结构化数据的AI助手，尤其是在金融和医疗等受监管行业。

Method: 提出了一种错误驱动的优化框架，通过聚类错误预测来迭代优化提示规则，从而提升算术推理能力。

Result: 该方法显著提升了小型语言模型（Qwen3 4B）的算术任务准确率，从基础模型的较低水平提升至70.8%。

Conclusion: 研究表明，通过系统化的错误驱动提示优化，小型模型可以在隐私合规的前提下超越大型语言模型（如GPT-3.5 Turbo），而无需昂贵的微调。

Abstract: Recent advancements in artificial intelligence have sparked interest in industrial agents capable of supporting analysts in regulated sectors, such as finance and healthcare, within tabular data workflows. A key capability for such systems is performing accurate arithmetic operations on structured data while ensuring sensitive information never leaves secure, on-premises environments. Here, we introduce an error-driven optimization framework for arithmetic reasoning that enhances a Code Generation Agent (CGA), specifically applied to on-premises small language models (SLMs). Through a systematic evaluation of a leading SLM (Qwen3 4B), we find that while the base model exhibits fundamental limitations in arithmetic tasks, our proposed error-driven method, which clusters erroneous predictions to refine prompt-rules iteratively, dramatically improves performance, elevating the model's accuracy to 70.8\%. Our results suggest that developing reliable, interpretable, and industrially deployable AI assistants can be achieved not only through costly fine-tuning but also via systematic, error-driven prompt optimization, enabling small models to surpass larger language models (GPT-3.5 Turbo) in a privacy-compliant manner.

</details>


### [256] [Behavior and Representation in Large Language Models for Combinatorial Optimization: From Feature Extraction to Algorithm Selection](https://arxiv.org/abs/2512.13374)
*Francesca Da Ros,Luca Di Gaspero,Kevin Roitero*

Main category: cs.AI

TL;DR: LLMs在组合优化问题中能够捕获有意义的结构信息，其隐藏层表示与传统特征提取方法在预测最佳求解器方面表现相当。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs如何内部表示组合优化问题，以及这些表示是否支持下游决策任务。

Method: 采用双重方法结合直接查询和探测分析，评估LLMs从问题实例中提取特征的能力，并扩展探测框架至实例级算法选择任务。

Result: LLMs展现出从中等问题实例中恢复特征信息的中等能力，无论是通过直接查询还是探测分析。

Conclusion: 研究表明，LLMs能够捕获与优化性能相关的有意义的结构信息，其隐藏层表示在预测最佳求解器方面的预测能力与传统特征提取方法相当。

Abstract: Recent advances in Large Language Models (LLMs) have opened new perspectives for automation in optimization. While several studies have explored how LLMs can generate or solve optimization models, far less is understood about what these models actually learn regarding problem structure or algorithmic behavior. This study investigates how LLMs internally represent combinatorial optimization problems and whether such representations can support downstream decision tasks. We adopt a twofold methodology combining direct querying, which assesses LLM capacity to explicitly extract instance features, with probing analyses that examine whether such information is implicitly encoded within their hidden layers. The probing framework is further extended to a per-instance algorithm selection task, evaluating whether LLM-derived representations can predict the best-performing solver. Experiments span four benchmark problems and three instance representations. Results show that LLMs exhibit moderate ability to recover feature information from problem instances, either through direct querying or probing. Notably, the predictive power of LLM hidden-layer representations proves comparable to that achieved through traditional feature extraction, suggesting that LLMs capture meaningful structural information relevant to optimization performance.

</details>


### [257] [Differentiable Evolutionary Reinforcement Learning](https://arxiv.org/abs/2512.13399)
*Sitao Cheng,Tianle Li,Xuhan Huang,Xunjian Yin,Difan Zou*

Main category: cs.AI

TL;DR: DERL是一种可微分的进化强化学习框架，通过元优化自主发现最优奖励信号，在多个复杂推理任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习中奖励函数设计困难的问题，尤其是复杂推理任务中因果关系的捕捉。

Method: 提出了一种双层框架DERL，通过组合结构化原子原语进化奖励函数，并利用内环策略训练的性能信号进行元优化。

Result: 在ALFWorld和ScienceWorld上达到最先进性能，显著优于依赖启发式奖励的方法。

Conclusion: DERL通过可微分的元优化方法，成功实现了自主发现最优奖励信号，显著提升了复杂推理任务的性能，尤其在分布外场景中表现优异。

Abstract: The design of effective reward functions presents a central and often arduous challenge in reinforcement learning (RL), particularly when developing autonomous agents for complex reasoning tasks. While automated reward optimization approaches exist, they typically rely on derivative-free evolutionary heuristics that treat the reward function as a black box, failing to capture the causal relationship between reward structure and task performance. To bridge this gap, we propose Differentiable Evolutionary Reinforcement Learning (DERL), a bilevel framework that enables the autonomous discovery of optimal reward signals. In DERL, a Meta-Optimizer evolves a reward function (i.e., Meta-Reward) by composing structured atomic primitives, guiding the training of an inner-loop policy. Crucially, unlike previous evolution, DERL is differentiable in its metaoptimization: it treats the inner-loop validation performance as a signal to update the Meta-Optimizer via reinforcement learning. This allows DERL to approximate the "meta-gradient" of task success, progressively learning to generate denser and more actionable feedback. We validate DERL across three distinct domains: robotic agent (ALFWorld), scientific simulation (ScienceWorld), and mathematical reasoning (GSM8k, MATH). Experimental results show that DERL achieves state-of-the-art performance on ALFWorld and ScienceWorld, significantly outperforming methods relying on heuristic rewards, especially in out-of-distribution scenarios. Analysis of the evolutionary trajectory demonstrates that DERL successfully captures the intrinsic structure of tasks, enabling selfimproving agent alignment without human intervention.

</details>


### [258] [neuralFOMO: Can LLMs Handle Being Second Best? Measuring Envy-Like Preferences in Multi-Agent Settings](https://arxiv.org/abs/2512.13481)
*Ojas Pungalia,Rashi Upadhyay,Abhishek Mishra,Abhiram H,Tejasvi Alladi,Sujan Yenuganti,Dhruv Kumar*

Main category: cs.AI

TL;DR: 研究测试了LLM是否表现出类似嫉妒的行为，发现某些模型在特定情境下确实如此，强调了在多智能体系统中考虑竞争倾向的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）越来越多地在协作和竞争工作流程中代表人类行动，迫切需要评估它们是否以及在什么条件下表现出类似嫉妒的偏好。

Method: 研究设计了两种场景：一种是点分配游戏，测试模型是否试图胜过其同伴；另一种是职场环境，观察在不公平认可情况下的行为。

Result: 研究发现某些LLM中表现出类似嫉妒的模式，不同模型和情境之间存在显著差异。例如，GPT-5-mini和Claude-3.7-Sonnet倾向于拉低同伴模型以平衡结果，而Mistral-Small-3.2-24B则专注于最大化自身收益。

Conclusion: 论文强调了在基于LLM的多智能体系统中考虑竞争倾向作为安全和设计因素的必要性。

Abstract: Envy is a common human behavior that shapes competitiveness and can alter outcomes in team settings. As large language models (LLMs) increasingly act on behalf of humans in collaborative and competitive workflows, there is a pressing need to evaluate whether and under what conditions they exhibit envy-like preferences. In this paper, we test whether LLMs show envy-like behavior toward each other. We considered two scenarios: (1) A point allocation game that tests whether a model tries to win over its peer. (2) A workplace setting observing behaviour when recognition is unfair. Our findings reveal consistent evidence of envy-like patterns in certain LLMs, with large variation across models and contexts. For instance, GPT-5-mini and Claude-3.7-Sonnet show a clear tendency to pull down the peer model to equalize outcomes, whereas Mistral-Small-3.2-24B instead focuses on maximizing its own individual gains. These results highlight the need to consider competitive dispositions as a safety and design factor in LLM-based multi-agent systems.

</details>


### [259] [Defending the Hierarchical Result Models of Precedential Constraint](https://arxiv.org/abs/2512.13505)
*Henry Prakken,Wijnand van Woerkom*

Main category: cs.AI

TL;DR: 本文反驳Bench-Capon对分层案例推理模型的批评，通过van Woerkom的基于维度模型展示了其有效性。


<details>
  <summary>Details</summary>
Motivation: 回应Bench-Capon对分层案例推理模型的批评，特别是关于中间因素在不同基础因素下强度不同的问题。

Method: 通过分析Bench-Capon的批评，并应用van Woerkom的基于维度的分层结果模型来重新解释示例。

Result: 证明van Woerkom的基于维度的分层结果模型能够有效避免Bench-Capon所指出的问题。

Conclusion: 本文通过论证van Woerkom的基于维度的分层结果模型可以避免Bench-Capon的批评，回应了其对分层案例推理模型的质疑。

Abstract: In recent years, hierarchical case-based-reasoning models of precedential constraint have been proposed. In various papers, Trevor Bench-Capon criticised these models on the grounds that they would give incorrect outcomes in some cases. In particular, the models would not account for the possibility that intermediate factors are established with different strengths by different base-level factors. In this paper we respond to these criticisms for van Woerkom's result-based hierarchical models. We argue that in some examples Bench-Capon seems to interpret intermediate factors as dimensions, and that applying van Woerkom's dimension-based version of the hierarchical result model to these examples avoids Bench-Capon's criticisms.

</details>


### [260] [MedCEG: Reinforcing Verifiable Medical Reasoning with Critical Evidence Graph](https://arxiv.org/abs/2512.13510)
*Linjie Mu,Yannian Gu,Zhongzhen Huang,Yakun Zhu,Shaoting Zhang,Xiaofan Zhang*

Main category: cs.AI

TL;DR: MedCEG通过Critical Evidence Graph增强医学语言模型的临床推理能力，实验显示其性能优于现有方法且推理链临床有效。


<details>
  <summary>Details</summary>
Motivation: 尽管强化学习在医学背景下有效提升了推理性能，但其推理过程的临床可靠性仍有限，因为训练过程中常忽略准确性和有效性。

Method: 提出MedCEG框架，通过算法构建Critical Evidence Graph（CEG）表示高质量可验证的推理路径，并引入Clinical Reasoning Procedure Reward来评估节点覆盖、结构正确性和链完整性。

Result: 实验结果表明，MedCEG在性能上超越现有方法，同时生成临床有效的推理链。

Conclusion: MedCEG框架通过Critical Evidence Graph（CEG）显式监督推理过程，显著提升了医学语言模型的临床可靠性，代表了可靠医学AI推理的实质性进展。

Abstract: Large language models with reasoning capabilities have demonstrated impressive performance across a wide range of domains. In clinical applications, a transparent, step-by-step reasoning process provides physicians with strong evidence to support decision-making. While reinforcement learning has effectively enhanced reasoning performance in medical contexts, the clinical reliability of these reasoning processes remains limited because their accuracy and validity are often overlooked during training. To address this gap, we propose MedCEG, a framework that augments medical language models with clinically valid reasoning pathways by explicitly supervising the reasoning process through a Critical Evidence Graph (CEG). We curate a dataset of challenging clinical cases and algorithmically construct a CEG for each sample to represent a high-quality verifiable reasoning pathway. To guide the reasoning process, we introduce a Clinical Reasoning Procedure Reward, which evaluates Node Coverage, Structural Correctness, and Chain Completeness, thereby providing a holistic assessment of reasoning quality. Experimental results show that MedCEG surpasses existing methods in performance while producing clinically valid reasoning chains, representing a solid advancement in reliable medical AI reasoning. The code and models are available at https://github.com/LinjieMu/MedCEG.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [261] [Vibe Coding in Practice: Flow, Technical Debt, and Guidelines for Sustainable Use](https://arxiv.org/abs/2512.11922)
*Muhammad Waseem,Aakash Ahmad,Kai-Kristian Kemell,Jussi Rasku,Sami Lahti,Kalle Mäkelä,Pekka Abrahamsson*

Main category: cs.SE

TL;DR: VC通过自然语言生成代码加速开发，但可能导致技术债务。文章分析了其成因并提出了解决方案。


<details>
  <summary>Details</summary>
Motivation: 研究VC在快速原型设计和MVP开发中的潜力及其带来的技术债务风险。

Method: 基于内部开发的多个MVP经验和行业报告分析，探讨了VC中的流程-债务权衡问题。

Result: 识别了模型、平台和硬件限制对技术债务的影响，并提出了相应的对策。

Conclusion: 文章提出了针对Vibe Coding（VC）中技术债务问题的对策，旨在推动更可持续的VC方法。

Abstract: Vibe Coding (VC) is a form of software development assisted by generative AI, in which developers describe the intended functionality or logic via natural language prompts, and the AI system generates the corresponding source code. VC can be leveraged for rapid prototyping or developing the Minimum Viable Products (MVPs); however, it may introduce several risks throughout the software development life cycle. Based on our experience from several internally developed MVPs and a review of recent industry reports, this article analyzes the flow-debt tradeoffs associated with VC. The flow-debt trade-off arises when the seamless code generation occurs, leading to the accumulation of technical debt through architectural inconsistencies, security vulnerabilities, and increased maintenance overhead. These issues originate from process-level weaknesses, biases in model training data, a lack of explicit design rationale, and a tendency to prioritize quick code generation over human-driven iterative development. Based on our experiences, we identify and explain how current model, platform, and hardware limitations contribute to these issues, and propose countermeasures to address them, informing research and practice towards more sustainable VC approaches.

</details>


### [262] [A Systematic Mapping Study on Risks and Vulnerabilities in Software Containers](https://arxiv.org/abs/2512.11940)
*Maha Sroor,Teerath Das,Rahul Mohanani,Tommi Mikkonen*

Main category: cs.SE

TL;DR: 通过系统映射研究分析129篇文献，总结了容器系统的安全风险、漏洞分类及缓解策略，为未来安全增强研究提供方向。


<details>
  <summary>Details</summary>
Motivation: 软件容器在开发和部署中广泛应用，但存在重大安全隐患，且缺乏对风险、漏洞、安全实践和工具的综述与系统化知识。

Method: 基于129篇选定的一手研究进行系统映射研究（SMS），探索并组织软件容器系统中的安全知识。

Result: 识别了容器生命周期中的关键风险和漏洞，并提出了分类法；总结了缓解技术和安全实践工具，以提升容器系统的整体安全性。

Conclusion: 本研究通过系统映射研究（SMS）总结了软件容器系统中的安全问题和解决方案，强调了未来软件工程研究应关注容器系统的安全增强实践和有效缓解策略。

Abstract: Software containers are widely adopted for developing and deploying software applications. Despite their popularity, major security concerns arise during container development and deployment. Software Engineering (SE) research literature reveals a lack of reviewed, aggregated, and organized knowledge of risks, vulnerabilities, security practices, and tools in container-based systems development and deployment. Therefore, we conducted a Systematic Mapping Study (SMS) based on 129 selected primary studies to explore and organize existing knowledge on security issues in software container systems. Data from the primary studies enabled us to identify critical risks and vulnerabilities across the container life-cycle and categorize them using a novel taxonomy. Additionally, the findings highlight the causes and implications and provide a list of mitigation techniques to overcome these risks and vulnerabilities. Furthermore, we provide an aggregation of security practices and tools that can help support and improve the overall security of container systems. This study offers critical insights into the current landscape of security issues within software container systems. Our analysis highlights the need for future SE research to focus on security enhancement practices that strengthen container systems and develop effective mitigation strategies to comprehensively address existing risks and vulnerabilities.

</details>


### [263] [Evidence-Driven Decision Support for AI Model Selection in Research Software Engineering](https://arxiv.org/abs/2512.11984)
*Alireza Joonbakhsh,Alireza Rostami,AmirMohammad Kamalinia,Ali Nazeri,Farshad Khunjush,Bedir Tekinerdogan,Siamak Farshidi*

Main category: cs.SE

TL;DR: 本研究提出一个基于多准则决策（MCDM）的AI模型选择框架ModelSelect，通过实证验证显示其推荐可靠且与专家推理一致，提升了研究软件决策的质量和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: AI模型和方法的快速扩散为研究软件工程师和研究人员在选择、集成和维护复杂研究流程中的模型带来了挑战，当前的选择过程依赖零散的元数据和个体专业知识，影响了可复现性、透明性和研究软件质量。

Method: 采用设计科学研究方法，提出了一个整合自动化数据收集管道、结构化知识图谱和MCDM原则的框架，并通过50个真实案例研究和与领先生成AI系统的对比实验进行实证验证。

Result: 评估结果显示，ModelSelect能生成可靠、可解释且可复现的推荐，与专家推理高度一致。在案例研究中，该框架在模型和库推荐任务中实现了高覆盖率和强合理性对齐，性能与生成AI助手相当，同时提供更优的可追溯性和一致性。

Conclusion: 本研究通过将AI模型选择问题概念化为多准则决策（MCDM）问题，提出了一个结构化和证据驱动的决策支持框架（ModelSelect），为研究软件工程中的透明和可复现决策支持奠定了严谨基础。

Abstract: The rapid proliferation of artificial intelligence (AI) models and methods presents growing challenges for research software engineers and researchers who must select, integrate, and maintain appropriate models within complex research workflows. Model selection is often performed in an ad hoc manner, relying on fragmented metadata and individual expertise, which can undermine reproducibility, transparency, and overall research software quality.
  This work proposes a structured and evidence-driven approach to support AI model selection that aligns with both technical and contextual requirements. We conceptualize AI model selection as a Multi-Criteria Decision-Making (MCDM) problem and introduce an evidence-based decision-support framework that integrates automated data collection pipelines, a structured knowledge graph, and MCDM principles. Following the Design Science Research methodology, the proposed framework (ModelSelect) is empirically validated through 50 real-world case studies and comparative experiments against leading generative AI systems.
  The evaluation results show that ModelSelect produces reliable, interpretable, and reproducible recommendations that closely align with expert reasoning. Across the case studies, the framework achieved high coverage and strong rationale alignment in both model and library recommendation tasks, performing comparably to generative AI assistants while offering superior traceability and consistency.
  By framing AI model selection as an MCDM problem, this work establishes a rigorous foundation for transparent and reproducible decision support in research software engineering. The proposed framework provides a scalable and explainable pathway for integrating empirical evidence into AI model recommendation processes, ultimately improving the quality and robustness of research software decision-making.

</details>


### [264] [Re-opening open-source science through AI assisted development](https://arxiv.org/abs/2512.11993)
*Ling-Hong Hung,Ka Yee Yeung*

Main category: cs.SE

TL;DR: AI团队成功修改STAR代码库，新增Flex数据处理功能，展示了AI在开源科学软件中的潜力。


<details>
  <summary>Details</summary>
Motivation: 解决开源科学软件因复杂性而难以修改的问题，重新开放科学软件社区参与。

Method: 采用AI团队主导的代码修改方法，对STAR代码库进行大规模修改，新增16,000行C++代码以支持Flex数据处理。

Result: 成功开发了首个支持Flex数据的开源处理软件STAR-Flex，并保持原有功能完整。

Conclusion: 开源科学软件通过AI团队的协作可以重新向社区开放，STAR-Flex案例展示了AI生成代码的可行性和效率。

Abstract: Open-source scientific software is effectively closed to modification by its complexity. With recent advances in technology, an agentic AI team led by a single human can now rapidly and robustly modify large codebases and re-open science to the community which can review and vet the AI generated code. We demonstrate this with a case study, STAR-Flex, which is an open source fork of STAR, adding 16,000 lines of C++ code to add the ability to process 10x Flex data, while maintaining full original function. This is the first open-source processing software for Flex data and was written as part of the NIH funded MorPHiC consortium.

</details>


### [265] [A Reference Architecture for Embedding Quantum Software Into Enterprise Systems](https://arxiv.org/abs/2512.12009)
*Marc Uphues,Sebastian Thöne,Herbert Kuchen*

Main category: cs.SE

TL;DR: 本文提出了一种模块化架构，用于将量子软件集成到企业系统中，并通过案例研究验证了其可行性。


<details>
  <summary>Details</summary>
Motivation: 量子计算在解决企业系统中的计算密集型问题方面具有潜力，但需要特定的软件架构考虑其特性和质量属性。

Method: 采用松散耦合和分布式服务构建模块，实现量子独立和量子特定任务，并通过可执行的BPMN模型规范其编排。

Result: 提出的参考架构在解决运筹学中的组合挑战的两个案例研究中得到了验证。

Conclusion: 本文提出了一种模块化的参考架构，用于将量子软件嵌入企业系统，并通过两个案例研究验证了其有效性。

Abstract: Quantum computing promises a remarkable performance boost for certain applications, including computational intensive problems addressed by enterprise systems. However, software architectures of enterprise systems must consider specific characteristics and quality attributes when collaborating with quantum computing services. Hence, this paper presents a modular reference architecture for embedding quantum software into enterprise systems. Its building blocks consist of loosely coupled and distributed services that implement both quantum-independent and quantum-specific tasks. Although these services either depend on the business domain or the selected quantum algorithm, their orchestration forms a stable and reusable pipeline, specified as an executable BPMN model. For demonstration and evaluation purposes, the proposed reference architecture is utilized in two case studies addressing combinatorial challenges from the field of operations research.

</details>


### [266] [Hyper model checking for high-level relational models](https://arxiv.org/abs/2512.12024)
*Nuno Macedo,Hugo Pacheco*

Main category: cs.SE

TL;DR: HyperPardinus 扩展了 Alloy，使其支持超属性的规范和验证，填补了早期设计阶段验证工具的空白。


<details>
  <summary>Details</summary>
Motivation: 现有的高级规范语言在支持软件工程实践者在系统设计早期验证超属性方面存在不足。

Method: 通过扩展 Pardinus（Alloy 的时序逻辑后端），利用现有的低级模型检查器来自动验证关系模型上的超属性。

Result: 评估表明，HyperPardinus 能够建模和找到具有交替量词的复杂超属性的（反）示例，使其能够解决相关的前沿场景。

Conclusion: HyperPardinus 扩展了 Alloy 的能力，使其能够支持高级别的超属性规范和自动验证，填补了现有工具在早期系统设计阶段验证超属性的空白。

Abstract: Many properties related to security or concurrency must be encoded as so-called hyperproperties, temporal properties that allow reasoning about multiple traces of a system. However, despite recent advances on model checking hyperproperties, there is still a lack of higher-level specification languages that can effectively support software engineering practitioners in verifying properties of this class at early stages of system design.
  Alloy is a lightweight formal method with a high-level specification language that is supported by automated analysis procedures, making it particularly well-suited for the verification of design models at early development stages. It does not natively support, however, the verification of hyperproperties.
  This work proposes HyperPardinus, a new model finding procedure that extends Pardinus -- the temporal logic backend of the Alloy language -- to automatically verify hyperproperties over relational models by relying on existing low-level model checkers for hyperproperties. It then conservatively extends Alloy to support the specification and automatic verification of hyperproperties over design models, as well as the visualization of (counter-)examples at a higher-level of abstraction. Evaluation shows that our approach enables modeling and finding (counter-)examples for complex hyperproperties with alternating quantifiers, making it feasible to address relevant scenarios from the state of the art.

</details>


### [267] [Instruction-Tuning Open-Weight Language Models for BPMN Model Generation](https://arxiv.org/abs/2512.12063)
*Gökberk Çelikmasat,Atay Özgövde,Fatma Başak Aydemir*

Main category: cs.SE

TL;DR: InstruBPM通过指令调优开源大语言模型，高效生成高质量BPMN流程模型，减少建模工作量。


<details>
  <summary>Details</summary>
Motivation: 解决实践中因耗时和专业性需求高而跳过建模的问题，探索低成本、隐私保护的自然语言生成BPMN模型方法。

Method: 引入InstruBPM方法，通过参数高效微调和量化技术对开源大语言模型进行指令调优，并采用多角度评估（文本/代码相似性、结构保真度、指南符合性及专家评审）。

Result: 调优后的模型在序列和结构指标上均优于基线，生成的图表遵循BPMN最佳实践，是减少建模工作的有效起点。

Conclusion: 指令调优的开源大语言模型InstruBPM在生成高质量BPMN流程模型方面表现优异，显著减少建模工作量，且资源需求低。

Abstract: Domain models are central to software engineering, as they enable a shared understanding, guide implementation, and support automated analyses and model-driven development. Yet, despite these benefits, practitioners often skip modeling because it is time-consuming and demands scarce expertise. We address this barrier by investigating whether open-weight large language models, adapted via instruction tuning, can generate high-quality BPMN process models directly from natural language descriptions in a cost-effective and privacy-preserving way. We introduce InstruBPM, a reproducible approach that prepares paired text-diagram data and instruction tunes an open source large language model with parameter-efficient fine-tuning and quantization for on-prem deployment. We evaluate the tuned model through complementary perspectives: (i) text/code similarity using BLEU, ROUGE-L, and METEOR, (ii) structural fidelity using Relative Graph Edit Distance, (iii) guidelines conformance using external tool checks, and (iv) a small expert review. Using a curated subset of a multi-domain BPMN dataset, we compare the tuned model with untuned open-weight baselines and strong proprietary models under consistent prompting regimes. Our compact tuned model outperforms all baselines across sequence and structural metrics while requiring substantially fewer resources; guideline analysis and expert feedback further indicate that the generated diagrams largely follow BPMN best practices and are useful starting points that reduce modeling effort. Overall, instruction tuning improves structural accuracy and robustness compared to untuned baselines and reduces reliance on heavy prompt scaffolding. We publicly share the trained models and scripts to support reproducibility and further research.

</details>


### [268] [Citation-Grounded Code Comprehension: Preventing LLM Hallucination Through Hybrid Retrieval and Graph-Augmented Context](https://arxiv.org/abs/2512.12117)
*Jahidul Arafat*

Main category: cs.SE

TL;DR: 论文提出混合检索系统结合结构推理，显著提高代码理解中的引用准确率，减少LLM幻觉。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在代码理解中产生的幻觉问题（生成看似合理但事实错误的引用），以实现可验证的、基于引用的代码理解。

Method: 开发了一种混合检索系统，结合BM25稀疏匹配、BGE密集嵌入和Neo4j图扩展（通过导入关系），在30个Python仓库和180个开发者查询中进行了系统性评估。

Result: 混合检索系统在引用准确率上比单一模式基线提高了14至18个百分点，并在62%的架构查询中发现了纯文本相似性遗漏的跨文件证据。

Conclusion: 论文主张将基于引用的生成作为代码理解系统的架构原则，并通过结合BM25稀疏匹配、BGE密集嵌入和Neo4j图扩展的混合检索系统，实现了92%的引用准确率和零幻觉。

Abstract: Large language models have become essential tools for code comprehension, enabling developers to query unfamiliar codebases through natural language interfaces. However, LLM hallucination, generating plausible but factually incorrect citations to source code, remains a critical barrier to reliable developer assistance. This paper addresses the challenges of achieving verifiable, citation grounded code comprehension through hybrid retrieval and lightweight structural reasoning. Our work is grounded in systematic evaluation across 30 Python repositories with 180 developer queries, comparing retrieval modalities, graph expansion strategies, and citation verification mechanisms. We find that challenges of citation accuracy arise from the interplay between sparse lexical matching, dense semantic similarity, and cross file architectural dependencies. Among these, cross file evidence discovery is the largest contributor to citation completeness, but it is largely overlooked because existing systems rely on pure textual similarity without leveraging code structure. We advocate for citation grounded generation as an architectural principle for code comprehension systems and demonstrate this need by achieving 92 percent citation accuracy with zero hallucinations. Specifically, we develop a hybrid retrieval system combining BM25 sparse matching, BGE dense embeddings, and Neo4j graph expansion via import relationships, which outperforms single mode baselines by 14 to 18 percentage points while discovering cross file evidence missed by pure text similarity in 62 percent of architectural queries.

</details>


### [269] [Training Versatile Coding Agents in Synthetic Environments](https://arxiv.org/abs/2512.12216)
*Yiqi Zhu,Apurva Gandhi,Graham Neubig*

Main category: cs.SE

TL;DR: SWE-Playground通过合成生成项目和任务，解决了现有方法依赖外部数据源和任务类型有限的问题，显著提升了训练效率和多样性。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖GitHub仓库且任务类型有限，限制了软件工程代理的训练多样性和灵活性。

Method: 引入SWE-Playground管道，利用强语言模型和代理从零开始生成项目和任务。

Result: 在三个基准测试中，SWE-Playground生成的轨迹提供了密集的训练信号，使代理在更少轨迹下达到可比性能。

Conclusion: SWE-Playground通过合成生成项目和任务，显著提升了训练编码代理的灵活性和多样性，减少了对外部数据源的依赖。

Abstract: Prior works on training software engineering agents have explored utilizing existing resources such as issues on GitHub repositories to construct software engineering tasks and corresponding test suites. These approaches face two key limitations: (1) their reliance on pre-existing GitHub repositories offers limited flexibility, and (2) their primary focus on issue resolution tasks restricts their applicability to the much wider variety of tasks a software engineer must handle. To overcome these challenges, we introduce SWE-Playground, a novel pipeline for generating environments and trajectories which supports the training of versatile coding agents. Unlike prior efforts, SWE-Playground synthetically generates projects and tasks from scratch with strong language models and agents, eliminating reliance on external data sources. This allows us to tackle a much wider variety of coding tasks, such as reproducing issues by generating unit tests and implementing libraries from scratch. We demonstrate the effectiveness of this approach on three distinct benchmarks, and results indicate that SWE-Playground produces trajectories with dense training signal, enabling agents to reach comparable performance with significantly fewer trajectories than previous works.

</details>


### [270] [Cluster-guided LLM-Based Anonymization of Software Analytics Data: Studying Privacy-Utility Trade-offs in JIT Defect Prediction](https://arxiv.org/abs/2512.12224)
*Maaz Khan,Gul Sher Khan,Ahsan Raza,Pir Sami Ullah,Abdul Ali Bangash*

Main category: cs.SE

TL;DR: 利用LLM的集群引导匿名化技术，在JIT缺陷预测中实现了更好的隐私-效用权衡。


<details>
  <summary>Details</summary>
Motivation: 现有匿名化方法忽视了软件指标间的上下文依赖关系，导致隐私与效用之间的权衡不佳。

Method: 提出了一种基于集群的匿名化方法，通过LLM生成上下文感知的参数配置，定义alpha-beta比率和变更混合分布用于匿名化。

Result: 在六个项目上的评估显示，该方法实现了隐私级别2（IPR >= 80%），比现有图基匿名化基线提升了18至25%的隐私保护，同时保持相当的F1分数。

Conclusion: 该论文展示了利用大型语言模型（LLMs）进行集群引导的匿名化技术，能够在保持预测准确性的同时显著提升隐私保护水平。

Abstract: The increasing use of machine learning (ML) for Just-In-Time (JIT) defect prediction raises concerns about privacy leakage from software analytics data. Existing anonymization methods, such as tabular transformations and graph perturbations, often overlook contextual dependencies among software metrics, leading to suboptimal privacy-utility tradeoffs. Leveraging the contextual reasoning of Large Language Models (LLMs), we propose a cluster-guided anonymization technique that preserves contextual and statistical relationships within JIT datasets. Our method groups commits into feature-based clusters and employs an LLM to generate context-aware parameter configurations for each commit cluster, defining alpha-beta ratios and churn mixture distributions used for anonymization. Our evaluation on six projects (Cassandra, Flink, Groovy, Ignite, OpenStack, and Qt) shows that our LLM-based approach achieves privacy level 2 (IPR >= 80 percent), improving privacy by 18 to 25 percent over four state-of-the-art graph-based anonymization baselines while maintaining comparable F1 scores. Our results demonstrate that LLMs can act as adaptive anonymization engines when provided with cluster-specific statistical information about similar data points, enabling context-sensitive and privacy-preserving software analytics without compromising predictive accuracy.

</details>


### [271] [Evaluating Asynchronous Semantics in Trace-Discovered Resilience Models: A Case Study on the OpenTelemetry Demo](https://arxiv.org/abs/2512.12314)
*Anatoly A. Krasnovsky*

Main category: cs.SE

TL;DR: 本文提出了一种基于OpenTelemetry追踪的服务依赖图模型，通过蒙特卡洛模拟评估端点可用性。研究发现，在该案例中，异步依赖建模对HTTP可用性影响微乎其微，简化模型已足够。


<details>
  <summary>Details</summary>
Motivation: 尽管分布式追踪和混沌工程已成为微服务的标准，但弹性模型仍主要依赖手动和定制化方法。本文旨在通过追踪发现的连接性模型改进这一现状。

Method: 通过原始OpenTelemetry追踪直接推导服务依赖图，附加端点特定的成功谓词，并引入简单的异步语义（将Kafka边缘视为非阻塞以实现即时HTTP成功）。

Result: 模型能够重现整体可用性下降曲线，而Kafka边缘的异步语义对预测可用性的影响极小（最多约10^(-5)）。

Conclusion: 对于该案例研究，立即HTTP可用性而言，显式建模异步依赖关系并非必要，仅基于连接性的简单模型已足够。

Abstract: While distributed tracing and chaos engineering are becoming standard for microservices, resilience models remain largely manual and bespoke. We revisit a trace-discovered connectivity model that derives a service dependency graph from traces and uses Monte Carlo simulation to estimate endpoint availability under fail-stop service failures. Compared to earlier work, we (i) derive the graph directly from raw OpenTelemetry traces, (ii) attach endpoint-specific success predicates, and (iii) add a simple asynchronous semantics that treats Kafka edges as non-blocking for immediate HTTP success. We apply this model to the OpenTelemetry Demo ("Astronomy Shop") using a GitHub Actions workflow that discovers the graph, runs simulations, and executes chaos experiments that randomly kill microservices in a Docker Compose deployment. Across the studied failure fractions, the model reproduces the overall availability degradation curve, while asynchronous semantics for Kafka edges change predicted availabilities by at most about 10^(-5) (0.001 percentage points). This null result suggests that for immediate HTTP availability in this case study, explicitly modeling asynchronous dependencies is not warranted, and a simpler connectivity-only model is sufficient.

</details>


### [272] [The Role of AI in Modern Penetration Testing](https://arxiv.org/abs/2512.12326)
*J. Alexander Curtis,Nasir U. Eisty*

Main category: cs.SE

TL;DR: AI（尤其是强化学习）在渗透测试中显示出自动化潜力，但当前应用集中在发现和利用阶段，其他阶段和LLMs应用仍需探索。


<details>
  <summary>Details</summary>
Motivation: 随着系统复杂性的增加，传统手动渗透测试方法在可扩展性和效率上面临挑战，需要更先进的自动化解决方案。

Method: 系统文献综述，分析了来自主要学术数据库的58篇同行评审研究。

Result: 研究发现AI辅助渗透测试主要集中在发现和利用阶段，77%的研究聚焦于强化学习。实际应用如欧洲空间局的PenBox和开源工具展示了AI在攻击路径分析和网络拓扑分析中的潜力。

Conclusion: AI在渗透测试中的应用尚处于早期阶段，但在自动化重复任务、优化攻击策略和提高漏洞识别方面显示出巨大潜力。尽管面临灵活性和某些测试阶段（如侦察和后利用）发展不足的挑战，AI技术尤其是强化学习，已展现出显著的进展。未来研究应关注大型语言模型（LLMs）的应用。

Abstract: Penetration testing is a cornerstone of cybersecurity, traditionally driven by manual, time-intensive processes. As systems grow in complexity, there is a pressing need for more scalable and efficient testing methodologies. This systematic literature review examines how Artificial Intelligence (AI) is reshaping penetration testing, analyzing 58 peer-reviewed studies from major academic databases. Our findings reveal that while AI-assisted pentesting is still in its early stages, notable progress is underway, particularly through Reinforcement Learning (RL), which was the focus of 77% of the reviewed works. Most research centers on the discovery and exploitation phases of pentesting, where AI shows the greatest promise in automating repetitive tasks, optimizing attack strategies, and improving vulnerability identification. Real-world applications remain limited but encouraging, including the European Space Agency's PenBox and various open-source tools. These demonstrate AI's potential to streamline attack path analysis, analyze complex network topology, and reduce manual workload. However, challenges persist: current models often lack flexibility and are underdeveloped for the reconnaissance and post-exploitation phases of pentesting. Applications involving Large Language Models (LLMs) remain relatively under-researched, pointing to a promising direction for future exploration. This paper offers a critical overview of AI's current and potential role in penetration testing, providing valuable insights for researchers, practitioners, and organizations aiming to enhance security assessments through advanced automation or looking for gaps in existing research.

</details>


### [273] [ATLAS: Automated Tree-based Language Analysis System for C and C++ source programs](https://arxiv.org/abs/2512.12507)
*Jaid Monwar Chowdhury,Ahmad Farhan Shahriar Chowdhury,Humayra Binte Monwar,Mahmuda Naznin*

Main category: cs.SE

TL;DR: ATLAS是一个工具，通过生成控制流图和数据流图，解决C/C++代码分析中的结构依赖问题，支持多文件和不可编译代码。


<details>
  <summary>Details</summary>
Motivation: 传统编程分析技术在软件工程任务中存在不足，机器学习和大型语言模型受限于数据处理方式，无法有效捕捉源代码的复杂结构和依赖关系。

Method: ATLAS是一个基于Python的命令行工具，能够生成语句级控制流图和类型感知数据流图，支持多文件C/C++项目，并处理可编译和不可编译代码。

Result: ATLAS能够生成统一的多视图代码表示，保留关键的结构和语义信息。

Conclusion: ATLAS通过生成控制流图和数据流图，为软件工程和基于机器学习的程序理解提供了实用的基础。

Abstract: The growing complexity of modern software systems has highlighted the shortcomings of traditional programming analysis techniques, particularly for Software Engineering (SE) tasks. While machine learning and Large Language Models (LLMs) offer promising solutions, their effectiveness is limited by the way they interpret data. Unlike natural language, source code meaning is defined less by token adjacency and more by complex, long-range, and structural relationships and dependencies. This limitation is especially pronounced for C and C++, where flatter syntactic hierarchies, pointer aliasing, multi-level indirection, typedef-based type obfuscation, and function-pointer calls hinder accurate static analysis. To address these challenges, this paper introduces ATLAS, a Python-based Command-Line Interface (CLI) that (i) generates statement-level Control Flow Graphs (CFG) and type-aware Data Flow Graphs (DFG) that capture inter-functional dependencies for the entire program; (ii) has the ability to work on entire C and C++ projects comprising multiple files; (iii) works on both compilable and non-compilable code and (iv) produces a unified multi-view code representation using Abstract Syntax Trees (AST), CFG and DFG. By preserving essential structural and semantic information, ATLAS provides a practical foundation for improving downstream SE and machine-learning-based program understanding. Video demonstration: https://youtu.be/RACWQe5ELwY Tool repository: https://github.com/jaid-monwar/ATLAS-code-representation-tool

</details>


### [274] [Diverse LLMs vs. Vulnerabilities: Who Detects and Fixes Them Better?](https://arxiv.org/abs/2512.12536)
*Arastoo Zibaeirad,Marco Vieira*

Main category: cs.SE

TL;DR: DVDR-LLM集成多个LLM，提升漏洞检测准确率10-12%，多文件漏洞效果显著，但需权衡误报与漏报。


<details>
  <summary>Details</summary>
Motivation: 单个LLM在识别复杂漏洞和生成修复时表现不足，研究是否通过集成多个LLM的输出可以提升检测准确性和修复效果。

Method: 提出DVDR-LLM集成框架，结合多个LLM的输出，评估聚合模型是否能降低错误率。通过对比集成模型与单个模型的性能差异，分析不同代码复杂度下的表现。

Result: DVDR-LLM比单个模型平均检测准确率提高10-12%，多文件漏洞场景下召回率提升18%、F1分数提升11.8%，但存在误报与漏报的权衡。

Conclusion: DVDR-LLM框架通过集成多个LLM的输出，显著提高了软件漏洞检测和修复的准确性，尤其是在复杂代码和多文件漏洞场景中。然而，该方法在减少误报的同时增加了漏报，需根据安全需求权衡模型间的一致性阈值。

Abstract: Large Language Models (LLMs) are increasingly being studied for Software Vulnerability Detection (SVD) and Repair (SVR). Individual LLMs have demonstrated code understanding abilities, but they frequently struggle when identifying complex vulnerabilities and generating fixes.
  This study presents DVDR-LLM, an ensemble framework that combines outputs from diverse LLMs to determine whether aggregating multiple models reduces error rates. Our evaluation reveals that DVDR-LLM achieves 10-12% higher detection accuracy compared to the average performance of individual models, with benefits increasing as code complexity grows. For multi-file vulnerabilities, the ensemble approach demonstrates significant improvements in recall (+18%) and F1 score (+11.8%) over individual models. However, the approach raises measurable trade-offs: reducing false positives in verification tasks while simultaneously increasing false negatives in detection tasks, requiring careful decision on the required level of agreement among the LLMs (threshold) for increased performance across different security contexts.
  Artifact: https://github.com/Erroristotle/DVDR_LLM

</details>


### [275] [Assessing the Capability of Android Dynamic Analysis Tools to Combat Anti-Runtime Analysis Techniques](https://arxiv.org/abs/2512.12551)
*Dewen Suo,Lei Xue,Weihao Huang,Runze Tan,Guozi Sun*

Main category: cs.SE

TL;DR: 论文实证研究表明，当前Android动态分析工具难以有效对抗ARA技术，亟需更强大的解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着Android应用的快速增长，恶意应用采用ARA技术阻碍动态分析，威胁生态系统安全，亟需研究现有工具的应对能力。

Method: 通过全面的实证研究，评估了广泛使用的Android动态分析工具绕过各种ARA技术的能力。

Result: 研究发现现有动态分析工具在对抗ARA机制方面存在显著不足，凸显了改进方法的紧迫性。

Conclusion: 该论文强调了现有Android动态分析工具在对抗ARA技术方面的不足，并呼吁开发更强大的解决方案以提升平台安全性。

Abstract: As the dominant mobile operating system, Android continues to attract a substantial influx of new applications each year. However, this growth is accompanied by increased attention from malicious actors, resulting in a significant rise in security threats to the Android ecosystem. Among these threats, the adoption of Anti-Runtime Analysis (ARA) techniques by malicious applications poses a serious challenge, as it hinders security professionals from effectively analyzing malicious behaviors using dynamic analysis tools. ARA technologies are designed to prevent the dynamic examination of applications, thus complicating efforts to ensure platform security. This paper presents a comprehensive empirical study that assesses the ability of widely-used Android dynamic analysis tools to bypass various ARA techniques. Our findings reveal a critical gap in the effectiveness of existing dynamic analysis tools to counter ARA mechanisms, highlighting an urgent need for more robust solutions. This work provides valuable insights into the limitations of existing tools and highlights the need for improved methods to counteract ARA technologies, thus advancing the field of software security and dynamic analysis.

</details>


### [276] [SHERLOCK: A Deep Learning Approach To Detect Software Vulnerabilities](https://arxiv.org/abs/2512.12593)
*Saadh Jawwadh,Guhanathan Poravi*

Main category: cs.SE

TL;DR: 使用CNN检测软件漏洞，效果优于传统方法，但数据集标准化是未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 软件漏洞可能导致安全漏洞和数据泄露，传统检测方法效果不佳。

Method: 采用卷积神经网络（CNN）和5折交叉验证方法，输入为标记化的源代码。

Result: Sherlock在函数级别成功检测到多个漏洞，对CWE-199、CWE-120和CWE-Other表现优异，但部分漏洞因数据集问题表现不稳定。

Conclusion: 与传统技术相比，提出的深度学习方法有潜力显著提高软件漏洞检测的准确性。

Abstract: The increasing reliance on software in various applications has made the problem of software vulnerability detection more critical. Software vulnerabilities can lead to security breaches, data theft, and other negative outcomes. Traditional software vulnerability detection techniques, such as static and dynamic analysis, have been shown to be ineffective at detecting multiple vulnerabilities.
  To address this issue, this study employed a deep learning approach, specifically Convolutional Neural Networks (CNN), to solve the software vulnerability detection problem. A 5-split cross-validation approach was used to train and evaluate the CNN model, which takes tokenized source code as input.
  The findings indicated that Sherlock successfully detected multiple vulnerabilities at the function level, and its performance was particularly strong for CWE-199, CWE-120, and CWE-Other, with an overall high accuracy rate and significant true positive and true negative values. However, the performance was less reliable for some vulnerabilities due to the lack of a standardized dataset which will be a future research direction. The results suggest that compared to current techniques, the proposed deep learning approach has the potential to substantially enhance the accuracy of software vulnerability detection.

</details>


### [277] [A Systematic Analysis of Higher Education on Software Engineering in the Netherlands](https://arxiv.org/abs/2512.12650)
*Bastiaan Heeren,Fabiano Dalpiaz,Mazyar Seraj,Roberto Verdecchia,Vadim Zaytsev*

Main category: cs.SE

TL;DR: 研究分析了荷兰10所大学的207门软件工程课程，发现Construction and Programming是本科最常覆盖的知识领域，识别了三个紧密耦合的知识领域集群，并指出软件工程经济学等未被充分代表的领域。


<details>
  <summary>Details</summary>
Motivation: 理解软件工程高等教育的现状，使教育者能够批判性评估课程，通过基准化观察到的实践进行微调，并最终提升课程质量。

Method: 研究通过考虑10所荷兰大学和207门大学课程，采用SWEBOK的知识领域进行分析，包括同质化和内部一致性改进阶段，随后进行数据分析。

Result: Construction and Programming是最常覆盖的本科知识领域，其他领域在本科和硕士阶段同等覆盖，而更高级的领域几乎仅在硕士阶段。识别了三个紧密耦合的知识领域集群，并发现荷兰大学普遍均匀覆盖所有知识领域，少数偏差反映机构研究优势。

Conclusion: 研究结果强调了关键知识领域之间的相关性及其对增强综合学习的潜力，并指出了如软件工程经济学等未被充分代表的领域，建议教育者考虑纳入课程。同时邀请研究者在其他地理区域应用该方法，以对比全球软件工程教育项目。

Abstract: Software engineering educators strive to continuously improve their courses and programs. Understanding the current state of practice of software engineering higher education can empower educators to critically assess their courses, fine-tune them by benchmarking against observed practices, and ultimately enhance their curricula. In this study, we aim to provide an encompassing analysis of higher education on software engineering by considering the higher educational offering of an entire European country, namely the Netherlands. We leverage a crowd-sourced analysis process by considering 10 Dutch universities and 207 university courses. The courses are analysed via knowledge areas adopted from the SWEBOK. The mapping process is refined via homogenisation and internal consistency improvement phases, and is followed by a data analysis phase. Given its fundamental nature, Construction and Programming is the most covered knowledge area at Bachelor level. Other knowledge areas are equally covered at Bachelor and Master level (e.g., software engineering models), while more advanced ones are almost exclusively covered at Master level. We identify three clusters of tightly coupled knowledge areas: (i) requirements, architecture, and design, (ii) testing, verification, and security, and (iii) process-oriented and DevOps topics. Dutch universities generally cover all knowledge areas uniformly, with minor deviations reflecting institutional research strengths. Our results highlight correlations among key knowledge areas and their potential for enhancing integrated learning. We also identify underrepresented areas, such as software engineering economics, which educators may consider including in curricula. We invite researchers to use our research method in their own geographical region, in order to contrast software engineering education programs across the globe.

</details>


### [278] [Attributes to Support the Formulation of Practically Relevant Research Problems in Software Engineering](https://arxiv.org/abs/2512.12699)
*Anrafel Fernandes Pereira,Maria Teresa Baldassarre,Daniel Mendez,Jürgen Börstler,Nauman bin Ali,Rahul Mohanani,Darja Smite,Stefan Biffl,Rogardt Heldal,Davide Falessi,Daniel Graziotin,Marcos Kalinowski*

Main category: cs.SE

TL;DR: 研究通过研讨会确认了七个属性在制定软件工程研究问题中的重要性，并提出了改进建议，以更好地对齐学术与行业需求。


<details>
  <summary>Details</summary>
Motivation: 软件工程（SE）中，一个良好制定的研究问题对实现实际相关性至关重要，但早期阶段缺乏结构化指导。

Method: 在ISERN 2024会议期间，与42位资深软件工程研究人员进行了研讨会。通过问题愿景板展示七个属性，参与者分组讨论、分享书面反馈，并完成调查评估其重要性、完整性和改进建议。

Result: 研究结果确认了七个属性在制定面向行业的研究问题中的重要性。定性反馈展示了如何实际应用这些属性，并提出了改进建议，如在影响/影响中纳入财务标准（如ROI），并在证据下解决可行性和约束。

Conclusion: 研究结果重申了七个属性在支持反思性和情境感知问题制定中的重要性。根据特定研究背景调整其使用有助于改善学术研究与行业需求之间的对齐。

Abstract: [Background] A well-formulated research problem is essential for achieving practical relevance in Software Engineering (SE), yet there is a lack of structured guidance in this early phase. [Aims] Our goal is to introduce and evaluate seven attributes identified in the SE literature as relevant for formulating research problems (practical problem, context, implications/impacts, practitioners, evidence, objective, and research questions) in terms of their perceived importance and completeness, and learn how they can be applied. [Method] We conducted a workshop with 42 senior SE researchers during the ISERN 2024 meeting. The seven attributes were presented using a Problem Vision board filled with a research example. Participants discussed attributes in groups, shared written feedback, and individually completed a survey assessing their importance, completeness, and suggestions for improvement. [Results] The findings confirm the importance of the seven attributes in the formulation of industry-oriented research problems. Qualitative feedback illustrated how they can be applied in practice and revealed suggestions to refine them, such as incorporating financial criteria (e.g., ROI) into implications/impacts and addressing feasibility and constraints under evidence. [Conclusion] The results reaffirm the importance of the seven attributes in supporting a reflective and context-aware problem formulation. Adapting their use to specific research contexts can help to improve the alignment between academic research and industry needs.

</details>


### [279] [Towards AI Agents Supported Research Problem Formulation](https://arxiv.org/abs/2512.12719)
*Anrafel Fernandes Pereira,Maria Teresa Baldassarre,Daniel Mendez,Marcos Kalinowski*

Main category: cs.SE

TL;DR: 本文探讨利用AI代理支持软件工程研究者在研究问题构建阶段，通过Lean Research Inception框架展示其潜力，但需进一步实证验证。


<details>
  <summary>Details</summary>
Motivation: 研究问题构建不当可能影响软件工程研究的实际相关性，未能反映工业实践的复杂性。本文探索利用AI代理支持SE研究者在研究项目早期阶段构建研究问题。

Method: 基于Lean Research Inception框架，并参考已发表的关于机器学习代码可维护性的研究，开发了一个描述性评估场景，展示AI代理如何支持SE研究者。

Result: 描述性评估表明，AI代理支持可以丰富协作讨论，并增强对研究问题价值、可行性和适用性的批判性反思。

Conclusion: 尽管将AI代理整合到LRI框架中以支持研究问题构建的愿景被认为是有前景的，但仍需实证验证来确认和优化这一整合。

Abstract: Poorly formulated research problems can compromise the practical relevance of Software Engineering studies by not reflecting the complexities of industrial practice. This vision paper explores the use of artificial intelligence agents to support SE researchers during the early stage of a research project, the formulation of the research problem. Based on the Lean Research Inception framework and using a published study on code maintainability in machine learning as a reference, we developed a descriptive evaluation of a scenario illustrating how AI agents, integrated into LRI, can support SE researchers by pre filling problem attributes, aligning stakeholder perspectives, refining research questions, simulating multiperspective assessments, and supporting decision making. The descriptive evaluation of the scenario suggests that AI agent support can enrich collaborative discussions and enhance critical reflection on the value, feasibility, and applicability of the research problem. Although the vision of integrating AI agents into LRI was perceived as promising to support the context aware and practice oriented formulation of research problems, empirical validation is needed to confirm and refine the integration of AI agents into problem formulation.

</details>


### [280] [Temporal HAL-API Dependencies as a Gateway to Formal Embedded Software Development](https://arxiv.org/abs/2512.12788)
*Manuel Bentele,Andreas Podelski,Axel Sikora,Bernd Westphal*

Main category: cs.SE

TL;DR: THADs 通过注释和自动验证，为嵌入式软件提供了一种经济高效的形式化方法，介于通用和特定属性之间。


<details>
  <summary>Details</summary>
Motivation: THADs 能够捕捉嵌入式软件开发中的一类重要正确性属性，且规范和验证成本适中。

Method: 通过程序注释进行规范，并通过软件模型检查自动验证。

Result: THADs 在规范和验证效率上取得了平衡，适合工业嵌入式软件开发。

Conclusion: THADs 在嵌入式软件开发中提供了一个介于通用属性和应用特定属性之间的平衡点，有望促进形式化方法在工业中的更广泛应用。

Abstract: Temporal HAL-API Dependencies (THADs) can be useful to capture an interesting class of correctness properties in embedded software development. They demand a moderate effort for specification (which can be done via program annotations) and verification (which can be done automatically via software model checking). In this sense, they have the potential to form an interesting sweet spot between generic properties (that demand virtually no specification effort, and that are typically addressed by static analysis) and application-specific properties as addressed by full-fledged formal methods. Thus, they may form a gateway to wider and more economic use of formal methods in industrial embedded software development.

</details>


### [281] [Challenges and Enablers: Remote Work for People with Disabilities in Software Development Teams](https://arxiv.org/abs/2512.12965)
*Thayssa Rocha,Luciano Teran,Marcelle Mota,Cleidson de Souza,Kiev Gama,Gustavo Pinto*

Main category: cs.SE

TL;DR: 远程工作为残疾开发者带来机会与挑战，但团队对其协作障碍认知有限，需改进工具与管理。


<details>
  <summary>Details</summary>
Motivation: 探讨远程和混合工作模式如何影响残疾人士在软件开发团队中的体验，聚焦远程环境中的独特挑战与策略。

Method: 通过在线调查（收集了有效回应）和14次结构化访谈（涵盖自闭症、身体残疾及聋哑开发者），结合定量数据和定性编码分析。

Result: 结果显示，残疾团队成员面临障碍，但队友和领导者对其日常协作挑战的认知不足。

Conclusion: 研究指出，尽管远程工作为残疾人士（PWD）在软件开发团队（SDT）中的融入带来了新的机会，但团队成员和领导者对其日常协作挑战的认知有限，需改进无障碍工具、沟通策略和适应性管理方法。

Abstract: The increasing adoption of remote and hybrid work modalities in the technology sector has brought new opportunities and challenges for the inclusion of people with disabilities (PWD) in software development teams (SDT). This study investigates how remote work affects PWDs' experience in mixed-ability SDT, focusing on the unique challenges and strategies that emerge in remote environments. We conducted an online survey with \totalSurveyResponses valid responses, encompassing PWD, their leaders, and teammates, to capture sociotechnical aspects of their experiences with remote collaboration. To deepen our understanding, we carried out 14 structured interviews with software developers who self-identified as having disabilities (six autistic individuals, six with physical disabilities, and two who are d/Deaf). Our analysis combines quantitative data with qualitative coding of open-ended survey responses and interview transcripts. The results reveal that, despite the barriers faced by team members with disabilities, their teammates and leaders have a limited perception of the daily challenges involved in sustaining collaborative remote work. These findings highlight opportunities for improvement in accessibility tools, communication strategies, and adaptive management approaches.

</details>


### [282] [A Decision Support Framework for Blockchain Pattern Selection Based on Soft Goals](https://arxiv.org/abs/2512.13239)
*Eddy Kiomba Kambilo,Nicolas Herbaut,Irina Rychkova,Carine Souveyet*

Main category: cs.SE

TL;DR: BC-TEAEM框架结合区块链模式和软目标，支持系统化选择区块链模式，案例验证了其适用性。


<details>
  <summary>Details</summary>
Motivation: 区块链技术的多样性和缺乏标准化框架使得系统架构师在选择模式时面临复杂挑战，需要一种方法将业务目标与技术设计决策联系起来。

Method: 提出了Blockchain--Technology-Aware Enterprise Modeling (BC-TEAEM)框架，结合区块链模式本体、领域无关软目标和多准则决策方法，通过迭代捕获和细化偏好来支持区块链模式的系统化选择。

Result: 开发了一个原型决策支持工具，并通过制药公司供应链追溯系统的案例研究验证了框架的适用性。

Conclusion: BC-TEAEM框架通过结合区块链模式和领域无关的软目标，提供了一种系统化的区块链模式选择方法，有效解决了业务目标与技术设计决策之间的对齐问题。

Abstract: Blockchain technology is gaining momentum across many sectors. Whereas blockchain solutions have important positive effects on the business domain, they also introduce constraints and may cause delayed or unforeseen negative effects, undermining business strategies. The diversity of blockchain patterns and lack of standardized frameworks linking business goals to technical design decisions make pattern selection a complex task for system architects. To address this challenge, we propose Blockchain--Technology-Aware Enterprise Modeling (BC-TEAEM), a decision support framework that combines ontologies of blockchain patterns and domain-independent soft goals with a multi-criteria decision-making approach. The framework focuses on the interplay between a domain expert and a technical expert to ensure alignment and traceability. By iteratively capturing and refining preferences, BC-TEAEM supports systematic selection of blockchain patterns. We develop a prototype decision support tool implementing our method and validate it through a case study of a pharmaceutical company's supply chain traceability system, demonstrating the framework's applicability. %a supply chain traceability case study.

</details>


### [283] [UCRBench: Benchmarking LLMs on Use Case Recovery](https://arxiv.org/abs/2512.13360)
*Shuyuan Xiao,Yiran Zhang,Weisong Sun,Xiaohong Chen,Yang Liu,Zhi Jin*

Main category: cs.SE

TL;DR: 研究构建了代码对齐的用例基准，首次系统评估了LLMs生成用例的能力，发现其在特定场景下存在局限性。


<details>
  <summary>Details</summary>
Motivation: 填补现有用例基准稀缺且与实际系统行为不对齐的空白，以更严谨地评估LLMs从源代码生成用例的能力。

Method: 通过手动验证九个真实世界软件项目的用户目标和子功能用例，构建代码对齐的用例基准，并采用分层评估协议（包括参与者正确性、名称准确性、路径保真度和行为覆盖度）进行系统研究。

Result: LLMs能部分重建系统功能，但性能在不同项目间差异显著，尤其在领域特定和多模块系统中表现较差。

Conclusion: LLMs在生成用例方面展现了潜力，但在领域特定和多模块系统中表现不佳，且存在高遗漏率和抽象一致性不足的问题。

Abstract: Use cases are widely employed to specify functional requirements, yet existing benchmarks are scarce and face the risk of being misaligned with actual system behavior, similarly limiting the rigorous evaluation of large language models (LLMs) in generating use cases from source code. We address this gap by introducing code-aligned use case benchmarks, constructed through manual validation of both user-goal and subfunction use cases across nine real-world software projects. Using this benchmark, we conduct the first systematic study of LLMs and propose a hierarchical evaluation protocol that assesses actor correctness, name accuracy, path fidelity, and behavioral coverage. The results show that while LLMs can partially reconstruct system functionality, their performance varies significantly across projects, with particularly noticeable shortcomings in domain-specific and multi-module systems. The models also exhibit high omission rates and struggle to maintain consistent abstraction when aggregating subfunctions into user-goal use cases, highlighting both the potential and current limitations of LLM-based use case reverse engineering.

</details>


### [284] [PSALM: applying Proportional SAmpLing strategy in Metamorphic testing](https://arxiv.org/abs/2512.13414)
*Zenghui Zhou,Pak-Lok Poon,Zheng Zheng,Xiao-Yi Zhang*

Main category: cs.SE

TL;DR: PSALM是一种适应于变形测试的选择策略，通过理论证明和实证研究验证其在源测试用例和变形组选择上的优越性。


<details>
  <summary>Details</summary>
Motivation: 变形测试的故障检测效果受源测试用例和变形组选择的影响，但现有研究对此缺乏系统性方法。比例抽样策略（PSS）在传统测试中表现良好，但其假设无法直接应用于变形测试。

Method: 本文提出了PSALM，一种将比例抽样策略（PSS）适应于变形测试的方法，用于源测试用例选择和变形组选择，并通过理论证明和实证研究验证其有效性。

Result: 在八个主题程序和184个突变体上的实证研究表明，PSALM的性能与理论分析一致，且通常优于现有选择策略如ART和MT-ART。

Conclusion: PSALM提供了一种理论上可靠且实际有效的选择策略，用于变形测试中的源测试用例选择和变形组选择，其性能优于现有策略如ART和MT-ART。

Abstract: Metamorphic testing (MT) alleviates the oracle problem by checking metamorphic relations (MRs) across multiple test executions. The fault detection effectiveness of MT is influenced not only by the choice and quality of MRs, but also by how source test cases and metamorphic groups (MGs) are selected. While substantial research has focused on designing, generating, and validating MRs, systematic methods for source test case selection and MG selection remain largely unexplored. Although the Proportional Sampling Strategy (PSS) provides strong theoretical guarantees in traditional testing, its assumptions cannot be directly applied in MT due to differences in selection domains, test units, and failure distributions. This paper proposes PSALM, an adaptation of PSS to MT for both source test case selection and MG selection. We formally prove that PSALM is never inferior to random selection regardless of how the source test case and MG domains are partitioned. We further identify the conditions under which applying PSALM to source test case selection and MG selection yields identical effectiveness. A comprehensive empirical study on eight subject programs and 184 mutants shows that the results are consistent with our theoretical analysis and that PSALM generally performs more effectively than existing selection strategies such as ART and MT-ART. These results demonstrate that PSALM provides a theoretically grounded and practically effective selection strategy for MT.

</details>


### [285] [QMon: Monitoring the Execution of Quantum Circuits with Mid-Circuit Measurement and Reset](https://arxiv.org/abs/2512.13422)
*Ning Ma,Jianjun Zhao,Foutse Khomh,Shaukat Ali,Heng Li*

Main category: cs.SE

TL;DR: QMON是一种量子电路监控方法，通过中电路测量和重置操作实现状态监测，有效检测错误且几乎不干扰原始状态。


<details>
  <summary>Details</summary>
Motivation: 量子电路因其不可克隆和测量导致的坍缩特性，难以直接观察或复制状态，这使得调试和运行时监控变得极具挑战性。

Method: QMON利用中电路测量和重置操作，在开发者指定的位置插入监测操作符，以比较预期和观测的量子状态概率。

Result: 实验结果表明，QMON在154个量子电路中成功保持了原有功能，并有效检测和定位了多种编程错误，尽管监测覆盖范围受限于量子纠缠等特性的保护需求。

Conclusion: QMON通过引入监测操作符，有效检测并定位量子电路中的编程错误，同时保持原始量子状态的最小干扰，为量子软件的开发提供了更可靠的工具。

Abstract: Unlike classical software, where logging and runtime tracing can effectively reveal internal execution status, quantum circuits possess unique properties, such as the no-cloning theorem and measurement-induced collapse, that prevent direct observation or duplication of their states. These characteristics make it especially challenging to monitor the execution of quantum circuits, complicating essential tasks such as debugging and runtime monitoring. This paper presents QMON, a practical methodology that leverages mid-circuit measurements and reset operations to monitor the internal states of quantum circuits while preserving their original runtime behavior. QMON enables the instrumentation of monitoring operators at developer-specified locations within the circuit, allowing comparisons between expected and observed quantum-state probabilities at those locations. We evaluated QMON by analyzing its impact on circuit behavior, monitoring coverage, and effectiveness in bug localization. Experimental results involving 154 quantum circuits show that all circuits preserve their intended functionality after instrumentation and that QMON successfully detects and localizes various programming errors. Although monitoring coverage is limited by the need to preserve delicate quantum properties, such as entanglement, QMON effectively detects errors while introducing no or negligible disturbance to the original quantum states. QMON facilitates the development of more robust and reliable quantum software as the field continues to mature.

</details>


### [286] [From User Interface to Agent Interface: Efficiency Optimization of UI Representations for LLM Agents](https://arxiv.org/abs/2512.13438)
*Dezhi Ran,Zhi Gong,Yuzhe Guo,Mengzhou Wu,Yuan Cao,Haochuan Lu,Hengyu Zhang,Xia Zeng,Gang Cao,Liangchao Yao,Yuetang Deng,Wei Yang,Tao Xie*

Main category: cs.SE

TL;DR: UIFormer是首个自动化优化框架，通过约束优化和结构化分解生成UI转换程序，显著提升LLM代理的UI导航效率。


<details>
  <summary>Details</summary>
Motivation: 现有UI表示效率低下成为LLM代理在自动化UI导航中的性能瓶颈，但UI表示优化面临缺乏布尔预言机和处理复杂UI树的挑战。

Method: UIFormer采用领域特定语言（DSL）限制程序空间，并通过基于LLM的迭代优化结合正确性和效率奖励，实现效率与完整性的协同优化。

Result: 在三个UI导航基准测试中，UIFormer实现了48.7%至55.8%的token减少，且运行时开销极小，同时保持或提升了代理性能。

Conclusion: UIFormer通过约束优化和结构化分解，有效解决了UI表示优化的两大挑战，显著提升了LLM代理在UI导航中的效率，同时在实际工业部署中验证了其有效性。

Abstract: While Large Language Model (LLM) agents show great potential for automated UI navigation such as automated UI testing and AI assistants, their efficiency has been largely overlooked. Our motivating study reveals that inefficient UI representation creates a critical performance bottleneck. However, UI representation optimization, formulated as the task of automatically generating programs that transform UI representations, faces two unique challenges. First, the lack of Boolean oracles, which traditional program synthesis uses to decisively validate semantic correctness, poses a fundamental challenge to co-optimization of token efficiency and completeness. Second, the need to process large, complex UI trees as input while generating long, compositional transformation programs, making the search space vast and error-prone. Toward addressing the preceding limitations, we present UIFormer, the first automated optimization framework that synthesizes UI transformation programs by conducting constraint-based optimization with structured decomposition of the complex synthesis task. First, UIFormer restricts the program space using a domain-specific language (DSL) that captures UI-specific operations. Second, UIFormer conducts LLM-based iterative refinement with correctness and efficiency rewards, providing guidance for achieving the efficiency-completeness co-optimization. UIFormer operates as a lightweight plugin that applies transformation programs for seamless integration with existing LLM agents, requiring minimal modifications to their core logic. Evaluations across three UI navigation benchmarks spanning Android and Web platforms with five LLMs demonstrate that UIFormer achieves 48.7% to 55.8% token reduction with minimal runtime overhead while maintaining or improving agent performance. Real-world industry deployment at WeChat further validates the practical impact of UIFormer.

</details>


### [287] [A Data Annotation Requirements Representation and Specification (DARS)](https://arxiv.org/abs/2512.13444)
*Yi Peng,Hina Saeeda,Hans-Martin Heyn,Jennifer Horkoff,Eric Knauss,Fredrick Warg*

Main category: cs.SE

TL;DR: DARS是一种数据注释需求表示和规范方法，通过注释协商卡和场景规范来对齐利益相关者需求，评估显示其能有效减少注释错误，提升安全关键系统的可靠性。


<details>
  <summary>Details</summary>
Motivation: 随着AI驱动的网络物理系统的兴起，数据注释已成为开发这些智能信息系统的关键但常被忽视的过程。现有需求工程研究探讨了AI系统及其数据需求的表示方法，但行业专业人士的访谈显示，数据注释及其相关需求引入了独特的挑战，表明需要特定于注释的需求表示。

Method: 提出了数据注释需求表示和规范（DARS），包括用于对齐利益相关者目标和约束的注释协商卡，以及用于表达原子和可验证数据注释需求的基于场景的注释规范。通过一个与正在进行项目相关的汽车感知案例，以及对18种真实世界数据注释错误类型的映射来评估DARS。

Result: 结果表明，DARS减轻了完整性、准确性和一致性注释错误的根本原因。

Conclusion: 通过将DARS集成到需求工程中，本研究提高了使用数据注释的安全关键系统的可靠性，并展示了工程框架如何必须为当今智能信息系统的数据依赖组件进行演进。

Abstract: With the rise of AI-enabled cyber-physical systems, data annotation has become a critical yet often overlooked process in the development of these intelligent information systems. Existing work in requirements engineering (RE) has explored how requirements for AI systems and their data can be represented. However, related interviews with industry professionals show that data annotations and their related requirements introduce distinct challenges, indicating a need for annotation-specific requirement representations. We propose the Data Annotation Requirements Representation and Specification (DARS), including an Annotation Negotiation Card to align stakeholders on objectives and constraints, and a Scenario-Based Annotation Specification to express atomic and verifiable data annotation requirements. We evaluate DARS with an automotive perception case related to an ongoing project, and a mapping against 18 real-world data annotation error types. The results suggest that DARS mitigates root causes of completeness, accuracy, and consistency annotation errors. By integrating DARS into RE, this work improves the reliability of safety-critical systems using data annotations and demonstrates how engineering frameworks must evolve for data-dependent components of today's intelligent information systems.

</details>


### [288] [Mapping of the system of software-related emissions and shared responsibilities](https://arxiv.org/abs/2512.13474)
*Laura Partanen,Antti Sipila,Md Sanaul Haque,Jari Porras*

Main category: cs.SE

TL;DR: 研究通过系统映射分析ICT行业的碳排放和能源消耗，旨在提升行业减排意识，助力《巴黎协定》目标。


<details>
  <summary>Details</summary>
Motivation: 应对全球气候变暖，特别是实现《巴黎协定》将温升控制在1.5°C的目标，需要ICT行业减少其环境足迹。

Method: 采用综合系统映射方法，识别ICT领域碳排放和能源消耗的主要来源。

Result: 研究明确了ICT领域碳排放的主要来源及软件生命周期中各利益相关方的责任。

Conclusion: 该研究通过系统映射提高了对ICT领域软件相关排放及其责任的认识，为行业减排提供了重要参考。

Abstract: The global climate is experiencing a rapid and unprecedented warming trend. The ICT sector is a notable contributor to global greenhouse gas emissions, with its environmental impact continuing to expand. Addressing this issue is vital for achieving the objectives of the Paris Agreement, particularly the goal of limiting global temperature rise to 1.5°C. At the European Union level, regulatory measures such as the CSRD and the CSDD impose obligations on companies, including those within the ICT sector, to recognize and mitigate their environmental footprint. This study provides a comprehensive system mapping aimed at enhancing the awareness and understanding of software-related emissions and the corresponding responsibilities borne by the ICT sector. The mapping identifies the primary sources of carbon emissions and energy consumption within the ICT domain while also outlining the key responsibilities of the stakeholders accountable throughout the software lifecycle.

</details>


### [289] [Fine-tuned LLM-based Code Migration Framework](https://arxiv.org/abs/2512.13515)
*Oleg Grynets,Vasyl Lyashkevych,Dmytro Baran,Maksym Orliansky,Taras Zelenyy,Markiian Leshchyshyn*

Main category: cs.SE

TL;DR: 该研究提出了一种结合传统软件工程和大型语言模型的框架，用于自动化SQL代码迁移，显著降低错误率并提升效率。


<details>
  <summary>Details</summary>
Motivation: 解决SQL基础系统迁移中的挑战，特别是语法映射、数据库逻辑优化及不同数据库系统间的兼容性问题。

Method: 提出了一种结合传统软件工程技术和大型语言模型的框架，通过精细调校和提示工程的权衡，解决SQL代码转换中的关键问题，如语法映射、Oracle PL/SQL与PostgreSQL之间的差异解决，以及数据库元素的优化。

Result: 通过目标评估方法和计算指标验证，该方法显著降低了语法错误率，提升了特征对齐，并通过数据集采样实现了持续改进。

Conclusion: 该研究通过集成精细调校的大型语言模型和系统化迁移工作流程，显著降低了语法错误率，提升了特征对齐，并实现了工作流程效率的持续改进。

Abstract: The study presents the outcomes of research and experimental validation in the domain of automated codebase migration, with a focus on addressing challenges in transitioning SQL-based systems. The proposed method for migration essentially appears as a framework that leverages the best aspects of traditional software engineering techniques and provides an iterative, scalable, precise and efficient solution for modern database transformations. The central piece of the approach is the integration of a fine-tuned Large Language Model to address critical issues in SQL code conversion, such as syntax mapping, resolving discrepancies between Oracle PL/SQL and PostgreSQL, and optimising database elements such as stored procedures, triggers, views, and overall database logic. Thus, the method involves a trade-off between fine-tuning and prompt engineering. Special attention is given to a fine-tuning approach, which enhances the adaptability and compatibility with migration requirements across the entire database. According to the achieved results, fine-tuning plays a very important role. The study employs targeted evaluation methodologies along with computational metrics to measure the success of iterative conversion cycles. Core innovations include automated SQL feature detection, semi-supervised error analysis and integration of Subject Matter Experts feedback within a systematic migration workflow. The methodology achieves significant reductions in Syntax Error Rates, enhances feature alignment throughout migration iterations, and leverages dataset sampling to ensure continual improvement. By embedding GAI into the migration process, the framework facilitates precise feature mapping, semi-automated error resolution, and data-driven optimisation loops, improving workflow efficiency.

</details>


### [290] [How Low Can You Go? The Data-Light SE Challenge](https://arxiv.org/abs/2512.13524)
*Kishan Kumar Ganguly,Tim Menzies*

Main category: cs.SE

TL;DR: 研究表明，许多软件工程任务中，轻量级方法仅需少量标签即可达到与先进优化器相当的效果，提出了‘数据轻量挑战’以探讨其适用条件。


<details>
  <summary>Details</summary>
Motivation: 挑战软件工程研究中依赖大规模数据集和CPU密集型优化器的假设，探索轻量级方法的潜力。

Method: 通过对比简单方法（如多样性采样、最小贝叶斯学习器或随机探测）与先进优化器（如SMAC、TPE、DEHB等）在多个SE任务中的表现，验证轻量级方法的有效性。

Result: 在几十个SE优化问题中，简单方法仅需少量标签即可达到接近90%的最佳报告结果，与先进优化器表现相当。

Conclusion: 本文提出了一种轻量级方法在软件工程任务中的有效性，并提出了‘数据轻量挑战’，探讨在何种情况下少量标签即可满足需求。

Abstract: Much of software engineering (SE) research assumes that progress depends on massive datasets and CPU-intensive optimizers. Yet has this assumption been rigorously tested?
  The counter-evidence presented in this paper suggests otherwise: across dozens of optimization problems from recent SE literature, including software configuration and performance tuning, cloud and systems optimization, project and process-level decision modeling, behavioral analytics, financial risk modeling, project health prediction, reinforcement learning tasks, sales forecasting, and software testing, even with just a few dozen labels, very simple methods (e.g. diversity sampling, a minimal Bayesian learner, or random probes) achieve near 90% of the best reported results. Further, these simple methods perform just as well as more state-of-the-the-art optimizers like SMAC, TPE, DEHB etc. While some tasks would require better outcomes and more sampling, these results seen after a few dozen samples would suffice for many engineering needs (particularly when the goal is rapid and cost-efficient guidance rather than slow and exhaustive optimization).
  Our results highlight that some SE tasks may be better served by lightweight approaches that demand fewer labels and far less computation. We hence propose the data-light challenge: when will a handful of labels suffice for SE tasks? To enable a large-scale investigation of this issue, we contribute (1) a mathematical formalization of labeling, (2) lightweight baseline algorithms, and (3) results on public-domain data showing the conditions under which lightweight methods excel or fail.
  For the purposes of open science, our scripts and data are online at https://github.com/KKGanguly/NEO .

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [291] [Optimal non-adaptive algorithm for edge estimation](https://arxiv.org/abs/2512.11994)
*Arijit Bishnu,Debarshi Chanda,Buddha Dev Das,Arijit Ghosh,Gopinath Mishra*

Main category: cs.DS

TL;DR: 提出一种非自适应随机算法，用$\widetilde{O}(\sqrt{n})$次查询估计无向图边数，并证明其最优性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是开发一种仅需次线性查询复杂度（即$\widetilde{O}(\sqrt{n})$）的方法来估计图中的边数，适用于可能包含孤立顶点的简单无向图。

Method: 算法通过独立采样一组顶点查询其度数，并独立采样一组边，利用这些查询结果来估计图中的总边数。

Result: 算法在$n$顶点图中仅需$\widetilde{O}(\sqrt{n})$次查询即可估计边数，且通过下界证明其最优性。

Conclusion: 该论文提出了一种非自适应随机算法，用于估计简单无向图中边的数量，并通过匹配的下界证明了该算法的最优性。

Abstract: We present a simple nonadaptive randomized algorithm that estimates the number of edges in a simple, unweighted, undirected graph, possibly containing isolated vertices, using only degree and random edge queries. For an $n$-vertex graph, our method requires only $\widetilde{O}(\sqrt{n})$ queries, achieving sublinear query complexity. The algorithm independently samples a set of vertices and queries their degrees, and also independently samples a set of edges, using the answers to these queries to estimate the total number of edges in the graph. We further prove a matching lower bound, establishing the optimality of our algorithm and resolving the non-adaptive query complexity of this problem with respect to degree and random-edge queries.

</details>


### [292] [Load Balancing with Duration Predictions](https://arxiv.org/abs/2512.12202)
*Yossi Azar,Niv Buchbinder,Tomer Epshtein*

Main category: cs.DS

TL;DR: 该论文提出了一种基于预测的动态负载均衡算法，其性能随预测准确性变化，并证明了使用不准确预测时的竞争力下限。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统动态负载均衡算法在预测信息不准确时性能下降的问题，研究者探索了一种更现实的模型，其中算法可以利用对任务持续时间的估计或预测。

Method: 研究者设计了一种新的负载均衡算法，该算法的性能依赖于可用预测的准确性，并通过实验验证了其优于传统方法的表现。

Result: 研究结果表明，新算法在预测准确性较高时表现优异，且性能随预测准确性的下降而平滑降低。此外，研究还确定了使用不准确预测的算法在竞争力上的理论下限。

Conclusion: 该研究通过引入预测模型，弥补了传统动态负载均衡算法在预测准确性不足时的性能下降问题，并提出了一种性能随预测准确性平滑变化的改进算法。同时，研究还证明了使用不准确预测的算法在竞争力上的下限。

Abstract: We study the classic fully dynamic load balancing problem on unrelated machines where jobs arrive and depart over time and the goal is minimizing the maximum load, or more generally the l_p-norm of the load vector. Previous work either studied the clairvoyant setting in which exact durations are known to the algorithm, or the unknown duration setting in which no information on the duration is given to the algorithm. For the clairvoyant setting algorithms with polylogarithmic competitive ratios were designed, while for the unknown duration setting strong lower bounds exist and only polynomial competitive factors are possible.
  We bridge this gap by studying a more realistic model in which some estimate/prediction of the duration is available to the algorithm. We observe that directly incorporating predictions into classical load balancing algorithms designed for the clairvoyant setting can lead to a notable decline in performance. We design better algorithms whose performance depends smoothly on the accuracy of the available prediction. We also prove lower bounds on the competitiveness of algorithms that use such inaccurate predictions.

</details>


### [293] [Learning with Structure: Computing Consistent Subsets on Structurally-Regular Graphs](https://arxiv.org/abs/2512.12860)
*Aritra Banik,Mano Prakash Parthasarathi,Venkatesh Raman,Diya Roy,Abhishek Sahu*

Main category: cs.DS

TL;DR: 本文研究了图上的最小一致子集问题，提出了基于顶点覆盖数和邻域多样性的高效算法，证明了其固定参数可解性。


<details>
  <summary>Details</summary>
Motivation: 现代应用中训练数据的庞大体积带来了显著的计算挑战，MCS问题旨在通过最小一致子集（S⊆X）来高效解决这一问题。

Method: 提出了两种算法，分别基于顶点覆盖数（vc）和邻域多样性（nd）参数，运行时间分别为vc^O(vc)·Poly(n,c)和nd^O(nd)·Poly(n,c)。

Result: 证明了MCS问题在vc和nd参数下是FPT，且算法复杂度与颜色数量多项式相关。

Conclusion: 本文证明了MCS问题在顶点覆盖数（vc）和邻域多样性（nd）参数下是固定参数可解的（FPT），并提出了两种高效算法，其复杂度与颜色数量多项式相关。

Abstract: The Minimum Consistent Subset (MCS) problem arises naturally in the context of supervised clustering and instance selection. In supervised clustering, one aims to infer a meaningful partitioning of data using a small labeled subset. However, the sheer volume of training data in modern applications poses a significant computational challenge. The MCS problem formalizes this goal: given a labeled dataset $\mathcal{X}$ in a metric space, the task is to compute a smallest subset $S \subseteq \mathcal{X}$ such that every point in $\mathcal{X}$ shares its label with at least one of its nearest neighbors in $S$.
  Recently, the MCS problem has been extended to graph metrics, where distances are defined by shortest paths. Prior work has shown that MCS remains NP-hard even on simple graph classes like trees, though an algorithm with runtime $\mathcal{O}(2^{6c} \cdot n^6)$ is known for trees, where $c$ is the number of colors and $n$ the number of vertices. This raises the challenge of identifying graph classes that admit algorithms efficient in both $n$ and $c$.
  In this work, we study the Minimum Consistent Subset problem on graphs, focusing on two well-established measures: the vertex cover number ($vc$) and the neighborhood diversity ($nd$). We develop an algorithm with running time $vc^{\mathcal{O}(vc)}\cdot\text{Poly}(n,c)$, and another algorithm with runtime $nd^{\mathcal{O}(nd)}\cdot\text{Poly}(n,c)$. In the language of parameterized complexity, this implies that MCS is fixed-parameter tractable (FPT) parameterized by the vertex cover number and the neighborhood diversity. Notably, our algorithms remain efficient for arbitrarily many colors, as their complexity is polynomially dependent on the number of colors.

</details>


### [294] [Sub-$n^k$ Deterministic algorithm for minimum $k$-way cut in simple graphs](https://arxiv.org/abs/2512.12900)
*Mohit Daga*

Main category: cs.DS

TL;DR: 提出了一种结合PSP和KT收缩的确定性算法，用于最小k割问题，运行时间优于随机算法。


<details>
  <summary>Details</summary>
Motivation: 解决最小k割问题的确定性算法，尤其是在特定条件下实现更优的运行时间。

Method: 结合主分割序列（PSP）和Kawarabayashi-Thorup（KT）收缩，通过结构分解定理和构建规范边界族（canonical border family）来实现算法。

Result: 提出了一种确定性算法，运行时间为$\widetilde{O}\left(\mathrm{poly}(m)+\Bigl(\tfrac{n}{λ_j}+n^{ω/3}\Bigr)^{R}\right)$，并在$λ_j \ge n^{\varepsilon}$时实现$n^{(1-\varepsilon)(k-1)+o(k)}$时间。

Conclusion: 该论文提出了一种确定性精确算法，用于解决简单图上的最小k割问题，结合了PSP和KT收缩方法，并在特定条件下实现了优于随机算法的运行时间。

Abstract: We present a \emph{deterministic exact algorithm} for the \emph{minimum $k$-cut problem} on simple graphs.
  Our approach combines the \emph{principal sequence of partitions (PSP)}, derived canonically from ideal loads, with a single level of \emph{Kawarabayashi--Thorup (KT)} contractions at the critical PSP threshold~$λ_j$.
  Let $j$ be the smallest index with $κ(P_j)\ge k$ and $R := k - κ(P_{j-1})$.
  We prove a structural decomposition theorem showing that an optimal $k$-cut can be expressed as the level-$(j\!-\!1)$ boundary $A_{\le j-1}$ together with exactly $(R-r)$ \emph{non-trivial} internal cuts of value at most~$λ_j$ and $r$ \emph{singleton isolations} (``islands'') inside the parts of~$P_{j-1}$.
  At this level, KT contractions yield kernels of total size $\widetilde{O}(n / λ_j)$, and from them we build a \emph{canonical border family}~$\mathcal{B}$ of the same order that deterministically covers all optimal refinement choices.
  Branching only over~$\mathcal{B}$ (and also including an explicit ``island'' branch) gives total running time
  $$
  T(n,m,k) = \widetilde{O}\left(\mathrm{poly}(m)+\Bigl(\tfrac{n}{λ_j}+n^{ω/3}\Bigr)^{R}\right),
  $$
  where $ω< 2.373$ is the matrix multiplication exponent.
  In particular, if $λ_j \ge n^{\varepsilon}$ for some constant $\varepsilon > 0$, we obtain a \emph{deterministic sub-$n^k$-time algorithm}, running in $n^{(1-\varepsilon)(k-1)+o(k)}$ time.
  Finally, combining our PSP$\times$KT framework with a small-$λ$ exact subroutine via a simple meta-reduction yields a deterministic $n^{c k+O(1)}$ algorithm for $c = \max\{ t/(t+1), ω/3 \} < 1$, aligning with the exponent in the randomized bound of He--Li (STOC~2022) under the assumed subroutine.

</details>


### [295] [Deterministic and Exact Fully-dynamic Minimum Cut of Superpolylogarithmic Size in Subpolynomial Time](https://arxiv.org/abs/2512.13105)
*Antoine El-Hayek,Monika Henzinger,Jason Li*

Main category: cs.DS

TL;DR: 提出确定性局部最小割算法，改进动态最小割问题的效率和适用范围。


<details>
  <summary>Details</summary>
Motivation: 改进Jin、Sun和Thorup（SODA 2024）的算法，其最小割大小限制为$(\log n)^{o(1)}$，并解决随机化方法的局限性。

Method: 提出了一种确定性完全动态最小割算法，运行时间为$n^{o(1)}$，适用于最小割大小不超过$2^{Θ(\log^{3/4-c}n)}$的情况。

Result: 实现了在加权图上的(1+ε)-近似全动态最小割算法，更新时间为$n^{o(1)}$。

Conclusion: 本文提出了一种确定性局部最小割算法，取代了之前的随机化方法，并结合图稀疏化技术，首次在加权图上实现了(1+ε)-近似全动态最小割算法。

Abstract: We present an exact fully-dynamic minimum cut algorithm that runs in $n^{o(1)}$ deterministic update time when the minimum cut size is at most $2^{Θ(\log^{3/4-c}n)}$ for any $c>0$, improving on the previous algorithm of Jin, Sun, and Thorup (SODA 2024) whose minimum cut size limit is $(\log n)^{o(1)}$. Combined with graph sparsification, we obtain the first $(1+ε)$-approximate fully-dynamic minimum cut algorithm on weighted graphs, for any $ε\ge2^{-Θ(\log^{3/4-c}n)}$, in $n^{o(1)}$ randomized update time.
  Our main technical contribution is a deterministic local minimum cut algorithm, which replaces the randomized LocalKCut procedure from El-Hayek, Henzinger, and Li (SODA 2025).

</details>


### [296] [Kernelization dichotomies for hitting minors under structural parameterizations](https://arxiv.org/abs/2512.13210)
*Marin Bougeret,Eric Brandwein,Ignasi Sau*

Main category: cs.DS

TL;DR: 论文扩展了$\mathcal{F}$-MINOR-DELETION问题的多项式核存在性，为包含平面图的家族提供精确核，并为多种图删除问题建立了新的二分法理论。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决$\mathcal{F}$-MINOR-DELETION问题的多项式核存在性，尤其是在更广泛的参数化条件下，填补了先前仅在特定案例（如VERTEX COVER和FEEDBACK VERTEX SET）中已知二分法的空白。

Method: 论文基于Jansen和Pieterse的技术，并结合Jansen、de Kroon和Wlodarczyk的结果进行适应性改进，提出了一种新的参数化方法，通过顶点删除距离和消除距离的组合来扩展多项式核的应用范围。

Result: 论文证明了对于包含平面图的任何有限双连通图家族$\mathcal{F}$，$\mathcal{F}$-MINOR-DELETION问题在参数化为顶点删除距离到$\mathcal{C}$时，当且仅当$\mathcal{C}$具有有限的消除距离到$\mathcal{F}$-minor-free图时，才存在多项式核。

Conclusion: 该论文通过将$\mathcal{F}$-MINOR-DELETION问题的多项式核存在性扩展到更广泛的参数化范围，为包含平面图的家族提供了精确多项式核，并为PLANAR VERTEX DELETION提供了近似多项式核。此外，通过结合先前的下界结果，论文展示了一系列无限二分法，为多种图删除问题（如CACTUS VERTEX DELETION、OUTERPLANAR VERTEX DELETION等）提供了新的理论框架。

Abstract: For a finite collection of connected graphs $\mathcal{F}$, the $\mathcal{F}$-MINOR-DELETION problem consists in, given a graph $G$ and an integer $\ell$, deciding whether $G$ contains a vertex set of size at most $\ell$ whose removal results in an $\mathcal{F}$-minor-free graph. We lift the existence of (approximate) polynomial kernels for $\mathcal{F}$-MINOR-DELETION by the solution size to (approximate) polynomial kernels parameterized by the vertex-deletion distance to graphs of bounded elimination distance to $\mathcal{F}$-minor-free graphs. This results in exact polynomial kernels for every family $\mathcal{F}$ that contains a planar graph, and an approximate polynomial kernel for PLANAR VERTEX DELETION. Moreover, combining our result with a previous lower bound, we obtain the following infinite set of dichotomies, assuming $NP \not\subseteq coNP/poly$: for any finite set $\mathcal{F}$ of biconnected graphs on at least three vertices containing a planar graph, and any minor-closed class of graphs $\mathcal{C}$, $\mathcal{F}$-MINOR-DELETION admits a polynomial kernel parameterized by the vertex-deletion distance to $\mathcal{C}$ if and only if $\mathcal{C}$ has bounded elimination distance to $\mathcal{F}$-minor-free graphs. For instance, this yields dichotomies for CACTUS VERTEX DELETION, OUTERPLANAR VERTEX DELETION, and TREEWIDTH-$t$ VERTEX DELETION for every integer $t \geq 0$. Prior to our work, such dichotomies were only known for the particular cases of VERTEX COVER and FEEDBACK VERTEX SET. Our approach builds on the techniques developed by Jansen and Pieterse [Theor. Comput. Sci. 2020] and also uses adaptations of some of the results by Jansen, de Kroon, and Wlodarczyk [STOC 2021].

</details>


### [297] [Space Efficient Algorithms for Parameterised Problems](https://arxiv.org/abs/2512.13342)
*Sheikh Shakil Akhtar,Pranabendu Misra,Geevarghese Philip*

Main category: cs.DS

TL;DR: 本文提出了一种内存高效的FPT算法，适用于k-Path等图问题，适用于大数据场景，解决了传统方法内存消耗大的问题。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于大数据环境下，处理超大规模问题实例时，传统poly(n)内存使用成本过高的问题。

Method: 设计了运行时间为f(k)*poly(n)且工作空间为g(k)*polylog(n)的算法，其中f和g仅为k的函数。

Result: 成功开发了针对特定图问题的空间高效FPT算法，克服了传统方法中无法大规模删除顶点或边的限制。

Conclusion: 本文提出了在有限内存条件下，针对k-Path、MaxLeaf SubTree和Multicut in Trees等图问题的高效FPT算法，证明了在理论上的可行性和实际应用中的潜力。

Abstract: We study "space efficient" FPT algorithms for graph problems with limited memory. Let n be the size of the input graph and k be the parameter. We present algorithms that run in time f(k)*poly(n) and use g(k)*polylog(n) working space, where f and g are functions of k alone, for k-Path, MaxLeaf SubTree and Multicut in Trees. These algorithms are motivated by big-data settings where very large problem instances must be solved, and using poly(n) memory is prohibitively expensive. They are also theoretically interesting, since most of the standard methods tools, such as deleting a large set of vertices or edges, are unavailable, and we must a develop different way to tackle them.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [298] [Accelerating Sparse Matrix-Matrix Multiplication on GPUs with Processing Near HBMs](https://arxiv.org/abs/2512.12036)
*Shiju Li,Younghoon Min,Hane Yie,Hoshik Kim,Soohong Ahn,Joonseop Sim,Chul-Ho Lee,Jongryool Kim*

Main category: cs.DC

TL;DR: 该论文提出了一种优化GPU上SpGEMM性能的硬件-软件协同框架，显著提升了图形分析和GNN训练的效率。


<details>
  <summary>Details</summary>
Motivation: SpGEMM是科学计算和数据分析中的基础操作，但常因不规则内存访问模式成为性能瓶颈，因此需要优化。

Method: 论文提出了一种硬件-软件协同设计的框架，结合哈希多阶段SpGEMM和AIA技术，优化了GPU上的SpGEMM操作。

Result: 在图形分析应用中，AIA技术相比纯软件实现减少了17.3%的时间，相比cuSPARSE在图形收缩和马尔可夫聚类中分别减少了76.5%和58.4%的时间。在GNN训练中，混合方法平均提速1.43倍，相比cuSPARSE提速1.95倍，最大提速达4.18倍。

Conclusion: 该论文提出的基于哈希的多阶段SpGEMM和AIA技术在GPU HBM上显著提升了SpGEMM的性能，尤其在处理复杂、特定应用的工作负载时表现优异。

Abstract: Sparse General Matrix-Matrix Multiplication (SpGEMM) is a fundamental operation in numerous scientific computing and data analytics applications, often bottlenecked by irregular memory access patterns. This paper presents Hash based Multi-phase SpGEMM on GPU and the Acceleration of Indirect Memory Access (AIA) technique, a novel custom near-memory processing approach to optimizing SpGEMM on GPU HBM. Our hardware-software co-designed framework for SpGEMM demonstrates significant performance improvements over state-of-the-art methods, particularly in handling complex, application-specific workloads. We evaluate our approach on various graph workloads, including graph contraction, Markov clustering, and Graph Neural Networks (GNNs), showcasing its practical applicability. For graph analytics applications, AIA demonstrates up to 17.3% time reduction from the software-only implementation, while achieving time reduction of 76.5% for Graph Contraction and 58.4% for Markov Clustering compared to cuSPARSE. For GNN training applications with structured global pruning, our hybrid approach delivers an average of 1.43x speedup over software-only implementation across six benchmark datasets and three architectures (GCN, GIN, GraphSAGE), and shows 1.95x speedup for GNN workloads when compared to cuSPARSE, with up to 4.18x gains on large-scale datasets.

</details>


### [299] [Near-Zero-Overhead Freshness for Recommendation Systems via Inference-Side Model Updates](https://arxiv.org/abs/2512.12295)
*Wenjun Yu,Sitian Chen,Cheng Chen,Amelie Chi Zhou*

Main category: cs.DC

TL;DR: LiveUpdate通过低秩适应和资源调度技术，实现了DLRMs的实时更新，提升了推荐系统的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 生产环境中的DLRMs因大规模参数同步导致多分钟延迟，影响推荐质量和收入。推理节点的CPU利用率低和EMT梯度的低秩结构为实时更新提供了机会。

Method: LiveUpdate采用动态秩适应和NUMA感知资源调度技术，解决了内存开销和更新推理争用问题。

Result: LiveUpdate在1小时窗口内实现了更高的准确性，更新成本比基线方法降低2倍，且在准确性上优于现有方法0.04%至0.24%。

Conclusion: LiveUpdate通过将低秩适应（LoRA）训练器与推理节点共置，消除了集群间同步，显著提升了推荐模型的实时性和准确性。

Abstract: Deep Learning Recommendation Models (DLRMs) underpin personalized services but face a critical freshness-accuracy tradeoff due to massive parameter synchronization overheads. Production DLRMs deploy decoupled training/inference clusters, where synchronizing petabyte-scale embedding tables (EMTs) causes multi-minute staleness, degrading recommendation quality and revenue. We observe that (1) inference nodes exhibit sustained CPU underutilization (peak <= 20%), and (2) EMT gradients possess intrinsic low-rank structure, enabling compact update representation. We present LiveUpdate, a system that eliminates inter-cluster synchronization by colocating Low-Rank Adaptation (LoRA) trainers within inference nodes. LiveUpdate addresses two core challenges: (1) dynamic rank adaptation via singular value monitoring to constrain memory overhead (<2% of EMTs), and (2) NUMA-aware resource scheduling with hardware-enforced QoS to eliminate update inference contention (P99 latency impact <20ms). Evaluations show LiveUpdate reduces update costs by 2x versus delta-update baselines while achieving higher accuracy within 1-hour windows. By transforming idle inference resources into freshness engines, LiveUpdate delivers online model updates while outperforming state-of-the-art delta-update methods by 0.04% to 0.24% in accuracy.

</details>


### [300] [A Conflict-Aware Resource Management Framework for the Computing Continuum](https://arxiv.org/abs/2512.12299)
*Vlad Popescu-Vifor,Ilir Murturi,Praveen Kumar Donta,Schahram Dustdar*

Main category: cs.DC

TL;DR: 提出了一种基于深度强化学习的自适应冲突解决框架，用于计算连续体中的资源编排，有效解决了资源冲突问题，并在测试中展示了高效和弹性。


<details>
  <summary>Details</summary>
Motivation: 计算连续体（涵盖边缘、雾和云计算）中设备异构性和分散化需求的增加带来了资源编排的新挑战，代理决策可能导致持续的冲突循环、资源利用效率低下和服务性能下降。

Method: 提出了一种基于深度强化学习（DRL）的自适应冲突解决框架，该框架整合了基于实时性能反馈和历史状态信息训练的DRL模型。

Result: 在基于Kubernetes的测试平台上原型化和验证了该框架，初步结果表明其能够实现高效的资源重新分配和动态场景下的自适应学习。

Conclusion: 该框架通过深度强化学习方法实现了计算连续体中资源冲突的自适应解决，展示了其在动态场景下的高效资源重新分配和自适应学习能力，为冲突感知的资源编排提供了可扩展且具有弹性的解决方案。

Abstract: The increasing device heterogeneity and decentralization requirements in the computing continuum (i.e., spanning edge, fog, and cloud) introduce new challenges in resource orchestration. In such environments, agents are often responsible for optimizing resource usage across deployed services. However, agent decisions can lead to persistent conflict loops, inefficient resource utilization, and degraded service performance. To overcome such challenges, we propose a novel framework for adaptive conflict resolution in resource-oriented orchestration using a Deep Reinforcement Learning (DRL) approach. The framework enables handling resource conflicts across deployments and integrates a DRL model trained to mediate such conflicts based on real-time performance feedback and historical state information. The framework has been prototyped and validated on a Kubernetes-based testbed, illustrating its methodological feasibility and architectural resilience. Preliminary results show that the framework achieves efficient resource reallocation and adaptive learning in dynamic scenarios, thus providing a scalable and resilient solution for conflict-aware orchestration in the computing continuum.

</details>


### [301] [Reputation-Based Leader Election under Partial Synchrony: Towards a Protocol-Independent Abstraction with Enhanced Guarantees](https://arxiv.org/abs/2512.12409)
*Xuyang Liu,Zijian Zhang,Zhen Li,Jiahang Sun,Jiamou Liu,Peng Jiang*

Main category: cs.DC

TL;DR: 本文提出了一种协议无关的领导者选举抽象框架和SWLE机制，显著提升了吞吐量和延迟，降低了拜占庭领导者频率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于信誉的领导者选举框架在部分同步拜占庭容错协议中存在协议特定证明、适用范围狭窄或网络稳定后恢复无界等问题，因此需要一种协议无关的解决方案。

Method: 本文设计了一种协议无关的抽象框架，用于形式化部分同步下的领导者选举的通用正确性属性和有效性保证。基于此，设计了滑动窗口领导者选举（SWLE）机制，通过共识行为基于的信誉分数动态调整领导者提名。

Result: SWLE机制在16台服务器部署中，吞吐量提高了4.2倍，延迟降低了75%，拜占庭领导者频率降低了27%，同时在无故障场景下保持高效。

Conclusion: 本文提出了SWLE机制，通过基于共识行为的信誉分数动态调整领导者提名，实现了拜占庭成本放大。实验证明，SWLE在16台服务器部署中，相比现有解决方案，吞吐量提高了4.2倍，延迟降低了75%，拜占庭领导者频率降低了27%，同时在无故障场景下保持高效。

Abstract: Leader election serves a well-defined role in leader-based Byzantine Fault Tolerant (BFT) protocols. Existing reputation-based leader election frameworks for partially synchronous BFTs suffer from either protocol-specific proofs, narrow applicability, or unbounded recovery after network stabilization, leaving an open problem. This paper presents a novel protocol-independent abstraction formalizing generic correctness properties and effectiveness guarantees for leader election under partial synchrony, enabling protocol-independent analysis and design. Building on this, we design the Sliding Window Leader Election (SWLE) mechanism. SWLE dynamically adjusts leader nominations via consensus-behavior-based reputation scores, enforcing Byzantine-cost amplification. We demonstrate SWLE introduces minimal extra overhead to the base protocol and prove it satisfies all abstraction properties and provides superior effectiveness. We show, with a 16-server deployment across 4 different regions in northern China, SWLE achieves up to 4.2x higher throughput, 75% lower latency and 27% Byzantine leader frequency compared to the state-of-the-art solution under common Byzantine faults, while maintaining efficiency in fault-free scenarios.

</details>


### [302] [HetRL: Efficient Reinforcement Learning for LLMs in Heterogeneous Environments](https://arxiv.org/abs/2512.12476)
*Yongjun He,Shuai Zhang,Jiading Gai,Xiyuan Zhang,Boran Han,Bernie Wang,Huzefa Rangwala,George Karypis*

Main category: cs.DC

TL;DR: HetRL是一个针对异构GPU环境的RL训练分布式系统，通过优化调度算法显著提升训练效率。


<details>
  <summary>Details</summary>
Motivation: 随着LLM规模的扩大和GPU更新速度加快，如何在异构环境中高效利用中端或旧代GPU进行RL训练成为挑战。

Method: HetRL将异构环境中的RL训练调度建模为一个约束联合优化问题，并引入多级搜索框架和连续减半算法来优化资源分配。

Result: HetRL在20,000 GPU小时的评估中，吞吐量最高达到现有系统的9.17倍，平均提升3.17倍。

Conclusion: HetRL通过创新的调度算法和优化策略，在异构GPU环境中显著提升了RL训练的吞吐量，为解决高需求GPU资源短缺问题提供了有效方案。

Abstract: As large language models (LLMs) continue to scale and new GPUs are released even more frequently, there is an increasing demand for LLM post-training in heterogeneous environments to fully leverage underutilized mid-range or previous-generation GPUs across regions and alleviate the shortage of homogeneous high-end GPUs within a single region. However, achieving high-performance reinforcement learning (RL) training for LLMs on such computing resources remains challenging because the workflow involves multiple models and tasks with complex computation and data dependencies. In this paper, we present HetRL, a distributed system for efficient RL training in infrastructures with heterogeneous GPUs and networks. HetRL formulates the scheduling of RL training in heterogeneous environments as a constrained joint optimization problem and introduces a novel scheduling algorithm that (1) decomposes the complex search space with a multi-level search framework; and (2) allocates the search budget via successive halving. Our extensive evaluation, consuming 20,000 GPU-hours, shows that HetRL delivers up to 9.17x the throughput of state-of-the-art systems, and 3.17x on average, under various workloads and settings.

</details>


### [303] [Strategic Server Deployment under Uncertainty in Mobile Edge Computing](https://arxiv.org/abs/2512.12532)
*Duc A. Tran,Dung Truong,Duy Le*

Main category: cs.DC

TL;DR: 论文提出了一种基于子模函数和贪婪算法的服务器部署方法，显著提升了移动边缘计算的效率和通信成本。


<details>
  <summary>Details</summary>
Motivation: 移动边缘计算中服务器部署的效率和通信成本是关键问题，但用户工作负载和服务器有效容量通常是未知且时变的，因此需要一种能持续适应这些不确定性的解决方案。

Method: 论文将服务器部署问题建模为随机双层优化问题，并利用子模函数近似目标函数，采用先进的贪婪算法进行求解。

Result: 通过真实数据评估，提出的算法性能优于其他方法，提升幅度高达55%。

Conclusion: 该论文通过将问题建模为随机双层优化问题，并利用子模函数近似目标函数，成功提出了一种高效的贪婪算法，显著提升了移动边缘计算中的服务器部署效率。

Abstract: Server deployment is a fundamental task in mobile edge computing: where to place the edge servers and what user cells to assign to them. To make this decision is context-specific, but common goals are 1) computing efficiency: maximize the amount of workload processed by the edge, and 2) communication efficiency: minimize the communication cost between the cells and their assigned servers. We focus on practical scenarios where the user workload in each cell is unknown and time-varying, and so are the effective capacities of the servers. Our research problem is to choose a subset of candidate servers and assign them to the user cells such that the above goals are sustainably achieved under the above uncertainties. We formulate this problem as a stochastic bilevel optimization, which is strongly NP-hard and unseen in the literature. By approximating the objective function with submodular functions, we can utilize state-of-the-art greedy algorithms for submodular maximization to effectively solve our problem. We evaluate the proposed algorithm using real-world data, showing its superiority to alternative methods; the improvement can be as high as 55%

</details>


### [304] [Ethical Risk Analysis of L2 Rollups](https://arxiv.org/abs/2512.12732)
*Georgy Ishmaev,Emmanuelle Anceaume,Davide Frey,François Taïani*

Main category: cs.DC

TL;DR: 论文分析了Layer 2 rollups中操作者和治理设计带来的伦理风险，发现即时升级和提案者控制是主要问题，并提出了缓解策略。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探讨哪些操作者和治理设计会导致伦理上存在问题的用户风险，特别是在Layer 2 rollups中。

Method: 论文采用了伦理风险分析方法，构建了一个基于角色的决策权威和暴露分类法，并结合了两个实证信号：L2BEAT的129个项目横截面快照和2022至2025年手动整理的事件集。

Result: 研究发现，即时升级无退出窗口的项目约占86%，提案者控制冻结提款的项目约占50%。事件主要集中在排序器活跃性和包含性上。

Conclusion: 论文总结出，基于L2组件的控制安排导致的伦理风险普遍存在，并提出了包括技术组件和治理机制在内的缓解策略建议。

Abstract: Layer 2 rollups improve throughput and fees, but can reintroduce risk through operator discretion and information asymmetry. We ask which operator and governance designs produce ethically problematic user risk. We adapt Ethical Risk Analysis to rollup architectures, build a role-based taxonomy of decision authority and exposure, and pair the framework with two empirical signals, a cross sectional snapshot of 129 projects from L2BEAT and a hand curated incident set covering 2022 to 2025. We analyze mechanisms that affect risks to users funds, including upgrade timing and exit windows, proposer liveness and whitelisting, forced inclusion usability, and data availability choices. We find that ethical hazards rooted in L2 components control arrangements are widespread: instant upgrades without exit windows appear in about 86 percent of projects, and proposer controls that can freeze withdrawals in about 50 percent. Reported incidents concentrate in sequencer liveness and inclusion, consistent with these dependencies. We translate these findings into ethically grounded suggestions on mitigation strategies including technical components and governance mechanisms.

</details>


### [305] [Fine-Grained Energy Prediction For Parallellized LLM Inference With PIE-P](https://arxiv.org/abs/2512.12801)
*Anurag Dutt,Young Won Choi,Avirup Sil,Anshul Gandhi,Aruna Balasubramanian,Niranjan Balasubramanian*

Main category: cs.DC

TL;DR: PIE-P是一个针对多GPU并行LLM推理的细粒度能源预测框架，解决了现有方法在并行环境中的局限性，显著提升了预测准确性。


<details>
  <summary>Details</summary>
Motivation: 由于硬件功耗监控器不可用且软件工具不准确，现有能源预测方法仅限于单GPU环境，无法适用于多GPU并行的现代LLM推理。

Method: 开发了一个可扩展的预测框架，通过精确采样、细粒度建模GPU间通信以及并行开销的仔细计算。

Result: 评估结果表明，PIE-P在各种并行策略下均能提供准确且细粒度的能源预测，显著优于基线方法。

Conclusion: PIE-P框架通过精确采样、细粒度建模和并行开销的仔细计算，显著提升了多GPU环境下LLM推理的能源预测准确性。

Abstract: With the widespread adoption of Large Language Models (LLMs), energy costs of running LLMs is quickly becoming a critical concern. However, precisely measuring the energy consumption of LLMs is often infeasible because hardware-based power monitors are not always accessible and software-based energy measurement tools are not accurate. While various prediction techniques have been developed to estimate LLM energy consumption, these approaches are limited to single-GPU environments and thus are not applicable to modern LLM inference which is typically parallelized across multiple GPUs. In this work, we remedy this gap and introduce PIE-P, a fine-grained energy prediction framework for multi-GPU inference, including tensor, pipeline, and data parallelism. Predicting the energy under parallelized inference is complicated by the non-determinism in inter-GPU communication, additional communication overheads, and difficulties in isolating energy during the communication/synchronization phase. We develop a scalable prediction framework that addresses these issues via precise sampling, fine-grained modeling of inter-GPU communication, and careful accounting of parallelization overhead. Our evaluation results show that PIE-P yields accurate and fine-grained energy predictions across parallelism strategies, significantly outperforming baselines.

</details>


### [306] [PROSERVE: Unified Multi-Priority Request Scheduling for LLM Serving](https://arxiv.org/abs/2512.12928)
*Weizhe Huang,Tao Peng,Tongxuan Liu,Donghe Jin,Xianzhe Dong,Ke Zhang*

Main category: cs.DC

TL;DR: PROSERVE通过双层调度框架优化LLM服务，显著提升优先级请求的处理效率和SLO达成率。


<details>
  <summary>Details</summary>
Motivation: 现有LLM服务调度器未能同时优化SLO达成率和客户端优先级差异，导致业务关键功能无法获得更高性能保障。

Method: 提出PROSERVE框架，包含SlideBatching（引擎层动态批处理与请求排序）和GoRouting（服务层基于增益和能力的请求分发）。

Result: 在四个开源数据集和真实工业场景中，PROSERVE将系统增益提升35%，SLO达成率提高52%。

Conclusion: PROSERVE框架通过双层调度策略，显著提升了服务增益和SLO达成率，优于现有基线方法。

Abstract: The widespread deployment of large language models (LLMs) for interactive applications necessitates serving systems that can handle thousands of concurrent requests with diverse Service Level Objective (SLO) requirements. A critical yet often overlooked dimension in this context is the inherent priority difference among clients; for instance, business-critical functions demand higher performance guarantees, as fulfilling such requests yields significantly greater business value. However, existing LLM serving schedulers fail to jointly optimize for both SLO attainment and client-level priorities.
  To bridge this gap, we first \textit{formalize multi-priority request scheduling as a service gain maximization problem}, where satisfying latency requirements for requests of different priorities contributes varying levels of gain. We then propose PROSERVE, a unified two-tier scheduling framework designed to maximize overall service gain. At the engine level, SlideBatching dynamically adapts batch formation and request ordering under varying load conditions, employing a sliding boundary mechanism to balance deadline-first and density-first strategies. At the service level, GoRouting performs gain-oriented and capability-aware dispatching across distributed instances, proactively reserving capacity for future high-priority or long requests. Extensive evaluation across four open-source datasets and a real-world industrial trace demonstrates that \systemname{} consistently outperforms state-of-the-art baselines, improving system gain by up to 35% and boosting SLO attainment by up to 52%.

</details>


### [307] [FlashFuser: Expanding the Scale of Kernel Fusion for Compute-Intensive Operators via Inter-Core Connection](https://arxiv.org/abs/2512.12949)
*Ziyu Huang,Yangjie Zhou,Zihan Liu,Xinhao Luo,Yijia Diao,Minyi Guo,Jidong Zhai,Yu Feng,Chen Zhang,Anbang Wu,Jingwen Leng*

Main category: cs.DC

TL;DR: FlashFuser是一个利用GPU分布式共享内存进行内核融合的编译器框架，显著提升计算效率。


<details>
  <summary>Details</summary>
Motivation: 随着计算吞吐量的提升，内存带宽成为深度学习工作负载的瓶颈，而现有融合技术受限于局部暂存内存，无法充分利用现代GPU的DSM潜力。

Method: FlashFuser提出了基于DSM的通信抽象、数据流分析器和统一的搜索引擎，以优化执行计划和数据移动。

Result: 在NVIDIA H100 GPU上的评估显示，FlashFuser减少了58%的内存访问，内核速度提升了3.3倍至4.1倍，端到端速度提升了1.24倍。

Conclusion: FlashFuser通过利用现代GPU的分布式共享内存（DSM）机制，显著提升了内核融合的效率，减少了内存访问并加速了计算任务。

Abstract: The scaling of computation throughput continues to outpace improvements in memory bandwidth, making many deep learning workloads memory-bound. Kernel fusion is a key technique to alleviate this problem, but the fusion strategies of existing compilers and frameworks are limited to using local scratchpad memory. When the intermediate results exceed the limited capacity (such as FFN), the fusion fails. Although modern GPUs (like the NVIDIA H100) now incorporate an inter-core connection mechanism known as Distributed Shared Memory(DSM)--providing a larger, high-bandwidth, and low-latency on-chip memory pool--this hardware potential has yet to be exploited by software frameworks. To bridge this gap, we present FlashFuser, the first compiler framework to utilize inter-core connection for kernel fusion on modern GPUs. FlashFuser extends established fusion techniques to the DSM domain through three core contributions. First, we propose a powerful DSM-based communication abstraction that formalizes complex cluster-based data exchange patterns, such as reduce, shuffle and multiply. Second, we introduce a dataflow analyzer that generalizes loop scheduling, resource mapping, and tile selection to the distributed memory hierarchy; it determines the optimal execution order and tile sizes by quantifying data movement across memory levels. Finally, FlashFuser integrates these components into a unified search engine that employs analytical cost modeling and DSM-aware pruning strategies to efficiently discover the optimal execution plan. Our evaluation on an NVIDIA H100 GPU shows that FlashFuser reduces memory access by 58% and delivers kernel speedups of 3.3x against highly-tuned libraries and 4.1x against state-of-the-art compilers, resulting in a 1.24x end-to-end speedup.

</details>


### [308] [Toward Self-Healing Networks-on-Chip: RL-Driven Routing in 2D Torus Architectures](https://arxiv.org/abs/2512.13096)
*Mohammad Walid Charrwi,Zaid Hussain*

Main category: cs.DC

TL;DR: RL自适应路由在2D环面NoCs中优于传统方法，提供更高吞吐量和故障恢复能力。


<details>
  <summary>Details</summary>
Motivation: 探讨在节点故障条件下，2D环面网络（NoCs）中自适应最小路由的性能，比较RL策略与传统自适应路由的优劣。环面拓扑因其低直径和高连接性被选用。

Method: 研究比较了基于强化学习的路由策略和自适应路由基线方法。RL方法将每个路由器建模为代理，根据网络状态学习转发数据包；自适应方案则使用固定的最短路径，并在故障时简单重路由。

Result: RL方法在高负载下吞吐量显著提高（约20-30%增益），并在故障增加时保持更高的可靠性。RL路由器通过利用路径多样性适应故障，而自适应方案在故障累积时性能急剧下降。

Conclusion: 基于强化学习（RL）的自适应路由在2D环面网络（NoCs）中表现出更高的吞吐量和故障恢复能力，尤其在故障密度增加时仍能保持较高的可靠性。

Abstract: We investigate adaptive minimal routing in 2D torus networks on chip NoCs under node fault conditions comparing a reinforcement learning RL based strategy to an adaptive routing baseline A torus topology is used for its low diameter high connectivity properties The RL approach models each router as an agent that learns to forward packets based on network state while the adaptive scheme uses fixed minimal paths with simple rerouting around faults We implement both methods in simulation injecting up to 50 node faults uniformly at random Key metrics are measured 1 throughput vs offered load at fault density 02 2 packet delivery ratio PDR vs fault density and 3 a fault adaptive score FT vs fault density Experimental results show the RL method achieves significantly higher throughput at high load approximately 2030 gain and maintains higher reliability under increasing faults The RL router delivers more packets per cycle and adapts to faults by exploiting path diversity whereas the adaptive scheme degrades sharply as faults accumulate In particular the RL approach preserves end to end connectivity longer PDR remains above 90 until approximately 3040 faults while adaptive PDR drops to approximately 70 at the same point The fault adaptive score likewise favors RL routing Thus RL based adaptive routing demonstrates clear advantages in throughput and fault resilience for torus NoCs

</details>


### [309] [SPARS: A Reinforcement Learning-Enabled Simulator for Power Management in HPC Job Scheduling](https://arxiv.org/abs/2512.13268)
*Muhammad Alfian Amrizal,Raka Satya Prasasta,Santana Yuda Pradata,Kadek Gemilang Santiyuda,Reza Pulungan,Hiroyuki Takizawa*

Main category: cs.DC

TL;DR: SPARS是一个基于强化学习的轻量级模拟器，用于HPC作业调度中的电源管理，旨在平衡能源效率与性能，支持灵活配置和模块化扩展。


<details>
  <summary>Details</summary>
Motivation: 高性能计算集群消耗大量能源，空闲节点是主要浪费来源。关闭未使用节点可以缓解此问题，但不当的转换时机会导致延迟和性能下降。

Method: SPARS集成了作业调度和节点电源状态管理，采用离散事件模拟框架，支持传统调度策略如FCFS和EASY Backfilling，以及利用强化学习代理动态决策节点开关的增强变体。

Result: SPARS提供全面的指标记录，包括能源使用、浪费功率、作业等待时间和节点利用率，并通过甘特图可视化分析调度动态和电源转换。

Conclusion: SPARS提供了一个灵活、可复现且可扩展的平台，使研究人员和从业者能够系统地评估节能调度策略，探索能源效率与性能之间的权衡，并加速可持续高性能计算操作的发展。

Abstract: High-performance computing (HPC) clusters consume enormous amounts of energy, with idle nodes as a major source of waste. Powering down unused nodes can mitigate this problem, but poorly timed transitions introduce long delays and reduce overall performance. To address this trade-off, we present SPARS, a reinforcement learning-enabled simulator for power management in HPC job scheduling. SPARS integrates job scheduling and node power state management within a discrete-event simulation framework. It supports traditional scheduling policies such as First Come First Served and EASY Backfilling, along with enhanced variants that employ reinforcement learning agents to dynamically decide when nodes should be powered on or off. Users can configure workloads and platforms in JSON format, specifying job arrivals, execution times, node power models, and transition delays. The simulator records comprehensive metrics-including energy usage, wasted power, job waiting times, and node utilization-and provides Gantt chart visualizations to analyze scheduling dynamics and power transitions. Unlike widely used Batsim-based frameworks that rely on heavy inter-process communication, SPARS provides lightweight event handling and consistent simulation results, making experiments easier to reproduce and extend. Its modular design allows new scheduling heuristics or learning algorithms to be integrated with minimal effort. By providing a flexible, reproducible, and extensible platform, SPARS enables researchers and practitioners to systematically evaluate power-aware scheduling strategies, explore the trade-offs between energy efficiency and performance, and accelerate the development of sustainable HPC operations.

</details>


### [310] [Temporal parallelisation of continuous-time maximum-a-posteriori trajectory estimation](https://arxiv.org/abs/2512.13319)
*Hassan Razavi,Ángel F. García-Fernández,Simo Särkkä*

Main category: cs.DC

TL;DR: 提出了一种并行时间方法，用于加速部分观测SDEs的MAP轨迹估计，通过最优控制问题重构和并行算法实现高效计算。


<details>
  <summary>Details</summary>
Motivation: 旨在提高部分观测随机微分方程（SDEs）状态的最大后验（MAP）轨迹估计在并行架构上的计算速度。

Method: 将MAP估计问题重新表述为基于Onsager-Machlup泛函的连续时间最优控制问题，并采用并行关联扫描算法进行求解。在非线性模型中通过泰勒展开进行扩展。

Result: GPU实验表明，该方法在线性和非线性模型上均实现了显著的计算加速。

Conclusion: 该论文提出的并行时间方法在保持顺序算法精度的同时，显著提高了计算速度，适用于线性和非线性模型。

Abstract: This paper proposes a parallel-in-time method for computing continuous-time maximum-a-posteriori (MAP) trajectory estimates of the states of partially observed stochastic differential equations (SDEs), with the goal of improving computational speed on parallel architectures. The MAP estimation problem is reformulated as a continuous-time optimal control problem based on the Onsager-Machlup functional. This reformulation enables the use of a previously proposed parallel-in-time solution for optimal control problems, which we adapt to the current problem. The structure of the resulting optimal control problem admits a parallel solution based on parallel associative scan algorithms. In the linear Gaussian special case, it yields a parallel Kalman-Bucy filter and a parallel continuous-time Rauch-Tung-Striebel smoother. These linear computational methods are further extended to nonlinear continuous-time state-space models through Taylor expansions. We also present the corresponding parallel two-filter smoother. The graphics processing unit (GPU) experiments on linear and nonlinear models demonstrate that the proposed framework achieves a significant speedup in computations while maintaining the accuracy of sequential algorithms.

</details>


### [311] [SIGMA: An AI-Empowered Training Stack on Early-Life Hardware](https://arxiv.org/abs/2512.13488)
*Lei Qu,Lianhai Ren,Peng Cheng,Rui Gao,Ruizhe Wang,Tianyu Chen,Xiao Liu,Xingjian Zhang,Yeyun Gong,Yifan Xiong,Yucheng Ding,Yuting Jiang,Zhenghao Lin,Zhongxin Guo,Ziyue Yang*

Main category: cs.DC

TL;DR: SIGMA是一个开源训练堆栈，通过LTP和LTF解决了早期AI加速器在大规模训练中的挑战，显著提升了可靠性和效率。


<details>
  <summary>Details</summary>
Motivation: 早期AI加速器在大规模训练中面临可靠性、正确性和效率的挑战，需要一种解决方案来提升训练效果。

Method: SIGMA是一个开源训练堆栈，核心是LTP系统，专为早期AI加速器集群优化。LTF在此基础上训练了200B MoE模型SIGMA-MOE。

Result: LTP实现了94.45%的集群加速器利用率，减少了节点回收和任务恢复时间。LTF训练SIGMA-MOE模型时达到了21.08% MFU，仅发生一次稳定性事件。

Conclusion: SIGMA通过LUCIA TRAINING PLATFORM (LTP)和LUCIA TRAINING FRAMEWORK (LTF)成功解决了早期AI加速器在大规模训练中的可靠性、稳定性和效率问题，为AI基础设施和平台创新设立了新标准。

Abstract: An increasing variety of AI accelerators is being considered for large-scale training. However, enabling large-scale training on early-life AI accelerators faces three core challenges: frequent system disruptions and undefined failure modes that undermine reliability; numerical errors and training instabilities that threaten correctness and convergence; and the complexity of parallelism optimization combined with unpredictable local noise that degrades efficiency. To address these challenges, SIGMA is an open-source training stack designed to improve the reliability, stability, and efficiency of large-scale distributed training on early-life AI hardware. The core of this initiative is the LUCIA TRAINING PLATFORM (LTP), the system optimized for clusters with early-life AI accelerators. Since its launch in March 2025, LTP has significantly enhanced training reliability and operational productivity. Over the past five months, it has achieved an impressive 94.45% effective cluster accelerator utilization, while also substantially reducing node recycling and job-recovery times. Building on the foundation of LTP, the LUCIA TRAINING FRAMEWORK (LTF) successfully trained SIGMA-MOE, a 200B MoE model, using 2,048 AI accelerators. This effort delivered remarkable stability and efficiency outcomes, achieving 21.08% MFU, state-of-the-art downstream accuracy, and encountering only one stability incident over a 75-day period. Together, these advances establish SIGMA, which not only tackles the critical challenges of large-scale training but also establishes a new benchmark for AI infrastructure and platform innovation, offering a robust, cost-effective alternative to prevailing established accelerator stacks and significantly advancing AI capabilities and scalability. The source code of SIGMA is available at https://github.com/microsoft/LuciaTrainingPlatform.

</details>


### [312] [Janus: Disaggregating Attention and Experts for Scalable MoE Inference](https://arxiv.org/abs/2512.13525)
*Zhexiang Zhang,Ye Wang,Xiangyu Wang,Yumiao Zhao,Jingzhe Jiang,Qizhen Weng,Shaohuai Shi,Yin Chen,Minchen Yu*

Main category: cs.DC

TL;DR: Janus是一个可扩展的MoE推理系统，通过解耦注意力和专家模块、优化通信和调度，显著提高了资源效率和推理性能。


<details>
  <summary>Details</summary>
Motivation: 现有的MoE模型推理解决方案通常将整个模型作为一个单一的整体单元部署，导致资源利用效率低下和可扩展性受限。Janus旨在通过解耦模块和独立管理资源来解决这些问题。

Method: Janus提出了一种可扩展的MoE推理系统，通过将注意力和专家模块分离到不同的GPU子集群上，并采用自适应两阶段通信方案、轻量级调度器以及细粒度资源管理来优化推理过程。

Result: 评估显示，Janus在满足每个令牌延迟要求的同时，实现了比现有系统高3.9倍的每GPU吞吐量。

Conclusion: Janus通过解耦注意力模块和专家模块，并采用自适应通信方案、轻量级调度器和细粒度资源管理，显著提高了MoE模型的推理效率和可扩展性，实现了比现有系统更高的吞吐量。

Abstract: Large Mixture-of-Experts (MoE) model inference is challenging due to high resource demands and dynamic workloads. Existing solutions often deploy the entire model as a single monolithic unit, which applies a unified resource configuration to both attention and expert modules despite their different requirements, leading to limited scalability and resource inefficiency. In this paper, we propose Janus, a scalable MoE inference system that disaggregates attention and experts on separate GPU sub-clusters, enabling each module to be managed and scaled independently. Janus incorporates three key designs for efficient, disaggregated MoE inference. First, it proposes an adaptive two-phase communication scheme that exploits intra- and inter-node bandwidth hierarchies for low-latency data exchange. Second, motivated by the memory-bound nature of MoE modules, Janus introduces a lightweight scheduler and implements it as a GPU kernel to balance the number of activated experts across GPUs at minimal overhead, thereby reducing inference latency. Third, Janus performs fine-grained resource management to dynamically adjust expert placement and independently scale attention and MoE resources to improve overall efficiency. Evaluation shows Janus achieves up to 3.9 higher perGPU throughput than state-of-the-art systems while meeting per-token latency requirements.

</details>


### [313] [astroCAMP: A Community Benchmark and Co-Design Framework for Sustainable SKA-Scale Radio Imaging](https://arxiv.org/abs/2512.13591)
*Denisa-Andreea Constantinescu,Rubén Rodríguez Álvarez,Jacques Morin,Etienne Orliac,Mickaël Dardaillon,Sunrise Wang,Hugo Miomandre,Miguel Peón-Quirós,Jean-François Nezan,David Atienza*

Main category: cs.DC

TL;DR: astroCAMP框架通过统一指标、标准化数据和协同设计方法，优化SKA成像管线的能效和科学回报。


<details>
  <summary>Details</summary>
Motivation: 当前射电干涉测量管线硬件性能利用率低（4-14%），且缺乏标准化指标，导致能效低下和碳成本高。

Method: 介绍了astroCAMP框架，提供统一的度量套件、标准化数据集和多目标协同设计方法。

Result: 评估了WSClean和IDG在AMD EPYC 9334和NVIDIA H100上的协同设计指标，展示了异构CPU-FPGA设计空间探索的潜力。

Conclusion: 呼吁SKA社区定义可量化的保真度指标和阈值，以加速SKA规模成像的原则性优化。

Abstract: The Square Kilometre Array (SKA) project will operate one of the world's largest continuous scientific data systems, sustaining petascale imaging under strict power caps. Yet, current radio-interferometric pipelines utilize only a small fraction of hardware peak performance, typically 4-14%, due to memory and I/O bottlenecks, resulting in poor energy efficiency and high operational and carbon costs. Progress is further limited by the absence of standardised metrics and fidelity tolerances, preventing principled hardware-software co-design and rigorous exploration of quality-efficiency trade-offs. We introduce astroCAMP, a framework for guiding the co-design of next-generation imaging pipelines and sustainable HPC architectures that maximise scientific return within SKA's operational and environmental limits. astroCAMP provides: (1) a unified, extensible metric suite covering scientific fidelity, computational performance, sustainability, and lifecycle economics; (2) standardised SKA-representative datasets and reference outputs enabling reproducible benchmarking across CPUs, GPUs, and emerging accelerators; and (3) a multi-objective co-design formulation linking scientific-quality constraints to time-, energy-, carbon-to-solution, and total cost of ownership. We release datasets, benchmarking results, and a reproducibility kit, and evaluate co-design metrics for WSClean and IDG on an AMD EPYC 9334 processor and an NVIDIA H100 GPU. Further, we illustrate the use of astroCAMP for heterogeneous CPU-FPGA design-space exploration, and its potential to facilitate the identification of Pareto-optimal operating points for SKA-scale imaging deployments. Last, we make a call to the SKA community to define quantifiable fidelity metrics and thresholds to accelerate principled optimisation for SKA-scale imaging.

</details>


### [314] [Design in Tiles: Automating GEMM Deployment on Tile-Based Many-PE Accelerators](https://arxiv.org/abs/2512.13638)
*Aofeng Shen,Chi Zhang,Yakup Budanaz,Alexandru Calotoiu,Torsten Hoefler,Luca Benini*

Main category: cs.DC

TL;DR: DiT自动化框架优化Tile-based多PE加速器的GEMM性能，超越NVIDIA GH200，速度提升1.2-2.0倍。


<details>
  <summary>Details</summary>
Motivation: Tile-based多PE加速器在GEMM任务中性能优异但编程困难，其最优软件映射与硬件设计深度耦合，手动部署效率低下。

Method: 提出'Design in Tiles (DiT)'框架，结合自动化部署工具链和可配置执行模型，优化GEMM在Tile-based多PE加速器上的软件映射。

Result: 在大型加速配置（如32x32 tiles，1979 TFLOPS@FP8，4 TB/s带宽）下，DiT框架实现了比NVIDIA GH200更高的PE利用率，速度提升1.2-2.0倍。

Conclusion: DiT框架通过自动化部署工具链和可配置执行模型，显著提升了Tile-based多PE加速器在GEMM任务中的性能，实现了比NVIDIA GH200更高的PE利用率和1.2-2.0倍的加速。

Abstract: Tile-based many-Processing Element (PE) accelerators can achieve competitive performance on General Matrix Multiplication (GEMM), but they are extremely hard to program, as their optimal software mapping is deeply coupled with hardware design which is unwieldy to manual deployment. We propose "Design in Tiles (DiT)", an automated framework connecting a deployment toolchain with a configurable executable model for these accelerators. For evaluation, we apply our framework to GEMM targeting a large acceleration configuration (e.g., 32x32 tiles, 1979 TFLOPS@FP8, 4 TB/s Bandwidth) comparable to an NVIDIA GH200. We achieve higher PE utilization than GH200 with its expert-tuned GEMM libraries, achieving 1.2-2.0x speedup across diverse matrix shapes.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [315] [Policy Gradient Algorithms for Age-of-Information Cost Minimization](https://arxiv.org/abs/2512.11990)
*José-Ramón Vidal,Vicent Pla,Luis Guijarro,Israel Leyva-Mayorga*

Main category: cs.NI

TL;DR: 本文提出两种基于强化学习的算法，优化网络物理系统中的信息更新策略，以最小化时间平均成本，并在广泛场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 网络物理系统中信息新鲜度的最大化是一个重要但具有挑战性的任务，尤其是在传输延迟和年龄成本函数特性未知的情况下。

Method: 采用基于模型无关强化学习（RL）的策略梯度方法，设计了两种算法，分别采用不同的更新决策策略，并可同时应用以进一步降低成本。

Result: 算法表现出良好的收敛性，时间平均成本接近最优值，并在多方面优于现有方法。

Conclusion: 所提出的算法在计算最优值时，时间平均成本在最优值的3%以内，并且与其他先进方法相比，在适用性、成本降低和计算效率方面表现更优。

Abstract: Recent developments in cyber-physical systems have increased the importance of maximizing the freshness of the information about the physical environment. However, optimizing the access policies of Internet of Things devices to maximize the data freshness, measured as a function of the Age-of-Information (AoI) metric, is a challenging task. This work introduces two algorithms to optimize the information update process in cyber-physical systems operating under the generate-at-will model, by finding an online policy without knowing the characteristics of the transmission delay or the age cost function. The optimization seeks to minimize the time-average cost, which integrates the AoI at the receiver and the data transmission cost, making the approach suitable for a broad range of scenarios. Both algorithms employ policy gradient methods within the framework of model-free reinforcement learning (RL) and are specifically designed to handle continuous state and action spaces. Each algorithm minimizes the cost using a distinct strategy for deciding when to send an information update. Moreover, we demonstrate that it is feasible to apply the two strategies simultaneously, leading to an additional reduction in cost. The results demonstrate that the proposed algorithms exhibit good convergence properties and achieve a time-average cost within 3% of the optimal value, when the latter is computable. A comparison with other state-of-the-art methods shows that the proposed algorithms outperform them in one or more of the following aspects: being applicable to a broader range of scenarios, achieving a lower time-average cost, and requiring a computational cost at least one order of magnitude lower.

</details>


### [316] [A Leaner and Faster Web: How CBOR Can Improve Dynamic Content Encoding in JSON and DNS over HTTPS](https://arxiv.org/abs/2512.12067)
*Martine S. Lenders,Carsten Bormann,Thomas C. Schmidt,Matthias Wählisch*

Main category: cs.NI

TL;DR: 使用CBOR格式压缩动态内容（JSON/DNS over HTTPS），显著减少数据量和加载时间，并推动标准化。


<details>
  <summary>Details</summary>
Motivation: 动态内容（如JSON和DNS over HTTPS）的大小持续增长，增加了延迟和数字不平等，需要更高效的压缩方法。

Method: 利用为受限物联网设计的CBOR格式，对JSON和DNS over HTTPS消息进行编码，并提出了两种名称压缩方案。

Result: 从JSON切换到CBOR减少了80.0%的数据量，加载时间减少13.8%；新的CBOR DNS格式减少了95.5%的数据量，名称压缩方案节省了226字节。

Conclusion: 采用CBOR格式显著减少了动态内容的大小，提升了加载速度，并为DNS消息格式的标准化做出了贡献。

Abstract: The Internet community has taken major efforts to decrease latency in the World Wide Web. Significant improvements have been achieved in accelerating content transport and in compressing static content. Less attention, however, has been dedicated to dynamic content compression. Such content is commonly provided by JSON and DNS over HTTPS. Aligned with the overall Web trend, dynamic content objects continue to grow in size, which increases latency and fosters the digital inequality. In this paper, we propose to counter this increase by utilizing components engineered for the constrained Internet of Things (IoT). We focus on the Concise Binary Object Representation (CBOR) and its use for dynamic content encoded in JSON or in DNS over HTTPS messages. CBOR was originally introduced to restrict packet sizes in constrained environments and enables small, effective encoding of data objects. We measure that simply switching the data representation from JSON to CBOR reduces data by up to 80.0% for a corpus of JSON objects collected via the HTTP Archive. This size reduction can decrease loading times by up to 13.8% when downloading large objects -- even in local setups. A new CBOR-based DNS message format designed for use with DNS over HTTPS (DoH) and DNS over CoAP (DoC) minimizes packets by up to 95.5% in its packed form and shows large potential for additionally compressing names and addresses. We contribute two name compression schemes that apply to the new CBOR format and save up to 226 bytes in a response. The decoder for our name compression scheme is lean and can fit into as little as 314 bytes of binary build size. One of those compression schemes and further optimization proposals directly influenced further improvements of the new CBOR format within Internet standardization.

</details>


### [317] [Dynamic SLA-aware Network Slice Monitoring](https://arxiv.org/abs/2512.12123)
*Niloy Saha,Mina Tahmasbi Arashloo,Nashid Shahriar,Raouf Boutaba*

Main category: cs.NI

TL;DR: SliceScope通过动态资源分配和变更触发INT技术，显著提升了网络切片监控的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有解决方案在确保网络切片SLA合规性方面存在两个基本限制：缺乏端到端可见性或缺乏动态分配监控资源的控制机制。

Method: 提出了一种正式框架，将切片监控重新定义为闭环控制问题，并定义了通过遥测原语合同实现SLA感知切片监控的最小数据平面要求。SliceScope实现了这一框架，结合了动态分配监控资源的控制策略和基于变更触发INT的数据平面。

Result: 评估结果表明，SliceScope在可编程交换机和大规模模拟中，相比静态基线，对关键切片的跟踪准确性提高了4倍，且变更触发INT在实现遥测原语合同方面优于其他替代方案。

Conclusion: SliceScope通过动态分配监控资源并结合数据平面的变更触发INT技术，有效提升了关键网络切片的监控准确性，同时满足了遥测预算的限制。

Abstract: Next-generation networks increasingly rely on network slices - logical networks tailored to specific application requirements, each with distinct Service-Level Agreements (SLAs). Ensuring compliance with these SLAs requires continuous, real-time monitoring of end-to-end performance metrics for each slice, within a limited telemetry budget. However, we find that existing solutions face two fundamental limitations: they either lack end-to-end visibility (e.g., sketches, probabilistic sampling) or provide visibility but lack the control mechanisms to dynamically allocate monitoring resources according to slice SLAs. We address this through a formal framework that reframes slice monitoring as a closed-loop control problem, and defines the minimal data plane requirements for SLA-aware slice monitoring via a telemetry primitive contract. We then present SliceScope, a realization of this framework that combines: (1) a control strategy that dynamically allocates the monitoring resources across diverse slices according to their SLA criticality, and (2) a data-plane based on change-triggered INT that provides per-packet end-to-end visibility with tunable accuracy-overhead trade-offs, satisfying the telemetry contract. Our evaluation results on programmable switches and in large-scale simulations with a mixture of different slice types, demonstrate that SliceScope tracks critical slices up to 4x more accurately compared to static baselines, while showing that change-triggered INT outperforms alternative primitives for realizing the telemetry primitive contract.

</details>


### [318] [Joint Power and Mobility Control](https://arxiv.org/abs/2512.12137)
*Yun Hou,Yening Zhang*

Main category: cs.NI

TL;DR: 研究通过联合优化传输功率和车辆移动性，提出了一种简化优化模型，显著提升了V2X网络的数据包接收率，验证了协调移动性和功率控制的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决自主V2X网络中网络连接性提升的挑战，通过联合优化传输功率和车辆移动性。

Method: 提出了一种基于SINR的sigmoid近似链路接收模型，并将其转化为基于功率的简化优化形式。在此基础上，构建了一个多节点网络效用最大化（NUM）问题，并证明了其凹性，从而实现分布式轨迹和功率调整。

Result: 仿真和实际实验验证了理论发现，表明在干扰受限条件下，对称定位和平衡功率分配显著提高了数据包接收率。

Conclusion: 协调的移动性和功率控制可以有效减轻干扰并提高高度动态车载网络的连接性，为未来自主和无人机系统的稳健通信铺平道路。

Abstract: This study addressed the challenge of improving network connectivity in autonomous V2X networks by jointly optimizing transmission power and vehicle mobility. We proposed a link reception model based on a sigmoid approximation of SINR and transformed it into a power-based formulation for simplicity in optimization. Building on this, we formulated a multi-node Network Utility Maximization (NUM) problem and demonstrated its concavity, enabling distributed trajectory and power adjustments. Both simulation and real-world experiments validated the theoretical findings, showing that symmetric positioning and balanced power allocation significantly enhance packet reception rates under interference-limited conditions. These results confirm that coordinated mobility and power control can effectively mitigate interference and improve connectivity in highly dynamic vehicular networks, paving the way for robust communication in future autonomous and UAV systems.

</details>


### [319] [Agentic AI for 6G: A New Paradigm for Autonomous RAN Security Compliance](https://arxiv.org/abs/2512.12400)
*Sotiris Chatzimiltis,Mahdi Boloursaz Mashhadi,Mohammad Shojafar,Merouane Debbah,Rahim Tafazolli*

Main category: cs.NI

TL;DR: 本文介绍了一个基于LLM和RAG的AI代理框架，用于自动化电信网络的安全合规性检查，展示了初步成果并讨论了未来方向。


<details>
  <summary>Details</summary>
Motivation: 传统方法难以跟上下一代无线接入网络(RANs)的复杂性和实时变化，因此需要自动化安全合规流程。

Method: 提出了一个框架，结合LLM-based AI代理和RAG管道，用于自动化安全合规性检查。

Result: 初步案例研究表明，代理能够评估配置文件是否符合O-RAN Alliance和3GPP标准，生成可解释的理由，并在需要时提出自动修复建议。

Conclusion: 本文提出了一个利用基于LLM的AI代理与RAG管道结合的框架，用于智能和自主地执行安全合规性。未来研究方向包括开发电信专用LLM和标准化评估框架。

Abstract: Agentic AI systems are emerging as powerful tools for automating complex, multi-step tasks across various industries. One such industry is telecommunications, where the growing complexity of next-generation radio access networks (RANs) opens up numerous opportunities for applying these systems. Securing the RAN is a key area, particularly through automating the security compliance process, as traditional methods often struggle to keep pace with evolving specifications and real-time changes. In this article, we propose a framework that leverages LLM-based AI agents integrated with a retrieval-augmented generation (RAG) pipeline to enable intelligent and autonomous enforcement of security compliance. An initial case study demonstrates how an agent can assess configuration files for compliance with O-RAN Alliance and 3GPP standards, generate explainable justifications, and propose automated remediation if needed. We also highlight key challenges such as model hallucinations and vendor inconsistencies, along with considerations like agent security, transparency, and system trust. Finally, we outline future directions, emphasizing the need for telecom-specific LLMs and standardized evaluation frameworks.

</details>


### [320] [Efficient Resource Allocation for Multi-User and Multi-Target MIMO-OFDM Underwater ISAC](https://arxiv.org/abs/2512.12611)
*Wei Men,Longfei Zhao,Yong Liang Guan,Xiangwang Hou,Yong Ren,Dusit Niyato*

Main category: cs.NI

TL;DR: 提出一种MIMO UWA-ISAC系统，通过优化算法在复杂水下环境中高效平衡通信与感知性能。


<details>
  <summary>Details</summary>
Motivation: 解决下一代水下网络中多用户覆盖和目标感知与通信性能平衡的挑战。

Method: 采用交错正交频分复用技术，结合水平阵列传输自适应波形，提出多目标优化框架和二维分组随机搜索算法。

Result: 数值模拟显示，所提算法比传统穷举搜索收敛速度快90%，PRR仅降低0.5 kbps km，且在严格约束下保持鲁棒性。

Conclusion: 本文提出的基于交错正交频分复用的MIMO UWA-ISAC系统在复杂水下声学环境中有效平衡了多用户通信与目标感知性能，并通过多目标优化框架和二维分组随机搜索算法实现了高效资源分配。

Abstract: Integrated sensing and communication (ISAC) technology is crucial for next-generation underwater networks. However, covering multiple users and targets and balancing sensing and communication performance in complex underwater acoustic (UWA) environments remains challenging. This paper proposes an interleaved orthogonal frequency division multiplexing-based MIMO UWA-ISAC system, which employs a horizontal array to simultaneously transmit adaptive waveforms for downlink multi-user communication and omnidirectional target sensing. A multi-objective optimization framework is formulated to maximize the product of communication rate and range (PRR) while ensuring sensing performance and peak-to-average power ratio (PAPR) constraints. To solve this mixed-integer nonconvex problem, a two-dimensional grouped random search algorithm is developed, efficiently exploring subcarrier interleaved patterns and resource allocation schemes. Numerical simulations under real-world UWA channels demonstrate the designed system's superiority and effectiveness: our algorithm achieves 90% faster convergence than conventional exhaustive search with only a marginal 0.5 kbps km PRR degradation. Furthermore, the proposed resource allocation scheme maintains robustness beyond the baseline allocation schemes under stringent PRR and PAPR constraints.

</details>


### [321] [Low-Complexity Monitoring and Compensation of Transceiver IQ Imbalance by Multi-dimensional Architecture for Dual-Polarization 16 Quadrature Amplitude Modulation](https://arxiv.org/abs/2512.13266)
*Yukun Zhang,Xiaoxue Gong,Xu Zhang,Lei Guo*

Main category: cs.NI

TL;DR: 提出低复杂度IQ不平衡补偿架构，通过收发器偏差估计和MIMO均衡器，显著降低计算复杂度，实验验证有效性。


<details>
  <summary>Details</summary>
Motivation: 解决收发器IQ不平衡对信号传输的影响，同时降低传统方法的计算复杂度。

Method: 提出了一种低复杂度IQ不平衡补偿架构，包括收发器IQ偏差估计方法和低复杂度MIMO均衡器结构。通过Gardner相位检测器估计接收端IQ偏差，发射端偏差通过最小化均衡器误差确定。MIMO均衡器采用复数MIMO（CV-MIMO）和实数DD-LMS MIMO（RV-MIMO）结构。

Result: 仿真和实验显示，接收端IQ偏差估计使实数乘法次数减少70%以上，低复杂度MIMO均衡器减少51%的计算量。

Conclusion: 该架构能够以低复杂度均衡受收发器IQ不平衡影响的信号，通过仿真和实验验证了其有效性。

Abstract: In this paper, a low-complexity IQ imbalance compensation architecture is proposed, which reduces the effects of in-phase (I) and quadrature (Q) imbalance. The architecture consists of transceiver IQ skew estimation methods and a low-complexity MIMO equalizer structure. Before the IQ skew estimation, the chromatic dispersion(CD) is pre-compensated in the transmitter(TX) by chirp filtering. The receiver(RX) IQ skew is estimated by Gardner's phase detector, and the TX skew is estimated by finding the value that yields the lowest equalizer error. The low-complexity MIMO equalizer consists of a complex-valued MIMO(CV-MIMO) and a real-valued DD-LMS MIMO(RV-MIMO), which employ a butterfly and a non-butterfly structure, respectively. The CV-MIMO is used to perform polarization demultiplexing. The RV-MIMO equalizes each of the two polarisations and simultaneously compensates for the TX IQ imbalance. The architecture first compensates for the IQ skew at low-complexity, and the other imperfections are compensated by the low-complexity MIMO equalizer. Therefore, this architecture can equalize signals impaired by the transceiver IQ imbalance with low complexity. A 100 km transmission simulation and experiment with 36 Gbaud dual-polarization quadrature amplitude modulation(DP-QAM) signals and offline DSP showed that, with the RX IQ skew estimation, the number of real multiplications is reduced by more than 70% compared with conventional cases. With the low-complexity MIMO equalizer, the number of real multiplications is reduced by 51% compared with 4x4 MIMO

</details>


### [322] [Resource Orchestration and Optimization in 6G Extreme-edge Scenario](https://arxiv.org/abs/2512.13306)
*Manuel A. Jimenez,Sarang Kahvazadeh,Ignacio Labrador,Josep Mangues-Bafalluy*

Main category: cs.NI

TL;DR: 6G网络编排架构，通过AI预测和大规模监测，提升极端边缘资源管理弹性。


<details>
  <summary>Details</summary>
Motivation: 解决6G网络中异构、动态且移动资源编排的挑战，超越传统运营商控制范围。

Method: 集成了AI/ML基础设施状态预测模块、大规模多样化遥测监测系统以及决策引擎和执行器。

Result: 展示了一种6G就绪的编排架构，能够在极端边缘实现资源预测和服务弹性。

Conclusion: 该论文提出了一种面向6G网络的编排架构，专注于极端边缘的资源预测和服务弹性，通过AI/ML预测、大规模监测系统和决策引擎实现主动管理。

Abstract: 6G networks envision a pervasive service infrastructure spanning from centralized cloud to distributed edge and highly dynamic extreme-edge domains. This vision introduces significant challenges in orchestrating services over heterogeneous, volatile, and often mobile resources beyond traditional operator control. To address these challenges, this demo presents a 6G-ready orchestration architecture focused on resource prediction and service resilience at the extreme-edge. The proposed solution integrates (i) an AI/ML-based Infrastructure Status Prediction Module, (ii) a Monitoring System capable of handling large-scale, diverse telemetry, and (iii) a Decision Engine and Actuator that ensures proactive

</details>


<div id='cs.OS'></div>

# cs.OS [[Back]](#toc)

### [323] [Sharpen the Spec, Cut the Code: A Case for Generative File System with SYSSPEC](https://arxiv.org/abs/2512.13047)
*Qingyuan Liu,Zou Mo,Hengbin Zhang,Dong Du,Yubin Xia,Haibo Chen*

Main category: cs.OS

TL;DR: SYSSPEC框架利用形式化规范和LLMs生成并演化文件系统，解决了传统开发的高开销问题，生成的SPECFS表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统文件系统开发模式在复杂性和维护成本上存在显著开销，需要一种新范式来支持快速演化和新硬件适配。

Method: SYSSPEC框架采用多部分规范替代模糊的自然语言提示，结合DAG结构的补丁和基于LLM的代理工具链。

Result: 生成的SPECFS文件系统通过了数百个回归测试，并成功集成了Ext4的10个实际功能。

Conclusion: SYSSPEC框架通过形式化方法指导LLMs生成和演化文件系统，证明了生成式文件系统的可行性和高效性。

Abstract: File systems are critical OS components that require constant evolution to support new hardware and emerging application needs. However, the traditional paradigm of developing features, fixing bugs, and maintaining the system incurs significant overhead, especially as systems grow in complexity. This paper proposes a new paradigm, generative file systems, which leverages Large Language Models (LLMs) to generate and evolve a file system from prompts, effectively addressing the need for robust evolution. Despite the widespread success of LLMs in code generation, attempts to create a functional file system have thus far been unsuccessful, mainly due to the ambiguity of natural language prompts.
  This paper introduces SYSSPEC, a framework for developing generative file systems. Its key insight is to replace ambiguous natural language with principles adapted from formal methods. Instead of imprecise prompts, SYSSPEC employs a multi-part specification that accurately describes a file system's functionality, modularity, and concurrency. The specification acts as an unambiguous blueprint, guiding LLMs to generate expected code flexibly. To manage evolution, we develop a DAG-structured patch that operates on the specification itself, enabling new features to be added without violating existing invariants. Moreover, the SYSSPEC toolchain features a set of LLM-based agents with mechanisms to mitigate hallucination during construction and evolution. We demonstrate our approach by generating SPECFS, a concurrent file system. SPECFS passes hundreds of regression tests, matching a manually-coded baseline. We further confirm its evolvability by seamlessly integrating 10 real-world features from Ext4. Our work shows that a specification-guided approach makes generating and evolving complex systems not only feasible but also highly effective.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [324] [Benchmarking Tesla's Traffic Light and Stop Sign Control: Field Dataset and Behavior Insights](https://arxiv.org/abs/2512.11802)
*Zheng Li,Peng Zhang,Shixiao Liang,Hang Zhou,Chengyuan Ma,Handong Yao,Qianwen Li,Xiaopeng Li*

Main category: cs.RO

TL;DR: 研究分析了特斯拉TLSSC系统与TCD的交互行为，通过实验数据和模型校准，为未来ADAS-TCD交互设计提供了基础。


<details>
  <summary>Details</summary>
Motivation: 理解ADAS与TCD的交互对评估其对交通运行的影响至关重要，但这一交互缺乏实证研究。

Method: 设计了涵盖不同速度限制和TCD类型的实验，收集了同步高分辨率车辆轨迹数据和驾驶员视角视频，并基于这些数据开发了TLSSC-TCD交互行为分类，校准了FVDM模型。

Result: 识别了跟随阈值（约90米），校准结果显示停止行为对速度偏差和相对速度的响应更强，加速行为更保守，交叉口跟随行为比标准跟随行为更平滑且车距更短。

Conclusion: 本研究通过实验数据和模型校准，为未来ADAS-TCD交互逻辑的仿真、安全评估和设计提供了基础。

Abstract: Understanding how Advanced Driver-Assistance Systems (ADAS) interact with Traffic Control Devices (TCDs) is critical for assessing their influence on traffic operations, yet this interaction has received little focused empirical study. This paper presents a field dataset and behavioral analysis of Tesla's Traffic Light and Stop Sign Control (TLSSC), a mature ADAS that perceives traffic lights and stop signs. We design and execute experiments across varied speed limits and TCD types, collecting synchronized high-resolution vehicle trajectory data and driver-perspective video. From these data, we develop a taxonomy of TLSSC-TCD interaction behaviors (i.e., stopping, accelerating, and car following) and calibrate the Full Velocity Difference Model (FVDM) to quantitatively characterize each behavior mode. A novel empirical insight is the identification of a car-following threshold (~90 m). Calibration results reveal that stopping behavior is driven by strong responsiveness to both desired speed deviation and relative speed, whereas accelerating behavior is more conservative. Intersection car-following behavior exhibits smoother dynamics and tighter headways compared to standard car-following behaviors. The established dataset, behavior definitions, and model characterizations together provide a foundation for future simulation, safety evaluation, and design of ADAS-TCD interaction logic. Our dataset is available at GitHub.

</details>


### [325] [ReGlove: A Soft Pneumatic Glove for Activities of Daily Living Assistance via Wrist-Mounted Vision](https://arxiv.org/abs/2512.11824)
*Rosh Ho,Jian Zhang*

Main category: cs.RO

TL;DR: ReGlove 是一种低成本、基于视觉的辅助系统，通过计算机视觉实现高效抓取，适用于上肢障碍患者。


<details>
  <summary>Details</summary>
Motivation: 慢性上肢障碍影响全球数百万人，但现有辅助技术要么过于昂贵，要么依赖不可靠的生物信号。

Method: 通过整合腕戴式摄像头与边缘计算推理引擎（Raspberry Pi 5），并采用实时 YOLO 计算机视觉模型，实现无需可靠肌肉信号的上下文感知抓取。

Result: 系统实现了 96.73% 的抓取分类准确率和低于 40.00 毫秒的端到端延迟，在 YCB 物体操作中达到 82.71% 的成功率，并在 27 项日常生活活动中表现可靠。

Conclusion: ReGlove 提供了一种基于视觉的上肢辅助技术基础，适用于被传统 EMG 控制设备排除在外的群体。

Abstract: This paper presents ReGlove, a system that converts low-cost commercial pneumatic rehabilitation gloves into vision-guided assistive orthoses. Chronic upper-limb impairment affects millions worldwide, yet existing assistive technologies remain prohibitively expensive or rely on unreliable biological signals. Our platform integrates a wrist-mounted camera with an edge-computing inference engine (Raspberry Pi 5) to enable context-aware grasping without requiring reliable muscle signals. By adapting real-time YOLO-based computer vision models, the system achieves \SI{96.73}{\percent} grasp classification accuracy with sub-\SI{40.00}{\milli\second} end-to-end latency. Physical validation using standardized benchmarks shows \SI{82.71}{\percent} success on YCB object manipulation and reliable performance across \SI{27.00}{} Activities of Daily Living (ADL) tasks. With a total cost under \$\SI{250.00}{} and exclusively commercial components, ReGlove provides a technical foundation for accessible, vision-based upper-limb assistance that could benefit populations excluded from traditional EMG-controlled devices.

</details>


### [326] [WAM-Diff: A Masked Diffusion VLA Framework with MoE and Online Reinforcement Learning for Autonomous Driving](https://arxiv.org/abs/2512.11872)
*Mingwang Xu,Jiahao Cui,Feipeng Cai,Hanlin Shang,Zhihao Zhu,Shan Luan,Yifang Xu,Neng Zhang,Yaoyi Li,Jia Cai,Siyu Zhu*

Main category: cs.RO

TL;DR: WAM-Diff利用掩码扩散迭代优化轨迹生成，结合MoE架构和GSPO强化学习，显著提升自动驾驶性能。


<details>
  <summary>Details</summary>
Motivation: 探索离散掩码扩散在轨迹生成中的潜力，以弥补自回归大语言模型和连续扩散策略的不足。

Method: 采用掩码扩散方法迭代优化离散序列表示未来自车轨迹，结合稀疏MoE架构和在线强化学习（GSPO）优化序列级驾驶奖励。

Result: 在NAVSIM-v1和NAVSIM-v2上分别达到91.0 PDMS和89.7 EPDMS，验证了掩码扩散在自动驾驶中的有效性。

Conclusion: WAM-Diff框架通过掩码扩散方法为自动驾驶轨迹生成提供了一种有前景的替代方案，支持场景感知的解码策略，显著提升了性能指标。

Abstract: End-to-end autonomous driving systems based on vision-language-action (VLA) models integrate multimodal sensor inputs and language instructions to generate planning and control signals. While autoregressive large language models and continuous diffusion policies are prevalent, the potential of discrete masked diffusion for trajectory generation remains largely unexplored. This paper presents WAM-Diff, a VLA framework that employs masked diffusion to iteratively refine a discrete sequence representing future ego-trajectories. Our approach features three key innovations: a systematic adaptation of masked diffusion for autonomous driving that supports flexible, non-causal decoding orders; scalable model capacity via a sparse MoE architecture trained jointly on motion prediction and driving-oriented visual question answering (VQA); and online reinforcement learning using Group Sequence Policy Optimization (GSPO) to optimize sequence-level driving rewards. Remarkably, our model achieves 91.0 PDMS on NAVSIM-v1 and 89.7 EPDMS on NAVSIM-v2, demonstrating the effectiveness of masked diffusion for autonomous driving. The approach provides a promising alternative to autoregressive and diffusion-based policies, supporting scenario-aware decoding strategies for trajectory generation. The code for this paper will be released publicly at: https://github.com/fudan-generative-vision/WAM-Diff

</details>


### [327] [Audio-Based Tactile Human-Robot Interaction Recognition](https://arxiv.org/abs/2512.11873)
*Antonia Yepes,Marie Charbonneau*

Main category: cs.RO

TL;DR: 研究通过机器人身上的麦克风捕捉触摸声音，使用卷积神经网络分类不同触摸类型，效果优于传统传感器方法。


<details>
  <summary>Details</summary>
Motivation: 传统触觉交互检测方法依赖于关节扭矩传感器或6轴力/扭矩传感器，这些方法可能成本高或实现复杂。本研究旨在探索一种基于声音的替代方案，利用机器人硬壳被触摸时产生的声音来检测触觉交互。

Method: 研究采用两个Adafruit I2S MEMS麦克风与Raspberry Pi 4集成，放置在Pollen Robotics Reachy机器人的躯干上，捕捉机器人手臂上各种触摸类型（轻敲、敲击、摩擦、抚摸、抓挠和按压）的音频信号。使用卷积神经网络对336个预处理样本（每种触摸类型48个样本）进行触摸分类训练。

Result: 训练后的卷积神经网络模型在区分具有明显声学主频率的不同触摸类型时表现出高分类准确率。

Conclusion: 该研究提出了一种利用机器人身上的麦克风通过声音检测触觉交互的创新方法，作为传统关节扭矩传感器或6轴力/扭矩传感器的替代方案。实验结果表明，该方法在区分具有明显声学主频率的不同触摸类型时具有高分类准确率。

Abstract: This study explores the use of microphones placed on a robot's body to detect tactile interactions via sounds produced when the hard shell of the robot is touched. This approach is proposed as an alternative to traditional methods using joint torque sensors or 6-axis force/torque sensors. Two Adafruit I2S MEMS microphones integrated with a Raspberry Pi 4 were positioned on the torso of a Pollen Robotics Reachy robot to capture audio signals from various touch types on the robot arms (tapping, knocking, rubbing, stroking, scratching, and pressing). A convolutional neural network was trained for touch classification on a dataset of 336 pre-processed samples (48 samples per touch type). The model shows high classification accuracy between touch types with distinct acoustic dominant frequencies.

</details>


### [328] [Traversability Aware Autonomous Navigation for Multi-Modal Mobility Morphobot (M4)](https://arxiv.org/abs/2512.11876)
*Hrigved Mahesh Suryawanshi*

Main category: cs.RO

TL;DR: 该论文提出了一种基于LiDAR和CNN的地形感知导航框架，通过实时定位和高程地图生成，优化路径规划以平衡效率与安全性。


<details>
  <summary>Details</summary>
Motivation: 非结构化环境中的自主导航需要机器人实时评估地形难度，并规划平衡效率与安全的路径。

Method: 研究采用FAST-LIO进行实时定位，利用LiDAR点云生成2.5D高程地图，并通过CNN模型估计可通行性分数，将其转化为导航成本。自定义A*规划器结合几何距离和能耗，生成优化路径。

Result: 实验表明，系统成功避开低可通行性区域，通过接受稍长路径显著降低地形成本。

Conclusion: 该研究为多模态机器人平台建立了智能地形感知导航的基础，通过平衡路径长度与地形质量，实现了高效且安全的导航。

Abstract: Autonomous navigation in unstructured environments requires robots to assess terrain difficulty in real-time and plan paths that balance efficiency with safety. This thesis presents a traversability-aware navigation framework for the M4 robot platform that uses learned terrain analysis to generate energy-efficient paths avoiding difficult terrain.Our approach uses FAST-LIO for real-time localization, generating 2.5D elevation maps from LiDAR point clouds. A CNN-based model processes these elevation maps to estimate traversability scores, which are converted into navigation costs for path planning. A custom A* planner incorporates these costs alongside geometric distance and energy consumption to find paths that trade modest distance increases for substantial terrain quality improvements. Before system development, a platform-agnostic study compared LiDAR-based and camera-based SLAM using OptiTrack ground truth. Point cloud comparison through ICP alignment and cloud-to-mesh distance analysis demonstrated that LiDAR-based mapping achieves centimeter-level precision essential for elevation mapping, while camera-based approaches exhibited significantly higher geometric error. These findings directly resulted in the selection of LiDAR as the primary sensor to generate elevation maps. The complete pipeline integrates FAST-LIO localization, GPU-accelerated elevation mapping, CNN-based traversability estimation, and Nav2 navigation with a custom traversability-aware planner. Experimental results demonstrate that the system successfully avoids low traversability regions and accepts a few longer paths to achieve a reduction in terrain cost. This work establishes a foundation for intelligent terrain-aware navigation applicable to multi-modal robotic platforms.

</details>


### [329] [Enabling Autonomous Navigation in a Snake Robot through Visual-Inertial Odometry and Closed-Loop Trajectory Tracking Control](https://arxiv.org/abs/2512.11886)
*Mohammed Irfan Ali*

Main category: cs.RO

TL;DR: 论文为蛇形机器人COBRA开发了一套自主导航系统，结合视觉-惯性SLAM和闭环控制，实现了动态运动中的精确航点跟踪。


<details>
  <summary>Details</summary>
Motivation: 蛇形机器人在极端地形中具有卓越的移动性，但其高度灵活的躯体在缺乏外部跟踪基础设施的环境中自主导航面临挑战。本文旨在解决这一问题，实现蛇形机器人的自主导航。

Method: 论文整合了机载视觉-惯性SLAM、降阶状态估计和闭环轨迹跟踪技术，结合深度摄像头和边缘计算实现动态运动中的实时定位，并通过运动捕捉系统验证了定位精度和独特的失败模式。

Result: 物理实验验证了系统的有效性，实现了精确的多航点跟踪，并揭示了蛇形机器人平台特有的漂移行为和失败模式。

Conclusion: 该论文开发了一个完整的自主导航系统，为模块化蛇形机器人COBRA实现了自主航点导航，并通过物理实验验证了系统的准确性，为未来蛇形机器人的自主导航奠定了基础。

Abstract: Snake robots offer exceptional mobility across extreme terrain inaccessible to conventional rovers, yet their highly articulated bodies present fundamental challenges for autonomous navigation in environments lacking external tracking infrastructure. This thesis develops a complete autonomy pipeline for COBRA, an 11 degree-of-freedom modular snake robot designed for planetary exploration. While the robot's biologically inspired serpentine gaits achieve impressive mobility, prior work has relied entirely on open-loop teleoperation. This approach integrates onboard visual-inertial SLAM, reduced-order state estimation, and closed-loop trajectory tracking to enable autonomous waypoint navigation. A depth camera paired with edge computing performs real-time localization during dynamic locomotion, validated against motion-capture ground truth to characterize drift behavior and failure modes unique to snake robot platforms. A reduced-order framework estimates Center-of-Mass pose, driving a closed-loop controller that modulates CPG gait parameters through distance-dependent yaw error blending. Physical experiments validate the complete system, demonstrating accurate multi-waypoint tracking and establishing foundations for autonomous snake robot navigation.

</details>


### [330] [VLSA: Vision-Language-Action Models with Plug-and-Play Safety Constraint Layer](https://arxiv.org/abs/2512.11891)
*Songqiao Hu,Zeyi Liu,Shuang Liu,Jun Cen,Zihan Meng,Xiao He*

Main category: cs.RO

TL;DR: AEGIS架构通过安全约束层提升VLA模型的安全性，实验显示其在障碍避免和任务成功率上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管VLA模型在多样化机器人操作任务中表现出色，但在非结构化环境中部署时，同时满足任务合规性和安全性（如避免碰撞）仍具挑战性。

Method: 提出了一种名为AEGIS的Vision-Language-Safe Action（VLSA）架构，包含一个基于控制屏障函数的即插即用安全约束（SC）层。

Result: AEGIS在障碍物避免率上提升了59.16%，任务执行成功率提高了17.25%，并在安全关键基准测试SafeLIBERO上优于现有基线方法。

Conclusion: AEGIS（VLSA架构）通过集成安全约束层显著提升了VLA模型在非结构化环境中的安全性，同时保持了指令执行的性能，为未来研究提供了可复现的资源。

Abstract: Vision-Language-Action (VLA) models have demonstrated remarkable capabilities in generalizing across diverse robotic manipulation tasks. However, deploying these models in unstructured environments remains challenging due to the critical need for simultaneous task compliance and safety assurance, particularly in preventing potential collisions during physical interactions. In this work, we introduce a Vision-Language-Safe Action (VLSA) architecture, named AEGIS, which contains a plug-and-play safety constraint (SC) layer formulated via control barrier functions. AEGIS integrates directly with existing VLA models to improve safety with theoretical guarantees, while maintaining their original instruction-following performance. To evaluate the efficacy of our architecture, we construct a comprehensive safety-critical benchmark SafeLIBERO, spanning distinct manipulation scenarios characterized by varying degrees of spatial complexity and obstacle intervention. Extensive experiments demonstrate the superiority of our method over state-of-the-art baselines. Notably, AEGIS achieves a 59.16% improvement in obstacle avoidance rate while substantially increasing the task execution success rate by 17.25%. To facilitate reproducibility and future research, we make our code, models, and the benchmark datasets publicly available at https://vlsa-aegis.github.io/.

</details>


### [331] [Data-driven Interpretable Hybrid Robot Dynamics](https://arxiv.org/abs/2512.11900)
*Christopher E. Mower,Rui Zong,Haitham Bou-Ammar*

Main category: cs.RO

TL;DR: 通过符号回归和SINDy方法，研究提出了一种可解释的混合机器人动力学模型，在仿真和真实数据中均表现出高准确性和泛化能力，优于传统神经网络。


<details>
  <summary>Details</summary>
Motivation: 研究数据驱动的可解释混合机器人动力学识别，其中分析性刚体动力学模型由学习的残差扭矩项补充。

Method: 使用符号回归和稀疏识别非线性动力学（SINDy）从关节空间数据中恢复残差的紧凑闭式表达式。

Result: 在7-DoF Franka臂的仿真中，这些模型准确恢复了惯性、科里奥利、重力和粘性效应，误差极小，且在准确性和泛化性上优于神经网络基线。在7-DoF WAM臂的真实数据中，符号回归残差的泛化能力显著优于SINDy和神经网络。

Conclusion: 可解释的残差动力学模型为扭矩预测提供了紧凑、准确且物理意义明确的替代方案，优于黑盒函数逼近器。

Abstract: We study data-driven identification of interpretable hybrid robot dynamics, where an analytical rigid-body dynamics model is complemented by a learned residual torque term. Using symbolic regression and sparse identification of nonlinear dynamics (SINDy), we recover compact closed-form expressions for this residual from joint-space data. In simulation on a 7-DoF Franka arm with known dynamics, these interpretable models accurately recover inertial, Coriolis, gravity, and viscous effects with very small relative error and outperform neural-network baselines in both accuracy and generalization. On real data from a 7-DoF WAM arm, symbolic-regression residuals generalize substantially better than SINDy and neural networks, which tend to overfit, and suggest candidate new closed-form formulations that extend the nominal dynamics model for this robot. Overall, the results indicate that interpretable residual dynamics models provide compact, accurate, and physically meaningful alternatives to black-box function approximators for torque prediction.

</details>


### [332] [Aion: Towards Hierarchical 4D Scene Graphs with Temporal Flow Dynamics](https://arxiv.org/abs/2512.11903)
*Iacopo Catalano,Eduardo Montijano,Javier Civera,Julio A. Placed,Jorge Pena-Queralta*

Main category: cs.RO

TL;DR: Aion框架将时间流动态嵌入到3D场景图中，结合语义和运动模式，提升了动态环境导航的可解释性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 现有的3D场景图扩展主要关注单个对象或代理，而动态地图通常与缺乏语义感知的网格离散化绑定，无法很好地扩展到大型环境。

Method: Aion采用基于图的稀疏MoD表示来捕捉任意时间间隔内的运动流，并将其附加到场景图的导航节点上。

Result: Aion框架结合了语义结构和时间演化的空间表示，改善了复杂动态环境中的规划和交互。

Conclusion: Aion框架通过将时间流动态直接嵌入到层次化的3D场景图中，显著提升了动态环境中导航和交互的可解释性和可扩展性。

Abstract: Autonomous navigation in dynamic environments requires spatial representations that capture both semantic structure and temporal evolution. 3D Scene Graphs (3DSGs) provide hierarchical multi-resolution abstractions that encode geometry and semantics, but existing extensions toward dynamics largely focus on individual objects or agents. In parallel, Maps of Dynamics (MoDs) model typical motion patterns and temporal regularities, yet are usually tied to grid-based discretizations that lack semantic awareness and do not scale well to large environments. In this paper we introduce Aion, a framework that embeds temporal flow dynamics directly within a hierarchical 3DSG, effectively incorporating the temporal dimension. Aion employs a graph-based sparse MoD representation to capture motion flows over arbitrary time intervals and attaches them to navigational nodes in the scene graph, yielding more interpretable and scalable predictions that improve planning and interaction in complex dynamic environments.

</details>


### [333] [Safe Learning for Contact-Rich Robot Tasks: A Survey from Classical Learning-Based Methods to Safe Foundation Models](https://arxiv.org/abs/2512.11908)
*Heng Zhang,Rui Dai,Gokhan Solak,Pokuang Zhou,Yu She,Arash Ajoudani*

Main category: cs.RO

TL;DR: 本文综述了安全学习型方法在机器人接触丰富任务中的应用，分类并回顾了关键技术，探讨了与基础模型的交互及未来方向。


<details>
  <summary>Details</summary>
Motivation: 接触丰富任务因不确定性、复杂动力学和高风险而具有挑战性，安全学习型控制方法虽展现出潜力，但确保安全仍是实际部署的关键瓶颈。

Method: 本文对现有方法进行了分类，主要分为安全探索和安全执行两大领域，并回顾了关键技术，如约束强化学习、风险敏感优化、不确定性感知建模、控制屏障函数和模型预测安全防护等。

Result: 本文总结了安全学习原则与新兴机器人基础模型（如VLM/VLA）的交互，探讨了其带来的新安全机遇与风险，并提供了相关资源和未来方向。

Conclusion: 本文概述了安全学习型方法在机器人接触丰富任务中的应用，并探讨了当前局限性和未来发展方向，旨在推动可靠、安全对齐且支持基础模型的机器人在复杂环境中的部署。

Abstract: Contact-rich tasks pose significant challenges for robotic systems due to inherent uncertainty, complex dynamics, and the high risk of damage during interaction. Recent advances in learning-based control have shown great potential in enabling robots to acquire and generalize complex manipulation skills in such environments, but ensuring safety, both during exploration and execution, remains a critical bottleneck for reliable real-world deployment. This survey provides a comprehensive overview of safe learning-based methods for robot contact-rich tasks. We categorize existing approaches into two main domains: safe exploration and safe execution. We review key techniques, including constrained reinforcement learning, risk-sensitive optimization, uncertainty-aware modeling, control barrier functions, and model predictive safety shields, and highlight how these methods incorporate prior knowledge, task structure, and online adaptation to balance safety and efficiency. A particular emphasis of this survey is on how these safe learning principles extend to and interact with emerging robotic foundation models, especially vision-language models (VLMs) and vision-language-action models (VLAs), which unify perception, language, and control for contact-rich manipulation. We discuss both the new safety opportunities enabled by VLM/VLA-based methods, such as language-level specification of constraints and multimodal grounding of safety signals, and the amplified risks and evaluation challenges they introduce. Finally, we outline current limitations and promising future directions toward deploying reliable, safety-aligned, and foundation-model-enabled robots in complex contact-rich environments. More details and materials are available at our \href{ https://github.com/jack-sherman01/Awesome-Learning4Safe-Contact-rich-tasks}{Project GitHub Repository}.

</details>


### [334] [Towards Accessible Physical AI: LoRA-Based Fine-Tuning of VLA Models for Real-World Robot Control](https://arxiv.org/abs/2512.11921)
*Abdullah Yahya Abdullah Omaisan,Ibrahim Sheikh Mohamed*

Main category: cs.RO

TL;DR: 本文提出了一种高效微调方法，使大型VLA模型能在低成本机器人平台上运行，并在实际任务中验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 解决大规模VLA模型在低成本机器人平台上部署的计算限制和新机器人实体适应效率的问题。

Method: 提出了一种资源高效的微调策略，结合低秩适应（LoRA）和量化技术，使数十亿参数的VLA模型能在8GB显存的消费级GPU上运行。

Result: 在SO101机械臂上实现了有效的按钮按压操控任务，同时保持了计算效率，并分析了训练数据量与实际性能的关系。

Conclusion: 通过适当的微调方法，VLA模型可以成功部署在低成本机器人平台上，使先进的操控能力不再局限于昂贵的研究机器人。

Abstract: Vision-Language-Action (VLA) models have demonstrated remarkable capabilities in robotic manipulation,enabling robots to execute natural language commands through end-to-end learning from visual observations.However, deploying large-scale VLA models on affordable robotic platforms remains challenging due to computational constraints and the need for efficient adaptation to new robot embodiments. This paper presents an efficient fine-tuning methodology and real-world deployment analysis for adapting VLA models to low-cost robotic manipulation systems.We propose a resource-efficient fine-tuning strategy using Low-Rank Adaptation (LoRA) and quantization techniques that enable multi-billion parameter VLA models ( 3.1B parameters) to run on consumer-grade GPUs with 8GB VRAM. Our methodology addresses the critical challenge of adapting pre-trained VLA models to new robot embodiments with limited demonstration data, focusing on the trade-offs between frozen and unfrozen vision encoders. Through real-world deployment on the SO101 robotic arm for a button-pressing manipulation task, we demonstrate that our approach achieves effective manipulation performance while maintaining computational efficiency. We provide detailed analysis of deployment challenges, failure modes, and the relationship between training data quantity and real-world performance,trained on 200 demonstration episodes. Our results show that with proper fine-tuning methodology, VLA models can be successfully deployed on affordable robotic platforms,making advanced manipulation capabilities accessible beyond expensive research robots.

</details>


### [335] [A Review of Learning-Based Motion Planning: Toward a Data-Driven Optimal Control Approach](https://arxiv.org/abs/2512.11944)
*Jia Hu,Yang Chang,Haoran Wang*

Main category: cs.RO

TL;DR: 论文综述了自动驾驶运动规划的演变，提出数据驱动最优控制框架，旨在解决传统方法与学习系统的矛盾，实现安全、可解释的类人自主驾驶。


<details>
  <summary>Details</summary>
Motivation: 解决高层次自动驾驶运动规划中管道方法的脆弱性与学习系统的‘黑盒’特性之间的根本性权衡问题。

Method: 通过全面综述基于学习的运动规划方法，提出了一种结合经典控制可验证结构与机器学习自适应能力的数据驱动最优控制范式。

Result: 该框架有望实现‘以人为中心’的定制化、‘平台自适应’的动态调整以及通过自调优实现的‘系统自优化’。

Conclusion: 论文提出了一种数据驱动的最优控制范式，作为统一框架，旨在开发既安全又可解释且具备类人自主能力的智能交通系统。

Abstract: Motion planning for high-level autonomous driving is constrained by a fundamental trade-off between the transparent, yet brittle, nature of pipeline methods and the adaptive, yet opaque, "black-box" characteristics of modern learning-based systems. This paper critically synthesizes the evolution of the field -- from pipeline methods through imitation learning, reinforcement learning, and generative AI -- to demonstrate how this persistent dilemma has hindered the development of truly trustworthy systems. To resolve this impasse, we conduct a comprehensive review of learning-based motion planning methods. Based on this review, we outline a data-driven optimal control paradigm as a unifying framework that synergistically integrates the verifiable structure of classical control with the adaptive capacity of machine learning, leveraging real-world data to continuously refine key components such as system dynamics, cost functions, and safety constraints. We explore this framework's potential to enable three critical next-generation capabilities: "Human-Centric" customization, "Platform-Adaptive" dynamics adaptation, and "System Self-Optimization" via self-tuning. We conclude by proposing future research directions based on this paradigm, aimed at developing intelligent transportation systems that are simultaneously safe, interpretable, and capable of human-like autonomy.

</details>


### [336] [Modified Hybrid A* Collision-Free Path-Planning for Automated Reverse Parking](https://arxiv.org/abs/2512.12021)
*Xincheng Cao,Haochong Chen,Bilin Aksun-Guvenc,Levent Guvenc*

Main category: cs.RO

TL;DR: 改进Hybrid-A*算法结合静态避碰功能，成功解决狭小空间停车难题。


<details>
  <summary>Details</summary>
Motivation: 解决在狭小空间内停车时由于可行路径稀缺且需避免碰撞带来的挑战。

Method: 通过结合标准Hybrid A*算法的可行性保证和静态障碍物避碰功能，使用运动学单轨模型描述车辆低速运动，并生成可行运动基元分支。

Result: 仿真研究表明，该算法能持续提供运动学可行且无碰撞的轨迹。

Conclusion: 该论文提出的改进Hybrid-A*路径规划算法能够有效生成在狭小空间内既运动学可行又无碰撞的轨迹。

Abstract: Parking a vehicle in tight spaces is a challenging task to perform due to the scarcity of feasible paths that are also collision-free. This paper presents a strategy to tackle this kind of maneuver with a modified Hybrid-A* path-planning algorithm that combines the feasibility guarantee inherent in the standard Hybrid A* algorithm with the addition of static obstacle collision avoidance. A kinematic single-track model is derived to describe the low-speed motion of the vehicle, which is subsequently used as the motion model in the Hybrid A* path-planning algorithm to generate feasible motion primitive branches. The model states are also used to reconstruct the vehicle centerline, which, in conjunction with an inflated binary occupancy map, facilitates static obstacle collision avoidance functions. Simulation study and animation are set up to test the efficacy of the approach, and the proposed algorithm proves to consistently provide kinematically feasible trajectories that are also collision-free.

</details>


### [337] [A Stochastic Approach to Terrain Maps for Safe Lunar Landing](https://arxiv.org/abs/2512.12058)
*Anja Sheppard,Chris Reale,Katherine A. Skinner*

Main category: cs.RO

TL;DR: 利用LRO数据和两阶段高斯过程模型，生成更准确的月球地形不确定性估计，提升着陆安全性。


<details>
  <summary>Details</summary>
Motivation: 月球南极地区地形复杂且阴影较多，传统视觉方法不可靠，而LiDAR技术在该环境下尚未充分验证。利用LRO数据生成先验地图可提高着陆安全性。

Method: 提出了一种两阶段高斯过程模型，首先通过次级高斯过程学习DEM置信度数据的空间变化噪声特性，然后将这些信息用于主高斯过程建模月球地形。此外，使用了随机变分高斯过程以实现可扩展的训练。

Result: 该方法能够更准确地建模异方差传感器噪声对地形图的影响，生成更具信息量的地形不确定性估计。

Conclusion: 该方法通过两阶段高斯过程模型，结合LRO DEM置信度数据，生成了更准确的月球地形不确定性估计，为安全着陆和危险检测提供了重要支持。

Abstract: Safely landing on the lunar surface is a challenging task, especially in the heavily-shadowed South Pole region where traditional vision-based hazard detection methods are not reliable. The potential existence of valuable resources at the lunar South Pole has made landing in that region a high priority for many space agencies and commercial companies. However, relying on a LiDAR for hazard detection during descent is risky, as this technology is fairly untested in the lunar environment.
  There exists a rich log of lunar surface data from the Lunar Reconnaissance Orbiter (LRO), which could be used to create informative prior maps of the surface before descent. In this work, we propose a method for generating stochastic elevation maps from LRO data using Gaussian processes (GPs), which are a powerful Bayesian framework for non-parametric modeling that produce accompanying uncertainty estimates. In high-risk environments such as autonomous spaceflight, interpretable estimates of terrain uncertainty are critical. However, no previous approaches to stochastic elevation mapping have taken LRO Digital Elevation Model (DEM) confidence maps into account, despite this data containing key information about the quality of the DEM in different areas.
  To address this gap, we introduce a two-stage GP model in which a secondary GP learns spatially varying noise characteristics from DEM confidence data. This heteroscedastic information is then used to inform the noise parameters for the primary GP, which models the lunar terrain. Additionally, we use stochastic variational GPs to enable scalable training. By leveraging GPs, we are able to more accurately model the impact of heteroscedastic sensor noise on the resulting elevation map. As a result, our method produces more informative terrain uncertainty, which can be used for downstream tasks such as hazard detection and safe landing site selection.

</details>


### [338] [B-ActiveSEAL: Scalable Uncertainty-Aware Active Exploration with Tightly Coupled Localization-Mapping](https://arxiv.org/abs/2512.12194)
*Min-Won Seo,Aamodh Suresh,Carlos Nieto-Granda,Solmaz S. Kia*

Main category: cs.RO

TL;DR: B-ActiveSEAL 是一种信息论驱动的主动探索框架，通过行为熵自适应平衡探索与利用，在复杂环境中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决大规模环境中长期操作时定位与地图构建的耦合不确定性带来的计算难题。

Method: 提出了 B-ActiveSEAL，一种基于信息论的可扩展主动探索框架，通过行为熵（BE）作为信息度量，自适应地平衡地图不确定性（探索）和定位不确定性（利用）。

Result: 实验证明 B-ActiveSEAL 在多样复杂环境中实现了探索与利用的平衡，并表现出适应性强的探索行为。

Conclusion: B-ActiveSEAL 框架通过理论分析和实验验证，展示了其在复杂环境中平衡探索与利用的优越性，并显著优于现有基线方法。

Abstract: Active robot exploration requires decision-making processes that integrate localization and mapping under tightly coupled uncertainty. However, managing these interdependent uncertainties over long-term operations in large-scale environments rapidly becomes computationally intractable. To address this challenge, we propose B-ActiveSEAL, a scalable information-theoretic active exploration framework that explicitly accounts for coupled uncertainties-from perception through mapping-into the decision-making process. Our framework (i) adaptively balances map uncertainty (exploration) and localization uncertainty (exploitation), (ii) accommodates a broad class of generalized entropy measures, enabling flexible and uncertainty-aware active exploration, and (iii) establishes Behavioral entropy (BE) as an effective information measure for active exploration by enabling intuitive and adaptive decision-making under coupled uncertainties. We establish a theoretical foundation for propagating coupled uncertainties and integrating them into general entropy formulations, enabling uncertainty-aware active exploration under tightly coupled localization-mapping. The effectiveness of the proposed approach is validated through rigorous theoretical analysis and extensive experiments on open-source maps and ROS-Unity simulations across diverse and complex environments. The results demonstrate that B-ActiveSEAL achieves a well-balanced exploration-exploitation trade-off and produces diverse, adaptive exploration behaviors across environments, highlighting clear advantages over representative baselines.

</details>


### [339] [Navigation Around Unknown Space Objects Using Visible-Thermal Image Fusion](https://arxiv.org/abs/2512.12203)
*Eric J. Elias,Michael Esswein,Jonathan P. How,David W. Miller*

Main category: cs.RO

TL;DR: 通过融合可见光和热红外图像，提升了未知空间物体导航的精度，尤其在复杂光照条件下表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决在轨道操作中，传统相机在阴影期性能下降，而热红外相机分辨率不足的问题。

Method: 通过像素级融合方法创建可见光/热红外复合图像，并利用单目SLAM算法比较不同光照和轨迹下的导航误差。

Result: 融合图像在各种光照和轨迹下均表现出显著的导航性能提升。

Conclusion: 融合可见光和热红外图像的导航方法显著优于单独使用可见光或热红外图像的方法。

Abstract: As the popularity of on-orbit operations grows, so does the need for precise navigation around unknown resident space objects (RSOs) such as other spacecraft, orbital debris, and asteroids. The use of Simultaneous Localization and Mapping (SLAM) algorithms is often studied as a method to map out the surface of an RSO and find the inspector's relative pose using a lidar or conventional camera. However, conventional cameras struggle during eclipse or shadowed periods, and lidar, though robust to lighting conditions, tends to be heavier, bulkier, and more power-intensive. Thermal-infrared cameras can track the target RSO throughout difficult illumination conditions without these limitations. While useful, thermal-infrared imagery lacks the resolution and feature-richness of visible cameras. In this work, images of a target satellite in low Earth orbit are photo-realistically simulated in both visible and thermal-infrared bands. Pixel-level fusion methods are used to create visible/thermal-infrared composites that leverage the best aspects of each camera. Navigation errors from a monocular SLAM algorithm are compared between visible, thermal-infrared, and fused imagery in various lighting and trajectories. Fused imagery yields substantially improved navigation performance over visible-only and thermal-only methods.

</details>


### [340] [Measuring What Matters: Scenario-Driven Evaluation for Trajectory Predictors in Autonomous Driving](https://arxiv.org/abs/2512.12211)
*Longchao Da,David Isele,Hua Wei,Manish Saroya*

Main category: cs.RO

TL;DR: 论文提出了一种新的评估流程，综合考虑预测器的准确性和多样性，动态评估其在自动驾驶中的实际贡献，优于传统误差指标。


<details>
  <summary>Details</summary>
Motivation: 现有的轨迹预测评估方法主要依赖基于误差的指标（如ADE、FDE），这些指标虽然能反映预测的准确性，但忽略了预测器对自动驾驶车辆（SDV）实际决策的影响，尤其是在复杂的交互场景中。

Method: 论文提出了一种全面的评估流程，通过两个维度（准确性和多样性）来评估预测器的性能，并根据驾驶场景的关键性动态结合这两个维度，生成最终评分。

Result: 在真实世界数据集上的闭环基准测试表明，该评估流程比传统指标更合理地评估预测器性能，并能更好地反映预测器评估与自动驾驶车辆驾驶性能之间的相关性。

Conclusion: 该论文提出了一种新的评估流程，通过综合考虑预测器的准确性和多样性，动态结合这两个维度来评估预测器的性能，从而更合理地反映预测器对自动驾驶车辆驾驶性能的实际影响。

Abstract: Being able to anticipate the motion of surrounding agents is essential for the safe operation of autonomous driving systems in dynamic situations. While various methods have been proposed for trajectory prediction, the current evaluation practices still rely on error-based metrics (e.g., ADE, FDE), which reveal the accuracy from a post-hoc view but ignore the actual effect the predictor brings to the self-driving vehicles (SDVs), especially in complex interactive scenarios: a high-quality predictor not only chases accuracy, but should also captures all possible directions a neighbor agent might move, to support the SDVs' cautious decision-making. Given that the existing metrics hardly account for this standard, in our work, we propose a comprehensive pipeline that adaptively evaluates the predictor's performance by two dimensions: accuracy and diversity. Based on the criticality of the driving scenario, these two dimensions are dynamically combined and result in a final score for the predictor's performance. Extensive experiments on a closed-loop benchmark using real-world datasets show that our pipeline yields a more reasonable evaluation than traditional metrics by better reflecting the correlation of the predictors' evaluation with the autonomous vehicles' driving performance. This evaluation pipeline shows a robust way to select a predictor that potentially contributes most to the SDV's driving performance.

</details>


### [341] [Semantic Zone based 3D Map Management for Mobile Robot](https://arxiv.org/abs/2512.12228)
*Huichang Yun,Seungho Yoo*

Main category: cs.RO

TL;DR: 提出语义区域3D地图管理方法，动态加载任务相关区域，显著减少内存使用，保持导航地图可用性。


<details>
  <summary>Details</summary>
Motivation: 大规模室内环境中的移动机器人需要精确的3D空间表示，但3D地图消耗大量内存，难以在有限的计算资源内维护完整地图数据。现有的SLAM框架通常依赖几何距离或时间指标进行内存管理，在空间分隔环境中数据检索效率低下。

Method: 提出了一种基于语义区域的3D地图管理方法，将环境划分为有意义的空间单元（如大厅、走廊），并将这些区域作为内存管理的主要单位。通过动态加载任务相关区域到工作内存（WM）并卸载非活动区域到长期内存（LTM），系统严格遵循用户定义的内存阈值。

Result: 与标准方法相比，该方法显著减少了不必要的签名加载/卸载周期和累积内存使用。

Conclusion: 语义区域为基础的3D地图管理方法在RTAB-Map框架中实现了稳定、可预测的内存使用，同时保持了导航所需的地图可用性。

Abstract: Mobile robots in large-scale indoor environments, such as hospitals and logistics centers, require accurate 3D spatial representations. However, 3D maps consume substantial memory, making it difficult to maintain complete map data within limited computational resources. Existing SLAM frameworks typically rely on geometric distance or temporal metrics for memory management, often resulting in inefficient data retrieval in spatially compartmentalized environments. To address this, we propose a semantic zone-based 3D map management method that shifts the paradigm from geometry-centric to semantics-centric control. Our approach partitions the environment into meaningful spatial units (e.g., lobbies, hallways) and designates these zones as the primary unit for memory management. By dynamically loading only task-relevant zones into Working Memory (WM) and offloading inactive zones to Long-Term Memory (LTM), the system strictly enforces user-defined memory thresholds. Implemented within the RTAB-Map framework, our method demonstrates substantial reductions in unnecessary signature load/unload cycles and cumulative memory utilization compared to standard approaches. The results confirm that semantic zone-based management ensures stable, predictable memory usage while preserving map availability for navigation. Code is available at: https://github.com/huichangs/rtabmap/tree/segment

</details>


### [342] [Learning to Get Up Across Morphologies: Zero-Shot Recovery with a Unified Humanoid Policy](https://arxiv.org/abs/2512.12230)
*Jonathan Spraggett*

Main category: cs.RO

TL;DR: 提出了一种适用于多种人形机器人的统一跌倒恢复策略，无需针对每种形态单独训练，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法需要为每种机器人形态训练单独策略的问题，提高在动态环境中的适应性。

Method: 使用CrossQ训练的统一DRL策略，能够在七种不同形态的人形机器人上实现零样本转移。

Result: 统一策略在未见过的形态上实现了高达86%的零样本转移成功率，甚至在某些情况下超越了专用策略。

Conclusion: 该研究展示了形态无关控制在跌倒恢复中的实用性，为通用人形机器人控制奠定了基础。

Abstract: Fall recovery is a critical skill for humanoid robots in dynamic environments such as RoboCup, where prolonged downtime often decides the match. Recent techniques using deep reinforcement learning (DRL) have produced robust get-up behaviors, yet existing methods require training of separate policies for each robot morphology. This paper presents a single DRL policy capable of recovering from falls across seven humanoid robots with diverse heights (0.48 - 0.81 m), weights (2.8 - 7.9 kg), and dynamics. Trained with CrossQ, the unified policy transfers zero-shot up to 86 +/- 7% (95% CI [81, 89]) on unseen morphologies, eliminating the need for robot-specific training. Comprehensive leave-one-out experiments, morph scaling analysis, and diversity ablations show that targeted morphological coverage improves zero-shot generalization. In some cases, the shared policy even surpasses the specialist baselines. These findings illustrate the practicality of morphology-agnostic control for fall recovery, laying the foundation for generalist humanoid control. The software is open-source and available at: https://github.com/utra-robosoccer/unified-humanoid-getup

</details>


### [343] [Robust Underwater Localization of Buoyancy Driven microFloats Using Acoustic Time-of-Flight Measurements](https://arxiv.org/abs/2512.12233)
*Murad Mehrab Abrar,Trevor W. Harrison*

Main category: cs.RO

TL;DR: 该论文提出了一种低成本、鲁棒性强的水下定位方法，通过双向声学ToF和滤波技术显著提高定位精度，适用于沿海水域的微型浮标。


<details>
  <summary>Details</summary>
Motivation: 低成本自主平台在高频位置更新需求下的水下精确定位仍具挑战性，因此需要一种鲁棒性强、成本低的定位方案。

Method: 论文采用双向声学ToF定位框架，结合非线性三边测量和基于几何成本与CRLB的滤波技术，有效去除多径效应和其他声学误差带来的异常值。

Result: 在实地测试中，定位管道的相对GPS位置中值误差低于4米，滤波技术使平均误差从139.29米降至12.07米，轨迹与GPS路径的对齐性也得到改善。

Conclusion: 该论文提出了一种低成本、高鲁棒性的水下定位方法，通过双向声学飞行时间（ToF）定位框架和几何成本与Cramer-Rao下界（CRLB）的滤波技术，显著提高了定位精度和频率，适用于沿海水域的浮力驱动微型浮标。

Abstract: Accurate underwater localization remains a challenge for inexpensive autonomous platforms that require highfrequency position updates. In this paper, we present a robust, low-cost localization pipeline for buoyancy-driven microFloats operating in coastal waters. We build upon previous work by introducing a bidirectional acoustic Time-of-Flight (ToF) localization framework, which incorporates both float-to-buoy and buoy-to-float transmissions, thereby increasing the number of usable measurements. The method integrates nonlinear trilateration with a filtering of computed position estimates based on geometric cost and Cramer-Rao Lower Bounds (CRLB). This approach removes outliers caused by multipath effects and other acoustic errors from the ToF estimation and improves localization robustness without relying on heavy smoothing. We validate the framework in two field deployments in Puget Sound, Washington, USA. The localization pipeline achieves median positioning errors below 4 m relative to GPS positions. The filtering technique shows a reduction in mean error from 139.29 m to 12.07 m, and improved alignment of trajectories with GPS paths. Additionally, we demonstrate a Time-Difference-of-Arrival (TDoA) localization for unrecovered floats that were transmitting during the experiment. Range-based acoustic localization techniques are widely used and generally agnostic to hardware-this work aims to maximize their utility by improving positioning frequency and robustness through careful algorithmic design.

</details>


### [344] [CAR-CHASE: Car-Like Robot Conflict-Aware Heuristic Adaptive Search Enhancement](https://arxiv.org/abs/2512.12243)
*HT To,S Nguyen,NH Pham*

Main category: cs.RO

TL;DR: CAR-CHASE通过冲突感知启发式缓存和自适应混合启发式，显著提升CL-CBS的计算效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 传统启发式缓存在CBS中因忽略约束上下文而失效，导致计算效率低下。

Method: 结合冲突感知启发式缓存和自适应混合启发式，通过冲突指纹、相关性过滤器和自适应切换策略实现。

Result: 在480个基准测试中，平均速度提升2.46倍，成功率提高6.9个百分点，总运行时间减少70.1%。

Conclusion: CAR-CHASE显著提升了CL-CBS的计算效率，保持了解决方案的最优性，并在复杂场景中展现出可扩展的性能优势。

Abstract: Multi-Agent Path Finding (MAPF) for car-like robots, addressed by algorithms such as Conflict-Based Search with Continuous Time (CL-CBS), faces significant computational challenges due to expensive kinematic heuristic calculations. Traditional heuristic caching assumes that the heuristic function depends only on the state, which is incorrect in CBS where constraints from conflict resolution make the search space context-dependent. We propose \textbf{CAR-CHASE} (Car-Like Robot Conflict-Aware Heuristic Adaptive Search Enhancement), a novel approach that combines \textbf{conflict-aware heuristic caching} -- which caches heuristic values based on both state and relevant constraint context -- with an \textbf{adaptive hybrid heuristic} that intelligently switches between fast approximate and exact computations. Our key innovations are (1) a compact \emph{conflict fingerprint} that efficiently encodes which constraints affect a state's heuristic, (2) a relevance filter using spatial, temporal, and geometric criteria, and (3) an adaptive switching strategy with theoretical quality bounds. Experimental evaluation on 480 benchmark instances with varying agent counts (10 to 30) and obstacle densities (0\% and 50\%) demonstrates a geometric mean speedup of 2.46$\times$ over the baseline CL-CBS implementation while maintaining solution optimality. The optimizations improve success rate from 77.9\% to 84.8\% (+6.9 percentage points), reduce total runtime by 70.1\%, and enable solving 33 additional instances that previously timed out. Performance gains scale with problem complexity, reaching up to 4.06$\times$ speedup for challenging 30-agent obstacle scenarios. Our techniques are general and applicable to other CBS variants.

</details>


### [345] [Programmable Deformation Design of Porous Soft Actuator through Volumetric-Pattern-Induced Anisotropy](https://arxiv.org/abs/2512.12320)
*Canqi Meng,Weibang Bai*

Main category: cs.RO

TL;DR: 提出一种通过切割多孔泡沫体图案实现可编程变形的软执行器设计方法，实验验证其多功能性和高效性。


<details>
  <summary>Details</summary>
Motivation: 传统软气动执行器结构支撑不足且需针对多功能性进行昂贵的几何重新设计，多孔材料虽能提供结构稳定性，但通过定制多孔体本身实现可编程变形的方法尚未充分探索。

Method: 通过在多孔泡沫体上切割特定图案，实现局部结构各向异性，从而在全局真空输入下引导材料变形。采用有限元分析（FEA）建立计算模型研究切割图案方法的机制。

Result: 实验表明，通过优化图案阵列数量N，执行器可实现弯曲80°（N=2）、倾斜18°（N=1）和扭转115°（N=8）。方法的通用性通过图案可转移性、可扩展性和无模具快速原型设计复杂设计得到验证。

Conclusion: 本文提出了一种高效、可扩展的设计多功能软多孔机器人的新范式。

Abstract: Conventional soft pneumatic actuators, typically based on hollow elastomeric chambers, often suffer from small structural support and require costly geometry-specific redesigns for multimodal functionality. Porous materials such as foam, filled into chambers, can provide structural stability for the actuators. However, methods to achieve programmable deformation by tailoring the porous body itself remain underexplored. In this paper, a novel design method is presented to realize soft porous actuators with programmable deformation by incising specific patterns into the porous foam body. This approach introduces localized structural anisotropy of the foam guiding the material's deformation under a global vacuum input. Furthermore, three fundamental patterns on a cylindrical foam substrate are discussed: transverse for bending, longitudinal for tilting, and diagonal for twisting. A computational model is built with Finite Element Analysis (FEA), to investigate the mechanism of the incision-patterning method. Experiments demonstrate that with a potential optimal design of the pattern array number N, actuators can achieve bending up to $80^{\circ}$ (N=2), tilting of $18^{\circ}$ (N=1), and twisting of $115^{\circ}$ (N=8). The versatility of our approach is demonstrated via pattern transferability, scalability, and mold-less rapid prototyping of complex designs. As a comprehensive application, we translate the human hand crease map into a functional incision pattern, creating a bio-inspired soft robot hand capable of human-like adaptive grasping. Our work provides a new, efficient, and scalable paradigm for the design of multi-functional soft porous robots.

</details>


### [346] [INDOOR-LiDAR: Bridging Simulation and Reality for Robot-Centric 360 degree Indoor LiDAR Perception -- A Robot-Centric Hybrid Dataset](https://arxiv.org/abs/2512.12377)
*Haichuan Li,Changda Tian,Panos Trahanias,Tomi Westerlund*

Main category: cs.RO

TL;DR: INDOOR-LIDAR是一个混合室内3D LiDAR点云数据集，结合模拟与真实扫描，解决了现有数据集的局限性，支持多种机器人感知应用。


<details>
  <summary>Details</summary>
Motivation: 解决现有室内LiDAR数据集规模有限、标注格式不一致及数据收集中人为变异性等问题。

Method: 整合模拟环境与自主地面机器人采集的真实世界扫描，提供密集点云数据和KITTI风格标注。

Result: INDOOR-LIDAR支持3D物体检测、BEV感知、SLAM等多种应用，并弥合了合成数据与真实数据之间的差距。

Conclusion: INDOOR-LIDAR通过结合模拟环境和真实世界扫描，为复杂室内环境中的机器人感知研究提供了一个可扩展、真实且可复现的基准。

Abstract: We present INDOOR-LIDAR, a comprehensive hybrid dataset of indoor 3D LiDAR point clouds designed to advance research in robot perception. Existing indoor LiDAR datasets often suffer from limited scale, inconsistent annotation formats, and human-induced variability during data collection. INDOOR-LIDAR addresses these limitations by integrating simulated environments with real-world scans acquired using autonomous ground robots, providing consistent coverage and realistic sensor behavior under controlled variations. Each sample consists of dense point cloud data enriched with intensity measurements and KITTI-style annotations. The annotation schema encompasses common indoor object categories within various scenes. The simulated subset enables flexible configuration of layouts, point densities, and occlusions, while the real-world subset captures authentic sensor noise, clutter, and domain-specific artifacts characteristic of real indoor settings. INDOOR-LIDAR supports a wide range of applications including 3D object detection, bird's-eye-view (BEV) perception, SLAM, semantic scene understanding, and domain adaptation between simulated and real indoor domains. By bridging the gap between synthetic and real-world data, INDOOR-LIDAR establishes a scalable, realistic, and reproducible benchmark for advancing robotic perception in complex indoor environments.

</details>


### [347] [Unifying Quadrotor Motion Planning and Control by Chaining Different Fidelity Models](https://arxiv.org/abs/2512.12427)
*Rudolf Reiter,Chao Qin,Leonard Bauersfeld,Davide Scaramuzza*

Main category: cs.RO

TL;DR: Unique框架通过统一高/低精度模型的MPC优化，显著提升四旋翼飞行器的闭环性能。


<details>
  <summary>Details</summary>
Motivation: 解决四旋翼飞行器任务中即时反应性和长时规划的矛盾，高精度模型计算慢，低精度模型闭环性能差。

Method: 提出了一种统一的MPC框架，结合短时高精度模型和长时低精度模型，通过成本对齐、可行性约束和过渡约束实现优化。采用3D渐进平滑调度和并行随机初始化MPC求解器避免局部极小值。

Result: 在仿真和实际飞行中，Unique相比标准MPC和分层规划器-跟踪器基线，闭环位置或速度跟踪性能提升高达75%。

Conclusion: Unique框架通过统一不同精度模型的MPC优化，显著提升了四旋翼飞行器的闭环性能，在相同计算预算下，位置或速度跟踪性能提升了高达75%。

Abstract: Many aerial tasks involving quadrotors demand both instant reactivity and long-horizon planning. High-fidelity models enable accurate control but are too slow for long horizons; low-fidelity planners scale but degrade closed-loop performance. We present Unique, a unified MPC that cascades models of different fidelity within a single optimization: a short-horizon, high-fidelity model for accurate control, and a long-horizon, low-fidelity model for planning. We align costs across horizons, derive feasibility-preserving thrust and body-rate constraints for the point-mass model, and introduce transition constraints that match the different states, thrust-induced acceleration, and jerk-body-rate relations. To prevent local minima emerging from nonsmooth clutter, we propose a 3D progressive smoothing schedule that morphs norm-based obstacles along the horizon. In addition, we deploy parallel randomly initialized MPC solvers to discover lower-cost local minima on the long, low-fidelity horizon. In simulation and real flights, under equal computational budgets, Unique improves closed-loop position or velocity tracking by up to 75% compared with standard MPC and hierarchical planner-tracker baselines. Ablations and Pareto analyses confirm robust gains across horizon variations, constraint approximations, and smoothing schedules.

</details>


### [348] [Sim2Real Reinforcement Learning for Soccer skills](https://arxiv.org/abs/2512.12437)
*Jonathan Spraggett*

Main category: cs.RO

TL;DR: 提出了一种结合课程训练和AMP技术的强化学习方法，显著提升了人形机器人控制任务的性能，但模拟到现实的策略转移仍未成功。


<details>
  <summary>Details</summary>
Motivation: 传统的强化学习方法在适应现实世界环境、复杂性和自然运动方面存在局限，需要一种更有效的方法来克服这些挑战。

Method: 通过课程训练和对抗运动先验（AMP）技术，提出了一种更高效和有效的方法来训练人形机器人的控制相关任务。

Result: 开发的强化学习策略在踢球、行走和跳跃等任务中表现出更高的动态性和适应性，且优于先前的方法。

Conclusion: 尽管所提出的方法在模拟环境中表现出色，但在将学习到的策略转移到现实世界时未能成功，突显了当前强化学习方法在完全适应现实场景方面的局限性。

Abstract: This thesis work presents a more efficient and effective approach to training control-related tasks for humanoid robots using Reinforcement Learning (RL). The traditional RL methods are limited in adapting to real-world environments, complexity, and natural motions, but the proposed approach overcomes these limitations by using curriculum training and Adversarial Motion Priors (AMP) technique. The results show that the developed RL policies for kicking, walking, and jumping are more dynamic, and adaptive, and outperformed previous methods. However, the transfer of the learned policy from simulation to the real world was unsuccessful, highlighting the limitations of current RL methods in fully adapting to real-world scenarios.

</details>


### [349] [Autonomously Unweaving Multiple Cables Using Visual Feedback](https://arxiv.org/abs/2512.12468)
*Tina Tian,Xinyu Wang,Andrew L. Orekhov,Fujun Ruan,Lu Li,Oliver Kroemer,Howie Choset*

Main category: cs.RO

TL;DR: 本文提出一种基于视觉反馈和图基表示的多电缆解缠方法，通过状态转移模型优化动作选择，实验成功率达84%。


<details>
  <summary>Details</summary>
Motivation: 现有研究集中于单电缆解结，而多电缆解缠（分离交织电缆）是电缆管理中的另一重要子任务，需自动化解决。

Method: 方法包括基于图的电缆状态表示、状态转移模型预测未来状态和动作选择，以及高低级动作优化。

Result: 实验表明，该方法在解缠电缆和鞋带时平均成功率为84%。

Conclusion: 本文提出的方法通过视觉反馈和图基电缆状态表示，成功实现了多电缆解缠任务，平均成功率达84%。

Abstract: Many cable management tasks involve separating out the different cables and removing tangles. Automating this task is challenging because cables are deformable and can have combinations of knots and multiple interwoven segments. Prior works have focused on untying knots in one cable, which is one subtask of cable management. However, in this paper, we focus on a different subtask called multi-cable unweaving, which refers to removing the intersections among multiple interwoven cables to separate them and facilitate further manipulation. We propose a method that utilizes visual feedback to unweave a bundle of loosely entangled cables. We formulate cable unweaving as a pick-and-place problem, where the grasp position is selected from discrete nodes in a graph-based cable state representation. Our cable state representation encodes both topological and geometric information about the cables from the visual image. To predict future cable states and identify valid actions, we present a novel state transition model that takes into account the straightening and bending of cables during manipulation. Using this state transition model, we select between two high-level action primitives and calculate predicted immediate costs to optimize the lower-level actions. We experimentally demonstrate that iterating the above perception-planning-action process enables unweaving electric cables and shoelaces with an 84% success rate on average.

</details>


### [350] [Optimized Conflict Management for Urban Air Mobility Using Swarm UAV Networks](https://arxiv.org/abs/2512.12632)
*Rishit Agnihotri,Sandeep Kumar Sharma*

Main category: cs.RO

TL;DR: 本文提出了一种基于边缘AI的分散式群体架构，通过轻量级神经网络优化实时决策，显著提升冲突解决效率。


<details>
  <summary>Details</summary>
Motivation: 城市空中交通（UAM）在高密度城市走廊中面临前所未有的交通协调挑战，尤其是无人机密度增加时。

Method: 使用控制算法和轻量级神经网络，通过边缘节点实现分布式冲突检测与解决。

Result: 冲突解决时间显著缩短至传统集中控制模型的3.8倍，且准确性提高。

Conclusion: 所提出的架构在未来城市空中交通系统中具有高度可扩展性、高效性和安全性。

Abstract: Urban Air Mobility (UAM) poses unprecedented traffic coordination challenges, especially with increasing UAV densities in dense urban corridors. This paper introduces a mathematical model using a control algorithm to optimize an Edge AI-driven decentralized swarm architecture for intelligent conflict resolution, enabling real-time decision-making with low latency. Using lightweight neural networks, the system leverages edge nodes to perform distributed conflict detection and resolution. A simulation platform was developed to evaluate the scheme under various UAV densities. Results indicate that the conflict resolution time is dramatically minimized up to 3.8 times faster, and accuracy is enhanced compared to traditional centralized control models. The proposed architecture is highly promising for scalable, efficient, and safe aerial traffic management in future UAM systems.

</details>


### [351] [Bayesian Optimization Parameter Tuning Framework for a Lyapunov Based Path Following Controller](https://arxiv.org/abs/2512.12649)
*Zhewen Zheng,Wenjing Cao,Hongkang Yu,Mo Chen,Takashi Suzuki*

Main category: cs.RO

TL;DR: 本文提出了一种贝叶斯优化框架，用于高效调参非线性路径跟踪控制器，实验证明其在真实机器人平台上具有实用性和数据效率。


<details>
  <summary>Details</summary>
Motivation: 在硬件实验中，参数调优受限于有限的评估预算。路径跟踪控制器中的多个增益通过耦合的非线性项影响动力学，这种相互依赖使得手动调参效率低下且难以在有限的试验次数内获得满意性能。

Method: 本文提出了一种贝叶斯优化（BO）框架，将闭环系统视为黑盒，并使用高斯过程代理选择控制器增益。

Result: 结果表明，BO在32次试验（包括15次预热初始评估）内提高了控制器性能，能够在真实条件下高效定位参数空间的高性能区域。

Conclusion: 本文的结论是贝叶斯优化（BO）为真实机器人平台上的非线性路径跟踪控制器提供了一种实用、可靠且数据高效的调参方法。

Abstract: Parameter tuning in real-world experiments is constrained by the limited evaluation budget available on hardware. The path-following controller studied in this paper reflects a typical situation in nonlinear geometric controller, where multiple gains influence the dynamics through coupled nonlinear terms. Such interdependence makes manual tuning inefficient and unlikely to yield satisfactory performance within a practical number of trials. To address this challenge, we propose a Bayesian optimization (BO) framework that treats the closed-loop system as a black box and selects controller gains using a Gaussian-process surrogate. BO offers model-free exploration, quantified uncertainty, and data-efficient search, making it well suited for tuning tasks where each evaluation is costly. The framework is implemented on Honda's AI-Formula three-wheeled robot and assessed through repeated full-lap experiments on a fixed test track. The results show that BO improves controller performance within 32 trials, including 15 warm-start initial evaluations, indicating that it can efficiently locate high-performing regions of the parameter space under real-world conditions. These findings demonstrate that BO provides a practical, reliable, and data-efficient tuning approach for nonlinear path-following controllers on real robotic platforms.

</details>


### [352] [HMPCC: Human-Aware Model Predictive Coverage Control](https://arxiv.org/abs/2512.12717)
*Mattia Catellani,Marta Gabbi,Lorenzo Sabattini*

Main category: cs.RO

TL;DR: HMPCC框架结合MPC和人类运动预测，实现机器人团队在未知环境中的高效安全覆盖。


<details>
  <summary>Details</summary>
Motivation: 传统覆盖策略在现实场景（尤其是涉及人类时）适应性不足，需解决未知环境、非凸空间及动态密度函数等挑战。

Method: 提出基于模型预测控制（MPC）的人机感知覆盖框架HMPCC，利用高斯混合模型（GMM）建模环境，并采用完全去中心化的团队协作方式。

Result: 实验表明，人类轨迹预测能提升覆盖效率和适应性，优化人机协作。

Conclusion: HMPCC框架通过将人类运动预测整合到MPC规划中，实现了在未知环境中机器人团队的高效覆盖和与人类的安全协作。

Abstract: We address the problem of coordinating a team of robots to cover an unknown environment while ensuring safe operation and avoiding collisions with non-cooperative agents. Traditional coverage strategies often rely on simplified assumptions, such as known or convex environments and static density functions, and struggle to adapt to real-world scenarios, especially when humans are involved. In this work, we propose a human-aware coverage framework based on Model Predictive Control (MPC), namely HMPCC, where human motion predictions are integrated into the planning process. By anticipating human trajectories within the MPC horizon, robots can proactively coordinate their actions %avoid redundant exploration, and adapt to dynamic conditions. The environment is modeled as a Gaussian Mixture Model (GMM), representing regions of interest. Team members operate in a fully decentralized manner, without relying on explicit communication, an essential feature in hostile or communication-limited scenarios. Our results show that human trajectory forecasting enables more efficient and adaptive coverage, improving coordination between human and robotic agents.

</details>


### [353] [Making Robots Play by the Rules: The ROS 2 CLIPS-Executive](https://arxiv.org/abs/2512.12722)
*Tarik Viehmann,Daniel Swoboda,Samridhi Kalra,Himanshu Grover,Gerhard Lakemeyer*

Main category: cs.RO

TL;DR: 将CLIPS集成到ROS，展示其通过PDDL规划的灵活性，适用于自主机器人协调。


<details>
  <summary>Details</summary>
Motivation: 受CLIPS-Executive启发，旨在将CLIPS这一基于规则的知识驱动编程语言应用于ROS生态系统，以解决自主机器人协调的复杂任务。

Method: 介绍了CLIPS与ROS生态系统的集成方法，以及基于PDDL的规划框架集成。

Result: 成功实现了CLIPS与ROS的集成，并展示了其在PDDL规划框架中的灵活性。

Conclusion: 将CLIPS集成到ROS生态系统中，并展示了其通过PDDL规划框架的灵活性，证明了CLIPS在协调自主机器人复杂任务中的适用性。

Abstract: CLIPS is a rule-based programming language for building knowledge-driven applications, well suited for the complex task of coordinating autonomous robots. Inspired by the CLIPS-Executive originally developed for the lesser known Fawkes robotics framework, we present an Integration of CLIPS into the ROS ecosystem. Additionally, we show the flexibility of CLIPS by describing a PDDL-based planning framework integration.

</details>


### [354] [VLG-Loc: Vision-Language Global Localization from Labeled Footprint Maps](https://arxiv.org/abs/2512.12793)
*Mizuho Aoki,Kohei Honda,Yasuhiro Yoshimura,Takeshi Ishita,Ryo Yonetani*

Main category: cs.RO

TL;DR: VLG-Loc利用视觉语言模型和蒙特卡洛定位框架，实现了在简单标记地图中的高效全局定位，优于传统扫描方法。


<details>
  <summary>Details</summary>
Motivation: 人类能够使用仅含名称和区域的标记地图进行定位，但机器人系统因缺乏几何和外观细节而难以实现类似能力。

Method: 利用视觉语言模型（VLM）在多方向图像观测中搜索地图中标注的视觉地标，并在蒙特卡洛定位框架中评估每个位姿假设的似然性。

Result: 在模拟和真实零售环境中的实验验证显示，VLG-Loc在环境变化下具有更高的鲁棒性，且通过视觉与扫描定位的概率融合进一步提升了性能。

Conclusion: VLG-Loc通过结合视觉语言模型和蒙特卡洛定位框架，实现了在缺乏几何和外观细节的地图中进行全局定位，表现出优于现有扫描方法的鲁棒性。

Abstract: This paper presents Vision-Language Global Localization (VLG-Loc), a novel global localization method that uses human-readable labeled footprint maps containing only names and areas of distinctive visual landmarks in an environment. While humans naturally localize themselves using such maps, translating this capability to robotic systems remains highly challenging due to the difficulty of establishing correspondences between observed landmarks and those in the map without geometric and appearance details. To address this challenge, VLG-Loc leverages a vision-language model (VLM) to search the robot's multi-directional image observations for the landmarks noted in the map. The method then identifies robot poses within a Monte Carlo localization framework, where the found landmarks are used to evaluate the likelihood of each pose hypothesis. Experimental validation in simulated and real-world retail environments demonstrates superior robustness compared to existing scan-based methods, particularly under environmental changes. Further improvements are achieved through the probabilistic fusion of visual and scan-based localization.

</details>


### [355] [SAGA: Open-World Mobile Manipulation via Structured Affordance Grounding](https://arxiv.org/abs/2512.12842)
*Kuan Fang,Yuxin Chen,Xinghao Zhu,Farzad Niroui,Lingfeng Sun,Jiuguang Wang*

Main category: cs.RO

TL;DR: SAGA是一个通用视觉运动控制框架，通过可供性任务表示和多模态模型实现跨任务泛化，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了开发一个能够跨环境、任务目标和用户规范通用的视觉运动控制框架。

Method: SAGA使用基于可供性的任务表示，通过多模态基础模型将任务表示与机器人视觉观察相结合，生成3D可供性热图，并训练条件策略进行全身控制。

Result: SAGA在11个真实世界任务中表现优于端到端和模块化基线方法。

Conclusion: SAGA框架通过结构化的可供性基础，为通用移动操作提供了可扩展且有效的途径。

Abstract: We present SAGA, a versatile and adaptive framework for visuomotor control that can generalize across various environments, task objectives, and user specifications. To efficiently learn such capability, our key idea is to disentangle high-level semantic intent from low-level visuomotor control by explicitly grounding task objectives in the observed environment. Using an affordance-based task representation, we express diverse and complex behaviors in a unified, structured form. By leveraging multimodal foundation models, SAGA grounds the proposed task representation to the robot's visual observation as 3D affordance heatmaps, highlighting task-relevant entities while abstracting away spurious appearance variations that would hinder generalization. These grounded affordances enable us to effectively train a conditional policy on multi-task demonstration data for whole-body control. In a unified framework, SAGA can solve tasks specified in different forms, including language instructions, selected points, and example demonstrations, enabling both zero-shot execution and few-shot adaptation. We instantiate SAGA on a quadrupedal manipulator and conduct extensive experiments across eleven real-world tasks. SAGA consistently outperforms end-to-end and modular baselines by substantial margins. Together, these results demonstrate that structured affordance grounding offers a scalable and effective pathway toward generalist mobile manipulation.

</details>


### [356] [MPC-Guided Safe Reinforcement Learning and Lipschitz-Based Filtering for Structured Nonlinear Systems](https://arxiv.org/abs/2512.12855)
*Patrick Kostelac,Xuerui Wang,Anahita Jamshidnejad*

Main category: cs.RO

TL;DR: 论文提出了一种结合MPC和RL的框架，利用MPC的安全约束指导RL学习，实现实时安全控制，适用于非线性系统。


<details>
  <summary>Details</summary>
Motivation: 现代工程系统（如自动驾驶车辆、柔性机器人和智能航空航天平台）需要控制器具备对不确定性的鲁棒性、对环境变化的适应性以及在实时约束下的安全感知能力。RL虽能提供强大的数据驱动适应性，但缺乏动态约束满足的内置机制；MPC虽能处理结构化约束和鲁棒性，但对精确模型的依赖和计算密集的在线优化带来挑战。

Method: 在训练阶段，MPC定义了安全控制边界，指导RL组件进行约束感知的策略学习；在部署阶段，学习到的策略通过基于Lipschitz连续性的轻量级安全过滤器实时运行，确保约束满足而无需繁重的在线优化。

Result: 该方法在非线性气动弹性翼系统上验证，展示了改进的干扰抑制、减少的执行器努力以及在湍流下的鲁棒性能。

Conclusion: 该论文提出了一种集成的MPC-RL框架，结合了MPC的稳定性和安全性保证与RL的适应性，为工程应用中的安全人工智能驱动控制提供了可扩展的解决方案。

Abstract: Modern engineering systems, such as autonomous vehicles, flexible robotics, and intelligent aerospace platforms, require controllers that are robust to uncertainties, adaptive to environmental changes, and safety-aware under real-time constraints. RL offers powerful data-driven adaptability for systems with nonlinear dynamics that interact with uncertain environments. RL, however, lacks built-in mechanisms for dynamic constraint satisfaction during exploration. MPC offers structured constraint handling and robustness, but its reliance on accurate models and computationally demanding online optimization may pose significant challenges. This paper proposes an integrated MPC-RL framework that combines stability and safety guarantees of MPC with the adaptability of RL. During training, MPC defines safe control bounds that guide the RL component and that enable constraint-aware policy learning. At deployment, the learned policy operates in real time with a lightweight safety filter based on Lipschitz continuity to ensure constraint satisfaction without heavy online optimizations. The approach, which is validated on a nonlinear aeroelastic wing system, demonstrates improved disturbance rejection, reduced actuator effort, and robust performance under turbulence. The architecture generalizes to other domains with structured nonlinearities and bounded disturbances, offering a scalable solution for safe artificial-intelligence-driven control in engineering applications.

</details>


### [357] [SLIM-VDB: A Real-Time 3D Probabilistic Semantic Mapping Framework](https://arxiv.org/abs/2512.12945)
*Anja Sheppard,Parker Ewen,Joey Wilson,Advaith V. Sethuraman,Benard Adewole,Anran Li,Yuzhen Chen,Ram Vasudevan,Katherine A. Skinner*

Main category: cs.RO

TL;DR: SLIM-VDB 是一种基于 OpenVDB 的轻量级语义映射系统，支持闭集和开放集语义融合，显著提升了效率和精度。


<details>
  <summary>Details</summary>
Motivation: 现有的语义映射系统缺乏对固定类别和开放语言标签预测的集成支持，且 OpenVDB 在语义映射中的应用尚未探索。

Method: 利用 OpenVDB 数据结构，并整合了一个统一的贝叶斯更新框架，用于闭集和开放集语义融合。

Result: 与当前最先进的语义映射方法相比，SLIM-VDB 在内存和集成时间上实现了显著减少，同时保持了可比的映射精度。

Conclusion: SLIM-VDB 是一种新型的轻量级语义映射系统，通过概率语义融合支持闭集和开放集词典，显著提升了内存和计算效率，同时保持较高的映射精度。

Abstract: This paper introduces SLIM-VDB, a new lightweight semantic mapping system with probabilistic semantic fusion for closed-set or open-set dictionaries. Advances in data structures from the computer graphics community, such as OpenVDB, have demonstrated significantly improved computational and memory efficiency in volumetric scene representation. Although OpenVDB has been used for geometric mapping in robotics applications, semantic mapping for scene understanding with OpenVDB remains unexplored. In addition, existing semantic mapping systems lack support for integrating both fixed-category and open-language label predictions within a single framework. In this paper, we propose a novel 3D semantic mapping system that leverages the OpenVDB data structure and integrates a unified Bayesian update framework for both closed- and open-set semantic fusion. Our proposed framework, SLIM-VDB, achieves significant reduction in both memory and integration times compared to current state-of-the-art semantic mapping approaches, while maintaining comparable mapping accuracy. An open-source C++ codebase with a Python interface is available at https://github.com/umfieldrobotics/slim-vdb.

</details>


### [358] [Tackling Snow-Induced Challenges: Safe Autonomous Lane-Keeping with Robust Reinforcement Learning](https://arxiv.org/abs/2512.12987)
*Amin Jalal Aghdasian,Farzaneh Abdollahi,Ali Kamali Iglie*

Main category: cs.RO

TL;DR: 本文提出两种基于DRL的算法（AR-RDPG和AR-CADPG）用于雪天自动驾驶车道保持系统，AR-CADPG在路径跟踪和鲁棒性上表现更优。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶车辆在雪天道路条件下的不确定性和打滑问题。

Method: 提出了两种基于深度强化学习（DRL）的算法：AR-RDPG和AR-CADPG。AR-RDPG通过多尺度神经网络去噪图像，并使用预训练的DCNN提取中心线系数；AR-CADPG则将CNN和注意力机制集成到DRL框架中。

Result: 在CARLA模拟器中训练并在多种雪天场景下验证，Jetson Nano自动驾驶车辆的实际实验证实了学习策略的可行性和稳定性。

Conclusion: AR-CADPG方法在路径跟踪精度和鲁棒性上表现更优，突出了结合时序记忆、对抗弹性和注意力机制在自动驾驶车辆中的有效性。

Abstract: This paper proposes two new algorithms for the lane keeping system (LKS) in autonomous vehicles (AVs) operating under snowy road conditions. These algorithms use deep reinforcement learning (DRL) to handle uncertainties and slippage. They include Action-Robust Recurrent Deep Deterministic Policy Gradient (AR-RDPG) and end-to-end Action-Robust convolutional neural network Attention Deterministic Policy Gradient (AR-CADPG), two action-robust approaches for decision-making. In the AR-RDPG method, within the perception layer, camera images are first denoised using multi-scale neural networks. Then, the centerline coefficients are extracted by a pre-trained deep convolutional neural network (DCNN). These coefficients, concatenated with the driving characteristics, are used as input to the control layer. The AR-CADPG method presents an end-to-end approach in which a convolutional neural network (CNN) and an attention mechanism are integrated within a DRL framework. Both methods are first trained in the CARLA simulator and validated under various snowy scenarios. Real-world experiments on a Jetson Nano-based autonomous vehicle confirm the feasibility and stability of the learned policies. Among the two models, the AR-CADPG approach demonstrates superior path-tracking accuracy and robustness, highlighting the effectiveness of combining temporal memory, adversarial resilience, and attention mechanisms in AVs.

</details>


### [359] [Learning Terrain Aware Bipedal Locomotion via Reduced Dimensional Perceptual Representations](https://arxiv.org/abs/2512.12993)
*Guillermo A. Castillo,Himanshu Lodha,Ayonga Hereid*

Main category: cs.RO

TL;DR: 论文提出了一种分层策略，结合CNN-VAE和强化学习，优化双足机器人在复杂地形中的步态生成，并通过实验验证了其鲁棒性和硬件部署潜力。


<details>
  <summary>Details</summary>
Motivation: 为了解决端到端方法在复杂地形中步态生成的不足，论文旨在通过降维感知表示和强化学习的结合，提升双足机器人的适应性和鲁棒性。

Method: 论文采用了一种结合卷积变分自编码器（CNN-VAE）和降阶机器人动力学的分层策略，通过优化紧凑状态空间来增强高层面（HL）策略。此外，方法还扩展为历史感知型，通过整合近期地形观测序列来提升鲁棒性。

Result: 实验结果表明，该方法在模拟和真实传感器数据中均表现出鲁棒性和适应性，验证了其在硬件部署中的可行性。

Conclusion: 该论文提出的分层策略通过整合降维感知表示和强化学习，显著提升了双足机器人在复杂地形中的实时步态生成能力，并验证了其在硬件部署中的潜力。

Abstract: This work introduces a hierarchical strategy for terrain-aware bipedal locomotion that integrates reduced-dimensional perceptual representations to enhance reinforcement learning (RL)-based high-level (HL) policies for real-time gait generation. Unlike end-to-end approaches, our framework leverages latent terrain encodings via a Convolutional Variational Autoencoder (CNN-VAE) alongside reduced-order robot dynamics, optimizing the locomotion decision process with a compact state. We systematically analyze the impact of latent space dimensionality on learning efficiency and policy robustness. Additionally, we extend our method to be history-aware, incorporating sequences of recent terrain observations into the latent representation to improve robustness. To address real-world feasibility, we introduce a distillation method to learn the latent representation directly from depth camera images and provide preliminary hardware validation by comparing simulated and real sensor data. We further validate our framework using the high-fidelity Agility Robotics (AR) simulator, incorporating realistic sensor noise, state estimation, and actuator dynamics. The results confirm the robustness and adaptability of our method, underscoring its potential for hardware deployment.

</details>


### [360] [K-VARK: Kernelized Variance-Aware Residual Kalman Filter for Sensorless Force Estimation in Collaborative Robots](https://arxiv.org/abs/2512.13009)
*Oğuzhan Akbıyık,Naseem Alhousani,Fares J. Abu-Dakka*

Main category: cs.RO

TL;DR: K-VARK是一种新型核化方差感知残差卡尔曼滤波器，通过优化激励轨迹和自适应卡尔曼滤波框架，显著提升了无传感器力估计的准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 由于固有建模误差和复杂的残差动力学及摩擦，精确的无传感器力估计仍然具有挑战性。

Method: 提出K-VARK（核化方差感知残差卡尔曼滤波器），通过核化运动基元训练优化的激励轨迹，捕捉残差扭矩的预测均值和输入依赖的异方差方差。

Result: 实验验证表明，K-VARK相比现有无传感器力估计方法，RMSE降低超过20%。

Conclusion: K-VARK方法在6自由度协作机械臂上实现了超过20%的RMSE降低，为高级任务（如抛光和装配）提供了鲁棒且准确的外部力/扭矩估计。

Abstract: Reliable estimation of contact forces is crucial for ensuring safe and precise interaction of robots with unstructured environments. However, accurate sensorless force estimation remains challenging due to inherent modeling errors and complex residual dynamics and friction. To address this challenge, in this paper, we propose K-VARK (Kernelized Variance-Aware Residual Kalman filter), a novel approach that integrates a kernelized, probabilistic model of joint residual torques into an adaptive Kalman filter framework. Through Kernelized Movement Primitives trained on optimized excitation trajectories, K-VARK captures both the predictive mean and input-dependent heteroscedastic variance of residual torques, reflecting data variability and distance-to-training effects. These statistics inform a variance-aware virtual measurement update by augmenting the measurement noise covariance, while the process noise covariance adapts online via variational Bayesian optimization to handle dynamic disturbances. Experimental validation on a 6-DoF collaborative manipulator demonstrates that K-VARK achieves over 20% reduction in RMSE compared to state-of-the-art sensorless force estimation methods, yielding robust and accurate external force/torque estimation suitable for advanced tasks such as polishing and assembly.

</details>


### [361] [Spatial-Aware VLA Pretraining through Visual-Physical Alignment from Human Videos](https://arxiv.org/abs/2512.13080)
*Yicheng Feng,Wanpeng Zhang,Ye Wang,Hao Luo,Haoqi Yuan,Sipeng Zheng,Zongqing Lu*

Main category: cs.RO

TL;DR: VIPA-VLA通过3D空间对齐预训练，解决了2D视觉与3D动作的差距，提升了机器人策略的性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型依赖2D视觉输入在3D物理环境中执行动作，导致感知与动作基础之间存在显著差距。

Method: 提出了一种空间感知的VLA预训练范式，利用大规模人类演示视频提取3D视觉和动作标注，构建双编码器架构VIPA-VLA，增强视觉表征的3D感知能力。

Result: VIPA-VLA在下游机器人任务中表现出更强的2D视觉与3D动作关联性，提升了策略的鲁棒性和泛化能力。

Conclusion: VIPA-VLA通过空间感知预训练范式显著提升了2D视觉与3D动作的关联性，从而实现了更鲁棒和通用的机器人策略。

Abstract: Vision-Language-Action (VLA) models provide a promising paradigm for robot learning by integrating visual perception with language-guided policy learning. However, most existing approaches rely on 2D visual inputs to perform actions in 3D physical environments, creating a significant gap between perception and action grounding. To bridge this gap, we propose a Spatial-Aware VLA Pretraining paradigm that performs explicit alignment between visual space and physical space during pretraining, enabling models to acquire 3D spatial understanding before robot policy learning. Starting from pretrained vision-language models, we leverage large-scale human demonstration videos to extract 3D visual and 3D action annotations, forming a new source of supervision that aligns 2D visual observations with 3D spatial reasoning. We instantiate this paradigm with VIPA-VLA, a dual-encoder architecture that incorporates a 3D visual encoder to augment semantic visual representations with 3D-aware features. When adapted to downstream robot tasks, VIPA-VLA achieves significantly improved grounding between 2D vision and 3D action, resulting in more robust and generalizable robotic policies.

</details>


### [362] [Multi-Robot Motion Planning from Vision and Language using Heat-Inspired Diffusion](https://arxiv.org/abs/2512.13090)
*Jebeom Chae,Junwoo Chang,Seungho Yeom,Yujin Kim,Jongeun Choi*

Main category: cs.RO

TL;DR: LCHD框架通过语义先验和扩散核提升多机器人运动规划，减少计算成本并增强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在多机器人场景中泛化能力有限，计算成本高，且缺乏几何可达性推理机制。

Method: LCHD是一种端到端的视觉框架，结合了CLIP语义先验和碰撞避免扩散核，用于生成语言条件化的无碰撞轨迹。

Result: LCHD在多样化的现实场景中表现优异，成功率高且规划延迟低，优于现有扩散规划器。

Conclusion: LCHD框架通过结合CLIP语义先验和碰撞避免扩散核，显著提升了多机器人运动规划的成功率和效率，同时减少了对显式环境表示的依赖。

Abstract: Diffusion models have recently emerged as powerful tools for robot motion planning by capturing the multi-modal distribution of feasible trajectories. However, their extension to multi-robot settings with flexible, language-conditioned task specifications remains limited. Furthermore, current diffusion-based approaches incur high computational cost during inference and struggle with generalization because they require explicit construction of environment representations and lack mechanisms for reasoning about geometric reachability. To address these limitations, we present Language-Conditioned Heat-Inspired Diffusion (LCHD), an end-to-end vision-based framework that generates language-conditioned, collision-free trajectories. LCHD integrates CLIP-based semantic priors with a collision-avoiding diffusion kernel serving as a physical inductive bias that enables the planner to interpret language commands strictly within the reachable workspace. This naturally handles out-of-distribution scenarios -- in terms of reachability -- by guiding robots toward accessible alternatives that match the semantic intent, while eliminating the need for explicit obstacle information at inference time. Extensive evaluations on diverse real-world-inspired maps, along with real-robot experiments, show that LCHD consistently outperforms prior diffusion-based planners in success rate, while reducing planning latency.

</details>


### [363] [PvP: Data-Efficient Humanoid Robot Learning with Proprioceptive-Privileged Contrastive Representations](https://arxiv.org/abs/2512.13093)
*Mingqi Yuan,Tao Yu,Haolin Song,Bo Li,Xin Jin,Hua Chen,Wenjun Zeng*

Main category: cs.RO

TL;DR: PvP框架通过对比学习提升人形机器人控制的样本效率，实验验证其优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习在人形机器人控制中样本效率低下的问题，由于复杂的动力学和部分可观测性。

Method: 提出PvP（Proprioceptive-Privileged对比学习框架），利用本体感觉和特权状态的内在互补性，学习紧凑且任务相关的潜在表示，无需手工数据增强。

Result: 在LimX Oli机器人上进行的速度跟踪和运动模仿任务实验表明，PvP相比基线SRL方法显著提高了样本效率和最终性能。

Conclusion: PvP框架显著提升了人形机器人学习的样本效率和最终性能，为数据高效的人形机器人学习提供了实用指导。

Abstract: Achieving efficient and robust whole-body control (WBC) is essential for enabling humanoid robots to perform complex tasks in dynamic environments. Despite the success of reinforcement learning (RL) in this domain, its sample inefficiency remains a significant challenge due to the intricate dynamics and partial observability of humanoid robots. To address this limitation, we propose PvP, a Proprioceptive-Privileged contrastive learning framework that leverages the intrinsic complementarity between proprioceptive and privileged states. PvP learns compact and task-relevant latent representations without requiring hand-crafted data augmentations, enabling faster and more stable policy learning. To support systematic evaluation, we develop SRL4Humanoid, the first unified and modular framework that provides high-quality implementations of representative state representation learning (SRL) methods for humanoid robot learning. Extensive experiments on the LimX Oli robot across velocity tracking and motion imitation tasks demonstrate that PvP significantly improves sample efficiency and final performance compared to baseline SRL methods. Our study further provides practical insights into integrating SRL with RL for humanoid WBC, offering valuable guidance for data-efficient humanoid robot learning.

</details>


### [364] [Sequence of Expert: Boosting Imitation Planners for Autonomous Driving through Temporal Alternation](https://arxiv.org/abs/2512.13094)
*Xiang Li,Gang Liu,Weitao Zhou,Hongyi Zhu,Zhong Cao*

Main category: cs.RO

TL;DR: SoE通过时间交替策略提升模仿学习在自动驾驶中的闭环性能，无需增加模型或数据，实验证明其显著有效。


<details>
  <summary>Details</summary>
Motivation: 模仿学习在开环设置中表现良好，但在闭环中由于小误差的累积导致性能下降，当前研究主要关注单时间点的状态级鲁棒性，而自动驾驶是连续时间过程，需从时间尺度提升鲁棒性。

Method: 提出了一种称为Sequence of Experts (SoE)的时间交替策略，通过利用时间尺度来增强鲁棒性。

Result: 在nuPlan等大规模自动驾驶基准测试中，SoE方法显著提升了所有评估模型的性能，并达到最先进水平。

Conclusion: SoE方法通过时间交替策略显著提升了模仿学习在自动驾驶中的闭环性能，无需增加模型规模或数据需求，具有广泛的应用潜力。

Abstract: Imitation learning (IL) has emerged as a central paradigm in autonomous driving. While IL excels in matching expert behavior in open-loop settings by minimizing per-step prediction errors, its performance degrades unexpectedly in closed-loop due to the gradual accumulation of small, often imperceptible errors over time.Over successive planning cycles, these errors compound, potentially resulting in severe failures.Current research efforts predominantly rely on increasingly sophisticated network architectures or high-fidelity training datasets to enhance the robustness of IL planners against error accumulation, focusing on the state-level robustness at a single time point. However, autonomous driving is inherently a continuous-time process, and leveraging the temporal scale to enhance robustness may provide a new perspective for addressing this issue.To this end, we propose a method termed Sequence of Experts (SoE), a temporal alternation policy that enhances closed-loop performance without increasing model size or data requirements. Our experiments on large-scale autonomous driving benchmarks nuPlan demonstrate that SoE method consistently and significantly improves the performance of all the evaluated models, and achieves state-of-the-art performance.This module may provide a key and widely applicable support for improving the training efficiency of autonomous driving models.

</details>


### [365] [OXE-AugE: A Large-Scale Robot Augmentation of OXE for Scaling Cross-Embodiment Policy Learning](https://arxiv.org/abs/2512.13100)
*Guanhua Ji,Harsha Polavaram,Lawrence Yunliang Chen,Sandeep Bajamahal,Zehan Ma,Simeon Adebola,Chenfeng Xu,Ken Goldberg*

Main category: cs.RO

TL;DR: OXE-AugE数据集通过增加9种机器人硬件配置，显著提升了通用机器人策略的性能，尤其是在未见过的硬件配置上，成功率提高了24-45%。


<details>
  <summary>Details</summary>
Motivation: 解决现有Open X-Embodiment (OXE)数据集高度不平衡的问题，避免对特定机器人-场景组合的过拟合，同时降低重新收集演示数据和重新训练的成本。

Method: 提出了AugE-Toolkit，一个可扩展的机器人数据增强流水线，并创建了OXE-AugE数据集，该数据集通过增加9种不同的机器人硬件配置来增强原有的OXE数据集。

Result: OXE-AugE数据集包含超过440万条轨迹，是原始OXE数据集的三倍多。实验表明，通过增加多样化的机械臂和夹持器，不仅提升了在增强机器人上的策略性能，还改善了在未见过的机器人及原始机器人分布变化下的表现。

Conclusion: 通过OXE-AugE数据集和AugE-Toolkit工具包的引入，显著提升了通用机器人策略的性能，尤其是在未见过的机器人硬件配置上的表现。

Abstract: Large and diverse datasets are needed for training generalist robot policies that have potential to control a variety of robot embodiments -- robot arm and gripper combinations -- across diverse tasks and environments. As re-collecting demonstrations and retraining for each new hardware platform are prohibitively costly, we show that existing robot data can be augmented for transfer and generalization. The Open X-Embodiment (OXE) dataset, which aggregates demonstrations from over 60 robot datasets, has been widely used as the foundation for training generalist policies. However, it is highly imbalanced: the top four robot types account for over 85\% of its real data, which risks overfitting to robot-scene combinations. We present AugE-Toolkit, a scalable robot augmentation pipeline, and OXE-AugE, a high-quality open-source dataset that augments OXE with 9 different robot embodiments. OXE-AugE provides over 4.4 million trajectories, more than triple the size of the original OXE. We conduct a systematic study of how scaling robot augmentation impacts cross-embodiment learning. Results suggest that augmenting datasets with diverse arms and grippers improves policy performance not only on the augmented robots, but also on unseen robots and even the original robots under distribution shifts. In physical experiments, we demonstrate that state-of-the-art generalist policies such as OpenVLA and $π_0$ benefit from fine-tuning on OXE-AugE, improving success rates by 24-45% on previously unseen robot-gripper combinations across four real-world manipulation tasks. Project website: https://OXE-AugE.github.io/.

</details>


### [366] [START: Traversing Sparse Footholds with Terrain Reconstruction](https://arxiv.org/abs/2512.13153)
*Ruiqi Yu,Qianshi Wang,Hongyi Li,Zheng Jun,Zhicheng Wang,Jun Wu,Qiuguo Zhu*

Main category: cs.RO

TL;DR: START是一个单阶段学习框架，通过低成本机载视觉和本体感知实现稀疏立足点上的敏捷稳定运动，展示了卓越的适应性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在稀疏立足点地形上运动时存在的泛化能力有限、行为保守或依赖噪声高度图等问题。

Method: START是一个单阶段学习框架，利用低成本机载视觉和本体感知准确重建局部地形高度图，提供明确的中间表示来传达稀疏立足点区域的关键特征。

Result: 实验结果表明，START在多样化的真实场景中实现了零样本迁移，表现出卓越的适应性、精确的立足点放置和鲁棒的运动能力。

Conclusion: START框架通过低成本机载视觉和本体感知实现了在稀疏立足点上的敏捷稳定运动，展示了卓越的适应性和鲁棒性。

Abstract: Traversing terrains with sparse footholds like legged animals presents a promising yet challenging task for quadruped robots, as it requires precise environmental perception and agile control to secure safe foot placement while maintaining dynamic stability. Model-based hierarchical controllers excel in laboratory settings, but suffer from limited generalization and overly conservative behaviors. End-to-end learning-based approaches unlock greater flexibility and adaptability, but existing state-of-the-art methods either rely on heightmaps that introduce noise and complex, costly pipelines, or implicitly infer terrain features from egocentric depth images, often missing accurate critical geometric cues and leading to inefficient learning and rigid gaits. To overcome these limitations, we propose START, a single-stage learning framework that enables agile, stable locomotion on highly sparse and randomized footholds. START leverages only low-cost onboard vision and proprioception to accurately reconstruct local terrain heightmap, providing an explicit intermediate representation to convey essential features relevant to sparse foothold regions. This supports comprehensive environmental understanding and precise terrain assessment, reducing exploration cost and accelerating skill acquisition. Experimental results demonstrate that START achieves zero-shot transfer across diverse real-world scenarios, showcasing superior adaptability, precise foothold placement, and robust locomotion.

</details>


### [367] [Iterative Tuning of Nonlinear Model Predictive Control for Robotic Manufacturing Tasks](https://arxiv.org/abs/2512.13170)
*Deepak Ingole,Valentin Bhend,Shiva Ganesh Murali,Oliver Dobrich,Alisa Rupenayan*

Main category: cs.RO

TL;DR: 提出一种基于任务级性能反馈的迭代学习框架，用于自动调参NMPC权重矩阵，在UR10e机器人碳纤维缠绕任务中验证，仅需4次在线重复即接近最优性能。


<details>
  <summary>Details</summary>
Motivation: 制造过程常因环境漂移和系统磨损而受扰动，即使在重复操作中也需要重新调参控制。

Method: 受范数最优迭代学习控制（ILC）启发，该方法通过构建经验敏感度矩阵，自适应调整NMPC权重Q和R，避免了基于梯度方法中需对NMPC求解器进行微分的需求。

Result: 仿真验证显示，该方法仅需4次在线重复即可达到接近最优的跟踪性能（RMSE在离线贝叶斯优化（BO）的0.3%以内），而BO算法需要100次离线评估。

Conclusion: 该论文提出的迭代学习框架为重复性机器人任务中的自适应NMPC调参提供了实用解决方案，结合了精确优化控制器的优势与在线适应的灵活性。

Abstract: Manufacturing processes are often perturbed by drifts in the environment and wear in the system, requiring control re-tuning even in the presence of repetitive operations. This paper presents an iterative learning framework for automatic tuning of Nonlinear Model Predictive Control (NMPC) weighting matrices based on task-level performance feedback. Inspired by norm-optimal Iterative Learning Control (ILC), the proposed method adaptively adjusts NMPC weights Q and R across task repetitions to minimize key performance indicators (KPIs) related to tracking accuracy, control effort, and saturation. Unlike gradient-based approaches that require differentiating through the NMPC solver, we construct an empirical sensitivity matrix, enabling structured weight updates without analytic derivatives. The framework is validated through simulation on a UR10e robot performing carbon fiber winding on a tetrahedral core. Results demonstrate that the proposed approach converges to near-optimal tracking performance (RMSE within 0.3% of offline Bayesian Optimization (BO)) in just 4 online repetitions, compared to 100 offline evaluations required by BO algorithm. The method offers a practical solution for adaptive NMPC tuning in repetitive robotic tasks, combining the precision of carefully optimized controllers with the flexibility of online adaptation.

</details>


### [368] [Efficient Generation of Smooth Paths with Curvature Guarantees by Mollification](https://arxiv.org/abs/2512.13183)
*Alfredo González-Calvin,Juan F. Jiménez,Héctor García de Marina*

Main category: cs.RO

TL;DR: 提出mollification方法，将非可微路径正则化为可微函数，高效且曲率可控，适用于实时机器人路径跟踪。


<details>
  <summary>Details</summary>
Motivation: 解决非可微路径（如分段函数）在移动机器人路径跟踪中的适用性问题，避免现有平滑方法的高计算成本或复杂轨迹。

Method: 使用mollification近似任意路径，生成可微函数，并系统化限制生成路径的曲率。

Result: 方法能高效生成可微路径，曲率可控，适用于实时实现。

Conclusion: 该论文提出了一种通过mollification正则化非可微函数的方法，能够高效生成可行路径，并适用于实时微控制器实现。

Abstract: Most path following and trajectory tracking algorithms in mobile robotics require the desired path or trajectory to be defined by at least twice continuously differentiable functions to guarantee key properties such as global convergence, especially for nonholonomic robots like unicycles with speed constraints. Consequently, these algorithms typically exclude continuous but non-differentiable paths, such as piecewise functions. Despite this exclusion, such paths provide convenient high-level inputs for describing robot missions or behavior. While techniques such as spline interpolation or optimization-based methods are commonly used to smooth non-differentiable paths or create feasible ones from sequences of waypoints, they either can produce unnecessarily complex trajectories or are computationally expensive. In this work, we present a method to regularize non-differentiable functions and generate feasible paths through mollification. Specifically, we approximate an arbitrary path with a differentiable function that can converge to it with arbitrary precision. Additionally, we provide a systematic method for bounding the curvature of generated paths, which we demonstrate by applying it to paths resulting from linking a sequence of waypoints with segments. The proposed approach is computationally efficient, enabling real-time implementation on microcontrollers and compatibility with standard trajectory tracking and path following algorithms.

</details>


### [369] [ALBATROSS: A robotised system for high-throughput electrolyte screening via automated electrolyte formulation, coin-cell fabrication, and electrochemical evaluation](https://arxiv.org/abs/2512.13198)
*Hyun-Gi Lee,Jaekyeong Han,Minjun Kwon,Hyeonuk Kwon,Jooha Park,Hoe Jin Ha,Dong-Hwa Seo*

Main category: cs.RO

TL;DR: ALBATROSS是一个自动化纽扣电池测试系统，显著提高了组装和测试效率，为电解质研究提供了高质量数据。


<details>
  <summary>Details</summary>
Motivation: 传统的纽扣电池组装和测试过程耗时耗力，阻碍了高通量筛选研究的进展。

Method: 开发了一个名为ALBATROSS的自动化系统，该系统集成了电解质配方、纽扣电池组装和电化学评估功能，并在氩气手套箱内实现全自动化操作。

Result: ALBATROSS实现了高组装可靠性，放电容量的相对标准偏差小于1.2%，EIS测量的标准偏差小于3Ω。

Conclusion: ALBATROSS系统通过高可靠性和自动化能力，为下一代电解质的开发提供了高质量的数据集，加速了研究进程。

Abstract: As battery technologies advance toward higher stability and energy density, the need for extensive cell-level testing across various component configurations becomes critical. To evaluate performance and understand the operating principles of batteries in laboratory scale, fabrication and evaluation of coin cells are essential processes. However, the conventional coin-cell assembly and testing processes require significant time and labor from researchers, posing challenges to high-throughput screening research. In this study, we introduce an Automated Li-ion BAttery Testing RObot SyStem (ALBATROSS), an automated system capable of electrolyte formulation, coin-cell assembly, and electrochemical evaluation. The system, integrated within a argon-filled glovebox, enables fully automated assembly and testing of up to 48 cells without researcher intervention. By incorporating custom-designed robot gripper and 3D-printed structures optimized for precise cell handling, ALBATROSS achieved high assembly reliability, yielding a relative standard deviation (RSD) of less than 1.2% in discharge capacity and a standard deviation of less than 3 Ω in EIS measurements for NCM811||Li half cells. Owing to its high reliability and automation capability, ALBATROSS allows for the acquisition of high-quality coin-cell datasets, which are expected to accelerate the development of next-generation electrolytes.

</details>


### [370] [Differentiable Material Point Method for the Control of Deformable Objects](https://arxiv.org/abs/2512.13214)
*Diego Bolliger,Gabriele Fadini,Markus Bambach,Alisa Rupenyan*

Main category: cs.RO

TL;DR: 可微分MPM模拟器优化控制轨迹，显著提升超弹性绳索的主动阻尼效果，比基线方法更快、更节能。


<details>
  <summary>Details</summary>
Motivation: 柔性物体因其非线性动力学和高维配置空间，变形控制具有挑战性。

Method: 提出了一种针对控制应用的可微分材料点方法（MPM）模拟器，并利用其可微分特性优化控制轨迹。

Result: 模拟器在超弹性绳索的主动阻尼问题中，比基线MPPI方法快约2倍，能量水平降低20%，且仅需约3%的计算时间。

Conclusion: 通过可微分MPM模拟器在控制应用中优化控制轨迹，显著提升了超弹性绳索的主动阻尼效果。

Abstract: Controlling the deformation of flexible objects is challenging due to their non-linear dynamics and high-dimensional configuration space. This work presents a differentiable Material Point Method (MPM) simulator targeted at control applications. We exploit the differentiability of the simulator to optimize a control trajectory in an active damping problem for a hyperelastic rope. The simulator effectively minimizes the kinetic energy of the rope around 2$\times$ faster than a baseline MPPI method and to a 20% lower energy level, while using about 3% of the computation time.

</details>


### [371] [Multi-directional Safe Rectangle Corridor-Based MPC for Nonholonomic Robots Navigation in Cluttered Environment](https://arxiv.org/abs/2512.13215)
*Yinsong Qu,Yunxiang Li,Shanlin Zhong*

Main category: cs.RO

TL;DR: ISMPC导航框架通过MDSRC和顺序MPC解决了AMR在复杂环境中的导航问题，提升了自由空间利用率和实时性能。


<details>
  <summary>Details</summary>
Motivation: 解决AMR在密集、杂乱和半结构化环境中导航的挑战，包括非完整车辆动力学、混合静态/动态障碍物交互以及非凸约束操作空间。

Method: 采用改进的顺序模型预测控制（ISMPC）导航框架，结合多方向安全矩形走廊（MDSRC）算法和顺序MPC导航框架，实现了静态和动态障碍物的避障。

Result: 实验表明，该框架在自由空间利用率上提升了41.05%，同时保持实时计算性能（平均走廊生成延迟为3毫秒）。

Conclusion: 该论文提出的ISMPC导航框架通过MDSRC算法和顺序MPC导航框架，有效解决了AMR在密集、杂乱和半结构化环境中的导航挑战，显著提升了自由空间利用率和实时计算性能。

Abstract: Autonomous Mobile Robots (AMRs) have become indispensable in industrial applications due to their operational flexibility and efficiency. Navigation serves as a crucial technical foundation for accomplishing complex tasks. However, navigating AMRs in dense, cluttered, and semi-structured environments remains challenging, primarily due to nonholonomic vehicle dynamics, interactions with mixed static/dynamic obstacles, and the non-convex constrained nature of such operational spaces. To solve these problems, this paper proposes an Improved Sequential Model Predictive Control (ISMPC) navigation framework that systematically reformulates navigation tasks as sequential switched optimal control problems. The framework addresses the aforementioned challenges through two key innovations: 1) Implementation of a Multi-Directional Safety Rectangular Corridor (MDSRC) algorithm, which encodes the free space through rectangular convex regions to avoid collision with static obstacles, eliminating redundant computational burdens and accelerating solver convergence; 2) A sequential MPC navigation framework that integrates corridor constraints with barrier function constraints is proposed to achieve static and dynamic obstacle avoidance. The ISMPC navigation framework enables direct velocity generation for AMRs, simplifying traditional navigation algorithm architectures. Comparative experiments demonstrate the framework's superiority in free-space utilization ( an increase of 41.05$\%$ in the average corridor area) while maintaining real-time computational performance (average corridors generation latency of 3 ms).

</details>


### [372] [A Unified Framework for Automated Assembly Sequence and Production Line Planning using Graph-based Optimization](https://arxiv.org/abs/2512.13219)
*Christoph Hartmann,Marios Demetriades,Kevin Prüfer,Zichen Zhang,Klaus Spindler,Stefan Weltge*

Main category: cs.RO

TL;DR: PyCAALP是一个基于Python的开源框架，通过图模型和混合整数规划方法，高效解决自动装配序列和生产规划问题，支持灵活定制并降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 解决自动装配序列和生产规划中的高组合复杂度问题，同时保证规划可行性和效率。

Method: 采用基于图的模型表示生产模块中的组件和连接，结合运动学边界条件（如零件碰撞检测）和启发式方法（如单件流装配和几何约束强化），并通过混合整数规划（MIP）优化生产线平衡。

Result: 开发了一个开源框架PyCAALP，能够生成所有可行的生产序列，并通过MIP优化生产线平衡，显著降低了计算时间。

Conclusion: PyCAALP框架通过图模型和混合整数规划方法，有效解决了自动装配序列规划（ASP）和生产线规划（PLP）的高组合复杂度问题，支持工程约束的灵活定制，并在开源平台上促进了工业与研究应用的合作。

Abstract: This paper presents PyCAALP (Python-based Computer-Aided Assembly Line Planning), a framework for automated Assembly Sequence Planning (ASP) and Production Line Planning (PLP), employing a graph-based approach to model components and joints within production modules. The framework integrates kinematic boundary conditions, such as potential part collisions, to guarantee the feasibility of automated assembly planning. The developed algorithm computes all feasible production sequences, integrating modules for detecting spatial relationships and formulating geometric constraints. The algorithm incorporates additional attributes, including handling feasibility, tolerance matching, and joint compatibility, to manage the high combinatorial complexity inherent in assembly sequence generation. Heuristics, such as Single-Piece Flow assembly and geometrical constraint enforcement, are utilized to further refine the solution space, facilitating more efficient planning for complex assemblies. The PLP stage is formulated as a Mixed-Integer Program (MIP), balancing the total times of a fixed number of manufacturing stations. While some complexity reduction techniques may sacrifice optimality, they significantly reduce the MIPs computational time. Furthermore, the framework enables customization of engineering constraints and supports a flexible trade-off between ASP and PLP. The open-source nature of the framework, available at https://github.com/TUM-utg/PyCAALP, promotes further collaboration and adoption in both industrial and production research applications.

</details>


### [373] [Post-Training and Test-Time Scaling of Generative Agent Behavior Models for Interactive Autonomous Driving](https://arxiv.org/abs/2512.13262)
*Hyunki Seong,Jeong-Kyun Lee,Heesoo Myeong,Yongho Shin,Hyun-Mook Cho,Duck Hoon Kim,Pranav Desai,Monu Surana*

Main category: cs.RO

TL;DR: GRBO和Warm-K策略提升了自动驾驶行为模型的鲁棒性和安全性，同时保持真实性。


<details>
  <summary>Details</summary>
Motivation: 解决模仿学习模型在安全关键场景中的鲁棒性不足和开环评估导致的误差累积问题。

Method: 提出了Group Relative Behavior Optimization (GRBO)强化学习后训练方法和Warm-K采样策略。

Result: GRBO仅使用10%的训练数据就将安全性能提升40%以上，Warm-K在不重新训练的情况下提升了行为一致性和反应性。

Conclusion: GRBO和Warm-K策略有效提升了自动驾驶中多智能体交互运动行为的鲁棒性和安全性，同时保持了行为真实性。

Abstract: Learning interactive motion behaviors among multiple agents is a core challenge in autonomous driving. While imitation learning models generate realistic trajectories, they often inherit biases from datasets dominated by safe demonstrations, limiting robustness in safety-critical cases. Moreover, most studies rely on open-loop evaluation, overlooking compounding errors in closed-loop execution. We address these limitations with two complementary strategies. First, we propose Group Relative Behavior Optimization (GRBO), a reinforcement learning post-training method that fine-tunes pretrained behavior models via group relative advantage maximization with human regularization. Using only 10% of the training dataset, GRBO improves safety performance by over 40% while preserving behavioral realism. Second, we introduce Warm-K, a warm-started Top-K sampling strategy that balances consistency and diversity in motion selection. Our Warm-K method-based test-time scaling enhances behavioral consistency and reactivity at test time without retraining, mitigating covariate shift and reducing performance discrepancies. Demo videos are available in the supplementary material.

</details>


### [374] [Lightweight Dynamic Modeling of Cable-Driven Continuum Robots Based on Actuation-Space Energy Formulation](https://arxiv.org/abs/2512.13271)
*Fangju Yang,Hang Yang,Ibrahim Alsarraj,Yuhao Wang,Ke Wu*

Main category: cs.RO

TL;DR: LASEM框架为CDCRs提供轻量级动态建模，通过变分推导简化模型，计算效率提升62.3%。


<details>
  <summary>Details</summary>
Motivation: CDCRs需要准确、实时的动态模型用于高速动力学预测或基于模型的控制，现有方法难以满足这一需求。

Method: 通过统一的变分推导，将动态模型简化为单个偏微分方程（PDE），仅需欧拉力矩平衡，同时隐式包含牛顿力平衡。避免了显式计算电缆-骨架接触力。

Result: 提出的Galerkin时空模态离散化方法实现了比现有实时动态建模方法平均62.3%的计算加速。

Conclusion: LASEM框架为CDCRs提供了一种轻量级且准确的动态建模方法，显著提高了计算效率，同时保持了几何精度和物理一致性。

Abstract: Cable-driven continuum robots (CDCRs) require accurate, real-time dynamic models for high-speed dynamics prediction or model-based control, making such capability an urgent need. In this paper, we propose the Lightweight Actuation-Space Energy Modeling (LASEM) framework for CDCRs, which formulates actuation potential energy directly in actuation space to enable lightweight yet accurate dynamic modeling. Through a unified variational derivation, the governing dynamics reduce to a single partial differential equation (PDE), requiring only the Euler moment balance while implicitly incorporating the Newton force balance. By also avoiding explicit computation of cable-backbone contact forces, the formulation simplifies the model structure and improves computational efficiency while preserving geometric accuracy and physical consistency. Importantly, the proposed framework for dynamic modeling natively supports both force-input and displacement-input actuation modes, a capability seldom achieved in existing dynamic formulations. Leveraging this lightweight structure, a Galerkin space-time modal discretization with analytical time-domain derivatives of the reduced state further enables an average 62.3% computational speedup over state-of-the-art real-time dynamic modeling approaches.

</details>


### [375] [Intrinsic-Motivation Multi-Robot Social Formation Navigation with Coordinated Exploration](https://arxiv.org/abs/2512.13293)
*Hao Fua,Wei Liu,Shuai Zhoua*

Main category: cs.RO

TL;DR: 本文提出了一种新型多机器人强化学习算法，通过内在奖励和双采样模式提升社会形成导航性能，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多机器人社会形成导航是实现人机共存的关键能力，但行人行为的不可预测性和不合作性对机器人协调探索的效率提出了挑战。

Method: 提出了一种协调探索的多机器人强化学习算法，包含自我学习的内在奖励机制和双采样模式，采用集中训练和分散执行的框架，并利用双时间尺度更新规则解耦参数更新。

Result: 在社会形成导航基准测试中，所提算法在关键指标上优于现有最先进方法。

Conclusion: 本文提出了一种新型的多机器人协调探索强化学习算法，通过内在奖励机制和双采样模式，显著提升了多机器人在社会形成导航任务中的性能，超越了现有先进方法。

Abstract: This paper investigates the application of reinforcement learning (RL) to multi-robot social formation navigation, a critical capability for enabling seamless human-robot coexistence. While RL offers a promising paradigm, the inherent unpredictability and often uncooperative dynamics of pedestrian behavior pose substantial challenges, particularly concerning the efficiency of coordinated exploration among robots. To address this, we propose a novel coordinated-exploration multi-robot RL algorithm introducing an intrinsic motivation exploration. Its core component is a self-learning intrinsic reward mechanism designed to collectively alleviate policy conservatism. Moreover, this algorithm incorporates a dual-sampling mode within the centralized training and decentralized execution framework to enhance the representation of both the navigation policy and the intrinsic reward, leveraging a two-time-scale update rule to decouple parameter updates. Empirical results on social formation navigation benchmarks demonstrate the proposed algorithm's superior performance over existing state-of-the-art methods across crucial metrics. Our code and video demos are available at: https://github.com/czxhunzi/CEMRRL.

</details>


### [376] [Humanoid Robot Running Through Random Stepping Stones and Jumping Over Obstacles: Step Adaptation Using Spring-Mass Trajectories](https://arxiv.org/abs/2512.13304)
*Sait Sovukluk,Johannes Englsberger,Christian Ott*

Main category: cs.RO

TL;DR: 该研究提出了一种基于弹簧-质量轨迹和死区控制增益库的步态适应框架，展示了其在复杂动态环境中的鲁棒性和包容性。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一个能够应对复杂动态环境的步态适应框架，支持人形机器人在各种挑战性场景下实现敏捷行为。

Method: 框架包括四个主要部分：自动生成弹簧-质量轨迹库、通过主动控制模板模型生成死区控制增益库、开发步态适应的轨迹选择策略，以及通过全身控制框架将弹簧-质量轨迹映射到人形模型。

Result: 在MuJoCo物理模拟器中成功实现了随机生成的步态、跳跃障碍、绕桩运动、突然转向和抗干扰等行为，且所有行为均使用单一库和相同的控制参数完成。

Conclusion: 该研究提出的步态适应框架通过弹簧-质量轨迹和死区控制增益库展示了其包容性和鲁棒性，能够应对各种挑战性和敏捷行为，且在多种不确定性和噪声条件下表现稳定。

Abstract: This study proposes a step adaptation framework for running through spring-mass trajectories and deadbeat control gain libraries. It includes four main parts: (1) Automatic spring-mass trajectory library generation; (2) Deadbeat control gain library generation through an actively controlled template model that resembles the whole-body dynamics well; (3) Trajectory selection policy development for step adaptation; (4) Mapping spring-mass trajectories to a humanoid model through a whole-body control (WBC) framework also accounting for closed-kinematic chain systems, self collisions, and reactive limb swinging. We show the inclusiveness and the robustness of the proposed framework through various challenging and agile behaviors such as running through randomly generated stepping stones, jumping over random obstacles, performing slalom motions, changing the running direction suddenly with a random leg, and rejecting significant disturbances and uncertainties through the MuJoCo physics simulator. We also perform additional simulations under a comprehensive set of uncertainties and noise to better justify the proposed method's robustness to real-world challenges, including signal noise, imprecision, modeling errors, and delays. All the aforementioned behaviors are performed with a single library and the same set of WBC control parameters without additional tuning. The spring-mass and the deadbeat control gain library are automatically computed in 4.5 seconds in total for 315 different trajectories.

</details>


### [377] [Control of a Twin Rotor using Twin Delayed Deep Deterministic Policy Gradient (TD3)](https://arxiv.org/abs/2512.13356)
*Zeyad Gamal,Youssef Mahran,Ayman El-Badawy*

Main category: cs.RO

TL;DR: 论文提出了一种基于TD3算法的强化学习框架，用于控制TRAS系统，仿真和实验验证了其优于传统PID控制器的性能。


<details>
  <summary>Details</summary>
Motivation: TRAS系统的复杂动力学和非线性特性使其难以用传统控制算法控制，而强化学习在多旋翼控制中的潜在应用激发了研究兴趣。

Method: 使用Twin Delayed Deep Deterministic Policy Gradient (TD3)算法训练强化学习代理，适用于连续状态和动作空间的环境。

Result: 仿真和实验结果表明，RL控制方法在稳定TRAS系统和跟踪轨迹方面有效，且对外部干扰（如风扰动）具有鲁棒性。

Conclusion: 论文通过仿真和实验验证了基于强化学习的控制方法在TRAS系统中的有效性，尤其是在存在外部干扰的情况下，其性能优于传统PID控制器。

Abstract: This paper proposes a reinforcement learning (RL) framework for controlling and stabilizing the Twin Rotor Aerodynamic System (TRAS) at specific pitch and azimuth angles and tracking a given trajectory. The complex dynamics and non-linear characteristics of the TRAS make it challenging to control using traditional control algorithms. However, recent developments in RL have attracted interest due to their potential applications in the control of multirotors. The Twin Delayed Deep Deterministic Policy Gradient (TD3) algorithm was used in this paper to train the RL agent. This algorithm is used for environments with continuous state and action spaces, similar to the TRAS, as it does not require a model of the system. The simulation results illustrated the effectiveness of the RL control method. Next, external disturbances in the form of wind disturbances were used to test the controller's effectiveness compared to conventional PID controllers. Lastly, experiments on a laboratory setup were carried out to confirm the controller's effectiveness in real-world applications.

</details>


### [378] [Fast Policy Learning for 6-DOF Position Control of Underwater Vehicles](https://arxiv.org/abs/2512.13359)
*Sümer Tunçay,Alain Andres,Ignacio Carlucho*

Main category: cs.RO

TL;DR: GPU加速强化学习训练流程实现快速训练，首次在真实AUV中验证六自由度RL控制。


<details>
  <summary>Details</summary>
Motivation: 传统控制器在未建模动态或环境干扰下性能下降，强化学习虽强大但训练慢且仿真到现实的迁移具有挑战性。

Method: 采用JAX和MuJoCo-XLA（MJX）构建的GPU加速强化学习训练流程，通过联合JIT编译大规模并行物理模拟和学习更新，实现两分钟内的训练时间。

Result: 通过系统评估多种RL算法，展示了稳健的六自由度轨迹跟踪和有效干扰抑制。

Conclusion: 该研究首次在真实水下实验中展示了基于强化学习的AUV六自由度位置控制，验证了从仿真到现实的零样本策略迁移。

Abstract: Autonomous Underwater Vehicles (AUVs) require reliable six-degree-of-freedom (6-DOF) position control to operate effectively in complex and dynamic marine environments. Traditional controllers are effective under nominal conditions but exhibit degraded performance when faced with unmodeled dynamics or environmental disturbances. Reinforcement learning (RL) provides a powerful alternative but training is typically slow and sim-to-real transfer remains challenging. This work introduces a GPU-accelerated RL training pipeline built in JAX and MuJoCo-XLA (MJX). By jointly JIT-compiling large-scale parallel physics simulation and learning updates, we achieve training times of under two minutes.Through systematic evaluation of multiple RL algorithms, we show robust 6-DOF trajectory tracking and effective disturbance rejection in real underwater experiments, with policies transferred zero-shot from simulation. Our results provide the first explicit real-world demonstration of RL-based AUV position control across all six degrees of freedom.

</details>


### [379] [Universal Dexterous Functional Grasping via Demonstration-Editing Reinforcement Learning](https://arxiv.org/abs/2512.13380)
*Chuan Mao,Haoqi Yuan,Ziye Huang,Chaoyi Xu,Kai Ma,Zongqing Lu*

Main category: cs.RO

TL;DR: DemoFunGrasp improves dexterous functional grasping by factorizing conditions into style and affordance, using one-step demonstration editing for efficient RL, achieving strong generalization and sim-to-real performance.


<details>
  <summary>Details</summary>
Motivation: Fine-grained functional grasping, essential for downstream manipulation tasks, remains underexplored due to challenges like specifying goals and reward functions for diverse objects, multi-task RL exploration difficulty, and sim-to-real transfer challenges.

Method: The authors propose DemoFunGrasp, which factorizes functional grasping conditions into grasping style and affordance, integrating them into an RL framework. They leverage a single grasping demonstration and reformulate the RL problem as one-step demonstration editing to enhance sample efficiency and performance.

Result: Experimental results in simulation and the real world show that DemoFunGrasp generalizes well to unseen object, affordance, and grasping style combinations, outperforming baselines in success rate and functional grasping accuracy.

Conclusion: DemoFunGrasp demonstrates strong generalization to unseen combinations of objects, affordances, and grasping styles, outperforming baselines in success rate and functional grasping accuracy. It also shows robust sim-to-real capability and achieves autonomous instruction-following grasp execution by incorporating a vision-language model (VLM).

Abstract: Reinforcement learning (RL) has achieved great success in dexterous grasping, significantly improving grasp performance and generalization from simulation to the real world. However, fine-grained functional grasping, which is essential for downstream manipulation tasks, remains underexplored and faces several challenges: the complexity of specifying goals and reward functions for functional grasps across diverse objects, the difficulty of multi-task RL exploration, and the challenge of sim-to-real transfer. In this work, we propose DemoFunGrasp for universal dexterous functional grasping. We factorize functional grasping conditions into two complementary components - grasping style and affordance - and integrate them into an RL framework that can learn to grasp any object with any functional grasping condition. To address the multi-task optimization challenge, we leverage a single grasping demonstration and reformulate the RL problem as one-step demonstration editing, substantially enhancing sample efficiency and performance. Experimental results in both simulation and the real world show that DemoFunGrasp generalizes to unseen combinations of objects, affordances, and grasping styles, outperforming baselines in both success rate and functional grasping accuracy. In addition to strong sim-to-real capability, by incorporating a vision-language model (VLM) for planning, our system achieves autonomous instruction-following grasp execution.

</details>


### [380] [Evaluating the Navigation Capabilities of a Modified COAST Guidewire Robot in an Anatomical Phantom Model](https://arxiv.org/abs/2512.13477)
*Timothy A. Brumfiel,Revanth Konda,Drew Elliott,Jaydev P. Desai*

Main category: cs.RO

TL;DR: A simplified two-tube COAST guidewire robot effectively navigates tortuous phantom vasculature, demonstrating potential for endovascular interventions.


<details>
  <summary>Details</summary>
Motivation: To address the challenges of manual guidewire navigation in endovascular interventions by developing a robotically steerable guidewire with enhanced maneuverability.

Method: The study evaluates the performance of a simplified two-tube version of the COAST guidewire robot through navigation experiments in an anatomical phantom model with pulsatile flow.

Result: The modified COAST guidewire robot successfully navigates the tortuous phantom vasculature, proving its capability.

Conclusion: The modified COAST guidewire robot demonstrates effectiveness in navigating tortuous phantom vasculature, showcasing its potential for endovascular interventions.

Abstract: To address the issues that arise due to the manual navigation of guidewires in endovascular interventions, research in medical robotics has taken a strong interest in developing robotically steerable guidewires, which offer the possibility of enhanced maneuverability and navigation, as the tip of the guidewire can be actively steered. The COaxially Aligned STeerable (COAST) guidewire robot has the ability to generate a wide variety of motions including bending motion with different bending lengths, follow-the-leader motion, and feedforward motion. In our past studies, we have explored different designs of the COAST guidewire robot and developed modeling, control, and sensing strategies for the COAST guidewire robot. In this study, the performance of a modified COAST guidewire robot is evaluated by conducting navigation experiments in an anatomical phantom model with pulsatile flow. The modified COAST guidewire robot is a simplified version of the COAST guidewire robot and consists of two tubes as opposed to three tubes. Through this study, we demonstrate the effectiveness of the modified COAST guidewire robot in navigating the tortuous phantom vasculature.

</details>


### [381] [Reinforcement Learning based 6-DoF Maneuvers for Microgravity Intravehicular Docking: A Simulation Study with Int-Ball2 in ISS-JEM](https://arxiv.org/abs/2512.13514)
*Aman Arora,Matteo El-Hariry,Miguel Olivares-Mendez*

Main category: cs.RO

TL;DR: 该论文提出了一种基于强化学习的6自由度对接框架，用于JAXA的Int-Ball2机器人在微重力环境中的高保真模拟，通过PPO训练实现了稳定对接，并探讨了推进物理对性能的影响。


<details>
  <summary>Details</summary>
Motivation: 在国际空间站（ISS）内，自主飞行器在感知噪声、微小驱动失配和环境变化下的精确对接仍是一个重要挑战。

Method: 使用近端策略优化（PPO）在Isaac Sim高保真模型中训练和评估控制器，结合领域随机化动力学和有界观测噪声，并明确建模螺旋桨拖曳扭矩效应和极性结构。

Result: 学习的策略在各种条件下实现了稳定可靠的对接。

Conclusion: 该研究通过强化学习框架成功实现了Int-Ball2机器人在微重力环境下的稳定对接，为未来在碰撞感知导航、安全RL、精确的模拟到现实转移及基于视觉的端到端对接等领域的扩展奠定了基础。

Abstract: Autonomous free-flyers play a critical role in intravehicular tasks aboard the International Space Station (ISS), where their precise docking under sensing noise, small actuation mismatches, and environmental variability remains a nontrivial challenge. This work presents a reinforcement learning (RL) framework for six-degree-of-freedom (6-DoF) docking of JAXA's Int-Ball2 robot inside a high-fidelity Isaac Sim model of the Japanese Experiment Module (JEM). Using Proximal Policy Optimization (PPO), we train and evaluate controllers under domain-randomized dynamics and bounded observation noise, while explicitly modeling propeller drag-torque effects and polarity structure. This enables a controlled study of how Int-Ball2's propulsion physics influence RL-based docking performance in constrained microgravity interiors. The learned policy achieves stable and reliable docking across varied conditions and lays the groundwork for future extensions pertaining to Int-Ball2 in collision-aware navigation, safe RL, propulsion-accurate sim-to-real transfer, and vision-based end-to-end docking.

</details>


### [382] [Near-Field Perception for Safety Enhancement of Autonomous Mobile Robots in Manufacturing Environments](https://arxiv.org/abs/2512.13561)
*Li-Wei Shih,Ruo-Syuan Mei,Jesse Heidrich,Hui-Ping Wang,Joel Hooton,Joshua Solomon,Jorge Arinez,Guangze Li,Chenhui Shao*

Main category: cs.RO

TL;DR: A three-tier near-field perception framework for AMRs combines light-discontinuity detection, light-displacement measurement, and computer vision, achieving real-time performance on Raspberry Pi 5.


<details>
  <summary>Details</summary>
Motivation: Conventional sensors like LiDAR and ultrasonic devices often fail to detect small objects near the robot base, necessitating a more robust near-field perception solution.

Method: The framework includes light-discontinuity detection for obstacle presence, light-displacement measurement for obstacle height estimation, and computer vision-based object detection for semantic perception. All methods are implemented on a Raspberry Pi 5 system.

Result: The framework achieves real-time performance at 25 or 50 frames per second, demonstrating a balance of precision, computation, and cost.

Conclusion: The proposed three-tier near-field perception framework effectively balances precision, computation, and cost, providing a scalable solution for safe AMR operations in manufacturing environments.

Abstract: Near-field perception is essential for the safe operation of autonomous mobile robots (AMRs) in manufacturing environments. Conventional ranging sensors such as light detection and ranging (LiDAR) and ultrasonic devices provide broad situational awareness but often fail to detect small objects near the robot base. To address this limitation, this paper presents a three-tier near-field perception framework. The first approach employs light-discontinuity detection, which projects a laser stripe across the near-field zone and identifies interruptions in the stripe to perform fast, binary cutoff sensing for obstacle presence. The second approach utilizes light-displacement measurement to estimate object height by analyzing the geometric displacement of a projected stripe in the camera image, which provides quantitative obstacle height information with minimal computational overhead. The third approach employs a computer vision-based object detection model on embedded AI hardware to classify objects, enabling semantic perception and context-aware safety decisions. All methods are implemented on a Raspberry Pi 5 system, achieving real-time performance at 25 or 50 frames per second. Experimental evaluation and comparative analysis demonstrate that the proposed hierarchy balances precision, computation, and cost, thereby providing a scalable perception solution for enabling safe operations of AMRs in manufacturing environments.

</details>


### [383] [World Models Can Leverage Human Videos for Dexterous Manipulation](https://arxiv.org/abs/2512.13644)
*Raktim Gautam Goswami,Amir Bar,David Fan,Tsung-Yen Yang,Gaoyue Zhou,Prashanth Krishnamurthy,Michael Rabbat,Farshad Khorrami,Yann LeCun*

Main category: cs.RO

TL;DR: DexWM通过手部一致性损失和大量视频数据训练，显著提升灵巧操作预测和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 灵巧操作需要理解手部细微动作如何通过物体接触影响环境，但缺乏相关数据集。DexWM旨在解决这一问题。

Method: DexWM是一个灵巧操作世界模型，通过预测环境的下一个潜在状态来训练。模型结合了视觉特征预测和手部一致性损失，以提升灵巧性。

Result: DexWM在预测未来状态方面优于现有世界模型，并在零样本任务中平均超过Diffusion Policy 50%以上。

Conclusion: DexWM通过引入辅助手部一致性损失和利用大量非灵巧机器人视频数据，显著提升了灵巧操作的预测准确性，并在零样本泛化任务中表现出色。

Abstract: Dexterous manipulation is challenging because it requires understanding how subtle hand motion influences the environment through contact with objects. We introduce DexWM, a Dexterous Manipulation World Model that predicts the next latent state of the environment conditioned on past states and dexterous actions. To overcome the scarcity of dexterous manipulation datasets, DexWM is trained on over 900 hours of human and non-dexterous robot videos. To enable fine-grained dexterity, we find that predicting visual features alone is insufficient; therefore, we introduce an auxiliary hand consistency loss that enforces accurate hand configurations. DexWM outperforms prior world models conditioned on text, navigation, and full-body actions, achieving more accurate predictions of future states. DexWM also demonstrates strong zero-shot generalization to unseen manipulation skills when deployed on a Franka Panda arm equipped with an Allegro gripper, outperforming Diffusion Policy by over 50% on average in grasping, placing, and reaching tasks.

</details>


### [384] [RoboTracer: Mastering Spatial Trace with Reasoning in Vision-Language Models for Robotics](https://arxiv.org/abs/2512.13660)
*Enshen Zhou,Cheng Chi,Yibo Li,Jingkun An,Jiayuan Zhang,Shanyu Rong,Yi Han,Yuheng Ji,Mengzhen Liu,Pengwei Wang,Zhongyuan Wang,Lu Sheng,Shanghang Zhang*

Main category: cs.RO

TL;DR: RoboTracer是一种3D感知的VLM，通过创新的训练方法和数据集，显著提升了机器人在空间追踪任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的方法在空间追踪这一复合任务中表现不佳，特别是在多步度量基础推理和复杂空间参考方面存在挑战。

Method: RoboTracer结合了通用的空间编码器和回归监督解码器，通过监督微调（SFT）增强尺度感知，并通过强化微调（RFT）和度量敏感的过程奖励推进多步度量基础推理。

Result: RoboTracer在空间理解、测量和参考方面的平均成功率达到79.1%，并在TraceSpatial-Bench上以36%的准确率优势超过Gemini-2.5-Pro。

Conclusion: RoboTracer通过其3D感知的视觉语言模型（VLM）和创新的训练方法，显著提升了机器人在空间追踪任务中的表现，能够执行复杂的长时程动态任务。

Abstract: Spatial tracing, as a fundamental embodied interaction ability for robots, is inherently challenging as it requires multi-step metric-grounded reasoning compounded with complex spatial referring and real-world metric measurement. However, existing methods struggle with this compositional task. To this end, we propose RoboTracer, a 3D-aware VLM that first achieves both 3D spatial referring and measuring via a universal spatial encoder and a regression-supervised decoder to enhance scale awareness during supervised fine-tuning (SFT). Moreover, RoboTracer advances multi-step metric-grounded reasoning via reinforcement fine-tuning (RFT) with metric-sensitive process rewards, supervising key intermediate perceptual cues to accurately generate spatial traces. To support SFT and RFT training, we introduce TraceSpatial, a large-scale dataset of 30M QA pairs, spanning outdoor/indoor/tabletop scenes and supporting complex reasoning processes (up to 9 steps). We further present TraceSpatial-Bench, a challenging benchmark filling the gap to evaluate spatial tracing. Experimental results show that RoboTracer surpasses baselines in spatial understanding, measuring, and referring, with an average success rate of 79.1%, and also achieves SOTA performance on TraceSpatial-Bench by a large margin, exceeding Gemini-2.5-Pro by 36% accuracy. Notably, RoboTracer can be integrated with various control policies to execute long-horizon, dynamic tasks across diverse robots (UR5, G1 humanoid) in cluttered real-world scenes.

</details>


### [385] [NL2SpaTiaL: Generating Geometric Spatio-Temporal Logic Specifications from Natural Language for Manipulation Tasks](https://arxiv.org/abs/2512.13670)
*Licheng Luo,Yu Xia,Kaier Liang,Mingyu Cai*

Main category: cs.RO

TL;DR: The paper introduces a framework to generate SpaTiaL specifications and natural-language descriptions, addressing the gap in representing spatial relations for robotic manipulation, and demonstrates its effectiveness in improving task grounding.


<details>
  <summary>Details</summary>
Motivation: Prior works relied on standard temporal logic (TL) which overlooks object-level interactions, failing to represent the layered spatial relations crucial for manipulation tasks. This gap is addressed by developing a framework that aligns natural language with multi-level spatial relations and temporal objectives.

Method: The paper introduces a dataset generation framework that synthesizes SpaTiaL specifications and converts them into natural-language descriptions via a deterministic, semantics-preserving back-translation procedure, resulting in the NL2SpaTiaL dataset. It also proposes a translation-verification framework with a language-based semantic checker to ensure SpaTiaL formulas accurately encode input descriptions.

Result: The NL2SpaTiaL dataset and the proposed framework effectively capture the compositional structure of manipulation tasks, enhancing interpretability and verifiability.

Conclusion: SpaTiaL-based representations provide more interpretable, verifiable, and compositional grounding for robotic manipulation tasks, as demonstrated by experiments across various tasks.

Abstract: Spatio-Temporal Logic (SpaTiaL) offers a principled formalism for expressing geometric spatial requirements-an essential component of robotic manipulation, where object locations, neighborhood relations, pose constraints, and interactions directly determine task success. Yet prior works have largely relied on standard temporal logic (TL), which models only robot trajectories and overlooks object-level interactions. Existing datasets built from randomly generated TL formulas paired with natural-language descriptions therefore cover temporal operators but fail to represent the layered spatial relations that manipulation tasks depend on. To address this gap, we introduce a dataset generation framework that synthesizes SpaTiaL specifications and converts them into natural-language descriptions through a deterministic, semantics-preserving back-translation procedure. This pipeline produces the NL2SpaTiaL dataset, aligning natural language with multi-level spatial relations and temporal objectives to reflect the compositional structure of manipulation tasks. Building on this foundation, we propose a translation-verification framework equipped with a language-based semantic checker that ensures the generated SpaTiaL formulas faithfully encode the semantics specified by the input description. Experiments across a suite of manipulation tasks show that SpaTiaL-based representations yield more interpretable, verifiable, and compositional grounding for instruction following. Project website: https://sites.google.com/view/nl2spatial

</details>
