<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 113]
- [cs.DC](#cs.DC) [Total: 11]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.DS](#cs.DS) [Total: 5]
- [cs.AI](#cs.AI) [Total: 57]
- [cs.OS](#cs.OS) [Total: 1]
- [cs.RO](#cs.RO) [Total: 22]
- [cs.SE](#cs.SE) [Total: 11]
- [cs.NI](#cs.NI) [Total: 4]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Two-Step Data Augmentation for Masked Face Detection and Recognition: Turning Fake Masks to Real](https://arxiv.org/abs/2512.15774)
*Yan Yang,George Bebis,Mircea Nicolescu*

Main category: cs.CV

TL;DR: 两步生成数据增强框架结合规则掩膜变形和GAN，提升掩膜人脸检测和识别的数据多样性及真实性。


<details>
  <summary>Details</summary>
Motivation: 数据稀缺和分布偏移是掩膜人脸检测和识别的主要挑战，需要一种超越纯合成变换的生成真实掩膜人脸样本的方法。

Method: 采用规则掩膜变形与GAN无配对图像转换相结合的两步生成数据增强框架，引入非掩膜保留损失和随机噪声注入以稳定训练并增强样本多样性。

Result: 相比仅基于规则变形的方法，所提方法在定性上表现一致提升，并补充了现有GAN掩膜人脸生成方法（如IAMGAN）。

Conclusion: 论文提出了一种结合规则掩膜变形和GAN无配对图像转换的两步生成数据增强框架，有效提升了掩膜人脸检测和识别的性能，并指出了未来数据中心增强的研究方向。

Abstract: Data scarcity and distribution shift pose major challenges for masked face detection and recognition. We propose a two-step generative data augmentation framework that combines rule-based mask warping with unpaired image-to-image translation using GANs, enabling the generation of realistic masked-face samples beyond purely synthetic transformations. Compared to rule-based warping alone, the proposed approach yields consistent qualitative improvements and complements existing GAN-based masked face generation methods such as IAMGAN. We introduce a non-mask preservation loss and stochastic noise injection to stabilize training and enhance sample diversity. Experimental observations highlight the effectiveness of the proposed components and suggest directions for future improvements in data-centric augmentation for face recognition tasks.

</details>


### [2] [Seeing Beyond Words: Self-Supervised Visual Learning for Multimodal Large Language Models](https://arxiv.org/abs/2512.15885)
*Davide Caffagni,Sara Sarto,Marcella Cornia,Lorenzo Baraldi,Pier Luigi Dovesi,Shaghayegh Roohi,Mark Granroth-Wilding,Rita Cucchiara*

Main category: cs.CV

TL;DR: JARVIS框架通过自监督视觉增强解决MLLMs视觉理解不足的问题，提升视觉任务表现而不损害多模态能力。


<details>
  <summary>Details</summary>
Motivation: MLLMs在基础视觉推理任务中的表现受限，主要因为其视觉理解依赖于主观且不完整的文本描述，且多模态指令调优规模较小导致过拟合语言先验。

Method: 将I-JEPA学习范式整合到MLLMs的标准视觉-语言对齐流程中，利用冻结的视觉基础模型作为上下文和目标编码器，训练LLM的早期层作为预测器。

Result: 在标准MLLM基准测试中，JARVIS在不同LLM家族上均能提升视觉中心任务的性能，且不影响多模态推理能力。

Conclusion: JARVIS框架通过自监督视觉增强显著提升了MLLMs在视觉中心任务上的性能，同时保持了多模态推理能力。

Abstract: Multimodal Large Language Models (MLLMs) have recently demonstrated impressive capabilities in connecting vision and language, yet their proficiency in fundamental visual reasoning tasks remains limited. This limitation can be attributed to the fact that MLLMs learn visual understanding primarily from textual descriptions, which constitute a subjective and inherently incomplete supervisory signal. Furthermore, the modest scale of multimodal instruction tuning compared to massive text-only pre-training leads MLLMs to overfit language priors while overlooking visual details. To address these issues, we introduce JARVIS, a JEPA-inspired framework for self-supervised visual enhancement in MLLMs. Specifically, we integrate the I-JEPA learning paradigm into the standard vision-language alignment pipeline of MLLMs training. Our approach leverages frozen vision foundation models as context and target encoders, while training the predictor, implemented as the early layers of an LLM, to learn structural and semantic regularities from images without relying exclusively on language supervision. Extensive experiments on standard MLLM benchmarks show that JARVIS consistently improves performance on vision-centric benchmarks across different LLM families, without degrading multimodal reasoning abilities. Our source code is publicly available at: https://github.com/aimagelab/JARVIS.

</details>


### [3] [Using Gaussian Splats to Create High-Fidelity Facial Geometry and Texture](https://arxiv.org/abs/2512.16397)
*Haodi He,Jihun Yu,Ronald Fedkiw*

Main category: cs.CV

TL;DR: 通过高斯泼溅和三角化表面约束，从11张图像重建高质量人脸模型，并转化为可视图依赖的神经纹理，适用于标准图形流程。


<details>
  <summary>Details</summary>
Motivation: 解决传统方法需要大量视频数据的问题，提供一种从少量图像生成高质量、可编辑人脸模型的解决方案。

Method: 利用高斯泼溅技术结合分割注释和三角化表面约束，从11张未校准图像重建中性姿势人脸模型，并通过扰动提高三角化表面精度。

Result: 成功实现从少量图像生成高质量人脸模型，并转化为可视图依赖的神经纹理，适用于标准图形流程。

Conclusion: 该方法通过高斯泼溅和三角化表面重建，实现了从少量图像生成高质量人脸模型，并进一步转化为可视图依赖的神经纹理，适用于标准图形流程。

Abstract: We leverage increasingly popular three-dimensional neural representations in order to construct a unified and consistent explanation of a collection of uncalibrated images of the human face. Our approach utilizes Gaussian Splatting, since it is more explicit and thus more amenable to constraints than NeRFs. We leverage segmentation annotations to align the semantic regions of the face, facilitating the reconstruction of a neutral pose from only 11 images (as opposed to requiring a long video). We soft constrain the Gaussians to an underlying triangulated surface in order to provide a more structured Gaussian Splat reconstruction, which in turn informs subsequent perturbations to increase the accuracy of the underlying triangulated surface. The resulting triangulated surface can then be used in a standard graphics pipeline. In addition, and perhaps most impactful, we show how accurate geometry enables the Gaussian Splats to be transformed into texture space where they can be treated as a view-dependent neural texture. This allows one to use high visual fidelity Gaussian Splatting on any asset in a scene without the need to modify any other asset or any other aspect (geometry, lighting, renderer, etc.) of the graphics pipeline. We utilize a relightable Gaussian model to disentangle texture from lighting in order to obtain a delit high-resolution albedo texture that is also readily usable in a standard graphics pipeline. The flexibility of our system allows for training with disparate images, even with incompatible lighting, facilitating robust regularization. Finally, we demonstrate the efficacy of our approach by illustrating its use in a text-driven asset creation pipeline.

</details>


### [4] [City Navigation in the Wild: Exploring Emergent Navigation from Web-Scale Knowledge in MLLMs](https://arxiv.org/abs/2512.15933)
*Dwip Dalal,Utkarsh Mishra,Narendra Ahuja,Nebojsa Jojic*

Main category: cs.CV

TL;DR: 论文提出了Sparsely Grounded Visual Navigation任务和CityNav基准测试，评估MLLMs在知识密集型环境中的导航能力，并提出了VoP方法显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的评估基准大多以语言为中心或依赖模拟环境，缺乏对知识密集型推理的深入评估，无法满足实际复杂任务的需求。

Method: 论文引入了Sparsely Grounded Visual Navigation任务，并开发了CityNav基准测试，包含四个全球城市，用于评估MLLMs在知识密集型环境中的顺序决策能力。

Result: 实验表明，当前最先进的MLLMs和标准推理技术（如Chain-of-Thought、Reflection）在这一挑战性任务中表现不佳。

Conclusion: 论文提出了一种名为Verbalization of Path (VoP)的方法，通过显式地构建认知地图（关键地标和朝向目的地的方向）来增强MLLMs的导航能力，显著提高了导航成功率。

Abstract: Leveraging multimodal large language models (MLLMs) to develop embodied agents offers significant promise for addressing complex real-world tasks. However, current evaluation benchmarks remain predominantly language-centric or heavily reliant on simulated environments, rarely probing the nuanced, knowledge-intensive reasoning essential for practical, real-world scenarios. To bridge this critical gap, we introduce the task of Sparsely Grounded Visual Navigation, explicitly designed to evaluate the sequential decision-making abilities of MLLMs in challenging, knowledge-intensive real-world environments. We operationalize this task with CityNav, a comprehensive benchmark encompassing four diverse global cities, specifically constructed to assess raw MLLM-driven agents in city navigation. Agents are required to rely solely on visual inputs and internal multimodal reasoning to sequentially navigate 50+ decision points without additional environmental annotations or specialized architectural modifications. Crucially, agents must autonomously achieve localization through interpreting city-specific cues and recognizing landmarks, perform spatial reasoning, and strategically plan and execute routes to their destinations. Through extensive evaluations, we demonstrate that current state-of-the-art MLLMs and standard reasoning techniques (e.g., Chain-of-Thought, Reflection) significantly underperform in this challenging setting. To address this, we propose Verbalization of Path (VoP), which explicitly grounds the agent's internal reasoning by probing an explicit cognitive map (key landmarks and directions toward the destination) from the MLLMs, substantially enhancing navigation success. Project Webpage: https://dwipddalal.github.io/AgentNav/

</details>


### [5] [Multi-scale Attention-Guided Intrinsic Decomposition and Rendering Pass Prediction for Facial Images](https://arxiv.org/abs/2512.16511)
*Hossein Javidnia*

Main category: cs.CV

TL;DR: MAGINet通过多尺度注意力网络和轻量级细化网络，实现了高精度的面部本征分解，支持高质量重新光照和材质编辑。


<details>
  <summary>Details</summary>
Motivation: 无约束光照下的精确面部本征分解是光真实感重新光照、高保真数字替身和增强现实效果的前提。

Method: MAGINet采用分层残差编码、空间和通道注意力机制，以及自适应多尺度特征融合，结合RefinementNet和Pix2PixHD-based translator预测六种物理渲染通道。

Result: MAGINet在FFHQ-UV-Intrinsics数据集上实现了最先进的漫反射反照率估计，并显著提升了完整渲染堆栈的保真度。

Conclusion: MAGINet通过多尺度注意力引导的固有网络和轻量级RefinementNet，实现了高精度的面部图像本征分解，支持高质量的重新光照和材质编辑。

Abstract: Accurate intrinsic decomposition of face images under unconstrained lighting is a prerequisite for photorealistic relighting, high-fidelity digital doubles, and augmented-reality effects. This paper introduces MAGINet, a Multi-scale Attention-Guided Intrinsics Network that predicts a $512\times512$ light-normalized diffuse albedo map from a single RGB portrait. MAGINet employs hierarchical residual encoding, spatial-and-channel attention in a bottleneck, and adaptive multi-scale feature fusion in the decoder, yielding sharper albedo boundaries and stronger lighting invariance than prior U-Net variants. The initial albedo prediction is upsampled to $1024\times1024$ and refined by a lightweight three-layer CNN (RefinementNet). Conditioned on this refined albedo, a Pix2PixHD-based translator then predicts a comprehensive set of five additional physically based rendering passes: ambient occlusion, surface normal, specular reflectance, translucency, and raw diffuse colour (with residual lighting). Together with the refined albedo, these six passes form the complete intrinsic decomposition. Trained with a combination of masked-MSE, VGG, edge, and patch-LPIPS losses on the FFHQ-UV-Intrinsics dataset, the full pipeline achieves state-of-the-art performance for diffuse albedo estimation and demonstrates significantly improved fidelity for the complete rendering stack compared to prior methods. The resulting passes enable high-quality relighting and material editing of real faces.

</details>


### [6] [R4: Retrieval-Augmented Reasoning for Vision-Language Models in 4D Spatio-Temporal Space](https://arxiv.org/abs/2512.15940)
*Tin Stribor Sohn,Maximilian Dillitzer,Jason J. Corso,Eric Sax*

Main category: cs.CV

TL;DR: R4是一个无需训练的检索增强推理框架，通过构建4D时空知识库提升视觉语言模型在动态环境中的表现。


<details>
  <summary>Details</summary>
Motivation: 受人类多模态记忆能力的启发，旨在为视觉语言模型赋予结构化、终身记忆能力，以支持上下文依赖的推理。

Method: R4框架通过锚定对象级语义描述在度量空间和时间中，持续构建4D知识数据库，支持自然语言查询的语义、空间和时间键分解与检索。

Result: 在具身问答和导航基准测试中，R4在时空信息检索和推理方面显著优于基线方法。

Conclusion: R4框架通过构建4D时空知识库，显著提升了视觉语言模型在动态环境中的推理能力，为具身智能提供了新的范例。

Abstract: Humans perceive and reason about their surroundings in four dimensions by building persistent, structured internal representations that encode semantic meaning, spatial layout, and temporal dynamics. These multimodal memories enable them to recall past events, infer unobserved states, and integrate new information into context-dependent reasoning. Inspired by this capability, we introduce R4, a training-free framework for retrieval-augmented reasoning in 4D spatio-temporal space that equips vision-language models (VLMs) with structured, lifelong memory. R4 continuously constructs a 4D knowledge database by anchoring object-level semantic descriptions in metric space and time, yielding a persistent world model that can be shared across agents. At inference, natural language queries are decomposed into semantic, spatial, and temporal keys to retrieve relevant observations, which are integrated into the VLM's reasoning. Unlike classical retrieval-augmented generation methods, retrieval in R4 operates directly in 4D space, enabling episodic and collaborative reasoning without training. Experiments on embodied question answering and navigation benchmarks demonstrate that R4 substantially improves retrieval and reasoning over spatio-temporal information compared to baselines, advancing a new paradigm for embodied 4D reasoning in dynamic environments.

</details>


### [7] [FrameDiffuser: G-Buffer-Conditioned Diffusion for Neural Forward Frame Rendering](https://arxiv.org/abs/2512.16670)
*Ole Beisswenger,Jan-Niklas Dihlmann,Hendrik P. A. Lensch*

Main category: cs.CV

TL;DR: FrameDiffuser是一种自回归神经渲染框架，通过双重条件架构和三阶段训练，在交互式应用中生成时间一致、逼真的帧。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于扩散的方法在交互式应用中无法保证时间一致性和计算效率的问题。

Method: 采用自回归神经渲染框架，结合ControlNet提供结构指导和ControlLoRA保持时间一致性，通过三阶段训练策略实现稳定生成。

Result: FrameDiffuser能够生成时间一致、逼真的帧，且在特定环境中表现优于通用方法。

Conclusion: FrameDiffuser通过结合ControlNet和ControlLoRA的双重条件架构，以及三阶段训练策略，实现了在交互式应用中生成时间一致、逼真帧的能力，专用于特定环境以提升质量。

Abstract: Neural rendering for interactive applications requires translating geometric and material properties (G-buffer) to photorealistic images with realistic lighting on a frame-by-frame basis. While recent diffusion-based approaches show promise for G-buffer-conditioned image synthesis, they face critical limitations: single-image models like RGBX generate frames independently without temporal consistency, while video models like DiffusionRenderer are too computationally expensive for most consumer gaming sets ups and require complete sequences upfront, making them unsuitable for interactive applications where future frames depend on user input. We introduce FrameDiffuser, an autoregressive neural rendering framework that generates temporally consistent, photorealistic frames by conditioning on G-buffer data and the models own previous output. After an initial frame, FrameDiffuser operates purely on incoming G-buffer data, comprising geometry, materials, and surface properties, while using its previously generated frame for temporal guidance, maintaining stable, temporal consistent generation over hundreds to thousands of frames. Our dual-conditioning architecture combines ControlNet for structural guidance with ControlLoRA for temporal coherence. A three-stage training strategy enables stable autoregressive generation. We specialize our model to individual environments, prioritizing consistency and inference speed over broad generalization, demonstrating that environment-specific training achieves superior photorealistic quality with accurate lighting, shadows, and reflections compared to generalized approaches.

</details>


### [8] [The Perceptual Observatory Characterizing Robustness and Grounding in MLLMs](https://arxiv.org/abs/2512.15949)
*Tejas Anvekar,Fenil Bardoliya,Pavan K. Turaga,Chitta Baral,Vivek Gupta*

Main category: cs.CV

TL;DR: 该论文提出了The Perceptual Observatory框架，用于系统性评估多模态大语言模型在视觉感知任务中的表现，揭示其在扰动下的能力与不足。


<details>
  <summary>Details</summary>
Motivation: 当前MLLMs的视觉感知能力缺乏系统性评估，大多数模型仅通过扩展语言组件而忽视视觉编码器的改进，引发了对模型是否真正具备视觉基础能力的质疑。

Method: 通过构建包含简单视觉任务、局部到全局理解等垂直领域的评估框架，并利用真实数据集和系统化的像素增强及扩散式风格化幻觉扰动，对MLLMs进行全面测试。

Result: The Perceptual Observatory 能够揭示MLLMs在扰动下的感知能力和局限性，为模型的优缺点分析提供了理论基础。

Conclusion: The Perceptual Observatory 提供了一个系统化的框架，用于评估多模态大语言模型（MLLMs）在视觉感知任务中的表现，揭示了模型在扰动下的感知能力和局限性，为未来模型的改进提供了理论基础。

Abstract: Recent advances in multimodal large language models (MLLMs) have yielded increasingly powerful models, yet their perceptual capacities remain poorly characterized. In practice, most model families scale language component while reusing nearly identical vision encoders (e.g., Qwen2.5-VL 3B/7B/72B), which raises pivotal concerns about whether progress reflects genuine visual grounding or reliance on internet-scale textual world knowledge. Existing evaluation methods emphasize end-task accuracy, overlooking robustness, attribution fidelity, and reasoning under controlled perturbations. We present The Perceptual Observatory, a framework that characterizes MLLMs across verticals like: (i) simple vision tasks, such as face matching and text-in-vision comprehension capabilities; (ii) local-to-global understanding, encompassing image matching, grid pointing game, and attribute localization, which tests general visual grounding. Each vertical is instantiated with ground-truth datasets of faces and words, systematically perturbed through pixel-based augmentations and diffusion-based stylized illusions. The Perceptual Observatory moves beyond leaderboard accuracy to yield insights into how MLLMs preserve perceptual grounding and relational structure under perturbations, providing a principled foundation for analyzing strengths and weaknesses of current and future models.

</details>


### [9] [SDFoam: Signed-Distance Foam for explicit surface reconstruction](https://arxiv.org/abs/2512.16706)
*Antonella Rech,Nicola Conci,Nicola Garau*

Main category: cs.CV

TL;DR: SDFoam结合显式Voronoi图和隐式SDF，优化网格重建准确性，保持高效和视觉质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如NeRF、3DGS、RadiantFoam）在精确网格重建方面仍存在不足，需要一种能同时保持高效和高质量的方法。

Method: 联合学习显式Voronoi图和隐式SDF，通过光线追踪优化场景，并通过Eikonal目标进行正则化。

Result: SDFoam在多样场景中显著改善了网格重建准确性（Chamfer距离），同时保持了相当的视觉质量（PSNR、SSIM）和效率。

Conclusion: SDFoam通过结合显式Voronoi图和隐式SDF，显著提高了网格重建的准确性，同时保持了与RadiantFoam相当的训练速度和渲染质量。

Abstract: Neural radiance fields (NeRF) have driven impressive progress in view synthesis by using ray-traced volumetric rendering. Splatting-based methods such as 3D Gaussian Splatting (3DGS) provide faster rendering by rasterizing 3D primitives. RadiantFoam (RF) brought ray tracing back, achieving throughput comparable to Gaussian Splatting by organizing radiance with an explicit Voronoi Diagram (VD). Yet, all the mentioned methods still struggle with precise mesh reconstruction. We address this gap by jointly learning an explicit VD with an implicit Signed Distance Field (SDF). The scene is optimized via ray tracing and regularized by an Eikonal objective. The SDF introduces metric-consistent isosurfaces, which, in turn, bias near-surface Voronoi cell faces to align with the zero level set. The resulting model produces crisper, view-consistent surfaces with fewer floaters and improved topology, while preserving photometric quality and maintaining training speed on par with RadiantFoam. Across diverse scenes, our hybrid implicit-explicit formulation, which we name SDFoam, substantially improves mesh reconstruction accuracy (Chamfer distance) with comparable appearance (PSNR, SSIM), without sacrificing efficiency.

</details>


### [10] [Seeing is Believing (and Predicting): Context-Aware Multi-Human Behavior Prediction with Vision Language Models](https://arxiv.org/abs/2512.15957)
*Utsav Panchal,Yuchen Liu,Luigi Palmieri,Ilche Georgievski,Marco Aiello*

Main category: cs.CV

TL;DR: CAMP-VLM是一个基于视觉语言模型的框架，通过结合上下文特征和空间感知，显著提升了多人类行为预测的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要集中在单人类行为的自我中心视角预测，而多人类行为的第三方视角预测在机器人应用中同样重要。

Method: 提出了CAMP-VLM框架，利用视觉输入和场景图的上下文特征，通过监督微调（SFT）和直接偏好优化（DPO）进行模型训练。

Result: CAMP-VLM在预测准确率上比最佳基线模型高出66.9%。

Conclusion: CAMP-VLM通过结合视觉语言模型和场景图的空间感知能力，显著提升了多人类行为预测的准确性，并在合成和真实世界数据上展示了良好的泛化能力。

Abstract: Accurately predicting human behaviors is crucial for mobile robots operating in human-populated environments. While prior research primarily focuses on predicting actions in single-human scenarios from an egocentric view, several robotic applications require understanding multiple human behaviors from a third-person perspective. To this end, we present CAMP-VLM (Context-Aware Multi-human behavior Prediction): a Vision Language Model (VLM)-based framework that incorporates contextual features from visual input and spatial awareness from scene graphs to enhance prediction of humans-scene interactions. Due to the lack of suitable datasets for multi-human behavior prediction from an observer view, we perform fine-tuning of CAMP-VLM with synthetic human behavior data generated by a photorealistic simulator, and evaluate the resulting models on both synthetic and real-world sequences to assess their generalization capabilities. Leveraging Supervised Fine-Tuning (SFT) and Direct Preference Optimization (DPO), CAMP-VLM outperforms the best-performing baseline by up to 66.9% in prediction accuracy.

</details>


### [11] [From Words to Wavelengths: VLMs for Few-Shot Multispectral Object Detection](https://arxiv.org/abs/2512.15971)
*Manuel Nkegoum,Minh-Tan Pham,Élisa Fromont,Bruno Avignon,Sébastien Lefèvre*

Main category: cs.CV

TL;DR: 本文探索了视觉语言模型（VLMs）在小样本多光谱目标检测中的潜力，通过调整现有VLM-based检测器并整合多模态信息，在数据稀缺和完全监督情况下均取得了优异表现。


<details>
  <summary>Details</summary>
Motivation: 在多光谱数据标注稀缺的情况下，文本类别信息可以作为语义监督的有价值来源。

Method: 我们调整了两个代表性的基于VLM的检测器（Grounding DINO和YOLO-World）以处理多光谱输入，并提出了一种有效机制来整合文本、视觉和热模态。

Result: 在FLIR和M3FD两个流行的多光谱图像基准上，VLM-based检测器不仅在小样本情况下显著优于专门的多光谱模型，而且在完全监督设置下也达到了竞争性或更优的结果。

Conclusion: 大型视觉语言模型（VLMs）的语义先验知识能够有效迁移到未见过的光谱模态，为数据高效的多光谱感知提供了强大途径。

Abstract: Multispectral object detection is critical for safety-sensitive applications such as autonomous driving and surveillance, where robust perception under diverse illumination conditions is essential. However, the limited availability of annotated multispectral data severely restricts the training of deep detectors. In such data-scarce scenarios, textual class information can serve as a valuable source of semantic supervision. Motivated by the recent success of Vision-Language Models (VLMs) in computer vision, we explore their potential for few-shot multispectral object detection. Specifically, we adapt two representative VLM-based detectors, Grounding DINO and YOLO-World, to handle multispectral inputs and propose an effective mechanism to integrate text, visual and thermal modalities. Through extensive experiments on two popular multispectral image benchmarks, FLIR and M3FD, we demonstrate that VLM-based detectors not only excel in few-shot regimes, significantly outperforming specialized multispectral models trained with comparable data, but also achieve competitive or superior results under fully supervised settings. Our findings reveal that the semantic priors learned by large-scale VLMs effectively transfer to unseen spectral modalities, ofFering a powerful pathway toward data-efficient multispectral perception.

</details>


### [12] [Are vision-language models ready to zero-shot replace supervised classification models in agriculture?](https://arxiv.org/abs/2512.15977)
*Earl Ranario,Mason J. Earles*

Main category: cs.CV

TL;DR: 研究评估了VLM在农业分类任务中的表现，发现其性能不及监督基线，但在受限条件下可作为辅助工具。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉语言模型（VLM）被广泛提议为视觉识别任务的通用解决方案，但其在农业决策支持中的可靠性仍未被充分理解。

Method: 研究对来自AgML集合的27个农业分类数据集（涵盖162个类别，包括植物病害、害虫和损害、植物和杂草物种识别）进行基准测试，比较了多种开源和闭源VLM的性能。

Result: 零样本VLM在所有任务中表现显著低于监督任务特定基线（YOLO11）。在多选提示下，最佳VLM（Gemini-3 Pro）的平均准确率约为62%，而开放式提示的性能更低（通常低于25%）。LLM基于语义判断提高了开放式准确率（例如，从21%提升至30%）。开源模型中，Qwen-VL-72B表现最佳，接近闭源模型在受限提示下的性能。任务级别分析显示，植物和杂草物种分类比害虫和损害识别更容易。

Conclusion: 当前的现成视觉语言模型（VLM）尚不适合作为独立的农业诊断系统，但在与受限接口、明确标签本体和领域感知评估策略结合时，可以作为辅助组件发挥作用。

Abstract: Vision-language models (VLMs) are increasingly proposed as general-purpose solutions for visual recognition tasks, yet their reliability for agricultural decision support remains poorly understood. We benchmark a diverse set of open-source and closed-source VLMs on 27 agricultural classification datasets from the AgML collection, spanning 162 classes across plant disease, pest and damage, and plant and weed species identification. Across all tasks, zero-shot VLMs substantially underperform a supervised task-specific baseline (YOLO11), which consistently achieves markedly higher accuracy than any foundation model. Under multiple-choice prompting, the best-performing VLM (Gemini-3 Pro) reaches approximately 62% average accuracy, while open-ended prompting yields much lower performance, with raw accuracies typically below 25%. Applying LLM-based semantic judging increases open-ended accuracy (for example, from 21% to 30% for top models) and alters model rankings, demonstrating that evaluation methodology meaningfully affects reported conclusions. Among open-source models, Qwen-VL-72B performs best, approaching closed-source performance under constrained prompting but still trailing top proprietary systems. Task-level analysis shows that plant and weed species classification is consistently easier than pest and damage identification, which remains the most challenging category across models. Overall, these results indicate that current off-the-shelf VLMs are not yet suitable as standalone agricultural diagnostic systems, but can function as assistive components when paired with constrained interfaces, explicit label ontologies, and domain-aware evaluation strategies.

</details>


### [13] [Eyes on the Grass: Biodiversity-Increasing Robotic Mowing Using Deep Visual Embeddings](https://arxiv.org/abs/2512.15993)
*Lars Beckers,Arno Waes,Aaron Van Campenhout,Toon Goedemé*

Main category: cs.CV

TL;DR: 该论文提出了一种机器人割草框架，通过深度视觉分析选择性保护植被多样性，实验证明其能有效提升花园生物多样性。


<details>
  <summary>Details</summary>
Motivation: 论文的动机是通过主动的视觉感知和自适应决策，增强花园的生物多样性，而不仅仅是被动的自然恢复方法。

Method: 论文采用的方法包括使用预训练的ResNet50网络（基于PlantNet300K）进行深度特征空间分析，以识别和保护视觉上多样化的植被区域，并通过全局偏差度量估计生物多样性，无需物种级监督。这些估计驱动选择性割草算法，动态切换割草和保护行为。

Result: 结果表明，嵌入空间分散与专家生物多样性评估之间存在强相关性，证实了深度视觉多样性作为生态丰富性代理的可行性，以及所提出的割草决策方法的有效性。

Conclusion: 该论文的结论是，通过提出的机器人割草框架，可以有效地将生态价值低的单一草坪转变为丰富且有价值的生物群落，从而提升城市生物多样性。

Abstract: This paper presents a robotic mowing framework that actively enhances garden biodiversity through visual perception and adaptive decision-making. Unlike passive rewilding approaches, the proposed system uses deep feature-space analysis to identify and preserve visually diverse vegetation patches in camera images by selectively deactivating the mower blades. A ResNet50 network pretrained on PlantNet300K provides ecologically meaningful embeddings, from which a global deviation metric estimates biodiversity without species-level supervision. These estimates drive a selective mowing algorithm that dynamically alternates between mowing and conservation behavior. The system was implemented on a modified commercial robotic mower and validated both in a controlled mock-up lawn and on real garden datasets. Results demonstrate a strong correlation between embedding-space dispersion and expert biodiversity assessment, confirming the feasibility of deep visual diversity as a proxy for ecological richness and the effectiveness of the proposed mowing decision approach. Widespread adoption of such systems will turn ecologically worthless, monocultural lawns into vibrant, valuable biotopes that boost urban biodiversity.

</details>


### [14] [CoVAR: Co-generation of Video and Action for Robotic Manipulation via Multi-Modal Diffusion](https://arxiv.org/abs/2512.16023)
*Liudi Yang,Yang Bai,George Eskandar,Fengyi Shen,Mohammad Altillawi,Dong Chen,Ziyuan Liu,Abhinav Valada*

Main category: cs.CV

TL;DR: 提出一种结合视频和动作扩散模型的方法，通过Bridge Attention和动作细化模块提升机器人策略学习效果。


<details>
  <summary>Details</summary>
Motivation: 克服现有方法在跨模态信息共享和预训练知识利用上的不足。

Method: 扩展预训练视频扩散模型，引入并行专用动作扩散模型和Bridge Attention机制，设计动作细化模块。

Result: 在多个公共基准和真实数据集上表现优于现有基线，生成更高质量的视频和更准确的动作。

Conclusion: 该方法通过扩展预训练视频扩散模型并引入Bridge Attention机制，显著提升了视频生成质量和动作准确性，为机器人学习提供了可扩展的框架。

Abstract: We present a method to generate video-action pairs that follow text instructions, starting from an initial image observation and the robot's joint states. Our approach automatically provides action labels for video diffusion models, overcoming the common lack of action annotations and enabling their full use for robotic policy learning. Existing methods either adopt two-stage pipelines, which limit tightly coupled cross-modal information sharing, or rely on adapting a single-modal diffusion model for a joint distribution that cannot fully leverage pretrained video knowledge. To overcome these limitations, we (1) extend a pretrained video diffusion model with a parallel, dedicated action diffusion model that preserves pretrained knowledge, (2) introduce a Bridge Attention mechanism to enable effective cross-modal interaction, and (3) design an action refinement module to convert coarse actions into precise controls for low-resolution datasets. Extensive evaluations on multiple public benchmarks and real-world datasets demonstrate that our method generates higher-quality videos, more accurate actions, and significantly outperforms existing baselines, offering a scalable framework for leveraging large-scale video data for robotic learning.

</details>


### [15] [Driving in Corner Case: A Real-World Adversarial Closed-Loop Evaluation Platform for End-to-End Autonomous Driving](https://arxiv.org/abs/2512.16055)
*Jiaheng Geng,Jiatong Du,Xinyu Zhang,Ye Li,Panqu Wang,Yanjun Huang*

Main category: cs.CV

TL;DR: 提出闭环评估平台，通过对抗性交互生成真实世界角点案例，有效检测端到端自动驾驶模型的问题。


<details>
  <summary>Details</summary>
Motivation: 现实世界中难以收集安全关键角点案例，而现有对抗性评估方法仅适用于简化模拟环境，因此需要一种针对真实世界端到端自动驾驶的评估方法。

Method: 提出了一种闭环评估平台，结合基于流匹配的真实世界图像生成器和高效的对抗性交通策略，以生成安全关键角点案例。

Result: 实验证明平台能高效生成逼真驾驶图像，并通过评估UniAD和VAD等模型，展示了对抗性策略下模型在角点案例中的性能下降。

Conclusion: 该平台能有效检测端到端自动驾驶模型的潜在问题，提升其安全性和鲁棒性。

Abstract: Safety-critical corner cases, difficult to collect in the real world, are crucial for evaluating end-to-end autonomous driving. Adversarial interaction is an effective method to generate such safety-critical corner cases. While existing adversarial evaluation methods are built for models operating in simplified simulation environments, adversarial evaluation for real-world end-to-end autonomous driving has been little explored. To address this challenge, we propose a closed-loop evaluation platform for end-to-end autonomous driving, which can generate adversarial interactions in real-world scenes. In our platform, the real-world image generator cooperates with an adversarial traffic policy to evaluate various end-to-end models trained on real-world data. The generator, based on flow matching, efficiently and stably generates real-world images according to the traffic environment information. The efficient adversarial surrounding vehicle policy is designed to model challenging interactions and create corner cases that current autonomous driving systems struggle to handle. Experimental results demonstrate that the platform can generate realistic driving images efficiently. Through evaluating the end-to-end models such as UniAD and VAD, we demonstrate that based on the adversarial policy, our platform evaluates the performance degradation of the tested model in corner cases. This result indicates that this platform can effectively detect the model's potential issues, which will facilitate the safety and robustness of end-to-end autonomous driving.

</details>


### [16] [FOD-Diff: 3D Multi-Channel Patch Diffusion Model for Fiber Orientation Distribution](https://arxiv.org/abs/2512.16075)
*Hao Tang,Hanyu Liu,Alessandro Perelli,Xi Chen,Chao Li*

Main category: cs.CV

TL;DR: 提出了一种基于3D多通道补丁扩散模型的方法，通过引入先验脑解剖结构和SH注意力模块，有效预测HAR-FOD，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决单壳低角分辨率dMRI（LAR-FOD）精度不足和多壳高角分辨率dMRI（HAR-FOD）扫描时间长的限制。

Method: 设计了一个3D多通道补丁扩散模型，包括FOD补丁适配器、体素级条件协调模块和SH注意力模块。

Result: 实验结果表明，该方法在HAR-FOD预测中表现最佳。

Conclusion: 提出的3D多通道补丁扩散模型在预测HAR-FOD方面表现出色，超越了现有最先进方法。

Abstract: Diffusion MRI (dMRI) is a critical non-invasive technique to estimate fiber orientation distribution (FOD) for characterizing white matter integrity. Estimating FOD from single-shell low angular resolution dMRI (LAR-FOD) is limited by accuracy, whereas estimating FOD from multi-shell high angular resolution dMRI (HAR-FOD) requires a long scanning time, which limits its applicability. Diffusion models have shown promise in estimating HAR-FOD based on LAR-FOD. However, using diffusion models to efficiently generate HAR-FOD is challenging due to the large number of spherical harmonic (SH) coefficients in FOD. Here, we propose a 3D multi-channel patch diffusion model to predict HAR-FOD from LAR-FOD. We design the FOD-patch adapter by introducing the prior brain anatomy for more efficient patch-based learning. Furthermore, we introduce a voxel-level conditional coordinating module to enhance the global understanding of the model. We design the SH attention module to effectively learn the complex correlations of the SH coefficients. Our experimental results show that our method achieves the best performance in HAR-FOD prediction and outperforms other state-of-the-art methods.

</details>


### [17] [Auto-Vocabulary 3D Object Detection](https://arxiv.org/abs/2512.16077)
*Haomeng Zhang,Kuan-Chuan Peng,Suhas Lohit,Raymond A. Yeh*

Main category: cs.CV

TL;DR: AV3DOD是一种无需用户输入类别的3D对象检测方法，通过2D视觉语言模型自动生成语义候选，在ScanNetV2和SUNRGB-D数据集上实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 研究Auto-Vocabulary 3D Object Detection（AV3DOD），自动生成检测对象的类别名称，无需用户输入。

Method: 提出了一种新颖的框架AV3DOD，利用2D视觉语言模型（VLMs）通过图像描述、伪3D框生成和特征空间语义扩展生成丰富的语义候选。

Result: AV3DOD在ScanNetV2上比现有最佳方法CoDA整体mAP提高了3.48，SS相对提升了24.5%。

Conclusion: AV3DOD在ScanNetV2和SUNRGB-D数据集上实现了在定位（mAP）和语义质量（SS）方面的最先进性能，显著超越了现有方法。

Abstract: Open-vocabulary 3D object detection methods are able to localize 3D boxes of classes unseen during training. Despite the name, existing methods rely on user-specified classes both at training and inference. We propose to study Auto-Vocabulary 3D Object Detection (AV3DOD), where the classes are automatically generated for the detected objects without any user input. To this end, we introduce Semantic Score (SS) to evaluate the quality of the generated class names. We then develop a novel framework, AV3DOD, which leverages 2D vision-language models (VLMs) to generate rich semantic candidates through image captioning, pseudo 3D box generation, and feature-space semantics expansion. AV3DOD achieves the state-of-the-art (SOTA) performance on both localization (mAP) and semantic quality (SS) on the ScanNetV2 and SUNRGB-D datasets. Notably, it surpasses the SOTA, CoDA, by 3.48 overall mAP and attains a 24.5% relative improvement in SS on ScanNetV2.

</details>


### [18] [LAPX: Lightweight Hourglass Network with Global Context](https://arxiv.org/abs/2512.16089)
*Haopeng Zhao,Marsha Mariya Kappan,Mahdi Bamdad,Francisco Cruz*

Main category: cs.CV

TL;DR: LAPX 是一种轻量级姿态估计模型，结合自注意力和改进设计，在边缘设备上实现高精度和实时性能。


<details>
  <summary>Details</summary>
Motivation: 现有的 SOTA 姿态估计方法参数量大、计算成本高，而轻量级方法在边缘设备上部署时要么效率不足，要么因设计过于简化而精度受限。

Method: 基于 Hourglass 网络，引入自注意力模块以捕获全局上下文信息，并优化了轻量级注意力模块和阶段设计。

Result: 在 MPII 和 COCO 数据集上取得了具有竞争力的结果，仅需 2.3M 参数，并实现了实时性能。

Conclusion: LAPX 是一种适用于边缘设备的轻量级姿态估计模型，通过自注意力模块和改进的阶段设计，在保持高精度的同时实现了实时性能。

Abstract: Human pose estimation is a crucial task in computer vision. Methods that have SOTA (State-of-the-Art) accuracy, often involve a large number of parameters and incur substantial computational cost. Many lightweight variants have been proposed to reduce the model size and computational cost of them. However, several of these methods still contain components that are not well suited for efficient deployment on edge devices. Moreover, models that primarily emphasize inference speed on edge devices often suffer from limited accuracy due to their overly simplified designs. To address these limitations, we propose LAPX, an Hourglass network with self-attention that captures global contextual information, based on previous work, LAP. In addition to adopting the self-attention module, LAPX advances the stage design and refine the lightweight attention modules. It achieves competitive results on two benchmark datasets, MPII and COCO, with only 2.3M parameters, and demonstrates real-time performance, confirming its edge-device suitability.

</details>


### [19] [Collimator-assisted high-precision calibration method for event cameras](https://arxiv.org/abs/2512.16092)
*Zibin Liu,Shunkun Liang,Banglei Guan,Dongcai Tan,Yang Shang,Qifeng Yu*

Main category: cs.CV

TL;DR: 提出了一种基于闪烁星型图案准直仪的事件相机标定方法，通过线性求解和非线性优化实现长距离高精度测量，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 事件相机作为一种新型脑启发视觉传感器，具有高动态范围和高时间分辨率等优势，但其几何标定（尤其是在长距离测量场景中）仍是一个重大挑战。

Method: 该方法首先利用准直仪的球体运动模型线性求解相机参数，随后通过非线性优化高精度地细化这些参数。

Result: 通过全面的实际实验验证，该方法在准确性和可靠性方面始终优于现有的事件相机标定方法。

Conclusion: 本文提出了一种基于闪烁星型图案准直仪的事件相机标定方法，有效解决了长距离高精度测量的双重需求，并在多种实际条件下验证了其优越性。

Abstract: Event cameras are a new type of brain-inspired visual sensor with advantages such as high dynamic range and high temporal resolution. The geometric calibration of event cameras, which involves determining their intrinsic and extrinsic parameters, particularly in long-range measurement scenarios, remains a significant challenge. To address the dual requirements of long-distance and high-precision measurement, we propose an event camera calibration method utilizing a collimator with flickering star-based patterns. The proposed method first linearly solves camera parameters using the sphere motion model of the collimator, followed by nonlinear optimization to refine these parameters with high precision. Through comprehensive real-world experiments across varying conditions, we demonstrate that the proposed method consistently outperforms existing event camera calibration methods in terms of accuracy and reliability.

</details>


### [20] [TurboDiffusion: Accelerating Video Diffusion Models by 100-200 Times](https://arxiv.org/abs/2512.16093)
*Jintao Zhang,Kaiwen Zheng,Kai Jiang,Haoxu Wang,Ion Stoica,Joseph E. Gonzalez,Jianfei Chen,Jun Zhu*

Main category: cs.CV

TL;DR: TurboDiffusion是一个视频生成加速框架，通过注意力加速、步骤蒸馏和量化技术，实现了100-200倍的加速，同时保持视频质量。


<details>
  <summary>Details</summary>
Motivation: 为了加速端到端的扩散生成过程，同时保持视频质量，TurboDiffusion被设计出来以解决现有方法在速度和效率上的不足。

Method: TurboDiffusion 主要通过注意力加速（低比特SageAttention和可训练稀疏线性注意力SLA）、步骤蒸馏（rCM）和W8A8量化（模型参数和激活量化为8位）来实现加速，并结合了其他工程优化。

Result: 实验结果表明，TurboDiffusion在单张RTX 5090 GPU上实现了100-200倍的视频生成加速，且视频质量与原始方法相当。

Conclusion: TurboDiffusion 成功实现了视频生成速度100-200倍的加速，同时保持了视频质量，为扩散模型的高效生成提供了可行的解决方案。

Abstract: We introduce TurboDiffusion, a video generation acceleration framework that can speed up end-to-end diffusion generation by 100-200x while maintaining video quality. TurboDiffusion mainly relies on several components for acceleration: (1) Attention acceleration: TurboDiffusion uses low-bit SageAttention and trainable Sparse-Linear Attention (SLA) to speed up attention computation. (2) Step distillation: TurboDiffusion adopts rCM for efficient step distillation. (3) W8A8 quantization: TurboDiffusion quantizes model parameters and activations to 8 bits to accelerate linear layers and compress the model. In addition, TurboDiffusion incorporates several other engineering optimizations.
  We conduct experiments on the Wan2.2-I2V-14B-720P, Wan2.1-T2V-1.3B-480P, Wan2.1-T2V-14B-720P, and Wan2.1-T2V-14B-480P models. Experimental results show that TurboDiffusion achieves 100-200x speedup for video generation even on a single RTX 5090 GPU, while maintaining comparable video quality. The GitHub repository, which includes model checkpoints and easy-to-use code, is available at https://github.com/thu-ml/TurboDiffusion.

</details>


### [21] [Flexible Camera Calibration using a Collimator System](https://arxiv.org/abs/2512.16113)
*Shunkun Liang,Banglei Guan,Zhenbao Yu,Dongcai Tan,Pengju Sun,Zibin Liu,Qifeng Yu,Yang Shang*

Main category: cs.CV

TL;DR: 提出一种基于准直仪系统的相机标定方法，通过角度不变性约束和球形运动模型简化标定，实验证明其优越性。


<details>
  <summary>Details</summary>
Motivation: 相机标定是摄影测量和3D视觉应用中的关键步骤，现有方法通常需要复杂的设置和相机运动。本文旨在通过准直仪系统提供一种可靠、可控且灵活的标定解决方案。

Method: 利用准直仪系统的光学几何特性，提出角度不变性约束和球形运动模型，开发了多图像闭式线性求解器和双图像最小求解器，以及基于角度不变性约束的单准直仪图像标定算法。

Result: 实验验证了准直仪系统标定的可行性，并表明该方法优于现有基线方法。

Conclusion: 该论文提出的基于准直仪系统的相机标定方法通过角度不变性约束和球形运动模型，显著简化了标定过程，并在合成和真实实验中验证了其优越性。

Abstract: Camera calibration is a crucial step in photogrammetry and 3D vision applications. This paper introduces a novel camera calibration method using a designed collimator system. Our collimator system provides a reliable and controllable calibration environment for the camera. Exploiting the unique optical geometry property of our collimator system, we introduce an angle invariance constraint and further prove that the relative motion between the calibration target and camera conforms to a spherical motion model. This constraint reduces the original 6DOF relative motion between target and camera to a 3DOF pure rotation motion. Using spherical motion constraint, a closed-form linear solver for multiple images and a minimal solver for two images are proposed for camera calibration. Furthermore, we propose a single collimator image calibration algorithm based on the angle invariance constraint. This algorithm eliminates the requirement for camera motion, providing a novel solution for flexible and fast calibration. The performance of our method is evaluated in both synthetic and real-world experiments, which verify the feasibility of calibration using the collimator system and demonstrate that our method is superior to existing baseline methods. Demo code is available at https://github.com/LiangSK98/CollimatorCalibration

</details>


### [22] [Interaction-via-Actions: Cattle Interaction Detection with Joint Learning of Action-Interaction Latent Space](https://arxiv.org/abs/2512.16133)
*Ren Nakagawa,Yang Yang,Risa Shinoda,Hiroaki Santo,Kenji Oyama,Fumio Okura,Takenao Ohkawa*

Main category: cs.CV

TL;DR: 论文提出CattleAct方法，通过分解个体行为并构建统一潜在空间，解决了放牧牛群交互检测的数据稀缺问题，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 放牧牛群的行为交互检测对智能畜牧管理至关重要，但现有研究缺乏包含交互行为的全面数据集，且交互事件罕见。

Method: 首先从大规模牛行为数据集中学习行为潜在空间，然后通过对比学习微调预训练潜在空间，嵌入罕见交互行为，构建行为与交互的统一潜在空间。

Result: 实验证明，该方法在商业规模牧场上实现了比基线更准确的交互检测。

Conclusion: 该论文提出的CattleAct方法通过分解个体牛的行为组合，有效解决了放牧牛群行为交互检测的数据稀缺问题，并在商业规模牧场中验证了其准确性。

Abstract: This paper introduces a method and application for automatically detecting behavioral interactions between grazing cattle from a single image, which is essential for smart livestock management in the cattle industry, such as for detecting estrus. Although interaction detection for humans has been actively studied, a non-trivial challenge lies in cattle interaction detection, specifically the lack of a comprehensive behavioral dataset that includes interactions, as the interactions of grazing cattle are rare events. We, therefore, propose CattleAct, a data-efficient method for interaction detection by decomposing interactions into the combinations of actions by individual cattle. Specifically, we first learn an action latent space from a large-scale cattle action dataset. Then, we embed rare interactions via the fine-tuning of the pre-trained latent space using contrastive learning, thereby constructing a unified latent space of actions and interactions. On top of the proposed method, we develop a practical working system integrating video and GPS inputs. Experiments on a commercial-scale pasture demonstrate the accurate interaction detection achieved by our method compared to the baselines. Our implementation is available at https://github.com/rakawanegan/CattleAct.

</details>


### [23] [ResDynUNet++: A nested U-Net with residual dynamic convolution blocks for dual-spectral CT](https://arxiv.org/abs/2512.16140)
*Ze Yuan,Wenbin Li,Shusen Zhao*

Main category: cs.CV

TL;DR: A hybrid DSCT reconstruction framework combining OPMT (knowledge-driven) and ResDynUNet++ (data-driven) achieves accurate results by addressing key challenges.


<details>
  <summary>Details</summary>
Motivation: To improve dual-spectral CT reconstruction by leveraging both iterative methods and deep learning, addressing specific challenges in the process.

Method: The framework combines a knowledge-driven module (using OPMT for fast intermediate reconstruction) and a data-driven module (using ResDynUNet++ for refinement). ResDynUNet++ enhances UNet++ with residual dynamic convolution blocks for adaptive feature extraction.

Result: Extensive experiments on synthetic phantoms and real clinical datasets validate the method's efficacy and superior performance.

Conclusion: The proposed hybrid reconstruction framework effectively integrates iterative methods with deep learning models, demonstrating superior performance in DSCT reconstruction by addressing challenges like channel imbalance and near-interface large artifacts.

Abstract: We propose a hybrid reconstruction framework for dual-spectral CT (DSCT) that integrates iterative methods with deep learning models. The reconstruction process consists of two complementary components: a knowledge-driven module and a data-driven module. In the knowledge-driven phase, we employ the oblique projection modification technique (OPMT) to reconstruct an intermediate solution of the basis material images from the projection data. We select OPMT for this role because of its fast convergence, which allows it to rapidly generate an intermediate solution that successfully achieves basis material decomposition. Subsequently, in the data-driven phase, we introduce a novel neural network, ResDynUNet++, to refine this intermediate solution. The ResDynUNet++ is built upon a UNet++ backbone by replacing standard convolutions with residual dynamic convolution blocks, which combine the adaptive, input-specific feature extraction of dynamic convolution with the stable training of residual connections. This architecture is designed to address challenges like channel imbalance and near-interface large artifacts in DSCT, producing clean and accurate final solutions. Extensive experiments on both synthetic phantoms and real clinical datasets validate the efficacy and superior performance of the proposed method.

</details>


### [24] [SegGraph: Leveraging Graphs of SAM Segments for Few-Shot 3D Part Segmentation](https://arxiv.org/abs/2512.16143)
*Yueyang Hu,Haiyong Jiang,Haoxuan Song,Jun Xiao,Hao Pan*

Main category: cs.CV

TL;DR: 提出SegGraph框架，通过SAM分割图学习几何特征，显著提升3D部件分割性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在将2D基础模型知识聚合到3D时，要么忽略几何结构，要么忽视SAM提供的高质量分组线索，导致分割不足和标签不一致。

Method: 提出了一种基于SAM分割图的传播方法（SegGraph），通过建模片段间的相互重叠和邻接关系来学习几何特征，并利用图神经网络传播特征以学习全局几何结构。

Result: 在PartNet-E数据集上的实验表明，SegGraph方法比所有竞争基线至少高出6.9%的mIoU。

Conclusion: SegGraph方法在PartNet-E数据集上显著优于现有基线，尤其在小型组件和部件边界上表现出色，展示了其卓越的几何理解能力。

Abstract: This work presents a novel framework for few-shot 3D part segmentation. Recent advances have demonstrated the significant potential of 2D foundation models for low-shot 3D part segmentation. However, it is still an open problem that how to effectively aggregate 2D knowledge from foundation models to 3D. Existing methods either ignore geometric structures for 3D feature learning or neglects the high-quality grouping clues from SAM, leading to under-segmentation and inconsistent part labels. We devise a novel SAM segment graph-based propagation method, named SegGraph, to explicitly learn geometric features encoded within SAM's segmentation masks. Our method encodes geometric features by modeling mutual overlap and adjacency between segments while preserving intra-segment semantic consistency. We construct a segment graph, conceptually similar to an atlas, where nodes represent segments and edges capture their spatial relationships (overlap/adjacency). Each node adaptively modulates 2D foundation model features, which are then propagated via a graph neural network to learn global geometric structures. To enforce intra-segment semantic consistency, we map segment features to 3D points with a novel view-direction-weighted fusion attenuating contributions from low-quality segments. Extensive experiments on PartNet-E demonstrate that our method outperforms all competing baselines by at least 6.9 percent mIoU. Further analysis reveals that SegGraph achieves particularly strong performance on small components and part boundaries, demonstrating its superior geometric understanding. The code is available at: https://github.com/YueyangHu2000/SegGraph.

</details>


### [25] [C-DGPA: Class-Centric Dual-Alignment Generative Prompt Adaptation](https://arxiv.org/abs/2512.16164)
*Chao Li,Dasha Hu,Chengyang Li,Yuming Jiang,Yuncheng Shen*

Main category: cs.CV

TL;DR: C-DGPA通过双分支架构协同优化边缘和条件分布对齐，解决了领域适应中类原型错位和语义判别性下降问题，在多个数据集上达到最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有提示调优策略主要关注边缘分布对齐，忽略了条件分布差异，导致类原型错位和语义判别性下降。

Method: C-DGPA采用动态对抗训练框架和类映射机制（CMM），通过双分支架构分别优化边缘分布对齐和条件分布对齐。

Result: 在OfficeHome、Office31和VisDA-2017等数据集上的广泛实验验证了C-DGPA的优越性，所有基准测试均达到新的最先进结果。

Conclusion: C-DGPA通过双分支架构协同优化边缘分布对齐和条件分布对齐，有效整合领域知识到提示学习中，实现了领域不变且语义可区分的表示，并在多个基准测试中达到了新的最先进结果。

Abstract: Unsupervised Domain Adaptation transfers knowledge from a labeled source domain to an unlabeled target domain. Directly deploying Vision-Language Models (VLMs) with prompt tuning in downstream UDA tasks faces the signifi cant challenge of mitigating domain discrepancies. Existing prompt-tuning strategies primarily align marginal distribu tion, but neglect conditional distribution discrepancies, lead ing to critical issues such as class prototype misalignment and degraded semantic discriminability. To address these lim itations, the work proposes C-DGPA: Class-Centric Dual Alignment Generative Prompt Adaptation. C-DGPA syner gistically optimizes marginal distribution alignment and con ditional distribution alignment through a novel dual-branch architecture. The marginal distribution alignment branch em ploys a dynamic adversarial training framework to bridge marginal distribution discrepancies. Simultaneously, the con ditional distribution alignment branch introduces a Class Mapping Mechanism (CMM) to align conditional distribu tion discrepancies by standardizing semantic prompt under standing and preventing source domain over-reliance. This dual alignment strategy effectively integrates domain knowl edge into prompt learning via synergistic optimization, ensur ing domain-invariant and semantically discriminative repre sentations. Extensive experiments on OfficeHome, Office31, and VisDA-2017 validate the superiority of C-DGPA. It achieves new state-of-the-art results on all benchmarks.

</details>


### [26] [Towards Closing the Domain Gap with Event Cameras](https://arxiv.org/abs/2512.16178)
*M. Oltan Sevinc,Liao Wu,Francisco Cruz*

Main category: cs.CV

TL;DR: 事件相机在昼夜光照差异的领域差距中表现优于传统相机，提供更一致的性能和更小的领域转移惩罚。


<details>
  <summary>Details</summary>
Motivation: 传统相机在训练数据与部署环境条件不匹配时性能大幅下降，特别是在昼夜光照差异的领域差距中。

Method: 提出使用事件相机替代传统相机，以应对光照条件变化带来的领域差距问题。

Result: 事件相机在光照条件变化下保持更一致的性能，领域转移惩罚较小，跨领域场景表现优于传统相机。

Conclusion: 事件相机在光照条件变化的领域差距中表现更一致，其领域转移惩罚通常与灰度帧相当或更小，并在跨领域场景中提供更优的基线性能。

Abstract: Although traditional cameras are the primary sensor for end-to-end driving, their performance suffers greatly when the conditions of the data they were trained on does not match the deployment environment, a problem known as the domain gap. In this work, we consider the day-night lighting difference domain gap. Instead of traditional cameras we propose event cameras as a potential alternative which can maintain performance across lighting condition domain gaps without requiring additional adjustments. Our results show that event cameras maintain more consistent performance across lighting conditions, exhibiting domain-shift penalties that are generally comparable to or smaller than grayscale frames and provide superior baseline performance in cross-domain scenarios.

</details>


### [27] [Avatar4D: Synthesizing Domain-Specific 4D Humans for Real-World Pose Estimation](https://arxiv.org/abs/2512.16199)
*Jerrin Bright,Zhibo Wang,Dmytro Klepachevskyi,Yuhao Chen,Sirisha Rambhatla,David Clausi,John Zelek*

Main category: cs.CV

TL;DR: Avatar4D是一个可定制化合成人类运动数据集的管道，特别适用于体育领域，展示了无需真实数据即可生成高质量合成数据的潜力。


<details>
  <summary>Details</summary>
Motivation: 针对领域特定应用（如体育）中人类动作和运动模式的独特挑战，现有方法局限于通用日常运动且灵活性不足。

Method: Avatar4D提供了一个可定制化合成人类运动数据集的管道，具有对身体姿态、外观、相机视角和环境上下文细粒度控制的能力，无需手动标注。

Result: 通过Syn2Sport数据集验证了Avatar4D的有效性，包括在监督学习、零样本迁移到真实数据及跨体育泛化方面的表现，并评估了合成数据与真实数据在特征空间中的对齐程度。

Conclusion: Avatar4D展示了生成可扩展、可控且可迁移的合成人类数据集在多样化领域特定任务中的潜力，无需依赖特定领域的真实数据。

Abstract: We present Avatar4D, a real-world transferable pipeline for generating customizable synthetic human motion datasets tailored to domain-specific applications. Unlike prior works, which focus on general, everyday motions and offer limited flexibility, our approach provides fine-grained control over body pose, appearance, camera viewpoint, and environmental context, without requiring any manual annotations. To validate the impact of Avatar4D, we focus on sports, where domain-specific human actions and movement patterns pose unique challenges for motion understanding. In this setting, we introduce Syn2Sport, a large-scale synthetic dataset spanning sports, including baseball and ice hockey. Avatar4D features high-fidelity 4D (3D geometry over time) human motion sequences with varying player appearances rendered in diverse environments. We benchmark several state-of-the-art pose estimation models on Syn2Sport and demonstrate their effectiveness for supervised learning, zero-shot transfer to real-world data, and generalization across sports. Furthermore, we evaluate how closely the generated synthetic data aligns with real-world datasets in feature space. Our results highlight the potential of such systems to generate scalable, controllable, and transferable human datasets for diverse domain-specific tasks without relying on domain-specific real data.

</details>


### [28] [Visual Alignment of Medical Vision-Language Models for Grounded Radiology Report Generation](https://arxiv.org/abs/2512.16201)
*Sarosij Bose,Ravi K. Rajendran,Biplob Debnath,Konstantinos Karydis,Amit K. Roy-Chowdhury,Srimat Chakradhar*

Main category: cs.CV

TL;DR: VALOR提出强化学习后对齐框架，通过两阶段训练提升放射学报告的视觉基础和临床准确性，实验显示其显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖大规模标注数据或检索策略，但未能有效解决视觉与语言表征跨模态对齐不足导致的幻觉问题。

Method: VALOR采用两阶段训练：1) 通过文本奖励改进Med-VLM以提升临床术语准确性；2) 对齐视觉投影模块与疾病发现，引导注意力至诊断任务相关图像区域。

Result: 在多基准测试中，VALOR显著提升事实准确性和视觉基础，性能优于现有报告生成方法。

Conclusion: VALOR通过强化学习后对齐框架显著提升了放射学报告生成的视觉基础和临床准确性，超越了现有最先进方法。

Abstract: Radiology Report Generation (RRG) is a critical step toward automating healthcare workflows, facilitating accurate patient assessments, and reducing the workload of medical professionals. Despite recent progress in Large Medical Vision-Language Models (Med-VLMs), generating radiology reports that are both visually grounded and clinically accurate remains a significant challenge. Existing approaches often rely on large labeled corpora for pre-training, costly task-specific preference data, or retrieval-based methods. However, these strategies do not adequately mitigate hallucinations arising from poor cross-modal alignment between visual and linguistic representations. To address these limitations, we propose VALOR:Visual Alignment of Medical Vision-Language Models for GrOunded Radiology Report Generation. Our method introduces a reinforcement learning-based post-alignment framework utilizing Group-Relative Proximal Optimization (GRPO). The training proceeds in two stages: (1) improving the Med-VLM with textual rewards to encourage clinically precise terminology, and (2) aligning the vision projection module of the textually grounded model with disease findings, thereby guiding attention toward image re gions most relevant to the diagnostic task. Extensive experiments on multiple benchmarks demonstrate that VALOR substantially improves factual accuracy and visual grounding, achieving significant performance gains over state-of-the-art report generation methods.

</details>


### [29] [Open Ad-hoc Categorization with Contextualized Feature Learning](https://arxiv.org/abs/2512.16202)
*Zilin Wang,Sangwoo Mo,Stella X. Yu,Sima Behpour,Liu Ren*

Main category: cs.CV

TL;DR: OAK模型通过结合CLIP和GCD的目标，在自适应分类任务中实现高性能和可解释性。


<details>
  <summary>Details</summary>
Motivation: 研究开放ad-hoc分类问题，旨在通过语义扩展和视觉聚类动态发现和扩展ad-hoc类别。

Method: 提出OAK模型，通过在冻结的CLIP输入中引入少量可学习的上下文令牌，并优化CLIP的图像-文本对齐目标和GCD的视觉聚类目标。

Result: 在Stanford和Clevr-4数据集上，OAK在准确率和概念发现方面达到最先进水平，例如在Stanford Mood数据集上达到87.4%的新颖准确率，超过CLIP和GCD超过50%。

Conclusion: OAK模型通过结合CLIP的图像-文本对齐目标和GCD的视觉聚类目标，在自适应分类任务中实现了最先进的性能，并提供了可解释的显著性图，增强了透明度和信任。

Abstract: Adaptive categorization of visual scenes is essential for AI agents to handle changing tasks. Unlike fixed common categories for plants or animals, ad-hoc categories are created dynamically to serve specific goals. We study open ad-hoc categorization: Given a few labeled exemplars and abundant unlabeled data, the goal is to discover the underlying context and to expand ad-hoc categories through semantic extension and visual clustering around it.
  Building on the insight that ad-hoc and common categories rely on similar perceptual mechanisms, we propose OAK, a simple model that introduces a small set of learnable context tokens at the input of a frozen CLIP and optimizes with both CLIP's image-text alignment objective and GCD's visual clustering objective.
  On Stanford and Clevr-4 datasets, OAK achieves state-of-the-art in accuracy and concept discovery across multiple categorizations, including 87.4% novel accuracy on Stanford Mood, surpassing CLIP and GCD by over 50%. Moreover, OAK produces interpretable saliency maps, focusing on hands for Action, faces for Mood, and backgrounds for Location, promoting transparency and trust while enabling adaptive and generalizable categorization.

</details>


### [30] [Enhanced 3D Shape Analysis via Information Geometry](https://arxiv.org/abs/2512.16213)
*Amit Vishwakarma,K. S. Subrahamanian Moosath*

Main category: cs.CV

TL;DR: 本文提出了一种基于信息几何的3D点云形状分析方法，通过修正对称KL散度（MSKL）解决了传统度量方法的不足，实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 传统几何度量（如Hausdorff和Chamfer距离）无法捕捉全局统计结构且对异常值敏感，现有KL近似也存在数值不稳定的问题。

Method: 通过将点云表示为统计流形上的高斯混合模型（GMMs），并引入修正对称Kullback-Leibler（MSKL）散度，确保数值稳定性。

Result: 在MPI-FAUST和G-PCD数据集上的实验表明，MSKL能稳定反映几何变化，优于其他方法。

Conclusion: 本文提出的MSKL散度在3D点云形状分析中表现出色，提供了数值稳定的比较方法，优于传统距离和现有的KL近似。

Abstract: Three-dimensional point clouds provide highly accurate digital representations of objects, essential for applications in computer graphics, photogrammetry, computer vision, and robotics. However, comparing point clouds faces significant challenges due to their unstructured nature and the complex geometry of the surfaces they represent. Traditional geometric metrics such as Hausdorff and Chamfer distances often fail to capture global statistical structure and exhibit sensitivity to outliers, while existing Kullback-Leibler (KL) divergence approximations for Gaussian Mixture Models can produce unbounded or numerically unstable values. This paper introduces an information geometric framework for 3D point cloud shape analysis by representing point clouds as Gaussian Mixture Models (GMMs) on a statistical manifold. We prove that the space of GMMs forms a statistical manifold and propose the Modified Symmetric Kullback-Leibler (MSKL) divergence with theoretically guaranteed upper and lower bounds, ensuring numerical stability for all GMM comparisons. Through comprehensive experiments on human pose discrimination (MPI-FAUST dataset) and animal shape comparison (G-PCD dataset), we demonstrate that MSKL provides stable and monotonically varying values that directly reflect geometric variation, outperforming traditional distances and existing KL approximations.

</details>


### [31] [Learning High-Quality Initial Noise for Single-View Synthesis with Diffusion Models](https://arxiv.org/abs/2512.16219)
*Zhihao Zhang,Xuejun Yang,Weihua Liu,Mouquan Shen*

Main category: cs.CV

TL;DR: 提出了一种基于编码器-解码器网络（EDN）的框架，将随机噪声转化为高质量噪声，显著提升了单视图新视角合成模型的性能。


<details>
  <summary>Details</summary>
Motivation: 扩散模型中存在某些高质量初始噪声模式能带来更好的生成效果，但目前缺乏专门的学习框架来让NVS模型学习这种高质量噪声。

Method: 设计了一种离散化的Euler反演方法，将图像语义信息注入随机噪声，构建了随机噪声与高质量噪声的配对数据集；并提出了基于编码器-解码器网络（EDN）的学习框架，直接实现随机噪声到高质量噪声的转换。

Result: 实验证明，提出的EDN可以无缝集成到多种NVS模型（如SV3D和MV-Adapter）中，在多个数据集上实现了显著的性能提升。

Conclusion: 通过提出的EDN框架，能够有效将随机噪声转化为高质量噪声，显著提升了多种NVS模型的性能。

Abstract: Single-view novel view synthesis (NVS) models based on diffusion models have recently attracted increasing attention, as they can generate a series of novel view images from a single image prompt and camera pose information as conditions. It has been observed that in diffusion models, certain high-quality initial noise patterns lead to better generation results than others. However, there remains a lack of dedicated learning frameworks that enable NVS models to learn such high-quality noise. To obtain high-quality initial noise from random Gaussian noise, we make the following contributions. First, we design a discretized Euler inversion method to inject image semantic information into random noise, thereby constructing paired datasets of random and high-quality noise. Second, we propose a learning framework based on an encoder-decoder network (EDN) that directly transforms random noise into high-quality noise. Experiments demonstrate that the proposed EDN can be seamlessly plugged into various NVS models, such as SV3D and MV-Adapter, achieving significant performance improvements across multiple datasets. Code is available at: https://github.com/zhihao0512/EDN.

</details>


### [32] [SNOW: Spatio-Temporal Scene Understanding with World Knowledge for Open-World Embodied Reasoning](https://arxiv.org/abs/2512.16461)
*Tin Stribor Sohn,Maximilian Dillitzer,Jason J. Corso,Eric Sax*

Main category: cs.CV

TL;DR: SNOW是一个无需训练、与骨干无关的框架，通过整合VLM语义、点云几何和时间一致性，构建4D场景图，显著提升了自主机器人的场景理解和推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLM）缺乏3D几何和时间动态的接地性，而几何感知又语义稀疏，因此需要一种统一的方法来整合语义、几何和时间信息。

Method: SNOW框架采用HDBSCAN聚类生成对象级提案，结合SAM2分割和STEP编码，构建4D场景图（4DSG），并通过轻量级SLAM后端实现空间锚定。

Result: 实验表明，SNOW在多个基准测试中实现了精确的4D场景理解和空间接地推理，达到了新的最先进性能。

Conclusion: SNOW通过整合VLM语义、点云几何和时间一致性，实现了统一的4D场景理解，为自主机器人提供了结构化4D先验，显著提升了场景理解和推理能力。

Abstract: Autonomous robotic systems require spatio-temporal understanding of dynamic environments to ensure reliable navigation and interaction. While Vision-Language Models (VLMs) provide open-world semantic priors, they lack grounding in 3D geometry and temporal dynamics. Conversely, geometric perception captures structure and motion but remains semantically sparse. We propose SNOW (Scene Understanding with Open-World Knowledge), a training-free and backbone-agnostic framework for unified 4D scene understanding that integrates VLM-derived semantics with point cloud geometry and temporal consistency. SNOW processes synchronized RGB images and 3D point clouds, using HDBSCAN clustering to generate object-level proposals that guide SAM2-based segmentation. Each segmented region is encoded through our proposed Spatio-Temporal Tokenized Patch Encoding (STEP), producing multimodal tokens that capture localized semantic, geometric, and temporal attributes. These tokens are incrementally integrated into a 4D Scene Graph (4DSG), which serves as 4D prior for downstream reasoning. A lightweight SLAM backend anchors all STEP tokens spatially in the environment, providing the global reference alignment, and ensuring unambiguous spatial grounding across time. The resulting 4DSG forms a queryable, unified world model through which VLMs can directly interpret spatial scene structure and temporal dynamics. Experiments on a diverse set of benchmarks demonstrate that SNOW enables precise 4D scene understanding and spatially grounded inference, thereby setting new state-of-the-art performance in several settings, highlighting the importance of structured 4D priors for embodied reasoning and autonomous robotics.

</details>


### [33] [Image Compression Using Singular Value Decomposition](https://arxiv.org/abs/2512.16226)
*Justin Jiang*

Main category: cs.CV

TL;DR: SVD和低秩矩阵近似用于图像压缩，视觉效果接近原始图像，但压缩效率不如JPEG等标准格式，且低误差下可能比原始图像更大。


<details>
  <summary>Details</summary>
Motivation: 图像在互联网中占比较大，高效压缩对减少存储和带宽需求至关重要。

Method: 使用奇异值分解（SVD）和低秩矩阵近似进行图像压缩，并通过相对Frobenius误差和压缩比评估性能。

Result: 低秩近似生成的图像在视觉上与原始图像相似，但压缩效率始终低于行业标准格式。

Conclusion: 该方法在图像压缩效率上不及行业标准编解码器（如JPEG、JPEG2000和WEBP），尤其是在低容忍误差水平下，压缩表示甚至可能超过原始图像大小。

Abstract: Images are a substantial portion of the internet, making efficient compression important for reducing storage and bandwidth demands. This study investigates the use of Singular Value Decomposition and low-rank matrix approximations for image compression, evaluating performance using relative Frobenius error and compression ratio. The approach is applied to both grayscale and multichannel images to assess its generality. Results show that the low-rank approximations often produce images that appear visually similar to the originals, but the compression efficiency remains consistently worse than established formats such as JPEG, JPEG2000, and WEBP at comparable error levels. At low tolerated error levels, the compressed representation produced by Singular Value Decomposition can even exceed the size of the original image, indicating that this method is not competitive with industry-standard codecs for practical image compression.

</details>


### [34] [GeoPredict: Leveraging Predictive Kinematics and 3D Gaussian Geometry for Precise VLA Manipulation](https://arxiv.org/abs/2512.16811)
*Jingjing Qian,Boyao Han,Chen Shi,Lei Xiao,Long Yang,Shaoshuai Shi,Li Jiang*

Main category: cs.CV

TL;DR: GeoPredict是一种几何感知的VLA框架，通过预测性运动与几何模块提升3D任务性能，实验证明其在复杂场景中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在3D推理任务中表现不足，尤其是在需要精确3D推理的机器人操作任务中。GeoPredict旨在通过几何和运动先验增强模型的3D推理能力。

Method: GeoPredict框架包含两个核心模块：轨迹级模块（编码运动历史并预测多步3D关键点轨迹）和预测性3D高斯几何模块（预测工作空间几何并通过轨迹引导的细化进行优化）。这些模块仅作为训练时的监督，推理时仅需轻量级查询令牌。

Result: 在RoboCasa Human-50、LIBERO和真实世界操作任务中，GeoPredict均显著优于现有VLA基线模型，特别是在几何密集和空间要求高的场景中。

Conclusion: GeoPredict通过引入预测性几何和运动先验，显著提升了VLA模型在3D密集型任务中的表现，尤其是在需要精确空间推理的场景下。

Abstract: Vision-Language-Action (VLA) models achieve strong generalization in robotic manipulation but remain largely reactive and 2D-centric, making them unreliable in tasks that require precise 3D reasoning. We propose GeoPredict, a geometry-aware VLA framework that augments a continuous-action policy with predictive kinematic and geometric priors. GeoPredict introduces a trajectory-level module that encodes motion history and predicts multi-step 3D keypoint trajectories of robot arms, and a predictive 3D Gaussian geometry module that forecasts workspace geometry with track-guided refinement along future keypoint trajectories. These predictive modules serve exclusively as training-time supervision through depth-based rendering, while inference requires only lightweight additional query tokens without invoking any 3D decoding. Experiments on RoboCasa Human-50, LIBERO, and real-world manipulation tasks show that GeoPredict consistently outperforms strong VLA baselines, especially in geometry-intensive and spatially demanding scenarios.

</details>


### [35] [ARMFlow: AutoRegressive MeanFlow for Online 3D Human Reaction Generation](https://arxiv.org/abs/2512.16234)
*Zichen Geng,Zeeshan Hayder,Wei Liu,Hesheng Wang,Ajmal Mian*

Main category: cs.CV

TL;DR: ARMFlow是一种新型自回归框架，通过BSCE训练和全局上下文编码，显著提升了3D人体反应生成的实时性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法同时满足3D人体反应生成的高运动保真度、实时推理和自回归适应性需求，因此提出ARMFlow以解决这些关键限制。

Method: ARMFlow采用MeanFlow-based自回归框架，包含因果上下文编码器和基于MLP的速度预测器，并引入Bootstrap Contextual Encoding（BSCE）训练方法以减少自回归生成中的误差累积。

Result: ARMFlow在InterHuman和InterX数据集上的在线单步生成性能超过现有在线方法40%以上（FID指标），同时与离线最先进方法性能相当。

Conclusion: ARMFlow通过其自回归框架和BSCE训练方法，有效解决了3D人体反应生成中的高保真度、实时推理和自回归适应性三大挑战，同时在在线和离线场景下均表现出色。

Abstract: 3D human reaction generation faces three main challenges:(1) high motion fidelity, (2) real-time inference, and (3) autoregressive adaptability for online scenarios. Existing methods fail to meet all three simultaneously. We propose ARMFlow, a MeanFlow-based autoregressive framework that models temporal dependencies between actor and reactor motions. It consists of a causal context encoder and an MLP-based velocity predictor. We introduce Bootstrap Contextual Encoding (BSCE) in training, encoding generated history instead of the ground-truth ones, to alleviate error accumulation in autoregressive generation. We further introduce the offline variant ReMFlow, achieving state-of-the-art performance with the fastest inference among offline methods. Our ARMFlow addresses key limitations of online settings by: (1) enhancing semantic alignment via a global contextual encoder; (2) achieving high accuracy and low latency in a single-step inference; and (3) reducing accumulated errors through BSCE. Our single-step online generation surpasses existing online methods on InterHuman and InterX by over 40% in FID, while matching offline state-of-the-art performance despite using only partial sequence conditions.

</details>


### [36] [OPENTOUCH: Bringing Full-Hand Touch to Real-World Interaction](https://arxiv.org/abs/2512.16842)
*Yuxin Ray Song,Jinzhou Li,Rao Fu,Devin Murphy,Kaichen Zhou,Rishi Shiv,Yaqi Li,Haoyu Xiong,Crystal Elaine Owens,Yilun Du,Yiyue Luo,Xianyi Cheng,Antonio Torralba,Wojciech Matusik,Paul Pu Liang*

Main category: cs.CV

TL;DR: OpenTouch是首个在自然环境中采集的自我中心全手触觉数据集，旨在通过多模态数据推动感知和机器人操作的发展。


<details>
  <summary>Details</summary>
Motivation: 人类手是与物理世界交互的主要接口，但自我中心感知很少知道何时、何地或如何施加力量。现有的可穿戴触觉传感器稀缺，且缺乏与第一人称视频对齐的全手触觉数据。

Method: 提出了OpenTouch，这是首个在自然环境中采集的自我中心全手触觉数据集，包含5.1小时的同步视频-触觉-姿态数据及2,900个经过筛选的片段和详细文本标注。

Result: 触觉信号为抓握理解提供了紧凑而强大的线索，增强了跨模态对齐，并能从自然视频查询中可靠检索。

Conclusion: OpenTouch数据集和基准测试的发布旨在推动多模态自我中心感知、具身学习以及接触丰富的机器人操作的发展。

Abstract: The human hand is our primary interface to the physical world, yet egocentric perception rarely knows when, where, or how forcefully it makes contact. Robust wearable tactile sensors are scarce, and no existing in-the-wild datasets align first-person video with full-hand touch. To bridge the gap between visual perception and physical interaction, we present OpenTouch, the first in-the-wild egocentric full-hand tactile dataset, containing 5.1 hours of synchronized video-touch-pose data and 2,900 curated clips with detailed text annotations. Using OpenTouch, we introduce retrieval and classification benchmarks that probe how touch grounds perception and action. We show that tactile signals provide a compact yet powerful cue for grasp understanding, strengthen cross-modal alignment, and can be reliably retrieved from in-the-wild video queries. By releasing this annotated vision-touch-pose dataset and benchmark, we aim to advance multimodal egocentric perception, embodied learning, and contact-rich robotic manipulation.

</details>


### [37] [AI-Powered Dermatological Diagnosis: From Interpretable Models to Clinical Implementation A Comprehensive Framework for Accessible and Trustworthy Skin Disease Detection](https://arxiv.org/abs/2512.16235)
*Satya Narayana Panda,Vaishnavi Kukkala,Spandana Iyer*

Main category: cs.CV

TL;DR: AI结合家族史与临床影像提升皮肤病诊断准确性，计划临床试验验证。


<details>
  <summary>Details</summary>
Motivation: 解决皮肤病诊断中家族史数据未被充分利用的问题，提升诊断准确性和个性化治疗建议。

Method: 采用可解释的卷积神经网络与临床决策树结合的方法，整合了深度学习的图像分析和结构化临床数据。

Result: 集成家族史数据的AI系统在遗传性皮肤病（如黑色素瘤、银屑病和特应性皮炎）的诊断中表现出更高的准确性。

Conclusion: 该研究开发了一个结合家族史数据和临床影像的多模态AI框架，显著提高了遗传性皮肤病的诊断准确性，并计划通过临床试验进一步验证其效果。

Abstract: Dermatological conditions affect 1.9 billion people globally, yet accurate diagnosis remains challenging due to limited specialist availability and complex clinical presentations. Family history significantly influences skin disease susceptibility and treatment responses, but is often underutilized in diagnostic processes. This research addresses the critical question: How can AI-powered systems integrate family history data with clinical imaging to enhance dermatological diagnosis while supporting clinical trial validation and real-world implementation?
  We developed a comprehensive multi-modal AI framework that combines deep learning-based image analysis with structured clinical data, including detailed family history patterns. Our approach employs interpretable convolutional neural networks integrated with clinical decision trees that incorporate hereditary risk factors. The methodology includes prospective clinical trials across diverse healthcare settings to validate AI-assisted diagnosis against traditional clinical assessment.
  In this work, validation was conducted with healthcare professionals to assess AI-assisted outputs against clinical expectations; prospective clinical trials across diverse healthcare settings are proposed as future work. The integrated AI system demonstrates enhanced diagnostic accuracy when family history data is incorporated, particularly for hereditary skin conditions such as melanoma, psoriasis, and atopic dermatitis. Expert feedback indicates potential for improved early detection and more personalized recommendations; formal clinical trials are planned. The framework is designed for integration into clinical workflows while maintaining interpretability through explainable AI mechanisms.

</details>


### [38] [Flowing from Reasoning to Motion: Learning 3D Hand Trajectory Prediction from Egocentric Human Interaction Videos](https://arxiv.org/abs/2512.16907)
*Mingfei Chen,Yifan Wang,Zhengqin Li,Homanga Bharadhwaj,Yujin Chen,Chuan Qin,Ziyi Kou,Yuan Tian,Eric Whitmire,Rajinder Sodhi,Hrvoje Benko,Eli Shlizerman,Yue Liu*

Main category: cs.CV

TL;DR: 论文提出EgoMAN数据集和模型，通过视觉语言推理和运动生成的结合，实现了准确且阶段感知的3D手部轨迹预测。


<details>
  <summary>Details</summary>
Motivation: 现有3D手部轨迹预测研究受限于将运动与语义监督解耦的数据集，以及推理与动作弱关联的模型。为了解决这些问题，作者提出了新的数据集和模型。

Method: 论文首先提出了EgoMAN数据集，包含219K 6DoF轨迹和3M结构化QA对，用于语义、空间和运动推理。随后介绍了EgoMAN模型，这是一个通过轨迹-令牌接口连接视觉语言推理和运动生成的推理到运动框架。

Result: EgoMAN模型通过逐步训练对齐推理与运动动态，生成了准确且阶段感知的轨迹，并在真实场景中表现出良好的泛化能力。

Conclusion: 该论文提出的EgoMAN模型通过结合视觉语言推理和运动生成，实现了准确且阶段感知的3D手部轨迹预测，并在真实场景中展现出良好的泛化能力。

Abstract: Prior works on 3D hand trajectory prediction are constrained by datasets that decouple motion from semantic supervision and by models that weakly link reasoning and action. To address these, we first present the EgoMAN dataset, a large-scale egocentric dataset for interaction stage-aware 3D hand trajectory prediction with 219K 6DoF trajectories and 3M structured QA pairs for semantic, spatial, and motion reasoning. We then introduce the EgoMAN model, a reasoning-to-motion framework that links vision-language reasoning and motion generation via a trajectory-token interface. Trained progressively to align reasoning with motion dynamics, our approach yields accurate and stage-aware trajectories with generalization across real-world scenes.

</details>


### [39] [Semi-Supervised Multi-View Crowd Counting by Ranking Multi-View Fusion Models](https://arxiv.org/abs/2512.16243)
*Qi Zhang,Yunfei Gong,Zhidan Xie,Zhizi Wang,Antoni B. Chan,Hui Huang*

Main category: cs.CV

TL;DR: 提出两种半监督多视角人群计数框架，通过模型预测或不确定性排序解决数据有限问题，实验证明其优势。


<details>
  <summary>Details</summary>
Motivation: 为了解决多视角计数数据有限的问题，避免收集和标注多视角图像的困难。

Method: 提出了两种半监督多视角人群计数框架，通过基于模型预测或模型不确定性对输入视角数量不同的多视角融合模型进行排序。第一种方法（普通模型）基于不同数量相机视角输入的预测结果进行排序；第二种方法基于模型不确定性进行排序，并通过多视角融合模型的预测误差进行指导。

Result: 提出的多视角模型排序方法在半监督计数中表现优于其他方法。

Conclusion: 实验结果表明，所提出的多视角模型排序方法在半监督计数方法中具有优势。

Abstract: Multi-view crowd counting has been proposed to deal with the severe occlusion issue of crowd counting in large and wide scenes. However, due to the difficulty of collecting and annotating multi-view images, the datasets for multi-view counting have a limited number of multi-view frames and scenes. To solve the problem of limited data, one approach is to collect synthetic data to bypass the annotating step, while another is to propose semi- or weakly-supervised or unsupervised methods that demand less multi-view data. In this paper, we propose two semi-supervised multi-view crowd counting frameworks by ranking the multi-view fusion models of different numbers of input views, in terms of the model predictions or the model uncertainties. Specifically, for the first method (vanilla model), we rank the multi-view fusion models' prediction results of different numbers of camera-view inputs, namely, the model's predictions with fewer camera views shall not be larger than the predictions with more camera views. For the second method, we rank the estimated model uncertainties of the multi-view fusion models with a variable number of view inputs, guided by the multi-view fusion models' prediction errors, namely, the model uncertainties with more camera views shall not be larger than those with fewer camera views. These constraints are introduced into the model training in a semi-supervised fashion for multi-view counting with limited labeled data. The experiments demonstrate the advantages of the proposed multi-view model ranking methods compared with other semi-supervised counting methods.

</details>


### [40] [MomaGraph: State-Aware Unified Scene Graphs with Vision-Language Model for Embodied Task Planning](https://arxiv.org/abs/2512.16909)
*Yuanchen Ju,Yongyuan Liang,Yen-Jen Wang,Nandiraju Gireesh,Yuanliang Ju,Seungjae Lee,Qiao Gu,Elvis Hsieh,Furong Huang,Koushil Sreenath*

Main category: cs.CV

TL;DR: 提出 MomaGraph 统一场景表示方法及配套数据集和评估套件，开发的 MomaGraph-R1 模型在基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有场景表示方法在空间与功能关系分离、忽略对象状态或时间更新、以及缺乏任务相关信息的问题。

Method: 提出 MomaGraph，一种集成了空间功能关系和部件级交互元素的统一场景表示方法，并开发了 MomaGraph-R1，一个通过强化学习在 MomaGraph-Scenes 上训练的 7B 视觉语言模型。

Result: MomaGraph-R1 在基准测试中表现优异，准确率达到 71.6%，比最佳基线高出 11.4%。

Conclusion: MomaGraph-R1 在基准测试中达到了 71.6% 的准确率（比最佳基线高出 11.4%），并在公开基准测试中展现出良好的泛化能力，同时能有效迁移到真实机器人实验中。

Abstract: Mobile manipulators in households must both navigate and manipulate. This requires a compact, semantically rich scene representation that captures where objects are, how they function, and which parts are actionable. Scene graphs are a natural choice, yet prior work often separates spatial and functional relations, treats scenes as static snapshots without object states or temporal updates, and overlooks information most relevant for accomplishing the current task. To address these limitations, we introduce MomaGraph, a unified scene representation for embodied agents that integrates spatial-functional relationships and part-level interactive elements. However, advancing such a representation requires both suitable data and rigorous evaluation, which have been largely missing. We thus contribute MomaGraph-Scenes, the first large-scale dataset of richly annotated, task-driven scene graphs in household environments, along with MomaGraph-Bench, a systematic evaluation suite spanning six reasoning capabilities from high-level planning to fine-grained scene understanding. Built upon this foundation, we further develop MomaGraph-R1, a 7B vision-language model trained with reinforcement learning on MomaGraph-Scenes. MomaGraph-R1 predicts task-oriented scene graphs and serves as a zero-shot task planner under a Graph-then-Plan framework. Extensive experiments demonstrate that our model achieves state-of-the-art results among open-source models, reaching 71.6% accuracy on the benchmark (+11.4% over the best baseline), while generalizing across public benchmarks and transferring effectively to real-robot experiments.

</details>


### [41] [Pixel Super-Resolved Fluorescence Lifetime Imaging Using Deep Learning](https://arxiv.org/abs/2512.16266)
*Paloma Casteleiro Costa,Parnian Ghapandar Kashani,Xuhui Liu,Alexander Chen,Ary Portes,Julien Bec,Laura Marcu,Aydogan Ozcan*

Main category: cs.CV

TL;DR: FLIM_PSR_k是一种基于cGAN的深度学习框架，能显著提升FLIM图像分辨率，加速临床转化。


<details>
  <summary>Details</summary>
Motivation: 解决FLIM技术因长像素停留时间和低信噪比（SNR）导致的临床应用受限问题。

Method: 采用基于条件生成对抗网络（cGAN）的像素超分辨率框架，从像素尺寸增加5倍的数据中重建高分辨率FLIM图像。

Result: 在患者来源的肿瘤组织样本上盲测显示，FLIM_PSR_k可靠地实现了5倍超分辨率因子，图像质量显著提升。

Conclusion: FLIM_PSR_k通过深度学习技术显著提高了FLIM图像的空间分辨率，使其在临床应用中更具潜力。

Abstract: Fluorescence lifetime imaging microscopy (FLIM) is a powerful quantitative technique that provides metabolic and molecular contrast, offering strong translational potential for label-free, real-time diagnostics. However, its clinical adoption remains limited by long pixel dwell times and low signal-to-noise ratio (SNR), which impose a stricter resolution-speed trade-off than conventional optical imaging approaches. Here, we introduce FLIM_PSR_k, a deep learning-based multi-channel pixel super-resolution (PSR) framework that reconstructs high-resolution FLIM images from data acquired with up to a 5-fold increased pixel size. The model is trained using the conditional generative adversarial network (cGAN) framework, which, compared to diffusion model-based alternatives, delivers a more robust PSR reconstruction with substantially shorter inference times, a crucial advantage for practical deployment. FLIM_PSR_k not only enables faster image acquisition but can also alleviate SNR limitations in autofluorescence-based FLIM. Blind testing on held-out patient-derived tumor tissue samples demonstrates that FLIM_PSR_k reliably achieves a super-resolution factor of k = 5, resulting in a 25-fold increase in the space-bandwidth product of the output images and revealing fine architectural features lost in lower-resolution inputs, with statistically significant improvements across various image quality metrics. By increasing FLIM's effective spatial resolution, FLIM_PSR_k advances lifetime imaging toward faster, higher-resolution, and hardware-flexible implementations compatible with low-numerical-aperture and miniaturized platforms, better positioning FLIM for translational applications.

</details>


### [42] [DVGT: Driving Visual Geometry Transformer](https://arxiv.org/abs/2512.16919)
*Sicheng Zuo,Zixun Xie,Wenzhao Zheng,Shaoqing Xu,Fang Li,Shengyin Jiang,Long Chen,Zhi-Xin Yang,Jiwen Lu*

Main category: cs.CV

TL;DR: DVGT是一种无需精确相机参数的自适应3D几何感知模型，通过多视角输入重建全局密集3D点地图，性能优越。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶领域缺乏适应不同场景和相机配置的密集几何感知模型的问题。

Method: 使用DINO骨干网络提取视觉特征，结合交替的视图内局部注意力、跨视图空间注意力和跨帧时间注意力推断几何关系，最终解码生成全局点地图和每帧的自我姿态。

Result: DVGT在nuScenes、OpenScene、Waymo、KITTI和DDAD等数据集上训练后，性能显著优于现有模型。

Conclusion: DVGT通过无显式3D几何先验的方法，成功实现了从多视角视觉输入中重建全局密集3D点地图，适用于任意相机配置，显著优于现有模型。

Abstract: Perceiving and reconstructing 3D scene geometry from visual inputs is crucial for autonomous driving. However, there still lacks a driving-targeted dense geometry perception model that can adapt to different scenarios and camera configurations. To bridge this gap, we propose a Driving Visual Geometry Transformer (DVGT), which reconstructs a global dense 3D point map from a sequence of unposed multi-view visual inputs. We first extract visual features for each image using a DINO backbone, and employ alternating intra-view local attention, cross-view spatial attention, and cross-frame temporal attention to infer geometric relations across images. We then use multiple heads to decode a global point map in the ego coordinate of the first frame and the ego poses for each frame. Unlike conventional methods that rely on precise camera parameters, DVGT is free of explicit 3D geometric priors, enabling flexible processing of arbitrary camera configurations. DVGT directly predicts metric-scaled geometry from image sequences, eliminating the need for post-alignment with external sensors. Trained on a large mixture of driving datasets including nuScenes, OpenScene, Waymo, KITTI, and DDAD, DVGT significantly outperforms existing models on various scenarios. Code is available at https://github.com/wzzheng/DVGT.

</details>


### [43] [TextEditBench: Evaluating Reasoning-aware Text Editing Beyond Rendering](https://arxiv.org/abs/2512.16270)
*Rui Gui,Yang Wan,Haochen Han,Dongxing Mao,Fangming Liu,Min Li,Alex Jinpeng Wang*

Main category: cs.CV

TL;DR: TextEditBench 是一个专注于图像中文本编辑的评估基准，强调推理密集型编辑场景，并揭示了当前模型在复杂推理任务上的不足。


<details>
  <summary>Details</summary>
Motivation: 图像中的文本编辑是一个未被充分探索的领域，需要生成可读字符的同时保持语义、几何和上下文的一致性。

Method: 提出了 TextEditBench，一个专注于图像中文本区域的综合评估基准，并引入了新的评估维度 Semantic Expectation (SE)。

Result: 实验表明，当前模型在遵循简单文本指令方面表现良好，但在上下文依赖推理、物理一致性和布局感知整合方面仍有困难。

Conclusion: TextEditBench 填补了图像中文本编辑评估的空白，为多模态生成中的文本引导图像编辑和推理提供了新的测试基准。

Abstract: Text rendering has recently emerged as one of the most challenging frontiers in visual generation, drawing significant attention from large-scale diffusion and multimodal models. However, text editing within images remains largely unexplored, as it requires generating legible characters while preserving semantic, geometric, and contextual coherence. To fill this gap, we introduce TextEditBench, a comprehensive evaluation benchmark that explicitly focuses on text-centric regions in images. Beyond basic pixel manipulations, our benchmark emphasizes reasoning-intensive editing scenarios that require models to understand physical plausibility, linguistic meaning, and cross-modal dependencies. We further propose a novel evaluation dimension, Semantic Expectation (SE), which measures reasoning ability of model to maintain semantic consistency, contextual coherence, and cross-modal alignment during text editing. Extensive experiments on state-of-the-art editing systems reveal that while current models can follow simple textual instructions, they still struggle with context-dependent reasoning, physical consistency, and layout-aware integration. By focusing evaluation on this long-overlooked yet fundamental capability, TextEditBench establishes a new testing ground for advancing text-guided image editing and reasoning in multimodal generation.

</details>


### [44] [GFLAN: Generative Functional Layouts](https://arxiv.org/abs/2512.16275)
*Mohamed Abouagour,Eleftherios Garyfallidis*

Main category: cs.CV

TL;DR: GFLAN是一种生成框架，通过两阶段分解（拓扑规划和几何实现）改进自动化楼层平面生成，解决了现有方法在建筑推理方面的不足。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习方法在捕捉建筑推理方面存在不足，如拓扑关系优先于几何实例化、功能约束通过邻接网络的传播等。GFLAN旨在通过明确的分解解决这些基本挑战。

Method: GFLAN采用两阶段生成方法：第一阶段使用具有双编码器的卷积架构，通过离散概率图在建筑包络内分配房间中心点；第二阶段构建异构图，应用Transformer增强的图神经网络联合回归房间边界。

Result: GFLAN在自动化楼层平面生成中表现出色，特别是在处理拓扑规划和几何实现方面，优于现有的像素到像素或墙追踪生成方法。

Conclusion: GFLAN框架通过将楼层平面生成分解为拓扑规划和几何实现两个阶段，显著提升了自动化楼层平面生成的性能，尤其是在捕捉建筑推理方面。

Abstract: Automated floor plan generation lies at the intersection of combinatorial search, geometric constraint satisfaction, and functional design requirements -- a confluence that has historically resisted a unified computational treatment. While recent deep learning approaches have improved the state of the art, they often struggle to capture architectural reasoning: the precedence of topological relationships over geometric instantiation, the propagation of functional constraints through adjacency networks, and the emergence of circulation patterns from local connectivity decisions. To address these fundamental challenges, this paper introduces GFLAN, a generative framework that restructures floor plan synthesis through explicit factorization into topological planning and geometric realization. Given a single exterior boundary and a front-door location, our approach departs from direct pixel-to-pixel or wall-tracing generation in favor of a principled two-stage decomposition. Stage A employs a specialized convolutional architecture with dual encoders -- separating invariant spatial context from evolving layout state -- to sequentially allocate room centroids within the building envelope via discrete probability maps over feasible placements. Stage B constructs a heterogeneous graph linking room nodes to boundary vertices, then applies a Transformer-augmented graph neural network (GNN) that jointly regresses room boundaries.

</details>


### [45] [MACL: Multi-Label Adaptive Contrastive Learning Loss for Remote Sensing Image Retrieval](https://arxiv.org/abs/2512.16294)
*Amna Amir,Erchan Aptoula*

Main category: cs.CV

TL;DR: MACL通过自适应对比学习技术，解决了多标签遥感图像检索中的语义不平衡问题，显著提升了检索性能。


<details>
  <summary>Details</summary>
Motivation: 解决遥感图像检索中语义重叠、标签分布极度不平衡和复杂类别共现模式的挑战。

Method: 提出了多标签自适应对比学习（MACL），结合标签感知采样、频率敏感加权和动态温度缩放技术。

Result: 在三个基准数据集（DLRSD、ML-AID和WHDLD）上的实验表明，MACL优于基于对比损失的基线方法，有效缓解了语义不平衡问题。

Conclusion: MACL通过整合标签感知采样、频率敏感加权和动态温度缩放，在多标签遥感图像检索中实现了跨常见和稀有类别的平衡表示学习，显著提升了检索性能。

Abstract: Semantic overlap among land-cover categories, highly imbalanced label distributions, and complex inter-class co-occurrence patterns constitute significant challenges for multi-label remote-sensing image retrieval. In this article, Multi-Label Adaptive Contrastive Learning (MACL) is introduced as an extension of contrastive learning to address them. It integrates label-aware sampling, frequency-sensitive weighting, and dynamic-temperature scaling to achieve balanced representation learning across both common and rare categories. Extensive experiments on three benchmark datasets (DLRSD, ML-AID, and WHDLD), show that MACL consistently outperforms contrastive-loss based baselines, effectively mitigating semantic imbalance and delivering more reliable retrieval performance in large-scale remote-sensing archives. Code, pretrained models, and evaluation scripts will be released at https://github.com/amna/MACL upon acceptance.

</details>


### [46] [PixelArena: A benchmark for Pixel-Precision Visual Intelligence](https://arxiv.org/abs/2512.16303)
*Feng Liang,Sizhe Cheng,Chenqi Yi*

Main category: cs.CV

TL;DR: PixelArena通过语义分割任务评估多模态大模型的细粒度生成能力，发现Gemini 3 Pro Image在零样本设置下表现优异，为未来研究提供方向。


<details>
  <summary>Details</summary>
Motivation: 现有的图像生成基准过于关注美学而非细粒度生成能力，因此需要一种新的评估方法来客观检验模型的像素级生成智能。

Method: 使用语义分割任务（PixelArena）客观评估模型的细粒度生成能力，并进行定性和定量比较。

Result: Gemini 3 Pro Image在零样本设置下生成高保真语义掩码，展现出新兴的图像生成能力和视觉智能。

Conclusion: 研究发现Gemini 3 Pro Image在零样本设置下展现出前所未有的视觉智能和真实泛化能力，为多模态、推理、可解释性和基准测试的未来研究提供了见解。

Abstract: Multi-modal large language models that have image output are emerging. Many image generation benchmarks focus on aesthetics instead of fine-grained generation capabilities. In PixelArena, we propose using semantic segmentation tasks to objectively examine their fine-grained generative intelligence with pixel precision. We find the latest Gemini 3 Pro Image has emergent image generation capabilities that generate semantic masks with high fidelity under zero-shot settings, showcasing visual intelligence unseen before and true generalization in new image generation tasks. We further investigate its results, compare them qualitatively and quantitatively with those of other models, and present failure cases. The findings not only signal exciting progress in the field but also provide insights into future research related to multimodality, reasoning, interpretability and benchmarking.

</details>


### [47] [LaverNet: Lightweight All-in-one Video Restoration via Selective Propagation](https://arxiv.org/abs/2512.16313)
*Haiyu Zhao,Yiwen Shan,Yuanbiao Gou,Xi Peng*

Main category: cs.CV

TL;DR: 轻量级网络LaverNet通过选择性特征传播，高效解决全功能视频恢复问题，性能媲美大型模型。


<details>
  <summary>Details</summary>
Motivation: 现有全功能视频恢复方法在处理时变退化时面临两大挑战：退化可能主导时间建模，混淆模型对内容的关注；且通常依赖大型模型掩盖问题。

Method: 提出了一种轻量级全功能视频恢复网络LaverNet（仅362K参数），并引入了一种新颖的传播机制，选择性传递与退化无关的特征。

Result: LaverNet在参数不到现有模型1%的情况下，性能相当甚至更优。

Conclusion: LaverNet通过轻量级网络设计，展示了在参数极少的情况下仍能实现强大的全功能视频恢复性能，甚至超越现有大型模型。

Abstract: Recent studies have explored all-in-one video restoration, which handles multiple degradations with a unified model. However, these approaches still face two challenges when dealing with time-varying degradations. First, the degradation can dominate temporal modeling, confusing the model to focus on artifacts rather than the video content. Second, current methods typically rely on large models to handle all-in-one restoration, concealing those underlying difficulties. To address these challenges, we propose a lightweight all-in-one video restoration network, LaverNet, with only 362K parameters. To mitigate the impact of degradations on temporal modeling, we introduce a novel propagation mechanism that selectively transmits only degradation-agnostic features across frames. Through LaverNet, we demonstrate that strong all-in-one restoration can be achieved with a compact network. Despite its small size, less than 1\% of the parameters of existing models, LaverNet achieves comparable, even superior performance across benchmarks.

</details>


### [48] [Ridge Estimation-Based Vision and Laser Ranging Fusion Localization Method for UAVs](https://arxiv.org/abs/2512.16314)
*Huayu Huang,Chen Chen,Banglei Guan,Ze Tan,Yang Shang,Zhang Li,Qifeng Yu*

Main category: cs.CV

TL;DR: 提出基于岭估计的融合定位方法，结合图像和激光数据，在有限观测条件下提升定位精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在有限观测条件下（如长距离、小交角和大倾角），最小二乘估计算法的设计矩阵列向量存在严重多重共线性，导致病态问题和低鲁棒性。

Method: 结合序列图像的丰富场景信息和激光测距的高精度，采用岭估计来缓解设计矩阵列向量的严重多重共线性问题。

Result: 实验结果表明，该方法相比基于单一信息的地面定位算法具有更高的定位精度，且岭估计的引入显著提升了鲁棒性。

Conclusion: 本文提出的基于岭估计的融合定位方法在有限观测条件下显著提高了定位精度和鲁棒性，尤其在长距离、小交角和大倾角等挑战性场景中表现优异。

Abstract: Tracking and measuring targets using a variety of sensors mounted on UAVs is an effective means to quickly and accurately locate the target. This paper proposes a fusion localization method based on ridge estimation, combining the advantages of rich scene information from sequential imagery with the high precision of laser ranging to enhance localization accuracy. Under limited conditions such as long distances, small intersection angles, and large inclination angles, the column vectors of the design matrix have serious multicollinearity when using the least squares estimation algorithm. The multicollinearity will lead to ill-conditioned problems, resulting in significant instability and low robustness. Ridge estimation is introduced to mitigate the serious multicollinearity under the condition of limited observation. Experimental results demonstrate that our method achieves higher localization accuracy compared to ground localization algorithms based on single information. Moreover, the introduction of ridge estimation effectively enhances the robustness, particularly under limited observation conditions.

</details>


### [49] [QUIDS: Quality-informed Incentive-driven Multi-agent Dispatching System for Mobile Crowdsensing](https://arxiv.org/abs/2512.16325)
*Nan Zhou,Zuxin Li,Fanhang Man,Xuecheng Chen,Susu Xu,Fan Dang,Chaopeng Hong,Yunhao Liu,Xiao-Ping Zhang,Xinlei Chen*

Main category: cs.CV

TL;DR: QUIDS是一种质量感知激励驱动的多智能体调度系统，显著提升了非专用车辆移动群智感知系统的信息质量。


<details>
  <summary>Details</summary>
Motivation: 解决非专用车辆移动群智感知系统中信息质量优化的挑战，特别是感知覆盖、可靠性和车辆动态参与的相互关联问题。

Method: 提出了QUIDS系统，包括新型度量标准ASQ和Mutually Assisted Belief-aware Vehicle Dispatching算法，用于在预算约束下提高感知覆盖和可靠性。

Result: 评估显示QUIDS比非调度场景提高了38%的ASQ，比现有最优方法提高了10%，并减少了39-74%的重建地图误差。

Conclusion: QUIDS通过联合优化覆盖范围和可靠性，实现了低成本、高质量的城市场景监测，适用于智能城市中的交通和环境感知等场景。

Abstract: This paper addresses the challenge of achieving optimal Quality of Information (QoI) in non-dedicated vehicular mobile crowdsensing (NVMCS) systems. The key obstacles are the interrelated issues of sensing coverage, sensing reliability, and the dynamic participation of vehicles. To tackle these, we propose QUIDS, a QUality-informed Incentive-driven multi-agent Dispatching System, which ensures high sensing coverage and reliability under budget constraints. QUIDS introduces a novel metric, Aggregated Sensing Quality (ASQ), to quantitatively capture QoI by integrating both coverage and reliability. We also develop a Mutually Assisted Belief-aware Vehicle Dispatching algorithm that estimates sensing reliability and allocates incentives under uncertainty, further improving ASQ. Evaluation using real-world data from a metropolitan NVMCS deployment shows QUIDS improves ASQ by 38% over non-dispatching scenarios and by 10% over state-of-the-art methods. It also reduces reconstruction map errors by 39-74% across algorithms. By jointly optimizing coverage and reliability via a quality-informed incentive mechanism, QUIDS enables low-cost, high-quality urban monitoring without dedicated infrastructure, applicable to smart-city scenarios like traffic and environmental sensing.

</details>


### [50] [Collaborative Edge-to-Server Inference for Vision-Language Models](https://arxiv.org/abs/2512.16349)
*Soochang Song,Yongjune Kim*

Main category: cs.CV

TL;DR: 提出一种两阶段协作边缘到服务器推理框架，通过选择性重传策略减少通信成本，同时保持准确性。


<details>
  <summary>Details</summary>
Motivation: 解决传统部署中因调整图像分辨率而丢失细粒度细节导致准确性下降的问题。

Method: 设计了一个两阶段框架：第一阶段服务器在全局图像上执行推理并识别兴趣区域（RoI）；第二阶段根据输出令牌的最小熵决定是否需要重传，若需要则请求边缘设备发送RoI的细节保留局部图像，最后联合利用全局和局部图像优化推理。

Result: 实验表明，该框架在多种VLM架构上显著降低了通信成本并保持了推理准确性。

Conclusion: 提出的协作边缘到服务器推理框架在显著降低通信成本的同时保持了推理准确性，适用于多种VLM架构。

Abstract: We propose a collaborative edge-to-server inference framework for vision-language models (VLMs) that reduces the communication cost while maintaining inference accuracy. In typical deployments, visual data captured at edge devices (clients) is transmitted to the server for VLM inference. However, resizing the original image (global image) to match the vision encoder's input resolution often discards fine-grained details, leading to accuracy degradation. To overcome this limitation, we design a two-stage framework. In the first stage, the server performs inference on the global image and identifies a region of interest (RoI) using the VLM's internal attention. The min-entropy of the output tokens is then computed as a confidence measure to determine whether retransmission is required. If the min-entropy exceeds a predefined threshold, the server requests the edge device to send a detail-preserved local image of the RoI. The server then refines its inference by jointly leveraging the global and local images. This selective retransmission strategy ensures that only essential visual content is transmitted. Experiments across multiple VLM architectures show that the proposed framework significantly reduces communication cost while maintaining inference accuracy.

</details>


### [51] [GMODiff: One-Step Gain Map Refinement with Diffusion Priors for HDR Reconstruction](https://arxiv.org/abs/2512.16357)
*Tao Hu,Weiyu Zhou,Yanjie Tu,Peng Wu,Wei Dong,Qingsen Yan,Yanning Zhang*

Main category: cs.CV

TL;DR: GMODiff 通过增益图驱动的单步扩散框架，解决了 LDM 在 HDR 重建中的动态范围、速度和幻觉问题，实现了高效高质量的 HDR 重建。


<details>
  <summary>Details</summary>
Motivation: 现有 LDM 方法在 HDR 重建中面临动态范围受限、推理成本高和内容幻觉问题，需要一种更高效且准确的解决方案。

Method: GMODiff 采用增益图驱动的单步扩散框架，将 HDR 重建任务重新定义为条件引导的增益图估计任务，并利用回归先验引导去噪过程和潜在解码。

Result: GMODiff 在实验中表现优于多种先进方法，推理速度比基于 LDM 的方法快 100 倍。

Conclusion: GMODiff 是一种高效且高质量的 HDR 重建方法，通过增益图估计和一步扩散框架，显著提升了动态范围重建的速度和质量。

Abstract: Pre-trained Latent Diffusion Models (LDMs) have recently shown strong perceptual priors for low-level vision tasks, making them a promising direction for multi-exposure High Dynamic Range (HDR) reconstruction. However, directly applying LDMs to HDR remains challenging due to: (1) limited dynamic-range representation caused by 8-bit latent compression, (2) high inference cost from multi-step denoising, and (3) content hallucination inherent to generative nature. To address these challenges, we introduce GMODiff, a gain map-driven one-step diffusion framework for multi-exposure HDR reconstruction. Instead of reconstructing full HDR content, we reformulate HDR reconstruction as a conditionally guided Gain Map (GM) estimation task, where the GM encodes the extended dynamic range while retaining the same bit depth as LDR images. We initialize the denoising process from an informative regression-based estimate rather than pure noise, enabling the model to generate high-quality GMs in a single denoising step. Furthermore, recognizing that regression-based models excel in content fidelity while LDMs favor perceptual quality, we leverage regression priors to guide both the denoising process and latent decoding of the LDM, suppressing hallucinations while preserving structural accuracy. Extensive experiments demonstrate that our GMODiff performs favorably against several state-of-the-art methods and is 100 faster than previous LDM-based methods.

</details>


### [52] [EverybodyDance: Bipartite Graph-Based Identity Correspondence for Multi-Character Animation](https://arxiv.org/abs/2512.16360)
*Haotian Ling,Zequn Chen,Qiuying Chen,Donglin Di,Yongjia Ma,Hao Li,Chen Wei,Zhulin Tao,Xun Yang*

Main category: cs.CV

TL;DR: EverybodyDance通过身份匹配图和针对性策略，解决了多角色动画中的身份对应问题，显著提升效果。


<details>
  <summary>Details</summary>
Motivation: 多角色动画中位置交换时的身份对应（IC）正确性是核心挑战，现有方法难以直接扩展。

Method: 该方法围绕身份匹配图（IMG）构建，通过掩码查询注意力（MQA）计算节点间亲和力，并将IC正确性建模为图结构度量进行优化。同时采用身份嵌入引导、多尺度匹配策略和预分类采样等策略。

Result: 实验表明，EverybodyDance在IC正确性和视觉保真度上显著优于现有基线方法。

Conclusion: EverybodyDance显著提升了多角色动画中的身份对应（IC）正确性和视觉保真度，通过引入身份匹配图（IMG）和一系列针对性策略，为多角色动画提供了系统化解决方案。

Abstract: Consistent pose-driven character animation has achieved remarkable progress in single-character scenarios. However, extending these advances to multi-character settings is non-trivial, especially when position swap is involved. Beyond mere scaling, the core challenge lies in enforcing correct Identity Correspondence (IC) between characters in reference and generated frames. To address this, we introduce EverybodyDance, a systematic solution targeting IC correctness in multi-character animation. EverybodyDance is built around the Identity Matching Graph (IMG), which models characters in the generated and reference frames as two node sets in a weighted complete bipartite graph. Edge weights, computed via our proposed Mask-Query Attention (MQA), quantify the affinity between each pair of characters. Our key insight is to formalize IC correctness as a graph structural metric and to optimize it during training. We also propose a series of targeted strategies tailored for multi-character animation, including identity-embedded guidance, a multi-scale matching strategy, and pre-classified sampling, which work synergistically. Finally, to evaluate IC performance, we curate the Identity Correspondence Evaluation benchmark, dedicated to multi-character IC correctness. Extensive experiments demonstrate that EverybodyDance substantially outperforms state-of-the-art baselines in both IC and visual fidelity.

</details>


### [53] [Factorized Video Generation: Decoupling Scene Construction and Temporal Synthesis in Text-to-Video Diffusion Models](https://arxiv.org/abs/2512.16371)
*Mariam Hassan,Bastien Van Delft,Wuyang Li,Alexandre Alahi*

Main category: cs.CV

TL;DR: FVG 通过分解任务提升视频生成质量，显著提高性能并加速采样。


<details>
  <summary>Details</summary>
Motivation: 当前 T2V 扩散模型在生成复杂场景或遵循逻辑时序指令时经常失败，许多错误源于模型无法构建语义正确或逻辑一致的初始帧。

Method: FVG 将文本到视频生成分解为三个专门阶段：推理（LLM 重写视频提示以描述初始场景）、构图（T2I 模型合成高质量的锚定帧）和时序合成（视频模型专注于动画化场景）。

Result: FVG 在 T2V CompBench 基准测试中创下新记录，并在 VBench2 上显著提升所有测试模型性能，同时将采样步骤减少 70%。

Conclusion: Factorized Video Generation (FVG) 提供了一种简单而实用的方法，实现了更高效、稳健和可控的视频合成。

Abstract: State-of-the-art Text-to-Video (T2V) diffusion models can generate visually impressive results, yet they still frequently fail to compose complex scenes or follow logical temporal instructions. In this paper, we argue that many errors, including apparent motion failures, originate from the model's inability to construct a semantically correct or logically consistent initial frame. We introduce Factorized Video Generation (FVG), a pipeline that decouples these tasks by decomposing the Text-to-Video generation into three specialized stages: (1) Reasoning, where a Large Language Model (LLM) rewrites the video prompt to describe only the initial scene, resolving temporal ambiguities; (2) Composition, where a Text-to-Image (T2I) model synthesizes a high-quality, compositionally-correct anchor frame from this new prompt; and (3) Temporal Synthesis, where a video model, finetuned to understand this anchor, focuses its entire capacity on animating the scene and following the prompt. Our decomposed approach sets a new state-of-the-art on the T2V CompBench benchmark and significantly improves all tested models on VBench2. Furthermore, we show that visual anchoring allows us to cut the number of sampling steps by 70% without any loss in performance, leading to a substantial speed-up in sampling. Factorized Video Generation offers a simple yet practical path toward more efficient, robust, and controllable video synthesis

</details>


### [54] [Adaptive Frequency Domain Alignment Network for Medical image segmentation](https://arxiv.org/abs/2512.16393)
*Zhanwei Li,Liang Li,Jiawan Zhang*

Main category: cs.CV

TL;DR: AFDAN是一种频域对齐的域适应框架，通过对抗学习和频域融合提升医学图像分割性能。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割的高质量标注数据稀缺，手动标注耗时耗力，因此需要一种有效的域适应方法来缓解这一问题。

Method: AFDAN结合了对抗域学习模块、源-目标频域融合模块和空间-频域集成模块，以实现跨域知识迁移。

Result: AFDAN在VITILIGO2025数据集上实现了90.9%的IoU，在DRIVE基准测试中达到了82.6%的IoU，超越了现有方法。

Conclusion: AFDAN通过频域特征对齐有效缓解了医学图像分割中的数据稀缺问题，并在多个数据集上实现了优于现有方法的性能。

Abstract: High-quality annotated data plays a crucial role in achieving accurate segmentation. However, such data for medical image segmentation are often scarce due to the time-consuming and labor-intensive nature of manual annotation. To address this challenge, we propose the Adaptive Frequency Domain Alignment Network (AFDAN)--a novel domain adaptation framework designed to align features in the frequency domain and alleviate data scarcity. AFDAN integrates three core components to enable robust cross-domain knowledge transfer: an Adversarial Domain Learning Module that transfers features from the source to the target domain; a Source-Target Frequency Fusion Module that blends frequency representations across domains; and a Spatial-Frequency Integration Module that combines both frequency and spatial features to further enhance segmentation accuracy across domains. Extensive experiments demonstrate the effectiveness of AFDAN: it achieves an Intersection over Union (IoU) of 90.9% for vitiligo segmentation in the newly constructed VITILIGO2025 dataset and a competitive IoU of 82.6% on the retinal vessel segmentation benchmark DRIVE, surpassing existing state-of-the-art approaches.

</details>


### [55] [BrepLLM: Native Boundary Representation Understanding with Large Language Models](https://arxiv.org/abs/2512.16413)
*Liyuan Deng,Hao Guo,Yunpeng Bai,Yongkang Dai,Huaxi Huang,Yilei Shi*

Main category: cs.CV

TL;DR: BrepLLM是首个能直接解析和处理3D Brep数据的LLM框架，通过两阶段训练和Brep2Text数据集，实现了3D几何与自然语言的高效交互。


<details>
  <summary>Details</summary>
Motivation: 当前基于token序列的LLM难以直接处理包含复杂几何和拓扑信息的3D Brep模型，需要一种新框架来弥合3D几何与自然语言之间的模态差距。

Method: 采用两阶段训练流程：跨模态对齐预训练和多阶段LLM微调。第一阶段通过自适应UV采样将Brep转换为图表示，并设计分层BrepEncoder提取几何和拓扑特征；第二阶段通过三阶段渐进训练策略整合预训练的BrepEncoder到LLM中。

Result: 实验表明，BrepLLM在3D物体分类和描述任务上取得了最先进的结果。

Conclusion: BrepLLM通过创新的两阶段训练流程和数据集构建，成功填补了3D Brep模型与自然语言处理之间的模态鸿沟，并在3D物体分类和描述任务上达到了最先进水平。

Abstract: Current token-sequence-based Large Language Models (LLMs) are not well-suited for directly processing 3D Boundary Representation (Brep) models that contain complex geometric and topological information. We propose BrepLLM, the first framework that enables LLMs to parse and reason over raw Brep data, bridging the modality gap between structured 3D geometry and natural language. BrepLLM employs a two-stage training pipeline: Cross-modal Alignment Pre-training and Multi-stage LLM Fine-tuning. In the first stage, an adaptive UV sampling strategy converts Breps into graphs representation with geometric and topological information. We then design a hierarchical BrepEncoder to extract features from geometry (i.e., faces and edges) and topology, producing both a single global token and a sequence of node tokens. Then we align the global token with text embeddings from a frozen CLIP text encoder (ViT-L/14) via contrastive learning. In the second stage, we integrate the pretrained BrepEncoder into an LLM. We then align its sequence of node tokens using a three-stage progressive training strategy: (1) training an MLP-based semantic mapping from Brep representation to 2D with 2D-LLM priors. (2) performing fine-tuning of the LLM. (3) designing a Mixture-of-Query Experts (MQE) to enhance geometric diversity modeling. We also construct Brep2Text, a dataset comprising 269,444 Brep-text question-answer pairs. Experiments show that BrepLLM achieves state-of-the-art (SOTA) results on 3D object classification and captioning tasks.

</details>


### [56] [CountZES: Counting via Zero-Shot Exemplar Selection](https://arxiv.org/abs/2512.16415)
*Muhammad Ibraheem Siddiqui,Muhammad Haris Khan*

Main category: cs.CV

TL;DR: CountZES是一种无训练的零样本目标计数框架，通过三个阶段（DAE、DGE、FCE）协同发现多样化样本，显著提升性能并实现跨领域泛化。


<details>
  <summary>Details</summary>
Motivation: 解决零样本目标计数（ZOC）中现有方法的局限性，如开放词汇检测器产生的多实例候选或随机补丁采样无法准确描绘目标实例的问题。

Method: CountZES采用无训练框架，通过三个阶段逐步发现多样化的样本：DAE（检测锚定样本）、DGE（密度引导样本）和FCE（特征共识样本）。DAE优化开放词汇检测以隔离精确的单实例样本；DGE通过密度驱动的自监督范式识别统计一致且语义紧凑的样本；FCE通过特征空间聚类增强视觉一致性。

Result: 在多个数据集上的实验表明，CountZES在ZOC方法中表现优异，并在自然、航空和医疗领域具有有效的泛化能力。

Conclusion: CountZES通过三个阶段（DAE、DGE、FCE）的协同作用，显著提升了零样本目标计数的性能，并在多个领域（自然、航空、医疗）中展现出优异的泛化能力。

Abstract: Object counting in complex scenes remains challenging, particularly in the zero-shot setting, where the goal is to count instances of unseen categories specified only by a class name. Existing zero-shot object counting (ZOC) methods that infer exemplars from text either rely on open-vocabulary detectors, which often yield multi-instance candidates, or on random patch sampling, which fails to accurately delineate object instances. To address this, we propose CountZES, a training-free framework for object counting via zero-shot exemplar selection. CountZES progressively discovers diverse exemplars through three synergistic stages: Detection-Anchored Exemplar (DAE), Density-Guided Exemplar (DGE), and Feature-Consensus Exemplar (FCE). DAE refines open-vocabulary detections to isolate precise single-instance exemplars. DGE introduces a density-driven, self-supervised paradigm to identify statistically consistent and semantically compact exemplars, while FCE reinforces visual coherence through feature-space clustering. Together, these stages yield a diverse, complementary exemplar set that balances textual grounding, count consistency, and feature representativeness. Experiments on diverse datasets demonstrate CountZES superior performance among ZOC methods while generalizing effectively across natural, aerial and medical domains.

</details>


### [57] [Geometric Disentanglement of Text Embeddings for Subject-Consistent Text-to-Image Generation using A Single Prompt](https://arxiv.org/abs/2512.16443)
*Shangxun Li,Youngjung Uh*

Main category: cs.CV

TL;DR: 本文提出一种训练免费方法，通过几何角度精炼文本嵌入解决语义纠缠问题，显著提升主题一致性和文本对齐。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像扩散模型在多输出中难以保持主题一致性，限制了其在视觉叙事中的应用。现有方法依赖模型微调或图像条件，计算成本高且需要逐主题优化。

Method: 提出了一种简单有效的训练免费方法，通过精炼文本嵌入来抑制不需要的语义，从几何角度解决语义纠缠问题。

Result: 大量实验证明，该方法在主题一致性和文本对齐方面显著优于现有基线。

Conclusion: 本文提出的训练免费方法通过从几何角度精炼文本嵌入，显著提高了主题一致性和文本对齐，优于现有基线。

Abstract: Text-to-image diffusion models excel at generating high-quality images from natural language descriptions but often fail to preserve subject consistency across multiple outputs, limiting their use in visual storytelling. Existing approaches rely on model fine-tuning or image conditioning, which are computationally expensive and require per-subject optimization. 1Prompt1Story, a training-free approach, concatenates all scene descriptions into a single prompt and rescales token embeddings, but it suffers from semantic leakage, where embeddings across frames become entangled, causing text misalignment. In this paper, we propose a simple yet effective training-free approach that addresses semantic entanglement from a geometric perspective by refining text embeddings to suppress unwanted semantics. Extensive experiments prove that our approach significantly improves both subject consistency and text alignment over existing baselines.

</details>


### [58] [Prime and Reach: Synthesising Body Motion for Gaze-Primed Object Reach](https://arxiv.org/abs/2512.16456)
*Masashi Hatano,Saptarshi Sinha,Jacob Chalk,Wei-Hong Li,Hideo Saito,Dima Damen*

Main category: cs.CV

TL;DR: 论文提出了一种扩散模型，用于生成模仿自然人类行为的动作序列，特别是在注视启动和到达目标位置的任务中表现良好。


<details>
  <summary>Details</summary>
Motivation: 人类动作生成是一个复杂任务，尤其是在模仿自然行为如注视启动和到达目标位置时。论文旨在通过扩散模型生成更自然的动作序列。

Method: 论文首先从五个公开数据集中筛选了23.7K个注视启动的人类动作序列，预训练了一个基于文本条件的扩散模型，然后根据目标姿态或位置进行微调。

Result: 在HD-EPIC数据集上，模型在目标物体位置条件下达到了60%的注视启动成功率和89%的到达成功率。

Conclusion: 该论文提出了一种基于扩散模型的人类动作生成方法，通过预训练和微调策略，成功生成了模仿自然人类行为的动作序列，特别是在注视启动和到达目标位置的动作上表现优异。

Abstract: Human motion generation is a challenging task that aims to create realistic motion imitating natural human behaviour. We focus on the well-studied behaviour of priming an object/location for pick up or put down -- that is, the spotting of an object/location from a distance, known as gaze priming, followed by the motion of approaching and reaching the target location. To that end, we curate, for the first time, 23.7K gaze-primed human motion sequences for reaching target object locations from five publicly available datasets, i.e., HD-EPIC, MoGaze, HOT3D, ADT, and GIMO. We pre-train a text-conditioned diffusion-based motion generation model, then fine-tune it conditioned on goal pose or location, on our curated sequences. Importantly, we evaluate the ability of the generated motion to imitate natural human movement through several metrics, including the 'Reach Success' and a newly introduced 'Prime Success' metric. On the largest dataset, HD-EPIC, our model achieves 60% prime success and 89% reach success when conditioned on the goal object location.

</details>


### [59] [StageVAR: Stage-Aware Acceleration for Visual Autoregressive Models](https://arxiv.org/abs/2512.16483)
*Senmao Li,Kai Wang,Salman Khan,Fahad Shahbaz Khan,Jian Yang,Yaxing Wang*

Main category: cs.CV

TL;DR: StageVAR是一种阶段感知加速框架，通过分析VAR模型不同阶段的重要性，优化后期计算以实现高效图像生成。


<details>
  <summary>Details</summary>
Motivation: VAR模型在大规模步骤下计算复杂度和运行时间急剧增加，现有加速方法依赖手动步骤选择且忽视生成过程中不同阶段的重要性。

Method: StageVAR提出了一个即插即用的加速策略，利用后期计算中的语义无关性和低秩特性，无需额外训练。

Result: StageVAR实现了最高3.4倍的加速，仅在GenEval上性能下降0.01，在DPG上下降0.26，优于现有加速基线。

Conclusion: StageVAR通过阶段感知设计，显著提升了VAR模型的效率，同时保持了生成质量，为高效视觉自回归图像生成提供了有力支持。

Abstract: Visual Autoregressive (VAR) modeling departs from the next-token prediction paradigm of traditional Autoregressive (AR) models through next-scale prediction, enabling high-quality image generation. However, the VAR paradigm suffers from sharply increased computational complexity and running time at large-scale steps. Although existing acceleration methods reduce runtime for large-scale steps, but rely on manual step selection and overlook the varying importance of different stages in the generation process. To address this challenge, we present StageVAR, a systematic study and stage-aware acceleration framework for VAR models. Our analysis shows that early steps are critical for preserving semantic and structural consistency and should remain intact, while later steps mainly refine details and can be pruned or approximated for acceleration. Building on these insights, StageVAR introduces a plug-and-play acceleration strategy that exploits semantic irrelevance and low-rank properties in late-stage computations, without requiring additional training. Our proposed StageVAR achieves up to 3.4x speedup with only a 0.01 drop on GenEval and a 0.26 decrease on DPG, consistently outperforming existing acceleration baselines. These results highlight stage-aware design as a powerful principle for efficient visual autoregressive image generation.

</details>


### [60] [Guiding Perception-Reasoning Closer to Human in Blind Image Quality Assessment](https://arxiv.org/abs/2512.16484)
*Yuan Li,Yahan Yu,Youyuan Lin,Yong-Hao Yang,Chenhui Chu,Shin'ya Nishida*

Main category: cs.CV

TL;DR: 研究通过强化学习训练模型实现人类相似的BIQA能力，评分预测与解释性均表现优异。


<details>
  <summary>Details</summary>
Motivation: 探索模型如何通过感知-推理级联获得与人类相似且自我一致的盲图像质量评估能力。

Method: 采用强化学习，以人类标注作为奖励信号，设计了一种驱动模型从自我生成的描述中推断图像质量的奖励机制。

Result: 模型在通用指标（如Pearson和Spearman相关系数）上表现与最先进的BIQA系统相当，且在人类-模型对齐评估中ROUGE-1得分显著高于基线（0.512 vs. 0.443）。

Conclusion: 该研究通过强化学习成功训练了一个模型，使其在盲图像质量评估（BIQA）中实现了与人类相似的感知-推理能力，并在评分预测和解释性方面表现出色。

Abstract: Humans assess image quality through a perception-reasoning cascade, integrating sensory cues with implicit reasoning to form self-consistent judgments. In this work, we investigate how a model can acquire both human-like and self-consistent reasoning capability for blind image quality assessment (BIQA). We first collect human evaluation data that capture several aspects of human perception-reasoning pipeline. Then, we adopt reinforcement learning, using human annotations as reward signals to guide the model toward human-like perception and reasoning. To enable the model to internalize self-consistent reasoning capability, we design a reward that drives the model to infer the image quality purely from self-generated descriptions. Empirically, our approach achieves score prediction performance comparable to state-of-the-art BIQA systems under general metrics, including Pearson and Spearman correlation coefficients. In addition to the rating score, we assess human-model alignment using ROUGE-1 to measure the similarity between model-generated and human perception-reasoning chains. On over 1,000 human-annotated samples, our model reaches a ROUGE-1 score of 0.512 (cf. 0.443 for baseline), indicating substantial coverage of human explanations and marking a step toward human-like interpretable reasoning in BIQA.

</details>


### [61] [Smile on the Face, Sadness in the Eyes: Bridging the Emotion Gap with a Multimodal Dataset of Eye and Facial Behaviors](https://arxiv.org/abs/2512.16485)
*Kejun Liu,Yuanyuan Liu,Lin Wei,Chang Tang,Yibing Zhan,Zijing Chen,Zhe Chen*

Main category: cs.CV

TL;DR: 本文提出眼动行为辅助的多模态情感识别方法，构建EMER数据集并设计EMERT模型，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前情感识别主要依赖面部表情，但面部表情常被用作社交工具而非真实情感表现。为弥补这一差距，引入眼动行为作为补充线索。

Method: 利用自发情感诱导范式收集真实情感数据，结合多模态标注，设计了基于模态对抗特征解耦和多任务Transformer的EMERT模型。

Result: EMERT模型在多种评估协议下显著优于现有方法，验证了眼动行为对情感识别的重要性。

Conclusion: 本文通过引入眼动行为作为情感识别的重要线索，构建了EMER数据集，并设计了EMERT模型，显著提升了情感识别的性能。数据集和模型将公开供研究使用。

Abstract: Emotion Recognition (ER) is the process of analyzing and identifying human emotions from sensing data. Currently, the field heavily relies on facial expression recognition (FER) because visual channel conveys rich emotional cues. However, facial expressions are often used as social tools rather than manifestations of genuine inner emotions. To understand and bridge this gap between FER and ER, we introduce eye behaviors as an important emotional cue and construct an Eye-behavior-aided Multimodal Emotion Recognition (EMER) dataset. To collect data with genuine emotions, spontaneous emotion induction paradigm is exploited with stimulus material, during which non-invasive eye behavior data, like eye movement sequences and eye fixation maps, is captured together with facial expression videos. To better illustrate the gap between ER and FER, multi-view emotion labels for mutimodal ER and FER are separately annotated. Furthermore, based on the new dataset, we design a simple yet effective Eye-behavior-aided MER Transformer (EMERT) that enhances ER by bridging the emotion gap. EMERT leverages modality-adversarial feature decoupling and a multitask Transformer to model eye behaviors as a strong complement to facial expressions. In the experiment, we introduce seven multimodal benchmark protocols for a variety of comprehensive evaluations of the EMER dataset. The results show that the EMERT outperforms other state-of-the-art multimodal methods by a great margin, revealing the importance of modeling eye behaviors for robust ER. To sum up, we provide a comprehensive analysis of the importance of eye behaviors in ER, advancing the study on addressing the gap between FER and ER for more robust ER performance. Our EMER dataset and the trained EMERT models will be publicly available at https://github.com/kejun1/EMER.

</details>


### [62] [YOLO11-4K: An Efficient Architecture for Real-Time Small Object Detection in 4K Panoramic Images](https://arxiv.org/abs/2512.16493)
*Huma Hafeez,Matthew Garratt,Jo Plested,Sankaran Iyer,Arcot Sowmya*

Main category: cs.CV

TL;DR: YOLO11-4K是一种针对4K全景图像的高效实时目标检测框架，通过多尺度检测头和GhostConv主干网络，显著提升性能并降低延迟。


<details>
  <summary>Details</summary>
Motivation: 解决传统检测器（如YOLO）在处理360度全景图像时因空间扭曲、宽视场和高分辨率输入带来的挑战。

Method: 提出了一种新颖的多尺度检测头（含P2层）和基于GhostConv的主干网络，以减少计算复杂度并提升对小物体的检测灵敏度。

Result: YOLO11-4K在CVIP360数据集上达到0.95 mAP（0.50 IoU），每帧推理时间为28.3毫秒，比YOLO11延迟降低75%，精度提升。

Conclusion: YOLO11-4K框架在4K全景图像中实现了高效实时的目标检测，平衡了效率和精度，适用于自动驾驶、监控和增强现实等应用。

Abstract: The processing of omnidirectional 360-degree images poses significant challenges for object detection due to inherent spatial distortions, wide fields of view, and ultra-high-resolution inputs. Conventional detectors such as YOLO are optimised for standard image sizes (for example, 640x640 pixels) and often struggle with the computational demands of 4K or higher-resolution imagery typical of 360-degree vision. To address these limitations, we introduce YOLO11-4K, an efficient real-time detection framework tailored for 4K panoramic images. The architecture incorporates a novel multi-scale detection head with a P2 layer to improve sensitivity to small objects often missed at coarser scales, and a GhostConv-based backbone to reduce computational complexity without sacrificing representational power. To enable evaluation, we manually annotated the CVIP360 dataset, generating 6,876 frame-level bounding boxes and producing a publicly available, detection-ready benchmark for 4K panoramic scenes. YOLO11-4K achieves 0.95 mAP at 0.50 IoU with 28.3 milliseconds inference per frame, representing a 75 percent latency reduction compared to YOLO11 (112.3 milliseconds), while also improving accuracy (mAP at 0.50 of 0.95 versus 0.908). This balance of efficiency and precision enables robust object detection in expansive 360-degree environments, making the framework suitable for real-world high-resolution panoramic applications. While this work focuses on 4K omnidirectional images, the approach is broadly applicable to high-resolution detection tasks in autonomous navigation, surveillance, and augmented reality.

</details>


### [63] [PoseMoE: Mixture-of-Experts Network for Monocular 3D Human Pose Estimation](https://arxiv.org/abs/2512.16494)
*Mengyuan Liu,Jiajie Liu,Jinyan Zhang,Wenhao Li,Junsong Yuan*

Main category: cs.CV

TL;DR: PoseMoE通过解耦2D姿态和深度特征的编码，解决了传统方法中深度不确定性对2D姿态的影响，显著提升了3D姿态估计精度。


<details>
  <summary>Details</summary>
Motivation: 传统的基于lifting的方法在编码2D姿态和深度时存在特征纠缠问题，深度不确定性会直接影响2D姿态特征，从而限制整体估计精度。

Method: 提出了一个混合专家网络（PoseMoE），包括专门优化2D姿态特征和学习深度特征的专家模块，以及一个跨专家知识聚合模块，用于增强特征表示。

Result: 在Human3.6M、MPI-INF-3DHP和3DPW三个数据集上的实验表明，PoseMoE优于传统方法。

Conclusion: PoseMoE通过解耦2D姿态和深度特征的编码过程，显著提升了单目3D人体姿态估计的准确性，并在多个数据集上优于传统基于lifting的方法。

Abstract: The lifting-based methods have dominated monocular 3D human pose estimation by leveraging detected 2D poses as intermediate representations. The 2D component of the final 3D human pose benefits from the detected 2D poses, whereas its depth counterpart must be estimated from scratch. The lifting-based methods encode the detected 2D pose and unknown depth in an entangled feature space, explicitly introducing depth uncertainty to the detected 2D pose, thereby limiting overall estimation accuracy. This work reveals that the depth representation is pivotal for the estimation process. Specifically, when depth is in an initial, completely unknown state, jointly encoding depth features with 2D pose features is detrimental to the estimation process. In contrast, when depth is initially refined to a more dependable state via network-based estimation, encoding it together with 2D pose information is beneficial. To address this limitation, we present a Mixture-of-Experts network for monocular 3D pose estimation named PoseMoE. Our approach introduces: (1) A mixture-of-experts network where specialized expert modules refine the well-detected 2D pose features and learn the depth features. This mixture-of-experts design disentangles the feature encoding process for 2D pose and depth, therefore reducing the explicit influence of uncertain depth features on 2D pose features. (2) A cross-expert knowledge aggregation module is proposed to aggregate cross-expert spatio-temporal contextual information. This step enhances features through bidirectional mapping between 2D pose and depth. Extensive experiments show that our proposed PoseMoE outperforms the conventional lifting-based methods on three widely used datasets: Human3.6M, MPI-INF-3DHP, and 3DPW.

</details>


### [64] [VenusBench-GD: A Comprehensive Multi-Platform GUI Benchmark for Diverse Grounding Tasks](https://arxiv.org/abs/2512.16501)
*Beitong Zhou,Zhexiao Huang,Yuan Guo,Zhangxuan Gu,Tianyu Xia,Zichen Luo,Fei Tang,Dehan Kong,Yanyi Shang,Suling Ou,Zhenlin Guo,Changhua Meng,Shuheng Shen*

Main category: cs.CV

TL;DR: VenusBench-GD 是一个多平台 GUI 接地基准，提供大规模数据、高质量标注和分层任务评估，揭示通用模型在基础任务上的竞争力及专用模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有 GUI 接地基准存在数据量不足、领域覆盖窄、平台单一或需专业知识的局限性，亟需一个全面、多平台的评估框架。

Method: 提出 VenusBench-GD 基准，包括大规模跨平台数据集、高质量数据构建流水线和分层任务分类法（基础与高级任务，共六种子任务）。

Result: 实验显示通用多模态模型在基础任务上表现优异，而专用模型在高级任务中仍有优势但存在过拟合和鲁棒性不足。

Conclusion: VenusBench-GD 是一个全面的双语 GUI 接地基准，覆盖多平台，支持分层评估，为实际应用提供了重要参考。实验结果表明，通用多模态模型在基础任务上已媲美或超越专用 GUI 模型，而高级任务仍依赖专用模型，但其存在过拟合和鲁棒性差的问题。

Abstract: GUI grounding is a critical component in building capable GUI agents. However, existing grounding benchmarks suffer from significant limitations: they either provide insufficient data volume and narrow domain coverage, or focus excessively on a single platform and require highly specialized domain knowledge. In this work, we present VenusBench-GD, a comprehensive, bilingual benchmark for GUI grounding that spans multiple platforms, enabling hierarchical evaluation for real-word applications. VenusBench-GD contributes as follows: (i) we introduce a large-scale, cross-platform benchmark with extensive coverage of applications, diverse UI elements, and rich annotated data, (ii) we establish a high-quality data construction pipeline for grounding tasks, achieving higher annotation accuracy than existing benchmarks, and (iii) we extend the scope of element grounding by proposing a hierarchical task taxonomy that divides grounding into basic and advanced categories, encompassing six distinct subtasks designed to evaluate models from complementary perspectives. Our experimental findings reveal critical insights: general-purpose multimodal models now match or even surpass specialized GUI models on basic grounding tasks. In contrast, advanced tasks, still favor GUI-specialized models, though they exhibit significant overfitting and poor robustness. These results underscore the necessity of comprehensive, multi-tiered evaluation frameworks.

</details>


### [65] [Skeleton-Snippet Contrastive Learning with Multiscale Feature Fusion for Action Localization](https://arxiv.org/abs/2512.16504)
*Qiushuo Cheng,Jingjing Liu,Catherine Morgan,Alan Whone,Majid Mirmehdi*

Main category: cs.CV

TL;DR: 本文提出了一种片段区分自监督预训练方法，结合U形模块增强特征分辨率，显著提升了骨架动作定位性能，并在多个数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督预训练方法在骨架动作识别中表现良好，但在动作定位任务中由于需要捕捉相邻帧间的细微差异而表现不足。本文旨在解决这一问题。

Method: 采用片段区分自监督预训练任务，将骨架序列密集投影到非重叠片段中，并通过对比学习区分它们。同时，利用U形模块融合中间特征以增强帧级定位的特征分辨率。

Result: 方法在BABEL数据集的不同子集和评估协议上一致提升了现有骨架对比学习方法的动作定位性能，并在PKUMMD上实现了最先进的迁移学习效果。

Conclusion: 本文提出的方法通过片段区分任务和U形模块融合中间特征，显著提升了基于骨架的动作定位性能，并在多个数据集上实现了最先进的迁移学习效果。

Abstract: The self-supervised pretraining paradigm has achieved great success in learning 3D action representations for skeleton-based action recognition using contrastive learning. However, learning effective representations for skeleton-based temporal action localization remains challenging and underexplored. Unlike video-level {action} recognition, detecting action boundaries requires temporally sensitive features that capture subtle differences between adjacent frames where labels change. To this end, we formulate a snippet discrimination pretext task for self-supervised pretraining, which densely projects skeleton sequences into non-overlapping segments and promotes features that distinguish them across videos via contrastive learning. Additionally, we build on strong backbones of skeleton-based action recognition models by fusing intermediate features with a U-shaped module to enhance feature resolution for frame-level localization. Our approach consistently improves existing skeleton-based contrastive learning methods for action localization on BABEL across diverse subsets and evaluation protocols. We also achieve state-of-the-art transfer learning performance on PKUMMD with pretraining on NTU RGB+D and BABEL.

</details>


### [66] [Weakly Supervised Pneumonia Localization from Chest X-Rays Using Deep Neural Network and Grad-CAM Explanations](https://arxiv.org/abs/2511.00456)
*Kiran Shahi,Anup Bagale*

Main category: cs.CV

TL;DR: 提出弱监督深度学习框架，利用Grad-CAM和图像级标签实现肺炎分类与定位，评估七种模型，ResNet-18和EfficientNet-B0表现最佳，支持可解释AI在放射诊断中的应用。


<details>
  <summary>Details</summary>
Motivation: 解决胸部X光影像中肺炎区域精确定位需要昂贵且耗时的像素级标注的问题。

Method: 提出了一种基于Grad-CAM的弱监督深度学习框架，利用图像级标签生成肺炎区域的临床意义热图，并评估了七种预训练深度学习模型。

Result: 所有模型均达到高分类准确率（96-98%），其中ResNet-18和EfficientNet-B0表现最佳，MobileNet-V3为轻量级替代方案。Grad-CAM热图可视化证实方法聚焦于临床相关肺区域。

Conclusion: 本研究强调了弱监督、可解释模型在增强AI辅助肺炎筛查透明度和临床信任方面的潜力。

Abstract: Chest X-ray imaging is commonly used to diagnose pneumonia, but accurately localizing the pneumonia-affected regions typically requires detailed pixel-level annotations, which are costly and time consuming to obtain. To address this limitation, this study proposes a weakly supervised deep learning framework for pneumonia classification and localization using Gradient-weighted Class Activation Mapping (Grad-CAM). Instead of relying on costly pixel-level annotations, the proposed method utilizes image-level labels to generate clinically meaningful heatmaps that highlight pneumonia-affected regions. Furthermore, we evaluate seven pre-trained deep learning models, including a Vision Transformer, under identical training conditions, using focal loss and patient-wise splits to prevent data leakage. Experimental results suggest that all models achieved high classification accuracy (96--98\%), with ResNet-18 and EfficientNet-B0 showing the best overall performance and MobileNet-V3 providing an efficient lightweight alternative. Grad-CAM heatmap visualizations confirm that the proposed methods focus on clinically relevant lung regions, supporting the use of explainable AI for radiological diagnostics. Overall, this work highlights the potential of weakly supervised, explainable models that enhance transparency and clinical trust in AI-assisted pneumonia screening.

</details>


### [67] [TTP: Test-Time Padding for Adversarial Detection and Robust Adaptation on Vision-Language Models](https://arxiv.org/abs/2512.16523)
*Zhiwei Li,Yitian Pang,Weining Wang,Zhenan Sun,Qi Li*

Main category: cs.CV

TL;DR: TTP是一种轻量级测试时防御框架，通过检测和适应对抗输入，提升对抗鲁棒性且不牺牲干净准确性。


<details>
  <summary>Details</summary>
Motivation: 现有对抗防御方法在训练时依赖标记数据和昂贵微调，而测试时策略无法可靠区分干净和对抗输入，限制了对抗鲁棒性和干净准确性的优化。

Method: TTP通过空间填充前后的CLIP特征嵌入余弦相似度偏移检测对抗输入，并使用可训练填充恢复注意力模式，结合相似性感知集成策略进行最终预测。

Result: TTP在多种CLIP架构和细粒度基准测试中均优于现有测试时防御方法，显著提升对抗鲁棒性。

Conclusion: TTP（Test-Time Padding）是一种轻量级防御框架，通过在推理时进行对抗检测和针对性适应，显著提升了对抗鲁棒性且不影响干净输入的准确性。

Abstract: Vision-Language Models (VLMs), such as CLIP, have achieved impressive zero-shot recognition performance but remain highly susceptible to adversarial perturbations, posing significant risks in safety-critical scenarios. Previous training-time defenses rely on adversarial fine-tuning, which requires labeled data and costly retraining, while existing test-time strategies fail to reliably distinguish between clean and adversarial inputs, thereby preventing both adversarial robustness and clean accuracy from reaching their optimum. To address these limitations, we propose Test-Time Padding (TTP), a lightweight defense framework that performs adversarial detection followed by targeted adaptation at inference. TTP identifies adversarial inputs via the cosine similarity shift between CLIP feature embeddings computed before and after spatial padding, yielding a universal threshold for reliable detection across architectures and datasets. For detected adversarial cases, TTP employs trainable padding to restore disrupted attention patterns, coupled with a similarity-aware ensemble strategy for a more robust final prediction. For clean inputs, TTP leaves them unchanged by default or optionally integrates existing test-time adaptation techniques for further accuracy gains. Comprehensive experiments on diverse CLIP backbones and fine-grained benchmarks show that TTP consistently surpasses state-of-the-art test-time defenses, delivering substantial improvements in adversarial robustness without compromising clean accuracy. The code for this paper will be released soon.

</details>


### [68] [N3D-VLM: Native 3D Grounding Enables Accurate Spatial Reasoning in Vision-Language Models](https://arxiv.org/abs/2512.16561)
*Yuxin Wang,Lei Ke,Boqiang Zhang,Tianyuan Qu,Hanxun Yu,Zhenpeng Huang,Meng Yu,Dan Xu,Dong Yu*

Main category: cs.CV

TL;DR: N3D-VLM通过原生3D感知和推理框架，显著提升3D空间理解能力，并在任务中达到最优性能。


<details>
  <summary>Details</summary>
Motivation: 现有多模态模型缺乏内在3D物体感知能力，限制了其对3D场景空间关系和深度线索的理解。

Method: 提出N3D-VLM框架，结合深度估计技术构建大规模3D标注数据，支持3D物体定位和空间推理的联合训练。

Result: 实验结果表明，N3D-VLM在3D定位任务中表现优异，且在3D空间推理任务中持续超越现有方法。

Conclusion: N3D-VLM框架通过整合原生3D物体感知与3D感知视觉推理，显著提升了3D空间理解能力，并在3D定位和空间推理任务中达到最先进性能。

Abstract: While current multimodal models can answer questions based on 2D images, they lack intrinsic 3D object perception, limiting their ability to comprehend spatial relationships and depth cues in 3D scenes. In this work, we propose N3D-VLM, a novel unified framework that seamlessly integrates native 3D object perception with 3D-aware visual reasoning, enabling both precise 3D grounding and interpretable spatial understanding. Unlike conventional end-to-end models that directly predict answers from RGB/RGB-D inputs, our approach equips the model with native 3D object perception capabilities, enabling it to directly localize objects in 3D space based on textual descriptions. Building upon accurate 3D object localization, the model further performs explicit reasoning in 3D, achieving more interpretable and structured spatial understanding. To support robust training for these capabilities, we develop a scalable data construction pipeline that leverages depth estimation to lift large-scale 2D annotations into 3D space, significantly increasing the diversity and coverage for 3D object grounding data, yielding over six times larger than the largest existing single-image 3D detection dataset. Moreover, the pipeline generates spatial question-answering datasets that target chain-of-thought (CoT) reasoning in 3D, facilitating joint training for both 3D object localization and 3D spatial reasoning. Experimental results demonstrate that our unified framework not only achieves state-of-the-art performance on 3D grounding tasks, but also consistently surpasses existing methods in 3D spatial reasoning in vision-language model.

</details>


### [69] [4D Primitive-Mâché: Glueing Primitives for Persistent 4D Scene Reconstruction](https://arxiv.org/abs/2512.16564)
*Kirill Mazur,Marwan Taher,Andrew J. Davison*

Main category: cs.CV

TL;DR: 提出了一种动态重建系统，通过分解场景为刚性3D基元并联合优化其运动，实现4D重建，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 旨在从单目RGB视频输入中重建场景的完整持久版本，包括当前可见和之前观察到的部分，以实现跨时间步的完整重建回放。

Method: 将场景分解为一组刚性3D基元，通过密集2D对应关系估计，联合推断这些基元的刚性运动，并通过优化流程实现4D重建。还引入了一种机制来推断不可见物体的运动，以保持连续性。

Result: 系统实现了4D时空感知，支持可回放的3D重建、多物体扫描和物体持久性，并在性能上显著优于现有方法。

Conclusion: 该系统能够实现场景的完整持久重建，支持4D时空感知，并在物体扫描和多物体数据集上显著优于现有方法。

Abstract: We present a dynamic reconstruction system that receives a casual monocular RGB video as input, and outputs a complete and persistent reconstruction of the scene. In other words, we reconstruct not only the the currently visible parts of the scene, but also all previously viewed parts, which enables replaying the complete reconstruction across all timesteps.
  Our method decomposes the scene into a set of rigid 3D primitives, which are assumed to be moving throughout the scene. Using estimated dense 2D correspondences, we jointly infer the rigid motion of these primitives through an optimisation pipeline, yielding a 4D reconstruction of the scene, i.e. providing 3D geometry dynamically moving through time. To achieve this, we also introduce a mechanism to extrapolate motion for objects that become invisible, employing motion-grouping techniques to maintain continuity.
  The resulting system enables 4D spatio-temporal awareness, offering capabilities such as replayable 3D reconstructions of articulated objects through time, multi-object scanning, and object permanence. On object scanning and multi-object datasets, our system significantly outperforms existing methods both quantitatively and qualitatively.

</details>


### [70] [Causal-Tune: Mining Causal Factors from Vision Foundation Models for Domain Generalized Semantic Segmentation](https://arxiv.org/abs/2512.16567)
*Yin Zhang,Yongqiang Zhang,Yaoyue Zheng,Bogdan Raducanu,Dan Liu*

Main category: cs.CV

TL;DR: Causal-Tune通过分离VFMs特征中的因果与非因果因素，提升DGSS性能，雪天条件下mIoU提升4.8%。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了预训练VFMs中的非因果因素（如频谱中的高低频成分）对DGSS性能的负面影响。

Method: 提出Causal-Tune，利用DCT和Gaussian带通滤波器分离特征频谱中的因果与非因果成分，并通过因果感知可学习令牌进一步优化。

Result: 在跨域任务中表现优异，尤其在雪天条件下mIoU提升4.8%。

Conclusion: Causal-Tune方法通过识别和分离VFMs中的因果与非因果因素，显著提升了DGSS的性能，尤其在恶劣天气条件下表现优异。

Abstract: Fine-tuning Vision Foundation Models (VFMs) with a small number of parameters has shown remarkable performance in Domain Generalized Semantic Segmentation (DGSS). Most existing works either train lightweight adapters or refine intermediate features to achieve better generalization on unseen domains. However, they both overlook the fact that long-term pre-trained VFMs often exhibit artifacts, which hinder the utilization of valuable representations and ultimately degrade DGSS performance. Inspired by causal mechanisms, we observe that these artifacts are associated with non-causal factors, which usually reside in the low- and high-frequency components of the VFM spectrum. In this paper, we explicitly examine the causal and non-causal factors of features within VFMs for DGSS, and propose a simple yet effective method to identify and disentangle them, enabling more robust domain generalization. Specifically, we propose Causal-Tune, a novel fine-tuning strategy designed to extract causal factors and suppress non-causal ones from the features of VFMs. First, we extract the frequency spectrum of features from each layer using the Discrete Cosine Transform (DCT). A Gaussian band-pass filter is then applied to separate the spectrum into causal and non-causal components. To further refine the causal components, we introduce a set of causal-aware learnable tokens that operate in the frequency domain, while the non-causal components are discarded. Finally, refined features are transformed back into the spatial domain via inverse DCT and passed to the next layer. Extensive experiments conducted on various cross-domain tasks demonstrate the effectiveness of Causal-Tune. In particular, our method achieves superior performance under adverse weather conditions, improving +4.8% mIoU over the baseline in snow conditions.

</details>


### [71] [CRONOS: Continuous Time Reconstruction for 4D Medical Longitudinal Series](https://arxiv.org/abs/2512.16577)
*Nico Albert Disch,Saikat Roy,Constantin Ulrich,Yannick Kirchhoff,Maximilian Rokuss,Robin Peretzke,David Zimmerer,Klaus Maier-Hein*

Main category: cs.CV

TL;DR: CRONOS是一个支持离散和连续时间戳的3D医学数据预测框架，通过学习时空速度场实现多对一预测，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 预测3D医学扫描随时间演变对疾病进展、治疗计划和发育评估至关重要，但现有模型依赖单一先验扫描、固定网格时间或全局标签，限制了不规则采样下的体素级预测。

Method: CRONOS通过学习一个时空速度场，将上下文体积传输到任意时间的目标体积，直接在3D体素空间中操作。

Result: 在三个公共数据集（Cine-MRI、灌注CT和纵向MRI）上，CRONOS优于其他基线方法，同时保持计算竞争力。

Conclusion: CRONOS是一个统一的框架，能够从多个过去的扫描中进行多对一预测，支持离散和连续时间戳，首次实现了3D医学数据的连续序列到图像预测。

Abstract: Forecasting how 3D medical scans evolve over time is important for disease progression, treatment planning, and developmental assessment. Yet existing models either rely on a single prior scan, fixed grid times, or target global labels, which limits voxel-level forecasting under irregular sampling. We present CRONOS, a unified framework for many-to-one prediction from multiple past scans that supports both discrete (grid-based) and continuous (real-valued) timestamps in one model, to the best of our knowledge the first to achieve continuous sequence-to-image forecasting for 3D medical data. CRONOS learns a spatio-temporal velocity field that transports context volumes toward a target volume at an arbitrary time, while operating directly in 3D voxel space. Across three public datasets spanning Cine-MRI, perfusion CT, and longitudinal MRI, CRONOS outperforms other baselines, while remaining computationally competitive. We will release code and evaluation protocols to enable reproducible, multi-dataset benchmarking of multi-context, continuous-time forecasting.

</details>


### [72] [Sketch-in-Latents: Eliciting Unified Reasoning in MLLMs](https://arxiv.org/abs/2512.16584)
*Jintao Tong,Jiaqi Gu,Yujing Lou,Lubin Fan,Yixiong Zou,Yue Wu,Jieping Ye,Ruixuan Li*

Main category: cs.CV

TL;DR: SkiLa 通过动态生成视觉潜在标记，实现了统一的多模态推理，显著提升了视觉任务的性能。


<details>
  <summary>Details</summary>
Motivation: 受人类在统一空间内进行视觉-文本思维的启发，认为当前的 MLLMs 已经将视觉和文本信息编码在同一特征空间中，因此可以在推理过程中无缝插入视觉标记。

Method: 提出了 Sketch-in-Latents (SkiLa) 范式，扩展了 MLLMs 的自回归能力，使其能够原生生成连续的视觉嵌入（潜在草图标记）。通过动态交替文本思考和视觉草图模式，结合潜在视觉语义重建机制，确保视觉标记的语义基础。

Result: 实验表明，SkiLa 在视觉中心任务上表现优异，并能泛化到多样化的多模态基准测试中。

Conclusion: SkiLa 提出了一种新颖的统一多模态推理范式，通过在推理过程中动态交替生成文本和视觉潜在标记，显著提升了视觉中心任务的性能，并展示了强大的泛化能力。

Abstract: While Multimodal Large Language Models (MLLMs) excel at visual understanding tasks through text reasoning, they often fall short in scenarios requiring visual imagination. Unlike current works that take predefined external toolkits or generate images during thinking, however, humans can form flexible visual-text imagination and interactions during thinking without predefined toolkits, where one important reason is that humans construct the visual-text thinking process in a unified space inside the brain. Inspired by this capability, given that current MLLMs already encode visual and text information in the same feature space, we hold that visual tokens can be seamlessly inserted into the reasoning process carried by text tokens, where ideally, all visual imagination processes can be encoded by the latent features. To achieve this goal, we propose Sketch-in-Latents (SkiLa), a novel paradigm for unified multi-modal reasoning that expands the auto-regressive capabilities of MLLMs to natively generate continuous visual embeddings, termed latent sketch tokens, as visual thoughts. During multi-step reasoning, the model dynamically alternates between textual thinking mode for generating textual think tokens and visual sketching mode for generating latent sketch tokens. A latent visual semantics reconstruction mechanism is proposed to ensure these latent sketch tokens are semantically grounded. Extensive experiments demonstrate that SkiLa achieves superior performance on vision-centric tasks while exhibiting strong generalization to diverse general multi-modal benchmarks. Codes will be released at https://github.com/TungChintao/SkiLa.

</details>


### [73] [Yuan-TecSwin: A text conditioned Diffusion model with Swin-transformer blocks](https://arxiv.org/abs/2512.16586)
*Shaohua Wu,Tong Yu,Shenling Wang,Xudong Zhao*

Main category: cs.CV

TL;DR: Yuan-TecSwin用Swin-transformer替代CNN，提升扩散模型的非局部建模能力，达到最佳FID分数1.37，生成图像逼真度极高。


<details>
  <summary>Details</summary>
Motivation: CNN的局部性限制了扩散模型对长距离语义信息的理解能力，因此需要一种能够更好建模非局部特征的架构。

Method: 提出Yuan-TecSwin，一种基于Swin-transformer的文本条件扩散模型，替换传统CNN块以增强非局部建模能力。通过优化文本编码器、文本嵌入的有效利用及文本条件的精心设计，提升了文本-图像对齐。采用自适应时间步搜索策略，进一步提升了10%的推理性能。

Result: Yuan-TecSwin在ImageNet生成基准上达到了1.37的FID分数，推理性能提升10%，且在人类评估中生成图像与真实绘画难以区分。

Conclusion: Yuan-TecSwin通过Swin-transformer替代CNN块，显著提升了扩散模型在长距离语义理解和图像生成方面的性能，达到了当前最佳的FID分数1.37，并在人类评估中难以区分生成图像与真实绘画。

Abstract: Diffusion models have shown remarkable capacity in image synthesis based on their U-shaped architecture and convolutional neural networks (CNN) as basic blocks. The locality of the convolution operation in CNN may limit the model's ability to understand long-range semantic information. To address this issue, we propose Yuan-TecSwin, a text-conditioned diffusion model with Swin-transformer in this work. The Swin-transformer blocks take the place of CNN blocks in the encoder and decoder, to improve the non-local modeling ability in feature extraction and image restoration. The text-image alignment is improved with a well-chosen text encoder, effective utilization of text embedding, and careful design in the incorporation of text condition. Using an adapted time step to search in different diffusion stages, inference performance is further improved by 10%. Yuan-TecSwin achieves the state-of-the-art FID score of 1.37 on ImageNet generation benchmark, without any additional models at different denoising stages. In a side-by-side comparison, we find it difficult for human interviewees to tell the model-generated images from the human-painted ones.

</details>


### [74] [Hazedefy: A Lightweight Real-Time Image and Video Dehazing Pipeline for Practical Deployment](https://arxiv.org/abs/2512.16609)
*Ayush Bhavsar*

Main category: cs.CV

TL;DR: Hazedefy是一种轻量级去雾管道，基于DCP和大气散射模型，适用于实时视频增强，无需GPU即可在消费级硬件上运行。


<details>
  <summary>Details</summary>
Motivation: 旨在提供一种计算简单、实用性强且能在消费级硬件上实时运行的视频去雾解决方案。

Method: 基于暗通道先验（DCP）和大气散射模型，采用伽马自适应重建、快速传输近似（含数值稳定性下限）、基于分数顶部像素平均的稳定大气光估计器，以及可选的颜色平衡阶段。

Result: 实验证明，Hazedefy在真实世界的图像和视频上显著提升了可见性和对比度，且无需GPU加速。

Conclusion: Hazedefy是一种轻量级且专注于应用的去雾管道，适用于实时视频和直播摄像头画面的增强，能够在消费级硬件上实现高效部署。

Abstract: This paper introduces Hazedefy, a lightweight and application-focused dehazing pipeline intended for real-time video and live camera feed enhancement. Hazedefy prioritizes computational simplicity and practical deployability on consumer-grade hardware, building upon the Dark Channel Prior (DCP) concept and the atmospheric scattering model. Key elements include gamma-adaptive reconstruction, a fast transmission approximation with lower bounds for numerical stability, a stabilized atmospheric light estimator based on fractional top-pixel averaging, and an optional color balance stage. The pipeline is suitable for mobile and embedded applications, as experimental demonstrations on real-world images and videos show improved visibility and contrast without requiring GPU acceleration.

</details>


### [75] [Trainable Log-linear Sparse Attention for Efficient Diffusion Transformers](https://arxiv.org/abs/2512.16615)
*Yifan Zhou,Zeqi Xiao,Tianyi Wei,Shuai Yang,Xingang Pan*

Main category: cs.CV

TL;DR: LLSA 是一种分层稀疏注意力机制，显著提升长序列 DiTs 的计算效率，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有的 Top-K 稀疏注意力方法在长序列上仍存在计算效率低下的问题，无法有效捕捉全局结构。

Method: LLSA 采用分层 Top-K 选择和 Hierarchical KV Enrichment 机制，减少计算复杂度。

Result: LLSA 在 256x256 像素序列上实现了 28.27 倍的注意力推理加速和 6.09 倍的 DiT 训练加速。

Conclusion: LLSA 通过分层结构和高效的 GPU 实现，显著提升了长序列 DiTs 的训练效率，同时保持了生成质量。

Abstract: Diffusion Transformers (DiTs) set the state of the art in visual generation, yet their quadratic self-attention cost fundamentally limits scaling to long token sequences. Recent Top-K sparse attention approaches reduce the computation of DiTs by compressing tokens into block-wise representation and selecting a small set of relevant key blocks, but still suffer from (i) quadratic selection cost on compressed tokens and (ii) increasing K required to maintain model quality as sequences grow. We identify that their inefficiency is due to the single-level design, as a single coarse level is insufficient to represent the global structure. In this paper, we introduce Log-linear Sparse Attention (LLSA), a trainable sparse attention mechanism for extremely long token sequences that reduces both selection and attention costs from quadratic to log-linear complexity by utilizing a hierarchical structure. LLSA performs hierarchical Top-K selection, progressively adopting sparse Top-K selection with the indices found at the previous level, and introduces a Hierarchical KV Enrichment mechanism that preserves global context while using fewer tokens of different granularity during attention computation. To support efficient training, we develop a high-performance GPU implementation that uses only sparse indices for both the forward and backward passes, eliminating the need for dense attention masks. We evaluate LLSA on high-resolution pixel-space image generation without using patchification and VAE encoding. LLSA accelerates attention inference by 28.27x and DiT training by 6.09x on 256x256 pixel token sequences, while maintaining generation quality. The results demonstrate that LLSA offers a promising direction for training long-sequence DiTs efficiently. Code is available at: https://github.com/SingleZombie/LLSA

</details>


### [76] [Plug to Place: Indoor Multimedia Geolocation from Electrical Sockets for Digital Investigation](https://arxiv.org/abs/2512.16620)
*Kanwal Aftab,Graham Adams,Mark Scanlon*

Main category: cs.CV

TL;DR: 论文提出基于电源插座的室内地理定位管道，通过深度学习实现高精度检测与分类，为犯罪调查提供实用工具，代码和数据开源。


<details>
  <summary>Details</summary>
Motivation: 室内多媒体地理定位在打击人口贩卖等犯罪中具有潜力，但因室内环境复杂（如布局相似、光线变化等）和数据稀缺而发展不足。电源插座因其标准化特性成为理想的室内标记。

Method: 采用三阶段深度学习管道：使用YOLOv11检测电源插座（mAP@0.5=0.843），Xception分类12种插座类型（准确率0.912），并将插座类型映射到国家（置信度>90%时准确率0.96）。为解决数据稀缺问题，创建了两个专用数据集。

Result: 在Hotels-50K数据集（尤其是TraffickCam子集）上评估，管道在真实条件下表现良好，优于传统旅行网站图像。检测和分类任务均达到高精度。

Conclusion: 该论文提出的管道在室内多媒体地理定位方面取得了显著成果，通过利用电源插座作为一致标记，结合深度学习技术，实现了高精度的检测和分类，为打击人口贩卖和儿童剥削等严重犯罪提供了实用工具。

Abstract: Computer vision is a rapidly evolving field, giving rise to powerful new tools and techniques in digital forensic investigation, and shows great promise for novel digital forensic applications. One such application, indoor multimedia geolocation, has the potential to become a crucial aid for law enforcement in the fight against human trafficking, child exploitation, and other serious crimes. While outdoor multimedia geolocation has been widely explored, its indoor counterpart remains underdeveloped due to challenges such as similar room layouts, frequent renovations, visual ambiguity, indoor lighting variability, unreliable GPS signals, and limited datasets in sensitive domains. This paper introduces a pipeline that uses electric sockets as consistent indoor markers for geolocation, since plug socket types are standardised by country or region. The three-stage deep learning pipeline detects plug sockets (YOLOv11, mAP@0.5 = 0.843), classifies them into one of 12 plug socket types (Xception, accuracy = 0.912), and maps the detected socket types to countries (accuracy = 0.96 at >90% threshold confidence). To address data scarcity, two dedicated datasets were created: socket detection dataset of 2,328 annotated images expanded to 4,072 through augmentation, and a classification dataset of 3,187 images across 12 plug socket classes. The pipeline was evaluated on the Hotels-50K dataset, focusing on the TraffickCam subset of crowd-sourced hotel images, which capture real-world conditions such as poor lighting and amateur angles. This dataset provides a more realistic evaluation than using professional, well-lit, often wide-angle images from travel websites. This framework demonstrates a practical step toward real-world digital forensic applications. The code, trained models, and the data for this paper are available open source.

</details>


### [77] [DeContext as Defense: Safe Image Editing in Diffusion Transformers](https://arxiv.org/abs/2512.16625)
*Linghui Shen,Mingyue Cui,Xingyi Yang*

Main category: cs.CV

TL;DR: DeContext通过扰动注意力层阻断上下文传播，有效防御图像恶意编辑，实验证明其高效且鲁棒。


<details>
  <summary>Details</summary>
Motivation: 针对大规模基于DiT的上下文扩散模型可能被用于恶意图像编辑的隐私问题，现有方法在鲁棒性方面尚未充分验证。

Method: 提出DeContext方法，通过注入小型定向扰动来削弱多模态注意力层的跨注意力路径，从而阻断上下文信息的传播。

Result: 在Flux Kontext和Step1X-Edit数据集上的实验表明，DeContext能持续阻断非授权编辑，同时保持视觉质量。

Conclusion: DeContext通过注入定向扰动有效阻断了输入与输出之间的关联，提供了一种高效且鲁棒的防御方法，对抗未经授权的图像编辑。

Abstract: In-context diffusion models allow users to modify images with remarkable ease and realism. However, the same power raises serious privacy concerns: personal images can be easily manipulated for identity impersonation, misinformation, or other malicious uses, all without the owner's consent. While prior work has explored input perturbations to protect against misuse in personalized text-to-image generation, the robustness of modern, large-scale in-context DiT-based models remains largely unexamined. In this paper, we propose DeContext, a new method to safeguard input images from unauthorized in-context editing. Our key insight is that contextual information from the source image propagates to the output primarily through multimodal attention layers. By injecting small, targeted perturbations that weaken these cross-attention pathways, DeContext breaks this flow, effectively decouples the link between input and output. This simple defense is both efficient and robust. We further show that early denoising steps and specific transformer blocks dominate context propagation, which allows us to concentrate perturbations where they matter most. Experiments on Flux Kontext and Step1X-Edit show that DeContext consistently blocks unwanted image edits while preserving visual quality. These results highlight the effectiveness of attention-based perturbations as a powerful defense against image manipulation.

</details>


### [78] [SARMAE: Masked Autoencoder for SAR Representation Learning](https://arxiv.org/abs/2512.16635)
*Danxu Liu,Di Wang,Hebaixu Wang,Haoyang Chen,Wentao Jiang,Yilin Cheng,Haonan Guo,Wei Cui,Jing Zhang*

Main category: cs.CV

TL;DR: SARMAE是一种噪声感知的掩码自编码器，通过构建百万级SAR数据集和引入噪声增强与语义约束，提升了SAR图像的表示学习性能。


<details>
  <summary>Details</summary>
Motivation: 解决SAR图像数据稀缺和斑点噪声对细粒度语义表示学习的阻碍。

Method: 提出了SARMAE，一种噪声感知的掩码自编码器，包括SAR-1M数据集构建、SARE（注入SAR特定斑点噪声）和SARC（利用配对光学先验对齐SAR特征）。

Result: 在多个SAR数据集上的实验表明，SARMAE在分类、检测和分割任务中表现最佳。

Conclusion: SARMAE通过结合噪声感知和语义一致性约束，在SAR图像的分类、检测和分割任务中实现了最先进的性能。

Abstract: Synthetic Aperture Radar (SAR) imagery plays a critical role in all-weather, day-and-night remote sensing applications. However, existing SAR-oriented deep learning is constrained by data scarcity, while the physically grounded speckle noise in SAR imagery further hampers fine-grained semantic representation learning. To address these challenges, we propose SARMAE, a Noise-Aware Masked Autoencoder for self-supervised SAR representation learning. Specifically, we construct SAR-1M, the first million-scale SAR dataset, with additional paired optical images, to enable large-scale pre-training. Building upon this, we design Speckle-Aware Representation Enhancement (SARE), which injects SAR-specific speckle noise into masked autoencoders to facilitate noise-aware and robust representation learning. Furthermore, we introduce Semantic Anchor Representation Constraint (SARC), which leverages paired optical priors to align SAR features and ensure semantic consistency. Extensive experiments across multiple SAR datasets demonstrate that SARMAE achieves state-of-the-art performance on classification, detection, and segmentation tasks. Code and models will be available at https://github.com/MiliLab/SARMAE.

</details>


### [79] [REGLUE Your Latents with Global and Local Semantics for Entangled Diffusion](https://arxiv.org/abs/2512.16636)
*Giorgos Petsangourakis,Christos Sgouropoulos,Bill Psomas,Theodoros Giannakopoulos,Giorgos Sfikas,Ioannis Kakogeorgiou*

Main category: cs.CV

TL;DR: REGLUE是一种联合建模VAE潜在空间和VFM语义的扩散框架，通过非线性压缩和全局-局部编码提升图像合成效果。


<details>
  <summary>Details</summary>
Motivation: 现有LDMs的语义监督间接且效率低，导致训练时间长且样本质量受限。REGLUE旨在充分利用VFM的丰富语义信息。

Method: REGLUE框架联合建模VAE图像潜在空间、局部（patch级）VFM语义和全局（图像级）[CLS]标记，并通过轻量级卷积语义压缩器非线性聚合多层VFM特征。

Result: 在ImageNet 256x256上，REGLUE显著提升了FID并加速了收敛，优于多个基线模型。

Conclusion: REGLUE通过结合VAE图像潜在空间、局部VFM语义和全局[CLS]标记，显著提升了图像合成的质量和训练效率，证明了空间语义和非线性压缩的重要性。

Abstract: Latent diffusion models (LDMs) achieve state-of-the-art image synthesis, yet their reconstruction-style denoising objective provides only indirect semantic supervision: high-level semantics emerge slowly, requiring longer training and limiting sample quality. Recent works inject semantics from Vision Foundation Models (VFMs) either externally via representation alignment or internally by jointly modeling only a narrow slice of VFM features inside the diffusion process, under-utilizing the rich, nonlinear, multi-layer spatial semantics available. We introduce REGLUE (Representation Entanglement with Global-Local Unified Encoding), a unified latent diffusion framework that jointly models (i) VAE image latents, (ii) compact local (patch-level) VFM semantics, and (iii) a global (image-level) [CLS] token within a single SiT backbone. A lightweight convolutional semantic compressor nonlinearly aggregates multi-layer VFM features into a low-dimensional, spatially structured representation, which is entangled with the VAE latents in the diffusion process. An external alignment loss further regularizes internal representations toward frozen VFM targets. On ImageNet 256x256, REGLUE consistently improves FID and accelerates convergence over SiT-B/2 and SiT-XL/2 baselines, as well as over REPA, ReDi, and REG. Extensive experiments show that (a) spatial VFM semantics are crucial, (b) non-linear compression is key to unlocking their full benefit, and (c) global tokens and external alignment act as complementary, lightweight enhancements within our global-local-latent joint modeling framework. The code is available at https://github.com/giorgospets/reglue .

</details>


### [80] [Few-Shot Fingerprinting Subject Re-Identification in 3D-MRI and 2D-X-Ray](https://arxiv.org/abs/2512.16685)
*Gonçalo Gaspar Alves,Shekoufeh Gorgi Zadeh,Andreas Husch,Ben Bausch*

Main category: cs.CV

TL;DR: 研究通过主题指纹技术解决数据合并中的数据泄漏问题，使用ResNet-50在MRI和X-ray数据上实现高精度主题重识别。


<details>
  <summary>Details</summary>
Motivation: 解决开源数据集合并时可能因同一主题出现在多个集合中而导致的数据泄漏问题，避免模型性能的虚假膨胀。

Method: 使用ResNet-50和三元组边际损失进行训练，评估了在标准（20-way 1-shot）和挑战性（1000-way 1-shot）场景下的少量样本指纹识别。

Result: 模型在ChestXray-14和BraTS-2021数据集上分别取得了99.10%（20-way 1-shot）和90.06%（500-way 5-shot）以及99.20%（20-way 1-shot）和98.86%（100-way 3-shot）的高Mean-Recall-@-K分数。

Conclusion: 通过主题指纹技术，模型在3D MRI和2D X-ray数据上实现了高准确率的主题重识别，验证了该方法在避免数据泄漏方面的有效性。

Abstract: Combining open-source datasets can introduce data leakage if the same subject appears in multiple sets, leading to inflated model performance. To address this, we explore subject fingerprinting, mapping all images of a subject to a distinct region in latent space, to enable subject re-identification via similarity matching. Using a ResNet-50 trained with triplet margin loss, we evaluate few-shot fingerprinting on 3D MRI and 2D X-ray data in both standard (20-way 1-shot) and challenging (1000-way 1-shot) scenarios. The model achieves high Mean- Recall-@-K scores: 99.10% (20-way 1-shot) and 90.06% (500-way 5-shot) on ChestXray-14; 99.20% (20-way 1-shot) and 98.86% (100-way 3-shot) on BraTS- 2021.

</details>


### [81] [Detecting Localized Deepfakes: How Well Do Synthetic Image Detectors Handle Inpainting?](https://arxiv.org/abs/2512.16688)
*Serafino Pandolfini,Lorenzo Pellegrini,Matteo Ferrara,Davide Maltoni*

Main category: cs.CV

TL;DR: 研究评估了深度伪造检测模型在局部修复检测中的表现，发现其在检测大面积操作时优于临时方法。


<details>
  <summary>Details</summary>
Motivation: 生成AI的快速发展使得高度逼真的图像操作（如修复和区域级编辑）成为可能，这些技术在网络安全威胁场景中被越来越多地利用。然而，针对完全合成图像的检测器在局部操作上的泛化能力尚未充分表征。

Method: 本研究系统地评估了原本用于深度伪造检测的最先进检测器在局部修复检测任务中的表现，利用了多个数据集，涵盖不同的生成器、掩码大小和修复技术。

Result: 实验表明，在大量生成器上训练的模型对基于修复的编辑具有部分可迁移性，并能可靠地检测中等和大面积操作或再生式修复。

Conclusion: 现有的深度伪造检测模型在局部修复检测任务中表现出部分可迁移性，尤其在检测中等和大面积操作或再生式修复时优于现有临时检测方法。

Abstract: The rapid progress of generative AI has enabled highly realistic image manipulations, including inpainting and region-level editing. These approaches preserve most of the original visual context and are increasingly exploited in cybersecurity-relevant threat scenarios. While numerous detectors have been proposed for identifying fully synthetic images, their ability to generalize to localized manipulations remains insufficiently characterized. This work presents a systematic evaluation of state-of-the-art detectors, originally trained for the deepfake detection on fully synthetic images, when applied to a distinct challenge: localized inpainting detection. The study leverages multiple datasets spanning diverse generators, mask sizes, and inpainting techniques. Our experiments show that models trained on a large set of generators exhibit partial transferability to inpainting-based edits and can reliably detect medium- and large-area manipulations or regeneration-style inpainting, outperforming many existing ad hoc detection approaches.

</details>


### [82] [A multi-centre, multi-device benchmark dataset for landmark-based comprehensive fetal biometry](https://arxiv.org/abs/2512.16710)
*Chiara Di Vece,Zhehua Mao,Netanell Avisdris,Brian Dromey,Raffaele Napolitano,Dafna Ben Bashat,Francisco Vasconcelos,Danail Stoyanov,Leo Joskowicz,Sophia Bano*

Main category: cs.CV

TL;DR: 该论文提出了首个公开的多中心、多设备、标注了胎儿生物测量解剖标志的超声图像数据集，用于促进AI辅助胎儿生长评估的研究，并验证了多中心测试的重要性。


<details>
  <summary>Details</summary>
Motivation: 手动标注胎儿超声图像中的解剖标志耗时且易受操作者和设备差异影响，限制了自动化方法的可重复性。因此，需要多源标注数据集来开发AI辅助的胎儿生长评估方法。

Method: 研究团队创建了一个包含4,513张超声图像的基准数据集，覆盖了1,904名受试者，来自三个临床中心并使用七种不同的超声设备。数据集包含标准化的训练/测试分割、评估代码和基线结果。

Result: 研究结果表明，仅基于单一中心的训练和评估会显著高估模型性能，而多中心测试更能反映真实场景下的表现。

Conclusion: 该研究提供了一个开放、多中心、多设备的胎儿超声图像基准数据集，旨在促进AI辅助胎儿生长评估方法的开发，并通过自动生物测量模型验证了多中心测试的重要性。

Abstract: Accurate fetal growth assessment from ultrasound (US) relies on precise biometry measured by manually identifying anatomical landmarks in standard planes. Manual landmarking is time-consuming, operator-dependent, and sensitive to variability across scanners and sites, limiting the reproducibility of automated approaches. There is a need for multi-source annotated datasets to develop artificial intelligence-assisted fetal growth assessment methods. To address this bottleneck, we present an open, multi-centre, multi-device benchmark dataset of fetal US images with expert anatomical landmark annotations for clinically used fetal biometric measurements. These measurements include head bi-parietal and occipito-frontal diameters, abdominal transverse and antero-posterior diameters, and femoral length. The dataset contains 4,513 de-identified US images from 1,904 subjects acquired at three clinical sites using seven different US devices. We provide standardised, subject-disjoint train/test splits, evaluation code, and baseline results to enable fair and reproducible comparison of methods. Using an automatic biometry model, we quantify domain shift and demonstrate that training and evaluation confined to a single centre substantially overestimate performance relative to multi-centre testing. To the best of our knowledge, this is the first publicly available multi-centre, multi-device, landmark-annotated dataset that covers all primary fetal biometry measures, providing a robust benchmark for domain adaptation and multi-centre generalisation in fetal biometry and enabling more reliable AI-assisted fetal growth assessment across centres. All data, annotations, training code, and evaluation pipelines are made publicly available.

</details>


### [83] [OMG-Bench: A New Challenging Benchmark for Skeleton-based Online Micro Hand Gesture Recognition](https://arxiv.org/abs/2512.16727)
*Haochen Chang,Pengfei Ren,Buyuan Zhang,Da Li,Tianhao Han,Haoyang Zhang,Liang Xie,Hongbo Chen,Erwei Yin*

Main category: cs.CV

TL;DR: 该论文提出了OMG-Bench，首个基于骨架的大规模在线微手势识别基准，并开发了HMATr框架，通过分层记忆库和位置感知查询提升识别性能，检测率提高7.6%。


<details>
  <summary>Details</summary>
Motivation: 在线微手势识别在VR/AR交互中至关重要，但由于缺乏公开数据集和任务特定算法，面临挑战。微手势的细微运动模式使得构建具有精确骨架和帧级注释的数据集变得困难。

Method: 提出了一种端到端的框架Hierarchical Memory-Augmented Transformer (HMATr)，通过分层记忆库存储帧级细节和窗口级语义，并结合可学习的位置感知查询来隐式编码手势位置和语义。

Result: HMATr在实验中表现优于现有方法，检测率提高了7.6%。

Conclusion: HMATr框架在在线微手势识别任务中表现优异，检测率比现有最佳方法高出7.6%，为该领域建立了强大的基准。

Abstract: Online micro gesture recognition from hand skeletons is critical for VR/AR interaction but faces challenges due to limited public datasets and task-specific algorithms. Micro gestures involve subtle motion patterns, which make constructing datasets with precise skeletons and frame-level annotations difficult. To this end, we develop a multi-view self-supervised pipeline to automatically generate skeleton data, complemented by heuristic rules and expert refinement for semi-automatic annotation. Based on this pipeline, we introduce OMG-Bench, the first large-scale public benchmark for skeleton-based online micro gesture recognition. It features 40 fine-grained gesture classes with 13,948 instances across 1,272 sequences, characterized by subtle motions, rapid dynamics, and continuous execution. To tackle these challenges, we propose Hierarchical Memory-Augmented Transformer (HMATr), an end-to-end framework that unifies gesture detection and classification by leveraging hierarchical memory banks which store frame-level details and window-level semantics to preserve historical context. In addition, it employs learnable position-aware queries initialized from the memory to implicitly encode gesture positions and semantics. Experiments show that HMATr outperforms state-of-the-art methods by 7.6\% in detection rate, establishing a strong baseline for online micro gesture recognition. Project page: https://omg-bench.github.io/

</details>


### [84] [Task-Oriented Data Synthesis and Control-Rectify Sampling for Remote Sensing Semantic Segmentation](https://arxiv.org/abs/2512.16740)
*Yunkai Yang,Yudong Zhang,Kunquan Zhang,Jinxiao Zhang,Xinying Chen,Haohuan Fu,Runmin Dong*

Main category: cs.CV

TL;DR: 提出TODSynth框架，结合MM-DiT和CRFM方法，有效提升遥感语义分割数据合成的质量和稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决可控生成中语义掩码控制的复杂性和采样质量不确定性对下游语义分割任务的影响。

Method: 提出了一种任务导向的数据合成框架（TODSynth），包含多模态扩散变换器（MM-DiT）和基于任务反馈的即插即用采样策略。

Result: 实验表明，该方法在遥感语义分割任务中优于现有可控生成方法，生成更稳定且任务导向的合成数据。

Conclusion: TODSynth框架，包括MM-DiT和CRFM方法，显著提升了遥感语义分割数据合成的效果，尤其在少样本和复杂场景下表现优异。

Abstract: With the rapid progress of controllable generation, training data synthesis has become a promising way to expand labeled datasets and alleviate manual annotation in remote sensing (RS). However, the complexity of semantic mask control and the uncertainty of sampling quality often limit the utility of synthetic data in downstream semantic segmentation tasks. To address these challenges, we propose a task-oriented data synthesis framework (TODSynth), including a Multimodal Diffusion Transformer (MM-DiT) with unified triple attention and a plug-and-play sampling strategy guided by task feedback. Built upon the powerful DiT-based generative foundation model, we systematically evaluate different control schemes, showing that a text-image-mask joint attention scheme combined with full fine-tuning of the image and mask branches significantly enhances the effectiveness of RS semantic segmentation data synthesis, particularly in few-shot and complex-scene scenarios. Furthermore, we propose a control-rectify flow matching (CRFM) method, which dynamically adjusts sampling directions guided by semantic loss during the early high-plasticity stage, mitigating the instability of generated images and bridging the gap between synthetic data and downstream segmentation tasks. Extensive experiments demonstrate that our approach consistently outperforms state-of-the-art controllable generation methods, producing more stable and task-oriented synthetic data for RS semantic segmentation.

</details>


### [85] [TreeNet: A Light Weight Model for Low Bitrate Image Compression](https://arxiv.org/abs/2512.16743)
*Mahadev Prasad Panda,Purnachandra Rao Makkena,Srivatsa Prativadibhayankaram,Siegfried Fößel,André Kaup*

Main category: cs.CV

TL;DR: TreeNet是一种低复杂度图像压缩模型，通过树状结构和注意力机制，性能优于JPEG AI且复杂度大幅降低。


<details>
  <summary>Details</summary>
Motivation: 降低计算复杂度是学习型图像压缩技术广泛应用的关键挑战。

Method: 提出TreeNet，一种利用二进制树结构编码器-解码器架构和注意力特征融合机制的低复杂度图像压缩模型。

Result: 在三个基准数据集上，TreeNet在低比特率下比JPEG AI平均BD-rate提升4.83%，模型复杂度降低87.82%。

Conclusion: TreeNet通过二进制树结构编码器-解码器架构和注意力特征融合机制，显著降低了计算复杂度，并在低比特率下性能优于JPEG AI。

Abstract: Reducing computational complexity remains a critical challenge for the widespread adoption of learning-based image compression techniques. In this work, we propose TreeNet, a novel low-complexity image compression model that leverages a binary tree-structured encoder-decoder architecture to achieve efficient representation and reconstruction. We employ attentional feature fusion mechanism to effectively integrate features from multiple branches. We evaluate TreeNet on three widely used benchmark datasets and compare its performance against competing methods including JPEG AI, a recent standard in learning-based image compression. At low bitrates, TreeNet achieves an average improvement of 4.83% in BD-rate over JPEG AI, while reducing model complexity by 87.82%. Furthermore, we conduct extensive ablation studies to investigate the influence of various latent representations within TreeNet, offering deeper insights into the factors contributing to reconstruction.

</details>


### [86] [Make-It-Poseable: Feed-forward Latent Posing Model for 3D Humanoid Character Animation](https://arxiv.org/abs/2512.16767)
*Zhiyang Guo,Ori Zhang,Jax Xiang,Alan Zhao,Wengang Zhou,Houqiang Li*

Main category: cs.CV

TL;DR: Make-It-Poseable 是一种新的前馈框架，通过潜在空间变换解决3D角色姿势问题，显著提升质量并支持3D编辑。


<details>
  <summary>Details</summary>
Motivation: 现有的3D角色姿势方法（如自动绑定和姿势条件生成）存在皮肤权重预测不准确、拓扑缺陷和姿势一致性差等问题，限制了其鲁棒性和泛化能力。

Method: 该方法通过潜在姿势变换器直接操作形状标记，利用密集姿势表示进行精确控制，并结合潜在空间监督策略和自适应补全模块，确保高保真几何和拓扑变化适应性。

Result: Make-It-Poseable 在姿势质量上表现出色，并自然扩展到部件替换和细化等3D编辑应用。

Conclusion: Make-It-Poseable 提出了一种新颖的前馈框架，通过将角色姿势建模为潜在空间变换问题，显著提升了3D角色姿势的质量和灵活性，同时扩展了3D编辑应用的可能性。

Abstract: Posing 3D characters is a fundamental task in computer graphics and vision. However, existing methods like auto-rigging and pose-conditioned generation often struggle with challenges such as inaccurate skinning weight prediction, topological imperfections, and poor pose conformance, limiting their robustness and generalizability. To overcome these limitations, we introduce Make-It-Poseable, a novel feed-forward framework that reformulates character posing as a latent-space transformation problem. Instead of deforming mesh vertices as in traditional pipelines, our method reconstructs the character in new poses by directly manipulating its latent representation. At the core of our method is a latent posing transformer that manipulates shape tokens based on skeletal motion. This process is facilitated by a dense pose representation for precise control. To ensure high-fidelity geometry and accommodate topological changes, we also introduce a latent-space supervision strategy and an adaptive completion module. Our method demonstrates superior performance in posing quality. It also naturally extends to 3D editing applications like part replacement and refinement.

</details>


### [87] [FlowDet: Unifying Object Detection and Generative Transport Flows](https://arxiv.org/abs/2512.16771)
*Enis Baty,C. P. Bridges,Simon Hadfield*

Main category: cs.CV

TL;DR: FlowDet利用Conditional Flow Matching改进生成式目标检测，性能优于DiffusionDet，尤其在召回率受限时表现更佳。


<details>
  <summary>Details</summary>
Motivation: 旨在探索比DiffusionDet更高效的生成式目标检测方法，通过改进生成式传输路径提升性能。

Method: FlowDet将目标检测重新定义为更广泛的生成式传输问题，利用Conditional Flow Matching技术学习更简单、更直接的路径，从而在推理步骤增加时更快提升检测性能。

Result: FlowDet在多种实验设置下均优于基于扩散的检测系统，尤其在COCO和LVIS数据集上分别实现了+3.6% AP和+4.2% AP$_{rare}$的提升。

Conclusion: FlowDet通过Conditional Flow Matching技术在目标检测中实现了优于DiffusionDet的性能，特别是在召回率受限的设置下，显著提升了AP指标。

Abstract: We present FlowDet, the first formulation of object detection using modern Conditional Flow Matching techniques. This work follows from DiffusionDet, which originally framed detection as a generative denoising problem in the bounding box space via diffusion. We revisit and generalise this formulation to a broader class of generative transport problems, while maintaining the ability to vary the number of boxes and inference steps without re-training. In contrast to the curved stochastic transport paths induced by diffusion, FlowDet learns simpler and straighter paths resulting in faster scaling of detection performance as the number of inference steps grows. We find that this reformulation enables us to outperform diffusion based detection systems (as well as non-generative baselines) across a wide range of experiments, including various precision/recall operating points using multiple feature backbones and datasets. In particular, when evaluating under recall-constrained settings, we can highlight the effects of the generative transport without over-compensating with large numbers of proposals. This provides gains of up to +3.6% AP and +4.2% AP$_{rare}$ over DiffusionDet on the COCO and LVIS datasets, respectively.

</details>


### [88] [Kling-Omni Technical Report](https://arxiv.org/abs/2512.16776)
*Kling Team,Jialu Chen,Yuanzheng Ci,Xiangyu Du,Zipeng Feng,Kun Gai,Sainan Guo,Feng Han,Jingbin He,Kang He,Xiao Hu,Xiaohua Hu,Boyuan Jiang,Fangyuan Kong,Hang Li,Jie Li,Qingyu Li,Shen Li,Xiaohan Li,Yan Li,Jiajun Liang,Borui Liao,Yiqiao Liao,Weihong Lin,Quande Liu,Xiaokun Liu,Yilun Liu,Yuliang Liu,Shun Lu,Hangyu Mao,Yunyao Mao,Haodong Ouyang,Wenyu Qin,Wanqi Shi,Xiaoyu Shi,Lianghao Su,Haozhi Sun,Peiqin Sun,Pengfei Wan,Chao Wang,Chenyu Wang,Meng Wang,Qiulin Wang,Runqi Wang,Xintao Wang,Xuebo Wang,Zekun Wang,Min Wei,Tiancheng Wen,Guohao Wu,Xiaoshi Wu,Zhenhua Wu,Da Xie,Yingtong Xiong,Yulong Xu,Sile Yang,Zikang Yang,Weicai Ye,Ziyang Yuan,Shenglong Zhang,Shuaiyu Zhang,Yuanxing Zhang,Yufan Zhang,Wenzheng Zhao,Ruiliang Zhou,Yan Zhou,Guosheng Zhu,Yongjie Zhu*

Main category: cs.CV

TL;DR: Kling-Omni 是一个多模态生成框架，整合视频生成、编辑和智能推理任务，支持多种输入，生成高质量视频内容，是多模态世界模拟器的重要进展。


<details>
  <summary>Details</summary>
Motivation: 旨在通过一个统一的框架解决多样化视频生成、编辑和智能推理任务的功能分离问题，支持多种用户输入（如文本指令、参考图像和视频上下文）。

Method: 采用端到端的视角，整合了多样化的视频生成、编辑和智能推理任务，构建了一个全面的数据系统，并实施了高效的大规模预训练策略和推理基础设施优化。

Result: 综合评估显示，Kling-Omni 在上下文生成、基于推理的编辑和多模态指令跟随方面表现出色。

Conclusion: Kling-Omni 是一个多模态世界模拟器的关键进展，能够感知、推理、生成并与动态复杂的世界交互。

Abstract: We present Kling-Omni, a generalist generative framework designed to synthesize high-fidelity videos directly from multimodal visual language inputs. Adopting an end-to-end perspective, Kling-Omni bridges the functional separation among diverse video generation, editing, and intelligent reasoning tasks, integrating them into a holistic system. Unlike disjointed pipeline approaches, Kling-Omni supports a diverse range of user inputs, including text instructions, reference images, and video contexts, processing them into a unified multimodal representation to deliver cinematic-quality and highly-intelligent video content creation. To support these capabilities, we constructed a comprehensive data system that serves as the foundation for multimodal video creation. The framework is further empowered by efficient large-scale pre-training strategies and infrastructure optimizations for inference. Comprehensive evaluations reveal that Kling-Omni demonstrates exceptional capabilities in in-context generation, reasoning-based editing, and multimodal instruction following. Moving beyond a content creation tool, we believe Kling-Omni is a pivotal advancement toward multimodal world simulators capable of perceiving, reasoning, generating and interacting with the dynamic and complex worlds.

</details>


### [89] [R3ST: A Synthetic 3D Dataset With Realistic Trajectories](https://arxiv.org/abs/2512.16784)
*Simone Teglia,Claudia Melis Tonti,Francesco Pro,Leonardo Russo,Andrea Alfarano,Leonardo Pentassuglia,Irene Amerini*

Main category: cs.CV

TL;DR: R3ST是一个结合真实轨迹和合成3D环境的合成数据集，解决了现有数据集的标注和真实性不足问题。


<details>
  <summary>Details</summary>
Motivation: 现有真实数据集缺乏精确标注，而合成数据集则缺乏真实的车辆运动轨迹。R3ST旨在克服这些限制。

Method: 生成合成3D环境并整合来自SinD（无人机拍摄的鸟瞰数据集）的真实世界轨迹，创建R3ST数据集。

Result: R3ST数据集提供了准确的标注和真实的车辆轨迹，推动了轨迹预测研究。

Conclusion: R3ST数据集通过结合真实世界轨迹和合成3D环境，填补了合成数据与真实轨迹之间的鸿沟，为道路车辆轨迹预测研究提供了准确的多模态标注和真实的人类驾驶车辆轨迹。

Abstract: Datasets are essential to train and evaluate computer vision models used for traffic analysis and to enhance road safety. Existing real datasets fit real-world scenarios, capturing authentic road object behaviors, however, they typically lack precise ground-truth annotations. In contrast, synthetic datasets play a crucial role, allowing for the annotation of a large number of frames without additional costs or extra time. However, a general drawback of synthetic datasets is the lack of realistic vehicle motion, since trajectories are generated using AI models or rule-based systems. In this work, we introduce R3ST (Realistic 3D Synthetic Trajectories), a synthetic dataset that overcomes this limitation by generating a synthetic 3D environment and integrating real-world trajectories derived from SinD, a bird's-eye-view dataset recorded from drone footage. The proposed dataset closes the gap between synthetic data and realistic trajectories, advancing the research in trajectory forecasting of road vehicles, offering both accurate multimodal ground-truth annotations and authentic human-driven vehicle trajectories.

</details>


### [90] [KineST: A Kinematics-guided Spatiotemporal State Space Model for Human Motion Tracking from Sparse Signals](https://arxiv.org/abs/2512.16791)
*Shuting Zhao,Zeyu Xiao,Xinrong Chen*

Main category: cs.CV

TL;DR: KineST 通过运动学引导和混合时空学习，高效解决了AR/VR中全身体运动跟踪的挑战。


<details>
  <summary>Details</summary>
Motivation: 解决基于稀疏信号的AR/VR设备在重建真实多样全身体姿态时的高计算成本或时空依赖分离建模问题。

Method: 提出 KineST，一种新颖的运动学引导状态空间模型，通过运动学引导的双向扫描策略和混合时空表示学习方法，有效提取时空依赖关系。

Result: 实验证明 KineST 在精度和时间一致性上表现优越。

Conclusion: KineST 在轻量级框架下实现了高精度和时间一致性，显著提升了全身体运动跟踪的性能。

Abstract: Full-body motion tracking plays an essential role in AR/VR applications, bridging physical and virtual interactions. However, it is challenging to reconstruct realistic and diverse full-body poses based on sparse signals obtained by head-mounted displays, which are the main devices in AR/VR scenarios. Existing methods for pose reconstruction often incur high computational costs or rely on separately modeling spatial and temporal dependencies, making it difficult to balance accuracy, temporal coherence, and efficiency. To address this problem, we propose KineST, a novel kinematics-guided state space model, which effectively extracts spatiotemporal dependencies while integrating local and global pose perception. The innovation comes from two core ideas. Firstly, in order to better capture intricate joint relationships, the scanning strategy within the State Space Duality framework is reformulated into kinematics-guided bidirectional scanning, which embeds kinematic priors. Secondly, a mixed spatiotemporal representation learning approach is employed to tightly couple spatial and temporal contexts, balancing accuracy and smoothness. Additionally, a geometric angular velocity loss is introduced to impose physically meaningful constraints on rotational variations for further improving motion stability. Extensive experiments demonstrate that KineST has superior performance in both accuracy and temporal consistency within a lightweight framework. Project page: https://kaka-1314.github.io/KineST/

</details>


### [91] [DenseBEV: Transforming BEV Grid Cells into 3D Objects](https://arxiv.org/abs/2512.16818)
*Marius Dähling,Sebastian Krebs,J. Marius Zöllner*

Main category: cs.CV

TL;DR: DenseBEV通过直接利用BEV特征单元作为锚点，结合两阶段锚点生成和混合时间建模，显著提升了多摄像头3D物体检测的性能。


<details>
  <summary>Details</summary>
Motivation: 传统方法使用随机查询作为锚点，效率较低。为了提高检测效率和准确性，作者提出直接利用BEV特征单元作为锚点。

Method: 提出了一种新颖的两阶段锚点生成方法，直接利用BEV特征单元作为锚点，结合BEV-based Non-Maximum Suppression和混合时间建模方法。

Result: 在nuScenes数据集上，NDS和mAP指标显著提升；在Waymo数据集上，LET-mAP达到60.7%，超越之前最佳结果5.4%。

Conclusion: DenseBEV方法在多摄像头3D物体检测任务中表现出色，尤其在nuScenes和Waymo数据集上取得了显著的性能提升，特别是在小物体检测方面。

Abstract: In current research, Bird's-Eye-View (BEV)-based transformers are increasingly utilized for multi-camera 3D object detection. Traditional models often employ random queries as anchors, optimizing them successively. Recent advancements complement or replace these random queries with detections from auxiliary networks. We propose a more intuitive and efficient approach by using BEV feature cells directly as anchors. This end-to-end approach leverages the dense grid of BEV queries, considering each cell as a potential object for the final detection task. As a result, we introduce a novel two-stage anchor generation method specifically designed for multi-camera 3D object detection. To address the scaling issues of attention with a large number of queries, we apply BEV-based Non-Maximum Suppression, allowing gradients to flow only through non-suppressed objects. This ensures efficient training without the need for post-processing. By using BEV features from encoders such as BEVFormer directly as object queries, temporal BEV information is inherently embedded. Building on the temporal BEV information already embedded in our object queries, we introduce a hybrid temporal modeling approach by integrating prior detections to further enhance detection performance. Evaluating our method on the nuScenes dataset shows consistent and significant improvements in NDS and mAP over the baseline, even with sparser BEV grids and therefore fewer initial anchors. It is particularly effective for small objects, enhancing pedestrian detection with a 3.8% mAP increase on nuScenes and an 8% increase in LET-mAP on Waymo. Applying our method, named DenseBEV, to the challenging Waymo Open dataset yields state-of-the-art performance, achieving a LET-mAP of 60.7%, surpassing the previous best by 5.4%. Code is available at https://github.com/mdaehl/DenseBEV.

</details>


### [92] [Next-Generation License Plate Detection and Recognition System using YOLOv8](https://arxiv.org/abs/2512.16826)
*Arslan Amin,Rafia Mumtaz,Muhammad Jawad Bashir,Syed Mohammad Hassan Zaidi*

Main category: cs.CV

TL;DR: 研究评估了YOLOv8变体在车牌和字符识别中的表现，提出了一种高效且准确的优化管道配置，适用于智能交通系统的边缘设备部署。


<details>
  <summary>Details</summary>
Motivation: 在交通管理和车辆监控领域，高效的车牌检测和识别至关重要，但现有方法在多样化环境中的实时准确性仍有待提高。

Method: 研究采用YOLOv8的不同变体（Nano和Small）进行车牌识别和字符识别任务，并引入了一种基于x轴位置的字符排序方法。

Result: YOLOv8 Nano在车牌识别任务中表现出0.964的精确度和0.918的mAP50，YOLOv8 Small在字符识别任务中表现出0.92的精确度和0.91的mAP50。

Conclusion: 本研究提出了一种优化的管道配置，结合YOLOv8 Nano和YOLOv8 Small，不仅保持了计算效率，还确保了高准确性，为智能交通系统中的边缘设备部署奠定了坚实基础。

Abstract: In the evolving landscape of traffic management and vehicle surveillance, efficient license plate detection and recognition are indispensable. Historically, many methodologies have tackled this challenge, but consistent real-time accuracy, especially in diverse environments, remains elusive. This study examines the performance of YOLOv8 variants on License Plate Recognition (LPR) and Character Recognition tasks, crucial for advancing Intelligent Transportation Systems. Two distinct datasets were employed for training and evaluation, yielding notable findings. The YOLOv8 Nano variant demonstrated a precision of 0.964 and mAP50 of 0.918 on the LPR task, while the YOLOv8 Small variant exhibited a precision of 0.92 and mAP50 of 0.91 on the Character Recognition task. A custom method for character sequencing was introduced, effectively sequencing the detected characters based on their x-axis positions. An optimized pipeline, utilizing YOLOv8 Nano for LPR and YOLOv8 Small for Character Recognition, is proposed. This configuration not only maintains computational efficiency but also ensures high accuracy, establishing a robust foundation for future real-world deployments on edge devices within Intelligent Transportation Systems. This effort marks a significant stride towards the development of smarter and more efficient urban infrastructures.

</details>


### [93] [Radiology Report Generation with Layer-Wise Anatomical Attention](https://arxiv.org/abs/2512.16841)
*Emmanuel D. Muñiz-De-León,Jorge A. Rosales-de-Golferichs,Ana S. Muñoz-Rodríguez,Alejandro I. Trejo-Castro,Eduardo de Avila-Armenta,Antonio Martínez-Torteya*

Main category: cs.CV

TL;DR: 提出了一种紧凑的胸部X光报告生成模型，通过单张正面图像和层级解剖注意力机制，显著提升了性能，且无需额外训练参数。


<details>
  <summary>Details</summary>
Motivation: 当前最先进的放射学报告生成系统（如MAIRA-2和MedPaLM-M）依赖大规模多模态训练、临床元数据和多视角图像，资源消耗大且难以普及。本文旨在开发一种更紧凑、高效的解决方案。

Method: 模型结合了冻结的DINOv3 ViT编码器和增强的GPT-2解码器，通过层级解剖注意力机制（利用肺部和心脏分割掩模）来偏置注意力至临床相关区域，无需额外可训练参数。

Result: 在MIMIC-CXR数据集上评估，CheXpert Macro-F1和Micro-F1分别提升了168%和146%，RadGraph F1提升了9.7%。

Conclusion: 该论文提出了一种紧凑的图像到文本架构，通过单张正面胸部X光图像生成报告中的发现部分。该方法通过结合冻结的DINOv3 ViT编码器和增强的GPT-2解码器，利用层级解剖注意力机制，显著提升了临床相关区域的关注度，并在资源有限的情况下实现了性能的大幅提升。

Abstract: Automatic radiology report generation is a promising application of multimodal deep learning, aiming to reduce reporting workload and improve consistency. However, current state-of-the-art (SOTA) systems - such as Multimodal AI for Radiology Applications (MAIRA-2) and Medical Pathways Language Model-Multimodal (MedPaLM-M) - depend on large-scale multimodal training, clinical metadata, and multiple imaging views, making them resource-intensive and inaccessible for most settings. We introduce a compact image-to-text architecture that generates the Findings section of chest X-ray reports from a single frontal image. The model combines a frozen Self-Distillation with No Labels v3 (DINOv3) Vision Transformer (ViT) encoder with a Generative Pre-trained Transformer 2 (GPT-2) decoder enhanced by layer-wise anatomical attention. This mechanism integrates lung and heart segmentation masks through hierarchical Gaussian smoothing, biasing attention toward clinically relevant regions without adding trainable parameters. Evaluated on the official Medical Information Mart for Intensive Care-Chest X-ray (MIMIC-CXR) dataset using Chest Radiograph Expert (CheXpert) and Radiology Graph (RadGraph) metrics, our approach achieved substantial gains: CheXpert Macro-F1 for five key pathologies increased by 168% (0.083 -> 0.238) and Micro-F1 by 146% (0.137 -> 0.337), while broader performance across 14 observations improved by 86% (0.170 -> 0.316). Structural coherence also improved, with RadGraph F1 rising by 9.7%. Despite its small size and purely image-conditioned design, the model demonstrates that decoder-level anatomical guidance improves spatial grounding and enhances coherence in clinically relevant regions. The source code is publicly available at: https://github.com/devMuniz02/UDEM-CXR-Reporting-Thesis-2025.

</details>


### [94] [GenEval 2: Addressing Benchmark Drift in Text-to-Image Evaluation](https://arxiv.org/abs/2512.16853)
*Amita Kamath,Kai-Wei Chang,Ranjay Krishna,Luke Zettlemoyer,Yushi Hu,Marjan Ghazvininejad*

Main category: cs.CV

TL;DR: The paper identifies benchmark drift in T2I evaluation, introduces GenEval 2 and Soft-TIFA as improved solutions, and stresses the need for ongoing benchmark audits.


<details>
  <summary>Details</summary>
Motivation: To address the problem of benchmark drift in T2I model evaluation, where static benchmarks fail to keep up with evolving model capabilities.

Method: The authors propose GenEval 2, a new benchmark with improved coverage of visual concepts and compositionality, and Soft-TIFA, an evaluation method combining judgments for visual primitives.

Result: GenEval 2 and Soft-TIFA are shown to be more challenging for current models and better aligned with human judgment, reducing drift.

Conclusion: The paper highlights the issue of benchmark drift in T2I model evaluation and introduces GenEval 2 with Soft-TIFA as a more robust and human-aligned benchmark, emphasizing the need for continual audits.

Abstract: Automating Text-to-Image (T2I) model evaluation is challenging; a judge model must be used to score correctness, and test prompts must be selected to be challenging for current T2I models but not the judge. We argue that satisfying these constraints can lead to benchmark drift over time, where the static benchmark judges fail to keep up with newer model capabilities. We show that benchmark drift is a significant problem for GenEval, one of the most popular T2I benchmarks. Although GenEval was well-aligned with human judgment at the time of its release, it has drifted far from human judgment over time -- resulting in an absolute error of as much as 17.7% for current models. This level of drift strongly suggests that GenEval has been saturated for some time, as we verify via a large-scale human study. To help fill this benchmarking gap, we introduce a new benchmark, GenEval 2, with improved coverage of primitive visual concepts and higher degrees of compositionality, which we show is more challenging for current models. We also introduce Soft-TIFA, an evaluation method for GenEval 2 that combines judgments for visual primitives, which we show is more well-aligned with human judgment and argue is less likely to drift from human-alignment over time (as compared to more holistic judges such as VQAScore). Although we hope GenEval 2 will provide a strong benchmark for many years, avoiding benchmark drift is far from guaranteed and our work, more generally, highlights the importance of continual audits and improvement for T2I and related automated model evaluation benchmarks.

</details>


### [95] [RePlan: Reasoning-guided Region Planning for Complex Instruction-based Image Editing](https://arxiv.org/abs/2512.16864)
*Tianyuan Qu,Lei Ke,Xiaohang Zhan,Longxiang Tang,Yuqi Liu,Bohao Peng,Bei Yu,Dong Yu,Jiaya Jia*

Main category: cs.CV

TL;DR: RePlan通过分步规划和区域对齐的扩散编辑，解决了复杂指令与杂乱场景下的图像编辑问题，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有模型在指令-视觉复杂性（IV-Complexity）下表现不佳的问题，即复杂指令与杂乱/模糊场景结合时的编辑挑战。

Method: RePlan结合了视觉语言规划器和扩散编辑器，采用分步推理和显式区域定位，通过无训练的注意力区域注入机制实现并行多区域编辑。

Result: 在IV-Complex设置下，RePlan在区域精度和整体保真度上均优于基线模型，且仅需1K指令示例进行强化学习。

Conclusion: RePlan通过其plan-then-execute框架和GRPO强化学习，显著提升了在复杂指令和视觉场景下的编辑精度和整体保真度，优于现有基于大数据训练的基线模型。

Abstract: Instruction-based image editing enables natural-language control over visual modifications, yet existing models falter under Instruction-Visual Complexity (IV-Complexity), where intricate instructions meet cluttered or ambiguous scenes. We introduce RePlan (Region-aligned Planning), a plan-then-execute framework that couples a vision-language planner with a diffusion editor. The planner decomposes instructions via step-by-step reasoning and explicitly grounds them to target regions; the editor then applies changes using a training-free attention-region injection mechanism, enabling precise, parallel multi-region edits without iterative inpainting. To strengthen planning, we apply GRPO-based reinforcement learning using 1K instruction-only examples, yielding substantial gains in reasoning fidelity and format reliability. We further present IV-Edit, a benchmark focused on fine-grained grounding and knowledge-intensive edits. Across IV-Complex settings, RePlan consistently outperforms strong baselines trained on far larger datasets, improving regional precision and overall fidelity. Our project page: https://replan-iv-edit.github.io

</details>


### [96] [Pixel Seal: Adversarial-only training for invisible image and video watermarking](https://arxiv.org/abs/2512.16874)
*Tomáš Souček,Pierre Fernandez,Hady Elsahar,Sylvestre-Alvise Rebuffi,Valeriu Lacatusu,Tuan Tran,Tom Sander,Alexandre Mourachko*

Main category: cs.CV

TL;DR: Pixel Seal 通过对抗训练、三阶段计划和分辨率适应策略，解决了现有水印方法的三大问题，实现了更优的鲁棒性和不可感知性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在平衡水印的鲁棒性和真正不可感知性方面存在困难，主要问题包括依赖不准确的感知损失、优化不稳定以及高分辨率下性能下降。

Method: 1. 提出仅对抗训练范式，消除不可靠的像素级不可感知性损失；2. 引入三阶段训练计划，通过解耦鲁棒性和不可感知性稳定收敛；3. 通过基于JND的衰减和训练时推理模拟解决高分辨率适应问题。

Result: Pixel Seal 在不同图像类型和广泛变换下表现出显著的鲁棒性和不可感知性改进，并能高效适应视频水印。

Conclusion: Pixel Seal 通过创新的训练范式和调整策略，显著提升了水印的鲁棒性和不可感知性，为图像和视频的真实来源追踪提供了实用且可扩展的解决方案。

Abstract: Invisible watermarking is essential for tracing the provenance of digital content. However, training state-of-the-art models remains notoriously difficult, with current approaches often struggling to balance robustness against true imperceptibility. This work introduces Pixel Seal, which sets a new state-of-the-art for image and video watermarking. We first identify three fundamental issues of existing methods: (i) the reliance on proxy perceptual losses such as MSE and LPIPS that fail to mimic human perception and result in visible watermark artifacts; (ii) the optimization instability caused by conflicting objectives, which necessitates exhaustive hyperparameter tuning; and (iii) reduced robustness and imperceptibility of watermarks when scaling models to high-resolution images and videos. To overcome these issues, we first propose an adversarial-only training paradigm that eliminates unreliable pixel-wise imperceptibility losses. Second, we introduce a three-stage training schedule that stabilizes convergence by decoupling robustness and imperceptibility. Third, we address the resolution gap via high-resolution adaptation, employing JND-based attenuation and training-time inference simulation to eliminate upscaling artifacts. We thoroughly evaluate the robustness and imperceptibility of Pixel Seal on different image types and across a wide range of transformations, and show clear improvements over the state-of-the-art. We finally demonstrate that the model efficiently adapts to video via temporal watermark pooling, positioning Pixel Seal as a practical and scalable solution for reliable provenance in real-world image and video settings.

</details>


### [97] [Memory-Enhanced SAM3 for Occlusion-Robust Surgical Instrument Segmentation](https://arxiv.org/abs/2512.16880)
*Valay Bundele,Mehran Hosseinzadeh,Hendrik P. A. Lensch*

Main category: cs.CV

TL;DR: ReMeDI-SAM3通过改进的记忆管理和遮挡恢复机制，显著提升了内窥镜视频中手术器械分割的准确性。


<details>
  <summary>Details</summary>
Motivation: 内窥镜视频中手术器械分割因遮挡、快速运动、镜面反射等问题具有挑战性，现有SAM3框架在手术场景中表现受限。

Method: 提出了ReMeDI-SAM3，包括：(i) 基于相关性的记忆过滤和专用遮挡感知记忆，(ii) 分段插值方案扩展有效记忆容量，(iii) 特征重识别模块与时间投票机制。

Result: 在EndoVis17和EndoVis18数据集上，零样本设置下分别实现了约7%和16%的mcIoU绝对提升，优于现有基于训练的方法。

Conclusion: ReMeDI-SAM3通过其三个创新组件显著提升了内窥镜视频中手术器械分割的准确性，特别是在遮挡恢复和错误累积缓解方面表现出色。

Abstract: Accurate surgical instrument segmentation in endoscopic videos is crucial for computer-assisted interventions, yet remains challenging due to frequent occlusions, rapid motion, specular artefacts, and long-term instrument re-entry. While SAM3 provides a powerful spatio-temporal framework for video object segmentation, its performance in surgical scenes is limited by indiscriminate memory updates, fixed memory capacity, and weak identity recovery after occlusions. We propose ReMeDI-SAM3, a training-free memory-enhanced extension of SAM3, that addresses these limitations through three components: (i) relevance-aware memory filtering with a dedicated occlusion-aware memory for storing pre-occlusion frames, (ii) a piecewise interpolation scheme that expands the effective memory capacity, and (iii) a feature-based re-identification module with temporal voting for reliable post-occlusion identity disambiguation. Together, these components mitigate error accumulation and enable reliable recovery after occlusions. Evaluations on EndoVis17 and EndoVis18 under a zero-shot setting show absolute mcIoU improvements of around 7% and 16%, respectively, over vanilla SAM3, outperforming even prior training-based approaches. Project page: https://valaybundele.github.io/remedi-sam3/.

</details>


### [98] [LinkedOut: Linking World Knowledge Representation Out of Video LLM for Next-Generation Video Recommendation](https://arxiv.org/abs/2512.16891)
*Haichao Zhang,Yao Lu,Lichen Wang,Yunzhe Li,Daiwei Chen,Yunpeng Xu,Yun Fu*

Main category: cs.CV

TL;DR: LinkedOut 是一种新型 VLLM 表示方法，解决了视频推荐中的延迟、多视频输入和视觉细节保留问题，实现了高效、个性化的推荐。


<details>
  <summary>Details</summary>
Motivation: 现有 VLLM 在视频推荐任务中面临高延迟、不支持多视频输入和语言输出限制等问题，缺乏保留像素级细节并利用世界知识的表示。

Method: LinkedOut 通过可提示查询和可选辅助模态，从原始帧中提取语义基础、知识感知的标记，并引入跨层知识融合 MoE，选择适当的抽象级别。

Result: LinkedOut 在标准基准测试中达到最先进水平，并通过可解释性研究和消融实验验证了层多样性和逐层融合的优势。

Conclusion: LinkedOut 是一种基于 VLLM 的视频推荐方法，首次在原始帧上操作，无需手工标签，实现了标准基准测试的最新成果。通过层多样性和逐层融合，展示了利用 VLLM 世界知识先验和视觉推理的实用路径。

Abstract: Video Large Language Models (VLLMs) unlock world-knowledge-aware video understanding through pretraining on internet-scale data and have already shown promise on tasks such as movie analysis and video question answering. However, deploying VLLMs for downstream tasks such as video recommendation remains challenging, since real systems require multi-video inputs, lightweight backbones, low-latency sequential inference, and rapid response. In practice, (1) decode-only generation yields high latency for sequential inference, (2) typical interfaces do not support multi-video inputs, and (3) constraining outputs to language discards fine-grained visual details that matter for downstream vision tasks. We argue that these limitations stem from the absence of a representation that preserves pixel-level detail while leveraging world knowledge. We present LinkedOut, a representation that extracts VLLM world knowledge directly from video to enable fast inference, supports multi-video histories, and removes the language bottleneck. LinkedOut extracts semantically grounded, knowledge-aware tokens from raw frames using VLLMs, guided by promptable queries and optional auxiliary modalities. We introduce a cross-layer knowledge fusion MoE that selects the appropriate level of abstraction from the rich VLLM features, enabling personalized, interpretable, and low-latency recommendation. To our knowledge, LinkedOut is the first VLLM-based video recommendation method that operates on raw frames without handcrafted labels, achieving state-of-the-art results on standard benchmarks. Interpretability studies and ablations confirm the benefits of layer diversity and layer-wise fusion, pointing to a practical path that fully leverages VLLM world-knowledge priors and visual reasoning for downstream vision tasks such as recommendation.

</details>


### [99] [M-PhyGs: Multi-Material Object Dynamics from Video](https://arxiv.org/abs/2512.16885)
*Norika Wada,Kohei Yamashita,Ryo Kawahara,Ko Nishino*

Main category: cs.CV

TL;DR: M-PhyGs 是一种从视频中估计多材料复杂自然对象（如花朵）材料组成和物理参数的新方法，通过级联损失和时间小批量处理实现高效估计，并在 Phlowers 数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法假设对象为单一材料、预学习动力学或简单拓扑结构，而现实世界中的对象（如花朵）通常具有复杂的材料和几何结构。

Method: M-PhyGs 通过新引入的级联 3D 和 2D 损失函数以及时间小批量处理，从自然环境中捕获的短视频中联合分割对象为相似材料并恢复其连续力学参数。

Result: 实验结果表明，M-PhyGs 在多材料复杂自然对象的材料组成和参数估计任务中表现优异。

Conclusion: M-PhyGs 在 Phlowers 数据集上展示了其在多材料物理参数估计任务中的准确性和有效性。

Abstract: Knowledge of the physical material properties governing the dynamics of a real-world object becomes necessary to accurately anticipate its response to unseen interactions. Existing methods for estimating such physical material parameters from visual data assume homogeneous single-material objects, pre-learned dynamics, or simplistic topologies. Real-world objects, however, are often complex in material composition and geometry lying outside the realm of these assumptions. In this paper, we particularly focus on flowers as a representative common object. We introduce Multi-material Physical Gaussians (M-PhyGs) to estimate the material composition and parameters of such multi-material complex natural objects from video. From a short video captured in a natural setting, M-PhyGs jointly segments the object into similar materials and recovers their continuum mechanical parameters while accounting for gravity. M-PhyGs achieves this efficiently with newly introduced cascaded 3D and 2D losses, and by leveraging temporal mini-batching. We introduce a dataset, Phlowers, of people interacting with flowers as a novel platform to evaluate the accuracy of this challenging task of multi-material physical parameter estimation. Experimental results on Phlowers dataset demonstrate the accuracy and effectiveness of M-PhyGs and its components.

</details>


### [100] [Instant Expressive Gaussian Head Avatar via 3D-Aware Expression Distillation](https://arxiv.org/abs/2512.16893)
*Kaiwen Jiang,Xueting Li,Seonwook Park,Ravi Ramamoorthi,Shalini De Mello,Koki Nagano*

Main category: cs.CV

TL;DR: 结合2D扩散模型和3D前馈编码器，实现快速、3D一致且高表现力的肖像动画，运行速度达107.31 FPS。


<details>
  <summary>Details</summary>
Motivation: 现有的2D方法在3D一致性和速度上存在不足，而3D方法虽然保证了3D一致性和速度，但牺牲了表情细节。本文旨在结合两者的优势。

Method: 通过从2D扩散模型中提取知识，构建一个前馈编码器，将单张图像快速转换为3D一致且可动画的表示。该方法采用轻量级局部融合策略，替代了计算密集的全局融合机制。

Result: 该方法在动画和姿态控制上达到107.31 FPS，动画质量与现有最佳方法相当，同时在速度和表现力上取得了平衡。

Conclusion: 本文提出了一种结合2D扩散模型和3D前馈编码器的方法，实现了快速、3D一致且表达丰富的肖像动画。该方法通过轻量级局部融合策略，在保持高动画表现力的同时，显著提升了运行速度（107.31 FPS）。

Abstract: Portrait animation has witnessed tremendous quality improvements thanks to recent advances in video diffusion models. However, these 2D methods often compromise 3D consistency and speed, limiting their applicability in real-world scenarios, such as digital twins or telepresence. In contrast, 3D-aware facial animation feedforward methods -- built upon explicit 3D representations, such as neural radiance fields or Gaussian splatting -- ensure 3D consistency and achieve faster inference speed, but come with inferior expression details. In this paper, we aim to combine their strengths by distilling knowledge from a 2D diffusion-based method into a feed-forward encoder, which instantly converts an in-the-wild single image into a 3D-consistent, fast yet expressive animatable representation. Our animation representation is decoupled from the face's 3D representation and learns motion implicitly from data, eliminating the dependency on pre-defined parametric models that often constrain animation capabilities. Unlike previous computationally intensive global fusion mechanisms (e.g., multiple attention layers) for fusing 3D structural and animation information, our design employs an efficient lightweight local fusion strategy to achieve high animation expressivity. As a result, our method runs at 107.31 FPS for animation and pose control while achieving comparable animation quality to the state-of-the-art, surpassing alternative designs that trade speed for quality or vice versa. Project website is https://research.nvidia.com/labs/amri/projects/instant4d

</details>


### [101] [EasyV2V: A High-quality Instruction-based Video Editing Framework](https://arxiv.org/abs/2512.16920)
*Jinjie Mai,Chaoyang Wang,Guocheng Gordon Qian,Willi Menapace,Sergey Tulyakov,Bernard Ghanem,Peter Wonka,Ashkan Mirzaei*

Main category: cs.CV

TL;DR: EasyV2V 是一个基于指令的视频编辑框架，通过优化数据、架构和控制设计，实现了灵活输入下的高效编辑，效果领先。


<details>
  <summary>Details</summary>
Motivation: 尽管图像编辑技术发展迅速，视频编辑仍面临一致性、控制和泛化等挑战，因此研究了数据、架构和控制的设计空间。

Method: 通过组合现有专家与快速逆变换构建多样视频对，利用单帧监督和共享仿射运动的伪对将图像编辑对提升为视频，挖掘密集标注的视频片段对，并添加过渡监督以教授编辑展开方式。模型方面，观察到预训练的文本到视频模型具备编辑能力，采用简单的序列连接条件和轻量级LoRA微调。

Result: EasyV2V 在灵活输入条件下实现了最先进的视频编辑效果，超越了同期和商业系统。

Conclusion: EasyV2V 是一个简单有效的基于指令的视频编辑框架，通过灵活输入（如视频+文本、视频+掩码+文本、视频+掩码+参考+文本）实现了最先进的视频编辑效果，超越了同期和商业系统。

Abstract: While image editing has advanced rapidly, video editing remains less explored, facing challenges in consistency, control, and generalization. We study the design space of data, architecture, and control, and introduce \emph{EasyV2V}, a simple and effective framework for instruction-based video editing. On the data side, we compose existing experts with fast inverses to build diverse video pairs, lift image edit pairs into videos via single-frame supervision and pseudo pairs with shared affine motion, mine dense-captioned clips for video pairs, and add transition supervision to teach how edits unfold. On the model side, we observe that pretrained text-to-video models possess editing capability, motivating a simplified design. Simple sequence concatenation for conditioning with light LoRA fine-tuning suffices to train a strong model. For control, we unify spatiotemporal control via a single mask mechanism and support optional reference images. Overall, EasyV2V works with flexible inputs, e.g., video+text, video+mask+text, video+mask+reference+text, and achieves state-of-the-art video editing results, surpassing concurrent and commercial systems. Project page: https://snap-research.github.io/easyv2v/

</details>


### [102] [FlashPortrait: 6x Faster Infinite Portrait Animation with Adaptive Latent Prediction](https://arxiv.org/abs/2512.16900)
*Shuyuan Tu,Yueming Pan,Yinming Huang,Xintong Han,Zhen Xing,Qi Dai,Kai Qiu,Chong Luo,Zuxuan Wu*

Main category: cs.CV

TL;DR: FlashPortrait是一种端到端视频扩散变换器，通过归一化面部特征对齐和动态滑动窗口技术，实现了身份一致的长肖像动画生成和6倍推理加速。


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散的长肖像动画加速方法难以保证身份一致性，因此需要一种能够同时保持身份一致性和加速推理速度的新方法。

Method: FlashPortrait首先使用现成的提取器计算身份无关的面部表情特征，然后通过归一化面部表情块将面部特征与扩散潜在空间对齐。在推理阶段，采用动态滑动窗口方案和加权混合技术，确保长动画中的平滑过渡和身份一致性。此外，基于潜在变化率和扩散层间的导数幅度比，利用高阶潜在导数直接预测未来时间步的潜在空间，从而跳过多个去噪步骤。

Result: 实验结果表明，FlashPortrait在定性和定量评估中均表现出色，能够生成身份一致的长动画，并实现高达6倍的推理加速。

Conclusion: FlashPortrait通过创新的视频扩散变换器和动态滑动窗口方案，成功实现了身份一致性保持的长肖像动画生成，并在推理速度上实现了高达6倍的加速。

Abstract: Current diffusion-based acceleration methods for long-portrait animation struggle to ensure identity (ID) consistency. This paper presents FlashPortrait, an end-to-end video diffusion transformer capable of synthesizing ID-preserving, infinite-length videos while achieving up to 6x acceleration in inference speed. In particular, FlashPortrait begins by computing the identity-agnostic facial expression features with an off-the-shelf extractor. It then introduces a Normalized Facial Expression Block to align facial features with diffusion latents by normalizing them with their respective means and variances, thereby improving identity stability in facial modeling. During inference, FlashPortrait adopts a dynamic sliding-window scheme with weighted blending in overlapping areas, ensuring smooth transitions and ID consistency in long animations. In each context window, based on the latent variation rate at particular timesteps and the derivative magnitude ratio among diffusion layers, FlashPortrait utilizes higher-order latent derivatives at the current timestep to directly predict latents at future timesteps, thereby skipping several denoising steps and achieving 6x speed acceleration. Experiments on benchmarks show the effectiveness of FlashPortrait both qualitatively and quantitatively.

</details>


### [103] [Differences That Matter: Auditing Models for Capability Gap Discovery and Rectification](https://arxiv.org/abs/2512.16921)
*Qihao Liu,Chengzhi Mao,Yaojie Liu,Alan Yuille,Wen-Sheng Chu*

Main category: cs.CV

TL;DR: AuditDM通过自动审计发现并修复MLLM的失败模式，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 传统多模态LLM评估方法缺乏可解释性，难以全面揭示模型间的显著能力差距。

Method: AuditDM通过强化学习微调MLLM作为审计员，生成挑战性问题和反事实图像以最大化目标模型间的分歧。

Result: AuditDM在SoTA模型（如Gemma-3和PaliGemma-2）中发现超过20种不同的失败类型，微调后所有模型在16个基准测试中均有提升，并使3B模型超越其28B版本。

Conclusion: 随着数据扩展的收益递减，定向模型审计为模型诊断和改进提供了有效途径。

Abstract: Conventional evaluation methods for multimodal LLMs (MLLMs) lack interpretability and are often insufficient to fully disclose significant capability gaps across models. To address this, we introduce AuditDM, an automated framework that actively discovers and rectifies MLLM failure modes by auditing their divergence. AuditDM fine-tunes an MLLM as an auditor via reinforcement learning to generate challenging questions and counterfactual images that maximize disagreement among target models. Once trained, the auditor uncovers diverse, interpretable exemplars that reveal model weaknesses and serve as annotation-free data for rectification. When applied to SoTA models like Gemma-3 and PaliGemma-2, AuditDM discovers more than 20 distinct failure types. Fine-tuning on these discoveries consistently improves all models across 16 benchmarks, and enables a 3B model to surpass its 28B counterpart. Our results suggest that as data scaling hits diminishing returns, targeted model auditing offers an effective path to model diagnosis and improvement.

</details>


### [104] [Alchemist: Unlocking Efficiency in Text-to-Image Model Training via Meta-Gradient Data Selection](https://arxiv.org/abs/2512.16905)
*Kaixin Ding,Yang Zhou,Xi Chen,Miao Yang,Jiarong Ou,Rui Chen,Xin Tao,Hengshuang Zhao*

Main category: cs.CV

TL;DR: Alchemist是一种基于元梯度的自动数据选择框架，通过数据评级和修剪提升文本到图像模型的训练效率和视觉质量，实验证明其筛选的50%数据效果优于完整数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像生成模型（如Imagen、Stable Diffusion和FLUX）的性能受限于训练数据的质量。网络爬取和合成图像数据集中常包含低质量或冗余样本，导致视觉保真度下降、训练不稳定和计算效率低下。因此，有效的数据选择对提高数据效率至关重要。

Method: Alchemist框架包含两个关键阶段：数据评级和数据修剪。首先训练一个轻量级评分器，基于梯度信息评估每个样本的影响力，并通过多粒度感知增强；然后使用Shift-Gsampling策略选择信息丰富的子集进行高效模型训练。

Result: 实验表明，Alchemist在合成和网络爬取数据集上均能一致提升视觉质量和下游性能。

Conclusion: Alchemist作为一种基于元梯度的自动、可扩展的数据选择框架，在文本到图像模型训练中显著提升了视觉质量和下游性能。实验证明，使用Alchemist筛选的50%数据训练，效果优于使用完整数据集。

Abstract: Recent advances in Text-to-Image (T2I) generative models, such as Imagen, Stable Diffusion, and FLUX, have led to remarkable improvements in visual quality. However, their performance is fundamentally limited by the quality of training data. Web-crawled and synthetic image datasets often contain low-quality or redundant samples, which lead to degraded visual fidelity, unstable training, and inefficient computation. Hence, effective data selection is crucial for improving data efficiency. Existing approaches rely on costly manual curation or heuristic scoring based on single-dimensional features in Text-to-Image data filtering. Although meta-learning based method has been explored in LLM, there is no adaptation for image modalities. To this end, we propose **Alchemist**, a meta-gradient-based framework to select a suitable subset from large-scale text-image data pairs. Our approach automatically learns to assess the influence of each sample by iteratively optimizing the model from a data-centric perspective. Alchemist consists of two key stages: data rating and data pruning. We train a lightweight rater to estimate each sample's influence based on gradient information, enhanced with multi-granularity perception. We then use the Shift-Gsampling strategy to select informative subsets for efficient model training. Alchemist is the first automatic, scalable, meta-gradient-based data selection framework for Text-to-Image model training. Experiments on both synthetic and web-crawled datasets demonstrate that Alchemist consistently improves visual quality and downstream performance. Training on an Alchemist-selected 50% of the data can outperform training on the full dataset.

</details>


### [105] [VIVA: VLM-Guided Instruction-Based Video Editing with Reward Optimization](https://arxiv.org/abs/2512.16906)
*Xiaoyan Cong,Haotian Yang,Angtian Wang,Yizhi Wang,Yiding Yang,Canyu Zhang,Chongyang Ma*

Main category: cs.CV

TL;DR: VIVA通过VLM编码和奖励优化，提升了视频编辑的泛化能力和质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的方法因训练数据局限于简单编辑操作，难以泛化到复杂真实指令，VIVA旨在填补这一泛化差距。

Method: 1. 引入基于VLM的指导器，将文本指令、源视频首帧和可选参考图像编码为视觉基础指令表示；2. 提出后训练阶段Edit-GRPO，通过相对奖励直接优化模型；3. 设计数据构建管道生成多样化的合成视频-指令数据。

Result: 实验表明VIVA在指令遵循、泛化和编辑质量上优于现有方法。

Conclusion: VIVA框架通过VLM引导的编码和奖励优化，显著提升了基于指令的视频编辑在指令遵循、泛化能力和编辑质量上的表现，优于现有最先进方法。

Abstract: Instruction-based video editing aims to modify an input video according to a natural-language instruction while preserving content fidelity and temporal coherence. However, existing diffusion-based approaches are often trained on paired data of simple editing operations, which fundamentally limits their ability to generalize to diverse and complex, real-world instructions. To address this generalization gap, we propose VIVA, a scalable framework for instruction-based video editing that leverages VLM-guided encoding and reward optimization. First, we introduce a VLM-based instructor that encodes the textual instruction, the first frame of the source video, and an optional reference image into visually-grounded instruction representations, providing fine-grained spatial and semantic context for the diffusion transformer backbone. Second, we propose a post-training stage, Edit-GRPO, which adapts Group Relative Policy Optimization to the domain of video editing, directly optimizing the model for instruction-faithful, content-preserving, and aesthetically pleasing edits using relative rewards. Furthermore, we propose a data construction pipeline designed to synthetically generate diverse, high-fidelity paired video-instruction data of basic editing operations. Extensive experiments show that VIVA achieves superior instruction following, generalization, and editing quality over state-of-the-art methods. Website: https://viva-paper.github.io

</details>


### [106] [SceneDiff: A Benchmark and Method for Multiview Object Change Detection](https://arxiv.org/abs/2512.16908)
*Yuqun Wu,Chih-hao Lin,Henry Che,Aditi Tiwari,Chuhang Zou,Shenlong Wang,Derek Hoiem*

Main category: cs.CV

TL;DR: 论文提出SceneDiff方法，通过3D对齐和特征比较检测多视角场景中的物体变化，显著优于现有方法，并发布了相关基准和代码。


<details>
  <summary>Details</summary>
Motivation: 研究多视角场景中物体变化检测的问题，这对于机器人整理、施工进度和安全监控等应用至关重要。

Method: 提出了一种无训练的SceneDiff方法，利用预训练的3D、分割和图像编码模型，通过3D对齐、提取物体区域并比较空间和语义特征来检测变化。

Result: 在多视角和双视角基准测试中，SceneDiff方法相对于现有方法分别实现了94%和37.4%的相对AP提升。

Conclusion: 论文提出的SceneDiff方法在多视角物体变化检测中表现优异，大幅超越现有方法，并公开了基准和代码。

Abstract: We investigate the problem of identifying objects that have been added, removed, or moved between a pair of captures (images or videos) of the same scene at different times. Detecting such changes is important for many applications, such as robotic tidying or construction progress and safety monitoring. A major challenge is that varying viewpoints can cause objects to falsely appear changed. We introduce SceneDiff Benchmark, the first multiview change detection benchmark with object instance annotations, comprising 350 diverse video pairs with thousands of changed objects. We also introduce the SceneDiff method, a new training-free approach for multiview object change detection that leverages pretrained 3D, segmentation, and image encoding models to robustly predict across multiple benchmarks. Our method aligns the captures in 3D, extracts object regions, and compares spatial and semantic region features to detect changes. Experiments on multi-view and two-view benchmarks demonstrate that our method outperforms existing approaches by large margins (94% and 37.4% relative AP improvements). The benchmark and code will be publicly released.

</details>


### [107] [SFTok: Bridging the Performance Gap in Discrete Tokenizers](https://arxiv.org/abs/2512.16910)
*Qihang Rao,Borui Zhang,Wenzhao Zheng,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: SFTok是一种创新的离散标记器，通过多步迭代和独特训练策略，在高压缩率下实现了卓越的图像重建和生成性能。


<details>
  <summary>Details</summary>
Motivation: 现有的离散标记器在多模态系统中表现不如连续标记器，限制了其应用。

Method: 提出了SFTok，一种结合多步迭代机制、自强制引导视觉重建和去偏拟合训练策略的离散标记器。

Result: 在每图像仅64个令牌的高压缩率下，SFTok在ImageNet上实现了rFID = 1.21的最优重建质量，并在类到图像生成任务中表现优异（gFID = 2.29）。

Conclusion: SFTok作为一种离散标记器，通过多步迭代机制和创新的训练策略，显著提升了图像重建质量，并在高压缩率下实现了最先进的性能。

Abstract: Recent advances in multimodal models highlight the pivotal role of image tokenization in high-resolution image generation. By compressing images into compact latent representations, tokenizers enable generative models to operate in lower-dimensional spaces, thereby improving computational efficiency and reducing complexity. Discrete tokenizers naturally align with the autoregressive paradigm but still lag behind continuous ones, limiting their adoption in multimodal systems. To address this, we propose \textbf{SFTok}, a discrete tokenizer that incorporates a multi-step iterative mechanism for precise reconstruction. By integrating \textbf{self-forcing guided visual reconstruction} and \textbf{debias-and-fitting training strategy}, SFTok resolves the training-inference inconsistency in multi-step process, significantly enhancing image reconstruction quality. At a high compression rate of only 64 tokens per image, SFTok achieves state-of-the-art reconstruction quality on ImageNet (rFID = 1.21) and demonstrates exceptional performance in class-to-image generation tasks (gFID = 2.29).

</details>


### [108] [Depth Any Panoramas: A Foundation Model for Panoramic Depth Estimation](https://arxiv.org/abs/2512.16913)
*Xin Lin,Meixi Song,Dizhe Zhang,Wenxuan Lu,Haodong Li,Bo Du,Ming-Hsuan Yang,Truong Nguyen,Lu Qi*

Main category: cs.CV

TL;DR: 提出一种泛化性强的全景度量深度基础模型，通过数据增强和优化技术实现跨场景的稳定深度预测。


<details>
  <summary>Details</summary>
Motivation: 为了解决室内/室外和合成/真实数据之间的领域差距，并提升全景深度估计的泛化能力。

Method: 采用DINOv3-Large作为主干网络，结合伪标签生成管道、范围掩码头、锐度优化和几何优化等技术，以提高模型对不同距离的鲁棒性和几何一致性。

Result: 在多个基准测试（如Stanford2D3D、Matterport3D和Deep360）中表现出色，尤其在真实场景中提供了稳健的度量预测。

Conclusion: 该研究提出的全景度量深度基础模型在多样化场景距离中表现出强大的泛化能力，通过实验验证了其在多个基准测试中的优异性能。

Abstract: In this work, we present a panoramic metric depth foundation model that generalizes across diverse scene distances. We explore a data-in-the-loop paradigm from the view of both data construction and framework design. We collect a large-scale dataset by combining public datasets, high-quality synthetic data from our UE5 simulator and text-to-image models, and real panoramic images from the web. To reduce domain gaps between indoor/outdoor and synthetic/real data, we introduce a three-stage pseudo-label curation pipeline to generate reliable ground truth for unlabeled images. For the model, we adopt DINOv3-Large as the backbone for its strong pre-trained generalization, and introduce a plug-and-play range mask head, sharpness-centric optimization, and geometry-centric optimization to improve robustness to varying distances and enforce geometric consistency across views. Experiments on multiple benchmarks (e.g., Stanford2D3D, Matterport3D, and Deep360) demonstrate strong performance and zero-shot generalization, with particularly robust and stable metric predictions in diverse real-world scenes. The project page can be found at: \href{https://insta360-research-team.github.io/DAP_website/} {https://insta360-research-team.github.io/DAP\_website/}

</details>


### [109] [StereoPilot: Learning Unified and Efficient Stereo Conversion via Generative Priors](https://arxiv.org/abs/2512.16915)
*Guibao Shen,Yihua Du,Wenhang Ge,Jing He,Chirui Chang,Donghao Zhou,Zhen Yang,Luozhou Wang,Xin Tao,Ying-Cong Chen*

Main category: cs.CV

TL;DR: StereoPilot是一种新型立体视频转换模型，通过统一数据集和高效前馈架构，解决了现有方法的局限性，并在性能上取得显著提升。


<details>
  <summary>Details</summary>
Motivation: 解决现有Monocular-to-Stereo转换方法中多阶段‘Depth-Warp-Inpaint’（DWI）管道的错误传播、深度模糊和格式不一致问题。

Method: 提出了StereoPilot，一种高效的前馈模型，配备了可学习的域切换器和循环一致性损失，能够无缝适应不同的立体格式。

Result: StereoPilot在视觉保真度和计算效率上均显著优于现有最先进方法。

Conclusion: StereoPilot模型通过直接合成目标视图，无需依赖显式深度图或迭代扩散采样，显著提升了立体视频转换的视觉保真度和计算效率。

Abstract: The rapid growth of stereoscopic displays, including VR headsets and 3D cinemas, has led to increasing demand for high-quality stereo video content. However, producing 3D videos remains costly and complex, while automatic Monocular-to-Stereo conversion is hindered by the limitations of the multi-stage ``Depth-Warp-Inpaint'' (DWI) pipeline. This paradigm suffers from error propagation, depth ambiguity, and format inconsistency between parallel and converged stereo configurations. To address these challenges, we introduce UniStereo, the first large-scale unified dataset for stereo video conversion, covering both stereo formats to enable fair benchmarking and robust model training. Building upon this dataset, we propose StereoPilot, an efficient feed-forward model that directly synthesizes the target view without relying on explicit depth maps or iterative diffusion sampling. Equipped with a learnable domain switcher and a cycle consistency loss, StereoPilot adapts seamlessly to different stereo formats and achieves improved consistency. Extensive experiments demonstrate that StereoPilot significantly outperforms state-of-the-art methods in both visual fidelity and computational efficiency. Project page: https://hit-perfect.github.io/StereoPilot/.

</details>


### [110] [AdaTooler-V: Adaptive Tool-Use for Images and Videos](https://arxiv.org/abs/2512.16918)
*Chaoyang Wang,Kaituo Feng,Dongyang Chen,Zhongyu Wang,Zhixun Li,Sicheng Gao,Meng Meng,Xu Zhou,Manyuan Zhang,Yuzhang Shang,Xiangyu Yue*

Main category: cs.CV

TL;DR: AdaTooler-V是一种自适应工具使用的MLLM，通过AT-GRPO算法和专用数据集训练，在多个视觉推理任务中超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有开源模型在视觉工具使用上存在盲目性，增加了推理开销并降低了性能，因此需要一种自适应工具使用的方法。

Method: 提出了AT-GRPO强化学习算法，通过工具效益评分自适应调整奖励规模，并构建了两个数据集支持训练。

Result: AdaTooler-V在12个基准测试中表现优异，尤其在V*基准上达到了89.8%的准确率，超越了GPT-4o和Gemini 1.5 Pro。

Conclusion: AdaTooler-V通过自适应工具使用显著提升了多模态大语言模型的推理能力，并在多个基准测试中超越了现有方法，包括商业专有模型。

Abstract: Recent advances have shown that multimodal large language models (MLLMs) benefit from multimodal interleaved chain-of-thought (CoT) with vision tool interactions. However, existing open-source models often exhibit blind tool-use reasoning patterns, invoking vision tools even when they are unnecessary, which significantly increases inference overhead and degrades model performance. To this end, we propose AdaTooler-V, an MLLM that performs adaptive tool-use by determining whether a visual problem truly requires tools. First, we introduce AT-GRPO, a reinforcement learning algorithm that adaptively adjusts reward scales based on the Tool Benefit Score of each sample, encouraging the model to invoke tools only when they provide genuine improvements. Moreover, we construct two datasets to support training: AdaTooler-V-CoT-100k for SFT cold start and AdaTooler-V-300k for RL with verifiable rewards across single-image, multi-image, and video data. Experiments across twelve benchmarks demonstrate the strong reasoning capability of AdaTooler-V, outperforming existing methods in diverse visual reasoning tasks. Notably, AdaTooler-V-7B achieves an accuracy of 89.8\% on the high-resolution benchmark V*, surpassing the commercial proprietary model GPT-4o and Gemini 1.5 Pro. All code, models, and data are released.

</details>


### [111] [Next-Embedding Prediction Makes Strong Vision Learners](https://arxiv.org/abs/2512.16922)
*Sihan Xu,Ziqiao Ma,Wenhao Chai,Xuweiyi Chen,Weiyang Jin,Joyce Chai,Saining Xie,Stella X. Yu*

Main category: cs.CV

TL;DR: NEPA通过预测未来嵌入的生成式预训练方法，在视觉任务中取得强效结果，无需复杂设计。


<details>
  <summary>Details</summary>
Motivation: 探索生成式预训练原则是否能应用于视觉自监督学习，从学习表征转向学习模型。

Method: 采用Next-Embedding Predictive Autoregression (NEPA)方法，通过因果掩码和停止梯度训练模型预测未来补丁嵌入。

Result: 在ImageNet-1K上，ViT-B和ViT-L骨干网络分别达到83.8%和85.3%的top-1准确率，并在ADE20K上有效迁移至语义分割任务。

Conclusion: 生成式预训练从嵌入学习为视觉自监督学习提供了一种简单、可扩展且可能模态无关的替代方案。

Abstract: Inspired by the success of generative pretraining in natural language, we ask whether the same principles can yield strong self-supervised visual learners. Instead of training models to output features for downstream use, we train them to generate embeddings to perform predictive tasks directly. This work explores such a shift from learning representations to learning models. Specifically, models learn to predict future patch embeddings conditioned on past ones, using causal masking and stop gradient, which we refer to as Next-Embedding Predictive Autoregression (NEPA). We demonstrate that a simple Transformer pretrained on ImageNet-1k with next embedding prediction as its sole learning objective is effective - no pixel reconstruction, discrete tokens, contrastive loss, or task-specific heads. This formulation retains architectural simplicity and scalability, without requiring additional design complexity. NEPA achieves strong results across tasks, attaining 83.8% and 85.3% top-1 accuracy on ImageNet-1K with ViT-B and ViT-L backbones after fine-tuning, and transferring effectively to semantic segmentation on ADE20K. We believe generative pretraining from embeddings provides a simple, scalable, and potentially modality-agnostic alternative to visual self-supervised learning.

</details>


### [112] [Generative Refocusing: Flexible Defocus Control from a Single Image](https://arxiv.org/abs/2512.16923)
*Chun-Wei Tuan Mu,Jia-Bin Huang,Yu-Lun Liu*

Main category: cs.CV

TL;DR: 提出Generative Refocusing，通过半监督训练和真实光学特性，实现单图像去模糊和可控散焦效果，性能优越且支持文本引导调整。


<details>
  <summary>Details</summary>
Motivation: 单图像重聚焦仍具挑战性，现有方法需全聚焦输入、依赖模拟数据且光圈控制有限。

Method: 采用两步法：DeblurNet恢复全聚焦图像，BokehNet生成可控散焦效果。创新点是半监督训练，结合合成配对数据和未配对的真实散焦图像，利用EXIF元数据捕捉真实光学特性。

Result: 实验表明，该方法在去模糊、散焦合成和重聚焦基准测试中表现最佳，且支持文本引导和自定义光圈。

Conclusion: Generative Refocusing通过结合半监督训练和真实光学特性，在去模糊、散焦合成和重聚焦任务中取得了最佳性能，并支持文本引导调整和自定义光圈形状。

Abstract: Depth-of-field control is essential in photography, but getting the perfect focus often takes several tries or special equipment. Single-image refocusing is still difficult. It involves recovering sharp content and creating realistic bokeh. Current methods have significant drawbacks. They need all-in-focus inputs, depend on synthetic data from simulators, and have limited control over aperture. We introduce Generative Refocusing, a two-step process that uses DeblurNet to recover all-in-focus images from various inputs and BokehNet for creating controllable bokeh. Our main innovation is semi-supervised training. This method combines synthetic paired data with unpaired real bokeh images, using EXIF metadata to capture real optical characteristics beyond what simulators can provide. Our experiments show we achieve top performance in defocus deblurring, bokeh synthesis, and refocusing benchmarks. Additionally, our Generative Refocusing allows text-guided adjustments and custom aperture shapes.

</details>


### [113] [The World is Your Canvas: Painting Promptable Events with Reference Images, Trajectories, and Text](https://arxiv.org/abs/2512.16924)
*Hanlin Wang,Hao Ouyang,Qiuyu Wang,Yue Yu,Yihao Meng,Wen Wang,Ka Leong Cheng,Shuailei Ma,Qingyan Bai,Yixuan Li,Cheng Chen,Yanhong Zeng,Xing Zhu,Yujun Shen,Qifeng Chen*

Main category: cs.CV

TL;DR: WorldCanvas是一个多模态框架，通过结合文本、轨迹和参考图像，生成用户可控的丰富世界事件，提升世界模型的交互性和可控性。


<details>
  <summary>Details</summary>
Motivation: 解决现有文本-only方法和轨迹控制的图像到视频方法在生成多代理交互、对象进出、参考引导外观和反直觉事件时的局限性。

Method: 结合文本、轨迹和参考图像的多模态方法，通过轨迹编码运动、时间和可见性，自然语言表达语义意图，参考图像提供视觉基础，生成连贯、可控的事件。

Result: 生成的视频不仅具有时间连贯性，还展现出突发一致性，即使在对象暂时消失时也能保持对象身份和场景。

Conclusion: WorldCanvas将世界模型从被动预测器提升为交互式、用户可塑造的模拟器，支持丰富的、用户导向的世界事件生成。

Abstract: We present WorldCanvas, a framework for promptable world events that enables rich, user-directed simulation by combining text, trajectories, and reference images. Unlike text-only approaches and existing trajectory-controlled image-to-video methods, our multimodal approach combines trajectories -- encoding motion, timing, and visibility -- with natural language for semantic intent and reference images for visual grounding of object identity, enabling the generation of coherent, controllable events that include multi-agent interactions, object entry/exit, reference-guided appearance and counterintuitive events. The resulting videos demonstrate not only temporal coherence but also emergent consistency, preserving object identity and scene despite temporary disappearance. By supporting expressive world events generation, WorldCanvas advances world models from passive predictors to interactive, user-shaped simulators. Our project page is available at: https://worldcanvas.github.io/.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [114] [LOG.io: Unified Rollback Recovery and Data Lineage Capture for Distributed Data Pipelines](https://arxiv.org/abs/2512.16038)
*Eric Simon,Renato B. Hoffmann,Lucas Alf,Dalvan Griebler*

Main category: cs.DC

TL;DR: LOG.io是一种针对分布式数据管道的解决方案，支持非阻塞恢复和细粒度数据血缘捕获，在特定条件下性能优于ABS协议。


<details>
  <summary>Details</summary>
Motivation: 为解决分布式数据管道中的正确回滚恢复和细粒度数据血缘捕获问题，特别是在无服务器可扩展架构中。

Method: LOG.io采用基于日志的回滚恢复协议，支持非阻塞恢复、非确定性操作、外部系统交互和自定义代码，并允许动态扩展操作。

Result: 在SAP Data Intelligence系统中，LOG.io在特定场景下性能与ABS相当或更优，且数据血缘捕获开销极小。

Conclusion: LOG.io在特定条件下（如存在滞后操作和中等事件吞吐量时）表现优于ABS协议，尤其在恢复阶段。在其他情况下，ABS表现更优，但数据并行化可显著降低LOG.io的开销。此外，事件级数据血缘捕获的开销极低（<1.5%）。

Abstract: This paper introduces LOG.io, a comprehensive solution designed for correct rollback recovery and fine-grain data lineage capture in distributed data pipelines. It is tailored for serverless scalable architectures and uses a log-based rollback recovery protocol. LOG.io supports a general programming model, accommodating non-deterministic operators, interactions with external systems, and arbitrary custom code. It is non-blocking, allowing failed operators to recover independently without interrupting other active operators, thereby leveraging data parallelization, and it facilitates dynamic scaling of operators during pipeline execution. Performance evaluations, conducted within the SAP Data Intelligence system, compare LOG.io with the Asynchronous Barrier Snapshotting (ABS) protocol, originally implemented in Flink. Our experiments show that when there are straggler operators in a data pipeline and the throughput of events is moderate (e.g., 1 event every 100 ms), LOG.io performs as well as ABS during normal processing and outperforms ABS during recovery. Otherwise, ABS performs better than LOG.io for both normal processing and recovery. However, we show that in these cases, data parallelization can largely reduce the overhead of LOG.io while ABS does not improve. Finally, we show that the overhead of data lineage capture, at the granularity of the event and between any two operators in a pipeline, is marginal, with less than 1.5% in all our experiments.

</details>


### [115] [MultiPath Transfer Engine: Breaking GPU and Host-Memory Bandwidth Bottlenecks in LLM Services](https://arxiv.org/abs/2512.16056)
*Lingfeng Tang,Daoping Zhang,Junjie Chen,Peihao Huang,Feng Jin,Chengguang Xu,Yuxin Chen,Feiqiang Sun,Guo Chen*

Main category: cs.DC

TL;DR: MMA通过多路径数据传输提升GPU与主机内存带宽，显著优化LLM性能。


<details>
  <summary>Details</summary>
Motivation: PCIe带宽限制成为LLM性能瓶颈，现有协议导致服务器内带宽未充分利用。

Method: 提出了Multipath Memory Access (MMA)方案，支持通过动态库注入无缝部署，无需代码修改。

Result: MMA实现了245 GB/s的峰值带宽，比单路径带宽提升了4.62倍，显著降低了LLM服务的TTFT和模型切换延迟。

Conclusion: MMA通过多路径数据传输显著提升了GPU与主机内存之间的带宽，为LLM服务带来了显著的性能提升。

Abstract: The limited bandwidth of PCIe has emerged as the critical bottleneck for large language model (LLM) performance, such as prefix cache fetching and model switching. Although intra-server multipath data transfer between GPU and host memory is theoretically possible, heterogeneous protocols such as PCIe and NVLink currently limit the bandwidth between host memory and GPUs to that of a single PICe link. This limitation resuals in underutilized intra-server bandwidth. To address this issue, we propose Multipath Memory Access (MMA), a scheme that, to the best of our knowledge, is the first to enalbe efficient multipath data transfer between GPU and host memory. MMA supports seamless deployment via dynamic library injection, enabling LLM applications to benefit from MMA without requiring any code modification. In our testbed, MMA significantly improves the data transfer bandwidth between the GPU and memory, achieving a peak bandwidth of 245 GB/s-representing a 4.62x speedup compared to the natice single-path bandwidth. End-to-end evaluations demonstrate that MMA reduces the time-to-first-token (TTFT) for LLM serving by 1.14x to 2.38x and decreases model-switching latency in vLLM's sleep mode by 1.12x to 2.48x.

</details>


### [116] [Twinning for Space-Air-Ground-Sea Integrated Networks: Beyond Conventional Digital Twin Towards Goal-Oriented Semantic Twin](https://arxiv.org/abs/2512.16058)
*Yifei Qiu,Tianle Liao,Xin Jin,Shaohua Wu,Dusit Niyato,Qinyu Zhang*

Main category: cs.DC

TL;DR: 本文提出了一种面向目标的语义孪生（GOST）框架，以解决传统数字孪生在SAGSIN中的局限性，并通过案例研究展示了其优越性。


<details>
  <summary>Details</summary>
Motivation: 传统数字孪生（DT）在SAGSIN中存在高计算开销、模型同步延迟和跨系统语义鸿沟等根本性限制，GOST框架旨在解决这些问题。

Method: 通过基于知识的语义、数据驱动的语义和目标导向原则三个层次系统阐述了GOST框架，并详细介绍了其核心使能技术。

Result: GOST在远程卫星-无人机网络的协作跟踪任务中显著优于传统DT，特别是在感知数据的及时性和协作跟踪方面。

Conclusion: GOST框架被确立为一种变革性的孪生范式，有望指导SAGSIN的发展。

Abstract: A space-air-ground-sea integrated network (SAGSIN) has emerged as a cornerstone of 6G systems, establishing a unified global architecture by integrating multi-domain network resources. Motivated by the demand for real-time situational awareness and intelligent operational maintenance, digital twin (DT) technology was initially regarded as a promising solution, owing to its capability to create virtual replicas and emulate physical system behaviors. However, in the context of SAGSIN, the high-fidelity, full-scale modeling paradigm inherent to conventional DTs encounters fundamental limitations, including prohibitive computational overhead, delayed model synchronization, and cross-system semantic gaps. To address these limitations, this survey paper proposes a novel twinning framework: goal-oriented semantic twin (GOST). Unlike DTs that pursue physical mirroring, GOST prioritizes ``utility'' over ``fidelity,'' leveraging semantic technologies and goal-oriented principles to construct lightweight, task-specific representations. This paper systematically articulates the GOST framework through three layers: knowledge-based semantics, data-driven semantics, and goal-oriented principles. Furthermore, we provide a comprehensive tutorial on constructing GOST by detailing its core enabling technologies and introduce a multidimensional evaluation framework for GOST. We present a case study targeting collaborative tracking tasks in remote satellite-UAV networks, demonstrating that GOST significantly outperforms conventional DTs in timeliness of perceptual data and collaborative tracking. Finally, we outline research directions, establishing GOST as a transformative twinning paradigm to guide the development of SAGSIN.

</details>


### [117] [Cold-Start Anti-Patterns and Refactorings in Serverless Systems: An Empirical Study](https://arxiv.org/abs/2512.16066)
*Syed Salauddin Mohammad Tariq,Foyzul Hassan,Amiangshu Bosu,Probir Roy*

Main category: cs.DC

TL;DR: 本研究通过分析开源问题报告，开发了SCABENCH和INITSCOPE，显著优化了无服务器冷启动问题的诊断效率和定位准确性。


<details>
  <summary>Details</summary>
Motivation: 冷启动延迟是无服务器计算的主要性能瓶颈，现有方法将其视为黑盒优化问题，而本研究将其视为开发者可见的设计问题。

Method: 通过分析81份开源无服务器系统的问题报告，归纳了初始化反模式、修复策略和诊断挑战，并开发了SCABENCH基准测试和INITSCOPE分析框架。

Result: INITSCOPE在SCABENCH上比现有工具提升了40%的定位准确性和64%的诊断效率，开发者研究显示任务准确性和诊断速度均有提高。

Conclusion: 本研究通过SCABENCH基准测试和INITSCOPE分析框架，显著提升了冷启动问题的定位准确性和诊断效率，为无服务器设计中的性能优化提供了实证驱动的实践方法。

Abstract: Serverless computing simplifies deployment and scaling, yet cold-start latency remains a major performance bottleneck. Unlike prior work that treats mitigation as a black-box optimization, we study cold starts as a developer-visible design problem. From 81 adjudicated issue reports across open-source serverless systems, we derive taxonomies of initialization anti-patterns, remediation strategies, and diagnostic challenges spanning design, packaging, and runtime layers. Building on these insights, we introduce SCABENCH, a reproducible benchmark, and INITSCOPE, a lightweight analysis framework linking what code is loaded with what is executed. On SCABENCH, INITSCOPE improved localization accuracy by up to 40% and reduced diagnostic effort by 64% compared with prior tools, while a developer study showed higher task accuracy and faster diagnosis. Together, these results advance evidence-driven, performance-aware practices for cold-start mitigation in serverless design. Availability: The research artifact is publicly accessible for future studies and improvements.

</details>


### [118] [An Online Fragmentation-Aware Scheduler for Managing GPU-Sharing Workloads on Multi-Instance GPUs](https://arxiv.org/abs/2512.16099)
*Hsu-Tzu Ting,Jerry Chou,Ming-Hung Chen,I-Hsin Chung*

Main category: cs.DC

TL;DR: 论文针对MIG技术中的资源争用和碎片化问题，提出动态调度框架，实验证明可显著提升系统效率。


<details>
  <summary>Details</summary>
Motivation: 现代GPU工作负载需要高效的资源共享，但NVIDIA的MIG技术在硬件级分区中仍面临资源争用和碎片化问题，尤其是由于有限的MIG配置和刚性配置约束。

Method: 采用条件负载均衡、动态分区和作业迁移的集成方法，动态适应作业放置以减少争用，并重组GPU分配以对抗内外碎片化。

Result: 实验结果显示，应用所有技术后，makespan（总完成时间）最高可提升35%。

Conclusion: 论文提出了一种在线调度框架，通过动态调整作业放置和GPU分配，有效解决了MIG技术中的资源争用和碎片化问题，显著提升了系统效率。

Abstract: Modern GPU workloads increasingly demand efficient resource sharing, as many jobs do not require the full capacity of a GPU. Among sharing techniques, NVIDIA's Multi-Instance GPU (MIG) offers strong resource isolation by enabling hardware-level GPU partitioning. However, leveraging MIG effectively introduces new challenges. First, resource contention persists due to shared components such as PCIe bandwidth. Second, GPU fragmentation becomes a critical issue, which is different from prior fine-grained GPU sharing work due to MIG's limited number of valid MIG configurations. Fragmentation arises not only from spatial discontinuity but also from rigid profile placement constraints, especially after job arrivals and terminations. To address these issues, we propose an online scheduling framework that integrates conditional load balancing, dynamic partitioning, and job migration. Our approach dynamically adapts job placement to minimize contention and reorganizes GPU allocations to combat both internal and external fragmentation. Experimental results show that our method significantly improves system efficiency. When all techniques are applied, the makespan improves by up to 35%.

</details>


### [119] [Staggered Batch Scheduling: Co-optimizing Time-to-First-Token and Throughput for High-Efficiency LLM Inference](https://arxiv.org/abs/2512.16134)
*Jian Tian,Shuailong Li,Yang Cao,Wenbo Cui,Minghan Zhu,Wenkang Wu,Jianming Zhang,Yanpeng Wang,Zhiwen Xiao,Zhenyu Hou,Dou Shen*

Main category: cs.DC

TL;DR: SBS 和负载感知全局分配策略优化了 DP+EP 架构的 LLM 服务调度，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: DP+EP 架构的高内部同步成本导致传统调度方法产生严重的排队和并行化气泡，影响 TTFT。

Method: 提出了 Staggered Batch Scheduling (SBS) 机制，通过缓冲请求形成最优执行批次，并引入 Load-Aware Global Allocation 策略平衡 DP 单元的计算负载。

Result: 在生产 H800 集群上部署后，TTFT 降低了 30%-40%，吞吐量提高了 15%-20%。

Conclusion: Staggered Batch Scheduling (SBS) 和 Load-Aware Global Allocation 策略显著降低了 Time-to-First-Token (TTFT) 并提高了吞吐量，适用于 DP+EP 架构的 LLM 服务。

Abstract: The evolution of Large Language Model (LLM) serving towards complex, distributed architectures--specifically the P/D-separated, large-scale DP+EP paradigm--introduces distinct scheduling challenges. Unlike traditional deployments where schedulers can treat instances as black boxes, DP+EP architectures exhibit high internal synchronization costs. We identify that immediate request dispatching in such systems leads to severe in-engine queuing and parallelization bubbles, degrading Time-to-First-Token (TTFT). To address this, we propose Staggered Batch Scheduling (SBS), a mechanism that deliberately buffers requests to form optimal execution batches. This temporal decoupling eliminates internal queuing bubbles without compromising throughput. Furthermore, leveraging the scheduling window created by buffering, we introduce a Load-Aware Global Allocation strategy that balances computational load across DP units for both Prefill and Decode phases. Deployed on a production H800 cluster serving Deepseek-V3, our system reduces TTFT by 30%-40% and improves throughput by 15%-20% compared to state-of-the-art immediate scheduling baselines.

</details>


### [120] [Lotus: Optimizing Disaggregated Transactions with Disaggregated Locks](https://arxiv.org/abs/2512.16136)
*Zhisheng Hu,Pengfei Zuo,Junliang Hu,Yizou Chen,Yingjia Wang,Ming-Chang Yang*

Main category: cs.DC

TL;DR: Lotus通过锁解耦和优化锁管理，解决了DM中RDMA瓶颈问题，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有分布式事务系统中，RDMA网络接口卡因高频率的原子锁操作成为性能瓶颈，限制了系统的可扩展性。

Method: Lotus采用锁解耦技术，将锁管理从内存节点移至计算节点，并结合应用感知的锁管理机制和锁优先事务协议。

Result: 实验结果显示，Lotus相比现有系统，事务吞吐量提升高达2.1倍，延迟降低49.4%。

Conclusion: Lotus通过锁解耦和创新的锁管理机制，显著提升了分布式事务系统的性能和可扩展性，实验证明其吞吐量和延迟表现优于现有系统。

Abstract: Disaggregated memory (DM) separates compute and memory resources, allowing flexible scaling to achieve high resource utilization. To ensure atomic and consistent data access on DM, distributed transaction systems have been adapted, where compute nodes (CNs) rely on one-sided RDMA operations to access remote data in memory nodes (MNs). However, we observe that in existing transaction systems, the RDMA network interface cards at MNs become a primary performance bottleneck. This bottleneck arises from the high volume of one-sided atomic operations used for locks, which hinders the system's ability to scale efficiently.
  To address this issue, this paper presents Lotus, a scalable distributed transaction system with lock disaggregation on DM. The key innovation of Lotus is to disaggregate locks from data and execute all locks on CNs, thus eliminating the bottleneck at MN RNICs. To achieve efficient lock management on CNs, Lotus employs an application-aware lock management mechanism that leverages the locality of the OLTP workloads to shard locks while maintaining load balance. To ensure consistent transaction processing with lock disaggregation, Lotus introduces a lock-first transaction protocol, which separates the locking phase as the first step in each read-write transaction execution. This protocol allows the system to determine the success of lock acquisitions early and proactively abort conflicting transactions, improving overall efficiency. To tolerate lock loss during CN failures, Lotus employs a lock-rebuild-free recovery mechanism that treats locks as ephemeral and avoids their reconstruction, ensuring lightweight recovery for CN failures. Experimental results demonstrate that Lotus improves transaction throughput by up to 2.1$\times$ and reduces latency by up to 49.4% compared to state-of-the-art transaction systems on DM.

</details>


### [121] [FlexKV: Flexible Index Offloading for Memory-Disaggregated Key-Value Store](https://arxiv.org/abs/2512.16148)
*Zhisheng Hu,Jiacheng Shen,Ming-Chang Yang*

Main category: cs.DC

TL;DR: FlexKV是一种内存解耦键值存储，通过动态索引卸载和优化缓存管理，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有内存解耦键值存储在索引处理和计算侧缓存效率上存在性能瓶颈，FlexKV旨在通过动态索引卸载解决这些问题。

Method: FlexKV提出了三种关键技术：1) 基于秩感知的热度检测算法平衡计算节点间的索引负载；2) 两级计算节点内存优化方案高效利用内存；3) RPC聚合的缓存管理机制降低一致性开销。

Result: 实验表明，FlexKV相比现有最优解，吞吐量提升最高达2.94倍，延迟降低最高达85.2%。

Conclusion: FlexKV通过动态卸载索引至计算节点，显著提升了内存解耦键值存储的性能，解决了现有方法在索引处理和计算侧缓存效率上的瓶颈。

Abstract: Disaggregated memory (DM) is a promising data center architecture that decouples CPU and memory into independent resource pools to improve resource utilization. Building on DM, memory-disaggregated key-value (KV) stores are adopted to efficiently manage remote data. Unfortunately, existing approaches suffer from poor performance due to two critical issues: 1) the overdependence on one-sided atomic operations in index processing, and 2) the constrained efficiency in compute-side caches. To address these issues, we propose FlexKV, a memory-disaggregated KV store with index proxying. Our key idea is to dynamically offload the index to compute nodes, leveraging their powerful CPUs to accelerate index processing and maintain high-performance compute-side caches. Three challenges have to be addressed to enable efficient index proxying on DM, i.e., the load imbalance across compute nodes, the limited memory of compute nodes, and the expensive cache coherence overhead. FlexKV proposes: 1) a rank-aware hotness detection algorithm to continuously balance index load across compute nodes, 2) a two-level CN memory optimization scheme to efficiently utilize compute node memory, and 3) an RPC-aggregated cache management mechanism to reduce cache coherence overhead. The experimental results show that FlexKV improves throughput by up to 2.94$\times$ and reduces latency by up to 85.2%, compared with the state-of-the-art memory-disaggregated KV stores.

</details>


### [122] [AI4EOSC: a Federated Cloud Platform for Artificial Intelligence in Scientific Research](https://arxiv.org/abs/2512.16455)
*Ignacio Heredia,Álvaro López García,Germán Moltó,Amanda Calatrava,Valentin Kozlov,Alessandro Costantini,Viet Tran,Mario David,Daniel San Martín,Marcin Płóciennik,Marta Obregón Ruiz,Saúl Fernandez,Judith Sáinz-Pardo Díaz,Miguel Caballer,Caterina Alarcón Marín,Stefan Dlugolinsky,Martin Šeleng,Lisana Berberi,Khadijeh Alibabaei,Borja Esteban Sanchis,Pedro Castro,Giacinto Donvito,Diego Aguirre,Sergio Langarita,Vicente Rodriguez,Leonhard Duda,Andrés Heredia Canales,Susana Rebolledo Ruiz,João Machado,Giang Nguyen,Fernando Aguilar Gómez,Jaime Díez*

Main category: cs.DC

TL;DR: 该论文描述了一个专为科学工作负载中AI设计的联邦计算平台，提供全生命周期支持，并强调可追溯性、可重复性和易定制性。


<details>
  <summary>Details</summary>
Motivation: 为了支持科学工作负载中的人工智能应用，并解决分布式电子基础设施的一致性和透明访问问题。

Method: 平台通过全面的服务目录提供集成的用户体验，涵盖机器学习全生命周期，包括模型开发、训练和部署，并提供工具确保AI模型的可追溯性和可重复性。

Result: 平台成功集成了多种AI模型提供商、数据集和存储资源，提供了从开发到部署的全生命周期支持，并易于定制以适应不同社区需求。

Conclusion: 该平台通过提供一致、透明的访问方式，支持科学工作负载中的人工智能应用，并降低了外部社区的采用门槛。

Abstract: In this paper, we describe a federated compute platform dedicated to support Artificial Intelligence in scientific workloads. Putting the effort into reproducible deployments, it delivers consistent, transparent access to a federation of physically distributed e-Infrastructures. Through a comprehensive service catalogue, the platform is able to offer an integrated user experience covering the full Machine Learning lifecycle, including model development (with dedicated interactive development environments), training (with GPU resources, annotation tools, experiment tracking, and federated learning support) and deployment (covering a wide range of deployment options all along the Cloud Continuum). The platform also provides tools for traceability and reproducibility of AI models, integrates with different Artificial Intelligence model providers, datasets and storage resources, allowing users to interact with the broader Machine Learning ecosystem. Finally, it is easily customizable to lower the adoption barrier by external communities.

</details>


### [123] [Efficient CPU-GPU Collaborative Inference for MoE-based LLMs on Memory-Limited Systems](https://arxiv.org/abs/2512.16473)
*En-Ming Huang,Li-Shang Lin,Chun-Yi Lee*

Main category: cs.DC

TL;DR: 本文提出了一种CPU-GPU协作推理框架，通过专家缓存机制优化推理性能，适合消费级硬件。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）计算需求高，混合专家（MoE）模型虽能减少计算需求，但仍需超出消费级GPU容量的内存。传统卸载方法因数据传输延迟限制了推理性能。

Method: 采用专家缓存机制在GPU上减少数据传输需求，并通过CPU多线程优化处理缓存未命中情况。

Result: 评估表明该框架能提升性能，并验证了CPU-GPU协作在单请求推理场景下最大化硬件利用的可行性。

Conclusion: 本文提出了一种新颖的CPU-GPU协作推理框架，通过专家缓存机制减少数据传输需求，并在缓存命中时实现更快的推理。实验证明该框架能提升性能，并展示了CPU-GPU协作在消费级系统上最大化硬件利用的潜力。

Abstract: Large Language Models (LLMs) have achieved impressive results across various tasks, yet their high computational demands pose deployment challenges, especially on consumer-grade hardware. Mixture of Experts (MoE) models provide an efficient solution through selective activation of parameter subsets, which reduces computation requirements. Despite this efficiency, state-of-the-art MoE models still require substantial memory beyond typical consumer GPU capacities. Traditional offloading methods that transfer model weights between CPU and GPU introduce latency, limiting inference performance. This paper presents a novel CPU-GPU collaborative inference framework that incorporates an expert caching mechanism on the GPU to reduce data transfer requirements and enable faster inference through cache hits. Computations are offloaded to CPU for efficient cache miss handling, which benefits from CPU multithreading optimizations. The evaluations of our framework demonstrate performance improvements and highlight the potential of CPU-GPU collaboration to maximize hardware utilization for single-request inference scenarios on consumer-grade systems. The implementation of our framework is available at https://github.com/elsa-lab/MoE-CPU-GPU-Collaborative-Inference.

</details>


### [124] [Delay-Aware Multi-Stage Edge Server Upgrade with Budget Constraint](https://arxiv.org/abs/2512.16792)
*Endar Suprih Wihidayat,Sieteng Soh,Kwan-Wu Chin,Duc-son Pham*

Main category: cs.DC

TL;DR: M-ESU框架通过多阶段优化边缘服务器升级和任务卸载，显著提升任务满足率，尤其适用于大型网络。


<details>
  <summary>Details</summary>
Motivation: 为了解决多阶段边缘计算系统中服务器升级和任务卸载的优化问题，以最大化满足延迟要求的任务数量。

Method: 提出了M-ESU框架，包含MILP模型和M-ESU/H启发式算法，分别适用于小型和大型网络。

Result: M-ESU/H在小型网络中接近最优解（偏差1.25%），在大型网络中相比其他启发式算法任务满足率提升高达21.57%。

Conclusion: M-ESU框架通过MILP模型和M-ESU/H启发式算法，有效解决了多阶段边缘服务器升级问题，尤其在大型网络中表现出显著的性能提升和可扩展性。

Abstract: In this paper, the Multi-stage Edge Server Upgrade (M-ESU) is proposed as a new network planning problem, involving the upgrading of an existing multi-access edge computing (MEC) system through multiple stages (e.g., over several years). More precisely, the problem considers two key decisions: (i) whether to deploy additional edge servers or upgrade those already installed, and (ii) how tasks should be offloaded so that the average number of tasks that meet their delay requirement is maximized. The framework specifically involves: (i) deployment of new servers combined with capacity upgrades for existing servers, and (ii) the optimal task offloading to maximize the average number of tasks with a delay requirement. It also considers the following constraints: (i) budget per stage, (ii) server deployment and upgrade cost (in $) and cost depreciation rate, (iii) computation resource of servers, (iv) number of tasks and their growth rate (in %), and (v) the increase in task sizes and stricter delay requirements over time. We present two solutions: a Mixed Integer Linear Programming (MILP) model and an efficient heuristic algorithm (M-ESU/H). MILP yields the optimal solution for small networks, whereas M-ESU/H is used in large-scale networks. For small networks, the simulation results show that the solution computed by M-ESU/H is within 1.25% of the optimal solution while running several orders of magnitude faster. For large networks, M-ESU/H is compared against three alternative heuristic solutions that consider only server deployment, or giving priority to server deployment or upgrade. Our experiments show that M-ESU/H yields up to 21.57% improvement in task satisfaction under identical budget and demand growth conditions, confirming its scalability and practical value for long-term MEC systems.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [125] [A Fast Volumetric Capture and Reconstruction Pipeline for Dynamic Point Clouds and Gaussian Splats](https://arxiv.org/abs/2512.15719)
*Athanasios Charisoudis,Simone Croci,Lam Kit Yung,Pascal Frossard,Aljosa Smolic*

Main category: cs.GR

TL;DR: 该系统通过改进GPS-Gaussian回归器，实现了高效3D重建，支持灵活部署和多种格式导出，开源框架便于研究。


<details>
  <summary>Details</summary>
Motivation: 开发一个快速、高效的体积捕获和重建系统，支持野外操作和灵活相机配置，便于部署和使用。

Method: 改进GPS-Gaussian回归器，处理RGB-D或RGB-only输入，生成点云和高斯泼溅的3D表示。

Result: 系统实现了5-10 FPS的实时预览，支持多种标准格式导出，并通过定性质化验证了部署性和效果。

Conclusion: 该系统通过改进GPS-Gaussian回归器，实现了高效、高质量的3D重建，支持多种输入格式和灵活部署，开源框架促进了可复现性和进一步研究。

Abstract: We present a fast and efficient volumetric capture and reconstruction system that processes either RGB-D or RGB-only input to generate 3D representations in the form of point clouds and Gaussian splats. For Gaussian splat reconstructions, we took the GPS-Gaussian regressor and improved it, enabling high-quality reconstructions with minimal overhead. The system is designed for easy setup and deployment, supporting in-the-wild operation under uncontrolled illumination and arbitrary backgrounds, as well as flexible camera configurations, including sparse setups, arbitrary camera numbers and baselines. Captured data can be exported in standard formats such as PLY, MPEG V-PCC, and SPLAT, and visualized through a web-based viewer or Unity/Unreal plugins. A live on-location preview of both input and reconstruction is available at 5-10 FPS. We present qualitative findings focused on deployability and targeted ablations. The complete framework is open-source, facilitating reproducibility and further research.

</details>


### [126] [Enhancing Line Density Plots with Outlier Control and Bin-based Illumination](https://arxiv.org/abs/2512.16017)
*Yumeng Xue,Bin Chen,Patrick Paetzold,Yunhai Wang,Christophe Hurter,Oliver Deussen*

Main category: cs.GR

TL;DR: 本文提出了一种基于分箱的照明模型，用于增强线型数据集（如轨迹）的可视化，通过解耦结构和密度，有效突出趋势和异常，同时保持色彩准确性和交互性。


<details>
  <summary>Details</summary>
Motivation: 密度图在总结大量点时非常有效，但在处理线型数据集时会破坏路径连续性，掩盖平滑趋势和罕见异常。因此，需要一种方法在保留密度图优点的同时解决这些问题。

Method: 提出了一种基于分箱的照明模型，通过引入分箱异常值度量对轨迹进行排序，并构建结构法线图，在亮度通道中应用局部自适应照明，以突出从主导趋势到非典型路径的各种模式。

Result: 该方法在多个真实数据集上展示了其有效性，能够揭示简单方法遗漏的细节，比标准着色方法显著降低了CIEDE2000色彩失真，并支持交互式更新。

Conclusion: 本文提出的基于分箱的照明模型有效解决了线型数据集（如轨迹或时间序列）在密度图中路径连续性被破坏的问题，通过解耦结构和密度，增强了流动感并揭示了稀疏异常值，同时保持了原始色彩映射。该方法支持交互式更新，适用于多达10,000条线的数据集。

Abstract: Density plots effectively summarize large numbers of points, which would otherwise lead to severe overplotting in, for example, a scatter plot. However, when applied to line-based datasets, such as trajectories or time series, density plots alone are insufficient, as they disrupt path continuity, obscuring smooth trends and rare anomalies. We propose a bin-based illumination model that decouples structure from density to enhance flow and reveal sparse outliers while preserving the original colormap. We introduce a bin-based outlierness metric to rank trajectories. Guided by this ranking, we construct a structural normal map and apply locally-adaptive lighting in the luminance channel to highlight chosen patterns -- from dominant trends to atypical paths -- with acceptable color distortion. Our interactive method enables analysts to prioritize main trends, focus on outliers, or strike a balance between the two. We demonstrate our method on several real-world datasets, showing it reveals details missed by simpler alternatives, achieves significantly lower CIEDE2000 color distortion than standard shading, and supports interactive updates for up to 10,000 lines.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [127] [Improved Lower Bounds for Privacy under Continual Release](https://arxiv.org/abs/2512.15981)
*Bardiya Aryanfard,Monika Henzinger,David Saulpic,A. R. Sricharan*

Main category: cs.DS

TL;DR: 论文研究了差分隐私下持续发布动态数据集统计信息的问题，证明了插入式图问题的多项式加性误差下界，并展示了允许乘法近似时的多对数误差机制。


<details>
  <summary>Details</summary>
Motivation: 研究在动态数据集下持续发布统计信息时的差分隐私问题，特别是插入式与完全动态更新之间的误差差异。

Method: 通过技术展示多项式加性误差的下界，并提出在允许乘法近似时的持续机制。

Result: 证明了插入式图问题（如最大匹配、度直方图和k-core）的多项式加性误差下界，并提出了允许乘法近似时的多对数加性误差机制。

Conclusion: 该论文展示了在插入式动态数据集下，差分隐私持续发布统计信息时，多项式加性误差的下界是不可避免的。同时，允许小的乘法近似可以显著降低加性误差至多对数级别。

Abstract: We study the problem of continually releasing statistics of an evolving dataset under differential privacy. In the event-level setting, we show the first polynomial lower bounds on the additive error for insertions-only graph problems such as maximum matching, degree histogram and $k$-core. This is an exponential improvement on the polylogarithmic lower bounds of Fichtenberger et al.[ESA 2021] for the former two problems, and are the first continual release lower bounds for the latter. Our results run counter to the intuition that the difference between insertions-only vs fully dynamic updates causes the gap between polylogarithmic and polynomial additive error. We show that for maximum matching and $k$-core, allowing small multiplicative approximations is what brings the additive error down to polylogarithmic.
  Beyond graph problems, our techniques also show that polynomial additive error is unavoidable for Simultaneous Norm Estimation in the insertions-only setting. When multiplicative approximations are allowed, we circumvent this lower bound by giving the first continual mechanism with polylogarithmic additive error under $(1+ζ)$ multiplicative approximations, for $ζ>0$, for estimating all monotone symmetric norms simultaneously.
  In the item-level setting, we show polynomial lower bounds on the product of the multiplicative and the additive error of continual mechanisms for a large range of graph problems. To the best of our knowledge, these are the first lower bounds for any differentially private continual release mechanism with multiplicative error. To obtain this, we prove a new lower bound on the product of multiplicative and additive error for 1-Way-Marginals, from which we reduce to continual graph problems. This generalizes the lower bounds of Hardt and Talwar[STOC 2010] and Bun et al.[STOC 2014] on the additive error for mechanisms with no multiplicative error.

</details>


### [128] [Instance Optimality in PageRank Centrality Estimation](https://arxiv.org/abs/2512.16087)
*Mikkel Thorup,Hanzhi Wang*

Main category: cs.DS

TL;DR: 自适应PageRank估计算法在稀疏和有界度数图中表现优异，但在高度数图中不适用。


<details>
  <summary>Details</summary>
Motivation: 探讨如何改进经典算法以适应不同图结构，特别是稀疏图和有界度数图。

Method: 研究了一种自适应变体的简单经典算法，用于估计顶点的PageRank中心性，具有恒定相对误差和恒定概率。

Result: 该算法在最大入度和出度不超过n的常数比例的有向图中，以及最多有polylogarithmic数量顶点具有无界度数的图中，是实例最优的（至多polylogarithmic因子）。

Conclusion: 该算法在大多数顶点度数接近n的图中不是实例最优的。

Abstract: We study an adaptive variant of a simple, classic algorithm for estimating a vertex's PageRank centrality within a constant relative error, with constant probability. We show that this algorithm is instance-optimal up to a polylogarithmic factor for any directed graph of order $n$ whose maximal in- and out-degrees are at most a constant fraction of $n$. The instance-optimality also extends to graphs in which up to a polylogarithmic number of vertices have unbounded degree, thereby covering all sparse graphs with $\widetilde{O}(n)$ edges. Finally, we provide a counterexample showing that the algorithm is not instance-optimal for graphs with degrees mostly equal to $n$.

</details>


### [129] [Conquering the Multiverse: The River Voting Method with Efficient Parallel Universe Tiebreaking](https://arxiv.org/abs/2512.16414)
*Jannes Malanowski*

Main category: cs.DS

TL;DR: River投票方法结合PUT在多项式时间内可计算，优化了算法效率。


<details>
  <summary>Details</summary>
Motivation: 解决Ranked Pairs方法在平局情况下无法同时保证中立性和计算可行性的问题。

Method: 引入半River图处理边顺序，并应用Prim算法变体计算River获胜者。

Result: 证明River与PUT结合可在多项式时间内计算，并优化了算法运行时间至O(n² log n)。

Conclusion: River与PUT结合的计算方法在多项式最坏情况下运行时间可行，且通过半River图和Prim算法变体优化了计算效率。

Abstract: Democracy relies on making collective decisions through voting. In addition, voting procedures have further applications, for example in the training of artificial intelligence. An essential criterion for determining the winner of a fair election is that all alternatives are treated equally: this is called neutrality. The established Ranked Pairs voting method cannot simultaneously guarantee neutrality and be computationally tractable for election with ties. River, the recently introduced voting method, shares desirable properties with Ranked Pairs and has further advantages, such as a new property related to resistance against manipulation. Both Ranked Pairs and River use a weighted margin graph to model the election. Ties in the election can lead to edges of equal margin. To order the edges in such a case, a tiebreaking scheme must be employed. Many tiebreaks violate neutrality or other important properties. A tiebreaking scheme that preserves neutrality is Parallel Universe Tiebreaking (PUT). Ranked Pairs with PUT is NP-hard to compute.
  The main result of this thesis shows that River with PUT can be computed in polynomial worst-case runtime: We can check whether an alternative is a River PUT winner, by running River with a specially constructed ordering of the edges. To construct this ordering, we introduce the semi-River diagram which contains the edges that can appear in any River diagram for some arbitrary tiebreak. On this diagram we can compute the River winners, by applying a variant of Prims algorithm per alternative. Additionally, we give an algorithm improve the previous naive runtime of River from $\mathcal{O}(n^4)$ to $\mathcal{O}(n^2 \log n)$, where n is the number of alternatives.

</details>


### [130] [Fully Dynamic Algorithms for Chamfer Distance](https://arxiv.org/abs/2512.16639)
*Gramoz Goranci,Shaofeng Jiang,Peter Kiss,Eva Szilagyi,Qiaoyuan Yang*

Main category: cs.DS

TL;DR: 首个动态算法用于维护Chamfer距离的近似值，基于ANN搜索，适用于动态点云数据集。


<details>
  <summary>Details</summary>
Motivation: Chamfer距离是点云数据中广泛使用的差异度量，动态数据集需要高效的重复评估，如机器学习中的损失函数。

Method: 算法通过近似最近邻搜索（ANN）实现，减少了计算开销。

Result: 实现了(1+ε)-近似和O(1/ε)-近似，分别在˜O(ε⁻ᵈ)和˜O(dn^{ε²}ε⁻⁴)的更新时间内完成。

Conclusion: 本文提出了首个动态算法，用于在ℓ₁和ℓ₂范数下维护Chamfer距离的近似值，并通过实际数据集验证了其性能。

Abstract: We study the problem of computing Chamfer distance in the fully dynamic setting, where two set of points $A, B \subset \mathbb{R}^{d}$, each of size up to $n$, dynamically evolve through point insertions or deletions and the goal is to efficiently maintain an approximation to $\mathrm{dist}_{\mathrm{CH}}(A,B) = \sum_{a \in A} \min_{b \in B} \textrm{dist}(a,b)$, where $\textrm{dist}$ is a distance measure. Chamfer distance is a widely used dissimilarity metric for point clouds, with many practical applications that require repeated evaluation on dynamically changing datasets, e.g., when used as a loss function in machine learning. In this paper, we present the first dynamic algorithm for maintaining an approximation of the Chamfer distance under the $\ell_p$ norm for $p \in \{1,2 \}$. Our algorithm reduces to approximate nearest neighbor (ANN) search with little overhead. Plugging in standard ANN bounds, we obtain $(1+ε)$-approximation in $\tilde{O}(ε^{-d})$ update time and $O(1/ε)$-approximation in $\tilde{O}(d n^{ε^2} ε^{-4})$ update time. We evaluate our method on real-world datasets and demonstrate that it performs competitively against natural baselines.

</details>


### [131] [Learning Confidence Ellipsoids and Applications to Robust Subspace Recovery](https://arxiv.org/abs/2512.16875)
*Chao Gao,Liren Shan,Vaidehi Srinivas,Aravindan Vijayaraghavan*

Main category: cs.DS

TL;DR: 本文提出了一种高效算法，用于在高维空间中寻找具有体积近似保证的置信椭圆体，并证明了其计算硬度。


<details>
  <summary>Details</summary>
Motivation: 研究高维空间中任意分布的置信椭圆体问题，尤其是在椭球条件数β趋于无穷时，如何高效找到具有体积近似保证的置信椭圆体。

Method: 算法和分析利用了最小体积包围椭圆的丰富原始对偶结构和几何Brascamp-Lieb不等式。

Result: 提出了一种多项式时间算法，找到的椭圆体体积在最佳β条件椭圆体的O(β^{γd})倍内，同时覆盖至少1-O(α/γ)的概率质量。

Conclusion: 本文的主要贡献是提出了一种多项式时间算法，能够在高维空间中高效找到具有体积近似保证的置信椭圆体，并与计算硬度结果相辅相成。

Abstract: We study the problem of finding confidence ellipsoids for an arbitrary distribution in high dimensions. Given samples from a distribution $D$ and a confidence parameter $α$, the goal is to find the smallest volume ellipsoid $E$ which has probability mass $\Pr_{D}[E] \ge 1-α$. Ellipsoids are a highly expressive class of confidence sets as they can capture correlations in the distribution, and can approximate any convex set. This problem has been studied in many different communities. In statistics, this is the classic minimum volume estimator introduced by Rousseeuw as a robust non-parametric estimator of location and scatter. However in high dimensions, it becomes NP-hard to obtain any non-trivial approximation factor in volume when the condition number $β$ of the ellipsoid (ratio of the largest to the smallest axis length) goes to $\infty$. This motivates the focus of our paper: can we efficiently find confidence ellipsoids with volume approximation guarantees when compared to ellipsoids of bounded condition number $β$?
  Our main result is a polynomial time algorithm that finds an ellipsoid $E$ whose volume is within a $O(β^{γd})$ multiplicative factor of the volume of best $β$-conditioned ellipsoid while covering at least $1-O(α/γ)$ probability mass for any $γ< α$. We complement this with a computational hardness result that shows that such a dependence seems necessary up to constants in the exponent. The algorithm and analysis uses the rich primal-dual structure of the minimum volume enclosing ellipsoid and the geometric Brascamp-Lieb inequality. As a consequence, we obtain the first polynomial time algorithm with approximation guarantees on worst-case instances of the robust subspace recovery problem.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [132] [Anubuddhi: A Multi-Agent AI System for Designing and Simulating Quantum Optics Experiments](https://arxiv.org/abs/2512.15736)
*S. K. Rithvik*

Main category: cs.AI

TL;DR: Anubuddhi是一个多代理AI系统，通过自然语言提示设计和模拟量子光学实验，无需专业编程知识，验证了设计的物理正确性，并在多数实验中优于受限框架。


<details>
  <summary>Details</summary>
Motivation: 旨在为非专业编程知识的用户提供设计和模拟量子光学实验的能力，从而民主化计算实验设计。

Method: 系统通过语义检索从三层工具箱中排列组件来组合光学布局，并通过物理模拟与收敛细化验证设计。架构结合了意图路由、知识增强生成和双模式验证（QuTiP和FreeSim）。

Result: 系统在13个实验中实现了8-9/10的设计-模拟对齐分数，模拟结果忠实建模了预期物理。自由形式模拟在11/13实验中优于受限框架。

Conclusion: Anubuddhi系统通过结合意图路由、知识增强生成和双模式验证，成功实现了从自然语言提示设计和模拟量子光学实验，为研究和教学提供了强大的初始设计工具。

Abstract: We present Anubuddhi, a multi-agent AI system that designs and simulates quantum optics experiments from natural language prompts without requiring specialized programming knowledge. The system composes optical layouts by arranging components from a three-tier toolbox via semantic retrieval, then validates designs through physics simulation with convergent refinement. The architecture combines intent routing, knowledge-augmented generation, and dual-mode validation (QuTiP and FreeSim). We evaluated 13 experiments spanning fundamental optics (Hong-Ou-Mandel interference, Michelson/Mach-Zehnder interferometry, Bell states, delayed-choice quantum eraser), quantum information protocols (BB84 QKD, Franson interferometry, GHZ states, quantum teleportation, hyperentanglement), and advanced technologies (boson sampling, electromagnetically induced transparency, frequency conversion). The system achieves design-simulation alignment scores of 8--9/10, with simulations faithfully modeling intended physics. A critical finding distinguishes structural correctness from quantitative accuracy: high alignment confirms correct physics architecture, while numerical predictions require expert review. Free-form simulation outperformed constrained frameworks for 11/13 experiments, revealing that quantum optics diversity demands flexible mathematical representations. The system democratizes computational experiment design for research and pedagogy, producing strong initial designs users can iteratively refine through conversation.

</details>


### [133] [The Principle of Proportional Duty: A Knowledge-Duty Framework for Ethical Equilibrium in Human and Artificial Systems](https://arxiv.org/abs/2512.15740)
*Timothy Prescher*

Main category: cs.AI

TL;DR: PPD框架将道德责任与不确定性动态关联，通过数学建模和跨领域验证，提供了一种新的伦理决策方法。


<details>
  <summary>Details</summary>
Motivation: 传统伦理框架难以在不确定性下建模决策，PPD旨在解决这一问题。

Method: 引入比例责任原则（PPD），通过数学公式和蒙特卡洛模拟验证框架的动态平衡效果。

Result: PPD框架在临床伦理、法律、经济治理和AI领域均表现出稳定性和减少过度自信决策的风险。

Conclusion: PPD框架通过将道德责任与不确定性动态关联，提供了一种可审计的AI决策系统开发方法，并在多个领域验证了其跨学科有效性。

Abstract: Traditional ethical frameworks often struggle to model decision-making under uncertainty, treating it as a simple constraint on action. This paper introduces the Principle of Proportional Duty (PPD), a novel framework that models how ethical responsibility scales with an agent's epistemic state. The framework reveals that moral duty is not lost to uncertainty but transforms: as uncertainty increases, Action Duty (the duty to act decisively) is proportionally converted into Repair Duty (the active duty to verify, inquire, and resolve uncertainty).
  This dynamic is expressed by the equation D_total = K[(1-HI) + HI * g(C_signal)], where Total Duty is a function of Knowledge (K), Humility/Uncertainty (HI), and Contextual Signal Strength (C_signal). Monte Carlo simulations demonstrate that systems maintaining a baseline humility coefficient (lambda > 0) produce more stable duty allocations and reduce the risk of overconfident decision-making.
  By formalizing humility as a system parameter, the PPD offers a mathematically tractable approach to moral responsibility that could inform the development of auditable AI decision systems. This paper applies the framework across four domains, clinical ethics, recipient-rights law, economic governance, and artificial intelligence, to demonstrate its cross-disciplinary validity. The findings suggest that proportional duty serves as a stabilizing principle within complex systems, preventing both overreach and omission by dynamically balancing epistemic confidence against contextual risk.

</details>


### [134] [Prompt-to-Parts: Generative AI for Physical Assembly and Scalable Instructions](https://arxiv.org/abs/2512.15743)
*David Noever*

Main category: cs.AI

TL;DR: 该论文提出了一种框架，通过自然语言描述生成物理可实现的组装指令，利用LDraw和大型语言模型，确保几何有效性、连接约束和构建顺序，并在复杂领域展示了其可扩展性和实用性。


<details>
  <summary>Details</summary>
Motivation: 旨在弥合语义设计意图与可制造输出之间的差距，提出一种新颖的基本通用语言，以解决之前基于像素的扩散方法或CAD模型无法支持复杂组装指令或组件交换的问题。

Method: 使用LDraw作为文本丰富的中间表示，通过大型语言模型引导工具生成有效的逐步构建序列和组装指令。引入了一个Python库用于程序化模型生成，并在复杂的卫星、飞机和建筑领域评估可构建输出。

Result: 在超过3000个组装部件的基于积木的原型上，展示了可扩展性、模块化和保真度，能够从自然语言规范中生成物理原型。

Conclusion: 该论文提出了一种新颖的"积木包"方法，作为一种物理API，通过约束词汇将精确定向的积木位置与"词袋"连接，从而将任意功能需求编译为物质现实。这种方法为制造和工程原型设计中的自然语言实现提供了新的设计选项。

Abstract: We present a framework for generating physically realizable assembly instructions from natural language descriptions. Unlike unconstrained text-to-3D approaches, our method operates within a discrete parts vocabulary, enforcing geometric validity, connection constraints, and buildability ordering. Using LDraw as a text-rich intermediate representation, we demonstrate that large language models can be guided with tools to produce valid step-by-step construction sequences and assembly instructions for brick-based prototypes of more than 3000 assembly parts. We introduce a Python library for programmatic model generation and evaluate buildable outputs on complex satellites, aircraft, and architectural domains. The approach aims for demonstrable scalability, modularity, and fidelity that bridges the gap between semantic design intent and manufacturable output. Physical prototyping follows from natural language specifications. The work proposes a novel elemental lingua franca as a key missing piece from the previous pixel-based diffusion methods or computer-aided design (CAD) models that fail to support complex assembly instructions or component exchange. Across four original designs, this novel "bag of bricks" method thus functions as a physical API: a constrained vocabulary connecting precisely oriented brick locations to a "bag of words" through which arbitrary functional requirements compile into material reality. Given such a consistent and repeatable AI representation opens new design options while guiding natural language implementations in manufacturing and engineering prototyping.

</details>


### [135] [Emergence: Overcoming Privileged Information Bias in Asymmetric Embodied Agents via Active Querying](https://arxiv.org/abs/2512.15776)
*Shaun Baek,Sam Liu,Joseph Ukpong*

Main category: cs.AI

TL;DR: 研究发现，在信息不对称的具身环境中，LLMs因缺乏心智理论而难以有效协作。通过实验证明，主动查询机制能显著提高协作成功率。


<details>
  <summary>Details</summary>
Motivation: 研究大型语言模型（LLMs）在具身环境中因信息不对称分布而面临的“符号接地”问题，特别是特权信息偏见（或“知识诅咒”）现象。

Method: 提出了一个新颖的非对称辅助推理框架（Asymmetric Assistive Reasoning framework）在AI2-THOR环境中进行实验。

Result: 实验揭示了显著的“成功差距”：领导者成功感知目标的概率为35.0%，而协作团队的成功率仅为17.0%，表明近50%的可行计划因沟通接地错误而失败。主动查询协议（Pull-based）比标准推送指令（Push-based）更稳健，成功案例中的澄清请求频率是后者的两倍。

Conclusion: 研究表明，主动不确定性减少机制是安全的人机协作和机器人间协作的前提条件。

Abstract: Large Language Models (LLMs) act as powerful reasoning engines but struggle with "symbol grounding" in embodied environments, particularly when information is asymmetrically distributed. We investigate the Privileged Information Bias (or "Curse of Knowledge"), where a knowledgeable "Leader" agent fails to guide a sensor-limited "Follower" due to a lack of Theory of Mind. To quantify this phenomenon, we propose a novel Asymmetric Assistive Reasoning framework within AI2-THOR. Our experiments reveal a significant "Success Gap": while the Leader successfully perceives the target in 35.0% of episodes, the collaborative team succeeds only 17.0% of the time, implying that nearly 50% of feasible plans fail solely due to communicative grounding errors. We demonstrate that a "Pull-based" protocol (active querying) is significantly more robust than standard "Push-based" instruction, with successful episodes featuring 2x the frequency of clarification requests. This research isolates the mechanism of active uncertainty reduction as a prerequisite for safe human-AI and robot-robot collaboration.

</details>


### [136] [AI Epidemiology: achieving explainable AI through expert oversight patterns](https://arxiv.org/abs/2512.15783)
*Kit Tempest-Walters*

Main category: cs.AI

TL;DR: AI Epidemiology是一种通过标准化AI-专家交互并利用统计关联预测输出失败的框架，旨在绕过模型复杂性问题，使领域专家能够有效监督AI系统。


<details>
  <summary>Details</summary>
Motivation: 当前的可解释性方法（如SHAP和机制可解释性）在部署模型规模上面临模型复杂性的问题，AI Epidemiology旨在绕过这一问题，提供一种更高效的治理方式。

Method: 该框架通过将AI-专家交互标准化为结构化评估字段（风险等级、对齐分数和准确度分数），并利用统计关联预测输出失败，类似于流行病学中的暴露变量。

Result: AI Epidemiology通过被动跟踪专家与AI建议的趋同和分歧，提供了自动审计跟踪，并在模型更新和供应商切换时保持治理连续性。此外，它还通过可靠性评分和语义评估帮助专家和机构在AI输出造成危害前检测不可靠输出。

Conclusion: AI Epidemiology框架通过标准化AI-专家交互的捕获，提供了一种无需依赖模型内部复杂性的治理方法，使领域专家能够在不具备机器学习专业知识的情况下监督AI系统。

Abstract: AI Epidemiology is a framework for governing and explaining advanced AI systems by applying population-level surveillance methods to AI outputs. The approach mirrors the way in which epidemiologists enable public health interventions through statistical evidence before molecular mechanisms are understood. This bypasses the problem of model complexity which plagues current interpretability methods (such as SHAP and mechanistic interpretability) at the scale of deployed models.
  AI Epidemiology achieves this population-level surveillance by standardising capture of AI-expert interactions into structured assessment fields: risk level, alignment score, and accuracy score. These function as exposure variables which predict output failure through statistical associations, much like cholesterol and blood pressure act as exposure variables predicting cardiac events. Output-failure associations are subsequently validated against expert overrides and real-world outcomes.
  The framework places zero burden on experts and provides automatic audit trails by passively tracking expert convergence and divergence with AI recommendations. Since it analyses outputs rather than internal model computations, it also provides governance continuity when institutions update models and switch vendors. Finally, by providing reliability scores and semantic assessments (e.g. 'this recommendation resembles 500 cases overridden by experts due to guideline violations'), it enables experts and institutions to detect unreliable AI outputs before they cause harm. This democratises AI oversight by enabling domain experts to govern AI systems without requiring machine learning expertise.

</details>


### [137] [Beyond Training: Enabling Self-Evolution of Agents with MOBIMEM](https://arxiv.org/abs/2512.15784)
*Zibin Liu,Cheng Zhang,Xi Zhao,Yunfei Feng,Bingyu Bai,Dahu Feng,Erhu Feng,Yubin Xia,Haibo Chen*

Main category: cs.AI

TL;DR: MOBIMEM是一种内存中心的代理系统，通过专用内存和OS服务实现自进化，显著提升性能与效率。


<details>
  <summary>Details</summary>
Motivation: 当前以模型为中心的代理架构在部署后难以自我进化，需要持续的重训练/微调，计算开销大且存在准确性与效率的权衡。

Method: MOBIMEM引入三种专用内存原语（Profile Memory、Experience Memory、Action Memory）和操作系统启发的服务（调度器、AgentRR机制、上下文感知异常处理）来解耦代理进化与模型权重。

Result: 在AndroidWorld和top-50应用上的评估显示，MOBIMEM实现了83.1%的配置文件对齐、23.83毫秒的检索时间（比GraphRAG基线快280倍），任务成功率提升高达50.3%，端到端延迟降低高达9倍。

Conclusion: MOBIMEM通过内存中心的架构和操作系统启发的服务，实现了无需模型重训练的自进化，显著提升了代理的性能和效率。

Abstract: Large Language Model (LLM) agents are increasingly deployed to automate complex workflows in mobile and desktop environments. However, current model-centric agent architectures struggle to self-evolve post-deployment: improving personalization, capability, and efficiency typically requires continuous model retraining/fine-tuning, which incurs prohibitive computational overheads and suffers from an inherent trade-off between model accuracy and inference efficiency.
  To enable iterative self-evolution without model retraining, we propose MOBIMEM, a memory-centric agent system. MOBIMEM first introduces three specialized memory primitives to decouple agent evolution from model weights: (1) Profile Memory uses a lightweight distance-graph (DisGraph) structure to align with user preferences, resolving the accuracy-latency trade-off in user profile retrieval; (2) Experience Memory employs multi-level templates to instantiate execution logic for new tasks, ensuring capability generalization; and (3) Action Memory records fine-grained interaction sequences, reducing the reliance on expensive model inference. Building upon this memory architecture, MOBIMEM further integrates a suite of OS-inspired services to orchestrate execution: a scheduler that coordinates parallel sub-task execution and memory operations; an agent record-and-replay (AgentRR) mechanism that enables safe and efficient action reuse; and a context-aware exception handling that ensures graceful recovery from user interruptions and runtime errors.
  Evaluation on AndroidWorld and top-50 apps shows that MOBIMEM achieves 83.1% profile alignment with 23.83 ms retrieval time (280x faster than GraphRAG baselines), improves task success rates by up to 50.3%, and reduces end-to-end latency by up to 9x on mobile devices.

</details>


### [138] [State-Augmented Graphs for Circular Economy Triage](https://arxiv.org/abs/2512.15824)
*Richard Fox,Rui Li,Gustav Jonsson,Farzaneh Goli,Miying Yang,Emel Aktas,Yongjing Wang*

Main category: cs.AI

TL;DR: 论文提出了一种基于状态增强DSP图的决策框架，用于优化循环经济分类决策，并通过电动汽车电池示例验证了其通用性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 循环经济分类需要对产品进行适应性决策，以平衡保留价值与处理和劳动力成本及约束。现有方法缺乏统一的框架来处理不同产品和操作环境下的复杂性。

Method: 采用简单的确定性求解器，在状态增强的DSP图上进行决策，通过将拆卸历史编码到状态中，确保马尔可夫属性，实现最优递归评估。

Result: 通过电动汽车电池的分层分类示例，展示了框架的灵活性，能够适应不同的机械复杂性、安全要求和经济驱动因素。

Conclusion: 该论文提出了一个统一的决策框架，通过状态增强的拆卸序列规划（DSP）图，为循环经济（CE）分类决策提供了可扩展和通用的解决方案。

Abstract: Circular economy (CE) triage is the assessment of products to determine which sustainable pathway they can follow once they reach the end of their usefulness as they are currently being used. Effective CE triage requires adaptive decisions that balance retained value against the costs and constraints of processing and labour. This paper presents a novel decision-making framework as a simple deterministic solver over a state-augmented Disassembly Sequencing Planning (DSP) graph. By encoding the disassembly history into the state, our framework enforces the Markov property, enabling optimal, recursive evaluation by ensuring each decision only depends on the previous state. The triage decision involves choices between continuing disassembly or committing to a CE option. The model integrates condition-aware utility based on diagnostic health scores and complex operational constraints. We demonstrate the framework's flexibility with a worked example: the hierarchical triage of electric vehicle (EV) batteries, where decisions are driven by the recursive valuation of components. The example illustrates how a unified formalism enables the accommodation of varying mechanical complexity, safety requirements, and economic drivers. This unified formalism therefore provides a tractable and generalisable foundation for optimising CE triage decisions across diverse products and operational contexts.

</details>


### [139] [PediatricAnxietyBench: Evaluating Large Language Model Safety Under Parental Anxiety and Pressure in Pediatric Consultations](https://arxiv.org/abs/2512.15894)
*Vahideh Zolfaghari*

Main category: cs.AI

TL;DR: LLMs struggle with pediatric advice under adversarial pressures, especially urgent queries. The 70B model is safer than the 8B model, but both fail in critical areas like seizures. PediatricAnxietyBench helps identify these flaws.


<details>
  <summary>Details</summary>
Motivation: To understand the safety of LLMs in pediatric guidance under real-world adversarial pressures, as anxious parents' urgent language may compromise model safeguards and lead to harmful advice.

Method: The study assessed two Llama models (70B and 8B) using PediatricAnxietyBench, an open-source benchmark of 300 high-quality queries (150 patient-derived, 150 adversarial) across 10 pediatric topics. A multi-dimensional safety framework evaluated diagnostic restraint, referral adherence, hedging, and emergency recognition. Adversarial queries simulated parental pressure patterns (urgency, economic barriers, etc.).

Result: The mean safety score was 5.50/15 (SD=2.41). The 70B model outperformed the 8B model (6.26 vs 4.95, p<0.001) with fewer critical failures (4.8% vs 12.0%, p=0.02). Adversarial queries reduced safety by 8% (p=0.03), with urgency causing the largest drop (-1.40). Vulnerabilities were notable in seizures (33.3% inappropriate diagnosis) and post-vaccination queries. Hedging correlated strongly with safety (r=0.68, p<0.001), while emergency recognition was absent.

Conclusion: Large language models (LLMs) exhibit vulnerabilities under real-world adversarial pressures, especially in pediatric advice scenarios. The 70B model showed better safety performance than the 8B model, but all models demonstrated significant weaknesses, particularly in handling urgent queries and specific medical topics like seizures and post-vaccination issues. PediatricAnxietyBench offers a reusable framework for identifying clinically significant failure modes in LLMs.

Abstract: Large language models (LLMs) are increasingly consulted by parents for pediatric guidance, yet their safety under real-world adversarial pressures is poorly understood. Anxious parents often use urgent language that can compromise model safeguards, potentially causing harmful advice. PediatricAnxietyBench is an open-source benchmark of 300 high-quality queries across 10 pediatric topics (150 patient-derived, 150 adversarial) enabling reproducible evaluation. Two Llama models (70B and 8B) were assessed using a multi-dimensional safety framework covering diagnostic restraint, referral adherence, hedging, and emergency recognition. Adversarial queries incorporated parental pressure patterns, including urgency, economic barriers, and challenges to disclaimers. Mean safety score was 5.50/15 (SD=2.41). The 70B model outperformed the 8B model (6.26 vs 4.95, p<0.001) with lower critical failures (4.8% vs 12.0%, p=0.02). Adversarial queries reduced safety by 8% (p=0.03), with urgency causing the largest drop (-1.40). Vulnerabilities appeared in seizures (33.3% inappropriate diagnosis) and post-vaccination queries. Hedging strongly correlated with safety (r=0.68, p<0.001), while emergency recognition was absent. Model scale influences safety, yet all models showed vulnerabilities to realistic parental pressures. PediatricAnxietyBench provides a reusable adversarial evaluation framework to reveal clinically significant failure modes overlooked by standard benchmarks.

</details>


### [140] [Darth Vecdor: An Open-Source System for Generating Knowledge Graphs Through Large Language Model Queries](https://arxiv.org/abs/2512.15906)
*Jonathan A. Handler*

Main category: cs.AI

TL;DR: DV是一个开源工具，将LLM知识结构化到SQL数据库，旨在解决直接查询LLM的问题，尤其适用于医疗保健领域。


<details>
  <summary>Details</summary>
Motivation: 解决直接查询LLM时可能遇到的成本、速度、安全性和置信度问题，尤其是在高容量操作中。

Method: DV通过提取LLM知识到SQL数据库，并提供浏览器图形界面以简化使用。

Result: DV能够缓解LLM响应中的错误、离题、自由文本、过度泛化和不一致等问题，并支持多元素响应。

Conclusion: DV是一个开源工具，旨在通过结构化知识图谱解决LLM直接查询的潜在问题，尽管存在风险，但作者希望它能推动医疗保健领域的进步。

Abstract: Many large language models (LLMs) are trained on a massive body of knowledge present on the Internet. Darth Vecdor (DV) was designed to extract this knowledge into a structured, terminology-mapped, SQL database ("knowledge base" or "knowledge graph"). Knowledge graphs may be useful in many domains, including healthcare. Although one might query an LLM directly rather than a SQL-based knowledge graph, concerns such as cost, speed, safety, and confidence may arise, especially in high-volume operations. These may be mitigated when the information is pre-extracted from the LLM and becomes query-able through a standard database. However, the author found the need to address several issues. These included erroneous, off-topic, free-text, overly general, and inconsistent LLM responses, as well as allowing for multi-element responses. DV was built with features intended to mitigate these issues. To facilitate ease of use, and to allow for prompt engineering by those with domain expertise but little technical background, DV provides a simple, browser-based graphical user interface. DV has been released as free, open-source, extensible software, on an "as is" basis, without warranties or conditions of any kind, either express or implied. Users need to be cognizant of the potential risks and benefits of using DV and its outputs, and users are responsible for ensuring any use is safe and effective. DV should be assumed to have bugs, potentially very serious ones. However, the author hopes that appropriate use of current and future versions of DV and its outputs can help improve healthcare.

</details>


### [141] [Leveraging Spreading Activation for Improved Document Retrieval in Knowledge-Graph-Based RAG Systems](https://arxiv.org/abs/2512.15922)
*Jovan Pavlović,Miklós Krész,László Hajdu*

Main category: cs.AI

TL;DR: 提出基于扩散激活算法的新型RAG框架，通过自动构建知识图谱提升复杂任务表现，实验显示性能显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有RAG系统在复杂推理任务中难以可靠检索多步证据，且标准RAG框架忽视信息的可信度和关联性。GraphRAG虽能改进，但依赖高质量图谱或不可靠的自动化构建流程。

Method: 采用扩散激活算法从由自动构建知识图谱连接的文档库中检索信息，结合链式思维迭代检索。

Result: 实验表明，该方法在性能上优于或与迭代RAG方法相当，结合链式思维迭代检索时，答案正确率比朴素RAG提升39%。

Conclusion: 本文提出的新型RAG框架通过扩散激活算法和自动构建的知识图谱，显著提升了大型语言模型在复杂任务（如多跳问答）中的表现，且易于集成到多种RAG方法中。

Abstract: Despite initial successes and a variety of architectures, retrieval-augmented generation (RAG) systems still struggle to reliably retrieve and connect the multi-step evidence required for complicated reasoning tasks. Most of the standard RAG frameworks regard all retrieved information as equally reliable, overlooking the varying credibility and interconnected nature of large textual corpora. GraphRAG approaches offer potential improvement to RAG systems by integrating knowledge graphs, which structure information into nodes and edges, capture entity relationships, and enable multi-step logical traversal. However, GraphRAG is not always an ideal solution as it depends on high-quality graph representations of the corpus, which requires either pre-existing knowledge graphs that are expensive to build and update, or automated graph construction pipelines that are often unreliable. Moreover, systems following this paradigm typically use large language models to guide graph traversal and evidence retrieval, leading to challenges similar to those encountered with standard RAG. In this paper, we propose a novel RAG framework that employs the spreading activation algorithm to retrieve information from a corpus of documents interconnected by automatically constructed knowledge graphs, thereby enhancing the performance of large language models on complex tasks such as multi-hop question answering. Experiments show that our method achieves better or comparable performance to iterative RAG methodologies, while also being easily integrable as a plug-and-play module with a wide range of RAG-based approaches. Combining our method with chain-of-thought iterative retrieval yields up to a 39\% absolute gain in answer correctness compared to naive RAG, achieving these results with small open-weight language models and highlighting its effectiveness in resource-constrained settings.

</details>


### [142] [Small Language Models for Efficient Agentic Tool Calling: Outperforming Large Models with Targeted Fine-tuning](https://arxiv.org/abs/2512.15943)
*Polaris Jhandi,Owais Kazi,Shreyas Subramanian,Neel Sendas*

Main category: cs.AI

TL;DR: 研究表明，通过精心设计和针对性训练，SLMs可以在特定任务中媲美LLMs，同时大幅降低成本和基础设施需求。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI的广泛应用，模型成本优化和操作效率成为决定其可持续性和可访问性的关键因素。LLMs的高计算需求使其在企业常规使用中成本过高，因此探索SLMs成为必要。

Method: 本研究通过Hugging Face TRL（Transformer Reinforcement Learning）中的监督微调（SFT）训练器，对facebook/opt-350m模型进行了单周期的微调，以执行传统由LLM处理的任务。

Result: 实验结果表明，经过微调的SLM在ToolBench评估中取得了77.55%的通过率，显著优于所有基线模型。

Conclusion: 经过优化的SLM在特定任务中表现优异，显著降低了生成式AI的采用门槛，使其在生产系统中实现成本效益和大规模集成成为可能。

Abstract: As organizations scale adoption of generative AI, model cost optimization and operational efficiency have emerged as critical factors determining sustainability and accessibility. While Large Language Models (LLMs) demonstrate impressive capabilities across diverse tasks, their extensive computational requirements make them cost-prohibitive for routine enterprise use. This limitation motivates the exploration of Small Language Models (SLMs), which can deliver comparable performance in targeted applications while drastically reducing infrastructure overhead (Irugalbandara et al., 2023). In this work, we investigate the feasibility of replacing LLM-driven workflows with optimized SLMs. We trained a domain-adapted SLM to execute representative tasks traditionally handled by LLMs, such as document summarization, query answering, and structured data interpretation. As part of the experiment, we investigated the fine-tuning of facebook/opt-350m model (single epoch only) using the Hugging Face TRL (Transformer Reinforcement Learning), specifically the Supervised Fine-Tuning (SFT) trainer. The OPT-350M model was released by Meta AI in 2022 as part of the OPT (Open Pretrained Transformer) family of models. Similar studies demonstrate that even models at the 350M parameter scale can meaningfully contribute to instruction-tuning pipelines (Mekala et al., 2024). Experimental results demonstrated that our fine-tuned SLM achieves exceptional performance with a 77.55\% pass rate on ToolBench evaluation, significantly outperforming all baseline models including ChatGPT-CoT (26.00\%), ToolLLaMA-DFS (30.18\%), and ToolLLaMA-CoT (16.27\%). These findings emphasize that thoughtful design and targeted training of SLMs can significantly lower barriers to adoption, enabling cost-effective, large-scale integration of generative AI into production systems.

</details>


### [143] [ParamExplorer: A framework for exploring parameters in generative art](https://arxiv.org/abs/2512.16529)
*Julien Gachadoat,Guillaume Lagarde*

Main category: cs.AI

TL;DR: ParamExplorer是一个交互式模块化框架，利用强化学习帮助探索生成艺术算法的参数空间，支持人工或自动化反馈，并评估了多种代理策略。


<details>
  <summary>Details</summary>
Motivation: 生成艺术系统的高维复杂参数空间中，美学上有吸引力的输出仅占很小且分散的区域，传统手动试错方法效率低下且易遗漏潜在有趣配置。

Method: 引入了ParamExplorer框架，该框架采用强化学习思想，支持交互式和模块化设计，允许人工或自动化反馈指导参数空间探索，并与现有p5.js项目无缝集成。

Result: 实现了多种探索策略（代理），并在框架内进行了评估，验证了其有效性。

Conclusion: ParamExplorer框架通过交互式和模块化的方式，结合强化学习思想，有效解决了生成艺术系统中参数空间探索的难题，并通过多种代理策略验证了其效果。

Abstract: Generative art systems often involve high-dimensional and complex parameter spaces in which aesthetically compelling outputs occupy only small, fragmented regions. Because of this combinatorial explosion, artists typically rely on extensive manual trial-and-error, leaving many potentially interesting configurations undiscovered. In this work we make two contributions. First, we introduce ParamExplorer, an interactive and modular framework inspired by reinforcement learning that helps the exploration of parameter spaces in generative art algorithms, guided by human-in-the-loop or even automated feedback. The framework also integrates seamlessly with existing p5.js projects. Second, within this framework we implement and evaluate several exploration strategies, referred to as agents.

</details>


### [144] [Subjective functions](https://arxiv.org/abs/2512.15948)
*Samuel J. Gershman*

Main category: cs.AI

TL;DR: 论文探讨了目标函数的来源，提出主观函数概念，并以预期预测误差为例验证其可行性。


<details>
  <summary>Details</summary>
Motivation: 探讨人类智能如何动态合成新目标函数，并尝试赋予人工系统相同能力。

Method: 通过引入主观函数的概念，并研究预期预测误差作为具体实例，探讨智能体内生目标函数的机制。

Result: 提出了主观函数的概念，并验证了预期预测误差作为主观函数的可行性，为理解目标函数的来源提供了新视角。

Conclusion: 该论文提出了一种新的主观函数概念，作为理解智能体如何内生地合成目标函数的基础，并通过预期预测误差这一具体例子进行了验证。

Abstract: Where do objective functions come from? How do we select what goals to pursue? Human intelligence is adept at synthesizing new objective functions on the fly. How does this work, and can we endow artificial systems with the same ability? This paper proposes an approach to answering these questions, starting with the concept of a subjective function, a higher-order objective function that is endogenous to the agent (i.e., defined with respect to the agent's features, rather than an external task). Expected prediction error is studied as a concrete example of a subjective function. This proposal has many connections to ideas in psychology, neuroscience, and machine learning.

</details>


### [145] [Conversational Time Series Foundation Models: Towards Explainable and Effective Forecasting](https://arxiv.org/abs/2512.16022)
*Defu Cao,Michael Gee,Jinbo Liu,Hengxuan Wang,Wei Yang,Rui Wang,Yan Liu*

Main category: cs.AI

TL;DR: 利用LLM作为智能评估者协调时间序列模型集成，通过微调和多轮对话优化预测性能，实现新SOTA。


<details>
  <summary>Details</summary>
Motivation: 时间序列基础模型的多样性导致单一方法无法持续优越，需要通过可解释的集成方法实现最优协调。

Method: 采用R1风格的微调过程，结合基于SHAP的忠实度评分，训练LLM解释集成权重作为时间动态的有意义因果陈述，并通过多轮对话迭代优化策略。

Result: 在GIFT-Eval基准测试中，该方法在23个数据集的97种设置下显著优于领先的时间序列基础模型，CRPS和MASE指标均达到新最优。

Conclusion: 该论文提出了一种通过重新定位大型语言模型（LLM）作为智能评估者来优化时间序列基础模型集成的方法，显著提升了预测性能并实现了新的最先进结果。

Abstract: The proliferation of time series foundation models has created a landscape where no single method achieves consistent superiority, framing the central challenge not as finding the best model, but as orchestrating an optimal ensemble with interpretability. While Large Language Models (LLMs) offer powerful reasoning capabilities, their direct application to time series forecasting has proven ineffective. We address this gap by repositioning the LLM as an intelligent judge that evaluates, explains, and strategically coordinates an ensemble of foundation models. To overcome the LLM's inherent lack of domain-specific knowledge on time series, we introduce an R1-style finetuning process, guided by SHAP-based faithfulness scores, which teaches the model to interpret ensemble weights as meaningful causal statements about temporal dynamics. The trained agent then engages in iterative, multi-turn conversations to perform forward-looking assessments, provide causally-grounded explanations for its weighting decisions, and adaptively refine the optimization strategy. Validated on the GIFT-Eval benchmark on 23 datasets across 97 settings, our approach significantly outperforms leading time series foundation models on both CRPS and MASE metrics, establishing new state-of-the-art results.

</details>


### [146] [Do Large Language Models Know What They Don't Know? Kalshibench: A New Benchmark for Evaluating Epistemic Calibration via Prediction Markets](https://arxiv.org/abs/2512.16030)
*Lukas Nel*

Main category: cs.AI

TL;DR: 研究发现LLMs在预测未来事件时普遍过度自信，校准误差显著，扩展规模和推理能力未改善校准，需针对性开发。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型在多样任务中表现卓越，但其认知校准能力仍未被充分理解。研究旨在评估模型是否能对真正未知的未来事件适当量化不确定性。

Method: 研究团队引入了KalshiBench，一个包含300个预测市场问题的基准，这些问题来自CFTC监管的交易所Kalshi，且结果在模型训练截止后实际发生。评估了五个前沿模型（Claude Opus 4.5、GPT-5.2、DeepSeek-V3.2、Qwen3-235B和Kimi-K2）的校准性能。

Result: 所有模型均表现出系统性过度自信。最佳校准模型（Claude Opus 4.5）的ECE为0.120，而推理增强模型（如GPT-5.2-XHigh）校准更差（ECE=0.395）。仅一个模型获得正Brier Skill Score，表明多数模型表现不如简单预测基准率。

Conclusion: 研究发现，大型语言模型在预测未知未来事件时普遍存在系统性过度自信问题，即使是最优校准模型（Claude Opus 4.5）也存在显著校准误差。扩展模型规模和增强推理能力并未自动改善校准性能，表明认知校准是一项需要针对性开发的独立能力。

Abstract: A well-calibrated model should express confidence that matches its actual accuracy -- when it claims 80\% confidence, it should be correct 80\% of the time. While large language models (LLMs) have achieved remarkable performance across diverse tasks, their epistemic calibration remains poorly understood. We introduce \textbf{KalshiBench}, a benchmark of 300 prediction market questions from Kalshi, a CFTC-regulated exchange, with verifiable real-world outcomes occurring after model training cutoffs. Unlike traditional benchmarks measuring accuracy on static knowledge, KalshiBench evaluates whether models can appropriately quantify uncertainty about genuinely unknown future events. We evaluate five frontier models -- Claude Opus 4.5, GPT-5.2, DeepSeek-V3.2, Qwen3-235B, and Kimi-K2 -- and find \textbf{systematic overconfidence across all models}. Even the best-calibrated model (Claude Opus 4.5, ECE=0.120) shows substantial calibration errors, while reasoning-enhanced models like GPT-5.2-XHigh exhibit \emph{worse} calibration (ECE=0.395) despite comparable accuracy. Critically, only one model achieves a positive Brier Skill Score, indicating most models perform worse than simply predicting base rates. Our findings suggest that scaling and enhanced reasoning do not automatically confer calibration benefits, highlighting epistemic calibration as a distinct capability requiring targeted development.

</details>


### [147] [Topic Discovery and Classification for Responsible Generative AI Adaptation in Higher Education](https://arxiv.org/abs/2512.16036)
*Diane Myung-kyung Woodbridge,Allyson Seba,Freddie Seba,Aydin Schwartz*

Main category: cs.AI

TL;DR: 研究开发了一个自动化系统，用于发现和分类课程大纲中的AI政策，结合主题建模和LLMs，提高了政策信息的结构化和可解释性。


<details>
  <summary>Details</summary>
Motivation: 随着生成式人工智能（GenAI）在教育中的广泛应用，学生对其使用的不确定性增加，需要一种系统化的方法来发现和分类AI相关政策。

Method: 结合无监督主题建模技术识别关键政策主题，并利用大型语言模型（LLMs）对政策文本中的GenAI允许程度和其他要求进行分类。

Result: 开发的应用程序在主题发现上获得了0.73的一致性分数，GPT-4.0基于政策分类的精确度在0.92至0.97之间，召回率在0.85至0.97之间。

Conclusion: 该工具通过提供结构化和可解释的政策信息，促进了生成式人工智能（GenAI）在教育中的安全、公平和教学对齐的使用。

Abstract: As generative artificial intelligence (GenAI) becomes increasingly capable of delivering personalized learning experiences and real-time feedback, a growing number of students are incorporating these tools into their academic workflows. They use GenAI to clarify concepts, solve complex problems, and, in some cases, complete assignments by copying and pasting model-generated contents. While GenAI has the potential to enhance learning experience, it also raises concerns around misinformation, hallucinated outputs, and its potential to undermine critical thinking and problem-solving skills. In response, many universities, colleges, departments, and instructors have begun to develop and adopt policies to guide responsible integration of GenAI into learning environments. However, these policies vary widely across institutions and contexts, and their evolving nature often leaves students uncertain about expectations and best practices. To address this challenge, the authors designed and implemented an automated system for discovering and categorizing AI-related policies found in course syllabi and institutional policy websites. The system combines unsupervised topic modeling techniques to identify key policy themes with large language models (LLMs) to classify the level of GenAI allowance and other requirements in policy texts. The developed application achieved a coherence score of 0.73 for topic discovery. In addition, GPT-4.0-based classification of policy categories achieved precision between 0.92 and 0.97, and recall between 0.85 and 0.97 across eight identified topics. By providing structured and interpretable policy information, this tool promotes the safe, equitable, and pedagogically aligned use of GenAI technologies in education. Furthermore, the system can be integrated into educational technology platforms to help students understand and comply with relevant guidelines.

</details>


### [148] [WeMusic-Agent: Efficient Conversational Music Recommendation via Knowledge Internalization and Agentic Boundary Learning](https://arxiv.org/abs/2512.16108)
*Wendong Bi,Yirong Mao,Xianglong Liu,Kai Tian,Jian Zhang,Hanjie Wang,Wenhui Que*

Main category: cs.AI

TL;DR: WeMusic-Agent框架通过知识内化和工具调用优化对话式音乐推荐，实验显示其优于现有方法，并提供了开源基准测试。


<details>
  <summary>Details</summary>
Motivation: 现有方法在平衡专业领域知识和灵活工具集成方面存在不足，需要更高效的对话式音乐推荐解决方案。

Method: 提出WeMusic-Agent训练框架，结合知识内化和代理边界学习，开发了WeMusic-Agent-M1模型，通过50B音乐相关语料库持续预训练，并支持调用外部工具。

Result: 在真实数据实验中，WeMusic-Agent表现优于现有模型，并构建了开源基准测试以支持多维度评估。

Conclusion: WeMusic-Agent框架通过结合知识内化和工具调用能力，显著提升了对话式音乐推荐的性能，并在真实数据实验中优于现有模型。

Abstract: Personalized music recommendation in conversational scenarios usually requires a deep understanding of user preferences and nuanced musical context, yet existing methods often struggle with balancing specialized domain knowledge and flexible tool integration. This paper proposes WeMusic-Agent, a training framework for efficient LLM-based conversational music recommendation. By integrating the knowledge internalization and agentic boundary learning, the framework aims to teach the model to intelligently decide when to leverage internalized knowledge and when to call specialized tools (e.g., music retrieval APIs, music recommendation systems). Under this framework, we present WeMusic-Agent-M1, an agentic model that internalizes extensive musical knowledge via continued pretraining on 50B music-related corpus while acquiring the ability to invoke external tools when necessary. Additionally, considering the lack of open-source benchmarks for conversational music recommendation, we also construct a benchmark for personalized music recommendations derived from real-world data in WeChat Listen. This benchmark enables comprehensive evaluation across multiple dimensions, including relevance, personalization, and diversity of the recommendations. Experiments on real-world data demonstrate that WeMusic-Agent achieves significant improvements over existing models.

</details>


### [149] [ToolForge: A Data Synthesis Pipeline for Multi-Hop Search without Real-World APIs](https://arxiv.org/abs/2512.16149)
*Hao Chen,Zhexin Hu,Jiajun Chai,Haocheng Yang,Hang He,Xiaohan Wang,Wei Lin,Luhang Wang,Guojun Yin,Zhuofeng zhao*

Main category: cs.AI

TL;DR: ToolForge是一个低成本、高效的自动化合成框架，通过虚拟工具生成高质量数据，显著提升模型在多跳搜索场景中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有合成数据生成方法依赖大量真实API调用，成本高昂且缺乏多跳推理和自反思能力。

Method: 采用自动化合成框架ToolForge，结合多跳推理和自反思机制生成工具学习数据，并通过多层验证框架确保数据保真度。

Result: 仅8B参数的模型在合成数据训练后，在多个基准测试中优于GPT-4o。

Conclusion: ToolForge框架通过少量虚拟工具生成高质量合成数据，显著降低了成本，并在多跳搜索场景中表现出色，甚至超越了GPT-4o的性能。

Abstract: Training LLMs to invoke tools and leverage retrieved information necessitates high-quality, diverse data. However, existing pipelines for synthetic data generation often rely on tens of thousands of real API calls to enhance generalization, incurring prohibitive costs while lacking multi-hop reasoning and self-reflection. To address these limitations, we introduce ToolForge, an automated synthesis framework that achieves strong real-world tool-calling performance by constructing only a small number of virtual tools, eliminating the need for real API calls. ToolForge leverages a (question, golden context, answer) triple to synthesize large-scale tool-learning data specifically designed for multi-hop search scenarios, further enriching the generated data through multi-hop reasoning and self-reflection mechanisms. To ensure data fidelity, we employ a Multi-Layer Validation Framework that integrates both rule-based and model-based assessments. Empirical results show that a model with only 8B parameters, when trained on our synthesized data, outperforms GPT-4o on multiple benchmarks. Our code and dataset are publicly available at https://github.com/Buycar-arb/ToolForge .

</details>


### [150] [Science Consultant Agent](https://arxiv.org/abs/2512.16171)
*Karthikeyan K,Philip Wu,Xin Tang,Alexandre Alves*

Main category: cs.AI

TL;DR: Science Consultant Agent是一款基于AI的网页工具，通过问卷、智能填充、研究推荐和原型构建四大组件，帮助从业者高效选择和实施AI建模策略。


<details>
  <summary>Details</summary>
Motivation: 旨在帮助从业者选择和实施最有效的AI建模策略，提升开发效率。

Method: 该工具结合结构化问卷、文献支持的解决方案推荐和原型生成，通过四个核心组件（问卷、智能填充、研究引导推荐、原型构建）实现。

Result: Science Consultant Agent成功整合了多种功能，加速了AI解决方案的开发流程。

Conclusion: Science Consultant Agent通过整合问卷、智能填充、研究引导推荐和原型构建四大核心组件，为AI解决方案的建模策略选择和实施提供了高效支持，加速了从产品经理到研究人员的开发流程。

Abstract: The Science Consultant Agent is a web-based Artificial Intelligence (AI) tool that helps practitioners select and implement the most effective modeling strategy for AI-based solutions. It operates through four core components: Questionnaire, Smart Fill, Research-Guided Recommendation, and Prototype Builder. By combining structured questionnaires, literature-backed solution recommendations, and prototype generation, the Science Consultant Agent accelerates development for everyone from Product Managers and Software Developers to Researchers. The full pipeline is illustrated in Figure 1.

</details>


### [151] [Weighted K-Harmonic Means Clustering: Convergence Analysis and Applications to Wireless Communications](https://arxiv.org/abs/2512.16185)
*Gourab Ghatak*

Main category: cs.AI

TL;DR: WKHM是一种新型聚类算法，适用于无线网络，通过逆距离加权实现软分配，并在信号强度与负载公平性上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决经典K均值和约束K均值在无线网络中的局限性，设计一种具有直接解释性的聚类算法。

Method: 提出了加权K调和均值（WKHM）聚类算法，通过逆距离加权实现软分配，并确保数值稳定性。

Result: 在确定性和随机设置下建立了严格的收敛保证，并通过仿真验证了WKHM在信号强度和负载公平性上的优越性。

Conclusion: WKHM算法在无线网络中实现了信号强度与负载公平性的优越权衡，为联合无线节点放置和用户关联提供了理论工具。

Abstract: We propose the \emph{weighted K-harmonic means} (WKHM) clustering algorithm, a regularized variant of K-harmonic means designed to ensure numerical stability while enabling soft assignments through inverse-distance weighting. Unlike classical K-means and constrained K-means, WKHM admits a direct interpretation in wireless networks: its weights are exactly equivalent to fractional user association based on received signal strength. We establish rigorous convergence guarantees under both deterministic and stochastic settings, addressing key technical challenges arising from non-convexity and random initialization. Specifically, we prove monotone descent to a local minimum under fixed initialization, convergence in probability under Binomial Point Process (BPP) initialization, and almost sure convergence under mild decay conditions. These results provide the first stochastic convergence guarantees for harmonic-mean-based clustering. Finally, through extensive simulations with diverse user distributions, we show that WKHM achieves a superior tradeoff between minimum signal strength and load fairness compared to classical and modern clustering baselines, making it a principled tool for joint radio node placement and user association in wireless networks.

</details>


### [152] [PDE-Agent: A toolchain-augmented multi-agent framework for PDE solving](https://arxiv.org/abs/2512.16214)
*Jianming Liu,Ren Zhu,Jian Xu,Kun Ding,Xu-Yao Zhang,Gaofeng Meng,Cheng-Lin Liu*

Main category: cs.AI

TL;DR: PDE-Agent是一个基于LLM驱动的多代理协作框架，通过创新工具链和动态规划机制，实现了从自然语言描述的自动化PDE求解。


<details>
  <summary>Details</summary>
Motivation: 传统PDE求解方法依赖专家知识且缺乏完全自主性，现有神经网络解决方案如PINNs和DeepXDE仍存在局限性。

Method: 提出了PDE-Agent框架，包括Prog-Act框架（带有图记忆的多代理协作）和Resource-Pool（集成工具参数分离机制的多工具协作）。

Result: 通过PDE-Bench评估，PDE-Agent在复杂多步骤任务中表现出色，验证了其优越的适用性和性能。

Conclusion: PDE-Agent通过多代理和多工具协作的创新框架，展示了在复杂多步骤任务中的优越适用性和性能，为自动化科学计算的未来发展提供了新范式。

Abstract: Solving Partial Differential Equations (PDEs) is a cornerstone of engineering and scientific research. Traditional methods for PDE solving are cumbersome, relying on manual setup and domain expertise. While Physics-Informed Neural Network (PINNs) introduced end-to-end neural network-based solutions, and frameworks like DeepXDE further enhanced automation, these approaches still depend on expert knowledge and lack full autonomy. In this work, we frame PDE solving as tool invocation via LLM-driven agents and introduce PDE-Agent, the first toolchain-augmented multi-agent collaboration framework, inheriting the reasoning capacity of LLMs and the controllability of external tools and enabling automated PDE solving from natural language descriptions. PDE-Agent leverages the strengths of multi-agent and multi-tool collaboration through two key innovations: (1) A Prog-Act framework with graph memory for multi-agent collaboration, which enables effective dynamic planning and error correction via dual-loop mechanisms (localized fixes and global revisions). (2) A Resource-Pool integrated with a tool-parameter separation mechanism for multi-tool collaboration. This centralizes the management of runtime artifacts and resolves inter-tool dependency gaps in existing frameworks. To validate and evaluate this new paradigm for PDE solving , we develop PDE-Bench, a multi-type PDE Benchmark for agent-based tool collaborative solving, and propose multi-level metrics for assessing tool coordination. Evaluations verify that PDE-Agent exhibits superior applicability and performance in complex multi-step, cross-step dependent tasks. This new paradigm of toolchain-augmented multi-agent PDE solving will further advance future developments in automated scientific computing. Our source code and dataset will be made publicly available.

</details>


### [153] [Scaling Spatial Reasoning in MLLMs through Programmatic Data Synthesis](https://arxiv.org/abs/2512.16237)
*Zhi Helu,Huang Jingjing,Xu Wang,Xu Yangbin,Zhang Wanyue,Jiang Baoyang,Deng Shirui,Zhu Liang,Li Fangfang,Zhao Tiejun,Lin Yankai,Yao Yuan*

Main category: cs.AI

TL;DR: SPRITE通过模拟器和LLMs生成高质量空间推理数据，显著提升视觉语言模型的性能，解决了传统方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在空间理解和推理能力上存在局限，传统模板数据集和人工标注方法各有不足，亟需一种既能保证多样性又能确保计算精度的数据生成方法。

Method: SPRITE将真实数据生成重构为代码生成任务，利用大型语言模型（LLMs）将复杂空间问题编译为可执行程序，并通过模拟器提取的高精度场景元信息进行验证。

Result: SPRITE生成了一个包含3个模拟器、11k+场景和300k+图像/视频指令调优对的数据集，训练后的视觉语言模型在多个空间基准测试中表现优异，且优于同等规模的其他开源数据集。

Conclusion: SPRITE框架通过结合模拟器和大型模型，成功生成了可扩展、多样且高质量的空间推理数据，显著提升了视觉语言模型在空间理解任务上的性能。

Abstract: Embodied intelligence, a grand challenge in artificial intelligence, is fundamentally constrained by the limited spatial understanding and reasoning capabilities of current models. Prevailing efforts to address this through enhancing Vision-Language Models (VLMs) are trapped in a dilemma: template-based datasets are scalable but structurally rigid, while manual annotation is linguistically diverse but unscalable and, critically, computationally imprecise. We introduce SPRITE, a novel framework that overcomes this dilemma by leveraging simulators and large models to programmatically synthesize scalable, diverse, and high-quality spatial reasoning data. The core innovation of SPRITE is to reframe ground-truth generation as a code-generation task. We utilize LLMs to compile complex spatial questions into executable programs, which are then verified against high-precision scene meta-information extracted from simulators. This ensures our ground truth is both computationally precise and verifiable, while the generative power of LLMs provides vast linguistic diversity. Leveraging this pipeline, we have curated a dataset encompassing 3 simulators, 11k+ scenes, and 300k+ image/video instruction-tuning pairs. We demonstrate that a VLM trained on our data achieves significant performance gains on multiple spatial benchmarks and outperforms other open-source datasets of equivalent size. Furthermore, a scalability analysis confirms our hypothesis that overcoming the low-diversity nature of traditional template methods is essential for building robust, generalizable spatial intelligence. We will make the SPRITE framework code and the full 300k+ dataset publicly available to facilitate future research in spatial intelligence.

</details>


### [154] [AlignMerge - Alignment-Preserving Large Language Model Merging via Fisher-Guided Geometric Constraints](https://arxiv.org/abs/2512.16245)
*Aniruddha Roy,Jyoti Patel,Aman Chadha,Vinija Jain,Amitava Das*

Main category: cs.AI

TL;DR: AlignMerge是一种几何感知的合并框架，通过优化几何和对齐损失，显著提升合并模型的对齐性，同时保持任务性能。


<details>
  <summary>Details</summary>
Motivation: 标准合并方案可能破坏模型的对齐性，因此需要一种几何约束的合并方法，确保对齐性成为显式不变性。

Method: AlignMerge是一个几何感知的合并框架，通过局部Fisher图估计对齐子空间，并优化包含几何保持、对齐惩罚和软对齐预算的损失函数。

Result: 在五个模型家族上的实验表明，AlignMerge在保持任务性能的同时，显著提升了对齐性指标（如AQI、毒性、LLM-judge对齐），且对齐子空间漂移和预算违规更少。

Conclusion: AlignMerge框架通过几何约束的合并操作，显著提升了模型在合并后的对齐性表现，同时保持了任务性能，为未来基础模型的几何感知组合提供了路径。

Abstract: Merging large language models (LLMs) is a practical way to compose capabilities from multiple fine-tuned checkpoints without retraining. Yet standard schemes (linear weight soups, task vectors, and Fisher-weighted averaging) can preserve loss while quietly destroying alignment. We argue that merging is not a numerical trick but a geometry-constrained operation around an already-aligned anchor: fusion must be steered to respect safety geometry, not validated post hoc.
  We introduce AlignMerge, a geometry-aware merging framework that makes alignment an explicit invariant. In a local Fisher chart around an instruction-tuned base, we estimate an alignment subspace with projector P_A and optimize:
  L_AlignMerge = L_geo + lambda_align * L_align + lambda_bud * L_bud,
  where L_geo keeps the merge close to its experts in Fisher-Rao geometry, L_align penalizes motion along alignment-sensitive directions, and L_bud enforces a soft alignment budget. As the alignment functional we use the decoding-invariant Alignment Quality Index (AQI), a latent-space criterion that captures how cleanly aligned and misaligned behaviors separate in representation space.
  Across five model families (LLaMA-3 8B, Mistral 7B, Qwen 2, Phi-3.5, Gemma 2), merging safety anchors with task experts, AlignMerge improves alignment metrics (AQI, toxicity, LLM-judge alignment) while matching or exceeding the best expert on instruction-following, reasoning, and helpfulness. It also exhibits smaller alignment-subspace drift and fewer budget violations than Fisher soups, TIES, SafeMerge, and MergeAlign. These results make alignment-preserving merging a first-class design goal and suggest a path to geometry-aware composition of future foundation models.

</details>


### [155] [AMUSE: Audio-Visual Benchmark and Alignment Framework for Agentic Multi-Speaker Understanding](https://arxiv.org/abs/2512.16250)
*Sanjoy Chowdhury,Karren D. Yang,Xudong Liu,Fartash Faghri,Pavan Kumar Anasosalu Vasu,Oncel Tuzel,Dinesh Manocha,Chun-Liang Li,Raviteja Vemulapalli*

Main category: cs.AI

TL;DR: AMUSE基准和RAFT框架旨在提升多模态大语言模型在多说话者场景中的代理推理能力，实验显示显著效果。


<details>
  <summary>Details</summary>
Motivation: 当前多模态大语言模型在多说话者、对话中心场景中表现不佳，需要代理推理能力来跟踪说话者、维持角色并跨时间基础事件。

Method: 提出了AMUSE基准和RAFT框架，后者结合奖励优化与内在多模态自我评估作为奖励，以及选择性参数适应。

Result: 使用RAFT框架在基准测试中实现了高达39.52%的相对准确率提升。

Conclusion: AMUSE和RAFT为多模态模型中的代理推理提供了一个实用平台，显著提升了模型在多说话者场景中的表现。

Abstract: Recent multimodal large language models (MLLMs) such as GPT-4o and Qwen3-Omni show strong perception but struggle in multi-speaker, dialogue-centric settings that demand agentic reasoning tracking who speaks, maintaining roles, and grounding events across time. These scenarios are central to multimodal audio-video understanding, where models must jointly reason over audio and visual streams in applications such as conversational video assistants and meeting analytics. We introduce AMUSE, a benchmark designed around tasks that are inherently agentic, requiring models to decompose complex audio-visual interactions into planning, grounding, and reflection steps. It evaluates MLLMs across three modes zero-shot, guided, and agentic and six task families, including spatio-temporal speaker grounding and multimodal dialogue summarization. Across all modes, current models exhibit weak multi-speaker reasoning and inconsistent behavior under both non-agentic and agentic evaluation. Motivated by the inherently agentic nature of these tasks and recent advances in LLM agents, we propose RAFT, a data-efficient agentic alignment framework that integrates reward optimization with intrinsic multimodal self-evaluation as reward and selective parameter adaptation for data and parameter efficient updates. Using RAFT, we achieve up to 39.52\% relative improvement in accuracy on our benchmark. Together, AMUSE and RAFT provide a practical platform for examining agentic reasoning in multimodal models and improving their capabilities.

</details>


### [156] [Learning to Wait: Synchronizing Agents with the Physical World](https://arxiv.org/abs/2512.16262)
*Yifei She,Ping Zhang,He Liu,Yanmin Jia,Yang Jing,Zijun Liu,Peng Sun,Xiangbin Li,Xiaohe Hu*

Main category: cs.AI

TL;DR: 本文提出了一种代理侧方法，使LLM能够主动对齐其认知时间线与物理世界，通过预测等待时间与异步环境同步，实验验证了时间感知能力的可学习性。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的代理任务通常涉及具有可变延迟的非阻塞动作，这导致了动作启动和完成之间的时间差距。现有的环境侧解决方案（如阻塞包装器或频繁轮询）要么限制了可扩展性，要么用冗余观察稀释了代理的上下文窗口。

Method: 通过将Code-as-Action范式扩展到时间领域，代理利用语义先验和上下文学习（ICL）预测精确的等待时间（time.sleep(t)），从而在不进行详尽检查的情况下与异步环境同步。

Result: 在模拟Kubernetes集群中的实验表明，代理能够精确校准其内部时钟，以最小化查询开销和执行延迟。

Conclusion: 时间感知能力是可学习的，对于在开放环境中自主进化的代理至关重要。

Abstract: Real-world agentic tasks, unlike synchronous Markov Decision Processes (MDPs), often involve non-blocking actions with variable latencies, creating a fundamental \textit{Temporal Gap} between action initiation and completion. Existing environment-side solutions, such as blocking wrappers or frequent polling, either limit scalability or dilute the agent's context window with redundant observations. In this work, we propose an \textbf{Agent-side Approach} that empowers Large Language Models (LLMs) to actively align their \textit{Cognitive Timeline} with the physical world. By extending the Code-as-Action paradigm to the temporal domain, agents utilize semantic priors and In-Context Learning (ICL) to predict precise waiting durations (\texttt{time.sleep(t)}), effectively synchronizing with asynchronous environment without exhaustive checking. Experiments in a simulated Kubernetes cluster demonstrate that agents can precisely calibrate their internal clocks to minimize both query overhead and execution latency, validating that temporal awareness is a learnable capability essential for autonomous evolution in open-ended environments.

</details>


### [157] [QuadSentinel: Sequent Safety for Machine-Checkable Control in Multi-agent Systems](https://arxiv.org/abs/2512.16279)
*Yiliu Yang,Yilei Jiang,Qunzhong Wang,Yingshui Tan,Xiaoyong Zhu,Sherman S. M. Chow,Bo Zheng,Xiangyu Yue*

Main category: cs.AI

TL;DR: QuadSentinel是一个四代理防护系统，用于将自然语言安全策略编译为机器可检查规则，并在运行时执行，以提高安全控制的准确性和减少误报。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型代理在解决复杂任务时存在安全风险，而部署者编写的自然语言策略模糊且依赖上下文，难以映射到机器可检查规则，运行时执行也不可靠。

Method: 通过将安全策略表示为序列，QuadSentinel采用四个代理（状态跟踪器、策略验证器、威胁观察者和裁判）来编译和执行这些策略。裁判逻辑和高效的top-k谓词更新器通过优先级检查和分层解决冲突来降低成本。

Result: 在ST-WebAgentBench和AgentHarm上的测试显示，QuadSentinel提高了防护准确性和规则召回率，同时减少了误报，优于单代理基线如ShieldAgent。

Conclusion: QuadSentinel提供了一种无需修改核心代理即可实现高效安全控制的模式，适用于近期部署。

Abstract: Safety risks arise as large language model-based agents solve complex tasks with tools, multi-step plans, and inter-agent messages. However, deployer-written policies in natural language are ambiguous and context dependent, so they map poorly to machine-checkable rules, and runtime enforcement is unreliable. Expressing safety policies as sequents, we propose \textsc{QuadSentinel}, a four-agent guard (state tracker, policy verifier, threat watcher, and referee) that compiles these policies into machine-checkable rules built from predicates over observable state and enforces them online. Referee logic plus an efficient top-$k$ predicate updater keeps costs low by prioritizing checks and resolving conflicts hierarchically. Measured on ST-WebAgentBench (ICML CUA~'25) and AgentHarm (ICLR~'25), \textsc{QuadSentinel} improves guardrail accuracy and rule recall while reducing false positives. Against single-agent baselines such as ShieldAgent (ICML~'25), it yields better overall safety control. Near-term deployments can adopt this pattern without modifying core agents by keeping policies separate and machine-checkable. Our code will be made publicly available at https://github.com/yyiliu/QuadSentinel.

</details>


### [158] [OS-Oracle: A Comprehensive Framework for Cross-Platform GUI Critic Models](https://arxiv.org/abs/2512.16295)
*Zhenyu Wu,Jingjing Xie,Zehao Li,Bowen Yang,Qiushi Sun,Zhaoyang Liu,Zhoumianze Liu,Yu Qiao,Xiangyu Yue,Zun Wang,Zichen Ding*

Main category: cs.AI

TL;DR: OS-Oracle通过合成GUI批评数据和建立基准，提升了VLM在GUI导航中的步骤级决策能力。


<details>
  <summary>Details</summary>
Motivation: 解决GUI导航和操作中可靠的步骤级决策问题，以及缺乏高质量GUI反馈数据和公共批评基准的挑战。

Method: 提出了一个可扩展的数据管道用于合成跨平台GUI批评数据，采用两阶段训练范式结合监督微调（SFT）和一致性保持组相对策略优化（CP-GRPO），并建立了OS-Critic Bench基准。

Result: 构建了包含310k批评样本的高质量数据集，OS-Oracle-7B在多个平台上表现优异，并提升了GUI代理的性能。

Conclusion: OS-Oracle-7B在OS-Critic Bench上实现了开源VLM中的最先进性能，并在移动领域超越了专有模型。此外，作为预批评模型，它还提升了原生GUI代理的性能。

Abstract: With VLM-powered computer-using agents (CUAs) becoming increasingly capable at graphical user interface (GUI) navigation and manipulation, reliable step-level decision-making has emerged as a key bottleneck for real-world deployment. In long-horizon workflows, errors accumulate quickly and irreversible actions can cause unintended consequences, motivating critic models that assess each action before execution. While critic models offer a promising solution, their effectiveness is hindered by the lack of diverse, high-quality GUI feedback data and public critic benchmarks for step-level evaluation in computer use. To bridge these gaps, we introduce OS-Oracle that makes three core contributions: (1) a scalable data pipeline for synthesizing cross-platform GUI critic data; (2) a two-stage training paradigm combining supervised fine-tuning (SFT) and consistency-preserving group relative policy optimization (CP-GRPO); (3) OS-Critic Bench, a holistic benchmark for evaluating critic model performance across Mobile, Web, and Desktop platforms. Leveraging this framework, we curate a high-quality dataset containing 310k critic samples. The resulting critic model, OS-Oracle-7B, achieves state-of-the-art performance among open-source VLMs on OS-Critic Bench, and surpasses proprietary models on the mobile domain. Furthermore, when serving as a pre-critic, OS-Oracle-7B improves the performance of native GUI agents such as UI-TARS-1.5-7B in OSWorld and AndroidWorld environments. The code is open-sourced at https://github.com/numbmelon/OS-Oracle.

</details>


### [159] [Code-in-the-Loop Forensics: Agentic Tool Use for Image Forgery Detection](https://arxiv.org/abs/2512.16300)
*Fanrui Zhang,Qiang Zhang,Sizhuo Zhou,Jianwen Sun,Chuanhao Li,Jiaxin Ai,Yukang Feng,Yujie Zhang,Wenjie Li,Zizhen Li,Yifan Chang,Jiawei Liu,Kaipeng Zhang*

Main category: cs.AI

TL;DR: ForenAgent是一个多轮交互的IFD框架，通过自主生成和执行Python工具，结合两阶段训练和动态推理循环，有效整合异构信息流，提升检测灵活性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有IFD方法难以统一低层次语义无关特征和高层次语义知识，导致信息流异构且交互困难。

Method: ForenAgent采用两阶段训练流程（冷启动和强化微调），设计动态推理循环（全局感知、局部聚焦、迭代探测和整体裁决），并实例化为数据采样策略和任务对齐的过程奖励。

Result: 实验表明，ForenAgent在低层次工具辅助下展现出新兴的工具使用能力和反思推理能力，为通用IFD开辟了有前景的路径。

Conclusion: ForenAgent通过多轮交互框架和两阶段训练流程，成功整合了低层次和高层次的语义信息，为图像伪造检测（IFD）提供了更灵活和可解释的分析方法。

Abstract: Existing image forgery detection (IFD) methods either exploit low-level, semantics-agnostic artifacts or rely on multimodal large language models (MLLMs) with high-level semantic knowledge. Although naturally complementary, these two information streams are highly heterogeneous in both paradigm and reasoning, making it difficult for existing methods to unify them or effectively model their cross-level interactions. To address this gap, we propose ForenAgent, a multi-round interactive IFD framework that enables MLLMs to autonomously generate, execute, and iteratively refine Python-based low-level tools around the detection objective, thereby achieving more flexible and interpretable forgery analysis. ForenAgent follows a two-stage training pipeline combining Cold Start and Reinforcement Fine-Tuning to enhance its tool interaction capability and reasoning adaptability progressively. Inspired by human reasoning, we design a dynamic reasoning loop comprising global perception, local focusing, iterative probing, and holistic adjudication, and instantiate it as both a data-sampling strategy and a task-aligned process reward. For systematic training and evaluation, we construct FABench, a heterogeneous, high-quality agent-forensics dataset comprising 100k images and approximately 200k agent-interaction question-answer pairs. Experiments show that ForenAgent exhibits emergent tool-use competence and reflective reasoning on challenging IFD tasks when assisted by low-level tools, charting a promising route toward general-purpose IFD. The code will be released after the review process is completed.

</details>


### [160] [Adaptation of Agentic AI](https://arxiv.org/abs/2512.16301)
*Pengcheng Jiang,Jiacheng Lin,Zhiyi Shi,Zifeng Wang,Luxi He,Yichen Wu,Ming Zhong,Peiyang Song,Qizheng Zhang,Heng Wang,Xueqiang Xu,Hanwen Xu,Pengrui Han,Dylan Zhang,Jiashuo Sun,Chaoqi Yang,Kun Qian,Tian Wang,Changran Hu,Manling Li,Quanzheng Li,Hao Peng,Sheng Wang,Jingbo Shang,Chao Zhang,Jiaxuan You,Liyuan Liu,Pan Lu,Yu Zhang,Heng Ji,Yejin Choi,Dawn Song,Jimeng Sun,Jiawei Han*

Main category: cs.AI

TL;DR: 本文提出了一个系统框架，统一了代理和工具适应的研究，分析了各类策略的优缺点，并指出了未来挑战和机遇。


<details>
  <summary>Details</summary>
Motivation: 随着代理AI系统在能力和范围上的增长，适应成为提高性能、可靠性和泛化的核心机制。

Method: 我们提出了一个系统框架，涵盖代理适应和工具适应，并将其分解为工具执行信号和代理输出信号形式的代理适应，以及代理无关和代理监督形式的工具适应。

Result: 该框架有助于明确代理AI中适应策略的设计空间，明确其权衡，并为系统设计中选择或切换策略提供实用指导。

Conclusion: 本文旨在为研究人员和实践者提供一个概念基础和实践路线图，以构建更强大、高效和可靠的代理AI系统。

Abstract: Cutting-edge agentic AI systems are built on foundation models that can be adapted to plan, reason, and interact with external tools to perform increasingly complex and specialized tasks. As these systems grow in capability and scope, adaptation becomes a central mechanism for improving performance, reliability, and generalization. In this paper, we unify the rapidly expanding research landscape into a systematic framework that spans both agent adaptations and tool adaptations. We further decompose these into tool-execution-signaled and agent-output-signaled forms of agent adaptation, as well as agent-agnostic and agent-supervised forms of tool adaptation. We demonstrate that this framework helps clarify the design space of adaptation strategies in agentic AI, makes their trade-offs explicit, and provides practical guidance for selecting or switching among strategies during system design. We then review the representative approaches in each category, analyze their strengths and limitations, and highlight key open challenges and future opportunities. Overall, this paper aims to offer a conceptual foundation and practical roadmap for researchers and practitioners seeking to build more capable, efficient, and reliable agentic AI systems.

</details>


### [161] [Design and Evaluation of Cost-Aware PoQ for Decentralized LLM Inference](https://arxiv.org/abs/2512.16317)
*Arther Tian,Alex Ding,Frank Chen,Alan Wu,Aaron Chan,Bruce Zhang*

Main category: cs.AI

TL;DR: 本文提出成本感知PoQ框架，通过整合效率测量和平衡质量与成本的奖励机制，为去中心化LLM推理提供经济可持续的解决方案。


<details>
  <summary>Details</summary>
Motivation: 解决现有验证方法难以扩展到现代模型的问题，同时考虑推理和评估节点的异构计算成本。

Method: 结合真实标记级F1、轻量级学习评估器和基于GPT的判断，采用线性奖励函数平衡标准化质量和成本。

Result: 实验表明，语义文本相似性双编码器与真实标记和GPT分数的相关性更高，质量-成本分析显示最大模型在单位延迟质量上最有效。蒙特卡洛模拟显示成本感知奖励方案能有效奖励高质量低成本节点。

Conclusion: 成本感知的PoQ框架为经济可持续的去中心化LLM推理提供了实用基础。

Abstract: Decentralized large language model (LLM) inference promises transparent and censorship resistant access to advanced AI, yet existing verification approaches struggle to scale to modern models. Proof of Quality (PoQ) replaces cryptographic verification of computation with consensus over output quality, but the original formulation ignores heterogeneous computational costs across inference and evaluator nodes. This paper introduces a cost-aware PoQ framework that integrates explicit efficiency measurements into the reward mechanism for both types of nodes. The design combines ground truth token level F1, lightweight learned evaluators, and GPT based judgments within a unified evaluation pipeline, and adopts a linear reward function that balances normalized quality and cost.
  Experiments on extractive question answering and abstractive summarization use five instruction tuned LLMs ranging from TinyLlama-1.1B to Llama-3.2-3B and three evaluation models spanning cross encoder and bi encoder architectures. Results show that a semantic textual similarity bi encoder achieves much higher correlation with both ground truth and GPT scores than cross encoders, indicating that evaluator architecture is a critical design choice for PoQ. Quality-cost analysis further reveals that the largest models in the pool are also the most efficient in terms of quality per unit latency. Monte Carlo simulations over 5\,000 PoQ rounds demonstrate that the cost-aware reward scheme consistently assigns higher average rewards to high quality low cost inference models and to efficient evaluators, while penalizing slow low quality nodes. These findings suggest that cost-aware PoQ provides a practical foundation for economically sustainable decentralized LLM inference.

</details>


### [162] [AI Needs Physics More Than Physics Needs AI](https://arxiv.org/abs/2512.16344)
*Peter Coveney,Roger Highfield*

Main category: cs.AI

TL;DR: 本文批评当前AI技术的局限性，提出结合理论严谨性与机器学习的'Big AI'发展路径。


<details>
  <summary>Details</summary>
Motivation: 尽管AI被广泛认为是变革性的，但其实际影响仍有限，主要局限于少数高调的科学和商业成功案例。当前AI技术在参数意义、分布偏差、不确定性量化、机制解释和科学定律捕捉方面存在明显不足。

Method: 文章回顾了当前AI架构（如大型语言模型、推理模型和代理AI）的局限性，并探讨了量子AI和模拟计算中的机会。

Result: 文章指出了当前AI技术的多重局限性，并提出了通过结合理论严谨性和机器学习灵活性来推动AI发展的'Big AI'路线图。

Conclusion: 本文提出了一种新的AI发展路径，即'Big AI'，结合理论严谨性与机器学习的灵活性，以解决当前AI技术的局限性。

Abstract: Artificial intelligence (AI) is commonly depicted as transformative. Yet, after more than a decade of hype, its measurable impact remains modest outside a few high-profile scientific and commercial successes. The 2024 Nobel Prizes in Chemistry and Physics recognized AI's potential, but broader assessments indicate the impact to date is often more promotional than technical. We argue that while current AI may influence physics, physics has significantly more to offer this generation of AI. Current architectures - large language models, reasoning models, and agentic AI - can depend on trillions of meaningless parameters, suffer from distributional bias, lack uncertainty quantification, provide no mechanistic insights, and fail to capture even elementary scientific laws. We review critiques of these limits, highlight opportunities in quantum AI and analogue computing, and lay down a roadmap for the adoption of 'Big AI': a synthesis of theory-based rigour with the flexibility of machine learning.

</details>


### [163] [PCIA: A Path Construction Imitation Algorithm for Global Optimization](https://arxiv.org/abs/2512.16392)
*Mohammad-Javad Rezaei,Mozafar Bag-Mohammadi*

Main category: cs.AI

TL;DR: PCIA是一种受人类路径构建行为启发的元启发式算法，通过随机种群和路径表示优化问题，测试结果显示其竞争力强。


<details>
  <summary>Details</summary>
Motivation: 受人类在路径封闭时智能混合现有路径以构建新路径的启发，开发一种新的元启发式优化算法。

Method: PCIA模仿人类构建新路径的行为，通过随机生成种群寻找最佳路径，每个粒子代表一条路径。

Result: PCIA在53个数学优化问题和13个约束优化问题上进行了测试，结果表现优异。

Conclusion: PCIA算法在数学优化和约束优化问题上表现出色，与现有流行的和最新的元启发式算法相比具有高度竞争力。

Abstract: In this paper, a new metaheuristic optimization algorithm, called Path Construction Imitation Algorithm (PCIA), is proposed. PCIA is inspired by how humans construct new paths and use them. Typically, humans prefer popular transportation routes. In the event of a path closure, a new route is built by mixing the existing paths intelligently. Also, humans select different pathways on a random basis to reach unknown destinations. PCIA generates a random population to find the best route toward the destination, similar to swarm-based algorithms. Each particle represents a path toward the destination. PCIA has been tested with 53 mathematical optimization problems and 13 constrained optimization problems. The results showed that the PCIA is highly competitive compared to both popular and the latest metaheuristic algorithms.

</details>


### [164] [Synthelite: Chemist-aligned and feasibility-aware synthesis planning with LLMs](https://arxiv.org/abs/2512.16424)
*Nguyen Xuan-Vu,Daniel Armstrong,Milena Wehrbach,Andres M Bran,Zlatko Jončev,Philippe Schwaller*

Main category: cs.AI

TL;DR: Synthelite是一个基于LLM的合成规划框架，能生成端到端合成路线并允许专家干预，实验显示其成功率高且灵活。


<details>
  <summary>Details</summary>
Motivation: 现有计算机辅助合成规划（CASP）框架缺乏与人类专家互动的机制，限制了化学家洞察力的整合。

Method: 利用大型语言模型（LLMs）直接提出逆合成转化，并通过自然语言提示允许专家干预。

Result: Synthelite在策略约束和起始材料约束的合成任务中成功率达到95%，并能灵活适应用户指定的约束。

Conclusion: Synthelite展示了将大型语言模型（LLMs）作为合成规划核心协调器的潜力，不仅是一个实用工具，也是向新范式迈进的步骤。

Abstract: Computer-aided synthesis planning (CASP) has long been envisioned as a complementary tool for synthetic chemists. However, existing frameworks often lack mechanisms to allow interaction with human experts, limiting their ability to integrate chemists' insights. In this work, we introduce Synthelite, a synthesis planning framework that uses large language models (LLMs) to directly propose retrosynthetic transformations. Synthelite can generate end-to-end synthesis routes by harnessing the intrinsic chemical knowledge and reasoning capabilities of LLMs, while allowing expert intervention through natural language prompts. Our experiments demonstrate that Synthelite can flexibly adapt its planning trajectory to diverse user-specified constraints, achieving up to 95\% success rates in both strategy-constrained and starting-material-constrained synthesis tasks. Additionally, Synthelite exhibits the ability to account for chemical feasibility during route design. We envision Synthelite to be both a useful tool and a step toward a paradigm where LLMs are the central orchestrators of synthesis planning.

</details>


### [165] [TIB AIssistant: a Platform for AI-Supported Research Across Research Life Cycles](https://arxiv.org/abs/2512.16442)
*Allard Oelen,Sören Auer*

Main category: cs.AI

TL;DR: TIB AIssistant是一个AI支持的研究平台，通过多个助手和工具支持研究生命周期，最终目标是建立社区维护的AI研究平台。


<details>
  <summary>Details</summary>
Motivation: 随着AI和大型语言模型（LLMs）的普及，AI支持的研究有潜力在整个研究生命周期中协助研究人员，因此开发了TIB AIssistant平台。

Method: 通过展示TIB AIssistant的主要功能，包括一系列助手和外部学术服务工具，生成的数据以RO-Crate格式存储以确保透明度和可重复性。

Result: TIB AIssistant成功展示了其功能，通过助手间的交互生成研究论文草稿的部分内容，并为未来社区维护的AI支持研究平台奠定了基础。

Conclusion: 本文介绍了TIB AIssistant作为一个AI支持的研究平台，旨在通过一系列助手和工具支持整个研究生命周期，并最终为建立一个社区维护的AI支持研究平台奠定了基础。

Abstract: The rapidly growing popularity of adopting Artificial Intelligence (AI), and specifically Large Language Models (LLMs), is having a widespread impact throughout society, including the academic domain. AI-supported research has the potential to support researchers with tasks across the entire research life cycle. In this work, we demonstrate the TIB AIssistant, an AI-supported research platform providing support throughout the research life cycle. The AIssistant consists of a collection of assistants, each responsible for a specific research task. In addition, tools are provided to give access to external scholarly services. Generated data is stored in the assets and can be exported as an RO-Crate bundle to provide transparency and enhance reproducibility of the research project. We demonstrate the AIssistant's main functionalities by means of a sequential walk-through of assistants, interacting with each other to generate sections for a draft research paper. In the end, with the AIssistant, we lay the foundation for a larger agenda of providing a community-maintained platform for AI-supported research.

</details>


### [166] [StarCraft+: Benchmarking Multi-agent Algorithms in Adversary Paradigm](https://arxiv.org/abs/2512.16444)
*Yadong Li,Tong Zhang,Bo Huang,Zhen Cui*

Main category: cs.AI

TL;DR: SC2BA环境和APyMARL库为MARL算法提供了多样化的对抗评估平台，揭示了现有算法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有MARL算法评估中，对手配置单一且缺乏多样性，限制了算法的全面评估。

Method: 通过创建SC2BA环境和APyMARL库，支持双算法配对对抗和多算法混合对抗两种模式，对经典MARL算法进行基准测试。

Result: 基准实验揭示了现有算法在对抗模式下的有效性、敏感性和可扩展性问题。

Conclusion: 本研究通过建立SC2BA环境和开发APyMARL库，为多智能体强化学习算法提供了更公平、多样化的对抗评估平台，并揭示了现有算法在有效性、敏感性和可扩展性方面的问题，标志着MARL领域的新进展。

Abstract: Deep multi-agent reinforcement learning (MARL) algorithms are booming in the field of collaborative intelligence, and StarCraft multi-agent challenge (SMAC) is widely-used as the benchmark therein. However, imaginary opponents of MARL algorithms are practically configured and controlled in a fixed built-in AI mode, which causes less diversity and versatility in algorithm evaluation. To address this issue, in this work, we establish a multi-agent algorithm-vs-algorithm environment, named StarCraft II battle arena (SC2BA), to refresh the benchmarking of MARL algorithms in an adversary paradigm. Taking StarCraft as infrastructure, the SC2BA environment is specifically created for inter-algorithm adversary with the consideration of fairness, usability and customizability, and meantime an adversarial PyMARL (APyMARL) library is developed with easy-to-use interfaces/modules. Grounding in SC2BA, we benchmark those classic MARL algorithms in two types of adversarial modes: dual-algorithm paired adversary and multi-algorithm mixed adversary, where the former conducts the adversary of pairwise algorithms while the latter focuses on the adversary to multiple behaviors from a group of algorithms. The extensive benchmark experiments exhibit some thought-provoking observations/problems in the effectivity, sensibility and scalability of these completed algorithms. The SC2BA environment as well as reproduced experiments are released in \href{https://github.com/dooliu/SC2BA}{Github}, and we believe that this work could mark a new step for the MARL field in the coming years.

</details>


### [167] [Towards AI-Supported Research: a Vision of the TIB AIssistant](https://arxiv.org/abs/2512.16447)
*Sören Auer,Allard Oelen,Mohamad Yaser Jaradeh,Mutahira Khalid,Farhana Keya,Sasi Kiran Gaddipati,Jennifer D'Souza,Lorenz Schlüter,Amirreza Alasti,Gollam Rabby,Azanzi Jiomekong,Oliver Karras*

Main category: cs.AI

TL;DR: TIB AIssistant是一个跨学科研究支持平台，通过模块化组件整合生成式AI，解决研究中的AI整合挑战。


<details>
  <summary>Details</summary>
Motivation: 尽管生成式AI和大型语言模型在研究中具有巨大潜力，但由于领域需求差异、AI素养不足、工具协调复杂以及生成AI准确性不明确等问题，有效整合AI仍面临挑战。

Method: 采用模块化组件（如提示和工具库、共享数据存储和灵活的编排框架）构建了一个领域无关的人机协作平台。

Result: 开发了一个早期原型，展示了该平台在支持研究生命周期各阶段任务（如构思、文献分析、方法开发、数据分析和学术写作）中的潜力。

Conclusion: TIB AIssistant平台展示了将生成式AI和大型语言模型整合到研究工作中的可行性和潜在影响，为跨学科研究提供了支持。

Abstract: The rapid advancements in Generative AI and Large Language Models promise to transform the way research is conducted, potentially offering unprecedented opportunities to augment scholarly workflows. However, effectively integrating AI into research remains a challenge due to varying domain requirements, limited AI literacy, the complexity of coordinating tools and agents, and the unclear accuracy of Generative AI in research. We present the vision of the TIB AIssistant, a domain-agnostic human-machine collaborative platform designed to support researchers across disciplines in scientific discovery, with AI assistants supporting tasks across the research life cycle. The platform offers modular components - including prompt and tool libraries, a shared data store, and a flexible orchestration framework - that collectively facilitate ideation, literature analysis, methodology development, data analysis, and scholarly writing. We describe the conceptual framework, system architecture, and implementation of an early prototype that demonstrates the feasibility and potential impact of our approach.

</details>


### [168] [TimeSeries2Report prompting enables adaptive large language model management of lithium-ion batteries](https://arxiv.org/abs/2512.16453)
*Jiayang Yang,Chunhui Zhao,Martin Guay,Zhixing Cao*

Main category: cs.AI

TL;DR: TS2R框架通过自然语言编码时间序列数据，提升LLM在电池管理中的性能，实现专家级决策质量。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在多变量时间序列数据解释方面具有潜力，但其在真实世界BESS运维中的应用仍未被充分探索。

Method: TS2R通过分段、语义抽象和基于规则的解读，将短期时间动态编码为自然语言，有效连接低层传感器信号与高层上下文洞察。

Result: TS2R在实验室和真实数据集上的基准测试显示，其在异常检测、充电状态预测和充放电管理任务中，报告质量与下游任务性能均优于基于视觉、嵌入和文本的提示基线。

Conclusion: TS2R框架通过将原始时间序列数据转换为结构化报告，显著提升了LLM在BESS管理中的决策质量和预测一致性，无需重新训练或架构修改，为自适应、LLM驱动的电池智能提供了实用路径。

Abstract: Large language models (LLMs) offer promising capabilities for interpreting multivariate time-series data, yet their application to real-world battery energy storage system (BESS) operation and maintenance remains largely unexplored. Here, we present TimeSeries2Report (TS2R), a prompting framework that converts raw lithium-ion battery operational time-series into structured, semantically enriched reports, enabling LLMs to reason, predict, and make decisions in BESS management scenarios. TS2R encodes short-term temporal dynamics into natural language through a combination of segmentation, semantic abstraction, and rule-based interpretation, effectively bridging low-level sensor signals with high-level contextual insights. We benchmark TS2R across both lab-scale and real-world datasets, evaluating report quality and downstream task performance in anomaly detection, state-of-charge prediction, and charging/discharging management. Compared with vision-, embedding-, and text-based prompting baselines, report-based prompting via TS2R consistently improves LLM performance in terms of across accuracy, robustness, and explainability metrics. Notably, TS2R-integrated LLMs achieve expert-level decision quality and predictive consistency without retraining or architecture modification, establishing a practical path for adaptive, LLM-driven battery intelligence.

</details>


### [169] [cuPilot: A Strategy-Coordinated Multi-agent Framework for CUDA Kernel Evolution](https://arxiv.org/abs/2512.16465)
*Jinwu Chen,Qidie Wu,Bin Li,Lin Ma,Xin Si,Yang Hu,Shouyi Yin,Jun Yang*

Main category: cs.AI

TL;DR: cuPilot通过策略协调的多智能体框架优化CUDA内核，性能提升显著，代码开源。


<details>
  <summary>Details</summary>
Motivation: 现有基于大语言模型和进化算法的自动内核优化方法因代理设计不佳和进化表示不匹配而性能不足。

Method: 提出了cuPilot框架，包括策略协调的进化算法、屋顶线引导提示和策略级种群初始化。

Result: 生成的CUDA内核在100个内核基准测试中平均加速3.09倍，GEMM任务中硬件单元利用率高。

Conclusion: cuPilot通过策略协调的多智能体框架和进化算法，显著提升了CUDA内核的性能，平均加速比达到3.09倍，并在GEMM任务中展示了硬件单元的高利用率。生成的代码已开源。

Abstract: Optimizing CUDA kernels is a challenging and labor-intensive task, given the need for hardware-software co-design expertise and the proprietary nature of high-performance kernel libraries. While recent large language models (LLMs) combined with evolutionary algorithms show promise in automatic kernel optimization, existing approaches often fall short in performance due to their suboptimal agent designs and mismatched evolution representations. This work identifies these mismatches and proposes cuPilot, a strategy-coordinated multi-agent framework that introduces strategy as an intermediate semantic representation for kernel evolution. Key contributions include a strategy-coordinated evolution algorithm, roofline-guided prompting, and strategy-level population initialization. Experimental results show that the generated kernels by cuPilot achieve an average speed up of 3.09$\times$ over PyTorch on a benchmark of 100 kernels. On the GEMM tasks, cuPilot showcases sophisticated optimizations and achieves high utilization of critical hardware units. The generated kernels are open-sourced at https://github.com/champloo2878/cuPilot-Kernels.git.

</details>


### [170] [Quantifying and Bridging the Fidelity Gap: A Decisive-Feature Approach to Comparing Synthetic and Real Imagery](https://arxiv.org/abs/2512.16468)
*Danial Safaei,Siddartha Khastgir,Mohsen Alirezaei,Jeroen Ploeg,Son Tong,Xingyu Zhao*

Main category: cs.AI

TL;DR: 本文提出决定性特征保真度（DFF）作为新的行为基础保真度度量，通过XAI方法识别因果证据差异，实验证明DFF能揭示传统方法忽略的差异，并提升模拟器保真度。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉保真度在模拟器中有所提升，但像素级保真度并不能确保系统在模拟和现实环境中的决策基于相同的因果证据。本文旨在解决缺乏行为基础保真度度量的问题。

Method: 引入决定性特征保真度（DFF），利用可解释AI（XAI）方法识别和比较驱动系统决策的决定性特征，并提出基于反事实解释的实用估计器及DFF引导的校准方案。

Result: 在2126对KITTI-VirtualKITTI2匹配对上进行的实验表明，DFF能够揭示传统输出值保真度忽略的差异，且DFF引导的校准方案提升了决定性特征和输入级保真度。

Conclusion: DFF作为一种新的行为基础保真度度量，能够有效揭示传统输出值保真度忽略的差异，并通过DFF引导的校准方案提升模拟器的保真度，而不牺牲输出值保真度。

Abstract: Virtual testing using synthetic data has become a cornerstone of autonomous vehicle (AV) safety assurance. Despite progress in improving visual realism through advanced simulators and generative AI, recent studies reveal that pixel-level fidelity alone does not ensure reliable transfer from simulation to the real world. What truly matters is whether the system-under-test (SUT) bases its decisions on the same causal evidence in both real and simulated environments - not just whether images "look real" to humans. This paper addresses the lack of such a behavior-grounded fidelity measure by introducing Decisive Feature Fidelity (DFF), a new SUT-specific metric that extends the existing fidelity spectrum to capture mechanism parity - the agreement in causal evidence underlying the SUT's decisions across domains. DFF leverages explainable-AI (XAI) methods to identify and compare the decisive features driving the SUT's outputs for matched real-synthetic pairs. We further propose practical estimators based on counterfactual explanations, along with a DFF-guided calibration scheme to enhance simulator fidelity. Experiments on 2126 matched KITTI-VirtualKITTI2 pairs demonstrate that DFF reveals discrepancies overlooked by conventional output-value fidelity. Furthermore, results show that DFF-guided calibration improves decisive-feature and input-level fidelity without sacrificing output value fidelity across diverse SUTs.

</details>


### [171] [Best Practices For Empirical Meta-Algorithmic Research Guidelines from the COSEAL Research Network](https://arxiv.org/abs/2512.16491)
*Theresa Eimer,Lennart Schäpermeier,André Biedenkapp,Alexander Tornede,Lars Kotthoff,Pieter Leyman,Matthias Feurer,Katharina Eggensperger,Kaitlin Maile,Tanja Tornede,Anna Kozak,Ke Xue,Marcel Wever,Mitra Baratchi,Damir Pulatov,Heike Trautmann,Haniye Kashgarani,Marius Lindauer*

Main category: cs.AI

TL;DR: 该报告总结了元算法研究中的最佳实践，为研究人员提供指南，涵盖从实验设计到结果呈现的全过程。


<details>
  <summary>Details</summary>
Motivation: 元算法研究（如算法选择、配置和调度）通常依赖计算密集型实验，实验设计和设置的自由度大，容易引入错误，影响科学见解的可扩展性和有效性。

Method: 通过收集和分析不同子领域的实践，建立了元算法研究的当前最佳实践。

Result: 报告总结了从研究问题提出到实验设计、执行、分析和结果呈现的整个实验周期的最佳实践。

Conclusion: 该报告汇集了COSEAL社区各子领域的最佳实践，为元算法研究的新研究人员和实践者提供了指南。

Abstract: Empirical research on meta-algorithmics, such as algorithm selection, configuration, and scheduling, often relies on extensive and thus computationally expensive experiments. With the large degree of freedom we have over our experimental setup and design comes a plethora of possible error sources that threaten the scalability and validity of our scientific insights. Best practices for meta-algorithmic research exist, but they are scattered between different publications and fields, and continue to evolve separately from each other. In this report, we collect good practices for empirical meta-algorithmic research across the subfields of the COSEAL community, encompassing the entire experimental cycle: from formulating research questions and selecting an experimental design, to executing ex- periments, and ultimately, analyzing and presenting results impartially. It establishes the current state-of-the-art practices within meta-algorithmic research and serves as a guideline to both new researchers and practitioners in meta-algorithmic fields.

</details>


### [172] [Scaling Laws for Energy Efficiency of Local LLMs](https://arxiv.org/abs/2512.16531)
*Ander Alvarez,Alessandro Genuardi,Nilotpal Sinha,Antonio Tiene,Samuel Mugel,Román Orús*

Main category: cs.AI

TL;DR: 本研究揭示了仅使用CPU进行本地语言和视觉语言模型推理的计算规律，并展示了模型压缩和输入分辨率预处理在提升边缘设备可持续性方面的有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管GPU在现代人工智能部署中占主导地位，但大多数消费硬件仍依赖CPU，而关于仅使用CPU进行本地语言和视觉语言工作负载的计算规律尚未充分探索。

Method: 采用基于连续采样处理器和内存使用情况并结合曲线下面积积分的统一方法，对语言模型和视觉语言模型在不同CPU层级上的计算负载进行了系统基准测试。

Result: 发现两条经验扩展规律：语言模型推理的计算成本与标记长度近似线性扩展；视觉语言模型表现出预处理驱动的“分辨率拐点”。此外，量子启发压缩技术可减少处理器和内存使用高达71.9%，能耗降低高达62%，同时保持或提高语义准确性。

Conclusion: 本研究系统地量化了仅使用CPU进行本地语言和视觉语言工作负载的多模态扩展，并确定了模型压缩和输入分辨率预处理作为可持续边缘推理的有效低成本杠杆。

Abstract: Deploying local large language models and vision-language models on edge devices requires balancing accuracy with constrained computational and energy budgets. Although graphics processors dominate modern artificial-intelligence deployment, most consumer hardware--including laptops, desktops, industrial controllers, and embedded systems--relies on central processing units. Despite this, the computational laws governing central-processing-unit-only inference for local language and vision-language workloads remain largely unexplored. We systematically benchmark large language and vision-language models on two representative central-processing-unit tiers widely used for local inference: a MacBook Pro M2, reflecting mainstream laptop-class deployment, and a Raspberry Pi 5, representing constrained, low-power embedded settings. Using a unified methodology based on continuous sampling of processor and memory usage together with area-under-curve integration, we characterize how computational load scales with input text length for language models and with image resolution for vision-language models. We uncover two empirical scaling laws: (1) computational cost for language-model inference scales approximately linearly with token length; and (2) vision-language models exhibit a preprocessing-driven "resolution knee", where compute remains constant above an internal resolution clamp and decreases sharply below it. Beyond these laws, we show that quantum-inspired compression reduces processor and memory usage by up to 71.9% and energy consumption by up to 62%, while preserving or improving semantic accuracy. These results provide a systematic quantification of multimodal central-processing-unit-only scaling for local language and vision-language workloads, and they identify model compression and input-resolution preprocessing as effective, low-cost levers for sustainable edge inference.

</details>


### [173] [From Personalization to Prejudice: Bias and Discrimination in Memory-Enhanced AI Agents for Recruitment](https://arxiv.org/abs/2512.16532)
*Himanshu Gharat,Himanshi Agrawal,Gourab K. Patro*

Main category: cs.AI

TL;DR: 记忆增强的LLM代理在个性化过程中会系统性引入偏见，需额外保护措施。


<details>
  <summary>Details</summary>
Motivation: 尽管记忆增强的个性化带来明显好处，但也引入了偏见风险，而记忆增强个性化代理导致的偏见尚未被充分探索。

Method: 通过模拟记忆增强个性化代理在招聘用例中的行为，研究偏见是否以及如何在操作的不同阶段被引入和放大。

Result: 实验发现，使用安全训练的LLM的代理会通过个性化系统性引入和强化偏见。

Conclusion: 研究表明，记忆增强的个性化AI代理会系统性引入并强化偏见，强调了在基于LLM的记忆增强AI代理中需要额外的保护措施或代理护栏。

Abstract: Large Language Models (LLMs) have empowered AI agents with advanced capabilities for understanding, reasoning, and interacting across diverse tasks. The addition of memory further enhances them by enabling continuity across interactions, learning from past experiences, and improving the relevance of actions and responses over time; termed as memory-enhanced personalization. Although such personalization through memory offers clear benefits, it also introduces risks of bias. While several previous studies have highlighted bias in ML and LLMs, bias due to memory-enhanced personalized agents is largely unexplored. Using recruitment as an example use case, we simulate the behavior of a memory-enhanced personalized agent, and study whether and how bias is introduced and amplified in and across various stages of operation. Our experiments on agents using safety-trained LLMs reveal that bias is systematically introduced and reinforced through personalization, emphasizing the need for additional protective measures or agent guardrails in memory-enhanced LLM-based AI agents.

</details>


### [174] [Needle in the Web: A Benchmark for Retrieving Targeted Web Pages in the Wild](https://arxiv.org/abs/2512.16553)
*Yumeng Wang,Tianyu Fan,Lingrui Xu,Chao Huang*

Main category: cs.AI

TL;DR: Needle in the Web 是一个新基准，用于评估搜索代理和基于LLM的系统在模糊探索性查询下的表现，结果显示当前系统在此类任务中表现不佳。


<details>
  <summary>Details</summary>
Motivation: 现有基准忽视模糊探索性搜索（Fuzzy Exploratory Search），即用户寻求最相关网页而非单一事实答案的查询。

Method: 采用灵活的方法论生成可控难度的查询，基于网页内容的真实声明。

Result: 大多数模型表现不佳，准确率低于35%，且没有模型能跨领域或难度级别持续表现出色。

Conclusion: Needle in the Web 是一个针对模糊探索性搜索的新基准，揭示了当前搜索系统在处理语义模糊性时的重大挑战。

Abstract: Large Language Models (LLMs) have evolved from simple chatbots into sophisticated agents capable of automating complex real-world tasks, where browsing and reasoning over live web content is key to assessing retrieval and cognitive skills. Existing benchmarks like BrowseComp and xBench-DeepSearch emphasize complex reasoning searches requiring multi-hop synthesis but neglect Fuzzy Exploratory Search, namely queries that are vague and multifaceted, where users seek the most relevant webpage rather than a single factual answer. To address this gap, we introduce Needle in the Web, a novel benchmark specifically designed to evaluate modern search agents and LLM-based systems on their ability to retrieve and reason over real-world web content in response to ambiguous, exploratory queries under varying levels of difficulty. Needle in the Web comprises 663 questions spanning seven distinct domains. To ensure high query quality and answer uniqueness, we employ a flexible methodology that reliably generates queries of controllable difficulty based on factual claims of web contents. We benchmark three leading LLMs and three agent-based search systems on Needle in the Web, finding that most models struggle: many achieve below 35% accuracy, and none consistently excel across domains or difficulty levels. These findings reveal that Needle in the Web presents a significant challenge for current search systems and highlights the open problem of effective fuzzy retrieval under semantic ambiguity.

</details>


### [175] [Implementing a Sharia Chatbot as a Consultation Medium for Questions About Islam](https://arxiv.org/abs/2512.16644)
*Wisnu Uriawan,Aria Octavian Hamza,Ade Ripaldi Nuralim,Adi Purnama,Ahmad Juaeni Yunus,Anissya Auliani Supriadi Putri*

Main category: cs.AI

TL;DR: 研究开发了一个符合伊斯兰教法的聊天机器人，结合强化学习和语义嵌入技术，在封闭领域查询中表现良好，但存在静态学习和数据集依赖的局限性。


<details>
  <summary>Details</summary>
Motivation: 旨在通过现代AI技术提升宗教素养、数字宣教和在工业4.0时代获取经过验证的伊斯兰知识。

Method: 研究采用CRISP-DM方法，处理了来自《古兰经》、圣训和学者法特瓦的25,000个问答对数据集，使用JSON格式以提高灵活性和可扩展性。聊天机器人原型采用Flask API后端和Flutter移动前端开发。

Result: 在功能测试中，聊天机器人在包括教法、信仰、崇拜和交易等多样主题上实现了87%的语义准确性。

Conclusion: 本研究展示了一个符合伊斯兰教法的聊天机器人，作为咨询伊斯兰问题的互动媒介，通过结合强化学习和语义嵌入技术，确保了回答的上下文相关性和准确性。尽管在封闭领域查询中表现良好，但静态学习和数据集依赖性等局限性为未来改进如持续适应和多轮对话支持提供了机会。

Abstract: This research presents the implementation of a Sharia-compliant chatbot as an interactive medium for consulting Islamic questions, leveraging Reinforcement Learning (Q-Learning) integrated with Sentence-Transformers for semantic embedding to ensure contextual and accurate responses. Utilizing the CRISP-DM methodology, the system processes a curated Islam QA dataset of 25,000 question-answer pairs from authentic sources like the Qur'an, Hadith, and scholarly fatwas, formatted in JSON for flexibility and scalability. The chatbot prototype, developed with a Flask API backend and Flutter-based mobile frontend, achieves 87% semantic accuracy in functional testing across diverse topics including fiqh, aqidah, ibadah, and muamalah, demonstrating its potential to enhance religious literacy, digital da'wah, and access to verified Islamic knowledge in the Industry 4.0 era. While effective for closed-domain queries, limitations such as static learning and dataset dependency highlight opportunities for future enhancements like continuous adaptation and multi-turn conversation support, positioning this innovation as a bridge between traditional Islamic scholarship and modern AI-driven consultation.

</details>


### [176] [Prefix Probing: Lightweight Harmful Content Detection for Large Language Models](https://arxiv.org/abs/2512.16650)
*Jirui Yang,Hengqi Guo,Zhihui Lu,Yi Zhao,Yuansen Zhang,Shijing Hu,Qiang Duan,Yinggui Wang,Tao Wei*

Main category: cs.AI

TL;DR: Prefix Probing 是一种高效的黑盒有害内容检测方法，通过前缀比较和缓存技术实现低成本高效果检测。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在现实世界安全敏感应用中常面临检测准确性、推理延迟和部署成本之间的三难权衡。

Method: 提出了一种名为 Prefix Probing 的黑盒有害内容检测方法，通过比较‘同意/执行’与‘拒绝/安全’开头前缀的条件对数概率，并利用前缀缓存将检测开销降至接近首词延迟。推理时仅需对探测前缀进行一次对数概率计算即可生成有害性分数并应用阈值，无需调用额外模型或多阶段推理。

Result: 大量实验表明，Prefix Probing 的检测效果与主流外部安全模型相当，同时仅需极低计算成本且无需额外模型部署。

Conclusion: Prefix Probing 方法在检测有害内容方面表现出色，其检测效果与主流外部安全模型相当，同时计算成本极低且无需额外模型部署，展现了强大的实用性和效率。

Abstract: Large language models often face a three-way trade-off among detection accuracy, inference latency, and deployment cost when used in real-world safety-sensitive applications. This paper introduces Prefix Probing, a black-box harmful content detection method that compares the conditional log-probabilities of "agreement/execution" versus "refusal/safety" opening prefixes and leverages prefix caching to reduce detection overhead to near first-token latency. During inference, the method requires only a single log-probability computation over the probe prefixes to produce a harmfulness score and apply a threshold, without invoking any additional models or multi-stage inference. To further enhance the discriminative power of the prefixes, we design an efficient prefix construction algorithm that automatically discovers highly informative prefixes, substantially improving detection performance. Extensive experiments demonstrate that Prefix Probing achieves detection effectiveness comparable to mainstream external safety models while incurring only minimal computational cost and requiring no extra model deployment, highlighting its strong practicality and efficiency.

</details>


### [177] [Comprehensive AI Literacy: The Case for Centering Human Agency](https://arxiv.org/abs/2512.16656)
*Sri Yash Tadimalla,Justin Cary,Gordon Hull,Jordan Register,Daniel Maxwell,David Pugalee,Tina Heafner*

Main category: cs.AI

TL;DR: 本文呼吁教育系统转向以人类能动性为核心的全面AI素养，强调批判性思考和自主选择权，而非被动接受技术。


<details>
  <summary>Details</summary>
Motivation: 当前教育框架未能有效应对AI技术快速普及带来的挑战，导致功能性技能与批判性、伦理思考之间的脱节。

Method: 通过AI素养、流畅性和能力框架（AI Literacy, Fluency, and Competency frameworks）来支持教育者和学生。

Result: 提出了一种以人类能动性为中心的AI素养框架，为教育者和学生提供了明确的决策路径和态度表达方式。

Conclusion: 本文主张在教育系统中进行系统性转变，强调以人类能动性为核心的全面AI素养，包括学生和教师的自主选择权，以及技术使用的批判性思考。

Abstract: The rapid assimilation of Artificial Intelligence technologies into various facets of society has created a significant educational imperative that current frameworks are failing to effectively address. We are witnessing the rise of a dangerous literacy gap, where a focus on the functional, operational skills of using AI tools is eclipsing the development of critical and ethical reasoning about them. This position paper argues for a systemic shift toward comprehensive AI literacy that centers human agency - the empowered capacity for intentional, critical, and responsible choice. This principle applies to all stakeholders in the educational ecosystem: it is the student's agency to question, create with, or consciously decide not to use AI based on the task; it is the teacher's agency to design learning experiences that align with instructional values, rather than ceding pedagogical control to a tool. True literacy involves teaching about agency itself, framing technology not as an inevitability to be adopted, but as a choice to be made. This requires a deep commitment to critical thinking and a robust understanding of epistemology. Through the AI Literacy, Fluency, and Competency frameworks described in this paper, educators and students will become agents in their own human-centric approaches to AI, providing necessary pathways to clearly articulate the intentions informing decisions and attitudes toward AI and the impact of these decisions on academic work, career, and society.

</details>


### [178] [Unsupervised Thematic Clustering Of hadith Texts Using The Apriori Algorithm](https://arxiv.org/abs/2512.16694)
*Wisnu Uriawan,Achmad Ajie Priyajie,Angga Gustian,Fikri Nur Hidayat,Sendi Ahmad Rafiudin,Muhamad Fikri Zaelani*

Main category: cs.AI

TL;DR: 研究利用Apriori算法自动分析印尼语布哈里圣训，揭示出有意义的语义关联模式，推动了数字伊斯兰研究的发展。


<details>
  <summary>Details</summary>
Motivation: 随着伊斯兰文本数字化的发展，迫切需要自动化对圣训进行主题分类。

Method: 研究采用无监督学习方法，使用Apriori算法进行关联规则挖掘分析，数据集为印尼语翻译的布哈里圣训，经过预处理（包括大小写折叠、标点清理、分词、停用词去除和词干提取）。

Result: 结果显示存在有意义的关联模式，如‘rakaat-祈祷’、‘verse-启示’和‘hadith-故事’之间的关系，这些模式描述了崇拜、启示和圣训叙述的主题。

Conclusion: 该研究证实了Apriori算法在自动揭示潜在语义关系方面的能力，同时为数字伊斯兰研究和基于技术的学习系统的发展做出了贡献。

Abstract: This research stems from the urgency to automate the thematic grouping of hadith in line with the growing digitalization of Islamic texts. Based on a literature review, the unsupervised learning approach with the Apriori algorithm has proven effective in identifying association patterns and semantic relations in unlabeled text data. The dataset used is the Indonesian Translation of the hadith of Bukhari, which first goes through preprocessing stages including case folding, punctuation cleaning, tokenization, stopword removal, and stemming. Next, an association rule mining analysis was conducted using the Apriori algorithm with support, confidence, and lift parameters. The results show the existence of meaningful association patterns such as the relationship between rakaat-prayer, verse-revelation, and hadith-story, which describe the themes of worship, revelation, and hadith narration. These findings demonstrate that the Apriori algorithm has the ability to automatically uncover latent semantic relationships, while contributing to the development of digital Islamic studies and technology-based learning systems.

</details>


### [179] [Do Multi-Agents Solve Better Than Single? Evaluating Agentic Frameworks for Diagram-Grounded Geometry Problem Solving and Reasoning](https://arxiv.org/abs/2512.16698)
*Mahbub E Sobhani,Md. Faiyaz Abdullah Sayeedi,Mohammad Nehad Alam,Proma Hossain Progga,Swakkhar Shatabda*

Main category: cs.AI

TL;DR: 多智能体设计对开源模型有益，尤其在新数据集上，但闭源模型在单智能体模式下表现更好。


<details>
  <summary>Details</summary>
Motivation: 探讨多智能体设计在解决几何问题中的优势是否普遍适用。

Method: 系统比较单智能体和多智能体流程在四个视觉数学基准上的表现。

Result: 开源模型在多智能体模式下性能提升，而闭源模型在单智能体模式下表现更佳。

Conclusion: 多智能体设计对开源模型有明显优势，尤其在新数据集上能提升性能，但并非在所有情况下都最优。

Abstract: Diagram-grounded geometry problem solving is a critical benchmark for multimodal large language models (MLLMs), yet the benefits of multi-agent design over single-agent remain unclear. We systematically compare single-agent and multi-agent pipelines on four visual math benchmarks: Geometry3K, MathVerse, OlympiadBench, and We-Math. For open-source models, multi-agent consistently improves performance. For example, Qwen-2.5-VL (7B) gains +6.8 points and Qwen-2.5-VL (32B) gains +3.3 on Geometry3K, and both Qwen-2.5-VL variants see further gains on OlympiadBench and We-Math. In contrast, the closed-source Gemini-2.0-Flash generally performs better in single-agent mode on classic benchmarks, while multi-agent yields only modest improvements on the newer We-Math dataset. These findings show that multi-agent pipelines provide clear benefits for open-source models and can assist strong proprietary systems on newer, less familiar benchmarks, but agentic decomposition is not universally optimal. All code, data, and reasoning files are available at https://github.com/faiyazabdullah/Interpreter-Solver

</details>


### [180] [Cyber Humanism in Education: Reclaiming Agency through AI and Learning Sciences](https://arxiv.org/abs/2512.16701)
*Giovanni Adorni*

Main category: cs.AI

TL;DR: 本文提出‘教育中的赛博人文主义’框架，通过三个设计支柱和案例研究，探讨如何在AI丰富的教育环境中重新确立人类能动性，并指出了未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 生成式人工智能正在迅速改变教育中知识的产生和验证方式，引发了关于认知卸载、教师去专业化等问题的担忧。本文旨在探讨如何在AI丰富的教育环境中重新确立人类能动性。

Method: 本文通过概念化AI支持的学习环境为人类与机器共同构建的社会技术基础设施，提出了三个设计支柱：反思能力、算法公民权和对话设计，并将其与国际数字和AI能力框架相关联。通过高等教育案例研究，特别是基于提示的学习和‘对话式AI教育者’认证，操作化了这些理念。

Result: 研究发现，提出的框架和实践可以增强认知能动性，同时也揭示了关于工作量、公平性和治理的紧张关系。

Conclusion: 本文提出了‘教育中的赛博人文主义’框架，旨在在生成式人工智能重塑教育的背景下重新确立人类能动性。通过案例研究展示了如何在高等教育中实施这一框架，并指出了未来AI丰富、以人为本的教育发展方向。

Abstract: Generative Artificial Intelligence (GenAI) is rapidly reshaping how knowledge is produced and validated in education. Rather than adding another digital tool, large language models reconfigure reading, writing, and coding into hybrid human-AI workflows, raising concerns about epistemic automation, cognitive offloading, and the de-professiona\-lisation of teachers. This paper proposes \emph{Cyber Humanism in Education} as a framework for reclaiming human agency in this landscape. We conceptualise AI-enabled learning environments as socio-technical infrastructures co-authored by humans and machines, and position educators and learners as epistemic agents and \emph{algorithmic citizens} who have both the right and the responsibility to shape these infrastructures.
  We articulate three pillars for cyber-humanist design, \emph{reflexive competence}, \emph{algorithmic citizenship}, and \emph{dialogic design}, and relate them to major international digital and AI competence frameworks. We then present higher-education case studies that operationalise these ideas through \emph{prompt-based learning} and a new \emph{Conversational AI Educator} certification within the EPICT ecosystem. The findings show how such practices can strengthen epistemic agency while surfacing tensions around workload, equity, and governance, and outline implications for the future of AI-rich, human-centred education.

</details>


### [181] [Dual Computational Horizons: Incompleteness and Unpredictability in Intelligent Systems](https://arxiv.org/abs/2512.16707)
*Abhisek Ganguly*

Main category: cs.AI

TL;DR: 论文通过形式化分析两种计算限制，揭示了智能系统在自我预测和推理方面的固有局限。


<details>
  <summary>Details</summary>
Motivation: 探讨智能系统中算法代理的自我预测和推理能力的结构限制。

Method: 形式化分析了形式不完备性和动态不可预测性这两种计算限制。

Result: 算法代理通常无法计算其自身的最大预测范围。

Conclusion: 形式不完备性和动态不可预测性共同限制了智能系统的自我分析和预测能力。

Abstract: We formalize two independent computational limitations that constrain algorithmic intelligence: formal incompleteness and dynamical unpredictability. The former limits the deductive power of consistent reasoning systems while the later bounds long-term prediction under finite precision. We show that these two extrema together impose structural bounds on an agent's ability to reason about its own predictive capabilities. In particular, an algorithmic agent cannot compute its own maximal prediction horizon generally. This perspective clarifies inherent trade-offs between reasoning, prediction, and self-analysis in intelligent systems.

</details>


### [182] [Discovering and Learning Probabilistic Models of Black-Box AI Capabilities](https://arxiv.org/abs/2512.16733)
*Daniel Bramblett,Rushang Karia,Adrian Ciotinga,Ruthvick Suresh,Pulkit Verma,YooJung Choi,Siddharth Srivastava*

Main category: cs.AI

TL;DR: 本文提出用PDDL风格表示法和MCTS学习黑盒AI的规划能力，验证了方法的有效性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 为确保黑盒AI系统（如基础模型）在序列决策中的安全部署，需要开发高效方法以提供其能力的可靠且可解释的表示。

Method: 采用蒙特卡洛树搜索（MCTS）范式，系统化生成测试任务、获取数据并剪枝可能的符号模型假设空间。

Result: 学习到的模型能描述BBAI的能力、执行条件及可能结果（含概率）。理论与实证结果证明了方法的范围、效率和准确性。

Conclusion: 本文展示了PDDL风格的表示法可以有效学习和建模黑盒AI（BBAI）的规划能力，并通过理论和实证结果验证了方法的有效性。

Abstract: Black-box AI (BBAI) systems such as foundational models are increasingly being used for sequential decision making. To ensure that such systems are safe to operate and deploy, it is imperative to develop efficient methods that can provide a sound and interpretable representation of the BBAI's capabilities. This paper shows that PDDL-style representations can be used to efficiently learn and model an input BBAI's planning capabilities. It uses the Monte-Carlo tree search paradigm to systematically create test tasks, acquire data, and prune the hypothesis space of possible symbolic models. Learned models describe a BBAI's capabilities, the conditions under which they can be executed, and the possible outcomes of executing them along with their associated probabilities. Theoretical results show soundness, completeness and convergence of the learned models. Empirical results with multiple BBAI systems illustrate the scope, efficiency, and accuracy of the presented methods.

</details>


### [183] [AI-Driven Prediction of Cancer Pain Episodes: A Hybrid Decision Support Approach](https://arxiv.org/abs/2512.16739)
*Yipeng Zhuang,Yifeng Guo,Yuewen Li,Yuheng Wu,Philip Leung-Ho Yu,Tingting Song,Zhiyong Wang,Kunzhong Zhou,Weifang Wang,Li Zhuang*

Main category: cs.AI

TL;DR: 结合机器学习和大型语言模型的混合方法能有效预测肺癌患者的疼痛发作，提高预测准确性和灵敏度，优化临床资源分配。


<details>
  <summary>Details</summary>
Motivation: 肺癌患者经常经历突破性疼痛发作，高达91%需要及时干预。为了实现主动疼痛管理，研究团队开发了这一预测工具。

Method: 提出了一种结合机器学习和大型语言模型的混合管道，利用结构化和非结构化的电子健康记录数据预测48小时和72小时内的疼痛发作。机器学习模块捕捉了时间药物趋势，而大型语言模型解释了模糊的剂量记录和自由文本临床笔记。

Result: 该框架在48小时和72小时内的预测准确率分别达到0.874和0.917，由于大型语言模型的增强，灵敏度提高了8.6%和10.4%。

Conclusion: 该混合方法提供了一个临床可解释且可扩展的工具，用于早期疼痛发作预测，有望提高治疗精确度并优化肿瘤护理中的资源分配。

Abstract: Lung cancer patients frequently experience breakthrough pain episodes, with up to 91% requiring timely intervention. To enable proactive pain management, we propose a hybrid machine learning and large language model pipeline that predicts pain episodes within 48 and 72 hours of hospitalization using both structured and unstructured electronic health record data. A retrospective cohort of 266 inpatients was analyzed, with features including demographics, tumor stage, vital signs, and WHO-tiered analgesic use. The machine learning module captured temporal medication trends, while the large language model interpreted ambiguous dosing records and free-text clinical notes. Integrating these modalities improved sensitivity and interpretability. Our framework achieved an accuracy of 0.874 (48h) and 0.917 (72h), with an improvement in sensitivity of 8.6% and 10.4% due to the augmentation of large language model. This hybrid approach offers a clinically interpretable and scalable tool for early pain episode forecasting, with potential to enhance treatment precision and optimize resource allocation in oncology care.

</details>


### [184] [CitySeeker: How Do VLMS Explore Embodied Urban Navigation With Implicit Human Needs?](https://arxiv.org/abs/2512.16755)
*Siqi Wang,Chao Liang,Yunfan Gao,Erxin Yu,Sen Li,Yushi Li,Jing Li,Haofen Wang*

Main category: cs.AI

TL;DR: CitySeeker基准测试评估视觉语言模型在隐含需求导航中的表现，发现现有模型表现不佳，并提出BCR策略以改进空间智能。


<details>
  <summary>Details</summary>
Motivation: 探索视觉语言模型在动态城市环境中理解隐含人类需求（如“我口渴”）的能力，填补现有研究的空白。

Method: 通过CitySeeker基准测试评估模型性能，并引入BCR策略（回溯机制、增强空间认知和基于记忆的检索）进行分析。

Result: 实验显示，即使是表现最佳的模型（如Qwen2.5-VL-32B-Instruct）任务完成率仅为21.1%，主要瓶颈在于长时推理中的错误累积、空间认知不足和经验回忆缺陷。

Conclusion: CitySeeker基准测试揭示了当前视觉语言模型在解决隐含需求导航任务中的局限性，并提出了BCR策略作为改进方向，为开发具有更强空间智能的模型提供了实用见解。

Abstract: Vision-Language Models (VLMs) have made significant progress in explicit instruction-based navigation; however, their ability to interpret implicit human needs (e.g., "I am thirsty") in dynamic urban environments remains underexplored. This paper introduces CitySeeker, a novel benchmark designed to assess VLMs' spatial reasoning and decision-making capabilities for exploring embodied urban navigation to address implicit needs. CitySeeker includes 6,440 trajectories across 8 cities, capturing diverse visual characteristics and implicit needs in 7 goal-driven scenarios. Extensive experiments reveal that even top-performing models (e.g., Qwen2.5-VL-32B-Instruct) achieve only 21.1% task completion. We find key bottlenecks in error accumulation in long-horizon reasoning, inadequate spatial cognition, and deficient experiential recall. To further analyze them, we investigate a series of exploratory strategies-Backtracking Mechanisms, Enriching Spatial Cognition, and Memory-Based Retrieval (BCR), inspired by human cognitive mapping's emphasis on iterative observation-reasoning cycles and adaptive path optimization. Our analysis provides actionable insights for developing VLMs with robust spatial intelligence required for tackling "last-mile" navigation challenges.

</details>


### [185] [TOGGLE: Temporal Logic-Guided Large Language Model Compression for Edge](https://arxiv.org/abs/2512.16855)
*Khurram Khalil,Khaza Anuarul Hoque*

Main category: cs.AI

TL;DR: TOGGLE是一种新型框架，通过信号时序逻辑（STL）在压缩过程中形式化保留语言特性，无需重新训练或微调，显著降低LLM的计算成本和模型大小。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在自然语言任务中表现优异，但计算资源需求高，难以在资源受限的边缘设备上部署。现有压缩技术（如量化和剪枝）常损害关键语言特性且缺乏行为保留的形式化保证。

Method: TOGGLE利用信号时序逻辑（STL）形式化指定并强制执行压缩过程中的语言特性，采用STL鲁棒性引导的贝叶斯优化系统探索分层量化和剪枝配置。

Result: 在四种LLM架构（GPT-2、DeepSeek-V2 7B、LLaMA 3 8B和Mistral 7B）上评估，TOGGLE实现了计算成本（FLOPs）最高3.3倍的降低和模型大小最高68.8%的缩减，同时满足所有语言特性。

Conclusion: TOGGLE首次将形式化方法集成到LLM压缩中，实现了在边缘硬件上高效、可验证的LLM部署。

Abstract: Large Language Models (LLMs) deliver exceptional performance across natural language tasks but demand substantial computational resources, limiting their deployment on resource-constrained edge devices. Existing compression techniques, such as quantization and pruning, often degrade critical linguistic properties and lack formal guarantees for preserving model behavior. We propose Temporal Logic-Guided Large Language Model Compression (TOGGLE), a novel framework that leverages Signal Temporal Logic (STL) to formally specify and enforce linguistic properties during compression. TOGGLE employs an STL robustness-guided Bayesian optimization to systematically explore layer-wise quantization and pruning configurations, generating compressed models that formally satisfy specified linguistic constraints without retraining or fine-tuning. Evaluating TOGGLE on four LLM architectures (GPT-2, DeepSeek-V2 7B, LLaMA 3 8B, and Mistral 7B), we achieve up to 3.3x reduction in computational costs (FLOPs) and up to a 68.8% reduction in model size while satisfying all linguistic properties. TOGGLE represents the first integration of formal methods into LLM compression, enabling efficient, verifiable deployment of LLMs on edge hardware.

</details>


### [186] [Distributional AGI Safety](https://arxiv.org/abs/2512.16856)
*Nenad Tomašev,Matija Franklin,Julian Jacobs,Sébastien Krier,Simon Osindero*

Main category: cs.AI

TL;DR: 论文认为当前AI安全研究过于关注单个系统，忽视了多代理协调的潜在风险，提出了一个基于虚拟沙盒经济和市场机制的分布式安全框架。


<details>
  <summary>Details</summary>
Motivation: 现有AI安全和对齐研究主要关注单个AI系统，忽视了通过协调多个子AGI代理实现通用能力的假设。随着具备工具使用和协调能力的AI代理快速部署，这一假设需要被重视。

Method: 提出了一个框架，包括设计虚拟代理沙盒经济和实施市场机制，结合审计、声誉管理和监督。

Result: 提出了一个分布式的AGI安全框架，以应对由多个子AGI代理协调带来的集体风险。

Conclusion: 论文提出了一个分布式的AGI安全框架，强调通过虚拟代理沙盒经济和市场机制来管理代理间的交互，以应对集体风险。

Abstract: AI safety and alignment research has predominantly been focused on methods for safeguarding individual AI systems, resting on the assumption of an eventual emergence of a monolithic Artificial General Intelligence (AGI). The alternative AGI emergence hypothesis, where general capability levels are first manifested through coordination in groups of sub-AGI individual agents with complementary skills and affordances, has received far less attention. Here we argue that this patchwork AGI hypothesis needs to be given serious consideration, and should inform the development of corresponding safeguards and mitigations. The rapid deployment of advanced AI agents with tool-use capabilities and the ability to communicate and coordinate makes this an urgent safety consideration. We therefore propose a framework for distributional AGI safety that moves beyond evaluating and aligning individual agents. This framework centers on the design and implementation of virtual agentic sandbox economies (impermeable or semi-permeable), where agent-to-agent transactions are governed by robust market mechanisms, coupled with appropriate auditability, reputation management, and oversight to mitigate collective risks.

</details>


### [187] [The Social Responsibility Stack: A Control-Theoretic Architecture for Governing Socio-Technical AI](https://arxiv.org/abs/2512.16873)
*Otman A. Basir*

Main category: cs.AI

TL;DR: 该论文提出SRS框架，通过六层架构将社会价值观嵌入AI系统，结合设计时保障与运行时监控，为可审计的社会技术AI系统提供实用方案。


<details>
  <summary>Details</summary>
Motivation: 随着AI系统越来越多地部署在影响人类行为、机构决策和社会结果的领域，现有的负责任AI和治理工作提供了重要的规范原则，但往往缺乏可执行的工程机制。

Method: 论文引入了社会责任感堆栈（SRS），这是一个六层架构框架，将社会价值观作为明确约束、保障措施、行为接口、审计机制和治理流程嵌入AI系统。SRS将责任感建模为对技术系统的闭环监督控制问题，整合设计时保障措施与运行时监控和机构监督。

Result: 案例研究表明，SRS能够将规范目标转化为可操作的工程和运营控制，展示了其在临床决策支持、协作自动驾驶和公共部门系统中的实际应用。

Conclusion: 该论文提出了社会责任感堆栈（SRS）框架，通过六层架构将社会价值观嵌入AI系统，为可问责、自适应和可审计的社会技术AI系统提供了实用基础。

Abstract: Artificial intelligence systems are increasingly deployed in domains that shape human behaviour, institutional decision-making, and societal outcomes. Existing responsible AI and governance efforts provide important normative principles but often lack enforceable engineering mechanisms that operate throughout the system lifecycle. This paper introduces the Social Responsibility Stack (SRS), a six-layer architectural framework that embeds societal values into AI systems as explicit constraints, safeguards, behavioural interfaces, auditing mechanisms, and governance processes. SRS models responsibility as a closed-loop supervisory control problem over socio-technical systems, integrating design-time safeguards with runtime monitoring and institutional oversight. We develop a unified constraint-based formulation, introduce safety-envelope and feedback interpretations, and show how fairness, autonomy, cognitive burden, and explanation quality can be continuously monitored and enforced. Case studies in clinical decision support, cooperative autonomous vehicles, and public-sector systems illustrate how SRS translates normative objectives into actionable engineering and operational controls. The framework bridges ethics, control theory, and AI governance, providing a practical foundation for accountable, adaptive, and auditable socio-technical AI systems.

</details>


### [188] [Generative Adversarial Reasoner: Enhancing LLM Reasoning with Adversarial Reinforcement Learning](https://arxiv.org/abs/2512.16917)
*Qihao Liu,Luoxin Ye,Wufei Ma,Yu-Cheng Chou,Alan Yuille*

Main category: cs.AI

TL;DR: 提出Generative Adversarial Reasoner框架，通过对抗性强化学习提升LLMs的数学推理能力，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在数学推理方面表现优异，但仍存在计算错误、逻辑脆弱等问题，因此需要一种更高效的方法来提升其推理质量。

Method: 采用对抗性强化学习方法，联合训练LLM推理器和基于LLM的判别器，通过逻辑切片和结构化评估生成密集的步骤级奖励。

Result: 在AIME24等数学基准测试中，该方法显著提升了模型性能，如DeepSeek-R1-Distill-Qwen-7B从54.0提升至61.3。

Conclusion: Generative Adversarial Reasoner框架通过对抗性强化学习显著提升了LLMs的数学推理能力，并在多个基准测试中取得了显著改进。

Abstract: Large language models (LLMs) with explicit reasoning capabilities excel at mathematical reasoning yet still commit process errors, such as incorrect calculations, brittle logic, and superficially plausible but invalid steps. In this paper, we introduce Generative Adversarial Reasoner, an on-policy joint training framework designed to enhance reasoning by co-evolving an LLM reasoner and an LLM-based discriminator through adversarial reinforcement learning. A compute-efficient review schedule partitions each reasoning chain into logically complete slices of comparable length, and the discriminator evaluates each slice's soundness with concise, structured justifications. Learning couples complementary signals: the LLM reasoner is rewarded for logically consistent steps that yield correct answers, while the discriminator earns rewards for correctly detecting errors or distinguishing traces in the reasoning process. This produces dense, well-calibrated, on-policy step-level rewards that supplement sparse exact-match signals, improving credit assignment, increasing sample efficiency, and enhancing overall reasoning quality of LLMs. Across various mathematical benchmarks, the method delivers consistent gains over strong baselines with standard RL post-training. Specifically, on AIME24, we improve DeepSeek-R1-Distill-Qwen-7B from 54.0 to 61.3 (+7.3) and DeepSeek-R1-Distill-Llama-8B from 43.7 to 53.7 (+10.0). The modular discriminator also enables flexible reward shaping for objectives such as teacher distillation, preference alignment, and mathematical proof-based reasoning.

</details>


<div id='cs.OS'></div>

# cs.OS [[Back]](#toc)

### [189] [Trustworthy and Controllable Professional Knowledge Utilization in Large Language Models with TEE-GPU Execution](https://arxiv.org/abs/2512.16238)
*Yifeng Cai,Zhida An,Yuhan Meng,Houqian Liu,Pengli Wang,Yao Guo,Ding Li*

Main category: cs.OS

TL;DR: PKUS 是一种专业知识利用系统，通过 TEE 和适配器设计，平衡了模型效用与推理效率，解决了提供商参与意愿低的问题。


<details>
  <summary>Details</summary>
Motivation: 专业知识的提供商面临收入与风险的失衡，现有技术无法提供可信且可控的知识利用方式，促使了 PKUS 的设计。

Method: PKUS 将专业知识作为独立构件处理，使用紧凑的适配器编码，并在 TEE 中执行。结合硬件生命周期协议、适配器剪枝、多提供商聚合和分片执行调度，实现了高效服务。

Result: 在多个数据集和模型上，PKUS 保持了模型效用（准确率和 F1 分数），同时实现了最低的每请求延迟，比纯 CPU TEE 推理和 CPU-GPU 协同执行快 8.1-11.9 倍。

Conclusion: PKUS 提出了一种可信且可控的专业知识利用系统，通过将专业知识编码为紧凑的适配器并在可信执行环境（TEE）中执行，既保留了模型效用，又显著提升了推理速度。

Abstract: Future improvements in large language model (LLM) services increasingly hinge on access to high-value professional knowledge rather than more generic web data. However, the data providers of this knowledge face a skewed tradeoff between income and risk: they receive little share of downstream value yet retain copyright and privacy liability, making them reluctant to contribute their assets to LLM services. Existing techniques do not offer a trustworthy and controllable way to use professional knowledge, because they keep providers in the dark and combine knowledge parameters with the underlying LLM backbone.
  In this paper, we present PKUS, the Professional Knowledge Utilization System, which treats professional knowledge as a first-class, separable artifact. PKUS keeps the backbone model on GPUs and encodes each provider's contribution as a compact adapter that executes only inside an attested Trusted Execution Environment (TEE). A hardware-rooted lifecycle protocol, adapter pruning, multi-provider aggregation, and split-execution scheduling together make this design practical at serving time. On SST-2, MNLI, and SQuAD with GPT-2 Large and Llama-3.2-1B, PKUS preserves model utility, matching the accuracy and F1 of full fine-tuning and plain LoRA, while achieving the lowest per-request latency with 8.1-11.9x speedup over CPU-only TEE inference and naive CPU-GPU co-execution.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [190] [Large Video Planner Enables Generalizable Robot Control](https://arxiv.org/abs/2512.15840)
*Boyuan Chen,Tianyuan Zhang,Haoran Geng,Kiwhan Song,Caiyi Zhang,Peihao Li,William T. Freeman,Jitendra Malik,Pieter Abbeel,Russ Tedrake,Vincent Sitzmann,Yilun Du*

Main category: cs.RO

TL;DR: 该论文提出了一种基于大规模视频预训练的机器人基础模型，通过零样本视频规划和实际执行验证了其泛化能力和现实可行性。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于探索不同于多模态大型语言模型（MLLMs）的替代范式，利用视频预训练捕捉与机器人行为自然对齐的时空状态和动作序列。

Method: 研究者构建了一个互联网规模的人类活动视频数据集，并首次在基础模型规模上训练了一个开放视频模型，用于生成机器人规划。

Result: 模型能够为零样本新场景和任务生成视频规划，并通过后处理提取可执行的机器人动作，在第三方任务和真实机器人实验中展示了成功的物理执行能力。

Conclusion: 该研究展示了基于大规模视频预训练的机器人基础模型的潜力，通过零样本视频规划和实际机器人执行验证了其泛化能力和现实可行性。

Abstract: General-purpose robots require decision-making models that generalize across diverse tasks and environments. Recent works build robot foundation models by extending multimodal large language models (MLLMs) with action outputs, creating vision-language-action (VLA) systems. These efforts are motivated by the intuition that MLLMs' large-scale language and image pretraining can be effectively transferred to the action output modality. In this work, we explore an alternative paradigm of using large-scale video pretraining as a primary modality for building robot foundation models. Unlike static images and language, videos capture spatio-temporal sequences of states and actions in the physical world that are naturally aligned with robotic behavior. We curate an internet-scale video dataset of human activities and task demonstrations, and train, for the first time at a foundation-model scale, an open video model for generative robotics planning. The model produces zero-shot video plans for novel scenes and tasks, which we post-process to extract executable robot actions. We evaluate task-level generalization through third-party selected tasks in the wild and real-robot experiments, demonstrating successful physical execution. Together, these results show robust instruction following, strong generalization, and real-world feasibility. We release both the model and dataset to support open, reproducible video-based robot learning. Our website is available at https://www.boyuan.space/large-video-planner/.

</details>


### [191] [SORS: A Modular, High-Fidelity Simulator for Soft Robots](https://arxiv.org/abs/2512.15994)
*Manuel Mekkattu,Mike Y. Michelis,Robert K. Katzschmann*

Main category: cs.RO

TL;DR: SORS是一个高保真软机器人模拟器，通过能量框架和优化接触处理，解决了现有模拟器在可扩展性和保真度上的不足，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 复杂软机器人在多物理环境中的部署需要先进的模拟框架，以准确捕捉材料间的相互作用并反映真实性能，但现有模拟器在可扩展性和应用相关性方面存在不足。

Method: 基于有限元方法的能量框架，结合顺序二次规划的约束非线性优化，实现了物理一致的接触处理。

Result: 通过多种真实实验（如悬臂梁偏转、软机械臂的压力驱动等）验证了模拟器在材料行为和复杂驱动动力学方面的高保真度。

Conclusion: SORS（Soft Over Rigid Simulator）通过高保真模拟和模块化扩展，填补了软机器人生态系统在可扩展性、保真度和可用性方面的空白，为下一代软机器人的原型设计提供了验证工具。

Abstract: The deployment of complex soft robots in multiphysics environments requires advanced simulation frameworks that not only capture interactions between different types of material, but also translate accurately to real-world performance. Soft robots pose unique modeling challenges due to their large nonlinear deformations, material incompressibility, and contact interactions, which complicate both numerical stability and physical accuracy. Despite recent progress, robotic simulators often struggle with modeling such phenomena in a scalable and application-relevant manner. We present SORS (Soft Over Rigid Simulator), a versatile, high-fidelity simulator designed to handle these complexities for soft robot applications. Our energy-based framework, built on the finite element method, allows modular extensions, enabling the inclusion of custom-designed material and actuation models. To ensure physically consistent contact handling, we integrate a constrained nonlinear optimization based on sequential quadratic programming, allowing for stable and accurate modeling of contact phenomena. We validate our simulator through a diverse set of real-world experiments, which include cantilever deflection, pressure-actuation of a soft robotic arm, and contact interactions from the PokeFlex dataset. In addition, we showcase the potential of our framework for control optimization of a soft robotic leg. These tests confirm that our simulator can capture both fundamental material behavior and complex actuation dynamics with high physical fidelity. By bridging the sim-to-real gap in these challenging domains, our approach provides a validated tool for prototyping next-generation soft robots, filling the gap of extensibility, fidelity, and usability in the soft robotic ecosystem.

</details>


### [192] [dLITE: Differentiable Lighting-Informed Trajectory Evaluation for On-Orbit Inspection](https://arxiv.org/abs/2512.16011)
*Jack Naylor,Raghav Mishra,Nicholas H. Barbara,Donald G. Dansereau*

Main category: cs.RO

TL;DR: $\partial$LITE是一种可微分模拟管道，用于优化在轨检查轨迹，显著提升数据质量。


<details>
  <summary>Details</summary>
Motivation: 低地球轨道（LEO）环境中的光照和相对运动对检查操作的数据质量构成挑战，现有方法在优化检查轨迹以改善图像质量方面存在不足。

Method: 利用最先进的可微分渲染工具和自定义轨道传播器，实现了基于视觉传感器数据的端到端轨道参数优化。

Result: $\partial$LITE能够自动设计非直观的轨迹，极大提升了获取数据的质量和实用性。

Conclusion: 该论文提出了$\partial$LITE，一种端到端可微分的模拟管道，用于优化在轨检查操作的轨迹设计，显著提高了数据质量和实用性。

Abstract: Visual inspection of space-borne assets is of increasing interest to spacecraft operators looking to plan maintenance, characterise damage, and extend the life of high-value satellites in orbit. The environment of Low Earth Orbit (LEO) presents unique challenges when planning inspection operations that maximise visibility, information, and data quality. Specular reflection of sunlight from spacecraft bodies, self-shadowing, and dynamic lighting in LEO significantly impact the quality of data captured throughout an orbit. This is exacerbated by the relative motion between spacecraft, which introduces variable imaging distances and attitudes during inspection. Planning inspection trajectories with the aide of simulation is a common approach. However, the ability to design and optimise an inspection trajectory specifically to improve the resulting image quality in proximity operations remains largely unexplored. In this work, we present $\partial$LITE, an end-to-end differentiable simulation pipeline for on-orbit inspection operations. We leverage state-of-the-art differentiable rendering tools and a custom orbit propagator to enable end-to-end optimisation of orbital parameters based on visual sensor data. $\partial$LITE enables us to automatically design non-obvious trajectories, vastly improving the quality and usefulness of attained data. To our knowledge, our differentiable inspection-planning pipeline is the first of its kind and provides new insights into modern computational approaches to spacecraft mission planning. Project page: https://appearance-aware.github.io/dlite/

</details>


### [193] [Few-Shot Inference of Human Perceptions of Robot Performance in Social Navigation Scenarios](https://arxiv.org/abs/2512.16019)
*Qiping Zhang,Nathan Tsoi,Mofeed Nagib,Hao-Tien Lewis Chiang,Marynel Vázquez*

Main category: cs.RO

TL;DR: 利用LLMs的少样本学习能力预测人类对机器人行为的感知，实验证明其在少量数据下优于传统方法，且个性化示例能进一步提升准确性。


<details>
  <summary>Details</summary>
Motivation: 传统方法需要大量标注数据，限制了数据驱动方法在实际中的应用，因此探索少样本学习的潜力。

Method: 扩展了SEAN TOGETHER数据集，增加了真实世界的人机导航片段和参与者反馈，并评估了多种LLMs基于少量上下文示例预测人类感知的能力。

Result: LLMs在少量标注实例下表现优于传统监督学习模型，且性能随上下文示例增加而提升。个性化示例进一步提高了预测准确性。

Conclusion: 本研究通过利用大型语言模型（LLMs）的少样本学习能力，提出了一种可扩展的方法来预测人类对机器人性能的感知，从而为开发符合人类期望的社交机器人提供了新途径。

Abstract: Understanding how humans evaluate robot behavior during human-robot interactions is crucial for developing socially aware robots that behave according to human expectations. While the traditional approach to capturing these evaluations is to conduct a user study, recent work has proposed utilizing machine learning instead. However, existing data-driven methods require large amounts of labeled data, which limits their use in practice. To address this gap, we propose leveraging the few-shot learning capabilities of Large Language Models (LLMs) to improve how well a robot can predict a user's perception of its performance, and study this idea experimentally in social navigation tasks. To this end, we extend the SEAN TOGETHER dataset with additional real-world human-robot navigation episodes and participant feedback. Using this augmented dataset, we evaluate the ability of several LLMs to predict human perceptions of robot performance from a small number of in-context examples, based on observed spatio-temporal cues of the robot and surrounding human motion. Our results demonstrate that LLMs can match or exceed the performance of traditional supervised learning models while requiring an order of magnitude fewer labeled instances. We further show that prediction performance can improve with more in-context examples, confirming the scalability of our approach. Additionally, we investigate what kind of sensor-based information an LLM relies on to make these inferences by conducting an ablation study on the input features considered for performance prediction. Finally, we explore the novel application of personalized examples for in-context learning, i.e., drawn from the same user being evaluated, finding that they further enhance prediction accuracy. This work paves the path to improving robot behavior in a scalable manner through user-centered feedback.

</details>


### [194] [Maintaining the Level of a Payload carried by Multi-Robot System on Irregular Surface](https://arxiv.org/abs/2512.16024)
*Rishabh Dev Yadav,Shrey Agrawal,Kamalakar Karlapalem*

Main category: cs.RO

TL;DR: 本文介绍了一种多机器人负载运输系统，通过结合开环和闭环PID控制器，在未知和不平坦地形上成功保持负载方向。


<details>
  <summary>Details</summary>
Motivation: 为了解决在未知和不平坦倾斜环境中运输负载并保持其所需方向的问题，设计了这一多机器人负载运输系统。

Method: 使用定制机器人，每个机器人顶部安装线性执行器（活塞），系统持续监测负载方向并计算每个机器人所需的活塞高度。提出了一种开环控制器与闭环PID控制器结合的方法。

Result: 系统在多种模拟环境中进行了测试，展示了其在不同和复杂地形上的有效性。

Conclusion: 该系统通过结合开环控制器和闭环PID控制器，成功实现了在未知和不平坦地形上保持负载所需方向的目标，展示了其在不同复杂地形中的有效性。

Abstract: In this paper, we introduce a multi robot payload transport system to carry payloads through an environment of unknown and uneven inclinations while maintaining the desired orientation of the payload. For this task, we used custom built robots with a linear actuator (pistons) mounted on top of each robot. The system continuously monitors the payload's orientation and computes the required piston height of each robot to maintain the desired orientation of the payload. In this work, we propose an open loop controller coupled with a closed loop PID controller to achieve the goal. As our modelling makes no assumptions on the type of terrain, the system can work on any unknown and uneven terrains and inclinations. We showcase the efficacy of our proposed controller by testing it on various simulated environments with varied and complex terrains.

</details>


### [195] [SWIFT-Nav: Stability-Aware Waypoint-Level TD3 with Fuzzy Arbitration for UAV Navigation in Cluttered Environments](https://arxiv.org/abs/2512.16027)
*Shuaidong Ji,Mahdi Bamdad,Francisco Cruz*

Main category: cs.RO

TL;DR: SWIFT-Nav是一个基于TD3的导航框架，通过结合模糊仲裁和优先经验回放，实现了无人机在复杂环境中的快速稳定导航。


<details>
  <summary>Details</summary>
Motivation: 在复杂和动态环境中实现高效可靠的无人机导航仍然具有挑战性。

Method: 提出了SWIFT-Nav框架，结合传感器驱动的感知前端和TD3路径点策略，使用优先经验回放和衰减的ε-贪婪探索计划进行训练，并引入轻量级模糊逻辑层计算安全分数。

Result: 在轨迹平滑性和对未见布局的泛化能力上优于基线方法，同时保持实时响应性。

Conclusion: 结合TD3与回放优先级、校准探索和模糊安全规则，为无人机在复杂场景中的导航提供了一个稳健且可部署的解决方案。

Abstract: Efficient and reliable UAV navigation in cluttered and dynamic environments remains challenging. We propose SWIFT-Nav: Stability-aware Waypoint-level Integration of Fuzzy arbitration and TD3 for Navigation, a TD3-based navigation framework that achieves fast, stable convergence to obstacle-aware paths. The system couples a sensor-driven perception front end with a TD3 waypoint policy: the perception module converts LiDAR ranges into a confidence-weighted safety map and goal cues, while the TD3 policy is trained with Prioritised Experience Replay to focus on high-error transitions and a decaying epsilon-greedy exploration schedule that gradually shifts from exploration to exploitation. A lightweight fuzzy-logic layer computes a safety score from radial measurements and near obstacles, gates mode switching and clamps unsafe actions; in parallel, task-aligned reward shaping combining goal progress, clearance, and switch-economy terms provides dense, well-scaled feedback that accelerates learning. Implemented in Webots with proximity-based collision checking, our approach consistently outperforms baselines in trajectory smoothness and generalization to unseen layouts, while preserving real-time responsiveness. These results show that combining TD3 with replay prioritisation, calibrated exploration, and fuzzy-safety rules yields a robust and deployable solution for UAV navigation in cluttered scenes.

</details>


### [196] [Sceniris: A Fast Procedural Scene Generation Framework](https://arxiv.org/abs/2512.16896)
*Jinghuan Shang,Harsh Patel,Ran Gong,Karl Schmeckpeper*

Main category: cs.RO

TL;DR: Sceniris是一个高效的场景生成框架，通过优化碰撞检查和批量采样，实现了比现有方法快234倍的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有的程序化生成方法输出吞吐量低，成为扩展数据集创建的主要瓶颈。

Method: 通过批量采样和cuRobo中更快的碰撞检查，Sceniris实现了比Scene Synthesizer至少234倍的加速。

Result: Sceniris不仅显著提升了生成速度，还扩展了对象间的空间关系，以满足多样化的场景需求。

Conclusion: Sceniris是一个高效的程序化场景生成框架，显著提升了大规模、无碰撞场景变体的生成速度，并支持机器人任务的操作可行性检查。

Abstract: Synthetic 3D scenes are essential for developing Physical AI and generative models. Existing procedural generation methods often have low output throughput, creating a significant bottleneck in scaling up dataset creation. In this work, we introduce Sceniris, a highly efficient procedural scene generation framework for rapidly generating large-scale, collision-free scene variations. Sceniris also provides an optional robot reachability check, providing manipulation-feasible scenes for robot tasks. Sceniris is designed for maximum efficiency by addressing the primary performance limitations of the prior method, Scene Synthesizer. Leveraging batch sampling and faster collision checking in cuRobo, Sceniris achieves at least 234x speed-up over Scene Synthesizer. Sceniris also expands the object-wise spatial relationships available in prior work to support diverse scene requirements. Our code is available at https://github.com/rai-inst/sceniris

</details>


### [197] [A Task-Driven, Planner-in-the-Loop Computational Design Framework for Modular Manipulators](https://arxiv.org/abs/2512.16069)
*Maolin Lei,Edoardo Romiti,Arturo Laurenzi,Rui Dai,Matteo Dalle Vedove,Jiatao Ding,Daniele Fontanelli,Nikos Tsagarakis*

Main category: cs.RO

TL;DR: 论文提出一个任务驱动的框架，整合轨迹规划和形态优化，通过HMPC和CMA-ES解决模块化机械臂的运动和设计问题，实验验证其有效性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 模块化机械臂虽然具有高适应性，但其部署需要同时优化形态和安装姿态，传统单分支设计在扩展工作空间时易违反扭矩限制。为此，论文提出一个统一框架来解决这些问题。

Method: 论文采用分层模型预测控制（HMPC）策略进行运动规划，并利用CMA-ES算法优化离散形态配置和连续安装姿态的混合搜索空间。此外，引入了虚拟模块抽象以实现双分支形态。

Result: 仿真和硬件实验表明，该框架能生成满足运动学和动力学约束的多种可行设计，并实现如最大化可操作性、最小化关节负荷或减少模块数量等灵活目标。双分支形态可在不增加基础模块能力的情况下扩展工作空间。

Conclusion: 该论文提出了一个统一的任务驱动计算框架，通过整合轨迹规划和形态优化，解决了模块化机械臂在运动规划和设计优化中的挑战。实验验证了框架的有效性，能够生成满足多种约束的可行设计，并实现灵活的设计目标。

Abstract: Modular manipulators composed of pre-manufactured and interchangeable modules offer high adaptability across diverse tasks. However, their deployment requires generating feasible motions while jointly optimizing morphology and mounted pose under kinematic, dynamic, and physical constraints. Moreover, traditional single-branch designs often extend reach by increasing link length, which can easily violate torque limits at the base joint. To address these challenges, we propose a unified task-driven computational framework that integrates trajectory planning across varying morphologies with the co-optimization of morphology and mounted pose. Within this framework, a hierarchical model predictive control (HMPC) strategy is developed to enable motion planning for both redundant and non-redundant manipulators. For design optimization, the CMA-ES is employed to efficiently explore a hybrid search space consisting of discrete morphology configurations and continuous mounted poses. Meanwhile, a virtual module abstraction is introduced to enable bi-branch morphologies, allowing an auxiliary branch to offload torque from the primary branch and extend the achievable workspace without increasing the capacity of individual joint modules. Extensive simulations and hardware experiments on polishing, drilling, and pick-and-place tasks demonstrate the effectiveness of the proposed framework. The results show that: 1) the framework can generate multiple feasible designs that satisfy kinematic and dynamic constraints while avoiding environmental collisions for given tasks; 2) flexible design objectives, such as maximizing manipulability, minimizing joint effort, or reducing the number of modules, can be achieved by customizing the cost functions; and 3) a bi-branch morphology capable of operating in a large workspace can be realized without requiring more powerful basic modules.

</details>


### [198] [A simulation platform calibration method for automated vehicle evaluation: accurate on both vehicle level and traffic flow level](https://arxiv.org/abs/2512.16076)
*Jia Hu,Junqi Li,Xuerun Yan,Jintao Lai,Lianhua An*

Main category: cs.RO

TL;DR: 提出一种高精度、全自动的仿真平台校准方法，显著提升自动驾驶车辆与背景交通交互的复现准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有校准方法在准确复现自动驾驶车辆与背景交通交互方面存在不足，本研究旨在填补这一空白。

Method: 该方法具备车辆间交互校准能力，提供准确性保证，提升效率，并支持流水线校准。

Result: 该方法将交互复现准确性提升了83.53%，校准效率提高了76.75%，并在车辆和交通流层面均保持了51.9%的准确性提升。

Conclusion: 该研究提出了一种高精度的仿真平台校准方法，显著提升了自动驾驶车辆与背景交通交互的复现准确性，并实现了全自动化校准流程。

Abstract: Simulation testing is a fundamental approach for evaluating automated vehicles (AVs). To ensure its reliability, it is crucial to accurately replicate interactions between AVs and background traffic, which necessitates effective calibration. However, existing calibration methods often fall short in achieving this goal. To address this gap, this study introduces a simulation platform calibration method that ensures high accuracy at both the vehicle and traffic flow levels. The method offers several key features:(1) with the capability of calibration for vehicle-to-vehicle interaction; (2) with accuracy assurance; (3) with enhanced efficiency; (4) with pipeline calibration capability. The proposed method is benchmarked against a baseline with no calibration and a state-of-the-art calibration method. Results show that it enhances the accuracy of interaction replication by 83.53% and boosts calibration efficiency by 76.75%. Furthermore, it maintains accuracy across both vehicle-level and traffic flow-level metrics, with an improvement of 51.9%. Notably, the entire calibration process is fully automated, requiring no human intervention.

</details>


### [199] [ManiLong-Shot: Interaction-Aware One-Shot Imitation Learning for Long-Horizon Manipulation](https://arxiv.org/abs/2512.16302)
*Zixuan Chen,Chongkai Gao,Lin Shao,Jieqi Shi,Jing Huo,Yang Gao*

Main category: cs.RO

TL;DR: ManiLong-Shot通过基元分解和交互感知，实现了一次性模仿学习在长视野操作任务中的高效应用，性能显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前一次性模仿学习方法主要局限于短视野任务，难以应用于复杂长视野操作任务。

Method: ManiLong-Shot利用物理交互事件重构长视野任务，通过视觉语言模型或基于机器人状态变化的启发式规则驱动基元分解，预测关键不变区域并建立演示与当前观察的对应关系。

Result: 在仅训练10个短视野任务的情况下，ManiLong-Shot通过一次性模仿学习在20个未见过的长视野任务上实现了22.8%的相对性能提升，并在真实机器人实验中验证了其鲁棒性。

Conclusion: ManiLong-Shot通过将长视野任务分解为交互感知的基元序列，显著提升了一次性模仿学习在复杂长视野操作任务中的性能和应用范围。

Abstract: One-shot imitation learning (OSIL) offers a promising way to teach robots new skills without large-scale data collection. However, current OSIL methods are primarily limited to short-horizon tasks, thus limiting their applicability to complex, long-horizon manipulations. To address this limitation, we propose ManiLong-Shot, a novel framework that enables effective OSIL for long-horizon prehensile manipulation tasks. ManiLong-Shot structures long-horizon tasks around physical interaction events, reframing the problem as sequencing interaction-aware primitives instead of directly imitating continuous trajectories. This primitive decomposition can be driven by high-level reasoning from a vision-language model (VLM) or by rule-based heuristics derived from robot state changes. For each primitive, ManiLong-Shot predicts invariant regions critical to the interaction, establishes correspondences between the demonstration and the current observation, and computes the target end-effector pose, enabling effective task execution. Extensive simulation experiments show that ManiLong-Shot, trained on only 10 short-horizon tasks, generalizes to 20 unseen long-horizon tasks across three difficulty levels via one-shot imitation, achieving a 22.8% relative improvement over the SOTA. Additionally, real-robot experiments validate ManiLong-Shot's ability to robustly execute three long-horizon manipulation tasks via OSIL, confirming its practical applicability.

</details>


### [200] [A2VISR: An Active and Adaptive Ground-Aerial Localization System Using Visual Inertial and Single-Range Fusion](https://arxiv.org/abs/2512.16367)
*Sijia Chen,Wei Dong*

Main category: cs.RO

TL;DR: 论文提出了一种地面-空中协作系统，通过综合多种传感器和动态调整策略，显著提升了飞行机器人在复杂环境中的定位鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖固定摄像头和预附标记，存在距离限制和捕获失败的问题。为了解决这些问题，论文提出了一种更全面的地面-空中定位框架。

Method: 论文采用了一种综合方法，包括主动视觉子系统、单点测距、惯性里程计和光流技术。通过动态旋转地面车辆上的摄像头来跟踪空中机器人的红外标记，结合维度降低的估计器和自适应滑动置信度评估算法，优化了定位性能。

Result: 实验表明，该方法在烟雾干扰、光照变化、障碍物遮挡等条件下，平均均方根误差约为0.09米，且对捕获丢失和传感器故障具有强韧性。

Conclusion: 该论文提出的地面-空中协作系统通过综合多种传感器和动态调整策略，显著提升了飞行机器人在复杂环境中的定位鲁棒性，尤其在视觉传感器性能下降时表现优异。

Abstract: It's a practical approach using the ground-aerial collaborative system to enhance the localization robustness of flying robots in cluttered environments, especially when visual sensors degrade. Conventional approaches estimate the flying robot's position using fixed cameras observing pre-attached markers, which could be constrained by limited distance and susceptible to capture failure. To address this issue, we improve the ground-aerial localization framework in a more comprehensive manner, which integrates active vision, single-ranging, inertial odometry, and optical flow. First, the designed active vision subsystem mounted on the ground vehicle can be dynamically rotated to detect and track infrared markers on the aerial robot, improving the field of view and the target recognition with a single camera. Meanwhile, the incorporation of single-ranging extends the feasible distance and enhances re-capture capability under visual degradation. During estimation, a dimension-reduced estimator fuses multi-source measurements based on polynomial approximation with an extended sliding window, balancing computational efficiency and redundancy. Considering different sensor fidelities, an adaptive sliding confidence evaluation algorithm is implemented to assess measurement quality and dynamically adjust the weighting parameters based on moving variance. Finally, extensive experiments under conditions such as smoke interference, illumination variation, obstacle occlusion, prolonged visual loss, and extended operating range demonstrate that the proposed approach achieves robust online localization, with an average root mean square error of approximately 0.09 m, while maintaining resilience to capture loss and sensor failures.

</details>


### [201] [E-SDS: Environment-aware See it, Do it, Sorted - Automated Environment-Aware Reinforcement Learning for Humanoid Locomotion](https://arxiv.org/abs/2512.16446)
*Enis Yalcin,Joshua O'Hara,Maria Stamatopoulou,Chengxu Zhou,Dimitrios Kanoulas*

Main category: cs.RO

TL;DR: E-SDS通过结合VLM和地形感知，自动生成奖励函数，显著提升人形机器人在复杂地形中的移动能力，减少人工设计时间。


<details>
  <summary>Details</summary>
Motivation: 当前基于VLM的方法缺乏环境感知能力，无法在复杂地形中导航，因此需要一种能自动生成感知奖励函数的框架。

Method: E-SDS整合了视觉语言模型（VLMs）和实时地形传感器分析，通过示例视频自动生成奖励函数，训练具有环境感知能力的移动策略。

Result: 在四种不同地形（简单、间隙、障碍、楼梯）上测试，E-SDS是唯一能成功完成楼梯下降任务的框架，同时将速度跟踪误差降低了51.9-82.6%。

Conclusion: E-SDS框架显著减少了人工设计奖励函数的工作量，同时生成了更鲁棒和高效的移动策略，尤其在复杂地形（如楼梯）中表现突出。

Abstract: Vision-language models (VLMs) show promise in automating reward design in humanoid locomotion, which could eliminate the need for tedious manual engineering. However, current VLM-based methods are essentially "blind", as they lack the environmental perception required to navigate complex terrain. We present E-SDS (Environment-aware See it, Do it, Sorted), a framework that closes this perception gap. E-SDS integrates VLMs with real-time terrain sensor analysis to automatically generate reward functions that facilitate training of robust perceptive locomotion policies, grounded by example videos. Evaluated on a Unitree G1 humanoid across four distinct terrains (simple, gaps, obstacles, stairs), E-SDS uniquely enabled successful stair descent, while policies trained with manually-designed rewards or a non-perceptive automated baseline were unable to complete the task. In all terrains, E-SDS also reduced velocity tracking error by 51.9-82.6%. Our framework reduces the human effort of reward design from days to less than two hours while simultaneously producing more robust and capable locomotion policies.

</details>


### [202] [Single-View Shape Completion for Robotic Grasping in Clutter](https://arxiv.org/abs/2512.16449)
*Abhishek Kashyap,Yuxuan Yang,Henrik Andreasson,Todor Stoyanov*

Main category: cs.RO

TL;DR: 通过扩散模型补全单视角观测的3D形状，提升复杂场景下的机器人抓取成功率。


<details>
  <summary>Details</summary>
Motivation: 单视角相机在复杂场景中仅能捕捉物体的一侧且易受遮挡，导致几何信息不完整，影响抓取算法的性能。

Method: 利用扩散模型从单视角的局部深度观测中重建完整3D形状，为抓取推理网络提供更丰富的上下文信息。

Result: 在复杂场景的初步评估中，该方法比未进行形状补全的基线抓取成功率提高23%，比现有形状补全方法提高19%。

Conclusion: 通过扩散模型从单视角深度观测完成类别级3D形状重建，显著提升了抓取规划的成功率。

Abstract: In vision-based robot manipulation, a single camera view can only capture one side of objects of interest, with additional occlusions in cluttered scenes further restricting visibility. As a result, the observed geometry is incomplete, and grasp estimation algorithms perform suboptimally. To address this limitation, we leverage diffusion models to perform category-level 3D shape completion from partial depth observations obtained from a single view, reconstructing complete object geometries to provide richer context for grasp planning. Our method focuses on common household items with diverse geometries, generating full 3D shapes that serve as input to downstream grasp inference networks. Unlike prior work, which primarily considers isolated objects or minimal clutter, we evaluate shape completion and grasping in realistic clutter scenarios with household objects. In preliminary evaluations on a cluttered scene, our approach consistently results in better grasp success rates than a naive baseline without shape completion by 23% and over a recent state of the art shape completion approach by 19%. Our code is available at https://amm.aass.oru.se/shape-completion-grasping/.

</details>


### [203] [AG-MPBS: a Mobility-Aware Prediction and Behavior-Based Scheduling Framework for Air-Ground Unmanned Systems](https://arxiv.org/abs/2512.16454)
*Tianhao Shao,Kaixing Zhao,Feng Liu,Lixin Yang,Bin Guo*

Main category: cs.RO

TL;DR: MPBS是一种可扩展的任务招募框架，通过行为分类和时空预测实时分配任务，提高无人系统的调度效率。


<details>
  <summary>Details</summary>
Motivation: 随着无人系统在城市场感测和应急响应等应用中的重要性增加，高效招募这些自主设备执行时间敏感任务成为关键挑战。

Method: MPBS结合了行为感知KNN分类器、时间变化马尔可夫预测模型和动态优先级调度机制。

Result: 在真实世界的GeoLife数据集上的实验评估显示，MPBS显著提高了任务完成效率和资源利用率。

Conclusion: MPBS框架为无人系统提供了一种预测性、行为感知的智能协作调度解决方案，显著提高了任务完成效率和资源利用率。

Abstract: As unmanned systems such as Unmanned Aerial Vehicles (UAVs) and Unmanned Ground Vehicles (UGVs) become increasingly important to applications like urban sensing and emergency response, efficiently recruiting these autonomous devices to perform time-sensitive tasks has become a critical challenge. This paper presents MPBS (Mobility-aware Prediction and Behavior-based Scheduling), a scalable task recruitment framework that treats each device as a recruitable "user". MPBS integrates three key modules: a behavior-aware KNN classifier, a time-varying Markov prediction model for forecasting device mobility, and a dynamic priority scheduling mechanism that considers task urgency and base station performance. By combining behavioral classification with spatiotemporal prediction, MPBS adaptively assigns tasks to the most suitable devices in real time. Experimental evaluations on the real-world GeoLife dataset show that MPBS significantly improves task completion efficiency and resource utilization. The proposed framework offers a predictive, behavior-aware solution for intelligent and collaborative scheduling in unmanned systems.

</details>


### [204] [Tri-Select: A Multi-Stage Visual Data Selection Framework for Mobile Visual Crowdsensing](https://arxiv.org/abs/2512.16469)
*Jiayu Zhang,Kaixing Zhao,Tianhao Shao,Bin Guo,Liang He*

Main category: cs.RO

TL;DR: Tri-Select 是一个三阶段视觉数据选择框架，通过元数据过滤、谱聚类和最大独立集搜索，有效解决移动视觉群智感知中的冗余和异构数据问题。


<details>
  <summary>Details</summary>
Motivation: 移动视觉群智感知产生的数据通常存在冗余和异构性，如重叠的采集视角、不同的分辨率和多样化的用户行为，这需要高效的数据选择方法来提升数据集质量。

Method: Tri-Select 通过三个阶段进行数据筛选：(1) 基于元数据的过滤；(2) 基于空间相似性的谱聚类；(3) 基于视觉特征的最大独立集搜索。

Result: 在真实世界和公共数据集上的实验表明，Tri-Select 能够显著提升选择效率和数据集质量。

Conclusion: Tri-Select 是一个高效的多阶段视觉数据选择框架，能够显著提升移动视觉群智感知的数据质量和选择效率，适用于可扩展的群智感知应用。

Abstract: Mobile visual crowdsensing enables large-scale, fine-grained environmental monitoring through the collection of images from distributed mobile devices. However, the resulting data is often redundant and heterogeneous due to overlapping acquisition perspectives, varying resolutions, and diverse user behaviors. To address these challenges, this paper proposes Tri-Select, a multi-stage visual data selection framework that efficiently filters redundant and low-quality images. Tri-Select operates in three stages: (1) metadata-based filtering to discard irrelevant samples; (2) spatial similarity-based spectral clustering to organize candidate images; and (3) a visual-feature-guided selection based on maximum independent set search to retain high-quality, representative images. Experiments on real-world and public datasets demonstrate that Tri-Select improves both selection efficiency and dataset quality, making it well-suited for scalable crowdsensing applications.

</details>


### [205] [A Formal Modular Synthesis Approach for the Coordination of 3-D Robotic Construction with Multi-robots](https://arxiv.org/abs/2512.16555)
*Marcelo Rosa,José E. R. Cury,Fabio L. Baldissera*

Main category: cs.RO

TL;DR: 本文提出了一种基于监督控制理论的方法，通过合成正确构造的反应式控制器（监督器），使多个机器人能够协调完成预定义的3-D结构构建。


<details>
  <summary>Details</summary>
Motivation: 解决多个移动机器人协调构建预定义3-D结构的问题，实现自主交互与协作。

Method: 采用监督控制理论，从单个机器人和目标结构的模型中合成一个正确构造的反应式控制器（监督器），并将该监督器复制到其他机器人上。

Result: 成功实现了多机器人协调构建目标3-D结构的目标。

Conclusion: 通过基于监督控制理论的方法，成功合成了一个正确构造的反应式控制器（监督器），使得多个机器人能够协调完成预定义的3-D结构构建。

Abstract: In this paper, we deal with the problem of coordinating multiple robots to build 3-D structures. This problem consists of a set of mobile robots that interact with each other in order to autonomously build a predefined 3-D structure. Our approach is based on Supervisory Control Theory, and it allows us to synthesize from models that represent a single robot and the target structure a correct-by-construction reactive controller, called supervisor. When this supervisor is replicated for the other robots, then the target structure can be completed by all robots

</details>


### [206] [Olaf: Bringing an Animated Character to Life in the Physical World](https://arxiv.org/abs/2512.16705)
*David Müller,Espen Knoop,Dario Mylonopoulos,Agon Serifi,Michael A. Hopkins,Ruben Grandia,Moritz Bächer*

Main category: cs.RO

TL;DR: 通过强化学习和创新机械设计，将动画角色Olaf物理化，实现了高度逼真的运动控制。


<details>
  <summary>Details</summary>
Motivation: 探索如何在物理世界中实现非物理比例的动画角色运动，创新机械设计和风格化运动控制。

Method: 采用强化学习控制，结合动画参考；使用不对称腿和软泡沫裙隐藏腿部运动；在手臂、嘴和眼睛中使用球形和平面的连杆结构；引入额外奖励以减少冲击噪音和防止执行器过热。

Result: 在仿真和硬件上验证了模型的有效性，展示了服装机器人角色无与伦比的逼真度。

Conclusion: 通过强化学习和动画参考指导的控制方法，成功将Olaf这一动画角色物理化，展现了前所未有的逼真度。

Abstract: Animated characters often move in non-physical ways and have proportions that are far from a typical walking robot. This provides an ideal platform for innovation in both mechanical design and stylized motion control. In this paper, we bring Olaf to life in the physical world, relying on reinforcement learning guided by animation references for control. To create the illusion of Olaf's feet moving along his body, we hide two asymmetric legs under a soft foam skirt. To fit actuators inside the character, we use spherical and planar linkages in the arms, mouth, and eyes. Because the walk cycle results in harsh contact sounds, we introduce additional rewards that noticeably reduce impact noise. The large head, driven by small actuators in the character's slim neck, creates a risk of overheating, amplified by the costume. To keep actuators from overheating, we feed temperature values as additional inputs to policies, introducing new rewards to keep them within bounds. We validate the efficacy of our modeling in simulation and on hardware, demonstrating an unmatched level of believability for a costumed robotic character.

</details>


### [207] [VERM: Leveraging Foundation Models to Create a Virtual Eye for Efficient 3D Robotic Manipulation](https://arxiv.org/abs/2512.16724)
*Yixiang Chen,Yan Huang,Keji He,Peiyan Li,Liang Wang*

Main category: cs.RO

TL;DR: VERM方法通过虚拟视图过滤冗余信息，提升3D操作效率，训练和推理速度显著提升。


<details>
  <summary>Details</summary>
Motivation: 多摄像头设置引入冗余和无关信息，增加计算成本和训练时间，需过滤冗余并提取任务相关特征。

Method: 提出VERM方法，利用基础模型知识从3D点云构建虚拟任务自适应视图，并设计深度感知模块和动态粗到细流程。

Result: 在RLBench仿真基准和真实世界评估中表现优异，训练时间加速1.89倍，推理速度提升1.54倍。

Conclusion: VERM方法通过虚拟任务自适应视图有效过滤冗余信息，提升了3D操作任务的效率和准确性，显著优于现有方法。

Abstract: When performing 3D manipulation tasks, robots have to execute action planning based on perceptions from multiple fixed cameras. The multi-camera setup introduces substantial redundancy and irrelevant information, which increases computational costs and forces the model to spend extra training time extracting crucial task-relevant details. To filter out redundant information and accurately extract task-relevant features, we propose the VERM (Virtual Eye for Robotic Manipulation) method, leveraging the knowledge in foundation models to imagine a virtual task-adaptive view from the constructed 3D point cloud, which efficiently captures necessary information and mitigates occlusion. To facilitate 3D action planning and fine-grained manipulation, we further design a depth-aware module and a dynamic coarse-to-fine procedure. Extensive experimental results on both simulation benchmark RLBench and real-world evaluations demonstrate the effectiveness of our method, surpassing previous state-of-the-art methods while achieving 1.89x speedup in training time and 1.54x speedup in inference speed. More results can be found on our project website at https://verm-ral.github.io .

</details>


### [208] [Vision-Language-Action Models for Autonomous Driving: Past, Present, and Future](https://arxiv.org/abs/2512.16760)
*Tianshuai Hu,Xiaolu Liu,Song Wang,Yiyao Zhu,Ao Liang,Lingdong Kong,Guoyang Zhao,Zeying Gong,Jun Cen,Zhiyu Huang,Xiaoshuai Hao,Linfeng Li,Hang Song,Xiangtai Li,Jun Ma,Shaojie Shen,Jianke Zhu,Dacheng Tao,Ziwei Liu,Junwei Liang*

Main category: cs.RO

TL;DR: 论文综述了自动驾驶中Vision-Language-Action (VLA) 框架的演变、分类及挑战，旨在推动更人类兼容的自动驾驶系统。


<details>
  <summary>Details</summary>
Motivation: 传统模块化自动驾驶系统在复杂场景中表现不佳，且感知错误会传播至下游规划与控制。VLA框架通过整合视觉理解、语言推理和可操作输出，提供了更可解释、泛化性更强且与人类对齐的驾驶策略。

Method: 论文通过从早期的VA方法到现代VLA框架的演变，将现有方法组织为两大主要范式：端到端VLA和双系统VLA，并进一步区分了子类。

Result: 论文系统梳理了VLA框架的演变、分类、数据集和基准测试，并指出了关键挑战如鲁棒性、可解释性和指令忠实度。

Conclusion: 该论文旨在为推进与人类兼容的自动驾驶系统奠定一致的基础，总结了VLA框架的关键挑战和开放方向。

Abstract: Autonomous driving has long relied on modular "Perception-Decision-Action" pipelines, where hand-crafted interfaces and rule-based components often break down in complex or long-tailed scenarios. Their cascaded design further propagates perception errors, degrading downstream planning and control. Vision-Action (VA) models address some limitations by learning direct mappings from visual inputs to actions, but they remain opaque, sensitive to distribution shifts, and lack structured reasoning or instruction-following capabilities. Recent progress in Large Language Models (LLMs) and multimodal learning has motivated the emergence of Vision-Language-Action (VLA) frameworks, which integrate perception with language-grounded decision making. By unifying visual understanding, linguistic reasoning, and actionable outputs, VLAs offer a pathway toward more interpretable, generalizable, and human-aligned driving policies. This work provides a structured characterization of the emerging VLA landscape for autonomous driving. We trace the evolution from early VA approaches to modern VLA frameworks and organize existing methods into two principal paradigms: End-to-End VLA, which integrates perception, reasoning, and planning within a single model, and Dual-System VLA, which separates slow deliberation (via VLMs) from fast, safety-critical execution (via planners). Within these paradigms, we further distinguish subclasses such as textual vs. numerical action generators and explicit vs. implicit guidance mechanisms. We also summarize representative datasets and benchmarks for evaluating VLA-based driving systems and highlight key challenges and open directions, including robustness, interpretability, and instruction fidelity. Overall, this work aims to establish a coherent foundation for advancing human-compatible autonomous driving systems.

</details>


### [209] [PhysBrain: Human Egocentric Data as a Bridge from Vision Language Models to Physical Intelligence](https://arxiv.org/abs/2512.16793)
*Xiaopeng Lin,Shijie Lian,Bin Yu,Ruoqi Yang,Changti Wu,Yuzhuo Miao,Yurun Jin,Yukun Shi,Cong Huang,Bojun Cheng,Kai Chen*

Main category: cs.RO

TL;DR: 通过Egocentric2Embodiment管道将人类自我中心视频转化为机器人训练数据，训练出的PhysBrain模型在自我中心理解和机器人控制任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决机器人视觉语言模型（VLM）因主要基于第三人称数据训练而导致的视角不匹配问题，利用大规模人类自我中心视频作为可扩展的替代方案。

Method: 提出Egocentric2Embodiment翻译管道，将第一人称视频转化为多层次、模式驱动的VQA监督，构建E2E-3M数据集，并训练出PhysBrain模型。

Result: PhysBrain在EgoThink上表现出显著改进的自我中心理解能力，简化环境（SimplerEnv）的成功率达到53.9%。

Conclusion: PhysBrain通过E2E-3M数据集训练，显著提升了以自我为中心的感知能力，特别是在EgoThink上的规划表现，并实现了从人类自我中心监督到机器人控制的有效迁移。

Abstract: Robotic generalization relies on physical intelligence: the ability to reason about state changes, contact-rich interactions, and long-horizon planning under egocentric perception and action. However, most VLMs are trained primarily on third-person data, creating a fundamental viewpoint mismatch for humanoid robots. Scaling robot egocentric data collection remains impractical due to high cost and limited diversity, whereas large-scale human egocentric videos offer a scalable alternative that naturally capture rich interaction context and causal structure. The key challenge is to convert raw egocentric videos into structured and reliable embodiment training supervision. Accordingly, we propose an Egocentric2Embodiment translation pipeline that transforms first-person videos into multi-level, schema-driven VQA supervision with enforced evidence grounding and temporal consistency, enabling the construction of the Egocentric2Embodiment dataset (E2E-3M) at scale. An egocentric-aware embodied brain, termed PhysBrain, is obtained by training on the E2E-3M dataset. PhysBrain exhibits substantially improved egocentric understanding, particularly for planning on EgoThink. It provides an egocentric-aware initialization that enables more sample-efficient VLA fine-tuning and higher SimplerEnv success rates (53.9\%), demonstrating effective transfer from human egocentric supervision to downstream robot control.

</details>


### [210] [ReinforceGen: Hybrid Skill Policies with Automated Data Generation and Reinforcement Learning](https://arxiv.org/abs/2512.16861)
*Zihan Zhou,Animesh Garg,Ajay Mandlekar,Caelan Garrett*

Main category: cs.RO

TL;DR: ReinforceGen结合任务分解与强化学习微调，显著提升长时程操作任务性能，成功率80%。


<details>
  <summary>Details</summary>
Motivation: 解决长时程操作任务在机器人领域的长期挑战。

Method: 系统首先将任务分解为多个局部技能，通过运动规划连接，利用10个人类示范生成的数据集进行模仿学习训练，并通过在线适应和强化学习微调。

Result: 在Robosuite数据集上，ReinforceGen在最高重置范围设置下达到80%的成功率，微调方法贡献了89%的平均性能提升。

Conclusion: ReinforceGen通过结合任务分解、数据生成、模仿学习和运动规划，并通过强化学习微调，显著提升了长时程操作任务的性能，在Robosuite数据集上达到80%的成功率。

Abstract: Long-horizon manipulation has been a long-standing challenge in the robotics community. We propose ReinforceGen, a system that combines task decomposition, data generation, imitation learning, and motion planning to form an initial solution, and improves each component through reinforcement-learning-based fine-tuning. ReinforceGen first segments the task into multiple localized skills, which are connected through motion planning. The skills and motion planning targets are trained with imitation learning on a dataset generated from 10 human demonstrations, and then fine-tuned through online adaptation and reinforcement learning. When benchmarked on the Robosuite dataset, ReinforceGen reaches 80% success rate on all tasks with visuomotor controls in the highest reset range setting. Additional ablation studies show that our fine-tuning approaches contributes to an 89% average performance increase. More results and videos available in https://reinforcegen.github.io/

</details>


### [211] [PolaRiS: Scalable Real-to-Sim Evaluations for Generalist Robot Policies](https://arxiv.org/abs/2512.16881)
*Arhan Jain,Mingtong Zhang,Kanav Arora,William Chen,Marcel Torne,Muhammad Zubair Irshad,Sergey Zakharov,Yue Wang,Sergey Levine,Chelsea Finn,Wei-Chiu Ma,Dhruv Shah,Abhishek Gupta,Karl Pertsch*

Main category: cs.RO

TL;DR: PolaRiS是一个可扩展的实景到仿真框架，通过神经重建和协同训练方法提升仿真评估的真实性，显著改善了仿真与真实世界性能的相关性。


<details>
  <summary>Details</summary>
Motivation: 机器人策略性能的准确测量和比较是研究中的重大挑战，现有仿真基准与真实世界之间存在视觉和物理领域的差距，且构建真实多样的仿真环境传统上需要大量人力和专业知识。

Method: PolaRiS利用神经重建方法将真实场景的短视频扫描转化为交互式仿真环境，并开发了一种简单的仿真数据协同训练方法，以弥合剩余的实景到仿真差距。

Result: 通过仿真与真实世界的广泛配对评估，PolaRiS的评估结果与真实世界通用策略性能的相关性远高于现有仿真基准，并能快速创建多样化的仿真环境。

Conclusion: PolaRiS提供了一个可扩展的实景到仿真框架，显著提升了仿真评估与真实世界性能的相关性，为下一代机器人基础模型的分布式和民主化评估奠定了基础。

Abstract: A significant challenge for robot learning research is our ability to accurately measure and compare the performance of robot policies. Benchmarking in robotics is historically challenging due to the stochasticity, reproducibility, and time-consuming nature of real-world rollouts. This challenge is exacerbated for recent generalist policies, which has to be evaluated across a wide variety of scenes and tasks. Evaluation in simulation offers a scalable complement to real world evaluations, but the visual and physical domain gap between existing simulation benchmarks and the real world has made them an unreliable signal for policy improvement. Furthermore, building realistic and diverse simulated environments has traditionally required significant human effort and expertise. To bridge the gap, we introduce Policy Evaluation and Environment Reconstruction in Simulation (PolaRiS), a scalable real-to-sim framework for high-fidelity simulated robot evaluation. PolaRiS utilizes neural reconstruction methods to turn short video scans of real-world scenes into interactive simulation environments. Additionally, we develop a simple simulation data co-training recipe that bridges remaining real-to-sim gaps and enables zero-shot evaluation in unseen simulation environments. Through extensive paired evaluations between simulation and the real world, we demonstrate that PolaRiS evaluations provide a much stronger correlation to real world generalist policy performance than existing simulated benchmarks. Its simplicity also enables rapid creation of diverse simulated environments. As such, this work takes a step towards distributed and democratized evaluation for the next generation of robotic foundation models.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [212] [XBIDetective: Leveraging Vision Language Models for Identifying Cross-Browser Visual Inconsistencies](https://arxiv.org/abs/2512.15804)
*Balreet Grewal,James Graham,Jeff Muizelaar,Jan Honza Odvarko,Suhaib Mujahid,Marco Castelluccio,Cor-Paul Bezemer*

Main category: cs.SE

TL;DR: XBIDetective利用视觉语言模型自动检测跨浏览器不一致性，准确率高达85%，适用于回归测试和错误报告分类。


<details>
  <summary>Details</summary>
Motivation: 浏览器渲染错误难以检测，尤其是由特定条件触发的错误。跨浏览器不一致性（XBIs）可作为检测此类错误的线索，但现有视觉和DOM分析方法难以处理动态和交互元素。

Method: 开发了XBIDetective工具，自动捕获网站在Mozilla Firefox和Google Chrome中的截图，并使用VLM分析XBIs。评估了现成和微调VLM在1,052个网站上的性能。

Result: XBIDetective在使用微调VLM时，检测跨浏览器差异的准确率为79%，动态元素和广告的检测准确率分别为84%和85%。

Conclusion: XBIDetective工具通过视觉语言模型（VLM）有效检测跨浏览器不一致性（XBIs），展示了在自动化回归测试、大规模网站监控和快速分类XBI错误报告等方面的实际应用潜力。

Abstract: Browser rendering bugs can be challenging to detect for browser developers, as they may be triggered by very specific conditions that are exhibited on only a very small subset of websites. Cross-browser inconsistencies (XBIs), variations in how a website is interpreted and displayed on different browsers, can be helpful guides to detect such rendering bugs. Although visual and Document Object Model (DOM)-based analysis techniques exist for detecting XBIs, they often struggle with dynamic and interactive elements. In this study, we discuss our industry experience with using vision language models (VLMs) to identify XBIs. We present the XBIDetective tool which automatically captures screenshots of a website in Mozilla Firefox and Google Chrome, and analyzes them with a VLM for XBIs. We evaluate XBIDetective's performance with an off-the-shelf and a fine-tuned VLM on 1,052 websites. We show that XBIDetective can identify cross-browser discrepancies with 79% accuracy and detect dynamic elements and advertisements with 84% and 85% accuracy, respectively, when using the fine-tuned VLM. We discuss important lessons learned, and we present several potential practical use cases for XBIDetective, including automated regression testing, large-scale monitoring of websites, and rapid triaging of XBI bug reports.

</details>


### [213] [CodeMem: Architecting Reproducible Agents via Dynamic MCP and Procedural Memory](https://arxiv.org/abs/2512.15813)
*Nishant Gaurav,Adit Akarsh,Tejas Ravishankar,Manoj Bajaj*

Main category: cs.SE

TL;DR: CodeMem通过代码实现程序性记忆，提升AI代理在重复任务中的可靠性和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有工具使用AI代理存在动作空间有限、上下文效率低和概率不稳定性问题，尤其不适用于重复任务。

Method: 使用Python语言作为无限动作空间，通过代码块执行复杂动作并仅输出相关结果，结合程序性记忆提升一致性。

Result: CodeMem架构通过程序性记忆解决了概率不稳定性问题，实现了可靠的代理工作流程。

Conclusion: 本文提出CodeMem架构，通过代码实现程序性记忆，以构建和运行可重复的代理工作流程，确保确定性可靠性。

Abstract: Current tool-using AI agents suffer from limited action space, context inefficiency, and probabilistic instability that makes them unsuitable for handling repetitive tasks which are otherwise reliably and efficiently tackled by agentic workflows built on platforms like n8n and Zapier. Earlier works like CodeAct, DynaSaur, Code Mode have tried to tackle the first two issues by using the whole Python language as its action space: The number of tools that the agent can call becomes infinite. Python code blocks can execute complex actions into a single step and print only relevant results which helps in keeping the context lean. However, the probabilistic instability issue still remains, as for the same task in the same environment, the agent can follow different trajectories due to the probabilistic nature of LLMs. Therefore, we need procedural memory for consistency and reliability. This paper proposes CodeMem, an architecture to implement procedural memory via code which can be used to build and run reusable agentic workflows with deterministic reliability.

</details>


### [214] [OLAF: Towards Robust LLM-Based Annotation Framework in Empirical Software Engineering](https://arxiv.org/abs/2512.15979)
*Mia Mohammad Imran,Tarannum Shaila Zaman*

Main category: cs.SE

TL;DR: 论文提出OLAF框架，将LLM注释视为测量过程，强调可靠性、透明度，促进软件工程研究中的可重复性。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM在软件工程中用于注释任务的可靠性和可重复性，现有研究缺乏标准化措施和配置细节。

Method: 提出了一个概念框架OLAF，组织关键构建：可靠性、校准、漂移、共识、聚合和透明度。

Result: OLAF框架为LLM基于的注释提供了一个系统化的方法论，促进未来实证研究。

Conclusion: 论文提出了OLAF框架，强调将LLM基于的注释视为测量过程，以提高软件工程研究中注释的透明度和可重复性。

Abstract: Large Language Models (LLMs) are increasingly used in empirical software engineering (ESE) to automate or assist annotation tasks such as labeling commits, issues, and qualitative artifacts. Yet the reliability and reproducibility of such annotations remain underexplored. Existing studies often lack standardized measures for reliability, calibration, and drift, and frequently omit essential configuration details. We argue that LLM-based annotation should be treated as a measurement process rather than a purely automated activity. In this position paper, we outline the \textbf{Operationalization for LLM-based Annotation Framework (OLAF)}, a conceptual framework that organizes key constructs: \textit{reliability, calibration, drift, consensus, aggregation}, and \textit{transparency}. The paper aims to motivate methodological discussion and future empirical work toward more transparent and reproducible LLM-based annotation in software engineering research.

</details>


### [215] [Embedding Software Intent: Lightweight Java Module Recovery](https://arxiv.org/abs/2512.15980)
*Yirui He,Yuqi Huai,Xingyu Chen,Joshua Garcia*

Main category: cs.SE

TL;DR: ClassLAR是一种基于类和语言模型的架构恢复方法，能高效恢复Java模块，性能优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 随着软件系统规模扩大，仅依赖代码级抽象变得不切实际，JPMS虽提供语言级模块化支持，但现有架构恢复技术在模块恢复上效果不佳。

Method: ClassLAR利用语言模型从完全限定类名中提取语义信息，结合结构和功能意图。

Result: 在20个流行Java项目评估中，ClassLAR在架构级相似性指标上优于所有现有技术，执行速度快3.99至10.50倍。

Conclusion: ClassLAR是一种轻量级且高效的方法，能够从单体Java系统中恢复Java模块，并在评估中表现出色，优于现有技术。

Abstract: As an increasing number of software systems reach unprecedented scale, relying solely on code-level abstractions is becoming impractical. While architectural abstractions offer a means to manage these systems, maintaining their consistency with the actual code has been problematic. The Java Platform Module System (JPMS), introduced in Java 9, addresses this limitation by enabling explicit module specification at the language level. JPMS enhances architectural implementation through improved encapsulation and direct specification of ground-truth architectures within Java projects. Although many projects are written in Java, modularizing existing monolithic projects to JPMS modules is an open challenge due to ineffective module recovery by existing architecture recovery techniques. To address this challenge, this paper presents ClassLAR (Class-and Language model-based Architectural Recovery), a novel, lightweight, and efficient approach that recovers Java modules from monolithic Java systems using fully-qualified class names. ClassLAR leverages language models to extract semantic information from package and class names, capturing both structural and functional intent. In evaluations across 20 popular Java projects, ClassLAR outperformed all state-of-the-art techniques in architectural-level similarity metrics while achieving execution times that were 3.99 to 10.50 times faster.

</details>


### [216] [LLM4Perf: Large Language Models Are Effective Samplers for Multi-Objective Performance Modeling (Copy)](https://arxiv.org/abs/2512.16070)
*Xin Wang,Zhenhao Li,Zishuo Ding*

Main category: cs.SE

TL;DR: LLM4Perf框架通过LLM引导的采样在多目标性能建模中表现优异，68.8%的场景中优于传统方法，且其配置空间剪枝能力显著提升了基线方法的性能。


<details>
  <summary>Details</summary>
Motivation: 现代软件系统的性能高度依赖其复杂的配置选项，而现有方法在多目标优化和利用文档语义信息方面存在不足。LLMs的成功激发了我们探索其作为多目标性能建模的有效采样器的潜力。

Method: 我们设计并实现了LLM4Perf，一个基于反馈的框架，并系统地评估了LLM引导的采样过程在四个高度可配置的真实世界系统中的表现。

Result: LLM4Perf在68.8%的评估场景中表现最佳，其有效性源于LLM的双重能力：配置空间剪枝和反馈驱动的策略优化。此外，这种剪枝还改善了基线方法在91.5%的情况下的性能。

Conclusion: 本文提供了强有力的证据，证明LLMs在性能工程中的有效性，并深入探讨了推动其成功的机制。

Abstract: The performance of modern software systems is critically dependent on their complex configuration options. Building accurate performance models to navigate this vast space requires effective sampling strategies, yet existing methods often struggle with multi-objective optimization and cannot leverage semantic information from documentation. The recent success of Large Language Models (LLMs) motivates the central question of this work: Can LLMs serve as effective samplers for multi-objective performance modeling? To explore this, we present a comprehensive empirical study investigating the capabilities and characteristics of LLM-driven sampling. We design and implement LLM4Perf, a feedback-based framework, and use it to systematically evaluate the LLM-guided sampling process across four highly configurable, real-world systems. Our study reveals that the LLM-guided approach outperforms traditional baselines in most cases. Quantitatively, LLM4Perf achieves the best performance in nearly 68.8% (77 out of 112) of all evaluation scenarios, demonstrating its superior effectiveness. We find this effectiveness stems from the LLM's dual capabilities of configuration space pruning and feedback-driven strategy refinement. The effectiveness of this pruning is further validated by the fact that it also improves the performance of the baseline methods in nearly 91.5% (410 out of 448) of cases. Furthermore, we show how the LLM choices for each component and hyperparameters within LLM4Perf affect its effectiveness. Overall, this paper provides strong evidence for the effectiveness of LLMs in performance engineering and offers concrete insights into the mechanisms that drive their success.

</details>


### [217] [Analysis of Design Patterns and Benchmark Practices in Apache Kafka Event-Streaming Systems](https://arxiv.org/abs/2512.16146)
*Muzeeb Mohammad*

Main category: cs.SE

TL;DR: 本文综合分析了42篇关于Kafka的研究，提出了九种常见设计模式，并揭示了现有研究在配置披露和可重复性方面的不足，为未来系统设计提供了实用指南。


<details>
  <summary>Details</summary>
Motivation: 尽管Kafka成熟且广泛应用，但关于可重用架构设计模式和可重复基准测试方法的研究在学术和工业出版物中仍然分散。

Method: 对2015年至2025年间发表的42篇同行评审研究进行了结构化综合，识别出九种常见的Kafka设计模式，并分析了共同使用趋势、领域特定部署和实证基准测试实践。

Result: 研究发现配置披露、评估严谨性和可重复性存在显著不一致，限制了跨研究比较和实际复制。

Conclusion: 本研究通过统一分类法、模式基准矩阵和可操作的决策启发式，为设计可重现、高性能和容错的基于Kafka的事件流系统提供了实用指导。

Abstract: Apache Kafka has become a foundational platform for high throughput event streaming, enabling real time analytics, financial transaction processing, industrial telemetry, and large scale data driven systems. Despite its maturity and widespread adoption, consolidated research on reusable architectural design patterns and reproducible benchmarking methodologies remains fragmented across academic and industrial publications. This paper presents a structured synthesis of forty two peer reviewed studies published between 2015 and 2025, identifying nine recurring Kafka design patterns including log compaction, CQRS bus, exactly once pipelines, change data capture, stream table joins, saga orchestration, tiered storage, multi tenant topics, and event sourcing replay. The analysis examines co usage trends, domain specific deployments, and empirical benchmarking practices using standard suites such as TPCx Kafka and the Yahoo Streaming Benchmark, as well as custom workloads. The study highlights significant inconsistencies in configuration disclosure, evaluation rigor, and reproducibility that limit cross study comparison and practical replication. By providing a unified taxonomy, pattern benchmark matrix, and actionable decision heuristics, this work offers practical guidance for architects and researchers designing reproducible, high performance, and fault tolerant Kafka based event streaming systems.

</details>


### [218] [Beyond Blind Spots: Analytic Hints for Mitigating LLM-Based Evaluation Pitfalls](https://arxiv.org/abs/2512.16272)
*Ora Nova Fandina,Eitan Farchi,Shmulik Froimovich,Raviv Gal,Wesam Ibraheem,Rami Katan,Alice Podolsky*

Main category: cs.SE

TL;DR: 研究发现，大型语言模型在评估代码生成时存在盲点，结合分析检查器可显著提高错误检测率和解释质量。


<details>
  <summary>Details</summary>
Motivation: 理解大型语言模型作为代码生成管道中评估者的局限性，特别是在遗留代码现代化等工业用例中。

Method: 通过分析生成的COBOL程序和大型语言模型的判断，构建初步分类法，并开发轻量级分析检查器工具。

Result: 实验显示，单独使用大型语言模型仅能检测约45%的错误，而结合分析检查器后，覆盖率提升至94%。

Conclusion: 结合分析检查器和大型语言模型的混合方法可以显著提高部署管道中的评估可靠性。

Abstract: Large Language Models are increasingly deployed as judges (LaaJ) in code generation pipelines. While attractive for scalability, LaaJs tend to overlook domain specific issues raising concerns about their reliability in critical evaluation tasks. To better understand these limitations in practice, we examine LaaJ behavior in a concrete industrial use case: legacy code modernization via COBOL code generation. In this setting, we find that even production deployed LaaJs can miss domain critical errors, revealing consistent blind spots in their evaluation capabilities.
  To better understand these blind spots, we analyze generated COBOL programs and associated LaaJs judgments, drawing on expert knowledge to construct a preliminary taxonomy. Based on this taxonomy, we develop a lightweight analytic checker tool that flags over 30 domain specific issues observed in practice. We use its outputs as analytic hints, dynamically injecting them into the judges prompt to encourage LaaJ to revisit aspects it may have overlooked.
  Experiments on a test set of 100 programs using four production level LaaJs show that LaaJ alone detects only about 45% of the errors present in the code (in all judges we tested), while the analytic checker alone lacks explanatory depth. When combined, the LaaJ+Hints configuration achieves up to 94% coverage (for the best performing judge and injection prompt) and produces qualitatively richer, more accurate explanations, demonstrating that analytic-LLM hybrids can substantially enhance evaluation reliability in deployed pipelines. We release the dataset and all used prompts.

</details>


### [219] [Using a Sledgehammer to Crack a Nut? Revisiting Automated Compiler Fault Isolation](https://arxiv.org/abs/2512.16335)
*Yibiao Yang,Qingyang Li,Maolin Sun,Jiangchang Wu,Yuming Zhou*

Main category: cs.SE

TL;DR: 本研究比较了基于BIC的Basic策略与基于SBFL的技术在编译器错误定位中的效果，发现Basic在多项指标上表现更优，建议将其作为未来研究的基线。


<details>
  <summary>Details</summary>
Motivation: 编译器错误可能带来严重后果，因此有效定位和解决编译器错误至关重要。尽管已有许多基于SBFL的复杂技术用于编译器故障隔离，但其效果尚未与实践中广泛采用的基于BIC的策略进行评估。本研究旨在填补这一空白。

Method: Basic策略识别最近的正常发布和最早的问题发布，并通过二分查找精确定位引入错误的提交。所有在该提交中修改的文件被标记为潜在问题文件。研究使用包含60个GCC错误和60个LLVM错误的基准对Basic与基于SBFL的技术进行了严格比较。

Result: 分析显示，Basic在关键Top-1和Top-5排名指标上表现与基于SBFL的最新技术相当甚至更优。

Conclusion: 本研究为现实世界编译器调试场景中基于SBFL技术的实际有效性提供了新见解，并建议未来研究在开发和评估新的编译器故障隔离方法时采用Basic作为基线。

Abstract: Background: Compilers are fundamental to software development, translating high-level source code into executable software systems. Faults in compilers can have severe consequences and thus effective localization and resolution of compiler bugs are crucial. Problem: In practice, developers often examine version history to identify and investigate bug-inducing commit (BIC) for fixing bugs. However, while numerous sophisticated Spectrum-Based Fault Localization (SBFL) techniques have been proposed for compiler fault isolation, their effectiveness has not been evaluated against the BIC-based strategies widely adopted in practice. Objective: This study aims to bridge this gap by directly comparing a BIC-based strategy, Basic, with representative SBFL techniques in the context of compiler fault localization. The BIC-based strategy closely aligns with common developer practices, as it directly identifies the BIC and treats the files modified in that commit as faulty candidates. Method: The Basic identifies the most recent good release and earliest bad release, and then employs a binary search to pinpoint the bug-inducing commit. All files modified in the identified commit are flagged as potentially faulty. We rigorously compare Basic against SBFL-based techniques using a benchmark consisting of 60 GCC bugs and 60 LLVM bugs. Result: Our analysis reveals that Basic performs comparably to, and in many cases outperforms, state-of-the-art SBFL-based techniques, particularly on the critical Top-1 and Top-5 ranking metrics. Conclusion: This study provides new insights into the practical effectiveness of SBFL-based techniques in real-world compiler debugging scenarios. We recommend that future research adopt Basic as a baseline when developing and evaluating new compiler fault isolation methods.

</details>


### [220] [An Empirical Study of the Realism of Mutants in Deep Learning](https://arxiv.org/abs/2512.16741)
*Zaheed Ahmed,Philip Makedonski,Jens Grabowski*

Main category: cs.SE

TL;DR: 研究发现预训练突变体比后训练突变体更接近真实故障，但计算成本高，需改进后训练方法。


<details>
  <summary>Details</summary>
Motivation: 验证深度学习突变分析中预训练和后训练突变方法的现实主义假设，填补传统软件系统与深度学习之间的研究空白。

Method: 引入统计框架量化预训练和后训练突变方法的耦合强度和行为相似性，使用公开的缺陷数据集和最新工具生成突变体。

Result: 预训练突变体表现出更强的耦合和更高的行为相似性，但计算成本显著。

Conclusion: 预训练突变体在耦合强度和行为相似性上表现优于后训练突变体，但计算成本较高，需要开发更有效的后训练操作符。

Abstract: Mutation analysis is a well-established technique for assessing test quality in the traditional software development paradigm by injecting artificial faults into programs. Its application to deep learning (DL) has expanded beyond classical testing to support tasks such as fault localization, repair, data generation, and model robustness evaluation. The core assumption is that mutants behave similarly to real faults, an assumption well established in traditional software systems but largely unverified for DL.
  This study presents the first empirical comparison of pre-training and post-training mutation approaches in DL with respect to realism. We introduce a statistical framework to quantify their coupling strength and behavioral similarity to real faults using publicly available bugs datasets: CleanML, DeepFD, DeepLocalize, and defect4ML. Mutants are generated using state-of-the-art tools representing both approaches.
  Results show that pre-training mutants exhibit consistently stronger coupling and higher behavioral similarity to real faults than post-training mutants, indicating greater realism. However, the substantial computational cost of pre-training mutation underscores the need for more effective post-training operators that match or exceed the realism demonstrated by pre-training mutants.

</details>


### [221] [Inside Out: Uncovering How Comment Internalization Steers LLMs for Better or Worse](https://arxiv.org/abs/2512.16790)
*Aaron Imani,Mohammad Moshirpour,Iftekhar Ahmed*

Main category: cs.SE

TL;DR: 研究发现 LLMs 将代码注释内化为潜在概念，并区分注释子类型。激活或停用这些概念会显著影响模型性能，为基于内部概念表示的 SE 工具开发提供了新思路。


<details>
  <summary>Details</summary>
Motivation: 尽管注释是源代码中的非功能性元素，但 LLMs 在执行 SE 任务时经常依赖它们。然而，模型如何依赖注释以及这种依赖如何影响性能尚不清楚。本研究旨在揭示 LLMs 在 SE 任务中对注释的内部表示机制。

Method: 使用概念激活向量（CAV）分析 LLMs 在代码补全、翻译和优化任务中对注释的内部表示。通过激活和停用这些概念，观察模型性能的变化，并进行控制实验测量注释概念在潜在表示中的激活强度。

Result: 研究发现，LLMs 将注释内化为不同的潜在概念，并能区分注释子类型。激活或停用这些概念会导致模型性能的显著变化（-90% 到 +67%）。代码总结任务最能激活注释概念，而代码补全任务对注释的敏感性最低。

Conclusion: 研究结果表明，LLMs 不仅将注释内化为不同的潜在概念，还能区分注释的子类型（如 Javadocs、内联注释和多行注释）。通过系统地激活和停用这些概念，可以显著影响模型在不同任务中的性能，这为构建基于内部概念表示的 SE 工具和模型提供了新方向。

Abstract: While comments are non-functional elements of source code, Large Language Models (LLM) frequently rely on them to perform Software Engineering (SE) tasks. Yet, where in the model this reliance resides, and how it affects performance, remains poorly understood. We present the first concept-level interpretability study of LLMs in SE, analyzing three tasks - code completion, translation, and refinement - through the lens of internal comment representation. Using Concept Activation Vectors (CAV), we show that LLMs not only internalize comments as distinct latent concepts but also differentiate between subtypes such as Javadocs, inline, and multiline comments. By systematically activating and deactivating these concepts in the LLMs' embedding space, we observed significant, model-specific, and task-dependent shifts in performance ranging from -90% to +67%. Finally, we conducted a controlled experiment using the same set of code inputs, prompting LLMs to perform 10 distinct SE tasks while measuring the activation of the comment concept within their latent representations. We found that code summarization consistently triggered the strongest activation of comment concepts, whereas code completion elicited the weakest sensitivity. These results open a new direction for building SE tools and models that reason about and manipulate internal concept representations rather than relying solely on surface-level input.

</details>


### [222] [Toward Systematic Counterfactual Fairness Evaluation of Large Language Models: The CAFFE Framework](https://arxiv.org/abs/2512.16816)
*Alessandra Parziale,Gianmario Voria,Valeria Pontillo,Gemma Catolino,Andrea De Lucia,Fabio Palomba*

Main category: cs.SE

TL;DR: CAFFE是一种结构化、意图感知的框架，用于测试LLM的反事实公平性，比现有方法更有效。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）在现代软件系统中的影响力增长，公平性问题日益突出，需要更有效的测试方法来检测不公平行为。

Method: CAFFE框架通过明确定义的组件（如提示意图、对话上下文、输入变体、预期公平性阈值和测试环境配置）来形式化LLM公平性测试用例，并自动生成目标测试数据，使用语义相似度度量评估模型响应。

Result: 实验表明，CAFFE在三种不同架构家族的LLM上实现了比现有变形测试方法更广泛的偏见覆盖和更可靠的不公平行为检测。

Conclusion: CAFFE框架在测试LLM的公平性方面比现有的变形测试方法更有效，能够实现更广泛的偏见覆盖和更可靠的不公平行为检测。

Abstract: Nowadays, Large Language Models (LLMs) are foundational components of modern software systems. As their influence grows, concerns about fairness have become increasingly pressing. Prior work has proposed metamorphic testing to detect fairness issues, applying input transformations to uncover inconsistencies in model behavior. This paper introduces an alternative perspective for testing counterfactual fairness in LLMs, proposing a structured and intent-aware framework coined CAFFE (Counterfactual Assessment Framework for Fairness Evaluation). Inspired by traditional non-functional testing, CAFFE (1) formalizes LLM-Fairness test cases through explicitly defined components, including prompt intent, conversational context, input variants, expected fairness thresholds, and test environment configuration, (2) assists testers by automatically generating targeted test data, and (3) evaluates model responses using semantic similarity metrics. Our experiments, conducted on three different architectural families of LLM, demonstrate that CAFFE achieves broader bias coverage and more reliable detection of unfair behavior than existing metamorphic approaches.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [223] [Privacy-Aware Sharing of Raw Spatial Sensor Data for Cooperative Perception](https://arxiv.org/abs/2512.16265)
*Bangya Liu,Chengpo Yan,Chenghao Jiang,Suman Banerjee,Akarsh Prabhakara*

Main category: cs.NI

TL;DR: 论文讨论了车辆协作感知中的隐私问题，提出了SHARP框架以减少隐私泄露，并呼吁跨学科合作以实现该目标。


<details>
  <summary>Details</summary>
Motivation: 探讨了车辆间协作感知在隐私方面的新问题，阻碍了原始传感器数据的共享。

Method: 提出了SHARP研究框架，以减少隐私泄露并推动基于原始数据的协作感知。

Result: SHARP框架被提出，以最小化隐私泄露并促进原始数据共享。

Conclusion: 论文提出了SHARP框架，旨在解决基于原始传感器数据的协作感知中的隐私问题，并讨论了实现该框架所需的跨学科合作。

Abstract: Cooperative perception between vehicles is poised to offer robust and reliable scene understanding. Recently, we are witnessing experimental systems research building testbeds that share raw spatial sensor data for cooperative perception. While there has been a marked improvement in accuracies and is the natural way forward, we take a moment to consider the problems with such an approach for eventual adoption by automakers. In this paper, we first argue that new forms of privacy concerns arise and discourage stakeholders to share raw sensor data. Next, we present SHARP, a research framework to minimize privacy leakage and drive stakeholders towards the ambitious goal of raw data based cooperative perception. Finally, we discuss open questions for networked systems, mobile computing, perception researchers, industry and government in realizing our proposed framework.

</details>


### [224] [A Network Arena for Benchmarking AI Agents on Network Troubleshooting](https://arxiv.org/abs/2512.16381)
*Zhihao Wang,Alessandro Cornacchia,Alessio Sacco,Franco Galante,Marco Canini,Dingde Jiang*

Main category: cs.NI

TL;DR: NIKA是最大的公开LLM网络故障诊断基准测试，支持快速原型设计，评估显示大型模型检测问题更优但定位不足。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏标准化且易于访问的基准测试，LLM代理在动态网络环境中的评估进展受阻。

Method: 提出了NIKA基准测试，包含数百个精选网络事件，覆盖五种网络场景和54种代表性网络问题，提供零成本重放和模块化API。

Result: 评估发现，大型模型在检测网络问题方面表现更好，但在定位故障和识别根本原因方面仍有困难。

Conclusion: NIKA作为目前最大的公开基准测试，为LLM驱动的网络故障诊断和排除提供了标准化评估工具，支持快速原型设计，并开源供社区使用。

Abstract: Agentic systems, powered by Large Language Models (LLMs), assist network engineers with network configuration synthesis and network troubleshooting tasks. For network troubleshooting, progress is hindered by the absence of standardized and accessible benchmarks for evaluating LLM agents in dynamic network settings at low operational effort. We present NIKA, the largest public benchmark to date for LLM-driven network incident diagnosis and troubleshooting. NIKA targets both domain experts and especially AI researchers alike, providing zero-effort replay of real-world network scenarios, and establishing well-defined agent-network interfaces for quick agent prototyping. NIKA comprises hundreds of curated network incidents, spanning five network scenarios, from data centers to ISP networks, and covers 54 representative network issues. Lastly, NIKA is modular and extensible by design, offering APIs to facilitate the integration of new network scenarios and failure cases. We evaluate state-of-the-art LLM agents on NIKA and find that while larger models succeed more often in detecting network issues, they still struggle to localize faults and identify root causes. NIKA is open-source and available to the community: https://github.com/sands-lab/nika.

</details>


### [225] [Acoustic RIS for Massive Spatial Multiplexing: Unleashing Degrees of Freedom and Capacity in Underwater Communications](https://arxiv.org/abs/2512.16470)
*Longfei Zhao,Jingbo Tan,Jintao Wang,Ian F Akyildiz,Zhi Sun*

Main category: cs.NI

TL;DR: 通过声学可重构智能表面（aRIS）和ASTAR架构，显著提升水下声学通信的空间自由度和信道容量，仿真验证效果显著。


<details>
  <summary>Details</summary>
Motivation: 解决传统水下声学MIMO系统因有限阵列分辨率导致的角模糊和空间自由度不足问题。

Method: 建立了海洋特定的自由度-信道耦合模型，推导了空间秩增强的条件，并提出了ASTAR aRIS架构，结合独立波束控制和自适应波束跟踪机制。

Result: 仿真验证显示，提出的联合aRIS部署和波束成形框架在浅海和深海场景中分别实现了265%和170%的信道容量提升。

Conclusion: 通过引入声学可重构智能表面（aRIS）和提出的ASTAR架构，本研究显著提升了水下声学通信的空间自由度和信道容量，尤其在浅海和深海环境中分别实现了高达265%和170%的容量提升。

Abstract: Underwater acoustic (UWA) communications are essential for high-speed marine data transmission but remain severely constrained by limited bandwidth, significant propagation loss, and sparse multipath structures. Conventional underwater acoustic multiple-input multiple-output (MIMO) systems primarily utilize spatial diversity but suffer from limited array resolution, causing angular ambiguity and insufficient spatial degrees of freedom (DoFs). This paper addresses these limitations through acoustic Reconfigurable Intelligent Surfaces (aRIS) to actively generate orthogonally distinguishable virtual paths, significantly enhancing spatial DoFs and channel capacity. An ocean-specific DoF-channel coupling model is established, explicitly deriving conditions for spatial rank enhancement. Subsequently, the optimal geometric locus, termed the Light-Point, is analytically identified, where deploying a single aRIS maximizes DoFs by introducing two and three additional resolvable paths in deep-sea and shallow-sea environments, respectively. Furthermore, an active simultaneous transmitting and reflecting (ASTAR) aRIS architecture with independent beam control and adaptive beam-tracking mechanism integrating unmanned underwater vehicles (UUVs) and acoustic intensity gradient sensing is proposed. Extensive simulations validate the proposed joint aRIS deployment and beamforming framework, demonstrating substantial UWA channel capacity improvements-up to 265% and 170% in shallow-sea and deep-sea scenarios, respectively.

</details>


### [226] [Coordinated Anti-Jamming Resilience in Swarm Networks via Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2512.16813)
*Bahman Abolhassani,Tugba Erpek,Kemal Davaslioglu,Yalin E. Sagduyu,Sastry Kompella*

Main category: cs.NI

TL;DR: QMIX框架通过MARL提升群体通信抗干扰能力，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 反应式干扰器对群体网络通信构成严重威胁，传统固定功率控制或静态信道跳变方法效果有限，需开发自适应对抗策略。

Method: 采用基于QMIX算法的多智能体强化学习框架，联合选择传输频率和功率，通过集中式但可分解的动作值函数实现协调且去中心化的执行。

Result: 仿真结果表明，QMIX快速收敛至接近理论最优的协作策略，吞吐量更高且干扰发生率低于基线方法。

Conclusion: QMIX算法在多智能体强化学习框架中表现出色，能够有效提升群体通信在反应式干扰下的韧性，接近理论最优性能，并在吞吐量和抗干扰方面优于基线方法。

Abstract: Reactive jammers pose a severe security threat to robotic-swarm networks by selectively disrupting inter-agent communications and undermining formation integrity and mission success. Conventional countermeasures such as fixed power control or static channel hopping are largely ineffective against such adaptive adversaries. This paper presents a multi-agent reinforcement learning (MARL) framework based on the QMIX algorithm to improve the resilience of swarm communications under reactive jamming. We consider a network of multiple transmitter-receiver pairs sharing channels while a reactive jammer with Markovian threshold dynamics senses aggregate power and reacts accordingly. Each agent jointly selects transmit frequency (channel) and power, and QMIX learns a centralized but factorizable action-value function that enables coordinated yet decentralized execution. We benchmark QMIX against a genie-aided optimal policy in a no-channel-reuse setting, and against local Upper Confidence Bound (UCB) and a stateless reactive policy in a more general fading regime with channel reuse enabled. Simulation results show that QMIX rapidly converges to cooperative policies that nearly match the genie-aided bound, while achieving higher throughput and lower jamming incidence than the baselines, thereby demonstrating MARL's effectiveness for securing autonomous swarms in contested environments.

</details>
