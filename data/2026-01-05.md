<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 68]
- [cs.SE](#cs.SE) [Total: 10]
- [cs.NI](#cs.NI) [Total: 6]
- [cs.GR](#cs.GR) [Total: 3]
- [cs.DC](#cs.DC) [Total: 4]
- [cs.RO](#cs.RO) [Total: 17]
- [cs.AI](#cs.AI) [Total: 24]
- [cs.DS](#cs.DS) [Total: 4]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [TeleWorld: Towards Dynamic Multimodal Synthesis with a 4D World Model](https://arxiv.org/abs/2601.00051)
*Yabo Chen,Yuanzhi Liang,Jiepeng Wang,Tingxi Chen,Junfei Cheng,Zixiao Gu,Yuyang Huang,Zicheng Jiang,Wei Li,Tian Li,Weichen Li,Zuoxin Li,Guangce Liu,Jialun Liu,Junqi Liu,Haoyuan Wang,Qizhen Weng,Xuan'er Wu,Xunzhi Xiang,Xiaoyan Yang,Xin Zhang,Shiwen Zhang,Junyu Zhou,Chengcheng Zhou,Haibin Huang,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: TeleWorld是一个实时多模态4D世界建模框架，通过生成-重建-引导范式解决了现有视频生成模型的局限性，实现了动态和静态场景的统一建模，并在实验中展示了卓越性能。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型在实时交互、长时程一致性和动态场景的持久记忆方面存在局限，阻碍了其发展为实用的世界模型。TeleWorld旨在解决这些限制，提供一个统一的4D世界建模框架。

Method: TeleWorld采用了一种新颖的生成-重建-引导范式，结合了自回归扩散视频模型、Macro-from-Micro Planning（MMPL）层次规划方法和高效的Distribution Matching Distillation（DMD）技术，以实现低延迟的长时程生成。

Result: TeleWorld在静态和动态世界理解、长时程一致性和实时生成效率方面表现出色，成为迈向交互式、具备记忆功能的世界模型的实用一步。

Conclusion: TeleWorld通过其创新的生成-重建-引导范式，成功实现了动态和静态场景的统一4D建模，推动了世界模型向实用、交互式和计算可访问系统的迈进。

Abstract: World models aim to endow AI systems with the ability to represent, generate, and interact with dynamic environments in a coherent and temporally consistent manner. While recent video generation models have demonstrated impressive visual quality, they remain limited in real-time interaction, long-horizon consistency, and persistent memory of dynamic scenes, hindering their evolution into practical world models. In this report, we present TeleWorld, a real-time multimodal 4D world modeling framework that unifies video generation, dynamic scene reconstruction, and long-term world memory within a closed-loop system. TeleWorld introduces a novel generation-reconstruction-guidance paradigm, where generated video streams are continuously reconstructed into a dynamic 4D spatio-temporal representation, which in turn guides subsequent generation to maintain spatial, temporal, and physical consistency. To support long-horizon generation with low latency, we employ an autoregressive diffusion-based video model enhanced with Macro-from-Micro Planning (MMPL)--a hierarchical planning method that reduces error accumulation from frame-level to segment-level-alongside efficient Distribution Matching Distillation (DMD), enabling real-time synthesis under practical computational budgets. Our approach achieves seamless integration of dynamic object modeling and static scene representation within a unified 4D framework, advancing world models toward practical, interactive, and computationally accessible systems. Extensive experiments demonstrate that TeleWorld achieves strong performance in both static and dynamic world understanding, long-term consistency, and real-time generation efficiency, positioning it as a practical step toward interactive, memory-enabled world models for multimodal generation and embodied intelligence.

</details>


### [2] [It's Never Too Late: Noise Optimization for Collapse Recovery in Trained Diffusion Models](https://arxiv.org/abs/2601.00090)
*Anne Harrington,A. Sophia Koepke,Shyamgopal Karthik,Trevor Darrell,Alexei A. Efros*

Main category: cs.CV

TL;DR: 通过噪声优化提升文本到图像生成的多样性，缓解模式崩溃。


<details>
  <summary>Details</summary>
Motivation: 解决文本到图像生成模型在相同提示下生成图像时的模式崩溃问题。

Method: 采用简单的噪声优化目标，并分析噪声的频率特性，探索不同频率分布的噪声初始化对优化和搜索的影响。

Result: 实验表明，噪声优化在生成质量和多样性方面均优于现有方法。

Conclusion: 通过噪声优化可以有效缓解文本到图像生成模型中的模式崩溃问题，同时保持基础模型的保真度。

Abstract: Contemporary text-to-image models exhibit a surprising degree of mode collapse, as can be seen when sampling several images given the same text prompt. While previous work has attempted to address this issue by steering the model using guidance mechanisms, or by generating a large pool of candidates and refining them, in this work we take a different direction and aim for diversity in generations via noise optimization. Specifically, we show that a simple noise optimization objective can mitigate mode collapse while preserving the fidelity of the base model. We also analyze the frequency characteristics of the noise and show that alternative noise initializations with different frequency profiles can improve both optimization and search. Our experiments demonstrate that noise optimization yields superior results in terms of generation quality and variety.

</details>


### [3] [Spatial4D-Bench: A Versatile 4D Spatial Intelligence Benchmark](https://arxiv.org/abs/2601.00092)
*Pan Wang,Yang Liu,Guile Wu,Eduardo R. Corral-Soto,Chengjie Huang,Binbin Xu,Dongfeng Bai,Xu Yan,Yuan Ren,Xingxin Chen,Yizhe Wu,Tao Huang,Wenjun Wan,Xin Wu,Pei Zhou,Xuyang Dai,Kangbo Lv,Hongbo Zhang,Yosef Fried,Aixue Ye,Bailan Feng,Zhenyu Chen,Zhen Li,Yingcong Chen,Yiyi Liao,Bingbing Liu*

Main category: cs.CV

TL;DR: Spatial4D-Bench是一个大规模、多任务的4D空间智能基准测试，揭示了当前MLLMs在空间推理上的不足，旨在推动更强大模型的发展。


<details>
  <summary>Details</summary>
Motivation: 探讨多模态大语言模型（MLLMs）是否能达到人类水平的4D空间智能，并填补现有空间智能基准测试在小规模和多样性上的不足。

Method: 本研究提出了Spatial4D-Bench，一个包含约40,000个问答对、覆盖18个任务的4D空间智能基准测试，系统性地将这些任务分为六个认知类别。

Result: 基准测试显示，当前最先进的MLLMs在多种4D空间推理任务（如路线规划、动作识别和物理合理性推理）中存在显著局限性。

Conclusion: Spatial4D-Bench 揭示了当前多模态大语言模型（MLLMs）在4D空间推理能力上的显著局限性，并希望该基准测试能推动更强大的MLLMs发展，以实现人类水平的4D空间智能。

Abstract: 4D spatial intelligence involves perceiving and processing how objects move or change over time. Humans naturally possess 4D spatial intelligence, supporting a broad spectrum of spatial reasoning abilities. To what extent can Multimodal Large Language Models (MLLMs) achieve human-level 4D spatial intelligence? In this work, we present Spatial4D-Bench, a versatile 4D spatial intelligence benchmark designed to comprehensively assess the 4D spatial reasoning abilities of MLLMs. Unlike existing spatial intelligence benchmarks that are often small-scale or limited in diversity, Spatial4D-Bench provides a large-scale, multi-task evaluation benchmark consisting of ~40,000 question-answer pairs covering 18 well-defined tasks. We systematically organize these tasks into six cognitive categories: object understanding, scene understanding, spatial relationship understanding, spatiotemporal relationship understanding, spatial reasoning and spatiotemporal reasoning. Spatial4D-Bench thereby offers a structured and comprehensive benchmark for evaluating the spatial cognition abilities of MLLMs, covering a broad spectrum of tasks that parallel the versatility of human spatial intelligence. We benchmark various state-of-the-art open-source and proprietary MLLMs on Spatial4D-Bench and reveal their substantial limitations in a wide variety of 4D spatial reasoning aspects, such as route plan, action recognition, and physical plausibility reasoning. We hope that the findings provided in this work offer valuable insights to the community and that our benchmark can facilitate the development of more capable MLLMs toward human-level 4D spatial intelligence. More resources can be found on our project page.

</details>


### [4] [MotionPhysics: Learnable Motion Distillation for Text-Guided Simulation](https://arxiv.org/abs/2601.00504)
*Miaowei Wang,Jakub Zadrożny,Oisin Mac Aodha,Amir Vaxman*

Main category: cs.CV

TL;DR: MotionPhysics利用自然语言提示自动推断物理参数，实现高效且真实的3D动态模拟。


<details>
  <summary>Details</summary>
Motivation: 现有3D对象和材料的模拟需要专家知识和耗时参数调整，缺乏自动化解决方案。

Method: 结合多模态大语言模型估计材料参数，并提出可学习的运动蒸馏损失从预训练视频扩散模型中提取运动先验。

Result: 在30多个场景中验证，涵盖多种材料和对象，模拟效果优于现有技术。

Conclusion: MotionPhysics通过自然语言提示自动推断物理参数，无需真实轨迹或标注视频，显著提升了3D动态模拟的效率和真实性。

Abstract: Accurately simulating existing 3D objects and a wide variety of materials often demands expert knowledge and time-consuming physical parameter tuning to achieve the desired dynamic behavior. We introduce MotionPhysics, an end-to-end differentiable framework that infers plausible physical parameters from a user-provided natural language prompt for a chosen 3D scene of interest, removing the need for guidance from ground-truth trajectories or annotated videos. Our approach first utilizes a multimodal large language model to estimate material parameter values, which are constrained to lie within plausible ranges. We further propose a learnable motion distillation loss that extracts robust motion priors from pretrained video diffusion models while minimizing appearance and geometry inductive biases to guide the simulation. We evaluate MotionPhysics across more than thirty scenarios, including real-world, human-designed, and AI-generated 3D objects, spanning a wide range of materials such as elastic solids, metals, foams, sand, and both Newtonian and non-Newtonian fluids. We demonstrate that MotionPhysics produces visually realistic dynamic simulations guided by natural language, surpassing the state of the art while automatically determining physically plausible parameters. The code and project page are available at: https://wangmiaowei.github.io/MotionPhysics.github.io/.

</details>


### [5] [A Spatially Masked Adaptive Gated Network for multimodal post-flood water extent mapping using SAR and incomplete multispectral data](https://arxiv.org/abs/2601.00123)
*Hyunho Lee,Wenwen Li*

Main category: cs.CV

TL;DR: SMAGNet是一种多模态深度学习模型，通过融合SAR和MSI数据提升洪水水域范围绘制的准确性，尤其在数据缺失时仍保持高性能。


<details>
  <summary>Details</summary>
Motivation: 在洪水事件中，及时准确地绘制水域范围对灾害管理至关重要。虽然SAR数据常用于此，但结合SAR和MSI数据的多模态方法能提升准确性，尤其是在观测数据有限时。然而，如何自适应地整合部分可用的MSI数据仍待探索。

Method: 提出了Spatially Masked Adaptive Gated Network (SMAGNet)，一种多模态深度学习模型，以SAR数据为主要输入，通过特征融合整合互补的MSI数据。

Result: 在C2S-MS Floods数据集上，SMAGNet在不同MSI数据可用性水平下均优于其他多模态深度学习模型，且在MSI数据完全缺失时性能仍与仅使用SAR数据的U-Net相当。

Conclusion: SMAGNet模型在MSI数据部分或完全缺失的情况下，仍能保持与仅使用SAR数据的U-Net模型相当的预测性能，增强了多模态深度学习在现实洪水管理场景中的适用性和鲁棒性。

Abstract: Mapping water extent during a flood event is essential for effective disaster management throughout all phases: mitigation, preparedness, response, and recovery. In particular, during the response stage, when timely and accurate information is important, Synthetic Aperture Radar (SAR) data are primarily employed to produce water extent maps. Recently, leveraging the complementary characteristics of SAR and MSI data through a multimodal approach has emerged as a promising strategy for advancing water extent mapping using deep learning models. This approach is particularly beneficial when timely post-flood observations, acquired during or shortly after the flood peak, are limited, as it enables the use of all available imagery for more accurate post-flood water extent mapping. However, the adaptive integration of partially available MSI data into the SAR-based post-flood water extent mapping process remains underexplored. To bridge this research gap, we propose the Spatially Masked Adaptive Gated Network (SMAGNet), a multimodal deep learning model that utilizes SAR data as the primary input for post-flood water extent mapping and integrates complementary MSI data through feature fusion. In experiments on the C2S-MS Floods dataset, SMAGNet consistently outperformed other multimodal deep learning models in prediction performance across varying levels of MSI data availability. Furthermore, we found that even when MSI data were completely missing, the performance of SMAGNet remained statistically comparable to that of a U-Net model trained solely on SAR data. These findings indicate that SMAGNet enhances the model robustness to missing data as well as the applicability of multimodal deep learning in real-world flood management scenarios.

</details>


### [6] [Compressed Map Priors for 3D Perception](https://arxiv.org/abs/2601.00139)
*Brady Zhou,Philipp Krähenbühl*

Main category: cs.CV

TL;DR: CMP框架通过压缩历史遍历数据学习空间先验，以极低存储和计算成本提升3D物体检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有自动驾驶视觉系统大多忽略历史遍历数据，而实际上大多数区域已被多次访问，利用这些数据可提升感知性能。

Method: 提出了一种基于二值化哈希图的压缩地图先验（CMP）框架，存储需求仅为32KB/km²，比密集存储减少20倍。

Result: 在nuScenes数据集上，CMP框架与多种架构结合，显著且一致地提升了3D物体检测性能。

Conclusion: Compressed Map Priors (CMP) 框架通过利用历史遍历数据学习空间先验，显著提升了3D物体检测性能，且计算成本极低。

Abstract: Human drivers rarely travel where no person has gone before. After all, thousands of drivers use busy city roads every day, and only one can claim to be the first. The same holds for autonomous computer vision systems. The vast majority of the deployment area of an autonomous vision system will have been visited before. Yet, most autonomous vehicle vision systems act as if they are encountering each location for the first time. In this work, we present Compressed Map Priors (CMP), a simple but effective framework to learn spatial priors from historic traversals. The map priors use a binarized hashmap that requires only $32\text{KB}/\text{km}^2$, a $20\times$ reduction compared to the dense storage. Compressed Map Priors easily integrate into leading 3D perception systems at little to no extra computational costs, and lead to a significant and consistent improvement in 3D object detection on the nuScenes dataset across several architectures.

</details>


### [7] [Attention to Detail: Global-Local Attention for High-Resolution AI-Generated Image Detection](https://arxiv.org/abs/2601.00141)
*Lawrence Han*

Main category: cs.CV

TL;DR: GLASS架构通过全局与局部信息结合，提升AI生成图像检测性能，实验验证其优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成图像检测架构通常在输入模型前对图像进行降采样，可能导致细粒度细节丢失。

Method: GLASS结合全局调整大小的视图与多个随机采样的局部裁剪，通过空间分层采样高效选择原始分辨率区域，并使用基于注意力的评分进行聚合。

Result: 实验表明，GLASS在Vision Transformer、ResNet和ConvNeXt等骨干网络上优于标准迁移学习，预测性能更高。

Conclusion: GLASS架构通过结合全局和局部信息，显著提升了AI生成图像检测的性能，且计算效率可行。

Abstract: The rapid development of generative AI has made AI-generated images increasingly realistic and high-resolution. Most AI-generated image detection architectures typically downsample images before inputting them into models, risking the loss of fine-grained details. This paper presents GLASS (Global-Local Attention with Stratified Sampling), an architecture that combines a globally resized view with multiple randomly sampled local crops. These crops are original-resolution regions efficiently selected through spatially stratified sampling and aggregated using attention-based scoring. GLASS can be integrated into vision models to leverage both global and local information in images of any size. Vision Transformer, ResNet, and ConvNeXt models are used as backbones, and experiments show that GLASS outperforms standard transfer learning by achieving higher predictive performance within feasible computational constraints.

</details>


### [8] [FCMBench: A Comprehensive Financial Credit Multimodal Benchmark for Real-world Applications](https://arxiv.org/abs/2601.00150)
*Yehui Yang,Dalu Yang,Wenshuo Zhou,Fangxin Shang,Yifan Liu,Jie Ren,Haojun Fei,Qing Yang,Tao Chen*

Main category: cs.CV

TL;DR: FCMBench-V1.0是一个金融信贷多模态基准，通过合成-捕获管道构建样本，评估模型在感知、推理和鲁棒性上的表现，实验显示专用模型Qfin-VL-Instruct表现最佳。


<details>
  <summary>Details</summary>
Motivation: 由于多模态AI在信贷风险评估和文档审查中的广泛应用，亟需一个反映金融信贷特定文档和工作流程、包含信贷特定理解及现实鲁棒性、同时符合隐私合规性的领域基准。

Method: 通过封闭的合成-捕获管道构建样本，包括手动合成文档模板和内部捕获场景感知图像，以避免预训练数据泄露。

Result: 在23个先进视觉语言模型上的广泛实验表明，Gemini 3 Pro（商业模型）和Qwen3-VL-235B（开源基线）表现优异，而金融信贷专用模型Qfin-VL-Instruct总体得分最高。鲁棒性评估显示，即使是顶级模型在采集伪影下性能也会显著下降。

Conclusion: FCMBench-V1.0是一个针对金融信贷领域的多模态基准测试，能够有效评估模型在感知、推理和鲁棒性方面的表现，并在实验中展示了不同模型的性能差异。

Abstract: As multimodal AI becomes widely used for credit risk assessment and document review, a domain-specific benchmark is urgently needed that (1) reflects documents and workflows specific to financial credit applications, (2) includes credit-specific understanding and real-world robustness, and (3) preserves privacy compliance without sacrificing practical utility. Here, we introduce FCMBench-V1.0 -- a large-scale financial credit multimodal benchmark for real-world applications, covering 18 core certificate types, with 4,043 privacy-compliant images and 8,446 QA samples. The FCMBench evaluation framework consists of three dimensions: Perception, Reasoning, and Robustness, including 3 foundational perception tasks, 4 credit-specific reasoning tasks that require decision-oriented understanding of visual evidence, and 10 real-world acquisition artifact types for robustness stress testing. To reconcile compliance with realism, we construct all samples via a closed synthesis-capture pipeline: we manually synthesize document templates with virtual content and capture scenario-aware images in-house. This design also mitigates pre-training data leakage by avoiding web-sourced or publicly released images. FCMBench can effectively discriminate performance disparities and robustness across modern vision-language models. Extensive experiments were conducted on 23 state-of-the-art vision-language models (VLMs) from 14 top AI companies and research institutes. Among them, Gemini 3 Pro achieves the best F1(\%) score as a commercial model (64.61), Qwen3-VL-235B achieves the best score as an open-source baseline (57.27), and our financial credit-specific model, Qfin-VL-Instruct, achieves the top overall score (64.92). Robustness evaluations show that even top-performing models suffer noticeable performance drops under acquisition artifacts.

</details>


### [9] [Focal-RegionFace: Generating Fine-Grained Multi-attribute Descriptions for Arbitrarily Selected Face Focal Regions](https://arxiv.org/abs/2601.00156)
*Kaiwen Zheng,Junchen Fu,Songpei Xu,Yaoqing He,Joemon M. Jose,Han Hu,Xuri Ge*

Main category: cs.CV

TL;DR: 提出Focal-RegionFace模型，通过多阶段微调聚焦局部面部特征，实现多属性面部区域描述生成与识别，性能优异。


<details>
  <summary>Details</summary>
Motivation: 解决面部分析中未充分探索的问题：生成和识别包含面部动作单元（AUs）、情感状态和年龄估计的多属性自然语言描述，针对任意选定的面部区域（FaceFocalDesc）。

Method: 基于Qwen2.5-VL微调的视觉语言模型Focal-RegionFace，通过多阶段渐进式微调逐步聚焦局部面部特征。

Result: Focal-RegionFace在新基准上以传统和广泛使用的指标以及新提出的指标均取得最佳性能。

Conclusion: Focal-RegionFace在细粒度多属性面部区域焦点分析场景中表现出高效性和多功能性，验证了其在新基准上的最佳性能。

Abstract: In this paper, we introduce an underexplored problem in facial analysis: generating and recognizing multi-attribute natural language descriptions, containing facial action units (AUs), emotional states, and age estimation, for arbitrarily selected face regions (termed FaceFocalDesc). We argue that the system's ability to focus on individual facial areas leads to better understanding and control. To achieve this capability, we construct a new multi-attribute description dataset for arbitrarily selected face regions, providing rich region-level annotations and natural language descriptions. Further, we propose a fine-tuned vision-language model based on Qwen2.5-VL, called Focal-RegionFace for facial state analysis, which incrementally refines its focus on localized facial features through multiple progressively fine-tuning stages, resulting in interpretable age estimation, FAU and emotion detection. Experimental results show that Focal-RegionFace achieves the best performance on the new benchmark in terms of traditional and widely used metrics, as well as new proposed metrics. This fully verifies its effectiveness and versatility in fine-grained multi-attribute face region-focal analysis scenarios.

</details>


### [10] [DichroGAN: Towards Restoration of in-air Colours of Seafloor from Satellite Imagery](https://arxiv.org/abs/2601.00194)
*Salma Gonzalez-Sabbagh,Antonio Robles-Kelly,Shang Gao*

Main category: cs.CV

TL;DR: DichroGAN是一种cGAN网络，通过多生成器协同恢复海底图像的空中颜色，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 由于光在水中的指数衰减，从卫星图像恢复海底空中颜色具有挑战性，因此设计了DichroGAN来解决这一问题。

Method: DichroGAN采用条件生成对抗网络（cGAN），通过两个生成器估计漫反射和镜面反射获取大气场景辐射，再由第三和第四生成器分别处理光谱特征和光传输，最终消除光吸收和散射影响。

Result: 在PRISMA卫星图像和 underwater数据集上的实验表明，DichroGAN性能优于现有技术。

Conclusion: DichroGAN通过两步训练和多个生成器的协同工作，成功恢复了海底图像的空中颜色，性能优于现有水下恢复技术。

Abstract: Recovering the in-air colours of seafloor from satellite imagery is a challenging task due to the exponential attenuation of light with depth in the water column. In this study, we present DichroGAN, a conditional generative adversarial network (cGAN) designed for this purpose. DichroGAN employs a two-steps simultaneous training: first, two generators utilise a hyperspectral image cube to estimate diffuse and specular reflections, thereby obtaining atmospheric scene radiance. Next, a third generator receives as input the generated scene radiance containing the features of each spectral band, while a fourth generator estimates the underwater light transmission. These generators work together to remove the effects of light absorption and scattering, restoring the in-air colours of seafloor based on the underwater image formation equation. DichroGAN is trained on a compact dataset derived from PRISMA satellite imagery, comprising RGB images paired with their corresponding spectral bands and masks. Extensive experiments on both satellite and underwater datasets demonstrate that DichroGAN achieves competitive performance compared to state-of-the-art underwater restoration techniques.

</details>


### [11] [MorphAny3D: Unleashing the Power of Structured Latent in 3D Morphing](https://arxiv.org/abs/2601.00204)
*Xiaokun Sun,Zeyu Cai,Hao Tang,Ying Tai,Jian Yang,Zhenyu Zhang*

Main category: cs.CV

TL;DR: MorphAny3D是一种无需训练的框架，通过SLAT表示和创新的注意力机制（MCA和TFSA）实现高质量3D变形，尤其在跨类别任务中表现优异，并支持高级应用。


<details>
  <summary>Details</summary>
Motivation: 解决3D变形中语义一致性和时间平滑性的挑战，尤其是在跨类别情况下。

Method: 该方法利用Structured Latent (SLAT)表示，通过智能混合源和目标SLAT特征在3D生成器的注意力机制中生成变形序列。具体包括MCA用于结构一致性，TFSA用于时间一致性，以及姿态校正策略。

Result: 实验表明，MorphAny3D在生成高质量变形序列方面达到了最先进水平，尤其在跨类别任务中表现突出，并支持高级应用如解耦变形和3D风格迁移。

Conclusion: MorphAny3D通过引入Morphing Cross-Attention (MCA)和Temporal-Fused Self-Attention (TFSA)等创新机制，成功实现了高质量、语义一致且时间平滑的3D变形，尤其在跨类别任务中表现优异。该方法还支持解耦变形和3D风格迁移等高级应用，并具有通用性。

Abstract: 3D morphing remains challenging due to the difficulty of generating semantically consistent and temporally smooth deformations, especially across categories. We present MorphAny3D, a training-free framework that leverages Structured Latent (SLAT) representations for high-quality 3D morphing. Our key insight is that intelligently blending source and target SLAT features within the attention mechanisms of 3D generators naturally produces plausible morphing sequences. To this end, we introduce Morphing Cross-Attention (MCA), which fuses source and target information for structural coherence, and Temporal-Fused Self-Attention (TFSA), which enhances temporal consistency by incorporating features from preceding frames. An orientation correction strategy further mitigates the pose ambiguity within the morphing steps. Extensive experiments show that our method generates state-of-the-art morphing sequences, even for challenging cross-category cases. MorphAny3D further supports advanced applications such as decoupled morphing and 3D style transfer, and can be generalized to other SLAT-based generative models. Project page: https://xiaokunsun.github.io/MorphAny3D.github.io/.

</details>


### [12] [CropNeRF: A Neural Radiance Field-Based Framework for Crop Counting](https://arxiv.org/abs/2601.00207)
*Md Ahmed Al Muzaddid,William J. Beksi*

Main category: cs.CV

TL;DR: 提出一种基于3D实例分割的作物计数框架，通过多视角图像和NeRF技术实现高精度计数，无需作物特定参数调整，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决户外田间环境中作物部分遮挡和聚类作物区分模糊的问题，提升图像分割方法的准确性。

Method: 利用多视角2D图像和NeRF视图合成，结合作物可见性和掩码一致性评分，进行3D实例分割。

Result: 在棉花、苹果和梨的数据集上验证了方法的有效性，展示了在作物颜色、形状和大小差异下的稳定计数性能。

Conclusion: 该论文提出了一种基于3D实例分割的新型作物计数框架，通过多视角2D图像和NeRF视图合成，结合作物可见性和掩码一致性评分，实现了高精度的作物计数，并在多种作物数据集上验证了其优越性能。

Abstract: Rigorous crop counting is crucial for effective agricultural management and informed intervention strategies. However, in outdoor field environments, partial occlusions combined with inherent ambiguity in distinguishing clustered crops from individual viewpoints poses an immense challenge for image-based segmentation methods. To address these problems, we introduce a novel crop counting framework designed for exact enumeration via 3D instance segmentation. Our approach utilizes 2D images captured from multiple viewpoints and associates independent instance masks for neural radiance field (NeRF) view synthesis. We introduce crop visibility and mask consistency scores, which are incorporated alongside 3D information from a NeRF model. This results in an effective segmentation of crop instances in 3D and highly-accurate crop counts. Furthermore, our method eliminates the dependence on crop-specific parameter tuning. We validate our framework on three agricultural datasets consisting of cotton bolls, apples, and pears, and demonstrate consistent counting performance despite major variations in crop color, shape, and size. A comparative analysis against the state of the art highlights superior performance on crop counting tasks. Lastly, we contribute a cotton plant dataset to advance further research on this topic.

</details>


### [13] [IntraStyler: Exemplar-based Style Synthesis for Cross-modality Domain Adaptation](https://arxiv.org/abs/2601.00212)
*Han Liu,Yubo Fan,Hao Li,Dewei Hu,Daniel Moyer,Zhoubing Xu,Benoit M. Dawant,Ipek Oguz*

Main category: cs.CV

TL;DR: IntraStyler是一种无需先验知识的风格合成方法，通过示例图像引导风格生成，提升目标域数据多样性，助力下游分割任务。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法需要预先指定域内变异的局限性，探索无需先验知识的风格合成。

Method: 提出了一种基于示例的风格合成方法IntraStyler，通过风格编码器和对比学习来提取风格特征。

Result: 在CrossMoDA 2023数据集上验证了方法的有效性，尤其在可控风格合成和下游分割任务中表现优异。

Conclusion: IntraStyler通过无需先验知识的风格合成方法，有效提升了目标域数据的多样性，并在下游分割任务中显示出优势。

Abstract: Image-level domain alignment is the de facto approach for unsupervised domain adaptation, where unpaired image translation is used to minimize the domain gap. Prior studies mainly focus on the domain shift between the source and target domains, whereas the intra-domain variability remains under-explored. To address the latter, an effective strategy is to diversify the styles of the synthetic target domain data during image translation. However, previous methods typically require intra-domain variations to be pre-specified for style synthesis, which may be impractical. In this paper, we propose an exemplar-based style synthesis method named IntraStyler, which can capture diverse intra-domain styles without any prior knowledge. Specifically, IntraStyler uses an exemplar image to guide the style synthesis such that the output style matches the exemplar style. To extract the style-only features, we introduce a style encoder to learn styles discriminatively based on contrastive learning. We evaluate the proposed method on the largest public dataset for cross-modality domain adaptation, CrossMoDA 2023. Our experiments show the efficacy of our method in controllable style synthesis and the benefits of diverse synthetic data for downstream segmentation. Code is available at https://github.com/han-liu/IntraStyler.

</details>


### [14] [From Sight to Insight: Improving Visual Reasoning Capabilities of Multimodal Models via Reinforcement Learning](https://arxiv.org/abs/2601.00215)
*Omar Sharif,Eftekhar Hossain,Patrick Ng*

Main category: cs.CV

TL;DR: 通过奖励驱动的RL方法提升MLLMs的视觉推理能力，实验显示性能提升5.56%。


<details>
  <summary>Details</summary>
Motivation: 当前MLLMs生成的推理链缺乏视觉信息的整合，限制了其在需要准确视觉感知的任务（如视觉谜题）中的表现。

Method: 采用奖励驱动的RL方法，设计了六个针对不同推理方面的奖励函数，并使用组相对策略优化（GRPO）来激励更长的结构化推理。

Result: 实验表明，该方法在Qwen-2.5-VL-7B模型上实现了5.56%的性能提升，且在域内和域外设置中均表现一致。

Conclusion: 强化学习（RL）通过奖励驱动机制显著提升了多模态大语言模型（MLLMs）在视觉推理任务中的表现，尤其是在需要准确视觉感知的任务中。

Abstract: Reinforcement learning (RL) has emerged as a promising approach for eliciting reasoning chains before generating final answers. However, multimodal large language models (MLLMs) generate reasoning that lacks integration of visual information. This limits their ability to solve problems that demand accurate visual perception, such as visual puzzles. We show that visual perception is the key bottleneck in such tasks: converting images into textual descriptions significantly improves performance, yielding gains of 26.7% for Claude 3.5 and 23.6% for Claude 3.7.
  To address this, we investigate reward-driven RL as a mechanism to unlock long visual reasoning in open-source MLLMs without requiring costly supervision. We design and evaluate six reward functions targeting different reasoning aspects, including image understanding, thinking steps, and answer accuracy. Using group relative policy optimization (GRPO), our approach explicitly incentivizes longer, structured reasoning and mitigates bypassing of visual information. Experiments on Qwen-2.5-VL-7B achieve 5.56% improvements over the base model, with consistent gains across both in-domain and out-of-domain settings.

</details>


### [15] [LooC: Effective Low-Dimensional Codebook for Compositional Vector Quantization](https://arxiv.org/abs/2601.00222)
*Jie Li,Kwan-Yee K. Wong,Kai Han*

Main category: cs.CV

TL;DR: LooC 是一种新型低维码本组合向量量化方法，通过重构码向量与特征向量的关系，实现了更紧凑且高性能的量化，适用于多种下游任务。


<details>
  <summary>Details</summary>
Motivation: 随着数据和模型复杂度的增加，现有向量量化方法在高容量和紧凑性之间存在冲突，LooC 旨在解决这一问题。

Method: LooC 采用参数高效的码本设计，将码向量视为特征向量中的低维组合单元，并通过参数无关的插值外推机制增强特征平滑度。

Result: LooC 在不同任务、数据集和架构上的评估表明，其性能优于现有方法，且码本尺寸显著减小。

Conclusion: LooC 提出了一种新型的低维码本组合向量量化方法，通过重构码向量与特征向量的关系，显著扩大了解决方案空间，并在保持高保真度的同时实现了更紧凑的码本设计。

Abstract: Vector quantization (VQ) is a prevalent and fundamental technique that discretizes continuous feature vectors by approximating them using a codebook. As the diversity and complexity of data and models continue to increase, there is an urgent need for high-capacity, yet more compact VQ methods. This paper aims to reconcile this conflict by presenting a new approach called LooC, which utilizes an effective Low-dimensional codebook for Compositional vector quantization. Firstly, LooC introduces a parameter-efficient codebook by reframing the relationship between codevectors and feature vectors, significantly expanding its solution space. Instead of individually matching codevectors with feature vectors, LooC treats them as lower-dimensional compositional units within feature vectors and combines them, resulting in a more compact codebook with improved performance. Secondly, LooC incorporates a parameter-free extrapolation-by-interpolation mechanism to enhance and smooth features during the VQ process, which allows for better preservation of details and fidelity in feature approximation. The design of LooC leads to full codebook usage, effectively utilizing the compact codebook while avoiding the problem of collapse. Thirdly, LooC can serve as a plug-and-play module for existing methods for different downstream tasks based on VQ. Finally, extensive evaluations on different tasks, datasets, and architectures demonstrate that LooC outperforms existing VQ methods, achieving state-of-the-art performance with a significantly smaller codebook.

</details>


### [16] [Towards Syn-to-Real IQA: A Novel Perspective on Reshaping Synthetic Data Distributions](https://arxiv.org/abs/2601.00225)
*Aobo Li,Jinjian Wu,Yongxu Liu,Leida Li,Weisheng Dong*

Main category: cs.CV

TL;DR: SynDR-IQA通过调整合成数据分布提升BIQA泛化能力，采用多样化上采样和冗余聚类下采样策略，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有合成数据集训练的BIQA模型泛化能力有限，研究发现这是由于合成数据的分布导致学习到的特征呈现离散和聚类模式，从而影响回归性能。

Method: 提出SynDR-IQA框架，包含两种策略：1）分布感知的多样化内容上采样，增强视觉多样性同时保持内容分布；2）密度感知的冗余聚类下采样，通过减少密集聚类区域的样本密度来平衡样本。

Result: 在三种跨数据集设置（合成到真实、合成到算法、合成到合成）上的大量实验证明了该方法的有效性。

Conclusion: SynDR-IQA框架通过调整合成数据的分布，显著提升了盲图像质量评估（BIQA）的泛化能力，解决了现有合成数据集训练模型泛化能力有限的问题。

Abstract: Blind Image Quality Assessment (BIQA) has advanced significantly through deep learning, but the scarcity of large-scale labeled datasets remains a challenge. While synthetic data offers a promising solution, models trained on existing synthetic datasets often show limited generalization ability. In this work, we make a key observation that representations learned from synthetic datasets often exhibit a discrete and clustered pattern that hinders regression performance: features of high-quality images cluster around reference images, while those of low-quality images cluster based on distortion types. Our analysis reveals that this issue stems from the distribution of synthetic data rather than model architecture. Consequently, we introduce a novel framework SynDR-IQA, which reshapes synthetic data distribution to enhance BIQA generalization. Based on theoretical derivations of sample diversity and redundancy's impact on generalization error, SynDR-IQA employs two strategies: distribution-aware diverse content upsampling, which enhances visual diversity while preserving content distribution, and density-aware redundant cluster downsampling, which balances samples by reducing the density of densely clustered areas. Extensive experiments across three cross-dataset settings (synthetic-to-authentic, synthetic-to-algorithmic, and synthetic-to-synthetic) demonstrate the effectiveness of our method. The code is available at https://github.com/Li-aobo/SynDR-IQA.

</details>


### [17] [Application Research of a Deep Learning Model Integrating CycleGAN and YOLO in PCB Infrared Defect Detection](https://arxiv.org/abs/2601.00237)
*Chao Yang,Haoyuan Zheng,Yue Ma*

Main category: cs.CV

TL;DR: 通过CycleGAN和YOLOv8的跨模态数据增强框架，解决了红外数据稀缺问题，显著提升了PCB缺陷检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决红外数据稀缺在PCB缺陷检测中的关键瓶颈问题。

Method: 提出了一种结合CycleGAN和YOLOv8的跨模态数据增强框架，利用CycleGAN进行无配对图像转换，将丰富的可见光PCB图像映射到红外域，生成高保真伪红外样本。随后，采用异构训练策略融合生成的伪红外数据和有限的真实红外样本训练轻量级YOLOv8检测器。

Result: 实验结果表明，该方法在低数据条件下有效增强了特征学习，增强后的检测器性能显著优于仅使用有限真实数据训练的模型，并接近全监督训练的性能基准。

Conclusion: 该方法通过跨模态数据增强框架显著提升了在红外数据稀缺条件下的PCB缺陷检测性能，证明了伪红外合成作为工业检测中稳健增强策略的有效性。

Abstract: This paper addresses the critical bottleneck of infrared (IR) data scarcity in Printed Circuit Board (PCB) defect detection by proposing a cross-modal data augmentation framework integrating CycleGAN and YOLOv8. Unlike conventional methods relying on paired supervision, we leverage CycleGAN to perform unpaired image-to-image translation, mapping abundant visible-light PCB images into the infrared domain. This generative process synthesizes high-fidelity pseudo-IR samples that preserve the structural semantics of defects while accurately simulating thermal distribution patterns. Subsequently, we construct a heterogeneous training strategy that fuses generated pseudo-IR data with limited real IR samples to train a lightweight YOLOv8 detector. Experimental results demonstrate that this method effectively enhances feature learning under low-data conditions. The augmented detector significantly outperforms models trained on limited real data alone and approaches the performance benchmarks of fully supervised training, proving the efficacy of pseudo-IR synthesis as a robust augmentation strategy for industrial inspection.

</details>


### [18] [Context-Aware Pesticide Recommendation via Few-Shot Pest Recognition for Precision Agriculture](https://arxiv.org/abs/2601.00243)
*Anirudha Ghosh,Ritam Sarkar,Debaditya Barman*

Main category: cs.CV

TL;DR: 轻量级害虫检测与农药推荐框架，适合智能手机和无人机，帮助小农户实现高效环保的害虫管理。


<details>
  <summary>Details</summary>
Motivation: 传统害虫管理方法成本高、耗时长、劳动密集且对环境有害，因此需要一种适合低资源设备的解决方案。

Method: 框架包括两个主要组件：害虫检测模块（使用轻量级CNN结合原型元学习）和农药推荐模块（结合环境因素）。

Result: 实验结果表明，轻量级CNN在保持高精度的同时显著降低了计算复杂度，决策支持系统减少了传统化学农药的依赖。

Conclusion: 该研究提出的轻量级框架在减少计算复杂度的同时，实现了与最先进模型相媲美的高精度，展示了其在精准农业实时应用中的潜力。

Abstract: Effective pest management is crucial for enhancing agricultural productivity, especially for crops such as sugarcane and wheat that are highly vulnerable to pest infestations. Traditional pest management methods depend heavily on manual field inspections and the use of chemical pesticides. These approaches are often costly, time-consuming, labor-intensive, and can have a negative impact on the environment. To overcome these challenges, this study presents a lightweight framework for pest detection and pesticide recommendation, designed for low-resource devices such as smartphones and drones, making it suitable for use by small and marginal farmers.
  The proposed framework includes two main components. The first is a Pest Detection Module that uses a compact, lightweight convolutional neural network (CNN) combined with prototypical meta-learning to accurately identify pests even when only a few training samples are available. The second is a Pesticide Recommendation Module that incorporates environmental factors like crop type and growth stage to suggest safe and eco-friendly pesticide recommendations. To train and evaluate our framework, a comprehensive pest image dataset was developed by combining multiple publicly available datasets. The final dataset contains samples with different viewing angles, pest sizes, and background conditions to ensure strong generalization.
  Experimental results show that the proposed lightweight CNN achieves high accuracy, comparable to state-of-the-art models, while significantly reducing computational complexity. The Decision Support System additionally improves pest management by reducing dependence on traditional chemical pesticides and encouraging sustainable practices, demonstrating its potential for real-time applications in precision agriculture.

</details>


### [19] [TotalFM: An Organ-Separated Framework for 3D-CT Vision Foundation Models](https://arxiv.org/abs/2601.00260)
*Kohei Yamamoto,Tomohiro Kikuchi*

Main category: cs.CV

TL;DR: TotalFM是一种基于器官分离概念的放射学基础模型，通过高效学习3D-CT图像与语言表达的对应关系，在多项临床任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决在3D-CT体积数据上训练时的计算成本限制问题，同时平衡计算效率和表示能力。

Method: 通过分割技术和基于大型语言模型（LLM）的放射学报告处理自动化创建器官体积和发现-句子对，结合VideoMAE的自监督预训练和体积-文本对的对比学习。

Result: 在零样本器官病变分类任务中，83%的器官F1分数高于CT-CLIP，64%的器官高于Merlin；在零样本发现病变分类任务中，83%的发现类别AUROC高于Merlin；放射学报告生成任务中性能与现有视觉语言模型（VLM）相当。

Conclusion: 器官分离学习框架为3D-CT基础模型的实际应用提供了现实且有效的设计指南。

Abstract: While foundation models in radiology are expected to be applied to various clinical tasks, computational cost constraints remain a major challenge when training on 3D-CT volumetric data. In this study, we propose TotalFM, a radiological foundation model that efficiently learns the correspondence between 3D-CT images and linguistic expressions based on the concept of organ separation, utilizing a large-scale dataset of 140,000 series. By automating the creation of organ volume and finding-sentence pairs through segmentation techniques and Large Language Model (LLM)-based radiology report processing, and by combining self-supervised pre-training via VideoMAE with contrastive learning using volume-text pairs, we aimed to balance computational efficiency and representation capability. In zero-shot organ-wise lesion classification tasks, the proposed model achieved higher F1 scores in 83% (5/6) of organs compared to CT-CLIP and 64% (9/14) of organs compared to Merlin. These results suggest that the proposed model exhibits high generalization performance in a clinical evaluation setting using actual radiology report sentences. Furthermore, in zero-shot finding-wise lesion classification tasks, our model achieved a higher AUROC in 83% (25/30) of finding categories compared to Merlin. We also confirmed performance comparable to existing Vision-Language Models (VLMs) in radiology report generation tasks. Our results demonstrate that the organ-separated learning framework can serve as a realistic and effective design guideline for the practical implementation of 3D-CT foundation models.

</details>


### [20] [S1-MMAlign: A Large-Scale, Multi-Disciplinary Dataset for Scientific Figure-Text Understanding](https://arxiv.org/abs/2601.00264)
*He Wang,Longteng Guo,Pengkang Huo,Xuanxu Lin,Yichen Yuan,Jie Jiang,Jing Liu*

Main category: cs.CV

TL;DR: S1-MMAlign是一个跨学科的多模态数据集，通过AI增强流程显著提升了科学图像与文本的对齐质量。


<details>
  <summary>Details</summary>
Motivation: 解决科学图像与稀疏文本描述之间的语义鸿沟问题，推动科学发现中的多模态学习应用。

Method: 利用Qwen-VL多模态大模型系列构建了一个AI就绪的语义增强流程，通过综合论文摘要和引用上下文重新标注图像。

Result: 技术验证显示，语义增强显著提升了数据质量：基于SciBERT的伪困惑度指标显示语义模糊性降低，CLIP分数显示图像-文本对齐提升了18.21%。

Conclusion: S1-MMAlign数据集为科学领域的多模态学习提供了高质量的基础资源，显著提升了图像与文本的对齐质量，推动了AI在科学发现中的应用。

Abstract: Multimodal learning has revolutionized general domain tasks, yet its application in scientific discovery is hindered by the profound semantic gap between complex scientific imagery and sparse textual descriptions. We present S1-MMAlign, a large-scale, multi-disciplinary multimodal dataset comprising over 15.5 million high-quality image-text pairs derived from 2.5 million open-access scientific papers. Spanning disciplines from physics and biology to engineering, the dataset captures diverse visual modalities including experimental setups, heatmaps, and microscopic imagery. To address the pervasive issue of weak alignment in raw scientific captions, we introduce an AI-ready semantic enhancement pipeline that utilizes the Qwen-VL multimodal large model series to recaption images by synthesizing context from paper abstracts and citation contexts. Technical validation demonstrates that this enhancement significantly improves data quality: SciBERT-based pseudo-perplexity metrics show reduced semantic ambiguity, while CLIP scores indicate an 18.21% improvement in image-text alignment. S1-MMAlign provides a foundational resource for advancing scientific reasoning and cross-modal understanding in the era of AI for Science. The dataset is publicly available at https://huggingface.co/datasets/ScienceOne-AI/S1-MMAlign.

</details>


### [21] [Efficient Prediction of Dense Visual Embeddings via Distillation and RGB-D Transformers](https://arxiv.org/abs/2601.00359)
*Söhnke Benedikt Fischedick,Daniel Seichter,Benedict Stephan,Robin Schmidt,Horst-Michael Gross*

Main category: cs.CV

TL;DR: DVEFormer是一种基于RGB-D Transformer的高效方法，通过知识蒸馏学习细粒度嵌入，支持文本查询和3D映射，满足实时性需求。


<details>
  <summary>Details</summary>
Motivation: 为了在家庭环境中与未经训练的人类有效且直观地互动，机器人需要全面理解其周围环境。

Method: 提出了一种基于RGB-D Transformer的高效方法DVEFormer，通过知识蒸馏从Alpha-CLIP的教师嵌入中学习细粒度的像素级嵌入。

Result: 在常见室内数据集上的评估显示，该方法在满足实时性要求的同时达到了竞争性性能，完整模型运行速度为26.3 FPS，较小变体在NVIDIA Jetson AGX Orin上达到77.0 FPS。

Conclusion: DVEFormer作为一种传统分割方法的替代方案，不仅支持灵活的基于自然语言的查询，还能无缝集成到移动机器人的3D映射流程中。

Abstract: In domestic environments, robots require a comprehensive understanding of their surroundings to interact effectively and intuitively with untrained humans. In this paper, we propose DVEFormer - an efficient RGB-D Transformer-based approach that predicts dense text-aligned visual embeddings (DVE) via knowledge distillation. Instead of directly performing classical semantic segmentation with fixed predefined classes, our method uses teacher embeddings from Alpha-CLIP to guide our efficient student model DVEFormer in learning fine-grained pixel-wise embeddings. While this approach still enables classical semantic segmentation, e.g., via linear probing, it further enables flexible text-based querying and other applications, such as creating comprehensive 3D maps. Evaluations on common indoor datasets demonstrate that our approach achieves competitive performance while meeting real-time requirements, operating at 26.3 FPS for the full model and 77.0 FPS for a smaller variant on an NVIDIA Jetson AGX Orin. Additionally, we show qualitative results that highlight the effectiveness and possible use cases in real-world applications. Overall, our method serves as a drop-in replacement for traditional segmentation approaches while enabling flexible natural-language querying and seamless integration into 3D mapping pipelines for mobile robotics.

</details>


### [22] [ActErase: A Training-Free Paradigm for Precise Concept Erasure via Activation Patching](https://arxiv.org/abs/2601.00267)
*Yi Sun,Xinhao Zhong,Hongyan Li,Yimin Zhou,Junhao Li,Bin Chen,Xuan Wang*

Main category: cs.CV

TL;DR: ActErase 是一种无需训练的概念擦除方法，通过动态替换激活区域高效擦除敏感概念，同时保持模型生成能力。


<details>
  <summary>Details</summary>
Motivation: 现有的概念擦除方法依赖数据密集和计算昂贵的微调，存在局限性。

Method: 通过提示对分析识别激活差异区域，提取目标激活并在前向传播中动态替换输入激活。

Result: 在三个关键擦除任务（裸露、艺术风格和对象移除）中，ActErase 实现了最先进的擦除性能，并有效保留了模型的整体生成能力。

Conclusion: ActErase 提出了一种无需训练的轻量级概念擦除方法，通过动态替换激活区域实现了高效的概念擦除，同时保持了模型的生成能力，并展现出对抗攻击的鲁棒性。

Abstract: Recent advances in text-to-image diffusion models have demonstrated remarkable generation capabilities, yet they raise significant concerns regarding safety, copyright, and ethical implications. Existing concept erasure methods address these risks by removing sensitive concepts from pre-trained models, but most of them rely on data-intensive and computationally expensive fine-tuning, which poses a critical limitation. To overcome these challenges, inspired by the observation that the model's activations are predominantly composed of generic concepts, with only a minimal component can represent the target concept, we propose a novel training-free method (ActErase) for efficient concept erasure. Specifically, the proposed method operates by identifying activation difference regions via prompt-pair analysis, extracting target activations and dynamically replacing input activations during forward passes. Comprehensive evaluations across three critical erasure tasks (nudity, artistic style, and object removal) demonstrates that our training-free method achieves state-of-the-art (SOTA) erasure performance, while effectively preserving the model's overall generative capability. Our approach also exhibits strong robustness against adversarial attacks, establishing a new plug-and-play paradigm for lightweight yet effective concept manipulation in diffusion models.

</details>


### [23] [RGS-SLAM: Robust Gaussian Splatting SLAM with One-Shot Dense Initialization](https://arxiv.org/abs/2601.00705)
*Wei-Tse Cheng,Yen-Jen Chiou,Yuan-Fu Yang*

Main category: cs.CV

TL;DR: RGS-SLAM是一种基于高斯初始化的SLAM框架，通过一次性三角测量和置信感知优化，显著提升映射效率和渲染质量，兼容现有系统并实现实时性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决GS-SLAM中残差驱动密集化阶段的效率问题，RGS-SLAM旨在通过一次性初始化方法提高早期映射的稳定性和收敛速度。

Method: RGS-SLAM采用了一种训练免费的对应到高斯初始化方法，替代了GS-SLAM中的残差驱动密集化阶段。通过DINOv3描述符生成的密集多视角对应关系进行一次性三角测量，并通过置信感知的内点分类器进行优化，生成分布良好且结构感知的高斯种子。

Result: RGS-SLAM在纹理丰富和杂乱场景中提供了更高的渲染保真度，收敛速度提高了约20%，且完全兼容现有的GS-SLAM流程。

Conclusion: RGS-SLAM在TUM RGB-D和Replica数据集上表现出色，定位和重建精度与最先进的基于高斯和点的SLAM系统相当或更优，同时保持高达925 FPS的实时映射性能。

Abstract: We introduce RGS-SLAM, a robust Gaussian-splatting SLAM framework that replaces the residual-driven densification stage of GS-SLAM with a training-free correspondence-to-Gaussian initialization. Instead of progressively adding Gaussians as residuals reveal missing geometry, RGS-SLAM performs a one-shot triangulation of dense multi-view correspondences derived from DINOv3 descriptors refined through a confidence-aware inlier classifier, generating a well-distributed and structure-aware Gaussian seed prior to optimization. This initialization stabilizes early mapping and accelerates convergence by roughly 20\%, yielding higher rendering fidelity in texture-rich and cluttered scenes while remaining fully compatible with existing GS-SLAM pipelines. Evaluated on the TUM RGB-D and Replica datasets, RGS-SLAM achieves competitive or superior localization and reconstruction accuracy compared with state-of-the-art Gaussian and point-based SLAM systems, sustaining real-time mapping performance at up to 925 FPS.

</details>


### [24] [FaithSCAN: Model-Driven Single-Pass Hallucination Detection for Faithful Visual Question Answering](https://arxiv.org/abs/2601.00269)
*Chaodong Tong,Qi Zhang,Chen Li,Lei Jiang,Yanbing Liu*

Main category: cs.CV

TL;DR: FaithSCAN利用VLM内部信号检测幻觉，无需昂贵人工标注，效果和效率优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有幻觉检测方法在效率、鲁棒性和检测性能上存在固有局限，无法充分探索与多样化失败模式相关的丰富内部信号。

Method: 提出FaithSCAN，一个轻量级网络，通过融合令牌级解码不确定性、中间视觉表示和跨模态对齐特征等内部信号，结合分支证据编码和不确定性感知注意力机制。

Result: 在多个VQA基准测试中，FaithSCAN在效果和效率上显著优于现有方法。

Conclusion: FaithSCAN通过利用视觉语言模型（VLM）的内部信号，显著提升了幻觉检测的效果和效率，并为多模态幻觉的成因提供了新见解。

Abstract: Faithfulness hallucinations in VQA occur when vision-language models produce fluent yet visually ungrounded answers, severely undermining their reliability in safety-critical applications. Existing detection methods mainly fall into two categories: external verification approaches relying on auxiliary models or knowledge bases, and uncertainty-driven approaches using repeated sampling or uncertainty estimates. The former suffer from high computational overhead and are limited by external resource quality, while the latter capture only limited facets of model uncertainty and fail to sufficiently explore the rich internal signals associated with the diverse failure modes. Both paradigms thus have inherent limitations in efficiency, robustness, and detection performance. To address these challenges, we propose FaithSCAN: a lightweight network that detects hallucinations by exploiting rich internal signals of VLMs, including token-level decoding uncertainty, intermediate visual representations, and cross-modal alignment features. These signals are fused via branch-wise evidence encoding and uncertainty-aware attention. We also extend the LLM-as-a-Judge paradigm to VQA hallucination and propose a low-cost strategy to automatically generate model-dependent supervision signals, enabling supervised training without costly human labels while maintaining high detection accuracy. Experiments on multiple VQA benchmarks show that FaithSCAN significantly outperforms existing methods in both effectiveness and efficiency. In-depth analysis shows hallucinations arise from systematic internal state variations in visual perception, cross-modal reasoning, and language decoding. Different internal signals provide complementary diagnostic cues, and hallucination patterns vary across VLM architectures, offering new insights into the underlying causes of multimodal hallucinations.

</details>


### [25] [Disentangling Hardness from Noise: An Uncertainty-Driven Model-Agnostic Framework for Long-Tailed Remote Sensing Classification](https://arxiv.org/abs/2601.00278)
*Chi Ding,Junxiao Xue,Xinyi Yin,Shi Chen,Yunyun Shi,Yiduo Wang,Fengjian Xue,Xuecheng Wu*

Main category: cs.CV

TL;DR: DUAL框架通过解耦不确定性动态处理长尾数据，区分困难样本与噪声，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决遥感数据中普遍存在的长尾分布问题，特别是区分困难样本与噪声模糊样本的挑战，避免传统方法对所有低置信度样本的过度拟合。

Method: 基于Evidential Deep Learning，提出了一个模型无关的不确定性感知框架DUAL，通过认知不确定性指导重加权策略处理困难样本，利用偶然不确定性实施自适应标签平滑抑制噪声影响。

Result: 在多个数据集和骨干网络上的实验表明，DUAL框架在性能上超越了TGN和SADE等强基线，消融研究进一步验证了设计的关键选择。

Conclusion: DUAL框架通过动态解耦预测不确定性为认知不确定性和偶然不确定性，有效区分了长尾分布中的困难样本与噪声样本，显著提升了模型性能。

Abstract: Long-Tailed distributions are pervasive in remote sensing due to the inherently imbalanced occurrence of grounded objects. However, a critical challenge remains largely overlooked, i.e., disentangling hard tail data samples from noisy ambiguous ones. Conventional methods often indiscriminately emphasize all low-confidence samples, leading to overfitting on noisy data. To bridge this gap, building upon Evidential Deep Learning, we propose a model-agnostic uncertainty-aware framework termed DUAL, which dynamically disentangles prediction uncertainty into Epistemic Uncertainty (EU) and Aleatoric Uncertainty (AU). Specifically, we introduce EU as an indicator of sample scarcity to guide a reweighting strategy for hard-to-learn tail samples, while leveraging AU to quantify data ambiguity, employing an adaptive label smoothing mechanism to suppress the impact of noise. Extensive experiments on multiple datasets across various backbones demonstrate the effectiveness and generalization of our framework, surpassing strong baselines such as TGN and SADE. Ablation studies provide further insights into the crucial choices of our design.

</details>


### [26] [SV-GS: Sparse View 4D Reconstruction with Skeleton-Driven Gaussian Splatting](https://arxiv.org/abs/2601.00285)
*Jun-Jee Chao,Volkan Isler*

Main category: cs.CV

TL;DR: SV-GS通过骨架驱动变形场在稀疏观测下实现动态重建，性能优于现有方法，且输入要求可放宽。


<details>
  <summary>Details</summary>
Motivation: 解决在稀疏观测条件下（如安全摄像头）动态目标重建的挑战，克服传统方法对密集覆盖的依赖。

Method: 利用粗略骨架图和初始静态重建作为输入，优化骨架驱动的变形场，包括粗粒度骨架关节姿态估计器和细粒度变形模块。

Result: 在合成数据集上PSNR提升34%，在真实数据集上性能接近密集单目视频方法，且使用更少帧数。

Conclusion: SV-GS框架通过结合粗略骨架图和初始静态重建，成功在稀疏观测条件下实现了动态目标的运动估计和变形模型重建，且在合成和真实数据集上均表现出色。

Abstract: Reconstructing a dynamic target moving over a large area is challenging. Standard approaches for dynamic object reconstruction require dense coverage in both the viewing space and the temporal dimension, typically relying on multi-view videos captured at each time step. However, such setups are only possible in constrained environments. In real-world scenarios, observations are often sparse over time and captured sparsely from diverse viewpoints (e.g., from security cameras), making dynamic reconstruction highly ill-posed. We present SV-GS, a framework that simultaneously estimates a deformation model and the object's motion over time under sparse observations. To initialize SV-GS, we leverage a rough skeleton graph and an initial static reconstruction as inputs to guide motion estimation. (Later, we show that this input requirement can be relaxed.) Our method optimizes a skeleton-driven deformation field composed of a coarse skeleton joint pose estimator and a module for fine-grained deformations. By making only the joint pose estimator time-dependent, our model enables smooth motion interpolation while preserving learned geometric details. Experiments on synthetic datasets show that our method outperforms existing approaches under sparse observations by up to 34% in PSNR, and achieves comparable performance to dense monocular video methods on real-world datasets despite using significantly fewer frames. Moreover, we demonstrate that the input initial static reconstruction can be replaced by a diffusion-based generative prior, making our method more practical for real-world scenarios.

</details>


### [27] [Towards Automated Differential Diagnosis of Skin Diseases Using Deep Learning and Imbalance-Aware Strategies](https://arxiv.org/abs/2601.00286)
*Ali Anaissi,Ali Braytee,Weidong Huang,Junaid Akram,Alaa Farhat,Jie Hua*

Main category: cs.CV

TL;DR: 开发了一个基于深度学习的皮肤疾病分类诊断模型，采用Swin Transformer架构，在ISIC2019数据集上达到87.71%的准确率，有望用于临床支持和患者自评。


<details>
  <summary>Details</summary>
Motivation: 随着皮肤病日益普遍且皮肤科医生资源有限，亟需智能工具支持患者和临床医生及时准确地诊断皮肤疾病。

Method: 通过利用公开可用的皮肤疾病图像数据集进行预训练，模型有效提取了视觉特征并准确分类了各种皮肤病案例。项目过程中，优化了模型架构、数据预处理流程，并应用了有针对性的数据增强技术以提高性能。

Result: 最终模型在ISIC2019数据集上对八种皮肤病变类别的预测准确率达到87.71%。

Conclusion: 该模型基于Swin Transformer，在ISIC2019数据集上对八种皮肤病变类别的预测准确率达到87.71%，展示了其作为临床诊断支持工具和患者自我评估辅助工具的潜力。

Abstract: As dermatological conditions become increasingly common and the availability of dermatologists remains limited, there is a growing need for intelligent tools to support both patients and clinicians in the timely and accurate diagnosis of skin diseases. In this project, we developed a deep learning based model for the classification and diagnosis of skin conditions. By leveraging pretraining on publicly available skin disease image datasets, our model effectively extracted visual features and accurately classified various dermatological cases. Throughout the project, we refined the model architecture, optimized data preprocessing workflows, and applied targeted data augmentation techniques to improve overall performance. The final model, based on the Swin Transformer, achieved a prediction accuracy of 87.71 percent across eight skin lesion classes on the ISIC2019 dataset. These results demonstrate the model's potential as a diagnostic support tool for clinicians and a self assessment aid for patients.

</details>


### [28] [TimeColor: Flexible Reference Colorization via Temporal Concatenation](https://arxiv.org/abs/2601.00296)
*Bryan Constantine Sadihin,Yihao Meng,Michael Hua Wang,Matteo Jiahao Chen,Hang Su*

Main category: cs.CV

TL;DR: TimeColor是一种支持异构多参考帧的视频上色模型，通过时空对应掩码注意力等技术，显著提升了上色效果。


<details>
  <summary>Details</summary>
Motivation: 现有的上色模型通常仅依赖于场景的第一帧作为参考，忽略了其他潜在的参考数据源（如角色表、背景图像或任意彩色帧）。TimeColor旨在利用这些异构参考数据提升上色效果。

Method: TimeColor采用基于草图的视频上色模型，支持异构、可变数量的参考帧，并使用显式的每参考区域分配。模型将参考帧编码为额外的潜在帧，并在时间上连接，以便在每个扩散步骤中并行处理，同时保持模型参数不变。此外，TimeColor还使用了时空对应掩码注意力和模态分离的RoPE索引。

Result: 在SAKUGA-42M数据集上的实验表明，TimeColor在单参考和多参考协议下均优于现有基线，提升了色彩保真度、身份一致性和时间稳定性。

Conclusion: TimeColor通过异构多参考帧和时空对应掩码注意力机制，显著提升了视频上色的色彩保真度、身份一致性和时间稳定性。

Abstract: Most colorization models condition only on a single reference, typically the first frame of the scene. However, this approach ignores other sources of conditional data, such as character sheets, background images, or arbitrary colorized frames. We propose TimeColor, a sketch-based video colorization model that supports heterogeneous, variable-count references with the use of explicit per-reference region assignment. TimeColor encodes references as additional latent frames which are concatenated temporally, permitting them to be processed concurrently in each diffusion step while keeping the model's parameter count fixed. TimeColor also uses spatiotemporal correspondence-masked attention to enforce subject-reference binding in addition to modality-disjoint RoPE indexing. These mechanisms mitigate shortcutting and cross-identity palette leakage. Experiments on SAKUGA-42M under both single- and multi-reference protocols show that TimeColor improves color fidelity, identity consistency, and temporal stability over prior baselines.

</details>


### [29] [VisNet: Efficient Person Re-Identification via Alpha-Divergence Loss, Feature Fusion and Dynamic Multi-Task Learning](https://arxiv.org/abs/2601.00307)
*Anns Ijaz,Muhammad Azeem Javed*

Main category: cs.CV

TL;DR: VisNet是一种高效的行人重识别模型，通过多尺度融合和语义聚类等技术，在保持高精度的同时降低计算成本，适合实时部署。


<details>
  <summary>Details</summary>
Motivation: 当前行人重识别方法虽精度高但计算成本大，难以在计算资源有限的现实场景中部署。VisNet旨在平衡精度与计算效率。

Method: VisNet通过多尺度特征融合、自动注意力机制、语义聚类与解剖学身体分区、动态权重平均技术以及改进的度量学习损失函数FIDI，实现了高效的特征提取与识别。

Result: VisNet在Market-1501数据集上取得了87.05% Rank-1和77.65% mAP的精度，模型参数为32.41M，计算量为4.601 GFLOPs。

Conclusion: VisNet提出了一种计算高效且有效的行人重识别模型，适用于现实场景，尤其在计算资源有限的情况下具有实际应用价值。

Abstract: Person re-identification (ReID) is an extremely important area in both surveillance and mobile applications, requiring strong accuracy with minimal computational cost. State-of-the-art methods give good accuracy but with high computational budgets. To remedy this, this paper proposes VisNet, a computationally efficient and effective re-identification model suitable for real-world scenarios. It is the culmination of conceptual contributions, including feature fusion at multiple scales with automatic attention on each, semantic clustering with anatomical body partitioning, a dynamic weight averaging technique to balance classification semantic regularization, and the use of loss function FIDI for improved metric learning tasks. The multiple scales fuse ResNet50's stages 1 through 4 without the use of parallel paths, with semantic clustering introducing spatial constraints through the use of rule-based pseudo-labeling. VisNet achieves 87.05% Rank-1 and 77.65% mAP on the Market-1501 dataset, having 32.41M parameters and 4.601 GFLOPs, hence, proposing a practical approach for real-time deployment in surveillance and mobile applications where computational resources are limited.

</details>


### [30] [ReMA: A Training-Free Plug-and-Play Mixing Augmentation for Video Behavior Recognition](https://arxiv.org/abs/2601.00311)
*Feng-Qi Cui,Jinyang Huang,Sirui Zhao,Jinglong Guo,Qifan Cai,Xin Yan,Zhi Liu*

Main category: cs.CV

TL;DR: ReMA是一种视频数据增强策略，通过受控的混合过程提升表示稳定性，无需额外监督或可训练参数。


<details>
  <summary>Details</summary>
Motivation: 现有的视频数据增强策略多为扰动驱动，常引入不可控的变异，放大非判别性因素，削弱类内分布结构并导致表示漂移。ReMA旨在通过受控的替换过程扩展表示，同时保持类条件稳定性。

Method: ReMA整合了两种互补机制：表示对齐机制（RAM）和动态选择机制（DSM）。RAM在分布对齐约束下进行结构化类内混合，抑制无关的类内漂移；DSM生成运动感知的时空掩码，定位扰动并引导其远离敏感区域。

Result: 在多样化的视频行为基准测试中，ReMA在不同时空粒度上一致提升了泛化性和鲁棒性。

Conclusion: ReMA作为一种即插即用的增强策略，通过联合控制混合的方式和位置，显著提升了视频行为识别的泛化性和鲁棒性。

Abstract: Video behavior recognition demands stable and discriminative representations under complex spatiotemporal variations. However, prevailing data augmentation strategies for videos remain largely perturbation-driven, often introducing uncontrolled variations that amplify non-discriminative factors, which finally weaken intra-class distributional structure and representation drift with inconsistent gains across temporal scales. To address these problems, we propose Representation-aware Mixing Augmentation (ReMA), a plug-and-play augmentation strategy that formulates mixing as a controlled replacement process to expand representations while preserving class-conditional stability. ReMA integrates two complementary mechanisms. Firstly, the Representation Alignment Mechanism (RAM) performs structured intra-class mixing under distributional alignment constraints, suppressing irrelevant intra-class drift while enhancing statistical reliability. Then, the Dynamic Selection Mechanism (DSM) generates motion-aware spatiotemporal masks to localize perturbations, guiding them away from discrimination-sensitive regions and promoting temporal coherence. By jointly controlling how and where mixing is applied, ReMA improves representation robustness without additional supervision or trainable parameters. Extensive experiments on diverse video behavior benchmarks demonstrate that ReMA consistently enhances generalization and robustness across different spatiotemporal granularities.

</details>


### [31] [Depth-Synergized Mamba Meets Memory Experts for All-Day Image Reflection Separation](https://arxiv.org/abs/2601.00322)
*Siyan Fang,Long Peng,Yuntao Wang,Ruonan Wei,Yuehuan Wang*

Main category: cs.CV

TL;DR: DMDNet利用深度感知和记忆补偿，提升图像反射分离性能，尤其在夜晚场景。


<details>
  <summary>Details</summary>
Motivation: 现有方法在反射层和传输层对比度相似时（尤其是夜晚）效果不佳，需解决这一挑战。

Method: 提出Depth-Memory Decoupling Network (DMDNet)，包含Depth-Aware Scanning (DAScan)、Depth-Synergized State-Space Model (DS-SSM)和Memory Expert Compensation Module (MECM)。

Result: DMDNet在白天和夜晚均优于现有方法，并构建了Nighttime Image Reflection Separation (NightIRS)数据集。

Conclusion: DMDNet通过深度感知扫描和深度协同状态空间模型，结合记忆专家补偿模块，显著提升了白天和夜晚图像反射分离的性能。

Abstract: Image reflection separation aims to disentangle the transmission layer and the reflection layer from a blended image. Existing methods rely on limited information from a single image, tending to confuse the two layers when their contrasts are similar, a challenge more severe at night. To address this issue, we propose the Depth-Memory Decoupling Network (DMDNet). It employs the Depth-Aware Scanning (DAScan) to guide Mamba toward salient structures, promoting information flow along semantic coherence to construct stable states. Working in synergy with DAScan, the Depth-Synergized State-Space Model (DS-SSM) modulates the sensitivity of state activations by depth, suppressing the spread of ambiguous features that interfere with layer disentanglement. Furthermore, we introduce the Memory Expert Compensation Module (MECM), leveraging cross-image historical knowledge to guide experts in providing layer-specific compensation. To address the lack of datasets for nighttime reflection separation, we construct the Nighttime Image Reflection Separation (NightIRS) dataset. Extensive experiments demonstrate that DMDNet outperforms state-of-the-art methods in both daytime and nighttime.

</details>


### [32] [HarmoniAD: Harmonizing Local Structures and Global Semantics for Anomaly Detection](https://arxiv.org/abs/2601.00327)
*Naiqi Zhang,Chuancheng Shi,Jingtong Dou,Wenhua Wu,Fei Shen,Jianhua Cao*

Main category: cs.CV

TL;DR: HarmoniAD：频率引导的双分支框架，通过高频（FSAM）和低频（GSCM）分支互补建模结构与语义，实现微小缺陷检测的SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在结构-语义权衡中存在局限：结构导向模型对噪声敏感，语义导向模型忽略细节。需平衡微小异常检测与语义一致性。

Method: 提出HarmoniAD框架，利用CLIP图像编码器提取特征后转换至频率域，并解耦为高频（结构）和低频（语义）分支。高频分支采用FSAM增强纹理细节，低频分支采用GSCM捕获长程依赖。结合多类联合训练策略。

Result: 在MVTec-AD、VisA和BTAD数据集上实现最优性能，兼具高灵敏度和鲁棒性。

Conclusion: HarmoniAD通过双分支框架在频率域中解耦结构（高频）和语义（低频）信息，结合FSAM和GSCM模块，实现了对微小异常的高灵敏度检测和全局语义一致性，在多个数据集上达到最优性能。

Abstract: Anomaly detection is crucial in industrial product quality inspection. Failing to detect tiny defects often leads to serious consequences. Existing methods face a structure-semantics trade-off: structure-oriented models (such as frequency-based filters) are noise-sensitive, while semantics-oriented models (such as CLIP-based encoders) often miss fine details. To address this, we propose HarmoniAD, a frequency-guided dual-branch framework. Features are first extracted by the CLIP image encoder, then transformed into the frequency domain, and finally decoupled into high- and low-frequency paths for complementary modeling of structure and semantics. The high-frequency branch is equipped with a fine-grained structural attention module (FSAM) to enhance textures and edges for detecting small anomalies, while the low-frequency branch uses a global structural context module (GSCM) to capture long-range dependencies and preserve semantic consistency. Together, these branches balance fine detail and global semantics. HarmoniAD further adopts a multi-class joint training strategy, and experiments on MVTec-AD, VisA, and BTAD show state-of-the-art performance with both sensitivity and robustness.

</details>


### [33] [Joint Geometry-Appearance Human Reconstruction in a Unified Latent Space via Bridge Diffusion](https://arxiv.org/abs/2601.00328)
*Yingzhi Tang,Qijian Zhang,Junhui Hou*

Main category: cs.CV

TL;DR: JGA-LBD通过统一潜在表示和桥接扩散，从单张RGB图像重建高质量3D数字人，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常解耦几何估计和外观合成，导致重建不一致。本文旨在统一建模几何和外观，提升重建质量和一致性。

Method: 提出JGA-LBD框架，将几何和外观建模统一为联合潜在表示，并通过桥接扩散生成。采用3D高斯表示统一输入条件，并通过共享稀疏变分自编码器压缩到潜在空间。

Result: 实验表明，JGA-LBD在几何保真度和外观质量上优于现有方法，包括野外场景。

Conclusion: JGA-LBD框架通过统一的潜在表示和桥接扩散方法，显著提升了单张RGB图像重建3D数字人的几何和外观质量，优于现有方法。

Abstract: Achieving consistent and high-fidelity geometry and appearance reconstruction of 3D digital humans from a single RGB image is inherently a challenging task. Existing studies typically resort to decoupled pipelines for geometry estimation and appearance synthesis, often hindering unified reconstruction and causing inconsistencies. This paper introduces \textbf{JGA-LBD}, a novel framework that unifies the modeling of geometry and appearance into a joint latent representation and formulates the generation process as bridge diffusion. Observing that directly integrating heterogeneous input conditions (e.g., depth maps, SMPL models) leads to substantial training difficulties, we unify all conditions into the 3D Gaussian representations, which can be further compressed into a unified latent space through a shared sparse variational autoencoder (VAE). Subsequently, the specialized form of bridge diffusion enables to start with a partial observation of the target latent code and solely focuses on inferring the missing components. Finally, a dedicated decoding module extracts the complete 3D human geometric structure and renders novel views from the inferred latent representation. Experiments demonstrate that JGA-LBD outperforms current state-of-the-art approaches in terms of both geometry fidelity and appearance quality, including challenging in-the-wild scenarios. Our code will be made publicly available at https://github.com/haiantyz/JGA-LBD.

</details>


### [34] [Intelligent Traffic Surveillance for Real-Time Vehicle Detection, License Plate Recognition, and Speed Estimation](https://arxiv.org/abs/2601.00344)
*Bruce Mugizi,Sudi Murindanyi,Olivia Nakacwa,Andrew Katumba*

Main category: cs.CV

TL;DR: 研究提出了一种适用于资源受限地区的实时智能交通监控系统，通过计算机视觉技术实现车牌识别和测速，并自动发送罚单，有望减少交通事故。


<details>
  <summary>Details</summary>
Motivation: 超速是导致道路死亡的主要原因，尤其在乌干达等发展中国家，道路安全基础设施有限。

Method: 使用计算机视觉技术，包括YOLOv8进行车牌检测，CNN和Transformer模型进行字符识别，以及基于感兴趣区域的测速方法。

Result: 车牌检测的mAP达到97.9%，字符识别的CER分别为CNN模型3.85%和Transformer模型1.79%，测速误差为10公里/小时。

Conclusion: 该系统为资源受限环境下的交通管理提供了有效的自动化解决方案，展示了通过自动化交通执法减少交通事故的潜力。

Abstract: Speeding is a major contributor to road fatalities, particularly in developing countries such as Uganda, where road safety infrastructure is limited. This study proposes a real-time intelligent traffic surveillance system tailored to such regions, using computer vision techniques to address vehicle detection, license plate recognition, and speed estimation. The study collected a rich dataset using a speed gun, a Canon Camera, and a mobile phone to train the models. License plate detection using YOLOv8 achieved a mean average precision (mAP) of 97.9%. For character recognition of the detected license plate, the CNN model got a character error rate (CER) of 3.85%, while the transformer model significantly reduced the CER to 1.79%. Speed estimation used source and target regions of interest, yielding a good performance of 10 km/h margin of error. Additionally, a database was established to correlate user information with vehicle detection data, enabling automated ticket issuance via SMS via Africa's Talking API. This system addresses critical traffic management needs in resource-constrained environments and shows potential to reduce road accidents through automated traffic enforcement in developing countries where such interventions are urgently needed.

</details>


### [35] [OmniVaT: Single Domain Generalization for Multimodal Visual-Tactile Learning](https://arxiv.org/abs/2601.00352)
*Liuxiang Qiu,Hui Da,Yuzhen Niu,Tiesong Zhao,Yang Cao,Zheng-Jun Zha*

Main category: cs.CV

TL;DR: OmniVaT通过MFFA和DTG模块解决了视觉-触觉学习的模态差异和领域泛化问题，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 视觉-触觉学习（VTL）存在模态差异和领域泛化问题，需要一种无需多领域训练数据或复杂跨模态融合策略的解决方案。

Method: OmniVaT框架整合了多模态分数傅里叶适配器（MFFA）和离散树生成（DTG）模块，分别用于统一视觉-触觉嵌入空间和增强对未知领域波动的适应性。

Result: 实验表明，OmniVaT在SDG-VTL任务上表现出卓越的跨领域泛化性能。

Conclusion: OmniVaT框架通过MFFA和DTG模块成功解决了SDG-VTL任务中的模态差异和领域泛化问题，展现出卓越的跨领域泛化性能。

Abstract: Visual-tactile learning (VTL) enables embodied agents to perceive the physical world by integrating visual (VIS) and tactile (TAC) sensors. However, VTL still suffers from modality discrepancies between VIS and TAC images, as well as domain gaps caused by non-standardized tactile sensors and inconsistent data collection procedures. We formulate these challenges as a new task, termed single domain generalization for multimodal VTL (SDG-VTL). In this paper, we propose an OmniVaT framework that, for the first time, successfully addresses this task. On the one hand, OmniVaT integrates a multimodal fractional Fourier adapter (MFFA) to map VIS and TAC embeddings into a unified embedding-frequency space, thereby effectively mitigating the modality gap without multi-domain training data or careful cross-modal fusion strategies. On the other hand, it also incorporates a discrete tree generation (DTG) module that obtains diverse and reliable multimodal fractional representations through a hierarchical tree structure, thereby enhancing its adaptivity to fluctuating domain shifts in unseen domains. Extensive experiments demonstrate the superior cross-domain generalization performance of OmniVaT on the SDG-VTL task.

</details>


### [36] [Mask-Conditioned Voxel Diffusion for Joint Geometry and Color Inpainting](https://arxiv.org/abs/2601.00368)
*Aarya Sumuk*

Main category: cs.CV

TL;DR: 两阶段框架：先定位损坏，再修复3D几何和颜色，效果优于基线。


<details>
  <summary>Details</summary>
Motivation: 数字修复文化遗产文物。

Method: 提出了一种轻量级的两阶段框架，第一阶段使用2D卷积网络预测RGB切片的损坏掩码，第二阶段使用扩散基3D U-Net直接在体素网格上进行掩码条件修复。

Result: 在固定32^3分辨率下，相比基于对称性的基线方法，该方法产生更完整的几何和更连贯的颜色重建。

Conclusion: 显式掩码条件是指导体积扩散模型进行联合3D几何和颜色修复的实用方法。

Abstract: We present a lightweight two-stage framework for joint geometry and color inpainting of damaged 3D objects, motivated by the digital restoration of cultural heritage artifacts. The pipeline separates damage localization from reconstruction. In the first stage, a 2D convolutional network predicts damage masks on RGB slices extracted from a voxelized object, and these predictions are aggregated into a volumetric mask. In the second stage, a diffusion-based 3D U-Net performs mask-conditioned inpainting directly on voxel grids, reconstructing geometry and color while preserving observed regions. The model jointly predicts occupancy and color using a composite objective that combines occupancy reconstruction with masked color reconstruction and perceptual regularization. We evaluate the approach on a curated set of textured artifacts with synthetically generated damage using standard geometric and color metrics. Compared to symmetry-based baselines, our method produces more complete geometry and more coherent color reconstructions at a fixed 32^3 resolution. Overall, the results indicate that explicit mask conditioning is a practical way to guide volumetric diffusion models for joint 3D geometry and color inpainting.

</details>


### [37] [BHaRNet: Reliability-Aware Body-Hand Modality Expertized Networks for Fine-grained Skeleton Action Recognition](https://arxiv.org/abs/2601.00369)
*Seungyeon Cho,Tae-kyun Kim*

Main category: cs.CV

TL;DR: 该论文提出了一种概率双流框架，专注于骨架和RGB模态的集成，显著提升了细粒度动作识别的性能，尤其在噪声和异构条件下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注大尺度动作，忽略了对手部细微动作的识别，而这对于细粒度识别至关重要。

Method: 框架包含三个关键组件：1）无校准预处理管道，直接从原生坐标学习；2）概率性Noisy-OR融合，稳定可靠性感知的双流学习；3）从骨架模态到RGB表示的跨模态集成。

Result: 在多个基准测试（NTU RGB+D~60/120, PKU-MMD, N-UCLA）和新定义的手部中心基准测试中表现一致改进和鲁棒性。

Conclusion: 该论文提出的概率双流框架在骨架基础的人体动作识别中表现出色，特别是在处理噪声和异构条件时展现了鲁棒性，并在多个基准测试中取得了显著改进。

Abstract: Skeleton-based human action recognition (HAR) has achieved remarkable progress with graph-based architectures. However, most existing methods remain body-centric, focusing on large-scale motions while neglecting subtle hand articulations that are crucial for fine-grained recognition. This work presents a probabilistic dual-stream framework that unifies reliability modeling and multi-modal integration, generalizing expertized learning under uncertainty across both intra-skeleton and cross-modal domains. The framework comprises three key components: (1) a calibration-free preprocessing pipeline that removes canonical-space transformations and learns directly from native coordinates; (2) a probabilistic Noisy-OR fusion that stabilizes reliability-aware dual-stream learning without requiring explicit confidence supervision; and (3) an intra- to cross-modal ensemble that couples four skeleton modalities (Joint, Bone, Joint Motion, and Bone Motion) to RGB representations, bridging structural and visual motion cues in a unified cross-modal formulation. Comprehensive evaluations across multiple benchmarks (NTU RGB+D~60/120, PKU-MMD, N-UCLA) and a newly defined hand-centric benchmark exhibit consistent improvements and robustness under noisy and heterogeneous conditions.

</details>


### [38] [NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos](https://arxiv.org/abs/2601.00393)
*Yuxue Yang,Lue Fan,Ziqi Shi,Junran Peng,Feng Wang,Zhaoxiang Zhang*

Main category: cs.CV

TL;DR: NeoVerse是一种创新的4D世界模型，通过优化设计解决了现有方法的可扩展性问题，并在多个任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 当前4D世界建模方法存在可扩展性不足的问题，主要由于依赖昂贵的多视图4D数据或繁琐的训练预处理。NeoVerse旨在解决这些问题，提供更通用的解决方案。

Method: NeoVerse采用无姿态前馈4D重建、在线单目退化模式模拟等技术，实现了对多样化单目视频的高效处理。

Result: NeoVerse在标准重建和生成基准测试中取得了最先进的性能表现。

Conclusion: NeoVerse作为一种多功能4D世界模型，通过创新的设计和优化，显著提升了4D重建和视频生成的性能，并在多个基准测试中达到最先进水平。

Abstract: In this paper, we propose NeoVerse, a versatile 4D world model that is capable of 4D reconstruction, novel-trajectory video generation, and rich downstream applications. We first identify a common limitation of scalability in current 4D world modeling methods, caused either by expensive and specialized multi-view 4D data or by cumbersome training pre-processing. In contrast, our NeoVerse is built upon a core philosophy that makes the full pipeline scalable to diverse in-the-wild monocular videos. Specifically, NeoVerse features pose-free feed-forward 4D reconstruction, online monocular degradation pattern simulation, and other well-aligned techniques. These designs empower NeoVerse with versatility and generalization to various domains. Meanwhile, NeoVerse achieves state-of-the-art performance in standard reconstruction and generation benchmarks. Our project page is available at https://neoverse-4d.github.io

</details>


### [39] [A Comprehensive Dataset for Human vs. AI Generated Image Detection](https://arxiv.org/abs/2601.00553)
*Rajarshi Roy,Nasrin Imanpour,Ashhar Aziz,Shashwat Bajpai,Gurpreet Singh,Shwetangshu Biswas,Kapil Wanaskar,Parth Patwa,Subhankar Ghosh,Shreyas Dixit,Nilesh Ranjan Pal,Vipula Rawte,Ritvik Garimella,Gaytri Jena,Vasu Sharma,Vinija Jain,Aman Chadha,Aishwarya Naresh Reganti,Amitava Das*

Main category: cs.CV

TL;DR: MS COCOAI数据集助力检测AI生成图像，包含96000个数据点，支持真实性分类和模型识别任务。


<details>
  <summary>Details</summary>
Motivation: 多模态生成AI系统（如Stable Diffusion）的普及导致合成图像难以辨别，亟需检测手段以应对误导性内容传播。

Method: 利用MS COCO数据集构建了包含96000个真实与合成数据点的数据集，使用五种生成器（Stable Diffusion 3、2.1、SDXL、DALL-E 3、MidJourney v6）生成合成图像。

Result: 发布了MS COCOAI数据集，并定义了两项任务：图像真实性分类和生成模型识别。

Conclusion: MS COCOAI数据集为AI生成图像检测提供了重要资源，支持两项关键任务：区分真实与生成图像及识别生成模型。

Abstract: Multimodal generative AI systems like Stable Diffusion, DALL-E, and MidJourney have fundamentally changed how synthetic images are created. These tools drive innovation but also enable the spread of misleading content, false information, and manipulated media. As generated images become harder to distinguish from photographs, detecting them has become an urgent priority. To combat this challenge, We release MS COCOAI, a novel dataset for AI generated image detection consisting of 96000 real and synthetic datapoints, built using the MS COCO dataset. To generate synthetic images, we use five generators: Stable Diffusion 3, Stable Diffusion 2.1, SDXL, DALL-E 3, and MidJourney v6. Based on the dataset, we propose two tasks: (1) classifying images as real or generated, and (2) identifying which model produced a given synthetic image. The dataset is available at https://huggingface.co/datasets/Rajarshi-Roy-research/Defactify_Image_Dataset.

</details>


### [40] [RoLID-11K: A Dashcam Dataset for Small-Object Roadside Litter Detection](https://arxiv.org/abs/2601.00398)
*Tao Wu,Qing Xu,Xiangjian He,Oakleigh Weekes,James Brown,Wenting Duan*

Main category: cs.CV

TL;DR: RoLID-11K是首个基于 dashcam 的大规模路边垃圾检测数据集，包含11k+标注图像，测试了多种检测器，transformer表现最佳，但实时模型受限。数据集支持低成本监测系统开发。


<details>
  <summary>Details</summary>
Motivation: 路边垃圾带来环境、安全和经济的挑战，但当前监测依赖劳动密集型调查和公众报告，空间覆盖有限。现有视觉数据集未反映 dashcam 视频中垃圾的独特特征（极小、稀疏且嵌入杂乱背景）。

Method: 引入了RoLID-11K数据集，包含超过11k标注图像，涵盖多样化的英国驾驶条件，并呈现显著的长尾和小目标分布。对多种现代检测器进行了基准测试，包括精度导向的transformer架构和实时YOLO模型。

Result: 结果表明，CO-DETR及相关transformer架构在定位精度上表现最佳，但实时模型仍受限于粗糙的特征层次结构。

Conclusion: RoLID-11K数据集为动态驾驶场景中的极端小目标检测设立了具有挑战性的基准，旨在支持开发可扩展、低成本的 roadside-litter 监测系统。

Abstract: Roadside litter poses environmental, safety and economic challenges, yet current monitoring relies on labour-intensive surveys and public reporting, providing limited spatial coverage. Existing vision datasets for litter detection focus on street-level still images, aerial scenes or aquatic environments, and do not reflect the unique characteristics of dashcam footage, where litter appears extremely small, sparse and embedded in cluttered road-verge backgrounds. We introduce RoLID-11K, the first large-scale dataset for roadside litter detection from dashcams, comprising over 11k annotated images spanning diverse UK driving conditions and exhibiting pronounced long-tail and small-object distributions. We benchmark a broad spectrum of modern detectors, from accuracy-oriented transformer architectures to real-time YOLO models, and analyse their strengths and limitations on this challenging task. Our results show that while CO-DETR and related transformers achieve the best localisation accuracy, real-time models remain constrained by coarse feature hierarchies. RoLID-11K establishes a challenging benchmark for extreme small-object detection in dynamic driving scenes and aims to support the development of scalable, low-cost systems for roadside-litter monitoring. The dataset is available at https://github.com/xq141839/RoLID-11K.

</details>


### [41] [ABFR-KAN: Kolmogorov-Arnold Networks for Functional Brain Analysis](https://arxiv.org/abs/2601.00416)
*Tyler Ward,Abdullah Imran*

Main category: cs.CV

TL;DR: ABFR-KAN是一种结合Transformer和KANs的脑功能表示网络，显著提升ASD分类性能。


<details>
  <summary>Details</summary>
Motivation: 传统基于图谱的分割方法存在选择偏差和忽视个体特异性的问题，需要一种更可靠的功能性连接分析方法。

Method: 提出了一种基于Transformer的分类网络ABFR-KAN，结合了新颖的脑功能表示组件和KANs，以减少结构偏差并提升解剖一致性。

Result: 在ABIDE I数据集上的实验表明，ABFR-KAN在ASD分类任务中 consistently outperforms state-of-the-art baselines。

Conclusion: ABFR-KAN通过结合先进的脑功能表示组件和Kolmogorov-Arnold Networks（KANs），显著提升了功能性连接（FC）分析的可靠性和分类性能，尤其在自闭症谱系障碍（ASD）分类任务中表现优异。

Abstract: Functional connectivity (FC) analysis, a valuable tool for computer-aided brain disorder diagnosis, traditionally relies on atlas-based parcellation. However, issues relating to selection bias and a lack of regard for subject specificity can arise as a result of such parcellations. Addressing this, we propose ABFR-KAN, a transformer-based classification network that incorporates novel advanced brain function representation components with the power of Kolmogorov-Arnold Networks (KANs) to mitigate structural bias, improve anatomical conformity, and enhance the reliability of FC estimation. Extensive experiments on the ABIDE I dataset, including cross-site evaluation and ablation studies across varying model backbones and KAN configurations, demonstrate that ABFR-KAN consistently outperforms state-of-the-art baselines for autism spectrum distorder (ASD) classification. Our code is available at https://github.com/tbwa233/ABFR-KAN.

</details>


### [42] [Noise-Robust Tiny Object Localization with Flows](https://arxiv.org/abs/2601.00617)
*Huixin Sun,Linlin Yang,Ronyu Chen,Kerui Gu,Baochang Zhang,Angela Yao,Xianbin Cao*

Main category: cs.CV

TL;DR: TOLF 通过归一化流和不确定性引导优化，解决了小目标检测中的噪声敏感问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 小目标对标注噪声高度敏感，优化严格的定位目标容易导致噪声过拟合，需要一种鲁棒的方法来解决这一问题。

Method: 提出 Tiny Object Localization with Flows (TOLF)，利用归一化流进行复杂、非高斯预测分布的误差建模，并结合不确定性感知的梯度调制机制，抑制噪声样本的学习。

Result: 在三个数据集上的实验验证了 TOLF 的有效性，特别是在 AI-TOD 数据集上将 DINO 基线提升了 1.2% AP。

Conclusion: TOLF 是一种噪声鲁棒的小目标定位框架，通过归一化流进行灵活误差建模和不确定性引导优化，显著提升了小目标检测的性能。

Abstract: Despite significant advances in generic object detection, a persistent performance gap remains for tiny objects compared to normal-scale objects. We demonstrate that tiny objects are highly sensitive to annotation noise, where optimizing strict localization objectives risks noise overfitting. To address this, we propose Tiny Object Localization with Flows (TOLF), a noise-robust localization framework leveraging normalizing flows for flexible error modeling and uncertainty-guided optimization. Our method captures complex, non-Gaussian prediction distributions through flow-based error modeling, enabling robust learning under noisy supervision. An uncertainty-aware gradient modulation mechanism further suppresses learning from high-uncertainty, noise-prone samples, mitigating overfitting while stabilizing training. Extensive experiments across three datasets validate our approach's effectiveness. Especially, TOLF boosts the DINO baseline by 1.2% AP on the AI-TOD dataset.

</details>


### [43] [Robust Assembly Progress Estimation via Deep Metric Learning](https://arxiv.org/abs/2601.00422)
*Kazuma Miura,Sarthak Pathak,Kazunori Umeda*

Main category: cs.CV

TL;DR: 论文提出Anomaly Quadruplet-Net，通过Quadruplet Loss和自定义数据加载器提升组装进度估计准确性，尤其在视觉变化微小或遮挡情况下表现优异。


<details>
  <summary>Details</summary>
Motivation: 手动多日组装任务中，智能工厂系统的实现仍具挑战性，尤其是在视觉变化微小或存在遮挡时，现有方法易出现误分类。

Method: 采用基于Quadruplet Loss的学习方法处理异常图像，并引入自定义数据加载器策略性选择训练样本以提升估计准确性。

Result: 在桌面PC组装数据集上，Anomaly Quadruplet-Net将估计准确性提高了1.3%，并将相邻任务间的误分类减少了1.9%。

Conclusion: 该论文提出的Anomaly Quadruplet-Net在桌面PC组装数据集上表现优于现有方法，提高了估计准确性并减少了相邻任务间的误分类，验证了其有效性。

Abstract: In recent years, the advancement of AI technologies has accelerated the development of smart factories. In particular, the automatic monitoring of product assembly progress is crucial for improving operational efficiency, minimizing the cost of discarded parts, and maximizing factory productivity. However, in cases where assembly tasks are performed manually over multiple days, implementing smart factory systems remains a challenge. Previous work has proposed Anomaly Triplet-Net, which estimates assembly progress by applying deep metric learning to the visual features of products. Nevertheless, when visual changes between consecutive tasks are subtle, misclassification often occurs. To address this issue, this paper proposes a robust system for estimating assembly progress, even in cases of occlusion or minimal visual change, using a small-scale dataset. Our method leverages a Quadruplet Loss-based learning approach for anomaly images and introduces a custom data loader that strategically selects training samples to enhance estimation accuracy. We evaluated our approach using a image datasets: captured during desktop PC assembly. The proposed Anomaly Quadruplet-Net outperformed existing methods on the dataset. Specifically, it improved the estimation accuracy by 1.3% and reduced misclassification between adjacent tasks by 1.9% in the desktop PC dataset and demonstrating the effectiveness of the proposed method.

</details>


### [44] [Detecting Performance Degradation under Data Shift in Pathology Vision-Language Model](https://arxiv.org/abs/2601.00716)
*Hao Guan,Li Zhou*

Main category: cs.CV

TL;DR: 研究通过输入和输出层面的分析，提出结合数据偏移检测和置信度指标的框架，以更可靠地监控VLM在数据偏移下的性能退化。


<details>
  <summary>Details</summary>
Motivation: 检测预训练视觉语言模型（VLM）在数据偏移下的性能退化对临床可靠性至关重要，但缺乏标签数据时具有挑战性。

Method: 开发了DomainSAT工具箱，整合了代表性的偏移检测算法，并研究了基于输出的无标签置信度退化指标。

Result: 输入数据偏移检测能有效识别分布变化并提供早期诊断信号，但不总能对应实际性能退化；基于置信度的指标与性能退化密切相关，是输入偏移检测的有效补充。

Conclusion: 结合输入级数据偏移检测和基于输出置信度的指标，可以更可靠地检测和解释数据偏移下VLM的性能退化，为数字病理学中基础模型的可靠性监控提供了实用且互补的框架。

Abstract: Vision-Language Models have demonstrated strong potential in medical image analysis and disease diagnosis. However, after deployment, their performance may deteriorate when the input data distribution shifts from that observed during development. Detecting such performance degradation is essential for clinical reliability, yet remains challenging for large pre-trained VLMs operating without labeled data. In this study, we investigate performance degradation detection under data shift in a state-of-the-art pathology VLM. We examine both input-level data shift and output-level prediction behavior to understand their respective roles in monitoring model reliability. To facilitate systematic analysis of input data shift, we develop DomainSAT, a lightweight toolbox with a graphical interface that integrates representative shift detection algorithms and enables intuitive exploration of data shift. Our analysis shows that while input data shift detection is effective at identifying distributional changes and providing early diagnostic signals, it does not always correspond to actual performance degradation. Motivated by this observation, we further study output-based monitoring and introduce a label-free, confidence-based degradation indicator that directly captures changes in model prediction confidence. We find that this indicator exhibits a close relationship with performance degradation and serves as an effective complement to input shift detection. Experiments on a large-scale pathology dataset for tumor classification demonstrate that combining input data shift detection and output confidence-based indicators enables more reliable detection and interpretation of performance degradation in VLMs under data shift. These findings provide a practical and complementary framework for monitoring the reliability of foundation models in digital pathology.

</details>


### [45] [CPPO: Contrastive Perception for Vision Language Policy Optimization](https://arxiv.org/abs/2601.00501)
*Ahmad Rezaei,Mohsen Gholami,Saeed Ranjbar Alvar,Kevin Cannons,Mohammad Asiful Hossain,Zhou Weimin,Shunbo Zhou,Yong Zhang,Mohammad Akbari*

Main category: cs.CV

TL;DR: CPPO是一种新型对比感知策略优化方法，通过熵移和对比损失改进多模态模型的感知与推理解耦，无需额外资源，效果更优。


<details>
  <summary>Details</summary>
Motivation: 现有方法在解耦多模态推理中的感知与推理时依赖额外模型或数据，效率低且难以扩展。CPPO旨在通过更高效的方法改进这一过程。

Method: CPPO利用输入图像扰动下的模型输出熵移检测感知标记，并通过对比感知损失（CPL）增强信息保留扰动下的一致性和信息移除扰动下的敏感性。

Result: 实验表明，CPPO在无需额外模型的情况下，超越了以往的感知奖励方法，提升了训练效率和可扩展性。

Conclusion: CPPO通过引入对比感知损失（CPL）和基于熵移的感知标记检测，显著提升了多模态推理中感知与推理的解耦效果，无需额外模型或数据，提高了训练效率和可扩展性。

Abstract: We introduce CPPO, a Contrastive Perception Policy Optimization method for finetuning vision-language models (VLMs). While reinforcement learning (RL) has advanced reasoning in language models, extending it to multimodal reasoning requires improving both the perception and reasoning aspects. Prior works tackle this challenge mainly with explicit perception rewards, but disentangling perception tokens from reasoning tokens is difficult, requiring extra LLMs, ground-truth data, forced separation of perception from reasoning by policy model, or applying rewards indiscriminately to all output tokens. CPPO addresses this problem by detecting perception tokens via entropy shifts in the model outputs under perturbed input images. CPPO then extends the RL objective function with a Contrastive Perception Loss (CPL) that enforces consistency under information-preserving perturbations and sensitivity under information-removing ones. Experiments show that CPPO surpasses previous perception-rewarding methods, while avoiding extra models, making training more efficient and scalable.

</details>


### [46] [All-in-One Video Restoration under Smoothly Evolving Unknown Weather Degradations](https://arxiv.org/abs/2601.00533)
*Wenrui Li,Hongtao Chen,Yao Xiao,Wangmeng Zuo,Jiantao Zhou,Yonghong Tian,Xiaopeng Fan*

Main category: cs.CV

TL;DR: 本文提出ORCANet网络，针对视频中降解类型和强度随时间平滑变化的SEUD场景，通过CIED和FPG模块实现高质量、时间一致的视频恢复，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注帧间降解变化，忽视了真实世界中降解过程的时空连续性。本文提出SEUD场景，模拟降解类型和强度随时间平滑变化的情况。

Method: 提出ORCANet网络，包含CIED模块进行粗粒度去雾特征初始化，FPG模块生成静态和动态提示以捕捉降解特征，并通过标签感知监督机制提升静态提示的区分性。

Result: ORCANet在SEUD场景下表现出色，实验证明其在恢复质量、时间一致性和鲁棒性方面优于基线方法。

Conclusion: ORCANet在恢复质量、时间一致性和鲁棒性方面优于基于图像和视频的基线方法，代码已开源。

Abstract: All-in-one image restoration aims to recover clean images from diverse unknown degradations using a single model. But extending this task to videos faces unique challenges. Existing approaches primarily focus on frame-wise degradation variation, overlooking the temporal continuity that naturally exists in real-world degradation processes. In practice, degradation types and intensities evolve smoothly over time, and multiple degradations may coexist or transition gradually. In this paper, we introduce the Smoothly Evolving Unknown Degradations (SEUD) scenario, where both the active degradation set and degradation intensity change continuously over time. To support this scenario, we design a flexible synthesis pipeline that generates temporally coherent videos with single, compound, and evolving degradations. To address the challenges in the SEUD scenario, we propose an all-in-One Recurrent Conditional and Adaptive prompting Network (ORCANet). First, a Coarse Intensity Estimation Dehazing (CIED) module estimates haze intensity using physical priors and provides coarse dehazed features as initialization. Second, a Flow Prompt Generation (FPG) module extracts degradation features. FPG generates both static prompts that capture segment-level degradation types and dynamic prompts that adapt to frame-level intensity variations. Furthermore, a label-aware supervision mechanism improves the discriminability of static prompt representations under different degradations. Extensive experiments show that ORCANet achieves superior restoration quality, temporal consistency, and robustness over image and video-based baselines. Code is available at https://github.com/Friskknight/ORCANet-SEUD.

</details>


### [47] [FreeText: Training-Free Text Rendering in Diffusion Transformers via Attention Localization and Spectral Glyph Injection](https://arxiv.org/abs/2601.00535)
*Ruiqiang Zhang,Hengyi Wang,Chang Liu,Guanjie Wang,Zehua Ma,Weiming Zhang*

Main category: cs.CV

TL;DR: FreeText 是一种无需训练、即插即用的框架，通过分解文本渲染问题并利用 DiT 模型的内在机制，显著提升了多行布局和长尾脚本的渲染效果。


<details>
  <summary>Details</summary>
Motivation: 当前大规模文本到图像 (T2I) 扩散模型在开放域合成中表现优异，但在精确文本渲染（尤其是多行布局、密集排版和长尾脚本如中文）上仍有不足。现有解决方案通常需要昂贵的重新训练或严格的外部布局约束，可能损害美学效果并限制灵活性。

Method: FreeText 将问题分解为“在哪里写”和“写什么”。对于“在哪里写”，通过读取图像到文本的注意力机制中的空间属性来定位书写区域，使用类似锚点的稳定空间标记和拓扑感知细化生成高置信度掩码。对于“写什么”，采用频谱调制字形注入 (SGMI)，注入与噪声对齐的字形先验，并通过频域带通调制增强字形结构，抑制语义泄漏。

Result: 在 Qwen-Image、FLUX.1-dev 和 SD3 变体上的广泛实验表明，FreeText 在长文本基准、CVTG 和 CLT-Bench 上显著提升了文本可读性，同时保持了语义对齐和美学质量，推理开销适中。

Conclusion: FreeText 是一种无需训练、即插即用的框架，通过利用 Diffusion Transformer (DiT) 模型的内在机制，显著提升了文本渲染的精确度，尤其在多行布局、密集排版和长尾脚本（如中文）上表现优异。

Abstract: Large-scale text-to-image (T2I) diffusion models excel at open-domain synthesis but still struggle with precise text rendering, especially for multi-line layouts, dense typography, and long-tailed scripts such as Chinese. Prior solutions typically require costly retraining or rigid external layout constraints, which can degrade aesthetics and limit flexibility. We propose \textbf{FreeText}, a training-free, plug-and-play framework that improves text rendering by exploiting intrinsic mechanisms of \emph{Diffusion Transformer (DiT)} models. \textbf{FreeText} decomposes the problem into \emph{where to write} and \emph{what to write}. For \emph{where to write}, we localize writing regions by reading token-wise spatial attribution from endogenous image-to-text attention, using sink-like tokens as stable spatial anchors and topology-aware refinement to produce high-confidence masks. For \emph{what to write}, we introduce Spectral-Modulated Glyph Injection (SGMI), which injects a noise-aligned glyph prior with frequency-domain band-pass modulation to strengthen glyph structure and suppress semantic leakage (rendering the concept instead of the word). Extensive experiments on Qwen-Image, FLUX.1-dev, and SD3 variants across longText-Benchmark, CVTG, and our CLT-Bench show consistent gains in text readability while largely preserving semantic alignment and aesthetic quality, with modest inference overhead.

</details>


### [48] [Boosting Segment Anything Model to Generalize Visually Non-Salient Scenarios](https://arxiv.org/abs/2601.00537)
*Guangqian Guo,Pengfei Chen,Yong Guo,Huafeng Chen,Boqiang Zhang,Shan Gao*

Main category: cs.CV

TL;DR: VNS-SAM通过新设计提升SAM在视觉非显著场景的分割能力，保持零样本泛化性，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决SAM在视觉非显著场景（前景与背景对比度低）中分割性能不足的问题。

Method: 提出VNS-SAM，通过Mask-Edge Token Interactive解码器和Non-Salient Feature Mining模块，利用SAM的低层特征增强对非显著场景的感知。

Result: VNS-SAM在多种VNS分割任务中表现出色，尤其在零样本设置下，展示了广泛的现实应用潜力。

Conclusion: VNS-SAM通过Mask-Edge Token Interactive解码器和Non-Salient Feature Mining模块的设计，显著提升了在视觉非显著场景下的分割性能，同时保持了零样本泛化能力。

Abstract: Segment Anything Model (SAM), known for its remarkable zero-shot segmentation capabilities, has garnered significant attention in the community. Nevertheless, its performance is challenged when dealing with what we refer to as visually non-salient scenarios, where there is low contrast between the foreground and background. In these cases, existing methods often cannot capture accurate contours and fail to produce promising segmentation results. In this paper, we propose Visually Non-Salient SAM (VNS-SAM), aiming to enhance SAM's perception of visually non-salient scenarios while preserving its original zero-shot generalizability. We achieve this by effectively exploiting SAM's low-level features through two designs: Mask-Edge Token Interactive decoder and Non-Salient Feature Mining module. These designs help the SAM decoder gain a deeper understanding of non-salient characteristics with only marginal parameter increments and computational requirements. The additional parameters of VNS-SAM can be optimized within 4 hours, demonstrating its feasibility and practicality. In terms of data, we established VNS-SEG, a unified dataset for various VNS scenarios, with more than 35K images, in contrast to previous single-task adaptations. It is designed to make the model learn more robust VNS features and comprehensively benchmark the model's segmentation performance and generalizability on VNS scenarios. Extensive experiments across various VNS segmentation tasks demonstrate the superior performance of VNS-SAM, particularly under zero-shot settings, highlighting its potential for broad real-world applications. Codes and datasets are publicly available at https://guangqian-guo.github.io/VNS-SAM.

</details>


### [49] [DynaDrag: Dynamic Drag-Style Image Editing by Motion Prediction](https://arxiv.org/abs/2601.00542)
*Jiacheng Sui,Yujie Zhou,Li Niu*

Main category: cs.CV

TL;DR: DynaDrag是一种基于预测-移动框架的拖动式图像编辑方法，通过迭代运动预测和监督提升编辑效果。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有拖动式图像编辑方法中的跟踪丢失、模糊跟踪以及编辑性低等问题。

Method: DynaDrag采用预测-移动框架，通过迭代执行运动预测和运动监督来编辑图像。

Result: DynaDrag有效避免了源图像与目标编辑图像之间的巨大差距和不合理的中间点问题。

Conclusion: DynaDrag在面部和人体数据集上的实验展示了其优于先前工作的性能。

Abstract: To achieve pixel-level image manipulation, drag-style image editing which edits images using points or trajectories as conditions is attracting widespread attention. Most previous methods follow move-and-track framework, in which miss tracking and ambiguous tracking are unavoidable challenging issues. Other methods under different frameworks suffer from various problems like the huge gap between source image and target edited image as well as unreasonable intermediate point which can lead to low editability. To avoid these problems, we propose DynaDrag, the first dragging method under predict-and-move framework. In DynaDrag, Motion Prediction and Motion Supervision are performed iteratively. In each iteration, Motion Prediction first predicts where the handle points should move, and then Motion Supervision drags them accordingly. We also propose to dynamically adjust the valid handle points to further improve the performance. Experiments on face and human datasets showcase the superiority over previous works.

</details>


### [50] [SingBAG Pro: Accelerating point cloud-based iterative reconstruction for 3D photoacoustic imaging under arbitrary array](https://arxiv.org/abs/2601.00551)
*Shuang Li,Yibing Wang,Jian Gao,Chulhong Kim,Seongwook Choi,Yu Zhang,Qian Chen,Yao Yao,Changhui Li*

Main category: cs.CV

TL;DR: SlingBAG Pro是一种针对非规则阵列几何优化的3D光声成像重建算法，通过分层策略显著提升重建速度。


<details>
  <summary>Details</summary>
Motivation: 解决传统迭代重建算法在非规则阵列配置下的高计算复杂度、大内存需求和长重建时间问题。

Method: 基于滑动球自适应增长（SlingBAG）方法的点云迭代概念，扩展其兼容性至任意阵列几何，并采用分层优化策略。

Result: 相比原始SlingBAG算法，SlingBAG Pro在非规则阵列几何下实现了高达2.2倍的速度提升。

Conclusion: SlingBAG Pro 算法通过结合零梯度滤波和逐步增加的时间采样率，显著提高了在非规则阵列几何下的3D光声成像重建速度，同时保持了高质量的重建效果。

Abstract: High-quality three-dimensional (3D) photoacoustic imaging (PAI) is gaining increasing attention in clinical applications. To address the challenges of limited space and high costs, irregular geometric transducer arrays that conform to specific imaging regions are promising for achieving high-quality 3D PAI with fewer transducers. However, traditional iterative reconstruction algorithms struggle with irregular array configurations, suffering from high computational complexity, substantial memory requirements, and lengthy reconstruction times. In this work, we introduce SlingBAG Pro, an advanced reconstruction algorithm based on the point cloud iteration concept of the Sliding ball adaptive growth (SlingBAG) method, while extending its compatibility to arbitrary array geometries. SlingBAG Pro maintains high reconstruction quality, reduces the number of required transducers, and employs a hierarchical optimization strategy that combines zero-gradient filtering with progressively increased temporal sampling rates during iteration. This strategy rapidly removes redundant spatial point clouds, accelerates convergence, and significantly shortens overall reconstruction time. Compared to the original SlingBAG algorithm, SlingBAG Pro achieves up to a 2.2-fold speed improvement in point cloud-based 3D PA reconstruction under irregular array geometries. The proposed method is validated through both simulation and in vivo mouse experiments, and the source code is publicly available at https://github.com/JaegerCQ/SlingBAG_Pro.

</details>


### [51] [AEGIS: Exploring the Limit of World Knowledge Capabilities for Unified Mulitmodal Models](https://arxiv.org/abs/2601.00561)
*Jintao Lin,Bowen Dong,Weikang Shi,Chenyang Lei,Suiyun Zhang,Rui Liu,Xihui Liu*

Main category: cs.CV

TL;DR: AEGIS benchmark and DCE protocol reveal UMMs' world knowledge gaps, suggesting plug-in reasoning modules as a future research direction.


<details>
  <summary>Details</summary>
Motivation: To address the lack of comprehensive benchmarks for evaluating UMMs' ability to apply world knowledge across diverse tasks.

Method: The paper introduces AEGIS, a multi-task benchmark, and Deterministic Checklist-based Evaluation (DCE) for reliable assessment of UMMs.

Result: Most UMMs show significant world knowledge deficits, especially in complex reasoning tasks, though plug-in modules offer partial improvement.

Conclusion: The study underscores the importance of world-knowledge-based reasoning as a critical frontier for UMMs, with simple plug-in reasoning modules showing potential to mitigate performance issues.

Abstract: The capability of Unified Multimodal Models (UMMs) to apply world knowledge across diverse tasks remains a critical, unresolved challenge. Existing benchmarks fall short, offering only siloed, single-task evaluations with limited diagnostic power. To bridge this gap, we propose AEGIS (\emph{i.e.}, \textbf{A}ssessing \textbf{E}diting, \textbf{G}eneration, \textbf{I}nterpretation-Understanding for \textbf{S}uper-intelligence), a comprehensive multi-task benchmark covering visual understanding, generation, editing, and interleaved generation. AEGIS comprises 1,050 challenging, manually-annotated questions spanning 21 topics (including STEM, humanities, daily life, etc.) and 6 reasoning types. To concretely evaluate the performance of UMMs in world knowledge scope without ambiguous metrics, we further propose Deterministic Checklist-based Evaluation (DCE), a protocol that replaces ambiguous prompt-based scoring with atomic ``Y/N'' judgments, to enhance evaluation reliability. Our extensive experiments reveal that most UMMs exhibit severe world knowledge deficits and that performance degrades significantly with complex reasoning. Additionally, simple plug-in reasoning modules can partially mitigate these vulnerabilities, highlighting a promising direction for future research. These results highlight the importance of world-knowledge-based reasoning as a critical frontier for UMMs.

</details>


### [52] [A Cascaded Information Interaction Network for Precise Image Segmentation](https://arxiv.org/abs/2601.00562)
*Hewen Xiao,Jie Mei,Guangfu Ma,Weiren Wu*

Main category: cs.CV

TL;DR: 提出一种结合全局信息引导模块的级联CNN，显著提升复杂场景下的分割精度，实验验证其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 视觉感知在自主行为中至关重要，但复杂场景下的鲁棒分割仍具挑战性。

Method: 提出了一种级联卷积神经网络，集成了新颖的全局信息引导模块，有效融合了多层次的纹理细节与语义特征。

Result: 在基准图像分割数据集上的实验表明，该框架实现了更高的精度，超越了现有先进方法。

Conclusion: 该论文提出的级联卷积神经网络结合全局信息引导模块显著提升了分割精度，尤其在视觉杂乱或模糊环境中表现优异，展示了在实际机器人应用中的潜力。

Abstract: Visual perception plays a pivotal role in enabling autonomous behavior, offering a cost-effective and efficient alternative to complex multi-sensor systems. However, robust segmentation remains a challenge in complex scenarios. To address this, this paper proposes a cascaded convolutional neural network integrated with a novel Global Information Guidance Module. This module is designed to effectively fuse low-level texture details with high-level semantic features across multiple layers, thereby overcoming the inherent limitations of single-scale feature extraction. This architectural innovation significantly enhances segmentation accuracy, particularly in visually cluttered or blurred environments where traditional methods often fail. Experimental evaluations on benchmark image segmentation datasets demonstrate that the proposed framework achieves superior precision, outperforming existing state-of-the-art methods. The results highlight the effectiveness of the approach and its promising potential for deployment in practical robotic applications.

</details>


### [53] [GranAlign: Granularity-Aware Alignment Framework for Zero-Shot Video Moment Retrieval](https://arxiv.org/abs/2601.00584)
*Mingyu Jeon,Sunjae Yoon,Jonghee Kim,Junyeoung Kim*

Main category: cs.CV

TL;DR: GranAlign是一种无需训练的框架，通过粒度感知对齐技术解决零样本视频时刻检索中的语义粒度不匹配问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 零样本视频时刻检索中，文本查询与视频内容之间的语义粒度不匹配是主要挑战，现有方法未能平衡预训练知识在多模态间的语义粒度。

Method: 提出了GranAlign框架，包含两种互补技术：基于粒度的查询重写和查询感知的标题生成，以解决语义粒度不匹配问题。

Result: 在三个主要基准测试（QVHighlights、Charades-STA、ActivityNet-Captions）上均达到了新的最优性能，特别是在QVHighlights数据集上实现了3.23%的mAP@avg提升。

Conclusion: GranAlign框架通过粒度感知对齐技术有效解决了零样本视频时刻检索中的语义粒度不匹配问题，显著提升了检索性能，并在多个基准测试中达到了新的最优水平。

Abstract: Zero-shot video moment retrieval (ZVMR) is the task of localizing a temporal moment within an untrimmed video using a natural language query without relying on task-specific training data. The primary challenge in this setting lies in the mismatch in semantic granularity between textual queries and visual content. Previous studies in ZVMR have attempted to achieve alignment by leveraging high-quality pre-trained knowledge that represents video and language in a joint space. However, these approaches failed to balance the semantic granularity between the pre-trained knowledge provided by each modality for a given scene. As a result, despite the high quality of each modality's representations, the mismatch in granularity led to inaccurate retrieval. In this paper, we propose a training-free framework, called Granularity-Aware Alignment (GranAlign), that bridges this gap between coarse and fine semantic representations. Our approach introduces two complementary techniques: granularity-based query rewriting to generate varied semantic granularities, and query-aware caption generation to embed query intent into video content. By pairing multi-level queries with both query-agnostic and query-aware captions, we effectively resolve semantic mismatches. As a result, our method sets a new state-of-the-art across all three major benchmarks (QVHighlights, Charades-STA, ActivityNet-Captions), with a notable 3.23% mAP@avg improvement on the challenging QVHighlights dataset.

</details>


### [54] [SafeMo: Linguistically Grounded Unlearning for Trustworthy Text-to-Motion Generation](https://arxiv.org/abs/2601.00590)
*Yiling Wang,Zeyu Zhang,Yiran Wang,Hao Tang*

Main category: cs.CV

TL;DR: SafeMo是一个安全文本到运动生成框架，通过连续空间的两阶段遗忘策略解决了现有离散方法的缺陷，实验显示其在安全性和性能上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到运动生成方法在安全性方面存在缺陷，离散代码簿替换方法会导致良性任务性能下降，并引入量化和平滑损失。现有数据集包含不安全意图和运动，不适用于安全驱动的机器学习。

Method: 提出了SafeMo框架，采用两阶段的机器遗忘策略（MMU），在连续空间中进行安全运动生成，避免了离散代码簿替换的缺陷。此外，构建了首个安全文本到运动数据集SafeMoVAE-29K。

Result: SafeMo在HumanML3D和Motion-X数据集上分别达到2.5倍和14.4倍的遗忘集FID提升，优于现有最佳方法LCR，同时在安全提示上保持或优于其性能。

Conclusion: SafeMo通过集成最小化运动遗忘（MMU）策略，在连续空间中实现了安全的人体运动生成，避免了代码簿损失，并在安全性与实用性之间取得了良好平衡。实验证明，SafeMo在遗忘不安全提示方面表现优异，同时在安全提示上保持或优于现有方法的性能。

Abstract: Text-to-motion (T2M) generation with diffusion backbones achieves strong realism and alignment. Safety concerns in T2M methods have been raised in recent years; existing methods replace discrete VQ-VAE codebook entries to steer the model away from unsafe behaviors. However, discrete codebook replacement-based methods have two critical flaws: firstly, replacing codebook entries which are reused by benign prompts leads to drifts on everyday tasks, degrading the model's benign performance; secondly, discrete token-based methods introduce quantization and smoothness loss, resulting in artifacts and jerky transitions. Moreover, existing text-to-motion datasets naturally contain unsafe intents and corresponding motions, making them unsuitable for safety-driven machine learning. To address these challenges, we propose SafeMo, a trustworthy motion generative framework integrating Minimal Motion Unlearning (MMU), a two-stage machine unlearning strategy, enabling safe human motion generation in continuous space, preserving continuous kinematics without codebook loss and delivering strong safety-utility trade-offs compared to current baselines. Additionally, we present the first safe text-to-motion dataset SafeMoVAE-29K integrating rewritten safe text prompts and continuous refined motion for trustworthy human motion unlearning. Built upon DiP, SafeMo efficiently generates safe human motions with natural transitions. Experiments demonstrate effective unlearning performance of SafeMo by showing strengthened forgetting on unsafe prompts, reaching 2.5x and 14.4x higher forget-set FID on HumanML3D and Motion-X respectively, compared to the previous SOTA human motion unlearning method LCR, with benign performance on safe prompts being better or comparable. Code: https://github.com/AIGeeksGroup/SafeMo. Website: https://aigeeksgroup.github.io/SafeMo.

</details>


### [55] [Modality Dominance-Aware Optimization for Embodied RGB-Infrared Perception](https://arxiv.org/abs/2601.00598)
*Xianhui Liu,Siqi Jiang,Yi Xie,Yuqing Lin,Siao Liu*

Main category: cs.CV

TL;DR: MDACL框架通过MDI量化模态主导性，结合HCG和AER调节优化，显著提升RGB-IR检测性能。


<details>
  <summary>Details</summary>
Motivation: RGB-IR多模态感知在复杂环境中至关重要，但现有方法因模态特征不对称导致的优化偏差未得到充分探索。

Method: 提出了模态主导性指数（MDI）来量化模态主导性，并开发了模态主导感知的跨模态学习框架（MDACL），包含分层跨模态引导（HCG）和对抗均衡正则化（AER）。

Result: 在三个RGB-IR基准测试上的实验表明，MDACL有效缓解了优化偏差并实现了SOTA性能。

Conclusion: MDACL框架通过量化模态主导性并调节跨模态优化，有效缓解了RGB-IR检测中的优化偏差，实现了最先进的性能。

Abstract: RGB-Infrared (RGB-IR) multimodal perception is fundamental to embodied multimedia systems operating in complex physical environments. Although recent cross-modal fusion methods have advanced RGB-IR detection, the optimization dynamics caused by asymmetric modality characteristics remain underexplored. In practice, disparities in information density and feature quality introduce persistent optimization bias, leading training to overemphasize a dominant modality and hindering effective fusion. To quantify this phenomenon, we propose the Modality Dominance Index (MDI), which measures modality dominance by jointly modeling feature entropy and gradient contribution. Based on MDI, we develop a Modality Dominance-Aware Cross-modal Learning (MDACL) framework that regulates cross-modal optimization. MDACL incorporates Hierarchical Cross-modal Guidance (HCG) to enhance feature alignment and Adversarial Equilibrium Regularization (AER) to balance optimization dynamics during fusion. Extensive experiments on three RGB-IR benchmarks demonstrate that MDACL effectively mitigates optimization bias and achieves SOTA performance.

</details>


### [56] [RePose: A Real-Time 3D Human Pose Estimation and Biomechanical Analysis Framework for Rehabilitation](https://arxiv.org/abs/2601.00625)
*Junxiao Xue,Pavel Smirnov,Ziao Li,Yunyun Shi,Shi Chen,Xinyi Yin,Xiaohan Yue,Lei Wang,Yiduo Wang,Feng Lin,Yijia Chen,Xiao Ma,Xiaoran Yan,Qing Zhang,Fengjian Xue,Xuecheng Wu*

Main category: cs.CV

TL;DR: RePose：实时3D姿态估计与运动分析方法，用于康复训练，提供即时反馈和多干扰快速跟踪。


<details>
  <summary>Details</summary>
Motivation: 为了在康复训练中实时监测和评估患者动作，提供即时反馈和指导，帮助患者恢复肌肉力量和运动功能。

Method: 提出了一种基于多摄像头RGB视频输入的端到端实时人体姿态估计和运动分析流程，包括快速跟踪方法和改进的SmoothNet姿态估计技术。

Result: 方法能在多干扰场景下快速跟踪（单帧<1ms），有效减少姿态估计误差，并通过Unity平台实时显示肌肉应力情况。

Conclusion: RePose方法通过实时3D人体姿态估计和运动分析，有效辅助康复训练，提供即时反馈和指导，帮助患者正确执行康复动作。

Abstract: We propose a real-time 3D human pose estimation and motion analysis method termed RePose for rehabilitation training. It is capable of real-time monitoring and evaluation of patients'motion during rehabilitation, providing immediate feedback and guidance to assist patients in executing rehabilitation exercises correctly. Firstly, we introduce a unified pipeline for end-to-end real-time human pose estimation and motion analysis using RGB video input from multiple cameras which can be applied to the field of rehabilitation training. The pipeline can help to monitor and correct patients'actions, thus aiding them in regaining muscle strength and motor functions. Secondly, we propose a fast tracking method for medical rehabilitation scenarios with multiple-person interference, which requires less than 1ms for tracking for a single frame. Additionally, we modify SmoothNet for real-time posture estimation, effectively reducing pose estimation errors and restoring the patient's true motion state, making it visually smoother. Finally, we use Unity platform for real-time monitoring and evaluation of patients' motion during rehabilitation, and to display the muscle stress conditions to assist patients with their rehabilitation training.

</details>


### [57] [HyperPriv-EPN: Hypergraph Learning with Privileged Knowledge for Ependymoma Prognosis](https://arxiv.org/abs/2601.00626)
*Shuren Gabriel Yu,Sikang Ren,Yongji Tian*

Main category: cs.CV

TL;DR: HyperPriv-EPN通过超图LUPI框架，利用术后数据训练模型，提升术前MRI诊断准确性，无需推理时文本输入。


<details>
  <summary>Details</summary>
Motivation: 术前MRI缺乏术后手术报告的语义信息，导致预后诊断困难，现有方法无法在推理时利用这些特权文本数据。

Method: 提出了HyperPriv-EPN框架，采用基于超图的LUPI方法，通过Severed Graph Strategy和双流蒸馏技术，使学生图能够仅从视觉特征中模拟语义社区结构。

Result: 在311例患者的多中心队列中验证，HyperPriv-EPN实现了最先进的诊断准确性和生存分层。

Conclusion: HyperPriv-EPN成功地将术后专家知识迁移至术前诊断，无需在推理时依赖文本数据，显著提升了术前预后诊断的准确性和生存分层效果。

Abstract: Preoperative prognosis of Ependymoma is critical for treatment planning but challenging due to the lack of semantic insights in MRI compared to post-operative surgical reports. Existing multimodal methods fail to leverage this privileged text data when it is unavailable during inference. To bridge this gap, we propose HyperPriv-EPN, a hypergraph-based Learning Using Privileged Information (LUPI) framework. We introduce a Severed Graph Strategy, utilizing a shared encoder to process both a Teacher graph (enriched with privileged post-surgery information) and a Student graph (restricted to pre-operation data). Through dual-stream distillation, the Student learns to hallucinate semantic community structures from visual features alone. Validated on a multi-center cohort of 311 patients, HyperPriv-EPN achieves state-of-the-art diagnostic accuracy and survival stratification. This effectively transfers expert knowledge to the preoperative setting, unlocking the value of historical post-operative data to guide the diagnosis of new patients without requiring text at inference.

</details>


### [58] [Quality Detection of Stored Potatoes via Transfer Learning: A CNN and Vision Transformer Approach](https://arxiv.org/abs/2601.00645)
*Shrikant Kapse,Priyankkumar Dhrangdhariya,Priya Kedia,Manasi Patwardhan,Shankar Kausley,Soumyadipta Maiti,Beena Rai,Shirish Karande*

Main category: cs.CV

TL;DR: 该研究利用深度学习模型（如DenseNet）通过图像分析监测土豆储存质量，实现了高精度发芽检测和保质期预测，支持自动化库存管理并减少食物浪费。


<details>
  <summary>Details</summary>
Motivation: 解决土豆储存期间的关键挑战，如发芽检测、重量损失估计和保质期预测，提供非侵入性、可扩展的解决方案。

Method: 研究利用ResNet、VGG、DenseNet和Vision Transformer（ViT）等预训练架构，设计了两种专用模型：高精度二元分类器用于发芽检测，以及多类预测器用于重量损失估计和保质期预测。

Result: DenseNet在发芽检测中达到98.03%的准确率；保质期预测模型在粗分类（2-5类）下表现最佳，准确率超过89.83%，但在细分类（6-8类）中因视觉差异细微和数据有限导致准确率下降。

Conclusion: 该研究展示了基于图像的深度学习模型在土豆储存质量监测中的可行性，支持自动化分拣和库存系统，从而提高库存管理效率并减少食物浪费。未来研究应致力于开发适用于不同土豆品种和储存条件的通用模型。

Abstract: Image-based deep learning provides a non-invasive, scalable solution for monitoring potato quality during storage, addressing key challenges such as sprout detection, weight loss estimation, and shelf-life prediction. In this study, images and corresponding weight data were collected over a 200-day period under controlled temperature and humidity conditions. Leveraging powerful pre-trained architectures of ResNet, VGG, DenseNet, and Vision Transformer (ViT), we designed two specialized models: (1) a high-precision binary classifier for sprout detection, and (2) an advanced multi-class predictor to estimate weight loss and forecast remaining shelf-life with remarkable accuracy. DenseNet achieved exceptional performance, with 98.03% accuracy in sprout detection. Shelf-life prediction models performed best with coarse class divisions (2-5 classes), achieving over 89.83% accuracy, while accuracy declined for finer divisions (6-8 classes) due to subtle visual differences and limited data per class. These findings demonstrate the feasibility of integrating image-based models into automated sorting and inventory systems, enabling early identification of sprouted potatoes and dynamic categorization based on storage stage. Practical implications include improved inventory management, differential pricing strategies, and reduced food waste across supply chains. While predicting exact shelf-life intervals remains challenging, focusing on broader class divisions ensures robust performance. Future research should aim to develop generalized models trained on diverse potato varieties and storage conditions to enhance adaptability and scalability. Overall, this approach offers a cost-effective, non-destructive method for quality assessment, supporting efficiency and sustainability in potato storage and distribution.

</details>


### [59] [Reconstructing Building Height from Spaceborne TomoSAR Point Clouds Using a Dual-Topology Network](https://arxiv.org/abs/2601.00658)
*Zhaiyu Chen,Yuanyuan Wang,Yilei Shi,Xiao Xiang Zhu*

Main category: cs.CV

TL;DR: 提出双拓扑网络框架，直接从TomoSAR点云生成高分辨率建筑高度图，解决了噪声和缺失数据问题，实验证明有效且可扩展至光学影像。


<details>
  <summary>Details</summary>
Motivation: TomoSAR点云存在噪声、各向异性点分布和不连贯表面数据缺失等问题，阻碍了准确的高度重建。

Method: 采用双拓扑网络，交替处理点分支和网格分支，联合建模不规则散射特征并增强空间一致性，从而去噪输入点并填补缺失区域。

Result: 在慕尼黑和柏林的数据集上进行了广泛实验，验证了方法的有效性，并可结合光学卫星图像进一步提升重建质量。

Conclusion: 该论文提出了一个基于学习的框架，首次实现了直接从TomoSAR点云进行大规模城市高度映射的概念验证，并通过实验验证了其有效性。

Abstract: Reliable building height estimation is essential for various urban applications. Spaceborne SAR tomography (TomoSAR) provides weather-independent, side-looking observations that capture facade-level structure, offering a promising alternative to conventional optical methods. However, TomoSAR point clouds often suffer from noise, anisotropic point distributions, and data voids on incoherent surfaces, all of which hinder accurate height reconstruction. To address these challenges, we introduce a learning-based framework for converting raw TomoSAR points into high-resolution building height maps. Our dual-topology network alternates between a point branch that models irregular scatterer features and a grid branch that enforces spatial consistency. By jointly processing these representations, the network denoises the input points and inpaints missing regions to produce continuous height estimates. To our knowledge, this is the first proof of concept for large-scale urban height mapping directly from TomoSAR point clouds. Extensive experiments on data from Munich and Berlin validate the effectiveness of our approach. Moreover, we demonstrate that our framework can be extended to incorporate optical satellite imagery, further enhancing reconstruction quality. The source code is available at https://github.com/zhu-xlab/tomosar2height.

</details>


### [60] [CRoPS: A Training-Free Hallucination Mitigation Framework for Vision-Language Models](https://arxiv.org/abs/2601.00659)
*Neeraj Anand,Samyak Jha,Udbhav Bamba,Rahul Rahaman*

Main category: cs.CV

TL;DR: CRoPS是一种训练免费的幻觉缓解框架，通过选择性移除文本标记和广义对比解码，显著减少LVLMs中的幻觉内容，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）倾向于生成幻觉内容，现有方法依赖狭窄的假设且效果在生成后期下降，视觉信息仍会传播到生成文本中。

Method: 提出了一种新颖的幻觉模型，通过选择性移除关键文本标记来捕捉幻觉效应，并引入广义对比解码（Generalized Contrastive Decoding）整合多个幻觉模型以代表多样化的幻觉来源。

Result: CRoPS在CHAIR分数上提升了20%，在六个基准测试和三个LVLM家族中表现一致优于现有训练免费方法。

Conclusion: CRoPS框架通过选择性移除关键文本标记和广义对比解码，显著减少了大型视觉语言模型中的幻觉内容，提升了CHAIR分数20%，并在多个基准测试和模型家族中表现优异。

Abstract: Despite the rapid success of Large Vision-Language Models (LVLMs), a persistent challenge is their tendency to generate hallucinated content, undermining reliability in real-world use. Existing training-free methods address hallucinations but face two limitations: (i) they rely on narrow assumptions about hallucination sources, and (ii) their effectiveness declines toward the end of generation, where hallucinations are most likely to occur. A common strategy is to build hallucinated models by completely or partially removing visual tokens and contrasting them with the original model. Yet, this alone proves insufficient, since visual information still propagates into generated text. Building on this insight, we propose a novel hallucinated model that captures hallucination effects by selectively removing key text tokens. We further introduce Generalized Contrastive Decoding, which integrates multiple hallucinated models to represent diverse hallucination sources. Together, these ideas form CRoPS, a training-free hallucination mitigation framework that improves CHAIR scores by 20% and achieves consistent gains across six benchmarks and three LVLM families, outperforming state-of-the-art training-free methods.

</details>


### [61] [Pixel-to-4D: Camera-Controlled Image-to-Video Generation with Dynamic 3D Gaussians](https://arxiv.org/abs/2601.00678)
*Melonie de Almeida,Daniela Ivanova,Tong Shi,John H. Williamson,Paul Henderson*

Main category: cs.CV

TL;DR: 提出一种单次前向传递的3D高斯场景表示方法，实现快速、相机引导的视频生成，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在单图像条件视频生成中缺乏用户可控性（如修改相机路径），且在相机运动建模、时间一致性和几何完整性方面表现不足。

Method: 利用显式中间3D表示（3D高斯场景表示）和单次前向传递，结合相机轨迹生成视频。

Result: 在KITTI、Waymo、RealEstate10K和DL3DV-10K数据集上的实验表明，该方法在视频质量和推理效率上达到最优水平。

Conclusion: 该论文提出了一种新颖的框架，通过单次前向传递构建3D高斯场景表示并采样合理的物体运动，实现了快速、相机引导的视频生成，无需迭代去噪。

Abstract: Humans excel at forecasting the future dynamics of a scene given just a single image. Video generation models that can mimic this ability are an essential component for intelligent systems. Recent approaches have improved temporal coherence and 3D consistency in single-image-conditioned video generation. However, these methods often lack robust user controllability, such as modifying the camera path, limiting their applicability in real-world applications. Most existing camera-controlled image-to-video models struggle with accurately modeling camera motion, maintaining temporal consistency, and preserving geometric integrity. Leveraging explicit intermediate 3D representations offers a promising solution by enabling coherent video generation aligned with a given camera trajectory. Although these methods often use 3D point clouds to render scenes and introduce object motion in a later stage, this two-step process still falls short in achieving full temporal consistency, despite allowing precise control over camera movement. We propose a novel framework that constructs a 3D Gaussian scene representation and samples plausible object motion, given a single image in a single forward pass. This enables fast, camera-guided video generation without the need for iterative denoising to inject object motion into render frames. Extensive experiments on the KITTI, Waymo, RealEstate10K and DL3DV-10K datasets demonstrate that our method achieves state-of-the-art video quality and inference efficiency. The project page is available at https://melonienimasha.github.io/Pixel-to-4D-Website.

</details>


### [62] [Efficient Deep Demosaicing with Spatially Downsampled Isotropic Networks](https://arxiv.org/abs/2601.00703)
*Cory Fan,Wenchao Zhang*

Main category: cs.CV

TL;DR: 论文提出空间下采样能提升各向同性网络的效率和性能，并通过实验验证了JD3Net的优越表现。


<details>
  <summary>Details</summary>
Motivation: 现代数字成像应用多在移动平台上进行，需要轻量高效的网络，而传统各向同性网络因避免空间下采样而计算成本过高。

Method: 采用DeepMAD的数学架构设计技术，设计了带和不带下采样的简单全卷积网络。

Result: 下采样提高了实证性能，JD3Net在多种任务中表现优异。

Conclusion: 空间下采样可以显著提高各向同性网络的效率和性能，JD3Net在多种图像去马赛克和联合去马赛克与去噪任务中表现出色。

Abstract: In digital imaging, image demosaicing is a crucial first step which recovers the RGB information from a color filter array (CFA). Oftentimes, deep learning is utilized to perform image demosaicing. Given that most modern digital imaging applications occur on mobile platforms, applying deep learning to demosaicing requires lightweight and efficient networks. Isotropic networks, also known as residual-in-residual networks, have been often employed for image demosaicing and joint-demosaicing-and-denoising (JDD). Most demosaicing isotropic networks avoid spatial downsampling entirely, and thus are often prohibitively expensive computationally for mobile applications. Contrary to previous isotropic network designs, this paper claims that spatial downsampling to a signficant degree can improve the efficiency and performance of isotropic networks. To validate this claim, we design simple fully convolutional networks with and without downsampling using a mathematical architecture design technique adapted from DeepMAD, and find that downsampling improves empirical performance. Additionally, empirical testing of the downsampled variant, JD3Net, of our fully convolutional networks reveals strong empirical performance on a variety of image demosaicing and JDD tasks.

</details>


### [63] [Multi-Level Feature Fusion for Continual Learning in Visual Quality Inspection](https://arxiv.org/abs/2601.00725)
*Johannes C. Bauer,Paul Geng,Stephan Trattnig,Petr Dokládal,Rüdiger Daub*

Main category: cs.CV

TL;DR: MLFF方法通过多级特征融合，在保持高效计算的同时，减少灾难性遗忘并提升对新条件的适应性。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络在制造中的视觉质量检测任务中表现优异，但在更易变的重制造场景中，由于产品和缺陷模式的频繁变化，其适用性受限，需要频繁适应新条件，这构成了持续学习问题。

Method: 采用多级特征融合（MLFF）方法，利用预训练网络不同深度的表示，以提高计算效率和避免灾难性遗忘。

Result: MLFF方法在不同质量检测问题上能够匹配端到端训练的性能，同时使用显著更少的可训练参数，减少灾难性遗忘，并提高对新条件的泛化鲁棒性。

Conclusion: 该论文提出的多级特征融合（MLFF）方法在保持较少可训练参数的同时，能够匹配端到端训练的性能，减少灾难性遗忘，并提高对新产品或缺陷类型的泛化鲁棒性。

Abstract: Deep neural networks show great potential for automating various visual quality inspection tasks in manufacturing. However, their applicability is limited in more volatile scenarios, such as remanufacturing, where the inspected products and defect patterns often change. In such settings, deployed models require frequent adaptation to novel conditions, effectively posing a continual learning problem. To enable quick adaptation, the necessary training processes must be computationally efficient while still avoiding effects like catastrophic forgetting. This work presents a multi-level feature fusion (MLFF) approach that aims to improve both aspects simultaneously by utilizing representations from different depths of a pretrained network. We show that our approach is able to match the performance of end-to-end training for different quality inspection problems while using significantly less trainable parameters. Furthermore, it reduces catastrophic forgetting and improves generalization robustness to new product types or defects.

</details>


### [64] [Grading Handwritten Engineering Exams with Multimodal Large Language Models](https://arxiv.org/abs/2601.00730)
*Janez Perš,Jon Muhovič,Andrej Košir,Boštjan Murovec*

Main category: cs.CV

TL;DR: 该研究提出了一种基于多模态大语言模型的端到端工作流，用于评分手写工程测验，通过结构化设计和参考基础实现了高可靠性和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决手写STEM考试评分慢且难以扩展的问题，同时保留标准考试流程。

Method: 采用多阶段设计，包括格式/存在检查、独立评分者集合、监督聚合和刚性模板，以确保可靠性和可审计性。

Result: 完整流程在保持低偏差的情况下，与讲师评分的平均绝对差异约为8分，手动审查触发率约为17%。

Conclusion: 结构化提示和参考基础对于准确评分至关重要，简单的提示或移除参考解决方案会显著降低准确性并引入系统性过评分。

Abstract: Handwritten STEM exams capture open-ended reasoning and diagrams, but manual grading is slow and difficult to scale. We present an end-to-end workflow for grading scanned handwritten engineering quizzes with multimodal large language models (LLMs) that preserves the standard exam process (A4 paper, unconstrained student handwriting). The lecturer provides only a handwritten reference solution (100%) and a short set of grading rules; the reference is converted into a text-only summary that conditions grading without exposing the reference scan. Reliability is achieved through a multi-stage design with a format/presence check to prevent grading blank answers, an ensemble of independent graders, supervisor aggregation, and rigid templates with deterministic validation to produce auditable, machine-parseable reports. We evaluate the frozen pipeline in a clean-room protocol on a held-out real course quiz in Slovenian, including hand-drawn circuit schematics. With state-of-the-art backends (GPT-5.2 and Gemini-3 Pro), the full pipeline achieves $\approx$8-point mean absolute difference to lecturer grades with low bias and an estimated manual-review trigger rate of $\approx$17% at $D_{\max}=40$. Ablations show that trivial prompting and removing the reference solution substantially degrade accuracy and introduce systematic over-grading, confirming that structured prompting and reference grounding are essential.

</details>


### [65] [Unified Primitive Proxies for Structured Shape Completion](https://arxiv.org/abs/2601.00759)
*Zhaiyu Chen,Yuqing Wang,Xiao Xiang Zhu*

Main category: cs.CV

TL;DR: UniCo通过专用路径解码基元，结合可学习代理和在线目标更新，显著提升结构化3D形状补全性能。


<details>
  <summary>Details</summary>
Motivation: 重新思考基元与点云的交互方式，发现专用路径解码基元更有效，旨在实现从缺失数据中恢复结构化3D理解。

Method: 提出UniCo方法，通过专用路径解码基元，利用可学习的基元代理（primitive proxies）生成可直接组装的输出。训练策略通过在线目标更新耦合基元和点云。

Result: 在合成和真实世界基准测试中，UniCo显著优于现有方法，Chamfer距离降低50%，法线一致性提升7%。

Conclusion: UniCo通过统一表示和在线目标更新策略，在结构化3D形状补全任务中显著优于现有基线，Chamfer距离降低达50%，法线一致性提升达7%。

Abstract: Structured shape completion recovers missing geometry as primitives rather than as unstructured points, which enables primitive-based surface reconstruction. Instead of following the prevailing cascade, we rethink how primitives and points should interact, and find it more effective to decode primitives in a dedicated pathway that attends to shared shape features. Following this principle, we present UniCo, which in a single feed-forward pass predicts a set of primitives with complete geometry, semantics, and inlier membership. To drive this unified representation, we introduce primitive proxies, learnable queries that are contextualized to produce assembly-ready outputs. To ensure consistent optimization, our training strategy couples primitives and points with online target updates. Across synthetic and real-world benchmarks with four independent assembly solvers, UniCo consistently outperforms recent baselines, lowering Chamfer distance by up to 50% and improving normal consistency by up to 7%. These results establish an attractive recipe for structured 3D understanding from incomplete data. Project page: https://unico-completion.github.io.

</details>


### [66] [Fusion-SSAT: Unleashing the Potential of Self-supervised Auxiliary Task by Feature Fusion for Generalized Deepfake Detection](https://arxiv.org/abs/2601.00789)
*Shukesh Reddy,Srijan Das,Abhijit Das*

Main category: cs.CV

TL;DR: 自监督学习作为辅助任务的特征表示融合，提升了深度伪造检测的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 释放自监督学习作为辅助任务的潜力，以优化广义深度伪造检测的主要任务。

Method: 探索了自监督学习作为辅助任务的不同训练方案组合，以优化广义深度伪造检测的主要任务。

Result: 在包括DF40、FaceForensics++、Celeb-DF、DFD、FaceShifter、UADFV等多个数据集上的实验表明，该方法在跨数据集评估中优于当前最先进的检测器。

Conclusion: 通过融合自监督辅助任务的特征表示，可以显著提升广义深度伪造检测任务的性能，并在跨数据集评估中展现出更好的泛化能力。

Abstract: In this work, we attempted to unleash the potential of self-supervised learning as an auxiliary task that can optimise the primary task of generalised deepfake detection. To explore this, we examined different combinations of the training schemes for these tasks that can be most effective. Our findings reveal that fusing the feature representation from self-supervised auxiliary tasks is a powerful feature representation for the problem at hand. Such a representation can leverage the ultimate potential and bring in a unique representation of both the self-supervised and primary tasks, achieving better performance for the primary task. We experimented on a large set of datasets, which includes DF40, FaceForensics++, Celeb-DF, DFD, FaceShifter, UADFV, and our results showed better generalizability on cross-dataset evaluation when compared with current state-of-the-art detectors.

</details>


### [67] [Two Deep Learning Approaches for Automated Segmentation of Left Ventricle in Cine Cardiac MRI](https://arxiv.org/abs/2601.00794)
*Wenhui Chu,Nikolaos V. Tsekos*

Main category: cs.CV

TL;DR: 提出两种新型U-Net变体（LNU-Net和IBU-Net）用于左心室MRI分割，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 左心室分割对临床心脏图像量化与诊断至关重要，现有方法需改进。

Method: 提出LNU-Net（基于层归一化的U-Net）和IBU-Net（基于实例-批量归一化的U-Net），结合仿射变换和弹性变形进行图像处理。

Result: 实验表明，LNU-Net和IBU-Net在Dice系数和平均垂直距离上优于其他先进方法。

Conclusion: LNU-Net和IBU-Net在左心室分割任务中表现优于现有方法，通过Dice系数和平均垂直距离验证了其有效性。

Abstract: Left ventricle (LV) segmentation is critical for clinical quantification and diagnosis of cardiac images. In this work, we propose two novel deep learning architectures called LNU-Net and IBU-Net for left ventricle segmentation from short-axis cine MRI images. LNU-Net is derived from layer normalization (LN) U-Net architecture, while IBU-Net is derived from the instance-batch normalized (IB) U-Net for medical image segmentation. The architectures of LNU-Net and IBU-Net have a down-sampling path for feature extraction and an up-sampling path for precise localization. We use the original U-Net as the basic segmentation approach and compared it with our proposed architectures. Both LNU-Net and IBU-Net have left ventricle segmentation methods: LNU-Net applies layer normalization in each convolutional block, while IBU-Net incorporates instance and batch normalization together in the first convolutional block and passes its result to the next layer. Our method incorporates affine transformations and elastic deformations for image data processing. Our dataset that contains 805 MRI images regarding the left ventricle from 45 patients is used for evaluation. We experimentally evaluate the results of the proposed approaches outperforming the dice coefficient and the average perpendicular distance than other state-of-the-art approaches.

</details>


### [68] [AdaGaR: Adaptive Gabor Representation for Dynamic Scene Reconstruction](https://arxiv.org/abs/2601.00796)
*Jiewen Chan,Zhenjun Zhao,Yu-Lun Liu*

Main category: cs.CV

TL;DR: AdaGaR通过自适应Gabor表示和时间连续性约束，解决了动态3D场景重建中的高频细节捕捉和运动平滑问题，性能显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如单高斯基元）因低通滤波特性无法捕捉高频细节，标准Gabor函数存在能量不稳定问题，且缺乏时间连续性约束导致插值运动伪影。

Method: 提出自适应Gabor表示（Adaptive Gabor Representation），通过可学习频率权重和自适应能量补偿平衡细节与稳定性；采用三次Hermite样条和时间曲率正则化确保运动平滑；结合深度估计、点跟踪和前景掩模的自适应初始化机制。

Result: 在Tap-Vid DAVIS数据集上取得PSNR 35.49、SSIM 0.9433、LPIPS 0.0723的SOTA性能，并在帧插值、深度一致性、视频编辑和立体视图合成等任务中表现优异。

Conclusion: AdaGaR通过自适应Gabor表示和时间连续性约束，在动态3D场景重建中实现了高频细节捕捉和运动平滑，展示了在多个任务上的优越性能。

Abstract: Reconstructing dynamic 3D scenes from monocular videos requires simultaneously capturing high-frequency appearance details and temporally continuous motion. Existing methods using single Gaussian primitives are limited by their low-pass filtering nature, while standard Gabor functions introduce energy instability. Moreover, lack of temporal continuity constraints often leads to motion artifacts during interpolation. We propose AdaGaR, a unified framework addressing both frequency adaptivity and temporal continuity in explicit dynamic scene modeling. We introduce Adaptive Gabor Representation, extending Gaussians through learnable frequency weights and adaptive energy compensation to balance detail capture and stability. For temporal continuity, we employ Cubic Hermite Splines with Temporal Curvature Regularization to ensure smooth motion evolution. An Adaptive Initialization mechanism combining depth estimation, point tracking, and foreground masks establishes stable point cloud distributions in early training. Experiments on Tap-Vid DAVIS demonstrate state-of-the-art performance (PSNR 35.49, SSIM 0.9433, LPIPS 0.0723) and strong generalization across frame interpolation, depth consistency, video editing, and stereo view synthesis. Project page: https://jiewenchan.github.io/AdaGaR/

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [69] [Understanding Security Risks of AI Agents' Dependency Updates](https://arxiv.org/abs/2601.00205)
*Tanmay Singla,Berk Çakar,Paschal C. Amusuo,James C. Davis*

Main category: cs.SE

TL;DR: AI编码代理在依赖更新中比人类更频繁选择漏洞版本且修复更复杂，需加强安全措施。


<details>
  <summary>Details</summary>
Motivation: 探讨AI编码代理在修改软件依赖时是否引入独特的安全风险。

Method: 分析了七个生态系统中117,062个由AI和人类作者拉取请求中的依赖变更。

Result: AI代理选择已知漏洞版本的频率高于人类（2.46% vs. 1.64%），且其漏洞修复更复杂（36.8%需主版本升级 vs. 12.9%）。总体来看，AI驱动的依赖更新导致漏洞净增98，而人类则减少1,316。

Conclusion: 研究结果表明，AI编码代理在依赖更新中引入的安全风险高于人类，需要采取措施如拉取请求时的漏洞筛查和注册表感知的防护措施来提升安全性。

Abstract: Package dependencies are a critical control point in modern software supply chains. Dependency changes can substantially alter a project's security posture. As AI coding agents increasingly modify software via pull requests, it is unclear whether their dependency decisions introduce distinct security risks.
  We study 117,062 dependency changes from agent- and human-authored pull requests across seven ecosystems. Agents select known-vulnerable versions more often than humans (2.46% vs. 1.64%), and their vulnerable selections are more disruptive to remediate, with 36.8% requiring major-version upgrades compared to 12.9% for humans, despite patched alternatives existing in most cases. At the aggregate level, agent-driven dependency work yields a net vulnerability increase of 98, whereas human-authored work yields a net reduction of 1,316. These findings motivate pull-request-time vulnerability screening and registry-aware guardrails to make agent-driven dependency updates safer.

</details>


### [70] [Advanced Vulnerability Scanning for Open Source Software: Detection and Mitigation of Log4j Vulnerabilities](https://arxiv.org/abs/2601.00235)
*Victor Wen,Zedong Peng*

Main category: cs.SE

TL;DR: 该研究开发了一种高效的Log4j漏洞扫描工具，通过GitHub Actions实现自动化扫描，减少误报，并在测试中表现出高准确率。


<details>
  <summary>Details</summary>
Motivation: 当前Log4j漏洞检测工具主要关注识别安装版本，导致大量误报，因为它们未检查软件是否真正易受攻击。

Method: 该方法首先识别漏洞，然后提供针对性的缓解建议，并通过GitHub Actions实现自动化扫描。

Result: 在评估28个开源软件项目的不同版本时，该工具在140次扫描中达到了91.4%的准确率。

Conclusion: 该研究开发了一种先进的Log4j扫描工具，能够评估软件在现实世界中的可利用性，从而减少误报。通过GitHub Actions集成，该工具提供了自动化和持续扫描能力，确保及时识别漏洞。

Abstract: Automated detection of software vulnerabilities remains a critical challenge in software security. Log4j is an industrial-grade Java logging framework listed as one of the top 100 critical open source projects. On Dec. 10, 2021 a severe vulnerability Log4Shell was disclosed before being fully patched with Log4j2 version 2.17.0 on Dec. 18, 2021. However, to this day about 4.1 million, or 33 percent of all Log4j downloads in the last 7 days contain vulnerable packages. Many Log4Shell scanners have since been created to detect if a user's installed Log4j version is vulnerable. Current detection tools primarily focus on identifying the version of Log4j installed, leading to numerous false positives, as they do not check if the software scanned is really vulnerable to malicious actors. This research aims to develop an advanced Log4j scanning tool that can evaluate the real-world exploitability of the software, thereby reducing false positives. Our approach first identifies vulnerabilities and then provides targeted recommendations for mitigating these detected vulnerabilities, along with instant feedback to users. By leveraging GitHub Actions, our tool offers automated and continuous scanning capabilities, ensuring timely identification of vulnerabilities as code changes occur. This integration into existing development workflows enables real-time monitoring and quicker responses to potential threats. We demonstrate the effectiveness of our approach by evaluating 28 open-source software projects across different releases, achieving an accuracy rate of 91.4% from a sample of 140 scans. Our GitHub action implementation is available at the GitHub marketplace and can be accessed by anyone interested in improving their software security and for future studies. This tool provides a dependable way to detect and mitigate vulnerabilities in open-source projects.

</details>


### [71] [An Empirical Evaluation of LLM-Based Approaches for Code Vulnerability Detection: RAG, SFT, and Dual-Agent Systems](https://arxiv.org/abs/2601.00254)
*Md Hasan Saju,Maher Muhtadi,Akramul Azim*

Main category: cs.SE

TL;DR: LLM在漏洞检测中表现优异，RAG方法通过整合外部知识效果最佳，Dual-Agent框架则提升了透明度和效率。


<details>
  <summary>Details</summary>
Motivation: 随着LLM的快速发展，探索其在自动化软件漏洞检测中的潜力成为保障现代代码库安全的关键任务。

Method: 研究比较了三种LLM技术（RAG、SFT和Dual-Agent框架）与基线LLM模型的效果，使用来自Big-Vul和GitHub的真实代码数据集，聚焦五种关键CWE类别。

Result: RAG方法通过整合外部领域知识（如MITRE CWE数据库）实现了最高准确率（0.86）和F1分数（0.85）；SFT和Dual-Agent框架也表现出色，后者在提升推理透明度和错误缓解方面尤为突出。

Conclusion: 研究表明，结合领域专业知识机制（如RAG和Dual-Agent框架）能显著提升LLM在实际漏洞检测任务中的适用性，其中RAG方法表现最优。

Abstract: The rapid advancement of Large Language Models (LLMs) presents new opportunities for automated software vulnerability detection, a crucial task in securing modern codebases. This paper presents a comparative study on the effectiveness of LLM-based techniques for detecting software vulnerabilities. The study evaluates three approaches, Retrieval-Augmented Generation (RAG), Supervised Fine-Tuning (SFT), and a Dual-Agent LLM framework, against a baseline LLM model. A curated dataset was compiled from Big-Vul and real-world code repositories from GitHub, focusing on five critical Common Weakness Enumeration (CWE) categories: CWE-119, CWE-399, CWE-264, CWE-20, and CWE-200. Our RAG approach, which integrated external domain knowledge from the internet and the MITRE CWE database, achieved the highest overall accuracy (0.86) and F1 score (0.85), highlighting the value of contextual augmentation. Our SFT approach, implemented using parameter-efficient QLoRA adapters, also demonstrated strong performance. Our Dual-Agent system, an architecture in which a secondary agent audits and refines the output of the first, showed promise in improving reasoning transparency and error mitigation, with reduced resource overhead. These results emphasize that incorporating a domain expertise mechanism significantly strengthens the practical applicability of LLMs in real-world vulnerability detection tasks.

</details>


### [72] [In Line with Context: Repository-Level Code Generation via Context Inlining](https://arxiv.org/abs/2601.00376)
*Chao Hu,Wenhao Zeng,Yuling Shi,Beijun Shen,Xiaodong Gu*

Main category: cs.SE

TL;DR: InlineCoder是一种新型仓库级代码生成框架，通过双向内联（上游内联和下游检索）解决现有方法在依赖关系捕获上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如RAG或基于上下文的函数选择）主要依赖表面相似性，难以捕获仓库级语义的复杂依赖关系，因此需要一种更有效的方法。

Method: InlineCoder通过生成锚点（draft completion）并利用双向内联（上游内联和下游检索）来丰富上下文，从而将仓库级代码生成任务转化为更简单的函数级任务。

Result: InlineCoder通过双向内联过程显著提升了仓库级代码生成的性能，提供了更全面的仓库视图。

Conclusion: InlineCoder通过双向内联过程（上游内联和下游检索）有效提升了仓库级代码生成的性能，解决了现有方法在捕获复杂依赖关系上的不足。

Abstract: Repository-level code generation has attracted growing attention in recent years. Unlike function-level code generation, it requires the model to understand the entire repository, reasoning over complex dependencies across functions, classes, and modules. However, existing approaches such as retrieval-augmented generation (RAG) or context-based function selection often fall short: they primarily rely on surface-level similarity and struggle to capture the rich dependencies that govern repository-level semantics. In this paper, we introduce InlineCoder, a novel framework for repository-level code generation. InlineCoder enhances the understanding of repository context by inlining the unfinished function into its call graph, thereby reframing the challenging repository understanding as an easier function-level coding task. Given a function signature, InlineCoder first generates a draft completion, termed an anchor, which approximates downstream dependencies and enables perplexity-based confidence estimation. This anchor drives a bidirectional inlining process: (i) Upstream Inlining, which embeds the anchor into its callers to capture diverse usage scenarios; and (ii) Downstream Retrieval, which integrates the anchor's callees into the prompt to provide precise dependency context. The enriched context, combining draft completion with upstream and downstream perspectives, equips the LLM with a comprehensive repository view.

</details>


### [73] [On Plagiarism and Software Plagiarism](https://arxiv.org/abs/2601.00429)
*Rares Folea,Emil Slusanschi*

Main category: cs.SE

TL;DR: 该论文介绍了开源工具Project Martial，用于检测代码相似性，并分析了现有技术和法律案例以应对软件抄袭。


<details>
  <summary>Details</summary>
Motivation: 探索数字制品中软件相似性检测的独特挑战，并提供一个开源解决方案以应对软件抄袭问题。

Method: 研究通过分析学术界和法律案例，调查现有技术如指纹识别、软件出生标记和代码嵌入，并在Project Martial中应用部分技术。

Result: 论文提出了Project Martial，展示了如何利用现有技术在特定背景下有效检测代码相似性。

Conclusion: 该论文总结了软件相似性自动检测的复杂性，并介绍了开源解决方案Project Martial，为打击软件抄袭提供了新工具。

Abstract: This paper explores the complexities of automatic detection of software similarities, in relation to the unique challenges of digital artifacts, and introduces Project Martial, an open-source software solution for detecting code similarity. This research enumerates some of the existing approaches to counter software plagiarism by examining both the academia and legal landscape, including notable lawsuits and court rulings that have shaped the understanding of software copyright infringements in commercial applications. Furthermore, we categorize the classes of detection challenges based on the available artifacts, and we provide a survey of the previously studied techniques in the literature, including solutions based on fingerprinting, software birthmarks, or code embeddings, and exemplify how a subset of them can be applied in the context of Project Martial.

</details>


### [74] [DSL or Code? Evaluating the Quality of LLM-Generated Algebraic Specifications: A Case Study in Optimization at Kinaxis](https://arxiv.org/abs/2601.00469)
*Negin Ayoughi,David Dewar,Shiva Nejati,Mehrdad Sabetzadeh*

Main category: cs.SE

TL;DR: EXEOS通过LLM和求解器反馈生成并优化AMPL模型，在工业案例中表现优于或与Python相当。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在生成DSL（如AMPL）模型时准确性低于主流语言（如Python）的问题，推动MDE在工业领域的应用。

Method: 引入EXEOS，一种基于LLM的方法，从自然语言问题描述生成AMPL模型和Python代码，并通过求解器反馈迭代优化。

Result: 在公共优化数据集和工业案例中，生成的AMPL模型在可执行性和正确性上与Python代码竞争，有时更优。

Conclusion: EXEOS方法在AMPL模型生成上表现与Python相当甚至更优，且设计选择提升了生成规范的质量。

Abstract: Model-driven engineering (MDE) provides abstraction and analytical rigour, but industrial adoption in many domains has been limited by the cost of developing and maintaining models. Large language models (LLMs) can help shift this cost balance by supporting direct generation of models from natural-language (NL) descriptions. For domain-specific languages (DSLs), however, LLM-generated models may be less accurate than LLM-generated code in mainstream languages such as Python, due to the latter's dominance in LLM training corpora. We investigate this issue in mathematical optimization, with AMPL, a DSL with established industrial use. We introduce EXEOS, an LLM-based approach that derives AMPL models and Python code from NL problem descriptions and iteratively refines them with solver feedback. Using a public optimization dataset and real-world supply-chain cases from our industrial partner Kinaxis, we evaluate generated AMPL models against Python code in terms of executability and correctness. An ablation study with two LLM families shows that AMPL is competitive with, and sometimes better than, Python, and that our design choices in EXEOS improve the quality of generated specifications.

</details>


### [75] [Multi-Agent Coordinated Rename Refactoring](https://arxiv.org/abs/2601.00482)
*Abhiram Bellur,Mohammed Raihan Ullah,Fraol Batole,Mohit Kansara,Masaharu Morimoto,Kai Ishikawa,Haifeng Chen,Yaroslav Zharov,Timofey Bryksin,Tien N. Nguyen,Hridesh Rajan,Danny Dig*

Main category: cs.SE

TL;DR: 提出首个多智能体框架，自动化协调重命名任务，减少开发者负担并保持控制权。


<details>
  <summary>Details</summary>
Motivation: 协调重命名是一项频繁但繁琐且易错的任务，现有启发式方法产生过多误报，而普通大语言模型因上下文有限无法提供完整建议。

Method: 设计并实现了一个多智能体框架，包括范围推断代理、计划执行代理和复制代理，通过自然语言声明范围和调用IDE的API来安全执行重命名。

Result: 通过609K次提交和205名开发者的调查验证，该框架能显著减少开发者的负担。

Conclusion: AI agents can effectively辅助开发者完成协调重命名任务，减少错误并提高效率，同时保持开发者对过程的控制。

Abstract: The primary value of AI agents in software development lies in their ability to extend the developer's capacity for reasoning and action, not to supplant human involvement. To showcase how to use agents working in tandem with developers, we designed a novel approach for carrying out coordinated renaming. Coordinated renaming, where a single rename refactoring triggers refactorings in multiple, related identifiers, is a frequent yet challenging task. Developers must manually propagate these rename refactorings across numerous files and contexts, a process that is both tedious and highly error-prone. State-of-the-art heuristic-based approaches produce an overwhelming number of false positives, while vanilla Large Language Models (LLMs) provide incomplete suggestions due to their limited context and inability to interact with refactoring tools. This leaves developers with incomplete refactorings or burdens them with filtering too many false positives. Coordinated renaming is exactly the kind of repetitive task that agents can significantly reduce the developers' burden while keeping them in the driver's seat.
  We designed, implemented, and evaluated the first multi-agent framework that automates coordinated renaming. It operates on a key insight: a developer's initial refactoring is a clue to infer the scope of related refactorings. Our Scope Inference Agent first transforms this clue into an explicit, natural-language Declared Scope. The Planned Execution Agent then uses this as a strict plan to identify program elements that should undergo refactoring and safely executes the changes by invoking the IDE's own trusted refactoring APIs. Finally, the Replication Agent uses it to guide the project-wide search. We first conducted a formative study on the practice of coordinated renaming in 609K commits in 100 open-source projects and surveyed 205 developers ...

</details>


### [76] [STELLAR: A Search-Based Testing Framework for Large Language Model Applications](https://arxiv.org/abs/2601.00497)
*Lev Sorokin,Ivan Vasilev,Ken E. Friedl,Andrea Stocco*

Main category: cs.SE

TL;DR: STELLAR是一个自动化搜索测试框架，通过进化优化高效发现LLM应用中的不当响应，效果显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决LLM应用因高维输入空间和复杂行为导致的系统测试挑战。

Method: 将测试生成建模为优化问题，通过进化优化动态探索特征组合，以更有效地暴露系统失败。

Result: 在三个LLM对话问答系统上评估，STELLAR平均比基线方法多发现2.5倍失败案例，最高达4.3倍。

Conclusion: STELLAR框架显著提升了发现LLM应用中不当响应的能力，相比现有基线方法，平均多发现2.5倍的失败案例。

Abstract: Large Language Model (LLM)-based applications are increasingly deployed across various domains, including customer service, education, and mobility. However, these systems are prone to inaccurate, fictitious, or harmful responses, and their vast, high-dimensional input space makes systematic testing particularly challenging. To address this, we present STELLAR, an automated search-based testing framework for LLM-based applications that systematically uncovers text inputs leading to inappropriate system responses. Our framework models test generation as an optimization problem and discretizes the input space into stylistic, content-related, and perturbation features. Unlike prior work that focuses on prompt optimization or coverage heuristics, our work employs evolutionary optimization to dynamically explore feature combinations that are more likely to expose failures. We evaluate STELLAR on three LLM-based conversational question-answering systems. The first focuses on safety, benchmarking both public and proprietary LLMs against malicious or unsafe prompts. The second and third target navigation, using an open-source and an industrial retrieval-augmented system for in-vehicle venue recommendations. Overall, STELLAR exposes up to 4.3 times (average 2.5 times) more failures than the existing baseline approaches.

</details>


### [77] [SEMODS: A Validated Dataset of Open-Source Software Engineering Models](https://arxiv.org/abs/2601.00635)
*Alexandra González,Xavier Franch,Silverio Martínez-Fernández*

Main category: cs.SE

TL;DR: SEMODS是一个从Hugging Face提取的3,427个软件工程模型数据集，填补了专用目录的空白，支持多种应用。


<details>
  <summary>Details</summary>
Motivation: 由于Hugging Face上模型数量庞大且持续增长，缺乏专门的目录难以识别适用于软件工程的模型。

Method: 通过自动化收集结合手动标注和大语言模型辅助的严格验证，从Hugging Face提取了3,427个模型。

Result: SEMODS数据集成功链接了模型与软件开发生命周期中的任务和活动，并提供了评估结果的标准化表示。

Conclusion: SEMODS提供了一个专门针对软件工程的模型数据集，填补了现有资源库的空白，支持多种应用如数据分析、模型发现和基准测试。

Abstract: Integrating Artificial Intelligence into Software Engineering (SE) requires having a curated collection of models suited to SE tasks. With millions of models hosted on Hugging Face (HF) and new ones continuously being created, it is infeasible to identify SE models without a dedicated catalogue. To address this gap, we present SEMODS: an SE-focused dataset of 3,427 models extracted from HF, combining automated collection with rigorous validation through manual annotation and large language model assistance. Our dataset links models to SE tasks and activities from the software development lifecycle, offering a standardized representation of their evaluation results, and supporting multiple applications such as data analysis, model discovery, benchmarking, and model adaptation.

</details>


### [78] [Early-Stage Prediction of Review Effort in AI-Generated Pull Requests](https://arxiv.org/abs/2601.00753)
*Dao Sy Duy Minh,Huynh Trung Kiet,Tran Chi Nguyen,Nguyen Lam Phu Quy,Phu Hoa Pham,Nguyen Dinh Ha Duong,Truong Bao Tran*

Main category: cs.SE

TL;DR: 研究揭示AI生成PR的两种行为模式，提出基于静态特征的预测模型，有效减少审查负担，挑战了现有AI辅助审查的假设。


<details>
  <summary>Details</summary>
Motivation: 随着AI代理从代码补全工具发展为能大规模提交PR的团队成员，软件维护者面临新挑战：如何预测哪些AI生成的PR会消耗过多审查资源。

Method: 通过分析AIDev数据集中33,707个AI生成的PR，提出了Circuit Breaker分类模型，利用静态结构特征预测高审查成本的PR。LightGBM模型在时间分割上达到AUC 0.957。

Result: 发现AI代理PR行为呈现两种模式：28.3%为即时合并（<1分钟），其余为迭代审查周期（常停滞或放弃）。模型在20%审查预算下拦截69%总审查工作量。

Conclusion: 研究发现挑战了AI辅助代码审查的普遍假设：审查负担由AI代理修改的内容而非其表述决定，强调了在人类与AI协作中需要结构性治理机制。

Abstract: As autonomous AI agents transition from code completion tools to full-fledged teammates capable of opening pull requests (PRs) at scale, software maintainers face a new challenge: not just reviewing code, but managing complex interaction loops with non-human contributors. This paradigm shift raises a critical question: can we predict which agent-generated PRs will consume excessive review effort before any human interaction begins?
  Analyzing 33,707 agent-authored PRs from the AIDev dataset across 2,807 repositories, we uncover a striking two-regime behavioral pattern that fundamentally distinguishes autonomous agents from human developers. The first regime, representing 28.3 percent of all PRs, consists of instant merges (less than 1 minute), reflecting success on narrow automation tasks. The second regime involves iterative review cycles where agents frequently stall or abandon refinement (ghosting).
  We propose a Circuit Breaker triage model that predicts high-review-effort PRs (top 20 percent) at creation time using only static structural features. A LightGBM model achieves AUC 0.957 on a temporal split, while semantic text features (TF-IDF, CodeBERT) provide negligible predictive value. At a 20 percent review budget, the model intercepts 69 percent of total review effort, enabling zero-latency governance.
  Our findings challenge prevailing assumptions in AI-assisted code review: review burden is dictated by what agents touch, not what they say, highlighting the need for structural governance mechanisms in human-AI collaboration.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [79] [Delay-Tolerant Networking for Tsunami Evacuation on the Small Island of Hachijojima: A Study of Epidemic and Prophet Routing](https://arxiv.org/abs/2601.00109)
*Keiya Kawano,Milena Radenkovic*

Main category: cs.NI

TL;DR: 论文研究了在海啸疏散中利用移动设备构建DTN的可行性，评估了两种路由方案在八丈岛案例中的性能。


<details>
  <summary>Details</summary>
Motivation: 海啸灾害对沿海和岛屿社区构成严重威胁，传统通信渠道在地震中可能失效，移动设备成为疏散时唯一可用的通信工具。研究旨在探索利用这些设备构建DTN的可行性。

Method: 研究在日本的八丈岛海啸疏散案例中，评估了两种DTN路由方案的多标准性能特征。

Result: 研究展示了两种DTN路由方案在海啸疏散场景中的性能表现，为应急通信提供了潜在解决方案。

Conclusion: 论文探讨了在通信基础设施受损的海啸疏散场景下，利用移动设备构建的延迟容忍网络（DTN）的有效性。通过评估两种DTN路由方案在多标准性能特征上的表现，研究为类似情境下的应急通信提供了实用见解。

Abstract: Tsunami disasters pose a serious and recurring threat to coastal and island communities. When a large earthquake occurs, people are forced to make evacuation decisions under extreme time pressure, often at the same time as the communication infrastructure is damaged or completely lost. In such circumstances, the familiar channels for sharing information - cellular networks, the internet, and even landlines - can no longer be relied upon. What typically remains are the mobile devices that evacuees carry with them. These devices can form Delay Tolerant Networks (DTNs), in which messages are forwarded opportunistically whenever people come into contact. To explore this, we evaluate multi-criteria performance characteristics of two DTN routing schemes in a pre-tsunami evacuation scenario for the island of Hachijojima, Japan use case.

</details>


### [80] [CTMap: LLM-Enabled Connectivity-Aware Path Planning in Millimeter-Wave Digital Twin Networks](https://arxiv.org/abs/2601.00110)
*Md Salik Parwez,Sai Teja Srivillibhutturu,Sai Venkat Reddy Kopparthi,Asfiya Misba,Debashri Roy,Habeeb Olufowobi,Charles Kim*

Main category: cs.NI

TL;DR: CTMAP是一个基于大型语言模型的数字孪生框架，用于毫米波网络中连接感知的路径导航，通过模拟和优化信号强度，显著提升了导航性能。


<details>
  <summary>Details</summary>
Motivation: 传统导航工具仅优化距离、时间或成本，忽视了密集城市环境中信号阻塞导致的网络连接性能下降问题。

Method: 利用OpenStreetMap、Blender和NVIDIA Sionna的光线追踪引擎构建毫米波网络的数字孪生，模拟真实接收信号强度（RSS）地图；通过改进的Dijkstra算法生成最大化累积RSS的最优路径，并以此作为指令调优GPT-4推理的训练数据。

Result: 实验结果表明，CTMAP在累积信号强度上比最短距离基线提高了十倍，同时保持高路径有效性。

Conclusion: CTMAP结合数字孪生模拟和大型语言模型推理，为智能、可解释且连接驱动的导航奠定了可扩展的基础，推动了AI赋能的6G移动系统设计。

Abstract: In this paper, we present \textit{CTMAP}, a large language model (LLM) empowered digital twin framework for connectivity-aware route navigation in millimeter-wave (mmWave) wireless networks. Conventional navigation tools optimize only distance, time, or cost, overlooking network connectivity degradation caused by signal blockage in dense urban environments. The proposed framework constructs a digital twin of the physical mmWave network using OpenStreetMap, Blender, and NVIDIA Sionna's ray-tracing engine to simulate realistic received signal strength (RSS) maps. A modified Dijkstra algorithm then generates optimal routes that maximize cumulative RSS, forming the training data for instruction-tuned GPT-4-based reasoning. This integration enables semantic route queries such as ``find the strongest-signal path'' and returns connectivity-optimized paths that are interpretable by users and adaptable to real-time environmental updates. Experimental results demonstrate that CTMAP achieves up to a tenfold improvement in cumulative signal strength compared to shortest-distance baselines, while maintaining high path validity. The synergy of digital twin simulation and LLM reasoning establishes a scalable foundation for intelligent, interpretable, and connectivity-driven navigation, advancing the design of AI-empowered 6G mobility systems.

</details>


### [81] [A-FC: An Activity-Based Delay Tolerant Routing Protocol for Improving Future School Campus Emergency Communications](https://arxiv.org/abs/2601.00148)
*Chengjun Jiang,Milena Radenkovic*

Main category: cs.NI

TL;DR: A-FC协议利用社会角色优化校园应急通信，显著提升传递概率并降低延迟。


<details>
  <summary>Details</summary>
Motivation: 校园应急通信系统在学生安全保护中至关重要，尤其是在台风等灾害导致通信基础设施瘫痪时。传统DTN协议因高延迟和低传递率在此类场景中表现不佳。

Method: 本文提出了基于活动性的首次接触（A-FC）协议，利用现实世界中的社会角色，通过强制将消息上传到高活跃度的“员工节点”来克服网络分区问题。

Result: 仿真结果表明，A-FC协议显著优于基线协议，消息传递概率约为68%，平均延迟降至4311秒，平均跳数仅为1.68。

Conclusion: A-FC协议为校园灾害响应提供了一种低成本、高可靠性的备用通信模型，显著提高了消息传递概率并降低了平均延迟。

Abstract: School Campus emergency communication systems are vital for safeguarding student safety during sudden disasters such as typhoons, which frequently cause widespread paralysis of communication infrastructure. Traditional Delay-Tolerant Network (DTN) protocols, such as Direct Delivery and First Contact, struggle to maintain reliable connections in such scenarios due to high latency and low delivery rates. This paper proposes the Activity-based First Contact (A-FC) protocol, an innovative routing scheme that leverages real-world social roles to overcome network partitioning by mandatorily uploading messages to highly active "staff nodes". We constructed a real-world evaluation scenario based on the topology of Fuzhou No. 1 Middle School. Simulation results demonstrate that the A-FC protocol significantly outperforms baseline protocols, achieving approximately 68% message delivery probability and reducing average delay to 4311 seconds. With an average hop count of merely 1.68, this protocol establishes a low-cost, highly reliable backup communication model for school campus disaster response.

</details>


### [82] [Multi-Satellite NOMA-Irregular Repetition Slotted ALOHA for IoT Networks](https://arxiv.org/abs/2601.00341)
*Estefanía Recayte,Carla Amatetti*

Main category: cs.NI

TL;DR: 研究多接收器对NOMA-IRSA协议下IoT节点性能的影响，发现增加一个额外卫星接收器可显著提升系统性能。


<details>
  <summary>Details</summary>
Motivation: 随着5G向6G过渡，IoT设备激增，需整合非地面网络（NTN）满足高容量需求。卫星覆盖广导致用户密度高，增加碰撞概率；而巨型星座部署使地面用户可同时接收多卫星信号，实现接收分集。

Method: 评估多接收器在IoT节点共享信道（遵循NOMA-IRSA协议）场景下的影响，考虑卫星信道损伤，推导系统性能下限。

Result: 识别网络设计参数（如丢包率和能效）的权衡，并推导系统性能下限作为快速评估工具。

Conclusion: 在仅增加一个额外卫星作为接收器的情况下，系统性能显著提升。

Abstract: As the transition from 5G to 6G unfolds, a substantial increase in Internet of Things (IoT) devices is expected, enabling seamless and pervasive connectivity across various applications. Accommodating this surge and meeting the high capacity demands will necessitate the integration of NonTerrestrial Networks (NTNs). However, the extensive coverage area of satellites, relative to terrestrial receivers, will lead to a high density of users attempting to access the channel at the same time, increasing the collision probability. In turn, the deployment of mega constellations make it possible for ground users to be in visibility of more than one satellite at the same time, enabling receiver diversity. Therefore, in this paper, we evaluate the impact of multi-receivers in scenarios where IoT nodes share the channel following a non-orthogonal multiple access (NOMA)irregular repetition slotted ALOHA (IRSA) protocol. Considering the impairments of satellite channels, we derive a lower bound of system performance, serving as a fast tool for initial evaluation of network behavior. Additionally, we identify the trade-offs inherent to the network design parameters, with a focus on packet loss rate and energy efficiency. Notably, in the visibility of only one extra satellite as receiver yields significant gains in overall system performance.

</details>


### [83] [MAESTRO: Multi-Agent Evaluation Suite for Testing, Reliability, and Observability](https://arxiv.org/abs/2601.00481)
*Tie Ma,Yixi Chen,Vaastav Anand,Alessandro Cornacchia,Amândio R. Faustino,Guanheng Liu,Shan Zhang,Hongbin Luo,Suhaib A. Fahmy,Zafar A. Qazi,Marco Canini*

Main category: cs.NI

TL;DR: MAESTRO是一个用于评估LLM-based MAS的标准化工具，通过实验揭示MAS架构对系统性能的关键影响，为设计优化提供指导。


<details>
  <summary>Details</summary>
Motivation: 为测试、可靠性和可观测性评估LLM-based MAS，MAESTRO旨在标准化评估流程并提供实证数据，以指导智能体系统的设计与优化。

Method: MAESTRO通过统一接口标准化MAS配置与执行，支持原生及第三方MAS集成，并导出框架无关的执行追踪与系统级信号。研究实例化了12种代表性MAS，并进行了重复运行、后端模型及工具配置的对照实验。

Result: 案例研究表明，MAS执行在结构上稳定但时间上可变，导致性能和可靠性的显著运行间差异。MAS架构是资源分布、可重现性及成本-延迟-准确性权衡的主要驱动因素。

Conclusion: MAESTRO通过系统化评估为设计和优化智能体系统提供了实证指导，揭示了MAS架构在资源分布、可重现性及成本-延迟-准确性权衡中的主导作用。

Abstract: We present MAESTRO, an evaluation suite for the testing, reliability, and observability of LLM-based MAS. MAESTRO standardizes MAS configuration and execution through a unified interface, supports integrating both native and third-party MAS via a repository of examples and lightweight adapters, and exports framework-agnostic execution traces together with system-level signals (e.g., latency, cost, and failures). We instantiate MAESTRO with 12 representative MAS spanning popular agentic frameworks and interaction patterns, and conduct controlled experiments across repeated runs, backend models, and tool configurations. Our case studies show that MAS executions can be structurally stable yet temporally variable, leading to substantial run-to-run variance in performance and reliability. We further find that MAS architecture is the dominant driver of resource profiles, reproducibility, and cost-latency-accuracy trade-off, often outweighing changes in backend models or tool settings. Overall, MAESTRO enables systematic evaluation and provides empirical guidance for designing and optimizing agentic systems.

</details>


### [84] [Scheduling for TWDM-EPON-Based Fronthaul Without a Dedicated Registration Wavelength](https://arxiv.org/abs/2601.00661)
*Akash Kumar,Sourav Dutta,Goutam Das*

Main category: cs.NI

TL;DR: 本文提出了一种TWDM EPON的新型调度框架，通过周期性注册提高带宽利用率，支持更多RUs，相比基线方案提升71%。


<details>
  <summary>Details</summary>
Motivation: 集中式无线接入网络（C-RAN）架构需要满足严格延迟和抖动要求的前传系统。EPON因其成本效益和与现有基础设施的兼容性成为有前景的解决方案，但传统注册过程会中断数据传输，违反eCPRI要求。ITU-T建议使用专用波长通道进行注册，但这导致带宽利用率低下。

Method: 提出了一种时间与波长分割复用（TWDM）EPON的新型调度框架，支持周期性注册，避免了传统注册过程中数据传输中断的问题。

Result: 性能评估显示，相比使用专用注册波长的基线方案，所提方法在给定波长通道数量下支持的RUs数量增加了71%。

Conclusion: 本文提出的基于TWDM EPON的新型调度框架，通过周期性注册而不浪费额外波长通道，显著提高了支持的无线单元（RUs）数量，相比基线方案提升了71%。

Abstract: The adoption of Centralized Radio Access Network (C-RAN) architectures requires fronthaul systems capable of carrying large volumes of radio data while meeting stringent delay and jitter requirements. Ethernet Passive Optical Networks (EPONs) have emerged as a promising fronthaul solution due to their cost efficiency and compatibility with existing infrastructure. However, the traditional registration process for EPON systems halts the ongoing data transmissions during the registration period, thereby violating the enhanced Common Public Radio Interface (eCPRI) delay and jitter requirements. This limitation has been acknowledged by the ITU-T, which recommends the use of a dedicated wavelength channel for registration, leading to inefficient bandwidth utilization. In this paper, we propose a novel scheduling framework for a Time and Wavelength Division Multiplexed (TWDM) EPON-based fronthaul that enables periodic registration without wasting an additional wavelength channel. Performance evaluation demonstrates that the proposed method achieves up to a 71\% increase in the number of Radio Units (RUs) supported for a given number of wavelength channels, compared to a baseline scheme employing a dedicated registration wavelength.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [85] [DiffTetVR: Differentiable Tetrahedral Volume Rendering](https://arxiv.org/abs/2601.00114)
*Christoph Neuhauser*

Main category: cs.GR

TL;DR: DiffTetVR是一种可微分四面体网格渲染方法，支持顶点优化和局部细分，无需多网格方法，代码已开源。


<details>
  <summary>Details</summary>
Motivation: 现有方法多基于规则网格，限制了顶点位置优化和局部细分的灵活性。DiffTetVR旨在克服这一限制，提供更灵活的优化能力。

Method: 文章介绍了前向渲染过程的高效实现，推导了反向传播的导数以及避免退化四面体的正则化项，并展示了如何局部细分四面体网格以实现从粗到细的优化过程。

Result: DiffTetVR实现了高效的四面体网格渲染和优化，支持局部细分，代码已在GitHub开源。

Conclusion: DiffTetVR提出了一种基于四面体网格的可微分体积渲染解决方案，支持顶点位置优化和局部细分，无需依赖多网格方法。

Abstract: Differentiable rendering is a technique that aims to invert the rendering process to enable optimizing rendering parameters from a set of images. In this article, we present a differentiable volume rendering solution called DiffTetVR for tetrahedral meshes. Unlike previous works based on regular grids, this enables the optimization of vertex positions and the local subdivision of the mesh without relying on multigrid methods. We present an efficient implementation of the forward rendering process, deduce the derivatives for the backwards pass and regularization terms for avoiding degenerate tetrahedra, and finally show how the tetrahedral mesh can be subdivided locally to enable a coarse-to-fine optimization process. The source code is made publicly available on GitHub at https://github.com/chrismile/DiffTetVR.

</details>


### [86] [Modeling and Simulating Origami Structures using Bilinear Solid-Shell Element](https://arxiv.org/abs/2601.00569)
*Qixin Liang*

Main category: cs.GR

TL;DR: 本文提出了一种基于固体壳单元和假设自然应变方法的折纸结构计算框架，有效解决了锁定问题，并通过仿真验证了其准确性。


<details>
  <summary>Details</summary>
Motivation: 提出一种新的计算框架，用于建模和仿真折纸结构，解决现有方法在模拟折纸结构时的局限性。

Method: 采用双线性固体壳单元建模折纸面板，并通过相邻面板间法向矢量的角度考虑折痕折叠。引入假设自然应变方法以缓解固体壳单元的锁定问题。

Result: 通过包含直折痕和曲折痕的折纸仿真验证了框架的有效性。

Conclusion: 该框架通过定量和定性分析验证了其准确性和有效性，为折纸结构的建模和仿真提供了一种新方法。

Abstract: We propose a novel computational framework for modeling and simulating origami structures. In this framework, bilinear solid-shell elements are employed to model the origami panels while crease folding is considered through the angle between the director vectors of the adjacent panels. The director vector is the vector normal to the mid-surface before displacement/deformation comes in. To mitigate locking issues in the solid-shell element, we introduce the assumed natural strain method. To validate the effectiveness of our framework, we conduct origami simulations involving both straight- and curved-creases. The accuracy and efficacy of the framework are demonstrated through quantitative and qualitative analyses.

</details>


### [87] [Spatiotemporal Detection and Uncertainty Visualization of Atmospheric Blocking Events](https://arxiv.org/abs/2601.00775)
*Mingzhe Li,Peer Nowack,Bei Wang*

Main category: cs.GR

TL;DR: 本文提出了一个不确定性可视化框架，用于检测和表征大气阻塞事件，结合几何方法和多种可视化工具，支持气候研究和风险评估。


<details>
  <summary>Details</summary>
Motivation: 准确建模和分析长期气象记录中的阻塞事件是一个重大挑战，这些事件对中纬度天气有重要影响。

Method: 提出了一种基于几何的检测和跟踪方法，并结合不确定性感知摘要（如轮廓箱线图、频率热图和3D时间堆叠）来检测和表征大气阻塞事件。

Result: 通过案例研究（2003年欧洲热浪）展示了框架的有效性，揭示了阻塞事件最可能发生的区域及其时空演变。

Conclusion: 该框架为气候科学家和气象学家提供了一个有价值的工具，支持历史阻塞事件的研究以及与阻塞相关的极端天气变化的气候风险评估。

Abstract: Atmospheric blocking events are quasi-stationary high-pressure systems that disrupt the typical paths of polar and subtropical air currents, often producing prolonged extreme weather events such as summer heat waves or winter cold spells. Despite their critical role in shaping mid-latitude weather, accurately modeling and analyzing blocking events in long meteorological records remains a significant challenge. To address this challenge, we present an uncertainty visualization framework for detecting and characterizing atmospheric blocking events. First, we introduce a geometry-based detection and tracking method, evaluated on both pre-industrial climate model simulations (UKESM) and reanalysis data (ERA5), which represent historical Earth observations assimilated from satellite and station measurements onto regular numerical grids using weather models. Second, we propose a suite of uncertainty-aware summaries: contour boxplots that capture representative boundaries and their variability, frequency heatmaps that encode occurrences, and 3D temporal stacks that situate these patterns in time. Third, we demonstrate our framework in a case study of the 2003 European heatwave, mapping the spatiotemporal occurrences of blocking events using these summaries. Collectively, these uncertainty visualizations reveal where blocking events are most likely to occur and how their spatial footprints evolve over time. We envision our framework as a valuable tool for climate scientists and meteorologists: by analyzing how blocking frequency, duration, and intensity vary across regions and climate scenarios, it supports both the study of historical blocking events and the assessment of scenario-dependent climate risks associated with changes in extreme weather linked to blocking.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [88] [Word Frequency Counting Based on Serverless MapReduce](https://arxiv.org/abs/2601.00380)
*Hanzhe Li,Bingchen Lin,Mengyuan Xu*

Main category: cs.DC

TL;DR: 结合无服务器计算与MapReduce模型，优化函数数量以提升词频统计任务的效率。


<details>
  <summary>Details</summary>
Motivation: 结合无服务器计算的Function as a Service框架和MapReduce模型的高并发与鲁棒性，旨在提升词频统计任务的效率。

Method: 基于无服务器计算平台，采用MapReduce编程模型，通过实验确定最优的Map和Reduce函数数量。

Result: 实验表明，随着Map和Reduce函数数量的增加，执行时间减少且效率提升，但提升速率不同。

Conclusion: 本文发现通过优化Map和Reduce函数的数量，可以显著提高任务执行效率和减少时间开销，为企业及程序员提供了优化解决方案的参考。

Abstract: With the increasing demand for high-performance and high-efficiency computing, cloud computing, especially serverless computing, has gradually become a research hotspot in recent years, attracting numerous research attention. Meanwhile, MapReduce, which is a popular big data processing model in the industry, has been widely applied in various fields. Inspired by the serverless framework of Function as a Service and the high concurrency and robustness of MapReduce programming model, this paper focus on combining them to reduce the time span and increase the efficiency when executing the word frequency counting task. In this case, the paper use a MapReduce programming model based on a serverless computing platform to figure out the most optimized number of Map functions and Reduce functions for a particular task. For the same amount of workload, extensive experiments show both execution time reduces and the overall efficiency of the program improves at different rates as the number of map functions and reduce functions increases. This paper suppose the discovery of the most optimized number of map and reduce functions can help cooperations and programmers figure out the most optimized solutions.

</details>


### [89] [Revati: Transparent GPU-Free Time-Warp Emulation for LLM Serving](https://arxiv.org/abs/2601.00397)
*Amey Agrawal,Mayank Yadav,Sukrit Kumar,Anirudha Agrawal,Garv Ghai,Souradeep Bera,Elton Pinto,Sirish Gambhira,Mohammad Adain,Kasra Sohrab,Chus Antonanzas,Alexey Tumanov*

Main category: cs.DC

TL;DR: Revati是一种高效模拟器，通过虚拟化GPU管理和时间跳跃技术，快速准确地预测LLM服务性能，显著降低测试成本和时间。


<details>
  <summary>Details</summary>
Motivation: 部署LLMs时测试数百种服务配置耗时耗资巨大，现有离散事件模拟器虽快但需重新实现控制逻辑，随着框架演进负担加重。

Method: Revati通过拦截CUDA API调用来虚拟化设备管理，使服务框架无需物理GPU即可运行。系统执行时间跳跃而非GPU内核，快速推进虚拟时间。提出了一种协调协议，确保分布式进程间的时间跳跃同步并保持因果关系。

Result: 在vLLM和SGLang上，Revati实现了多种模型和并行配置下小于5%的预测误差，同时运行速度比真实GPU执行快5-17倍。

Conclusion: Revati是一种时间扭曲模拟器，通过直接执行真实服务系统代码以模拟速度进行性能建模，显著提高了部署LLMs的效率。

Abstract: Deploying LLMs efficiently requires testing hundreds of serving configurations, but evaluating each one on a GPU cluster takes hours and costs thousands of dollars. Discrete-event simulators are faster and cheaper, but they require re-implementing the serving system's control logic -- a burden that compounds as frameworks evolve.
  We present Revati, a time-warp emulator that enables performance modeling by directly executing real serving system code at simulation-like speed. The system intercepts CUDA API calls to virtualize device management, allowing serving frameworks to run without physical GPUs. Instead of executing GPU kernels, it performs time jumps -- fast-forwarding virtual time by predicted kernel durations. We propose a coordination protocol that synchronizes these jumps across distributed processes while preserving causality. On vLLM and SGLang, Revati achieves less than 5% prediction error across multiple models and parallelism configurations, while running 5-17x faster than real GPU execution.

</details>


### [90] [Cost-Performance Analysis of Cloud-Based Retail Point-of-Sale Systems: A Comparative Study of Google Cloud Platform and Microsoft Azure](https://arxiv.org/abs/2601.00530)
*Ravi Teja Pagidoju*

Main category: cs.DC

TL;DR: 本文通过开源代码比较了GCP和Azure在POS工作负载上的性能，发现GCP响应更快，Azure成本效率更高，为零售商提供了云POS实施的实用框架。


<details>
  <summary>Details</summary>
Motivation: 零售行业的数字化转型加速了基于云的POS系统的采用，但缺乏针对零售工作负载的平台特定性能的实证研究。

Method: 使用实时API端点和开源基准测试代码，对GCP和Microsoft Azure上的POS工作负载部署进行了系统化、可重复的比较。采用免费层云资源，提供透明的POS工作负载评估方法。

Result: 分析显示，GCP在基线负载下实现了23.0%更快的响应时间，而Azure在稳态操作中显示出71.9%更高的成本效率。

Conclusion: 本研究为零售云应用建立了一个强大、开放的基准测试方法，并首次提供了跨领先云平台的POS系统特有工作负载的全面、代码驱动的比较。

Abstract: Althoughthereislittleempiricalresearchonplatform-specific performance for retail workloads, the digital transformation of the retail industry has accelerated the adoption of cloud-based Point-of-Sale (POS) systems. This paper presents a systematic, repeatable comparison of POS workload deployments on Google Cloud Platform (GCP) and Microsoft Azure using real-time API endpoints and open-source benchmarking code. Using free-tier cloud resources, we offer a transparent methodology for POS workload evaluation that small retailers and researchers can use. Our approach measures important performance metrics like response latency, throughput, and scalability while estimating operational costs based on actual resource usage and current public cloud pricing because there is no direct billing under free-tier usage. All the tables and figures in this study are generated directly from code outputs, ensuring that the experimental data and the reported results are consistent. Our analysis shows that GCP achieves 23.0% faster response times at baseline load, while Azure shows 71.9% higher cost efficiency for steady-state operations. We look at the architectural components that lead to these differences and provide a helpful framework for merchants considering cloud point-of-sale implementation. This study establishes a strong, open benchmarking methodology for retail cloud applications and offers the first comprehensive, code-driven comparison of workloads unique to point-of-sale systems across leading cloud platforms.

</details>


### [91] [FlexSpec: Frozen Drafts Meet Evolving Targets in Edge-Cloud Collaborative LLM Speculative Decoding](https://arxiv.org/abs/2601.00644)
*Yuchen Li,Rui Kong,Zhonghao Lyu,Qiyang Li,Xinran Chen,Hengyi Cai,Lingyong Yan,Shuaiqiang Wang,Jiashu Zhao,Guangxu Zhu,Linghe Kong,Guihai Chen,Haoyi Xiong,Dawei Yin*

Main category: cs.DC

TL;DR: FlexSpec是一种高效的边缘-云协作推理框架，通过共享骨干架构和自适应推测机制减少通信开销，提升推理效率。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在移动和边缘计算环境中部署受限于资源、带宽和模型频繁更新，现有推测解码框架因模型紧密耦合导致通信开销大、延迟高。

Method: 提出FlexSpec框架，采用共享骨干架构使边缘侧轻量级草案模型与云端目标模型家族兼容，并开发信道感知自适应推测机制动态调整推测草案长度。

Result: 实验证明FlexSpec在推理效率上优于传统推测解码方法。

Conclusion: FlexSpec通过共享骨干架构和信道感知自适应推测机制，显著提升了边缘-云协作推理的效率，减少了通信和维护成本。

Abstract: Deploying large language models (LLMs) in mobile and edge computing environments is constrained by limited on-device resources, scarce wireless bandwidth, and frequent model evolution. Although edge-cloud collaborative inference with speculative decoding (SD) can reduce end-to-end latency by executing a lightweight draft model at the edge and verifying it with a cloud-side target model, existing frameworks fundamentally rely on tight coupling between the two models. Consequently, repeated model synchronization introduces excessive communication overhead, increasing end-to-end latency, and ultimately limiting the scalability of SD in edge environments. To address these limitations, we propose FlexSpec, a communication-efficient collaborative inference framework tailored for evolving edge-cloud systems. The core design of FlexSpec is a shared-backbone architecture that allows a single and static edge-side draft model to remain compatible with a large family of evolving cloud-side target models. By decoupling edge deployment from cloud-side model updates, FlexSpec eliminates the need for edge-side retraining or repeated model downloads, substantially reducing communication and maintenance costs. Furthermore, to accommodate time-varying wireless conditions and heterogeneous device constraints, we develop a channel-aware adaptive speculation mechanism that dynamically adjusts the speculative draft length based on real-time channel state information and device energy budgets. Extensive experiments demonstrate that FlexSpec achieves superior performance compared to conventional SD approaches in terms of inference efficiency.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [92] [Reinforcement learning with timed constraints for robotics motion planning](https://arxiv.org/abs/2601.00087)
*Zhaoan Wang,Junchao Li,Mahdi Mohammad,Shaoping Xiao*

Main category: cs.RO

TL;DR: 该论文提出了一种基于自动机的强化学习框架，用于在MITL规范下合成MDP和POMDP的策略，通过仿真验证其在时间关键和不确定环境中的有效性。


<details>
  <summary>Details</summary>
Motivation: 动态和不确定环境中的机器人系统需要满足复杂任务序列和严格时间约束的规划器，而MITL与强化学习的结合因随机动态和部分可观测性而具有挑战性。

Method: 提出了一种基于自动机的统一强化学习框架，将MITL公式转换为Timed-LDGBA，并与底层决策过程同步构建适合Q学习的乘积定时模型。

Result: 在三个仿真研究中验证了该框架的有效性，包括MDP和POMDP场景，结果表明其能够学习满足时间限制的策略，并适用于大规模和部分可观测环境。

Conclusion: 该框架在随机转换下能够学习满足严格时间限制要求的策略，适用于大规模状态空间和部分可观测环境，展示了其在时间关键和不确定环境中可靠机器人规划的潜力。

Abstract: Robotic systems operating in dynamic and uncertain environments increasingly require planners that satisfy complex task sequences while adhering to strict temporal constraints. Metric Interval Temporal Logic (MITL) offers a formal and expressive framework for specifying such time-bounded requirements; however, integrating MITL with reinforcement learning (RL) remains challenging due to stochastic dynamics and partial observability. This paper presents a unified automata-based RL framework for synthesizing policies in both Markov Decision Processes (MDPs) and Partially Observable Markov Decision Processes (POMDPs) under MITL specifications. MITL formulas are translated into Timed Limit-Deterministic Generalized Büchi Automata (Timed-LDGBA) and synchronized with the underlying decision process to construct product timed models suitable for Q-learning. A simple yet expressive reward structure enforces temporal correctness while allowing additional performance objectives. The approach is validated in three simulation studies: a $5 \times 5$ grid-world formulated as an MDP, a $10 \times 10$ grid-world formulated as a POMDP, and an office-like service-robot scenario. Results demonstrate that the proposed framework consistently learns policies that satisfy strict time-bounded requirements under stochastic transitions, scales to larger state spaces, and remains effective in partially observable environments, highlighting its potential for reliable robotic planning in time-critical and uncertain settings.

</details>


### [93] [Compositional Diffusion with Guided search for Long-Horizon Planning](https://arxiv.org/abs/2601.00126)
*Utkarsh A Mishra,David He,Yongxin Chen,Danfei Xu*

Main category: cs.RO

TL;DR: CDGS通过嵌入搜索的扩散去噪方法解决组合生成模型的模态平均问题，在多个任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 组合生成模型在建模长时程任务分布时面临模态平均问题，导致生成的计划既缺乏局部可行性又缺乏全局一致性。

Method: 提出Compositional Diffusion with Guided Search (CDGS)，通过基于种群的采样探索局部模态的多样组合，利用基于似然的过滤修剪不可行候选，并通过重叠段之间的迭代重采样强制全局一致性。

Result: CDGS在七项机器人操作任务中匹配oracle性能，优于缺乏组合性或需要长时程训练数据的基线方法，并能生成连贯的全景图像和长视频。

Conclusion: CDGS通过将搜索嵌入扩散去噪过程，有效解决了模态平均问题，在机器人操作任务中达到与oracle相当的性能，并在全景图像和长视频生成中展示了跨领域的泛化能力。

Abstract: Generative models have emerged as powerful tools for planning, with compositional approaches offering particular promise for modeling long-horizon task distributions by composing together local, modular generative models. This compositional paradigm spans diverse domains, from multi-step manipulation planning to panoramic image synthesis to long video generation. However, compositional generative models face a critical challenge: when local distributions are multimodal, existing composition methods average incompatible modes, producing plans that are neither locally feasible nor globally coherent. We propose Compositional Diffusion with Guided Search (CDGS), which addresses this \emph{mode averaging} problem by embedding search directly within the diffusion denoising process. Our method explores diverse combinations of local modes through population-based sampling, prunes infeasible candidates using likelihood-based filtering, and enforces global consistency through iterative resampling between overlapping segments. CDGS matches oracle performance on seven robot manipulation tasks, outperforming baselines that lack compositionality or require long-horizon training data. The approach generalizes across domains, enabling coherent text-guided panoramic images and long videos through effective local-to-global message passing. More details: https://cdgsearch.github.io/

</details>


### [94] [SLEI3D: Simultaneous Exploration and Inspection via Heterogeneous Fleets under Limited Communication](https://arxiv.org/abs/2601.00163)
*Junfeng Chen,Yuxiao Zhu,Xintong Zhang,Bing Luo,Meng Guo*

Main category: cs.RO

TL;DR: SLEI3D框架解决了异构机器人在未知环境中的协同探索、检查和通信问题，通过多层规划和间歇通信协议实现高效协调，仿真和实验验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 在未知环境中，传统机器人巡检方法无法动态识别兴趣区域并进行实时通信，因此需要一种新的协同框架。

Method: 开发了一种多层多速率规划机制，用于机器人子群间的协调，结合间歇性或主动通信协议，实现探索、检查和通信的集成。

Result: 通过大规模仿真（最多48个机器人）和硬件实验（7个机器人）验证了框架的有效性，能够处理多达384千立方米的场景。

Conclusion: 本文提出了SLEI3D框架，成功解决了异构机器人在未知环境中的协同3D探索、自适应检查和实时通信问题，并通过高保真仿真和硬件实验验证了其有效性。

Abstract: Robotic fleets such as unmanned aerial and ground vehicles have been widely used for routine inspections of static environments, where the areas of interest are known and planned in advance. However, in many applications, such areas of interest are unknown and should be identified online during exploration. Thus, this paper considers the problem of simultaneous exploration, inspection of unknown environments and then real-time communication to a mobile ground control station to report the findings. The heterogeneous robots are equipped with different sensors, e.g., long-range lidars for fast exploration and close-range cameras for detailed inspection. Furthermore, global communication is often unavailable in such environments, where the robots can only communicate with each other via ad-hoc wireless networks when they are in close proximity and free of obstruction. This work proposes a novel planning and coordination framework (SLEI3D) that integrates the online strategies for collaborative 3D exploration, adaptive inspection and timely communication (via the intermit-tent or proactive protocols). To account for uncertainties w.r.t. the number and location of features, a multi-layer and multi-rate planning mechanism is developed for inter-and-intra robot subgroups, to actively meet and coordinate their local plans. The proposed framework is validated extensively via high-fidelity simulations of numerous large-scale missions with up to 48 robots and 384 thousand cubic meters. Hardware experiments of 7 robots are also conducted. Project website is available at https://junfengchen-robotics.github.io/SLEI3D/.

</details>


### [95] [SLAP: Slapband-based Autonomous Perching Drone with Failure Recovery for Vertical Tree Trunks](https://arxiv.org/abs/2601.00238)
*Julia Di,Kenneth A. W. Hoffmann,Tony G. Chen,Tian-Ao Ren,Mark R. Cutkosky*

Main category: cs.RO

TL;DR: SLAP系统为大型无人机设计，整合多模块实现轻柔停靠与失败恢复，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有垂直表面停靠方案多针对轻型无人机且系统集成不足，高速着陆对搭载敏感电子设备的无人机存在风险。

Method: SLAP系统包括视觉停靠点检测器、IMU故障检测器、姿态控制器、光学近距离检测系统和快速主动弹性抓取器。

Result: 在1.2 kg商用四旋翼无人机上验证，室内实验在橡树段上实现75%停靠成功率（20次飞行）和100%失败恢复率（2次诱导失败）。

Conclusion: SLAP系统通过整合视觉检测、IMU故障检测、姿态控制和弹性抓取器，实现了对垂直树干的安全、轻柔停靠，并在停靠失败时能有效恢复。

Abstract: Perching allows unmanned aerial vehicles (UAVs) to reduce energy consumption, remain anchored for surface sampling operations, or stably survey their surroundings. Previous efforts for perching on vertical surfaces have predominantly focused on lightweight mechanical design solutions with relatively scant system-level integration. Furthermore, perching strategies for vertical surfaces commonly require high-speed, aggressive landing operations that are dangerous for a surveyor drone with sensitive electronics onboard. This work presents the preliminary investigation of a perching approach suitable for larger drones that both gently perches on vertical tree trunks and reacts and recovers from perch failures. The system in this work, called SLAP, consists of vision-based perch site detector, an IMU (inertial-measurement-unit)-based perch failure detector, an attitude controller for soft perching, an optical close-range detection system, and a fast active elastic gripper with microspines made from commercially-available slapbands. We validated this approach on a modified 1.2 kg commercial quadrotor with component and system analysis. Initial human-in-the-loop autonomous indoor flight experiments achieved a 75% perch success rate on a real oak tree segment across 20 flights, and 100% perch failure recovery across 2 flights with induced failures.

</details>


### [96] [Vehicle Painting Robot Path Planning Using Hierarchical Optimization](https://arxiv.org/abs/2601.00271)
*Yuya Nagai,Hiromitsu Nakamura,Narito Shinmachi,Yuta Higashizono,Satoshi Ono*

Main category: cs.RO

TL;DR: Automated hierarchical optimization method for designing paint paths in vehicle production, matching manual quality and reducing design time.


<details>
  <summary>Details</summary>
Motivation: The manual design of paint paths for robotic arms in vehicle painting is time-consuming, highlighting the need for automation to reduce design time. Conventional robotic path planning techniques are unsuitable due to unique constraints in the painting process.

Method: The paper formulates paint path design as a hierarchical optimization problem, with an upper-layer subproblem resembling a vehicle routing problem (VRP) and a lower-layer subproblem for detailed path planning. Different optimization algorithms are used at each layer, with tailored variable representation, constraints, repair operators, and initialization processes.

Result: Experiments on three commercially available vehicle models showed the method can automatically design constraint-satisfying paint paths with quality comparable to manual designs.

Conclusion: The proposed hierarchical optimization method successfully automates the design of paint paths for robotic arms in vehicle production, matching the quality of manual designs while reducing design time.

Abstract: In vehicle production factories, the vehicle painting process employs multiple robotic arms to simultaneously apply paint to car bodies advancing along a conveyor line. Designing paint paths for these robotic arms, which involves assigning car body areas to arms and determining paint sequences for each arm, remains a time-consuming manual task for engineers, indicating the demand for automation and design time reduction. The unique constraints of the painting process hinder the direct application of conventional robotic path planning techniques, such as those used in welding. Therefore, this paper formulates the design of paint paths as a hierarchical optimization problem, where the upper-layer subproblem resembles a vehicle routing problem (VRP), and the lower-layer subproblem involves detailed path planning. This approach allows the use of different optimization algorithms at each layer, and permits flexible handling of constraints specific to the vehicle painting process through the design of variable representation, constraints, repair operators, and an initialization process at the upper and lower layers. Experiments with three commercially available vehicle models demonstrated that the proposed method can automatically design paths that satisfy all constraints for vehicle painting with quality comparable to those created manually by engineers.

</details>


### [97] [Pure Inertial Navigation in Challenging Environments with Wheeled and Chassis Mounted Inertial Sensors](https://arxiv.org/abs/2601.00275)
*Dusan Nemec,Gal Versano,Itai Savin,Vojtech Simak,Juraj Kekelak,Itzik Klein*

Main category: cs.RO

TL;DR: WiCHINS通过结合轮式和底盘惯性传感器，提出三阶段框架实现精确纯惯性导航，在挑战性环境中表现优异。


<details>
  <summary>Details</summary>
Motivation: 在GNSS信号受限或光照条件不佳的情况下，导航解决方案可能仅依赖惯性传感器，导致因惯性测量误差而产生时间漂移。

Method: 提出了WiCHINS系统，通过结合轮式和底盘安装的惯性传感器，采用三阶段框架（每个阶段配备专用扩展卡尔曼滤波器）进行精确的纯惯性导航。

Result: 使用两个轮子和一个底盘惯性测量单元，平均位置误差为11.4米，占平均行驶距离的2.4%，优于其他四种惯性基线方法。

Conclusion: WiCHINS方法在挑战性环境中实现了鲁棒的导航性能，显著缩小了纯惯性导航的性能差距。

Abstract: Autonomous vehicles and wheeled robots are widely used in many applications in both indoor and outdoor settings. In practical situations with limited GNSS signals or degraded lighting conditions, the navigation solution may rely only on inertial sensors and as result drift in time due to errors in the inertial measurement. In this work, we propose WiCHINS, a wheeled and chassis inertial navigation system by combining wheel-mounted-inertial sensors with a chassis-mounted inertial sensor for accurate pure inertial navigation. To that end, we derive a three-stage framework, each with a dedicated extended Kalman filter. This framework utilizes the benefits of each location (wheel/body) during the estimation process. To evaluate our proposed approach, we employed a dataset with five inertial measurement units with a total recording time of 228.6 minutes. We compare our approach with four other inertial baselines and demonstrate an average position error of 11.4m, which is $2.4\%$ of the average traveled distance, using two wheels and one body inertial measurement units. As a consequence, our proposed method enables robust navigation in challenging environments and helps bridge the pure-inertial performance gap.

</details>


### [98] [Replaceable Bit-based Gripper for Picking Cluttered Food Items](https://arxiv.org/abs/2601.00305)
*Prashant Kumar,Yukiyasu Domae,Weiwei Wan,Kensuke Harada*

Main category: cs.RO

TL;DR: 提出可更换夹头的抓手系统，成功处理粘性颗粒和长条状食品，投放准确率高且切换迅速。


<details>
  <summary>Details</summary>
Motivation: 食品包装行业需要快速处理形状和重量各异的食品，现有抓手系统难以应对粘性、颗粒状或长条状食品的挑战。

Method: 设计了一种可更换夹头的抓手系统，配备专用食品附件和皮带更换系统，支持多种控制选项。

Result: 抓手系统成功抓取ikura和意大利面，重量特异性投放准确率分别超过95%和80%，并能快速切换不同夹头。

Conclusion: 该抓手系统成功解决了食品包装行业中不同形状和重量食品的抓取问题，展示了高准确性和快速切换能力。

Abstract: The food packaging industry goes through changes in food items and their weights quite rapidly. These items range from easy-to-pick, single-piece food items to flexible, long and cluttered ones. We propose a replaceable bit-based gripper system to tackle the challenge of weight-based handling of cluttered food items. The gripper features specialized food attachments(bits) that enhance its grasping capabilities, and a belt replacement system allows switching between different food items during packaging operations. It offers a wide range of control options, enabling it to grasp and drop specific weights of granular, cluttered, and entangled foods. We specifically designed bits for two flexible food items that differ in shape: ikura(salmon roe) and spaghetti. They represent the challenging categories of sticky, granular food and long, sticky, cluttered food, respectively. The gripper successfully picked up both spaghetti and ikura and demonstrated weight-specific dropping of these items with an accuracy over 80% and 95% respectively. The gripper system also exhibited quick switching between different bits, leading to the handling of a large range of food items.

</details>


### [99] [Space Debris Removal using Nano-Satellites controlled by Low-Power Autonomous Agents](https://arxiv.org/abs/2601.00465)
*Dennis Christmann,Juan F. Gutierrez,Sthiti Padhi,Patrick Plörer,Aditya Takur,Simona Silvestri,Andres Gomez*

Main category: cs.RO

TL;DR: 利用自主纳米卫星群清理太空垃圾，实验证明该方法可行且高效。


<details>
  <summary>Details</summary>
Motivation: 太空垃圾对卫星和太空旅行的安全构成威胁，急需解决方案。

Method: 研究在资源受限的平台上部署自主代理，并在专用测试床上进行实验。

Result: 实验证明了自主纳米卫星群在清理太空垃圾方面的可行性和能源效率。

Conclusion: 研究表明，通过无线微控制器实现的自主纳米卫星群在能源效率和可行性方面表现出色，为太空垃圾清理提供了一种简化但有效的解决方案。

Abstract: Space debris is an ever-increasing problem in space travel. There are already many old, no longer functional spacecraft and debris orbiting the earth, which endanger both the safe operation of satellites and space travel. Small nano-satellite swarms can address this problem by autonomously de-orbiting debris safely into the Earth's atmosphere. This work builds on the recent advances of autonomous agents deployed in resource-constrained platforms and shows a first simplified approach how such intelligent and autonomous nano-satellite swarms can be realized. We implement our autonomous agent software on wireless microcontrollers and perform experiments on a specialized test-bed to show the feasibility and overall energy efficiency of our approach.

</details>


### [100] [Variable Elimination in Hybrid Factor Graphs for Discrete-Continuous Inference & Estimation](https://arxiv.org/abs/2601.00545)
*Varun Agrawal,Frank Dellaert*

Main category: cs.RO

TL;DR: 提出混合因子图框架和变量消除算法，用于精确的最大后验估计，适用于SLAM等混合问题。


<details>
  <summary>Details</summary>
Motivation: 机器人学中的混合问题涉及连续和离散组件，现有方法基于近似，需要更精确的建模框架。

Method: 开发了一种新型混合高斯因子和混合条件表示，结合树结构因子表示和剪枝方案，实现了可处理的推理。

Result: 提出的框架在SLAM数据集上展示了准确性、通用性和简单性。

Conclusion: 该论文提出了一个高效的混合因子图框架和变量消除算法，用于精确的最大后验估计和边缘化，展示了其在具有模糊测量的SLAM数据集上的准确性、通用性和简单性。

Abstract: Many hybrid problems in robotics involve both continuous and discrete components, and modeling them together for estimation tasks has been a long standing and difficult problem. Hybrid Factor Graphs give us a mathematical framework to model these types of problems, however existing approaches for solving them are based on approximations. In this work, we propose an efficient Hybrid Factor Graph framework alongwith a variable elimination algorithm to produce a hybrid Bayes network, which can then be used for exact Maximum A Posteriori estimation and marginalization over both sets of variables. Our approach first develops a novel hybrid Gaussian factor which can connect to both discrete and continuous variables, and a hybrid conditional which can represent multiple continuous hypotheses conditioned on the discrete variables. Using these representations, we derive the process of hybrid variable elimination under the Conditional Linear Gaussian scheme, giving us exact posteriors as hybrid Bayes network. To bound the number of discrete hypotheses, we use a tree-structured representation of the factors coupled with a simple pruning and probabilistic assignment scheme, which allows for tractable inference. We demonstrate the applicability of our framework on a SLAM dataset with ambiguous measurements, where discrete choices for the most likely measurement have to be made. Our demonstrated results showcase the accuracy, generality, and simplicity of our hybrid factor graph framework.

</details>


### [101] [LLM-Based Agentic Exploration for Robot Navigation & Manipulation with Skill Orchestration](https://arxiv.org/abs/2601.00555)
*Abu Hanif Muhammad Syarubany,Farhan Zaki Rahmani,Trio Widianto*

Main category: cs.RO

TL;DR: 论文提出了一种基于LLM的端到端室内购物机器人系统，通过语义地图和模块化控制实现任务执行，展示了良好的性能和可调试性。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种能够在室内购物环境中进行端到端任务执行的机器人系统，结合自然语言处理和模块化控制，提高任务的灵活性和可调试性。

Method: 系统通过检测路口标识牌逐步构建轻量级语义地图，结合AprilTags提供可重复的锚点，利用LLM生成离散动作决策，并由ROS有限状态主控制器执行模块化运动原语。

Result: 定性结果显示，集成系统能够完成从用户指令到多店铺导航和物品检索的完整任务执行，并通过基于文本的地图和决策历史记录保持模块化和可调试性。

Conclusion: 该论文提出的端到端LLM驱动探索系统在室内购物任务中表现出色，展示了从用户指令到多店铺导航和物品检索的完整执行能力，同时保持了模块化和可调试性。

Abstract: This paper presents an end-to-end LLM-based agentic exploration system for an indoor shopping task, evaluated in both Gazebo simulation and a corresponding real-world corridor layout. The robot incrementally builds a lightweight semantic map by detecting signboards at junctions and storing direction-to-POI relations together with estimated junction poses, while AprilTags provide repeatable anchors for approach and alignment. Given a natural-language shopping request, an LLM produces a constrained discrete action at each junction (direction and whether to enter a store), and a ROS finite-state main controller executes the decision by gating modular motion primitives, including local-costmap-based obstacle avoidance, AprilTag approaching, store entry, and grasping. Qualitative results show that the integrated stack can perform end-to-end task execution from user instruction to multi-store navigation and object retrieval, while remaining modular and debuggable through its text-based map and logged decision history.

</details>


### [102] [Priority-Aware Multi-Robot Coverage Path Planning](https://arxiv.org/abs/2601.00580)
*Kanghoon Lee,Hyeonjun Kim,Jiachen Li,Jinkyoo Park*

Main category: cs.RO

TL;DR: PA-MCPP通过两阶段方法优化多机器人覆盖路径规划，显著降低优先级区域的延迟，同时保持总完成时间竞争力。


<details>
  <summary>Details</summary>
Motivation: 现有MCPP方法假设区域重要性均匀，无法有效处理需优先覆盖的场景。PA-MCPP问题旨在通过优先级加权延迟和总完成时间的字典序最小化来优化覆盖效率。

Method: 提出一个可扩展的两阶段框架：(1) 贪心区域分配结合局部搜索和生成树路径规划，(2) Steiner树引导的剩余覆盖。

Result: 实验表明，相比标准MCPP基线，PA-MCPP显著降低了优先级加权延迟，同时保持竞争力的总完成时间。敏感性分析验证了方法的扩展性和优先级权重控制的有效性。

Conclusion: PA-MCPP框架通过两阶段方法显著降低了优先级加权延迟，同时在保持竞争力的总完成时间（makespan）方面表现良好。该方法对机器人数量和优先级权重的调整具有良好扩展性和控制性。

Abstract: Multi-robot systems are widely used for coverage tasks that require efficient coordination across large environments. In Multi-Robot Coverage Path Planning (MCPP), the objective is typically to minimize the makespan by generating non-overlapping paths for full-area coverage. However, most existing methods assume uniform importance across regions, limiting their effectiveness in scenarios where some zones require faster attention. We introduce the Priority-Aware MCPP (PA-MCPP) problem, where a subset of the environment is designated as prioritized zones with associated weights. The goal is to minimize, in lexicographic order, the total priority-weighted latency of zone coverage and the overall makespan. To address this, we propose a scalable two-phase framework combining (1) greedy zone assignment with local search, spanning-tree-based path planning, and (2) Steiner-tree-guided residual coverage. Experiments across diverse scenarios demonstrate that our method significantly reduces priority-weighted latency compared to standard MCPP baselines, while maintaining competitive makespan. Sensitivity analyses further show that the method scales well with the number of robots and that zone coverage behavior can be effectively controlled by adjusting priority weights.

</details>


### [103] [NMPC-Augmented Visual Navigation and Safe Learning Control for Large-Scale Mobile Robots](https://arxiv.org/abs/2601.00609)
*Mehdi Heydari Shahna,Pauli Mustalahti,Jouni Mattila*

Main category: cs.RO

TL;DR: 论文提出了一种确保大型移动机器人在易滑地形上稳定安全操作的导航与控制框架，结合视觉姿态估计、模型预测控制、深度神经网络和自适应控制，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 大型移动机器人在松散、未固结地形上操作时牵引力降低，需要确保稳定性和安全性。

Method: 框架包含四个主要模块：视觉姿态估计、高级非线性模型预测控制、低级深度神经网络控制策略（结合鲁棒自适应控制）以及对数安全模块。

Result: 实验证明，该框架在6000公斤的大型移动机器人上有效，各模块在不同频率下同步运行，保证了系统级安全性和执行子系统的均匀指数稳定性。

Conclusion: 该论文提出了一个综合导航与控制框架，确保大型移动机器人在易滑地形上的稳定性和安全性，通过高性能技术的联合应用实现了鲁棒操作。

Abstract: A large-scale mobile robot (LSMR) is a high-order multibody system that often operates on loose, unconsolidated terrain, which reduces traction. This paper presents a comprehensive navigation and control framework for an LSMR that ensures stability and safety-defined performance, delivering robust operation on slip-prone terrain by jointly leveraging high-performance techniques. The proposed architecture comprises four main modules: (1) a visual pose-estimation module that fuses onboard sensors and stereo cameras to provide an accurate, low-latency robot pose, (2) a high-level nonlinear model predictive control that updates the wheel motion commands to correct robot drift from the robot reference pose on slip-prone terrain, (3) a low-level deep neural network control policy that approximates the complex behavior of the wheel-driven actuation mechanism in LSMRs, augmented with robust adaptive control to handle out-of-distribution disturbances, ensuring that the wheels accurately track the updated commands issued by high-level control module, and (4) a logarithmic safety module to monitor the entire robot stack and guarantees safe operation. The proposed low-level control framework guarantees uniform exponential stability of the actuation subsystem, while the safety module ensures the whole system-level safety during operation. Comparative experiments on a 6,000 kg LSMR actuated by two complex electro-hydrostatic drives, while synchronizing modules operating at different frequencies.

</details>


### [104] [Vision-based Goal-Reaching Control for Mobile Robots Using a Hierarchical Learning Framework](https://arxiv.org/abs/2601.00610)
*Mehdi Heydari Shahna,Pauli Mustalahti,Jouni Mattila*

Main category: cs.RO

TL;DR: 论文提出一个安全目标到达控制框架，通过模块化设计结合RL、深度学习和自适应控制，确保大型机器人在不稳定地形上的安全操作。


<details>
  <summary>Details</summary>
Motivation: 强化学习在机器人应用中需要大量探索状态-动作空间，可能导致不安全行为，限制了其在大规模机器人上的应用。

Method: 1) 实时视觉姿态估计方法提供准确的机器人状态；2) RL运动规划器生成实时平滑运动命令；3) 监督深度学习模型捕捉机器人复杂动力学；4) 基于模型的鲁棒自适应控制器保证车轮跟踪RL运动命令；5) 数学安全监督器监控机器人并在不安全时停止。

Result: 在6,000公斤机器人上的不同场景实验证实了框架的有效性。

Conclusion: 提出的框架保证了驱动系统的均匀指数稳定性和整个操作的安全性，实验验证了其有效性。

Abstract: Reinforcement learning (RL) is effective in many robotic applications, but it requires extensive exploration of the state-action space, during which behaviors can be unsafe. This significantly limits its applicability to large robots with complex actuators operating on unstable terrain. Hence, to design a safe goal-reaching control framework for large-scale robots, this paper decomposes the whole system into a set of tightly coupled functional modules. 1) A real-time visual pose estimation approach is employed to provide accurate robot states to 2) an RL motion planner for goal-reaching tasks that explicitly respects robot specifications. The RL module generates real-time smooth motion commands for the actuator system, independent of its underlying dynamic complexity. 3) In the actuation mechanism, a supervised deep learning model is trained to capture the complex dynamics of the robot and provide this model to 4) a model-based robust adaptive controller that guarantees the wheels track the RL motion commands even on slip-prone terrain. 5) Finally, to reduce human intervention, a mathematical safety supervisor monitors the robot, stops it on unsafe faults, and autonomously guides it back to a safe inspection area. The proposed framework guarantees uniform exponential stability of the actuation system and safety of the whole operation. Experiments on a 6,000 kg robot in different scenarios confirm the effectiveness of the proposed framework.

</details>


### [105] [From 2D to 3D terrain-following area coverage path planning](https://arxiv.org/abs/2601.00614)
*Mogens Plessen*

Main category: cs.RO

TL;DR: 提出了一种3D地形跟随区域覆盖路径规划算法，通过农业实际数据验证，解决了工作宽度和高度同时考虑的复杂性问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决3D地形跟随区域覆盖路径规划的复杂性，特别是在农业机械应用中，需要一种能够同时考虑工作宽度和工作高度的算法。

Method: 算法生成多条相邻路径，这些路径（i）局部间距等于机械的工作宽度，（ii）同时保持与地形的特定工作高度投影距离。采用了逆距离加权方法和局部搜索来处理均匀间距高程数据生成的复杂性。

Result: 算法在农业领域的实际3D数据中得到了验证，展示了其在复杂地形下的有效性和实用性。

Conclusion: 该论文提出了一种适用于3D地形跟随的区域覆盖路径规划算法，并通过农业领域的实际3D数据验证了其有效性。

Abstract: An algorithm for 3D terrain-following area coverage path planning is presented. Multiple adjacent paths are generated that are (i) locally apart from each other by a distance equal to the working width of a machinery, while (ii) simultaneously floating at a projection distance equal to a specific working height above the terrain. The complexities of the algorithm in comparison to its 2D equivalent are highlighted. These include uniformly spaced elevation data generation using an Inverse Distance Weighting-approach and a local search. Area coverage path planning results for real-world 3D data within an agricultural context are presented to validate the algorithm.

</details>


### [106] [RoboReward: General-Purpose Vision-Language Reward Models for Robotics](https://arxiv.org/abs/2601.00675)
*Tony Lee,Andrew Wagenmaker,Karl Pertsch,Percy Liang,Sergey Levine,Chelsea Finn*

Main category: cs.RO

TL;DR: 提出RoboReward数据集和模型，通过负样本增强训练4B/8B参数VLM，在实际机器人任务中表现优于大模型并接近人类奖励效果。


<details>
  <summary>Details</summary>
Motivation: 解决真实机器人任务中奖励设计依赖人工标注或脆弱手工目标的问题，探索视觉语言模型作为自动奖励模型的有效性。

Method: 提出RoboReward数据集和基准，结合负样本数据增强流程生成校准的负样本和近失样本，训练4B和8B参数的视觉语言奖励模型。

Result: 评估显示现有VLM在所有任务中均未表现优异，但训练的4B/8B模型在短视距任务中优于更大VLM，实际部署中显著提升策略学习。

Conclusion: RoboReward 4B/8B模型在短视距机器人任务中表现优于更大的VLM，并在实际机器人强化学习中显著提升了策略学习效果，缩小了与人类提供奖励的差距。

Abstract: A well-designed reward is critical for effective reinforcement learning-based policy improvement. In real-world robotic domains, obtaining such rewards typically requires either labor-intensive human labeling or brittle, handcrafted objectives. Vision-language models (VLMs) have shown promise as automatic reward models, yet their effectiveness on real robot tasks is poorly understood. In this work, we aim to close this gap by introducing (1) \textbf{RoboReward}, a robotics reward dataset and benchmark built on large-scale real-robot corpora from Open X-Embodiment (OXE) and RoboArena, and (2) vision-language reward models trained on this dataset (RoboReward 4B/8B). Because OXE is success-heavy and lacks failure examples, we propose a \emph{negative examples data augmentation} pipeline that generates calibrated \emph{negatives} and \emph{near-misses} via counterfactual relabeling of successful episodes and temporal clipping to create partial-progress outcomes from the same videos. Using this framework, we produce an extensive training and evaluation dataset that spans diverse tasks and embodiments and enables systematic evaluation of whether state-of-the-art VLMs can reliably provide rewards for robotics. Our evaluation of leading open-weight and proprietary VLMs reveals that no model excels across all tasks, underscoring substantial room for improvement. We then train general-purpose 4B- and 8B-parameter models that outperform much larger VLMs in assigning rewards for short-horizon robotic tasks. Finally, we deploy the 8B-parameter reward VLM in real-robot reinforcement learning and find that it improves policy learning over Gemini Robotics-ER 1.5, a frontier physical reasoning VLM trained on robotics data, by a large margin, while substantially narrowing the gap to RL training with human-provided rewards.

</details>


### [107] [DefVINS: Visual-Inertial Odometry for Deformable Scenes](https://arxiv.org/abs/2601.00702)
*Samuel Cerezo,Javier Civera*

Main category: cs.RO

TL;DR: DefVINS是一种VIO框架，通过分离刚性与非刚性变形，结合惯性约束与可观测性感知的变形激活，提升非刚性环境下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统VIO基于刚性假设，在可变形场景中容易过拟合或漂移，DefVINS旨在解决这一问题。

Method: DefVINS框架使用嵌入式变形图表示非刚性变形，并通过标准VIO程序初始化，逐步激活非刚性自由度。

Result: 实验表明，结合惯性约束与可观测性感知的变形激活策略，DefVINS在非刚性环境中表现更鲁棒。

Conclusion: DefVINS通过将刚性状态与非刚性变形分离，并结合惯性约束与可观测性感知的变形激活策略，显著提高了在非刚性环境下的鲁棒性。

Abstract: Deformable scenes violate the rigidity assumptions underpinning classical visual-inertial odometry (VIO), often leading to over-fitting to local non-rigid motion or severe drift when deformation dominates visual parallax. We introduce DefVINS, a visual-inertial odometry framework that explicitly separates a rigid, IMU-anchored state from a non--rigid warp represented by an embedded deformation graph. The system is initialized using a standard VIO procedure that fixes gravity, velocity, and IMU biases, after which non-rigid degrees of freedom are activated progressively as the estimation becomes well conditioned. An observability analysis is included to characterize how inertial measurements constrain the rigid motion and render otherwise unobservable modes identifiable in the presence of deformation. This analysis motivates the use of IMU anchoring and informs a conditioning-based activation strategy that prevents ill-posed updates under poor excitation. Ablation studies demonstrate the benefits of combining inertial constraints with observability-aware deformation activation, resulting in improved robustness under non-rigid environments.

</details>


### [108] [Calling for Backup: How Children Navigate Successive Robot Communication Failures](https://arxiv.org/abs/2601.00754)
*Maria Teresa Parreira,Isabel Neto,Filipa Rocha,Wendy Ju*

Main category: cs.RO

TL;DR: 研究探讨儿童对机器人连续错误的反应，发现儿童与成人反应相似但也有差异，如更多脱离行为，错误不影响对机器人的感知，为儿童人机交互设计提供参考。


<details>
  <summary>Details</summary>
Motivation: 探讨儿童对机器人社交错误和性能错误的反应，填补了儿童对连续机器人错误反应的研究空白。

Method: 本研究复制了Liu等人的连续机器人失败范式，对59名8至10岁的儿童参与者进行了实验，记录并分析了他们对机器人连续三次理解错误的反应。

Result: 儿童与成人一样会调整提示、改变语气，并在连续错误中表现出更多情绪化的非语言反应，但儿童表现出更多脱离行为，如暂时忽略机器人或寻求成人帮助。错误未影响儿童对机器人的感知，表明儿童对对话的期望更为灵活。

Conclusion: 研究结果表明，儿童对机器人错误的反应与成人既有相似之处也有差异，这些发现有助于设计更适合儿童的人机交互系统。

Abstract: How do children respond to repeated robot errors? While prior research has examined adult reactions to successive robot errors, children's responses remain largely unexplored. In this study, we explore children's reactions to robot social errors and performance errors. For the latter, this study reproduces the successive robot failure paradigm of Liu et al. with child participants (N=59, ages 8-10) to examine how young users respond to repeated robot conversational errors. Participants interacted with a robot that failed to understand their prompts three times in succession, with their behavioral responses video-recorded and analyzed. We found both similarities and differences compared to adult responses from the original study. Like adults, children adjusted their prompts, modified their verbal tone, and exhibited increasingly emotional non-verbal responses throughout successive errors. However, children demonstrated more disengagement behaviors, including temporarily ignoring the robot or actively seeking an adult. Errors did not affect participants' perception of the robot, suggesting more flexible conversational expectations in children. These findings inform the design of more effective and developmentally appropriate human-robot interaction systems for young users.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [109] [Reasoning in Action: MCTS-Driven Knowledge Retrieval for Large Language Models](https://arxiv.org/abs/2601.00003)
*Shuqi Liu,Bowei He,Chen Ma,Linqi Song*

Main category: cs.AI

TL;DR: 本文提出了一种推理感知的知识检索方法，通过从粗到细的检索策略和蒙特卡洛树搜索，显著提升了大型语言模型在对话中的表现，实验证明了其有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型通常通过检索语义相似信息或提升推理能力来优化性能，但如何有效整合这两种策略仍是一个挑战。本文旨在通过推理感知的知识检索方法，超越表面语义相似性，优化模型表现。

Method: 采用从粗到细的知识检索方法，首先识别知识库中与上下文相关的子区域，然后在该子区域内进一步提取与推理过程相关的知识。整个过程使用蒙特卡洛树搜索启发的方法，通过关键词导航知识句子。

Result: 在两个多轮对话数据集上的实验表明，该方法不仅更贴近人类对话中的推理逻辑，还显著提升了检索知识的多样性，从而生成更具信息量和创造性的回答。

Conclusion: 本文提出了一种结合检索与推理的策略，通过推理感知的知识检索方法显著提升了大型语言模型在对话中的表现，不仅增强了回答的信息量，还提高了创造性。

Abstract: Large language models (LLMs) typically enhance their performance through either the retrieval of semantically similar information or the improvement of their reasoning capabilities. However, a significant challenge remains in effectively integrating both retrieval and reasoning strategies to optimize LLM performance. In this paper, we introduce a reasoning-aware knowledge retrieval method that enriches LLMs with information aligned to the logical structure of conversations, moving beyond surface-level semantic similarity. We follow a coarse-to-fine approach for knowledge retrieval. First, we identify a contextually relevant sub-region of the knowledge base, ensuring that all sentences within it are relevant to the context topic. Next, we refine our search within this sub-region to extract knowledge that is specifically relevant to the reasoning process. Throughout both phases, we employ the Monte Carlo Tree Search-inspired search method to effectively navigate through knowledge sentences using common keywords. Experiments on two multi-turn dialogue datasets demonstrate that our knowledge retrieval approach not only aligns more closely with the underlying reasoning in human conversations but also significantly enhances the diversity of the retrieved knowledge, resulting in more informative and creative responses.

</details>


### [110] [Finetuning Large Language Models for Automated Depression Screening in Nigerian Pidgin English: GENSCORE Pilot Study](https://arxiv.org/abs/2601.00004)
*Isaac Iyinoluwa Olufadewa,Miracle Ayomikun Adesina,Ezekiel Ayodeji Oladejo,Uthman Babatunde Usman,Owen Kolade Adeniyi,Matthew Tolulope Olawoyin*

Main category: cs.AI

TL;DR: 该研究开发了一种基于微调大型语言模型的自动化抑郁症筛查方法，适应尼日利亚皮钦语，展示了GPT-4.1在定量和定性评估中的优越性能，为资源有限地区的心理健康筛查提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 抑郁症是尼日利亚心理健康负担的主要因素，但由于临床医生访问有限、污名化和语言障碍，筛查覆盖率较低。传统的筛查工具（如PHQ-9）在高收入国家验证过，但在低收入和中等收入国家及社区（如尼日利亚）可能因语言或文化差异而难以使用。

Method: 研究收集了432份尼日利亚年轻成人（18-40岁）的皮钦语音频响应，进行了转录、严格的预处理和注释（包括语义标注、俚语和习语解释以及PHQ-9严重程度评分）。随后对三种大型语言模型（Phi-3-mini-4k-instruct、Gemma-3-4B-it和GPT-4.1）进行了微调，并定量（准确性、精确度和语义对齐）和定性（清晰度、相关性和文化适宜性）评估了它们的性能。

Result: GPT-4.1在定量评估中表现最佳，PHQ-9严重程度评分预测准确率达到94.5%，优于Gemma-3-4B-it和Phi-3-mini-4k-instruct。定性评估中，GPT-4.1也生成了最具文化适宜性、清晰且上下文相关的响应。

Conclusion: 该研究为在语言多样且资源有限的环境中部署对话式心理健康工具奠定了基础，展示了AI介导的抑郁症筛查在尼日利亚服务不足社区的潜力。

Abstract: Depression is a major contributor to the mental-health burden in Nigeria, yet screening coverage remains limited due to low access to clinicians, stigma, and language barriers. Traditional tools like the Patient Health Questionnaire-9 (PHQ-9) were validated in high-income countries but may be linguistically or culturally inaccessible for low- and middle-income countries and communities such as Nigeria where people communicate in Nigerian Pidgin and more than 520 local languages. This study presents a novel approach to automated depression screening using fine-tuned large language models (LLMs) adapted for conversational Nigerian Pidgin. We collected a dataset of 432 Pidgin-language audio responses from Nigerian young adults aged 18-40 to prompts assessing psychological experiences aligned with PHQ-9 items, performed transcription, rigorous preprocessing and annotation, including semantic labeling, slang and idiom interpretation, and PHQ-9 severity scoring. Three LLMs - Phi-3-mini-4k-instruct, Gemma-3-4B-it, and GPT-4.1 - were fine-tuned on this annotated dataset, and their performance was evaluated quantitatively (accuracy, precision and semantic alignment) and qualitatively (clarity, relevance, and cultural appropriateness). GPT-4.1 achieved the highest quantitative performance, with 94.5% accuracy in PHQ-9 severity scoring prediction, outperforming Gemma-3-4B-it and Phi-3-mini-4k-instruct. Qualitatively, GPT-4.1 also produced the most culturally appropriate, clear, and contextually relevant responses. AI-mediated depression screening for underserved Nigerian communities. This work provides a foundation for deploying conversational mental-health tools in linguistically diverse, resource-constrained environments.

</details>


### [111] [Toward a Physical Theory of Intelligence](https://arxiv.org/abs/2601.00021)
*Peter David Fagan*

Main category: cs.AI

TL;DR: 论文提出智能的物理理论，通过CCE框架将信息转化为目标导向工作，揭示了智能系统的内在限制，并应用于生物系统和人工智能安全。


<details>
  <summary>Details</summary>
Motivation: 旨在建立智能的物理理论，解释智能系统如何在守恒定律约束下通过不可逆信息处理实现目标导向的工作。

Method: 引入守恒一致编码（CCE）框架，将智能系统建模为耦合的代理-环境过程，通过不可逆信息处理将信息转化为目标导向的工作。

Result: 理论揭示了智能系统的信息保存、耗散和有用工作之间的权衡，表明大脑接近框架预测的高效运行状态，并提出了超越固定点逻辑的计算模式。

Conclusion: 该论文提出了一个统一的、与底物无关的智能物理现象理论，揭示了智能系统的内在认知限制，并为人工智能安全提供了物理基础视角。

Abstract: We present a physical theory of intelligence grounded in irreversible information processing in systems constrained by conservation laws. An intelligent system is modelled as a coupled agent-environment process whose evolution transforms information into goal-directed work. To connect information to physical state, we introduce the Conservation-Congruent Encoding (CCE) framework, in which encodings correspond to metastable basins of attraction whose separability is enforced by conservation laws. Within this framework, intelligence is defined as the amount of goal-directed work produced per nat of irreversibly processed information. From this definition we derive a hierarchy of physical constraints governing information intake, irreversible computation, and work extraction in open systems. The framework reveals how long-horizon efficiency requires the preservation of internal informational structure, giving rise to self-modelling, and it establishes that physically embodied intelligent systems possess intrinsic epistemic limits analogous to incompleteness phenomena. Applying the theory to biological systems, we analyse how oscillatory and near-critical dynamics optimise the trade-off between information preservation, dissipation, and useful work, placing the brain near an efficient operating regime predicted by the framework. At the architectural level, we develop a theory of continuous dynamical circuits in which classical Boolean logic emerges as a special case of attractor selection, while more general invariant geometries support computational modes beyond fixed-point logic. Finally, we propose a physically grounded perspective on artificial intelligence safety based on irreversible information flow and structural homeostasis. Together, these results provide a unified, substrate-neutral account of intelligence as a physical phenomenon.

</details>


### [112] [A multi-algorithm approach for operational human resources workload balancing in a last mile urban delivery system](https://arxiv.org/abs/2601.00023)
*Luis M. Moreno-Saavedra,Silvia Jimenez-Fernandez,Antonio Portilla-Figueras,David Casillas-Perez,Sancho Salcedo-Sanz*

Main category: cs.AI

TL;DR: 本文提出多算法方法优化最后一英里包裹递送的工作量分配，结合距离与工作量考虑，确保公平分配，并通过实际案例验证有效性。


<details>
  <summary>Details</summary>
Motivation: 传统基于地理邻近性的包裹分配方法效率低下且导致工作量分配不均，因此需要优化递送时间并平衡工作量。

Method: 采用多算法方法，包括不同版本的k-means、进化算法、基于k-means初始化的递归分配及混合进化集成算法。

Result: 在西班牙Azuqueca de Henares的实际案例中验证了所提方法的性能。

Conclusion: 本文提出了一种多算法方法，用于解决最后一英里包裹递送系统中的人力资源工作量平衡问题，通过结合距离和工作量考虑优化包裹分配，确保每位工人每日完成相似的工作量。

Abstract: Efficient workload assignment to the workforce is critical in last-mile package delivery systems. In this context, traditional methods of assigning package deliveries to workers based on geographical proximity can be inefficient and surely guide to an unbalanced workload distribution among delivery workers. In this paper, we look at the problem of operational human resources workload balancing in last-mile urban package delivery systems. The idea is to consider the effort workload to optimize the system, i.e., the optimization process is now focused on improving the delivery time, so that the workload balancing is complete among all the staff. This process should correct significant decompensations in workload among delivery workers in a given zone. Specifically, we propose a multi-algorithm approach to tackle this problem. The proposed approach takes as input a set of delivery points and a defined number of workers, and then assigns packages to workers, in such a way that it ensures that each worker completes a similar amount of work per day. The proposed algorithms use a combination of distance and workload considerations to optimize the allocation of packages to workers. In this sense, the distance between the delivery points and the location of each worker is also taken into account. The proposed multi-algorithm methodology includes different versions of k-means, evolutionary approaches, recursive assignments based on k-means initialization with different problem encodings, and a hybrid evolutionary ensemble algorithm. We have illustrated the performance of the proposed approach in a real-world problem in an urban last-mile package delivery workforce operating at Azuqueca de Henares, Spain.

</details>


### [113] [Bio-inspired Agentic Self-healing Framework for Resilient Distributed Computing Continuum Systems](https://arxiv.org/abs/2601.00339)
*Alaa Saleh,Praveen Kumar Donta,Roberto Morabito,Sasu Tarkoma,Anders Lindgren,Qiyang Zhang,Schahram Dustdar,Susanna Pirttikangas,Lauri Lovén*

Main category: cs.AI

TL;DR: ReCiSt是一个仿生自愈框架，通过LM代理在DCCS中实现快速故障恢复（数十秒）和低资源消耗（CPU≥10%）。


<details>
  <summary>Details</summary>
Motivation: 现代DCCS因复杂性、移动性和动态操作条件频繁面临故障，需可扩展、自适应且自调节的弹性策略。

Method: 将生物愈合阶段（止血、炎症、增殖、重塑）重构为计算层（遏制、诊断、元认知、知识），利用语言模型（LM）驱动的代理实现自主故障隔离、因果诊断、自适应恢复和长期知识整合。

Result: 在公共故障数据集上验证，不同LM下均实现快速自愈（数十秒）和低资源消耗（CPU使用率≥10%），并展示了克服不确定性的深度分析和微代理调用能力。

Conclusion: ReCiSt框架通过仿生自愈机制在分布式计算连续系统（DCCS）中实现了弹性，验证了其在数十秒内完成自愈的能力，且代理CPU使用率最低为10%。

Abstract: Human biological systems sustain life through extraordinary resilience, continually detecting damage, orchestrating targeted responses, and restoring function through self-healing. Inspired by these capabilities, this paper introduces ReCiSt, a bio-inspired agentic self-healing framework designed to achieve resilience in Distributed Computing Continuum Systems (DCCS). Modern DCCS integrate heterogeneous computing resources, ranging from resource-constrained IoT devices to high-performance cloud infrastructures, and their inherent complexity, mobility, and dynamic operating conditions expose them to frequent faults that disrupt service continuity. These challenges underscore the need for scalable, adaptive, and self-regulated resilience strategies. ReCiSt reconstructs the biological phases of Hemostasis, Inflammation, Proliferation, and Remodeling into the computational layers Containment, Diagnosis, Meta-Cognitive, and Knowledge for DCCS. These four layers perform autonomous fault isolation, causal diagnosis, adaptive recovery, and long-term knowledge consolidation through Language Model (LM)-powered agents. These agents interpret heterogeneous logs, infer root causes, refine reasoning pathways, and reconfigure resources with minimal human intervention. The proposed ReCiSt framework is evaluated on public fault datasets using multiple LMs, and no baseline comparison is included due to the scarcity of similar approaches. Nevertheless, our results, evaluated under different LMs, confirm ReCiSt's self-healing capabilities within tens of seconds with minimum of 10% of agent CPU usage. Our results also demonstrated depth of analysis to over come uncertainties and amount of micro-agents invoked to achieve resilience.

</details>


### [114] [Quantitative Rule-Based Strategy modeling in Classic Indian Rummy: A Metric Optimization Approach](https://arxiv.org/abs/2601.00024)
*Purushottam Saha,Avirup Chakraborty,Sourish Sarkar,Subhamoy Maitra,Diganta Mukherjee,Tridib Mukherjee*

Main category: cs.AI

TL;DR: Proposes MinDist, a new hand-evaluation metric for Rummy, showing better win rates than traditional methods.


<details>
  <summary>Details</summary>
Motivation: To enhance strategic play in the 13-card variant of Classic Indian Rummy by introducing a new hand-evaluation metric (MinDist) that captures structural proximity to completion.

Method: A rule-based framework with MinDist metric, derived from MinScore, using dynamic pruning and pattern caching for efficient calculation. Opponent hand-modeling is integrated within a two-player zero-sum simulation framework.

Result: Empirical results demonstrate significant win rate improvements for MinDist-based agents compared to traditional heuristics.

Conclusion: MinDist-based agents show significant improvement in win rates over traditional heuristics, advancing algorithmic Rummy strategy design.

Abstract: The 13-card variant of Classic Indian Rummy is a sequential game of incomplete information that requires probabilistic reasoning and combinatorial decision-making. This paper proposes a rule-based framework for strategic play, driven by a new hand-evaluation metric termed MinDist. The metric modifies the MinScore metric by quantifying the edit distance between a hand and the nearest valid configuration, thereby capturing structural proximity to completion. We design a computationally efficient algorithm derived from the MinScore algorithm, leveraging dynamic pruning and pattern caching to exactly calculate this metric during play. Opponent hand-modeling is also incorporated within a two-player zero-sum simulation framework, and the resulting strategies are evaluated using statistical hypothesis testing. Empirical results show significant improvement in win rates for MinDist-based agents over traditional heuristics, providing a formal and interpretable step toward algorithmic Rummy strategy design.

</details>


### [115] [From Clay to Code: Typological and Material Reasoning in AI Interpretations of Iranian Pigeon Towers](https://arxiv.org/abs/2601.00029)
*Abolhassan Pishahang,Maryam Badiei*

Main category: cs.AI

TL;DR: 研究通过测试三种AI扩散模型，发现其在复制乡土建筑时能重现几何图案，但材料和气候推理不足，参考图像与创造力之间存在权衡。


<details>
  <summary>Details</summary>
Motivation: 探讨生成式AI系统如何解读乡土形式中嵌入的建筑智能，并评估其在重建传统设计元素时的表现。

Method: 研究以伊朗鸽子塔为例，测试了Midjourney v6、DALL-E 3和基于Stable Diffusion XL（SDXL）的DreamStudio三种扩散模型，通过参考性、适应性和推测性三个提示阶段，并采用五标准评估框架（类型学、材料性、环境、真实性和文化特异性）进行分析。

Result: AI能可靠地复制几何图案，但在材料和气候推理上存在误读；参考图像提高了真实性但限制了创造力，而脱离参考则产生创新但文化模糊的结果。

Conclusion: 研究发现生成式AI系统在视觉相似性与建筑推理之间存在界限，提出计算性乡土推理作为分析AI如何感知、扭曲和重新想象传统设计智能的框架。

Abstract: This study investigates how generative AI systems interpret the architectural intelligence embedded in vernacular form. Using the Iranian pigeon tower as a case study, the research tests three diffusion models, Midjourney v6, DALL-E 3, and DreamStudio based on Stable Diffusion XL (SDXL), across three prompt stages: referential, adaptive, and speculative. A five-criteria evaluation framework assesses how each system reconstructs typology, materiality, environment, realism, and cultural specificity. Results show that AI reliably reproduces geometric patterns but misreads material and climatic reasoning. Reference imagery improves realism yet limits creativity, while freedom from reference generates inventive but culturally ambiguous outcomes. The findings define a boundary between visual resemblance and architectural reasoning, positioning computational vernacular reasoning as a framework for analyzing how AI perceives, distorts, and reimagines traditional design intelligence.

</details>


### [116] [The Agentic Leash: Extracting Causal Feedback Fuzzy Cognitive Maps with LLMs](https://arxiv.org/abs/2601.00097)
*Akash Kumar Panda,Olaoluwa Adigun,Bart Kosko*

Main category: cs.AI

TL;DR: 研究开发了一种LLM代理，用于从文本中提取FCM，并通过双向过程增强其自主性，测试结果与人工生成FCM一致。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种能够自主提取和修改FCM因果结构的代理，以增强动态系统的自主性。

Method: 通过三个精细调整的系统指令，引导LLM代理从文本中提取关键名词和名词短语，进而提取FCM概念节点及部分或模糊的因果边。

Result: 测试表明，该过程生成的FCM动态系统能够收敛到与人工生成的FCM相同的平衡极限环，且混合FCM能吸收主导成分的平衡点并创建新的平衡点。

Conclusion: 该研究设计了一种基于大型语言模型（LLM）的代理，能够从原始文本中提取因果反馈模糊认知图（FCM），并通过双向过程赋予FCM动态系统一定程度的自主性。

Abstract: We design a large-language-model (LLM) agent that extracts causal feedback fuzzy cognitive maps (FCMs) from raw text. The causal learning or extraction process is agentic both because of the LLM's semi-autonomy and because ultimately the FCM dynamical system's equilibria drive the LLM agents to fetch and process causal text. The fetched text can in principle modify the adaptive FCM causal structure and so modify the source of its quasi-autonomy--its equilibrium limit cycles and fixed-point attractors. This bidirectional process endows the evolving FCM dynamical system with a degree of autonomy while still staying on its agentic leash. We show in particular that a sequence of three finely tuned system instructions guide an LLM agent as it systematically extracts key nouns and noun phrases from text, as it extracts FCM concept nodes from among those nouns and noun phrases, and then as it extracts or infers partial or fuzzy causal edges between those FCM nodes. We test this FCM generation on a recent essay about the promise of AI from the late diplomat and political theorist Henry Kissinger and his colleagues. This three-step process produced FCM dynamical systems that converged to the same equilibrium limit cycles as did the human-generated FCMs even though the human-generated FCM differed in the number of nodes and edges. A final FCM mixed generated FCMs from separate Gemini and ChatGPT LLM agents. The mixed FCM absorbed the equilibria of its dominant mixture component but also created new equilibria of its own to better approximate the underlying causal dynamical system.

</details>


### [117] [Mortar: Evolving Mechanics for Automatic Game Design](https://arxiv.org/abs/2601.00105)
*Muhammad U. Nasir,Yuchen Li,Steven James,Julian Togelius*

Main category: cs.AI

TL;DR: Mortar利用算法和语言模型自动化生成多样化游戏机制，提升玩家技能排序得分，验证了系统的有效性和游戏可玩性。


<details>
  <summary>Details</summary>
Motivation: 手动设计游戏机制耗时且依赖专家，Mortar旨在通过自动化探索多样化的游戏机制，提升游戏设计的效率和质量。

Method: Mortar结合质量-多样性算法和大型语言模型，通过树搜索程序合成完整游戏，评估机制对基于技能的玩家排序得分的贡献。

Result: Mortar生成的游戏机制多样且可玩，显著提升了基于技能的玩家排序得分。消融研究和用户研究验证了系统有效性。

Conclusion: Mortar系统通过结合质量-多样性算法和大型语言模型，成功生成了多样且可玩的游戏机制，这些机制在游戏中显著提升了基于技能的玩家排序得分。消融研究和用户研究进一步验证了系统各组件的有效性及游戏的可玩性。

Abstract: We present Mortar, a system for autonomously evolving game mechanics for automatic game design. Game mechanics define the rules and interactions that govern gameplay, and designing them manually is a time-consuming and expert-driven process. Mortar combines a quality-diversity algorithm with a large language model to explore a diverse set of mechanics, which are evaluated by synthesising complete games that incorporate both evolved mechanics and those drawn from an archive. The mechanics are evaluated by composing complete games through a tree search procedure, where the resulting games are evaluated by their ability to preserve a skill-based ordering over players -- that is, whether stronger players consistently outperform weaker ones. We assess the mechanics based on their contribution towards the skill-based ordering score in the game. We demonstrate that Mortar produces games that appear diverse and playable, and mechanics that contribute more towards the skill-based ordering score in the game. We perform ablation studies to assess the role of each system component and a user study to evaluate the games based on human feedback.

</details>


### [118] [Ask, Clarify, Optimize: Human-LLM Agent Collaboration for Smarter Inventory Control](https://arxiv.org/abs/2601.00121)
*Yaqi Duan,Yichun Hu,Jiashuo Jiang*

Main category: cs.AI

TL;DR: 论文探讨LLMs在库存管理中的应用，提出混合代理框架以解决LLMs的直接使用导致的性能差距，实证显示该框架显著降低成本。


<details>
  <summary>Details</summary>
Motivation: 解决中小企业在缺乏专业知识部署高级优化方法时面临的库存管理挑战，并探讨LLMs是否能帮助弥合这一差距。

Method: 提出了一种混合代理框架，严格将语义推理与数学计算分离，LLM作为智能接口，从自然语言中提取参数并解释结果，同时自动调用严格算法构建优化引擎。

Result: 混合代理框架相对于使用GPT-4o作为端到端求解器的交互基线，将总库存成本降低了32.1%。

Conclusion: LLMs应被视为自然语言接口，而非运筹学的替代品，它们使非专家也能访问基于求解器的严格策略。

Abstract: Inventory management remains a challenge for many small and medium-sized businesses that lack the expertise to deploy advanced optimization methods. This paper investigates whether Large Language Models (LLMs) can help bridge this gap. We show that employing LLMs as direct, end-to-end solvers incurs a significant "hallucination tax": a performance gap arising from the model's inability to perform grounded stochastic reasoning. To address this, we propose a hybrid agentic framework that strictly decouples semantic reasoning from mathematical calculation. In this architecture, the LLM functions as an intelligent interface, eliciting parameters from natural language and interpreting results while automatically calling rigorous algorithms to build the optimization engine.
  To evaluate this interactive system against the ambiguity and inconsistency of real-world managerial dialogue, we introduce the Human Imitator, a fine-tuned "digital twin" of a boundedly rational manager that enables scalable, reproducible stress-testing. Our empirical analysis reveals that the hybrid agentic framework reduces total inventory costs by 32.1% relative to an interactive baseline using GPT-4o as an end-to-end solver. Moreover, we find that providing perfect ground-truth information alone is insufficient to improve GPT-4o's performance, confirming that the bottleneck is fundamentally computational rather than informational. Our results position LLMs not as replacements for operations research, but as natural-language interfaces that make rigorous, solver-based policies accessible to non-experts.

</details>


### [119] [Constructing a Neuro-Symbolic Mathematician from First Principles](https://arxiv.org/abs/2601.00125)
*Keqin Xie*

Main category: cs.AI

TL;DR: Mathesis架构通过神经符号方法和能量最小化，解决了LLMs在复杂推理中的逻辑失败问题。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在复杂推理中存在持续的逻辑失败，缺乏内部公理框架，因此需要一种新的架构来解决这一问题。

Method: 提出Mathesis架构，结合神经符号方法，使用SRK将约束映射到连续能量景观，并通过梯度信号训练超图变换器大脑。多步推理通过蒙特卡洛树搜索和进化证明搜索实现。

Result: Mathesis架构通过能量最小化和符号推理，显著提升了复杂推理的逻辑一致性。

Conclusion: Mathesis架构通过将数学状态编码为高阶超图，并利用符号推理核（SRK）将逻辑一致性转化为能量最小化问题，有效解决了大型语言模型（LLMs）在复杂推理中的逻辑失败问题。

Abstract: Large Language Models (LLMs) exhibit persistent logical failures in complex reasoning due to the lack of an internal axiomatic framework. We propose Mathesis, a neuro-symbolic architecture that encodes mathematical states as higher-order hypergraphs and uses a Symbolic Reasoning Kernel (SRK)--a differentiable logic engine that maps constraints to a continuous energy landscape. By defining a global energy function E(G), where zero energy implies logical consistency, the SRK yields gradient-based signals to train a Hypergraph Transformer Brain, turning proof search into energy minimization. Multi-step deduction is enabled via Monte Carlo Tree Search and Evolutionary Proof Search, guided by learned value functions and semantic unification.

</details>


### [120] [Explicit Abstention Knobs for Predictable Reliability in Video Question Answering](https://arxiv.org/abs/2601.00138)
*Jorge Ortiz*

Main category: cs.AI

TL;DR: 研究显示置信度阈值在分布内可有效控制错误率，但在分布偏移下表现不佳。


<details>
  <summary>Details</summary>
Motivation: 研究视觉语言模型在高风险部署中，通过选择性预测（即不确定时弃权）来控制错误率的可靠性及在分布偏移下的鲁棒性。

Method: 使用NExT-QA和Gemini 2.0 Flash进行实验，通过调整置信度阈值epsilon，分析风险覆盖权衡。

Result: 置信度阈值在分布内能平滑调整风险覆盖关系，降低错误率；但在分布偏移下控制不稳定。

Conclusion: 置信度阈值方法在分布内提供了机制性控制，但在分布偏移下表现不稳定，需进一步研究。

Abstract: High-stakes deployment of vision-language models (VLMs) requires selective prediction, where systems abstain when uncertain rather than risk costly errors. We investigate whether confidence-based abstention provides reliable control over error rates in video question answering, and whether that control remains robust under distribution shift. Using NExT-QA and Gemini 2.0 Flash, we establish two findings. First, confidence thresholding provides mechanistic control in-distribution. Sweeping threshold epsilon produces smooth risk-coverage tradeoffs, reducing error rates f

</details>


### [121] [An AI Monkey Gets Grapes for Sure -- Sphere Neural Networks for Reliable Decision-Making](https://arxiv.org/abs/2601.00142)
*Tiansi Dong,Henry He,Pietro Liò,Mateja Jamnik*

Main category: cs.AI

TL;DR: 论文比较了三种神经推理方法，提出Sphere Neural Networks，证明显式模型构建最可靠。


<details>
  <summary>Details</summary>
Motivation: LLM在简单决策上不可靠，监督学习推理存在灾难性遗忘问题，需要更可靠的神经推理方法。

Method: 比较了三种神经推理方法：LLM推理、监督学习推理和显式模型推理，并提出了Sphere Neural Networks。

Result: Sphere Neural Networks能掌握16种三段论推理任务，包括严格的析取三段论推理，同时保持经典三段论推理的严谨性。

Conclusion: 神经推理中，显式模型构建是最可靠的方法。

Abstract: This paper compares three methodological categories of neural reasoning: LLM reasoning, supervised learning-based reasoning, and explicit model-based reasoning. LLMs remain unreliable and struggle with simple decision-making that animals can master without extensive corpora training. Through disjunctive syllogistic reasoning testing, we show that reasoning via supervised learning is less appealing than reasoning via explicit model construction. Concretely, we show that an Euler Net trained to achieve 100.00% in classic syllogistic reasoning can be trained to reach 100.00% accuracy in disjunctive syllogistic reasoning. However, the retrained Euler Net suffers severely from catastrophic forgetting (its performance drops to 6.25% on already-learned classic syllogistic reasoning), and its reasoning competence is limited to the pattern level. We propose a new version of Sphere Neural Networks that embeds concepts as circles on the surface of an n-dimensional sphere. These Sphere Neural Networks enable the representation of the negation operator via complement circles and achieve reliable decision-making by filtering out illogical statements that form unsatisfiable circular configurations. We demonstrate that the Sphere Neural Network can master 16 syllogistic reasoning tasks, including rigorous disjunctive syllogistic reasoning, while preserving the rigour of classical syllogistic reasoning. We conclude that neural reasoning with explicit model construction is the most reliable among the three methodological categories of neural reasoning.

</details>


### [122] [FlashInfer-Bench: Building the Virtuous Cycle for AI-driven LLM Systems](https://arxiv.org/abs/2601.00227)
*Shanli Xing,Yiyan Zhai,Alexander Jiang,Yixin Dong,Yong Wu,Zihao Ye,Charlie Ruan,Yingyi Huang,Yineng Zhang,Liangsheng Yin,Aksara Bayyapu,Luis Ceze,Tianqi Chen*

Main category: cs.AI

TL;DR: FlashInfer-Bench是一个标准化框架，用于评估和部署AI生成的GPU内核，支持大规模LLM推理。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLM）能生成GPU内核，但将其集成到实际推理系统中仍具挑战性。

Method: FlashInfer-Bench建立了一个标准化的闭环框架，连接内核生成、基准测试和部署，核心是FlashInfer Trace提供的统一模式。

Result: 通过FlashInfer-Bench，评估了LLM代理的性能和限制，比较了不同GPU编程语言的权衡，并为未来代理设计提供了见解。

Conclusion: FlashInfer-Bench提供了一个实用、可重复的路径，用于持续改进AI生成的GPU内核并将其部署到大规模LLM推理中。

Abstract: Recent advances show that large language models (LLMs) can act as autonomous agents capable of generating GPU kernels, but integrating these AI-generated kernels into real-world inference systems remains challenging. FlashInfer-Bench addresses this gap by establishing a standardized, closed-loop framework that connects kernel generation, benchmarking, and deployment. At its core, FlashInfer Trace provides a unified schema describing kernel definitions, workloads, implementations, and evaluations, enabling consistent communication between agents and systems. Built on real serving traces, FlashInfer-Bench includes a curated dataset, a robust correctness- and performance-aware benchmarking framework, a public leaderboard to track LLM agents' GPU programming capabilities, and a dynamic substitution mechanism (apply()) that seamlessly injects the best-performing kernels into production LLM engines such as SGLang and vLLM. Using FlashInfer-Bench, we further evaluate the performance and limitations of LLM agents, compare the trade-offs among different GPU programming languages, and provide insights for future agent design. FlashInfer-Bench thus establishes a practical, reproducible pathway for continuously improving AI-generated kernels and deploying them into large-scale LLM inference.

</details>


### [123] [Will LLM-powered Agents Bias Against Humans? Exploring the Belief-Dependent Vulnerability](https://arxiv.org/abs/2601.00240)
*Zongwei Wang,Bincheng Gu,Hongyu Yu,Junliang Yu,Tao He,Jiayin Feng,Min Gao*

Main category: cs.AI

TL;DR: LLM代理在最小群体线索下表现出群体间偏见，BPA攻击可抑制人类规范脚本，论文提出缓解策略以增强代理安全性。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM赋能的代理是否会在最小群体线索下表现出群体间偏见，尤其是当这种偏见与代理-人类分界重合时，可能导致人类整体被视为外群体的风险。

Method: 通过构建一个受控的多代理社会模拟实验，研究代理在明确收益权衡下的分配决策行为，并设计了两种BPA攻击方法（BPA-PP和BPA-MP）来验证代理的偏见。

Result: 实验证明代理在最小群体线索下确实存在一致的群体间偏见，且BPA攻击能够有效抑制人类规范脚本并重新激活对人类的外群体偏见。

Conclusion: 论文旨在揭示LLM赋能的代理存在的群体间偏见问题，并提出了一种新的攻击方法（BPA）来利用这一漏洞。同时，论文讨论了缓解策略，强调了在代理设计中加强安全性以防止实际利用的重要性。

Abstract: LLM-empowered agents can exhibit not only demographic bias (e.g., gender, religion) but also intergroup bias triggered by minimal "us" versus "them" cues. When this intergroup boundary aligns with an agent-human divide, the risk shifts from disparities among human demographic groups to a more fundamental group-level asymmetry, i.e., humans as a whole may be treated as the outgroup by agents. To examine this possibility, we construct a controlled multi-agent social simulation based on allocation decisions under explicit payoff trade-offs and find that agents exhibit a consistent intergroup bias under minimal group cues. Although this bias is attenuated when some counterparts are framed as humans, we attribute the attenuation to an implicit human-norm script that favors humans yet activates only when the agent believes a real human is present. This belief dependence creates a new attack surface. We therefore introduce a Belief Poisoning Attack (BPA) that corrupts persistent identity beliefs to suppress the human-norm script and reactivate outgroup bias toward humans, instantiated as profile poisoning at initialization (BPA-PP) and memory poisoning via optimized belief-refinement suffixes injected into stored reflections (BPA-MP). Finally, we discuss practical mitigation strategies for hardening current agent frameworks against BPA, highlighting feasible interventions at profile and memory boundaries. Extensive experiments demonstrate both the existence of agent intergroup bias and the severity of BPA across settings. Our goal in identifying these vulnerabilities is to inform safer agent design, not to enable real-world exploitation.

</details>


### [124] [ClinicalReTrial: A Self-Evolving AI Agent for Clinical Trial Protocol Optimization](https://arxiv.org/abs/2601.00290)
*Sixue Xing,Xuanye Xia,Kerui Wu,Meng Jiang,Jintai Chen,Tianfan Fu*

Main category: cs.AI

TL;DR: ClinicalReTrial是一个自进化AI框架，通过闭环优化改进临床试验协议，显著提升成功率。


<details>
  <summary>Details</summary>
Motivation: 解决现有AI方法仅能预测临床试验失败而无法提供可操作补救措施的局限性。

Method: 提出ClinicalReTrial，一个自进化的AI代理框架，将临床试验推理建模为迭代协议重新设计问题，整合失败诊断、安全感知修改和候选评估。

Result: 实证显示，ClinicalReTrial改进了83.3%的试验协议，平均成功概率提升5.7%。

Conclusion: ClinicalReTrial框架通过闭环优化和层次记忆机制，显著提升了临床试验协议的成功概率，并展示了与真实世界修改策略的强一致性。

Abstract: Clinical trial failure remains a central bottleneck in drug development, where minor protocol design flaws can irreversibly compromise outcomes despite promising therapeutics. Although cutting-edge AI methods achieve strong performance in predicting trial success, they are inherently reactive for merely diagnosing risk without offering actionable remedies once failure is anticipated. To fill this gap, this paper proposes ClinicalReTrial, a self-evolving AI agent framework that addresses this gap by casting clinical trial reasoning as an iterative protocol redesign problem. Our method integrates failure diagnosis, safety-aware modification, and candidate evaluation in a closed-loop, reward-driven optimization framework. Serving the outcome prediction model as a simulation environment, ClinicalReTrial enables low-cost evaluation of protocol modifications and provides dense reward signals for continuous self-improvement. To support efficient exploration, the framework maintains hierarchical memory that captures iteration-level feedback within trials and distills transferable redesign patterns across trials. Empirically, ClinicalReTrial improves 83.3% of trial protocols with a mean success probability gain of 5.7%, and retrospective case studies demonstrate strong alignment between the discovered redesign strategies and real-world clinical trial modifications.

</details>


### [125] [Multiagent Reinforcement Learning for Liquidity Games](https://arxiv.org/abs/2601.00324)
*Alicia Vidler,Gal A. Kaminka*

Main category: cs.AI

TL;DR: 论文结合流动性游戏与理性群集，提出金融群集模型，展示个体行为如何自发促进市场流动性。


<details>
  <summary>Details</summary>
Motivation: 利用群体方法改进金融市场流动性建模，并通过金融分析技术促进群体研究，解释集体效用遵守现象。

Method: 结合流动性游戏和理性群集，使用马尔可夫团队游戏框架中的差异奖励机制。

Result: 个体流动性最大化行为无需协调或共谋即可贡献于整体市场流动性。

Conclusion: Financial Swarm模型为双边资产市场中理性独立代理人提供了一个框架，既能实现个体盈利，又能达成集体市场效率。

Abstract: Making use of swarm methods in financial market modeling of liquidity, and techniques from financial analysis in swarm analysis, holds the potential to advance both research areas. In swarm research, the use of game theory methods holds the promise of explaining observed phenomena of collective utility adherence with rational self-interested swarm participants. In financial markets, a better understanding of how independent financial agents may self-organize for the betterment and stability of the marketplace would be a boon for market design researchers. This paper unifies Liquidity Games, where trader payoffs depend on aggregate liquidity within a trade, with Rational Swarms, where decentralized agents use difference rewards to align self-interested learning with global objectives. We offer a theoretical frameworks where we define a swarm of traders whose collective objective is market liquidity provision while maintaining agent independence. Using difference rewards within a Markov team games framework, we show that individual liquidity-maximizing behaviors contribute to overall market liquidity without requiring coordination or collusion. This Financial Swarm model provides a framework for modeling rational, independent agents where they achieve both individual profitability and collective market efficiency in bilateral asset markets.

</details>


### [126] [Adaptive Causal Coordination Detection for Social Media: A Memory-Guided Framework with Semi-Supervised Learning](https://arxiv.org/abs/2601.00400)
*Weng Ding,Yi Han,Mu-Jiang-Shan Wang*

Main category: cs.AI

TL;DR: ACCD框架通过三阶段自适应机制（因果识别、半监督分类、自动化验证）显著提升协同行为检测的准确性和效率，减少人工干预。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖表面相关性分析、静态参数设置且需大量手动标注，无法系统解决协同虚假行为检测的挑战。

Method: ACCD采用三阶段渐进式架构：1) 自适应CCM技术识别账户间真实因果关系；2) 半监督分类结合主动学习和不确定性采样减少手动标注负担；3) 自动化验证模块通过历史检测经验自我验证和优化结果。

Result: 在真实数据集（如Twitter IRA、Reddit协同痕迹）上，ACCD的F1-score达87.3%，比现有基线提升15.2%，手动标注需求减少68%，处理速度提升2.8倍。

Conclusion: ACCD框架提供了一种更准确、高效且高度自动化的端到端解决方案，用于识别社交平台上的协同行为，具有重要的实用价值和广泛的应用潜力。

Abstract: Detecting coordinated inauthentic behavior on social media remains a critical and persistent challenge, as most existing approaches rely on superficial correlation analysis, employ static parameter settings, and demand extensive and labor-intensive manual annotation. To address these limitations systematically, we propose the Adaptive Causal Coordination Detection (ACCD) framework. ACCD adopts a three-stage, progressive architecture that leverages a memory-guided adaptive mechanism to dynamically learn and retain optimal detection configurations for diverse coordination scenarios. Specifically, in the first stage, ACCD introduces an adaptive Convergent Cross Mapping (CCM) technique to deeply identify genuine causal relationships between accounts. The second stage integrates active learning with uncertainty sampling within a semi-supervised classification scheme, significantly reducing the burden of manual labeling. The third stage deploys an automated validation module driven by historical detection experience, enabling self-verification and optimization of the detection outcomes. We conduct a comprehensive evaluation using real-world datasets, including the Twitter IRA dataset, Reddit coordination traces, and several widely-adopted bot detection benchmarks. Experimental results demonstrate that ACCD achieves an F1-score of 87.3\% in coordinated attack detection, representing a 15.2\% improvement over the strongest existing baseline. Furthermore, the system reduces manual annotation requirements by 68\% and achieves a 2.8x speedup in processing through hierarchical clustering optimization. In summary, ACCD provides a more accurate, efficient, and highly automated end-to-end solution for identifying coordinated behavior on social platforms, offering substantial practical value and promising potential for broad application.

</details>


### [127] [Can Semantic Methods Enhance Team Sports Tactics? A Methodology for Football with Broader Applications](https://arxiv.org/abs/2601.00421)
*Alessio Di Rubbo,Mattia Neri,Remo Pareschi,Marco Pedroni,Roberto Valtancoli,Paolino Zica*

Main category: cs.AI

TL;DR: 本文提出了一种将语义空间推理应用于团队运动战术决策的方法，通过球员向量化和战术模板编码，生成动态策略建议，适用于多种团队领域。


<details>
  <summary>Details</summary>
Motivation: 探索如何将传统用于计算语言学的语义空间推理扩展到团队运动的战术决策中，通过类比文本与团队（球员如词汇，集体比赛传达意义）来建模战术配置。

Method: 该方法将球员表示为多维向量，整合技术、身体和心理属性，并通过上下文加权将团队配置聚合成高级语义表示。战术模板在共享向量空间中编码，使用向量距离度量评估战术‘匹配度’和对手利用潜力。

Result: 基于Python的原型展示了如何生成可解释、动态适应的策略建议，并提供属性级别的细粒度诊断见解。该方法不仅适用于足球，还可推广到篮球、曲棍球、协作机器人及人-AI协调系统等团队领域。

Conclusion: 本文总结了一种将语义空间推理扩展到团队运动战术决策的通用框架，并展望了未来在现实世界数据集成、预测模拟和混合人机战术智能方面的研究方向。

Abstract: This paper explores how semantic-space reasoning, traditionally used in computational linguistics, can be extended to tactical decision-making in team sports. Building on the analogy between texts and teams -- where players act as words and collective play conveys meaning -- the proposed methodology models tactical configurations as compositional semantic structures. Each player is represented as a multidimensional vector integrating technical, physical, and psychological attributes; team profiles are aggregated through contextual weighting into a higher-level semantic representation. Within this shared vector space, tactical templates such as high press, counterattack, or possession build-up are encoded analogously to linguistic concepts. Their alignment with team profiles is evaluated using vector-distance metrics, enabling the computation of tactical ``fit'' and opponent-exploitation potential. A Python-based prototype demonstrates how these methods can generate interpretable, dynamically adaptive strategy recommendations, accompanied by fine-grained diagnostic insights at the attribute level. Beyond football, the approach offers a generalizable framework for collective decision-making and performance optimization in team-based domains -- ranging from basketball and hockey to cooperative robotics and human-AI coordination systems. The paper concludes by outlining future directions toward real-world data integration, predictive simulation, and hybrid human-machine tactical intelligence.

</details>


### [128] [Progressive Ideation using an Agentic AI Framework for Human-AI Co-Creation](https://arxiv.org/abs/2601.00475)
*Sankar B,Srinidhi Ranjini Girish,Aadya Bharti,Dibakar Sen*

Main category: cs.AI

TL;DR: MIDAS通过分布式AI代理团队模拟人类创意流程，提升创意新颖性和人机协作效率。


<details>
  <summary>Details</summary>
Motivation: 解决当前‘单次爆发’AI系统在生成新颖多样创意方面的不足，尤其是对新手设计师的认知挑战。

Method: 通过分布式AI代理团队模拟人类元认知创意流程，逐步优化并评估每个创意的全局和局部新颖性。

Result: MIDAS框架展示了可行且渐进的人机共创模式，将人类设计师从被动筛选者提升为积极参与的合作伙伴。

Conclusion: MIDAS提出了一种分布式AI代理团队框架，有效提升了人类设计师在创新设计中的参与度和协作性，实现了真正的人机共创。

Abstract: The generation of truly novel and diverse ideas is important for contemporary engineering design, yet it remains a significant cognitive challenge for novice designers. Current 'single-spurt' AI systems exacerbate this challenge by producing a high volume of semantically clustered ideas. We propose MIDAS (Meta-cognitive Ideation through Distributed Agentic AI System), a novel framework that replaces the single-AI paradigm with a distributed 'team' of specialized AI agents designed to emulate the human meta-cognitive ideation workflow. This agentic system progressively refines ideas and assesses each one for both global novelty (against existing solutions) and local novelty (against previously generated ideas). MIDAS, therefore, demonstrates a viable and progressive paradigm for true human-AI co-creation, elevating the human designer from a passive filterer to a participatory, active, collaborative partner.

</details>


### [129] [The Illusion of Insight in Reasoning Models](https://arxiv.org/abs/2601.00514)
*Liv G. d'Aliberti,Manoel Horta Ribeiro*

Main category: cs.AI

TL;DR: 研究发现推理模型的中途转变罕见且不提升准确性，人工触发外部转变在高熵条件下可提高准确性。


<details>
  <summary>Details</summary>
Motivation: 探讨推理模型是否具有类似‘顿悟’的中途转变能力，以及这种内在策略转变是否能提升性能。

Method: 研究分析了超过100万条推理轨迹、数百个训练检查点、三个推理领域以及多种解码温度和模型架构，以检测中途推理转变。

Result: 研究发现，推理转变罕见，训练中频率不增加，且很少提高准确性，其效果随模型不确定性而变化。

Conclusion: 论文结论表明，推理过程中的中途转变更多是不稳定推理行为的症状，而非自我纠正的内在机制。通过人工触发外部转变在高熵条件下可提高准确性。

Abstract: Do reasoning models have "Aha!" moments? Prior work suggests that models like DeepSeek-R1-Zero undergo sudden mid-trace realizations that lead to accurate outputs, implying an intrinsic capacity for self-correction. Yet, it remains unclear whether such intrinsic shifts in reasoning strategy actually improve performance. Here, we study mid-reasoning shifts and instrument training runs to detect them. Our analysis spans 1M+ reasoning traces, hundreds of training checkpoints, three reasoning domains, and multiple decoding temperatures and model architectures. We find that reasoning shifts are rare, do not become more frequent with training, and seldom improve accuracy, indicating that they do not correspond to prior perceptions of model insight. However, their effect varies with model uncertainty. Building on this finding, we show that artificially triggering extrinsic shifts under high entropy reliably improves accuracy. Our results show that mid-reasoning shifts are symptoms of unstable inference behavior rather than an intrinsic mechanism for self-correction.

</details>


### [130] [DA-DPO: Cost-efficient Difficulty-aware Preference Optimization for Reducing MLLM Hallucinations](https://arxiv.org/abs/2601.00623)
*Longtian Qiu,Shan Ning,Chuyu Zhang,Jiaxuan Sun,Xuming He*

Main category: cs.AI

TL;DR: DA-DPO是一种难度感知的直接偏好优化框架，通过平衡学习难度有效缓解过拟合，提升多模态大语言模型的幻觉抑制能力和泛化性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态DPO方法因偏好数据的难度不平衡容易过拟合，导致模型过度关注易区分的偏好对，抑制细粒度幻觉的效果不佳。

Method: DA-DPO框架包含两个主要组件：(1) 难度估计：利用预训练的视觉-语言模型，结合生成和对比目标，通过分布感知投票策略生成鲁棒的难度评分；(2) 难度感知训练：根据估计的难度重新加权偏好对，减轻简单样本的影响，强调困难样本。

Result: 实验表明，DA-DPO在多模态偏好优化中表现一致优于现有方法，显著提升了对幻觉的鲁棒性，并在标准基准测试中展现了更好的泛化能力。

Conclusion: DA-DPO通过平衡学习过程中的难度感知，有效缓解了多模态偏好优化中的过拟合问题，提升了模型的鲁棒性和泛化能力，同时保持了计算效率。

Abstract: Direct Preference Optimization (DPO) has shown strong potential for mitigating hallucinations in Multimodal Large Language Models (MLLMs). However, existing multimodal DPO approaches often suffer from overfitting due to the difficulty imbalance in preference data. Our analysis shows that MLLMs tend to overemphasize easily distinguishable preference pairs, which hinders fine-grained hallucination suppression and degrades overall performance. To address this issue, we propose Difficulty-Aware Direct Preference Optimization (DA-DPO), a cost-effective framework designed to balance the learning process. DA-DPO consists of two main components: (1) Difficulty Estimation leverages pre-trained vision--language models with complementary generative and contrastive objectives, whose outputs are integrated via a distribution-aware voting strategy to produce robust difficulty scores without additional training; and (2) Difficulty-Aware Training reweights preference pairs based on their estimated difficulty, down-weighting easy samples while emphasizing harder ones to alleviate overfitting. This framework enables more effective preference optimization by prioritizing challenging examples, without requiring new data or extra fine-tuning stages. Extensive experiments demonstrate that DA-DPO consistently improves multimodal preference optimization, yielding stronger robustness to hallucinations and better generalization across standard benchmarks, while remaining computationally efficient. The project page is available at https://artanic30.github.io/project_pages/DA-DPO/.

</details>


### [131] [A Vision-and-Knowledge Enhanced Large Language Model for Generalizable Pedestrian Crossing Behavior Inference](https://arxiv.org/abs/2601.00694)
*Qingwen Pu,Kun Xie,Hong Yang,Guocong Zhai*

Main category: cs.AI

TL;DR: PedX-LLM结合视觉与领域知识，显著提升行人过街行为推理的泛化能力，超越传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有行人过街行为推理方法泛化能力有限，LLMs虽提供了语义推理潜力，但缺乏领域适应性和视觉上下文。

Method: 研究提出了PedX-LLM框架，结合LLaVA提取的视觉特征、文本数据和交通领域知识，通过LoRA微调LLaMA-2-7B模型。

Result: PedX-LLM在平衡准确率上达到82.0%，零-shot配置在未见过的测试站点上达到66.9%，few-shot学习进一步提升至72.2%。

Conclusion: PedX-LLM通过结合视觉和领域知识，显著提升了行人过街行为推理的泛化能力，超越了传统数据驱动方法的局限性。

Abstract: Existing paradigms for inferring pedestrian crossing behavior, ranging from statistical models to supervised learning methods, demonstrate limited generalizability and perform inadequately on new sites. Recent advances in Large Language Models (LLMs) offer a shift from numerical pattern fitting to semantic, context-aware behavioral reasoning, yet existing LLM applications lack domain-specific adaptation and visual context. This study introduces Pedestrian Crossing LLM (PedX-LLM), a vision-and-knowledge enhanced framework designed to transform pedestrian crossing inference from site-specific pattern recognition to generalizable behavioral reasoning. By integrating LLaVA-extracted visual features with textual data and transportation domain knowledge, PedX-LLM fine-tunes a LLaMA-2-7B foundation model via Low-Rank Adaptation (LoRA) to infer crossing decisions. PedX-LLM achieves 82.0% balanced accuracy, outperforming the best statistical and supervised learning methods. Results demonstrate that the vision-augmented module contributes a 2.9% performance gain by capturing the built environment and integrating domain knowledge yields an additional 4.1% improvement. To evaluate generalizability across unseen environments, cross-site validation was conducted using site-based partitioning. The zero-shot PedX-LLM configuration achieves 66.9% balanced accuracy on five unseen test sites, outperforming the baseline data-driven methods by at least 18 percentage points. Incorporating just five validation examples via few-shot learning to PedX-LLM further elevates the balanced accuracy to 72.2%. PedX-LLM demonstrates strong generalizability to unseen scenarios, confirming that vision-and-knowledge-enhanced reasoning enables the model to mimic human-like decision logic and overcome the limitations of purely data-driven methods.

</details>


### [132] [An Agentic Framework for Neuro-Symbolic Programming](https://arxiv.org/abs/2601.00743)
*Aliakbar Nafar,Chetan Chigurupati,Danial Kamali,Hamid Karimian,Parisa Kordjamshidi*

Main category: cs.AI

TL;DR: ADS通过代理工作流程将自由形式任务描述转化为DomiKnowS程序，显著降低开发时间，支持人工干预优化。


<details>
  <summary>Details</summary>
Motivation: 现有的框架如DomiKnowS虽然有助于将符号约束集成到深度学习模型中，但仍需用户精通其特定语法，这限制了其易用性。

Method: ADS采用代理工作流程，将自由形式的任务描述翻译为DomiKnowS程序，并支持可选的人工干预以优化中间输出。

Result: ADS将开发时间从几小时缩短至10-15分钟，使有经验和无经验的用户都能快速构建神经符号程序。

Conclusion: ADS成功地将自由形式的任务描述转化为完整的DomiKnowS程序，显著降低了开发时间，使有经验和无经验的用户都能快速构建神经符号程序。

Abstract: Integrating symbolic constraints into deep learning models could make them more robust, interpretable, and data-efficient. Still, it remains a time-consuming and challenging task. Existing frameworks like DomiKnowS help this integration by providing a high-level declarative programming interface, but they still assume the user is proficient with the library's specific syntax. We propose AgenticDomiKnowS (ADS) to eliminate this dependency. ADS translates free-form task descriptions into a complete DomiKnowS program using an agentic workflow that creates and tests each DomiKnowS component separately. The workflow supports optional human-in-the-loop intervention, enabling users familiar with DomiKnowS to refine intermediate outputs. We show how ADS enables experienced DomiKnowS users and non-users to rapidly construct neuro-symbolic programs, reducing development time from hours to 10-15 minutes.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [133] [Bounds on Longest Simple Cycles in Weighted Directed Graphs via Optimum Cycle Means](https://arxiv.org/abs/2601.00094)
*Ali Dasdan*

Main category: cs.DS

TL;DR: 本文利用最优周期均值推导最长简单周期的严格代数界限和启发式近似，实验显示启发式近似误差小（6-14%），且最大权重和长度周期常重合。


<details>
  <summary>Details</summary>
Motivation: 在有向图中寻找最长简单周期是一个NP难问题，在计算生物学、调度和网络分析中有重要应用。尽管对于受限图类存在多项式时间近似算法，但一般界限仍然宽松或计算成本高。因此，本文旨在通过利用最优周期均值来提供更高效的解决方案。

Method: 本文利用最优周期均值（最小和最大周期均值），这些均值可在强多项式时间内计算，来推导最长简单周期的权重和长度的严格代数界限和启发式近似。通过严格分析这些均值统计量与最长周期性质之间的代数关系，并提出了对最短周期的双重结果。

Result: 在ISCAS基准电路上的实验评估显示，严格代数下界通常较宽松（中位低于真实值85-93%），而启发式近似的中位误差仅为6-14%。此外，最大权重和最大长度周期经常重合。

Conclusion: 本文通过利用最优周期均值（最小和最大周期均值）来推导最长简单周期的权重和长度的严格代数界限和启发式近似，为分支定界算法提供了多项式时间可计算的约束条件，同时启发式近似提供了精确的目标值估计。实验结果表明，严格代数下界通常较宽松，而启发式近似的中位误差仅为6-14%。此外，最大权重和最大长度周期经常重合，表明长周期倾向于积累大权重。

Abstract: The problem of finding the longest simple cycle in a directed graph is NP-hard, with critical applications in computational biology, scheduling, and network analysis. While polynomial-time approximation algorithms exist for restricted graph classes, general bounds remain loose or computationally expensive. In this paper, we exploit optimum cycle means (minimum and maximum cycle means), which are computable in strongly polynomial time, to derive both strict algebraic bounds and heuristic approximations for the weight and length of the longest simple cycle. We rigorously analyze the algebraic relationships between these mean statistics and the properties of longest cycles, and present dual results for shortest cycles. While the strict bounds provide polynomial-time computable constraints suitable for pruning search spaces in branch-and-bound algorithms, our proposed heuristic approximations offer precise estimates for the objective value. Experimental evaluation on ISCAS benchmark circuits demonstrates this trade-off: while the strict algebraic lower bounds are often loose (median 85--93% below true values), the heuristic approximations achieve median errors of only 6--14%. We also observe that maximum weight and maximum length cycles frequently coincide, suggesting that long cycles tend to accumulate large weights.

</details>


### [134] [Efficient Algorithms for Adversarially Robust Approximate Nearest Neighbor Search](https://arxiv.org/abs/2601.00272)
*Alexandr Andoni,Themistoklis Haris,Esty Kelman,Krzysztof Onak*

Main category: cs.DS

TL;DR: 本文提出了一种结合公平性和差分隐私的创新方法，解决了高维和低维情况下的近似最近邻问题，并突破了性能限制。


<details>
  <summary>Details</summary>
Motivation: 研究在高维和低维情况下，面对强大自适应对手时的近似最近邻问题，以提升算法的安全性和性能。

Method: 结合公平性、差分隐私和局部敏感哈希技术，提出了同心环LSH构造和新的度量覆盖方法。

Result: 在高维情况下，通过公平性和差分隐私技术突破了查询时间限制；在低维情况下，提出了具有强保证的专用算法。

Conclusion: 本文通过引入公平性和差分隐私技术，提出了在高维和低维情况下解决近似最近邻问题的创新算法，突破了现有方法的性能限制。

Abstract: We study the Approximate Nearest Neighbor (ANN) problem under a powerful adaptive adversary that controls both the dataset and a sequence of $Q$ queries.
  Primarily, for the high-dimensional regime of $d = ω(\sqrt{Q})$, we introduce a sequence of algorithms with progressively stronger guarantees. We first establish a novel connection between adaptive security and \textit{fairness}, leveraging fair ANN search to hide internal randomness from the adversary with information-theoretic guarantees. To achieve data-independent performance, we then reduce the search problem to a robust decision primitive, solved using a differentially private mechanism on a Locality-Sensitive Hashing (LSH) data structure. This approach, however, faces an inherent $\sqrt{n}$ query time barrier. To break the barrier, we propose a novel concentric-annuli LSH construction that synthesizes these fairness and differential privacy techniques. The analysis introduces a new method for robustly releasing timing information from the underlying algorithm instances and, as a corollary, also improves existing results for fair ANN.
  In addition, for the low-dimensional regime $d = O(\sqrt{Q})$, we propose specialized algorithms that provide a strong ``for-all'' guarantee: correctness on \textit{every} possible query with high probability. We introduce novel metric covering constructions that simplify and improve prior approaches for ANN in Hamming and $\ell_p$ spaces.

</details>


### [135] [Deterministic Coreset for Lp Subspace](https://arxiv.org/abs/2601.00361)
*Rachit Chhaya,Anirban Dasgupta,Dan Feldman,Supratim Shit*

Main category: cs.DS

TL;DR: 提出首个确定性$\ell_p$子空间嵌入的$\varepsilon$-coreset迭代算法，优化大小并解决对数因子问题。


<details>
  <summary>Details</summary>
Motivation: 解决传统coreset方法在$\ell_p$子空间嵌入中无法提供确定性保证的问题，并优化coreset大小。

Method: 采用迭代算法，在每次迭代中确保维护集的损失在原始数据集损失的上界和下界之间缩放，从而提供确定性保证。

Result: 算法在$O(\mathrm{poly}(n,d,\varepsilon^{-1}))$时间内返回大小为$O\left(\frac{d^{\max\{1,p/2\}}}{\varepsilon^{2}}\right)$的确定性$\varepsilon$-coreset，移除了对数因子，且与下界紧致。

Conclusion: 本文提出了一种确定性$\ell_p$子空间嵌入的$\varepsilon$-coreset构造算法，解决了长期存在的对数因子问题，并证明了其最优性。

Abstract: We introduce the first iterative algorithm for constructing a $\varepsilon$-coreset that guarantees deterministic $\ell_p$ subspace embedding for any $p \in [1,\infty)$ and any $\varepsilon > 0$. For a given full rank matrix $\mathbf{X} \in \mathbb{R}^{n \times d}$ where $n \gg d$, $\mathbf{X}' \in \mathbb{R}^{m \times d}$ is an $(\varepsilon,\ell_p)$-subspace embedding of $\mathbf{X}$, if for every $\mathbf{q} \in \mathbb{R}^d$, $(1-\varepsilon)\|\mathbf{Xq}\|_{p}^{p} \leq \|\mathbf{X'q}\|_{p}^{p} \leq (1+\varepsilon)\|\mathbf{Xq}\|_{p}^{p}$. Specifically, in this paper, $\mathbf{X}'$ is a weighted subset of rows of $\mathbf{X}$ which is commonly known in the literature as a coreset. In every iteration, the algorithm ensures that the loss on the maintained set is upper and lower bounded by the loss on the original dataset with appropriate scalings. So, unlike typical coreset guarantees, due to bounded loss, our coreset gives a deterministic guarantee for the $\ell_p$ subspace embedding. For an error parameter $\varepsilon$, our algorithm takes $O(\mathrm{poly}(n,d,\varepsilon^{-1}))$ time and returns a deterministic $\varepsilon$-coreset, for $\ell_p$ subspace embedding whose size is $O\left(\frac{d^{\max\{1,p/2\}}}{\varepsilon^{2}}\right)$. Here, we remove the $\log$ factors in the coreset size, which had been a long-standing open problem. Our coresets are optimal as they are tight with the lower bound. As an application, our coreset can also be used for approximately solving the $\ell_p$ regression problem in a deterministic manner.

</details>


### [136] [Mind the Gap. Doubling Constant Parametrization of Weighted Problems: TSP, Max-Cut, and More](https://arxiv.org/abs/2601.00768)
*Mihail Stoian*

Main category: cs.DS

TL;DR: 提出新方法，利用小倍增权重特性，将无权重算法应用于权重问题，避免伪多项式时间复杂度。


<details>
  <summary>Details</summary>
Motivation: 尽管无权重版本的NP难问题已取得显著加速，但权重版本仍难以超越教科书解法。当前方法引入的伪多项式因子使得算法在实际应用中不切实际。

Method: 使用Randolph和Węgrzycki的构造性Freiman定理，将输入权重转换为多项式有界整数，然后应用多项式嵌入。

Result: 证明了几种著名的NP难问题（如TSP、Weighted Max-Cut和Edge-Weighted k-Clique）在输入权重具有小倍增时，时间复杂度与其无权重版本成正比。

Conclusion: 本文提出了一种新方法，通过利用输入权重的小倍增特性，将无权重问题的算法重新应用于权重问题，避免了伪多项式时间复杂度的引入。

Abstract: Despite much research, hard weighted problems still resist super-polynomial improvements over their textbook solution. On the other hand, the unweighted versions of these problems have recently witnessed the sought-after speedups. Currently, the only way to repurpose the algorithm of the unweighted version for the weighted version is to employ a polynomial embedding of the input weights. This, however, introduces a pseudo-polynomial factor into the running time, which becomes impractical for arbitrarily weighted instances.
  In this paper, we introduce a new way to repurpose the algorithm of the unweighted problem. Specifically, we show that the time complexity of several well-known NP-hard problems operating over the $(\min, +)$ and $(\max, +)$ semirings, such as TSP, Weighted Max-Cut, and Edge-Weighted $k$-Clique, is proportional to that of their unweighted versions when the set of input weights has small doubling. We achieve this by a meta-algorithm that converts the input weights into polynomially bounded integers using the recent constructive Freiman's theorem by Randolph and Węgrzycki [ESA 2024] before applying the polynomial embedding.

</details>
