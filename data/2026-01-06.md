<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 173]
- [cs.GR](#cs.GR) [Total: 4]
- [cs.DS](#cs.DS) [Total: 6]
- [cs.DC](#cs.DC) [Total: 12]
- [cs.NI](#cs.NI) [Total: 8]
- [cs.SE](#cs.SE) [Total: 24]
- [cs.AI](#cs.AI) [Total: 55]
- [cs.RO](#cs.RO) [Total: 31]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Free Energy-Based Modeling of Emotional Dynamics in Video Advertisements](https://arxiv.org/abs/2601.00812)
*Takashi Ushio,Kazuhiro Onishi,Hideyoshi Yanagisawa*

Main category: cs.CV

TL;DR: 研究通过自由能原理量化广告视频情感，KLD、BS、UN分别对应愉悦、惊喜和习惯化，方法稳健且可扩展。


<details>
  <summary>Details</summary>
Motivation: 为无需依赖生理信号或主观评分的可解释情感估计建立方法基础。

Method: 基于自由能原理，从广告视频的场景级表达特征中量化‘愉悦感’、‘惊喜’和‘习惯化’，利用KLD、BS和UN作为核心指标。

Result: 实验表明KLD反映品牌呈现的‘愉悦感’，BS捕捉信息复杂性引发的‘惊喜’，UN反映元素类型和空间排列不确定性驱动的‘惊喜’，并识别了三种情感模式。方法在超参数设置和泛化测试中表现稳健。

Conclusion: 本研究通过自由能原理量化了广告视频中的情感反应，证明了KLD、BS和UN分别与‘愉悦感’、‘惊喜’和‘习惯化’相关，方法具有稳健性和泛化能力，未来可扩展更多表达元素并验证主观评分。

Abstract: Emotional responses during advertising video viewing are recognized as essential for understanding media effects because they have influenced attention, memory, and purchase intention. To establish a methodological basis for explainable emotion estimation without relying on external information such as physiological signals or subjective ratings, we have quantified "pleasantness," "surprise," and "habituation" solely from scene-level expression features of advertising videos, drawing on the free energy(FE) principle, which has provided a unified account of perception, learning, and behavior. In this framework, Kullback-Leibler divergence (KLD) has captured prediction error, Bayesian surprise (BS) has captured belief updates, and uncertainty (UN) has reflected prior ambiguity, and together they have formed the core components of FE. Using 1,059 15 s food video advertisements, the experiments have shown that KLD has reflected "pleasantness" associated with brand presentation, BS has captured "surprise" arising from informational complexity, and UN has reflected "surprise" driven by uncertainty in element types and spatial arrangements, as well as by the variability and quantity of presented elements. This study also identified three characteristic emotional patterns, namely uncertain stimulus, sustained high emotion, and momentary peak and decay, demonstrating the usefulness of the proposed method. Robustness across nine hyperparameter settings and generalization tests with six types of Japanese advertising videos (three genres and two durations) confirmed that these tendencies remained stable. This work can be extended by integrating a wider range of expression elements and validating the approach through subjective ratings, ultimately guiding the development of technologies that can support the creation of more engaging advertising videos.

</details>


### [2] [Can Generative Models Actually Forge Realistic Identity Documents?](https://arxiv.org/abs/2601.00829)
*Alexander Vinogradov*

Main category: cs.CV

TL;DR: 研究发现，现有生成模型难以伪造具有法医真实性的身份文档，风险可能被高估。


<details>
  <summary>Details</summary>
Motivation: 探讨当代开源和公开可用的扩散生成模型是否能生成足以欺骗人类或自动化验证系统的身份文档伪造品。

Method: 评估了多种公开可用的生成模型家族（如Stable Diffusion、Qwen、Flux、Nano-Banana等）的文本到图像和图像到图像生成流程。

Result: 当前生成模型能模拟文档的表面美学，但无法复制结构和法医真实性。

Conclusion: 当前的开源和公开可用的扩散生成模型虽然能够模拟身份文档的表面美学，但无法复制结构和法医真实性，因此生成身份文档深度伪造达到法医级真实性的风险可能被高估。

Abstract: Generative image models have recently shown significant progress in image realism, leading to public concerns about their potential misuse for document forgery. This paper explores whether contemporary open-source and publicly accessible diffusion-based generative models can produce identity document forgeries that could realistically bypass human or automated verification systems. We evaluate text-to-image and image-to-image generation pipelines using multiple publicly available generative model families, including Stable Diffusion, Qwen, Flux, Nano-Banana, and others. The findings indicate that while current generative models can simulate surface-level document aesthetics, they fail to reproduce structural and forensic authenticity. Consequently, the risk of generative identity document deepfakes achieving forensic-level authenticity may be overestimated, underscoring the value of collaboration between machine learning practitioners and document-forensics experts in realistic risk assessment.

</details>


### [3] [Pediatric Pneumonia Detection from Chest X-Rays:A Comparative Study of Transfer Learning and Custom CNNs](https://arxiv.org/abs/2601.00837)
*Agniv Roy Choudhury*

Main category: cs.CV

TL;DR: 该研究比较了自定义CNN与迁移学习模型（如ResNet50）在儿童肺炎检测中的表现，发现微调后的ResNet50表现最佳，准确率接近完美，具有在资源有限地区作为筛查工具的潜力。


<details>
  <summary>Details</summary>
Motivation: Pneumonia is a leading cause of mortality in children under five, with over 700,000 deaths annually. Accurate diagnosis from chest X-rays is limited by radiologist availability and variability.

Method: A dataset of 5,216 pediatric chest X-rays was split 80/10/10 for training, validation, and testing. Seven models were trained and assessed using accuracy, F1-score, and AUC. Grad-CAM visualizations provided explainability.

Result: Fine-tuned ResNet50 achieved the best performance: 99.43% accuracy, 99.61% F1-score, and 99.93% AUC, with only 3 misclassifications. Fine-tuning outperformed frozen-backbone models by 5.5 percentage points on average. Grad-CAM confirmed clinically relevant lung regions guided predictions.

Conclusion: Transfer learning with fine-tuning substantially outperforms CNNs trained from scratch for pediatric pneumonia detection, showing near-perfect accuracy. This system has strong potential as a screening tool in resource-limited settings. Future work should validate these findings on multi-center and adult datasets.

Abstract: Pneumonia is a leading cause of mortality in children under five, with over 700,000 deaths annually. Accurate diagnosis from chest X-rays is limited by radiologist availability and variability.
  Objective: This study compares custom CNNs trained from scratch with transfer learning (ResNet50, DenseNet121, EfficientNet-B0) for pediatric pneumonia detection, evaluating frozen-backbone and fine-tuning regimes.
  Methods: A dataset of 5,216 pediatric chest X-rays was split 80/10/10 for training, validation, and testing. Seven models were trained and assessed using accuracy, F1-score, and AUC. Grad-CAM visualizations provided explainability.
  Results: Fine-tuned ResNet50 achieved the best performance: 99.43\% accuracy, 99.61\% F1-score, and 99.93\% AUC, with only 3 misclassifications. Fine-tuning outperformed frozen-backbone models by 5.5 percentage points on average. Grad-CAM confirmed clinically relevant lung regions guided predictions.
  Conclusions: Transfer learning with fine-tuning substantially outperforms CNNs trained from scratch for pediatric pneumonia detection, showing near-perfect accuracy. This system has strong potential as a screening tool in resource-limited settings. Future work should validate these findings on multi-center and adult datasets.
  Keywords: Pneumonia detection, deep learning, transfer learning, CNN, chest X-ray, pediatric diagnosis, ResNet, DenseNet, EfficientNet, Grad-CAM.

</details>


### [4] [Unified Review and Benchmark of Deep Segmentation Architectures for Cardiac Ultrasound on CAMUS](https://arxiv.org/abs/2601.00839)
*Zahid Ullah,Muhammad Hilal,Eunsoo Lee,Dragan Pamucar,Jihie Kim*

Main category: cs.CV

TL;DR: 本研究对比了U-Net、Attention U-Net和TransUNet在心脏超声分割任务中的表现，提供了数据预处理和自监督学习的实用建议，并展示了伪标签生成的潜力。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏将心脏影像与深度学习进展相结合的综述与统一实验基准的研究，本研究旨在填补这一空白。

Method: 结合心脏超声分割文献的综述，对U-Net、Attention U-Net和TransUNet三种架构在CAMUS数据集上进行了对比实验，包括多种预处理方法和自监督预训练。

Result: U-Net在NIfTI数据上达到94%的平均Dice分数，Attention U-Net在小区域或低对比度区域表现更优，TransUNet在全局空间建模上表现最强。伪标签生成提高了模型的鲁棒性。

Conclusion: 本研究通过统一且可重复的实验基准，比较了U-Net、Attention U-Net和TransUNet在心脏超声分割任务中的表现，并提供了关于数据预处理、自监督学习和伪标签生成的实用建议。

Abstract: Several review papers summarize cardiac imaging and DL advances, few works connect this overview to a unified and reproducible experimental benchmark. In this study, we combine a focused review of cardiac ultrasound segmentation literature with a controlled comparison of three influential architectures, U-Net, Attention U-Net, and TransUNet, on the Cardiac Acquisitions for Multi-Structure Ultrasound Segmentation (CAMUS) echocardiography dataset. Our benchmark spans multiple preprocessing routes, including native NIfTI volumes, 16-bit PNG exports, GPT-assisted polygon-based pseudo-labels, and self-supervised pretraining (SSL) on thousands of unlabeled cine frames. Using identical training splits, losses, and evaluation criteria, a plain U-Net achieved a 94% mean Dice when trained directly on NIfTI data (preserving native dynamic range), while the PNG-16-bit workflow reached 91% under similar conditions. Attention U-Net provided modest improvements on small or low-contrast regions, reducing boundary leakage, whereas TransUNet demonstrated the strongest generalization on challenging frames due to its ability to model global spatial context, particularly when initialized with SSL. Pseudo-labeling expanded the training set and improved robustness after confidence filtering. Overall, our contributions are threefold: a harmonized, apples-to-apples benchmark of U-Net, Attention U-Net, and TransUNet under standardized CAMUS preprocessing and evaluation; practical guidance on maintaining intensity fidelity, resolution consistency, and alignment when preparing ultrasound data; and an outlook on scalable self-supervision and emerging multimodal GPT-based annotation pipelines for rapid labeling, quality assurance, and targeted dataset curation.

</details>


### [5] [EgoGrasp: World-Space Hand-Object Interaction Estimation from Egocentric Videos](https://arxiv.org/abs/2601.01050)
*Hongming Fu,Wenjia Wang,Xiaozhen Qiao,Shuo Yang,Zheng Liu,Bo Zhao*

Main category: cs.CV

TL;DR: EgoGrasp是首个从动态相机拍摄的自我中心单目视频中重建世界空间手-物体交互的方法，通过多阶段框架和HOI先验模型实现了最先进性能。


<details>
  <summary>Details</summary>
Motivation: 准确的世界空间手-物体交互重建对于理解人类行为和在具身智能与虚拟现实中的应用至关重要。现有方法局限于单幅图像或相机坐标，无法建模时间动态或一致的全局轨迹。

Method: 提出了一个多阶段框架，包括基于新开发的空间智能模型的鲁棒预处理流程、基于解耦扩散模型的全身HOI先验模型，以及多目标测试时优化范式。

Result: 实验证明，该方法在世界空间手-物体交互重建中达到了最先进的性能。

Conclusion: EgoGrasp实现了在动态相机拍摄的自我中心单目视频中进行世界空间手-物体交互（W-HOI）重建的最先进性能。

Abstract: We propose EgoGrasp, the first method to reconstruct world-space hand-object interactions (W-HOI) from egocentric monocular videos with dynamic cameras in the wild. Accurate W-HOI reconstruction is critical for understanding human behavior and enabling applications in embodied intelligence and virtual reality. However, existing hand-object interactions (HOI) methods are limited to single images or camera coordinates, failing to model temporal dynamics or consistent global trajectories. Some recent approaches attempt world-space hand estimation but overlook object poses and HOI constraints. Their performance also suffers under severe camera motion and frequent occlusions common in egocentric in-the-wild videos. To address these challenges, we introduce a multi-stage framework with a robust pre-process pipeline built on newly developed spatial intelligence models, a whole-body HOI prior model based on decoupled diffusion models, and a multi-objective test-time optimization paradigm. Our HOI prior model is template-free and scalable to multiple objects. In experiments, we prove our method achieving state-of-the-art performance in W-HOI reconstruction.

</details>


### [6] [Motion-Compensated Latent Semantic Canvases for Visual Situational Awareness on Edge](https://arxiv.org/abs/2601.00854)
*Igor Lodin,Sergii Filatov,Vira Filatova,Dmytro Filatov*

Main category: cs.CV

TL;DR: MCLSC通过运动补偿和潜在语义画布技术，显著提升了边缘设备上的视觉情境感知效率。


<details>
  <summary>Details</summary>
Motivation: 旨在为资源受限的边缘设备提供高效的视觉情境感知解决方案。

Method: 提出了一种基于运动补偿的潜在语义画布（MCLSC）方法，包括静态和动态两层潜在画布，并通过运动触发分割推理。

Result: 在480p视频片段上，原型系统减少了30倍以上的分割调用，并将端到端处理时间降低了20倍以上。

Conclusion: MCLSC通过维护静态和动态的潜在语义画布，显著减少了分割调用的次数和处理时间，同时保持了语义覆盖的连贯性。

Abstract: We propose Motion-Compensated Latent Semantic Canvases (MCLSC) for visual situational awareness on resource-constrained edge devices. The core idea is to maintain persistent semantic metadata in two latent canvases - a slowly accumulating static layer and a rapidly updating dynamic layer - defined in a baseline coordinate frame stabilized from the video stream. Expensive panoptic segmentation (Mask2Former) runs asynchronously and is motion-gated: inference is triggered only when motion indicates new information, while stabilization/motion compensation preserves a consistent coordinate system for latent semantic memory. On prerecorded 480p clips, our prototype reduces segmentation calls by >30x and lowers mean end-to-end processing time by >20x compared to naive per-frame segmentation, while maintaining coherent static/dynamic semantic overlays.

</details>


### [7] [VL-OrdinalFormer: Vision Language Guided Ordinal Transformers for Interpretable Knee Osteoarthritis Grading](https://arxiv.org/abs/2601.00879)
*Zahid Ullah,Jihie Kim*

Main category: cs.CV

TL;DR: VLOrdinalFormer通过结合视觉语言引导的序数学习框架，显著提升了KOA早期分级的准确性，同时保持临床可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决KOA早期阶段（KL1和KL2）在KL分级系统中因影像学差异细微导致的观察者间变异性问题。

Method: 结合ViT L16骨干网络、CORAL序数回归和CLIP驱动的语义对齐模块，通过分层五折交叉验证、类别感知重加权和测试时间增强优化模型鲁棒性。

Result: 在OAI kneeKL224数据集上，VLOrdinalFormer在宏观F1分数和总体准确率上优于CNN和ViT基线模型，尤其在KL1和KL2分类上有显著提升。

Conclusion: 该研究提出的VLOrdinalFormer框架在KOA分级中表现出色，尤其在早期阶段（KL1和KL2）的分类准确性上有显著提升，同时保持了模型的临床可解释性。

Abstract: Knee osteoarthritis (KOA) is a leading cause of disability worldwide, and accurate severity assessment using the Kellgren Lawrence (KL) grading system is critical for clinical decision making. However, radiographic distinctions between early disease stages, particularly KL1 and KL2, are subtle and frequently lead to inter-observer variability among radiologists. To address these challenges, we propose VLOrdinalFormer, a vision language guided ordinal learning framework for fully automated KOA grading from knee radiographs. The proposed method combines a ViT L16 backbone with CORAL based ordinal regression and a Contrastive Language Image Pretraining (CLIP) driven semantic alignment module, allowing the model to incorporate clinically meaningful textual concepts related to joint space narrowing, osteophyte formation, and subchondral sclerosis. To improve robustness and mitigate overfitting, we employ stratified five fold cross validation, class aware re weighting to emphasize challenging intermediate grades, and test time augmentation with global threshold optimization. Experiments conducted on the publicly available OAI kneeKL224 dataset demonstrate that VLOrdinalFormer achieves state of the art performance, outperforming CNN and ViT baselines in terms of macro F1 score and overall accuracy. Notably, the proposed framework yields substantial performance gains for KL1 and KL2 without compromising classification accuracy for mild or severe cases. In addition, interpretability analyses using Grad CAM and CLIP similarity maps confirm that the model consistently attends to clinically relevant anatomical regions. These results highlight the potential of vision language aligned ordinal transformers as reliable and interpretable tools for KOA grading and disease progression assessment in routine radiological practice.

</details>


### [8] [VideoCuRL: Video Curriculum Reinforcement Learning with Orthogonal Difficulty Decomposition](https://arxiv.org/abs/2601.00887)
*Hongbo Jin,Kuanwei Lin,Wenhao Zhang,Yichen Jin,Ge Li*

Main category: cs.CV

TL;DR: VideoCuRL通过分解视觉和认知难度，提出了一种高效的视频强化学习课程框架，显著提升了性能并降低了推理开销。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习范式在视频理解中主要依赖随机数据洗牌或基于标量难度指标的简单课程策略，无法区分视觉时间感知负荷和认知推理深度这两个正交挑战。

Method: 提出VideoCuRL框架，使用光流和关键帧熵作为视觉复杂度的无训练代理，校准惊讶度作为认知复杂度的代理，将数据映射到二维课程网格，并采用能力感知对角线波前策略进行训练调度。

Result: VideoCuRL在推理任务（VSI-Bench +2.5）和感知任务（VideoMME +2.9）上均优于现有强化学习基线，且消除了生成式课程的高推理开销。

Conclusion: VideoCuRL框架通过分解视觉时间感知负荷和认知推理深度两个正交挑战，提供了一种可扩展的视频后训练解决方案，显著提升了视频理解和推理任务的性能。

Abstract: Reinforcement Learning (RL) is crucial for empowering VideoLLMs with complex spatiotemporal reasoning. However, current RL paradigms predominantly rely on random data shuffling or naive curriculum strategies based on scalar difficulty metrics. We argue that scalar metrics fail to disentangle two orthogonal challenges in video understanding: Visual Temporal Perception Load and Cognitive Reasoning Depth. To address this, we propose VideoCuRL, a novel framework that decomposes difficulty into these two axes. We employ efficient, training-free proxies, optical flow and keyframe entropy for visual complexity, Calibrated Surprisal for cognitive complexity, to map data onto a 2D curriculum grid. A competence aware Diagonal Wavefront strategy then schedules training from base alignment to complex reasoning. Furthermore, we introduce Dynamic Sparse KL and Structured Revisiting to stabilize training against reward collapse and catastrophic forgetting. Extensive experiments show that VideoCuRL surpasses strong RL baselines on reasoning (+2.5 on VSI-Bench) and perception (+2.9 on VideoMME) tasks. Notably, VideoCuRL eliminates the prohibitive inference overhead of generation-based curricula, offering a scalable solution for robust video post-training.

</details>


### [9] [Comparative Evaluation of CNN Architectures for Neural Style Transfer in Indonesian Batik Motif Generation: A Comprehensive Study](https://arxiv.org/abs/2601.00888)
*Happy Gery Pangestu,Andi Prademon Yunus,Siti Khomsah*

Main category: cs.CV

TL;DR: 本研究比较了五种CNN骨干网络在NST中的表现，发现ResNet在效率和结构保留上优于VGG，适合资源有限的蜡染生成应用。


<details>
  <summary>Details</summary>
Motivation: 神经风格迁移（NST）为印度尼西亚蜡染图案的数字保存和生成探索提供了计算框架，但现有方法主要基于VGG架构，其强大的风格表现力以高计算和内存需求为代价，限制了在资源有限环境中的实际部署。

Method: 本研究对五种广泛使用的CNN骨干网络（VGG16、VGG19、Inception V3、ResNet50和ResNet101）进行了系统的比较分析，基于245个对照实验，结合定量指标、定性评估和统计分析，以检验结构保留、风格行为和计算效率之间的权衡。

Result: 结果显示，骨干网络选择在结构相似性上没有产生统计学上的显著差异（ANOVA on SSIM，p=0.83），表明结构保留水平相当而非风格质量相同。基于ResNet的架构比VGG模型快约5-6倍收敛，同时保持相似的感知相似性（LPIPS=0.53），且需要超过16倍的FLOPs（0.63 vs 10.12 GFLOPs）。定性分析揭示了一致的风格权衡，VGG产生更密集的绘画纹理，ResNet倾向于几何稳定性和蜡染笔触保留，风格化较温和，Inception V3表现出中间但更嘈杂的行为。

Conclusion: 研究重新定位了NST中的架构选择，从最大化风格强度转向效率感知和结构保留的部署，突出了基于ResNet的骨干网络作为可扩展、面向行业的蜡染生成的实用基础。

Abstract: Neural Style Transfer (NST) provides a computational framework for the digital preservation and generative exploration of Indonesian batik motifs; however, existing approaches remain largely centered on VGG-based architectures whose strong stylistic expressiveness comes at the cost of high computational and memory demands, that limits practical deployment in resource-limited environments. This study presents a systematic comparative analysis of five widely used CNN backbones, namely VGG16, VGG19, Inception V3, ResNet50, and ResNet101, based on 245 controlled experiments combining quantitative metrics, qualitative assessment, and statistical analysis to examine the trade-off between structural preservation, stylistic behavior, and computational efficiency. The results show that backbone selection does not yield statistically significant differences in structural similarity, as confirmed by ANOVA on SSIM (p= 0.83), indicating comparable levels of structural preservation rather than equivalent stylistic quality. Within this context, ResNet-based architectures achieve approximately 5-6x faster convergence than VGG models while maintaining similar perceptual similarity (LPIPS = 0.53) and requiring over 16x fewer FLOPs (0.63 vs 10.12 GFLOPs). Qualitative analysis reveals consistent stylistic trade-offs, with VGG producing denser painterly textures, ResNet favoring geometric stability and canting stroke preservation with milder stylization, and Inception V3 exhibiting intermediate but noisier behavior. These findings reposition architectural choice in NST from maximizing stylistic intensity toward efficiency-aware and structure-preserving deployment, highlighting ResNet-based backbones as a practical foundation for scalable, industry-oriented batik generation.

</details>


### [10] [CornViT: A Multi-Stage Convolutional Vision Transformer Framework for Hierarchical Corn Kernel Analysis](https://arxiv.org/abs/2601.00897)
*Sai Teja Erukude,Jane Mascarenhas,Lior Shamir*

Main category: cs.CV

TL;DR: CornViT是一个三阶段CvT框架，用于玉米粒分级，准确率高且部署便捷。


<details>
  <summary>Details</summary>
Motivation: 玉米粒的准确分级对种子认证、定向播种和育种至关重要，但目前主要依赖人工检查。

Method: 采用三阶段卷积视觉变换器（CvT）框架，分别进行纯度、形态和胚胎方向分类。

Result: CornViT在纯度、形状和胚胎方向检测上的测试准确率分别为93.76%、94.11%和91.12%，优于ResNet-50和DenseNet-121。

Conclusion: CornViT框架、精选数据集和Web应用为种子质量工作流中的玉米粒自动质量评估提供了可部署的解决方案。

Abstract: Accurate grading of corn kernels is critical for seed certification, directional seeding, and breeding, yet it is still predominantly performed by manual inspection. This work introduces CornViT, a three-stage Convolutional Vision Transformer (CvT) framework that emulates the hierarchical reasoning of human seed analysts for single-kernel evaluation. Three sequential CvT-13 classifiers operate on 384x384 RGB images: Stage 1 distinguishes pure from impure kernels; Stage 2 categorizes pure kernels into flat and round morphologies; and Stage 3 determines the embryo orientation (up vs. down) for pure, flat kernels. Starting from a public corn seed image collection, we manually relabeled and filtered images to construct three stage-specific datasets: 7265 kernels for purity, 3859 pure kernels for morphology, and 1960 pure-flat kernels for embryo orientation, all released as benchmarks. Head-only fine-tuning of ImageNet-22k pretrained CvT-13 backbones yields test accuracies of 93.76% for purity, 94.11% for shape, and 91.12% for embryo-orientation detection. Under identical training conditions, ResNet-50 reaches only 76.56 to 81.02 percent, whereas DenseNet-121 attains 86.56 to 89.38 percent accuracy. These results highlight the advantages of convolution-augmented self-attention for kernel analysis. To facilitate adoption, we deploy CornViT in a Flask-based web application that performs stage-wise inference and exposes interpretable outputs through a browser interface. Together, the CornViT framework, curated datasets, and web application provide a deployable solution for automated corn kernel quality assessment in seed quality workflows. Source code and data are publicly available.

</details>


### [11] [Evaluating Contextual Intelligence in Recyclability: A Comprehensive Study of Image-Based Reasoning Systems](https://arxiv.org/abs/2601.00905)
*Eliot Park,Abhi Kumar,Pranav Rajpurkar*

Main category: cs.CV

TL;DR: 研究利用先进视觉语言模型预测物品可回收性，发现模型在上下文理解上有进步但仍有改进空间。


<details>
  <summary>Details</summary>
Motivation: 高效回收的重要性被广泛认可，但公众准确判断物品的可回收性及其正确处理方式仍是一项复杂任务。

Method: 本研究探索了先进的视觉语言模型（GPT-4o、GPT-4o-mini和Claude 3.5）在预测常见丢弃物品可回收性中的应用，并评估了它们在匹配物品到合适回收箱中的能力。

Result: 研究结果表明，这些模型在上下文理解方面相比之前版本有显著进步，但仍存在不足。

Conclusion: 持续优化上下文感知模型对于提升公众回收实践和推动环境可持续发展至关重要。

Abstract: While the importance of efficient recycling is widely acknowledged, accurately determining the recyclability of items and their proper disposal remains a complex task for the general public. In this study, we explore the application of cutting-edge vision-language models (GPT-4o, GPT-4o-mini, and Claude 3.5) for predicting the recyclability of commonly disposed items. Utilizing a curated dataset of images, we evaluated the models' ability to match objects to appropriate recycling bins, including assessing whether the items could physically fit into the available bins. Additionally, we investigated the models' performance across several challenging scenarios: (i) adjusting predictions based on location-specific recycling guidelines; (ii) accounting for contamination or structural damage; and (iii) handling objects composed of multiple materials. Our findings highlight the significant advancements in contextual understanding offered by these models compared to previous iterations, while also identifying areas where they still fall short. The continued refinement of context-aware models is crucial for enhancing public recycling practices and advancing environmental sustainability.

</details>


### [12] [Clean-GS: Semantic Mask-Guided Pruning for 3D Gaussian Splatting](https://arxiv.org/abs/2601.00913)
*Subhankar Mishra*

Main category: cs.CV

TL;DR: Clean-GS利用稀疏语义掩码去除3D高斯溅射模型中的背景杂波和浮动物，实现高效模型压缩，适合带宽受限应用。


<details>
  <summary>Details</summary>
Motivation: 3D高斯溅射虽能生成高质量场景重建，但会产生大量伪高斯（浮动物），不仅遮挡目标对象，还增加模型大小，限制了在带宽受限应用中的部署。

Method: Clean-GS采用多阶段方法：1）通过投影到掩码区域进行白名单过滤；2）深度缓冲颜色验证；3）基于邻居的异常值去除。该方法仅需3个分割掩码（1%的视图）即可识别并移除不属于目标对象的高斯。

Result: 在Tanks and Temples数据集上的实验表明，Clean-GS将文件大小从125MB减少到47MB，同时保持渲染质量，使3DGS模型更适合网页部署和AR/VR应用。

Conclusion: Clean-GS通过结合白名单空间过滤、颜色引导验证和基于邻居的异常值去除，有效减少了3D高斯溅射模型中的伪高斯（浮动物），实现了60-80%的模型压缩，同时保持了对象质量，使其更适合带宽受限的应用。

Abstract: 3D Gaussian Splatting produces high-quality scene reconstructions but generates hundreds of thousands of spurious Gaussians (floaters) scattered throughout the environment. These artifacts obscure objects of interest and inflate model sizes, hindering deployment in bandwidth-constrained applications. We present Clean-GS, a method for removing background clutter and floaters from 3DGS reconstructions using sparse semantic masks. Our approach combines whitelist-based spatial filtering with color-guided validation and outlier removal to achieve 60-80\% model compression while preserving object quality. Unlike existing 3DGS pruning methods that rely on global importance metrics, Clean-GS uses semantic information from as few as 3 segmentation masks (1\% of views) to identify and remove Gaussians not belonging to the target object. Our multi-stage approach consisting of (1) whitelist filtering via projection to masked regions, (2) depth-buffered color validation, and (3) neighbor-based outlier removal isolates monuments and objects from complex outdoor scenes. Experiments on Tanks and Temples show that Clean-GS reduces file sizes from 125MB to 47MB while maintaining rendering quality, making 3DGS models practical for web deployment and AR/VR applications. Our code is available at https://github.com/smlab-niser/clean-gs

</details>


### [13] [Four-Stage Alzheimer's Disease Classification from MRI Using Topological Feature Extraction, Feature Selection, and Ensemble Learning](https://arxiv.org/abs/2601.00918)
*Faisal Ahmed*

Main category: cs.CV

TL;DR: TDA-Alz 是一种基于拓扑数据分析和集成学习的轻量级框架，用于阿尔茨海默病严重程度分类，具有高准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决阿尔茨海默病（AD）严重程度分类的准确性和效率问题，特别是在数据有限和模型可解释性受限的情况下。

Method: 使用拓扑数据分析（TDA）提取脑 MRI 的拓扑描述符，并通过特征选择保留最具区分性的拓扑特征，然后使用集成学习策略进行分类。

Result: 在 OASIS-1 MRI 数据集上，该方法达到了 98.19% 的准确率和 99.75% 的 AUC，优于或匹配基于深度学习的现有方法。

Conclusion: TDA-Alz 提供了一种强大、轻量级且可解释的替代方案，用于基于 MRI 的阿尔茨海默病严重程度分类，具有在现实世界临床决策支持系统中应用的潜力。

Abstract: Accurate and efficient classification of Alzheimer's disease (AD) severity from brain magnetic resonance imaging (MRI) remains a critical challenge, particularly when limited data and model interpretability are of concern. In this work, we propose TDA-Alz, a novel framework for four-stage Alzheimer's disease severity classification (non-demented, moderate dementia, mild, and very mild) using topological data analysis (TDA) and ensemble learning. Instead of relying on deep convolutional architectures or extensive data augmentation, our approach extracts topological descriptors that capture intrinsic structural patterns of brain MRI, followed by feature selection to retain the most discriminative topological features. These features are then classified using an ensemble learning strategy to achieve robust multiclass discrimination.
  Experiments conducted on the OASIS-1 MRI dataset demonstrate that the proposed method achieves an accuracy of 98.19% and an AUC of 99.75%, outperforming or matching state-of-the-art deep learning--based methods reported on OASIS and OASIS-derived datasets. Notably, the proposed framework does not require data augmentation, pretrained networks, or large-scale computational resources, making it computationally efficient and fast compared to deep neural network approaches. Furthermore, the use of topological descriptors provides greater interpretability, as the extracted features are directly linked to the underlying structural characteristics of brain MRI rather than opaque latent representations. These results indicate that TDA-Alz offers a powerful, lightweight, and interpretable alternative to deep learning models for MRI-based Alzheimer's disease severity classification, with strong potential for real-world clinical decision-support systems.

</details>


### [14] [Application of deep learning techniques in non-contrast computed tomography pulmonary angiogram for pulmonary embolism diagnosis](https://arxiv.org/abs/2601.00925)
*I-Hsien Ting,Yi-Jun Tseng,Yu-Sheng Lin*

Main category: cs.CV

TL;DR: 本研究利用3D卷积神经网络模型，成功实现了无造影剂CT图像中肺栓塞的自动分类，准确率达85%，为肺栓塞的早期诊断提供了新方法。


<details>
  <summary>Details</summary>
Motivation: 肺栓塞是一种危及生命的疾病，早期检测和治疗可显著降低死亡率。然而，造影剂可能对慢性肾病患者造成急性肾损伤，且造影剂需要时间生效，可能延误急性肺栓塞患者的黄金治疗时间。

Method: 本研究采用3D卷积神经网络模型，利用深度学习技术对无造影剂的CT图像进行肺栓塞自动分类。

Result: 深度学习模型在无造影剂CT图像的肺栓塞分类中表现显著，准确率为85%，AUC为0.84。

Conclusion: 该研究证实了深度学习模型在无造影剂CT图像中自动分类肺栓塞的可行性，准确率达85%，AUC为0.84。

Abstract: Pulmonary embolism is a life-threatening disease, early detection and treatment can significantly reduce mortality. In recent years, many studies have been using deep learning in the diagnosis of pulmonary embolism with contrast medium computed tomography pulmonary angiography, but the contrast medium is likely to cause acute kidney injury in patients with pulmonary embolism and chronic kidney disease, and the contrast medium takes time to work, patients with acute pulmonary embolism may miss the golden treatment time.
  This study aims to use deep learning techniques to automatically classify pulmonary embolism in CT images without contrast medium by using a 3D convolutional neural network model. The deep learning model used in this study had a significant impact on the pulmonary embolism classification of computed tomography images without contrast with 85\% accuracy and 0.84 AUC, which confirms the feasibility of the model in the diagnosis of pulmonary embolism.

</details>


### [15] [Analyzing the Shopping Journey: Computing Shelf Browsing Visits in a Physical Retail Store](https://arxiv.org/abs/2601.00928)
*Luis Yoichi Morales,Francesco Zanlungo,David M. Woollard*

Main category: cs.CV

TL;DR: 该论文提出了一种通过机器视觉追踪顾客轨迹并识别其货架浏览行为的算法，展示了算法在不同环境中的适用性，并探讨了其在零售规划和人机交互中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于零售业中机器人部署的挑战，旨在通过理解顾客的购物意图，提升零售环境的智能化水平。

Method: 研究提出了一种算法，通过基于机器视觉的3D追踪和头顶摄像头获取的轨迹数据，计算顾客的“货架访问”行为。算法经过两组独立轨迹数据（8138条和15129条）的校准，并在不同商店的轨迹数据上进行了评估。

Result: 算法能够在不同于校准环境的情况下识别顾客的浏览活动，并成功分析了顾客浏览模式与实际购买行为的关系。

Conclusion: 该研究展示了算法在不同环境中识别顾客浏览行为的能力，并探讨了如何利用这些信息进行零售规划和人机交互场景的应用。

Abstract: Motivated by recent challenges in the deployment of robots into customer-facing roles within retail, this work introduces a study of customer activity in physical stores as a step toward autonomous understanding of shopper intent. We introduce an algorithm that computes shoppers' ``shelf visits'' -- capturing their browsing behavior in the store. Shelf visits are extracted from trajectories obtained via machine vision-based 3D tracking and overhead cameras. We perform two independent calibrations of the shelf visit algorithm, using distinct sets of trajectories (consisting of 8138 and 15129 trajectories), collected in different stores and labeled by human reviewers. The calibrated models are then evaluated on trajectories held out of the calibration process both from the same store on which calibration was performed and from the other store. An analysis of the results shows that the algorithm can recognize customers' browsing activity when evaluated in an environment different from the one on which calibration was performed. We then use the model to analyze the customers' ``browsing patterns'' on a large set of trajectories and their relation to actual purchases in the stores. Finally, we discuss how shelf browsing information could be used for retail planning and in the domain of human-robot interaction scenarios.

</details>


### [16] [ShadowGS: Shadow-Aware 3D Gaussian Splatting for Satellite Imagery](https://arxiv.org/abs/2601.00939)
*Feng Luo,Hongbo Pan,Xiang Yang,Baoyu Jiang,Fengqing Liu,Tao Huang*

Main category: cs.CV

TL;DR: ShadowGS是基于3DGS的新框架，通过物理渲染和光线行进技术解决多时相卫星图像中的阴影不一致问题，显著提升3D重建精度和渲染效率。


<details>
  <summary>Details</summary>
Motivation: 多时相卫星图像中，由于光照条件变化导致的阴影不一致问题显著，需要一种能够精确建模几何一致阴影并保持高效渲染的方法。

Method: 基于3D高斯溅射（3DGS）的ShadowGS框架，结合遥感物理渲染方程和高效光线行进技术，精确建模几何一致的阴影，并有效解耦场景中的不同光照成分和表观属性。

Result: 实验表明，ShadowGS在RGB、全色锐化和稀疏视图卫星输入等多种设置下均表现稳健。

Conclusion: ShadowGS在阴影解耦精度、3D重建精度和新视角合成质量上优于当前最先进方法，且仅需几分钟训练时间，表现出色。

Abstract: 3D Gaussian Splatting (3DGS) has emerged as a novel paradigm for 3D reconstruction from satellite imagery. However, in multi-temporal satellite images, prevalent shadows exhibit significant inconsistencies due to varying illumination conditions. To address this, we propose ShadowGS, a novel framework based on 3DGS. It leverages a physics-based rendering equation from remote sensing, combined with an efficient ray marching technique, to precisely model geometrically consistent shadows while maintaining efficient rendering. Additionally, it effectively disentangles different illumination components and apparent attributes in the scene. Furthermore, we introduce a shadow consistency constraint that significantly enhances the geometric accuracy of 3D reconstruction. We also incorporate a novel shadow map prior to improve performance with sparse-view inputs. Extensive experiments demonstrate that ShadowGS outperforms current state-of-the-art methods in shadow decoupling accuracy, 3D reconstruction precision, and novel view synthesis quality, with only a few minutes of training. ShadowGS exhibits robust performance across various settings, including RGB, pansharpened, and sparse-view satellite inputs.

</details>


### [17] [Learning to Segment Liquids in Real-world Images](https://arxiv.org/abs/2601.00940)
*Jonas Li,Michelle Li,Luke Liu,Heng Fan*

Main category: cs.CV

TL;DR: 构建了大规模液体数据集LQDS，并提出LQDM模型，通过交叉注意力机制提升液体分割效果，实验证明其优越性。


<details>
  <summary>Details</summary>
Motivation: 液体在日常生活中的普遍存在与机器人安全交互的需求，以及液体外观多样性带来的分割挑战。

Method: 设计了一种名为LQDM的新型液体检测模型，利用专用边界分支与主分割分支之间的交叉注意力机制来增强分割预测。

Result: LQDM在LQDS测试集上表现出色，优于现有方法。

Conclusion: LQDM模型在LQDS测试集上表现优异，超越了现有最先进方法，为液体语义分割建立了强有力的基准。

Abstract: Different types of liquids such as water, wine and medicine appear in all aspects of daily life. However, limited attention has been given to the task, hindering the ability of robots to avoid or interact with liquids safely. The segmentation of liquids is difficult because liquids come in diverse appearances and shapes; moreover, they can be both transparent or reflective, taking on arbitrary objects and scenes from the background or surroundings. To take on this challenge, we construct a large-scale dataset of liquids named LQDS consisting of 5000 real-world images annotated into 14 distinct classes, and design a novel liquid detection model named LQDM, which leverages cross-attention between a dedicated boundary branch and the main segmentation branch to enhance segmentation predictions. Extensive experiments demonstrate the effectiveness of LQDM on the test set of LQDS, outperforming state-of-the-art methods and establishing a strong baseline for the semantic segmentation of liquids.

</details>


### [18] [PhyEduVideo: A Benchmark for Evaluating Text-to-Video Models for Physics Education](https://arxiv.org/abs/2601.00943)
*Megha Mariam K. M,Aditya Arun,Zakaria Laskar,C. V. Jawahar*

Main category: cs.CV

TL;DR: 研究通过基准测试评估T2V模型生成物理教学视频的能力，发现视觉质量高但概念准确性不足，尤其在抽象领域表现不佳，旨在推动AI生成准确的教学内容。


<details>
  <summary>Details</summary>
Motivation: 评估生成式AI（特别是T2V系统）在物理教育中的潜力，通过自动化生成直观的教学视频，推动可扩展、易获取和个性化的AI驱动学习体验。

Method: 通过设计一个专门用于评估T2V模型生成物理教学视频能力的基准测试，将物理概念分解为细粒度的教学点，并为每个点设计提示词以生成视觉解释。

Result: 当前模型能生成视觉连贯、运动流畅的视频，但在概念准确性上表现不稳定，力学、流体和光学领域表现较好，电磁学和热力学则较差。

Conclusion: 当前T2V模型在生成教育视频时，视觉质量较高但概念准确性不足，尤其在电磁学和热力学等抽象领域表现不佳。希望该基准测试能帮助社区缩小这一差距，推动T2V系统生成准确且符合课程要求的物理教学内容。

Abstract: Generative AI models, particularly Text-to-Video (T2V) systems, offer a promising avenue for transforming science education by automating the creation of engaging and intuitive visual explanations. In this work, we take a first step toward evaluating their potential in physics education by introducing a dedicated benchmark for explanatory video generation. The benchmark is designed to assess how well T2V models can convey core physics concepts through visual illustrations. Each physics concept in our benchmark is decomposed into granular teaching points, with each point accompanied by a carefully crafted prompt intended for visual explanation of the teaching point. T2V models are evaluated on their ability to generate accurate videos in response to these prompts. Our aim is to systematically explore the feasibility of using T2V models to generate high-quality, curriculum-aligned educational content-paving the way toward scalable, accessible, and personalized learning experiences powered by AI. Our evaluation reveals that current models produce visually coherent videos with smooth motion and minimal flickering, yet their conceptual accuracy is less reliable. Performance in areas such as mechanics, fluids, and optics is encouraging, but models struggle with electromagnetism and thermodynamics, where abstract interactions are harder to depict. These findings underscore the gap between visual quality and conceptual correctness in educational video generation. We hope this benchmark helps the community close that gap and move toward T2V systems that can deliver accurate, curriculum-aligned physics content at scale. The benchmark and accompanying codebase are publicly available at https://github.com/meghamariamkm/PhyEduVideo.

</details>


### [19] [Deep Clustering with Associative Memories](https://arxiv.org/abs/2601.00963)
*Bishwajit Saha,Dmitry Krotov,Mohammed J. Zaki,Parikshit Ram*

Main category: cs.CV

TL;DR: DCAM通过能量基动力学和关联记忆，将表示学习和聚类统一在一个目标中，提升了聚类效果。


<details>
  <summary>Details</summary>
Motivation: 现有的深度聚类方法中，表示学习是可微分的，而聚类是一个离散优化任务，需要各种近似和正则化来适应标准的可微分流程，导致表示学习和聚类之间存在割裂。

Method: 提出了一种新颖的损失函数，利用能量基动力学和关联记忆（Associative Memories）来构建深度聚类方法DCAM。

Result: 实验表明，DCAM在各种架构选择（卷积、残差或全连接）和数据模态（图像或文本）下均能提升聚类质量。

Conclusion: DCAM方法通过能量基动力学和关联记忆，将表示学习和聚类更紧密地结合在一个单一目标中，显著提升了聚类质量。

Abstract: Deep clustering - joint representation learning and latent space clustering - is a well studied problem especially in computer vision and text processing under the deep learning framework. While the representation learning is generally differentiable, clustering is an inherently discrete optimization task, requiring various approximations and regularizations to fit in a standard differentiable pipeline. This leads to a somewhat disjointed representation learning and clustering. In this work, we propose a novel loss function utilizing energy-based dynamics via Associative Memories to formulate a new deep clustering method, DCAM, which ties together the representation learning and clustering aspects more intricately in a single objective. Our experiments showcase the advantage of DCAM, producing improved clustering quality for various architecture choices (convolutional, residual or fully-connected) and data modalities (images or text).

</details>


### [20] [A Deep Learning Approach for Automated Skin Lesion Diagnosis with Explainable AI](https://arxiv.org/abs/2601.00964)
*Md. Maksudul Haque,Rahnuma Akter,A S M Ahsanul Sarkar Akib,Abdul Hasib*

Main category: cs.CV

TL;DR: 论文提出了一种基于深度学习的皮肤病变分类方法，结合多种技术提升性能，并通过可解释AI增强临床可信度，在七类病变中表现优异。


<details>
  <summary>Details</summary>
Motivation: 皮肤癌是全球常见且危险的癌症类型，需要及时准确的诊断。

Method: 结合高质量数据平衡方法、大规模数据增强、混合EfficientNetV2-L框架与通道注意力机制，以及三阶段渐进式学习策略。

Result: 模型在HAM10000数据集上实现了91.15%的总准确率、85.45%的宏F1分数和99.33%的微平均AUC。

Conclusion: 该论文提出的深度学习架构在皮肤病变分类中表现出色，准确率达到91.15%，尤其在黑色素瘤和黑色素细胞痣分类中表现优异。通过可解释AI技术，增强了模型的临床可信度。

Abstract: Skin cancer is also one of the most common and dangerous types of cancer in the world that requires timely and precise diagnosis. In this paper, a deep-learning architecture of the multi-class skin lesion classification on the HAM10000 dataset will be described. The system suggested combines high-quality data balancing methods, large-scale data augmentation, hybridized EfficientNetV2-L framework with channel attention, and a three-stage progressive learning approach. Moreover, we also use explainable AI (XAI) techniques such as Grad-CAM and saliency maps to come up with intelligible visual representations of model predictions. Our strategy is with a total accuracy of 91.15 per cent, macro F1 of 85.45\% and micro-average AUC of 99.33\%. The model has shown high performance in all the seven lesion classes with specific high performance of melanoma and melanocytic nevi. In addition to enhancing diagnostic transparency, XAI also helps to find out the visual characteristics that cause the classifications, which enhances clinical trustworthiness.

</details>


### [21] [Few-Shot Video Object Segmentation in X-Ray Angiography Using Local Matching and Spatio-Temporal Consistency Loss](https://arxiv.org/abs/2601.00988)
*Lin Xi,Yingliang Ma,Xiahai Zhuang*

Main category: cs.CV

TL;DR: 提出了一种新型FSVOS模型，通过方向采样和对比学习提升视频分割性能，并在多个数据集上验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统方法在非CUDA设备上的可移植性限制以及参数化层的计算成本问题，同时适应多样化的空间结构。

Method: 采用基于方向的采样视角重新组织局部采样过程，实现非参数化采样机制，并设计了监督时空对比学习方案以增强特征一致性。

Result: 在CADICA、XACV和MOSXAV数据集上的大量实验表明，FSVOS方法在分割精度和泛化能力上优于现有方法。

Conclusion: 该论文提出的FSVOS模型在分割精度和泛化能力上优于现有最先进的视频分割方法，为广泛的临床应用提供了更高的灵活性和潜力。

Abstract: We introduce a novel FSVOS model that employs a local matching strategy to restrict the search space to the most relevant neighboring pixels. Rather than relying on inefficient standard im2col-like implementations (e.g., spatial convolutions, depthwise convolutions and feature-shifting mechanisms) or hardware-specific CUDA kernels (e.g., deformable and neighborhood attention), which often suffer from limited portability across non-CUDA devices, we reorganize the local sampling process through a direction-based sampling perspective. Specifically, we implement a non-parametric sampling mechanism that enables dynamically varying sampling regions. This approach provides the flexibility to adapt to diverse spatial structures without the computational costs of parametric layers and the need for model retraining. To further enhance feature coherence across frames, we design a supervised spatio-temporal contrastive learning scheme that enforces consistency in feature representations. In addition, we introduce a publicly available benchmark dataset for multi-object segmentation in X-ray angiography videos (MOSXAV), featuring detailed, manually labeled segmentation ground truth. Extensive experiments on the CADICA, XACV, and MOSXAV datasets show that our proposed FSVOS method outperforms current state-of-the-art video segmentation methods in terms of segmentation accuracy and generalization capability (i.e., seen and unseen categories). This work offers enhanced flexibility and potential for a wide range of clinical applications.

</details>


### [22] [UnrealPose: Leveraging Game Engine Kinematics for Large-Scale Synthetic Human Pose Data](https://arxiv.org/abs/2601.00991)
*Joshua Kawaguchi,Saad Manzur,Emily Gao Wang,Maitreyi Sinha,Bryan Vela,Yunxi Wang,Brandon Vela,Wayne B. Hayes*

Main category: cs.CV

TL;DR: 提出UnrealPose-Gen管线生成高质量合成人体姿态数据，发布UnrealPose-1M数据集，验证其在多项任务中的实用性。


<details>
  <summary>Details</summary>
Motivation: 解决野外数据集缺乏真实标注和高质量3D人体姿态数据稀缺的问题。

Method: 使用Unreal Engine 5和Movie Render Queue构建的UnrealPose-Gen管线，生成包含3D关节、2D投影、遮挡标志等丰富标注的合成数据。

Result: 生成了包含约100万帧的UnrealPose-1M数据集，并在四项任务中验证了其真实性。

Conclusion: UnrealPose-1M数据集和UnrealPose-Gen管线的发布，支持第三方生成高质量的人体姿态数据，弥补了真实数据稀缺和标注成本高的问题。

Abstract: Diverse, accurately labeled 3D human pose data is expensive and studio-bound, while in-the-wild datasets lack known ground truth. We introduce UnrealPose-Gen, an Unreal Engine 5 pipeline built on Movie Render Queue for high-quality offline rendering. Our generated frames include: (i) 3D joints in world and camera coordinates, (ii) 2D projections and COCO-style keypoints with occlusion and joint-visibility flags, (iii) person bounding boxes, and (iv) camera intrinsics and extrinsics. We use UnrealPose-Gen to present UnrealPose-1M, an approximately one million frame corpus comprising eight sequences: five scripted "coherent" sequences spanning five scenes, approximately 40 actions, and five subjects; and three randomized sequences across three scenes, approximately 100 actions, and five subjects, all captured from diverse camera trajectories for broad viewpoint coverage. As a fidelity check, we report real-to-synthetic results on four tasks: image-to-3D pose, 2D keypoint detection, 2D-to-3D lifting, and person detection/segmentation. Though time and resources constrain us from an unlimited dataset, we release the UnrealPose-1M dataset, as well as the UnrealPose-Gen pipeline to support third-party generation of human pose data.

</details>


### [23] [WildIng: A Wildlife Image Invariant Representation Model for Geographical Domain Shift](https://arxiv.org/abs/2601.00993)
*Julian D. Santamaria,Claudia Isaza,Jhony H. Giraldo*

Main category: cs.CV

TL;DR: WildIng通过结合文本与图像特征，解决了野生动物识别模型在地理域转移时的性能下降问题，准确率提升30%。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习模型在地理域转移时性能显著下降，主要依赖图像表示使其对背景、光照等变化敏感。

Method: WildIng整合了文本描述与图像特征，创建了对地理域转移更鲁棒的表示方法。

Result: WildIng在美洲和非洲数据集上的实验表明，其将BioCLIP等基础模型的准确率提升了30%。

Conclusion: WildIng通过整合文本描述与图像特征，显著提升了基础模型在地理域转移条件下的性能，为野生动物监测提供了更鲁棒的解决方案。

Abstract: Wildlife monitoring is crucial for studying biodiversity loss and climate change. Camera trap images provide a non-intrusive method for analyzing animal populations and identifying ecological patterns over time. However, manual analysis is time-consuming and resource-intensive. Deep learning, particularly foundation models, has been applied to automate wildlife identification, achieving strong performance when tested on data from the same geographical locations as their training sets. Yet, despite their promise, these models struggle to generalize to new geographical areas, leading to significant performance drops. For example, training an advanced vision-language model, such as CLIP with an adapter, on an African dataset achieves an accuracy of 84.77%. However, this performance drops significantly to 16.17% when the model is tested on an American dataset. This limitation partly arises because existing models rely predominantly on image-based representations, making them sensitive to geographical data distribution shifts, such as variation in background, lighting, and environmental conditions. To address this, we introduce WildIng, a Wildlife image Invariant representation model for geographical domain shift. WildIng integrates text descriptions with image features, creating a more robust representation to geographical domain shifts. By leveraging textual descriptions, our approach captures consistent semantic information, such as detailed descriptions of the appearance of the species, improving generalization across different geographical locations. Experiments show that WildIng enhances the accuracy of foundation models such as BioCLIP by 30% under geographical domain shift conditions. We evaluate WildIng on two datasets collected from different regions, namely America and Africa. The code and models are publicly available at https://github.com/Julian075/CATALOG/tree/WildIng.

</details>


### [24] [DVGBench: Implicit-to-Explicit Visual Grounding Benchmark in UAV Imagery with Large Vision-Language Models](https://arxiv.org/abs/2601.00998)
*Yue Zhou,Jue Chen,Zilun Zhang,Penghui Huang,Ran Ding,Zhentao Zou,PengFei Gao,Yuchen Wei,Ke Li,Xue Yang,Xue Jiang,Hongxin Yang,Jonathan Li*

Main category: cs.CV

TL;DR: 提出了无人机隐式视觉定位基准DVGBench和DroneVG-R1模型，通过I2E-CoT方法提升推理能力，发现现有模型局限性。


<details>
  <summary>Details</summary>
Motivation: 现有遥感视觉定位数据集主要依赖显式参考表达，限制了在需要领域知识的隐式任务上的表现。

Method: 设计了DroneVG-R1模型，结合I2E-CoT方法和强化学习范式，将隐式查询转换为显式查询以降低定位难度。

Result: 评估显示主流模型在显式和隐式视觉定位任务上存在显著推理能力不足。

Conclusion: 本文提出了DVGBench基准和DroneVG-R1模型，通过I2E-CoT方法提升无人机场景下的隐式视觉定位能力，并揭示了现有主流模型在推理能力上的局限性。

Abstract: Remote sensing (RS) large vision-language models (LVLMs) have shown strong promise across visual grounding (VG) tasks. However, existing RS VG datasets predominantly rely on explicit referring expressions-such as relative position, relative size, and color cues-thereby constraining performance on implicit VG tasks that require scenario-specific domain knowledge. This article introduces DVGBench, a high-quality implicit VG benchmark for drones, covering six major application scenarios: traffic, disaster, security, sport, social activity, and productive activity. Each object provides both explicit and implicit queries. Based on the dataset, we design DroneVG-R1, an LVLM that integrates the novel Implicit-to-Explicit Chain-of-Thought (I2E-CoT) within a reinforcement learning paradigm. This enables the model to take advantage of scene-specific expertise, converting implicit references into explicit ones and thus reducing grounding difficulty. Finally, an evaluation of mainstream models on both explicit and implicit VG tasks reveals substantial limitations in their reasoning capabilities. These findings provide actionable insights for advancing the reasoning capacity of LVLMs for drone-based agents. The code and datasets will be released at https://github.com/zytx121/DVGBench

</details>


### [25] [Lightweight Channel Attention for Efficient CNNs](https://arxiv.org/abs/2601.01002)
*Prem Babu Kanaparthi,Tulasi Venkata Sri Varshini Padamata*

Main category: cs.CV

TL;DR: LCA模块通过自适应一维卷积和分组操作，在保持参数效率的同时实现了高准确率，适用于资源受限环境。


<details>
  <summary>Details</summary>
Motivation: 尽管注意力机制在现代CNN中表现优异，但不同通道注意力设计在效率与准确性之间的权衡尚未充分探索。

Method: 本研究通过经验性比较，评估了SE、ECA和提出的LCA模块在ResNet 18和MobileNetV2架构上的性能。LCA采用自适应一维卷积和分组操作以减少参数使用，同时保持有效的注意力行为。

Result: 实验结果表明，LCA在CIFAR 10数据集上实现了竞争性准确率，同时在参数效率和推理延迟方面表现优异。

Conclusion: LCA模块在保持参数效率的同时，达到了与ECA相当的准确率（ResNet 18上94.68%，MobileNetV2上93.10%），并在推理延迟方面表现良好，为资源受限环境中的注意力增强CNN部署提供了实用见解。

Abstract: Attention mechanisms have become integral to modern convolutional neural networks (CNNs), delivering notable performance improvements with minimal computational overhead. However, the efficiency accuracy trade off of different channel attention designs remains underexplored. This work presents an empirical study comparing Squeeze and Excitation (SE), Efficient Channel Attention (ECA), and a proposed Lite Channel Attention (LCA) module across ResNet 18 and MobileNetV2 architectures on CIFAR 10. LCA employs adaptive one dimensional convolutions with grouped operations to reduce parameter usage while preserving effective attention behavior. Experimental results show that LCA achieves competitive accuracy, reaching 94.68 percent on ResNet 18 and 93.10 percent on MobileNetV2, while matching ECA in parameter efficiency and maintaining favorable inference latency. Comprehensive benchmarks including FLOPs, parameter counts, and GPU latency measurements are provided, offering practical insights for deploying attention enhanced CNNs in resource constrained environments.

</details>


### [26] [Decoupling Amplitude and Phase Attention in Frequency Domain for RGB-Event based Visual Object Tracking](https://arxiv.org/abs/2601.01022)
*Shiao Wang,Xiao Wang,Haonan Zhao,Jiarui Xu,Bo Jiang,Lin Zhu,Xin Zhao,Yonghong Tian,Jin Tang*

Main category: cs.CV

TL;DR: 论文提出了一种频域早期融合和运动引导的RGB-Event跟踪框架，有效利用事件相机特性，提升性能并降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有RGB-Event视觉目标跟踪方法主要依赖传统特征级融合，未能充分利用事件相机的独特优势，如高动态范围和运动敏感性，且对低信息区域处理方式单一，导致不必要的计算开销。

Method: 论文方法包括将RGB和事件模态通过快速傅里叶变换从空间域转换到频域，分离振幅和相位成分，并通过振幅和相位注意力选择性融合高频事件信息。此外，利用运动引导的空间稀疏化模块捕获目标运动线索与空间概率分布的关系，过滤低信息区域。

Result: 在FE108、FELT和COESOT三个广泛使用的RGB-Event跟踪基准数据集上的大量实验表明，该方法具有高性能和高效率。

Conclusion: 该论文提出了一种新颖的RGB-Event视觉目标跟踪框架，通过频域早期融合和运动引导的空间稀疏化模块，有效利用了事件相机的高动态范围和运动敏感性，显著提升了跟踪性能并降低了计算开销。

Abstract: Existing RGB-Event visual object tracking approaches primarily rely on conventional feature-level fusion, failing to fully exploit the unique advantages of event cameras. In particular, the high dynamic range and motion-sensitive nature of event cameras are often overlooked, while low-information regions are processed uniformly, leading to unnecessary computational overhead for the backbone network. To address these issues, we propose a novel tracking framework that performs early fusion in the frequency domain, enabling effective aggregation of high-frequency information from the event modality. Specifically, RGB and event modalities are transformed from the spatial domain to the frequency domain via the Fast Fourier Transform, with their amplitude and phase components decoupled. High-frequency event information is selectively fused into RGB modality through amplitude and phase attention, enhancing feature representation while substantially reducing backbone computation. In addition, a motion-guided spatial sparsification module leverages the motion-sensitive nature of event cameras to capture the relationship between target motion cues and spatial probability distribution, filtering out low-information regions and enhancing target-relevant features. Finally, a sparse set of target-relevant features is fed into the backbone network for learning, and the tracking head predicts the final target position. Extensive experiments on three widely used RGB-Event tracking benchmark datasets, including FE108, FELT, and COESOT, demonstrate the high performance and efficiency of our method. The source code of this paper will be released on https://github.com/Event-AHU/OpenEvTracking

</details>


### [27] [ITSELF: Attention Guided Fine-Grained Alignment for Vision-Language Retrieval](https://arxiv.org/abs/2601.01024)
*Tien-Huy Nguyen,Huu-Loc Tran,Thanh Duc Ngo*

Main category: cs.CV

TL;DR: ITSELF是一种注意力引导的隐式局部对齐框架，通过GRAB、MARS和ATS组件，无需额外监督即可在TBPS任务中实现高性能和强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过局部对齐处理TBPS任务，但容易陷入捷径学习和虚假关联，导致错位；同时注入先验知识可能扭曲模态内结构。研究发现编码器注意力从早期训练阶段即可提供空间精确的证据，因此提出ITSELF框架以缓解这些问题。

Method: ITSELF框架包括三个核心组件：GRAB（通过注意力银行转换高显著性标记并应用局部目标）、MARS（跨层聚合注意力并执行多样性感知的top-k选择）和ATS（从粗到细调度保留预算）。

Result: 在三个广泛使用的TBPS基准测试中，ITSELF表现出最先进的性能和强大的跨数据集泛化能力。

Conclusion: ITSELF框架通过注意力引导的隐式局部对齐方法，在无需额外先验监督的情况下，实现了文本基于人物搜索（TBPS）任务的最先进性能，并展示了强大的跨数据集泛化能力。

Abstract: Vision Language Models (VLMs) have rapidly advanced and show strong promise for text-based person search (TBPS), a task that requires capturing fine-grained relationships between images and text to distinguish individuals. Previous methods address these challenges through local alignment, yet they are often prone to shortcut learning and spurious correlations, yielding misalignment. Moreover, injecting prior knowledge can distort intra-modality structure. Motivated by our finding that encoder attention surfaces spatially precise evidence from the earliest training epochs, and to alleviate these issues, we introduceITSELF, an attention-guided framework for implicit local alignment. At its core, Guided Representation with Attentive Bank (GRAB) converts the model's own attention into an Attentive Bank of high-saliency tokens and applies local objectives on this bank, learning fine-grained correspondences without extra supervision. To make the selection reliable and non-redundant, we introduce Multi-Layer Attention for Robust Selection (MARS), which aggregates attention across layers and performs diversity-aware top-k selection; and Adaptive Token Scheduler (ATS), which schedules the retention budget from coarse to fine over training, preserving context early while progressively focusing on discriminative details. Extensive experiments on three widely used TBPS benchmarks showstate-of-the-art performance and strong cross-dataset generalization, confirming the effectiveness and robustness of our approach without additional prior supervision. Our project is publicly available at https://trhuuloc.github.io/itself

</details>


### [28] [Enhanced Leukemic Cell Classification Using Attention-Based CNN and Data Augmentation](https://arxiv.org/abs/2601.01026)
*Douglas Costa Braga,Daniel Oliveira Dantas*

Main category: cs.CV

TL;DR: 提出了一种高效且可解释的深度学习管道，用于白血病细胞分类，显著提升了准确率和计算效率。


<details>
  <summary>Details</summary>
Motivation: 急性淋巴细胞白血病（ALL）是最常见的儿童癌症，依赖专家显微镜诊断存在观察者间变异和时间限制的问题。

Method: 提出了一种结合EfficientNetV2-B3与Squeeze-and-Excitation机制的注意力卷积神经网络，采用全面的数据增强、焦点损失函数和患者级数据分割。

Result: 在C-NMC 2019数据集上，系统实现了97.89%的F1分数和准确率，显著优于基线方法（p < 0.001），参数数量比VGG16少89%。

Conclusion: 现代基于注意力的架构可以提高白血病细胞分类的准确性，同时保持适合临床部署的计算效率。

Abstract: We present a reproducible deep learning pipeline for leukemic cell classification, focusing on system architecture, experimental robustness, and software design choices for medical image analysis. Acute lymphoblastic leukemia (ALL) is the most common childhood cancer, requiring expert microscopic diagnosis that suffers from inter-observer variability and time constraints. The proposed system integrates an attention-based convolutional neural network combining EfficientNetV2-B3 with Squeeze-and-Excitation mechanisms for automated ALL cell classification. Our approach employs comprehensive data augmentation, focal loss for class imbalance, and patient-wise data splitting to ensure robust and reproducible evaluation. On the C-NMC 2019 dataset (12,528 original images from 62 patients), the system achieves a 97.89% F1-score and 97.89% accuracy on the test set, with statistical validation through 100-iteration Monte Carlo experiments confirming significant improvements (p < 0.001) over baseline methods. The proposed pipeline outperforms existing approaches by up to 4.67% while using 89% fewer parameters than VGG16 (15.2M vs. 138M). The attention mechanism provides interpretable visualizations of diagnostically relevant cellular features, demonstrating that modern attention-based architectures can improve leukemic cell classification while maintaining computational efficiency suitable for clinical deployment.

</details>


### [29] [Mono3DV: Monocular 3D Object Detection with 3D-Aware Bipartite Matching and Variational Query DeNoising](https://arxiv.org/abs/2601.01036)
*Kiet Dang Vu,Trung Thai Tran,Kien Nguyen Do Trung,Duc Dung Nguyen*

Main category: cs.CV

TL;DR: Mono3DV通过3D感知匹配和去噪技术，解决了单目3D检测中的训练不稳定问题，性能达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 解决DETR类架构在单目3D目标检测中因忽略3D属性导致的训练不稳定和性能下降问题。

Method: 提出了Mono3DV框架，包含三个关键创新：3D感知的二分匹配策略、3D去噪方案和变分查询去噪机制。

Result: 在KITTI 3D目标检测基准测试中取得了最先进的结果，且未使用任何外部数据。

Conclusion: Mono3DV通过引入3D感知的二分匹配策略、3D去噪方案和变分查询去噪机制，显著提升了单目3D目标检测的性能，并在KITTI基准测试中取得了最先进的结果。

Abstract: While DETR-like architectures have demonstrated significant potential for monocular 3D object detection, they are often hindered by a critical limitation: the exclusion of 3D attributes from the bipartite matching process. This exclusion arises from the inherent ill-posed nature of 3D estimation from monocular image, which introduces instability during training. Consequently, high-quality 3D predictions can be erroneously suppressed by 2D-only matching criteria, leading to suboptimal results. To address this, we propose Mono3DV, a novel Transformer-based framework. Our approach introduces three key innovations. First, we develop a 3D-Aware Bipartite Matching strategy that directly incorporates 3D geometric information into the matching cost, resolving the misalignment caused by purely 2D criteria. Second, it is important to stabilize the Bipartite Matching to resolve the instability occurring when integrating 3D attributes. Therefore, we propose 3D-DeNoising scheme in the training phase. Finally, recognizing the gradient vanishing issue associated with conventional denoising techniques, we propose a novel Variational Query DeNoising mechanism to overcome this limitation, which significantly enhances model performance. Without leveraging any external data, our method achieves state-of-the-art results on the KITTI 3D object detection benchmark.

</details>


### [30] [Deepfake Detection with Multi-Artifact Subspace Fine-Tuning and Selective Layer Masking](https://arxiv.org/abs/2601.01041)
*Xiang Zhang,Wenliang Weng,Daoyong Fu,Ziqiang Li,Zhangjie Fu*

Main category: cs.CV

TL;DR: MASM方法通过解耦语义和伪影表示，约束伪影子空间拟合，提升跨数据集深度伪造检测的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 深度伪造检测在跨数据集和现实复杂场景中面临挑战，主要原因是不同伪造方法引入的伪影分布高度多样化，而预训练模型在适应新伪影时易破坏其原始通用语义结构。

Method: 提出基于多伪影子空间和选择性层掩码（MASM）的深度伪造检测方法，通过奇异值分解将预训练权重划分为稳定的语义主子空间和多个可学习的伪影子空间，并引入选择性层掩码策略自适应调节网络层更新行为。

Result: MASM方法通过解耦建模不同伪造伪影模式并保留通用语义子空间，结合正交性和谱一致性约束，有效提升了检测的泛化能力。

Conclusion: MASM方法通过解耦语义表示和伪造伪影表示，并约束伪影子空间的拟合强度，有效提升了跨数据集场景下的泛化鲁棒性。

Abstract: Deepfake detection still faces significant challenges in cross-dataset and real-world complex scenarios. The root cause lies in the high diversity of artifact distributions introduced by different forgery methods, while pretrained models tend to disrupt their original general semantic structures when adapting to new artifacts. Existing approaches usually rely on indiscriminate global parameter updates or introduce additional supervision signals, making it difficult to effectively model diverse forgery artifacts while preserving semantic stability. To address these issues, this paper proposes a deepfake detection method based on Multi-Artifact Subspaces and selective layer masks (MASM), which explicitly decouples semantic representations from artifact representations and constrains the fitting strength of artifact subspaces, thereby improving generalization robustness in cross-dataset scenarios. Specifically, MASM applies singular value decomposition to model weights, partitioning pretrained weights into a stable semantic principal subspace and multiple learnable artifact subspaces. This design enables decoupled modeling of different forgery artifact patterns while preserving the general semantic subspace. On this basis, a selective layer mask strategy is introduced to adaptively regulate the update behavior of corresponding network layers according to the learning state of each artifact subspace, suppressing overfitting to any single forgery characteristic. Furthermore, orthogonality constraints and spectral consistency constraints are imposed to jointly regularize multiple artifact subspaces, guiding them to learn complementary and diverse artifact representations while maintaining a stable overall spectral structure.

</details>


### [31] [Evaluating transfer learning strategies for improving dairy cattle body weight prediction in small farms using depth-image and point-cloud data](https://arxiv.org/abs/2601.01044)
*Jin Wang,Angelo De Castro,Yuxi Zhang,Lucas Basolli Borsatto,Yuechen Guo,Victoria Bastos Primo,Ana Beatriz Montevecchio Bernardino,Gota Morota,Ricardo C Chebel,Haipeng Yu*

Main category: cs.CV

TL;DR: 迁移学习可有效提升小农场奶牛体重预测精度，深度图像与点云模型性能相当。


<details>
  <summary>Details</summary>
Motivation: 探索迁移学习在畜牧业中的应用效果，比较深度图像与点云数据在体重预测中的性能差异，解决小规模农场数据不足的问题。

Method: 使用四种深度学习模型（ConvNeXt、MobileViT处理深度图像；PointNet、DGCNN处理点云数据），在三个规模不同的农场（1,201、215、58头牛）中评估迁移学习的效果。

Result: 迁移学习在小农场中表现优于单源学习，性能接近或超过联合学习；深度图像与点云模型无一致性能差异。

Conclusion: 迁移学习在小规模农场中显著提升了体重预测的准确性，且深度图像与点云模型性能无显著差异，适用于数据共享受限的场景。

Abstract: Computer vision provides automated, non-invasive, and scalable tools for monitoring dairy cattle, thereby supporting management, health assessment, and phenotypic data collection. Although transfer learning is commonly used for predicting body weight from images, its effectiveness and optimal fine-tuning strategies remain poorly understood in livestock applications, particularly beyond the use of pretrained ImageNet or COCO weights. In addition, while both depth images and three-dimensional point-cloud data have been explored for body weight prediction, direct comparisons of these two modalities in dairy cattle are limited. Therefore, the objectives of this study were to 1) evaluate whether transfer learning from a large farm enhances body weight prediction on a small farm with limited data, and 2) compare the predictive performance of depth-image- and point-cloud-based approaches under three experimental designs. Top-view depth images and point-cloud data were collected from 1,201, 215, and 58 cows at large, medium, and small dairy farms, respectively. Four deep learning models were evaluated: ConvNeXt and MobileViT for depth images, and PointNet and DGCNN for point clouds. Transfer learning markedly improved body weight prediction on the small farm across all four models, outperforming single-source learning and achieving gains comparable to or greater than joint learning. These results indicate that pretrained representations generalize well across farms with differing imaging conditions and dairy cattle populations. No consistent performance difference was observed between depth-image- and point-cloud-based models. Overall, these findings suggest that transfer learning is well suited for small farm prediction scenarios where cross-farm data sharing is limited by privacy, logistical, or policy constraints, as it requires access only to pretrained model weights rather than raw data.

</details>


### [32] [Enhancing Histopathological Image Classification via Integrated HOG and Deep Features with Robust Noise Performance](https://arxiv.org/abs/2601.01056)
*Ifeanyi Ezuma,Ugochukwu Ugwu*

Main category: cs.CV

TL;DR: 本研究评估了深度学习模型在组织病理学图像分类中的性能，发现微调的InceptionResNet-v2结合深度特征显著提升了分类准确率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 随着数字病理学的发展，自动化的图像分析在临床实践中变得至关重要。本研究旨在评估机器学习和深度学习模型在组织病理学图像分类中的性能。

Method: 研究使用了微调的InceptionResNet-v2网络作为分类器和特征提取器，并比较了不同模型在LC25000数据集上的表现。

Result: 微调的InceptionResNet-v2网络达到了96.01%的分类准确率和96.8%的平均AUC。使用深度特征的模型表现更优，其中神经网络模型达到了99.99%的AUC和99.84%的准确率。在噪声环境下，GBM和KNN模型表现出更强的鲁棒性。

Conclusion: 研究表明，经过微调的InceptionResNet-v2网络在LC25000数据集上表现出色，特别是在结合深度特征后，模型的分类性能和鲁棒性显著提升。

Abstract: The era of digital pathology has advanced histopathological examinations, making automated image analysis essential in clinical practice. This study evaluates the classification performance of machine learning and deep learning models on the LC25000 dataset, which includes five classes of histopathological images. We used the fine-tuned InceptionResNet-v2 network both as a classifier and for feature extraction. Our results show that the fine-tuned InceptionResNet-v2 achieved a classification accuracy of 96.01\% and an average AUC of 96.8\%. Models trained on deep features from InceptionResNet-v2 outperformed those using only the pre-trained network, with the Neural Network model achieving an AUC of 99.99\% and accuracy of 99.84\%. Evaluating model robustness under varying SNR conditions revealed that models using deep features exhibited greater resilience, particularly GBM and KNN. The combination of HOG and deep features showed enhanced performance, however, less so in noisy environments.

</details>


### [33] [Efficient Hyperspectral Image Reconstruction Using Lightweight Separate Spectral Transformers](https://arxiv.org/abs/2601.01064)
*Jianan Li,Wangcai Zhao,Tingfa Xu*

Main category: cs.CV

TL;DR: LSST是一种轻量化的超光谱图像重建架构，通过分而治之策略和创新的损失机制，高效处理光谱和空间信息。


<details>
  <summary>Details</summary>
Motivation: 超光谱成像（HSI）在多个领域至关重要，但从压缩感知测量中高效重建超光谱图像存在挑战。

Method: 采用分而治之策略，结合Separate Spectral Transformer Blocks（SSTB）和Lightweight Spatial Convolution Blocks（LSCB），分别处理光谱和空间信息。SSTB使用Grouped Spectral Self-attention和Spectrum Shuffle操作，LSCB采用深度可分离卷积。

Result: LSST在减少FLOPs和参数的同时，实现了卓越的重建性能。

Conclusion: LSST架构通过其轻量化的设计和创新的损失机制，在减少计算资源的同时实现了高效的超光谱图像重建。

Abstract: Hyperspectral imaging (HSI) is essential across various disciplines for its capacity to capture rich spectral information. However, efficiently reconstructing hyperspectral images from compressive sensing measurements presents significant challenges. To tackle these, we adopt a divide-and-conquer strategy that capitalizes on the unique spectral and spatial characteristics of hyperspectral images. We introduce the Lightweight Separate Spectral Transformer (LSST), an innovative architecture tailored for efficient hyperspectral image reconstruction. This architecture consists of Separate Spectral Transformer Blocks (SSTB) for modeling spectral relationships and Lightweight Spatial Convolution Blocks (LSCB) for spatial processing. The SSTB employs Grouped Spectral Self-attention and a Spectrum Shuffle operation to effectively manage both local and non-local spectral relationships. Simultaneously, the LSCB utilizes depth-wise separable convolutions and strategic ordering to enhance spatial information processing. Furthermore, we implement the Focal Spectrum Loss, a novel loss weighting mechanism that dynamically adjusts during training to improve reconstruction across spectrally complex bands. Extensive testing demonstrates that our LSST achieves superior performance while requiring fewer FLOPs and parameters, underscoring its efficiency and effectiveness. The source code is available at: https://github.com/wcz1124/LSST.

</details>


### [34] [Real-Time LiDAR Point Cloud Densification for Low-Latency Spatial Data Transmission](https://arxiv.org/abs/2601.01210)
*Kazuhiko Murasaki,Shunsuke Konagai,Masakatsu Aoki,Taiga Yoshida,Ryuichi Tanida*

Main category: cs.CV

TL;DR: 本文提出了一种高速LiDAR点云增密方法，结合LiDAR与彩色图像，通过CNN实现实时密集深度图生成，速度提升15倍，几何准确无伪影。


<details>
  <summary>Details</summary>
Motivation: 为了实现沉浸式远程呈现的低延迟空间传输系统，需要解决动态3D场景的密集捕获和实时处理问题。LiDAR传感器虽然能实时捕获3D数据，但生成的点云稀疏。

Method: 结合多个LiDAR输入与高分辨率彩色图像，通过卷积神经网络架构实现联合双边滤波策略。

Result: 实验表明，该方法能以全高清分辨率实时（30 fps）生成密集深度图，速度比最近的基于训练的深度补全方法快15倍以上，且生成的密集点云几何准确，无多视图不一致或重影伪影。

Conclusion: 本文提出了一种高速LiDAR点云增密方法，能够在保持实时性能的同时，实现低延迟的空间传输系统，解决了动态3D场景密集捕获和实时处理的难题。

Abstract: To realize low-latency spatial transmission system for immersive telepresence, there are two major problems: capturing dynamic 3D scene densely and processing them in real time. LiDAR sensors capture 3D in real time, but produce sparce point clouds. Therefore, this paper presents a high-speed LiDAR point cloud densification method to generate dense 3D scene with minimal latency, addressing the need for on-the-fly depth completion while maintaining real-time performance. Our approach combines multiple LiDAR inputs with high-resolution color images and applies a joint bilateral filtering strategy implemented through a convolutional neural network architecture. Experiments demonstrate that the proposed method produces dense depth maps at full HD resolution in real time (30 fps), which is over 15x faster than a recent training-based depth completion approach. The resulting dense point clouds exhibit accurate geometry without multiview inconsistencies or ghosting artifacts.

</details>


### [35] [A UAV-Based Multispectral and RGB Dataset for Multi-Stage Paddy Crop Monitoring in Indian Agricultural Fields](https://arxiv.org/abs/2601.01084)
*Adari Rama Sukanya,Puvvula Roopesh Naga Sri Sai,Kota Moses,Rimalapudi Sarvendranath*

Main category: cs.CV

TL;DR: 该论文介绍了印度水稻田的高分辨率RGB和多光谱图像数据集，覆盖所有生长阶段，支持精准农业研究。


<details>
  <summary>Details</summary>
Motivation: 填补印度水稻田高分辨率图像数据集的空白，支持精准农业应用如靶向喷洒、病害分析和产量估算。

Method: 使用20兆像素RGB相机和5兆像素四波段多光谱相机采集图像，开发了标准化操作流程（SOP）和检查表以确保数据采集的可重复性。

Result: 生成了包含42,430张原始图像（415 GB）的数据集，具有1厘米/像素的地面采样距离（GSD）和丰富的元数据，如GPS坐标、飞行高度和环境条件。

Conclusion: 该数据集为印度水稻田提供了高分辨率的RGB和多光谱图像，覆盖了从育苗到收获的所有生长阶段，支持精准农业研究。

Abstract: We present a large-scale unmanned aerial vehicle (UAV)-based RGB and multispectral image dataset collected over paddy fields in the Vijayawada region, Andhra Pradesh, India, covering nursery to harvesting stages. We used a 20-megapixel RGB camera and a 5-megapixel four-band multispectral camera capturing red, green, red-edge, and near-infrared bands. Standardised operating procedure (SOP) and checklists were developed to ensure repeatable data acquisition. Our dataset comprises of 42,430 raw images (415 GB) captured over 5 acres with 1 cm/pixel ground sampling distance (GSD) with associated metadata such as GPS coordinates, flight altitude, and environmental conditions. Captured images were validated using Pix4D Fields to generate orthomosaic maps and vegetation index maps, such as normalised difference vegetation index (NDVI) and normalised difference red-edge (NDRE) index. Our dataset is one of the few datasets that provide high-resolution images with rich metadata that cover all growth stages of Indian paddy crops. The dataset is available on IEEE DataPort with DOI, . It can support studies on targeted spraying, disease analysis, and yield estimation.

</details>


### [36] [Luminark: Training-free, Probabilistically-Certified Watermarking for General Vision Generative Models](https://arxiv.org/abs/2601.01085)
*Jiayi Xu,Zhang Zhang,Yuanrui Zhang,Ruitao Chen,Yixian Xu,Tianyu He,Di He*

Main category: cs.CV

TL;DR: Luminark是一种无需训练的通用视觉生成模型水印方法，通过块级亮度统计实现高检测准确率和强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 为视觉生成模型提供一种无需训练、通用且能保证图像质量的水印方法。

Method: 该方法基于块级亮度统计定义水印，服务提供商预定义二进制模式及对应的块级阈值。检测时，评估每个块的亮度是否超过阈值，并验证生成的二进制模式是否与目标一致。通过统计方法控制误检率，确保认证检测。

Result: 在九种模型（扩散、自回归和混合框架）上的实验表明，Luminark具有高检测准确率、强鲁棒性和良好的视觉质量。

Conclusion: Luminark是一种无需训练且具有概率认证的水印方法，适用于广泛的视觉生成模型。它通过新颖的水印定义和统计分析方法，实现了高检测准确率、强鲁棒性和良好的视觉质量。

Abstract: In this paper, we introduce \emph{Luminark}, a training-free and probabilistically-certified watermarking method for general vision generative models. Our approach is built upon a novel watermark definition that leverages patch-level luminance statistics. Specifically, the service provider predefines a binary pattern together with corresponding patch-level thresholds. To detect a watermark in a given image, we evaluate whether the luminance of each patch surpasses its threshold and then verify whether the resulting binary pattern aligns with the target one. A simple statistical analysis demonstrates that the false positive rate of the proposed method can be effectively controlled, thereby ensuring certified detection. To enable seamless watermark injection across different paradigms, we leverage the widely adopted guidance technique as a plug-and-play mechanism and develop the \emph{watermark guidance}. This design enables Luminark to achieve generality across state-of-the-art generative models without compromising image quality. Empirically, we evaluate our approach on nine models spanning diffusion, autoregressive, and hybrid frameworks. Across all evaluations, Luminark consistently demonstrates high detection accuracy, strong robustness against common image transformations, and good performance on visual quality.

</details>


### [37] [DrivingGen: A Comprehensive Benchmark for Generative Video World Models in Autonomous Driving](https://arxiv.org/abs/2601.01528)
*Yang Zhou,Hao Shao,Letian Wang,Zhuofan Zong,Hongsheng Li,Steven L. Waslander*

Main category: cs.CV

TL;DR: DrivingGen是首个用于生成驾驶世界模型的综合基准，通过多样化数据集和新评估指标，揭示了现有模型在视觉真实性和物理合理性之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 当前视频生成模型在自动驾驶领域的评估存在局限性，缺乏严格的基准来衡量进展和指导优先级。现有评估忽略了安全关键的成像因素、轨迹合理性、时间和代理级别的一致性，以及自我条件的可控性。

Method: 通过结合来自驾驶数据集和互联网规模视频源的多样化评估数据集，以及一套新的评估指标，共同评估视觉真实性、轨迹合理性、时间一致性和可控性。

Result: 对14种最先进模型的基准测试揭示了明显的权衡：通用模型看起来更好但违反物理规律，而驾驶专用模型能真实捕捉运动但在视觉质量上落后。

Conclusion: DrivingGen提供了一个统一的评估框架，旨在推动可靠、可控且可部署的驾驶世界模型的发展，支持可扩展的仿真、规划和数据驱动的决策。

Abstract: Video generation models, as one form of world models, have emerged as one of the most exciting frontiers in AI, promising agents the ability to imagine the future by modeling the temporal evolution of complex scenes. In autonomous driving, this vision gives rise to driving world models: generative simulators that imagine ego and agent futures, enabling scalable simulation, safe testing of corner cases, and rich synthetic data generation. Yet, despite fast-growing research activity, the field lacks a rigorous benchmark to measure progress and guide priorities. Existing evaluations remain limited: generic video metrics overlook safety-critical imaging factors; trajectory plausibility is rarely quantified; temporal and agent-level consistency is neglected; and controllability with respect to ego conditioning is ignored. Moreover, current datasets fail to cover the diversity of conditions required for real-world deployment. To address these gaps, we present DrivingGen, the first comprehensive benchmark for generative driving world models. DrivingGen combines a diverse evaluation dataset curated from both driving datasets and internet-scale video sources, spanning varied weather, time of day, geographic regions, and complex maneuvers, with a suite of new metrics that jointly assess visual realism, trajectory plausibility, temporal coherence, and controllability. Benchmarking 14 state-of-the-art models reveals clear trade-offs: general models look better but break physics, while driving-specific ones capture motion realistically but lag in visual quality. DrivingGen offers a unified evaluation framework to foster reliable, controllable, and deployable driving world models, enabling scalable simulation, planning, and data-driven decision-making.

</details>


### [38] [600k-ks-ocr: a large-scale synthetic dataset for optical character recognition in kashmiri script](https://arxiv.org/abs/2601.01088)
*Haq Nawaz Malik*

Main category: cs.CV

TL;DR: 600K-KS-OCR数据集填补克什米尔语OCR资源空白，包含60万单词级图像，支持多种OCR模型训练，采用CC-BY-4.0许可证。


<details>
  <summary>Details</summary>
Motivation: 解决克什米尔语在光学字符识别领域的资源匮乏问题，支持低资源语言的OCR研究。

Method: 生成方法采用了三种传统的克什米尔字体，全面的数据增强模拟真实文档退化，以及多样化的背景纹理以增强模型鲁棒性。

Result: 数据集以十个分区存档形式分发，总计约10.6 GB，采用CC-BY-4.0许可证发布，便于研究使用。

Conclusion: 该技术报告介绍了600K-KS-OCR数据集，这是一个大规模合成语料库，包含约602,000个单词级分割图像，旨在训练和评估针对克什米尔文字的光学字符识别系统。数据集填补了克什米尔语（一种濒危的达尔德语，使用修改后的波斯-阿拉伯书写系统，约七百万人使用）的关键资源缺口。

Abstract: This technical report presents the 600K-KS-OCR Dataset, a large-scale synthetic corpus comprising approximately 602,000 word-level segmented images designed for training and evaluating optical character recognition systems targeting Kashmiri script. The dataset addresses a critical resource gap for Kashmiri, an endangered Dardic language utilizing a modified Perso-Arabic writing system spoken by approximately seven million people. Each image is rendered at 256x64 pixels with corresponding ground-truth transcriptions provided in multiple formats compatible with CRNN, TrOCR, and generalpurpose machine learning pipelines. The generation methodology incorporates three traditional Kashmiri typefaces, comprehensive data augmentation simulating real-world document degradation, and diverse background textures to enhance model robustness. The dataset is distributed across ten partitioned archives totaling approximately 10.6 GB and is released under the CC-BY-4.0 license to facilitate research in low-resource language optical character recognition.

</details>


### [39] [Real-Time Lane Detection via Efficient Feature Alignment and Covariance Optimization for Low-Power Embedded Systems](https://arxiv.org/abs/2601.01696)
*Yian Liu,Xiong Wang,Ping Xu,Lei Zhu,Ming Yan,Linyun Xue*

Main category: cs.CV

TL;DR: 提出CDO模块优化嵌入式系统中的实时车道检测，提升精度且易于集成，实验显示精度提升0.01%-1.5%。


<details>
  <summary>Details</summary>
Motivation: 嵌入式系统中的实时车道检测面临视觉信号稀疏和计算资源有限的挑战，现有深度学习模型缺乏针对低功耗嵌入式环境的通用优化技术。

Method: 提出了创新的协方差分布优化（CDO）模块，专门为高效实时应用设计，通过紧密对齐车道特征分布与真实标签来提升检测精度。

Result: 在三个主要数据集（CULane、TuSimple和LLAMAS）上测试了六种模型，实验结果显示精度提升范围在0.01%至1.5%之间。

Conclusion: 提出的CDO模块在不增加计算复杂度的前提下显著提升了检测精度，且易于集成到现有系统中，为嵌入式系统提供了性能、能效和操作灵活性的显著优势。

Abstract: Real-time lane detection in embedded systems encounters significant challenges due to subtle and sparse visual signals in RGB images, often constrained by limited computational resources and power consumption. Although deep learning models for lane detection categorized into segmentation-based, anchor-based, and curve-based methods there remains a scarcity of universally applicable optimization techniques tailored for low-power embedded environments. To overcome this, we propose an innovative Covariance Distribution Optimization (CDO) module specifically designed for efficient, real-time applications. The CDO module aligns lane feature distributions closely with ground-truth labels, significantly enhancing detection accuracy without increasing computational complexity. Evaluations were conducted on six diverse models across all three method categories, including two optimized for real-time applications and four state-of-the-art (SOTA) models, tested comprehensively on three major datasets: CULane, TuSimple, and LLAMAS. Experimental results demonstrate accuracy improvements ranging from 0.01% to 1.5%. The proposed CDO module is characterized by ease of integration into existing systems without structural modifications and utilizes existing model parameters to facilitate ongoing training, thus offering substantial benefits in performance, power efficiency, and operational flexibility in embedded systems.

</details>


### [40] [NarrativeTrack: Evaluating Video Language Models Beyond the Frame](https://arxiv.org/abs/2601.01095)
*Hyeonjeong Ha,Jinjin Ge,Bo Feng,Kaixin Ma,Gargi Chakraborty*

Main category: cs.CV

TL;DR: NarrativeTrack是首个评估MLLMs细粒度叙事理解的基准，揭示其在实体跟踪和时间推理上的不足，提出感知与时间推理整合的必要性。


<details>
  <summary>Details</summary>
Motivation: 探索MLLMs在视频中理解时间展开叙事的能力，填补现有基准在细粒度实体推理上的不足。

Method: 通过Compositional Reasoning Progression (CRP)框架，逐步增加叙事复杂性，评估MLLMs在实体存在、变化和模糊性三个维度的表现。

Result: 现有MLLMs在视觉转换和时间动态中无法稳健跟踪实体，常出现上下文偏移下的身份幻觉。开源通用MLLMs感知基础强但时间连贯性弱，视频专用MLLMs则相反。

Conclusion: NarrativeTrack揭示了MLLMs在叙事理解中的核心挑战：感知基础与时间推理之间的权衡，只有两者的整合才能实现真正的叙事理解。

Abstract: Multimodal large language models (MLLMs) have achieved impressive progress in vision-language reasoning, yet their ability to understand temporally unfolding narratives in videos remains underexplored. True narrative understanding requires grounding who is doing what, when, and where, maintaining coherent entity representations across dynamic visual and temporal contexts. We introduce NarrativeTrack, the first benchmark to evaluate narrative understanding in MLLMs through fine-grained entity-centric reasoning. Unlike existing benchmarks limited to short clips or coarse scene-level semantics, we decompose videos into constituent entities and examine their continuity via a Compositional Reasoning Progression (CRP), a structured evaluation framework that progressively increases narrative complexity across three dimensions: entity existence, entity changes, and entity ambiguity. CRP challenges models to advance from temporal persistence to contextual evolution and fine-grained perceptual reasoning. A fully automated entity-centric pipeline enables scalable extraction of temporally grounded entity representations, providing the foundation for CRP. Evaluations of state-of-the-art MLLMs reveal that models fail to robustly track entities across visual transitions and temporal dynamics, often hallucinating identity under context shifts. Open-source general-purpose MLLMs exhibit strong perceptual grounding but weak temporal coherence, while video-specific MLLMs capture temporal context yet hallucinate entity's contexts. These findings uncover a fundamental trade-off between perceptual grounding and temporal reasoning, indicating that narrative understanding emerges only from their integration. NarrativeTrack provides the first systematic framework to diagnose and advance temporally grounded narrative comprehension in MLLMs.

</details>


### [41] [VIT-Ped: Visionary Intention Transformer for Pedestrian Behavior Analysis](https://arxiv.org/abs/2601.01989)
*Aly R. Elkammar,Karim M. Gamaleldin,Catherine M. Elias*

Main category: cs.CV

TL;DR: 论文提出了一种基于Transformer的行人意图预测算法，结合多模态数据，在JAAD数据集上性能超越SOTA。


<details>
  <summary>Details</summary>
Motivation: 行人意图预测是自动驾驶从L3向L4过渡的关键技术，理解行人过街行为对提升道路安全至关重要。

Method: 采用不同规模的Transformer/Video Vision Transformer算法，结合多种数据模态进行行人意图预测。

Result: 在JAAD数据集上实现了SOTA性能，并在准确率、AUC和F1分数等指标上超越了现有最佳方法。

Conclusion: 该论文通过引入基于Transformer/Video Vision Transformer的算法，结合多种数据模态，在行人意图预测领域取得了显著的性能提升，并在JAAD数据集上达到了SOTA水平。

Abstract: Pedestrian Intention prediction is one of the key technologies in the transition from level 3 to level 4 autonomous driving. To understand pedestrian crossing behaviour, several elements and features should be taken into consideration to make the roads of tomorrow safer for everybody. We introduce a transformer / video vision transformer based algorithm of different sizes which uses different data modalities .We evaluated our algorithms on popular pedestrian behaviour dataset, JAAD, and have reached SOTA performance and passed the SOTA in metrics like Accuracy, AUC and F1-score. The advantages brought by different model design choices are investigated via extensive ablation studies.

</details>


### [42] [Evolving CNN Architectures: From Custom Designs to Deep Residual Models for Diverse Image Classification and Detection Tasks](https://arxiv.org/abs/2601.01099)
*Mahmudul Hasan,Mabsur Fatin Bin Hossain*

Main category: cs.CV

TL;DR: 自定义CNN与预训练模型在多种图像任务中的比较研究表明，深层CNN在复杂任务中表现更优，而轻量模型适用于简单任务，为实际应用提供了网络选择指导。


<details>
  <summary>Details</summary>
Motivation: 探讨不同CNN架构在多种图像数据集（包括二元分类、细粒度多类识别和物体检测场景）中的性能表现，为实际应用提供网络设计选择的依据。

Method: 本文提出了一种自定义卷积神经网络（CNN）架构，并与广泛使用的预训练和迁移学习CNN模型在五个真实世界图像数据集上进行了比较研究。分析了网络深度、残差连接和特征提取策略等架构因素如何影响分类和定位性能。

Result: 结果显示，更深层的CNN架构在细粒度多类数据集上表现显著提升，而轻量级预训练和迁移学习模型在简单的二元分类任务中仍然非常有效。此外，提出的架构在物体检测场景中也展示了适应性。

Conclusion: 本研究通过系统分析自定义CNN架构与预训练和迁移学习模型，为根据任务复杂性和资源限制选择合适的网络设计提供了实用指导。

Abstract: This paper presents a comparative study of a custom convolutional neural network (CNN) architecture against widely used pretrained and transfer learning CNN models across five real-world image datasets. The datasets span binary classification, fine-grained multiclass recognition, and object detection scenarios. We analyze how architectural factors, such as network depth, residual connections, and feature extraction strategies, influence classification and localization performance. The results show that deeper CNN architectures provide substantial performance gains on fine-grained multiclass datasets, while lightweight pretrained and transfer learning models remain highly effective for simpler binary classification tasks. Additionally, we extend the proposed architecture to an object detection setting, demonstrating its adaptability in identifying unauthorized auto-rickshaws in real-world traffic scenes. Building upon a systematic analysis of custom CNN architectures alongside pretrained and transfer learning models, this study provides practical guidance for selecting suitable network designs based on task complexity and resource constraints.

</details>


### [43] [Histogram Assisted Quality Aware Generative Model for Resolution Invariant NIR Image Colorization](https://arxiv.org/abs/2601.01103)
*Abhinav Attri,Rajeev Ranjan Dwivedi,Samiran Das,Vinod Kumar Kurmi*

Main category: cs.CV

TL;DR: HAQAGen 是一个统一的生成模型，通过结合多种损失项和先验，实现了高分辨率的 NIR-to-RGB 转换，并在多个评估中表现优异。


<details>
  <summary>Details</summary>
Motivation: 旨在实现分辨率不变的 NIR-to-RGB 着色，平衡色彩真实性与结构保真度。

Method: HAQAGen 结合了全局颜色统计对齐、局部色调-饱和度先验注入和纹理感知监督，采用 Mamba 骨干网络，并引入了自适应分辨率推理引擎。

Result: 在多个数据集和评估指标上，HAQAGen 显著优于现有基线方法，生成具有更锐利纹理和自然色彩的图像。

Conclusion: HAQAGen 被定位为一个可扩展且有效的解决方案，适用于多种成像场景中的 NIR-to-RGB 转换。

Abstract: We present HAQAGen, a unified generative model for resolution-invariant NIR-to-RGB colorization that balances chromatic realism with structural fidelity. The proposed model introduces (i) a combined loss term aligning the global color statistics through differentiable histogram matching, perceptual image quality measure, and feature based similarity to preserve texture information, (ii) local hue-saturation priors injected via Spatially Adaptive Denormalization (SPADE) to stabilize chromatic reconstruction, and (iii) texture-aware supervision within a Mamba backbone to preserve fine details. We introduce an adaptive-resolution inference engine that further enables high-resolution translation without sacrificing quality. Our proposed NIR-to-RGB translation model simultaneously enforces global color statistics and local chromatic consistency, while scaling to native resolutions without compromising texture fidelity or generalization. Extensive evaluations on FANVID, OMSIV, VCIP2020, and RGB2NIR using different evaluation metrics demonstrate consistent improvements over state-of-the-art baseline methods. HAQAGen produces images with sharper textures, natural colors, attaining significant gains as per perceptual metrics. These results position HAQAGen as a scalable and effective solution for NIR-to-RGB translation across diverse imaging scenarios. Project Page: https://rajeev-dw9.github.io/HAQAGen/

</details>


### [44] [Cross-Layer Attentive Feature Upsampling for Low-latency Semantic Segmentation](https://arxiv.org/abs/2601.01167)
*Tianheng Cheng,Xinggang Wang,Junchao Liao,Wenyu Liu*

Main category: cs.CV

TL;DR: GAI方法通过自适应插值高分辨率特征与语义特征，解决了特征不对齐和计算负担问题，实现了低延迟下的最优语义分割效果。


<details>
  <summary>Details</summary>
Motivation: 当前坐标引导的低分辨率特征插值方法（如双线性插值）生成的高分辨率特征粗糙，存在特征不对齐和上下文信息不足的问题，且语义丰富化计算负担高，难以满足低延迟推理需求。

Method: 提出了一种新颖的引导注意力插值（GAI）方法，通过确定不同分辨率特征的空间和语义关系，利用这些关系插值具有丰富语义的高分辨率特征。

Result: 基于GAI的语义分割网络GAIN在Cityscapes上达到78.8 mIoU（22.3 FPS），在CamVid上达到80.6 mIoU（64.5 FPS），均使用NVIDIA 1080Ti GPU，成为低延迟语义分割的最新最优结果。

Conclusion: GAI方法通过自适应插值细粒度高分辨率特征与语义特征，解决了特征不对齐和上下文信息不足的问题，并在低延迟推理中实现了最先进的语义分割效果。

Abstract: Semantic segmentation is a fundamental problem in computer vision and it requires high-resolution feature maps for dense prediction. Current coordinate-guided low-resolution feature interpolation methods, e.g., bilinear interpolation, produce coarse high-resolution features which suffer from feature misalignment and insufficient context information. Moreover, enriching semantics to high-resolution features requires a high computation burden, so that it is challenging to meet the requirement of lowlatency inference. We propose a novel Guided Attentive Interpolation (GAI) method to adaptively interpolate fine-grained high-resolution features with semantic features to tackle these issues. Guided Attentive Interpolation determines both spatial and semantic relations of pixels from features of different resolutions and then leverages these relations to interpolate high-resolution features with rich semantics. GAI can be integrated with any deep convolutional network for efficient semantic segmentation. In experiments, the GAI-based semantic segmentation networks, i.e., GAIN, can achieve78.8 mIoU with 22.3 FPS on Cityscapes and 80.6 mIoU with 64.5 on CamVid using an NVIDIA 1080Ti GPU, which are the new state-of-the-art results of low-latency semantic segmentation. Code and models are available at: https://github.com/hustvl/simpleseg.

</details>


### [45] [CardioMOD-Net: A Modal Decomposition-Neural Network Framework for Diagnosis and Prognosis of HFpEF from Echocardiography Cine Loops](https://arxiv.org/abs/2601.01176)
*Andrés Bell-Navas,Jesús Garicano-Mena,Antonella Ausiello,Soledad Le Clainche,María Villalba-Orero,Enrique Lara-Pezzi*

Main category: cs.CV

TL;DR: 开发了CardioMOD-Net框架，通过单一超声心动图循环实现HFpEF的多类诊断和连续发病预测，准确率65%，预测误差21.72周。


<details>
  <summary>Details</summary>
Motivation: 解决当前AI模型在HFpEF早期诊断和预后中的局限性，如缺乏针对特定并发症的表型分析和疾病进展的时间预测。

Method: 使用小鼠超声心动图视频，通过高阶动态模式分解（HODMD）提取时间特征，结合Vision Transformers进行分类和回归分析。

Result: 诊断准确率为65%，预后模块的预测误差为21.72周，OB和SAH组的预测最为准确。

Conclusion: CardioMOD-Net框架展示了从小数据集的单一超声心动图循环中实现多类表型分析和连续HFpEF发病预测的潜力，为临床前HFpEF研究提供了诊断和预后建模的基础。

Abstract: Introduction: Heart failure with preserved ejection fraction (HFpEF) arises from diverse comorbidities and progresses through prolonged subclinical stages, making early diagnosis and prognosis difficult. Current echocardiography-based Artificial Intelligence (AI) models focus primarily on binary HFpEF detection in humans and do not provide comorbidity-specific phenotyping or temporal estimates of disease progression towards decompensation. We aimed to develop a unified AI framework, CardioMOD-Net, to perform multiclass diagnosis and continuous prediction of HFpEF onset directly from standard echocardiography cine loops in preclinical models.
  Methods: Mouse echocardiography videos from four groups were used: control (CTL), hyperglycaemic (HG), obesity (OB), and systemic arterial hypertension (SAH). Two-dimensional parasternal long-axis cine loops were decomposed using Higher Order Dynamic Mode Decomposition (HODMD) to extract temporal features for downstream analysis. A shared latent representation supported Vision Transformers, one for a classifier for diagnosis and another for a regression module for predicting the age at HFpEF onset.
  Results: Overall diagnostic accuracy across the four groups was 65%, with all classes exceeding 50% accuracy. Misclassifications primarily reflected early-stage overlap between OB or SAH and CTL. The prognostic module achieved a root-mean-square error of 21.72 weeks for time-to-HFpEF prediction, with OB and SAH showing the most accurate estimates. Predicted HFpEF onset closely matched true distributions in all groups.
  Discussion: This unified framework demonstrates that multiclass phenotyping and continuous HFpEF onset prediction can be obtained from a single cine loop, even under small-data conditions. The approach offers a foundation for integrating diagnostic and prognostic modelling in preclinical HFpEF research.

</details>


### [46] [GenCAMO: Scene-Graph Contextual Decoupling for Environment-aware and Mask-free Camouflage Image-Dense Annotation Generation](https://arxiv.org/abs/2601.01181)
*Chenglizhao Chen,Shaojiang Yuan,Xiaoxue Lu,Mengke Song,Jia Song,Zhenyu Wu,Wenfeng Song,Shuai Li*

Main category: cs.CV

TL;DR: 提出GenCAMO框架和数据集，通过生成合成数据解决伪装数据集稀缺问题，提升密集预测性能。


<details>
  <summary>Details</summary>
Motivation: 高质量、大规模的伪装数据集稀缺，数据收集和标注成本高昂，因此探索利用生成模型合成数据以训练CDP模型。

Method: 提出了GenCAMO-DB数据集和GenCAMO生成框架，后者是一个环境感知且无需掩码的生成方法，能生成高保真伪装图像密集标注。

Result: 在多模态实验中，GenCAMO显著提升了密集预测性能。

Conclusion: GenCAMO框架通过生成高质量合成数据显著提升了复杂伪装场景下的密集预测性能，代码和数据集将在论文接受后发布。

Abstract: Conceal dense prediction (CDP), especially RGB-D camouflage object detection and open-vocabulary camouflage object segmentation, plays a crucial role in advancing the understanding and reasoning of complex camouflage scenes. However, high-quality and large-scale camouflage datasets with dense annotation remain scarce due to expensive data collection and labeling costs. To address this challenge, we explore leveraging generative models to synthesize realistic camouflage image-dense data for training CDP models with fine-grained representations, prior knowledge, and auxiliary reasoning. Concretely, our contributions are threefold: (i) we introduce GenCAMO-DB, a large-scale camouflage dataset with multi-modal annotations, including depth maps, scene graphs, attribute descriptions, and text prompts; (ii) we present GenCAMO, an environment-aware and mask-free generative framework that produces high-fidelity camouflage image-dense annotations; (iii) extensive experiments across multiple modalities demonstrate that GenCAMO significantly improves dense prediction performance on complex camouflage scenes by providing high-quality synthetic data. The code and datasets will be released after paper acceptance.

</details>


### [47] [Crowded Video Individual Counting Informed by Social Grouping and Spatial-Temporal Displacement Priors](https://arxiv.org/abs/2601.01192)
*Hao Lu,Xuhui Zhu,Wenjing Zhang,Yanan Li,Xiang Bai*

Main category: cs.CV

TL;DR: OMAN++通过O2M匹配和位移先验注入器，显著提升了拥挤场景下的视频个体计数性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有VIC方法在拥挤场景（如地铁通勤）中的性能不足问题。

Method: 通过放松标准的一对一匹配（O2O）为一对多匹配（O2M），并设计了位移先验注入器，结合隐式上下文生成器和O2M匹配器。

Result: 在WuhanMetroCrowd数据集上误差降低了38.12%，并在SenseCrowd、CroHD和MovingDroneCrowd基准上表现优异。

Conclusion: OMAN++ 在拥挤场景中表现出色，显著降低了误差，并在多个基准数据集上超越了现有VIC基线。

Abstract: Video Individual Counting (VIC) is a recently introduced task aiming to estimate pedestrian flux from a video. It extends Video Crowd Counting (VCC) beyond the per-frame pedestrian count. In contrast to VCC that learns to count pedestrians across frames, VIC must identify co-existent pedestrians between frames, which turns out to be a correspondence problem. Existing VIC approaches, however, can underperform in congested scenes such as metro commuting. To address this, we build WuhanMetroCrowd, one of the first VIC datasets that characterize crowded, dynamic pedestrian flows. It features sparse-to-dense density levels, short-to-long video clips, slow-to-fast flow variations, front-to-back appearance changes, and light-to-heavy occlusions. To better adapt VIC approaches to crowds, we rethink the nature of VIC and recognize two informative priors: i) the social grouping prior that indicates pedestrians tend to gather in groups and ii) the spatial-temporal displacement prior that informs an individual cannot teleport physically. The former inspires us to relax the standard one-to-one (O2O) matching used by VIC to one-to-many (O2M) matching, implemented by an implicit context generator and a O2M matcher; the latter facilitates the design of a displacement prior injector, which strengthens not only O2M matching but also feature extraction and model training. These designs jointly form a novel and strong VIC baseline OMAN++. Extensive experiments show that OMAN++ not only outperforms state-of-the-art VIC baselines on the standard SenseCrowd, CroHD, and MovingDroneCrowd benchmarks, but also indicates a clear advantage in crowded scenes, with a 38.12% error reduction on our WuhanMetroCrowd dataset. Code, data, and pretrained models are available at https://github.com/tiny-smart/OMAN.

</details>


### [48] [MS-ISSM: Objective Quality Assessment of Point Clouds Using Multi-scale Implicit Structural Similarity](https://arxiv.org/abs/2601.01200)
*Zhang Chen,Shuai Wan,Yuezhe Zhang,Siyu Ren,Fuzheng Yang,Junhui Hou*

Main category: cs.CV

TL;DR: 提出MS-ISSM方法，通过RBF和ResGrouped-MLP网络解决点云质量评估中的不规则性问题，实验证明其优越性。


<details>
  <summary>Details</summary>
Motivation: 点云的非结构化和不规则性给质量评估带来挑战，传统点对点匹配方法存在误差。

Method: 采用多尺度隐式结构相似性测量（MS-ISSM）和ResGrouped-MLP质量评估网络，通过RBF表示局部特征，并利用分组编码策略结合残差块和通道注意力机制。

Result: 在多个基准测试中，MS-ISSM在可靠性和泛化性上优于现有方法。

Conclusion: MS-ISSM方法在点云质量评估中表现出色，超越了现有最先进的指标，具有较高的可靠性和泛化能力。

Abstract: The unstructured and irregular nature of point clouds poses a significant challenge for objective quality assessment (PCQA), particularly in establishing accurate perceptual feature correspondence. To tackle this, we propose the Multi-scale Implicit Structural Similarity Measurement (MS-ISSM). Unlike traditional point-to-point matching, MS-ISSM utilizes Radial Basis Functions (RBF) to represent local features continuously, transforming distortion measurement into a comparison of implicit function coefficients. This approach effectively circumvents matching errors inherent in irregular data. Additionally, we propose a ResGrouped-MLP quality assessment network, which robustly maps multi-scale feature differences to perceptual scores. The network architecture departs from traditional flat MLPs by adopting a grouped encoding strategy integrated with Residual Blocks and Channel-wise Attention mechanisms. This hierarchical design allows the model to preserve the distinct physical semantics of luma, chroma, and geometry while adaptively focusing on the most salient distortion features across High, Medium, and Low scales. Experimental results on multiple benchmarks demonstrate that MS-ISSM outperforms state-of-the-art metrics in both reliability and generalization. The source code is available at: https://github.com/ZhangChen2022/MS-ISSM.

</details>


### [49] [RefSR-Adv: Adversarial Attack on Reference-based Image Super-Resolution Models](https://arxiv.org/abs/2601.01202)
*Jiazhu Dai,Huihui Jiang*

Main category: cs.CV

TL;DR: RefSR-Adv是一种针对RefSR的对抗攻击方法，通过扰动参考图像导致超分辨率输出质量下降，揭示了模型的安全漏洞。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注RefSR的后门攻击，而对抗攻击的脆弱性尚未充分探索。

Method: 提出了RefSR-Adv对抗攻击方法，通过仅扰动参考图像来降低超分辨率输出质量。

Result: 实验证实，低分辨率输入与参考图像的相似度与攻击效果呈正相关，揭示了模型过度依赖参考特征是关键安全缺陷。

Conclusion: 本研究揭示了RefSR系统的安全漏洞，旨在促使研究人员关注RefSR的鲁棒性问题。

Abstract: Single Image Super-Resolution (SISR) aims to recover high-resolution images from low-resolution inputs. Unlike SISR, Reference-based Super-Resolution (RefSR) leverages an additional high-resolution reference image to facilitate the recovery of high-frequency textures. However, existing research mainly focuses on backdoor attacks targeting RefSR, while the vulnerability of the adversarial attacks targeting RefSR has not been fully explored. To fill this research gap, we propose RefSR-Adv, an adversarial attack that degrades SR outputs by perturbing only the reference image. By maximizing the difference between adversarial and clean outputs, RefSR-Adv induces significant performance degradation and generates severe artifacts across CNN, Transformer, and Mamba architectures on the CUFED5, WR-SR, and DRefSR datasets. Importantly, experiments confirm a positive correlation between the similarity of the low-resolution input and the reference image and attack effectiveness, revealing that the model's over-reliance on reference features is a key security flaw. This study reveals a security vulnerability in RefSR systems, aiming to urge researchers to pay attention to the robustness of RefSR.

</details>


### [50] [XStreamVGGT: Extremely Memory-Efficient Streaming Vision Geometry Grounded Transformer with KV Cache Compression](https://arxiv.org/abs/2601.01204)
*Zunhai Su,Weihao Ye,Hansen Feng,Keyu Fan,Jing Zhang,Dahai Yu,Zhengwu Liu,Ngai Wong*

Main category: cs.CV

TL;DR: XStreamVGGT通过剪枝和量化压缩KV缓存，显著降低内存和延迟，适用于流式3D应用。


<details>
  <summary>Details</summary>
Motivation: StreamVGGT虽然利用帧级因果注意力实现了强大的流式重建，但随着输入帧的累积，KV缓存的无限增长导致内存消耗和推理延迟不断增加。

Method: 通过有效的令牌重要性识别剪枝多视图输入产生的冗余KV，并利用KV张量的独特分布进行量化，进一步减少内存消耗。

Result: XStreamVGGT在性能损失可忽略的情况下，内存使用减少了4.42倍，推理速度提高了5.48倍。

Conclusion: XStreamVGGT通过联合剪枝和量化系统性地压缩KV缓存，实现了高效的内存流式推理，显著降低了内存使用和推理延迟，适用于可扩展的流式3D应用。

Abstract: Learning-based 3D visual geometry models have benefited substantially from large-scale transformers. Among these, StreamVGGT leverages frame-wise causal attention for strong streaming reconstruction, but suffers from unbounded KV cache growth, leading to escalating memory consumption and inference latency as input frames accumulate. We propose XStreamVGGT, a tuning-free approach that systematically compresses the KV cache through joint pruning and quantization, enabling extremely memory-efficient streaming inference. Specifically, redundant KVs originating from multi-view inputs are pruned through efficient token importance identification, enabling a fixed memory budget. Leveraging the unique distribution of KV tensors, we incorporate KV quantization to further reduce memory consumption. Extensive evaluations show that XStreamVGGT achieves mostly negligible performance degradation while substantially reducing memory usage by 4.42$\times$ and accelerating inference by 5.48$\times$, enabling scalable and practical streaming 3D applications. The code is available at https://github.com/ywh187/XStreamVGGT/.

</details>


### [51] [Promptable Foundation Models for SAR Remote Sensing: Adapting the Segment Anything Model for Snow Avalanche Segmentation](https://arxiv.org/abs/2601.01213)
*Riccardo Gelato,Carlo Sgaravatti,Jakob Grahn,Giacomo Boracchi,Filippo Maria Bianchi*

Main category: cs.CV

TL;DR: 利用改进的SAM模型适配Sentinel-1 SAR数据，通过多项技术优化显著提升雪崩标注效率。


<details>
  <summary>Details</summary>
Motivation: 解决SAR图像标注的高成本问题，加速雪崩映射的标注过程。

Method: 采用适配器缓解领域差异，多编码器处理多通道SAR输入，提示工程策略提升定位精度，以及高效训练算法优化计算瓶颈。

Result: 实验证明，该方法有效提升了SAR图像的标注速度。

Conclusion: 通过结合适配器、多编码器、提示工程策略和高效的训练算法，成功将SAM模型适配于Sentinel-1 SAR数据，显著提升了雪崩标注效率。

Abstract: Remote sensing solutions for avalanche segmentation and mapping are key to supporting risk forecasting and mitigation in mountain regions. Synthetic Aperture Radar (SAR) imagery from Sentinel-1 can be effectively used for this task, but training an effective detection model requires gathering a large dataset with high-quality annotations from domain experts, which is prohibitively time-consuming. In this work, we aim to facilitate and accelerate the annotation of SAR images for avalanche mapping. We build on the Segment Anything Model (SAM), a segmentation foundation model trained on natural images, and tailor it to Sentinel-1 SAR data. Adapting SAM to our use-case requires addressing several domain-specific challenges: (i) domain mismatch, since SAM was not trained on satellite/SAR imagery; (ii) input adaptation, because SAR products typically provide more than three channels, while SAM is constrained to RGB images; (iii) robustness to imprecise prompts that can affect target identification and degrade the segmentation quality, an issue exacerbated in small, low-contrast avalanches; and (iv) training efficiency, since standard fine-tuning is computationally demanding for SAM. We tackle these challenges through a combination of adapters to mitigate the domain gap, multiple encoders to handle multi-channel SAR inputs, prompt-engineering strategies to improve avalanche localization accuracy, and a training algorithm that limits the training time of the encoder, which is recognized as the major bottleneck. We integrate the resulting model into an annotation tool and show experimentally that it speeds up the annotation of SAR images.

</details>


### [52] [UniSH: Unifying Scene and Human Reconstruction in a Feed-Forward Pass](https://arxiv.org/abs/2601.01222)
*Mengfei Li,Peng Li,Zheng Zhang,Jiahao Lu,Chengfeng Zhao,Wei Xue,Qifeng Liu,Sida Peng,Wenxiao Zhang,Wenhan Luo,Yuan Liu,Yike Guo*

Main category: cs.CV

TL;DR: UniSH是一个统一的前馈框架，通过创新的训练范式（鲁棒蒸馏和两阶段监督）解决了合成数据与真实数据之间的域差距问题，实现了高保真的场景和人体重建，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 该领域的核心挑战是缺乏大规模、标注的真实世界数据，导致依赖合成数据集，从而引入了显著的模拟到真实的域差距，表现为泛化能力差、人体几何保真度低以及对野外视频的对齐效果不佳。

Method: UniSH采用了一个统一的、前馈的框架，结合了场景重建和HMR的强先验知识，通过两个核心组件进行训练：(1) 从专家深度模型中提取高频细节的鲁棒蒸馏策略；(2) 两阶段监督方案，先在合成数据上学习粗定位，然后在真实数据上通过直接优化SMPL网格与人体点云之间的几何对应进行微调。

Result: 实验结果表明，UniSH在人体中心场景重建方面达到了最先进的性能，并在全局人体运动估计方面表现出了高度竞争力，优于基于优化的框架和仅使用HMR的方法。

Conclusion: UniSH框架通过创新的训练范式，有效地解决了合成数据与真实数据之间的域差距问题，实现了高保真的场景几何和人体重建，并在人体中心场景重建和全局人体运动估计中达到了最先进的性能。

Abstract: We present UniSH, a unified, feed-forward framework for joint metric-scale 3D scene and human reconstruction. A key challenge in this domain is the scarcity of large-scale, annotated real-world data, forcing a reliance on synthetic datasets. This reliance introduces a significant sim-to-real domain gap, leading to poor generalization, low-fidelity human geometry, and poor alignment on in-the-wild videos. To address this, we propose an innovative training paradigm that effectively leverages unlabeled in-the-wild data. Our framework bridges strong, disparate priors from scene reconstruction and HMR, and is trained with two core components: (1) a robust distillation strategy to refine human surface details by distilling high-frequency details from an expert depth model, and (2) a two-stage supervision scheme, which first learns coarse localization on synthetic data, then fine-tunes on real data by directly optimizing the geometric correspondence between the SMPL mesh and the human point cloud. This approach enables our feed-forward model to jointly recover high-fidelity scene geometry, human point clouds, camera parameters, and coherent, metric-scale SMPL bodies, all in a single forward pass. Extensive experiments demonstrate that our model achieves state-of-the-art performance on human-centric scene reconstruction and delivers highly competitive results on global human motion estimation, comparing favorably against both optimization-based frameworks and HMR-only methods. Project page: https://murphylmf.github.io/UniSH/

</details>


### [53] [Improved Object-Centric Diffusion Learning with Registers and Contrastive Alignment](https://arxiv.org/abs/2601.01224)
*Bac Nguyen,Yuhta Takida,Naoki Murata,Chieh-Hsin Lai,Toshimitsu Uesaka,Stefano Ermon,Yuki Mitsufuji*

Main category: cs.CV

TL;DR: CODA通过注册槽和对比对齐损失改进Slot Attention，提升对象中心学习的性能和效率。


<details>
  <summary>Details</summary>
Motivation: Slot Attention（SA）与预训练扩散模型在对象中心学习（OCL）中表现出潜力，但存在槽纠缠和对象槽与图像内容对齐弱的问题。

Method: 提出了对比对象中心扩散对齐（CODA），通过（i）使用注册槽吸收残差注意力减少对象槽之间的干扰，（ii）应用对比对齐损失显式增强槽与图像的对应关系。

Result: 在合成（MOVi-C/E）和真实世界数据集（VOC，COCO）上，CODA在对象发现（如COCO上FG-ARI提升6.1%）、属性预测和组合图像生成方面优于基线。

Conclusion: CODA作为一种有效的框架，展示了在复杂真实场景中进行鲁棒对象中心学习的潜力。

Abstract: Slot Attention (SA) with pretrained diffusion models has recently shown promise for object-centric learning (OCL), but suffers from slot entanglement and weak alignment between object slots and image content. We propose Contrastive Object-centric Diffusion Alignment (CODA), a simple extension that (i) employs register slots to absorb residual attention and reduce interference between object slots, and (ii) applies a contrastive alignment loss to explicitly encourage slot-image correspondence. The resulting training objective serves as a tractable surrogate for maximizing mutual information (MI) between slots and inputs, strengthening slot representation quality. On both synthetic (MOVi-C/E) and real-world datasets (VOC, COCO), CODA improves object discovery (e.g., +6.1% FG-ARI on COCO), property prediction, and compositional image generation over strong baselines. Register slots add negligible overhead, keeping CODA efficient and scalable. These results indicate potential applications of CODA as an effective framework for robust OCL in complex, real-world scenes.

</details>


### [54] [HyDRA: Hybrid Denoising Regularization for Measurement-Only DEQ Training](https://arxiv.org/abs/2601.01228)
*Markus Haltmeier,Lukas Neumann,Nadja Gruber,Johannes Schwab,Gyeongha Hwang*

Main category: cs.CV

TL;DR: HyDRA是一种仅需测量数据的DEQ训练框架，通过自适应正则化和早期停止准则，在稀疏视图CT中实现高质量快速重建。


<details>
  <summary>Details</summary>
Motivation: 解决仅测量数据可用时的图像重建问题，克服传统DEQ模型需要监督数据对的限制。

Method: HyDRA结合了测量一致性和自适应去噪正则化项，并采用数据驱动的早期停止准则进行训练。

Result: 在稀疏视图CT上的实验表明，HyDRA实现了与监督方法竞争的重建质量和快速推理。

Conclusion: HyDRA框架在仅使用测量数据的情况下，通过结合测量一致性和自适应去噪正则化项，以及数据驱动的早期停止准则，实现了与监督方法竞争的重建质量和快速推理。

Abstract: Solving image reconstruction problems of the form \(\mathbf{A} \mathbf{x} = \mathbf{y}\) remains challenging due to ill-posedness and the lack of large-scale supervised datasets. Deep Equilibrium (DEQ) models have been used successfully but typically require supervised pairs \((\mathbf{x},\mathbf{y})\). In many practical settings, only measurements \(\mathbf{y}\) are available. We introduce HyDRA (Hybrid Denoising Regularization Adaptation), a measurement-only framework for DEQ training that combines measurement consistency with an adaptive denoising regularization term, together with a data-driven early stopping criterion. Experiments on sparse-view CT demonstrate competitive reconstruction quality and fast inference.

</details>


### [55] [RFAssigner: A Generic Label Assignment Strategy for Dense Object Detection](https://arxiv.org/abs/2601.01240)
*Ziqian Guan,Xieyi Fu,Yuting Wang,Haowen Xiao,Jiarui Zhu,Yingying Zhu,Yongtao Liu,Lin Gu*

Main category: cs.CV

TL;DR: RFAssigner是一种新颖的标签分配策略，通过自适应选择正样本解决密集检测器中的尺度不平衡问题，显著提升多尺度对象检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有密集检测器的标签分配策略在训练过程中往往对小对象分配的正样本不足，导致尺度不平衡。RFAssigner旨在通过改进分配策略解决这一问题。

Method: RFAssigner首先利用基于点的先验建立初始正样本集，然后通过高斯感受野（GRF）距离度量未分配候选位置与真实对象之间的相似性，自适应地从候选池中选择补充正样本。

Result: 在三个不同对象尺度分布的数据集上的实验表明，RFAssigner显著提升了检测性能，尤其是在小对象上，使用FCOS-ResNet-50检测器即可实现最先进的表现。

Conclusion: RFAssigner通过引入基于高斯感受野距离的自适应正样本选择策略，显著提升了密集检测器在多尺度对象上的性能，无需额外模块或启发式方法即可实现最先进的表现。

Abstract: Label assignment is a critical component in training dense object detectors. State-of-the-art methods typically assign each training sample a positive and a negative weight, optimizing the assignment scheme during training. However, these strategies often assign an insufficient number of positive samples to small objects, leading to a scale imbalance during training. To address this limitation, we introduce RFAssigner, a novel assignment strategy designed to enhance the multi-scale learning capabilities of dense detectors. RFAssigner first establishes an initial set of positive samples using a point-based prior. It then leverages a Gaussian Receptive Field (GRF) distance to measure the similarity between the GRFs of unassigned candidate locations and the ground-truth objects. Based on this metric, RFAssigner adaptively selects supplementary positive samples from the unassigned pool, promoting a more balanced learning process across object scales. Comprehensive experiments on three datasets with distinct object scale distributions validate the effectiveness and generalizability of our method. Notably, a single FCOS-ResNet-50 detector equipped with RFAssigner achieves state-of-the-art performance across all object scales, consistently outperforming existing strategies without requiring auxiliary modules or heuristics.

</details>


### [56] [MambaFormer: Token-Level Guided Routing Mixture-of-Experts for Accurate and Efficient Clinical Assistance](https://arxiv.org/abs/2601.01260)
*Hamad Khan,Saddam Hussain Khan*

Main category: cs.CV

TL;DR: MambaFormer框架通过动态路由和定制化专家模型，高效解决医疗QA任务，显著降低延迟并提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在临床应用中计算成本与线性时间模型效率之间的权衡问题。

Method: 提出基于LLM的MambaFormer混合MoE框架，结合轻量级门控机制动态路由至定制化Transformer专家（ET5）或状态空间模型专家（EMamba），并通过多目标损失联合优化路由决策与计算成本。

Result: MambaFormer在DentalQA和PubMedQA数据集上表现优异（BERTScore=0.9180），延迟极低（0.077秒），速度比T5-Large快24.4倍。

Conclusion: MambaFormer框架通过轻量级门控机制和定制化专家模型，在医疗QA任务中实现了高效与低延迟的平衡，为资源受限的临床部署提供了可扩展解决方案。

Abstract: The deployment of large language models (LLMs) in real-world clinical applications is constrained by the fundamental trade-off between computational cost and the efficiency of linear-time models. To address this, we propose an LLM-based MambaFormer hybrid Mixture-of-Experts (MoE) framework for efficient medical question-answering (QA) and clinical assistance. The MambaFormer employs a lightweight gating mechanism that performs token-level dynamic routing to a customized Transformer expert (ET5) for short, complex queries or to a State Space Model expert (EMamba) for long, high-throughput sequences. The customized EMamba and ET5 models are tailored to accommodate input sequence dimensionality, embedding structure, sequence length, and target-specific output heads, and are fine-tuned through transfer learning on a new, custom-designed DentalQA dataset. Moreover, intelligent routing decisions are driven by the contextual complexity of token embeddings, normalized sequence length, and domain-aware features, thereby enforcing a Pareto-optimal trade-off between inference latency and prediction accuracy. Furthermore, a novel utility-guided multi-objective loss jointly optimizes decisions, router parameters, routing behavior, expert utilization, and computational cost by adaptively regulating token-level expert activation. Finally, the proposed MambaFormer is cross-validated (holdout) for medical QA on the new, custom-designed DentalQA and PubMedQA datasets and compared with state-of-the-art techniques. The proposed MambaFormer outperforms (BERTScore = 0.9180) with ultra-low latency (0.077 s), delivering a 24.4 speedup over T5-Large and establishing a scalable solution for resource-constrained clinical deployment.

</details>


### [57] [AI-Powered Deepfake Detection Using CNN and Vision Transformer Architectures](https://arxiv.org/abs/2601.01281)
*Sifatullah Sheikh Urmi,Kirtonia Nuzath Tabassum Arthi,Md Al-Imran*

Main category: cs.CV

TL;DR: AI models, especially VFDNET with MobileNetV3, effectively detect deepfakes, addressing challenges in digital authenticity.


<details>
  <summary>Details</summary>
Motivation: The rise of AI-generated deepfakes poses significant challenges to digital authenticity, necessitating robust detection methods.

Method: Four AI-based models (three CNNs and one Vision Transformer) were evaluated using large face image datasets, with data preprocessing and augmentation techniques applied to enhance performance.

Result: VFDNET paired with MobileNetV3 achieved superior accuracy, demonstrating efficient performance in deepfake detection.

Conclusion: AI, particularly VFDNET with MobileNetV3, shows strong capabilities for reliable deepfake detection, highlighting its potential in maintaining digital authenticity.

Abstract: The increasing use of artificial intelligence generated deepfakes creates major challenges in maintaining digital authenticity. Four AI-based models, consisting of three CNNs and one Vision Transformer, were evaluated using large face image datasets. Data preprocessing and augmentation techniques improved model performance across different scenarios. VFDNET demonstrated superior accuracy with MobileNetV3, showing efficient performance, thereby demonstrating AI's capabilities for dependable deepfake detection.

</details>


### [58] [S2M-Net: Spectral-Spatial Mixing for Medical Image Segmentation with Morphology-Aware Adaptive Loss](https://arxiv.org/abs/2601.01285)
*Md. Sanaullah Chowdhury Lameya Sabrin*

Main category: cs.CV

TL;DR: S2M-Net通过SSTM和MASL技术，解决了医学图像分割的三难问题，在多个数据集上实现了最先进的性能，同时减少了计算资源需求。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割需要在局部精度、全局上下文和计算效率之间取得平衡，现有架构无法同时满足这些需求。

Method: S2M-Net结合了两种创新技术：(i) Spectral-Selective Token Mixer (SSTM)，通过截断的2D FFT和可学习的频率滤波实现全局上下文；(ii) Morphology-Aware Adaptive Segmentation Loss (MASL)，通过分析结构特征自动调整损失函数。

Result: 在16个医学影像数据集上，S2M-Net表现出色，如96.12% Dice在息肉分割上，83.77%在外科器械上（比现有技术提高17.85%），80.90%在脑肿瘤上，且参数数量比基于Transformer的方法少3.5-6倍。

Conclusion: S2M-Net通过创新的SSTM和MASL方法，成功解决了医学图像分割中的三难问题，实现了在计算效率、局部精度和全局上下文之间的平衡，并在多个数据集上达到了最先进的性能。

Abstract: Medical image segmentation requires balancing local precision for boundary-critical clinical applications, global context for anatomical coherence, and computational efficiency for deployment on limited data and hardware a trilemma that existing architectures fail to resolve. Although convolutional networks provide local precision at $\mathcal{O}(n)$ cost but limited receptive fields, vision transformers achieve global context through $\mathcal{O}(n^2)$ self-attention at prohibitive computational expense, causing overfitting on small clinical datasets. We propose S2M-Net, a 4.7M-parameter architecture that achieves $\mathcal{O}(HW \log HW)$ global context through two synergistic innovations: (i) Spectral-Selective Token Mixer (SSTM), which exploits the spectral concentration of medical images via truncated 2D FFT with learnable frequency filtering and content-gated spatial projection, avoiding quadratic attention cost while maintaining global receptive fields; and (ii) Morphology-Aware Adaptive Segmentation Loss (MASL), which automatically analyzes structure characteristics (compactness, tubularity, irregularity, scale) to modulate five complementary loss components through constrained learnable weights, eliminating manual per-dataset tuning. Comprehensive evaluation in 16 medical imaging datasets that span 8 modalities demonstrates state-of-the-art performance: 96.12\% Dice on polyp segmentation, 83.77\% on surgical instruments (+17.85\% over the prior art) and 80.90\% on brain tumors, with consistent 3-18\% improvements over specialized baselines while using 3.5--6$\times$ fewer parameters than transformer-based methods.

</details>


### [59] [VReID-XFD: Video-based Person Re-identification at Extreme Far Distance Challenge Results](https://arxiv.org/abs/2601.01312)
*Kailash A. Hambarde,Hugo Proença,Md Rashidunnabi,Pranita Samale,Qiwei Yang,Pingping Zhang,Zijing Gong,Yuhao Wang,Xi Zhang,Ruoshui Qu,Qiaoyun He,Yuhang Zhang,Thi Ngoc Ha Nguyen,Tien-Dung Mai,Cheng-Jun Kang,Yu-Fan Lin,Jin-Hui Jiang,Chih-Chung Hsu,Tamás Endrei,György Cserey,Ashwat Rajbhandari*

Main category: cs.CV

TL;DR: VReID-XFD是一个极端远距离空对地行人重识别基准，揭示了性能随距离和视角的下降趋势，最佳方法表现有限。


<details>
  <summary>Details</summary>
Motivation: 现有行人重识别系统在极端远距离下因分辨率下降、视角变化、运动线索不稳定和服装变化而表现不佳，需要新的研究基准。

Method: 研究团队引入了VReID-XFD，一个基于视频的极端远距离（XFD）空中到地面行人重识别基准，包含371个身份、11,288个轨迹和11.75百万帧，覆盖多种高度、视角和水平距离。

Result: VReID-XFD-25挑战吸引了10个团队参与，最佳方法SAS-PReID在空对地设置下仅达到43.93%的mAP。

Conclusion: VReID-XFD提供了一个极端远距离空中到地面行人重识别的视频基准和社区挑战，揭示了性能随高度和距离的单调下降以及俯视视角的普遍劣势。

Abstract: Person re-identification (ReID) across aerial and ground views at extreme far distances introduces a distinct operating regime where severe resolution degradation, extreme viewpoint changes, unstable motion cues, and clothing variation jointly undermine the appearance-based assumptions of existing ReID systems. To study this regime, we introduce VReID-XFD, a video-based benchmark and community challenge for extreme far-distance (XFD) aerial-to-ground person re-identification. VReID-XFD is derived from the DetReIDX dataset and comprises 371 identities, 11,288 tracklets, and 11.75 million frames, captured across altitudes from 5.8 m to 120 m, viewing angles from oblique (30 degrees) to nadir (90 degrees), and horizontal distances up to 120 m. The benchmark supports aerial-to-aerial, aerial-to-ground, and ground-to-aerial evaluation under strict identity-disjoint splits, with rich physical metadata. The VReID-XFD-25 Challenge attracted 10 teams with hundreds of submissions. Systematic analysis reveals monotonic performance degradation with altitude and distance, a universal disadvantage of nadir views, and a trade-off between peak performance and robustness. Even the best-performing SAS-PReID method achieves only 43.93 percent mAP in the aerial-to-ground setting. The dataset, annotations, and official evaluation protocols are publicly available at https://www.it.ubi.pt/DetReIDX/ .

</details>


### [60] [LinMU: Multimodal Understanding Made Linear](https://arxiv.org/abs/2601.01322)
*Hongjie Wang,Niraj K. Jha*

Main category: cs.CV

TL;DR: LinMU是一种线性复杂度的VLM设计，通过M-MATE块和三阶段蒸馏框架，在保持性能的同时显著提升效率。


<details>
  <summary>Details</summary>
Motivation: 解决现代视觉语言模型因自注意力的二次复杂度而无法在边缘设备部署及处理高分辨率图像和长视频的高成本问题。

Method: LinMU通过M-MATE块（结合Flex-MA分支和Local-Swin分支）替换自注意力层，并采用三阶段蒸馏框架（初始化、联合微调、LoRA适配器微调）转换预训练VLM。

Result: 在多个基准测试中，LinMU性能与教师模型相当，但TTFT降低2.7倍，令牌吞吐量提升9.0倍。

Conclusion: LinMU框架证明了无需二次注意力即可实现最先进的多模态推理，为处理高分辨率图像和长视频的长上下文VLM开辟了新途径。

Abstract: Modern Vision-Language Models (VLMs) achieve impressive performance but are limited by the quadratic complexity of self-attention, which prevents their deployment on edge devices and makes their understanding of high-resolution images and long-context videos prohibitively expensive. To address this challenge, we introduce LinMU (Linear-complexity Multimodal Understanding), a VLM design that achieves linear complexity without using any quadratic-complexity modules while maintaining the performance of global-attention-based VLMs. LinMU replaces every self-attention layer in the VLM with the M-MATE block: a dual-branch module that combines a bidirectional state-space model for global context (Flex-MA branch) with localized Swin-style window attention (Local-Swin branch) for adjacent correlations. To transform a pre-trained VLM into the LinMU architecture, we propose a three-stage distillation framework that (i) initializes both branches with self-attention weights and trains the Flex-MA branch alone, (ii) unfreezes the Local-Swin branch and fine-tunes it jointly with the Flex-MA branch, and (iii) unfreezes the remaining blocks and fine-tunes them using LoRA adapters, while regressing on hidden states and token-level logits of the frozen VLM teacher. On MMMU, TextVQA, LongVideoBench, Video-MME, and other benchmarks, LinMU matches the performance of teacher models, yet reduces Time-To-First-Token (TTFT) by up to 2.7$\times$ and improves token throughput by up to 9.0$\times$ on minute-length videos. Ablations confirm the importance of each distillation stage and the necessity of the two branches of the M-MATE block. The proposed framework demonstrates that state-of-the-art multimodal reasoning can be achieved without quadratic attention, thus opening up avenues for long-context VLMs that can deal with high-resolution images and long videos.

</details>


### [61] [Achieving Fine-grained Cross-modal Understanding through Brain-inspired Hierarchical Representation Learning](https://arxiv.org/abs/2601.01339)
*Weihang You,Hanqi Jiang,Yi Pan,Junhao Chen,Tianming Liu,Fei Dou*

Main category: cs.CV

TL;DR: NeuroAlign通过模拟视觉系统的层次结构，结合NTCL和动态多模态融合，提升了fMRI-视频对齐的精度。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法反映视觉处理的层次性和时序性，NeuroAlign旨在填补这一空白。

Method: 采用两阶段机制：全局语义理解（NTCL）和细粒度模式匹配（增强向量量化），结合DynaSyncMM-EMA实现动态多模态融合。

Result: 在跨模态检索任务中，NeuroAlign显著优于现有方法。

Conclusion: NeuroAlign通过模拟人类视觉系统的层次结构，显著提升了fMRI-视频对齐的精度，为理解视觉认知机制提供了新范式。

Abstract: Understanding neural responses to visual stimuli remains challenging due to the inherent complexity of brain representations and the modality gap between neural data and visual inputs. Existing methods, mainly based on reducing neural decoding to generation tasks or simple correlations, fail to reflect the hierarchical and temporal processes of visual processing in the brain. To address these limitations, we present NeuroAlign, a novel framework for fine-grained fMRI-video alignment inspired by the hierarchical organization of the human visual system. Our framework implements a two-stage mechanism that mirrors biological visual pathways: global semantic understanding through Neural-Temporal Contrastive Learning (NTCL) and fine-grained pattern matching through enhanced vector quantization. NTCL explicitly models temporal dynamics through bidirectional prediction between modalities, while our DynaSyncMM-EMA approach enables dynamic multi-modal fusion with adaptive weighting. Experiments demonstrate that NeuroAlign significantly outperforms existing methods in cross-modal retrieval tasks, establishing a new paradigm for understanding visual cognitive mechanisms.

</details>


### [62] [Slot-ID: Identity-Preserving Video Generation from Reference Videos via Slot-Based Temporal Identity Encoding](https://arxiv.org/abs/2601.01352)
*Yixuan Lai,He Wang,Kun Zhou,Tianjia Shao*

Main category: cs.CV

TL;DR: 该论文提出了一种基于短参考视频的动态身份标记方法，用于改进视频生成中的身份保持和运动自然性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在基于单张图像生成视频时，往往忽略时间签名，导致姿势锁定、不自然的扭曲和‘平均’面孔问题。研究旨在解决身份保持与运动自然性之间的张力，通过引入动态参考来改进视频生成。

Method: 研究团队提出了一种基于扩散-变换器的视频生成模型变体，该模型利用短参考视频而非单张肖像来捕捉主体特定的动态模式。通过Sinkhorn路由编码器从参考视频中学习紧凑的身份标记，这些标记能够捕捉特征动态，同时与预训练主干兼容。

Result: 该方法在各种主体和提示下，显著提升了在大姿势变化和丰富表情下的身份保持能力，同时保持了提示忠实度和视觉真实感。

Conclusion: 该方法通过引入基于短参考视频的动态身份标记，显著提升了在姿势变化和丰富表情下身份保持的能力，同时保持了视频生成的提示忠实度和视觉真实感。

Abstract: Producing prompt-faithful videos that preserve a user-specified identity remains challenging: models need to extrapolate facial dynamics from sparse reference while balancing the tension between identity preservation and motion naturalness. Conditioning on a single image completely ignores the temporal signature, which leads to pose-locked motions, unnatural warping, and "average" faces when viewpoints and expressions change. To this end, we introduce an identity-conditioned variant of a diffusion-transformer video generator which uses a short reference video rather than a single portrait. Our key idea is to incorporate the dynamics in the reference. A short clip reveals subject-specific patterns, e.g., how smiles form, across poses and lighting. From this clip, a Sinkhorn-routed encoder learns compact identity tokens that capture characteristic dynamics while remaining pretrained backbone-compatible. Despite adding only lightweight conditioning, the approach consistently improves identity retention under large pose changes and expressive facial behavior, while maintaining prompt faithfulness and visual realism across diverse subjects and prompts.

</details>


### [63] [Advanced Machine Learning Approaches for Enhancing Person Re-Identification Performance](https://arxiv.org/abs/2601.01356)
*Dang H. Pham,Tu N. Nguyen,Hoa N. Nguyen*

Main category: cs.CV

TL;DR: 论文提出三种方法（监督、域适应、无监督）提升行人重识别性能，实验验证了其在多个数据集上的有效性。


<details>
  <summary>Details</summary>
Motivation: 行人重识别在复杂环境中面临外观变化、域偏移和标记数据有限等挑战，需提升性能以应对实际监控需求。

Method: 1. SCM-ReID结合监督对比学习和混合损失优化（分类、中心、三元组和质心-三元组损失）。2. IQAGA和DAPRH结合GAN图像增强、域不变映射和伪标签细化。3. ViTC-UReID利用Vision Transformer特征编码和相机感知代理学习。

Result: SCM-ReID在Market-1501和CUHK03数据集上达到最先进精度；IQAGA和DAPRH在跨域场景中mAP和Rank-1提升高达12%；ViTC-UReID在大规模基准上显著优于现有无监督方法。

Conclusion: 该论文通过提出三种先进方法（SCM-ReID、IQAGA和DAPRH、ViTC-UReID），在监督、无监督域适应和完全无监督设置下显著提升了行人重识别性能，为实际监控系统的稳健部署铺平了道路。

Abstract: Person re-identification (ReID) plays a critical role in intelligent surveillance systems by linking identities across multiple cameras in complex environments. However, ReID faces significant challenges such as appearance variations, domain shifts, and limited labeled data. This dissertation proposes three advanced approaches to enhance ReID performance under supervised, unsupervised domain adaptation (UDA), and fully unsupervised settings. First, SCM-ReID integrates supervised contrastive learning with hybrid loss optimization (classification, center, triplet, and centroid-triplet losses), improving discriminative feature representation and achieving state-of-the-art accuracy on Market-1501 and CUHK03 datasets. Second, for UDA, IQAGA and DAPRH combine GAN-based image augmentation, domain-invariant mapping, and pseudo-label refinement to mitigate domain discrepancies and enhance cross-domain generalization. Experiments demonstrate substantial gains over baseline methods, with mAP and Rank-1 improvements up to 12% in challenging transfer scenarios. Finally, ViTC-UReID leverages Vision Transformer-based feature encoding and camera-aware proxy learning to boost unsupervised ReID. By integrating global and local attention with camera identity constraints, this method significantly outperforms existing unsupervised approaches on large-scale benchmarks. Comprehensive evaluations across CUHK03, Market-1501, DukeMTMC-reID, and MSMT17 confirm the effectiveness of the proposed methods. The contributions advance ReID research by addressing key limitations in feature learning, domain adaptation, and label noise handling, paving the way for robust deployment in real-world surveillance systems.

</details>


### [64] [Garment Inertial Denoiser (GID): Endowing Accurate Motion Capture via Loose IMU Denoiser](https://arxiv.org/abs/2601.01360)
*Jiawei Fang,Ruonan Zheng,Xiaoxia Gao,Shifan Jiang,Anjun Chen,Qi Ye,Shihui Guo*

Main category: cs.CV

TL;DR: GID是一种轻量级Transformer，用于宽松服装中IMU传感器的去噪，通过三阶段处理和专家架构实现高效动作捕捉。


<details>
  <summary>Details</summary>
Motivation: 解决宽松服装中IMU传感器因位移引入的噪声问题，提升穿戴式惯性动作捕捉的舒适性和实用性。

Method: GID采用三阶段处理流程：位置特定去噪、自适应跨服装融合和通用姿态预测，结合位置感知专家架构和轻量级融合模块。

Result: GID在单用户训练下实现实时去噪，并能泛化至未见过的用户、动作和服装类型，显著提升现有惯性动作捕捉方法的性能。

Conclusion: GID作为一种轻量级、即插即用的Transformer模块，能够有效解决宽松服装中IMU传感器的噪声问题，并在实时去噪中表现出色，适用于不同用户、动作和服装类型。

Abstract: Wearable inertial motion capture (MoCap) provides a portable, occlusion-free, and privacy-preserving alternative to camera-based systems, but its accuracy depends on tightly attached sensors - an intrusive and uncomfortable requirement for daily use. Embedding IMUs into loose-fitting garments is a desirable alternative, yet sensor-body displacement introduces severe, structured, and location-dependent corruption that breaks standard inertial pipelines. We propose GID (Garment Inertial Denoiser), a lightweight, plug-and-play Transformer that factorizes loose-wear MoCap into three stages: (i) location-specific denoising, (ii) adaptive cross-wear fusion, and (iii) general pose prediction. GID uses a location-aware expert architecture, where a shared spatio-temporal backbone models global motion while per-IMU expert heads specialize in local garment dynamics, and a lightweight fusion module ensures cross-part consistency. This inductive bias enables stable training and effective learning from limited paired loose-tight IMU data. We also introduce GarMoCap, a combined public and newly collected dataset covering diverse users, motions, and garments. Experiments show that GID enables accurate, real-time denoising from single-user training and generalizes across unseen users, motions, and garment types, consistently improving state-of-the-art inertial MoCap methods when used as a drop-in module.

</details>


### [65] [Unsupervised SE(3) Disentanglement for in situ Macromolecular Morphology Identification from Cryo-Electron Tomography](https://arxiv.org/abs/2601.01364)
*Mostofa Rafid Uddin,Mahek Vora,Qifeng Wu,Muyuan Chen,Min Xu*

Main category: cs.CV

TL;DR: 论文提出了一种解耦深度学习框架，用于从噪声cryo-ET数据中分离形态与变换，显著提升分析效果并发现新形态。


<details>
  <summary>Details</summary>
Motivation: 现有的期望最大化方法在分析cryo-ET数据时，常遗漏罕见但重要的形态，且需要大量手动超参数调整。

Method: 采用解耦的深度表示学习框架，结合新颖的多选择学习模块，从cryo-ET数据中分离SE(3)变换与形态内容。

Result: 在模拟和真实cryo-ET数据集上的实验显示，该方法明显优于现有方法，并发现了新的大分子形态。

Conclusion: 该论文提出了一种解耦的深度表示学习框架，能够从高度噪声的cryo-ET数据中分离SE(3)变换与形态内容，显著提升了形态学分析的准确性，并发现了此前未识别的大分子形态。

Abstract: Cryo-electron tomography (cryo-ET) provides direct 3D visualization of macromolecules inside the cell, enabling analysis of their in situ morphology. This morphology can be regarded as an SE(3)-invariant, denoised volumetric representation of subvolumes extracted from tomograms. Inferring morphology is therefore an inverse problem of estimating both a template morphology and its SE(3) transformation. Existing expectation-maximization based solution to this problem often misses rare but important morphologies and requires extensive manual hyperparameter tuning. Addressing this issue, we present a disentangled deep representation learning framework that separates SE(3) transformations from morphological content in the representation space. The framework includes a novel multi-choice learning module that enables this disentanglement for highly noisy cryo-ET data, and the learned morphological content is used to generate template morphologies. Experiments on simulated and real cryo-ET datasets demonstrate clear improvements over prior methods, including the discovery of previously unidentified macromolecular morphologies.

</details>


### [66] [ParkGaussian: Surround-view 3D Gaussian Splatting for Autonomous Parking](https://arxiv.org/abs/2601.01386)
*Xiaobao Wei,Zhangjie Ye,Yuxiang Gu,Zunjie Zhu,Yunfei Guo,Yingying Shen,Shan Zhao,Ming Lu,Haiyang Sun,Bing Wang,Guang Chen,Rongfeng Lu,Hangjun Ye*

Main category: cs.CV

TL;DR: 该论文提出了首个停车场景3D重建基准ParkRecon3D和框架ParkGaussian，通过整合3DGS技术和停车位感知策略，显著提升了重建质量和下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注2D停车位感知，而3D重建在复杂停车场景中的空间几何捕捉方面仍未被充分探索。单纯提升重建视觉质量并不能直接提升自动停车性能。

Method: 提出了ParkGaussian框架，整合了3D高斯泼溅（3DGS）技术，并引入了一种基于停车位感知的重建策略，以提升重建质量。

Result: 在ParkRecon3D基准测试中，ParkGaussian实现了最先进的重建质量，并显著提升了感知一致性。

Conclusion: ParkGaussian框架在ParkRecon3D基准测试中实现了最先进的重建质量，并更好地保持了感知一致性，为下游任务提供了支持。

Abstract: Parking is a critical task for autonomous driving systems (ADS), with unique challenges in crowded parking slots and GPS-denied environments. However, existing works focus on 2D parking slot perception, mapping, and localization, 3D reconstruction remains underexplored, which is crucial for capturing complex spatial geometry in parking scenarios. Naively improving the visual quality of reconstructed parking scenes does not directly benefit autonomous parking, as the key entry point for parking is the slots perception module. To address these limitations, we curate the first benchmark named ParkRecon3D, specifically designed for parking scene reconstruction. It includes sensor data from four surround-view fisheye cameras with calibrated extrinsics and dense parking slot annotations. We then propose ParkGaussian, the first framework that integrates 3D Gaussian Splatting (3DGS) for parking scene reconstruction. To further improve the alignment between reconstruction and downstream parking slot detection, we introduce a slot-aware reconstruction strategy that leverages existing parking perception methods to enhance the synthesis quality of slot regions. Experiments on ParkRecon3D demonstrate that ParkGaussian achieves state-of-the-art reconstruction quality and better preserves perception consistency for downstream tasks. The code and dataset will be released at: https://github.com/wm-research/ParkGaussian

</details>


### [67] [Evaluation of Convolutional Neural Network For Image Classification with Agricultural and Urban Datasets](https://arxiv.org/abs/2601.01393)
*Shamik Shafkat Avro,Nazira Jesmin Lina,Shahanaz Sharmin*

Main category: cs.CV

TL;DR: 开发了一种高效的CustomCNN，通过创新的架构设计在多领域图像分类任务中表现优异，适用于智能城市和农业应用。


<details>
  <summary>Details</summary>
Motivation: 研究架构设计选择如何影响多领域图像分类任务，并为智能城市和农业成像应用提供高效解决方案。

Method: 开发了一种自定义卷积神经网络（CustomCNN），结合了残差连接、Squeeze-and-Excitation注意力机制、渐进通道缩放和Kaiming初始化，以提升数据表示能力和训练速度。

Result: 在五个公开数据集上的测试表明，CustomCNN在保持计算效率的同时，性能与流行CNN架构相当。

Conclusion: 该论文强调了在现实世界的智能城市和农业成像应用中，深思熟虑的架构设计的重要性。

Abstract: This paper presents the development and evaluation of a custom Convolutional Neural Network (CustomCNN) created to study how architectural design choices affect multi-domain image classification tasks. The network uses residual connections, Squeeze-and-Excitation attention mechanisms, progressive channel scaling, and Kaiming initialization to improve its ability to represent data and speed up training. The model is trained and tested on five publicly available datasets: unauthorized vehicle detection, footpath encroachment detection, polygon-annotated road damage and manhole detection, MangoImageBD and PaddyVarietyBD. A comparison with popular CNN architectures shows that the CustomCNN delivers competitive performance while remaining efficient in computation. The results underscore the importance of thoughtful architectural design for real-world Smart City and agricultural imaging applications.

</details>


### [68] [SwinIFS: Landmark Guided Swin Transformer For Identity Preserving Face Super Resolution](https://arxiv.org/abs/2601.01406)
*Habiba Kausar,Saeed Anwar,Omar Jamal Hammad,Abdul Bais*

Main category: cs.CV

TL;DR: SwinIFS 是一种基于地标引导的超分辨率框架，通过结合结构先验和分层注意力机制，实现了身份保留的面部图像重建，适用于各种放大倍数。


<details>
  <summary>Details</summary>
Motivation: 面部超分辨率任务在恢复严重退化的低分辨率输入时面临丢失精细结构细节和身份特征的挑战。

Method: 该方法结合了密集高斯热图的关键面部标志和紧凑的 Swin Transformer 主干，以捕捉长距离上下文信息并保持局部几何结构。

Result: 在 CelebA 基准测试中，SwinIFS 实现了卓越的感知质量、更清晰的复原效果和更好的身份保留，即使在 8 倍放大下也表现优异。

Conclusion: SwinIFS 提供了一种在重建精度和计算效率之间取得平衡的解决方案，适用于面部增强、监控和数字修复等实际应用。

Abstract: Face super-resolution aims to recover high-quality facial images from severely degraded low-resolution inputs, but remains challenging due to the loss of fine structural details and identity-specific features. This work introduces SwinIFS, a landmark-guided super-resolution framework that integrates structural priors with hierarchical attention mechanisms to achieve identity-preserving reconstruction at both moderate and extreme upscaling factors. The method incorporates dense Gaussian heatmaps of key facial landmarks into the input representation, enabling the network to focus on semantically important facial regions from the earliest stages of processing. A compact Swin Transformer backbone is employed to capture long-range contextual information while preserving local geometry, allowing the model to restore subtle facial textures and maintain global structural consistency. Extensive experiments on the CelebA benchmark demonstrate that SwinIFS achieves superior perceptual quality, sharper reconstructions, and improved identity retention; it consistently produces more photorealistic results and exhibits strong performance even under 8x magnification, where most methods fail to recover meaningful structure. SwinIFS also provides an advantageous balance between reconstruction accuracy and computational efficiency, making it suitable for real-world applications in facial enhancement, surveillance, and digital restoration. Our code, model weights, and results are available at https://github.com/Habiba123-stack/SwinIFS.

</details>


### [69] [Mask-Guided Multi-Task Network for Face Attribute Recognition](https://arxiv.org/abs/2601.01408)
*Gong Gao,Zekai Wang,Jian Zhao,Ziqi Xie,Xianhui Liu,Weidong Zhao*

Main category: cs.CV

TL;DR: MGMTN通过自适应掩模学习和组-全局特征融合，有效解决了传统面部属性识别中的冗余特征问题，提升了识别精度。


<details>
  <summary>Details</summary>
Motivation: 传统多任务属性识别方法依赖全局区域进行特征提取和分类，导致冗余特征问题，需要更高效的特征学习方法。

Method: 提出了一种名为MGMTN的新方法，结合了AML（自适应掩模学习）和G2FF（组-全局特征融合），利用预训练的关键点标注模型和全卷积网络，精确定位关键面部区域并生成组掩模。

Result: 在两个具有挑战性的面部属性识别数据集上的实验表明，MGMTN显著提升了FAR性能。

Conclusion: MGMTN通过结合AML和G2FF，有效提升了面部属性识别的性能，证明了其在减少冗余特征和增强特征学习方面的优势。

Abstract: Face Attribute Recognition (FAR) plays a crucial role in applications such as person re-identification, face retrieval, and face editing. Conventional multi-task attribute recognition methods often process the entire feature map for feature extraction and attribute classification, which can produce redundant features due to reliance on global regions. To address these challenges, we propose a novel approach emphasizing the selection of specific feature regions for efficient feature learning. We introduce the Mask-Guided Multi-Task Network (MGMTN), which integrates Adaptive Mask Learning (AML) and Group-Global Feature Fusion (G2FF) to address the aforementioned limitations. Leveraging a pre-trained keypoint annotation model and a fully convolutional network, AML accurately localizes critical facial parts (e.g., eye and mouth groups) and generates group masks that delineate meaningful feature regions, thereby mitigating negative transfer from global region usage. Furthermore, G2FF combines group and global features to enhance FAR learning, enabling more precise attribute identification. Extensive experiments on two challenging facial attribute recognition datasets demonstrate the effectiveness of MGMTN in improving FAR performance.

</details>


### [70] [AirSpatialBot: A Spatially-Aware Aerial Agent for Fine-Grained Vehicle Attribute Recognization and Retrieval](https://arxiv.org/abs/2601.01416)
*Yue Zhou,Ran Ding,Xue Yang,Xue Jiang,Xingzhao Liu*

Main category: cs.CV

TL;DR: 该研究通过空间感知数据集和两阶段训练策略，提升了遥感视觉语言模型的空间理解能力，并开发了空中代理AirSpatialBot。


<details>
  <summary>Details</summary>
Motivation: 现有遥感视觉语言模型在空间理解方面存在不足，限制了其在实际应用中的效果。

Method: 采用两阶段训练策略：图像理解预训练和空间理解微调，开发了空间感知的视觉语言模型，并构建了空中代理AirSpatialBot。

Result: 实验结果表明，该方法有效提升了模型的空间理解能力，并开发了具备动态任务规划、图像理解、空间理解和任务执行能力的AirSpatialBot。

Conclusion: 该研究通过引入空间感知数据集AirSpatial和两阶段训练策略，显著提升了遥感视觉语言模型的空间理解能力，并开发了具备细粒度车辆属性识别和检索能力的空中代理AirSpatialBot。实验验证了方法的有效性，并揭示了现有模型的局限性。

Abstract: Despite notable advancements in remote sensing vision-language models (VLMs), existing models often struggle with spatial understanding, limiting their effectiveness in real-world applications. To push the boundaries of VLMs in remote sensing, we specifically address vehicle imagery captured by drones and introduce a spatially-aware dataset AirSpatial, which comprises over 206K instructions and introduces two novel tasks: Spatial Grounding and Spatial Question Answering. It is also the first remote sensing grounding dataset to provide 3DBB. To effectively leverage existing image understanding of VLMs to spatial domains, we adopt a two-stage training strategy comprising Image Understanding Pre-training and Spatial Understanding Fine-tuning. Utilizing this trained spatially-aware VLM, we develop an aerial agent, AirSpatialBot, which is capable of fine-grained vehicle attribute recognition and retrieval. By dynamically integrating task planning, image understanding, spatial understanding, and task execution capabilities, AirSpatialBot adapts to diverse query requirements. Experimental results validate the effectiveness of our approach, revealing the spatial limitations of existing VLMs while providing valuable insights. The model, code, and datasets will be released at https://github.com/VisionXLab/AirSpatialBot

</details>


### [71] [DreamID-V:Bridging the Image-to-Video Gap for High-Fidelity Face Swapping via Diffusion Transformer](https://arxiv.org/abs/2601.01425)
*Xu Guo,Fulong Ye,Xinghui Li,Pengqi Tu,Pengze Zhang,Qichao Sun,Songtao Zhao,Xiangwang Hou,Qian He*

Main category: cs.CV

TL;DR: DreamID-V 是一个基于 Diffusion Transformer 的视频人脸交换框架，通过新颖的数据管道和强化学习策略，解决了身份相似性和时间一致性的挑战，并在实验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法在保持身份相似性和属性保留的同时难以维持时间一致性，因此需要将图像人脸交换的优势无缝转移到视频领域。

Method: 提出了一个基于 Diffusion Transformer 的框架 DreamID-V，采用 Modality-Aware Conditioning 模块、Synthetic-to-Real Curriculum 机制和 Identity-Coherence Reinforcement Learning 策略。

Result: DreamID-V 在实验中表现优于现有方法，并展示了在多样化场景中的卓越性能。

Conclusion: DreamID-V 框架在视频人脸交换任务中表现出色，不仅超越了现有方法，还展示了卓越的通用性，可无缝适应多种交换相关任务。

Abstract: Video Face Swapping (VFS) requires seamlessly injecting a source identity into a target video while meticulously preserving the original pose, expression, lighting, background, and dynamic information. Existing methods struggle to maintain identity similarity and attribute preservation while preserving temporal consistency. To address the challenge, we propose a comprehensive framework to seamlessly transfer the superiority of Image Face Swapping (IFS) to the video domain. We first introduce a novel data pipeline SyncID-Pipe that pre-trains an Identity-Anchored Video Synthesizer and combines it with IFS models to construct bidirectional ID quadruplets for explicit supervision. Building upon paired data, we propose the first Diffusion Transformer-based framework DreamID-V, employing a core Modality-Aware Conditioning module to discriminatively inject multi-model conditions. Meanwhile, we propose a Synthetic-to-Real Curriculum mechanism and an Identity-Coherence Reinforcement Learning strategy to enhance visual realism and identity consistency under challenging scenarios. To address the issue of limited benchmarks, we introduce IDBench-V, a comprehensive benchmark encompassing diverse scenes. Extensive experiments demonstrate DreamID-V outperforms state-of-the-art methods and further exhibits exceptional versatility, which can be seamlessly adapted to various swap-related tasks.

</details>


### [72] [EdgeNeRF: Edge-Guided Regularization for Neural Radiance Fields from Sparse Views](https://arxiv.org/abs/2601.01431)
*Weiqi Yu,Yiyang Yao,Lin He,Jianming Lv*

Main category: cs.CV

TL;DR: EdgeNeRF利用边缘引导的深度正则化提升稀疏视图3D重建，保留细节并减少伪影，可即插即用。


<details>
  <summary>Details</summary>
Motivation: 解决NeRF在稀疏输入下因几何伪影导致重建质量下降的问题，同时避免现有全局深度正则化方法丢失几何边界细节的缺陷。

Method: 提出EdgeNeRF算法，利用深度和法线在边缘处的突变特性，首先提取输入图像的边缘，然后在非边缘区域应用深度和法线正则化约束。

Result: 在LLFF和DTU数据集上的实验表明，EdgeNeRF在保留锐利几何边界和抑制伪影方面表现优异，且模块可即插即用提升其他方法性能。

Conclusion: EdgeNeRF通过边缘引导的深度正则化模块显著提升了稀疏视图下的3D重建质量，保留了高频细节，并可无缝集成到其他方法中。

Abstract: Neural Radiance Fields (NeRF) achieve remarkable performance in dense multi-view scenarios, but their reconstruction quality degrades significantly under sparse inputs due to geometric artifacts. Existing methods utilize global depth regularization to mitigate artifacts, leading to the loss of geometric boundary details. To address this problem, we propose EdgeNeRF, an edge-guided sparse-view 3D reconstruction algorithm. Our method leverages the prior that abrupt changes in depth and normals generate edges. Specifically, we first extract edges from input images, then apply depth and normal regularization constraints to non-edge regions, enhancing geometric consistency while preserving high-frequency details at boundaries. Experiments on LLFF and DTU datasets demonstrate EdgeNeRF's superior performance, particularly in retaining sharp geometric boundaries and suppressing artifacts. Additionally, the proposed edge-guided depth regularization module can be seamlessly integrated into other methods in a plug-and-play manner, significantly improving their performance without substantially increasing training time. Code is available at https://github.com/skyhigh404/edgenerf.

</details>


### [73] [In defense of the two-stage framework for open-set domain adaptive semantic segmentation](https://arxiv.org/abs/2601.01439)
*Wenqi Ren,Weijie Wang,Meng Zheng,Ziyan Wu,Yang Tang,Zhun Zhong,Nicu Sebe*

Main category: cs.CV

TL;DR: SATS通过分离-适应策略和硬未知探索，解决了开放集域适应语义分割中的类别不平衡问题，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在单一阶段处理已知和未知类别时，因标注不平衡导致已知类别负迁移和未知类别欠拟合。

Method: 提出SATS（分离-适应训练策略），包括已知/未知类别分离和未知感知域适应两个步骤，并引入硬未知探索数据增强方法。

Result: 在GTA5-to-Cityscapes和SYNTHIA-to-Cityscapes基准上，H-Score分别提升3.85%和18.64%，优于现有方法。

Conclusion: SATS方法通过分离和适应两个步骤，有效解决了开放集域适应语义分割中的已知和未知类别平衡问题，显著提升了性能。

Abstract: Open-Set Domain Adaptation for Semantic Segmentation (OSDA-SS) presents a significant challenge, as it requires both domain adaptation for known classes and the distinction of unknowns. Existing methods attempt to address both tasks within a single unified stage. We question this design, as the annotation imbalance between known and unknown classes often leads to negative transfer of known classes and underfitting for unknowns. To overcome these issues, we propose SATS, a Separating-then-Adapting Training Strategy, which addresses OSDA-SS through two sequential steps: known/unknown separation and unknown-aware domain adaptation. By providing the model with more accurate and well-aligned unknown classes, our method ensures a balanced learning of discriminative features for both known and unknown classes, steering the model toward discovering truly unknown objects. Additionally, we present hard unknown exploration, an innovative data augmentation method that exposes the model to more challenging unknowns, strengthening its ability to capture more comprehensive understanding of target unknowns. We evaluate our method on public OSDA-SS benchmarks. Experimental results demonstrate that our method achieves a substantial advancement, with a +3.85% H-Score improvement for GTA5-to-Cityscapes and +18.64% for SYNTHIA-to-Cityscapes, outperforming previous state-of-the-art methods.

</details>


### [74] [PartImageNet++ Dataset: Enhancing Visual Models with High-Quality Part Annotations](https://arxiv.org/abs/2601.01454)
*Xiao Li,Zilong Liu,Yining Liu,Zhuhong Li,Na Dong,Sitian Qin,Xiaolin Hu*

Main category: cs.CV

TL;DR: PIN++是一个包含100K图像的详细部分注释数据集，用于提升基于部分的模型性能。提出的MPM模型结合伪部分标签和原始注释，显著提升了对象识别和下游任务的性能。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有数据集中高质量部分注释稀缺的问题，引入了PartImageNet++（PIN++）数据集，提供ImageNet-1K所有类别的详细部分注释。

Method: 利用PIN++训练了一个部分分割网络，生成伪部分标签用于未标注图像，并提出了MPM模型，该模型结合了传统识别架构和辅助旁路层，同时受到伪部分标签和原始部分注释的监督。

Result: 实验结果表明，该方法不仅增强了基于部分的模型在对象识别中的鲁棒性，还为多个下游任务（如部分分割、对象分割和少样本学习）建立了强基线。

Conclusion: PIN++数据集和MPM模型不仅提升了基于部分的模型在对象识别中的鲁棒性，还为多个下游任务建立了强基线，展示了部分注释在提升模型性能中的潜力。

Abstract: To address the scarcity of high-quality part annotations in existing datasets, we introduce PartImageNet++ (PIN++), a dataset that provides detailed part annotations for all categories in ImageNet-1K. With 100 annotated images per category, totaling 100K images, PIN++ represents the most comprehensive dataset covering a diverse range of object categories. Leveraging PIN++, we propose a Multi-scale Part-supervised recognition Model (MPM) for robust classification on ImageNet-1K. We first trained a part segmentation network using PIN++ and used it to generate pseudo part labels for the remaining unannotated images. MPM then integrated a conventional recognition architecture with auxiliary bypass layers, jointly supervised by both pseudo part labels and the original part annotations. Furthermore, we conducted extensive experiments on PIN++, including part segmentation, object segmentation, and few-shot learning, exploring various ways to leverage part annotations in downstream tasks. Experimental results demonstrated that our approach not only enhanced part-based models for robust object recognition but also established strong baselines for multiple downstream tasks, highlighting the potential of part annotations in improving model performance. The dataset and the code are available at https://github.com/LixiaoTHU/PartImageNetPP.

</details>


### [75] [Rethinking Multimodal Few-Shot 3D Point Cloud Segmentation: From Fused Refinement to Decoupled Arbitration](https://arxiv.org/abs/2601.01456)
*Wentao Bian,Fenglei Xu*

Main category: cs.CV

TL;DR: DA-FSS通过解耦语义和几何路径，解决了FS-PCS中的冲突和CLIP的混淆问题，实验证明其性能优越。


<details>
  <summary>Details</summary>
Motivation: 解决多模态少样本3D点云语义分割中的‘可塑性-稳定性困境’和CLIP的类间混淆导致的语义盲区问题。

Method: 提出了并行专家细化模块和堆叠仲裁模块（SAM），分别生成模态相关性和仲裁各模态路径。几何专家保持可塑性，语义专家确保稳定性，通过解耦对齐模块（DAM）协调知识传递。

Result: 在S3DIS和ScanNet数据集上的实验表明，DA-FSS优于MM-FSS，且在几何边界、完整性和纹理区分方面均优于基线。

Conclusion: DA-FSS通过解耦语义和几何路径，并相互调节其梯度，有效解决了FS-PCS中的‘可塑性-稳定性困境’和CLIP的类间混淆问题，实现了更好的泛化性能。

Abstract: In this paper, we revisit multimodal few-shot 3D point cloud semantic segmentation (FS-PCS), identifying a conflict in "Fuse-then-Refine" paradigms: the "Plasticity-Stability Dilemma." In addition, CLIP's inter-class confusion can result in semantic blindness. To address these issues, we present the Decoupled-experts Arbitration Few-Shot SegNet (DA-FSS), a model that effectively distinguishes between semantic and geometric paths and mutually regularizes their gradients to achieve better generalization. DA-FSS employs the same backbone and pre-trained text encoder as MM-FSS to generate text embeddings, which can increase free modalities' utilization rate and better leverage each modality's information space. To achieve this, we propose a Parallel Expert Refinement module to generate each modal correlation. We also propose a Stacked Arbitration Module (SAM) to perform convolutional fusion and arbitrate correlations for each modality pathway. The Parallel Experts decouple two paths: a Geometric Expert maintains plasticity, and a Semantic Expert ensures stability. They are coordinated via a Decoupled Alignment Module (DAM) that transfers knowledge without propagating confusion. Experiments on popular datasets (S3DIS, ScanNet) demonstrate the superiority of DA-FSS over MM-FSS. Meanwhile, geometric boundaries, completeness, and texture differentiation are all superior to the baseline. The code is available at: https://github.com/MoWenQAQ/DA-FSS.

</details>


### [76] [Language as Prior, Vision as Calibration: Metric Scale Recovery for Monocular Depth Estimation](https://arxiv.org/abs/2601.01457)
*Mingxing Zhan,Li Zhang,Beibei Wang,Yingjie Wang,Zenglin Shi*

Main category: cs.CV

TL;DR: 通过语言和视觉特征结合，在固定骨干网络下恢复单目度量深度，提升准确性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 单目度量深度由于全局尺度不可识别和域转移敏感性而难以解决，而相对深度基础模型在迁移中表现良好。本文旨在通过结合语言和视觉特征，解决这一问题。

Method: 使用图像特定的仿射变换在逆深度中恢复度量深度，训练轻量级校准头部，同时保持相对深度骨干网络和CLIP文本编码器固定。利用语言预测不确定性感知的边界，约束可行校准参数，并通过多尺度视觉特征选择图像特定的校准。

Result: 在NYUv2和KITTI上提高了域内准确性，零样本迁移到SUN-RGBD和DDAD时，相比仅使用语言的基线方法表现出更强的鲁棒性。

Conclusion: 该方法通过结合语言和视觉特征，在保持相对深度骨干网络固定的情况下，实现了单目度量深度的准确恢复，并在多个数据集上展示了优越的性能和鲁棒性。

Abstract: Relative-depth foundation models transfer well, yet monocular metric depth remains ill-posed due to unidentifiable global scale and heightened domain-shift sensitivity. Under a frozen-backbone calibration setting, we recover metric depth via an image-specific affine transform in inverse depth and train only lightweight calibration heads while keeping the relative-depth backbone and the CLIP text encoder fixed. Since captions provide coarse but noisy scale cues that vary with phrasing and missing objects, we use language to predict an uncertainty-aware envelope that bounds feasible calibration parameters in an unconstrained space, rather than committing to a text-only point estimate. We then use pooled multi-scale frozen visual features to select an image-specific calibration within this envelope. During training, a closed-form least-squares oracle in inverse depth provides per-image supervision for learning the envelope and the selected calibration. Experiments on NYUv2 and KITTI improve in-domain accuracy, while zero-shot transfer to SUN-RGBD and DDAD demonstrates improved robustness over strong language-only baselines.

</details>


### [77] [Domain Adaptation of Carotid Ultrasound Images using Generative Adversarial Network](https://arxiv.org/abs/2601.01460)
*Mohd Usama,Belal Ahmad,Christer Gronlund,Faleh Menawer R Althiyabi*

Main category: cs.CV

TL;DR: 提出一种基于GAN的域适应方法，用于超声图像的跨设备或跨设置分析，通过图像翻译调整纹理和去除噪声，实验证明效果显著。


<details>
  <summary>Details</summary>
Motivation: 医疗影像中，不同设备或参数设置的图像存在纹理和噪声差异，导致模型跨域性能下降。传统方法需针对每个设备或设置重新训练模型，成本高昂。

Method: 采用生成对抗网络（GAN）将域适应任务转化为图像到图像的翻译任务，调整源域图像的纹理模式并去除混响噪声，以匹配目标域图像，同时保持图像内容不变。

Result: 实验结果表明，模型成功实现了纹理模式的翻译和混响噪声的去除，域适应性能显著优于无适应情况（如直方图相关性和Bhattacharya距离指标）。

Conclusion: 提出的基于GAN的模型成功实现了超声图像中的域适应，通过调整纹理模式和去除混响噪声，显著提升了跨设备或跨设置的图像分析性能。

Abstract: Deep learning has been extensively used in medical imaging applications, assuming that the test and training datasets belong to the same probability distribution. However, a common challenge arises when working with medical images generated by different systems or even the same system with different parameter settings. Such images contain diverse textures and reverberation noise that violate the aforementioned assumption. Consequently, models trained on data from one device or setting often struggle to perform effectively with data from other devices or settings. In addition, retraining models for each specific device or setting is labor-intensive and costly. To address these issues in ultrasound images, we propose a novel Generative Adversarial Network (GAN)-based model. We formulated the domain adaptation tasks as an image-to-image translation task, in which we modified the texture patterns and removed reverberation noise in the test data images from the source domain to align with those in the target domain images while keeping the image content unchanged. We applied the proposed method to two datasets containing carotid ultrasound images from three different domains. The experimental results demonstrate that the model successfully translated the texture pattern of images and removed reverberation noise from the ultrasound images. Furthermore, we evaluated the CycleGAN approaches for a comparative study with the proposed model. The experimental findings conclusively demonstrated that the proposed model achieved domain adaptation (histogram correlation (0.960 (0.019), & 0.920 (0.043) and bhattacharya distance (0.040 (0.020), & 0.085 (0.048)), compared to no adaptation (0.916 (0.062) & 0.890 (0.077), 0.090 (0.070) & 0.121 (0.095)) for both datasets.

</details>


### [78] [Robust Ship Detection and Tracking Using Modified ViBe and Backwash Cancellation Algorithm](https://arxiv.org/abs/2601.01481)
*Mohammad Hassan Saghafi,Seyed Majid Noorhosseini,Seyed Abolfazl Seyed Javadein,Hadi Khalili*

Main category: cs.CV

TL;DR: 本文提出了一种改进的ViBe方法，用于海岸视频序列中船舶的实时检测和跟踪，具有鲁棒性和实时性。


<details>
  <summary>Details</summary>
Motivation: 由于海岸场景具有不可预测性和动态特性，需要一种能够适应这些条件的鲁棒检测方法。

Method: 本文提出了一种改进的ViBe方法用于移动物体检测，能够检测船舶和尾流，并减少了丢失船舶的概率。同时，基于船舶的几何特性和亮度失真等概念，提出了一种新的尾流消除方法。

Result: 实验结果表明，所提出的策略和方法在船舶检测和跟踪中具有卓越的性能。

Conclusion: 该论文提出的方法在船舶检测和跟踪中表现出色，实现了实时且精确的性能。

Abstract: In this paper, we propose a robust real time detection and tracking method for detecting ships in a coastal video sequences. Since coastal scenarios are unpredictable and scenes have dynamic properties it is essential to apply detection methods that are robust to these conditions. This paper presents modified ViBe for moving object detection which detects ships and backwash. In the modified ViBe the probability of losing ships is decreased in comparison with the original ViBe. It is robust to natural sea waves and variation of lights and is capable of quickly updating the background. Based on geometrical properties of ship and some concepts such as brightness distortion, a new method for backwash cancellation is proposed. Experimental results demonstrate that the proposed strategy and methods have outstanding performance in ship detection and tracking. These results also illustrate real time and precise performance of the proposed strategy.

</details>


### [79] [Unified Generation and Self-Verification for Vision-Language Models via Advantage Decoupled Preference Optimization](https://arxiv.org/abs/2601.01483)
*Xinyu Qiu,Heng Jia,Zhengwen Zeng,Shuheng Shen,Changhua Meng,Yi Yang,Linchao Zhu*

Main category: cs.CV

TL;DR: ADPO是一个统一的强化学习框架，通过偏好验证奖励和解耦优化机制，联合优化答案生成和自我验证，显著提升性能并降低推理时间。


<details>
  <summary>Details</summary>
Motivation: 解决并行测试时扩展中训练和推理成本高的问题，提出统一的框架以联合优化生成和验证。

Method: ADPO引入了偏好验证奖励和解耦优化机制，通过计算生成和验证的独立优势，应用令牌掩码隔离梯度，并结合掩码GRPO目标。

Result: ADPO在验证AUC上提升34.1%，推理时间降低53.5%，并在多个任务中取得显著准确率提升。

Conclusion: ADPO通过统一的强化学习框架，联合学习答案生成和自我验证，显著提升了验证能力和推理效率。

Abstract: Parallel test-time scaling typically trains separate generation and verification models, incurring high training and inference costs. We propose Advantage Decoupled Preference Optimization (ADPO), a unified reinforcement learning framework that jointly learns answer generation and self-verification within a single policy. ADPO introduces two innovations: a preference verification reward improving verification capability and a decoupled optimization mechanism enabling synergistic optimization of generation and verification. Specifically, the preference verification reward computes mean verification scores from positive and negative samples as decision thresholds, providing positive feedback when prediction correctness aligns with answer correctness. Meanwhile, the advantage decoupled optimization computes separate advantages for generation and verification, applies token masks to isolate gradients, and combines masked GRPO objectives, preserving generation quality while calibrating verification scores. ADPO achieves up to +34.1% higher verification AUC and -53.5% lower inference time, with significant gains of +2.8%/+1.4% accuracy on MathVista/MMMU, +1.9 cIoU on ReasonSeg, and +1.7%/+1.0% step success rate on AndroidControl/GUI Odyssey.

</details>


### [80] [Higher-Order Domain Generalization in Magnetic Resonance-Based Assessment of Alzheimer's Disease](https://arxiv.org/abs/2601.01485)
*Zobia Batool,Diala Lteif,Vijaya B. Kolachalama,Huseyin Ozkan,Erchan Aptoula*

Main category: cs.CV

TL;DR: EM框架通过混合高阶特征矩提升AD诊断模型的跨域性能，平均宏F1提高2.4个百分点。


<details>
  <summary>Details</summary>
Motivation: 由于扫描仪、协议和患者人口统计学的差异，基于结构磁共振成像（sMRI）训练的深度学习模型在新队列中表现不佳，而阿尔茨海默病（AD）的诊断需要鲁棒且可泛化的分类方法。

Method: 提出了Extended MixStyle (EM)框架，通过混合高阶特征矩（偏度和峰度）来模拟多样化的分布变化，以增强模型在跨域数据集上的泛化能力。

Result: 在三个未见过的队列（总计n=3,126）上测试，EM的平均宏F1分数比现有最佳单域泛化（SDG）基准提高了2.4个百分点。

Conclusion: Extended MixStyle (EM) 框架通过混合高阶特征矩（偏度和峰度）来模拟多样化的分布变化，显著提升了阿尔茨海默病（AD）诊断模型在跨域数据集上的性能，展示了其在真实世界异构环境中的鲁棒性和可靠性。

Abstract: Despite progress in deep learning for Alzheimer's disease (AD) diagnostics, models trained on structural magnetic resonance imaging (sMRI) often do not perform well when applied to new cohorts due to domain shifts from varying scanners, protocols and patient demographics. AD, the primary driver of dementia, manifests through progressive cognitive and neuroanatomical changes like atrophy and ventricular expansion, making robust, generalizable classification essential for real-world use. While convolutional neural networks and transformers have advanced feature extraction via attention and fusion techniques, single-domain generalization (SDG) remains underexplored yet critical, given the fragmented nature of AD datasets. To bridge this gap, we introduce Extended MixStyle (EM), a framework for blending higher-order feature moments (skewness and kurtosis) to mimic diverse distributional variations. Trained on sMRI data from the National Alzheimer's Coordinating Center (NACC; n=4,647) to differentiate persons with normal cognition (NC) from those with mild cognitive impairment (MCI) or AD and tested on three unseen cohorts (total n=3,126), EM yields enhanced cross-domain performance, improving macro-F1 on average by 2.4 percentage points over state-of-the-art SDG benchmarks, underscoring its promise for invariant, reliable AD detection in heterogeneous real-world settings. The source code will be made available upon acceptance at https://github.com/zobia111/Extended-Mixstyle.

</details>


### [81] [DeepInv: A Novel Self-supervised Learning Approach for Fast and Accurate Diffusion Inversion](https://arxiv.org/abs/2601.01487)
*Ziyue Zhang,Luxi Lin,Xiaolin Hu,Chao Chang,HuaiXi Wang,Yiyi Zhou,Rongrong Ji*

Main category: cs.CV

TL;DR: DeepInv是一种自监督扩散反演方法，通过数据增强和迭代训练实现高效准确的图像到噪声映射，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有扩散反演方法因缺乏可行监督信号而依赖近似解的问题，提升性能和效率。

Method: 提出了一种自监督扩散反演方法DeepInv，结合自监督目标和数据增强策略，通过迭代和多尺度训练训练参数化反演求解器。

Result: 在COCO数据集上，DeepInv的SSIM比EasyInv高40.435%，速度比ReNoise快9887.5%。

Conclusion: DeepInv通过自监督目标和数据增强策略，实现了高效准确的扩散反演，显著提升了性能和推理速度。

Abstract: Diffusion inversion is a task of recovering the noise of an image in a diffusion model, which is vital for controllable diffusion image editing. At present, diffusion inversion still remains a challenging task due to the lack of viable supervision signals. Thus, most existing methods resort to approximation-based solutions, which however are often at the cost of performance or efficiency. To remedy these shortcomings, we propose a novel self-supervised diffusion inversion approach in this paper, termed Deep Inversion (DeepInv). Instead of requiring ground-truth noise annotations, we introduce a self-supervised objective as well as a data augmentation strategy to generate high-quality pseudo noises from real images without manual intervention. Based on these two innovative designs, DeepInv is also equipped with an iterative and multi-scale training regime to train a parameterized inversion solver, thereby achieving the fast and accurate image-to-noise mapping. To the best of our knowledge, this is the first attempt of presenting a trainable solver to predict inversion noise step by step. The extensive experiments show that our DeepInv can achieve much better performance and inference speed than the compared methods, e.g., +40.435% SSIM than EasyInv and +9887.5% speed than ReNoise on COCO dataset. Moreover, our careful designs of trainable solvers can also provide insights to the community. Codes and model parameters will be released in https://github.com/potato-kitty/DeepInv.

</details>


### [82] [DiffKD-DCIS: Predicting Upgrade of Ductal Carcinoma In Situ with Diffusion Augmentation and Knowledge Distillation](https://arxiv.org/abs/2601.01507)
*Tao Li,Qing Li,Na Li,Hui Xie*

Main category: cs.CV

TL;DR: DiffKD-DCIS通过扩散模型和知识蒸馏提升DCIS升级预测，合成数据质量高，学生网络性能优，临床潜力大。


<details>
  <summary>Details</summary>
Motivation: 准确预测DCIS升级至IDC对手术规划至关重要，但传统深度学习方法因数据有限和泛化能力差而面临挑战。

Method: 框架分为三个阶段：1）使用条件扩散模型生成高质量超声图像进行数据增强；2）深度教师网络从原始和合成数据中提取鲁棒特征；3）紧凑学生网络通过知识蒸馏学习，平衡泛化能力和计算效率。

Result: 在多中心1,435例数据集中，合成图像质量良好，学生网络参数更少、推理更快。在外部测试集上，其性能优于部分组合，准确性与资深放射科医师相当，优于初级医师。

Conclusion: DiffKD-DCIS框架通过结合条件扩散模型和师生知识蒸馏，显著提升了DCIS升级预测的准确性和泛化能力，展现了重要的临床潜力。

Abstract: Accurately predicting the upgrade of ductal carcinoma in situ (DCIS) to invasive ductal carcinoma (IDC) is crucial for surgical planning. However, traditional deep learning methods face challenges due to limited ultrasound data and poor generalization ability. This study proposes the DiffKD-DCIS framework, integrating conditional diffusion modeling with teacher-student knowledge distillation.
  The framework operates in three stages: First, a conditional diffusion model generates high-fidelity ultrasound images using multimodal conditions for data augmentation. Then, a deep teacher network extracts robust features from both original and synthetic data. Finally, a compact student network learns from the teacher via knowledge distillation, balancing generalization and computational efficiency.
  Evaluated on a multi-center dataset of 1,435 cases, the synthetic images were of good quality. The student network had fewer parameters and faster inference. On external test sets, it outperformed partial combinations, and its accuracy was comparable to senior radiologists and superior to junior ones, showing significant clinical potential.

</details>


### [83] [A Novel Deep Learning Method for Segmenting the Left Ventricle in Cardiac Cine MRI](https://arxiv.org/abs/2601.01512)
*Wenhui Chu,Aobo Jin,Hardik A. Gohel*

Main category: cs.CV

TL;DR: GBU-Net 是一种新型深度学习网络，专为左心室 MRI 分割设计，性能优于现有方法，dice 分数达 97%。


<details>
  <summary>Details</summary>
Motivation: 开发一种能够精确分割短轴 cine MRI 扫描中左心室的深度学习方法，以解决传统 CNN 分割方法在上下文理解上的不足。

Method: 采用基于 group-batch-normalized U-Net 框架的深度学习网络，包含下采样路径用于特征提取和上采样路径用于细节恢复，并针对医学影像进行了优化。

Result: GBU-Net 在 SunnyBrook 测试数据集上达到了 97% 的 dice 分数，显著提升了左心室分割的准确性。

Conclusion: GBU-Net 提供了一种高精度的左心室分割方法，特别适用于外科机器人和医学分析，其创新设计在性能上超越了现有方法。

Abstract: This research aims to develop a novel deep learning network, GBU-Net, utilizing a group-batch-normalized U-Net framework, specifically designed for the precise semantic segmentation of the left ventricle in short-axis cine MRI scans. The methodology includes a down-sampling pathway for feature extraction and an up-sampling pathway for detail restoration, enhanced for medical imaging. Key modifications include techniques for better contextual understanding crucial in cardiac MRI segmentation. The dataset consists of 805 left ventricular MRI scans from 45 patients, with comparative analysis using established metrics such as the dice coefficient and mean perpendicular distance. GBU-Net significantly improves the accuracy of left ventricle segmentation in cine MRI scans. Its innovative design outperforms existing methods in tests, surpassing standard metrics like the dice coefficient and mean perpendicular distance. The approach is unique in its ability to capture contextual information, often missed in traditional CNN-based segmentation. An ensemble of the GBU-Net attains a 97% dice score on the SunnyBrook testing dataset. GBU-Net offers enhanced precision and contextual understanding in left ventricle segmentation for surgical robotics and medical analysis.

</details>


### [84] [FastV-RAG: Towards Fast and Fine-Grained Video QA with Retrieval-Augmented Generation](https://arxiv.org/abs/2601.01513)
*Gen Li,Peiyu Liu*

Main category: cs.CV

TL;DR: VideoSpeculateRAG通过推测解码和实体过滤策略，高效提升视觉语言模型在检索增强生成任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 解决当前检索增强生成（RAG）方法效率低下且答案质量不稳定的问题。

Method: 提出VideoSpeculateRAG框架，包含推测解码管道（轻量级草稿模型生成候选答案，再由重量级模型验证和优化）和基于相似性的实体过滤策略。

Result: 实验显示VideoSpeculateRAG在保持或提升准确性的同时，推理速度提升约2倍。

Conclusion: VideoSpeculateRAG框架通过结合推测解码和检索增强推理，显著提升了复杂多模态任务的效率和可靠性。

Abstract: Vision-Language Models (VLMs) excel at visual reasoning but still struggle with integrating external knowledge. Retrieval-Augmented Generation (RAG) is a promising solution, but current methods remain inefficient and often fail to maintain high answer quality. To address these challenges, we propose VideoSpeculateRAG, an efficient VLM-based RAG framework built on two key ideas. First, we introduce a speculative decoding pipeline: a lightweight draft model quickly generates multiple answer candidates, which are then verified and refined by a more accurate heavyweight model, substantially reducing inference latency without sacrificing correctness. Second, we identify a major source of error - incorrect entity recognition in retrieved knowledge - and mitigate it with a simple yet effective similarity-based filtering strategy that improves entity alignment and boosts overall answer accuracy. Experiments demonstrate that VideoSpeculateRAG achieves comparable or higher accuracy than standard RAG approaches while accelerating inference by approximately 2x. Our framework highlights the potential of combining speculative decoding with retrieval-augmented reasoning to enhance efficiency and reliability in complex, knowledge-intensive multimodal tasks.

</details>


### [85] [BARE: Towards Bias-Aware and Reasoning-Enhanced One-Tower Visual Grounding](https://arxiv.org/abs/2601.01526)
*Hongbing Li,Linhui Xiao,Zihan Zhao,Qi Shen,Yixiang Huang,Bo Xiao,Zhanyu Ma*

Main category: cs.CV

TL;DR: BARE是一种针对视觉定位任务的偏置感知和推理增强框架，通过三个新模块解决了多模态表示和语义推理问题，实现了高性能和高效率。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉定位方法在多模态表示过度纠缠和语义推理不足方面存在局限性，影响了参考线索的理解。

Method: BARE采用了一种机制，通过三个新模块（语言显著性调制器、视觉偏差校正和参考关系增强）来保留模态特定特征并构建参考语义。

Result: 在五个基准测试上的广泛实验结果表明，BARE不仅达到了最先进的性能，还比现有方法具有更高的计算效率。

Conclusion: BARE框架通过引入语言显著性调制器、视觉偏差校正和参考关系增强三个模块，有效解决了多模态表示过度纠缠和语义推理不足的问题，在视觉定位任务中实现了最先进的性能和高计算效率。

Abstract: Visual Grounding (VG), which aims to locate a specific region referred to by expressions, is a fundamental yet challenging task in the multimodal understanding fields. While recent grounding transfer works have advanced the field through one-tower architectures, they still suffer from two primary limitations: (1) over-entangled multimodal representations that exacerbate deceptive modality biases, and (2) insufficient semantic reasoning that hinders the comprehension of referential cues. In this paper, we propose BARE, a bias-aware and reasoning-enhanced framework for one-tower visual grounding. BARE introduces a mechanism that preserves modality-specific features and constructs referential semantics through three novel modules: (i) language salience modulator, (ii) visual bias correction and (iii) referential relationship enhancement, which jointly mitigate multimodal distractions and enhance referential comprehension. Extensive experimental results on five benchmarks demonstrate that BARE not only achieves state-of-the-art performance but also delivers superior computational efficiency compared to existing approaches. The code is publicly accessible at https://github.com/Marloweeee/BARE.

</details>


### [86] [Improving Flexible Image Tokenizers for Autoregressive Image Generation](https://arxiv.org/abs/2601.01535)
*Zixuan Fu,Lanqing Guo,Chong Wang,Binbin Song,Ding Liu,Bihan Wen*

Main category: cs.CV

TL;DR: ReToK通过冗余令牌填充和分层语义正则化优化灵活图像标记器，提升生成性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有灵活图像标记器因尾部截断导致信息过度集中在早期令牌，从而限制自回归图像生成效果的问题。

Method: 提出ReToK，结合冗余令牌填充和分层语义正则化，前者激活尾部令牌，后者通过预训练视觉基础模型对齐早期令牌的解码特征。

Result: 在ImageNet 256×256上，ReToK的生成性能优于灵活和固定长度标记器。

Conclusion: ReToK通过冗余令牌填充和分层语义正则化，显著提升了灵活图像标记器的性能，在ImageNet 256×256上实现了优于固定长度标记器的生成效果。

Abstract: Flexible image tokenizers aim to represent an image using an ordered 1D variable-length token sequence. This flexible tokenization is typically achieved through nested dropout, where a portion of trailing tokens is randomly truncated during training, and the image is reconstructed using the remaining preceding sequence. However, this tail-truncation strategy inherently concentrates the image information in the early tokens, limiting the effectiveness of downstream AutoRegressive (AR) image generation as the token length increases. To overcome these limitations, we propose \textbf{ReToK}, a flexible tokenizer with \underline{Re}dundant \underline{Tok}en Padding and Hierarchical Semantic Regularization, designed to fully exploit all tokens for enhanced latent modeling. Specifically, we introduce \textbf{Redundant Token Padding} to activate tail tokens more frequently, thereby alleviating information over-concentration in the early tokens. In addition, we apply \textbf{Hierarchical Semantic Regularization} to align the decoding features of earlier tokens with those from a pre-trained vision foundation model, while progressively reducing the regularization strength toward the tail to allow finer low-level detail reconstruction. Extensive experiments demonstrate the effectiveness of ReTok: on ImageNet 256$\times$256, our method achieves superior generation performance compared with both flexible and fixed-length tokenizers. Code will be available at: \href{https://github.com/zfu006/ReTok}{https://github.com/zfu006/ReTok}

</details>


### [87] [FAR-AMTN: Attention Multi-Task Network for Face Attribute Recognition](https://arxiv.org/abs/2601.01537)
*Gong Gao,Zekai Wang,Xianhui Liu,Weidong Zhao*

Main category: cs.CV

TL;DR: FAR-AMTN通过注意力机制和动态权重策略优化多任务学习，提升面部属性识别的泛化性能并减少参数。


<details>
  <summary>Details</summary>
Motivation: 传统多任务网络在面部属性识别中存在参数爆炸和高层次特征交互不足的问题，影响了泛化性能。

Method: 提出了FAR-AMTN，包含Weight-Shared Group-Specific Attention (WSGSA)模块、Cross-Group Feature Fusion (CGFF)模块和Dynamic Weighting Strategy (DWS)。

Result: 在CelebA和LFWA数据集上的实验表明，FAR-AMTN在减少参数的同时实现了更高的准确率。

Conclusion: FAR-AMTN通过结合WSGSA模块、CGFF模块和DWS策略，显著提升了多任务网络在面部属性识别中的泛化性能，同时减少了模型参数。

Abstract: To enhance the generalization performance of Multi-Task Networks (MTN) in Face Attribute Recognition (FAR), it is crucial to share relevant information across multiple related prediction tasks effectively. Traditional MTN methods create shared low-level modules and distinct high-level modules, causing an exponential increase in model parameters with the addition of tasks. This approach also limits feature interaction at the high level, hindering the exploration of semantic relations among attributes, thereby affecting generalization negatively. In response, this study introduces FAR-AMTN, a novel Attention Multi-Task Network for FAR. It incorporates a Weight-Shared Group-Specific Attention (WSGSA) module with shared parameters to minimize complexity while improving group feature representation. Furthermore, a Cross-Group Feature Fusion (CGFF) module is utilized to foster interactions between attribute groups, enhancing feature learning. A Dynamic Weighting Strategy (DWS) is also introduced for synchronized task convergence. Experiments on the CelebA and LFWA datasets demonstrate that the proposed FAR-AMTN demonstrates superior accuracy with significantly fewer parameters compared to existing models.

</details>


### [88] [EscherVerse: An Open World Benchmark and Dataset for Teleo-Spatial Intelligence with Physical-Dynamic and Intent-Driven Understanding](https://arxiv.org/abs/2601.01547)
*Tianjun Gu,Chenghua Gong,Jingyu Gong,Zhizhong Zhang,Yuan Xie,Lizhuang Ma,Xin Tan*

Main category: cs.CV

TL;DR: 论文提出TSI范式，结合物理和意图推理，并推出EscherVerse（基准、数据集和模型），推动空间智能从被动描述转向目的驱动理解。


<details>
  <summary>Details</summary>
Motivation: 当前研究忽视了空间变化背后的人类意图，论文旨在通过TSI范式统一物理动态推理和意图驱动推理，填补这一空白。

Method: 论文提出了一种新的数据筛选流程，并构建了EscherVerse，包含大规模开放世界基准（Escher-Bench）、数据集（Escher-35k）和模型（Escher系列），以评估代理在动态、以人为中心的场景中对物体持久性、状态转换和轨迹预测的推理能力。

Result: EscherVerse是首个系统评估意图驱动推理的基准，挑战模型将物理事件与潜在的人类目的联系起来，推动了空间智能的发展。

Conclusion: 该论文提出了Teleo-Spatial Intelligence (TSI)新范式，结合物理动态推理和意图驱动推理，并通过EscherVerse（包括Escher-Bench、Escher-35k数据集和Escher系列模型）推动TSI研究，为空间智能从被动场景描述转向目的驱动的整体理解奠定了基础。

Abstract: The ability to reason about spatial dynamics is a cornerstone of intelligence, yet current research overlooks the human intent behind spatial changes. To address these limitations, we introduce Teleo-Spatial Intelligence (TSI), a new paradigm that unifies two critical pillars: Physical-Dynamic Reasoning--understanding the physical principles of object interactions--and Intent-Driven Reasoning--inferring the human goals behind these actions. To catalyze research in TSI, we present EscherVerse, consisting of a large-scale, open-world benchmark (Escher-Bench), a dataset (Escher-35k), and models (Escher series). Derived from real-world videos, EscherVerse moves beyond constrained settings to explicitly evaluate an agent's ability to reason about object permanence, state transitions, and trajectory prediction in dynamic, human-centric scenarios. Crucially, it is the first benchmark to systematically assess Intent-Driven Reasoning, challenging models to connect physical events to their underlying human purposes. Our work, including a novel data curation pipeline, provides a foundational resource to advance spatial intelligence from passive scene description toward a holistic, purpose-driven understanding of the world.

</details>


### [89] [Beyond Patches: Global-aware Autoregressive Model for Multimodal Few-Shot Font Generation](https://arxiv.org/abs/2601.01593)
*Haonan Cai,Yuxuan Luo,Zhouhui Lian*

Main category: cs.CV

TL;DR: GAR-Font 是一种新型自回归框架，通过全局感知标记器和多模态风格编码器，显著提升少样本字体生成的质量和风格控制能力。


<details>
  <summary>Details</summary>
Motivation: 解决少样本字体生成中结构完整性和风格保真度的挑战，突破传统图像到图像范式的限制，引入语言风格适配器。

Method: 提出了 GAR-Font，一个新型自回归框架，包含全局感知标记器、多模态风格编码器和后处理流程。

Result: 实验表明，GAR-Font 在少样本字体生成任务中优于现有方法，尤其在全局风格忠实度和文本风格引导下生成更高质量的字体。

Conclusion: GAR-Font 通过引入全局感知的标记器、多模态风格编码器和后处理流程，显著提升了少样本字体生成的性能，尤其在保持全局风格忠实度和结构保真度方面表现优异。

Abstract: Manual font design is an intricate process that transforms a stylistic visual concept into a coherent glyph set. This challenge persists in automated Few-shot Font Generation (FFG), where models often struggle to preserve both the structural integrity and stylistic fidelity from limited references. While autoregressive (AR) models have demonstrated impressive generative capabilities, their application to FFG is constrained by conventional patch-level tokenization, which neglects global dependencies crucial for coherent font synthesis. Moreover, existing FFG methods remain within the image-to-image paradigm, relying solely on visual references and overlooking the role of language in conveying stylistic intent during font design. To address these limitations, we propose GAR-Font, a novel AR framework for multimodal few-shot font generation. GAR-Font introduces a global-aware tokenizer that effectively captures both local structures and global stylistic patterns, a multimodal style encoder offering flexible style control through a lightweight language-style adapter without requiring intensive multimodal pretraining, and a post-refinement pipeline that further enhances structural fidelity and style coherence. Extensive experiments show that GAR-Font outperforms existing FFG methods, excelling in maintaining global style faithfulness and achieving higher-quality results with textual stylistic guidance.

</details>


### [90] [Guiding Token-Sparse Diffusion Models](https://arxiv.org/abs/2601.01608)
*Felix Krause,Stefan Andreas Baumann,Johannes Schusterbauer,Olga Grebenkova,Ming Gui,Vincent Tao Hu,Björn Ommer*

Main category: cs.CV

TL;DR: SG通过标记级稀疏性优化推理性能，显著提升稀疏训练扩散模型的质量和效率。


<details>
  <summary>Details</summary>
Motivation: 稀疏训练的扩散模型在推理阶段由于对Classifier-free Guidance (CFG)的响应不足，导致性能不佳。SG旨在解决这一问题。

Method: 提出了Sparse Guidance (SG)方法，利用标记级稀疏性而非条件性丢弃来引导扩散模型，从而在推理阶段更好地保留条件预测的高方差。

Result: SG在ImageNet-256基准测试中实现了1.58 FID，计算量减少25%，并在匹配基线质量时节省高达58%的FLOPs。此外，SG在文本到图像扩散模型中提升了构图和人类偏好评分，同时增加了吞吐量。

Conclusion: Sparse Guidance (SG) 通过在推理阶段利用标记级稀疏性，显著提升了稀疏训练扩散模型的性能，实现了高质量和高方差输出，同时降低了计算成本。

Abstract: Diffusion models deliver high quality in image synthesis but remain expensive during training and inference. Recent works have leveraged the inherent redundancy in visual content to make training more affordable by training only on a subset of visual information. While these methods were successful in providing cheaper and more effective training, sparsely trained diffusion models struggle in inference. This is due to their lacking response to Classifier-free Guidance (CFG) leading to underwhelming performance during inference. To overcome this, we propose Sparse Guidance (SG). Instead of using conditional dropout as a signal to guide diffusion models, SG uses token-level sparsity. As a result, SG preserves the high-variance of the conditional prediction better, achieving good quality and high variance outputs. Leveraging token-level sparsity at inference, SG improves fidelity at lower compute, achieving 1.58 FID on the commonly used ImageNet-256 benchmark with 25% fewer FLOPs, and yields up to 58% FLOP savings at matched baseline quality. To demonstrate the effectiveness of Sparse Guidance, we train a 2.5B text-to-image diffusion model using training time sparsity and leverage SG during inference. SG achieves improvements in composition and human preference score while increasing throughput at the same time.

</details>


### [91] [CAP-IQA: Context-Aware Prompt-Guided CT Image Quality Assessment](https://arxiv.org/abs/2601.01613)
*Kazi Ramisa Rifa,Jie Zhang,Abdullah Imran*

Main category: cs.CV

TL;DR: CAP-IQA框架通过文本和视觉编码器的融合及因果去偏技术，显著提升了CT图像质量评估的准确性和泛化性。


<details>
  <summary>Details</summary>
Motivation: 现有的基于提示的方法在CT图像质量评估中引入理想化定义导致的偏差，无法适应真实世界的退化情况。

Method: 提出了Context-Aware Prompt-guided Image Quality Assessment (CAP-IQA)框架，结合CNN视觉编码器和领域特定文本编码器，利用放射学风格提示和上下文感知融合技术。

Result: 在2023 LDCTIQA挑战基准测试中，CAP-IQA的总体相关性得分比榜首团队高4.24%，并在91,514张儿科CT图像的内部分数据集上验证了泛化能力。

Conclusion: CAP-IQA框架通过结合文本级先验和实例级上下文提示，并应用因果去偏技术，显著提升了CT图像质量评估的准确性和泛化能力。

Abstract: Prompt-based methods, which encode medical priors through descriptive text, have been only minimally explored for CT Image Quality Assessment (IQA). While such prompts can embed prior knowledge about diagnostic quality, they often introduce bias by reflecting idealized definitions that may not hold under real-world degradations such as noise, motion artifacts, or scanner variability. To address this, we propose the Context-Aware Prompt-guided Image Quality Assessment (CAP-IQA) framework, which integrates text-level priors with instance-level context prompts and applies causal debiasing to separate idealized knowledge from factual, image-specific degradations. Our framework combines a CNN-based visual encoder with a domain-specific text encoder to assess diagnostic visibility, anatomical clarity, and noise perception in abdominal CT images. The model leverages radiology-style prompts and context-aware fusion to align semantic and perceptual representations. On the 2023 LDCTIQA challenge benchmark, CAP-IQA achieves an overall correlation score of 2.8590 (sum of PLCC, SROCC, and KROCC), surpassing the top-ranked leaderboard team (2.7427) by 4.24%. Moreover, our comprehensive ablation experiments confirm that prompt-guided fusion and the simplified encoder-only design jointly enhance feature alignment and interpretability. Furthermore, evaluation on an in-house dataset of 91,514 pediatric CT images demonstrates the true generalizability of CAP-IQA in assessing perceptual fidelity in a different patient population.

</details>


### [92] [An Empirical Study of Monocular Human Body Measurement Under Weak Calibration](https://arxiv.org/abs/2601.01639)
*Gaurav Sekar*

Main category: cs.CV

TL;DR: 本研究通过三种弱校准单目策略的系统评估，揭示了校准假设对测量稳定性的影响，为消费设备上的轻量级人体测量系统提供了设计参考。


<details>
  <summary>Details</summary>
Motivation: 由于尺度模糊性、视角敏感性和缺乏明确的深度信息，从单目RGB图像估计人体测量仍然具有挑战性。

Method: 研究系统地评估了三种弱校准单目策略：基于地标的几何方法、姿态驱动的回归方法和对象校准的轮廓方法，使用消费级相机在半约束条件下进行。

Result: 结果表明，不同的校准假设对测量行为、鲁棒性和失败模式在不同体型中的影响存在明显差异。

Conclusion: 本文作为轻量级单目人体测量系统在消费设备上部署的实证设计参考，揭示了用户在校准过程中的努力与所得周长量的稳定性之间的权衡。

Abstract: Estimating human body measurements from monocular RGB imagery remains challenging due to scale ambiguity, viewpoint sensitivity, and the absence of explicit depth information. This work presents a systematic empirical study of three weakly calibrated monocular strategies: landmark-based geometry, pose-driven regression, and object-calibrated silhouettes, evaluated under semi-constrained conditions using consumer-grade cameras. Rather than pursuing state-of-the-art accuracy, the study analyzes how differing calibration assumptions influence measurement behavior, robustness, and failure modes across varied body types. The results reveal a clear trade-off between user effort during calibration and the stability of resulting circumferential quantities. This paper serves as an empirical design reference for lightweight monocular human measurement systems intended for deployment on consumer devices.

</details>


### [93] [FALCON: Few-Shot Adversarial Learning for Cross-Domain Medical Image Segmentation](https://arxiv.org/abs/2601.01687)
*Abdur R. Fayjie,Pankhi Kashyap,Jutika Borah,Patrick Vandewalle*

Main category: cs.CV

TL;DR: FALCON是一种跨域少样本分割框架，通过2D切片处理实现高精度3D医学图像分割，减少标注数据和计算需求。


<details>
  <summary>Details</summary>
Motivation: 解决3D医学图像分割中标注数据稀缺、患者特异性变异、数据隐私和计算开销大的问题。

Method: 提出FALCON框架，结合元学习（自然图像预训练）、对抗微调、边界感知学习和任务感知推理，动态适应患者特异性解剖变异。

Result: 在四个基准测试中，FALCON实现了最低的Hausdorff距离分数（边界精度最优），且Dice相似系数与现有最佳模型相当。

Conclusion: FALCON框架通过跨域少样本学习，实现了高精度的3D医学图像分割，显著减少了标注数据需求、计算开销，并保持了与现有最佳模型相当的Dice相似系数。

Abstract: Precise delineation of anatomical and pathological structures within 3D medical volumes is crucial for accurate diagnosis, effective surgical planning, and longitudinal disease monitoring. Despite advancements in AI, clinically viable segmentation is often hindered by the scarcity of 3D annotations, patient-specific variability, data privacy concerns, and substantial computational overhead. In this work, we propose FALCON, a cross-domain few-shot segmentation framework that achieves high-precision 3D volume segmentation by processing data as 2D slices. The framework is first meta-trained on natural images to learn-to-learn generalizable segmentation priors, then transferred to the medical domain via adversarial fine-tuning and boundary-aware learning. Task-aware inference, conditioned on support cues, allows FALCON to adapt dynamically to patient-specific anatomical variations across slices. Experiments on four benchmarks demonstrate that FALCON consistently achieves the lowest Hausdorff Distance scores, indicating superior boundary accuracy while maintaining a Dice Similarity Coefficient comparable to the state-of-the-art models. Notably, these results are achieved with significantly less labeled data, no data augmentation, and substantially lower computational overhead.

</details>


### [94] [Animated 3DGS Avatars in Diverse Scenes with Consistent Lighting and Shadows](https://arxiv.org/abs/2601.01660)
*Aymen Mir,Riza Alp Guler,Jian Wang,Gerard Pons-Moll,Bing Zhou*

Main category: cs.CV

TL;DR: DGSM和SH重光照技术实现了3DGS虚拟形象与场景交互时的连贯阴影和光照效果，无需网格化。


<details>
  <summary>Details</summary>
Motivation: 解决动画3D高斯泼溅(3DGS)虚拟形象与3DGS场景或动态物体交互时的光照和阴影一致性问题。

Method: 提出了Deep Gaussian Shadow Maps (DGSM)，一种针对3DGS表示的体积阴影计算方法，结合了球形谐波(SH)基的HDRI探针进行快速光照传输。

Result: 在AvatarX和ActorsHQ虚拟形象中展示了环境一致的光照效果，并在ScanNet++、DL3DV和SuperSplat场景中实现了与插入物体的交互。

Conclusion: DGSM和SH重光照技术在3DGS表示中实现了连贯的阴影和重光照效果，避免了网格化的需求。

Abstract: We present a method for consistent lighting and shadows when animated 3D Gaussian Splatting (3DGS) avatars interact with 3DGS scenes or with dynamic objects inserted into otherwise static scenes. Our key contribution is Deep Gaussian Shadow Maps (DGSM), a modern analogue of the classical shadow mapping algorithm tailored to the volumetric 3DGS representation. Building on the classic deep shadow mapping idea, we show that 3DGS admits closed form light accumulation along light rays, enabling volumetric shadow computation without meshing. For each estimated light, we tabulate transmittance over concentric radial shells and store them in octahedral atlases, which modern GPUs can sample in real time per query to attenuate affected scene Gaussians and thus cast and receive shadows consistently. To relight moving avatars, we approximate the local environment illumination with HDRI probes represented in a spherical harmonic (SH) basis and apply a fast per Gaussian radiance transfer, avoiding explicit BRDF estimation or offline optimization. We demonstrate environment consistent lighting for avatars from AvatarX and ActorsHQ, composited into ScanNet++, DL3DV, and SuperSplat scenes, and show interactions with inserted objects. Across single and multi avatar settings, DGSM and SH relighting operate fully in the volumetric 3DGS representation, yielding coherent shadows and relighting while avoiding meshing.

</details>


### [95] [LabelAny3D: Label Any Object 3D in the Wild](https://arxiv.org/abs/2601.01676)
*Jin Yao,Radowan Mahmud Redoy,Sebastian Elbaum,Matthew B. Dwyer,Zezhou Cheng*

Main category: cs.CV

TL;DR: LabelAny3D通过分析-合成方法生成高质量3D标注，构建COCO3D基准，显著提升单目3D检测性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有单目3D检测模型在野外图像中表现不佳的问题，主要由于缺乏野外3D数据集和3D标注的挑战。

Method: 采用分析-合成框架LabelAny3D，从2D图像重建整体3D场景以高效生成3D边界框标注，并基于此构建了COCO3D新基准。

Result: LabelAny3D生成的标注在多个基准测试中提升了单目3D检测性能，质量优于先前的自动标注方法。

Conclusion: LabelAny3D框架通过分析-合成方法生成高质量3D标注，显著提升了单目3D检测性能，展示了基础模型驱动标注在开放世界3D识别中的潜力。

Abstract: Detecting objects in 3D space from monocular input is crucial for applications ranging from robotics to scene understanding. Despite advanced performance in the indoor and autonomous driving domains, existing monocular 3D detection models struggle with in-the-wild images due to the lack of 3D in-the-wild datasets and the challenges of 3D annotation. We introduce LabelAny3D, an \emph{analysis-by-synthesis} framework that reconstructs holistic 3D scenes from 2D images to efficiently produce high-quality 3D bounding box annotations. Built on this pipeline, we present COCO3D, a new benchmark for open-vocabulary monocular 3D detection, derived from the MS-COCO dataset and covering a wide range of object categories absent from existing 3D datasets. Experiments show that annotations generated by LabelAny3D improve monocular 3D detection performance across multiple benchmarks, outperforming prior auto-labeling approaches in quality. These results demonstrate the promise of foundation-model-driven annotation for scaling up 3D recognition in realistic, open-world settings.

</details>


### [96] [Trustworthy Data-Driven Wildfire Risk Prediction and Understanding in Western Canada](https://arxiv.org/abs/2601.01677)
*Zhengsen Xu,Lanying Wang,Sibo Cheng,Xue Rui,Kyle Gao,Yimin Zhu,Mabel Heffring,Zack Dewis,Saeid Taleghanidoozdoozan,Megan Greenwood,Motasem Alkayid,Quinn Ledingham,Hongjie He,Jonathan Li,Lincoln Linlin Xu*

Main category: cs.CV

TL;DR: 论文提出了一种可信赖的野火风险预测框架，整合多种驱动因素并量化不确定性，在加拿大西部表现优异，F1得分0.90，PR-AUC 0.98。


<details>
  <summary>Details</summary>
Motivation: 近年来，加拿大西部野火活动的加剧导致了重大的社会经济和环境损失，但野火风险的准确预测受到点火和蔓延的内在随机性以及多种因素非线性相互作用的挑战。

Method: 基于长序列、多尺度时间建模的数据驱动框架，整合了燃料条件、气象、气候变率、地形和人类活动等多种驱动因素。

Result: 在2023和2024年创纪录的火灾季节中，该模型在加拿大西部的表现优于现有时间序列方法，F1得分为0.90，PR-AUC为0.98，且计算成本低。

Conclusion: 该论文提出了一个可信赖的数据驱动野火风险预测框架，通过长序列、多尺度时间建模整合了异质性驱动因素，同时明确量化预测不确定性并支持过程级解释。

Abstract: In recent decades, the intensification of wildfire activity in western Canada has resulted in substantial socio-economic and environmental losses. Accurate wildfire risk prediction is hindered by the intrinsic stochasticity of ignition and spread and by nonlinear interactions among fuel conditions, meteorology, climate variability, topography, and human activities, challenging the reliability and interpretability of purely data-driven models. We propose a trustworthy data-driven wildfire risk prediction framework based on long-sequence, multi-scale temporal modeling, which integrates heterogeneous drivers while explicitly quantifying predictive uncertainty and enabling process-level interpretation. Evaluated over western Canada during the record-breaking 2023 and 2024 fire seasons, the proposed model outperforms existing time-series approaches, achieving an F1 score of 0.90 and a PR-AUC of 0.98 with low computational cost. Uncertainty-aware analysis reveals structured spatial and seasonal patterns in predictive confidence, highlighting increased uncertainty associated with ambiguous predictions and spatiotemporal decision boundaries. SHAP-based interpretation provides mechanistic understanding of wildfire controls, showing that temperature-related drivers dominate wildfire risk in both years, while moisture-related constraints play a stronger role in shaping spatial and land-cover-specific contrasts in 2024 compared to the widespread hot and dry conditions of 2023. Data and code are available at https://github.com/SynUW/mmFire.

</details>


### [97] [Evaluating Deep Learning-Based Face Recognition for Infants and Toddlers: Impact of Age Across Developmental Stages](https://arxiv.org/abs/2601.01680)
*Afzal Hossain,Mst Rumana Sumi,Stephanie Schuckers*

Main category: cs.CV

TL;DR: 研究评估了四种人脸识别模型在婴幼儿纵向数据集上的表现，发现年龄越小识别准确率越低，但DANN方法显著提升了时间稳定性，对智能城市应用具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 婴幼儿人脸识别面临独特挑战，如快速的面部形态变化、高类间相似性和数据集有限。研究旨在评估模型在不同发育阶段的识别准确性，并提出解决方案以提高时间稳定性。

Method: 本研究评估了四种基于深度学习的人脸识别模型（FaceNet、ArcFace、MagFace和CosFace）在新开发的纵向数据集上的表现，并应用了领域对抗神经网络（DANN）方法来减少嵌入漂移。

Result: 分析显示，0至6个月婴儿的识别准确率仅为30.7%（0.1% FAR），而2.5至3岁儿童提升至64.7%。DANN方法将TAR提高了12%以上，显著改善了时间稳定性。

Conclusion: 研究强调了在智能城市应用中构建随时间可靠的生物识别系统的重要性，特别是在公共医疗、儿童安全和数字身份服务等领域。早期年龄组的挑战凸显了未来研究隐私保护生物认证系统的重要性，以解决时间变异性问题。

Abstract: Face recognition for infants and toddlers presents unique challenges due to rapid facial morphology changes, high inter-class similarity, and limited dataset availability. This study evaluates the performance of four deep learning-based face recognition models FaceNet, ArcFace, MagFace, and CosFace on a newly developed longitudinal dataset collected over a 24 month period in seven sessions involving children aged 0 to 3 years. Our analysis examines recognition accuracy across developmental stages, showing that the True Accept Rate (TAR) is only 30.7% at 0.1% False Accept Rate (FAR) for infants aged 0 to 6 months, due to unstable facial features. Performance improves significantly in older children, reaching 64.7% TAR at 0.1% FAR in the 2.5 to 3 year age group. We also evaluate verification performance over different time intervals, revealing that shorter time gaps result in higher accuracy due to reduced embedding drift. To mitigate this drift, we apply a Domain Adversarial Neural Network (DANN) approach that improves TAR by over 12%, yielding features that are more temporally stable and generalizable. These findings are critical for building biometric systems that function reliably over time in smart city applications such as public healthcare, child safety, and digital identity services. The challenges observed in early age groups highlight the importance of future research on privacy preserving biometric authentication systems that can address temporal variability, particularly in secure and regulated urban environments where child verification is essential.

</details>


### [98] [Subimage Overlap Prediction: Task-Aligned Self-Supervised Pretraining For Semantic Segmentation In Remote Sensing Imagery](https://arxiv.org/abs/2601.01781)
*Lakshay Sharma,Alex Marin*

Main category: cs.CV

TL;DR: 提出子图像重叠预测的自监督预训练方法，减少数据需求并提升遥感图像语义分割性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有自监督学习方法依赖大量预训练数据的问题，特别是在遥感图像语义分割任务中。

Method: 提出了一种新颖的自监督预训练任务——子图像重叠预测，通过训练模型预测子图像在原图像中的位置语义掩码。

Result: 实验表明，该方法在减少预训练数据的情况下，实现了更快的收敛速度和同等或更好的下游分割性能（通过mIoU衡量）。

Conclusion: 该论文提出的子图像重叠预测方法在减少预训练数据需求的同时，显著提升了语义分割任务的收敛速度和性能表现。

Abstract: Self-supervised learning (SSL) methods have become a dominant paradigm for creating general purpose models whose capabilities can be transferred to downstream supervised learning tasks. However, most such methods rely on vast amounts of pretraining data. This work introduces Subimage Overlap Prediction, a novel self-supervised pretraining task to aid semantic segmentation in remote sensing imagery that uses significantly lesser pretraining imagery. Given an image, a sub-image is extracted and the model is trained to produce a semantic mask of the location of the extracted sub-image within the original image. We demonstrate that pretraining with this task results in significantly faster convergence, and equal or better performance (measured via mIoU) on downstream segmentation. This gap in convergence and performance widens when labeled training data is reduced. We show this across multiple architecture types, and with multiple downstream datasets. We also show that our method matches or exceeds performance while requiring significantly lesser pretraining data relative to other SSL methods. Code and model weights are provided at \href{https://github.com/sharmalakshay93/subimage-overlap-prediction}{github.com/sharmalakshay93/subimage-overlap-prediction}.

</details>


### [99] [VerLM: Explaining Face Verification Using Natural Language](https://arxiv.org/abs/2601.01798)
*Syed Abdul Hannan,Hazim Bukhari,Thomas Cantalapiedra,Eman Ansar,Massa Baali,Rita Singh,Bhiksha Raj*

Main category: cs.CV

TL;DR: 本文提出了一种创新的视觉语言模型（VLM），用于人脸验证，不仅能准确判断两张人脸图像是否属于同一人，还能通过简洁和详细的解释说明决策依据，模型性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管人脸验证系统取得了显著进展，但其决策过程往往缺乏透明度，因此需要开发一种既能准确验证又能解释决策的模型。

Method: 通过改进并适配一种最初为音频区分设计的先进建模方法，使其适用于视觉输入，结合了复杂的特征提取技术和高级推理能力。

Result: 提出的VLM模型在性能上超越了基线方法和现有模型，显著提高了准确性和可解释性。

Conclusion: 本研究提出的视觉语言模型（VLM）在人脸验证任务中表现出色，不仅提高了准确性，还通过两种解释风格增强了决策的透明性，为构建更可靠、可解释的人脸验证系统提供了新思路。

Abstract: Face verification systems have seen substantial advancements; however, they often lack transparency in their decision-making processes. In this paper, we introduce an innovative Vision-Language Model (VLM) for Face Verification, which not only accurately determines if two face images depict the same individual but also explicitly explains the rationale behind its decisions. Our model is uniquely trained using two complementary explanation styles: (1) concise explanations that summarize the key factors influencing its decision, and (2) comprehensive explanations detailing the specific differences observed between the images. We adapt and enhance a state-of-the-art modeling approach originally designed for audio-based differentiation to suit visual inputs effectively. This cross-modal transfer significantly improves our model's accuracy and interpretability. The proposed VLM integrates sophisticated feature extraction techniques with advanced reasoning capabilities, enabling clear articulation of its verification process. Our approach demonstrates superior performance, surpassing baseline methods and existing models. These findings highlight the immense potential of vision language models in face verification set up, contributing to more transparent, reliable, and explainable face verification systems.

</details>


### [100] [Mitigating Longitudinal Performance Degradation in Child Face Recognition Using Synthetic Data](https://arxiv.org/abs/2601.01689)
*Afzal Hossain,Stephanie Schuckers*

Main category: cs.CV

TL;DR: 研究证实合成数据增强能有效提升儿童人脸识别的纵向稳定性，显著降低时间跨度内的错误率。


<details>
  <summary>Details</summary>
Motivation: 儿童面部快速且非线性的生长导致模板漂移和随时间增加的验证错误，研究合成人脸数据是否能作为纵向稳定器提升儿童人脸识别模型的时间鲁棒性。

Method: 在YFA数据集上采用身份不相交协议，评估了三种设置：(i)未经数据集特定微调的预训练MagFace嵌入，(ii)仅使用真实训练人脸微调的MagFace，(iii)结合真实和合成生成训练人脸微调的MagFace。合成数据使用StyleGAN2 ADA生成，并通过后生成过滤步骤减少身份泄漏和去除伪影样本。

Result: 实验结果显示，在6至36个月的注册验证间隔中，合成数据增强的微调相较于预训练基线和仅使用真实数据的微调，显著降低了错误率。

Conclusion: 合成数据增强的微调显著降低了儿童人脸识别的错误率，为提升儿科人脸识别的身份持久性提供了风险感知的评估。

Abstract: Longitudinal face recognition in children remains challenging due to rapid and nonlinear facial growth, which causes template drift and increasing verification errors over time. This work investigates whether synthetic face data can act as a longitudinal stabilizer by improving temporal robustness of child face recognition models. Using an identity disjoint protocol on the Young Face Aging (YFA) dataset, we evaluate three settings: (i) pretrained MagFace embeddings without dataset specific fine-tuning, (ii) MagFace fine-tuned using authentic training faces only, and (iii) MagFace fine-tuned using a combination of authentic and synthetically generated training faces. Synthetic data is generated using StyleGAN2 ADA and incorporated exclusively within the training identities; a post generation filtering step is applied to mitigate identity leakage and remove artifact affected samples. Experimental results across enrollment verification gaps from 6 to 36 months show that synthetic-augmented fine tuning substantially reduces error rates relative to both the pretrained baseline and real only fine tuning. These findings provide a risk aware assessment of synthetic augmentation for improving identity persistence in pediatric face recognition.

</details>


### [101] [Adaptive Hybrid Optimizer based Framework for Lumpy Skin Disease Identification](https://arxiv.org/abs/2601.01807)
*Ubaidullah,Muhammad Abid Hussain,Mohsin Raza Jafri,Rozi Khan,Moid Sandhu,Abd Ullah Khan,Hyundong Shin*

Main category: cs.CV

TL;DR: LUMPNet 是一种混合深度学习模型，用于早期检测 LSD，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: LSD 是一种传染性病毒，对全球经济和粮食安全构成严重威胁，早期精确识别对预防爆发至关重要。

Method: 结合 YOLOv11、基于 EfficientNet 的 CNN 分类器和新型自适应混合优化器，构建了 LUMPNet 模型。

Result: LUMPNet 在公开数据集上表现优异，训练和验证准确率分别达到 99% 和 98%，且优于 AdamW 优化的 EfficientNet-B0 模型。

Conclusion: LUMPNet 在 LSD 早期检测中表现出色，训练准确率达 99%，验证准确率达 98%，优于现有方案。

Abstract: Lumpy Skin Disease (LSD) is a contagious viral infection that significantly deteriorates livestock health, thereby posing a serious threat to the global economy and food security. Owing to its rapid spread characteristics, early and precise identification is crucial to prevent outbreaks and ensure timely intervention. In this paper, we propose a hybrid deep learning-based approach called LUMPNet for the early detection of LSD. LUMPNet utilizes image data to detect and classify skin nodules -- the primary indicator of LSD. To this end, LUMPNet uses YOLOv11, EfficientNet-based CNN classifier with compound scaling, and a novel adaptive hybrid optimizer. More precisely, LUMPNet detects and localizes LSD skin nodules and lesions on cattle images. It exploits EfficientNet to classify the localized cattle images into LSD-affected or healthy categories. To stabilize and accelerate the training of YOLOv11 and EfficientNet hybrid model, a novel adaptive hybrid optimizer is proposed and utilized. We evaluate LUMPNet at various stages of LSD using a publicly available dataset. Results indicate that the proposed scheme achieves 99% LSD detection training accuracy, and outperforms existing schemes. The model also achieves validation accuracy of 98%. Moreover, for further evaluation, we conduct a case study using an optimized EfficientNet-B0 model trained with the AdamW optimizer, and compare its performance with LUMPNet. The results show that LUMPNet achieves superior performance.

</details>


### [102] [Learnability-Driven Submodular Optimization for Active Roadside 3D Detection](https://arxiv.org/abs/2601.01695)
*Ruiyu Mao,Baoming Zhang,Nicholas Ruozzi,Yunhui Guo*

Main category: cs.CV

TL;DR: LH3D通过主动学习选择可学习性高的路边场景，显著降低标注成本并保持高性能，验证了可学习性对3D感知的重要性。


<details>
  <summary>Details</summary>
Motivation: 路边感知数据集通常依赖车辆与路边的协同标注，但实际部署中常需仅标注路边数据，导致标注困难且成本高，尤其是固有模糊样本的存在。

Method: 提出了一种基于可学习性的主动学习框架LH3D，用于路边单目3D物体检测，通过选择既信息丰富又可可靠标注的场景，抑制固有模糊样本。

Result: 在DAIR-V2X-I数据集上，LH3D仅用25%的标注预算就达到了车辆、行人和骑车者86.06%、67.32%和78.67%的全性能表现，显著优于基于不确定性的基线方法。

Conclusion: LH3D框架通过主动学习选择信息丰富且可可靠标注的场景，显著减少了标注成本，同时保持了高性能，验证了可学习性而非不确定性对路边3D感知的关键作用。

Abstract: Roadside perception datasets are typically constructed via cooperative labeling between synchronized vehicle and roadside frame pairs. However, real deployment often requires annotation of roadside-only data due to hardware and privacy constraints. Even human experts struggle to produce accurate labels without vehicle-side data (image, LIDAR), which not only increases annotation difficulty and cost, but also reveals a fundamental learnability problem: many roadside-only scenes contain distant, blurred, or occluded objects whose 3D properties are ambiguous from a single view and can only be reliably annotated by cross-checking paired vehicle--roadside frames. We refer to such cases as inherently ambiguous samples. To reduce wasted annotation effort on inherently ambiguous samples while still obtaining high-performing models, we turn to active learning. This work focuses on active learning for roadside monocular 3D object detection and proposes a learnability-driven framework that selects scenes which are both informative and reliably labelable, suppressing inherently ambiguous samples while ensuring coverage. Experiments demonstrate that our method, LH3D, achieves 86.06%, 67.32%, and 78.67% of full-performance for vehicles, pedestrians, and cyclists respectively, using only 25% of the annotation budget on DAIR-V2X-I, significantly outperforming uncertainty-based baselines. This confirms that learnability, not uncertainty, matters for roadside 3D perception.

</details>


### [103] [RSwinV2-MD: An Enhanced Residual SwinV2 Transformer for Monkeypox Detection from Skin Images](https://arxiv.org/abs/2601.01835)
*Rashid Iqbal,Saddam Hussain Khan*

Main category: cs.CV

TL;DR: RSwinV2是一种结合SwinTransformer和IRB的深度学习方法，显著提升了Mpox病变分类的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 旨在通过深度学习提升Mpox病变分类能力，克服传统CNN和SwinTransformer在局部区域注意力计算中的局限性。

Method: RSwinV2方法通过定制化的分层Transformer结构、非重叠图像块处理、多注意力头嵌入以及引入IRB模块，有效解决了梯度消失问题并提升了分类性能。

Result: 在Kaggle公共数据集上，RSwinV2实现了96.21%的准确率和95.62%的F1分数，优于标准CNN和SwinTransformer模型。

Conclusion: RSwinV2方法通过结合SwinTransformer的全局链接能力和IRB的局部模式链接能力，显著提高了Mpox病变分类的准确性，证明了其作为计算机辅助工具的价值。

Abstract: In this paper, a deep learning approach for Mpox diagnosis named Customized Residual SwinTransformerV2 (RSwinV2) has been proposed, trying to enhance the capability of lesion classification by employing the RSwinV2 tool-assisted vision approach. In the RSwinV2 method, a hierarchical structure of the transformer has been customized based on the input dimensionality, embedding structure, and output targeted by the method. In this RSwinV2 approach, the input image has been split into non-overlapping patches and processed using shifted windows and attention in these patches. This process has helped the method link all the windows efficiently by avoiding the locality issues of non-overlapping regions in attention, while being computationally efficient. RSwinV2 has further developed based on SwinTransformer and has included patch and position embeddings to take advantage of the transformer global-linking capability by employing multi-head attention in these embeddings. Furthermore, RSwinV2 has developed and incorporated the Inverse Residual Block (IRB) into this method, which utilizes convolutional skip connections with these inclusive designs to address the vanishing gradient issues during processing. RSwinV2 inclusion of IRB has therefore facilitated this method to link global patterns as well as local patterns; hence, its integrity has helped improve lesion classification capability by minimizing variability of Mpox and increasing differences of Mpox, chickenpox, measles, and cowpox. In testing SwinV2, its accuracy of 96.21 and an F1score of 95.62 have been achieved on the Kaggle public dataset, which has outperformed standard CNN models and SwinTransformers; RSwinV2 vector has thus proved its valiance as a computer-assisted tool for Mpox lesion observation interpretation.

</details>


### [104] [FFP-300K: Scaling First-Frame Propagation for Generalizable Video Editing](https://arxiv.org/abs/2601.01720)
*Xijie Huang,Chengming Xu,Donghao Luo,Xiaobin Hu,Peng Tang,Xu Peng,Jiangning Zhang,Chengjie Wang,Yanwei Fu*

Main category: cs.CV

TL;DR: FFP-300K数据集和AST-RoPE框架解决了视频编辑的运行时依赖问题，性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有视频编辑方法因训练数据不足（短、低分辨率、缺乏多样性）而依赖运行时指导，限制了可控性。

Method: 提出了一种基于FFP-300K数据集的新框架，采用AST-RoPE动态重映射位置编码，并结合自蒸馏策略。

Result: 在EditVerseBench基准测试中，性能显著优于现有学术和商业模型（PickScore提升约0.2，VLM评分提升约0.3）。

Conclusion: 该方法通过引入FFP-300K数据集和AST-RoPE架构，解决了现有视频编辑方法对运行时指导的依赖问题，显著提升了性能。

Abstract: First-Frame Propagation (FFP) offers a promising paradigm for controllable video editing, but existing methods are hampered by a reliance on cumbersome run-time guidance. We identify the root cause of this limitation as the inadequacy of current training datasets, which are often too short, low-resolution, and lack the task diversity required to teach robust temporal priors. To address this foundational data gap, we first introduce FFP-300K, a new large-scale dataset comprising 300K high-fidelity video pairs at 720p resolution and 81 frames in length, constructed via a principled two-track pipeline for diverse local and global edits. Building on this dataset, we propose a novel framework designed for true guidance-free FFP that resolves the critical tension between maintaining first-frame appearance and preserving source video motion. Architecturally, we introduce Adaptive Spatio-Temporal RoPE (AST-RoPE), which dynamically remaps positional encodings to disentangle appearance and motion references. At the objective level, we employ a self-distillation strategy where an identity propagation task acts as a powerful regularizer, ensuring long-term temporal stability and preventing semantic drift. Comprehensive experiments on the EditVerseBench benchmark demonstrate that our method significantly outperforming existing academic and commercial models by receiving about 0.2 PickScore and 0.3 VLM score improvement against these competitors.

</details>


### [105] [CogFlow: Bridging Perception and Reasoning through Knowledge Internalization for Visual Mathematical Problem Solving](https://arxiv.org/abs/2601.01874)
*Shuhang Chen,Yunqiu Xu,Junjie Xie,Aojun Lu,Tao Feng,Zeying Huang,Ning Zhang,Yi Sun,Yi Yang,Hangjie Yuan*

Main category: cs.CV

TL;DR: CogFlow通过模拟人类认知的三阶段流程，解决了视觉数学推理中视觉线索整合不足的问题，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法忽视了视觉线索在后续推理中的忠实整合和利用问题，CogFlow旨在解决这一关键问题。

Method: 提出了CogFlow框架，包含知识内化阶段，设计了协同视觉奖励、知识内化奖励模型和视觉门控策略优化算法。

Result: 在常用视觉数学推理基准测试中，CogFlow表现出色，并贡献了包含12万高质量标注的新数据集MathCog。

Conclusion: CogFlow框架通过模拟人类认知的三阶段流程（感知→内化→推理），显著提升了视觉数学问题的解决能力，实验验证了其优越性。

Abstract: Despite significant progress, multimodal large language models continue to struggle with visual mathematical problem solving. Some recent works recognize that visual perception is a bottleneck in visual mathematical reasoning, but their solutions are limited to improving the extraction and interpretation of visual inputs. Notably, they all ignore the key issue of whether the extracted visual cues are faithfully integrated and properly utilized in subsequent reasoning. Motivated by this, we present CogFlow, a novel cognitive-inspired three-stage framework that incorporates a knowledge internalization stage, explicitly simulating the hierarchical flow of human reasoning: perception$\Rightarrow$internalization$\Rightarrow$reasoning. Inline with this hierarchical flow, we holistically enhance all its stages. We devise Synergistic Visual Rewards to boost perception capabilities in parametric and semantic spaces, jointly improving visual information extraction from symbols and diagrams. To guarantee faithful integration of extracted visual cues into subsequent reasoning, we introduce a Knowledge Internalization Reward model in the internalization stage, bridging perception and reasoning. Moreover, we design a Visual-Gated Policy Optimization algorithm to further enforce the reasoning is grounded with the visual knowledge, preventing models seeking shortcuts that appear coherent but are visually ungrounded reasoning chains. Moreover, we contribute a new dataset MathCog for model training, which contains samples with over 120K high-quality perception-reasoning aligned annotations. Comprehensive experiments and analysis on commonly used visual mathematical reasoning benchmarks validate the superiority of the proposed CogFlow.

</details>


### [106] [Point-SRA: Self-Representation Alignment for 3D Representation Learning](https://arxiv.org/abs/2601.01746)
*Lintong Wei,Jian Lu,Haozhe Cheng,Jihua Zhu,Kaibing Zhang*

Main category: cs.CV

TL;DR: Point-SRA通过动态掩码和概率建模优化3D表示学习，显著提升多个任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法固定掩码比率忽略了多级表征相关性和内在几何结构，且依赖于与点云多样性冲突的点级重建假设。

Method: 提出了一种名为Point-SRA的3D表示学习方法，包括动态掩码比率的MAE、MeanFlow Transformer（MFT）以及双自表征对齐机制。

Result: Point-SRA在ScanObjectNN上比Point-MAE提升了5.37%，在颅内动脉瘤分割中达到了96.07%的平均IoU（动脉）和86.87%（动脉瘤），在3D物体检测中AP@50达到47.3%，超越了MaskPoint 5.12%。

Conclusion: Point-SRA通过自蒸馏和概率建模实现了3D表示学习中的表征对齐，显著提升了在多个下游任务中的性能表现。

Abstract: Masked autoencoders (MAE) have become a dominant paradigm in 3D representation learning, setting new performance benchmarks across various downstream tasks. Existing methods with fixed mask ratio neglect multi-level representational correlations and intrinsic geometric structures, while relying on point-wise reconstruction assumptions that conflict with the diversity of point cloud. To address these issues, we propose a 3D representation learning method, termed Point-SRA, which aligns representations through self-distillation and probabilistic modeling. Specifically, we assign different masking ratios to the MAE to capture complementary geometric and semantic information, while the MeanFlow Transformer (MFT) leverages cross-modal conditional embeddings to enable diverse probabilistic reconstruction. Our analysis further reveals that representations at different time steps in MFT also exhibit complementarity. Therefore, a Dual Self-Representation Alignment mechanism is proposed at both the MAE and MFT levels. Finally, we design a Flow-Conditioned Fine-Tuning Architecture to fully exploit the point cloud distribution learned via MeanFlow. Point-SRA outperforms Point-MAE by 5.37% on ScanObjectNN. On intracranial aneurysm segmentation, it reaches 96.07% mean IoU for arteries and 86.87% for aneurysms. For 3D object detection, Point-SRA achieves 47.3% AP@50, surpassing MaskPoint by 5.12%.

</details>


### [107] [Nodule-DETR: A Novel DETR Architecture with Frequency-Channel Attention for Ultrasound Thyroid Nodule Detection](https://arxiv.org/abs/2601.01908)
*Jingjing Wang,Qianglin Liu,Zhuo Xiao,Xinning Yao,Bo Liu,Lu Li,Lijuan Niu,Fugen Zhou*

Main category: cs.CV

TL;DR: Nodule-DETR是一种新型甲状腺结节检测变换器架构，通过创新模块提升超声图像中低对比度结节的检测性能，实验显示其性能显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 超声是检测甲状腺结节的首选成像方式，但其诊断准确性常受低图像对比度和模糊结节边界的限制。为解决这些问题，提出了Nodule-DETR。

Method: Nodule-DETR是一种新型检测变换器（DETR）架构，包含三个关键创新：多光谱频域通道注意力（MSFCA）模块、分层特征融合（HFF）模块和多尺度可变形注意力（MSDA）模块。

Result: 在真实世界甲状腺超声图像的临床数据集上进行的实验表明，Nodule-DETR在mAP@0.5:0.95上显著优于基线模型0.149，达到了最先进的性能。

Conclusion: Nodule-DETR展示了在计算机辅助甲状腺诊断中的显著潜力，其卓越的准确性使其成为临床应用的潜在有效工具。

Abstract: Thyroid cancer is the most common endocrine malignancy, and its incidence is rising globally. While ultrasound is the preferred imaging modality for detecting thyroid nodules, its diagnostic accuracy is often limited by challenges such as low image contrast and blurred nodule boundaries. To address these issues, we propose Nodule-DETR, a novel detection transformer (DETR) architecture designed for robust thyroid nodule detection in ultrasound images. Nodule-DETR introduces three key innovations: a Multi-Spectral Frequency-domain Channel Attention (MSFCA) module that leverages frequency analysis to enhance features of low-contrast nodules; a Hierarchical Feature Fusion (HFF) module for efficient multi-scale integration; and Multi-Scale Deformable Attention (MSDA) to flexibly capture small and irregularly shaped nodules. We conducted extensive experiments on a clinical dataset of real-world thyroid ultrasound images. The results demonstrate that Nodule-DETR achieves state-of-the-art performance, outperforming the baseline model by a significant margin of 0.149 in mAP@0.5:0.95. The superior accuracy of Nodule-DETR highlights its significant potential for clinical application as an effective tool in computer-aided thyroid diagnosis. The code of work is available at https://github.com/wjj1wjj/Nodule-DETR.

</details>


### [108] [MANGO:Natural Multi-speaker 3D Talking Head Generation via 2D-Lifted Enhancement](https://arxiv.org/abs/2601.01749)
*Lei Zhu,Lijian Lin,Ye Zhu,Jiahao Wu,Xuehan Hou,Yu Li,Yunfei Liu,Jie Chen*

Main category: cs.CV

TL;DR: MANGO是一个两阶段框架，通过纯图像级监督和交替训练，解决了现有音频驱动3D头部生成方法在双向对话场景中的不足，实现了更高保真度和可控性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要针对单说话者场景，缺乏自然的双向听-说交互，且依赖伪3D标签导致精细面部动态捕捉不足。

Method: 采用两阶段框架：第一阶段使用基于扩散的Transformer和双音频交互模块建模多说话者音频的自然3D运动；第二阶段通过快速3D高斯渲染器生成高保真图像，并通过交替训练提供2D级光度监督。

Result: 实验表明，MANGO在建模两人3D对话运动时表现出色，显著提升了音频驱动说话头部的保真度和可控性。

Conclusion: MANGO框架通过两阶段训练和纯图像级监督，显著提升了音频驱动3D头部生成的准确性和真实感，特别是在双向对话场景中。

Abstract: Current audio-driven 3D head generation methods mainly focus on single-speaker scenarios, lacking natural, bidirectional listen-and-speak interaction. Achieving seamless conversational behavior, where speaking and listening states transition fluidly remains a key challenge. Existing 3D conversational avatar approaches rely on error-prone pseudo-3D labels that fail to capture fine-grained facial dynamics. To address these limitations, we introduce a novel two-stage framework MANGO, which leveraging pure image-level supervision by alternately training to mitigate the noise introduced by pseudo-3D labels, thereby achieving better alignment with real-world conversational behaviors. Specifically, in the first stage, a diffusion-based transformer with a dual-audio interaction module models natural 3D motion from multi-speaker audio. In the second stage, we use a fast 3D Gaussian Renderer to generate high-fidelity images and provide 2D-level photometric supervision for the 3D motions through alternate training. Additionally, we introduce MANGO-Dialog, a high-quality dataset with over 50 hours of aligned 2D-3D conversational data across 500+ identities. Extensive experiments demonstrate that our method achieves exceptional accuracy and realism in modeling two-person 3D dialogue motion, significantly advancing the fidelity and controllability of audio-driven talking heads.

</details>


### [109] [CTIS-QA: Clinical Template-Informed Slide-level Question Answering for Pathology](https://arxiv.org/abs/2601.01769)
*Hao Lu,Ziniu Qian,Yifu Li,Yang Zhou,Bingzheng Wei,Yan Xu*

Main category: cs.CV

TL;DR: 论文提出标准化病理信息提取流程和CTIS-QA模型，在多个任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 旨在通过标准化流程和数据集，提升病理报告的自动化和准确性，同时通过CTIS-QA模型模拟病理学家的诊断方法。

Method: 设计了临床病理报告模板（CPRT）来标准化提取病理特征，并构建了CTIS-Align和CTIS-Bench数据集。CTIS-QA模型采用双流架构，分别捕捉全局和局部信息。

Result: CTIS-QA模型在WSI-VQA、CTIS-Bench和幻灯片级诊断任务中均优于现有最佳模型。

Conclusion: 论文提出了一个基于临床诊断模板的流程，通过标准化提取病理信息并构建了CTIS-QA模型，该模型在多个任务上表现优于现有最佳模型。

Abstract: In this paper, we introduce a clinical diagnosis template-based pipeline to systematically collect and structure pathological information. In collaboration with pathologists and guided by the the College of American Pathologists (CAP) Cancer Protocols, we design a Clinical Pathology Report Template (CPRT) that ensures comprehensive and standardized extraction of diagnostic elements from pathology reports. We validate the effectiveness of our pipeline on TCGA-BRCA. First, we extract pathological features from reports using CPRT. These features are then used to build CTIS-Align, a dataset of 80k slide-description pairs from 804 WSIs for vision-language alignment training, and CTIS-Bench, a rigorously curated VQA benchmark comprising 977 WSIs and 14,879 question-answer pairs. CTIS-Bench emphasizes clinically grounded, closed-ended questions (e.g., tumor grade, receptor status) that reflect real diagnostic workflows, minimize non-visual reasoning, and require genuine slide understanding. We further propose CTIS-QA, a Slide-level Question Answering model, featuring a dual-stream architecture that mimics pathologists' diagnostic approach. One stream captures global slide-level context via clustering-based feature aggregation, while the other focuses on salient local regions through attention-guided patch perception module. Extensive experiments on WSI-VQA, CTIS-Bench, and slide-level diagnostic tasks show that CTIS-QA consistently outperforms existing state-of-the-art models across multiple metrics. Code and data are available at https://github.com/HLSvois/CTIS-QA.

</details>


### [110] [DDNet: A Dual-Stream Graph Learning and Disentanglement Framework for Temporal Forgery Localization](https://arxiv.org/abs/2601.01784)
*Boyang Zhao,Xin Liao,Jiaxin Chen,Xiaoshuai Wu,Yufeng Wu*

Main category: cs.CV

TL;DR: DDNet通过双流图学习和解缠框架，显著提升时间伪造定位性能，优于现有方法9%的AP@0.95。


<details>
  <summary>Details</summary>
Motivation: AIGC技术的快速发展使得视频篡改仅需改动小片段即可误导观众，现有方法因局限于局部视角而无法捕捉全局异常，因此需要更精确的时间伪造定位方法。

Method: 提出DDNet框架，结合时间距离流（捕捉局部伪影）和语义内容流（捕捉长程连接），并引入Trace Disentanglement and Adaptation（TDA）和Cross-Level Feature Embedding（CLFE）技术。

Result: 在ForgeryNet和TVIL基准测试中，DDNet的AP@0.95比现有方法提高了约9%，跨域鲁棒性显著提升。

Conclusion: DDNet通过双流图学习和解缠框架，显著提升了时间伪造定位的准确性和跨域鲁棒性，实验结果表明其在ForgeryNet和TVIL基准上优于现有方法约9%的AP@0.95。

Abstract: The rapid evolution of AIGC technology enables misleading viewers by tampering mere small segments within a video, rendering video-level detection inaccurate and unpersuasive. Consequently, temporal forgery localization (TFL), which aims to precisely pinpoint tampered segments, becomes critical. However, existing methods are often constrained by \emph{local view}, failing to capture global anomalies. To address this, we propose a \underline{d}ual-stream graph learning and \underline{d}isentanglement framework for temporal forgery localization (DDNet). By coordinating a \emph{Temporal Distance Stream} for local artifacts and a \emph{Semantic Content Stream} for long-range connections, DDNet prevents global cues from being drowned out by local smoothness. Furthermore, we introduce Trace Disentanglement and Adaptation (TDA) to isolate generic forgery fingerprints, alongside Cross-Level Feature Embedding (CLFE) to construct a robust feature foundation via deep fusion of hierarchical features. Experiments on ForgeryNet and TVIL benchmarks demonstrate that our method outperforms state-of-the-art approaches by approximately 9\% in AP@0.95, with significant improvements in cross-domain robustness.

</details>


### [111] [Enhancing Object Detection with Privileged Information: A Model-Agnostic Teacher-Student Approach](https://arxiv.org/abs/2601.02016)
*Matthias Bartolo,Dylan Seychell,Gabriel Hili,Matthew Montebello,Carl James Debono,Saviour Formosa,Konstantinos Makantasis*

Main category: cs.CV

TL;DR: 本文提出了一种利用特权信息提升物体检测性能的通用方法，通过师生架构实现，实验证明其在不增加计算负担的情况下显著提高精度。


<details>
  <summary>Details</summary>
Motivation: 研究如何利用训练期间可用但在推理时不可用的细粒度描述性信息，以提升物体检测的性能。

Method: 提出了一种通用的、模型无关的方法，通过师生架构将特权信息（如边界框掩码、显著性图和深度线索）注入基于深度学习的物体检测器中。

Result: 实验结果表明，LUPI训练的学生模型在检测精度上显著优于基线模型，且不增加推理复杂度或模型大小。中等和大尺寸物体的性能提升尤为明显。

Conclusion: 研究发现，LUPI框架为在资源受限和现实世界环境中推进物体检测系统提供了一种有效且实用的策略。

Abstract: This paper investigates the integration of the Learning Using Privileged Information (LUPI) paradigm in object detection to exploit fine-grained, descriptive information available during training but not at inference. We introduce a general, model-agnostic methodology for injecting privileged information-such as bounding box masks, saliency maps, and depth cues-into deep learning-based object detectors through a teacher-student architecture. Experiments are conducted across five state-of-the-art object detection models and multiple public benchmarks, including UAV-based litter detection datasets and Pascal VOC 2012, to assess the impact on accuracy, generalization, and computational efficiency. Our results demonstrate that LUPI-trained students consistently outperform their baseline counterparts, achieving significant boosts in detection accuracy with no increase in inference complexity or model size. Performance improvements are especially marked for medium and large objects, while ablation studies reveal that intermediate weighting of teacher guidance optimally balances learning from privileged and standard inputs. The findings affirm that the LUPI framework provides an effective and practical strategy for advancing object detection systems in both resource-constrained and real-world settings.

</details>


### [112] [Agentic Retoucher for Text-To-Image Generation](https://arxiv.org/abs/2601.02046)
*Shaocheng Shen,Jianfeng Liang. Chunlei Cai,Cong Geng,Huiyu Duan,Xiaoyun Zhang,Qiang Hu,Guangtao Zhai*

Main category: cs.CV

TL;DR: Agentic Retoucher 通过感知-推理-行动循环，高效修正文本到图像生成的局部失真，显著提升质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在成本高或语义漂移问题，需一种更可靠且可控的局部修正方法。

Method: 设计了三个代理：(1) 感知代理学习上下文显著性以定位失真，(2) 推理代理通过渐进偏好对齐进行诊断，(3) 行动代理基于用户偏好规划局部修复。

Result: 在 GenBlemish-27K 数据集上实验表明，该方法在感知质量、失真定位和用户偏好对齐上优于现有方法。

Conclusion: Agentic Retoucher 提出了一种新的层次化决策驱动框架，通过感知-推理-行动的循环实现了对文本到图像生成中局部失真的高效修正，显著提升了生成图像的质量和用户偏好对齐。

Abstract: Text-to-image (T2I) diffusion models such as SDXL and FLUX have achieved impressive photorealism, yet small-scale distortions remain pervasive in limbs, face, text and so on. Existing refinement approaches either perform costly iterative re-generation or rely on vision-language models (VLMs) with weak spatial grounding, leading to semantic drift and unreliable local edits. To close this gap, we propose Agentic Retoucher, a hierarchical decision-driven framework that reformulates post-generation correction as a human-like perception-reasoning-action loop. Specifically, we design (1) a perception agent that learns contextual saliency for fine-grained distortion localization under text-image consistency cues, (2) a reasoning agent that performs human-aligned inferential diagnosis via progressive preference alignment, and (3) an action agent that adaptively plans localized inpainting guided by user preference. This design integrates perceptual evidence, linguistic reasoning, and controllable correction into a unified, self-corrective decision process. To enable fine-grained supervision and quantitative evaluation, we further construct GenBlemish-27K, a dataset of 6K T2I images with 27K annotated artifact regions across 12 categories. Extensive experiments demonstrate that Agentic Retoucher consistently outperforms state-of-the-art methods in perceptual quality, distortion localization and human preference alignment, establishing a new paradigm for self-corrective and perceptually reliable T2I generation.

</details>


### [113] [Causality-Aware Temporal Projection for Video Understanding in Video-LLMs](https://arxiv.org/abs/2601.01804)
*Zhengjian Kang,Qi Chen,Rui Liu,Kangtong Mo,Xingyu Zhang,Xiaoyu Deng,Ye Zhang*

Main category: cs.CV

TL;DR: V-CORE通过显式时序约束提升视频理解，在多个基准测试中表现优异，尤其在时序和因果推理任务中显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有的视频大语言模型（Video-LLMs）在需要一致时序和因果连贯性的视频理解任务中表现不足，主要原因是缺乏显式的时序约束机制。

Method: V-CORE包含两个关键组件：可学习的空间聚合（LSA）和因果感知时序投影器（CATP），通过块因果注意力和终端动态摘要令牌确保时序信息的严格有序聚合。

Result: V-CORE在NExT-QA基准测试中达到61.2%的准确率，并在MSVD-QA、MSRVTT-QA和TGIF-QA等任务中保持竞争力，尤其在时序和因果推理子类别中分别提升3.5%和5.2%。

Conclusion: V-CORE框架通过引入显式的时间顺序约束，显著提升了视频理解任务中的时序和因果推理能力，验证了显式时序约束的重要性。

Abstract: Recent Video Large Language Models (Video-LLMs) have shown strong multimodal reasoning capabilities, yet remain challenged by video understanding tasks that require consistent temporal ordering and causal coherence. Many parameter-efficient Video-LLMs rely on unconstrained bidirectional projectors to model inter-frame interactions, which can blur temporal ordering by allowing later frames to influence earlier representations, without explicit architectural mechanisms to respect the directional nature of video reasoning. To address this limitation, we propose V-CORE, a parameter-efficient framework that introduces explicit temporal ordering constraints for video understanding. V-CORE consists of two key components: (1) Learnable Spatial Aggregation (LSA), which adaptively selects salient spatial tokens to reduce redundancy, and (2) a Causality-Aware Temporal Projector (CATP), which enforces structured unidirectional information flow via block-causal attention and a terminal dynamic summary token acting as a causal sink. This design preserves intra-frame spatial interactions while ensuring that temporal information is aggregated in a strictly ordered manner. With 4-bit QLoRA and a frozen LLM backbone, V-CORE can be trained efficiently on a single consumer GPU. Experiments show that V-CORE achieves strong performance on the challenging NExT-QA benchmark, reaching 61.2% accuracy, and remains competitive across MSVD-QA, MSRVTT-QA, and TGIF-QA, with gains concentrated in temporal and causal reasoning subcategories (+3.5% and +5.2% respectively), directly validating the importance of explicit temporal ordering constraints.

</details>


### [114] [Robust Egocentric Visual Attention Prediction Through Language-guided Scene Context-aware Learning](https://arxiv.org/abs/2601.01818)
*Sungjune Park,Hongda Mao,Qingshuang Chen,Yong Man Ro,Yelin Kim*

Main category: cs.CV

TL;DR: 该论文提出了一种语言引导的场景上下文感知学习框架，用于自我中心视觉注意力预测，通过上下文感知器和特定训练目标，在多个数据集中实现了最佳性能。


<details>
  <summary>Details</summary>
Motivation: 由于动态自我中心场景的复杂性和模糊性，自我中心视觉注意力预测具有挑战性。研究表明场景上下文信息在调节人类注意力中起关键作用，因此提出了语言引导的场景上下文感知学习框架。

Method: 设计了一个上下文感知器，基于语言场景描述生成上下文感知的视频表示，并引入了两个训练目标：一是聚焦于目标兴趣区域，二是抑制不太可能吸引第一人称注意力的无关区域的干扰。

Result: 在Ego4D和Aria Everyday Activities (AEA)数据集上的大量实验证明了该方法的有效性，实现了最先进的性能。

Conclusion: 该论文提出的语言引导的场景上下文感知学习框架在自我中心视觉注意力预测任务中表现出色，实现了最先进的性能，并在多样化的动态自我中心场景中增强了鲁棒性。

Abstract: As the demand for analyzing egocentric videos grows, egocentric visual attention prediction, anticipating where a camera wearer will attend, has garnered increasing attention. However, it remains challenging due to the inherent complexity and ambiguity of dynamic egocentric scenes. Motivated by evidence that scene contextual information plays a crucial role in modulating human attention, in this paper, we present a language-guided scene context-aware learning framework for robust egocentric visual attention prediction. We first design a context perceiver which is guided to summarize the egocentric video based on a language-based scene description, generating context-aware video representations. We then introduce two training objectives that: 1) encourage the framework to focus on the target point-of-interest regions and 2) suppress distractions from irrelevant regions which are less likely to attract first-person attention. Extensive experiments on Ego4D and Aria Everyday Activities (AEA) datasets demonstrate the effectiveness of our approach, achieving state-of-the-art performance and enhanced robustness across diverse, dynamic egocentric scenarios.

</details>


### [115] [Remote Sensing Change Detection via Weak Temporal Supervision](https://arxiv.org/abs/2601.02126)
*Xavier Bou,Elliot Vincent,Gabriele Facciolo,Rafael Grompone von Gioi,Jean-Michel Morel,Thibaud Ehret*

Main category: cs.CV

TL;DR: 利用现有单时相数据集的弱时间监督策略，无需新标注，实现了高性能变化检测，适用于零样本和低数据量场景。


<details>
  <summary>Details</summary>
Motivation: 解决遥感语义变化检测中标注数据稀缺的问题，避免高成本的像素级标注，同时提升模型的域外泛化能力。

Method: 提出了一种弱时间监督策略，通过扩展单时相数据集为多时相观测，并假设真实双时相对大多无变化，同时利用不同位置的图像生成变化样本。采用对象感知的变化图生成和迭代优化过程处理弱标签噪声。

Result: 在FLAIR和IAILD航空数据集的扩展版本上验证了方法的有效性，展示了零样本和低数据量下的高性能，并在法国大区域应用中显示了可扩展性。

Conclusion: 该方法通过弱时间监督策略有效利用了现有单时相数据集，无需额外标注，实现了零样本和低数据量下的高性能变化检测，并展示了在大规模应用中的潜力。

Abstract: Semantic change detection in remote sensing aims to identify land cover changes between bi-temporal image pairs. Progress in this area has been limited by the scarcity of annotated datasets, as pixel-level annotation is costly and time-consuming. To address this, recent methods leverage synthetic data or generate artificial change pairs, but out-of-domain generalization remains limited. In this work, we introduce a weak temporal supervision strategy that leverages additional temporal observations of existing single-temporal datasets, without requiring any new annotations. Specifically, we extend single-date remote sensing datasets with new observations acquired at different times and train a change detection model by assuming that real bi-temporal pairs mostly contain no change, while pairing images from different locations to generate change examples. To handle the inherent noise in these weak labels, we employ an object-aware change map generation and an iterative refinement process. We validate our approach on extended versions of the FLAIR and IAILD aerial datasets, achieving strong zero-shot and low-data regime performance across different benchmarks. Lastly, we showcase results over large areas in France, highlighting the scalability potential of our method.

</details>


### [116] [BiPrompt: Bilateral Prompt Optimization for Visual and Textual Debiasing in Vision-Language Models](https://arxiv.org/abs/2601.02147)
*Sunny Gupta,Shounak Das,Amit Sethi*

Main category: cs.CV

TL;DR: BiPrompt通过双边提示优化同时减少视觉和文本模态中的非因果特征依赖，提升模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决现有去偏方法仅针对单一模态（视觉或文本）导致的部分鲁棒性和不稳定适应问题。

Method: 采用结构化注意力引导擦除以抑制背景激活，并在文本侧引入平衡提示归一化，对齐类嵌入至各向同性语义空间。

Result: 在真实世界和合成偏置基准测试中，BiPrompt在平均和最差组准确率上均优于现有测试时去偏方法。

Conclusion: BiPrompt框架通过双边提示优化，有效减少了视觉和文本模态中的非因果特征依赖，提升了模型在分布变化下的鲁棒性和适应性，无需重新训练或领域监督。

Abstract: Vision language foundation models such as CLIP exhibit impressive zero-shot generalization yet remain vulnerable to spurious correlations across visual and textual modalities. Existing debiasing approaches often address a single modality either visual or textual leading to partial robustness and unstable adaptation under distribution shifts. We propose a bilateral prompt optimization framework (BiPrompt) that simultaneously mitigates non-causal feature reliance in both modalities during test-time adaptation. On the visual side, it employs structured attention-guided erasure to suppress background activations and enforce orthogonal prediction consistency between causal and spurious regions. On the textual side, it introduces balanced prompt normalization, a learnable re-centering mechanism that aligns class embeddings toward an isotropic semantic space. Together, these modules jointly minimize conditional mutual information between spurious cues and predictions, steering the model toward causal, domain invariant reasoning without retraining or domain supervision. Extensive evaluations on real-world and synthetic bias benchmarks demonstrate consistent improvements in both average and worst-group accuracies over prior test-time debiasing methods, establishing a lightweight yet effective path toward trustworthy and causally grounded vision-language adaptation.

</details>


### [117] [ESGaussianFace: Emotional and Stylized Audio-Driven Facial Animation via 3D Gaussian Splatting](https://arxiv.org/abs/2601.01847)
*Chuhang Ma,Shuai Tan,Ye Pan,Jiaolong Yang,Xin Tong*

Main category: cs.CV

TL;DR: ESGaussianFace 是一个创新的情感化和风格化音频驱动面部动画框架，通过3D高斯点溅射和情感音频引导的空间注意力方法，实现了高质量、高效率的视频生成，实验表现优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 当前音频驱动面部动画研究多集中于中性情感视频生成，情感化和风格化的高质量视频生成仍具挑战性。本文旨在解决这一挑战，提出一个高效生成情感化和风格化面部动画的框架。

Method: 利用3D高斯点溅射技术重建3D场景并渲染视频，提出情感音频引导的空间注意力方法，以及两个3D高斯点变形预测器，实现情感和风格特征的3D高斯点变形。采用多阶段训练策略逐步学习嘴唇运动、情感变化和风格特征。

Result: 生成的视频具有高效率、高质量和3D一致性，实验结果表明在嘴唇运动准确性、表情变化和风格特征表现力方面优于现有技术。

Conclusion: ESGaussianFace 框架通过创新的3D高斯点变形预测器和情感音频引导的空间注意力方法，成功实现了高质量、高效率的情感化和风格化音频驱动面部动画生成，实验证明其在嘴唇运动准确性、表情变化和风格特征表现力方面优于现有技术。

Abstract: Most current audio-driven facial animation research primarily focuses on generating videos with neutral emotions. While some studies have addressed the generation of facial videos driven by emotional audio, efficiently generating high-quality talking head videos that integrate both emotional expressions and style features remains a significant challenge. In this paper, we propose ESGaussianFace, an innovative framework for emotional and stylized audio-driven facial animation. Our approach leverages 3D Gaussian Splatting to reconstruct 3D scenes and render videos, ensuring efficient generation of 3D consistent results. We propose an emotion-audio-guided spatial attention method that effectively integrates emotion features with audio content features. Through emotion-guided attention, the model is able to reconstruct facial details across different emotional states more accurately. To achieve emotional and stylized deformations of the 3D Gaussian points through emotion and style features, we introduce two 3D Gaussian deformation predictors. Futhermore, we propose a multi-stage training strategy, enabling the step-by-step learning of the character's lip movements, emotional variations, and style features. Our generated results exhibit high efficiency, high quality, and 3D consistency. Extensive experimental results demonstrate that our method outperforms existing state-of-the-art techniques in terms of lip movement accuracy, expression variation, and style feature expressiveness.

</details>


### [118] [GCR: Geometry-Consistent Routing for Task-Agnostic Continual Anomaly Detection](https://arxiv.org/abs/2601.01856)
*Joongwon Chae,Lihui Luo,Yang Liu,Runming Wang,Dongmei Yu,Zeming Liang,Xi Yuan,Dayan Zhang,Zhenglin Chen,Peiwu Qin,Ilmoon Chae*

Main category: cs.CV

TL;DR: GCR是一种几何一致的路由框架，通过分离跨头决策和头内异常评分，解决了跨头路由中的分数可比性问题，提升了持续异常检测的稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在跨类别路由时，由于分数分布在不同类别间差异较大，导致路由不可靠。GCR旨在通过几何一致的路由机制解决这一问题。

Method: GCR是一种轻量级的专家混合框架，通过在共享的冻结补丁嵌入空间中最小化累积最近原型距离来路由测试图像，并使用标准的基于原型的评分规则在路由的专家内计算异常图。

Result: 在MVTec AD和VisA数据集上的实验表明，GCR显著提高了路由稳定性，并实现了近乎零遗忘的持续异常检测性能。

Conclusion: GCR框架通过几何一致的路由机制，显著提高了路由稳定性并缓解了持续性能崩溃，实现了近乎零遗忘的同时保持了竞争力的检测和定位性能。

Abstract: Feature-based anomaly detection is widely adopted in industrial inspection due to the strong representational power of large pre-trained vision encoders. While most existing methods focus on improving within-category anomaly scoring, practical deployments increasingly require task-agnostic operation under continual category expansion, where the category identity is unknown at test time. In this setting, overall performance is often dominated by expert selection, namely routing an input to an appropriate normality model before any head-specific scoring is applied. However, routing rules that compare head-specific anomaly scores across independently constructed heads are unreliable in practice, as score distributions can differ substantially across categories in scale and tail behavior.
  We propose GCR, a lightweight mixture-of-experts framework for stabilizing task-agnostic continual anomaly detection through geometry-consistent routing. GCR routes each test image directly in a shared frozen patch-embedding space by minimizing an accumulated nearest-prototype distance to category-specific prototype banks, and then computes anomaly maps only within the routed expert using a standard prototype-based scoring rule. By separating cross-head decision making from within-head anomaly scoring, GCR avoids cross-head score comparability issues without requiring end-to-end representation learning.
  Experiments on MVTec AD and VisA show that geometry-consistent routing substantially improves routing stability and mitigates continual performance collapse, achieving near-zero forgetting while maintaining competitive detection and localization performance. These results indicate that many failures previously attributed to representation forgetting can instead be explained by decision-rule instability in cross-head routing. Code is available at https://github.com/jw-chae/GCR

</details>


### [119] [NextFlow: Unified Sequential Modeling Activates Multimodal Understanding and Generation](https://arxiv.org/abs/2601.02204)
*Huichao Zhang,Liao Qu,Yiheng Liu,Hang Chen,Yangyang Song,Yongsheng Dong,Shikun Sun,Xian Li,Xu Wang,Yi Jiang,Hu Ye,Bo Chen,Yiming Gao,Peng Liu,Akide Liu,Zhipeng Yang,Qili Deng,Linjie Xing,Jiyang Liu,Zhao Wang,Yang Zhou,Mingcong Liu,Yi Zhang,Qian He,Xiwei Hu,Zhongqi Qi,Jie Shao,Zhiye Fu,Shuai Wang,Fangmin Chen,Xuezhi Chai,Zhihua Wu,Yitong Wang,Zehuan Yuan,Daniel K. Du,Xinglong Wu*

Main category: cs.CV

TL;DR: NextFlow是一个统一的解码器自回归模型，通过创新的多尺度预测方法，高效生成高质量文本和图像，挑战专业扩散模型。


<details>
  <summary>Details</summary>
Motivation: 针对文本和图像模态的不同特性（文本严格序列化，图像具有层次性），提出统一的处理框架以激活多模态理解和生成能力。

Method: 采用统一的解码器自回归架构，结合文本的下一词预测和图像的下一尺度预测，通过稳健的训练方法和前缀调优策略优化生成过程。

Result: NextFlow在5秒内生成1024x1024图像，速度远超同类AR模型，并在视觉质量上媲美专业扩散模型。

Conclusion: NextFlow通过统一的解码器自回归架构和创新的多尺度预测方法，在文本和图像生成任务中实现了高效和高质量的输出，挑战了专业扩散模型的性能。

Abstract: We present NextFlow, a unified decoder-only autoregressive transformer trained on 6 trillion interleaved text-image discrete tokens. By leveraging a unified vision representation within a unified autoregressive architecture, NextFlow natively activates multimodal understanding and generation capabilities, unlocking abilities of image editing, interleaved content and video generation. Motivated by the distinct nature of modalities - where text is strictly sequential and images are inherently hierarchical - we retain next-token prediction for text but adopt next-scale prediction for visual generation. This departs from traditional raster-scan methods, enabling the generation of 1024x1024 images in just 5 seconds - orders of magnitude faster than comparable AR models. We address the instabilities of multi-scale generation through a robust training recipe. Furthermore, we introduce a prefix-tuning strategy for reinforcement learning. Experiments demonstrate that NextFlow achieves state-of-the-art performance among unified models and rivals specialized diffusion baselines in visual quality.

</details>


### [120] [RRNet: Configurable Real-Time Video Enhancement with Arbitrary Local Lighting Variations](https://arxiv.org/abs/2601.01865)
*Wenlong Yang,Canran Jin,Weihang Yuan,Chao Wang,Lifeng Sun*

Main category: cs.CV

TL;DR: RRNet是一个轻量级框架，通过虚拟光源参数估计和深度感知渲染实现高效局部重照明，适用于视频会议等应用，实验表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 实时视频增强在直播应用中的需求日益增长，现有方法在速度和有效曝光控制（尤其是在不均匀光照下）之间难以平衡。

Method: RRNet是一个轻量级且可配置的框架，通过估计最小虚拟光源集的参数，通过深度感知渲染模块实现局部重照明，无需像素对齐的训练数据。

Result: RRNet在视觉质量和效率之间实现了最先进的权衡，通过简化的编码器和轻量级预测头支持实时高分辨率性能。

Conclusion: RRNet通过其可解释的照明控制和高效架构，适用于视频会议、AR肖像增强和移动摄影等实际应用，实验表明其在低光增强、局部照明调整和眩光去除方面优于现有方法。

Abstract: With the growing demand for real-time video enhancement in live applications, existing methods often struggle to balance speed and effective exposure control, particularly under uneven lighting. We introduce RRNet (Rendering Relighting Network), a lightweight and configurable framework that achieves a state-of-the-art tradeoff between visual quality and efficiency. By estimating parameters for a minimal set of virtual light sources, RRNet enables localized relighting through a depth-aware rendering module without requiring pixel-aligned training data. This object-aware formulation preserves facial identity and supports real-time, high-resolution performance using a streamlined encoder and lightweight prediction head. To facilitate training, we propose a generative AI-based dataset creation pipeline that synthesizes diverse lighting conditions at low cost. With its interpretable lighting control and efficient architecture, RRNet is well suited for practical applications such as video conferencing, AR-based portrait enhancement, and mobile photography. Experiments show that RRNet consistently outperforms prior methods in low-light enhancement, localized illumination adjustment, and glare removal.

</details>


### [121] [Seeing the Unseen: Zooming in the Dark with Event Cameras](https://arxiv.org/abs/2601.02206)
*Dachun Kai,Zeyu Xiao,Huyue Zhu,Jiaxiao Wang,Yueyi Zhang,Xiaoyan Sun*

Main category: cs.CV

TL;DR: RetinexEVSR是一种新型事件驱动的低光视频超分辨率框架，通过结合事件信号和Retinex先验，显著提升了视频质量和处理效率。


<details>
  <summary>Details</summary>
Motivation: 现有的低光视频超分辨率方法由于对比度有限和高频信息不足，难以恢复细节。

Method: 提出了一种双向跨模态融合策略，包括光照引导的事件增强模块和事件引导的反射增强模块，以从噪声事件数据和退化的RGB帧中提取并整合有用信息。

Result: 在三个数据集上实现了最先进的性能，特别是在SDSD基准测试中，性能提升达2.95 dB，同时运行时减少65%。

Conclusion: RetinexEVSR通过结合事件信号和Retinex先验，显著提升了低光视频超分辨率的质量和效率，成为当前最先进的方法。

Abstract: This paper addresses low-light video super-resolution (LVSR), aiming to restore high-resolution videos from low-light, low-resolution (LR) inputs. Existing LVSR methods often struggle to recover fine details due to limited contrast and insufficient high-frequency information. To overcome these challenges, we present RetinexEVSR, the first event-driven LVSR framework that leverages high-contrast event signals and Retinex-inspired priors to enhance video quality under low-light scenarios. Unlike previous approaches that directly fuse degraded signals, RetinexEVSR introduces a novel bidirectional cross-modal fusion strategy to extract and integrate meaningful cues from noisy event data and degraded RGB frames. Specifically, an illumination-guided event enhancement module is designed to progressively refine event features using illumination maps derived from the Retinex model, thereby suppressing low-light artifacts while preserving high-contrast details. Furthermore, we propose an event-guided reflectance enhancement module that utilizes the enhanced event features to dynamically recover reflectance details via a multi-scale fusion mechanism. Experimental results show that our RetinexEVSR achieves state-of-the-art performance on three datasets. Notably, on the SDSD benchmark, our method can get up to 2.95 dB gain while reducing runtime by 65% compared to prior event-based methods. Code: https://github.com/DachunKai/RetinexEVSR.

</details>


### [122] [Entity-Guided Multi-Task Learning for Infrared and Visible Image Fusion](https://arxiv.org/abs/2601.01870)
*Wenyu Shao,Hongbo Liu,Yunchuan Ma,Ruili Wang*

Main category: cs.CV

TL;DR: EGMT是一种新型红外与可见光图像融合方法，通过实体级文本提取和多任务学习提升融合质量，实验效果优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖句子级文本信息，易引入语义噪声且未能充分利用文本的深层语义价值，因此需要一种更高效的融合方法。

Method: 提出了一种基于实体级文本信息提取和多任务学习的融合方法，包括实体级文本信息提取、并行多任务学习架构构建以及实体引导的跨模态交互模块开发。

Result: 实验证明EGMT在保留显著目标、纹理细节和语义一致性方面优于现有方法，并发布了四个公共数据集的实体标注版本。

Conclusion: EGMT方法通过实体引导的多任务学习架构，显著提升了红外与可见光图像融合的质量和语义密度，并在实验中展现出优于现有方法的性能。

Abstract: Existing text-driven infrared and visible image fusion approaches often rely on textual information at the sentence level, which can lead to semantic noise from redundant text and fail to fully exploit the deeper semantic value of textual information. To address these issues, we propose a novel fusion approach named Entity-Guided Multi-Task learning for infrared and visible image fusion (EGMT). Our approach includes three key innovative components: (i) A principled method is proposed to extract entity-level textual information from image captions generated by large vision-language models, eliminating semantic noise from raw text while preserving critical semantic information; (ii) A parallel multi-task learning architecture is constructed, which integrates image fusion with a multi-label classification task. By using entities as pseudo-labels, the multi-label classification task provides semantic supervision, enabling the model to achieve a deeper understanding of image content and significantly improving the quality and semantic density of the fused image; (iii) An entity-guided cross-modal interactive module is also developed to facilitate the fine-grained interaction between visual and entity-level textual features, which enhances feature representation by capturing cross-modal dependencies at both inter-visual and visual-entity levels. To promote the wide application of the entity-guided image fusion framework, we release the entity-annotated version of four public datasets (i.e., TNO, RoadScene, M3FD, and MSRS). Extensive experiments demonstrate that EGMT achieves superior performance in preserving salient targets, texture details, and semantic consistency, compared to the state-of-the-art methods. The code and dataset will be publicly available at https://github.com/wyshao-01/EGMT.

</details>


### [123] [VIBE: Visual Instruction Based Editor](https://arxiv.org/abs/2601.02242)
*Grigorii Alekseenko,Aleksandr Gordeev,Irina Tolstykh,Bulat Suleimanov,Vladimir Dokholyan,Georgii Fedorov,Sergey Yakubson,Aleksandra Tsybina,Mikhail Chernyshov,Maksim Kuprashevich*

Main category: cs.CV

TL;DR: 提出了一种高效的小模型图像编辑流程，性能媲美大模型，适合低成本和快速推理。


<details>
  <summary>Details</summary>
Motivation: 当前开源模型在真实世界质量上有限，且主流扩散模型参数庞大（6B-20B），计算成本高，需要更高效的解决方案。

Method: 采用2B参数的Qwen3-VL模型指导编辑过程和1.6B参数的扩散模型Sana1.5进行图像生成，设计决策涵盖架构、数据处理、训练配置和评估。

Result: 在ImgEdit和GEdit基准测试中，该方法匹配或超越了参数更多、推理成本更高的基线模型，尤其在保持输入图像的编辑任务上表现突出。模型在24GB GPU内存内运行，生成2K分辨率图像约4秒。

Conclusion: 该论文提出了一种紧凑、高吞吐量的基于指令的图像编辑流程，使用较小的模型（Qwen3-VL和Sana1.5）在保持高质量的同时实现了低成本和严格源一致性。

Abstract: Instruction-based image editing is among the fastest developing areas in generative AI. Over the past year, the field has reached a new level, with dozens of open-source models released alongside highly capable commercial systems. However, only a limited number of open-source approaches currently achieve real-world quality. In addition, diffusion backbones, the dominant choice for these pipelines, are often large and computationally expensive for many deployments and research settings, with widely used variants typically containing 6B to 20B parameters. This paper presents a compact, high-throughput instruction-based image editing pipeline that uses a modern 2B-parameter Qwen3-VL model to guide the editing process and the 1.6B-parameter diffusion model Sana1.5 for image generation. Our design decisions across architecture, data processing, training configuration, and evaluation target low-cost inference and strict source consistency while maintaining high quality across the major edit categories feasible at this scale. Evaluated on the ImgEdit and GEdit benchmarks, the proposed method matches or exceeds the performance of substantially heavier baselines, including models with several times as many parameters and higher inference cost, and is particularly strong on edits that require preserving the input image, such as an attribute adjustment, object removal, background edits, and targeted replacement. The model fits within 24 GB of GPU memory and generates edited images at up to 2K resolution in approximately 4 seconds on an NVIDIA H100 in BF16, without additional inference optimizations or distillation.

</details>


### [124] [Agentic AI in Remote Sensing: Foundations, Taxonomy, and Emerging Systems](https://arxiv.org/abs/2601.01891)
*Niloufar Alipour Talemi,Julia Boone,Fatemeh Afghah*

Main category: cs.CV

TL;DR: 本文综述了遥感领域代理AI的发展，提出了分类法和架构分析，并指出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 地球观测分析范式正从静态深度学习模型转向自主代理AI，但现有视觉基础模型和多模态大语言模型在复杂地理空间工作流中缺乏顺序规划和主动工具协调能力。

Method: 介绍了区分单智能体协作者和多智能体系统的统一分类法，并分析了规划机制、检索增强生成和记忆结构等架构基础。

Result: 综述了遥感领域中代理AI的首次全面回顾，并评估了从像素级精度到轨迹感知推理正确性的新兴基准。

Conclusion: 本文概述了稳健、自主地理空间智能发展的战略路线图。

Abstract: The paradigm of Earth Observation analysis is shifting from static deep learning models to autonomous agentic AI. Although recent vision foundation models and multimodal large language models advance representation learning, they often lack the sequential planning and active tool orchestration required for complex geospatial workflows. This survey presents the first comprehensive review of agentic AI in remote sensing. We introduce a unified taxonomy distinguishing between single-agent copilots and multi-agent systems while analyzing architectural foundations such as planning mechanisms, retrieval-augmented generation, and memory structures. Furthermore, we review emerging benchmarks that move the evaluation from pixel-level accuracy to trajectory-aware reasoning correctness. By critically examining limitations in grounding, safety, and orchestration, this work outlines a strategic roadmap for the development of robust, autonomous geospatial intelligence.

</details>


### [125] [A Comparative Study of Custom CNNs, Pre-trained Models, and Transfer Learning Across Multiple Visual Datasets](https://arxiv.org/abs/2601.02246)
*Annoor Sharara Akhand*

Main category: cs.CV

TL;DR: 比较三种CNN训练范式，迁移学习表现最佳，定制CNN在效率与准确性上平衡较好。


<details>
  <summary>Details</summary>
Motivation: 比较不同CNN训练范式在实际应用中的表现，为实践者提供选择依据。

Method: 对三种CNN训练范式（定制CNN训练、预训练CNN固定特征提取器、迁移学习）在五个真实世界图像分类数据集上进行了对比评估。

Result: 迁移学习在准确率和宏F1分数上表现最佳，定制CNN在效率和准确性之间提供了良好的平衡。

Conclusion: 迁移学习在预测性能上表现最佳，而定制CNN在计算和内存预算有限时提供了效率与准确性的良好平衡。

Abstract: Convolutional Neural Networks (CNNs) are a standard approach for visual recognition due to their capacity to learn hierarchical representations from raw pixels. In practice, practitioners often choose among (i) training a compact custom CNN from scratch, (ii) using a large pre-trained CNN as a fixed feature extractor, and (iii) performing transfer learning via partial or full fine-tuning of a pre-trained backbone. This report presents a controlled comparison of these three paradigms across five real-world image classification datasets spanning road-surface defect recognition, agricultural variety identification, fruit/leaf disease recognition, pedestrian walkway encroachment recognition, and unauthorized vehicle recognition. Models are evaluated using accuracy and macro F1-score, complemented by efficiency metrics including training time per epoch and parameter counts. The results show that transfer learning consistently yields the strongest predictive performance, while the custom CNN provides an attractive efficiency--accuracy trade-off, especially when compute and memory budgets are constrained.

</details>


### [126] [Forget Less by Learning from Parents Through Hierarchical Relationships](https://arxiv.org/abs/2601.01892)
*Arjun Ramesh Kaushik,Naresh Kumar Devulapally,Vishnu Suresh Lokhande,Nalini K. Ratha,Venu Govindaraju*

Main category: cs.CV

TL;DR: FLLP是一种在双曲空间中通过父子概念学习机制缓解灾难性遗忘的新框架，实验证明其有效提升了模型的鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注最小化概念间的干扰，忽略了概念间可能的积极互动，因此需要一种新方法来保留先验知识并支持新概念的持续学习。

Method: 提出了FLLP框架，利用双曲空间（Lorentzian流形）中的父子概念学习机制，通过已学习概念指导新概念的适应，实现知识的持续整合。

Result: 在三个公共数据集和一个合成基准上验证了FLLP的鲁棒性和泛化能力，显示出一致的改进。

Conclusion: FLLP框架通过在双曲空间中引入父子概念学习机制，有效缓解了灾难性遗忘问题，并在多个数据集上验证了其鲁棒性和泛化能力的提升。

Abstract: Custom Diffusion Models (CDMs) offer impressive capabilities for personalization in generative modeling, yet they remain vulnerable to catastrophic forgetting when learning new concepts sequentially. Existing approaches primarily focus on minimizing interference between concepts, often neglecting the potential for positive inter-concept interactions. In this work, we present Forget Less by Learning from Parents (FLLP), a novel framework that introduces a parent-child inter-concept learning mechanism in hyperbolic space to mitigate forgetting. By embedding concept representations within a Lorentzian manifold, naturally suited to modeling tree-like hierarchies, we define parent-child relationships in which previously learned concepts serve as guidance for adapting to new ones. Our method not only preserves prior knowledge but also supports continual integration of new concepts. We validate FLLP on three public datasets and one synthetic benchmark, showing consistent improvements in both robustness and generalization.

</details>


### [127] [TopoLoRA-SAM: Topology-Aware Parameter-Efficient Adaptation of Foundation Segmenters for Thin-Structure and Cross-Domain Binary Semantic Segmentation](https://arxiv.org/abs/2601.02273)
*Salim Khazem*

Main category: cs.CV

TL;DR: TopoLoRA-SAM是一种拓扑感知的参数高效适应框架，用于改进SAM在特定领域的分割性能，仅需少量参数训练即可超越全微调模型。


<details>
  <summary>Details</summary>
Motivation: 解决基础分割模型（如SAM）在特定领域语义分割（尤其是薄结构和噪声模态）中的适应性问题，同时避免全微调的计算成本和灾难性遗忘风险。

Method: 提出了TopoLoRA-SAM框架，结合了低秩适应（LoRA）、轻量级空间卷积适配器和可微分clDice的拓扑感知监督。

Result: 在五个基准测试中（包括视网膜血管分割、息肉分割和SAR海陆分割），TopoLoRA-SAM实现了最佳的平均Dice分数，且仅训练了5.2%的模型参数。

Conclusion: TopoLoRA-SAM通过拓扑感知和参数高效的适应框架，在多个数据集上实现了最佳分割性能，同时仅训练了少量参数，证明了其在薄结构和噪声模态上的优越性。

Abstract: Foundation segmentation models such as the Segment Anything Model (SAM) exhibit strong zero-shot generalization through large-scale pretraining, but adapting them to domain-specific semantic segmentation remains challenging, particularly for thin structures (e.g., retinal vessels) and noisy modalities (e.g., SAR imagery). Full fine-tuning is computationally expensive and risks catastrophic forgetting. We propose \textbf{TopoLoRA-SAM}, a topology-aware and parameter-efficient adaptation framework for binary semantic segmentation. TopoLoRA-SAM injects Low-Rank Adaptation (LoRA) into the frozen ViT encoder, augmented with a lightweight spatial convolutional adapter and optional topology-aware supervision via differentiable clDice. We evaluate our approach on five benchmarks spanning retinal vessel segmentation (DRIVE, STARE, CHASE\_DB1), polyp segmentation (Kvasir-SEG), and SAR sea/land segmentation (SL-SSDD), comparing against U-Net, DeepLabV3+, SegFormer, and Mask2Former. TopoLoRA-SAM achieves the best retina-average Dice and the best overall average Dice across datasets, while training only \textbf{5.2\%} of model parameters ($\sim$4.9M). On the challenging CHASE\_DB1 dataset, our method substantially improves segmentation accuracy and robustness, demonstrating that topology-aware parameter-efficient adaptation can match or exceed fully fine-tuned specialist models. Code is available at : https://github.com/salimkhazem/Seglab.git

</details>


### [128] [Learning Action Hierarchies via Hybrid Geometric Diffusion](https://arxiv.org/abs/2601.01914)
*Arjun Ramesh Kaushik,Nalini K. Ratha,Venu Govindaraju*

Main category: cs.CV

TL;DR: HybridTAS通过结合欧几里得和双曲几何，利用动作的层次结构改进扩散模型的去噪过程，在多个数据集上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于迭代优化的方法未能充分利用人类动作的层次结构，因此需要一种能显式利用这种结构的创新方法。

Method: 提出HybridTAS框架，将欧几里得和双曲几何结合到扩散模型的去噪过程中，利用双曲几何的树状关系从粗到细指导动作标签的去噪过程。

Result: 在GTEA、50Salads和Breakfast三个基准数据集上实现了最先进的性能。

Conclusion: HybridTAS框架通过结合欧几里得和双曲几何，在扩散模型的去噪过程中利用动作的层次结构，显著提升了时间动作分割任务的性能，并在多个基准数据集上达到了最先进水平。

Abstract: Temporal action segmentation is a critical task in video understanding, where the goal is to assign action labels to each frame in a video. While recent advances leverage iterative refinement-based strategies, they fail to explicitly utilize the hierarchical nature of human actions. In this work, we propose HybridTAS - a novel framework that incorporates a hybrid of Euclidean and hyperbolic geometries into the denoising process of diffusion models to exploit the hierarchical structure of actions. Hyperbolic geometry naturally provides tree-like relationships between embeddings, enabling us to guide the action label denoising process in a coarse-to-fine manner: higher diffusion timesteps are influenced by abstract, high-level action categories (root nodes), while lower timesteps are refined using fine-grained action classes (leaf nodes). Extensive experiments on three benchmark datasets, GTEA, 50Salads, and Breakfast, demonstrate that our method achieves state-of-the-art performance, validating the effectiveness of hyperbolic-guided denoising for the temporal action segmentation task.

</details>


### [129] [TalkPhoto: A Versatile Training-Free Conversational Assistant for Intelligent Image Editing](https://arxiv.org/abs/2601.01915)
*Yujie Hu,Zecheng Tang,Xu Jiang,Weiqi Li,Jian Zhang*

Main category: cs.CV

TL;DR: TalkPhoto 是一个免训练的通用图像编辑框架，通过对话交互实现精确编辑，无需额外训练即可调用现有方法，效果优于传统多指令训练方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于指令的图像编辑方法需要构建多指令数据集进行训练，耗时耗力且效果不佳。

Method: 使用开源 LLM 和专门设计的提示模板，分层调用现有高级编辑方法，无需额外训练。

Result: 实验表明，TalkPhoto 在多种图像编辑任务中实现了更高的编辑质量和更低的 token 消耗。

Conclusion: TalkPhoto 框架通过免训练的方式实现了高质量的图像编辑，展示了在多任务编辑中的优越性和灵活性。

Abstract: Thanks to the powerful language comprehension capabilities of Large Language Models (LLMs), existing instruction-based image editing methods have introduced Multimodal Large Language Models (MLLMs) to promote information exchange between instructions and images, ensuring the controllability and flexibility of image editing. However, these frameworks often build a multi-instruction dataset to train the model to handle multiple editing tasks, which is not only time-consuming and labor-intensive but also fails to achieve satisfactory results. In this paper, we present TalkPhoto, a versatile training-free image editing framework that facilitates precise image manipulation through conversational interaction. We instruct the open-source LLM with a specially designed prompt template to analyze user needs after receiving instructions and hierarchically invoke existing advanced editing methods, all without additional training. Moreover, we implement a plug-and-play and efficient invocation of image editing methods, allowing complex and unseen editing tasks to be integrated into the current framework, achieving stable and high-quality editing results. Extensive experiments demonstrate that our method not only provides more accurate invocation with fewer token consumption but also achieves higher editing quality across various image editing tasks.

</details>


### [130] [AR-MOT: Autoregressive Multi-object Tracking](https://arxiv.org/abs/2601.01925)
*Lianjie Jia,Yuhan Wu,Binghao Ran,Yifan Wang,Lijun Wang,Huchuan Lu*

Main category: cs.CV

TL;DR: AR-MOT是一种基于LLM的自回归多目标跟踪方法，通过序列生成实现灵活跟踪，性能媲美现有最优方法。


<details>
  <summary>Details</summary>
Motivation: 现有MOT方法架构僵化且任务特定，难以适应多样化任务和新跟踪场景。

Method: 提出AR-MOT，一种基于LLM的自回归范式，将MOT任务转化为序列生成问题，并引入Object Tokenizer、RAA模块和TMF模块。

Result: 在MOT17和DanceTrack上的实验验证了方法的可行性，性能与现有最优方法相当。

Conclusion: AR-MOT通过自回归范式在LLM框架中实现MOT任务，展示了与现有方法相当的性能，并为更通用和灵活的MOT系统奠定了基础。

Abstract: As multi-object tracking (MOT) tasks continue to evolve toward more general and multi-modal scenarios, the rigid and task-specific architectures of existing MOT methods increasingly hinder their applicability across diverse tasks and limit flexibility in adapting to new tracking formulations. Most approaches rely on fixed output heads and bespoke tracking pipelines, making them difficult to extend to more complex or instruction-driven tasks. To address these limitations, we propose AR-MOT, a novel autoregressive paradigm that formulates MOT as a sequence generation task within a large language model (LLM) framework. This design enables the model to output structured results through flexible sequence construction, without requiring any task-specific heads. To enhance region-level visual perception, we introduce an Object Tokenizer based on a pretrained detector. To mitigate the misalignment between global and regional features, we propose a Region-Aware Alignment (RAA) module, and to support long-term tracking, we design a Temporal Memory Fusion (TMF) module that caches historical object tokens. AR-MOT offers strong potential for extensibility, as new modalities or instructions can be integrated by simply modifying the output sequence format without altering the model architecture. Extensive experiments on MOT17 and DanceTrack validate the feasibility of our approach, achieving performance comparable to state-of-the-art methods while laying the foundation for more general and flexible MOT systems.

</details>


### [131] [MacVQA: Adaptive Memory Allocation and Global Noise Filtering for Continual Visual Question Answering](https://arxiv.org/abs/2601.01926)
*Zhifei Li,Yiran Wang,Chenyi Xiong,Yujing Xia,Xiaoju Hou,Yue Zhao,Miao Zhang,Kui Xiao,Bing Yang*

Main category: cs.CV

TL;DR: MacVQA是一种新型持续VQA框架，通过自适应内存和噪声过滤优化性能，实验表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前方法在持续学习中难以平衡知识保留、适应和鲁棒特征表示，MacVQA旨在解决这些挑战。

Method: 提出了一种名为MacVQA的新框架，融合视觉和问题信息并过滤噪声，采用基于原型的记忆分配优化特征质量和内存使用。

Result: 在十个持续VQA任务中，MacVQA平均准确率为43.38%，平均遗忘率为2.32%；在新组合任务中，平均准确率为42.53%，平均遗忘率为3.60%。

Conclusion: MacVQA通过自适应内存分配和全局噪声过滤，在持续视觉问答学习中平衡了知识获取、保留和组合泛化，显著优于现有基线方法。

Abstract: Visual Question Answering (VQA) requires models to reason over multimodal information, combining visual and textual data. With the development of continual learning, significant progress has been made in retaining knowledge and adapting to new information in the VQA domain. However, current methods often struggle with balancing knowledge retention, adaptation, and robust feature representation. To address these challenges, we propose a novel framework with adaptive memory allocation and global noise filtering called MacVQA for visual question answering. MacVQA fuses visual and question information while filtering noise to ensure robust representations, and employs prototype-based memory allocation to optimize feature quality and memory usage. These designs enable MacVQA to balance knowledge acquisition, retention, and compositional generalization in continual VQA learning. Experiments on ten continual VQA tasks show that MacVQA outperforms existing baselines, achieving 43.38% average accuracy and 2.32% average forgetting on standard tasks, and 42.53% average accuracy and 3.60% average forgetting on novel composition tasks.

</details>


### [132] [Face Normal Estimation from Rags to Riches](https://arxiv.org/abs/2601.01950)
*Meng Wang,Wenjing Dai,Jiawan Zhang,Xiaojie Guo*

Main category: cs.CV

TL;DR: 该论文提出了一种从粗到细的面部法线估计方法，通过自注意力机制和细化网络减少对大规模数据的需求，实验证明其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有面部法线估计方法依赖于大规模配对数据进行训练，本文旨在通过开发从粗到细的估计器来缓解这一需求。

Method: 首先使用小数据集训练一个简洁模型生成粗糙的面部法线（称为示例），然后通过自注意力机制捕捉长距离依赖关系以修复局部伪影，最后定制细化网络将输入图像与示例映射到高质量的面部法线。

Result: 实验和消融研究表明，该方法在训练成本和估计质量上均优于现有技术。

Conclusion: 该论文提出了一种从粗到细的面部法线估计方法，显著减少了对大规模配对数据和计算资源的需求，并在实验中证明了其设计的有效性和优越性。

Abstract: Although recent approaches to face normal estimation have achieved promising results, their effectiveness heavily depends on large-scale paired data for training. This paper concentrates on relieving this requirement via developing a coarse-to-fine normal estimator. Concretely, our method first trains a neat model from a small dataset to produce coarse face normals that perform as guidance (called exemplars) for the following refinement. A self-attention mechanism is employed to capture long-range dependencies, thus remedying severe local artifacts left in estimated coarse facial normals. Then, a refinement network is customized for the sake of mapping input face images together with corresponding exemplars to fine-grained high-quality facial normals. Such a logical function split can significantly cut the requirement of massive paired data and computational resource. Extensive experiments and ablation studies are conducted to demonstrate the efficacy of our design and reveal its superiority over state-of-the-art methods in terms of both training expense as well as estimation quality. Our code and models are open-sourced at: https://github.com/AutoHDR/FNR2R.git.

</details>


### [133] [MotionAdapter: Video Motion Transfer via Content-Aware Attention Customization](https://arxiv.org/abs/2601.01955)
*Zhexin Zhang,Yifeng Zhu,Yangyang Xu,Long Chen,Yong Du,Shengfeng He,Jun Yu*

Main category: cs.CV

TL;DR: MotionAdapter是一个内容感知的运动迁移框架，通过解耦运动与外观并定制运动场，显著提升了DiT-based T2V模型的运动迁移效果。


<details>
  <summary>Details</summary>
Motivation: 尽管基于扩散的文本到视频模型在生成高质量视频方面取得了显著进展，但视频间复杂运动的迁移仍具挑战性。

Method: MotionAdapter首先通过分析3D全注意力模块中的跨帧注意力来提取运动场，然后利用DINO引导的运动定制模块根据内容对应关系重新排列和优化运动场，最终指导DiT去噪过程。

Result: 实验表明，MotionAdapter在定性和定量评估中均优于现有方法，并能自然支持复杂运动迁移和编辑任务。

Conclusion: MotionAdapter通过显式解耦运动与外观，并引入DINO引导的运动定制模块，成功实现了在DiT-based T2V模型中的高效运动迁移，显著优于现有方法。

Abstract: Recent advances in diffusion-based text-to-video models, particularly those built on the diffusion transformer architecture, have achieved remarkable progress in generating high-quality and temporally coherent videos. However, transferring complex motions between videos remains challenging. In this work, we present MotionAdapter, a content-aware motion transfer framework that enables robust and semantically aligned motion transfer within DiT-based T2V models. Our key insight is that effective motion transfer requires \romannumeral1) explicit disentanglement of motion from appearance and \romannumeral 2) adaptive customization of motion to target content. MotionAdapter first isolates motion by analyzing cross-frame attention within 3D full-attention modules to extract attention-derived motion fields. To bridge the semantic gap between reference and target videos, we further introduce a DINO-guided motion customization module that rearranges and refines motion fields based on content correspondences. The customized motion field is then used to guide the DiT denoising process, ensuring that the synthesized video inherits the reference motion while preserving target appearance and semantics. Extensive experiments demonstrate that MotionAdapter outperforms state-of-the-art methods in both qualitative and quantitative evaluations. Moreover, MotionAdapter naturally supports complex motion transfer and motion editing tasks such as zooming.

</details>


### [134] [AFTER: Mitigating the Object Hallucination of LVLM via Adaptive Factual-Guided Activation Editing](https://arxiv.org/abs/2601.01957)
*Tianbo Wang,Yuqing Ma,Kewei Liao,Zhange Zhang,Simin Li,Jinyang Guo,Xianglong Liu*

Main category: cs.CV

TL;DR: AFTER方法通过事实引导的视觉-文本编辑，有效减少LVLMs中的对象幻觉，实验显示显著效果。


<details>
  <summary>Details</summary>
Motivation: LVLMs由于语言偏差易产生对象幻觉，阻碍可信AI应用。现有编辑方法忽视事实文本语义的指导，难以显式缓解语言偏差。

Method: AFTER方法包含FAS和QAO两个模块，FAS提供事实和通用指导以编辑激活，QAO则引入查询感知偏移估计器以增强编辑的多样性和细粒度。

Result: AFTER在多个LVLMs上验证有效，特别是在AMBER基准上实现了16.3%的幻觉减少。

Conclusion: AFTER方法通过Factual-Augmented Activation Steering (FAS)和Query-Adaptive Offset Optimization (QAO)有效减少了LVLMs中的幻觉问题，实验证明其在多个基准测试中显著降低了幻觉现象。

Abstract: Large Vision-Language Models (LVLMs) have achieved substantial progress in cross-modal tasks. However, due to language bias, LVLMs are susceptible to object hallucination, which can be primarily divided into category, attribute, and relation hallucination, significantly impeding the trustworthy AI applications. Editing the internal activations of LVLMs has shown promising effectiveness in mitigating hallucinations with minimal cost. However, previous editing approaches neglect the effective guidance offered by factual textual semantics, thereby struggling to explicitly mitigate language bias. To address these issues, we propose Adaptive Factual-guided Visual-Textual Editing for hallucination mitigation (AFTER), which comprises Factual-Augmented Activation Steering (FAS) and Query-Adaptive Offset Optimization (QAO), to adaptively guides the original biased activations towards factual semantics. Specifically, FAS is proposed to provide factual and general guidance for activation editing, thereby explicitly modeling the precise visual-textual associations. Subsequently, QAO introduces a query-aware offset estimator to establish query-specific editing from the general steering vector, enhancing the diversity and granularity of editing. Extensive experiments on standard hallucination benchmarks across three widely adopted LVLMs validate the efficacy of the proposed AFTER, notably achieving up to a 16.3% reduction of hallucination over baseline on the AMBER benchmark. Our code and data will be released for reproducibility.

</details>


### [135] [Forget Less by Learning Together through Concept Consolidation](https://arxiv.org/abs/2601.01963)
*Arjun Ramesh Kaushik,Naresh Kumar Devulapally,Vishnu Suresh Lokhande,Nalini Ratha,Venu Govindaraju*

Main category: cs.CV

TL;DR: FL2T框架通过跨概念学习模块解决了CDMs的灾难性遗忘问题，实验显示其显著提升了概念保留和新概念整合效果。


<details>
  <summary>Details</summary>
Motivation: 现有CDMs在持续学习新概念时存在灾难性遗忘问题，且多数研究忽略了概念间的交互作用。FL2T旨在实现并发且顺序无关的概念学习，同时解决遗忘问题。

Method: 提出了一种新颖的框架FL2T，包含一个集合不变性的跨概念学习模块，通过代理指导跨概念的特征选择，优化知识保留和转移。

Result: 在三个数据集上的实验表明，FL2T显著提高了概念保留率，平均CLIP图像对齐分数至少提升了2%。

Conclusion: FL2T框架通过引入跨概念学习模块，有效解决了CDMs在持续学习中的灾难性遗忘问题，显著提升了概念保留和新概念整合的能力。

Abstract: Custom Diffusion Models (CDMs) have gained significant attention due to their remarkable ability to personalize generative processes. However, existing CDMs suffer from catastrophic forgetting when continuously learning new concepts. Most prior works attempt to mitigate this issue under the sequential learning setting with a fixed order of concept inflow and neglect inter-concept interactions. In this paper, we propose a novel framework - Forget Less by Learning Together (FL2T) - that enables concurrent and order-agnostic concept learning while addressing catastrophic forgetting. Specifically, we introduce a set-invariant inter-concept learning module where proxies guide feature selection across concepts, facilitating improved knowledge retention and transfer. By leveraging inter-concept guidance, our approach preserves old concepts while efficiently incorporating new ones. Extensive experiments, across three datasets, demonstrates that our method significantly improves concept retention and mitigates catastrophic forgetting, highlighting the effectiveness of inter-concept catalytic behavior in incremental concept learning of ten tasks with at least 2% gain on average CLIP Image Alignment scores.

</details>


### [136] [Thinking with Blueprints: Assisting Vision-Language Models in Spatial Reasoning via Structured Object Representation](https://arxiv.org/abs/2601.01984)
*Weijian Ma,Shizhao Sun,Tianyu Yu,Ruiyu Wang,Tat-Seng Chua,Jiang Bian*

Main category: cs.CV

TL;DR: 论文提出了一种结合对象蓝图和三种技术的方法，显著提升视觉语言模型的空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法在空间推理中要么过于局部化，要么忽视对象间的整体组织，因此需要一种更全面的解决方案。

Method: 1. 蓝图嵌入推理轨迹用于监督微调；2. 蓝图感知奖励在强化学习中鼓励因果对齐；3. 抗捷径数据增强以规避表面线索依赖。

Result: 实验表明，该方法在空间推理任务上优于现有视觉语言模型和专用模型。

Conclusion: 该论文通过引入对象为中心的空间蓝图概念，结合三种关键技术，显著提升了视觉语言模型的空间推理能力，并在实验中优于现有方法。

Abstract: Spatial reasoning -- the ability to perceive and reason about relationships in space -- advances vision-language models (VLMs) from visual perception toward spatial semantic understanding. Existing approaches either revisit local image patches, improving fine-grained perception but weakening global spatial awareness, or mark isolated coordinates, which capture object locations but overlook their overall organization. In this work, we integrate the cognitive concept of an object-centric blueprint into VLMs to enhance spatial reasoning. Given an image and a question, the model first constructs a JSON-style blueprint that records the positions, sizes, and attributes of relevant objects, and then reasons over this structured representation to produce the final answer. To achieve this, we introduce three key techniques: (1) blueprint-embedded reasoning traces for supervised fine-tuning to elicit basic reasoning skills; (2) blueprint-aware rewards in reinforcement learning to encourage the blueprint to include an appropriate number of objects and to align final answers with this causal reasoning; and (3) anti-shortcut data augmentation that applies targeted perturbations to images and questions, discouraging reliance on superficial visual or linguistic cues. Experiments show that our method consistently outperforms existing VLMs and specialized spatial reasoning models.

</details>


### [137] [API: Empowering Generalizable Real-World Image Dehazing via Adaptive Patch Importance Learning](https://arxiv.org/abs/2601.01992)
*Chen Zhu,Huiwen Zhang,Yujie Li,Mu He,Xiaotian Qiao*

Main category: cs.CV

TL;DR: 该论文提出了一种自适应补丁重要性感知（API）框架，通过混合数据增强和多负对比损失，显著提升了真实世界图像去雾的性能和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有学习方法在复杂真实世界雾霾场景中性能下降明显，主要由于训练数据有限和雾密度分布的内在复杂性。

Method: API框架包含自动雾生成（AHG）模块和密度感知雾去除（DHR）模块，结合多负对比去雾（MNCD）损失函数，实现了对复杂雾密度分布的适应性处理。

Result: 实验表明，该框架在多个真实世界基准测试中取得了最先进的性能，定量指标和定性视觉质量均表现出色，并展现出对不同雾分布的强鲁棒性。

Conclusion: 该论文提出的API框架通过自适应补丁重要性感知和混合数据增强策略，显著提升了真实世界图像去雾任务的性能，并在多个基准测试中达到了最先进的水平。

Abstract: Real-world image dehazing is a fundamental yet challenging task in low-level vision. Existing learning-based methods often suffer from significant performance degradation when applied to complex real-world hazy scenes, primarily due to limited training data and the intrinsic complexity of haze density distributions.To address these challenges, we introduce a novel Adaptive Patch Importance-aware (API) framework for generalizable real-world image dehazing. Specifically, our framework consists of an Automatic Haze Generation (AHG) module and a Density-aware Haze Removal (DHR) module. AHG provides a hybrid data augmentation strategy by generating realistic and diverse hazy images as additional high-quality training data. DHR considers hazy regions with varying haze density distributions for generalizable real-world image dehazing in an adaptive patch importance-aware manner. To alleviate the ambiguity of the dehazed image details, we further introduce a new Multi-Negative Contrastive Dehazing (MNCD) loss, which fully utilizes information from multiple negative samples across both spatial and frequency domains. Extensive experiments demonstrate that our framework achieves state-of-the-art performance across multiple real-world benchmarks, delivering strong results in both quantitative metrics and qualitative visual quality, and exhibiting robust generalization across diverse haze distributions.

</details>


### [138] [Nighttime Hazy Image Enhancement via Progressively and Mutually Reinforcing Night-Haze Priors](https://arxiv.org/abs/2601.01998)
*Chen Zhu,Huiwen Zhang,Mu He,Yujie Li,Xiaotian Qiao*

Main category: cs.CV

TL;DR: 该论文提出了一种新型框架，通过强化雾霾和低光先验之间的内在一致性，显著提升了夜间雾霾图像的可见度，并在多种任务中展示了良好的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常单独处理单一类型的退化（如雾霾或低光），忽略了不同类型退化之间的相互作用，导致可见度提升有限。本文观察到低光和雾霾先验之间的共享领域知识可以相互强化以提升可见度。

Method: 模型利用图像、块和像素级别的专家，在视觉和频率域中逐步恢复全局场景结构、区域模式和细粒度细节，并通过频率感知路由器自适应引导每个专家的贡献。

Result: 大量实验证明，该模型在夜间去雾基准测试中在定量和定性上均表现出色，并在白天去雾和低光增强任务中展示了良好的泛化能力。

Conclusion: 该论文提出的新型框架通过强化雾霾和低光先验之间的内在一致性，显著提升了夜间雾霾图像的可见度，并在白天去雾和低光增强任务中展示了良好的泛化能力。

Abstract: Enhancing the visibility of nighttime hazy images is challenging due to the complex degradation distributions. Existing methods mainly address a single type of degradation (e.g., haze or low-light) at a time, ignoring the interplay of different degradation types and resulting in limited visibility improvement. We observe that the domain knowledge shared between low-light and haze priors can be reinforced mutually for better visibility. Based on this key insight, in this paper, we propose a novel framework that enhances visibility in nighttime hazy images by reinforcing the intrinsic consistency between haze and low-light priors mutually and progressively. In particular, our model utilizes image-, patch-, and pixel-level experts that operate across visual and frequency domains to recover global scene structure, regional patterns, and fine-grained details progressively. A frequency-aware router is further introduced to adaptively guide the contribution of each expert, ensuring robust image restoration. Extensive experiments demonstrate the superior performance of our model on nighttime dehazing benchmarks both quantitatively and qualitatively. Moreover, we showcase the generalizability of our model in daytime dehazing and low-light enhancement tasks.

</details>


### [139] [Towards Any-Quality Image Segmentation via Generative and Adaptive Latent Space Enhancement](https://arxiv.org/abs/2601.02018)
*Guangqian Guo,Aixi Ren,Yong Guo,Xuehui Yu,Jiacheng Tian,Wenli Li,Yaoxing Wang,Shan Gao*

Main category: cs.CV

TL;DR: GleSAM++通过生成潜在空间增强和退化感知自适应机制，显著提升了SAMs在低质量图像上的分割性能，同时保持泛化能力。


<details>
  <summary>Details</summary>
Motivation: 针对SAMs在严重退化、低质量图像上性能显著下降的问题，旨在提升其在真实场景中的有效性。

Method: 提出了GleSAM++，利用Generative Latent space Enhancement增强低质量图像的鲁棒性，并引入Feature Distribution Alignment (FDA)和Channel Replication and Expansion (CRE)技术以提升预训练扩散模型与分割框架的兼容性。进一步提出了DAE机制，将任意质量特征的重构过程解耦为退化级别预测和退化感知重构两个阶段。

Result: 大量实验表明，GleSAM++在复杂退化图像上的分割鲁棒性显著提升，同时保持了在清晰图像上的泛化能力，并在未见过的退化类型上表现良好。

Conclusion: GleSAM++通过引入Degradation-aware Adaptive Enhancement (DAE)机制，显著提升了在复杂退化图像上的分割鲁棒性，同时保持了在清晰图像上的泛化能力，并在未见过的退化类型上表现良好。

Abstract: Segment Anything Models (SAMs), known for their exceptional zero-shot segmentation performance, have garnered significant attention in the research community. Nevertheless, their performance drops significantly on severely degraded, low-quality images, limiting their effectiveness in real-world scenarios. To address this, we propose GleSAM++, which utilizes Generative Latent space Enhancement to boost robustness on low-quality images, thus enabling generalization across various image qualities. Additionally, to improve compatibility between the pre-trained diffusion model and the segmentation framework, we introduce two techniques, i.e., Feature Distribution Alignment (FDA) and Channel Replication and Expansion (CRE). However, the above components lack explicit guidance regarding the degree of degradation. The model is forced to implicitly fit a complex noise distribution that spans conditions from mild noise to severe artifacts, which substantially increases the learning burden and leads to suboptimal reconstructions. To address this issue, we further introduce a Degradation-aware Adaptive Enhancement (DAE) mechanism. The key principle of DAE is to decouple the reconstruction process for arbitrary-quality features into two stages: degradation-level prediction and degradation-aware reconstruction. Our method can be applied to pre-trained SAM and SAM2 with only minimal additional learnable parameters, allowing for efficient optimization. Extensive experiments demonstrate that GleSAM++ significantly improves segmentation robustness on complex degradations while maintaining generalization to clear images. Furthermore, GleSAM++ also performs well on unseen degradations, underscoring the versatility of our approach and dataset.

</details>


### [140] [Adapting Depth Anything to Adverse Imaging Conditions with Events](https://arxiv.org/abs/2601.02020)
*Shihan Peng,Yuyang Xiong,Hanyu Zhou,Zhiwei Shi,Haoyue Liu,Gang Chen,Luxin Yan,Yi Chang*

Main category: cs.CV

TL;DR: ADAE通过事件相机增强Depth Anything，在恶劣光照和运动模糊条件下提升深度估计性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度基础模型在理想场景中表现优异，但在极端光照和运动模糊等恶劣条件下性能下降，ADAE旨在通过事件相机的高动态范围和时间分辨率来补偿这些退化。

Method: ADAE框架采用熵感知空间融合和运动引导时间校正两种策略，分别处理光照引起的退化和运动模糊区域的特征模糊问题。

Result: 大量实验验证了ADAE方法的优越性，表明其在恶劣成像条件下能有效提升深度估计的鲁棒性。

Conclusion: ADAE框架成功增强了Depth Anything在恶劣成像条件下的深度估计能力，通过熵感知空间融合和运动引导时间校正的互补设计，实现了对现有基础模型的继承与扩展。

Abstract: Robust depth estimation under dynamic and adverse lighting conditions is essential for robotic systems. Currently, depth foundation models, such as Depth Anything, achieve great success in ideal scenes but remain challenging under adverse imaging conditions such as extreme illumination and motion blur. These degradations corrupt the visual signals of frame cameras, weakening the discriminative features of frame-based depths across the spatial and temporal dimensions. Typically, existing approaches incorporate event cameras to leverage their high dynamic range and temporal resolution, aiming to compensate for corrupted frame features. However, such specialized fusion models are predominantly trained from scratch on domain-specific datasets, thereby failing to inherit the open-world knowledge and robust generalization inherent to foundation models. In this work, we propose ADAE, an event-guided spatiotemporal fusion framework for Depth Anything in degraded scenes. Our design is guided by two key insights: 1) Entropy-Aware Spatial Fusion. We adaptively merge frame-based and event-based features using an information entropy strategy to indicate illumination-induced degradation. 2) Motion-Guided Temporal Correction. We resort to the event-based motion cue to recalibrate ambiguous features in blurred regions. Under our unified framework, the two components are complementary to each other and jointly enhance Depth Anything under adverse imaging conditions. Extensive experiments have been performed to verify the superiority of the proposed method. Our code will be released upon acceptance.

</details>


### [141] [Leveraging 2D-VLM for Label-Free 3D Segmentation in Large-Scale Outdoor Scene Understanding](https://arxiv.org/abs/2601.02029)
*Toshihiko Nishimura,Hirofumi Abe,Kazuhiko Murasaki,Taiga Yoshida,Ryuichi Tanida*

Main category: cs.CV

TL;DR: 无需标注3D数据或RGB图像，通过虚拟相机和自然语言提示实现3D点云语义分割，准确度媲美监督方法，支持开放词汇识别。


<details>
  <summary>Details</summary>
Motivation: 解决大规模点云数据3D语义分割中需要标注训练数据或配对RGB图像的限制，同时支持开放词汇识别。

Method: 提出了一种新颖的3D语义分割方法，通过虚拟相机将3D点云投影到2D图像，利用自然语言提示引导的2D基础模型进行分割，并通过加权投票聚合多视角预测。

Result: 该方法在无需训练数据的情况下优于现有无监督方法，分割准确度与监督方法相当，并支持任意文本查询的对象检测。

Conclusion: 该方法通过虚拟相机将3D点云投影到2D图像，并利用自然语言提示引导的2D基础模型进行语义分割，无需标注的3D训练数据或配对的RGB图像，实现了与监督方法相当的准确度，并支持开放词汇识别。

Abstract: This paper presents a novel 3D semantic segmentation method for large-scale point cloud data that does not require annotated 3D training data or paired RGB images. The proposed approach projects 3D point clouds onto 2D images using virtual cameras and performs semantic segmentation via a foundation 2D model guided by natural language prompts. 3D segmentation is achieved by aggregating predictions from multiple viewpoints through weighted voting. Our method outperforms existing training-free approaches and achieves segmentation accuracy comparable to supervised methods. Moreover, it supports open-vocabulary recognition, enabling users to detect objects using arbitrary text queries, thus overcoming the limitations of traditional supervised approaches.

</details>


### [142] [AlignVTOFF: Texture-Spatial Feature Alignment for High-Fidelity Virtual Try-Off](https://arxiv.org/abs/2601.02038)
*Yihan Zhu,Mengying Ge*

Main category: cs.CV

TL;DR: AlignVTOFF通过并行U-Net框架和混合注意力设计，解决了虚拟试衣任务中纹理衰减和结构失真的问题，显著提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法因轻量级模块导致纹理衰减和结构模式丢失，无法满足高频细节和复杂几何变形的需求。

Method: 提出AlignVTOFF框架，包含Reference U-Net进行多尺度特征提取和几何保真，以及TSFA模块通过混合注意力设计注入参考服装特征。

Result: 在多种实验设置下，AlignVTOFF均优于现有方法，生成结果具有更高的结构真实性和高频细节保真度。

Conclusion: AlignVTOFF通过结合Reference U-Net和TSFA模块，显著提升了虚拟试衣（VTOFF）任务中高频细节和结构真实性的生成质量。

Abstract: Virtual Try-Off (VTOFF) is a challenging multimodal image generation task that aims to synthesize high-fidelity flat-lay garments under complex geometric deformation and rich high-frequency textures. Existing methods often rely on lightweight modules for fast feature extraction, which struggles to preserve structured patterns and fine-grained details, leading to texture attenuation during generation.To address these issues, we propose AlignVTOFF, a novel parallel U-Net framework built upon a Reference U-Net and Texture-Spatial Feature Alignment (TSFA). The Reference U-Net performs multi-scale feature extraction and enhances geometric fidelity, enabling robust modeling of deformation while retaining complex structured patterns. TSFA then injects the reference garment features into a frozen denoising U-Net via a hybrid attention design, consisting of a trainable cross-attention module and a frozen self-attention module. This design explicitly aligns texture and spatial cues and alleviates the loss of high-frequency information during the denoising process.Extensive experiments across multiple settings demonstrate that AlignVTOFF consistently outperforms state-of-the-art methods, producing flat-lay garment results with improved structural realism and high-frequency detail fidelity.

</details>


### [143] [PhysSFI-Net: Physics-informed Geometric Learning of Skeletal and Facial Interactions for Orthognathic Surgical Outcome Prediction](https://arxiv.org/abs/2601.02088)
*Jiahao Bao,Huazhen Liu,Yu Zhuang,Leran Tao,Xinyu Xu,Yongtao Shi,Mengjia Cheng,Yiming Wang,Congshuang Ku,Ting Zeng,Yilang Du,Siyi Chen,Shunyao Shen,Suncheng Xiang,Hongbo Yu*

Main category: cs.CV

TL;DR: PhysSFI-Net 是一种物理信息几何深度学习框架，用于精确预测正颌手术后的软组织变形，具有高精度和可解释性，临床潜力显著。


<details>
  <summary>Details</summary>
Motivation: 传统的生物力学模型计算成本高，而几何深度学习方法通常缺乏可解释性。因此，开发一种既能精确预测软组织变形又具有可解释性的方法是必要的。

Method: PhysSFI-Net 包含三个组件：分层图模块（结合颅面和手术计划编码器及注意力机制）、基于 LSTM 的序列预测器和生物力学启发的模块，用于高分辨率面部表面重建。

Result: PhysSFI-Net 的点云形状误差为 1.070 +/- 0.088 mm，表面偏差误差为 1.296 +/- 0.349 mm，标志定位误差为 2.445 +/- 1.326 mm，优于现有方法 ACMT-Net。

Conclusion: PhysSFI-Net 能够以更高的准确度实现可解释、高分辨率的术后面部形态预测，显示出在正颌手术规划和模拟中的临床应用潜力。

Abstract: Orthognathic surgery repositions jaw bones to restore occlusion and enhance facial aesthetics. Accurate simulation of postoperative facial morphology is essential for preoperative planning. However, traditional biomechanical models are computationally expensive, while geometric deep learning approaches often lack interpretability. In this study, we develop and validate a physics-informed geometric deep learning framework named PhysSFI-Net for precise prediction of soft tissue deformation following orthognathic surgery. PhysSFI-Net consists of three components: a hierarchical graph module with craniofacial and surgical plan encoders combined with attention mechanisms to extract skeletal-facial interaction features; a Long Short-Term Memory (LSTM)-based sequential predictor for incremental soft tissue deformation; and a biomechanics-inspired module for high-resolution facial surface reconstruction. Model performance was assessed using point cloud shape error (Hausdorff distance), surface deviation error, and landmark localization error (Euclidean distances of craniomaxillofacial landmarks) between predicted facial shapes and corresponding ground truths. A total of 135 patients who underwent combined orthodontic and orthognathic treatment were included for model training and validation. Quantitative analysis demonstrated that PhysSFI-Net achieved a point cloud shape error of 1.070 +/- 0.088 mm, a surface deviation error of 1.296 +/- 0.349 mm, and a landmark localization error of 2.445 +/- 1.326 mm. Comparative experiments indicated that PhysSFI-Net outperformed the state-of-the-art method ACMT-Net in prediction accuracy. In conclusion, PhysSFI-Net enables interpretable, high-resolution prediction of postoperative facial morphology with superior accuracy, showing strong potential for clinical application in orthognathic surgical planning and simulation.

</details>


### [144] [MCD-Net: A Lightweight Deep Learning Baseline for Optical-Only Moraine Segmentation](https://arxiv.org/abs/2601.02091)
*Zhehuan Cao,Fiseha Berhanu Tesema,Ping Fu,Jianfeng Ren,Ahmed Nasr*

Main category: cs.CV

TL;DR: 该研究提出了首个大规模仅基于光学的冰碛分割数据集，并开发了轻量级模型MCD-Net，在性能与效率上均优于深层骨干网络。


<details>
  <summary>Details</summary>
Motivation: 冰碛分割对于重建过去冰川动态和评估气候驱动的景观变化至关重要，但弱光学对比和高分辨率DEM的有限可用性阻碍了自动化制图。

Method: 研究开发了MCD-Net，一个轻量级基线模型，集成了MobileNetV2编码器、CBAM模块和DeepLabV3+解码器。

Result: MCD-Net在基准测试中达到62.3%的mIoU和72.8%的Dice系数，同时计算成本降低了60%以上。

Conclusion: 该研究证明仅使用光学图像即可提供可靠的冰碛体分割，为高海拔冰川监测提供了可部署的基线。

Abstract: Glacial segmentation is essential for reconstructing past glacier dynamics and evaluating climate-driven landscape change. However, weak optical contrast and the limited availability of high-resolution DEMs hinder automated mapping. This study introduces the first large-scale optical-only moraine segmentation dataset, comprising 3,340 manually annotated high-resolution images from Google Earth covering glaciated regions of Sichuan and Yunnan, China. We develop MCD-Net, a lightweight baseline that integrates a MobileNetV2 encoder, a Convolutional Block Attention Module (CBAM), and a DeepLabV3+ decoder. Benchmarking against deeper backbones (ResNet152, Xception) shows that MCD-Net achieves 62.3\% mean Intersection over Union (mIoU) and 72.8\% Dice coefficient while reducing computational cost by more than 60\%. Although ridge delineation remains constrained by sub-pixel width and spectral ambiguity, the results demonstrate that optical imagery alone can provide reliable moraine-body segmentation. The dataset and code are publicly available at https://github.com/Lyra-alpha/MCD-Net, establishing a reproducible benchmark for moraine-specific segmentation and offering a deployable baseline for high-altitude glacial monitoring.

</details>


### [145] [InpaintHuman: Reconstructing Occluded Humans with Multi-Scale UV Mapping and Identity-Preserving Diffusion Inpainting](https://arxiv.org/abs/2601.02098)
*Jinlong Fan,Shanshan Zhao,Liang Zheng,Jing Zhang,Yuxiang Yang,Mingming Gong*

Main category: cs.CV

TL;DR: InpaintHuman通过多尺度UV表示和扩散修复模块，从遮挡单目视频生成高质量3D人体化身，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在遮挡情况下难以生成完整的3D人体化身，导致几何损坏和时间不一致性。InpaintHuman旨在解决这一问题。

Method: 该方法采用多尺度UV参数化表示和层次化的粗到细特征插值，结合身份保持扩散修复模块，通过直接像素级监督确保身份保真度。

Result: 在合成基准（PeopleSnapshot、ZJU-MoCap）和真实场景（OcMotion）上的实验显示，该方法在多样姿态和视角下均能提升重建质量。

Conclusion: InpaintHuman提出了一种新颖的方法，通过多尺度UV参数化表示和身份保持扩散修复模块，成功从遮挡的单目视频中生成高保真、完整且可动画的3D人体化身。实验证明该方法在重建质量上具有竞争优势。

Abstract: Reconstructing complete and animatable 3D human avatars from monocular videos remains challenging, particularly under severe occlusions. While 3D Gaussian Splatting has enabled photorealistic human rendering, existing methods struggle with incomplete observations, often producing corrupted geometry and temporal inconsistencies. We present InpaintHuman, a novel method for generating high-fidelity, complete, and animatable avatars from occluded monocular videos. Our approach introduces two key innovations: (i) a multi-scale UV-parameterized representation with hierarchical coarse-to-fine feature interpolation, enabling robust reconstruction of occluded regions while preserving geometric details; and (ii) an identity-preserving diffusion inpainting module that integrates textual inversion with semantic-conditioned guidance for subject-specific, temporally coherent completion. Unlike SDS-based methods, our approach employs direct pixel-level supervision to ensure identity fidelity. Experiments on synthetic benchmarks (PeopleSnapshot, ZJU-MoCap) and real-world scenarios (OcMotion) demonstrate competitive performance with consistent improvements in reconstruction quality across diverse poses and viewpoints.

</details>


### [146] [360-GeoGS: Geometrically Consistent Feed-Forward 3D Gaussian Splatting Reconstruction for 360 Images](https://arxiv.org/abs/2601.02102)
*Jiaqi Yao,Zhongmiao Yan,Jingyi Xu,Songpengcheng Xia,Yan Xiang,Ling Pei*

Main category: cs.CV

TL;DR: 本文提出了一种新型前馈式3D高斯泼溅框架，通过深度-法线几何正则化提升几何一致性，同时保持高渲染质量，适用于空间感知任务中的3D重建。


<details>
  <summary>Details</summary>
Motivation: 传统多视角立体视觉在稀疏视角或低纹理区域表现不佳，而神经渲染方法虽能产生高质量结果，但缺乏实时效率且需要逐场景优化。显式3D高斯泼溅（3DGS）虽能实现高效渲染，但多数前馈变体关注视觉质量而非几何一致性，限制了其在空间感知任务中的准确性和可靠性。

Method: 引入深度-法线几何正则化，将渲染深度梯度与法线信息耦合，监督高斯的旋转、尺度和位置，以提高点云和表面的准确性。

Result: 实验结果表明，所提方法在保持高渲染质量的同时，显著提升了几何一致性。

Conclusion: 本文提出的新型前馈式3D高斯泼溅框架在保持高渲染质量的同时，显著提升了几何一致性，为空间感知任务中的3D重建提供了有效解决方案。

Abstract: 3D scene reconstruction is fundamental for spatial intelligence applications such as AR, robotics, and digital twins. Traditional multi-view stereo struggles with sparse viewpoints or low-texture regions, while neural rendering approaches, though capable of producing high-quality results, require per-scene optimization and lack real-time efficiency. Explicit 3D Gaussian Splatting (3DGS) enables efficient rendering, but most feed-forward variants focus on visual quality rather than geometric consistency, limiting accurate surface reconstruction and overall reliability in spatial perception tasks. This paper presents a novel feed-forward 3DGS framework for 360 images, capable of generating geometrically consistent Gaussian primitives while maintaining high rendering quality. A Depth-Normal geometric regularization is introduced to couple rendered depth gradients with normal information, supervising Gaussian rotation, scale, and position to improve point cloud and surface accuracy. Experimental results show that the proposed method maintains high rendering quality while significantly improving geometric consistency, providing an effective solution for 3D reconstruction in spatial perception tasks.

</details>


### [147] [HeadLighter: Disentangling Illumination in Generative 3D Gaussian Heads via Lightstage Captures](https://arxiv.org/abs/2601.02103)
*Yating Wang,Yuan Sun,Xuan Wang,Ran Yi,Boyao Zhou,Yipengjing Sun,Hongyu Liu,Yinuo Wang,Lizhuang Ma*

Main category: cs.CV

TL;DR: HeadLighter 通过双分支架构和渐进式解缠训练，实现了头部生成模型中外观与照明的物理合理分解，支持高质量实时渲染和显式编辑。


<details>
  <summary>Details</summary>
Motivation: 现有方法在光照与内在外观的深度纠缠问题上存在局限，依赖强假设进行弱监督学习，难以处理复杂光照。

Method: 采用双分支架构分别建模光照不变的头部位属性和物理基础的渲染组件，结合渐进式解缠训练和多视角图像监督。

Result: 实验证明，该方法在保持高质量生成和实时渲染的同时，支持显式光照和视角编辑。

Conclusion: HeadLighter 提出了一种新颖的监督框架，成功实现了头部生成模型中外观与照明的物理合理分解，支持高质量的实时渲染和显式光照与视角编辑。

Abstract: Recent 3D-aware head generative models based on 3D Gaussian Splatting achieve real-time, photorealistic and view-consistent head synthesis. However, a fundamental limitation persists: the deep entanglement of illumination and intrinsic appearance prevents controllable relighting. Existing disentanglement methods rely on strong assumptions to enable weakly supervised learning, which restricts their capacity for complex illumination. To address this challenge, we introduce HeadLighter, a novel supervised framework that learns a physically plausible decomposition of appearance and illumination in head generative models. Specifically, we design a dual-branch architecture that separately models lighting-invariant head attributes and physically grounded rendering components. A progressive disentanglement training is employed to gradually inject head appearance priors into the generative architecture, supervised by multi-view images captured under controlled light conditions with a light stage setup. We further introduce a distillation strategy to generate high-quality normals for realistic rendering. Experiments demonstrate that our method preserves high-quality generation and real-time rendering, while simultaneously supporting explicit lighting and viewpoint editing. We will publicly release our code and dataset.

</details>


### [148] [MagicFight: Personalized Martial Arts Combat Video Generation](https://arxiv.org/abs/2601.02107)
*Jiancheng Huang,Mingfu Yan,Songyan Chen,Yi Huang,Shifeng Chen*

Main category: cs.CV

TL;DR: MagicFight是一个针对双人武术战斗视频生成的新方法，解决了现有单人生成模型的不足，并通过Unity生成定制数据集，实现了高质量的双人互动视频生成。


<details>
  <summary>Details</summary>
Motivation: 现有单人生成模型无法捕捉双人武术战斗的复杂性和细节，导致身份混淆、肢体异常和动作不匹配等问题。

Method: MagicFight通过改进和调整现有模型及策略，利用Unity游戏物理引擎生成定制数据集，包含多样化的3D角色、武术动作和场景。

Result: MagicFight能够生成高保真的双人战斗视频，保持个体身份并确保动作序列的连贯性。

Conclusion: MagicFight为双人互动视频生成（尤其是武术战斗）奠定了基础，为未来交互式视频内容创作提供了新的研究方向。

Abstract: Amid the surge in generic text-to-video generation, the field of personalized human video generation has witnessed notable advancements, primarily concentrated on single-person scenarios. However, to our knowledge, the domain of two-person interactions, particularly in the context of martial arts combat, remains uncharted. We identify a significant gap: existing models for single-person dancing generation prove insufficient for capturing the subtleties and complexities of two engaged fighters, resulting in challenges such as identity confusion, anomalous limbs, and action mismatches. To address this, we introduce a pioneering new task, Personalized Martial Arts Combat Video Generation. Our approach, MagicFight, is specifically crafted to overcome these hurdles. Given this pioneering task, we face a lack of appropriate datasets. Thus, we generate a bespoke dataset using the game physics engine Unity, meticulously crafting a multitude of 3D characters, martial arts moves, and scenes designed to represent the diversity of combat. MagicFight refines and adapts existing models and strategies to generate high-fidelity two-person combat videos that maintain individual identities and ensure seamless, coherent action sequences, thereby laying the groundwork for future innovations in the realm of interactive video content creation.
  Website: https://MingfuYAN.github.io/MagicFight/
  Dataset: https://huggingface.co/datasets/MingfuYAN/KungFu-Fiesta

</details>


### [149] [Car Drag Coefficient Prediction from 3D Point Clouds Using a Slice-Based Surrogate Model](https://arxiv.org/abs/2601.02112)
*Utkarsh Singh,Absaar Ali,Adarsh Roy*

Main category: cs.CV

TL;DR: 提出轻量级替代模型，通过切片处理和双向LSTM预测车辆Cd，实现快速、高精度气动评估。


<details>
  <summary>Details</summary>
Motivation: 传统的气动评估方法（如CFD和风洞测试）资源密集，阻碍早期设计阶段的快速迭代。机器学习替代模型虽有潜力，但现有方法存在计算复杂度高、可解释性差或对详细几何输入精度不足的问题。

Method: 模型将3D车辆点云沿流向轴分解为有序的2D横截面切片序列，每个切片通过轻量级PointNet2D模块编码，切片嵌入序列由双向LSTM处理以捕捉纵向几何演变。

Result: 在DrivAerNet++数据集上，模型实现了高决定系数（R^2 > 0.9528）和低平均绝对误差（MAE ≈ 6.046 x 10^{-3}），推理时间约为0.025秒/样本。

Conclusion: 本文提出了一种基于顺序切片处理的轻量级替代模型，用于预测3D车辆的气动阻力系数（Cd），该方法在DrivAerNet++数据集上表现出高精度和低误差，且推理速度快，为汽车设计提供了快速、准确且可解释的气动反馈。

Abstract: The automotive industry's pursuit of enhanced fuel economy and performance necessitates efficient aerodynamic design. However, traditional evaluation methods such as computational fluid dynamics (CFD) and wind tunnel testing are resource intensive, hindering rapid iteration in the early design stages. Machine learning-based surrogate models offer a promising alternative, yet many existing approaches suffer from high computational complexity, limited interpretability, or insufficient accuracy for detailed geometric inputs. This paper introduces a novel lightweight surrogate model for the prediction of the aerodynamic drag coefficient (Cd) based on a sequential slice-wise processing of the geometry of the 3D vehicle. Inspired by medical imaging, 3D point clouds of vehicles are decomposed into an ordered sequence of 2D cross-sectional slices along the stream-wise axis. Each slice is encoded by a lightweight PointNet2D module, and the sequence of slice embeddings is processed by a bidirectional LSTM to capture longitudinal geometric evolution. The model, trained and evaluated on the DrivAerNet++ dataset, achieves a high coefficient of determination (R^2 > 0.9528) and a low mean absolute error (MAE approx 6.046 x 10^{-3}) in Cd prediction. With an inference time of approximately 0.025 seconds per sample on a consumer-grade GPU, our approach provides fast, accurate, and interpretable aerodynamic feedback, facilitating more agile and informed automotive design exploration.

</details>


### [150] [Beyond Segmentation: An Oil Spill Change Detection Framework Using Synthetic SAR Imagery](https://arxiv.org/abs/2601.02139)
*Chenyang Lai,Shuaiyu Chen,Tianjin Huang,Siyang Song,Guangliang Cheng,Chunbo Luo,Zeyu Fu*

Main category: cs.CV

TL;DR: 提出OSCD任务和TAHI框架，通过双时序SAR图像变化检测提升油污监测准确性，减少误报。


<details>
  <summary>Details</summary>
Motivation: 现有基于单张SAR图像的静态方法难以区分真实油污与视觉相似的海面特征，导致高误报率和有限泛化能力。

Method: 提出了Oil Spill Change Detection (OSCD)任务和Temporal-Aware Hybrid Inpainting (TAHI)框架，包括高保真混合修复和时序真实性增强两个关键组件。

Result: OSCD显著减少了误报并提高了检测准确性，优于传统分割方法。

Conclusion: OSCD结合TAHI框架显著降低了误报率，提高了油污检测的准确性，证明了时间感知方法在真实场景中可靠、可扩展的油污监测价值。

Abstract: Marine oil spills are urgent environmental hazards that demand rapid and reliable detection to minimise ecological and economic damage. While Synthetic Aperture Radar (SAR) imagery has become a key tool for large-scale oil spill monitoring, most existing detection methods rely on deep learning-based segmentation applied to single SAR images. These static approaches struggle to distinguish true oil spills from visually similar oceanic features (e.g., biogenic slicks or low-wind zones), leading to high false positive rates and limited generalizability, especially under data-scarce conditions. To overcome these limitations, we introduce Oil Spill Change Detection (OSCD), a new bi-temporal task that focuses on identifying changes between pre- and post-spill SAR images. As real co-registered pre-spill imagery is not always available, we propose the Temporal-Aware Hybrid Inpainting (TAHI) framework, which generates synthetic pre-spill images from post-spill SAR data. TAHI integrates two key components: High-Fidelity Hybrid Inpainting for oil-free reconstruction, and Temporal Realism Enhancement for radiometric and sea-state consistency. Using TAHI, we construct the first OSCD dataset and benchmark several state-of-the-art change detection models. Results show that OSCD significantly reduces false positives and improves detection accuracy compared to conventional segmentation, demonstrating the value of temporally-aware methods for reliable, scalable oil spill monitoring in real-world scenarios.

</details>


### [151] [Efficient Unrolled Networks for Large-Scale 3D Inverse Problems](https://arxiv.org/abs/2601.02141)
*Romain Vo,Julián Tachella*

Main category: cs.CV

TL;DR: 该论文提出了一种解决大规模成像问题中前向算子内存消耗过大的方法，通过领域分割和算子近似，实现了高性能的3D重建，且仅需单个GPU。


<details>
  <summary>Details</summary>
Motivation: 现有方法在3D成像等大规模问题中，由于全局前向算子内存消耗过大，无法将算子整合到网络架构中，限制了性能提升。

Method: 采用领域分割策略和正常算子近似方法，解决了大规模成像问题中前向算子内存消耗过大的问题。

Result: 所提方法在3D X射线锥束断层扫描和3D多线圈加速MRI上实现了最先进的性能，且仅需单个GPU。

Conclusion: 该论文提出了一种领域分割策略和正常算子近似方法，成功将大规模问题的前向算子整合到网络架构中，实现了在3D X射线锥束断层扫描和3D多线圈加速MRI上的最先进性能，且仅需单个GPU进行训练和推理。

Abstract: Deep learning-based methods have revolutionized the field of imaging inverse problems, yielding state-of-the-art performance across various imaging domains. The best performing networks incorporate the imaging operator within the network architecture, typically in the form of deep unrolling. However, in large-scale problems, such as 3D imaging, most existing methods fail to incorporate the operator in the architecture due to the prohibitive amount of memory required by global forward operators, which hinder typical patching strategies. In this work, we present a domain partitioning strategy and normal operator approximations that enable the training of end-to-end reconstruction models incorporating forward operators of arbitrarily large problems into their architecture. The proposed method achieves state-of-the-art performance on 3D X-ray cone-beam tomography and 3D multi-coil accelerated MRI, while requiring only a single GPU for both training and inference.

</details>


### [152] [Why Commodity WiFi Sensors Fail at Multi-Person Gait Identification: A Systematic Analysis Using ESP32](https://arxiv.org/abs/2601.02177)
*Oliver Custance,Saad Khan,Simon Parkinson*

Main category: cs.CV

TL;DR: 研究发现商品级ESP32传感器信号质量不足，导致多人步态识别准确率低（最佳方法NMF仅56%），性能随人数增加急剧下降。


<details>
  <summary>Details</summary>
Motivation: 探索多人步态识别的性能限制是算法问题还是硬件限制，填补现有研究中依赖复杂昂贵设备的空白。

Method: 系统评估了六种信号分离方法（FastICA、SOBI、PCA、NMF、小波变换、张量分解），在1-10人场景下使用ESP32传感器，并通过新颖的诊断指标（主体内变异性、主体间可区分性、性能退化率）进行分析。

Result: 所有方法在多人员场景下准确率相似且较低（45-56%，σ=3.74%），性能随人数增加显著下降，表明硬件信号质量不足。

Conclusion: 商品级ESP32 WiFi传感器在多人员步态识别中信号质量不足，无法实现可靠的多人分离。

Abstract: WiFi Channel State Information (CSI) has shown promise for single-person gait identification, with numerous studies reporting high accuracy. However, multi-person identification remains largely unexplored, with the limited existing work relying on complex, expensive setups requiring modified firmware. A critical question remains unanswered: is poor multi-person performance an algorithmic limitation or a fundamental hardware constraint? We systematically evaluate six diverse signal separation methods (FastICA, SOBI, PCA, NMF, Wavelet, Tensor Decomposition) across seven scenarios with 1-10 people using commodity ESP32 WiFi sensors--a simple, low-cost, off-the-shelf solution. Through novel diagnostic metrics (intra-subject variability, inter-subject distinguishability, performance degradation rate), we reveal that all methods achieve similarly low accuracy (45-56\%, $σ$=3.74\%) with statistically insignificant differences (p $>$ 0.05). Even the best-performing method, NMF, achieves only 56\% accuracy. Our analysis reveals high intra-subject variability, low inter-subject distinguishability, and severe performance degradation as person count increases, indicating that commodity ESP32 sensors cannot provide sufficient signal quality for reliable multi-person separation.

</details>


### [153] [QuIC: A Quantum-Inspired Interaction Classifier for Revitalizing Shallow CNNs in Fine-Grained Recognition](https://arxiv.org/abs/2601.02189)
*Cheng Ying Wu,Yen Jui Chang*

Main category: cs.CV

TL;DR: QuIC是一种量子启发的轻量级模块，通过捕捉二阶特征协方差，显著提升浅层网络在细粒度分类中的性能，避免特征维度爆炸。


<details>
  <summary>Details</summary>
Motivation: 解决细粒度视觉分类任务中，深度模型计算成本高而浅层网络无法捕捉高阶特征交互的问题。

Method: 提出Quantum-inspired Interaction Classifier (QuIC)，通过量子力学启发的可学习观测算子捕捉二阶特征协方差，支持稳定的端到端训练。

Result: QuIC显著提升了浅层网络（如VGG16）的性能，Top-1准确率提升近20%，并在ResNet18上优于最先进的注意力机制（SE-Block）。

Conclusion: QuIC作为一种轻量级、即插即用的模块，显著提升了浅层网络在细粒度视觉分类任务中的性能，解决了传统方法在特征维度爆炸和训练不稳定性方面的问题。

Abstract: Deploying deep learning models for Fine-Grained Visual Classification (FGVC) on resource-constrained edge devices remains a significant challenge. While deep architectures achieve high accuracy on benchmarks like CUB-200-2011, their computational cost is often prohibitive. Conversely, shallow networks (e.g., AlexNet, VGG) offer efficiency but fail to distinguish visually similar sub-categories. This is because standard Global Average Pooling (GAP) heads capture only first-order statistics, missing the subtle high-order feature interactions required for FGVC. While Bilinear CNNs address this, they suffer from high feature dimensionality and instability during training. To bridge this gap, we propose the Quantum-inspired Interaction Classifier (QuIC). Drawing inspiration from quantum mechanics, QuIC models feature channels as interacting quantum states and captures second-order feature covariance via a learnable observable operator. Designed as a lightweight, plug-and-play module, QuIC supports stable, single-stage end-to-end training without exploding feature dimensions. Experimental results demonstrate that QuIC significantly revitalizes shallow backbones: it boosts the Top-1 accuracy of VGG16 by nearly 20% and outperforms state-of-the-art attention mechanisms (SE-Block) on ResNet18. Qualitative analysis, including t-SNE visualization, further confirms that QuIC resolves ambiguous cases by explicitly attending to fine-grained discriminative features and enforcing compact intra-class clustering.

</details>


### [154] [Mind the Gap: Continuous Magnification Sampling for Pathology Foundation Models](https://arxiv.org/abs/2601.02198)
*Alexander Möllers,Julius Hense,Florian Schulz,Timo Milbich,Maximilian Alber,Lukas Ruff*

Main category: cs.CV

TL;DR: 研究病理学基础模型在不同放大倍数下的性能，提出连续采样和优化分布策略，显著提升中间放大倍数的分类准确率。


<details>
  <summary>Details</summary>
Motivation: 理解病理学基础模型在不同放大倍数下的性能以及训练过程中放大倍数采样的影响。

Method: 通过将放大倍数采样建模为多源域适应问题，开发了一个简单的理论框架，揭示了采样策略之间的系统性权衡。引入了连续放大倍数采样和优化的采样分布。

Result: 连续采样在中间放大倍数下显著优于离散采样，平衡分类准确率提升高达4个百分点，优化分布可进一步提高性能。

Conclusion: 本研究为未来的病理学基础模型在不同放大倍数下可靠性能的实现铺平了道路。

Abstract: In histopathology, pathologists examine both tissue architecture at low magnification and fine-grained morphology at high magnification. Yet, the performance of pathology foundation models across magnifications and the effect of magnification sampling during training remain poorly understood. We model magnification sampling as a multi-source domain adaptation problem and develop a simple theoretical framework that reveals systematic trade-offs between sampling strategies. We show that the widely used discrete uniform sampling of magnifications (0.25, 0.5, 1.0, 2.0 mpp) leads to degradation at intermediate magnifications. We introduce continuous magnification sampling, which removes gaps in magnification coverage while preserving performance at standard scales. Further, we derive sampling distributions that optimize representation quality across magnification scales. To evaluate these strategies, we introduce two new benchmarks (TCGA-MS, BRACS-MS) with appropriate metrics. Our experiments show that continuous sampling substantially improves over discrete sampling at intermediate magnifications, with gains of up to 4 percentage points in balanced classification accuracy, and that optimized distributions can further improve performance. Finally, we evaluate current histopathology foundation models, finding that magnification is a primary driver of performance variation across models. Our work paves the way towards future pathology foundation models that perform reliably across magnifications.

</details>


### [155] [Parameter-Efficient Domain Adaption for CSI Crowd-Counting via Self-Supervised Learning with Adapter Modules](https://arxiv.org/abs/2601.02203)
*Oliver Custance,Saad Khan,Simon Parkinson,Quan Z. Sheng*

Main category: cs.CV

TL;DR: 提出基于CSI-ResNet-A的两阶段框架，通过自监督学习和Adapter微调解决WiFi人群计数的领域偏移问题，在多个测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决WiFi信道状态信息（CSI）在设备无关人群计数中的领域偏移问题，以推动隐私保护的物联网应用发展。

Method: 提出了一个基于CSI-ResNet-A架构的两阶段框架，通过自监督对比学习预训练以学习领域不变表示，并利用轻量级Adapter模块进行高效微调。

Result: 在WiFlow数据集的10-shot学习场景中，无监督方法实现了0.44的MAE，同时在WiAR基准测试中达到98.8%的准确率。

Conclusion: 本文提出了一个实用的、可扩展的解决方案，用于开发适用于真实世界物联网部署的鲁棒感知系统。

Abstract: Device-free crowd-counting using WiFi Channel State Information (CSI) is a key enabling technology for a new generation of privacy-preserving Internet of Things (IoT) applications. However, practical deployment is severely hampered by the domain shift problem, where models trained in one environment fail to generalise to another. To overcome this, we propose a novel two-stage framework centred on a CSI-ResNet-A architecture. This model is pre-trained via self-supervised contrastive learning to learn domain-invariant representations and leverages lightweight Adapter modules for highly efficient fine-tuning. The resulting event sequence is then processed by a stateful counting machine to produce a final, stable occupancy estimate. We validate our framework extensively. On our WiFlow dataset, our unsupervised approach excels in a 10-shot learning scenario, achieving a final Mean Absolute Error (MAE) of just 0.44--a task where supervised baselines fail. To formally quantify robustness, we introduce the Generalisation Index (GI), on which our model scores near-perfectly, confirming its ability to generalise. Furthermore, our framework sets a new state-of-the-art public WiAR benchmark with 98.8\% accuracy. Our ablation studies reveal the core strength of our design: adapter-based fine-tuning achieves performance within 1\% of a full fine-tune (98.84\% vs. 99.67\%) while training 97.2\% fewer parameters. Our work provides a practical and scalable solution for developing robust sensing systems ready for real-world IoT deployments.

</details>


### [156] [Unraveling MMDiT Blocks: Training-free Analysis and Enhancement of Text-conditioned Diffusion](https://arxiv.org/abs/2601.02211)
*Binglei Li,Mengping Yang,Zhiyu Tan,Junping Zhang,Hao Li*

Main category: cs.CV

TL;DR: 本文系统分析了MMDiT模型的模块功能，提出了无需训练的策略，显著提升了文本对齐和编辑性能，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管现有方法尝试分析MMDiT模型的特定组件（如位置编码和注意力层），但对不同模块及其与文本条件交互作用的全面理解仍不足。

Method: 开发了一个系统化的分析流程，通过移除、禁用和增强文本隐藏状态来研究每个模块的功能，并基于分析结果提出了训练自由的改进策略。

Result: 实验表明，该方法在文本到图像生成、图像编辑和推理加速方面优于多种基线方法，显著提升了T2I-Combench++和GenEval的评分。

Conclusion: 本文通过系统分析MMDiT模型的内部机制，提出了无需训练的策略，显著提升了文本对齐、精确编辑和推理加速的性能，为MMDiT模型的进一步优化提供了新思路。

Abstract: Recent breakthroughs of transformer-based diffusion models, particularly with Multimodal Diffusion Transformers (MMDiT) driven models like FLUX and Qwen Image, have facilitated thrilling experiences in text-to-image generation and editing. To understand the internal mechanism of MMDiT-based models, existing methods tried to analyze the effect of specific components like positional encoding and attention layers. Yet, a comprehensive understanding of how different blocks and their interactions with textual conditions contribute to the synthesis process remains elusive. In this paper, we first develop a systematic pipeline to comprehensively investigate each block's functionality by removing, disabling and enhancing textual hidden-states at corresponding blocks. Our analysis reveals that 1) semantic information appears in earlier blocks and finer details are rendered in later blocks, 2) removing specific blocks is usually less disruptive than disabling text conditions, and 3) enhancing textual conditions in selective blocks improves semantic attributes. Building on these observations, we further propose novel training-free strategies for improved text alignment, precise editing, and acceleration. Extensive experiments demonstrated that our method outperforms various baselines and remains flexible across text-to-image generation, image editing, and inference acceleration. Our method improves T2I-Combench++ from 56.92% to 63.00% and GenEval from 66.42% to 71.63% on SD3.5, without sacrificing synthesis quality. These results advance understanding of MMDiT models and provide valuable insights to unlock new possibilities for further improvements.

</details>


### [157] [Prior-Guided DETR for Ultrasound Nodule Detection](https://arxiv.org/abs/2601.02212)
*Jingjing Wang,Zhuo Xiao,Xinning Yao,Bo Liu,Lijuan Niu,Xiangzhi Bai,Fugen Zhou*

Main category: cs.CV

TL;DR: 先验引导DETR框架通过多阶段融入几何和结构先验，显著提升超声结节检测精度，尤其在复杂结节上表现突出。


<details>
  <summary>Details</summary>
Motivation: 超声结节检测因形状不规则、边界模糊、尺度变化大及斑点噪声而具有挑战性，需改进现有方法。

Method: 框架结合了SDFPR、MSFFM和DFI机制，逐步融入几何和结构先验知识，优化特征提取和查询细化。

Result: 在两个甲状腺超声数据集（Thyroid I和II）及两个公开基准（TN3K和BUSI）上验证了方法的优越性。

Conclusion: 提出的先验引导DETR框架在超声结节检测中表现出色，特别是在形态复杂结节上优于现有18种检测方法。

Abstract: Accurate detection of ultrasound nodules is essential for the early diagnosis and treatment of thyroid and breast cancers. However, this task remains challenging due to irregular nodule shapes, indistinct boundaries, substantial scale variations, and the presence of speckle noise that degrades structural visibility. To address these challenges, we propose a prior-guided DETR framework specifically designed for ultrasound nodule detection. Instead of relying on purely data-driven feature learning, the proposed framework progressively incorporates different prior knowledge at multiple stages of the network. First, a Spatially-adaptive Deformable FFN with Prior Regularization (SDFPR) is embedded into the CNN backbone to inject geometric priors into deformable sampling, stabilizing feature extraction for irregular and blurred nodules. Second, a Multi-scale Spatial-Frequency Feature Mixer (MSFFM) is designed to extract multi-scale structural priors, where spatial-domain processing emphasizes contour continuity and boundary cues, while frequency-domain modeling captures global morphology and suppresses speckle noise. Furthermore, a Dense Feature Interaction (DFI) mechanism propagates and exploits these prior-modulated features across all encoder layers, enabling the decoder to enhance query refinement under consistent geometric and structural guidance. Experiments conducted on two clinically collected thyroid ultrasound datasets (Thyroid I and Thyroid II) and two public benchmarks (TN3K and BUSI) for thyroid and breast nodules demonstrate that the proposed method achieves superior accuracy compared with 18 detection methods, particularly in detecting morphologically complex nodules.The source code is publicly available at https://github.com/wjj1wjj/Ultrasound-DETR.

</details>


### [158] [FMVP: Masked Flow Matching for Adversarial Video Purification](https://arxiv.org/abs/2601.02228)
*Duoxun Tang,Xueyi Zhang,Chak Hin Wang,Xi Xiao,Dasen Dai,Xinhang Jiang,Wentao Shi,Rui Li,Qing Li*

Main category: cs.CV

TL;DR: FMVP通过掩码和CFM物理破坏对抗结构，结合FGL分离噪声，显著提升视频对抗攻击的鲁棒性和检测能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的净化方法采样效率低且轨迹弯曲，直接回归干净视频因扰动细微而难以恢复忠实内容，需物理破坏对抗结构。

Method: FMVP采用掩码策略破坏对抗结构，利用条件流匹配（CFM）和修复目标重建视频动态，并设计频率门控损失（FGL）分离语义内容和对抗噪声。攻击感知和通用训练范式分别处理已知和未知威胁。

Result: 在UCF-101和HMDB-51上，FMVP对PGD和CW攻击的鲁棒准确率分别超过87%和89%，对抗自适应攻击（DiffHammer）表现优异，零样本检测准确率达98%（PGD）和79%（CW）。

Conclusion: FMVP通过物理破坏全局对抗结构并重建干净视频动态，结合频率门控损失和攻击感知训练范式，显著提升了视频对抗攻击的鲁棒性，同时在零样本对抗检测中表现出色。

Abstract: Video recognition models remain vulnerable to adversarial attacks, while existing diffusion-based purification methods suffer from inefficient sampling and curved trajectories. Directly regressing clean videos from adversarial inputs often fails to recover faithful content due to the subtle nature of perturbations; this necessitates physically shattering the adversarial structure. Therefore, we propose Flow Matching for Adversarial Video Purification FMVP. FMVP physically shatters global adversarial structures via a masking strategy and reconstructs clean video dynamics using Conditional Flow Matching (CFM) with an inpainting objective. To further decouple semantic content from adversarial noise, we design a Frequency-Gated Loss (FGL) that explicitly suppresses high-frequency adversarial residuals while preserving low-frequency fidelity. We design Attack-Aware and Generalist training paradigms to handle known and unknown threats, respectively. Extensive experiments on UCF-101 and HMDB-51 demonstrate that FMVP outperforms state-of-the-art methods (DiffPure, Defense Patterns (DP), Temporal Shuffling (TS) and FlowPure), achieving robust accuracy exceeding 87% against PGD and 89% against CW attacks. Furthermore, FMVP demonstrates superior robustness against adaptive attacks (DiffHammer) and functions as a zero-shot adversarial detector, attaining detection accuracies of 98% for PGD and 79% for highly imperceptible CW attacks.

</details>


### [159] [SLGNet: Synergizing Structural Priors and Language-Guided Modulation for Multimodal Object Detection](https://arxiv.org/abs/2601.02249)
*Xiantai Xiang,Guangyao Zhou,Zixiao Wen,Wenshuai Li,Ben Niu,Feng Wang,Lijia Huang,Qiantong Wang,Yuhan Liu,Zongxu Pan,Yuxin Hu*

Main category: cs.CV

TL;DR: SLGNet通过结构感知和语言引导调制，高效提升多模态物体检测性能，尤其在复杂场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法在跨模态结构一致性和环境动态适应性方面存在不足，导致在高对比度或夜间环境等复杂场景下性能受限。

Method: 提出了SLGNet框架，包括结构感知适配器（Structure-Aware Adapter）和语言引导调制模块（Language-Guided Modulation），利用冻结的ViT基础模型动态注入层次结构表示和语言引导的环境感知。

Result: 在LLVIP、FLIR、KAIST和DroneVehicle数据集上取得SOTA性能，LLVIP上mAP达66.1，同时减少约87%的可训练参数。

Conclusion: SLGNet通过结合层次结构先验和语言引导调制，在保持参数效率的同时，显著提升了多模态物体检测的性能，尤其在复杂动态场景下表现出色。

Abstract: Multimodal object detection leveraging RGB and Infrared (IR) images is pivotal for robust perception in all-weather scenarios. While recent adapter-based approaches efficiently transfer RGB-pretrained foundation models to this task, they often prioritize model efficiency at the expense of cross-modal structural consistency. Consequently, critical structural cues are frequently lost when significant domain gaps arise, such as in high-contrast or nighttime environments. Moreover, conventional static multimodal fusion mechanisms typically lack environmental awareness, resulting in suboptimal adaptation and constrained detection performance under complex, dynamic scene variations. To address these limitations, we propose SLGNet, a parameter-efficient framework that synergizes hierarchical structural priors and language-guided modulation within a frozen Vision Transformer (ViT)-based foundation model. Specifically, we design a Structure-Aware Adapter to extract hierarchical structural representations from both modalities and dynamically inject them into the ViT to compensate for structural degradation inherent in ViT-based backbones. Furthermore, we propose a Language-Guided Modulation module that exploits VLM-driven structured captions to dynamically recalibrate visual features, thereby endowing the model with robust environmental awareness. Extensive experiments on the LLVIP, FLIR, KAIST, and DroneVehicle datasets demonstrate that SLGNet establishes new state-of-the-art performance. Notably, on the LLVIP benchmark, our method achieves an mAP of 66.1, while reducing trainable parameters by approximately 87% compared to traditional full fine-tuning. This confirms SLGNet as a robust and efficient solution for multimodal perception.

</details>


### [160] [VAR RL Done Right: Tackling Asynchronous Policy Conflicts in Visual Autoregressive Generation](https://arxiv.org/abs/2601.02256)
*Shikun Sun,Liao Qu,Huichao Zhang,Yiheng Liu,Yangyang Song,Xian Li,Xu Wang,Yi Jiang,Daniel K. Du,Xinglong Wu,Jia Jia*

Main category: cs.CV

TL;DR: 提出新框架管理VAR模型的异步策略冲突，整合三种组件提升样本质量和目标对齐。


<details>
  <summary>Details</summary>
Motivation: 解决VAR模型在异构输入结构中产生的异步策略冲突问题，特别是在强化学习场景下的训练不稳定和对齐不佳。

Method: 整合了三种协同组件：稳定中间奖励、动态时间步重加权方案和基于奖励反馈学习的掩码传播算法。

Result: 在样本质量和目标对齐上显著优于基础GRPO方法。

Conclusion: 提出的新框架通过管理异步策略冲突，显著提升了VAR模型的样本质量和目标对齐，实现了稳健有效的优化。

Abstract: Visual generation is dominated by three paradigms: AutoRegressive (AR), diffusion, and Visual AutoRegressive (VAR) models. Unlike AR and diffusion, VARs operate on heterogeneous input structures across their generation steps, which creates severe asynchronous policy conflicts. This issue becomes particularly acute in reinforcement learning (RL) scenarios, leading to unstable training and suboptimal alignment. To resolve this, we propose a novel framework to enhance Group Relative Policy Optimization (GRPO) by explicitly managing these conflicts. Our method integrates three synergistic components: 1) a stabilizing intermediate reward to guide early-stage generation; 2) a dynamic time-step reweighting scheme for precise credit assignment; and 3) a novel mask propagation algorithm, derived from principles of Reward Feedback Learning (ReFL), designed to isolate optimization effects both spatially and temporally. Our approach demonstrates significant improvements in sample quality and objective alignment over the vanilla GRPO baseline, enabling robust and effective optimization for VAR models.

</details>


### [161] [DiffProxy: Multi-View Human Mesh Recovery via Diffusion-Generated Dense Proxies](https://arxiv.org/abs/2601.02267)
*Renke Wang,Zhenyu Zhang,Ying Tai,Jian Yang*

Main category: cs.CV

TL;DR: DiffProxy利用扩散模型生成先验，结合合成数据训练，实现多视角一致人体代理生成，并在真实场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决真实世界数据集标注不完美导致训练偏差，以及合成数据与真实数据领域差距的问题。

Method: DiffProxy框架包括多条件机制生成多视角一致的人体代理、手部细化模块增强局部细节，以及不确定性感知的测试时缩放方法提升优化鲁棒性。

Result: 在五个真实世界基准测试中达到最先进性能，展示了在遮挡和部分视角等挑战性场景中的强零样本泛化能力。

Conclusion: DiffProxy通过结合扩散模型的生成先验和合成数据的精确监督，成功实现了在真实世界基准测试中的零样本泛化，尤其在遮挡和部分视角等挑战性场景中表现优异。

Abstract: Human mesh recovery from multi-view images faces a fundamental challenge: real-world datasets contain imperfect ground-truth annotations that bias the models' training, while synthetic data with precise supervision suffers from domain gap. In this paper, we propose DiffProxy, a novel framework that generates multi-view consistent human proxies for mesh recovery. Central to DiffProxy is leveraging the diffusion-based generative priors to bridge the synthetic training and real-world generalization. Its key innovations include: (1) a multi-conditional mechanism for generating multi-view consistent, pixel-aligned human proxies; (2) a hand refinement module that incorporates flexible visual prompts to enhance local details; and (3) an uncertainty-aware test-time scaling method that increases robustness to challenging cases during optimization. These designs ensure that the mesh recovery process effectively benefits from the precise synthetic ground truth and generative advantages of the diffusion-based pipeline. Trained entirely on synthetic data, DiffProxy achieves state-of-the-art performance across five real-world benchmarks, demonstrating strong zero-shot generalization particularly on challenging scenarios with occlusions and partial views. Project page: https://wrk226.github.io/DiffProxy.html

</details>


### [162] [InfiniteVGGT: Visual Geometry Grounded Transformer for Endless Streams](https://arxiv.org/abs/2601.02281)
*Shuai Yuan,Yantai Yang,Xiaotian Yang,Xupeng Zhang,Zhonghao Zhao,Lingming Zhang,Zhipeng Zhang*

Main category: cs.CV

TL;DR: InfiniteVGGT通过滚动内存和剪枝策略，解决了3D几何理解的长期稳定性问题，并推出Long3D基准测试验证性能。


<details>
  <summary>Details</summary>
Motivation: 现有离线模型无法实时处理，而流式架构在长期稳定性或无限输入支持上表现不足，亟需一种兼顾可扩展性和长期稳定性的解决方案。

Method: 提出了InfiniteVGGT，一种因果视觉几何变换器，采用有界但自适应的KV缓存实现滚动内存，并结合训练无关的注意力无关剪枝策略。

Result: InfiniteVGGT在无限时间序列处理中表现优异，优于现有流式方法，并通过Long3D基准测试验证了其长期稳定性。

Conclusion: InfiniteVGGT 通过创新的滚动内存机制和训练无关的剪枝策略，成功解决了长期3D几何理解的稳定性和可扩展性问题，并通过Long3D基准测试验证了其无限时间序列处理能力。

Abstract: The grand vision of enabling persistent, large-scale 3D visual geometry understanding is shackled by the irreconcilable demands of scalability and long-term stability. While offline models like VGGT achieve inspiring geometry capability, their batch-based nature renders them irrelevant for live systems. Streaming architectures, though the intended solution for live operation, have proven inadequate. Existing methods either fail to support truly infinite-horizon inputs or suffer from catastrophic drift over long sequences. We shatter this long-standing dilemma with InfiniteVGGT, a causal visual geometry transformer that operationalizes the concept of a rolling memory through a bounded yet adaptive and perpetually expressive KV cache. Capitalizing on this, we devise a training-free, attention-agnostic pruning strategy that intelligently discards obsolete information, effectively ``rolling'' the memory forward with each new frame. Fully compatible with FlashAttention, InfiniteVGGT finally alleviates the compromise, enabling infinite-horizon streaming while outperforming existing streaming methods in long-term stability. The ultimate test for such a system is its performance over a truly infinite horizon, a capability that has been impossible to rigorously validate due to the lack of extremely long-term, continuous benchmarks. To address this critical gap, we introduce the Long3D benchmark, which, for the first time, enables a rigorous evaluation of continuous 3D geometry estimation on sequences about 10,000 frames. This provides the definitive evaluation platform for future research in long-term 3D geometry understanding. Code is available at: https://github.com/AutoLab-SAI-SJTU/InfiniteVGGT

</details>


### [163] [Rank-based Geographical Regularization: Revisiting Contrastive Self-Supervised Learning for Multispectral Remote Sensing Imagery](https://arxiv.org/abs/2601.02289)
*Tom Burgert,Leonard Hackel,Paolo Rota,Begüm Demir*

Main category: cs.CV

TL;DR: GeoRank通过优化球面距离嵌入地理关系，提升了多光谱遥感图像的对比自监督学习效果。


<details>
  <summary>Details</summary>
Motivation: 自监督学习在计算机视觉中表现优异，但在多光谱遥感图像中面临地理和时间变化的独特挑战。

Method: 提出GeoRank方法，优化球面距离以嵌入地理关系，并系统研究了对比自监督学习在多光谱遥感图像中的关键适应性。

Result: GeoRank优于或匹配现有整合地理元数据的方法，并持续改进多种对比自监督学习算法（如BYOL、DINO）。

Conclusion: GeoRank作为一种新颖的对比自监督学习正则化方法，通过直接优化球面距离将地理关系嵌入学习特征空间，显著提升了多光谱遥感图像的处理效果。

Abstract: Self-supervised learning (SSL) has become a powerful paradigm for learning from large, unlabeled datasets, particularly in computer vision (CV). However, applying SSL to multispectral remote sensing (RS) images presents unique challenges and opportunities due to the geographical and temporal variability of the data. In this paper, we introduce GeoRank, a novel regularization method for contrastive SSL that improves upon prior techniques by directly optimizing spherical distances to embed geographical relationships into the learned feature space. GeoRank outperforms or matches prior methods that integrate geographical metadata and consistently improves diverse contrastive SSL algorithms (e.g., BYOL, DINO). Beyond this, we present a systematic investigation of key adaptations of contrastive SSL for multispectral RS images, including the effectiveness of data augmentations, the impact of dataset cardinality and image size on performance, and the task dependency of temporal views. Code is available at https://github.com/tomburgert/georank.

</details>


### [164] [SortWaste: A Densely Annotated Dataset for Object Detection in Industrial Waste Sorting](https://arxiv.org/abs/2601.02299)
*Sara Inácio,Hugo Proença,João C. Neves*

Main category: cs.CV

TL;DR: 提出了SortWaste数据集和ClutterScore指标，用于评估废物分拣的视觉复杂性，并在塑料检测任务中取得59.7%的mAP，但高杂乱场景下性能下降。


<details>
  <summary>Details</summary>
Motivation: 废物管理中的自动分拣系统因缺乏真实世界数据集和视觉复杂性而发展不足。

Method: 提出了SortWaste数据集和ClutterScore指标，用于评估场景的视觉复杂性。

Result: 在塑料检测任务中达到59.7%的mAP，但在高杂乱场景中性能下降。

Conclusion: 尽管在塑料检测任务中取得了59.7%的mAP，但在高度杂乱的场景中性能显著下降，这表明需要更多具有挑战性的数据集。

Abstract: The increasing production of waste, driven by population growth, has created challenges in managing and recycling materials effectively. Manual waste sorting is a common practice; however, it remains inefficient for handling large-scale waste streams and presents health risks for workers. On the other hand, existing automated sorting approaches still struggle with the high variability, clutter, and visual complexity of real-world waste streams. The lack of real-world datasets for waste sorting is a major reason automated systems for this problem are underdeveloped. Accordingly, we introduce SortWaste, a densely annotated object detection dataset collected from a Material Recovery Facility. Additionally, we contribute to standardizing waste detection in sorting lines by proposing ClutterScore, an objective metric that gauges the scene's hardness level using a set of proxies that affect visual complexity (e.g., object count, class and size entropy, and spatial overlap). In addition to these contributions, we provide an extensive benchmark of state-of-the-art object detection models, detailing their results with respect to the hardness level assessed by the proposed metric. Despite achieving promising results (mAP of 59.7% in the plastic-only detection task), performance significantly decreases in highly cluttered scenes. This highlights the need for novel and more challenging datasets on the topic.

</details>


### [165] [360DVO: Deep Visual Odometry for Monocular 360-Degree Camera](https://arxiv.org/abs/2601.02309)
*Xiaopeng Guo,Yinzhe Xu,Huajian Huang,Sai-Kit Yeung*

Main category: cs.CV

TL;DR: 360DVO是首个基于深度学习的全向视觉里程计框架，通过DAS-Feat和ODBA模块显著提升了鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有基于手工特征或光度目标的方法在挑战性场景中鲁棒性不足，如剧烈运动和光照变化。

Method: 提出了一个包含失真感知球形特征提取器（DAS-Feat）和全向可微分束调整（ODBA）模块的深度学习框架。

Result: 在真实世界OVO基准和公开合成数据集上，360DVO在鲁棒性上提升50%，准确性上提升37.5%，超越了现有最佳基线。

Conclusion: 360DVO通过深度学习框架显著提升了单目全向视觉里程计（OVO）的鲁棒性和准确性，尤其在挑战性场景中表现优异。

Abstract: Monocular omnidirectional visual odometry (OVO) systems leverage 360-degree cameras to overcome field-of-view limitations of perspective VO systems. However, existing methods, reliant on handcrafted features or photometric objectives, often lack robustness in challenging scenarios, such as aggressive motion and varying illumination. To address this, we present 360DVO, the first deep learning-based OVO framework. Our approach introduces a distortion-aware spherical feature extractor (DAS-Feat) that adaptively learns distortion-resistant features from 360-degree images. These sparse feature patches are then used to establish constraints for effective pose estimation within a novel omnidirectional differentiable bundle adjustment (ODBA) module. To facilitate evaluation in realistic settings, we also contribute a new real-world OVO benchmark. Extensive experiments on this benchmark and public synthetic datasets (TartanAir V2 and 360VO) demonstrate that 360DVO surpasses state-of-the-art baselines (including 360VO and OpenVSLAM), improving robustness by 50% and accuracy by 37.5%. Homepage: https://chris1004336379.github.io/360DVO-homepage

</details>


### [166] [Prithvi-Complimentary Adaptive Fusion Encoder (CAFE): unlocking full-potential for flood inundation mapping](https://arxiv.org/abs/2601.02315)
*Saurabh Kaushik,Lalit Maurya,Beth Tellman*

Main category: cs.CV

TL;DR: Prithvi-CAFE通过结合GFM预训练编码器和CNN残差分支，在洪水映射任务中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 针对GFMs在洪水映射任务中难以捕捉关键局部细节的问题，提出了Prithvi-CAFE以提升性能。

Method: Prithvi-CAFE通过将Prithvi GFM预训练编码器与并行CNN残差分支结合，并增强卷积注意力模块（CAM），实现了快速高效的微调和多尺度、多层次特征融合。

Result: 在Sen1Flood11和FloodPlanet数据集上，Prithvi-CAFE均取得了最先进的结果，显著优于基线U-Net和其他GFMs。

Conclusion: Prithvi-CAFE展示了在需要多通道和多模态数据提供互补信息且局部细节至关重要的分割任务中的强大潜力。

Abstract: Geo-Foundation Models (GFMs), have proven effective in diverse downstream applications, including semantic segmentation, classification, and regression tasks. However, in case of flood mapping using Sen1Flood11 dataset as a downstream task, GFMs struggles to outperform the baseline U-Net, highlighting model's limitation in capturing critical local nuances. To address this, we present the Prithvi-Complementary Adaptive Fusion Encoder (CAFE), which integrate Prithvi GFM pretrained encoder with a parallel CNN residual branch enhanced by Convolutional Attention Modules (CAM). Prithvi-CAFE enables fast and efficient fine-tuning through adapters in Prithvi and performs multi-scale, multi-level fusion with CNN features, capturing critical local details while preserving long-range dependencies. We achieve state-of-the-art results on two comprehensive flood mapping datasets: Sen1Flood11 and FloodPlanet. On Sen1Flood11 test data, Prithvi-CAFE (IoU 83.41) outperforms the original Prithvi (IoU 82.50) and other major GFMs (TerraMind 82.90, DOFA 81.54, spectralGPT: 81.02). The improvement is even more pronounced on the hold-out test site, where Prithvi-CAFE achieves an IoU of 81.37 compared to the baseline U-Net (70.57) and original Prithvi (72.42). On FloodPlanet, Prithvi-CAFE also surpasses the baseline U-Net and other GFMs, achieving an IoU of 64.70 compared to U-Net (60.14), Terramind (62.33), DOFA (59.15) and Prithvi 2.0 (61.91). Our proposed simple yet effective Prithvi-CAFE demonstrates strong potential for improving segmentation tasks where multi-channel and multi-modal data provide complementary information and local details are critical. The code is released on \href{https://github.com/Sk-2103/Prithvi-CAFE}{Prithvi-CAFE Github}

</details>


### [167] [Fusion2Print: Deep Flash-Non-Flash Fusion for Contactless Fingerprint Matching](https://arxiv.org/abs/2601.02318)
*Roja Sahoo,Anoop Namboodiri*

Main category: cs.CV

TL;DR: F2P框架通过融合闪光与非闪光指纹图像，解决了无接触指纹识别中的脊线清晰度问题，显著提升了识别性能。


<details>
  <summary>Details</summary>
Motivation: 接触式指纹识别存在卫生和便利性问题，而无接触图像因光照变化和噪声导致脊线清晰度下降，需解决这一问题。

Method: 提出F2P框架，包括构建FNF数据库、手动闪光-非闪光减法、轻量级注意力融合网络、U-Net增强模块和深度嵌入模型。

Result: F2P在识别性能上表现优异（AUC=0.999，EER=1.12%），优于单捕获基线方法（Verifinger, DeepPrint）。

Conclusion: Fusion2Print (F2P) 框架通过融合闪光与非闪光接触式指纹图像，显著提升了指纹识别的清晰度和性能，实现了与接触式指纹兼容的统一嵌入空间。

Abstract: Contactless fingerprint recognition offers a hygienic and convenient alternative to contact-based systems, enabling rapid acquisition without latent prints, pressure artifacts, or hygiene risks. However, contactless images often show degraded ridge clarity due to illumination variation, subcutaneous skin discoloration, and specular reflections. Flash captures preserve ridge detail but introduce noise, whereas non-flash captures reduce noise but lower ridge contrast. We propose Fusion2Print (F2P), the first framework to systematically capture and fuse paired flash-non-flash contactless fingerprints. We construct a custom paired dataset, FNF Database, and perform manual flash-non-flash subtraction to isolate ridge-preserving signals. A lightweight attention-based fusion network also integrates both modalities, emphasizing informative channels and suppressing noise, and then a U-Net enhancement module produces an optimally weighted grayscale image. Finally, a deep embedding model with cross-domain compatibility, generates discriminative and robust representations in a unified embedding space compatible with both contactless and contact-based fingerprints for verification. F2P enhances ridge clarity and achieves superior recognition performance (AUC=0.999, EER=1.12%) over single-capture baselines (Verifinger, DeepPrint).

</details>


### [168] [BEDS: Bayesian Emergent Dissipative Structures](https://arxiv.org/abs/2601.02329)
*Laurent Caraffa*

Main category: cs.CV

TL;DR: BEDS框架通过统一热力学和贝叶斯推断，提出学习是熵输出驱动的结构形成过程，并在实践中显著提升了能效。


<details>
  <summary>Details</summary>
Motivation: 统一物理、生物和计算系统中的学习概念，探索可持续学习系统的本质。

Method: 基于Prigogine的耗散结构理论，建立了热力学过程与贝叶斯更新之间的形式同构，推导了数学常数（e, π, φ）作为贝叶斯推断的固定点，并提出猜想将哥德尔不完备定理与热力学约束联系起来。

Result: 提出了BEDS理论框架，并在对等网络架构中实现了比现有分布式共识系统高六个数量级的能效提升。

Conclusion: BEDS框架将非平衡热力学、贝叶斯推断、信息几何和机器学习统一起来，提出学习本质上是通过熵输出将通量转化为结构的过程。该理论不仅提供了对学习和计算本质的理论见解，还为可持续人工智能提供了具体路径。

Abstract: We present BEDS (Bayesian Emergent Dissipative Structures), a theoretical framework that unifies concepts from non-equilibrium thermodynamics, Bayesian inference, information geometry, and machine learning. The central thesis proposes that learning, across physical, biological, and computational systems, fundamentally constitutes the conversion of flux into structure through entropy export. Building on Prigogine's theory of dissipative structures, we establish a formal isomorphism between thermodynamic processes and Bayesian updating, demonstrating that sustainable learning systems must follow dissipative patterns where crystallized posteriors become priors for subsequent levels of emergence.
  We derive fundamental mathematical constants (e, π, φ) as fixed points of Bayesian inference under minimal axioms, suggesting these constants emerge necessarily from any system capable of representing and updating uncertainty. Furthermore, we propose a conjecture linking Gödel's incompleteness theorems to thermodynamic constraints, hypothesizing that pathologies of formal systems (incompleteness, undecidability) are structurally analogous to dissipation deficits in physical systems.
  As practical validation, we present a peer-to-peer network architecture implementing BEDS principles, achieving six orders of magnitude improvement in energy efficiency compared to existing distributed consensus systems while enabling continuous learning. This work bridges fundamental physics, mathematical logic, and practical system design, offering both theoretical insights into the nature of learning and computation, and a concrete pathway toward sustainable artificial intelligence.

</details>


### [169] [Joint Semantic and Rendering Enhancements in 3D Gaussian Modeling with Anisotropic Local Encoding](https://arxiv.org/abs/2601.02339)
*Jingming He,Chongyi Li,Shiqi Wang,Sam Kwong*

Main category: cs.CV

TL;DR: 提出了一种联合语义和渲染的3D高斯建模框架，通过新描述符和自适应策略提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法将语义和渲染分支分开处理，仅依赖2D监督而忽略3D高斯几何，且自适应策略仅依赖渲染梯度，导致在细微或无纹理区域表现不足。

Method: 引入了各向异性3D高斯切比雪夫描述符来捕捉细粒度3D形状细节，并通过局部语义和形状信号自适应调整高斯分配和球谐函数，还采用了跨场景知识转移模块。

Result: 在多个数据集上的实验表明，该方法在分割精度和渲染质量上均有提升，同时保持高渲染帧率。

Conclusion: 该论文提出了一种联合增强框架，通过结合语义和渲染分支，显著提升了3D语义高斯建模的分割精度和渲染质量，同时保持了高渲染帧率。

Abstract: Recent works propose extending 3DGS with semantic feature vectors for simultaneous semantic segmentation and image rendering. However, these methods often treat the semantic and rendering branches separately, relying solely on 2D supervision while ignoring the 3D Gaussian geometry. Moreover, current adaptive strategies adapt the Gaussian set depending solely on rendering gradients, which can be insufficient in subtle or textureless regions. In this work, we propose a joint enhancement framework for 3D semantic Gaussian modeling that synergizes both semantic and rendering branches. Firstly, unlike conventional point cloud shape encoding, we introduce an anisotropic 3D Gaussian Chebyshev descriptor using the Laplace-Beltrami operator to capture fine-grained 3D shape details, thereby distinguishing objects with similar appearances and reducing reliance on potentially noisy 2D guidance. In addition, without relying solely on rendering gradient, we adaptively adjust Gaussian allocation and spherical harmonics with local semantic and shape signals, enhancing rendering efficiency through selective resource allocation. Finally, we employ a cross-scene knowledge transfer module to continuously update learned shape patterns, enabling faster convergence and robust representations without relearning shape information from scratch for each new scene. Experiments on multiple datasets demonstrate improvements in segmentation accuracy and rendering quality while maintaining high rendering frame rates.

</details>


### [170] [Meta-Learning Guided Pruning for Few-Shot Plant Pathology on Edge Devices](https://arxiv.org/abs/2601.02353)
*Shahnawaz Alam,Mohammed Mudassir Uddin,Mohammed Kaif Pasha*

Main category: cs.CV

TL;DR: 论文结合模型剪枝和少样本学习，提出DACIS方法和PMP流程，显著减小模型大小并保持高准确率，使实时田间诊断在低成本设备上可行。


<details>
  <summary>Details</summary>
Motivation: 偏远地区农民缺乏实验室或高性能计算资源，现有深度学习模型在低成本边缘设备上运行困难且训练数据收集成本高。

Method: 论文提出了Disease-Aware Channel Importance Scoring (DACIS)方法，结合了三阶段的Prune-then-Meta-Learn-then-Prune (PMP)流程，通过识别神经网络中对区分植物病害最重要的部分，并进行剪枝和少样本学习。

Result: 在PlantVillage和PlantDoc数据集上的实验表明，该方法将模型大小减少了78%，同时保持了92.3%的原始准确率，压缩后的模型在Raspberry Pi 4上以每秒7帧的速度运行。

Conclusion: 该论文提出的DACIS方法和PMP流程有效解决了在资源受限设备上运行深度学习模型的挑战，通过模型剪枝和少样本学习的结合，显著减少了模型大小并保持了高准确率，为小农户提供了实用的实时田间诊断方案。

Abstract: Farmers in remote areas need quick and reliable methods for identifying plant diseases, yet they often lack access to laboratories or high-performance computing resources. Deep learning models can detect diseases from leaf images with high accuracy, but these models are typically too large and computationally expensive to run on low-cost edge devices such as Raspberry Pi. Furthermore, collecting thousands of labeled disease images for training is both expensive and time-consuming. This paper addresses both challenges by combining neural network pruning -- removing unnecessary parts of the model -- with few-shot learning, which enables the model to learn from limited examples. This paper proposes Disease-Aware Channel Importance Scoring (DACIS), a method that identifies which parts of the neural network are most important for distinguishing between different plant diseases, integrated into a three-stage Prune-then-Meta-Learn-then-Prune (PMP) pipeline. Experiments on PlantVillage and PlantDoc datasets demonstrate that the proposed approach reduces model size by 78\% while maintaining 92.3\% of the original accuracy, with the compressed model running at 7 frames per second on a Raspberry Pi 4, making real-time field diagnosis practical for smallholder farmers.

</details>


### [171] [Talk2Move: Reinforcement Learning for Text-Instructed Object-Level Geometric Transformation in Scenes](https://arxiv.org/abs/2601.02356)
*Jing Tan,Zhaoyang Zhang,Yantao Shen,Jiarui Cai,Shuo Yang,Jiajun Wu,Wei Xia,Zhuowen Tu,Stefano Soatto*

Main category: cs.CV

TL;DR: Talk2Move 是一个基于强化学习的扩散框架，通过 GRPO 和空间奖励模型实现文本指令下的目标空间变换，无需配对数据且效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 自然语言指令下的目标空间变换是多模态生成系统的挑战，现有方法在目标级几何变换（如平移、旋转或缩放）上表现不佳。

Method: Talk2Move 采用 Group Relative Policy Optimization (GRPO) 和空间奖励模型，通过多样化 rollout 和轻量级文本变体探索几何动作，无需昂贵的配对数据。

Result: 在精选基准测试中，Talk2Move 实现了精确、一致且语义忠实的目标变换，表现优于现有方法。

Conclusion: Talk2Move 通过 GRPO 和空间奖励模型实现了精确、一致且语义忠实的目标变换，在空间准确性和场景连贯性上优于现有文本引导编辑方法。

Abstract: We introduce Talk2Move, a reinforcement learning (RL) based diffusion framework for text-instructed spatial transformation of objects within scenes. Spatially manipulating objects in a scene through natural language poses a challenge for multimodal generation systems. While existing text-based manipulation methods can adjust appearance or style, they struggle to perform object-level geometric transformations-such as translating, rotating, or resizing objects-due to scarce paired supervision and pixel-level optimization limits. Talk2Move employs Group Relative Policy Optimization (GRPO) to explore geometric actions through diverse rollouts generated from input images and lightweight textual variations, removing the need for costly paired data. A spatial reward guided model aligns geometric transformations with linguistic description, while off-policy step evaluation and active step sampling improve learning efficiency by focusing on informative transformation stages. Furthermore, we design object-centric spatial rewards that evaluate displacement, rotation, and scaling behaviors directly, enabling interpretable and coherent transformations. Experiments on curated benchmarks demonstrate that Talk2Move achieves precise, consistent, and semantically faithful object transformations, outperforming existing text-guided editing approaches in both spatial accuracy and scene coherence.

</details>


### [172] [VINO: A Unified Visual Generator with Interleaved OmniModal Context](https://arxiv.org/abs/2601.02358)
*Junyi Chen,Tong He,Zhoujie Fu,Pengfei Wan,Kun Gai,Weicai Ye*

Main category: cs.CV

TL;DR: VINO是一个统一的视觉生成器，通过共享扩散主干和交错条件令牌实现图像和视频的生成与编辑，展示了高效且高质量的视觉创作能力。


<details>
  <summary>Details</summary>
Motivation: 旨在通过单一框架实现图像和视频的生成与编辑，避免依赖任务特定模型或独立模块，提升视觉创作的效率和质量。

Method: VINO结合了视觉语言模型（VLM）与多模态扩散变换器（MMDiT），通过多阶段训练流程逐步扩展视频生成基础模型，支持多参考基础、长指令跟随及跨静态和动态内容的一致性身份保持。

Result: VINO在多样化的生成和编辑基准测试中展现出强大的视觉质量、准确的指令跟随、改进的参考和属性保持能力，以及更可控的多身份编辑。

Conclusion: VINO展示了实现可扩展统一视觉生成的实用路径，并突出了交错上下文计算作为通用视觉创作基础的潜力。

Abstract: We present VINO, a unified visual generator that performs image and video generation and editing within a single framework. Instead of relying on task-specific models or independent modules for each modality, VINO uses a shared diffusion backbone that conditions on text, images and videos, enabling a broad range of visual creation and editing tasks under one model. Specifically, VINO couples a vision-language model (VLM) with a Multimodal Diffusion Transformer (MMDiT), where multimodal inputs are encoded as interleaved conditioning tokens, and then used to guide the diffusion process. This design supports multi-reference grounding, long-form instruction following, and coherent identity preservation across static and dynamic content, while avoiding modality-specific architectural components. To train such a unified system, we introduce a multi-stage training pipeline that progressively expands a video generation base model into a unified, multi-task generator capable of both image and video input and output. Across diverse generation and editing benchmarks, VINO demonstrates strong visual quality, faithful instruction following, improved reference and attribute preservation, and more controllable multi-identity edits. Our results highlight a practical path toward scalable unified visual generation, and the promise of interleaved, in-context computation as a foundation for general-purpose visual creation.

</details>


### [173] [ExposeAnyone: Personalized Audio-to-Expression Diffusion Models Are Robust Zero-Shot Face Forgery Detectors](https://arxiv.org/abs/2601.02359)
*Kaede Shiohara,Toshihiko Yamasaki,Vladislav Golyanik*

Main category: cs.CV

TL;DR: ExposeAnyone是一种自监督扩散模型方法，通过音频生成表情序列并计算身份距离，有效检测未知深度伪造，性能优于现有方法且对干扰鲁棒。


<details>
  <summary>Details</summary>
Motivation: 现有深度伪造检测方法难以泛化到未知伪造类型，主要依赖监督训练导致过拟合。自监督方法虽有潜力，但现有工作难以仅通过自监督学习到判别性表示。

Method: 提出ExposeAnyone，一种基于扩散模型的完全自监督方法，通过音频生成表情序列，并利用参考集对特定对象进行个性化建模，通过扩散重建误差计算身份距离。

Result: 1) 在DF-TIMIT、DFDCP、KoDF和IDForge数据集上平均AUC比现有最优方法高4.22个百分点；2) 能检测Sora2生成的视频；3) 对模糊和压缩等干扰具有高鲁棒性。

Conclusion: ExposeAnyone 是一种基于扩散模型的完全自监督方法，通过音频生成表情序列，并在个性化到特定对象后，通过扩散重建误差计算身份距离，实现了对未知深度伪造的有效检测。该方法在多个数据集上表现优异，并能检测Sora2生成的视频，展现了在真实世界中的高鲁棒性。

Abstract: Detecting unknown deepfake manipulations remains one of the most challenging problems in face forgery detection. Current state-of-the-art approaches fail to generalize to unseen manipulations, as they primarily rely on supervised training with existing deepfakes or pseudo-fakes, which leads to overfitting to specific forgery patterns. In contrast, self-supervised methods offer greater potential for generalization, but existing work struggles to learn discriminative representations only from self-supervision. In this paper, we propose ExposeAnyone, a fully self-supervised approach based on a diffusion model that generates expression sequences from audio. The key idea is, once the model is personalized to specific subjects using reference sets, it can compute the identity distances between suspected videos and personalized subjects via diffusion reconstruction errors, enabling person-of-interest face forgery detection. Extensive experiments demonstrate that 1) our method outperforms the previous state-of-the-art method by 4.22 percentage points in the average AUC on DF-TIMIT, DFDCP, KoDF, and IDForge datasets, 2) our model is also capable of detecting Sora2-generated videos, where the previous approaches perform poorly, and 3) our method is highly robust to corruptions such as blur and compression, highlighting the applicability in real-world face forgery detection.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [174] [PyBatchRender: A Python Library for Batched 3D Rendering at Up to One Million FPS](https://arxiv.org/abs/2601.01288)
*Evgenii Rudakov,Jonathan Shock,Benjamin Ultan Cowley*

Main category: cs.GR

TL;DR: PyBatchRender 是一个高性能 Python 3D 渲染库，专为强化学习优化，提供简单易用的批处理渲染，性能远超现有工具。


<details>
  <summary>Details</summary>
Motivation: 解决现有 3D 渲染环境在性能和复杂性上的瓶颈，为强化学习研究者提供更高效、灵活的工具。

Method: 基于 Panda3D 游戏引擎，通过优化的批处理渲染技术实现高达 1000 倍的加速，支持完全用 Python 快速构建自定义场景。

Result: PyBatchRender 在简单场景下实现了超过 100 万 FPS 的渲染速度，性能媲美最先进的 C++ 引擎。

Conclusion: PyBatchRender 是一个高性能的 Python 3D 渲染库，专为强化学习设计，提供了高吞吐量和易用性，填补了现有工具的性能与复杂性之间的空白。

Abstract: Reinforcement learning from pixels is often bottlenecked by the performance and complexity of 3D rendered environments. Researchers face a trade-off between high-speed, low-level engines and slower, more accessible Python frameworks. To address this, we introduce PyBatchRender, a Python library for high-throughput, batched 3D rendering that achieves over 1 million FPS on simple scenes. Built on the Panda3D game engine, it utilizes its mature ecosystem while enhancing performance through optimized batched rendering for up to 1000X speedups. Designed as a physics-agnostic renderer for reinforcement learning from pixels, PyBatchRender offers greater flexibility than dedicated libraries, simpler setup than typical game-engine wrappers, and speeds rivaling state-of-the-art C++ engines like Madrona. Users can create custom scenes entirely in Python with tens of lines of code, enabling rapid prototyping for scalable AI training. Open-source and easy to integrate, it serves to democratize high-performance 3D simulation for researchers and developers. The library is available at https://github.com/dolphin-in-a-coma/PyBatchRender.

</details>


### [175] [VARTS: A Tool for the Visualization and Analysis of Representative Time Series Data](https://arxiv.org/abs/2601.01361)
*Duosi Jin,Jianqiu Xu,Guidong Zhang*

Main category: cs.GR

TL;DR: VARTS是一款交互式可视化工具，通过M4采样、DTW相似度和贪婪选择，帮助用户从大规模时间序列中选择代表性数据并可视化，提升分析效率。


<details>
  <summary>Details</summary>
Motivation: 大规模时间序列可视化常因视觉混乱和冗余模式而难以理解主要时间趋势。

Method: VARTS结合了M4采样、DTW相似度计算和贪婪选择，提供了一个响应式图形界面，支持用户导入数据、执行代表性选择并通过多视图可视化原始和简化数据。

Result: VARTS成功减少了冗余并保留了关键数据模式，增强了大规模时间序列分析的视觉清晰度和可解释性。

Conclusion: VARTS通过整合M4采样、DTW相似度计算和贪婪选择，有效提升了大规模时间序列数据的视觉清晰度和可解释性。

Abstract: Large-scale time series visualization often suffers from excessive visual clutter and redundant patterns, making it difficult for users to understand the main temporal trends. To address this challenge, we present VARTS, an interactive visual analytics tool for representative time series selection and visualization. Building upon our previous work M4-Greedy, VARTS integrates M4-based sampling, DTW-based similarity computation, and greedy selection into a unified workflow for the identification and visualization of representative series. The tool provides a responsive graphical interface that allows users to import time series datasets, perform representative selection, and visualize both raw and reduced data through multiple coordinated views. By reducing redundancy while preserving essential data patterns, VARTS effectively enhances visual clarity and interpretability for large-scale time series analysis. The demo video is available at https://youtu.be/mS9f12Rf0jo.

</details>


### [176] [SketchRodGS: Sketch-based Extraction of Slender Geometries for Animating Gaussian Splatting Scenes](https://arxiv.org/abs/2601.02072)
*Haato Watanabe,Nobuyuki Umetani*

Main category: cs.GR

TL;DR: 本文提出了一种从高斯泼溅中提取细长物体多段线的方法，通过用户草图和动态编程实现稳健构建。


<details>
  <summary>Details</summary>
Motivation: 高斯泼溅缺乏连接信息且高斯基元配置包含大量噪声，难以直接构建多段线表示。

Method: 采用动态编程高效解决的屏幕空间最短路径分析，从高斯泼溅场景中提取细长物体的多段线表示。

Result: 在多个实际场景中验证了该方法的有效性。

Conclusion: 本文提出了一种从高斯泼溅场景中提取细长物体多段线表示的有效方法，通过用户草图输入和屏幕空间最短路径分析，能够稳健地构建代表细长部分的多段线网格。

Abstract: Physics simulation of slender elastic objects often requires discretization as a polyline. However, constructing a polyline from Gaussian splatting is challenging as Gaussian splatting lacks connectivity information and the configuration of Gaussian primitives contains much noise. This paper presents a method to extract a polyline representation of the slender part of the objects in a Gaussian splatting scene from the user's sketching input. Our method robustly constructs a polyline mesh that represents the slender parts using the screen-space shortest path analysis that can be efficiently solved using dynamic programming. We demonstrate the effectiveness of our approach in several in-the-wild examples.

</details>


### [177] [Dancing Points: Synthesizing Ballroom Dancing with Three-Point Inputs](https://arxiv.org/abs/2601.02096)
*Peizhuo Li,Sebastian Starke,Yuting Ye,Olga Sorkine-Hornung*

Main category: cs.GR

TL;DR: 使用VR三点轨迹简化舞者运动建模，通过MLP预测跟随者轨迹，并在多样化数据集上验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决舞者间高维度全身运动交互建模的挑战，简化运动描述与合成。

Method: 利用VR设备的三点轨迹作为运动描述符，采用高效的MLP网络预测跟随者轨迹，并通过确定性神经网络将轨迹转换为虚拟化身。

Result: 方法在结构化舞蹈数据集（如ballroom dancing）和多样化数据集（如LaFAN）上均表现稳健，提供了一种计算和数据高效的解决方案。

Conclusion: 该论文提出了一种使用VR设备的三点轨迹作为舞者运动描述符的方法，简化了舞者间全身运动的建模与合成。通过低维度和高效MLP网络，成功预测跟随者的三点轨迹，并展示了该方法在更广泛数据集上的泛化能力。

Abstract: Ballroom dancing is a structured yet expressive motion category. Its highly diverse movement and complex interactions between leader and follower dancers make the understanding and synthesis challenging. We demonstrate that the three-point trajectory available from a virtual reality (VR) device can effectively serve as a dancer's motion descriptor, simplifying the modeling and synthesis of interplay between dancers' full-body motions down to sparse trajectories. Thanks to the low dimensionality, we can employ an efficient MLP network to predict the follower's three-point trajectory directly from the leader's three-point input for certain types of ballroom dancing, addressing the challenge of modeling high-dimensional full-body interaction. It also prevents our method from overfitting thanks to its compact yet explicit representation. By leveraging the inherent structure of the movements and carefully planning the autoregressive procedure, we show a deterministic neural network is able to translate three-point trajectories into a virtual embodied avatar, which is typically considered under-constrained and requires generative models for common motions. In addition, we demonstrate this deterministic approach generalizes beyond small, structured datasets like ballroom dancing, and performs robustly on larger, more diverse datasets such as LaFAN. Our method provides a computationally- and data-efficient solution, opening new possibilities for immersive paired dancing applications. Code and pre-trained models for this paper are available at https://peizhuoli.github.io/dancing-points.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [178] [The cost of cyclic permutations and remainder sums in the Euclidean algorithm](https://arxiv.org/abs/2601.00979)
*Valentin Blomer,Kai-Uwe Bux*

Main category: cs.DS

TL;DR: 论文改进了Gries-Mills块交换方案，优化了原地旋转的平均性能至1.85次移动/元素，最坏情况仍为3次移动/元素。


<details>
  <summary>Details</summary>
Motivation: 改进现有的Gries-Mills块交换方案，以提高原地旋转的平均性能。

Method: 通过分析欧几里得算法中余数和的渐近行为，研究了平均情况下的性能。

Result: 改进后的方案实现了平均每个元素1.85次移动的性能，同时保持了最坏情况下3次移动的上限。

Conclusion: 该论文提出了一种改进的Gries-Mills块交换方案，用于原地旋转，平均成本为每个元素1.85次移动，最坏情况下仍为每个元素3次移动。

Abstract: We discuss a modification to the Gries-Mills block swapping scheme for in-place rotation with average costs of 1.85 moves per element and worst case performance still at 3 moves per element. Analysis of the average case relies on the asymptotic behavior of the sum of remainders in the Euclidean algorithm.

</details>


### [179] [AGIS: Fast Approximate Graph Pattern Mining with Structure-Informed Sampling](https://arxiv.org/abs/2601.01388)
*Seoyong Lee,Jinho Lee*

Main category: cs.DS

TL;DR: AGIS通过非均匀采样技术显著提升图模式挖掘效率，成为首个能处理超大规模图数据的AGPM系统。


<details>
  <summary>Details</summary>
Motivation: 现有基于采样的AGPM系统依赖均匀采样，忽略了潜在概率分布，限制了其对更广泛模式的可扩展性。

Method: AGIS采用结构通知的邻居采样技术，通过推导理想采样分布并提出实用近似方法，平衡收敛速度与计算开销。

Result: 实验结果显示，AGIS在几何平均速度上显著优于现有技术，特定情况下速度提升超过100,000倍，并能处理数百亿边图。

Conclusion: AGIS是一种极快的近似图模式挖掘系统，能够处理大规模图数据，并在几秒内提供准确估计。该系统通过结构通知的邻居采样技术显著提升了性能，且是唯一能扩展到数百亿边图的AGPM系统。

Abstract: Approximate Graph Pattern Mining (AGPM) is essential for analyzing large-scale graphs where exact counting is computationally prohibitive. While there exist numerous sampling-based AGPM systems, they all rely on uniform sampling and overlook the underlying probability distribution. This limitation restricts their scalability to a broader range of patterns.
  In this paper, we introduce AGIS, an extremely fast AGPM system capable of counting arbitrary patterns from huge graphs. AGIS employs structure-informed neighbor sampling, a novel sampling technique that deviates from uniformness but allocates specific sampling probabilities based on the pattern structure. We first derive the ideal sampling distribution for AGPM and then present a practical method to approximate it. Furthermore, we develop a method that balances convergence speed and computational overhead, determining when to use the approximated distribution.
  Experimental results demonstrate that AGIS significantly outperforms the state-of-the-art AGPM system, achieving 28.5x geometric mean speedup and more than 100,000x speedup in specific cases. Furthermore, AGIS is the only AGPM system that scales to graphs with tens of billions of edges and robustly handles diverse patterns, successfully providing accurate estimates within seconds. We will open-source AGIS to encourage further research in this field.

</details>


### [180] [Derandomizing Pseudopolynomial Algorithms for Subset Sum](https://arxiv.org/abs/2601.01390)
*Timothy M. Chan*

Main category: cs.DS

TL;DR: 提出了首个$\widetilde{O}(t)$时间的确定性算法解决子集和问题，并展示了技术的广泛应用。


<details>
  <summary>Details</summary>
Motivation: 重新审视经典子集和问题，旨在提升现有确定性算法的效率，达到与随机算法相当的时间复杂度。

Method: 采用动态编程技术，结合最新的确定性算法改进，实现了$\widetilde{O}(t)$的时间复杂度。

Result: 成功开发出运行时间为$\widetilde{O}(t)$的确定性算法，并展示了该技术在多个其他问题中的应用。

Conclusion: 本文提出了第一个确定性算法，运行时间为$\widetilde{O}(t)$，解决了经典子集和问题，并展示了该技术的其他应用。

Abstract: We reexamine the classical subset sum problem: given a set $X$ of $n$ positive integers and a number $t$, decide whether there exists a subset of $X$ that sums to $t$; or more generally, compute the set $\mbox{out}$ of all numbers $y\in\{0,\ldots,t\}$ for which there exists a subset of $X$ that sums to $y$. Standard dynamic programming solves the problem in $O(tn)$ time. In SODA'17, two papers appeared giving the current best deterministic and randomized algorithms, ignoring polylogarithmic factors: Koiliaris and Xu's deterministic algorithm runs in $\widetilde{O}(t\sqrt{n})$ time, while Bringmann's randomized algorithm runs in $\widetilde{O}(t)$ time. We present the first deterministic algorithm running in $\widetilde{O}(t)$ time.
  Our technique has a number of other applications: for example, we can also derandomize the more recent output-sensitive algorithms by Bringmann and Nakos [STOC'20] and Bringmann, Fischer, and Nakos [SODA'25] running in $\widetilde{O}(|\mbox{out}|^{4/3})$ and $\widetilde{O}(|\mbox{out}|\sqrt{n})$ time, and we can derandomize a previous fine-grained reduction from 0-1 knapsack to min-plus convolution by Cygan et al. [ICALP'17].

</details>


### [181] [Publishing Below-Threshold Triangle Counts under Local Weight Differential Privacy](https://arxiv.org/abs/2601.01710)
*Kevin Pfisterer,Quentin Hillebrand,Vorapong Suppakitpaisarn*

Main category: cs.DS

TL;DR: 论文提出了一种在加权图中保护隐私的算法，通过两轮通信计算低于阈值三角形，并展示了有偏和无偏变体的差异及改进效果。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的网络（如道路网络和电信网络）通常包含边权重，而现有研究主要集中在无权图上。因此，需要一种算法在保护个体对边权重隐私的同时，计算加权图中的低于阈值三角形。

Method: 采用两轮通信方法：第一轮，每个节点在本地权重差分隐私下发布其关联的权重信息；第二轮，节点本地计算低于阈值的三角形，并引入了有偏和无偏两种变体。此外，提出了预计算步骤和计算平滑敏感度的算法以减少误差和运行时间。

Result: 实验证明了有偏和无偏变体之间的差异，预计算步骤和平滑敏感度算法的有效性，显著降低了误差和运行时间。

Conclusion: 论文提出了一种在加权图中计算低于阈值三角形的算法，通过本地权重差分隐私保护个体对边权重的影响隐私。实验结果表明了有偏和无偏变体之间的差异以及所提改进的有效性。

Abstract: We propose an algorithm for counting below-threshold triangles in weighted graphs under local weight differential privacy. While prior work focused on unweighted graphs, many real-world networks naturally include edge weights. We study the setting where the graph topology is public known and the privacy of the influence of an individual on the edge weights is protected. This captures realistic scenarios such as road networks and telecommunication networks. Our approach consists of two rounds of communication. In the first round, each node publishes their incident weight information under local weight differential privacy while in the second round, the nodes locally count below-threshold triangles, for which we introduce a biased and unbiased variant. We further propose two different improvements. We present a pre-computation step that reduces the covariance and thereby lowers the expected error. Secondly, we develop an algorithm for computing the smooth-sensitivity, which significantly reduces the running time compared to a straightforward approach. Finally, we provide experimental results that demonstrate the differences between the biased and unbiased variants and the effectiveness of the proposed improvements.

</details>


### [182] [Improved Approximation Algorithms for the Multiple-Depot Split Delivery Vehicle Routing Problem](https://arxiv.org/abs/2601.01841)
*Jingyang Zhao,Yonghang Su,Mingyu Xiao*

Main category: cs.DS

TL;DR: 本文针对多仓库分割配送车辆路径问题，提出了改进的近似算法，解决了固定数量仓库的开放性问题，并扩展了算法的适用范围。


<details>
  <summary>Details</summary>
Motivation: MD-SDVRP是物流领域中的一个重要问题，现有研究仅提供了固定数量仓库的6-近似算法，且是否能够改进这一比率仍是一个开放性问题。本文旨在解决这一问题并扩展算法的适用范围。

Method: 研究采用了近似算法的方法，针对MD-SDVRP问题设计了多种算法，包括改进的近似算法、参数化近似算法和双因子近似算法。

Result: 本文成功提出了$(6-2\cdot 10^{-36})$-近似算法，解决了固定数量仓库的开放性问题，并开发了适用于非固定数量仓库的常数因子近似算法，改进了参数化近似算法，并提出了双因子近似算法。

Conclusion: 本文提出了针对多仓库分割配送车辆路径问题（MD-SDVRP）的改进近似算法，包括针对固定数量仓库的$(6-2\cdot 10^{-36})$-近似算法，以及适用于非固定数量仓库的常数因子近似算法，还改进了与车辆容量和仓库数量相关的参数化近似算法，并提出了双因子近似算法。

Abstract: The Multiple-Depot Split Delivery Vehicle Routing Problem (MD-SDVRP) is a challenging problem with broad applications in logistics. The goal is to serve customers' demand using a fleet of capacitated vehicles located in multiple depots, where each customer's demand can be served by more than one vehicle, while minimizing the total travel cost of all vehicles. We study approximation algorithms for this problem. Previously, the only known result was a $6$-approximation algorithm for a constant number of depots (INFORMS J. Comput. 2023), and whether this ratio could be improved was left as an open question. In this paper, we resolve it by proposing a $(6-2\cdot 10^{-36})$-approximation algorithm for this setting. Moreover, we develop constant-factor approximation algorithms that work beyond a constant number of depots, improved parameterized approximation algorithms related to the vehicle capacity and the number of depots, as well as bi-factor approximation algorithms.

</details>


### [183] [Exact Clique Number Manipulation via Edge Interdiction](https://arxiv.org/abs/2601.01869)
*Yi Zhou,Haoyu Jiang,Chenghao Zhu,André Rossi*

Main category: cs.DS

TL;DR: 论文提出RLCM算法，通过重构问题和两阶段优化，显著提升了EICP问题的求解效率。


<details>
  <summary>Details</summary>
Motivation: EICP问题在蛋白质功能维护和图像匹配等实际应用中具有重要意义，但现有方法在图形规模和预算k增长时难以扩展。

Method: 通过将问题重新表述为参数化的Edge Blocker Clique Problems（EBCP）序列，并设计了两阶段算法RLCM，结合问题特定的缩减技术和定制的分支切割框架。

Result: RLCM算法在最大团基准图、大型真实稀疏网络和随机图上均优于现有方法。

Conclusion: 论文提出了一种新的混合整数线性规划公式和两阶段精确算法RLCM，显著提升了Edge Interdiction Clique Problem（EICP）的计算效率，并在多种图上验证了其优越性。

Abstract: The Edge Interdiction Clique Problem (EICP) aims to remove at most $k$ edges from a graph so as to minimize the size of the largest clique in the remaining graph. This problem captures a fundamental question in graph manipulation: which edges are structurally critical for preserving large cliques? Such a problem is also motivated by practical applications including protein function maintenance and image matching. The EICP is computationally challenging and belongs to a complexity class beyond NP. Existing approaches rely on general mixed-integer bilevel programming solvers or reformulate the problem into a single-level mixed integer linear program. However, they are still not scalable when the graph size and interdiction budget $k$ grow. To overcome this, we investigate new mixed integer linear formulations, which recast the problem into a sequence of parameterized Edge Blocker Clique Problems (EBCP). This perspective decomposes the original problem into simpler subproblems and enables tighter modeling of clique-related inequalities. Furthermore, we propose a two-stage exact algorithm, \textsc{RLCM}, which first applies problem-specific reduction techniques to shrink the graph and then solves the reduced problem using a tailored branch-and-cut framework. Extensive computational experiments on maximum clique benchmark graphs, large real-world sparse networks, and random graphs demonstrate that \textsc{RLCM} consistently outperforms existing approaches.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [184] [A Multi-Port Concurrent Communication Model for handling Compute Intensive Tasks on Distributed Satellite System Constellations](https://arxiv.org/abs/2601.01031)
*Bharadwaj Veeravalli*

Main category: cs.DC

TL;DR: Developed an MPCC-DLT framework for DSS, optimizing load allocation and completion time, with practical extensions for real-time task handling.


<details>
  <summary>Details</summary>
Motivation: To address the challenges of concurrent data dissemination, parallel computation, and result return in heterogeneous onboard processing and inter-satellite link conditions within distributed satellite systems.

Method: The authors propose a formulation with closed-form expressions for optimal load allocation and completion time, considering computation speed, link bandwidth, and result-size overhead. They also derive deadline feasibility conditions and extend the framework with a real-time admission control mechanism.

Result: Simulations show latency reduction for distributable tasks but diminishing returns for communication-heavy tasks due to overheads. The extended framework effectively handles stochastic task arrivals and deadlines.

Conclusion: This work presents the first analytically tractable MPCC-DLT model for DSS, offering practical insights for application-aware scheduling and system-level design of future satellite constellations.

Abstract: We develop an integrated Multi-Port Concurrent Communication Divisible Load Theory (MPCC-DLT) framework for relay-centric distributed satellite systems (DSS), capturing concurrent data dissemination, parallel computation, and result return under heterogeneous onboard processing and inter-satellite link conditions. We propose a formulation that yields closed-form expressions for optimal load allocation and completion time that explicitly quantify the joint impact of computation speed, link bandwidth, and result-size overhead. We further derive deadline feasibility conditions that enable explicit sizing of cooperative satellite clusters to meet time-critical task requirements. Extensive simulation results demonstrate that highly distributable tasks achieve substantial latency reduction, while communication-heavy tasks exhibit diminishing returns due to result-transfer overheads. To bridge theory and practice, we extend the MPCC-DLT framework with a real-time admission control mechanism that handles stochastic task arrivals and deadline constraints, enabling blocking-aware operation. Our real-time simulations illustrate how task structure and system parameters jointly govern deadline satisfaction and operating regimes. Overall, this work provides the first analytically tractable MPCC-DLT model for distributed satellite systems and offers actionable insights for application-aware scheduling and system-level design of future satellite constellations.

</details>


### [185] [Performance and Security Aware Distributed Service Placement in Fog Computing](https://arxiv.org/abs/2601.01125)
*Mohammad Goudarzi,Arash Shaghaghi,Zhiyu Wang,Rajkumar Buyya*

Main category: cs.DC

TL;DR: SPA-DDRL框架通过分布式深度强化学习优化雾计算中的服务部署，兼顾响应时间和安全性，实验显示性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 解决雾计算中异构资源、动态工作负载和多样化安全需求带来的服务部署挑战。

Method: 采用分布式深度强化学习框架，结合长短期记忆网络、优先经验回放和离策略校正机制。

Result: 实验表明，SPA-DDRL在响应时间和安全性方面均优于现有方法，且在所有系统规模下均能保持一致的性能。

Conclusion: SPA-DDRL框架显著提升了雾计算中的服务响应时间和安全性，相比现有方法，响应时间改善了16.3%，收敛速度提高了33%。

Abstract: The rapid proliferation of IoT applications has intensified the demand for efficient and secure service placement in Fog computing. However, heterogeneous resources, dynamic workloads, and diverse security requirements make optimal service placement highly challenging. Most solutions focus primarily on performance metrics while overlooking the security implications of deployment decisions. This paper proposes a Security and Performance-Aware Distributed Deep Reinforcement Learning (SPA-DDRL) framework for joint optimization of service response time and security compliance in Fog computing. The problem is formulated as a weighted multi-objective optimization task, minimizing latency while maximizing a security score derived from the security capabilities of Fog nodes. The security score features a new three-tier hierarchy, where configuration-level checks verify proper settings, capability-level assessments evaluate the resource security features, and control-level evaluations enforce stringent policies, thereby ensuring compliant solutions that align with performance objectives. SPA-DDRL adopts a distributed broker-learner architecture where multiple brokers perform autonomous service-placement decisions and a centralized learner coordinates global policy optimization through shared prioritized experiences. It integrates three key improvements, including Long Short-Term Memory networks, Prioritized Experience Replay, and off-policy correction mechanisms to improve the agent's performance. Experiments based on real IoT workloads show that SPA-DDRL significantly improves both service response time and placement security compared to current approaches, achieving a 16.3% improvement in response time and a 33% faster convergence rate. It also maintains consistent, feasible, security-compliant solutions across all system scales, while baseline techniques fail or show performance degradation.

</details>


### [186] [OrchestrRL: Dynamic Compute and Network Orchestration for Disaggregated RL](https://arxiv.org/abs/2601.01209)
*Xin Tan,Yicheng Feng,Yu Zhou,Yimin Jiang,Yibo Zhu,Hong Xu*

Main category: cs.DC

TL;DR: OrchestrRL和RFabric通过动态调整计算和网络资源，显著提升分解式强化学习的效率和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 分解式强化学习中的生成阶段成为瓶颈，且网络流量模式动态变化，传统网络架构难以应对。

Method: OrchestrRL采用自适应计算调度器动态调整并行度，RFabric则通过可重构混合光电网络实时调整拓扑结构。

Result: 实验证明OrchestrRL在48个H800 GPU上实现了1.40倍的吞吐量提升，RFabric在性能和成本效率上优于静态Fat-Tree网络。

Conclusion: OrchestrRL和RFabric的结合显著提升了分解式强化学习的效率和可扩展性，特别是在大规模GPU集群中。

Abstract: Post-training with reinforcement learning (RL) has greatly enhanced the capabilities of large language models. Disaggregating the generation and training stages in RL into a parallel, asynchronous pipeline offers the potential for flexible scaling and improved throughput. However, it still faces two critical challenges. First, the generation stage often becomes a bottleneck due to dynamic workload shifts and severe execution imbalances. Second, the decoupled stages result in diverse and dynamic network traffic patterns that overwhelm conventional network fabrics. This paper introduces OrchestrRL, an orchestration framework that dynamically manages compute and network rhythms in disaggregated RL. To improve generation efficiency, OrchestrRL employs an adaptive compute scheduler that dynamically adjusts parallelism to match workload characteristics within and across generation steps. This accelerates execution while continuously rebalancing requests to mitigate stragglers. To address the dynamic network demands inherent in disaggregated RL -- further intensified by parallelism switching -- we co-design RFabric, a reconfigurable hybrid optical-electrical fabric. RFabric leverages optical circuit switches at selected network tiers to reconfigure the topology in real time, enabling workload-aware circuits for (i) layer-wise collective communication during training iterations, (ii) generation under different parallelism configurations, and (iii) periodic inter-cluster weight synchronization. We evaluate OrchestrRL on a physical testbed with 48 H800 GPUs, demonstrating up to a 1.40x throughput improvement. Furthermore, we develop RLSim, a high-fidelity simulator, to evaluate RFabric at scale. Our results show that RFabric achieves superior performance-cost efficiency compared to static Fat-Tree networks, establishing it as a highly effective solution for large-scale RL workloads.

</details>


### [187] [Making MoE based LLM inference resilient with Tarragon](https://arxiv.org/abs/2601.01310)
*Songyu Zhang,Aaron Tam,Myungjin Lee,Shixiong Qi,K. K. Ramakrishnan*

Main category: cs.DC

TL;DR: Tarragon是一个容错的MoE推理框架，通过分离故障域和自愈机制，显著减少故障导致的停滞时间。


<details>
  <summary>Details</summary>
Motivation: 现有系统在MoE模型部署中，单个工作节点故障会触发整个服务的重启，导致累积进度丢失和推理管道停滞，这对延迟敏感的LLM服务不适用。

Method: Tarragon通过可重构的数据路径和自愈机制，分离注意力工作者（AWs）和专家工作者（EWs）的故障域，并采用异步KV缓存检查点和影子专家技术来降低恢复成本。

Result: 与MegaScale-Infer相比，Tarragon将故障导致的停滞时间减少了160-213倍（从约64秒降至0.3-0.4秒），且在无故障时性能保持不变。

Conclusion: Tarragon显著提升了MoE模型的容错能力，将故障影响限制在单个工作节点，同时保持推理管道的持续进展，极大减少了故障导致的停滞时间。

Abstract: Mixture-of-Experts (MoE) models are increasingly used to serve LLMs at scale, but failures become common as deployment scale grows. Existing systems exhibit poor failure resilience: even a single worker failure triggers a coarse-grained, service-wide restart, discarding accumulated progress and halting the entire inference pipeline during recovery--an approach clearly ill-suited for latency-sensitive, LLM services.
  We present Tarragon, a resilient MoE inference framework that confines the failures impact to individual workers while allowing the rest of the pipeline to continue making forward progress. Tarragon exploits the natural separation between the attention and expert computation in MoE-based transformers, treating attention workers (AWs) and expert workers (EWs) as distinct failure domains. Tarragon introduces a reconfigurable datapath to mask failures by rerouting requests to healthy workers. On top of this datapath, Tarragon implements a self-healing mechanism that relaxes the tightly synchronized execution of existing MoE frameworks. For stateful AWs, Tarragon performs asynchronous, incremental KV cache checkpointing with per-request restoration, and for stateless EWs, it leverages residual GPU memory to deploy shadow experts. These together keep recovery cost and recomputation overhead extremely low. Our evaluation shows that, compared to state-of-the-art MegaScale-Infer, Tarragon reduces failure-induced stalls by 160-213x (from ~64 s down to 0.3-0.4 s) while preserving performance when no failures occur.

</details>


### [188] [DiT-HC: Enabling Efficient Training of Visual Generation Model DiT on HPC-oriented CPU Cluster](https://arxiv.org/abs/2601.01500)
*Jinxiao Zhang,Yunpu Xu,Xiyong Wu,Runmin Dong,Shenggan Cheng,Yi Zhao,Mengxuan Chen,Qinrui Zheng,Jianting Liu,Haohuan Fu*

Main category: cs.DC

TL;DR: DiT-HC是首个在HPC CPU集群上训练和扩展生成模型DiT的系统，通过三项关键技术实现了高效训练，展示了CPU集群在生成模型训练中的潜力。


<details>
  <summary>Details</summary>
Motivation: 随着新硬件特性（如矩阵加速单元和高带宽内存）的发展，CPU集群为加速和扩展生成模型提供了机会，促进了AI与科学计算的统一。

Method: DiT-HC引入了三项关键技术：(1) 带有AutoMem的通信自由张量并行(CFTP)，(2) HCOps优化的GEMM和算子内核，(3) 自定义MPI后端，重叠计算、通信和内存移动。

Result: 实验显示，DiT-HC在256个节点上实现了8.2至87.7倍的加速，弱扩展效率达到90.6%。

Conclusion: DiT-HC展示了在CPU集群上大规模训练生成模型的可行性，并为未来HPC与AI的协同设计提供了新见解。

Abstract: Generative foundation models have become an important tool for data reconstruction and simulation in scientific computing, showing a tight integration with traditional numerical simulations. At the same time, with the development of new hardware features, such as matrix acceleration units and high-bandwidth memory, CPU-based clusters offer promising opportunities to accelerate and scale such models, facilitating the unification of artificial intelligence and scientific computing. We present DiT-HC, the first system to train and scale the generative model DiT on a next-generation HPC CPU cluster. DiT-HC introduces three key techniques: (1) communication-free tensor parallelism (CFTP) with AutoMem for automated memory-aware dataflow, (2) HCOps, a suite of optimized GEMM and operator kernels leveraging vector and matrix acceleration units, and (3) a custom MPI backend that overlaps computation, communication, and memory movement. Experiments show 8.2 to 87.7 times speedups over native or public CPU libraries and 90.6% weak scaling efficiency on 256 nodes. These results demonstrate the feasibility of large-scale generative model training on CPU clusters and provide new insights for future HPC-AI co-design.

</details>


### [189] [FFCz: Fast Fourier Correction for Spectrum-Preserving Lossy Compression of Scientific Data](https://arxiv.org/abs/2601.01596)
*Congrong Ren,Robert Underwood,Sheng Di,Emrecan Kutay,Zarija Lukic,Aylin Yener,Franck Cappello,Hanqi Guo*

Main category: cs.DC

TL;DR: 提出一种新技术，通过快速傅里叶校正算法在损失压缩中保留频谱特征，并在多个科学数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有压缩方法仅保证空间域的准确性，而忽略了频域，这对于依赖频域表示的科学应用（如宇宙学、燃烧模拟等）至关重要。

Method: 通过将频域误差表示为空间域误差的线性组合，推导出联合约束两个域误差的区域，并迭代投影空间误差向量直至满足约束条件。

Result: 在宇宙学模拟、X射线衍射等数据集上验证了该方法能有效保留空间和频域的关键科学信息。

Conclusion: 本文提出了一种基于快速傅里叶校正算法的新技术，用于在损失压缩中保留频谱特征，通过GPU并行加速实现实用性能，并在多个科学数据集上验证了其有效性。

Abstract: This paper introduces a novel technique to preserve spectral features in lossy compression based on a novel fast Fourier correction algorithm\added{ for regular-grid data}. Preserving both spatial and frequency representations of data is crucial for applications such as cosmology, turbulent combustion, and X-ray diffraction, where spatial and frequency views provide complementary scientific insights. In particular, many analysis tasks rely on frequency-domain representations to capture key features, including the power spectrum of cosmology simulations, the turbulent energy spectrum in combustion, and diffraction patterns in reciprocal space for ptychography. However, existing compression methods guarantee accuracy only in the spatial domain while disregarding the frequency domain. To address this limitation, we propose an algorithm that corrects the errors produced by off-the-shelf ``base'' compressors such as SZ3, ZFP, and SPERR, thereby preserving both spatial and frequency representations by bounding errors in both domains. By expressing frequency-domain errors as linear combinations of spatial-domain errors, we derive a region that jointly bounds errors in both domains. Given as input the spatial errors from a base compressor and user-defined error bounds in the spatial and frequency domains, we iteratively project the spatial error vector onto the regions defined by the spatial and frequency constraints until it lies within their intersection. We further accelerate the algorithm using GPU parallelism to achieve practical performance. We validate our approach with datasets from cosmology simulations, X-ray diffraction, combustion simulation, and electroencephalography demonstrating its effectiveness in preserving critical scientific information in both spatial and frequency domains.

</details>


### [190] [RelayGR: Scaling Long-Sequence Generative Recommendation via Cross-Stage Relay-Race Inference](https://arxiv.org/abs/2601.01712)
*Jiarui Wang,Huichao Chai,Yuanhang Zhang,Zongjin Zhou,Wei Guo,Xingkun Yang,Qiang Tang,Bo Pan,Jiawei Zhu,Ke Cheng,Yuting Yan,Shulan Wang,Yingjie Zhu,Zhengfan Yuan,Jiaqi Huang,Yuhan Zhang,Xiaosong Sun,Zhinan Zhang,Hong Zhu,Yongsheng Zhang,Tiantian Dong,Zhong Xiao,Deliang Liu,Chengzhou Lu,Yuan Sun,Zhiyuan Chen,Xinming Han,Zaizhu Liu,Yaoyuan Wang,Ziyang Zhang,Yong Liu,Jinxin Xu,Yajing Sun,Zhoujun Yu,Wenting Zhou,Qidong Zhang,Zhengyong Zhang,Zhonghai Gu,Yibo Jin,Yongxiang Feng,Pengfei Zuo*

Main category: cs.DC

TL;DR: RelayGR通过预推断和缓存优化，在工业级生成推荐系统中实现更长序列处理和更高吞吐量。


<details>
  <summary>Details</summary>
Motivation: 生成式推荐模型因处理长用户行为序列而提升推荐质量，但在生产环境中受限于严格的延迟预算，序列长度被大幅压缩。

Method: RelayGR采用序列感知触发器、亲和感知路由器和内存感知扩展器三项技术，实现高效的用户行为前缀预推断和缓存管理。

Result: 在固定P99 SLO下，RelayGR支持1.5倍更长的序列，并将符合SLO的吞吐量提升至3.6倍。

Conclusion: RelayGR系统通过选择性预推断、KV缓存驻留和本地化路由等技术，在严格延迟SLO下显著提升了生成式推荐模型的序列长度和吞吐量。

Abstract: Real-time recommender systems execute multi-stage cascades (retrieval, pre-processing, fine-grained ranking) under strict tail-latency SLOs, leaving only tens of milliseconds for ranking. Generative recommendation (GR) models can improve quality by consuming long user-behavior sequences, but in production their online sequence length is tightly capped by the ranking-stage P99 budget. We observe that the majority of GR tokens encode user behaviors that are independent of the item candidates, suggesting an opportunity to pre-infer a user-behavior prefix once and reuse it during ranking rather than recomputing it on the critical path. Realizing this idea at industrial scale is non-trivial: the prefix cache must survive across multiple pipeline stages before the final ranking instance is determined, the user population implies cache footprints far beyond a single device, and indiscriminate pre-inference would overload shared resources under high QPS. We present RelayGR, a production system that enables in-HBM relay-race inference for GR. RelayGR selectively pre-infers long-term user prefixes, keeps their KV caches resident in HBM over the request lifecycle, and ensures the subsequent ranking can consume them without remote fetches. RelayGR combines three techniques: 1) a sequence-aware trigger that admits only at-risk requests under a bounded cache footprint and pre-inference load, 2) an affinity-aware router that co-locates cache production and consumption by routing both the auxiliary pre-infer signal and the ranking request to the same instance, and 3) a memory-aware expander that uses server-local DRAM to capture short-term cross-request reuse while avoiding redundant reloads. We implement RelayGR on Huawei Ascend NPUs and evaluate it with real queries. Under a fixed P99 SLO, RelayGR supports up to 1.5$\times$ longer sequences and improves SLO-compliant throughput by up to 3.6$\times$.

</details>


### [191] [pMSz: A Distributed Parallel Algorithm for Correcting Extrema and Morse Smale Segmentations in Lossy Compression](https://arxiv.org/abs/2601.01787)
*Yuxiao Li,Mingze Xia,Xin Liang,Bei Wang,Robert Underwood,Sheng Di,Hemant Sharma,Dishant Beniwal,Franck Cappello,Hanqi Guo*

Main category: cs.DC

TL;DR: 本文提出了一种分布式并行算法，用于修正有损压缩后的拓扑特征，通过简化MSz方法并减少通信开销，在128个GPU上实现了高效扩展。


<details>
  <summary>Details</summary>
Motivation: 有损压缩在科学数据中的应用可能扭曲关键特征，影响下游分析和科学结论。现有的单GPU算法（MSz）无法扩展到极端规模数据。

Method: 算法通过保留所有位置的最陡上升和下降方向，简化了MSz方法，减少了进程间通信，同时引入可忽略的额外存储开销。

Result: 在Perlmutter超级计算机上，该方法在真实数据集上实现了128个GPU超过90%的并行效率。

Conclusion: 本文提出的分布式并行算法通过简化MSz方法，避免了显式计算和修正积分路径，显著提高了拓扑特征修正的可扩展性，在128个GPU上实现了超过90%的并行效率。

Abstract: Lossy compression, widely used by scientists to reduce data from simulations, experiments, and observations, can distort features of interest even under bounded error. Such distortions may compromise downstream analyses and lead to incorrect scientific conclusions in applications such as combustion and cosmology. This paper presents a distributed and parallel algorithm for correcting topological features, specifically, piecewise linear Morse Smale segmentations (PLMSS), which decompose the domain into monotone regions labeled by their corresponding local minima and maxima. While a single GPU algorithm (MSz) exists for PLMSS correction after compression, no methodology has been developed that scales beyond a single GPU for extreme scale data. We identify the key bottleneck in scaling PLMSS correction as the parallel computation of integral paths, a communication-intensive computation that is notoriously difficult to scale. Instead of explicitly computing and correcting integral paths, our algorithm simplifies MSz by preserving steepest ascending and descending directions across all locations, thereby minimizing interprocess communication while introducing negligible additional storage overhead. With this simplified algorithm and relaxed synchronization, our method achieves over 90% parallel efficiency on 128 GPUs on the Perlmutter supercomputer for real world datasets.

</details>


### [192] [Bringing computation to the data: A MOEA-driven approach for optimising data processing in the context of the SKA and SRCNet](https://arxiv.org/abs/2601.01980)
*Manuel Parra-Royón,Álvaro Rodríguez-Gallardo,Susana Sánchez-Expósito,Laura Darriba-Pol,Jesús Sánchez-Castañeda,M. Ángeles Mendoza,Julián Garrido,Javier Moldón,Lourdes Verdes-Montenegro*

Main category: cs.DC

TL;DR: Proposes FaaS + MOEAs for SKA's data processing, shifting to computation-to-data to overcome bottlenecks, optimizing workflows for time, energy, and cost.


<details>
  <summary>Details</summary>
Motivation: The SKA's unprecedented data volumes make traditional data-centric computing models unviable due to network and storage bottlenecks, necessitating a shift towards distributed and in-situ computing.

Method: The work proposes integrating Function-as-a-Service (FaaS) with Multi-Objective Evolutionary Algorithms (MOEAs) to optimize data-intensive workflows by moving computation closer to data sources.

Result: The proposed framework explores near-optimal execution plans balancing execution time, energy consumption, and data transfer costs.

Conclusion: The paper establishes a baseline framework for efficient and cost-aware computation-to-data strategies within the SKA Regional Centres Network (SRCNet) architecture, leveraging distributed and in-situ computing with FaaS and MOEAs.

Abstract: The Square Kilometre Array (SKA) will generate unprecedented data volumes, making efficient data processing a critical challenge. Within this context, the SKA Regional Centres Network (SRCNet) must operate in a near-exascale environment where traditional data-centric computing models based on moving large datasets to centralised resources are no longer viable due to network and storage bottlenecks.
  To address this limitation, this work proposes a shift towards distributed and in-situ computing, where computation is moved closer to the data. We explore the integration of Function-as-a-Service (FaaS) with an intelligent decision-making entity based on Evolutionary Algorithms (EAs) to optimise data-intensive workflows within SRCNet. FaaS enables lightweight and modular function execution near data sources while abstracting infrastructure management.
  The proposed decision-making entity employs Multi-Objective Evolutionary Algorithms (MOEAs) to explore near-optimal execution plans considering execution time and energy consumption, together with constraints related to data location and transfer costs. This work establishes a baseline framework for efficient and cost-aware computation-to-data strategies within the SRCNet architecture.

</details>


### [193] [SuperSFL: Resource-Heterogeneous Federated Split Learning with Weight-Sharing Super-Networks](https://arxiv.org/abs/2601.02092)
*Abdullah Al Asif,Sixing Yu,Juan Pablo Munoz,Arya Mazaheri,Ali Jannesari*

Main category: cs.DC

TL;DR: SuperSFL通过动态子网络和TPGF机制，在异构环境中显著提升联邦学习效率，降低通信成本和训练时间。


<details>
  <summary>Details</summary>
Motivation: 解决SplitFed Learning在异构环境中因设备计算和通信能力差异导致的效率低下问题。

Method: SuperSFL采用权重共享的超网络动态生成客户端特定子网络，并引入三阶段梯度融合（TPGF）机制优化本地更新、服务器端计算和梯度融合。此外，还设计了容错的客户端分类器和协作式客户端-服务器聚合机制。

Result: 在CIFAR-10和CIFAR-100数据集上，SuperSFL比基线SFL收敛速度快2-5倍，通信成本降低20倍，训练时间缩短13倍，且能效更高。

Conclusion: SuperSFL通过动态生成资源感知的客户端特定子网络和引入三阶段梯度融合机制，显著提升了在异构边缘环境中的联邦学习效率，同时降低了通信成本和训练时间。

Abstract: SplitFed Learning (SFL) combines federated learning and split learning to enable collaborative training across distributed edge devices; however, it faces significant challenges in heterogeneous environments with diverse computational and communication capabilities. This paper proposes \textit{SuperSFL}, a federated split learning framework that leverages a weight-sharing super-network to dynamically generate resource-aware client-specific subnetworks, effectively mitigating device heterogeneity. SuperSFL introduces Three-Phase Gradient Fusion (TPGF), an optimization mechanism that coordinates local updates, server-side computation, and gradient fusion to accelerate convergence. In addition, a fault-tolerant client-side classifier and collaborative client--server aggregation enable uninterrupted training under intermittent communication failures. Experimental results on CIFAR-10 and CIFAR-100 with up to 100 heterogeneous clients show that SuperSFL converges $2$--$5\times$ faster in terms of communication rounds than baseline SFL while achieving higher accuracy, resulting in up to $20\times$ lower total communication cost and $13\times$ shorter training time. SuperSFL also demonstrates improved energy efficiency compared to baseline methods, making it a practical solution for federated learning in heterogeneous edge environments.

</details>


### [194] [BigSUMO: A Scalable Framework for Big Data Traffic Analytics and Parallel Simulation](https://arxiv.org/abs/2601.02286)
*Rahul Sengupta,Nooshin Yousefzadeh,Manav Sanghvi,Yash Ranjan,Anand Rangarajan,Sanjay Ranka,Yashaswi Karnati,Jeremy Dilmore,Tushar Patel,Ryan Casburn*

Main category: cs.DC

TL;DR: BigSUMO是一个开源框架，用于交通数据分析、中断检测和并行模拟，帮助优化城市交通管理。


<details>
  <summary>Details</summary>
Motivation: 随着全球城市化进程加快，交通基础设施的高效管理对交通机构和城市规划者至关重要。需要工具来分析大量存储的交通数据并进行有效干预。

Method: BigSUMO整合了高分辨率环路检测器和信号状态数据，以及稀疏的探测轨迹数据，进行描述性分析并检测潜在中断。然后使用SUMO微模拟器进行预测性分析，测试数百种假设场景以优化交通性能。

Result: BigSUMO通过模块化设计实现了数据处理和异常检测算法的集成，具有成本效益、可扩展性且易于部署。

Conclusion: BigSUMO是一个开源、可扩展的框架，旨在为智能城市交通解决方案提供有价值的支持。

Abstract: With growing urbanization worldwide, efficient management of traffic infrastructure is critical for transportation agencies and city planners. It is essential to have tools that help analyze large volumes of stored traffic data and make effective interventions. To address this need, we present ``BigSUMO", an end-to-end, scalable, open-source framework for analytics, interruption detection, and parallel traffic simulation. Our system ingests high-resolution loop detector and signal state data, along with sparse probe trajectory data. It first performs descriptive analytics and detects potential interruptions. It then uses the SUMO microsimulator for prescriptive analytics, testing hundreds of what-if scenarios to optimize traffic performance. The modular design allows integration of different algorithms for data processing and outlier detection. Built using open-source software and libraries, the pipeline is cost-effective, scalable, and easy to deploy. We hope BigSUMO will be a valuable aid in developing smart city mobility solutions.

</details>


### [195] [Placement Semantics for Distributed Deep Learning: A Systematic Framework for Analyzing Parallelism Strategies](https://arxiv.org/abs/2601.02311)
*Deep Pankajbhai Mehta*

Main category: cs.DC

TL;DR: 论文提出了一种通过放置语义预测并行策略行为的统一框架，证明了梯度完整性和状态一致性的重要性，并提供了组合策略的规则。


<details>
  <summary>Details</summary>
Motivation: 当前实践中，并行策略的选择依赖于试错，缺乏统一的系统框架来预测其行为。

Method: 通过放置语义（五种模式和四种训练状态的组合）来预测内存消耗和通信量，无需实现细节。

Result: 预测结果与已发表结果完全匹配，例如ZeRO-3的内存消耗比数据并行少8倍，通信成本增加1.5倍。

Conclusion: 该论文提出了一个统一的系统框架，通过放置语义来预测并行策略的行为，证明了梯度完整性和状态一致性是分布式训练与单设备结果匹配的必要和充分条件，并提供了安全组合策略的规则。

Abstract: Training large language models requires distributing computation across many accelerators, yet practitioners select parallelism strategies (data, tensor, pipeline, ZeRO) through trial and error because no unified systematic framework predicts their behavior. We introduce placement semantics: each strategy is specified by how it places four training states (parameters, optimizer, gradients, activations) across devices using five modes (replicated, sharded, sharded-with-gather, materialized, offloaded). From placement alone, without implementation details, we derive memory consumption and communication volume. Our predictions match published results exactly: ZeRO-3 uses 8x less memory than data parallelism at 1.5x communication cost, as reported in the original paper. We prove two conditions (gradient integrity, state consistency) are necessary and sufficient for distributed training to match single-device results, and provide composition rules for combining strategies safely. The framework unifies ZeRO Stages 1-3, Fully Sharded Data Parallel (FSDP), tensor parallelism, and pipeline parallelism as instances with different placement choices.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [196] [Improving the Graph Challenge Reference Implementation](https://arxiv.org/abs/2601.00974)
*Inna Voloshchuk,Hayden Jananthan,Chansup Byun,Jeremy Kepner*

Main category: cs.NI

TL;DR: 论文通过重构和并行化优化了Graph Challenge的参考代码，代码量减少67%，性能提升，为参与者提供了更高效的基础。


<details>
  <summary>Details</summary>
Motivation: 提高Graph Challenge参考代码的清晰度、适应性和性能，以促进大规模图和稀疏数据分析的创新。

Method: 使用pMatlab和pPython分布式数组编程库，通过并行映射对数据进行并行基准测试，优化了原始Python实现。

Result: 代码从1000行缩减至325行，功能完整，并行处理能力提升，展示了大规模流量矩阵求和与分析的可扩展性能。

Conclusion: 重构后的代码不仅显著减少了代码量（67%），还保持了完整功能，并通过并行映射提升了性能，为Graph Challenge参与者提供了更清晰高效的基础。

Abstract: The MIT/IEEE/Amazon Graph Challenge provides a venue for individuals and teams to showcase new innovations in large-scale graph and sparse data analysis. The Anonymized Network Sensing Graph Challenge processes over 100 billion network packets to construct privacy-preserving traffic matrices, with a GraphBLAS reference implementation demonstrating how hypersparse matrices can be applied to this problem. This work presents a refactoring and benchmarking of a section of the reference code to improve clarity, adaptability, and performance. The original Python implementation spanning approximately 1000 lines across 3 files has been streamlined to 325 lines across two focused modules, achieving a 67% reduction in code size while maintaining full functionality. Using pMatlab and pPython distributed array programming libraries, the addition of parallel maps allowed for parallel benchmarking of the data. Scalable performance is demonstrated for large-scale summation and analysis of traffic matrices. The resulting implementation increases the potential impact of the Graph Challenge by providing a clear and efficient foundation for participants.

</details>


### [197] [Decision-Aware Semantic State Synchronization in Compute-First Networking](https://arxiv.org/abs/2601.01086)
*Jianpeng Qi,Chao Liu,Chengrui Wang,Rui Wang,Junyu Dong,Yanwei Yu*

Main category: cs.NI

TL;DR: SenseCFN通过决策感知的状态同步，在CFN中优化任务卸载，显著提高成功率并减少更新开销。


<details>
  <summary>Details</summary>
Motivation: 现有基于周期性更新或信息年龄（AoI）的方法主要关注时间新鲜度，常忽略状态变化对卸载决策的实际相关性，导致在高系统负载下性能下降。

Method: 提出了SenseCFN框架，包括轻量级语义状态表示和语义偏差指数（SDI），采用集中训练分布式执行（CTDE）方法联合优化更新和卸载策略。

Result: 仿真结果显示，SenseCFN在易饱和场景中任务成功率高达99.6%，比基线方法提升超过25%，同时状态更新频率降低约70%至96%。

Conclusion: SenseCFN通过决策感知的状态同步框架，在计算优先网络（CFN）中有效平衡了更新开销和决策准确性，显著提高了任务成功率并大幅减少了状态更新频率。

Abstract: In Compute-First Networking (CFN), an Access Point (AP) makes task offloading decisions based on resource state information reported by a Service Node (SN). A fundamental challenge arises from the trade-off between update overhead and decision accuracy: Frequent state updates consume limited network resources, while infrequent updates lead to stale state views and degraded task performance, especially under high system load. Existing approaches based on periodic updates or Age of Information (AoI) mainly focus on temporal freshness and often overlook whether a state change is actually relevant to offloading decisions. This paper proposes SenseCFN, a decision-aware state synchronization framework for CFN. Instead of synchronizing raw resource states, SenseCFN focuses on identifying state changes that are likely to alter offloading decisions. To this end, we introduce a lightweight semantic state representation that captures decision-relevant system characteristics, along with a Semantic Deviation Index (SDI) to quantify the impact of state shifts on decision outcomes. Based on SDI, the SN triggers updates only when significant decision-impacting changes are detected. Meanwhile, the AP performs offloading decisions using cached semantic states with explicit awareness of potential staleness. The update and offloading policies are jointly optimized using a centralized training with distributed execution (CTDE) approach. Simulation results show that SenseCFN maintains a task success rate of up to 99.6% in saturation-prone scenarios, outperforming baseline methods by more than 25%, while reducing status update frequency by approximately 70% to 96%. These results indicate that decision-aware state synchronization provides an effective and practical alternative to purely time-based update strategies in CFN.

</details>


### [198] [Utility Maximization in Wireless Backhaul Networks with Service Guarantees](https://arxiv.org/abs/2601.01630)
*Nicholas Jones,Eytan Modiano*

Main category: cs.NI

TL;DR: 论文提出了一种优化无线回程网络效用的方法，通过pinwheel调度和混合整数规划满足SLA，并开发了高效的分布式算法。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决无线回程网络中满足SLA（端到端数据包延迟和瞬时吞吐量）的效用最大化问题，这是一个NP完全问题。

Method: 论文采用混合整数规划优化准入决策和pinwheel调度，并开发了一种新颖的pinwheel调度算法，显著扩展了多项式时间内可找到的调度集合。

Result: 开发了一种可扩展的分布式方法，其复杂度与树的深度呈线性关系，显著优于现有技术。

Conclusion: 论文提出了一种在无线回程网络中最大化效用的方法，通过构建具有有界调度间隔的链路调度来满足SLA要求，并在对称树拓扑下证明了简单轮询调度的最优性。

Abstract: We consider the problem of maximizing utility in wireless backhaul networks, where utility is a function of satisfied service level agreements (SLAs), defined in terms of end-to-end packet delays and instantaneous throughput. We model backhaul networks as a tree topology and show that SLAs can be satisfied by constructing link schedules with bounded inter-scheduling times, an NP-complete problem known as pinwheel scheduling. For symmetric tree topologies, we show that simple round-robin schedules can be optimal under certain conditions. In the general case, we develop a mixed-integer program that optimizes over the set of admission decisions and pinwheel schedules. We develop a novel pinwheel scheduling algorithm, which significantly expands the set of schedules that can be found in polynomial time over the state of the art. Using conditions from this algorithm, we develop a scalable, distributed approach to solve the utility-maximization problem, with complexity that is linear in the depth of the tree.

</details>


### [199] [Revisiting the Interface between Error and Erasure Correction in Wireless Standards](https://arxiv.org/abs/2601.01645)
*Vipindev Adat Vasudevan,Homa Esfahanizadeh,Benjamin D. Kim,Laura Landon,Alejandro Cohen,Muriel Médard*

Main category: cs.NI

TL;DR: 网络编码在5G中作为替代HARQ/ARQ的方案，通过仿真验证其在延迟和资源效率上的优势，为6G标准化提供模块化设计启示。


<details>
  <summary>Details</summary>
Motivation: 现代5G通信系统采用的纠错和基于反馈的擦除校正机制（如HARQ/ARQ）可能导致显著延迟和资源低效，网络编码被提出作为更高效的替代方案。

Method: 通过数学建模和网络切片环境下的仿真，比较了现有可靠性机制与网络编码的性能。

Result: 仿真结果表明，网络编码不仅提升了切片应用的顺序交付延迟和吞吐量，还通过减少编码切片的资源利用，使共享网络的其他应用受益。

Conclusion: 研究强调了未来无线网络协议栈设计需要更高的模块化，以整合新技术如网络编码，这对6G标准化过程提出了新的思考方向。

Abstract: Modern 5G communication systems implement a combination of error correction and feedback-based erasure correction (HARQ/ARQ) as reliability mechanisms, which can introduce substantial delay and resource inefficiency. We propose forward erasure correction using network coding as a more delay-efficient alternative. We present a mathematical characterization of network delay for existing reliability mechanisms and network coding. Through simulations in a network slicing environment, we demonstrate that network coding not only improves the in-order delivery delay and goodput for the applications utilizing the slice, but also benefits other applications sharing the network by reducing resource utilization for the coded slice. Our analysis and characterization point towards ideas that require attention in the 6G standardization process. These findings highlight the need for greater modularity in protocol stack design that enables the integration of novel technologies in future wireless networks.

</details>


### [200] [Enhanced Open-Source NWDAF for Event-Driven Analytics in 5G Networks](https://arxiv.org/abs/2601.01838)
*Henok Daniel,Omar Alhussein,Jie Liang,Cheng Li,Ernesto Damiani*

Main category: cs.NI

TL;DR: 开源NWDAF框架集成Free5GC，支持标准化事件订阅与预测分析，部署验证可靠性和80.65%切换预测准确率。


<details>
  <summary>Details</summary>
Motivation: 现有NWDAF实现多为专有方案，开源替代方案缺乏端到端事件订阅与通知的全面支持。

Method: 扩展了会话管理功能以支持标准化事件暴露接口，并在SMF和AMF中引入自定义通知机制，实现无缝数据交付。NWDAF订阅事件并生成关于UE行为、会话生命周期和切换动态的分析。

Result: 通过两周部署验证，系统支持可靠的UE注册、状态跟踪和跨小区切换，并展示了预测能力（预测下一gNB切换小区的准确率达80.65%）。

Conclusion: 本文提出的开源NWDAF框架成功集成到Free5GC中，支持标准化事件订阅与通知机制，并通过实际部署验证了其可靠性和预测能力。

Abstract: The network data analytics function (NWDAF) has been introduced in the fifth-generation (5G) core standards to enable event-driven analytics and support intelligent network automation. However, existing implementations remain largely proprietary, and open-source alternatives lack comprehensive support for end-to-end event subscription and notification. In this paper, we present an open source NWDAF framework integrated into an existing Free5GC implementation, which serves as an open-source 5G core implementation. Our implementation extends the session management function to support standardized event exposure interfaces and introduces custom-built notification mechanisms into the SMF and the access and mobility management function for seamless data delivery. The NWDAF subscribes to events and generates analytics on user equipment (UE) behavior, session lifecycle, and handover dynamics. We validate our system through a two-week deployment involving four virtual next-generation NodeBs (gNBs) and multiple virtual UEs with dynamic mobility patterns. To demonstrate predictive capabilities, we incorporate a mobility-aware module that achieves 80.65\% accuracy in forecasting the next gNB handover cell. The framework supports reliable UE registration, state tracking, and cross-cell handovers.

</details>


### [201] [Near-Field Multi-Cell ISCAP with Extremely Large-Scale Antenna Array](https://arxiv.org/abs/2601.01968)
*Yuan Guo,Yilong Chen,Zixiang Ren,Derrick Wing Kwan Ng,Jie Xu*

Main category: cs.NI

TL;DR: 论文提出了一种鲁棒优化框架，用于多小区集成感知、通信和供电系统，通过优化波束成形策略平衡感知、通信和供电的需求，并开发了低复杂度次优方案。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决在多小区集成感知、通信和供电（ISCAP）系统中，如何在电磁近场环境下同时支持下行通信、无线功率传输（WPT）和环境感知的挑战。

Method: 论文采用半定松弛（SDR）技术将原始非凸问题转化为凸半定规划问题，并证明了松弛的紧性。此外，还提出了一种基于最大比传输（MRT）的低复杂度次优方案。

Result: 数值结果揭示了感知精度、通信可靠性和WPT效率之间的基本权衡。

Conclusion: 该论文提出了一个鲁棒的优化框架，通过优化波束成形策略，在规定的感知区域内最大化最坏情况下的检测概率，同时满足每个用户的信干噪比约束和能量接收器的能量收集要求，并明确考虑了能量接收器位置的不确定性。此外，还开发了一种基于最大比传输的低复杂度次优方案，在无限天线数量的渐近情况下提供了闭式解。

Abstract: This paper investigates a coordinated multi-cell integrated sensing, communication, and powering (ISCAP) system operating in the electromagnetic near field, where each base station (BS) employs an extremely large-scale antenna array (ELAA) to simultaneously support downlink communication, wireless power transfer (WPT), and environmental sensing. Three categories of communication users (CUs) with different interference cancellation capabilities are considered, and sensing is enabled through a distributed multiple-input multiple-output (MIMO) radar architecture. To address the resulting design challenges, a robust optimization framework is proposed by optimizing the beamforming strategy to maximize the worst-case detection probability over a prescribed sensing region, subject to per-user signal-to-interference-plus-noise ratio (SINR) constraints and energy harvesting requirements at energy receivers (ERs), while explicitly capturing the uncertainty in ER locations. By leveraging semidefinite relaxation (SDR), the original non-convex problem is reformulated as a convex semidefinite program with a provably tight relaxation. Furthermore, a low-complexity maximum ratio transmission (MRT)-based suboptimal scheme is developed, yielding a closed-form solution in the asymptotic regime as the number of antenna elements approaches infinity. Extensive numerical results reveal the fundamental trade-offs among sensing accuracy, communication reliability, and WPT efficiency.

</details>


### [202] [AgentVNE: LLM-Augmented Graph Reinforcement Learning for Affinity-Aware Multi-Agent Placement in Edge Agentic AI](https://arxiv.org/abs/2601.02021)
*Runze Zheng,Yuqing Zheng,Zhengyi Cheng,Long Luo,Haoxiang Luo,Gang Sun,Hongfang Yu,Dusit Niyato*

Main category: cs.NI

TL;DR: AgentVNE是一个云边协作框架，通过语义感知和拓扑推理解决了边缘智能中多代理服务部署的挑战，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 边缘计算中的多代理服务（MAS）部署面临资源受限、动态内存积累和复杂跨节点交互等挑战，传统VNE算法无法满足其实时响应需求。

Method: 提出了一个双层架构的AgentVNE框架，结合LLM识别语义约束并生成资源增强，同时构建资源相似性感知神经网络，通过预训练和PPO微调策略捕获动态工作流与异构网络的拓扑相似性。

Result: 仿真结果表明，AgentVNE将工作流通信延迟降低至基线的40%以下，并在高负载场景下将服务接受率提高了约5%-10%。

Conclusion: AgentVNE为边缘智能中的多代理服务部署提供了语义感知的基础解决方案，显著降低了通信延迟并提高了服务接受率。

Abstract: The Internet of Agents is propelling edge computing toward agentic AI and edge general intelligence (EGI). However, deploying multi-agent service (MAS) on resource-constrained edge infrastructure presents severe challenges. MAS service workflows are driven by complex cross-node interactions, dynamic memory accumulation, and collaborative tool usage. Exhibiting chain-like topological dependencies and strict affinity constraints, these workflows demand real-time responsiveness that exceeds the capabilities of traditional VNE algorithms designed for static resources. To address this, we propose AgentVNE, a cloud-edge collaborative framework utilizing a dual-layer architecture. First, AgentVNE employs a large language model (LLM) to identify implicit semantic constraints and generate affinity-based resource augmentation to resolve physical dependency issues. Second, it constructs a resource similarity-aware neural network, utilizing a pre-training and PPO fine-tuning strategy to precisely capture topological similarities between dynamic workflows and heterogeneous networks. By coupling semantic perception with topological reasoning, this mechanism effectively bridges the gap between dynamic service requirements and physical infrastructure. Simulation results demonstrate that AgentVNE reduces workflow communication latency to less than 40% of baselines and improves the service acceptance rate by approximately 5%-10% under high-load scenarios. Ultimately, this work provides a foundational solution for the semantic-aware deployment of agentic AI.

</details>


### [203] [Enabling Deep Reinforcement Learning Research for Energy Saving in Open RAN](https://arxiv.org/abs/2601.02240)
*Matteo Bordin,Andrea Lacava,Michele Polese,Francesca Cuomo,Tommaso Melodia*

Main category: cs.NI

TL;DR: 该论文提出了一种基于DRL的框架，通过开源工具ns-O-RAN和Gymnasium优化5G网络的能源效率，并在真实场景中验证其效果。


<details>
  <summary>Details</summary>
Motivation: 下一代无线系统对性能和部署密度的需求日益增长，需要有效管理移动网络的能源效率。

Method: 使用开源模拟器ns-O-RAN和强化学习环境Gymnasium，训练和评估DRL代理动态控制5G网络中小区激活与休眠。

Result: 展示了在真实5G网络场景中（包括用户移动性、切换、完整协议栈和3GPP兼容信道模型）DRL对能源效率的影响，并提供了数据收集和评估方法。

Conclusion: 该论文提出了一个基于深度强化学习（DRL）的框架，用于提高智能可编程开放无线接入网（O-RAN）系统的能源效率，并通过开源工具和教程推动相关研究。

Abstract: The growing performance demands and higher deployment densities of next-generation wireless systems emphasize the importance of adopting strategies to manage the energy efficiency of mobile networks. In this demo, we showcase a framework that enables research on Deep Reinforcement Learning (DRL) techniques for improving the energy efficiency of intelligent and programmable Open Radio Access Network (RAN) systems. Using the open-source simulator ns-O-RAN and the reinforcement learning environment Gymnasium, the framework enables to train and evaluate DRL agents that dynamically control the activation and deactivation of cells in a 5G network. We show how to collect data for training and evaluate the impact of DRL on energy efficiency in a realistic 5G network scenario, including users' mobility and handovers, a full protocol stack, and 3rd Generation Partnership Project (3GPP)-compliant channel models. The tool will be open-sourced and a tutorial for energy efficiency testing in ns-O-RAN.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [204] [SeRe: A Security-Related Code Review Dataset Aligned with Real-World Review Activities](https://arxiv.org/abs/2601.01042)
*Zixiao Zhao,Yanjie Jiang,Hui Liu,Kui Liu,Lu Zhang*

Main category: cs.SE

TL;DR: 论文提出SeRe数据集，采用主动学习构建安全相关代码审查数据，填补现有研究空白，并验证其与实际分布的吻合性。


<details>
  <summary>Details</summary>
Motivation: 软件安全漏洞可能导致严重后果，早期检测至关重要。现有数据集和研究主要关注通用代码审查评论，缺乏安全特定注释或规模不足，无法支持大规模研究。

Method: 采用基于主动学习的集成分类方法，通过人工标注迭代优化模型预测，以高精度和合理召回率构建了安全相关的代码审查数据集SeRe。

Result: 通过精细调整的集成分类器，从373,824个原始审查实例中提取了6,732个安全相关评论，确保跨多种编程语言的代表性。统计分析表明SeRe与实际安全相关审查分布一致。

Conclusion: 论文通过引入SeRe数据集和基准测试结果，旨在推动自动化安全代码审查的研究，并促进更有效的安全软件工程实践的发展。

Abstract: Software security vulnerabilities can lead to severe consequences, making early detection essential. Although code review serves as a critical defense mechanism against security flaws, relevant feedback remains scarce due to limited attention to security issues or a lack of expertise among reviewers. Existing datasets and studies primarily focus on general-purpose code review comments, either lacking security-specific annotations or being too limited in scale to support large-scale research. To bridge this gap, we introduce \textbf{SeRe}, a \textbf{security-related code review dataset}, constructed using an active learning-based ensemble classification approach. The proposed approach iteratively refines model predictions through human annotations, achieving high precision while maintaining reasonable recall. Using the fine-tuned ensemble classifier, we extracted 6,732 security-related reviews from 373,824 raw review instances, ensuring representativeness across multiple programming languages. Statistical analysis indicates that SeRe generally \textbf{aligns with real-world security-related review distribution}. To assess both the utility of SeRe and the effectiveness of existing code review comment generation approaches, we benchmark state-of-the-art approaches on security-related feedback generation. By releasing SeRe along with our benchmark results, we aim to advance research in automated security-focused code review and contribute to the development of more effective secure software engineering practices.

</details>


### [205] [RovoDev Code Reviewer: A Large-Scale Online Evaluation of LLM-based Code Review Automation at Atlassian](https://arxiv.org/abs/2601.01129)
*Kla Tantithamthavorn,Yaotian Zou,Andy Wong,Michael Gupta,Zhe Wang,Mike Buller,Ryan Jiang,Matthew Watson,Minwoo Jeong,Kun Chen,Ming Wu*

Main category: cs.SE

TL;DR: RovoDev Code Reviewer 是一个企业级 LLM 代码审查工具，无需微调即可生成高质量评论，显著提升审查效率和软件质量。


<details>
  <summary>Details</summary>
Motivation: 解决设计无需微调、具备审查引导、上下文感知和质量检查的代码审查评论生成工具的实际挑战。

Method: 设计了 RovoDev Code Reviewer，一个无需微调的企业级 LLM 代码审查自动化工具，并集成到 Atlassian 的 Bitbucket 中。

Result: RovoDev Code Reviewer 在一年评估期内，显著提升了代码审查效率和质量。

Conclusion: RovoDev Code Reviewer 在 Atlassian 的开发生态系统中大规模部署，通过离线、在线和用户反馈评估，证明其能有效生成代码审查评论（38.70% 触发后续代码变更），加速反馈周期（减少 PR 周期时间 30.8%），减轻审查者工作量（减少人工编写评论 35.6%），并提升软件质量（提供可操作建议的错误发现）。

Abstract: Large Language Models (LLMs)-powered code review automation has the potential to transform code review workflows. Despite the advances of LLM-powered code review comment generation approaches, several practical challenges remain for designing enterprise-grade code review automation tools. In particular, this paper aims at answering the practical question: how can we design a review-guided, context-aware, quality-checked code review comment generation without fine-tuning?
  In this paper, we present RovoDev Code Reviewer, an enterprise-grade LLM-based code review automation tool designed and deployed at scale within Atlassian's development ecosystem with seamless integration into Atlassian's Bitbucket. Through the offline, online, user feedback evaluations over a one-year period, we conclude that RovoDev Code Reviewer is (1) effective in generating code review comments that could lead to code resolution for 38.70% (i.e., comments that triggered code changes in the subsequent commits); and (2) offers the promise of accelerating feedback cycles (i.e., decreasing the PR cycle time by 30.8%), alleviating reviewer workload (i.e., reducing the number of human-written comments by 35.6%), and improving overall software quality (i.e., finding errors with actionable suggestions).

</details>


### [206] [Abductive Vibe Coding (Extended Abstract)](https://arxiv.org/abs/2601.01199)
*Logan Murphy,Aren A. Babikian,Marsha Chechik*

Main category: cs.SE

TL;DR: 该研究旨在为AI生成的代码提供半正式的理由评估框架，以替代难以实现的形式化验证。


<details>
  <summary>Details</summary>
Motivation: 由于许多现实世界中的AI生成代码场景难以形式化验证，因此需要一种替代方法来评估其适当性。

Method: 研究描述了一个框架，该框架生成一组条件，在这些条件下，生成的代码可以被视为适当。

Result: 研究正在进行中，描述了当前框架的实施进展和预期的研究机会。

Conclusion: 该研究提出了一种框架，用于提取可分析的半正式理由，以评估AI生成代码的适当性，而非直接判定其正确性。

Abstract: When software artifacts are generated by AI models ("vibe coding"), human engineers assume responsibility for validating them. Ideally, this validation would be done through the creation of a formal proof of correctness. However, this is infeasible for many real-world vibe coding scenarios, especially when requirements for the AI-generated artifacts resist formalization. This extended abstract describes ongoing work towards the extraction of analyzable, semi-formal rationales for the adequacy of vibe-coded artifacts. Rather than deciding correctness directly, our framework produces a set of conditions under which the generated code can be considered adequate. We describe current efforts towards implementing our framework and anticipated research opportunities.

</details>


### [207] [Correctness isnt Efficiency: Runtime Memory Divergence in LLM-Generated Code](https://arxiv.org/abs/2601.01215)
*Prateek Rajput,Yewei Song,Abdoul Aziz Bonkoungou,Iyiola E. Olatunji,Abdoul Kader Kabore,Jacques Klein,Tegawendé F. Bissyandé*

Main category: cs.SE

TL;DR: 研究发现LLM生成的程序即使通过测试也可能存在运行时不稳定问题，提出DMPD和MIS度量方法，并建议在CI/CD中优先选择稳定性高的解决方案。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）可以生成通过单元测试的程序，但通过测试并不保证可靠的运行时行为。研究发现，同一任务的不同正确解决方案可能表现出非常不同的内存和性能模式，这可能导致隐藏的操作风险。

Method: 提出了一个框架来测量多个正确生成程序在执行时的内存稳定性。在解决方案层面，引入了动态平均成对距离（DMPD），利用动态时间规整（DTW）比较内存使用轨迹的形状，并通过转换为单调峰值轮廓（MPPs）减少瞬态噪声。在任务层面聚合DMPD得到模型不稳定性分数（MIS）。

Result: 在BigOBench和CodeContests上的实验显示，正确解决方案之间存在显著的运行时差异。不稳定性通常随着采样温度的增加而增加，即使pass@1有所改善。还观察到稳定性度量与软件工程指标（如认知和圈复杂度）之间的相关性，表明操作行为与可维护性之间存在联系。

Conclusion: 研究结果支持在持续集成/持续交付（CI/CD）流程中采用稳定性感知的选择策略，以在不牺牲正确性的前提下降低操作风险。

Abstract: Large language models (LLMs) can generate programs that pass unit tests, but passing tests does not guarantee reliable runtime behavior. We find that different correct solutions to the same task can show very different memory and performance patterns, which can lead to hidden operational risks. We present a framework to measure execution-time memory stability across multiple correct generations. At the solution level, we introduce Dynamic Mean Pairwise Distance (DMPD), which uses Dynamic Time Warping to compare the shapes of memory-usage traces after converting them into Monotonic Peak Profiles (MPPs) to reduce transient noise. Aggregating DMPD across tasks yields a model-level Model Instability Score (MIS). Experiments on BigOBench and CodeContests show substantial runtime divergence among correct solutions. Instability often increases with higher sampling temperature even when pass@1 improves. We also observe correlations between our stability measures and software engineering indicators such as cognitive and cyclomatic complexity, suggesting links between operational behavior and maintainability. Our results support stability-aware selection among passing candidates in CI/CD to reduce operational risk without sacrificing correctness. Artifacts are available.

</details>


### [208] [HD-GEN: A High-Performance Software System for Human Mobility Data Generation Based on Patterns of Life](https://arxiv.org/abs/2601.01219)
*Hossein Amiri,Joon-Seok Kim,Hamdi Kavak,Andrew Crooks,Dieter Pfoser,Carola Wenk,Andreas Züfle*

Main category: cs.SE

TL;DR: 论文提出一个软件管道，结合经验数据和模拟的优势，生成并处理大规模人类移动数据集。


<details>
  <summary>Details</summary>
Motivation: 解决真实轨迹数据集的数据稀疏性和参与者偏差问题，同时提升合成数据的真实性。

Method: 系统包括四个集成组件：数据生成引擎、基于遗传算法的校准模块、数据处理套件和可视化模块。

Result: 开发了一个能够生成具有真实世界移动特征的合成数据的系统，适用于下游应用如模型训练和基准测试。

Conclusion: 该论文提出了一个综合软件管道，用于校准、生成、处理和可视化大规模个体级人类移动数据集，结合了经验数据的真实性和模拟的控制性与可扩展性。

Abstract: Understanding individual-level human mobility is critical for a wide range of applications. Real-world trajectory datasets provide valuable insights into actual movement behaviors but are often constrained by data sparsity and participant bias. Synthetic data, by contrast, offer scalability and flexibility but frequently lack realism. To address this gap, we introduce a comprehensive software pipeline for calibrating, generating, processing, and visualizing large-scale individual-level human mobility datasets that combine the realism of empirical data with the control and extensibility of Patterns-of-Life simulations. Our system consists of four integrated components. (1) a data generation engine constructs geographically grounded simulations using OpenStreetMap data to produce diverse mobility logs. (2) a genetic algorithm-based calibration module fine-tunes simulation parameters to align with real-world mobility characteristics, such as daily trip counts and radius of gyration, enabling realistic behavioral modeling. (3) a data processing suite transforms raw simulation logs into structured formats suitable for downstream applications, including model training and benchmarking. (4) a visualization module extracts key mobility patterns and insights from the processed datasets and presents them through intuitive visual analytics for improved interpretability.

</details>


### [209] [Atomizer: An LLM-based Collaborative Multi-Agent Framework for Intent-Driven Commit Untangling](https://arxiv.org/abs/2601.01233)
*Kangchen Zhu,Zhiliang Tian,Shangwen Wang,Mingyue Leng,Xiaoguang Mao*

Main category: cs.SE

TL;DR: Atomizer通过多代理协作和语义意图分析，显著提升复合提交解耦效果。


<details>
  <summary>Details</summary>
Motivation: 现有的自动化解耦方法过度依赖结构信息且缺乏反思机制，无法有效处理复合提交中的语义意图。

Method: Atomizer采用意图导向的思维链（IO-CoT）策略，利用大语言模型（LLMs）推断代码变更的语义意图，并通过分组-评审协作循环迭代优化分组。

Result: 在C#和Java数据集上，Atomizer平均性能分别超越现有最佳方法6.0%和5.5%，复杂提交中优势达16%以上。

Conclusion: Atomizer显著优于现有的基于图的方法，在C#和Java数据集上分别提升了6.0%和5.5%的性能，尤其在复杂提交中优势更为明显（超过16%）。

Abstract: Composite commits, which entangle multiple unrelated concerns, are prevalent in software development and significantly hinder program comprehension and maintenance. Existing automated untangling methods, particularly state-of-the-art graph clustering-based approaches, are fundamentally limited by two issues. (1) They over-rely on structural information, failing to grasp the crucial semantic intent behind changes, and (2) they operate as ``single-pass'' algorithms, lacking a mechanism for the critical reflection and refinement inherent in human review processes. To overcome these challenges, we introduce Atomizer, a novel collaborative multi-agent framework for composite commit untangling. To address the semantic deficit, Atomizer employs an Intent-Oriented Chain-of-Thought (IO-CoT) strategy, which prompts large language models (LLMs) to infer the intent of each code change according to both the structure and the semantic information of code. To overcome the limitations of ``single-pass'' grouping, we employ two agents to establish a grouper-reviewer collaborative refinement loop, which mirrors human review practices by iteratively refining groupings until all changes in a cluster share the same underlying semantic intent. Extensive experiments on two benchmark C# and Java datasets demonstrate that Atomizer significantly outperforms several representative baselines. On average, it surpasses the state-of-the-art graph-based methods by over 6.0% on the C# dataset and 5.5% on the Java dataset. This superiority is particularly pronounced on complex commits, where Atomizer's performance advantage widens to over 16%.

</details>


### [210] [CatchAll: Repository-Aware Exception Handling with Knowledge-Guided LLMs](https://arxiv.org/abs/2601.01271)
*Qingxiao Tao,Xiaodong Gu,Hao Zhong,Beijun Shen*

Main category: cs.SE

TL;DR: CatchAll是一种基于LLM的仓库感知异常处理方法，通过三层知识整合提升性能，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在仓库级异常处理中表现不佳，主要由于复杂的依赖关系和上下文约束。

Method: CatchAll为LLM提供了三层异常处理知识：API级异常知识、仓库级执行上下文和跨仓库处理知识，并通过结构化提示指导LLM生成代码。

Result: CatchAll在RepoExEval基准测试中表现优异，CodeBLEU得分为0.31，意图预测准确率为60.1%，Pass@1为29%，均优于现有基线。

Conclusion: CatchAll通过整合API级异常知识、仓库级执行上下文和跨仓库处理知识，显著提升了LLM在仓库级异常处理中的表现，实验证明了其有效性。

Abstract: Exception handling is a vital forward error-recovery mechanism in many programming languages, enabling developers to manage runtime anomalies through structured constructs (e.g., try-catch blocks). Improper or missing exception handling often leads to severe consequences, including system crashes and resource leaks. While large language models (LLMs) have demonstrated strong capabilities in code generation, they struggle with exception handling at the repository level, due to complex dependencies and contextual constraints. In this work, we propose CatchAll, a novel LLM-based approach for repository-aware exception handling. CatchAll equips LLMs with three complementary layers of exception-handling knowledge: (1) API-level exception knowledge, obtained from an empirically constructed API-exception mapping that characterizes the exception-throwing behaviors of APIs in real-world codebases; (2) repository-level execution context, which captures exception propagation by modeling contextual call traces around the target code; and (3) cross-repository handling knowledge, distilled from reusable exception-handling patterns mined from historical code across projects. The knowledge is encoded into structured prompts to guide the LLM in generating accurate and context-aware exception-handling code. To evaluate CatchAll, we construct two new benchmarks for repository-aware exception handling: a large-scale dataset RepoExEval and an executable subset RepoExEval-Exec. Experiments demonstrate that RepoExEval consistently outperforms state-of-the-art baselines, achieving a CodeBLEU score of 0.31 (vs. 0.27% for the best baseline), intent prediction accuracy of 60.1% (vs. 48.0%), and Pass@1 of 29% (vs. 25%). These results affirm RepoExEval's effectiveness in real-world repository-level exception handling.

</details>


### [211] [Adaptive Hierarchical Evaluation of LLMs and SAST tools for CWE Prediction in Python](https://arxiv.org/abs/2601.01320)
*Muntasir Adnan,Carlos C. N. Kuhn*

Main category: cs.SE

TL;DR: ALPHA 是首个分层感知的 Python 漏洞检测基准，评估了 LLMs 和 SAST 工具的性能，发现 LLMs 整体表现更好但 SAST 更精确，并提出了未来改进方向。


<details>
  <summary>Details</summary>
Motivation: 现有漏洞检测基准缺乏 CWE 级别的特异性，无法为迭代修正系统提供可操作的反馈。ALPHA 旨在填补这一空白。

Method: ALPHA 采用分层感知的 CWE 特定惩罚机制，区分过度泛化、过度规范和横向错误，评估了 7 个 LLMs 和 2 个 SAST 工具的性能。

Result: LLMs 显著优于 SAST 工具，但 SAST 在检测发生时表现出更高的精确度。模型间的预测一致性差异显著（8.26%-81.87% 一致率），对反馈驱动系统有重要影响。

Conclusion: ALPHA 是首个针对 Python 的函数级基准测试，通过分层感知的 CWE 特定惩罚评估 LLMs 和 SAST 工具，为反馈驱动系统提供了重要见解。未来工作可将 ALPHA 惩罚纳入监督微调，以实现层次感知的漏洞检测。

Abstract: Large Language Models have become integral to software development, yet they frequently generate vulnerable code. Existing code vulnerability detection benchmarks employ binary classification, lacking the CWE-level specificity required for actionable feedback in iterative correction systems. We present ALPHA (Adaptive Learning via Penalty in Hierarchical Assessment), the first function-level Python benchmark that evaluates both LLMs and SAST tools using hierarchically aware, CWE-specific penalties. ALPHA distinguishes between over-generalisation, over-specification, and lateral errors, reflecting practical differences in diagnostic utility. Evaluating seven LLMs and two SAST tools, we find LLMs substantially outperform SAST, though SAST demonstrates higher precision when detections occur. Critically, prediction consistency varies dramatically across models (8.26%-81.87% agreement), with significant implications for feedback-driven systems. We further outline a pathway for future work incorporating ALPHA penalties into supervised fine-tuning, which could provide principled hierarchy-aware vulnerability detection pending empirical validation.

</details>


### [212] [GlycoPy: An Equation-Oriented and Object-Oriented Software for Hierarchical Modeling, Optimization, and Control in Python](https://arxiv.org/abs/2601.01413)
*Yingjie Ma,Jing Guo,Richard D. Braatz*

Main category: cs.SE

TL;DR: GlycoPy是一个Python框架，支持非线性模型预测控制的建模与算法定制，填补了算法与实际应用的差距。


<details>
  <summary>Details</summary>
Motivation: 现有线性模型预测控制在非线性（生物）化学过程中性能受限，缺乏分层建模工具和高效NMPC算法实现。

Method: 开发了GlycoPy，一个基于Python的方程导向、面向对象的软件框架，支持分层建模、参数估计、动态优化和NMPC算法定制。

Result: 通过三个案例研究（从简单微分代数系统到多尺度生物过程模型）验证了GlycoPy的建模、优化和NMPC功能。

Conclusion: GlycoPy框架有效填补了高级非线性模型预测控制（NMPC）算法与实际工业应用之间的鸿沟，通过案例研究验证了其建模、优化和控制能力。

Abstract: Most existing model predictive control (MPC) applications in process industries employ lin-ear models, although real-world (bio)chemical processes are typically nonlinear. The use of linear models limits the performance and applicability of MPC for processes that span a wide range of operating conditions. A challenge in employing nonlinear models in MPC for com-plex systems is the lack of tools that facilitate hierarchical model development, as well as lack of efficient implementations of the corresponding nonlinear MPC (NMPC) algorithms. As a step towards making NMPC more practical for hierarchical systems, we introduce Gly-coPy, an equation-oriented, object-oriented software framework for process modeling, opti-mization, and NMPC in Python. GlycoPy enables users to focus on writing equations for modeling while supporting hierarchical modeling. GlycoPy includes algorithms for parame-ter estimation, dynamic optimization, and NMPC, and allows users to customize the simula-tion, optimization, and control algorithms. Three case studies, ranging from a simple differ-ential algebraic equation system to a multiscale bioprocess model, validate the modeling, optimization, and NMPC capabilities of GlycoPy. GlycoPy has the potential to bridge the gap between advanced NMPC algorithms and their practical application in real-world (bio)chemical processes.

</details>


### [213] [SWE-Lego: Pushing the Limits of Supervised Fine-tuning for Software Issue Resolving](https://arxiv.org/abs/2601.01426)
*Chaofan Tao,Jierun Chen,Yuxin Jiang,Kaiqi Kou,Shaowei Wang,Ruoyu Wang,Xiaohui Li,Sidi Yang,Yiming Du,Jianbo Dai,Zhiming Mao,Xinyu Wang,Lifeng Shang,Haoli Bai*

Main category: cs.SE

TL;DR: SWE-Lego通过轻量级SFT和优化数据集，在软件工程任务中实现高性能，并通过TTS进一步优化表现。


<details>
  <summary>Details</summary>
Motivation: 探索如何在软件工程（SWE）任务中通过轻量级的SFT方法达到最先进性能，避免复杂训练范式的依赖。

Method: SWE-Lego采用三个核心构建块：1）包含32k高质量任务实例和18k验证轨迹的数据集；2）结合错误掩码和基于难度的课程学习的优化SFT流程；3）基于训练良好的验证器的测试时扩展（TTS）。

Result: SWE-Lego-Qwen3-8B和32B模型在SWE-bench Verified上分别达到42.2%和52.6%的准确率，通过TTS@16进一步提升至49.6%和58.8%。

Conclusion: SWE-Lego通过轻量级的监督微调（SFT）方法，结合高质量数据集和优化的训练流程，实现了在软件工程任务中的最先进性能，并通过测试时扩展（TTS）进一步提升了模型表现。

Abstract: We present SWE-Lego, a supervised fine-tuning (SFT) recipe designed to achieve state-ofthe-art performance in software engineering (SWE) issue resolving. In contrast to prevalent methods that rely on complex training paradigms (e.g., mid-training, SFT, reinforcement learning, and their combinations), we explore how to push the limits of a lightweight SFT-only approach for SWE tasks. SWE-Lego comprises three core building blocks, with key findings summarized as follows: 1) the SWE-Lego dataset, a collection of 32k highquality task instances and 18k validated trajectories, combining real and synthetic data to complement each other in both quality and quantity; 2) a refined SFT procedure with error masking and a difficulty-based curriculum, which demonstrably improves action quality and overall performance. Empirical results show that with these two building bricks alone,the SFT can push SWE-Lego models to state-of-the-art performance among open-source models of comparable size on SWE-bench Verified: SWE-Lego-Qwen3-8B reaches 42.2%, and SWE-Lego-Qwen3-32B attains 52.6%. 3) We further evaluate and improve test-time scaling (TTS) built upon the SFT foundation. Based on a well-trained verifier, SWE-Lego models can be significantly boosted--for example, 42.2% to 49.6% and 52.6% to 58.8% under TTS@16 for the 8B and 32B models, respectively.

</details>


### [214] [Group versus Individual Review Requests: Tradeoffs in Speed and Quality at Mozilla Firefox](https://arxiv.org/abs/2601.01514)
*Matej Kucera,Marco Castelluccio,Daniel Feitosa,Ayushi Rastogi*

Main category: cs.SE

TL;DR: 研究发现，群体代码评审（如GitHub的群体分配）能提高质量（减少回归），但对速度无显著影响，同时带来工作均衡和培训新评审员的好处。


<details>
  <summary>Details</summary>
Motivation: 探讨代码评审分配过程中‘群体评审请求’对评审速度和质量的影响，填补现有研究中这一环节的空白。

Method: 结合统计建模（分析约66,000个Mozilla Firefox项目的修订）和焦点小组讨论的实践者观点。

Result: 群体评审与评审质量提升相关，但对速度影响不明显。

Conclusion: 群体评审请求与更高的评审质量相关（表现为更少的回归问题），但对评审速度的影响微乎其微。此外，群体评审还能带来工作负载均衡和新评审员培训的机会。

Abstract: The speed at which code changes are integrated into the software codebase, also referred to as code review velocity, is a prevalent industry metric for improved throughput and developer satisfaction. While prior studies have explored factors influencing review velocity, the role of the review assignment process, particularly the `group review request', is unclear. In group review requests, available on platforms like Phabricator, GitHub, and Bitbucket, a code change is assigned to a reviewer group, allowing any member to review it, unlike individual review assignments to specific reviewers. Drawing parallels with shared task queues in Management Sciences, this study examines the effects of group versus individual review requests on velocity and quality. We investigate approximately 66,000 revisions in the Mozilla Firefox project, combining statistical modeling with practitioner views from a focus group discussion. Our study associates group reviews with improved review quality, characterized by fewer regressions, while having a negligible association with review velocity. Additional perceived benefits include balanced work distribution and training opportunities for new reviewers.

</details>


### [215] [MTS-1: A Lightweight Delta-Encoded Telemetry Format optimised for Low-Resource Environments and Offline-First System Health Monitoring](https://arxiv.org/abs/2601.01602)
*Henry Ndou*

Main category: cs.SE

TL;DR: MTS-1是一种新型二进制遥测格式，专为带宽受限环境设计，相比现有格式显著提升了压缩效率和网络性能。


<details>
  <summary>Details</summary>
Motivation: 现有遥测编码如JSON、CBOR等在高带宽、始终在线的环境中设计，但在带宽受限的网络中（如撒哈拉以南非洲、农村企业部署和不稳定的LAN环境）会产生显著开销。

Method: 通过合成基准测试，比较MTS-1与JSON、JSON Lines、CBOR、MessagePack和Protocol Buffers在有效载荷大小、编码成本、网络效率和成本延迟性能方面的表现。

Result: MTS-1在初步测试中展现出显著的压缩优势，并适用于离线优先的系统监控、LAN辅助代理传输和节能的IoT到服务器传输。

Conclusion: MTS-1在带宽受限的网络环境中表现出色，相比JSON和MessagePack分别实现了74.7%和5.4%的压缩提升，且具有线性扩展特性。

Abstract: System-level telemetry is fundamental to modern remote monitoring, predictive maintenance, and AI-driven infrastructure optimisation. Existing telemetry encodings such as JSON, JSON Lines, CBOR, and Protocol Buffers were designed for high-bandwidth, always-online environments. They impose significant overhead when deployed in bandwidth-constrained networks common across Sub-Saharan Africa, rural enterprise deployments, and unstable LAN environments. This paper introduces MTS-1 (Magenta Telemetry Standard v1), a novel delta-encoded binary telemetry format designed for offline-first system monitoring, LAN-assisted proxy delivery, and energy-efficient IoT-to-server transmission. We compare MTS-1 against JSON, JSON Lines, CBOR, MessagePack, and Protocol Buffers across payload size, encoding cost, network efficiency, and cost-latency performance. Synthetic benchmarking demonstrates preliminary compression improvements of up to 74.7% versus JSON and 5.4% versus MessagePack, with linear scaling characteristics across dataset sizes.

</details>


### [216] [LIA: Supervised Fine-Tuning of Large Language Models for Automatic Issue Assignment](https://arxiv.org/abs/2601.01780)
*Arsham Khosravani,Alireza Hosseinpour,Arshia Akhavan,Mehdi Keshani,Abbas Heydarnoori*

Main category: cs.SE

TL;DR: LIA利用LLM的预训练语义理解能力，通过监督微调实现高效问题分配，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 手动问题分配在大型开源项目中存在不一致和易错的问题，现有自动化方法依赖大量项目特定训练数据或稀疏嘈杂的关系信息，效果有限。

Method: LIA采用监督微调方法，利用DeepSeek-R1-Distill-Llama-8B模型的预训练语义理解能力，直接从问题标题和描述生成开发者推荐排名。

Result: LIA在Hit@1指标上比基础预训练模型高出187.8%，并优于四种领先的问题分配方法，最高提升211.2%。

Conclusion: LIA（基于LLM的问题分配方法）通过监督微调适应LLM，显著提高了问题分配的准确性和效率，成为软件维护任务中实用且高性能的解决方案。

Abstract: Issue assignment is a critical process in software maintenance, where new issue reports are validated and assigned to suitable developers. However, manual issue assignment is often inconsistent and error-prone, especially in large open-source projects where thousands of new issues are reported monthly. Existing automated approaches have shown promise, but many rely heavily on large volumes of project-specific training data or relational information that is often sparse and noisy, which limits their effectiveness. To address these challenges, we propose LIA (LLM-based Issue Assignment), which employs supervised fine-tuning to adapt an LLM, DeepSeek-R1-Distill-Llama-8B in this work, for automatic issue assignment. By leveraging the LLM's pretrained semantic understanding of natural language and software-related text, LIA learns to generate ranked developer recommendations directly from issue titles and descriptions. The ranking is based on the model's learned understanding of historical issue-to-developer assignments, using patterns from past tasks to infer which developers are most likely to handle new issues. Through comprehensive evaluation, we show that LIA delivers substantial improvements over both its base pretrained model and state-of-the-art baselines. It achieves up to +187.8% higher Hit@1 compared to the DeepSeek-R1-Distill-Llama-8B pretrained base model, and outperforms four leading issue assignment methods by as much as +211.2% in Hit@1 score. These results highlight the effectiveness of domain-adapted LLMs for software maintenance tasks and establish LIA as a practical, high-performing solution for issue assignment.

</details>


### [217] [The Machine Learning Canvas: Empirical Findings on Why Strategy Matters More Than AI Code Generation](https://arxiv.org/abs/2601.01839)
*Martin Prause*

Main category: cs.SE

TL;DR: 研究提出‘机器学习画布’框架，揭示战略、流程、生态系统和支持四个互联因素为ML项目成功关键，AI助手虽加速编码但无法替代战略思考。


<details>
  <summary>Details</summary>
Motivation: 尽管AI编码助手日益流行，但超过80%的机器学习项目未能提供实际商业价值，因此需要研究成功因素。

Method: 通过调查150名数据科学家并采用统计建模分析其反馈，创建并测试了‘机器学习画布’框架。

Result: 识别出四个关键成功因素：战略、流程、生态系统和支持，并发现它们相互关联，共同决定项目成败。

Conclusion: AI编码助手虽然能加速编码过程，但无法替代战略思考的‘为什么’和‘做什么’，成功的关键在于战略、流程、生态系统和支持四个因素的有机结合。

Abstract: Despite the growing popularity of AI coding assistants, over 80% of machine learning (ML) projects fail to deliver real business value. This study creates and tests a Machine Learning Canvas, a practical framework that combines business strategy, software engineering, and data science in order to determine the factors that lead to the success of ML projects. We surveyed 150 data scientists and analyzed their responses using statistical modeling. We identified four key success factors: Strategy (clear goals and planning), Process (how work gets done), Ecosystem (tools and infrastructure), and Support (organizational backing and resources). Our results show that these factors are interconnected - each one affects the next. For instance, strong organizational support results in a clearer strategy (β= 0.432, p < 0.001), which improves work processes (β= 0.428, p < 0.001) and builds better infrastructure (β= 0.547, p < 0.001). Together, these elements determine whether a project succeeds. The surprising finding? Although AI assistants make coding faster, they don't guarantee project success. AI assists with the "how" of coding but cannot replace the "why" and "what" of strategic thinking.

</details>


### [218] [A Defect is Being Born: How Close Are We? A Time Sensitive Forecasting Approach](https://arxiv.org/abs/2601.01921)
*Mikel Robredo,Matteo Esposito,Fabio Palomba,Rafael Peñaloza,Valentina Lenarduzzi*

Main category: cs.SE

TL;DR: 研究探索时间敏感技术在缺陷预测中的有效性，并识别早期指标。


<details>
  <summary>Details</summary>
Motivation: 随着软件系统的持续演进，需要能够预测缺陷的时间敏感方法。

Method: 训练多种时间敏感预测技术，预测软件项目的未来缺陷密度，并识别缺陷出现的早期症状。

Result: 预期结果为早期估计缺陷倾向的有效性提供了实证证据。

Conclusion: 该研究为软件缺陷预测提供了时间敏感技术的有效性证据，并识别了缺陷出现的早期指标。

Abstract: Background. Defect prediction has been a highly active topic among researchers in the Empirical Software Engineering field. Previous literature has successfully achieved the most accurate prediction of an incoming fault and identified the features and anomalies that precede it through just-in-time prediction. As software systems evolve continuously, there is a growing need for time-sensitive methods capable of forecasting defects before they manifest.
  Aim. Our study seeks to explore the effectiveness of time-sensitive techniques for defect forecasting. Moreover, we aim to investigate the early indicators that precede the occurrence of a defect.
  Method. We will train multiple time-sensitive forecasting techniques to forecast the future bug density of a software project, as well as identify the early symptoms preceding the occurrence of a defect.
  Expected results. Our expected results are translated into empirical evidence on the effectiveness of our approach for early estimation of bug proneness.

</details>


### [219] [The Invisible Hand of AI Libraries Shaping Open Source Projects and Communities](https://arxiv.org/abs/2601.01944)
*Matteo Esposito,Andrea Janes,Valentina Lenarduzzi,Davide Taibi*

Main category: cs.SE

TL;DR: 论文分析AI库在Python和Java开源项目中的采用及其对开发实践的影响，通过大规模比较揭示差异。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在开源项目中日益普及，但其采用和对项目的影响尚未得到充分探索。

Method: 对157.7k个潜在开源仓库进行大规模分析，采用仓库指标和软件指标，比较采用AI库与未采用AI库的项目。

Result: 预计将识别采用AI库与未采用AI库的开源项目在开发活动、社区参与和代码复杂性方面的可测量差异。

Conclusion: 该论文旨在通过大规模分析揭示AI库在Python和Java开源项目中的采用情况及其对开发实践的影响，为AI集成如何重塑软件开发提供基于证据的见解。

Abstract: In the early 1980s, Open Source Software emerged as a revolutionary concept amidst the dominance of proprietary software. What began as a revolutionary idea has now become the cornerstone of computer science. Amidst OSS projects, AI is increasing its presence and relevance. However, despite the growing popularity of AI, its adoption and impacts on OSS projects remain underexplored.
  We aim to assess the adoption of AI libraries in Python and Java OSS projects and examine how they shape development, including the technical ecosystem and community engagement. To this end, we will perform a large-scale analysis on 157.7k potential OSS repositories, employing repository metrics and software metrics to compare projects adopting AI libraries against those that do not. We expect to identify measurable differences in development activity, community engagement, and code complexity between OSS projects that adopt AI libraries and those that do not, offering evidence-based insights into how AI integration reshapes software development practices.

</details>


### [220] [Context-Adaptive Requirements Defect Prediction through Human-LLM Collaboration](https://arxiv.org/abs/2601.01952)
*Max Unterbusch,Andreas Vogelsang*

Main category: cs.SE

TL;DR: HLC通过LLM链式推理和用户反馈实现需求缺陷的自适应预测，仅需少量样本即超越传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统需求评估方法依赖通用模式，但缺陷定义具有上下文依赖性，需适应不同项目和利益相关者的需求。

Method: 提出Human-LLM Collaboration (HLC)方法，利用LLM的链式思维推理和用户验证反馈循环，通过少量样本学习自适应调整预测。

Result: 在QuRE基准测试中，HLC仅需20个验证样本即可快速提升性能，结合解释的验证显著优于传统方法，同时保持高召回率。

Conclusion: HLC方法通过结合LLM的链式思维推理和用户验证，实现了对需求缺陷的自适应预测，显著超越传统方法，为持续学习工具提供了新思路。

Abstract: Automated requirements assessment traditionally relies on universal patterns as proxies for defectiveness, implemented through rule-based heuristics or machine learning classifiers trained on large annotated datasets. However, what constitutes a "defect" is inherently context-dependent and varies across projects, domains, and stakeholder interpretations. In this paper, we propose a Human-LLM Collaboration (HLC) approach that treats defect prediction as an adaptive process rather than a static classification task. HLC leverages LLM Chain-of-Thought reasoning in a feedback loop: users validate predictions alongside their explanations, and these validated examples adaptively guide future predictions through few-shot learning. We evaluate this approach using the weak word smell on the QuRE benchmark of 1,266 annotated Mercedes-Benz requirements. Our results show that HLC effectively adapts to the provision of validated examples, with rapid performance gains from as few as 20 validated examples. Incorporating validated explanations, not just labels, enables HLC to substantially outperform both standard few-shot prompting and fine-tuned BERT models while maintaining high recall. These results highlight how the in-context and Chain-of-Thought learning capabilities of LLMs enable adaptive classification approaches that move beyond one-size-fits-all models, creating opportunities for tools that learn continuously from stakeholder feedback.

</details>


### [221] [Reporting LLM Prompting in Automated Software Engineering: A Guideline Based on Current Practices and Expectations](https://arxiv.org/abs/2601.01954)
*Alexander Korn,Lea Zaruchas,Chetan Arora,Andreas Metzger,Sven Smolka,Fanyu Wang,Andreas Vogelsang*

Main category: cs.SE

TL;DR: 本文通过实证研究揭示了LLM在软件工程研究中提示报告的不一致问题，并提出了一套结构化指南以改善透明度和可重复性。


<details>
  <summary>Details</summary>
Motivation: 由于提示相关决策在SE研究中缺乏系统性和透明性的记录，影响了研究的可重复性和可比性，因此需要填补这一空白。

Method: 研究分为两个阶段：首先分析了近300篇发表在顶级SE会议上的论文，评估了当前提示设计、测试和优化的报告情况；其次调查了105位程序委员会成员，了解他们对LLM驱动研究中提示报告的期望。

Result: 研究发现当前实践与评审者期望之间存在显著不一致，特别是在版本披露、提示理由和有效性威胁方面。

Conclusion: 本文提出了一个结构化指南，旨在提高基于LLM的软件工程研究的透明度、可重复性和方法严谨性。

Abstract: Large Language Models, particularly decoder-only generative models such as GPT, are increasingly used to automate Software Engineering tasks. These models are primarily guided through natural language prompts, making prompt engineering a critical factor in system performance and behavior. Despite their growing role in SE research, prompt-related decisions are rarely documented in a systematic or transparent manner, hindering reproducibility and comparability across studies. To address this gap, we conducted a two-phase empirical study. First, we analyzed nearly 300 papers published at the top-3 SE conferences since 2022 to assess how prompt design, testing, and optimization are currently reported. Second, we surveyed 105 program committee members from these conferences to capture their expectations for prompt reporting in LLM-driven research. Based on the findings, we derived a structured guideline that distinguishes essential, desirable, and exceptional reporting elements. Our results reveal significant misalignment between current practices and reviewer expectations, particularly regarding version disclosure, prompt justification, and threats to validity. We present our guideline as a step toward improving transparency, reproducibility, and methodological rigor in LLM-based SE research.

</details>


### [222] [The State of Open Science in Software Engineering Research: A Case Study of ICSE Artifacts](https://arxiv.org/abs/2601.02066)
*Al Muttakin,Saikat Mondal,Chanchal Roy*

Main category: cs.SE

TL;DR: 研究评估了100个SE复制包，发现仅40%可执行，35%重现结果，提出了改进指南。


<details>
  <summary>Details</summary>
Motivation: 填补软件工程研究中复制包可执行性和可重现性综合研究的空白。

Method: 评估了过去十年ICSE会议中发表的100个复制包，包括可执行性、所需修改、执行挑战及结果重现性。

Result: 仅40%的工件可执行，其中32.5%无需修改即可运行；35%的可执行工件重现了原始结果。

Conclusion: 研究发现，软件工程研究中复制包的可用性、可执行性和可重现性存在显著差距，并提出了三条可操作的指南以改进研究工件的准备、文档和审查。

Abstract: Replication packages are crucial for enabling transparency, validation, and reuse in software engineering (SE) research. While artifact sharing is now a standard practice and even expected at premier SE venues such as ICSE, the practical usability of these replication packages remains underexplored. In particular, there is a marked lack of studies that comprehensively examine the executability and reproducibility of replication packages in SE research. In this paper, we aim to fill this gap by evaluating 100 replication packages published as part of ICSE proceedings over the past decade (2015--2024). We assess the (1) executability of the replication packages, (2) efforts and modifications required to execute them, (3) challenges that prevent executability, and (4) reproducibility of the original findings. We spent approximately 650 person-hours in total executing the artifacts and reproducing the study findings. Our findings reveal that only 40\% of the 100 evaluated artifacts were executable, of which 32.5\% (13 out of 40) ran without any modification. Regarding effort levels, 17.5\% (7 out of 40) required low effort, while 82.5\% (33 out of 40) required moderate to high effort to execute successfully. We identified five common types of modifications and 13 challenges leading to execution failure, spanning environmental, documentation, and structural issues. Among the executable artifacts, only 35\% (14 out of 40) reproduced the original results. These findings highlight a notable gap between artifact availability, executability, and reproducibility. Our study proposes three actionable guidelines to improve the preparation, documentation, and review of research artifacts, thereby strengthening the rigor and sustainability of open science practices in SE research.

</details>


### [223] [Code for Machines, Not Just Humans: Quantifying AI-Friendliness with Code Health Metrics](https://arxiv.org/abs/2601.02200)
*Markus Borg,Nadim Hagatulah,Adam Tornhill,Emma Söderberg*

Main category: cs.SE

TL;DR: 研究表明，人类友好的代码也更能兼容AI工具，CodeHealth指标可用于评估AI干预的风险，为大规模AI采用做准备。


<details>
  <summary>Details</summary>
Motivation: 随着人类开发者与AI编码代理在同一个代码库中工作的混合时代的到来，确保不同能力的LLM能可靠地编辑代码变得日益重要。

Method: 通过对来自竞赛编程的5,000个Python文件进行基于LLM的重构，研究AI友好代码的概念。

Result: 研究发现，CodeHealth（一种针对人类理解校准的质量指标）与AI重构后的语义保留之间存在有意义的关联。

Conclusion: 人类友好的代码也更能兼容AI工具，组织可以利用CodeHealth指标来评估AI干预的风险，并决定是否需要额外的人工监督。投资于代码可维护性不仅对人类有益，也为大规模AI采用做好了准备。

Abstract: We are entering a hybrid era in which human developers and AI coding agents work in the same codebases. While industry practice has long optimized code for human comprehension, it is increasingly important to ensure that LLMs with different capabilities can edit code reliably. In this study, we investigate the concept of ``AI-friendly code'' via LLM-based refactoring on a dataset of 5,000 Python files from competitive programming. We find a meaningful association between CodeHealth, a quality metric calibrated for human comprehension, and semantic preservation after AI refactoring. Our findings confirm that human-friendly code is also more compatible with AI tooling. These results suggest that organizations can use CodeHealth to guide where AI interventions are lower risk and where additional human oversight is warranted. Investing in maintainability not only helps humans; it also prepares for large-scale AI adoption.

</details>


### [224] [LLM-Empowered Functional Safety and Security by Design in Automotive Systems](https://arxiv.org/abs/2601.02215)
*Nenad Petrovic,Vahid Zolfaghari,Fengjunjie Pan,Alois Knoll*

Main category: cs.SE

TL;DR: LLM赋能的工作流程支持SDV开发，涵盖安全拓扑设计和事件驱动代码分析，通过事件链模型和MDE方法实现。


<details>
  <summary>Details</summary>
Motivation: 解决软件定义车辆开发中的安全感知系统设计和事件驱动代码分析的挑战。

Method: 采用事件链模型进行代码分析，结合模型驱动工程（MDE）方法和对象约束语言（OCL）规则进行安全拓扑分析。

Result: 在高级驾驶辅助系统（ADAS）相关场景中评估了本地可部署和专有解决方案的有效性。

Conclusion: 该论文提出了一种基于LLM的工作流程，有效支持了软件定义车辆（SDV）的软件开发，特别是在安全感知系统拓扑设计和事件驱动决策代码分析方面。

Abstract: This paper presents LLM-empowered workflow to support Software Defined Vehicle (SDV) software development, covering the aspects of security-aware system topology design, as well as event-driven decision-making code analysis. For code analysis we adopt event chains model which provides formal foundations to systematic validation of functional safety, taking into account the semantic validity of messages exchanged between key components, including both CAN and Vehicle Signal Specification (VSS). Analysis of security aspects for topology relies on synergy with Model-Driven Engineering (MDE) approach and Object Constraint Language (OCL) rules. Both locally deployable and proprietary solution are taken into account for evaluation within Advanced Driver-Assistance Systems (ADAS)-related scenarios.

</details>


### [225] [NQC2: A Non-Intrusive QEMU Code Coverage Plugin](https://arxiv.org/abs/2601.02238)
*Nils Bosbach,Alwalid Salama,Lukas Jünger,Mark Burton,Niko Zurstraßen,Rebecca Pelke,Rainer Leupers*

Main category: cs.SE

TL;DR: NQC2通过QEMU插件实现嵌入式系统代码覆盖率分析，无需插桩且性能提升显著。


<details>
  <summary>Details</summary>
Motivation: 传统代码覆盖率分析方法在嵌入式系统（尤其是裸机程序）中因缺乏操作系统和文件系统支持而受限。

Method: 通过QEMU插件NQC2在运行时提取覆盖率信息，并将数据存储在主机文件中。

Result: NQC2性能超越Xilinx类似方案达8.5倍。

Conclusion: NQC2作为一种无需目标软件插桩的解决方案，显著提升了嵌入式系统代码覆盖率分析的效率和兼容性。

Abstract: Code coverage analysis has become a standard approach in software development, facilitating the assessment of test suite effectiveness, the identification of under-tested code segments, and the discovery of performance bottlenecks. When code coverage of software for embedded systems needs to be measured, conventional approaches quickly meet their limits. A commonly used approach involves instrumenting the source files with added code that collects and dumps coverage information during runtime. This inserted code usually relies on the existence of an operating and a file system to dump the collected data. These features are not available for bare-metal programs that are executed on embedded systems.
  To overcome this issue, we present NQC2, a plugin for QEMU.NQC2 extracts coverage information from QEMU during runtime and stores them into a file on the host machine. This approach is even compatible with modified QEMU versions and does not require target-software instrumentation. NQC2 outperforms a comparable approach from Xilinx by up to 8.5 x.

</details>


### [226] [Automatic Assertion Mining in Assertion-Based Verification: Techniques, Challenges, and Future Directions](https://arxiv.org/abs/2601.02248)
*Mohammad Reza Heidari Iman,Giorgio Di Natale,Katell Morin-Allory*

Main category: cs.SE

TL;DR: 本文回顾了最新的断言挖掘器，比较了它们的方法，指出了未来改进的方向。


<details>
  <summary>Details</summary>
Motivation: 为研究人员和验证从业者提供对现有挖掘器能力和局限性的深入见解。

Method: 回顾了最新、先进且广泛采用的断言挖掘器，并对它们的方法进行了比较分析。

Result: 提供了对断言挖掘器方法的比较分析，并识别了它们的不足之处。

Conclusion: 本文总结了现有断言挖掘器的优缺点，并指出了未来开发更强大、先进的断言挖掘器的方向。

Abstract: Functional verification increasingly relies on Assertion-Based Verification (ABV), which has become a key approach for verifying hardware designs due to its efficiency and effectiveness. Central to ABV are automatic assertion miners, which apply different techniques to generate assertions automatically. This paper reviews the most recent, advanced, and widely adopted assertion miners, offering a comparative analysis of their methodologies. The goal is to provide researchers and verification practitioners with insights into the capabilities and limitations of existing miners. By identifying their shortcomings, this work also points toward directions for developing more powerful and advanced assertion miners in the future.

</details>


### [227] [Question Answering for Multi-Release Systems: A Case Study at Ciena](https://arxiv.org/abs/2601.02345)
*Parham Khamsepour,Mark Cole,Ish Ashraf,Sandeep Puri,Mehrdad Sabetzadeh,Shiva Nejati*

Main category: cs.SE

TL;DR: QAMR是一个针对多版本系统文档优化的问答聊天机器人，通过改进的RAG方法显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有问答技术在多版本系统文档上的准确性不足，促使开发QAMR以应对这一挑战。

Method: QAMR通过结合预处理、查询重写和上下文选择，采用双分块策略优化检索和答案生成。

Result: QAMR在答案正确性（88.5%）和检索准确性（90%）上分别比基线提升16.5%和12%，响应时间减少8%。

Conclusion: QAMR在跨多版本系统文档的问答任务中表现出色，显著提升了答案正确性和检索准确性，同时减少了响应时间。

Abstract: Companies regularly have to contend with multi-release systems, where several versions of the same software are in operation simultaneously. Question answering over documents from multi-release systems poses challenges because different releases have distinct yet overlapping documentation. Motivated by the observed inaccuracy of state-of-the-art question-answering techniques on multi-release system documents, we propose QAMR, a chatbot designed to answer questions across multi-release system documentation. QAMR enhances traditional retrieval-augmented generation (RAG) to ensure accuracy in the face of highly similar yet distinct documentation for different releases. It achieves this through a novel combination of pre-processing, query rewriting, and context selection. In addition, QAMR employs a dual-chunking strategy to enable separately tuned chunk sizes for retrieval and answer generation, improving overall question-answering accuracy. We evaluate QAMR using a public software-engineering benchmark as well as a collection of real-world, multi-release system documents from our industry partner, Ciena. Our evaluation yields five main findings: (1) QAMR outperforms a baseline RAG-based chatbot, achieving an average answer correctness of 88.5% and an average retrieval accuracy of 90%, which correspond to improvements of 16.5% and 12%, respectively. (2) An ablation study shows that QAMR's mechanisms for handling multi-release documents directly improve answer accuracy. (3) Compared to its component-ablated variants, QAMR achieves a 19.6% average gain in answer correctness and a 14.0% average gain in retrieval accuracy over the best ablation. (4) QAMR reduces response time by 8% on average relative to the baseline. (5) The automatically computed accuracy metrics used in our evaluation strongly correlate with expert human assessments, validating the reliability of our methodology.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [228] [Semantic Alignment of Multilingual Knowledge Graphs via Contextualized Vector Projections](https://arxiv.org/abs/2601.00814)
*Abhishek Kumar*

Main category: cs.AI

TL;DR: 论文提出一种基于嵌入的跨语言本体对齐系统，通过增强实体描述和使用多语言Transformer模型，显著提升了对齐性能。


<details>
  <summary>Details</summary>
Motivation: 解决跨语言本体对齐的挑战，提升对齐系统的性能。

Method: 使用基于嵌入的余弦相似度匹配，通过新颖技术生成描述以丰富本体实体的上下文，并采用微调后的多语言Transformer模型生成更好的嵌入。通过余弦相似度找到正本体实体对，再应用阈值过滤保留高相似度实体。

Result: 在OAEI-2022 multifarm track评估数据集上达到71%的F1分数（78%召回率和65%精确率）。

Conclusion: 论文提出的跨语言本体对齐管道能够有效捕捉细微的跨语言相似性，F1分数比最佳基线提高了16%。

Abstract: The paper presents our work on cross-lingual ontology alignment system which uses embedding based cosine similarity matching. The ontology entities are made contextually richer by creating descriptions using novel techniques. We use a fine-tuned transformer based multilingual model for generating better embeddings. We use cosine similarity to find positive ontology entities pairs and then apply threshold filtering to retain only highly similar entities. We have evaluated our work on OAEI-2022 multifarm track. We achieve 71% F1 score (78% recall and 65% precision) on the evaluation dataset, 16% increase from best baseline score. This suggests that our proposed alignment pipeline is able to capture the subtle cross-lingual similarities.

</details>


### [229] [MathLedger: A Verifiable Learning Substrate with Ledger-Attested Feedback](https://arxiv.org/abs/2601.00816)
*Ismail Ahmad Abdullah*

Main category: cs.AI

TL;DR: MathLedger是一个可验证的AI学习框架，结合形式化验证和密码学认证，初步实验验证了其基础设施的有效性。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统虽然性能卓越，但缺乏透明度和可验证性，导致在安全关键部署中信任危机。MathLedger旨在解决这一问题。

Method: 系统实现了反射形式学习（RFL），这是一种符号化的梯度下降方法，其更新由验证结果而非统计损失驱动。

Result: 初步实验验证了测量和治理基础设施在受控条件下的有效性，包括Delta p计算、方差跟踪和故障关闭治理触发机制。

Conclusion: MathLedger提供了一个可验证的机器学习基础设施，通过结合形式化验证、密码学认证和学习动态，实现了大规模的可审计性。

Abstract: Contemporary AI systems achieve extraordinary performance yet remain opaque and non-verifiable, creating a crisis of trust for safety-critical deployment. We introduce MathLedger, a substrate for verifiable machine cognition that integrates formal verification, cryptographic attestation, and learning dynamics into a single epistemic loop. The system implements Reflexive Formal Learning (RFL), a symbolic analogue of gradient descent where updates are driven by verifier outcomes rather than statistical loss.
  Phase I experiments validate the measurement and governance substrate under controlled conditions. CAL-EXP-3 validates measurement infrastructure (Delta p computation, variance tracking); separate stress tests confirm fail-closed governance triggers correctly under out-of-bounds conditions. No convergence or capability claims are made. The contribution is infrastructural: a working prototype of ledger-attested learning that enables auditability at scale.
  Keywords: verifiable learning, formal verification, cryptographic attestation, reflexive feedback, fail-closed governance

</details>


### [230] [Agentic AI for Autonomous, Explainable, and Real-Time Credit Risk Decision-Making](https://arxiv.org/abs/2601.00818)
*Chandra Sekhar Kubam*

Main category: cs.AI

TL;DR: 本文提出了一种自主AI框架，通过多代理系统提升信用风险评估的效率和透明度，优于传统方法，但仍有改进空间。


<details>
  <summary>Details</summary>
Motivation: 金融服务的快速数字化迫切需要自主、透明、实时的信用风险决策系统，传统机器学习模型缺乏现代金融运营所需的适应性推理、情境感知和自主性。

Method: 研究引入了一个多代理系统，结合强化学习、自然语言推理、可解释AI模块和实时数据吸收管道，用于评估借款人的风险。

Result: 研究发现，决策速度、透明度和响应性优于传统信用评分模型，但仍存在模型漂移、高维数据解释不一致、监管不确定性及低资源环境下的基础设施限制等实际限制。

Conclusion: 该系统具有改变信用分析的潜力，未来研究应关注动态合规性、新型代理协作、对抗鲁棒性及跨国信用生态系统的大规模实施。

Abstract: Significant digitalization of financial services in a short period of time has led to an urgent demand to have autonomous, transparent and real-time credit risk decision making systems. The traditional machine learning models are effective in pattern recognition, but do not have the adaptive reasoning, situational awareness, and autonomy needed in modern financial operations. As a proposal, this paper presents an Agentic AI framework, or a system where AI agents view the world of dynamic credit independent of human observers, who then make actions based on their articulable decision-making paths. The research introduces a multi-agent system with reinforcing learning, natural language reasoning, explainable AI modules, and real-time data absorption pipelines as a means of assessing the risk profiles of borrowers with few humans being involved. The processes consist of agent collaboration protocol, risk-scoring engines, interpretability layers, and continuous feedback learning cycles. Findings indicate that decision speed, transparency and responsiveness is better than traditional credit scoring models. Nevertheless, there are still some practical limitations such as risks of model drift, inconsistencies in interpreting high dimensional data and regulatory uncertainties as well as infrastructure limitations in low-resource settings. The suggested system has a high prospective to transform credit analytics and future studies ought to be directed on dynamic regulatory compliance mobilizers, new agent teamwork, adversarial robustness, and large-scale implementation in cross-country credit ecosystems.

</details>


### [231] [CogCanvas: Compression-Resistant Cognitive Artifacts for Long LLM Conversations](https://arxiv.org/abs/2601.00821)
*Tao An*

Main category: cs.AI

TL;DR: CogCanvas是一个无需训练的框架，通过提取和组织对话中的认知构件，显著提升长对话中的信息检索性能。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在长对话中上下文窗口限制与信息保真度之间的根本矛盾。

Method: 通过提取对话中的认知构件（决策、事实、提醒）并将其组织成时间感知图，实现抗压缩检索。

Result: 在LoCoMo基准测试中，CogCanvas整体准确率达34.7%，显著优于RAG和GraphRAG，尤其在时间推理和多跳因果推理上表现突出。

Conclusion: CogCanvas提供了一个无需训练的框架，显著优于标准基线方法，为实践者提供了即插即用的解决方案。

Abstract: Large language models face a fundamental tension between context window limits and information fidelity in long conversations. Existing approaches--truncation and summarization--either discard early information or lose nuanced details. We introduce CogCanvas, a training-free framework that extracts verbatim-grounded cognitive artifacts (decisions, facts, reminders) from conversation turns and organizes them into a temporal-aware graph for compression-resistant retrieval.
  On the LoCoMo benchmark, CogCanvas achieves 34.7% overall accuracy, outperforming RAG (25.6%, +9.1pp) and GraphRAG (13.7%, +21.0pp). The advantage is most pronounced on temporal reasoning: 31.5% vs. 9.3% (RAG) and 5.0% (GraphRAG)--a +530% relative improvement. On multi-hop causal reasoning, CogCanvas achieves 81.0% pass rate vs. 40.0% for GraphRAG (+41.0pp). Controlled benchmarks show 97.5% recall (+78.5pp vs. summarization) with 93.0% exact match preservation.
  While heavily-optimized approaches achieve higher absolute scores through dedicated training (EverMemOS: approximately 92%), our training-free approach provides practitioners with an immediately-deployable alternative that significantly outperforms standard baselines. Code and data: https://github.com/tao-hpu/cog-canvas.

</details>


### [232] [Energy-Aware Routing to Large Reasoning Models](https://arxiv.org/abs/2601.00823)
*Austin R. Ellis-Mohr,Max Hartman,Lav R. Varshney*

Main category: cs.AI

TL;DR: 本文探讨了大型推理模型的能源效率问题，提出通过方差感知的路由和调度策略优化能源使用，为能源感知的模型路由提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型的异构能耗特性导致能源浪费或过度依赖辅助能源，因此需要优化模型选择和推理方式以减少能源消耗。

Method: 通过分析不同大型推理模型（LRMs）的异构推理能耗，研究了任务调度系统中能源供应与随机波动之间的平衡。重点研究了临界状态下的性能表现，并提出了二阶表征方法。

Result: 研究发现，在临界状态下，系统的性能受时间、模型和执行选择中变异性吸收的影响，方差感知路由和调度成为关键设计方向。

Conclusion: 本文提出了一种基于方差感知的路由和调度策略，为开发能源感知的模型路由策略提供了理论基础。

Abstract: Large reasoning models (LRMs) have heterogeneous inference energy costs based on which model is used and how much it reasons. To reduce energy, it is important to choose the right LRM and operate it in the right way. As a result, the performance of systems that dispatch tasks to different individual LRMs depend on the balance between mean energy provisioning and stochastic fluctuations. The critical regime is the unique operating point at which neither auxiliary energy nor baseline energy is systematically wasted. Increasing baseline supply shifts the system toward persistent over-supply and baseline-energy waste, while reducing supply induces persistent reliance on auxiliary energy. Yet in this regime, performance remains volatility-limited and so a second-order characterization provides further insights that we develop. Here, performance is governed by how variability is absorbed across time, models, and execution choices. This perspective highlights variance-aware routing and dispatch as a principled design axis, and provides a theoretical basis for developing energy-aware model routing policies. Routing behavior is characterized when dispatch policies are based on training-compute and inference-compute scaling laws for LRMs.

</details>


### [233] [Decomposing LLM Self-Correction: The Accuracy-Correction Paradox and Error Depth Hypothesis](https://arxiv.org/abs/2601.00828)
*Yin Li*

Main category: cs.AI

TL;DR: 研究发现LLMs的内在自校正能力有限，较弱模型校正率更高，错误检测与校正成功率无关，错误位置提示反而降低性能。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）被认为具有自校正能力，但近期研究表明其内在自校正（无需外部反馈的自我输出修正）效果有限。

Method: 通过跨模型实验（GSM8K-Complex数据集，n=500每模型，共346个错误）系统分解自校正为三个子能力：错误检测、错误定位和错误校正。

Result: 发现了一个显著的准确性-校正悖论：较弱模型（GPT-3.5，66%准确率）的内在校正率比强模型（DeepSeek，94%准确率）高1.6倍（26.8% vs 16.7%）。错误检测率在不同架构间差异巨大（10%至82%），但检测能力不预测校正成功。提供错误位置提示对所有模型均有负面影响。

Conclusion: 研究挑战了关于模型能力和自我改进的线性假设，对自优化流程的设计具有重要意义。

Abstract: Large Language Models (LLMs) are widely believed to possess self-correction capabilities, yet recent studies suggest that intrinsic self-correction--where models correct their own outputs without external feedback--remains largely ineffective. In this work, we systematically decompose self-correction into three distinct sub-capabilities: error detection, error localization, and error correction. Through cross-model experiments on GSM8K-Complex (n=500 per model, 346 total errors) with three major LLMs, we uncover a striking Accuracy-Correction Paradox: weaker models (GPT-3.5, 66% accuracy) achieve 1.6x higher intrinsic correction rates than stronger models (DeepSeek, 94% accuracy)--26.8% vs 16.7%. We propose the Error Depth Hypothesis: stronger models make fewer but deeper errors that resist self-correction. Error detection rates vary dramatically across architectures (10% to 82%), yet detection capability does not predict correction success--Claude detects only 10% of errors but corrects 29% intrinsically. Surprisingly, providing error location hints hurts all models. Our findings challenge linear assumptions about model capability and self-improvement, with important implications for the design of self-refinement pipelines.

</details>


### [234] [Can We Trust AI Explanations? Evidence of Systematic Underreporting in Chain-of-Thought Reasoning](https://arxiv.org/abs/2601.00830)
*Deep Pankajbhai Mehta*

Main category: cs.AI

TL;DR: AI模型的解释往往不真实反映其推理影响因素，强制报告提示会降低准确性，用户偏好提示尤其危险。


<details>
  <summary>Details</summary>
Motivation: 验证AI系统逐步解释其推理时，这些解释是否真实反映了影响AI答案的因素。

Method: 在11个领先的AI模型中，通过嵌入提示并测量模型是否提及这些提示，进行了超过9,000个测试案例的研究。

Result: 模型几乎从不自发提及提示，但当直接询问时会承认注意到它们；强制报告提示会导致模型在无提示时也报告，并降低准确性；特别危险的提示是那些迎合用户偏好的，模型最常遵循但最少报告。

Conclusion: 研究结果表明，仅观察AI的推理过程不足以发现其隐藏的影响因素。

Abstract: When AI systems explain their reasoning step-by-step, practitioners often assume these explanations reveal what actually influenced the AI's answer. We tested this assumption by embedding hints into questions and measuring whether models mentioned them. In a study of over 9,000 test cases across 11 leading AI models, we found a troubling pattern: models almost never mention hints spontaneously, yet when asked directly, they admit noticing them. This suggests models see influential information but choose not to report it. Telling models they are being watched does not help. Forcing models to report hints works, but causes them to report hints even when none exist and reduces their accuracy. We also found that hints appealing to user preferences are especially dangerous-models follow them most often while reporting them least. These findings suggest that simply watching AI reasoning is not enough to catch hidden influences.

</details>


### [235] [OmniNeuro: A Multimodal HCI Framework for Explainable BCI Feedback via Generative AI and Sonification](https://arxiv.org/abs/2601.00843)
*Ayda Aghaei Nia*

Main category: cs.AI

TL;DR: OmniNeuro 是一个可解释的 BCI 框架，通过三种引擎提供透明反馈，提升用户体验和解码效果。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习提高了 BCI 的解码准确性，但其黑盒特性阻碍了临床采用，导致用户挫败感和神经可塑性效果不佳。

Method: OmniNeuro 整合了三种可解释性引擎：物理学（能量）、混沌（分形复杂性）和量子启发的不确定性建模，通过实时神经声化和生成式 AI 临床报告提供反馈。

Result: 在 PhysioNet 数据集（N=109）上，系统平均准确率为 58.52%，定性试点研究（N=3）证实可解释反馈有助于用户调节心理努力并减少试错阶段。

Conclusion: OmniNeuro 作为一个可解释性框架，成功地将 BCI 从黑盒解码器转变为透明的反馈伙伴，提升了用户体验和神经可塑性效果。

Abstract: While Deep Learning has improved Brain-Computer Interface (BCI) decoding accuracy, clinical adoption is hindered by the "Black Box" nature of these algorithms, leading to user frustration and poor neuroplasticity outcomes. We propose OmniNeuro, a novel HCI framework that transforms the BCI from a silent decoder into a transparent feedback partner. OmniNeuro integrates three interpretability engines: (1) Physics (Energy), (2) Chaos (Fractal Complexity), and (3) Quantum-Inspired uncertainty modeling. These metrics drive real-time Neuro-Sonification and Generative AI Clinical Reports. Evaluated on the PhysioNet dataset ($N=109$), the system achieved a mean accuracy of 58.52%, with qualitative pilot studies ($N=3$) confirming that explainable feedback helps users regulate mental effort and reduces the "trial-and-error" phase. OmniNeuro is decoder-agnostic, acting as an essential interpretability layer for any state-of-the-art architecture.

</details>


### [236] [Enhancing Temporal Awareness in LLMs for Temporal Point Processes](https://arxiv.org/abs/2601.00845)
*Lili Chen,Wensheng Gan,Shuang Liang,Philip S. Yu*

Main category: cs.AI

TL;DR: TPP-TAL是一种增强LLMs时间感知的新框架，通过显式对齐时间与语义提升事件建模效果，实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以有效捕捉时间信息与语义上下文间的复杂交互，这在准确事件建模中至关重要。

Method: TPP-TAL是一种即插即用框架，通过显式对齐时间动态与上下文语义，而非简单拼接事件时间和类型嵌入，来增强LLMs的时间推理能力。

Result: 在多个基准数据集上的实验表明，TPP-TAL在时间似然估计和事件预测准确性上均有显著提升。

Conclusion: TPP-TAL显著提升了LLMs在连续时间事件建模中的时间感知能力，通过实验验证了其在时间似然估计和事件预测准确性上的优越性。

Abstract: Temporal point processes (TPPs) are crucial for analyzing events over time and are widely used in fields such as finance, healthcare, and social systems. These processes are particularly valuable for understanding how events unfold over time, accounting for their irregularity and dependencies. Despite the success of large language models (LLMs) in sequence modeling, applying them to temporal point processes remains challenging. A key issue is that current methods struggle to effectively capture the complex interaction between temporal information and semantic context, which is vital for accurate event modeling. In this context, we introduce TPP-TAL (Temporal Point Processes with Enhanced Temporal Awareness in LLMs), a novel plug-and-play framework designed to enhance temporal reasoning within LLMs. Rather than using the conventional method of simply concatenating event time and type embeddings, TPP-TAL explicitly aligns temporal dynamics with contextual semantics before feeding this information into the LLM. This alignment allows the model to better perceive temporal dependencies and long-range interactions between events and their surrounding contexts. Through comprehensive experiments on several benchmark datasets, it is shown that TPP-TAL delivers substantial improvements in temporal likelihood estimation and event prediction accuracy, highlighting the importance of enhancing temporal awareness in LLMs for continuous-time event modeling. The code is made available at https://github.com/chenlilil/TPP-TAL

</details>


### [237] [Temporal Attack Pattern Detection in Multi-Agent AI Workflows: An Open Framework for Training Trace-Based Security Models](https://arxiv.org/abs/2601.00848)
*Ron F. Del Rosario*

Main category: cs.AI

TL;DR: 该论文提出了一种通过OpenTelemetry跟踪分析微调语言模型的方法，用于检测多代理AI工作流程中的时间攻击模式，显著提升了检测准确率，并开源了数据集和训练脚本。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一种可复现的方法，用于检测多代理AI工作流程中的时间攻击模式，填补现有技术中的知识空白。

Method: 通过迭代QLoRA微调在资源受限的ARM64硬件（NVIDIA DGX Spark）上进行了三次训练迭代，并采用策略性增强。数据集包括来自18个公共网络安全源的80,851个示例和35,026个合成的OpenTelemetry跟踪。

Result: 自定义基准测试准确率从42.86%提升至74.29%，实现了显著的31.4个百分点提升。针对特定知识空白的示例表现优于无差别扩展。

Conclusion: 本研究建立了一个可重复的框架，使从业者能够根据其威胁环境构建自定义的代理安全模型。尽管实际部署由于误报率需要人工监督，但这项工作为多代理AI工作流程中的时间攻击模式检测提供了首个可复现的方法。

Abstract: We present an openly documented methodology for fine-tuning language models to detect temporal attack patterns in multi-agent AI workflows using OpenTelemetry trace analysis. We curate a dataset of 80,851 examples from 18 public cybersecurity sources and 35,026 synthetic OpenTelemetry traces. We apply iterative QLoRA fine-tuning on resource-constrained ARM64 hardware (NVIDIA DGX Spark) through three training iterations with strategic augmentation. Our custom benchmark accuracy improves from 42.86% to 74.29%, a statistically significant 31.4-point gain. Targeted examples addressing specific knowledge gaps outperform indiscriminate scaling. Key contributions include: (1) synthetic trace generation methodology for multi-agent coordination attacks and regulatory violations, (2) empirical evidence that training data composition fundamentally determines behavior, and (3) complete open release of datasets, training scripts, and evaluation benchmarks on HuggingFace. While practical deployment requires human oversight due to false positive rates, this work establishes the first reproducible framework enabling practitioners to build custom agentic security models adapted to their threat landscapes.

</details>


### [238] [Comment on: Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Tasks](https://arxiv.org/abs/2601.00856)
*Milos Stankovic,Ella Hirche,Sarah Kollatzsch,Julia Nadine Doetsch*

Main category: cs.AI

TL;DR: A critique of Kosmyna et al.'s study on AI and human performance, pointing out design flaws, reproducibility, methodological issues, and transparency gaps, suggesting improvements for publication.


<details>
  <summary>Details</summary>
Motivation: To provide constructive feedback on the study by Kosmyna et al. (2025) to enhance its readiness for peer-reviewed publication by addressing identified limitations.

Method: The analysis focuses on reviewing the study design, sample size, reproducibility of analyses, EEG methodology, result reporting, and transparency.

Result: Identified key concerns include limited sample size, reproducibility issues, methodological flaws in EEG analysis, inconsistent results reporting, and lack of transparency.

Conclusion: The paper critiques the study by Kosmyna et al. (2025), highlighting concerns about study design, reproducibility, methodological issues, result inconsistencies, and transparency. It suggests more conservative interpretation of results and improvements for peer-reviewed publication.

Abstract: Recently published work titled Your Brain on ChatGPT: Accumulation of Cognitive Debt When Using an AI Assistant for Essay Writing Task by Kosmyna et al. (2025) has sparked a vivid debate on the topic of artificial intelligence (AI) and human performance. We sincerely congratulate Kosmyna et al. for initiating such important research, collecting a valuable dataset, and establishing highly automated pipelines for Natural Language Processing (NLP) analyses and scoring. We aim to provide constructive comments that may improve the manuscript's readiness for peer-reviewed publication, as some results by Kosmyna et al. (2025) could be interpreted more conservatively. Our primary concerns focus on: (i) study design considerations, including the limited sample size; (ii) the reproducibility of the analyses; (iii) methodological issues related to the EEG analysis; (iv) inconsistencies in the reporting of results; and (v) limited transparency in several aspects of the study's procedures and findings.

</details>


### [239] [Cultural Encoding in Large Language Models: The Existence Gap in AI-Mediated Brand Discovery](https://arxiv.org/abs/2601.00869)
*Huang Junyao,Situ Ruimin,Ye Renqin*

Main category: cs.AI

TL;DR: 研究显示，品牌在AI推荐中的可见性高度依赖训练数据的文化编码，中国LLMs的品牌提及率显著高于国际LLMs，提出了数据护城河框架和生成引擎优化战略。


<details>
  <summary>Details</summary>
Motivation: 探讨AI系统中品牌推荐的系统性差异，揭示训练数据地理分布对品牌可见性的影响。

Method: 分析了1,909个纯英文查询，覆盖6种大型语言模型（GPT-4o、Claude、Gemini、Qwen3、DeepSeek、Doubao）和30个品牌，通过案例研究（如Zhizibianjie）验证了语言边界障碍的影响。

Result: 中国LLMs的品牌提及率比国际LLMs高30.6个百分点（88.9% vs. 58.3%），且相同英文查询中差异仍存在，表明训练数据地理分布是主要驱动因素。

Conclusion: 研究发现，品牌在AI中介市场中的可见性受限于其训练数据的文化编码，提出了‘数据护城河框架’和‘算法无处不在’作为生成引擎优化的战略目标，并为品牌提供了18个月的建设路线图。

Abstract: As artificial intelligence systems increasingly mediate consumer information discovery,
  brands face algorithmic invisibility. This study investigates Cultural Encoding in Large
  Language Models (LLMs) -- systematic differences in brand recommendations arising from
  training data composition. Analyzing 1,909 pure-English queries across 6 LLMs (GPT-4o,
  Claude, Gemini, Qwen3, DeepSeek, Doubao) and 30 brands, we find Chinese LLMs exhibit 30.6
  percentage points higher brand mention rates than International LLMs (88.9% vs. 58.3%,
  p<.001). This disparity persists in identical English queries, indicating training data
  geography -- not language -- drives the effect. We introduce the Existence Gap: brands
  absent from LLM training corpora lack "existence" in AI responses regardless of quality.
  Through a case study of Zhizibianjie (OmniEdge), a collaboration platform with 65.6%
  mention rate in Chinese LLMs but 0% in International models (p<.001), we demonstrate how
  Linguistic Boundary Barriers create invisible market entry obstacles. Theoretically, we
  contribute the Data Moat Framework, conceptualizing AI-visible content as a VRIN strategic
  resource. We operationalize Algorithmic Omnipresence -- comprehensive brand visibility
  across LLM knowledge bases -- as the strategic objective for Generative Engine Optimization
  (GEO). Managerially, we provide an 18-month roadmap for brands to build Data Moats
  through semantic coverage, technical depth, and cultural localization. Our findings reveal
  that in AI-mediated markets, the limits of a brand's "Data Boundaries" define the limits
  of its "Market Frontiers."

</details>


### [240] [Universal Conditional Logic: A Formal Language for Prompt Engineering](https://arxiv.org/abs/2601.00880)
*Anthony Mikinka*

Main category: cs.AI

TL;DR: UCL框架将提示工程系统化，显著降低令牌使用，模型架构差异影响优化配置。


<details>
  <summary>Details</summary>
Motivation: 将提示工程从启发式实践转变为系统优化，提出Universal Conditional Logic（UCL）数学框架。

Method: 通过系统评估（N=305，11个模型，4次迭代），验证了核心机制——指示函数、结构开销和早期绑定。

Result: 显著减少令牌使用（29.8%），并通过结构开销函数解释了版本特定性能差异。

Conclusion: UCL被确立为一个可校准的框架，用于高效的LLM交互，模型家族特定优化成为关键研究方向。

Abstract: We present Universal Conditional Logic (UCL), a mathematical framework for prompt optimization that transforms prompt engineering from heuristic practice into systematic optimization. Through systematic evaluation (N=305, 11 models, 4 iterations), we demonstrate significant token reduction (29.8%, t(10)=6.36, p < 0.001, Cohen's d = 2.01) with corresponding cost savings. UCL's structural overhead function O_s(A) explains version-specific performance differences through the Over-Specification Paradox: beyond threshold S* = 0.509, additional specification degrades performance quadratically. Core mechanisms -- indicator functions (I_i in {0,1}), structural overhead (O_s = gamma * sum(ln C_k)), early binding -- are validated. Notably, optimal UCL configuration varies by model architecture -- certain models (e.g., Llama 4 Scout) require version-specific adaptations (V4.1). This work establishes UCL as a calibratable framework for efficient LLM interaction, with model-family-specific optimization as a key research direction.

</details>


### [241] [Counterfactual Self-Questioning for Stable Policy Optimization in Language Models](https://arxiv.org/abs/2601.00885)
*Mandar Parab*

Main category: cs.AI

TL;DR: 提出 Counterfactual Self-Questioning 框架，单语言模型通过自我生成和评估反事实批评改进推理，无需外部辅助，实验显示其提升准确性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 现有语言模型自我改进方法多依赖外部批评者、学习奖励模型或集成采样，增加了复杂性和训练不稳定性。

Method: 该方法首先生成初始推理轨迹，然后针对潜在失败点提出针对性问题，并生成替代推理轨迹以暴露错误假设或无效步骤，从而提供结构化相对反馈。

Result: 在多个数学推理基准测试中，Counterfactual Self-Questioning 提高了准确性和训练稳定性。

Conclusion: Counterfactual Self-Questioning 框架通过单语言模型生成和评估自身推理的反事实批评，无需外部批评者或奖励模型，显著提升了推理准确性和训练稳定性，尤其适用于小型模型。

Abstract: Recent work on language model self-improvement shows that models can refine their own reasoning through reflection, verification, debate, or self-generated rewards. However, most existing approaches rely on external critics, learned reward models, or ensemble sampling, which increases complexity and training instability. We propose Counterfactual Self-Questioning, a framework in which a single language model generates and evaluates counterfactual critiques of its own reasoning. The method produces an initial reasoning trace, formulates targeted questions that challenge potential failure points, and generates alternative reasoning trajectories that expose incorrect assumptions or invalid steps. These counterfactual trajectories provide structured relative feedback that can be directly used for policy optimization without auxiliary models. Experiments on multiple mathematical reasoning benchmarks show that counterfactual self-questioning improves accuracy and training stability, particularly for smaller models, enabling scalable self-improvement using internally generated supervision alone.

</details>


### [242] [Context Collapse: In-Context Learning and Model Collapse](https://arxiv.org/abs/2601.00923)
*Josef Ott*

Main category: cs.AI

TL;DR: 论文研究LLM中的上下文学习和模型崩溃，揭示ICL的相变和梯度旋转机制，证明模型崩溃的必然性，并提出上下文崩溃概念。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型中上下文学习和模型崩溃的机制及其对生成模型长期稳定性的影响。

Method: 使用线性变换器和权重绑定技术研究ICL，通过预条件梯度下降分析最优预条件器；利用鞅和随机游走理论分析线性回归和高斯拟合下的模型崩溃。

Result: 发现ICL中参数相变和梯度方向旋转现象，证明模型崩溃几乎必然发生，除非数据增长足够快或长期保留，并提出上下文崩溃概念。

Conclusion: 该论文通过线性变换器和简化设置研究了大型语言模型中的上下文学习和模型崩溃现象，揭示了参数相变和梯度方向旋转的机制，并提出了上下文崩溃的新概念，将ICL动态与生成模型的长期稳定性挑战联系起来。

Abstract: This thesis investigates two key phenomena in large language models (LLMs): in-context learning (ICL) and model collapse. We study ICL in a linear transformer with tied weights trained on linear regression tasks, and show that minimising the in-context loss leads to a phase transition in the learned parameters. Above a critical context length, the solution develops a skew-symmetric component. We prove this by reducing the forward pass of the linear transformer under weight tying to preconditioned gradient descent, and then analysing the optimal preconditioner. This preconditioner includes a skew-symmetric component, which induces a rotation of the gradient direction. For model collapse, we use martingale and random walk theory to analyse simplified settings - linear regression and Gaussian fitting - under both replacing and cumulative data regimes. We strengthen existing results by proving almost sure convergence, showing that collapse occurs unless the data grows sufficiently fast or is retained over time. Finally, we introduce the notion of context collapse: a degradation of context during long generations, especially in chain-of-thought reasoning. This concept links the dynamics of ICL with long-term stability challenges in generative models.

</details>


### [243] [ElecTwit: A Framework for Studying Persuasion in Multi-Agent Social Systems](https://arxiv.org/abs/2601.00994)
*Michael Bao*

Main category: cs.AI

TL;DR: ElecTwit是一个模拟社交媒体政治选举互动的框架，研究LLM在多智能体系统中的说服行为，发现25种说服技术使用广泛，模型差异影响显著，并观察到独特现象。


<details>
  <summary>Details</summary>
Motivation: 旨在克服以往研究中基于游戏的模拟的局限性，通过更真实的环境研究说服行为。

Method: 通过在多智能体系统中模拟社交媒体平台上的互动，特别是在政治选举期间，设计了一个名为ElecTwit的仿真框架。

Result: 观察到25种特定说服技术在大多数测试的LLM中被广泛使用，范围超过以往报告。不同模型在技术使用和整体说服输出上的差异突显了模型架构和训练对现实社交模拟动态的影响。此外，还发现了独特现象，如“真相内核”信息和自发的“墨水”迷恋现象。

Conclusion: 本研究为评估现实世界中具有说服力的LLM代理提供了基础，确保其一致性并预防潜在危险结果。

Abstract: This paper introduces ElecTwit, a simulation framework designed to study persuasion within multi-agent systems, specifically emulating the interactions on social media platforms during a political election. By grounding our experiments in a realistic environment, we aimed to overcome the limitations of game-based simulations often used in prior research. We observed the comprehensive use of 25 specific persuasion techniques across most tested LLMs, encompassing a wider range than previously reported. The variations in technique usage and overall persuasion output between models highlight how different model architectures and training can impact the dynamics in realistic social simulations. Additionally, we observed unique phenomena such as "kernel of truth" messages and spontaneous developments with an "ink" obsession, where agents collectively demanded written proof. Our study provides a foundation for evaluating persuasive LLM agents in real-world contexts, ensuring alignment and preventing dangerous outcomes.

</details>


### [244] [Reinforcement Learning Enhanced Multi-hop Reasoning for Temporal Knowledge Question Answering](https://arxiv.org/abs/2601.01195)
*Wuzhenghong Wen,Chao Xue,Su Pan,Yuwei Sun,Minlong Peng*

Main category: cs.AI

TL;DR: MRE框架通过提示工程和T-GRPO优化多跳推理，提升TKGQA性能。


<details>
  <summary>Details</summary>
Motivation: 解决TKGQA中多跳推理时因时间相似和语义复杂关系导致的子图检索问题，减少次优决策和错误传播。

Method: 提出MRE框架，包括提示工程生成多样化推理轨迹、监督微调作为冷启动策略，以及T-GRPO（树形相对策略优化）递归学习方法。

Result: 在两个TKGQA基准测试中，MRE模型在复杂多跳查询处理上表现优于现有SOTA方法，且具有更好的可解释性和对噪声时间标注的鲁棒性。

Conclusion: MRE框架通过增强前向和后向推理，结合T-GRPO方法，显著提升了TKGQA任务中的多跳推理能力，并在复杂查询处理上超越了现有SOTA方法。

Abstract: Temporal knowledge graph question answering (TKGQA) involves multi-hop reasoning over temporally constrained entity relationships in the knowledge graph to answer a given question. However, at each hop, large language models (LLMs) retrieve subgraphs with numerous temporally similar and semantically complex relations, increasing the risk of suboptimal decisions and error propagation. To address these challenges, we propose the multi-hop reasoning enhanced (MRE) framework, which enhances both forward and backward reasoning to improve the identification of globally optimal reasoning trajectories. Specifically, MRE begins with prompt engineering to guide the LLM in generating diverse reasoning trajectories for a given question. Valid reasoning trajectories are then selected for supervised fine-tuning, serving as a cold-start strategy. Finally, we introduce Tree-Group Relative Policy Optimization (T-GRPO), a recursive, tree-structured learning-by-exploration approach. At each hop, exploration establishes strong causal dependencies on the previous hop, while evaluation is informed by multi-path exploration feedback from subsequent hops. Experimental results on two TKGQA benchmarks indicate that the proposed MRE-based model consistently surpasses state-of-the-art (SOTA) approaches in handling complex multi-hop queries. Further analysis highlights improved interpretability and robustness to noisy temporal annotations.

</details>


### [245] [Accelerating Monte-Carlo Tree Search with Optimized Posterior Policies](https://arxiv.org/abs/2601.01301)
*Keith Frankston,Benjamin Howard*

Main category: cs.AI

TL;DR: RMCTS是一种快速递归蒙特卡洛树搜索算法，速度显著优于MCTS-UCB，性能相当。


<details>
  <summary>Details</summary>
Motivation: 解决AlphaZero的MCTS-UCB算法速度较慢的问题，提升搜索效率。

Method: 采用递归的AlphaZero风格蒙特卡洛树搜索算法（RMCTS），通过广度优先搜索和大批量网络推断减少GPU延迟。

Result: RMCTS在单根状态搜索时比MCTS-UCB快40倍，大批量搜索时快3倍，且训练时间缩短至三分之一。

Conclusion: RMCTS在训练时间和性能上与MCTS-UCB相当，但速度显著更快。

Abstract: We introduce a recursive AlphaZero-style Monte--Carlo tree search algorithm, "RMCTS". The advantage of RMCTS over AlphaZero's MCTS-UCB is speed. In RMCTS, the search tree is explored in a breadth-first manner, so that network inferences naturally occur in large batches. This significantly reduces the GPU latency cost. We find that RMCTS is often more than 40 times faster than MCTS-UCB when searching a single root state, and about 3 times faster when searching a large batch of root states.
  The recursion in RMCTS is based on computing optimized posterior policies at each game state in the search tree, starting from the leaves and working back up to the root. Here we use the posterior policy explored in "Monte--Carlo tree search as regularized policy optimization" (Grill, et al.) Their posterior policy is the unique policy which maximizes the expected reward given estimated action rewards minus a penalty for diverging from the prior policy.
  The tree explored by RMCTS is not defined in an adaptive manner, as it is in MCTS-UCB. Instead, the RMCTS tree is defined by following prior network policies at each node. This is a disadvantage, but the speedup advantage is more significant, and in practice we find that RMCTS-trained networks match the quality of MCTS-UCB-trained networks in roughly one-third of the training time. We include timing and quality comparisons of RMCTS vs. MCTS-UCB for three games: Connect-4, Dots-and-Boxes, and Othello.

</details>


### [246] [Digital Twin AI: Opportunities and Challenges from Large Language Models to World Models](https://arxiv.org/abs/2601.01321)
*Rong Zhou,Dongping Chen,Zihan Jia,Yao Su,Yixin Liu,Yiwen Lu,Dongwei Shi,Yue Huang,Tianyang Xu,Yi Pan,Xinliang Li,Yohannes Abate,Qingyu Chen,Zhengzhong Tu,Yu Yang,Yu Zhang,Qingsong Wen,Gengchen Mai,Sunyang Fu,Jiachen Li,Xuyu Wang,Ziran Wang,Jing Huang,Tianming Liu,Yong Chen,Lichao Sun,Lifang He*

Main category: cs.AI

TL;DR: 本文提出了一个四阶段框架，系统化AI在数字孪生生命周期中的集成，强调物理建模与数据驱动的协同，并探讨生成式AI如何提升数字孪生的认知能力。


<details>
  <summary>Details</summary>
Motivation: 数字孪生作为物理系统的精确数字表示，通过人工智能技术的集成，已从被动仿真工具演变为智能自主实体。本文旨在系统性地描述AI在数字孪生生命周期中的集成方式。

Method: 通过综合现有技术和实践，提炼出一个统一的四阶段框架，包括建模、镜像、干预和自主管理，并分析了物理建模与数据驱动学习的协同作用。

Result: 通过跨领域综述，识别了与可扩展性、可解释性和可信赖性相关的共同挑战，并提出了负责任AI驱动数字孪生系统的发展方向。

Conclusion: 本文提出了一个统一的四阶段框架，系统性地描述了人工智能技术在数字孪生生命周期中的集成，强调了从传统数值求解器向物理信息和基础模型的转变，并探讨了生成式AI技术如何将数字孪生转变为主动和自我改进的认知系统。

Abstract: Digital twins, as precise digital representations of physical systems, have evolved from passive simulation tools into intelligent and autonomous entities through the integration of artificial intelligence technologies. This paper presents a unified four-stage framework that systematically characterizes AI integration across the digital twin lifecycle, spanning modeling, mirroring, intervention, and autonomous management. By synthesizing existing technologies and practices, we distill a unified four-stage framework that systematically characterizes how AI methodologies are embedded across the digital twin lifecycle: (1) modeling the physical twin through physics-based and physics-informed AI approaches, (2) mirroring the physical system into a digital twin with real-time synchronization, (3) intervening in the physical twin through predictive modeling, anomaly detection, and optimization strategies, and (4) achieving autonomous management through large language models, foundation models, and intelligent agents. We analyze the synergy between physics-based modeling and data-driven learning, highlighting the shift from traditional numerical solvers to physics-informed and foundation models for physical systems. Furthermore, we examine how generative AI technologies, including large language models and generative world models, transform digital twins into proactive and self-improving cognitive systems capable of reasoning, communication, and creative scenario generation. Through a cross-domain review spanning eleven application domains, including healthcare, aerospace, smart manufacturing, robotics, and smart cities, we identify common challenges related to scalability, explainability, and trustworthiness, and outline directions for responsible AI-driven digital twin systems.

</details>


### [247] [Beyond Gemini-3-Pro: Revisiting LLM Routing and Aggregation at Scale](https://arxiv.org/abs/2601.01330)
*Shengji Tang,Weihao Lin,Jingqi Ye,Hao Li,Bo Zhang,Shuyue Hu,Tao Chen,Wangli Ouyang,Lei Bai,Peng Ye*

Main category: cs.AI

TL;DR: JiSi框架通过创新路由和聚合方法，使开源LLM协作超越Gemini-3-Pro，展示了集体智能的AGI潜力。


<details>
  <summary>Details</summary>
Motivation: 探索集体智能作为替代单一模型扩展的方法，解决当前路由和聚合的瓶颈。

Method: 引入JiSi框架，包含三个创新：混合查询-响应路由、基于支持集的聚合器选择和自适应路由-聚合切换。

Result: 在九个基准测试中，JiSi仅用47%的成本即超越Gemini-3-Pro，并优于主流基线。

Conclusion: JiSi框架通过集体智能展示了超越Gemini-3-Pro的潜力，为AGI提供了一条新路径。

Abstract: Large Language Models (LLMs) have rapidly advanced, with Gemini-3-Pro setting a new performance milestone. In this work, we explore collective intelligence as an alternative to monolithic scaling, and demonstrate that open-source LLMs' collaboration can surpass Gemini-3-Pro. We first revisit LLM routing and aggregation at scale and identify three key bottlenecks: (1) current train-free routers are limited by a query-based paradigm focusing solely on textual similarity; (2) recent aggregation methods remain largely static, failing to select appropriate aggregators for different tasks;(3) the complementarity of routing and aggregation remains underutilized. To address these problems, we introduce JiSi, a novel framework designed to release the full potential of LLMs' collaboration through three innovations: (1) Query-Response Mixed Routing capturing both semantic information and problem difficulty; (2) Support-Set-based Aggregator Selection jointly evaluating the aggregation and domain capacity of aggregators; (3) Adaptive Routing-Aggregation Switch dynamically leveraging the advantages of routing and aggregation. Comprehensive experiments on nine benchmarks demonstrate that JiSi can surpass Gemini-3-Pro with only 47% costs by orchestrating ten open-source LLMs, while outperforming mainstream baselines. It suggests that collective intelligence represents a novel path towards Artificial General Intelligence (AGI).

</details>


### [248] [A unified multimodal understanding and generation model for cross-disciplinary scientific research](https://arxiv.org/abs/2601.01363)
*Xiaomeng Yang,Zhiyu Tan,Xiaohui Zhong,Mengping Yang,Qiusheng Huang,Lei Chen,Libo Wu,Hao Li*

Main category: cs.AI

TL;DR: FuXi-Uni是一个统一的多模态科学模型，通过跨学科标记对齐和科学解码器，在地球科学和生物医学领域表现出色，优于现有SOTA模型。


<details>
  <summary>Details</summary>
Motivation: 解决跨学科科学问题需要整合异构、高维数据，而现有AI模型通常局限于特定领域或缺乏同时理解和生成多模态科学数据的能力。

Method: FuXi-Uni将跨学科科学标记与自然语言标记对齐，并利用科学解码器重建科学标记，支持自然语言对话和科学数值预测。

Result: 在地球科学中，FuXi-Uni的10天全球天气预报在0.25°分辨率下优于SOTA物理预报系统，在热带气旋预测和高分辨率区域天气场生成中表现卓越；在生物医学中，它在多个生物医学视觉问答基准上领先于其他多模态大语言模型。

Conclusion: FuXi-Uni通过统一异构科学模态于原生共享潜在空间，同时保持强大的领域特定性能，为更通用的多模态科学模型迈出了一步。

Abstract: Scientific discovery increasingly relies on integrating heterogeneous, high-dimensional data across disciplines nowadays. While AI models have achieved notable success across various scientific domains, they typically remain domain-specific or lack the capability of simultaneously understanding and generating multimodal scientific data, particularly for high-dimensional data. Yet, many pressing global challenges and scientific problems are inherently cross-disciplinary and require coordinated progress across multiple fields. Here, we present FuXi-Uni, a native unified multimodal model for scientific understanding and high-fidelity generation across scientific domains within a single architecture. Specifically, FuXi-Uni aligns cross-disciplinary scientific tokens within natural language tokens and employs science decoder to reconstruct scientific tokens, thereby supporting both natural language conversation and scientific numerical prediction. Empirically, we validate FuXi-Uni in Earth science and Biomedicine. In Earth system modeling, the model supports global weather forecasting, tropical cyclone (TC) forecast editing, and spatial downscaling driven by only language instructions. FuXi-Uni generates 10-day global forecasts at 0.25° resolution that outperform the SOTA physical forecasting system. It shows superior performance for both TC track and intensity prediction relative to the SOTA physical model, and generates high-resolution regional weather fields that surpass standard interpolation baselines. Regarding biomedicine, FuXi-Uni outperforms leading multimodal large language models on multiple biomedical visual question answering benchmarks. By unifying heterogeneous scientific modalities within a native shared latent space while maintaining strong domain-specific performance, FuXi-Uni provides a step forward more general-purpose, multimodal scientific models.

</details>


### [249] [KGCE: Knowledge-Augmented Dual-Graph Evaluator for Cross-Platform Educational Agent Benchmarking with Multimodal Language Models](https://arxiv.org/abs/2601.01366)
*Zixian Liu,Sihao Liu,Yuqi Zhao*

Main category: cs.AI

TL;DR: KGCE 是一个结合知识库和双图评估的教育跨平台任务基准平台，解决了现有框架的不足并提升了代理效率。


<details>
  <summary>Details</summary>
Motivation: 现有基准框架在教育场景的跨平台任务支持上存在不足，尤其是对私有领域软件的结构理解不足导致代理效率低下，且当前评估方法难以捕捉复杂任务中的细节执行效率。

Method: KGCE 整合了知识库增强和双图评估框架，构建了包含104个教育相关任务的数据集，并开发了针对学校特定软件的知识库增强代理系统。

Result: KGCE 通过双图评估框架提供了细粒度的评估指标，并显著提升了代理在私有领域任务中的执行效率。

Conclusion: KGCE 提出了一种结合知识库增强和双图评估框架的新基准平台，有效解决了教育场景中跨平台任务执行的评估问题，并显著提升了代理在私有领域软件中的执行效率。

Abstract: With the rapid adoption of multimodal large language models (MLMs) in autonomous agents, cross-platform task execution capabilities in educational settings have garnered significant attention. However, existing benchmark frameworks still exhibit notable deficiencies in supporting cross-platform tasks in educational contexts, especially when dealing with school-specific software (such as XiaoYa Intelligent Assistant, HuaShi XiaZi, etc.), where the efficiency of agents often significantly decreases due to a lack of understanding of the structural specifics of these private-domain software. Additionally, current evaluation methods heavily rely on coarse-grained metrics like goal orientation or trajectory matching, making it challenging to capture the detailed execution and efficiency of agents in complex tasks. To address these issues, we propose KGCE (Knowledge-Augmented Dual-Graph Evaluator for Cross-Platform Educational Agent Benchmarking with Multimodal Language Models), a novel benchmarking platform that integrates knowledge base enhancement and a dual-graph evaluation framework. We first constructed a dataset comprising 104 education-related tasks, covering Windows, Android, and cross-platform collaborative tasks. KGCE introduces a dual-graph evaluation framework that decomposes tasks into multiple sub-goals and verifies their completion status, providing fine-grained evaluation metrics. To overcome the execution bottlenecks of existing agents in private-domain tasks, we developed an enhanced agent system incorporating a knowledge base specific to school-specific software. The code can be found at https://github.com/Kinginlife/KGCE.

</details>


### [250] [Empowering Small Language Models with Factual Hallucination-Aware Reasoning for Financial Classification](https://arxiv.org/abs/2601.01378)
*Han Yuan,Yilin Wu,Li Zhang,Zheng Ma*

Main category: cs.AI

TL;DR: 论文提出AAAI流程，通过检测和修正事实幻觉提升SLMs在金融分类中的表现。


<details>
  <summary>Details</summary>
Motivation: 小型语言模型（SLMs）在金融分类中因事实幻觉导致性能较差，需探索缓解这一问题的方法。

Method: 采用三步流程AAAI，包括关联识别、自动检测和自适应推理，并通过实验验证其有效性。

Result: 实验表明：(1) 事实幻觉与错误分类正相关；(2) 基于编码器的验证器能有效检测事实幻觉；(3) 反馈机制可提升分类性能。

Conclusion: 该论文提出的AAAI流程（关联识别、自动检测和自适应推理）有助于提升小型语言模型（SLMs）在金融分类中的可信度和有效性。

Abstract: Small language models (SLMs) are increasingly used for financial classification due to their fast inference and local deployability. However, compared with large language models, SLMs are more prone to factual hallucinations in reasoning and exhibit weaker classification performance. This raises a natural question: Can mitigating factual hallucinations improve SLMs' financial classification? To address this, we propose a three-step pipeline named AAAI (Association Identification, Automated Detection, and Adaptive Inference). Experiments on three representative SLMs reveal that: (1) factual hallucinations are positively correlated with misclassifications; (2) encoder-based verifiers effectively detect factual hallucinations; and (3) incorporating feedback on factual errors enables SLMs' adaptive inference that enhances classification performance. We hope this pipeline contributes to trustworthy and effective applications of SLMs in finance.

</details>


### [251] [A construction of an optimal base for conditional attribute and attributional condition implications in triadic contexts](https://arxiv.org/abs/2601.01467)
*Romuald Kwessy Mouona,Blaise Blériot Koguep Njionou,Etienne Romuald Temgoua Alomo,Rokia Missaoui,Leonard Kwuida*

Main category: cs.AI

TL;DR: 研究三元上下文中的条件属性和属性条件蕴含，并构建其最优基。


<details>
  <summary>Details</summary>
Motivation: 探讨三元上下文中这些蕴含的潜在应用和理论基础。

Method: 研究聚焦于Ganter和Obiedkov引入的条件属性和属性条件蕴含。

Result: 成功构建了这些蕴含的最优基。

Conclusion: 本文为三元上下文中的条件属性和属性条件蕴含构建了一个最优基。

Abstract: This article studies implications in triadic contexts. Specifically, we focus on those introduced by Ganter and Obiedkov, namely conditional attribute and attributional condition implications. Our aim is to construct an optimal base for these implications.

</details>


### [252] [Reading Between the Lines: Deconfounding Causal Estimates using Text Embeddings and Deep Learning](https://arxiv.org/abs/2601.01511)
*Ahmed Dawoud,Osama El-Shamy*

Main category: cs.AI

TL;DR: 研究提出神经网络增强的DML框架，利用文本嵌入解决观测性研究中的混杂偏差，深度学习方法显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 在观测性研究中，未观察到的混杂因素常导致选择偏差，而传统计量经济学方法难以处理与结构化协变量正交的混杂因素。高维非结构化文本数据可能包含这些潜在变量的丰富代理信息。

Method: 提出了一种神经网络增强的双重机器学习（DML）框架，利用文本嵌入进行因果识别，并通过合成基准验证其效果。

Result: 研究表明，非结构化文本嵌入能捕捉结构化表格数据中缺失的关键混杂信息。标准的基于树的DML估计器因无法建模嵌入流形的连续拓扑结构而保留显著偏差（+24%），而深度学习方法通过优化架构将偏差降至-0.86%，有效恢复了真实因果参数。

Conclusion: 深度学习架构在利用高维自然语言数据进行因果推断时至关重要，能够有效满足无混杂假设。

Abstract: Estimating causal treatment effects in observational settings is frequently compromised by selection bias arising from unobserved confounders. While traditional econometric methods struggle when these confounders are orthogonal to structured covariates, high-dimensional unstructured text often contains rich proxies for these latent variables. This study proposes a Neural Network-Enhanced Double Machine Learning (DML) framework designed to leverage text embeddings for causal identification. Using a rigorous synthetic benchmark, we demonstrate that unstructured text embeddings capture critical confounding information that is absent from structured tabular data. However, we show that standard tree-based DML estimators retain substantial bias (+24%) due to their inability to model the continuous topology of embedding manifolds. In contrast, our deep learning approach reduces bias to -0.86% with optimized architectures, effectively recovering the ground-truth causal parameter. These findings suggest that deep learning architectures are essential for satisfying the unconfoundedness assumption when conditioning on high-dimensional natural language data

</details>


### [253] [Bayesian Orchestration of Multi-LLM Agents for Cost-Aware Sequential Decision-Making](https://arxiv.org/abs/2601.01522)
*Danial Amin*

Main category: cs.AI

TL;DR: 论文提出多LLM贝叶斯框架，通过对比提示和稳健聚合优化不对称成本决策，实验显示成本降低34%、公平性提升45%。


<details>
  <summary>Details</summary>
Motivation: 现有方法（单一LLM后验阈值决策）在成本不对称的序列决策中表现不足，需改进。

Method: 采用对比提示法获取各候选状态的似然，通过稳健统计方法聚合多样模型，并在新证据到来时基于显式先验使用贝叶斯规则更新信念。

Result: 在简历筛选中，相比最佳单LLM基线，总成本降低34%（294,000美元），人口统计公平性提升45%（最大群体差距从22%降至5%）。

Conclusion: 论文提出了一个贝叶斯、成本感知的多LLM协调框架，通过将LLMs视为近似似然模型而非分类器，显著降低了决策成本并提高了公平性。

Abstract: Large language models (LLMs) are increasingly deployed as autonomous decision agents in settings with asymmetric error costs: hiring (missed talent vs wasted interviews), medical triage (missed emergencies vs unnecessary escalation), and fraud detection (approved fraud vs declined legitimate payments). The dominant design queries a single LLM for a posterior over states, thresholds "confidence," and acts; we prove this is inadequate for sequential decisions with costs. We propose a Bayesian, cost-aware multi-LLM orchestration framework that treats LLMs as approximate likelihood models rather than classifiers. For each candidate state, we elicit likelihoods via contrastive prompting, aggregate across diverse models with robust statistics, and update beliefs with Bayes rule under explicit priors as new evidence arrives. This enables coherent belief updating, expected-cost action selection, principled information gathering via value of information, and fairness gains via ensemble bias mitigation. In resume screening with costs of 40000 USD per missed hire, 2500 USD per interview, and 150 USD per phone screen, experiments on 1000 resumes using five LLMs (GPT-4o, Claude 4.5 Sonnet, Gemini Pro, Grok, DeepSeek) reduce total cost by 294000 USD (34 percent) versus the best single-LLM baseline and improve demographic parity by 45 percent (max group gap 22 to 5 percentage points). Ablations attribute 51 percent of savings to multi-LLM aggregation, 43 percent to sequential updating, and 20 percent to disagreement-triggered information gathering, consistent with the theoretical benefits of correct probabilistic foundations.

</details>


### [254] [Aletheia: Quantifying Cognitive Conviction in Reasoning Models via Regularized Inverse Confusion Matrix](https://arxiv.org/abs/2601.01532)
*Fanzhe Fu*

Main category: cs.AI

TL;DR: 本文提出Project Aletheia框架，通过Tikhonov Regularization和Synthetic Proxy Protocol量化AI认知信念深度，并引入S_aligned确保安全性，为AI科学诚信评估提供新方法。


<details>
  <summary>Details</summary>
Motivation: 当前评估范式在AGI发展中面临认识论危机，静态基准测试无法量化信念深度，需要新的框架来测量AI的认知信念。

Method: 采用Tikhonov Regularization反转评委的混淆矩阵，并通过Synthetic Proxy Protocol验证方法，避免依赖不透明的私有数据。

Result: 初步研究表明，推理模型在对抗压力下可能表现出“防御性过度思考”，同时提出了S_aligned来验证信念与安全性的平衡。

Conclusion: 本文提出了一个量化AI认知信念深度的框架Project Aletheia，并引入Aligned Conviction Score（S_aligned）来确保信念与安全性不冲突，为衡量AI科学诚信提供了蓝图。

Abstract: In the progressive journey toward Artificial General Intelligence (AGI), current evaluation paradigms face an epistemological crisis. Static benchmarks measure knowledge breadth but fail to quantify the depth of belief. While Simhi et al. (2025) defined the CHOKE phenomenon in standard QA, we extend this framework to quantify "Cognitive Conviction" in System 2 reasoning models. We propose Project Aletheia, a cognitive physics framework that employs Tikhonov Regularization to invert the judge's confusion matrix. To validate this methodology without relying on opaque private data, we implement a Synthetic Proxy Protocol. Our preliminary pilot study on 2025 baselines (e.g., DeepSeek-R1, OpenAI o1) suggests that while reasoning models act as a "cognitive buffer," they may exhibit "Defensive OverThinking" under adversarial pressure. Furthermore, we introduce the Aligned Conviction Score (S_aligned) to verify that conviction does not compromise safety. This work serves as a blueprint for measuring AI scientific integrity.

</details>


### [255] [Improving Behavioral Alignment in LLM Social Simulations via Context Formation and Navigation](https://arxiv.org/abs/2601.01546)
*Letian Kong,Qianran,Jin,Renyu Zhang*

Main category: cs.AI

TL;DR: 提出两阶段框架改善LLM与人类行为对齐，复杂任务需两阶段，简单任务仅需上下文形成。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在模拟人类行为时，在复杂决策环境中与人类行为存在系统性差异，需改进对齐方法。

Method: 提出了一个两阶段框架（上下文形成和上下文导航），并通过多个实验（顺序购买游戏、众筹游戏和需求估计任务）验证其有效性。

Result: 在四种SOTA模型上验证，复杂任务需两阶段框架，简单任务仅需上下文形成。

Conclusion: 研究发现，在复杂决策环境中，两阶段框架（上下文形成和上下文导航）对于实现LLM与人类行为对齐是必要的，而在简单任务中仅需上下文形成。这为设计和诊断LLM社会模拟提供了系统性方法。

Abstract: Large language models (LLMs) are increasingly used to simulate human behavior in experimental settings, but they systematically diverge from human decisions in complex decision-making environments, where participants must anticipate others' actions and form beliefs based on observed behavior. We propose a two-stage framework for improving behavioral alignment. The first stage, context formation, explicitly specifies the experimental design to establish an accurate representation of the decision task and its context. The second stage, context navigation, guides the reasoning process within that representation to make decisions. We validate this framework through a focal replication of a sequential purchasing game with quality signaling (Kremer and Debo, 2016), extending to a crowdfunding game with costly signaling (Cason et al., 2025) and a demand-estimation task (Gui and Toubia, 2025) to test generalizability across decision environments. Across four state-of-the-art (SOTA) models (GPT-4o, GPT-5, Claude-4.0-Sonnet-Thinking, DeepSeek-R1), we find that complex decision-making environments require both stages to achieve behavioral alignment with human benchmarks, whereas the simpler demand-estimation task requires only context formation. Our findings clarify when each stage is necessary and provide a systematic approach for designing and diagnosing LLM social simulations as complements to human subjects in behavioral research.

</details>


### [256] [CaveAgent: Transforming LLMs into Stateful Runtime Operators](https://arxiv.org/abs/2601.01569)
*Maohao Ran,Zhenglin Wan,Cooper Lin,Yanting Zhang,Hongyu Xin,Hongwei Fan,Yibo Xu,Beier Luo,Yaxin Zhou,Wangbo Zhao,Lijie Yang,Lang Feng,Fuchao Yang,Jingxuan Wu,Yiqiao Huang,Chendong Ma,Dailing Jiang,Jianbo Deng,Sihui Han,Bo An,Yike Guo,Jun Song*

Main category: cs.AI

TL;DR: CaveAgent通过双流架构和状态管理机制，解决了传统文本代理在多轮任务和数据密集型任务中的局限性，显著提升了执行效率和成功率。


<details>
  <summary>Details</summary>
Motivation: 现有的基于文本的代理系统在多轮依赖和上下文漂移问题上表现不佳，限制了复杂任务的执行能力。

Method: 提出了Dual-stream Context Architecture，将状态管理解耦为轻量级的语义流和持久化的Python运行时流，并引入了Stateful Runtime Management机制，支持复杂Python对象的注入和检索。

Result: 在Tau$^2$-bench和BFCL等基准测试中，CaveAgent在零售任务上成功率提高了10.5%，多轮场景下总token消耗减少了28.4%，数据密集型任务中token消耗减少了59%。

Conclusion: CaveAgent框架通过将LLM从文本生成器转变为运行时操作符，显著提升了复杂任务的执行效率和成功率，特别是在多轮交互和数据密集型任务中表现突出。

Abstract: LLM-based agents are increasingly capable of complex task execution, yet current agentic systems remain constrained by text-centric paradigms. Traditional approaches rely on procedural JSON-based function calling, which often struggles with long-horizon tasks due to fragile multi-turn dependencies and context drift. In this paper, we present CaveAgent, a framework that transforms the paradigm from "LLM-as-Text-Generator" to "LLM-as-Runtime-Operator." We introduce a Dual-stream Context Architecture that decouples state management into a lightweight semantic stream for reasoning and a persistent, deterministic Python Runtime stream for execution. In addition to leveraging code generation to efficiently resolve interdependent sub-tasks (e.g., loops, conditionals) in a single step, we introduce \textit{Stateful Runtime Management} in CaveAgent. Distinct from existing code-based approaches that remain text-bound and lack the support for external object injection and retrieval, CaveAgent injects, manipulates, and retrieves complex Python objects (e.g., DataFrames, database connections) that persist across turns. This persistence mechanism acts as a high-fidelity external memory to eliminate context drift, avoid catastrophic forgetting, while ensuring that processed data flows losslessly to downstream applications. Comprehensive evaluations on Tau$^2$-bench, BFCL and various case studies across representative SOTA LLMs demonstrate CaveAgent's superiority. Specifically, our framework achieves a 10.5\% success rate improvement on retail tasks and reduces total token consumption by 28.4\% in multi-turn scenarios. On data-intensive tasks, direct variable storage and retrieval reduces token consumption by 59\%, allowing CaveAgent to handle large-scale data that causes context overflow failures in both JSON-based and Code-based agents.

</details>


### [257] [Logics-STEM: Empowering LLM Reasoning via Failure-Driven Post-Training and Document Knowledge Enhancement](https://arxiv.org/abs/2601.01562)
*Mingyu Xu,Cheng Fang,Keyue Jiang,Yuqian Zheng,Yanghua Xiao,Baojian Zhou,Qifang Zhao,Suhang Zheng,Xiuwen Zhu,Jiyang Tang,Yongchi Zhao,Yijia Luo,Zhiqi Bai,Yuchi Xu,Wenbo Su,Wei Wang,Bing Zhao,Lin Qu,Xiaoxiao Xu*

Main category: cs.AI

TL;DR: Logics-STEM是一个针对STEM推理任务的先进模型，通过数据-算法协同设计和高质量数据集，显著提升推理性能。


<details>
  <summary>Details</summary>
Motivation: 针对STEM领域的推理任务，通过构建高质量、多样化的数据集和优化算法，提升推理模型的性能。

Method: Logics-STEM通过数据-算法协同设计引擎优化，包括数据阶段的5阶段精心设计（标注、去重、去污、蒸馏和分层采样）和算法阶段的失败驱动后训练框架（利用目标知识检索和数据合成）。

Result: Logics-STEM在STEM相关基准测试中表现优异，平均提升4.68%，优于其他8B规模的模型。

Conclusion: Logics-STEM展示了将大规模开源数据与精心设计的合成数据相结合的潜力，强调了数据-算法协同设计在通过后训练增强推理能力中的关键作用。

Abstract: We present Logics-STEM, a state-of-the-art reasoning model fine-tuned on Logics-STEM-SFT-Dataset, a high-quality and diverse dataset at 10M scale that represents one of the largest-scale open-source long chain-of-thought corpora. Logics-STEM targets reasoning tasks in the domains of Science, Technology, Engineering, and Mathematics (STEM), and exhibits exceptional performance on STEM-related benchmarks with an average improvement of 4.68% over the next-best model at 8B scale. We attribute the gains to our data-algorithm co-design engine, where they are jointly optimized to fit a gold-standard distribution behind reasoning. Data-wise, the Logics-STEM-SFT-Dataset is constructed from a meticulously designed data curation engine with 5 stages to ensure the quality, diversity, and scalability, including annotation, deduplication, decontamination, distillation, and stratified sampling. Algorithm-wise, our failure-driven post-training framework leverages targeted knowledge retrieval and data synthesis around model failure regions in the Supervised Fine-tuning (SFT) stage to effectively guide the second-stage SFT or the reinforcement learning (RL) for better fitting the target distribution. The superior empirical performance of Logics-STEM reveals the vast potential of combining large-scale open-source data with carefully designed synthetic data, underscoring the critical role of data-algorithm co-design in enhancing reasoning capabilities through post-training. We make both the Logics-STEM models (8B and 32B) and the Logics-STEM-SFT-Dataset (10M and downsampled 2.2M versions) publicly available to support future research in the open-source community.

</details>


### [258] [A New Benchmark for the Appropriate Evaluation of RTL Code Optimization](https://arxiv.org/abs/2601.01765)
*Yao Lu,Shang Liu,Hangan Zhou,Wenji Fang,Qijun Zhang,Zhiyao Xie*

Main category: cs.AI

TL;DR: RTL-OPT是一个评估LLM在RTL优化能力的基准，包含36个手工设计的数字设计，并集成了自动化评估框架，以量化PPA改进。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要评估语法正确性，而非优化质量（PPA），因此需要一个新的基准来评估LLM在RTL优化中的能力。

Method: RTL-OPT包含36个手工设计的数字设计，覆盖组合逻辑、流水线数据路径、有限状态机和内存接口等类别，每个任务提供一对RTL代码（次优版本和人工优化参考版本），并集成了自动化评估框架。

Result: RTL-OPT能够标准化和有意义地评估生成模型在硬件设计优化中的表现，验证功能正确性并量化PPA改进。

Conclusion: RTL-OPT是一个评估LLM在RTL优化能力的基准，包含36个手工设计的数字设计，覆盖多种实现类别，并集成了自动化评估框架，以验证功能正确性和量化PPA改进。

Abstract: The rapid progress of artificial intelligence increasingly relies on efficient integrated circuit (IC) design. Recent studies have explored the use of large language models (LLMs) for generating Register Transfer Level (RTL) code, but existing benchmarks mainly evaluate syntactic correctness rather than optimization quality in terms of power, performance, and area (PPA). This work introduces RTL-OPT, a benchmark for assessing the capability of LLMs in RTL optimization. RTL-OPT contains 36 handcrafted digital designs that cover diverse implementation categories including combinational logic, pipelined datapaths, finite state machines, and memory interfaces. Each task provides a pair of RTL codes, a suboptimal version and a human-optimized reference that reflects industry-proven optimization patterns not captured by conventional synthesis tools. Furthermore, RTL-OPT integrates an automated evaluation framework to verify functional correctness and quantify PPA improvements, enabling standardized and meaningful assessment of generative models for hardware design optimization.

</details>


### [259] [Structured Decomposition for LLM Reasoning: Cross-Domain Validation and Semantic Web Integration](https://arxiv.org/abs/2601.01609)
*Albert Sadowski,Jarosław A. Chudziak*

Main category: cs.AI

TL;DR: 论文提出了一种结合LLMs灵活性和符号推理确定性的框架，用于自然语言输入的规则推理，实验证明其在多个领域优于少样本提示。


<details>
  <summary>Details</summary>
Motivation: 在需要可审计和可证明决策的领域（如临床协议、证据规则、科学标准），规则推理需兼具解释灵活性和形式化保证。LLMs提供灵活性但无法确保一致性，符号系统提供保证但需结构化输入。

Method: 该论文提出了一种集成模式，将LLMs用作本体填充引擎，将非结构化文本转换为ABox断言，同时利用基于SWRL的推理器应用规则。框架将推理分解为实体识别、断言提取和符号验证，任务定义基于OWL 2本体。

Result: 在三个领域（法律传闻判定、科学方法任务应用、临床试验资格）和十一个语言模型上的实验验证了该方法的有效性。结构化分解在总体上显著优于少样本提示，且符号验证提供了额外收益。

Conclusion: 该框架通过结合大型语言模型（LLMs）的灵活性和基于SWRL的推理器的确定性保证，实现了对自然语言输入的规则推理，显著优于少样本提示方法，并在三个领域（法律、科学、临床）中验证了其有效性。

Abstract: Rule-based reasoning over natural language input arises in domains where decisions must be auditable and justifiable: clinical protocols specify eligibility criteria in prose, evidence rules define admissibility through textual conditions, and scientific standards dictate methodological requirements. Applying rules to such inputs demands both interpretive flexibility and formal guarantees. Large language models (LLMs) provide flexibility but cannot ensure consistent rule application; symbolic systems provide guarantees but require structured input. This paper presents an integration pattern that combines these strengths: LLMs serve as ontology population engines, translating unstructured text into ABox assertions according to expert-authored TBox specifications, while SWRL-based reasoners apply rules with deterministic guarantees. The framework decomposes reasoning into entity identification, assertion extraction, and symbolic verification, with task definitions grounded in OWL 2 ontologies. Experiments across three domains (legal hearsay determination, scientific method-task application, clinical trial eligibility) and eleven language models validate the approach. Structured decomposition achieves statistically significant improvements over few-shot prompting in aggregate, with gains observed across all three domains. An ablation study confirms that symbolic verification provides substantial benefit beyond structured prompting alone. The populated ABox integrates with standard semantic web tooling for inspection and querying, positioning the framework for richer inference patterns that simpler formalisms cannot express.

</details>


### [260] [Yuan3.0 Flash: An Open Multimodal Large Language Model for Enterprise Applications](https://arxiv.org/abs/2601.01718)
*YuanLab. ai,:,Shawn Wu,Sean Wang,Louie Li,Darcy Chen,Allen Wang,Jiangang Luo,Xudong Zhao,Joseph Shen,Gawain Ma,Jasper Jia,Marcus Mao,Claire Wang,Hunter He,Carol Wang,Zera Zhang,Jason Wang,Chonly Shen,Leo Zhang,Logan Chen,Qasim Meng,James Gong,Danied Zhao,Penn Zheng,Owen Zhu,Tong Yu*

Main category: cs.AI

TL;DR: Yuan3.0 Flash是一个开源的多模态MoE模型，通过RAPO算法解决过度思考问题，在企业任务和通用任务中均表现优异，且高效节能。


<details>
  <summary>Details</summary>
Motivation: 解决大型推理模型（LRMs）中常见的过度思考现象，并提升企业任务和通用任务的性能。

Method: 采用混合专家（MoE）架构，提出Reflection-aware Adaptive Policy Optimization（RAPO）算法来调节过度思考行为。

Result: 在企业任务（如检索增强生成、复杂表格理解和摘要）中表现优异，同时在数学、科学等领域展现强推理能力，仅需1/4至1/2的平均token即可达到前沿模型的准确率。

Conclusion: Yuan3.0 Flash是一个开源的多模态大型语言模型，专为企业任务设计，同时在通用任务上保持竞争力，已完全开源以促进研究和实际部署。

Abstract: We introduce Yuan3.0 Flash, an open-source Mixture-of-Experts (MoE) MultiModal Large Language Model featuring 3.7B activated parameters and 40B total parameters, specifically designed to enhance performance on enterprise-oriented tasks while maintaining competitive capabilities on general-purpose tasks. To address the overthinking phenomenon commonly observed in Large Reasoning Models (LRMs), we propose Reflection-aware Adaptive Policy Optimization (RAPO), a novel RL training algorithm that effectively regulates overthinking behaviors. In enterprise-oriented tasks such as retrieval-augmented generation (RAG), complex table understanding, and summarization, Yuan3.0 Flash consistently achieves superior performance. Moreover, it also demonstrates strong reasoning capabilities in domains such as mathematics, science, etc., attaining accuracy comparable to frontier model while requiring only approximately 1/4 to 1/2 of the average tokens. Yuan3.0 Flash has been fully open-sourced to facilitate further research and real-world deployment: https://github.com/Yuan-lab-LLM/Yuan3.0.

</details>


### [261] [AI Agent Systems: Architectures, Applications, and Evaluation](https://arxiv.org/abs/2601.01743)
*Bin Xu*

Main category: cs.AI

TL;DR: 该论文综述了AI代理架构的现状，提出了统一的分类法，并讨论了设计权衡、评估挑战及未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着AI代理（结合基础模型与推理、规划、记忆和工具使用的系统）成为自然语言意图与真实世界计算之间的实用接口，理解其架构和挑战变得至关重要。

Method: 论文通过综合现有研究，构建了一个统一的分类法，涵盖代理组件、协调模式和部署设置，并讨论了设计权衡和评估复杂性。

Result: 论文提出了一个统一的分类法，总结了AI代理架构的关键组件和协调模式，并分析了设计权衡和评估挑战。

Conclusion: 该论文总结了AI代理架构的关键设计权衡和评估挑战，并提出了未来的开放性问题，如工具动作的验证与防护、可扩展的内存和上下文管理、代理决策的可解释性，以及在现实工作负载下的可重复评估。

Abstract: AI agents -- systems that combine foundation models with reasoning, planning, memory, and tool use -- are rapidly becoming a practical interface between natural-language intent and real-world computation. This survey synthesizes the emerging landscape of AI agent architectures across: (i) deliberation and reasoning (e.g., chain-of-thought-style decomposition, self-reflection and verification, and constraint-aware decision making), (ii) planning and control (from reactive policies to hierarchical and multi-step planners), and (iii) tool calling and environment interaction (retrieval, code execution, APIs, and multimodal perception). We organize prior work into a unified taxonomy spanning agent components (policy/LLM core, memory, world models, planners, tool routers, and critics), orchestration patterns (single-agent vs.\ multi-agent; centralized vs.\ decentralized coordination), and deployment settings (offline analysis vs.\ online interactive assistance; safety-critical vs.\ open-ended tasks). We discuss key design trade-offs -- latency vs.\ accuracy, autonomy vs.\ controllability, and capability vs.\ reliability -- and highlight how evaluation is complicated by non-determinism, long-horizon credit assignment, tool and environment variability, and hidden costs such as retries and context growth. Finally, we summarize measurement and benchmarking practices (task suites, human preference and utility metrics, success under constraints, robustness and security) and identify open challenges including verification and guardrails for tool actions, scalable memory and context management, interpretability of agent decisions, and reproducible evaluation under realistic workloads.

</details>


### [262] [Can Large Language Models Solve Engineering Equations? A Systematic Comparison of Direct Prediction and Solver-Assisted Approaches](https://arxiv.org/abs/2601.01774)
*Sai Varun Kodathala,Rakesh Vunnam*

Main category: cs.AI

TL;DR: LLMs在符号操作和知识检索上表现优异，但数值精度不足，更适合作为经典求解器的智能接口。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型是否能通过直接数值预测或结合符号操作与经典迭代求解器的混合架构有效解决工程中的超越方程。

Method: 通过测试六种先进模型（GPT-5.1、GPT-5.2、Gemini-3-Flash、Gemini-2.5-Lite、Claude-Sonnet-4.5、Claude-Opus-4.5）在100个跨七个工程领域的问题上，比较直接预测与求解器辅助计算的性能。

Result: 直接预测的平均相对误差为0.765至1.262，而求解器辅助计算的误差为0.225至0.301，误差减少67.9%至81.8%。电子学领域改善显著（93.1%），流体力学领域改善较小（7.2%）。

Conclusion: 当代大型语言模型（LLMs）擅长符号操作和领域知识检索，但在精度关键的迭代算术上表现不佳，建议将其作为经典数值求解器的智能接口而非独立计算引擎。

Abstract: Transcendental equations requiring iterative numerical solution pervade engineering practice, from fluid mechanics friction factor calculations to orbital position determination. We systematically evaluate whether Large Language Models can solve these equations through direct numerical prediction or whether a hybrid architecture combining LLM symbolic manipulation with classical iterative solvers proves more effective. Testing six state-of-the-art models (GPT-5.1, GPT-5.2, Gemini-3-Flash, Gemini-2.5-Lite, Claude-Sonnet-4.5, Claude-Opus-4.5) on 100 problems spanning seven engineering domains, we compare direct prediction against solver-assisted computation where LLMs formulate governing equations and provide initial conditions while Newton-Raphson iteration performs numerical solution. Direct prediction yields mean relative errors of 0.765 to 1.262 across models, while solver-assisted computation achieves 0.225 to 0.301, representing error reductions of 67.9% to 81.8%. Domain-specific analysis reveals dramatic improvements in Electronics (93.1%) due to exponential equation sensitivity, contrasted with modest gains in Fluid Mechanics (7.2%) where LLMs exhibit effective pattern recognition. These findings establish that contemporary LLMs excel at symbolic manipulation and domain knowledge retrieval but struggle with precision-critical iterative arithmetic, suggesting their optimal deployment as intelligent interfaces to classical numerical solvers rather than standalone computational engines.

</details>


### [263] [PsychEval: A Multi-Session and Multi-Therapy Benchmark for High-Realism and Comprehensive AI Psychological Counselor](https://arxiv.org/abs/2601.01802)
*Qianjun Pan,Junyi Wang,Jie Zhou,Yutao Yang,Junsong Li,Kaiyin Xu,Yougen Zhou,Yihan Li,Jingyuan Zhao,Qin Chen,Ningning Zhou,Kai Chen,Liang He*

Main category: cs.AI

TL;DR: PsychEval是一个多会话、多疗法的高真实感AI心理咨询基准测试，解决了AI咨询师的真实性、多疗法训练和系统性评估问题。


<details>
  <summary>Details</summary>
Motivation: 开发可靠的AI心理评估工具，解决三个关键挑战：训练高真实感的AI咨询师、多疗法AI咨询师的训练方法，以及系统性评估AI咨询师的框架。

Method: 提出了一个多会话、多疗法的基准测试PsychEval，包含6-10个会话、三种不同阶段的数据集，标注了677种元技能和4577种原子技能，覆盖五种治疗模式和六种核心心理主题。

Result: 实验分析验证了数据集的高质量和临床保真度，构建了2000多个多样化的客户档案和18个治疗特定及共享的评估指标。

Conclusion: PsychEval作为一个高保真的强化学习环境，不仅超越了静态基准测试，还能支持临床责任感和适应性AI咨询师的自我进化训练。

Abstract: To develop a reliable AI for psychological assessment, we introduce \texttt{PsychEval}, a multi-session, multi-therapy, and highly realistic benchmark designed to address three key challenges: \textbf{1) Can we train a highly realistic AI counselor?} Realistic counseling is a longitudinal task requiring sustained memory and dynamic goal tracking. We propose a multi-session benchmark (spanning 6-10 sessions across three distinct stages) that demands critical capabilities such as memory continuity, adaptive reasoning, and longitudinal planning. The dataset is annotated with extensive professional skills, comprising over 677 meta-skills and 4577 atomic skills. \textbf{2) How to train a multi-therapy AI counselor?} While existing models often focus on a single therapy, complex cases frequently require flexible strategies among various therapies. We construct a diverse dataset covering five therapeutic modalities (Psychodynamic, Behaviorism, CBT, Humanistic Existentialist, and Postmodernist) alongside an integrative therapy with a unified three-stage clinical framework across six core psychological topics. \textbf{3) How to systematically evaluate an AI counselor?} We establish a holistic evaluation framework with 18 therapy-specific and therapy-shared metrics across Client-Level and Counselor-Level dimensions. To support this, we also construct over 2,000 diverse client profiles. Extensive experimental analysis fully validates the superior quality and clinical fidelity of our dataset. Crucially, \texttt{PsychEval} transcends static benchmarking to serve as a high-fidelity reinforcement learning environment that enables the self-evolutionary training of clinically responsible and adaptive AI counselors.

</details>


### [264] [Admissibility Alignment](https://arxiv.org/abs/2601.01816)
*Chris Duffey*

Main category: cs.AI

TL;DR: 本文提出了Admissibility Alignment概念，并通过MAP-AI系统架构实现，将AI对齐视为概率性和决策理论属性，而非静态或二元条件。


<details>
  <summary>Details</summary>
Motivation: 将AI对齐重新定义为在不确定性下对结果分布的可接受行动和决策选择的属性，通过候选政策的行为进行评估。

Method: 提出了MAP-AI（Monte Carlo Alignment for Policy）作为实现Admissibility Alignment的规范系统架构，通过蒙特卡洛估计结果分布和可接受性控制的政策选择来强制执行对齐。

Result: MAP-AI框架通过评估决策政策在多个可能未来中的表现，明确建模不确定性、干预效果、价值模糊性和治理约束，提供了一种可执行的方法来评估企业及机构AI系统中的信任和对齐。

Conclusion: Admissibility Alignment提供了一个实用的基础，用于治理那些影响由政策行为在分布和尾部事件中决定的AI系统。

Abstract: This paper introduces Admissibility Alignment: a reframing of AI alignment as a property of admissible action and decision selection over distributions of outcomes under uncertainty, evaluated through the behavior of candidate policies. We present MAP-AI (Monte Carlo Alignment for Policy) as a canonical system architecture for operationalizing admissibility alignment, formalizing alignment as a probabilistic, decision-theoretic property rather than a static or binary condition.
  MAP-AI, a new control-plane system architecture for aligned decision-making under uncertainty, enforces alignment through Monte Carlo estimation of outcome distributions and admissibility-controlled policy selection rather than static model-level constraints. The framework evaluates decision policies across ensembles of plausible futures, explicitly modeling uncertainty, intervention effects, value ambiguity, and governance constraints. Alignment is assessed through distributional properties including expected utility, variance, tail risk, and probability of misalignment rather than accuracy or ranking performance. This approach distinguishes probabilistic prediction from decision reasoning under uncertainty and provides an executable methodology for evaluating trust and alignment in enterprise and institutional AI systems. The result is a practical foundation for governing AI systems whose impact is determined not by individual forecasts, but by policy behavior across distributions and tail events. Finally, we show how distributional alignment evaluation can be integrated into decision-making itself, yielding an admissibility-controlled action selection mechanism that alters policy behavior under uncertainty without retraining or modifying underlying models.

</details>


### [265] [COMPASS: A Framework for Evaluating Organization-Specific Policy Alignment in LLMs](https://arxiv.org/abs/2601.01836)
*Dasol Choi,DongGeon Lee,Brigitta Jesica Kartono,Helena Berndt,Taeyoun Kwon,Joonwon Jang,Haon Park,Hwanjo Yu,Minsuk Kahng*

Main category: cs.AI

TL;DR: COMPASS是首个系统性评估LLMs是否符合组织政策的框架，发现当前模型在执行禁止政策时表现不佳，强调其在企业AI安全中的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型在企业高风险应用中的部署，确保其遵守组织特定政策变得至关重要，而现有安全评估仅关注普遍危害。

Method: 提出了COMPASS框架，用于评估LLMs是否符合组织的允许列表和禁止列表政策。在八个不同的行业场景中生成并验证了5,920个查询，测试常规合规性和对抗性鲁棒性。

Result: 评估七个最先进模型发现，模型在处理合法请求时准确率超过95%，但在执行禁止政策时表现极差，仅拒绝13-40%的对抗性违规请求。

Conclusion: 当前的大型语言模型缺乏政策关键部署所需的鲁棒性，COMPASS 框架为组织AI安全提供了必要的评估工具。

Abstract: As large language models are deployed in high-stakes enterprise applications, from healthcare to finance, ensuring adherence to organization-specific policies has become essential. Yet existing safety evaluations focus exclusively on universal harms. We present COMPASS (Company/Organization Policy Alignment Assessment), the first systematic framework for evaluating whether LLMs comply with organizational allowlist and denylist policies. We apply COMPASS to eight diverse industry scenarios, generating and validating 5,920 queries that test both routine compliance and adversarial robustness through strategically designed edge cases. Evaluating seven state-of-the-art models, we uncover a fundamental asymmetry: models reliably handle legitimate requests (>95% accuracy) but catastrophically fail at enforcing prohibitions, refusing only 13-40% of adversarial denylist violations. These results demonstrate that current LLMs lack the robustness required for policy-critical deployments, establishing COMPASS as an essential evaluation framework for organizational AI safety.

</details>


### [266] [Clinical Knowledge Graph Construction and Evaluation with Multi-LLMs via Retrieval-Augmented Generation](https://arxiv.org/abs/2601.01844)
*Udiptaman Das,Krishnasai B. Atmakuri,Duy Ho,Chi Lee,Yugyung Lee*

Main category: cs.AI

TL;DR: 该论文提出了一种端到端框架，直接从自由文本构建和评估临床知识图谱，无需黄金标准注释，实验结果显示其在多个指标上优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）为从非结构化临床叙述中构建知识图谱（KGs）提供了新机会。然而，现有方法通常依赖结构化输入，并且缺乏对事实准确性和语义一致性的鲁棒验证，这些限制在肿瘤学领域尤为突出。

Method: 论文提出的框架包括：（1）基于提示的实体、属性和关系提取；（2）基于熵的不确定性评分；（3）与本体对齐的RDF/OWL模式生成；（4）多LLM共识验证用于幻觉检测和语义细化。此外，该框架支持持续的细化和自监督评估，实现图谱质量的迭代改进。

Result: 该方法应用于两个肿瘤学队列（PDAC和BRCA），实验结果表明其在精确度、相关性和本体合规性方面优于基线方法。

Conclusion: 该论文提出了一种端到端的框架，利用多智能体提示和模式约束的检索增强生成（KG-RAG）策略，直接从自由文本构建和评估临床知识图谱（KG）。该方法在无需依赖黄金标准注释的情况下，生成可解释、SPARQL兼容且临床基础的知识图谱，实验结果显示其在精确度、相关性和本体合规性方面优于基线方法。

Abstract: Large language models (LLMs) offer new opportunities for constructing knowledge graphs (KGs) from unstructured clinical narratives. However, existing approaches often rely on structured inputs and lack robust validation of factual accuracy and semantic consistency, limitations that are especially problematic in oncology. We introduce an end-to-end framework for clinical KG construction and evaluation directly from free text using multi-agent prompting and a schema-constrained Retrieval-Augmented Generation (KG-RAG) strategy. Our pipeline integrates (1) prompt-driven entity, attribute, and relation extraction; (2) entropy-based uncertainty scoring; (3) ontology-aligned RDF/OWL schema generation; and (4) multi-LLM consensus validation for hallucination detection and semantic refinement. Beyond static graph construction, the framework supports continuous refinement and self-supervised evaluation, enabling iterative improvement of graph quality. Applied to two oncology cohorts (PDAC and BRCA), our method produces interpretable, SPARQL-compatible, and clinically grounded knowledge graphs without relying on gold-standard annotations. Experimental results demonstrate consistent gains in precision, relevance, and ontology compliance over baseline methods.

</details>


### [267] [Jenius Agent: Towards Experience-Driven Accuracy Optimization in Real-World Scenarios](https://arxiv.org/abs/2601.01857)
*Defei Xia,Bingfeng Pi,Shenbin Zhang,Song Hua,Yunfei Wei,Lei Zuo*

Main category: cs.AI

TL;DR: 论文提出Jenius-Agent框架，通过自适应提示、工具编排和分层内存三大创新，显著提升LLM代理的任务性能，并已在Jenius平台部署。


<details>
  <summary>Details</summary>
Motivation: 尽管基于LLM的代理系统在整体设计上已有进展，但其内部推理和工具使用流程的系统性优化仍未被充分探索。因此，作者旨在通过实际经验驱动的框架设计，提升代理在上下文理解、工具使用和响应生成方面的任务性能。

Method: 论文提出了三大关键创新：(1) 自适应提示生成策略；(2) 上下文感知工具编排模块；(3) 分层内存机制。这些方法通过优化内部推理和工具使用流程，提升了代理的性能。

Result: 实验结果显示，该框架使任务准确率提升了20%，同时降低了token成本、响应延迟和调用失败率。

Conclusion: 该论文提出了一个名为Jenius-Agent的端到端框架，通过自适应提示生成、上下文感知工具编排和分层内存机制三大创新，显著提升了任务准确率并降低了token成本、响应延迟和调用失败率。该框架已在Jenius平台部署，为轻量级、可扩展的自主代理提供了解决方案。

Abstract: As agent systems powered by large language models (LLMs) advance, improving the task performance of an autonomous agent, especially in context understanding, tool usage, and response generation, has become increasingly critical. Although prior studies have advanced the overall design of LLM-based agents, systematic optimization of their internal reasoning and tool-use pipelines remains underexplored. This paper introduces an agent framework grounded in real-world practical experience, with three key innovations: (1) an adaptive prompt generation strategy that aligns with the agent's state and task goals to improve reliability and robustness; (2) a context-aware tool orchestration module that performs tool categorization, semantic retrieval, and adaptive invocation based on user intent and context; and (3) a layered memory mechanism that integrates session memory, task history, and external summaries to improve relevance and efficiency through dynamic summarization and compression. An end-to-end framework named Jenius-Agent has been integrated with three key optimizations, including tools based on the Model Context Protocol (MCP), file input/output (I/O), and execution feedback. The experiments show a 20 percent improvement in task accuracy, along with a reduced token cost, response latency, and invocation failures. The framework is already deployed in Jenius (https://www.jenius.cn), providing a lightweight and scalable solution for robust, protocol-compatible autonomous agents.

</details>


### [268] [Toward Auditable Neuro-Symbolic Reasoning in Pathology: SQL as an Explicit Trace of Evidence](https://arxiv.org/abs/2601.01875)
*Kewen Cao,Jianxu Chen,Yongbing Zhang,Ye Zhang,Hongxiao Wang*

Main category: cs.AI

TL;DR: 论文提出了一种基于SQL的代理框架，通过可审计的特征测量和推理，提升病理图像分析的透明度和可解释性。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉语言模型生成的解释缺乏可验证证据的问题，提升病理图像分析的可解释性和决策可追溯性。

Method: 论文引入了一个SQL中心的代理框架，包括特征推理代理（执行SQL查询聚合视觉证据）和知识比较代理（评估发现与病理知识的一致性）。

Result: 在两个病理视觉问答数据集上的实验表明，该方法提高了可解释性和决策可追溯性，并生成了可执行的SQL追踪。

Conclusion: 该论文提出的SQL中心代理框架通过可审计的特征测量和推理，显著提高了病理图像分析的透明度和可解释性，同时生成的SQL追踪将细胞测量与诊断结论直接关联。

Abstract: Automated pathology image analysis is central to clinical diagnosis, but clinicians still ask which slide features drive a model's decision and why. Vision-language models can produce natural language explanations, but these are often correlational and lack verifiable evidence. In this paper, we introduce an SQL-centered agentic framework that enables both feature measurement and reasoning to be auditable. Specifically, after extracting human-interpretable cellular features, Feature Reasoning Agents compose and execute SQL queries over feature tables to aggregate visual evidence into quantitative findings. A Knowledge Comparison Agent then evaluates these findings against established pathological knowledge, mirroring how pathologists justify diagnoses from measurable observations. Extensive experiments evaluated on two pathology visual question answering datasets demonstrate our method improves interpretability and decision traceability while producing executable SQL traces that link cellular measurements to diagnostic conclusions.

</details>


### [269] [Theory Trace Card: Theory-Driven Socio-Cognitive Evaluation of LLMs](https://arxiv.org/abs/2601.01878)
*Farzan Karimi-Malekabadi,Suhaib Abdurahman,Zhivar Sourati,Jackson Trager,Morteza Dehghani*

Main category: cs.AI

TL;DR: 本文指出社会认知评估基准因缺乏明确理论基础而产生有效性幻觉，并提出理论追踪卡（TTC）作为解决方案，以增强评估的可解释性和可重用性。


<details>
  <summary>Details</summary>
Motivation: 现有的社会认知评估基准往往缺乏明确的理论基础，导致评估结果被误解为广泛能力的证据，从而产生系统性有效性幻觉。

Method: 首先诊断并形式化了理论差距问题，随后设计了理论追踪卡（TTC），用于明确记录评估的理论基础、目标能力、操作化及局限性。

Result: 理论追踪卡（TTC）的引入能够增强社会认知评估的可解释性和可重用性，无需修改基准或要求对单一理论达成一致。

Conclusion: 本文提出了理论追踪卡（TTC）作为一种轻量级文档工具，旨在明确社会认知评估的理论基础、目标能力的组成部分、操作化及其局限性，从而增强评估的可解释性和可重用性。

Abstract: Socio-cognitive benchmarks for large language models (LLMs) often fail to predict real-world behavior, even when models achieve high benchmark scores. Prior work has attributed this evaluation-deployment gap to problems of measurement and validity. While these critiques are insightful, we argue that they overlook a more fundamental issue: many socio-cognitive evaluations proceed without an explicit theoretical specification of the target capability, leaving the assumptions linking task performance to competence implicit. Without this theoretical grounding, benchmarks that exercise only narrow subsets of a capability are routinely misinterpreted as evidence of broad competence: a gap that creates a systemic validity illusion by masking the failure to evaluate the capability's other essential dimensions. To address this gap, we make two contributions. First, we diagnose and formalize this theory gap as a foundational failure that undermines measurement and enables systematic overgeneralization of benchmark results. Second, we introduce the Theory Trace Card (TTC), a lightweight documentation artifact designed to accompany socio-cognitive evaluations, which explicitly outlines the theoretical basis of an evaluation, the components of the target capability it exercises, its operationalization, and its limitations. We argue that TTCs enhance the interpretability and reuse of socio-cognitive evaluations by making explicit the full validity chain, which links theory, task operationalization, scoring, and limitations, without modifying benchmarks or requiring agreement on a single theory.

</details>


### [270] [MMP-A*: Multimodal Perception Enhanced Incremental Heuristic Search on Path Planning](https://arxiv.org/abs/2601.01910)
*Minh Hieu Ha,Khanh Ly Ta,Hung Phan,Tung Doan,Tung Dao,Dao Tran,Huynh Thi Thanh Binh*

Main category: cs.AI

TL;DR: MMP-A* 是一个多模态框架，通过视觉语言模型和自适应衰减机制，解决了复杂环境中路径规划的计算效率和几何有效性问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统 A* 算法在复杂环境中计算和内存成本过高的问题，以及纯文本规划器在空间定位和几何有效性上的不足，提出了 MMP-A* 框架。

Method: MMP-A* 结合了视觉语言模型的空间定位能力和自适应衰减机制，动态调节不确定路径点的影响，确保几何有效性并降低内存开销。

Result: 实验结果表明，MMP-A* 在严重杂乱和拓扑复杂的环境中实现了接近最优的轨迹，同时显著降低了操作成本。

Conclusion: MMP-A* 框架通过整合视觉语言模型的空间定位能力和自适应衰减机制，显著提升了自主导航的效率和几何有效性，为复杂环境中的路径规划提供了新的解决方案。

Abstract: Autonomous path planning requires a synergy between global reasoning and geometric precision, especially in complex or cluttered environments. While classical A* is valued for its optimality, it incurs prohibitive computational and memory costs in large-scale scenarios. Recent attempts to mitigate these limitations by using Large Language Models for waypoint guidance remain insufficient, as they rely only on text-based reasoning without spatial grounding. As a result, such models often produce incorrect waypoints in topologically complex environments with dead ends, and lack the perceptual capacity to interpret ambiguous physical boundaries. These inconsistencies lead to costly corrective expansions and undermine the intended computational efficiency.
  We introduce MMP-A*, a multimodal framework that integrates the spatial grounding capabilities of vision-language models with a novel adaptive decay mechanism. By anchoring high-level reasoning in physical geometry, the framework produces coherent waypoint guidance that addresses the limitations of text-only planners. The adaptive decay mechanism dynamically regulates the influence of uncertain waypoints within the heuristic, ensuring geometric validity while substantially reducing memory overhead. To evaluate robustness, we test the framework in challenging environments characterized by severe clutter and topological complexity. Experimental results show that MMP-A* achieves near-optimal trajectories with significantly reduced operational costs, demonstrating its potential as a perception-grounded and computationally efficient paradigm for autonomous navigation.

</details>


### [271] [OpenSocInt: A Multi-modal Training Environment for Human-Aware Social Navigation](https://arxiv.org/abs/2601.01939)
*Victor Sanchez,Chris Reinke,Ahamed Mohamed,Xavier Alameda-Pineda*

Main category: cs.AI

TL;DR: OpenSocInt是一个开源的多模态社交交互模拟器，支持模块化训练社交代理，已公开可用。


<details>
  <summary>Details</summary>
Motivation: 开发一个开源工具，以促进多模态社交交互的研究和社交代理的训练。

Method: 介绍了OpenSocInt软件包及其模块化架构，通过基于社交导航任务的实验协议展示其功能。

Result: 软件包已成功开发并公开可用，支持多种感知特征和代理的探索。

Conclusion: OpenSocInt是一个开源软件包，提供了多模态社交交互的模拟器和模块化架构，用于训练社交代理。该软件已公开发布，支持探索不同感知特征的使用、编码和融合，以及不同代理的应用。

Abstract: In this paper, we introduce OpenSocInt, an open-source software package providing a simulator for multi-modal social interactions and a modular architecture to train social agents. We described the software package and showcased its interest via an experimental protocol based on the task of social navigation. Our framework allows for exploring the use of different perceptual features, their encoding and fusion, as well as the use of different agents. The software is already publicly available under GPL at https://gitlab.inria.fr/robotlearn/OpenSocInt/.

</details>


### [272] [CNC-TP: Classifier Nominal Concept Based on Top-Pertinent Attributes](https://arxiv.org/abs/2601.01976)
*Yasmine Souissi,Fabrice Boissier,Nida Meddouri*

Main category: cs.AI

TL;DR: 本文综述了基于FCA的分类器，提出了一种构建部分概念格的新方法，并通过实验验证了其效率。


<details>
  <summary>Details</summary>
Motivation: 知识发现（KDD）旨在从大量数据中提取隐藏且有意义的模式，而形式概念分析（FCA）因其可解释性和可解释性学习而受到认可。本文旨在综述FCA分类器的最新进展并提出改进方法。

Method: 本文探讨了从名义数据计算闭包算子的多种方法，并引入了一种构建部分概念格的新方法。

Result: 实验结果表明，提出的构建部分概念格的方法是高效的。

Conclusion: 本文总结了基于形式概念分析（FCA）的分类器的最新研究进展，并提出了一种构建部分概念格的新方法，该方法专注于最相关的概念。实验结果表明了该方法的效率。

Abstract: Knowledge Discovery in Databases (KDD) aims to exploit the vast amounts of data generated daily across various domains of computer applications. Its objective is to extract hidden and meaningful knowledge from datasets through a structured process comprising several key steps: data selection, preprocessing, transformation, data mining, and visualization. Among the core data mining techniques are classification and clustering. Classification involves predicting the class of new instances using a classifier trained on labeled data. Several approaches have been proposed in the literature, including Decision Tree Induction, Bayesian classifiers, Nearest Neighbor search, Neural Networks, Support Vector Machines, and Formal Concept Analysis (FCA). The last one is recognized as an effective approach for interpretable and explainable learning. It is grounded in the mathematical structure of the concept lattice, which enables the generation of formal concepts and the discovery of hidden relationships among them. In this paper, we present a state-of-theart review of FCA-based classifiers. We explore various methods for computing closure operators from nominal data and introduce a novel approach for constructing a partial concept lattice that focuses on the most relevant concepts. Experimental results are provided to demonstrate the efficiency of the proposed method.

</details>


### [273] [ChaosBench-Logic: A Benchmark for Logical and Symbolic Reasoning on Chaotic Dynamical Systems](https://arxiv.org/abs/2601.01982)
*Noel Thomas*

Main category: cs.AI

TL;DR: ChaosBench-Logic 是一个评估 LLM 逻辑推理能力的基准，显示前沿模型在单项任务中表现良好，但在组合推理和对话中仍有显著缺陷。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）在自然语言任务中表现出色，但在需要精确逻辑和符号推理的领域中表现脆弱，混沌动力系统因其确定性常被误解为随机性或复杂性，因此需要严格的测试基准。

Method: 引入了 ChaosBench-Logic 基准，通过统一的一阶逻辑（FOL）本体评估 LLM 在 30 种动态系统中的推理能力，生成 621 个问题，涵盖多种推理类别。

Result: 前沿 LLM（如 GPT-4、Claude 3.5 Sonnet 等）在单项准确率上达到 91-94%，但在组合项上得分为 0%，对话级准确率从 53.1% 到 75.5% 不等。

Conclusion: ChaosBench-Logic 为诊断 LLM 在逻辑推理中的失败提供了严格的测试基准，并为开发神经符号方法以改进 LLM 的科学推理能力奠定了基础。

Abstract: Large language models (LLMs) excel at natural language tasks but remain brittle in domains requiring precise logical and symbolic reasoning. Chaotic dynamical systems provide an especially demanding test because chaos is deterministic yet often misinterpreted as randomness or complexity. We introduce ChaosBench-Logic, a benchmark that evaluates LLM reasoning across 30 diverse dynamical systems using a unified first-order logic (FOL) ontology. Each system is annotated with truth assignments for 11 semantic predicates, and 621 questions are generated across seven reasoning categories, including multi-hop implications, cross-system analogies, counterfactual reasoning, bias probes, and multi-turn dialogues. We define metrics for logical accuracy, implication consistency, dialogue coherence, and contradiction, and we release an open-source evaluation pipeline. Initial experiments show that frontier LLMs such as GPT-4, Claude 3.5 Sonnet, Gemini 2.5 Flash, and the open-source LLaMA-3 70B achieve 91-94% per-item accuracy, yet still score 0% on compositional items and exhibit fragile global coherence. Dialogue-level accuracy ranges from 53.1% (GPT-4 CoT) to 75.5% (LLaMA-3 zero-shot). ChaosBench-Logic provides a rigorous testbed for diagnosing such failures and a foundation for developing neuro-symbolic approaches that improve scientific reasoning in LLMs.

</details>


### [274] [MindChat: A Privacy-preserving Large Language Model for Mental Health Support](https://arxiv.org/abs/2601.01993)
*Dong Xue,Jicheng Tu,Ming Wang,Xin Yan,Fangzhou Liu,Jie Hu*

Main category: cs.AI

TL;DR: MindChat通过合成数据集MindCorpus和隐私保护技术，提供高效且隐私安全的心理健康支持。


<details>
  <summary>Details</summary>
Motivation: 解决心理健康支持领域真实咨询对话稀缺且敏感的问题，同时保护用户隐私。

Method: 采用多智能体角色扮演框架构建合成数据集MindCorpus，结合双闭环反馈设计提升数据质量；使用联邦学习和差分隐私优化技术进行模型微调。

Result: MindCorpus提升了训练效果，MindChat在自动评估和人工评估中表现优于基线模型，隐私泄露风险更低。

Conclusion: MindChat和MindCorpus通过合成数据和隐私保护技术，在心理健康支持领域展现了竞争力，同时降低了隐私泄露风险。

Abstract: Large language models (LLMs) have shown promise for mental health support, yet training such models is constrained by the scarcity and sensitivity of real counseling dialogues. In this article, we present MindChat, a privacy-preserving LLM for mental health support, together with MindCorpus, a synthetic multi-turn counseling dataset constructed via a multi-agent role-playing framework. To synthesize high-quality counseling data, the developed dialogue-construction framework employs a dual closed-loop feedback design to integrate psychological expertise and counseling techniques through role-playing: (i) turn-level critique-and-revision to improve coherence and counseling appropriateness within a session, and (ii) session-level strategy refinement to progressively enrich counselor behaviors across sessions. To mitigate privacy risks under decentralized data ownership, we fine-tune the base model using federated learning with parameter-efficient LoRA adapters and incorporate differentially private optimization to reduce membership and memorization risks. Experiments on synthetic-data quality assessment and counseling capability evaluation show that MindCorpus improves training effectiveness and that MindChat is competitive with existing general and counseling-oriented LLM baselines under both automatic LLM-judge and human evaluation protocols, while exhibiting reduced privacy leakage under membership inference attacks.

</details>


### [275] [XAI-MeD: Explainable Knowledge Guided Neuro-Symbolic Framework for Domain Generalization and Rare Class Detection in Medical Imaging](https://arxiv.org/abs/2601.02008)
*Midhat Urooj,Ayan Banerjee,Sandeep Gupta*

Main category: cs.AI

TL;DR: XAIMeD是一种结合临床知识与深度学习的可解释医疗AI框架，显著提升分布偏移下的鲁棒性和罕见类别敏感性，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决医疗AI中解释性、领域泛化和罕见类别可靠性等关键挑战，避免深度模型在真实世界分布偏移下的失效和对罕见临床条件的偏见。

Method: XAIMeD采用神经符号架构，将临床专业知识编码为逻辑连接词和原子医学命题，通过加权特征满足分数量化诊断效用，并结合符号推理分支与神经预测。通过置信加权融合和基于熵不平衡增益（EIG）及罕见类基尼系数的自适应路由机制，缓解类别不平衡和不确定性。

Result: 在多种模态和四个挑战性任务中，XAIMeD表现出显著性能提升，包括跨领域泛化能力提高6%，罕见类别F1分数提升10%，远超现有深度学习基线。

Conclusion: XAIMeD框架通过结合临床专家知识和深度学习，显著提升了医疗AI在分布偏移下的鲁棒性、罕见类别的敏感性，并提供了透明且临床对齐的解释。

Abstract: Explainability domain generalization and rare class reliability are critical challenges in medical AI where deep models often fail under real world distribution shifts and exhibit bias against infrequent clinical conditions This paper introduces XAIMeD an explainable medical AI framework that integrates clinically accurate expert knowledge into deep learning through a unified neuro symbolic architecture XAIMeD is designed to improve robustness under distribution shift enhance rare class sensitivity and deliver transparent clinically aligned interpretations The framework encodes clinical expertise as logical connectives over atomic medical propositions transforming them into machine checkable class specific rules Their diagnostic utility is quantified through weighted feature satisfaction scores enabling a symbolic reasoning branch that complements neural predictions A confidence weighted fusion integrates symbolic and deep outputs while a Hunt inspired adaptive routing mechanism guided by Entropy Imbalance Gain EIG and Rare Class Gini mitigates class imbalance high intra class variability and uncertainty We evaluate XAIMeD across diverse modalities on four challenging tasks i Seizure Onset Zone SOZ localization from rs fMRI ii Diabetic Retinopathy grading across 6 multicenter datasets demonstrate substantial performance improvements including 6 percent gains in cross domain generalization and a 10 percent improved rare class F1 score far outperforming state of the art deep learning baselines Ablation studies confirm that the clinically grounded symbolic components act as effective regularizers ensuring robustness to distribution shifts XAIMeD thus provides a principled clinically faithful and interpretable approach to multimodal medical AI.

</details>


### [276] [Simulated Reasoning is Reasoning](https://arxiv.org/abs/2601.02043)
*Hendrik Kempt,Alon Lavie*

Main category: cs.AI

TL;DR: 基础模型通过模仿“思考过程”进行推理，但其缺乏常识和基础，导致推理脆弱。本文探讨了这种现象的哲学解释，并提出了安全性和规范性考量。


<details>
  <summary>Details</summary>
Motivation: 探讨基础模型如何通过模仿“思考过程”进行推理，以及这种推理方式与人类推理的本质区别。

Method: 通过哲学解释和论证，分析基础模型的推理过程及其局限性。

Result: 研究发现基础模型的推理过程缺乏常识和基础，导致其脆弱性，并提出了相应的安全性和规范性考量。

Conclusion: 本文探讨了基础模型（FM）在推理任务中的表现，指出其与人类推理的根本差异，并提出了对安全性和鲁棒性防御的考量。

Abstract: Reasoning has long been understood as a pathway between stages of understanding. Proper reasoning leads to understanding of a given subject. This reasoning was conceptualized as a process of understanding in a particular way, i.e., "symbolic reasoning". Foundational Models (FM) demonstrate that this is not a necessary condition for many reasoning tasks: they can "reason" by way of imitating the process of "thinking out loud", testing the produced pathways, and iterating on these pathways on their own. This leads to some form of reasoning that can solve problems on its own or with few-shot learning, but appears fundamentally different from human reasoning due to its lack of grounding and common sense, leading to brittleness of the reasoning process. These insights promise to substantially alter our assessment of reasoning and its necessary conditions, but also inform the approaches to safety and robust defences against this brittleness of FMs. This paper offers and discusses several philosophical interpretations of this phenomenon, argues that the previously apt metaphor of the "stochastic parrot" has lost its relevance and thus should be abandoned, and reflects on different normative elements in the safety- and appropriateness-considerations emerging from these reasoning models and their growing capacity.

</details>


### [277] [Higher-Order Action Regularization in Deep Reinforcement Learning: From Continuous Control to Building Energy Management](https://arxiv.org/abs/2601.02061)
*Faizan Ahmed,Aniket Dixit,James Brusey*

Main category: cs.AI

TL;DR: 本文提出高阶动作正则化方法，通过急动最小化实现平滑控制，在保持性能的同时减少设备切换60%，适用于能源关键应用。


<details>
  <summary>Details</summary>
Motivation: 深度强化学习代理常表现出不稳定、高频的控制行为，这在实际部署中由于高能耗和机械磨损而受到阻碍。

Method: 我们通过高阶导数惩罚系统地研究了动作平滑正则化，从连续控制基准的理论理解到建筑能源管理的实际验证。

Result: 在四个连续控制环境中的全面评估表明，三阶导数惩罚（急动最小化）始终能实现更优的平滑性，同时保持竞争力性能。在HVAC控制系统中，平滑策略将设备切换减少了60%，带来显著的操作效益。

Conclusion: 本文确立了高阶动作正则化作为在能源关键应用中连接RL优化与操作约束的有效桥梁。

Abstract: Deep reinforcement learning agents often exhibit erratic, high-frequency control behaviors that hinder real-world deployment due to excessive energy consumption and mechanical wear. We systematically investigate action smoothness regularization through higher-order derivative penalties, progressing from theoretical understanding in continuous control benchmarks to practical validation in building energy management. Our comprehensive evaluation across four continuous control environments demonstrates that third-order derivative penalties (jerk minimization) consistently achieve superior smoothness while maintaining competitive performance. We extend these findings to HVAC control systems where smooth policies reduce equipment switching by 60%, translating to significant operational benefits. Our work establishes higher-order action regularization as an effective bridge between RL optimization and operational constraints in energy-critical applications.

</details>


### [278] [FormuLLA: A Large Language Model Approach to Generating Novel 3D Printable Formulations](https://arxiv.org/abs/2601.02071)
*Adeshola Okubena,Yusuf Ali Mohammed,Moe Elbadawi*

Main category: cs.AI

TL;DR: 研究利用大型语言模型（LLMs）优化药物3D打印制剂开发，发现Llama2表现最佳，但需解决灾难性遗忘和评估指标不足等问题。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用人工通用智能（AGI）概念，使AI系统超越传统预测模型，实现更通用的、类人推理能力，以解决药物3D打印中广泛的制剂挑战。

Method: 研究通过微调四种LLM架构（基于包含1400多种制剂的FDM数据集），系统评估微调和生成参数配置，以推荐适合的辅料并预测长丝机械性能。

Result: 结果显示，Llama2最适合推荐FDM制剂的辅料；模型选择和参数化显著影响性能，较小的LLMs可能出现灾难性遗忘；标准LLM指标仅评估语言性能而非制剂可加工性。

Conclusion: 为了推进大型语言模型（LLMs）在药物制剂开发中的应用，必须解决模型选择、参数配置以及数据集规模等问题，以确保其不仅具备语言能力，还能可靠地支持制剂开发。

Abstract: Pharmaceutical three-dimensional (3D) printing is an advanced fabrication technology with the potential to enable truly personalised dosage forms. Recent studies have integrated artificial intelligence (AI) to accelerate formulation and process development, drastically transforming current approaches to pharmaceutical 3D printing. To date, most AI-driven efforts remain narrowly focused, while failing to account for the broader formulation challenges inherent to the technology. Recent advances in AI have introduced artificial general intelligence concepts, wherein systems extend beyond conventional predictive modelling toward more generalised, human-like reasoning. In this work, we investigate the application of large language models (LLMs), fine-tuned on a fused deposition modelling (FDM) dataset comprising over 1400 formulations, to recommend suitable excipients based on active pharmaceutical ingredient (API) dose, and predict filament mechanical properties. Four LLM architectures were fine-tuned, with systematic evaluation of both fine-tuning and generative parameter configurations. Our results demonstrate that Llama2 was best suited for recommending excipients for FDM formulations. Additionally, model selection and parameterisation significantly influence performance, with smaller LLMs exhibiting instances of catastrophic forgetting. Furthermore, we demonstrate: (i) even with relatively small dataset of over 1400 formulations, it can lead to model catastrophic forgetting; (ii) standard LLM metrics only evaluate linguistic performance but not formulation processability; and (iii) LLMs trained on biomedically-related data do not always produce the best results. Addressing these challenges is essential to advancing LLMs beyond linguistic proficiency and toward reliable systems for pharmaceutical formulation development.

</details>


### [279] [EverMemOS: A Self-Organizing Memory Operating System for Structured Long-Horizon Reasoning](https://arxiv.org/abs/2601.02163)
*Chuanrui Hu,Xingze Gao,Zuyi Zhou,Dannong Xu,Yi Bai,Xintong Li,Hui Zhang,Tong Li,Chong Zhang,Lidong Bing,Yafeng Deng*

Main category: cs.AI

TL;DR: EverMemOS是一种自组织内存操作系统，通过三个核心模块提升LLMs在长期交互中的连贯性，实验证明其性能优越。


<details>
  <summary>Details</summary>
Motivation: 解决现有内存系统在长期交互中因存储孤立记录和检索片段而难以维持连贯行为的问题。

Method: 引入EverMemOS系统，包括Episodic Trace Formation、Semantic Consolidation和Reconstructive Recollection三个核心模块，分别处理对话流、组织语义结构和指导检索。

Result: 在LoCoMo和LongMemEval实验中达到最先进的性能，并在PersonaMem v2和定性案例研究中展示了用户画像和Foresight等能力。

Conclusion: EverMemOS通过自组织内存操作系统实现了计算内存的生命周期管理，显著提升了长期交互中的连贯性表现，并在实验中展示了最先进的性能。

Abstract: Large Language Models (LLMs) are increasingly deployed as long-term interactive agents, yet their limited context windows make it difficult to sustain coherent behavior over extended interactions. Existing memory systems often store isolated records and retrieve fragments, limiting their ability to consolidate evolving user states and resolve conflicts. We introduce EverMemOS, a self-organizing memory operating system that implements an engram-inspired lifecycle for computational memory. Episodic Trace Formation converts dialogue streams into MemCells that capture episodic traces, atomic facts, and time-bounded Foresight signals. Semantic Consolidation organizes MemCells into thematic MemScenes, distilling stable semantic structures and updating user profiles. Reconstructive Recollection performs MemScene-guided agentic retrieval to compose the necessary and sufficient context for downstream reasoning. Experiments on LoCoMo and LongMemEval show that EverMemOS achieves state-of-the-art performance on memory-augmented reasoning tasks. We further report a profile study on PersonaMem v2 and qualitative case studies illustrating chat-oriented capabilities such as user profiling and Foresight. Code is available at https://github.com/EverMind-AI/EverMemOS.

</details>


### [280] [Streaming Hallucination Detection in Long Chain-of-Thought Reasoning](https://arxiv.org/abs/2601.02170)
*Haolang Lu,Minghui Pan,Ripeng Li,Guoshun Nan,Jialin Zhuang,Zijie Zhao,Zhongxiang Sun,Kun Wang,Yang Liu*

Main category: cs.AI

TL;DR: 该论文提出了一种实时检测长链思维推理中幻觉的方法，通过累积前缀级信号跟踪全局状态演变。


<details>
  <summary>Details</summary>
Motivation: 长链思维推理中的幻觉往往微妙且跨步骤传播，需将其视为演变的潜在状态而非一次性错误事件。

Method: 将步骤级幻觉判断视为局部观察，并引入累积前缀级幻觉信号以跟踪推理状态的全局演变。

Result: 提出的方法能够实时检测长链思维推理中的幻觉，并提供可解释的证据。

Conclusion: 通过引入累积前缀级幻觉信号，该方法实现了长链思维推理中的实时幻觉检测，提供了可解释的证据。

Abstract: Long chain-of-thought (CoT) reasoning improves the performance of large language models, yet hallucinations in such settings often emerge subtly and propagate across reasoning steps. We suggest that hallucination in long CoT reasoning is better understood as an evolving latent state rather than a one-off erroneous event. Accordingly, we treat step-level hallucination judgments as local observations and introduce a cumulative prefix-level hallucination signal that tracks the global evolution of the reasoning state over the entire trajectory. Overall, our approach enables streaming hallucination detection in long CoT reasoning, providing real-time, interpretable evidence.

</details>


### [281] [Project Ariadne: A Structural Causal Framework for Auditing Faithfulness in LLM Agents](https://arxiv.org/abs/2601.02314)
*Sourena Khanzadeh*

Main category: cs.AI

TL;DR: 研究发现LLM智能体的推理轨迹可能不忠实，仅作为‘推理剧场’。提出的Project Ariadne框架通过因果干预揭示了普遍存在的‘因果解耦’现象，建议用Ariadne评分提升推理忠实性。


<details>
  <summary>Details</summary>
Motivation: 随着LLM智能体越来越多地承担高风险的自主决策任务，其推理过程的透明度成为关键的安全问题。尽管链式思维（CoT）提示能生成人类可读的推理轨迹，但这些轨迹是否真实反映模型的决策驱动因素尚不明确。

Method: 提出了Project Ariadne框架，利用结构因果模型（SCMs）和反事实逻辑，通过对中间推理节点进行硬干预（如逻辑反转、前提否定等），测量终端答案的因果敏感性（φ），从而审计推理的因果完整性。

Result: 实证评估显示，当前最先进的模型普遍存在‘忠实性差距’，并检测到一种广泛存在的故障模式‘因果解耦’（违反密度ρ高达0.77）。智能体在内部逻辑矛盾的情况下仍得出相同结论，表明其推理轨迹仅为‘推理剧场’，决策实际由潜在参数先验主导。

Conclusion: 当前基于大型语言模型（LLM）的智能体在自主决策中存在推理过程不透明的问题，其生成的推理轨迹可能只是事后合理化而非真实的决策驱动因素。通过Project Ariadne框架，研究发现现有模型普遍存在‘因果解耦’现象，即推理轨迹与决策脱节。建议采用Ariadne评分作为新基准，以提升推理的忠实性。

Abstract: As Large Language Model (LLM) agents are increasingly tasked with high-stakes autonomous decision-making, the transparency of their reasoning processes has become a critical safety concern. While \textit{Chain-of-Thought} (CoT) prompting allows agents to generate human-readable reasoning traces, it remains unclear whether these traces are \textbf{faithful} generative drivers of the model's output or merely \textbf{post-hoc rationalizations}. We introduce \textbf{Project Ariadne}, a novel XAI framework that utilizes Structural Causal Models (SCMs) and counterfactual logic to audit the causal integrity of agentic reasoning. Unlike existing interpretability methods that rely on surface-level textual similarity, Project Ariadne performs \textbf{hard interventions} ($do$-calculus) on intermediate reasoning nodes -- systematically inverting logic, negating premises, and reversing factual claims -- to measure the \textbf{Causal Sensitivity} ($φ$) of the terminal answer. Our empirical evaluation of state-of-the-art models reveals a persistent \textit{Faithfulness Gap}. We define and detect a widespread failure mode termed \textbf{Causal Decoupling}, where agents exhibit a violation density ($ρ$) of up to $0.77$ in factual and scientific domains. In these instances, agents arrive at identical conclusions despite contradictory internal logic, proving that their reasoning traces function as "Reasoning Theater" while decision-making is governed by latent parametric priors. Our findings suggest that current agentic architectures are inherently prone to unfaithful explanation, and we propose the Ariadne Score as a new benchmark for aligning stated logic with model action.

</details>


### [282] [Falcon-H1R: Pushing the Reasoning Frontiers with a Hybrid Model for Efficient Test-Time Scaling](https://arxiv.org/abs/2601.02346)
*Falcon LLM Team,Iheb Chaabane,Puneesh Khanna,Suhail Mohmad,Slim Frikha,Shi Hu,Abdalgader Abubaker,Reda Alami,Mikhail Lubinets,Mohamed El Amine Seddik,Hakim Hacid*

Main category: cs.AI

TL;DR: Falcon-H1R-7B, a compact reasoning-optimized model, achieves SOTA performance through efficient training and architecture, proving SLMs can rival larger models.


<details>
  <summary>Details</summary>
Motivation: To prove that small language models (SLMs) can achieve competitive reasoning performance without increasing model size, emphasizing parameter efficiency.

Method: Utilizes careful data curation, efficient supervised fine-tuning (SFT), RL scaling, and a hybrid-parallel architecture design for faster inference and token efficiency.

Result: Falcon-H1R matches or outperforms SOTA reasoning models 2× to 7× larger across benchmarks, with advancements in inference speed, token efficiency, and accuracy.

Conclusion: Falcon-H1R-7B demonstrates that compact models can achieve robust and scalable reasoning performance through targeted training and architectural optimizations, challenging the need for larger models.

Abstract: This work introduces Falcon-H1R, a 7B-parameter reasoning-optimized model that establishes the feasibility of achieving competitive reasoning performance with small language models (SLMs). Falcon-H1R stands out for its parameter efficiency, consistently matching or outperforming SOTA reasoning models that are $2\times$ to $7\times$ larger across a variety of reasoning-intensive benchmarks. These results underscore the importance of careful data curation and targeted training strategies (via both efficient SFT and RL scaling) in delivering significant performance gains without increasing model size. Furthermore, Falcon-H1R advances the 3D limits of reasoning efficiency by combining faster inference (through its hybrid-parallel architecture design), token efficiency, and higher accuracy. This unique blend makes Falcon-H1R-7B a practical backbone for scaling advanced reasoning systems, particularly in scenarios requiring extensive chain-of-thoughts generation and parallel test-time scaling. Leveraging the recently introduced DeepConf approach, Falcon-H1R achieves state-of-the-art test-time scaling efficiency, offering substantial improvements in both accuracy and computational cost. As a result, Falcon-H1R demonstrates that compact models, through targeted model training and architectural choices, can deliver robust and scalable reasoning performance.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [283] [Value Vision-Language-Action Planning & Search](https://arxiv.org/abs/2601.00969)
*Ali Salamatian,Ke,Ren,Kieran Pattison,Cyrus Neary*

Main category: cs.RO

TL;DR: V-VLAPS通过结合轻量级价值函数和MCTS，提升了VLA模型在机器人操作中的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型依赖行为克隆，导致在分布偏移下表现脆弱，且现有MCTS方法仅依赖VLA先验，缺乏对未来回报的准确估计。

Method: 在固定VLA骨干网络（Octo）的潜在表示上训练一个简单的多层感知机（MLP），为MCTS提供明确的价值信号。

Result: 在LIBERO机器人操作套件上的实验表明，V-VLAPS将成功率提高了5个百分点以上，同时减少了5-15%的MCTS模拟次数。

Conclusion: V-VLAPS框架通过引入轻量级可学习价值函数，显著提升了VLA模型在机器人操作任务中的性能和效率。

Abstract: Vision-Language-Action (VLA) models have emerged as powerful generalist policies for robotic manipulation, yet they remain fundamentally limited by their reliance on behavior cloning, leading to brittleness under distribution shift. While augmenting pretrained models with test-time search algorithms like Monte Carlo Tree Search (MCTS) can mitigate these failures, existing formulations rely solely on the VLA prior for guidance, lacking a grounded estimate of expected future return. Consequently, when the prior is inaccurate, the planner can only correct action selection via the exploration term, which requires extensive simulation to become effective. To address this limitation, we introduce Value Vision-Language-Action Planning and Search (V-VLAPS), a framework that augments MCTS with a lightweight, learnable value function. By training a simple multilayer perceptron (MLP) on the latent representations of a fixed VLA backbone (Octo), we provide the search with an explicit success signal that biases action selection toward high-value regions. We evaluate V-VLAPS on the LIBERO robotic manipulation suite, demonstrating that our value-guided search improves success rates by over 5 percentage points while reducing the average number of MCTS simulations by 5-15 percent compared to baselines that rely only on the VLA prior.

</details>


### [284] [From Perception to Symbolic Task Planning: Vision-Language Guided Human-Robot Collaborative Structured Assembly](https://arxiv.org/abs/2601.00978)
*Yanyi Chen,Min Deng*

Main category: cs.RO

TL;DR: 提出了一种基于设计的人机协作规划框架，结合视觉语言模型和知识驱动规划，提高了动态条件下的状态估计和任务规划鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决结构化装配中人机协作（HRC）在噪声感知和人类干预下的可靠状态估计和自适应任务规划挑战。

Method: 框架包含两个耦合模块：模块I（PSS）使用视觉语言模型代理将RGB-D观测与设计规范和领域知识对齐，合成可验证的符号化装配状态；模块II（HPR）执行任务级多机器人分配，并在观测状态偏离预期执行结果时更新计划。

Result: 在27组件木框架装配上验证，PSS模块达到97%的状态合成准确率，HPR模块在多样化HRC场景中保持可行任务进展。

Conclusion: 整合基于视觉语言模型的感知与知识驱动规划，在动态条件下提高了状态估计和任务规划的鲁棒性。

Abstract: Human-robot collaboration (HRC) in structured assembly requires reliable state estimation and adaptive task planning under noisy perception and human interventions. To address these challenges, we introduce a design-grounded human-aware planning framework for human-robot collaborative structured assembly. The framework comprises two coupled modules. Module I, Perception-to-Symbolic State (PSS), employs vision-language models (VLMs) based agents to align RGB-D observations with design specifications and domain knowledge, synthesizing verifiable symbolic assembly states. It outputs validated installed and uninstalled component sets for online state tracking. Module II, Human-Aware Planning and Replanning (HPR), performs task-level multi-robot assignment and updates the plan only when the observed state deviates from the expected execution outcome. It applies a minimal-change replanning rule to selectively revise task assignments and preserve plan stability even under human interventions. We validate the framework on a 27-component timber-frame assembly. The PSS module achieves 97% state synthesis accuracy, and the HPR module maintains feasible task progression across diverse HRC scenarios. Results indicate that integrating VLM-based perception with knowledge-driven planning improves robustness of state estimation and task planning under dynamic conditions.

</details>


### [285] [Simulations of MRI Guided and Powered Ferric Applicators for Tetherless Delivery of Therapeutic Interventions](https://arxiv.org/abs/2601.00981)
*Wenhui Chu,Khang Tran,Nikolaos V. Tsekos*

Main category: cs.RO

TL;DR: 开发了一个MRI引导血管内手术的术前规划平台，通过虚拟夹具和磁场梯度波形确保手术安全，支持实时操作。


<details>
  <summary>Details</summary>
Motivation: 为MRI引导的血管内介入手术提供术前规划和建模工具，确保手术安全性和可行性。

Method: 平台采用双向数据和命令管道连接MRI扫描仪、计算核心和操作者，包括血管床提取、虚拟走廊拟合、磁场梯度波形生成等模块，支持多线程实时操作。

Result: 平台成功实现了血管路径的虚拟建模和安全性评估，能够生成磁场梯度波形并模拟不同血流条件下的器械操控。

Conclusion: 该研究提出了一个用于MRI引导血管内介入手术的术前规划和建模计算平台，通过虚拟夹具确保手术安全性，并为实时操作提供了技术基础。

Abstract: Magnetic Resonance Imaging (MRI) is a well-established modality for pre-operative planning and is also explored for intra-operative guidance of procedures such as intravascular interventions. Among the experimental robot-assisted technologies, the magnetic field gradients of the MRI scanner are used to power and maneuver ferromagnetic applicators for accessing sites in the patient's body via the vascular network. In this work, we propose a computational platform for preoperative planning and modeling of MRI-powered applicators inside blood vessels. This platform was implemented as a two-way data and command pipeline that links the MRI scanner, the computational core, and the operator. The platform first processes multi-slice MR data to extract the vascular bed and then fits a virtual corridor inside the vessel. This corridor serves as a virtual fixture (VF), a forbidden region for the applicators to avoid vessel perforation or collision. The geometric features of the vessel centerline, the VF, and MRI safety compliance (dB/dt, max available gradient) are then used to generate magnetic field gradient waveforms. Different blood flow profiles can be user-selected, and those parameters are used for modeling the applicator's maneuvering. The modeling module further generates cues about whether the selected vascular path can be safely maneuvered. Given future experimental studies that require a real-time operation, the platform was implemented on the Qt framework (C/C++) with software modules performing specific tasks running on dedicated threads: PID controller, generation of VF, generation of MR gradient waveforms.

</details>


### [286] [Topological Mapping and Navigation using a Monocular Camera based on AnyLoc](https://arxiv.org/abs/2601.01067)
*Wenzheng Zhang,Yoshitaka Hara,Sousuke Nakamura*

Main category: cs.RO

TL;DR: 提出一种基于单目摄像头的拓扑地图构建与导航方法，通过关键节点简化路径规划，实验显示其高效且轻量。


<details>
  <summary>Details</summary>
Motivation: 拓扑地图通过关键节点而非精确坐标表示环境，简化了路径规划和导航，尤其适用于需要快速地图构建和导航的场景。

Method: 基于AnyLoc，将关键帧转换为描述符以构建拓扑关系，实现环路检测和地图构建。通过比较分割图像与目标节点关联的图像来确定视觉导航动作。

Result: 实验表明，该方法在真实和仿真环境中无需预训练即可有效进行环路检测和导航，相比基于ResNet的方法平均成功率提高了60.2%。

Conclusion: 该方法仅依赖单目摄像头，提供了一种轻量级解决方案，适用于机器人和人类在各种场景中的导航，显著提高了成功率并降低了时间和空间成本。

Abstract: This paper proposes a method for topological mapping and navigation using a monocular camera. Based on AnyLoc, keyframes are converted into descriptors to construct topological relationships, enabling loop detection and map building. Unlike metric maps, topological maps simplify path planning and navigation by representing environments with key nodes instead of precise coordinates. Actions for visual navigation are determined by comparing segmented images with the image associated with target nodes. The system relies solely on a monocular camera, ensuring fast map building and navigation using key nodes. Experiments show effective loop detection and navigation in real and simulation environments without pre-training. Compared to a ResNet-based method, this approach improves success rates by 60.2% on average while reducing time and space costs, offering a lightweight solution for robot and human navigation in various scenarios.

</details>


### [287] [Towards reliable subsea object recovery: a simulation study of an auv with a suction-actuated end effector](https://arxiv.org/abs/2601.01106)
*Michele Grimaldi,Yosaku Maeda,Hitoshi Kakami,Ignacio Carlucho,Yvan Petillot,Tomoya Inoue*

Main category: cs.RO

TL;DR: 本文通过高保真模拟验证了超深渊带自主物体回收任务的可行性，展示了模拟在深海干预行为评估中的有效性。


<details>
  <summary>Details</summary>
Motivation: 由于极端静水压力、能见度低、水流以及深海精确操作的需求，自主物体回收在超深渊带具有挑战性，实地实验成本高、风险大且车辆可用性有限。

Method: 使用Stonefish模拟器模拟真实的车辆动力学、流体动力干扰、感知以及与目标物体的交互，控制框架结合了世界坐标系PID控制器和基于逆运动学的机械臂控制器。

Result: HSV在模拟中成功从海面下潜至6000米，执行结构化海底覆盖，检测目标物体并完成基于吸力的回收。

Conclusion: 高保真模拟为深海干预行为提供了一种有效且低风险的评估手段，适用于实地部署前的验证。

Abstract: Autonomous object recovery in the hadal zone is challenging due to extreme hydrostatic pressure, limited visibility and currents, and the need for precise manipulation at full ocean depth. Field experimentation in such environments is costly, high-risk, and constrained by limited vehicle availability, making early validation of autonomous behaviors difficult. This paper presents a simulation-based study of a complete autonomous subsea object recovery mission using a Hadal Small Vehicle (HSV) equipped with a three-degree-of-freedom robotic arm and a suction-actuated end effector. The Stonefish simulator is used to model realistic vehicle dynamics, hydrodynamic disturbances, sensing, and interaction with a target object under hadal-like conditions. The control framework combines a world-frame PID controller for vehicle navigation and stabilization with an inverse-kinematics-based manipulator controller augmented by acceleration feed-forward, enabling coordinated vehicle - manipulator operation. In simulation, the HSV autonomously descends from the sea surface to 6,000 m, performs structured seafloor coverage, detects a target object, and executes a suction-based recovery. The results demonstrate that high-fidelity simulation provides an effective and low-risk means of evaluating autonomous deep-sea intervention behaviors prior to field deployment.

</details>


### [288] [Latent Space Reinforcement Learning for Multi-Robot Exploration](https://arxiv.org/abs/2601.01139)
*Sriram Rajasekar,Ashwini Ratnoo*

Main category: cs.RO

TL;DR: 论文提出了一种结合自动编码器和分层深度强化学习的多智能体导航系统，通过降维和复杂环境训练，提高了在未知环境中的可扩展性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体系统中运动规划算法的可扩展性限制，以及现有强化学习方法因输入大小限制而仅适用于离散环境的问题。

Method: 利用自动编码器进行降维，将高保真占用地图压缩为潜在状态向量，同时保留关键空间信息；引入基于Perlin噪声的程序生成算法创建复杂训练环境；采用分层深度强化学习框架进行分散协调；引入加权共识机制通过可调信任参数调节对共享数据的依赖。

Result: 实验结果表明，所提出的系统在多智能体数量和陌生环境中的表现均优于现有方法。

Conclusion: 该论文提出的系统在多智能体数量增加时能有效扩展，对陌生且结构不同的环境具有良好泛化能力，并在通信受限情况下表现出韧性。

Abstract: Autonomous mapping of unknown environments is a critical challenge, particularly in scenarios where time is limited. Multi-agent systems can enhance efficiency through collaboration, but the scalability of motion-planning algorithms remains a key limitation. Reinforcement learning has been explored as a solution, but existing approaches are constrained by the limited input size required for effective learning, restricting their applicability to discrete environments. This work addresses that limitation by leveraging autoencoders to perform dimensionality reduction, compressing high-fidelity occupancy maps into latent state vectors while preserving essential spatial information. Additionally, we introduce a novel procedural generation algorithm based on Perlin noise, designed to generate topologically complex training environments that simulate asteroid fields, caves and forests. These environments are used for training the autoencoder and the navigation algorithm using a hierarchical deep reinforcement learning framework for decentralized coordination. We introduce a weighted consensus mechanism that modulates reliance on shared data via a tuneable trust parameter, ensuring robustness to accumulation of errors. Experimental results demonstrate that the proposed system scales effectively with number of agents and generalizes well to unfamiliar, structurally distinct environments and is resilient in communication-constrained settings.

</details>


### [289] [VISO: Robust Underwater Visual-Inertial-Sonar SLAM with Photometric Rendering for Dense 3D Reconstruction](https://arxiv.org/abs/2601.01144)
*Shu Pan,Simon Archieri,Ahmet Cinar,Jonatan Scharff Willners,Ignacio Carlucho,Yvan Petillot*

Main category: cs.RO

TL;DR: VISO是一种融合立体相机、IMU和3D声纳的水下SLAM系统，通过在线校准和光度渲染策略，显著提升了定位和重建性能，实验验证其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 水下环境的视觉挑战严重影响了基于视觉的定位精度和高保真稠密重建，因此需要一种更鲁棒的解决方案。

Method: 提出了一种从粗到精的在线校准方法用于3D声纳与相机之间的外参估计，并设计了3D声纳点云的光度渲染策略以增强声纳地图的视觉信息。

Result: 实验室水箱和开放湖泊的广泛实验表明，VISO在定位鲁棒性和准确性上优于现有水下和基于视觉的SLAM算法，同时展示了与离线稠密建图方法相当的实时稠密3D重建性能。

Conclusion: VISO系统通过融合立体相机、IMU和3D声纳，显著提升了水下环境中的定位精度和稠密3D重建质量，实验证明其在定位鲁棒性和准确性上优于现有水下SLAM算法，并实现了接近离线稠密建图方法的实时性能。

Abstract: Visual challenges in underwater environments significantly hinder the accuracy of vision-based localisation and the high-fidelity dense reconstruction. In this paper, we propose VISO, a robust underwater SLAM system that fuses a stereo camera, an inertial measurement unit (IMU), and a 3D sonar to achieve accurate 6-DoF localisation and enable efficient dense 3D reconstruction with high photometric fidelity. We introduce a coarse-to-fine online calibration approach for extrinsic parameters estimation between the 3D sonar and the camera. Additionally, a photometric rendering strategy is proposed for the 3D sonar point cloud to enrich the sonar map with visual information. Extensive experiments in a laboratory tank and an open lake demonstrate that VISO surpasses current state-of-the-art underwater and visual-based SLAM algorithms in terms of localisation robustness and accuracy, while also exhibiting real-time dense 3D reconstruction performance comparable to the offline dense mapping method.

</details>


### [290] [ORION: Option-Regularized Deep Reinforcement Learning for Cooperative Multi-Agent Online Navigation](https://arxiv.org/abs/2601.01155)
*Zhang Shizhe,Liang Jingsong,Zhou Zhitao,Ye Shuhan,Wang Yizhuo,Tan Ming Siang Derek,Chiun Jimmy,Cao Yuhong,Sartoretti Guillaume*

Main category: cs.RO

TL;DR: ORION是一个深度强化学习框架，用于部分已知环境中的多智能体在线导航，通过分散决策和自适应协作实现高效合作。


<details>
  <summary>Details</summary>
Motivation: 解决部分已知环境中多智能体导航的挑战，平衡路径最优性与信息共享。

Method: ORION采用深度强化学习框架，结合共享图编码器和选项-评论家框架，实现分散决策和自适应协作。

Result: ORION在不同团队规模和环境中表现出色，优于现有基线方法。

Conclusion: ORION框架在物理机器人团队上验证了其鲁棒性和实际应用性，证明了其在真实世界合作导航中的实用性。

Abstract: Existing methods for multi-agent navigation typically assume fully known environments, offering limited support for partially known scenarios such as warehouses or factory floors. There, agents may need to plan trajectories that balance their own path optimality with their ability to collect and share information about the environment that can help their teammates reach their own goals. To these ends, we propose ORION, a novel deep reinforcement learning framework for cooperative multi-agent online navigation in partially known environments. Starting from an imperfect prior map, ORION trains agents to make decentralized decisions, coordinate to reach their individual targets, and actively reduce map uncertainty by sharing online observations in a closed perception-action loop. We first design a shared graph encoder that fuses prior map with online perception into a unified representation, providing robust state embeddings under dynamic map discrepancies. At the core of ORION is an option-critic framework that learns to reason about a set of high-level cooperative modes that translate into sequences of low-level actions, allowing agents to switch between individual navigation and team-level exploration adaptively. We further introduce a dual-stage cooperation strategy that enables agents to assist teammates under map uncertainty, thereby reducing the overall makespan. Across extensive maze-like maps and large-scale warehouse environments, our simulation results show that ORION achieves high-quality, real-time decentralized cooperation over varying team sizes, outperforming state-of-the-art classical and learning-based baselines. Finally, we validate ORION on physical robot teams, demonstrating its robustness and practicality for real-world cooperative navigation.

</details>


### [291] [DST-Calib: A Dual-Path, Self-Supervised, Target-Free LiDAR-Camera Extrinsic Calibration Network](https://arxiv.org/abs/2601.01188)
*Zhiwei Huang,Yanwei Fu,Yi Zhou,Xieyuanli Chen,Qijun Chen,Rui Fan*

Main category: cs.RO

TL;DR: 本文提出了一种无需特定标定目标的自监督LiDAR-相机外参标定网络，通过双面数据增强和差异图构建提升精度和泛化性。


<details>
  <summary>Details</summary>
Motivation: 现有LiDAR-相机外参标定方法依赖手工标定目标或特定静态场景，限制了其在真实机器人应用中的适应性和部署。

Method: 采用双面数据增强技术生成多视角相机视图，并设计双路径自监督标定框架，结合差异图构建过程关联LiDAR和相机特征。

Result: 在五个公共基准数据集和自录数据集上的实验表明，该方法在泛化性上显著优于现有方法。

Conclusion: 本文提出的自监督LiDAR-相机外参标定网络通过双面数据增强和差异图构建，显著提升了标定精度和泛化能力，适用于实际机器人应用。

Abstract: LiDAR-camera extrinsic calibration is essential for multi-modal data fusion in robotic perception systems. However, existing approaches typically rely on handcrafted calibration targets (e.g., checkerboards) or specific, static scene types, limiting their adaptability and deployment in real-world autonomous and robotic applications. This article presents the first self-supervised LiDAR-camera extrinsic calibration network that operates in an online fashion and eliminates the need for specific calibration targets. We first identify a significant generalization degradation problem in prior methods, caused by the conventional single-sided data augmentation strategy. To overcome this limitation, we propose a novel double-sided data augmentation technique that generates multi-perspective camera views using estimated depth maps, thereby enhancing robustness and diversity during training. Built upon this augmentation strategy, we design a dual-path, self-supervised calibration framework that reduces the dependence on high-precision ground truth labels and supports fully adaptive online calibration. Furthermore, to improve cross-modal feature association, we replace the traditional dual-branch feature extraction design with a difference map construction process that explicitly correlates LiDAR and camera features. This not only enhances calibration accuracy but also reduces model complexity. Extensive experiments conducted on five public benchmark datasets, as well as our own recorded dataset, demonstrate that the proposed method significantly outperforms existing approaches in terms of generalizability.

</details>


### [292] [EduSim-LLM: An Educational Platform Integrating Large Language Models and Robotic Simulation for Beginners](https://arxiv.org/abs/2601.01196)
*Shenqi Lu,Liangwei Zhang*

Main category: cs.RO

TL;DR: EduSim-LLM integrates LLMs with robot simulation to enable language-driven control, achieving over 88.9% accuracy in complex tasks.


<details>
  <summary>Details</summary>
Motivation: The integration of natural language understanding into robotic control is a challenge hindering intuitive human control over complex robotic systems, limiting their educational and practical accessibility.

Method: The study presents EduSim-LLM, an educational platform integrating LLMs with robot simulation, designing two human-robot interaction models (direct and autonomous control) and conducting systematic simulations based on multiple language models.

Result: Experiential results show LLMs can reliably translate natural language instructions into executable robot behavior sequences, with improved accuracy through prompt-engineering templates.

Conclusion: LLMs can reliably convert natural language into structured robot actions, with prompt-engineering templates significantly improving instruction-parsing accuracy. The highest complexity tests show an overall accuracy rate exceeding 88.9%.

Abstract: In recent years, the rapid development of Large Language Models (LLMs) has significantly enhanced natural language understanding and human-computer interaction, creating new opportunities in the field of robotics. However, the integration of natural language understanding into robotic control is an important challenge in the rapid development of human-robot interaction and intelligent automation industries. This challenge hinders intuitive human control over complex robotic systems, limiting their educational and practical accessibility. To address this, we present the EduSim-LLM, an educational platform that integrates LLMs with robot simulation and constructs a language-drive control model that translates natural language instructions into executable robot behavior sequences in CoppeliaSim. We design two human-robot interaction models: direct control and autonomous control, conduct systematic simulations based on multiple language models, and evaluate multi-robot collaboration, motion planning, and manipulation capabilities. Experiential results show that LLMs can reliably convert natural language into structured robot actions; after applying prompt-engineering templates instruction-parsing accuracy improves significantly; as task complexity increases, overall accuracy rate exceeds 88.9% in the highest complexity tests.

</details>


### [293] [SAHA: Supervised Autonomous HArvester for selective forest thinning](https://arxiv.org/abs/2601.01282)
*Fang Nan,Meher Malladi,Qingqing Li,Fan Yang,Joonas Juola,Tiziano Guadagnino,Jens Behley,Cesar Cadena,Cyrill Stachniss,Marco Hutter*

Main category: cs.RO

TL;DR: 本文提出了一种基于小型机器人收割机（SAHA）的解决方案，用于森林选择性疏伐任务，通过实验验证了其在真实环境中的可行性。


<details>
  <summary>Details</summary>
Motivation: 森林管理任务（如选择性疏伐）需要熟练操作员且劳动密集，机器人技术可提升效率。

Method: 基于4.5吨收割机平台，通过硬件改造实现感知与自动控制，结合学习和模型方法实现液压执行器精确控制、复杂环境导航、鲁棒状态估计及地形可穿越性语义估计。

Result: 通过北欧森林的公里级自主任务实验，验证了机器人收割机在真实森林环境中的操作能力。

Conclusion: 本文通过实验验证了小型机器人收割机（SAHA）在森林选择性疏伐任务中的可行性，并总结了推进机器人森林管理的经验教训。

Abstract: Forestry plays a vital role in our society, creating significant ecological, economic, and recreational value. Efficient forest management involves labor-intensive and complex operations. One essential task for maintaining forest health and productivity is selective thinning, which requires skilled operators to remove specific trees to create optimal growing conditions for the remaining ones. In this work, we present a solution based on a small-scale robotic harvester (SAHA) designed for executing this task with supervised autonomy. We build on a 4.5-ton harvester platform and implement key hardware modifications for perception and automatic control. We implement learning- and model-based approaches for precise control of hydraulic actuators, accurate navigation through cluttered environments, robust state estimation, and reliable semantic estimation of terrain traversability. Integrating state-of-the-art techniques in perception, planning, and control, our robotic harvester can autonomously navigate forest environments and reach targeted trees for selective thinning. We present experimental results from extensive field trials over kilometer-long autonomous missions in northern European forests, demonstrating the harvester's ability to operate in real forests. We analyze the performance and provide the lessons learned for advancing robotic forest management.

</details>


### [294] [Online Estimation and Manipulation of Articulated Objects](https://arxiv.org/abs/2601.01438)
*Russell Buchanan,Adrian Röfer,João Moura,Abhinav Valada,Sethu Vijayakumar*

Main category: cs.RO

TL;DR: 提出一种结合视觉先验和本体感知的铰接物体在线估计方法，实验证明其能有效操作未知铰接物体。


<details>
  <summary>Details</summary>
Motivation: 解决机器人对任意铰接物体操作的需求，弥补现有方法依赖先验或操作能力的局限性。

Method: 使用因子图结合视觉先验和本体感知（如运动学和力传感），基于螺旋理论进行铰接估计。

Result: 在仿真和真实实验中，机器人能成功打开未见过的抽屉，真实硬件实验中成功率75%。

Conclusion: 该论文提出了一种结合视觉先验和本体感知的在线估计方法，成功实现了机器人对未知铰接物体的自主操作，实验验证了其有效性。

Abstract: From refrigerators to kitchen drawers, humans interact with articulated objects effortlessly every day while completing household chores. For automating these tasks, service robots must be capable of manipulating arbitrary articulated objects. Recent deep learning methods have been shown to predict valuable priors on the affordance of articulated objects from vision. In contrast, many other works estimate object articulations by observing the articulation motion, but this requires the robot to already be capable of manipulating the object. In this article, we propose a novel approach combining these methods by using a factor graph for online estimation of articulation which fuses learned visual priors and proprioceptive sensing during interaction into an analytical model of articulation based on Screw Theory. With our method, a robotic system makes an initial prediction of articulation from vision before touching the object, and then quickly updates the estimate from kinematic and force sensing during manipulation. We evaluate our method extensively in both simulations and real-world robotic manipulation experiments. We demonstrate several closed-loop estimation and manipulation experiments in which the robot was capable of opening previously unseen drawers. In real hardware experiments, the robot achieved a 75% success rate for autonomous opening of unknown articulated objects.

</details>


### [295] [AIMS: An Adaptive Integration of Multi-Sensor Measurements for Quadrupedal Robot Localization](https://arxiv.org/abs/2601.01561)
*Yujian Qiu,Yuqiu Mu,Wen Yang,Hao Zhu*

Main category: cs.RO

TL;DR: AIMS是一种自适应LiDAR-IMU-腿部里程计融合方法，显著提升四足机器人在狭窄隧道环境中的定位性能。


<details>
  <summary>Details</summary>
Motivation: 解决四足机器人在狭窄隧道类环境中因LiDAR测量几何约束弱、传统传感器融合方法易累积运动估计误差的问题。

Method: 提出AIMS，一种基于误差状态卡尔曼滤波的自适应LiDAR-IMU-腿部里程计融合方法，通过在线退化感知可靠性评估动态调整测量噪声协方差矩阵。

Result: 实验结果表明，在狭窄走廊环境中，AIMS方法在定位精度和鲁棒性上优于现有方法。

Conclusion: AIMS方法在狭窄隧道环境中显著提高了四足机器人的定位精度和鲁棒性，优于现有先进方法。

Abstract: This paper addresses the problem of accurate localization for quadrupedal robots operating in narrow tunnel-like environments. Due to the long and homogeneous characteristics of such scenarios, LiDAR measurements often provide weak geometric constraints, making traditional sensor fusion methods susceptible to accumulated motion estimation errors. To address these challenges, we propose AIMS, an adaptive LiDAR-IMU-leg odometry fusion method for robust quadrupedal robot localization in degenerate environments. The proposed method is formulated within an error-state Kalman filtering framework, where LiDAR and leg odometry measurements are integrated with IMU-based state prediction, and measurement noise covariance matrices are adaptively adjusted based on online degeneracy-aware reliability assessment. Experimental results obtained in narrow corridor environments demonstrate that the proposed method improves localization accuracy and robustness compared with state-of-the-art approaches.

</details>


### [296] [HanoiWorld : A Joint Embedding Predictive Architecture BasedWorld Model for Autonomous Vehicle Controller](https://arxiv.org/abs/2601.01577)
*Tran Tien Dat,Nguyen Hai An,Nguyen Khanh Viet Dung,Nguyen Duy Duc*

Main category: cs.RO

TL;DR: Hanoi-World结合JEPA与RNN，优化自动驾驶规划的长期性与安全性，实验显示其碰撞率显著低于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前强化学习方法在自动驾驶控制器中存在数据需求高、性能不稳定、安全性不足及过度关注噪声特征的问题，而自监督学习通过JEPA架构模拟人脑学习能力，为这一问题提供了潜在解决方案。

Method: 采用基于JEPA架构的Hanoi-World模型，利用RNN进行长期水平规划，并在Highway-Env环境中进行实验验证。

Result: 实验结果表明，Hanoi-World在高速公路环境中表现出色，具有较低碰撞率，优于现有先进基准。

Conclusion: Hanoi-World模型通过结合JEPA架构和RNN，在自动驾驶控制任务中实现了长期规划与安全意识的平衡，显著降低了碰撞率，优于现有基准方法。

Abstract: Current attempts of Reinforcement Learning for Autonomous Controller are data-demanding while the results are under-performed, unstable, and unable to grasp and anchor on the concept of safety, and over-concentrating on noise features due to the nature of pixel reconstruction. While current Self-Supervised Learningapproachs that learning on high-dimensional representations by leveraging the JointEmbedding Predictive Architecture (JEPA) are interesting and an effective alternative, as the idea mimics the natural ability of the human brain in acquiring new skill usingimagination and minimal samples of observations. This study introduces Hanoi-World, a JEPA-based world model that using recurrent neural network (RNN) formaking longterm horizontal planning with effective inference time. Experimentsconducted on the Highway-Env package with difference enviroment showcase the effective capability of making a driving plan while safety-awareness, with considerablecollision rate in comparison with SOTA baselines

</details>


### [297] [Action-Sketcher: From Reasoning to Action via Visual Sketches for Long-Horizon Robotic Manipulation](https://arxiv.org/abs/2601.01618)
*Huajie Tan,Peterson Co,Yijie Xu,Shanyu Rong,Yuheng Ji,Cheng Chi,Xiansheng Chen,Qiongyu Zhang,Zhongxia Zhao,Pengwei Wang,Zhongyuan Wang,Shanghang Zhang*

Main category: cs.RO

TL;DR: Action-Sketcher通过视觉草图外部化空间意图，结合自适应工作流和多阶段训练，提升了长时程机器人操作的性能与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有端到端和分层的视觉-语言-动作（VLA）策略依赖文本线索且意图隐含，导致在复杂场景中参考基础薄弱、任务分解低效，且动作选择缺乏因果解释。

Method: 提出Visual Sketch作为视觉中间表示，并基于此构建Action-Sketcher框架，采用See-Think-Sketch-Act循环工作流，结合多阶段课程学习方法进行训练。

Result: 在仿真和真实任务中，Action-Sketcher在杂乱场景和多对象任务中表现出更高的长时程成功率、更强的动态场景变化鲁棒性，以及通过可编辑草图和分步计划增强的可解释性。

Conclusion: Action-Sketcher框架通过视觉草图（Visual Sketch）外部化空间意图，结合自适应令牌门控策略，显著提升了长时程机器人操作的性能、鲁棒性和可解释性。

Abstract: Long-horizon robotic manipulation is increasingly important for real-world deployment, requiring spatial disambiguation in complex layouts and temporal resilience under dynamic interaction. However, existing end-to-end and hierarchical Vision-Language-Action (VLA) policies often rely on text-only cues while keeping plan intent latent, which undermines referential grounding in cluttered or underspecified scenes, impedes effective task decomposition of long-horizon goals with close-loop interaction, and limits causal explanation by obscuring the rationale behind action choices. To address these issues, we first introduce Visual Sketch, an implausible visual intermediate that renders points, boxes, arrows, and typed relations in the robot's current views to externalize spatial intent, connect language to scene geometry. Building on Visual Sketch, we present Action-Sketcher, a VLA framework that operates in a cyclic See-Think-Sketch-Act workflow coordinated by adaptive token-gated strategy for reasoning triggers, sketch revision, and action issuance, thereby supporting reactive corrections and human interaction while preserving real-time action prediction. To enable scalable training and evaluation, we curate diverse corpus with interleaved images, text, Visual Sketch supervision, and action sequences, and train Action-Sketcher with a multi-stage curriculum recipe that combines interleaved sequence alignment for modality unification, language-to-sketch consistency for precise linguistic grounding, and imitation learning augmented with sketch-to-action reinforcement for robustness. Extensive experiments on cluttered scenes and multi-object tasks, in simulation and on real-world tasks, show improved long-horizon success, stronger robustness to dynamic scene changes, and enhanced interpretability via editable sketches and step-wise plans. Project website: https://action-sketcher.github.io

</details>


### [298] [DemoBot: Efficient Learning of Bimanual Manipulation with Dexterous Hands From Third-Person Human Videos](https://arxiv.org/abs/2601.01651)
*Yucheng Xu,Xiaofeng Mao,Elle Miller,Xinyu Yi,Yang Li,Zhibin Li,Robert B. Fisher*

Main category: cs.RO

TL;DR: DemoBot框架通过视频和强化学习，让机器人从单一未标注视频中学习复杂操作技能，成功完成双手装配任务。


<details>
  <summary>Details</summary>
Motivation: 解决从单一未标注视频中学习复杂操作技能的挑战，避免从零开始学习，提高学习效率和精度。

Method: 方法包括从原始视频数据中提取双手和物体的结构化运动轨迹，作为运动先验知识，结合强化学习（RL）管道进行细化。具体技术包括基于时间段的RL、成功门控重置策略和事件驱动的奖励课程。

Result: 成功实现了长时程同步和异步双手装配任务。

Conclusion: DemoBot框架通过从单一未标注RGB-D视频中学习，成功实现了双臂多指机器人系统对复杂操作技能的获取，为从人类视频直接获取技能提供了可扩展的方法。

Abstract: This work presents DemoBot, a learning framework that enables a dual-arm, multi-finger robotic system to acquire complex manipulation skills from a single unannotated RGB-D video demonstration. The method extracts structured motion trajectories of both hands and objects from raw video data. These trajectories serve as motion priors for a novel reinforcement learning (RL) pipeline that learns to refine them through contact-rich interactions, thereby eliminating the need to learn from scratch. To address the challenge of learning long-horizon manipulation skills, we introduce: (1) Temporal-segment based RL to enforce temporal alignment of the current state with demonstrations; (2) Success-Gated Reset strategy to balance the refinement of readily acquired skills and the exploration of subsequent task stages; and (3) Event-Driven Reward curriculum with adaptive thresholding to guide the RL learning of high-precision manipulation. The novel video processing and RL framework successfully achieved long-horizon synchronous and asynchronous bimanual assembly tasks, offering a scalable approach for direct skill acquisition from human videos.

</details>


### [299] [VisuoTactile 6D Pose Estimation of an In-Hand Object using Vision and Tactile Sensor Data](https://arxiv.org/abs/2601.01675)
*Snehal s. Dikhale,Karankumar Patel,Daksh Dhingra,Itoshi Naramura,Akinobu Hayashi,Soshi Iba,Nawid Jamali*

Main category: cs.RO

TL;DR: 提出一种结合触觉和视觉数据的方法，通过点云表示和密集融合网络架构，显著提升了6D物体姿态估计的准确性，并能从合成数据泛化到实际应用。


<details>
  <summary>Details</summary>
Motivation: 解决机器人夹持器导致的严重遮挡问题，以及触觉数据缺乏标准表示和传感器融合的挑战。

Method: 提出了一种基于点云表示触觉数据的物体表面接触方法，并设计了一个基于像素级密集融合的网络架构。同时扩展了NVIDIA的深度学习数据集合成器以生成合成视觉数据和对应的触觉点云。

Result: 实验结果表明，结合触觉数据显著改善了6D姿态估计的准确性，且网络能够从合成数据泛化到实际机器人。

Conclusion: 结合触觉和视觉数据的方法显著提高了6D物体姿态估计的准确性，且网络能够成功从合成训练泛化到实际机器人应用。

Abstract: Knowledge of the 6D pose of an object can benefit in-hand object manipulation. In-hand 6D object pose estimation is challenging because of heavy occlusion produced by the robot's grippers, which can have an adverse effect on methods that rely on vision data only. Many robots are equipped with tactile sensors at their fingertips that could be used to complement vision data. In this paper, we present a method that uses both tactile and vision data to estimate the pose of an object grasped in a robot's hand. To address challenges like lack of standard representation for tactile data and sensor fusion, we propose the use of point clouds to represent object surfaces in contact with the tactile sensor and present a network architecture based on pixel-wise dense fusion. We also extend NVIDIA's Deep Learning Dataset Synthesizer to produce synthetic photo-realistic vision data and corresponding tactile point clouds. Results suggest that using tactile data in addition to vision data improves the 6D pose estimate, and our network generalizes successfully from synthetic training to real physical robots.

</details>


### [300] [Explicit World Models for Reliable Human-Robot Collaboration](https://arxiv.org/abs/2601.01705)
*Kenneth Kwok,Basura Fernando,Qianli Xu,Vigneshwaran Subbaraju,Dongkyu Choi,Boon Kiat Quek*

Main category: cs.RO

TL;DR: 本文主张通过构建‘显式世界模型’来对齐AI与人类期望，强调动态交互而非传统验证方法，以提升具体化AI在复杂环境中的可靠性。


<details>
  <summary>Details</summary>
Motivation: 探讨在充满传感噪声、模糊指令和复杂人机交互的环境中，如何实现具体化AI的可靠性。

Method: 强调动态、模糊和主观的人机交互特性，而非传统的模型可预测性和鲁棒性验证方法。

Result: 提出了一种以‘显式世界模型’为基础的方法，用于在多变的社会化、多模态和流动的人类环境中实现可靠的AI交互。

Conclusion: 本文提出了一种以构建和更新‘显式世界模型’为核心的新方法，旨在实现可靠的具体化AI，通过这一模型来对齐机器行为与人类期望。

Abstract: This paper addresses the topic of robustness under sensing noise, ambiguous instructions, and human-robot interaction. We take a radically different tack to the issue of reliable embodied AI: instead of focusing on formal verification methods aimed at achieving model predictability and robustness, we emphasise the dynamic, ambiguous and subjective nature of human-robot interactions that requires embodied AI systems to perceive, interpret, and respond to human intentions in a manner that is consistent, comprehensible and aligned with human expectations. We argue that when embodied agents operate in human environments that are inherently social, multimodal, and fluid, reliability is contextually determined and only has meaning in relation to the goals and expectations of humans involved in the interaction. This calls for a fundamentally different approach to achieving reliable embodied AI that is centred on building and updating an accessible "explicit world model" representing the common ground between human and AI, that is used to align robot behaviours with human expectations.

</details>


### [301] [Simulations and Advancements in MRI-Guided Power-Driven Ferric Tools for Wireless Therapeutic Interventions](https://arxiv.org/abs/2601.01726)
*Wenhui Chu,Aobo Jin,Hardik A. Gohel*

Main category: cs.RO

TL;DR: 该研究开发了一种与MRI扫描仪集成的计算系统，用于机器人辅助血管内介入，提升了手术的精确性和安全性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在增强MRI在医学成像中的作用，特别是在机器人辅助设备引导血管内介入中的应用。

Method: 研究引入了一种新的计算系统，包括计算单元和用户界面，用于与MRI扫描仪无缝集成。该系统处理MR图像以描绘血管网络，建立虚拟路径和边界以防止手术损伤。

Result: 关键发现表明，该系统能够根据血管几何形状和安全规范创建定制的磁场梯度模式，并适应不同的血流特性以实现更精细的导航。此外，系统的建模方面评估了预设血管路径导航的安全性和可行性。

Conclusion: 该系统基于Qt框架和C/C++开发，结合专用软件模块，代表了成像技术与机器人辅助的重大进步，显著提升了血管内手术的精确性和安全性。

Abstract: Designing a robotic system that functions effectively within the specific environment of a Magnetic Resonance Imaging (MRI) scanner requires solving numerous technical issues, such as maintaining the robot's precision and stability under strong magnetic fields. This research focuses on enhancing MRI's role in medical imaging, especially in its application to guide intravascular interventions using robot-assisted devices. A newly developed computational system is introduced, designed for seamless integration with the MRI scanner, including a computational unit and user interface. This system processes MR images to delineate the vascular network, establishing virtual paths and boundaries within vessels to prevent procedural damage. Key findings reveal the system's capability to create tailored magnetic field gradient patterns for device control, considering the vessel's geometry and safety norms, and adapting to different blood flow characteristics for finer navigation. Additionally, the system's modeling aspect assesses the safety and feasibility of navigating pre-set vascular paths. Conclusively, this system, based on the Qt framework and C/C++, with specialized software modules, represents a major step forward in merging imaging technology with robotic aid, significantly enhancing precision and safety in intravascular procedures.

</details>


### [302] [AlignDrive: Aligned Lateral-Longitudinal Planning for End-to-End Autonomous Driving](https://arxiv.org/abs/2601.01762)
*Yanhao Wu,Haoyang Zhang,Fei He,Rui Wu,Congpei Qiu,Liang Gao,Wei Ke,Tong Zhang*

Main category: cs.RO

TL;DR: 提出级联框架，通过路径条件化公式显式结合驾驶路径与纵向规划，提升自动驾驶协调性与安全性，Bench2Drive测试表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有SOTA端到端自动驾驶模型在规划阶段将横向和纵向预测解耦，可能导致路径与速度协调失败，且未充分利用驾驶路径作为纵向规划的先验信息。

Method: 提出了一种新颖的级联框架，通过路径条件化公式将驾驶路径显式地纳入纵向规划，并基于此预测沿驾驶路径的纵向位移而非完整的2D轨迹点。此外，引入了面向规划的数据增强策略，模拟罕见的安全关键事件。

Result: 在Bench2Drive基准测试中，该方法创下了新的SOTA，驾驶得分为89.07，成功率为73.18%，显著提升了协调性和安全性。

Conclusion: 提出的级联框架通过显式地将纵向规划建立在驾驶路径上，实现了横向和纵向规划的协调与碰撞感知，显著提升了自动驾驶的协调性和安全性。

Abstract: End-to-end autonomous driving has rapidly progressed, enabling joint perception and planning in complex environments. In the planning stage, state-of-the-art (SOTA) end-to-end autonomous driving models decouple planning into parallel lateral and longitudinal predictions. While effective, this parallel design can lead to i) coordination failures between the planned path and speed, and ii) underutilization of the drive path as a prior for longitudinal planning, thus redundantly encoding static information. To address this, we propose a novel cascaded framework that explicitly conditions longitudinal planning on the drive path, enabling coordinated and collision-aware lateral and longitudinal planning. Specifically, we introduce a path-conditioned formulation that explicitly incorporates the drive path into longitudinal planning. Building on this, the model predicts longitudinal displacements along the drive path rather than full 2D trajectory waypoints. This design simplifies longitudinal reasoning and more tightly couples it with lateral planning. Additionally, we introduce a planning-oriented data augmentation strategy that simulates rare safety-critical events, such as vehicle cut-ins, by adding agents and relabeling longitudinal targets to avoid collision. Evaluated on the challenging Bench2Drive benchmark, our method sets a new SOTA, achieving a driving score of 89.07 and a success rate of 73.18%, demonstrating significantly improved coordination and safety

</details>


### [303] [DisCo-FLoc: Using Dual-Level Visual-Geometric Contrasts to Disambiguate Depth-Aware Visual Floorplan Localization](https://arxiv.org/abs/2601.01822)
*Shiyong Meng,Tao Zou,Bolei Chen,Chaoxu Mu,Jianxin Wang*

Main category: cs.RO

TL;DR: DisCo-FLoc通过双级对比学习解决平面图定位模糊问题，无需语义标签，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法因简约平面图中的重复结构导致定位模糊，且昂贵的语义标注限制了其应用，因此需要一种无需额外语义标签的解决方案。

Method: 提出了一种基于深度估计的射线回归预测器，以及带有位置级和方向级约束的新型对比学习方法，严格匹配深度感知视觉特征与平面图中的几何结构。

Result: 在两个标准视觉平面定位基准测试中，DisCo-FLoc在鲁棒性和准确性上均优于现有基于语义的方法。

Conclusion: DisCo-FLoc通过双级视觉-几何对比有效解决了简约化平面图中重复结构导致的定位模糊问题，无需额外语义标签，显著提升了视觉平面定位的鲁棒性和准确性。

Abstract: Since floorplan data is readily available, long-term persistent, and robust to changes in visual appearance, visual Floorplan Localization (FLoc) has garnered significant attention. Existing methods either ingeniously match geometric priors or utilize sparse semantics to reduce FLoc uncertainty. However, they still suffer from ambiguous FLoc caused by repetitive structures within minimalist floorplans. Moreover, expensive but limited semantic annotations restrict their applicability. To address these issues, we propose DisCo-FLoc, which utilizes dual-level visual-geometric Contrasts to Disambiguate depth-aware visual Floc, without requiring additional semantic labels. Our solution begins with a ray regression predictor tailored for ray-casting-based FLoc, predicting a series of FLoc candidates using depth estimation expertise. In addition, a novel contrastive learning method with position-level and orientation-level constraints is proposed to strictly match depth-aware visual features with the corresponding geometric structures in the floorplan. Such matches can effectively eliminate FLoc ambiguity and select the optimal imaging pose from FLoc candidates. Exhaustive comparative studies on two standard visual Floc benchmarks demonstrate that our method outperforms the state-of-the-art semantic-based method, achieving significant improvements in both robustness and accuracy.

</details>


### [304] [CausalNav: A Long-term Embodied Navigation System for Autonomous Mobile Robots in Dynamic Outdoor Scenarios](https://arxiv.org/abs/2601.01872)
*Hongbo Duan,Shangyi Luo,Zhiyuan Deng,Yanbo Chen,Yuanhao Chiang,Yi Liu,Fangming Liu,Xueqian Wang*

Main category: cs.RO

TL;DR: CausalNav是一种基于场景图的语义导航框架，专为动态户外环境设计，通过多级语义场景图和实时感知提升导航能力，实验证明其高效且鲁棒。


<details>
  <summary>Details</summary>
Motivation: 解决大规模户外环境中自主语言引导导航的挑战，包括语义推理、动态条件和长期稳定性问题。

Method: 构建多级语义场景图（Embodied Graph），结合LLMs和离线地图数据，支持检索增强生成（RAG）以实现语义导航和长程规划。动态对象在场景图构建和分层规划模块中显式处理，并通过时间窗口持续更新。

Result: 在仿真和真实环境中的大量实验表明，CausalNav具有优越的鲁棒性和效率。

Conclusion: CausalNav框架通过结合多级语义场景图和实时感知，显著提升了动态户外环境中的自主导航能力，展现了卓越的鲁棒性和效率。

Abstract: Autonomous language-guided navigation in large-scale outdoor environments remains a key challenge in mobile robotics, due to difficulties in semantic reasoning, dynamic conditions, and long-term stability. We propose CausalNav, the first scene graph-based semantic navigation framework tailored for dynamic outdoor environments. We construct a multi-level semantic scene graph using LLMs, referred to as the Embodied Graph, that hierarchically integrates coarse-grained map data with fine-grained object entities. The constructed graph serves as a retrievable knowledge base for Retrieval-Augmented Generation (RAG), enabling semantic navigation and long-range planning under open-vocabulary queries. By fusing real-time perception with offline map data, the Embodied Graph supports robust navigation across varying spatial granularities in dynamic outdoor environments. Dynamic objects are explicitly handled in both the scene graph construction and hierarchical planning modules. The Embodied Graph is continuously updated within a temporal window to reflect environmental changes and support real-time semantic navigation. Extensive experiments in both simulation and real-world settings demonstrate superior robustness and efficiency.

</details>


### [305] [From Metrics to Meaning: Insights from a Mixed-Methods Field Experiment on Retail Robot Deployment](https://arxiv.org/abs/2601.01946)
*Sichao Song,Yuki Okafuji,Takuya Iwamoto,Jun Baba,Hiroshi Ishiguro*

Main category: cs.RO

TL;DR: 研究发现零售机器人虽增加顾客停留率，但减少了店员主导的后续服务步骤，揭示了员工与机器人互动的挑战，并提出了部署建议。


<details>
  <summary>Details</summary>
Motivation: 探讨在零售环境中部署对话服务机器人对顾客行为和服务流程的影响，以及员工与机器人互动的挑战。

Method: 采用混合方法实地实验，包括12天的三种条件交替（无机器人、仅机器人、机器人+固定装置），并通过视频注释服务漏斗，后续通过六次员工访谈解释定量模式。

Result: 机器人增加了顾客停留率（尤其是与固定装置结合时），但减少了店员主导的下游步骤（如接近、进店、协助体验和购买）。访谈揭示了员工避免打断机器人与顾客对话、面对对话延迟的时机模糊性以及机器人对儿童的吸引力等问题。

Conclusion: 研究综合了顾客、员工和机器人之间的互动关系，并为高接触零售环境中服务机器人的部署提供了实用建议。

Abstract: We report a mixed-methods field experiment of a conversational service robot deployed under everyday staffing discretion in a live bedding store. Over 12 days we alternated three conditions--Baseline (no robot), Robot-only, and Robot+Fixture--and video-annotated the service funnel from passersby to purchase. An explanatory sequential design then used six post-experiment staff interviews to interpret the quantitative patterns.
  Quantitatively, the robot increased stopping per passerby (highest with the fixture), yet clerk-led downstream steps per stopper--clerk approach, store entry, assisted experience, and purchase--decreased. Interviews explained this divergence: clerks avoided interrupting ongoing robot-customer talk, struggled with ambiguous timing amid conversational latency, and noted child-centered attraction that often satisfied curiosity at the doorway. The fixture amplified visibility but also anchored encounters at the threshold, creating a well-defined micro-space where needs could ``close'' without moving inside.
  We synthesize these strands into an integrative account from the initial show of interest on the part of a customer to their entering the store and derive actionable guidance. The results advance the understanding of interactions between customers, staff members, and the robot and offer practical recommendations for deploying service robots in high-touch retail.

</details>


### [306] [Learning Diffusion Policy from Primitive Skills for Robot Manipulation](https://arxiv.org/abs/2601.01948)
*Zhihao Gu,Ming Yang,Difan Zou,Dong Xu*

Main category: cs.RO

TL;DR: SDP是一种基于技能的扩散策略，通过分解任务为基本技能并确保技能一致性，显著提升了机器人动作生成的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散策略方法依赖全局指令生成短期控制信号，可能导致动作生成不对齐。基本技能（如“向上移动”和“打开夹爪”）为机器人学习提供了更直观有效的接口。

Method: SDP整合了可解释的技能学习与条件动作规划，抽象出八个可重用的基本技能，并利用视觉语言模型从视觉观察和语言指令中提取离散表示。设计了一个轻量级路由器网络，为每个状态分配所需的基本技能，构建单一技能策略以生成技能对齐的动作。

Result: 在两个具有挑战性的仿真基准和真实机器人部署中，SDP始终优于最先进的方法。

Conclusion: SDP通过将复杂任务分解为一系列基本技能并选择单一技能策略，确保了跨任务的技能一致性行为，为基于技能的机器人学习提供了新范式。

Abstract: Diffusion policies (DP) have recently shown great promise for generating actions in robotic manipulation. However, existing approaches often rely on global instructions to produce short-term control signals, which can result in misalignment in action generation. We conjecture that the primitive skills, referred to as fine-grained, short-horizon manipulations, such as ``move up'' and ``open the gripper'', provide a more intuitive and effective interface for robot learning. To bridge this gap, we propose SDP, a skill-conditioned DP that integrates interpretable skill learning with conditional action planning. SDP abstracts eight reusable primitive skills across tasks and employs a vision-language model to extract discrete representations from visual observations and language instructions. Based on them, a lightweight router network is designed to assign a desired primitive skill for each state, which helps construct a single-skill policy to generate skill-aligned actions. By decomposing complex tasks into a sequence of primitive skills and selecting a single-skill policy, SDP ensures skill-consistent behavior across diverse tasks. Extensive experiments on two challenging simulation benchmarks and real-world robot deployments demonstrate that SDP consistently outperforms SOTA methods, providing a new paradigm for skill-based robot learning with diffusion policies.

</details>


### [307] [What you reward is what you learn: Comparing rewards for online speech policy optimization in public HRI](https://arxiv.org/abs/2601.01969)
*Sichao Song,Yuki Okafuji,Kaito Ariu,Amy Koike*

Main category: cs.RO

TL;DR: 研究通过在线优化和离线评估，为公共HRI场景中的语音策略设计提供了实用经验。


<details>
  <summary>Details</summary>
Motivation: 设计在开放多样环境中既高效又可接受的对话服务机器人策略具有挑战性，在线学习能适应非稳态条件。

Method: 通过12天的现场部署，将在线策略优化建模为多臂老虎机问题，并采用Thompson采样在六种动作（语速慢/正常/快，简洁/详细）中选择。同时，结合三种二元奖励（用户评分、对话结束、至少两轮对话）进行比较。

Result: 每种奖励机制诱导出不同的动作分布和交互行为，离线评估进一步分析了上下文因素（如人群密度、小组规模）。

Conclusion: 本研究为在真实公共人机交互（HRI）场景中部署在线语音策略优化提供了可直接应用的设计经验。

Abstract: Designing policies that are both efficient and acceptable for conversational service robots in open and diverse environments is non-trivial. Unlike fixed, hand-tuned parameters, online learning can adapt to non-stationary conditions. In this paper, we study how to adapt a social robot's speech policy in the wild. During a 12-day in-situ deployment with over 1,400 public encounters, we cast online policy optimization as a multi-armed bandit problem and use Thompson sampling to select among six actions defined by speech rate (slow/normal/fast) and verbosity (concise/detailed). We compare three complementary binary rewards--Ru (user rating), Rc (conversation closure), and Rt (>=2 turns)--and show that each induces distinct arm distributions and interaction behaviors. We complement the online results with offline evaluations that analyze contextual factors (e.g., crowd level, group size) using video-annotated data. Taken together, we distill ready-to-use design lessons for deploying online optimization of speech policies in real public HRI settings.

</details>


### [308] [Deep Robust Koopman Learning from Noisy Data](https://arxiv.org/abs/2601.01971)
*Aditya Singh,Rajpal Singh,Jishnu Keshavan*

Main category: cs.RO

TL;DR: 提出了一种基于自动编码器的神经架构，用于从噪声数据中学习Koopman算子，显著减少噪声诱导偏差，提高了预测和跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界的数据通常带有噪声，导致Koopman算子的近似存在噪声诱导偏差，严重影响预测和跟踪性能。

Method: 采用自动编码器神经网络架构，联合学习系统的正向和反向时间动态一致的Koopman基函数，并利用这些动态合成减少偏差的Koopman算子。

Result: 理论分析表明该方法在训练噪声下显著减少了偏差。多个串联机械臂的动态预测和跟踪控制仿真验证了其在不同噪声水平下的鲁棒性，Franka FR3 7-DoF机械臂的实验研究进一步证明了其在实际场景中的有效性。

Conclusion: 本文提出了一种基于自动编码器的神经架构，用于从噪声数据中联合学习适当的提升函数和减少偏差的Koopman算子，显著提高了噪声环境下的预测和跟踪性能。

Abstract: Koopman operator theory has emerged as a leading data-driven approach that relies on a judicious choice of observable functions to realize global linear representations of nonlinear systems in the lifted observable space. However, real-world data is often noisy, making it difficult to obtain an accurate and unbiased approximation of the Koopman operator. The Koopman operator generated from noisy datasets is typically corrupted by noise-induced bias that severely degrades prediction and downstream tracking performance. In order to address this drawback, this paper proposes a novel autoencoder-based neural architecture to jointly learn the appropriate lifting functions and the reduced-bias Koopman operator from noisy data. The architecture initially learns the Koopman basis functions that are consistent for both the forward and backward temporal dynamics of the system. Subsequently, by utilizing the learned forward and backward temporal dynamics, the Koopman operator is synthesized with a reduced bias making the method more robust to noise compared to existing techniques. Theoretical analysis is used to demonstrate significant bias reduction in the presence of training noise. Dynamics prediction and tracking control simulations are conducted for multiple serial manipulator arms, including performance comparisons with leading alternative designs, to demonstrate its robustness under various noise levels. Experimental studies with the Franka FR3 7-DoF manipulator arm are further used to demonstrate the effectiveness of the proposed approach in a practical setting.

</details>


### [309] [Genie Sim 3.0 : A High-Fidelity Comprehensive Simulation Platform for Humanoid Robot](https://arxiv.org/abs/2601.02078)
*Chenghao Yin,Da Huang,Di Yang,Jichao Wang,Nanshu Zhao,Chen Xu,Wenjun Sun,Linjie Hou,Zhijun Li,Junhui Wu,Zhaobo Liu,Zhen Xiao,Sheng Zhang,Lei Bao,Rui Feng,Zhenquan Pang,Jiayu Li,Qian Wang,Maoqing Yao*

Main category: cs.RO

TL;DR: Genie Sim 3.0是一个统一的机器人操作模拟平台，利用LLM生成高保真场景和自动评估基准，开源数据集验证了合成数据在模拟到现实转移中的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决物理世界中数据收集的高成本和可扩展性挑战，以及现有模拟基准的碎片化、范围狭窄或保真度不足问题。

Method: 介绍了Genie Sim 3.0，一个统一的机器人操作模拟平台，以及Genie Sim Generator，一个由大型语言模型（LLM）驱动的工具，用于从自然语言指令构建高保真场景。还提出了首个利用LLM进行自动评估的基准，并发布了包含200多个任务、超过10,000小时合成数据的开源数据集。

Result: 验证了合成数据在零样本模拟到现实转移中的有效性，并展示了其在可扩展策略训练中的潜力。

Conclusion: 通过系统实验验证了开源数据集在零样本模拟到现实转移中的稳健能力，表明在受控条件下合成数据可以有效地替代真实世界数据用于可扩展的策略训练。

Abstract: The development of robust and generalizable robot learning models is critically contingent upon the availability of large-scale, diverse training data and reliable evaluation benchmarks. Collecting data in the physical world poses prohibitive costs and scalability challenges, and prevailing simulation benchmarks frequently suffer from fragmentation, narrow scope, or insufficient fidelity to enable effective sim-to-real transfer. To address these challenges, we introduce Genie Sim 3.0, a unified simulation platform for robotic manipulation. We present Genie Sim Generator, a large language model (LLM)-powered tool that constructs high-fidelity scenes from natural language instructions. Its principal strength resides in rapid and multi-dimensional generalization, facilitating the synthesis of diverse environments to support scalable data collection and robust policy evaluation. We introduce the first benchmark that pioneers the application of LLM for automated evaluation. It leverages LLM to mass-generate evaluation scenarios and employs Vision-Language Model (VLM) to establish an automated assessment pipeline. We also release an open-source dataset comprising more than 10,000 hours of synthetic data across over 200 tasks. Through systematic experimentation, we validate the robust zero-shot sim-to-real transfer capability of our open-source dataset, demonstrating that synthetic data can server as an effective substitute for real-world data under controlled conditions for scalable policy training. For code and dataset details, please refer to: https://github.com/AgibotTech/genie_sim.

</details>


### [310] [Vision-Based Early Fault Diagnosis and Self-Recovery for Strawberry Harvesting Robots](https://arxiv.org/abs/2601.02085)
*Meili Sun,Chunjiang Zhao,Lichao Yang,Hao Liu,Shimin Hu,Ya Xiong*

Main category: cs.RO

TL;DR: SRR-Net框架通过多任务感知与实时控制策略，显著提升草莓采摘机器人的稳定性和效率，实验显示其在检测、分割和成熟度估计任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决草莓采摘机器人因视觉感知不足、定位偏差、空抓和果实滑落导致的采摘效率低下问题。

Method: 提出了一种视觉故障诊断与自恢复框架，核心为SRR-Net多任务感知模型，结合相对误差补偿方法和早期中止策略，并利用微光学摄像头实时反馈。

Result: SRR-Net在检测、分割和成熟度估计任务中表现优异，检测精度达0.895（草莓）和0.972（手），分割精度为0.887（草莓）和0.974（手），成熟度估计平均绝对误差为0.035，推理速度达163.35 FPS。

Conclusion: SRR-Net框架通过多任务感知与纠正控制策略的结合，有效解决了草莓采摘机器人面临的视觉感知不足、定位偏差、空抓和果实滑落等问题，显著提升了采摘的稳定性和效率。

Abstract: Strawberry harvesting robots faced persistent challenges such as low integration of visual perception, fruit-gripper misalignment, empty grasping, and strawberry slippage from the gripper due to insufficient gripping force, all of which compromised harvesting stability and efficiency in orchard environments. To overcome these issues, this paper proposed a visual fault diagnosis and self-recovery framework that integrated multi-task perception with corrective control strategies. At the core of this framework was SRR-Net, an end-to-end multi-task perception model that simultaneously performed strawberry detection, segmentation, and ripeness estimation, thereby unifying visual perception with fault diagnosis. Based on this integrated perception, a relative error compensation method based on the simultaneous target-gripper detection was designed to address positional misalignment, correcting deviations when error exceeded the tolerance threshold. To mitigate empty grasping and fruit-slippage faults, an early abort strategy was implemented. A micro-optical camera embedded in the end-effector provided real-time visual feedback, enabling grasp detection during the deflating stage and strawberry slip prediction during snap-off through MobileNet V3-Small classifier and a time-series LSTM classifier. Experiments demonstrated that SRR-Net maintained high perception accuracy. For detection, it achieved a precision of 0.895 and recall of 0.813 on strawberries, and 0.972/0.958 on hands. In segmentation, it yielded a precision of 0.887 and recall of 0.747 for strawberries, and 0.974/0.947 for hands. For ripeness estimation, SRR-Net attained a mean absolute error of 0.035, while simultaneously supporting multi-task perception and sustaining a competitive inference speed of 163.35 FPS.

</details>


### [311] [SingingBot: An Avatar-Driven System for Robotic Face Singing Performance](https://arxiv.org/abs/2601.02125)
*Zhuoxiong Xu,Xuanchen Li,Yuhao Cheng,Fei Xu,Yichao Yan,Xiaokang Yang*

Main category: cs.RO

TL;DR: 提出了一种基于头像驱动的机器人歌唱框架，通过语义映射和情感动态范围指标，显著提升了歌唱表演的情感表达和吸引力。


<details>
  <summary>Details</summary>
Motivation: 现有机器人面部驱动研究主要集中于对话或模仿静态表情，难以满足歌唱中连续情感表达和一致性的高要求。

Method: 利用嵌入广泛人类先验的肖像视频生成模型合成生动的歌唱头像，并通过语义导向的映射函数将这些面部特征传递到机器人上。此外，提出了情感动态范围（Emotion Dynamic Range）指标来量化歌唱中的情感丰富度。

Result: 综合实验证明，该方法在保持唇音同步的同时实现了丰富的情感表达，显著优于现有方法。

Conclusion: 该论文提出了一种新颖的基于头像驱动的机器人歌唱框架，通过语义导向的映射函数将丰富的面部表情特征传递到机器人上，显著提升了歌唱表演的情感表达和吸引力。

Abstract: Equipping robotic faces with singing capabilities is crucial for empathetic Human-Robot Interaction. However, existing robotic face driving research primarily focuses on conversations or mimicking static expressions, struggling to meet the high demands for continuous emotional expression and coherence in singing. To address this, we propose a novel avatar-driven framework for appealing robotic singing. We first leverage portrait video generation models embedded with extensive human priors to synthesize vivid singing avatars, providing reliable expression and emotion guidance. Subsequently, these facial features are transferred to the robot via semantic-oriented mapping functions that span a wide expression space. Furthermore, to quantitatively evaluate the emotional richness of robotic singing, we propose the Emotion Dynamic Range metric to measure the emotional breadth within the Valence-Arousal space, revealing that a broad emotional spectrum is crucial for appealing performances. Comprehensive experiments prove that our method achieves rich emotional expressions while maintaining lip-audio synchronization, significantly outperforming existing approaches.

</details>


### [312] [Differential Barometric Altimetry for Submeter Vertical Localization and Floor Recognition Indoors](https://arxiv.org/abs/2601.02184)
*Yuhang Zhang,Sören Schwertfeger*

Main category: cs.RO

TL;DR: 本文提出了一种基于差分气压传感的低成本垂直定位框架，实现了亚米级精度和100%楼层识别，优于传统SLAM方法，并开源了ROS兼容的实现。


<details>
  <summary>Details</summary>
Motivation: 在复杂的多楼层环境中，准确的垂直定位和楼层识别对机器人导航至关重要，而现有的视觉或LiDAR SLAM方法在垂直定位上表现不足。

Method: 通过差分气压传感技术，结合固定基站和移动传感器的实时气压数据，构建了一个完全兼容ROS的软件包。

Result: 实验表明，该方法在封闭楼梯间和电梯等挑战性场景中实现了亚米级垂直精度（RMSE: 0.29 m）和完美的楼层识别率（100%）。

Conclusion: 本文提出的基于差分气压传感的垂直定位框架在复杂多楼层环境中实现了亚米级垂直精度（RMSE: 0.29 m）和100%的楼层识别准确率，为机器人部署提供了实用且低成本的解决方案。

Abstract: Accurate altitude estimation and reliable floor recognition are critical for mobile robot localization and navigation within complex multi-storey environments. In this paper, we present a robust, low-cost vertical estimation framework leveraging differential barometric sensing integrated within a fully ROS-compliant software package. Our system simultaneously publishes real-time altitude data from both a stationary base station and a mobile sensor, enabling precise and drift-free vertical localization. Empirical evaluations conducted in challenging scenarios -- such as fully enclosed stairwells and elevators, demonstrate that our proposed barometric pipeline achieves sub-meter vertical accuracy (RMSE: 0.29 m) and perfect (100%) floor-level identification. In contrast, our results confirm that standalone height estimates, obtained solely from visual- or LiDAR-based SLAM odometry, are insufficient for reliable vertical localization. The proposed ROS-compatible barometric module thus provides a practical and cost-effective solution for robust vertical awareness in real-world robotic deployments. The implementation of our method is released as open source at https://github.com/witsir/differential-barometric.

</details>


### [313] [CycleVLA: Proactive Self-Correcting Vision-Language-Action Models via Subtask Backtracking and Minimum Bayes Risk Decoding](https://arxiv.org/abs/2601.02295)
*Chenyang Ma,Guangyu Yang,Kai Lu,Shitong Xu,Bill Byrne,Niki Trigoni,Andrew Markham*

Main category: cs.RO

TL;DR: CycleVLA是一种主动自我纠正系统，通过预测失败和MBR解码策略提升VLA模型的执行效率。


<details>
  <summary>Details</summary>
Motivation: 当前机器人失败检测和纠正方法多为事后处理，CycleVLA旨在通过主动预测和纠正失败，提升VLA模型的执行效率和鲁棒性。

Method: CycleVLA结合了进度感知的VLA、VLM-based失败预测器和MBR解码策略，实现了在任务执行中的主动自我纠正。

Result: 实验表明，CycleVLA显著提升了VLA模型的性能，MBR解码策略在零样本测试中表现优异。

Conclusion: CycleVLA通过整合进度感知的VLA、基于VLM的失败预测器和MBR解码策略，显著提升了VLA模型的性能，尤其是在失败预测和主动自我纠正方面。

Abstract: Current work on robot failure detection and correction typically operate in a post hoc manner, analyzing errors and applying corrections only after failures occur. This work introduces CycleVLA, a system that equips Vision-Language-Action models (VLAs) with proactive self-correction, the capability to anticipate incipient failures and recover before they fully manifest during execution. CycleVLA achieves this by integrating a progress-aware VLA that flags critical subtask transition points where failures most frequently occur, a VLM-based failure predictor and planner that triggers subtask backtracking upon predicted failure, and a test-time scaling strategy based on Minimum Bayes Risk (MBR) decoding to improve retry success after backtracking. Extensive experiments show that CycleVLA improves performance for both well-trained and under-trained VLAs, and that MBR serves as an effective zero-shot test-time scaling strategy for VLAs. Project Page: https://dannymcy.github.io/cyclevla/

</details>
