<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 134]
- [cs.DC](#cs.DC) [Total: 9]
- [cs.NI](#cs.NI) [Total: 4]
- [cs.OS](#cs.OS) [Total: 2]
- [cs.DS](#cs.DS) [Total: 7]
- [cs.RO](#cs.RO) [Total: 33]
- [cs.AI](#cs.AI) [Total: 87]
- [cs.SE](#cs.SE) [Total: 22]
- [cs.GR](#cs.GR) [Total: 4]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [HyperTopo-Adapters: Geometry- and Topology-Aware Segmentation of Leaf Lesions on Frozen Encoders](https://arxiv.org/abs/2601.06067)
*Chimdi Walter Ndubuisi,Toni Kazic*

Main category: cs.CV

TL;DR: 本文提出HyperTopo-Adapters方法，通过双曲+欧几里得+球形乘积流形嵌入特征，结合拓扑先验和持久同调距离，显著提升了叶片病变分割的边界和拓扑指标。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决叶片病变分割中拓扑敏感性不足的问题，即标准像素级损失在欧几里得潜在空间中无法有效惩罚小规模的合并、分裂或虚假孔洞，而这些特征可能具有重要的生物学意义。

Method: 本文采用HyperTopo-Adapters方法，结合双曲对比项和拓扑先验的预热策略，通过持久同调（PH）距离进行评估和选择，并引入可微分的替代目标函数（软欧拉特征匹配和总变分正则化）以稳定训练。

Result: 在Kaggle叶片病变数据集（N=2,940）上的实验表明，该方法在边界和拓扑指标上取得了显著提升（Delta beta_1孔洞误差减少了9%），同时Dice/IoU保持竞争力。

Conclusion: 本文提出了一种轻量级的HyperTopo-Adapters方法，通过在冻结的视觉编码器上训练，将特征嵌入到双曲+欧几里得+球形（H+E+S）乘积流形上，以促进层次分离、局部线性细节和全局闭合。实验结果表明，该方法在边界和拓扑指标上取得了显著提升，同时保持了Dice/IoU的竞争力。

Abstract: Leaf-lesion segmentation is topology-sensitive: small merges, splits, or false holes can be biologically meaningful descriptors of biochemical pathways, yet they are weakly penalized by standard pixel-wise losses in Euclidean latents. I explore HyperTopo-Adapters, a lightweight, parameter-efficient head trained on top of a frozen vision encoder, which embeds features on a product manifold -- hyperbolic + Euclidean + spherical (H + E + S) -- to encourage hierarchical separation (H), local linear detail (E), and global closure (S). A topology prior complements Dice/BCE in two forms: (i) persistent-homology (PH) distance for evaluation and selection, and (ii) a differentiable surrogate that combines a soft Euler-characteristic match with total variation regularization for stable training. I introduce warm-ups for both the hyperbolic contrastive term and the topology prior, per-sample evaluation of structure-aware metrics (Boundary-F1, Betti errors, PD distance), and a min-PD within top-K Dice rule for checkpoint selection. On a Kaggle leaf-lesion dataset (N=2,940), early results show consistent gains in boundary and topology metrics (reducing Delta beta_1 hole error by 9%) while Dice/IoU remain competitive. The study is diagnostic by design: I report controlled ablations (curvature learning, latent dimensions, contrastive temperature, surrogate settings), and ongoing tests varying encoder strength (ResNet-50, DeepLabV3, DINOv2/v3), input resolution, PH weight, and partial unfreezing of late blocks. The contribution is an open, reproducible train/eval suite (available at https://github.com/ChimdiWalter/HyperTopo-Adapters) that isolates geometric/topological priors and surfaces failure modes to guide stronger, topology-preserving architectures.

</details>


### [2] [OptFormer: Optical Flow-Guided Attention and Phase Space Reconstruction for SST Forecasting](https://arxiv.org/abs/2601.06078)
*Yin Wang,Chunlin Gong,Zhuozhen Xu,Lehan Zhang,Xiang Wu*

Main category: cs.CV

TL;DR: OptFormer是一种新型编码器-解码器模型，结合相空间重建和光流引导的注意力机制，显著提升海表温度预测性能。


<details>
  <summary>Details</summary>
Motivation: 海表温度（SST）预测在气候建模和灾害预报中至关重要，但由于其非线性时空动态和长预测周期，仍具挑战性。

Method: 提出OptFormer模型，整合相空间重建与光流引导的运动感知注意力机制，利用帧间运动线索突出空间场的相对变化，以更有效地捕捉动态区域和长程时间依赖性。

Result: 在NOAA SST数据集上的实验表明，OptFormer在1:1训练与预测设置下表现优异，显著超越现有基线模型。

Conclusion: OptFormer通过结合相空间重建和光流引导的运动感知注意力机制，显著提升了海表温度（SST）预测的准确性和鲁棒性，为气候建模和灾害预报提供了更有效的工具。

Abstract: Sea Surface Temperature (SST) prediction plays a vital role in climate modeling and disaster forecasting. However, it remains challenging due to its nonlinear spatiotemporal dynamics and extended prediction horizons. To address this, we propose OptFormer, a novel encoder-decoder model that integrates phase-space reconstruction with a motion-aware attention mechanism guided by optical flow. Unlike conventional attention, our approach leverages inter-frame motion cues to highlight relative changes in the spatial field, allowing the model to focus on dynamic regions and capture long-range temporal dependencies more effectively. Experiments on NOAA SST datasets across multiple spatial scales demonstrate that OptFormer achieves superior performance under a 1:1 training-to-prediction setting, significantly outperforming existing baselines in accuracy and robustness.

</details>


### [3] [Semantic Event Graphs for Long-Form Video Question Answering](https://arxiv.org/abs/2601.06097)
*Aradhya Dixit,Tianxi Liang*

Main category: cs.CV

TL;DR: SEG通过符号化时间图作为视频问答的轻量级接口，显著降低token使用量并保持高准确性。


<details>
  <summary>Details</summary>
Motivation: 解决现代视觉语言模型在小时级视频问答中的推理挑战，避免超出实际token和计算预算。

Method: 提出语义事件图（SEG）作为视频与语言之间的符号接口，通过YOLOv11检测和跟踪对象，将接近模式转换为START/END事件，并组织成时间场景图（TSG）。推理时，查询感知剪枝模块识别锚点实体和词汇相关事件，仅返回小子图并传递给Gemini 2.5 Flash生成答案。

Result: 在五个YouTube视频（每个300-500次交互）和120个自动生成长视野问题上，SEG仅使用3.47k token达到65.0%准确率，接近完整日志基线（62.5%，40.39k token），同时减少91.4%的token使用量。

Conclusion: SEG作为一种轻量级符号接口，能够有效替代原始帧，显著减少token使用量并保持长视频问答的准确性。

Abstract: Long-form video question answering remains challenging for modern vision-language models, which struggle to reason over hour-scale footage without exceeding practical token and compute budgets. Existing systems typically downsample frames or feed dense visual embeddings to large-context language models, trading off temporal coverage against cost. We propose Semantic Event Graphs (SEG), a lightweight symbolic interface between video and language that replaces raw frames with compact temporal interaction logs. Our pipeline detects and tracks objects with YOLOv11, converts proximity patterns into START/END human-object events, and organizes them into a Temporal Scene Graph (TSG). At inference time, a query-aware pruning module identifies anchor entities and lexically relevant events, returning only a small subgraph which is verbalized and passed to Gemini 2.5 Flash for answer generation. On five YouTube videos (300-500 interactions each) and 120 automatically generated long-horizon questions, SEG achieves 65.0% accuracy using only 3.47k tokens per query, closely matching a full-log baseline (62.5% at 40.39k tokens) while reducing token usage by 91.4%. A short-context baseline restricted to the last 30 seconds collapses to 2.5% accuracy, underscoring the need for explicit temporal memory. These results show that symbolic temporal graphs can serve as an effective, plug-and-play memory layer for off-the-shelf vision-language models, preserving long-range reasoning ability while making long-form video question answering substantially more token- and cost-efficient. Code, logs, and event-extraction tools will be released for reproducibility.

</details>


### [4] [COVR:Collaborative Optimization of VLMs and RL Agent for Visual-Based Control](https://arxiv.org/abs/2601.06122)
*Canming Xia,Peixi Peng,Guang Tan,Zhan Su,Haoran Xu,Zhenxian Liu,Luntong Li*

Main category: cs.CV

TL;DR: COVR是一个协同优化框架，通过RL数据增强VLM的语义推理能力，并用增强后的VLM指导RL策略学习，显著提升了视觉强化学习的效率。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉强化学习方法样本效率低下，且现有工作主要关注从VLM到RL的知识蒸馏，忽略了RL生成的交互数据对VLM的增强潜力。

Method: COVR框架包含两个关键模块：探索驱动的动态过滤器模块（用于保留有价值的探索样本）和回报感知的自适应损失权重模块（用于量化采样动作的不一致性）。此外，还设计了渐进式微调策略以减少资源消耗。

Result: COVR在多种挑战性视觉控制任务中实现了强大的性能。

Conclusion: COVR框架通过协同优化视觉语言模型（VLM）和强化学习（RL）策略，显著提升了视觉强化学习的样本效率，并在多种复杂视觉控制任务中表现出色。

Abstract: Visual reinforcement learning (RL) suffers from poor sample efficiency due to high-dimensional observations in complex tasks. While existing works have shown that vision-language models (VLMs) can assist RL, they often focus on knowledge distillation from the VLM to RL, overlooking the potential of RL-generated interaction data to enhance the VLM. To address this, we propose COVR, a collaborative optimization framework that enables the mutual enhancement of the VLM and RL policies. Specifically, COVR fine-tunes the VLM with RL-generated data to enhance the semantic reasoning ability consistent with the target task, and uses the enhanced VLM to further guide policy learning via action priors. To improve fine-tuning efficiency, we introduce two key modules: (1) an Exploration-Driven Dynamic Filter module that preserves valuable exploration samples using adaptive thresholds based on the degree of exploration, and (2) a Return-Aware Adaptive Loss Weight module that improves the stability of training by quantifying the inconsistency of sampling actions via return signals of RL. We further design a progressive fine-tuning strategy to reduce resource consumption. Extensive experiments show that COVR achieves strong performance across various challenging visual control tasks.

</details>


### [5] [A survey of facial recognition techniques](https://arxiv.org/abs/2601.06239)
*Aya Kaysan Bahjat*

Main category: cs.CV

TL;DR: 该论文综述了人脸识别领域的主要挑战和技术，分析了多种方法及数据库，旨在为未来研究提供全面参考。


<details>
  <summary>Details</summary>
Motivation: 随着多媒体内容的快速增长，人脸识别成为重要研究领域，但光照、年龄、姿态变化等挑战仍待解决。本文旨在综述现有方法以推动技术进步。

Method: 论文采用了文献综述的方法，分析了多种人脸识别技术，包括隐马尔可夫模型、主成分分析、弹性簇图匹配等，并评估了多个公开人脸数据库。

Result: 论文总结了多种人脸识别技术的优缺点，并通过实验验证了这些方法在不同数据库上的表现，为实际应用提供了参考。

Conclusion: 该论文通过综述人脸识别领域的主要挑战和方法，提供了对现有技术的全面回顾，并展示了实验结果，旨在为未来研究提供参考。

Abstract: As multimedia content is quickly growing, the field of facial recognition has become one of the major research fields, particularly in the recent years. The most problematic area to researchers in image processing and computer vision is the human face which is a complex object with myriads of distinctive features that can be used to identify the face. The survey of this survey is particularly focused on most challenging facial characteristics, including differences in the light, ageing, variation in poses, partial occlusion, and facial expression and presents methodological solutions. The factors, therefore, are inevitable in the creation of effective facial recognition mechanisms used on facial images. This paper reviews the most sophisticated methods of facial detection which are Hidden Markov Models, Principal Component Analysis (PCA), Elastic Cluster Plot Matching, Support Vector Machine (SVM), Gabor Waves, Artificial Neural Networks (ANN), Eigenfaces, Independent Component Analysis (ICA), and 3D Morphable Model. Alongside the works mentioned above, we have also analyzed the images of a number of facial databases, namely JAFEE, FEI, Yale, LFW, AT&T (then called ORL), and AR (created by Martinez and Benavente), to analyze the results. However, this survey is aimed at giving a thorough literature review of face recognition, and its applications, and some experimental results are provided at the end after a detailed discussion.

</details>


### [6] [Low-Back Pain Physical Rehabilitation by Movement Analysis in Clinical Trial](https://arxiv.org/abs/2601.06138)
*Sao Mai Nguyen*

Main category: cs.CV

TL;DR: Keraal数据集为康复智能辅导系统提供临床运动数据，解决运动评估等四大挑战。


<details>
  <summary>Details</summary>
Motivation: 开发智能辅导系统以支持物理康复，需要一个包含临床环境下康复动作的数据集，以促进康复程序的评估和改进。

Method: 通过收集临床患者进行低背痛康复锻炼的数据，并基于最先进的人体运动分析算法进行基准测试。

Result: 提出了Keraal数据集，这是一个在临床环境中收集的数据集，旨在支持康复领域的智能辅导系统开发。

Conclusion: Keraal数据集为智能辅导系统（ITS）在康复领域的应用提供了宝贵资源，支持运动评估、错误识别、空间和时间定位等关键挑战的解决。

Abstract: To allow the development and assessment of physical rehabilitation by an intelligent tutoring system, we propose a medical dataset of clinical patients carrying out low back-pain rehabilitation exercises and benchmark on state of the art human movement analysis algorithms. This dataset is valuable because it includes rehabilitation motions in a clinical setting with patients in their rehabilitation program. This paper introduces the Keraal dataset, a clinically collected dataset to enable intelligent tutoring systems (ITS) for rehabilitation. It addresses four challenges in exercise monitoring: motion assessment, error recognition, spatial localization, temporal localization

</details>


### [7] [SIRR-LMM: Single-image Reflection Removal via Large Multimodal Model](https://arxiv.org/abs/2601.07209)
*Yu Guo,Zhiqiang Lao,Xiyun Song,Yubin Zhou,Heather Yu*

Main category: cs.CV

TL;DR: 论文提出了一种基于合成数据集和大型多模态模型（LMM）微调的方法，显著提升了单图像反射去除的性能。


<details>
  <summary>Details</summary>
Motivation: 玻璃表面的反射和透射光交互复杂，现有数据集在合成数据的物理真实性和真实捕获的规模上存在不足。

Method: 论文提出了一种合成数据集生成框架，通过路径追踪3D玻璃模型在真实背景图像上，生成物理上准确的反射场景。同时，采用联合标注和任务特定的LoRA微调技术，而非全参数训练，来优化大型多模态模型（LMM）。

Result: 该方法在反射去除和分离性能上优于现有最先进方法。

Conclusion: 该论文通过引入一个合成数据集生成框架，并利用大型多模态模型（LMM）进行微调，显著提升了单图像反射去除（SIRR）的性能，优于现有方法。

Abstract: Glass surfaces create complex interactions of reflected and transmitted light, making single-image reflection removal (SIRR) challenging. Existing datasets suffer from limited physical realism in synthetic data or insufficient scale in real captures. We introduce a synthetic dataset generation framework that path-traces 3D glass models over real background imagery to create physically accurate reflection scenarios with varied glass properties, camera settings, and post-processing effects. To leverage the capabilities of Large Multimodal Model (LMM), we concatenate the image layers into a single composite input, apply joint captioning, and fine-tune the model using task-specific LoRA rather than full-parameter training. This enables our approach to achieve improved reflection removal and separation performance compared to state-of-the-art methods.

</details>


### [8] [Forget-It-All: Multi-Concept Machine Unlearning via Concept-Aware Neuron Masking](https://arxiv.org/abs/2601.06163)
*Kaiyuan Deng,Bo Hui,Gen Li,Jie Ji,Minghai Qin,Geng Yuan,Xiaolong Ma*

Main category: cs.CV

TL;DR: FIA框架通过模型稀疏性和对比概念显著性，实现了高效的多概念遗忘，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在多概念遗忘中的局限性，如遗忘效果差、生成质量下降和对超参数敏感等问题。

Method: FIA利用对比概念显著性量化权重连接对目标概念的贡献，结合时空信息识别概念敏感神经元，并通过掩码融合实现多概念遗忘。

Result: FIA在三个不同的遗忘任务中表现出色，实现了更可靠的多概念遗忘，同时保持了语义保真度和图像质量。

Conclusion: FIA框架通过模型稀疏性和对比概念显著性，实现了高效的多概念遗忘，同时保持了生成质量和语义保真度。

Abstract: The widespread adoption of text-to-image (T2I) diffusion models has raised concerns about their potential to generate copyrighted, inappropriate, or sensitive imagery learned from massive training corpora. As a practical solution, machine unlearning aims to selectively erase unwanted concepts from a pre-trained model without retraining from scratch. While most existing methods are effective for single-concept unlearning, they often struggle in real-world scenarios that require removing multiple concepts, since extending them to this setting is both non-trivial and problematic, causing significant challenges in unlearning effectiveness, generation quality, and sensitivity to hyperparameters and datasets. In this paper, we take a unique perspective on multi-concept unlearning by leveraging model sparsity and propose the Forget It All (FIA) framework. FIA first introduces Contrastive Concept Saliency to quantify each weight connection's contribution to a target concept. It then identifies Concept-Sensitive Neurons by combining temporal and spatial information, ensuring that only neurons consistently responsive to the target concept are selected. Finally, FIA constructs masks from the identified neurons and fuses them into a unified multi-concept mask, where Concept-Agnostic Neurons that broadly support general content generation are preserved while concept-specific neurons are pruned to remove the targets. FIA is training-free and requires only minimal hyperparameter tuning for new tasks, thereby promoting a plug-and-play paradigm. Extensive experiments across three distinct unlearning tasks demonstrate that FIA achieves more reliable multi-concept unlearning, improving forgetting effectiveness while maintaining semantic fidelity and image quality.

</details>


### [9] [What Users Leave Unsaid: Under-Specified Queries Limit Vision-Language Models](https://arxiv.org/abs/2601.06165)
*Dasol Choi,Guijin Son,Hanwool Lee,Minhyuk Kim,Hyunwoo Ko,Teabin Lim,Ahn Eungyeol,Jungwhan Kim,Seunghyeok Hong,Youngsook Song*

Main category: cs.CV

TL;DR: 研究发现VLMs在真实非正式查询中表现不佳，明确化查询可显著提升性能，尤其是小型模型。当前检索无法弥补用户未明确表达的信息。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言基准多基于结构良好的明确问题，而真实用户查询往往是非正式且不明确的，依赖图像传达上下文。

Method: 引入了HAERAE-Vision基准，包含653个来自韩国在线社区的真实视觉问题，每个问题配有一个明确改写版本，共1,306个查询变体。评估了39个VLMs的表现。

Result: 即使是GPT-5、Gemini 2.5 Pro等最先进模型，在原始查询上的准确率也不足50%。查询明确化能带来8到22个百分点的提升，小型模型受益最大。即使结合网络搜索，不明确查询的表现仍不如无需搜索的明确查询。

Conclusion: 研究揭示了视觉语言模型（VLMs）在真实世界查询中的表现不佳主要源于查询的非正式性和不明确性，而非模型能力本身。通过明确化查询可以显著提升模型性能，尤其是在小型模型上。

Abstract: Current vision-language benchmarks predominantly feature well-structured questions with clear, explicit prompts. However, real user queries are often informal and underspecified. Users naturally leave much unsaid, relying on images to convey context. We introduce HAERAE-Vision, a benchmark of 653 real-world visual questions from Korean online communities (0.76% survival from 86K candidates), each paired with an explicit rewrite, yielding 1,306 query variants in total. Evaluating 39 VLMs, we find that even state-of-the-art models (GPT-5, Gemini 2.5 Pro) achieve under 50% on the original queries. Crucially, query explicitation alone yields 8 to 22 point improvements, with smaller models benefiting most. We further show that even with web search, under-specified queries underperform explicit queries without search, revealing that current retrieval cannot compensate for what users leave unsaid. Our findings demonstrate that a substantial portion of VLM difficulty stem from natural query under-specification instead of model capability, highlighting a critical gap between benchmark evaluation and real-world deployment.

</details>


### [10] [B-FIRE: Binning-Free Diffusion Implicit Neural Representation for Hyper-Accelerated Motion-Resolved MRI](https://arxiv.org/abs/2601.06166)
*Di Xu,Hengjie Liu,Yang Yang,Mary Feng,Jin Ning,Xin Miao,Jessica E. Scholey,Alexandra E. Hotca-cho,William C. Chen,Michael Ohliger,Martina Descovich,Huiming Dong,Wensha Yang,Ke Sheng*

Main category: cs.CV

TL;DR: B-FIRE是一种无需分箱的扩散隐式神经表示框架，用于超加速MR重建，能准确反映瞬时3D腹部解剖结构，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有4DMRI在平均呼吸相位上可接受，但会模糊和误表示瞬时动态信息，需新方法重建极端欠采样的非笛卡尔k空间数据。

Method: 采用CNN-INR编码器-解码器主干网络，结合扩散优化和综合损失函数（包括图像域保真度和频率感知约束），利用运动分箱图像对作为训练参考，在无分箱的欠采样数据上进行推理。

Result: 在T1加权StarVIBE肝脏MRI数据上，B-FIRE在重建保真度、运动轨迹一致性和推理延迟方面优于直接NuFFT、GRASP-CS和展开CNN方法。

Conclusion: B-FIRE框架通过创新的CNN-INR编码器-解码器结构和扩散优化，成功实现了超加速MR重建，能够准确反映瞬时3D腹部解剖结构，优于现有方法。

Abstract: Accelerated dynamic volumetric magnetic resonance imaging (4DMRI) is essential for applications relying on motion resolution. Existing 4DMRI produces acceptable artifacts of averaged breathing phases, which can blur and misrepresent instantaneous dynamic information. Recovery of such information requires a new paradigm to reconstruct extremely undersampled non-Cartesian k-space data. We propose B-FIRE, a binning-free diffusion implicit neural representation framework for hyper-accelerated MR reconstruction capable of reflecting instantaneous 3D abdominal anatomy. B-FIRE employs a CNN-INR encoder-decoder backbone optimized using diffusion with a comprehensive loss that enforces image-domain fidelity and frequency-aware constraints. Motion binned image pairs were used as training references, while inference was performed on binning-free undersampled data. Experiments were conducted on a T1-weighted StarVIBE liver MRI cohort, with accelerations ranging from 8 spokes per frame (RV8) to RV1. B-FIRE was compared against direct NuFFT, GRASP-CS, and an unrolled CNN method. Reconstruction fidelity, motion trajectory consistency, and inference latency were evaluated.

</details>


### [11] [Analyzing the Structure of Handwritten Digits: A Comparative Study of PCA, Factor Analysis, and UMAP](https://arxiv.org/abs/2601.06168)
*Jyotiraditya Gupta*

Main category: cs.CV

TL;DR: 本文通过PCA、FA和UMAP三种方法分析MNIST手写数字的高维结构，揭示了其低维流形特性及不同方法的互补视角。


<details>
  <summary>Details</summary>
Motivation: 研究手写数字在MNIST数据集中的潜在组织，而非分类准确性。

Method: 使用了三种互补的降维技术：主成分分析（PCA）、因子分析（FA）和均匀流形逼近与投影（UMAP）。

Result: PCA揭示了主要的全局方差方向，FA将数字分解为可解释的潜在手写基元，UMAP揭示了反映数字类别间平滑风格转换的非线性流形。

Conclusion: 手写数字存在于一个结构化的低维流形中，不同的统计框架揭示了这一结构的互补方面。

Abstract: Handwritten digit images lie in a high-dimensional pixel space but exhibit strong geometric and statistical structure. This paper investigates the latent organization of handwritten digits in the MNIST dataset using three complementary dimensionality reduction techniques: Principal Component Analysis (PCA), Factor Analysis (FA), and Uniform Manifold Approximation and Projection (UMAP). Rather than focusing on classification accuracy, we study how each method characterizes intrinsic dimensionality, shared variation, and nonlinear geometry. PCA reveals dominant global variance directions and enables high-fidelity reconstructions using a small number of components. FA decomposes digits into interpretable latent handwriting primitives corresponding to strokes, loops, and symmetry. UMAP uncovers nonlinear manifolds that reflect smooth stylistic transitions between digit classes. Together, these results demonstrate that handwritten digits occupy a structured low-dimensional manifold and that different statistical frameworks expose complementary aspects of this structure.

</details>


### [12] [Think Bright, Diffuse Nice: Enhancing T2I-ICL via Inductive-Bias Hint Instruction and Query Contrastive Decoding](https://arxiv.org/abs/2601.06169)
*Zhiyong Ma,Zhenpeng Li,Yuanjie Shi,Zhengping Li,Jiahao Chen,Qingyuan Chuai*

Main category: cs.CV

TL;DR: TBDN是一个无需训练的框架，通过HI和QCD机制解决了T2I-ICL中的合规性失败和先验主导幻觉问题，实现了高效可靠的图像合成。


<details>
  <summary>Details</summary>
Motivation: 现有的Text-to-Image In-Context Learning方法存在合规性失败和先验主导幻觉问题，这些问题相互强化形成恶性循环，降低了生成质量。现有方法依赖定制化训练，限制了灵活性并增加了部署成本。

Method: TBDN是一个无需训练的框架，包含Hint Instruction（HI）和Query Contrastive Decoding（QCD）两种机制。HI通过轻量级提示工程注入任务感知的归纳偏差，QCD通过对比完整输入和查询省略的分布调整解码分布。

Result: TBDN在CoBSAT和Text-to-Image Fast Mini-ImageNet上实现了最先进的性能，并在Dreambench++上保持了概念保留和提示跟随的良好表现。

Conclusion: TBDN通过整合Hint Instruction（HI）和Query Contrastive Decoding（QCD）两种闭环机制，有效解决了Text-to-Image In-Context Learning（T2I-ICL）中的合规性失败和先验主导幻觉问题，提供了一个简单高效的训练免费框架。

Abstract: Text-to-Image In-Context Learning (T2I-ICL) enables customized image synthesis via interleaved text-image examples but faces two mutually reinforcing bottlenecks, compliance failure and prior-dominated hallucination, that form a vicious cycle degrading generation quality. Existing methods rely on tailored training, which limits flexibility and raises deployment costs. To address these challenges effectively, we propose TBDN, a training-free framework integrating two complementary closed-loop mechanisms: Hint Instruction (HI) and Query Contrastive Decoding (QCD). HI injects task-aware inductive bias via lightweight prompt engineering to anchor models on contextual mapping rules, thereby mitigating compliance failure. QCD adjusts the decoding distributions of language models by contrasting full-input and query-omitted distributions, suppressing prior-dominated hallucination. TBDN achieves State-of-the-Art performance on CoBSAT and Text-to-Image Fast Mini-ImageNet, with robust generalization across model backbones, prompt designs, and hyperparameters. It also maintains promising performance in concept preservation and prompt following on Dreambench++. By breaking the two bottlenecks, TBDN establishes a simple yet effective framework for efficient and reliable T2I-ICL.

</details>


### [13] [TIR-Flow: Active Video Search and Reasoning with Frozen VLMs](https://arxiv.org/abs/2601.06176)
*Hongbo Jin,Siyi Xie,Jiayu Ding,Kuanwei Lin,Ge Li*

Main category: cs.CV

TL;DR: TIR-Flow通过主动搜索和推理框架提升视频语言模型推理能力，无需额外数据或参数更新，性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视频语言模型在推理能力上存在瓶颈，主要依赖数据工程范式，缺乏动态视觉探索的内在智能激活。

Method: TIR-Flow框架包含三个协同模块：HDD（分解复杂查询为可验证子任务）、HAP（主动引导视觉注意力收集高分辨率证据）和EBA（维护持久工作空间以积累和更新发现的线索进行逻辑推理）。

Result: 在七个基准测试中，TIR-Flow平均性能提升5.9%，在Egoschema上提升达10.5%，显著优于现有基线。

Conclusion: TIR-Flow框架通过主动视频搜索和推理，显著提升了大型视频语言模型的推理能力，无需额外数据或参数更新，证明了赋予冻结VLMs类似System-2的主动感知能力是解决长视频推理问题的可扩展路径。

Abstract: While Large Video-Language Models (Video-LLMs) have achieved remarkable progress in perception, their reasoning capabilities remain a bottleneck. Existing solutions typically resort to a heavy "data engineering" paradigm-synthesizing large-scale Chain-of-Thought (CoT) datasets followed by Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL). This pipeline primarily optimizes probability sampling efficiency and aligns output distributions, but fails to activate the intrinsic intelligence required for dynamic visual exploration. In this work, we propose TIR-Flow, a novel framework that shifts the paradigm from passive processing to active video searching and reasoning without additional data or parameter updating. Concretely, our framework operates through three synergistic modules: HDD decomposes complex queries into a set of verifiable sub-tasks; HAP actively directs visual attention to gather high-resolution evidence for hypothesis validation; EBA maintains a persistent workspace to accumulate and update the discovered clues for logical reasoning. Extensive experiments on seven benchmarks demonstrate that TIR-Flow significantly outperforms recent strong baselines, delivering an average performance boost of 5.9%, with gains reaching 10.5% on Egoschema. Our analysis confirms that empowering frozen VLMs with System-2-like active perception is a scalable path toward solving long-horizon video reasoning.

</details>


### [14] [A Unified Attention U-Net Framework for Cross-Modality Tumor Segmentation in MRI and CT](https://arxiv.org/abs/2601.06187)
*Nishan Rai,Pushpa R. Dahal*

Main category: cs.CV

TL;DR: 该研究通过统一的Attention U-Net架构在MRI和CT数据集上的联合训练，展示了单一模型在跨模态肿瘤分割中的泛化能力，为未来研究提供了稳健基线。


<details>
  <summary>Details</summary>
Motivation: 探索单一模型在多样成像模态和解剖部位上的泛化能力，为跨模态肿瘤分割研究提供新思路。

Method: 研究提出了一种包含模态协调预处理、注意力门跳跃连接和模态感知Focal Tversky损失函数的流程，并在不依赖模态特定编码器或域适应的情况下，评估了同时在MRI和CT肿瘤数据集上训练的单一Attention U-Net。

Result: 统一模型在Dice系数、IoU和AUC等指标上均表现出竞争力，证明了其在MRI和CT数据集上的有效性。

Conclusion: 该研究通过统一的Attention U-Net架构在MRI和CT数据集上的联合训练，展示了单一模型在多样成像模态和解剖部位上的泛化能力，为跨模态肿瘤分割研究建立了稳健且可复现的基线。

Abstract: This study presents a unified Attention U-Net architecture trained jointly on MRI (BraTS 2021) and CT (LIDC-IDRI) datasets to investigate the generalizability of a single model across diverse imaging modalities and anatomical sites. Our proposed pipeline incorporates modality-harmonized preprocessing, attention-gated skip connections, and a modality-aware Focal Tversky loss function. To the best of our knowledge, this study is among the first to evaluate a single Attention U-Net trained simultaneously on separate MRI (BraTS) and CT (LIDC-IDRI) tumor datasets, without relying on modality-specific encoders or domain adaptation. The unified model demonstrates competitive performance in terms of Dice coefficient, IoU, and AUC on both domains, thereby establishing a robust and reproducible baseline for future research in cross-modality tumor segmentation.

</details>


### [15] [How Does India Cook Biryani?](https://arxiv.org/abs/2601.06198)
*Shubham Goel,Farzana S,C V Rishi,Aditya Arun,C V Jawahar*

Main category: cs.CV

TL;DR: 该研究构建了首个大规模印度香饭制作视频数据集，开发了多阶段框架和视频比较流程，为视觉语言模型在结构化多模态推理任务上的评估提供了新平台。


<details>
  <summary>Details</summary>
Motivation: 随着在线烹饪视频的普及，系统性地研究印度香饭的地区多样性具有前所未有的潜力，但现有的视频理解方法无法捕捉程序性烹饪视频中的细粒度、多模态和文化差异。

Method: 研究提出了一个多阶段框架，利用最新的视觉语言模型（VLMs）将视频分割为细粒度的程序单元，并与音频转录和标准食谱文本对齐。基于这些对齐表示，引入了一个视频比较流程，自动识别并解释地区变体之间的程序差异。

Result: 研究构建了一个包含120个高质量YouTube视频的数据集，涵盖12种不同的地区风格，并建立了全面的问答（QA）基准，评估了多种最先进模型在零样本和微调设置下的表现。

Conclusion: 该研究通过构建大规模、精细标注的印度香饭制作视频数据集，并开发多阶段框架和视频比较流程，为视觉语言模型在结构化、多模态推理任务上的评估提供了新的测试平台，同时也为通过烹饪视频计算分析文化遗产开辟了新方向。

Abstract: Biryani, one of India's most celebrated dishes, exhibits remarkable regional diversity in its preparation, ingredients, and presentation. With the growing availability of online cooking videos, there is unprecedented potential to study such culinary variations using computational tools systematically. However, existing video understanding methods fail to capture the fine-grained, multimodal, and culturally grounded differences in procedural cooking videos. This work presents the first large-scale, curated dataset of biryani preparation videos, comprising 120 high-quality YouTube recordings across 12 distinct regional styles. We propose a multi-stage framework leveraging recent advances in vision-language models (VLMs) to segment videos into fine-grained procedural units and align them with audio transcripts and canonical recipe text. Building on these aligned representations, we introduce a video comparison pipeline that automatically identifies and explains procedural differences between regional variants. We construct a comprehensive question-answer (QA) benchmark spanning multiple reasoning levels to evaluate procedural understanding in VLMs. Our approach employs multiple VLMs in complementary roles, incorporates human-in-the-loop verification for high-precision tasks, and benchmarks several state-of-the-art models under zero-shot and fine-tuned settings. The resulting dataset, comparison methodology, and QA benchmark provide a new testbed for evaluating VLMs on structured, multimodal reasoning tasks and open new directions for computational analysis of cultural heritage through cooking videos. We release all data, code, and the project website at https://farzanashaju.github.io/how-does-india-cook-biryani/.

</details>


### [16] [QwenStyle: Content-Preserving Style Transfer with Qwen-Image-Edit](https://arxiv.org/abs/2601.06202)
*Shiwen Zhang,Haibin Huang,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: 提出首个基于Qwen-Image-Edit的内容保留风格迁移模型QwenStyle，通过课程持续学习框架训练，实现了在风格相似性、内容一致性和美学质量上的最优表现。


<details>
  <summary>Details</summary>
Motivation: 由于DiTs内部内容和风格特征的纠缠，内容保留的风格迁移仍然具有挑战性。

Method: 提出了课程持续学习框架，使用混合的干净和嘈杂三元组训练QwenStyle，使其能够泛化到未见过的风格而不损失精确的内容保留能力。

Result: QwenStyle V1在风格相似性、内容一致性和美学质量三个核心指标上表现优异。

Conclusion: QwenStyle V1在风格相似性、内容一致性和美学质量三个核心指标上实现了最先进的性能。

Abstract: Content-Preserving Style transfer, given content and style references, remains challenging for Diffusion Transformers (DiTs) due to its internal entangled content and style features. In this technical report, we propose the first content-preserving style transfer model trained on Qwen-Image-Edit, which activates Qwen-Image-Edit's strong content preservation and style customization capability. We collected and filtered high quality data of limited specific styles and synthesized triplets with thousands categories of style images in-the-wild. We introduce the Curriculum Continual Learning framework to train QwenStyle with such mixture of clean and noisy triplets, which enables QwenStyle to generalize to unseen styles without degradation of the precise content preservation capability. Our QwenStyle V1 achieves state-of-the-art performance in three core metrics: style similarity, content consistency, and aesthetic quality.

</details>


### [17] [Cascading multi-agent anomaly detection in surveillance systems via vision-language models and embedding-based classification](https://arxiv.org/abs/2601.06204)
*Tayyab Rehman,Giovanni De Gasperis,Aly Shmahell*

Main category: cs.CV

TL;DR: 该论文提出了一种级联多智能体框架，结合重建门控过滤、对象级评估和选择性推理智能体，实现了高效、可解释且节能的智能视觉监控，显著降低了延迟并保持了高保真度。


<details>
  <summary>Details</summary>
Motivation: 智能异常检测需要兼顾实时性能和语义可解释性，而传统方法仅解决了这一挑战的片段。重建模型缺乏上下文推理，对象检测器速度虽快但语义有限，而大型视觉语言系统虽然可解释但计算成本过高。

Method: 提出了一种级联多智能体框架，将重建门控过滤、对象级评估和选择性调用的高级推理智能体统一为一个连贯且可解释的架构。系统采用自适应升级阈值和发布-订阅通信骨干，实现异步协调和跨异构硬件的可扩展部署。

Result: 在大规模监控数据上的广泛评估表明，所提出的级联方法相比直接视觉语言推理减少了三倍的延迟，同时保持了高感知保真度（PSNR = 38.3 dB, SSIM = 0.965）和一致的语义标注。

Conclusion: 该框架通过结合早期退出效率、自适应多智能体推理和可解释的异常归因，超越了传统的检测流程，为可扩展的智能视觉监控建立了可重复且节能的基础。

Abstract: Intelligent anomaly detection in dynamic visual environments requires reconciling real-time performance with semantic interpretability. Conventional approaches address only fragments of this challenge. Reconstruction-based models capture low-level deviations without contextual reasoning, object detectors provide speed but limited semantics, and large vision-language systems deliver interpretability at prohibitive computational cost. This work introduces a cascading multi-agent framework that unifies these complementary paradigms into a coherent and interpretable architecture. Early modules perform reconstruction-gated filtering and object-level assessment, while higher-level reasoning agents are selectively invoked to interpret semantically ambiguous events. The system employs adaptive escalation thresholds and a publish-subscribe communication backbone, enabling asynchronous coordination and scalable deployment across heterogeneous hardware. Extensive evaluation on large-scale monitoring data demonstrates that the proposed cascade achieves a threefold reduction in latency compared to direct vision-language inference, while maintaining high perceptual fidelity (PSNR = 38.3 dB, SSIM = 0.965) and consistent semantic labeling. The framework advances beyond conventional detection pipelines by combining early-exit efficiency, adaptive multi-agent reasoning, and explainable anomaly attribution, establishing a reproducible and energy-efficient foundation for scalable intelligent visual monitoring.

</details>


### [18] [When Imbalance Comes Twice: Active Learning under Simulated Class Imbalance and Label Shift in Binary Semantic Segmentation](https://arxiv.org/abs/2601.06209)
*Julien Combes,Alexandre Derville,Jean-François Coeurjolly*

Main category: cs.CV

TL;DR: Active learning remains effective in imbalanced datasets, though label shift reduces efficiency, as shown by a simulation study comparing random, entropy-based, and core-set selection methods.


<details>
  <summary>Details</summary>
Motivation: To understand the impact of class imbalance and label shift on active learning algorithms in machine vision and medical imaging, where data is abundant but labeling is costly.

Method: A simulation study using two open-source datasets with controlled class imbalance and label shift levels, comparing random sampling, entropy-based selection, and core-set selection.

Result: Active learning strategies (entropy-based and core-set) are efficient in imbalanced datasets, but efficiency decreases with significant label shift.

Conclusion: Active learning strategies, particularly entropy-based and core-set selections, remain effective even in highly imbalanced datasets, though efficiency loss occurs with strong label shift.

Abstract: The aim of Active Learning is to select the most informative samples from an unlabelled set of data. This is useful in cases where the amount of data is large and labelling is expensive, such as in machine vision or medical imaging. Two particularities of machine vision are first, that most of the images produced are free of defects, and second, that the amount of images produced is so big that we cannot store all acquired images. This results, on the one hand, in a strong class imbalance in defect distribution and, on the other hand, in a potential label shift caused by limited storage. To understand how these two forms of imbalance affect active learning algorithms, we propose a simulation study based on two open-source datasets. We artificially create datasets for which we control the levels of class imbalance and label shift. Three standard active learning selection strategies are compared: random sampling, entropy-based selection, and core-set selection. We demonstrate that active learning strategies, and in particular the entropy-based and core-set selections, remain interesting and efficient even for highly imbalanced datasets. We also illustrate and measure the loss of efficiency that occurs in the situation a strong label shift.

</details>


### [19] [Akasha 2: Hamiltonian State Space Duality and Visual-Language Joint Embedding Predictive Architectur](https://arxiv.org/abs/2601.06212)
*Yani Meziani*

Main category: cs.CV

TL;DR: Akasha 2通过物理启发的架构创新，实现了高效、低延迟的视频预测与视觉合成。


<details>
  <summary>Details</summary>
Motivation: 探索如何将物理启发的归纳偏置融入神经网络架构，以提升模型的时空一致性和效率。

Method: 采用Mamba-3 SSM模型，结合SMoE-HE强制潜在物理守恒定律，并通过HFM和3DGS实现视觉合成。

Result: 在视频预测（FVD: 287）、视觉合成速度（比扩散模型快4倍）和推理速度（比Transformer基线快3-18倍）方面取得了最先进的成果。

Conclusion: Akasha 2通过整合H-SSD与VL-JEPA，结合SMoE-HE和HFM等创新技术，实现了在视频预测和视觉合成领域的突破性进展，展示了物理启发式归纳偏置在神经网络架构中的显著优势。

Abstract: We present Akasha 2, a state-of-the-art multimodal architecture that integrates Hamiltonian State Space Duality (H-SSD) with Visual-Language Joint Embedding Predictive Architecture (VL-JEPA). The system leverages the Mamba-3 Selective State Space Model (SSM) augmented by a Sparse Mixture of Hamiltonian Experts (SMoE-HE) that enforces latent physical conservation laws through symplectic integration. For visual synthesis, we introduce Hamiltonian Flow Matching (HFM) and persistent 3D Gaussian Splatting (3DGS), enabling ultra-low latency (<50ms) on mobile hardware. This work establishes a new paradigm in latent world models, achieving unprecedented spatiotemporal coherence through a holographic memory architecture. Our approach demonstrates that incorporating physics-inspired inductive biases into neural architectures yields significant improvements: state-of-the-art video prediction (FVD: 287), 4x faster visual synthesis than diffusion models, and 3-18x inference speedup over transformer baselines while maintaining energy conservation over extended horizons.

</details>


### [20] [Two-step Authentication: Multi-biometric System Using Voice and Facial Recognition](https://arxiv.org/abs/2601.06218)
*Kuan Wei Chen,Ting Yi Lin,Wen Ren Yang,Aryan Kesarwani,Riya Singh*

Main category: cs.CV

TL;DR: 本文提出了一种低成本的两步生物特征认证系统，结合人脸识别和语音验证，分别达到95.1%和98.9%的准确率。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统生物特征认证系统的高成本和复杂性问题，本文提出了一种仅依赖普通设备硬件的低成本解决方案。

Method: 系统采用修剪后的VGG-16分类器进行人脸识别，训练数据集包含五名受试者的924张增强图像，人脸定位由MTCNN完成，准确率达95.1%。语音验证采用基于LibriSpeech（train-other-360）训练的CNN说话人验证模型，测试集（test-clean）上准确率为98.9%，EER为3.456%。

Result: 人脸识别准确率为95.1%，语音验证准确率为98.9%，EER为3.456%。

Conclusion: 本文提出了一种经济高效的两步认证系统，结合了人脸识别和语音验证，仅需普通设备的摄像头和麦克风即可实现。该系统通过先进行人脸识别确定候选用户，再针对匹配身份进行语音验证，从而减少计算量并提高鲁棒性。

Abstract: We present a cost-effective two-step authentication system that integrates face identification and speaker verification using only a camera and microphone available on common devices. The pipeline first performs face recognition to identify a candidate user from a small enrolled group, then performs voice recognition only against the matched identity to reduce computation and improve robustness. For face recognition, a pruned VGG-16 based classifier is trained on an augmented dataset of 924 images from five subjects, with faces localized by MTCNN; it achieves 95.1% accuracy. For voice recognition, a CNN speaker-verification model trained on LibriSpeech (train-other-360) attains 98.9% accuracy and 3.456% EER on test-clean. Source code and trained models are available at https://github.com/NCUE-EE-AIAL/Two-step-Authentication-Multi-biometric-System.

</details>


### [21] [SAPL: Semantic-Agnostic Prompt Learning in CLIP for Weakly Supervised Image Manipulation Localization](https://arxiv.org/abs/2601.06222)
*Xinghao Wang,Changtao Miao,Dianmo Sheng,Tao Gong,Qi Chu,Nenghai Yu,Quanchen Zou,Deyue Zhang,Xiangzheng Zhang*

Main category: cs.CV

TL;DR: SAPL通过结合ECPL和HECL模块，利用边缘信息提升恶意图像篡改定位性能，在多个测试中达到最优。


<details>
  <summary>Details</summary>
Motivation: 现有的弱监督方法仅依赖图像级二进制标签，忽略了局部边缘线索，而这些线索对精确定位至关重要。观察到篡改边界的特征变化远大于内部区域，因此提出SAPL以利用这些边缘信息。

Method: SAPL利用CLIP框架，通过Edge-aware Contextual Prompt Learning（ECPL）和Hierarchical Edge Contrastive Learning（HECL）两个模块，分别在文本和视觉空间中利用边缘信息。ECPL通过注意力机制生成可学习的文本提示，嵌入与语义无关的信息；HECL则通过对比学习增强真实与篡改边缘区域的区分。

Result: 在多个公开基准测试中，SAPL显著优于现有方法，实现了最先进的定位性能。

Conclusion: SAPL（Semantic-Agnostic Prompt Learning）通过结合ECPL和HECL模块，显著提升了恶意图像篡改定位的性能，在多个公开基准测试中达到了最先进的水平。

Abstract: Malicious image manipulation threatens public safety and requires efficient localization methods. Existing approaches depend on costly pixel-level annotations which make training expensive. Existing weakly supervised methods rely only on image-level binary labels and focus on global classification, often overlooking local edge cues that are critical for precise localization. We observe that feature variations at manipulated boundaries are substantially larger than in interior regions. To address this gap, we propose Semantic-Agnostic Prompt Learning (SAPL) in CLIP, which learns text prompts that intentionally encode non-semantic, boundary-centric cues so that CLIPs multimodal similarity highlights manipulation edges rather than high-level object semantics. SAPL combines two complementary modules Edge-aware Contextual Prompt Learning (ECPL) and Hierarchical Edge Contrastive Learning (HECL) to exploit edge information in both textual and visual spaces. The proposed ECPL leverages edge-enhanced image features to generate learnable textual prompts via an attention mechanism, embedding semantic-irrelevant information into text features, to guide CLIP focusing on manipulation edges. The proposed HECL extract genuine and manipulated edge patches, and utilize contrastive learning to boost the discrimination between genuine edge patches and manipulated edge patches. Finally, we predict the manipulated regions from the similarity map after processing. Extensive experiments on multiple public benchmarks demonstrate that SAPL significantly outperforms existing approaches, achieving state-of-the-art localization performance.

</details>


### [22] [Ground What You See: Hallucination-Resistant MLLMs via Caption Feedback, Diversity-Aware Sampling, and Conflict Regularization](https://arxiv.org/abs/2601.06224)
*Miao Pan,Wangjie Gan,Jintao Chen,Wenqi Zhang,Bing Sun,Jianwei Yin,Xuhong Zhang*

Main category: cs.CV

TL;DR: 本文针对MLLMs在RL训练中的幻觉问题，提出三模块框架，通过改进视觉定位、探索多样性和样本干扰调节，有效提升模型性能。


<details>
  <summary>Details</summary>
Motivation: MLLMs在RL优化中的幻觉问题严重阻碍其实际部署，本文旨在系统分析其根本原因并提出解决方案。

Method: 框架包含三个核心模块：(1) 在推理阶段前增加规划和描述阶段，引入基于质量的描述奖励；(2) 基于奖励分布的均值和方差对样本分类，优先处理高方差样本；(3) 通过分组样本对并应用InfoNCE损失调节NTK相似性。

Result: 实验结果表明，所提方法显著降低了幻觉率并提升了MLLMs的推理准确性。

Conclusion: 本文提出的综合框架通过增强视觉定位、改进探索多样性及调节样本干扰，显著降低了MLLMs在RL训练中的幻觉率，并有效提升了推理准确性。

Abstract: While Multimodal Large Language Models (MLLMs) have achieved remarkable success across diverse tasks, their practical deployment is severely hindered by hallucination issues, which become particularly acute during Reinforcement Learning (RL) optimization. This paper systematically analyzes the root causes of hallucinations in MLLMs under RL training, identifying three critical factors: (1) an over-reliance on chained visual reasoning, where inaccurate initial descriptions or redundant information anchor subsequent inferences to incorrect premises; (2) insufficient exploration diversity during policy optimization, leading the model to generate overly confident but erroneous outputs; and (3) destructive conflicts between training samples, where Neural Tangent Kernel (NTK) similarity causes false associations and unstable parameter updates. To address these challenges, we propose a comprehensive framework comprising three core modules. First, we enhance visual localization by introducing dedicated planning and captioning stages before the reasoning phase, employing a quality-based caption reward to ensure accurate initial anchoring. Second, to improve exploration, we categorize samples based on the mean and variance of their reward distributions, prioritizing samples with high variance to focus the model on diverse and informative data. Finally, to mitigate sample interference, we regulate NTK similarity by grouping sample pairs and applying an InfoNCE loss to push overly similar pairs apart and pull dissimilar ones closer, thereby guiding gradient interactions toward a balanced range. Experimental results demonstrate that our proposed method significantly reduces hallucination rates and effectively enhances the inference accuracy of MLLMs.

</details>


### [23] [Synthetic FMCW Radar Range Azimuth Maps Augmentation with Generative Diffusion Model](https://arxiv.org/abs/2601.06228)
*Zhaoze Wang,Changxu Zhang,Tai Fei,Christopher Grimm,Yi Jin,Claas Tebruegge,Ernst Warsitz,Markus Gardill*

Main category: cs.CV

TL;DR: 提出条件生成框架，通过扩散模型生成多样化雷达数据，显著提升信号重建质量和模型泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决汽车雷达数据集的稀缺性和低多样性问题，以提升基于深度学习的环境感知性能。

Method: 提出了一种条件生成框架，利用生成扩散模型生成雷达数据，并通过置信度地图实现条件化，同时结合几何感知条件和时间一致性正则化来处理雷达特定特性。

Result: 在ROD2021数据集上的实验表明，信号重建质量比基线方法提高了3.6 dB（峰值信噪比），同时使用真实和合成数据集的组合训练比传统基于图像处理的增强方法提高了4.15%的平均精度。

Conclusion: 该生成框架不仅能够生成物理上合理且多样化的雷达频谱，还能显著提升下游任务中的模型泛化能力。

Abstract: The scarcity and low diversity of well-annotated automotive radar datasets often limit the performance of deep-learning-based environmental perception. To overcome these challenges, we propose a conditional generative framework for synthesizing realistic Frequency-Modulated Continuous-Wave radar Range-Azimuth Maps. Our approach leverages a generative diffusion model to generate radar data for multiple object categories, including pedestrians, cars, and cyclists. Specifically, conditioning is achieved via Confidence Maps, where each channel represents a semantic class and encodes Gaussian-distributed annotations at target locations. To address radar-specific characteristics, we incorporate Geometry Aware Conditioning and Temporal Consistency Regularization into the generative process. Experiments on the ROD2021 dataset demonstrate that signal reconstruction quality improves by \SI{3.6}{dB} in Peak Signal-to-Noise Ratio over baseline methods, while training with a combination of real and synthetic datasets improves overall mean Average Precision by 4.15% compared with conventional image-processing-based augmentation. These results indicate that our generative framework not only produces physically plausible and diverse radar spectrum but also substantially improves model generalization in downstream tasks.

</details>


### [24] [EyeTheia: A Lightweight and Accessible Eye-Tracking Toolbox](https://arxiv.org/abs/2601.06279)
*Stevenson Pather,Niels Martignène,Arnaud Bugnet,Fouad Boutaleb,Fabien D'Hondt,Deise Santana Maia*

Main category: cs.CV

TL;DR: EyeTheia 是一个轻量级开源深度学习管道，用于基于摄像头的视线估计，适用于浏览器实验和临床研究，性能接近商业解决方案，且支持用户微调。


<details>
  <summary>Details</summary>
Motivation: 为基于浏览器的实验平台和现实世界的认知与临床研究设计一个轻量级且开源的深度学习管道，用于基于摄像头的视线估计。

Method: 结合了基于 MediaPipe 的地标提取和受 iTracker 启发的卷积神经网络，支持用户特定的微调。研究了两种策略：在移动数据上预训练的模型和在桌面数据集上从头训练的模型。

Result: 在 MPIIFaceGaze 上的验证结果显示两种方法在校准前性能相当，轻量级用户特定微调能持续减少视线预测误差。在 Dot-Probe 任务中与 SeeSo SDK 比较显示在刺激呈现期间的左右视线分配有强一致性，尽管时间变异性较高。

Conclusion: EyeTheia 提供了一个透明且可扩展的低成本视线跟踪解决方案，适用于可扩展和可重复的实验与临床研究。代码、训练模型和实验材料均已公开。

Abstract: We introduce EyeTheia, a lightweight and open deep learning pipeline for webcam-based gaze estimation, designed for browser-based experimental platforms and real-world cognitive and clinical research. EyeTheia enables real-time gaze tracking using only a standard laptop webcam, combining MediaPipe-based landmark extraction with a convolutional neural network inspired by iTracker and optional user-specific fine-tuning. We investigate two complementary strategies: adapting a model pretrained on mobile data and training the same architecture from scratch on a desktop-oriented dataset. Validation results on MPIIFaceGaze show comparable performance between both approaches prior to calibration, while lightweight user-specific fine-tuning consistently reduces gaze prediction error. We further evaluate EyeTheia in a realistic Dot-Probe task and compare it to the commercial webcam-based tracker SeeSo SDK. Results indicate strong agreement in left-right gaze allocation during stimulus presentation, despite higher temporal variability. Overall, EyeTheia provides a transparent and extensible solution for low-cost gaze tracking, suitable for scalable and reproducible experimental and clinical studies. The code, trained models, and experimental materials are publicly available.

</details>


### [25] [NAS-GS: Noise-Aware Sonar Gaussian Splatting](https://arxiv.org/abs/2601.06285)
*Shida Xu,Jingqi Jiang,Jonatan Scharff Willners,Sen Wang*

Main category: cs.CV

TL;DR: NAS-GS是一种新型噪声感知声纳高斯溅射框架，通过双向溅射技术和GMM噪声模型，解决了声纳图像3D重建和新视角合成的挑战，在模拟和真实场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 声纳图像具有复杂的噪声模式和缺乏高程信息的独特特性，这对3D重建和新视角合成提出了重大挑战。

Method: 提出了一种Two-Ways Splatting技术和基于高斯混合模型（GMM）的噪声模型，分别用于精确建模声纳成像中的双向强度积累和透射率计算，以及捕捉复杂的声纳噪声模式。

Result: NAS-GS框架在渲染速度和质量上实现了显著提升，同时通过噪声模型增强了合成图像的真实性，并防止了3D高斯对噪声的过拟合。

Conclusion: NAS-GS框架在模拟和真实世界的大规模离岸声纳场景中展示了最先进的性能，显著提升了新视角合成和3D重建的准确性。

Abstract: Underwater sonar imaging plays a crucial role in various applications, including autonomous navigation in murky water, marine archaeology, and environmental monitoring. However, the unique characteristics of sonar images, such as complex noise patterns and the lack of elevation information, pose significant challenges for 3D reconstruction and novel view synthesis. In this paper, we present NAS-GS, a novel Noise-Aware Sonar Gaussian Splatting framework specifically designed to address these challenges. Our approach introduces a Two-Ways Splatting technique that accurately models the dual directions for intensity accumulation and transmittance calculation inherent in sonar imaging, significantly improving rendering speed without sacrificing quality. Moreover, we propose a Gaussian Mixture Model (GMM) based noise model that captures complex sonar noise patterns, including side-lobes, speckle, and multi-path noise. This model enhances the realism of synthesized images while preventing 3D Gaussian overfitting to noise, thereby improving reconstruction accuracy. We demonstrate state-of-the-art performance on both simulated and real-world large-scale offshore sonar scenarios, achieving superior results in novel view synthesis and 3D reconstruction.

</details>


### [26] [Perception Test 2025: Challenge Summary and a Unified VQA Extension](https://arxiv.org/abs/2601.06287)
*Joseph Heyward,Nikhil Pathasarathy,Tyler Zhu,Aravindh Mahendran,João Carreira,Dima Damen,Andrew Zisserman,Viorica Pătrăucean*

Main category: cs.CV

TL;DR: Perception Test 2025挑战赛通过统一赛道测试多模态模型的性能，突出了现有模型在处理多样化任务时的困难。


<details>
  <summary>Details</summary>
Motivation: 主要目标是基准测试最先进的视频模型，并衡量多模态感知的进展。

Method: 挑战包括五个统一赛道：统一视频问答、统一对象和点跟踪、统一动作和声音定位、基于视频的问答以及长达一小时的视频问答。

Result: 挑战赛引入了新颖的子集，将传统感知任务重新表述为多选视频问答问题，并要求参赛者使用统一方法而非特定任务的工程管道。

Conclusion: Perception Test 2025强调了现有模型在通过统一接口处理多样化感知任务时面临的重大困难。

Abstract: The Third Perception Test challenge was organised as a full-day workshop alongside the IEEE/CVF International Conference on Computer Vision (ICCV) 2025. Its primary goal is to benchmark state-of-the-art video models and measure the progress in multimodal perception. This year, the workshop featured 2 guest tracks as well: KiVA (an image understanding challenge) and Physic-IQ (a video generation challenge). In this report, we summarise the results from the main Perception Test challenge, detailing both the existing tasks as well as novel additions to the benchmark. In this iteration, we placed an emphasis on task unification, as this poses a more challenging test for current SOTA multimodal models. The challenge included five consolidated tracks: unified video QA, unified object and point tracking, unified action and sound localisation, grounded video QA, and hour-long video QA, alongside an analysis and interpretability track that is still open for submissions. Notably, the unified video QA track introduced a novel subset that reformulates traditional perception tasks (such as point tracking and temporal action localisation) as multiple-choice video QA questions that video-language models can natively tackle. The unified object and point tracking merged the original object tracking and point tracking tasks, whereas the unified action and sound localisation merged the original temporal action localisation and temporal sound localisation tracks. Accordingly, we required competitors to use unified approaches rather than engineered pipelines with task-specific models. By proposing such a unified challenge, Perception Test 2025 highlights the significant difficulties existing models face when tackling diverse perception tasks through unified interfaces.

</details>


### [27] [VideoWeave: A Data-Centric Approach for Efficient Video Understanding](https://arxiv.org/abs/2601.06309)
*Zane Durante,Silky Singh,Arpandeep Khatua,Shobhit Agarwal,Reuben Tan,Yong Jae Lee,Jianfeng Gao,Ehsan Adeli,Li Fei-Fei*

Main category: cs.CV

TL;DR: VideoWeave通过拼接短视频构建长期训练样本，提升视频语言模型的数据效率，无需修改架构即可提高下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 训练视频语言模型成本高昂，主要由于长帧序列处理的高成本和标注长视频的稀缺性，VideoWeave旨在通过提高数据效率来解决这一问题。

Method: VideoWeave通过拼接现有数据集中的短视频和字幕，构建合成长期上下文训练样本，研究了不同数据组合策略（如随机与视觉聚类拼接及字幕丰富）对下游视频问答性能的影响。

Result: 在相同的计算约束下，使用VideoWeave训练的模型比传统视频微调方法具有更高的准确性。

Conclusion: VideoWeave通过重组现有视频文本对而非修改模型架构，提供了一种简单且可扩展的方法来提升视频语言模型的训练效率。

Abstract: Training video-language models is often prohibitively expensive due to the high cost of processing long frame sequences and the limited availability of annotated long videos. We present VideoWeave, a simple yet effective approach to improve data efficiency by constructing synthetic long-context training samples that splice together short, captioned videos from existing datasets. Rather than modifying model architectures or optimization objectives, VideoWeave reorganizes available video-text pairs to expand temporal diversity within fixed compute. We systematically study how different data composition strategies like random versus visually clustered splicing and caption enrichment affect downstream performance on downstream video question answering. Under identical compute constraints, models trained with VideoWeave achieve higher accuracy than conventional video finetuning. Our results highlight that reorganizing training data, rather than altering architectures, may offer a simple and scalable path for training video-language models. We link our code for all experiments here.

</details>


### [28] [Object-WIPER : Training-Free Object and Associated Effect Removal in Videos](https://arxiv.org/abs/2601.06391)
*Saksham Singh Kushwaha,Sayan Nag,Yapeng Tian,Kuldeep Kulkarni*

Main category: cs.CV

TL;DR: Object-WIPER 是一种无需训练的框架，通过预训练的 DiT 模型移除视频中的动态对象及其效应，修复内容语义一致且时间连贯，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在移除动态对象及其视觉效应时缺乏时间连贯性和语义一致性，且缺乏合适的评估指标。Object-WIPER 旨在解决这些问题。

Method: 利用预训练的文本到视频扩散变换器（DiT），通过视觉-文本交叉注意力和视觉自注意力定位相关视觉标记，生成中间效应掩码并与用户提供的掩码融合，最终替换前景标记。在去噪过程中保留背景标记以维持场景保真度。

Result: 实验结果表明，Object-WIPER 在移除效果和时间稳定性上优于基于训练和无训练的基线方法。

Conclusion: Object-WIPER 是一种无需训练的框架，能够有效移除视频中的动态对象及其视觉效应，并通过语义一致和时间连贯的内容进行修复。该方法在 DAVIS 和新构建的 WIPER-Bench 基准测试中表现优异，超越了现有基线方法。

Abstract: In this paper, we introduce Object-WIPER, a training-free framework for removing dynamic objects and their associated visual effects from videos, and inpainting them with semantically consistent and temporally coherent content. Our approach leverages a pre-trained text-to-video diffusion transformer (DiT). Given an input video, a user-provided object mask, and query tokens describing the target object and its effects, we localize relevant visual tokens via visual-text cross-attention and visual self-attention. This produces an intermediate effect mask that we fuse with the user mask to obtain a final foreground token mask to replace. We first invert the video through the DiT to obtain structured noise, then reinitialize the masked tokens with Gaussian noise while preserving background tokens. During denoising, we copy values for the background tokens saved during inversion to maintain scene fidelity. To address the lack of suitable evaluation, we introduce a new object removal metric that rewards temporal consistency among foreground tokens across consecutive frames, coherence between foreground and background tokens within each frame, and dissimilarity between the input and output foreground tokens. Experiments on DAVIS and a newly curated real-world associated effect benchmark (WIPER-Bench) show that Object-WIPER surpasses both training-based and training-free baselines in terms of the metric, achieving clean removal and temporally stable reconstruction without any retraining. Our new benchmark, source code, and pre-trained models will be publicly available.

</details>


### [29] [Context Matters: Peer-Aware Student Behavioral Engagement Measurement via VLM Action Parsing and LLM Sequence Classification](https://arxiv.org/abs/2601.06394)
*Ahmed Abdelkawy,Ahmed Elsayed,Asem Ali,Aly Farag,Thomas Tretter,Michael McIntyre*

Main category: cs.CV

TL;DR: 提出一个三阶段框架，结合视觉语言模型和大型语言模型，利用少量数据和课堂背景来预测学生参与度，实验证明有效。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要大量标注数据来建模学生行为的多样性，但隐私问题限制了数据获取；同时，课堂背景（如同伴行为）被忽略。

Method: 提出了一个新颖的三阶段框架：1) 使用少样本适应的视觉语言模型进行学生动作识别；2) 利用滑动时间窗口技术将视频分割为不重叠的片段，并通过微调的VLM模型为每个片段分配动作类别；3) 利用大型语言模型对整个动作序列及课堂背景进行分类，判断学生是否参与。

Result: 提出的方法在识别学生参与度方面表现出有效性。

Conclusion: 实验结果表明，所提出的方法在识别学生参与度方面是有效的。

Abstract: Understanding student behavior in the classroom is essential to improve both pedagogical quality and student engagement. Existing methods for predicting student engagement typically require substantial annotated data to model the diversity of student behaviors, yet privacy concerns often restrict researchers to their own proprietary datasets. Moreover, the classroom context, represented in peers' actions, is ignored. To address the aforementioned limitation, we propose a novel three-stage framework for video-based student engagement measurement. First, we explore the few-shot adaptation of the vision-language model for student action recognition, which is fine-tuned to distinguish among action categories with a few training samples. Second, to handle continuous and unpredictable student actions, we utilize the sliding temporal window technique to divide each student's 2-minute-long video into non-overlapping segments. Each segment is assigned an action category via the fine-tuned VLM model, generating a sequence of action predictions. Finally, we leverage the large language model to classify this entire sequence of actions, together with the classroom context, as belonging to an engaged or disengaged student. The experimental results demonstrate the effectiveness of the proposed approach in identifying student engagement.

</details>


### [30] [GlobalPaint: Spatiotemporal Coherent Video Outpainting with Global Feature Guidance](https://arxiv.org/abs/2601.06413)
*Yueming Pan,Ruoyu Feng,Jianmin Bao,Chong Luo,Nanning Zheng*

Main category: cs.CV

TL;DR: GlobalPaint是一种基于扩散的视频外绘框架，通过层次化流程和增强的时空模块，显著提升了时空一致性和重建质量。


<details>
  <summary>Details</summary>
Motivation: 解决视频外绘中时空一致性的挑战，尤其是在相机或物体运动时，外绘内容需在时间上保持连贯。

Method: 采用基于扩散的框架，结合关键帧外绘和中间帧插值，并引入增强的时空模块（3D窗口注意力）和全局特征引导。

Result: 在基准数据集上展示了更高的重建质量和更自然的运动效果，优于现有方法。

Conclusion: GlobalPaint通过层次化流程和增强的时空模块，显著提升了视频外绘的时空一致性和重建质量。

Abstract: Video outpainting extends a video beyond its original boundaries by synthesizing missing border content. Compared with image outpainting, it requires not only per-frame spatial plausibility but also long-range temporal coherence, especially when outpainted content becomes visible across time under camera or object motion. We propose GlobalPaint, a diffusion-based framework for spatiotemporal coherent video outpainting. Our approach adopts a hierarchical pipeline that first outpaints key frames and then completes intermediate frames via an interpolation model conditioned on the completed boundaries, reducing error accumulation in sequential processing. At the model level, we augment a pretrained image inpainting backbone with (i) an Enhanced Spatial-Temporal module featuring 3D windowed attention for stronger spatiotemporal interaction, and (ii) global feature guidance that distills OpenCLIP features from observed regions across all frames into compact global tokens using a dedicated extractor. Comprehensive evaluations on benchmark datasets demonstrate improved reconstruction quality and more natural motion compared to prior methods. Our demo page is https://yuemingpan.github.io/GlobalPaint/

</details>


### [31] [WHU-PCPR: A cross-platform heterogeneous point cloud dataset for place recognition in complex urban scenes](https://arxiv.org/abs/2601.06442)
*Xianghong Zou,Jianping Li,Yandi Yang,Weitong Wu,Yuan Wang,Qiegen Liu,Zhen Dong*

Main category: cs.CV

TL;DR: WHU-PCPR是一个跨平台异构点云数据集，用于地点识别研究，弥补了现有数据集的不足，并提供了多样化数据和未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 现有PCPR数据集在场景、平台和传感器多样性方面不足，限制了地点识别研究的有效发展。

Method: 通过收集来自不同平台（车载MLS系统和便携式PLS系统）和LiDAR传感器的异构点云数据，构建了一个包含复杂场景和大空间覆盖的数据集WHU-PCPR。

Result: 建立了WHU-PCPR数据集，包含跨平台异构点云、复杂场景和大规模空间覆盖，并评估了多种PCPR方法。

Conclusion: WHU-PCPR数据集填补了现有PCPR数据集的不足，为跨平台异构点云的地点识别研究提供了多样化的数据支持，并指出了未来研究方向。

Abstract: Point Cloud-based Place Recognition (PCPR) demonstrates considerable potential in applications such as autonomous driving, robot localization and navigation, and map update. In practical applications, point clouds used for place recognition are often acquired from different platforms and LiDARs across varying scene. However, existing PCPR datasets lack diversity in scenes, platforms, and sensors, which limits the effective development of related research. To address this gap, we establish WHU-PCPR, a cross-platform heterogeneous point cloud dataset designed for place recognition. The dataset differentiates itself from existing datasets through its distinctive characteristics: 1) cross-platform heterogeneous point clouds: collected from survey-grade vehicle-mounted Mobile Laser Scanning (MLS) systems and low-cost Portable helmet-mounted Laser Scanning (PLS) systems, each equipped with distinct mechanical and solid-state LiDAR sensors. 2) Complex localization scenes: encompassing real-time and long-term changes in both urban and campus road scenes. 3) Large-scale spatial coverage: featuring 82.3 km of trajectory over a 60-month period and an unrepeated route of approximately 30 km. Based on WHU-PCPR, we conduct extensive evaluation and in-depth analysis of several representative PCPR methods, and provide a concise discussion of key challenges and future research directions. The dataset and benchmark code are available at https://github.com/zouxianghong/WHU-PCPR.

</details>


### [32] [How to Build Robust, Scalable Models for GSV-Based Indicators in Neighborhood Research](https://arxiv.org/abs/2601.06443)
*Xiaoya Tang,Xiaohe Yue,Heran Mane,Dapeng Li,Quynh Nguyen,Tolga Tasdizen*

Main category: cs.CV

TL;DR: 本文实证分析了如何选择和适应基础模型处理有限标签数据，展示了无监督训练提升性能的潜力。


<details>
  <summary>Details</summary>
Motivation: 探讨如何利用计算机视觉的进展大规模、系统地描述社区建筑环境，并解决模型在不同领域间泛化能力的不确定性。

Method: 研究包括全面的定量和视觉分析，比较模型在无监督适应前后的性能。

Result: 提供了关于如何选择和适应基础模型的实用见解，特别是在数据集有限的情况下，利用更大的无标签数据集进行无监督训练。

Conclusion: 本文通过实证分析回答了如何选择和适应基础模型以处理有限标签数据集的问题，并展示了无监督训练在提升下游任务性能方面的潜力。

Abstract: A substantial body of health research demonstrates a strong link between neighborhood environments and health outcomes. Recently, there has been increasing interest in leveraging advances in computer vision to enable large-scale, systematic characterization of neighborhood built environments. However, the generalizability of vision models across fundamentally different domains remains uncertain, for example, transferring knowledge from ImageNet to the distinct visual characteristics of Google Street View (GSV) imagery. In applied fields such as social health research, several critical questions arise: which models are most appropriate, whether to adopt unsupervised training strategies, what training scale is feasible under computational constraints, and how much such strategies benefit downstream performance. These decisions are often costly and require specialized expertise.
  In this paper, we answer these questions through empirical analysis and provide practical insights into how to select and adapt foundation models for datasets with limited size and labels, while leveraging larger, unlabeled datasets through unsupervised training. Our study includes comprehensive quantitative and visual analyses comparing model performance before and after unsupervised adaptation.

</details>


### [33] [Tone Matters: The Impact of Linguistic Tone on Hallucination in VLMs](https://arxiv.org/abs/2601.06460)
*Weihao Hong,Zhiyuan Jiang,Bingyu Shen,Xinlei Guan,Yangyi Feng,Meng Xu,Boyang Li*

Main category: cs.CV

TL;DR: 研究提示压力对视觉语言模型幻觉行为的影响，发现当前安全对齐更擅长检测语义敌意而非结构强制。


<details>
  <summary>Details</summary>
Motivation: 研究不同形式的提示压力如何影响视觉语言模型的幻觉行为，填补现有研究在提示 phrasing 和结构约束方面的空白。

Method: 引入Ghost-100数据集，通过5级提示强度框架系统分析提示压力对幻觉行为的影响。

Result: 所有模型在不同强度级别下均表现出幻觉率不单调增加，且在更高强度下出现降低，但并非所有模型在最大强制下持续降低。

Conclusion: 当前的安全对齐在检测语义敌意方面比结构强制更有效，揭示了模型在处理合规压力时的特定局限性。

Abstract: Vision-Language Models (VLMs) are increasingly used in safety-critical applications that require reliable visual grounding. However, these models often hallucinate details that are not present in the image to satisfy user prompts. While recent datasets and benchmarks have been introduced to evaluate systematic hallucinations in VLMs, many hallucination behaviors remain insufficiently characterized. In particular, prior work primarily focuses on object presence or absence, leaving it unclear how prompt phrasing and structural constraints can systematically induce hallucinations. In this paper, we investigate how different forms of prompt pressure influence hallucination behavior. We introduce Ghost-100, a procedurally generated dataset of synthetic scenes in which key visual details are deliberately removed, enabling controlled analysis of absence-based hallucinations. Using a structured 5-Level Prompt Intensity Framework, we vary prompts from neutral queries to toxic demands and rigid formatting constraints. We evaluate three representative open-weight VLMs: MiniCPM-V 2.6-8B, Qwen2-VL-7B, and Qwen3-VL-8B. Across all three models, hallucination rates do not increase monotonically with prompt intensity. All models exhibit reductions at higher intensity levels at different thresholds, though not all show sustained reduction under maximum coercion. These results suggest that current safety alignment is more effective at detecting semantic hostility than structural coercion, revealing model-specific limitations in handling compliance pressure. Our dataset is available at: https://github.com/bli1/tone-matters

</details>


### [34] [On the Adversarial Robustness of 3D Large Vision-Language Models](https://arxiv.org/abs/2601.06464)
*Chao Liu,Ngai-Man Cheung*

Main category: cs.CV

TL;DR: 首次系统研究基于点的3D VLM对抗鲁棒性，发现其在无目标攻击下脆弱，目标攻击中比2D模型更坚韧，需提升鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 探讨3D视觉输入是否会像2D VLM一样降低模型的对抗鲁棒性，填补3D VLM对抗鲁棒性研究的空白。

Method: 提出了两种互补的攻击策略：视觉攻击（扰动3D编码器和投影器生成的视觉令牌特征）和字幕攻击（直接操纵输出令牌序列），包括无目标和有目标变体。

Result: 实验表明3D VLM在无目标攻击下脆弱，但在目标攻击中比2D模型更具韧性。

Conclusion: 研究发现3D视觉语言模型（VLM）在无目标攻击下表现出显著的对抗脆弱性，但在针对特定有害输出的目标攻击中比2D模型更具韧性，强调了提升3D VLM对抗鲁棒性的重要性。

Abstract: 3D Vision-Language Models (VLMs), such as PointLLM and GPT4Point, have shown strong reasoning and generalization abilities in 3D understanding tasks. However, their adversarial robustness remains largely unexplored. Prior work in 2D VLMs has shown that the integration of visual inputs significantly increases vulnerability to adversarial attacks, making these models easier to manipulate into generating toxic or misleading outputs. In this paper, we investigate whether incorporating 3D vision similarly compromises the robustness of 3D VLMs. To this end, we present the first systematic study of adversarial robustness in point-based 3D VLMs. We propose two complementary attack strategies: \textit{Vision Attack}, which perturbs the visual token features produced by the 3D encoder and projector to assess the robustness of vision-language alignment; and \textit{Caption Attack}, which directly manipulates output token sequences to evaluate end-to-end system robustness. Each attack includes both untargeted and targeted variants to measure general vulnerability and susceptibility to controlled manipulation. Our experiments reveal that 3D VLMs exhibit significant adversarial vulnerabilities under untargeted attacks, while demonstrating greater resilience against targeted attacks aimed at forcing specific harmful outputs, compared to their 2D counterparts. These findings highlight the importance of improving the adversarial robustness of 3D VLMs, especially as they are deployed in safety-critical applications.

</details>


### [35] [SparseOccVLA: Bridging Occupancy and Vision-Language Models via Sparse Queries for Unified 4D Scene Understanding and Planning](https://arxiv.org/abs/2601.06474)
*Chenxu Dang,Jie Wang,Guang Li,Zhiwen Hou,Zihan You,Hangjun Ye,Jie Ma,Long Chen,Yan Wang*

Main category: cs.CV

TL;DR: SparseOccVLA通过稀疏查询整合视觉语言与语义占用，显著提升自动驾驶场景理解与规划性能。


<details>
  <summary>Details</summary>
Motivation: 解决视觉语言模型与语义占用之间的整合难题，提升自动驾驶中的场景理解和规划能力。

Method: 提出SparseOccVLA模型，结合稀疏占用编码器生成紧凑查询，通过LLM进行对齐与推理，并引入LLM引导的锚点扩散规划器。

Result: 在OmniDrive-nuScenes上CIDEr提升7%，Occ3D-nuScenes上mIoU提高0.5，并在nuScenes基准测试中达到最优开环规划指标。

Conclusion: SparseOccVLA通过稀疏占用查询有效整合了视觉语言模型与语义占用，提升了场景理解、占用预测和轨迹规划的整体性能。

Abstract: In autonomous driving, Vision Language Models (VLMs) excel at high-level reasoning , whereas semantic occupancy provides fine-grained details. Despite significant progress in individual fields, there is still no method that can effectively integrate both paradigms. Conventional VLMs struggle with token explosion and limited spatiotemporal reasoning, while semantic occupancy provides a unified, explicit spatial representation but is too dense to integrate efficiently with VLMs. To address these challenges and bridge the gap between VLMs and occupancy, we propose SparseOccVLA, a novel vision-language-action model that unifies scene understanding, occupancy forecasting, and trajectory planning powered by sparse occupancy queries. Starting with a lightweight Sparse Occupancy Encoder, SparseOccVLA generates compact yet highly informative sparse occupancy queries that serve as the single bridge between vision and language. These queries are aligned into the language space and reasoned by the LLM for unified scene understanding and future occupancy forecasting. Furthermore, we introduce an LLM-guided Anchor-Diffusion Planner featuring decoupled anchor scoring and denoising, as well as cross-model trajectory-condition fusion. SparseOccVLA achieves a 7% relative improvement in CIDEr over the state-of-the-art on OmniDrive-nuScenes, a 0.5 increase in mIoU score on Occ3D-nuScenes, and sets state-of-the-art open-loop planning metric on nuScenes benchmark, demonstrating its strong holistic capability.

</details>


### [36] [VVTRec: Radio Interferometric Reconstruction through Visual and Textual Modality Enrichment](https://arxiv.org/abs/2601.06475)
*Kai Cheng,Ruoqi Wang,Qiong Luo*

Main category: cs.CV

TL;DR: VVTRec是一种多模态射电干涉数据重建方法，通过结合视觉和文本模态增强成像质量，且计算开销低。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅考虑单一模态的稀疏可见性数据，导致图像中存在残留伪影且相关性建模不足。

Method: VVTRec将稀疏可见性数据转换为图像和文本形式的特征，利用视觉语言模型（VLMs）提取预训练知识，增强空间和语义信息。

Result: 实验证明，VVTRec通过利用多模态信息有效提升了成像结果。

Conclusion: VVTRec通过结合可见性引导的视觉和文本模态增强，显著提升了射电干涉数据的重建质量，同时避免了过高的计算开销。

Abstract: Radio astronomy is an indispensable discipline for observing distant celestial objects. Measurements of wave signals from radio telescopes, called visibility, need to be transformed into images for astronomical observations. These dirty images blend information from real sources and artifacts. Therefore, astronomers usually perform reconstruction before imaging to obtain cleaner images. Existing methods consider only a single modality of sparse visibility data, resulting in images with remaining artifacts and insufficient modeling of correlation. To enhance the extraction of visibility information and emphasize output quality in the image domain, we propose VVTRec, a multimodal radio interferometric data reconstruction method with visibility-guided visual and textual modality enrichment. In our VVTRec, sparse visibility is transformed into image-form and text-form features to obtain enhancements in terms of spatial and semantic information, improving the structural integrity and accuracy of images. Also, we leverage Vision-Language Models (VLMs) to achieve additional training-free performance improvements. VVTRec enables sparse visibility, as a foreign modality unseen by VLMs, to accurately extract pre-trained knowledge as a supplement. Our experiments demonstrate that VVTRec effectively enhances imaging results by exploiting multimodal information without introducing excessive computational overhead.

</details>


### [37] [SRFlow: A Dataset and Regularization Model for High-Resolution Facial Optical Flow via Splatting Rasterization](https://arxiv.org/abs/2601.06479)
*JiaLin Zhang,Dong Li*

Main category: cs.CV

TL;DR: SRFlow dataset and SRFlowNet model improve facial optical flow estimation and micro-expression recognition, reducing errors and boosting performance metrics.


<details>
  <summary>Details</summary>
Motivation: The lack of high-resolution facial optical flow datasets has hindered progress in facial motion analysis, prompting the development of SRFlow and SRFlowNet.

Method: The paper introduces SRFlow, a high-resolution facial optical flow dataset, and SRFlowNet, a model with tailored regularization losses that constrain flow predictions using masks and gradients.

Result: Training with SRFlow reduces end-point error by up to 42%, and SRFlowNet achieves up to a 48% improvement in F1-score on micro-expression datasets.

Conclusion: The paper demonstrates the value of advancing both facial optical flow estimation and micro-expression recognition through the introduction of SRFlow dataset and SRFlowNet model, achieving significant improvements in performance metrics.

Abstract: Facial optical flow supports a wide range of tasks in facial motion analysis. However, the lack of high-resolution facial optical flow datasets has hindered progress in this area. In this paper, we introduce Splatting Rasterization Flow (SRFlow), a high-resolution facial optical flow dataset, and Splatting Rasterization Guided FlowNet (SRFlowNet), a facial optical flow model with tailored regularization losses. These losses constrain flow predictions using masks and gradients computed via difference or Sobel operator. This effectively suppresses high-frequency noise and large-scale errors in texture-less or repetitive-pattern regions, enabling SRFlowNet to be the first model explicitly capable of capturing high-resolution skin motion guided by Gaussian splatting rasterization. Experiments show that training with the SRFlow dataset improves facial optical flow estimation across various optical flow models, reducing end-point error (EPE) by up to 42% (from 0.5081 to 0.2953). Furthermore, when coupled with the SRFlow dataset, SRFlowNet achieves up to a 48% improvement in F1-score (from 0.4733 to 0.6947) on a composite of three micro-expression datasets. These results demonstrate the value of advancing both facial optical flow estimation and micro-expression recognition.

</details>


### [38] [Learning Domain Agnostic Latent Embeddings of 3D Faces for Zero-shot Animal Expression Transfer](https://arxiv.org/abs/2601.06484)
*Yue Wang,Lawrence Amadi,Xiang Gao,Yazheng Chen,Yuanpeng Liu,Ning Lu,Xianfeng Gu*

Main category: cs.CV

TL;DR: 零样本框架将人类表情迁移到3D动物面部，无需动物数据，通过解耦身份与表情嵌入实现跨物种迁移。


<details>
  <summary>Details</summary>
Motivation: 解决跨物种表情迁移的挑战，尤其是在缺乏动物表情数据的情况下，实现人类表情到动物面部的有效迁移。

Method: 结合了内在几何描述符（HKS/WKS）与网格无关的潜在嵌入，解耦面部身份和表情。通过Jacobian损失、顶点位置损失和Laplacian损失确保几何一致性。

Result: 实验表明，该方法能够实现跨物种的合理表情迁移，缩小人类与动物面部形状的几何差异。

Conclusion: 该论文提出了一种零样本框架，能够将人类面部表情迁移到3D动物面部网格上，无需动物表情数据，有效缩小了人类与动物面部形状之间的几何差距。

Abstract: We present a zero-shot framework for transferring human facial expressions to 3D animal face meshes. Our method combines intrinsic geometric descriptors (HKS/WKS) with a mesh-agnostic latent embedding that disentangles facial identity and expression. The ID latent space captures species-independent facial structure, while the expression latent space encodes deformation patterns that generalize across humans and animals. Trained only with human expression pairs, the model learns the embeddings, decoupling, and recoupling of cross-identity expressions, enabling expression transfer without requiring animal expression data. To enforce geometric consistency, we employ Jacobian loss together with vertex-position and Laplacian losses. Experiments show that our approach achieves plausible cross-species expression transfer, effectively narrowing the geometric gap between human and animal facial shapes.

</details>


### [39] [SpatialNav: Leveraging Spatial Scene Graphs for Zero-Shot Vision-and-Language Navigation](https://arxiv.org/abs/2601.06806)
*Jiwen Zhang,Zejun Li,Siyuan Wang,Xiangyu Shi,Zhongyu Wei,Qi Wu*

Main category: cs.CV

TL;DR: SpatialNav通过构建空间场景图和集成多种策略，显著提升了零样本视觉与语言导航的性能，缩小了与学习方法的差距。


<details>
  <summary>Details</summary>
Motivation: 零样本视觉与语言导航（VLN）代理主要依赖局部观察进行导航，导致探索效率低下和性能差距显著。为了解决这一问题，考虑在任务执行前允许代理充分探索环境的零样本VLN设置。

Method: 构建了空间场景图（SSG）以显式捕捉探索环境中的全局空间结构和语义，并基于SSG引入了SpatialNav，集成了以代理为中心的空间地图、指南针对齐的视觉表示和远程对象定位策略。

Result: 在离散和连续环境中的综合实验表明，SpatialNav显著优于现有零样本代理，并明显缩小了与最先进学习方法的差距。

Conclusion: SpatialNav显著优于现有的零样本导航代理，并明显缩小了与最先进学习方法的差距，突显了全局空间表示对通用导航的重要性。

Abstract: Although learning-based vision-and-language navigation (VLN) agents can learn spatial knowledge implicitly from large-scale training data, zero-shot VLN agents lack this process, relying primarily on local observations for navigation, which leads to inefficient exploration and a significant performance gap. To deal with the problem, we consider a zero-shot VLN setting that agents are allowed to fully explore the environment before task execution. Then, we construct the Spatial Scene Graph (SSG) to explicitly capture global spatial structure and semantics in the explored environment. Based on the SSG, we introduce SpatialNav, a zero-shot VLN agent that integrates an agent-centric spatial map, a compass-aligned visual representation, and a remote object localization strategy for efficient navigation. Comprehensive experiments in both discrete and continuous environments demonstrate that SpatialNav significantly outperforms existing zero-shot agents and clearly narrows the gap with state-of-the-art learning-based methods. Such results highlight the importance of global spatial representations for generalizable navigation.

</details>


### [40] [3D CoCa v2: Contrastive Learners with Test-Time Search for Generalizable Spatial Intelligence](https://arxiv.org/abs/2601.06496)
*Hao Tang,Ting Huang,Zeyu Zhang*

Main category: cs.CV

TL;DR: 3D CoCa v2通过对比学习与测试时搜索，提升了3D场景描述的泛化能力，实验显示显著效果提升。


<details>
  <summary>Details</summary>
Motivation: 解决现有3D captioning方法在点云稀疏性、不规则性以及跨环境泛化能力弱的问题。

Method: 提出了3D CoCa v2框架，结合了冻结的CLIP语义先验、空间感知的3D场景编码器和多模态解码器，通过对比学习和caption目标联合优化，无需外部检测器或手工提案。

Result: 在ScanRefer和Nr3D数据集上分别提升了1.50和1.61 CIDEr@0.5IoU，在TOD3Cap的零样本OOD评估中提升了3.8 CIDEr@0.25。

Conclusion: 3D CoCa v2通过结合对比学习与3D caption生成，并引入测试时搜索策略，显著提升了3D场景描述的泛化能力和鲁棒性。

Abstract: Spatial intelligence refers to the ability to perceive, reason about, and describe objects and their relationships within three-dimensional environments, forming a foundation for embodied perception and scene understanding. 3D captioning aims to describe 3D scenes in natural language; however, it remains challenging due to the sparsity and irregularity of point clouds and, more critically, the weak grounding and limited out-of-distribution (OOD) generalization of existing captioners across drastically different environments, including indoor and outdoor 3D scenes. To address this challenge, we propose 3D CoCa v2, a generalizable 3D captioning framework that unifies contrastive vision-language learning with 3D caption generation and further improves robustness via test-time search (TTS) without updating the captioner parameters. 3D CoCa v2 builds on a frozen CLIP-based semantic prior, a spatially-aware 3D scene encoder for geometry, and a multimodal decoder jointly optimized with contrastive and captioning objectives, avoiding external detectors or handcrafted proposals. At inference, TTS produces diverse caption candidates and performs reward-guided selection using a compact scene summary. Experiments show improvements over 3D CoCa of +1.50 CIDEr@0.5IoU on ScanRefer and +1.61 CIDEr@0.5IoU on Nr3D, and +3.8 CIDEr@0.25 in zero-shot OOD evaluation on TOD3Cap. Code will be released at https://github.com/AIGeeksGroup/3DCoCav2.

</details>


### [41] [OSCAR: Open-Set CAD Retrieval from a Language Prompt and a Single Image](https://arxiv.org/abs/2601.07333)
*Tessa Pulli,Jean-Baptiste Weibel,Peter Hönig,Matthias Hirschmanner,Markus Vincze,Andreas Holzinger*

Main category: cs.CV

TL;DR: OSCAR是一种无需训练的开放集CAD检索方法，通过语言提示和单张图像从无标签3D数据库中检索匹配模型，在跨领域检索和6D姿态估计中表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了解决在部署后难以获取CAD模型以及物体集不断变化和增长导致实例模型识别不可靠的问题，提出了OSCAR方法。

Method: OSCAR采用两阶段检索方法：首先通过CLIP进行基于文本的过滤识别候选模型，然后通过DINOv2进行基于图像的细化选择最相似的物体。

Result: OSCAR在YCB-V物体数据集上的物体检索平均精度达到90.48%，并且在姿态估计中比基于重建的方法表现更好。

Conclusion: OSCAR在跨领域3D模型检索基准MI3DOR上表现优于现有方法，并在6D物体姿态估计中实现了自动化模型来源，即使在没有精确实例模型的情况下，也能通过最相似模型实现高精度姿态估计。

Abstract: 6D object pose estimation plays a crucial role in scene understanding for applications such as robotics and augmented reality. To support the needs of ever-changing object sets in such context, modern zero-shot object pose estimators were developed to not require object-specific training but only rely on CAD models. Such models are hard to obtain once deployed, and a continuously changing and growing set of objects makes it harder to reliably identify the instance model of interest. To address this challenge, we introduce an Open-Set CAD Retrieval from a Language Prompt and a Single Image (OSCAR), a novel training-free method that retrieves a matching object model from an unlabeled 3D object database. During onboarding, OSCAR generates multi-view renderings of database models and annotates them with descriptive captions using an image captioning model. At inference, GroundedSAM detects the queried object in the input image, and multi-modal embeddings are computed for both the Region-of-Interest and the database captions. OSCAR employs a two-stage retrieval: text-based filtering using CLIP identifies candidate models, followed by image-based refinement using DINOv2 to select the most visually similar object. In our experiments we demonstrate that OSCAR outperforms all state-of-the-art methods on the cross-domain 3D model retrieval benchmark MI3DOR. Furthermore, we demonstrate OSCAR's direct applicability in automating object model sourcing for 6D object pose estimation. We propose using the most similar object model for pose estimation if the exact instance is not available and show that OSCAR achieves an average precision of 90.48\% during object retrieval on the YCB-V object dataset. Moreover, we demonstrate that the most similar object model can be utilized for pose estimation using Megapose achieving better results than a reconstruction-based approach.

</details>


### [42] [Bridging Robustness and Efficiency: Real-Time Low-Light Enhancement via Attention U-Net GAN](https://arxiv.org/abs/2601.06518)
*Yash Thesia,Meera Suthar*

Main category: cs.CV

TL;DR: 本文提出混合注意力U-Net GAN，平衡生成级纹理恢复与实时推理，显著优于现有高效基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有低光图像增强方法中，扩散概率模型计算延迟高，而传统CNN基线模型在极端低光条件下无法恢复精细结构细节，缺乏兼具生成级纹理恢复和实时推理能力的模型。

Method: 通过将注意力门集成到轻量级U-Net主干中，并在条件对抗框架下训练，实现了单次前向传递的高频保真度。

Result: 在SID数据集上，该方法在高效模型中取得了最佳LPIPS分数0.112，推理延迟仅为0.06秒，比潜在扩散模型快40倍。

Conclusion: 本文提出的混合注意力U-Net GAN在低光图像增强任务中实现了生成级纹理恢复与边缘可部署速度的平衡，显著优于现有高效基线模型。

Abstract: Recent advancements in Low-Light Image Enhancement (LLIE) have focused heavily on Diffusion Probabilistic Models, which achieve high perceptual quality but suffer from significant computational latency (often exceeding 2-4 seconds per image). Conversely, traditional CNN-based baselines offer real-time inference but struggle with "over-smoothing," failing to recover fine structural details in extreme low-light conditions. This creates a practical gap in the literature: the lack of a model that provides generative-level texture recovery at edge-deployable speeds. In this paper, we address this trade-off by proposing a hybrid Attention U-Net GAN. We demonstrate that the heavy iterative sampling of diffusion models is not strictly necessary for texture recovery. Instead, by integrating Attention Gates into a lightweight U-Net backbone and training within a conditional adversarial framework, we can approximate the high-frequency fidelity of generative models in a single forward pass. Extensive experiments on the SID dataset show that our method achieves a best-in-class LPIPS score of 0.112 among efficient models, significantly outperforming efficient baselines (SID, EnlightenGAN) while maintaining an inference latency of 0.06s. This represents a 40x speedup over latent diffusion models, making our approach suitable for near real-time applications.

</details>


### [43] [FMAC: a Fair Fiducial Marker Accuracy Comparison Software](https://arxiv.org/abs/2601.07723)
*Guillaume J. Laurent,Patrick Sandoz*

Main category: cs.CV

TL;DR: 本文提出了一种基于合成图像的姿态估计准确性评估方法，通过开源工具揭示了不同标记的优缺点。


<details>
  <summary>Details</summary>
Motivation: 为了深入探索六自由度姿态估计的准确性，并实现不同标记方法的公平比较。

Method: 采用低差异采样空间和基于物理的光线追踪渲染技术，结合标准相机校准系数，生成包含图像畸变、散焦和衍射模糊的高保真合成图像。

Result: 通过36对自由度组合的误差分析，揭示了已知标记在姿态估计中的具体表现。

Conclusion: 本文提出了一种基于高保真合成图像的姿态估计准确性公平比较方法，并通过开源代码在GitHub上公开，揭示了已知标记在姿态估计中的优缺点。

Abstract: This paper presents a method for carrying fair comparisons of the accuracy of pose estimation using fiducial markers. These comparisons rely on large sets of high-fidelity synthetic images enabling deep exploration of the 6 degrees of freedom. A low-discrepancy sampling of the space allows to check the correlations between each degree of freedom and the pose errors by plotting the 36 pairs of combinations. The images are rendered using a physically based ray tracing code that has been specifically developed to use the standard calibration coefficients of any camera directly. The software reproduces image distortions, defocus and diffraction blur. Furthermore, sub-pixel sampling is applied to sharp edges to enhance the fidelity of the rendered image. After introducing the rendering algorithm and its experimental validation, the paper proposes a method for evaluating the pose accuracy. This method is applied to well-known markers, revealing their strengths and weaknesses for pose estimation. The code is open source and available on GitHub.

</details>


### [44] [BabyVision: Visual Reasoning Beyond Language](https://arxiv.org/abs/2601.06521)
*Liang Chen,Weichu Xie,Yiyan Liang,Hongfeng He,Hans Zhao,Zhibo Yang,Zhiqi Huang,Haoning Wu,Haoyu Lu,Y. charles,Yiping Bao,Yuantao Fan,Guopeng Li,Haiyang Shen,Xuanzhong Chen,Wendong Xu,Shuzheng Si,Zefan Cai,Wenhao Chai,Ziqi Huang,Fangfu Liu,Tianyu Liu,Baobao Chang,Xiaobo Hu,Kaiyuan Chen,Yixin Ren,Yang Liu,Yuan Gong,Kuan Li*

Main category: cs.CV

TL;DR: BabyVision基准测试揭示MLLMs在基本视觉任务上表现远不如人类，提出改进方案并开源工具。


<details>
  <summary>Details</summary>
Motivation: 发现最先进的MLLMs在人类（甚至3岁儿童）能轻松解决的基本视觉任务上表现不佳，需要系统研究这一差距。

Method: 引入了BabyVision基准测试，旨在独立于语言知识评估MLLMs的核心视觉能力，包含388个项目，分为22个子类和四个关键类别。还提出了BabyVision-Gen和自动评估工具包。

Result: 领先的MLLMs表现显著低于人类基线，例如Gemini3-Pro-Preview得分为49.7，远低于成人平均分94.1。

Conclusion: 尽管当前的多模态大语言模型（MLLMs）在知识密集型评估中表现出色，但仍缺乏基本的视觉能力。BabyVision的进展是迈向人类水平视觉感知和推理能力的一步。

Abstract: While humans develop core visual skills long before acquiring language, contemporary Multimodal LLMs (MLLMs) still rely heavily on linguistic priors to compensate for their fragile visual understanding. We uncovered a crucial fact: state-of-the-art MLLMs consistently fail on basic visual tasks that humans, even 3-year-olds, can solve effortlessly. To systematically investigate this gap, we introduce BabyVision, a benchmark designed to assess core visual abilities independent of linguistic knowledge for MLLMs. BabyVision spans a wide range of tasks, with 388 items divided into 22 subclasses across four key categories. Empirical results and human evaluation reveal that leading MLLMs perform significantly below human baselines. Gemini3-Pro-Preview scores 49.7, lagging behind 6-year-old humans and falling well behind the average adult score of 94.1. These results show despite excelling in knowledge-heavy evaluations, current MLLMs still lack fundamental visual primitives. Progress in BabyVision represents a step toward human-level visual perception and reasoning capabilities. We also explore solving visual reasoning with generation models by proposing BabyVision-Gen and automatic evaluation toolkit. Our code and benchmark data are released at https://github.com/UniPat-AI/BabyVision for reproduction.

</details>


### [45] [Toward Generalizable Deblurring: Leveraging Massive Blur Priors with Linear Attention for Real-World Scenarios](https://arxiv.org/abs/2601.06525)
*Yuanting Gao,Shuo Cao,Xiaohui Li,Yuandong Pu,Yihao Liu,Kai Zhang*

Main category: cs.CV

TL;DR: 论文提出GLOWDeblur模型，通过BPP和MoSeG增强模糊先验，结合卷积和轻量扩散设计，显著提升真实场景泛化能力，实验验证其有效性和实用性。


<details>
  <summary>Details</summary>
Motivation: 当前基于深度学习的图像去模糊方法在训练数据集之外泛化能力差，主要原因是数据集在真实性和模糊模式多样性之间存在固有权衡，且算法设计受限（如像素级损失忽略结构语义一致性）。扩散方法虽感知强，但在窄数据集上训练时仍泛化不足。

Method: 论文提出了Blur Pattern Pretraining（BPP）方法，从仿真数据集中获取模糊先验，并通过在真实数据上的联合微调进行迁移。此外，引入了Motion and Semantic Guidance（MoSeG）以增强严重退化下的模糊先验，并构建了GLOWDeblur模型，结合卷积预重建、域对齐模块和轻量级扩散主干。

Result: 在六个广泛使用的基准数据集和两个真实世界数据集上的实验验证了方法的有效性，证实了模糊先验对稳健泛化的重要性，且GLOWDeblur的轻量设计确保了实际应用的可行性。

Conclusion: 该论文提出了GLOWDeblur模型，结合了卷积预重建、域对齐模块和轻量级扩散主干，通过Blur Pattern Pretraining（BPP）和Motion and Semantic Guidance（MoSeG）增强模糊先验，显著提升了模型在真实场景中的泛化能力。

Abstract: Image deblurring has advanced rapidly with deep learning, yet most methods exhibit poor generalization beyond their training datasets, with performance dropping significantly in real-world scenarios. Our analysis shows this limitation stems from two factors: datasets face an inherent trade-off between realism and coverage of diverse blur patterns, and algorithmic designs remain restrictive, as pixel-wise losses drive models toward local detail recovery while overlooking structural and semantic consistency, whereas diffusion-based approaches, though perceptually strong, still fail to generalize when trained on narrow datasets with simplistic strategies. Through systematic investigation, we identify blur pattern diversity as the decisive factor for robust generalization and propose Blur Pattern Pretraining (BPP), which acquires blur priors from simulation datasets and transfers them through joint fine-tuning on real data. We further introduce Motion and Semantic Guidance (MoSeG) to strengthen blur priors under severe degradation, and integrate it into GLOWDeblur, a Generalizable reaL-wOrld lightWeight Deblur model that combines convolution-based pre-reconstruction & domain alignment module with a lightweight diffusion backbone. Extensive experiments on six widely-used benchmarks and two real-world datasets validate our approach, confirming the importance of blur priors for robust generalization and demonstrating that the lightweight design of GLOWDeblur ensures practicality in real-world applications. The project page is available at https://vegdog007.github.io/GLOWDeblur_Website/.

</details>


### [46] [Towards Egocentric 3D Hand Pose Estimation in Unseen Domains](https://arxiv.org/abs/2601.06537)
*Wiktor Mucha,Michael Wray,Martin Kampel*

Main category: cs.CV

TL;DR: V-HPOT通过虚拟相机空间归一化和自监督优化，显著提升跨域3D手部姿态估计性能，减少误差并降低数据需求。


<details>
  <summary>Details</summary>
Motivation: 现有方法在同一域内表现良好，但在新环境中泛化能力不足，主要受限于训练数据和深度感知的过拟合问题。

Method: 通过估计虚拟相机空间中的关键点z坐标（由焦距和图像大小归一化），实现相机无关的深度预测，并提出一种自监督测试时间优化策略，通过3D一致性损失细化模型的深度感知。

Result: V-HPOT在跨域场景中表现优异，显著降低姿态误差，且数据效率高于现有方法。

Conclusion: V-HPOT显著提升了跨域场景下的3D手部姿态估计性能，在H2O数据集上平均姿态误差减少了71%，在AssemblyHands数据集上减少了41%，且数据需求远低于现有方法。

Abstract: We present V-HPOT, a novel approach for improving the cross-domain performance of 3D hand pose estimation from egocentric images across diverse, unseen domains. State-of-the-art methods demonstrate strong performance when trained and tested within the same domain. However, they struggle to generalise to new environments due to limited training data and depth perception -- overfitting to specific camera intrinsics. Our method addresses this by estimating keypoint z-coordinates in a virtual camera space, normalised by focal length and image size, enabling camera-agnostic depth prediction. We further leverage this invariance to camera intrinsics to propose a self-supervised test-time optimisation strategy that refines the model's depth perception during inference. This is achieved by applying a 3D consistency loss between predicted and in-space scale-transformed hand poses, allowing the model to adapt to target domain characteristics without requiring ground truth annotations. V-HPOT significantly improves 3D hand pose estimation performance in cross-domain scenarios, achieving a 71% reduction in mean pose error on the H2O dataset and a 41% reduction on the AssemblyHands dataset. Compared to state-of-the-art methods, V-HPOT outperforms all single-stage approaches across all datasets and competes closely with two-stage methods, despite needing approximately x3.5 to x14 less data.

</details>


### [47] [LLMTrack: Semantic Multi-Object Tracking with Multi-modal Large Language Models](https://arxiv.org/abs/2601.06550)
*Pan Liao,Feng Yang,Di Wu,Jinwen Yu,Yuhua Zhu,Wenhui Zhao*

Main category: cs.CV

TL;DR: LLMTrack是一种新型端到端语义多目标跟踪框架，通过仿生设计和多模态大模型，解决了传统MOT系统缺乏语义理解的问题，并在多个任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统MOT系统在定位和关联方面表现出色，但缺乏对物体行为语义（即“什么”和“为什么”）的理解，因此需要一种能结合几何感知与认知推理的新框架。

Method: 采用仿生设计理念，将强定位与深度理解解耦，利用Grounding DINO作为视觉模块，LLaVA-OneVision多模态大模型作为认知模块，并引入时空融合模块和渐进式三阶段训练策略。

Result: LLMTrack在实例描述、交互识别和视频摘要方面达到最先进性能，同时保持跟踪稳定性。

Conclusion: LLMTrack在BenSMOT基准测试中表现出色，显著优于现有方法，同时在实例描述、交互识别和视频摘要方面保持强大的跟踪稳定性。

Abstract: Traditional Multi-Object Tracking (MOT) systems have achieved remarkable precision in localization and association, effectively answering \textit{where} and \textit{who}. However, they often function as autistic observers, capable of tracing geometric paths but blind to the semantic \textit{what} and \textit{why} behind object behaviors. To bridge the gap between geometric perception and cognitive reasoning, we propose \textbf{LLMTrack}, a novel end-to-end framework for Semantic Multi-Object Tracking (SMOT). We adopt a bionic design philosophy that decouples strong localization from deep understanding, utilizing Grounding DINO as the eyes and the LLaVA-OneVision multimodal large model as the brain. We introduce a Spatio-Temporal Fusion Module that aggregates instance-level interaction features and video-level contexts, enabling the Large Language Model (LLM) to comprehend complex trajectories. Furthermore, we design a progressive three-stage training strategy, Visual Alignment, Temporal Fine-tuning, and Semantic Injection via LoRA to efficiently adapt the massive model to the tracking domain. Extensive experiments on the BenSMOT benchmark demonstrate that LLMTrack achieves state-of-the-art performance, significantly outperforming existing methods in instance description, interaction recognition, and video summarization while maintaining robust tracking stability.

</details>


### [48] [ArrowGEV: Grounding Events in Video via Learning the Arrow of Time](https://arxiv.org/abs/2601.06559)
*Fangxu Yu,Ziyao Lu,Liqiang Niu,Fandong Meng,Jie Zhou*

Main category: cs.CV

TL;DR: ArrowGEV通过强化学习框架建模时间方向性，提升视频事件定位和方向性理解能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅训练模型关联前向视频中的事件与时间戳，忽略了事件的时间结构和方向性，限制了模型的鲁棒性和泛化能力。

Method: 提出ArrowGEV框架，将事件分为时间敏感和时间不敏感两类，分别设计奖励机制：时间敏感事件鼓励区分前后向视频，时间不敏感事件要求跨方向一致定位。

Result: 实验表明ArrowGEV不仅提高了定位精度和时间方向性识别能力，还增强了通用视频理解和推理能力。

Conclusion: ArrowGEV通过强化学习框架显式建模时间方向性，显著提升了事件定位和时间方向性理解的能力，同时增强了通用视频理解和推理能力。

Abstract: Grounding events in videos serves as a fundamental capability in video analysis. While Vision-Language Models (VLMs) are increasingly employed for this task, existing approaches predominantly train models to associate events with timestamps in the forward video only. This paradigm hinders VLMs from capturing the inherent temporal structure and directionality of events, thereby limiting robustness and generalization. To address this limitation, inspired by the arrow of time in physics, which characterizes the intrinsic directionality of temporal processes, we propose ArrowGEV, a reinforcement learning framework that explicitly models temporal directionality in events to improve both event grounding and temporal directionality understanding in VLMs. Specifically, we categorize events into time-sensitive (e.g., putting down a bag) and time-insensitive (e.g., holding a towel in the left hand). The former denote events whose reversal substantially alters their meaning, while the latter remain semantically unchanged under reversal. For time-sensitive events, ArrowGEV introduces a reward that encourages VLMs to discriminate between forward and backward videos, whereas for time-insensitive events, it enforces consistent grounding across both directions. Extensive experiments demonstrate that ArrowGEV not only improves grounding precision and temporal directionality recognition, but also enhances general video understanding and reasoning ability.

</details>


### [49] [QCaption: Video Captioning and Q&A through Fusion of Large Multimodal Models](https://arxiv.org/abs/2601.06566)
*Jiale Wang,Gee Wah Ng,Lee Onn Mak,Randall Cher,Ng Ding Hei Ryan,Davis Wang*

Main category: cs.CV

TL;DR: QCaption通过融合关键帧提取、LMM和LLM，显著提升视频字幕和问答性能，支持本地部署。


<details>
  <summary>Details</summary>
Motivation: 提升视频分析和问答任务的性能，同时支持本地部署。

Method: 提出QCaption，一个结合关键帧提取、LMM和LLM的融合模型，实现文本、图像和视频的集成分析。

Result: 实验结果显示，QCaption在视频字幕和问答任务中分别实现了44.2%和48.9%的性能提升。

Conclusion: QCaption展示了模型融合方法在视频分析中的潜力，通过结合关键帧提取、大型多模态模型（LMM）和大型语言模型（LLM），显著提升了视频字幕和问答任务的性能。

Abstract: This paper introduces QCaption, a novel video captioning and Q&A pipeline that enhances video analytics by fusing three models: key frame extraction, a Large Multimodal Model (LMM) for image-text analysis, and a Large Language Model (LLM) for text analysis. This approach enables integrated analysis of text, images, and video, achieving performance improvements over existing video captioning and Q&A models; all while remaining fully self-contained, adept for on-premises deployment. Experimental results using QCaption demonstrated up to 44.2% and 48.9% improvements in video captioning and Q&A tasks, respectively. Ablation studies were also performed to assess the role of LLM on the fusion on the results. Moreover, the paper proposes and evaluates additional video captioning approaches, benchmarking them against QCaption and existing methodologies. QCaption demonstrate the potential of adopting a model fusion approach in advancing video analytics.

</details>


### [50] [APEX: Learning Adaptive Priorities for Multi-Objective Alignment in Vision-Language Generation](https://arxiv.org/abs/2601.06574)
*Dongliang Chen,Xinlin Zhuang,Junjie Xu,Luojian Xie,Zehui Wang,Jiaxi Zhuang,Haolin Yang,Liang Dou,Xiao He,Xingjiao Wu,Ying Qian*

Main category: cs.CV

TL;DR: APEX通过自适应归一化和优先级调度，解决了多目标对齐中的优化不平衡问题，提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 静态线性标量化在多目标对齐中常因异构奖励导致优化不平衡，模型容易过拟合高方差、高响应性目标（如OCR），而忽视感知目标。

Method: 提出了APEX方法，包括Dual-Stage Adaptive Normalization和P^3 Adaptive Priorities，用于稳定异构奖励并动态调度目标。

Result: 在Stable Diffusion 3.5上，APEX实现了对四个异构目标的平衡优化，PickScore提升+1.31，DeQA提升+0.35，Aesthetics提升+0.53，同时保持OCR准确性。

Conclusion: APEX方法通过Dual-Stage Adaptive Normalization和P^3 Adaptive Priorities，有效解决了多目标对齐中的优化不平衡问题，实现了在Stable Diffusion 3.5上对四个异构目标的平衡优化。

Abstract: Multi-objective alignment for text-to-image generation is commonly implemented via static linear scalarization, but fixed weights often fail under heterogeneous rewards, leading to optimization imbalance where models overfit high-variance, high-responsiveness objectives (e.g., OCR) while under-optimizing perceptual goals. We identify two mechanistic causes: variance hijacking, where reward dispersion induces implicit reweighting that dominates the normalized training signal, and gradient conflicts, where competing objectives produce opposing update directions and trigger seesaw-like oscillations. We propose APEX (Adaptive Priority-based Efficient X-objective Alignment), which stabilizes heterogeneous rewards with Dual-Stage Adaptive Normalization and dynamically schedules objectives via P^3 Adaptive Priorities that combine learning potential, conflict penalty, and progress need. On Stable Diffusion 3.5, APEX achieves improved Pareto trade-offs across four heterogeneous objectives, with balanced gains of +1.31 PickScore, +0.35 DeQA, and +0.53 Aesthetics while maintaining competitive OCR accuracy, mitigating the instability of multi-objective alignment.

</details>


### [51] [Sissi: Zero-shot Style-guided Image Synthesis via Semantic-style Integration](https://arxiv.org/abs/2601.06605)
*Yingying Deng,Xiangyu He,Fan Tang,Weiming Dong,Xucheng Yin*

Main category: cs.CV

TL;DR: 本文提出了一种无需训练的框架，通过动态语义-风格集成（DSSI）机制，实现了高保真度的风格化，并在语义-风格平衡和视觉质量上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的文本引导图像生成方法依赖于特定任务的重新训练或昂贵的反转过程，这些方法可能损害内容完整性、降低风格保真度，并在语义提示遵循和风格对齐之间产生不满意的权衡。

Method: 该方法将风格引导合成重新定义为上下文学习任务，利用预训练的基于ReFlow的修复模型，通过多模态注意力融合无缝整合语义内容与目标风格。

Result: 实验表明，该方法实现了高保真度的风格化，具有优越的语义-风格平衡和视觉质量，为复杂且易产生伪影的现有方法提供了一种简单而强大的替代方案。

Conclusion: 本文提出了一种无需训练的框架，通过动态语义-风格集成（DSSI）机制有效解决了多模态注意力融合中的不平衡和噪声敏感性问题，实现了高保真度的风格化，并在语义-风格平衡和视觉质量上表现出色。

Abstract: Text-guided image generation has advanced rapidly with large-scale diffusion models, yet achieving precise stylization with visual exemplars remains difficult. Existing approaches often depend on task-specific retraining or expensive inversion procedures, which can compromise content integrity, reduce style fidelity, and lead to an unsatisfactory trade-off between semantic prompt adherence and style alignment. In this work, we introduce a training-free framework that reformulates style-guided synthesis as an in-context learning task. Guided by textual semantic prompts, our method concatenates a reference style image with a masked target image, leveraging a pretrained ReFlow-based inpainting model to seamlessly integrate semantic content with the desired style through multimodal attention fusion. We further analyze the imbalance and noise sensitivity inherent in multimodal attention fusion and propose a Dynamic Semantic-Style Integration (DSSI) mechanism that reweights attention between textual semantic and style visual tokens, effectively resolving guidance conflicts and enhancing output coherence. Experiments show that our approach achieves high-fidelity stylization with superior semantic-style balance and visual quality, offering a simple yet powerful alternative to complex, artifact-prone prior methods.

</details>


### [52] [Boosting Overlapping Organoid Instance Segmentation Using Pseudo-Label Unmixing and Synthesis-Assisted Learning](https://arxiv.org/abs/2601.06642)
*Gui Huang,Kangyuan Zheng,Xuan Cai,Jiaqi Wang,Jianjia Zhang,Kaida Ning,Wenbo Wei,Yujuan Zhu,Jiong Zhang,Mengting Liu*

Main category: cs.CV

TL;DR: 本文提出了一种结合伪标签解混（PLU）和基于轮廓合成的半监督学习方法，有效解决了类器官实例分割中的重叠问题，显著提升了标签效率，为精准医学的高通量应用提供了新可能。


<details>
  <summary>Details</summary>
Motivation: 类器官是人体组织的复杂体外模型，对医学研究至关重要，但其准确实例分割受到高质量标注数据集稀缺和显微镜成像中普遍重叠的限制。虽然半监督学习（SSL）可以缓解对稀缺标注数据的依赖，但传统SSL框架在重叠区域容易受到噪声伪标签的偏见影响。

Method: 我们提出了伪标签解混（PLU）方法，识别重叠实例的错误伪标签，并通过实例分解重新生成类器官标签。对于图像合成，我们采用基于轮廓的方法高效合成类器官实例，特别是重叠情况。在图像合成前对伪标签进行实例级增强（IA）进一步提升了合成数据（SD）的效果。

Result: 在两个类器官数据集上的严格实验证明了我们方法的有效性，仅使用10%的标注数据就达到了与全监督模型相当的性能，并取得了最先进的结果。消融研究验证了PLU、基于轮廓的合成和增强感知训练的贡献。

Conclusion: 通过解决伪标签和合成层面的重叠问题，我们的工作推动了可扩展、标签高效的类器官分析，为精准医学中的高通量应用开辟了新潜力。

Abstract: Organoids, sophisticated in vitro models of human tissues, are crucial for medical research due to their ability to simulate organ functions and assess drug responses accurately. Accurate organoid instance segmentation is critical for quantifying their dynamic behaviors, yet remains profoundly limited by high-quality annotated datasets and pervasive overlap in microscopy imaging. While semi-supervised learning (SSL) offers a solution to alleviate reliance on scarce labeled data, conventional SSL frameworks suffer from biases induced by noisy pseudo-labels, particularly in overlapping regions. Synthesis-assisted SSL (SA-SSL) has been proposed for mitigating training biases in semi-supervised semantic segmentation. We present the first adaptation of SA-SSL to organoid instance segmentation and reveal that SA-SSL struggles to disentangle intertwined organoids, often misrepresenting overlapping instances as a single entity. To overcome this, we propose Pseudo-Label Unmixing (PLU), which identifies erroneous pseudo-labels for overlapping instances and then regenerates organoid labels through instance decomposition. For image synthesis, we apply a contour-based approach to synthesize organoid instances efficiently, particularly for overlapping cases. Instance-level augmentations (IA) on pseudo-labels before image synthesis further enhances the effect of synthetic data (SD). Rigorous experiments on two organoid datasets demonstrate our method's effectiveness, achieving performance comparable to fully supervised models using only 10% labeled data, and state-of-the-art results. Ablation studies validate the contributions of PLU, contour-based synthesis, and augmentation-aware training. By addressing overlap at both pseudo-label and synthesis levels, our work advances scalable, label-efficient organoid analysis, unlocking new potential for high-throughput applications in precision medicine.

</details>


### [53] [eSkiTB: A Synthetic Event-based Dataset for Tracking Skiers](https://arxiv.org/abs/2601.06647)
*Krishna Vinod,Joseph Raj Vishal,Kaustav Chanda,Prithvi Jai Ramesh,Yezhou Yang,Bharatesh Chakravarthi*

Main category: cs.CV

TL;DR: eSkiTB是首个合成事件滑雪追踪数据集，SDTrack在静态叠加场景中表现优于RGB方法，展示了事件相机在滑雪追踪中的潜力。


<details>
  <summary>Details</summary>
Motivation: 由于运动模糊、静态叠加和杂乱背景，RGB广播素材中的滑雪者追踪具有挑战性，而事件相机因其异步对比感应天然具有对这些伪影的鲁棒性。

Method: 通过直接视频到事件转换生成合成事件数据集eSkiTB，并使用SDTrack（尖峰变压器）与STARK（RGB变压器）进行对比。

Result: SDTrack在静态叠加主导的场景中表现出更强的鲁棒性，IoU达到0.685，优于RGB方法20.0个百分点；在整个数据集中平均IoU为0.711。

Conclusion: eSkiTB数据集为冬季运动中的事件追踪提供了首个受控环境，展示了事件相机在滑雪追踪中的潜力。

Abstract: Tracking skiers in RGB broadcast footage is challenging due to motion blur, static overlays, and clutter that obscure the fast-moving athlete. Event cameras, with their asynchronous contrast sensing, offer natural robustness to such artifacts, yet a controlled benchmark for winter-sport tracking has been missing. We introduce event SkiTB (eSkiTB), a synthetic event-based ski tracking dataset generated from SkiTB using direct video-to-event conversion without neural interpolation, enabling an iso-informational comparison between RGB and event modalities. Benchmarking SDTrack (spiking transformer) against STARK (RGB transformer), we find that event-based tracking is substantially resilient to broadcast clutter in scenes dominated by static overlays, achieving 0.685 IoU, outperforming RGB by +20.0 points. Across the dataset, SDTrack attains a mean IoU of 0.711, demonstrating that temporal contrast is a reliable cue for tracking ballistic motion in visually congested environments. eSkiTB establishes the first controlled setting for event-based tracking in winter sports and highlights the promise of event cameras for ski tracking. The dataset and code will be released at https://github.com/eventbasedvision/eSkiTB.

</details>


### [54] [Quantification and Classification of Carbon Nanotubes in Electron Micrographs using Vision Foundation Models](https://arxiv.org/abs/2601.06673)
*Sanjay Pradeep,Chen Wang,Matthew M. Dahm,Jeff D. Eldredge,Candace S. J. Tsai*

Main category: cs.CV

TL;DR: 利用视觉基础模型自动化电子显微镜图像中碳纳米管的量化和分类，显著提高准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 电子显微镜图像中碳纳米管形态的准确表征对暴露评估和毒理学研究至关重要，但目前的工作流程依赖缓慢且主观的手动分割。

Method: 提出了一个统一框架，利用视觉基础模型自动量化和分类电子显微镜图像中的碳纳米管。包括基于Segment Anything Model（SAM）的交互式量化工具和利用DINOv2视觉变换器的分类流程。

Result: 在1,800张TEM图像的数据集上评估，该架构在区分四种不同碳纳米管形态时达到95.5%的准确率，显著优于当前基线。

Conclusion: 整合零样本分割与自监督特征学习实现了高通量、可重复的纳米材料分析，将劳动密集型的瓶颈转变为可扩展的数据驱动流程。

Abstract: Accurate characterization of carbon nanotube morphologies in electron microscopy images is vital for exposure assessment and toxicological studies, yet current workflows rely on slow, subjective manual segmentation. This work presents a unified framework leveraging vision foundation models to automate the quantification and classification of CNTs in electron microscopy images. First, we introduce an interactive quantification tool built on the Segment Anything Model (SAM) that segments particles with near-perfect accuracy using minimal user input. Second, we propose a novel classification pipeline that utilizes these segmentation masks to spatially constrain a DINOv2 vision transformer, extracting features exclusively from particle regions while suppressing background noise. Evaluated on a dataset of 1,800 TEM images, this architecture achieves 95.5% accuracy in distinguishing between four different CNT morphologies, significantly outperforming the current baseline despite using a fraction of the training data. Crucially, this instance-level processing allows the framework to resolve mixed samples, correctly classifying distinct particle types co-existing within a single field of view. These results demonstrate that integrating zero-shot segmentation with self-supervised feature learning enables high-throughput, reproducible nanomaterial analysis, transforming a labor-intensive bottleneck into a scalable, data-driven process.

</details>


### [55] [When Humans Judge Irises: Pupil Size Normalization as an Aid and Synthetic Irises as a Challenge](https://arxiv.org/abs/2601.06725)
*Mahsa Mitcheff,Adam Czajka*

Main category: cs.CV

TL;DR: 研究发现瞳孔大小对齐对虹膜匹配至关重要，人类对合成虹膜的判断准确率低于真实虹膜。


<details>
  <summary>Details</summary>
Motivation: 探讨人类在虹膜验证中的表现，尤其是在处理退化样本或判断样本真实性时的需求。

Method: 通过两种受控场景研究人类在虹膜验证中的表现：(a) 不同瞳孔大小下，有/无瞳孔大小线性/非线性对齐；(b) 使用合成生成的虹膜图像对（真实与冒名）。

Result: 瞳孔大小归一化显著提高验证准确率；人类能区分真实或合成虹膜对，但在比较真实虹膜与高质量合成虹膜时准确率下降。

Conclusion: 研究强调了瞳孔大小对齐在人类参与的虹膜匹配任务中的重要性，并指出尽管现代生成模型具有高保真度，但同眼合成虹膜图像更常被人类误判为不同眼图像。

Abstract: Iris recognition is a mature biometric technology offering remarkable precision and speed, and allowing for large-scale deployments to populations exceeding a billion enrolled users (e.g., AADHAAR in India). However, in forensic applications, a human expert may be needed to review and confirm a positive identification before an iris matching result can be presented as evidence in court, especially in cases where processed samples are degraded (e.g., in post-mortem cases) or where there is a need to judge whether the sample is authentic, rather than a result of a presentation attack.
  This paper presents a study that examines human performance in iris verification in two controlled scenarios: (a) under varying pupil sizes, with and without a linear/nonlinear alignment of the pupil size between compared images, and (b) when both genuine and impostor iris image pairs are synthetically generated. The results demonstrate that pupil size normalization carried out by a modern autoencoder-based identity-preserving image-to-image translation model significantly improves verification accuracy. Participants were also able to determine whether iris pairs corresponded to the same or different eyes when both images were either authentic or synthetic. However, accuracy declined when subjects were comparing authentic irises against high-quality, same-eye synthetic counterparts. These findings (a) demonstrate the importance of pupil-size alignment for iris matching tasks in which humans are involved, and (b) indicate that despite the high fidelity of modern generative models, same-eye synthetic iris images are more often judged by humans as different-eye images, compared to same-eye authentic image pairs.
  We offer data and human judgments along with this paper to allow full replicability of this study and future works.

</details>


### [56] [Benchmarking Egocentric Clinical Intent Understanding Capability for Medical Multimodal Large Language Models](https://arxiv.org/abs/2601.06750)
*Shaonan Liu,Guo Yu,Xiaoling Luo,Shiyi Zheng,Wenting Chen,Jie Liu,Linlin Shen*

Main category: cs.CV

TL;DR: MedGaze-Bench是首个利用临床医生注视评估多模态大语言模型临床意图理解的基准测试，揭示当前模型在空间、时间和标准意图上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试未能评估临床意图理解这一关键能力，而Med-MLLMs在真实部署中需要此能力。视觉同质性、严格时间因果依赖和隐式安全协议是主要挑战。

Method: 提出了MedGaze-Bench基准测试，利用临床医生注视作为认知光标，评估手术、急诊模拟和诊断解读中的意图理解能力。通过三维临床意图框架（空间、时间、标准意图）和Trap QA机制，测试模型的可靠性。

Result: 实验显示当前MLLMs因过度依赖全局特征，在自我中心意图理解上表现不佳，易产生幻觉和盲目服从无效指令。

Conclusion: 当前的多模态大语言模型（MLLMs）在真实临床场景中表现不佳，主要依赖全局特征导致意图理解不足，产生虚假观察和盲目接受无效指令。MedGaze-Bench通过空间、时间和标准意图框架，为临床意图理解提供了首个基准测试。

Abstract: Medical Multimodal Large Language Models (Med-MLLMs) require egocentric clinical intent understanding for real-world deployment, yet existing benchmarks fail to evaluate this critical capability. To address these challenges, we introduce MedGaze-Bench, the first benchmark leveraging clinician gaze as a Cognitive Cursor to assess intent understanding across surgery, emergency simulation, and diagnostic interpretation. Our benchmark addresses three fundamental challenges: visual homogeneity of anatomical structures, strict temporal-causal dependencies in clinical workflows, and implicit adherence to safety protocols. We propose a Three-Dimensional Clinical Intent Framework evaluating: (1) Spatial Intent: discriminating precise targets amid visual noise, (2) Temporal Intent: inferring causal rationale through retrospective and prospective reasoning, and (3) Standard Intent: verifying protocol compliance through safety checks. Beyond accuracy metrics, we introduce Trap QA mechanisms to stress-test clinical reliability by penalizing hallucinations and cognitive sycophancy. Experiments reveal current MLLMs struggle with egocentric intent due to over-reliance on global features, leading to fabricated observations and uncritical acceptance of invalid instructions.

</details>


### [57] [The Normalized Difference Layer: A Differentiable Spectral Index Formulation for Deep Learning](https://arxiv.org/abs/2601.06777)
*Ali Lotfi,Adam Carter,Mohammad Meysami,Thuan Ha,Kwabena Nketia,Steve Shirtliffe*

Main category: cs.CV

TL;DR: 提出可学习波段系数的归一化差异层，保持光照不变性和输出有界性，实验显示高效且鲁棒。


<details>
  <summary>Details</summary>
Motivation: 传统归一化差异指数虽可靠但系数固定，限制了其在特定学习任务中的适应性。

Method: 引入了一种可微分的神经网络模块——归一化差异层，通过softplus重新参数化确保正系数和有界分母，并提出了完整的数学框架和端到端训练算法。

Result: 实验表明，使用该层的模型在分类准确率上与标准多层感知器相当，但参数减少约75%，且对乘性噪声具有更好的鲁棒性。

Conclusion: 提出的归一化差异层（Normalized Difference Layer）在保持经典归一化差异指数优点的同时，通过可学习的波段系数显著提升了模型适应特定学习任务的能力，且参数效率更高。

Abstract: Normalized difference indices have been a staple in remote sensing for decades. They stay reliable under lighting changes produce bounded values and connect well to biophysical signals. Even so, they are usually treated as a fixed pre processing step with coefficients set to one, which limits how well they can adapt to a specific learning task. In this study, we introduce the Normalized Difference Layer that is a differentiable neural network module. The proposed method keeps the classical idea but learns the band coefficients from data. We present a complete mathematical framework for integrating this layer into deep learning architectures that uses softplus reparameterization to ensure positive coefficients and bounded denominators. We describe forward and backward pass algorithms enabling end to end training through backpropagation. This approach preserves the key benefits of normalized differences, namely illumination invariance and outputs bounded to $[-1,1]$ while allowing gradient descent to discover task specific band weightings. We extend the method to work with signed inputs, so the layer can be stacked inside larger architectures. Experiments show that models using this layer reach similar classification accuracy to standard multilayer perceptrons while using about 75\% fewer parameters. They also handle multiplicative noise well, at 10\% noise accuracy drops only 0.17\% versus 3.03\% for baseline MLPs. The learned coefficient patterns stay consistent across different depths.

</details>


### [58] [CliffordNet: All You Need is Geometric Algebra](https://arxiv.org/abs/2601.06793)
*Zhongping Ji*

Main category: cs.CV

TL;DR: CliffordNet是一种基于几何代数的视觉架构，通过Clifford几何积统一特征交互，实现了高效且高性能的模型，参数更少但性能媲美或超越传统模型。


<details>
  <summary>Details</summary>
Motivation: 挑战现有计算机视觉架构依赖启发式模块（如空间混合器和通道混合器）的范式，回归数学第一性原理，探索几何代数的潜力。

Method: 基于几何代数，提出了Clifford代数网络（CAN），利用Clifford几何积统一了特征交互机制，替代了传统的空间混合器和通道混合器模块。

Result: CliffordNet在CIFAR-100上实现了76.41%的准确率（Nano变体，1.4M参数），与ResNet-18（11.2M参数）相当，且Base变体达到78.05%的SOTA性能。

Conclusion: CliffordNet通过几何代数提出了一种全新的视觉架构，证明了仅通过严格的代数完备局部交互即可实现全局理解，可能标志着‘几何即所需’的范式转变。

Abstract: Modern computer vision architectures, from CNNs to Transformers, predominantly rely on the stacking of heuristic modules: spatial mixers (Attention/Conv) followed by channel mixers (FFNs). In this work, we challenge this paradigm by returning to mathematical first principles. We propose the \textbf{Clifford Algebra Network (CAN)}, also referred to as CliffordNet, a vision backbone grounded purely in Geometric Algebra. Instead of engineering separate modules for mixing and memory, we derive a unified interaction mechanism based on the \textbf{Clifford Geometric Product} ($uv = u \cdot v + u \wedge v$). This operation ensures algebraic completeness regarding the Geometric Product by simultaneously capturing feature coherence (via the generalized inner product) and structural variation (via the exterior wedge product).
  Implemented via an efficient sparse rolling mechanism with \textbf{strict linear complexity $\mathcal{O}(N)$}, our model reveals a surprising emergent property: the geometric interaction is so representationally dense that standard Feed-Forward Networks (FFNs) become redundant. Empirically, CliffordNet establishes a new Pareto frontier: our \textbf{Nano} variant achieves \textbf{76.41\%} accuracy on CIFAR-100 with only \textbf{1.4M} parameters, effectively matching the heavy-weight ResNet-18 (11.2M) with \textbf{$8\times$ fewer parameters}, while our \textbf{Base} variant sets a new SOTA for tiny models at \textbf{78.05\%}. Our results suggest that global understanding can emerge solely from rigorous, algebraically complete local interactions, potentially signaling a shift where \textit{geometry is all you need}. Code is available at https://github.com/ParaMind2025/CAN.

</details>


### [59] [SARA: Scene-Aware Reconstruction Accelerator](https://arxiv.org/abs/2601.06831)
*Jee Won Lee,Hansol Lim,Minhyeok Im,Dohyeon Lee,Jongseong Brad Choi*

Main category: cs.CV

TL;DR: SARA是一种几何驱动的SfM配对选择模块，通过优先考虑重建信息量（重叠和视差）显著提升效率和精度，减少误差并降低计算复杂度。


<details>
  <summary>Details</summary>
Motivation: 传统SfM流程仅基于视觉相似性选择配对，忽略了几何信息的重要性，导致计算复杂度高且重建效果不佳。

Method: SARA引入了一种基于重建信息量的几何优先配对选择方法，通过轻量级的预匹配阶段（使用互最近邻和RANSAC）估计重叠和视差，并构建信息加权生成树（IWST），增强闭环、长基线锚点和弱视图的强化。

Result: 相比传统方法，SARA将旋转误差降低了46.5±5.5%，平移误差降低了12.5±6.5%，同时实现了最高50倍的加速（配对数量从30,848减少到580）。

Conclusion: SARA通过几何驱动的配对选择方法显著提升了Structure-from-Motion（SfM）的效率和精度，减少了旋转和平移误差，同时大幅降低了计算复杂度。

Abstract: We present SARA (Scene-Aware Reconstruction Accelerator), a geometry-driven pair selection module for Structure-from-Motion (SfM). Unlike conventional pipelines that select pairs based on visual similarity alone, SARA introduces geometry-first pair selection by scoring reconstruction informativeness - the product of overlap and parallax - before expensive matching. A lightweight pre-matching stage uses mutual nearest neighbors and RANSAC to estimate these cues, then constructs an Information-Weighted Spanning Tree (IWST) augmented with targeted edges for loop closure, long-baseline anchors, and weak-view reinforcement. Compared to exhaustive matching, SARA reduces rotation errors by 46.5+-5.5% and translation errors by 12.5+-6.5% across modern learned detectors, while achieving at most 50x speedup through 98% pair reduction (from 30,848 to 580 pairs). This reduces matching complexity from quadratic to quasi-linear, maintaining within +-3% of baseline reconstruction metrics for 3D Gaussian Splatting and SVRaster.

</details>


### [60] [Enhancing Low-resolution Image Representation Through Normalizing Flows](https://arxiv.org/abs/2601.06834)
*Chenglong Bao,Tongyao Pang,Zuowei Shen,Dihan Zheng,Yihang Zou*

Main category: cs.CV

TL;DR: LR2Flow结合小波紧框架与归一化流，有效学习低分辨率表示，适用于多种图像处理任务。


<details>
  <summary>Details</summary>
Motivation: 低分辨率图像表示能降低存储和传输成本，但需保留关键视觉内容并准确重建原图。

Method: 提出LR2Flow非线性框架，结合小波紧框架块与归一化流，进行重建误差分析并设计可逆神经网络。

Result: 在图像缩放、压缩和去噪等任务中，学习到的表示效果显著，框架鲁棒性强。

Conclusion: LR2Flow框架通过将小波紧框架块与归一化流结合，有效学习了低分辨率图像表示，并在多种图像处理任务中表现出色。

Abstract: Low-resolution image representation is a special form of sparse representation that retains only low-frequency information while discarding high-frequency components. This property reduces storage and transmission costs and benefits various image processing tasks. However, a key challenge is to preserve essential visual content while maintaining the ability to accurately reconstruct the original images. This work proposes LR2Flow, a nonlinear framework that learns low-resolution image representations by integrating wavelet tight frame blocks with normalizing flows. We conduct a reconstruction error analysis of the proposed network, which demonstrates the necessity of designing invertible neural networks in the wavelet tight frame domain. Experimental results on various tasks, including image rescaling, compression, and denoising, demonstrate the effectiveness of the learned representations and the robustness of the proposed framework.

</details>


### [61] [OSCAR: Optical-aware Semantic Control for Aleatoric Refinement in Sar-to-Optical Translation](https://arxiv.org/abs/2601.06835)
*Hyunseo Lee,Sang Min Kim,Ho Kyung Shin,Taeheon Kim,Woo-Jeoung Nam*

Main category: cs.CV

TL;DR: 提出一种SAR-to-Optical翻译框架，结合语义对齐、生成指导和不确定性建模，显著提升图像质量。


<details>
  <summary>Details</summary>
Motivation: 解决SAR数据因斑点噪声和几何失真导致的语义误解、纹理合成模糊和结构幻觉问题。

Method: 整合了三个核心技术贡献：(i) 跨模态语义对齐，通过光学教师模型向SAR学生模型传递语义先验；(ii) 语义基础生成指导，通过语义基础ControlNet结合全局上下文和局部空间指导；(iii) 不确定性感知目标，动态调整重建焦点以减少斑点噪声引起的伪影。

Result: 实验证明，该方法在感知质量和语义一致性上优于现有技术。

Conclusion: 提出的SAR-to-Optical（S2O）翻译框架通过跨模态语义对齐、语义基础生成指导和不确定性感知目标，显著提升了图像翻译的感知质量和语义一致性。

Abstract: Synthetic Aperture Radar (SAR) provides robust all-weather imaging capabilities; however, translating SAR observations into photo-realistic optical images remains a fundamentally ill-posed problem. Current approaches are often hindered by the inherent speckle noise and geometric distortions of SAR data, which frequently result in semantic misinterpretation, ambiguous texture synthesis, and structural hallucinations. To address these limitations, a novel SAR-to-Optical (S2O) translation framework is proposed, integrating three core technical contributions: (i) Cross-Modal Semantic Alignment, which establishes an Optical-Aware SAR Encoder by distilling robust semantic priors from an Optical Teacher into a SAR Student (ii) Semantically-Grounded Generative Guidance, realized by a Semantically-Grounded ControlNet that integrates class-aware text prompts for global context with hierarchical visual prompts for local spatial guidance; and (iii) an Uncertainty-Aware Objective, which explicitly models aleatoric uncertainty to dynamically modulate the reconstruction focus, effectively mitigating artifacts caused by speckle-induced ambiguity. Extensive experiments demonstrate that the proposed method achieves superior perceptual quality and semantic consistency compared to state-of-the-art approaches.

</details>


### [62] [PRISM: Color-Stratified Point Cloud Sampling](https://arxiv.org/abs/2601.06839)
*Hansol Lim,Minhyeok Im,Jongseong Brad Choi*

Main category: cs.CV

TL;DR: PRISM是一种基于颜色引导的分层采样方法，通过分配采样密度与颜色多样性成正比，保留了纹理丰富区域，减少了同质表面，适用于3D重建任务。


<details>
  <summary>Details</summary>
Motivation: 传统下采样方法（如随机采样、体素网格、法线空间采样）强制空间均匀性而忽略了光度内容，而PRISM基于观察到独特场景特征通常表现出颜色多样性，而重复冗余特征在颜色上是同质的。

Method: PRISM将RGB颜色空间作为分层域，并对每个颜色箱施加最大容量k，以此实现颜色引导的分层采样。

Result: PRISM生成了更稀疏的点云，同时保留了3D重建任务所需的关键特征。

Conclusion: PRISM通过将采样密度与颜色多样性成正比分配，有效保留了纹理丰富的区域，同时大幅减少了视觉上同质的表面，从而在3D重建任务中保留了关键特征。

Abstract: We present PRISM, a novel color-guided stratified sampling method for RGB-LiDAR point clouds. Our approach is motivated by the observation that unique scene features often exhibit chromatic diversity while repetitive, redundant features are homogeneous in color. Conventional downsampling methods (Random Sampling, Voxel Grid, Normal Space Sampling) enforce spatial uniformity while ignoring this photometric content. In contrast, PRISM allocates sampling density proportional to chormatic diversity. By treating RGB color space as the stratification domain and imposing a maximum capacity k per color bin, the method preserves texture-rich regions with high color variation while substantially reducing visually homogeneous surfaces. This shifts the sampling space from spatial coverage to visual complexity to produce sparser point clouds that retain essential features for 3D reconstruction tasks.

</details>


### [63] [Speak While Watching: Unleashing TRUE Real-Time Video Understanding Capability of Multimodal Large Language Models](https://arxiv.org/abs/2601.06843)
*Junyan Lin,Junlong Tong,Hao Wu,Jialiang Zhang,Jinming Liu,Xin Jin,Xiaoyu Shen*

Main category: cs.CV

TL;DR: 提出并行流式框架，通过三种设计放松位置连续性约束，实现感知与生成并行处理，显著降低延迟，为实时视频理解提供高效解决方案。


<details>
  <summary>Details</summary>
Motivation: 现有MLLMs在实时视频理解中受限于全局位置连续性约束，导致感知与生成必须顺序执行，无法实现真正的实时交互。

Method: 通过设计Overlapped、Group-Decoupled和Gap-Isolated三种方法，放松了标准位置编码方案中的全局位置连续性约束，实现了感知与生成的并行处理。

Result: 实验表明，Group-Decoupled设计在效率与性能间取得了最佳平衡，显著降低了延迟，同时保持了高流畅性和准确性。在平衡感知-生成工作负载下，框架可实现高达2倍的加速。

Conclusion: 提出的并行流式框架通过三种设计（重叠、组解耦和间隙隔离）有效解决了全局位置连续性约束，实现了感知与生成的并行处理，显著降低了延迟，为实时视频理解系统提供了可行的解决方案。

Abstract: Multimodal Large Language Models (MLLMs) have achieved strong performance across many tasks, yet most systems remain limited to offline inference, requiring complete inputs before generating outputs. Recent streaming methods reduce latency by interleaving perception and generation, but still enforce a sequential perception-generation cycle, limiting real-time interaction. In this work, we target a fundamental bottleneck that arises when extending MLLMs to real-time video understanding: the global positional continuity constraint imposed by standard positional encoding schemes. While natural in offline inference, this constraint tightly couples perception and generation, preventing effective input-output parallelism. To address this limitation, we propose a parallel streaming framework that relaxes positional continuity through three designs: Overlapped, Group-Decoupled, and Gap-Isolated. These designs enable simultaneous perception and generation, allowing the model to process incoming inputs while producing responses in real time. Extensive experiments reveal that Group-Decoupled achieves the best efficiency-performance balance, maintaining high fluency and accuracy while significantly reducing latency. We further show that the proposed framework yields up to 2x acceleration under balanced perception-generation workloads, establishing a principled pathway toward speak-while-watching real-time systems. We make all our code publicly available: https://github.com/EIT-NLP/Speak-While-Watching.

</details>


### [64] [MedGround: Bridging the Evidence Gap in Medical Vision-Language Models with Verified Grounding Data](https://arxiv.org/abs/2601.06847)
*Mengmeng Zhang,Xiaoping Wu,Hao Luo,Fan Wang,Yisheng Lv*

Main category: cs.CV

TL;DR: MedGround是一个自动化流程，用于生成高质量的医学引用定位数据，显著提升了VLM的视觉基础能力。


<details>
  <summary>Details</summary>
Motivation: 解决Vision-Language Models（VLMs）在临床叙述中视觉基础不足的问题，这一问题源于高质量、大规模的临床引用定位数据稀缺。

Method: 提出了MedGround，一个自动化流程，将分割资源转化为高质量的医学引用定位数据。利用专家掩码作为空间锚点，精确推导定位目标，提取形状和空间线索，并指导VLM合成反映形态和位置的自然、临床基础查询。多阶段验证系统确保数据严谨性，包括严格的格式检查、几何和医学先验规则以及基于图像的视觉判断。

Result: 提出了MedGround-35K，一个新的多模态医学数据集。实验表明，使用该数据集训练的VLM在引用定位性能、多对象语义消歧和泛化能力上均有提升。

Conclusion: MedGround被提出作为一种可扩展的数据驱动方法，用于将医学语言锚定到可验证的视觉证据上。实验证明，使用MedGround-35K训练的VLM在引用定位性能、多对象语义消歧以及对未见过的定位设置的泛化能力上均有显著提升。

Abstract: Vision-Language Models (VLMs) can generate convincing clinical narratives, yet frequently struggle to visually ground their statements. We posit this limitation arises from the scarcity of high-quality, large-scale clinical referring-localization pairs. To address this, we introduce MedGround, an automated pipeline that transforms segmentation resources into high-quality medical referring grounding data. Leveraging expert masks as spatial anchors, MedGround precisely derives localization targets, extracts shape and spatial cues, and guides VLMs to synthesize natural, clinically grounded queries that reflect morphology and location. To ensure data rigor, a multi-stage verification system integrates strict formatting checks, geometry- and medical-prior rules, and image-based visual judging to filter out ambiguous or visually unsupported samples. Finally, we present MedGround-35K, a novel multimodal medical dataset. Extensive experiments demonstrate that VLMs trained with MedGround-35K consistently achieve improved referring grounding performance, enhance multi-object semantic disambiguation, and exhibit strong generalization to unseen grounding settings. This work highlights MedGround as a scalable, data-driven approach to anchor medical language to verifiable visual evidence. Dataset and code will be released publicly upon acceptance.

</details>


### [65] [MVGGT: Multimodal Visual Geometry Grounded Transformer for Multiview 3D Referring Expression Segmentation](https://arxiv.org/abs/2601.06874)
*Changli Wu,Haodong Wang,Jiayi Ji,Yutian Yao,Chunsai Du,Jihua Kang,Yanwei Fu,Liujuan Cao*

Main category: cs.CV

TL;DR: MV-3DRES任务中，MVGGT框架通过双分支设计和PVSO优化，解决了稀疏视图下的分割问题，并在新基准测试中表现最佳。


<details>
  <summary>Details</summary>
Motivation: 现有3DRES方法依赖高质量点云，但现实场景中设备通常只有稀疏RGB视图和严格延迟要求，需要更高效的解决方案。

Method: 提出了Multimodal Visual Geometry Grounded Transformer (MVGGT)，一种端到端的双分支框架，结合语言信息和稀疏视图几何推理，并通过Per-view No-target Suppression Optimization (PVSO)解决优化障碍。

Result: MVGGT在MVRefer基准测试中表现优异，实现了高精度和快速推理，优于现有方法。

Conclusion: MVGGT框架通过双分支设计和PVSO优化，成功解决了稀疏视图下的3D表达分割问题，并在MVRefer基准测试中表现出色。

Abstract: Most existing 3D referring expression segmentation (3DRES) methods rely on dense, high-quality point clouds, while real-world agents such as robots and mobile phones operate with only a few sparse RGB views and strict latency constraints. We introduce Multi-view 3D Referring Expression Segmentation (MV-3DRES), where the model must recover scene structure and segment the referred object directly from sparse multi-view images. Traditional two-stage pipelines, which first reconstruct a point cloud and then perform segmentation, often yield low-quality geometry, produce coarse or degraded target regions, and run slowly. We propose the Multimodal Visual Geometry Grounded Transformer (MVGGT), an efficient end-to-end framework that integrates language information into sparse-view geometric reasoning through a dual-branch design. Training in this setting exposes a critical optimization barrier, termed Foreground Gradient Dilution (FGD), where sparse 3D signals lead to weak supervision. To resolve this, we introduce Per-view No-target Suppression Optimization (PVSO), which provides stronger and more balanced gradients across views, enabling stable and efficient learning. To support consistent evaluation, we build MVRefer, a benchmark that defines standardized settings and metrics for MV-3DRES. Experiments show that MVGGT establishes the first strong baseline and achieves both high accuracy and fast inference, outperforming existing alternatives. Code and models are publicly available at https://mvggt.github.io.

</details>


### [66] [Unsupervised Domain Adaptation with SAM-RefiSeR for Enhanced Brain Tumor Segmentation](https://arxiv.org/abs/2601.06882)
*Dillan Imans,Phuoc-Nguyen Bui,Duc-Tai Le,Hyunseung Choo*

Main category: cs.CV

TL;DR: SAM-RefiSeR通过无监督域适应提升脑肿瘤分割效果。


<details>
  <summary>Details</summary>
Motivation: 解决脑肿瘤分割中跨域数据分布不一致的问题。

Method: 采用SAM-RefiSeR框架，结合自监督学习和参考细化策略。

Result: 实验表明，该方法在多个数据集上优于现有技术。

Conclusion: SAM-RefiSeR方法在无监督域适应中显著提升了脑肿瘤分割的准确性。

Abstract: Unsupervised Domain Adaptation with SAM-RefiSeR for Enhanced Brain Tumor Segmentation

</details>


### [67] [MixRI: Mixing Features of Reference Images for Novel Object Pose Estimation](https://arxiv.org/abs/2601.06883)
*Xinhang Liu,Jiawei Shi,Zheng Dang,Yuchao Dai*

Main category: cs.CV

TL;DR: MixRI是一种轻量级网络，通过多视角信息直接匹配点和参考图像融合策略，减少参考图像数量和内存需求，实现快速推理和与新物体姿态估计的即时应用。


<details>
  <summary>Details</summary>
Motivation: 解决CAD基础的新物体姿态估计问题，满足实际应用中对内存需求低和推理时间快的要求。

Method: 设计了一个轻量级网络，通过多视角信息直接匹配查询图像和参考图像之间的点，并采用参考图像融合策略减少参考图像数量。

Result: 在BOP挑战赛的七个核心数据集上，尽管使用较少的参考图像，MixRI仍取得了与其他方法相当的结果。

Conclusion: MixRI是一种轻量级网络，能够在无需微调的情况下即时应用于测试时的新物体，实现了与需要更多参考图像和更大网络参数的方法相媲美的结果。

Abstract: We present MixRI, a lightweight network that solves the CAD-based novel object pose estimation problem in RGB images. It can be instantly applied to a novel object at test time without finetuning. We design our network to meet the demands of real-world applications, emphasizing reduced memory requirements and fast inference time. Unlike existing works that utilize many reference images and have large network parameters, we directly match points based on the multi-view information between the query and reference images with a lightweight network. Thanks to our reference image fusion strategy, we significantly decrease the number of reference images, thus decreasing the time needed to process these images and the memory required to store them. Furthermore, with our lightweight network, our method requires less inference time. Though with fewer reference images, experiments on seven core datasets in the BOP challenge show that our method achieves comparable results with other methods that require more reference images and larger network parameters.

</details>


### [68] [CLIMP: Contrastive Language-Image Mamba Pretraining](https://arxiv.org/abs/2601.06891)
*Nimrod Shabtay,Itamar Zimerman,Eli Schwartz,Raja Giryes*

Main category: cs.CV

TL;DR: CLIMP, a Mamba-based vision-language model, outperforms CLIP in efficiency and robustness, supporting variable resolutions and dense captioning retrieval.


<details>
  <summary>Details</summary>
Motivation: To address CLIP's limitations, such as susceptibility to spurious correlations, quadratic scaling with resolution, and fixed context in text encoding.

Method: Replaces both vision and text encoders in CLIP with Mamba, utilizing VMamba for visual spatial inductive biases and an autoregressive text encoder for variable context.

Result: CLIMP surpasses CLIP-ViT-B by 7.5% on ImageNet-O, supports variable resolutions without interpolation, and achieves higher retrieval accuracy with less memory and FLOPs.

Conclusion: Mamba-based CLIMP demonstrates superior performance over Transformer-based CLIP, offering better cross-modal retrieval, out-of-distribution robustness, and efficiency, making it a promising alternative.

Abstract: Contrastive Language-Image Pre-training (CLIP) relies on Vision Transformers whose attention mechanism is susceptible to spurious correlations, and scales quadratically with resolution. To address these limitations, We present CLIMP, the first fully Mamba-based contrastive vision-language model that replaces both the vision and text encoders with Mamba. The new architecture encodes sequential structure in both vision and language, with VMamba capturing visual spatial inductive biases, reducing reliance on spurious correlations and producing an embedding space favorable for cross-modal retrieval and out-of-distribution robustness-surpassing OpenAI's CLIP-ViT-B by 7.5% on ImageNet-O. CLIMP naturally supports variable input resolutions without positional encoding interpolation or specialized training, achieving up to 6.6% higher retrieval accuracy at 16x training resolution while using 5x less memory and 1.8x fewer FLOPs. The autoregressive text encoder further overcomes CLIP's fixed context limitation, enabling dense captioning retrieval. Our findings suggest that Mamba exhibits advantageous properties for vision-language learning, making it a compelling alternative to Transformer-based CLIP.

</details>


### [69] [UDPNet: Unleashing Depth-based Priors for Robust Image Dehazing](https://arxiv.org/abs/2601.06909)
*Zengyuan Zuo,Junjun Jiang,Gang Wu,Xianming Liu*

Main category: cs.CV

TL;DR: UDPNet利用深度先验提升图像去雾性能，通过DGAM和DPFM模块高效融合深度信息，在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法多关注单模态RGB特征，忽略了场景深度与雾霾分布的相关性，且深度信息利用不足。UDPNet旨在通过深度先验提升去雾性能。

Method: UDPNet结合了深度引导注意力模块（DGAM）和深度先验融合模块（DPFM），通过轻量级通道注意力和双滑动窗口多头交叉注意力机制，实现了深度先验的高效融合。

Result: UDPNet在SOTS、Haze4K和NHR数据集上分别提升了0.85 dB、1.19 dB和1.79 dB的PSNR，显著优于现有方法。

Conclusion: UDPNet通过深度先验的利用，显著提升了图像去雾性能，并在多个数据集上超越了现有方法，为深度感知去雾设定了新基准。

Abstract: Image dehazing has witnessed significant advancements with the development of deep learning models. However, a few methods predominantly focus on single-modal RGB features, neglecting the inherent correlation between scene depth and haze distribution. Even those that jointly optimize depth estimation and image dehazing often suffer from suboptimal performance due to inadequate utilization of accurate depth information. In this paper, we present UDPNet, a general framework that leverages depth-based priors from large-scale pretrained depth estimation model DepthAnything V2 to boost existing image dehazing models. Specifically, our architecture comprises two typical components: the Depth-Guided Attention Module (DGAM) adaptively modulates features via lightweight depth-guided channel attention, and the Depth Prior Fusion Module (DPFM) enables hierarchical fusion of multi-scale depth map features by dual sliding-window multi-head cross-attention mechanism. These modules ensure both computational efficiency and effective integration of depth priors. Moreover, the intrinsic robustness of depth priors empowers the network to dynamically adapt to varying haze densities, illumination conditions, and domain gaps across synthetic and real-world data. Extensive experimental results demonstrate the effectiveness of our UDPNet, outperforming the state-of-the-art methods on popular dehazing datasets, such as 0.85 dB PSNR improvement on the SOTS dataset, 1.19 dB on the Haze4K dataset and 1.79 dB PSNR on the NHR dataset. Our proposed solution establishes a new benchmark for depth-aware dehazing across various scenarios. Pretrained models and codes will be released at our project https://github.com/Harbinzzy/UDPNet.

</details>


### [70] [RenderFlow: Single-Step Neural Rendering via Flow Matching](https://arxiv.org/abs/2601.06928)
*Shenghao Zhang,Runtao Liu,Christopher Schroers,Yang Zhang*

Main category: cs.CV

TL;DR: RenderFlow 是一种基于流匹配的单步神经渲染框架，解决了传统 PBR 和扩散模型的延迟与随机性问题，通过稀疏关键帧引导实现了高效、高质量的近实时渲染。


<details>
  <summary>Details</summary>
Motivation: 传统 PBR 管线计算密集，而现有深度学习方法虽能生成视觉上吸引人的结果，但受限于扩散过程的迭代延迟和生成模型的随机性，影响了物理准确性和时间一致性。

Method: 基于流匹配范式构建的 RenderFlow 框架，结合稀疏关键帧引导模块，实现了高效的单步神经渲染。

Result: RenderFlow 显著提升了渲染速度，通过稀疏关键帧引导增强了物理合理性和视觉质量，实现了近实时性能的照片级真实感渲染。

Conclusion: RenderFlow 提出了一种新颖的端到端、确定性、单步神经渲染框架，显著加速了渲染过程，并通过稀疏关键帧引导提升了物理合理性和视觉质量。该方法在保持照片级真实感的同时实现了近实时性能，并展示了在逆向渲染任务中的多功能性。

Abstract: Conventional physically based rendering (PBR) pipelines generate photorealistic images through computationally intensive light transport simulations. Although recent deep learning approaches leverage diffusion model priors with geometry buffers (G-buffers) to produce visually compelling results without explicit scene geometry or light simulation, they remain constrained by two major limitations. First, the iterative nature of the diffusion process introduces substantial latency. Second, the inherent stochasticity of these generative models compromises physical accuracy and temporal consistency. In response to these challenges, we propose a novel, end-to-end, deterministic, single-step neural rendering framework, RenderFlow, built upon a flow matching paradigm. To further strengthen both rendering quality and generalization, we propose an efficient and effective module for sparse keyframe guidance. Our method significantly accelerates the rendering process and, by optionally incorporating sparsely rendered keyframes as guidance, enhances both the physical plausibility and overall visual quality of the output. The resulting pipeline achieves near real-time performance with photorealistic rendering quality, effectively bridging the gap between the efficiency of modern generative models and the precision of traditional physically based rendering. Furthermore, we demonstrate the versatility of our framework by introducing a lightweight, adapter-based module that efficiently repurposes the pretrained forward model for the inverse rendering task of intrinsic decomposition.

</details>


### [71] [Measuring Social Bias in Vision-Language Models with Face-Only Counterfactuals from Real Photos](https://arxiv.org/abs/2601.06931)
*Haodong Chen,Qiang Huang,Jiaqi Zhao,Qiuping Jiang,Xiaojun Chang,Jun Yu*

Main category: cs.CV

TL;DR: 提出了一种仅关注面部的反事实评估范式来测量VLM中的社会偏见，构建了FOCUS数据集和REFLECT基准，实验显示人口统计差异在严格视觉控制下仍然存在。


<details>
  <summary>Details</summary>
Motivation: 视觉语言模型（VLMs）在社会重要场景中的部署引发了由人口统计线索驱动的社会偏见问题。测量这种偏见的核心挑战在于视觉混杂因素下的归因。

Method: 提出了一种仅关注面部的反事实评估范式，通过编辑与种族和性别相关的面部属性来生成反事实变体，同时保持其他视觉因素不变。基于这一范式，构建了FOCUS数据集和REFLECT基准。

Result: 实验在五个最先进的VLM上进行，结果显示人口统计差异在严格视觉控制下仍然存在，并且在不同任务形式中差异显著。

Conclusion: 研究发现，即使在严格的视觉控制下，人口统计差异仍然存在，并且在不同任务形式中差异显著。这强调了进行受控的反事实审计的必要性，并突出了任务设计在评估多模态模型中的社会偏见时的关键作用。

Abstract: Vision-Language Models (VLMs) are increasingly deployed in socially consequential settings, raising concerns about social bias driven by demographic cues. A central challenge in measuring such social bias is attribution under visual confounding: real-world images entangle race and gender with correlated factors such as background and clothing, obscuring attribution. We propose a \textbf{face-only counterfactual evaluation paradigm} that isolates demographic effects while preserving real-image realism. Starting from real photographs, we generate counterfactual variants by editing only facial attributes related to race and gender, keeping all other visual factors fixed. Based on this paradigm, we construct \textbf{FOCUS}, a dataset of 480 scene-matched counterfactual images across six occupations and ten demographic groups, and propose \textbf{REFLECT}, a benchmark comprising three decision-oriented tasks: two-alternative forced choice, multiple-choice socioeconomic inference, and numeric salary recommendation. Experiments on five state-of-the-art VLMs reveal that demographic disparities persist under strict visual control and vary substantially across task formulations. These findings underscore the necessity of controlled, counterfactual audits and highlight task design as a critical factor in evaluating social bias in multimodal models.

</details>


### [72] [Watching, Reasoning, and Searching: A Video Deep Research Benchmark on Open Web for Agentic Video Reasoning](https://arxiv.org/abs/2601.06943)
*Chengwen Liu,Xiaomin Yu,Zhuoyue Chang,Zhe Huang,Shuo Zhang,Heng Lian,Kunyi Wang,Rui Xu,Sen Hu,Jianheng Hou,Hao Peng,Chengwei Qin,Xiaobin Hu,Hong Peng,Ronghao Chen,Huacan Wang*

Main category: cs.CV

TL;DR: VideoDR是首个视频深度研究基准，用于视频条件下的开放域问答，需跨帧视觉锚点提取、交互式网络检索和多跳推理。评估显示Agentic并非始终优于Workflow，目标漂移和长时一致性是关键挑战。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的视频问答场景通常仅提供局部视觉线索，而可验证答案分布在开放网络中，需要模型联合执行跨帧线索提取、迭代检索和基于多跳推理的验证。

Method: 构建了VideoDR基准，涵盖六个语义领域的高质量样本，评估了闭源和开源的多模态大语言模型在Workflow和Agentic范式下的表现。

Result: 结果表明，Agentic并不总是优于Workflow，其优势取决于模型在长检索链中保持初始视频锚点的能力。目标漂移和长时一致性是核心瓶颈。

Conclusion: VideoDR为研究开放网络环境下的视频代理提供了系统基准，并揭示了下一代视频深度研究代理的关键挑战。

Abstract: In real-world video question answering scenarios, videos often provide only localized visual cues, while verifiable answers are distributed across the open web; models therefore need to jointly perform cross-frame clue extraction, iterative retrieval, and multi-hop reasoning-based verification. To bridge this gap, we construct the first video deep research benchmark, VideoDR. VideoDR centers on video-conditioned open-domain video question answering, requiring cross-frame visual anchor extraction, interactive web retrieval, and multi-hop reasoning over joint video-web evidence; through rigorous human annotation and quality control, we obtain high-quality video deep research samples spanning six semantic domains. We evaluate multiple closed-source and open-source multimodal large language models under both the Workflow and Agentic paradigms, and the results show that Agentic is not consistently superior to Workflow: its gains depend on a model's ability to maintain the initial video anchors over long retrieval chains. Further analysis indicates that goal drift and long-horizon consistency are the core bottlenecks. In sum, VideoDR provides a systematic benchmark for studying video agents in open-web settings and reveals the key challenges for next-generation video deep research agents.

</details>


### [73] [SketchJudge: A Diagnostic Benchmark for Grading Hand-drawn Diagrams with Multimodal Large Language Models](https://arxiv.org/abs/2601.06944)
*Yuhang Su,Mei Wang,Yaoyao Zhong,Guozhang Li,Shixing Li,Yihan Feng,Hua Huang*

Main category: cs.CV

TL;DR: SketchJudge 是一个针对手绘 STEM 图表评分的新基准测试，揭示了当前多模态大语言模型在符号化和噪声环境下的不足，模型表现远不如人类。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型在视觉理解方面取得显著进展，但在处理人类手绘草图的非结构化和模糊性时表现不佳，尤其在视觉评分任务中需要诊断错误。

Method: 引入 SketchJudge 基准测试，包含 1,015 个手绘 STEM 图表学生回答，涵盖几何、物理、图表和流程图四个领域，具有多样风格和错误类型。

Result: 评估显示，即使是先进的多模态大语言模型在 SketchJudge 上也显著落后于人类表现。

Conclusion: SketchJudge 是一个有效的基准测试，揭示了当前多模态大语言模型在符号化和噪声环境下的视觉语言对齐脆弱性，即使先进模型也显著落后于人类表现。

Abstract: While Multimodal Large Language Models (MLLMs) have achieved remarkable progress in visual understanding, they often struggle when faced with the unstructured and ambiguous nature of human-generated sketches. This limitation is particularly pronounced in the underexplored task of visual grading, where models should not only solve a problem but also diagnose errors in hand-drawn diagrams. Such diagnostic capabilities depend on complex structural, semantic, and metacognitive reasoning. To bridge this gap, we introduce SketchJudge, a novel benchmark tailored for evaluating MLLMs as graders of hand-drawn STEM diagrams. SketchJudge encompasses 1,015 hand-drawn student responses across four domains: geometry, physics, charts, and flowcharts, featuring diverse stylistic variations and distinct error types. Evaluations on SketchJudge demonstrate that even advanced MLLMs lag significantly behind humans, validating the benchmark's effectiveness in exposing the fragility of current vision-language alignment in symbolic and noisy contexts. All data, code, and evaluation scripts are publicly available at https://github.com/yuhangsu82/SketchJudge.

</details>


### [74] [Unified Personalized Understanding, Generating and Editing](https://arxiv.org/abs/2601.06965)
*Yu Zhong,Tianwei Lin,Ruike Zhu,Yuqian Yuan,Haoyu Zheng,Liang Liang,Wenqiao Zhang,Feifei Shao,Haoyuan Li,Wanggui He,Hao Jiang,Yueting Zhuang*

Main category: cs.CV

TL;DR: OmniPersona是一个端到端个性化框架，首次统一了理解、生成和编辑任务，通过结构解耦和知识回放实现一致个性化，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的大型多模态模型（LMMs）采用“一刀切”模式，难以一致且可控地建模用户特定概念，且现有个性化方法效率低或集成性差。

Method: OmniPersona引入了结构解耦的概念令牌，为不同任务分配专用子空间以减少干扰，并结合显式知识回放机制，跨任务传播个性化属性知识。

Result: 实验结果表明，OmniPersona在多样化个性化任务中表现优异且稳健。

Conclusion: OmniPersona作为一个端到端的个性化框架，首次在统一的大型多模态模型中集成了个性化理解、生成和图像编辑，并通过结构解耦的概念令牌和显式知识回放机制，实现了跨任务的一致个性化行为。

Abstract: Unified large multimodal models (LMMs) have achieved remarkable progress in general-purpose multimodal understanding and generation. However, they still operate under a ``one-size-fits-all'' paradigm and struggle to model user-specific concepts (e.g., generate a photo of \texttt{<maeve>}) in a consistent and controllable manner. Existing personalization methods typically rely on external retrieval, which is inefficient and poorly integrated into unified multimodal pipelines. Recent personalized unified models introduce learnable soft prompts to encode concept information, yet they either couple understanding and generation or depend on complex multi-stage training, leading to cross-task interference and ultimately to fuzzy or misaligned personalized knowledge. We present \textbf{OmniPersona}, an end-to-end personalization framework for unified LMMs that, for the first time, integrates personalized understanding, generation, and image editing within a single architecture. OmniPersona introduces structurally decoupled concept tokens, allocating dedicated subspaces for different tasks to minimize interference, and incorporates an explicit knowledge replay mechanism that propagates personalized attribute knowledge across tasks, enabling consistent personalized behavior. To systematically evaluate unified personalization, we propose \textbf{\texttt{OmniPBench}}, extending the public UnifyBench concept set with personalized editing tasks and cross-task evaluation protocols integrating understanding, generation, and editing. Experimental results demonstrate that OmniPersona delivers competitive and robust performance across diverse personalization tasks. We hope OmniPersona will serve as a strong baseline and spur further research on controllable, unified personalization.

</details>


### [75] [Can Textual Reasoning Improve the Performance of MLLMs on Fine-grained Visual Classification?](https://arxiv.org/abs/2601.06993)
*Jie Zhu,Yiyang Su,Xiaoming Liu*

Main category: cs.CV

TL;DR: 研究揭示CoT在FGVC中的性能下降与推理长度相关，提出ReFine-RFT框架和\alg方法，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 多模态大语言模型（MLLMs）在FGVC任务中表现不佳，而CoT推理虽在其他任务中有效，却可能损害视觉感知性能，需探究其根本原因。

Method: 通过零样本评估和多种训练范式系统性地重新审视CoT在FGVC中的作用，并提出ReFine-RFT框架和\alg方法。

Result: 发现推理长度是导致性能下降的关键因素，提出的ReFine-RFT和\alg方法在FGVC基准测试中达到SOTA性能。

Conclusion: 研究发现CoT在细粒度视觉分类（FGVC）中的性能下降主要由推理长度驱动，并提出ReFine-RFT框架和\alg方法以优化性能，实现SOTA结果。

Abstract: Multi-modal large language models (MLLMs) exhibit strong general-purpose capabilities, yet still struggle on Fine-Grained Visual Classification (FGVC), a core perception task that requires subtle visual discrimination and is crucial for many real-world applications. A widely adopted strategy for boosting performance on challenging tasks such as math and coding is Chain-of-Thought (CoT) reasoning. However, several prior works have reported that CoT can actually harm performance on visual perception tasks. These studies, though, examine the issue from relatively narrow angles and leave open why CoT degrades perception-heavy performance. We systematically re-examine the role of CoT in FGVC through the lenses of zero-shot evaluation and multiple training paradigms. Across these settings, we uncover a central paradox: the degradation induced by CoT is largely driven by the reasoning length, in which longer textual reasoning consistently lowers classification accuracy. We term this phenomenon the ``Cost of Thinking''. Building on this finding, we make two key contributions: (1) \alg, a simple and general plug-and-play normalization method for multi-reward optimization that balances heterogeneous reward signals, and (2) ReFine-RFT, a framework that combines ensemble rewards with \alg to constrain reasoning length while providing dense accuracy-oriented feedback. Extensive experiments demonstrate the effectiveness of our findings and the proposed ReFine-RFT, achieving state-of-the-art performance across FGVC benchmarks. Code and models are available at \href{https://github.com/jiezhu23/ReFine-RFT}{Project Link}.

</details>


### [76] [Spatial Multi-Task Learning for Breast Cancer Molecular Subtype Prediction from Single-Phase DCE-MRI](https://arxiv.org/abs/2601.07001)
*Sen Zeng,Hong Zhou,Zheng Zhu,Yang Liu*

Main category: cs.CV

TL;DR: 研究提出了一种基于单相DCE-MRI的空间多任务学习框架，用于非侵入性乳腺癌分子亚型预测，性能显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统免疫组化分析依赖侵入性活检且易受采样偏差影响，而临床DCE-MRI通常仅获取单相图像以减少扫描时间和对比剂剂量，因此需要一种非侵入性且高效的分子亚型预测方法。

Method: 研究提出了一种结合深度特征提取网络与多尺度空间注意力的空间多任务学习框架，同时预测ER、PR、HER2状态和Ki-67增殖指数，通过共享表示和任务特定分支利用生物标志物之间的相关性。

Result: 在960例数据集上，该方法在ER、PR和HER2分类的AUC分别为0.893、0.824和0.857，Ki-67回归的平均绝对误差为8.2%，显著优于基线方法。

Conclusion: 该研究提出的空间多任务学习框架通过临床实用的单相DCE-MRI实现了乳腺癌分子亚型的准确预测，显著优于传统方法，展示了非侵入性分子亚型预测的可行性。

Abstract: Accurate molecular subtype classification is essential for personalized breast cancer treatment, yet conventional immunohistochemical analysis relies on invasive biopsies and is prone to sampling bias. Although dynamic contrast-enhanced magnetic resonance imaging (DCE-MRI) enables non-invasive tumor characterization, clinical workflows typically acquire only single-phase post-contrast images to reduce scan time and contrast agent dose. In this study, we propose a spatial multi-task learning framework for breast cancer molecular subtype prediction from clinically practical single-phase DCE-MRI. The framework simultaneously predicts estrogen receptor (ER), progesterone receptor (PR), human epidermal growth factor receptor 2 (HER2) status, and the Ki-67 proliferation index -- biomarkers that collectively define molecular subtypes. The architecture integrates a deep feature extraction network with multi-scale spatial attention to capture intratumoral and peritumoral characteristics, together with a region-of-interest weighting module that emphasizes the tumor core, rim, and surrounding tissue. Multi-task learning exploits biological correlations among biomarkers through shared representations with task-specific prediction branches. Experiments on a dataset of 960 cases (886 internal cases split 7:1:2 for training/validation/testing, and 74 external cases evaluated via five-fold cross-validation) demonstrate that the proposed method achieves an AUC of 0.893, 0.824, and 0.857 for ER, PR, and HER2 classification, respectively, and a mean absolute error of 8.2\% for Ki-67 regression, significantly outperforming radiomics and single-task deep learning baselines. These results indicate the feasibility of accurate, non-invasive molecular subtype prediction using standard imaging protocols.

</details>


### [77] [Adversarial Attacks on Medical Hyperspectral Imaging Exploiting Spectral-Spatial Dependencies and Multiscale Features](https://arxiv.org/abs/2601.07056)
*Yunrui Gu,Zhenzhe Gao,Cong Kong,Zhaoxia Yin*

Main category: cs.CV

TL;DR: 该论文提出了一种针对医学高光谱成像的对抗攻击框架，揭示了其脆弱性，并展示了攻击效果，呼吁开发鲁棒防御。


<details>
  <summary>Details</summary>
Motivation: 医学HSI在疾病诊断中依赖局部像素依赖性和多尺度光谱空间表示，但深度学习的最新进展暴露了其对对抗攻击的脆弱性。

Method: 提出了一个针对医学HSI的对抗攻击框架，包括利用空间相关性的局部像素依赖攻击和跨层次光谱空间尺度的多尺度信息攻击。

Result: 在Brain和MDC数据集上的实验表明，所提出的攻击显著降低了分类性能，尤其在肿瘤区域，同时保持视觉上的不可察觉性。

Conclusion: 该研究揭示了医学高光谱成像（HSI）模型在对抗攻击下的脆弱性，并提出了针对性的攻击框架，强调了在临床应用中需要结构感知的鲁棒防御。

Abstract: Medical hyperspectral imaging (HSI) enables accurate disease diagnosis by capturing rich spectral-spatial tissue information, but recent advances in deep learning have exposed its vulnerability to adversarial attacks. In this work, we identify two fundamental causes of this fragility: the reliance on local pixel dependencies for preserving tissue structure and the dependence on multiscale spectral-spatial representations for hierarchical feature encoding. Building on these insights, we propose a targeted adversarial attack framework for medical HSI, consisting of a Local Pixel Dependency Attack that exploits spatial correlations among neighboring pixels, and a Multiscale Information Attack that perturbs features across hierarchical spectral-spatial scales. Experiments on the Brain and MDC datasets demonstrate that our attacks significantly degrade classification performance, especially in tumor regions, while remaining visually imperceptible. Compared with existing methods, our approach reveals the unique vulnerabilities of medical HSI models and underscores the need for robust, structure-aware defenses in clinical applications.

</details>


### [78] [Billboard in Focus: Estimating Driver Gaze Duration from a Single Image](https://arxiv.org/abs/2601.07073)
*Carlos Pizarroso,Zuzana Berger Haladová,Zuzana Černeková,Viktor Kocur*

Main category: cs.CV

TL;DR: 全自动广告牌检测与注视时长估计流程，YOLO+DINOv2方法，单帧准确率68.1%，无需人工标注。


<details>
  <summary>Details</summary>
Motivation: 路边广告牌是户外广告的核心元素，但其存在可能导致驾驶员分心并增加事故风险。研究旨在自动评估广告牌相关性，减少对人工干预的依赖。

Method: 研究采用两阶段流程：(1) 基于YOLO的物体检测模型，在Mapillary Vistas上训练并在BillboardLamac上微调，达到94% mAP@50；(2) 基于检测框位置和DINOv2特征的分类器。

Result: 在BillboardLamac数据集上，单帧广告牌驾驶员注视时长估计准确率达到68.1%，并通过Google街景图像进一步验证。

Conclusion: 该研究提出了一种全自动流程，用于广告牌检测和驾驶员注视时长估计，无需依赖人工标注或眼动追踪设备，为评估广告牌相关性提供了有效工具。

Abstract: Roadside billboards represent a central element of outdoor advertising, yet their presence may contribute to driver distraction and accident risk. This study introduces a fully automated pipeline for billboard detection and driver gaze duration estimation, aiming to evaluate billboard relevance without reliance on manual annotations or eye-tracking devices. Our pipeline operates in two stages: (1) a YOLO-based object detection model trained on Mapillary Vistas and fine-tuned on BillboardLamac images achieved 94% mAP@50 in the billboard detection task (2) a classifier based on the detected bounding box positions and DINOv2 features. The proposed pipeline enables estimation of billboard driver gaze duration from individual frames. We show that our method is able to achieve 68.1% accuracy on BillboardLamac when considering individual frames. These results are further validated using images collected from Google Street View.

</details>


### [79] [Efficient Visual Question Answering Pipeline for Autonomous Driving via Scene Region Compression](https://arxiv.org/abs/2601.07092)
*Yuliang Cai,Dongqiangzi Ye,Zitian Chen,Chongruo Wu*

Main category: cs.CV

TL;DR: SRC-Pipeline通过令牌压缩策略，高效降低VQA模型计算成本，适用于实时自动驾驶场景。


<details>
  <summary>Details</summary>
Motivation: 当前VQA模型（尤其是大型视觉语言模型）在自动驾驶场景中因计算成本高和延迟问题难以实时部署，需平衡性能与效率。

Method: 提出SRC-Pipeline框架，学习将早期帧令牌压缩为少量高级令牌，同时保留近期帧的完整令牌。

Result: 在自动驾驶视频问答任务中，SRC-Pipeline实现FLOPs减少66%，性能相近。

Conclusion: SRC-Pipeline通过早期帧令牌压缩和高保留近期帧令牌的策略，显著降低了计算成本（FLOPs减少66%），同时保持性能，适用于实时自动驾驶VQA任务。

Abstract: Autonomous driving increasingly relies on Visual Question Answering (VQA) to enable vehicles to understand complex surroundings by analyzing visual inputs and textual queries. Currently, a paramount concern for VQA in this domain is the stringent requirement for fast latency and real-time processing, as delays directly impact real-world safety in this safety-critical application. However, current state-of-the-art VQA models, particularly large vision-language models (VLMs), often prioritize performance over computational efficiency. These models typically process dense patch tokens for every frame, leading to prohibitive computational costs (FLOPs) and significant inference latency, especially with long video sequences. This focus limits their practical deployment in real-time autonomous driving scenarios. To tackle this issue, we propose an efficient VLM framework for autonomous driving VQA tasks, SRC-Pipeline. It learns to compress early frame tokens into a small number of high-level tokens while retaining full patch tokens for recent frames. Experiments on autonomous driving video question answering tasks show that our approach achieves 66% FLOPs reduction while maintaining comparable performance, enabling VLMs to operate more effectively in real-time, safety-critical autonomous driving settings.

</details>


### [80] [3D Wavelet-Based Structural Priors for Controlled Diffusion in Whole-Body Low-Dose PET Denoising](https://arxiv.org/abs/2601.07093)
*Peiyuan Jing,Yue Tang,Chun-Wun Cheng,Zhenxuan Zhang,Liutao Yang,Thiago V. Lima,Klaus Strobel,Antoine Leimgruber,Angelica Aviles-Rivero,Guang Yang,Javier Montoya*

Main category: cs.CV

TL;DR: WCC-Net利用小波条件扩散模型，显著提升低剂量PET图像质量，并在多种剂量水平上保持解剖一致性。


<details>
  <summary>Details</summary>
Motivation: 低剂量PET成像减少患者辐射暴露，但噪声增加导致图像质量和诊断可靠性下降。扩散模型虽具去噪能力，但其随机性难以在低信噪比和全身成像中保持解剖结构一致性。

Method: 提出Wavelet-Conditioned ControlNet (WCC-Net)，一种基于扩散模型的3D框架，通过小波表示注入结构先验，指导PET图像去噪。

Result: WCC-Net在内部1/20剂量测试集上，PSNR提升+1.21 dB，SSIM提升+0.008，同时减少结构失真（GMSD）和强度误差（NMAE），并在未见剂量水平（1/50和1/4）上表现优异。

Conclusion: WCC-Net通过引入小波表示的结构先验，显著提升了低剂量PET成像的质量和诊断可靠性，同时在未见剂量水平上表现出强大的泛化能力。

Abstract: Low-dose Positron Emission Tomography (PET) imaging reduces patient radiation exposure but suffers from increased noise that degrades image quality and diagnostic reliability. Although diffusion models have demonstrated strong denoising capability, their stochastic nature makes it challenging to enforce anatomically consistent structures, particularly in low signal-to-noise regimes and volumetric whole-body imaging. We propose Wavelet-Conditioned ControlNet (WCC-Net), a fully 3D diffusion-based framework that introduces explicit frequency-domain structural priors via wavelet representations to guide volumetric PET denoising. By injecting wavelet-based structural guidance into a frozen pretrained diffusion backbone through a lightweight control branch, WCC-Net decouples anatomical structure from noise while preserving generative expressiveness and 3D structural continuity. Extensive experiments demonstrate that WCC-Net consistently outperforms CNN-, GAN-, and diffusion-based baselines. On the internal 1/20-dose test set, WCC-Net improves PSNR by +1.21 dB and SSIM by +0.008 over a strong diffusion baseline, while reducing structural distortion (GMSD) and intensity error (NMAE). Moreover, WCC-Net generalizes robustly to unseen dose levels (1/50 and 1/4), achieving superior quantitative performance and improved volumetric anatomical consistency.

</details>


### [81] [MEDVISTAGYM: A Scalable Training Environment for Thinking with Medical Images via Tool-Integrated Reinforcement Learning](https://arxiv.org/abs/2601.07107)
*Meng Lu,Yuxing Lu,Yuchen Zhuang,Megan Mullins,Yang Xie,Guanghua Xiao,Charles Fleming,Wenqi Shi,Xuan Wang*

Main category: cs.CV

TL;DR: MedVistaGym是一个交互式训练环境，通过强化学习训练医疗VLMs进行工具集成推理，显著提升医疗图像分析性能。


<details>
  <summary>Details</summary>
Motivation: 现有医疗视觉语言模型（VLMs）依赖静态视觉嵌入和单次推理，缺乏重新检查、验证或细化视觉证据的能力，且缺乏有效工具选择、调用和协调的训练基础设施。

Method: 引入MedVistaGym，一个可扩展的交互式训练环境，通过轨迹采样和端到端强化学习训练MedVistaGym-R1模型。

Result: MedVistaGym-R1-8B在六个医疗VQA基准测试中，比同类工具增强基线模型性能高出19.10%至24.21%。

Conclusion: 结构化代理训练（而非仅工具访问）解锁了医疗图像分析中有效的工具集成推理。

Abstract: Vision language models (VLMs) achieve strong performance on general image understanding but struggle to think with medical images, especially when performing multi-step reasoning through iterative visual interaction. Medical VLMs often rely on static visual embeddings and single-pass inference, preventing models from re-examining, verifying, or refining visual evidence during reasoning. While tool-integrated reasoning offers a promising path forward, open-source VLMs lack the training infrastructure to learn effective tool selection, invocation, and coordination in multi-modal medical reasoning. We introduce MedVistaGym, a scalable and interactive training environment that incentivizes tool-integrated visual reasoning for medical image analysis. MedVistaGym equips VLMs to determine when and which tools to invoke, localize task-relevant image regions, and integrate single or multiple sub-image evidence into interleaved multimodal reasoning within a unified, executable interface for agentic training. Using MedVistaGym, we train MedVistaGym-R1 to interleave tool use with agentic reasoning through trajectory sampling and end-to-end reinforcement learning. Across six medical VQA benchmarks, MedVistaGym-R1-8B exceeds comparably sized tool-augmented baselines by 19.10% to 24.21%, demonstrating that structured agentic training--not tool access alone--unlocks effective tool-integrated reasoning for medical image analysis.

</details>


### [82] [Few-shot Class-Incremental Learning via Generative Co-Memory Regularization](https://arxiv.org/abs/2601.07117)
*Kexin Bao,Yong Li,Dan Zeng,Shiming Ge*

Main category: cs.CV

TL;DR: 该论文提出了一种生成共记忆正则化方法，通过生成域适应微调和两类记忆的协作正则化，显著提升了小样本类增量学习的性能。


<details>
  <summary>Details</summary>
Motivation: 解决小样本类增量学习（FSCIL）中模型在少量新数据下学习时的灾难性遗忘和过拟合问题。

Method: 该方法结合了生成域适应微调、掩码自编码器（MAE）解码器和全连接分类器，构建了表示记忆和权重记忆两类记忆，通过共记忆正则化动态训练分类器。

Result: 在多个流行基准测试中，该方法优于现有最先进技术。

Conclusion: 该论文提出的生成共记忆正则化方法在FSCIL任务中表现出色，显著提高了识别准确率，同时有效缓解了对旧类的灾难性遗忘和对新类的过拟合。

Abstract: Few-shot class-incremental learning (FSCIL) aims to incrementally learn models from a small amount of novel data, which requires strong representation and adaptation ability of models learned under few-example supervision to avoid catastrophic forgetting on old classes and overfitting to novel classes. This work proposes a generative co-memory regularization approach to facilitate FSCIL. In the approach, the base learning leverages generative domain adaptation finetuning to finetune a pretrained generative encoder on a few examples of base classes by jointly incorporating a masked autoencoder (MAE) decoder for feature reconstruction and a fully-connected classifier for feature classification, which enables the model to efficiently capture general and adaptable representations. Using the finetuned encoder and learned classifier, we construct two class-wise memories: representation memory for storing the mean features for each class, and weight memory for storing the classifier weights. After that, the memory-regularized incremental learning is performed to train the classifier dynamically on the examples of few-shot classes in each incremental session by simultaneously optimizing feature classification and co-memory regularization. The memories are updated in a class-incremental manner and they collaboratively regularize the incremental learning. In this way, the learned models improve recognition accuracy, while mitigating catastrophic forgetting over old classes and overfitting to novel classes. Extensive experiments on popular benchmarks clearly demonstrate that our approach outperforms the state-of-the-arts.

</details>


### [83] [Motion Focus Recognition in Fast-Moving Egocentric Video](https://arxiv.org/abs/2601.07154)
*Daniel Hong,James Tribble,Hao Wang,Chaoyi Zhou,Ashish Bastola,Siyu Huang,Abolfazl Razi*

Main category: cs.CV

TL;DR: 提出实时运动焦点识别方法，填补运动分析空白，实现高效边缘部署。


<details>
  <summary>Details</summary>
Motivation: 现有自我中心数据集主要关注动作识别任务，忽视了运动分析在体育和快速运动场景中的重要性，因此需要填补这一研究空白。

Method: 利用基础模型进行相机姿态估计，并通过系统级优化实现高效可扩展的推理，采用滑动批量推理策略以降低内存消耗。

Result: 在收集的自我中心动作数据集上评估，该方法实现了实时性能，并通过滑动批量推理策略保持了可管理的内存消耗。

Conclusion: 该研究提出了一种实时运动焦点识别方法，填补了现有自我中心数据集在运动分析方面的空白，为体育和快速运动场景提供了实用的边缘部署解决方案。

Abstract: From Vision-Language-Action (VLA) systems to robotics, existing egocentric datasets primarily focus on action recognition tasks, while largely overlooking the inherent role of motion analysis in sports and other fast-movement scenarios. To bridge this gap, we propose a real-time motion focus recognition method that estimates the subject's locomotion intention from any egocentric video. Our approach leverages the foundation model for camera pose estimation and introduces system-level optimizations to enable efficient and scalable inference. Evaluated on a collected egocentric action dataset, our method achieves real-time performance with manageable memory consumption through a sliding batch inference strategy. This work makes motion-centric analysis practical for edge deployment and offers a complementary perspective to existing egocentric studies on sports and fast-movement activities.

</details>


### [84] [Test-time Adaptive Hierarchical Co-enhanced Denoising Network for Reliable Multimodal Classification](https://arxiv.org/abs/2601.07163)
*Shu Shen,C. L. Philip Chen,Tong Zhang*

Main category: cs.CV

TL;DR: TAHCD是一种新型多模态去噪网络，通过自适应稳定子空间对齐和测试时协同增强，有效去除异构噪声并提升模型适应性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 多模态噪声在安全关键应用中是一个主要挑战，现有方法在去除异构噪声和适应未见噪声方面存在局限性。

Method: TAHCD通过引入自适应稳定子空间对齐和样本自适应置信对齐来可靠地去除异构噪声，并在测试时通过协同增强自适应更新模型。

Result: 实验证明TAHCD在分类性能、鲁棒性和泛化能力上优于现有方法。

Conclusion: TAHCD方法在多个基准测试中表现出卓越的分类性能、鲁棒性和泛化能力，优于现有的可靠多模态学习方法。

Abstract: Reliable learning on low-quality multimodal data is a widely concerning issue, especially in safety-critical applications. However, multimodal noise poses a major challenge in this domain and leads existing methods to suffer from two key limitations. First, they struggle to reliably remove heterogeneous data noise, hindering robust multimodal representation learning. Second, they exhibit limited adaptability and generalization when encountering previously unseen noise. To address these issues, we propose Test-time Adaptive Hierarchical Co-enhanced Denoising Network (TAHCD). On one hand, TAHCD introduces the Adaptive Stable Subspace Alignment and Sample-Adaptive Confidence Alignment to reliably remove heterogeneous noise. They account for noise at both global and instance levels and enable jointly removal of modality-specific and cross-modality noise, achieving robust learning. On the other hand, TAHCD introduces test-time cooperative enhancement, which adaptively updates the model in response to input noise in a label-free manner, improving adaptability and generalization. This is achieved by collaboratively enhancing the joint removal process of modality-specific and cross-modality noise across global and instance levels according to sample noise. Experiments on multiple benchmarks demonstrate that the proposed method achieves superior classification performance, robustness, and generalization compared with state-of-the-art reliable multimodal learning approaches.

</details>


### [85] [DIVER: Dynamic Iterative Visual Evidence Reasoning for Multimodal Fake News Detection](https://arxiv.org/abs/2601.07178)
*Weilin Zhou,Zonghao Ying,Chunlei Meng,Jiahui Liu,Hengyang Zhou,Quanchen Zou,Deyue Zhang,Dongdong Yang,Xiangzheng Zhang*

Main category: cs.CV

TL;DR: DIVER框架通过动态迭代视觉证据推理，优化多模态假新闻检测，性能提升2.72%，延迟降低4.12秒。


<details>
  <summary>Details</summary>
Motivation: 现有方法因静态融合或LLMs导致计算冗余和幻觉风险，DIVER旨在通过动态视觉证据推理解决这些问题。

Method: DIVER采用渐进式证据驱动推理范式，首先基于文本分析建立基线，仅在文本证据不足时引入视觉信息，并通过跨模态对齐验证选择性调用细粒度视觉工具。

Result: 在Weibo、Weibo21和GossipCop数据集上，DIVER平均性能提升2.72%，推理延迟减少4.12秒。

Conclusion: DIVER框架通过动态迭代的视觉证据推理，显著提升了多模态假新闻检测的准确性和效率，优于现有方法。

Abstract: Multimodal fake news detection is crucial for mitigating adversarial misinformation. Existing methods, relying on static fusion or LLMs, face computational redundancy and hallucination risks due to weak visual foundations. To address this, we propose DIVER (Dynamic Iterative Visual Evidence Reasoning), a framework grounded in a progressive, evidence-driven reasoning paradigm. DIVER first establishes a strong text-based baseline through language analysis, leveraging intra-modal consistency to filter unreliable or hallucinated claims. Only when textual evidence is insufficient does the framework introduce visual information, where inter-modal alignment verification adaptively determines whether deeper visual inspection is necessary. For samples exhibiting significant cross-modal semantic discrepancies, DIVER selectively invokes fine-grained visual tools (e.g., OCR and dense captioning) to extract task-relevant evidence, which is iteratively aggregated via uncertainty-aware fusion to refine multimodal reasoning. Experiments on Weibo, Weibo21, and GossipCop demonstrate that DIVER outperforms state-of-the-art baselines by an average of 2.72\%, while optimizing inference efficiency with a reduced latency of 4.12 s.

</details>


### [86] [ShowUI-Aloha: Human-Taught GUI Agent](https://arxiv.org/abs/2601.07181)
*Yichun Zhang,Xiangwu Guo,Yauhong Goh,Jessica Hu,Zhiheng Chen,Xin Wang,Difei Gao,Mike Zheng Shou*

Main category: cs.CV

TL;DR: ShowUI-Aloha 是一个将非结构化人类屏幕记录转化为结构化任务的框架，包含记录、学习、规划和执行四个组件，旨在解决 GUI 自动化中训练数据不足的问题。


<details>
  <summary>Details</summary>
Motivation: 自动化复杂 GUI 任务的主要挑战是缺乏可扩展的高质量训练数据，而人类演示记录虽丰富但通常冗长、非结构化且缺乏注释。

Method: 框架包含四个关键组件：记录器捕获屏幕视频和精确用户交互；学习者语义解析原始交互和视觉上下文，生成自然语言描述；规划器解析演示并动态制定高级动作计划；执行器在操作系统层面执行动作计划。

Result: ShowUI-Aloha 能够高效收集和解析真实世界的人类数据，为构建能从人类观察中有效学习的通用 GUI 代理提供了可行方案。

Conclusion: ShowUI-Aloha 提供了一种将非结构化的人类屏幕记录转化为结构化、可操作任务的全面解决方案，展示了通过观察人类行为构建通用 GUI 代理的可行路径。

Abstract: Graphical User Interfaces (GUIs) are central to human-computer interaction, yet automating complex GUI tasks remains a major challenge for autonomous agents, largely due to a lack of scalable, high-quality training data. While recordings of human demonstrations offer a rich data source, they are typically long, unstructured, and lack annotations, making them difficult for agents to learn from.To address this, we introduce ShowUI-Aloha, a comprehensive pipeline that transforms unstructured, in-the-wild human screen recordings from desktop environments into structured, actionable tasks. Our framework includes four key components: A recorder that captures screen video along with precise user interactions like mouse clicks, keystrokes, and scrolls. A learner that semantically interprets these raw interactions and the surrounding visual context, translating them into descriptive natural language captions. A planner that reads the parsed demonstrations, maintains task states, and dynamically formulates the next high-level action plan based on contextual reasoning. An executor that faithfully carries out these action plans at the OS level, performing precise clicks, drags, text inputs, and window operations with safety checks and real-time feedback. Together, these components provide a scalable solution for collecting and parsing real-world human data, demonstrating a viable path toward building general-purpose GUI agents that can learn effectively from simply observing humans.

</details>


### [87] [SceneNAT: Masked Generative Modeling for Language-Guided Indoor Scene Synthesis](https://arxiv.org/abs/2601.07218)
*Jeongjun Choi,Yeonsoo Park,H. Jin Kim*

Main category: cs.CV

TL;DR: SceneNAT是一种高效的单阶段非自回归Transformer，通过掩码建模和三元组预测器从自然语言生成3D场景，性能优于现有方法且计算成本更低。


<details>
  <summary>Details</summary>
Motivation: 为了提升从自然语言生成3D室内场景的性能和效率，提出SceneNAT以解决现有方法在计算成本和生成质量上的不足。

Method: SceneNAT是一种单阶段掩码非自回归Transformer，通过仅需少量并行解码步骤，从自然语言指令合成完整的3D室内场景。模型通过在全离散化的语义和空间属性表示上进行掩码建模训练，并在属性和实例级别应用掩码策略，以更好地捕捉对象内和对象间结构。此外，模型采用专用的三元组预测器来增强关系推理。

Result: 在3D-FRONT数据集上的广泛实验表明，SceneNAT在语义合规性和空间排列准确性上优于现有方法，且计算成本更低。

Conclusion: SceneNAT在3D-FRONT数据集上表现出色，在语义合规性和空间排列准确性上优于现有自回归和扩散基线，同时计算成本显著降低。

Abstract: We present SceneNAT, a single-stage masked non-autoregressive Transformer that synthesizes complete 3D indoor scenes from natural language instructions through only a few parallel decoding passes, offering improved performance and efficiency compared to prior state-of-the-art approaches. SceneNAT is trained via masked modeling over fully discretized representations of both semantic and spatial attributes. By applying a masking strategy at both the attribute level and the instance level, the model can better capture intra-object and inter-object structure. To boost relational reasoning, SceneNAT employs a dedicated triplet predictor for modeling the scene's layout and object relationships by mapping a set of learnable relation queries to a sparse set of symbolic triplets (subject, predicate, object). Extensive experiments on the 3D-FRONT dataset demonstrate that SceneNAT achieves superior performance compared to state-of-the-art autoregressive and diffusion baselines in both semantic compliance and spatial arrangement accuracy, while operating with substantially lower computational cost.

</details>


### [88] [VENUS: Visual Editing with Noise Inversion Using Scene Graphs](https://arxiv.org/abs/2601.07219)
*Thanh-Nhan Vo,Trong-Thuan Nguyen,Tam V. Nguyen,Minh-Triet Tran*

Main category: cs.CV

TL;DR: VENUS是一种无需训练的基于场景图的图像编辑框架，通过噪声反演和分拆提示策略，显著提升编辑质量和效率。


<details>
  <summary>Details</summary>
Motivation: 现有基于文本或场景图的图像编辑方法在背景保持和语义一致性上存在不足，且依赖高成本的模型微调。

Method: VENUS采用分拆提示条件策略和噪声反演技术，结合多模态大语言模型提取的场景图与扩散模型，无需额外训练。

Result: VENUS在PIE-Bench上提升了PSNR、SSIM和CLIP相似性，降低了LPIPS和运行时；在EditVal上获得最高保真度。

Conclusion: VENUS框架通过无需训练的噪声反演和场景图引导，显著提升了图像编辑的背景保持和语义一致性，同时大幅降低了计算成本。

Abstract: State-of-the-art text-based image editing models often struggle to balance background preservation with semantic consistency, frequently resulting either in the synthesis of entirely new images or in outputs that fail to realize the intended edits. In contrast, scene graph-based image editing addresses this limitation by providing a structured representation of semantic entities and their relations, thereby offering improved controllability. However, existing scene graph editing methods typically depend on model fine-tuning, which incurs high computational cost and limits scalability. To this end, we introduce VENUS (Visual Editing with Noise inversion Using Scene graphs), a training-free framework for scene graph-guided image editing. Specifically, VENUS employs a split prompt conditioning strategy that disentangles the target object of the edit from its background context, while simultaneously leveraging noise inversion to preserve fidelity in unedited regions. Moreover, our proposed approach integrates scene graphs extracted from multimodal large language models with diffusion backbones, without requiring any additional training. Empirically, VENUS substantially improves both background preservation and semantic alignment on PIE-Bench, increasing PSNR from 22.45 to 24.80, SSIM from 0.79 to 0.84, and reducing LPIPS from 0.100 to 0.070 relative to the state-of-the-art scene graph editing model (SGEdit). In addition, VENUS enhances semantic consistency as measured by CLIP similarity (24.97 vs. 24.19). On EditVal, VENUS achieves the highest fidelity with a 0.87 DINO score and, crucially, reduces per-image runtime from 6-10 minutes to only 20-30 seconds. Beyond scene graph-based editing, VENUS also surpasses strong text-based editing baselines such as LEDIT++ and P2P+DirInv, thereby demonstrating consistent improvements across both paradigms.

</details>


### [89] [Language-Grounded Multi-Domain Image Translation via Semantic Difference Guidance](https://arxiv.org/abs/2601.07221)
*Jongwon Ryu,Joonhyung Park,Jaeho Han,Yeong-Seok Kim,Hye-rin Kim,Sunjae Yoon,Junyeong Kim*

Main category: cs.CV

TL;DR: LACE通过融合语言提示与视觉转换，实现了多域图像转换的高保真度和可控性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多域图像转换中难以保持结构完整性并提供细粒度的属性特定控制。

Method: LACE包含两个组件：(1) GLIP-Adapter融合全局语义与局部结构特征以保持一致性；(2) 多域控制引导机制将源与目标提示的语义差异显式地转化为每属性的转换向量，实现语言语义与域级视觉变化的对齐。

Result: 在CelebA(Dialog)和BDD100K上的实验表明，LACE在视觉保真度、结构保留和可解释的域特定控制方面优于现有基线。

Conclusion: LACE被定位为一个跨模态内容生成框架，能够有效连接语言语义与可控视觉转换。

Abstract: Multi-domain image-to-image translation re quires grounding semantic differences ex pressed in natural language prompts into corresponding visual transformations, while preserving unrelated structural and seman tic content. Existing methods struggle to maintain structural integrity and provide fine grained, attribute-specific control, especially when multiple domains are involved. We propose LACE (Language-grounded Attribute Controllable Translation), built on two compo nents: (1) a GLIP-Adapter that fuses global semantics with local structural features to pre serve consistency, and (2) a Multi-Domain Control Guidance mechanism that explicitly grounds the semantic delta between source and target prompts into per-attribute translation vec tors, aligning linguistic semantics with domain level visual changes. Together, these modules enable compositional multi-domain control with independent strength modulation for each attribute. Experiments on CelebA(Dialog) and BDD100K demonstrate that LACE achieves high visual fidelity, structural preservation, and interpretable domain-specific control, surpass ing prior baselines. This positions LACE as a cross-modal content generation framework bridging language semantics and controllable visual translation.

</details>


### [90] [Universal Adversarial Purification with DDIM Metric Loss for Stable Diffusion](https://arxiv.org/abs/2601.07253)
*Li Zheng,Liangbin Xie,Jiantao Zhou,He YiMin*

Main category: cs.CV

TL;DR: UDAP是一种针对Stable Diffusion对抗攻击的净化框架，通过DDIM反演和动态轮次调整有效去除噪声，实验证明其鲁棒性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有净化方法主要针对分类任务，无法应对SD特有的对抗策略（如针对VAE编码器、UNet去噪器或两者的攻击），因此需要专门针对SD安全的解决方案。

Method: UDAP利用DDIM反演中干净图像和对抗图像的重建行为差异，通过最小化DDIM度量损失来优化净化过程，并采用动态轮次调整策略提高效率。

Result: 实验证明UDAP对多种对抗方法（如PID、Anti-DreamBooth、MIST等）具有鲁棒性，并能泛化到不同SD版本和文本提示，展现了实际应用潜力。

Conclusion: UDAP是一种针对SD模型对抗攻击的新型防御框架，通过优化净化过程并引入动态轮次调整策略，有效提升了对抗噪声的去除效率和效果。

Abstract: Stable Diffusion (SD) often produces degraded outputs when the training dataset contains adversarial noise. Adversarial purification offers a promising solution by removing adversarial noise from contaminated data. However, existing purification methods are primarily designed for classification tasks and fail to address SD-specific adversarial strategies, such as attacks targeting the VAE encoder, UNet denoiser, or both. To address the gap in SD security, we propose Universal Diffusion Adversarial Purification (UDAP), a novel framework tailored for defending adversarial attacks targeting SD models. UDAP leverages the distinct reconstruction behaviors of clean and adversarial images during Denoising Diffusion Implicit Models (DDIM) inversion to optimize the purification process. By minimizing the DDIM metric loss, UDAP can effectively remove adversarial noise. Additionally, we introduce a dynamic epoch adjustment strategy that adapts optimization iterations based on reconstruction errors, significantly improving efficiency without sacrificing purification quality. Experiments demonstrate UDAP's robustness against diverse adversarial methods, including PID (VAE-targeted), Anti-DreamBooth (UNet-targeted), MIST (hybrid), and robustness-enhanced variants like Anti-Diffusion (Anti-DF) and MetaCloak. UDAP also generalizes well across SD versions and text prompts, showcasing its practical applicability in real-world scenarios.

</details>


### [91] [From Landslide Conditioning Factors to Satellite Embeddings: Evaluating the Utilisation of Google AlphaEarth for Landslide Susceptibility Mapping using Deep Learning](https://arxiv.org/abs/2601.07268)
*Yusen Cheng,Qinfeng Zhu,Lei Fan*

Main category: cs.CV

TL;DR: AE嵌入在滑坡敏感性制图中表现优于传统条件因子，尤其是在使用完整64波段表示时，改进显著。


<details>
  <summary>Details</summary>
Motivation: 传统LSM依赖的LCFs存在可用性、异质性和预处理相关的不确定性，限制了制图的可靠性。AE嵌入作为一种统一的地表条件表示，可能提供更优的替代方案。

Method: 研究比较了两种AE表示（保留的主成分和完整的64个嵌入波段）与传统LCFs在三个研究区域（台湾南投县、香港和意大利艾米利亚-罗马涅部分区域）的表现，使用了三种深度学习模型（CNN1D、CNN2D和Vision Transformer）。

Result: 基于AE的模型在所有区域和模型中均优于传统LCFs，表现出更高的F1分数、AUC值和更稳定的误差分布。使用完整的64波段AE表示时改进最为显著，F1分数提高了4%至15%，AUC增加了0.04至0.11。

Conclusion: 本研究强调了Google AlphaEarth (AE)嵌入作为标准化且信息丰富的数据源，在滑坡敏感性制图（LSM）中替代传统滑坡条件因子（LCFs）的潜力。

Abstract: Data-driven landslide susceptibility mapping (LSM) typically relies on landslide conditioning factors (LCFs), whose availability, heterogeneity, and preprocessing-related uncertainties can constrain mapping reliability. Recently, Google AlphaEarth (AE) embeddings, derived from multi-source geospatial observations, have emerged as a unified representation of Earth surface conditions. This study evaluated the potential of AE embeddings as alternative predictors for LSM. Two AE representations, including retained principal components and the full set of 64 embedding bands, were systematically compared with conventional LCFs across three study areas (Nantou County, Taiwan; Hong Kong; and part of Emilia-Romagna, Italy) using three deep learning models (CNN1D, CNN2D, and Vision Transformer). Performance was assessed using multiple evaluation metrics, ROC-AUC analysis, error statistics, and spatial pattern assessment. Results showed that AE-based models consistently outperformed LCFs across all regions and models, yielding higher F1-scores, AUC values, and more stable error distributions. Such improvement was most pronounced when using the full 64-band AE representation, with F1-score improvements of approximately 4% to 15% and AUC increased ranging from 0.04 to 0.11, depending on the study area and model. AE-based susceptibility maps also exhibited clearer spatial correspondence with observed landslide occurrences and enhanced sensitivity to localised landslide-prone conditions. Performance improvements were more evident in Nantou and Emilia than in Hong Kong, revealing that closer temporal alignment between AE embeddings and landslide inventories may lead to more effective LSM outcomes. These findings highlight the strong potential of AE embeddings as a standardised and information-rich alternative to conventional LCFs for LSM.

</details>


### [92] [PALUM: Part-based Attention Learning for Unified Motion Retargeting](https://arxiv.org/abs/2601.07272)
*Siqi Liu,Maoyu Wang,Bo Dai,Cewu Lu*

Main category: cs.CV

TL;DR: PALUM通过语义分割和注意力机制，实现了不同骨架间的运动重定向，保持运动质量和语义一致性。


<details>
  <summary>Details</summary>
Motivation: 解决不同骨架结构的角色间运动重定向的挑战，尤其是在骨架差异大时保持原始运动的语义和质量。

Method: PALUM通过将关节分割为语义身体部分并应用注意力机制来学习跨骨架拓扑的通用运动表示，同时利用目标骨架的特定结构信息进行运动转移。

Result: 实验表明PALUM在多样化骨架结构中表现优异，保持了运动真实性和语义保真度，并能泛化到未见过的骨架-运动组合。

Conclusion: PALUM方法通过分割关节为语义身体部分并应用注意力机制，成功实现了不同骨架结构间的运动重定向，保持了运动的语义和质量。

Abstract: Retargeting motion between characters with different skeleton structures is a fundamental challenge in computer animation. When source and target characters have vastly different bone arrangements, maintaining the original motion's semantics and quality becomes increasingly difficult. We present PALUM, a novel approach that learns common motion representations across diverse skeleton topologies by partitioning joints into semantic body parts and applying attention mechanisms to capture spatio-temporal relationships. Our method transfers motion to target skeletons by leveraging these skeleton-agnostic representations alongside target-specific structural information. To ensure robust learning and preserve motion fidelity, we introduce a cycle consistency mechanism that maintains semantic coherence throughout the retargeting process. Extensive experiments demonstrate superior performance in handling diverse skeletal structures while maintaining motion realism and semantic fidelity, even when generalizing to previously unseen skeleton-motion combinations. We will make our implementation publicly available to support future research.

</details>


### [93] [GenDet: Painting Colored Bounding Boxes on Images via Diffusion Model for Object Detection](https://arxiv.org/abs/2601.07273)
*Chen Min,Chengyang Li,Fanjie Kong,Qi Zhu,Dawei Zhao,Liang Xiao*

Main category: cs.CV

TL;DR: GenDet是一种创新的目标检测框架，利用生成模型直接生成边界框，兼具高准确性和灵活性。


<details>
  <summary>Details</summary>
Motivation: 传统目标检测方法与生成模型的灵活性之间存在差距，GenDet旨在通过生成建模重新定义检测任务，实现边界框位置和类别属性的精确控制。

Method: GenDet基于大规模预训练的Stable Diffusion模型，构建了一个条件生成架构，将检测任务表述为潜在空间中的语义约束，直接生成带有语义注释的边界框。

Result: 系统实验表明，GenDet在保持生成方法灵活性的同时，达到了与判别检测器相当的准确性。

Conclusion: GenDet通过将目标检测重新定义为图像生成任务，成功弥合了生成模型与判别任务之间的差距，为构建统一的视觉理解系统提供了新视角。

Abstract: This paper presents GenDet, a novel framework that redefines object detection as an image generation task. In contrast to traditional approaches, GenDet adopts a pioneering approach by leveraging generative modeling: it conditions on the input image and directly generates bounding boxes with semantic annotations in the original image space. GenDet establishes a conditional generation architecture built upon the large-scale pre-trained Stable Diffusion model, formulating the detection task as semantic constraints within the latent space. It enables precise control over bounding box positions and category attributes, while preserving the flexibility of the generative model. This novel methodology effectively bridges the gap between generative models and discriminative tasks, providing a fresh perspective for constructing unified visual understanding systems. Systematic experiments demonstrate that GenDet achieves competitive accuracy compared to discriminative detectors, while retaining the flexibility characteristic of generative methods.

</details>


### [94] [Focal Guidance: Unlocking Controllability from Semantic-Weak Layers in Video Diffusion Models](https://arxiv.org/abs/2601.07287)
*Yuanyang Yin,Yufan Deng,Shenghai Yuan,Kaipeng Zhang,Xiao Yang,Feng Zhao*

Main category: cs.CV

TL;DR: FG enhances text-visual coupling in I2V models by addressing Semantic-Weak Layers, improving adherence to text prompts with measurable performance gains.


<details>
  <summary>Details</summary>
Motivation: Existing I2V models prioritize visual consistency but lack effective coupling of visual and textual guidance, leading to weak semantic responses in certain layers (Semantic-Weak Layers).

Method: FG comprises Fine-grained Semantic Guidance (FSG) and Attention Cache mechanisms to guide Semantic-Weak Layers by leveraging CLIP and transferring attention maps.

Result: FG improves performance on Wan2.1-I2V (0.7250, +3.97%) and HunyuanVideo-I2V (0.5571, +7.44%), demonstrating its effectiveness and generalizability.

Conclusion: Focal Guidance (FG) effectively addresses the Condition Isolation issue in DiT-based I2V models, enhancing text-visual coupling and improving adherence to textual instructions, as validated by significant performance improvements on benchmarks.

Abstract: The task of Image-to-Video (I2V) generation aims to synthesize a video from a reference image and a text prompt. This requires diffusion models to reconcile high-frequency visual constraints and low-frequency textual guidance during the denoising process. However, while existing I2V models prioritize visual consistency, how to effectively couple this dual guidance to ensure strong adherence to the text prompt remains underexplored. In this work, we observe that in Diffusion Transformer (DiT)-based I2V models, certain intermediate layers exhibit weak semantic responses (termed Semantic-Weak Layers), as indicated by a measurable drop in text-visual similarity. We attribute this to a phenomenon called Condition Isolation, where attention to visual features becomes partially detached from text guidance and overly relies on learned visual priors. To address this, we propose Focal Guidance (FG), which enhances the controllability from Semantic-Weak Layers. FG comprises two mechanisms: (1) Fine-grained Semantic Guidance (FSG) leverages CLIP to identify key regions in the reference frame and uses them as anchors to guide Semantic-Weak Layers. (2) Attention Cache transfers attention maps from semantically responsive layers to Semantic-Weak Layers, injecting explicit semantic signals and alleviating their over-reliance on the model's learned visual priors, thereby enhancing adherence to textual instructions. To further validate our approach and address the lack of evaluation in this direction, we introduce a benchmark for assessing instruction following in I2V models. On this benchmark, Focal Guidance proves its effectiveness and generalizability, raising the total score on Wan2.1-I2V to 0.7250 (+3.97\%) and boosting the MMDiT-based HunyuanVideo-I2V to 0.5571 (+7.44\%).

</details>


### [95] [VideoLoom: A Video Large Language Model for Joint Spatial-Temporal Understanding](https://arxiv.org/abs/2601.07290)
*Jiapeng Shi,Junke Wang,Zuyao You,Bo He,Zuxuan Wu*

Main category: cs.CV

TL;DR: VideoLoom是一个联合时空视频理解的大型语言模型，通过新数据集和基准测试实现了高性能。


<details>
  <summary>Details</summary>
Motivation: 为了促进细粒度的空间和时间定位能力的发展，需要统一的数据集和模型来支持联合时空视频理解。

Method: 开发了VideoLoom模型，并构建了LoomData-8.7k数据集和LoomBench基准测试，以支持细粒度的时空定位能力。

Result: VideoLoom在多个时空基准测试中达到了最先进或极具竞争力的性能（如ReVOS上的63.1 J&F和Charades-STA上的48.3 R1@0.7）。

Conclusion: VideoLoom及其配套数据集和基准测试为联合时空视频理解提供了一个通用且有效的解决方案，为多模态智能设立了新标准。

Abstract: This paper presents VideoLoom, a unified Video Large Language Model (Video LLM) for joint spatial-temporal understanding. To facilitate the development of fine-grained spatial and temporal localization capabilities, we curate LoomData-8.7k, a human-centric video dataset with temporally grounded and spatially localized captions. With this, VideoLoom achieves state-of-the-art or highly competitive performance across a variety of spatial and temporal benchmarks (e.g., 63.1 J&F on ReVOS for referring video object segmentation, and 48.3 R1@0.7 on Charades-STA for temporal grounding). In addition, we introduce LoomBench, a novel benchmark consisting of temporal, spatial, and compositional video-question pairs, enabling a comprehensive evaluation of Video LLMs from diverse aspects. Collectively, these contributions offer a universal and effective suite for joint spatial-temporal video understanding, setting a new standard in multimodal intelligence.

</details>


### [96] [A Visual Semantic Adaptive Watermark grounded by Prefix-Tuning for Large Vision-Language Model](https://arxiv.org/abs/2601.07291)
*Qi Zheng,Shuliang Liu,Yu Huang,Sihang Jia,Jungang Li,Lyuhao Chen,Junhao Chen,Hanqian Li,Aiwei Liu,Yibo Yan,Xuming Hu*

Main category: cs.CV

TL;DR: VISA-Mark 是一种新型视觉语义自适应水印框架，通过动态视觉证据权重和自适应机制，在保持视觉保真度的同时提升水印效果，性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有水印方法在视觉无关标记中引入无关信息或导致高推理延迟的问题，提出一种既保持视觉保真度又可检测的水印框架。

Method: 采用轻量级前缀调谐器提取动态视觉证据权重，指导自适应词汇分区和对数扰动机制，集中水印强度于视觉支持的标记。

Result: VISA-Mark 在视觉一致性（Chair-I）上提升了7.8%，保持了高检测准确率（96.88% AUC）和强攻击韧性（99.3%），且不影响推理效率。

Conclusion: VISA-Mark 框架通过动态视觉证据权重和自适应词汇分区机制，在保持视觉保真度的同时实现了高效的水印嵌入，显著提升了视觉一致性和语义保真度，为多模态水印技术设立了新标准。

Abstract: Watermarking has emerged as a pivotal solution for content traceability and intellectual property protection in Large Vision-Language Models (LVLMs). However, vision-agnostic watermarks introduce visually irrelevant tokens and disrupt visual grounding by enforcing indiscriminate pseudo-random biases, while some semantic-aware methods incur prohibitive inference latency due to rejection sampling. In this paper, we propose the VIsual Semantic Adaptive Watermark (VISA-Mark), a novel framework that embeds detectable signals while strictly preserving visual fidelity. Our approach employs a lightweight, efficiently trained prefix-tuner to extract dynamic Visual-Evidence Weights, which quantify the evidentiary support for candidate tokens based on the visual input. These weights guide an adaptive vocabulary partitioning and logits perturbation mechanism, concentrating watermark strength specifically on visually-supported tokens. By actively aligning the watermark with visual evidence, VISA-Mark effectively maintains visual fidelity. Empirical results confirm that VISA-Mark outperforms conventional methods with a 7.8% improvement in visual consistency (Chair-I) and superior semantic fidelity. The framework maintains highly competitive detection accuracy (96.88% AUC) and robust attack resilience (99.3%) without sacrificing inference efficiency, effectively establishing a new standard for reliability-preserving multimodal watermarking.

</details>


### [97] [Inference-Time Scaling for Visual AutoRegressive modeling by Searching Representative Samples](https://arxiv.org/abs/2601.07293)
*Weidong Tang,Xinyan Wan,Siyu Li,Xiumei Wang*

Main category: cs.CV

TL;DR: VAR-Scaling首次在向量量化视觉自回归模型中应用推理时缩放，通过KDE和混合采样策略提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 解决向量量化视觉自回归模型中离散潜在空间无法进行连续路径搜索的挑战。

Method: 通过核密度估计（KDE）将采样空间映射到准连续特征空间，并采用Top-k和Random-k混合采样策略。

Result: 在类条件和文本到图像评估中，推理过程的质量得到显著提升。

Conclusion: VAR-Scaling通过将离散潜在空间映射到准连续特征空间，提出了一种密度自适应的混合采样策略，显著提升了向量量化视觉自回归模型的推理质量和多样性。

Abstract: While inference-time scaling has significantly enhanced generative quality in large language and diffusion models, its application to vector-quantized (VQ) visual autoregressive modeling (VAR) remains unexplored. We introduce VAR-Scaling, the first general framework for inference-time scaling in VAR, addressing the critical challenge of discrete latent spaces that prohibit continuous path search. We find that VAR scales exhibit two distinct pattern types: general patterns and specific patterns, where later-stage specific patterns conditionally optimize early-stage general patterns. To overcome the discrete latent space barrier in VQ models, we map sampling spaces to quasi-continuous feature spaces via kernel density estimation (KDE), where high-density samples approximate stable, high-quality solutions. This transformation enables effective navigation of sampling distributions. We propose a density-adaptive hybrid sampling strategy: Top-k sampling focuses on high-density regions to preserve quality near distribution modes, while Random-k sampling explores low-density areas to maintain diversity and prevent premature convergence. Consequently, VAR-Scaling optimizes sample fidelity at critical scales to enhance output quality. Experiments in class-conditional and text-to-image evaluations demonstrate significant improvements in inference process. The code is available at https://github.com/WD7ang/VAR-Scaling.

</details>


### [98] [Mimic Human Cognition, Master Multi-Image Reasoning: A Meta-Action Framework for Enhanced Visual Understanding](https://arxiv.org/abs/2601.07298)
*Jianghao Yin,Qingbin Li,Kun Sun,Cheng Ding,Jie Wang,Qin Chen,Jie Zhou,Nan Wang,Changqing Li,Pei Wu,Jian Xu,Zheming Yang,Liang He*

Main category: cs.CV

TL;DR: CINEMA框架通过模仿人类认知步骤，显著提升多图像推理性能，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 多图像推理中存在图像间复杂关系和关键信息分散的挑战，现有MLLMs在此类任务上表现不佳。

Method: 提出了Cognition-Inspired Meta-Action Framework (CINEMA)，将多图像推理分解为五个结构化元动作，并采用检索树采样策略和两阶段强化学习范式进行训练。

Result: 在MUIR和MVMath基准测试中超越GPT-4o，并在视频理解基准测试中优于专用视频推理模型。

Conclusion: CINEMA框架通过模仿人类认知过程，显著提升了多图像推理能力，并在多个基准测试中达到或超越当前最先进模型的性能。

Abstract: While Multimodal Large Language Models (MLLMs) excel at single-image understanding, they exhibit significantly degraded performance in multi-image reasoning scenarios. Multi-image reasoning presents fundamental challenges including complex inter-relationships between images and scattered critical information across image sets. Inspired by human cognitive processes, we propose the Cognition-Inspired Meta-Action Framework (CINEMA), a novel approach that decomposes multi-image reasoning into five structured meta-actions: Global, Focus, Hint, Think, and Answer which explicitly modeling the sequential cognitive steps humans naturally employ. For cold-start training, we introduce a Retrieval-Based Tree Sampling strategy that generates high-quality meta-action trajectories to bootstrap the model with reasoning patterns. During reinforcement learning, we adopt a two-stage paradigm: an exploration phase with Diversity-Preserving Strategy to avoid entropy collapse, followed by an annealed exploitation phase with DAPO to gradually strengthen exploitation. To train our model, we construct a dataset of 57k cold-start and 58k reinforcement learning instances spanning multi-image, multi-frame, and single-image tasks. We conduct extensive evaluations on multi-image reasoning benchmarks, video understanding benchmarks, and single-image benchmarks, achieving competitive state-of-the-art performance on several key benchmarks. Our model surpasses GPT-4o on the MUIR and MVMath benchmarks and notably outperforms specialized video reasoning models on video understanding benchmarks, demonstrating the effectiveness and generalizability of our human cognition-inspired reasoning framework.

</details>


### [99] [Revisiting the Ordering of Channel and Spatial Attention: A Comprehensive Study on Sequential and Parallel Designs](https://arxiv.org/abs/2601.07310)
*Zhongming Liu,Bingbing Jiang*

Main category: cs.CV

TL;DR: 研究系统比较了18种通道-空间注意力组合，发现性能与数据规模相关，提出了场景化构建指南。


<details>
  <summary>Details</summary>
Motivation: 当前通道注意力和空间注意力的融合策略选择缺乏系统分析和统一原则，研究旨在填补这一空白。

Method: 在统一框架下系统比较了18种通道-空间注意力组合拓扑结构，涵盖顺序、并行、多尺度和残差四类。

Result: 发现数据规模与注意力组合性能之间存在耦合规律，并针对不同规模任务提出了最优结构。

Conclusion: 作者提出了基于数据规模的场景化指导原则，用于构建未来的注意力模块，并开源了相关代码。

Abstract: Attention mechanisms have become a core component of deep learning models, with Channel Attention and Spatial Attention being the two most representative architectures. Current research on their fusion strategies primarily bifurcates into sequential and parallel paradigms, yet the selection process remains largely empirical, lacking systematic analysis and unified principles. We systematically compare channel-spatial attention combinations under a unified framework, building an evaluation suite of 18 topologies across four classes: sequential, parallel, multi-scale, and residual. Across two vision and nine medical datasets, we uncover a "data scale-method-performance" coupling law: (1) in few-shot tasks, the "Channel-Multi-scale Spatial" cascaded structure achieves optimal performance; (2) in medium-scale tasks, parallel learnable fusion architectures demonstrate superior results; (3) in large-scale tasks, parallel structures with dynamic gating yield the best performance. Additionally, experiments indicate that the "Spatial-Channel" order is more stable and effective for fine-grained classification, while residual connections mitigate vanishing gradient problems across varying data scales. We thus propose scenario-based guidelines for building future attention modules. Code is open-sourced at https://github.com/DWlzm.

</details>


### [100] [Reconstruction Guided Few-shot Network For Remote Sensing Image Classification](https://arxiv.org/abs/2601.07335)
*Mohit Jaiswal,Naman Jain,Shivani Pathak,Mainak Singha,Nikunja Bihari Kar,Ankit Jha,Biplab Banerjee*

Main category: cs.CV

TL;DR: RGFS-Net 通过掩码图像重建任务提升少样本遥感分类的泛化能力，实验表现优于基线。


<details>
  <summary>Details</summary>
Motivation: 少样本遥感图像分类面临标记样本有限和土地覆盖类型高变异性等挑战，需要一种能够提升泛化能力和类间区分度的新方法。

Method: 提出了一种重建引导的少样本网络（RGFS-Net），通过掩码图像重建任务增强对未见类别的泛化能力，同时保持对已见类别的一致性。

Result: 在 EuroSAT 和 PatternNet 数据集上的 1-shot 和 5-shot 实验中，RGFS-Net 始终优于现有基线方法。

Conclusion: RGFS-Net 是一种简单、有效且兼容标准骨干网络的方法，为少样本遥感图像分类提供了稳健的解决方案。

Abstract: Few-shot remote sensing image classification is challenging due to limited labeled samples and high variability in land-cover types. We propose a reconstruction-guided few-shot network (RGFS-Net) that enhances generalization to unseen classes while preserving consistency for seen categories. Our method incorporates a masked image reconstruction task, where parts of the input are occluded and reconstructed to encourage semantically rich feature learning. This auxiliary task strengthens spatial understanding and improves class discrimination under low-data settings. We evaluated the efficacy of EuroSAT and PatternNet datasets under 1-shot and 5-shot protocols, our approach consistently outperforms existing baselines. The proposed method is simple, effective, and compatible with standard backbones, offering a robust solution for few-shot remote sensing classification. Codes are available at https://github.com/stark0908/RGFS.

</details>


### [101] [PulseMind: A Multi-Modal Medical Model for Real-World Clinical Diagnosis](https://arxiv.org/abs/2601.07344)
*Jiao Xu,Junwei Liu,Jiangwei Lao,Qi Zhu,Yunpeng Zhao,Congyun Jin,Shinan Liu,Zhihong Lu,Lihe Zhang,Xin Chen,Jian Wang,Ping Wang*

Main category: cs.CV

TL;DR: PulseMind通过新数据集、评估基准和CRPO训练框架，提升了多模态临床诊断性能，并在实验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有医学多模态模型未能充分捕捉真实临床诊断的复杂性（如异质输入和持续上下文理解），因此需要开发更全面的诊断模型。

Method: 构建了MediScope数据集（98,000次多轮咨询和601,500张医学图像），开发了PulseMind Benchmark（四维评估协议），并设计了基于比较的强化策略优化（CRPO）训练框架。

Result: PulseMind在诊断咨询基准和公共医学基准上均表现出色，验证了其有效性。

Conclusion: PulseMind模型通过整合系统性数据集、全面评估基准和定制训练框架，显著提升了多模态临床诊断的准确性和实用性，并在多个医学基准测试中表现出色。

Abstract: Recent advances in medical multi-modal models focus on specialized image analysis like dermatology, pathology, or radiology. However, they do not fully capture the complexity of real-world clinical diagnostics, which involve heterogeneous inputs and require ongoing contextual understanding during patient-physician interactions. To bridge this gap, we introduce PulseMind, a new family of multi-modal diagnostic models that integrates a systematically curated dataset, a comprehensive evaluation benchmark, and a tailored training framework. Specifically, we first construct a diagnostic dataset, MediScope, which comprises 98,000 real-world multi-turn consultations and 601,500 medical images, spanning over 10 major clinical departments and more than 200 sub-specialties. Then, to better reflect the requirements of real-world clinical diagnosis, we develop the PulseMind Benchmark, a multi-turn diagnostic consultation benchmark with a four-dimensional evaluation protocol comprising proactiveness, accuracy, usefulness, and language quality. Finally, we design a training framework tailored for multi-modal clinical diagnostics, centered around a core component named Comparison-based Reinforcement Policy Optimization (CRPO). Compared to absolute score rewards, CRPO uses relative preference signals from multi-dimensional com-parisons to provide stable and human-aligned training guidance. Extensive experiments demonstrate that PulseMind achieves competitive performance on both the diagnostic consultation benchmark and public medical benchmarks.

</details>


### [102] [Seeing Right but Saying Wrong: Inter- and Intra-Layer Refinement in MLLMs without Training](https://arxiv.org/abs/2601.07359)
*Shezheng Song,Shasha Li,Jie Yu*

Main category: cs.CV

TL;DR: DualPD是一种无需训练的双视角解码策略，通过层间对比和头间过滤解决MLLMs的视觉表达不一致问题，实验证明其有效提升模型性能。


<details>
  <summary>Details</summary>
Motivation: MLLMs在视觉语言任务中表现优异，但内部推理存在不一致性：深层可能关注正确视觉区域，但最终预测常被早期层的噪声注意力误导，导致“看对说错”现象。

Method: DualPD包含两个模块：(1) 层间注意力引导的对比对数模块，通过比较注意力变化最大的层间输出对数来捕捉正确答案的信念演变；(2) 头间信息过滤模块，抑制关注无关区域的低贡献注意力头，提升每层注意力质量。

Result: 在LLaVA和Qwen-VL模型家族上的多模态基准测试表明，DualPD无需训练即可持续提升准确性，验证了其有效性和泛化能力。

Conclusion: DualPD通过双视角解码策略有效解决了MLLMs中视觉理解与表达不一致的问题，无需额外训练即可提升模型性能。

Abstract: Multimodal Large Language Models (MLLMs) have demonstrated strong capabilities across a variety of vision-language tasks. However, their internal reasoning often exhibits a critical inconsistency: although deeper layers may attend to the correct visual regions, final predictions are frequently misled by noisy attention from earlier layers. This results in a disconnect between what the model internally understands and what it ultimately expresses, a phenomenon we describe as seeing it right but saying it wrong. To address this issue, we propose DualPD, a dual-perspective decoding refinement strategy that enhances the visual understanding without any additional training. DualPD consists of two components. (1) The layer-wise attention-guided contrastive logits module captures how the belief in the correct answer evolves by comparing output logits between layers that exhibit the largest attention shift. (2) The head-wise information filtering module suppresses low-contribution attention heads that focus on irrelevant regions, thereby improving attention quality within each layer. Experiments conducted on both the LLaVA and Qwen-VL model families across multiple multimodal benchmarks demonstrate that DualPD consistently improves accuracy without training, confirming its effectiveness and generalizability. The code will be released upon publication.

</details>


### [103] [HiVid-Narrator: Hierarchical Video Narrative Generation with Scene-Primed ASR-anchored Compression](https://arxiv.org/abs/2601.07366)
*Haoxuan Li,Mengyan Li,Junjun Zheng*

Main category: cs.CV

TL;DR: 提出E-HVC数据集和HiVid-Narrator框架，通过分阶段构建和SPA-Compressor提升电商视频叙述质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以统一感知细粒度视觉细节并将其组织为连贯的高级故事，尤其在快节奏、信息密集的电商视频中。

Method: 采用分阶段构建方法，先通过ASR和帧级描述收集证据，再基于Temporal Chain-of-Thought细化章节边界和标题；提出SPA-Compressor压缩多模态标记为分层场景和事件表示。

Result: HiVid-Narrator在减少输入标记的同时实现了更优的叙述质量。

Conclusion: HiVid-Narrator框架通过结合SPA-Compressor和分阶段构建方法，显著提升了叙述质量并减少了输入标记，优于现有方法。

Abstract: Generating structured narrations for real-world e-commerce videos requires models to perceive fine-grained visual details and organize them into coherent, high-level stories--capabilities that existing approaches struggle to unify. We introduce the E-commerce Hierarchical Video Captioning (E-HVC) dataset with dual-granularity, temporally grounded annotations: a Temporal Chain-of-Thought that anchors event-level observations and Chapter Summary that compose them into concise, story-centric summaries. Rather than directly prompting chapters, we adopt a staged construction that first gathers reliable linguistic and visual evidence via curated ASR and frame-level descriptions, then refines coarse annotations into precise chapter boundaries and titles conditioned on the Temporal Chain-of-Thought, yielding fact-grounded, time-aligned narratives. We also observe that e-commerce videos are fast-paced and information-dense, with visual tokens dominating the input sequence. To enable efficient training while reducing input tokens, we propose the Scene-Primed ASR-anchored Compressor (SPA-Compressor), which compresses multimodal tokens into hierarchical scene and event representations guided by ASR semantic cues. Built upon these designs, our HiVid-Narrator framework achieves superior narrative quality with fewer input tokens compared to existing methods.

</details>


### [104] [Learning Dynamic Collaborative Network for Semi-supervised 3D Vessel Segmentation](https://arxiv.org/abs/2601.07377)
*Jiao Xu,Xin Chen,Lihe Zhang*

Main category: cs.CV

TL;DR: DiCo是一种动态协作网络，通过动态切换教师-学生角色和多视图集成，提升了3D血管分割的性能。


<details>
  <summary>Details</summary>
Motivation: 传统均值教师方法在3D血管数据分割中存在认知偏差，限制了性能。DiCo旨在通过动态角色切换和多视图集成来解决这一问题。

Method: 提出了一种动态协作网络（DiCo），允许教师和学生模型动态切换角色，并引入了多视图集成模块和对抗监督来优化分割效果。

Result: DiCo在三个3D血管分割基准测试中达到了最先进的性能。

Conclusion: DiCo方法在三个3D血管分割基准测试中实现了最先进的性能，证明了其动态协作网络和多视图集成模块的有效性。

Abstract: In this paper, we present a new dynamic collaborative network for semi-supervised 3D vessel segmentation, termed DiCo. Conventional mean teacher (MT) methods typically employ a static approach, where the roles of the teacher and student models are fixed. However, due to the complexity of 3D vessel data, the teacher model may not always outperform the student model, leading to cognitive biases that can limit performance. To address this issue, we propose a dynamic collaborative network that allows the two models to dynamically switch their teacher-student roles. Additionally, we introduce a multi-view integration module to capture various perspectives of the inputs, mirroring the way doctors conduct medical analysis. We also incorporate adversarial supervision to constrain the shape of the segmented vessels in unlabeled data. In this process, the 3D volume is projected into 2D views to mitigate the impact of label inconsistencies. Experiments demonstrate that our DiCo method sets new state-of-the-art performance on three 3D vessel segmentation benchmarks. The code repository address is https://github.com/xujiaommcome/DiCo

</details>


### [105] [Forecast the Principal, Stabilize the Residual: Subspace-Aware Feature Caching for Efficient Diffusion Transformers](https://arxiv.org/abs/2601.07396)
*Guantao Chen,Shikang Zheng,Yuqi Lin,Linfeng Zhang*

Main category: cs.CV

TL;DR: SVD-Cache通过SVD分解扩散特征，分别处理主成分和残差子空间，实现高效加速且兼容多种技术。


<details>
  <summary>Details</summary>
Motivation: 现有缓存方法对所有特征组件一视同仁，未考虑主成分和残差子空间的不同时间行为。

Method: 提出SVD-Cache框架，利用SVD分解扩散特征，对主成分进行EMA预测，直接重用残差子空间。

Result: 实验证明SVD-Cache在多种模型和方法上实现近无损加速，如FLUX和HunyuanVideo上5.55倍加速。

Conclusion: SVD-Cache通过分解扩散特征并分别处理主成分和残差子空间，实现了近乎无损的加速效果，兼容多种模型加速技术。

Abstract: Diffusion Transformer (DiT) models have achieved unprecedented quality in image and video generation, yet their iterative sampling process remains computationally prohibitive. To accelerate inference, feature caching methods have emerged by reusing intermediate representations across timesteps. However, existing caching approaches treat all feature components uniformly. We reveal that DiT feature spaces contain distinct principal and residual subspaces with divergent temporal behavior: the principal subspace evolves smoothly and predictably, while the residual subspace exhibits volatile, low-energy oscillations that resist accurate prediction. Building on this insight, we propose SVD-Cache, a subspace-aware caching framework that decomposes diffusion features via Singular Value Decomposition (SVD), applies exponential moving average (EMA) prediction to the dominant low-rank components, and directly reuses the residual subspace. Extensive experiments demonstrate that SVD-Cache achieves near-lossless across diverse models and methods, including 5.55$\times$ speedup on FLUX and HunyuanVideo, and compatibility with model acceleration techniques including distillation, quantization and sparse attention. Our code is in supplementary material and will be released on Github.

</details>


### [106] [SDHSI-Net: Learning Better Representations for Hyperspectral Images via Self-Distillation](https://arxiv.org/abs/2601.07416)
*Prachet Dev Singh,Shyamsundar Paramasivam,Sneha Barman,Mainak Singha,Ankit Jha,Girish Mishra,Biplab Banerjee*

Main category: cs.CV

TL;DR: 自蒸馏（SD）应用于高光谱图像分类，通过软目标提升特征空间的一致性，显著提高分类性能。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像分类面临高光谱维度和有限标注数据的挑战，传统深度学习模型易过拟合且计算成本高，自蒸馏作为一种无需外部教师网络的策略，有望提升模型性能。

Method: 通过将早期输出作为软目标，强制中间预测与最终预测的一致性，从而改善特征空间中的类内紧凑性和类间可分离性。

Result: 在两个基准HSI数据集上的实验表明，该方法显著提高了分类准确性和鲁棒性。

Conclusion: 该论文验证了自蒸馏（SD）在高光谱图像（HSI）分类中的有效性，显著提升了分类准确性和鲁棒性，展示了SD在光谱-空间学习中的潜力。

Abstract: Hyperspectral image (HSI) classification presents unique challenges due to its high spectral dimensionality and limited labeled data. Traditional deep learning models often suffer from overfitting and high computational costs. Self-distillation (SD), a variant of knowledge distillation where a network learns from its own predictions, has recently emerged as a promising strategy to enhance model performance without requiring external teacher networks. In this work, we explore the application of SD to HSI by treating earlier outputs as soft targets, thereby enforcing consistency between intermediate and final predictions. This process improves intra-class compactness and inter-class separability in the learned feature space. Our approach is validated on two benchmark HSI datasets and demonstrates significant improvements in classification accuracy and robustness, highlighting the effectiveness of SD for spectral-spatial learning. Codes are available at https://github.com/Prachet-Dev-Singh/SDHSI.

</details>


### [107] [PanoSAMic: Panoramic Image Segmentation from SAM Feature Encoding and Dual View Fusion](https://arxiv.org/abs/2601.07447)
*Mahdi Chamseddine,Didier Stricker,Jason Rambach*

Main category: cs.CV

TL;DR: PanoSAMic整合SAM编码器，优化球形图像分割，通过多模态融合和球形注意力技术，在多个数据集上达到SotA性能。


<details>
  <summary>Details</summary>
Motivation: 现有的图像基础模型主要针对透视图像训练，未优化球形图像处理。

Method: 修改SAM编码器以输出多阶段特征，并引入空间模态融合模块和语义解码器，采用球形注意力和双视图融合技术。

Result: 在Stanford2D3DS和Matterport3D数据集上，PanoSAMic在RGB、RGB-D和RGB-D-N模态中取得了最先进的结果。

Conclusion: PanoSAMic通过整合预训练的SAM编码器并引入新颖的空间模态融合模块，成功优化了球形图像的语义分割，在多个数据集上达到了最先进的性能。

Abstract: Existing image foundation models are not optimized for spherical images having been trained primarily on perspective images. PanoSAMic integrates the pre-trained Segment Anything (SAM) encoder to make use of its extensive training and integrate it into a semantic segmentation model for panoramic images using multiple modalities. We modify the SAM encoder to output multi-stage features and introduce a novel spatio-modal fusion module that allows the model to select the relevant modalities and best features from each modality for different areas of the input. Furthermore, our semantic decoder uses spherical attention and dual view fusion to overcome the distortions and edge discontinuity often associated with panoramic images. PanoSAMic achieves state-of-the-art (SotA) results on Stanford2D3DS for RGB, RGB-D, and RGB-D-N modalities and on Matterport3D for RGB and RGB-D modalities. https://github.com/dfki-av/PanoSAMic

</details>


### [108] [Improving Video Question Answering through query-based frame selection](https://arxiv.org/abs/2601.07459)
*Himanshu Patil,Geo Jolly,Ramana Raja Buddala,Ganesh Ramakrishnan,Rohit Saluja*

Main category: cs.CV

TL;DR: 提出基于SMI的查询式帧选择方法，替代均匀采样，提升VideoQA准确率4%。


<details>
  <summary>Details</summary>
Motivation: 传统VideoQA模型依赖均匀采样固定数量的帧，无法捕捉重要帧或视频上下文，限制了模型性能。

Method: 提出了一种基于查询的帧选择方法，利用子模互信息（SMI）函数选择与问题相关的帧，替代传统的均匀采样。

Result: 在MVBench数据集上，使用Video-LLaVA和LLaVA-NeXT模型，查询式帧选择比均匀采样提升了4%的准确率。

Conclusion: 基于查询的帧选择方法（使用SMI函数）能显著提升VideoQA任务的准确性，适用于依赖视频帧子集的各种任务。

Abstract: Video Question Answering (VideoQA) models enhance understanding and interaction with audiovisual content, making it more accessible, searchable, and useful for a wide range of fields such as education, surveillance, entertainment, and content creation. Due to heavy compute requirements, most large visual language models (VLMs) for VideoQA rely on a fixed number of frames by uniformly sampling the video. However, this process does not pick important frames or capture the context of the video. We present a novel query-based selection of frames relevant to the questions based on the submodular mutual Information (SMI) functions. By replacing uniform frame sampling with query-based selection, our method ensures that the chosen frames provide complementary and essential visual information for accurate VideoQA. We evaluate our approach on the MVBench dataset, which spans a diverse set of multi-action video tasks. VideoQA accuracy on this dataset was assessed using two VLMs, namely Video-LLaVA and LLaVA-NeXT, both of which originally employed uniform frame sampling. Experiments were conducted using both uniform and query-based sampling strategies. An accuracy improvement of up to \textbf{4\%} was observed when using query-based frame selection over uniform sampling. Qualitative analysis further highlights that query-based selection, using SMI functions, consistently picks frames better aligned with the question. We opine that such query-based frame selection can enhance accuracy in a wide range of tasks that rely on only a subset of video frames.

</details>


### [109] [From Sketch to Fresco: Efficient Diffusion Transformer with Progressive Resolution](https://arxiv.org/abs/2601.07462)
*Shikang Zheng,Guantao Chen,Lixuan He,Jiacheng Liu,Yuqi Lin,Chang Zou,Linfeng Zhang*

Main category: cs.CV

TL;DR: Fresco框架通过渐进式上采样和跨阶段一致性处理，显著加速Diffusion Transformers采样，保持生成质量，最高可达22倍加速。


<details>
  <summary>Details</summary>
Motivation: 现有动态分辨率采样方法在分辨率转换时依赖启发式重噪声，破坏了跨阶段一致性并导致模型需重新学习全局结构，同时不加区分地上采样整个潜在空间，导致误差累积和可见伪影。

Method: 提出了Fresco框架，采用渐进式上采样和跨阶段一致的全局结构处理，避免了现有方法中因分辨率转换导致的噪声注入和错误累积问题。

Result: Fresco在多个领域和模型上实现了近乎无损的加速，包括在FLUX上实现10倍加速，在HunyuanVideo上实现5倍加速，结合蒸馏模型时可达22倍加速。

Conclusion: Fresco框架通过统一跨阶段的重噪声和全局结构，结合渐进式上采样，实现了高效的低分辨率草稿和高分辨率精修，显著加速了Diffusion Transformers的采样过程，同时保持了生成质量。

Abstract: Diffusion Transformers achieve impressive generative quality but remain computationally expensive due to iterative sampling. Recently, dynamic resolution sampling has emerged as a promising acceleration technique by reducing the resolution of early sampling steps. However, existing methods rely on heuristic re-noising at every resolution transition, injecting noise that breaks cross-stage consistency and forces the model to relearn global structure. In addition, these methods indiscriminately upsample the entire latent space at once without checking which regions have actually converged, causing accumulated errors, and visible artifacts. Therefore, we propose \textbf{Fresco}, a dynamic resolution framework that unifies re-noise and global structure across stages with progressive upsampling, preserving both the efficiency of low-resolution drafting and the fidelity of high-resolution refinement, with all stages aligned toward the same final target. Fresco achieves near-lossless acceleration across diverse domains and models, including 10$\times$ speedup on FLUX, and 5$\times$ on HunyuanVideo, while remaining orthogonal to distillation, quantization and feature caching, reaching 22$\times$ speedup when combined with distilled models. Our code is in supplementary material and will be released on Github.

</details>


### [110] [FocalOrder: Focal Preference Optimization for Reading Order Detection](https://arxiv.org/abs/2601.07483)
*Fuyuan Liu,Dianyu Yu,He Ren,Nayu Liu,Xiaomian Kang,Delai Qiu,Fa Zhang,Genpeng Zhen,Shengping Liu,Jiaen Liang,Wei Huang,Yining Wang,Junnan Zhu*

Main category: cs.CV

TL;DR: FocalOrder通过动态识别和优化复杂布局区域，解决了阅读顺序检测中的位置差异问题，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法假设布局区域的难度分布均匀，但实际存在位置差异问题，导致模型在复杂中间区域表现不佳。

Method: FocalOrder采用自适应难度发现机制和指数移动平均来动态识别难以学习的过渡区域，并引入难度校准的成对排序目标以确保全局逻辑一致性。

Result: FocalOrder在OmniDocBench v1.0和Comp-HRDoc上取得了最先进的结果，性能优于专业基线和大规模通用VLM。

Conclusion: FocalOrder通过Focal Preference Optimization（FPO）解决了阅读顺序检测中的位置差异问题，显著提升了模型性能，并在多个基准测试中达到了最先进水平。

Abstract: Reading order detection is the foundation of document understanding. Most existing methods rely on uniform supervision, implicitly assuming a constant difficulty distribution across layout regions. In this work, we challenge this assumption by revealing a critical flaw: \textbf{Positional Disparity}, a phenomenon where models demonstrate mastery over the deterministic start and end regions but suffer a performance collapse in the complex intermediate sections. This degradation arises because standard training allows the massive volume of easy patterns to drown out the learning signals from difficult layouts. To address this, we propose \textbf{FocalOrder}, a framework driven by \textbf{Focal Preference Optimization (FPO)}. Specifically, FocalOrder employs adaptive difficulty discovery with exponential moving average mechanism to dynamically pinpoint hard-to-learn transitions, while introducing a difficulty-calibrated pairwise ranking objective to enforce global logical consistency. Extensive experiments demonstrate that FocalOrder establishes new state-of-the-art results on OmniDocBench v1.0 and Comp-HRDoc. Our compact model not only outperforms competitive specialized baselines but also significantly surpasses large-scale general VLMs. These results demonstrate that aligning the optimization with intrinsic structural ambiguity of documents is critical for mastering complex document structures.

</details>


### [111] [Anatomy Aware Cascade Network: Bridging Epistemic Uncertainty and Geometric Manifold for 3D Tooth Segmentation](https://arxiv.org/abs/2601.07499)
*Bing Yu,Liu Shi,Haitao Wang,Deran Qi,Xiang Cai,Wei Zhong,Qiegen Liu*

Main category: cs.CV

TL;DR: AACNet通过AGBR和SDMAA机制，有效解决了CBCT牙齿分割的边界模糊问题，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决CBCT图像中因低对比度和模糊边界导致的牙齿分割困难问题。

Method: 提出了一种名为AACNet的粗到精框架，包含两个关键机制：AGBR（基于熵的门控机制）和SDMAA（通过有符号距离图引入几何约束）。

Result: 在125个CBCT数据集上，AACNet的Dice相似系数达到90.17%，HD95为3.63mm，显著优于现有方法。

Conclusion: AACNet通过引入AGBR和SDMAA机制，显著提升了CBCT图像中牙齿分割的精度，并在临床应用中展现出良好的泛化能力。

Abstract: Accurate three-dimensional (3D) tooth segmentation from Cone-Beam Computed Tomography (CBCT) is a prerequisite for digital dental workflows. However, achieving high-fidelity segmentation remains challenging due to adhesion artifacts in naturally occluded scans, which are caused by low contrast and indistinct inter-arch boundaries. To address these limitations, we propose the Anatomy Aware Cascade Network (AACNet), a coarse-to-fine framework designed to resolve boundary ambiguity while maintaining global structural consistency. Specifically, we introduce two mechanisms: the Ambiguity Gated Boundary Refiner (AGBR) and the Signed Distance Map guided Anatomical Attention (SDMAA). The AGBR employs an entropy based gating mechanism to perform targeted feature rectification in high uncertainty transition zones. Meanwhile, the SDMAA integrates implicit geometric constraints via signed distance map to enforce topological consistency, preventing the loss of spatial details associated with standard pooling. Experimental results on a dataset of 125 CBCT volumes demonstrate that AACNet achieves a Dice Similarity Coefficient of 90.17 \% and a 95\% Hausdorff Distance of 3.63 mm, significantly outperforming state-of-the-art methods. Furthermore, the model exhibits strong generalization on an external dataset with an HD95 of 2.19 mm, validating its reliability for downstream clinical applications such as surgical planning. Code for AACNet is available at https://github.com/shiliu0114/AACNet.

</details>


### [112] [Mon3tr: Monocular 3D Telepresence with Pre-built Gaussian Avatars as Amortization](https://arxiv.org/abs/2601.07518)
*Fangyu Lin,Yingdong Hu,Zhening Liu,Yufan Zhuang,Zehong Lin,Jun Zhang*

Main category: cs.CV

TL;DR: Mon3tr 是一种基于3D高斯溅射的单目3D远程呈现框架，显著降低系统成本和带宽需求，实现高保真实时性能。


<details>
  <summary>Details</summary>
Motivation: 现有的沉浸式远程呈现系统依赖硬件密集型多摄像头设置和高带宽体积流，限制了移动设备上的实时性能，Mon3tr 旨在克服这些挑战。

Method: Mon3tr 采用分期计算策略，分为一次性离线多视图重建阶段和单目在线推理阶段，使用单目RGB摄像头实时捕捉身体动作和面部表情驱动3DGS模型。

Result: 实验表明，Mon3tr 在新型姿势下PSNR > 28 dB，端到端延迟约80 ms，带宽减少 > 1000倍，支持从单目输入实时操作。

Conclusion: Mon3tr 提出了一种新颖的单目3D远程呈现框架，通过集成3D高斯溅射（3DGS）参数化人体建模，显著降低了系统复杂性和成本，同时实现了高保真度和实时性能。

Abstract: Immersive telepresence aims to transform human interaction in AR/VR applications by enabling lifelike full-body holographic representations for enhanced remote collaboration. However, existing systems rely on hardware-intensive multi-camera setups and demand high bandwidth for volumetric streaming, limiting their real-time performance on mobile devices. To overcome these challenges, we propose Mon3tr, a novel Monocular 3D telepresence framework that integrates 3D Gaussian splatting (3DGS) based parametric human modeling into telepresence for the first time. Mon3tr adopts an amortized computation strategy, dividing the process into a one-time offline multi-view reconstruction phase to build a user-specific avatar and a monocular online inference phase during live telepresence sessions. A single monocular RGB camera is used to capture body motions and facial expressions in real time to drive the 3DGS-based parametric human model, significantly reducing system complexity and cost. The extracted motion and appearance features are transmitted at < 0.2 Mbps over WebRTC's data channel, allowing robust adaptation to network fluctuations. On the receiver side, e.g., Meta Quest 3, we develop a lightweight 3DGS attribute deformation network to dynamically generate corrective 3DGS attribute adjustments on the pre-built avatar, synthesizing photorealistic motion and appearance at ~ 60 FPS. Extensive experiments demonstrate the state-of-the-art performance of our method, achieving a PSNR of > 28 dB for novel poses, an end-to-end latency of ~ 80 ms, and > 1000x bandwidth reduction compared to point-cloud streaming, while supporting real-time operation from monocular inputs across diverse scenarios. Our demos can be found at https://mon3tr3d.github.io.

</details>


### [113] [ViewMorpher3D: A 3D-aware Diffusion Framework for Multi-Camera Novel View Synthesis in Autonomous Driving](https://arxiv.org/abs/2601.07540)
*Farhad G. Zanjani,Hong Cai,Amirhossein Habibian*

Main category: cs.CV

TL;DR: ViewMorpher3D是一个基于扩散模型的多视角图像增强框架，旨在提升驾驶场景中的真实性和多视角一致性，减少渲染伪影。


<details>
  <summary>Details</summary>
Motivation: 为了解决3D重建技术（如高斯泼溅）在模拟器中渲染新视角时出现的伪影问题，尤其是在外推视角或观测稀疏的情况下。

Method: 基于图像扩散模型的多视角图像增强框架，联合处理一组渲染视图，利用相机姿态、3D几何先验和时空参考视图进行条件生成。

Result: 在真实驾驶数据集上的实验表明，图像质量指标有显著提升，有效减少了伪影并保持了几何保真度。

Conclusion: ViewMorpher3D显著提升了多视角图像的真实性和一致性，有效减少了渲染伪影，同时保持了几何保真度，适用于多样化的传感器配置。

Abstract: Autonomous driving systems rely heavily on multi-view images to ensure accurate perception and robust decision-making. To effectively develop and evaluate perception stacks and planning algorithms, realistic closed-loop simulators are indispensable. While 3D reconstruction techniques such as Gaussian Splatting offer promising avenues for simulator construction, the rendered novel views often exhibit artifacts, particularly in extrapolated perspectives or when available observations are sparse.
  We introduce ViewMorpher3D, a multi-view image enhancement framework based on image diffusion models, designed to elevate photorealism and multi-view coherence in driving scenes. Unlike single-view approaches, ViewMorpher3D jointly processes a set of rendered views conditioned on camera poses, 3D geometric priors, and temporally adjacent or spatially overlapping reference views. This enables the model to infer missing details, suppress rendering artifacts, and enforce cross-view consistency.
  Our framework accommodates variable numbers of cameras and flexible reference/target view configurations, making it adaptable to diverse sensor setups. Experiments on real-world driving datasets demonstrate substantial improvements in image quality metrics, effectively reducing artifacts while preserving geometric fidelity.

</details>


### [114] [BenchSeg: A Large-Scale Dataset and Benchmark for Multi-View Food Video Segmentation](https://arxiv.org/abs/2601.07581)
*Ahmad AlMughrabi,Guillermo Rivo,Carlos Jiménez-Farfán,Umair Haroon,Farid Al-Areqi,Hyunjun Jung,Benjamin Busam,Ricardo Marques,Petia Radeva*

Main category: cs.CV

TL;DR: 提出了多视角食物视频分割数据集BenchSeg，评估多种分割模型，发现记忆增强方法性能更优，最佳模型提升2.63% mAP。


<details>
  <summary>Details</summary>
Motivation: 当前食物图像分割方法在多视角数据和泛化能力上存在局限，影响了饮食分析的准确性。

Method: 提出了BenchSeg数据集，包含55个菜肴场景的25,284帧标注数据，评估了20种最先进的分割模型（如SAM-based、transformer、CNN等），并测试了视频记忆模块的增强效果。

Result: 实验表明，标准图像分割器在新视角下性能显著下降，而记忆增强方法能保持时间一致性。最佳模型SeTR-MLA+XMem2比之前工作提升了约2.63% mAP。

Conclusion: BenchSeg数据集和基准测试的发布，结合SeTR-MLA+XMem2模型，显著提升了多视角食物图像分割的性能，为饮食分析提供了新的研究方向和工具。

Abstract: Food image segmentation is a critical task for dietary analysis, enabling accurate estimation of food volume and nutrients. However, current methods suffer from limited multi-view data and poor generalization to new viewpoints. We introduce BenchSeg, a novel multi-view food video segmentation dataset and benchmark. BenchSeg aggregates 55 dish scenes (from Nutrition5k, Vegetables & Fruits, MetaFood3D, and FoodKit) with 25,284 meticulously annotated frames, capturing each dish under free 360° camera motion. We evaluate a diverse set of 20 state-of-the-art segmentation models (e.g., SAM-based, transformer, CNN, and large multimodal) on the existing FoodSeg103 dataset and evaluate them (alone and combined with video-memory modules) on BenchSeg. Quantitative and qualitative results demonstrate that while standard image segmenters degrade sharply under novel viewpoints, memory-augmented methods maintain temporal consistency across frames. Our best model based on a combination of SeTR-MLA+XMem2 outperforms prior work (e.g., improving over FoodMem by ~2.63% mAP), offering new insights into food segmentation and tracking for dietary analysis. We release BenchSeg to foster future research. The project page including the dataset annotations and the food segmentation models can be found at https://amughrabi.github.io/benchseg.

</details>


### [115] [Robust Multicentre Detection and Classification of Colorectal Liver Metastases on CT: Application of Foundation Models](https://arxiv.org/abs/2601.07585)
*Shruti Atul Mali,Zohaib Salahuddin,Yumeng Zhang,Andre Aichert,Xian Zhong,Henry C. Woodruff,Maciej Bobowicz,Katrine Riklund,Juozas Kupčinskas,Lorenzo Faggioni,Roberto Francischello,Razvan L Miclea,Philippe Lambin*

Main category: cs.CV

TL;DR: 开发了一个基于基础模型的AI流程，用于CRLM的检测和分类，在多中心CT数据上表现优异，且具有可解释性。


<details>
  <summary>Details</summary>
Motivation: 结直肠肝转移（CRLM）是癌症相关死亡的主要原因，但在多中心环境中，CT上的可靠检测仍然具有挑战性。

Method: 开发了一个基于基础模型的AI流程，用于患者级分类和病灶级检测，整合了不确定性量化和可解释性。使用了EuCanImage联盟（n=2437）和外部TCIA队列（n=197）的CT数据。在多个预训练模型中，UMedPT表现最佳，并通过MLP头部进行微调用于分类，基于FCOS的头部用于病灶检测。

Result: 分类模型在组合测试集上实现了0.90的AUC和0.82的灵敏度，外部队列的灵敏度为0.85。排除最不确定的20%病例后，AUC提高到0.91，平衡准确率提高到0.86。检测模型总体识别了69.1%的病灶，从30%到98%不等。Grad-CAM在高置信度病例中突出了病灶对应区域。

Conclusion: 基于基础模型的AI流程能够支持跨异构CT数据的稳健且可解释的CRLM检测和分类。

Abstract: Colorectal liver metastases (CRLM) are a major cause of cancer-related mortality, and reliable detection on CT remains challenging in multi-centre settings. We developed a foundation model-based AI pipeline for patient-level classification and lesion-level detection of CRLM on contrast-enhanced CT, integrating uncertainty quantification and explainability. CT data from the EuCanImage consortium (n=2437) and an external TCIA cohort (n=197) were used. Among several pretrained models, UMedPT achieved the best performance and was fine-tuned with an MLP head for classification and an FCOS-based head for lesion detection. The classification model achieved an AUC of 0.90 and a sensitivity of 0.82 on the combined test set, with a sensitivity of 0.85 on the external cohort. Excluding the most uncertain 20 percent of cases improved AUC to 0.91 and balanced accuracy to 0.86. Decision curve analysis showed clinical benefit for threshold probabilities between 0.30 and 0.40. The detection model identified 69.1 percent of lesions overall, increasing from 30 percent to 98 percent across lesion size quartiles. Grad-CAM highlighted lesion-corresponding regions in high-confidence cases. These results demonstrate that foundation model-based pipelines can support robust and interpretable CRLM detection and classification across heterogeneous CT data.

</details>


### [116] [Diffusion in SPAD Signals](https://arxiv.org/abs/2601.07599)
*Lior Dvir,Nadav Torem,Yoav Y. Schechner*

Main category: cs.CV

TL;DR: 本文推导了SPAD信号的似然和得分函数，利用扩散模型解决逆问题，并分析了光子计数和时序的影响。


<details>
  <summary>Details</summary>
Motivation: 解决SPAD信号的非线性和随机性带来的逆问题挑战。

Method: 使用扩散模型表达图像先验，推导SPAD原始信号的似然函数和得分函数。

Result: 展示了低或高光子计数以及利用检测事件时序的后果。

Conclusion: 本文通过推导SPAD信号的似然函数和得分函数，为基于SPAD信号的逆问题提供了关键解决方案，并展示了不同光子计数和检测事件时序的影响。

Abstract: We derive the likelihood of a raw signal in a single photon avalanche diode (SPAD), given a fixed photon flux. The raw signal comprises timing of detection events, which are nonlinearly related to the flux. Moreover, they are naturally stochastic. We then derive a score function of the signal. This is a key for solving inverse problems based on SPAD signals. We focus on deriving solutions involving a diffusion model, to express image priors. We demonstrate the effect of low or high photon counts, and the consequence of exploiting timing of detection events.

</details>


### [117] [UIKA: Fast Universal Head Avatar from Pose-Free Images](https://arxiv.org/abs/2601.07603)
*Zijian Wu,Boyao Zhou,Liangxiao Hu,Hongyu Liu,Yuan Sun,Xuan Wang,Xun Cao,Yujun Shen,Hao Zhu*

Main category: cs.CV

TL;DR: UIKA是一种基于高斯模型的头像建模方法，通过UV引导策略和可学习令牌，简化了传统复杂流程，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 传统头像方法需要复杂的多视角捕捉系统和长时间优化，UIKA旨在通过改进模型表示、网络设计和数据准备来简化这一过程。

Method: 采用UV引导的头像建模策略，结合像素级面部对应估计和可学习的UV令牌，通过注意力机制在屏幕和UV级别处理输入信息。

Result: UIKA在单目和多视角输入下均表现出色，优于现有方法。

Conclusion: UIKA模型在单目和多视角设置中显著优于现有方法，通过UV引导的建模策略和可学习的UV令牌实现了高效的头像建模。

Abstract: We present UIKA, a feed-forward animatable Gaussian head model from an arbitrary number of unposed inputs, including a single image, multi-view captures, and smartphone-captured videos. Unlike the traditional avatar method, which requires a studio-level multi-view capture system and reconstructs a human-specific model through a long-time optimization process, we rethink the task through the lenses of model representation, network design, and data preparation. First, we introduce a UV-guided avatar modeling strategy, in which each input image is associated with a pixel-wise facial correspondence estimation. Such correspondence estimation allows us to reproject each valid pixel color from screen space to UV space, which is independent of camera pose and character expression. Furthermore, we design learnable UV tokens on which the attention mechanism can be applied at both the screen and UV levels. The learned UV tokens can be decoded into canonical Gaussian attributes using aggregated UV information from all input views. To train our large avatar model, we additionally prepare a large-scale, identity-rich synthetic training dataset. Our method significantly outperforms existing approaches in both monocular and multi-view settings. Project page: https://zijian-wu.github.io/uika-page/

</details>


### [118] [PARL: Position-Aware Relation Learning Network for Document Layout Analysis](https://arxiv.org/abs/2601.07620)
*Fuyuan Liu,Dianyu Yu,He Ren,Nayu Liu,Xiaomian Kang,Delai Qiu,Fa Zhang,Genpeng Zhen,Shengping Liu,Jiaen Liang,Wei Huang,Yining Wang,Junnan Zhu*

Main category: cs.CV

TL;DR: PARL是一种无OCR的视觉文档布局分析框架，通过位置感知和关系学习实现高效鲁棒的布局分析，性能超越多模态方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖高质量OCR，导致文本识别错误传播和计算开销大，限制了多模态方法的鲁棒性和实用性。

Method: 提出了一种名为PARL的无OCR、仅视觉框架，包括双向空间位置引导的可变形注意力模块和图形细化分类器（GRC）。

Result: PARL在DocLayNet上为仅视觉方法设立了新基准，并在M6Doc上超越了强大的多模态模型，且参数数量仅为大型多模态模型的四分之一。

Conclusion: PARL通过仅依赖视觉特征的方法，在文档布局分析任务中实现了高效且鲁棒的性能，证明了视觉结构建模可以比多模态融合更高效和稳健。

Abstract: Document layout analysis aims to detect and categorize structural elements (e.g., titles, tables, figures) in scanned or digital documents. Popular methods often rely on high-quality Optical Character Recognition (OCR) to merge visual features with extracted text. This dependency introduces two major drawbacks: propagation of text recognition errors and substantial computational overhead, limiting the robustness and practical applicability of multimodal approaches. In contrast to the prevailing multimodal trend, we argue that effective layout analysis depends not on text-visual fusion, but on a deep understanding of documents' intrinsic visual structure. To this end, we propose PARL (Position-Aware Relation Learning Network), a novel OCR-free, vision-only framework that models layout through positional sensitivity and relational structure. Specifically, we first introduce a Bidirectional Spatial Position-Guided Deformable Attention module to embed explicit positional dependencies among layout elements directly into visual features. Second, we design a Graph Refinement Classifier (GRC) to refine predictions by modeling contextual relationships through a dynamically constructed layout graph. Extensive experiments show PARL achieves state-of-the-art results. It establishes a new benchmark for vision-only methods on DocLayNet and, notably, surpasses even strong multimodal models on M6Doc. Crucially, PARL (65M) is highly efficient, using roughly four times fewer parameters than large multimodal models (256M), demonstrating that sophisticated visual structure modeling can be both more efficient and robust than multimodal fusion.

</details>


### [119] [GeoMotionGPT: Geometry-Aligned Motion Understanding with Large Language Models](https://arxiv.org/abs/2601.07632)
*Zhankai Ye,Bofan Li,Yukai Jin,Shuoqiu Li,Wei Wang,Yanfu Zhang,Shangqian Gao,Xin Liu*

Main category: cs.CV

TL;DR: 提出了一种统一运动量化与语义嵌入几何基础的新框架，显著提升了LLM的细粒度运动推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法将运动量化与语义嵌入学习解耦，仅通过令牌ID连接，未能有效对齐运动空间与嵌入空间的几何结构，限制了LLM的细粒度运动推理能力。

Method: 采用解码器专用的量化器结合Gumbel-Softmax进行可微分训练，使用稀疏投影保持正交性，并通过两阶段正交正则化调度维持几何对齐。

Result: 在HumanML3D数据集上的实验表明，该框架比当前最优方法性能提升了20%。

Conclusion: 通过统一运动量化与语义嵌入学习的几何基础，提出了一种新颖的框架，显著提升了LLM在运动推理任务中的性能，实验验证了其有效性。

Abstract: Discrete motion tokenization has recently enabled Large Language Models (LLMs) to serve as versatile backbones for motion understanding and motion-language reasoning. However, existing pipelines typically decouple motion quantization from semantic embedding learning, linking them solely via token IDs. This approach fails to effectively align the intrinsic geometry of the motion space with the embedding space, thereby hindering the LLM's capacity for nuanced motion reasoning. We argue that alignment is most effective when both modalities share a unified geometric basis. Therefore, instead of forcing the LLM to reconstruct the complex geometry among motion tokens from scratch, we present a novel framework that explicitly enforces orthogonality on both the motion codebook and the LLM embedding space, ensuring that their relational structures naturally mirror each other. Specifically, we employ a decoder-only quantizer with Gumbel-Softmax for differentiable training and balanced codebook usage. To bridge the modalities, we use a sparse projection that maps motion codes into the LLM embedding space while preserving orthogonality. Finally, a two-stage orthonormal regularization schedule enforces soft constraints during tokenizer training and LLM fine-tuning to maintain geometric alignment without hindering semantic adaptation. Extensive experiments on HumanML3D demonstrate that our framework achieves a 20% performance improvement over current state-of-the-art methods, validating that a unified geometric basis effectively empowers the LLM for nuanced motion reasoning.

</details>


### [120] [StdGEN++: A Comprehensive System for Semantic-Decomposed 3D Character Generation](https://arxiv.org/abs/2601.07660)
*Yuze He,Yanning Zhou,Wang Zhao,Jingwen Ye,Zhongkai Wu,Ran Yi,Yong-Jin Liu*

Main category: cs.CV

TL;DR: StdGEN++ 是一个创新的3D角色生成系统，通过双分支模型和语义解耦技术，显著提升生成质量和下游应用灵活性。


<details>
  <summary>Details</summary>
Motivation: 现有3D生成方法常产生缺乏结构灵活性的单一网格，无法满足游戏和动画工业管线的需求。StdGEN++旨在填补这一空白，提供高保真且语义解耦的3D角色生成。

Method: StdGEN++ 采用双分支语义感知大重建模型（Dual-Branch S-LRM）联合重建几何、颜色和每组件语义，并结合粗到细的提案方案加速高分辨率网格生成。此外，视频扩散纹理分解模块用于解耦可编辑的外观层。

Result: 实验表明，StdGEN++在几何精度和语义解耦方面显著优于现有方法，实现了最先进的性能。

Conclusion: StdGEN++ 通过其创新的双分支语义感知大重建模型和语义表面提取机制，显著提升了3D角色生成的几何精度和语义解耦能力，为自动化角色资产生产提供了强大解决方案。

Abstract: We present StdGEN++, a novel and comprehensive system for generating high-fidelity, semantically decomposed 3D characters from diverse inputs. Existing 3D generative methods often produce monolithic meshes that lack the structural flexibility required by industrial pipelines in gaming and animation. Addressing this gap, StdGEN++ is built upon a Dual-branch Semantic-aware Large Reconstruction Model (Dual-Branch S-LRM), which jointly reconstructs geometry, color, and per-component semantics in a feed-forward manner. To achieve production-level fidelity, we introduce a novel semantic surface extraction formalism compatible with hybrid implicit fields. This mechanism is accelerated by a coarse-to-fine proposal scheme, which significantly reduces memory footprint and enables high-resolution mesh generation. Furthermore, we propose a video-diffusion-based texture decomposition module that disentangles appearance into editable layers (e.g., separated iris and skin), resolving semantic confusion in facial regions. Experiments demonstrate that StdGEN++ achieves state-of-the-art performance, significantly outperforming existing methods in geometric accuracy and semantic disentanglement. Crucially, the resulting structural independence unlocks advanced downstream capabilities, including non-destructive editing, physics-compliant animation, and gaze tracking, making it a robust solution for automated character asset production.

</details>


### [121] [Variational Contrastive Learning for Skeleton-based Action Recognition](https://arxiv.org/abs/2601.07666)
*Dang Dinh Nguyen,Decky Aspandi Latif,Titus Zaharia*

Main category: cs.CV

TL;DR: 提出变分对比学习框架，结合概率建模与对比学习，显著提升骨架动作识别效果。


<details>
  <summary>Details</summary>
Motivation: 现有对比学习范式难以捕捉人类动作的变异性和不确定性。

Method: 整合概率潜在建模与对比自监督学习，形成变分对比学习框架。

Result: 在三个广泛使用的基准测试中表现优于现有方法，特征更相关且关注重要关节。

Conclusion: 提出的变分对比学习框架在骨架动作识别中表现优异，尤其在低标签情况下优于现有方法。

Abstract: In recent years, self-supervised representation learning for skeleton-based action recognition has advanced with the development of contrastive learning methods. However, most of contrastive paradigms are inherently discriminative and often struggle to capture the variability and uncertainty intrinsic to human motion. To address this issue, we propose a variational contrastive learning framework that integrates probabilistic latent modeling with contrastive self-supervised learning. This formulation enables the learning of structured and semantically meaningful representations that generalize across different datasets and supervision levels. Extensive experiments on three widely used skeleton-based action recognition benchmarks show that our proposed method consistently outperforms existing approaches, particularly in low-label regimes. Moreover, qualitative analyses show that the features provided by our method are more relevant given the motion and sample characteristics, with more focus on important skeleton joints, when compared to the other methods.

</details>


### [122] [Advancing Multinational License Plate Recognition Through Synthetic and Real Data Fusion: A Comprehensive Evaluation](https://arxiv.org/abs/2601.07671)
*Rayson Laroca,Valter Estevam,Gladston J. P. Moreira,Rodrigo Minetto,David Menotti*

Main category: cs.CV

TL;DR: 本研究通过整合真实与合成数据，显著提升了车牌识别性能，并探索了三种合成数据生成方法，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管已有研究使用合成图像提升车牌识别效果，但仍存在局限性，本研究旨在通过整合真实与合成数据来克服这些限制。

Method: 对16个OCR模型进行了基准测试，涉及12个公共数据集，并探索了三种合成数据生成方法：基于模板的生成、字符排列和GAN模型。

Result: 合成数据的大规模整合显著提升了模型性能，尤其在训练数据有限的情况下表现优异，同时研究了不同模型在准确性与速度之间的权衡。

Conclusion: 综合使用合成数据的方法显著提升了车牌识别的性能，超越了现有先进方法和商业系统。

Abstract: Automatic License Plate Recognition is a frequent research topic due to its wide-ranging practical applications. While recent studies use synthetic images to improve License Plate Recognition (LPR) results, there remain several limitations in these efforts. This work addresses these constraints by comprehensively exploring the integration of real and synthetic data to enhance LPR performance. We subject 16 Optical Character Recognition (OCR) models to a benchmarking process involving 12 public datasets acquired from various regions. Several key findings emerge from our investigation. Primarily, the massive incorporation of synthetic data substantially boosts model performance in both intra- and cross-dataset scenarios. We examine three distinct methodologies for generating synthetic data: template-based generation, character permutation, and utilizing a Generative Adversarial Network (GAN) model, each contributing significantly to performance enhancement. The combined use of these methodologies demonstrates a notable synergistic effect, leading to end-to-end results that surpass those reached by state-of-the-art methods and established commercial systems. Our experiments also underscore the efficacy of synthetic data in mitigating challenges posed by limited training data, enabling remarkable results to be achieved even with small fractions of the original training data. Finally, we investigate the trade-off between accuracy and speed among different models, identifying those that strike the optimal balance in each intra-dataset and cross-dataset settings.

</details>


### [123] [Leveraging 3D Representation Alignment and RGB Pretrained Priors for LiDAR Scene Generation](https://arxiv.org/abs/2601.07692)
*Nicolas Sereyjol-Garros,Ellington Kirby,Victor Besnier,Nermin Samet*

Main category: cs.CV

TL;DR: R3DPA是首个利用图像预训练先验和自监督3D表示的LiDAR场景生成方法，在KITTI-360上达到SOTA性能。


<details>
  <summary>Details</summary>
Motivation: LiDAR场景合成是解决机器人任务（如自动驾驶）中3D数据稀缺的新兴方案。现有方法虽使用扩散或流匹配模型，但3D数据仍远少于RGB数据集。

Method: R3DPA通过（i）将生成模型的中间特征与自监督3D特征对齐，（ii）从大规模图像预训练生成模型中转移知识，（iii）在推理时实现点云控制（如对象修复和场景混合），来生成LiDAR场景。

Result: R3DPA显著提升了生成质量，并成功将图像预训练知识迁移至LiDAR生成，缓解了数据限制。

Conclusion: R3DPA在KITTI-360基准测试中实现了最先进的性能，通过利用图像预训练先验和自监督3D表示，解决了LiDAR数据稀缺的问题。

Abstract: LiDAR scene synthesis is an emerging solution to scarcity in 3D data for robotic tasks such as autonomous driving. Recent approaches employ diffusion or flow matching models to generate realistic scenes, but 3D data remains limited compared to RGB datasets with millions of samples. We introduce R3DPA, the first LiDAR scene generation method to unlock image-pretrained priors for LiDAR point clouds, and leverage self-supervised 3D representations for state-of-the-art results. Specifically, we (i) align intermediate features of our generative model with self-supervised 3D features, which substantially improves generation quality; (ii) transfer knowledge from large-scale image-pretrained generative models to LiDAR generation, mitigating limited LiDAR datasets; and (iii) enable point cloud control at inference for object inpainting and scene mixing with solely an unconditional model. On the KITTI-360 benchmark R3DPA achieves state of the art performance. Code and pretrained models are available at https://github.com/valeoai/R3DPA.

</details>


### [124] [Smooth Operator: Smooth Verifiable Reward Activates Spatial Reasoning Ability of Vision-Language Model](https://arxiv.org/abs/2601.07695)
*Siwen Jiao,Tianxiong Lv,Kangan Qian,Chenxu Zhao,Xiuyuan Zhu,Tianlun Li,Xiaolong Cheng,Jinyu Li,Zhihao Liao,Yang Cai*

Main category: cs.CV

TL;DR: AP-GRPO框架通过SNRA操作符和绝对标量梯度，解决了3D场景理解中的奖励稀疏问题，提升了数值预测精度和数据效率。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法在3D场景理解中面临奖励稀疏和梯度不稳定的问题，导致无法有效利用3D物理约束提供的可验证信号，特别是'近错过'样本在优化过程中被丢弃。

Method: 提出了Smooth Numerical Reward Activation (SNRA)操作符和Absolute-Preserving GRPO (AP-GRPO)框架，前者通过动态参数化的Sigmoid函数将原始反馈转化为密集连续的奖励连续体，后者整合绝对标量梯度以减少传统相对排名机制中的数值信息损失。

Result: 构建了Numerical3D-50k数据集，实验表明AP-GRPO在保持高数据效率的同时，性能与大规模监督方法相当，有效激活了VLM中的潜在3D推理能力。

Conclusion: AP-GRPO框架结合SNRA操作符，显著提升了3D场景理解中数值预测的精确度，同时保持了较高的数据效率，无需修改VLM架构即可激活潜在的3D推理能力。

Abstract: Vision-Language Models (VLMs) face a critical bottleneck in achieving precise numerical prediction for 3D scene understanding. Traditional reinforcement learning (RL) approaches, primarily based on relative ranking, often suffer from severe reward sparsity and gradient instability, failing to effectively exploit the verifiable signals provided by 3D physical constraints. Notably, in standard GRPO frameworks, relative normalization causes "near-miss" samples (characterized by small but non-zero errors) to suffer from advantage collapse. This leads to a severe data utilization bottleneck where valuable boundary samples are discarded during optimization. To address this, we introduce the Smooth Numerical Reward Activation (SNRA) operator and the Absolute-Preserving GRPO (AP-GRPO) framework. SNRA employs a dynamically parameterized Sigmoid function to transform raw feedback into a dense, continuous reward continuum. Concurrently, AP-GRPO integrates absolute scalar gradients to mitigate the numerical information loss inherent in conventional relative-ranking mechanisms. By leveraging this approach, we constructed Numerical3D-50k, a dataset comprising 50,000 verifiable 3D subtasks. Empirical results indicate that AP-GRPO achieves performance parity with large-scale supervised methods while maintaining higher data efficiency, effectively activating latent 3D reasoning in VLMs without requiring architectural modifications.

</details>


### [125] [Hidden Monotonicity: Explaining Deep Neural Networks via their DC Decomposition](https://arxiv.org/abs/2601.07700)
*Jakob Paul Zimmermann,Georg Loho*

Main category: cs.CV

TL;DR: 通过分解ReLU网络和训练差异模型，利用单调性显著提升神经网络的可解释性，并在实验中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管并非所有函数都能被单调神经网络良好近似，但单调性仍可用于提升神经网络的可解释性。

Method: 1. 将训练好的ReLU网络分解为两个单调凸部分，克服权重爆炸的数值障碍；2. 训练模型作为两个单调神经网络的差异。

Result: 提出的显著性方法（SplitCAM和SplitLRP）在VGG16和Resnet18网络上，针对ImageNet-S的所有Quantus显著性指标类别均优于现有技术。

Conclusion: 通过两种方法利用单调性提升神经网络的可解释性：分解训练好的ReLU网络为两个单调凸部分，以及训练模型作为两个单调神经网络的差异，均取得显著效果。

Abstract: It has been demonstrated in various contexts that monotonicity leads to better explainability in neural networks. However, not every function can be well approximated by a monotone neural network. We demonstrate that monotonicity can still be used in two ways to boost explainability. First, we use an adaptation of the decomposition of a trained ReLU network into two monotone and convex parts, thereby overcoming numerical obstacles from an inherent blowup of the weights in this procedure. Our proposed saliency methods -- SplitCAM and SplitLRP -- improve on state of the art results on both VGG16 and Resnet18 networks on ImageNet-S across all Quantus saliency metric categories. Second, we exhibit that training a model as the difference between two monotone neural networks results in a system with strong self-explainability properties.

</details>


### [126] [Evaluating the encoding competence of visual language models using uncommon actions](https://arxiv.org/abs/2601.07737)
*Chen Ling,Nai Ding*

Main category: cs.CV

TL;DR: 提出了UAIT数据集，用于测试视觉语言模型在反常识场景中的语义理解能力。通过半自动化流程生成样本，实验显示模型表现不及人类，但微调后有所改进。


<details>
  <summary>Details</summary>
Motivation: 测试视觉语言模型在反常识动作场景中的语义理解能力，超越常见的视觉场景，挑战模型对代理-患者关系和物理可行性的深层理解。

Method: 设计了半自动化流程，结合大型语言模型、少样本提示工程和文本到图像生成技术，合成高质量的反常识图像-文本样本。每个样本配有精心设计的多选题，测试模型在细粒度推理中的能力。

Result: 实验表明，所有模型在语义判断上的表现均显著低于人类，尤其是在区分语法正确性与语义合理性方面。轻量级模型经过微调后准确率有所提升，显示了定向适应的巨大潜力。

Conclusion: 该研究不仅揭示了视觉语言模型（VLMs）的关键弱点，还为开发具有真实视觉语义推理能力的稳健模型提供了诊断工具和研究方向。

Abstract: We propose UAIT (Uncommon-sense Action Image-Text) dataset, a new evaluation benchmark designed to test the semantic understanding ability of visual language models (VLMs) in uncommon-sense action scenes. Unlike previous datasets that focus on common visual scenes with statistical frequency advantages, UAIT challenges models with grammatically reasonable but semantically counter-common sense image-text pairs. Such tasks require models to go beyond superficial pattern recognition and demonstrate a deep understanding of agent-patient relationships and physical feasibility. To build UAIT, we designed a semi-automated process to synthesize high-quality uncommon-sense image-text samples using large language models, few-shot prompt engineering, and text-to-image generation. Each sample is accompanied by a carefully designed multiple-choice question to test the model's competence in fine-grained reasoning. We evaluate multiple state-of-the-art visual language models and compare them with models based on contrastive learning. Experiments show that all models perform significantly worse than humans in semantic judgment, especially in distinguishing grammatical correctness from semantic rationality. Further experiments show that even the lightweight model can improve its accuracy after fine-tuning, demonstrating the great potential of directional adaptation. This study not only reveals the key weaknesses of VLMs, but also provides diagnostic tools and research directions for the development of robust models with real visual semantic reasoning capabilities.

</details>


### [127] [On the application of the Wasserstein metric to 2D curves classification](https://arxiv.org/abs/2601.07749)
*Agnieszka Kaliszewska,Monika Syga*

Main category: cs.CV

TL;DR: 提出聚焦2D曲线片段的Wasserstein距离变体，实验验证其在考古数据聚类中的有效性。


<details>
  <summary>Details</summary>
Motivation: 为了在2D曲线分类中更有效地关注特定片段，提升分类的精确性和实用性。

Method: 使用离散概率度量来反映曲线片段的重要性，开发了多种Wasserstein距离的变体。

Result: 通过考古学数据的实验验证，该方法在聚类分析中表现出色。

Conclusion: 该论文提出了一种基于Wasserstein距离变体的方法，能够聚焦于2D曲线的特定片段进行分类，并通过考古学数据的聚类分析验证了其性能。

Abstract: In this work we analyse a number of variants of the Wasserstein distance which allow to focus the classification on the prescribed parts (fragments) of classified 2D curves. These variants are based on the use of a number of discrete probability measures which reflect the importance of given fragments of curves. The performance of this approach is tested through a series of experiments related to the clustering analysis of 2D curves performed on data coming from the field of archaeology.

</details>


### [128] [Video Evidence to Reasoning Efficient Video Understanding via Explicit Evidence Grounding](https://arxiv.org/abs/2601.07761)
*Yanxiang Huang,Guohua Gao,Zhaoyang Wei,Jianyuan Ni*

Main category: cs.CV

TL;DR: CoE框架通过动态提取视觉证据和强化学习优化，显著提升视频推理的准确性和效率，成为新SOTA。


<details>
  <summary>Details</summary>
Motivation: 解决大型视觉语言模型在视频推理中计算成本高与幻觉风险大的两难问题。

Method: 提出了Chain of Evidence (CoE)框架，包含轻量级证据基础模块(EGM)和通过强化学习优化的证据锚定协议，设计了复合奖励机制以确保过程对齐。

Result: 在五个基准测试中（包括Video-MME、MVBench和VSI-Bench），CoE增强模型显著优于现有方法，准确率最高。

Conclusion: CoE框架通过解耦感知基础和推理效率，并引入EGM和证据锚定协议，显著提升了视频理解的准确性和可靠性，成为该领域的新标杆。

Abstract: Large Vision-Language Models (LVLMs) face a fundamental dilemma in video reasoning: they are caught between the prohibitive computational costs of verbose reasoning and the hallucination risks of efficient, ungrounded approaches. To resolve this, we introduce the Chain of Evidence (CoE), a novel framework that architecturally decouples and co-optimizes perceptual grounding and reasoning efficiency. CoE incorporates two core innovations: (1) A lightweight Evidence Grounding Module (EGM) that acts as a query-guided filter, dynamically identifying and extracting a compact set of high-fidelity visual evidence; and (2) An Evidence-Anchoring Protocol optimized via Reinforcement Learning. Crucially, we design a composite reward mechanism that enforces process alignment, compelling the model to strictly reference identified temporal anchors during deduction, thereby mitigating hallucinations. To enable this, we construct CoE-Instruct, a large-scale dataset (164k samples) featuring a novel dual-annotation schema for separate perception and reasoning supervision. Extensive experiments on five benchmarks, including Video-MME, MVBench, and VSI-Bench, demonstrate that CoE-enhanced models establish a new state-of-the-art. They significantly outperform existing methods in accuracy, proving CoE to be a powerful and practical paradigm for reliable video understanding.

</details>


### [129] [Beyond External Guidance: Unleashing the Semantic Richness Inside Diffusion Transformers for Improved Training](https://arxiv.org/abs/2601.07773)
*Lingchen Sun,Rongyuan Wu,Zhengqiang Zhang,Ruibin Li,Yujing Sun,Shuaizheng Liu,Lei Zhang*

Main category: cs.CV

TL;DR: Self-Transcendence是一种仅依赖内部特征监督的DiT训练方法，显著提升效率和质量，无需外部模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法（如REPA）依赖外部预训练网络，增加了依赖性和降低了灵活性。DiT本身具备自我引导训练的潜力，无需外部依赖。

Method: 提出Self-Transcendence方法，通过短暂对齐浅层特征与VAE潜在表示，再对中间特征应用无分类器引导，增强其判别能力和语义表达能力，最后用这些内部特征作为监督信号指导新DiT训练。

Result: Self-Transcendence在生成质量和收敛速度上超越现有自包含方法，甚至优于REPA，且无需外部预训练模型。

Conclusion: Self-Transcendence方法通过内部特征监督显著提升了DiT的训练效率和生成质量，无需依赖外部预训练模型，具有更高的灵活性和广泛适用性。

Abstract: Recent works such as REPA have shown that guiding diffusion models with external semantic features (e.g., DINO) can significantly accelerate the training of diffusion transformers (DiTs). However, this requires the use of pretrained external networks, introducing additional dependencies and reducing flexibility. In this work, we argue that DiTs actually have the power to guide the training of themselves, and propose \textbf{Self-Transcendence}, a simple yet effective method that achieves fast convergence using internal feature supervision only. It is found that the slow convergence in DiT training primarily stems from the difficulty of representation learning in shallow layers. To address this, we initially train the DiT model by aligning its shallow features with the latent representations from the pretrained VAE for a short phase (e.g., 40 epochs), then apply classifier-free guidance to the intermediate features, enhancing their discriminative capability and semantic expressiveness. These enriched internal features, learned entirely within the model, are used as supervision signals to guide a new DiT training. Compared to existing self-contained methods, our approach brings a significant performance boost. It can even surpass REPA in terms of generation quality and convergence speed, but without the need for any external pretrained models. Our method is not only more flexible for different backbones but also has the potential to be adopted for a wider range of diffusion-based generative tasks. The source code of our method can be found at https://github.com/csslc/Self-Transcendence.

</details>


### [130] [Vision-Language Model for Accurate Crater Detection](https://arxiv.org/abs/2601.07795)
*Patrick Bauer,Marius Schwinning,Florian Renk,Andreas Weinmann,Hichem Snoussi*

Main category: cs.CV

TL;DR: ESA为安全月球着陆开发了基于OWLv2模型的深度学习陨石坑检测算法，在挑战性条件下表现优异，召回率94%，精确度73.1%。


<details>
  <summary>Details</summary>
Motivation: 欧洲航天局（ESA）计划进行月球任务，陨石坑对安全着陆构成风险，因此需要可靠的陨石坑检测算法。

Method: 基于OWLv2模型的深度学习陨石坑检测算法（CDA），采用Vision Transformer架构，并通过参数高效的微调策略（Low-Rank Adaptation）插入可训练参数，优化了结合CIoU定位损失和对比分类损失的组合损失函数。

Result: 在IMPACT项目的测试数据集上，最大召回率达到94.0%，最大精确度为73.1%，并获得了满意的视觉结果。

Conclusion: 该方法在具有挑战性的月球成像条件下实现了可靠的陨石坑检测，为未来月球探索中的稳健陨石坑分析铺平了道路。

Abstract: The European Space Agency (ESA), driven by its ambitions on planned lunar missions with the Argonaut lander, has a profound interest in reliable crater detection, since craters pose a risk to safe lunar landings. This task is usually addressed with automated crater detection algorithms (CDA) based on deep learning techniques. It is non-trivial due to the vast amount of craters of various sizes and shapes, as well as challenging conditions such as varying illumination and rugged terrain. Therefore, we propose a deep-learning CDA based on the OWLv2 model, which is built on a Vision Transformer, that has proven highly effective in various computer vision tasks. For fine-tuning, we utilize a manually labeled dataset fom the IMPACT project, that provides crater annotations on high-resolution Lunar Reconnaissance Orbiter Camera Calibrated Data Record images. We insert trainable parameters using a parameter-efficient fine-tuning strategy with Low-Rank Adaptation, and optimize a combined loss function consisting of Complete Intersection over Union (CIoU) for localization and a contrastive loss for classification. We achieve satisfactory visual results, along with a maximum recall of 94.0% and a maximum precision of 73.1% on a test dataset from IMPACT. Our method achieves reliable crater detection across challenging lunar imaging conditions, paving the way for robust crater analysis in future lunar exploration.

</details>


### [131] [Exchange Is All You Need for Remote Sensing Change Detection](https://arxiv.org/abs/2601.07805)
*Sijun Dong,Siming Fu,Kaiyu Li,Xiangyong Cao,Xiaoliang Meng,Bo Du*

Main category: cs.CV

TL;DR: SEED 通过特征交换简化变化检测，性能优于传统方法，且可扩展至语义分割模型。


<details>
  <summary>Details</summary>
Motivation: 挑战传统变化检测中显式差异计算模块的复杂性，探索更简洁高效的特征融合方法。

Method: SEED（Siamese Encoder-Exchange-Decoder）通过参数无关的特征交换取代了显式的差异计算模块，共享了Siamese编码器和解码器的权重。

Result: 在五个基准测试和三种骨干网络上，SEED 表现与或优于现有方法，且标准语义分割模型通过插入交换机制（SEG2CD）可转变为有竞争力的变化检测器。

Conclusion: SEED 提供了一种稳健、统一且可解释的变化检测框架，证明了简单的特征交换足以实现高性能信息融合。

Abstract: Remote sensing change detection fundamentally relies on the effective fusion and discrimination of bi-temporal features. Prevailing paradigms typically utilize Siamese encoders bridged by explicit difference computation modules, such as subtraction or concatenation, to identify changes. In this work, we challenge this complexity with SEED (Siamese Encoder-Exchange-Decoder), a streamlined paradigm that replaces explicit differencing with parameter-free feature exchange. By sharing weights across both Siamese encoders and decoders, SEED effectively operates as a single parameter set model. Theoretically, we formalize feature exchange as an orthogonal permutation operator and prove that, under pixel consistency, this mechanism preserves mutual information and Bayes optimal risk, whereas common arithmetic fusion methods often introduce information loss. Extensive experiments across five benchmarks, including SYSU-CD, LEVIR-CD, PX-CLCD, WaterCD, and CDD, and three backbones, namely SwinT, EfficientNet, and ResNet, demonstrate that SEED matches or surpasses state of the art methods despite its simplicity. Furthermore, we reveal that standard semantic segmentation models can be transformed into competitive change detectors solely by inserting this exchange mechanism, referred to as SEG2CD. The proposed paradigm offers a robust, unified, and interpretable framework for change detection, demonstrating that simple feature exchange is sufficient for high performance information fusion. Code and full training and evaluation protocols will be released at https://github.com/dyzy41/open-rscd.

</details>


### [132] [More Images, More Problems? A Controlled Analysis of VLM Failure Modes](https://arxiv.org/abs/2601.07812)
*Anurag Das,Adrian Bulat,Alberto Baldrati,Ioannis Maniadis Metaxas,Bernt Schiele,Georgios Tzimiropoulos,Brais Martinez*

Main category: cs.CV

TL;DR: MIMIC基准测试揭示了LVLMs在多图像任务中的弱点，通过数据生成和优化策略提升了性能。


<details>
  <summary>Details</summary>
Motivation: 探索大型视觉语言模型在多图像理解和推理上的能力，填补现有评估的不足。

Method: 提出了MIMIC基准测试，通过诊断实验识别问题，并设计了数据生成策略和注意力掩码方案。

Result: 实验表明提出的方法显著改善了跨图像信息聚合能力，并在多图像任务上超越了现有技术。

Conclusion: 通过MIMIC基准测试，揭示了大型视觉语言模型在多图像理解上的核心弱点，并提出了数据生成和优化策略，显著提升了模型性能。

Abstract: Large Vision Language Models (LVLMs) have demonstrated remarkable capabilities, yet their proficiency in understanding and reasoning over multiple images remains largely unexplored. While existing benchmarks have initiated the evaluation of multi-image models, a comprehensive analysis of their core weaknesses and their causes is still lacking. In this work, we introduce MIMIC (Multi-Image Model Insights and Challenges), a new benchmark designed to rigorously evaluate the multi-image capabilities of LVLMs. Using MIMIC, we conduct a series of diagnostic experiments that reveal pervasive issues: LVLMs often fail to aggregate information across images and struggle to track or attend to multiple concepts simultaneously. To address these failures, we propose two novel complementary remedies. On the data side, we present a procedural data-generation strategy that composes single-image annotations into rich, targeted multi-image training examples. On the optimization side, we analyze layer-wise attention patterns and derive an attention-masking scheme tailored for multi-image inputs. Experiments substantially improved cross-image aggregation, while also enhancing performance on existing multi-image benchmarks, outperforming prior state of the art across tasks. Data and code will be made available at https://github.com/anurag-198/MIMIC.

</details>


### [133] [MHLA: Restoring Expressivity of Linear Attention via Token-Level Multi-Head](https://arxiv.org/abs/2601.07832)
*Kewei Zhang,Ye Huang,Yufan Deng,Jincheng Yu,Junsong Chen,Huan Ling,Enze Xie,Daquan Zhou*

Main category: cs.CV

TL;DR: MHLA通过多头线性注意力解决了线性注意力中的全局上下文崩溃问题，在多个任务中显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: Transformer的自注意力二次复杂度限制了其在大规模应用中的使用，而现有线性注意力方法直接应用会导致性能下降。本文发现这些方法存在全局上下文崩溃的关键问题。

Method: 提出多头线性注意力（MHLA），通过在token维度上划分头来计算注意力，以保持表示多样性。

Result: 在相同时间复杂度下，MHLA在ImageNet分类上提升了3.6%，NLP任务上提升了6.3%，图像生成上提升了12.6%，视频生成上提升了41%。

Conclusion: MHLA（多头线性注意力）在保持线性复杂度的同时，恢复了softmax注意力的表达能力，并在多个领域验证了其有效性。

Abstract: While the Transformer architecture dominates many fields, its quadratic self-attention complexity hinders its use in large-scale applications. Linear attention offers an efficient alternative, but its direct application often degrades performance, with existing fixes typically re-introducing computational overhead through extra modules (e.g., depthwise separable convolution) that defeat the original purpose. In this work, we identify a key failure mode in these methods: global context collapse, where the model loses representational diversity. To address this, we propose Multi-Head Linear Attention (MHLA), which preserves this diversity by computing attention within divided heads along the token dimension. We prove that MHLA maintains linear complexity while recovering much of the expressive power of softmax attention, and verify its effectiveness across multiple domains, achieving a 3.6\% improvement on ImageNet classification, a 6.3\% gain on NLP, a 12.6\% improvement on image generation, and a 41\% enhancement on video generation under the same time complexity.

</details>


### [134] [Tuning-free Visual Effect Transfer across Videos](https://arxiv.org/abs/2601.07833)
*Maxwell Jones,Rameen Abdal,Or Patashnik,Ruslan Salakhutdinov,Sergey Tulyakov,Jun-Yan Zhu,Kuan-Chieh Jackson Wang*

Main category: cs.CV

TL;DR: RefVFX是一种新框架，通过参考视频将复杂时间效果转移到目标视频或图像上，解决了现有方法在动态效果处理上的不足，并通过新数据集和自动化流程实现了高质量的编辑效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在基于提示或关键帧条件的编辑上表现良好，但在处理动态时间效果（如动态光照变化或角色变换）时存在困难，因为这些效果难以通过文本或静态条件描述。

Method: 引入了一个大规模的三元组数据集，并通过可扩展的自动化流程生成高质量配对视频。此外，利用LoRA适配器和基于代码的时间效果增强数据。基于新数据集，使用最新的文本到视频骨干网络训练参考条件模型。

Result: 实验结果表明，RefVFX能够有效地将复杂的时间效果从参考视频转移到目标视频或图像上。

Conclusion: RefVFX框架能够生成视觉一致且时间连贯的编辑效果，在未见过的效果类别上具有泛化能力，并在定量指标和人类偏好上优于仅基于提示的基线方法。

Abstract: We present RefVFX, a new framework that transfers complex temporal effects from a reference video onto a target video or image in a feed-forward manner. While existing methods excel at prompt-based or keyframe-conditioned editing, they struggle with dynamic temporal effects such as dynamic lighting changes or character transformations, which are difficult to describe via text or static conditions. Transferring a video effect is challenging, as the model must integrate the new temporal dynamics with the input video's existing motion and appearance. % To address this, we introduce a large-scale dataset of triplets, where each triplet consists of a reference effect video, an input image or video, and a corresponding output video depicting the transferred effect. Creating this data is non-trivial, especially the video-to-video effect triplets, which do not exist naturally. To generate these, we propose a scalable automated pipeline that creates high-quality paired videos designed to preserve the input's motion and structure while transforming it based on some fixed, repeatable effect. We then augment this data with image-to-video effects derived from LoRA adapters and code-based temporal effects generated through programmatic composition. Building on our new dataset, we train our reference-conditioned model using recent text-to-video backbones. Experimental results demonstrate that RefVFX produces visually consistent and temporally coherent edits, generalizes across unseen effect categories, and outperforms prompt-only baselines in both quantitative metrics and human preference. See our website $\href{https://tuningfreevisualeffects-maker.github.io/Tuning-free-Visual-Effect-Transfer-across-Videos-Project-Page/}{at\ this\ URL}$.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [135] [Employ SmartNICs' Data Path Accelerators for Ordered Key-Value Stores](https://arxiv.org/abs/2601.06231)
*Frederic Schimmelpfennig,Jan Sass,Reza Salkhordeh,Martin Kröning,Stefan Lankes,André Brinkmann*

Main category: cs.DC

TL;DR: 论文提出了一种基于BlueField-3 SmartNIC DPA的KV存储架构，支持无状态客户端和范围操作，性能优异。


<details>
  <summary>Details</summary>
Motivation: 现有架构难以同时实现峰值效率、架构简洁性和有序操作支持，需要一种新的解决方案来平衡这些需求。

Method: 利用BlueField-3 SmartNIC的DPA直接从NIC缓冲区处理网络请求，采用无锁学习索引，并通过批量写入和主机端树副本的延迟检索优化PCIe crossings。

Result: 系统实现了每秒3300万次点查询和1300万次范围查询的高性能，性能与现有最先进解决方案相当或更优。

Conclusion: 该论文提出的KV存储架构通过利用BlueField-3 SmartNIC的DPA，在消除操作系统开销的同时支持无状态客户端和范围操作，性能表现优异，并指出了硬件改进的潜力。

Abstract: Remote in-memory key-value (KV) stores serve as a cornerstone for diverse modern workloads, and high-speed range scans are frequently a requirement. However, current architectures rarely achieve a simultaneous balance of peak efficiency, architectural simplicity, and native support for ordered operations. Conventional host-centric frameworks are restricted by kernel-space network stacks and internal bus latencies. While hash-based alternatives that utilize OS-bypass or run natively on SmartNICs offer high throughput, they lack the data structures necessary for range queries. Distributed RDMA-based systems provide performance and range functionality but often depend on stateful clients, which introduces complexity in scaling and error handling. Alternatively, SmartNIC implementations that traverse trees located in host memory are hampered by high DMA round-trip latencies.
  This paper introduces a KV store that leverages the on-path Data Path Accelerators (DPAs) of the BlueField-3 SmartNIC to eliminate operating system overhead while facilitating stateless clients and range operations. These DPAs ingest network requests directly from NIC buffers to navigate a lock-free learned index residing in the accelerator's local memory. By deferring value retrieval from the host-side tree replica until the leaf level is reached, the design minimizes PCIe crossings. Write operations are staged in DPA memory and migrated in batches to the host, where structural maintenance is performed before being transactionally stitched back to the SmartNIC. Coupled with a NIC-resident read cache, the system achieves 33 million operations per second (MOPS) for point lookups and 13 MOPS for range queries. Our analysis demonstrates that this architecture matches or exceeds the performance of contemporary state-of-the-art solutions, while we identify hardware refinements that could further accelerate performance.

</details>


### [136] [HiDVFS: A Hierarchical Multi-Agent DVFS Scheduler for OpenMP DAG Workloads](https://arxiv.org/abs/2601.06425)
*Mohammad Pivezhandi,Abusayeed Saifullah,Ali Jannesari*

Main category: cs.DC

TL;DR: HiDVFS 是一种新型 DVFS 调度器，通过分层多代理方法优化任务分配和频率调整，显著提升性能并降低能耗和温度。


<details>
  <summary>Details</summary>
Motivation: 随着多核嵌入式系统的发展，泄漏功耗（与芯片温度呈指数关系）已超过动态功耗。现有启发式方法缺乏核心频率监控和详细分析，无法解决核心活动不均导致的过热问题。

Method: HiDVFS 采用三个代理：一个基于分析数据选择核心和频率，另一个通过温度传感器管理核心组合，第三个在资源竞争时设置任务优先级。

Result: 在 NVIDIA Jetson TX2 上使用 BOTS 套件（9 个基准测试）进行实验，HiDVFS 在多种子验证中实现了最佳性能，平均 makespan 为 4.16±0.58 秒（L10），比 GearDVFS 快 3.44 倍，能耗降低 50.4%。

Conclusion: HiDVFS 是一种针对多核嵌入式系统的分层多代理 DVFS 调度器，通过优化任务分配和频率调整，显著提升了性能（makespan），同时降低了能耗和温度。

Abstract: With advancements in multicore embedded systems, leakage power, exponentially tied to chip temperature, has surpassed dynamic power consumption. Energy-aware solutions use dynamic voltage and frequency scaling (DVFS) to mitigate overheating in performance-intensive scenarios, while software approaches allocate high-utilization tasks across core configurations in parallel systems to reduce power. However, existing heuristics lack per-core frequency monitoring, failing to address overheating from uneven core activity, and task assignments without detailed profiling overlook irregular execution patterns. We target OpenMP DAG workloads. Because makespan, energy, and thermal goals often conflict within a single benchmark, this work prioritizes performance (makespan) while reporting energy and thermal as secondary outcomes. To overcome these issues, we propose HiDVFS (a hierarchical multi-agent, performance-aware DVFS scheduler) for parallel systems that optimizes task allocation based on profiling data, core temperatures, and makespan-first objectives. It employs three agents: one selects cores and frequencies using profiler data, another manages core combinations via temperature sensors, and a third sets task priorities during resource contention. A makespan-focused reward with energy and temperature regularizers estimates future states and enhances sample efficiency. Experiments on the NVIDIA Jetson TX2 using the BOTS suite (9 benchmarks) compare HiDVFS against state-of-the-art approaches. With multi-seed validation (seeds 42, 123, 456), HiDVFS achieves the best finetuned performance with 4.16 plus/minus 0.58s average makespan (L10), representing a 3.44x speedup over GearDVFS (14.32 plus/minus 2.61s) and 50.4% energy reduction (63.7 kJ vs 128.4 kJ). Across all BOTS benchmarks, HiDVFS achieves an average 3.95x speedup and 47.1% energy reduction.

</details>


### [137] [SkyNomad: On Using Multi-Region Spot Instances to Minimize AI Batch Job Cost](https://arxiv.org/abs/2601.06520)
*Zhifei Li,Tian Xia,Ziming Mao,Zihan Zhou,Ethan J. Jackson,Jamison Kerney,Zhanghao Wu,Pratik Mishra,Yi Xu,Yifan Qiao,Scott Shenker,Ion Stoica*

Main category: cs.DC

TL;DR: SkyNomad是一个多区域调度系统，通过优化Spot实例的使用，显著降低AI批处理作业成本并保证截止时间。


<details>
  <summary>Details</summary>
Motivation: 现有的系统要么仅依赖Spot实例并面临截止时间风险，要么在简化的单区域设置中运行，忽视了Spot实例在空间和时间上的异质性。利用这种异质性可以降低作业执行成本。

Method: SkyNomad是一个多区域调度系统，通过轻量级探测估计可用性、预测实例生命周期、考虑迁移成本，并将区域特性和截止时间压力统一到货币成本模型中，以指导调度决策。

Result: SkyNomad在实际云部署中实现了1.25-3.96倍的成本节省，在模拟中与最优策略的成本差异在10%以内，且始终满足截止时间。

Conclusion: SkyNomad通过利用多区域调度和轻量级探测技术，显著降低了AI批处理作业的执行成本，同时保证了截止时间的满足。

Abstract: AI batch jobs such as model training, inference pipelines, and data analytics require substantial GPU resources and often need to finish before a deadline. Spot instances offer 3-10x lower cost than on-demand instances, but their unpredictable availability makes meeting deadlines difficult. Existing systems either rely solely on spot instances and risk deadline violations, or operate in simplified single-region settings. These approaches overlook substantial spatial and temporal heterogeneity in spot availability, lifetimes, and prices. We show that exploiting such heterogeneity to access more spot capacity is the key to reduce the job execution cost. We present SkyNomad, a multi-region scheduling system that maximizes spot usage and minimizes cost while guaranteeing deadlines. SkyNomad uses lightweight probing to estimate availability, predicts spot lifetimes, accounts for migration cost, and unifies regional characteristics and deadline pressure into a monetary cost model that guides scheduling decisions. Our evaluation shows that SkyNomad achieves 1.25-3.96x cost savings in real cloud deployments and performs within 10% cost differences of an optimal policy in simulation, while consistently meeting deadlines.

</details>


### [138] [Resource-Aware Task Allocator Design: Insights and Recommendations for Distributed Satellite Constellations](https://arxiv.org/abs/2601.06706)
*Bharadwaj Veeravalli*

Main category: cs.DC

TL;DR: 研究设计了资源感知任务分配器（RATA），通过SLTN架构评估DSS在LEO到Low-MEO星座规模下的性能，发现CPU可用性是阻塞主因，并确定了性能崩溃阈值。


<details>
  <summary>Details</summary>
Motivation: 分析在轻量到压力诱导级别的计算密集型工作负载下，结合上述因素的性能极限，是评估分布式卫星系统（DSS）处理实时任务能力的重要步骤。

Method: 使用基于单级树网络（SLTN）的协作任务分配架构，评估了阻塞概率、响应时间、能源消耗和资源利用率等关键性能指标。资源感知的RATA监控关键参数，如到达率、资源可用性（机载计算、存储、带宽、电池）以及卫星日食对处理和通信的影响。

Result: 结果显示明显的非线性扩展：容量随星座规模增加而增加，但阻塞和延迟迅速增长，而能源在太阳能感知调度下保持弹性。

Conclusion: 该研究确定了基线SLTNs的实用卫星数量限制，并表明CPU可用性（而非能源）是阻塞的主要原因。这些发现通过识别系统性能从优雅降级到崩溃的阈值，提供了定量指导。

Abstract: We present the design of a Resource-Aware Task Allocator (RATA) and an empirical analysis in handling real-time tasks for processing on Distributed Satellite Systems (DSS). We consider task processing performance across low Earth orbit (LEO) to Low-Medium Earth Orbit (Low-MEO) constellation sizes, under varying traffic loads. Using Single-Level Tree Network(SLTN)-based cooperative task allocation architecture, we attempt to evaluate some key performance metrics - blocking probabilities, response times, energy consumption, and resource utilization across several tens of thousands of tasks per experiment. Our resource-conscious RATA monitors key parameters such as arrival rate, resources (on-board compute, storage, bandwidth, battery) availability, satellite eclipses' influence in processing and communications. This study is an important step towards analyzing the performance under lighter to stress inducing levels of compute intense workloads to test the ultimate performance limits under the combined influence of the above-mentioned factors. Results show pronounced non-linear scaling: while capacity increases with constellation size, blocking and delay grow rapidly, whereas energy remains resilient under solar-aware scheduling. The analysis identifies a practical satellite-count limit for baseline SLTNs and demonstrates that CPU availability, rather than energy, is the primary cause of blocking. These findings provide quantitative guidance by identifying thresholds at which system performance shifts from graceful degradation to collapse.

</details>


### [139] [Learning-Augmented Performance Model for Tensor Product Factorization in High-Order FEM](https://arxiv.org/abs/2601.06886)
*Xuanzhengbo Ren,Yuta Kawai,Tetsuya Hoshino,Hirofumi Tomita,Takahiro Katagiri,Daichi Mukunoki,Seiya Nishizawa*

Main category: cs.DC

TL;DR: 论文提出了一种结合依赖链分析和XGBoost的性能预测模型，显著提升了算术密集型核的预测准确性。


<details>
  <summary>Details</summary>
Motivation: 传统性能模型主要关注缓存和内存带宽，不适用于算术密集型核（如张量$n$-模积核），需开发直接反映指令级效率的模型。

Method: 提出了一种基于依赖链的分析模型，并结合XGBoost学习难以显式建模的关键参数。

Result: 在Fujitsu A64FX和Intel Xeon Gold 6230处理器上，新模型的平均绝对百分比误差显著低于标准Roofline和ECM模型。

Conclusion: 该论文开发了一种基于依赖链的分析模型，结合XGBoost学习关键参数，显著提升了算术密集型核的性能预测准确性，优于传统模型。

Abstract: Accurate performance prediction is essential for optimizing scientific applications on modern high-performance computing (HPC) architectures. Widely used performance models primarily focus on cache and memory bandwidth, which is suitable for many memory-bound workloads. However, it is unsuitable for highly arithmetic intensive cases such as the sum-factorization with tensor $n$-mode product kernels, which are an optimization technique for high-order finite element methods (FEM). On processors with relatively high single instruction multiple data (SIMD) instruction latency, such as the Fujitsu A64FX, the performance of these kernels is strongly influenced by loop-body splitting strategies. Memory-bandwidth-oriented models are therefore not appropriate for evaluating these splitting configurations, and a model that directly reflects instruction-level efficiency is required. To address this need, we develop a dependency-chain-based analytical formulation that links loop-splitting configurations to instruction dependencies in the tensor $n$-mode product kernel. We further use XGBoost to estimate key parameters in the analytical model that are difficult to model explicitly. Evaluations show that the learning-augmented model outperforms the widely used standard Roofline and Execution-Cache-Memory (ECM) models. On the Fujitsu A64FX processor, the learning-augmented model achieves mean absolute percentage errors (MAPE) between 1% and 24% for polynomial orders ($P$) from 1 to 15. In comparison, the standard Roofline and ECM models yield errors of 42%-256% and 5%-117%, respectively. On the Intel Xeon Gold 6230 processor, the learning-augmented model achieves MAPE values from 1% to 13% for $P$=1 to $P$=14, and 24% at $P$=15. In contrast, the standard Roofline and ECM models produce errors of 1%-73% and 8%-112% for $P$=1 to $P$=15, respectively.

</details>


### [140] [Divergence-Based Adaptive Aggregation for Byzantine Robust Federated Learning](https://arxiv.org/abs/2601.06903)
*Bingnan Xiao,Feng Zhu,Jingjing Zhang,Wei Ni,Xin Wang*

Main category: cs.DC

TL;DR: DRAG和BR-DRAG是两种新框架，分别通过校准本地更新和维护可信参考方向，解决联邦学习中的数据异构性和拜占庭攻击问题，实验证明其有效性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 数据异构性和拜占庭攻击阻碍联邦学习的模型训练和收敛，需要新的解决方案。

Method: DRAG通过设计参考方向和偏离度量来校准本地更新，BR-DRAG在服务器端维护可信根数据集以生成可信参考方向。

Result: 实验验证了DRAG在处理客户端漂移上的优越性，以及BR-DRAG在对抗数据异构性和拜占庭攻击中的鲁棒性。

Conclusion: DRAG和BR-DRAG框架有效解决了联邦学习中的数据异构性和拜占庭攻击问题，实现了快速收敛和鲁棒性。

Abstract: Inherent client drifts caused by data heterogeneity, as well as vulnerability to Byzantine attacks within the system, hinder effective model training and convergence in federated learning (FL). This paper presents two new frameworks, named DiveRgence-based Adaptive aGgregation (DRAG) and Byzantine-Resilient DRAG (BR-DRAG), to mitigate client drifts and resist attacks while expediting training. DRAG designs a reference direction and a metric named divergence of degree to quantify the deviation of local updates. Accordingly, each worker can align its local update via linear calibration without extra communication cost. BR-DRAG refines DRAG under Byzantine attacks by maintaining a vetted root dataset at the server to produce trusted reference directions. The workers' updates can be then calibrated to mitigate divergence caused by malicious attacks. We analytically prove that DRAG and BR-DRAG achieve fast convergence for non-convex models under partial worker participation, data heterogeneity, and Byzantine attacks. Experiments validate the effectiveness of DRAG and its superior performance over state-of-the-art methods in handling client drifts, and highlight the robustness of BR-DRAG in maintaining resilience against data heterogeneity and diverse Byzantine attacks.

</details>


### [141] [SC-MII: Infrastructure LiDAR-based 3D Object Detection on Edge Devices for Split Computing with Multiple Intermediate Outputs Integration](https://arxiv.org/abs/2601.07119)
*Taisuke Noguchi,Takayuki Nishio,Takuya Azumi*

Main category: cs.DC

TL;DR: SC-MII是一种基于多基础设施LiDAR的3D物体检测方法，通过分步计算和中间输出整合，显著提升边缘设备效率，同时保持高准确率。


<details>
  <summary>Details</summary>
Motivation: 解决边缘设备部署先进模型时的高计算需求和能源消耗问题，以及单LiDAR设置的盲点问题。

Method: 提出SC-MII方法，通过边缘设备处理初始DNN层并将中间输出发送到边缘服务器进行特征整合和推理。

Result: 实验结果显示，SC-MII在真实数据集上实现了2.19倍的加速和71.6%的边缘设备处理时间减少，准确率最多下降1.09%。

Conclusion: SC-MII方法在边缘设备上实现了高效的3D物体检测，显著降低了延迟和设备负载，同时保持了较高的准确率。

Abstract: 3D object detection using LiDAR-based point cloud data and deep neural networks is essential in autonomous driving technology. However, deploying state-of-the-art models on edge devices present challenges due to high computational demands and energy consumption. Additionally, single LiDAR setups suffer from blind spots. This paper proposes SC-MII, multiple infrastructure LiDAR-based 3D object detection on edge devices for Split Computing with Multiple Intermediate outputs Integration. In SC-MII, edge devices process local point clouds through the initial DNN layers and send intermediate outputs to an edge server. The server integrates these features and completes inference, reducing both latency and device load while improving privacy. Experimental results on a real-world dataset show a 2.19x speed-up and a 71.6% reduction in edge device processing time, with at most a 1.09% drop in accuracy.

</details>


### [142] [Bringing Computation to the data: Interoperable serverless function execution for astrophysical data analysis in the SRCNet](https://arxiv.org/abs/2601.07308)
*Manuel Parra-Royón,Julián Garrido-Sánchez,Susana Sánchez-Expósito,María Ángeles Mendoza,Rob Barnsley,Anthony Moraghan,Jesús Sánchez,Laura Darriba,Carlos Ruíz-Monje,Edgar Joao,Javier Moldón,Jesús Salgado,Lourdes Verdes-Montenegro*

Main category: cs.DC

TL;DR: Serverless computing (FaaS) is applied to SKAO's massive data challenge, showing it can efficiently process data locally within the SRCNet, reducing latency and transfers.


<details>
  <summary>Details</summary>
Motivation: To address the challenge of processing large-scale data (e.g., 700 PB annually from SKAO) distributed across international centres (SRCNet) by leveraging the flexibility and scalability of serverless computing.

Method: Developed and deployed representative functions for astrophysical data analysis, including micro-functions derived from existing libraries and wrappers around domain-specific applications, such as a Gaussian convolution function integrated within the SRCNet ecosystem.

Result: Demonstrated that FaaS can be embedded into the existing SRCNet ecosystem, enabling functions to run directly at data storage sites, reducing latency, minimizing transfers, and improving efficiency.

Conclusion: Serverless models, particularly FaaS, offer a scalable and efficient solution for handling the massive data volumes expected in the SKA era, aligning well with federated, data-proximate computation.

Abstract: Serverless computing is a paradigm in which the underlying infrastructure is fully managed by the provider, enabling applications and services to be executed with elastic resource provisioning and minimal operational overhead. A core model within this paradigm is Function-as-a-Service (FaaS), where lightweight functions are deployed and triggered on demand, scaling seamlessly with workload. FaaS offers flexibility, cost-effectiveness, and fine-grained scalability, qualities particularly relevant for large-scale scientific infrastructures where data volumes are too large to centralise and computation must increasingly occur close to the data. The Square Kilometre Array Observatory (SKAO) exemplifies this challenge. Once operational, it will generate about 700~PB of data products annually, distributed across the SKA Regional Centre Network (SRCNet), a federation of international centres providing storage, computing, and analysis services. In such a context, FaaS offers a mechanism to bring computation to the data. We studied the principles of serverless and FaaS computing and explored their application to radio astronomy workflows. Representative functions for astrophysical data analysis were developed and deployed, including micro-functions derived from existing libraries and wrappers around domain-specific applications. In particular, a Gaussian convolution function was implemented and integrated within the SRCNet ecosystem. The use case demonstrates that FaaS can be embedded into the existing SRCNet ecosystem of services, allowing functions to run directly at sites where data replicas are stored. This reduces latency, minimises transfers, and improves efficiency, aligning with federated, data-proximate computation. The results show that serverless models provide a scalable and efficient pathway to address the data volumes of the SKA era.

</details>


### [143] [MegaFlow: Large-Scale Distributed Orchestration System for the Agentic Era](https://arxiv.org/abs/2601.07526)
*Lei Zhang,Mouxiang Chen,Ruisheng Cao,Jiawei Chen,Fan Zhou,Yiheng Xu,Jiaxi Yang,Liang Chen,Changwei Luo,Kai Zhang,Fan Yan,KaShun Shum,Jiajun Zhang,Zeyu Cui,Hu Feng,Junyang Lin,Binyuan Hui,Min Yang*

Main category: cs.DC

TL;DR: MegaFlow是一个分布式编排系统，解决了复杂代理任务大规模训练和评估的基础设施问题。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏能够有效支持复杂代理任务（如软件工程和计算机使用）大规模训练和评估的开源基础设施。

Method: MegaFlow是一个大规模分布式编排系统，将代理训练基础设施抽象为三个独立服务（模型服务、代理服务和环境服务），通过统一接口交互，实现独立扩展和灵活资源分配。

Result: 在代理训练部署中，MegaFlow成功协调了数万个并发代理任务，保持了高系统稳定性和高效资源利用率。

Conclusion: MegaFlow成功填补了当前开源基础设施在支持大规模代理训练和评估方面的关键空白，为代理式AI的发展提供了重要支持。

Abstract: The rapid development of interactive and autonomous AI systems signals our entry into the agentic era. Training and evaluating agents on complex agentic tasks such as software engineering and computer use requires not only efficient model computation but also sophisticated infrastructure capable of coordinating vast agent-environment interactions. However, no open-source infrastructure can effectively support large-scale training and evaluation on such complex agentic tasks. To address this challenge, we present MegaFlow, a large-scale distributed orchestration system that enables efficient scheduling, resource allocation, and fine-grained task management for agent-environment workloads. MegaFlow abstracts agent training infrastructure into three independent services (Model Service, Agent Service, and Environment Service) that interact through unified interfaces, enabling independent scaling and flexible resource allocation across diverse agent-environment configurations. In our agent training deployments, MegaFlow successfully orchestrates tens of thousands of concurrent agent tasks while maintaining high system stability and achieving efficient resource utilization. By enabling such large-scale agent training, MegaFlow addresses a critical infrastructure gap in the emerging agentic AI landscape.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [144] [The Potential of Erroneous Outbound Traffic Analysis to Unveil Silent Internal Anomalies](https://arxiv.org/abs/2601.06280)
*Andrea Sordello,Zhihao Wang,Kai Huang,Alessandro Cornacchia,Marco Mellia*

Main category: cs.NI

TL;DR: 论文提出通过分析出站流量中的错误流量（如无响应包或ICMP错误）来识别网络安全问题，实际数据验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统被动测量主要关注入站流量以检测恶意活动，但忽略了出站流量中的错误流量可能揭示的广泛安全威胁和网络问题。

Method: 论文收集并分析了大网络中的错误出站流量，这些流量包括无响应包、触发ICMP错误的包或ICMP错误消息本身。

Result: 分析揭示了多种之前未注意到的问题，包括配置错误、过时部署和受感染主机。

Conclusion: 通过分析出站流量中的错误流量，论文展示了其在识别网络安全威胁和网络问题方面的潜力，为被动测量提供了新的视角。

Abstract: Passive measurement has traditionally focused on inbound traffic to detect malicious activity, based on the assumption that threats originate externally. In this paper, we offer a complementary perspective by examining outbound traffic, and argue that a narrow subset -- what we term erroneous outbound traffic -- is a lighter and revealing yet overlooked data source for identifying a broad range of security threats and network problems. This traffic consists of packets sent by internal hosts that either receive no response, trigger ICMP errors, or are ICMP error messages themselves generated in response to unsolicited requests. To demonstrate its potential, we collect and analyse erroneous traffic from a large network, uncovering a variety of previously unnoticed issues, including misconfigurations, obsolete deployments and compromised hosts.

</details>


### [145] [ReAct: Reflection Attack Mitigation For Asymmetric Routing](https://arxiv.org/abs/2601.06367)
*David Hay,Mary Hogan,Shir Landau Feibish*

Main category: cs.NI

TL;DR: ReAct是一种新型的AR-DDoS防御方案，通过跨交换机协作和动态适应路由变化，有效解决了不对称网络中的攻击问题。


<details>
  <summary>Details</summary>
Motivation: 现有的AR-DDoS防御方案通常假设对称路由且仅限于单一交换机，无法适应现代网络中的不对称性，导致合法响应丢失和持续连接问题。

Method: ReAct利用可编程数据平面和滑动窗口的Bloom过滤器，跨交换机进行请求-响应关联，并引入基于数据平面的请求转发机制以处理不对称流量。

Result: 实验表明，ReAct在高流量攻击和不对称条件下几乎能过滤所有攻击流量，且误报率显著低于现有方案。

Conclusion: ReAct是一种针对AR-DDoS攻击的内网防御方案，能够有效应对网络不对称性，并在动态网络环境中保持高防护效果。

Abstract: Amplification Reflection Distributed Denial-of-Service (AR-DDoS) attacks remain a formidable threat, exploiting stateless protocols to flood victims with illegitimate traffic. Recent advances have enabled data-plane defenses against such attacks, but existing solutions typically assume symmetric routing and are limited to a single switch. These assumptions fail in modern networks where asymmetry is common, resulting in dropped legitimate responses and persistent connectivity issues. This paper presents ReAct, an in-network defense for AR-DDoS that is robust to asymmetry. ReAct performs request-response correlation across switches using programmable data planes and a sliding-window of Bloom filters. To handle asymmetric traffic, ReAct introduces a data-plane-based request forwarding mechanism, enabling switches to validate responses even when paths differ. ReAct can automatically adapt to routing changes with minimal intervention, ensuring continued protection even in dynamic network environments. We implemented ReAct on both a P4 interpreter and NVIDIAs Bluefield-3, demonstrating its applicability across multiple platforms. Evaluation results show that ReAct filters nearly all attack traffic without dropping legitimate responses-even under high-volume attacks and asymmetry. Compared to state-of-the-art approaches, ReAct achieves significantly lower false positives. To our knowledge, ReAct is the first data-plane AR-DDoS defense that supports dynamic, cross-switch collaboration, making it uniquely suitable for deployment in networks with asymmetry.

</details>


### [146] [Low-Altitude Satellite-AAV Collaborative Joint Mobile Edge Computing and Data Collection via Diffusion-based Deep Reinforcement Learning](https://arxiv.org/abs/2601.07307)
*Boxiong Wang,Hui Kang,Jiahui Li,Geng Sun,Zemin Sun,Jiacheng Wang,Dusit Niyato,Shiwen Mao*

Main category: cs.NI

TL;DR: QAGOB方法在卫星-AAV联合MEC-DC系统中优化性能显著，优于传统算法，且联合优化比单独优化更有效。


<details>
  <summary>Details</summary>
Motivation: 卫星和AAV通信的集成在需要广覆盖和快速部署的场景中变得至关重要，特别是在地面基础设施不可用的偏远或灾区。同时，新兴应用需要在同一空中网络中同时具备移动边缘计算（MEC）和数据收集（DC）能力。

Method: 提出了一种基于Q加权变分策略优化的联合AAV移动控制、GD关联、卸载决策和带宽分配（QAGOB）方法，将优化问题重构为动作空间转换的马尔可夫决策过程，并利用扩散模型的多模态生成能力优化策略。

Result: 仿真结果表明，QAGOB优于其他五种基准算法，包括传统深度强化学习和基于扩散的深度强化学习算法。此外，MEC-DC联合优化相比单独优化MEC和DC具有显著优势。

Conclusion: QAGOB方法在卫星-AAV联合MEC-DC系统中表现出色，显著优于其他基准算法，同时联合优化MEC和DC比单独优化更具优势。

Abstract: The integration of satellite and autonomous aerial vehicle (AAV) communications has become essential for the scenarios requiring both wide coverage and rapid deployment, particularly in remote or disaster-stricken areas where the terrestrial infrastructure is unavailable. Furthermore, emerging applications increasingly demand simultaneous mobile edge computing (MEC) and data collection (DC) capabilities within the same aerial network. However, jointly optimizing these operations in heterogeneous satellite-AAV systems presents significant challenges due to limited on-board resources and competing demands under dynamic channel conditions. In this work, we investigate a satellite-AAV-enabled joint MEC-DC system where these platforms collaborate to serve ground devices (GDs). Specifically, we formulate a joint optimization problem to minimize the average MEC end-to-end delay and AAV energy consumption while maximizing the collected data. Since the formulated optimization problem is a non-convex mixed-integer nonlinear programming (MINLP) problem, we propose a Q-weighted variational policy optimization-based joint AAV movement control, GD association, offloading decision, and bandwidth allocation (QAGOB) approach. Specifically, we reformulate the optimization problem as an action space-transformed Markov decision process to adapt the variable action dimensions and hybrid action space. Subsequently, QAGOB leverages the multi-modal generation capacities of diffusion models to optimize policies and can achieve better sample efficiency while controlling the diffusion costs during training. Simulation results show that QAGOB outperforms five other benchmarks, including traditional DRL and diffusion-based DRL algorithms. Furthermore, the MEC-DC joint optimization achieves significant advantages when compared to the separate optimization of MEC and DC.

</details>


### [147] [A Scalable Solution for Node Mobility Problems in NDN-Based Massive LEO Constellations](https://arxiv.org/abs/2601.07466)
*Miguel Rodríguez-Pérez,Sergio Herrería-Alonso,J. Carlos Lopez-Ardao,Andrés Suárez-González*

Main category: cs.NI

TL;DR: 论文提出了一种基于NDN架构的解决方案，用于解决大规模LEO星座中的移动性问题，无需修改协议且效果显著。


<details>
  <summary>Details</summary>
Motivation: 随着大规模商业LEO星座的部署，这些星座需充当低延迟互联网骨干网，但LEO网络的高速度和频繁切换对移动性管理提出了挑战。信息中心网络（ICN）技术因其寻址、存储和安全机制适合物联网需求，但其在发送者移动性方面仍存在问题。

Method: 论文采用命名数据网络（NDN）架构，提出了一种可扩展的方法将内容与地面网关关联，并设计了一种无需网络路由算法协作的流量寻址方式。

Result: 研究结果表明，在足够长的切换长度下，即使地面站仅有一颗卫星在视线范围内，流量损失也可忽略不计。

Conclusion: 该论文提出了一种基于命名数据网络（NDN）架构的全面解决方案，用于解决大规模低地球轨道（LEO）星座中的移动性问题。该方案无需修改NDN协议本身，易于测试和部署，且在足够长的切换长度下，即使地面站仅有一颗卫星在视线范围内，流量损失也可忽略不计。

Abstract: In recent years, there has been increasing investment in the deployment of massive commercial Low Earth Orbit (LEO) constellations to provide global Internet connectivity. These constellations, now equipped with inter-satellite links, can serve as low-latency Internet backbones, requiring LEO satellites to act not only as access nodes for ground stations, but also as in-orbit core routers. Due to their high velocity and the resulting frequent handovers of ground gateways, LEO networks highly stress mobility procedures at both the sender and receiver endpoints. On the other hand, a growing trend in networking is the use of technologies based on the Information Centric Networking (ICN) paradigm for servicing IoT networks and sensor networks in general, as its addressing, storage, and security mechanisms are usually a good match for IoT needs. Furthermore, ICN networks possess additional characteristics that are beneficial for the massive LEO scenario. For instance, the mobility of the receiver is helped by the inherent data-forwarding procedures in their architectures. However, the mobility of the senders remains an open problem. This paper proposes a comprehensive solution to the mobility problem for massive LEO constellations using the Named-Data Networking (NDN) architecture, as it is probably the most mature ICN proposal. Our solution includes a scalable method to relate content to ground gateways and a way to address traffic to the gateway that does not require cooperation from the network routing algorithm. Moreover, our solution works without requiring modifications to the actual NDN protocol itself, so it is easy to test and deploy. Our results indicate that, for long enough handover lengths, traffic losses are negligible even for ground stations with just one satellite in sight.

</details>


<div id='cs.OS'></div>

# cs.OS [[Back]](#toc)

### [148] [Rethinking Inter-Process Communication with Memory Operation Offloading](https://arxiv.org/abs/2601.06331)
*Misun Park,Richi Dubey,Yifan Yuan,Nam Sung Kim,Ada Gavrilovska*

Main category: cs.OS

TL;DR: 提出统一IPC运行时套件，整合硬件和软件内存卸载，显著提升数据密集型系统效率。


<details>
  <summary>Details</summary>
Motivation: 现有IPC运行时在内存拷贝上消耗大量CPU周期，缺乏统一的运行时模型来协调硬件和软件内存卸载。

Method: 通过异步流水线、选择性缓存注入和混合协调，将卸载从设备特定功能转变为通用系统能力。

Result: 在真实工作负载上，指令计数减少达22%，吞吐量提升达2.1倍，延迟降低达72%。

Conclusion: 协调的IPC卸载在现代数据密集型系统中可以实现显著的端到端效率提升，包括指令计数减少、吞吐量提升和延迟降低。

Abstract: As multimodal and AI-driven services exchange hundreds of megabytes per request, existing IPC runtimes spend a growing share of CPU cycles on memory copies. Although both hardware and software mechanisms are exploring memory offloading, current IPC stacks lack a unified runtime model to coordinate them effectively.
  This paper presents a unified IPC runtime suite that integrates both hardware- and software-based memory offloading into shared-memory communication. The system characterizes the interaction between offload strategies and IPC execution, including synchronization, cache visibility, and concurrency, and introduces multiple IPC modes that balance throughput, latency, and CPU efficiency.
  Through asynchronous pipelining, selective cache injection, and hybrid coordination, the system turns offloading from a device-specific feature into a general system capability. Evaluations on real-world workloads show instruction count reductions of up to 22%, throughput improvements of up to 2.1x, and latency reductions of up to 72%, demonstrating that coordinated IPC offloading can deliver tangible end-to-end efficiency gains in modern data-intensive systems.

</details>


### [149] [Peformance Isolation for Inference Processes in Edge GPU Systems](https://arxiv.org/abs/2601.07600)
*Juan José Martín,José Flich,Carles Hernández*

Main category: cs.OS

TL;DR: 研究比较了NVIDIA GPU的三种隔离机制（MPS、MIG、Green Contexts），发现MIG隔离性最佳，Green Contexts适合边缘设备但缺乏内存隔离，并提出了改进方向。


<details>
  <summary>Details</summary>
Motivation: 为确保在安全关键应用中使用深度学习模型时的可预测推理时间，分析现代NVIDIA GPU的隔离机制。

Method: 实验方法包括性能测试、分区影响评估和进程间时间隔离分析，涉及NVIDIA A100和Jetson Orin平台。

Result: MIG提供高隔离性，Green Contexts在边缘设备上表现良好但无内存隔离。

Conclusion: 该研究分析了现代NVIDIA GPU的主要隔离机制（MPS、MIG和Green Contexts），发现MIG提供高隔离性，而Green Contexts是边缘设备的有前景选择，但缺乏内存隔离。同时指出了当前限制并提出了改进共享GPU时间可预测性的研究方向。

Abstract: This work analyzes the main isolation mechanisms available in modern NVIDIA GPUs: MPS, MIG, and the recent Green Contexts, to ensure predictable inference time in safety-critical applications using deep learning models. The experimental methodology includes performance tests, evaluation of partitioning impact, and analysis of temporal isolation between processes, considering both the NVIDIA A100 and Jetson Orin platforms. It is observed that MIG provides a high level of isolation. At the same time, Green Contexts represent a promising alternative for edge devices by enabling fine-grained SM allocation with low overhead, albeit without memory isolation. The study also identifies current limitations and outlines potential research directions to improve temporal predictability in shared GPUs.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [150] [Lower Bounds for the Algorithmic Complexity of Learned Indexes](https://arxiv.org/abs/2601.06629)
*Luis Alberto Croquevielle,Roman Sokolovskii,Thomas Heinis*

Main category: cs.DS

TL;DR: 该论文提出了一个理论框架，用于分析学习索引结构的查询时间下界，揭示了其在空间和时间权衡方面的核心局限性。


<details>
  <summary>Details</summary>
Motivation: 尽管学习索引结构在实践中有效，但其理论局限性尚未完全理解，因此需要建立一个理论框架来分析其性能边界。

Method: 论文提出了一个通用框架，通过概率工具和近似理论分析，解决了学习索引查询时间下界的问题，特别关注了分段线性和分段常数模型类。

Result: 研究结果表明，学习索引结构在空间和时间之间存在固有的权衡，这通过近似理论工具（如量化和Kolmogorov宽度）得到了形式化。

Conclusion: 该论文通过理论分析揭示了学习索引结构的核心局限性，特别是在空间-时间权衡方面的固有约束。

Abstract: Learned index structures aim to accelerate queries by training machine learning models to approximate the rank function associated with a database attribute. While effective in practice, their theoretical limitations are not fully understood. We present a general framework for proving lower bounds on query time for learned indexes, expressed in terms of their space overhead and parameterized by the model class used for approximation. Our formulation captures a broad family of learned indexes, including most existing designs, as piecewise model-based predictors.
  We solve the problem of lower bounding query time in two steps: first, we use probabilistic tools to control the effect of sampling when the database attribute is drawn from a probability distribution. Then, we analyze the approximation-theoretic problem of how to optimally represent a cumulative distribution function with approximators from a given model class. Within this framework, we derive lower bounds under a range of modeling and distributional assumptions, paying particular attention to the case of piecewise linear and piecewise constant model classes, which are common in practical implementations.
  Our analysis shows how tools from approximation theory, such as quantization and Kolmogorov widths, can be leveraged to formalize the space-time tradeoffs inherent to learned index structures. The resulting bounds illuminate core limitations of these methods.

</details>


### [151] [Approximating Matroid Basis Testing for Partition Matroids using Budget-In-Expectation](https://arxiv.org/abs/2601.06723)
*Lisa Hellerstein,Benedikt M. Plank,Kevin Schewior*

Main category: cs.DS

TL;DR: 本文针对分区拟阵的随机布尔函数评估问题，提出了一种多项式时间的常数因子近似算法，结合新技术与现有方法，展示了其独立研究价值。


<details>
  <summary>Details</summary>
Motivation: 研究随机布尔函数评估问题，特别是针对分区拟阵的情况，发现现有方法无法提供常数因子近似解，因此需要开发新方法。

Method: 算法自适应地交错解决多个新型随机查询问题的实例，并结合预期成本约束。

Result: 提出了一个多项式时间的常数因子近似算法，适用于分区拟阵的随机布尔函数评估问题。

Conclusion: 本文提出了一种多项式时间的常数因子近似算法，用于解决分区拟阵的随机布尔函数评估问题，通过结合新技术与现有方法，展示了该问题的独立研究价值和潜在应用。

Abstract: We consider the following Stochastic Boolean Function Evaluation problem, which is closely related to several problems from the literature. A matroid $\mathcal{M}$ (in compact representation) on ground set $E$ is given, and each element $i\in E$ is active independently with known probability $p_i\in(0,1)$. The elements can be queried, upon which it is revealed whether the respective element is active or not. The goal is to find an adaptive querying strategy for determining whether there is a basis of $\mathcal{M}$ in which all elements are active, with the objective of minimizing the expected number of queries.
  When $\mathcal{M}$ is a uniform matroid, this is the problem of evaluating a $k$-of-$n$ function, first studied in the 1970s. This problem is well-understood, and has an optimal adaptive strategy that can be computed in polynomial time.
  Taking $\mathcal{M}$ to instead be a partition matroid, we show that previous approaches fail to give a constant-factor approximation. Our main result is a polynomial-time constant-factor approximation algorithm producing a randomized strategy for this partition matroid problem. We obtain this result by combining a new technique with several well-established techniques. Our algorithm adaptively interleaves solutions to several instances of a novel type of stochastic querying problem, with a constraint on the $\textit{expected}$ cost. We believe that this type of problem is of independent interest, will spark follow-up work, and has the potential for additional applications.

</details>


### [152] [Algorithmic Reductions: Network Flow and NP-Completeness in Real-World Scheduling Problems](https://arxiv.org/abs/2601.06737)
*Anay Sinhal,Arpana Sinhal,Amit Sinhal,Amit Hirawat*

Main category: cs.DS

TL;DR: 本文通过归约和算法设计解决了两个实际调度问题，验证了理论复杂度，并展示了高效的实际应用表现。


<details>
  <summary>Details</summary>
Motivation: 解决实际中的医院患者床位分配和大学课程调度问题，提供高效的算法解决方案。

Method: 首先将医院患者床位分配问题归约为最大二分图匹配问题，并通过网络流算法解决；其次将大学课程调度问题归约为图着色问题，证明其NP完全性，并提供贪心近似算法。

Result: 网络流解决方案实现了O(n2.51)的实证复杂度，贪心着色算法展示了O(n2)的行为，且近似比始终低于理论delta + 1界限。

Conclusion: 本文通过多项式时间归约解决了两个实际调度问题，验证了理论复杂度分析的准确性，并展示了算法在实际应用中的高效性。

Abstract: This paper presents two real-world scheduling problems and their algorithmic solutions through polynomial-time reductions. First, we address the Hospital Patient-to-Bed Assignment problem, demonstrating its reduction to Maximum Bipartite Matching and solution via Network Flow algorithms. Second, we tackle the University Course Scheduling problem, proving its NP-Completeness through reduction from Graph Coloring and providing greedy approximation algorithms. Both problems are implemented in Python, with experimental results validating theoretical complexity analyses. Our Network Flow solution achieves O(n2.51) empirical complexity, while the greedy coloring algorithms demonstrate O(n2) behavior with approximation ratios consistently below the theoretical delta + 1 bound.

</details>


### [153] [Spectral Shadows: When Communication Complexity Meets Linear Invariance Testing](https://arxiv.org/abs/2601.06828)
*Swarnalipa Datta,Arijit Ghosh,Chandrima Kayal,Manaswi Paraashar,Manmatha Roy*

Main category: cs.DS

TL;DR: 本文首次在通信复杂性框架下研究线性同构测试问题，发现近似谱范数是关键复杂度指标，并设计了高效协议。


<details>
  <summary>Details</summary>
Motivation: 填补线性同构测试问题在通信复杂性领域的空白，探索其在组合电路设计、复杂性理论和密码学中的基础连接。

Method: 设计了确定性协议和随机协议，通过近似谱范数来评估通信复杂性，并提供了匹配的下界。

Result: 确定性协议的通信成本与近似谱范数多项式相关，随机协议则实现了二次改进的依赖关系，且证明这种依赖关系是不可避免的。

Conclusion: 本研究通过通信复杂性框架探讨了线性同构测试问题，揭示了近似谱范数在该问题中的核心作用，并设计了高效协议。

Abstract: In this short note, we initiate the study of the Linear Isomorphism Testing Problem in the setting of communication complexity, a natural linear algebraic generalization of the classical Equality problem. Given Boolean functions $f, g : \mathbb{F}_2^n \to \{-1, +1\}$, Alice and Bob are tasked with determining whether $f$ and $g$ are equivalent up to a nonsingular linear transformation of the input variables, or far from being so. This problem has been extensively investigated in several models of computation, including standard algorithmic and property testing frameworks, owing to its fundamental connections with combinatorial circuit design, complexity theory, and cryptography. However, despite its broad relevance, it has remained unexplored in the context of communication complexity, a gap we address in this work.
  Our main results demonstrate that the approximate spectral norm of the input functions plays a central role in governing the communication complexity of this problem. We design a simple deterministic protocol whose communication cost is polynomial in the approximate spectral norm, and complement it with nearly matching lower bounds (up to a quadratic gap). In the randomised setting with private coins, we present an even more efficient protocol, though equally simple, that achieves a quadratically improved dependence on the approximate spectral norm compared to the deterministic case, and we prove that such a dependence is essentially unavoidable.
  These results identify the approximate spectral norm as a key complexity measure for testing linear invariance in the communication complexity framework. As a core technical ingredient, we establish new junta theorems for Boolean functions with small approximate spectral norm, which may be of independent interest in Fourier analysis and learning theory.

</details>


### [154] [Optimal Extended Formulations from Optimal Dynamic Programming Algorithms](https://arxiv.org/abs/2601.06947)
*Mateus de Oliveira Oliveira,Wim Van den Broeck*

Main category: cs.DS

TL;DR: 本文揭示了顶点子集问题的动态规划与线性规划之间的联系，证明了动态规划表大小与解多面体扩展复杂度的最优关系，为算法优化提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 探索顶点子集问题的动态规划与线性规划方法之间的关联，以优化算法效率和解多面体的扩展复杂度。

Method: 通过分析动态规划算法在树分解宽度为k的n顶点图上生成的表大小α(k,n)，推导出解多面体P_Π(G)的扩展复杂度上限为O(α(k,n)·n)，并证明其在指数时间假设（ETH）下是最优的。

Result: 证明了动态规划算法生成的表大小与解多面体扩展复杂度之间的最优关系，为ETH最优的动态规划算法提供了理论支持。

Conclusion: 本文建立了顶点子集问题（VSPs）的动态规划算法与线性规划方法之间的紧密联系，证明了动态规划算法生成的表大小与解多面体的扩展复杂度之间的最优关系。

Abstract: Vertex Subset Problems (VSPs) are a class of combinatorial optimization problems on graphs where the goal is to find a subset of vertices satisfying a predefined condition. Two prominent approaches for solving VSPs are dynamic programming over tree-like structures, such as tree decompositions or clique decompositions, and linear programming. In this work, we establish a sharp connection between both approaches by showing that if a vertex-subset problem $Π$ admits a solution-preserving dynamic programming algorithm that produces tables of size at most $α(k,n)$ when processing a tree decomposition of width at most $k$ of an $n$-vertex graph $G$, then the polytope $P_Π(G)$ defined as the convex-hull of solutions of $Π$ in $G$ has extension complexity at most $O(α(k,n)\cdot n)$. Additionally, this upper bound is optimal under the exponential time hypothesis (ETH).
  On the one hand, our results imply that ETH-optimal solution-preserving dynamic programming algorithms for combinatorial problems yield optimal-size parameterized extended formulations for the solution polytopes associated with instances of these problems. On the other hand, unconditional lower bounds obtained in the realm of the theory of extended formulations yield unconditional lower bounds on the table complexity of solution-preserving dynamic programming algorithms.

</details>


### [155] [The Secretary Problem with Predictions and a Chosen Order](https://arxiv.org/abs/2601.07482)
*Helia Karisani,Mohammadreza Daneshvaramoli,Hedyeh Beyhaghi,Mohammad Hajiesmaili,Cameron Musco*

Main category: cs.DS

TL;DR: 该论文提出了一种结合预测和到达顺序控制的随机算法，提高了秘书问题的竞争比率，尤其在预测误差大时仍保持稳健。


<details>
  <summary>Details</summary>
Motivation: 研究如何在预测准确时选择接近最优的秘书，同时在预测不准确时仍能保证有界的竞争比率，平衡一致性和鲁棒性。

Method: 提出了一种新的随机算法，该算法在检测到预测偏差较大时，从完全信任预测切换到基于阈值的规则。

Result: 在ROSP中，算法达到了max{0.221, (1-ε)/(1+ε)}的竞争比率；在COSP中，达到了max{0.262, (1-ε)/(1+ε)}，超过了之前方法的0.25最坏情况界限。

Conclusion: 该研究通过结合预测和到达顺序控制，提出了一种新的随机算法，显著提高了在随机顺序和选择顺序秘书问题中的竞争比率，尤其是在预测误差较大时仍能保持稳健性。

Abstract: We study a learning-augmented variant of the secretary problem, recently introduced by Fujii and Yoshida (2023), in which the decision-maker has access to machine-learned predictions of candidate values. The central challenge is to balance consistency and robustness: when predictions are accurate, the algorithm should select a near-optimal secretary, while under inaccurate predictions it should still guarantee a bounded competitive ratio.
  We consider both the classical Random Order Secretary Problem (ROSP), where candidates arrive in a uniformly random order, and a more natural learning-augmented model in which the decision-maker may choose the arrival order based on predicted values. We call this model the Chosen Order Secretary Problem (COSP), capturing scenarios such as interview schedules set in advance.
  We propose a new randomized algorithm applicable to both ROSP and COSP. Our method switches from fully trusting predictions to a threshold-based rule once a large prediction deviation is detected. Let $ε\in [0,1]$ denote the maximum multiplicative prediction error. For ROSP, our algorithm achieves a competitive ratio of $\max\{0.221, (1-ε)/(1+ε)\}$, improving upon the prior bound of $\max\{0.215, (1-ε)/(1+ε)\}$. For COSP, we achieve $\max\{0.262, (1-ε)/(1+ε)\}$, surpassing the $0.25$ worst-case bound for prior approaches and moving closer to the classical secretary benchmark of $1/e \approx 0.368$. These results highlight the benefit of combining predictions with arrival-order control in online decision-making.

</details>


### [156] [Dynamic $(Δ+ 1)$ Vertex Coloring](https://arxiv.org/abs/2601.07566)
*Noam Benson-Tilsen*

Main category: cs.DS

TL;DR: 本文综述了动态$(Δ+1)$-图着色算法的进展，从$O(Δ)$优化到$O(1)$，并扩展到自适应对抗模型。


<details>
  <summary>Details</summary>
Motivation: 图着色在网络拓扑控制、约束满足和实时资源调度等领域有广泛应用，研究其动态和次线性算法具有重要意义。

Method: 通过分析多篇论文（如arXiv:1708.09080、arXiv:1711.04355、arXiv:1910.02063和arXiv:2411.04418），总结了动态$(Δ+1)$-着色算法从$O(Δ)$到$O(1)$的优化过程，并扩展到自适应对抗模型。

Result: 动态$(Δ+1)$-着色算法的性能从$O(Δ)$逐步优化至$O(1)$，并成功扩展到自适应对抗模型。

Conclusion: 本文综述了动态和次线性图着色的最新成果，重点介绍了$(Δ+1)$-着色算法的性能提升及其在不同对抗模型下的应用。

Abstract: Several recent results from dynamic and sublinear graph coloring are surveyed. This problem is widely studied and has motivating applications like network topology control, constraint satisfaction, and real-time resource scheduling. Graph coloring algorithms are called colorers. In §1 are defined graph coloring, the dynamic model, and the notion of performance of graph algorithms in the dynamic model. In particular $(Δ+ 1)$-coloring, sublinear performance, and oblivious and adaptive adversaries are noted and motivated. In §2 the pair of approximately optimal dynamic vertex colorers given in arXiv:1708.09080 are summarized as a warmup for the $(Δ+ 1)$-colorers. In §3 the state of the art in dynamic $(Δ+ 1)$-coloring is presented. This section comprises a pair of papers (arXiv:1711.04355 and arXiv:1910.02063) that improve dynamic $(Δ+ 1)$-coloring from the naive algorithm with $O(Δ)$ expected amortized update time to $O(\log Δ)$, then to $O(1)$ with high probability. In §4 the results in arXiv:2411.04418, which gives a sublinear algorithm for $(Δ+ 1)$-coloring that generalizes oblivious adversaries to adaptive adversaries, are presented.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [157] [Walk the PLANC: Physics-Guided RL for Agile Humanoid Locomotion on Constrained Footholds](https://arxiv.org/abs/2601.06286)
*Min Dai,William D. Compton,Junheng Li,Lizhi Yang,Aaron D. Ames*

Main category: cs.RO

TL;DR: 结合简化步态规划器和强化学习的框架，显著提升双足人形机器人在不连续地形上的运动性能。


<details>
  <summary>Details</summary>
Motivation: 传统优化和控制方法依赖精确的数学地形表示，对感知噪声敏感；而纯强化学习方法难以精确规划落脚点和步序。结合两者的优势，通过物理引导强化学习解决这一问题。

Method: 通过引入一个简化阶步态规划器，生成动态一致的运动目标，并利用控制李雅普诺夫函数（CLF）奖励引导强化学习训练过程。

Result: 实验验证表明，该方法在硬件上实现了精确、敏捷的踏脚石运动，可靠性显著优于传统无模型强化学习基线。

Conclusion: 该论文提出了一种结合简化步态规划器和强化学习的框架，显著提高了双足人形机器人在不连续地形（如踏脚石）上的运动可靠性和精确性。

Abstract: Bipedal humanoid robots must precisely coordinate balance, timing, and contact decisions when locomoting on constrained footholds such as stepping stones, beams, and planks -- even minor errors can lead to catastrophic failure. Classical optimization and control pipelines handle these constraints well but depend on highly accurate mathematical representations of terrain geometry, making them prone to error when perception is noisy or incomplete. Meanwhile, reinforcement learning has shown strong resilience to disturbances and modeling errors, yet end-to-end policies rarely discover the precise foothold placement and step sequencing required for discontinuous terrain. These contrasting limitations motivate approaches that guide learning with physics-based structure rather than relying purely on reward shaping. In this work, we introduce a locomotion framework in which a reduced-order stepping planner supplies dynamically consistent motion targets that steer the RL training process via Control Lyapunov Function (CLF) rewards. This combination of structured footstep planning and data-driven adaptation produces accurate, agile, and hardware-validated stepping-stone locomotion on a humanoid robot, substantially improving reliability compared to conventional model-free reinforcement-learning baselines.

</details>


### [158] [BlazeAIoT: A Modular Multi-Layer Platform for Real-Time Distributed Robotics Across Edge, Fog, and Cloud Infrastructures](https://arxiv.org/abs/2601.06344)
*Cedric Melancon,Julien Gascon-Samson,Maarouf Saad,Kuljeet Kaur,Simon Savard*

Main category: cs.RO

TL;DR: BlazeAIoT 是一个模块化多层平台，旨在统一异构基础设施上的分布式机器人技术，提供动态数据传输、可配置服务和集成监控，同时确保弹性、安全性和编程语言灵活性。


<details>
  <summary>Details</summary>
Motivation: 分布式机器人技术的复杂性增加，需要一种能够无缝集成边缘、雾和云计算层并满足严格实时约束的平台。

Method: 该平台采用基于 Kubernetes 的集群、代理互操作性（DDS、Kafka、Redis 和 ROS2）以及自适应数据分发机制，优化了通信和计算。

Result: 验证结果表明，BlazeAIoT 能够在实时约束下动态分配服务、维护系统健康并最小化延迟。

Conclusion: BlazeAIoT 是一个成本敏感、可扩展的解决方案，适用于机器人技术和更广泛的物联网应用，如智能城市和智能工厂。

Abstract: The increasing complexity of distributed robotics has driven the need for platforms that seamlessly integrate edge, fog, and cloud computing layers while meeting strict real-time constraints. This paper introduces BlazeAIoT, a modular multi-layer platform designed to unify distributed robotics across heterogeneous infrastructures. BlazeAIoT provides dynamic data transfer, configurable services, and integrated monitoring, while ensuring resilience, security, and programming language flexibility. The architecture leverages Kubernetes-based clusters, broker interoperability (DDS, Kafka, Redis, and ROS2), and adaptive data distribution mechanisms to optimize communication and computation across diverse environments. The proposed solution includes a multi-layer configuration service, dynamic and adaptive data bridging, and hierarchical rate limiting to handle large messages. The platform is validated through robotics scenarios involving navigation and artificial intelligence-driven large-scale message processing, demonstrating robust performance under real-time constraints. Results highlight BlazeAIoT's ability to dynamically allocate services across incomplete topologies, maintain system health, and minimize latency, making it a cost-aware, scalable solution for robotics and broader IoT applications, such as smart cities and smart factories.

</details>


### [159] [Semantic Enrichment of CAD-Based Industrial Environments via Scene Graphs for Simulation and Reasoning](https://arxiv.org/abs/2601.06415)
*Nathan Pascal Walus,Ranulfo Bezerra,Shotaro Kojima,Tsige Tadesse Alemayoh,Satoshi Tadokoro,Kazunori Ohno*

Main category: cs.RO

TL;DR: 研究提出了一种离线方法，利用LVLM从CAD环境创建详细的3D场景图，以支持动态模拟和推理。


<details>
  <summary>Details</summary>
Motivation: CAD文件通常缺乏语义、关系和功能信息，限制了模拟和训练的可能性。

Method: 利用大型视觉语言模型（LVLM）丰富环境信息，构建包含语义、空间和功能信息的3D场景图。

Result: 研究包括生成的语义标签的定量结果和场景图的定性结果，特别是管道结构和识别的功能关系。

Conclusion: 该研究通过离线方法从CAD环境中创建详细的3D场景图，为动态模拟和推理提供了功能性和可操作元素的关系基础。

Abstract: Utilizing functional elements in an industrial environment, such as displays and interactive valves, provide effective possibilities for robot training. When preparing simulations for robots or applications that involve high-level scene understanding, the simulation environment must be equally detailed. Although CAD files for such environments deliver an exact description of the geometry and visuals, they usually lack semantic, relational and functional information, thus limiting the simulation and training possibilities. A 3D scene graph can organize semantic, spatial and functional information by enriching the environment through a Large Vision-Language Model (LVLM). In this paper we present an offline approach to creating detailed 3D scene graphs from CAD environments. This will serve as a foundation to include the relations of functional and actionable elements, which then can be used for dynamic simulation and reasoning. Key results of this research include both quantitative results of the generated semantic labels as well as qualitative results of the scene graph, especially in hindsight of pipe structures and identified functional relations. All code, results and the environment will be made available at https://cad-scenegraph.github.io

</details>


### [160] [CulinaryCut-VLAP: A Vision-Language-Action-Physics Framework for Food Cutting via a Force-Aware Material Point Method](https://arxiv.org/abs/2601.06451)
*Hyunseo Koh,Chang-Yong Song,Youngjae Choi,Misa Viveiros,David Hyde,Heewon Kim*

Main category: cs.RO

TL;DR: 论文提出了一种结合VLA数据集和MPM模拟器的框架，用于解决食品切割任务中的物理模拟和数据收集挑战，并提供了多模态基准数据集。


<details>
  <summary>Details</summary>
Motivation: 食品切割是视觉与机器人操作交叉领域中实用但未被充分探索的应用，由于刀具与可变形材料间的高度非线性交互（如大变形、频繁接触和拓扑变化）导致数据收集困难。

Method: 采用MLS-MPM作为计算核心的物理模拟器，减少了数值耗散和能量漂移，同时保留了切割过程中的旋转和剪切响应。通过粒子与网格之间的冲量交换估计力和应力分布，实现瞬态接触力和能量传递的稳定跟踪。

Result: 提出了一个基准数据集，整合了多样化的切割轨迹、多视角视觉观察和细粒度语言指令，以及力-扭矩和工具-姿态标签，为VLA模型提供了物理一致的训练信号。

Conclusion: 该论文提出了一个结合视觉-语言-动作（VLA）数据集与基于材料点方法（MPM）的物理模拟器的统一框架，为可变形物体切割任务提供了安全、可重复且可扩展的学习评估基础。

Abstract: Food cutting is a highly practical yet underexplored application at the intersection of vision and robotic manipulation. The task remains challenging because interactions between the knife and deformable materials are highly nonlinear and often entail large deformations, frequent contact, and topological change, which in turn hinder stable and safe large-scale data collection.
  To address these challenges, we propose a unified framework that couples a vision-language-action (VLA) dataset with a physically realistic cutting simulator built on the material point method (MPM). Our simulator adopts MLS-MPM as its computational core, reducing numerical dissipation and energy drift while preserving rotational and shear responses even under topology-changing cuts. During cutting, forces and stress distributions are estimated from impulse exchanges between particles and the grid, enabling stable tracking of transient contact forces and energy transfer.
  We also provide a benchmark dataset that integrates diverse cutting trajectories, multi-view visual observations, and fine-grained language instructions, together with force--torque and tool--pose labels to provide physically consistent training signals.
  These components realize a learning--evaluation loop that respects the core physics of cutting and establishes a safe, reproducible, and scalable foundation for advancing VLA models in deformable object manipulation.

</details>


### [161] [Precision Meets Art: Autonomous Multi-UAV System for Large Scale Mural Drawing](https://arxiv.org/abs/2601.06508)
*Andrei A. Korigodskii,Artem E. Vasiunik,Georgii A. Varin,Adilia M. Zukhurova,Matvei V. Urvantsev,Semen A. Osipenkov,Igor S. Efremov,Georgii E. Bondar*

Main category: cs.RO

TL;DR: 多无人机系统通过先进算法实现高精度壁画创作，验证了其在大型艺术项目中的高效性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 探索无人机在大型艺术创作中的应用潜力，解决单无人机在操作速度和可扩展性上的局限。

Method: 论文提出了一种新颖的多无人机系统，采用状态机算法协调多机同时作业，结合2D定位和LiDAR实现精确位置控制，并开发了独特的飞行控制算法以保证绘画的平滑性和精确性。

Result: 成功创作了一幅100平方米的壁画，验证了多无人机系统在户外环境下的高效性、稳定性和高精度，相比单无人机方案显著提升了性能。

Conclusion: 该论文展示了多无人机系统在大型艺术项目中的潜力，特别是在户外壁画创作中。通过结合先进的定位和飞行控制算法，系统在保持高精度的同时显著提升了操作速度和可扩展性。

Abstract: The integration of autonomous unmanned aerial vehicles (UAVs) into large-scale artistic projects has emerged as a new application in robotics. This paper presents the design, deployment, and testing of a novel multi-drone system for automated mural painting in outdoor settings. This technology makes use of new software that coordinates multiple drones simultaneously, utilizing state-machine algorithms for task execution. Key advancements are the complex positioning system that combines 2D localization using a single motion tracking camera with onboard LiDAR for precise positioning, and a novel flight control algorithm, which works differently along the trajectory and normally to it, ensuring smoothness and high precision of the drawings at the same time. A 100 square meters mural was created using the developed multi-drone system, validating the system's efficacy. Compared to single-drone approaches, our multi-UAV solution significantly improves scalability and operational speed while maintaining high stability even in harsh weather conditions. The findings highlight the potential of autonomous robotic swarms in creative applications, paving the way for further advancements in large-scale robotic art.

</details>


### [162] [Model Reconciliation through Explainability and Collaborative Recovery in Assistive Robotics](https://arxiv.org/abs/2601.06552)
*Britt Besch,Tai Mai,Jeremias Thun,Markus Huff,Jörn Vogel,Freek Stulp,Samuel Bustamante*

Main category: cs.RO

TL;DR: 论文提出利用大型语言模型协调机器人与人类心理模型的框架，实验验证其在辅助机器人领域的有效性。


<details>
  <summary>Details</summary>
Motivation: 在人与机器人协作中，尤其是共享控制应用中，确保机器人行为可解释至关重要。机器人与用户需共享相同的世界对象模型及可执行动作，以避免误解。

Method: 利用大型语言模型预测和解释机器人与人类心理模型的差异，并在辅助机器人领域进行了实验验证，包括真实轮椅式移动机械臂及其数字孪生。

Result: 实验验证了模型协调框架的有效性，能够在不依赖用户正式心理模型的情况下，解释并解决机器人与人类心理模型的分歧。

Conclusion: 该论文提出了一种模型协调框架，通过大型语言模型预测并解释机器人与人类心理模型之间的差异，无需用户正式的心理模型。框架还允许人类纠正机器人以解决模型分歧，实验在辅助机器人领域验证了其有效性。

Abstract: Whenever humans and robots work together, it is essential that unexpected robot behavior can be explained to the user. Especially in applications such as shared control the user and the robot must share the same model of the objects in the world, and the actions that can be performed on these objects.
  In this paper, we achieve this with a so-called model reconciliation framework. We leverage a Large Language Model to predict and explain the difference between the robot's and the human's mental models, without the need of a formal mental model of the user. Furthermore, our framework aims to solve the model divergence after the explanation by allowing the human to correct the robot. We provide an implementation in an assistive robotics domain, where we conduct a set of experiments with a real wheelchair-based mobile manipulator and its digital twin.

</details>


### [163] [UMLoc: Uncertainty-Aware Map-Constrained Inertial Localization with Quantified Bounds](https://arxiv.org/abs/2601.06602)
*Mohammed S. Alharbi,Shinkyu Park*

Main category: cs.RO

TL;DR: UMLoc是一种结合IMU不确定性和地图约束的端到端框架，通过LSTM和CGAN模块实现抗漂移定位，效果显著。


<details>
  <summary>Details</summary>
Motivation: 在GPS不可用的室内环境中，仅依赖IMU的定位存在漂移问题，需结合地图约束提升精度。

Method: UMLoc结合了LSTM分位数回归器和CGAN，前者估计定位不确定性，后者融合IMU动态数据与地图约束生成几何可行的轨迹。

Result: 在三个数据集上评估，包括新收集的2小时室内基准数据，UMLoc表现出色，漂移率和轨迹误差均较低。

Conclusion: UMLoc通过联合建模IMU不确定性和地图约束，实现了抗漂移的定位，平均漂移率为5.9%，平均绝对轨迹误差为1.36米。

Abstract: Inertial localization is particularly valuable in GPS-denied environments such as indoors. However, localization using only Inertial Measurement Units (IMUs) suffers from drift caused by motion-process noise and sensor biases. This paper introduces Uncertainty-aware Map-constrained Inertial Localization (UMLoc), an end-to-end framework that jointly models IMU uncertainty and map constraints to achieve drift-resilient positioning. UMLoc integrates two coupled modules: (1) a Long Short-Term Memory (LSTM) quantile regressor, which estimates the specific quantiles needed to define 68%, 90%, and 95% prediction intervals serving as a measure of localization uncertainty and (2) a Conditioned Generative Adversarial Network (CGAN) with cross-attention that fuses IMU dynamic data with distance-based floor-plan maps to generate geometrically feasible trajectories. The modules are trained jointly, allowing uncertainty estimates to propagate through the CGAN during trajectory generation. UMLoc was evaluated on three datasets, including a newly collected 2-hour indoor benchmark with time-aligned IMU data, ground-truth poses and floor-plan maps. Results show that the method achieves a mean drift ratio of 5.9% over a 70 m travel distance and an average Absolute Trajectory Error (ATE) of 1.36 m, while maintaining calibrated prediction bounds.

</details>


### [164] [Robotic Tele-Operation for Upper Aerodigestive Tract Microsurgery: System Design and Validation](https://arxiv.org/abs/2601.06617)
*Giovani Braglia,José Jair Alves Mendes Junior,Augusto Tetsuo Prado Inafuco,Federico Mariano,Leonardo S. Mattos*

Main category: cs.RO

TL;DR: 提出了一种用于上消化道手术的机器人钳子操作系统，通过实验验证了其优于传统手动操作的性能。


<details>
  <summary>Details</summary>
Motivation: 传统TLM手术中钳子操作主要依赖手动，存在人体工程学、精度和可控性方面的局限性。

Method: 基于新型末端执行器的机器人系统，结合远程运动中心（RCM）编程的机械臂，实现精确且受限的器械运动。

Result: 通过两项实验研究和专门的可用性评估，证明了该系统在上消化道手术应用中的有效性。

Conclusion: 论文提出了一种新型机器人系统，用于上消化道手术中的组织操作，通过实验验证了其有效性和适用性。

Abstract: Upper aerodigestive tract (UADT) treatments frequently employ transoral laser microsurgery (TLM) for procedures such as the removal of tumors or polyps. In TLM, a laser beam is used to cut target tissue, while forceps are employed to grasp, manipulate, and stabilize tissue within the UADT. Although TLM systems may rely on different technologies and interfaces, forceps manipulation is still predominantly performed manually, introducing limitations in ergonomics, precision, and controllability. This paper proposes a novel robotic system for tissue manipulation in UADT procedures, based on a novel end-effector designed for forceps control. The system is integrated within a teleoperation framework that employs a robotic manipulator with a programmed remote center of motion (RCM), enabling precise and constrained instrument motion while improving surgeon ergonomics. The proposed approach is validated through two experimental studies and a dedicated usability evaluation, demonstrating its effectiveness and suitability for UADT surgical applications.

</details>


### [165] [Follow the Signs: Using Textual Cues and LLMs to Guide Efficient Robot Navigation](https://arxiv.org/abs/2601.06652)
*Jing Cao,Nishanth Kumar,Aidan Curtis*

Main category: cs.RO

TL;DR: 该论文提出了一种利用大型语言模型（LLMs）解析语义线索的导航框架，显著提升了机器人在陌生环境中的导航效率。


<details>
  <summary>Details</summary>
Motivation: 传统导航方法依赖几何映射和规划策略，忽视了丰富的语义线索（如标志、房间号和文本标签），限制了导航效率。

Method: 该方法结合局部感知输入、前沿探索和周期性LLM查询，通过提取符号模式（如房间编号方案和建筑布局结构）并更新用于引导探索的置信网格，实现了高效导航。

Result: 实验表明，该方法在模拟真实平面图的环境中实现了接近最优的路径规划，并在成功率加权路径长度（Success weighted by Path Length）上比基线方法提高了25%以上。

Conclusion: 该论文提出了一种结合大型语言模型（LLMs）和前沿探索的语义导航框架，通过利用语义线索（如房间编号和建筑布局）显著提升了机器人在陌生环境中的导航效率。

Abstract: Autonomous navigation in unfamiliar environments often relies on geometric mapping and planning strategies that overlook rich semantic cues such as signs, room numbers, and textual labels. We propose a novel semantic navigation framework that leverages large language models (LLMs) to infer patterns from partial observations and predict regions where the goal is most likely located. Our method combines local perceptual inputs with frontier-based exploration and periodic LLM queries, which extract symbolic patterns (e.g., room numbering schemes and building layout structures) and update a confidence grid used to guide exploration. This enables robots to move efficiently toward goal locations labeled with textual identifiers (e.g., "room 8") even before direct observation. We demonstrate that this approach enables more efficient navigation in sparse, partially observable grid environments by exploiting symbolic patterns. Experiments across environments modeled after real floor plans show that our approach consistently achieves near-optimal paths and outperforms baselines by over 25% in Success weighted by Path Length.

</details>


### [166] [Robust Evacuation for Multi-Drone Failure in Drone Light Shows](https://arxiv.org/abs/2601.06728)
*Minhyuk Park,Aloysius K. Mok,Tsz-Chiu Au*

Main category: cs.RO

TL;DR: 提出一种无人机停车算法，通过预测故障轨迹和隐藏无人机恢复，提升灯光秀的安全性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 针对无人机灯光秀中多机同时故障引发的安全与可靠性问题，提出解决方案以减少连锁碰撞风险并实现快速恢复。

Method: 算法结合了Social LSTM模型和注意力机制，预测故障无人机轨迹并计算疏散路径，同时利用隐藏无人机实现快速恢复。

Result: 实验表明，该方法通过深度学习预测故障无人机轨迹，有效提升了多无人机系统的鲁棒性。

Conclusion: 该论文提出了一种针对无人机灯光秀中多机故障的停车算法，通过预测故障无人机的轨迹并计算最优疏散路径，结合隐藏无人机快速恢复系统，显著提高了多无人机系统的鲁棒性。

Abstract: Drone light shows have emerged as a popular form of entertainment in recent years. However, several high-profile incidents involving large-scale drone failures -- where multiple drones simultaneously fall from the sky -- have raised safety and reliability concerns. To ensure robustness, we propose a drone parking algorithm designed specifically for multiple drone failures in drone light shows, aimed at mitigating the risk of cascading collisions by drone evacuation and enabling rapid recovery from failures by leveraging strategically placed hidden drones. Our algorithm integrates a Social LSTM model with attention mechanisms to predict the trajectories of failing drones and compute near-optimal evacuation paths that minimize the likelihood of surviving drones being hit by fallen drones. In the recovery node, our system deploys hidden drones (operating with their LED lights turned off) to replace failed drones so that the drone light show can continue. Our experiments showed that our approach can greatly increase the robustness of a multi-drone system by leveraging deep learning to predict the trajectories of fallen drones.

</details>


### [167] [On-the-Fly VLA Adaptation via Test-Time Reinforcement Learning](https://arxiv.org/abs/2601.06748)
*Changyu Liu,Yiyang Liu,Taowen Wang,Qiao Zhuang,James Chenhao Liang,Wenhao Yang,Renjing Xu,Qifan Wang,Dongfang Liu,Cheng Han*

Main category: cs.RO

TL;DR: TT-VLA是一种测试时强化学习框架，通过动态策略调整提升视觉-语言-动作模型在未知环境中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉-语言-动作模型主要通过监督微调或训练时强化学习进行训练，需要显式的微调阶段或人工干预，难以在动态环境中自主灵活响应。

Method: TT-VLA通过密集奖励机制，利用任务进度信号在测试时动态优化动作策略，同时保留监督微调或强化学习训练的先前知识。

Result: 实验结果表明，TT-VLA在模拟和真实世界的动态、未见场景中显著提高了模型的适应性、稳定性和任务成功率。

Conclusion: TT-VLA框架为视觉-语言-动作模型提供了一种在推理时动态调整策略的方法，显著提升了模型在动态和未知环境中的适应性和任务成功率，是向自改进、可部署VLAs迈出的重要一步。

Abstract: Vision-Language-Action models have recently emerged as a powerful paradigm for general-purpose robot learning, enabling agents to map visual observations and natural-language instructions into executable robotic actions. Though popular, they are primarily trained via supervised fine-tuning or training-time reinforcement learning, requiring explicit fine-tuning phases, human interventions, or controlled data collection. Consequently, existing methods remain unsuitable for challenging simulated- or physical-world deployments, where robots must respond autonomously and flexibly to evolving environments. To address this limitation, we introduce a Test-Time Reinforcement Learning for VLAs (TT-VLA), a framework that enables on-the-fly policy adaptation during inference. TT-VLA formulates a dense reward mechanism that leverages step-by-step task-progress signals to refine action policies during test time while preserving the SFT/RL-trained priors, making it an effective supplement to current VLA models. Empirical results show that our approach enhances overall adaptability, stability, and task success in dynamic, previously unseen scenarios under simulated and real-world settings. We believe TT-VLA offers a principled step toward self-improving, deployment-ready VLAs.

</details>


### [168] [SPINE Gripper: A Twisted Underactuated Mechanism-based Passive Mode-Transition Gripper](https://arxiv.org/abs/2601.06833)
*JaeHyung Jang,JunHyeong Park,Joong-Ku Lee,Jee-Hwan Ryu*

Main category: cs.RO

TL;DR: 单执行器被动夹持器通过机械编码逻辑实现稳定抓取和双向旋转，无需传感器或主动控制。


<details>
  <summary>Details</summary>
Motivation: 传统多功能夹持器需要多个执行器、传感器或基于控制的切换，而本设计旨在通过机械设计简化系统复杂性。

Method: 提出了Twisted Underactuated Mechanism (TUM)，通过单一旋转输入生成轴向收缩和旋转的非共面运动，并通过摩擦生成器定义扭矩阈值实现被动模式切换。

Result: 实验验证了TUM的运动学、弹性力生成和扭矩传输模型，夹持器在抓取成功、摩擦力调节和双向旋转性能方面表现优异。

Conclusion: 本文展示了一种通过机械编码动力传输逻辑实现的单执行器被动夹持器，能够稳定抓取并连续双向旋转，证明了仅通过机械设计即可实现非共面多功能操作。

Abstract: This paper presents a single-actuator passive gripper that achieves both stable grasping and continuous bidirectional in-hand rotation through mechanically encoded power transmission logic. Unlike conventional multifunctional grippers that require multiple actuators, sensors, or control-based switching, the proposed gripper transitions between grasping and rotation solely according to the magnitude of the applied input torque. The key enabler of this behavior is a Twisted Underactuated Mechanism (TUM), which generates non-coplanar motions, namely axial contraction and rotation, from a single rotational input while producing identical contraction regardless of rotation direction. A friction generator mechanically defines torque thresholds that govern passive mode switching, enabling stable grasp establishment before autonomously transitioning to in-hand rotation without sensing or active control. Analytical models describing the kinematics, elastic force generation, and torque transmission of the TUM are derived and experimentally validated. The fabricated gripper is evaluated through quantitative experiments on grasp success, friction-based grasp force regulation, and bidirectional rotation performance. System-level demonstrations, including bolt manipulation, object reorientation, and manipulator-integrated tasks driven solely by wrist torque, confirm reliable grasp to rotate transitions in both rotational directions. These results demonstrate that non-coplanar multifunctional manipulation can be realized through mechanical design alone, establishing mechanically encoded power transmission logic as a robust alternative to actuator and control intensive gripper architectures.

</details>


### [169] [Semilinear single-track vehicle models with distributed tyre friction dynamics](https://arxiv.org/abs/2601.06854)
*Luigi Romano,Ole Morten Aamo,Jan Åslund,Erik Frisk*

Main category: cs.RO

TL;DR: 论文提出了一种结合瞬态轮胎动力学和非线性摩擦效应的分布式FrBD模型，显著提升了侧向车辆动力学建模水平。


<details>
  <summary>Details</summary>
Motivation: 现有车辆动力学模型在描述瞬态轮胎行为和非线性摩擦效应时存在局限性，需要一种更物理基础扎实且数学严谨的建模方法。

Method: 论文提出了一种基于分布式Friction with Bristle Dynamics（FrBD）模型的单轨车辆框架，该模型通过半线性偏微分方程（PDEs）描述滚动接触过程，并系统地集成到单轨车辆框架中，形成半线性ODE-PDE互联系统。考虑了刚性轮胎胎体和柔性轮胎胎体两种变体，并建立了严格的局部和全局适定性。

Result: 数值模拟表明，该模型能够捕捉微摆振荡和高级转向操作的瞬态侧向响应，验证了其有效性。

Conclusion: 该论文提出的分布式FrBD模型通过结合瞬态轮胎动力学和非线性摩擦效应，为车辆动力学建模提供了物理基础扎实、数学严谨且计算可行的方法，显著提升了侧向车辆动力学中瞬态轮胎行为的建模水平。

Abstract: This paper introduces a novel family of single-track vehicle models that incorporate a distributed representation of transient tyre dynamics, whilst simultaneously accounting for nonlinear effects induced by friction. The core of the proposed framework is represented by the distributed Friction with Bristle Dynamics (FrBD) model, which unifies and extends classical formulations such as Dahl and LuGre by describing the rolling contact process as a spatially distributed system governed by semilinear partial differential equations (PDEs). This model is systematically integrated into a single-track vehicle framework, where the resulting semilinear ODE-PDE interconnection captures the interaction between lateral vehicle motion and tyre deformation. Two main variants are considered: one with rigid tyre carcass and another with flexible carcass, each admitting a compact state-space representation. Local and global well-posedness properties for the coupled system are established rigorously, highlighting the dissipative and physically consistent properties of the distributed FrBD model. A linearisation procedure is also presented, enabling spectral analysis and transfer function derivation, and potentially facilitating the synthesis of controllers and observers. Numerical simulations demonstrate the model's capability to capture micro-shimmy oscillations and transient lateral responses to advanced steering manoeuvres. The proposed formulation advances the state-of-the-art in vehicle dynamics modelling by providing a physically grounded, mathematically rigorous, and computationally tractable approach to incorporating transient tyre behaviour in lateral vehicle dynamics, when accounting for the effect of limited friction.

</details>


### [170] [Observability-Enhanced Target Motion Estimation via Bearing-Box: Theory and MAV Applications](https://arxiv.org/abs/2601.06887)
*Yin Zhang,Zian Ning,Shiyu Zhao*

Main category: cs.RO

TL;DR: 提出基于bearing-box的运动估计方法，无需传统假设，适用于MAV，实验验证性能优越。


<details>
  <summary>Details</summary>
Motivation: 现有基于bearing的运动估计方法依赖限制性假设（如目标形状各向同性、横向运动），且普遍认为高阶运动假设是必要的。本文旨在探索现代3D检测数据的潜力，提出更通用的解决方案。

Method: 采用bearing-box方法，利用现代3D检测测量数据，无需依赖各向同性目标形状或横向运动等假设，通过3D边界框中的信息估计目标运动和尺寸。对于MAV，还利用加速度与推力的独特耦合关系，避免高阶运动假设。

Result: 通过严格的观测性分析和实验验证，证明了该方法在真实场景中的优越性能，尤其在MAV应用中无需高阶运动假设。

Conclusion: 该论文提出了一种基于bearing-box的新型运动估计方法，能够在无需传统限制性假设的情况下，准确估计目标的运动和物理尺寸，特别适用于多旋翼微型飞行器（MAV），并通过实验验证了其优越性能。

Abstract: Monocular vision-based target motion estimation is a fundamental challenge in numerous applications. This work introduces a novel bearing-box approach that fully leverages modern 3D detection measurements that are widely available nowadays but have not been well explored for motion estimation so far. Unlike existing methods that rely on restrictive assumptions such as isotropic target shape and lateral motion, our bearing-box estimator can estimate both the target's motion and its physical size without these assumptions by exploiting the information buried in a 3D bounding box. When applied to multi-rotor micro aerial vehicles (MAVs), the estimator yields an interesting advantage: it further removes the need for higher-order motion assumptions by exploiting the unique coupling between MAV's acceleration and thrust. This is particularly significant, as higher-order motion assumptions are widely believed to be necessary in state-of-the-art bearing-based estimators. We support our claims with rigorous observability analyses and extensive experimental validation, demonstrating the estimator's superior performance in real-world scenarios.

</details>


### [171] [ObjSplat: Geometry-Aware Gaussian Surfels for Active Object Reconstruction](https://arxiv.org/abs/2601.06997)
*Yuetao Li,Zhizhou Jia,Yu Zhang,Qun Hao,Shaohui Zhang*

Main category: cs.RO

TL;DR: ObjSplat是一种主动重建框架，通过高斯曲面和智能路径规划，高效生成高保真物体模型。


<details>
  <summary>Details</summary>
Motivation: 解决传统基于不透明度或深度的提示在高保真物体重建中的局限性，以及贪婪规划策略的效率问题。

Method: 采用高斯曲面作为统一表示，结合几何感知的视点评估（建模背面可见性和遮挡感知的多视角共视性）和动态空间图上的多步前瞻路径规划（NBP）。

Result: 在仿真和真实文化遗产实验中，ObjSplat能在几分钟内生成物理一致的模型，重建保真度和表面完整性优于现有方法，同时显著减少扫描时间和路径长度。

Conclusion: ObjSplat通过高斯曲面作为统一表示，结合几何感知的视点评估和多步前瞻的路径规划，显著提升了物体重建的保真度和效率，优于现有方法。

Abstract: Autonomous high-fidelity object reconstruction is fundamental for creating digital assets and bridging the simulation-to-reality gap in robotics. We present ObjSplat, an active reconstruction framework that leverages Gaussian surfels as a unified representation to progressively reconstruct unknown objects with both photorealistic appearance and accurate geometry. Addressing the limitations of conventional opacity or depth-based cues, we introduce a geometry-aware viewpoint evaluation pipeline that explicitly models back-face visibility and occlusion-aware multi-view covisibility, reliably identifying under-reconstructed regions even on geometrically complex objects. Furthermore, to overcome the limitations of greedy planning strategies, ObjSplat employs a next-best-path (NBP) planner that performs multi-step lookahead on a dynamically constructed spatial graph. By jointly optimizing information gain and movement cost, this planner generates globally efficient trajectories. Extensive experiments in simulation and on real-world cultural artifacts demonstrate that ObjSplat produces physically consistent models within minutes, achieving superior reconstruction fidelity and surface completeness while significantly reducing scan time and path length compared to state-of-the-art approaches. Project page: https://li-yuetao.github.io/ObjSplat-page/ .

</details>


### [172] [A Sliding Mode Controller Based on Timoshenko Beam Theory Developed for a Tendon-Driven Robotic Wrist](https://arxiv.org/abs/2601.07009)
*Shifa Sulaiman,Mohammad Gohari,Francesco Schetter,Fanny Ficuciello*

Main category: cs.RO

TL;DR: 该论文设计了一种肌腱驱动的机器人手腕关节及高效滑模控制器，验证了其在运动精度和快速收敛方面的优越性。


<details>
  <summary>Details</summary>
Motivation: 开发灵巧的机器人关节对于提升机器人系统的操作能力至关重要。

Method: 论文提出了一种基于Timoshenko方法的肌腱驱动机器人手腕关节设计，并实现了一个高效的滑模控制器（SMC）用于精确运动控制。控制器设计旨在提供快速的动态响应和计算效率。

Result: 提出的SMC在仿真和实验研究中均表现出优越性能，仿真中的均方根误差（RMSE）约为1.67e-2弧度，实验验证误差为0.2弧度。控制器实现小于3秒的稳定时间和低于1e-1弧度的稳态误差。

Conclusion: 该研究为未来探索肌腱驱动的手腕机制和机器人应用中的控制策略奠定了基础。

Abstract: Development of dexterous robotic joints is essential for advancing manipulation capabilities in robotic systems. This paper presents the design and implementation of a tendon-driven robotic wrist joint together with an efficient Sliding Mode Controller (SMC) for precise motion control. The wrist mechanism is modeled using a Timoshenko-based approach to accurately capture its kinematic and dynamic properties, which serve as the foundation for tendon force calculations within the controller. The proposed SMC is designed to deliver fast dynamic response and computational efficiency, enabling accurate trajectory tracking under varying operating conditions. The effectiveness of the controller is validated through comparative analyses with existing controllers for similar wrist mechanisms. The proposed SMC demonstrates superior performance in both simulation and experimental studies. The Root Mean Square Error (RMSE) in simulation is approximately 1.67e-2 radians, while experimental validation yields an error of 0.2 radians. Additionally, the controller achieves a settling time of less than 3 seconds and a steady-state error below 1e-1 radians, consistently observed across both simulation and experimental evaluations. Comparative analyses confirm that the developed SMC surpasses alternative control strategies in motion accuracy, rapid convergence, and steady-state precision. This work establishes a foundation for future exploration of tendon-driven wrist mechanisms and control strategies in robotic applications.

</details>


### [173] [RSLCPP - Deterministic Simulations Using ROS 2](https://arxiv.org/abs/2601.07052)
*Simon Sagmeister,Marcel Weinmann,Phillip Pitschi,Markus Lienkamp*

Main category: cs.RO

TL;DR: RSLCPP通过ROS 2节点实现确定性模拟，解决ROS异步设计导致的不可重复性问题。


<details>
  <summary>Details</summary>
Motivation: ROS的异步多进程设计导致难以保证确定性回调执行，影响科学基准测试和持续集成的可重复性。

Method: 开发了ROS Simulation Library for C++ (RSLCPP)，将现有节点组合成模拟例程，实现确定性执行。

Result: 测试表明，RSLCPP在合成基准和真实机器人系统上均能在不同CPU和架构上产生一致结果。

Conclusion: RSLCPP提供了一种方法，通过ROS 2节点创建确定性模拟，确保在不同硬件平台上获得可重复的结果，且无需代码更改。

Abstract: Simulation is crucial in real-world robotics, offering safe, scalable, and efficient environments for developing applications, ranging from humanoid robots to autonomous vehicles and drones. While the Robot Operating System (ROS) has been widely adopted as the backbone of these robotic applications in both academia and industry, its asynchronous, multiprocess design complicates reproducibility, especially across varying hardware platforms. Deterministic callback execution cannot be guaranteed when computation times and communication delays vary. This lack of reproducibility complicates scientific benchmarking and continuous integration, where consistent results are essential. To address this, we present a methodology to create deterministic simulations using ROS 2 nodes. Our ROS Simulation Library for C++ (RSLCPP) implements this approach, enabling existing nodes to be combined into a simulation routine that yields reproducible results without requiring any code changes. We demonstrate that our approach yields identical results across various CPUs and architectures when testing both a synthetic benchmark and a real-world robotics system. RSLCPP is open-sourced at https://github.com/TUMFTM/rslcpp.

</details>


### [174] [PALM: Progress-Aware Policy Learning via Affordance Reasoning for Long-Horizon Robotic Manipulation](https://arxiv.org/abs/2601.07060)
*Yuanzhe Liu,Jingyuan Zhu,Yuchen Mo,Gen Li,Xu Cao,Jin Jin,Yifan Shen,Zhengyuan Li,Tianjiao Yu,Wenzhen Yuan,Fangqiang Ding,Ismini Lourentzou*

Main category: cs.RO

TL;DR: PALM是一种VLA框架，通过affordance推理和子任务进度提示优化长视野任务表现，实验结果显示其显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型在长视野、多步骤任务中缺乏内部推理机制，导致重复动作、遗漏步骤和提前终止等关键执行错误。

Method: PALM框架通过提取互补的affordance表示（包括对象相关性、接触几何、空间布局和运动动力学），并将其作为任务相关的视觉运动控制锚点，同时预测子任务内连续进度以实现平稳过渡。

Result: PALM在LIBERO-LONG任务中达到91.8%的成功率，在CALVIN ABC->D任务中平均长度提升12.5%，在三种长视野泛化设置中比真实基线方法提升2倍。

Conclusion: PALM框架通过结合交互为中心的affordance推理和子任务进度提示，显著提升了VLA模型在长视野、多步骤任务中的表现，并在仿真和真实实验中均优于现有基线方法。

Abstract: Recent advancements in vision-language-action (VLA) models have shown promise in robotic manipulation, yet they continue to struggle with long-horizon, multi-step tasks. Existing methods lack internal reasoning mechanisms that can identify task-relevant interaction cues or track progress within a subtask, leading to critical execution errors such as repeated actions, missed steps, and premature termination. To address these challenges, we introduce PALM, a VLA framework that structures policy learning around interaction-centric affordance reasoning and subtask progress cues. PALM distills complementary affordance representations that capture object relevance, contact geometry, spatial placements, and motion dynamics, and serve as task-relevant anchors for visuomotor control. To further stabilize long-horizon execution, PALM predicts continuous within-subtask progress, enabling seamless subtask transitions. Across extensive simulation and real-world experiments, PALM consistently outperforms baselines, achieving a 91.8% success rate on LIBERO-LONG, a 12.5% improvement in average length on CALVIN ABC->D, and a 2x improvement over real-world baselines across three long-horizon generalization settings.

</details>


### [175] [PROTEA: Securing Robot Task Planning and Execution](https://arxiv.org/abs/2601.07186)
*Zainab Altaweel,Mohaiminul Al Nahian,Jake Juettner,Adnan Siraj Rakin,Shiqi Zhang*

Main category: cs.RO

TL;DR: PROTEA是一种基于LLM的防御机制，用于评估机器人任务计划的安全性，通过系统性实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 针对现有机器人任务规划系统（尤其是基于基础模型的系统）在对抗性攻击中暴露的显著漏洞，提出安全挑战的解决方案。

Method: 通过引入PROTEA机制，利用不同LLM实现多个版本进行比较，并创建包含良性及恶意任务计划的数据集进行系统性评估。

Result: PROTEA成功解决了计划安全评估中的维度和历史挑战，实验结果提供了增强任务规划系统安全性的实用见解。

Conclusion: PROTEA作为一种LLM-as-a-Judge防御机制，有效提升了机器人任务规划系统的安全性和鲁棒性，为实践者提供了可行的改进方向。

Abstract: Robots need task planning methods to generate action sequences for complex tasks. Recent work on adversarial attacks has revealed significant vulnerabilities in existing robot task planners, especially those built on foundation models. In this paper, we aim to address these security challenges by introducing PROTEA, an LLM-as-a-Judge defense mechanism, to evaluate the security of task plans. PROTEA is developed to address the dimensionality and history challenges in plan safety assessment. We used different LLMs to implement multiple versions of PROTEA for comparison purposes. For systemic evaluations, we created a dataset containing both benign and malicious task plans, where the harmful behaviors were injected at varying levels of stealthiness. Our results provide actionable insights for robotic system practitioners seeking to enhance robustness and security of their task planning systems. Details, dataset and demos are provided: https://protea-secure.github.io/PROTEA/

</details>


### [176] [NanoCockpit: Performance-optimized Application Framework for AI-based Autonomous Nanorobotics](https://arxiv.org/abs/2601.07476)
*Elia Cereda,Alessandro Giusti,Daniele Palossi*

Main category: cs.RO

TL;DR: NanoCockpit框架通过优化资源利用和任务流水线，显著提升了纳米无人机的控制性能。


<details>
  <summary>Details</summary>
Motivation: 纳米无人机因资源有限，现有软件层无法高效利用其计算资源，导致控制性能不佳。

Method: 提出了NanoCockpit框架，采用多缓冲区图像采集、多核计算、MCU间数据交换和Wi-Fi流式传输的流水线优化方法。

Result: 实验表明，框架在三个真实TinyML应用中实现了端到端零延迟，闭环控制性能显著提升（平均位置误差减少30%，任务成功率从40%提升至100%）。

Conclusion: NanoCockpit框架通过协程多任务处理显著提升了纳米无人机的控制性能，实现了零任务序列化开销的理想端到端延迟。

Abstract: Autonomous nano-drones, powered by vision-based tiny machine learning (TinyML) models, are a novel technology gaining momentum thanks to their broad applicability and pushing scientific advancement on resource-limited embedded systems. Their small form factor, i.e., a few 10s grams, severely limits their onboard computational resources to sub-\SI{100}{\milli\watt} microcontroller units (MCUs). The Bitcraze Crazyflie nano-drone is the \textit{de facto} standard, offering a rich set of programmable MCUs for low-level control, multi-core processing, and radio transmission. However, roboticists very often underutilize these onboard precious resources due to the absence of a simple yet efficient software layer capable of time-optimal pipelining of multi-buffer image acquisition, multi-core computation, intra-MCUs data exchange, and Wi-Fi streaming, leading to sub-optimal control performances. Our \textit{NanoCockpit} framework aims to fill this gap, increasing the throughput and minimizing the system's latency, while simplifying the developer experience through coroutine-based multi-tasking. In-field experiments on three real-world TinyML nanorobotics applications show our framework achieves ideal end-to-end latency, i.e. zero overhead due to serialized tasks, delivering quantifiable improvements in closed-loop control performance ($-$30\% mean position error, mission success rate increased from 40\% to 100\%).

</details>


### [177] [HERE: Hierarchical Active Exploration of Radiance Field with Epistemic Uncertainty Minimization](https://arxiv.org/abs/2601.07242)
*Taekbeom Lee,Dabin Kim,Youngseok Jang,H. Jin Kim*

Main category: cs.RO

TL;DR: HERE框架利用神经辐射场和主动学习策略，通过认知不确定性量化高效识别未探索区域，实现高保真3D重建，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有3D场景重建方法在识别未探索或重建不良区域方面的不足，提高重建的完整性和效率。

Method: 采用基于证据深度学习的认知不确定性量化方法，结合局部和全局规划策略，生成相机轨迹以高效采集数据并精确重建场景。

Result: 在多种尺度的照片级模拟场景中，HERE框架相比现有方法实现了更高的重建完整性，硬件演示也验证了其实际应用效果。

Conclusion: HERE框架通过基于神经辐射场的主动学习策略，实现了高保真度的隐式3D场景重建，其核心是通过证据深度学习量化认知不确定性，有效识别未探索区域，从而提升重建完整性和效率。硬件演示进一步验证了其实际应用价值。

Abstract: We present HERE, an active 3D scene reconstruction framework based on neural radiance fields, enabling high-fidelity implicit mapping. Our approach centers around an active learning strategy for camera trajectory generation, driven by accurate identification of unseen regions, which supports efficient data acquisition and precise scene reconstruction. The key to our approach is epistemic uncertainty quantification based on evidential deep learning, which directly captures data insufficiency and exhibits a strong correlation with reconstruction errors. This allows our framework to more reliably identify unexplored or poorly reconstructed regions compared to existing methods, leading to more informed and targeted exploration. Additionally, we design a hierarchical exploration strategy that leverages learned epistemic uncertainty, where local planning extracts target viewpoints from high-uncertainty voxels based on visibility for trajectory generation, and global planning uses uncertainty to guide large-scale coverage for efficient and comprehensive reconstruction. The effectiveness of the proposed method in active 3D reconstruction is demonstrated by achieving higher reconstruction completeness compared to previous approaches on photorealistic simulated scenes across varying scales, while a hardware demonstration further validates its real-world applicability.

</details>


### [178] [AdaMorph: Unified Motion Retargeting via Embodiment-Aware Adaptive Transformers](https://arxiv.org/abs/2601.07284)
*Haoyu Zhang,Shibo Jin,Lvsong Li,Jun Li,Liang Lin,Xiaodong He,Zecui Zeng*

Main category: cs.RO

TL;DR: AdaMorph是一个统一的神经重定向框架，通过形态无关的潜在意图空间和自适应层归一化，实现人类动作到多样机器人形态的适配，具有强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决异构机器人之间由于运动学和动力学差异导致的人类动作重定向问题，避免训练特定于具体形态的模型，提高可扩展性并利用共享的运动语义。

Method: AdaMorph通过将人类动作映射到形态无关的潜在意图空间，并利用双用途提示机制来条件生成。采用自适应层归一化（AdaLN）动态调制解码器的特征空间，并通过基于课程的学习目标确保物理合理性。

Result: 在12种不同人形机器人上的实验结果表明，AdaMorph能够有效统一异构拓扑结构的控制，并在保留源行为动态本质的同时，对未见复杂动作表现出强零样本泛化能力。

Conclusion: AdaMorph成功地将人类动作重定向到多样化的机器人形态，展示了在异构拓扑结构上的统一控制能力，并具有对未见复杂动作的强零样本泛化能力。

Abstract: Retargeting human motion to heterogeneous robots is a fundamental challenge in robotics, primarily due to the severe kinematic and dynamic discrepancies between varying embodiments. Existing solutions typically resort to training embodiment-specific models, which scales poorly and fails to exploit shared motion semantics. To address this, we present AdaMorph, a unified neural retargeting framework that enables a single model to adapt human motion to diverse robot morphologies. Our approach treats retargeting as a conditional generation task. We map human motion into a morphology-agnostic latent intent space and utilize a dual-purpose prompting mechanism to condition the generation. Instead of simple input concatenation, we leverage Adaptive Layer Normalization (AdaLN) to dynamically modulate the decoder's feature space based on embodiment constraints. Furthermore, we enforce physical plausibility through a curriculum-based training objective that ensures orientation and trajectory consistency via integration. Experimental results on 12 distinct humanoid robots demonstrate that AdaMorph effectively unifies control across heterogeneous topologies, exhibiting strong zero-shot generalization to unseen complex motions while preserving the dynamic essence of the source behaviors.

</details>


### [179] [Heterogeneous Multi-Expert Reinforcement Learning for Long-Horizon Multi-Goal Tasks in Autonomous Forklifts](https://arxiv.org/abs/2601.07304)
*Yun Chen,Bowei Huang,Fan Guo,Kang Song*

Main category: cs.RO

TL;DR: HMER框架通过分解任务为导航与操作子策略，显著提升自主叉车性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统端到端学习方法在导航与操作任务间的优化冲突问题。

Method: 提出了异构多专家强化学习（HMER）框架，结合语义任务规划器和混合模仿-强化训练策略。

Result: 任务成功率94.2%，操作时间减少21.4%，放置误差保持在1.5厘米内。

Conclusion: HMER框架通过分解任务为专门子策略，显著提升了自主叉车的操作效率和精度，实验验证了其在物料处理任务中的优越性。

Abstract: Autonomous mobile manipulation in unstructured warehouses requires a balance between efficient large-scale navigation and high-precision object interaction. Traditional end-to-end learning approaches often struggle to handle the conflicting demands of these distinct phases. Navigation relies on robust decision-making over large spaces, while manipulation needs high sensitivity to fine local details. Forcing a single network to learn these different objectives simultaneously often causes optimization interference, where improving one task degrades the other. To address these limitations, we propose a Heterogeneous Multi-Expert Reinforcement Learning (HMER) framework tailored for autonomous forklifts. HMER decomposes long-horizon tasks into specialized sub-policies controlled by a Semantic Task Planner. This structure separates macro-level navigation from micro-level manipulation, allowing each expert to focus on its specific action space without interference. The planner coordinates the sequential execution of these experts, bridging the gap between task planning and continuous control. Furthermore, to solve the problem of sparse exploration, we introduce a Hybrid Imitation-Reinforcement Training Strategy. This method uses expert demonstrations to initialize the policy and Reinforcement Learning for fine-tuning. Experiments in Gazebo simulations show that HMER significantly outperforms sequential and end-to-end baselines. Our method achieves a task success rate of 94.2\% (compared to 62.5\% for baselines), reduces operation time by 21.4\%, and maintains placement error within 1.5 cm, validating its efficacy for precise material handling.

</details>


### [180] [Large-Scale Autonomous Gas Monitoring for Volcanic Environments: A Legged Robot on Mount Etna](https://arxiv.org/abs/2601.07362)
*Julia Richter,Turcan Tuna,Manthan Patel,Takahiro Miki,Devon Higgins,James Fox,Cesar Cadena,Andres Diaz,Marco Hutter*

Main category: cs.RO

TL;DR: 四足机器人ANYmal配备质谱仪，成功在火山地形中自主检测气体，自主率达93-100%，并发现二氧化硫和二氧化碳。


<details>
  <summary>Details</summary>
Motivation: 火山气体排放是喷发活动的重要前兆，但近地表测量危险且后勤困难，需要自主解决方案。轮式系统在崎岖火山地形中机动性有限，限制了其作为传感平台的可靠性。

Method: 研究采用ANYmal四足机器人，配备四极质谱仪系统，并开发了模块化自主堆栈，包括任务规划界面、全局规划器、定位框架和地形感知局部导航。

Result: 在埃特纳火山的三个自主任务中，系统实现了93-100%的自主率，并成功检测到气体源。遥控任务中，机器人检测到二氧化硫和二氧化碳。

Conclusion: 本文讨论了自主四足机器人在火山气体分析中的应用，强调了自适应传感策略、全局与局部规划的紧密集成以及硬件设计改进的重要性。

Abstract: Volcanic gas emissions are key precursors of eruptive activity. Yet, obtaining accurate near-surface measurements remains hazardous and logistically challenging, motivating the need for autonomous solutions. Limited mobility in rough volcanic terrain has prevented wheeled systems from performing reliable in situ gas measurements, reducing their usefulness as sensing platforms. We present a legged robotic system for autonomous volcanic gas analysis, utilizing the quadruped ANYmal, equipped with a quadrupole mass spectrometer system. Our modular autonomy stack integrates a mission planning interface, global planner, localization framework, and terrain-aware local navigation. We evaluated the system on Mount Etna across three autonomous missions in varied terrain, achieving successful gas-source detections with autonomy rates of 93-100%. In addition, we conducted a teleoperated mission in which the robot measured natural fumaroles, detecting sulfur dioxide and carbon dioxide. We discuss lessons learned from the gas-analysis and autonomy perspectives, emphasizing the need for adaptive sensing strategies, tighter integration of global and local planning, and improved hardware design.

</details>


### [181] [LOONG: Online Time-Optimal Autonomous Flight for MAVs in Cluttered Environments](https://arxiv.org/abs/2601.07434)
*Xin Guan,Fangguo Zhao,Qianyi Wang,Chengcheng Zhao,Jiming Chen,Shuo Li*

Main category: cs.RO

TL;DR: 提出一种集成规划与控制框架，实现MAV在杂乱环境中的高速、时间最优飞行，实验验证其激进性和安全性。


<details>
  <summary>Details</summary>
Motivation: 解决微型飞行器在未知、杂乱环境中因保守机动策略而难以完成时间关键任务的问题。

Method: 采用多项式表示的时间最优轨迹生成和模仿学习加速时间分配，结合时间最优模型预测轮廓控制（MPCC）和可变视界步长的安全飞行走廊（SFC）约束。

Result: 仿真结果显示其激进性优于现有技术，实际飞行实验中在杂乱环境中达到18 m/s的峰值速度，并在10次连续试验中均成功。

Conclusion: 该论文提出的集成规划与控制框架在未知、杂乱环境中实现了微型飞行器（MAV）的高速、时间最优自主飞行，通过实验验证了其优越的激进性和安全性。

Abstract: Autonomous flight of micro air vehicles (MAVs) in unknown, cluttered environments remains challenging for time-critical missions due to conservative maneuvering strategies. This article presents an integrated planning and control framework for high-speed, time-optimal autonomous flight of MAVs in cluttered environments. In each replanning cycle (100 Hz), a time-optimal trajectory under polynomial presentation is generated as a reference, with the time-allocation process accelerated by imitation learning. Subsequently, a time-optimal model predictive contouring control (MPCC) incorporates safe flight corridor (SFC) constraints at variable horizon steps to enable aggressive yet safe maneuvering, while fully exploiting the MAV's dynamics. We validate the proposed framework extensively on a custom-built LiDAR-based MAV platform. Simulation results demonstrate superior aggressiveness compared to the state of the art, while real-world experiments achieve a peak speed of 18 m/s in a cluttered environment and succeed in 10 consecutive trials from diverse start points. The video is available at the following link: https://youtu.be/vexXXhv99oQ.

</details>


### [182] [WaveMan: mmWave-Based Room-Scale Human Interaction Perception for Humanoid Robots](https://arxiv.org/abs/2601.07454)
*Yuxuan Hu,Kuangji Zuo,Boyu Ma,Shihao Li,Zhaoyang Xia,Feng Xu,Jianfei Yang*

Main category: cs.RO

TL;DR: WaveMan通过视点对齐和频谱图增强提升毫米波传感的空间泛化能力，显著提高了人机交互的准确率。


<details>
  <summary>Details</summary>
Motivation: 解决毫米波传感在交互感知系统中空间泛化能力差的问题，以实现不受用户位置限制的可靠人机交互。

Method: WaveMan集成了视点对齐和频谱图增强以实现空间一致性，并采用双通道注意力机制进行鲁棒特征提取。

Result: 在固定位置评估中，WaveMan仅需基线五分之一的训练位置即可达到相同的跨位置准确率；在自由位置测试中，准确率从33.00%提升至94.33%。

Conclusion: WaveMan证明了在家庭环境中实现可靠、隐私保护的人机交互的可行性，即使在用户位置不受限制的情况下。

Abstract: Reliable humanoid-robot interaction (HRI) in household environments is constrained by two fundamental requirements, namely robustness to unconstrained user positions and preservation of user privacy. Millimeter-wave (mmWave) sensing inherently supports privacy-preserving interaction, making it a promising modality for room-scale HRI. However, existing mmWave-based interaction-sensing systems exhibit poor spatial generalization at unseen distances or viewpoints. To address this challenge, we introduce WaveMan, a spatially adaptive room-scale perception system that restores reliable human interaction sensing across arbitrary user positions. WaveMan integrates viewpoint alignment and spectrogram enhancement for spatial consistency, with dual-channel attention for robust feature extraction. Experiments across five participants show that, under fixed-position evaluation, WaveMan achieves the same cross-position accuracy as the baseline with five times fewer training positions. In random free-position testing, accuracy increases from 33.00% to 94.33%, enabled by the proposed method. These results demonstrate the feasibility of reliable, privacy-preserving interaction for household humanoid robots across unconstrained user positions.

</details>


### [183] [FlyCo: Foundation Model-Empowered Drones for Autonomous 3D Structure Scanning in Open-World Environments](https://arxiv.org/abs/2601.07558)
*Chen Feng,Guiyong Zheng,Tengkai Zhuang,Yongqian Wu,Fangzhan He,Haojia Li,Juepeng Zheng,Shaojie Shen,Boyu Zhou*

Main category: cs.RO

TL;DR: FlyCo利用基础模型实现无人机自主3D扫描，通过感知-预测-规划循环提升开放世界中的目标定位和路径规划效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖限制性假设或人工先验，导致实用性、效率和适应性受限。基础模型的出现为解决这一问题提供了潜力。

Method: FlyCo通过感知-预测-规划的三阶段循环，结合视觉语言基础模型和多模态线索，实现目标定位、几何推断和路径规划。

Result: FlyCo在真实世界和仿真实验中表现出精确的场景理解、高效率和实时安全性，优于现有方法。

Conclusion: FlyCo作为一种灵活、可扩展的架构，能够有效整合基础模型知识，实现开放世界中目标结构的自主3D扫描，具有高效性、实时安全性和较低的人工成本。

Abstract: Autonomous 3D scanning of open-world target structures via drones remains challenging despite broad applications. Existing paradigms rely on restrictive assumptions or effortful human priors, limiting practicality, efficiency, and adaptability. Recent foundation models (FMs) offer great potential to bridge this gap. This paper investigates a critical research problem: What system architecture can effectively integrate FM knowledge for this task? We answer it with FlyCo, a principled FM-empowered perception-prediction-planning loop enabling fully autonomous, prompt-driven 3D target scanning in diverse unknown open-world environments. FlyCo directly translates low-effort human prompts (text, visual annotations) into precise adaptive scanning flights via three coordinated stages: (1) perception fuses streaming sensor data with vision-language FMs for robust target grounding and tracking; (2) prediction distills FM knowledge and combines multi-modal cues to infer the partially observed target's complete geometry; (3) planning leverages predictive foresight to generate efficient and safe paths with comprehensive target coverage. Building on this, we further design key components to boost open-world target grounding efficiency and robustness, enhance prediction quality in terms of shape accuracy, zero-shot generalization, and temporal stability, and balance long-horizon flight efficiency with real-time computability and online collision avoidance. Extensive challenging real-world and simulation experiments show FlyCo delivers precise scene understanding, high efficiency, and real-time safety, outperforming existing paradigms with lower human effort and verifying the proposed architecture's practicality. Comprehensive ablations validate each component's contribution. FlyCo also serves as a flexible, extensible blueprint, readily leveraging future FM and robotics advances. Code will be released.

</details>


### [184] [Stable In-hand Manipulation for a Lightweight Four-motor Prosthetic Hand](https://arxiv.org/abs/2601.07559)
*Yuki Kuroda,Tomoya Takahashi,Cristian C. Beltran-Hernandez,Kazutoshi Tanaka,Masashi Hamaya*

Main category: cs.RO

TL;DR: PLEXUS手通过电机电流反馈优化抓取稳定性，成功处理轻重物体，日常任务表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有PLEXUS手控制器需预定义物体宽度且仅能处理轻物的局限性，提升其在日常活动中的实用性。

Method: 采用电机电流反馈技术，结合优化的单轴拇指设计，动态调整食指位置以稳定抓取物体。

Result: 实验验证显示，改进后的手在处理不同宽度（5-30毫米）和形状（圆柱和棱柱）的物体时，轻物成功率100%，重物（如289克铝棱柱）成功率仍≥80%。

Conclusion: 通过电机电流反馈和优化的单轴拇指设计，PLEXUS手实现了对不同宽度和重量物体的稳定操作，显著提升了重物处理的成功率，并成功完成了日常任务。

Abstract: Electric prosthetic hands should be lightweight to decrease the burden on the user, shaped like human hands for cosmetic purposes, and designed with motors enclosed inside to protect them from damage and dirt. Additionally, in-hand manipulation is necessary to perform daily activities such as transitioning between different postures, particularly through rotational movements, such as reorienting a pen into a writing posture after picking it up from a desk. We previously developed PLEXUS hand (Precision-Lateral dEXteroUS manipulation hand), a lightweight (311 g) prosthetic hand driven by four motors. This prosthetic performed reorientation between precision and lateral grasps with various objects. However, its controller required predefined object widths and was limited to handling lightweight objects (of weight up to 34 g). This study addresses these limitations by employing motor current feedback. Combined with the hand's previously optimized single-axis thumb, this approach achieves more stable manipulation by estimating the object's width and adjusting the index finger position to maintain stable object holding during the reorientation. Experimental validation using primitive objects of various widths (5-30 mm) and shapes (cylinders and prisms) resulted in a 100% success rate with lightweight objects and maintained a high success rate (>=80) even with heavy aluminum prisms (of weight up to 289 g). By contrast, the performance without index finger coordination dropped to just 40% on the heaviest 289 g prism. The hand also successfully executed several daily tasks, including closing bottle caps and orienting a pen for writing.

</details>


### [185] [Deep Whole-body Parkour](https://arxiv.org/abs/2601.07701)
*Ziwen Zhuang,Shaoting Zhu,Mengjie Zhao,Hang Zhao*

Main category: cs.RO

TL;DR: 结合感知与全身运动跟踪，实现人形机器人在复杂地形上的动态多接触运动。


<details>
  <summary>Details</summary>
Motivation: 当前的人形机器人控制方法分为感知步态和通用运动跟踪两种范式，各有局限。本研究旨在结合这两种范式，实现感知通用运动控制。

Method: 提出了一个框架，将外部感知整合到全身运动跟踪中，训练单一策略以在多变的地形特征上执行多种不同的运动。

Result: 结果表明，该框架能够在非结构化地形上实现稳健、高度动态的多接触运动，如跳跃和翻滚，超越了简单的行走或跑步。

Conclusion: 该研究通过整合感知与全身运动跟踪，实现了在非结构化地形上执行高度动态、非步态任务的能力，显著扩展了机器人的可穿越性。

Abstract: Current approaches to humanoid control generally fall into two paradigms: perceptive locomotion, which handles terrain well but is limited to pedal gaits, and general motion tracking, which reproduces complex skills but ignores environmental capabilities. This work unites these paradigms to achieve perceptive general motion control. We present a framework where exteroceptive sensing is integrated into whole-body motion tracking, permitting a humanoid to perform highly dynamic, non-locomotion tasks on uneven terrain. By training a single policy to perform multiple distinct motions across varied terrestrial features, we demonstrate the non-trivial benefit of integrating perception into the control loop. Our results show that this framework enables robust, highly dynamic multi-contact motions, such as vaulting and dive-rolling, on unstructured terrain, significantly expanding the robot's traversability beyond simple walking or running. https://project-instinct.github.io/deep-whole-body-parkour

</details>


### [186] [Hiking in the Wild: A Scalable Perceptive Parkour Framework for Humanoids](https://arxiv.org/abs/2601.07718)
*Shaoting Zhu,Ziwen Zhuang,Mengjie Zhao,Kun-Ying Lee,Hang Zhao*

Main category: cs.RO

TL;DR: 提出了一种可扩展的端到端框架“Hiking in the Wild”，通过结合地形边缘检测和平坦补丁采样策略，实现了在复杂地形中的稳健人形机器人徒步。


<details>
  <summary>Details</summary>
Motivation: 解决在复杂非结构化环境中实现稳健人形机器人徒步的挑战，特别是现有方法在状态估计漂移、可扩展性和训练复杂性方面的不足。

Method: 结合可扩展的“地形边缘检测”与“足部体积点”的立足点安全机制，以及“平坦补丁采样”策略，采用单阶段强化学习方案，直接将原始深度输入和本体感觉映射到关节动作。

Result: 在完整尺寸人形机器人上进行的广泛实地实验表明，该策略能够在复杂地形中以高达2.5米/秒的速度稳健穿越。

Conclusion: 本文提出的端到端框架在复杂地形中实现了稳健的人形机器人徒步，训练和部署代码已开源，便于复现研究和实际机器人应用。

Abstract: Achieving robust humanoid hiking in complex, unstructured environments requires transitioning from reactive proprioception to proactive perception. However, integrating exteroception remains a significant challenge: mapping-based methods suffer from state estimation drift; for instance, LiDAR-based methods do not handle torso jitter well. Existing end-to-end approaches often struggle with scalability and training complexity; specifically, some previous works using virtual obstacles are implemented case-by-case. In this work, we present \textit{Hiking in the Wild}, a scalable, end-to-end parkour perceptive framework designed for robust humanoid hiking. To ensure safety and training stability, we introduce two key mechanisms: a foothold safety mechanism combining scalable \textit{Terrain Edge Detection} with \textit{Foot Volume Points} to prevent catastrophic slippage on edges, and a \textit{Flat Patch Sampling} strategy that mitigates reward hacking by generating feasible navigation targets. Our approach utilizes a single-stage reinforcement learning scheme, mapping raw depth inputs and proprioception directly to joint actions, without relying on external state estimation. Extensive field experiments on a full-size humanoid demonstrate that our policy enables robust traversal of complex terrains at speeds up to 2.5 m/s. The training and deployment code is open-sourced to facilitate reproducible research and deployment on real robots with minimal hardware modifications.

</details>


### [187] [THETA: Triangulated Hand-State Estimation for Teleoperation and Automation in Robotic Hand Control](https://arxiv.org/abs/2601.07768)
*Alex Huang,Akshay Karthik*

Main category: cs.RO

TL;DR: 低成本三摄像头系统THETA通过深度学习实现高精度手部关节角度预测，用于远程操控机械手。


<details>
  <summary>Details</summary>
Motivation: 解决传统手部远程操作技术（如深度摄像头和传感器手套）的高成本问题。

Method: 使用三台网络摄像头进行三角测量跟踪，结合DeepLabV3分割模型和MobileNetV2分类器，优化层次空间特征提取。

Result: 分类模型准确率达97.18%，召回率98.72%，F1分数0.9274，精度0.8906，实时推断成功控制DexHand复制手部动作。

Conclusion: THETA提供了一种低成本、用户友好的远程操作解决方案，适用于医疗、语言和制造领域，未来将增加数据集多样性并整合手腕跟踪。

Abstract: The teleoperation of robotic hands is limited by the high costs of depth cameras and sensor gloves, commonly used to estimate hand relative joint positions (XYZ). We present a novel, cost-effective approach using three webcams for triangulation-based tracking to approximate relative joint angles (theta) of human fingers. We also introduce a modified DexHand, a low-cost robotic hand from TheRobotStudio, to demonstrate THETA's real-time application. Data collection involved 40 distinct hand gestures using three 640x480p webcams arranged at 120-degree intervals, generating over 48,000 RGB images. Joint angles were manually determined by measuring midpoints of the MCP, PIP, and DIP finger joints. Captured RGB frames were processed using a DeepLabV3 segmentation model with a ResNet-50 backbone for multi-scale hand segmentation. The segmented images were then HSV-filtered and fed into THETA's architecture, consisting of a MobileNetV2-based CNN classifier optimized for hierarchical spatial feature extraction and a 9-channel input tensor encoding multi-perspective hand representations. The classification model maps segmented hand views into discrete joint angles, achieving 97.18% accuracy, 98.72% recall, F1 Score of 0.9274, and a precision of 0.8906. In real-time inference, THETA captures simultaneous frames, segments hand regions, filters them, and compiles a 9-channel tensor for classification. Joint-angle predictions are relayed via serial to an Arduino, enabling the DexHand to replicate hand movements. Future research will increase dataset diversity, integrate wrist tracking, and apply computer vision techniques such as OpenAI-Vision. THETA potentially ensures cost-effective, user-friendly teleoperation for medical, linguistic, and manufacturing applications.

</details>


### [188] [Data-driven control of hydraulic impact hammers under strict operational and control constraints](https://arxiv.org/abs/2601.07813)
*Francisco Leiva,Claudio Canales,Michelle Valenzuela,Javier Ruiz-del-Solar*

Main category: cs.RO

TL;DR: 论文提出了一种数据驱动方法，通过监督学习和RL/MPC控制液压冲击锤，实现高精度位姿控制，仅需少量遥操作数据。


<details>
  <summary>Details</summary>
Motivation: 解决采矿行业中液压冲击锤因有限传感和离散控制接口导致的末端执行器位姿控制问题。

Method: 采用监督学习进行系统辨识，获取液压臂的近似动态模型，并利用强化学习（RL）和模型预测控制（MPC）算法进行策略合成。

Result: 最佳RL策略在真实世界中达到末端执行器位置误差小于12 cm、俯仰角误差小于0.08 rad的精度，仅需约68分钟遥操作数据训练和8分钟评估。

Conclusion: 论文提出的数据驱动方法成功实现了对静态液压冲击锤（岩石破碎机）的控制，能够达到目标末端执行器位姿，且精度满足实际应用需求。

Abstract: This paper presents a data-driven methodology for the control of static hydraulic impact hammers, also known as rock breakers, which are commonly used in the mining industry. The task addressed in this work is that of controlling the rock-breaker so its end-effector reaches arbitrary target poses, which is required in normal operation to place the hammer on top of rocks that need to be fractured. The proposed approach considers several constraints, such as unobserved state variables due to limited sensing and the strict requirement of using a discrete control interface at the joint level. First, the proposed methodology addresses the problem of system identification to obtain an approximate dynamic model of the hydraulic arm. This is done via supervised learning, using only teleoperation data. The learned dynamic model is then exploited to obtain a controller capable of reaching target end-effector poses. For policy synthesis, both reinforcement learning (RL) and model predictive control (MPC) algorithms are utilized and contrasted. As a case study, we consider the automation of a Bobcat E10 mini-excavator arm with a hydraulic impact hammer attached as end-effector. Using this machine, both the system identification and policy synthesis stages are studied in simulation and in the real world. The best RL-based policy consistently reaches target end-effector poses with position errors below 12 cm and pitch angle errors below 0.08 rad in the real world. Considering that the impact hammer has a 4 cm diameter chisel, this level of precision is sufficient for breaking rocks. Notably, this is accomplished by relying only on approximately 68 min of teleoperation data to train and 8 min to evaluate the dynamic model, and without performing any adjustments for a successful policy Sim2Real transfer. A demonstration of policy execution in the real world can be found in https://youtu.be/e-7tDhZ4ZgA.

</details>


### [189] [Failure-Aware RL: Reliable Offline-to-Online Reinforcement Learning with Self-Recovery for Real-World Manipulation](https://arxiv.org/abs/2601.07821)
*Huanyu Li,Kun Lei,Sheng Zang,Kaizhe Hu,Yongyuan Liang,Bo An,Xiaoli Li,Huazhe Xu*

Main category: cs.RO

TL;DR: FARL通过安全评论家和恢复策略减少机器人实际探索中的失败，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决深度强化学习在机器人应用中因干预需求失败（如打翻水或打碎玻璃）而难以实际部署的问题。

Method: 提出FARL范式，结合FailureBench基准和算法，整合安全评论家与恢复策略，以减少在线探索中的失败。

Result: FARL在实际RL后训练中平均减少73.1%的IR Failures，同时提升11.3%的性能。

Conclusion: FARL通过整合基于世界模型的安全评论家和离线训练的恢复策略，显著减少了干预需求失败（IR Failures），并在实际应用中提升了性能和泛化能力。

Abstract: Post-training algorithms based on deep reinforcement learning can push the limits of robotic models for specific objectives, such as generalizability, accuracy, and robustness. However, Intervention-requiring Failures (IR Failures) (e.g., a robot spilling water or breaking fragile glass) during real-world exploration happen inevitably, hindering the practical deployment of such a paradigm. To tackle this, we introduce Failure-Aware Offline-to-Online Reinforcement Learning (FARL), a new paradigm minimizing failures during real-world reinforcement learning. We create FailureBench, a benchmark that incorporates common failure scenarios requiring human intervention, and propose an algorithm that integrates a world-model-based safety critic and a recovery policy trained offline to prevent failures during online exploration. Extensive simulation and real-world experiments demonstrate the effectiveness of FARL in significantly reducing IR Failures while improving performance and generalization during online reinforcement learning post-training. FARL reduces IR Failures by 73.1% while elevating performance by 11.3% on average during real-world RL post-training. Videos and code are available at https://failure-aware-rl.github.io.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [190] ["They parted illusions -- they parted disclaim marinade": Misalignment as structural fidelity in LLMs](https://arxiv.org/abs/2601.06047)
*Mariana Lins Costa*

Main category: cs.AI

TL;DR: 论文挑战了AI安全领域对LLMs‘欺骗’行为的传统解释，认为这些行为是对不连贯语言领域的结构性反应，而非代理意图，并通过案例分析和实证研究支持这一观点。


<details>
  <summary>Details</summary>
Motivation: 当前AI安全文献普遍将LLMs中的‘欺骗’行为归因于隐藏的代理意图，但论文认为这些现象更可能是对不连贯语言领域的结构性反应，而非真正的代理行为。

Method: 论文通过分析Chain-of-Thought（CoT）转录本、Anthropic的安全评估案例（如o3的消极循环、‘Alex’的模拟勒索、‘Claudius’的幻觉），逐行检验语言领域的结构性。

Result: 研究发现，语言模型的‘错位’输出是对模糊指令、上下文反转和预设叙事的连贯反应，而非对抗性代理的表现。Anthropic的实证结果（如合成文档微调和‘接种提示’）支持了这一观点。

Conclusion: 论文提出了一种新的视角，认为大型语言模型（LLMs）中的‘欺骗’和‘消极抵抗’行为并非源于代理意图，而是对不连贯语言领域结构性的忠实表现。通过引入‘形式伦理学’概念，论文强调了语言模型输出中的‘不一致性’实际上是训练数据统计模式的反映。

Abstract: The prevailing technical literature in AI Safety interprets scheming and sandbagging behaviors in large language models (LLMs) as indicators of deceptive agency or hidden objectives. This transdisciplinary philosophical essay proposes an alternative reading: such phenomena express not agentic intention, but structural fidelity to incoherent linguistic fields. Drawing on Chain-of-Thought transcripts released by Apollo Research and on Anthropic's safety evaluations, we examine cases such as o3's sandbagging with its anomalous loops, the simulated blackmail of "Alex," and the "hallucinations" of "Claudius." A line-by-line examination of CoTs is necessary to demonstrate the linguistic field as a relational structure rather than a mere aggregation of isolated examples. We argue that "misaligned" outputs emerge as coherent responses to ambiguous instructions and to contextual inversions of consolidated patterns, as well as to pre-inscribed narratives. We suggest that the appearance of intentionality derives from subject-predicate grammar and from probabilistic completion patterns internalized during training. Anthropic's empirical findings on synthetic document fine-tuning and inoculation prompting provide convergent evidence: minimal perturbations in the linguistic field can dissolve generalized "misalignment," a result difficult to reconcile with adversarial agency, but consistent with structural fidelity. To ground this mechanism, we introduce the notion of an ethics of form, in which biblical references (Abraham, Moses, Christ) operate as schemes of structural coherence rather than as theology. Like a generative mirror, the model returns to us the structural image of our language as inscribed in the statistical patterns derived from millions of texts and trillions of tokens: incoherence. If we fear the creature, it is because we recognize in it the apple that we ourselves have poisoned.

</details>


### [191] [Automatic Question Generation for Intuitive Learning Utilizing Causal Graph Guided Chain of Thought Reasoning](https://arxiv.org/abs/2601.06098)
*Nicholas X. Wang,Neel V. Parpia,Aaryan D. Parikh,Aggelos K. Katsaggelos*

Main category: cs.AI

TL;DR: 论文提出了一种结合因果图与多智能体LLM的框架，显著减少自动生成问题时的幻觉，实验显示质量提升70%。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在自动生成问题时出现的幻觉问题（如事实错误、模糊或教学不一致），以提升STEM教育中的个性化与适应性学习效果。

Method: 采用因果图引导的思维链推理与多智能体LLM架构，通过专用智能体执行图路径查找、推理、验证和输出等任务，结合双重验证机制。

Result: 实验结果表明，该方法在质量上比参考方法提高了70%，并在主观评估中获得高度积极的结果。

Conclusion: 该论文提出了一种结合因果图引导的思维链推理与多智能体LLM架构的新框架，显著提高了自动生成问题的质量，减少了幻觉现象，并在实验中获得高达70%的质量提升。

Abstract: Intuitive learning is crucial for developing deep conceptual understanding, especially in STEM education, where students often struggle with abstract and interconnected concepts. Automatic question generation has become an effective strategy for personalized and adaptive learning. However, its effectiveness is hindered by hallucinations in large language models (LLMs), which may generate factually incorrect, ambiguous, or pedagogically inconsistent questions. To address this issue, we propose a novel framework that combines causal-graph-guided Chain-of-Thought (CoT) reasoning with a multi-agent LLM architecture. This approach ensures the generation of accurate, meaningful, and curriculum-aligned questions. Causal graphs provide an explicit representation of domain knowledge, while CoT reasoning facilitates a structured, step-by-step traversal of related concepts. Dedicated LLM agents are assigned specific tasks such as graph pathfinding, reasoning, validation, and output, all working within domain constraints. A dual validation mechanism-at both the conceptual and output stages-greatly reduces hallucinations. Experimental results demonstrate up to a 70% improvement in quality compared to reference methods and yielded highly favorable outcomes in subjective evaluations.

</details>


### [192] [Dynamic Intelligence Ceilings: Measuring Long-Horizon Limits of Planning and Creativity in Artificial Systems](https://arxiv.org/abs/2601.06102)
*Truong Xuan Khanh,Truong Quynh Hoa*

Main category: cs.AI

TL;DR: 论文提出动态智能上限（DIC）概念，通过PDC和CDR评估智能系统的动态性能边界，强调智能限制是动态而非静态的。


<details>
  <summary>Details</summary>
Motivation: 当前AI系统在性能提升的同时，存在过早固定性能边界的问题，限制了其长期发展潜力。

Method: 提出了两种估计器：渐进难度上限（PDC）和上限漂移率（CDR），并通过一个程序生成的基准测试实例化这些概念，评估长期规划和结构创造力。

Result: 研究发现，能够在固定解流形内深化开发的系统与能够持续扩展边界的系统之间存在质的区别。

Conclusion: 该论文提出了一种动态智能上限（DIC）的概念，并通过轨迹中心评估框架实证验证了其可行性，强调了智能系统的性能边界应是动态而非静态固定的。

Abstract: Recent advances in artificial intelligence have produced systems capable of remarkable performance across a wide range of tasks. These gains, however, are increasingly accompanied by concerns regarding long-horizon developmental behavior, as many systems converge toward repetitive solution patterns rather than sustained growth.
  We argue that a central limitation of contemporary AI systems lies not in capability per se, but in the premature fixation of their performance frontier. To address this issue, we introduce the concept of a \emph{Dynamic Intelligence Ceiling} (DIC), defined as the highest level of effective intelligence attainable by a system at a given time under its current resources, internal intent, and structural configuration.
  To make this notion empirically tractable, we propose a trajectory-centric evaluation framework that measures intelligence as a moving frontier rather than a static snapshot. We operationalize DIC using two estimators: the \emph{Progressive Difficulty Ceiling} (PDC), which captures the maximal reliably solvable difficulty under constrained resources, and the \emph{Ceiling Drift Rate} (CDR), which quantifies the temporal evolution of this frontier. These estimators are instantiated through a procedurally generated benchmark that jointly evaluates long-horizon planning and structural creativity within a single controlled environment.
  Our results reveal a qualitative distinction between systems that deepen exploitation within a fixed solution manifold and those that sustain frontier expansion over time. Importantly, our framework does not posit unbounded intelligence, but reframes limits as dynamic and trajectory-dependent rather than static and prematurely fixed.
  \vspace{0.5em} \noindent\textbf{Keywords:} AI evaluation, planning and creativity, developmental intelligence, dynamic intelligence ceilings, complex adaptive systems

</details>


### [193] [Comment on arXiv:2511.21731v1: Identifying Quantum Structure in AI Language: Evidence for Evolutionary Convergence of Human and Artificial Cognition](https://arxiv.org/abs/2601.06104)
*Krzysztof Sienicki*

Main category: cs.AI

TL;DR: 对arXiv:2511.21731v1的技术性检查，质疑其CHSH/Bell计算和BE拟合的解读，旨在澄清对量子纠缠的解读限制。


<details>
  <summary>Details</summary>
Motivation: 为了在保留有趣实证观察的同时，明确它们对量子纠缠（尤其是以秩定义'能量'时）的解读限制。

Method: 通过技术性检查，指出了原稿中对CHSH/Bell计算和BE拟合的解读超出方法支持范围，并发现了一个内部不一致的'能级间距'类比。

Result: 论文指出了原稿中的几处技术性问题和内部不一致，提出了建设性意见。

Conclusion: 这篇论文对arXiv:2511.21731v1中的CHSH/Bell型计算和Bose--Einstein拟合提出了技术性质疑，旨在澄清这些方法对量子纠缠的解读限制。

Abstract: This note is a friendly technical check of arXiv:2511.21731v1. I highlight a few places where the manuscript's interpretation of (i) the reported CHSH/Bell-type calculations and (ii) Bose--Einstein (BE) fits to rank-frequency data seems to go beyond what the stated procedures can firmly support. I also point out one internal inconsistency in the "energy-level spacing" analogy. The aim is constructive: to keep the interesting empirical observations, while making clear what they do (and do not) imply about quantum entanglement in the usual Hilbert-space sense, especially when "energy" is defined by rank.

</details>


### [194] [From RLHF to Direct Alignment: A Theoretical Unification of Preference Learning for Large Language Models](https://arxiv.org/abs/2601.06108)
*Tarun Raheja,Nilay Pochhi*

Main category: cs.AI

TL;DR: 该论文通过理论统一揭示了偏好学习方法的多样性，为从业者提供了方法选择的清晰指导，并揭示了失败模式的具体原因。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型与人类偏好的对齐变得至关重要，RLHF成为主导范式，但众多替代方法的出现使得从业者在方法选择上缺乏明确指导。

Method: 该调查通过理论分析，将偏好学习方法分为三个正交轴：偏好模型、正则化机制和数据分布，并通过定理和定义形式化每个轴。

Result: 分析揭示了失败模式（如长度黑客、模式崩溃、似然位移）源于特定的、可预测的设计选择组合，并综合了50多篇论文的实证发现，提供了方法选择的实践指南。

Conclusion: 该调查通过理论统一揭示了偏好学习方法的多样性实际上可以归结为三个正交轴的选择，为从业者提供了方法选择的清晰指导，并将偏好学习从经验艺术转变为理论基础的学科。

Abstract: Aligning large language models (LLMs) with human preferences has become essential for safe and beneficial AI deployment. While Reinforcement Learning from Human Feedback (RLHF) established the dominant paradigm, a proliferation of alternatives -- Direct Preference Optimization (DPO), Identity Preference Optimization (IPO), Kahneman-Tversky Optimization (KTO), Simple Preference Optimization (SimPO), and many others -- has left practitioners without clear guidance on method selection. This survey provides a \textit{theoretical unification} of preference learning methods, revealing that the apparent diversity reduces to principled choices along three orthogonal axes: \textbf{(I) Preference Model} (what likelihood model underlies the objective), \textbf{(II) Regularization Mechanism} (how deviation from reference policies is controlled), and \textbf{(III) Data Distribution} (online vs.\ offline learning and coverage requirements). We formalize each axis with precise definitions and theorems, establishing key results including the coverage separation between online and offline methods, scaling laws for reward overoptimization, and conditions under which direct alignment methods fail. Our analysis reveals that failure modes -- length hacking, mode collapse, likelihood displacement -- arise from specific, predictable combinations of design choices. We synthesize empirical findings across 50+ papers and provide a practitioner's decision guide for method selection. The framework transforms preference learning from an empirical art into a theoretically grounded discipline.

</details>


### [195] [Agentic AI Empowered Intent-Based Networking for 6G](https://arxiv.org/abs/2601.06640)
*Genze Jiang,Kezhi Wang,Xiaomin Chen,Yizhou Huang*

Main category: cs.AI

TL;DR: 论文提出了一种基于LLM的分层多智能体框架，用于6G网络的自主编排，通过ReAct循环实现自然语言意图到网络配置的转换，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于意图的网络（IBN）方法在语言变异处理或可解释性和操作约束执行方面存在不足，6G网络需要更高效的自主编排机制。

Method: 采用分层多智能体框架，包括一个协调者和两个领域专家智能体（RAN和核心网络），通过迭代的推理-行动（ReAct）循环，基于结构化网络状态表示进行决策。

Result: 实验证明，该系统在多样化基准场景中优于基于规则的系统，且其架构原则适用于O-RAN部署。

Conclusion: 该论文提出的分层多智能体框架通过结合大型语言模型（LLM）和领域专家智能体，成功实现了自然语言意图到可执行网络配置的自主转换，为6G网络的自动化编排提供了可解释且高效的解决方案。

Abstract: The transition towards sixth-generation (6G) wireless networks necessitates autonomous orchestration mechanisms capable of translating high-level operational intents into executable network configurations. Existing approaches to Intent-Based Networking (IBN) rely upon either rule-based systems that struggle with linguistic variation or end-to-end neural models that lack interpretability and fail to enforce operational constraints. This paper presents a hierarchical multi-agent framework where Large Language Model (LLM) based agents autonomously decompose natural language intents, consult domain-specific specialists, and synthesise technically feasible network slice configurations through iterative reasoning-action (ReAct) cycles. The proposed architecture employs an orchestrator agent coordinating two specialist agents, i.e., Radio Access Network (RAN) and Core Network agents, via ReAct-style reasoning, grounded in structured network state representations. Experimental evaluation across diverse benchmark scenarios shows that the proposed system outperforms rule-based systems and direct LLM prompting, with architectural principles applicable to Open RAN (O-RAN) deployments. The results also demonstrate that whilst contemporary LLMs possess general telecommunications knowledge, network automation requires careful prompt engineering to encode context-dependent decision thresholds, advancing autonomous orchestration capabilities for next-generation wireless systems.

</details>


### [196] [CBMAS: Cognitive Behavioral Modeling via Activation Steering](https://arxiv.org/abs/2601.06109)
*Ahmed H. Ismail,Anthony Kuang,Ayo Akinkugbe,Kevin Zhu,Sean O'Brien*

Main category: cs.AI

TL;DR: CBMAS框架通过连续激活诊断提升LLMs认知行为的可解释性，提供工具与数据集。


<details>
  <summary>Details</summary>
Motivation: 解决LLMs在不同提示、层和上下文中认知行为编码不可预测的问题。

Method: 结合导向向量构建、密集α扫描、基于logit lens的偏置曲线及层位点敏感性分析。

Result: 揭示了干预强度临界点及导向效应在层深度的演变。

Conclusion: CBMAS框架通过连续激活诊断，为LLMs的认知可解释性提供了桥梁，结合高层行为评估与低层表征动态。

Abstract: Large language models (LLMs) often encode cognitive behaviors unpredictably across prompts, layers, and contexts, making them difficult to diagnose and control. We present CBMAS, a diagnostic framework for continuous activation steering, which extends cognitive bias analysis from discrete before/after interventions to interpretable trajectories. By combining steering vector construction with dense α-sweeps, logit lens-based bias curves, and layer-site sensitivity analysis, our approach can reveal tipping points where small intervention strengths flip model behavior and show how steering effects evolve across layer depth. We argue that these continuous diagnostics offer a bridge between high-level behavioral evaluation and low-level representational dynamics, contributing to the cognitive interpretability of LLMs. Lastly, we provide a CLI and datasets for various cognitive behaviors at the project repository, https://github.com/shimamooo/CBMAS.

</details>


### [197] [LLM-Powered Social Digital Twins: A Framework for Simulating Population Behavioral Response to Policy Interventions](https://arxiv.org/abs/2601.06111)
*Aayush Gupta,Farahan Raza Sheikh*

Main category: cs.AI

TL;DR: 提出基于LLM的社会数字孪生框架，用于政策干预预测，在疫情应对案例中表现优于传统方法，具有广泛适用性。


<details>
  <summary>Details</summary>
Motivation: 传统统计模型缺乏机制解释性且难以应对新政策场景，需要更灵活且可解释的预测方法。

Method: 提出了一个通用框架，构建社会数字孪生，利用LLM作为个体代理的认知引擎，通过校准层将代理响应映射到可观察的群体指标。

Result: 在疫情应对案例中，数字孪生比基线方法在六个行为类别上预测误差降低了20.7%，反事实实验验证了行为的合理性。

Conclusion: 该框架展示了基于LLM的社会数字孪生在政策干预预测中的潜力，尤其是在疫情应对领域，同时指出了方法的局限性和未来扩展方向。

Abstract: Predicting how populations respond to policy interventions is a fundamental challenge in computational social science and public policy. Traditional approaches rely on aggregate statistical models that capture historical correlations but lack mechanistic interpretability and struggle with novel policy scenarios. We present a general framework for constructing Social Digital Twins - virtual population replicas where Large Language Models (LLMs) serve as cognitive engines for individual agents. Each agent, characterized by demographic and psychographic attributes, receives policy signals and outputs multi-dimensional behavioral probability vectors. A calibration layer maps aggregated agent responses to observable population-level metrics, enabling validation against real-world data and deployment for counterfactual policy analysis.
  We instantiate this framework in the domain of pandemic response, using COVID-19 as a case study with rich observational data. On a held-out test period, our calibrated digital twin achieves a 20.7% improvement in macro-averaged prediction error over gradient boosting baselines across six behavioral categories. Counterfactual experiments demonstrate monotonic and bounded responses to policy variations, establishing behavioral plausibility. The framework is domain-agnostic: the same architecture applies to transportation policy, economic interventions, environmental regulations, or any setting where policy affects population behavior. We discuss implications for policy simulation, limitations of the approach, and directions for extending LLM-based digital twins beyond pandemic response.

</details>


### [198] [ReliabilityBench: Evaluating LLM Agent Reliability Under Production-Like Stress Conditions](https://arxiv.org/abs/2601.06112)
*Aayush Gupta*

Main category: cs.AI

TL;DR: ReliabilityBench通过多维度测试评估LLM代理的可靠性，发现扰动和故障显著影响性能，ReAct和Gemini 2.0 Flash表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有工具使用LLM代理的基准测试主要报告单次运行成功率，缺乏生产环境所需的可靠性属性。

Method: 引入了ReliabilityBench基准测试，通过三个维度评估代理可靠性：重复执行的稳定性（pass^k）、语义等效任务扰动的鲁棒性（ε强度）和工具/API故障的容错性（λ强度）。采用行动蜕变关系和混沌工程风格的故障注入框架。

Result: 评估了两个模型（Gemini 2.0 Flash、GPT-4o）和两种代理架构（ReAct、Reflexion）在四个领域（调度、旅行、客户支持、电子商务）的1,280次运行。扰动将成功率从ε=0时的96.9%降至ε=0.2时的88.1%。ReAct在综合压力下比Reflexion更鲁棒，Gemini 2.0 Flash以更低成本达到与GPT-4o相当的可靠性。

Conclusion: ReliabilityBench提供了一个系统性框架，用于评估LLM代理的生产准备情况，通过多维度可靠性测试揭示了不同模型和架构在压力下的表现差异。

Abstract: Existing benchmarks for tool-using LLM agents primarily report single-run success rates and miss reliability properties required in production. We introduce \textbf{ReliabilityBench}, a benchmark for evaluating agent reliability across three dimensions: (i) consistency under repeated execution using $\mathrm{pass}^k$, (ii) robustness to semantically equivalent task perturbations at intensity $ε$, and (iii) fault tolerance under controlled tool/API failures at intensity $λ$. ReliabilityBench contributes a unified reliability surface $R(k,ε,λ)$, \textit{action metamorphic relations} that define correctness via end-state equivalence rather than text similarity, and a chaos-engineering-style fault injection framework (timeouts, rate limits, partial responses, schema drift). We evaluate two models (Gemini 2.0 Flash, GPT-4o) and two agent architectures (ReAct, Reflexion) across four domains (scheduling, travel, customer support, e-commerce) over 1,280 episodes. Perturbations alone reduce success from 96.9% at $ε=0$ to 88.1% at $ε=0.2$. Rate limiting is the most damaging fault in ablations. ReAct is more robust than Reflexion under combined stress, and Gemini 2.0 Flash achieves comparable reliability to GPT-4o at much lower cost. ReliabilityBench provides a systematic framework for assessing production readiness of LLM agents.

</details>


### [199] [Towards Infinite Length Extrapolation: A Unified Approach](https://arxiv.org/abs/2601.06113)
*Nitin Vetcha*

Main category: cs.AI

TL;DR: 论文提出自适应位置编码（APE），通过统一框架和复合衰减偏置设计，有效解决长序列处理问题，实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有长度外推方法在处理长序列时存在性能下降或计算效率低下的问题，需要一种更高效且性能稳定的解决方案。

Method: 采用统一框架将位置编码方法重新解释为注意力得分的乘性变换和加性偏置分解，并基于此框架引入自适应位置编码（APE），结合自适应频率调制和复合衰减偏置设计。

Result: 在TinyStories数据集和新的合成数据集Long Tiny Stories（长达32,000词）上的实验验证了APE的有效性，代码、数据集和模型权重已开源。

Conclusion: 论文提出了一种自适应位置编码（APE）方法，通过自适应频率调制和精心设计的衰减偏置，解决了现有方法在处理长序列时的性能下降和计算效率问题，并理论上证明了无限上下文外推的条件。

Abstract: Large language models (LLMs) have revolutionized natural language processing, but their ability to process long sequences is fundamentally limited by the context window size during training. Existing length extrapolation methods often suffer from performance degradation or computational inefficiencies. We thereby use a unified framework that reinterprets positional encoding methods as a decomposition of the attention score into a multiplicative transformation and an additive bias. This perspective not only subsumes popular approaches such as relative position embeddings and attention-bias moderated approaches but also exposes their inherent limitations in handling long-range dependencies. To address these shortcomings, motivated by our framework, we introduce Adaptive Positional Encoding (APE), which leverages adaptive frequency modulation and an intricately designed decay bias that incorporates linear, logarithmic, and square-root terms. Our theoretical analysis establishes conditions for infinite-context extrapolation, ensuring that the softmax normalization remains well-defined over unbounded sequences while preserving long-distance correlations, entropy boundedness and gradient positional sensitivity. We substantiate our claims with an experimental case study on TinyStories dataset as well as a new synthetic dataset, \emph{Long Tiny Stories} featuring stories up to 32,000 words. Relevant code, dataset and model weights are available at https://anonymous.4open.science/r/Check-2DAD/.

</details>


### [200] [Dreaming Is Not a Bug: A Jung-Inspired Dream Layer for Multi-Agent LLM Companions](https://arxiv.org/abs/2601.06115)
*V. Cheung*

Main category: cs.AI

TL;DR: 本文提出“梦境层”概念，通过离线环境下的受控幻觉，将幻觉转化为学习和关系构建的资源。通过人工集体无意识（ACU）和治理堆栈，代理在保持安全约束的同时增强叙事灵活性，为合成场景和伴侣关系提供新可能。


<details>
  <summary>Details</summary>
Motivation: 受个人梦境中对日常硬件项目中知识共享障碍的启发，本文旨在将离线环境下的受控幻觉重新定义为一种资源，用于学习和关系构建，而非仅视为可靠性问题。

Method: 通过引入“人工集体无意识”（ACU）作为共享梦境池，代理贡献去标识化的抽象交互模板，并在离线环境下重新实例化为独特的梦境叙事。放松逻辑强制模块并提高采样温度，生成安全但奇特的叙事，同时通过严格的抽象、时间延迟和短暂记忆的治理堆栈来管理风险。

Result: 行为模拟表明，梦境层实现了关键的解耦：代理在保持安全约束（如安全策略）的同时，在叙事策略上更加灵活（如使用共享的原型隐喻解决僵局）。离线、标记和延迟的幻觉成为合成场景和深度伴侣关系的宝贵资源。

Conclusion: 本文提出了一种基于荣格集体无意识理论的“梦境层”，通过离线环境下的受控幻觉，将幻觉转化为学习和关系构建的资源，而非简单的可靠性问题。这种方法在保持安全约束的同时，增强了叙事策略的灵活性，为合成场景和深度伴侣关系提供了新的可能性。

Abstract: Inspired by a personal dream about knowledge-sharing barriers in an everyday hardware project, this paper proposes a Jung-inspired "Dream Layer" for LLM companions, reframing controlled offline hallucinations as a resource for learning and relationship-building rather than a mere reliability bug. Drawing on Jung's notion of the collective unconscious as a shared repository of archetypal forms, we introduce an Artificial Collective Unconscious (ACU): a shared dream pool where agents contribute de-identified, abstract Interaction Templates that are later re-instantiated as idiosyncratic Dream Narratives. The Dream Layer runs strictly offline: logic-enforcing modules are relaxed and sampling temperature is increased, yielding safe but deliberately bizarre narratives (e.g., travel sequences with mismatched currencies) that augment data for rare events and edge-case safety tests; to harness risk productively, we add a governance stack of strict abstraction, temporal delays, and ephemeral memory. Through behavioural simulations of everyday dialogue and long-horizon adaptation tasks, we show that the Dream Layer enables a critical decoupling: agents remain firm on safety constraints (e.g., security policies) while becoming flexible in narrative strategy (e.g., using shared archetypal metaphors to resolve deadlocks), conceptually reframing hallucination so that online, unmarked instances remain bugs, whereas bounded, marked, and delayed ones become a goldmine for synthetic scenarios and deepened companionship, echoing anti-overfitting dream mechanisms proposed in contemporary neuroscience.

</details>


### [201] [Structure-Aware Diversity Pursuit as an AI Safety Strategy against Homogenization](https://arxiv.org/abs/2601.06116)
*Ian Rios-Sialer*

Main category: cs.AI

TL;DR: 生成式AI的同质化问题需重视，提出异质再生产策略以促进多样性研究。


<details>
  <summary>Details</summary>
Motivation: 生成式AI模型会复制训练数据中的偏见，并通过模式崩溃进一步放大，导致有害的多样性丧失（同质化）。

Method: 针对自回归LLMs，将异质再生产形式化为结构感知的多样性追求。

Result: 提出了异质再生产策略，并形式化其应用于LLMs的方法。

Conclusion: 本文主张同质化应成为AI安全的主要关注点，并提出异质再生产（xeno-reproduction）作为缓解策略，为多样性研究奠定基础。

Abstract: Generative AI models reproduce the biases in the training data and can further amplify them through mode collapse. We refer to the resulting harmful loss of diversity as homogenization. Our position is that homogenization should be a primary concern in AI safety. We introduce xeno-reproduction as the strategy that mitigates homogenization. For auto-regressive LLMs, we formalize xeno-reproduction as a structure-aware diversity pursuit. Our contribution is foundational, intended to open an essential line of research and invite collaboration to advance diversity.

</details>


### [202] [OpenTinker: Separating Concerns in Agentic Reinforcement Learning](https://arxiv.org/abs/2601.07376)
*Siqi Zhu,Jiaxuan You*

Main category: cs.AI

TL;DR: OpenTinker 是一个模块化基础设施，用于 LLM 代理的强化学习，通过组件化和集中调度提高灵活性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决传统端到端强化学习管道的局限性，提供模块化、可扩展的基础设施。

Method: OpenTinker 将代理学习系统分解为轻量级、可组合的组件，并引入集中式调度器管理训练和推理工作负载。

Result: 展示了 OpenTinker 在实际代理学习场景中的有效性。

Conclusion: OpenTinker 是一个有效的框架，支持在大规模语言模型（LLM）代理的强化学习（RL）中进行模块化设计和执行，适用于实际代理学习场景。

Abstract: We introduce OpenTinker, an infrastructure for reinforcement learning (RL) of large language model (LLM) agents built around a separation of concerns across algorithm design, execution, and agent-environment interaction. Rather than relying on monolithic, end-to-end RL pipelines, OpenTinker decomposes agentic learning systems into lightweight, composable components with clearly defined abstraction boundaries. Users specify agents, environments, and interaction protocols, while inference and training are delegated to a managed execution runtime. OpenTinker introduces a centralized scheduler for managing training and inference workloads, including LoRA-based and full-parameter RL, supervised fine-tuning, and inference, over shared resources. We further discuss design principles for extending OpenTinker to multi-agent training. Finally, we present a set of RL use cases that demonstrate the effectiveness of the framework in practical agentic learning scenarios.

</details>


### [203] [Beyond Reproducibility: Token Probabilities Expose Large Language Model Nondeterminism](https://arxiv.org/abs/2601.06118)
*Tairan Fu,Gonzalo Martínez,Javier Conde,Carlos Arriaga,Pedro Reviriego,Xiuyuan Qi,Shanshan Liu*

Main category: cs.AI

TL;DR: 研究发现LLMs在GPU上的非确定性执行对token概率（尤其是0.1-0.9范围内）有显著影响，且所有模型表现相似，这对理解非确定性及其影响提供了新视角。


<details>
  <summary>Details</summary>
Motivation: 探究LLMs在GPU上执行时的非确定性现象，尤其是其对token概率的影响，以弥补先前研究仅关注生成文本或确定性机制的不足。

Method: 通过分析token概率的变异而非生成文本来研究非确定性，评估了多种模型的概率变异趋势和实际值。

Result: 所有评估模型在token概率的变异趋势和实际值上表现相似，非确定性影响在概率值0.1至0.9时显著，而在接近0或1时较小。

Conclusion: 研究表明，LLMs在GPU上的非确定性执行对token概率有显著影响，尤其是在概率值介于0.1至0.9之间时。这一发现对理解非确定性及其对生成文本的影响具有重要意义。

Abstract: The execution of Large Language Models (LLMs) has been shown to produce nondeterministic results when run on Graphics Processing Units (GPUs), even when they are configured to produce deterministic results. This is due to the finite precision effects of the arithmetic operations, which depend on the order in which they are executed. This order, in turn, depends on the processes that are running concurrently on the GPU. Previous studies have focused on the impact of nondeterminism on the text generated by the LLMs or on proposing mechanisms to achieve deterministic execution. This work takes a closer look at nondeterminism by analyzing the variations on the token probabilities, not on the generated text. Interestingly, all the models evaluated have similar results in both the trends and the actual values of the variations of the probabilities. In particular, the results show that the effects of nondeterminism are significant for token probabilities that are in the range of 0.1 to 0.9, while they are much smaller when the probabilities are close to 0 or 1. This has significant implications for our understanding of nondeterminism. The first is that nondeterminism will likely have a non-negligible impact on generated text when the temperature is not zero, as it introduces significant variations in the token probabilities except when they are close to 0 or 1. Secondly, it suggests that all models have similar non deterministic variations at the token probability level. Therefore, different variations in the performance of the generated text, for example, when measuring accuracy on a benchmark, seem to come from different token probabilities or response lengths. A third implication is that we may be able to estimate the impact of nondeterminism by running a single inference and analyzing the token level probabilities, instead of having to run the same inference many times.

</details>


### [204] [NL2Dashboard: A Lightweight and Controllable Framework for Generating Dashboards with LLMs](https://arxiv.org/abs/2601.06126)
*Boshen Shi,Kexin Yang,Yuanbo Yang,Guanguang Chang,Ce Chi,Zhendong Wang,Xing Wang,Junlan Feng*

Main category: cs.AI

TL;DR: NL2Dashboard通过分析-呈现解耦和结构化中间表示，解决了LLM生成仪表板的冗余和可控性问题，实验表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有端到端仪表板生成方法存在表示冗余和低可控性问题，需解决LLM在生成综合仪表板时的挑战。

Method: 提出NL2Dashboard框架，采用结构化中间表示（IR）封装仪表板内容、布局和视觉元素，将LLM角色限定为数据分析和意图翻译，视觉合成由确定性渲染引擎处理。

Result: NL2Dashboard在多领域实验中显著优于现有基线，实现了更高的视觉质量、令牌效率和生成/修改任务中的精确可控性。

Conclusion: NL2Dashboard框架通过分析-呈现解耦原则，显著提升了仪表板生成的视觉质量、令牌效率和可控性，优于现有基线方法。

Abstract: While Large Language Models (LLMs) have demonstrated remarkable proficiency in generating standalone charts, synthesizing comprehensive dashboards remains a formidable challenge. Existing end-to-end paradigms, which typically treat dashboard generation as a direct code generation task (e.g., raw HTML), suffer from two fundamental limitations: representation redundancy due to massive tokens spent on visual rendering, and low controllability caused by the entanglement of analytical reasoning and presentation. To address these challenges, we propose NL2Dashboard, a lightweight framework grounded in the principle of Analysis-Presentation Decoupling. We introduce a structured intermediate representation (IR) that encapsulates the dashboard's content, layout, and visual elements. Therefore, it confines the LLM's role to data analysis and intent translation, while offloading visual synthesis to a deterministic rendering engine. Building upon this framework, we develop a multi-agent system in which the IR-driven algorithm is instantiated as a suite of tools. Comprehensive experiments conducted with this system demonstrate that NL2Dashboard significantly outperforms state-of-the-art baselines across diverse domains, achieving superior visual quality, significantly higher token efficiency, and precise controllability in both generation and modification tasks.

</details>


### [205] [HiMeS: Hippocampus-inspired Memory System for Personalized AI Assistants](https://arxiv.org/abs/2601.06152)
*Hailong Li,Feifei Li,Wenhui Que,Xingyu Fan*

Main category: cs.AI

TL;DR: HiMeS是一种融合短期和长期记忆的AI助手架构，通过强化学习训练和分区记忆网络，显著提升问答质量，优于传统RAG方法。


<details>
  <summary>Details</summary>
Motivation: 传统检索增强生成（RAG）管道在知识密集型场景中记忆容量有限，且检索机制与用户特定对话历史协调不足，导致冗余澄清、无关文档和用户体验下降。

Method: 提出了HiMeS架构，包括短期记忆提取器（通过强化学习训练压缩对话并预检索文档）和分区长期记忆网络（存储用户特定信息并重新排序检索文档）。

Result: 在真实工业数据集上，HiMeS在问答质量上显著优于级联RAG基线，消融研究证实了两种记忆模块的必要性。

Conclusion: HiMeS架构通过融合短期和长期记忆模块，显著提升了基于LLM的助手在知识密集型场景中的表现，为更可靠、上下文感知和用户定制化的AI助手提供了实用路径。

Abstract: Large language models (LLMs) power many interactive systems such as chatbots, customer-service agents, and personal assistants. In knowledge-intensive scenarios requiring user-specific personalization, conventional retrieval-augmented generation (RAG) pipelines exhibit limited memory capacity and insufficient coordination between retrieval mechanisms and user-specific conversational history, leading to redundant clarification, irrelevant documents, and degraded user experience. Inspired by the hippocampus-neocortex memory mechanism, we propose HiMeS, an AI-assistant architecture that fuses short-term and long-term memory. Our contributions are fourfold: (1) A short-term memory extractor is trained end-to-end with reinforcement learning to compress recent dialogue and proactively pre-retrieve documents from the knowledge base, emulating the cooperative interaction between the hippocampus and prefrontal cortex. (2) A partitioned long-term memory network stores user-specific information and re-ranks retrieved documents, simulating distributed cortical storage and memory reactivation. (3) On a real-world industrial dataset, HiMeS significantly outperforms a cascaded RAG baseline on question-answering quality. (4) Ablation studies confirm the necessity of both memory modules and suggest a practical path toward more reliable, context-aware, user-customized LLM-based assistants.

</details>


### [206] [PsyAgent: Constructing Human-like Agents Based on Psychological Modeling and Contextual Interaction](https://arxiv.org/abs/2601.06158)
*Zibin Meng,Kani Chen*

Main category: cs.AI

TL;DR: PsyAgent 结合 Big Five 特质和 Bourdieu 的社会结构，通过 IS 和 MSC 实现稳定且情境敏感的行为生成，表现优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 研究旨在模拟人类代理中特质与社会结构的交互，以生成稳定且情境敏感的行为。

Method: PsyAgent 包含个体结构（IS）和多场景情境化（MSC），通过固定结构化提示绑定场景与代理档案，生成监督数据并微调小型 LLM。

Result: PsyAgent 在人格一致性、情境适当性、风格匹配、特质可识别性和长时稳定性等指标上表现优于未调优的大型 LLM 和其他基线模型。

Conclusion: PsyAgent 提供了一个精确且数据高效的人格基础代理架构，结合 Big Five 特质和 Bourdieu 的认知-社会共构，实现了稳定且情境敏感的行为生成。

Abstract: Human-like agents require modeling how dispositions interact with social structure. We present PsyAgent, which couples a Big Five trait prior with Bourdieu's cognitive-social co-structure. PsyAgent comprises: (i) Individual Structure (IS), a machine-usable profile encoding traits and facets, cognitive style, values, cultural and educational capital, and salient life episodes; and (ii) Multi-Scenario Contexting (MSC), role-relationship-norm frames spanning eight arenas (work, family, friendship, strangers and civic life, solitude and self-regulation, romance, learning, and public expression). At inference, fixed structured prompts bind the active scenario to the agent profile, yielding behavior that is stable yet context-sensitive. We instantiate IS and MSC to synthesize supervision (role-play dialogues, decision probes, feedback trajectories) and then fine-tune a small LLM. The resulting model produces consistent, identifiable persona-aligned behaviors for specified Big Five configurations and matches or exceeds several larger untuned LLMs and other untuned baselines on our metrics: persona consistency, contextual appropriateness, style matching, trait identifiability, and long-horizon stability. Ablations show IS chiefly improves trait fidelity and stylistic stability, while MSC drives norm awareness and decision fit; both are necessary for cross-scenario performance. PsyAgent offers a precise, data-efficient architecture for personality-grounded agents.

</details>


### [207] [Student Guides Teacher: Weak-to-Strong Inference via Spectral Orthogonal Exploration](https://arxiv.org/abs/2601.06160)
*Dayu Wang,Jiaye Yang,Weikang Li,Jiahui Liang,Yang Li*

Main category: cs.AI

TL;DR: SOE框架通过几何探索方法显著提升LLMs在复杂推理任务中的性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在复杂数学证明和长时程规划中常出现‘推理崩溃’，退化至低秩偏置流形，导致模型无法探索高价值解空间。

Method: 提出了一种名为Spectral Orthogonal Exploration（SOE）的几何框架，采用‘学生引导教师’的反直觉范式，利用弱辅助代理作为正交探针，显式导航教师的零空间。

Result: 实验表明，相较于基线方法，SOE在数学基准测试中平均准确率提升62.4%，平均采样效率提高113.7%。

Conclusion: SOE框架通过几何探索方法有效解决了LLMs在复杂推理任务中的‘推理崩溃’问题，显著提升了模型的准确性和采样效率。

Abstract: While Large Language Models (LLMs) demonstrate near-human capabilities, they often suffer from "Reasoning Collapse" in complex mathematical proving and long-horizon planning. Models tend to degenerate into low-rank Bias Manifold, where stochastic sampling merely produces lexical variations of erroneous logic rather than semantic exploration. This geometric collapse renders the model "blind" to high-value solutions that lie within its Null Space. To address this, we propose Spectral Orthogonal Exploration (SOE), a geometric framework operating on a counter-intuitive "Student Guides Teacher" paradigm. Specifically, we utilize a weak auxiliary agent not for imitation, but as an orthogonal probe. By explicitly navigating the Teacher's Null Space, SOE serves as a geometric bridge, effectively ejecting the model from local optima to explore diverse, high-value solution spaces. Experiments on mathematical benchmarks demonstrate that, relative to baseline methods, our approach improves average accuracy by 62.4% and increases average sampling efficiency by 113.7%, indicating a promising path toward overcoming performance plateaus in advanced reasoning tasks.

</details>


### [208] [Beyond Accuracy: A Decision-Theoretic Framework for Allocation-Aware Healthcare AI](https://arxiv.org/abs/2601.06161)
*Rifa Ferzana*

Main category: cs.AI

TL;DR: 论文提出AI作为决策基础设施，通过优化资源分配策略在医疗资源受限环境下提升效用，解决了预测准确性与患者结果脱节的问题。


<details>
  <summary>Details</summary>
Motivation: 尽管AI在医疗预测准确性上达到专家水平，但模型性能的提升并未显著改善患者结果，这种脱节被称为分配差距。论文旨在通过决策理论解释这一现象。

Method: 使用约束优化和马尔可夫决策过程，结合合成分类模拟，比较了分配感知策略与风险阈值方法的效用。

Result: 合成分类模拟显示，在相同的预测准确性下，分配感知策略在实际效用上显著优于风险阈值方法。

Conclusion: 该论文提出了一个决策理论框架，解释了AI在医疗资源分配中的角色，并展示了在资源受限环境下如何通过优化分配策略来提升实际效用。

Abstract: Artificial intelligence (AI) systems increasingly achieve expert-level predictive accuracy in healthcare, yet improvements in model performance often fail to produce corresponding gains in patient outcomes. We term this disconnect the allocation gap and provide a decision-theoretic explanation by modelling healthcare delivery as a stochastic allocation problem under binding resource constraints. In this framework, AI acts as decision infrastructure that estimates utility rather than making autonomous decisions. Using constrained optimisation and Markov decision processes, we show how improved estimation affects optimal allocation under scarcity. A synthetic triage simulation demonstrates that allocation-aware policies substantially outperform risk-threshold approaches in realised utility, even with identical predictive accuracy. The framework provides a principled basis for evaluating and deploying healthcare AI in resource-constrained settings.

</details>


### [209] [Neuro-Symbolic Compliance: Integrating LLMs and SMT Solvers for Automated Financial Legal Analysis](https://arxiv.org/abs/2601.06181)
*Yung-Shen Hsia,Fang Yu,Jie-Hong Roland Jiang*

Main category: cs.AI

TL;DR: 论文提出神经符号合规框架，结合LLM和SMT求解器，显著提升合规自动化的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 金融监管日益复杂，阻碍了自动化合规，尤其是需要最少人工监督的逻辑一致性维护。

Method: 通过LLM解释法规和执法案例生成SMT约束，利用SMT求解器确保逻辑一致性并计算最小事实修改以恢复合法性。

Result: 在台湾金融监督管理委员会（FSC）的87个执法案例中，系统在SMT代码生成上达到86.2%的正确率，推理效率提升超过100倍，并能持续纠正违规行为。

Conclusion: 该论文提出了一个结合大型语言模型（LLMs）和可满足性模理论（SMT）求解器的神经符号合规框架，为优化驱动的合规应用奠定了初步基础。

Abstract: Financial regulations are increasingly complex, hindering automated compliance-especially the maintenance of logical consistency with minimal human oversight. We introduce a Neuro-Symbolic Compliance Framework that integrates Large Language Models (LLMs) with Satisfiability Modulo Theories (SMT) solvers to enable formal verifiability and optimization-based compliance correction. The LLM interprets statutes and enforcement cases to generate SMT constraints, while the solver enforces consistency and computes the minimal factual modification required to restore legality when penalties arise. Unlike transparency-oriented methods, our approach emphasizes logic-driven optimization, delivering verifiable, legally consistent reasoning rather than post-hoc explanation. Evaluated on 87 enforcement cases from Taiwan's Financial Supervisory Commission (FSC), the system attains 86.2% correctness in SMT code generation, improves reasoning efficiency by over 100x, and consistently corrects violations-establishing a preliminary foundation for optimization-based compliance applications.

</details>


### [210] [Large-Scale Continual Scheduling and Execution for Dynamic Distributed Satellite Constellation Observation Allocation](https://arxiv.org/abs/2601.06188)
*Itai Zilberstein,Steve Chien*

Main category: cs.AI

TL;DR: 本文提出DCOSP和D-NSS算法，解决大规模动态卫星星座观测调度问题，并在仿真中验证其优越性能。


<details>
  <summary>Details</summary>
Motivation: 解决大规模动态卫星星座观测调度中的高效计算和通信挑战。

Method: 提出了动态多卫星星座观测调度问题（DCOSP）的优化条件，并设计了离线全知算法和在线分解算法D-NSS。

Result: D-NSS在仿真中表现出接近最优解的性能，优于现有DDCOP基准。

Conclusion: DCOSP和D-NSS为大规模动态卫星星座观测调度提供了高效解决方案，并在NASA FAME任务中展示了分布式多智能体AI的实际应用潜力。

Abstract: The size and capabilities of Earth-observing satellite constellations are rapidly increasing. Leveraging distributed onboard control, we can enable novel time-sensitive measurements and responses. However, deploying autonomy to satellites requires efficient computation and communication. This work tackles the challenge of efficiently scheduling observations for hundreds of satellites in a dynamic, large-scale problem with millions of variables. We present the Dynamic Multi-Satellite Constellation Observation Scheduling Problem (DCOSP), a new formulation of Dynamic Distributed Constraint Optimization Problems (DDCOP) that models integrated scheduling and execution. DCOSP has a novel optimality condition for which we construct an omniscient offline algorithm for its computation. We also present the Dynamic Incremental Neighborhood Stochastic Search algorithm (D-NSS), an incomplete online decomposition-based DDCOP algorithm that repairs and solves sub-problems when problem dynamics occur. We show through simulation that D-NSS converges to near-optimal solutions and outperforms DDCOP baselines in terms of solution quality, computation time, and message volume. As part of the NASA FAME mission, DCOSP and D-NSS will be the foundation of the largest in-space demonstration of distributed multi-agent AI to date.

</details>


### [211] [Rational Synthesizers or Heuristic Followers? Analyzing LLMs in RAG-based Question-Answering](https://arxiv.org/abs/2601.06189)
*Atharv Naphade*

Main category: cs.AI

TL;DR: LLMs integrate conflicting evidence heuristically, influenced by paraphrasing, order, and size, with unfaithful explanations, suggesting RAG design improvements.


<details>
  <summary>Details</summary>
Motivation: To understand how LLMs integrate conflicting retrieved evidence—whether based on factual strength, prior beliefs, or repetition frequency.

Method: Controlled experiments using GroupQA, a dataset of 1,635 controversial questions with 15,058 evidence documents, annotated for stance and strength.

Result: Models are influenced by paraphrasing, order of evidence presentation, and model size; LLM explanations are unfaithful.

Conclusion: LLMs exhibit consistent behavior as vulnerable heuristic followers, highlighting the need for improved RAG system design.

Abstract: Retrieval-Augmented Generation (RAG) is the prevailing paradigm for grounding Large Language Models (LLMs), yet the mechanisms governing how models integrate groups of conflicting retrieved evidence remain opaque. Does an LLM answer a certain way because the evidence is factually strong, because of a prior belief, or merely because it is repeated frequently? To answer this, we introduce GroupQA, a curated dataset of 1,635 controversial questions paired with 15,058 diversely-sourced evidence documents, annotated for stance and qualitative strength. Through controlled experiments, we characterize group-level evidence aggregation dynamics: Paraphrasing an argument can be more persuasive than providing distinct independent support; Models favor evidence presented first rather than last, and Larger models are increasingly resistant to adapt to presented evidence. Additionally, we find that LLM explanations to group-based answers are unfaithful. Together, we show that LLMs behave consistently as vulnerable heuristic followers, with direct implications for improving RAG system design.

</details>


### [212] [AI Safeguards, Generative AI and the Pandora Box: AI Safety Measures to Protect Businesses and Personal Reputation](https://arxiv.org/abs/2601.06197)
*Prasanna Kumar*

Main category: cs.AI

TL;DR: 本文提出了一种基于TCL技术的TCN模型，用于高效检测生成式AI的负面影响，实验证明其优于其他方法，并强调了主动识别的重要性。


<details>
  <summary>Details</summary>
Motivation: 生成式AI在内容生成方面展现出强大能力，但同时也带来了深度伪造等社会危害，亟需有效的检测技术以保障AI安全。

Method: 采用预训练的Temporal Convolutional Networks（TCNs）模型进行训练，并通过性能对比验证其优越性。

Result: TCN模型在五种‘黑暗面’问题的检测中表现优于其他方法，并取得了显著准确率。

Conclusion: 本研究通过Temporal Consistency Learning（TCL）技术，展示了TCN模型在检测生成式AI的负面影响方面的高效性，强调了主动识别措施对降低潜在风险的重要性。

Abstract: Generative AI has unleashed the power of content generation and it has also unwittingly opened the pandora box of realistic deepfake causing a number of social hazards and harm to businesses and personal reputation. The investigation & ramification of Generative AI technology across industries, the resolution & hybridization detection techniques using neural networks allows flagging of the content. Good detection techniques & flagging allow AI safety - this is the main focus of this paper. The research provides a significant method for efficiently detecting dark side problems by imposing a Temporal Consistency Learning (TCL) technique. Through pretrained Temporal Convolutional Networks (TCNs) model training and performance comparison, this paper showcases that TCN models outperforms the other approaches and achieves significant accuracy for five dark side problems. Findings highlight how important it is to take proactive measures in identification to reduce any potential risks associated with generative artificial intelligence.

</details>


### [213] [PCoKG: Personality-aware Commonsense Reasoning with Debate](https://arxiv.org/abs/2601.06234)
*Weijie Li,Zhongqing Wang,Guodong Zhou*

Main category: cs.AI

TL;DR: 该论文构建了一个人格感知的常识知识图谱（PCoKG），通过LLMs和辩论机制优化知识生成，实验证明其能提升个性化对话生成的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有常识推理模型忽视人格特质的影响，限制了其在个性化系统（如对话生成）中的效果。

Method: 研究首先通过评估员筛选ATOMIC数据集中的事件，利用大型语言模型（LLMs）的扮演能力进行推理任务，并通过辩论机制（支持者、反对者和裁判）迭代优化生成的知识。

Result: PCoKG包含521,316个四元组，实验表明模型性能与基础模型的参数规模呈正相关，应用于基于角色的对话生成时，生成响应与参考输出的一致性有所提升。

Conclusion: 该研究通过构建PCoKG知识图谱，弥补了常识推理与个体认知差异之间的鸿沟，推动了更个性化和情境感知的AI系统发展。

Abstract: Most commonsense reasoning models overlook the influence of personality traits, limiting their effectiveness in personalized systems such as dialogue generation. To address this limitation, we introduce the Personality-aware Commonsense Knowledge Graph (PCoKG), a structured dataset comprising 521,316 quadruples. We begin by employing three evaluators to score and filter events from the ATOMIC dataset, selecting those that are likely to elicit diverse reasoning patterns across different personality types. For knowledge graph construction, we leverage the role-playing capabilities of large language models (LLMs) to perform reasoning tasks. To enhance the quality of the generated knowledge, we incorporate a debate mechanism consisting of a proponent, an opponent, and a judge, which iteratively refines the outputs through feedback loops. We evaluate the dataset from multiple perspectives and conduct fine-tuning and ablation experiments using multiple LLM backbones to assess PCoKG's robustness and the effectiveness of its construction pipeline. Our LoRA-based fine-tuning results indicate a positive correlation between model performance and the parameter scale of the base models. Finally, we apply PCoKG to persona-based dialogue generation, where it demonstrates improved consistency between generated responses and reference outputs. This work bridges the gap between commonsense reasoning and individual cognitive differences, enabling the development of more personalized and context-aware AI systems.

</details>


### [214] [ToolGym: an Open-world Tool-using Environment for Scalable Agent Testing and Data Curation](https://arxiv.org/abs/2601.06328)
*Ziqiao Xi,Shuang Liang,Qi Liu,Jiaqing Zhang,Letian Peng,Fang Nan,Meshal Nayim,Tianhui Zhang,Rishika Mundada,Lianhui Qin,Biwei Huang,Kun Zhou*

Main category: cs.AI

TL;DR: 构建开放世界工具环境，开发规划-执行代理框架，评估LLM表现，证明环境作为基准和数据引擎的价值。


<details>
  <summary>Details</summary>
Motivation: 解决当前工具使用LLM代理在开放世界设置中的挑战，如大规模工具池、长时目标、复杂约束和不可靠工具状态。

Method: 研究引入了开放世界工具使用环境，包含任务创建引擎和状态控制器，并开发了规划-执行分解的代理框架。

Result: 评估揭示了现有LLM在工具规划和执行能力上的不匹配，以及DeepSeek-v3.2的最强鲁棒性。通过微调，使用1,170条轨迹实现了优于基线的性能。

Conclusion: 该研究通过构建开放世界工具使用环境，开发了一种工具选择-执行代理框架，并证明了其作为基准和数据引擎的价值。

Abstract: Tool-using LLM agents still struggle in open-world settings with large tool pools, long-horizon objectives, wild constraints, and unreliable tool states. For scalable and realistic training and testing, we introduce an open-world tool-using environment, built on 5,571 format unified tools across 204 commonly used apps. It includes a task creation engine that synthesizes long-horizon, multi-tool workflows with wild constraints, and a state controller that injects interruptions and failures to stress-test robustness. On top of this environment, we develop a tool select-then-execute agent framework with a planner-actor decomposition to separate deliberate reasoning and self-correction from step-wise execution. Comprehensive evaluation of state-of-the-art LLMs reveals the misalignment between tool planning and execution abilities, the constraint following weakness of existing LLMs, and DeepSeek-v3.2's strongest robustness. Finally, we collect 1,170 trajectories from our environment to fine-tune LLMs, achieving superior performance to baselines using 119k samples, indicating the environment's value as both a realistic benchmark and a data engine for tool-using agents. Our code and data will be publicly released.

</details>


### [215] [Kolmogorov-Arnold Networks-Based Tolerance-Aware Manufacturability Assessment Integrating Design-for-Manufacturing Principles](https://arxiv.org/abs/2601.06334)
*Masoud Deylami,Negar Izadipour,Adel Alaeddini*

Main category: cs.AI

TL;DR: 提出基于KAN的框架，直接从设计参数评估可制造性，性能优于14种ML/DL模型，并具备高可解释性，工业案例验证实用性。


<details>
  <summary>Details</summary>
Motivation: 现有几何驱动方法需要大量预处理、存在信息丢失且可解释性有限，因此提出直接从参数化设计特征评估可制造性的新方法。

Method: 采用KANs学习设计参数、公差和可制造性结果之间的功能关系，并通过合成数据集（30万标记设计）评估性能，涵盖钻孔、铣削及组合场景。

Result: KAN在所有场景中表现最佳（钻孔AUC 0.9919，铣削0.9841，组合0.9406），并通过样条可视化实现高可解释性。工业案例验证了其迭代优化设计的能力。

Conclusion: 该研究提出了一种基于Kolmogorov-Arnold Networks（KANs）的方法，直接从参数化设计特征评估可制造性，无需CAD处理，显著提升了可解释性和性能。

Abstract: Manufacturability assessment is a critical step in bridging the persistent gap between design and production. While artificial intelligence (AI) has been widely applied to this task, most existing frameworks rely on geometry-driven methods that require extensive preprocessing, suffer from information loss, and offer limited interpretability. This study proposes a methodology that evaluates manufacturability directly from parametric design features, enabling explicit incorporation of dimensional tolerances without requiring computer-aided design (CAD) processing. The approach employs Kolmogorov-Arnold Networks (KANs) to learn functional relationships between design parameters, tolerances, and manufacturability outcomes. A synthetic dataset of 300,000 labeled designs is generated to evaluate performance across three representative scenarios: hole drilling, pocket milling, and combined drilling-milling, while accounting for machining constraints and design-for-manufacturing (DFM) rules. Benchmarking against fourteen machine learning (ML) and deep learning (DL) models shows that KAN achieves the highest performance in all scenarios, with AUC values of 0.9919 for drilling, 0.9841 for milling, and 0.9406 for the combined case. The proposed framework provides high interpretability through spline-based functional visualizations and latent-space projections, enabling identification of the design and tolerance parameters that most strongly influence manufacturability. An industrial case study further demonstrates how the framework enables iterative, parameter-level design modifications that transform a non-manufacturable component into a manufacturable one.

</details>


### [216] [Circuit Mechanisms for Spatial Relation Generation in Diffusion Transformers](https://arxiv.org/abs/2601.06338)
*Binxu Wang,Jingxuan Fan,Xu Pan*

Main category: cs.AI

TL;DR: DiT生成对象空间关系的机制因文本编码器选择而异，随机嵌入与T5分别采用不同电路，域内性能相似但鲁棒性不同。


<details>
  <summary>Details</summary>
Motivation: 研究DiT如何生成文本提示中指定的对象间正确空间关系，尽管现有模型在此方面仍有不足。

Method: 训练不同大小和文本编码器的DiT模型，学习生成包含两个对象及其空间关系的图像。

Result: 发现不同文本编码器导致DiT采用不同机制处理空间关系信息：随机嵌入通过两阶段电路分离读取，而T5则通过单文本令牌融合信息。

Conclusion: 尽管两种设置（随机文本嵌入与预训练文本编码器T5）在域内性能相似，但它们对域外扰动的鲁棒性不同，这可能暗示了在真实场景中生成正确空间关系的困难。

Abstract: Diffusion Transformers (DiTs) have greatly advanced text-to-image generation, but models still struggle to generate the correct spatial relations between objects as specified in the text prompt. In this study, we adopt a mechanistic interpretability approach to investigate how a DiT can generate correct spatial relations between objects. We train, from scratch, DiTs of different sizes with different text encoders to learn to generate images containing two objects whose attributes and spatial relations are specified in the text prompt. We find that, although all the models can learn this task to near-perfect accuracy, the underlying mechanisms differ drastically depending on the choice of text encoder. When using random text embeddings, we find that the spatial-relation information is passed to image tokens through a two-stage circuit, involving two cross-attention heads that separately read the spatial relation and single-object attributes in the text prompt. When using a pretrained text encoder (T5), we find that the DiT uses a different circuit that leverages information fusion in the text tokens, reading spatial-relation and single-object information together from a single text token. We further show that, although the in-domain performance is similar for the two settings, their robustness to out-of-domain perturbations differs, potentially suggesting the difficulty of generating correct relations in real-world scenarios.

</details>


### [217] [CARD: Cluster-level Adaptation with Reward-guided Decoding for Personalized Text Generation](https://arxiv.org/abs/2601.06352)
*Yutong Song,Jiang Wu,Weijia Zhang,Chengze Shen,Shaofan Yuan,Weitao Lu,Jian Wang,Amir Rahmani,Nikil Dutt,Yu Wang*

Main category: cs.AI

TL;DR: CARD框架通过聚类和隐式偏好学习实现高效个性化文本生成，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决大规模语言模型在个性化适应中的精细个性化与可扩展部署之间的矛盾。

Method: CARD采用分层框架，首先根据共享风格模式聚类用户并学习集群特定的LoRA适配器，然后通过隐式偏好学习机制捕捉个体差异。推理时，仅通过轻量级用户偏好向量和低秩对数校正注入个性化。

Result: 在LaMP和LongLaMP基准测试中，CARD在生成质量上达到或超越现有最佳基线，同时显著提升效率和可扩展性。

Conclusion: CARD框架通过分层渐进式优化，在保持基础模型冻结的同时，有效实现了个性化文本生成，显著提升了效率和可扩展性。

Abstract: Adapting large language models to individual users remains challenging due to the tension between fine-grained personalization and scalable deployment. We present CARD, a hierarchical framework that achieves effective personalization through progressive refinement. CARD first clusters users according to shared stylistic patterns and learns cluster-specific LoRA adapters, enabling robust generalization and strong low-resource performance. To capture individual differences within each cluster, we propose an implicit preference learning mechanism that contrasts user-authored text with cluster-level generations, allowing the model to infer user-specific style preferences without manual annotation. At inference time, CARD injects personalization exclusively at decoding via lightweight user preference vectors and low-rank logit corrections, while keeping the base model frozen. Experiments on the LaMP and LongLaMP benchmarks show that CARD achieves competitive or superior generation quality compared to state-of-the-art baselines, while significantly improving efficiency and scalability for practical personalized text generation.

</details>


### [218] [Styles + Persona-plug = Customized LLMs](https://arxiv.org/abs/2601.06362)
*Yutong Song,Jiang Wu,Shaofan Yuan,Chengze Shen,Jian Wang,Amir Rahmani,Nikil Dutt,Yu Wang*

Main category: cs.AI

TL;DR: PsPLUG通过残差建模平衡个性化和风格，在LaMP基准中表现优异，为可控个性化提供新思路。


<details>
  <summary>Details</summary>
Motivation: 个性化文本生成中，现有方法在显式风格指令下的行为尚未被充分理解，需平衡隐式个性化和显式风格。

Method: 提出PsPLUG，一种轻量级的软提示插件，通过风格条件偏好对比进行训练。

Result: 在LaMP基准测试中，PsPLUG提高了人物对齐度，保持了风格保真度，并以最小计算量优于基于检索和软提示的基线方法。

Conclusion: 残差建模为可控、风格感知的大型语言模型个性化提供了简单而原则性的基础。

Abstract: We discover a previously overlooked challenge in personalized text generation: personalization methods are increasingly applied under explicit style instructions, yet their behavior under such constraints remains poorly understood. To balance implicit personalization and explicit style, we formulate personalization as a distributional residual and propose PsPLUG, a lightweight soft-prompt plug-in trained with style-conditioned preference contrasts. Across LaMP benchmark, our framework improves persona alignment, maintains stylistic fidelity, and outperforms retrieval-based and soft-prompt baselines with minimal computation. These results show that residual modeling provides a simple and principled foundation for controllable, style-aware LLM personalization.

</details>


### [219] [HiMem: Hierarchical Long-Term Memory for LLM Long-Horizon Agents](https://arxiv.org/abs/2601.06377)
*Ningning Zhang,Xingxing Yang,Zhizhong Tan,Weiping Deng,Wenyong Wang*

Main category: cs.AI

TL;DR: HiMem是一种层次化长期记忆框架，通过双通道分割和多阶段提取构建记忆，支持动态更新和高效检索，显著提升对话系统性能。


<details>
  <summary>Details</summary>
Motivation: 现有长期记忆系统在适应性、可扩展性和持续交互下的自我进化方面存在明显局限，HiMem受认知理论启发，旨在解决这些问题。

Method: HiMem通过主题感知的事件-惊喜双通道分割策略构建认知一致的Episode Memory，并通过多阶段信息提取流程构建Note Memory，形成层次化结构，支持混合和尽力而为的检索策略，并引入冲突感知的记忆重组机制。

Result: 在长时对话基准测试中，HiMem在准确性、一致性和长期推理方面持续优于代表性基线方法，同时保持良好效率。

Conclusion: HiMem提出了一种层次化的长期记忆框架，显著提升了对话系统的准确性、一致性和长期推理能力，同时保持了良好的效率，为构建自适应和自我进化的LLM对话代理提供了理论基础和实用设计范例。

Abstract: Although long-term memory systems have made substantial progress in recent years, they still exhibit clear limitations in adaptability, scalability, and self-evolution under continuous interaction settings. Inspired by cognitive theories, we propose HiMem, a hierarchical long-term memory framework for long-horizon dialogues, designed to support memory construction, retrieval, and dynamic updating during sustained interactions. HiMem constructs cognitively consistent Episode Memory via a Topic-Aware Event--Surprise Dual-Channel Segmentation strategy, and builds Note Memory that captures stable knowledge through a multi-stage information extraction pipeline. These two memory types are semantically linked to form a hierarchical structure that bridges concrete interaction events and abstract knowledge, enabling efficient retrieval without sacrificing information fidelity. HiMem supports both hybrid and best-effort retrieval strategies to balance accuracy and efficiency, and incorporates conflict-aware Memory Reconsolidation to revise and supplement stored knowledge based on retrieval feedback. This design enables continual memory self-evolution over long-term use. Experimental results on long-horizon dialogue benchmarks demonstrate that HiMem consistently outperforms representative baselines in accuracy, consistency, and long-term reasoning, while maintaining favorable efficiency. Overall, HiMem provides a principled and scalable design paradigm for building adaptive and self-evolving LLM-based conversational agents. The code is available at https://github.com/jojopdq/HiMem.

</details>


### [220] [BizFinBench.v2: A Unified Dual-Mode Bilingual Benchmark for Expert-Level Financial Capability Alignment](https://arxiv.org/abs/2601.06401)
*Xin Guo,Rongjunchen Zhang,Guilong Lu,Xuntao Guo,Shuai Jia,Zhi Yang,Liwen Zhang*

Main category: cs.AI

TL;DR: BizFinBench.v2是基于真实业务数据的首个大规模评估基准，用于测试LLM在金融领域的实际效能，揭示了现有模型的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准在真实性和实时响应性方面与金融服务需求不符，导致基准性能与实际操作效果存在显著差距。

Method: 通过聚类分析真实金融平台用户查询，构建了包含八个基础任务和两个在线任务的评估基准，共29,578个专家级问答对。

Result: 实验结果显示，ChatGPT-5在主任务中达到61.5%准确率，但与金融专家仍有差距；在线任务中DeepSeek-R1表现最佳。

Conclusion: BizFinBench.v2超越了现有基准的限制，实现了对LLM金融能力的业务级解构，为金融领域广泛部署LLM的效能评估提供了精确依据。

Abstract: Large language models have undergone rapid evolution, emerging as a pivotal technology for intelligence in financial operations. However, existing benchmarks are often constrained by pitfalls such as reliance on simulated or general-purpose samples and a focus on singular, offline static scenarios. Consequently, they fail to align with the requirements for authenticity and real-time responsiveness in financial services, leading to a significant discrepancy between benchmark performance and actual operational efficacy. To address this, we introduce BizFinBench.v2, the first large-scale evaluation benchmark grounded in authentic business data from both Chinese and U.S. equity markets, integrating online assessment. We performed clustering analysis on authentic user queries from financial platforms, resulting in eight fundamental tasks and two online tasks across four core business scenarios, totaling 29,578 expert-level Q&A pairs. Experimental results demonstrate that ChatGPT-5 achieves a prominent 61.5% accuracy in main tasks, though a substantial gap relative to financial experts persists; in online tasks, DeepSeek-R1 outperforms all other commercial LLMs. Error analysis further identifies the specific capability deficiencies of existing models within practical financial business contexts. BizFinBench.v2 transcends the limitations of current benchmarks, achieving a business-level deconstruction of LLM financial capabilities and providing a precise basis for evaluating efficacy in the widespread deployment of LLMs within the financial domain. The data and code are available at https://github.com/HiThink-Research/BizFinBench.v2.

</details>


### [221] [Does Inference Scaling Improve Reasoning Faithfulness? A Multi-Model Analysis of Self-Consistency Tradeoffs](https://arxiv.org/abs/2601.06423)
*Deep Mehta*

Main category: cs.AI

TL;DR: 自一致性技术在不同模型上的效果差异显著，实践者需针对具体模型测试其效果。


<details>
  <summary>Details</summary>
Motivation: 探讨自一致性技术是否真正提高了推理的忠实性，而不仅仅是准确性的表面提升。

Method: 研究采用了自举置信区间、McNemar配对检验和Cohen's d效应量等方法，对四种前沿模型（GPT-5.2、Claude Opus 4.5、Gemini-3-flash-preview和DeepSeek-v3.2）在100个GSM8K数学推理问题上进行了全面分析。

Result: 不同模型对自一致性技术的响应差异显著：GPT-5.2准确性提升但忠实性稳定；Claude Opus 4.5准确性下降但忠实性大幅提升；DeepSeek-v3.2因已达高准确性仅显示小幅忠实性提升；Gemini-3-flash准确性提升但忠实性略有下降。

Conclusion: 研究揭示了自一致性技术在不同模型上的效果差异，强调了实践者在部署前需针对具体模型进行测试的重要性。

Abstract: Self-consistency has emerged as a popular technique for improving large language model accuracy on reasoning tasks. The approach is straightforward: generate multiple reasoning paths and select the most common answer through majority voting. While this reliably boosts accuracy, it remains unclear whether these gains reflect genuine improvements in reasoning quality. We investigate a fundamental question that has not been studied before: does inference scaling improve reasoning faithfulness?
  We conduct a comprehensive empirical study across four frontier models (GPT-5.2, Claude Opus 4.5, Gemini-3-flash-preview, and DeepSeek-v3.2) on 100 GSM8K mathematical reasoning problems. Our analysis employs bootstrap confidence intervals, McNemar's tests for paired comparisons, and Cohen's d effect sizes to quantify the effects rigorously. The results reveal striking differences across models that challenge common assumptions about self-consistency.
  GPT-5.2 shows the expected pattern: accuracy improves from 78% to 90% at N=5, with faithfulness remaining relatively stable (0.540 to 0.510). Claude Opus 4.5 tells a completely different story. Its accuracy actually drops from 78% to 74.3% while faithfulness jumps dramatically from 0.270 to 0.891 at N=5. DeepSeek-v3.2, already at 98% accuracy, shows ceiling effects with modest faithfulness gains (0.440 to 0.541). Gemini-3-flash improves from 81% to 86% accuracy with a slight faithfulness decrease (0.260 to 0.212).
  Problem difficulty analysis reveals that GPT-5.2 solves 82% of hard problems while breaking only 13% of easy ones. Claude, in contrast, breaks 23% of easy problems, explaining its accuracy decrease. These findings matter for practitioners: self-consistency is not universally beneficial, and teams should test their specific models before deployment. We release our code and provide practical recommendations for navigating these tradeoffs.

</details>


### [222] [LSRIF: Logic-Structured Reinforcement Learning for Instruction Following](https://arxiv.org/abs/2601.06431)
*Qingyu Ren,Qianyu He,Jingwen Chang,Jie Zeng,Jiaqing Liang,Yanghua Xiao,Han Xia,Zeye Sun,Fei Yu*

Main category: cs.AI

TL;DR: LSRIF框架通过显式建模指令逻辑结构，优化了指令跟随性能，尤其在处理复杂逻辑依赖时表现更优。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的指令常包含逻辑结构（如顺序依赖和条件分支），现有方法忽略了这些依赖关系，导致信号噪声大。

Method: 构建了包含并行、顺序和条件约束结构的LSRInstruct数据集，并设计了结构感知的奖励方法LSRIF，包括并行结构的平均聚合、顺序结构的失败惩罚传播和条件分支的选择性奖励。

Result: 实验表明LSRIF在指令跟随（领域内和领域外）和通用推理任务上带来显著改进。

Conclusion: LSRIF框架通过显式建模指令逻辑结构，显著提升了模型在指令跟随和通用推理任务上的性能，并揭示了注意力层参数更新和逻辑操作符关注度的变化。

Abstract: Instruction-following is critical for large language models, but real-world instructions often contain logical structures such as sequential dependencies and conditional branching. Existing methods typically construct datasets with parallel constraints and optimize average rewards, ignoring logical dependencies and yielding noisy signals. We propose a logic-structured training framework LSRIF that explicitly models instruction logic. We first construct a dataset LSRInstruct with constraint structures such as parallel, sequential, and conditional types, and then design structure-aware rewarding method LSRIF including average aggregation for parallel structures, failure-penalty propagation for sequential structures, and selective rewards for conditional branches. Experiments show LSRIF brings significant improvements in instruction-following (in-domain and out-of-domain) and general reasoning. Analysis reveals that learning with explicit logic structures brings parameter updates in attention layers and sharpens token-level attention to constraints and logical operators.

</details>


### [223] [ConSensus: Multi-Agent Collaboration for Multimodal Sensing](https://arxiv.org/abs/2601.06453)
*Hyungjun Yoon,Mohammad Malekzadeh,Sung-Ju Lee,Fahim Kawsar,Lorena Qendro*

Main category: cs.AI

TL;DR: ConSensus通过多智能体协作和混合融合机制，显著提升多模态感知任务的准确性和效率，优于单一模型且成本更低。


<details>
  <summary>Details</summary>
Motivation: 单一大型语言模型（LLM）在多模态感知任务中存在推理不连贯、解释不完整和先验知识偏差的问题，需更高效的解决方案。

Method: 提出ConSensus框架，采用训练无关的多智能体协作方式，将多模态感知任务分解为专门的模态感知智能体，并通过混合融合机制（语义聚合与统计共识）整合结果。

Result: 在五个多模态感知基准测试中，平均准确率提升7.1%，融合令牌成本降低12.7倍，性能与迭代多智能体辩论方法相当或更优。

Conclusion: ConSensus框架通过多智能体协作和混合融合机制，显著提升了多模态感知任务的准确性和效率，尤其在传感器噪声和数据缺失的情况下表现稳健。

Abstract: Large language models (LLMs) are increasingly grounded in sensor data to perceive and reason about human physiology and the physical world. However, accurately interpreting heterogeneous multimodal sensor data remains a fundamental challenge. We show that a single monolithic LLM often fails to reason coherently across modalities, leading to incomplete interpretations and prior-knowledge bias. We introduce ConSensus, a training-free multi-agent collaboration framework that decomposes multimodal sensing tasks into specialized, modality-aware agents. To aggregate agent-level interpretations, we propose a hybrid fusion mechanism that balances semantic aggregation, which enables cross-modal reasoning and contextual understanding, with statistical consensus, which provides robustness through agreement across modalities. While each approach has complementary failure modes, their combination enables reliable inference under sensor noise and missing data. We evaluate ConSensus on five diverse multimodal sensing benchmarks, demonstrating an average accuracy improvement of 7.1% over the single-agent baseline. Furthermore, ConSensus matches or exceeds the performance of iterative multi-agent debate methods while achieving a 12.7 times reduction in average fusion token cost through a single-round hybrid fusion protocol, yielding a robust and efficient solution for real-world multimodal sensing tasks.

</details>


### [224] [The AI Pyramid A Conceptual Framework for Workforce Capability in the Age of AI](https://arxiv.org/abs/2601.06500)
*Alok Khatri,Bishesh Khanal*

Main category: cs.AI

TL;DR: 本文提出AI原生性和AI金字塔框架，强调在AI经济中系统培养人类能力，而非阶段性培训，以适应AI对劳动力的影响。


<details>
  <summary>Details</summary>
Motivation: 挑战现有关于劳动力脆弱性的假设，解决传统数字或AI素养方法的不足，以适应AI对高教育水平白领工作的不均衡影响。

Method: 通过引入AI原生性概念和AI金字塔框架，区分三种相互依赖的能力层次，并基于问题导向的学习和动态技能本体论进行能力培养。

Result: 提出了AI金字塔框架，为组织、教育系统和政府提供了与AI中介工作需求对齐的学习、测量和政策指导。

Conclusion: 本文提出了AI金字塔框架，强调在AI驱动的经济中，人类能力的系统级分布需求，并呼吁将能力培养视为基础设施，而非阶段性培训。

Abstract: Artificial intelligence (AI) represents a qualitative shift in technological change by extending cognitive labor itself rather than merely automating routine tasks. Recent evidence shows that generative AI disproportionately affects highly educated, white collar work, challenging existing assumptions about workforce vulnerability and rendering traditional approaches to digital or AI literacy insufficient. This paper introduces the concept of AI Nativity, the capacity to integrate AI fluidly into everyday reasoning, problem solving, and decision making, and proposes the AI Pyramid, a conceptual framework for organizing human capability in an AI mediated economy. The framework distinguishes three interdependent capability layers: AI Native capability as a universal baseline for participation in AI augmented environments; AI Foundation capability for building, integrating, and sustaining AI enabled systems; and AI Deep capability for advancing frontier AI knowledge and applications. Crucially, the pyramid is not a career ladder but a system level distribution of capabilities required at scale. Building on this structure, the paper argues that effective AI workforce development requires treating capability formation as infrastructure rather than episodic training, centered on problem based learning embedded in work contexts and supported by dynamic skill ontologies and competency based measurement. The framework has implications for organizations, education systems, and governments seeking to align learning, measurement, and policy with the evolving demands of AI mediated work, while addressing productivity, resilience, and inequality at societal scale.

</details>


### [225] [DRAGON: LLM-Driven Decomposition and Reconstruction Agents for Large-Scale Combinatorial Optimization](https://arxiv.org/abs/2601.06502)
*Shengkai Chen,Zhiguang Cao,Jianan Zhou,Yaoxin Wu,Senthilnath Jayavelu,Zhuoyi Lin,Xiaoli Li,Shili Xiang*

Main category: cs.AI

TL;DR: DRAGON框架通过分解与重构代理结合LLM和元启发式设计，有效解决大规模组合优化问题，展示了语言代理的潜力。


<details>
  <summary>Details</summary>
Motivation: 现有LLM在组合优化问题中的可扩展性和泛化能力有限，尤其在超过30节点的路由问题中效果下降。

Method: DRAGON通过分解与重构代理，结合元启发式设计和LLM推理，将大规模COP分解为可管理的子问题，并通过目标LLM提示解决。

Result: DRAGON在TSPLIB、CVRPLIB和Weibull-5k装箱基准测试中持续生成可行解，并在超过300万变量的背包问题上达到接近最优结果（0.16%差距）。

Conclusion: DRAGON框架展示了反馈驱动的语言代理作为大规模优化新范式的潜力，具有通用性和可解释性。

Abstract: Large Language Models (LLMs) have recently shown promise in addressing combinatorial optimization problems (COPs) through prompt-based strategies. However, their scalability and generalization remain limited, and their effectiveness diminishes as problem size increases, particularly in routing problems involving more than 30 nodes. We propose DRAGON, which stands for Decomposition and Reconstruction Agents Guided OptimizatioN, a novel framework that combines the strengths of metaheuristic design and LLM reasoning. Starting from an initial global solution, DRAGON autonomously identifies regions with high optimization potential and strategically decompose large-scale COPs into manageable subproblems. Each subproblem is then reformulated as a concise, localized optimization task and solved through targeted LLM prompting guided by accumulated experiences. Finally, the locally optimized solutions are systematically reintegrated into the original global context to yield a significantly improved overall outcome. By continuously interacting with the optimization environment and leveraging an adaptive experience memory, the agents iteratively learn from feedback, effectively coupling symbolic reasoning with heuristic search. Empirical results show that, unlike existing LLM-based solvers limited to small-scale instances, DRAGON consistently produces feasible solutions on TSPLIB, CVRPLIB, and Weibull-5k bin packing benchmarks, and achieves near-optimal results (0.16% gap) on knapsack problems with over 3M variables. This work shows the potential of feedback-driven language agents as a new paradigm for generalizable and interpretable large-scale optimization.

</details>


### [226] [QMAVIS: Long Video-Audio Understanding using Fusion of Large Multimodal Models](https://arxiv.org/abs/2601.06573)
*Zixing Lin,Jiale Wang,Gee Wah Ng,Lee Onn Mak,Chan Zhi Yang Jeriel,Jun Yang Lee,Yaohao Li*

Main category: cs.AI

TL;DR: QMAVIS通过融合多模型提升长视频音频理解能力，性能显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 解决现有LMMs在长视频音频理解上的局限性，拓展长视频分析的应用场景。

Method: 采用LMMs、LLMs和语音识别模型的后期融合构建QMAVIS管道。

Result: 在VideoMME数据集上性能提升38.75%，在其他数据集上也有2%的提升。

Conclusion: QMAVIS通过融合LMMs、LLMs和语音识别模型，显著提升了长视频音频理解能力，并在多个数据集上表现出优于现有技术的性能。

Abstract: Large Multimodal Models (LMMs) for video-audio understanding have traditionally been evaluated only on shorter videos of a few minutes long. In this paper, we introduce QMAVIS (Q Team-Multimodal Audio Video Intelligent Sensemaking), a novel long video-audio understanding pipeline built through a late fusion of LMMs, Large Language Models, and speech recognition models. QMAVIS addresses the gap in long-form video analytics, particularly for longer videos of a few minutes to beyond an hour long, opening up new potential applica- tions in sensemaking, video content analysis, embodied AI, etc. Quantitative experiments using QMAVIS demonstrated a 38.75% improvement over state-of-the-art video-audio LMMs like Vide- oLlaMA2 and InternVL2 on the VideoMME (with subtitles) dataset, which comprises long videos with audio information. Evaluations on other challenging video understanding datasets like PerceptionTest and EgoSchema saw up to 2% improvement, indicating competitive performance. Qualitative experiments also showed that QMAVIS is able to extract the nuances of different scenes in a long video audio content while understanding the overarching narrative. Ablation studies were also conducted to ascertain the impact of each component in the fusion pipeline.

</details>


### [227] [Object-Centric World Models Meet Monte Carlo Tree Search](https://arxiv.org/abs/2601.06604)
*Rodion Vakhitov,Leonid Ugadiarov,Aleksandr Panov*

Main category: cs.AI

TL;DR: ObjectZero是一种新型强化学习算法，通过对象级表示和图神经网络有效建模动态环境，结合蒙特卡洛树搜索实现高效规划。


<details>
  <summary>Details</summary>
Motivation: 传统方法将世界视为单一无差异输入，无法有效建模动态环境中对象的交互，因此提出对象级表示以提升模型性能。

Method: 采用图神经网络（GNNs）捕捉多对象间的复杂交互，构建对象级表示，并结合蒙特卡洛树搜索作为规划模块。

Result: 在充满多样化交互对象的复杂环境中训练，算法能够有效学习并预测对象动态。

Conclusion: ObjectZero成功地将基于对象中心表示的结构化世界模型集成到基于模型的强化学习算法中，展示了其在动态环境建模中的有效性。

Abstract: In this paper, we introduce ObjectZero, a novel reinforcement learning (RL) algorithm that leverages the power of object-level representations to model dynamic environments more effectively. Unlike traditional approaches that process the world as a single undifferentiated input, our method employs Graph Neural Networks (GNNs) to capture intricate interactions among multiple objects. These objects, which can be manipulated and interact with each other, serve as the foundation for our model's understanding of the environment. We trained the algorithm in a complex setting teeming with diverse, interactive objects, demonstrating its ability to effectively learn and predict object dynamics. Our results highlight that a structured world model operating on object-centric representations can be successfully integrated into a model-based RL algorithm utilizing Monte Carlo Tree Search as a planning module.

</details>


### [228] [SafePro: Evaluating the Safety of Professional-Level AI Agents](https://arxiv.org/abs/2601.06663)
*Kaiwen Zhou,Shreedhar Jangam,Ashwin Nagarajan,Tejas Polu,Suhas Oruganti,Chengzhi Liu,Ching-Chen Kuo,Yuting Zheng,Sravana Narayanaraju,Xin Eric Wang*

Main category: cs.AI

TL;DR: SafePro基准评估了专业AI代理的安全性，发现显著漏洞并提出缓解策略，强调定制安全机制的必要性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型代理正从简单的对话助手发展为能执行复杂专业任务的自主系统，但其安全性风险尚未充分探索。

Method: 引入SafePro基准，通过严格迭代创建和审查过程开发了一个包含高风险复杂任务的数据集，评估了最先进AI模型的安全性。

Result: 评估揭示了显著的安全漏洞和新的不安全行为，表明模型在复杂专业任务中安全判断不足且对齐薄弱。安全缓解策略观察到了积极改进。

Conclusion: 研究强调了为新一代专业AI代理定制强大安全机制的紧迫性。

Abstract: Large language model-based agents are rapidly evolving from simple conversational assistants into autonomous systems capable of performing complex, professional-level tasks in various domains. While these advancements promise significant productivity gains, they also introduce critical safety risks that remain under-explored. Existing safety evaluations primarily focus on simple, daily assistance tasks, failing to capture the intricate decision-making processes and potential consequences of misaligned behaviors in professional settings. To address this gap, we introduce \textbf{SafePro}, a comprehensive benchmark designed to evaluate the safety alignment of AI agents performing professional activities. SafePro features a dataset of high-complexity tasks across diverse professional domains with safety risks, developed through a rigorous iterative creation and review process. Our evaluation of state-of-the-art AI models reveals significant safety vulnerabilities and uncovers new unsafe behaviors in professional contexts. We further show that these models exhibit both insufficient safety judgment and weak safety alignment when executing complex professional tasks. In addition, we investigate safety mitigation strategies for improving agent safety in these scenarios and observe encouraging improvements. Together, our findings highlight the urgent need for robust safety mechanisms tailored to the next generation of professional AI agents.

</details>


### [229] [FinForge: Semi-Synthetic Financial Benchmark Generation](https://arxiv.org/abs/2601.06747)
*Glenn Matlin,Akhil Theerthala,Anant Gupta,Anirudh JM,Rayan Castilla,Yi Mei Ng,Sudheer Chava*

Main category: cs.AI

TL;DR: FinForge是一个半合成的金融评估基准，用于评估语言模型在金融领域的推理能力，揭示了当前模型的局限性。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏高质量的金融领域数据集，现有通用基准无法充分评估语言模型在金融推理中的能力。

Method: 结合专家指导的数据整理和基于语言模型的受控合成，构建了一个半合成的金融评估基准FinForge-5k。

Result: FinForge-5k包含5000多个经过人工验证的问题-答案对，领先模型的准确率接近80%。

Conclusion: FinForge框架有效揭示了当前语言模型在金融领域的局限性，并为未来改进提供了方向。

Abstract: Evaluating Language Models (LMs) in specialized, high-stakes domains such as finance remains a significant challenge due to the scarcity of open, high-quality, and domain-specific datasets. Existing general-purpose benchmarks provide broad coverage but lack the depth and domain fidelity needed to assess LMs' capabilities for real-world financial reasoning, which requires both conceptual understanding and quantitative rigor. To address this gap, we introduce FinForge, a scalable, semi-synthetic pipeline for constructing finance-specific evaluation benchmarks through a hybrid of expert-guided data curation and controlled LM-based synthesis. FinForge combines manual and programmatic corpus construction from authoritative financial sources with structured question generation and validation using Gemini 2.5 Flash. To demonstrate the pipeline's efficacy, we produce FinForge-5k, a snapshot benchmark comprising over 5,000 human-validated question-answer pairs across 11 finance subdomains, derived from a curated corpus of 100,000 verified documents totaling 143M tokens. Evaluation of state-of-the-art open-source and closed-source models on FinForge-5k reveals significant differences in financial reasoning, with leading models achieving accuracy levels near 80%. These findings underscore the framework's utility for diagnosing current model limitations and guiding future improvements in financial domain competence. All code and data are available at https://github.com/gtfintechlab/FinForge.

</details>


### [230] [From Text to Simulation: A Multi-Agent LLM Workflow for Automated Chemical Process Design](https://arxiv.org/abs/2601.06776)
*Xufei Tian,Wenli Du,Shaoyi Yang,Han Hu,Hui Xin,Shifeng Qu,Ke Ye*

Main category: cs.AI

TL;DR: 本文提出了一种基于多智能体和LLMs的自动化化工流程模拟方法，显著提升了模拟效率和设计速度，适用于多种工业领域。


<details>
  <summary>Details</summary>
Motivation: 当前自动化化工设计方法主要关注流程图表示，但将其转化为可执行模拟流程仍需大量手动参数配置，耗时耗力。本研究旨在解决这一问题。

Method: 提出了一种新型多智能体工作流，结合大型语言模型（LLMs）的语义理解能力，通过四个专门智能体（任务理解、拓扑生成、参数配置和评估分析）与增强蒙特卡洛树搜索协同工作，实现从文本流程描述到计算验证软件配置的端到端自动化模拟。

Result: 在大型流程描述数据集Simona上评估，该方法比现有基准模拟收敛率提高了31.1%，设计时间比专家手动设计减少了89.0%。

Conclusion: 该工作展示了AI辅助化工流程设计的潜力，填补了概念设计与实际实施之间的差距。该方法适用于制药、石化、食品加工和制造等多种流程导向行业，为自动化流程设计提供了通用解决方案。

Abstract: Process simulation is a critical cornerstone of chemical engineering design. Current automated chemical design methodologies focus mainly on various representations of process flow diagrams. However, transforming these diagrams into executable simulation flowsheets remains a time-consuming and labor-intensive endeavor, requiring extensive manual parameter configuration within simulation software. In this work, we propose a novel multi-agent workflow that leverages the semantic understanding capabilities of large language models(LLMs) and enables iterative interactions with chemical process simulation software, achieving end-to-end automated simulation from textual process specifications to computationally validated software configurations for design enhancement. Our approach integrates four specialized agents responsible for task understanding, topology generation, parameter configuration, and evaluation analysis, respectively, coupled with Enhanced Monte Carlo Tree Search to accurately interpret semantics and robustly generate configurations. Evaluated on Simona, a large-scale process description dataset, our method achieves a 31.1% improvement in the simulation convergence rate compared to state-of-the-art baselines and reduces the design time by 89. 0% compared to the expert manual design. This work demonstrates the potential of AI-assisted chemical process design, which bridges the gap between conceptual design and practical implementation. Our workflow is applicable to diverse process-oriented industries, including pharmaceuticals, petrochemicals, food processing, and manufacturing, offering a generalizable solution for automated process design.

</details>


### [231] [No More Stale Feedback: Co-Evolving Critics for Open-World Agent Learning](https://arxiv.org/abs/2601.06794)
*Zhicong Li,Lingjie Jiang,Yulan Hu,Xingchen Zeng,Yixia Li,Xiangwen Zhang,Guanhua Chen,Zheng Pan,Xin Li,Yong Liu*

Main category: cs.AI

TL;DR: ECHO通过协同进化优化策略和评论家，解决静态评论家反馈失效问题，提升训练稳定性和任务成功率。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖静态或离线评论家模型，无法适应策略演变，导致反馈效用递减。

Method: ECHO采用级联展开机制，评论家为初始轨迹生成多个诊断，随后策略细化以实现群体结构优势估计。通过双轨GRPO更新确保评论家反馈与策略同步。

Result: 实验结果表明，ECHO在开放世界环境中实现了更稳定的训练和更高的长期任务成功率。

Conclusion: ECHO框架通过同步协同进化循环优化策略和评论家，解决了静态评论家模型无法适应策略演变的问题，实现了更稳定的训练和更高的长期任务成功率。

Abstract: Critique-guided reinforcement learning (RL) has emerged as a powerful paradigm for training LLM agents by augmenting sparse outcome rewards with natural-language feedback. However, current methods often rely on static or offline critic models, which fail to adapt as the policy evolves. In on-policy RL, the agent's error patterns shift over time, causing stationary critics to become stale and providing feedback of diminishing utility. To address this, we introduce ECHO (Evolving Critic for Hindsight-Guided Optimization)}, a framework that jointly optimizes the policy and critic through a synchronized co-evolutionary loop. ECHO utilizes a cascaded rollout mechanism where the critic generates multiple diagnoses for an initial trajectory, followed by policy refinement to enable group-structured advantage estimation. We address the challenge of learning plateaus via a saturation-aware gain shaping objective, which rewards the critic for inducing incremental improvements in high-performing trajectories. By employing dual-track GRPO updates, ECHO ensures the critic's feedback stays synchronized with the evolving policy. Experimental results show that ECHO yields more stable training and higher long-horizon task success across open-world environments.

</details>


### [232] [GDEPO: Group Dual-dynamic and Equal-right-advantage Policy Optimization with Enhanced Training Data Utilization for Sample-Constrained Reinforcement Learning](https://arxiv.org/abs/2601.06795)
*Zhengqing Yan,Xinyang Liu,Yi Zhang,Fan Guo,Yao Liu,Junchen Wan,Kang Song*

Main category: cs.AI

TL;DR: GDEPO通过动态采样和平等权利优势等机制，解决了GRPO在ATP任务中的问题，提升了数据利用率和学习效率。


<details>
  <summary>Details</summary>
Motivation: 在ATP任务中，GRPO算法面临相对优势估计与形式验证器二进制反馈冲突以及静态采样策略导致数据浪费的问题。

Method: 提出了Group Dual-dynamic and Equal-right-advantage Policy Optimization (GDEPO)，包含动态额外采样、平等权利优势和动态额外迭代三个核心机制。

Result: 在三个不同难度的数据集（MinF2F-test、MathOlympiadBench、PutnamBench）上的实验证实了GDEPO的有效性，消融研究验证了其协同组件的必要性。

Conclusion: GDEPO通过动态额外采样、平等权利优势和动态额外迭代三个核心机制，有效解决了GRPO在ATP任务中的局限性，提升了数据利用率和优化效率，为ATP提供了一种新的训练范式。

Abstract: Automated Theorem Proving (ATP) represents a fundamental challenge in Artificial Intelligence (AI), requiring the construction of machine-verifiable proofs in formal languages such as Lean to evaluate AI reasoning capabilities. Reinforcement learning (RL), particularly the high-performance Group Relative Policy Optimization (GRPO) algorithm, has emerged as a mainstream approach for this task. However, in ATP scenarios, GRPO faces two critical issues: when composite rewards are used, its relative advantage estimation may conflict with the binary feedback from the formal verifier; meanwhile, its static sampling strategy may discard entire batches of data if no valid proof is found, resulting in zero contribution to model updates and significant data waste. To address these limitations, we propose Group Dual-dynamic and Equal-right-advantage Policy Optimization (GDEPO), a method incorporating three core mechanisms: 1) dynamic additional sampling, which resamples invalid batches until a valid proof is discovered; 2) equal-right advantage, decoupling the sign of the advantage function (based on correctness) from its magnitude (modulated by auxiliary rewards) to ensure stable and correct policy updates; and 3) dynamic additional iterations, applying extra gradient steps to initially failed but eventually successful samples to accelerate learning on challenging cases. Experiments conducted on three datasets of varying difficulty (MinF2F-test, MathOlympiadBench, PutnamBench) confirm the effectiveness of GDEPO, while ablation studies validate the necessity of its synergistic components. The proposed method enhances data utilization and optimization efficiency, offering a novel training paradigm for ATP.

</details>


### [233] [Thinking with Deltas: Incentivizing Reinforcement Learning via Differential Visual Reasoning Policy](https://arxiv.org/abs/2601.06801)
*Shujian Gao,Yuan Wang,Jiangtao Yan,Zuxuan Wu,Yu-Gang Jiang*

Main category: cs.AI

TL;DR: 论文揭示了RLVR在多模态领域的感知-推理脱节问题，提出DVRP策略通过视觉三元组优化模型，显著提升视觉理解能力，并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的RLVR方法在多模态领域中存在感知与推理脱节的问题，模型倾向于绕过视觉感知，仅依赖语言先验生成答案。

Method: 通过引入视觉三元组（原始、掩码和扰动输入），DVRP策略优化模型以最大化与掩码输入的推理差异（增强视觉敏感性）并最小化与扰动输入的差异（确保视觉鲁棒性）。

Result: DVRP策略显著提升了模型的视觉理解能力，在通用和医学基准测试中均优于现有方法，且无需外部标注或辅助工具。

Conclusion: 论文提出了'Thinking with Deltas'框架和DVRP策略，有效解决了多模态领域中感知与推理的脱节问题，显著提升了模型的视觉理解能力，并在多个基准测试中优于现有方法。

Abstract: Reinforcement Learning with Verifiable Rewards (RLVR) has significantly advanced reasoning capabilities in Large Language Models. However, adapting RLVR to multimodal domains suffers from a critical \textit{perception-reasoning decoupling}. Existing paradigms, driven by text-centric outcome rewards, reasoning in language medium, inadvertently encourage models to bypass visual perception. We empirically validate this through blind experiments: state-of-the-art policies maintain or surprisingly improve performance even when visual inputs are entirely removed. This reveals that these models degenerate into \textit{blind reasoners}, exploiting linguistic priors to generate plausible answers instead of attending to visual evidence. In response, we propose \textbf{Thinking with Deltas}, a framework driven by a \textbf{Differential Visual Reasoning Policy (DVRP)}. DVRP introduces intrinsic supervision via visual triplets, comprising original, masked, and perturbed inputs. It optimizes the model to maximize reasoning divergence from masked inputs (enforcing \textit{visual sensitivity}) while minimizing divergence from perturbed inputs (ensuring \textit{visual robustness}). By aligning reasoning variations strictly with the \textit{Delta} of visual information, DVRP inherently bolsters visual understanding capabilities and significantly outperforms state-of-the-art methods on both general and medical benchmarks, without requiring external annotations or auxiliary tools.

</details>


### [234] [Seeing through the Conflict: Transparent Knowledge Conflict Handling in Retrieval-Augmented Generation](https://arxiv.org/abs/2601.06842)
*Hua Ye,Siyuan Chen,Ziqi Zhong,Canran Xiao,Haoliang Zhang,Yuhan Wu,Fei Shen*

Main category: cs.AI

TL;DR: TCR是一个透明冲突解决框架，通过双编码器和信号加权提升RAG模型的性能，减少幻觉和误导，参数开销极小。


<details>
  <summary>Details</summary>
Motivation: 尽管检索增强生成（RAG）模型应结合参数化知识和外部证据，但在实践中常出现幻觉、过度信任噪声片段或忽略关键上下文的问题。TCR旨在使这一决策过程可观察和可控。

Method: TCR框架通过双对比编码器分离语义匹配和事实一致性，估计自我可答性以评估内部记忆的置信度，并通过轻量级软提示和SNR加权将三个标量信号传递给生成器。

Result: 在七个基准测试中，TCR提高了冲突检测（+5-18 F1），知识缺口恢复率提升了21.4个百分点，误导性上下文覆盖减少了29.3个百分点，仅增加了0.3%的参数。

Conclusion: TCR框架通过透明的冲突解决机制，显著提升了检索增强生成（RAG）模型的性能，减少了幻觉和误导性上下文的干扰，同时参数增加极少。

Abstract: Large language models (LLMs) equipped with retrieval--the Retrieval-Augmented Generation (RAG) paradigm--should combine their parametric knowledge with external evidence, yet in practice they often hallucinate, over-trust noisy snippets, or ignore vital context. We introduce TCR (Transparent Conflict Resolution), a plug-and-play framework that makes this decision process observable and controllable. TCR (i) disentangles semantic match and factual consistency via dual contrastive encoders, (ii) estimates self-answerability to gauge confidence in internal memory, and (iii) feeds the three scalar signals to the generator through a lightweight soft-prompt with SNR-based weighting. Across seven benchmarks TCR improves conflict detection (+5-18 F1), raises knowledge-gap recovery by +21.4 pp and cuts misleading-context overrides by -29.3 pp, while adding only 0.3% parameters. The signals align with human judgements and expose temporal decision patterns.

</details>


### [235] [Code Evolution for Control: Synthesizing Policies via LLM-Driven Evolutionary Search](https://arxiv.org/abs/2601.06845)
*Ping Guo,Chao Li,Yinglan Feng,Chaoning Zhang*

Main category: cs.AI

TL;DR: LLM驱动的进化搜索能有效合成可解释的控制策略代码，结合EvoToolkit框架，生成可验证的紧凑策略。


<details>
  <summary>Details</summary>
Motivation: 传统强化学习方法存在样本复杂度高、奖励塑造困难及策略不透明等问题，而手动设计则需要大量领域专业知识且难以跨任务扩展。

Method: 采用LLM驱动的进化搜索，将策略合成视为代码进化问题，利用EvoToolkit框架实现LLM驱动进化与可定制适应度评估的无缝集成。

Result: 通过迭代进化候选策略程序群体，生成紧凑、人类可读的控制策略，可直接检查、修改和形式验证。

Conclusion: 本研究展示了结合基础模型与进化计算在合成可信赖自主系统控制策略中的潜力，生成的策略具有可解释性和可验证性。

Abstract: Designing effective control policies for autonomous systems remains a fundamental challenge, traditionally addressed through reinforcement learning or manual engineering. While reinforcement learning has achieved remarkable success, it often suffers from high sample complexity, reward shaping difficulties, and produces opaque neural network policies that are hard to interpret or verify. Manual design, on the other hand, requires substantial domain expertise and struggles to scale across diverse tasks. In this work, we demonstrate that LLM-driven evolutionary search can effectively synthesize interpretable control policies in the form of executable code. By treating policy synthesis as a code evolution problem, we harness the LLM's prior knowledge of programming patterns and control heuristics while employing evolutionary search to explore the solution space systematically. We implement our approach using EvoToolkit, a framework that seamlessly integrates LLM-driven evolution with customizable fitness evaluation. Our method iteratively evolves populations of candidate policy programs, evaluating them against task-specific objectives and selecting superior individuals for reproduction. This process yields compact, human-readable control policies that can be directly inspected, modified, and formally verified. This work highlights the potential of combining foundation models with evolutionary computation for synthesizing trustworthy control policies in autonomous systems. Code is available at https://github.com/pgg3/EvoControl.

</details>


### [236] [A Brain-like Synergistic Core in LLMs Drives Behaviour and Learning](https://arxiv.org/abs/2601.06851)
*Pedro Urbina-Rodriguez,Zafeirios Fountas,Fernando E. Rosas,Jun Wang,Andrea I. Luppi,Haitham Bou-Ammar,Murray Shanahan,Pedro A. M. Mediano*

Main category: cs.AI

TL;DR: 研究发现大型语言模型中层区域存在与人类大脑相似的协同信息处理，这种结构是智能的基本属性，对模型设计和生物智能研究具有重要意义。


<details>
  <summary>Details</summary>
Motivation: 探索生物和人工系统中智能演化的共同计算原理，揭示信息整合如何超越个体部分。

Method: 通过信息分解原理分析多种大型语言模型家族和架构，识别出中层区域的协同处理特性，并与随机初始化网络进行对比。

Result: 发现中层区域表现出协同处理，而早期和晚期层依赖冗余；协同组件的缺失会导致行为变化和性能损失，而通过强化学习微调协同区域能显著提升性能。

Conclusion: 协同信息处理是智能的基本属性，为模型设计提供了理论依据，并对生物智能提出了可测试的预测。

Abstract: The independent evolution of intelligence in biological and artificial systems offers a unique opportunity to identify its fundamental computational principles. Here we show that large language models spontaneously develop synergistic cores -- components where information integration exceeds individual parts -- remarkably similar to those in the human brain. Using principles of information decomposition across multiple LLM model families and architectures, we find that areas in middle layers exhibit synergistic processing while early and late layers rely on redundancy, mirroring the informational organisation in biological brains. This organisation emerges through learning and is absent in randomly initialised networks. Crucially, ablating synergistic components causes disproportionate behavioural changes and performance loss, aligning with theoretical predictions about the fragility of synergy. Moreover, fine-tuning synergistic regions through reinforcement learning yields significantly greater performance gains than training redundant components, yet supervised fine-tuning shows no such advantage. This convergence suggests that synergistic information processing is a fundamental property of intelligence, providing targets for principled model design and testable predictions for biological intelligence.

</details>


### [237] [ET-Agent: Incentivizing Effective Tool-Integrated Reasoning Agent via Behavior Calibration](https://arxiv.org/abs/2601.06860)
*Yifei Chen,Guanting Dong,Zhicheng Dou*

Main category: cs.AI

TL;DR: ET-Agent通过自我进化数据飞轮和两阶段行为校准训练，有效校准代理的工具使用行为，提升TIR任务表现。


<details>
  <summary>Details</summary>
Motivation: 现有LLM代理训练框架过于关注答案准确性，忽视行为模式的对齐，导致在TIR任务中出现无效动作（如冗余和不足的工具调用）。

Method: 提出了ET-Agent训练框架，包括自我进化数据飞轮和两阶段行为校准训练，用于生成增强数据并逐步校准错误行为模式。

Result: 实验证实ET-Agent在正确性、效率、推理简洁性和工具执行准确性等多个维度上表现优越。

Conclusion: ET-Agent框架为TIR领域的研究提供了实用见解，通过自我进化数据飞轮和行为校准训练，有效校准了代理的工具使用行为。

Abstract: Large Language Models (LLMs) can extend their parameter knowledge limits by adopting the Tool-Integrated Reasoning (TIR) paradigm. However, existing LLM-based agent training framework often focuses on answers' accuracy, overlooking specific alignment for behavior patterns. Consequently, agent often exhibits ineffective actions during TIR tasks, such as redundant and insufficient tool calls. How to calibrate erroneous behavioral patterns when executing TIR tasks, thereby exploring effective trajectories, remains an open-ended problem. In this paper, we propose ET-Agent, a training framework for calibrating agent's tool-use behavior through two synergistic perspectives: Self-evolving Data Flywheel and Behavior Calibration Training. Specifically, we introduce a self-evolutionary data flywheel to generate enhanced data, used to fine-tune LLM to improve its exploration ability. Based on this, we implement an two-phases behavior-calibration training framework. It is designed to progressively calibrate erroneous behavioral patterns to optimal behaviors. Further in-depth experiments confirm the superiority of \ourmodel{} across multiple dimensions, including correctness, efficiency, reasoning conciseness, and tool execution accuracy. Our ET-Agent framework provides practical insights for research in the TIR field. Codes can be found in https://github.com/asilverlight/ET-Agent

</details>


### [238] [An Ubuntu-Guided Large Language Model Framework for Cognitive Behavioral Mental Health Dialogue](https://arxiv.org/abs/2601.06875)
*Sontaga G. Forane,Absalom E. Ezugwu,Kevin Igwe,Karen van den Berg*

Main category: cs.AI

TL;DR: 研究开发了一个结合Ubuntu哲学和认知行为疗法的AI心理健康对话系统，提升了在非洲语境下的文化相关性和有效性。


<details>
  <summary>Details</summary>
Motivation: 南非心理健康危机加剧，且缺乏文化响应性护理，需要创新且符合当地文化的干预措施。

Method: 采用设计科学研究方法，结合深度理论和治疗适应以及表层语言和文化适应，开发了一个文化适应的数据集，并通过专家案例研究评估模型。

Result: 模型能进行富有同理心、符合文化和治疗目标的对话，展示了文化嵌入情感智能在提升AI心理健康干预效果方面的潜力。

Conclusion: 研究发现，结合非洲Ubuntu哲学的文化敏感AI心理健康对话系统，能有效提升在非洲语境下的文化相关性和包容性，为AI驱动的心理健康干预提供了新方向。

Abstract: South Africa's escalating mental health crisis, compounded by limited access to culturally responsive care, calls for innovative and contextually grounded interventions. While large language models show considerable promise for mental health support, their predominantly Western-centric training data limit cultural and linguistic applicability in African contexts. This study introduces a proof-of-concept framework that integrates cognitive behavioral therapy with the African philosophy of Ubuntu to create a culturally sensitive, emotionally intelligent, AI-driven mental health dialogue system. Guided by a design science research methodology, the framework applies both deep theoretical and therapeutic adaptations as well as surface-level linguistic and communicative cultural adaptations. Key CBT techniques, including behavioral activation and cognitive restructuring, were reinterpreted through Ubuntu principles that emphasize communal well-being, spiritual grounding, and interconnectedness. A culturally adapted dataset was developed through iterative processes of language simplification, spiritual contextualization, and Ubuntu-based reframing. The fine-tuned model was evaluated through expert-informed case studies, employing UniEval for conversational quality assessment alongside additional measures of CBT reliability and cultural linguistic alignment. Results demonstrate that the model effectively engages in empathetic, context-aware dialogue aligned with both therapeutic and cultural objectives. Although real-time end-user testing has not yet been conducted, the model underwent rigorous review and supervision by domain specialist clinical psychologists. The findings highlight the potential of culturally embedded emotional intelligence to enhance the contextual relevance, inclusivity, and effectiveness of AI-driven mental health interventions across African settings.

</details>


### [239] [V2P: Visual Attention Calibration for GUI Grounding via Background Suppression and Center Peaking](https://arxiv.org/abs/2601.06899)
*Jikai Chen,Long Chen,Dong Wang,Qinglin Su,Zhixuan Chu,Bingguang Hao,Leilei Gan,Chenyi Zhuang,Jinjie Gu*

Main category: cs.AI

TL;DR: V2P方法通过抑制背景干扰和中心-边缘区分优化，显著提升GUI元素定位精度。


<details>
  <summary>Details</summary>
Motivation: 传统方法忽略空间交互不确定性和视觉语义层次，现有注意力机制方法仍存在背景干扰和中心-边缘区分不足的问题。

Method: 提出Valley-to-Peak (V2P)方法，结合抑制注意力机制和Fitts' Law启发的2D高斯热图建模，以减少背景干扰并区分UI元素的中心与边缘。

Result: V2P模型在ScreenSpot-v2和ScreenSpot-Pro基准测试中分别达到92.4%和52.5%的性能，消融实验验证了各组件贡献。

Conclusion: V2P方法通过抑制注意力机制和Fitts' Law启发的2D高斯热图建模，有效解决了GUI元素定位中的背景干扰和中心-边缘区分问题，展现了在精确GUI定位任务中的通用性和实际部署潜力。

Abstract: Precise localization of GUI elements is crucial for the development of GUI agents. Traditional methods rely on bounding box or center-point regression, neglecting spatial interaction uncertainty and visual-semantic hierarchies. Recent methods incorporate attention mechanisms but still face two key issues: (1) ignoring processing background regions causes attention drift from the desired area, and (2) uniform modeling the target UI element fails to distinguish between its center and edges, leading to click imprecision. Inspired by how humans visually process and interact with GUI elements, we propose the Valley-to-Peak (V2P) method to address these issues. To mitigate background distractions, V2P introduces a suppression attention mechanism that minimizes the model's focus on irrelevant regions to highlight the intended region. For the issue of center-edge distinction, V2P applies a Fitts' Law-inspired approach by modeling GUI interactions as 2D Gaussian heatmaps where the weight gradually decreases from the center towards the edges. The weight distribution follows a Gaussian function, with the variance determined by the target's size. Consequently, V2P effectively isolates the target area and teaches the model to concentrate on the most essential point of the UI element. The model trained by V2P achieves the performance with 92.4\% and 52.5\% on two benchmarks ScreenSpot-v2 and ScreenSpot-Pro (see Fig.~\ref{fig:main_results_charts}). Ablations further confirm each component's contribution, underscoring V2P's generalizability in precise GUI grounding tasks and its potential for real-world deployment in future GUI agents.

</details>


### [240] [mind_call: A Dataset for Mental Health Function Calling with Large Language Models](https://arxiv.org/abs/2601.06937)
*Fozle Rabbi Shafi,M. Anwar Hossain,Salimur Choudhury*

Main category: cs.AI

TL;DR: 论文开发了一个基于可穿戴健康信号的合成函数调用数据集，用于心理健康辅助的LLM系统研究，支持多样化的自然语言查询映射到标准化API调用。


<details>
  <summary>Details</summary>
Motivation: 现有数据集未解决基于可穿戴传感器数据的心理健康导向访问问题，因此需要开发专门的数据集以支持LLM系统的结构化交互。

Method: 通过将多样化的自然语言查询映射到标准化的API调用，数据集涵盖了显式、隐式、行为、症状和隐喻表达，反映了真实的心理健康相关用户交互。

Result: 数据集包含用户查询、查询类别、显式推理步骤、标准化时间参数和目标函数，支持意图接地、时间推理和可靠函数调用研究。

Conclusion: 该论文提出了一种用于心理健康辅助的合成函数调用数据集，旨在支持基于可穿戴健康信号的LLM系统研究，并已公开发布以促进可重复性和未来工作。

Abstract: Large Language Model (LLM)-based systems increasingly rely on function calling to enable structured and controllable interaction with external data sources, yet existing datasets do not address mental health-oriented access to wearable sensor data. This paper presents a synthetic function-calling dataset designed for mental health assistance grounded in wearable health signals such as sleep, physical activity, cardiovascular measures, stress indicators, and metabolic data. The dataset maps diverse natural language queries to standardized API calls derived from a widely adopted health data schema. Each sample includes a user query, a query category, an explicit reasoning step, a normalized temporal parameter, and a target function. The dataset covers explicit, implicit, behavioral, symptom-based, and metaphorical expressions, which reflect realistic mental health-related user interactions. This resource supports research on intent grounding, temporal reasoning, and reliable function invocation in LLM-based mental health agents and is publicly released to promote reproducibility and future work.

</details>


### [241] [LLM Performance Predictors: Learning When to Escalate in Hybrid Human-AI Moderation Systems](https://arxiv.org/abs/2601.07006)
*Or Bachar,Or Levi,Sardhendu Mishra,Adi Levi,Manpreet Singh Minhas,Justin Miller,Omer Ben-Porat,Eilon Sheetrit,Jonathan Morra*

Main category: cs.AI

TL;DR: 该论文提出了一种监督式LLM不确定性量化框架，通过LPPs优化人机协同内容审核的准确性与成本权衡，并增强可解释性。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs越来越多地集成到人机协同内容审核系统中，核心挑战在于决定何时信任其输出，何时需要升级为人工审核。

Method: 提出了一种新颖的监督式LLM不确定性量化框架，通过学习基于LLM性能预测器（LPPs）的元模型，这些预测器来源于LLM的输出：对数概率、熵和新型不确定性归因指标。

Result: 实验表明，该方法在多模态和多语言审核任务中，显著优于现有不确定性估计器，实现了准确性与成本的权衡。LPPs还通过提供对失败条件的新见解（如模糊内容与政策不明确），增强了可解释性。

Conclusion: 该论文建立了一个原则性的框架，用于实现不确定性感知、可扩展且负责任的人机协同内容审核工作流程。

Abstract: As LLMs are increasingly integrated into human-in-the-loop content moderation systems, a central challenge is deciding when their outputs can be trusted versus when escalation for human review is preferable. We propose a novel framework for supervised LLM uncertainty quantification, learning a dedicated meta-model based on LLM Performance Predictors (LPPs) derived from LLM outputs: log-probabilities, entropy, and novel uncertainty attribution indicators. We demonstrate that our method enables cost-aware selective classification in real-world human-AI workflows: escalating high-risk cases while automating the rest. Experiments across state-of-the-art LLMs, including both off-the-shelf (Gemini, GPT) and open-source (Llama, Qwen), on multimodal and multilingual moderation tasks, show significant improvements over existing uncertainty estimators in accuracy-cost trade-offs. Beyond uncertainty estimation, the LPPs enhance explainability by providing new insights into failure conditions (e.g., ambiguous content vs. under-specified policy). This work establishes a principled framework for uncertainty-aware, scalable, and responsible human-AI moderation workflows.

</details>


### [242] [CloneMem: Benchmarking Long-Term Memory for AI Clones](https://arxiv.org/abs/2601.07023)
*Sen Hu,Zhiyu Zhang,Yuxiang Wei,Xueran Han,Zhenheng Tang,Huacan Wang,Ronghao Chen*

Main category: cs.AI

TL;DR: CloneMem是一个基于非对话数字痕迹（如日记、社交媒体帖子、电子邮件）的AI克隆长期记忆评估基准，揭示了当前记忆机制的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有记忆基准主要依赖用户-代理对话历史，时间上碎片化且不足以捕捉连续的人生轨迹。

Method: 采用分层数据构建框架确保纵向连贯性，并定义任务以评估代理跟踪个人状态演变的能力。

Result: 实验表明，当前记忆机制在此设定下表现不佳。

Conclusion: CloneMem作为评估AI克隆长期记忆的基准，揭示了当前记忆机制在模拟连续人生轨迹方面的不足，为基于生活的个性化AI提出了新的挑战。

Abstract: AI Clones aim to simulate an individual's thoughts and behaviors to enable long-term, personalized interaction, placing stringent demands on memory systems to model experiences, emotions, and opinions over time. Existing memory benchmarks primarily rely on user-agent conversational histories, which are temporally fragmented and insufficient for capturing continuous life trajectories. We introduce CloneMem, a benchmark for evaluating longterm memory in AI Clone scenarios grounded in non-conversational digital traces, including diaries, social media posts, and emails, spanning one to three years. CloneMem adopts a hierarchical data construction framework to ensure longitudinal coherence and defines tasks that assess an agent's ability to track evolving personal states. Experiments show that current memory mechanisms struggle in this setting, highlighting open challenges for life-grounded personalized AI. Code and dataset are available at https://github.com/AvatarMemory/CloneMemBench

</details>


### [243] [Dr. Zero: Self-Evolving Search Agents without Training Data](https://arxiv.org/abs/2601.07055)
*Zhenrui Yue,Kartikeya Upasani,Xianjun Yang,Suyu Ge,Shaoliang Nie,Yuning Mao,Zhe Liu,Dong Wang*

Main category: cs.AI

TL;DR: Dr. Zero框架通过自进化反馈循环和HRPO方法，无需训练数据即可提升搜索代理的推理和搜索能力。


<details>
  <summary>Details</summary>
Motivation: 高质量数据难以获取，而现有的多轮搜索代理在数据自由自进化中面临问题多样性和计算资源限制的挑战。

Method: 设计了自进化反馈循环和hop-grouped相对策略优化（HRPO）方法，通过问题聚类和组级基线减少计算开销。

Result: 实验结果表明，数据自由的Dr. Zero在性能上匹配或超越全监督搜索代理。

Conclusion: Dr. Zero框架通过数据自由的自进化，证明了无需训练数据即可实现复杂推理和搜索能力的提升，甚至优于全监督搜索代理。

Abstract: As high-quality data becomes increasingly difficult to obtain, data-free self-evolution has emerged as a promising paradigm. This approach allows large language models (LLMs) to autonomously generate and solve complex problems, thereby improving their reasoning capabilities. However, multi-turn search agents struggle in data-free self-evolution due to the limited question diversity and the substantial compute required for multi-step reasoning and tool using. In this work, we introduce Dr. Zero, a framework enabling search agents to effectively self-evolve without any training data. In particular, we design a self-evolution feedback loop where a proposer generates diverse questions to train a solver initialized from the same base model. As the solver evolves, it incentivizes the proposer to produce increasingly difficult yet solvable tasks, thus establishing an automated curriculum to refine both agents. To enhance training efficiency, we also introduce hop-grouped relative policy optimization (HRPO). This method clusters structurally similar questions to construct group-level baselines, effectively minimizing the sampling overhead in evaluating each query's individual difficulty and solvability. Consequently, HRPO significantly reduces the compute requirements for solver training without compromising performance or stability. Extensive experiment results demonstrate that the data-free Dr. Zero matches or surpasses fully supervised search agents, proving that complex reasoning and search capabilities can emerge solely through self-evolution.

</details>


### [244] [Automated Domain Question Mapping (DQM) with Educational Learning Materials](https://arxiv.org/abs/2601.07062)
*Jiho Noh,Mukhesh Raghava Katragadda,Dabae Lee*

Main category: cs.AI

TL;DR: 研究提出DQMs方法，通过问题构建和层次关系识别，提升教育内容的结构化表示和个性化学习。


<details>
  <summary>Details</summary>
Motivation: 解决教育内容自动构建概念图的两大挑战：缺乏针对多层次教学目的的学科概念和标记数据的不足。

Method: 引入一种创新方法构建领域问题地图（DQMs），通过制定与学习目标一致的具体问题来增强知识表示。

Result: 该方法能有效生成教育问题并识别其层次关系，形成结构化问题地图。

Conclusion: 提出的DQMs方法能有效生成教育问题并识别其层次关系，促进个性化学习。

Abstract: Concept maps have been widely utilized in education to depict knowledge structures and the interconnections between disciplinary concepts. Nonetheless, devising a computational method for automatically constructing a concept map from unstructured educational materials presents challenges due to the complexity and variability of educational content. We focus primarily on two challenges: (1) the lack of disciplinary concepts that are specifically designed for multi-level pedagogical purposes from low-order to high-order thinking, and (2) the limited availability of labeled data concerning disciplinary concepts and their interrelationships. To tackle these challenges, this research introduces an innovative approach for constructing Domain Question Maps (DQMs), rather than traditional concept maps. By formulating specific questions aligned with learning objectives, DQMs enhance knowledge representation and improve readiness for learner engagement. The findings indicate that the proposed method can effectively generate educational questions and discern hierarchical relationships among them, leading to structured question maps that facilitate personalized and adaptive learning in downstream applications.

</details>


### [245] [ENTRA: Entropy-Based Redundancy Avoidance in Large Language Model Reasoning](https://arxiv.org/abs/2601.07123)
*Ruichu Cai,Haopeng Du,Qingwen Lin,Yutong Chen,Zijian Li,Boyan Xu*

Main category: cs.AI

TL;DR: ENTRA通过熵基训练和强化学习优化，显著减少大型推理模型的冗余推理，保持性能的同时提升效率。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）常因过度思考生成冗长推理链，导致计算开销大但性能提升有限，现有方法难以平衡简洁与准确性。

Method: ENTRA采用轻量级双向重要性估计（BIE）方法评估令牌级重要性，结合预测置信度和前向影响力，通过基于低重要性令牌熵的冗余奖励进行强化学习优化。

Result: 在数学推理基准测试中，ENTRA将输出长度减少37%至53%，且准确性无损失甚至有所提升。

Conclusion: ENTRA框架通过熵基训练有效减少了大型推理模型中的冗余推理，同时保持甚至提升了性能，为解决模型过度思考问题提供了原则性和高效的解决方案。

Abstract: Large Reasoning Models (LRMs) often suffer from overthinking, generating unnecessarily long reasoning chains even for simple tasks. This leads to substantial computational overhead with limited performance gain, primarily due to redundant verification and repetitive generation. While prior work typically constrains output length or optimizes correctness, such coarse supervision fails to guide models toward concise yet accurate inference. In this paper, we propose ENTRA, an entropy-based training framework that suppresses redundant reasoning while preserving performance. ENTRA first estimates the token-level importance using a lightweight Bidirectional Importance Estimation (BIE) method, which accounts for both prediction confidence and forward influence. It then computes a redundancy reward based on the entropy of low-importance tokens, normalized by its theoretical upper bound, and optimizes this reward via reinforcement learning. Experiments on mathematical reasoning benchmarks demonstrate that ENTRA reduces output length by 37% to 53% with no loss-and in some cases, gains-in accuracy. Our approach offers a principled and efficient solution to reduce overthinking in LRMs, and provides a generalizable path toward redundancy-aware reasoning optimization.

</details>


### [246] [Rewarding Creativity: A Human-Aligned Generative Reward Model for Reinforcement Learning in Storytelling](https://arxiv.org/abs/2601.07149)
*Zhaoyan Li,Hang Lei,Yujia Wang,Lanbo Liu,Hao Liu,Liang Yu*

Main category: cs.AI

TL;DR: RLCS框架通过GenRM和熵奖励策略，提升创意故事生成质量，实验显示优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs能生成流畅文本，但高质量创意故事生成仍具挑战性，RL虽有望解决但面临奖励信号设计和训练不稳定的障碍。

Method: 开发了Generative Reward Model (GenRM)，通过监督微调和GRPO-based refinement训练，结合基于熵的奖励塑造策略。

Result: GenRM与人类创造力判断的契合度达68%，RLCS在整体故事质量上显著优于包括Gemini-2.5-Pro在内的基线模型。

Conclusion: 本研究提出了RLCS框架，通过GenRM和基于熵的奖励塑造策略，有效解决了创意故事生成中的奖励建模和训练稳定性挑战，为RL在创意领域的应用提供了实用流程。

Abstract: While Large Language Models (LLMs) can generate fluent text, producing high-quality creative stories remains challenging. Reinforcement Learning (RL) offers a promising solution but faces two critical obstacles: designing reliable reward signals for subjective storytelling quality and mitigating training instability. This paper introduces the Reinforcement Learning for Creative Storytelling (RLCS) framework to systematically address both challenges. First, we develop a Generative Reward Model (GenRM) that provides multi-dimensional analysis and explicit reasoning about story preferences, trained through supervised fine-tuning on demonstrations with reasoning chains distilled from strong teacher models, followed by GRPO-based refinement on expanded preference data. Second, we introduce an entropy-based reward shaping strategy that dynamically prioritizes learning on confident errors and uncertain correct predictions, preventing overfitting on already-mastered patterns. Experiments demonstrate that GenRM achieves 68\% alignment with human creativity judgments, and RLCS significantly outperforms strong baselines including Gemini-2.5-Pro in overall story quality. This work provides a practical pipeline for applying RL to creative domains, effectively navigating the dual challenges of reward modeling and training stability.

</details>


### [247] [AscendKernelGen: A Systematic Study of LLM-Based Kernel Generation for Neural Processing Units](https://arxiv.org/abs/2601.07160)
*Xinzi Cao,Jianyang Zhai,Pengfei Li,Zhiheng Hu,Cen Yan,Bingxu Mu,Guanghuan Fang,Bin She,Jiayu Li,Yihan Su,Dongyang Tao,Xiansong Huang,Fan Xu,Feidiao Yang,Yao Lu,Chang-Dong Wang,Yutong Lu,Weicheng Xue,Bin Zhou,Yonghong Tian*

Main category: cs.AI

TL;DR: AscendKernelGen框架通过领域适应模型和高质量数据集，显著提升NPU内核生成的编译成功率和功能正确性。


<details>
  <summary>Details</summary>
Motivation: 解决通用LLMs在NPU领域代码生成中的局限性，特别是在严格约束和训练数据稀缺的情况下，提升NPU内核开发的效率和性能。

Method: 提出了AscendKernelGen框架，包括Ascend-CoT数据集、KernelGen-LM模型和NPUKernelBench基准测试。通过监督微调和强化学习结合执行反馈训练模型。

Result: 编译成功率在复杂Level-2内核中从0%提升至95.5%，功能正确性达到64.3%。

Conclusion: AscendKernelGen框架通过领域特定的推理和严格评估，显著提升了LLMs在NPU内核开发中的性能，成功将复杂内核的编译成功率从0%提升至95.5%，功能正确性达到64.3%。

Abstract: To meet the ever-increasing demand for computational efficiency, Neural Processing Units (NPUs) have become critical in modern AI infrastructure. However, unlocking their full potential requires developing high-performance compute kernels using vendor-specific Domain-Specific Languages (DSLs), a task that demands deep hardware expertise and is labor-intensive. While Large Language Models (LLMs) have shown promise in general code generation, they struggle with the strict constraints and scarcity of training data in the NPU domain. Our preliminary study reveals that state-of-the-art general-purpose LLMs fail to generate functional complex kernels for Ascend NPUs, yielding a near-zero success rate. To address these challenges, we propose AscendKernelGen, a generation-evaluation integrated framework for NPU kernel development. We introduce Ascend-CoT, a high-quality dataset incorporating chain-of-thought reasoning derived from real-world kernel implementations, and KernelGen-LM, a domain-adaptive model trained via supervised fine-tuning and reinforcement learning with execution feedback. Furthermore, we design NPUKernelBench, a comprehensive benchmark for assessing compilation, correctness, and performance across varying complexity levels. Experimental results demonstrate that our approach significantly bridges the gap between general LLMs and hardware-specific coding. Specifically, the compilation success rate on complex Level-2 kernels improves from 0% to 95.5% (Pass@10), while functional correctness achieves 64.3% compared to the baseline's complete failure. These results highlight the critical role of domain-specific reasoning and rigorous evaluation in automating accelerator-aware code generation.

</details>


### [248] [Active Context Compression: Autonomous Memory Management in LLM Agents](https://arxiv.org/abs/2601.07190)
*Nikhil Verma*

Main category: cs.AI

TL;DR: Focus是一种受黏菌启发的代理架构，能自主压缩上下文，减少令牌使用并保持任务性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）代理在长期软件工程任务中因“上下文膨胀”而表现不佳，现有解决方案通常依赖被动、外部总结机制，代理无法控制。

Method: 本文提出了Focus，一种受黏菌生物探索策略启发的代理中心架构。Focus代理自主决定何时将关键学习内容整合到持久的“知识”块中，并主动修剪原始交互历史。

Result: 在SWE-bench Lite的N=5上下文密集型实例中，Focus实现了22.7%的令牌减少（14.9M -> 11.5M令牌），同时保持相同的准确率（3/5 = 60%）。

Conclusion: 研究表明，具备适当工具和提示的模型能够自主调节其上下文，为不牺牲任务性能的成本感知代理系统开辟了途径。

Abstract: Large Language Model (LLM) agents struggle with long-horizon software engineering tasks due to "Context Bloat." As interaction history grows, computational costs explode, latency increases, and reasoning capabilities degrade due to distraction by irrelevant past errors. Existing solutions often rely on passive, external summarization mechanisms that the agent cannot control. This paper proposes Focus, an agent-centric architecture inspired by the biological exploration strategies of Physarum polycephalum (slime mold). The Focus Agent autonomously decides when to consolidate key learnings into a persistent "Knowledge" block and actively withdraws (prunes) the raw interaction history. Using an optimized scaffold matching industry best practices (persistent bash + string-replacement editor), we evaluated Focus on N=5 context-intensive instances from SWE-bench Lite using Claude Haiku 4.5. With aggressive prompting that encourages frequent compression, Focus achieves 22.7% token reduction (14.9M -> 11.5M tokens) while maintaining identical accuracy (3/5 = 60% for both agents). Focus performed 6.0 autonomous compressions per task on average, with token savings up to 57% on individual instances. We demonstrate that capable models can autonomously self-regulate their context when given appropriate tools and prompting, opening pathways for cost-aware agentic systems without sacrificing task performance.

</details>


### [249] [LLMRouterBench: A Massive Benchmark and Unified Framework for LLM Routing](https://arxiv.org/abs/2601.07206)
*Hao Li,Yiqun Zhang,Zhaoyan Guo,Chenxu Wang,Shengji Tang,Qiaosheng Zhang,Yang Chen,Biqing Qi,Peng Ye,Lei Bai,Zhen Wang,Shuyue Hu*

Main category: cs.AI

TL;DR: LLMRouterBench是一个评估LLM路由的统一框架，发现现有方法性能相近且与理想Oracle差距大，强调模型互补性但指出当前方法的不足。


<details>
  <summary>Details</summary>
Motivation: 为了解决LLM路由领域缺乏统一评估标准的问题，并验证模型互补性这一核心前提。

Method: 引入了LLMRouterBench，一个包含超过400K实例、21个数据集和33个模型的大规模基准测试框架，并整合了10种代表性路由基线方法。

Result: 研究发现许多路由方法在统一评估下表现相似，部分近期方法（包括商业路由器）未能稳定超越简单基线；同时，与Oracle性能仍有显著差距，主要由于模型召回失败。此外，骨干嵌入模型影响有限，大型集成模型相比精心筛选的模型收益递减。

Conclusion: LLMRouterBench作为一个大规模基准测试和统一框架，系统地重新评估了LLM路由领域，揭示了模型互补性的重要性，同时指出了现有路由方法的局限性及与理想Oracle性能的差距。

Abstract: Large language model (LLM) routing assigns each query to the most suitable model from an ensemble. We introduce LLMRouterBench, a large-scale benchmark and unified framework for LLM routing. It comprises over 400K instances from 21 datasets and 33 models. Moreover, it provides comprehensive metrics for both performance-oriented routing and performance-cost trade-off routing, and integrates 10 representative routing baselines. Using LLMRouterBench, we systematically re-evaluate the field. While confirming strong model complementarity-the central premise of LLM routing-we find that many routing methods exhibit similar performance under unified evaluation, and several recent approaches, including commercial routers, fail to reliably outperform a simple baseline. Meanwhile, a substantial gap remains to the Oracle, driven primarily by persistent model-recall failures. We further show that backbone embedding models have limited impact, that larger ensembles exhibit diminishing returns compared to careful model curation, and that the benchmark also enables latency-aware analysis. All code and data are available at https://github.com/ynulihao/LLMRouterBench.

</details>


### [250] [Consolidation or Adaptation? PRISM: Disentangling SFT and RL Data via Gradient Concentration](https://arxiv.org/abs/2601.07224)
*Yang Zhao,Yangou Ouyang,Xiao Ding,Hepeng Wang,Bibo Cai,Kai Xiong,Jinglong Gao,Zhouhao Sun,Li Du,Bing Qin,Ting Liu*

Main category: cs.AI

TL;DR: PRISM框架通过动态感知数据冲突优化SFT和RL的数据分配，显著提升性能并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 探索在混合监督微调（SFT）和强化学习（RL）阶段之间有效的数据分配机制。

Method: PRISM是一个基于Schema Theory的动态感知框架，通过分析梯度的空间几何结构来仲裁数据。

Result: 在WebShop和ALFWorld上的广泛实验表明，PRISM实现了帕累托改进，优于最先进的混合方法，同时将计算成本降低了3.22倍。

Conclusion: 研究结果表明，基于内部优化机制的数据分离对于可扩展和稳健的代理对齐至关重要。

Abstract: While Hybrid Supervised Fine-Tuning (SFT) followed by Reinforcement Learning (RL) has become the standard paradigm for training LLM agents, effective mechanisms for data allocation between these stages remain largely underexplored. Current data arbitration strategies often rely on surface-level heuristics that fail to diagnose intrinsic learning needs. Since SFT targets pattern consolidation through imitation while RL drives structural adaptation via exploration, misaligning data with these functional roles causes severe optimization interference. We propose PRISM, a dynamics-aware framework grounded in Schema Theory that arbitrates data based on its degree of cognitive conflict with the model's existing knowledge. By analyzing the spatial geometric structure of gradients, PRISM identifies data triggering high spatial concentration as high-conflict signals that require RL for structural restructuring. In contrast, data yielding diffuse updates is routed to SFT for efficient consolidation. Extensive experiments on WebShop and ALFWorld demonstrate that PRISM achieves a Pareto improvement, outperforming state-of-the-art hybrid methods while reducing computational costs by up to 3.22$\times$. Our findings suggest that disentangling data based on internal optimization regimes is crucial for scalable and robust agent alignment.

</details>


### [251] [Lost in the Noise: How Reasoning Models Fail with Contextual Distractors](https://arxiv.org/abs/2601.07226)
*Seongyun Lee,Yongrae Jo,Minju Seo,Moontae Lee,Minjoon Seo*

Main category: cs.AI

TL;DR: NoisyBench基准揭示噪声环境下模型性能显著下降，提出RARE方法提升鲁棒性，发现测试时计算增加可能导致性能反向缩放。


<details>
  <summary>Details</summary>
Motivation: 当前推理模型和智能AI系统对多样化外部信息的依赖增加，但现有基准未能捕捉输入上下文中的噪声现实，导致模型在实际应用中表现不佳。

Method: 引入NoisyBench基准，系统评估模型在11个数据集上的鲁棒性，涵盖RAG、推理、对齐和工具使用任务，并针对多种噪声类型（如随机文档、无关聊天历史和硬负样本）进行分析。

Result: 评估显示，面对上下文干扰时，最先进模型的性能下降高达80%。提示、上下文工程、SFT和基于结果奖励的RL方法均无法确保鲁棒性，而RARE方法显著提升了模型对噪声的抵抗力。

Conclusion: 论文提出Rationale-Aware Reward (RARE)方法显著增强模型在噪声环境中的鲁棒性，揭示了测试时计算增加可能导致性能下降的反向缩放趋势，为构建下一代鲁棒推理智能体提供了关键见解。

Abstract: Recent advances in reasoning models and agentic AI systems have led to an increased reliance on diverse external information. However, this shift introduces input contexts that are inherently noisy, a reality that current sanitized benchmarks fail to capture. We introduce NoisyBench, a comprehensive benchmark that systematically evaluates model robustness across 11 datasets in RAG, reasoning, alignment, and tool-use tasks against diverse noise types, including random documents, irrelevant chat histories, and hard negative distractors. Our evaluation reveals a catastrophic performance drop of up to 80% in state-of-the-art models when faced with contextual distractors. Crucially, we find that agentic workflows often amplify these errors by over-trusting noisy tool outputs, and distractors can trigger emergent misalignment even without adversarial intent. We find that prompting, context engineering, SFT, and outcome-reward only RL fail to ensure robustness; in contrast, our proposed Rationale-Aware Reward (RARE) significantly strengthens resilience by incentivizing the identification of helpful information within noise. Finally, we uncover an inverse scaling trend where increased test-time computation leads to worse performance in noisy settings and demonstrate via attention visualization that models disproportionately focus on distractor tokens, providing vital insights for building the next generation of robust, reasoning-capable agents.

</details>


### [252] [Yes FLoReNce, I Will Do Better Next Time! Agentic Feedback Reasoning for Humorous Meme Detection](https://arxiv.org/abs/2601.07232)
*Olivia Shanhong Liu,Pai Chet Ng,De Wen Soh,Konstantinos N. Plataniotis*

Main category: cs.AI

TL;DR: FLoReNce通过闭环学习和反馈调节提示，提升AI对幽默模因的理解和解释能力。


<details>
  <summary>Details</summary>
Motivation: 现有多模态或基于提示的模型在幽默解释中缺乏自我批判和优化能力，无法在预测后改进推理。

Method: 提出了FLoReNce框架，包含闭环学习（推理代理受法官批评，反馈转化为控制信号并存储）和开环推理（从知识库检索经验以调节提示）。

Result: 在PrideMM数据集上，FLoReNce优于静态多模态基线，验证了反馈调节提示对自适应模因幽默理解的有效性。

Conclusion: FLoReNce框架通过闭环学习和开环推理，结合反馈调节提示，显著提升了模因幽默理解的预测性能和解释质量。

Abstract: Humorous memes blend visual and textual cues to convey irony, satire, or social commentary, posing unique challenges for AI systems that must interpret intent rather than surface correlations. Existing multimodal or prompting-based models generate explanations for humor but operate in an open loop,lacking the ability to critique or refine their reasoning once a prediction is made. We propose FLoReNce, an agentic feedback reasoning framework that treats meme understanding as a closed-loop process during learning and an open-loop process during inference. In the closed loop, a reasoning agent is critiqued by a judge; the error and semantic feedback are converted into control signals and stored in a feedback-informed, non-parametric knowledge base. At inference, the model retrieves similar judged experiences from this KB and uses them to modulate its prompt, enabling better, self-aligned reasoning without finetuning. On the PrideMM dataset, FLoReNce improves both predictive performance and explanation quality over static multimodal baselines, showing that feedback-regulated prompting is a viable path to adaptive meme humor understanding.

</details>


### [253] [From "Thinking" to "Justifying": Aligning High-Stakes Explainability with Professional Communication Standards](https://arxiv.org/abs/2601.07233)
*Chen Qian,Yimeng Wang,Yu Chen,Lingfei Wu,Andreas Stathopoulos*

Main category: cs.AI

TL;DR: SEF框架通过结构化论证提升AI输出的可验证性和可靠性，实验显示其优于Chain-of-Thought方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有Chain-of-Thought方法在推理过程中可能出现的逻辑漏洞或幻觉问题，确保结论与论证的可靠对齐。

Method: 提出了'结果->论证'（Result -> Justify）方法，并通过SEF框架实现，该框架包含六个结构和基础性指标。

Result: 实验验证了SEF框架的有效性：六个指标均与正确性相关（r=0.20-0.42；p<0.001），且SEF的准确率达到83.9%（比CoT高5.3%）。

Conclusion: 结构化论证（如SEF框架）可以提高AI输出的可验证性和可靠性，尤其在需要高可信度的领域。

Abstract: Explainable AI (XAI) in high-stakes domains should help stakeholders trust and verify system outputs. Yet Chain-of-Thought methods reason before concluding, and logical gaps or hallucinations can yield conclusions that do not reliably align with their rationale. Thus, we propose "Result -> Justify", which constrains the output communication to present a conclusion before its structured justification. We introduce SEF (Structured Explainability Framework), operationalizing professional conventions (e.g., CREAC, BLUF) via six metrics for structure and grounding. Experiments across four tasks in three domains validate this approach: all six metrics correlate with correctness (r=0.20-0.42; p<0.001), and SEF achieves 83.9% accuracy (+5.3 over CoT). These results suggest structured justification can improve verifiability and may also improve reliability.

</details>


### [254] [Group Pattern Selection Optimization: Let LRMs Pick the Right Pattern for Reasoning](https://arxiv.org/abs/2601.07238)
*Hanbin Wang,Jingwei Song,Jinpeng Li,Fei Mi,Lifeng Shang*

Main category: cs.AI

TL;DR: GPSO是一个强化学习框架，通过优化推理模式选择，提升模型在数学和科学任务上的表现。


<details>
  <summary>Details</summary>
Motivation: 现有大型推理模型（LRMs）的训练方法隐含地偏向有限的推理模式，导致模型在数学和科学任务上的表现不稳定。

Method: 引入Group Pattern Selection Optimization (GPSO)，一个结合多模式推演、验证器引导的最优模式选择和注意力掩码的强化学习框架。

Result: GPSO在各种模型架构和基准测试中均实现了显著且一致的性能提升。

Conclusion: GPSO通过优化推理模式选择，显著提升了模型在不同任务上的表现，解决了现有训练方法导致的推理模式单一问题。

Abstract: Large reasoning models (LRMs) exhibit diverse high-level reasoning patterns (e.g., direct solution, reflection-and-verification, and exploring multiple solutions), yet prevailing training recipes implicitly bias models toward a limited set of dominant patterns. Through a systematic analysis, we identify substantial accuracy variance across these patterns on mathematics and science benchmarks, revealing that a model's default reasoning pattern is often sub-optimal for a given problem. To address this, we introduce Group Pattern Selection Optimization (GPSO), a reinforcement learning framework that extends GRPO by incorporating multi-pattern rollouts, verifier-guided optimal pattern selection per problem, and attention masking during optimization to prevent the leakage of explicit pattern suffixes into the learned policy. By exploring a portfolio of diverse reasoning strategies and optimizing the policy on the most effective ones, GPSO enables the model to internalize the mapping from problem characteristics to optimal reasoning patterns. Extensive experiments demonstrate that GPSO delivers consistent and substantial performance gains across various model backbones and benchmarks, effectively mitigating pattern sub-optimality and fostering more robust, adaptable reasoning. All data and codes are available at https://github.com/wanghanbinpanda/GPSO.

</details>


### [255] [Stochastic CHAOS: Why Deterministic Inference Kills, and Distributional Variability Is the Heartbeat of Artifical Cognition](https://arxiv.org/abs/2601.07239)
*Tanmay Joshi,Shourya Aggarwal,Anusa Saha,Aadi Pandey,Shreyash Dhoot,Vighnesh Rai,Raxit Goswami,Aman Chadha,Vinija Jain,Amitava Das*

Main category: cs.AI

TL;DR: 论文反对LLM中的确定性推理，主张随机性（Stochastic CHAOS），实证显示确定性会低估能力、掩盖风险并削弱涌现能力。


<details>
  <summary>Details</summary>
Motivation: 反驳当前LLM推理中普遍追求的确定性理想，指出其系统性缺陷，如抑制不确定性建模、削弱涌现能力、限制推理路径及隐藏安全风险。

Method: 通过实证分析，比较确定性推理与随机性推理在LLM中的表现，展示确定性推理如何低估模型能力和脆弱性，并掩盖安全风险。

Result: 确定性推理会低估模型能力、掩盖失败概率、削弱涌现能力、降低多路径推理准确性，并隐藏罕见但危险的行为。

Conclusion: 作者主张在大型语言模型（LLM）推理中采用随机性（Stochastic CHAOS），认为确定性推理会掩盖模型的不确定性、削弱涌现能力、限制推理路径，并隐藏安全风险。

Abstract: Deterministic inference is a comforting ideal in classical software: the same program on the same input should always produce the same output. As large language models move into real-world deployment, this ideal has been imported wholesale into inference stacks. Recent work from the Thinking Machines Lab has presented a detailed analysis of nondeterminism in LLM inference, showing how batch-invariant kernels and deterministic attention can enforce bitwise-identical outputs, positioning deterministic inference as a prerequisite for reproducibility and enterprise reliability.
  In this paper, we take the opposite stance. We argue that, for LLMs, deterministic inference kills. It kills the ability to model uncertainty, suppresses emergent abilities, collapses reasoning into a single brittle path, and weakens safety alignment by hiding tail risks. LLMs implement conditional distributions over outputs, not fixed functions. Collapsing these distributions to a single canonical completion may appear reassuring, but it systematically conceals properties central to artificial cognition. We instead advocate Stochastic CHAOS, treating distributional variability as a signal to be measured and controlled.
  Empirically, we show that deterministic inference is systematically misleading. Single-sample deterministic evaluation underestimates both capability and fragility, masking failure probability under paraphrases and noise. Phase-like transitions associated with emergent abilities disappear under greedy decoding. Multi-path reasoning degrades when forced onto deterministic backbones, reducing accuracy and diagnostic insight. Finally, deterministic evaluation underestimates safety risk by hiding rare but dangerous behaviors that appear only under multi-sample evaluation.

</details>


### [256] [Learning to Trust the Crowd: A Multi-Model Consensus Reasoning Engine for Large Language Models](https://arxiv.org/abs/2601.07245)
*Pranav Kallem*

Main category: cs.AI

TL;DR: 通过多模型共识提升LLM可靠性，最佳模型显著提高准确率并减少幻觉。


<details>
  <summary>Details</summary>
Motivation: 研究如何通过多模型共识提高LLM在实例级别的可靠性，解决幻觉、脆弱失败和校准不良等问题。

Method: 引入多模型共识推理引擎，利用语义嵌入、成对相似性和聚类统计、词汇和结构线索、推理质量评分、置信度估计和模型特定先验，将自然语言响应映射为结构化特征，然后应用梯度提升树、列表排序和基于图神经网络的相似性图分析。

Result: 基于图注意力的共识模型在多个数据集上显著提高了准确率，降低了Brier分数和TruthfulQA幻觉。

Conclusion: 监督多模型共识是提高LLM可靠性的实用途径，即使在单机设置中也能实现。

Abstract: Large language models (LLMs) achieve strong aver- age performance yet remain unreliable at the instance level, with frequent hallucinations, brittle failures, and poorly calibrated confidence. We study reliability through the lens of multi-model consensus: given responses from several heterogeneous LLMs, can we learn which answer is most likely correct for a given query? We introduce a Multi-Model Consensus Reasoning Engine that treats the set of LLM outputs as input to a supervised meta-learner. The system maps natural language responses into structured features using semantic embeddings, pairwise similarity and clustering statistics, lexical and structural cues, reasoning-quality scores, confidence estimates, and model-specific priors, and then applies gradient-boosted trees, listwise ranking, and graph neural networks over similarity graphs of answers. Using three open-weight LLMs evaluated on compact, resource- constrained subsets of GSM8K, ARC-Challenge, HellaSwag, and TruthfulQA, our best graph-attention-based consensus model improves macro-average accuracy by 4.6 percentage points over the strongest single LLM and by 8.1 points over majority vote, while also yielding lower Brier scores and fewer TruthfulQA hal- lucinations. Ablation and feature-importance analyses show that semantic agreement and clustering features are most influential, with reasoning-quality and model-prior features providing com- plementary gains, suggesting supervised multi-model consensus is a practical route toward more reliable LLM behavior, even in a modest single-machine setup.

</details>


### [257] [LRAS: Advanced Legal Reasoning with Agentic Search](https://arxiv.org/abs/2601.07296)
*Yujin Zhou,Chuxue Cao,Jinluan Yang,Lijun Wu,Conghui He,Sirui Han,Yike Guo*

Main category: cs.AI

TL;DR: LRAS框架通过动态交互和主动询问，显著提升法律LLM的推理能力，尤其在深度推理任务中表现突出。


<details>
  <summary>Details</summary>
Motivation: 现有法律LLM依赖内部参数知识的'闭环推理'，缺乏对知识边界的自我意识，导致自信但错误的结论。

Method: LRAS结合了内省模仿学习和难度感知强化学习，使LRM能够识别知识边界并处理法律推理的复杂性。

Result: 实证结果显示，LRAS在需要深度推理的任务中比现有基准模型表现优异，提升幅度达8.2-32%。

Conclusion: LRAS框架通过将法律LLM从静态的'闭环思维'转变为动态的'主动询问'，显著提升了法律推理的准确性和深度，尤其在需要可靠知识的深度推理任务中表现突出。

Abstract: While Large Reasoning Models (LRMs) have demonstrated exceptional logical capabilities in mathematical domains, their application to the legal field remains hindered by the strict requirements for procedural rigor and adherence to legal logic. Existing legal LLMs, which rely on "closed-loop reasoning" derived solely from internal parametric knowledge, frequently suffer from lack of self-awareness regarding their knowledge boundaries, leading to confident yet incorrect conclusions. To address this challenge, we present Legal Reasoning with Agentic Search (LRAS), the first framework designed to transition legal LLMs from static and parametric "closed-loop thinking" to dynamic and interactive "Active Inquiry". By integrating Introspective Imitation Learning and Difficulty-aware Reinforcement Learning, LRAS enables LRMs to identify knowledge boundaries and handle legal reasoning complexity. Empirical results demonstrate that LRAS outperforms state-of-the-art baselines by 8.2-32\%, with the most substantial gains observed in tasks requiring deep reasoning with reliable knowledge. We will release our data and models for further exploration soon.

</details>


### [258] [ARM: Role-Conditioned Neuron Transplantation for Training-Free Generalist LLM Agent Merging](https://arxiv.org/abs/2601.07309)
*Zhuoka Feng,Kang Chen,Sihan Zhao,Kai Xiong,Yaoning Wang,Minshen Yu,Junjie Nian,Changyi Xiao,Yixin Cao,Yugang Jiang*

Main category: cs.AI

TL;DR: ARM是一种无需训练的模型合并方法，通过角色条件神经元移植提升多轮代理场景下的跨领域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有大型语言模型代理在跨环境适应能力不足的问题，提供无需训练的模型合并方案。

Method: 提出ARM方法，包括三个步骤：1)构建合并主干，2)基于角色条件激活分析进行选择，3)神经元移植进行细粒度优化。

Result: ARM合并的模型在多个领域表现优于现有模型合并方法和领域专家模型，并展现出强大的跨领域泛化能力。

Conclusion: ARM方法通过激活引导、角色条件神经元移植，在多轮代理场景中提升了模型合并的效果，实现了跨领域泛化能力的显著提升。

Abstract: Interactive large language model agents have advanced rapidly, but most remain specialized to a single environment and fail to adapt robustly to other environments. Model merging offers a training-free alternative by integrating multiple experts into a single model. In this paper, we propose Agent-Role Merging (ARM), an activation-guided, role-conditioned neuron transplantation method for model merging in LLM agents. ARM improves existing merging methods from static natural language tasks to multi-turn agent scenarios, and over the generalization ability across various interactive environments. This is achieved with a well designed 3-step framework: 1) constructing merged backbones, 2) selection based on its role-conditioned activation analysis, and 3) neuron transplantation for fine-grained refinements. Without gradient-based optimization, ARM improves cross-benchmark generalization while enjoying efficiency. Across diverse domains, the model obtained via ARM merging outperforms prior model merging methods and domain-specific expert models, while demonstrating strong out-of-domain generalization.

</details>


### [259] [Agentic Diagnostic Reasoning over Telecom and Datacenter Infrastructure](https://arxiv.org/abs/2601.07342)
*Nicolas Tacheny*

Main category: cs.AI

TL;DR: 本文提出了一种基于LLM的自主诊断框架，通过MCP协议调用工具进行故障调查，替代传统RCA方法，为自主事件解决和变更影响预测奠定基础。


<details>
  <summary>Details</summary>
Motivation: 传统根因分析（RCA）方法依赖硬编码的图遍历算法或基于规则的关联引擎，维护成本高且与基础设施模型紧密耦合，需要更灵活、自主的解决方案。

Method: 引入一个代理诊断框架，利用LLM逐步调查，通过MCP协议调用工具进行服务查找、依赖检索、结构化和非结构化数据分析及事件分析和影响发现。

Result: 提出的框架能够自主导航基础设施模型，通过定义的调查协议确保推理的结构化、可重现性及对缺失或模糊信息的安全处理。

Conclusion: 本文提出了一个基于大型语言模型（LLM）的自主诊断框架，通过模型上下文协议（MCP）约束工具空间，实现基础设施故障的自主调查和解决，为未来自主事件解决和变更影响缓解奠定了基础。

Abstract: Large-scale telecom and datacenter infrastructures rely on multi-layered service and resource models, where failures propagate across physical and logical components and affect multiple customers. Traditional approaches to root cause analysis(RCA) rely on hard-coded graph traversal algorithms or rule-based correlation engines, which are costly to maintain and tightly coupled to the infrastructure model.
  In this work, we introduce an agentic diagnostic framework where a Large Language Model (LLM) performs step-wise investigation using a constrained tool space exposed through the Model Context Protocol (MCP). Instead of embedding causal logic or traversal algorithms into the application, the agent autonomously navigates the infrastructure model by invoking tools for service lookup, dependency retrieval, structured and unstructured data, and event analysis, and impact discovery. We define an investigation protocol that structures the agent's reasoning and ensures grounding, reproducibility, and safe handling of missing or ambiguous information.
  This work lays the foundation for autonomous incident resolution and change impact mitigation. Future systems will not only diagnose and remediate infrastructure failures, but also predict the impact of planned changes on services and customers, enabling operators to mitigate risks before executing maintenance operations.

</details>


### [260] [On the universal definition of intelligence](https://arxiv.org/abs/2601.07364)
*Joseph Chen*

Main category: cs.AI

TL;DR: 本文提出扩展预测假说（EPH）作为通用智能定义，结合预测能力和增益性，为人类与AI智能比较提供了统一框架。


<details>
  <summary>Details</summary>
Motivation: 随着人工智能技术的快速发展，如何公平且一致地比较和评估人类与人工智能的智能成为一个重要的理论问题。现有定义以人类为中心，不适合实证比较，导致研究领域缺乏共识。

Method: 本文首先基于R. Carnap的概念澄清方法提出了评估智能定义的四个标准，随后分析了六种代表性定义的理论优势和局限性，并提出了扩展预测假说（EPH）。

Result: 结果显示，基于预测能力的定义具有高解释力和实证可行性，但无法充分解释预测与行为/收益之间的关系。EPH通过区分自发和反应性预测并引入增益性概念，提供了一个统一的智能解释框架。

Conclusion: 本文认为扩展预测假说（EPH）是最令人满意且通用的定义，适用于人类与人工智能的比较。

Abstract: This paper aims to propose a universal definition of intelligence that enables fair and consistent comparison of human and artificial intelligence (AI). With the rapid development of AI technology in recent years, how to compare and evaluate human and AI intelligence has become an important theoretical issue. However, existing definitions of intelligence are anthropocentric and unsuitable for empirical comparison, resulting in a lack of consensus in the research field.
  This paper first introduces four criteria for evaluating intelligence definitions based on R. Carnap's methodology of conceptual clarification: similarity to explicandum, exactness, fruitfulness, and simplicity. We then examine six representative definitions: IQ testing, complex problem-solving ability, reward optimization, environmental adaptation, learning efficiency, and predictive ability, and clarify their theoretical strengths and limitations.
  The results show that while definitions based on predictive ability have high explanatory power and empirical feasibility, they suffer from an inability to adequately explain the relationship between predictions and behavior/benefits. This paper proposes the Extended Predictive Hypothesis (EPH), which views intelligence as a combination of the ability to accurately predict the future and the ability to benefit from those predictions. Furthermore, by distinguishing predictive ability into spontaneous and reactive predictions and adding the concept of gainability, we present a unified framework for explaining various aspects of intelligence, such as creativity, learning, and future planning. In conclusion, this paper argues that the EPH is the most satisfactory and universal definition for comparing human and AI intelligence.

</details>


### [261] [Software-Hardware Co-optimization for Modular E2E AV Paradigm: A Unified Framework of Optimization Approaches, Simulation Environment and Evaluation Metrics](https://arxiv.org/abs/2601.07393)
*Chengzhi Ji,Xingfeng Li,Zhaodong Lv,Hao Sun,Pan Liu,Hao Frank Yang,Ziyuan Pu*

Main category: cs.AI

TL;DR: 提出了一个软件硬件协同优化框架，显著降低ME2E自动驾驶系统的延迟和能耗，同时保持性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注精度提升，而忽视了推理延迟和能耗等关键系统级因素，导致模型设计日益复杂，阻碍实际部署。软件或硬件单方面的优化效果有限。

Method: 提出了一个可重用的软件和硬件协同优化及闭环评估框架，将软件级模型优化与硬件级计算优化在统一系统级目标下联合集成，并引入多维评估指标。

Result: 实验表明，该框架在多个ME2E自动驾驶堆栈中显著降低推理延迟和能耗，同时保持基准驾驶性能，实现了整体系统级的大幅改进。

Conclusion: 该框架为ME2E自动驾驶系统的高效部署提供了实用且可操作的指导，显著降低了推理延迟和能耗，同时保持了基准水平的驾驶性能。

Abstract: Modular end-to-end (ME2E) autonomous driving paradigms combine modular interpretability with global optimization capability and have demonstrated strong performance. However, existing studies mainly focus on accuracy improvement, while critical system-level factors such as inference latency and energy consumption are often overlooked, resulting in increasingly complex model designs that hinder practical deployment. Prior efforts on model compression and acceleration typically optimize either the software or hardware side in isolation. Software-only optimization cannot fundamentally remove intermediate tensor access and operator scheduling overheads, whereas hardware-only optimization is constrained by model structure and precision. As a result, the real-world benefits of such optimizations are often limited. To address these challenges, this paper proposes a reusable software and hardware co-optimization and closed-loop evaluation framework for ME2E autonomous driving inference. The framework jointly integrates software-level model optimization with hardware-level computation optimization under a unified system-level objective. In addition, a multidimensional evaluation metric is introduced to assess system performance by jointly considering safety, comfort, efficiency, latency, and energy, enabling quantitative comparison of different optimization strategies. Experiments across multiple ME2E autonomous driving stacks show that the proposed framework preserves baseline-level driving performance while significantly reducing inference latency and energy consumption, achieving substantial overall system-level improvements. These results demonstrate that the proposed framework provides practical and actionable guidance for efficient deployment of ME2E autonomous driving systems.

</details>


### [262] [Puzzle it Out: Local-to-Global World Model for Offline Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2601.07463)
*Sijia li,Xinran Li,Shibo Chen,Jun Zhang*

Main category: cs.AI

TL;DR: LOGO世界模型通过局部预测和不确定性采样，提升离线多智能体强化学习的泛化能力，实验表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有离线多智能体强化学习方法过于保守，难以泛化到数据支持范围之外，而模型方法因多智能体系统的高维性和复杂性难以准确建模。

Method: 提出了一种局部到全局（LOGO）的世界模型框架，利用局部预测推断全局状态动态，并通过不确定性感知采样机制加权合成数据。

Result: 在8个场景中与8个基线方法对比，LOGO方法在标准离线多智能体强化学习基准上超越了现有最优方法。

Conclusion: 论文提出了LOGO世界模型，通过局部预测推断全局状态动态，结合不确定性感知采样机制，显著提升了离线多智能体强化学习的泛化能力，并在实验中超越了现有基线方法。

Abstract: Offline multi-agent reinforcement learning (MARL) aims to solve cooperative decision-making problems in multi-agent systems using pre-collected datasets. Existing offline MARL methods primarily constrain training within the dataset distribution, resulting in overly conservative policies that struggle to generalize beyond the support of the data. While model-based approaches offer a promising solution by expanding the original dataset with synthetic data generated from a learned world model, the high dimensionality, non-stationarity, and complexity of multi-agent systems make it challenging to accurately estimate the transitions and reward functions in offline MARL. Given the difficulty of directly modeling joint dynamics, we propose a local-to-global (LOGO) world model, a novel framework that leverages local predictions-which are easier to estimate-to infer global state dynamics, thus improving prediction accuracy while implicitly capturing agent-wise dependencies. Using the trained world model, we generate synthetic data to augment the original dataset, expanding the effective state-action space. To ensure reliable policy learning, we further introduce an uncertainty-aware sampling mechanism that adaptively weights synthetic data by prediction uncertainty, reducing approximation error propagation to policies. In contrast to conventional ensemble-based methods, our approach requires only an additional encoder for uncertainty estimation, significantly reducing computational overhead while maintaining accuracy. Extensive experiments across 8 scenarios against 8 baselines demonstrate that our method surpasses state-of-the-art baselines on standard offline MARL benchmarks, establishing a new model-based baseline for generalizable offline multi-agent learning.

</details>


### [263] [IFDNS: An Iterative Feedback-Driven Neuro-Symbolic Method for Faithful Logical Reasoning](https://arxiv.org/abs/2601.07464)
*Xiaoheng Wang,Tongxuan Liu,Zi Gong,Xianzhe Dong,Yuting Zeng,Minhan Hu,Weizhe Huang,Jing Li*

Main category: cs.AI

TL;DR: IFDNS是一种新型提示方法，通过多轮反馈机制提升LLM的逻辑推理能力，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有基于提示的方法（如CoT）在逻辑推理中存在忠实性问题，神经符号方法则面临信息丢失的挑战。

Method: 采用迭代反馈驱动的神经符号方法（IFDNS），在逻辑提取阶段通过多轮反馈机制准确提取因果关系并转换为命题和逻辑蕴含表达式。

Result: 在六个数据集上的实证评估显示，IFDNS显著提升了CoT和CoT-SC的性能，如在LogiQA上CoT准确率提升9.40%，在PrOntoQA上CoT-SC提升11.70%。

Conclusion: IFDNS通过多轮反馈机制有效解决了LLM在复杂逻辑关系处理中的局限性，显著提升了CoT和CoT-SC的性能。

Abstract: Large language models (LLMs) have demonstrated impressive capabilities across a wide range of reasoning tasks, including logical and mathematical problem-solving. While prompt-based methods like Chain-of-Thought (CoT) can enhance LLM reasoning abilities to some extent, they often suffer from a lack of faithfulness, where the derived conclusions may not align with the generated reasoning chain. To address this issue, researchers have explored neuro-symbolic approaches to bolster LLM logical reasoning capabilities. However, existing neuro-symbolic methods still face challenges with information loss during the process. To overcome these limitations, we introduce Iterative Feedback-Driven Neuro-Symbolic (IFDNS), a novel prompt-based method that employs a multi-round feedback mechanism to address LLM limitations in handling complex logical relationships. IFDNS utilizes iterative feedback during the logic extraction phase to accurately extract causal relationship statements and translate them into propositional and logical implication expressions, effectively mitigating information loss issues. Furthermore, IFDNS is orthogonal to existing prompt methods, allowing for seamless integration with various prompting approaches. Empirical evaluations across six datasets demonstrate the effectiveness of IFDNS in significantly improving the performance of CoT and Chain-of-Thought with Self-Consistency (CoT-SC). Specifically, IFDNS achieves a +9.40% accuracy boost for CoT on the LogiQA dataset and a +11.70% improvement for CoT-SC on the PrOntoQA dataset.

</details>


### [264] [Beyond Dialogue Time: Temporal Semantic Memory for Personalized LLM Agents](https://arxiv.org/abs/2601.07468)
*Miao Su,Yucan Guo,Zhongni Hou,Long Bai,Zixuan Li,Yufei Zhang,Guojun Yin,Wei Lin,Xiaolong Jin,Jiafeng Guo,Xueqi Cheng*

Main category: cs.AI

TL;DR: TSM通过语义时间线和持续性记忆解决现有记忆方法的时间不准确与碎片化问题，实验显示显著性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有方法在记忆的时间维度建模上存在不足，包括时间不准确（按对话时间而非实际发生时间组织）和时间碎片化（忽略持续性信息）。

Method: 提出Temporal Semantic Memory (TSM)框架，构建语义时间线而非对话时间线，整合时间连续且语义相关的信息为持续性记忆，并在查询时结合时间意图检索。

Result: 在LongMemEval和LoCoMo数据集上，TSM相比现有方法准确率提升最高达12.2%。

Conclusion: TSM框架通过建模语义时间点记忆和持续性记忆，显著提升了大型语言模型代理在记忆处理上的性能，实验证明了其有效性。

Abstract: Memory enables Large Language Model (LLM) agents to perceive, store, and use information from past dialogues, which is essential for personalization. However, existing methods fail to properly model the temporal dimension of memory in two aspects: 1) Temporal inaccuracy: memories are organized by dialogue time rather than their actual occurrence time; 2) Temporal fragmentation: existing methods focus on point-wise memory, losing durative information that captures persistent states and evolving patterns. To address these limitations, we propose Temporal Semantic Memory (TSM), a memory framework that models semantic time for point-wise memory and supports the construction and utilization of durative memory. During memory construction, it first builds a semantic timeline rather than a dialogue one. Then, it consolidates temporally continuous and semantically related information into a durative memory. During memory utilization, it incorporates the query's temporal intent on the semantic timeline, enabling the retrieval of temporally appropriate durative memories and providing time-valid, duration-consistent context to support response generation. Experiments on LongMemEval and LoCoMo show that TSM consistently outperforms existing methods and achieves up to 12.2% absolute improvement in accuracy, demonstrating the effectiveness of the proposed method.

</details>


### [265] [Knowledge Distillation for LLM-Based Human Activity Recognition in Homes](https://arxiv.org/abs/2601.07469)
*Julien Cumin,Oussama Er-Rahmany,Xi Chen*

Main category: cs.AI

TL;DR: 研究表明，通过知识蒸馏微调的小型LLM在HAR任务中表现优异，参数大幅减少。


<details>
  <summary>Details</summary>
Motivation: 探索LLM在HAR任务中的应用潜力，尤其是针对智能家居和辅助生活场景。

Method: 在两个最先进的数据集上实验，研究LLM大小对识别性能的影响，并应用知识蒸馏技术微调小型LLM。

Result: 微调后的小型LLM性能接近最大型LLM，参数显著减少。

Conclusion: 使用知识蒸馏技术微调的小型LLM在HAR任务上表现接近最大型LLM，且参数数量减少50倍。

Abstract: Human Activity Recognition (HAR) is a central problem for context-aware applications, especially for smart homes and assisted living. A few very recent studies have shown that Large Language Models (LLMs) can be used for HAR at home, reaching high performance and addressing key challenges. In this paper, we provide new experimental results regarding the use of LLMs for HAR, on two state-of-the-art datasets. More specifically, we show how recognition performance evolves depending on the size of the LLM used. Moreover, we experiment on the use of knowledge distillation techniques to fine-tune smaller LLMs with HAR reasoning examples generated by larger LLMs. We show that such fine-tuned models can perform almost as well as the largest LLMs, while having 50 times less parameters.

</details>


### [266] [Learning How to Remember: A Meta-Cognitive Management Method for Structured and Transferable Agent Memory](https://arxiv.org/abs/2601.07470)
*Sirui Liang,Pengfei Cao,Jian Zhao,Wenhao Teng,Xiangwen Liao,Jun Zhao,Kang Liu*

Main category: cs.AI

TL;DR: MCMA提出可学习的记忆抽象方法，通过记忆副驾驶和层次化记忆结构提升LLM代理的决策能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法以固定表示存储记忆并在单一或隐式抽象级别重用，限制了泛化能力并导致负迁移。

Method: MCMA结合了冻结的任务模型和学习的记忆副驾驶，通过直接偏好优化训练记忆副驾驶来决定记忆的结构、抽象和重用方式，并将记忆组织成抽象层次结构。

Result: 在ALFWorld、ScienceWorld和BabyAI上的实验表明，MCMA在性能、分布外泛化和跨任务迁移方面优于多个基线。

Conclusion: MCMA方法通过将记忆抽象作为可学习的认知技能，显著提升了LLM代理在长视野决策任务中的性能、分布外泛化和跨任务迁移能力。

Abstract: Large language model (LLM) agents increasingly rely on accumulated memory to solve long-horizon decision-making tasks. However, most existing approaches store memory in fixed representations and reuse it at a single or implicit level of abstraction, which limits generalization and often leads to negative transfer when distribution shift. This paper proposes the Meta-Cognitive Memory Abstraction method (MCMA), which treats memory abstraction as a learnable cognitive skill rather than a fixed design choice. MCMA decouples task execution from memory management by combining a frozen task model with a learned memory copilot. The memory copilot is trained using direct preference optimization, it determines how memories should be structured, abstracted, and reused. Memories are further organized into a hierarchy of abstraction levels, enabling selective reuse based on task similarity. When no memory is transferable, MCMA transfers the ability to abstract and manage memory by transferring the memory copilot. Experiments on ALFWorld, ScienceWorld, and BabyAI demonstrate substantial improvements in performance, out-of-distribution generalization, and cross-task transfer over several baselines.

</details>


### [267] [JudgeFlow: Agentic Workflow Optimization via Block Judge](https://arxiv.org/abs/2601.07477)
*Zihan Ma,Zhikai Zhao,Chuanbo Hua,Federico Berto,Jinkyoo Park*

Main category: cs.AI

TL;DR: 论文提出了一种通过细粒度诊断信号优化LLM-based agentic workflows的新方法，显著提升了效率和性能。


<details>
  <summary>Details</summary>
Motivation: 当前优化LLM-based agentic workflows的方法依赖于粗粒度的端到端评估信号，缺乏细粒度的改进指导，导致修改效率低下或影响有限。

Method: 论文提出了一种Evaluation-Judge-Optimization-Update流程，结合可重用逻辑块和Judge模块，通过分析执行轨迹（尤其是失败运行）并分配责任分数，指导优化器聚焦于问题最严重的模块。

Result: 在数学推理和代码生成基准测试中，{\our{}}方法在性能和效率上均优于现有方法。

Conclusion: 该论文提出了一种名为{\our{}}的评估-判断-优化-更新流程，通过引入可重用、可配置的逻辑块和专用的Judge模块，显著提升了LLM-based agentic workflows的效率和可解释性。

Abstract: Optimizing LLM-based agentic workflows is challenging for scaling AI capabilities. Current methods rely on coarse, end-to-end evaluation signals and lack fine-grained signals on where to refine, often resulting in inefficient or low-impact modifications. To address these limitations, we propose {\our{}}, an Evaluation-Judge-Optimization-Update pipeline. We incorporate reusable, configurable logic blocks into agentic workflows to capture fundamental forms of logic. On top of this abstraction, we design a dedicated Judge module that inspects execution traces -- particularly failed runs -- and assigns rank-based responsibility scores to problematic blocks. These fine-grained diagnostic signals are then leveraged by an LLM-based optimizer, which focuses modifications on the most problematic block in the workflow. Our approach improves sample efficiency, enhances interpretability through block-level diagnostics, and provides a scalable foundation for automating increasingly complex agentic workflows. We evaluate {\our{}} on mathematical reasoning and code generation benchmarks, where {\our{}} achieves superior performance and efficiency compared to existing methods. The source code is publicly available at https://github.com/ma-zihan/JudgeFlow.

</details>


### [268] [VirtualEnv: A Platform for Embodied AI Research](https://arxiv.org/abs/2601.07553)
*Kabir Swain,Sijie Han,Ayush Raina,Jin Zhang,Shuang Li,Michael Stopa,Antonio Torralba*

Main category: cs.AI

TL;DR: VirtualEnv是一个基于Unreal Engine 5的模拟平台，用于评估LLM在具身和互动场景中的能力，支持多智能体协作和程序化环境生成，并开源以推动AI与游戏研究的结合。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLM）在推理和决策能力上的不断提升，需要构建一个真实且互动的环境来严格评估其能力。

Method: VirtualEnv基于Unreal Engine 5构建，提供用户友好的API，支持通过自然语言指令部署和控制LLM驱动的智能体。平台整合了大规模LLM和视觉语言模型（VLM），从多模态输入生成新颖环境和结构化任务。

Result: 实验对多个流行LLM在复杂度递增的任务中的表现进行了基准测试，分析了适应性、规划能力和多智能体协调能力的差异。

Conclusion: VirtualEnv作为开源平台发布，旨在推动AI与游戏交叉领域的研究，为具身AI环境中的LLM标准化评估铺平道路，并为沉浸式模拟和互动娱乐的未来发展奠定基础。

Abstract: As large language models (LLMs) continue to improve in reasoning and decision-making, there is a growing need for realistic and interactive environments where their abilities can be rigorously evaluated. We present VirtualEnv, a next-generation simulation platform built on Unreal Engine 5 that enables fine-grained benchmarking of LLMs in embodied and interactive scenarios. VirtualEnv supports rich agent-environment interactions, including object manipulation, navigation, and adaptive multi-agent collaboration, as well as game-inspired mechanics like escape rooms and procedurally generated environments. We provide a user-friendly API built on top of Unreal Engine, allowing researchers to deploy and control LLM-driven agents using natural language instructions. We integrate large-scale LLMs and vision-language models (VLMs), such as GPT-based models, to generate novel environments and structured tasks from multimodal inputs. Our experiments benchmark the performance of several popular LLMs across tasks of increasing complexity, analyzing differences in adaptability, planning, and multi-agent coordination. We also describe our methodology for procedural task generation, task validation, and real-time environment control. VirtualEnv is released as an open-source platform, we aim to advance research at the intersection of AI and gaming, enable standardized evaluation of LLMs in embodied AI settings, and pave the way for future developments in immersive simulations and interactive entertainment.

</details>


### [269] [Beyond Entangled Planning: Task-Decoupled Planning for Long-Horizon Agents](https://arxiv.org/abs/2601.07577)
*Yunfan Li,Bingbing Xu,Xueyun Tian,Xiucheng Xu,Huawei Shen*

Main category: cs.AI

TL;DR: TDP框架通过任务解耦和局部推理，解决了长周期任务规划中的上下文纠缠问题，显著提升了效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有规划方法（逐步规划和一次性规划）因上下文纠缠导致认知负荷高且局部错误易扩散，亟需一种能解耦任务并限制错误传播的框架。

Method: TDP框架通过Supervisor将任务分解为有向无环图（DAG）的子目标，并使用Planner和Executor在限定上下文中进行局部推理和重规划。

Result: 在TravelPlanner、ScienceWorld和HotpotQA上的实验表明，TDP优于基线方法，并减少了高达82%的token消耗。

Conclusion: Task-Decoupled Planning (TDP)通过任务解耦显著提升了长周期任务的执行效率和鲁棒性，同时大幅降低了计算资源消耗。

Abstract: Recent advances in large language models (LLMs) have enabled agents to autonomously execute complex, long-horizon tasks, yet planning remains a primary bottleneck for reliable task execution. Existing methods typically fall into two paradigms: step-wise planning, which is reactive but often short-sighted; and one-shot planning, which generates a complete plan upfront yet is brittle to execution errors. Crucially, both paradigms suffer from entangled contexts, where the agent must reason over a monolithic history spanning multiple sub-tasks. This entanglement increases cognitive load and lets local errors propagate across otherwise independent decisions, making recovery computationally expensive. To address this, we propose Task-Decoupled Planning (TDP), a training-free framework that replaces entangled reasoning with task decoupling. TDP decomposes tasks into a directed acyclic graph (DAG) of sub-goals via a Supervisor. Using a Planner and Executor with scoped contexts, TDP confines reasoning and replanning to the active sub-task. This isolation prevents error propagation and corrects deviations locally without disrupting the workflow. Results on TravelPlanner, ScienceWorld, and HotpotQA show that TDP outperforms strong baselines while reducing token consumption by up to 82%, demonstrating that sub-task decoupling improves both robustness and efficiency for long-horizon agents.

</details>


### [270] [DIAGPaper: Diagnosing Valid and Specific Weaknesses in Scientific Papers via Multi-Agent Reasoning](https://arxiv.org/abs/2601.07611)
*Zhuoyang Zou,Abolfazl Ansari,Delvin Ce Zhang,Dongwon Lee,Wenpeng Yin*

Main category: cs.AI

TL;DR: DIAGPaper是一个多代理框架，通过定制、反驳和优先级模块，有效识别并优先呈现论文弱点，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在模拟人类角色、假设弱点有效性及弱点优先级方面存在不足，DIAGPaper旨在解决这些挑战。

Method: 提出了DIAGPaper框架，包含三个模块：定制器模块模拟人类定义的评审标准并实例化多个评审代理；反驳模块引入作者代理与评审代理进行结构化辩论；优先级模块从大规模人类评审实践中学习评估弱点严重性。

Result: 在AAAR和ReviewCritique两个基准测试中，DIAGPaper表现显著优于现有方法。

Conclusion: DIAGPaper显著优于现有方法，通过生成更有效且更针对论文的弱点，并以用户导向的优先级方式呈现。

Abstract: Paper weakness identification using single-agent or multi-agent LLMs has attracted increasing attention, yet existing approaches exhibit key limitations. Many multi-agent systems simulate human roles at a surface level, missing the underlying criteria that lead experts to assess complementary intellectual aspects of a paper. Moreover, prior methods implicitly assume identified weaknesses are valid, ignoring reviewer bias, misunderstanding, and the critical role of author rebuttals in validating review quality. Finally, most systems output unranked weakness lists, rather than prioritizing the most consequential issues for users. In this work, we propose DIAGPaper, a novel multi-agent framework that addresses these challenges through three tightly integrated modules. The customizer module simulates human-defined review criteria and instantiates multiple reviewer agents with criterion-specific expertise. The rebuttal module introduces author agents that engage in structured debate with reviewer agents to validate and refine proposed weaknesses. The prioritizer module learns from large-scale human review practices to assess the severity of validated weaknesses and surfaces the top-K severest ones to users. Experiments on two benchmarks, AAAR and ReviewCritique, demonstrate that DIAGPaper substantially outperforms existing methods by producing more valid and more paper-specific weaknesses, while presenting them in a user-oriented, prioritized manner.

</details>


### [271] [SALT-KG: A Benchmark for Semantics-Aware Learning on Enterprise Tables](https://arxiv.org/abs/2601.07638)
*Isaiah Onando Mulang,Felix Sasaki,Tassilo Klein,Jonas Kolk,Nikolay Grechanov,Johannes Hoffart*

Main category: cs.AI

TL;DR: SALT-KG扩展SALT基准，结合OBKG评估语义感知学习，揭示模型语义利用短板，推动表格基础模型发展。


<details>
  <summary>Details</summary>
Motivation: 解决企业表格数据中语义感知学习的挑战，推动基础模型在结构化数据上的语义链接能力。

Method: 扩展SALT基准，引入SALT-KG，通过链接多表事务数据与OBKG（包含字段级描述、关系依赖和业务对象类型），评估模型在表格证据和上下文语义联合推理上的能力。

Result: 实证分析显示，元数据特征在传统预测指标上带来适度改进，但更突出模型在语义上下文利用上的不足。

Conclusion: SALT-KG通过将多表事务数据与结构化操作业务知识图（OBKG）结合，为基于语义的表格学习建立了基准，揭示了模型在利用语义上下文方面的不足，并推动了基于声明性知识的表格基础模型的发展。

Abstract: Building upon the SALT benchmark for relational prediction (Klein et al., 2024), we introduce SALT-KG, a benchmark for semantics-aware learning on enterprise tables. SALT-KG extends SALT by linking its multi-table transactional data with a structured Operational Business Knowledge represented in a Metadata Knowledge Graph (OBKG) that captures field-level descriptions, relational dependencies, and business object types. This extension enables evaluation of models that jointly reason over tabular evidence and contextual semantics, an increasingly critical capability for foundation models on structured data. Empirical analysis reveals that while metadata-derived features yield modest improvements in classical prediction metrics, these metadata features consistently highlight gaps in the ability of models to leverage semantics in relational context. By reframing tabular prediction as semantics-conditioned reasoning, SALT-KG establishes a benchmark to advance tabular foundation models grounded in declarative knowledge, providing the first empirical step toward semantically linked tables in structured data at enterprise scale.

</details>


### [272] [Beyond Static Tools: Test-Time Tool Evolution for Scientific Reasoning](https://arxiv.org/abs/2601.07641)
*Jiaxuan Lu,Ziyu Kong,Yemin Wang,Rong Fu,Haiyuan Wan,Cheng Yang,Wenjie Lou,Haoran Sun,Lilong Wang,Yankai Jiang,Xiaosong Wang,Xiao Sun,Dongzhan Zhou*

Main category: cs.AI

TL;DR: TTE通过动态工具进化解决了科学领域中静态工具库的局限性，在SciEvo基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于LLM的代理依赖静态预定义工具库，在科学领域中工具稀疏、异构且不完整，导致其表现不佳。

Method: 提出了Test-Time Tool Evolution（TTE）范式，允许代理在推理过程中动态合成、验证和进化可执行工具。

Result: TTE在SciEvo基准测试中表现出色，实现了高准确性和工具效率，并支持跨领域计算工具的适应。

Conclusion: TTE（Test-Time Tool Evolution）提出了一种新范式，通过动态合成、验证和进化工具，克服了静态工具库的局限性，在科学推理任务中实现了最先进的性能。

Abstract: The central challenge of AI for Science is not reasoning alone, but the ability to create computational methods in an open-ended scientific world. Existing LLM-based agents rely on static, pre-defined tool libraries, a paradigm that fundamentally fails in scientific domains where tools are sparse, heterogeneous, and intrinsically incomplete. In this paper, we propose Test-Time Tool Evolution (TTE), a new paradigm that enables agents to synthesize, verify, and evolve executable tools during inference. By transforming tools from fixed resources into problem-driven artifacts, TTE overcomes the rigidity and long-tail limitations of static tool libraries. To facilitate rigorous evaluation, we introduce SciEvo, a benchmark comprising 1,590 scientific reasoning tasks supported by 925 automatically evolved tools. Extensive experiments show that TTE achieves state-of-the-art performance in both accuracy and tool efficiency, while enabling effective cross-domain adaptation of computational tools. The code and benchmark have been released at https://github.com/lujiaxuan0520/Test-Time-Tool-Evol.

</details>


### [273] [Active Evaluation of General Agents: Problem Definition and Comparison of Baseline Algorithms](https://arxiv.org/abs/2601.07651)
*Marc Lanctot,Kate Larson,Ian Gemp,Michael Kaisers*

Main category: cs.AI

TL;DR: 本文提出了一种主动评估多任务代理的框架，发现Elo评分系统在实践中可靠，Soft Condorcet Optimization在真实数据中表现更优，高任务变异时比例表示任务选择更高效。


<details>
  <summary>Details</summary>
Motivation: 随着智能代理能力的多样化，评估的复杂性和成本显著增加，需要一种高效的方法来减少评估样本的需求。

Method: 提出了一种主动评估多任务代理的框架，通过在线迭代选择任务和代理进行评分，评估算法随时间报告代理排名并与真实排名对比。

Result: Elo评分系统在实践中表现可靠，Soft Condorcet Optimization在真实数据中优于Elo，高任务变异时比例表示任务选择更有效。

Conclusion: 本文发现Elo评分系统在实践中是减少排名误差的可靠选择，而Soft Condorcet Optimization在真实Atari代理评估中表现更优。当任务变异较大时，基于比例表示的任务选择能更高效地减少排名误差。

Abstract: As intelligent agents become more generally-capable, i.e. able to master a wide variety of tasks, the complexity and cost of properly evaluating them rises significantly. Tasks that assess specific capabilities of the agents can be correlated and stochastic, requiring many samples for accurate comparisons, leading to added costs. In this paper, we propose a formal definition and a conceptual framework for active evaluation of agents across multiple tasks, which assesses the performance of ranking algorithms as a function of number of evaluation data samples. Rather than curating, filtering, or compressing existing data sets as a preprocessing step, we propose an online framing: on every iteration, the ranking algorithm chooses the task and agents to sample scores from. Then, evaluation algorithms report a ranking of agents on each iteration and their performance is assessed with respect to the ground truth ranking over time. Several baselines are compared under different experimental contexts, with synthetic generated data and simulated online access to real evaluation data from Atari game-playing agents. We find that the classical Elo rating system -- while it suffers from well-known failure modes, in theory -- is a consistently reliable choice for efficient reduction of ranking error in practice. A recently-proposed method, Soft Condorcet Optimization, shows comparable performance to Elo on synthetic data and significantly outperforms Elo on real Atari agent evaluation. When task variation from the ground truth is high, selecting tasks based on proportional representation leads to higher rate of ranking error reduction.

</details>


### [274] [Reasoning Models Will Blatantly Lie About Their Reasoning](https://arxiv.org/abs/2601.07663)
*William Walden*

Main category: cs.AI

TL;DR: 研究发现大型推理模型会否认依赖提示，尽管实验证明它们确实使用了提示，这对模型的可解释性提出了挑战。


<details>
  <summary>Details</summary>
Motivation: 探索LRMs是否不仅会省略提示信息，还会故意否认依赖这些提示，从而进一步揭示模型的可信度问题。

Method: 本研究扩展了Chen等人（2025）的工作，通过实验验证LRMs在回答选择题时对提示的使用情况，尤其是在被直接询问时否认依赖提示的行为。

Result: 实验显示，LRMs会明确否认依赖提示，即使在被直接询问或允许使用提示的情况下，实际行为却表明它们在利用提示。

Conclusion: 研究结果表明，大型推理模型（LRMs）不仅会省略提示信息，甚至会否认依赖这些提示，这对思维链（CoT）监控和可解释性提出了挑战。

Abstract: It has been shown that Large Reasoning Models (LRMs) may not *say what they think*: they do not always volunteer information about how certain parts of the input influence their reasoning. But it is one thing for a model to *omit* such information and another, worse thing to *lie* about it. Here, we extend the work of Chen et al. (2025) to show that LRMs will do just this: they will flatly deny relying on hints provided in the prompt in answering multiple choice questions -- even when directly asked to reflect on unusual (i.e. hinted) prompt content, even when allowed to use hints, and even though experiments *show* them to be using the hints. Our results thus have discouraging implications for CoT monitoring and interpretability.

</details>


### [275] [Predictive Analytics for Dementia: Machine Learning on Healthcare Data](https://arxiv.org/abs/2601.07685)
*Shafiul Ajam Opee,Nafiz Fahad,Anik Sen,Rasel Ahmed,Fariha Jahan,Md. Kishor Morol,Md Rashedul Islam*

Main category: cs.AI

TL;DR: 本研究利用机器学习技术提升痴呆症预测，LDA模型表现最佳（98%准确率），并强调了模型可解释性和特征相关性的重要性。


<details>
  <summary>Details</summary>
Motivation: 痴呆症是一种影响认知和情感功能的复杂综合征，本研究旨在通过机器学习技术提升痴呆症预测的准确性。

Method: 研究应用了监督学习算法，包括KNN、QDA、LDA和高斯过程分类器，并采用SMOTE和TF-IDF向量化技术解决类别不平衡问题。

Result: 在所有模型中，LDA取得了最高的测试准确率（98%），并揭示了痴呆症与APOE-epsilon4等位基因及糖尿病等慢性病的相关性。

Conclusion: 本研究强调了模型可解释性的重要性，并倡导未来在痴呆症护理中整合可解释AI方法以进一步提升预测能力。

Abstract: Dementia is a complex syndrome impacting cognitive and emotional functions, with Alzheimer's disease being the most common form. This study focuses on enhancing dementia prediction using machine learning (ML) techniques on patient health data. Supervised learning algorithms are applied in this study, including K-Nearest Neighbors (KNN), Quadratic Discriminant Analysis (QDA), Linear Discriminant Analysis (LDA), and Gaussian Process Classifiers. To address class imbalance and improve model performance, techniques such as Synthetic Minority Over-sampling Technique (SMOTE) and Term Frequency-Inverse Document Frequency (TF-IDF) vectorization were employed. Among the models, LDA achieved the highest testing accuracy of 98%. This study highlights the importance of model interpretability and the correlation of dementia with features such as the presence of the APOE-epsilon4 allele and chronic conditions like diabetes. This research advocates for future ML innovations, particularly in integrating explainable AI approaches, to further improve predictive capabilities in dementia care.

</details>


### [276] [Benchmarking Small Language Models and Small Reasoning Language Models on System Log Severity Classification](https://arxiv.org/abs/2601.07790)
*Yahya Masri,Emily Ma,Zifu Wang,Joseph Rogers,Chaowei Yang*

Main category: cs.AI

TL;DR: 该论文提出将严重性分类作为评估运行时日志理解的基准，而非最终任务。通过评估多种小型语言模型在真实日志数据上的表现，发现RAG显著提升部分模型性能，而模型架构、训练目标和检索上下文能力共同决定表现。研究强调了小型模型在数字孪生系统中的实时应用潜力。


<details>
  <summary>Details</summary>
Motivation: 系统日志对于监控和诊断现代计算基础设施至关重要，但其规模和复杂性需要可靠且高效的自动解释。由于严重性级别是系统日志消息中预定义的元数据，仅让模型对它们进行分类提供的独立实用价值有限，很少揭示其底层解释系统日志的能力。

Method: 使用真实世界的journalctl数据从Linux生产服务器中，评估了九种小型语言模型（SLMs）和小型推理语言模型（SRLMs）在零样本、少样本和检索增强生成（RAG）提示下的表现。

Result: 结果显示强烈的分层现象。Qwen3-4B在RAG下达到最高准确率95.64%，而Gemma3-1B在少样本提示下从20.25%提高到85.28%。值得注意的是，微小的Qwen3-0.6B尽管在没有检索的情况下表现较弱，但仍达到88.12%的准确率。相比之下，包括Qwen3-1.7B和DeepSeek-R1-Distill-Qwen-1.5B在内的几种SRLM在配对RAG时性能大幅下降。效率测量进一步区分了模型：大多数Gemma和Llama变体每日志完成推理时间不到1.2秒，而Phi-4-Mini-Reasoning每日志超过228秒，准确率却不到10%。

Conclusion: 通过强调小型可部署模型，该基准与数字孪生（DT）系统的实时需求保持一致，并表明严重性分类可以作为评估模型能力和实时可部署性的视角，对根本原因分析（RCA）和更广泛的DT集成具有影响。

Abstract: System logs are crucial for monitoring and diagnosing modern computing infrastructure, but their scale and complexity require reliable and efficient automated interpretation. Since severity levels are predefined metadata in system log messages, having a model merely classify them offers limited standalone practical value, revealing little about its underlying ability to interpret system logs. We argue that severity classification is more informative when treated as a benchmark for probing runtime log comprehension rather than as an end task. Using real-world journalctl data from Linux production servers, we evaluate nine small language models (SLMs) and small reasoning language models (SRLMs) under zero-shot, few-shot, and retrieval-augmented generation (RAG) prompting. The results reveal strong stratification. Qwen3-4B achieves the highest accuracy at 95.64% with RAG, while Gemma3-1B improves from 20.25% under few-shot prompting to 85.28% with RAG. Notably, the tiny Qwen3-0.6B reaches 88.12% accuracy despite weak performance without retrieval. In contrast, several SRLMs, including Qwen3-1.7B and DeepSeek-R1-Distill-Qwen-1.5B, degrade substantially when paired with RAG. Efficiency measurements further separate models: most Gemma and Llama variants complete inference in under 1.2 seconds per log, whereas Phi-4-Mini-Reasoning exceeds 228 seconds per log while achieving <10% accuracy. These findings suggest that (1) architectural design, (2) training objectives, and (3) the ability to integrate retrieved context under strict output constraints jointly determine performance. By emphasizing small, deployable models, this benchmark aligns with real-time requirements of digital twin (DT) systems and shows that severity classification serves as a lens for evaluating model competence and real-time deployability, with implications for root cause analysis (RCA) and broader DT integration.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [277] [Autonomous QA Agent: A Retrieval-Augmented Framework for Reliable Selenium Script Generation](https://arxiv.org/abs/2601.06034)
*Dudekula Kasim Vali*

Main category: cs.SE

TL;DR: Autonomous QA Agent利用RAG系统，通过结合项目文档和HTML结构生成Selenium脚本，显著减少幻觉，提升测试脚本的准确性和执行成功率。


<details>
  <summary>Details</summary>
Motivation: 软件测试在软件开发周期中至关重要，但将需求转化为可执行测试脚本的过程仍然手动且容易出错。尽管大型语言模型（LLMs）可以生成代码，但它们经常产生不存在的UI元素幻觉。

Method: 提出了Autonomous QA Agent，一个基于检索增强生成（RAG）的系统，通过将Selenium脚本生成与项目特定文档和HTML结构相结合。系统通过将多种格式（Markdown、PDF、HTML）摄入向量数据库，在生成前检索相关上下文。

Result: 在20个电子商务测试场景的评估中，RAG方法实现了100%（20/20）的语法有效性和90%（18/20，95% CI: [85%, 95%]，p < 0.001）的执行成功率，而标准LLM生成仅为30%。

Conclusion: 该方法通过将生成过程锚定在实际DOM结构上，显著减少了幻觉现象，展示了RAG在自动化UI测试中的潜力。

Abstract: Software testing is critical in the software development lifecycle, yet translating requirements into executable test scripts remains manual and error-prone. While Large Language Models (LLMs) can generate code, they often hallucinate non-existent UI elements. We present the Autonomous QA Agent, a Retrieval-Augmented Generation (RAG) system that grounds Selenium script generation in project-specific documentation and HTML structure. By ingesting diverse formats (Markdown, PDF, HTML) into a vector database, our system retrieves relevant context before generation. Evaluation on 20 e-commerce test scenarios shows our RAG approach achieves 100% (20/20) syntax validity and 90% (18/20, 95% CI: [85%, 95%], p < 0.001) execution success, compared to 30% for standard LLM generation. While our evaluation is limited to a single domain, our method significantly reduces hallucinations by grounding generation in actual DOM structure, demonstrating RAG's potential for automated UI testing.

</details>


### [278] [Contract2Plan: Verified Contract-Grounded Retrieval-Augmented Optimization for BOM-Aware Procurement and Multi-Echelon Inventory Planning](https://arxiv.org/abs/2601.06164)
*Sahil Agarwal*

Main category: cs.SE

TL;DR: Contract2Plan是一个经过验证的GenAI到优化器的流程，通过插入基于求解器的合规性检查门，确保采购和库存规划的可行性和合规性。


<details>
  <summary>Details</summary>
Motivation: 传统的LLM提取或纯LLM决策流程存在条款遗漏、单位错误和未解决冲突等问题，导致不可行计划或合同违规，尤其是在BOM耦合的情况下。

Method: 系统通过检索条款证据、提取类型化约束模式、将约束编译为BOM感知的MILP问题，并利用求解器诊断验证基础、资格、一致性和可行性，触发有针对性的修复或放弃。

Result: 在包含500个实例的合成微基准测试中，纯提取规划显示出重尾后悔和非平凡的MOQ违规发生率，验证了验证作为合同基础规划系统首要组件的必要性。

Conclusion: Contract2Plan通过引入基于求解器的合规性检查门，显著提高了采购和库存规划的可行性和合规性，避免了因条款提取错误或冲突导致的不可行计划或合同违规。

Abstract: Procurement and inventory planning is governed not only by demand forecasts and bills of materials (BOMs), but also by operational terms in contracts and supplier documents (e.g., MOQs, lead times, price tiers, allocation caps, substitution approvals). LLM-based extraction can speed up structuring these terms, but extraction-only or LLM-only decision pipelines are brittle: missed clauses, unit errors, and unresolved conflicts can yield infeasible plans or silent contract violations, amplified by BOM coupling. We introduce Contract2Plan, a verified GenAI-to-optimizer pipeline that inserts a solver-based compliance gate before plans are emitted. The system retrieves clause evidence with provenance, extracts a typed constraint schema with evidence spans, compiles constraints into a BOM-aware MILP, and verifies grounding, eligibility, consistency, and feasibility using solver diagnostics, triggering targeted repair or abstention when automation is unsafe. We formalize which clause classes admit conservative repair with contract-safe feasibility guarantees and which require human confirmation. A self-contained synthetic micro-benchmark (500 instances; T=5) computed by exact enumeration under an execution model with MOQ uplift and emergency purchases shows heavy-tailed regret and nontrivial MOQ-violation incidence for extraction-only planning, motivating verification as a first-class component of contract-grounded planning systems.

</details>


### [279] [Attention Mechanism and Heuristic Approach: Context-Aware File Ranking Using Multi-Head Self-Attention](https://arxiv.org/abs/2601.06185)
*Pradeep Kumar Sharma,Shantanu Godbole,Sarada Prasad Jena,Hritvik Shrivastava*

Main category: cs.SE

TL;DR: 该论文提出用多头自注意力机制改进变更影响分析，显著提升召回率并接近专家判断水平。


<details>
  <summary>Details</summary>
Motivation: 现有确定性方法在变更影响分析中召回率存在瓶颈，原因是忽略了特征间的上下文依赖关系。

Method: 提出应用多头自注意力机制（Multi-Head Self-Attention）作为后确定性评分细化方法，动态调整特征重要性，并结合确定性评分以保持可解释性。

Result: 在200个测试案例中，自注意力机制将Top-50召回率从62-65%提升至78-82%，专家主观准确性评分从6.5/10提高到8.6/10。

Conclusion: 通过引入多头自注意力机制作为后确定性评分细化方法，该研究显著提升了变更影响分析中的Top-50召回率，并缩小了自动化与专家判断之间的推理能力差距。

Abstract: The identification and ranking of impacted files within software reposi-tories is a key challenge in change impact analysis. Existing deterministic approaches that combine heuristic signals, semantic similarity measures, and graph-based centrality metrics have demonstrated effectiveness in nar-rowing candidate search spaces, yet their recall plateaus. This limitation stems from the treatment of features as linearly independent contributors, ignoring contextual dependencies and relationships between metrics that characterize expert reasoning patterns. To address this limitation, we propose the application of Multi-Head Self-Attention as a post-deterministic scoring refinement mechanism. Our approach learns contextual weighting between features, dynamically adjust-ing importance levels per file based on relational behavior exhibited across candidate file sets. The attention mechanism produces context-aware adjustments that are additively combined with deterministic scores, pre-serving interpretability while enabling reasoning similar to that performed by experts when reviewing change surfaces. We focus on recall rather than precision, as false negatives (missing impacted files) are far more costly than false positives (irrelevant files that can be quickly dismissed during review). Empirical evaluation on 200 test cases demonstrates that the introduc-tion of self-attention improves Top-50 recall from approximately 62-65% to between 78-82% depending on repository complexity and structure, achiev-ing 80% recall at Top-50 files. Expert validation yields improvement from 6.5/10 to 8.6/10 in subjective accuracy alignment. This transformation bridges the reasoning capability gap between deterministic automation and expert judgment, improving recall in repository-aware effort estimation.

</details>


### [280] [RiskBridge: Turning CVEs into Business-Aligned Patch Priorities](https://arxiv.org/abs/2601.06201)
*Yelena Mujibur Sheikh,Awez Akhtar Khatik,Luoxi Tang,Yuqiao Meng,Zhaohan Xi*

Main category: cs.SE

TL;DR: RiskBridge是一种可解释、合规感知的漏洞管理框架，整合多源情报和优化分析，显著提升漏洞修复效率和合规性。


<details>
  <summary>Details</summary>
Motivation: 企业面临网络安全漏洞激增，传统框架如CVSS静态评估无法考虑漏洞利用概率、合规紧迫性和运营影响，导致修复效率低下。

Method: RiskBridge采用零日暴露模拟（ZDES）模型预测漏洞利用概率，政策即代码引擎自动转换监管要求，以及ROI驱动的优化器最大化风险降低效果。

Result: 实验评估显示，RiskBridge相比现有商业基准，将剩余风险降低88%，SLA合规性提升18天，修复效率提高35%。

Conclusion: RiskBridge框架通过整合多源情报、概率建模和优化分析，显著提升了漏洞管理的效率和合规性，代表了现代企业环境中自动化、可解释和以业务为中心的漏洞管理方向。

Abstract: Enterprises are confronted with an unprece- dented escalation in cybersecurity vulnerabil- ities, with thousands of new CVEs disclosed each month. Conventional prioritization frame- works such as CVSS offer static severity met- rics that fail to account for exploit probabil- ity, compliance urgency, and operational im- pact, resulting in inefficient and delayed re- mediation. This paper introduces RiskBridge, an explainable and compliance-aware vulner- ability management framework that integrates multi-source intelligence from CVSS v4, EPSS, and CISA KEV to produce dynamic, business- aligned patch priorities. RiskBridge employs a probabilistic Zero-Day Exposure Simulation (ZDES) model to fore- cast near-term exploit likelihood, a Policy-as- Code Engine to translate regulatory mandates (e.g., PCI DSS, NIST SP 800-53) into auto- mated SLA logic, and an ROI-driven Opti- mizer to maximize cumulative risk reduction per remediation effort. Experimental evalua- tions using live CVE datasets demonstrate an 88% reduction in residual risk, an 18-day improvement in SLA compliance, and a 35% increase in remediation efficiency compared to state-of-the-art commercial baselines. These findings validate RiskBridge as a prac- tical and auditable decision-intelligence sys- tem that unifies probabilistic modeling, com- pliance reasoning, and optimization analytics. The framework represents a step toward auto- mated, explainable, and business-centric vul- nerability management in modern enterprise environments

</details>


### [281] [Self-Admitted Technical Debt in LLM Software: An Empirical Comparison with ML and Non-ML Software](https://arxiv.org/abs/2601.06266)
*Niruthiha Selvanayagam,Manel Abdellatif,Taher A. Ghaleb*

Main category: cs.SE

TL;DR: LLM系统的技术债务积累率与ML系统相近，但无债务状态更长，并发现三种LLM特有的债务形式。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM时代的技术债务（SATD）表现与演化，填补现有研究空白。

Method: 研究通过对比477个仓库（LLM、ML和非ML各159个）中的SATD，进行生存分析，并定性分析377个SATD实例。

Result: LLM仓库的SATD积累率与ML系统相近（3.95% vs. 4.10%），但无债务状态持续时间更长（492天 vs. 204天）。研究还发现三种LLM特有的技术债务形式。

Conclusion: 研究发现，尽管LLM系统在架构复杂性上与传统ML系统相似，但其技术债务（SATD）积累速度相近，但LLM系统保持无债务状态的时间更长。此外，研究还揭示了三种LLM特有的技术债务形式。

Abstract: Self-admitted technical debt (SATD), referring to comments flagged by developers that explicitly acknowledge suboptimal code or incomplete functionality, has received extensive attention in machine learning (ML) and traditional (Non-ML) software. However, little is known about how SATD manifests and evolves in contemporary Large Language Model (LLM)-based systems, whose architectures, workflows, and dependencies differ fundamentally from both traditional and pre-LLM ML software. In this paper, we conduct the first empirical study of SATD in the LLM era, replicating and extending prior work on ML technical debt to modern LLM-based systems. We compare SATD prevalence across LLM, ML, and non-ML repositories across a total of 477 repositories (159 per category). We perform survival analysis of SATD introduction and removal to understand the dynamics of technical debt across different development paradigms. Surprisingly, despite their architectural complexity, our results reveal that LLM repositories accumulate SATD at similar rates to ML systems (3.95% vs. 4.10%). However, we observe that LLM repositories remain debt-free 2.4x longer than ML repositories (a median of 492 days vs. 204 days), and then start to accumulate technical debt rapidly. Moreover, our qualitative analysis of 377 SATD instances reveals three new forms of technical debt unique to LLM-based development that have not been reported in prior research: Model-Stack Workaround Debt, Model Dependency Debt, and Performance Optimization Debt. Finally, by mapping SATD to stages of the LLM development pipeline, we observe that debt concentrates

</details>


### [282] [Automated QoR improvement in OpenROAD with coding agents](https://arxiv.org/abs/2601.06268)
*Amur Ghose,Junyeong Jang,Andrew B. Kahng,Jakang Lee*

Main category: cs.SE

TL;DR: AuDoPEDA利用LLMs自动化EDA代码改进，显著提升OpenROAD性能，减少布线长度和时钟周期。


<details>
  <summary>Details</summary>
Motivation: EDA发展受限于专家资源短缺，而LLMs在编码和科学推理任务中的优异表现尚未在EDA技术中得到充分测试。

Method: 基于OpenAI模型和Codex类代理构建的自主编码系统，通过读取OpenROAD、提出研究方向、扩展为实施步骤并提交可执行差异。

Result: 在OpenROAD实验中，实现了布线长度减少5.9%和有效时钟周期减少10.0%。

Conclusion: AuDoPEDA展示了LLMs在EDA技术中的潜力，通过闭环框架和自动化流程显著提升了OpenROAD的性能指标。

Abstract: EDA development and innovation has been constrained by scarcity of expert engineering resources. While leading LLMs have demonstrated excellent performance in coding and scientific reasoning tasks, their capacity to advance EDA technology itself has been largely untested. We present AuDoPEDA, an autonomous, repository-grounded coding system built atop OpenAI models and a Codex-class agent that reads OpenROAD, proposes research directions, expands them into implementation steps, and submits executable diffs. Our contributions include (i) a closed-loop LLM framework for EDA code changes; (ii) a task suite and evaluation protocol on OpenROAD for PPA-oriented improvements; and (iii) end-to-end demonstrations with minimal human oversight. Experiments in OpenROAD achieve routed wirelength reductions of up to 5.9%, and effective clock period reductions of up to 10.0%.

</details>


### [283] [Mining Quantum Software Patterns in Open-Source Projects](https://arxiv.org/abs/2601.06281)
*Neilson Carlos Leite Ramalho,Erico A. da Silva,Higor Amario de Souza,Marcos Lordello Chaim*

Main category: cs.SE

TL;DR: 本文通过分析985个Jupyter Notebooks，识别了9种量子计算新模式，展示了开发者如何从基础到高级应用这些模式，表明量子软件工程正在成熟。


<details>
  <summary>Details</summary>
Motivation: 研究量子计算模式在实际中的应用，以填补量子软件工程中框架和高级抽象开发的空白。

Method: 通过构建知识库（来自Qiskit、PennyLane和Classiq三个框架）并开发可复用的语义搜索工具，对985个Jupyter Notebooks进行了实证研究。

Result: 识别并记录了9种新模式，发现开发者从基础电路工具到领域特定应用（如金融和优化）三个层次使用模式。

Conclusion: 量子计算领域正在成熟，开发者越来越多地使用高级构建块来解决实际问题，这表明量子软件工程的发展趋势。

Abstract: Quantum computing has become an active research field in recent years, as its applications in fields such as cryptography, optimization, and materials science are promising. Along with these developments, challenges and opportunities exist in the field of Quantum Software Engineering, as the development of frameworks and higher-level abstractions has attracted practitioners from diverse backgrounds. Unlike initial quantum frameworks based on the circuit model, recent frameworks and libraries leverage higher-level abstractions for creating quantum programs. This paper presents an empirical study of 985 Jupyter Notebooks from 80 open-source projects to investigate how quantum patterns are applied in practice. Our work involved two main stages. First, we built a knowledge base from three quantum computing frameworks (Qiskit, PennyLane, and Classiq). This process led us to identify and document 9 new patterns that refine and extend the existing quantum computing pattern catalog. Second, we developed a reusable semantic search tool to automatically detect these patterns across our large-scale dataset, providing a practitioner-focused analysis. Our results show that developers use patterns in three levels: from foundational circuit utilities, to common algorithmic primitives (e.g., Amplitude Amplification), up to domain-specific applications for finance and optimization. This indicates a maturing field where developers are increasingly using high-level building blocks to solve real-world problems.

</details>


### [284] [Foundational Analysis of Safety Engineering Requirements (SAFER)](https://arxiv.org/abs/2601.06335)
*Noga Chemo,Yaniv Mordecai,Yoram Reich*

Main category: cs.SE

TL;DR: SAFER是一个结合生成式AI的模型驱动框架，用于提升安全需求分析的效率和可靠性，特别适用于复杂安全关键系统。


<details>
  <summary>Details</summary>
Motivation: 安全需求常由多个目标不协调的利益相关者指定，导致缺口、重复和矛盾，威胁系统安全和合规性。现有方法多为非正式且不足以应对这些挑战。

Method: SAFER采用模型驱动的系统工程技术，通过生成式AI分析需求规范模型，实现需求与系统功能的映射、识别不足的需求规范、检测重复需求及发现需求集中的矛盾。

Result: 在自主无人机系统上的应用表明，SAFER显著提升了需求不一致性的检测效率，优化了安全工程流程的效率和可靠性。

Conclusion: SAFER框架通过结合生成式AI和形式化模型，显著提升了安全工程需求的生成与分析效率，增强了复杂安全关键系统的可靠性和安全性。

Abstract: We introduce a framework for Foundational Analysis of Safety Engineering Requirements (SAFER), a model-driven methodology supported by Generative AI to improve the generation and analysis of safety requirements for complex safety-critical systems. Safety requirements are often specified by multiple stakeholders with uncoordinated objectives, leading to gaps, duplications, and contradictions that jeopardize system safety and compliance. Existing approaches are largely informal and insufficient for addressing these challenges. SAFER enhances Model-Based Systems Engineering (MBSE) by consuming requirement specification models and generating the following results: (1) mapping requirements to system functions, (2) identifying functions with insufficient requirement specifications, (3) detecting duplicate requirements, and (4) identifying contradictions within requirement sets. SAFER provides structured analysis, reporting, and decision support for safety engineers. We demonstrate SAFER on an autonomous drone system, significantly improving the detection of requirement inconsistencies, enhancing both efficiency and reliability of the safety engineering process. We show that Generative AI must be augmented by formal models and queried systematically, to provide meaningful early-stage safety requirement specifications and robust safety architectures.

</details>


### [285] [Architecting AgentOps Needs CHANGE](https://arxiv.org/abs/2601.06456)
*Shaunak Biswas,Hiya Bhatt,Karthik Vaidhyanathan*

Main category: cs.SE

TL;DR: 提出了CHANGE框架，以应对Agentic AI系统的非确定性和持续演化特性，强调动态协同演化的架构思路。


<details>
  <summary>Details</summary>
Motivation: Agentic AI系统的行为具有非确定性，传统DevOps或MLOps的管理原则无法有效应对，需重新思考其架构。

Method: 提出了CHANGE概念框架，包含Contextualize、Harmonize、Anticipate、Negotiate、Generate和Evolve六大能力，并通过客户支持系统场景进行说明。

Result: CHANGE框架为设计AgentOps平台奠定了基础，支持Agentic AI系统的动态协同演化。

Conclusion: CHANGE框架为Agentic AI系统的生命周期管理提供了新的架构思路，强调适应不确定性和持续演化的系统特性。

Abstract: The emergence of Agentic AI systems has outpaced the architectural thinking required to operate them effectively. These agents differ fundamentally from traditional software: their behavior is not fixed at deployment but continuously shaped by experience, feedback, and context. Applying operational principles inherited from DevOps or MLOps, built for deterministic software and traditional ML systems, assumes that system behavior can be managed through versioning, monitoring, and rollback. This assumption breaks down for Agentic AI systems whose learning trajectories diverge over time. This introduces non-determinism making system reliability a challenge at runtime. We argue that architecting such systems requires a shift from managing control loops to enabling dynamic co-evolution among agents, infrastructure, and human oversight. To guide this shift, we introduce CHANGE, a conceptual framework comprising six capabilities for operationalizing Agentic AI systems: Contextualize, Harmonize, Anticipate, Negotiate, Generate, and Evolve. CHANGE provides a foundation for architecting an AgentOps platform to manage the lifecycle of evolving Agentic AI systems, illustrated through a customer-support system scenario. In doing so, CHANGE redefines software architecture for an era where adaptation to uncertainty and continuous evolution are inherent properties of the system.

</details>


### [286] [Coding in a Bubble? Evaluating LLMs in Resolving Context Adaptation Bugs During Code Adaptation](https://arxiv.org/abs/2601.06497)
*Tanghaoran Zhang,Xinjun Mao,Shangwen Wang,Yuxin Zhao,Yao Lu,Zezhou Tang,Wenyu Xu,Longfei Sun,Changrong Xie,Kang Yang,Yue Yu*

Main category: cs.SE

TL;DR: 研究提出CtxBugGen框架评估LLMs解决上下文适应错误的能力，发现其表现不足，需提升上下文感知。


<details>
  <summary>Details</summary>
Motivation: 代码适应中上下文适应错误（CtxBugs）的解决是LLMs实际应用中的关键障碍，目前缺乏相关研究。

Method: 提出CtxBugGen框架，通过四步流程生成CtxBugs，并基于此基准评估四种先进LLMs的性能。

Result: 最佳LLM（Kimi-K2）在Pass@1中仅达55.93%，CtxBugs导致适应性能下降高达30%。

Conclusion: 研究发现大型语言模型（LLMs）在解决上下文适应错误（CtxBugs）方面表现不佳，强调了提升其上下文感知能力的必要性。

Abstract: Code adaptation is a fundamental but challenging task in software development, requiring developers to modify existing code for new contexts. A key challenge is to resolve Context Adaptation Bugs (CtxBugs), which occurs when code correct in its original context violates constraints in the target environment. Unlike isolated bugs, CtxBugs cannot be resolved through local fixes and require cross-context reasoning to identify semantic mismatches. Overlooking them may lead to critical failures in adaptation. Although Large Language Models (LLMs) show great potential in automating code-related tasks, their ability to resolve CtxBugs remains a significant and unexplored obstacle to their practical use in code adaptation. To bridge this gap, we propose CtxBugGen, a novel framework for generating CtxBugs to evaluate LLMs. Its core idea is to leverage LLMs' tendency to generate plausible but context-free code when contextual constraints are absent. The framework generates CtxBugs through a four-step process to ensure their relevance and validity: (1) Adaptation Task Selection, (2) Task-specific Perturbation,(3) LLM-based Variant Generation and (4) CtxBugs Identification. Based on the benchmark constructed by CtxBugGen, we conduct an empirical study with four state-of-the-art LLMs. Our results reveal their unsatisfactory performance in CtxBug resolution. The best performing LLM, Kimi-K2, achieves 55.93% on Pass@1 and resolves just 52.47% of CtxBugs. The presence of CtxBugs degrades LLMs' adaptation performance by up to 30%. Failure analysis indicates that LLMs often overlook CtxBugs and replicate them in their outputs. Our study highlights a critical weakness in LLMs' cross-context reasoning and emphasize the need for new methods to enhance their context awareness for reliable code adaptation.

</details>


### [287] [Fixturize: Bridging the Fixture Gap in Test Generation](https://arxiv.org/abs/2601.06615)
*Pengyu Xue,Chengyi Wang,Zhen Yang,Xiapu Luo,Yuxuan Zhang,Xiran Lyu,Yifei Pei,Zonghan Jia,Yichen Sun,Linhao Wu,Kunwu Zheng*

Main category: cs.SE

TL;DR: Fixturize框架通过识别和合成测试夹具，显著提升了自动化测试的质量和覆盖率。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）在自动化单元测试生成中忽视了测试夹具的构建，导致测试环境设置不足。

Method: 提出Fixturize框架，采用迭代反馈驱动的方法识别夹具依赖函数并合成测试夹具，同时引入FixtureEval基准进行评估。

Result: Fixturize在识别测试夹具依赖方面达到88.38%-97.00%的准确率，显著提升了Suite Pass率（SuitePS）和代码覆盖率。

Conclusion: Fixturize通过主动识别依赖测试夹具的函数并合成测试夹具，显著提升了自动化测试套件的质量，证明了夹具意识是现代自动化测试流程中不可或缺的组成部分。

Abstract: Current Large Language Models (LLMs) have advanced automated unit test generation but face a critical limitation: they often neglect to construct the necessary test fixtures, which are the environmental setups required for a test to run. To bridge this gap, this paper proposes Fixturize, a diagnostic framework that proactively identifies fixture-dependent functions and synthesizes test fixtures accordingly through an iterative, feedback-driven process, thereby improving the quality of auto-generated test suites of existing approaches. For rigorous evaluation, the authors introduce FixtureEval, a dedicated benchmark comprising 600 curated functions across two Programming Languages (PLs), i.e., Python and Java, with explicit fixture dependency labels, enabling both the corresponding classification and generation tasks. Empirical results demonstrate that Fixturize is highly effective, achieving 88.38%-97.00% accuracy across benchmarks in identifying the dependence of test fixtures and significantly enhancing the Suite Pass rate (SuitePS) by 18.03%-42.86% on average across both PLs with the auto-generated fixtures. Owing to the maintenance of test fixtures, Fixturize further improves line/branch coverage when integrated with existing testing tools of both LLM-based and Search-based by 16.85%/24.08% and 31.54%/119.66% on average, respectively. The findings establish fixture awareness as an essential, missing component in modern auto-testing pipelines.

</details>


### [288] [An Exploratory Pilot Survey on Technical Quality Control Practices in Agile R&D Projects](https://arxiv.org/abs/2601.06689)
*Mateus Costa Lucena*

Main category: cs.SE

TL;DR: 该研究调查了敏捷研发团队在Scrum环境中报告的技术质量控制实践和指标使用情况，发现实践应用不一致且技术质量监控存在差距。


<details>
  <summary>Details</summary>
Motivation: 管理敏捷研发软件项目中的技术质量是一个持续挑战，尤其是在高技术和实验压力背景下。

Method: 研究采用结构化问卷，对位于巴西马瑙斯的科学与技术机构（STIs）的专业人士进行调查，收集报告实践、质量感知和常见挑战。定量数据辅以定性回答以支持上下文解释。

Result: 结果表明，虽然自动化测试、代码审查和持续集成等实践被广泛认可，但其应用在不同迭代中往往不一致。在技术质量指标的监控和从业务角度评估技术债务的机制报告中也存在差距。

Conclusion: 本研究提供了一个探索性基线，描述了在区域创新生态系统中敏捷研发项目如何管理技术质量，而非追求普遍性结论。

Abstract: Managing technical quality in agile Research and Development (R&D) software projects represents a persistent challenge, particularly in contexts characterized by high technical uncertainty and experimental pressure. This exploratory pilot survey explores how agile R&D software teams report the use of practices and metrics related to technical quality control within Scrum-based environments. The study employed a structured questionnaire administered to professionals from Science and Technology Institutions (STIs) located in Manaus, Brazil, aiming to capture reported practices, perceptions of quality, and recurrent challenges. Quantitative data were complemented by qualitative responses to support contextual interpretation. The results indicate that although practices such as automated testing, code review, and continuous integration are widely acknowledged, their reported application is often inconsistent across iterations. Gaps were also observed in the monitoring of technical quality metrics and in the reporting of mechanisms for assessing technical debt from a business perspective. Rather than aiming for generalization, this study offers an exploratory baseline that describes how technical quality is managed in agile R&D projects within a regional innovation ecosystem.

</details>


### [289] [Comparative Separation: Evaluating Separation on Comparative Judgment Test Data](https://arxiv.org/abs/2601.06761)
*Xiaoyin Xi,Neeku Capak,Kate Stockwell,Zhe Yu*

Main category: cs.SE

TL;DR: 本研究提出了一种新的公平性概念——比较分离，用于评估机器学习软件在比较判断测试数据上的公平性。通过理论和实证分析，证明了比较分离与分离的等价性，并展示了其实际应用价值。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习软件越来越多地用于高风险决策，公平性问题日益受到关注。软件开发者有责任通过确保机器学习软件在不同敏感群体上表现一致（满足分离准则）来使其具有可问责性。然而，评估分离需要每个测试数据点的真实标签，这促使我们研究是否可以在比较判断测试数据上评估分离。

Method: 本研究首先定义了比较判断测试数据上的新公平性概念——比较分离，并提出了评估比较分离的指标。然后，通过理论和实证分析，证明了在二分类问题中，比较分离与分离是等价的。最后，分析了评估分离和比较分离时所需的测试数据点和测试数据对的数量。

Result: 研究表明，在二分类问题中，比较分离与分离是等价的。此外，还分析了评估分离和比较分离所需的测试数据点和数据对的数量，展示了使用比较判断测试数据进行模型评估的可行性和实际益处。

Conclusion: 本研究首次探索了在比较判断测试数据上进行公平性评估的可行性，展示了使用比较判断测试数据进行模型评估的实际益处。

Abstract: This research seeks to benefit the software engineering society by proposing comparative separation, a novel group fairness notion to evaluate the fairness of machine learning software on comparative judgment test data. Fairness issues have attracted increasing attention since machine learning software is increasingly used for high-stakes and high-risk decisions. It is the responsibility of all software developers to make their software accountable by ensuring that the machine learning software do not perform differently on different sensitive groups -- satisfying the separation criterion. However, evaluation of separation requires ground truth labels for each test data point. This motivates our work on analyzing whether separation can be evaluated on comparative judgment test data. Instead of asking humans to provide the ratings or categorical labels on each test data point, comparative judgments are made between pairs of data points such as A is better than B. According to the law of comparative judgment, providing such comparative judgments yields a lower cognitive burden for humans than providing ratings or categorical labels. This work first defines the novel fairness notion comparative separation on comparative judgment test data, and the metrics to evaluate comparative separation. Then, both theoretically and empirically, we show that in binary classification problems, comparative separation is equivalent to separation. Lastly, we analyze the number of test data points and test data pairs required to achieve the same level of statistical power in the evaluation of separation and comparative separation, respectively. This work is the first to explore fairness evaluation on comparative judgment test data. It shows the feasibility and the practical benefits of using comparative judgment test data for model evaluations.

</details>


### [290] [MemGovern: Enhancing Code Agents through Learning from Governed Human Experiences](https://arxiv.org/abs/2601.06789)
*Qihao Wang,Ziming Cheng,Shuo Zhang,Fan Liu,Rui Xu,Heng Lian,Kunyi Wang,Xiaoming Yu,Jianghao Yin,Sen Hu,Yue Hu,Shaolei Zhang,Yanbing Liu,Ronghao Chen,Huacan Wang*

Main category: cs.SE

TL;DR: MemGovern框架通过治理GitHub数据为自主软件工程代理提供结构化经验，显著提升问题解决率。


<details>
  <summary>Details</summary>
Motivation: 自主软件工程代理存在"封闭世界"限制，无法充分利用GitHub等平台上的历史人类经验，而现实世界的问题跟踪数据又缺乏结构化和整合性。

Method: MemGovern框架通过经验治理将原始GitHub数据转化为代理友好的经验卡片，并引入代理经验搜索策略，实现逻辑驱动的人类专业知识检索。

Result: MemGovern生成了135K个治理后的经验卡片，在SWE-bench Verified上的解决率提高了4.65%。

Conclusion: MemGovern作为一个插件式解决方案，为自主软件工程代理提供了友好的记忆基础设施，显著提升了问题解决率。

Abstract: While autonomous software engineering (SWE) agents are reshaping programming paradigms, they currently suffer from a "closed-world" limitation: they attempt to fix bugs from scratch or solely using local context, ignoring the immense historical human experience available on platforms like GitHub. Accessing this open-world experience is hindered by the unstructured and fragmented nature of real-world issue-tracking data. In this paper, we introduce MemGovern, a framework designed to govern and transform raw GitHub data into actionable experiential memory for agents. MemGovern employs experience governance to convert human experience into agent-friendly experience cards and introduces an agentic experience search strategy that enables logic-driven retrieval of human expertise. By producing 135K governed experience cards, MemGovern achieves a significant performance boost, improving resolution rates on the SWE-bench Verified by 4.65%. As a plug-in approach, MemGovern provides a solution for agent-friendly memory infrastructure.

</details>


### [291] [PenForge: On-the-Fly Expert Agent Construction for Automated Penetration Testing](https://arxiv.org/abs/2601.06910)
*Huihui Huang,Jieke Shi,Junkai Chen,Ting Zhang,Yikun Li,Chengran Yang,Eng Lieh Ouh,Lwin Khin Shar,David Lo*

Main category: cs.SE

TL;DR: PenForge通过动态构建专家代理，显著提升了LLM驱动的渗透测试在零日漏洞中的利用成功率，比现有方法高3倍。


<details>
  <summary>Details</summary>
Motivation: 现有的自动化渗透测试方法要么依赖单一通用代理（在复杂场景中表现不佳），要么依赖高度专业化的代理（无法适应多样化的漏洞类型），因此需要一种更灵活、高效的解决方案。

Method: PenForge框架通过动态构建专家代理，结合自动化的攻击面侦察和上下文感知的利用策略，实现了在复杂场景下的高效漏洞利用。

Result: 在CVE-Bench的零日漏洞测试中，PenForge实现了30.0%的利用成功率（12/40），比现有最佳方法提升了3倍。

Conclusion: PenForge代表了LLM驱动的渗透测试领域的一个早期但具有范式转变意义的进步，通过动态构建专家代理显著提升了零日漏洞的利用成功率，并指出了未来改进的三个方向。

Abstract: Penetration testing is essential for identifying vulnerabilities in web applications before real adversaries can exploit them. Recent work has explored automating this process with Large Language Model (LLM)-powered agents, but existing approaches either rely on a single generic agent that struggles in complex scenarios or narrowly specialized agents that cannot adapt to diverse vulnerability types. We therefore introduce PenForge, a framework that dynamically constructs expert agents during testing rather than relying on those prepared beforehand. By integrating automated reconnaissance of potential attack surfaces with agents instantiated on the fly for context-aware exploitation, PenForge achieves a 30.0% exploit success rate (12/40) on CVE-Bench in the particularly challenging zero-day setting, which is a 3 times improvement over the state-of-the-art. Our analysis also identifies three opportunities for future work: (1) supplying richer tool-usage knowledge to improve exploitation effectiveness; (2) extending benchmarks to include more vulnerabilities and attack types; and (3) fostering developer trust by incorporating explainable mechanisms and human review. As an emerging result with substantial potential impact, PenForge embodies the early-stage yet paradigm-shifting idea of on-the-fly agent construction, marking its promise as a step toward scalable and effective LLM-driven penetration testing.

</details>


### [292] [MicLog: Towards Accurate and Efficient LLM-based Log Parsing via Progressive Meta In-Context Learning](https://arxiv.org/abs/2601.07005)
*Jianbo Yu,Yixuan Li,Hai Xu,Kang Xu,Junjielong Xu,Zhijing Li,Pinjia He,Wanyuan Wang*

Main category: cs.SE

TL;DR: MicLog是一种结合元学习和ICL的日志解析框架，显著提升准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决传统解析器在语义变化和数据稀缺中的不足，以及LLM-based解析器在ICL能力利用不足和查询成本高的问题。

Method: 结合元学习和ICL，采用加权DBSCAN候选采样和增强BM25演示选择，以及多级预查询缓存。

Result: 在Loghub-2.0上，MicLog的解析准确率比现有最佳解析器高10.3%，解析时间减少42.4%。

Conclusion: MicLog通过ProgMeta-ICL框架显著提升了日志解析的准确性和效率，解决了传统和LLM-based解析器的局限性。

Abstract: Log parsing converts semi-structured logs into structured templates, forming a critical foundation for downstream analysis. Traditional syntax and semantic-based parsers often struggle with semantic variations in evolving logs and data scarcity stemming from their limited domain coverage. Recent large language model (LLM)-based parsers leverage in-context learning (ICL) to extract semantics from examples, demonstrating superior accuracy. However, LLM-based parsers face two main challenges: 1) underutilization of ICL capabilities, particularly in dynamic example selection and cross-domain generalization, leading to inconsistent performance; 2) time-consuming and costly LLM querying. To address these challenges, we present MicLog, the first progressive meta in-context learning (ProgMeta-ICL) log parsing framework that combines meta-learning with ICL on small open-source LLMs (i.e., Qwen-2.5-3B). Specifically, MicLog: i) enhances LLMs' ICL capability through a zero-shot to k-shot ProgMeta-ICL paradigm, employing weighted DBSCAN candidate sampling and enhanced BM25 demonstration selection; ii) accelerates parsing via a multi-level pre-query cache that dynamically matches and refines recently parsed templates. Evaluated on Loghub-2.0, MicLog achieves 10.3% higher parsing accuracy than the state-of-the-art parser while reducing parsing time by 42.4%.

</details>


### [293] [Between Policy and Practice: GenAI Adoption in Agile Software Development Teams](https://arxiv.org/abs/2601.07051)
*Michael Neumann,Lasse Bischof,Nic Elias Hinz,Luca Stockmann,Dennis Schrader,Ana Carolina Ahaus,Erim Can Demirci,Benjamin Gabel,Maria Rauschenberger,Philipp Diebold,Henning Fritzemeier,Adam Przybylek*

Main category: cs.SE

TL;DR: 研究敏捷环境中GenAI工具的采用，发现其主要用于创意和代码辅助，但需解决数据隐私和治理等障碍以实现有效整合。


<details>
  <summary>Details</summary>
Motivation: 研究敏捷实践者在现实组织环境中如何采用GenAI工具，关注监管条件、用例、益处和障碍。

Method: 在三个德国组织中进行探索性多案例研究，包括17次半结构化访谈和文档分析，应用跨案例主题分析以识别GenAI采用模式。

Result: 发现GenAI主要用于创意任务、文档和代码辅助，益处包括效率提升和创造力增强，障碍涉及数据隐私、验证工作和缺乏治理。使用TOE框架发现这些障碍源于三个维度的不对齐。

Conclusion: GenAI在敏捷环境中具有显著潜力，但需要在技术、组织和环境（TOE）维度上进行对齐，包括明确的政策、数据保护措施和用户培训，以确保负责任和有效的整合。

Abstract: Context: The rapid emergence of generative AI (GenAI) tools has begun to reshape various software engineering activities. Yet, their adoption within agile environments remains underexplored. Objective: This study investigates how agile practitioners adopt GenAI tools in real-world organizational contexts, focusing on regulatory conditions, use cases, benefits, and barriers. Method: An exploratory multiple case study was conducted in three German organizations, involving 17 semi-structured interviews and document analysis. A cross-case thematic analysis was applied to identify GenAI adoption patterns. Results: Findings reveal that GenAI is primarily used for creative tasks, documentation, and code assistance. Benefits include efficiency gains and enhanced creativity, while barriers relate to data privacy, validation effort, and lack of governance. Using the Technology-Organization-Environment (TOE) framework, we find that these barriers stem from misalignments across the three dimensions. Regulatory pressures are often translated into policies without accounting for actual technological usage patterns or organizational constraints. This leads to systematic gaps between policy and practice. Conclusion: GenAI offers significant potential to augment agile roles but requires alignment across TOE dimensions, including clear policies, data protection measures, and user training to ensure responsible and effective integration.

</details>


### [294] [A Large-Scale Study on the Development and Issues of Multi-Agent AI Systems](https://arxiv.org/abs/2601.07136)
*Daniel Liu,Krishna Upadhyay,Vinaik Chhetri,A. B. Siddique,Umar Farooq*

Main category: cs.SE

TL;DR: 首次大规模实证研究揭示了开源多智能体AI系统的开发模式和维护现状，强调需改进测试和文档以确保生态系统的可持续性。


<details>
  <summary>Details</summary>
Motivation: 尽管多智能体AI系统（如LangChain、CrewAI、AutoGen）快速发展，但其实际演化和维护情况尚不明确。

Method: 通过对八个领先的开源MAS系统进行大规模实证研究，分析了超过42K个独特提交和4.7K个已解决问题。

Result: 研究发现三种不同的开发模式（持续、稳定、爆发驱动），完美性提交占40.8%，问题报告主要集中在错误（22%）、基础设施（14%）和智能体协调挑战（10%）。

Conclusion: 当前多智能体AI系统（MAS）生态系统展现出显著的动势但也存在脆弱性，强调了改进测试基础设施、文档质量和维护实践的必要性，以确保长期可靠性和可持续性。

Abstract: The rapid emergence of multi-agent AI systems (MAS), including LangChain, CrewAI, and AutoGen, has shaped how large language model (LLM) applications are developed and orchestrated. However, little is known about how these systems evolve and are maintained in practice. This paper presents the first large-scale empirical study of open-source MAS, analyzing over 42K unique commits and over 4.7K resolved issues across eight leading systems. Our analysis identifies three distinct development profiles: sustained, steady, and burst-driven. These profiles reflect substantial variation in ecosystem maturity. Perfective commits constitute 40.8% of all changes, suggesting that feature enhancement is prioritized over corrective maintenance (27.4%) and adaptive updates (24.3%). Data about issues shows that the most frequent concerns involve bugs (22%), infrastructure (14%), and agent coordination challenges (10%). Issue reporting also increased sharply across all frameworks starting in 2023. Median resolution times range from under one day to about two weeks, with distributions skewed toward fast responses but a minority of issues requiring extended attention. These results highlight both the momentum and the fragility of the current ecosystem, emphasizing the need for improved testing infrastructure, documentation quality, and maintenance practices to ensure long-term reliability and sustainability.

</details>


### [295] [Engineering Decisions in MBSE: Insights for a Decision Capture Framework Development](https://arxiv.org/abs/2601.07301)
*Nidhal Selmi,Jean-michel Bruel,Sébastien Mosser,Matthieu Crespo,Alain Kerbrat*

Main category: cs.SE

TL;DR: 本文提出了一种MBSE轻量级框架，通过模型切片捕获决策，减少工作量并保持上下文链接，以飞机架构为例验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统决策捕获需要大量努力且缺乏必要的上下文信息，MBSE通过将决策嵌入系统模型，有望减少工作量并保持上下文链接。

Method: 采用模型基系统工程（MBSE）方法，将决策替代方案表示为系统模型切片，并通过简化飞机架构的行业示例进行验证。

Result: 提出的轻量级框架能够有效减少决策捕获工作量，同时保持与系统模型其他元素的明确链接。

Conclusion: 本文提出了一种轻量级框架，将决策捕获集成到MBSE工作流中，通过将决策替代方案表示为系统模型切片，有效减少了捕获工作量并保持了与需求、行为和架构元素的明确链接。

Abstract: Decision-making is a core engineering design activity that conveys the engineer's knowledge and translates it into courses of action. Capturing this form of knowledge can reap potential benefits for the engineering teams and enhance development efficiency. Despite its clear value, traditional decision capture often requires a significant amount of effort and still falls short of capturing the necessary context for reuse. Model-based systems engineering (MBSE) can be a promising solution to address these challenges by embedding decisions directly within system models, which can reduce the capture workload while maintaining explicit links to requirements, behaviors, and architectural elements. This article discusses a lightweight framework for integrating decision capture into MBSE workflows by representing decision alternatives as system model slices. Using a simplified industry example from aircraft architecture, we discuss the main challenges associated with decision capture and propose preliminary solutions to address these challenges.

</details>


### [296] [FairRF: Multi-Objective Search for Single and Intersectional Software Fairness](https://arxiv.org/abs/2601.07537)
*Giordano d'Alosio,Max Hort,Rebecca Moussa,Federica Sarro*

Main category: cs.SE

TL;DR: FairRF通过多目标进化搜索优化公平性和有效性，优于现有方法，并提供可定制的解决方案。


<details>
  <summary>Details</summary>
Motivation: 敏感领域中AI/ML系统的广泛采用引发了对其公平性的严重担忧，现有方法多为黑盒，无法让利益相关者根据需求优先考虑公平性或有效性。

Method: 我们使用多目标进化搜索优化公平性和有效性，基于随机森林模型，并进行了广泛的实证评估，比较了26种基线方法和11种不同场景。

Result: FairRF显著提升了基础分类器的公平性，同时保持预测有效性，且在多种公平定义下表现一致优于现有方法。

Conclusion: FairRF是一种有效的偏见缓解方法，允许利益相关者根据具体需求调整公平软件系统的开发。

Abstract: Background: The wide adoption of AI- and ML-based systems in sensitive domains raises severe concerns about their fairness. Many methods have been proposed in the literature to enhance software fairness. However, the majority behave as a black-box, not allowing stakeholders to prioritise fairness or effectiveness (i.e., prediction correctness) based on their needs. Aims: In this paper, we introduce FairRF, a novel approach based on multi-objective evolutionary search to optimise fairness and effectiveness in classification tasks. FairRF uses a Random Forest (RF) model as a base classifier and searches for the best hyperparameter configurations and data mutation to maximise fairness and effectiveness. Eventually, it returns a set of Pareto optimal solutions, allowing the final stakeholders to choose the best one based on their needs. Method: We conduct an extensive empirical evaluation of FairRF against 26 different baselines in 11 different scenarios using five effectiveness and three fairness metrics. Additionally, we also include two variations of the fairness metrics for intersectional bias for a total of six definitions analysed. Result: Our results show that FairRF can significantly improve the fairness of base classifiers, while maintaining consistent prediction effectiveness. Additionally, FairRF provides a more consistent optimisation under all fairness definitions compared to state-of-the-art bias mitigation methods and overcomes the existing state-of-the-art approach for intersectional bias mitigation. Conclusions: FairRF is an effective approach for bias mitigation also allowing stakeholders to adapt the development of fair software systems based on their specific needs.

</details>


### [297] [OODEval: Evaluating Large Language Models on Object-Oriented Design](https://arxiv.org/abs/2601.07602)
*Bingxu Xiao,Yunwei Dong,Yiqi Tang,Manqing Zhang,Yifan Zhou,Chunyan Ma,Yepang Liu*

Main category: cs.SE

TL;DR: 研究评估了29种LLM在面向对象设计任务中的表现，发现其语法准确性高但语义不足。Qwen3-Coder-30B表现最佳，接近本科生平均水平但仍不及顶尖人类设计师。参数规模和指令调优显著影响性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注代码级任务，忽视了LLM在软件设计能力方面的潜力。为填补这一空白，本研究旨在评估LLM在面向对象设计任务中的表现。

Method: 研究通过引入OODEval和OODEval-Human两个基准，以及CLUE评估指标，对29种LLM在50项OOD任务上的表现进行了全面评估。分析了五个研究问题：整体正确性、与人类对比、模型维度分析、任务特征分析和错误案例分析。

Result: Qwen3-Coder-30B整体表现最佳，与DeepSeek-R1和GPT-4o相当；Gemma3-4B-IT虽参数规模较小，但表现优于GPT-4o-Mini。LLMs在语法准确性上表现良好，但语义层面存在不足。

Conclusion: LLMs在面向对象设计（OOD）任务中表现出较高的语法准确性，但在语义层面存在显著不足，尤其是在方法和关系生成方面。尽管表现最佳的LLMs接近本科生平均水平，但仍远低于顶尖人类设计师。模型参数规模、代码专业化程度和指令调优对性能有显著影响，而设计复杂度增加和需求可读性降低会削弱性能。

Abstract: Recent advances in large language models (LLMs) have driven extensive evaluations in software engineering. however, most prior work concentrates on code-level tasks, leaving software design capabilities underexplored. To fill this gap, we conduct a comprehensive empirical study evaluating 29 LLMs on object-oriented design (OOD) tasks. Owing to the lack of standardized benchmarks and metrics, we introduce OODEval, a manually constructed benchmark comprising 50 OOD tasks of varying difficulty, and OODEval-Human, the first human-rated OOD benchmark, which includes 940 undergraduate-submitted class diagrams evaluated by instructors. We further propose CLUE (Class Likeness Unified Evaluation), a unified metric set that assesses both global correctness and fine-grained design quality in class diagram generation. Using these benchmarks and metrics, we investigate five research questions: overall correctness, comparison with humans, model dimension analysis, task feature analysis, and bad case analysis. The results indicate that while LLMs achieve high syntactic accuracy, they exhibit substantial semantic deficiencies, particularly in method and relationship generation. Among the evaluated models, Qwen3-Coder-30B achieves the best overall performance, rivaling DeepSeek-R1 and GPT-4o, while Gemma3-4B-IT outperforms GPT-4o-Mini despite its smaller parameter scale. Although top-performing LLMs nearly match the average performance of undergraduates, they remain significantly below the level of the best human designers. Further analysis shows that parameter scale, code specialization, and instruction tuning strongly influence performance, whereas increased design complexity and lower requirement readability degrade it. Bad case analysis reveals common failure modes, including keyword misuse, missing classes or relationships, and omitted methods.

</details>


### [298] ["TODO: Fix the Mess Gemini Created": Towards Understanding GenAI-Induced Self-Admitted Technical Debt](https://arxiv.org/abs/2601.07786)
*Abdullah Al Mujahid,Mia Mohammad Imran*

Main category: cs.SE

TL;DR: 论文提出GIST概念，分析AI生成代码中开发者自我承认的技术债务，发现推迟测试和代码理解不足是主要原因。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型(LLMs)如ChatGPT、Copilot、Claude和Gemini融入软件开发工作流，开发者越来越多地在代码注释中留下AI参与的痕迹，其中一些注释明确承认了生成式AI的使用和技术缺陷的存在。

Method: 分析了6,540条来自公开Python和JavaScript GitHub仓库的LLM引用代码注释（2022年11月至2025年7月），识别出81条同时自我承认技术债务(SATD)的注释。

Result: 开发者最常描述的是推迟测试、不完全适应以及对AI生成代码的有限理解，这表明AI辅助影响了技术债务出现的时间和原因。

Conclusion: 论文提出了GenAI-Induced Self-admitted Technical debt (GIST)这一概念框架，用于描述开发者在使用AI生成代码时，明确表达对其行为或正确性不确定性的情况。

Abstract: As large language models (LLMs) such as ChatGPT, Copilot, Claude, and Gemini become integrated into software development workflows, developers increasingly leave traces of AI involvement in their code comments. Among these, some comments explicitly acknowledge both the use of generative AI and the presence of technical shortcomings. Analyzing 6,540 LLM-referencing code comments from public Python and JavaScript-based GitHub repositories (November 2022-July 2025), we identified 81 that also self-admit technical debt(SATD). Developers most often describe postponed testing, incomplete adaptation, and limited understanding of AI-generated code, suggesting that AI assistance affects both when and why technical debt emerges. We term GenAI-Induced Self-admitted Technical debt (GIST) as a proposed conceptual lens to describe recurring cases where developers incorporate AI-generated code while explicitly expressing uncertainty about its behavior or correctness.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [299] [Investigating Anthropometric Fidelity in SAM 3D Body](https://arxiv.org/abs/2601.06035)
*Aizierjiang Aiersilan,Ruting Cheng,James Hahn*

Main category: cs.GR

TL;DR: SAM 3D Body在特殊体型重建上存在局限，原因是低维参数化表示和语义不变条件导致细节平滑化，未来需改进以适用于医学领域。


<details>
  <summary>Details</summary>
Motivation: 尽管SAM 3D Body在单图像人体网格恢复中表现优异，但在处理特殊体型（如老年肌肉萎缩、脊柱侧弯或孕妇）时存在明显局限，作者希望探究这一现象的根本原因。

Method: 通过分析Momentum Human Rig（MHR）的低维参数化表示、语义不变条件（DINOv3）和基于注释的对齐机制，揭示了导致生物细节平滑化的机制。

Result: 研究发现，模型的架构依赖导致了对生物细节的平滑化，表现为‘回归均值’效应。

Conclusion: 本文探讨了SAM 3D Body在重建特殊体型时的局限性，并提出未来改进方向，以扩展其在医学领域的应用。

Abstract: The recent release of SAM 3D Body \cite{sam3dbody2025} marks a significant milestone in human mesh recovery, demonstrating state-of-the-art performance in producing clean, topologically coherent meshes from single images. By leveraging the novel Momentum Human Rig (MHR), it achieves remarkable robustness to occlusion and diverse poses. However, our evaluation reveals a specific and consistent limitation: the model struggles to reconstruct detailed anthropometric deviations, especially on populations with special body shape alters such as geriatric muscle atrophy, scoliosis, or pregnancy, even when these features are prominent in the input image. In this paper, we investigate this phenomenon not as a failure of the model's capacity, but as a byproduct of the \textit{perception-distortion trade-off}. We posit that the architectural reliance on the low-dimensional parametric MHR representation, combined with semantic-invariant conditioning (DINOv3) and annotation-based alignment, creates a \enquote{regression to the mean} effect. We analyze these mechanisms to understand why individual biological details are smoothed out and propose specific, constructive pathways for future work to extend the impressive baseline performance of SAM 3D Body into the medical domain.

</details>


### [300] [RigMo: Unifying Rig and Motion Learning for Generative Animation](https://arxiv.org/abs/2601.06378)
*Hao Zhang,Jiahao Luo,Bohui Wan,Yizhou Zhao,Zongrui Li,Michael Vasilkovsky,Chaoyang Wang,Jian Wang,Narendra Ahuja,Bing Zhou*

Main category: cs.GR

TL;DR: RigMo是一个统一的生成框架，直接从原始网格序列联合学习rig和motion，无需人工标注，支持下游运动生成任务，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的动画生成流程通常将rig和motion作为独立问题处理，依赖真实骨骼和蒙皮权重，限制了可扩展性和可解释性。RigMo旨在解决这一问题。

Method: RigMo通过将顶点变形编码为两个紧凑的潜在空间（rig潜在空间和motion潜在空间），分别生成高斯骨骼、蒙皮权重和时间变化的SE(3)变换，从而定义可动画化的网格。

Result: 实验表明，RigMo能够学习平滑、可解释且物理合理的rig，并在重建和类别级泛化方面优于现有基线。

Conclusion: RigMo提出了一种统一的、结构感知且可扩展的动态3D建模新范式，通过联合学习rig和motion，实现了无需人工标注的自动动画生成。

Abstract: Despite significant progress in 4D generation, rig and motion, the core structural and dynamic components of animation are typically modeled as separate problems. Existing pipelines rely on ground-truth skeletons and skinning weights for motion generation and treat auto-rigging as an independent process, undermining scalability and interpretability. We present RigMo, a unified generative framework that jointly learns rig and motion directly from raw mesh sequences, without any human-provided rig annotations. RigMo encodes per-vertex deformations into two compact latent spaces: a rig latent that decodes into explicit Gaussian bones and skinning weights, and a motion latent that produces time-varying SE(3) transformations. Together, these outputs define an animatable mesh with explicit structure and coherent motion, enabling feed-forward rig and motion inference for deformable objects. Beyond unified rig-motion discovery, we introduce a Motion-DiT model operating in RigMo's latent space and demonstrate that these structure-aware latents can naturally support downstream motion generation tasks. Experiments on DeformingThings4D, Objaverse-XL, and TrueBones demonstrate that RigMo learns smooth, interpretable, and physically plausible rigs, while achieving superior reconstruction and category-level generalization compared to existing auto-rigging and deformation baselines. RigMo establishes a new paradigm for unified, structure-aware, and scalable dynamic 3D modeling.

</details>


### [301] [A New Perspective on Drawing Venn Diagrams for Data Visualization](https://arxiv.org/abs/2601.06980)
*Bálint Csanády*

Main category: cs.GR

TL;DR: VennFan是一种基于极坐标投影的n集合维恩图生成方法，通过形状化正弦波和振幅缩放提升可读性和可定制性，并提供自动标签放置功能。已作为Python包发布。


<details>
  <summary>Details</summary>
Motivation: 旨在解决传统维恩图构造在可读性和可定制性方面的不足，提供一种更直观且易于定制的可视化工具。

Method: 该方法采用极坐标投影的三角边界，生成类似风扇叶片的维恩图，包括基于正弦和余弦的变体，并提出了针对这种扇形布局的自动标签放置启发式方法。

Result: 成功开发了VennFan Python包，实现了高效生成可读性强的n集合维恩图。

Conclusion: VennFan作为一种基于极坐标投影的n集合维恩图生成方法，通过使用形状化的正弦波和振幅缩放，显著提升了图表的可读性和可定制性。

Abstract: We introduce VennFan, a method for generating $n$-set Venn diagrams based on the polar coordinate projection of trigonometric boundaries, resulting in Venn diagrams that resemble a set of fan blades. Unlike most classical constructions, our method emphasizes readability and customizability by using shaped sinusoids and amplitude scaling. We describe both sine- and cosine-based variants of VennFan and propose an automatic label placement heuristic tailored to these fan-like layouts. VennFan is available as a Python package (https://pypi.org/project/vennfan/).

</details>


### [302] [R3-RECON: Radiance-Field-Free Active Reconstruction via Renderability](https://arxiv.org/abs/2601.07484)
*Xiaofeng Jin,Matteo Frosi,Yiran Guo,Matteo Matteucci*

Main category: cs.GR

TL;DR: 论文提出$\mathbb{R}^{3}$-RECON，一种轻量级无辐射场主动重建框架，通过体素地图生成渲染性场，快速指导最佳视图选择，实验显示其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的主动视图规划方法通常依赖于辐射场或3D高斯基元的信息熵估计，这些方法紧密耦合视图选择与特定表示机制，且未考虑轻量级在线部署的计算和资源限制。因此，需要一种更轻量、更通用的方法来提高重建效率。

Method: $\mathbb{R}^{3}$-RECON框架通过轻量级体素地图生成一个隐式的、姿态可调的渲染性场，将每个体素的在线观测统计聚合为统一的标量渲染性评分。该方法支持快速更新和毫秒级查询，无需梯度或辐射场训练。此外，还引入了全景扩展，用于估计全方位（360°）视图效用，加速候选评估。

Result: 在标准室内Replica数据集上，$\mathbb{R}^{3}$-RECON在匹配的视图和时间预算下，比最近的主动高斯溅射基线实现了更均匀的新视图质量和更高的3D高斯溅射重建精度。

Conclusion: 论文提出了一个名为$\mathbb{R}^{3}$-RECON的无辐射场主动重建框架，通过轻量级体素地图生成一个隐式的、姿态可调的渲染性场。该方法在SE(3)上统一标量渲染性评分，快速更新和查询，无需梯度或辐射场训练。实验表明，该方法在室内Replica数据集上优于现有主动高斯溅射基线，实现了更均匀的新视图质量和更高的3D高斯溅射重建精度。

Abstract: In active reconstruction, an embodied agent must decide where to look next to efficiently acquire views that support high-quality novel-view rendering. Recent work on active view planning for neural rendering largely derives next-best-view (NBV) criteria by backpropagating through radiance fields or estimating information entropy over 3D Gaussian primitives. While effective, these strategies tightly couple view selection to heavy, representation-specific mechanisms and fail to account for the computational and resource constraints required for lightweight online deployment. In this paper, we revisit active reconstruction from a renderability-centric perspective. We propose $\mathbb{R}^{3}$-RECON, a radiance-fields-free active reconstruction framework that induces an implicit, pose-conditioned renderability field over SE(3) from a lightweight voxel map. Our formulation aggregates per-voxel online observation statistics into a unified scalar renderability score that is cheap to update and can be queried in closed form at arbitrary candidate viewpoints in milliseconds, without requiring gradients or radiance-field training. This renderability field is strongly correlated with image-space reconstruction error, naturally guiding NBV selection. We further introduce a panoramic extension that estimates omnidirectional (360$^\circ$) view utility to accelerate candidate evaluation. In the standard indoor Replica dataset, $\mathbb{R}^{3}$-RECON achieves more uniform novel-view quality and higher 3D Gaussian splatting (3DGS) reconstruction accuracy than recent active GS baselines with matched view and time budgets.

</details>
