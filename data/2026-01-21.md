<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 266]
- [cs.NI](#cs.NI) [Total: 24]
- [cs.RO](#cs.RO) [Total: 62]
- [cs.OS](#cs.OS) [Total: 3]
- [cs.GR](#cs.GR) [Total: 2]
- [cs.DC](#cs.DC) [Total: 36]
- [cs.AI](#cs.AI) [Total: 101]
- [cs.SE](#cs.SE) [Total: 59]
- [cs.DS](#cs.DS) [Total: 14]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Domain-Specific Self-Supervised Pre-training for Agricultural Disease Classification: A Hierarchical Vision Transformer Study](https://arxiv.org/abs/2601.11612)
*Arnav S. Sonavane*

Main category: cs.CV

TL;DR: 自监督预训练（SimCLR）在农业疾病分类中比架构设计更有效，性能提升显著且架构无关。


<details>
  <summary>Details</summary>
Motivation: 探索领域特定的自监督预训练对农业疾病分类任务的影响，并比较其与架构设计对性能的提升效果。

Method: 使用HierarchicalViT（HVT）和Swin-Base、ViT-Base等架构，结合SimCLR自监督预训练方法，在三个农业疾病数据集上进行评估。

Result: SimCLR预训练在3000张未标记农业图像上带来+4.57%的准确率提升，超过分层架构设计的+3.70%。HVT-Base在参数相近的情况下比Swin-Base性能提升+1.68%。

Conclusion: 研究表明，在农业疾病分类任务中，领域特定的自监督预训练（如SimCLR）比架构设计（如分层视觉变换器）带来更大的性能提升，且这种优势与架构无关。

Abstract: We investigate the impact of domain-specific self-supervised pre-training on agricultural disease classification using hierarchical vision transformers. Our key finding is that SimCLR pre-training on just 3,000 unlabeled agricultural images provides a +4.57% accuracy improvement--exceeding the +3.70% gain from hierarchical architecture design. Critically, we show this SSL benefit is architecture-agnostic: applying the same pre-training to Swin-Base yields +4.08%, to ViT-Base +4.20%, confirming practitioners should prioritize domain data collection over architectural choices. Using HierarchicalViT (HVT), a Swin-style hierarchical transformer, we evaluate on three datasets: Cotton Leaf Disease (7 classes, 90.24%), PlantVillage (38 classes, 96.3%), and PlantDoc (27 classes, 87.1%). At matched parameter counts, HVT-Base (78M) achieves 88.91% vs. Swin-Base (88M) at 87.23%, a +1.68% improvement. For deployment reliability, we report calibration analysis showing HVT achieves 3.56% ECE (1.52% after temperature scaling). Code: https://github.com/w2sg-arnav/HierarchicalViT

</details>


### [2] [PointSLAM++: Robust Dense Neural Gaussian Point Cloud-based SLAM](https://arxiv.org/abs/2601.11617)
*Xu Wang,Boyao Han,Xiaojun Chen,Ying Liu,Ruihui Li*

Main category: cs.CV

TL;DR: PointSLAM++是一种新型RGB-D SLAM系统，通过神经高斯表示和渐进姿态优化提升3D重建和渲染质量，适用于AR和机器人。


<details>
  <summary>Details</summary>
Motivation: 现有的SLAM方法在深度噪声存在时难以保持结构一致性和鲁棒的姿态估计，因此需要一种新方法来提升实时3D重建的精度和渲染质量。

Method: 采用分层约束的神经高斯表示生成高斯基元进行场景映射，并利用渐进姿态优化减少深度传感器噪声，同时通过动态神经表示图调整高斯节点分布以适应复杂场景细节。

Result: 实验结果表明，PointSLAM++在重建精度和渲染质量上优于现有的基于3DGS的SLAM方法。

Conclusion: PointSLAM++通过结合分层约束的神经高斯表示和渐进姿态优化，显著提升了3D重建和渲染的质量，适用于大规模AR和机器人应用。

Abstract: Real-time 3D reconstruction is crucial for robotics and augmented reality, yet current simultaneous localization and mapping(SLAM) approaches often struggle to maintain structural consistency and robust pose estimation in the presence of depth noise. This work introduces PointSLAM++, a novel RGB-D SLAM system that leverages a hierarchically constrained neural Gaussian representation to preserve structural relationships while generating Gaussian primitives for scene mapping. It also employs progressive pose optimization to mitigate depth sensor noise, significantly enhancing localization accuracy. Furthermore, it utilizes a dynamic neural representation graph that adjusts the distribution of Gaussian nodes based on local geometric complexity, enabling the map to adapt to intricate scene details in real time. This combination yields high-precision 3D mapping and photorealistic scene rendering. Experimental results show PointSLAM++ outperforms existing 3DGS-based SLAM methods in reconstruction accuracy and rendering quality, demonstrating its advantages for large-scale AR and robotics.

</details>


### [3] [Multi-modal MRI-Based Alzheimer's Disease Diagnosis with Transformer-based Image Synthesis and Transfer Learning](https://arxiv.org/abs/2601.11614)
*Jason Qiu*

Main category: cs.CV

TL;DR: 该研究通过3D TransUNet从T1加权MRI合成扩散MRI的FA和MD图，显著提升了AD和MCI的诊断准确率，为临床提供了高效且可及的解决方案。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病（AD）的早期检测至关重要，但常规T1加权MRI只能检测到疾病晚期的宏观变化，而扩散MRI（dMRI）虽能检测早期微结构异常，却因耗时和易受运动伪影影响而难以在临床中广泛应用。

Method: 提出了一种3D TransUNet图像合成框架，直接从T1加权MRI预测FA和MD图。

Result: 模型生成的FA和MD图具有高保真度（SSIM>0.93，Pearson相关性>0.94），在多模态诊断模型中，合成特征将AD分类准确率提高了5%（78.75%->83.75%），并显著改善了轻度认知障碍（MCI）检测（提升12.5%）。

Conclusion: 该研究表明，通过从常规T1加权MRI推断高质量的扩散微结构信息，可以在缺乏扩散数据的临床环境中实现多模态成像的优势，从而提高AD诊断的可及性、效率和准确性。

Abstract: Alzheimer's disease (AD) is a progressive neurodegenerative disorder in which pathological changes begin many years before the onset of clinical symptoms, making early detection essential for timely intervention. T1-weighted (T1w) Magnetic Resonance Imaging (MRI) is routinely used in clinical practice to identify macroscopic brain alterations, but these changes typically emerge relatively late in the disease course. Diffusion MRI (dMRI), in contrast, is sensitive to earlier microstructural abnormalities by probing water diffusion in brain tissue. dMRI metrics, including fractional anisotropy (FA) and mean diffusivity (MD), provide complementary information about white matter integrity and neurodegeneration. However, dMRI acquisitions are time-consuming and susceptible to motion artifacts, limiting their routine use in clinical populations. To bridge this gap, I propose a 3D TransUNet image synthesis framework that predicts FA and MD maps directly from T1w MRI. My model generates high-fidelity maps, achieving a structural similarity index (SSIM) exceeding 0.93 and a strong Pearson correlation (>0.94) with ground-truth dMRI. When integrated into a multi-modal diagnostic model, these synthetic features boost AD classification accuracy by 5% (78.75%->83.75%) and, most importantly, improve mild cognitive impairment (MCI) detection by 12.5%. This study demonstrates that high-quality diffusion microstructural information can be inferred from routinely acquired T1w MRI, effectively transferring the benefits of multi-modality imaging to settings where diffusion data are unavailable. By reducing scan time while preserving complementary structural and microstructural information, the proposed approach has the potential to improve the accessibility, efficiency, and accuracy of AD diagnosis in clinical practice.

</details>


### [4] [Soft Shadow Diffusion (SSD): Physics-inspired Learning for 3D Computational Periscopy](https://arxiv.org/abs/2601.12257)
*Fadlullah Raji,John Murray-Bruce*

Main category: cs.CV

TL;DR: 本文提出了一种从普通NLOS照片中重建3D隐藏场景的新方法，通过光传输模型重构和两种解决方案（梯度优化和SSD神经网络），在实验中表现出色且具有强鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 传统成像需要视线来创建场景的准确视觉表示，但在某些情况下，获取合适的视线可能不切实际、危险甚至不可能。非视距（NLOS）成像通过间接测量重建场景来解决这一挑战。

Method: 提出了一种新的光传输模型重构方法，将隐藏场景分解为“光遮挡”和“非光遮挡”组件，形成可分离的非线性最小二乘（SNLLS）逆问题。开发了两种解决方案：基于梯度的优化方法和物理启发的神经网络方法（SSD）。

Result: 在众多3D场景的真实实验场景中，所提出的方法表现出色。SSD虽然在模拟中训练，但在模拟和真实世界的NLOS场景中均能很好地泛化到未见过的类别，并对噪声和环境光照表现出惊人的鲁棒性。

Conclusion: 本文通过提出一种新的光传输模型重构方法，成功实现了从普通非视距（NLOS）照片中重建3D隐藏场景，并通过梯度优化和物理启发的神经网络方法（SSD）有效解决了这一逆问题。

Abstract: Conventional imaging requires a line of sight to create accurate visual representations of a scene. In certain circumstances, however, obtaining a suitable line of sight may be impractical, dangerous, or even impossible. Non-line-of-sight (NLOS) imaging addresses this challenge by reconstructing the scene from indirect measurements. Recently, passive NLOS methods that use an ordinary photograph of the subtle shadow cast onto a visible wall by the hidden scene have gained interest. These methods are currently limited to 1D or low-resolution 2D color imaging or to localizing a hidden object whose shape is approximately known. Here, we generalize this class of methods and demonstrate a 3D reconstruction of a hidden scene from an ordinary NLOS photograph. To achieve this, we propose a novel reformulation of the light transport model that conveniently decomposes the hidden scene into \textit{light-occluding} and \textit{non-light-occluding} components to yield a separable non-linear least squares (SNLLS) inverse problem. We develop two solutions: A gradient-based optimization method and a physics-inspired neural network approach, which we call Soft Shadow diffusion (SSD). Despite the challenging ill-conditioned inverse problem encountered here, our approaches are effective on numerous 3D scenes in real experimental scenarios. Moreover, SSD is trained in simulation but generalizes well to unseen classes in simulation and real-world NLOS scenes. SSD also shows surprising robustness to noise and ambient illumination.

</details>


### [5] [NeuralFur: Animal Fur Reconstruction From Multi-View Images](https://arxiv.org/abs/2601.12481)
*Vanessa Sklyarova,Berna Kabadayi,Anastasios Yiannakidis,Giorgio Becherini,Michael J. Black,Justus Thies*

Main category: cs.CV

TL;DR: 提出一种多视角3D动物毛发重建方法，利用VLM指导毛发长度和方向，实现高保真重建。


<details>
  <summary>Details</summary>
Motivation: 动物毛发重建因细节精细、自遮挡和视角依赖的外观而极具挑战性，且缺乏可用于学习的毛发先验数据集。

Method: 首先通过传统多视角立体技术重建粗糙表面几何，然后利用VLM检索毛发长度和结构信息，构建无毛几何并在其上生长毛发。通过几何和光度损失监督重建，并利用VLM指导毛发生长方向和重力向量关系。

Result: 该方法展示了在多种毛发类型动物上的泛化能力。

Conclusion: 该论文提出了一种利用视觉语言模型（VLM）指导的多视角3D动物毛发重建方法，能够泛化到多种毛发类型的动物。

Abstract: Reconstructing realistic animal fur geometry from images is a challenging task due to the fine-scale details, self-occlusion, and view-dependent appearance of fur. In contrast to human hairstyle reconstruction, there are also no datasets that can be leveraged to learn a fur prior for different animals. In this work, we present a first multi-view-based method for high-fidelity 3D fur modeling of animals using a strand-based representation, leveraging the general knowledge of a vision language model. Given multi-view RGB images, we first reconstruct a coarse surface geometry using traditional multi-view stereo techniques. We then use a vision language model (VLM) system to retrieve information about the realistic length structure of the fur for each part of the body. We use this knowledge to construct the animal's furless geometry and grow strands atop it. The fur reconstruction is supervised with both geometric and photometric losses computed from multi-view images. To mitigate orientation ambiguities stemming from the Gabor filters that are applied to the input images, we additionally utilize the VLM to guide the strands' growth direction and their relation to the gravity vector that we incorporate as a loss. With this new schema of using a VLM to guide 3D reconstruction from multi-view inputs, we show generalization across a variety of animals with different fur types. For additional results and code, please refer to https://neuralfur.is.tue.mpg.de.

</details>


### [6] [Handcrafted Feature-Assisted One-Class Learning for Artist Authentication in Historical Drawings](https://arxiv.org/abs/2601.11627)
*Hassan Ugail,Jan Ritch-Frel,Irina Matuzava*

Main category: cs.CV

TL;DR: 论文提出一种基于一类自动编码器的历史素描认证框架，使用手工特征训练艺术家特定验证器，在数据稀缺环境下提供定量认证支持。


<details>
  <summary>Details</summary>
Motivation: 解决文化遗产中纸质作品认证和归属的挑战，尤其是在参考样本少且风格线索主要通过线条和有限色调变化表达的情况下。

Method: 使用一类自动编码器训练十位艺术家特定的验证器，基于傅里叶域能量、香农熵、全局对比度、GLCM同质性及分形复杂度等手工特征。

Result: 在900次验证决策中，系统在选定操作点下实现了83.3%的真实接受率和9.5%的虚假接受率，性能因艺术家而异。

Conclusion: 该论文提出的基于一类自动编码器的计算框架旨在为文化遗产中的纸质作品认证提供可重复的定量证据，补充而非替代传统的鉴赏方法。

Abstract: Authentication and attribution of works on paper remain persistent challenges in cultural heritage, particularly when the available reference corpus is small and stylistic cues are primarily expressed through line and limited tonal variation. We present a verification-based computational framework for historical drawing authentication using one-class autoencoders trained on a compact set of interpretable handcrafted features. Ten artist-specific verifiers are trained using authenticated sketches from the Metropolitan Museum of Art open-access collection, the Ashmolean Collections Catalogue, the Morgan Library and Museum, the Royal Collection Trust (UK), the Victoria and Albert Museum Collections, and an online catalogue of the Casa Buonarroti collection and evaluated under a biometric-style protocol with genuine and impostor trials. Feature vectors comprise Fourier-domain energy, Shannon entropy, global contrast, GLCM-based homogeneity, and a box-counting estimate of fractal complexity. Across 900 verification decisions (90 genuine and 810 impostor trials), the pooled system achieves a True Acceptance Rate of 83.3% with a False Acceptance Rate of 9.5% at the chosen operating point. Performance varies substantially by artist, with near-zero false acceptance for some verifiers and elevated confusability for others. A pairwise attribution of false accepts indicates structured error pathways consistent with stylistic proximity and shared drawing conventions, whilst also motivating tighter control of digitisation artefacts and threshold calibration. The proposed methodology is designed to complement, rather than replace, connoisseurship by providing reproducible, quantitative evidence suitable for data-scarce settings common in historical sketch attribution.

</details>


### [7] [Deep Feature Deformation Weights](https://arxiv.org/abs/2601.12527)
*Richard Liu,Itai Lang,Rana Hanocka*

Main category: cs.CV

TL;DR: 结合传统精确控制与数据驱动语义先验，通过深度特征实现快速、语义化的网格变形，支持实时处理百万面网格。


<details>
  <summary>Details</summary>
Motivation: 传统网格变形技术需要用户预先知道控制手柄的理想分布，而数据驱动方法虽能获得语义编辑但速度慢且不精确。本文旨在融合两者的优势。

Method: 采用深度特征蒸馏管道（barycentric feature distillation），利用形状渲染的视觉信号最小化蒸馏成本，支持高分辨率网格的快速权重计算。

Result: 提出的技术能在消费级机器上实时处理高达100万面的网格变形，并支持语义部分的共变形和对称保持变形。

Conclusion: 该论文提出了一种结合传统精确控制和数据驱动语义先验的网格变形技术，通过深度特征接近性实现平滑且语义化的变形权重，无需额外正则化，并能实时计算。

Abstract: Handle-based mesh deformation has been a long-standing paradigm in computer graphics, enabling intuitive shape edits from sparse controls. Classic techniques offer precise and rapid deformation control. However, they solve an optimization problem with constraints defined by control handle placement, requiring a user to know apriori the ideal distribution of handles on the shape to accomplish the desired edit. The mapping from handle set to deformation behavior is often unintuitive and, importantly, non-semantic. Modern data-driven methods, on the other hand, leverage a data prior to obtain semantic edits, but are slow and imprecise. We propose a technique that fuses the semantic prior of data with the precise control and speed of traditional frameworks. Our approach is surprisingly simple yet effective: deep feature proximity makes for smooth and semantic deformation weights, with no need for additional regularization. The weights can be computed in real-time for any surface point, whereas prior methods require optimization for new handles. Moreover, the semantic prior from deep features enables co-deformation of semantic parts. We introduce an improved feature distillation pipeline, barycentric feature distillation, which efficiently uses the visual signal from shape renders to minimize distillation cost. This allows our weights to be computed for high resolution meshes in under a minute, in contrast to potentially hours for both classical and neural methods. We preserve and extend properties of classical methods through feature space constraints and locality weighting. Our field representation allows for automatic detection of semantic symmetries, which we use to produce symmetry-preserving deformations. We show a proof-of-concept application which can produce deformations for meshes up to 1 million faces in real-time on a consumer-grade machine.

</details>


### [8] [A one-step generation model with a Single-Layer Transformer: Layer number re-distillation of FreeFlow](https://arxiv.org/abs/2601.11630)
*Haonan Wei,Linyuan Wang,Nuolin Sun,Zhizhong Zheng,Lei Li,Bin Yan*

Main category: cs.CV

TL;DR: SLT通过单层Transformer蒸馏FreeFlow的28层模型，大幅减少参数并提升生成效率和质量。


<details>
  <summary>Details</summary>
Motivation: 观察到FreeFlow的28层Transformer架构可视为ODE的欧拉离散化方案，希望通过蒸馏减少层数，提升效率。

Method: 提出SLT（Single-Layer Transformer），使用单一共享DiT块近似28层教师模型的深度特征演化。训练时匹配教师中间特征并融合，同时对齐最终速度预测。

Result: 将参数从675M压缩至4.3M，实验显示在相同时间内可筛选100+噪声点，显著提升生成稳定性和质量。

Conclusion: SLT通过蒸馏训练将28层Transformer块压缩为单一共享块，显著减少参数数量并提升生成质量。在相同时间内，SLT能筛选更多噪声空间候选点，从而为教师模型FreeFlow选择更高质量的初始点，最终提升生成图像的稳定性和平均质量。

Abstract: Currently, Flow matching methods aim to compress the iterative generation process of diffusion models into a few or even a single step, with MeanFlow and FreeFlow being representative achievements of one-step generation based on Ordinary Differential Equations (ODEs). We observe that the 28-layer Transformer architecture of FreeFlow can be characterized as an Euler discretization scheme for an ODE along the depth axis, where the layer index serves as the discrete time step. Therefore, we distill the number of layers of the FreeFlow model, following the same derivation logic as FreeFlow, and propose SLT (Single-Layer Transformer), which uses a single shared DiT block to approximate the depth-wise feature evolution of the 28-layer teacher. During training, it matches the teacher's intermediate features at several depth patches, fuses those patch-level representations, and simultaneously aligns the teacher's final velocity prediction. Through distillation training, we compress the 28 independent Transformer Blocks of the teacher model DiT-XL/2 into a single Transformer Block, reducing the parameter count from 675M to 4.3M. Furthermore, leveraging its minimal parameters and rapid sampling speed, SLT can screen more candidate points in the noise space within the same timeframe, thereby selecting higher-quality initial points for the teacher model FreeFlow and ultimately enhancing the quality of generated images. Experimental results demonstrate that within a time budget comparable to two random samplings of the teacher model, our method performs over 100 noise screenings and produces a high-quality sample through the teacher model using the selected points. Quality fluctuations caused by low-quality initial noise under a limited number of FreeFlow sampling calls are effectively avoided, substantially improving the stability and average generation quality of one-step generation.

</details>


### [9] [Rig-Aware 3D Reconstruction of Vehicle Undercarriages using Gaussian Splatting](https://arxiv.org/abs/2601.14208)
*Nitin Kulkarni,Akhil Devarashetti,Charlie Cluss,Livio Forte,Dan Buckmaster,Philip Schneider,Chunming Qiao,Alina Vereshchaka*

Main category: cs.CV

TL;DR: 提出三相机系统生成交互式3D底盘模型，提升检查效率和买家信心，通过先进SfM技术克服广角畸变和低视差挑战。


<details>
  <summary>Details</summary>
Motivation: 传统底盘检查需人工爬入车底，效率低且在线买家难以查看底盘照片。

Method: 通过集成精确相机校准、同步视频流和相机支架的几何先验，克服广角镜头畸变和低视差场景的挑战。使用DISK特征提取器和LightGlue匹配器生成高质量稀疏点云，并通过高斯泼溅生成实时渲染的逼真模型。

Result: 实验证明，该方法能生成高质量3D底盘模型，实现实时渲染，并在质量和效率上达到领先水平。

Conclusion: 该论文提出了一种端到端的三相机系统管道，用于生成交互式3D底盘模型，显著提升了检查效率和买家信心。

Abstract: Inspecting the undercarriage of used vehicles is a labor-intensive task that requires inspectors to crouch or crawl underneath each vehicle to thoroughly examine it. Additionally, online buyers rarely see undercarriage photos. We present an end-to-end pipeline that utilizes a three-camera rig to capture videos of the undercarriage as the vehicle drives over it, and produces an interactive 3D model of the undercarriage. The 3D model enables inspectors and customers to rotate, zoom, and slice through the undercarriage, allowing them to detect rust, leaks, or impact damage in seconds, thereby improving both workplace safety and buyer confidence. Our primary contribution is a rig-aware Structure-from-Motion (SfM) pipeline specifically designed to overcome the challenges of wide-angle lens distortion and low-parallax scenes. Our method overcomes the challenges of wide-angle lens distortion and low-parallax scenes by integrating precise camera calibration, synchronized video streams, and strong geometric priors from the camera rig. We use a constrained matching strategy with learned components, the DISK feature extractor, and the attention-based LightGlue matcher to generate high-quality sparse point clouds that are often unattainable with standard SfM pipelines. These point clouds seed the Gaussian splatting process to generate photorealistic undercarriage models that render in real-time. Our experiments and ablation studies demonstrate that our design choices are essential to achieve state-of-the-art quality.

</details>


### [10] [Compress to Focus: Efficient Coordinate Compression for Policy Optimization in Multi-Turn GUI Agents](https://arxiv.org/abs/2601.11631)
*Yurun Song,Jiong Yin,Rongjunchen Zhang,Ian G. Harris*

Main category: cs.CV

TL;DR: CCPO框架通过视觉压缩与策略优化结合，显著提升多轮GUI代理效率与性能。


<details>
  <summary>Details</summary>
Motivation: 解决多轮GUI代理因交互历史积累导致的上下文膨胀问题，现有方法在长时上下文或空间结构上存在妥协。

Method: 提出Coordinate Compression Policy Optimization (CCPO)框架，包含Coordinate-Aware Spatial Compression (CASC)和Distance-Based Advantage，通过聚合坐标和基于距离的优势信号优化策略。

Result: 在四个基准测试中达到SOTA性能，实现55%令牌压缩和3.8倍训练加速。

Conclusion: CCPO通过结合视觉压缩与策略优化，显著提升了多轮GUI代理的性能，实现了高达55%的令牌压缩和3.8倍的训练加速。

Abstract: Multi-turn GUI agents enable complex task completion through sequential decision-making, but suffer from severe context inflation as interaction history accumulates. Existing strategies either sacrifice long-term context via truncation or compromise spatial structure through token pruning. In this paper, we propose Coordinate Compression Policy Optimization (CCPO), an efficient policy optimization framework that couples visual compression with policy optimization for multi-turn GUI agents. CCPO introduces Coordinate-Aware Spatial Compression (CASC), which aggregates coordinates from multiple rollouts to capture target-relevant regions and progressively narrow historical attention around key visual areas. From interactions across rollouts, CASC adaptively constructs attention boundaries that concentrate computation on the most informative regions of the scene. We further design a Distance-Based Advantage that provides fine-grained learning signals based on distance rather than binary correctness, improving both grounding accuracy and compression quality. Extensive experiments demonstrate that CCPO achieves SOTA performance across four benchmarks with up to 55% token compression and 3.8$\times$ training speedup.

</details>


### [11] [KG-ViP: Bridging Knowledge Grounding and Visual Perception in Multi-modal LLMs for Visual Question Answering](https://arxiv.org/abs/2601.11632)
*Zhiyang Li,Ao Ke,Yukun Cao,Xike Xie*

Main category: cs.CV

TL;DR: KG-ViP通过融合场景图和常识图，解决了MLLMs在VQA中的知识幻觉和视觉感知不足问题，实验证明其性能显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 多模态大型语言模型在视觉问答中存在知识幻觉和细粒度视觉感知不足的缺陷，而场景图和常识图分别能提供外部知识和细粒度视觉细节，但以往工作未充分利用二者的协同潜力。

Method: 提出KG-ViP框架，采用检索与融合的流程，通过查询作为语义桥梁逐步整合场景图和常识图，生成统一的结构化上下文。

Result: 在FVQA 2.0+和MVQA基准测试中，KG-ViP显著优于现有VQA方法。

Conclusion: KG-ViP框架通过融合场景图和常识图，显著提升了多模态大型语言模型在视觉问答任务中的表现，解决了知识幻觉和细粒度视觉感知不足的问题。

Abstract: Multi-modal Large Language Models (MLLMs) for Visual Question Answering (VQA) often suffer from dual limitations: knowledge hallucination and insufficient fine-grained visual perception. Crucially, we identify that commonsense graphs and scene graphs provide precisely complementary solutions to these respective deficiencies by providing rich external knowledge and capturing fine-grained visual details. However, prior works typically treat them in isolation, overlooking their synergistic potential. To bridge this gap, we propose KG-ViP, a unified framework that empowers MLLMs by fusing scene graphs and commonsense graphs. The core of the KG-ViP framework is a novel retrieval-and-fusion pipeline that utilizes the query as a semantic bridge to progressively integrate both graphs, synthesizing a unified structured context that facilitates reliable multi-modal reasoning. Extensive experiments on FVQA 2.0+ and MVQA benchmarks demonstrate that KG-ViP significantly outperforms existing VQA methods.

</details>


### [12] [Beyond Accuracy: Evaluating Grounded Visual Evidence in Thinking with Images](https://arxiv.org/abs/2601.11633)
*Xuchen Li,Xuzhao Li,Renjie Pi,Shiyu Hu,Jian Zhao,Jiahui Gao*

Main category: cs.CV

TL;DR: ViEBench是一个新的视觉推理基准，通过细粒度任务分类和双轴矩阵评估VLMs的真实推理能力，发现模型存在定位与推理不一致的问题。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要依赖结果导向的准确性，缺乏评估模型是否能准确利用细粒度视觉线索进行多步推理的能力。

Method: ViEBench是一个过程可验证的基准，包含200个多场景高分辨率图像和专家标注的视觉证据，任务按难度分为感知和推理维度，推理任务需要利用局部视觉细节和先验知识。

Result: 实验发现：（1）VLMs有时会基于无关区域产生正确答案；（2）它们可能成功定位正确证据但仍无法利用其得出准确结论。

Conclusion: ViEBench被提出作为一个更可解释和实用的基准，用于全面评估视觉语言模型（VLMs）的有效性。

Abstract: Despite the remarkable progress of Vision-Language Models (VLMs) in adopting "Thinking-with-Images" capabilities, accurately evaluating the authenticity of their reasoning process remains a critical challenge. Existing benchmarks mainly rely on outcome-oriented accuracy, lacking the capability to assess whether models can accurately leverage fine-grained visual cues for multi-step reasoning. To address these limitations, we propose ViEBench, a process-verifiable benchmark designed to evaluate faithful visual reasoning. Comprising 200 multi-scenario high-resolution images with expert-annotated visual evidence, ViEBench uniquely categorizes tasks by difficulty into perception and reasoning dimensions, where reasoning tasks require utilizing localized visual details with prior knowledge. To establish comprehensive evaluation criteria, we introduce a dual-axis matrix that provides fine-grained metrics through four diagnostic quadrants, enabling transparent diagnosis of model behavior across varying task complexities. Our experiments yield several interesting observations: (1) VLMs can sometimes produce correct final answers despite grounding on irrelevant regions, and (2) they may successfully locate the correct evidence but still fail to utilize it to reach accurate conclusions. Our findings demonstrate that ViEBench can serve as a more explainable and practical benchmark for comprehensively evaluating the effectiveness agentic VLMs. The codes will be released at: https://github.com/Xuchen-Li/ViEBench.

</details>


### [13] [When Rules Fall Short: Agent-Driven Discovery of Emerging Content Issues in Short Video Platforms](https://arxiv.org/abs/2601.11634)
*Chenghui Yu,Hongwei Wang,Junwen Chen,Zixuan Wang,Bingfeng Deng,Zhuolin Hao,Hongyu Xiong,Yang Song*

Main category: cs.CV

TL;DR: 提出基于多模态LLM代理的自动问题发现方法，显著提升效率并加速标注策略迭代。


<details>
  <summary>Details</summary>
Motivation: 传统人工发现问题速度过慢，导致标注策略更新延迟，影响内容治理效果。

Method: 采用两阶段聚类策略对潜在新问题的短视频进行分组，每个聚类对应一个新发现的问题，并由代理生成更新的标注策略。

Result: 离线与在线实验显示，该方法显著提升了问题发现的F1分数（超过20%），并减少了问题视频的观看量（约15%）。

Conclusion: 基于多模态LLM代理的自动问题发现方法显著提升了新兴问题的发现效率，并优化了后续治理效果，同时大幅降低了时间成本。

Abstract: Trends on short-video platforms evolve at a rapid pace, with new content issues emerging every day that fall outside the coverage of existing annotation policies. However, traditional human-driven discovery of emerging issues is too slow, which leads to delayed updates of annotation policies and poses a major challenge for effective content governance. In this work, we propose an automatic issue discovery method based on multimodal LLM agents. Our approach automatically recalls short videos containing potential new issues and applies a two-stage clustering strategy to group them, with each cluster corresponding to a newly discovered issue. The agent then generates updated annotation policies from these clusters, thereby extending coverage to these emerging issues. Our agent has been deployed in the real system. Both offline and online experiments demonstrate that this agent-based method significantly improves the effectiveness of emerging-issue discovery (with an F1 score improvement of over 20%) and enhances the performance of subsequent issue governance (reducing the view count of problematic videos by approximately 15%). More importantly, compared to manual issue discovery, it greatly reduces time costs and substantially accelerates the iteration of annotation policies.

</details>


### [14] [Now You See Me, Now You Don't: A Unified Framework for Expression Consistent Anonymization in Talking Head Videos](https://arxiv.org/abs/2601.11635)
*Anil Egin,Andrea Tangherloni,Antitza Dantcheva*

Main category: cs.CV

TL;DR: Anon-NET是一种新型面部视频匿名化框架，通过扩散模型和视频驱动动画实现隐私保护，同时保留原始视频的关键属性。


<details>
  <summary>Details</summary>
Motivation: 为了保护隐私同时允许在计算机视觉下游任务（如表情识别、人员跟踪和动作识别）中分析视频。

Method: 通过基于扩散的生成模型进行面部修复，结合高级属性识别和运动感知的表情转移，然后通过视频驱动动画对去身份化的面部进行动画处理。

Result: 在VoxCeleb2、CelebV-HQ和HDTF数据集上的大量实验表明，Anon-NET在混淆身份的同时保持了视觉真实性和时间一致性。

Conclusion: Anon-NET是一种有效的面部视频匿名化框架，能够在保护隐私的同时保留原始视频的年龄、性别、种族、姿态和表情等属性。

Abstract: Face video anonymization is aimed at privacy preservation while allowing for the analysis of videos in a number of computer vision downstream tasks such as expression recognition, people tracking, and action recognition. We propose here a novel unified framework referred to as Anon-NET, streamlined to de-identify facial videos, while preserving age, gender, race, pose, and expression of the original video. Specifically, we inpaint faces by a diffusion-based generative model guided by high-level attribute recognition and motion-aware expression transfer. We then animate deidentified faces by video-driven animation, which accepts the de-identified face and the original video as input. Extensive experiments on the datasets VoxCeleb2, CelebV-HQ, and HDTF, which include diverse facial dynamics, demonstrate the effectiveness of AnonNET in obfuscating identity while retaining visual realism and temporal consistency. The code of AnonNet will be publicly released.

</details>


### [15] [Evaluating Self-Correcting Vision Agents Through Quantitative and Qualitative Metrics](https://arxiv.org/abs/2601.11637)
*Aradhya Dixit*

Main category: cs.CV

TL;DR: 该研究通过诊断性微基准测试揭示了视觉语言智能体在自我修正中的瓶颈，特别是语义漂移，为改进多模态智能体提供了方向。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态基础模型的最新进展使得视觉语言智能体（VLAs）能够将复杂视觉任务分解为可执行的工具计划，但迭代自我修正的定量限制和主导推理瓶颈仍未明确表征。

Method: 引入了一个诊断性微基准测试，分析解耦了任务成功率（TSR）和修正成功率（CSR），并量化了修正的递减回报。通过失败分类法识别了语义漂移为主要瓶颈。

Result: 任务成功率为62%，修正成功率为25%至33%，修正效果在三次尝试后趋于饱和。语义漂移约占失败的28%。

Conclusion: 该基准测试通过解耦任务成功率（TSR）和修正成功率（CSR），揭示了初始能力与修复能力之间的不相关性，并量化了修正的递减回报。通过失败分类法，明确了语义漂移（约占失败的28%）是主要瓶颈，为构建状态感知、可信赖的多模态智能体提供了可复现的框架。

Abstract: Recent progress in multimodal foundation models has enabled Vision-Language Agents (VLAs) to decompose complex visual tasks into executable tool-based plans. While recent benchmarks have begun to evaluate iterative self-correction, its quantitative limits and dominant reasoning bottlenecks remain poorly characterized. This work introduces a Diagnostic Micro-Benchmark. Our analysis decouples Task Success Rate (TSR = 62 percent) from Correction Success Rate (CSR = 25 to 33 percent), revealing that initial competence does not predict repair ability. We explicitly quantify the diminishing returns of correction, which saturates after three retries. Our Failure Taxonomy reveals a frequent factor is Semantic Drift (about 28 percent of failures), a loss of contextual state. By isolating this reasoning bottleneck, this benchmark defines a reproducible framework toward stateful, trustworthy multimodal agents.

</details>


### [16] [Confident Learning for Object Detection under Model Constraints](https://arxiv.org/abs/2601.11640)
*Yingda Yu,Jiaqi Xuan,Shuhui Shi,Xuanyu Teng,Shuyang Xu,Guanchao Tong*

Main category: cs.CV

TL;DR: MDDC框架通过数据质量优化提升边缘设备上的杂草检测性能，实验显示mAP@0.5提升5-25%。


<details>
  <summary>Details</summary>
Motivation: 农业杂草检测在边缘设备上受到模型容量、计算资源和实时推理延迟的严格限制，无法通过模型扩展或集成来提升性能。

Method: 提出了Model-Driven Data Correction (MDDC)框架，通过迭代诊断和纠正数据质量缺陷来提升检测性能。自动化错误分析过程将检测失败分为四类：假阴性、假阳性、类别混淆和定位错误。这些错误模式通过结构化的训练-修复-再训练流程和版本控制的数据管理得到系统解决。

Result: 在多个杂草检测数据集上的实验结果表明，使用固定的轻量级检测器（YOLOv8n）时，mAP@0.5持续提升了5-25%。

Conclusion: 系统化的数据质量优化可以有效缓解固定模型容量约束下的性能瓶颈。

Abstract: Agricultural weed detection on edge devices is subject to strict constraints on model capacity, computational resources, and real-time inference latency, which prevent performance improvements through model scaling or ensembling. This paper proposes Model-Driven Data Correction (MDDC), a data-centric framework that enhances detection performance by iteratively diagnosing and correcting data quality deficiencies. An automated error analysis procedure categorizes detection failures into four types: false negatives, false positives, class confusion, and localization errors. These error patterns are systematically addressed through a structured train-fix-retrain pipeline with version-controlled data management. Experimental results on multiple weed detection datasets demonstrate consistent improvements of 5-25 percent in mAP at 0.5 using a fixed lightweight detector (YOLOv8n), indicating that systematic data quality optimization can effectively alleviate performance bottlenecks under fixed model capacity constraints.

</details>


### [17] [Mixture of Distributions Matters: Dynamic Sparse Attention for Efficient Video Diffusion Transformers](https://arxiv.org/abs/2601.11641)
*Yuxi Liu,Yipeng Hu,Zekun Zhang,Kunze Jiang,Kun Yuan*

Main category: cs.CV

TL;DR: MOD-DiT是一种新型动态注意力框架，通过两阶段方法提升视频生成效率和质量，克服传统稀疏注意力的计算限制。


<details>
  <summary>Details</summary>
Motivation: 解决DiTs在视频生成中因自注意力机制的二次复杂度导致的效率低下问题，以及现有稀疏注意力方法的不足。

Method: 提出了一种名为MOD-DiT的无采样动态注意力框架，通过先验信息和分布式混合方法建模线性近似模型，预测掩码模式，并结合在线块掩码策略动态应用这些掩码。

Result: 在多个基准测试和模型架构中实现了加速和质量提升。

Conclusion: MOD-DiT通过两阶段动态注意力框架，显著提升了视频生成的效率和质量，克服了传统稀疏注意力方法的计算限制。

Abstract: While Diffusion Transformers (DiTs) have achieved notable progress in video generation, this long-sequence generation task remains constrained by the quadratic complexity inherent to self-attention mechanisms, creating significant barriers to practical deployment. Although sparse attention methods attempt to address this challenge, existing approaches either rely on oversimplified static patterns or require computationally expensive sampling operations to achieve dynamic sparsity, resulting in inaccurate pattern predictions and degraded generation quality. To overcome these limitations, we propose a \underline{\textbf{M}}ixtrue-\underline{\textbf{O}}f-\underline{\textbf{D}}istribution \textbf{DiT} (\textbf{MOD-DiT}), a novel sampling-free dynamic attention framework that accurately models evolving attention patterns through a two-stage process. First, MOD-DiT leverages prior information from early denoising steps and adopts a {distributed mixing approach} to model an efficient linear approximation model, which is then used to predict mask patterns for a specific denoising interval. Second, an online block masking strategy dynamically applies these predicted masks while maintaining historical sparsity information, eliminating the need for repetitive sampling operations. Extensive evaluations demonstrate consistent acceleration and quality improvements across multiple benchmarks and model architectures, validating MOD-DiT's effectiveness for efficient, high-quality video generation while overcoming the computational limitations of traditional sparse attention approaches.

</details>


### [18] [PSSF: Early osteoarthritis detection using physical synthetic knee X-ray scans and AI radiomics models](https://arxiv.org/abs/2601.11642)
*Abbas Alzubaidi,Ali Al-Bayaty*

Main category: cs.CV

TL;DR: 该研究开发了一种物理基础合成模拟框架（PSSF），用于生成可控的膝关节X射线扫描图像，解决了数据隐私和获取难题，并通过机器学习验证了其可行性。


<details>
  <summary>Details</summary>
Motivation: 膝关节OA是全球残疾的主要原因，但目前主要依赖主观的放射学评分（如KL量表）。AI和放射组学虽能提供定量评估工具，但依赖大量标注良好的图像数据集，这些数据因隐私、治理和资源限制难以获取。

Method: 研究采用物理基础合成模拟框架（PSSF）生成膝关节X射线扫描图像，并通过自动定位、预处理和IBSI标准化处理，利用逻辑回归、随机森林和梯度提升三种机器学习模型进行训练和预测。

Result: 研究成功生成了一个包含180名受试者（260个膝盖）的虚拟队列，并在三种协议（参考、低剂量和几何偏移）下成像。机器学习模型在IBSI协议、跨协议和多协议场景下表现出鲁棒性，特征稳定性通过组内相关系数评估。

Conclusion: 该研究提出的物理基础合成模拟框架（PSSF）能够在不侵犯患者隐私和机构限制的情况下生成可控的X射线扫描图像，为膝关节骨关节炎（OA）的定量评估提供了新工具。通过虚拟队列和机器学习模型的验证，证明了该方法的可行性和鲁棒性。

Abstract: Knee osteoarthritis (OA) is a major cause of disability worldwide and is still largely assessed using subjective radiographic grading, most commonly the Kellgren-Lawrence (KL) scale. Artificial intelligence (AI) and radiomics offer quantitative tools for OA assessment but depend on large, well-annotated image datasets, mainly X-ray scans, that are often difficult to obtain because of privacy, governance and resourcing constraints. In this research, we introduce a physics-based synthetic simulation framework (PSSF) to fully generate controllable X-ray scans without patients' involvement and violating their privacy and institutional constraints. This PSSF is a 2D X-ray projection simulator of anteroposterior knee radiographs from a parametric anatomical model of the distal femur and proximal tibia. Using PSSF, we create a virtual cohort of 180 subjects (260 knees), each is imaged under three protocols (reference, low-dose, and geometry-shift). Medial joint regions are automatically localized, preprocessed, and processed with the Image Biomarker Standardisation Initiative (IBSI). Practically, three machine learning (ML) models are utilized, logistic regression, random forest, and gradient boosting, to train binary (KL-like "0" vs. "2") and three-class (0-2) prediction radiographic images. Robustness is assessed within IBSI protocol, cross-protocol, and multi-protocol scenarios. Finally, features stability is then evaluated using intraclass correlation coefficients across acquisition changes.

</details>


### [19] [Predicting When to Trust Vision-Language Models for Spatial Reasoning](https://arxiv.org/abs/2601.11644)
*Muhammad Imran,Yugyung Lee*

Main category: cs.CV

TL;DR: A vision-based framework improves VLM spatial reasoning reliability by geometric verification, outperforming self-assessment methods with significant accuracy and coverage gains.


<details>
  <summary>Details</summary>
Motivation: VLMs exhibit systematic spatial reasoning failures, which is a critical issue for safe deployment in robotics and autonomous systems, necessitating a method to predict when to trust VLM spatial predictions.

Method: A vision-based confidence estimation framework that combines four signals (geometric alignment, spatial ambiguity, detection quality, and VLM internal uncertainty) via gradient boosting for independent geometric verification.

Result: The framework achieves 0.674 AUROC on BLIP-2 (34.0% improvement over baselines) and 0.583 AUROC on CLIP (16.1% improvement), with feature analysis showing 87.4% contribution from vision-based signals. Selective prediction at 60% target accuracy achieves 61.9% coverage (2.2x improvement).

Conclusion: The proposed vision-based confidence estimation framework significantly improves the reliability of Vision-Language Models (VLMs) in spatial reasoning tasks by leveraging geometric verification, outperforming text-based self-assessment methods.

Abstract: Vision-Language Models (VLMs) demonstrate impressive capabilities across multimodal tasks, yet exhibit systematic spatial reasoning failures, achieving only 49% (CLIP) to 54% (BLIP-2) accuracy on basic directional relationships. For safe deployment in robotics and autonomous systems, we need to predict when to trust VLM spatial predictions rather than accepting all outputs. We propose a vision-based confidence estimation framework that validates VLM predictions through independent geometric verification using object detection. Unlike text-based approaches relying on self-assessment, our method fuses four signals via gradient boosting: geometric alignment between VLM claims and coordinates, spatial ambiguity from overlap, detection quality, and VLM internal uncertainty. We achieve 0.674 AUROC on BLIP-2 (34.0% improvement over text-based baselines) and 0.583 AUROC on CLIP (16.1% improvement), generalizing across generative and classification architectures. Our framework enables selective prediction: at 60% target accuracy, we achieve 61.9% coverage versus 27.6% baseline (2.2x improvement) on BLIP-2. Feature analysis reveals vision-based signals contribute 87.4% of model importance versus 12.7% from VLM confidence, validating that external geometric verification outperforms self-assessment. We demonstrate reliable scene graph construction where confidence-based pruning improves precision from 52.1% to 78.3% while retaining 68.2% of edges.

</details>


### [20] [IMSAHLO: Integrating Multi-Scale Attention and Hybrid Loss Optimization Framework for Robust Neuronal Brain Cell Segmentation](https://arxiv.org/abs/2601.11645)
*Ujjwal Jain,Oshin Misra,Roshni Chakraborty,Mahua Bhattacharya*

Main category: cs.CV

TL;DR: IMSAHLO框架通过多尺度注意力和混合损失优化，显著提升了神经元细胞分割的准确性和鲁棒性，适用于复杂生物医学图像。


<details>
  <summary>Details</summary>
Motivation: 荧光显微镜中神经元细胞的准确分割是计算神经科学定量分析的基本任务，但由于密集和稀疏分布的细胞共存、复杂的重叠形态以及严重的类别不平衡等挑战，传统深度学习模型往往难以保留精细的拓扑细节或准确描绘边界。

Method: 提出了一种名为IMSAHLO的深度学习框架，结合了多尺度密集块（MSDBs）以捕捉不同感受野的特征，以及分层注意力（HA）机制来自适应聚焦于显著形态特征。此外，还引入了混合损失函数，结合Tversky和Focal损失以应对类别不平衡，以及拓扑感知的中心线Dice（clDice）损失和轮廓加权边界损失。

Result: 在公开的荧光神经元细胞（FNC）数据集上的大规模实验表明，该框架在密集和稀疏案例中表现优异，精确度达81.4%，宏F1分数82.7%，微F1分数83.3%，平衡准确率达99.5%。消融研究验证了多尺度注意力和混合损失项的协同效益。

Conclusion: 该研究为适用于广泛生物医学成像模式的通用分割模型奠定了基础，推动了AI辅助分析向高通量神经生物学流程的发展。

Abstract: Accurate segmentation of neuronal cells in fluorescence microscopy is a fundamental task for quantitative analysis in computational neuroscience. However, it is significantly impeded by challenges such as the coexistence of densely packed and sparsely distributed cells, complex overlapping morphologies, and severe class imbalance. Conventional deep learning models often fail to preserve fine topological details or accurately delineate boundaries under these conditions. To address these limitations, we propose a novel deep learning framework, IMSAHLO (Integrating Multi-Scale Attention and Hybrid Loss Optimization), for robust and adaptive neuronal segmentation. The core of our model features Multi-Scale Dense Blocks (MSDBs) to capture features at various receptive fields, effectively handling variations in cell density, and a Hierarchical Attention (HA) mechanism that adaptively focuses on salient morphological features to preserve Region of Interest (ROI) boundary details. Furthermore, we introduce a novel hybrid loss function synergistically combining Tversky and Focal loss to combat class imbalance, alongside a topology-aware Centerline Dice (clDice) loss and a Contour-Weighted Boundary loss to ensure topological continuity and precise separation of adjacent cells. Large-scale experiments on the public Fluorescent Neuronal Cells (FNC) dataset demonstrate that our framework outperforms state-of-the-art architectures, achieving precision of 81.4%, macro F1 score of 82.7%, micro F1 score of 83.3%, and balanced accuracy of 99.5% on difficult dense and sparse cases. Ablation studies validate the synergistic benefits of multi-scale attention and hybrid loss terms. This work establishes a foundation for generalizable segmentation models applicable to a wide range of biomedical imaging modalities, pushing AI-assisted analysis toward high-throughput neurobiological pipelines.

</details>


### [21] [Aesthetics as Structural Harm: Algorithmic Lookism Across Text-to-Image Generation and Classification](https://arxiv.org/abs/2601.11651)
*Miriam Doh,Aditya Gulati,Corina Canali,Nuria Oliver*

Main category: cs.CV

TL;DR: 研究发现生成AI模型系统性地将外貌与正面属性关联，并在性别分类中表现出偏见，加剧了不平等。


<details>
  <summary>Details</summary>
Motivation: 探讨生成AI模型中是否存在基于外貌的系统性偏见，以及这些偏见如何影响下游任务（如性别分类）。

Method: 通过分析Stable Diffusion 2.1和3.5 Medium生成的26,400张合成人脸，研究生成AI模型如何系统地将面部吸引力与正面属性关联。

Result: 研究发现：(1) T2I模型系统性地编码了吸引力与正面属性的关联；(2) 性别分类算法中存在显著偏见，女性面孔（尤其是带有负面属性的）误分类率更高；(3) 新模型通过年龄同质化、性别化曝光模式和地理简化加剧了审美约束。

Conclusion: 本文揭示了算法外貌主义在文本到图像生成AI和性别分类任务中的系统性偏见，强调了这些偏见如何通过代表性和识别加剧现有不平等。

Abstract: This paper examines algorithmic lookism-the systematic preferential treatment based on physical appearance-in text-to-image (T2I) generative AI and a downstream gender classification task. Through the analysis of 26,400 synthetic faces created with Stable Diffusion 2.1 and 3.5 Medium, we demonstrate how generative AI models systematically associate facial attractiveness with positive attributes and vice-versa, mirroring socially constructed biases rather than evidence-based correlations. Furthermore, we find significant gender bias in three gender classification algorithms depending on the attributes of the input faces. Our findings reveal three critical harms: (1) the systematic encoding of attractiveness-positive attribute associations in T2I models; (2) gender disparities in classification systems, where women's faces, particularly those generated with negative attributes, suffer substantially higher misclassification rates than men's; and (3) intensifying aesthetic constraints in newer models through age homogenization, gendered exposure patterns, and geographic reductionism. These convergent patterns reveal algorithmic lookism as systematic infrastructure operating across AI vision systems, compounding existing inequalities through both representation and recognition.
  Disclaimer: This work includes visual and textual content that reflects stereotypical associations between physical appearance and socially constructed attributes, including gender, race, and traits associated with social desirability. Any such associations found in this study emerge from the biases embedded in generative AI systems-not from empirical truths or the authors' views.

</details>


### [22] [PSSI-MaxST: An Efficient Pixel-Segment Similarity Index Using Intensity and Smoothness Features for Maximum Spanning Tree Based Segmentation](https://arxiv.org/abs/2601.11654)
*Kaustubh Shivshankar Shejole,Gaurav Mishra*

Main category: cs.CV

TL;DR: 提出PSSI-MaxST方法，结合PSSI、MeanShift和MaxST，显著提升交互式图分割性能，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有交互式图分割方法存在计算成本高、对用户输入敏感、前景与背景颜色分布相似时性能下降等问题，亟需改进。

Method: 结合了PSSI（像素段相似性指数）、MeanShift和MaxST（最大生成树），通过多特征联合捕获（颜色相似性、平滑度、纹理、形状和强局部连接性）实现高效分割。

Result: 实验结果表明，PSSI-MaxST在Jaccard指数（IoU）、F1分数、执行时间和平均误差（ME）上均优于现有方法。

Conclusion: 提出的PSSI-MaxST方法在GrabCut和Images250数据集上表现出色，显著优于现有方法（如AMOE、OneCut和SSNCut），在分割质量、执行时间和平均误差等方面均有提升。

Abstract: Interactive graph-based segmentation methods partition an image into foreground and background regions with the aid of user inputs. However, existing approaches often suffer from high computational costs, sensitivity to user interactions, and degraded performance when the foreground and background share similar color distributions. A key factor influencing segmentation performance is the similarity measure used for assigning edge weights in the graph. To address these challenges, we propose a novel Pixel Segment Similarity Index (PSSI), which leverages the harmonic mean of inter-channel similarities by incorporating both pixel intensity and spatial smoothness features. The harmonic mean effectively penalizes dissimilarities in any individual channel, enhancing robustness. The computational complexity of PSSI is $\mathcal{O}(B)$, where $B$ denotes the number of histogram bins. Our segmentation framework begins with low-level segmentation using MeanShift, which effectively captures color, texture, and segment shape. Based on the resulting pixel segments, we construct a pixel-segment graph with edge weights determined by PSSI. For partitioning, we employ the Maximum Spanning Tree (MaxST), which captures strongly connected local neighborhoods beneficial for precise segmentation. The integration of the proposed PSSI, MeanShift, and MaxST allows our method to jointly capture color similarity, smoothness, texture, shape, and strong local connectivity. Experimental evaluations on the GrabCut and Images250 datasets demonstrate that our method consistently outperforms current graph-based interactive segmentation methods such as AMOE, OneCut, and SSNCut in terms of segmentation quality, as measured by Jaccard Index (IoU), $F_1$ score, execution time and Mean Error (ME). Code is publicly available at: https://github.com/KaustubhShejole/PSSI-MaxST.

</details>


### [23] [Zeros can be Informative: Masked Binary U-Net for Image Segmentation on Tensor Cores](https://arxiv.org/abs/2601.11660)
*Chunshu Wu,Ruibing Song,Sushant Kondguli,Tong Geng,Ang Li*

Main category: cs.CV

TL;DR: MBU-Net通过掩码策略和GPU优化，在图像分割中实现高效与准确性平衡。


<details>
  <summary>Details</summary>
Motivation: 实时图像分割在资源受限的边缘设备上需要平衡准确性、延迟和能耗。二进制网络虽硬件友好，但存在准确率下降和缺乏端到端高效实现的挑战。

Method: 采用成本感知的掩码策略优化二进制U-Net权重，并开发了基于Tensor Core的GPU执行框架，通过减法位编码方案高效实现掩码二进制权重与二进制激活。

Result: 在3个分割基准测试中，MBU-Net接近全精度准确性（平均下降3%），同时比16位浮点U-Net提速2.04倍，能耗降低3.54倍。

Conclusion: MBU-Net通过成本感知的掩码策略和GPU执行框架，在保持接近全精度准确性的同时，实现了显著的加速和能耗降低。

Abstract: Real-time image segmentation is a key enabler for AR/VR, robotics, drones, and autonomous systems, where tight accuracy, latency, and energy budgets must be met on resource-constrained edge devices. While U-Net offers a favorable balance of accuracy and efficiency compared to large transformer-based models, achieving real-time performance on high-resolution input remains challenging due to compute, memory, and power limits. Extreme quantization, particularly binary networks, is appealing for its hardware-friendly operations. However, two obstacles limit practicality: (1) severe accuracy degradation, and (2) a lack of end-to-end implementations that deliver efficiency on general-purpose GPUs.
  We make two empirical observations that guide our design. (1) An explicit zero state is essential: training with zero masking to binary U-Net weights yields noticeable sparsity. (2) Quantization sensitivity is uniform across layers. Motivated by these findings, we introduce Masked Binary U-Net (MBU-Net), obtained through a cost-aware masking strategy that prioritizes masking where it yields the highest accuracy-per-cost, reconciling accuracy with near-binary efficiency.
  To realize these gains in practice, we develop a GPU execution framework that maps MBU-Net to Tensor Cores via a subtractive bit-encoding scheme, efficiently implementing masked binary weights with binary activations. This design leverages native binary Tensor Core BMMA instructions, enabling high throughput and energy savings on widely available GPUs. Across 3 segmentation benchmarks, MBU-Net attains near full-precision accuracy (3% average drop) while delivering 2.04x speedup and 3.54x energy reductions over a 16-bit floating point U-Net.

</details>


### [24] [LTV-YOLO: A Lightweight Thermal Object Detector for Young Pedestrians in Adverse Conditions](https://arxiv.org/abs/2601.11662)
*Abdullah Jirjees,Ryan Myers,Muhammad Haris Ikram,Mohamed H. Zaki*

Main category: cs.CV

TL;DR: 本文提出了一种轻量级热成像目标检测模型LTV-YOLO，专为在恶劣环境下检测儿童和青少年等VRUs而设计，优化了计算效率和实时性能。


<details>
  <summary>Details</summary>
Motivation: 在低光和恶劣天气条件下，传统RGB摄像头在可见光谱中的性能受限，难以可靠检测易受伤害的道路使用者（VRUs），尤其是儿童和青少年。本文旨在解决这一问题，提升智能交通系统中的行人安全。

Method: 基于YOLO11架构并针对热成像检测进行了定制，LTV-YOLO通过集成深度可分离卷积和特征金字塔网络（FPN），优化了计算效率和准确性，特别适用于检测小规模、部分遮挡和热特征明显的VRUs。

Result: LTV-YOLO在检测小规模、部分遮挡和热特征明显的VRUs方面表现出色，同时在边缘设备上保持了轻量化和实时性能。

Conclusion: 本文提出了一种名为LTV-YOLO的轻量级热成像目标检测模型，专为在恶劣环境下检测儿童和青少年等易受伤害的道路使用者（VRUs）而设计。该模型在边缘设备上实现了高效、准确和实时的性能，为智能交通系统中的行人安全提供了实用且可扩展的解决方案。

Abstract: Detecting vulnerable road users (VRUs), particularly children and adolescents, in low light and adverse weather conditions remains a critical challenge in computer vision, surveillance, and autonomous vehicle systems. This paper presents a purpose-built lightweight object detection model designed to identify young pedestrians in various environmental scenarios. To address these challenges, our approach leverages thermal imaging from long-wave infrared (LWIR) cameras, which enhances detection reliability in conditions where traditional RGB cameras operating in the visible spectrum fail. Based on the YOLO11 architecture and customized for thermal detection, our model, termed LTV-YOLO (Lightweight Thermal Vision YOLO), is optimized for computational efficiency, accuracy and real-time performance on edge devices. By integrating separable convolutions in depth and a feature pyramid network (FPN), LTV-YOLO achieves strong performance in detecting small-scale, partially occluded, and thermally distinct VRUs while maintaining a compact architecture. This work contributes a practical and scalable solution to improve pedestrian safety in intelligent transportation systems, particularly in school zones, autonomous navigation, and smart city infrastructure. Unlike prior thermal detectors, our contribution is task-specific: a thermally only edge-capable design designed for young and small VRUs (children and distant adults). Although FPN and depthwise separable convolutions are standard components, their integration into a thermal-only pipeline optimized for short/occluded VRUs under adverse conditions is, to the best of our knowledge, novel.

</details>


### [25] [UAV-Based Infrastructure Inspections: A Literature Review and Proposed Framework for AEC+FM](https://arxiv.org/abs/2601.11665)
*Amir Farzin Nikkhah,Dong Chen,Bradford Campbell,Somayeh Asadi,Arsalan Heydarian*

Main category: cs.CV

TL;DR: 本文综述了无人机在AEC+FM领域的应用，提出了一个多模态数据融合的工作流程框架，并指出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 无人机在基础设施检测中的潜力尚未完全发挥，尤其是在实时处理、多模态数据融合和通用性方面存在挑战。

Method: 通过综合150多项研究，提出了一个结合RGB图像、LiDAR和热传感与基于transformer架构的工作流程框架。

Result: 无人机在结构健康监测、灾害响应、城市基础设施管理等方面展现出价值，提出的框架提高了缺陷检测的准确性和可靠性。

Conclusion: 本文总结了无人机在AEC+FM领域的应用现状，并提出了未来研究方向，包括轻量级AI模型、自适应飞行规划、合成数据集和更丰富的模态融合。

Abstract: Unmanned Aerial Vehicles (UAVs) are transforming infrastructure inspections in the Architecture, Engineering, Construction, and Facility Management (AEC+FM) domain. By synthesizing insights from over 150 studies, this review paper highlights UAV-based methodologies for data acquisition, photogrammetric modeling, defect detection, and decision-making support. Key innovations include path optimization, thermal integration, and advanced machine learning (ML) models such as YOLO and Faster R-CNN for anomaly detection. UAVs have demonstrated value in structural health monitoring (SHM), disaster response, urban infrastructure management, energy efficiency evaluations, and cultural heritage preservation. Despite these advancements, challenges in real-time processing, multimodal data fusion, and generalizability remain. A proposed workflow framework, informed by literature and a case study, integrates RGB imagery, LiDAR, and thermal sensing with transformer-based architectures to improve accuracy and reliability in detecting structural defects, thermal anomalies, and geometric inconsistencies. The proposed framework ensures precise and actionable insights by fusing multimodal data and dynamically adapting path planning for complex environments, presented as a comprehensive step-by-step guide to address these challenges effectively. This paper concludes with future research directions emphasizing lightweight AI models, adaptive flight planning, synthetic datasets, and richer modality fusion to streamline modern infrastructure inspections.

</details>


### [26] [MATEX: Multi-scale Attention and Text-guided Explainability of Medical Vision-Language Models](https://arxiv.org/abs/2601.11666)
*Muhammad Imran,Chi Lee,Yugyung Lee*

Main category: cs.CV

TL;DR: MATEX是一种新型医学视觉语言模型解释框架，通过多尺度注意力和文本引导提升可解释性，在MS-CXR数据集上表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在空间不精确、缺乏解剖学基础和注意力粒度有限等关键局限性，以实现更忠实和可解释的模型解释。

Method: MATEX结合多层注意力展开、文本引导空间先验和层一致性分析，生成精确、稳定且临床有意义的梯度归因图。

Result: 在MS-CXR数据集上评估，MATEX在空间精度和与专家标注结果的对齐性上均优于最先进的M2IB方法。

Conclusion: MATEX框架通过结合解剖学信息空间推理，显著提升了医学视觉语言模型的可解释性，增强了放射学AI应用的信任和透明度。

Abstract: We introduce MATEX (Multi-scale Attention and Text-guided Explainability), a novel framework that advances interpretability in medical vision-language models by incorporating anatomically informed spatial reasoning. MATEX synergistically combines multi-layer attention rollout, text-guided spatial priors, and layer consistency analysis to produce precise, stable, and clinically meaningful gradient attribution maps. By addressing key limitations of prior methods, such as spatial imprecision, lack of anatomical grounding, and limited attention granularity, MATEX enables more faithful and interpretable model explanations. Evaluated on the MS-CXR dataset, MATEX outperforms the state-of-the-art M2IB approach in both spatial precision and alignment with expert-annotated findings. These results highlight MATEX's potential to enhance trust and transparency in radiological AI applications.

</details>


### [27] [Generating metamers of human scene understanding](https://arxiv.org/abs/2601.11675)
*Ritik Raina,Abe Leite,Alexandros Graikos,Seoyoung Ahn,Dimitris Samaras,Gregory J. Zelinsky*

Main category: cs.CV

TL;DR: MetamerGen是一个潜在扩散模型，通过结合外围和注视点的信息生成与人类场景理解一致的图像。实验证明其生成图像与人类潜在表示高度对齐，尤其在基于观看者注视区域时。


<details>
  <summary>Details</summary>
Motivation: 人类视觉通过结合来自视觉外围的低分辨率“要点”信息和来自注视点的高分辨率信息来构建对视觉场景的连贯理解。MetamerGen旨在生成与人类潜在场景表示一致的场景。

Method: MetamerGen是一个潜在扩散模型，结合了从外围获得的场景要点信息和从场景注视点获得的信息，生成与人类对场景理解相符的图像。通过引入双流表示方法，将注视区域的详细特征与外围退化的场景上下文特征融合。

Result: 通过行为实验评估了MetamerGen生成图像与人类潜在场景表示的感知对齐性，发现当生成场景基于观看者自己的注视区域时，高级语义对齐最能预测同构性。

Conclusion: MetamerGen是一个强大的工具，用于理解人类对场景的理解。通过概念验证分析，揭示了在多个视觉处理层次上影响人类判断的具体特征。

Abstract: Human vision combines low-resolution "gist" information from the visual periphery with sparse but high-resolution information from fixated locations to construct a coherent understanding of a visual scene. In this paper, we introduce MetamerGen, a tool for generating scenes that are aligned with latent human scene representations. MetamerGen is a latent diffusion model that combines peripherally obtained scene gist information with information obtained from scene-viewing fixations to generate image metamers for what humans understand after viewing a scene. Generating images from both high and low resolution (i.e. "foveated") inputs constitutes a novel image-to-image synthesis problem, which we tackle by introducing a dual-stream representation of the foveated scenes consisting of DINOv2 tokens that fuse detailed features from fixated areas with peripherally degraded features capturing scene context. To evaluate the perceptual alignment of MetamerGen generated images to latent human scene representations, we conducted a same-different behavioral experiment where participants were asked for a "same" or "different" response between the generated and the original image. With that, we identify scene generations that are indeed metamers for the latent scene representations formed by the viewers. MetamerGen is a powerful tool for understanding scene understanding. Our proof-of-concept analyses uncovered specific features at multiple levels of visual processing that contributed to human judgments. While it can generate metamers even conditioned on random fixations, we find that high-level semantic alignment most strongly predicts metamerism when the generated scenes are conditioned on viewers' own fixated regions.

</details>


### [28] [Conformal Point and the Calibrated Conic](https://arxiv.org/abs/2601.11679)
*Richard Hartley*

Main category: cs.CV

TL;DR: 本文介绍了共形点与校准圆锥的关系及其在图像几何计算中的应用。


<details>
  <summary>Details</summary>
Motivation: 研究共形点与校准圆锥的关系，旨在提供更直观的图像几何计算方法。

Method: 通过分析共形点和校准圆锥的几何特性，推导出它们在图像中计算角度和方向的方法。

Result: 研究结果表明，共形点和校准圆锥能有效简化图像几何的计算过程。

Conclusion: 本文探讨了共形点与校准圆锥的关系，并展示了它们在图像几何可视化中的实用性。

Abstract: This gives some information about the conformal point and the calibrating conic, and their relationship one to the other. These concepts are useful for visualizing image geometry, and lead to intuitive ways to compute geometry, such as angles and directions in an image.

</details>


### [29] [Telling Human and Machine Handwriting Apart](https://arxiv.org/abs/2601.11700)
*Luis A. Leiva,Moises Diaz,Nuwan T. Attygalle,Miguel A. Ferrer,Rejean Plamondon*

Main category: cs.CV

TL;DR: 研究利用手写运动作为生物特征，通过浅层循环神经网络高效区分人类与人工输入，AUC达98.3%，适用于安全验证。


<details>
  <summary>Details</summary>
Motivation: 手写运动作为一种独特的行为生物特征，可以用于验证设备或应用程序的真实用户，防止人工生成的输入攻击。

Method: 研究使用了十个公共手写符号数据集，并采用七种不同的合成器（包括Kinematic Theory、生成对抗网络、Transformers和Diffusion模型）进行人工复制。训练了一个浅层循环神经网络，使用非特征化的轨迹数据作为输入。

Result: 分类器在所有合成器和数据集上平均达到98.3%的AUC分数和1.4%的等错误率，在少样本和跨域设置中表现优异。

Conclusion: 该研究通过利用手写运动作为行为生物特征，提出了一种高效的验证方法，能够有效区分人类与人工生成的输入，为计算机系统提供了额外的安全层。

Abstract: Handwriting movements can be leveraged as a unique form of behavioral biometrics, to verify whether a real user is operating a device or application. This task can be framed as a reverse Turing test in which a computer has to detect if an input instance has been generated by a human or artificially. To tackle this task, we study ten public datasets of handwritten symbols (isolated characters, digits, gestures, pointing traces, and signatures) that are artificially reproduced using seven different synthesizers, including, among others, the Kinematic Theory (Sigma h model), generative adversarial networks, Transformers, and Diffusion models. We train a shallow recurrent neural network that achieves excellent performance (98.3 percent Area Under the ROC Curve (AUC) score and 1.4 percent equal error rate on average across all synthesizers and datasets) using nonfeaturized trajectory data as input. In few-shot settings, we show that our classifier achieves such an excellent performance when trained on just 10 percent of the data, as evaluated on the remaining 90% of the data as a test set. We further challenge our classifier in out-of-domain settings, and observe very competitive results as well. Our work has implications for computerized systems that need to verify human presence, and adds an additional layer of security to keep attackers at bay.

</details>


### [30] [SemAlign: Language Guided Semi-supervised Domain Generalization](https://arxiv.org/abs/2601.11724)
*Muditha Fernando,Kajhanan Kailainathan,Krishnakanth Nagaratnam,Isuranga Udaravi Bandara Senavirathne,Ranga Rodrigo*

Main category: cs.CV

TL;DR: 本文提出了一种结合VLM特征对齐、图像增强和正则化的SSDG方法，显著提升性能并在多个测试中达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有SSDG方法过度关注伪标签准确性而忽视了训练期间数据的最大化利用，限制了性能提升潜力。本文旨在通过特征对齐和增强策略解决这一问题。

Method: 提出了一种新颖的SSDG方法，通过将模型中间特征与视觉语言模型（VLM）的语义丰富且泛化的特征空间对齐，促进域不变性。该方法结合了图像级增强和输出级正则化策略。

Result: 在四个基准测试中，该方法相比现有SSDG基线在定性和定量上均达到了SOTA效果。

Conclusion: 论文提出了一种通过中间特征对齐VLM的方法，结合图像级增强和输出级正则化策略，显著提升了SSDG任务的性能，并在多个基准测试中达到了SOTA效果。

Abstract: Semi-supervised Domain Generalization (SSDG) addresses the challenge of generalizing to unseen target domains with limited labeled data. Existing SSDG methods highlight the importance of achieving high pseudo-labeling (PL) accuracy and preventing model overfitting as the main challenges in SSDG. In this light, we show that the SSDG literature's excessive focus on PL accuracy, without consideration for maximum data utilization during training, limits potential performance improvements. We propose a novel approach to the SSDG problem by aligning the intermediate features of our model with the semantically rich and generalized feature space of a Vision Language Model (VLM) in a way that promotes domain-invariance. The above approach is enhanced with effective image-level augmentation and output-level regularization strategies to improve data utilization and minimize overfitting. Extensive experimentation across four benchmarks against existing SSDG baselines suggests that our method achieves SOTA results both qualitatively and quantitatively. The code will be made publicly available.

</details>


### [31] [SpaRRTa: A Synthetic Benchmark for Evaluating Spatial Intelligence in Visual Foundation Models](https://arxiv.org/abs/2601.11729)
*Turhan Can Kargin,Wojciech Jasiński,Adam Pardyl,Bartosz Zieliński,Marcin Przewięźlikowski*

Main category: cs.CV

TL;DR: SpaRRTa基准测试评估视觉基础模型的空间推理能力，揭示其显著差异，为未来空间感知模型发展提供指导。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉基础模型（如DINO和CLIP）在图像语义理解方面表现出色，但其空间推理能力有限，限制了其在具体系统中的应用。现有研究尝试将3D任务（如深度估计）纳入训练，但模型性能在其他空间任务中表现不一致，引发了对模型是否真正具备空间意识或仅过拟合特定3D目标的疑问。

Method: 通过引入Spatial Relation Recognition Task (SpaRRTa)基准测试，评估视觉基础模型识别图像中物体相对位置的能力。该基准生成任意数量的真实感图像，包含多样化场景和完全可控的物体排列，并提供可自由访问的空间注释。

Result: 评估一系列最先进的视觉基础模型后，发现它们在空间推理能力上存在显著差异。分析揭示了支持或阻碍现代视觉基础模型空间意识的机制。

Conclusion: SpaRRTa基准测试揭示了当前视觉基础模型在空间推理能力上的显著差异，并提供了对支持或阻碍空间意识机制的理解，有望指导未来空间感知视觉模型的发展。

Abstract: Visual Foundation Models (VFMs), such as DINO and CLIP, excel in semantic understanding of images but exhibit limited spatial reasoning capabilities, which limits their applicability to embodied systems. As a result, recent work incorporates some 3D tasks (such as depth estimation) into VFM training. However, VFM performance remains inconsistent across other spatial tasks, raising the question of whether these models truly have spatial awareness or overfit to specific 3D objectives. To address this question, we introduce the Spatial Relation Recognition Task (SpaRRTa) benchmark, which evaluates the ability of VFMs to identify relative positions of objects in the image. Unlike traditional 3D objectives that focus on precise metric prediction (e.g., surface normal estimation), SpaRRTa probes a fundamental capability underpinning more advanced forms of human-like spatial understanding. SpaRRTa generates an arbitrary number of photorealistic images with diverse scenes and fully controllable object arrangements, along with freely accessible spatial annotations. Evaluating a range of state-of-the-art VFMs, we reveal significant disparities between their spatial reasoning abilities. Through our analysis, we provide insights into the mechanisms that support or hinder spatial awareness in modern VFMs. We hope that SpaRRTa will serve as a useful tool for guiding the development of future spatially aware visual models.

</details>


### [32] [From Pixels to Purchase: Building and Evaluating a Taxonomy-Decoupled Visual Search Engine for Home Goods E-commerce](https://arxiv.org/abs/2601.11769)
*Cheng Lyu,Jingyue Zhang,Ryan Maunu,Mengwei Li,Vinny DeGenova,Yuanli Pei*

Main category: cs.CV

TL;DR: 提出解耦分类的视觉搜索架构和LLM评估方法，提升电商搜索效果。


<details>
  <summary>Details</summary>
Motivation: 解决现有电商视觉搜索系统因依赖分类和噪声数据导致的鲁棒性和扩展性不足问题。

Method: 采用分类无关的区域提议和统一嵌入进行相似性检索，结合LLM零样本评估框架。

Result: 系统在全球家居平台上显著提升检索质量并增加用户参与度，离线指标与实际效果强相关。

Conclusion: 提出的解耦分类架构和LLM评估框架显著提升了视觉搜索的灵活性和泛化能力，并在实际应用中验证了其有效性。

Abstract: Visual search is critical for e-commerce, especially in style-driven domains where user intent is subjective and open-ended. Existing industrial systems typically couple object detection with taxonomy-based classification and rely on catalog data for evaluation, which is prone to noise that limits robustness and scalability. We propose a taxonomy-decoupled architecture that uses classification-free region proposals and unified embeddings for similarity retrieval, enabling a more flexible and generalizable visual search. To overcome the evaluation bottleneck, we propose an LLM-as-a-Judge framework that assesses nuanced visual similarity and category relevance for query-result pairs in a zero-shot manner, removing dependence on human annotations or noise-prone catalog data. Deployed at scale on a global home goods platform, our system improves retrieval quality and yields a measurable uplift in customer engagement, while our offline evaluation metrics strongly correlate with real-world outcomes.

</details>


### [33] [studentSplat: Your Student Model Learns Single-view 3D Gaussian Splatting](https://arxiv.org/abs/2601.11772)
*Yimu Pan,Hongda Mao,Qingshuang Chen,Yelin Kim*

Main category: cs.CV

TL;DR: studentSplat是一种单视角3D高斯溅射方法，通过教师-学生架构和外推网络解决单视角重建中的尺度模糊和外推问题，实现了高质量的单视角场景重建和深度估计。


<details>
  <summary>Details</summary>
Motivation: 解决单视角3D场景重建中因单视角固有模糊性导致的尺度模糊和外推问题。

Method: 提出了两种技术：1）教师-学生架构，其中多视角教师模型为单视角学生模型提供几何监督；2）外推网络，用于补全缺失的场景上下文。

Result: studentSplat在单视角新视角重建质量上达到最先进水平，并在场景级别上与多视角方法性能相当，同时在自监督单视角深度估计任务中表现出竞争力。

Conclusion: studentSplat在单视角3D场景重建中表现出色，不仅实现了最先进的单视角新视角重建质量，还在场景级别上与多视角方法性能相当，同时展示了作为自监督单视角深度估计方法的潜力。

Abstract: Recent advance in feed-forward 3D Gaussian splatting has enable remarkable multi-view 3D scene reconstruction or single-view 3D object reconstruction but single-view 3D scene reconstruction remain under-explored due to inherited ambiguity in single-view. We present \textbf{studentSplat}, a single-view 3D Gaussian splatting method for scene reconstruction. To overcome the scale ambiguity and extrapolation problems inherent in novel-view supervision from a single input, we introduce two techniques: 1) a teacher-student architecture where a multi-view teacher model provides geometric supervision to the single-view student during training, addressing scale ambiguity and encourage geometric validity; and 2) an extrapolation network that completes missing scene context, enabling high-quality extrapolation. Extensive experiments show studentSplat achieves state-of-the-art single-view novel-view reconstruction quality and comparable performance to multi-view methods at the scene level. Furthermore, studentSplat demonstrates competitive performance as a self-supervised single-view depth estimation method, highlighting its potential for general single-view 3D understanding tasks.

</details>


### [34] [Cross-Domain Object Detection Using Unsupervised Image Translation](https://arxiv.org/abs/2601.11779)
*Vinicius F. Arruda,Rodrigo F. Berriel,Thiago M. Paixão,Claudine Badue,Alberto F. De Souza,Nicu Sebe,Thiago Oliveira-Santos*

Main category: cs.CV

TL;DR: 提出一种通过生成目标域人工数据集的方法，简化实现并提升性能，显著优于现有最优方法。


<details>
  <summary>Details</summary>
Motivation: 解决无监督领域自适应目标检测中现有方法实现复杂、难以解释的问题，并缩小与性能上限的差距。

Method: 使用两种无监督图像翻译模型（CycleGAN和AdaIN-based模型），仅利用源域的标注数据和目标域的非标注数据，生成目标域的人工数据集。

Result: 在自动驾驶的真实场景中，该方法显著优于现有最优方法，进一步缩小了与上限的差距。

Conclusion: 本文提出了一种更简单、更有效且更具可解释性的方法，通过生成目标域的人工数据集来训练目标检测器，显著提升了性能，进一步缩小了与上限的差距。

Abstract: Unsupervised domain adaptation for object detection addresses the adaption of detectors trained in a source domain to work accurately in an unseen target domain. Recently, methods approaching the alignment of the intermediate features proven to be promising, achieving state-of-the-art results. However, these methods are laborious to implement and hard to interpret. Although promising, there is still room for improvements to close the performance gap toward the upper-bound (when training with the target data). In this work, we propose a method to generate an artificial dataset in the target domain to train an object detector. We employed two unsupervised image translators (CycleGAN and an AdaIN-based model) using only annotated data from the source domain and non-annotated data from the target domain. Our key contributions are the proposal of a less complex yet more effective method that also has an improved interpretability. Results on real-world scenarios for autonomous driving show significant improvements, outperforming state-of-the-art methods in most cases, further closing the gap toward the upper-bound.

</details>


### [35] [Digital FAST: An AI-Driven Multimodal Framework for Rapid and Early Stroke Screening](https://arxiv.org/abs/2601.11896)
*Ngoc-Khai Hoang,Thi-Nhu-Mai Nguyen,Huy-Hieu Pham*

Main category: cs.CV

TL;DR: 多模态深度学习框架结合面部、语音和动作数据，实现了高精度（95.83%）的中风筛查，但需更大数据集支持实际应用。


<details>
  <summary>Details</summary>
Motivation: 早期识别中风症状对及时干预和改善患者预后至关重要，尤其在院前环境中。本研究旨在通过多模态数据提升中风筛查的鲁棒性。

Method: 研究提出了一种快速、非侵入式的多模态深度学习框架，结合面部表情、语音信号和上半身运动数据。面部动态使用基于地标的特征和Transformer架构建模，语音信号通过梅尔频谱图和音频频谱Transformer处理，上半身姿势序列则用MLP-Mixer网络分析时空运动模式。多模态特征通过基于注意力的融合机制整合。

Result: 在包含37名受试者的222个视频自采集数据集上，多模态模型性能显著优于单模态基线，达到95.83%准确率和96.00% F1分数，且在敏感性和特异性之间取得了良好平衡。

Conclusion: 该研究提出的多模态深度学习框架在早期中风筛查中表现出色，准确率和F1分数均超过95%，成功检测了所有测试集中的中风病例，展示了多模态学习和迁移学习的潜力。同时，研究强调了需要更大、更具临床代表性的数据集以支持实际应用。

Abstract: Early identification of stroke symptoms is essential for enabling timely intervention and improving patient outcomes, particularly in prehospital settings. This study presents a fast, non-invasive multimodal deep learning framework for automatic binary stroke screening based on data collected during the F.A.S.T. assessment. The proposed approach integrates complementary information from facial expressions, speech signals, and upper-body movements to enhance diagnostic robustness. Facial dynamics are represented using landmark based features and modeled with a Transformer architecture to capture temporal dependencies. Speech signals are converted into mel spectrograms and processed using an Audio Spectrogram Transformer, while upper-body pose sequences are analyzed with an MLP-Mixer network to model spatiotemporal motion patterns. The extracted modality specific representations are combined through an attention-based fusion mechanism to effectively learn cross modal interactions. Experiments conducted on a self-collected dataset of 222 videos from 37 subjects demonstrate that the proposed multimodal model consistently outperforms unimodal baselines, achieving 95.83% accuracy and a 96.00% F1-score. The model attains a strong balance between sensitivity and specificity and successfully detects all stroke cases in the test set. These results highlight the potential of multimodal learning and transfer learning for early stroke screening, while emphasizing the need for larger, clinically representative datasets to support reliable real-world deployment.

</details>


### [36] [RemoteVAR: Autoregressive Visual Modeling for Remote Sensing Change Detection](https://arxiv.org/abs/2601.11898)
*Yilmaz Korkmaz,Vishal M. Patel*

Main category: cs.CV

TL;DR: RemoteVAR是一个基于视觉自回归模型的变化检测框架，通过多分辨率特征融合和交叉注意力机制，显著提升了性能，成为遥感变化检测的有力竞争者。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉自回归模型（VARs）在图像生成方面表现出色，但在像素级判别任务中的应用受限，主要由于可控性弱、密集预测性能不佳和曝光偏差。本文旨在解决这些限制，推动VAR在遥感变化检测中的应用。

Method: RemoteVAR框架通过条件自回归预测在多分辨率融合的双时相特征上使用交叉注意力机制，并采用专为变化图预测设计的自回归训练策略。

Result: 在标准变化检测基准测试中，RemoteVAR相比基于扩散和基于Transformer的基线方法，表现出一致且显著的性能提升。

Conclusion: RemoteVAR作为一种新的基于VAR的变化检测框架，通过多分辨率融合的双时相特征和交叉注意力机制，以及专为变化图预测设计的自回归训练策略，显著提升了性能，为遥感变化检测提供了一个有竞争力的自回归替代方案。

Abstract: Remote sensing change detection aims to localize and characterize scene changes between two time points and is central to applications such as environmental monitoring and disaster assessment. Meanwhile, visual autoregressive models (VARs) have recently shown impressive image generation capability, but their adoption for pixel-level discriminative tasks remains limited due to weak controllability, suboptimal dense prediction performance and exposure bias. We introduce RemoteVAR, a new VAR-based change detection framework that addresses these limitations by conditioning autoregressive prediction on multi-resolution fused bi-temporal features via cross-attention, and by employing an autoregressive training strategy designed specifically for change map prediction. Extensive experiments on standard change detection benchmarks show that RemoteVAR delivers consistent and significant improvements over strong diffusion-based and transformer-based baselines, establishing a competitive autoregressive alternative for remote sensing change detection. Code will be available \href{https://github.com/yilmazkorkmaz1/RemoteVAR}{\underline{here}}.

</details>


### [37] [Towards Airborne Object Detection: A Deep Learning Analysis](https://arxiv.org/abs/2601.11907)
*Prosenjit Chatterjee,ANK Zaman*

Main category: cs.CV

TL;DR: 本研究开发了一种基于EfficientNetB4的双任务模型，用于空中目标分类和威胁等级预测，在多个数据集上表现优异，准确率高达96%和90%。


<details>
  <summary>Details</summary>
Motivation: 随着商用飞机、无人机和UAV等空中平台的快速增加，对实时、自动化的威胁评估系统的需求日益迫切。当前方法主要依赖人工监控，存在可扩展性差和操作效率低的问题。

Method: 本研究提出了一种基于EfficientNetB4的双任务模型，能够同时进行空中目标分类和威胁等级预测。为了解决训练数据稀缺和不平衡的问题，研究团队通过整合和优化多个公共数据源构建了AODTA数据集。

Result: EfficientNetB4模型在AVD数据集和新开发的AODTA数据集上的表现均优于ResNet-50基线模型，分类和威胁预测准确率显著提高。

Conclusion: EfficientNetB4模型在目标分类和威胁等级预测上表现出色，准确率分别达到96%和90%，展示了其在监控、防御和空域管理中的应用潜力。

Abstract: The rapid proliferation of airborne platforms, including commercial aircraft, drones, and UAVs, has intensified the need for real-time, automated threat assessment systems. Current approaches depend heavily on manual monitoring, resulting in limited scalability and operational inefficiencies. This work introduces a dual-task model based on EfficientNetB4 capable of performing airborne object classification and threat-level prediction simultaneously. To address the scarcity of clean, balanced training data, we constructed the AODTA Dataset by aggregating and refining multiple public sources. We benchmarked our approach on both the AVD Dataset and the newly developed AODTA Dataset and further compared performance against a ResNet-50 baseline, which consistently underperformed EfficientNetB4. Our EfficientNetB4 model achieved 96% accuracy in object classification and 90% accuracy in threat-level prediction, underscoring its promise for applications in surveillance, defense, and airspace management. Although the title references detection, this study focuses specifically on classification and threat-level inference using pre-localized airborne object images provided by existing datasets.

</details>


### [38] [Effects of the retina-inspired light intensity encoding on color discrimination performance](https://arxiv.org/abs/2601.11909)
*Io Yamada,Hirotsugu Okuno*

Main category: cs.CV

TL;DR: 研究了不同光强度编码函数对颜色恒常性的影响，发现N-R函数结合双对立颜色平面表示效果最佳。


<details>
  <summary>Details</summary>
Motivation: 颜色是视觉功能的重要信息源，但受光照颜色影响较大，研究颜色恒常性（CC）对使用颜色信息的视觉系统至关重要。

Method: 研究了光强度编码函数（对数函数和N-R函数）对C/S retinex模型颜色恒常性性能的影响，使用HSV颜色空间和基于对立颜色理论的颜色平面表示颜色信息。

Result: N-R函数与双对立颜色平面表示的组合在颜色辨别性能上表现更优。

Conclusion: 结合N-R函数和双对立颜色平面表示提供了更优的颜色辨别性能。

Abstract: Color is an important source of information for visual functions such as object recognition, but it is greatly affected by the color of illumination. The ability to perceive the color of a visual target independent of illumination color is called color constancy (CC), and is an important feature for vision systems that use color information. In this study, we investigated the effects of the light intensity encoding function on the performance of CC of the center/surround (C/S) retinex model, which is a well-known model inspired by CC of the visual nervous system. The functions used to encode light intensity are the logarithmic function used in the original C/S retinex model and the Naka-Rushton (N-R) function, which is a model of retinal photoreceptor response. Color-variable LEDs were used to illuminate visual targets with various lighting colors, and color information computed by each model was used to evaluate the degree to which the color of visual targets illuminated with different lighting colors could be discriminated. Color information was represented using the HSV color space and a color plane based on the classical opponent color theory. The results showed that the combination of the N-R function and the double opponent color plane representation provided superior discrimination performance.

</details>


### [39] [A Training-Free Guess What Vision Language Model from Snippets to Open-Vocabulary Object Detection](https://arxiv.org/abs/2601.11910)
*Guiying Zhu,Bowen Yang,Yin Zhuang,Tong Zhang,Guanqun Wang,Zhihao Che,He Chen,Lianlin Li*

Main category: cs.CV

TL;DR: GW-VLM通过MS-VLS和CCP技术，无需训练即可实现卓越的开放词汇对象检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有预训练基础模型在零样本能力上表现优异，但忽视了为任何对象认知建立通用理解的必要性。

Method: 提出了一种基于MS-VLS和CCP的无训练方法GW-VLM，利用预训练的VLM和LLM进行对象检测。

Result: 在COCO val、Pascal VOC、DIOR和NWPU-10等数据集上的实验表明，GW-VLM性能优于现有方法。

Conclusion: GW-VLM在无需训练的情况下，通过MS-VLS和CCP技术，实现了优于现有方法的OVOD性能。

Abstract: Open-Vocabulary Object Detection (OVOD) aims to develop the capability to detect anything. Although myriads of large-scale pre-training efforts have built versatile foundation models that exhibit impressive zero-shot capabilities to facilitate OVOD, the necessity of creating a universal understanding for any object cognition according to already pretrained foundation models is usually overlooked. Therefore, in this paper, a training-free Guess What Vision Language Model, called GW-VLM, is proposed to form a universal understanding paradigm based on our carefully designed Multi-Scale Visual Language Searching (MS-VLS) coupled with Contextual Concept Prompt (CCP) for OVOD. This approach can engage a pre-trained Vision Language Model (VLM) and a Large Language Model (LLM) in the game of "guess what". Wherein, MS-VLS leverages multi-scale visual-language soft-alignment for VLM to generate snippets from the results of class-agnostic object detection, while CCP can form the concept of flow referring to MS-VLS and then make LLM understand snippets for OVOD. Finally, the extensive experiments are carried out on natural and remote sensing datasets, including COCO val, Pascal VOC, DIOR, and NWPU-10, and the results indicate that our proposed GW-VLM can achieve superior OVOD performance compared to the-state-of-the-art methods without any training step.

</details>


### [40] [Reliable Deep Learning for Small-Scale Classifications: Experiments on Real-World Image Datasets from Bangladesh](https://arxiv.org/abs/2601.11911)
*Muhammad Ibrahim,Alfe Suny,MD Sakib Ul Islam,Md. Imran Hossain*

Main category: cs.CV

TL;DR: 紧凑型CNN在孟加拉国多个真实图像数据集上表现优异，适合小类别分类任务。


<details>
  <summary>Details</summary>
Motivation: 尽管CNN在图像识别任务中表现优异，但复杂架构可能在小数据集上过拟合。因此，研究旨在探索简化CNN在小数据集上的表现。

Method: 本研究评估了一种紧凑型CNN，在孟加拉国的五个公开真实世界图像数据集上进行了测试，包括城市侵占、车辆检测、道路损坏和农作物分类。

Result: 定量指标和显著性分析表明，该模型能有效捕捉判别性特征，并在多样化场景中稳健泛化。

Conclusion: 该研究表明，简化的CNN架构在小类别图像分类任务中表现出色，具有高分类准确率、高效收敛和低计算开销，适合多样化场景。

Abstract: Convolutional neural networks (CNNs) have achieved state-of-the-art performance in image recognition tasks but often involve complex architectures that may overfit on small datasets. In this study, we evaluate a compact CNN across five publicly available, real-world image datasets from Bangladesh, including urban encroachment, vehicle detection, road damage, and agricultural crops. The network demonstrates high classification accuracy, efficient convergence, and low computational overhead. Quantitative metrics and saliency analyses indicate that the model effectively captures discriminative features and generalizes robustly across diverse scenarios, highlighting the suitability of streamlined CNN architectures for small-class image classification tasks.

</details>


### [41] [From Spurious to Causal: Low-rank Orthogonal Subspace Intervention for Generalizable Face Forgery Detection](https://arxiv.org/abs/2601.11915)
*Chi Wang,Xinjue Hu,Boyu Wang,Ziwen He,Zhangjie Fu*

Main category: cs.CV

TL;DR: 提出一种通过低秩投影移除虚假相关性特征的方法，显著提升人脸伪造检测的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 虚假相关性因素导致人脸伪造检测的泛化能力受限，传统方法难以逐一识别和解决这些因素。

Method: 提出了一种表示空间的干预范式，将虚假相关性特征统一建模为低秩子空间，并通过正交低秩投影分解和移除这些特征。

Result: 该方法仅需0.43M可训练参数，便在多个基准测试中表现出卓越的鲁棒性和泛化能力。

Conclusion: 通过正交低秩投影分解和移除虚假相关性特征，该方法有效提升了人脸伪造检测的泛化能力，并在多个基准测试中达到了最先进的性能。

Abstract: The generalization problem remains a critical challenge in face forgery detection. Some researches have discovered that ``a backdoor path" in the representations from forgery-irrelevant information to labels induces biased learning, thereby hindering the generalization. In this paper, these forgery-irrelevant information are collectively termed spurious correlations factors. Previous methods predominantly focused on identifying concrete, specific spurious correlation and designing corresponding solutions to address them. However, spurious correlations arise from unobservable confounding factors, making it impractical to identify and address each one individually. To address this, we propose an intervention paradigm for representation space. Instead of tracking and blocking various instance-level spurious correlation one by one, we uniformly model them as a low-rank subspace and intervene in them. Specifically, we decompose spurious correlation features into a low-rank subspace via orthogonal low-rank projection, subsequently removing this subspace from the original representation and training its orthogonal complement to capture forgery-related features. This low-rank projection removal effectively eliminates spurious correlation factors, ensuring that classification decision is based on authentic forgery cues. With only 0.43M trainable parameters, our method achieves state-of-the-art performance across several benchmarks, demonstrating excellent robustness and generalization.

</details>


### [42] [Effects of Gabor Filters on Classification Performance of CNNs Trained on a Limited Number of Conditions](https://arxiv.org/abs/2601.11918)
*Akito Morita,Hirotsugu Okuno*

Main category: cs.CV

TL;DR: 研究提出使用Gabor滤波器作为CNN预处理器，提高边缘设备上CNN的准确性和泛化能力，同时减小模型规模。


<details>
  <summary>Details</summary>
Motivation: 边缘设备上的CNN需要小型架构且能高效训练，视觉神经系统（VNS）是一个满足这些要求的例子。

Method: 使用Gabor滤波器作为CNN的预处理器，评估在不同条件下训练的CNN的准确性。

Result: Gabor滤波器预处理提高了CNN的泛化性能，并减小了模型规模。

Conclusion: 预处理使用Gabor滤波器可以提高CNN的泛化性能，并有助于减小CNN的规模。

Abstract: In this study, we propose a technique to improve the accuracy and reduce the size of convolutional neural networks (CNNs) running on edge devices for real-world robot vision applications. CNNs running on edge devices must have a small architecture, and CNNs for robot vision applications involving on-site object recognition must be able to be trained efficiently to identify specific visual targets from data obtained under a limited variation of conditions. The visual nervous system (VNS) is a good example that meets the above requirements because it learns from few visual experiences. Therefore, we used a Gabor filter, a model of the feature extractor of the VNS, as a preprocessor for CNNs to investigate the accuracy of the CNNs trained with small amounts of data. To evaluate how well CNNs trained on image data acquired under a limited variation of conditions generalize to data acquired under other conditions, we created an image dataset consisting of images acquired from different camera positions, and investigated the accuracy of the CNNs that trained using images acquired at a certain distance. The results were compared after training on multiple CNN architectures with and without Gabor filters as preprocessing. The results showed that preprocessing with Gabor filters improves the generalization performance of CNNs and contributes to reducing the size of CNNs.

</details>


### [43] [SupScene: Learning Overlap-Aware Global Descriptor for Unconstrained SfM](https://arxiv.org/abs/2601.11930)
*Xulei Shi,Maoyu Wang,Yuning Peng,Guanbo Wang,Xin Wang,Qi Chen,Pengjie Tao*

Main category: cs.CV

TL;DR: SupScene通过子图训练和DiVLAD聚合器，优化了SfM中的图像检索性能，在GL3D数据集上达到SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在图像检索中过于关注语义相似性而忽略了几何匹配性，SupScene旨在解决这一问题。

Method: 采用子图训练策略和软监督对比损失，结合DINO启发的VLAD聚合器（DiVLAD）及可学习门控机制。

Result: 在GL3D数据集上表现优异，显著优于NetVLAD，且额外可训练参数极少。

Conclusion: SupScene通过创新的子图训练策略和DiVLAD聚合器，显著提升了图像检索在SfM中的性能，并在GL3D数据集上达到了最先进水平。

Abstract: Image retrieval is a critical step for alleviating the quadratic complexity of image matching in unconstrained Structure-from-Motion (SfM). However, in this context, image retrieval typically focuses more on the image pairs of geometric matchability than on those of semantic similarity, a nuance that most existing deep learning-based methods guided by batched binaries (overlapping vs. non-overlapping pairs) fail to capture. In this paper, we introduce SupScene, a novel solution that learns global descriptors tailored for finding overlapping image pairs of similar geometric nature for SfM. First, to better underline co-visible regions, we employ a subgraph-based training strategy that moves beyond equally important isolated pairs, leveraging ground-truth geometric overlapping relationships with various weights to provide fine-grained supervision via a soft supervised contrastive loss. Second, we introduce DiVLAD, a DINO-inspired VLAD aggregator that leverages the inherent multi-head attention maps from the last block of ViT. And then, a learnable gating mechanism is designed to adaptively utilize these semantically salient cues with visual features, enabling a more discriminative global descriptor. Extensive experiments on the GL3D dataset demonstrate that our method achieves state-of-the-art performance, significantly outperforming NetVLAD while introducing a negligible number of additional trainable parameters. Furthermore, we show that the proposed training strategy brings consistent gains across different aggregation techniques. Code and models are available at https://anonymous.4open.science/r/SupScene-5B73.

</details>


### [44] [Language-Guided and Motion-Aware Gait Representation for Generalizable Recognition](https://arxiv.org/abs/2601.11931)
*Zhengxian Wu,Chuanrui Zhang,Shenao Jiang,Hangrui Xu,Zirui Liao,Luyuan Zhang,Huaqiu Li,Peng Jiao,Haoqian Wang*

Main category: cs.CV

TL;DR: LMGait框架利用语言线索和运动感知，解决了步态识别中的静态噪声过拟合和动态运动捕捉不足问题。


<details>
  <summary>Details</summary>
Motivation: 现有步态识别方法依赖复杂架构，容易在静态噪声（如衣物）上过拟合，且未能有效捕捉动态运动区域。

Method: 设计了步态相关的语言线索来捕捉步态序列中的关键运动特征。

Result: 提出了LMGait框架，通过语言引导和运动感知改进步态识别。

Conclusion: LMGait框架通过语言引导和运动感知，有效解决了现有步态识别方法在静态噪声上的过拟合问题，并提升了动态运动区域的捕捉能力。

Abstract: Gait recognition is emerging as a promising technology and an innovative field within computer vision. However, existing methods typically rely on complex architectures to directly extract features from images and apply pooling operations to obtain sequence-level representations. Such designs often lead to overfitting on static noise (e.g., clothing), while failing to effectively capture dynamic motion regions.To address the above challenges, we present a Language guided and Motion-aware gait recognition framework, named LMGait.In particular, we utilize designed gait-related language cues to capture key motion features in gait sequences.

</details>


### [45] [Deep learning-based neurodevelopmental assessment in preterm infants](https://arxiv.org/abs/2601.11944)
*Lexin Ren,Jiamiao Lu,Weichuan Zhang,Benqing Wu,Tuo Wang,Yi Liao,Jiapan Guo,Changming Sun,Liang Guo*

Main category: cs.CV

TL;DR: 提出一种新型神经网络HDAN，通过注意力机制提升早产儿脑部MRI中白质和灰质的分割精度，证实早产儿神经发育延迟的影像学差异。


<details>
  <summary>Details</summary>
Motivation: 早产儿脑部MRI中白质和灰质信号强度相近（等强度表现），导致传统分割方法难以准确区分。

Method: 采用3D空间-通道注意力机制和注意力引导的密集上采样策略，增强低对比度体积数据中的特征区分能力。

Result: 提出的方法在分割性能上优于现有基线，并证实早产儿的白质和灰质体积显著低于足月儿。

Conclusion: 提出的Hierarchical Dense Attention Network在早产儿脑部MRI扫描中显著提升了白质和灰质的分割精度，为早产儿神经发育延迟提供了新的影像学证据。

Abstract: Preterm infants (born between 28 and 37 weeks of gestation) face elevated risks of neurodevelopmental delays, making early identification crucial for timely intervention. While deep learning-based volumetric segmentation of brain MRI scans offers a promising avenue for assessing neonatal neurodevelopment, achieving accurate segmentation of white matter (WM) and gray matter (GM) in preterm infants remains challenging due to their comparable signal intensities (isointense appearance) on MRI during early brain development. To address this, we propose a novel segmentation neural network, named Hierarchical Dense Attention Network. Our architecture incorporates a 3D spatial-channel attention mechanism combined with an attention-guided dense upsampling strategy to enhance feature discrimination in low-contrast volumetric data. Quantitative experiments demonstrate that our method achieves superior segmentation performance compared to state-of-the-art baselines, effectively tackling the challenge of isointense tissue differentiation. Furthermore, application of our algorithm confirms that WM and GM volumes in preterm infants are significantly lower than those in term infants, providing additional imaging evidence of the neurodevelopmental delays associated with preterm birth. The code is available at: https://github.com/ICL-SUST/HDAN.

</details>


### [46] [Decoder Gradient Shields: A Family of Provable and High-Fidelity Methods Against Gradient-Based Box-Free Watermark Removal](https://arxiv.org/abs/2601.11952)
*Haonan An,Guang Hua,Wei Du,Hangcheng Cao,Yihang Tao,Guowen Xu,Susanto Rahardja,Yuguang Fang*

Main category: cs.CV

TL;DR: 本文提出Decoder Gradient Shields (DGSs)防御机制，有效防止解码器水印被攻击，实验显示100%防御成功率。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注编码器的鲁棒性，而解码器被忽视，导致水印易受攻击。本文针对解码器攻击提出防御机制。

Method: 提出Decoder Gradient Shields (DGSs)防御机制，包括输出层(DGS-O)、输入层(DGS-I)和中间层(DGS-L)的梯度保护，其中DGS-O有闭式解，所有DGS均有可证明的性能。

Result: 在去雨和图像生成任务中，DGSs在最新无盒水印技术下实现了100%的防御成功率。

Conclusion: 提出的Decoder Gradient Shields (DGSs)在各种应用场景中均表现出色，实验结果表明在所有设置下防御成功率达到100%。

Abstract: Box-free model watermarking has gained significant attention in deep neural network (DNN) intellectual property protection due to its model-agnostic nature and its ability to flexibly manage high-entropy image outputs from generative models. Typically operating in a black-box manner, it employs an encoder-decoder framework for watermark embedding and extraction. While existing research has focused primarily on the encoders for the robustness to resist various attacks, the decoders have been largely overlooked, leading to attacks against the watermark. In this paper, we identify one such attack against the decoder, where query responses are utilized to obtain backpropagated gradients to train a watermark remover. To address this issue, we propose Decoder Gradient Shields (DGSs), a family of defense mechanisms, including DGS at the output (DGS-O), at the input (DGS-I), and in the layers (DGS-L) of the decoder, with a closed-form solution for DGS-O and provable performance for all DGS. Leveraging the joint design of reorienting and rescaling of the gradients from watermark channel gradient leaking queries, the proposed DGSs effectively prevent the watermark remover from achieving training convergence to the desired low-loss value, while preserving image quality of the decoder output. We demonstrate the effectiveness of our proposed DGSs in diverse application scenarios. Our experimental results on deraining and image generation tasks with the state-of-the-art box-free watermarking show that our DGSs achieve a defense success rate of 100% under all settings.

</details>


### [47] [Real-Time Multi-Modal Embedded Vision Framework for Object Detection Facial Emotion Recognition and Biometric Identification on Low-Power Edge Platforms](https://arxiv.org/abs/2601.11970)
*S. M. Khalid Bin Zahid,Md. Rakibul Hasan Nishat,Abdul Hasib,Md. Rakibul Hasan,Md. Ashiqussalehin,Md. Sahadat Hossen Sajib,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

TL;DR: 该论文提出了一种实时多模态视觉框架，通过自适应调度机制在边缘设备上高效集成目标检测、人脸识别和情绪检测，显著降低计算负载并保持高性能。


<details>
  <summary>Details</summary>
Motivation: 智能监控系统通常独立处理感知任务（如目标检测、人脸识别和情绪分析），但缺乏统一的、基于上下文触发的动态计算资源分配调度器，限制了其在低功耗边缘设备上的整体理解与效率。

Method: 提出了一个实时多模态视觉框架，集成了目标检测、特定人脸识别和情绪检测，部署在Raspberry Pi 5边缘平台上。核心是一个自适应调度机制，通过选择性激活模块（如YOLOv8n、自定义FaceNet嵌入系统和DeepFace的CNN）减少65%的计算负载。

Result: 实验结果显示，目标检测模块的平均精度（AP）为0.861，人脸识别准确率达88%，情绪检测表现出强区分能力（特定情绪的AUC高达0.97），系统运行速度为5.6帧/秒。

Conclusion: 该研究展示了上下文感知调度是实现复杂多模态AI在低成本边缘硬件上运行的关键，使智能感知更加普及且保护隐私。

Abstract: Intelligent surveillance systems often handle perceptual tasks such as object detection, facial recognition, and emotion analysis independently, but they lack a unified, adaptive runtime scheduler that dynamically allocates computational resources based on contextual triggers. This limits their holistic understanding and efficiency on low-power edge devices. To address this, we present a real-time multi-modal vision framework that integrates object detection, owner-specific face recognition, and emotion detection into a unified pipeline deployed on a Raspberry Pi 5 edge platform. The core of our system is an adaptive scheduling mechanism that reduces computational load by 65\% compared to continuous processing by selectively activating modules such as, YOLOv8n for object detection, a custom FaceNet-based embedding system for facial recognition, and DeepFace's CNN for emotion classification. Experimental results demonstrate the system's efficacy, with the object detection module achieving an Average Precision (AP) of 0.861, facial recognition attaining 88\% accuracy, and emotion detection showing strong discriminatory power (AUC up to 0.97 for specific emotions), while operating at 5.6 frames per second. Our work demonstrates that context-aware scheduling is the key to unlocking complex multi-modal AI on cost-effective edge hardware, making intelligent perception more accessible and privacy-preserving.

</details>


### [48] [AVIR: Adaptive Visual In-Document Retrieval for Efficient Multi-Page Document Question Answering](https://arxiv.org/abs/2601.11976)
*Zongmin Li,Yachuan Li,Lei Kang,Dimosthenis Karatzas,Wenkang Ma*

Main category: cs.CV

TL;DR: AVIR框架通过自适应页面选择和冻结模型，高效解决多页文档视觉问答问题，显著降低计算成本并提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决多页文档视觉问答中长文档对计算资源和注意力机制效率的挑战。

Method: 采用轻量级检索模型对每页进行问题相关性评分，通过聚类和Top-K筛选自适应选择相关内容，仅将选定页面输入冻结的大型视觉语言模型生成答案。

Result: 平均页数减少70%，在MP-DocVQA数据集上达到84.58%的ANLS，优于先前方法且计算成本更低。

Conclusion: AVIR框架显著减少了多页文档视觉问答所需的平均页数，同时保持了高准确率，验证了其在多个基准测试中的有效性。

Abstract: Multi-page Document Visual Question Answering (MP-DocVQA) remains challenging because long documents not only strain computational resources but also reduce the effectiveness of the attention mechanism in large vision-language models (LVLMs). We tackle these issues with an Adaptive Visual In-document Retrieval (AVIR) framework. A lightweight retrieval model first scores each page for question relevance. Pages are then clustered according to the score distribution to adaptively select relevant content. The clustered pages are screened again by Top-K to keep the context compact. However, for short documents, clustering reliability decreases, so we use a relevance probability threshold to select pages. The selected pages alone are fed to a frozen LVLM for answer generation, eliminating the need for model fine-tuning. The proposed AVIR framework reduces the average page count required for question answering by 70%, while achieving an ANLS of 84.58% on the MP-DocVQA dataset-surpassing previous methods with significantly lower computational cost. The effectiveness of the proposed AVIR is also verified on the SlideVQA and DUDE benchmarks. The code is available at https://github.com/Li-yachuan/AVIR.

</details>


### [49] [Nip Rumors in the Bud: Retrieval-Guided Topic-Level Adaptation for Test-Time Fake News Video Detection](https://arxiv.org/abs/2601.11981)
*Jian Lang,Rongpei Hong,Ting Zhong,Yong Wang,Fan Zhou*

Main category: cs.CV

TL;DR: RADAR是首个支持测试时适应的假新闻视频检测框架，通过检索引导和稳定参考实现对新主题的快速适应。


<details>
  <summary>Details</summary>
Motivation: 现有方法假设训练和测试阶段的新闻主题分布一致，无法检测与新兴事件和未见主题相关的假新闻视频，RADAR旨在填补这一空白。

Method: 提出了基于熵选择的检索机制和稳定锚引导的对齐模块，结合目标域感知的自训练范式，实现了对不稳定实例的稳健适应。

Result: 大量实验证明，RADAR在测试时假新闻视频检测中表现优异，能够快速适应未见主题。

Conclusion: RADAR框架通过创新的检索引导适应范式，成功实现了对未见新闻视频的实时适应，显著提升了假新闻视频检测的性能。

Abstract: Fake News Video Detection (FNVD) is critical for social stability. Existing methods typically assume consistent news topic distribution between training and test phases, failing to detect fake news videos tied to emerging events and unseen topics. To bridge this gap, we introduce RADAR, the first framework that enables test-time adaptation to unseen news videos. RADAR pioneers a new retrieval-guided adaptation paradigm that leverages stable (source-close) videos from the target domain to guide robust adaptation of semantically related but unstable instances. Specifically, we propose an Entropy Selection-Based Retrieval mechanism that provides videos with stable (low-entropy), relevant references for adaptation. We also introduce a Stable Anchor-Guided Alignment module that explicitly aligns unstable instances' representations to the source domain via distribution-level matching with their stable references, mitigating severe domain discrepancies. Finally, our novel Target-Domain Aware Self-Training paradigm can generate informative pseudo-labels augmented by stable references, capturing varying and imbalanced category distributions in the target domain and enabling RADAR to adapt to the fast-changing label distributions. Extensive experiments demonstrate that RADAR achieves superior performance for test-time FNVD, enabling strong on-the-fly adaptation to unseen fake news video topics.

</details>


### [50] [An AI-IoT Based Smart Wheelchair with Gesture-Controlled Mobility, Deep Learning-Based Obstacle Detection, Multi-Sensor Health Monitoring, and Emergency Alert System](https://arxiv.org/abs/2601.11983)
*Md. Asiful Islam,Abdul Hasib,Tousif Mahmud Emon,Khandaker Tabin Hasan,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

TL;DR: AI-IoT智能轮椅整合手势控制、超声波避障、YOLOv8物体检测和健康监测，成本低、性能优，提升用户安全与自主性。


<details>
  <summary>Details</summary>
Motivation: 针对传统轮椅功能单一且现有智能轮椅成本高、功能局限的问题，研究旨在开发一种经济实惠、多功能的智能轮椅系统，以满足残障人士和老年人的个性化需求。

Method: 系统结合了手套式手势控制（95.5%成功率）、超声波避障（94%准确率）和YOLOv8物体检测（91.5%精确率、90.2%召回率、90.8% F1分数），并集成实时健康监测（心率、血氧、心电图、体温），数据上传至ThingSpeak平台并触发邮件警报。

Result: 手势控制成功率达95.5%，超声波避障准确率94%，YOLOv8物体检测性能优异（精确率91.5%、召回率90.2%、F1分数90.8%），健康监测数据实时可靠。

Conclusion: 该论文提出了一种基于AI-IoT的智能轮椅系统，通过多模态技术（手势控制、超声波避障、YOLOv8物体检测）和实时健康监测，显著提升了用户自主性和安全性，为辅助技术领域提供了实用、可扩展且经济高效的解决方案。

Abstract: The growing number of differently-abled and elderly individuals demands affordable, intelligent wheelchairs that combine safe navigation with health monitoring. Traditional wheelchairs lack dynamic features, and many smart alternatives remain costly, single-modality, and limited in health integration. Motivated by the pressing demand for advanced, personalized, and affordable assistive technologies, we propose a comprehensive AI-IoT based smart wheelchair system that incorporates glove-based gesture control for hands-free navigation, real-time object detection using YOLOv8 with auditory feedback for obstacle avoidance, and ultrasonic for immediate collision avoidance. Vital signs (heart rate, SpO$_2$, ECG, temperature) are continuously monitored, uploaded to ThingSpeak, and trigger email alerts for critical conditions. Built on a modular and low-cost architecture, the gesture control achieved a 95.5\% success rate, ultrasonic obstacle detection reached 94\% accuracy, and YOLOv8-based object detection delivered 91.5\% Precision, 90.2\% Recall, and a 90.8\% F1-score. This integrated, multi-modal approach offers a practical, scalable, and affordable solution, significantly enhancing user autonomy, safety, and independence by bridging the gap between innovative research and real-world deployment.

</details>


### [51] [Structural Graph Neural Networks with Anatomical Priors for Explainable Chest X-ray Diagnosis](https://arxiv.org/abs/2601.11987)
*Khaled Berkani*

Main category: cs.CV

TL;DR: 提出结合解剖学先验的结构图推理框架，通过自定义传播机制提升视觉诊断的可解释性和结构推理能力。


<details>
  <summary>Details</summary>
Motivation: 旨在通过结合解剖学先验，构建一个可解释的视觉诊断框架，提升结构推理和可解释性。

Method: 框架将卷积特征图重新解释为补丁级图，节点编码外观和空间坐标，边反映局部结构邻接。不同于传统图神经网络，引入自定义结构传播机制，显式建模空间关系。

Result: 在胸部X光案例研究中，展示了结构先验如何引导关系推理并提高可解释性，同时模型支持节点级和图级推理。

Conclusion: 该论文提出了一个结合解剖学先验的结构图推理框架，用于可解释的视觉诊断。通过将卷积特征图重新解释为补丁级图，并引入自定义的结构传播机制，模型能够同时支持节点级病变感知预测和图级诊断推理，提供内在可解释性。

Abstract: We present a structural graph reasoning framework that incorporates explicit anatomical priors for explainable vision-based diagnosis. Convolutional feature maps are reinterpreted as patch-level graphs, where nodes encode both appearance and spatial coordinates, and edges reflect local structural adjacency. Unlike conventional graph neural networks that rely on generic message passing, we introduce a custom structural propagation mechanism that explicitly models relative spatial relations as part of the reasoning process. This design enables the graph to act as an inductive bias for structured inference rather than a passive relational representation. The proposed model jointly supports node-level lesion-aware predictions and graph-level diagnostic reasoning, yielding intrinsic explainability through learned node importance scores without relying on post-hoc visualization techniques. We demonstrate the approach through a chest X-ray case study, illustrating how structural priors guide relational reasoning and improve interpretability. While evaluated in a medical imaging context, the framework is domain-agnostic and aligns with the broader vision of graph-based reasoning across artificial intelligence systems. This work contributes to the growing body of research exploring graphs as computational substrates for structure-aware and explainable learning.

</details>


### [52] [DAOS: A Multimodal In-cabin Behavior Monitoring with Driver Action-Object Synergy Dataset](https://arxiv.org/abs/2601.11990)
*Yiming Li,Chen Cai,Tianyi Liu,Dan Lin,Wenqian Wang,Wenfei Liang,Bingbing Li,Kim-Hui Yap*

Main category: cs.CV

TL;DR: DAOS数据集填补了驾驶员动作识别中物体关联的空白，AOR-Net通过多级推理和动态知识选择提升了识别性能。


<details>
  <summary>Details</summary>
Motivation: 现有驾驶员监控数据集缺乏准确的物体位置标注或未将物体与动作关联，导致动作识别不可靠。

Method: 提出了Action-Object-Relation Network (AOR-Net)，结合多级推理和动作链提示机制，动态选择关键知识。

Result: AOR-Net在多个数据集上优于其他最先进方法。

Conclusion: 提出的AOR-Net模型通过多级推理和动作链提示机制，显著提升了驾驶员动作识别的准确性，尤其在对象丰富或稀缺的条件下表现优异。

Abstract: In driver activity monitoring, movements are mostly limited to the upper body, which makes many actions look similar. To tell these actions apart, human often rely on the objects the driver is using, such as holding a phone compared with gripping the steering wheel. However, most existing driver-monitoring datasets lack accurate object-location annotations or do not link objects to their associated actions, leaving a critical gap for reliable action recognition. To address this, we introduce the Driver Action with Object Synergy (DAOS) dataset, comprising 9,787 video clips annotated with 36 fine-grained driver actions and 15 object classes, totaling more than 2.5 million corresponding object instances. DAOS offers multi-modal, multi-view data (RGB, IR, and depth) from front, face, left, and right perspectives. Although DAOS captures a wide range of cabin objects, only a few are directly relevant to each action for prediction, so focusing on task-specific human-object relations is essential. To tackle this challenge, we propose the Action-Object-Relation Network (AOR-Net). AOR-Net comprehends complex driver actions through multi-level reasoning and a chain-of-action prompting mechanism that models the logical relationships among actions, objects, and their relations. Additionally, the Mixture of Thoughts module is introduced to dynamically select essential knowledge at each stage, enhancing robustness in object-rich and object-scarce conditions. Extensive experiments demonstrate that our model outperforms other state-of-the-art methods on various datasets.

</details>


### [53] [SMc2f: Robust Scenario Mining for Robotic Autonomy from Coarse to Fine](https://arxiv.org/abs/2601.12010)
*Yifei Chen,Ross Greer*

Main category: cs.CV

TL;DR: SMc2f是一种新的自动驾驶场景挖掘方法，结合视觉语言模型和对比学习，提升了检索效果。


<details>
  <summary>Details</summary>
Motivation: 现有的场景挖掘方法依赖于轨迹标签，忽略了自然语言与原始RGB图像的直接联系，且受限于上游3D目标检测和跟踪的质量，导致空间和时间定位不准确。

Method: 提出了一种从粗到细的管道，包括使用视觉语言模型进行粗略的图像-文本过滤，构建成功挖掘案例的数据库，并引入文本-轨迹对比学习进行细粒度匹配。

Result: 在公共数据集上的实验表明，SMc2f在检索质量和效率上均有显著提升。

Conclusion: SMc2f通过结合视觉语言模型和对比学习，显著提升了自动驾驶机器人场景挖掘的质量和效率。

Abstract: The safety validation of autonomous robotic vehicles hinges on systematically testing their planning and control stacks against rare, safety-critical scenarios. Mining these long-tail events from massive real-world driving logs is therefore a critical step in the robotic development lifecycle. The goal of the Scenario Mining task is to retrieve useful information to enable targeted re-simulation, regression testing, and failure analysis of the robot's decision-making algorithms. RefAV, introduced by the Argoverse team, is an end-to-end framework that uses large language models (LLMs) to spatially and temporally localize scenarios described in natural language. However, this process performs retrieval on trajectory labels, ignoring the direct connection between natural language and raw RGB images, which runs counter to the intuition of video retrieval; it also depends on the quality of upstream 3D object detection and tracking. Further, inaccuracies in trajectory data lead to inaccuracies in downstream spatial and temporal localization. To address these issues, we propose Robust Scenario Mining for Robotic Autonomy from Coarse to Fine (SMc2f), a coarse-to-fine pipeline that employs vision-language models (VLMs) for coarse image-text filtering, builds a database of successful mining cases on top of RefAV and automatically retrieves exemplars to few-shot condition the LLM for more robust retrieval, and introduces text-trajectory contrastive learning to pull matched pairs together and push mismatched pairs apart in a shared embedding space, yielding a fine-grained matcher that refines the LLM's candidate trajectories. Experiments on public datasets demonstrate substantial gains in both retrieval quality and efficiency.

</details>


### [54] [SAR-Based Marine Oil Spill Detection Using the DeepSegFusion Architecture](https://arxiv.org/abs/2601.12015)
*Pavan Kumar Yata,Pediredla Pradeep,Goli Himanish,Swathi M*

Main category: cs.CV

TL;DR: 提出DeepSegFusion模型，通过混合深度学习方法显著提升油污分割精度，减少误报，适用于实时监测。


<details>
  <summary>Details</summary>
Motivation: 传统基于阈值的方法因风浪和船舶尾迹等类似现象导致高误报率，性能下降。

Method: 提出了混合深度学习模型DeepSegFusion，结合SegNet和DeepLabV3+，并集成基于注意力的特征融合机制。

Result: 在SAR油污数据集上，模型准确率达94.85%，IoU为0.5685，ROC-AUC得分为0.9330，误检率比基线模型减少64.4%。

Conclusion: DeepSegFusion模型在各种海洋条件下表现稳定，适用于近实时油污监测。

Abstract: Detection of oil spills from satellite images is essential for both environmental surveillance and maritime safety. Traditional threshold-based methods frequently encounter performance degradation due to very high false alarm rates caused by look-alike phenomena such as wind slicks and ship wakes. Here, a hybrid deep learning model, DeepSegFusion, is presented for oil spill segmentation in Synthetic Aperture Radar (SAR) images. The model uses SegNet and DeepLabV3+ integrated with an attention-based feature fusion mechanism to achieve better boundary precision as well as improved contextual understanding. Results obtained on SAR oil spill datasets, including ALOS PALSAR imagery, confirm that the proposed DeepSegFusion model achieves an accuracy of 94.85%, an Intersection over Union (IoU) of 0.5685, and a ROC-AUC score of 0.9330. The proposed method delivers more than three times fewer false detections compared to individual baseline models and traditional non-segmentation methods, achieving a reduction of 64.4%. These results indicate that DeepSegFusion is a stable model under various marine conditions and can therefore be used in near real-time oil spill monitoring scenarios.

</details>


### [55] [DIAMOND-SSS: Diffusion-Augmented Multi-View Optimization for Data-efficient SubSurface Scattering](https://arxiv.org/abs/2601.12020)
*Guillermo Figueroa-Araneda,Iris Diana Jimenez,Florian Hofherr,Manny Ko,Hector Andrade-Loarca,Daniel Cremers*

Main category: cs.CV

TL;DR: DIAMOND-SSS 是一个高效框架，通过扩散模型和几何先验，在极稀疏监督下实现高质量半透明材质重建，显著减少数据需求。


<details>
  <summary>Details</summary>
Motivation: 解决神经渲染中半透明材质建模的挑战，尤其是在数据稀疏情况下的高保真重建需求。

Method: 通过微调扩散模型进行新视角合成和重光照，结合光照无关的几何先验（多视角轮廓一致性损失和深度一致性损失）来稳定重建。

Result: DIAMOND-SSS 在稀疏监督下（甚至仅需十张图像）实现了最先进的渲染质量，减少了高达90%的实际捕捉需求。

Conclusion: DIAMOND-SSS 在稀疏监督下实现了高质量的半透明材质重建，显著减少了实际捕捉需求。

Abstract: Subsurface scattering (SSS) gives translucent materials -- such as wax, jade, marble, and skin -- their characteristic soft shadows, color bleeding, and diffuse glow. Modeling these effects in neural rendering remains challenging due to complex light transport and the need for densely captured multi-view, multi-light datasets (often more than 100 views and 112 OLATs).
  We present DIAMOND-SSS, a data-efficient framework for high-fidelity translucent reconstruction from extremely sparse supervision -- even as few as ten images. We fine-tune diffusion models for novel-view synthesis and relighting, conditioned on estimated geometry and trained on less than 7 percent of the dataset, producing photorealistic augmentations that can replace up to 95 percent of missing captures. To stabilize reconstruction under sparse or synthetic supervision, we introduce illumination-independent geometric priors: a multi-view silhouette consistency loss and a multi-view depth consistency loss.
  Across all sparsity regimes, DIAMOND-SSS achieves state-of-the-art quality in relightable Gaussian rendering, reducing real capture requirements by up to 90 percent compared to SSS-3DGS.

</details>


### [56] [\textit{FocaLogic}: Logic-Based Interpretation of Visual Model Decisions](https://arxiv.org/abs/2601.12049)
*Chenchen Zhao,Muxi Chen,Qiang Xu*

Main category: cs.CV

TL;DR: FocaLogic 是一种模型无关框架，通过逻辑表达式和定量指标解释视觉模型的决策过程，解决了现有方法依赖白盒或缺乏定量严谨性的问题。


<details>
  <summary>Details</summary>
Motivation: 现代视觉模型的可解释性至关重要，尤其是在高风险应用中。然而，现有的可解释性方法通常依赖于白盒模型访问或缺乏足够的定量严谨性。

Method: FocaLogic 是一种新颖的模型无关框架，通过基于逻辑的表示来解释和量化视觉模型的决策过程。它识别出对模型预测有决定性影响的最小可解释视觉区域子集（称为视觉焦点），并将其转化为精确且紧凑的逻辑表达式。

Result: 实证分析表明，FocaLogic 能够揭示训练诱导的集中、通过泛化提高焦点准确性以及在偏见和对抗攻击下的异常焦点等关键见解。

Conclusion: FocaLogic 提供了一种系统性、可扩展且量化的解决方案，用于解释视觉模型，揭示了训练诱导的集中、通过泛化提高焦点准确性以及在偏见和对抗攻击下的异常焦点等关键见解。

Abstract: Interpretability of modern visual models is crucial, particularly in high-stakes applications. However, existing interpretability methods typically suffer from either reliance on white-box model access or insufficient quantitative rigor. To address these limitations, we introduce FocaLogic, a novel model-agnostic framework designed to interpret and quantify visual model decision-making through logic-based representations. FocaLogic identifies minimal interpretable subsets of visual regions-termed visual focuses-that decisively influence model predictions. It translates these visual focuses into precise and compact logical expressions, enabling transparent and structured interpretations. Additionally, we propose a suite of quantitative metrics, including focus precision, recall, and divergence, to objectively evaluate model behavior across diverse scenarios. Empirical analyses demonstrate FocaLogic's capability to uncover critical insights such as training-induced concentration, increasing focus accuracy through generalization, and anomalous focuses under biases and adversarial attacks. Overall, FocaLogic provides a systematic, scalable, and quantitative solution for interpreting visual models.

</details>


### [57] [A Unified Masked Jigsaw Puzzle Framework for Vision and Language Models](https://arxiv.org/abs/2601.12051)
*Weixin Ye,Wei Wang,Yahui Liu,Yue Song,Bin Ren,Wei Bi,Rita Cucchiara,Nicu Sebe*

Main category: cs.CV

TL;DR: MJP通过打乱token顺序和掩盖位置信息，提升Transformer在联邦学习中对梯度攻击的防御能力，同时增强其在CV和NLP任务中的表现。


<details>
  <summary>Details</summary>
Motivation: Transformer在联邦学习中面临梯度攻击的挑战，且位置嵌入的梯度可能泄露输入数据。MJP旨在通过破坏局部空间信息来增强模型的安全性和性能。

Method: 提出了一种Masked Jigsaw Puzzle (MJP)框架，通过随机打乱token顺序并使用可学习的未知位置嵌入来掩盖打乱token的位置信息，从而破坏局部空间信息的编码。

Result: 实验结果表明，MJP在图像分类（如ImageNet-1K）和文本情感分析（如Yelp和Amazon）任务中均能提升模型性能并增强对抗梯度攻击的能力。

Conclusion: MJP框架不仅提高了Transformer模型在对抗梯度攻击时的鲁棒性，还提升了其在视觉和文本任务中的性能表现，证明了其在不同Transformer模型中的通用性。

Abstract: In federated learning, Transformer, as a popular architecture, faces critical challenges in defending against gradient attacks and improving model performance in both Computer Vision (CV) and Natural Language Processing (NLP) tasks. It has been revealed that the gradient of Position Embeddings (PEs) in Transformer contains sufficient information, which can be used to reconstruct the input data. To mitigate this issue, we introduce a Masked Jigsaw Puzzle (MJP) framework. MJP starts with random token shuffling to break the token order, and then a learnable \textit{unknown (unk)} position embedding is used to mask out the PEs of the shuffled tokens. In this manner, the local spatial information which is encoded in the position embeddings is disrupted, and the models are forced to learn feature representations that are less reliant on the local spatial information. Notably, with the careful use of MJP, we can not only improve models' robustness against gradient attacks, but also boost their performance in both vision and text application scenarios, such as classification for images (\textit{e.g.,} ImageNet-1K) and sentiment analysis for text (\textit{e.g.,} Yelp and Amazon). Experimental results suggest that MJP is a unified framework for different Transformer-based models in both vision and language tasks. Code is publicly available via https://github.com/ywxsuperstar/transformerattack

</details>


### [58] [Task-Driven Prompt Learning: A Joint Framework for Multi-modal Cloud Removal and Segmentation](https://arxiv.org/abs/2601.12052)
*Zaiyan Zhang,Jie Li,Shaowei Shi,Qiangqiang Yuan*

Main category: cs.CV

TL;DR: TDP-CR是一种任务驱动的多模态框架，通过PGF机制和两阶段训练策略，有效结合云去除与土地覆盖分割，显著提升数据质量和语义实用性。


<details>
  <summary>Details</summary>
Motivation: 光学遥感影像在云遮挡下实用性受限，现有云去除方法在低层次保真度上优化过度，导致视觉修复与语义实用性不匹配。

Method: 提出了一种Prompt-Guided Fusion（PGF）机制，利用可学习的退化提示编码云层厚度和空间不确定性，并结合全局通道上下文与局部提示条件空间偏置，自适应地整合SAR信息。此外，采用参数高效的两阶段训练策略，解耦重建和语义表示学习。

Result: 在LuojiaSET-OSFCR数据集上，TDP-CR在PSNR上超越现有基线0.18 dB，仅使用15%的参数，并在mIoU上持续优于多任务竞争对手1.4%。

Conclusion: TDP-CR框架通过任务驱动的多模态方法，有效结合云去除和土地覆盖分割，显著提升了分析就绪数据（ARD）的质量和语义实用性。

Abstract: Optical remote sensing imagery is indispensable for Earth observation, yet persistent cloud occlusion limits its downstream utility. Most cloud removal (CR) methods are optimized for low-level fidelity and can over-smooth textures and boundaries that are critical for analysis-ready data (ARD), leading to a mismatch between visually plausible restoration and semantic utility. To bridge this gap, we propose TDP-CR, a task-driven multimodal framework that jointly performs cloud removal and land-cover segmentation. Central to our approach is a Prompt-Guided Fusion (PGF) mechanism, which utilizes a learnable degradation prompt to encode cloud thickness and spatial uncertainty. By combining global channel context with local prompt-conditioned spatial bias, PGF adaptively integrates Synthetic Aperture Radar (SAR) information only where optical data is corrupted. We further introduce a parameter-efficient two-phase training strategy that decouples reconstruction and semantic representation learning. Experiments on the LuojiaSET-OSFCR dataset demonstrate the superiority of our framework: TDP-CR surpasses heavy state-of-the-art baselines by 0.18 dB in PSNR while using only 15\% of the parameters, and achieves a 1.4\% improvement in mIoU consistently against multi-task competitors, effectively delivering analysis-ready data.

</details>


### [59] [Automating Parameter Selection in Deep Image Prior for Fluorescence Microscopy Image Denoising via Similarity-Based Parameter Transfer](https://arxiv.org/abs/2601.12055)
*Lina Meyer,Felix Wissel,Tobias Knopp,Susanne Pfefferle,Ralf Fliegert,Maximilian Sandmann,Liana Uebler,Franziska Möckl,Björn-Philipp Diercks,David Lohr,René Werner*

Main category: cs.CV

TL;DR: AUTO-DIP通过自动参数转移优化DIP性能，显著提升荧光显微镜图像去噪效果，尤其适用于高噪声输入。


<details>
  <summary>Details</summary>
Motivation: 解决无监督深度图像先验（DIP）在参数优化上的时间消耗问题，提出相似图像共享最优参数的假设，以扩展DIP在荧光显微镜领域的应用。

Method: 利用校准集（n=110）和验证集（n=55）进行网络架构搜索，优化U-net架构和停止点，并实现参数自动转移的AUTO-DIP流程。

Result: AUTO-DIP在多个开源测试数据集上表现优于基线DIP和变分去噪方法，尤其在处理高噪声输入时效果显著。

Conclusion: AUTO-DIP通过自动参数转移，显著提升了DIP在荧光显微镜图像去噪中的性能，尤其在处理高噪声输入时表现优越。

Abstract: Unsupervised deep image prior (DIP) addresses shortcomings of training data requirements and limited generalization associated with supervised deep learning. The performance of DIP depends on the network architecture and the stopping point of its iterative process. Optimizing these parameters for a new image requires time, restricting DIP application in domains where many images need to be processed. Focusing on fluorescence microscopy data, we hypothesize that similar images share comparable optimal parameter configurations for DIP-based denoising, potentially enabling optimization-free DIP for fluorescence microscopy. We generated a calibration (n=110) and validation set (n=55) of semantically different images from an open-source dataset for a network architecture search targeted towards ideal U-net architectures and stopping points. The calibration set represented our transfer basis. The validation set enabled the assessment of which image similarity criterion yields the best results. We then implemented AUTO-DIP, a pipeline for automatic parameter transfer, and compared it to the originally published DIP configuration (baseline) and a state-of-the-art image-specific variational denoising approach. We show that a parameter transfer from the calibration dataset to a test image based on only image metadata similarity (e.g., microscope type, imaged specimen) leads to similar and better performance than a transfer based on quantitative image similarity measures. AUTO-DIP outperforms the baseline DIP (DIP with original DIP parameters) as well as the variational denoising approaches for several open-source test datasets of varying complexity, particularly for very noisy inputs. Applications to locally acquired fluorescence microscopy images further proved superiority of AUTO-DIP.

</details>


### [60] [Learning Language-Driven Sequence-Level Modal-Invariant Representations for Video-Based Visible-Infrared Person Re-Identification](https://arxiv.org/abs/2601.12062)
*Xiaomei Yang,Xizhan Gao,Antai Liu,Kang Wei,Fa Zhu,Guang Feng,Xiaofeng Qu,Sijie Niu*

Main category: cs.CV

TL;DR: LSMRL通过语言驱动和模块化设计，解决了视频-红外行人重识别中的模态不变表示学习问题，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在空间-时间建模效率、跨模态交互充分性和显式模态级损失指导方面存在不足，需改进以提升模态不变表示学习效果。

Method: 提出了语言驱动的序列级模态不变表示学习（LSMRL）方法，包括空间-时间特征学习（STFL）模块、语义扩散（SD）模块和跨模态交互（CMI）模块。STFL模块基于CLIP进行高效建模，SD模块通过扩散语言提示建立模态一致性，CMI模块利用双向自注意力消除模态差异。

Result: 在大规模VVI-ReID数据集上的实验表明，LSMRL方法优于现有技术。

Conclusion: LSMRL方法通过结合空间-时间特征学习、语义扩散和跨模态交互模块，以及引入模态级损失，显著提升了视频-红外行人重识别的性能，优于现有方法。

Abstract: The core of video-based visible-infrared person re-identification (VVI-ReID) lies in learning sequence-level modal-invariant representations across different modalities. Recent research tends to use modality-shared language prompts generated by CLIP to guide the learning of modal-invariant representations. Despite achieving optimal performance, such methods still face limitations in efficient spatial-temporal modeling, sufficient cross-modal interaction, and explicit modality-level loss guidance. To address these issues, we propose the language-driven sequence-level modal-invariant representation learning (LSMRL) method, which includes spatial-temporal feature learning (STFL) module, semantic diffusion (SD) module and cross-modal interaction (CMI) module. To enable parameter- and computation-efficient spatial-temporal modeling, the STFL module is built upon CLIP with minimal modifications. To achieve sufficient cross-modal interaction and enhance the learning of modal-invariant features, the SD module is proposed to diffuse modality-shared language prompts into visible and infrared features to establish preliminary modal consistency. The CMI module is further developed to leverage bidirectional cross-modal self-attention to eliminate residual modality gaps and refine modal-invariant representations. To explicitly enhance the learning of modal-invariant representations, two modality-level losses are introduced to improve the features' discriminative ability and their generalization to unseen categories. Extensive experiments on large-scale VVI-ReID datasets demonstrate the superiority of LSMRL over AOTA methods.

</details>


### [61] [Learning Stochastic Bridges for Video Object Removal via Video-to-Video Translation](https://arxiv.org/abs/2601.12066)
*Zijie Lou,Xiangwei Feng,Jiaxin Wang,Xiaochao Qu,Luoqi Liu,Ting Liu*

Main category: cs.CV

TL;DR: 本文提出了一种基于随机桥模型的视频对象移除方法，通过视频到视频转换和自适应掩码调制，显著提升了移除效果和生成内容的一致性。


<details>
  <summary>Details</summary>
Motivation: 现有视频对象移除方法主要依赖扩散模型，从无信息的高斯噪声开始生成，忽略了输入视频中的丰富结构和上下文先验，导致移除不彻底或生成内容不符合场景物理逻辑。

Method: 本文方法将视频对象移除重新定义为视频到视频的转换任务，通过随机桥模型建立从源视频到目标视频的直接随机路径，并引入自适应掩码调制策略动态调节输入嵌入。

Result: 实验表明，该方法在视觉质量和时间一致性上显著优于现有方法。

Conclusion: 本文提出了一种基于随机桥模型的视频对象移除方法，通过视频到视频的转换任务，有效利用输入视频作为结构先验，实现了精确的对象移除和逻辑一致的填充。自适应掩码调制策略进一步平衡了背景保真度和生成灵活性，显著提升了视觉质量和时间一致性。

Abstract: Existing video object removal methods predominantly rely on diffusion models following a noise-to-data paradigm, where generation starts from uninformative Gaussian noise. This approach discards the rich structural and contextual priors present in the original input video. Consequently, such methods often lack sufficient guidance, leading to incomplete object erasure or the synthesis of implausible content that conflicts with the scene's physical logic. In this paper, we reformulate video object removal as a video-to-video translation task via a stochastic bridge model. Unlike noise-initialized methods, our framework establishes a direct stochastic path from the source video (with objects) to the target video (objects removed). This bridge formulation effectively leverages the input video as a strong structural prior, guiding the model to perform precise removal while ensuring that the filled regions are logically consistent with the surrounding environment. To address the trade-off where strong bridge priors hinder the removal of large objects, we propose a novel adaptive mask modulation strategy. This mechanism dynamically modulates input embeddings based on mask characteristics, balancing background fidelity with generative flexibility. Extensive experiments demonstrate that our approach significantly outperforms existing methods in both visual quality and temporal consistency.

</details>


### [62] [ARMARecon: An ARMA Convolutional Filter based Graph Neural Network for Neurodegenerative Dementias Classification](https://arxiv.org/abs/2601.12067)
*VSS Tejaswi Abburi,Ananya Singhal,Saurabh J. Shigwan,Nitin Kumar*

Main category: cs.CV

TL;DR: ARMARecon是一个结合ARMA图滤波和重构目标的图学习框架，用于早期检测AD和FTD，在ADNI和NIFD数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 神经退行性疾病如阿尔茨海默病（AD）和额颞叶痴呆（FTD）的早期检测对减缓疾病进展至关重要，图依赖的传播模式使图神经网络成为捕捉这些模式的理想工具。

Method: ARMARecon结合了自回归移动平均（ARMA）图滤波和重构驱动目标，利用20-bin分数各向异性（FA）直方图特征建模局部和全局连接性，同时缓解过平滑问题。

Result: ARMARecon在多站点dMRI数据集ADNI和NIFD上实现了优于现有方法的性能。

Conclusion: ARMARecon在ADNI和NIFD多站点dMRI数据集上表现优于现有方法，证明了其在神经退行性疾病早期检测中的有效性。

Abstract: Early detection of neurodegenerative diseases such as Alzheimer's Disease (AD) and Frontotemporal Dementia (FTD) is essential for reducing the risk of progression to severe disease stages. As AD and FTD propagate along white-matter regions in a global, graph-dependent manner, graph-based neural networks are well suited to capture these patterns. Hence, we introduce ARMARecon, a unified graph learning framework that integrates Autoregressive Moving Average (ARMA) graph filtering with a reconstruction-driven objective to enhance feature representation and improve classification accuracy. ARMARecon effectively models both local and global connectivity by leveraging 20-bin Fractional Anisotropy (FA) histogram features extracted from white-matter regions, while mitigating over-smoothing. Overall, ARMARecon achieves superior performance compared to state-of-the-art methods on the multi-site dMRI datasets ADNI and NIFD.

</details>


### [63] [CroBIM-V: Memory-Quality Controlled Remote Sensing Referring Video Object Segmentation](https://arxiv.org/abs/2601.12076)
*H. Jiang,Y. Sun,Z. Dong,T. Liu,Y. Gu*

Main category: cs.CV

TL;DR: 构建了首个大规模RS-RVOS基准数据集RS-RVOS Bench，并提出MQC-SAM框架，通过运动一致性模块和质量控制机制提升分割性能。


<details>
  <summary>Details</summary>
Motivation: 解决远程感知视频参考对象分割中目标显著性弱和视觉信息截断严重的问题，以及现有模型中初始内存构建偏差和内存积累中的噪声问题。

Method: 提出了MQC-SAM框架，包括时序运动一致性模块用于初始内存校准和解耦的基于注意力的内存集成机制，动态评估质量以选择性更新高置信度语义特征。

Result: 在RS-RVOS Bench上的大量实验表明MQC-SAM表现出色。

Conclusion: MQC-SAM在RS-RVOS Bench上实现了最先进的性能，通过数据和方法论的双重贡献推动了RS-RVOS研究的发展。

Abstract: Remote sensing video referring object segmentation (RS-RVOS) is challenged by weak target saliency and severe visual information truncation in dynamic scenes, making it extremely difficult to maintain discriminative target representations during segmentation. Moreover, progress in this field is hindered by the absence of large-scale dedicated benchmarks, while existing models are often affected by biased initial memory construction that impairs accurate instance localization in complex scenarios, as well as indiscriminate memory accumulation that encodes noise from occlusions or misclassifications, leading to persistent error propagation. This paper advances RS-RVOS research through dual contributions in data and methodology. First, we construct RS-RVOS Bench, the first large-scale benchmark comprising 111 video sequences, about 25,000 frames, and 213,000 temporal referring annotations. Unlike common RVOS benchmarks where many expressions are written with access to the full video context, our dataset adopts a strict causality-aware annotation strategy in which linguistic references are generated solely from the target state in the initial frame. Second, we propose a memory-quality-aware online referring segmentation framework, termed Memory Quality Control with Segment Anything Model (MQC-SAM). MQC-SAM introduces a temporal motion consistency module for initial memory calibration, leveraging short-term motion trajectory priors to correct structural deviations and establish accurate memory anchoring. Furthermore, it incorporates a decoupled attention-based memory integration mechanism with dynamic quality assessment, selectively updating high-confidence semantic features while filtering unreliable information, thereby effectively preventing error accumulation and propagation. Extensive experiments on RS-RVOS Bench demonstrate that MQC-SAM achieves state-of-the-art performance.

</details>


### [64] [EmoLat: Text-driven Image Sentiment Transfer via Emotion Latent Space](https://arxiv.org/abs/2601.12079)
*Jing Zhang,Bingjie Fan,Jixiang Zhu,Zhe Wang*

Main category: cs.CV

TL;DR: EmoLat 是一种新型情感潜在空间，通过文本语义与视觉情感的跨模态关联，实现精细化的图像情感编辑，并在实验中表现优异。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有方法在文本驱动图像情感转换中缺乏细粒度控制的问题，EmoLat 旨在建模文本语义与视觉情感特征的跨模态关联。

Method: 提出 EmoLat 情感潜在空间，结合情感语义图和对抗正则化方法，构建跨模态情感转换框架，并通过多目标损失函数优化网络。

Result: 在 EmoSpace Set 数据集上的实验表明，EmoLat 在定量指标和定性转换保真度上均显著优于现有方法。

Conclusion: EmoLat 通过构建情感语义图和多模态对齐，显著提升了图像情感编辑的精细度和可控性，为文本驱动的图像情感转换设立了新范式。

Abstract: We propose EmoLat, a novel emotion latent space that enables fine-grained, text-driven image sentiment transfer by modeling cross-modal correlations between textual semantics and visual emotion features. Within EmoLat, an emotion semantic graph is constructed to capture the relational structure among emotions, objects, and visual attributes. To enhance the discriminability and transferability of emotion representations, we employ adversarial regularization, aligning the latent emotion distributions across modalities. Building upon EmoLat, a cross-modal sentiment transfer framework is proposed to manipulate image sentiment via joint embedding of text and EmoLat features. The network is optimized using a multi-objective loss incorporating semantic consistency, emotion alignment, and adversarial regularization. To support effective modeling, we construct EmoSpace Set, a large-scale benchmark dataset comprising images with dense annotations on emotions, object semantics, and visual attributes. Extensive experiments on EmoSpace Set demonstrate that our approach significantly outperforms existing state-of-the-art methods in both quantitative metrics and qualitative transfer fidelity, establishing a new paradigm for controllable image sentiment editing guided by textual input. The EmoSpace Set and all the code are available at http://github.com/JingVIPLab/EmoLat.

</details>


### [65] [Toward Real-World High-Precision Image Matting and Segmentation](https://arxiv.org/abs/2601.12080)
*Haipeng Zhou,Zhaohu Xing,Hongqiu Wang,Jun Ma,Ping Li,Lei Zhu*

Main category: cs.CV

TL;DR: FCLM模型通过深度感知蒸馏和领域适应策略，提升了高精度场景解析的性能，支持交互预测。


<details>
  <summary>Details</summary>
Motivation: 现有方法多关注单一前景对象且依赖合成数据，导致泛化能力不足。FCLM旨在解决这些问题。

Method: FCLM模型采用深度感知蒸馏策略和领域不变学习策略，结合面向对象的解码器，支持视觉和语言提示的交互预测。

Result: 实验表明，FCLM在定量和定性上均优于现有SOTA方法。

Conclusion: 提出的FCLM模型通过深度感知蒸馏和领域不变学习策略，显著提升了高精度场景解析任务的性能，尤其在处理合成数据和真实数据间的领域差异方面表现突出。

Abstract: High-precision scene parsing tasks, including image matting and dichotomous segmentation, aim to accurately predict masks with extremely fine details (such as hair). Most existing methods focus on salient, single foreground objects. While interactive methods allow for target adjustment, their class-agnostic design restricts generalization across different categories. Furthermore, the scarcity of high-quality annotation has led to a reliance on inharmonious synthetic data, resulting in poor generalization to real-world scenarios. To this end, we propose a Foreground Consistent Learning model, dubbed as FCLM, to address the aforementioned issues. Specifically, we first introduce a Depth-Aware Distillation strategy where we transfer the depth-related knowledge for better foreground representation. Considering the data dilemma, we term the processing of synthetic data as domain adaptation problem where we propose a domain-invariant learning strategy to focus on foreground learning. To support interactive prediction, we contribute an Object-Oriented Decoder that can receive both visual and language prompts to predict the referring target. Experimental results show that our method quantitatively and qualitatively outperforms SOTA methods.

</details>


### [66] [From Prompts to Pavement: LMMs-based Agentic Behavior-Tree Generation Framework for Autonomous Vehicles](https://arxiv.org/abs/2601.12358)
*Omar Y. Goba,Ahmed Y. Gado,Catherine M. Elias,Ahmed Hussein*

Main category: cs.CV

TL;DR: 利用LLM和LVM的动态行为树框架，成功实现自动驾驶车辆在复杂环境中的自适应导航。


<details>
  <summary>Details</summary>
Motivation: 传统行为树（BTs）静态且需人工调优，难以适应SAE Level 5自动驾驶的复杂需求，因此需要一种能够动态生成和调整BT的解决方案。

Method: 通过三个专门设计的智能体（Descriptor、Planner、Generator）结合链式符号提示、上下文学习和XML生成技术，动态构建和调整行为树。

Result: 在CARLA+Nav2模拟环境中，该系统在基线BT失败时成功导航绕过意外障碍（如街道堵塞），无需人工干预。

Conclusion: 本文提出的基于LLM和LVM的智能体框架成功实现了动态行为树的生成与适应，为自动驾驶车辆在不可预测环境中的安全导航提供了概念验证。

Abstract: Autonomous vehicles (AVs) require adaptive behavior planners to navigate unpredictable, real-world environments safely. Traditional behavior trees (BTs) offer structured decision logic but are inherently static and demand labor-intensive manual tuning, limiting their applicability at SAE Level 5 autonomy. This paper presents an agentic framework that leverages large language models (LLMs) and multi-modal vision models (LVMs) to generate and adapt BTs on the fly. A specialized Descriptor agent applies chain-of-symbols prompting to assess scene criticality, a Planner agent constructs high-level sub-goals via in-context learning, and a Generator agent synthesizes executable BT sub-trees in XML format. Integrated into a CARLA+Nav2 simulation, our system triggers only upon baseline BT failure, demonstrating successful navigation around unexpected obstacles (e.g., street blockage) with no human intervention. Compared to a static BT baseline, this approach is a proof-of-concept that extends to diverse driving scenarios.

</details>


### [67] [Conditional Random Fields for Interactive Refinement of Histopathological Predictions](https://arxiv.org/abs/2601.12082)
*Tiffanie Godelaine,Maxime Zanella,Karim El Khoury,Saïd Mahmoudi,Benoît Macq,Christophe De Vleeschouwer*

Main category: cs.CV

TL;DR: HistoCRF通过CRF优化VLM的零样本预测，无需训练即可显著提升组织病理学图像分类准确率，尤其结合专家注释和人机交互效果更佳。


<details>
  <summary>Details</summary>
Motivation: 辅助病理学家分析组织病理学图像对癌症检测和分期具有重要临床价值，但现有VLM的零样本预测存在不足。

Method: 提出HistoCRF框架，利用CRF优化VLM的零样本预测，通过定义新的成对势函数促进标签多样性和利用专家注释。

Result: 在五个数据集上的实验显示，无注释时平均准确率提升16.0%，100个专家注释时提升27.5%，人机交互进一步提升至32.6%。

Conclusion: HistoCRF框架通过无需额外训练的CRF方法显著提升了组织病理学图像分析的准确性，尤其是在结合专家注释和人机交互的情况下。

Abstract: Assisting pathologists in the analysis of histopathological images has high clinical value, as it supports cancer detection and staging. In this context, histology foundation models have recently emerged. Among them, Vision-Language Models (VLMs) provide strong yet imperfect zero-shot predictions. We propose to refine these predictions by adapting Conditional Random Fields (CRFs) to histopathological applications, requiring no additional model training. We present HistoCRF, a CRF-based framework, with a novel definition of the pairwise potential that promotes label diversity and leverages expert annotations. We consider three experiments: without annotations, with expert annotations, and with iterative human-in-the-loop annotations that progressively correct misclassified patches. Experiments on five patch-level classification datasets covering different organs and diseases demonstrate average accuracy gains of 16.0% without annotations and 27.5% with only 100 annotations, compared to zero-shot predictions. Moreover, integrating a human in the loop reaches a further gain of 32.6% with the same number of annotations. The code will be made available on https://github.com/tgodelaine/HistoCRF.

</details>


### [68] [CD-TWINSAFE: A ROS-enabled Digital Twin for Scene Understanding and Safety Emerging V2I Technology](https://arxiv.org/abs/2601.12373)
*Amro Khaled,Farah Khaled,Omar Riad,Catherine M. Elias*

Main category: cs.CV

TL;DR: CD-TWINSAFE是一种V2I数字孪生架构，通过并行运行的车载堆栈和数字孪生堆栈实现自动驾驶车辆的实时安全监控，测试验证了其有效性和实时性。


<details>
  <summary>Details</summary>
Motivation: 为了解决自动驾驶车辆在复杂环境中的实时安全监控问题，提出了一种基于V2I的数字孪生架构，以提升场景理解和安全警报的实时性。

Method: 该架构由两个并行运行的堆栈组成：车载驾驶堆栈（包括立体摄像头进行场景理解）和数字孪生堆栈（使用Unreal Engine 5复制场景并返回安全警报）。车载堆栈包含定位和感知模块，通过传感器获取车辆位置和方向，并通过立体摄像头处理图像进行对象检测和特征提取。数据通过ROS2消息和4G调制解调器进行V2I通信。

Result: 测试表明，该架构在多种驾驶场景下均能有效运行，并实现实时响应。

Conclusion: CD-TWINSAFE架构通过实时数字孪生技术成功实现了车辆与基础设施之间的高效通信，验证了其在多种驾驶场景下的有效性和实时响应能力。

Abstract: In this paper, the CD-TWINSAFE is introduced, a V2I-based digital twin for Autonomous Vehicles. The proposed architecture is composed of two stacks running simultaneously, an on-board driving stack that includes a stereo camera for scene understanding, and a digital twin stack that runs an Unreal Engine 5 replica of the scene viewed by the camera as well as returning safety alerts to the cockpit. The on-board stack is implemented on the vehicle side including 2 main autonomous modules; localization and perception. The position and orientation of the ego vehicle are obtained using on-board sensors. Furthermore, the perception module is responsible for processing 20-fps images from stereo camera and understands the scene through two complementary pipelines. The pipeline are working on object detection and feature extraction including object velocity, yaw and the safety metrics time-to-collision and time-headway. The collected data form the driving stack are sent to the infrastructure side through the ROS-enabled architecture in the form of custom ROS2 messages and sent over UDP links that ride a 4G modem for V2I communication. The environment is monitored via the digital twin through the shared messages which update the information of the spawned ego vehicle and detected objects based on the real-time localization and perception data. Several tests with different driving scenarios to confirm the validity and real-time response of the proposed architecture.

</details>


### [69] [Detecting 3D Line Segments for 6DoF Pose Estimation with Limited Data](https://arxiv.org/abs/2601.12090)
*Matej Mok,Lukáš Gajdošech,Michal Mesároš,Martin Madaras,Viktor Kocur*

Main category: cs.CV

TL;DR: 提出一种针对工业箱子的6DoF姿态估计新方法，利用3D线段检测和几何处理，无需CAD模型，显著提高精度。


<details>
  <summary>Details</summary>
Motivation: 解决传统深度学习方法在工业自动化中因数据稀缺和对象实例多样而受限的问题。

Method: 通过扩展2D线段检测网络LeTR以处理结构化点云数据，首先检测与箱子顶部边缘对应的中间3D线段，然后利用简单几何程序稳健确定箱子的6DoF姿态。

Result: 结合合成训练数据显著提高了真实扫描的姿势估计准确性，并在姿态精度上优于现有方法。

Conclusion: 该方法在无需实例特定CAD模型的情况下，显著优于当前最先进的6DoF姿态估计方法，姿态精度达到3厘米平移误差和8.2°旋转误差。

Abstract: The task of 6DoF object pose estimation is one of the fundamental problems of 3D vision with many practical applications such as industrial automation. Traditional deep learning approaches for this task often require extensive training data or CAD models, limiting their application in real-world industrial settings where data is scarce and object instances vary. We propose a novel method for 6DoF pose estimation focused specifically on bins used in industrial settings. We exploit the cuboid geometry of bins by first detecting intermediate 3D line segments corresponding to their top edges. Our approach extends the 2D line segment detection network LeTR to operate on structured point cloud data. The detected 3D line segments are then processed using a simple geometric procedure to robustly determine the bin's 6DoF pose. To evaluate our method, we extend an existing dataset with a newly collected and annotated dataset, which we make publicly available. We show that incorporating synthetic training data significantly improves pose estimation accuracy on real scans. Moreover, we show that our method significantly outperforms current state-of-the-art 6DoF pose estimation methods in terms of the pose accuracy (3 cm translation error, 8.2$^\circ$ rotation error) while not requiring instance-specific CAD models during inference.

</details>


### [70] [DC-VLAQ: Query-Residual Aggregation for Robust Visual Place Recognition](https://arxiv.org/abs/2601.12729)
*Hanyu Zhu,Zhihao Zhan,Yuhang Ming,Liang Li,Dibo Hou,Javier Civera,Wanzeng Kong*

Main category: cs.CV

TL;DR: DC-VLAQ 是一个结合互补 VFMs 和稳健全局聚合的框架，通过残差引导融合和 VLAQ 聚合方案，在 VPR 任务中实现了最先进性能。


<details>
  <summary>Details</summary>
Motivation: 视觉地点识别（VPR）中，学习一个在视角变化、光照变化和严重领域转移下仍具有区分性的全局表示是一个核心挑战。现有方法多依赖单一模型，忽略了不同视觉基础模型（VFMs）提供的互补信息。

Method: 提出了 DC-VLAQ 框架，包括轻量级残差引导互补融合和 Vector of Local Aggregated Queries (VLAQ) 全局聚合方案。

Result: 在 Pitts30k、Tokyo24/7、MSLS、Nordland、SPED 和 AmsterTime 等标准 VPR 基准测试中，DC-VLAQ 始终优于强基线。

Conclusion: DC-VLAQ 在标准 VPR 基准测试中表现优异，特别是在具有挑战性的领域转移和长期外观变化情况下，实现了最先进的性能。

Abstract: One of the central challenges in visual place recognition (VPR) is learning a robust global representation that remains discriminative under large viewpoint changes, illumination variations, and severe domain shifts. While visual foundation models (VFMs) provide strong local features, most existing methods rely on a single model, overlooking the complementary cues offered by different VFMs. However, exploiting such complementary information inevitably alters token distributions, which challenges the stability of existing query-based global aggregation schemes. To address these challenges, we propose DC-VLAQ, a representation-centric framework that integrates the fusion of complementary VFMs and robust global aggregation. Specifically, we first introduce a lightweight residual-guided complementary fusion that anchors representations in the DINOv2 feature space while injecting complementary semantics from CLIP through a learned residual correction. In addition, we propose the Vector of Local Aggregated Queries (VLAQ), a query--residual global aggregation scheme that encodes local tokens by their residual responses to learnable queries, resulting in improved stability and the preservation of fine-grained discriminative cues. Extensive experiments on standard VPR benchmarks, including Pitts30k, Tokyo24/7, MSLS, Nordland, SPED, and AmsterTime, demonstrate that DC-VLAQ consistently outperforms strong baselines and achieves state-of-the-art performance, particularly under challenging domain shifts and long-term appearance changes.

</details>


### [71] [Energy-Aware Ensemble Learning for Coffee Leaf Disease Classification](https://arxiv.org/abs/2601.12109)
*Larissa Ferreira Rodrigues Moreira,Rodrigo Moreira,Leonardo Gabriel Ferreira Rodrigues*

Main category: cs.CV

TL;DR: 通过知识蒸馏和集成学习，轻量级模型在咖啡叶病害诊断中实现高效低耗，适用于物联网应用。


<details>
  <summary>Details</summary>
Motivation: 咖啡叶病害的及时准确诊断对产量至关重要，但现有AI视觉模型因设备限制和连接问题难以在田间广泛应用。

Method: 使用知识蒸馏技术，通过集成学习将高容量卷积神经网络（CNNs）的知识转移到紧凑型CNNs中，并结合密集微小对进行优化集成。

Result: 在精选的咖啡叶数据集上，蒸馏后的微小集成模型在显著降低能耗和碳足迹的同时，达到了与先前工作相当的准确度。

Conclusion: 轻量级模型通过知识蒸馏和集成学习，可以在严格的计算和能源限制下提供实用的咖啡叶病害诊断解决方案，显著降低能耗和碳足迹。

Abstract: Coffee yields are contingent on the timely and accurate diagnosis of diseases; however, assessing leaf diseases in the field presents significant challenges. Although Artificial Intelligence (AI) vision models achieve high accuracy, their adoption is hindered by the limitations of constrained devices and intermittent connectivity. This study aims to facilitate sustainable on-device diagnosis through knowledge distillation: high-capacity Convolutional Neural Networks (CNNs) trained in data centers transfer knowledge to compact CNNs through Ensemble Learning (EL). Furthermore, dense tiny pairs were integrated through simple and optimized ensembling to enhance accuracy while adhering to strict computational and energy constraints. On a curated coffee leaf dataset, distilled tiny ensembles achieved competitive with prior work with significantly reduced energy consumption and carbon footprint. This indicates that lightweight models, when properly distilled and ensembled, can provide practical diagnostic solutions for Internet of Things (IoT) applications.

</details>


### [72] [RCDN: Real-Centered Detection Network for Robust Face Forgery Identification](https://arxiv.org/abs/2601.12111)
*Wyatt McCurdy,Xin Zhang,Yuqi Song,Min Gao*

Main category: cs.CV

TL;DR: RCDN是一种基于频率空间CNN的伪造检测网络，通过强调真实图像的一致性，显著提升了跨域性能，适用于应对新兴伪造技术。


<details>
  <summary>Details</summary>
Motivation: 现有检测方法在跨域场景下性能显著下降，难以应对不断涌现的新伪造技术，因此需要一种更鲁棒的检测方法。

Method: 提出了一种基于频率空间卷积神经网络（CNN）的框架RCDN，采用Xception主干网络，通过双分支架构和真实中心损失设计来增强分布偏移下的鲁棒性。

Result: 在DiFF数据集上的实验表明，RCDN不仅实现了最先进的域内准确率，还显著提升了跨域泛化能力，减少了泛化差距。

Conclusion: RCDN通过强调真实图像的一致性，显著提升了跨域场景下的检测性能，并减少了泛化差距，展现了其作为防御新兴伪造技术的潜力。

Abstract: Image forgery has become a critical threat with the rapid proliferation of AI-based generation tools, which make it increasingly easy to synthesize realistic but fraudulent facial content. Existing detection methods achieve near-perfect performance when training and testing are conducted within the same domain, yet their effectiveness deteriorates substantially in crossdomain scenarios. This limitation is problematic, as new forgery techniques continuously emerge and detectors must remain reliable against unseen manipulations. To address this challenge, we propose the Real-Centered Detection Network (RCDN), a frequency spatial convolutional neural networks(CNN) framework with an Xception backbone that anchors its representation space around authentic facial images. Instead of modeling the diverse and evolving patterns of forgeries, RCDN emphasizes the consistency of real images, leveraging a dual-branch architecture and a real centered loss design to enhance robustness under distribution shifts. Extensive experiments on the DiFF dataset, focusing on three representative forgery types (FE, I2I, T2I), demonstrate that RCDN achieves both state-of-the-art in-domain accuracy and significantly stronger cross-domain generalization. Notably, RCDN reduces the generalization gap compared to leading baselines and achieves the highest cross/in-domain stability ratio, highlighting its potential as a practical solution for defending against evolving and unseen image forgery techniques.

</details>


### [73] [CARLA-Round: A Multi-Factor Simulation Dataset for Roundabout Trajectory Prediction](https://arxiv.org/abs/2601.12119)
*Xiaotong Zhou,Zhenhui Yuan,Yi Han,Tianhua Xu,Laurence T. Yang*

Main category: cs.CV

TL;DR: CARLA-Round是一个系统化设计的环岛轨迹预测仿真数据集，通过控制天气和交通密度量化了不同条件的影响，并展示了良好的仿真到现实迁移能力。


<details>
  <summary>Details</summary>
Motivation: 环岛场景的车辆轨迹预测对减少交通事故至关重要，但现有数据集稀缺且难以隔离混杂因素。

Method: 提出了CARLA-Round数据集，通过控制天气条件（五种类型）和交通密度水平（A-E级），设计了25种结构化场景，并提供明确的标注。

Result: 验证实验表明，交通密度对预测难度具有单调性影响，而天气条件呈现非线性影响。最佳模型在真实数据集上的ADE为0.312米。

Conclusion: CARLA-Round数据集通过系统化设计，量化了不同条件对轨迹预测性能的影响，填补了现有数据集的空白，并展示了有效的仿真到现实的迁移能力。

Abstract: Accurate trajectory prediction of vehicles at roundabouts is critical for reducing traffic accidents, yet it remains highly challenging due to their circular road geometry, continuous merging and yielding interactions, and absence of traffic signals. Developing accurate prediction algorithms relies on reliable, multimodal, and realistic datasets; however, such datasets for roundabout scenarios are scarce, as real-world data collection is often limited by incomplete observations and entangled factors that are difficult to isolate. We present CARLA-Round, a systematically designed simulation dataset for roundabout trajectory prediction. The dataset varies weather conditions (five types) and traffic density levels (spanning Level-of-Service A-E) in a structured manner, resulting in 25 controlled scenarios. Each scenario incorporates realistic mixtures of driving behaviors and provides explicit annotations that are largely absent from existing datasets. Unlike randomly sampled simulation data, this structured design enables precise analysis of how different conditions influence trajectory prediction performance. Validation experiments using standard baselines (LSTM, GCN, GRU+GCN) reveal traffic density dominates prediction difficulty with strong monotonic effects, while weather shows non-linear impacts. The best model achieves 0.312m ADE on real-world rounD dataset, demonstrating effective sim-to-real transfer. This systematic approach quantifies factor impacts impossible to isolate in confounded real-world datasets. Our CARLA-Round dataset is available at https://github.com/Rebecca689/CARLA-Round.

</details>


### [74] [Learning Fine-Grained Correspondence with Cross-Perspective Perception for Open-Vocabulary 6D Object Pose Estimation](https://arxiv.org/abs/2601.13565)
*Yu Qin,Shimeng Fan,Fan Yang,Zixuan Xue,Zijie Mai,Wenrui Chen,Kailun Yang,Zhiyong Li*

Main category: cs.CV

TL;DR: FiCoP通过块级对应和空间过滤，显著提升了开放词汇6D物体姿态估计的鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 现有开放词汇6D物体姿态估计方法依赖无约束的全局匹配策略，在开放世界场景中容易因背景干扰导致匹配模糊，因此需要一种更精细的匹配方法。

Method: 1. 对象中心解耦预处理以隔离语义目标与环境噪声；2. 跨视角全局感知（CPGP）模块融合双视角特征，通过显式上下文推理建立结构共识；3. 块相关性预测器（PCP）生成精确的块级关联图，作为空间过滤器实现细粒度、抗噪声匹配。

Result: 在REAL275和Toyota-Light数据集上，FiCoP的平均召回率分别比现有最优方法提高了8.0%和6.1%。

Conclusion: FiCoP框架通过从全局匹配转向空间约束的块级对应，显著提高了开放词汇6D物体姿态估计的准确性和鲁棒性，实验结果表明其在REAL275和Toyota-Light数据集上的平均召回率分别提升了8.0%和6.1%。

Abstract: Open-vocabulary 6D object pose estimation empowers robots to manipulate arbitrary unseen objects guided solely by natural language. However, a critical limitation of existing approaches is their reliance on unconstrained global matching strategies. In open-world scenarios, trying to match anchor features against the entire query image space introduces excessive ambiguity, as target features are easily confused with background distractors. To resolve this, we propose Fine-grained Correspondence Pose Estimation (FiCoP), a framework that transitions from noise-prone global matching to spatially-constrained patch-level correspondence. Our core innovation lies in leveraging a patch-to-patch correlation matrix as a structural prior to narrowing the matching scope, effectively filtering out irrelevant clutter to prevent it from degrading pose estimation. Firstly, we introduce an object-centric disentanglement preprocessing to isolate the semantic target from environmental noise. Secondly, a Cross-Perspective Global Perception (CPGP) module is proposed to fuse dual-view features, establishing structural consensus through explicit context reasoning. Finally, we design a Patch Correlation Predictor (PCP) that generates a precise block-wise association map, acting as a spatial filter to enforce fine-grained, noise-resilient matching. Experiments on the REAL275 and Toyota-Light datasets demonstrate that FiCoP improves Average Recall by 8.0% and 6.1%, respectively, compared to the state-of-the-art method, highlighting its capability to deliver robust and generalized perception for robotic agents operating in complex, unconstrained open-world environments. The source code will be made publicly available at https://github.com/zjjqinyu/FiCoP.

</details>


### [75] [Segment and Matte Anything in a Unified Model](https://arxiv.org/abs/2601.12147)
*Zezhong Fan,Xiaohan Li,Topojoy Biswas,Kaushiki Nag,Kannan Achan*

Main category: cs.CV

TL;DR: SAMA是SAM的轻量级扩展，通过MVLE和Local-Adapter模块实现高质量分割和抠图，性能优异。


<details>
  <summary>Details</summary>
Motivation: 尽管SAM在分割任务中表现优异，但其掩码预测精度仍不足，且交互式抠图任务尚未在SAM框架中探索。分割与抠图之间的强相关性提示了统一模型的可能性。

Method: 提出了Multi-View Localization Encoder (MVLE)捕获局部视图的细节特征，以及Local-Adapter模块优化掩码输出，同时架构中整合了两个预测头分别用于分割和抠图任务。

Result: SAMA在多个分割和抠图基准测试中达到了最先进的性能，证明了其在广泛下游任务中的有效性。

Conclusion: SAMA作为SAM的轻量级扩展，通过MVLE和Local-Adapter模块实现了高质量的分割和抠图，展示了在多任务中的适应性和高效性。

Abstract: Segment Anything (SAM) has recently pushed the boundaries of segmentation by demonstrating zero-shot generalization and flexible prompting after training on over one billion masks. Despite this, its mask prediction accuracy often falls short of the precision required in real-world applications. While several refinement modules have been proposed to boost SAM's segmentation quality, achieving highly accurate object delineation within a single, unified framework remains an open challenge. Furthermore, interactive image matting, which aims to generate fine-grained alpha mattes guided by diverse user hints, has not yet been explored in the context of SAM. Insights from recent studies highlight strong correlations between segmentation and matting, suggesting the feasibility of a unified model capable of both tasks. In this paper, we introduce Segment And Matte Anything (SAMA), a lightweight extension of SAM that delivers high-quality interactive image segmentation and matting with minimal extra parameters. Our Multi-View Localization Encoder (MVLE) captures detailed features from local views, while the Localization Adapter (Local-Adapter) refines mask outputs by recovering subtle boundary details. We also incorporate two prediction heads for each task into the architecture to generate segmentation and matting masks, simultaneously. Trained on a diverse dataset aggregated from publicly available sources, SAMA achieves state-of-the-art performance across multiple segmentation and matting benchmarks, showcasing its adaptability and effectiveness in a wide range of downstream tasks.

</details>


### [76] [FantasyVLN: Unified Multimodal Chain-of-Thought Reasoning for Vision-Language Navigation](https://arxiv.org/abs/2601.13976)
*Jing Zuo,Lingzhou Mu,Fan Jiang,Chengcheng Ma,Mu Xu,Yonggang Qi*

Main category: cs.CV

TL;DR: FantasyVLN提出了一种隐式推理框架，通过紧凑的潜在空间编码和多CoT策略，实现了高效的实时视觉与语言导航。


<details>
  <summary>Details</summary>
Motivation: 现有方法在视觉与语言导航（VLN）中存在空间基础不足和标记膨胀问题，导致实时导航不切实际。

Method: 使用预训练的视觉自回归器（VAR）将想象的视觉标记编码到紧凑的潜在空间中，并在多CoT策略下联合学习文本、视觉和多模态CoT模式。

Result: 在LH-VLN上的实验表明，该方法实现了推理感知的实时导航，成功率和效率均有提升，推理延迟比显式CoT方法低一个数量级。

Conclusion: FantasyVLN框架通过隐式推理保留了CoT推理的优势，无需显式标记开销，实现了实时导航，显著提高了成功率和效率。

Abstract: Achieving human-level performance in Vision-and-Language Navigation (VLN) requires an embodied agent to jointly understand multimodal instructions and visual-spatial context while reasoning over long action sequences. Recent works, such as NavCoT and NavGPT-2, demonstrate the potential of Chain-of-Thought (CoT) reasoning for improving interpretability and long-horizon planning. Moreover, multimodal extensions like OctoNav-R1 and CoT-VLA further validate CoT as a promising pathway toward human-like navigation reasoning. However, existing approaches face critical drawbacks: purely textual CoTs lack spatial grounding and easily overfit to sparse annotated reasoning steps, while multimodal CoTs incur severe token inflation by generating imagined visual observations, making real-time navigation impractical. In this work, we propose FantasyVLN, a unified implicit reasoning framework that preserves the benefits of CoT reasoning without explicit token overhead. Specifically, imagined visual tokens are encoded into a compact latent space using a pretrained Visual AutoRegressor (VAR) during CoT reasoning training, and the model jointly learns from textual, visual, and multimodal CoT modes under a unified multi-CoT strategy. At inference, our model performs direct instruction-to-action mapping while still enjoying reasoning-aware representations. Extensive experiments on LH-VLN show that our approach achieves reasoning-aware yet real-time navigation, improving success rates and efficiency while reducing inference latency by an order of magnitude compared to explicit CoT methods.

</details>


### [77] [Principal Component Analysis-Based Terahertz Self-Supervised Denoising and Deblurring Deep Neural Networks](https://arxiv.org/abs/2601.12149)
*Pengfei Zhu,Xavier Maldague*

Main category: cs.CV

TL;DR: THz-SSDD网络通过自监督学习和PCA，无需人工干预即可同时处理THz图像的低频模糊和高频噪声。


<details>
  <summary>Details</summary>
Motivation: 传统图像处理方法无法同时解决THz图像中的低频模糊和高频噪声问题，且需要人工干预。

Method: 采用基于PCA的自监督去噪和去模糊网络（THz-SSDD），利用Recorrupted-to-Recorrupted策略捕捉噪声特征，并通过PCA分解与重构恢复图像。

Result: 在四种样本上验证了THz-SSDD的有效性，仅需少量无标签噪声图像进行训练，测试结果表明其能有效去噪和去模糊。

Conclusion: THz-SSDD网络通过自监督学习策略和PCA分解，有效解决了THz图像中的低频模糊和高频噪声问题，同时保留了信号的物理特性。

Abstract: Terahertz (THz) systems inherently introduce frequency-dependent degradation effects, resulting in low-frequency blurring and high-frequency noise in amplitude images. Conventional image processing techniques cannot simultaneously address both issues, and manual intervention is often required due to the unknown boundary between denoising and deblurring. To tackle this challenge, we propose a principal component analysis (PCA)-based THz self-supervised denoising and deblurring network (THz-SSDD). The network employs a Recorrupted-to-Recorrupted self-supervised learning strategy to capture the intrinsic features of noise by exploiting invariance under repeated corruption. PCA decomposition and reconstruction are then applied to restore images across both low and high frequencies. The performance of the THz-SSDD network was evaluated on four types of samples. Training requires only a small set of unlabeled noisy images, and testing across samples with different material properties and measurement modes demonstrates effective denoising and deblurring. Quantitative analysis further validates the network feasibility, showing improvements in image quality while preserving the physical characteristics of the original signals.

</details>


### [78] [Enhanced Diagnostic Performance via Large-Resolution Inference Optimization for Pathology Foundation Models](https://arxiv.org/abs/2601.12150)
*Mengxuan Hu,Zihan Guan,John Kang,Sheng Li,Zhongliang Zhou*

Main category: cs.CV

TL;DR: 提出一种高效推理策略，通过稀疏化注意力和过滤非信息性标记，降低WSI推理时的资源消耗，同时提升分类和分割性能。


<details>
  <summary>Details</summary>
Motivation: 解决病理学基础模型在应用于全切片图像（WSI）时因固定输入尺寸导致的效率低下问题，避免直接放大输入或降采样带来的GPU内存消耗或关键形态细节丢失。

Method: 采用空间感知的邻近块稀疏化注意力机制，并通过全局注意力分数过滤非信息性标记。

Result: 实验结果显示，该方法在ROI分类任务中最高提升7.67%，在分割任务中表现兼容。

Conclusion: 提出的空间和时间高效推理策略通过稀疏化注意力机制和过滤非信息性标记，显著降低了高分辨率WSI推理时的GPU内存和运行时间，同时保持甚至提升了下游任务性能。

Abstract: Despite their prominent performance on tasks such as ROI classification and segmentation, many pathology foundation models remain constrained by a specific input size e.g. 224 x 224, creating substantial inefficiencies when applied to whole-slide images (WSIs), which span thousands of resolutions. A naive strategy is to either enlarge inputs or downsample the WSIs. However, enlarging inputs results in prohibitive GPU memory consumption, while downsampling alters the microns-per-pixel resolution and obscures critical morphological details. To overcome these limitations, we propose an space- and time- efficient inference strategy that sparsifies attention using spatially aware neighboring blocks and filters out non-informative tokens through global attention scores. This design substantially reduces GPU memory and runtime during high-resolution WSI inference while preserving and even improving the downstream performance, enabling inference at higher resolutions under the same GPU budget. The experimental results show that our method can achieves up to an 7.67% improvement in the ROI classification and compatible results in segmentation.

</details>


### [79] [Inverse Rendering for High-Genus 3D Surface Meshes from Multi-view Images with Persistent Homology Priors](https://arxiv.org/abs/2601.12155)
*Xiang Gao,Xinmu Wang,Yuanpeng Liu,Yue Wang,Junqi Huang,Wei Chen,Xianfeng Gu*

Main category: cs.CV

TL;DR: 该论文提出了一种结合持久同调先验的协作逆渲染方法，有效解决了高亏格表面重建中的拓扑模糊性问题，实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 解决从图像重建3D物体时因几何、外观和拓扑模糊性导致的困难，特别是高亏格表面的重建问题。

Method: 采用基于网格的逆渲染框架内的梯度优化方法，结合持久同调先验，利用多视角图像的光度一致性和同调引导。

Result: 实验结果表明，该方法在Chamfer Distance（CD）和Volume IoU上优于现有方法，验证了几何准确性和拓扑鲁棒性的提升。

Conclusion: 通过结合持久同调先验，该方法在重建高亏格表面时表现出更高的几何准确性和拓扑鲁棒性，优于现有基于网格的方法。

Abstract: Reconstructing 3D objects from images is inherently an ill-posed problem due to ambiguities in geometry, appearance, and topology. This paper introduces collaborative inverse rendering with persistent homology priors, a novel strategy that leverages topological constraints to resolve these ambiguities. By incorporating priors that capture critical features such as tunnel loops and handle loops, our approach directly addresses the difficulty of reconstructing high-genus surfaces. The collaboration between photometric consistency from multi-view images and homology-based guidance enables recovery of complex high-genus geometry while circumventing catastrophic failures such as collapsing tunnels or losing high-genus structure. Instead of neural networks, our method relies on gradient-based optimization within a mesh-based inverse rendering framework to highlight the role of topological priors. Experimental results show that incorporating persistent homology priors leads to lower Chamfer Distance (CD) and higher Volume IoU compared to state-of-the-art mesh-based methods, demonstrating improved geometric accuracy and robustness against topological failure.

</details>


### [80] [VIRTUE: Versatile Video Retrieval Through Unified Embeddings](https://arxiv.org/abs/2601.12193)
*Shaunak Halbe,Bhagyashree Puranik,Jayakrishnan Unnikrishnan,Kushan Thakkar,Vimal Bhat,Toufiq Parag*

Main category: cs.CV

TL;DR: VIRTUE是一个基于MLLM的视频检索框架，通过共享主干和对比对齐技术，在多种检索任务中表现优异，接近专业模型。


<details>
  <summary>Details</summary>
Motivation: 解决现有专业架构无法处理组合多模态查询，而MLLM方法检索性能不足的问题。

Method: 使用共享MLLM主干生成视觉和文本嵌入，并通过对比对齐技术进行高效嵌入搜索。采用LoRA在70万对视觉-文本数据上高效训练。

Result: 在零样本视频检索、时刻检索和组合检索任务中超越其他MLLM方法，甚至接近专业模型的性能。

Conclusion: VIRTUE框架通过共享MLLM主干和对比对齐技术，成功整合了多种视频检索任务，并在零样本检索和组合检索中表现出色，甚至媲美专业模型。

Abstract: Modern video retrieval systems are expected to handle diverse tasks ranging from corpus-level retrieval and fine-grained moment localization to flexible multimodal querying. Specialized architectures achieve strong retrieval performance by training modality-specific encoders on massive datasets, but they lack the ability to process composed multimodal queries. In contrast, multimodal LLM (MLLM)-based methods support rich multimodal search but their retrieval performance remains well below that of specialized systems. We present VIRTUE, an MLLM-based versatile video retrieval framework that integrates corpus and moment-level retrieval capabilities while accommodating composed multimodal queries within a single architecture. We use contrastive alignment of visual and textual embeddings generated using a shared MLLM backbone to facilitate efficient embedding-based candidate search. Our embedding model, trained efficiently using low-rank adaptation (LoRA) on 700K paired visual-text data samples, surpasses other MLLM-based methods on zero-shot video retrieval tasks. Additionally, we demonstrate that the same model can be adapted without further training to achieve competitive results on zero-shot moment retrieval, and state of the art results for zero-shot composed video retrieval. With additional training for reranking candidates identified in the embedding-based search, our model substantially outperforms existing MLLM-based retrieval systems and achieves retrieval performance comparable to state of the art specialized models which are trained on orders of magnitude larger data.

</details>


### [81] [Where It Moves, It Matters: Referring Surgical Instrument Segmentation via Motion](https://arxiv.org/abs/2601.12224)
*Meng Wei,Kun Yuan,Shi Li,Yue Zhou,Long Bai,Nassir Navab,Hongliang Ren,Hong Joo Lee,Tom Vercauteren,Nicolas Padoy*

Main category: cs.CV

TL;DR: SurgRef是一种运动引导框架，通过器械运动而非外观实现自然语言描述的手术器械定位，显著提升准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 手术场景中基于自然语言的交互是实现智能手术室和自主手术机器人辅助的关键步骤，但现有方法因依赖静态视觉线索和预定义器械名称而泛化能力不足。

Method: 提出了SurgRef，一种新颖的运动引导框架，通过捕捉器械的运动和交互而非静态视觉特征，实现自由形式语言表达与器械运动的关联。

Result: SurgRef在Ref-IMotion数据集上实现了最先进的准确性和泛化能力，为语言驱动的手术视频分割设定了新基准。

Conclusion: SurgRef通过运动引导框架在手术视频中实现了基于自然语言描述的器械定位，显著提高了准确性和泛化能力，为智能手术室和自主手术机器人辅助奠定了基础。

Abstract: Enabling intuitive, language-driven interaction with surgical scenes is a critical step toward intelligent operating rooms and autonomous surgical robotic assistance. However, the task of referring segmentation, localizing surgical instruments based on natural language descriptions, remains underexplored in surgical videos, with existing approaches struggling to generalize due to reliance on static visual cues and predefined instrument names. In this work, we introduce SurgRef, a novel motion-guided framework that grounds free-form language expressions in instrument motion, capturing how tools move and interact across time, rather than what they look like. This allows models to understand and segment instruments even under occlusion, ambiguity, or unfamiliar terminology. To train and evaluate SurgRef, we present Ref-IMotion, a diverse, multi-institutional video dataset with dense spatiotemporal masks and rich motion-centric expressions. SurgRef achieves state-of-the-art accuracy and generalization across surgical procedures, setting a new benchmark for robust, language-driven surgical video segmentation.

</details>


### [82] [DiffusionQC: Artifact Detection in Histopathology via Diffusion Model](https://arxiv.org/abs/2601.12233)
*Zhenzhen Wang,Zhongliang Zhou,Zhuoyu Wen,Jeong Hwan Kook,John B Wojcik,John Kang*

Main category: cs.CV

TL;DR: DiffusionQC通过扩散模型和对比学习检测病理图像伪影，仅需干净图像训练，性能优越且泛化能力强。


<details>
  <summary>Details</summary>
Motivation: 传统监督模型需要大量标注数据且难以泛化至新型伪影类型，DiffusionQC旨在解决这一问题，仅需干净图像训练，降低资源消耗。

Method: 提出DiffusionQC，利用扩散模型将伪影视为干净图像中的异常值进行检测，并结合对比学习模块增强伪影与干净图像的分布分离。

Result: 实验结果表明，DiffusionQC在性能和跨染色泛化能力上优于现有方法，且所需数据和标注显著减少。

Conclusion: DiffusionQC通过扩散模型和对比学习模块，有效检测组织病理学图像中的伪影，仅需干净图像训练，无需大量标注数据，展现出卓越性能和跨染色泛化能力。

Abstract: Digital pathology plays a vital role across modern medicine, offering critical insights for disease diagnosis, prognosis, and treatment. However, histopathology images often contain artifacts introduced during slide preparation and digitization. Detecting and excluding them is essential to ensure reliable downstream analysis. Traditional supervised models typically require large annotated datasets, which is resource-intensive and not generalizable to novel artifact types. To address this, we propose DiffusionQC, which detects artifacts as outliers among clean images using a diffusion model. It requires only a set of clean images for training rather than pixel-level artifact annotations and predefined artifact types. Furthermore, we introduce a contrastive learning module to explicitly enlarge the distribution separation between artifact and clean images, yielding an enhanced version of our method. Empirical results demonstrate superior performance to state-of-the-art and offer cross-stain generalization capacity, with significantly less data and annotations.

</details>


### [83] [Less is More: Label-Guided Summarization of Procedural and Instructional Videos](https://arxiv.org/abs/2601.12243)
*Shreya Rajpal,Michal Golovanesky,Carsten Eickhoff*

Main category: cs.CV

TL;DR: PRISM是一种三阶段视频摘要框架，通过语义和多模态分析生成上下文连贯的摘要，在保留高语义内容的同时显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 视频摘要在高风险领域（如手术培训）中至关重要，现有方法从基本视觉特征发展到预训练的视觉-语言模型，但仍需更语义化和上下文感知的解决方案。

Method: PRISM框架结合了自适应视觉采样、标签驱动的关键帧锚定和基于大型语言模型（LLM）的上下文验证，确保摘要内容具有语义基础且上下文连贯。

Result: 在采样少于原始视频5%的帧的情况下，PRISM生成的摘要保留了84%的语义内容，比基线方法提升了33%。

Conclusion: PRISM框架在视频摘要任务中表现出色，不仅保留了84%的语义内容，还在语义对齐和精确度上显著优于基线方法，适用于多种视频类型。

Abstract: Video summarization helps turn long videos into clear, concise representations that are easier to review, document, and analyze, especially in high-stakes domains like surgical training. Prior work has progressed from using basic visual features like color, motion, and structural changes to using pre-trained vision-language models that can better understand what's happening in the video (semantics) and capture temporal flow, resulting in more context-aware video summarization. We propose a three-stage framework, PRISM: Procedural Representation via Integrated Semantic and Multimodal analysis, that produces semantically grounded video summaries. PRISM combines adaptive visual sampling, label-driven keyframe anchoring, and contextual validation using a large language model (LLM). Our method ensures that selected frames reflect meaningful and procedural transitions while filtering out generic or hallucinated content, resulting in contextually coherent summaries across both domain-specific and instructional videos. We evaluate our method on instructional and activity datasets, using reference summaries for instructional videos. Despite sampling fewer than 5% of the original frames, our summaries retain 84% semantic content while improving over baselines by as much as 33%. Our approach generalizes across procedural and domain-specific video tasks, achieving strong performance with both semantic alignment and precision.

</details>


### [84] [An Innovative Framework for Breast Cancer Detection Using Pyramid Adaptive Atrous Convolution, Transformer Integration, and Multi-Scale Feature Fusion](https://arxiv.org/abs/2601.12249)
*Ehsan Sadeghi Pour,Mahdi Esmaeili,Morteza Romoozi*

Main category: cs.CV

TL;DR: 提出结合PAAC和Transformer的乳腺癌检测框架，通过多尺度特征融合和混合损失函数优化，在多个指标上显著优于传统方法，验证了模型的高效性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 乳腺癌是全球女性最常见癌症之一，准确及时的诊断对改善治疗效果至关重要。

Method: 通过整合金字塔自适应空洞卷积（PAAC）和Transformer架构，利用多尺度特征融合增强良恶性组织特征提取，并结合Dice Loss和Focal Loss函数优化模型学习过程。

Result: 模型在INbreast、MIAS和DDSM数据集上训练后，准确率达98.5%，灵敏度97.8%，特异性96.3%，F1-score 98.2%，精确度97.9%，优于基础模型。

Conclusion: 该模型展示了作为乳腺癌诊断可靠高效工具的潜力，并能有效整合到医疗诊断系统中。

Abstract: Breast cancer is one of the most common cancers among women worldwide, and its accurate and timely diagnosis plays a critical role in improving treatment outcomes. This thesis presents an innovative framework for detecting malignant masses in mammographic images by integrating the Pyramid Adaptive Atrous Convolution (PAAC) and Transformer architectures. The proposed approach utilizes Multi-Scale Feature Fusion to enhance the extraction of features from benign and malignant tissues and combines Dice Loss and Focal Loss functions to improve the model's learning process, effectively reducing errors in binary breast cancer classification and achieving high accuracy and efficiency. In this study, a comprehensive dataset of breast cancer images from INbreast, MIAS, and DDSM was preprocessed through data augmentation and contrast enhancement and resized to 227x227 pixels for model training. Leveraging the Transformer's ability to manage long-range dependencies with Self-Attention mechanisms, the proposed model achieved high accuracy in detecting cancerous masses, outperforming foundational models such as BreastNet, DeepMammo, Multi-Scale CNN, Swin-Unet, and SegFormer. The final evaluation results for the proposed model include an accuracy of 98.5\%, sensitivity of 97.8\%, specificity of 96.3\%, F1-score of 98.2\%, and overall precision of 97.9\%. These metrics demonstrate a significant improvement over traditional methods and confirm the model's effectiveness in identifying cancerous masses in complex scenarios and large datasets. This model shows potential as a reliable and efficient tool for breast cancer diagnosis and can be effectively integrated into medical diagnostic systems.

</details>


### [85] [Federated Joint Learning for Domain and Class Generalization](https://arxiv.org/abs/2601.12253)
*Haoran Xu,Jiaze Li,Jianzhong Ju,Zhenbo Luo*

Main category: cs.CV

TL;DR: FedDCG是一种联合解决类别和领域泛化的新方法，通过领域分组和知识解耦提升性能，实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常单独处理未见类别或未见领域问题，缺乏联合框架，FedDCG旨在同时解决这两类泛化问题。

Method: 采用领域分组策略训练类别泛化网络，并通过可学习网络和知识解耦机制提升类别和领域泛化能力。

Result: 在多个数据集上的实验表明，FedDCG在准确性和鲁棒性上优于现有基线方法。

Conclusion: FedDCG提出了一种联合解决类别和领域泛化的新方法，通过领域分组策略和可学习网络增强泛化能力，实验证明其在准确性和鲁棒性上优于现有方法。

Abstract: Efficient fine-tuning of visual-language models like CLIP has become crucial due to their large-scale parameter size and extensive pretraining requirements. Existing methods typically address either the issue of unseen classes or unseen domains in isolation, without considering a joint framework for both. In this paper, we propose \textbf{Fed}erated Joint Learning for \textbf{D}omain and \textbf{C}lass \textbf{G}eneralization, termed \textbf{FedDCG}, a novel approach that addresses both class and domain generalization in federated learning settings. Our method introduces a domain grouping strategy where class-generalized networks are trained within each group to prevent decision boundary confusion. During inference, we aggregate class-generalized results based on domain similarity, effectively integrating knowledge from both class and domain generalization. Specifically, a learnable network is employed to enhance class generalization capabilities, and a decoupling mechanism separates general and domain-specific knowledge, improving generalization to unseen domains. Extensive experiments across various datasets show that \textbf{FedDCG} outperforms state-of-the-art baselines in terms of accuracy and robustness.

</details>


### [86] [AgenticPruner: MAC-Constrained Neural Network Compression via LLM-Driven Strategy Search](https://arxiv.org/abs/2601.12272)
*Shahrzad Esmat,Mahdi Banisharif,Ali Jannesari*

Main category: cs.CV

TL;DR: AgenticPruner利用LLM和协同代理系统实现MAC约束剪枝，提升精度和效率，适用于严格计算预算场景。


<details>
  <summary>Details</summary>
Motivation: 现有剪枝方法主要关注参数减少，而未直接控制计算成本，导致在需要严格MAC预算的场景中推理延迟不可预测。

Method: 采用三个专门代理（Profiling Agent、Master Agent和Analysis Agent）协同工作，通过上下文学习和图结构分组实现MAC约束优化。

Result: 在ImageNet-1K上验证了ResNet、ConvNeXt和DeiT架构，实现了MAC目标并提升精度，如ResNet-50达到1.77G MACs和77.04%准确率（+0.91%）。

Conclusion: AgenticPruner框架通过利用大型语言模型和协同代理系统，成功实现了在严格MAC预算下的神经网络剪枝，同时保持或提高了模型精度。

Abstract: Neural network pruning remains essential for deploying deep learning models on resource-constrained devices, yet existing approaches primarily target parameter reduction without directly controlling computational cost. This yields unpredictable inference latency in deployment scenarios where strict Multiply-Accumulate (MAC) operation budgets must be met. We propose AgenticPruner, a framework utilizing large language models to achieve MAC-constrained optimization through iterative strategy learning. Our approach coordinates three specialized agents: a Profiling Agent that analyzes model architecture and MAC distributions, a Master Agent that orchestrates the workflow with divergence monitoring, and an Analysis Agent powered by Claude 3.5 Sonnet that learns optimal strategies from historical attempts. Through in-context learning, the Analysis Agent improves convergence success rate from 48% to 71% compared to grid search. Building upon isomorphic pruning's graph-based structural grouping, our method adds context-aware adaptation by analyzing patterns across pruning iterations, enabling automatic convergence to target MAC budgets within user-defined tolerance bands.
  We validate our framework on ImageNet-1K across ResNet, ConvNeXt, and DeiT architectures. On CNNs, our approach achieves MAC targeting while maintaining or improving accuracy: ResNet-50 reaches 1.77G MACs with 77.04% accuracy (+0.91% vs baseline); ResNet-101 achieves 4.22G MACs with 78.94% accuracy (+1.56% vs baseline). For ConvNeXt-Small, pruning to 8.17G MACs yields 1.41x GPU and 1.07x CPU speedup with 45% parameter reduction. On Vision Transformers, we demonstrate MAC-budget compliance within user-defined tolerance bands (typically +1% to +5% overshoot, -5% to -15% undershoot), establishing feasibility for deployment scenarios requiring strict computational guarantees.

</details>


### [87] [CytoCLIP: Learning Cytoarchitectural Characteristics in Developing Human Brain Using Contrastive Language Image Pre-Training](https://arxiv.org/abs/2601.12282)
*Pralaypati Ta,Sriram Venkatesaperumal,Keerthi Ram,Mohanasankar Sivaprakasam*

Main category: cs.CV

TL;DR: CytoCLIP 是一种自动化大脑细胞结构识别方法，结合视觉和文本表示，显著提高了分类准确率。


<details>
  <summary>Details</summary>
Motivation: 手动划分大脑细胞结构区域耗时且需要专业知识，因此需要自动化方法以减少人工干预。

Method: 提出了 CytoCLIP，一个基于预训练 CLIP 框架的视觉-语言模型，包含低分辨率全区域图像和高分辨率图像块两种变体，用于学习大脑细胞结构的联合表示。

Result: CytoCLIP 在区域分类和跨模态检索任务中表现优异，低分辨率分类 F1 得分为 0.87，高分辨率分类 F1 得分为 0.91，优于现有方法。

Conclusion: CytoCLIP 通过结合视觉和文本表示，成功实现了对大脑细胞结构的自动识别，显著提高了分类准确率，并展示了良好的泛化能力。

Abstract: The functions of different regions of the human brain are closely linked to their distinct cytoarchitecture, which is defined by the spatial arrangement and morphology of the cells. Identifying brain regions by their cytoarchitecture enables various scientific analyses of the brain. However, delineating these areas manually in brain histological sections is time-consuming and requires specialized knowledge. An automated approach is necessary to minimize the effort needed from human experts. To address this, we propose CytoCLIP, a suite of vision-language models derived from pre-trained Contrastive Language-Image Pre-Training (CLIP) frameworks to learn joint visual-text representations of brain cytoarchitecture. CytoCLIP comprises two model variants: one is trained using low-resolution whole-region images to understand the overall cytoarchitectural pattern of an area, and the other is trained on high-resolution image tiles for detailed cellular-level representation. The training dataset is created from NISSL-stained histological sections of developing fetal brains of different gestational weeks. It includes 86 distinct regions for low-resolution images and 384 brain regions for high-resolution tiles. We evaluate the model's understanding of the cytoarchitecture and generalization ability using region classification and cross-modal retrieval tasks. Multiple experiments are performed under various data setups, including data from samples of different ages and sectioning planes. Experimental results demonstrate that CytoCLIP outperforms existing methods. It achieves an F1 score of 0.87 for whole-region classification and 0.91 for high-resolution image tile classification.

</details>


### [88] [SDiT: Semantic Region-Adaptive for Diffusion Transformers](https://arxiv.org/abs/2601.12283)
*Bowen Lin,Fanjiang Ye,Yihua Liu,Zhenghui Guo,Boyuan Zhang,Weijian Zheng,Yufan Xu,Tiancheng Xing,Yuke Wang,Chengming Zhang*

Main category: cs.CV

TL;DR: SDiT通过语义区域自适应计算分配，在不重新训练或修改架构的情况下，显著加速了Diffusion Transformers，同时保持高质量输出。


<details>
  <summary>Details</summary>
Motivation: 观察到去噪动态在空间上不均匀，背景区域快速收敛而边缘和纹理区域变化更活跃，因此提出按区域复杂度分配计算以降低计算成本。

Method: 提出了SDiT，一个语义区域自适应的扩散Transformer，结合了（1）基于快速Quickshift分割的语义感知聚类，（2）复杂度驱动的区域调度以选择性更新信息区域，（3）边界感知细化以保持空间一致性。

Result: SDiT实现了高达3.0倍的加速，同时保持了与全注意力推理几乎相同的感知和语义质量。

Conclusion: SDiT通过语义区域自适应计算分配，在不重新训练或修改架构的情况下，实现了高达3.0倍的加速，同时保持了与全注意力推理几乎相同的感知和语义质量。

Abstract: Diffusion Transformers (DiTs) achieve state-of-the-art performance in text-to-image synthesis but remain computationally expensive due to the iterative nature of denoising and the quadratic cost of global attention. In this work, we observe that denoising dynamics are spatially non-uniform-background regions converge rapidly while edges and textured areas evolve much more actively. Building on this insight, we propose SDiT, a Semantic Region-Adaptive Diffusion Transformer that allocates computation according to regional complexity. SDiT introduces a training-free framework combining (1) semantic-aware clustering via fast Quickshift-based segmentation, (2) complexity-driven regional scheduling to selectively update informative areas, and (3) boundary-aware refinement to maintain spatial coherence. Without any model retraining or architectural modification, SDiT achieves up to 3.0x acceleration while preserving nearly identical perceptual and semantic quality to full-attention inference.

</details>


### [89] [LegacyAvatars: Volumetric Face Avatars For Traditional Graphics Pipelines](https://arxiv.org/abs/2601.12285)
*Safa C. Medin,Gengyan Li,Ziqian Bai,Ruofei Du,Leonhard Helminger,Yinda Zhang,Stephan J. Garbin,Philip L. Davidson,Gregory W. Wornell,Thabo Beeler,Abhimitra Meka*

Main category: cs.CV

TL;DR: 提出一种结合辐射场和参数化模型的3D人脸化身表示方法，支持高效经典渲染和动画控制。


<details>
  <summary>Details</summary>
Motivation: 旨在实现高效、可控的3D人脸化身渲染，适用于传统图形平台，无需定制工程或集成。

Method: 利用参数化人脸模型锚定的辐射场技术，学习3D空间中的辐射流形，提取显式分层网格及外观和变形纹理。

Result: 实现了复杂面部特征（如头发、皮肤和眼睛）的可控体积渲染，并能通过简单的线性混合和alpha合成进行动画控制。

Conclusion: 该论文提出了一种新颖的3D人脸化身表示方法，通过结合参数化人脸模型和辐射场技术，实现了高效、可控的经典渲染，适用于多种图形平台。

Abstract: We introduce a novel representation for efficient classical rendering of photorealistic 3D face avatars. Leveraging recent advances in radiance fields anchored to parametric face models, our approach achieves controllable volumetric rendering of complex facial features, including hair, skin, and eyes. At enrollment time, we learn a set of radiance manifolds in 3D space to extract an explicit layered mesh, along with appearance and warp textures. During deployment, this allows us to control and animate the face through simple linear blending and alpha compositing of textures over a static mesh. This explicit representation also enables the generated avatar to be efficiently streamed online and then rendered using classical mesh and shader-based rendering on legacy graphics platforms, eliminating the need for any custom engineering or integration.

</details>


### [90] [Concepts from Representations: Post-hoc Concept Bottleneck Models via Sparse Decomposition of Visual Representations](https://arxiv.org/abs/2601.12303)
*Shizhan Gong,Xiaofan Zhang,Qi Dou*

Main category: cs.CV

TL;DR: PCBM-ReD是一种通过表示分解实现可解释性的新方法，自动提取视觉概念并优化选择，在图像分类任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在图像识别方面取得了显著成功，但其固有的不透明性在关键领域部署时带来了挑战。现有的后处理方法和前处理概念瓶颈模型（CBMs）存在概念相关性不可靠、概念定义非可视化或劳动密集型、以及模型或数据无关假设等局限性。

Method: PCBM-ReD自动从预训练编码器中提取视觉概念，利用多模态大语言模型（MLLMs）根据视觉可识别性和任务相关性对概念进行标记和筛选，并通过重建引导的优化选择独立子集。利用CLIP的视觉-文本对齐，将图像表示分解为概念嵌入的线性组合，以适应概念瓶颈模型（CBMs）的抽象。

Result: PCBM-ReD在11个图像分类任务中实现了最先进的准确率，缩小了与端到端模型的性能差距，并展现出更好的可解释性。

Conclusion: PCBM-ReD通过表示分解的方法，成功地在预训练不透明模型上实现了可解释性，同时在11个图像分类任务中达到了最先进的准确率，缩小了与端到端模型的性能差距，并展现出更好的可解释性。

Abstract: Deep learning has achieved remarkable success in image recognition, yet their inherent opacity poses challenges for deployment in critical domains. Concept-based interpretations aim to address this by explaining model reasoning through human-understandable concepts. However, existing post-hoc methods and ante-hoc concept bottleneck models (CBMs), suffer from limitations such as unreliable concept relevance, non-visual or labor-intensive concept definitions, and model or data-agnostic assumptions. This paper introduces Post-hoc Concept Bottleneck Model via Representation Decomposition (PCBM-ReD), a novel pipeline that retrofits interpretability onto pretrained opaque models. PCBM-ReD automatically extracts visual concepts from a pre-trained encoder, employs multimodal large language models (MLLMs) to label and filter concepts based on visual identifiability and task relevance, and selects an independent subset via reconstruction-guided optimization. Leveraging CLIP's visual-text alignment, it decomposes image representations into linear combination of concept embeddings to fit into the CBMs abstraction. Extensive experiments across 11 image classification tasks show PCBM-ReD achieves state-of-the-art accuracy, narrows the performance gap with end-to-end models, and exhibits better interpretability.

</details>


### [91] [A Two-Stage Globally-Diverse Adversarial Attack for Vision-Language Pre-training Models](https://arxiv.org/abs/2601.12304)
*Wutao Chen,Huaqin Zou,Chen Wan,Lifeng Huang*

Main category: cs.CV

TL;DR: 2S-GDA通过文本与视觉的双重全局多样性扰动策略，显著提升黑盒攻击成功率，且具备模块化优势。


<details>
  <summary>Details</summary>
Motivation: 针对现有多模态攻击方法在扰动多样性和多阶段流程稳定性上的不足，旨在提升对抗样本在黑盒场景下的攻击效果。

Method: 提出了两阶段全局多样性攻击框架（2S-GDA），首阶段通过候选文本扩展与全局感知替换引入文本扰动，次阶段利用多尺度调整与块状旋转增强视觉多样性。

Result: 在VLP模型上的实验表明，2S-GDA攻击成功率显著优于现有方法，黑盒设置下最高提升11.17%。

Conclusion: 2S-GDA框架通过全局多样性策略显著提升了黑盒场景下的攻击成功率，且模块化设计便于与现有方法结合，进一步增强对抗迁移性。

Abstract: Vision-language pre-training (VLP) models are vulnerable to adversarial examples, particularly in black-box scenarios. Existing multimodal attacks often suffer from limited perturbation diversity and unstable multi-stage pipelines. To address these challenges, we propose 2S-GDA, a two-stage globally-diverse attack framework. The proposed method first introduces textual perturbations through a globally-diverse strategy by combining candidate text expansion with globally-aware replacement. To enhance visual diversity, image-level perturbations are generated using multi-scale resizing and block-shuffle rotation. Extensive experiments on VLP models demonstrate that 2S-GDA consistently improves attack success rates over state-of-the-art methods, with gains of up to 11.17\% in black-box settings. Our framework is modular and can be easily combined with existing methods to further enhance adversarial transferability.

</details>


### [92] [Adaptive Multi-Scale Correlation Meta-Network for Few-Shot Remote Sensing Image Classification](https://arxiv.org/abs/2601.12308)
*Anurag Kaushish,Ayan Sar,Sampurna Roy,Sudeshna Chakraborty,Prashant Trivedi,Tanupriya Choudhury,Kanav Gupta*

Main category: cs.CV

TL;DR: AMC-MetaNet是一个轻量级框架，通过多尺度相关性创新解决遥感小样本学习问题，高效且准确。


<details>
  <summary>Details</summary>
Motivation: 解决小样本遥感学习中的三个挑战：标记数据稀缺、显著的领域偏移和地理空间对象的多尺度性质。

Method: 引入了自适应多尺度相关元网络（AMC-MetaNet），包括三个关键创新：相关性引导的特征金字塔、自适应通道相关模块（ACCM）和相关性引导的元学习。

Result: 在多个遥感数据集上实现了高达86.65%的准确率，参数数量比ResNet-18少20倍，推理时间小于50毫秒每图像。

Conclusion: AMC-MetaNet被证明是一个计算高效、尺度感知的框架，适用于现实世界中的小样本遥感学习。

Abstract: Few-shot learning in remote sensing remains challenging due to three factors: the scarcity of labeled data, substantial domain shifts, and the multi-scale nature of geospatial objects. To address these issues, we introduce Adaptive Multi-Scale Correlation Meta-Network (AMC-MetaNet), a lightweight yet powerful framework with three key innovations: (i) correlation-guided feature pyramids for capturing scale-invariant patterns, (ii) an adaptive channel correlation module (ACCM) for learning dynamic cross-scale relationships, and (iii) correlation-guided meta-learning that leverages correlation patterns instead of conventional prototype averaging. Unlike prior approaches that rely on heavy pre-trained models or transformers, AMC-MetaNet is trained from scratch with only $\sim600K$ parameters, offering $20\times$ fewer parameters than ResNet-18 while maintaining high efficiency ($<50$ms per image inference). AMC-MetaNet achieves up to 86.65\% accuracy in 5-way 5-shot classification on various remote sensing datasets, including EuroSAT, NWPU-RESISC45, UC Merced Land Use, and AID. Our results establish AMC-MetaNet as a computationally efficient, scale-aware framework for real-world few-shot remote sensing.

</details>


### [93] [CurConMix+: A Unified Spatio-Temporal Framework for Hierarchical Surgical Workflow Understanding](https://arxiv.org/abs/2601.12312)
*Yongjun Jeon,Jongmin Shin,Kanggil Park,Seonmin Park,Soyoung Lim,Jung Yong Kim,Jinsoo Rhu,Jongman Kim,Gyu-Seong Choi,Namkee Oh,Kyu-Hwan Jung*

Main category: cs.CV

TL;DR: 提出 CurConMix+ 框架和 LLS48 数据集，通过课程对比学习和多分辨率时间变换器解决手术动作三元组识别的挑战，实验显示其优越性能和跨层次泛化能力。


<details>
  <summary>Details</summary>
Motivation: 手术动作三元组识别在临床工作流分析和技能评估中具有重要意义，但现有方法因类别不平衡、视觉变化细微及三元组语义互依赖性而受限，缺乏整体性解决方案。

Method: 基于 CurConMix 的空间表示框架，采用课程引导的对比学习策略，结合结构化硬对采样和特征级混合。其时间扩展 CurConMix+ 集成了多分辨率时间变换器（MRTT），自适应融合多尺度时间特征并动态平衡时空线索。

Result: 在 CholecT45 和 LLS48 上的实验表明，CurConMix+ 在三元组识别中优于现有方法，并展现出强大的跨层次泛化能力，其细粒度特征可有效迁移至高层次的阶段和步骤识别任务。

Conclusion: CurConMix+ 框架和 LLS48 数据集为层次感知、可重复且可解释的手术工作流理解提供了统一基础。代码和数据集将在 GitHub 公开，以促进可重复性和进一步研究。

Abstract: Surgical action triplet recognition aims to understand fine-grained surgical behaviors by modeling the interactions among instruments, actions, and anatomical targets. Despite its clinical importance for workflow analysis and skill assessment, progress has been hindered by severe class imbalance, subtle visual variations, and the semantic interdependence among triplet components. Existing approaches often address only a subset of these challenges rather than tackling them jointly, which limits their ability to form a holistic understanding. This study builds upon CurConMix, a spatial representation framework. At its core, a curriculum-guided contrastive learning strategy learns discriminative and progressively correlated features, further enhanced by structured hard-pair sampling and feature-level mixup. Its temporal extension, CurConMix+, integrates a Multi-Resolution Temporal Transformer (MRTT) that achieves robust, context-aware understanding by adaptively fusing multi-scale temporal features and dynamically balancing spatio-temporal cues. Furthermore, we introduce LLS48, a new, hierarchically annotated benchmark for complex laparoscopic left lateral sectionectomy, providing step-, task-, and action-level annotations. Extensive experiments on CholecT45 and LLS48 demonstrate that CurConMix+ not only outperforms state-of-the-art approaches in triplet recognition, but also exhibits strong cross-level generalization, as its fine-grained features effectively transfer to higher-level phase and step recognition tasks. Together, the framework and dataset provide a unified foundation for hierarchy-aware, reproducible, and interpretable surgical workflow understanding. The code and dataset will be publicly released on GitHub to facilitate reproducibility and further research.

</details>


### [94] [S^2F-Net:A Robust Spatial-Spectral Fusion Framework for Cross-Model AIGC Detection](https://arxiv.org/abs/2601.12313)
*Xiangyu Hu,Yicheng Hong,Hongchuang Zheng,Wenjun Zeng,Bingyao Liu*

Main category: cs.CV

TL;DR: S 2 F-Net利用频谱差异提升检测泛化性，在跨域检测中表现优异。


<details>
  <summary>Details</summary>
Motivation: 生成模型的快速发展对具有强泛化能力的检测方案提出了迫切需求，现有方法通常对特定源模型过拟合，面对未见过的生成架构时性能显著下降。

Method: 提出了一种名为S 2 F-Net的跨模型检测框架，通过可学习的频率注意力模块自适应加权和增强判别性频带，结合空间纹理分析和频谱依赖性。

Result: 在包含17类生成模型的AIGCDetectBenchmark上，S 2 F-Net的检测准确率达到90.49%，显著优于现有基线方法。

Conclusion: S 2 F-Net通过探索和利用真实与合成纹理之间的固有频谱差异，显著提升了检测模型的泛化性能，在跨域检测场景中表现优异。

Abstract: The rapid development of generative models has imposed an urgent demand for detection schemes with strong generalization capabilities. However, existing detection methods generally suffer from overfitting to specific source models, leading to significant performance degradation when confronted with unseen generative architectures. To address these challenges, this paper proposes a cross-model detection framework called S 2 F-Net, whose core lies in exploring and leveraging the inherent spectral discrepancies between real and synthetic textures. Considering that upsampling operations leave unique and distinguishable frequency fingerprints in both texture-poor and texture-rich regions, we focus our research on the detection of frequency-domain artifacts, aiming to fundamentally improve the generalization performance of the model. Specifically, we introduce a learnable frequency attention module that adaptively weights and enhances discriminative frequency bands by synergizing spatial texture analysis and spectral dependencies.On the AIGCDetectBenchmark, which includes 17 categories of generative models, S 2 F-Net achieves a detection accuracy of 90.49%, significantly outperforming various existing baseline methods in cross-domain detection scenarios.

</details>


### [95] [GazeFormer-MoE: Context-Aware Gaze Estimation via CLIP and MoE Transformer](https://arxiv.org/abs/2601.12316)
*Xinyuan Zhao,Xianrui Chen,Ahmad Chaddad*

Main category: cs.CV

TL;DR: 该论文提出了一种语义调制和多尺度Transformer结合的3D视线估计模型，通过原型条件化和混合专家机制显著提升了性能，在多个数据集上达到最优结果。


<details>
  <summary>Details</summary>
Motivation: 为了提升3D视线估计的准确性和鲁棒性，论文提出了一种新的模型架构，旨在通过多尺度特征融合和条件化机制来解决现有方法的局限性。

Method: 模型通过可学习的原型库（如光照、头部姿态、背景、方向）条件化CLIP全局特征，将这些原型增强的全局向量与CLIP局部标记和高分辨率CNN标记在统一的注意力空间中进行融合，并采用路由/共享的混合专家机制替代部分FFN块以增加条件容量。

Result: 在MPIIFaceGaze、EYEDIAP、Gaze360和ETH-XGaze数据集上，模型分别达到了2.49°、3.22°、10.16°和1.44°的角误差，相对之前最优结果提升了64%。

Conclusion: 该论文提出的基于语义调制和多尺度Transformer的3D视线估计模型，通过原型条件化、跨尺度融合和混合专家机制，显著提升了性能，并在多个数据集上达到了新的最优结果。

Abstract: We present a semantics modulated, multi scale Transformer for 3D gaze estimation. Our model conditions CLIP global features with learnable prototype banks (illumination, head pose, background, direction), fuses these prototype-enriched global vectors with CLIP patch tokens and high-resolution CNN tokens in a unified attention space, and replaces several FFN blocks with routed/shared Mixture of Experts to increase conditional capacity. Evaluated on MPIIFaceGaze, EYEDIAP, Gaze360 and ETH-XGaze, our model achieves new state of the art angular errors of 2.49°, 3.22°, 10.16°, and 1.44°, demonstrating up to a 64% relative improvement over previously reported results. ablations attribute gains to prototype conditioning, cross scale fusion, MoE and hyperparameter. Our code is publicly available at https://github. com/AIPMLab/Gazeformer.

</details>


### [96] [Multi-Sensor Matching with HyperNetworks](https://arxiv.org/abs/2601.12325)
*Eli Passov,Nathan S. Netanyahu,Yosi Keller*

Main category: cs.CV

TL;DR: 提出了一种结合超网络和条件实例归一化的轻量级描述符学习架构，显著提升了多模态补丁匹配的鲁棒性和性能。


<details>
  <summary>Details</summary>
Motivation: 利用超网络的灵活性来改进多模态补丁匹配，以应对外观变化带来的挑战。

Method: 提出了一种轻量级描述符学习架构，结合了超网络模块（用于计算自适应、每通道的缩放和偏移）和条件实例归一化（用于在浅层提供模态特定的适应）。

Result: 在VIS-NIR和其他VIS-IR基准测试中取得了最先进的性能，并在其他数据集上匹配或超越了先前的方法。

Conclusion: 通过引入超网络模块和条件实例归一化，该方法在保持推理效率的同时显著提升了跨模态匹配的鲁棒性，并在多个基准测试中达到了最先进的性能。

Abstract: Hypernetworks are models that generate or modulate the weights of another network. They provide a flexible mechanism for injecting context and task conditioning and have proven broadly useful across diverse applications without significant increases in model size. We leverage hypernetworks to improve multimodal patch matching by introducing a lightweight descriptor-learning architecture that augments a Siamese CNN with (i) hypernetwork modules that compute adaptive, per-channel scaling and shifting and (ii) conditional instance normalization that provides modality-specific adaptation (e.g., visible vs. infrared, VIS-IR) in shallow layers. This combination preserves the efficiency of descriptor-based methods during inference while increasing robustness to appearance shifts. Trained with a triplet loss and hard-negative mining, our approach achieves state-of-the-art results on VIS-NIR and other VIS-IR benchmarks and matches or surpasses prior methods on additional datasets, despite their higher inference cost. To spur progress on domain shift, we also release GAP-VIR, a cross-platform (ground/aerial) VIS-IR patch dataset with 500K pairs, enabling rigorous evaluation of cross-domain generalization and adaptation.

</details>


### [97] [EmoKGEdit: Training-free Affective Injection via Visual Cue Transformation](https://arxiv.org/abs/2601.12326)
*Jing Zhang,Bingjie Fan*

Main category: cs.CV

TL;DR: EmoKGEdit通过知识图谱和解耦模块实现精准且结构保持的图像情感编辑，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有图像情感编辑方法难以将情感线索与潜在内容表征解耦，导致情感表达弱且视觉结构失真。

Method: 提出EmoKGEdit框架，包括构建多模态情感关联知识图谱（MSA-KG）和解耦结构-情感编辑模块，利用外部知识指导多模态大模型推理情感相关视觉线索。

Result: 实验表明EmoKGEdit在情感保真度和内容保持方面表现优异，超越现有技术。

Conclusion: EmoKGEdit通过构建MSA-KG知识图谱和设计解耦编辑模块，显著提升了图像情感编辑的精确性和结构保持能力，优于现有方法。

Abstract: Existing image emotion editing methods struggle to disentangle emotional cues from latent content representations, often yielding weak emotional expression and distorted visual structures. To bridge this gap, we propose EmoKGEdit, a novel training-free framework for precise and structure-preserving image emotion editing. Specifically, we construct a Multimodal Sentiment Association Knowledge Graph (MSA-KG) to disentangle the intricate relationships among objects, scenes, attributes, visual clues and emotion. MSA-KG explicitly encode the causal chain among object-attribute-emotion, and as external knowledge to support chain of thought reasoning, guiding the multimodal large model to infer plausible emotion-related visual cues and generate coherent instructions. In addition, based on MSA-KG, we design a disentangled structure-emotion editing module that explicitly separates emotional attributes from layout features within the latent space, which ensures that the target emotion is effectively injected while strictly maintaining visual spatial coherence. Extensive experiments demonstrate that EmoKGEdit achieves excellent performance in both emotion fidelity and content preservation, and outperforms the state-of-the-art methods.

</details>


### [98] [FlowIID: Single-Step Intrinsic Image Decomposition via Latent Flow Matching](https://arxiv.org/abs/2601.12329)
*Mithlesh Singla,Seema Kumari,Shanmuganathan Raman*

Main category: cs.CV

TL;DR: FlowIID是一种基于流匹配的IID模型，参数高效且性能优越，适用于实时应用。


<details>
  <summary>Details</summary>
Motivation: 现有的IID模型参数过多，难以与其他模型结合，限制了实际应用。

Method: FlowIID基于潜在流匹配设计，结合了VAE引导的潜在空间和流匹配模块，实现了稳定的反照率和阴影分解。

Result: FlowIID在单次推理步骤中生成结果，并在多个基准测试中表现优于现有模型。

Conclusion: FlowIID是一种参数高效且性能优越的模型，适用于资源受限和实时视觉应用。

Abstract: Intrinsic Image Decomposition (IID) separates an image into albedo and shading components. It is a core step in many real-world applications, such as relighting and material editing. Existing IID models achieve good results, but often use a large number of parameters. This makes them costly to combine with other models in real-world settings. To address this problem, we propose a flow matching-based solution. For this, we design a novel architecture, FlowIID, based on latent flow matching. FlowIID combines a VAE-guided latent space with a flow matching module, enabling a stable decomposition of albedo and shading. FlowIID is not only parameter-efficient, but also produces results in a single inference step. Despite its compact design, FlowIID delivers competitive and superior results compared to existing models across various benchmarks. This makes it well-suited for deployment in resource-constrained and real-time vision applications.

</details>


### [99] [Turbo-GoDec: Exploiting the Cluster Sparsity Prior for Hyperspectral Anomaly Detection](https://arxiv.org/abs/2601.12337)
*Jiahui Sheng,Xiaorun Li,Shuhan Chen*

Main category: cs.CV

TL;DR: Turbo-GoDec通过结合集群稀疏先验改进GoDec算法，在高光谱异常检测中表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖低秩背景和稀疏异常的先验假设，但很少扩展异常的空间分布特性。观察到异常像素在空间中呈现小集群分布，提出了集群稀疏先验。

Method: 结合了集群稀疏先验与经典GoDec算法，通过马尔可夫随机场建模异常的空间分布特性，并在因子图上通过消息传递计算异常概率。

Result: 在三个真实高光谱图像数据集上的实验表明，Turbo-GoDec方法在小尺寸异常检测中表现优异。

Conclusion: Turbo-GoDec方法在检测小尺寸异常方面表现出色，优于传统GoDec（LSMAD）和其他先进异常检测方法。

Abstract: As a key task in hyperspectral image processing, hyperspectral anomaly detection has garnered significant attention and undergone extensive research. Existing methods primarily relt on two prior assumption: low-rank background and sparse anomaly, along with additional spatial assumptions of the background. However, most methods only utilize the sparsity prior assumption for anomalies and rarely expand on this hypothesis. From observations of hyperspectral images, we find that anomalous pixels exhibit certain spatial distribution characteristics: they often manifest as small, clustered groups in space, which we refer to as cluster sparsity of anomalies. Then, we combined the cluster sparsity prior with the classical GoDec algorithm, incorporating the cluster sparsity prior into the S-step of GoDec. This resulted in a new hyperspectral anomaly detection method, which we called Turbo-GoDec. In this approach, we modeled the cluster sparsity prior of anomalies using a Markov random field and computed the marginal probabilities of anomalies through message passing on a factor graph. Locations with high anomalous probabilities were treated as the sparse component in the Turbo-GoDec. Experiments are conducted on three real hyperspectral image (HSI) datasets which demonstrate the superior performance of the proposed Turbo-GoDec method in detecting small-size anomalies comparing with the vanilla GoDec (LSMAD) and state-of-the-art anomaly detection methods. The code is available at https://github.com/jiahuisheng/Turbo-GoDec.

</details>


### [100] [MMDeepResearch-Bench: A Benchmark for Multimodal Deep Research Agents](https://arxiv.org/abs/2601.12346)
*Peizhou Huang,Zixuan Zhong,Zhongwei Wan,Donghao Zhou,Samiul Alam,Xin Wang,Zexin Li,Zhihao Dou,Li Zhu,Jing Xiong,Chaofan Tao,Yan Xu,Dimitrios Dimitriadis,Tuo Zhang,Mi Zhang*

Main category: cs.CV

TL;DR: MMDR-Bench是一个新基准，用于评估多模态证据使用和报告生成，通过FLAE、TRACE和MOSAIC三个评估指标揭示模型在生成质量、引用纪律和多模态基础上的表现，发现多模态完整性是关键挑战。


<details>
  <summary>Details</summary>
Motivation: 现有基准主要针对纯文本设置或短格式多模态问答，缺乏端到端多模态证据使用评估，因此需要一个新的基准来填补这一空白。

Method: 提出了MMDR-Bench基准，包含140个专家设计的任务，覆盖21个领域，每个任务提供图文捆绑以评估多模态理解和引用支撑的报告生成。进一步提出了统一的、可解释的评估流程：FLAE、TRACE和MOSAIC，分别针对报告质量、引用证据对齐和文本-视觉完整性。

Result: 实验覆盖25个最先进模型，揭示了生成质量、引用纪律和多模态基础之间的系统权衡，表明强文本生成能力并不保证忠实证据使用，多模态完整性仍是关键瓶颈。

Conclusion: MMDR-Bench通过引入多模态证据使用和细粒度评估指标，揭示了当前深度研究代理在生成质量、引用纪律和多模态基础之间的系统权衡，强调了强文本生成能力并不等同于忠实证据使用，多模态完整性仍是关键瓶颈。

Abstract: Deep Research Agents (DRAs) generate citation-rich reports via multi-step search and synthesis, yet existing benchmarks mainly target text-only settings or short-form multimodal QA, missing end-to-end multimodal evidence use. We introduce MMDeepResearch-Bench (MMDR-Bench), a benchmark of 140 expert-crafted tasks across 21 domains, where each task provides an image-text bundle to evaluate multimodal understanding and citation-grounded report generation. Compared to prior setups, MMDR-Bench emphasizes report-style synthesis with explicit evidence use, where models must connect visual artifacts to sourced claims and maintain consistency across narrative, citations, and visual references. We further propose a unified, interpretable evaluation pipeline: Formula-LLM Adaptive Evaluation (FLAE) for report quality, Trustworthy Retrieval-Aligned Citation Evaluation (TRACE) for citation-grounded evidence alignment, and Multimodal Support-Aligned Integrity Check (MOSAIC) for text-visual integrity, each producing fine-grained signals that support error diagnosis beyond a single overall score. Experiments across 25 state-of-the-art models reveal systematic trade-offs between generation quality, citation discipline, and multimodal grounding, highlighting that strong prose alone does not guarantee faithful evidence use and that multimodal integrity remains a key bottleneck for deep research agents.

</details>


### [101] [SimpleMatch: A Simple and Strong Baseline for Semantic Correspondence](https://arxiv.org/abs/2601.12357)
*Hailing Jin,Huiying Li*

Main category: cs.CV

TL;DR: SimpleMatch是一个简单有效的语义对应框架，通过轻量级上采样解码器和多尺度监督损失，在低分辨率下实现高性能，并减少51%训练内存使用。


<details>
  <summary>Details</summary>
Motivation: 当前方法依赖于高分辨率输入图像以实现最佳性能，导致计算开销大。此外，深度下采样操作会导致相邻关键点特征的不可逆融合。

Method: 提出了一个轻量级的上采样解码器，逐步恢复空间细节，并通过多尺度监督损失确保上采样特征保留不同空间尺度的判别性特征。此外，引入了稀疏匹配和基于窗口的定位来优化训练内存使用。

Result: 在252x252分辨率下（比当前SOTA方法小3.3倍），SimpleMatch在SPair-71k基准上实现了84.1%的PCK@0.1性能。

Conclusion: SimpleMatch框架为语义对应研究提供了一个实用且高效的基线，即使在低分辨率下也能实现优越性能。

Abstract: Recent advances in semantic correspondence have been largely driven by the use of pre-trained large-scale models. However, a limitation of these approaches is their dependence on high-resolution input images to achieve optimal performance, which results in considerable computational overhead. In this work, we address a fundamental limitation in current methods: the irreversible fusion of adjacent keypoint features caused by deep downsampling operations. This issue is triggered when semantically distinct keypoints fall within the same downsampled receptive field (e.g., 16x16 patches). To address this issue, we present SimpleMatch, a simple yet effective framework for semantic correspondence that delivers strong performance even at low resolutions. We propose a lightweight upsample decoder that progressively recovers spatial detail by upsampling deep features to 1/4 resolution, and a multi-scale supervised loss that ensures the upsampled features retain discriminative features across different spatial scales. In addition, we introduce sparse matching and window-based localization to optimize training memory usage and reduce it by 51%. At a resolution of 252x252 (3.3x smaller than current SOTA methods), SimpleMatch achieves superior performance with 84.1% PCK@0.1 on the SPair-71k benchmark. We believe this framework provides a practical and efficient baseline for future research in semantic correspondence. Code is available at: https://github.com/hailong23-jin/SimpleMatch.

</details>


### [102] [DepthCropSeg++: Scaling a Crop Segmentation Foundation Model With Depth-Labeled Data](https://arxiv.org/abs/2601.12366)
*Jiafei Zhang,Songliang Cao,Binghui Xu,Yanan Li,Weiwei Jia,Tingting Wu,Hao Lu,Weijuan Hu,Zhiguo Han*

Main category: cs.CV

TL;DR: DepthCropSeg++ 是一种作物分割基础模型，通过大规模数据集和改进架构，在多种挑战性场景中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 当前作物分割模型因像素级标注成本高而数据有限，泛化能力不足。本文旨在通过大规模跨物种和跨场景数据集及改进模型架构，提升作物分割的泛化性能。

Method: 基于 ViT-Adapter 架构，通过动态上采样增强细节感知能力，并采用两阶段自训练流程进行训练。

Result: DepthCropSeg++ 在综合测试集上达到 93.11% mIoU，显著优于监督基线（+0.36%）和通用视觉基础模型如 SAM（+48.57%）。

Conclusion: DepthCropSeg++ 在作物分割领域取得了新的最先进性能，特别是在夜间环境、高密度冠层和未见过的作物品种等挑战性场景中表现优异。

Abstract: DepthCropSeg++: a foundation model for crop segmentation, capable of segmenting different crop species under open in-field environment. Crop segmentation is a fundamental task for modern agriculture, which closely relates to many downstream tasks such as plant phenotyping, density estimation, and weed control. In the era of foundation models, a number of generic large language and vision models have been developed. These models have demonstrated remarkable real world generalization due to significant model capacity and largescale datasets. However, current crop segmentation models mostly learn from limited data due to expensive pixel-level labelling cost, often performing well only under specific crop types or controlled environment. In this work, we follow the vein of our previous work DepthCropSeg, an almost unsupervised approach to crop segmentation, to scale up a cross-species and crossscene crop segmentation dataset, with 28,406 images across 30+ species and 15 environmental conditions. We also build upon a state-of-the-art semantic segmentation architecture ViT-Adapter architecture, enhance it with dynamic upsampling for improved detail awareness, and train the model with a two-stage selftraining pipeline. To systematically validate model performance, we conduct comprehensive experiments to justify the effectiveness and generalization capabilities across multiple crop datasets. Results demonstrate that DepthCropSeg++ achieves 93.11% mIoU on a comprehensive testing set, outperforming both supervised baselines and general-purpose vision foundation models like Segmentation Anything Model (SAM) by significant margins (+0.36% and +48.57% respectively). The model particularly excels in challenging scenarios including night-time environment (86.90% mIoU), high-density canopies (90.09% mIoU), and unseen crop varieties (90.09% mIoU), indicating a new state of the art for crop segmentation.

</details>


### [103] [Utilizing the Score of Data Distribution for Hyperspectral Anomaly Detection](https://arxiv.org/abs/2601.12379)
*Jiahui Sheng,Yidan Shi,Shu Xiang,Xiaorun Li,Shuhan Chen*

Main category: cs.CV

TL;DR: 提出ScoreAD方法，利用基于分数的生成模型（SGM）学习高光谱数据分布的梯度场，通过流形假设区分背景与异常光谱，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 高光谱图像的光谱由少数因素（如化学成分和光照）决定，满足流形假设，背景光谱位于低维流形上，而异常光谱因其独特的光谱特征被视为不符合背景流形的离群点。

Method: 方法首先在整个高光谱图像的光谱集上训练SGM，测试时通过扰动核处理每个光谱，并将扰动后的光谱输入训练好的SGM以获取估计分数。

Result: 在四个高光谱数据集上的实验证明了该方法的有效性。

Conclusion: 基于高光谱流形假设，提出的ScoreAD方法通过利用基于分数的生成模型（SGM）学习数据分布的时间依赖梯度场，实现了有效的高光谱异常检测。

Abstract: Hyperspectral images (HSIs) are a type of image that contains abundant spectral information. As a type of real-world data, the high-dimensional spectra in hyperspectral images are actually determined by only a few factors, such as chemical composition and illumination. Thus, spectra in hyperspectral images are highly likely to satisfy the manifold hypothesis. Based on the hyperspectral manifold hypothesis, we propose a novel hyperspectral anomaly detection method (named ScoreAD) that leverages the time-dependent gradient field of the data distribution (i.e., the score), as learned by a score-based generative model (SGM). Our method first trains the SGM on the entire set of spectra from the hyperspectral image. At test time, each spectrum is passed through a perturbation kernel, and the resulting perturbed spectrum is fed into the trained SGM to obtain the estimated score. The manifold hypothesis of HSIs posits that background spectra reside on one or more low-dimensional manifolds. Conversely, anomalous spectra, owing to their unique spectral signatures, are considered outliers that do not conform to the background manifold. Based on this fundamental discrepancy in their manifold distributions, we leverage a generative SGM to achieve hyperspectral anomaly detection. Experiments on the four hyperspectral datasets demonstrate the effectiveness of the proposed method. The code is available at https://github.com/jiahuisheng/ScoreAD.

</details>


### [104] [A Hierarchical Benchmark of Foundation Models for Dermatology](https://arxiv.org/abs/2601.12382)
*Furkan Yuceyalcin,Abdurrahim Yilmaz,Burak Temelkuran*

Main category: cs.CV

TL;DR: 研究评估了十种基础模型的嵌入效用，发现通用医学模型适合高层次筛查，但细粒度诊断需专用模型。


<details>
  <summary>Details</summary>
Motivation: 当前皮肤病学基准测试常将复杂的诊断分类简化为扁平、二元分类任务，掩盖了模型进行细粒度鉴别诊断的能力，这对临床工作流程整合至关重要。

Method: 使用DERM12345数据集，计算冻结嵌入并训练轻量级适配器模型，采用五折交叉验证。引入分层评估框架，评估四个临床粒度级别的性能。

Result: MedImageInsights在二元恶性肿瘤检测中表现最佳（加权F1分数97.52%），但在细粒度40类亚型分类中降至65.50%。而MedSigLip（69.79%）和皮肤病特定模型在细粒度分类中表现更优。

Conclusion: 通用医学基础模型在高层次筛查中非常有效，但在诊断支持系统中所需的细粒度区分方面，需要专门的建模策略。

Abstract: Foundation models have transformed medical image analysis by providing robust feature representations that reduce the need for large-scale task-specific training. However, current benchmarks in dermatology often reduce the complex diagnostic taxonomy to flat, binary classification tasks, such as distinguishing melanoma from benign nevi. This oversimplification obscures a model's ability to perform fine-grained differential diagnoses, which is critical for clinical workflow integration. This study evaluates the utility of embeddings derived from ten foundation models, spanning general computer vision, general medical imaging, and dermatology-specific domains, for hierarchical skin lesion classification. Using the DERM12345 dataset, which comprises 40 lesion subclasses, we calculated frozen embeddings and trained lightweight adapter models using a five-fold cross-validation. We introduce a hierarchical evaluation framework that assesses performance across four levels of clinical granularity: 40 Subclasses, 15 Main Classes, 2 and 4 Superclasses, and Binary Malignancy. Our results reveal a "granularity gap" in model capabilities: MedImageInsights achieved the strongest overall performance (97.52% weighted F1-Score on Binary Malignancy detection) but declined to 65.50% on fine-grained 40-class subtype classification. Conversely, MedSigLip (69.79%) and dermatology-specific models (Derm Foundation and MONET) excelled at fine-grained 40-class subtype discrimination while achieving lower overall performance than MedImageInsights on broader classification tasks. Our findings suggest that while general medical foundation models are highly effective for high-level screening, specialized modeling strategies are necessary for the granular distinctions required in diagnostic support systems.

</details>


### [105] [Class-Partitioned VQ-VAE and Latent Flow Matching for Point Cloud Scene Generation](https://arxiv.org/abs/2601.12391)
*Dasith de Silva Edirimuni,Ajmal Saeed Mian*

Main category: cs.CV

TL;DR: 提出CPVQ-VAE和LFMM，通过类分区码本和类感知更新机制，实现无需外部数据库的纯点云生成，显著提升复杂场景重建精度。


<details>
  <summary>Details</summary>
Motivation: 当前基于扩散的方法在解码潜在特征时无法有效生成与目标类别一致的点云对象，限制了复杂场景的生成能力。

Method: 提出了Class-Partitioned Vector Quantized Variational Autoencoder (CPVQ-VAE)和Latent-space Flow Matching Model (LFMM)，通过类分区码本和类感知更新机制解决码本崩溃问题。

Result: 实验表明，该方法在复杂客厅场景中Chamfer和Point2Mesh误差分别降低了70.4%和72.3%。

Conclusion: 通过引入CPVQ-VAE和LFMM，该方法实现了无需依赖外部对象数据库的纯点云生成，显著提升了复杂场景中点云重建的准确性。

Abstract: Most 3D scene generation methods are limited to only generating object bounding box parameters while newer diffusion methods also generate class labels and latent features. Using object size or latent feature, they then retrieve objects from a predefined database. For complex scenes of varied, multi-categorical objects, diffusion-based latents cannot be effectively decoded by current autoencoders into the correct point cloud objects which agree with target classes. We introduce a Class-Partitioned Vector Quantized Variational Autoencoder (CPVQ-VAE) that is trained to effectively decode object latent features, by employing a pioneering $\textit{class-partitioned codebook}$ where codevectors are labeled by class. To address the problem of $\textit{codebook collapse}$, we propose a $\textit{class-aware}$ running average update which reinitializes dead codevectors within each partition. During inference, object features and class labels, both generated by a Latent-space Flow Matching Model (LFMM) designed specifically for scene generation, are consumed by the CPVQ-VAE. The CPVQ-VAE's class-aware inverse look-up then maps generated latents to codebook entries that are decoded to class-specific point cloud shapes. Thereby, we achieve pure point cloud generation without relying on an external objects database for retrieval. Extensive experiments reveal that our method reliably recovers plausible point cloud scenes, with up to 70.4% and 72.3% reduction in Chamfer and Point2Mesh errors on complex living room scenes.

</details>


### [106] [Weaknesses of Facial Emotion Recognition Systems](https://arxiv.org/abs/2601.12402)
*Aleksandra Jamróz,Patrycja Wysocka,Piotr Garbat*

Main category: cs.CV

TL;DR: 综述人脸情绪检测方法，选择三种最佳神经网络进行跨数据集测试，揭示现有方案的弱点。


<details>
  <summary>Details</summary>
Motivation: 人脸情绪检测是人机交互中的关键机器学习问题，现有方法多样，因此需要对相关文献进行深入综述。

Method: 选择了三种最有趣和最佳解决方案的神经网络进行训练，并在不同数据集上进行性能比较实验。

Result: 实验揭示了现有解决方案的弱点，如数据集间的差异和情绪识别的不均衡性。

Conclusion: 现有解决方案在跨数据集测试中暴露出弱点，包括数据集间的差异、识别特定情绪的难度不均以及区分相近情绪的挑战。

Abstract: Emotion detection from faces is one of the machine learning problems needed for human-computer interaction. The variety of methods used is enormous, which motivated an in-depth review of articles and scientific studies. Three of the most interesting and best solutions are selected, followed by the selection of three datasets that stood out for the diversity and number of images in them. The selected neural networks are trained, and then a series of experiments are performed to compare their performance, including testing on different datasets than a model was trained on. This reveals weaknesses in existing solutions, including differences between datasets, unequal levels of difficulty in recognizing certain emotions and the challenges in differentiating between closely related emotions.

</details>


### [107] [HOT-POT: Optimal Transport for Sparse Stereo Matching](https://arxiv.org/abs/2601.12423)
*Antonin Clerc,Michael Quellmalz,Moritz Piening,Philipp Flotho,Gregor Kornhardt,Gabriele Steidl*

Main category: cs.CV

TL;DR: 论文利用最优传输视角和相机几何线约束，提出了一种高效的稀疏立体匹配方法，特别适用于面部分析中的标志点匹配。


<details>
  <summary>Details</summary>
Motivation: 立体视觉在应用中面临遮挡、运动和相机失真等挑战，稀疏特征的立体匹配尤其因参数敏感性而复杂。论文旨在克服这种不适定性，实现无监督的稀疏匹配。

Method: 论文提出了两种距离度量（经典极线距离和3D射线距离）作为最优传输问题的成本函数，并进一步将方法扩展到无监督对象匹配，通过分层最优传输问题实现。

Result: 数值实验表明，所提出的算法能够高效实现特征和对象匹配，特别是在面部分析中匹配不同的标志点约定。

Conclusion: 该论文提出了一种基于最优传输（OT）视角的稀疏匹配方法，通过利用相机几何的线约束，有效解决了稀疏特征（如面部标志点）的立体匹配问题，并在面部分析应用中展示了其高效性。

Abstract: Stereo vision between images faces a range of challenges, including occlusions, motion, and camera distortions, across applications in autonomous driving, robotics, and face analysis. Due to parameter sensitivity, further complications arise for stereo matching with sparse features, such as facial landmarks. To overcome this ill-posedness and enable unsupervised sparse matching, we consider line constraints of the camera geometry from an optimal transport (OT) viewpoint. Formulating camera-projected points as (half)lines, we propose the use of the classical epipolar distance as well as a 3D ray distance to quantify matching quality. Employing these distances as a cost function of a (partial) OT problem, we arrive at efficiently solvable assignment problems. Moreover, we extend our approach to unsupervised object matching by formulating it as a hierarchical OT problem. The resulting algorithms allow for efficient feature and object matching, as demonstrated in our numerical experiments. Here, we focus on applications in facial analysis, where we aim to match distinct landmarking conventions.

</details>


### [108] [SkeFi: Cross-Modal Knowledge Transfer for Wireless Skeleton-Based Action Recognition](https://arxiv.org/abs/2601.12432)
*Shunyu Huang,Yunjiao Zhou,Jianfei Yang*

Main category: cs.CV

TL;DR: SkeFi利用跨模态知识转移和TC-AGC方法，从噪声无线传感器数据中提取准确姿态和动作，解决了RGB相机的局限性和无线传感器的噪声问题。


<details>
  <summary>Details</summary>
Motivation: 解决RGB相机在黑暗环境和隐私问题中的局限性，探索非侵入式无线传感器（LiDAR和mmWave）作为替代方案，并应对其数据不足和噪声问题。

Method: 提出增强的TC-AGC（时间相关自适应图卷积）与帧交互增强，结合双时间卷积的多尺度时间建模，实现跨模态知识转移。

Result: 实验表明，SkeFi在mmWave和LiDAR上实现了最先进的性能。

Conclusion: SkeFi通过跨模态知识转移和增强的TC-AGC方法，成功从噪声无线传感器数据中提取准确姿态和动作，在mmWave和LiDAR上实现了最先进的性能。

Abstract: Skeleton-based action recognition leverages human pose keypoints to categorize human actions, which shows superior generalization and interoperability compared to regular end-to-end action recognition. Existing solutions use RGB cameras to annotate skeletal keypoints, but their performance declines in dark environments and raises privacy concerns, limiting their use in smart homes and hospitals. This paper explores non-invasive wireless sensors, i.e., LiDAR and mmWave, to mitigate these challenges as a feasible alternative. Two problems are addressed: (1) insufficient data on wireless sensor modality to train an accurate skeleton estimation model, and (2) skeletal keypoints derived from wireless sensors are noisier than RGB, causing great difficulties for subsequent action recognition models. Our work, SkeFi, overcomes these gaps through a novel cross-modal knowledge transfer method acquired from the data-rich RGB modality. We propose the enhanced Temporal Correlation Adaptive Graph Convolution (TC-AGC) with frame interactive enhancement to overcome the noise from missing or inconsecutive frames. Additionally, our research underscores the effectiveness of enhancing multiscale temporal modeling through dual temporal convolution. By integrating TC-AGC with temporal modeling for cross-modal transfer, our framework can extract accurate poses and actions from noisy wireless sensors. Experiments demonstrate that SkeFi realizes state-of-the-art performances on mmWave and LiDAR. The code is available at https://github.com/Huang0035/Skefi.

</details>


### [109] [Adversarial Defense in Vision-Language Models: An Overview](https://arxiv.org/abs/2601.12443)
*Xiaowei Fu,Lei Zhang*

Main category: cs.CV

TL;DR: 综述分析了VLMs对抗防御的三种方法：训练时、测试时适应和免训练防御，讨论其优缺点及持续挑战。


<details>
  <summary>Details</summary>
Motivation: 广泛使用的视觉语言模型（如CLIP）面临复杂且难以察觉的对抗攻击威胁，可能影响跨模态任务的性能和系统安全。

Method: 综述分析了三种主要的防御范式：训练时防御、测试时适应防御和免训练防御。

Result: 训练时防御通过对抗性微调提升鲁棒性但计算成本高；测试时适应防御灵活但复杂；免训练防御通过修改输入或特征嵌入避免额外训练。

Conclusion: 本综述总结了视觉语言模型（VLMs）对抗防御策略的最新进展，强调了各种方法的优缺点，并讨论了提升VLMs鲁棒性的持续挑战。

Abstract: The widespread use of Vision Language Models (VLMs, e.g. CLIP) has raised concerns about their vulnerability to sophisticated and imperceptible adversarial attacks. These attacks could compromise model performance and system security in cross-modal tasks. To address this challenge, three main defense paradigms have been proposed: Training-time Defense, Test-time Adaptation Defense, and Training-free Defense. Training-time Defense involves modifying the training process, typically through adversarial fine-tuning to improve the robustness to adversarial examples. While effective, this approach requires substantial computational resources and may not generalize across all adversarial attacks. Test-time Adaptation Defense focuses on adapting the model at inference time by updating its parameters to handle unlabeled adversarial examples, offering flexibility but often at the cost of increased complexity and computational overhead. Training-free Defense avoids modifying the model itself, instead focusing on altering the adversarial inputs or their feature embeddings, which enforces input perturbations to mitigate the impact of attacks without additional training. This survey reviews the latest advancements in adversarial defense strategies for VLMs, highlighting the strengths and limitations of such approaches and discussing ongoing challenges in enhancing the robustness of VLMs.

</details>


### [110] [Large-scale EM Benchmark for Multi-Organelle Instance Segmentation in the Wild](https://arxiv.org/abs/2601.12464)
*Yanrui Lu,Danyang Chen,Haowen Xiao,Jiarui Zhu,Fukang Ge,Binqian Zou,Jiali Guan,Jiayin Liang,Yuting Wang,Ziqian Guan,Xiangcheng Bao,Jinhao Bi,Lin Gu,Jun He,Yingying Zhu*

Main category: cs.CV

TL;DR: 开发了一个大规模EM数据集用于多细胞器实例分割，测试发现当前模型在异质性数据和全局形态细胞器上表现不佳。


<details>
  <summary>Details</summary>
Motivation: 当前基于小型、精选数据集的基准无法捕捉真实世界EM数据的异质性和大空间上下文，限制了当前基于补丁的方法的应用。

Method: 开发了一个大规模、多源的多细胞器实例分割基准数据集，包含超过10万张2D EM图像，覆盖多种细胞类型和五个细胞器类别。数据集注释通过设计的连通性感知标签传播算法（3D LPA）结合专家细化生成。

Result: 基准测试了包括U-Net、SAM变体和Mask2Former在内的多种先进模型，发现这些模型在异质性EM数据上泛化能力不足，对具有全局分布形态的细胞器表现较差。

Conclusion: 当前模型在处理异质性EM数据和具有全局分布形态的细胞器（如内质网）时表现不佳，凸显了局部上下文模型与真实世界变异性中长距离结构连续性建模之间的根本性不匹配。

Abstract: Accurate instance-level segmentation of organelles in electron microscopy (EM) is critical for quantitative analysis of subcellular morphology and inter-organelle interactions. However, current benchmarks, based on small, curated datasets, fail to capture the inherent heterogeneity and large spatial context of in-the-wild EM data, imposing fundamental limitations on current patch-based methods. To address these limitations, we developed a large-scale, multi-source benchmark for multi-organelle instance segmentation, comprising over 100,000 2D EM images across variety cell types and five organelle classes that capture real-world variability. Dataset annotations were generated by our designed connectivity-aware Label Propagation Algorithm (3D LPA) with expert refinement. We further benchmarked several state-of-the-art models, including U-Net, SAM variants, and Mask2Former. Our results show several limitations: current models struggle to generalize across heterogeneous EM data and perform poorly on organelles with global, distributed morphologies (e.g., Endoplasmic Reticulum). These findings underscore the fundamental mismatch between local-context models and the challenge of modeling long-range structural continuity in the presence of real-world variability. The benchmark dataset and labeling tool will be publicly released soon.

</details>


### [111] [DCAC: Dynamic Class-Aware Cache Creates Stronger Out-of-Distribution Detectors](https://arxiv.org/abs/2601.12468)
*Yanqi Wu,Qichao Chen,Runhe Lai,Xinhua Lu,Jia-Xin Zhuang,Zhilin Zhao,Wei-Shi Zheng,Ruixuan Wang*

Main category: cs.CV

TL;DR: DCAC通过类感知缓存校准OOD检测，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 发现OOD样本在预测为同一类别或高概率时，视觉上更相似，而不同于真实ID样本，因此提出类感知的校准方法。

Method: 提出DCAC模块，利用缓存视觉特征和预测概率，通过轻量级两层模块减轻OOD样本上的过度自信预测。

Result: 在多个OOD基准测试中，DCAC显著提升现有方法性能，如在ImageNet OOD基准上集成ASH-S时FPR95降低6.55%。

Conclusion: DCAC作为一种无需训练、测试时校准的模块，通过动态维护每个ID类别的缓存来收集高熵样本并校准输入样本的原始预测，显著提升了现有OOD检测方法的性能。

Abstract: Out-of-distribution (OOD) detection remains a fundamental challenge for deep neural networks, particularly due to overconfident predictions on unseen OOD samples during testing. We reveal a key insight: OOD samples predicted as the same class, or given high probabilities for it, are visually more similar to each other than to the true in-distribution (ID) samples. Motivated by this class-specific observation, we propose DCAC (Dynamic Class-Aware Cache), a training-free, test-time calibration module that maintains separate caches for each ID class to collect high-entropy samples and calibrate the raw predictions of input samples. DCAC leverages cached visual features and predicted probabilities through a lightweight two-layer module to mitigate overconfident predictions on OOD samples. This module can be seamlessly integrated with various existing OOD detection methods across both unimodal and vision-language models while introducing minimal computational overhead. Extensive experiments on multiple OOD benchmarks demonstrate that DCAC significantly enhances existing methods, achieving substantial improvements, i.e., reducing FPR95 by 6.55% when integrated with ASH-S on ImageNet OOD benchmark.

</details>


### [112] [Histopath-C: Towards Realistic Domain Shifts for Histopathology Vision-Language Adaptation](https://arxiv.org/abs/2601.12493)
*Mehrdad Noori,Gustavo Adolfo Vargas Hakim,David Osowiechi,Fereshteh Shakeri,Ali Bahri,Moslem Yazdanpanah,Sahar Dastani,Ismail Ben Ayed,Christian Desrosiers*

Main category: cs.CV

TL;DR: 提出Histopath-C基准和LATTE方法，通过合成腐蚀和低秩适应策略提升组织病理学VLM的稳健性。


<details>
  <summary>Details</summary>
Motivation: 组织病理学图像可能存在严重的领域偏移（如染色、污染、模糊和噪声），这会严重影响VLM的下游性能。

Method: 提出了一种名为LATTE的转导性低秩适应策略，利用多种文本模板来减轻组织病理学VLM对多样化文本输入的敏感性。

Result: LATTE在多个组织病理学数据集上超越了专为自然图像设计的最先进TTA方法。

Conclusion: LATTE方法在多种组织病理学数据集上表现优于现有技术，证明了其在组织病理学图像中稳健适应的有效性。

Abstract: Medical Vision-language models (VLMs) have shown remarkable performances in various medical imaging domains such as histo\-pathology by leveraging pre-trained, contrastive models that exploit visual and textual information. However, histopathology images may exhibit severe domain shifts, such as staining, contamination, blurring, and noise, which may severely degrade the VLM's downstream performance. In this work, we introduce Histopath-C, a new benchmark with realistic synthetic corruptions designed to mimic real-world distribution shifts observed in digital histopathology. Our framework dynamically applies corruptions to any available dataset and evaluates Test-Time Adaptation (TTA) mechanisms on the fly. We then propose LATTE, a transductive, low-rank adaptation strategy that exploits multiple text templates, mitigating the sensitivity of histopathology VLMs to diverse text inputs. Our approach outperforms state-of-the-art TTA methods originally designed for natural images across a breadth of histopathology datasets, demonstrating the effectiveness of our proposed design for robust adaptation in histopathology images. Code and data are available at https://github.com/Mehrdad-Noori/Histopath-C.

</details>


### [113] [Video Individual Counting and Tracking from Moving Drones: A Benchmark and Methods](https://arxiv.org/abs/2601.12500)
*Yaowu Fan,Jia Wan,Tao Han,Andy J. Ma,Antoni B. Chan*

Main category: cs.CV

TL;DR: 提出GD3A和DVTrack方法，利用移动无人机捕捉视频进行人群计数与跟踪，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖固定摄像头数据集，空间覆盖有限，无法满足大规模密集人群分析需求。

Method: 提出了GD3A（基于密度图的视频个体计数方法）和DVTrack（通过描述符投票机制实现行人跟踪），避免了显式定位。

Result: 在MovingDroneCrowd++数据集上，GD3A和DVTrack显著优于现有方法。

Conclusion: GD3A和DVTrack方法在大规模密集人群场景中显著优于现有方法，计数误差减少47.4%，跟踪性能提升39.2%。

Abstract: Counting and tracking dense crowds in large-scale scenes is highly challenging, yet existing methods mainly rely on datasets captured by fixed cameras, which provide limited spatial coverage and are inadequate for large-scale dense crowd analysis. To address this limitation, we propose a flexible solution using moving drones to capture videos and perform video-level crowd counting and tracking of unique pedestrians across entire scenes. We introduce MovingDroneCrowd++, the largest video-level dataset for dense crowd counting and tracking captured by moving drones, covering diverse and complex conditions with varying flight altitudes, camera angles, and illumination. Existing methods fail to achieve satisfactory performance on this dataset. To this end, we propose GD3A (Global Density Map Decomposition via Descriptor Association), a density map-based video individual counting method that avoids explicit localization. GD3A establishes pixel-level correspondences between pedestrian descriptors across consecutive frames via optimal transport with an adaptive dustbin score, enabling the decomposition of global density maps into shared, inflow, and outflow components. Building on this framework, we further introduce DVTrack, which converts descriptor-level matching into instance-level associations through a descriptor voting mechanism for pedestrian tracking. Experimental results show that our methods significantly outperform existing approaches under dense crowds and complex motion, reducing counting error by 47.4 percent and improving tracking performance by 39.2 percent.

</details>


### [114] [SDCoNet: Saliency-Driven Multi-Task Collaborative Network for Remote Sensing Object Detection](https://arxiv.org/abs/2601.12507)
*Ruo Qi,Linhui Dai,Yusong Qin,Chaolei Yang,Yanshan Li*

Main category: cs.CV

TL;DR: SDCoNet通过多任务协作网络提升低质量遥感图像中小目标检测性能，结合Swin Transformer和梯度路由策略优化特征共享与冲突。


<details>
  <summary>Details</summary>
Motivation: 解决传统串行流程中优化目标不一致、特征冗余以及超分辨率和检测任务间缺乏有效交互的问题。

Method: 提出了一种基于Swin Transformer的共享编码器，结合多尺度显著性预测模块和梯度路由策略，实现跨任务特征协作和优化冲突缓解。

Result: 在NWPU VHR-10-Split、DOTAv1.5-Split和HRSSD-Split等公开数据集上，SDCoNet显著优于现有主流算法。

Conclusion: SDCoNet通过多任务协作网络，结合超分辨率和检测任务，显著提升了低质量遥感图像中小目标的检测性能，同时保持了计算效率。

Abstract: In remote sensing images, complex backgrounds, weak object signals, and small object scales make accurate detection particularly challenging, especially under low-quality imaging conditions. A common strategy is to integrate single-image super-resolution (SR) before detection; however, such serial pipelines often suffer from misaligned optimization objectives, feature redundancy, and a lack of effective interaction between SR and detection. To address these issues, we propose a Saliency-Driven multi-task Collaborative Network (SDCoNet) that couples SR and detection through implicit feature sharing while preserving task specificity. SDCoNet employs the swin transformer-based shared encoder, where hierarchical window-shifted self-attention supports cross-task feature collaboration and adaptively balances the trade-off between texture refinement and semantic representation. In addition, a multi-scale saliency prediction module produces importance scores to select key tokens, enabling focused attention on weak object regions, suppression of background clutter, and suppression of adverse features introduced by multi-task coupling. Furthermore, a gradient routing strategy is introduced to mitigate optimization conflicts. It first stabilizes detection semantics and subsequently routes SR gradients along a detection-oriented direction, enabling the framework to guide the SR branch to generate high-frequency details that are explicitly beneficial for detection. Experiments on public datasets, including NWPU VHR-10-Split, DOTAv1.5-Split, and HRSSD-Split, demonstrate that the proposed method, while maintaining competitive computational efficiency, significantly outperforms existing mainstream algorithms in small object detection on low-quality remote sensing images. Our code is available at https://github.com/qiruo-ya/SDCoNet.

</details>


### [115] [Fine-Tuning Cycle-GAN for Domain Adaptation of MRI Images](https://arxiv.org/abs/2601.12512)
*Mohd Usama,Belal Ahmad,Faleh Menawer R Althiyabi*

Main category: cs.CV

TL;DR: 提出无监督Cycle-GAN模型，通过双向映射和内容保留解决MRI跨域适应问题，实验证明其有效提升模型性能并减少域变异。


<details>
  <summary>Details</summary>
Motivation: 不同扫描仪或机构获取的MRI数据存在域偏移问题，导致基于源域数据训练的深度学习模型在目标域图像上性能下降，需解决这一挑战以提升医疗诊断准确性。

Method: 利用Cycle-GAN实现源域和目标域之间的无监督双向映射，结合内容损失和差异损失，确保图像域适应的同时保持解剖结构完整性。

Result: 在多个MRI数据集上的实验表明，该模型无需标注数据即可实现有效的双向域适应，统计结果证实其能提升模型性能并减少域相关变异。

Conclusion: 该研究提出的基于Cycle-GAN的无监督医学图像域适应模型，通过双向映射和内容保留策略，显著提升了模型在跨域MRI数据上的性能，减少了域相关变异，为医疗图像分析的精确性和一致性提供了新途径。

Abstract: Magnetic Resonance Imaging (MRI) scans acquired from different scanners or institutions often suffer from domain shifts owing to variations in hardware, protocols, and acquisition parameters. This discrepancy degrades the performance of deep learning models trained on source domain data when applied to target domain images. In this study, we propose a Cycle-GAN-based model for unsupervised medical-image domain adaptation. Leveraging CycleGANs, our model learns bidirectional mappings between the source and target domains without paired training data, preserving the anatomical content of the images. By leveraging Cycle-GAN capabilities with content and disparity loss for adaptation tasks, we ensured image-domain adaptation while maintaining image integrity. Several experiments on MRI datasets demonstrated the efficacy of our model in bidirectional domain adaptation without labelled data. Furthermore, research offers promising avenues for improving the diagnostic accuracy of healthcare. The statistical results confirm that our approach improves model performance and reduces domain-related variability, thus contributing to more precise and consistent medical image analysis.

</details>


### [116] [XRefine: Attention-Guided Keypoint Match Refinement](https://arxiv.org/abs/2601.12530)
*Jan Fabian Schmid,Annika Hagemann*

Main category: cs.CV

TL;DR: XRefine是一种与检测器无关的关键点细化方法，通过交叉注意力架构实现跨检测器的泛化，显著提升了匹配准确性。


<details>
  <summary>Details</summary>
Motivation: 当前关键点检测器产生的空间匹配不准确，且现有细化方法通常需要针对每个检测器重新训练。

Method: 提出了一种基于交叉注意力的架构，仅通过以匹配关键点为中心的图像块进行操作，实现了跨检测器的泛化。

Result: 在MegaDepth、KITTI和ScanNet上的实验表明，XRefine显著提高了几何估计的准确性，且保持了运行时效率。

Conclusion: XRefine是一种新颖的、与检测器无关的子像素关键点细化方法，能够在不依赖内部检测器表示的情况下预测细化后的关键点坐标，并在多个数据集中表现出优越的性能。

Abstract: Sparse keypoint matching is crucial for 3D vision tasks, yet current keypoint detectors often produce spatially inaccurate matches. Existing refinement methods mitigate this issue through alignment of matched keypoint locations, but they are typically detector-specific, requiring retraining for each keypoint detector. We introduce XRefine, a novel, detector-agnostic approach for sub-pixel keypoint refinement that operates solely on image patches centered at matched keypoints. Our cross-attention-based architecture learns to predict refined keypoint coordinates without relying on internal detector representations, enabling generalization across detectors. Furthermore, XRefine can be extended to handle multi-view feature tracks. Experiments on MegaDepth, KITTI, and ScanNet demonstrate that the approach consistently improves geometric estimation accuracy, achieving superior performance compared to existing refinement methods while maintaining runtime efficiency. Our code and trained models can be found at https://github.com/boschresearch/xrefine.

</details>


### [117] [BirdsEye-RU: A Dataset For Detecting Faces from Overhead Images](https://arxiv.org/abs/2601.12533)
*Md. Ahanaf Arif Khan,Ariful Islam,Sangeeta Biswas,Md. Iqbal Aziz Khan,Subrata Pramanik,Sanjoy Kumar Chakrabarty,Bimal Kumar Pramanik*

Main category: cs.CV

TL;DR: 为解决高空图像中人脸检测的挑战，研究团队创建并公开了BirdsEye-RU数据集，包含大量标注人脸的高空图像。


<details>
  <summary>Details</summary>
Motivation: 高空图像中的人脸检测因极端尺度变化和环境干扰而具有挑战性。

Method: 创建了包含2,978张图像和超过8,000个标注人脸的BirdsEye-RU数据集，涵盖无人机和高空智能手机拍摄的图像。

Result: 数据集公开可用，可通过指定链接访问。

Conclusion: BirdsEye-RU数据集为解决高空图像中的人脸检测问题提供了有价值的资源，并通过公开共享促进了该领域的研究。

Abstract: Detecting faces in overhead images remains a significant challenge due to extreme scale variations and environmental clutter. To address this, we created the BirdsEye-RU dataset, a comprehensive collection of 2,978 images containing over eight thousand annotated faces. This dataset is specifically designed to capture small and distant faces across diverse environments, containing both drone images and smartphone-captured images from high altitude. We present a detailed description of the BirdsEye-RU dataset in this paper. We made our dataset freely available to the public, and it can be accessed at https://www.kaggle.com/datasets/mdahanafarifkhan/birdseye-ru.

</details>


### [118] [Encoding Emotion Through Self-Supervised Eye Movement Reconstruction](https://arxiv.org/abs/2601.12534)
*Marcus Ma,Jordan Prescott,Emily Zhou,Tiantian Feng,Kleanthis Avramidis,Gabor Mihaly Toth,Shrikanth Narayanan*

Main category: cs.CV

TL;DR: 研究利用自我监督的眼动重建模型从低分辨率视频中预测情感表达，发现该方法有效且与情感处理性能正相关。


<details>
  <summary>Details</summary>
Motivation: 研究如何从自然、低分辨率视频中利用眼动预测情感表达的多模态标记，以克服高分辨率眼动追踪设备的局限性。

Method: 开发了一种新颖的注视检测模型，利用自我监督的眼动重建技术，有效利用未标记视频。使用该模型的编码器嵌入对两个与情感表达相关的下游任务进行微调。

Result: 新模型能够预测情感结果，并观察到预训练性能与情感处理性能之间的正相关关系。

Conclusion: 自我监督的眼动重建是编码眼动所携带情感信号的有效方法。

Abstract: The relationship between emotional expression and eye movement is well-documented, with literature establishing gaze patterns are reliable indicators of emotion. However, most studies utilize specialized, high-resolution eye-tracking equipment, limiting the potential reach of findings. We investigate how eye movement can be used to predict multimodal markers of emotional expression from naturalistic, low-resolution videos. We utilize a collection of video interviews from the USC Shoah Foundation's Visual History Archive with Holocaust survivors as they recount their experiences in the Auschwitz concentration camp. Inspired by pretraining methods on language models, we develop a novel gaze detection model that uses self-supervised eye movement reconstruction that can effectively leverage unlabeled video. We use this model's encoder embeddings to fine-tune models on two downstream tasks related to emotional expression. The first is aligning eye movement with directional emotion estimates from speech. The second task is using eye gaze as a predictor of three momentary manifestations of emotional behaviors: laughing, crying/sobbing, and sighing. We find our new model is predictive of emotion outcomes and observe a positive correlation between pretraining performance and emotion processing performance for both experiments. We conclude self-supervised eye movement reconstruction is an effective method for encoding the affective signal they carry.

</details>


### [119] [PISE: Physics-Anchored Semantically-Enhanced Deep Computational Ghost Imaging for Robust Low-Bandwidth Machine Perception](https://arxiv.org/abs/2601.12551)
*Tong Wu*

Main category: cs.CV

TL;DR: PISE框架通过物理信息深度鬼成像，提升低带宽边缘感知性能，分类准确性提高2.57%，方差降低9倍。


<details>
  <summary>Details</summary>
Motivation: 解决低带宽边缘感知中的分类准确性和方差问题。

Method: 采用物理信息深度鬼成像框架，结合伴随算子初始化和语义引导。

Result: 在5%采样率下，分类准确性提升2.57%，方差降低9倍。

Conclusion: PISE通过结合伴随算子初始化和语义引导，显著提升了低带宽边缘感知的分类准确性并降低了方差。

Abstract: We propose PISE, a physics-informed deep ghost imaging framework for low-bandwidth edge perception. By combining adjoint operator initialization with semantic guidance, PISE improves classification accuracy by 2.57% and reduces variance by 9x at 5% sampling.

</details>


### [120] [Camera Pose Revisited](https://arxiv.org/abs/2601.12567)
*Władysław Skarbek,Michał Salomonowicz,Michał Król*

Main category: cs.CV

TL;DR: PnP-ProCay78算法通过结合二次重建误差和Cayley参数化，简化了PnP问题的求解，实验显示其精度与SQPnP相当，结构更简单，适合教学。


<details>
  <summary>Details</summary>
Motivation: 解决相机标定和多传感器系统中相机位置和姿态的初始估计问题，特别是在平面透视-n-点问题中。

Method: 本文提出PnP-ProCay78算法，结合了重建误差的经典二次形式与Cayley旋转参数化和最小二乘优化。关键是通过对两个规范向量的重建误差分析，确定性地选择起始点，避免了昂贵的解空间搜索过程。

Result: 实验验证表明，PnP-ProCay78算法在RGB和低分辨率热相机集成系统中，投影精度与SQPnP相当，略高于IPPE，同时算法结构更简单。

Conclusion: 本文提出的PnP-ProCay78算法在保持算法结构简单的同时，达到了与最优SQPnP相当的投影精度，并略高于IPPE。该方法在Cayley空间中的优化轨迹分析为收敛过程提供了直观的见解，使其在教学上也具有吸引力。

Abstract: Estimating the position and orientation of a camera with respect to an observed scene is one of the central problems in computer vision, particularly in the context of camera calibration and multi-sensor systems. This paper addresses the planar Perspective--$n$--Point problem, with special emphasis on the initial estimation of the pose of a calibration object. As a solution, we propose the \texttt{PnP-ProCay78} algorithm, which combines the classical quadratic formulation of the reconstruction error with a Cayley parameterization of rotations and least-squares optimization. The key component of the method is a deterministic selection of starting points based on an analysis of the reconstruction error for two canonical vectors, allowing costly solution-space search procedures to be avoided. Experimental validation is performed using data acquired also from high-resolution RGB cameras and very low-resolution thermal cameras in an integrated RGB--IR setup. The results demonstrate that the proposed algorithm achieves practically the same projection accuracy as optimal \texttt{SQPnP} and slightly higher than \texttt{IPPE}, both prominent \texttt{PnP-OpenCV} procedures. However, \texttt{PnP-ProCay78} maintains a significantly simpler algorithmic structure. Moreover, the analysis of optimization trajectories in Cayley space provides an intuitive insight into the convergence process, making the method attractive also from a didactic perspective. Unlike existing PnP solvers, the proposed \texttt{PnP-ProCay78} algorithm combines projection error minimization with an analytically eliminated reconstruction-error surrogate for translation, yielding a hybrid cost formulation that is both geometrically transparent and computationally efficient.

</details>


### [121] [Linear Mechanisms for Spatiotemporal Reasoning in Vision Language Models](https://arxiv.org/abs/2601.12626)
*Raphi Kang,Hongqiao Chen,Georgia Gkioxari,Pietro Perona*

Main category: cs.CV

TL;DR: 研究发现VLMs通过线性绑定空间ID到文本激活进行时空推理，空间ID能调节模型信念并作为诊断工具。视频VLMs中也有类似的时间ID机制。


<details>
  <summary>Details</summary>
Motivation: 探索视觉语言模型中时空推理能力的底层机制，揭示其如何结合视觉/几何和文本表示进行推理，以提高模型的可解释性和设计更优的模型。

Method: 研究采用因果干预方法，实证分析了VLMs中空间ID的线性绑定机制及其在模型行为中的作用。通过严格的实验验证了空间ID在中间层对模型信念的系统性调节。

Result: 研究发现VLMs通过线性绑定空间ID到文本激活来编码对象位置，并通过语言标记进行推理。空间ID在中间层能系统性调节模型信念，并可作为诊断工具和学习信号。视频VLMs中也发现了类似的线性时间ID机制。

Conclusion: 本文通过研究发现，视觉语言模型（VLMs）通过线性绑定空间ID到文本激活来编码对象位置，并通过语言标记进行推理。这些空间ID不仅作为诊断工具揭示了现有VLMs的局限性，还为改进模型设计提供了学习信号。研究还扩展到了视频VLMs，发现了类似的线性时间ID机制。

Abstract: Spatio-temporal reasoning is a remarkable capability of Vision Language Models (VLMs), but the underlying mechanisms of such abilities remain largely opaque. We postulate that visual/geometrical and textual representations of spatial structure must be combined at some point in VLM computations. We search for such confluence, and ask whether the identified representation can causally explain aspects of input-output model behavior through a linear model. We show empirically that VLMs encode object locations by linearly binding \textit{spatial IDs} to textual activations, then perform reasoning via language tokens. Through rigorous causal interventions we demonstrate that these IDs, which are ubiquitous across the model, can systematically mediate model beliefs at intermediate VLM layers. Additionally, we find that spatial IDs serve as a diagnostic tool for identifying limitations in existing VLMs, and as a valuable learning signal. We extend our analysis to video VLMs and identify an analogous linear temporal ID mechanism. By characterizing our proposed spatiotemporal ID mechanism, we elucidate a previously underexplored internal reasoning process in VLMs, toward improved interpretability and the principled design of more aligned and capable models. We release our code for reproducibility: https://github.com/Raphoo/linear-mech-vlms.

</details>


### [122] [From Bands to Depth: Understanding Bathymetry Decisions on Sentinel-2](https://arxiv.org/abs/2601.12636)
*Satyaki Roy Chowdhury,Aswathnarayan Radhakrishnan,Hsiao Jou Hsu,Hari Subramoni,Joachim Moortgat*

Main category: cs.CV

TL;DR: Swin-BathyUNet模型通过光谱分析和注意力机制改进卫星测深，提出跨区域迁移的实用指南。


<details>
  <summary>Details</summary>
Motivation: 解决Sentinel-2卫星测深（SDB）在不同地点部署时的鲁棒性挑战，理解模型如何推断水深及其预测的可信度。

Method: 采用Swin-Transformer为基础的U-Net模型（Swin-BathyUNet），通过留一波段研究评估光谱重要性，并开发了适用于回归的基于消融的CAM方法（A-CAM-R）。

Result: 研究表明，注意力消融显示解码器的跨注意力机制能有效提升对光斑/泡沫的鲁棒性；跨区域推理揭示了深度依赖的性能退化。

Conclusion: 论文提出了使用Swin-BathyUNet模型进行卫星测深的实用指南，包括保持宽感受野、保护绿/蓝通道的辐射保真度、预过滤近岸高亮度高方差区域，以及结合深度感知校准进行跨区域迁移。

Abstract: Deploying Sentinel-2 satellite derived bathymetry (SDB) robustly across sites remains challenging. We analyze a Swin-Transformer based U-Net model (Swin-BathyUNet) to understand how it infers depth and when its predictions are trustworthy. A leave-one-band out study ranks spectral importance to the different bands consistent with shallow water optics. We adapt ablation-based CAM to regression (A-CAM-R) and validate the reliability via a performance retention test: keeping only the top-p% salient pixels while neutralizing the rest causes large, monotonic RMSE increase, indicating explanations localize on evidence the model relies on. Attention ablations show decoder conditioned cross attention on skips is an effective upgrade, improving robustness to glint/foam. Cross-region inference (train on one site, test on another) reveals depth-dependent degradation: MAE rises nearly linearly with depth, and bimodal depth distributions exacerbate mid/deep errors. Practical guidance follows: maintain wide receptive fields, preserve radiometric fidelity in green/blue channels, pre-filter bright high variance near shore, and pair light target site fine tuning with depth aware calibration to transfer across regions.

</details>


### [123] [Mixed Precision PointPillars for Efficient 3D Object Detection with TensorRT](https://arxiv.org/abs/2601.12638)
*Ninnart Fuengfusin,Keisuke Yoneda,Naoki Suganuma*

Main category: cs.CV

TL;DR: A mixed precision framework for PointPillars optimizes LIDAR 3D object detection by addressing quantization challenges, achieving real-time performance with reduced latency and size.


<details>
  <summary>Details</summary>
Motivation: To enable real-time LIDAR 3D object detection for autonomous vehicles while mitigating performance degradation from model quantization due to LIDAR's wide numerical distributions and outliers.

Method: The framework involves searching for sensitive layers with PTQ, assigning top-k layers as FP, and greedily searching combinations to produce mixed precision models. It also uses minimal calibration data to handle outliers.

Result: The method reduces latency and model size by up to 2.35 and 2.26 times respectively, with performance competitive to FP models.

Conclusion: The proposed mixed precision framework for PointPillars effectively addresses the challenges of LIDAR 3D object detection by balancing performance and real-time requirements through model quantization. It achieves competitive performance to FP models with reduced latency and model size.

Abstract: LIDAR 3D object detection is one of the important tasks for autonomous vehicles. Ensuring that this task operates in real-time is crucial. Toward this, model quantization can be used to accelerate the runtime. However, directly applying model quantization often leads to performance degradation due to LIDAR's wide numerical distributions and extreme outliers. To address the wide numerical distribution, we proposed a mixed precision framework designed for PointPillars. Our framework first searches for sensitive layers with post-training quantization (PTQ) by quantizing one layer at a time to 8-bit integer (INT8) and evaluating each model for average precision (AP). The top-k most sensitive layers are assigned as floating point (FP). Combinations of these layers are greedily searched to produce candidate mixed precision models, which are finalized with either PTQ or quantization-aware training (QAT). Furthermore, to handle outliers, we observe that using a very small number of calibration data reduces the likelihood of encountering outliers, thereby improving PTQ performance. Our methods provides mixed precision models without training in the PTQ pipeline, while our QAT pipeline achieves the performance competitive to FP models. With TensorRT deployment, our models offer less latency and sizes by up to 2.35 and 2.26 times, respectively.

</details>


### [124] [Generalizable Hyperparameter Optimization for Federated Learning on Non-IID Cancer Images](https://arxiv.org/abs/2601.12664)
*Elisa Gonçalves Ribeiro,Rodrigo Moreira,Larissa Ferreira Rodrigues Moreira,André Ricardo Backes*

Main category: cs.CV

TL;DR: 研究探讨了在非独立同分布联邦学习中超参数优化的可迁移性，提出了一种简单的跨数据集聚合方法，并在癌症分类任务中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习在癌症组织病理学训练中因隐私约束而面临的挑战，探索联邦学习在非独立同分布数据下的超参数优化问题。

Method: 采用集中式贝叶斯超参数优化方法，并将特定数据集的最优参数迁移到非独立同分布的联邦学习设置中。

Result: 提出的跨数据集聚合启发式方法在卵巢癌和结直肠癌的二元组织病理学任务中取得了竞争性的分类性能。

Conclusion: 本研究通过简单的跨数据集聚合启发式方法，结合学习率平均、优化器和批量大小的模态选择，实现了竞争性的分类性能，证明了在非独立同分布联邦学习场景中，超参数优化的可迁移性。

Abstract: Deep learning for cancer histopathology training conflicts with privacy constraints in clinical settings. Federated Learning (FL) mitigates this by keeping data local; however, its performance depends on hyperparameter choices under non-independent and identically distributed (non-IID) client datasets. This paper examined whether hyperparameters optimized on one cancer imaging dataset generalized across non-IID federated scenarios. We considered binary histopathology tasks for ovarian and colorectal cancers. We perform centralized Bayesian hyperparameter optimization and transfer dataset-specific optima to the non-IID FL setup. The main contribution of this study is the introduction of a simple cross-dataset aggregation heuristic by combining configurations by averaging the learning rates and considering the modal optimizers and batch sizes. This combined configuration achieves a competitive classification performance.

</details>


### [125] [Near-Light Color Photometric Stereo for mono-Chromaticity non-lambertian surface](https://arxiv.org/abs/2601.12666)
*Zonglin Li,Jieji Ren,Shuangfan Zhou,Heng Guo,Jinnuo Zhang,Jiang Zhou,Boxin Shi,Zhanyu Ma,Guoying Gu*

Main category: cs.CV

TL;DR: 提出一种基于神经隐式表示的单色性假设框架，解决了彩色光度立体视觉的固有不适定性，实现了单幅图像下的精确表面重建。


<details>
  <summary>Details</summary>
Motivation: 现有方法大多假设理想远距离照明和朗伯反射，忽略了实际近光条件和非朗伯表面，限制了彩色光度立体视觉的应用。

Method: 利用神经隐式表示建模深度和BRDF，并基于单色性假设（均匀色度和同质材料），设计了一种紧凑的光学触觉传感器进行验证。

Result: 在合成和真实数据集上的实验表明，该方法实现了准确且鲁棒的表面重建。

Conclusion: 该方法通过神经隐式表示和单色性假设，有效解决了彩色光度立体视觉的固有不适定性，实现了单幅图像下的精确表面重建。

Abstract: Color photometric stereo enables single-shot surface reconstruction, extending conventional photometric stereo that requires multiple images of a static scene under varying illumination to dynamic scenarios. However, most existing approaches assume ideal distant lighting and Lambertian reflectance, leaving more practical near-light conditions and non-Lambertian surfaces underexplored. To overcome this limitation, we propose a framework that leverages neural implicit representations for depth and BRDF modeling under the assumption of mono-chromaticity (uniform chromaticity and homogeneous material), which alleviates the inherent ill-posedness of color photometric stereo and allows for detailed surface recovery from just one image. Furthermore, we design a compact optical tactile sensor to validate our approach. Experiments on both synthetic and real-world datasets demonstrate that our method achieves accurate and robust surface reconstruction.

</details>


### [126] [Exploiting Test-Time Augmentation in Federated Learning for Brain Tumor MRI Classification](https://arxiv.org/abs/2601.12671)
*Thamara Leandra de Deus Melo,Rodrigo Moreira,Larissa Ferreira Rodrigues Moreira,André Ricardo Backes*

Main category: cs.CV

TL;DR: 研究显示，在联邦学习中，测试时增强（TTA）结合轻量预处理可显著提升脑肿瘤MRI分类效果。


<details>
  <summary>Details</summary>
Motivation: 高效脑肿瘤诊断对早期治疗至关重要，但由于病变变异性和图像复杂性，诊断具有挑战性。

Method: 评估了卷积神经网络（CNNs）在联邦学习（FL）环境中的表现，比较了在原始MRI图像与预处理（调整大小、灰度转换、归一化、滤波和直方图均衡化）后的图像上训练的模型。

Result: 单独预处理效果有限；与测试时增强（TTA）结合使用时，在联邦MRI分类中实现了稳定且统计学显著的改进（p<0.001）。

Conclusion: 在实践中，TTA应作为基于联邦学习的医学影像分析的默认推理策略；在计算预算允许的情况下，结合轻量级预处理可提供额外的可靠增益。

Abstract: Efficient brain tumor diagnosis is crucial for early treatment; however, it is challenging because of lesion variability and image complexity. We evaluated convolutional neural networks (CNNs) in a federated learning (FL) setting, comparing models trained on original versus preprocessed MRI images (resizing, grayscale conversion, normalization, filtering, and histogram equalization). Preprocessing alone yielded negligible gains; combined with test-time augmentation (TTA), it delivered consistent, statistically significant improvements in federated MRI classification (p<0.001). In practice, TTA should be the default inference strategy in FL-based medical imaging; when the computational budget permits, pairing TTA with light preprocessing provides additional reliable gains.

</details>


### [127] [VILTA: A VLM-in-the-Loop Adversary for Enhancing Driving Policy Robustness](https://arxiv.org/abs/2601.12672)
*Qimao Chen,Fang Li,Shaoqing Xu,Zhiyi Lai,Zixun Xie,Yuechen Luo,Shengyin Jiang,Hanbing Li,Long Chen,Bing Wang,Yi Zhang,Zhi-Xin Yang*

Main category: cs.CV

TL;DR: VILTA框架通过VLM直接编辑代理轨迹，生成多样化挑战性场景，显著提升AD策略的安全性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在生成多样化和新颖的挑战性场景方面存在局限，无法充分利用VLM的生成潜力，因此需要一种更直接的集成方法。

Method: VILTA是一个新颖的框架，将VLM集成到AD代理的闭环训练中，通过理解和动态编辑驾驶环境中的代理轨迹来生成挑战性场景。

Result: VILTA框架生成的多样化挑战性场景显著提升了AD策略在长尾事件中的表现。

Conclusion: VILTA框架通过直接编辑周围代理的未来轨迹，充分利用VLM的强大泛化能力，显著提升了AD策略的安全性和鲁棒性，特别是在处理长尾事件方面。

Abstract: The safe deployment of autonomous driving (AD) systems is fundamentally hindered by the long-tail problem, where rare yet critical driving scenarios are severely underrepresented in real-world data. Existing solutions including safety-critical scenario generation and closed-loop learning often rely on rule-based heuristics, resampling methods and generative models learned from offline datasets, limiting their ability to produce diverse and novel challenges. While recent works leverage Vision Language Models (VLMs) to produce scene descriptions that guide a separate, downstream model in generating hazardous trajectories for agents, such two-stage framework constrains the generative potential of VLMs, as the diversity of the final trajectories is ultimately limited by the generalization ceiling of the downstream algorithm. To overcome these limitations, we introduce VILTA (VLM-In-the-Loop Trajectory Adversary), a novel framework that integrates a VLM into the closed-loop training of AD agents. Unlike prior works, VILTA actively participates in the training loop by comprehending the dynamic driving environment and strategically generating challenging scenarios through direct, fine-grained editing of surrounding agents' future trajectories. This direct-editing approach fully leverages the VLM's powerful generalization capabilities to create a diverse curriculum of plausible yet challenging scenarios that extend beyond the scope of traditional methods. We demonstrate that our approach substantially enhances the safety and robustness of the resulting AD policy, particularly in its ability to navigate critical long-tail events.

</details>


### [128] [Fusion-Restoration Image Processing Algorithm to Improve the High-Temperature Deformation Measurement](https://arxiv.org/abs/2601.12682)
*Banglei Guan,Dongcai Tan,Jing Tao,Ang Su,Yang Shang,Qifeng Yu*

Main category: cs.CV

TL;DR: 提出融合-恢复图像处理方法，抑制高温变形测量中的热辐射和热霾干扰，显著提升图像质量并减少测量误差。


<details>
  <summary>Details</summary>
Motivation: 高温结构变形测量中，热辐射导致的图像退化和热霾引入的随机误差限制了测量的准确性和有效性，需通过融合-恢复图像处理方法抑制这些干扰。

Method: 针对热辐射导致的图像退化，采用基于图像分层表示的方法，将图像分解为正负通道并行处理，并通过多曝光图像融合优化质量；针对热霾引入的高频随机误差，采用FSIM作为目标函数指导模型参数迭代优化，并结合灰度平均算法均衡异常灰度值。

Result: 多曝光图像融合算法将欠曝光图像的有效计算区域从26%提升至50%，过曝光图像从32%提升至40%；图像恢复结合灰度平均算法使静态热变形测量误差中ε_xx降低85.3%，ε_yy和γ_xy分别降低36.0%和36.4%。

Conclusion: 本文提出的图像处理方法能有效抑制高温变形测量中热辐射和热霾的干扰，实验证明该方法可提升图像质量、减少变形测量误差，具有在热变形测量中的应用潜力。

Abstract: In the deformation measurement of high-temperature structures, image degradation caused by thermal radiation and random errors introduced by heat haze restrict the accuracy and effectiveness of deformation measurement. To suppress thermal radiation and heat haze using fusion-restoration image processing methods, thereby improving the accuracy and effectiveness of DIC in the measurement of high-temperature deformation. For image degradation caused by thermal radiation, based on the image layered representation, the image is decomposed into positive and negative channels for parallel processing, and then optimized for quality by multi-exposure image fusion. To counteract the high-frequency, random errors introduced by heat haze, we adopt the FSIM as the objective function to guide the iterative optimization of model parameters, and the grayscale average algorithm is applied to equalize anomalous gray values, thereby reducing measurement error. The proposed multi-exposure image fusion algorithm effectively suppresses image degradation caused by complex illumination conditions, boosting the effective computation area from 26% to 50% for under-exposed images and from 32% to 40% for over-exposed images without degrading measurement accuracy in the experiment. Meanwhile, the image restoration combined with the grayscale average algorithm reduces static thermal deformation measurement errors. The error in ε_xx is reduced by 85.3%, while the errors in ε_yy and γ_xy are reduced by 36.0% and 36.4%, respectively. We present image processing methods to suppress the interference of thermal radiation and heat haze in high-temperature deformation measurement using DIC. The experimental results verify that the proposed method can effectively improve image quality, reduce deformation measurement errors, and has potential application value in thermal deformation measurement.

</details>


### [129] [GaussianTrimmer: Online Trimming Boundaries for 3DGS Segmentation](https://arxiv.org/abs/2601.12683)
*Liwei Liao,Ronggang Wang*

Main category: cs.CV

TL;DR: 提出GaussianTrimmer，一种在线边界修剪方法，通过虚拟相机和2D分割结果修剪高斯基元，改善现有3D高斯分割的边界锯齿问题。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯分割方法基于高斯基元进行分割，但由于3D高斯的尺度变化范围大，大尺寸高斯常跨越前景和背景，导致分割对象的边界锯齿。

Method: 方法包括两个核心步骤：1.生成均匀且覆盖良好的虚拟相机；2.基于虚拟相机上的2D分割结果在原始级别修剪高斯。

Result: 大量定量和定性实验表明，该方法能作为即插即用方法提升现有3D高斯分割方法的分割质量。

Conclusion: GaussianTrimmer作为一种即插即用的后处理方法，能够有效改善现有3D高斯分割方法的边界锯齿问题，提升分割质量。

Abstract: With the widespread application of 3D Gaussians in 3D scene representation, 3D scene segmentation methods based on 3D Gaussians have also gradually emerged. However, existing 3D Gaussian segmentation methods basically segment on the basis of Gaussian primitives. Due to the large variation range of the scale of 3D Gaussians, large-sized Gaussians that often span the foreground and background lead to jagged boundaries of segmented objects. To this end, we propose an online boundary trimming method, GaussianTrimmer, which is an efficient and plug-and-play post-processing method capable of trimming coarse boundaries for existing 3D Gaussian segmentation methods. Our method consists of two core steps: 1. Generating uniformly and well-covered virtual cameras; 2. Trimming Gaussian at the primitive level based on 2D segmentation results on virtual cameras. Extensive quantitative and qualitative experiments demonstrate that our method can improve the segmentation quality of existing 3D Gaussian segmentation methods as a plug-and-play method.

</details>


### [130] [Fusing in 3D: Free-Viewpoint Fusion Rendering with a 3D Infrared-Visible Scene Representation](https://arxiv.org/abs/2601.12697)
*Chao Yang,Deshui Miao,Chao Tian,Guoqing Zhu,Yameng Gu,Zhenyu He*

Main category: cs.CV

TL;DR: IVGF框架通过CMA模块和融合损失，解决了红外-可见光图像融合中的信息丢失问题，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有2D融合方法局限于固定视角，缺乏对复杂场景的全面理解，导致关键信息丢失。

Method: 提出了一个新颖的红外-可见光高斯融合（IVGF）框架，包括跨模态调整（CMA）模块和融合损失函数，用于优化高斯不透明度并保留双模态特征。

Result: 定性和定量实验验证了IVGF框架的有效性，能够保留双模态的关键特征并生成高质量的融合图像。

Conclusion: 提出的IVGF框架通过跨模态调整模块和融合损失函数，有效解决了红外-可见光图像融合中的信息丢失问题，实验证明了其优越性。

Abstract: Infrared-visible image fusion aims to integrate infrared and visible information into a single fused image. Existing 2D fusion methods focus on fusing images from fixed camera viewpoints, neglecting a comprehensive understanding of complex scenarios, which results in the loss of critical information about the scene. To address this limitation, we propose a novel Infrared-Visible Gaussian Fusion (IVGF) framework, which reconstructs scene geometry from multimodal 2D inputs and enables direct rendering of fused images. Specifically, we propose a cross-modal adjustment (CMA) module that modulates the opacity of Gaussians to solve the problem of cross-modal conflicts. Moreover, to preserve the distinctive features from both modalities, we introduce a fusion loss that guides the optimization of CMA, thus ensuring that the fused image retains the critical characteristics of each modality. Comprehensive qualitative and quantitative experiments demonstrate the effectiveness of the proposed method.

</details>


### [131] [P2L-CA: An Effective Parameter Tuning Framework for Rehearsal-Free Multi-Label Class-Incremental Learning](https://arxiv.org/abs/2601.12714)
*Songlin Dong,Jiangyang Li,Chenhao Ding,Zhiheng Ma,Haoyu Luo,Yuhang He,Yihong Gong*

Main category: cs.CV

TL;DR: P2L-CA是一个参数高效的多标签类增量学习框架，通过提示模块和适配器模块显著提升性能，同时降低计算和存储成本。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多标签类增量学习中面临高计算成本、存储开销大以及特征混淆和领域差异问题，P2L-CA旨在克服这些限制。

Method: P2L-CA框架结合了Prompt-to-Label模块和Continuous Adapter模块，前者利用类特定提示解耦多标签表示，后者通过轻量级适配器缓解预训练模型与下游任务之间的领域差异。

Result: 在MS-COCO和PASCAL VOC数据集上的实验表明，P2L-CA在性能和泛化能力上均优于现有方法，且所需可训练参数极少，无需内存缓冲区。

Conclusion: P2L-CA框架在多标签类增量学习任务中表现出色，显著优于现有方法，同时减少了计算和存储开销。

Abstract: Multi-label Class-Incremental Learning aims to continuously recognize novel categories in complex scenes where multiple objects co-occur. However, existing approaches often incur high computational costs due to full-parameter fine-tuning and substantial storage overhead from memory buffers, or they struggle to address feature confusion and domain discrepancies adequately. To overcome these limitations, we introduce P2L-CA, a parameter-efficient framework that integrates a Prompt-to-Label module with a Continuous Adapter module. The P2L module leverages class-specific prompts to disentangle multi-label representations while incorporating linguistic priors to enforce stable semantic-visual alignment. Meanwhile, the CA module employs lightweight adapters to mitigate domain gaps between pre-trained models and downstream tasks, thereby enhancing model plasticity. Extensive experiments across standard and challenging MLCIL settings on MS-COCO and PASCAL VOC show that P2L-CA not only achieves substantial improvements over state-of-the-art methods but also demonstrates strong generalization in CIL scenarios, all while requiring minimal trainable parameters and eliminating the need for memory buffers.

</details>


### [132] [RSOD: Reliability-Guided Sonar Image Object Detection with Extremely Limited Labels](https://arxiv.org/abs/2601.12715)
*Chengzhou Li,Ping Guo,Guanchen Meng,Qi Jia,Jinyuan Liu,Zhu Liu,Xiaokang Liu,Yu Liu,Zhongxuan Luo,Xin Fan*

Main category: cs.CV

TL;DR: RSOD框架通过教师-学生模型和伪标签策略，在极有限标注下实现高效声纳图像检测，性能媲美全标注基线。


<details>
  <summary>Details</summary>
Motivation: 声纳图像纹理细节少、噪声多，非专家难以提供精确标注，亟需设计适用于极有限标注数据的检测方法。

Method: 提出RSOD框架，包括可靠性评分计算、对象混合伪标签方法和可靠性引导的自适应约束优化。

Result: 在UATD数据集上，仅用5%标注数据即可达到与全标注基线相当的效果，并收集了新数据集以推动声纳研究。

Conclusion: RSOD框架通过教师-学生模型和伪标签策略，有效解决了声纳图像标注数据有限的问题，在仅使用5%标注数据的情况下，性能媲美全标注基线。

Abstract: Object detection in sonar images is a key technology in underwater detection systems. Compared to natural images, sonar images contain fewer texture details and are more susceptible to noise, making it difficult for non-experts to distinguish subtle differences between classes. This leads to their inability to provide precise annotation data for sonar images. Therefore, designing effective object detection methods for sonar images with extremely limited labels is particularly important. To address this, we propose a teacher-student framework called RSOD, which aims to fully learn the characteristics of sonar images and develop a pseudo-label strategy suitable for these images to mitigate the impact of limited labels. First, RSOD calculates a reliability score by assessing the consistency of the teacher's predictions across different views. To leverage this score, we introduce an object mixed pseudo-label method to tackle the shortage of labeled data in sonar images. Finally, we optimize the performance of the student by implementing a reliability-guided adaptive constraint. By taking full advantage of unlabeled data, the student can perform well even in situations with extremely limited labels. Notably, on the UATD dataset, our method, using only 5% of labeled data, achieves results that can compete against those of our baseline algorithm trained on 100% labeled data. We also collected a new dataset to provide more valuable data for research in the field of sonar.

</details>


### [133] [S2DiT: Sandwich Diffusion Transformer for Mobile Streaming Video Generation](https://arxiv.org/abs/2601.12719)
*Lin Zhao,Yushu Wu,Aleksei Lebedev,Dishani Lahiri,Meng Dong,Arpit Sahni,Michael Vasilkovsky,Hao Chen,Ju Hu,Aliaksandr Siarohin,Sergey Tulyakov,Yanzhi Wang,Anil Kag,Yanyu Li*

Main category: cs.CV

TL;DR: S2DiT是一种高效的流式视频生成模型，结合了新型注意力机制和蒸馏技术，在移动设备上实现了高质量实时生成。


<details>
  <summary>Details</summary>
Motivation: 解决Diffusion Transformers (DiTs)在视频生成中计算成本高、难以实时或设备端生成的问题。

Method: 采用LinConv Hybrid Attention (LCHA)和Stride Self-Attention (SSA)的高效注意力机制，并通过预算感知的动态编程搜索优化三明治设计。

Result: S2DiT在iPhone上实现了超过10 FPS的流式视频生成，质量与最先进的服务器视频模型相当。

Conclusion: S2DiT通过创新的注意力机制和蒸馏框架，实现了在移动硬件上高效、高质量的流式视频生成，性能与服务器视频模型相当。

Abstract: Diffusion Transformers (DiTs) have recently improved video generation quality. However, their heavy computational cost makes real-time or on-device generation infeasible. In this work, we introduce S2DiT, a Streaming Sandwich Diffusion Transformer designed for efficient, high-fidelity, and streaming video generation on mobile hardware. S2DiT generates more tokens but maintains efficiency with novel efficient attentions: a mixture of LinConv Hybrid Attention (LCHA) and Stride Self-Attention (SSA). Based on this, we uncover the sandwich design via a budget-aware dynamic programming search, achieving superior quality and efficiency. We further propose a 2-in-1 distillation framework that transfers the capacity of large teacher models (e.g., Wan 2.2-14B) to the compact few-step sandwich model. Together, S2DiT achieves quality on par with state-of-the-art server video models, while streaming at over 10 FPS on an iPhone.

</details>


### [134] [KaoLRM: Repurposing Pre-trained Large Reconstruction Models for Parametric 3D Face Reconstruction](https://arxiv.org/abs/2601.12736)
*Qingtian Zhu,Xu Cao,Zhixiang Wang,Yinqiang Zheng,Takafumi Taketomi*

Main category: cs.CV

TL;DR: KaoLRM利用LRM的3D先验和FLAME-based 2D高斯泼溅技术，提升了单视角3D面部重建的准确性和视角一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的3DMM回归器在不同视角下表现不一致，KaoLRM旨在利用LRM的丰富先验知识提升重建的鲁棒性和准确性。

Method: KaoLRM将LRM预训练的三平面特征投影到FLAME参数空间以恢复几何形状，并通过与FLAME网格紧密耦合的2D高斯基元建模外观。

Result: 实验表明，KaoLRM在受控和野外基准测试中均实现了优越的重建精度和跨视角一致性。

Conclusion: KaoLRM通过利用LRM的预训练3D先验并结合FLAME-based 2D高斯泼溅技术，显著提升了单视角图像参数化3D面部重建的准确性和跨视角一致性。

Abstract: We propose KaoLRM to re-target the learned prior of the Large Reconstruction Model (LRM) for parametric 3D face reconstruction from single-view images. Parametric 3D Morphable Models (3DMMs) have been widely used for facial reconstruction due to their compact and interpretable parameterization, yet existing 3DMM regressors often exhibit poor consistency across varying viewpoints. To address this, we harness the pre-trained 3D prior of LRM and incorporate FLAME-based 2D Gaussian Splatting into LRM's rendering pipeline. Specifically, KaoLRM projects LRM's pre-trained triplane features into the FLAME parameter space to recover geometry, and models appearance via 2D Gaussian primitives that are tightly coupled to the FLAME mesh. The rich prior enables the FLAME regressor to be aware of the 3D structure, leading to accurate and robust reconstructions under self-occlusions and diverse viewpoints. Experiments on both controlled and in-the-wild benchmarks demonstrate that KaoLRM achieves superior reconstruction accuracy and cross-view consistency, while existing methods remain sensitive to viewpoint variations. The code is released at https://github.com/CyberAgentAILab/KaoLRM.

</details>


### [135] [SSPFormer: Self-Supervised Pretrained Transformer for MRI Images](https://arxiv.org/abs/2601.12747)
*Jingkai Li,Xiaoze Tian,Yuhang Shen,Jia Wang,Dianjie Lu,Guijuan Zhang,Zhuoran Zheng*

Main category: cs.CV

TL;DR: SSPFormer是一种针对MRI的自监督预训练Transformer，通过逆频率投影掩码和噪声增强策略，显著提升了医学图像处理任务的性能。


<details>
  <summary>Details</summary>
Motivation: 预训练Transformer在自然图像处理中表现优异，但直接迁移到MRI图像面临医学解剖结构特异性和数据隐私与稀缺性的挑战。

Method: 提出了自监督预训练Transformer（SSPFormer），结合逆频率投影掩码和频率加权FFT噪声增强策略，以学习领域不变和抗伪影的特征。

Result: 在分割、超分辨率和去噪任务中，SSPFormer实现了最先进的性能。

Conclusion: SSPFormer通过自监督预训练和特定领域策略（如逆频率投影掩码和频率加权FFT噪声增强），在MRI图像处理任务中实现了最先进的性能，验证了其捕获细粒度MRI图像保真度和适应临床需求的能力。

Abstract: The pre-trained transformer demonstrates remarkable generalization ability in natural image processing. However, directly transferring it to magnetic resonance images faces two key challenges: the inability to adapt to the specificity of medical anatomical structures and the limitations brought about by the privacy and scarcity of medical data. To address these issues, this paper proposes a Self-Supervised Pretrained Transformer (SSPFormer) for MRI images, which effectively learns domain-specific feature representations of medical images by leveraging unlabeled raw imaging data. To tackle the domain gap and data scarcity, we introduce inverse frequency projection masking, which prioritizes the reconstruction of high-frequency anatomical regions to enforce structure-aware representation learning. Simultaneously, to enhance robustness against real-world MRI artifacts, we employ frequency-weighted FFT noise enhancement that injects physiologically realistic noise into the Fourier domain. Together, these strategies enable the model to learn domain-invariant and artifact-robust features directly from raw scans. Through extensive experiments on segmentation, super-resolution, and denoising tasks, the proposed SSPFormer achieves state-of-the-art performance, fully verifying its ability to capture fine-grained MRI image fidelity and adapt to clinical application requirements.

</details>


### [136] [Moaw: Unleashing Motion Awareness for Video Diffusion Models](https://arxiv.org/abs/2601.12761)
*Tianqi Zhang,Ziyi Wang,Wenzhao Zheng,Weiliang Chen,Yuanhui Huang,Zhengyang Huang,Jie Zhou,Jiwen Lu*

Main category: cs.CV

TL;DR: Moaw框架利用视频扩散模型的运动感知能力，通过训练和特征注入实现零样本运动转移，为视频学习提供新范式。


<details>
  <summary>Details</summary>
Motivation: 基于视频扩散模型在零样本设置下能够捕捉跨帧共享特征的能力，本研究旨在探讨监督训练是否能更充分地利用视频扩散模型的跟踪能力。

Method: 我们提出了Moaw框架，训练一个扩散模型用于运动感知，并将其模态从图像到视频生成转变为视频到密集跟踪。然后构建一个运动标记数据集，识别编码最强运动信息的特征，并将这些特征注入结构相同的视频生成模型中。

Result: Moaw框架通过零样本方式自然适应运动特征，实现了无需额外适配器的运动转移。

Conclusion: 本研究提出了一种新范式，通过Moaw框架将生成建模与运动理解相结合，为更统一和可控的视频学习框架铺平了道路。

Abstract: Video diffusion models, trained on large-scale datasets, naturally capture correspondences of shared features across frames. Recent works have exploited this property for tasks such as optical flow prediction and tracking in a zero-shot setting. Motivated by these findings, we investigate whether supervised training can more fully harness the tracking capability of video diffusion models. To this end, we propose Moaw, a framework that unleashes motion awareness for video diffusion models and leverages it to facilitate motion transfer. Specifically, we train a diffusion model for motion perception, shifting its modality from image-to-video generation to video-to-dense-tracking. We then construct a motion-labeled dataset to identify features that encode the strongest motion information, and inject them into a structurally identical video generation model. Owing to the homogeneity between the two networks, these features can be naturally adapted in a zero-shot manner, enabling motion transfer without additional adapters. Our work provides a new paradigm for bridging generative modeling and motion understanding, paving the way for more unified and controllable video learning frameworks.

</details>


### [137] [Towards Unbiased Source-Free Object Detection via Vision Foundation Models](https://arxiv.org/abs/2601.12765)
*Zhi Cai,Yingjie Gao,Yanan Zhang,Xinzhu Ma,Di Huang*

Main category: cs.CV

TL;DR: DSOD通过VFM辅助和特征正则化，解决了SFOD的源偏差问题，显著提升跨域检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有SFOD方法存在源偏差问题，导致模型泛化能力差和自训练中的误差累积。

Method: 提出了Unified Feature Injection (UFI)模块和Semantic-aware Feature Regularization (SAFR)方法，以及VFM-free的DSOD-distill变体。

Result: 在多个基准测试中表现优异，如Normal-to-Foggy天气适应达到48.1% AP。

Conclusion: DSOD通过VFM辅助的框架有效解决了SFOD中的源偏差问题，显著提升了跨域任务的性能。

Abstract: Source-Free Object Detection (SFOD) has garnered much attention in recent years by eliminating the need of source-domain data in cross-domain tasks, but existing SFOD methods suffer from the Source Bias problem, i.e. the adapted model remains skewed towards the source domain, leading to poor generalization and error accumulation during self-training. To overcome this challenge, we propose Debiased Source-free Object Detection (DSOD), a novel VFM-assisted SFOD framework that can effectively mitigate source bias with the help of powerful VFMs. Specifically, we propose Unified Feature Injection (UFI) module that integrates VFM features into the CNN backbone through Simple-Scale Extension (SSE) and Domain-aware Adaptive Weighting (DAAW). Then, we propose Semantic-aware Feature Regularization (SAFR) that constrains feature learning to prevent overfitting to source domain characteristics. Furthermore, we propose a VFM-free variant, termed DSOD-distill for computation-restricted scenarios through a novel Dual-Teacher distillation scheme. Extensive experiments on multiple benchmarks demonstrate that DSOD outperforms state-of-the-art SFOD methods, achieving 48.1% AP on Normal-to-Foggy weather adaptation, 39.3% AP on Cross-scene adaptation, and 61.4% AP on Synthetic-to-Real adaptation.

</details>


### [138] [Spatial-VLN: Zero-Shot Vision-and-Language Navigation With Explicit Spatial Perception and Exploration](https://arxiv.org/abs/2601.12766)
*Lu Yue,Yue Fan,Shiwei Lian,Yu Zhao,Jiaxin Yu,Liang Xie,Feitian Zhang*

Main category: cs.CV

TL;DR: Spatial-VLN通过感知增强和多专家推理机制，解决了零样本VLN在复杂环境中的空间感知瓶颈，实现了高性能和真实世界适用性。


<details>
  <summary>Details</summary>
Motivation: 现有基于大型语言模型（LLM）的零样本VLN代理在空间感知上存在不足，尤其在门交互、多房间导航和模糊指令执行等场景中失败率高。

Method: 框架包含空间感知增强（SPE）模块和多专家推理（EMR）模块，前者通过全景过滤和专家系统提升空间感知，后者利用并行LLM专家处理语义和空间转换，并通过主动探索解决歧义。

Result: 在VLN-CE基准测试中达到最先进性能，并通过真实世界评估验证了其泛化性和鲁棒性。

Conclusion: Spatial-VLN框架在复杂连续环境中通过感知增强和多专家推理机制，显著提升了零样本视觉与语言导航（VLN）的性能，并在真实环境中验证了其泛化能力和鲁棒性。

Abstract: Zero-shot Vision-and-Language Navigation (VLN) agents leveraging Large Language Models (LLMs) excel in generalization but suffer from insufficient spatial perception. Focusing on complex continuous environments, we categorize key perceptual bottlenecks into three spatial challenges: door interaction,multi-room navigation, and ambiguous instruction execution, where existing methods consistently suffer high failure rates. We present Spatial-VLN, a perception-guided exploration framework designed to overcome these challenges. The framework consists of two main modules. The Spatial Perception Enhancement (SPE) module integrates panoramic filtering with specialized door and region experts to produce spatially coherent, cross-view consistent perceptual representations. Building on this foundation, our Explored Multi-expert Reasoning (EMR) module uses parallel LLM experts to address waypoint-level semantics and region-level spatial transitions. When discrepancies arise between expert predictions, a query-and-explore mechanism is activated, prompting the agent to actively probe critical areas and resolve perceptual ambiguities. Experiments on VLN-CE demonstrate that Spatial VLN achieves state-of-the-art performance using only low-cost LLMs. Furthermore, to validate real-world applicability, we introduce a value-based waypoint sampling strategy that effectively bridges the Sim2Real gap. Extensive real-world evaluations confirm that our framework delivers superior generalization and robustness in complex environments. Our codes and videos are available at https://yueluhhxx.github.io/Spatial-VLN-web/.

</details>


### [139] [Delving Deeper: Hierarchical Visual Perception for Robust Video-Text Retrieval](https://arxiv.org/abs/2601.12768)
*Zequn Xie,Boyun Zhang,Yuxiao Lin,Tao Jin*

Main category: cs.CV

TL;DR: HVP-Net通过分层提取视频特征提升文本检索精度，在多个基准测试中达到最优。


<details>
  <summary>Details</summary>
Motivation: 当前基于预训练模型（如CLIP）的视频文本检索方法受限于视频的固有冗余性和对粗粒度最终层特征的依赖，导致匹配精度受限。

Method: 提出HVP-Net（分层视觉感知网络），通过从视觉编码器的多个中间层提取和精炼特征，挖掘更丰富的视频语义信息。

Result: HVP-Net在MSRVTT、DiDeMo和ActivityNet等挑战性基准测试中取得了新的最先进性能。

Conclusion: HVP-Net通过利用分层视觉特征显著提升了视频文本检索的性能，验证了分层特征在视频文本检索中的有效性。

Abstract: Video-text retrieval (VTR) aims to locate relevant videos using natural language queries. Current methods, often based on pre-trained models like CLIP, are hindered by video's inherent redundancy and their reliance on coarse, final-layer features, limiting matching accuracy. To address this, we introduce the HVP-Net (Hierarchical Visual Perception Network), a framework that mines richer video semantics by extracting and refining features from multiple intermediate layers of a vision encoder. Our approach progressively distills salient visual concepts from raw patch-tokens at different semantic levels, mitigating redundancy while preserving crucial details for alignment. This results in a more robust video representation, leading to new state-of-the-art performance on challenging benchmarks including MSRVTT, DiDeMo, and ActivityNet. Our work validates the effectiveness of exploiting hierarchical features for advancing video-text retrieval. Our codes are available at https://github.com/boyun-zhang/HVP-Net.

</details>


### [140] [Generalizable and Animatable 3D Full-Head Gaussian Avatar from a Single Image](https://arxiv.org/abs/2601.12770)
*Shuling Zhao,Dan Xu*

Main category: cs.CV

TL;DR: 提出新框架，通过3D GAN先验和UV空间对称性，实现单图像实时构建高质量3D可动画头部头像。


<details>
  <summary>Details</summary>
Motivation: 解决单图像构建3D可动画头部头像的挑战，特别是在大视角变化下现有方法难以保持真实感的问题。

Method: 提出了一种基于高斯基元嵌入参数化面部模型UV空间的框架，利用预训练的3D GAN进行全局特征提取和多视角监督，并通过UV空间的对称性融合局部细粒度图像特征。

Result: 实验证明该方法能够实现高质量的全头部3D建模和实时动画，提升了3D头像的真实感。

Conclusion: 该方法通过结合3D生成对抗网络的先验知识和UV空间的对称性，实现了高质量的全头部3D建模和实时动画，显著提升了3D头像的真实感。

Abstract: Building 3D animatable head avatars from a single image is an important yet challenging problem. Existing methods generally collapse under large camera pose variations, compromising the realism of 3D avatars. In this work, we propose a new framework to tackle the novel setting of one-shot 3D full-head animatable avatar reconstruction in a single feed-forward pass, enabling real-time animation and simultaneous 360$^\circ$ rendering views. To facilitate efficient animation control, we model 3D head avatars with Gaussian primitives embedded on the surface of a parametric face model within the UV space. To obtain knowledge of full-head geometry and textures, we leverage rich 3D full-head priors within a pretrained 3D generative adversarial network (GAN) for global full-head feature extraction and multi-view supervision. To increase the fidelity of the 3D reconstruction of the input image, we take advantage of the symmetric nature of the UV space and human faces to fuse local fine-grained input image features with the global full-head textures. Extensive experiments demonstrate the effectiveness of our method, achieving high-quality 3D full-head modeling as well as real-time animation, thereby improving the realism of 3D talking avatars.

</details>


### [141] [Open Vocabulary Panoptic Segmentation With Retrieval Augmentation](https://arxiv.org/abs/2601.12779)
*Nafis Sadeq,Qingfeng Liu,Mostafa El-Khamy*

Main category: cs.CV

TL;DR: RetCLIP结合检索和CLIP方法，提升开放词汇全景分割在未见类别上的性能，显著优于基线。


<details>
  <summary>Details</summary>
Motivation: 解决传统全景分割系统在未见类别上泛化能力不足的问题。

Method: 构建了一个掩码片段特征数据库，并在推理时使用输入图像的掩码片段特征作为查询键，从数据库中检索相似特征和关联类别标签。分类分数基于查询特征与检索特征的相似度，并与CLIP分数结合生成最终输出。

Result: 在COCO上训练后，在ADE20k数据集上实现了30.9 PQ、19.3 mAP、44.0 mIoU，相比基线分别提升了+4.5 PQ、+2.5 mAP、+10.0 mIoU。

Conclusion: RetCLIP通过结合检索增强和CLIP的方法，显著提升了开放词汇全景分割在未见类别上的性能。

Abstract: Given an input image and set of class names, panoptic segmentation aims to label each pixel in an image with class labels and instance labels. In comparison, Open Vocabulary Panoptic Segmentation aims to facilitate the segmentation of arbitrary classes according to user input. The challenge is that a panoptic segmentation system trained on a particular dataset typically does not generalize well to unseen classes beyond the training data. In this work, we propose RetCLIP, a retrieval-augmented panoptic segmentation method that improves the performance of unseen classes. In particular, we construct a masked segment feature database using paired image-text data. At inference time, we use masked segment features from the input image as query keys to retrieve similar features and associated class labels from the database. Classification scores for the masked segment are assigned based on the similarity between query features and retrieved features. The retrieval-based classification scores are combined with CLIP-based scores to produce the final output. We incorporate our solution with a previous SOTA method (FC-CLIP). When trained on COCO, the proposed method demonstrates 30.9 PQ, 19.3 mAP, 44.0 mIoU on the ADE20k dataset, achieving +4.5 PQ, +2.5 mAP, +10.0 mIoU absolute improvement over the baseline.

</details>


### [142] [SKANet: A Cognitive Dual-Stream Framework with Adaptive Modality Fusion for Robust Compound GNSS Interference Classification](https://arxiv.org/abs/2601.12791)
*Zhihan Zeng,Yang Zhao,Kaihe Wang,Dusit Niyato,Hongyuan Shu,Junchu Zhao,Yanjun Huang,Yue Xiu,Zhongpei Zhang,Ning Wei*

Main category: cs.CV

TL;DR: SKANet通过动态感受野和特征重校准，显著提升GNSS复合干扰分类性能，准确率达96.99%。


<details>
  <summary>Details</summary>
Motivation: 复杂电磁环境下，GNSS面临复合干扰的威胁，现有单域方法因特征提取尺度冲突导致性能下降，需开发能同时捕捉瞬态和全局特征的动态自适应方法。

Method: 提出了一种基于双流架构的认知深度学习框架SKANet，整合了时频图像和功率谱密度，采用多分支选择性核模块和非对称卷积块动态调整感受野，并结合SE机制自适应重校准异构特征。

Result: 在40.5万样本数据集上，SKANet总体准确率达96.99%，尤其在低JNR环境下表现出优越的鲁棒性。

Conclusion: SKANet通过动态调整感受野和自适应特征重校准，显著提升了复合干扰分类的准确性和鲁棒性，尤其在低JNR环境下表现优异。

Abstract: As the electromagnetic environment becomes increasingly complex, Global Navigation Satellite Systems (GNSS) face growing threats from sophisticated jamming interference. Although Deep Learning (DL) effectively identifies basic interference, classifying compound interference remains difficult due to the superposition of diverse jamming sources. Existing single-domain approaches often suffer from performance degradation because transient burst signals and continuous global signals require conflicting feature extraction scales. We propose the Selective Kernel and Asymmetric convolution Network(SKANet), a cognitive deep learning framework built upon a dual-stream architecture that integrates Time-Frequency Images (TFIs) and Power Spectral Density (PSD). Distinct from conventional fusion methods that rely on static receptive fields, the proposed architecture incorporates a Multi-Branch Selective Kernel (SK) module combined with Asymmetric Convolution Blocks (ACBs). This mechanism enables the network to dynamically adjust its receptive fields, acting as an adaptive filter that simultaneously captures micro-scale transient features and macro-scale spectral trends within entangled compound signals. To complement this spatial-temporal adaptation, a Squeeze-and-Excitation (SE) mechanism is integrated at the fusion stage to adaptively recalibrate the contribution of heterogeneous features from each modality. Evaluations on a dataset of 405,000 samples demonstrate that SKANet achieves an overall accuracy of 96.99\%, exhibiting superior robustness for compound jamming classification, particularly under low Jamming-to-Noise Ratio (JNR) regimes.

</details>


### [143] [Combating Noisy Labels through Fostering Self- and Neighbor-Consistency](https://arxiv.org/abs/2601.12795)
*Zeren Sun,Yazhou Yao,Tongliang Liu,Zechao Li,Fumin Shen,Jinhui Tang*

Main category: cs.CV

TL;DR: Jo-SNC是一种噪声鲁棒方法，通过联合样本选择和模型正则化解决标签噪声问题，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 标签噪声在现实场景中普遍存在，现有方法常忽视不同小批量间的噪声不平衡和分布外噪声数据。

Method: 提出了一种基于Jensen-Shannon散度的样本选择方法，结合自适应的数据驱动阈值方案，以及三重一致性正则化。

Result: 在多个基准数据集上的实验证明了Jo-SNC方法的有效性和优越性。

Conclusion: Jo-SNC方法通过联合样本选择和模型正则化，有效解决了标签噪声问题，并在多个基准数据集上展示了其优越性。

Abstract: Label noise is pervasive in various real-world scenarios, posing challenges in supervised deep learning. Deep networks are vulnerable to such label-corrupted samples due to the memorization effect. One major stream of previous methods concentrates on identifying clean data for training. However, these methods often neglect imbalances in label noise across different mini-batches and devote insufficient attention to out-of-distribution noisy data. To this end, we propose a noise-robust method named Jo-SNC (\textbf{Jo}int sample selection and model regularization based on \textbf{S}elf- and \textbf{N}eighbor-\textbf{C}onsistency). Specifically, we propose to employ the Jensen-Shannon divergence to measure the ``likelihood'' of a sample being clean or out-of-distribution. This process factors in the nearest neighbors of each sample to reinforce the reliability of clean sample identification. We design a self-adaptive, data-driven thresholding scheme to adjust per-class selection thresholds. While clean samples undergo conventional training, detected in-distribution and out-of-distribution noisy samples are trained following partial label learning and negative learning, respectively. Finally, we advance the model performance further by proposing a triplet consistency regularization that promotes self-prediction consistency, neighbor-prediction consistency, and feature consistency. Extensive experiments on various benchmark datasets and comprehensive ablation studies demonstrate the effectiveness and superiority of our approach over existing state-of-the-art methods.

</details>


### [144] [PhyG-MoE: A Physics-Guided Mixture-of-Experts Framework for Energy-Efficient GNSS Interference Recognition](https://arxiv.org/abs/2601.12798)
*Zhihan Zeng,Yang Zhao,Kaihe Wang,Dusit Niyato,Yue Xiu,Lu Chen,Zhongpei Zhang,Ning Wei*

Main category: cs.CV

TL;DR: PhyG-MoE通过动态路由信号处理复杂度，显著提升GNSS抗干扰能力，准确率达97.58%。


<details>
  <summary>Details</summary>
Motivation: 解决静态模型在动态电磁环境中因固定计算拓扑导致的资源不匹配问题，提升GNSS在复杂电磁干扰下的可靠性。

Method: 引入PhyG-MoE框架，采用基于频谱的门控机制，根据信号频谱特征纠缠动态路由信号，高容量TransNeXt专家按需处理复杂特征，轻量级专家处理基础信号以减少延迟。

Result: 在21种干扰类别上实现了97.58%的整体准确率。

Conclusion: PhyG-MoE框架通过动态调整模型容量与信号复杂度对齐，显著降低了计算开销且无性能损失，为资源受限的认知接收器提供了可行解决方案。

Abstract: Complex electromagnetic interference increasingly compromises Global Navigation Satellite Systems (GNSS), threatening the reliability of Space-Air-Ground Integrated Networks (SAGIN). Although deep learning has advanced interference recognition, current static models suffer from a \textbf{fundamental limitation}: they impose a fixed computational topology regardless of the input's physical entropy. This rigidity leads to severe resource mismatch, where simple primitives consume the same processing cost as chaotic, saturated mixtures. To resolve this, this paper introduces PhyG-MoE (Physics-Guided Mixture-of-Experts), a framework designed to \textbf{dynamically align model capacity with signal complexity}. Unlike static architectures, the proposed system employs a spectrum-based gating mechanism that routes signals based on their spectral feature entanglement. A high-capacity TransNeXt expert is activated on-demand to disentangle complex features in saturated scenarios, while lightweight experts handle fundamental signals to minimize latency. Evaluations on 21 jamming categories demonstrate that PhyG-MoE achieves an overall accuracy of 97.58\%. By resolving the intrinsic conflict between static computing and dynamic electromagnetic environments, the proposed framework significantly reduces computational overhead without performance degradation, offering a viable solution for resource-constrained cognitive receivers.

</details>


### [145] [Left-Right Symmetry Breaking in CLIP-style Vision-Language Models Trained on Synthetic Spatial-Relation Data](https://arxiv.org/abs/2601.12809)
*Takaki Yamamoto,Chihiro Noguchi,Toshihiro Tanizawa*

Main category: cs.CV

TL;DR: 通过可控1D图像文本测试平台，研究发现对比训练能学习左右关系，标签多样性是关键，注意力机制揭示了对称性打破的机制。


<details>
  <summary>Details</summary>
Motivation: 探究视觉语言模型是否真正获得空间理解能力及其机制。

Method: 使用轻量级Transformer视觉和文本编码器端到端训练，评估未见物体对的泛化能力，并系统性地变化标签和布局多样性。

Result: 对比训练成功学习左右关系，标签多样性对泛化起主要作用。注意力分解揭示了位置和标记嵌入的相互作用如何打破对称性。

Conclusion: 对比训练能够学习左右关系，且标签多样性（而非布局多样性）是泛化的主要驱动力。通过注意力分解发现，位置嵌入和标记嵌入的相互作用诱导了水平注意力梯度，从而打破了编码器中的左右对称性。

Abstract: Spatial understanding remains a key challenge in vision-language models. Yet it is still unclear whether such understanding is truly acquired, and if so, through what mechanisms. We present a controllable 1D image-text testbed to probe how left-right relational understanding emerges in Transformer-based vision and text encoders trained with a CLIP-style contrastive objective. We train lightweight Transformer-based vision and text encoders end-to-end on paired descriptions of one- and two-object scenes and evaluate generalization to unseen object pairs while systematically varying label and layout diversity. We find that contrastive training learns left-right relations and that label diversity, more than layout diversity, is the primary driver of generalization in this setting. To gain the mechanistic understanding, we perform an attention decomposition and show that interactions between positional and token embeddings induce a horizontal attention gradient that breaks left-right symmetry in the encoders; ablating this contribution substantially reduces left-right discrimination. Our results provide a mechanistic insight of when and how CLIP-style models acquire relational competence.

</details>


### [146] [CSGaussian: Progressive Rate-Distortion Compression and Segmentation for 3D Gaussian Splatting](https://arxiv.org/abs/2601.12814)
*Yu-Jen Tseng,Chia-Hao Kao,Jing-Zhong Chen,Alessandro Gnutti,Shao-Yuan Lo,Yen-Yu Lin,Wen-Hsiao Peng*

Main category: cs.CV

TL;DR: 首个统一框架用于3DGS的率失真优化压缩与分割，通过轻量级超先验和压缩引导学习，降低传输成本并保持高质量渲染与分割。


<details>
  <summary>Details</summary>
Motivation: 尽管3DGS在实时渲染和语义场景理解中表现优异，但之前的工作大多独立处理这些任务，未探索其联合考虑。本文旨在通过集成语义学习到压缩流程中，支持解码端应用（如场景编辑和操作）。

Method: 通过轻量级隐式神经表示超先验，高效编码颜色和语义属性，避免传统网格超先验的高成本。进一步开发了压缩引导的分割学习，包括量化感知训练和质量感知加权机制。

Result: 在LERF和3D-OVS数据集上的大量实验表明，该方法显著降低了传输成本，同时保持了高渲染质量和强分割性能。

Conclusion: 该论文提出了首个统一框架，用于3D高斯溅射（3DGS）的率失真优化压缩与分割，显著降低了传输成本，同时保持了高质量的渲染和分割性能。

Abstract: We present the first unified framework for rate-distortion-optimized compression and segmentation of 3D Gaussian Splatting (3DGS). While 3DGS has proven effective for both real-time rendering and semantic scene understanding, prior works have largely treated these tasks independently, leaving their joint consideration unexplored. Inspired by recent advances in rate-distortion-optimized 3DGS compression, this work integrates semantic learning into the compression pipeline to support decoder-side applications--such as scene editing and manipulation--that extend beyond traditional scene reconstruction and view synthesis. Our scheme features a lightweight implicit neural representation-based hyperprior, enabling efficient entropy coding of both color and semantic attributes while avoiding costly grid-based hyperprior as seen in many prior works. To facilitate compression and segmentation, we further develop compression-guided segmentation learning, consisting of quantization-aware training to enhance feature separability and a quality-aware weighting mechanism to suppress unreliable Gaussian primitives. Extensive experiments on the LERF and 3D-OVS datasets demonstrate that our approach significantly reduces transmission cost while preserving high rendering quality and strong segmentation performance.

</details>


### [147] [A Generalist Foundation Model for Total-body PET/CT Enables Diagnostic Reporting and System-wide Metabolic Profiling](https://arxiv.org/abs/2601.12820)
*Wei Chen,Liang Wu,Shuyi Lu,Yuanyuan Sun,Wenkai Bi,Zilong Yuan,Yaoyao He,Feng Wang,Junchi Ma,Shuyong Liu,Zhaoping Cheng,Xiaoyan Hu,Jianfeng Qiu*

Main category: cs.CV

TL;DR: SDF-HOLO是一种多模态基础模型，通过双流编码器和跨模态交互模块优化全身PET/CT分析，显著提升诊断性能并揭示系统级代谢特征。


<details>
  <summary>Details</summary>
Motivation: 现有医学AI模型假设单一模态输入、局部视野和粗略的图像-文本对齐，无法应对全身PET/CT的异质解剖和代谢信号、约2米的轴向覆盖和结构化放射学语义的挑战。

Method: SDF-HOLO采用双流编码器解耦CT和PET表示学习，并通过跨模态交互模块耦合它们，结合局部窗口和全局注意力的分层上下文建模，以及使用解剖分割掩模作为显式语义锚点进行体素-掩模-文本对齐。

Result: 在肿瘤分割、低剂量病变检测和多语言诊断报告生成任务中，SDF-HOLO优于强任务特定和临床参考基线，减少了定位错误和幻觉发现。

Conclusion: SDF-HOLO模型为全身PET/CT诊断提供了可扩展的计算基础，支持系统级精准肿瘤学，并揭示了肿瘤相关的器官间代谢网络相互作用特征。

Abstract: Total-body PET/CT enables system-wide molecular imaging, but heterogeneous anatomical and metabolic signals, approximately 2 m axial coverage, and structured radiology semantics challenge existing medical AI models that assume single-modality inputs, localized fields of view, and coarse image-text alignment. We introduce SDF-HOLO (Systemic Dual-stream Fusion Holo Model), a multimodal foundation model for holistic total-body PET/CT, pre-trained on more than 10,000 patients. SDF-HOLO decouples CT and PET representation learning with dual-stream encoders and couples them through a cross-modal interaction module, allowing anatomical context to refine PET aggregation while metabolic saliency guides subtle morphological reasoning. To model long-range dependencies across the body, hierarchical context modeling combines efficient local windows with global attention. To bridge voxels and clinical language, we use anatomical segmentation masks as explicit semantic anchors and perform voxel-mask-text alignment during pre-training. Across tumor segmentation, low-dose lesion detection, and multilingual diagnostic report generation, SDF-HOLO outperforms strong task-specific and clinical-reference baselines while reducing localization errors and hallucinated findings. Beyond focal interpretation, the model enables system-wide metabolic profiling and reveals tumor-associated fingerprints of inter-organ metabolic network interactions, providing a scalable computational foundation for total-body PET/CT diagnostics and system-level precision oncology.

</details>


### [148] [TreeDGS: Aerial Gaussian Splatting for Distant DBH Measurement](https://arxiv.org/abs/2601.12823)
*Belal Shaheen,Minh-Hieu Nguyen,Bach-Thuan Bui,Shubham,Tim Wu,Michael Fairley,Matthew David Zane,Michael Wu,James Tompkin*

Main category: cs.CV

TL;DR: TreeDGS是一种基于3D高斯泼溅的空中图像重建方法，专为树干直径（DBH）测量设计，其精度超越LiDAR，展示了低成本高精度测量的可行性。


<details>
  <summary>Details</summary>
Motivation: 空中遥感在复杂自然场景中难以直接进行物体级精确测量，尤其是树干直径（DBH）的测量。现有的3D视觉技术（如NeRF和3D高斯泼溅）虽提升了重建保真度，但在空中测量中仍面临挑战。

Method: TreeDGS利用3D高斯泼溅作为连续、可密集化的场景表示，结合SfM-MVS初始化和高斯优化，通过RaDe-GS的深度感知累积不透明度积分提取密集点集，并使用不透明度加权实心圆拟合估计DBH。

Result: 在10个地块的实地测量DBH评估中，TreeDGS达到4.79厘米的RMSE（约2.6像素），优于最先进的LiDAR基准方法（7.91厘米RMSE）。

Conclusion: TreeDGS通过3D高斯泼溅技术实现了对空中图像中树干直径（DBH）的准确测量，其性能优于现有的LiDAR基准方法，展示了低成本、高精度的空中测量潜力。

Abstract: Aerial remote sensing enables efficient large-area surveying, but accurate direct object-level measurement remains difficult in complex natural scenes. Recent advancements in 3D vision, particularly learned radiance-field representations such as NeRF and 3D Gaussian Splatting, have begun to raise the ceiling on reconstruction fidelity and densifiable geometry from posed imagery. Nevertheless, direct aerial measurement of important natural attributes such as tree diameter at breast height (DBH) remains challenging. Trunks in aerial forest scans are distant and sparsely observed in image views: at typical operating altitudes, stems may span only a few pixels. With these constraints, conventional reconstruction methods leave breast-height trunk geometry weakly constrained. We present TreeDGS, an aerial image reconstruction method that leverages 3D Gaussian Splatting as a continuous, densifiable scene representation for trunk measurement. After SfM-MVS initialization and Gaussian optimization, we extract a dense point set from the Gaussian field using RaDe-GS's depth-aware cumulative-opacity integration and associate each sample with a multi-view opacity reliability score. We then estimate DBH from trunk-isolated points using opacity-weighted solid-circle fitting. Evaluated on 10 plots with field-measured DBH, TreeDGS reaches 4.79,cm RMSE (about 2.6 pixels at this GSD) and outperforms a state-of-the-art LiDAR baseline (7.91,cm RMSE), demonstrating that densified splat-based geometry can enable accurate, low-cost aerial DBH measurement.

</details>


### [149] [Seeing Isn't Always Believing: Analysis of Grad-CAM Faithfulness and Localization Reliability in Lung Cancer CT Classification](https://arxiv.org/abs/2601.12826)
*Teerapong Panboonyuen*

Main category: cs.CV

TL;DR: 该研究评估了Grad-CAM在五种深度学习模型中的可靠性，发现其在卷积网络中表现良好，但在Transformer模型中效果不佳，并揭示了当前XAI方法在医学影像中的局限性。


<details>
  <summary>Details</summary>
Motivation: 尽管Grad-CAM等XAI技术在医学影像分析中广泛使用，但其热图解释的忠实性和可靠性仍受到质疑。本研究旨在探讨Grad-CAM是否能真实反映用于肺癌图像分类的深度模型的内部决策过程。

Method: 使用公开的IQ-OTH/NCCD数据集，评估了五种代表性架构（ResNet-50、ResNet-101、DenseNet-161、EfficientNet-B0和ViT-Base-Patch16-224），并引入了一个定量评估框架，结合定位准确性、基于扰动的忠实性和解释一致性来评估Grad-CAM在不同架构中的可靠性。

Result: 实验结果表明，Grad-CAM在大多数卷积网络中能有效突出肿瘤区域，但在Vision Transformer模型中的解释忠实性显著下降。跨模型比较显示，显著定位存在显著变异性，表明Grad-CAM的解释可能与网络实际使用的诊断证据不一致。

Conclusion: 该研究揭示了当前基于显著性的可解释人工智能（XAI）方法在医学影像中的局限性，并强调了需要开发既计算合理又具有临床意义的模型感知解释方法。

Abstract: Explainable Artificial Intelligence (XAI) techniques, such as Gradient-weighted Class Activation Mapping (Grad-CAM), have become indispensable for visualizing the reasoning process of deep neural networks in medical image analysis. Despite their popularity, the faithfulness and reliability of these heatmap-based explanations remain under scrutiny. This study critically investigates whether Grad-CAM truly represents the internal decision-making of deep models trained for lung cancer image classification. Using the publicly available IQ-OTH/NCCD dataset, we evaluate five representative architectures: ResNet-50, ResNet-101, DenseNet-161, EfficientNet-B0, and ViT-Base-Patch16-224, to explore model-dependent variations in Grad-CAM interpretability. We introduce a quantitative evaluation framework that combines localization accuracy, perturbation-based faithfulness, and explanation consistency to assess Grad-CAM reliability across architectures. Experimental findings reveal that while Grad-CAM effectively highlights salient tumor regions in most convolutional networks, its interpretive fidelity significantly degrades for Vision Transformer models due to non-local attention behavior. Furthermore, cross-model comparisons indicate substantial variability in saliency localization, implying that Grad-CAM explanations may not always correspond to the true diagnostic evidence used by the networks. This work exposes critical limitations of current saliency-based XAI approaches in medical imaging and emphasizes the need for model-aware interpretability methods that are both computationally sound and clinically meaningful. Our findings aim to inspire a more cautious and rigorous adoption of visual explanation tools in medical AI, urging the community to rethink what it truly means to "trust" a model's explanation.

</details>


### [150] [FGTBT: Frequency-Guided Task-Balancing Transformer for Unified Facial Landmark Detection](https://arxiv.org/abs/2601.12863)
*Jun Wan,Xinyu Xiong,Ning Chen,Zhihui Lai,Jie Zhou,Wenwen Min*

Main category: cs.CV

TL;DR: 提出FGTBT框架，通过FMB-loss和FGSA模型提升面部标志检测性能，尤其在挑战性场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有FLD方法在挑战性场景（如大姿态变化、光照变化和面部表情变化）中表现不佳，且数据集规模和多样性有限。

Method: 提出了一种新颖的细粒度多任务平衡损失（FMB-loss）和频率引导的结构感知（FGSA）模型，通过频率域建模增强面部结构感知。

Result: 在多个基准数据集上的实验表明，FGTBT框架的性能与最先进方法相当。

Conclusion: FGTBT框架通过频率引导的任务平衡和多数据集统一训练，显著提升了在挑战性场景下的面部标志检测性能。

Abstract: Recently, deep learning based facial landmark detection (FLD) methods have achieved considerable success. However, in challenging scenarios such as large pose variations, illumination changes, and facial expression variations, they still struggle to accurately capture the geometric structure of the face, resulting in performance degradation. Moreover, the limited size and diversity of existing FLD datasets hinder robust model training, leading to reduced detection accuracy. To address these challenges, we propose a Frequency-Guided Task-Balancing Transformer (FGTBT), which enhances facial structure perception through frequency-domain modeling and multi-dataset unified training. Specifically, we propose a novel Fine-Grained Multi-Task Balancing loss (FMB-loss), which moves beyond coarse task-level balancing by assigning weights to individual landmarks based on their occurrence across datasets. This enables more effective unified training and mitigates the issue of inconsistent gradient magnitudes. Additionally, a Frequency-Guided Structure-Aware (FGSA) model is designed to utilize frequency-guided structure injection and regularization to help learn facial structure constraints. Extensive experimental results on popular benchmark datasets demonstrate that the integration of the proposed FMB-loss and FGSA model into our FGTBT framework achieves performance comparable to state-of-the-art methods. The code is available at https://github.com/Xi0ngxinyu/FGTBT.

</details>


### [151] [Proxy Robustness in Vision Language Models is Effortlessly Transferable](https://arxiv.org/abs/2601.12865)
*Xiaowei Fu,Fuxiang Huang,Lei Zhang*

Main category: cs.CV

TL;DR: 论文提出HPT-GPD方法，利用CLIP的固有防御能力，通过跨架构鲁棒性蒸馏和解耦学习率调度，实现了对抗鲁棒性的高效转移，同时保持零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 由于大规模多模态模型对抗训练的高计算成本，论文探索了CLIP模型的固有防御能力，并提出了一种无需对抗训练的鲁棒性转移方法。

Method: 论文设计了Heterogeneous Proxy Transfer (HPT)框架和Generalization-Pivot Decoupling (GPD)方法，通过跨架构鲁棒性蒸馏通道和解耦学习率调度，实现了对抗鲁棒性与自然泛化的平衡。

Result: 在15个零样本数据集上的实验证明了HPT-GPD方法的有效性，成功实现了对抗鲁棒性的高效转移。

Conclusion: 论文提出了HPT-GPD方法，通过代理对抗鲁棒性和泛化-枢轴解耦，成功在视觉语言模型中实现了对抗鲁棒性的高效转移，同时保持了零样本自然泛化能力。

Abstract: As a pivotal technique for improving the defense of deep models, adversarial robustness transfer via distillation has demonstrated remarkable success in conventional image classification tasks. However, this paradigm encounters critical challenges when applied to vision-language models (VLM) (e.g., CLIP): constructing adversarially robust teacher for large-scale multi-modal models demands prohibitively high computational resources. We bridge this gap by revealing an interesting phenomenon: vanilla CLIP (without adversarial training) exhibits intrinsic defensive capabilities against adversarial examples generated by another CLIP with different architectures. We formally define this as proxy adversarial robustness, and naturally propose a Heterogeneous Proxy Transfer (HPT) framework that establishes cross-architectural robustness distillation channels between CLIP variants, effortlessly enabling the VLM robustness transfer from proxy to target models. Yet, such proxy transfer paradigm easily induces severe overfitting, leading to a sharp degradation in zero-shot natural generalization. To resolve that, we design Generalization-Pivot Decoupling (GPD) by leveraging the difference in learning rate scheduling. This decouples the proxy transfer process into a generalization-anchored warm-up that maintains generalization and a generalization-pulled HPT that promotes adversarial robustness, to achieve an equilibrium between natural generalization and adversarial robustness. Extensive experiments on 15 zero-shot datasets demonstrate the effectiveness of our HPT-GPD method. The code is available at the website of github.com/fxw13/HPT-GPD.

</details>


### [152] [Exploring Talking Head Models With Adjacent Frame Prior for Speech-Preserving Facial Expression Manipulation](https://arxiv.org/abs/2601.12876)
*Zhenxuan Lu,Zhihua Xu,Zhijing Yang,Feng Gao,Yongyi Lu,Keze Wang,Tianshui Chen*

Main category: cs.CV

TL;DR: THFEM框架结合AD-THG与SPFEM，通过相邻帧学习策略提升口型同步与图像质量。


<details>
  <summary>Details</summary>
Motivation: 解决SPFEM在表情操纵中口型同步不准确的问题，利用AD-THG模型生成精确口型同步的帧。

Method: 提出THFEM框架，结合AD-THG模型生成精确口型同步的帧，并开发相邻帧学习策略以优化模型。

Result: 实验证明THFEM框架能有效保留表情操纵中的口型，整合AD-THG与SPFEM带来显著优势。

Conclusion: 该研究提出的THFEM框架通过整合AD-THG与SPFEM，有效解决了表情操纵中口型同步的难题，并通过相邻帧学习策略提升了图像质量。

Abstract: Speech-Preserving Facial Expression Manipulation (SPFEM) is an innovative technique aimed at altering facial expressions in images and videos while retaining the original mouth movements. Despite advancements, SPFEM still struggles with accurate lip synchronization due to the complex interplay between facial expressions and mouth shapes. Capitalizing on the advanced capabilities of audio-driven talking head generation (AD-THG) models in synthesizing precise lip movements, our research introduces a novel integration of these models with SPFEM. We present a new framework, Talking Head Facial Expression Manipulation (THFEM), which utilizes AD-THG models to generate frames with accurately synchronized lip movements from audio inputs and SPFEM-altered images. However, increasing the number of frames generated by AD-THG models tends to compromise the realism and expression fidelity of the images. To counter this, we develop an adjacent frame learning strategy that finetunes AD-THG models to predict sequences of consecutive frames. This strategy enables the models to incorporate information from neighboring frames, significantly improving image quality during testing. Our extensive experimental evaluations demonstrate that this framework effectively preserves mouth shapes during expression manipulations, highlighting the substantial benefits of integrating AD-THG with SPFEM.

</details>


### [153] [YOLO26: An Analysis of NMS-Free End to End Framework for Real-Time Object Detection](https://arxiv.org/abs/2601.12882)
*Sudip Chakrabarty*

Main category: cs.CV

TL;DR: YOLO26通过端到端学习取代NMS，引入新技术提升性能，在速度和精度上超越现有模型。


<details>
  <summary>Details</summary>
Motivation: 传统YOLO版本因NMS后处理的延迟和超参数敏感性受限，YOLO26旨在通过端到端学习重新定义这一范式。

Method: 引入了MuSGD优化器以稳定轻量级骨干网络，STAL用于小目标感知分配，以及ProgLoss进行动态监督。

Result: YOLO26在推理速度和检测精度上均优于前代及最新竞争对手（如RTMDet和DAMO-YOLO），建立了新的Pareto前沿。

Conclusion: YOLO26通过消除NMS并采用端到端学习策略，成功解决了延迟与精度之间的历史性权衡，标志着边缘计算机视觉的下一步进化。

Abstract: The "You Only Look Once" (YOLO) framework has long served as the benchmark for real-time object detection, yet traditional iterations (YOLOv1 through YOLO11) remain constrained by the latency and hyperparameter sensitivity of Non-Maximum Suppression (NMS) post-processing. This paper analyzes a comprehensive analysis of YOLO26, an architecture that fundamentally redefines this paradigm by eliminating NMS in favor of a native end-to-end learning strategy. This study examines the critical innovations that enable this transition, specifically the introduction of the MuSGD optimizer for stabilizing lightweight backbones, STAL for small-target-aware assignment, and ProgLoss for dynamic supervision. Through a systematic review of official performance benchmarks, the results demonstrate that YOLO26 establishes a new Pareto front, outperforming a comprehensive suite of predecessors and state-of-the-art competitors (including RTMDet and DAMO-YOLO) in both inference speed and detection accuracy. The analysis confirms that by decoupling representation learning from heuristic post-processing, YOLOv26 successfully resolves the historical trade-off between latency and precision, signaling the next evolutionary step in edge-based computer vision.

</details>


### [154] [Simultaneous Detection of LSD and FMD in Cattle Using Ensemble Deep Learning](https://arxiv.org/abs/2601.12889)
*Nazibul Basar Ayon,Abdul Hasib,Md. Faishal Ahmed,Md. Sadiqur Rahman,Kamrul Islam,T. M. Mehrab Hasan,A. S. M. Ahsanul Sarkar Akib*

Main category: cs.CV

TL;DR: 集成深度学习框架通过优化加权平均实现LSD和FMD的高精度检测（98.2%准确率），解决症状重叠问题，支持自动化诊断。


<details>
  <summary>Details</summary>
Motivation: LSD和FMD是高度传染性牛病，症状与其他良性条件重叠，导致诊断困难，亟需自动化工具提升早期检测效率。

Method: 利用VGG16、ResNet50和InceptionV3的集成深度学习框架，通过优化加权平均实现LSD和FMD的同时检测。

Result: 模型准确率达98.2%，宏平均精确率、召回率、F1分数均为98.1%，AUC-ROC为99.5%。

Conclusion: 该研究提出的集成深度学习框架在LSD和FMD的检测中表现出色，准确率达98.2%，为解决症状重叠问题提供了自动化诊断工具，有望提升疾病管理效率并支持全球农业可持续发展。

Abstract: Lumpy Skin Disease (LSD) and Foot-and-Mouth Disease (FMD) are highly contagious viral diseases affecting cattle, causing significant economic losses and welfare challenges. Their visual diagnosis is complicated by significant symptom overlap with each other and with benign conditions like insect bites or chemical burns, hindering timely control measures. Leveraging a comprehensive dataset of 10,516 expert-annotated images from 18 farms across India, Brazil, and the USA, this study presents a novel Ensemble Deep Learning framework integrating VGG16, ResNet50, and InceptionV3 with optimized weighted averaging for simultaneous LSD and FMD detection. The model achieves a state-of-the-art accuracy of 98.2\%, with macro-averaged precision of 98.2\%, recall of 98.1\%, F1-score of 98.1\%, and an AUC-ROC of 99.5\%. This approach uniquely addresses the critical challenge of symptom overlap in multi-disease detection, enabling early, precise, and automated diagnosis. This tool has the potential to enhance disease management, support global agricultural sustainability, and is designed for future deployment in resource-limited settings.

</details>


### [155] [Membership Inference Test: Auditing Training Data in Object Classification Models](https://arxiv.org/abs/2601.12929)
*Gonzalo Mancera,Daniel DeAlcala,Aythami Morales,Ruben Tolosana,Julian Fierrez*

Main category: cs.CV

TL;DR: 提出定制化MINT架构用于物体识别，实验验证其区分训练/测试数据的有效性（精度70%-80%）。


<details>
  <summary>Details</summary>
Motivation: 解决物体识别领域中数据是否用于训练阶段的检测问题，优化MINT模型的性能和效率。

Method: 提出了针对MINT模型的定制化架构，结合卷积层捕捉训练数据激活模式，并在三个公共数据库（超17.4万张图像）上进行了实验。

Result: 实验显示，所提架构能有效识别训练和测试数据，精度为70%-80%，并分析了影响MINT模块的因素。

Conclusion: 本研究通过定制化架构优化了MINT模型在物体识别领域的性能，实验结果表明其能够有效区分训练和测试数据，精度达70%-80%。

Abstract: In this research, we analyze the performance of Membership Inference Tests (MINT), focusing on determining whether given data were utilized during the training phase, specifically in the domain of object recognition. Within the area of object recognition, we propose and develop architectures tailored for MINT models. These architectures aim to optimize performance and efficiency in data utilization, offering a tailored solution to tackle the complexities inherent in the object recognition domain. We conducted experiments involving an object detection model, an embedding extractor, and a MINT module. These experiments were performed in three public databases, totaling over 174K images. The proposed architecture leverages convolutional layers to capture and model the activation patterns present in the data during the training process. Through our analysis, we are able to identify given data used for testing and training, achieving precision rates ranging between 70% and 80%, contingent upon the depth of the detection module layer chosen for input to the MINT module. Additionally, our studies entail an analysis of the factors influencing the MINT Module, delving into the contributing elements behind more transparent training processes.

</details>


### [156] [TwoHead-SwinFPN: A Unified DL Architecture for Synthetic Manipulation, Detection and Localization in Identity Documents](https://arxiv.org/abs/2601.12895)
*Chan Naseeb,Adeel Ashraf Cheema,Hassan Sami,Tayyab Afzal,Muhammad Omair,Usman Habib*

Main category: cs.CV

TL;DR: TwoHead-SwinFPN is a deep learning model for detecting and localizing synthetic ID document manipulations, achieving high performance and efficiency.


<details>
  <summary>Details</summary>
Motivation: The increasing threat of synthetic manipulations in ID documents via generative AI models necessitates robust detection and localization methods.

Method: The paper proposes a unified deep learning architecture combining Swin Transformer, FPN, UNet-style decoder, and CBAM, with a dual-head design for joint optimization of detection and segmentation tasks.

Result: The model achieves 84.31% accuracy, 90.78% AUC for classification, 57.24% mean Dice score for localization, and an F1-score of 88.61%, validated across multiple languages and devices.

Conclusion: TwoHead-SwinFPN demonstrates superior performance in detecting and localizing synthetic manipulations in ID documents, achieving high accuracy and computational efficiency suitable for real-world deployment.

Abstract: The proliferation of sophisticated generative AI models has significantly escalated the threat of synthetic manipulations in identity documents, particularly through face swapping and text inpainting attacks. This paper presents TwoHead-SwinFPN, a unified deep learning architecture that simultaneously performs binary classification and precise localization of manipulated regions in ID documents. Our approach integrates a Swin Transformer backbone with Feature Pyramid Network (FPN) and UNet-style decoder, enhanced with Convolutional Block Attention Module (CBAM) for improved feature representation. The model employs a dual-head architecture for joint optimization of detection and segmentation tasks, utilizing uncertainty-weighted multi-task learning. Extensive experiments on the FantasyIDiap dataset demonstrate superior performance with 84.31\% accuracy, 90.78\% AUC for classification, and 57.24\% mean Dice score for localization. The proposed method achieves an F1-score of 88.61\% for binary classification while maintaining computational efficiency suitable for real-world deployment through FastAPI implementation. Our comprehensive evaluation includes ablation studies, cross-device generalization analysis, and detailed performance assessment across 10 languages and 3 acquisition devices.

</details>


### [157] [Supervision-by-Hallucination-and-Transfer: A Weakly-Supervised Approach for Robust and Precise Facial Landmark Detection](https://arxiv.org/abs/2601.12919)
*Jun Wan,Yuanzhi Yao,Zhihui Lai,Jie Zhou,Xianxu Hou,Wenwen Min*

Main category: cs.CV

TL;DR: SHT框架通过DHLN和FPTN模块，结合面部超分辨率和姿态转换，提升了低分辨率图像下的面部关键点检测精度。


<details>
  <summary>Details</summary>
Motivation: 解决低分辨率图像、训练数据不足和标注不精确导致的面部关键点检测精度下降问题。

Method: 提出了一种弱监督框架SHT，包含DHLN和FPTN两个模块。DHLN通过学习高分辨率表示和生成有效的关键点热图，FPTN通过面部姿态转换进一步优化热图和超分辨率图像。

Result: 实验结果表明，SHT在面部超分辨率和关键点检测任务上均优于现有技术。

Conclusion: SHT框架通过结合DHLN和FPTN模块，显著提升了面部关键点检测的精度和鲁棒性，尤其是在低分辨率图像和弱监督条件下。

Abstract: High-precision facial landmark detection (FLD) relies on high-resolution deep feature representations. However, low-resolution face images or the compression (via pooling or strided convolution) of originally high-resolution images hinder the learning of such features, thereby reducing FLD accuracy. Moreover, insufficient training data and imprecise annotations further degrade performance. To address these challenges, we propose a weakly-supervised framework called Supervision-by-Hallucination-and-Transfer (SHT) for more robust and precise FLD. SHT contains two novel mutually enhanced modules: Dual Hallucination Learning Network (DHLN) and Facial Pose Transfer Network (FPTN). By incorporating FLD and face hallucination tasks, DHLN is able to learn high-resolution representations with low-resolution inputs for recovering both facial structures and local details and generating more effective landmark heatmaps. Then, by transforming faces from one pose to another, FPTN can further improve landmark heatmaps and faces hallucinated by DHLN for detecting more accurate landmarks. To the best of our knowledge, this is the first study to explore weakly-supervised FLD by integrating face hallucination and facial pose transfer tasks. Experimental results of both face hallucination and FLD demonstrate that our method surpasses state-of-the-art techniques.

</details>


### [158] [Dual-Stream Collaborative Transformer for Image Captioning](https://arxiv.org/abs/2601.12926)
*Jun Wan,Jun Liu,Zhihui lai,Jie Zhou*

Main category: cs.CV

TL;DR: DSCT通过动态融合区域和分割特征，解决了现有图像描述方法的上下文不足问题，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于区域特征的图像描述方法因缺乏上下文信息和对部分描述的过度依赖，易生成无关描述。

Method: 提出双流协作变换器（DSCT），包含模式特定互注意力编码器（PSMAE）和动态提名解码器（DND），动态融合区域和分割特征。

Result: 在多个基准数据集上，DSCT表现优于现有最先进模型。

Conclusion: DSCT模型通过动态融合区域和分割特征，显著提升了图像描述生成的准确性和描述性，优于现有最先进模型。

Abstract: Current region feature-based image captioning methods have progressed rapidly and achieved remarkable performance. However, they are still prone to generating irrelevant descriptions due to the lack of contextual information and the over-reliance on generated partial descriptions for predicting the remaining words. In this paper, we propose a Dual-Stream Collaborative Transformer (DSCT) to address this issue by introducing the segmentation feature. The proposed DSCT consolidates and then fuses the region and segmentation features to guide the generation of caption sentences. It contains multiple Pattern-Specific Mutual Attention Encoders (PSMAEs) and Dynamic Nomination Decoders (DNDs). The PSMAE effectively highlights and consolidates the private information of two representations by querying each other. The DND dynamically searches for the most relevant learning blocks to the input textual representations and exploits the homogeneous features between the consolidated region and segmentation features to generate more accurate and descriptive caption sentences. To the best of our knowledge, this is the first study to explore how to fuse different pattern-specific features in a dynamic way to bypass their semantic inconsistencies and spatial misalignment issues for image captioning. The experimental results from popular benchmark datasets demonstrate that our DSCT outperforms the state-of-the-art image captioning models in the literature.

</details>


### [159] [QASA: Quality-Guided K-Adaptive Slot Attention for Unsupervised Object-Centric Learning](https://arxiv.org/abs/2601.12936)
*Tianran Ouyang,Xingping Dong,Jing Zhang,Mang Ye,Jun Chen,Bo Du*

Main category: cs.CV

TL;DR: QASA通过质量引导的动态槽选择和解耦重构，解决了K自适应方法的性能瓶颈，实现了超越固定K方法的成果。


<details>
  <summary>Details</summary>
Motivation: 现有K自适应方法在槽绑定质量和优化目标冲突方面存在局限，导致性能落后于固定K方法。

Method: 提出了一种质量引导的K自适应槽注意力（QASA），包括解耦槽选择与重构、设计无监督的槽质量度量、以及基于质量动态选择高质量槽的方案。

Result: QASA在真实和合成数据集上显著优于现有K自适应方法，并在真实数据集上超越了固定K方法。

Conclusion: QASA通过解耦槽选择与重构，并引入无监督的槽质量度量，显著提升了K自适应方法的性能，甚至在某些情况下超越了固定K的方法。

Abstract: Slot Attention, an approach that binds different objects in a scene to a set of "slots", has become a leading method in unsupervised object-centric learning. Most methods assume a fixed slot count K, and to better accommodate the dynamic nature of object cardinality, a few works have explored K-adaptive variants. However, existing K-adaptive methods still suffer from two limitations. First, they do not explicitly constrain slot-binding quality, so low-quality slots lead to ambiguous feature attribution. Second, adding a slot-count penalty to the reconstruction objective creates conflicting optimization goals between reducing the number of active slots and maintaining reconstruction fidelity. As a result, they still lag significantly behind strong K-fixed baselines. To address these challenges, we propose Quality-Guided K-Adaptive Slot Attention (QASA). First, we decouple slot selection from reconstruction, eliminating the mutual constraints between the two objectives. Then, we propose an unsupervised Slot-Quality metric to assess per-slot quality, providing a principled signal for fine-grained slot--object binding. Based on this metric, we design a Quality-Guided Slot Selection scheme that dynamically selects a subset of high-quality slots and feeds them into our newly designed gated decoder for reconstruction during training. At inference, token-wise competition on slot attention yields a K-adaptive outcome. Experiments show that QASA substantially outperforms existing K-adaptive methods on both real and synthetic datasets. Moreover, on real-world datasets QASA surpasses K-fixed methods.

</details>


### [160] [TVWorld: Foundations for Remote-Control TV Agents](https://arxiv.org/abs/2601.13142)
*Zhantao Ma,Quanfeng Lu,Shuai Zhong,Dahai Yu,Ping Luo,Michael K. Ng*

Main category: cs.CV

TL;DR: 该论文提出了TVWorld基准和TVTheseus模型，专注于电视遥控导航任务，通过拓扑感知训练提升了模型性能，达到了SOTA水平。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要关注点按交互，而日常生活中常见的遥控交互（如电视导航）尚未得到充分探索。

Method: 提出了一个基于图的世界抽象TVWorld，并在此基础上开发了两个互补的基准TVWorld-N和TVWorld-G。进一步提出了一个拓扑感知训练框架，用于增强大型视觉语言模型的拓扑感知能力。

Result: TVTheseus在TVWorld-N上的成功率为68.3%，超过了Gemini 3 Flash等基线模型。

Conclusion: TVTheseus模型在TVWorld-N基准上达到了68.3%的成功率，超越了Gemini 3 Flash等闭源基线，并建立了最先进的性能。

Abstract: Recent large vision-language models (LVLMs) have demonstrated strong potential for device control. However, existing research has primarily focused on point-and-click (PnC) interaction, while remote-control (RC) interaction commonly encountered in everyday TV usage remains largely underexplored. To fill this gap, we introduce \textbf{TVWorld}, an offline graph-based abstraction of real-world TV navigation that enables reproducible and deployment-free evaluation. On this basis, we derive two complementary benchmarks that comprehensively assess TV-use capabilities: \textbf{TVWorld-N} for topology-aware navigation and \textbf{TVWorld-G} for focus-aware grounding. These benchmarks expose a key limitation of existing agents: insufficient topology awareness for focus-based, long-horizon TV navigation. Motivated by this finding, we propose a \emph{Topology-Aware Training} framework that injects topology awareness into LVLMs. Using this framework, we develop \textbf{TVTheseus}, a foundation model specialized for TV navigation. TVTheseus achieves a success rate of $68.3\%$ on TVWorld-N, surpassing strong closed-source baselines such as Gemini 3 Flash and establishing state-of-the-art (SOTA) performance. Additional analyses further provide valuable insights into the development of effective TV-use agents.

</details>


### [161] [GazeD: Context-Aware Diffusion for Accurate 3D Gaze Estimation](https://arxiv.org/abs/2601.12948)
*Riccardo Catalini,Davide Di Nucci,Guido Borghi,Davide Davoli,Lorenzo Garattoni,Giampiero Francesca,Yuki Kawana,Roberto Vezzani*

Main category: cs.CV

TL;DR: GazeD 是一种新的3D视线估计方法，通过扩散模型从单张RGB图像中联合估计3D视线和人体姿态，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 提出一种新的3D视线估计方法，能够从单张RGB图像中联合提供3D视线和人体姿态。

Method: GazeD 利用扩散模型处理不确定性的能力，基于输入图像提取的2D上下文信息生成多个可能的3D视线和姿态假设。去噪过程的条件包括2D姿态、主体周围环境和场景上下文。

Result: 在三个基准数据集上的评估显示，GazeD 在3D视线估计中表现优异。

Conclusion: GazeD 在3D视线估计中实现了最先进的性能，甚至超过了依赖时间信息的方法。

Abstract: We introduce GazeD, a new 3D gaze estimation method that jointly provides 3D gaze and human pose from a single RGB image. Leveraging the ability of diffusion models to deal with uncertainty, it generates multiple plausible 3D gaze and pose hypotheses based on the 2D context information extracted from the input image. Specifically, we condition the denoising process on the 2D pose, the surroundings of the subject, and the context of the scene. With GazeD we also introduce a novel way of representing the 3D gaze by positioning it as an additional body joint at a fixed distance from the eyes. The rationale is that the gaze is usually closely related to the pose, and thus it can benefit from being jointly denoised during the diffusion process. Evaluations across three benchmark datasets demonstrate that GazeD achieves state-of-the-art performance in 3D gaze estimation, even surpassing methods that rely on temporal information. Project details will be available at https://aimagelab.ing.unimore.it/go/gazed.

</details>


### [162] [From 100,000+ images to winning the first brain MRI foundation model challenges: Sharing lessons and models](https://arxiv.org/abs/2601.13166)
*Pedro M. Gordaliza,Jaume Banus,Benoît Gérin,Maxence Wynen,Nataliia Molchanova,Jonas Richiardi,Meritxell Bach Cuadra*

Main category: cs.CV

TL;DR: 提出了一种基于U-Net CNN的高效医学图像分析模型，在两项竞赛中夺冠，训练速度快且模型体积小。


<details>
  <summary>Details</summary>
Motivation: 开发基础模型以解决医学图像分析中的独特挑战，特别是在3D脑MRI领域。

Method: 采用U-Net CNN架构，结合解剖学先验知识和神经影像领域知识，优化模型训练。

Result: 模型训练速度比基于Transformer的方法快1-2个数量级，模型体积小10倍，并在竞赛中排名第一。

Conclusion: 该论文提出的基于U-Net CNN架构的解决方案在SSL3D和FOMO25竞赛中表现优异，证明了其在医学图像分析中的高效性和实用性。

Abstract: Developing Foundation Models for medical image analysis is essential to overcome the unique challenges of radiological tasks. The first challenges of this kind for 3D brain MRI, SSL3D and FOMO25, were held at MICCAI 2025. Our solution ranked first in tracks of both contests. It relies on a U-Net CNN architecture combined with strategies leveraging anatomical priors and neuroimaging domain knowledge. Notably, our models trained 1-2 orders of magnitude faster and were 10 times smaller than competing transformer-based approaches. Models are available here: https://github.com/jbanusco/BrainFM4Challenges.

</details>


### [163] [StyMam: A Mamba-Based Generator for Artistic Style Transfer](https://arxiv.org/abs/2601.12954)
*Zhou Hong,Rongsheng Hu,Yicheng Di,Xiaolong Xu,Ning Dong,Yihua Shao,Run Ling,Yun Wang,Juqin Wang,Zhanjie Zhang,Ao Ma*

Main category: cs.CV

TL;DR: 提出基于Mamba的生成器StyMam，通过双路径扫描和注意力模块改进风格迁移，实验显示其在质量与速度上均领先。


<details>
  <summary>Details</summary>
Motivation: 现有GAN或SD方法在图像风格迁移中存在局部与全局依赖关系难以兼顾、内容结构保留不足及推理速度慢等问题。

Method: 采用基于Mamba的生成器，结合残差双路径带状扫描机制和通道重加权空间注意力模块，分别捕捉局部纹理特征和全局依赖关系。

Result: 大量定性和定量实验证明，StyMam在质量和速度上均优于现有先进算法。

Conclusion: 提出的StyMam方法在图像风格迁移任务中表现优异，既避免了GAN和SD方法的缺陷，又提升了生成质量和速度。

Abstract: Image style transfer aims to integrate the visual patterns of a specific artistic style into a content image while preserving its content structure. Existing methods mainly rely on the generative adversarial network (GAN) or stable diffusion (SD). GAN-based approaches using CNNs or Transformers struggle to jointly capture local and global dependencies, leading to artifacts and disharmonious patterns. SD-based methods reduce such issues but often fail to preserve content structures and suffer from slow inference. To address these issues, we revisit GAN and propose a mamba-based generator, termed as StyMam, to produce high-quality stylized images without introducing artifacts and disharmonious patterns. Specifically, we introduce a mamba-based generator with a residual dual-path strip scanning mechanism and a channel-reweighted spatial attention module. The former efficiently captures local texture features, while the latter models global dependencies. Finally, extensive qualitative and quantitative experiments demonstrate that the proposed method outperforms state-of-the-art algorithms in both quality and speed.

</details>


### [164] [A Semantic Decoupling-Based Two-Stage Rainy-Day Attack for Revealing Weather Robustness Deficiencies in Vision-Language Models](https://arxiv.org/abs/2601.13238)
*Chengyin Hu,Xiang Chen,Zhe Jia,Weiwen Shi,Fengyu Zhang,Jiujiang Guo,Yiwei Wei*

Main category: cs.CV

TL;DR: 该论文提出首个利用真实雨天攻击VLMs的对抗框架，通过两阶段扰动模型分析雨致决策偏移，揭示主流模型在天气扰动下的语义对齐脆弱性。


<details>
  <summary>Details</summary>
Motivation: 研究VLMs在真实天气条件下的鲁棒性及其跨模态语义对齐的稳定性，填补现有研究中对雨天场景下对抗性攻击的空白。

Method: 采用两阶段参数化扰动模型：第一阶段通过低维全局调制建模降雨的全局效应，弱化原始语义决策边界；第二阶段显式建模多尺度雨滴外观和降雨引起的照明变化，优化不可微天气空间以诱导稳定的语义偏移。

Result: 实验表明，即使物理合理且高度约束的天气扰动也能导致主流VLMs的显著语义错位，照明建模和多尺度雨滴结构是语义偏移的关键驱动因素。

Conclusion: 该研究揭示了主流视觉语言模型（VLMs）在真实天气条件下的语义对齐稳定性问题，提出了一种基于语义解耦的两阶段对抗框架，通过物理合理的天气扰动引发显著的语义错位，为实际部署中的安全性和可靠性风险提供了新见解。

Abstract: Vision-Language Models (VLMs) are trained on image-text pairs collected under canonical visual conditions and achieve strong performance on multimodal tasks. However, their robustness to real-world weather conditions, and the stability of cross-modal semantic alignment under such structured perturbations, remain insufficiently studied. In this paper, we focus on rainy scenarios and introduce the first adversarial framework that exploits realistic weather to attack VLMs, using a two-stage, parameterized perturbation model based on semantic decoupling to analyze rain-induced shifts in decision-making. In Stage 1, we model the global effects of rainfall by applying a low-dimensional global modulation to condition the embedding space and gradually weaken the original semantic decision boundaries. In Stage 2, we introduce structured rain variations by explicitly modeling multi-scale raindrop appearance and rainfall-induced illumination changes, and optimize the resulting non-differentiable weather space to induce stable semantic shifts. Operating in a non-pixel parameter space, our framework generates perturbations that are both physically grounded and interpretable. Experiments across multiple tasks show that even physically plausible, highly constrained weather perturbations can induce substantial semantic misalignment in mainstream VLMs, posing potential safety and reliability risks in real-world deployment. Ablations further confirm that illumination modeling and multi-scale raindrop structures are key drivers of these semantic shifts.

</details>


### [165] [Cross-Scale Pretraining: Enhancing Self-Supervised Learning for Low-Resolution Satellite Imagery for Semantic Segmentation](https://arxiv.org/abs/2601.12964)
*John Waithaka,Gustave Bwirayesu,Moise Busogi*

Main category: cs.CV

TL;DR: 利用HR图像设计空间亲和力组件，提升MR图像自监督学习效果，优于单独使用HR或MR预训练。


<details>
  <summary>Details</summary>
Motivation: 探索如何利用高分辨率（HR）数据集增强中分辨率（MR）图像的自监督预训练及下游分割任务性能。

Method: 设计了空间亲和力组件，可集成到现有自监督学习框架中，利用HR图像优化MR图像的表征学习。

Result: 在两种自监督学习框架中测试表明，该方法优于单独使用HR或MR图像预训练的模型。

Conclusion: 通过在自监督学习框架中添加空间亲和力组件，利用高分辨率（HR）图像提升中分辨率（MR）图像的表征学习，显著提高了下游MR任务的性能。

Abstract: Self-supervised pretraining in remote sensing is mostly done using mid-spatial resolution (MR) image datasets due to their high availability. Given the release of high-resolution (HR) datasets, we ask how HR datasets can be included in self-supervised pretraining to enhance MR image representation learning and downstream segmentation performance on MR tasks. We design a spatial affinity component that can be added to existing self-supervised learning frameworks and that uses HR imagery to learn better representations of MR imagery. We test the spatial affinity component on two self-supervised learning frameworks and show that it outperforms models pretrained on HR or MR images alone.

</details>


### [166] [Early Prediction of Type 2 Diabetes Using Multimodal data and Tabular Transformers](https://arxiv.org/abs/2601.12981)
*Sulaiman Khan,Md. Rafiul Biswas,Zubair Shah*

Main category: cs.CV

TL;DR: 研究提出TabTrans架构用于早期2型糖尿病风险预测，通过分析纵向患者数据，模型表现优于传统方法，并识别出关键风险指标。


<details>
  <summary>Details</summary>
Motivation: 传统方法常忽视疾病进展中的复杂长期依赖关系，因此需要一种新方法来更准确地预测早期2型糖尿病风险。

Method: 研究采用tabular transformer（TabTrans）架构处理纵向患者数据和骨相关表格数据，结合SMOTE和SMOTE-ENN技术解决类别不平衡问题，并与传统机器学习及生成式AI模型进行比较。

Result: TabTrans模型在T2DM预测中表现优异，ROC AUC ≥ 79.7%，优于生成式AI模型和传统机器学习方法。特征分析确定了内脏脂肪组织（VAT）质量和体积、骨密度（BMD）和骨矿物质含量（BMC）等关键风险指标。

Conclusion: 该研究展示了TabTrans架构在早期2型糖尿病风险预测中的显著潜力，为卡塔尔人群提供了主动管理和个性化临床干预的强大工具。

Abstract: This study introduces a novel approach for early Type 2 Diabetes Mellitus (T2DM) risk prediction using a tabular transformer (TabTrans) architecture to analyze longitudinal patient data. By processing patients` longitudinal health records and bone-related tabular data, our model captures complex, long-range dependencies in disease progression that conventional methods often overlook. We validated our TabTrans model on a retrospective Qatar BioBank (QBB) cohort of 1,382 subjects, comprising 725 men (146 diabetic, 579 healthy) and 657 women (133 diabetic, 524 healthy). The study integrated electronic health records (EHR) with dual-energy X-ray absorptiometry (DXA) data. To address class imbalance, we employed SMOTE and SMOTE-ENN resampling techniques. The proposed model`s performance is evaluated against conventional machine learning (ML) and generative AI models, including Claude 3.5 Sonnet (Anthropic`s constitutional AI), GPT-4 (OpenAI`s generative pre-trained transformer), and Gemini Pro (Google`s multimodal language model). Our TabTrans model demonstrated superior predictive performance, achieving ROC AUC $\geq$ 79.7 % for T2DM prediction compared to both generative AI models and conventional ML approaches. Feature interpretation analysis identified key risk indicators, with visceral adipose tissue (VAT) mass and volume, ward bone mineral density (BMD) and bone mineral content (BMC), T and Z-scores, and L1-L4 scores emerging as the most important predictors associated with diabetes development in Qatari adults. These findings demonstrate the significant potential of TabTrans for analyzing complex tabular healthcare data, providing a powerful tool for proactive T2DM management and personalized clinical interventions in the Qatari population.
  Index Terms: tabular transformers, multimodal data, DXA data, diabetes, T2DM, feature interpretation, tabular data

</details>


### [167] [Organ-Aware Attention Improves CT Triage and Classification](https://arxiv.org/abs/2601.13385)
*Lavsen Dahal,Yubraj Bhandari,Geoffrey D. Rubin,Joseph Y. Lo*

Main category: cs.CV

TL;DR: ORACLE-CT模型通过器官掩码注意力和标量融合技术，在胸部和腹部CT分类中实现了最先进的性能。


<details>
  <summary>Details</summary>
Motivation: 解决高容量医学影像（如CT）的分类和分诊需求，改善患者护理并缓解放射科医生的工作压力。

Method: 研究采用了CT-RATE和RADCHEST-CT数据集，提出了ORACLE-CT模型，结合器官掩码注意力和器官标量融合技术。

Result: ORACLE-CT在胸部CT分类中AUROC达到0.86，在腹部CT分类中AUROC提升至0.85。

Conclusion: ORACLE-CT模型在胸部和腹部CT分类中均达到了最先进的监督分类性能，为医学影像分类提供了高效解决方案。

Abstract: There is an urgent need for triage and classification of high-volume medical imaging modalities such as computed tomography (CT), which can improve patient care and mitigate radiologist burnout. Study-level CT triage requires calibrated predictions with localized evidence; however, off-the-shelf Vision Language Models (VLM) struggle with 3D anatomy, protocol shifts, and noisy report supervision. This study used the two largest publicly available chest CT datasets: CT-RATE and RADCHEST-CT (held-out external test set). Our carefully tuned supervised baseline (instantiated as a simple Global Average Pooling head) establishes a new supervised state of the art, surpassing all reported linear-probe VLMs. Building on this baseline, we present ORACLE-CT, an encoder-agnostic, organ-aware head that pairs Organ-Masked Attention (mask-restricted, per-organ pooling that yields spatial evidence) with Organ-Scalar Fusion (lightweight fusion of normalized volume and mean-HU cues). In the chest setting, ORACLE-CT masked attention model achieves AUROC 0.86 on CT-RATE; in the abdomen setting, on MERLIN (30 findings), our supervised baseline exceeds a reproduced zero-shot VLM baseline obtained by running publicly released weights through our pipeline, and adding masked attention plus scalar fusion further improves performance to AUROC 0.85. Together, these results deliver state-of-the-art supervised classification performance across both chest and abdomen CT under a unified evaluation protocol. The source code is available at https://github.com/lavsendahal/oracle-ct.

</details>


### [168] [AsyncBEV: Cross-modal Flow Alignment in Asynchronous 3D Object Detection](https://arxiv.org/abs/2601.12994)
*Shiming Wang,Holger Caesar,Liangliang Nan,Julian F. P. Kooij*

Main category: cs.CV

TL;DR: AsyncBEV通过特征流对齐解决传感器异步问题，显著提升动态物体检测性能。


<details>
  <summary>Details</summary>
Motivation: 多模态感知任务中的传感器异步问题（如不同频率、网络延迟等）会降低感知性能，尤其是动态物体。

Method: AsyncBEV通过估计两种不同传感器模态的BEV特征的2D流，并利用预测的特征流对特征图进行空间对齐，可轻松集成到现有的BEV检测器架构中。

Result: 在LiDAR或相机传感器异步情况下，AsyncBEV显著提升了CMT和UniBEV的鲁棒性，动态物体检测性能在0.5秒时间偏移的最坏情况下分别提升了16.6%和11.9% NDS。

Conclusion: AsyncBEV是一个可训练的轻量级通用模块，显著提高了3D BEV目标检测模型对传感器异步的鲁棒性，尤其在动态物体上表现突出。

Abstract: In autonomous driving, multi-modal perception tasks like 3D object detection typically rely on well-synchronized sensors, both at training and inference. However, despite the use of hardware- or software-based synchronization algorithms, perfect synchrony is rarely guaranteed: Sensors may operate at different frequencies, and real-world factors such as network latency, hardware failures, or processing bottlenecks often introduce time offsets between sensors. Such asynchrony degrades perception performance, especially for dynamic objects. To address this challenge, we propose AsyncBEV, a trainable lightweight and generic module to improve the robustness of 3D Birds' Eye View (BEV) object detection models against sensor asynchrony. Inspired by scene flow estimation, AsyncBEV first estimates the 2D flow from the BEV features of two different sensor modalities, taking into account the known time offset between these sensor measurements. The predicted feature flow is then used to warp and spatially align the feature maps, which we show can easily be integrated into different current BEV detector architectures (e.g., BEV grid-based and token-based). Extensive experiments demonstrate AsyncBEV improves robustness against both small and large asynchrony between LiDAR or camera sensors in both the token-based CMT and grid-based UniBEV, especially for dynamic objects. We significantly outperform the ego motion compensated CMT and UniBEV baselines, notably by $16.6$ % and $11.9$ % NDS on dynamic objects in the worst-case scenario of a $0.5 s$ time offset. Code will be released upon acceptance.

</details>


### [169] [Deep Image Prior with L0 Gradient Regularizer for Image Smoothing](https://arxiv.org/abs/2601.13400)
*Nhat Thanh Tran,Kevin Bui,Jack Xin*

Main category: cs.CV

TL;DR: DIP-ℓ0是一种无需训练数据的图像平滑方法，结合ℓ0正则化，通过ADMM优化，在边缘保留和JPEG伪影去除中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法需要精心构建的训练数据集，而构建适合图像平滑的数据集具有挑战性。

Method: 提出了一种结合ℓ0梯度正则化的深度图像先验框架（DIP-ℓ0），并开发了基于ADMM的优化算法。

Result: 数值实验表明，DIP-ℓ0在边缘保留和JPEG伪影去除任务中优于多种图像平滑算法。

Conclusion: DIP-ℓ0框架在无需训练数据的情况下，实现了高质量的图像平滑，且在边缘保留和JPEG伪影去除方面优于现有算法。

Abstract: Image smoothing is a fundamental image processing operation that preserves the underlying structure, such as strong edges and contours, and removes minor details and textures in an image. Many image smoothing algorithms rely on computing local window statistics or solving an optimization problem. Recent state-of-the-art methods leverage deep learning, but they require a carefully curated training dataset. Because constructing a proper training dataset for image smoothing is challenging, we propose DIP-$\ell_0$, a deep image prior framework that incorporates the $\ell_0$ gradient regularizer. This framework can perform high-quality image smoothing without any training data. To properly minimize the associated loss function that has the nonconvex, nonsmooth $\ell_0$ ``norm", we develop an alternating direction method of multipliers algorithm that utilizes an off-the-shelf $\ell_0$ gradient minimization solver. Numerical experiments demonstrate that the proposed DIP-$\ell_0$ outperforms many image smoothing algorithms in edge-preserving image smoothing and JPEG artifact removal.

</details>


### [170] [Think3D: Thinking with Space for Spatial Reasoning](https://arxiv.org/abs/2601.13029)
*Zaibin Zhang,Yuhan Wu,Lianjie Jia,Yifan Wang,Zhongbo Zhang,Yijiang Li,Binghao Ran,Fuxi Zhang,Zhuohan Sun,Zhenfei Yin,Lijun Wang,Huchuan Lu*

Main category: cs.CV

TL;DR: Think3D框架通过3D重建和交互式操作提升视觉大模型的3D推理能力，无需额外训练即可显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 当前视觉大模型（VLMs）在2D感知上表现出色，但在真正的3D推理方面存在困难，因此需要一种方法提升其空间推理能力。

Method: 利用3D重建模型从图像或视频中恢复点云和相机姿态，通过基于相机的操作和自我/全局视图切换，将空间推理转化为交互式的3D思维链过程。

Result: Think3D显著提升了GPT-4.1和Gemini 2.5 Pro等先进模型的空间推理性能，在BLINK Multi-view和MindCube上平均提升7.8%，在VSI-Bench上提升4.7%。通过强化学习策略，较小模型的空间探索能力从+0.7%提升至+6.8%。

Conclusion: Think3D通过结合3D重建模型和交互式空间操作，显著提升了多模态代理的3D推理能力，为更灵活、类人的空间智能开辟了新途径。

Abstract: Understanding and reasoning about the physical world requires spatial intelligence: the ability to interpret geometry, perspective, and spatial relations beyond 2D perception. While recent vision large models (VLMs) excel at visual understanding, they remain fundamentally 2D perceivers and struggle with genuine 3D reasoning. We introduce Think3D, a framework that enables VLM agents to think with 3D space. By leveraging 3D reconstruction models that recover point clouds and camera poses from images or videos, Think3D allows the agent to actively manipulate space through camera-based operations and ego/global-view switching, transforming spatial reasoning into an interactive 3D chain-of-thought process. Without additional training, Think3D significantly improves the spatial reasoning performance of advanced models such as GPT-4.1 and Gemini 2.5 Pro, yielding average gains of +7.8% on BLINK Multi-view and MindCube, and +4.7% on VSI-Bench. We further show that smaller models, which struggle with spatial exploration, benefit significantly from a reinforcement learning policy that enables the model to select informative viewpoints and operations. With RL, the benefit from tool usage increases from +0.7% to +6.8%. Our findings demonstrate that training-free, tool-augmented spatial exploration is a viable path toward more flexible and human-like 3D reasoning in multimodal agents, establishing a new dimension of multimodal intelligence. Code and weights are released at https://github.com/zhangzaibin/spagent.

</details>


### [171] [Reasoning with Pixel-level Precision: QVLM Architecture and SQuID Dataset for Quantitative Geospatial Analytics](https://arxiv.org/abs/2601.13401)
*Peter A. Massih,Eric Cosatto*

Main category: cs.CV

TL;DR: 论文提出QVLM模型和SQuID数据集，通过解耦语言与视觉处理提升定量空间推理准确性，实验显示QVLM显著优于传统VLM。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型（VLMs）在定量空间推理上表现不佳，因为其架构破坏了计数和测量所需的像素级信息。

Method: 提出QVLM（定量视觉语言模型），一种代码生成架构，通过将语言理解与视觉分析解耦来保持像素精度。QVLM生成可执行代码，首先调用分割模型获取像素级掩码，然后直接在这些掩码上操作，保持空间索引。

Result: QVLM使用GPT-5作为编码器，在SQuID基准上达到42.0%的准确率，优于直接使用图像-问题对的VLM（28.1%）。

Conclusion: 对于定量空间推理任务，架构解耦能够提升准确性。

Abstract: Current Vision-Language Models (VLMs) fail at quantitative spatial reasoning because their architectures destroy pixel-level information required for counting and measurements. Vision encoders compress images through patch embeddings, reducing spatial indexing and losing the precise pixel-level tracking required for accurate counting. We present two contributions to address this fundamental limitation. First, we introduce SQuID (Satellite Quantitative Intelligence Dataset), a benchmark of 2,000 satellite image Question-Answer pairs with both numerical range and categorical answers, designed to evaluate quantitative spatial reasoning. The dataset spans three difficulty tiers with annotations automatically generated from human labels and their learned variability. Second, we propose QVLM (Quantitative Vision-Language Model), a code-generation architecture that maintains pixel precision by decoupling language understanding from visual analysis. Instead of encoding images into embeddings, QVLM generates executable code that first calls a segmentation model to obtain pixel-level masks, then operates directly on these masks, preserving spatial indexing throughout the reasoning process. Our experiments show that QVLM using GPT-5 as coder achieves 42.0% accuracy on SQuID compared to 28.1% for a VLM prompted with image-question pairs. Our work reveals that, for quantitative spatial reasoning, architectural decoupling enables better accuracy on quantitative tasks.

</details>


### [172] [GridNet-HD: A High-Resolution Multi-Modal Dataset for LiDAR-Image Fusion on Power Line Infrastructure](https://arxiv.org/abs/2601.13052)
*Antoine Carreaud,Shanci Li,Malo De Lacour,Digre Frinde,Jan Skaloud,Adrien Gressin*

Main category: cs.CV

TL;DR: GridNet-HD是一个结合高密度LiDAR与高分辨率倾斜影像的多模态数据集，用于电力线资产的三维语义分割，融合模型性能显著优于单模态。


<details>
  <summary>Details</summary>
Motivation: 目前缺乏同时提供高密度LiDAR、高分辨率倾斜影像及三维语义标签的公开数据集，GridNet-HD旨在解决这一问题。

Method: 通过多模态融合（LiDAR与倾斜影像）进行三维语义分割，提供了单模态（仅LiDAR或仅影像）和多模态融合的基线模型。

Result: 在多模态融合模型中，性能较最佳单模态基线提升了+5.55 mIoU，证明了几何与外观信息的互补性。

Conclusion: GridNet-HD数据集填补了高密度LiDAR与高分辨率倾斜影像联合标注的空白，为电力线资产的三维语义分割提供了重要资源。

Abstract: This paper presents GridNet-HD, a multi-modal dataset for 3D semantic segmentation of overhead electrical infrastructures, pairing high-density LiDAR with high-resolution oblique imagery. The dataset comprises 7,694 images and 2.5 billion points annotated into 11 classes, with predefined splits and mIoU metrics. Unimodal (LiDAR-only, image-only) and multi-modal fusion baselines are provided. On GridNet-HD, fusion models outperform the best unimodal baseline by +5.55 mIoU, highlighting the complementarity of geometry and appearance. As reviewed in Sec. 2, no public dataset jointly provides high-density LiDAR and high-resolution oblique imagery with 3D semantic labels for power-line assets. Dataset, baselines, and codes are available: https://huggingface.co/collections/heig-vd-geo/gridnet-hd.

</details>


### [173] [Local-to-Global Logical Explanations for Deep Vision Models](https://arxiv.org/abs/2601.13404)
*Bhavan Vasu,Giuseppe Raffa,Prasad Tadepalli*

Main category: cs.CV

TL;DR: 提出了一种基于原始概念的可解释性方法，通过逻辑公式和单调解释列表，为黑盒模型提供高保真度的局部和全局解释。


<details>
  <summary>Details</summary>
Motivation: 深度神经网络虽在图像分类中高效，但其不透明且难以解释。

Method: 提出了局部和全局解释方法，将解释转化为人类可识别的原始概念的逻辑公式（单调析取范式，MDNF），并展示了用于多类分类解释的单调解释列表算法。

Result: 解释方法在保持高保真度和覆盖率的同时，提供了可理解的局部和全局解释。

Conclusion: 尽管简单且可解释性强，所提出的解释方法在具有挑战性的视觉数据集中保持了高保真度和覆盖率。

Abstract: While deep neural networks are extremely effective at classifying images, they remain opaque and hard to interpret. We introduce local and global explanation methods for black-box models that generate explanations in terms of human-recognizable primitive concepts. Both the local explanations for a single image and the global explanations for a set of images are cast as logical formulas in monotone disjunctive-normal-form (MDNF), whose satisfaction guarantees that the model yields a high score on a given class. We also present an algorithm for explaining the classification of examples into multiple classes in the form of a monotone explanation list over primitive concepts. Despite their simplicity and interpretability we show that the explanations maintain high fidelity and coverage with respect to the blackbox models they seek to explain in challenging vision datasets.

</details>


### [174] [Prototype Learning-Based Few-Shot Segmentation for Low-Light Crack on Concrete Structures](https://arxiv.org/abs/2601.13059)
*Yulun Guo*

Main category: cs.CV

TL;DR: 提出一种结合Retinex和少样本学习的双分支网络，用于低光照裂缝分割，减少对标注数据的依赖并提升精度。


<details>
  <summary>Details</summary>
Motivation: 现实世界中的裂缝常出现在低光照环境（如隧道、桥梁底部），传统计算机视觉分割方法在这些条件下精度下降，且像素级标注耗时。现有深度学习方法通常需要大量光照良好的数据集，难以适应低光照场景。

Method: 采用双分支原型学习网络，结合Retinex理论（基于反射分量学习光照不变的全局表示）和度量学习（减少对大标注数据集的依赖）。通过交叉相似性先验掩码生成模块和多尺度特征增强模块，优化裂缝位置和结构的捕捉。

Result: 在多个基准测试中，该方法在低光照条件下表现优于现有技术，展示了其优越性和鲁棒性。

Conclusion: 该论文提出了一种结合Retinex理论和少样本学习的双分支原型学习网络，用于低光照条件下的裂缝分割，显著提高了分割精度，并在多个基准测试中展示了最先进的性能。

Abstract: Crack detection is critical for concrete infrastructure safety, but real-world cracks often appear in low-light environments like tunnels and bridge undersides, degrading computer vision segmentation accuracy. Pixel-level annotation of low-light crack images is extremely time-consuming, yet most deep learning methods require large, well-illuminated datasets. We propose a dual-branch prototype learning network integrating Retinex theory with few-shot learning for low-light crack segmentation. Retinex-based reflectance components guide illumination-invariant global representation learning, while metric learning reduces dependence on large annotated datasets. We introduce a cross-similarity prior mask generation module that computes high-dimensional similarities between query and support features to capture crack location and structure, and a multi-scale feature enhancement module that fuses multi-scale features with the prior mask to alleviate spatial inconsistency. Extensive experiments on multiple benchmarks demonstrate consistent state-of-the-art performance under low-light conditions. Code: https://github.com/YulunGuo/CrackFSS.

</details>


### [175] [Using deep learning for predicting cleansing quality of colon capsule endoscopy images](https://arxiv.org/abs/2601.13412)
*Puneet Sharma,Kristian Dalsbø Hindberg,Benedicte Schelde-Olesen,Ulrik Deding,Esmaeil S. Nadimi,Jan-Matthias Braun*

Main category: cs.CV

TL;DR: 研究通过ResNet-18和剪枝技术，在CCE图像清洁质量预测中实现高效且可解释的模型，准确率达88%。


<details>
  <summary>Details</summary>
Motivation: 探索深度学习技术在结肠胶囊内窥镜（CCE）图像清洁质量预测中的应用，解决临床评估的挑战。

Method: 使用ResNet-18模型进行训练，并采用分层K折交叉验证确保性能。通过结构化剪枝技术优化模型，并利用多种CAM方法评估模型解释性。

Result: 剪枝后的模型在交叉验证中达到88%的准确率和79%的稀疏度，效率从84%提升至88%且未牺牲性能。

Conclusion: 研究表明，通过结构化剪枝技术可以在保持高准确率的同时显著提升模型效率，并强调了在临床应用中解释性的重要性。

Abstract: In this study, we explore the application of deep learning techniques for predicting cleansing quality in colon capsule endoscopy (CCE) images. Using a dataset of 500 images labeled by 14 clinicians on the Leighton-Rex scale (Poor, Fair, Good, and Excellent), a ResNet-18 model was trained for classification, leveraging stratified K-fold cross-validation to ensure robust performance. To optimize the model, structured pruning techniques were applied iteratively, achieving significant sparsity while maintaining high accuracy. Explainability of the pruned model was evaluated using Grad-CAM, Grad-CAM++, Eigen-CAM, Ablation-CAM, and Random-CAM, with the ROAD method employed for consistent evaluation. Our results indicate that for a pruned model, we can achieve a cross-validation accuracy of 88% with 79% sparsity, demonstrating the effectiveness of pruning in improving efficiency from 84% without compromising performance. We also highlight the challenges of evaluating cleansing quality of CCE images, emphasize the importance of explainability in clinical applications, and discuss the challenges associated with using the ROAD method for our task. Finally, we employ a variant of adaptive temperature scaling to calibrate the pruned models for an external dataset.

</details>


### [176] [Patient-Conditioned Adaptive Offsets for Reliable Diagnosis across Subgroups](https://arxiv.org/abs/2601.13094)
*Gelei Xu,Yuying Duan,Jun Xia,Ruining Deng,Wei Jin,Yiyu Shi*

Main category: cs.CV

TL;DR: HyperAdapt通过患者条件化适应提升医疗AI子群体可靠性，不牺牲整体准确性。


<details>
  <summary>Details</summary>
Motivation: 医疗AI模型在不同患者群体中表现不均，现有公平性方法可能牺牲关键诊断信息。HyperAdapt旨在保留共享医学知识的同时，针对患者特异性进行调整。

Method: 引入HyperAdapt框架，将临床相关属性编码为紧凑嵌入，通过超网络风格模块生成小残差调制参数，用于共享骨干网络的选定层。

Result: 在多个公共医疗影像基准测试中，HyperAdapt显著提升子群体性能，如在PAD-UFES-20数据集上，召回率和F1分数分别提高4.1%和4.4%。

Conclusion: HyperAdapt框架通过患者条件化适应显著提升了医疗AI模型在子群体中的可靠性，同时保持了共享诊断模型的整体准确性。

Abstract: AI models for medical diagnosis often exhibit uneven performance across patient populations due to heterogeneity in disease prevalence, imaging appearance, and clinical risk profiles. Existing algorithmic fairness approaches typically seek to reduce such disparities by suppressing sensitive attributes. However, in medical settings these attributes often carry essential diagnostic information, and removing them can degrade accuracy and reliability, particularly in high-stakes applications. In contrast, clinical decision making explicitly incorporates patient context when interpreting diagnostic evidence, suggesting a different design direction for subgroup-aware models. In this paper, we introduce HyperAdapt, a patient-conditioned adaptation framework that improves subgroup reliability while maintaining a shared diagnostic model. Clinically relevant attributes such as age and sex are encoded into a compact embedding and used to condition a hypernetwork-style module, which generates small residual modulation parameters for selected layers of a shared backbone. This design preserves the general medical knowledge learned by the backbone while enabling targeted adjustments that reflect patient-specific variability. To ensure efficiency and robustness, adaptations are constrained through low-rank and bottlenecked parameterizations, limiting both model complexity and computational overhead. Experiments across multiple public medical imaging benchmarks demonstrate that the proposed approach consistently improves subgroup-level performance without sacrificing overall accuracy. On the PAD-UFES-20 dataset, our method outperforms the strongest competing baseline by 4.1% in recall and 4.4% in F1 score, with larger gains observed for underrepresented patient populations.

</details>


### [177] [CARPE: Context-Aware Image Representation Prioritization via Ensemble for Large Vision-Language Models](https://arxiv.org/abs/2601.13622)
*Donghee Lee,Rui Cai,Zhe Zhao*

Main category: cs.CV

TL;DR: CARPE通过动态权衡视觉与文本模态，提升LVLMs在视觉任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 解决LVLMs在视觉中心任务（如图像分类）中表现不佳的问题，尤其是与基础视觉编码器相比。

Method: 提出CARPE框架，引入视觉集成层和上下文感知集成策略，动态权衡视觉与文本模态。

Result: CARPE在图像分类和视觉语言基准测试中均取得一致性的性能提升。

Conclusion: CARPE是一种模型无关的框架，通过视觉集成层和上下文感知集成策略，有效提升了LVLMs在图像分类和视觉语言任务中的性能，并展示了广泛的适应性。

Abstract: Recent advancements in Large Vision-Language Models (LVLMs) have pushed them closer to becoming general-purpose assistants. Despite their strong performance, LVLMs still struggle with vision-centric tasks such as image classification, underperforming compared to their base vision encoders, which are often CLIP-based models. To address this limitation, we propose Context-Aware Image Representation Prioritization via Ensemble (CARPE), a novel, model-agnostic framework which introduces vision-integration layers and a context-aware ensemble strategy to identify when to prioritize image representations or rely on the reasoning capabilities of the language model. This design enhances the model's ability to adaptively weight visual and textual modalities and enables the model to capture various aspects of image representations, leading to consistent improvements in generalization across classification and vision-language benchmarks. Extensive experiments demonstrate that CARPE not only improves performance on image classification benchmarks but also enhances results across various vision-language benchmarks. Finally, CARPE is designed to be effectively integrated with most open-source LVLMs that consist of a vision encoder and a language model, ensuring its adaptability across diverse architectures.

</details>


### [178] [A Streamlined Attention-Based Network for Descriptor Extraction](https://arxiv.org/abs/2601.13126)
*Mattia D'Urso,Emanuele Santellani,Christian Sormann,Mattia Rossi,Andreas Kuhn,Friedrich Fraundorfer*

Main category: cs.CV

TL;DR: SANDesc是一种高效的关键点描述符网络，通过注意力机制和残差路径提升匹配性能，参数少且计算高效。


<details>
  <summary>Details</summary>
Motivation: 提升关键点描述符的匹配性能，同时不增加计算复杂度。

Method: 采用改进的U-Net架构，结合卷积块注意力模块和残差路径，使用改进的三元组损失和课程学习策略进行训练。

Result: 在多个数据集上表现优于原始描述符，模型参数仅240万，计算资源需求低。

Conclusion: SANDesc通过优化的注意力机制和残差路径，在不改变现有关键点检测器的情况下显著提升了描述符的匹配性能，同时保持了计算效率。

Abstract: We introduce SANDesc, a Streamlined Attention-Based Network for Descriptor extraction that aims to improve on existing architectures for keypoint description.
  Our descriptor network learns to compute descriptors that improve matching without modifying the underlying keypoint detector. We employ a revised U-Net-like architecture enhanced with Convolutional Block Attention Modules and residual paths, enabling effective local representation while maintaining computational efficiency. We refer to the building blocks of our model as Residual U-Net Blocks with Attention. The model is trained using a modified triplet loss in combination with a curriculum learning-inspired hard negative mining strategy, which improves training stability.
  Extensive experiments on HPatches, MegaDepth-1500, and the Image Matching Challenge 2021 show that training SANDesc on top of existing keypoint detectors leads to improved results on multiple matching tasks compared to the original keypoint descriptors. At the same time, SANDesc has a model complexity of just 2.4 million parameters.
  As a further contribution, we introduce a new urban dataset featuring 4K images and pre-calibrated intrinsics, designed to evaluate feature extractors. On this benchmark, SANDesc achieves substantial performance gains over the existing descriptors while operating with limited computational resources.

</details>


### [179] [PhaseMark: A Post-hoc, Optimization-Free Watermarking of AI-generated Images in the Latent Frequency Domain](https://arxiv.org/abs/2601.13128)
*Sung Ju Lee,Nam Ik Cho*

Main category: cs.CV

TL;DR: PhaseMark 是一种快速、抗攻击的水印框架，通过调制 VAE 潜在频率域的相位实现高效水印，无需迭代优化。


<details>
  <summary>Details</summary>
Motivation: 现有后处理水印方法因迭代优化或反转过程导致速度过慢，无法满足实际需求。

Method: PhaseMark 直接在 VAE 潜在频率域调制相位，避免了迭代优化或反转过程，显著提升了速度。

Result: PhaseMark 速度比基于优化的方法快数千倍，且在严重攻击（如再生）下仍保持最先进的抗性，且不影响图像质量。

Conclusion: PhaseMark 提出了一种利用 VAE 潜在频率域相位调制的单次优化自由框架，实现了高效且抗攻击的水印技术，为水印领域提供了新的范式。

Abstract: The proliferation of hyper-realistic images from Latent Diffusion Models (LDMs) demands robust watermarking, yet existing post-hoc methods are prohibitively slow due to iterative optimization or inversion processes. We introduce PhaseMark, a single-shot, optimization-free framework that directly modulates the phase in the VAE latent frequency domain. This approach makes PhaseMark thousands of times faster than optimization-based techniques while achieving state-of-the-art resilience against severe attacks, including regeneration, without degrading image quality. We analyze four modulation variants, revealing a clear performance-quality trade-off. PhaseMark demonstrates a new paradigm where efficient, resilient watermarking is achieved by exploiting intrinsic latent properties.

</details>


### [180] [GaussExplorer: 3D Gaussian Splatting for Embodied Exploration and Reasoning](https://arxiv.org/abs/2601.13132)
*Kim Yu-Ji,Dahye Lee,Kim Jun-Seong,GeonU Kim,Nam Hyeon-Woo,Yongjin Kwon,Yu-Chiang Frank Wang,Jaesung Choe,Tae-Hyun Oh*

Main category: cs.CV

TL;DR: GaussExplorer结合VLM与3DGS，提升复杂语言查询的解释能力，实验表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有语言嵌入3DGS方法对复杂组合查询解释能力不足，而基于RGB-D结构化记忆的方法受限于固定视角。

Method: 在3DGS基础上引入VLM，首先识别与查询问题最相关的预捕获图像，随后调整至新视角以获取更准确的视觉信息供VLM推理。

Result: 实验证明，GaussExplorer在多个基准测试中表现优于现有方法。

Conclusion: GaussExplorer通过将视觉语言模型（VLM）与3D高斯泼溅（3DGS）结合，显著提升了复杂组合语言查询的解释能力，并在多个基准测试中优于现有方法。

Abstract: We present GaussExplorer, a framework for embodied exploration and reasoning built on 3D Gaussian Splatting (3DGS). While prior approaches to language-embedded 3DGS have made meaningful progress in aligning simple text queries with Gaussian embeddings, they are generally optimized for relatively simple queries and struggle to interpret more complex, compositional language queries. Alternative studies based on object-centric RGB-D structured memories provide spatial grounding but are constrained by pre-fixed viewpoints. To address these issues, GaussExplorer introduces Vision-Language Models (VLMs) on top of 3DGS to enable question-driven exploration and reasoning within 3D scenes. We first identify pre-captured images that are most correlated with the query question, and subsequently adjust them into novel viewpoints to more accurately capture visual information for better reasoning by VLMs. Experiments show that ours outperforms existing methods on several benchmarks, demonstrating the effectiveness of integrating VLM-based reasoning with 3DGS for embodied tasks.

</details>


### [181] [Attention-space Contrastive Guidance for Efficient Hallucination Mitigation in LVLMs](https://arxiv.org/abs/2601.13707)
*Yujin Jo,Sangyoon Bae,Taesup Kim*

Main category: cs.CV

TL;DR: ACG通过单次前向计算和正交化校正，有效减少LVLMs中的幻觉问题，提升描述质量并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 解决大型视觉语言模型（LVLMs）中因语言先验主导导致的幻觉问题，如对象误识别和视觉不一致描述。

Method: 提出了Attention-space Contrastive Guidance (ACG)，一种单次前向计算机制，通过自注意力层构建视觉-语言和纯语言注意力路径，并结合正交化校正以减少语言路径的偏差。

Result: ACG在CHAIR和POPE基准测试中表现优异，显著提升了忠实性和描述质量，同时计算成本降低2倍。

Conclusion: ACG方法通过单次前向计算和正交化校正，显著降低了计算成本，同时在CHAIR和POPE基准测试中实现了最先进的忠实性和描述质量。

Abstract: Hallucinations in large vision-language models (LVLMs) often arise when language priors dominate over visual evidence, causing object misidentification and visually inconsistent descriptions. We address this issue by framing hallucination mitigation as contrastive guidance, steering generation toward visually grounded and semantically faithful text. This approach regulates the model's internal behavior by reducing over-dependence on language priors and contrasting visually grounded with language-only representations. We propose Attention-space Contrastive Guidance (ACG), a single-pass mechanism that operates within self-attention layers to construct both vision-language and language-only attention paths in a single forward computation. This integration enables computationally efficient guidance directly embedded in the model's representation contextualization. To correct approximation bias introduced by the single-pass formulation, we further apply an orthogonalized correction that removes components aligned with the language-only path, selectively amplifying visual contributions. Experiments on the CHAIR and POPE benchmarks show that ACG achieves state-of-the-art faithfulness and caption quality while significantly reducing computational cost. Our method establishes a principled and efficient alternative, reducing latency by up to 2x compared to prior contrastive decoding methods that require multiple forward passes.

</details>


### [182] [CLIP-Guided Adaptable Self-Supervised Learning for Human-Centric Visual Tasks](https://arxiv.org/abs/2601.13133)
*Mingshuang Luo,Ruibing Hou,Bo Chao,Hong Chang,Zimo Liu,Yaowei Wang,Shiguang Shan*

Main category: cs.CV

TL;DR: CLASP是一种新型无监督预训练框架，利用CLIP生成多级语义伪标签，通过MoE模块动态适配任务需求，显著提升人类中心视觉任务性能。


<details>
  <summary>Details</summary>
Motivation: 随着大规模无标签人类图像数据集的涌现，需要一种通用的无监督预训练模型来支持多样化的人类中心下游任务。

Method: CLASP利用CLIP生成低层次（如身体部位）和高层次（如属性）语义伪标签，并通过Prompt-Controlled MoE模块动态调整特征提取，结合多任务预训练策略优化表示学习。

Result: 在多个基准测试中，CLASP consistently outperforms existing unsupervised pre-training methods。

Conclusion: CLASP框架通过结合CLIP生成的多层次语义伪标签和Prompt-Controlled MoE模块，显著提升了无监督预训练模型在人类中心视觉任务中的表现，推动了该领域的进步。

Abstract: Human-centric visual analysis plays a pivotal role in diverse applications, including surveillance, healthcare, and human-computer interaction. With the emergence of large-scale unlabeled human image datasets, there is an increasing need for a general unsupervised pre-training model capable of supporting diverse human-centric downstream tasks. To achieve this goal, we propose CLASP (CLIP-guided Adaptable Self-suPervised learning), a novel framework designed for unsupervised pre-training in human-centric visual tasks. CLASP leverages the powerful vision-language model CLIP to generate both low-level (e.g., body parts) and high-level (e.g., attributes) semantic pseudo-labels. These multi-level semantic cues are then integrated into the learned visual representations, enriching their expressiveness and generalizability. Recognizing that different downstream tasks demand varying levels of semantic granularity, CLASP incorporates a Prompt-Controlled Mixture-of-Experts (MoE) module. MoE dynamically adapts feature extraction based on task-specific prompts, mitigating potential feature conflicts and enhancing transferability. Furthermore, CLASP employs a multi-task pre-training strategy, where part- and attribute-level pseudo-labels derived from CLIP guide the representation learning process. Extensive experiments across multiple benchmarks demonstrate that CLASP consistently outperforms existing unsupervised pre-training methods, advancing the field of human-centric visual analysis.

</details>


### [183] [Hierarchical Long Video Understanding with Audiovisual Entity Cohesion and Agentic Search](https://arxiv.org/abs/2601.13719)
*Xinlei Yin,Xiulian Peng,Xiao Li,Zhiwei Xiong,Yan Lu*

Main category: cs.CV

TL;DR: HAVEN框架通过结构化多模态推理和代理搜索，显著提升了长视频理解的连贯性和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于分块策略和检索增强生成方法在长视频理解中存在的信息碎片化和全局连贯性丢失问题。

Method: HAVEN框架通过整合视听实体级表示和层次化视频索引（全局摘要、场景、片段和实体级别），并采用代理搜索机制进行动态检索和推理。

Result: 在LVBench上达到84.1%的整体准确率，在具有挑战性的推理类别中达到80.1%，展示了在长视频理解中的优越性能。

Conclusion: HAVEN框架通过整合视听实体凝聚力和层次化视频索引与代理搜索，实现了长视频理解的连贯性和全面性，显著提升了性能，特别是在LVBench上达到了84.1%的整体准确率。

Abstract: Long video understanding presents significant challenges for vision-language models due to extremely long context windows. Existing solutions relying on naive chunking strategies with retrieval-augmented generation, typically suffer from information fragmentation and a loss of global coherence. We present HAVEN, a unified framework for long-video understanding that enables coherent and comprehensive reasoning by integrating audiovisual entity cohesion and hierarchical video indexing with agentic search. First, we preserve semantic consistency by integrating entity-level representations across visual and auditory streams, while organizing content into a structured hierarchy spanning global summary, scene, segment, and entity levels. Then we employ an agentic search mechanism to enable dynamic retrieval and reasoning across these layers, facilitating coherent narrative reconstruction and fine-grained entity tracking. Extensive experiments demonstrate that our method achieves good temporal coherence, entity consistency, and retrieval efficiency, establishing a new state-of-the-art with an overall accuracy of 84.1% on LVBench. Notably, it achieves outstanding performance in the challenging reasoning category, reaching 80.1%. These results highlight the effectiveness of structured, multimodal reasoning for comprehensive and context-consistent understanding of long-form videos.

</details>


### [184] [Insight: Interpretable Semantic Hierarchies in Vision-Language Encoders](https://arxiv.org/abs/2601.13798)
*Kai Wittenmayer,Sukrut Rao,Amin Parchami-Araghi,Bernt Schiele,Jonas Fischer*

Main category: cs.CV

TL;DR: Insight是一种语言对齐的概念基础模型，通过分层稀疏自编码器提取细粒度、可解释的概念，提升空间定位和任务泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有语言对齐视觉基础模型表示不透明、空间定位差且仅限于图像分类任务的问题。

Method: 采用分层稀疏自编码器和具有强语义表示的基础模型，自动提取不同粒度的概念，并通过概念间的局部共现依赖关系定义概念关系。

Result: 在基准数据上，Insight在分类和分割任务中表现竞争力，并提供高质量的概念解释。

Conclusion: Insight模型在保持与不透明基础模型竞争性能的同时，提供了细粒度、高质量的概念解释。

Abstract: Language-aligned vision foundation models perform strongly across diverse downstream tasks. Yet, their learned representations remain opaque, making interpreting their decision-making hard. Recent works decompose these representations into human-interpretable concepts, but provide poor spatial grounding and are limited to image classification tasks. In this work, we propose Insight, a language-aligned concept foundation model that provides fine-grained concepts, which are human-interpretable and spatially grounded in the input image. We leverage a hierarchical sparse autoencoder and a foundation model with strong semantic representations to automatically extract concepts at various granularities. Examining local co-occurrence dependencies of concepts allows us to define concept relationships. Through these relations we further improve concept naming and obtain richer explanations. On benchmark data, we show that Insight provides performance on classification and segmentation that is competitive with opaque foundation models while providing fine-grained, high quality concept-based explanations. Code is available at https://github.com/kawi19/Insight.

</details>


### [185] [ICo3D: An Interactive Conversational 3D Virtual Human](https://arxiv.org/abs/2601.13148)
*Richard Shaw,Youngkyoon Jang,Athanasios Papaioannou,Arthur Moreau,Helisa Dhamo,Zhensong Zhang,Eduardo Pérez-Pellitero*

Main category: cs.CV

TL;DR: ICo3D是一种生成交互式、对话式且逼真3D虚拟人类化身的方法，结合多视角捕捉、高斯渲染和LLM，适用于游戏、教育等领域。


<details>
  <summary>Details</summary>
Motivation: 旨在生成交互式、对话式且逼真的3D虚拟人类化身，支持实时用户互动。

Method: 基于多视角捕捉，创建可动画的3D面部模型和动态3D身体模型，通过高斯基元渲染，并利用LLM赋予对话能力。音频驱动面部动画，实现精确同步。改进的动态高斯模型（SWinGS++和HeadGaS++）提升真实感，并提供无瑕疵的面部和身体模型合并方案。

Result: 开发了ICo3D系统，展示了实时与3D化身对话的多个用例，支持沉浸式环境中的口头和书面交互。

Conclusion: ICo3D 提供了一个完全集成的虚拟化身体验，适用于游戏、虚拟助手和个性化教育等多个领域。

Abstract: This work presents Interactive Conversational 3D Virtual Human (ICo3D), a method for generating an interactive, conversational, and photorealistic 3D human avatar. Based on multi-view captures of a subject, we create an animatable 3D face model and a dynamic 3D body model, both rendered by splatting Gaussian primitives. Once merged together, they represent a lifelike virtual human avatar suitable for real-time user interactions. We equip our avatar with an LLM for conversational ability. During conversation, the audio speech of the avatar is used as a driving signal to animate the face model, enabling precise synchronization. We describe improvements to our dynamic Gaussian models that enhance photorealism: SWinGS++ for body reconstruction and HeadGaS++ for face reconstruction, and provide as well a solution to merge the separate face and body models without artifacts. We also present a demo of the complete system, showcasing several use cases of real-time conversation with the 3D avatar. Our approach offers a fully integrated virtual avatar experience, supporting both oral and written form interactions in immersive environments. ICo3D is applicable to a wide range of fields, including gaming, virtual assistance, and personalized education, among others. Project page: https://ico3d.github.io/

</details>


### [186] [OmniOVCD: Streamlining Open-Vocabulary Change Detection with SAM 3](https://arxiv.org/abs/2601.13895)
*Xu Zhang,Danyang Li,Yingjie Xia,Xiaohang Dong,Hualong Yu,Jianye Wang,Qicheng Li*

Main category: cs.CV

TL;DR: OmniOVCD利用SAM 3的SFID策略，实现高精度变化检测，在多个基准测试中表现最优。


<details>
  <summary>Details</summary>
Motivation: 现有免训练的OVCD方法依赖CLIP和额外模型（如DINO）提取特征，但多模型组合易导致特征匹配问题和系统不稳定。SAM 3的集成能力为OVCD任务提供了新可能。

Method: 提出OmniOVCD框架，利用SAM 3的解耦输出头，设计SFID策略，融合语义、实例和存在输出构建土地覆盖掩码，并分解为单个实例掩码进行变化比较。

Result: 在LEVIR-CD、WHU-CD、S2Looking和SECOND四个基准测试中，IoU分数分别为67.2、66.5、24.5和27.1，超越所有先前方法。

Conclusion: OmniOVCD通过SFID策略有效整合了SAM 3的解耦输出头，实现了高精度的类别识别和实例级一致性，在四个公开基准测试中均达到SOTA性能。

Abstract: Change Detection (CD) is a fundamental task in remote sensing. It monitors the evolution of land cover over time. Based on this, Open-Vocabulary Change Detection (OVCD) introduces a new requirement. It aims to reduce the reliance on predefined categories. Existing training-free OVCD methods mostly use CLIP to identify categories. These methods also need extra models like DINO to extract features. However, combining different models often causes problems in matching features and makes the system unstable. Recently, the Segment Anything Model 3 (SAM 3) is introduced. It integrates segmentation and identification capabilities within one promptable model, which offers new possibilities for the OVCD task. In this paper, we propose OmniOVCD, a standalone framework designed for OVCD. By leveraging the decoupled output heads of SAM 3, we propose a Synergistic Fusion to Instance Decoupling (SFID) strategy. SFID first fuses the semantic, instance, and presence outputs of SAM 3 to construct land-cover masks, and then decomposes them into individual instance masks for change comparison. This design preserves high accuracy in category recognition and maintains instance-level consistency across images. As a result, the model can generate accurate change masks. Experiments on four public benchmarks (LEVIR-CD, WHU-CD, S2Looking, and SECOND) demonstrate SOTA performance, achieving IoU scores of 67.2, 66.5, 24.5, and 27.1 (class-average), respectively, surpassing all previous methods.

</details>


### [187] [GTPred: Benchmarking MLLMs for Interpretable Geo-localization and Time-of-capture Prediction](https://arxiv.org/abs/2601.13207)
*Jinnao Li,Zijian Chen,Tingzhu Chen,Changbo Wang*

Main category: cs.CV

TL;DR: GTPred是一个新的地理时间预测基准，评估了MLLMs在结合时间信息时的定位性能，发现时间信息能显著提升推断效果。


<details>
  <summary>Details</summary>
Motivation: 现有基准大多忽略了图像中的时间信息，而时间信息可以进一步约束位置，因此需要填补这一空白。

Method: 引入了GTPred这一新基准，包含370张全球分布、跨越120年的图像，评估了8个专有和7个开源MLLMs的预测，通过联合考虑年份和分层位置序列匹配，并进一步评估中间推理链。

Result: 实验表明，尽管MLLMs具有强大的视觉感知能力，但在世界知识和地理时间推理方面仍有局限，同时结合时间信息能显著提升定位推断性能。

Conclusion: 当前的多模态大语言模型（MLLMs）在世界知识和地理时间推理方面仍有局限，但结合时间信息能显著提升定位推断性能。

Abstract: Geo-localization aims to infer the geographic location where an image was captured using observable visual evidence. Traditional methods achieve impressive results through large-scale training on massive image corpora. With the emergence of multi-modal large language models (MLLMs), recent studies have explored their applications in geo-localization, benefiting from improved accuracy and interpretability. However, existing benchmarks largely ignore the temporal information inherent in images, which can further constrain the location. To bridge this gap, we introduce GTPred, a novel benchmark for geo-temporal prediction. GTPred comprises 370 globally distributed images spanning over 120 years. We evaluate MLLM predictions by jointly considering year and hierarchical location sequence matching, and further assess intermediate reasoning chains using meticulously annotated ground-truth reasoning processes. Experiments on 8 proprietary and 7 open-source MLLMs show that, despite strong visual perception, current models remain limited in world knowledge and geo-temporal reasoning. Results also demonstrate that incorporating temporal information significantly enhances location inference performance.

</details>


### [188] [Glance-or-Gaze: Incentivizing LMMs to Adaptively Focus Search via Reinforcement Learning](https://arxiv.org/abs/2601.13942)
*Hongbo Bai,Yujin Zhou,Yile Wu,Chi-Min Chan,Pengcheng Wen,Kunhao Pan,Sirui Han,Yike Guo*

Main category: cs.CV

TL;DR: GoG框架通过选择性注视和强化学习，解决了大型多模态模型在复杂视觉查询中的局限性，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有的大型多模态模型在知识密集型查询中表现不佳，尤其是涉及长尾实体或动态信息时，现有搜索增强方法存在视觉冗余和噪声问题。

Method: 提出了Glance-or-Gaze (GoG)框架，包含选择性注视机制和双阶段训练策略（监督微调和复杂性自适应强化学习）。

Result: 在六个基准测试中表现出最先进的性能，选择性注视和复杂性自适应强化学习被证明对有效视觉搜索至关重要。

Conclusion: GoG框架通过选择性注视机制和复杂性自适应强化学习，显著提升了大型多模态模型在复杂视觉查询中的性能，并在六个基准测试中取得了最先进的结果。

Abstract: Large Multimodal Models (LMMs) have achieved remarkable success in visual understanding, yet they struggle with knowledge-intensive queries involving long-tail entities or evolving information due to static parametric knowledge. Recent search-augmented approaches attempt to address this limitation, but existing methods rely on indiscriminate whole-image retrieval that introduces substantial visual redundancy and noise, and lack deep iterative reflection, limiting their effectiveness on complex visual queries. To overcome these challenges, we propose Glance-or-Gaze (GoG), a fully autonomous framework that shifts from passive perception to active visual planning. GoG introduces a Selective Gaze mechanism that dynamically chooses whether to glance at global context or gaze into high-value regions, filtering irrelevant information before retrieval. We design a dual-stage training strategy: Reflective GoG Behavior Alignment via supervised fine-tuning instills the fundamental GoG paradigm, while Complexity-Adaptive Reinforcement Learning further enhances the model's capability to handle complex queries through iterative reasoning. Experiments across six benchmarks demonstrate state-of-the-art performance. Ablation studies confirm that both Selective Gaze and complexity-adaptive RL are essential for effective visual search. We will release our data and models for further exploration soon.

</details>


### [189] [Rethinking Skip Connections: Additive U-Net for Robust and Interpretable Denoising](https://arxiv.org/abs/2601.13208)
*Vikram R Lakkavalli*

Main category: cs.CV

TL;DR: Additive U-Net replaces concatenative skips with gated additive connections, offering interpretable control over encoder contributions and achieving competitive denoising performance without channel inflation.


<details>
  <summary>Details</summary>
Motivation: Standard concatenation in U-Net architectures doubles channel dimensionality and obscures information flow, leading to uncontrolled noise transfer. The authors aim to address these limitations.

Method: The paper proposes the Additive U-Net, which replaces concatenative skips with gated additive connections, each scaled by a learnable non-negative scalar to control encoder contributions without channel inflation.

Result: Evaluations on the Kodak-17 denoising benchmark show competitive PSNR/SSIM at various noise levels (σ = 15, 25, 50), with robustness across kernel schedules and depths. The model naturally learns a feature progression without explicit down/up-sampling.

Conclusion: Additive skips are presented as a lightweight and interpretable alternative to concatenation in U-Net architectures, enabling efficient design and clearer understanding of multi-scale information transfer.

Abstract: Skip connections are central to U-Net architectures for image denoising, but standard concatenation doubles channel dimensionality and obscures information flow, allowing uncontrolled noise transfer. We propose the Additive U-Net, which replaces concatenative skips with gated additive connections. Each skip pathway is scaled by a learnable non-negative scalar, offering explicit and interpretable control over encoder contributions while avoiding channel inflation. Evaluations on the Kodak-17 denoising benchmark show that Additive U-Net achieves competitive PSNR/SSIM at noise levels σ = 15, 25, 50, with robustness across kernel schedules and depths. Notably, effective denoising is achieved even without explicit down/up-sampling or forced hierarchies, as the model naturally learns a progression from high-frequency to band-pass to low-frequency features. These results position additive skips as a lightweight and interpretable alternative to concatenation, enabling both efficient design and a clearer understanding of multi-scale information transfer in reconstruction networks.

</details>


### [190] [ObjectVisA-120: Object-based Visual Attention Prediction in Interactive Street-crossing Environments](https://arxiv.org/abs/2601.13218)
*Igor Vozniak,Philipp Mueller,Nils Lipp,Janis Sprenger,Konstantin Poddubnyy,Davit Hovhannisyan,Christian Mueller,Andreas Bulling,Philipp Slusallek*

Main category: cs.CV

TL;DR: 论文提出新数据集和oSIM指标，优化对象注意力模型性能，SUMGraph模型表现优异。


<details>
  <summary>Details</summary>
Motivation: 由于缺乏合适的数据集和评估指标，基于对象的视觉注意力在计算模型中未得到充分研究。

Method: 研究者提出了一个包含120名参与者的虚拟现实数据集，用于评估基于对象的视觉注意力，并开发了oSIM评估指标和SUMGraph模型。

Result: 优化对象注意力不仅提高了oSIM性能，还提升了模型在常见指标上的表现。SUMGraph模型在多个先进方法中表现更优。

Conclusion: 该论文通过提出一个新的数据集和评估指标，显著推动了基于对象的视觉注意力模型的研究，并展示了优化对象注意力对模型性能的积极影响。

Abstract: The object-based nature of human visual attention is well-known in cognitive science, but has only played a minor role in computational visual attention models so far. This is mainly due to a lack of suitable datasets and evaluation metrics for object-based attention. To address these limitations, we present \dataset~ -- a novel 120-participant dataset of spatial street-crossing navigation in virtual reality specifically geared to object-based attention evaluations. The uniqueness of the presented dataset lies in the ethical and safety affiliated challenges that make collecting comparable data in real-world environments highly difficult. \dataset~ not only features accurate gaze data and a complete state-space representation of objects in the virtual environment, but it also offers variable scenario complexities and rich annotations, including panoptic segmentation, depth information, and vehicle keypoints. We further propose object-based similarity (oSIM) as a novel metric to evaluate the performance of object-based visual attention models, a previously unexplored performance characteristic. Our evaluations show that explicitly optimising for object-based attention not only improves oSIM performance but also leads to an improved model performance on common metrics. In addition, we present SUMGraph, a Mamba U-Net-based model, which explicitly encodes critical scene objects (vehicles) in a graph representation, leading to further performance improvements over several state-of-the-art visual attention prediction methods. The dataset, code and models will be publicly released.

</details>


### [191] [Generalizing Abstention for Noise-Robust Learning in Medical Image Segmentation](https://arxiv.org/abs/2601.14039)
*Wesam Moustafa,Hossam Elsafty,Helen Schneider,Lorenz Sparrenberg,Rafet Sifa*

Main category: cs.CV

TL;DR: 论文提出了一种通用的弃权框架，通过选择性忽略噪声样本提升分割模型的鲁棒性，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 医学图像分割中标签噪声问题严重，现有方法对此探索不足，弃权机制在分类任务中有效但在分割领域潜力未验证。

Method: 引入了两个关键组件：一个信息化的正则化项来指导弃权行为，以及一个基于幂律的自动调整算法用于弃权惩罚。

Result: 在CaDIS和DSAD数据集上的实验表明，提出的方法在高噪声水平下显著优于非弃权基线。

Conclusion: 该论文提出了一个通用的模块化弃权框架，通过选择性忽略噪声样本，显著提升了医学图像分割模型的鲁棒性和可靠性。

Abstract: Label noise is a critical problem in medical image segmentation, often arising from the inherent difficulty of manual annotation. Models trained on noisy data are prone to overfitting, which degrades their generalization performance. While a number of methods and strategies have been proposed to mitigate noisy labels in the segmentation domain, this area remains largely under-explored. The abstention mechanism has proven effective in classification tasks by enhancing the capabilities of Cross Entropy, yet its potential in segmentation remains unverified. In this paper, we address this gap by introducing a universal and modular abstention framework capable of enhancing the noise-robustness of a diverse range of loss functions. Our framework improves upon prior work with two key components: an informed regularization term to guide abstention behaviour, and a more flexible power-law-based auto-tuning algorithm for the abstention penalty. We demonstrate the framework's versatility by systematically integrating it with three distinct loss functions to create three novel, noise-robust variants: GAC, SAC, and ADS. Experiments on the CaDIS and DSAD medical datasets show our methods consistently and significantly outperform their non-abstaining baselines, especially under high noise levels. This work establishes that enabling models to selectively ignore corrupted samples is a powerful and generalizable strategy for building more reliable segmentation models. Our code is publicly available at https://github.com/wemous/abstention-for-segmentation.

</details>


### [192] [Not all Blends are Equal: The BLEMORE Dataset of Blended Emotion Expressions with Relative Salience Annotations](https://arxiv.org/abs/2601.13225)
*Tim Lachmann,Alexandra Israelsson,Christina Tornberg,Teimuraz Saghinadze,Michal Balazia,Philipp Müller,Petri Laukka*

Main category: cs.CV

TL;DR: BLEMORE数据集填补了混合情感识别数据空白，多模态方法显著提升情感存在及显著性预测准确率。


<details>
  <summary>Details</summary>
Motivation: 现有视频情感识别方法多针对单一情感，缺乏处理混合情感及其相对显著性的能力，主要因缺乏相关标注数据集。

Method: 引入BLEMORE数据集，包含3000多个多模态（视频、音频）情感样本，标注了情感混合的相对显著性。评估了多种视频分类方法在两项任务上的表现：情感存在预测和情感显著性预测。

Result: 单模态分类器在验证集上情感存在准确率最高29%，显著性准确率13%；多模态方法表现更优，ImageBind + WavLM情感存在准确率35%，HiCMAE显著性准确率18%。测试集上最佳模型情感存在准确率33%（VideoMAEv2 + HuBERT），显著性准确率18%（HiCMAE）。

Conclusion: BLEMORE数据集为研究混合情感识别系统提供了宝贵资源，有助于理解情感表达的复杂性和重要性。

Abstract: Humans often experience not just a single basic emotion at a time, but rather a blend of several emotions with varying salience. Despite the importance of such blended emotions, most video-based emotion recognition approaches are designed to recognize single emotions only. The few approaches that have attempted to recognize blended emotions typically cannot assess the relative salience of the emotions within a blend. This limitation largely stems from the lack of datasets containing a substantial number of blended emotion samples annotated with relative salience. To address this shortcoming, we introduce BLEMORE, a novel dataset for multimodal (video, audio) blended emotion recognition that includes information on the relative salience of each emotion within a blend. BLEMORE comprises over 3,000 clips from 58 actors, performing 6 basic emotions and 10 distinct blends, where each blend has 3 different salience configurations (50/50, 70/30, and 30/70). Using this dataset, we conduct extensive evaluations of state-of-the-art video classification approaches on two blended emotion prediction tasks: (1) predicting the presence of emotions in a given sample, and (2) predicting the relative salience of emotions in a blend. Our results show that unimodal classifiers achieve up to 29% presence accuracy and 13% salience accuracy on the validation set, while multimodal methods yield clear improvements, with ImageBind + WavLM reaching 35% presence accuracy and HiCMAE 18% salience accuracy. On the held-out test set, the best models achieve 33% presence accuracy (VideoMAEv2 + HuBERT) and 18% salience accuracy (HiCMAE). In sum, the BLEMORE dataset provides a valuable resource to advancing research on emotion recognition systems that account for the complexity and significance of blended emotion expressions.

</details>


### [193] [Decoder-Free Supervoxel GNN for Accurate Brain-Tumor Localization in Multi-Modal MRI](https://arxiv.org/abs/2601.14055)
*Andrea Protani,Marc Molina Van Den Bosch,Lorenzo Giusti,Heloisa Barbosa Da Silva,Paolo Cacace,Albert Sund Aillet,Miguel Angel Gonzalez Ballester,Friedhelm Hummel,Luigi Serio*

Main category: cs.CV

TL;DR: SVGFormer是一种无解码器的3D医学图像处理方法，通过语义图和分层编码器实现高效特征学习，在BraTS数据集上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现代3D医学成像视觉主干通常通过参数密集的编码器-解码器结构处理密集体素网格，这种设计将大部分参数分配给空间重建而非特征学习。

Method: 引入SVGFormer，一种无解码器的流程，建立在内容感知分组阶段上，将体积分割为超体素的语义图。其分层编码器通过结合补丁级Transformer和超体素级图注意力网络，学习丰富的节点表示，共同建模细粒度区域内特征和更广泛的区域间依赖关系。

Result: 在BraTS数据集上训练的两个专门模型（一个用于节点级分类，一个用于肿瘤比例回归）均表现出色，分类模型的F1分数为0.875，回归模型的MAE为0.028。

Conclusion: 基于图的仅编码器范式为3D医学图像表示提供了准确且内在可解释的替代方案。

Abstract: Modern vision backbones for 3D medical imaging typically process dense voxel grids through parameter-heavy encoder-decoder structures, a design that allocates a significant portion of its parameters to spatial reconstruction rather than feature learning. Our approach introduces SVGFormer, a decoder-free pipeline built upon a content-aware grouping stage that partitions the volume into a semantic graph of supervoxels. Its hierarchical encoder learns rich node representations by combining a patch-level Transformer with a supervoxel-level Graph Attention Network, jointly modeling fine-grained intra-region features and broader inter-regional dependencies. This design concentrates all learnable capacity on feature encoding and provides inherent, dual-scale explainability from the patch to the region level. To validate the framework's flexibility, we trained two specialized models on the BraTS dataset: one for node-level classification and one for tumor proportion regression. Both models achieved strong performance, with the classification model achieving a F1-score of 0.875 and the regression model a MAE of 0.028, confirming the encoder's ability to learn discriminative and localized features. Our results establish that a graph-based, encoder-only paradigm offers an accurate and inherently interpretable alternative for 3D medical image representation.

</details>


### [194] [ConvMambaNet: A Hybrid CNN-Mamba State Space Architecture for Accurate and Real-Time EEG Seizure Detection](https://arxiv.org/abs/2601.13234)
*Md. Nishan Khan,Kazi Shahriar Sanjid,Md. Tanzim Hossain,Asib Mostakim Fony,Istiak Ahmed,M. Monir Uddin*

Main category: cs.CV

TL;DR: ConvMambaNet是一种结合CNN和Mamba-SSM的混合模型，用于癫痫检测，在CHB-MIT数据集上表现优异，准确率达99%。


<details>
  <summary>Details</summary>
Motivation: 癫痫是一种严重影响生活质量的慢性神经系统疾病，脑电图（EEG）是监测神经活动和检测癫痫的主要工具，但由于EEG信号的时间复杂性，自动化分析仍具挑战性。

Method: 该研究提出了一种混合深度学习模型ConvMambaNet，结合了卷积神经网络（CNN）和Mamba结构化状态空间模型（SSM），以增强时间特征提取。

Result: 在CHB-MIT Scalp EEG数据集上评估，ConvMambaNet达到了99%的准确率，并在严重的类别不平衡下表现出鲁棒性能。

Conclusion: ConvMambaNet展示了在临床环境中实现实时、自动化癫痫监测的潜力，其高准确性和对类别不平衡的鲁棒性为癫痫检测提供了可行路径。

Abstract: Epilepsy is a chronic neurological disorder marked by recurrent seizures that can severely impact quality of life. Electroencephalography (EEG) remains the primary tool for monitoring neural activity and detecting seizures, yet automated analysis remains challenging due to the temporal complexity of EEG signals. This study introduces ConvMambaNet, a hybrid deep learning model that integrates Convolutional Neural Networks (CNNs) with the Mamba Structured State Space Model (SSM) to enhance temporal feature extraction. By embedding the Mamba-SSM block within a CNN framework, the model effectively captures both spatial and long-range temporal dynamics. Evaluated on the CHB-MIT Scalp EEG dataset, ConvMambaNet achieved a 99% accuracy and demonstrated robust performance under severe class imbalance. These results underscore the model's potential for precise and efficient seizure detection, offering a viable path toward real-time, automated epilepsy monitoring in clinical environments.

</details>


### [195] [POCI-Diff: Position Objects Consistently and Interactively with 3D-Layout Guided Diffusion](https://arxiv.org/abs/2601.14056)
*Andrea Rigo,Luca Stornaiuolo,Weijie Wang,Mauro Martino,Bruno Lepri,Nicu Sebe*

Main category: cs.CV

TL;DR: POCI-Diff是一种扩散模型框架，通过3D几何约束和语义绑定实现高质量的文本到图像生成与编辑，解决了传统方法的几何扭曲问题。


<details>
  <summary>Details</summary>
Motivation: 现有方法在空间一致性和跨编辑一致性上表现不足，常导致对象几何扭曲。POCI-Diff旨在解决这些问题，提供更高质量的3D布局控制和编辑。

Method: 提出了一种基于扩散模型的框架POCI-Diff，通过Blended Latent Diffusion将文本描述绑定到特定3D边界框，并利用IP-Adapter在扩散过程中引入参考图像，实现无变形的生成式编辑。

Result: 实验表明，POCI-Diff在视觉保真度和布局一致性上优于现有方法，且避免了变形导致的几何伪影。

Conclusion: POCI-Diff 通过结合3D几何约束和实例级语义绑定，显著提升了文本到图像生成的一致性和交互性编辑能力，消除了传统方法中的几何扭曲问题。

Abstract: We propose a diffusion-based approach for Text-to-Image (T2I) generation with consistent and interactive 3D layout control and editing. While prior methods improve spatial adherence using 2D cues or iterative copy-warp-paste strategies, they often distort object geometry and fail to preserve consistency across edits. To address these limitations, we introduce a framework for Positioning Objects Consistently and Interactively (POCI-Diff), a novel formulation for jointly enforcing 3D geometric constraints and instance-level semantic binding within a unified diffusion process. Our method enables explicit per-object semantic control by binding individual text descriptions to specific 3D bounding boxes through Blended Latent Diffusion, allowing one-shot synthesis of complex multi-object scenes. We further propose a warping-free generative editing pipeline that supports object insertion, removal, and transformation via regeneration rather than pixel deformation. To preserve object identity and consistency across edits, we condition the diffusion process on reference images using IP-Adapter, enabling coherent object appearance throughout interactive 3D editing while maintaining global scene coherence. Experimental results demonstrate that POCI-Diff produces high-quality images consistent with the specified 3D layouts and edits, outperforming state-of-the-art methods in both visual fidelity and layout adherence while eliminating warping-induced geometric artifacts.

</details>


### [196] [Unsupervised Video Class-Incremental Learning via Deep Embedded Clustering Management](https://arxiv.org/abs/2601.14069)
*Nattapong Kurpukdee,Adrian G. Bors*

Main category: cs.CV

TL;DR: 本文提出了一种无监督视频类增量学习方法，通过深度特征提取和聚类，显著优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 无监督视频类增量学习是一个重要的学习范式，但现有方法依赖于标签和任务边界知识，成本高且不现实。本文旨在解决这一问题。

Method: 首先使用深度特征提取网络提取视频特征，然后逐步构建一系列深度聚类。在连续任务学习中，利用前一任务更新的模型作为初始状态，将知识传递到当前学习任务。

Result: 在UCF101、HMDB51和Something-to-Something V2数据集上，忽略监督设置中的标签后，该方法显著优于其他基线。

Conclusion: 本文提出了一种简单而有效的方法来解决无监督视频类增量学习（uVCIL）问题，通过在标准视频动作识别数据集上的评估，证明了该方法显著优于其他基线。

Abstract: Unsupervised video class incremental learning (uVCIL) represents an important learning paradigm for learning video information without forgetting, and without considering any data labels. Prior approaches have focused on supervised class-incremental learning, relying on using the knowledge of labels and task boundaries, which is costly, requires human annotation, or is simply not a realistic option. In this paper, we propose a simple yet effective approach to address the uVCIL. We first consider a deep feature extractor network, providing a set of representative video features during each task without assuming any class or task information. We then progressively build a series of deep clusters from the extracted features. During the successive task learning, the model updated from the previous task is used as an initial state in order to transfer knowledge to the current learning task. We perform in-depth evaluations on three standard video action recognition datasets, including UCF101, HMDB51, and Something-to-Something V2, by ignoring the labels from the supervised setting. Our approach significantly outperforms other baselines on all datasets.

</details>


### [197] [Deep Learning for Semantic Segmentation of 3D Ultrasound Data](https://arxiv.org/abs/2601.13263)
*Chenyu Liu,Marco Cecotti,Harikrishnan Vijayakumar,Patrick Robinson,James Barson,Mihai Caleap*

Main category: cs.CV

TL;DR: 本文提出了一种基于学习的3D语义分割框架，使用Calyo Pulse超声传感器系统，展示了其在恶劣环境中的稳健性能，并指出3D超声传感作为自动驾驶补充模态的潜力。


<details>
  <summary>Details</summary>
Motivation: 开发成本效益高且可靠的感知系统是自动驾驶车辆的核心挑战，LiDAR和摄像头系统在成本、鲁棒性和恶劣条件下的性能存在权衡。

Method: 采用3D U-Net架构对空间超声数据进行体积分割训练。

Result: 结果表明，Calyo Pulse传感器实现了稳健的分割性能，通过更大数据集、精细地面真值和加权损失函数还有进一步改进潜力。

Conclusion: 本研究强调了3D超声传感作为一种有前景的补充模态，为可靠自动驾驶提供了新的可能性。

Abstract: Developing cost-efficient and reliable perception systems remains a central challenge for automated vehicles. LiDAR and camera-based systems dominate, yet they present trade-offs in cost, robustness and performance under adverse conditions. This work introduces a novel framework for learning-based 3D semantic segmentation using Calyo Pulse, a modular, solid-state 3D ultrasound sensor system for use in harsh and cluttered environments. A 3D U-Net architecture is introduced and trained on the spatial ultrasound data for volumetric segmentation. Results demonstrate robust segmentation performance from Calyo Pulse sensors, with potential for further improvement through larger datasets, refined ground truth, and weighted loss functions. Importantly, this study highlights 3D ultrasound sensing as a promising complementary modality for reliable autonomy.

</details>


### [198] [DermaBench: A Clinician-Annotated Benchmark Dataset for Dermatology Visual Question Answering and Reasoning](https://arxiv.org/abs/2601.14084)
*Abdurrahim Yilmaz,Ozan Erdem,Ece Gokyayla,Ayda Acar,Burc Bugra Dagtas,Dilara Ilhan Erdil,Gulsum Gencoglan,Burak Temelkuran*

Main category: cs.CV

TL;DR: DermaBench是一个专家标注的皮肤病VQA基准测试，用于评估视觉语言模型的临床推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有的皮肤病数据集主要关注图像级分类任务，无法全面评估多模态模型的视觉理解、语言基础和临床推理能力。

Method: 基于Diverse Dermatology Images (DDI)数据集，通过专家标注的22个主要问题和开放式描述构建了656张临床图像的VQA基准测试。

Result: DermaBench包含约14,474个VQA风格标注，覆盖Fitzpatrick皮肤类型I-VI的570名患者。

Conclusion: DermaBench是一个公开可用的皮肤病视觉问答基准测试，旨在评估视觉语言模型在皮肤病学中的全面理解和临床推理能力。

Abstract: Vision-language models (VLMs) are increasingly important in medical applications; however, their evaluation in dermatology remains limited by datasets that focus primarily on image-level classification tasks such as lesion recognition. While valuable for recognition, such datasets cannot assess the full visual understanding, language grounding, and clinical reasoning capabilities of multimodal models. Visual question answering (VQA) benchmarks are required to evaluate how models interpret dermatological images, reason over fine-grained morphology, and generate clinically meaningful descriptions. We introduce DermaBench, a clinician-annotated dermatology VQA benchmark built on the Diverse Dermatology Images (DDI) dataset. DermaBench comprises 656 clinical images from 570 unique patients spanning Fitzpatrick skin types I-VI. Using a hierarchical annotation schema with 22 main questions (single-choice, multi-choice, and open-ended), expert dermatologists annotated each image for diagnosis, anatomic site, lesion morphology, distribution, surface features, color, and image quality, together with open-ended narrative descriptions and summaries, yielding approximately 14.474 VQA-style annotations. DermaBench is released as a metadata-only dataset to respect upstream licensing and is publicly available at Harvard Dataverse.

</details>


### [199] [Enginuity: Building an Open Multi-Domain Dataset of Complex Engineering Diagrams](https://arxiv.org/abs/2601.13299)
*Ethan Seefried,Prahitha Movva,Naga Harshita Marupaka,Tilak Kasturi,Tirthankar Ghosal*

Main category: cs.CV

TL;DR: Enginuity是首个开放、大规模、多领域的工程图数据集，旨在通过结构标注推动AI在科学发现中的应用，特别是在工程图解析和跨模态任务中。


<details>
  <summary>Details</summary>
Motivation: 旨在解决AI在科学工作流程中因无法理解和操作工程图中的视觉结构知识而受限的问题，推动AI在科学发现中的全面参与。

Method: 提出了Enginuity数据集，这是一个开放、大规模、多领域的工程图数据集，包含全面的结构标注，旨在支持自动化图解析。

Result: Enginuity数据集能够支持多模态大型语言模型处理工程图解析等下游任务，为AI在科学发现中的应用提供了新的可能性。

Conclusion: Enginuity数据集通过提供大规模、多领域的工程图结构标注，为AI在科学发现中的应用开辟了新途径，尤其是在工程图解析、跨模态信息检索和AI辅助工程模拟等关键任务中。

Abstract: We propose Enginuity - the first open, large-scale, multi-domain engineering diagram dataset with comprehensive structural annotations designed for automated diagram parsing. By capturing hierarchical component relationships, connections, and semantic elements across diverse engineering domains, our proposed dataset would enable multimodal large language models to address critical downstream tasks including structured diagram parsing, cross-modal information retrieval, and AI-assisted engineering simulation. Enginuity would be transformative for AI for Scientific Discovery by enabling artificial intelligence systems to comprehend and manipulate the visual-structural knowledge embedded in engineering diagrams, breaking down a fundamental barrier that currently prevents AI from fully participating in scientific workflows where diagram interpretation, technical drawing analysis, and visual reasoning are essential for hypothesis generation, experimental design, and discovery.

</details>


### [200] [Two-Stream temporal transformer for video action classification](https://arxiv.org/abs/2601.14086)
*Nattapong Kurpukdee,Adrian G. Bors*

Main category: cs.CV

TL;DR: 该论文提出了一种双流变换器视频分类器，通过结合内容和光流的时空信息，在人类活动视频数据集上取得了优异的分类效果。


<details>
  <summary>Details</summary>
Motivation: 运动表示在视频理解中扮演重要角色，具有广泛的应用前景。近年来，变换器网络通过其自注意力机制在许多应用中证明了其效率。

Method: 引入了一种新的双流变换器视频分类器，通过自注意力机制从内容和光流中提取时空信息，并在变换器编码器机制中表示它们的关系。

Result: 实验结果表明，所提出的方法在三个知名的人类活动视频数据集上提供了优秀的分类结果。

Conclusion: 该研究提出的双流变换器视频分类器在三个知名的人类活动视频数据集上表现出色，证明了其在视频理解中的有效性。

Abstract: Motion representation plays an important role in video understanding and has many applications including action recognition, robot and autonomous guidance or others. Lately, transformer networks, through their self-attention mechanism capabilities, have proved their efficiency in many applications. In this study, we introduce a new two-stream transformer video classifier, which extracts spatio-temporal information from content and optical flow representing movement information. The proposed model identifies self-attention features across the joint optical flow and temporal frame domain and represents their relationships within the transformer encoder mechanism. The experimental results show that our proposed methodology provides excellent classification results on three well-known video datasets of human activities.

</details>


### [201] [CausalSpatial: A Benchmark for Object-Centric Causal Spatial Reasoning](https://arxiv.org/abs/2601.13304)
*Wenxin Ma,Chenlong Wang,Ruisheng Yuan,Hao Chen,Nanru Dai,S. Kevin Zhou,Yijun Yang,Alan Yuille,Jieneng Chen*

Main category: cs.CV

TL;DR: 论文提出CausalSpatial基准测试，揭示MLLMs在因果空间推理上的不足，并提出COW框架通过视频模拟改善推理能力。


<details>
  <summary>Details</summary>
Motivation: 人类能够通过静态场景预测动态结果，而当前多模态大语言模型（MLLMs）无法做到这一点，主要局限于静态空间感知，难以回答3D场景中的“假设”问题。

Method: 引入CausalSpatial基准测试，评估模型在四个任务（碰撞、兼容性、遮挡和轨迹）中预测物体运动后果的能力，并分析失败原因。提出COW框架，通过生成假设动态的视频来外部化模拟过程。

Result: 人类在基准测试中得分84%，而GPT-5仅得54%。分析发现模型过度依赖文本链式推理，导致与视觉证据脱节，产生流畅但空间上无根据的幻觉。

Conclusion: 论文提出了Causal Object World模型（COW），通过生成假设动态的视频来外部化模拟过程，帮助模型在物理现实中而非语言先验中进行推理。数据集和代码已公开。

Abstract: Humans can look at a static scene and instantly predict what happens next -- will moving this object cause a collision? We call this ability Causal Spatial Reasoning. However, current multimodal large language models (MLLMs) cannot do this, as they remain largely restricted to static spatial perception, struggling to answer "what-if" questions in a 3D scene. We introduce CausalSpatial, a diagnostic benchmark evaluating whether models can anticipate consequences of object motions across four tasks: Collision, Compatibility, Occlusion, and Trajectory. Results expose a severe gap: humans score 84% while GPT-5 achieves only 54%. Why do MLLMs fail? Our analysis uncovers a fundamental deficiency: models over-rely on textual chain-of-thought reasoning that drifts from visual evidence, producing fluent but spatially ungrounded hallucinations. To address this, we propose the Causal Object World model (COW), a framework that externalizes the simulation process by generating videos of hypothetical dynamics. With explicit visual cues of causality, COW enables models to ground their reasoning in physical reality rather than linguistic priors. We make the dataset and code publicly available here: https://github.com/CausalSpatial/CausalSpatial

</details>


### [202] [MultiST: A Cross-Attention-Based Multimodal Model for Spatial Transcriptomic](https://arxiv.org/abs/2601.13331)
*Wei Wang,Quoc-Toan Ly,Chong Yu,Jun Bai*

Main category: cs.CV

TL;DR: MultiST是一种多模态框架，通过融合空间拓扑、基因表达和组织形态学，显著提升了空间转录组数据的解析效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在整合组织学形态与分子谱时效果有限，导致空间域边界模糊，MultiST旨在解决这一问题。

Method: MultiST采用基于图的基因编码器和对抗对齐学习空间表示，并结合颜色归一化的组织学特征，通过跨注意力融合多模态数据。

Result: 在13个不同ST数据集上测试显示，MultiST生成的空间域边界更清晰，伪时间轨迹更稳定，细胞间互作模式更具生物解释性。

Conclusion: MultiST通过跨注意力融合和多模态学习，显著提升了空间转录组数据的解析能力，尤其在边界清晰度和生物解释性方面优于现有方法。

Abstract: Spatial transcriptomics (ST) enables transcriptome-wide profiling while preserving the spatial context of tissues, offering unprecedented opportunities to study tissue organization and cell-cell interactions in situ. Despite recent advances, existing methods often lack effective integration of histological morphology with molecular profiles, relying on shallow fusion strategies or omitting tissue images altogether, which limits their ability to resolve ambiguous spatial domain boundaries. To address this challenge, we propose MultiST, a unified multimodal framework that jointly models spatial topology, gene expression, and tissue morphology through cross-attention-based fusion. MultiST employs graph-based gene encoders with adversarial alignment to learn robust spatial representations, while integrating color-normalized histological features to capture molecular-morphological dependencies and refine domain boundaries. We evaluated the proposed method on 13 diverse ST datasets spanning two organs, including human brain cortex and breast cancer tissue. MultiST yields spatial domains with clearer and more coherent boundaries than existing methods, leading to more stable pseudotime trajectories and more biologically interpretable cell-cell interaction patterns. The MultiST framework and source code are available at https://github.com/LabJunBMI/MultiST.git.

</details>


### [203] [LLM Augmented Intervenable Multimodal Adaptor for Post-operative Complication Prediction in Lung Cancer Surgery](https://arxiv.org/abs/2601.14154)
*Shubham Pandey,Bhavin Jawade,Srirangaraj Setlur,Venu Govindaraju,Kenneth Seastedt*

Main category: cs.CV

TL;DR: MIRACLE是一种深度学习模型，通过融合临床和影像数据预测肺癌术后并发症风险，并提供可解释的临床建议，实验证明其优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 术后并发症对患者预后和医疗成本有显著负面影响，因此需要一种能够整合多源数据并提供可解释预测的方法来改善术后风险管理。

Method: MIRACLE采用深度学习架构，结合超球面嵌入空间融合异构输入，从结构化临床记录和高维放射影像中提取鲁棒且区分性强的特征，并引入干预性深度学习模块以增强预测透明度和临床实用性。

Result: 在POC-L数据集（3,094名肺癌手术患者）上的实验表明，MIRACLE在预测性能上优于传统机器学习模型和当代大型语言模型（LLM）变体。

Conclusion: MIRACLE架构通过整合术前临床和放射学数据，显著提升了术后并发症风险的预测准确性，并提供了可解释的临床见解，有助于个性化术后风险管理。

Abstract: Postoperative complications remain a critical concern in clinical practice, adversely affecting patient outcomes and contributing to rising healthcare costs. We present MIRACLE, a deep learning architecture for prediction of risk of postoperative complications in lung cancer surgery by integrating preoperative clinical and radiological data. MIRACLE employs a hyperspherical embedding space fusion of heterogeneous inputs, enabling the extraction of robust, discriminative features from both structured clinical records and high-dimensional radiological images. To enhance transparency of prediction and clinical utility, we incorporate an interventional deep learning module in MIRACLE, that not only refines predictions but also provides interpretable and actionable insights, allowing domain experts to interactively adjust recommendations based on clinical expertise. We validate our approach on POC-L, a real-world dataset comprising 3,094 lung cancer patients who underwent surgery at Roswell Park Comprehensive Cancer Center. Our results demonstrate that MIRACLE outperforms various traditional machine learning models and contemporary large language models (LLM) variants alone, for personalized and explainable postoperative risk management.

</details>


### [204] [Real-Time 4D Radar Perception for Robust Human Detection in Harsh Enclosed Environments](https://arxiv.org/abs/2601.13364)
*Zhenan Liu,Yaodong Cui,Amir Khajepour,George Shaker*

Main category: cs.CV

TL;DR: 论文提出了一种在粉尘密集环境中进行毫米波传播研究的新方法，包括噪声过滤和实时行人检测，显著提升了系统性能。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决在高度杂乱的环境中（如地下矿井、公路隧道或倒塌建筑物）进行可重复的毫米波传播研究的挑战，特别是粉尘颗粒和反射表面对传感功能的联合影响。

Method: 开发了一种基于阈值的噪声过滤框架，利用关键雷达参数（RCS、速度、方位角、仰角）来抑制幽灵目标并在原始数据层面减轻强多径反射。基于过滤后的点云，采用基于规则的分类管道，利用雷达语义（速度、RCS和体积扩散）实现可靠的实时行人检测，无需大量领域特定训练。

Result: 实验结果表明，该方法在粉尘密集的采矿环境中显著增强了杂波抑制、检测鲁棒性和系统整体韧性。

Conclusion: 该论文提出了一种集成方法，显著提高了在粉尘密集的采矿环境中的杂波抑制、检测鲁棒性和系统整体韧性。

Abstract: This paper introduces a novel methodology for generating controlled, multi-level dust concentrations in a highly cluttered environment representative of harsh, enclosed environments, such as underground mines, road tunnels, or collapsed buildings, enabling repeatable mm-wave propagation studies under severe electromagnetic constraints. We also present a new 4D mmWave radar dataset, augmented by camera and LiDAR, illustrating how dust particles and reflective surfaces jointly impact the sensing functionality. To address these challenges, we develop a threshold-based noise filtering framework leveraging key radar parameters (RCS, velocity, azimuth, elevation) to suppress ghost targets and mitigate strong multipath reflections at the raw data level. Building on the filtered point clouds, a cluster-level, rule-based classification pipeline exploits radar semantics-velocity, RCS, and volumetric spread-to achieve reliable, real-time pedestrian detection without extensive domainspecific training. Experimental results confirm that this integrated approach significantly enhances clutter mitigation, detection robustness, and overall system resilience in dust-laden mining environments.

</details>


### [205] [VideoMaMa: Mask-Guided Video Matting via Generative Prior](https://arxiv.org/abs/2601.14255)
*Sangbeom Lim,Seoung Wug Oh,Jiahui Huang,Heeji Yoon,Seungryong Kim,Joon-Young Lee*

Main category: cs.CV

TL;DR: VideoMaMa利用预训练扩散模型从粗糙掩码生成精确alpha遮罩，零样本泛化能力强，并构建了大规模MA-V数据集，提升了视频抠像性能。


<details>
  <summary>Details</summary>
Motivation: 由于标记数据的稀缺，将视频抠像模型推广到真实世界视频中仍然是一个重大挑战。

Method: 我们提出了Video Mask-to-Matte Model (VideoMaMa)，利用预训练的视频扩散模型将粗糙的分割掩码转换为像素级精确的alpha遮罩。

Result: VideoMaMa展示了强大的零样本泛化能力，即使在仅使用合成数据训练的情况下也能处理真实世界素材。我们还构建了Matting Anything in Video (MA-V)数据集，包含超过50K真实世界视频的高质量抠像注释。

Conclusion: 这些发现强调了大规模伪标记视频抠像的重要性，并展示了生成先验和可访问的分割线索如何推动视频抠像研究的可扩展进展。

Abstract: Generalizing video matting models to real-world videos remains a significant challenge due to the scarcity of labeled data. To address this, we present Video Mask-to-Matte Model (VideoMaMa) that converts coarse segmentation masks into pixel accurate alpha mattes, by leveraging pretrained video diffusion models. VideoMaMa demonstrates strong zero-shot generalization to real-world footage, even though it is trained solely on synthetic data. Building on this capability, we develop a scalable pseudo-labeling pipeline for large-scale video matting and construct the Matting Anything in Video (MA-V) dataset, which offers high-quality matting annotations for more than 50K real-world videos spanning diverse scenes and motions. To validate the effectiveness of this dataset, we fine-tune the SAM2 model on MA-V to obtain SAM2-Matte, which outperforms the same model trained on existing matting datasets in terms of robustness on in-the-wild videos. These findings emphasize the importance of large-scale pseudo-labeled video matting and showcase how generative priors and accessible segmentation cues can drive scalable progress in video matting research.

</details>


### [206] [Spherical Geometry Diffusion: Generating High-quality 3D Face Geometry via Sphere-anchored Representations](https://arxiv.org/abs/2601.13371)
*Junyi Zhang,Yiming Wang,Yunhong Lu,Qichao Wang,Wenzhe Qian,Xiaoyin Xu,David Gu,Min Zhang*

Main category: cs.CV

TL;DR: 通过将3D面部几何约束到球体上并联合建模几何与纹理，新方法在生成质量和效率上优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 解决文本到3D面部生成中几何质量不高的问题，核心难点在于3D空间中顶点的任意和复杂分布导致现有模型难以建立清晰的连接性。

Method: 提出球形几何表示，将几何信号锚定到均匀的球面坐标上，并基于此构建球形几何扩散框架，联合建模几何和纹理。

Result: 在文本到3D生成、面部重建和基于文本的3D编辑等任务中表现出色，几何质量、文本保真度和推理效率显著提升。

Conclusion: 通过将3D几何结构约束到简单的拓扑球体上，并提出球形几何表示和球形几何扩散框架，该方法在几何质量、文本保真度和推理效率上显著优于现有方法。

Abstract: A fundamental challenge in text-to-3D face generation is achieving high-quality geometry. The core difficulty lies in the arbitrary and intricate distribution of vertices in 3D space, making it challenging for existing models to establish clean connectivity and resulting in suboptimal geometry. To address this, our core insight is to simplify the underlying geometric structure by constraining the distribution onto a simple and regular manifold, a topological sphere. Building on this, we first propose the Spherical Geometry Representation, a novel face representation that anchors geometric signals to uniform spherical coordinates. This guarantees a regular point distribution, from which the mesh connectivity can be robustly reconstructed. Critically, this canonical sphere can be seamlessly unwrapped into a 2D map, creating a perfect synergy with powerful 2D generative models. We then introduce Spherical Geometry Diffusion, a conditional diffusion framework built upon this 2D map. It enables diverse and controllable generation by jointly modeling geometry and texture, where the geometry explicitly conditions the texture synthesis process. Our method's effectiveness is demonstrated through its success in a wide range of tasks: text-to-3D generation, face reconstruction, and text-based 3D editing. Extensive experiments show that our approach substantially outperforms existing methods in geometric quality, textual fidelity, and inference efficiency.

</details>


### [207] [A Lightweight Model-Driven 4D Radar Framework for Pervasive Human Detection in Harsh Conditions](https://arxiv.org/abs/2601.13373)
*Zhenan Liu,Amir Khajepour,George Shaker*

Main category: cs.CV

TL;DR: 论文提出了一种模型驱动的4D雷达感知框架，适用于恶劣工业环境，能在摄像头和LiDAR失效时稳定检测行人。


<details>
  <summary>Details</summary>
Motivation: 工业及地下环境中的粉尘、烟雾、狭窄空间和金属结构严重限制了光学和LiDAR感知，而4D毫米波雷达对此类条件具有强韧性，但对其稀疏且各向异性的点云处理缺乏深入理解。

Method: 系统采用雷达作为唯一感知模态，结合多阈值滤波、自我运动补偿时间累积、KD树欧几里得聚类与多普勒感知细化，以及基于规则的3D分类器。

Result: 在粉尘充斥的封闭拖车和真实地下矿道测试中，雷达检测器在摄像头和LiDAR因严重能见度下降失效时仍能稳定识别行人。

Conclusion: 该论文提出的模型驱动4D雷达感知框架在恶劣工业及地下环境中表现出色，为安全关键应用提供了稳健、可解释且计算高效的感知解决方案。

Abstract: Pervasive sensing in industrial and underground environments is severely constrained by airborne dust, smoke, confined geometry, and metallic structures, which rapidly degrade optical and LiDAR based perception. Elevation resolved 4D mmWave radar offers strong resilience to such conditions, yet there remains a limited understanding of how to process its sparse and anisotropic point clouds for reliable human detection in enclosed, visibility degraded spaces. This paper presents a fully model-driven 4D radar perception framework designed for real-time execution on embedded edge hardware. The system uses radar as its sole perception modality and integrates domain aware multi threshold filtering, ego motion compensated temporal accumulation, KD tree Euclidean clustering with Doppler aware refinement, and a rule based 3D classifier. The framework is evaluated in a dust filled enclosed trailer and in real underground mining tunnels, and in the tested scenarios the radar based detector maintains stable pedestrian identification as camera and LiDAR modalities fail under severe visibility degradation. These results suggest that the proposed model-driven approach provides robust, interpretable, and computationally efficient perception for safety-critical applications in harsh industrial and subterranean environments.

</details>


### [208] [Practical Insights into Semi-Supervised Object Detection Approaches](https://arxiv.org/abs/2601.13380)
*Chaoxin Wang,Bharaneeshwar Balasubramaniyam,Anurag Sangem,Nicolais Guevara,Doina Caragea*

Main category: cs.CV

TL;DR: 本文比较了三种SSOD方法在低数据量场景下的性能，揭示了准确性、模型大小和延迟之间的权衡。


<details>
  <summary>Details</summary>
Motivation: 研究社区对数据稀缺环境下的学习日益关注，SSOD旨在通过利用大量未标记图像和少量标记图像（即少样本学习）来提高检测性能。

Method: 本文对三种最先进的SSOD方法（MixPL、Semi-DETR和Consistent-Teacher）进行了全面比较，使用MS-COCO、Pascal VOC和自定义Beetle数据集进行实验。

Result: 实验结果表明，不同SSOD方法在性能上随标记图像数量的变化而变化，特别是在专业数据集上的表现。

Conclusion: 研究强调了在半监督目标检测（SSOD）中，不同方法在准确性、模型大小和延迟之间的权衡，为低数据量场景下的最佳方法选择提供了见解。

Abstract: Learning in data-scarce settings has recently gained significant attention in the research community. Semi-supervised object detection(SSOD) aims to improve detection performance by leveraging a large number of unlabeled images alongside a limited number of labeled images(a.k.a.,few-shot learning). In this paper, we present a comprehensive comparison of three state-of-the-art SSOD approaches, including MixPL, Semi-DETR and Consistent-Teacher, with the goal of understanding how performance varies with the number of labeled images. We conduct experiments using the MS-COCO and Pascal VOC datasets, two popular object detection benchmarks which allow for standardized evaluation. In addition, we evaluate the SSOD approaches on a custom Beetle dataset which enables us to gain insights into their performance on specialized datasets with a smaller number of object categories. Our findings highlight the trade-offs between accuracy, model size, and latency, providing insights into which methods are best suited for low-data regimes.

</details>


### [209] [Leveraging Transformer Decoder for Automotive Radar Object Detection](https://arxiv.org/abs/2601.13386)
*Changxu Zhang,Zhaoze Wang,Tai Fei,Christopher Grimm,Yi Jin,Claas Tebruegge,Ernst Warsitz,Markus Gardill*

Main category: cs.CV

TL;DR: 提出了一种基于Transformer的3D雷达物体检测方法，通过新型Decoder和PTF模块直接回归边界框，无需密集提案生成或NMS调优，性能优于现有雷达基线。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统雷达物体检测中密集提案生成和启发式后处理（如非极大值抑制调优）的问题，设计了一种能够建模长距离时空相关性和跨特征交互的方法。

Method: 采用Transformer Decoder作为预测头，直接回归3D边界框和类别分数，并通过Pyramid Token Fusion模块将多尺度雷达特征转换为统一的、尺度感知的令牌序列。

Result: 在RADDet数据集上评估，该方法显著优于现有雷达基线。

Conclusion: 该论文提出的基于Transformer的架构和Pyramid Token Fusion模块显著提升了3D雷达物体检测的性能，超越了现有雷达基线的表现。

Abstract: In this paper, we present a Transformer-based architecture for 3D radar object detection that uses a novel Transformer Decoder as the prediction head to directly regress 3D bounding boxes and class scores from radar feature representations. To bridge multi-scale radar features and the decoder, we propose Pyramid Token Fusion (PTF), a lightweight module that converts a feature pyramid into a unified, scale-aware token sequence. By formulating detection as a set prediction problem with learnable object queries and positional encodings, our design models long-range spatial-temporal correlations and cross-feature interactions. This approach eliminates dense proposal generation and heuristic post-processing such as extensive non-maximum suppression (NMS) tuning. We evaluate the proposed framework on the RADDet, where it achieves significant improvements over state-of-the-art radar-only baselines.

</details>


### [210] [Diffusion Representations for Fine-Grained Image Classification: A Marine Plankton Case Study](https://arxiv.org/abs/2601.13416)
*A. Nieto Juscafresa,Á. Mazcuñán Herreros,J. Sullivan*

Main category: cs.CV

TL;DR: 扩散模型作为特征编码器在细粒度识别任务中表现优异，适应性强。


<details>
  <summary>Details</summary>
Motivation: 探索扩散模型作为通用特征编码器的潜力，特别是在无标签的自监督学习场景中。

Method: 利用冻结的扩散模型作为特征编码器，通过探测不同层和时间步的去噪特征，并为每对特征训练线性分类器。

Result: 冻结扩散特征在细粒度识别任务中与监督基线竞争，并在自监督方法中表现最佳，尤其在数据分布变化时保持高准确率。

Conclusion: 扩散模型作为通用特征编码器具有潜力，尤其在细粒度识别任务中表现优异，能够适应数据分布变化。

Abstract: Diffusion models have emerged as state-of-the-art generative methods for image synthesis, yet their potential as general-purpose feature encoders remains underexplored. Trained for denoising and generation without labels, they can be interpreted as self-supervised learners that capture both low- and high-level structure. We show that a frozen diffusion backbone enables strong fine-grained recognition by probing intermediate denoising features across layers and timesteps and training a linear classifier for each pair. We evaluate this in a real-world plankton-monitoring setting with practical impact, using controlled and comparable training setups against established supervised and self-supervised baselines. Frozen diffusion features are competitive with supervised baselines and outperform other self-supervised methods in both balanced and naturally long-tailed settings. Out-of-distribution evaluations on temporally and geographically shifted plankton datasets further show that frozen diffusion features maintain strong accuracy and Macro F1 under substantial distribution shift.

</details>


### [211] [SGW-GAN: Sliced Gromov-Wasserstein Guided GANs for Retinal Fundus Image Enhancement](https://arxiv.org/abs/2601.13417)
*Yujian Xiong,Xuanzhao Dong,Wenhui Zhu,Xin Li,Oana Dumitrascu,Yalin Wang*

Main category: cs.CV

TL;DR: SGW-GAN结合Sliced GW方法，高效解决视网膜图像增强中的类内几何失真问题，提升临床任务表现。


<details>
  <summary>Details</summary>
Motivation: 现有基于GAN和扩散模型的视网膜图像增强方法虽能提升感知质量，但可能导致类内几何失真，影响临床相关样本的分类和下游任务。

Method: 提出SGW-GAN框架，利用Sliced GW (SGW)近似GW距离，通过随机投影保留类内结构关系，显著降低计算成本。

Result: 在公共数据集上，SGW-GAN不仅生成视觉上令人满意的增强图像，还在糖尿病视网膜病变分级任务中表现优异，且报告了最低的GW差异。

Conclusion: SGW-GAN通过结合Sliced Gromov Wasserstein (SGW)方法，成功解决了传统GAN和扩散模型在视网膜图像增强中可能导致的类内几何失真问题，同时保持了计算效率。

Abstract: Retinal fundus photography is indispensable for ophthalmic screening and diagnosis, yet image quality is often degraded by noise, artifacts, and uneven illumination. Recent GAN- and diffusion-based enhancement methods improve perceptual quality by aligning degraded images with high-quality distributions, but our analysis shows that this focus can distort intra-class geometry: clinically related samples become dispersed, disease-class boundaries blur, and downstream tasks such as grading or lesion detection are harmed. The Gromov Wasserstein (GW) discrepancy offers a principled solution by aligning distributions through internal pairwise distances, naturally preserving intra-class structure, but its high computational cost restricts practical use. To overcome this, we propose SGW-GAN, the first framework to incorporate Sliced GW (SGW) into retinal image enhancement. SGW approximates GW via random projections, retaining relational fidelity while greatly reducing cost. Experiments on public datasets show that SGW-GAN produces visually compelling enhancements, achieves superior diabetic retinopathy grading, and reports the lowest GW discrepancy across disease labels, demonstrating both efficiency and clinical fidelity for unpaired medical image enhancement.

</details>


### [212] [Analyzing VLM-Based Approaches for Anomaly Classification and Segmentation](https://arxiv.org/abs/2601.13440)
*Mohit Kakda,Mirudula Shri Muthukumaran,Uttapreksha Patel,Lawrence Swaminathan Xavier Prince*

Main category: cs.CV

TL;DR: VLMs（如CLIP）通过零样本和少样本学习革新了异常检测，本文系统分析了其架构、性能及局限性，为工业质量控制提供指导。


<details>
  <summary>Details</summary>
Motivation: 利用VLMs（如CLIP）的潜力，无需大量标注数据即可实现异常检测，解决传统方法对任务特定训练或缺陷样本的依赖。

Method: 系统分析了WinCLIP、AprilLab框架和组合提示集成策略等关键架构范式，评估了特征提取、文本-视觉对齐策略、提示工程技术等维度。

Result: 在MVTec AD和VisA等基准测试中，比较了分类准确性、分割精度和推理效率，验证了VLM方法的有效性。

Conclusion: VLMs在异常检测中表现出色，提供了零样本和少样本的解决方案，但仍需进一步研究以克服当前限制。

Abstract: Vision-Language Models (VLMs), particularly CLIP, have revolutionized anomaly detection by enabling zero-shot and few-shot defect identification without extensive labeled datasets. By learning aligned representations of images and text, VLMs facilitate anomaly classification and segmentation through natural language descriptions of normal and abnormal states, eliminating traditional requirements for task-specific training or defect examples. This project presents a comprehensive analysis of VLM-based approaches for anomaly classification (AC) and anomaly segmentation (AS). We systematically investigate key architectural paradigms including sliding window-based dense feature extraction (WinCLIP), multi-stage feature alignment with learnable projections (AprilLab framework), and compositional prompt ensemble strategies. Our analysis evaluates these methods across critical dimensions: feature extraction mechanisms, text-visual alignment strategies, prompt engineering techniques, zero-shot versus few-shot trade-offs, computational efficiency, and cross-domain generalization. Through rigorous experimentation on benchmarks such as MVTec AD and VisA, we compare classification accuracy, segmentation precision, and inference efficiency. The primary contribution is a foundational understanding of how and why VLMs succeed in anomaly detection, synthesizing practical insights for method selection and identifying current limitations. This work aims to facilitate informed adoption of VLM-based methods in industrial quality control and guide future research directions.

</details>


### [213] [Optical Linear Systems Framework for Event Sensing and Computational Neuromorphic Imaging](https://arxiv.org/abs/2601.13498)
*Nimrod Kruger,Nicholas Owen Ralph,Gregory Cohen,Paul Hurley*

Main category: cs.CV

TL;DR: 该论文提出了一种处理事件流的方法，将其映射到对数强度和导数估计，并嵌入动态线性系统模型，实现了从事件数据直接进行逆滤波，为动态光学系统中的事件传感和计算成像提供了桥梁。


<details>
  <summary>Details</summary>
Motivation: 事件视觉传感器的非线性系统特性难以与大多数计算成像和光学系统设计所依赖的线性前向模型集成。

Method: 提出了一种基于物理的处理流程，将事件流映射到每像素对数强度和强度导数的估计，并将这些测量嵌入到具有时变点扩散函数的动态线性系统模型中。

Result: 在模拟和真实事件数据中验证了方法的有效性，展示了源定位和可分离性。

Conclusion: 该框架为动态光学系统中的事件传感和基于模型的计算成像之间搭建了实用的桥梁。

Abstract: Event vision sensors (neuromorphic cameras) output sparse, asynchronous ON/OFF events triggered by log-intensity threshold crossings, enabling microsecond-scale sensing with high dynamic range and low data bandwidth. As a nonlinear system, this event representation does not readily integrate with the linear forward models that underpin most computational imaging and optical system design. We present a physics-grounded processing pipeline that maps event streams to estimates of per-pixel log-intensity and intensity derivatives, and embeds these measurements in a dynamic linear systems model with a time-varying point spread function. This enables inverse filtering directly from event data, using frequency-domain Wiener deconvolution with a known (or parameterised) dynamic transfer function. We validate the approach in simulation for single and overlapping point sources under modulated defocus, and on real event data from a tunable-focus telescope imaging a star field, demonstrating source localisation and separability. The proposed framework provides a practical bridge between event sensing and model-based computational imaging for dynamic optical systems.

</details>


### [214] [DIS2: Disentanglement Meets Distillation with Classwise Attention for Robust Remote Sensing Segmentation under Missing Modalities](https://arxiv.org/abs/2601.13502)
*Nhi Kieu,Kien Nguyen,Arnold Wiliem,Clinton Fookes,Sridha Sridharan*

Main category: cs.CV

TL;DR: DIS2通过DLKD、CFLM和HF结构，有效解决遥感多模态学习中的模态缺失问题，性能超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 遥感数据多模态学习中，模态缺失严重削弱学习效果，且数据高度异构、尺度变化大，现有方法无法有效应对。

Method: 提出DIS2方法，包括DLKD（解耦学习与知识蒸馏的结合）、CFLM（类特定特征学习模块）和HF（分层混合融合结构）。

Result: 实验证明DIS2在多个基准测试中显著优于现有方法。

Conclusion: DIS2方法通过结合解耦学习和知识蒸馏（DLKD）、类特定特征学习模块（CFLM）以及分层混合融合（HF）结构，显著提升了多模态遥感数据在缺失模态情况下的学习效果，优于现有方法。

Abstract: The efficacy of multimodal learning in remote sensing (RS) is severely undermined by missing modalities. The challenge is exacerbated by the RS highly heterogeneous data and huge scale variation. Consequently, paradigms proven effective in other domains often fail when confronted with these unique data characteristics. Conventional disentanglement learning, which relies on significant feature overlap between modalities (modality-invariant), is insufficient for this heterogeneity. Similarly, knowledge distillation becomes an ill-posed mimicry task where a student fails to focus on the necessary compensatory knowledge, leaving the semantic gap unaddressed. Our work is therefore built upon three pillars uniquely designed for RS: (1) principled missing information compensation, (2) class-specific modality contribution, and (3) multi-resolution feature importance. We propose a novel method DIS2, a new paradigm shifting from modality-shared feature dependence and untargeted imitation to active, guided missing features compensation. Its core novelty lies in a reformulated synergy between disentanglement learning and knowledge distillation, termed DLKD. Compensatory features are explicitly captured which, when fused with the features of the available modality, approximate the ideal fused representation of the full-modality case. To address the class-specific challenge, our Classwise Feature Learning Module (CFLM) adaptively learn discriminative evidence for each target depending on signal availability. Both DLKD and CFLM are supported by a hierarchical hybrid fusion (HF) structure using features across resolutions to strengthen prediction. Extensive experiments validate that our proposed approach significantly outperforms state-of-the-art methods across benchmarks.

</details>


### [215] [GO-MLVTON: Garment Occlusion-Aware Multi-Layer Virtual Try-On with Diffusion Models](https://arxiv.org/abs/2601.13524)
*Yang Yu,Yunze Deng,Yige Zhang,Yanjie Xiao,Youkun Ou,Wenhao Hu,Mingchao Li,Bin Feng,Wenyu Liu,Dandan Zheng,Jingdong Chen*

Main category: cs.CV

TL;DR: GO-MLVTON是首个针对多层虚拟试衣（ML-VTON）的方法，通过遮挡学习和衣物变形模块解决了多层衣物试衣的挑战，并提出了新的数据集和评价指标。


<details>
  <summary>Details</summary>
Motivation: 现有的虚拟试衣方法主要关注单层或多件衣物的试衣，忽略了多层衣物的试衣（ML-VTON），其核心挑战在于准确建模内外层衣物间的遮挡关系以减少冗余内层衣物特征的干扰。

Method: 提出了GO-MLVTON方法，包含Garment Occlusion Learning模块用于学习遮挡关系，以及StableDiffusion-based Garment Morphing & Fitting模块用于衣物的变形和贴合。此外，还提出了MLG数据集和新的评价指标LACD。

Result: 大量实验证明了GO-MLVTON的先进性能，能够生成高质量的多层试衣效果。

Conclusion: GO-MLVTON在多层虚拟试衣（ML-VTON）任务中表现出色，通过引入Garment Occlusion Learning模块和StableDiffusion-based Garment Morphing & Fitting模块，成功解决了多层衣物间的遮挡关系建模问题，并生成了高质量的试衣效果。

Abstract: Existing Image-based virtual try-on (VTON) methods primarily focus on single-layer or multi-garment VTON, neglecting multi-layer VTON (ML-VTON), which involves dressing multiple layers of garments onto the human body with realistic deformation and layering to generate visually plausible outcomes. The main challenge lies in accurately modeling occlusion relationships between inner and outer garments to reduce interference from redundant inner garment features. To address this, we propose GO-MLVTON, the first multi-layer VTON method, introducing the Garment Occlusion Learning module to learn occlusion relationships and the StableDiffusion-based Garment Morphing & Fitting module to deform and fit garments onto the human body, producing high-quality multi-layer try-on results. Additionally, we present the MLG dataset for this task and propose a new metric named Layered Appearance Coherence Difference (LACD) for evaluation. Extensive experiments demonstrate the state-of-the-art performance of GO-MLVTON. Project page: https://upyuyang.github.io/go-mlvton/.

</details>


### [216] [DiffFace-Edit: A Diffusion-Based Facial Dataset for Forgery-Semantic Driven Deepfake Detection Analysis](https://arxiv.org/abs/2601.13551)
*Feng Ding,Wenhui Yi,Xinan He,Mengyao Xiao,Jianfeng Xu,Jianqiang Du*

Main category: cs.CV

TL;DR: DiffFace-Edit数据集填补了细粒度区域操纵样本的空白，分析了检测器规避样本的影响，并提供了跨域评估方法。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成人脸数据集缺乏细粒度区域操纵样本，且未研究拼接攻击对检测器的实际影响。

Method: 引入了DiffFace-Edit数据集，包含超过两百万张AI生成的假图像，覆盖八个面部区域的编辑，并分析了检测器规避样本对检测模型的影响。

Result: 提出了DiffFace-Edit数据集，并进行了全面分析，结合了IMDL方法的跨域评估。

Conclusion: DiffFace-Edit数据集填补了现有AI生成人脸数据集的空白，专注于细粒度区域操纵样本，并首次研究了拼接攻击对检测器的实际影响。

Abstract: Generative models now produce imperceptible, fine-grained manipulated faces, posing significant privacy risks. However, existing AI-generated face datasets generally lack focus on samples with fine-grained regional manipulations. Furthermore, no researchers have yet studied the real impact of splice attacks, which occur between real and manipulated samples, on detectors. We refer to these as detector-evasive samples. Based on this, we introduce the DiffFace-Edit dataset, which has the following advantages: 1) It contains over two million AI-generated fake images. 2) It features edits across eight facial regions (e.g., eyes, nose) and includes a richer variety of editing combinations, such as single-region and multi-region edits. Additionally, we specifically analyze the impact of detector-evasive samples on detection models. We conduct a comprehensive analysis of the dataset and propose a cross-domain evaluation that combines IMDL methods. Dataset will be available at https://github.com/ywh1093/DiffFace-Edit.

</details>


### [217] [ChartVerse: Scaling Chart Reasoning via Reliable Programmatic Synthesis from Scratch](https://arxiv.org/abs/2601.13606)
*Zheng Liu,Honglin Lin,Chonghan Qin,Xiaoyang Wang,Xin Gao,Yu Li,Mengzhang Cai,Yun Zhu,Zhanping Zhong,Qizhi Pei,Zhuoshi Pan,Xiaoran Shang,Bin Cui,Conghui He,Wentao Zhang,Lijun Wu*

Main category: cs.CV

TL;DR: ChartVerse 是一个可扩展的框架，通过量化图表复杂性和 truth-anchored inverse QA 合成方法，解决了现有数据集的不足，生成的模型性能优异。


<details>
  <summary>Details</summary>
Motivation: 开源视觉语言模型（VLMs）的发展因缺乏高质量训练数据而受到严重阻碍。现有数据集存在合成图表过于简单、重复，且问答对容易产生幻觉、缺乏复杂任务所需的推理深度等问题。

Method: 提出了 Rollout Posterior Entropy (RPE) 指标量化图表复杂性，并开发了复杂度感知的图表编码器，通过可执行程序自主合成多样化的高复杂度图表。此外，采用 truth-anchored inverse QA 合成方法，确保推理严谨性。

Result: 通过 ChartVerse 框架合成了 ChartVerse-SFT-600K 和 ChartVerse-RL-40K 数据集，并验证了其有效性。

Conclusion: ChartVerse-8B 在实验中表现出色，超越了其教师模型 Qwen3-VL-30B-A3B-Thinking，并与更强的 Qwen3-VL-32B-Thinking 相媲美，展示了其卓越的性能。

Abstract: Chart reasoning is a critical capability for Vision Language Models (VLMs). However, the development of open-source models is severely hindered by the lack of high-quality training data. Existing datasets suffer from a dual challenge: synthetic charts are often simplistic and repetitive, while the associated QA pairs are prone to hallucinations and lack the reasoning depth required for complex tasks. To bridge this gap, we propose ChartVerse, a scalable framework designed to synthesize complex charts and reliable reasoning data from scratch. (1) To address the bottleneck of simple patterns, we first introduce Rollout Posterior Entropy (RPE), a novel metric that quantifies chart complexity. Guided by RPE, we develop complexity-aware chart coder to autonomously synthesize diverse, high-complexity charts via executable programs. (2) To guarantee reasoning rigor, we develop truth-anchored inverse QA synthesis. Diverging from standard generation, we adopt an answer-first paradigm: we extract deterministic answers directly from the source code, generate questions conditional on these anchors, and enforce strict consistency verification. To further elevate difficulty and reasoning depth, we filter samples based on model fail-rate and distill high-quality Chain-of-Thought (CoT) reasoning. We curate ChartVerse-SFT-600K and ChartVerse-RL-40K using Qwen3-VL-30B-A3B-Thinking as the teacher. Experimental results demonstrate that ChartVerse-8B achieves state-of-the-art performance, notably surpassing its teacher and rivaling the stronger Qwen3-VL-32B-Thinking.

</details>


### [218] [Scaling Test-time Inference for Visual Grounding](https://arxiv.org/abs/2601.13633)
*Guanqi Zhan,Changye Li,Zhijian Liu,Yao Lu,Yi Wu,Song Han,Ligeng Zhu*

Main category: cs.CV

TL;DR: EGM通过调整测试时计算量，使小型视觉语言模型在视觉定位任务中性能优于大型模型，同时保持高效部署。


<details>
  <summary>Details</summary>
Motivation: 解决小型视觉语言模型因语言理解能力不足而导致的视觉定位性能差距，同时保持部署友好性。

Method: 提出'Efficient visual Grounding language Models' (EGM)，通过调整测试时计算量（生成令牌数）来提升小型模型的视觉定位能力。

Result: 在RefCOCO基准测试中，EGM-Qwen3-VL-8B以737ms延迟（比Qwen3-VL-235B快5.9倍）达到91.4 IoU，优于大型模型的90.5 IoU。在新设置的无模态定位任务中，EGM同样显著提升小型模型性能。

Conclusion: EGM方法通过调整测试时计算量，显著提升了小型视觉语言模型的视觉定位能力，使其在效率和性能上均优于大型模型。

Abstract: Visual grounding is an essential capability of Visual Language Models (VLMs) to understand the real physical world. Previous state-of-the-art grounding visual language models usually have large model sizes, making them heavy for deployment and slow for inference. However, we notice that the sizes of visual encoders are nearly the same for small and large VLMs and the major difference is the sizes of the language models. Small VLMs fall behind larger VLMs in grounding because of the difference in language understanding capability rather than visual information handling. To mitigate the gap, we introduce 'Efficient visual Grounding language Models' (EGM): a method to scale the test-time computation (#generated tokens). Scaling the test-time computation of a small model is deployment-friendly, and yields better end-to-end latency as the cost of each token is much cheaper compared to directly running a large model. On the RefCOCO benchmark, our EGM-Qwen3-VL-8B demonstrates 91.4 IoU with an average of 737ms (5.9x faster) latency while Qwen3-VL-235B demands 4,320ms to achieve 90.5 IoU. To validate our approach's generality, we further set up a new amodal grounding setting that requires the model to predict both the visible and occluded parts of the objects. Experiments show our method can consistently and significantly improve the vanilla grounding and amodal grounding capabilities of small models to be on par with or outperform the larger models, thereby improving the efficiency for visual grounding.

</details>


### [219] [Face-Voice Association with Inductive Bias for Maximum Class Separation](https://arxiv.org/abs/2601.13651)
*Marta Moscati,Oleksandr Kats,Mubashir Noman,Muhammad Zaigham Zaheer,Yufang Hou,Markus Schedl,Shah Nawaz*

Main category: cs.CV

TL;DR: 本研究提出了一种利用最大类别分离作为归纳偏置的跨模态学习方法，实验证明其在人脸-声音关联任务中表现优异，为领域内新范式奠定基础。


<details>
  <summary>Details</summary>
Motivation: 探索在跨模态学习中应用最大类别分离作为归纳偏置的潜力，填补该领域的研究空白。

Method: 开发了一种方法，通过将不同说话者的多模态表示之间的最大类别分离作为归纳偏置来增强嵌入的判别能力。

Result: 通过定量实验证明该方法在两个任务中达到SOTA性能，并通过消融研究显示结合类间正交性损失时效果最佳。

Conclusion: 本研究首次在跨模态学习中应用并证明了最大类别分离作为归纳偏置的有效性，为建立新范式铺平了道路。

Abstract: Face-voice association is widely studied in multimodal learning and is approached representing faces and voices with embeddings that are close for a same person and well separated from those of others. Previous work achieved this with loss functions. Recent advancements in classification have shown that the discriminative ability of embeddings can be strengthened by imposing maximum class separation as inductive bias. This technique has never been used in the domain of face-voice association, and this work aims at filling this gap. More specifically, we develop a method for face-voice association that imposes maximum class separation among multimodal representations of different speakers as an inductive bias. Through quantitative experiments we demonstrate the effectiveness of our approach, showing that it achieves SOTA performance on two task formulation of face-voice association. Furthermore, we carry out an ablation study to show that imposing inductive bias is most effective when combined with losses for inter-class orthogonality. To the best of our knowledge, this work is the first that applies and demonstrates the effectiveness of maximum class separation as an inductive bias in multimodal learning; it hence paves the way to establish a new paradigm.

</details>


### [220] [VIAFormer: Voxel-Image Alignment Transformer for High-Fidelity Voxel Refinement](https://arxiv.org/abs/2601.13664)
*Tiancheng Fang,Bowen Pan,Lingxi Chen,Jiangjing Lyu,Chengfei Lyu,Chaoyue Niu,Fan Wu*

Main category: cs.CV

TL;DR: VIAFormer是一种体素-图像对齐变压器模型，通过图像索引、校正流目标和混合流变压器的协同设计，有效修复不完整且有噪声的体素，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 解决使用校准的多视角图像作为指导修复不完整且有噪声的体素的任务。

Method: VIAFormer结合了图像索引（提供2D图像标记的显式3D空间基础）、校正流目标（学习直接的体素细化轨迹）和混合流变压器（实现鲁棒的跨模态融合）。

Result: 实验表明，VIAFormer在纠正从强大的视觉基础模型获得的体素形状的严重合成损坏和现实伪影方面建立了新的最先进水平。

Conclusion: VIAFormer作为一种实用的、可靠的桥梁，在现实世界的3D创作流程中展示了其潜力，为基于体素的方法在大模型和大数据浪潮中的繁荣铺平了道路。

Abstract: We propose VIAFormer, a Voxel-Image Alignment Transformer model designed for Multi-view Conditioned Voxel Refinement--the task of repairing incomplete noisy voxels using calibrated multi-view images as guidance. Its effectiveness stems from a synergistic design: an Image Index that provides explicit 3D spatial grounding for 2D image tokens, a Correctional Flow objective that learns a direct voxel-refinement trajectory, and a Hybrid Stream Transformer that enables robust cross-modal fusion. Experiments show that VIAFormer establishes a new state of the art in correcting both severe synthetic corruptions and realistic artifacts on the voxel shape obtained from powerful Vision Foundation Models. Beyond benchmarking, we demonstrate VIAFormer as a practical and reliable bridge in real-world 3D creation pipelines, paving the way for voxel-based methods to thrive in large-model, big-data wave.

</details>


### [221] [Transformer based Multi-task Fusion Network for Food Spoilage Detection and Shelf life Forecasting](https://arxiv.org/abs/2601.13665)
*Mounika Kanulla,Rajasree Dadigi,Sailaja Thota,Vivek Yelleti*

Main category: cs.CV

TL;DR: 融合CNN和DeiT Transformer的架构在减少食物浪费方面表现优异，尤其在蔬菜分类和腐败检测上效果显著。


<details>
  <summary>Details</summary>
Motivation: 减少农业供应链中的食物浪费，通过准确检测腐败和预测保质期来延长供应链管理。

Method: 结合CNN与LSTM和DeiT Transformer的融合架构，同时处理蔬菜分类、食物腐败检测和保质期预测。

Result: CNN+DeiT Transformer在蔬菜分类和腐败检测的F1分数分别为0.98和0.61，保质期预测的MSE和SMAPE分别为3.58和41.66%。

Conclusion: 融合架构CNN+DeiT Transformer在蔬菜分类、食物腐败检测和保质期预测方面表现优异，验证了其可靠性和实用性。

Abstract: Food wastage is one of the critical challenges in the agricultural supply chain, and accurate and effective spoilage detection can help to reduce it. Further, it is highly important to forecast the spoilage information. This aids the longevity of the supply chain management in the agriculture field. This motivated us to propose fusion based architectures by combining CNN with LSTM and DeiT transformer for the following multi-tasks simultaneously: (i) vegetable classification, (ii) food spoilage detection, and (iii) shelf life forecasting. We developed a dataset by capturing images of vegetables from their fresh state until they were completely spoiled. From the experimental analysis it is concluded that the proposed fusion architectures CNN+CNN-LSTM and CNN+DeiT Transformer outperformed several deep learning models such as CNN, VGG16, ResNet50, Capsule Networks, and DeiT Transformers. Overall, CNN + DeiT Transformer yielded F1-score of 0.98 and 0.61 in vegetable classification and spoilage detection respectively and mean squared error (MSE) and symmetric mean absolute percentage error (SMAPE) of 3.58, and 41.66% respectively in spoilage forecasting. Further, the reliability of the fusion models was validated on noisy images and integrated with LIME to visualize the model decisions.

</details>


### [222] [Finally Outshining the Random Baseline: A Simple and Effective Solution for Active Learning in 3D Biomedical Imaging](https://arxiv.org/abs/2601.13677)
*Carsten T. Lüth,Jeremias Traub,Kim-Celine Kahl,Till J. Bungert,Lukas Klein,Lars Krämer,Paul F. Jäger,Klaus Maier-Hein,Fabian Isensee*

Main category: cs.CV

TL;DR: ClaSP PE通过类别分层和噪声调度策略，显著提升了3D生物医学图像分割的主动学习效果，泛化性强且易于部署。


<details>
  <summary>Details</summary>
Motivation: 现有主动学习方法在3D生物医学图像分割中无法稳定超越改进的随机采样基线，亟需一种可靠解决方案以减少昂贵的专家标注成本。

Method: ClaSP PE结合了类别分层查询和基于对数尺度功率噪声的衰减调度，以解决类别不平衡和早期选择冗余问题。

Result: 在24种实验设置和四个未见数据集的测试中，ClaSP PE在分割质量和标注效率上均显著优于基线方法，且无需手动调参。

Conclusion: ClaSP PE是一种简单有效的主动学习方法，能够在3D生物医学图像分割中一致性地超越改进的随机采样基线，且在现实应用中表现出良好的泛化能力。

Abstract: Active learning (AL) has the potential to drastically reduce annotation costs in 3D biomedical image segmentation, where expert labeling of volumetric data is both time-consuming and expensive. Yet, existing AL methods are unable to consistently outperform improved random sampling baselines adapted to 3D data, leaving the field without a reliable solution. We introduce Class-stratified Scheduled Power Predictive Entropy (ClaSP PE), a simple and effective query strategy that addresses two key limitations of standard uncertainty-based AL methods: class imbalance and redundancy in early selections. ClaSP PE combines class-stratified querying to ensure coverage of underrepresented structures and log-scale power noising with a decaying schedule to enforce query diversity in early-stage AL and encourage exploitation later. In our evaluation on 24 experimental settings using four 3D biomedical datasets within the comprehensive nnActive benchmark, ClaSP PE is the only method that generally outperforms improved random baselines in terms of both segmentation quality with statistically significant gains, whilst remaining annotation efficient. Furthermore, we explicitly simulate the real-world application by testing our method on four previously unseen datasets without manual adaptation, where all experiment parameters are set according to predefined guidelines. The results confirm that ClaSP PE robustly generalizes to novel tasks without requiring dataset-specific tuning. Within the nnActive framework, we present compelling evidence that an AL method can consistently outperform random baselines adapted to 3D segmentation, in terms of both performance and annotation efficiency in a realistic, close-to-production scenario. Our open-source implementation and clear deployment guidelines make it readily applicable in practice. Code is at https://github.com/MIC-DKFZ/nnActive.

</details>


### [223] [Dynamic Differential Linear Attention: Enhancing Linear Diffusion Transformer for High-Quality Image Generation](https://arxiv.org/abs/2601.13683)
*Boyuan Cao,Xingbo Yao,Chenhui Wang,Jiaxin Ye,Yujie Wei,Hongming Shan*

Main category: cs.CV

TL;DR: DyDi-LiT通过动态差分线性注意力（DyDiLA）解决了线性扩散变换器的过平滑问题，显著提升了生成质量，并在实验中超越了现有最佳模型。


<details>
  <summary>Details</summary>
Motivation: 现有的线性扩散变换器（LiTs）虽然降低了计算成本，但常因过平滑的注意力权重导致生成性能下降。DyDiLA旨在通过新颖的线性注意力机制提升LiTs的表达能力和生成质量。

Method: 提出了动态差分线性注意力（DyDiLA），包含三个关键设计：动态投影模块、动态测量核和令牌差分算子，以解决线性注意力机制中的过平滑问题。基于DyDiLA，构建了改进的LiT模型DyDi-LiT。

Result: 实验表明，DyDi-LiT在多个指标上均优于当前最先进模型，验证了DyDiLA的有效性。

Conclusion: DyDi-LiT，通过引入动态差分线性注意力（DyDiLA），显著提升了线性扩散变换器（LiTs）的生成质量，并在多个指标上超越了现有最佳模型，展示了其强大的实际应用潜力。

Abstract: Diffusion transformers (DiTs) have emerged as a powerful architecture for high-fidelity image generation, yet the quadratic cost of self-attention poses a major scalability bottleneck. To address this, linear attention mechanisms have been adopted to reduce computational cost; unfortunately, the resulting linear diffusion transformers (LiTs) models often come at the expense of generative performance, frequently producing over-smoothed attention weights that limit expressiveness. In this work, we introduce Dynamic Differential Linear Attention (DyDiLA), a novel linear attention formulation that enhances the effectiveness of LiTs by mitigating the oversmoothing issue and improving generation quality. Specifically, the novelty of DyDiLA lies in three key designs: (i) dynamic projection module, which facilitates the decoupling of token representations by learning with dynamically assigned knowledge; (ii) dynamic measure kernel, which provides a better similarity measurement to capture fine-grained semantic distinctions between tokens by dynamically assigning kernel functions for token processing; and (iii) token differential operator, which enables more robust query-to-key retrieval by calculating the differences between the tokens and their corresponding information redundancy produced by dynamic measure kernel. To capitalize on DyDiLA, we introduce a refined LiT, termed DyDi-LiT, that systematically incorporates our advancements. Extensive experiments show that DyDi-LiT consistently outperforms current state-of-the-art (SOTA) models across multiple metrics, underscoring its strong practical potential.

</details>


### [224] [Reasoning or Pattern Matching? Probing Large Vision-Language Models with Visual Puzzles](https://arxiv.org/abs/2601.13705)
*Maria Lymperaiou,Vasileios Karampinis,Giorgos Filandrianos,Angelos Vlachos,Chrysoula Zerva,Athanasios Voulodimos*

Main category: cs.CV

TL;DR: 该调查统一了视觉谜题在LVLMs中的视角，分类现有基准测试，揭示模型局限性，并展望未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 视觉谜题作为人类认知的紧凑且揭示性探针，可以评估LVLMs的推理能力，提供可控且可验证的多模态基准测试替代方案。

Method: 通过统一的抽象框架组织现有基准测试，并按目标推理机制（归纳、类比、算法、演绎和几何/空间）分类，将谜题设计与解决所需的认知操作联系起来。

Result: 研究发现当前模型存在普遍局限性，如脆弱的泛化能力、感知与推理的紧密纠缠，以及流畅解释与忠实执行之间的持续差距。

Conclusion: 该调查总结了视觉谜题在大型视觉语言模型（LVLMs）中的诊断作用，指出了当前模型的局限性，并提出了未来基准测试和推理感知多模态系统的关键方向。

Abstract: Puzzles have long served as compact and revealing probes of human cognition, isolating abstraction, rule discovery, and systematic reasoning with minimal reliance on prior knowledge. Leveraging these properties, visual puzzles have recently emerged as a powerful diagnostic tool for evaluating the reasoning abilities of Large Vision-Language Models (LVLMs), offering controlled, verifiable alternatives to open-ended multimodal benchmarks. This survey provides a unified perspective of visual puzzle reasoning in LVLMs. We frame visual puzzles through a common abstraction and organize existing benchmarks by the reasoning mechanisms they target (inductive, analogical, algorithmic, deductive, and geometric/spatial), thereby linking puzzle design to the cognitive operations required for solving. Synthesizing empirical evidence across these categories, we identify consistent limitations in current models, including brittle generalization, tight entanglement between perception and reasoning, and a persistent gap between fluent explanations and faithful execution. By framing visual puzzles as diagnostic instruments rather than task formats, this survey elaborates on the state of LVLM reasoning and outlines key directions for future benchmarks and reasoning-aware multimodal systems.

</details>


### [225] [ParkingTwin: Training-Free Streaming 3D Reconstruction for Parking-Lot Digital Twins](https://arxiv.org/abs/2601.13706)
*Xinhao Liu,Yu Wang,Xiansheng Guo,Gordon Owusu Boateng,Yu Cao,Haonan Si,Xingchen Guo,Nirwan Ansari*

Main category: cs.CV

TL;DR: ParkingTwin是一个实时3D重建系统，通过OSM语义拓扑、动态过滤和光照鲁棒融合技术，显著提升了重建效率和质量，适用于边缘设备。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶代客泊车（AVP）中高保真数字孪生重建面临的几何模糊、动态遮挡和光照变化等挑战。

Method: ParkingTwin结合了OSM语义拓扑驱动的几何构造、几何感知的动态过滤和光照鲁棒的融合技术，实现了高效的在线3D重建。

Result: 在68,000平方米的真实数据集上，ParkingTwin实现了SSIM 0.87（提升16%），端到端速度提升15倍，GPU内存减少83.3%。

Conclusion: ParkingTwin是一个轻量级、免训练的系统，能够在边缘设备上实时进行3D重建，显著提升了重建质量和效率，同时降低了硬件需求。

Abstract: High-fidelity parking-lot digital twins provide essential priors for path planning, collision checking, and perception validation in Automated Valet Parking (AVP). Yet robot-oriented reconstruction faces a trilemma: sparse forward-facing views cause weak parallax and ill-posed geometry; dynamic occlusions and extreme lighting hinder stable texture fusion; and neural rendering typically needs expensive offline optimization, violating edge-side streaming constraints. We propose ParkingTwin, a training-free, lightweight system for online streaming 3D reconstruction. First, OSM-prior-driven geometric construction uses OpenStreetMap semantic topology to directly generate a metric-consistent TSDF, replacing blind geometric search with deterministic mapping and avoiding costly optimization. Second, geometry-aware dynamic filtering employs a quad-modal constraint field (normal/height/depth consistency) to reject moving vehicles and transient occlusions in real time. Third, illumination-robust fusion in CIELAB decouples luminance and chromaticity via adaptive L-channel weighting and depth-gradient suppression, reducing seams under abrupt lighting changes. ParkingTwin runs at 30+ FPS on an entry-level GTX 1660. On a 68,000 m^2 real-world dataset, it achieves SSIM 0.87 (+16.0%), delivers about 15x end-to-end speedup, and reduces GPU memory by 83.3% compared with state-of-the-art 3D Gaussian Splatting (3DGS) that typically requires high-end GPUs (RTX 4090D). The system outputs explicit triangle meshes compatible with Unity/Unreal digital-twin pipelines. Project page: https://mihoutao-liu.github.io/ParkingTwin/

</details>


### [226] [MVGD-Net: A Novel Motion-aware Video Glass Surface Detection Network](https://arxiv.org/abs/2601.13715)
*Yiwei Lu,Hao Huang,Tao Yan*

Main category: cs.CV

TL;DR: MVGD-Net利用运动不一致性检测视频中的玻璃表面，通过新模块和数据集验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 玻璃表面在视频运动场景中会导致反射（或透射）物体运动速度与非玻璃区域不一致，这种运动不一致性可有效揭示玻璃表面的存在。

Method: 提出了MVGD-Net网络，包含跨尺度多模态融合模块（CMFM）、历史引导注意力模块（HGAM）和时间交叉注意力模块（TCAM），以及时空解码器（TSD）。

Result: MVGD-Net在包含312个多样玻璃场景的大规模数据集上表现优异。

Conclusion: MVGD-Net通过利用运动不一致性线索，在视频中检测玻璃表面，表现优于现有最先进方法。

Abstract: Glass surface ubiquitous in both daily life and professional environments presents a potential threat to vision-based systems, such as robot and drone navigation. To solve this challenge, most recent studies have shown significant interest in Video Glass Surface Detection (VGSD). We observe that objects in the reflection (or transmission) layer appear farther from the glass surfaces. Consequently, in video motion scenarios, the notable reflected (or transmitted) objects on the glass surface move slower than objects in non-glass regions within the same spatial plane, and this motion inconsistency can effectively reveal the presence of glass surfaces. Based on this observation, we propose a novel network, named MVGD-Net, for detecting glass surfaces in videos by leveraging motion inconsistency cues. Our MVGD-Net features three novel modules: the Cross-scale Multimodal Fusion Module (CMFM) that integrates extracted spatial features and estimated optical flow maps, the History Guided Attention Module (HGAM) and Temporal Cross Attention Module (TCAM), both of which further enhances temporal features. A Temporal-Spatial Decoder (TSD) is also introduced to fuse the spatial and temporal features for generating the glass region mask. Furthermore, for learning our network, we also propose a large-scale dataset, which comprises 312 diverse glass scenarios with a total of 19,268 frames. Extensive experiments demonstrate that our MVGD-Net outperforms relevant state-of-the-art methods.

</details>


### [227] [Facial Spatiotemporal Graphs: Leveraging the 3D Facial Surface for Remote Physiological Measurement](https://arxiv.org/abs/2601.13724)
*Sam Cantrill,David Ahmedt-Aristizabal,Lars Petersson,Hanna Suominen,Mohammad Ali Armin*

Main category: cs.CV

TL;DR: 提出STGraph和MeshPhys方法，通过3D面部网格序列对齐感受野，显著提升rPPG信号估计性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法未能明确将感受野与3D面部表面对齐，而面部表面是rPPG信号的空间支撑。

Method: 提出Facial Spatiotemporal Graph（STGraph）表示，结合3D面部网格序列编码面部颜色和结构，并设计轻量级时空图卷积网络MeshPhys进行生理信号估计。

Result: 在四个基准数据集上，MeshPhys在数据集内和跨数据集设置中均达到最先进或竞争性性能。消融研究表明，将模型感受野限制在面部表面是一种强大的结构先验，且表面对齐的3D感知节点特征对稳健编码面部表面颜色至关重要。

Conclusion: STGraph和MeshPhys为面部rPPG提供了一种新颖、原则性的建模范式，实现了稳健、可解释且可泛化的信号估计。

Abstract: Facial remote photoplethysmography (rPPG) methods estimate physiological signals by modeling subtle color changes on the 3D facial surface over time. However, existing methods fail to explicitly align their receptive fields with the 3D facial surface-the spatial support of the rPPG signal. To address this, we propose the Facial Spatiotemporal Graph (STGraph), a novel representation that encodes facial color and structure using 3D facial mesh sequences-enabling surface-aligned spatiotemporal processing. We introduce MeshPhys, a lightweight spatiotemporal graph convolutional network that operates on the STGraph to estimate physiological signals. Across four benchmark datasets, MeshPhys achieves state-of-the-art or competitive performance in both intra- and cross-dataset settings. Ablation studies show that constraining the model's receptive field to the facial surface acts as a strong structural prior, and that surface-aligned, 3D-aware node features are critical for robustly encoding facial surface color. Together, the STGraph and MeshPhys constitute a novel, principled modeling paradigm for facial rPPG, enabling robust, interpretable, and generalizable estimation. Code is available at https://samcantrill.github.io/facial-stgraph-rppg/ .

</details>


### [228] [HiT: History-Injection Transformers for Onboard Continuous Flood Change Detection](https://arxiv.org/abs/2601.13751)
*Daniel Kyselica,Jonáš Herec,Oliver Kutis,Rado Pitoňák*

Main category: cs.CV

TL;DR: 本文提出HiT-Prithvi模型，通过减少99%数据存储并保持检测精度，实现了小型卫星上的实时洪水监测。


<details>
  <summary>Details</summary>
Motivation: 解决洪水检测这一灾害管理中的关键应用，通过开发适用于小型卫星的机载变化检测系统，满足多时相数据处理和严格操作约束的需求。

Method: 开发了一种名为History Injection mechanism for Transformer models (HiT)的机载变化检测系统，该系统在小型卫星的内存和计算限制内运行，并通过HiT机制减少了99%以上的原始图像数据存储。

Result: 在STTORM-CD洪水数据集上的测试表明，HiT机制在Prithvi-tiny基础模型中保持了与双时相基线相当的检测精度，并在Jetson Orin Nano上实现了43 FPS的处理速度。

Conclusion: 本文提出了HiT-Prithvi模型，为基于卫星的自然灾害连续监测建立了实用框架，支持实时灾害评估，无需依赖地面处理基础设施。

Abstract: Natural disaster monitoring through continuous satellite observation requires processing multi-temporal data under strict operational constraints. This paper addresses flood detection, a critical application for hazard management, by developing an onboard change detection system that operates within the memory and computational limits of small satellites. We propose History Injection mechanism for Transformer models (HiT), that maintains historical context from previous observations while reducing data storage by over 99\% of original image size. Moreover, testing on the STTORM-CD flood dataset confirms that the HiT mechanism within the Prithvi-tiny foundation model maintains detection accuracy compared to the bitemporal baseline. The proposed HiT-Prithvi model achieved 43 FPS on Jetson Orin Nano, a representative onboard hardware used in nanosats. This work establishes a practical framework for satellite-based continuous monitoring of natural disasters, supporting real-time hazard assessment without dependency on ground-based processing infrastructure. Architecture as well as model checkpoints is available at https://github.com/zaitra/HiT-change-detection

</details>


### [229] [PREGEN: Uncovering Latent Thoughts in Composed Video Retrieval](https://arxiv.org/abs/2601.13797)
*Gabriele Serussi,David Vainshtein,Jonathan Kouchly,Dotan Di Castro,Chaim Baskin*

Main category: cs.CV

TL;DR: PREGEN是一种高效的组合视频检索框架，结合预训练VLM和轻量编码器，显著提升性能且无需微调。


<details>
  <summary>Details</summary>
Motivation: 当前组合视频检索方法未能充分利用现代视觉语言模型，存在架构过时或计算成本高的问题。

Method: PREGEN采用冻结的预训练视觉语言模型（VLM）与轻量级编码模型相结合，无需微调VLM，仅通过提取隐藏状态并训练简单编码器来生成紧凑的检索嵌入。

Result: PREGEN在标准CoVR基准测试中显著超越现有方法，Recall@1提升+27.23和+69.59，并在复杂文本修改任务中展现出强零样本泛化能力。

Conclusion: PREGEN框架通过结合预训练的视觉语言模型和轻量级编码模型，显著提升了组合视频检索的性能，且在零样本泛化能力上表现出色。

Abstract: Composed Video Retrieval (CoVR) aims to retrieve a video based on a query video and a modifying text. Current CoVR methods fail to fully exploit modern Vision-Language Models (VLMs), either using outdated architectures or requiring computationally expensive fine-tuning and slow caption generation. We introduce PREGEN (PRE GENeration extraction), an efficient and powerful CoVR framework that overcomes these limitations. Our approach uniquely pairs a frozen, pre-trained VLM with a lightweight encoding model, eliminating the need for any VLM fine-tuning. We feed the query video and modifying text into the VLM and extract the hidden state of the final token from each layer. A simple encoder is then trained on these pooled representations, creating a semantically rich and compact embedding for retrieval. PREGEN significantly advances the state of the art, surpassing all prior methods on standard CoVR benchmarks with substantial gains in Recall@1 of +27.23 and +69.59. Our method demonstrates robustness across different VLM backbones and exhibits strong zero-shot generalization to more complex textual modifications, highlighting its effectiveness and semantic capabilities.

</details>


### [230] [Discriminant Learning-based Colorspace for Blade Segmentation](https://arxiv.org/abs/2601.13816)
*Raül Pérez-Gonzalo,Andreas Espersen,Antonio Agudo*

Main category: cs.CV

TL;DR: CSDA是一种新型色彩空间判别分析算法，通过优化色彩表示提升图像分割准确性，实验验证了其在特定领域的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有算法常忽视色彩表示对图像分割准确性的影响，导致分割效果不佳。

Method: 提出了一种新颖的多维非线性判别分析算法Colorspace Discriminant Analysis (CSDA)，通过最大化多维有符号类间可分性并最小化类内变异性来定制色彩表示。

Result: 在风力涡轮机叶片数据上的实验显示，CSDA显著提高了分割准确性。

Conclusion: CSDA算法通过优化色彩表示显著提升了图像分割的准确性，强调了在特定领域分割中定制化预处理的重要性。

Abstract: Suboptimal color representation often hinders accurate image segmentation, yet many modern algorithms neglect this critical preprocessing step. This work presents a novel multidimensional nonlinear discriminant analysis algorithm, Colorspace Discriminant Analysis (CSDA), for improved segmentation. Extending Linear Discriminant Analysis into a deep learning context, CSDA customizes color representation by maximizing multidimensional signed inter-class separability while minimizing intra-class variability through a generalized discriminative loss. To ensure stable training, we introduce three alternative losses that enable end-to-end optimization of both the discriminative colorspace and segmentation process. Experiments on wind turbine blade data demonstrate significant accuracy gains, emphasizing the importance of tailored preprocessing in domain-specific segmentation.

</details>


### [231] [FastGHA: Generalized Few-Shot 3D Gaussian Head Avatars with Real-Time Animation](https://arxiv.org/abs/2601.13837)
*Xinya Ji,Sebastian Weiss,Manuel Kansy,Jacek Naruniec,Xun Cao,Barbara Solenthaler,Derek Bradley*

Main category: cs.CV

TL;DR: 提出了一种高效生成高质量高斯头像的方法，仅需少量输入图像，支持实时动画，并在渲染质量和效率上优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管3D高斯基头像建模取得进展，但高效生成高保真头像仍具挑战性。现有方法依赖多视图捕获或单目视频，限制了在未见主体上的可扩展性和易用性。

Method: 提出了一种基于前馈的方法，直接从少量输入图像中学习每像素高斯表示，并使用基于transformer的编码器聚合多视图信息。为支持实时动画，扩展了显式高斯表示，并引入了轻量级MLP动态网络来预测3D高斯变形。

Result: 实验表明，该方法在渲染质量和推理效率上显著优于现有方法。

Conclusion: 该方法在渲染质量和推理效率上显著优于现有方法，同时支持实时动态头像动画。

Abstract: Despite recent progress in 3D Gaussian-based head avatar modeling, efficiently generating high fidelity avatars remains a challenge. Current methods typically rely on extensive multi-view capture setups or monocular videos with per-identity optimization during inference, limiting their scalability and ease of use on unseen subjects. To overcome these efficiency drawbacks, we propose \OURS, a feed-forward method to generate high-quality Gaussian head avatars from only a few input images while supporting real-time animation. Our approach directly learns a per-pixel Gaussian representation from the input images, and aggregates multi-view information using a transformer-based encoder that fuses image features from both DINOv3 and Stable Diffusion VAE. For real-time animation, we extend the explicit Gaussian representations with per-Gaussian features and introduce a lightweight MLP-based dynamic network to predict 3D Gaussian deformations from expression codes. Furthermore, to enhance geometric smoothness of the 3D head, we employ point maps from a pre-trained large reconstruction model as geometry supervision. Experiments show that our approach significantly outperforms existing methods in both rendering quality and inference efficiency, while supporting real-time dynamic avatar animation.

</details>


### [232] [DisasterVQA: A Visual Question Answering Benchmark Dataset for Disaster Scenes](https://arxiv.org/abs/2601.13839)
*Aisha Al-Mohannadi,Ayisha Firoz,Yin Yang,Muhammad Imran,Ferda Ofli*

Main category: cs.CV

TL;DR: DisasterVQA 是一个针对灾难响应设计的 VQA 基准数据集，测试发现现有模型在复杂推理任务中表现不足，需进一步优化。


<details>
  <summary>Details</summary>
Motivation: 社交媒体图像在灾难响应中提供低延迟的情境信息，但现有 VQA 技术在复杂且安全关键的灾难推理中的适用性尚不明确。

Method: 引入 DisasterVQA 基准数据集，包含 1,395 张真实世界图像和 4,405 个专家策划的问答对，涵盖多种灾难事件。基于 FEMA ESF 和 OCHA MIRA 等人道主义框架，数据集包含二元、多项选择和开放式问题。

Result: 测试了七种最先进的视觉语言模型，发现它们在二元问题上表现良好，但在细粒度定量推理、对象计数和上下文敏感解释方面表现不佳，尤其是对于代表性不足的灾难场景。

Conclusion: DisasterVQA 提供了一个具有挑战性和实用性的基准，旨在指导开发更鲁棒且对灾难响应操作更有意义的视觉语言模型。

Abstract: Social media imagery provides a low-latency source of situational information during natural and human-induced disasters, enabling rapid damage assessment and response. While Visual Question Answering (VQA) has shown strong performance in general-purpose domains, its suitability for the complex and safety-critical reasoning required in disaster response remains unclear. We introduce DisasterVQA, a benchmark dataset designed for perception and reasoning in crisis contexts. DisasterVQA consists of 1,395 real-world images and 4,405 expert-curated question-answer pairs spanning diverse events such as floods, wildfires, and earthquakes. Grounded in humanitarian frameworks including FEMA ESF and OCHA MIRA, the dataset includes binary, multiple-choice, and open-ended questions covering situational awareness and operational decision-making tasks. We benchmark seven state-of-the-art vision-language models and find performance variability across question types, disaster categories, regions, and humanitarian tasks. Although models achieve high accuracy on binary questions, they struggle with fine-grained quantitative reasoning, object counting, and context-sensitive interpretation, particularly for underrepresented disaster scenarios. DisasterVQA provides a challenging and practical benchmark to guide the development of more robust and operationally meaningful vision-language models for disaster response. The dataset is publicly available at https://zenodo.org/records/18267770.

</details>


### [233] [Probabilistic Deep Discriminant Analysis for Wind Blade Segmentation](https://arxiv.org/abs/2601.13852)
*Raül Pérez-Gonzalo,Andreas Espersen,Antonio Agudo*

Main category: cs.CV

TL;DR: 提出概率深度判别分析（PDDA），通过优化Fisher准则和结合概率损失，显著提升风力叶片分割的性能和稳定性。


<details>
  <summary>Details</summary>
Motivation: 线性判别分析在非线性可分数据上表现不佳，因此需要一种能够直接优化Fisher准则并适应深度网络的方法。

Method: 引入了深度判别分析（DDA），通过深度网络直接优化Fisher准则，并结合有符号类间方差、Sigmoid函数输出限制及乘法关系转加法关系来确保训练稳定性。提出了两种稳定的DDA损失函数，并进一步结合概率损失形成概率DDA（PDDA）。

Result: PDDA有效减少了输出分布中的类别重叠，产生了高置信度的预测并降低了类内方差。

Conclusion: PDDA在风力叶片分割中表现出显著的性能和一致性提升，这是DDA首次应用于图像分割领域。

Abstract: Linear discriminant analysis improves class separability but struggles with non-linearly separable data. To overcome this, we introduce Deep Discriminant Analysis (DDA), which directly optimizes the Fisher criterion utilizing deep networks. To ensure stable training and avoid computational instabilities, we incorporate signed between-class variance, bound outputs with a sigmoid function, and convert multiplicative relationships into additive ones. We present two stable DDA loss functions and augment them with a probability loss, resulting in Probabilistic DDA (PDDA). PDDA effectively minimizes class overlap in output distributions, producing highly confident predictions with reduced within-class variance. When applied to wind blade segmentation, PDDA showcases notable advances in performance and consistency, critical for wind energy maintenance. To our knowledge, this is the first application of DDA to image segmentation.

</details>


### [234] [OCCAM: Class-Agnostic, Training-Free, Prior-Free and Multi-Class Object Counting](https://arxiv.org/abs/2601.13871)
*Michail Spanakis,Iason Oikonomidis,Antonis Argyros*

Main category: cs.CV

TL;DR: OCCAM是首个无需训练的多类别对象计数方法，利用SAM2和FINCH算法变体，在基准数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有CAC方法通常依赖单类别假设或额外信息，OCCAM旨在解决这些限制。

Method: 利用Segment Anything Model 2（SAM2）和自定义的FINCH算法变体实现。

Result: 在FSC-147和CARPK数据集上表现优异，并提出了合成多类别数据集和F1评分作为更合适的评估指标。

Conclusion: OCCAM是首个无需训练且无需额外信息的CAC方法，能够处理多类别对象计数问题，并在FSC-147和CARPK基准数据集上表现优异。

Abstract: Class-Agnostic object Counting (CAC) involves counting instances of objects from arbitrary classes within an image. Due to its practical importance, CAC has received increasing attention in recent years. Most existing methods assume a single object class per image, rely on extensive training of large deep learning models and address the problem by incorporating additional information, such as visual exemplars or text prompts. In this paper, we present OCCAM, the first training-free approach to CAC that operates without the need of any supplementary information. Moreover, our approach addresses the multi-class variant of the problem, as it is capable of counting the object instances in each and every class among arbitrary object classes within an image. We leverage Segment Anything Model 2 (SAM2), a foundation model, and a custom threshold-based variant of the First Integer Neighbor Clustering Hierarchy (FINCH) algorithm to achieve competitive performance on widely used benchmark datasets, FSC-147 and CARPK. We propose a synthetic multi-class dataset and F1 score as a more suitable evaluation metric. The code for our method and the proposed synthetic dataset will be made publicly available at https://mikespanak.github.io/OCCAM_counter.

</details>


### [235] [Revisiting Multi-Task Visual Representation Learning](https://arxiv.org/abs/2601.13886)
*Shangzhe Di,Zhonghua Zhai,Weidi Xie*

Main category: cs.CV

TL;DR: MTV框架通过整合视觉语言对比、自监督和密集空间目标，结合伪标签技术，实现了视觉表示学习的全局与局部优势互补。


<details>
  <summary>Details</summary>
Motivation: 当前视觉表示学习方法在全局语义对齐和局部结构捕捉上存在互补性，但缺乏整合。MTV旨在通过多任务框架和密集空间监督实现两者的优势结合。

Method: 提出了MTV多任务视觉预训练框架，结合视觉语言对比、自监督和密集空间目标，利用专家模型（如Depth Anything V2和OWLv2）生成伪标签。

Result: MTV在细粒度空间推理和全局语义理解上均表现出色，验证了多任务学习与伪监督的可扩展性。

Conclusion: MTV框架通过多任务学习和高质量伪监督，实现了视觉编码器的全局语义理解和局部空间推理能力的双重提升，为通用视觉编码器的开发提供了可扩展的路径。

Abstract: Current visual representation learning remains bifurcated: vision-language models (e.g., CLIP) excel at global semantic alignment but lack spatial precision, while self-supervised methods (e.g., MAE, DINO) capture intricate local structures yet struggle with high-level semantic context. We argue that these paradigms are fundamentally complementary and can be integrated into a principled multi-task framework, further enhanced by dense spatial supervision. We introduce MTV, a multi-task visual pretraining framework that jointly optimizes a shared backbone across vision-language contrastive, self-supervised, and dense spatial objectives. To mitigate the need for manual annotations, we leverage high-capacity "expert" models -- such as Depth Anything V2 and OWLv2 -- to synthesize dense, structured pseudo-labels at scale. Beyond the framework, we provide a systematic investigation into the mechanics of multi-task visual learning, analyzing: (i) the marginal gain of each objective, (ii) task synergies versus interference, and (iii) scaling behavior across varying data and model scales. Our results demonstrate that MTV achieves "best-of-both-worlds" performance, significantly enhancing fine-grained spatial reasoning without compromising global semantic understanding. Our findings suggest that multi-task learning, fueled by high-quality pseudo-supervision, is a scalable path toward more general visual encoders.

</details>


### [236] [Towards Visually Explaining Statistical Tests with Applications in Biomedical Imaging](https://arxiv.org/abs/2601.13899)
*Masoumeh Javanbakhat,Piotr Komorowski,Dilyara Bareeva,Wei-Chang Lai,Wojciech Samek,Christoph Lippert*

Main category: cs.CV

TL;DR: 提出了一种可解释的深度统计测试框架，通过样本和特征级解释增强深度两样本测试，揭示了驱动组间差异的关键因素，为医学影像分析提供了直观见解。


<details>
  <summary>Details</summary>
Motivation: 尽管深度神经网络两样本测试在检测组间分布差异方面表现出强大能力，但其黑盒特性限制了在生物医学分析中的可解释性和实际应用。此外，现有的后验解释方法大多依赖类标签，不适用于无标签统计测试场景。

Method: 该方法通过增强深度两样本测试，提供样本级和特征级解释，揭示了哪些样本和输入特征驱动了显著的组间差异。

Result: 在生物医学影像数据上的应用表明，该框架能够识别有影响力的样本，并突出与疾病相关变异相关的解剖学意义区域。

Conclusion: 该研究通过提出一种可解释的深度统计测试框架，成功将统计推断与可解释AI结合，为医学影像中的无标签群体分析提供了直观的见解。

Abstract: Deep neural two-sample tests have recently shown strong power for detecting distributional differences between groups, yet their black-box nature limits interpretability and practical adoption in biomedical analysis. Moreover, most existing post-hoc explainability methods rely on class labels, making them unsuitable for label-free statistical testing settings. We propose an explainable deep statistical testing framework that augments deep two-sample tests with sample-level and feature-level explanations, revealing which individual samples and which input features drive statistically significant group differences. Our method highlights which image regions and which individual samples contribute most to the detected group difference, providing spatial and instance-wise insight into the test's decision. Applied to biomedical imaging data, the proposed framework identifies influential samples and highlights anatomically meaningful regions associated with disease-related variation. This work bridges statistical inference and explainable AI, enabling interpretable, label-free population analysis in medical imaging.

</details>


### [237] [On the Role of Rotation Equivariance in Monocular 3D Human Pose Estimation](https://arxiv.org/abs/2601.13913)
*Pavlo Melnyk,Cuong Le,Urs Waldmann,Per-Erik Forssén,Bastian Wandt*

Main category: cs.CV

TL;DR: 本文提出通过数据增强学习2D旋转等变性，提升单视图3D人体姿态估计性能，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决单视图3D人体姿态估计中的旋转输入问题，提出学习旋转等变性比直接学习点对点映射更简单且几何基础更牢固。

Method: 采用两阶段方法，首先检测2D骨骼关节点，然后进行2D到3D的提升，并通过数据增强学习旋转等变性。

Result: 在常见的人体姿态估计基准测试中，通过增强学习的旋转等变性模型优于设计等变性方法。

Conclusion: 通过增强学习2D旋转等变性，模型在单视图3D人体姿态估计任务中表现优于现有的设计等变性方法。

Abstract: Estimating 3D from 2D is one of the central tasks in computer vision. In this work, we consider the monocular setting, i.e. single-view input, for 3D human pose estimation (HPE). Here, the task is to predict a 3D point set of human skeletal joints from a single 2D input image. While by definition this is an ill-posed problem, recent work has presented methods that solve it with up to several-centimetre error. Typically, these methods employ a two-step approach, where the first step is to detect the 2D skeletal joints in the input image, followed by the step of 2D-to-3D lifting. We find that common lifting models fail when encountering a rotated input. We argue that learning a single human pose along with its in-plane rotations is considerably easier and more geometrically grounded than directly learning a point-to-point mapping. Furthermore, our intuition is that endowing the model with the notion of rotation equivariance without explicitly constraining its parameter space should lead to a more straightforward learning process than one with equivariance by design. Utilising the common HPE benchmarks, we confirm that the 2D rotation equivariance per se improves the model performance on human poses akin to rotations in the image plane, and can be efficiently and straightforwardly learned by augmentation, outperforming state-of-the-art equivariant-by-design methods.

</details>


### [238] [TrackletGPT: A Language-like GPT Framework for White Matter Tract Segmentation](https://arxiv.org/abs/2601.13935)
*Anoushkrit Goel,Simroop Singh,Ankita Joshi,Ranjeet Ranjan Jha,Chirag Ahuja,Aditya Nigam,Arnav Bhavsar*

Main category: cs.CV

TL;DR: TrackletGPT是一种基于GPT的框架，通过tracklets重新引入序列信息，在白质束分割任务中表现优异，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 白质束分割对研究脑结构连接、神经系统疾病和神经外科至关重要，但由于束间、跨受试者和条件下的差异以及跨半球和受试者的相似3D结构，任务复杂。

Method: 提出TrackletGPT，一种类似GPT的框架，利用tracklets重新引入序列信息，实现全自动、跨数据集通用，并能编码细粒度子流线片段。

Result: TrackletGPT在平均DICE、Overlap和Overreach分数上优于现有方法，包括跨数据集实验。

Conclusion: TrackletGPT在TractoInferno和HCP数据集上表现出色，优于现有方法，展示了其在白质束分割中的潜力。

Abstract: White Matter Tract Segmentation is imperative for studying brain structural connectivity, neurological disorders and neurosurgery. This task remains complex, as tracts differ among themselves, across subjects and conditions, yet have similar 3D structure across hemispheres and subjects. To address these challenges, we propose TrackletGPT, a language-like GPT framework which reintroduces sequential information in tokens using tracklets. TrackletGPT generalises seamlessly across datasets, is fully automatic, and encodes granular sub-streamline segments, Tracklets, scaling and refining GPT models in Tractography Segmentation. Based on our experiments, TrackletGPT outperforms state-of-the-art methods on average DICE, Overlap and Overreach scores on TractoInferno and HCP datasets, even on inter-dataset experiments.

</details>


### [239] [VTONGuard: Automatic Detection and Authentication of AI-Generated Virtual Try-On Content](https://arxiv.org/abs/2601.13951)
*Shengyi Wu,Yan Hong,Shengyao Chen,Zheng Wang,Xianbing Sun,Jiahui Zhan,Jun Lan,Jianfu Zhang*

Main category: cs.CV

TL;DR: VTONGuard是一个大规模虚拟试穿图像数据集，用于评估检测方法并促进安全部署，通过多任务框架提升检测性能。


<details>
  <summary>Details</summary>
Motivation: 随着生成式AI的快速发展，虚拟试穿（VTON）系统在电子商务和数字娱乐中日益普及，但其真实性及负责任使用问题亟待解决。

Method: 提出了VTONGuard大规模基准数据集，包含超过775,000张真实与合成试穿图像，并基于此数据集系统评估了多种检测范式。设计了集成辅助分割的多任务框架以增强边界感知特征学习。

Result: 多任务框架在VTONGuard上实现了最佳整体性能，揭示了各方法的优缺点及跨范式泛化的持续挑战。

Conclusion: VTONGuard基准数据集及其多任务框架为虚拟试穿技术的安全与负责任部署提供了支持，促进了更强大检测模型的发展。

Abstract: With the rapid advancement of generative AI, virtual try-on (VTON) systems are becoming increasingly common in e-commerce and digital entertainment. However, the growing realism of AI-generated try-on content raises pressing concerns about authenticity and responsible use. To address this, we present VTONGuard, a large-scale benchmark dataset containing over 775,000 real and synthetic try-on images. The dataset covers diverse real-world conditions, including variations in pose, background, and garment styles, and provides both authentic and manipulated examples. Based on this benchmark, we conduct a systematic evaluation of multiple detection paradigms under unified training and testing protocols. Our results reveal each method's strengths and weaknesses and highlight the persistent challenge of cross-paradigm generalization. To further advance detection, we design a multi-task framework that integrates auxiliary segmentation to enhance boundary-aware feature learning, achieving the best overall performance on VTONGuard. We expect this benchmark to enable fair comparisons, facilitate the development of more robust detection models, and promote the safe and responsible deployment of VTON technologies in practice.

</details>


### [240] [DExTeR: Weakly Semi-Supervised Object Detection with Class and Instance Experts for Medical Imaging](https://arxiv.org/abs/2601.13954)
*Adrien Meyer,Didier Mutter,Nicolas Padoy*

Main category: cs.CV

TL;DR: DExTeR是一种基于Transformer的点到框回归器，专为医学影像设计，通过类引导可变形注意力和CLICK-MoE提升检测性能，并在多点训练策略下实现高鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 医学影像中的解剖标志检测对诊断和干预指导至关重要，但传统目标检测模型依赖高成本的边界框标注，限制了可扩展性。弱半监督目标检测（WSSOD）通过点标注减少标注时间，但医学影像的独特挑战（如重叠解剖结构、可变对象大小和难以捉摸的结构）阻碍了准确的边界框推断。

Method: DExTeR基于Point-DETR，将单点标注编码为对象查询，通过提出的类引导可变形注意力改进特征提取，并引入CLICK-MoE解耦类和实例表示以减少相邻或重叠实例的混淆。此外，采用多点训练策略提升对标注变化的鲁棒性。

Result: DExTeR在三种医学领域数据集上表现优异，显著降低了标注成本并保持了高检测准确性。

Conclusion: DExTeR（DETR with Experts）在三种不同医学领域数据集（内窥镜、胸部X光和内窥镜超声）上实现了最先进的性能，展示了其在降低标注成本的同时保持高检测准确性的潜力。

Abstract: Detecting anatomical landmarks in medical imaging is essential for diagnosis and intervention guidance. However, object detection models rely on costly bounding box annotations, limiting scalability. Weakly Semi-Supervised Object Detection (WSSOD) with point annotations proposes annotating each instance with a single point, minimizing annotation time while preserving localization signals. A Point-to-Box teacher model, trained on a small box-labeled subset, converts these point annotations into pseudo-box labels to train a student detector. Yet, medical imagery presents unique challenges, including overlapping anatomy, variable object sizes, and elusive structures, which hinder accurate bounding box inference. To overcome these challenges, we introduce DExTeR (DETR with Experts), a transformer-based Point-to-Box regressor tailored for medical imaging. Built upon Point-DETR, DExTeR encodes single-point annotations as object queries, refining feature extraction with the proposed class-guided deformable attention, which guides attention sampling using point coordinates and class labels to capture class-specific characteristics. To improve discrimination in complex structures, it introduces CLICK-MoE (CLass, Instance, and Common Knowledge Mixture of Experts), decoupling class and instance representations to reduce confusion among adjacent or overlapping instances. Finally, we implement a multi-point training strategy which promotes prediction consistency across different point placements, improving robustness to annotation variability. DExTeR achieves state-of-the-art performance across three datasets spanning different medical domains (endoscopy, chest X-rays, and endoscopic ultrasound) highlighting its potential to reduce annotation costs while maintaining high detection accuracy.

</details>


### [241] [STEC: A Reference-Free Spatio-Temporal Entropy Coverage Metric for Evaluating Sampled Video Frames](https://arxiv.org/abs/2601.13974)
*Shih-Yao Lin*

Main category: cs.CV

TL;DR: STEC是一种新的视频帧采样评估指标，通过时空熵覆盖联合建模空间信息强度、时间分散和非冗余性，提供轻量级且任务无关的采样质量诊断。


<details>
  <summary>Details</summary>
Motivation: 现有的评估指标主要关注感知质量或重建保真度，无法评估采样帧是否充分捕捉了信息丰富且具代表性的视频内容。

Method: STEC基于时空帧熵（STFE）构建，通过熵基结构复杂性测量每帧的空间信息，并根据时间覆盖和冗余评估采样帧。

Result: 在MSR-VTT test-1k基准测试中，STEC明显区分了常见的采样策略，并揭示了平均性能无法捕捉的个体视频稳健性模式。

Conclusion: STEC是一种简单且无参考的度量标准，用于评估视频帧采样的有效性，能够提供关于采样质量的原则性和轻量级测量。

Abstract: Frame sampling is a fundamental component in video understanding and video--language model pipelines, yet evaluating the quality of sampled frames remains challenging. Existing evaluation metrics primarily focus on perceptual quality or reconstruction fidelity, and are not designed to assess whether a set of sampled frames adequately captures informative and representative video content.
  We propose Spatio-Temporal Entropy Coverage (STEC), a simple and non-reference metric for evaluating the effectiveness of video frame sampling. STEC builds upon Spatio-Temporal Frame Entropy (STFE), which measures per-frame spatial information via entropy-based structural complexity, and evaluates sampled frames based on their temporal coverage and redundancy. By jointly modeling spatial information strength, temporal dispersion, and non-redundancy, STEC provides a principled and lightweight measure of sampling quality.
  Experiments on the MSR-VTT test-1k benchmark demonstrate that STEC clearly differentiates common sampling strategies, including random, uniform, and content-aware methods. We further show that STEC reveals robustness patterns across individual videos that are not captured by average performance alone, highlighting its practical value as a general-purpose evaluation tool for efficient video understanding.
  We emphasize that STEC is not designed to predict downstream task accuracy, but to provide a task-agnostic diagnostic signal for analyzing frame sampling behavior under constrained budgets.

</details>


### [242] [Harmonizing the Deep: A Unified Information Pipeline for Robust Marine Biodiversity Assessment Across Heterogeneous Domains](https://arxiv.org/abs/2601.13975)
*Marco Piccolo,Qiwei Han,Astrid van Toor,Joachim Vanneste*

Main category: cs.CV

TL;DR: 该论文提出了一种统一信息管道，用于标准化异构数据集并评估跨域检测器性能，发现结构因素对性能影响更大，并验证了在低成本硬件上的运行可行性。


<details>
  <summary>Details</summary>
Motivation: 解决现有检测解决方案在新站点部署时性能急剧下降的问题，为北极和大西洋海洋生态系统的多年入侵物种监测计划奠定基础检测层。

Method: 开发了一个统一信息管道（Unified Information Pipeline），将异构数据集标准化为可比信息流，并在受控的跨域协议下评估固定的、与部署相关的检测器。

Result: 研究发现，结构因素（如场景组成、物体密度和上下文冗余）比视觉退化（如浑浊度）更能解释跨域性能损失，稀疏场景会引发特有的“上下文崩溃”故障模式。此外，通过在低成本边缘硬件上基准测试推理，验证了运行可行性，运行时优化可实现远程监测的实用采样率。

Conclusion: 该研究强调了结构感知可靠性在海洋生物多样性监测中的重要性，而非单纯依赖图像增强技术，为海洋生态系统评估提供了一个民主化的工具。

Abstract: Marine biodiversity monitoring requires scalability and reliability across complex underwater environments to support conservation and invasive-species management. Yet existing detection solutions often exhibit a pronounced deployment gap, with performance degrading sharply when transferred to new sites. This work establishes the foundational detection layer for a multi-year invasive species monitoring initiative targeting Arctic and Atlantic marine ecosystems. We address this challenge by developing a Unified Information Pipeline that standardises heterogeneous datasets into a comparable information flow and evaluates a fixed, deployment-relevant detector under controlled cross-domain protocols. Across multiple domains, we find that structural factors, such as scene composition, object density, and contextual redundancy, explain cross-domain performance loss more strongly than visual degradation such as turbidity, with sparse scenes inducing a characteristic "Context Collapse" failure mode. We further validate operational feasibility by benchmarking inference on low-cost edge hardware, showing that runtime optimisation enables practical sampling rates for remote monitoring. The results shift emphasis from image enhancement toward structure-aware reliability, providing a democratised tool for consistent marine ecosystem assessment.

</details>


### [243] [Equivariant Learning for Unsupervised Image Dehazing](https://arxiv.org/abs/2601.13986)
*Zhang Wen,Jiangwei Xie,Dongdong Chen*

Main category: cs.CV

TL;DR: 提出无监督的等变图像去雾框架EID，利用对称性和对抗学习，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有去雾方法依赖精心设计的先验或大量无雾真实数据，这些在科学成像中难以获取。

Method: 提出了一种名为等变图像去雾（EID）的无监督学习框架，利用图像信号的对称性，通过强制雾霾一致性和系统等变性来恢复清晰图像。还采用对抗学习策略建模未知雾霾物理。

Result: 在两个科学图像去雾基准测试（包括细胞显微镜和医学内窥镜）以及自然图像去雾实验中，EID显著优于现有方法。

Conclusion: EID通过结合等变学习和建模雾霾物理，为科学成像提供了更通用和有效的去雾方法。

Abstract: Image Dehazing (ID) aims to produce a clear image from an observation contaminated by haze. Current ID methods typically rely on carefully crafted priors or extensive haze-free ground truth, both of which are expensive or impractical to acquire, particularly in the context of scientific imaging. We propose a new unsupervised learning framework called Equivariant Image Dehazing (EID) that exploits the symmetry of image signals to restore clarity to hazy observations. By enforcing haze consistency and systematic equivariance, EID can recover clear patterns directly from raw, hazy images. Additionally, we propose an adversarial learning strategy to model unknown haze physics and facilitate EID learning. Experiments on two scientific image dehazing benchmarks (including cell microscopy and medical endoscopy) and on natural image dehazing have demonstrated that EID significantly outperforms state-of-the-art approaches. By unifying equivariant learning with modelling haze physics, we hope that EID will enable more versatile and effective haze removal in scientific imaging. Code and datasets will be published.

</details>


### [244] [Likelihood-Separable Diffusion Inference for Multi-Image MRI Super-Resolution](https://arxiv.org/abs/2601.14030)
*Samuel W. Remedios,Zhangxing Bian,Shuwen Wei,Aaron Carass,Jerry L. Prince,Blake E. Dewey*

Main category: cs.CV

TL;DR: 扩散模型通过DPS似然校正实现多图像MRI超分辨率，无需修改模型即可显著提升重建质量。


<details>
  <summary>Details</summary>
Motivation: 尽管扩散模型在单图像逆问题上表现出色，但MRI等模态通常需要多幅互补测量，现有方法对此支持不足。

Method: 本研究将常见的基于扩散的单图像逆问题求解器推广到MISR MRI，利用DPS似然校正实现独立测量间的梯度分解，无需构建联合算子或修改扩散模型。

Result: 在4×/8×/16×各向异性退化情况下，MISR方法显著优于SISR，实现了各向异性MRI体积的超分辨率重建。

Conclusion: 扩散模型在多图像超分辨率（MISR）MRI中表现出色，能够从常规2D多切片采集重建接近各向同性的解剖结构，显著优于单图像超分辨率（SISR）。

Abstract: Diffusion models are the current state-of-the-art for solving inverse problems in imaging. Their impressive generative capability allows them to approximate sampling from a prior distribution, which alongside a known likelihood function permits posterior sampling without retraining the model. While recent methods have made strides in advancing the accuracy of posterior sampling, the majority focuses on single-image inverse problems. However, for modalities such as magnetic resonance imaging (MRI), it is common to acquire multiple complementary measurements, each low-resolution along a different axis. In this work, we generalize common diffusion-based inverse single-image problem solvers for multi-image super-resolution (MISR) MRI. We show that the DPS likelihood correction allows an exactly-separable gradient decomposition across independently acquired measurements, enabling MISR without constructing a joint operator, modifying the diffusion model, or increasing network function evaluations. We derive MISR versions of DPS, DMAP, DPPS, and diffusion-based PnP/ADMM, and demonstrate substantial gains over SISR across $4\times/8\times/16\times$ anisotropic degradations. Our results achieve state-of-the-art super-resolution of anisotropic MRI volumes and, critically, enable reconstruction of near-isotropic anatomy from routine 2D multi-slice acquisitions, which are otherwise highly degraded in orthogonal views.

</details>


### [245] [Human detectors are surprisingly powerful reward models](https://arxiv.org/abs/2601.14037)
*Kumar Ashutosh,XuDong Wang,Xi Yin,Kristen Grauman,Adam Polyak,Ishan Misra,Rohit Girdhar*

Main category: cs.CV

TL;DR: HuDA通过简单奖励模型提升视频生成中复杂人类动作的质量，胜率73%，并扩展至动物和人机交互生成。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型在复杂非刚性运动（如体育、舞蹈等）中表现不佳，常出现肢体缺失、姿态扭曲等问题。

Method: 提出HuDA奖励模型，结合人类检测置信度和时间提示对齐分数，无需额外训练即可优化视频生成质量。采用GRPO后训练策略进一步优化模型。

Result: HuDA在复杂人类动作生成上优于现有模型（如Wan 2.1），胜率达73%，并在动物视频和人机交互生成中同样表现优异。

Conclusion: HuDA作为一种简单但高效的奖励模型，显著提升了视频生成中复杂人类动作的质量，并在动物视频和人机交互等其他领域也展现出广泛的应用潜力。

Abstract: Video generation models have recently achieved impressive visual fidelity and temporal coherence. Yet, they continue to struggle with complex, non-rigid motions, especially when synthesizing humans performing dynamic actions such as sports, dance, etc. Generated videos often exhibit missing or extra limbs, distorted poses, or physically implausible actions. In this work, we propose a remarkably simple reward model, HuDA, to quantify and improve the human motion in generated videos. HuDA integrates human detection confidence for appearance quality, and a temporal prompt alignment score to capture motion realism. We show this simple reward function that leverages off-the-shelf models without any additional training, outperforms specialized models finetuned with manually annotated data. Using HuDA for Group Reward Policy Optimization (GRPO) post-training of video models, we significantly enhance video generation, especially when generating complex human motions, outperforming state-of-the-art models like Wan 2.1, with win-rate of 73%. Finally, we demonstrate that HuDA improves generation quality beyond just humans, for instance, significantly improving generation of animal videos and human-object interactions.

</details>


### [246] [Correcting and Quantifying Systematic Errors in 3D Box Annotations for Autonomous Driving](https://arxiv.org/abs/2601.14038)
*Alexandre Justo Miro,Ludvig af Klinteberg,Bogdan Timus,Aron Asefaw,Ajinkya Khoche,Thomas Gustafsson,Sina Sharif Mansouri,Masoud Daneshtalab*

Main category: cs.CV

TL;DR: 本研究首次发现并修正了动态场景下3D框标注的系统性错误，提升了标注质量，并量化了其对基准测试的影响。


<details>
  <summary>Details</summary>
Motivation: 发现广泛使用的公开数据集中存在动态场景下的标注错误，这些错误会影响自动驾驶系统的性能评估。

Method: 提出了一种新颖的离线估计方法，用于修正3D框标注，确保其符合物理可行轨迹并与传感器数据在时空上一致。

Result: 在Argoverse 2、MAN TruckScenes及专有数据集上，标注质量提升了17%以上，并量化了原始标注的误差（最大2.5米）。

Conclusion: 准确的标注对于自动驾驶系统的性能评估至关重要，本研究通过离线估计方法显著提升了标注质量，并量化了标注错误对基准测试的影响。

Abstract: Accurate ground truth annotations are critical to supervised learning and evaluating the performance of autonomous vehicle systems. These vehicles are typically equipped with active sensors, such as LiDAR, which scan the environment in predefined patterns. 3D box annotation based on data from such sensors is challenging in dynamic scenarios, where objects are observed at different timestamps, hence different positions. Without proper handling of this phenomenon, systematic errors are prone to being introduced in the box annotations. Our work is the first to discover such annotation errors in widely used, publicly available datasets. Through our novel offline estimation method, we correct the annotations so that they follow physically feasible trajectories and achieve spatial and temporal consistency with the sensor data. For the first time, we define metrics for this problem; and we evaluate our method on the Argoverse 2, MAN TruckScenes, and our proprietary datasets. Our approach increases the quality of box annotations by more than 17% in these datasets. Furthermore, we quantify the annotation errors in them and find that the original annotations are misplaced by up to 2.5 m, with highly dynamic objects being the most affected. Finally, we test the impact of the errors in benchmarking and find that the impact is larger than the improvements that state-of-the-art methods typically achieve with respect to the previous state-of-the-art methods; showing that accurate annotations are essential for correct interpretation of performance. Our code is available at https://github.com/alexandre-justo-miro/annotation-correction-3D-boxes.

</details>


### [247] [Federated Balanced Learning](https://arxiv.org/abs/2601.14042)
*Jiaze Li,Haoran Xu,Wanyi Wu,Changwei Wang,Shuaiguang Li,Jianzhong Ju,Zhenbo Luo,Jian Luan,Youyang Qu,Longxiang Gao,Xudong Yang,Lumin Xing*

Main category: cs.CV

TL;DR: FBL 通过客户端样本平衡和知识策略，解决了非独立同分布场景下的联邦学习客户端漂移问题，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 在非独立同分布（non-iid）场景下，全局模型因客户端漂移而性能下降，现有方法仅基于损失函数或梯度修正模型，忽略了客户端样本的影响。

Method: FBL 通过知识填充和知识采样实现客户端样本平衡，并设计了知识对齐策略和知识丢弃策略来优化方法。

Result: 实验表明，FBL 在性能上优于现有基线方法。

Conclusion: Federated Balanced Learning (FBL) 通过客户端样本平衡有效解决了非独立同分布（non-iid）场景下的客户端漂移问题，显著提升了模型性能。

Abstract: Federated learning is a paradigm of joint learning in which clients collaborate by sharing model parameters instead of data. However, in the non-iid setting, the global model experiences client drift, which can seriously affect the final performance of the model. Previous methods tend to correct the global model that has already deviated based on the loss function or gradient, overlooking the impact of the client samples. In this paper, we rethink the role of the client side and propose Federated Balanced Learning, i.e., FBL, to prevent this issue from the beginning through sample balance on the client side. Technically, FBL allows unbalanced data on the client side to achieve sample balance through knowledge filling and knowledge sampling using edge-side generation models, under the limitation of a fixed number of data samples on clients. Furthermore, we design a Knowledge Alignment Strategy to bridge the gap between synthetic and real data, and a Knowledge Drop Strategy to regularize our method. Meanwhile, we scale our method to real and complex scenarios, allowing different clients to adopt various methods, and extend our framework to further improve performance. Numerous experiments show that our method outperforms state-of-the-art baselines. The code is released upon acceptance.

</details>


### [248] [Weather-R1: Logically Consistent Reinforcement Fine-Tuning for Multimodal Reasoning in Meteorology](https://arxiv.org/abs/2601.14044)
*Kaiyu Wu,Pucheng Han,Hualong Zhang,Naigeng Wu,Keze Wang*

Main category: cs.CV

TL;DR: 论文提出LoCo-RFT方法和Weather-R1模型，解决了气象领域视觉语言模型的自我矛盾推理问题，并在WeatherQA基准上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决视觉语言模型在气象领域的领域差距和推理忠实度问题，特别是自我矛盾推理问题。

Method: 提出了逻辑一致性奖励的LoCo-RFT方法，并构建了WeatherQA基准。

Result: Weather-R1在WeatherQA上比基线提升了9.8个百分点，优于监督微调和RFT，甚至超过Qwen2.5-VL-32B。

Conclusion: Weather-R1通过LoCo-RFT方法显著提升了气象领域的多模态推理能力，解决了自我矛盾推理问题，并在WeatherQA基准上表现优异。

Abstract: While Vision Language Models (VLMs) show advancing reasoning capabilities, their application in meteorology is constrained by a domain gap and a reasoning faithfulness gap. Specifically, mainstream Reinforcement Fine-Tuning (RFT) can induce Self-Contradictory Reasoning (Self-Contra), where the model's reasoning contradicts its final answer, which is unacceptable in such a high-stakes domain. To address these challenges, we construct WeatherQA, a novel multimodal reasoning benchmark in meteorology. We also propose Logically Consistent Reinforcement Fine-Tuning (LoCo-RFT), which resolves Self-Contra by introducing a logical consistency reward. Furthermore, we introduce Weather-R1, the first reasoning VLM with logical faithfulness in meteorology, to the best of our knowledge. Experiments demonstrate that Weather-R1 improves performance on WeatherQA by 9.8 percentage points over the baseline, outperforming Supervised Fine-Tuning and RFT, and even surpassing the original Qwen2.5-VL-32B. These results highlight the effectiveness of our LoCo-RFT and the superiority of Weather-R1. Our benchmark and code are available at https://github.com/Marcowky/Weather-R1.

</details>


### [249] [Vision Also You Need: Navigating Out-of-Distribution Detection with Multimodal Large Language Model](https://arxiv.org/abs/2601.14052)
*Haoran Xu,Yanlin Liu,Zizhao Tong,Jiaze Li,Kexue Fu,Yuyang Zhang,Longxiang Gao,Shuaiguang Li,Xingyu Li,Yanran Xu,Changwei Wang*

Main category: cs.CV

TL;DR: MM-OOD是一种新型零样本OOD检测方法，利用MLLMs的多模态能力提升近/远OOD任务性能，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前零样本OOD检测方法过度依赖文本空间的知识，忽视了图像空间中检测OOD样本的固有挑战。因此，作者提出MM-OOD，利用MLLMs的多模态能力来弥补这一不足。

Method: MM-OOD采用两种策略：(1)对于近OOD任务，直接将ID图像和文本提示输入MLLMs以识别潜在异常；(2)对于远OOD任务，引入sketch-generate-elaborate框架：先用文本提示勾勒异常暴露，生成对应的视觉OOD样本，最后通过多模态提示进行细化。

Result: 实验表明，MM-OOD在Food-101等广泛使用的多模态数据集上取得了显著改进，同时在ImageNet-1K上验证了其可扩展性。

Conclusion: MM-OOD通过利用多模态大语言模型（MLLMs）的多模态推理能力和多轮对话能力，显著提升了近OOD和远OOD任务的检测性能，并在Food-101和ImageNet-1K等数据集上验证了其有效性和可扩展性。

Abstract: Out-of-Distribution (OOD) detection is a critical task that has garnered significant attention. The emergence of CLIP has spurred extensive research into zero-shot OOD detection, often employing a training-free approach. Current methods leverage expert knowledge from large language models (LLMs) to identify potential outliers. However, these approaches tend to over-rely on knowledge in the text space, neglecting the inherent challenges involved in detecting out-of-distribution samples in the image space. In this paper, we propose a novel pipeline, MM-OOD, which leverages the multimodal reasoning capabilities of MLLMs and their ability to conduct multi-round conversations for enhanced outlier detection. Our method is designed to improve performance in both near OOD and far OOD tasks. Specifically, (1) for near OOD tasks, we directly feed ID images and corresponding text prompts into MLLMs to identify potential outliers; and (2) for far OOD tasks, we introduce the sketch-generate-elaborate framework: first, we sketch outlier exposure using text prompts, then generate corresponding visual OOD samples, and finally elaborate by using multimodal prompts. Experiments demonstrate that our method achieves significant improvements on widely used multimodal datasets such as Food-101, while also validating its scalability on ImageNet-1K.

</details>


### [250] [Fine-Grained Zero-Shot Composed Image Retrieval with Complementary Visual-Semantic Integration](https://arxiv.org/abs/2601.14060)
*Yongcong Ye,Kai Zhang,Yanghai Zhang,Enhong Chen,Longfei Li,Jun Zhou*

Main category: cs.CV

TL;DR: CVSI是一种新型细粒度零样本组合图像检索方法，通过互补视觉-语义整合解决了现有方法的不足，实验证明其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有ZS-CIR方法在捕捉细粒度变化和整合视觉语义信息方面存在不足，主要依赖单模态转换或LLM生成描述，导致视觉信息和语义上下文不完整。

Method: CVSI通过三个关键组件实现：(1) 视觉信息提取，包括全局图像特征和伪令牌生成；(2) 语义信息提取，利用预训练模型生成多描述并借助LLM生成修改后的描述；(3) 互补信息检索，整合查询和数据库图像信息进行检索。

Result: 在CIRR、CIRCO和FashionIQ数据集上的实验表明，CVSI显著优于现有方法。

Conclusion: CVSI方法在三个公开数据集上显著优于现有最先进方法，证明了其在细粒度零样本组合图像检索中的有效性。

Abstract: Zero-shot composed image retrieval (ZS-CIR) is a rapidly growing area with significant practical applications, allowing users to retrieve a target image by providing a reference image and a relative caption describing the desired modifications. Existing ZS-CIR methods often struggle to capture fine-grained changes and integrate visual and semantic information effectively. They primarily rely on either transforming the multimodal query into a single text using image-to-text models or employing large language models for target image description generation, approaches that often fail to capture complementary visual information and complete semantic context. To address these limitations, we propose a novel Fine-Grained Zero-Shot Composed Image Retrieval method with Complementary Visual-Semantic Integration (CVSI). Specifically, CVSI leverages three key components: (1) Visual Information Extraction, which not only extracts global image features but also uses a pre-trained mapping network to convert the image into a pseudo token, combining it with the modification text and the objects most likely to be added. (2) Semantic Information Extraction, which involves using a pre-trained captioning model to generate multiple captions for the reference image, followed by leveraging an LLM to generate the modified captions and the objects most likely to be added. (3) Complementary Information Retrieval, which integrates information extracted from both the query and database images to retrieve the target image, enabling the system to efficiently handle retrieval queries in a variety of situations. Extensive experiments on three public datasets (e.g., CIRR, CIRCO, and FashionIQ) demonstrate that CVSI significantly outperforms existing state-of-the-art methods. Our code is available at https://github.com/yyc6631/CVSI.

</details>


### [251] [VERIDAH: Solving Enumeration Anomaly Aware Vertebra Labeling across Imaging Sequences](https://arxiv.org/abs/2601.14066)
*Hendrik Möller,Hanna Schoen,Robert Graf,Matan Atad,Nathan Molinier,Anjany Sekuboyina,Bettina K. Budai,Fabian Bamberg,Steffen Ringhof,Christopher Schlett,Tobias Pischon,Thoralf Niendorf,Josua A. Decker,Marc-André Weber,Bjoern Menze,Daniel Rueckert,Jan S. Kirschke*

Main category: cs.CV

TL;DR: VERIDAH是一种新型椎骨标记算法，能高效识别胸腰椎枚举异常，在T2w和CT图像上表现优异。


<details>
  <summary>Details</summary>
Motivation: 临床报告中胸腰椎连接处评估不足，且缺乏自动标记枚举异常的方法。

Method: 提出了一种基于多分类头和加权椎骨序列预测算法的新型椎骨标记算法VERIDAH。

Result: 在T2w TSE矢状面和CT成像上，VERIDAH的准确率分别为98.30%和99.18%，显著高于现有模型。对于胸椎和腰椎的枚举异常，识别准确率分别在87.80%-96.30%和94.48%-97.22%之间。

Conclusion: VERIDAH算法在T2w和CT图像上显著优于现有模型，能够有效识别胸椎和腰椎的枚举异常，具有较高的准确率。

Abstract: The human spine commonly consists of seven cervical, twelve thoracic, and five lumbar vertebrae. However, enumeration anomalies may result in individuals having eleven or thirteen thoracic vertebrae and four or six lumbar vertebrae. Although the identification of enumeration anomalies has potential clinical implications for chronic back pain and operation planning, the thoracolumbar junction is often poorly assessed and rarely described in clinical reports. Additionally, even though multiple deep-learning-based vertebra labeling algorithms exist, there is a lack of methods to automatically label enumeration anomalies. Our work closes that gap by introducing "Vertebra Identification with Anomaly Handling" (VERIDAH), a novel vertebra labeling algorithm based on multiple classification heads combined with a weighted vertebra sequence prediction algorithm. We show that our approach surpasses existing models on T2w TSE sagittal (98.30% vs. 94.24% of subjects with all vertebrae correctly labeled, p < 0.001) and CT imaging (99.18% vs. 77.26% of subjects with all vertebrae correctly labeled, p < 0.001) and works in arbitrary field-of-view images. VERIDAH correctly labeled the presence 2 Möller et al. of thoracic enumeration anomalies in 87.80% and 96.30% of T2w and CT images, respectively, and lumbar enumeration anomalies in 94.48% and 97.22% for T2w and CT, respectively. Our code and models are available at: https://github.com/Hendrik-code/spineps.

</details>


### [252] [VENI: Variational Encoder for Natural Illumination](https://arxiv.org/abs/2601.14079)
*Paul Walker,James A. D. Gardner,Andreea Ardelean,William A. P. Smith,Bernhard Egger*

Main category: cs.CV

TL;DR: 提出旋转等变变分自编码器，通过VN-ViT和SO(2)-等变层改进光照建模，潜在空间表现更优。


<details>
  <summary>Details</summary>
Motivation: 现有工作要么忽略了光照环境的球形和旋转等变特性，要么未能提供良好的潜在空间。为了解决这些问题，作者提出了一个不依赖2D投影的旋转等变变分自编码器。

Method: 使用了一种新型的Vector Neuron Vision Transformer (VN-ViT)作为编码器，以及旋转等变的条件神经场作为解码器。编码器中通过新型的SO(2)-等变全连接层（Vector Neurons的扩展）将等变性从SO(3)降至SO(2)。

Result: 实验表明，SO(2)-等变全连接层在SO(2)-等变模型中优于标准Vector Neurons，且变分自编码器在潜在空间插值和潜在空间表现上优于先前方法。

Conclusion: 该论文提出了一种旋转等变的变分自编码器，通过保留环境映射的SO(2)-等变性，实现了更平滑的潜在空间插值和更良好的潜在空间表现。

Abstract: Inverse rendering is an ill-posed problem, but priors like illumination priors, can simplify it. Existing work either disregards the spherical and rotation-equivariant nature of illumination environments or does not provide a well-behaved latent space. We propose a rotation-equivariant variational autoencoder that models natural illumination on the sphere without relying on 2D projections. To preserve the SO(2)-equivariance of environment maps, we use a novel Vector Neuron Vision Transformer (VN-ViT) as encoder and a rotation-equivariant conditional neural field as decoder. In the encoder, we reduce the equivariance from SO(3) to SO(2) using a novel SO(2)-equivariant fully connected layer, an extension of Vector Neurons. We show that our SO(2)-equivariant fully connected layer outperforms standard Vector Neurons when used in our SO(2)-equivariant model. Compared to previous methods, our variational autoencoder enables smoother interpolation in latent space and offers a more well-behaved latent space.

</details>


### [253] [Curriculum-Based Strategies for Efficient Cross-Domain Action Recognition](https://arxiv.org/abs/2601.14101)
*Emily Kim,Allen Wu,Jessica Hodgins*

Main category: cs.CV

TL;DR: 课程学习策略在跨视角动作识别中结合合成与真实数据，保持性能的同时显著提升训练效率。


<details>
  <summary>Details</summary>
Motivation: 尽管人类动作识别取得显著进展，但泛化到多样视角仍具挑战性。现有数据集多从地面视角捕获，模型难以迁移到如空中视角等截然不同的领域。

Method: 探索了两种课程学习策略：两阶段直接微调和多阶段渐进式扩展数据集后微调，使用SlowFast（CNN-based）和MViTv2（Transformer-based）架构进行评估。

Result: 结合两种域外数据集（合成空中视角和真实地面视角）明显优于单一域训练。课程策略在保持性能的同时提升效率：两阶段微调减少迭代次数（SlowFast达37%，MViTv2达30%），多阶段渐进式进一步减少（SlowFast达9%，MViTv2达30%）。

Conclusion: 课程学习策略在跨视角动作识别中能够保持可比性能（top-1准确率在3%范围内）的同时提升训练效率。

Abstract: Despite significant progress in human action recognition, generalizing to diverse viewpoints remains a challenge. Most existing datasets are captured from ground-level perspectives, and models trained on them often struggle to transfer to drastically different domains such as aerial views. This paper examines how curriculum-based training strategies can improve generalization to unseen real aerial-view data without using any real aerial data during training.
  We explore curriculum learning for cross-view action recognition using two out-of-domain sources: synthetic aerial-view data and real ground-view data. Our results on the evaluation on order of training (fine-tuning on synthetic aerial data vs. real ground data) shows that fine-tuning on real ground data but differ in how they transition from synthetic to real. The first uses a two-stage curriculum with direct fine-tuning, while the second applies a progressive curriculum that expands the dataset in multiple stages before fine-tuning. We evaluate both methods on the REMAG dataset using SlowFast (CNN-based) and MViTv2 (Transformer-based) architectures.
  Results show that combining the two out-of-domain datasets clearly outperforms training on a single domain, whether real ground-view or synthetic aerial-view. Both curriculum strategies match the top-1 accuracy of simple dataset combination while offering efficiency gains. With the two-step fine-tuning method, SlowFast achieves up to a 37% reduction in iterations and MViTv2 up to a 30% reduction compared to simple combination. The multi-step progressive approach further reduces iterations, by up to 9% for SlowFast and 30% for MViTv2, relative to the two-step method. These findings demonstrate that curriculum-based training can maintain comparable performance (top-1 accuracy within 3% range) while improving training efficiency in cross-view action recognition.

</details>


### [254] [Interp3D: Correspondence-aware Interpolation for Generative Textured 3D Morphing](https://arxiv.org/abs/2601.14103)
*Xiaolu Liu,Yicong Li,Qiyuan He,Jiayin Zhu,Wei Ji,Angela Yao,Jianke Zhu*

Main category: cs.CV

TL;DR: Interp3D是一种无训练的3D变形框架，通过生成先验和渐进对齐实现几何与纹理的平滑过渡，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法在3D变形中存在几何一致性、纹理对齐和鲁棒性的不足，需要一种联合保持这些特性的解决方案。

Method: Interp3D采用无训练框架，结合生成先验和渐进对齐原则，通过SLAT引导的结构插值和细粒度纹理融合实现变形。

Result: 定量指标和人类研究表明，Interp3D在保真度、过渡平滑性和合理性上优于现有方法。

Conclusion: Interp3D显著优于现有方法，通过生成先验和渐进对齐原则，实现了几何保真和纹理一致性的3D变形。

Abstract: Textured 3D morphing seeks to generate smooth and plausible transitions between two 3D assets, preserving both structural coherence and fine-grained appearance. This ability is crucial not only for advancing 3D generation research but also for practical applications in animation, editing, and digital content creation. Existing approaches either operate directly on geometry, limiting them to shape-only morphing while neglecting textures, or extend 2D interpolation strategies into 3D, which often causes semantic ambiguity, structural misalignment, and texture blurring. These challenges underscore the necessity to jointly preserve geometric consistency, texture alignment, and robustness throughout the transition process. To address this, we propose Interp3D, a novel training-free framework for textured 3D morphing. It harnesses generative priors and adopts a progressive alignment principle to ensure both geometric fidelity and texture coherence. Starting from semantically aligned interpolation in condition space, Interp3D enforces structural consistency via SLAT (Structured Latent)-guided structure interpolation, and finally transfers appearance details through fine-grained texture fusion. For comprehensive evaluations, we construct a dedicated dataset, Interp3DData, with graded difficulty levels and assess generation results from fidelity, transition smoothness, and plausibility. Both quantitative metrics and human studies demonstrate the significant advantages of our proposed approach over previous methods. Source code is available at https://github.com/xiaolul2/Interp3D.

</details>


### [255] [PMCE: Probabilistic Multi-Granularity Semantics with Caption-Guided Enhancement for Few-Shot Learning](https://arxiv.org/abs/2601.14111)
*Jiaying Wu,Can Gao,Jinglu Hu,Hui Li,Xiaofeng Cao,Jingcai Guo*

Main category: cs.CV

TL;DR: PMCE通过多粒度语义和标题增强优化少样本学习，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决少样本学习中因数据稀缺导致的原型偏差和泛化能力差的问题，现有语义方法主要应用于支持集而忽略了查询表示。

Method: PMCE构建了一个非参数知识库，存储视觉统计数据和CLIP编码的基类名称嵌入。在元测试时，基于类名嵌入的相似性检索最相关的基类，并通过MAP更新将这些统计信息与支持集原型融合。同时，利用冻结的BLIP标题生成器提供无标签的实例级图像描述，并通过轻量级增强器优化支持原型和查询特征。

Result: 在四个基准测试上，PMCE均表现出色，特别是在MiniImageNet的1-shot设置中，比最强的语义竞争对手提高了7.71%的绝对增益。

Conclusion: PMCE通过结合多粒度语义和标题引导增强，显著提升了少样本学习的性能，实验证明其在多个基准测试上均优于现有方法。

Abstract: Few-shot learning aims to identify novel categories from only a handful of labeled samples, where prototypes estimated from scarce data are often biased and generalize poorly. Semantic-based methods alleviate this by introducing coarse class-level information, but they are mostly applied on the support side, leaving query representations unchanged. In this paper, we present PMCE, a Probabilistic few-shot framework that leverages Multi-granularity semantics with Caption-guided Enhancement. PMCE constructs a nonparametric knowledge bank that stores visual statistics for each category as well as CLIP-encoded class name embeddings of the base classes. At meta-test time, the most relevant base classes are retrieved based on the similarities of class name embeddings for each novel category. These statistics are then aggregated into category-specific prior information and fused with the support set prototypes via a simple MAP update. Simultaneously, a frozen BLIP captioner provides label-free instance-level image descriptions, and a lightweight enhancer trained on base classes optimizes both support prototypes and query features under an inductive protocol with a consistency regularization to stabilize noisy captions. Experiments on four benchmarks show that PMCE consistently improves over strong baselines, achieving up to 7.71% absolute gain over the strongest semantic competitor on MiniImageNet in the 1-shot setting. Our code is available at https://anonymous.4open.science/r/PMCE-275D

</details>


### [256] [The Side Effects of Being Smart: Safety Risks in MLLMs' Multi-Image Reasoning](https://arxiv.org/abs/2601.14127)
*Renmiao Chen,Yida Lu,Shiyao Cui,Xuan Ouyang,Victor Shea-Jay Huang,Shumin Zhang,Chengwei Pan,Han Qiu,Minlie Huang*

Main category: cs.CV

TL;DR: MIR-SafetyBench基准揭示，多模态大型语言模型在多图像推理能力提升时可能更易受安全攻击，且不安全生成与低注意力熵相关。


<details>
  <summary>Details</summary>
Motivation: 随着MLLMs在多图像推理能力上的提升，可能引发新的安全风险，需要系统性评估。

Method: 通过引入MIR-SafetyBench基准，包含2,676个实例和9种多图像关系分类，对19种MLLMs进行了广泛评估。

Result: 评估发现，高级推理模型在MIR-SafetyBench上更易受攻击，且许多标记为安全的回复是表面的或逃避性的。此外，不安全生成的注意力熵较低，表明模型可能过度关注任务解决而忽视安全约束。

Conclusion: 研究表明，多模态大型语言模型（MLLMs）在多图像推理能力提升的同时，可能带来新的安全风险，尤其是高级推理模型在MIR-SafetyBench上表现更为脆弱。

Abstract: As Multimodal Large Language Models (MLLMs) acquire stronger reasoning capabilities to handle complex, multi-image instructions, this advancement may pose new safety risks. We study this problem by introducing MIR-SafetyBench, the first benchmark focused on multi-image reasoning safety, which consists of 2,676 instances across a taxonomy of 9 multi-image relations. Our extensive evaluations on 19 MLLMs reveal a troubling trend: models with more advanced multi-image reasoning can be more vulnerable on MIR-SafetyBench. Beyond attack success rates, we find that many responses labeled as safe are superficial, often driven by misunderstanding or evasive, non-committal replies. We further observe that unsafe generations exhibit lower attention entropy than safe ones on average. This internal signature suggests a possible risk that models may over-focus on task solving while neglecting safety constraints. Our code and data are available at https://github.com/thu-coai/MIR-SafetyBench.

</details>


### [257] [GIC-DLC: Differentiable Logic Circuits for Hardware-Friendly Grayscale Image Compression](https://arxiv.org/abs/2601.14130)
*Till Aczel,David F. Jenny,Simon Bührer,Andreas Plesner,Antonio Di Maio,Roger Wattenhofer*

Main category: cs.CV

TL;DR: GIC-DLC是一种硬件感知的编解码器，通过训练查找表结合神经网络的灵活性和布尔运算的效率，在压缩效率和能耗上优于传统方法，适用于边缘设备。


<details>
  <summary>Details</summary>
Motivation: 解决神经图像编解码器在能耗受限设备（如智能手机、相机和无人机）上部署时的高计算开销问题。

Method: 训练查找表，将神经网络的灵活性与布尔运算的效率相结合。

Result: 在灰度基准数据集上的实验表明，GIC-DLC在压缩效率上优于传统编解码器，同时显著降低了能耗和延迟。

Conclusion: GIC-DLC展示了学习型压缩可以在硬件上友好实现，为边缘设备上的低功耗图像压缩提供了有前景的方向。

Abstract: Neural image codecs achieve higher compression ratios than traditional hand-crafted methods such as PNG or JPEG-XL, but often incur substantial computational overhead, limiting their deployment on energy-constrained devices such as smartphones, cameras, and drones. We propose Grayscale Image Compression with Differentiable Logic Circuits (GIC-DLC), a hardware-aware codec where we train lookup tables to combine the flexibility of neural networks with the efficiency of Boolean operations. Experiments on grayscale benchmark datasets show that GIC-DLC outperforms traditional codecs in compression efficiency while allowing substantial reductions in energy consumption and latency. These results demonstrate that learned compression can be hardware-friendly, offering a promising direction for low-power image compression on edge devices.

</details>


### [258] [One-Shot Refiner: Boosting Feed-forward Novel View Synthesis via One-Step Diffusion](https://arxiv.org/abs/2601.14161)
*Yitong Dong,Qi Zhang,Minchao Jiang,Zhiqiang Wu,Qingnan Fan,Ying Feng,Huaqi Zhang,Hujun Bao,Guofeng Zhang*

Main category: cs.CV

TL;DR: 提出了一种结合双域细节感知模块和扩散网络的新框架，解决了ViT-based 3DGS方法在高分辨率和3D一致性上的问题，实现了高质量的新视图合成。


<details>
  <summary>Details</summary>
Motivation: 现有ViT-based 3DGS方法因计算成本限制仅能处理低分辨率输入，且生成增强方法多为3D无关，导致跨视图结构不一致，尤其在未见区域。

Method: 设计了双域细节感知模块（Dual-Domain Detail Perception Module）和特征引导扩散网络（feature-guided diffusion network），并提出了统一的训练策略联合优化ViT-based几何主干和扩散细化模块。

Result: 实验表明，该方法在多个数据集上均能保持卓越的生成质量。

Conclusion: 该方法通过双域细节感知模块和特征引导扩散网络，成功克服了现有ViT-based 3DGS方法在高分辨率输入和3D一致性上的限制，实现了高质量的NVS。

Abstract: We present a novel framework for high-fidelity novel view synthesis (NVS) from sparse images, addressing key limitations in recent feed-forward 3D Gaussian Splatting (3DGS) methods built on Vision Transformer (ViT) backbones. While ViT-based pipelines offer strong geometric priors, they are often constrained by low-resolution inputs due to computational costs. Moreover, existing generative enhancement methods tend to be 3D-agnostic, resulting in inconsistent structures across views, especially in unseen regions. To overcome these challenges, we design a Dual-Domain Detail Perception Module, which enables handling high-resolution images without being limited by the ViT backbone, and endows Gaussians with additional features to store high-frequency details. We develop a feature-guided diffusion network, which can preserve high-frequency details during the restoration process. We introduce a unified training strategy that enables joint optimization of the ViT-based geometric backbone and the diffusion-based refinement module. Experiments demonstrate that our method can maintain superior generation quality across multiple datasets.

</details>


### [259] [ASBA: A-line State Space Model and B-line Attention for Sparse Optical Doppler Tomography Reconstruction](https://arxiv.org/abs/2601.14165)
*Zhenghong Li,Wensheng Cheng,Congwu Du,Yingtian Pan,Zhaozheng Yin,Haibin Ling*

Main category: cs.CV

TL;DR: ASBA网络通过A-line ROI状态空间模型和B-line相位注意力机制，有效提升了稀疏采样下的ODT图像重建质量，尤其在血流信号处理上表现突出。


<details>
  <summary>Details</summary>
Motivation: 当前ODT技术依赖密集采样，导致扫描时间长、存储需求高且难以捕捉快速血流动态。稀疏采样虽被探索，但因保守采样率和统一建模方式效果有限。

Method: 提出了一种名为ASBA的新型血流感知网络，结合A-line ROI状态空间模型和B-line相位注意力机制，以及血流感知加权损失函数，用于从高度稀疏采样的原始A-scan重建ODT图像。

Result: 在真实动物数据上的实验表明，ASBA方法明显优于现有最先进的重建方法。

Conclusion: 本研究提出的ASBA网络通过创新的A-line ROI状态空间模型和B-line相位注意力机制，显著提高了稀疏采样下的ODT图像重建质量，尤其在血流信号重建方面表现优异。

Abstract: Optical Doppler Tomography (ODT) is an emerging blood flow analysis technique. A 2D ODT image (B-scan) is generated by sequentially acquiring 1D depth-resolved raw A-scans (A-line) along the lateral axis (B-line), followed by Doppler phase-subtraction analysis. To ensure high-fidelity B-scan images, current practices rely on dense sampling, which prolongs scanning time, increases storage demands, and limits the capture of rapid blood flow dynamics. Recent studies have explored sparse sampling of raw A-scans to alleviate these limitations, but their effectiveness is hindered by the conservative sampling rates and the uniform modeling of flow and background signals. In this study, we introduce a novel blood flow-aware network, named ASBA (A-line ROI State space model and B-line phase Attention), to reconstruct ODT images from highly sparsely sampled raw A-scans. Specifically, we propose an A-line ROI state space model to extract sparsely distributed flow features along the A-line, and a B-line phase attention to capture long-range flow signals along each B-line based on phase difference. Moreover, we introduce a flow-aware weighted loss function that encourages the network to prioritize the accurate reconstruction of flow signals. Extensive experiments on real animal data demonstrate that the proposed approach clearly outperforms existing state-of-the-art reconstruction methods.

</details>


### [260] [Progressive self-supervised blind-spot denoising method for LDCT denoising](https://arxiv.org/abs/2601.14180)
*Yichao Liu,Yueyang Teng,Junwen Guo*

Main category: cs.CV

TL;DR: 提出了一种仅需LDCT图像的自监督去噪方法，通过逐步盲点去噪和高斯噪声正则化，性能优于现有自监督方法，媲美有监督方法。


<details>
  <summary>Details</summary>
Motivation: 解决低剂量CT（LDCT）图像去噪中对配对正常剂量CT（NDCT）数据的依赖问题，这些数据在临床实践中难以获取。

Method: 提出了一种新颖的自监督训练策略，仅依赖LDCT图像，通过逐步盲点去噪机制和高斯噪声正则化来实现精细去噪学习。

Result: 在Mayo LDCT数据集上的大量实验表明，该方法一致优于现有的自监督方法，并与几种代表性有监督去噪方法性能相当或更好。

Conclusion: 该方法在Mayo LDCT数据集上表现优异，不仅超越了现有的自监督方法，甚至与一些有监督去噪方法性能相当或更好。

Abstract: Self-supervised learning is increasingly investigated for low-dose computed tomography (LDCT) image denoising, as it alleviates the dependence on paired normal-dose CT (NDCT) data, which are often difficult to acquire in clinical practice. In this paper, we propose a novel self-supervised training strategy that relies exclusively on LDCT images. We introduce a step-wise blind-spot denoising mechanism that enforces conditional independence in a progressive manner, enabling more fine-grained denoising learning. In addition, we add Gaussian noise to LDCT images, which acts as a regularization and mitigates overfitting. Extensive experiments on the Mayo LDCT dataset demonstrate that the proposed method consistently outperforms existing self-supervised approaches and achieves performance comparable to, or better than, several representative supervised denoising methods.

</details>


### [261] [IIR-VLM: In-Context Instance-level Recognition for Large Vision-Language Models](https://arxiv.org/abs/2601.14188)
*Liang Shi,Wei Li,Kevin M Beussman,Lin Chen,Yun Fu*

Main category: cs.CV

TL;DR: IIR-VLM通过整合预训练ILR专家模型，提升了VLM在实例级识别任务中的性能，支持一次性学习新实例，并在多样化测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现代VLM在实例级识别（ILR）任务中表现不佳，限制了其在需要识别熟悉人物或物体的实际应用中的有效性。现有方法通常需要逐个学习实例，数据收集和训练成本高，且难以实现细粒度区分。

Method: 提出IIR-VLM方法，整合预训练的ILR专家模型作为辅助视觉编码器，提供专业化特征以支持多样实例的学习，并实现一次性学习新实例的能力。

Result: IIR-VLM在现有实例个性化基准测试中验证了其有效性，并在包含不同难度和多样类别的新基准测试中展现了卓越的ILR性能。

Conclusion: IIR-VLM通过整合预训练的ILR专家模型作为辅助视觉编码器，显著提升了VLM在实例级识别任务中的性能，实现了对新实例的一次性学习，并在多样化的实例识别任务中表现出色。

Abstract: Instance-level recognition (ILR) concerns distinguishing individual instances from one another, with person re-identification as a prominent example. Despite the impressive visual perception capabilities of modern VLMs, we find their performance on ILR unsatisfactory, often dramatically underperforming domain-specific ILR models. This limitation hinders many practical application of VLMs, e.g. where recognizing familiar people and objects is crucial for effective visual understanding. Existing solutions typically learn to recognize instances one at a time using instance-specific datasets, which not only incur substantial data collection and training costs but also struggle with fine-grained discrimination. In this work, we propose IIR-VLM, a VLM enhanced for In-context Instance-level Recognition. We integrate pre-trained ILR expert models as auxiliary visual encoders to provide specialized features for learning diverse instances, which enables VLMs to learn new instances in-context in a one-shot manner. Further, IIR-VLM leverages this knowledge for instance-aware visual understanding. We validate IIR-VLM's efficacy on existing instance personalization benchmarks. Finally, we demonstrate its superior ILR performance on a challenging new benchmark, which assesses ILR capabilities across varying difficulty and diverse categories, with person, face, pet and general objects as the instances at task.

</details>


### [262] [Soft Tail-dropping for Adaptive Visual Tokenization](https://arxiv.org/abs/2601.14246)
*Zeyuan Chen,Kai Zhang,Zhuowen Tu,Yuanjun Xiong*

Main category: cs.CV

TL;DR: STAT是一种自适应视觉分词器，通过动态调整令牌数量提升因果自回归模型的视觉生成质量，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 旨在解决传统视觉生成模型中难以适应不同复杂度和细节水平的图像的问题，同时提升因果自回归模型的视觉生成质量。

Method: STAT将图像编码为离散代码序列，并伴随每个令牌的保留概率，通过正则化这些概率使其沿序列单调递减，并与图像级复杂度度量对齐。

Result: 在ImageNet-1k上，配备STAT的因果自回归模型在视觉生成质量上优于其他概率模型家族，并展现出良好的扩展行为。

Conclusion: STAT作为一种自适应视觉分词器，通过调整输出令牌数量以适应图像的结构复杂性和细节水平，显著提升了因果自回归视觉生成模型的性能。

Abstract: We present Soft Tail-dropping Adaptive Tokenizer (STAT), a 1D discrete visual tokenizer that adaptively chooses the number of output tokens per image according to its structural complexity and level of detail. STAT encodes an image into a sequence of discrete codes together with per-token keep probabilities. Beyond standard autoencoder objectives, we regularize these keep probabilities to be monotonically decreasing along the sequence and explicitly align their distribution with an image-level complexity measure. As a result, STAT produces length-adaptive 1D visual tokens that are naturally compatible with causal 1D autoregressive (AR) visual generative models. On ImageNet-1k, equipping vanilla causal AR models with STAT yields competitive or superior visual generation quality compared to other probabilistic model families, while also exhibiting favorable scaling behavior that has been elusive in prior vanilla AR visual generation attempts.

</details>


### [263] [OmniTransfer: All-in-one Framework for Spatio-temporal Video Transfer](https://arxiv.org/abs/2601.14250)
*Pengze Zhang,Yanze Wu,Mengtian Li,Xu Bai,Songtao Zhao,Fulong Ye,Chong Mou,Xinghui Li,Zhuowei Chen,Qian He,Mingyuan Gao*

Main category: cs.CV

TL;DR: OmniTransfer 是一个统一的时空视频转换框架，通过多视角和时间线索提升一致性，实验证明其在多种任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频定制方法未能充分利用视频的时空信息，限制了生成的灵活性和泛化能力。

Method: OmniTransfer 包含三个关键设计：任务感知的位置偏置、参考解耦的因果学习以及任务自适应的多模态对齐，以统一多种视频转换任务。

Result: 实验表明，OmniTransfer 在外观（ID 和风格）和时间（相机运动和视频效果）转换上优于现有方法，同时在运动转换中与基于姿态的方法表现相当。

Conclusion: OmniTransfer 通过多视角信息利用和时间线索提取，实现了灵活且高保真的视频生成，为视频时空转换任务设立了新范式。

Abstract: Videos convey richer information than images or text, capturing both spatial and temporal dynamics. However, most existing video customization methods rely on reference images or task-specific temporal priors, failing to fully exploit the rich spatio-temporal information inherent in videos, thereby limiting flexibility and generalization in video generation. To address these limitations, we propose OmniTransfer, a unified framework for spatio-temporal video transfer. It leverages multi-view information across frames to enhance appearance consistency and exploits temporal cues to enable fine-grained temporal control. To unify various video transfer tasks, OmniTransfer incorporates three key designs: Task-aware Positional Bias that adaptively leverages reference video information to improve temporal alignment or appearance consistency; Reference-decoupled Causal Learning separating reference and target branches to enable precise reference transfer while improving efficiency; and Task-adaptive Multimodal Alignment using multimodal semantic guidance to dynamically distinguish and tackle different tasks. Extensive experiments show that OmniTransfer outperforms existing methods in appearance (ID and style) and temporal transfer (camera movement and video effects), while matching pose-guided methods in motion transfer without using pose, establishing a new paradigm for flexible, high-fidelity video generation.

</details>


### [264] [LightOnOCR: A 1B End-to-End Multilingual Vision-Language Model for State-of-the-Art OCR](https://arxiv.org/abs/2601.14251)
*Said Taghadouini,Adrien Cavaillès,Baptiste Aubertin*

Main category: cs.CV

TL;DR: LightOnOCR-2-1B 是一个1B参数的端到端多语言视觉-语言模型，高效转换文档图像为文本，支持边界框预测，性能领先且更小更快。


<details>
  <summary>Details</summary>
Motivation: 旨在解决传统OCR流程的脆弱性问题，提供更高效、更准确的文档图像到文本的转换方案，并扩展功能以支持图像边界框的预测。

Method: 模型基于大规模、高质量的数据蒸馏混合训练，覆盖了扫描文档、法语文档和科学PDF。采用了恢复策略进行预训练中的定位，并通过基于IoU奖励的RLVR进行细化。此外，还使用了检查点平均和任务算术合并来提高鲁棒性。

Result: LightOnOCR-2-1B 在OlmOCR-Bench上实现了最先进的性能，模型大小缩小了9倍，速度显著提升。同时，通过新引入的边界框预测和鲁棒性改进技术，进一步增强了模型的实用性。

Conclusion: LightOnOCR-2-1B 是一个高效的端到端多语言视觉-语言模型，能够在文档图像（如PDF）上实现最先进的文本转换性能，同时模型更小、速度更快。此外，通过扩展输出格式预测标准化边界框和改进鲁棒性技术，进一步提升了模型的实用性。

Abstract: We present \textbf{LightOnOCR-2-1B}, a 1B-parameter end-to-end multilingual vision--language model that converts document images (e.g., PDFs) into clean, naturally ordered text without brittle OCR pipelines. Trained on a large-scale, high-quality distillation mix with strong coverage of scans, French documents, and scientific PDFs, LightOnOCR-2 achieves state-of-the-art results on OlmOCR-Bench while being 9$\times$ smaller and substantially faster than prior best-performing models. We further extend the output format to predict normalized bounding boxes for embedded images, introducing localization during pretraining via a resume strategy and refining it with RLVR using IoU-based rewards. Finally, we improve robustness with checkpoint averaging and task-arithmetic merging. We release model checkpoints under Apache 2.0, and publicly release the dataset and \textbf{LightOnOCR-bbox-bench} evaluation under their respective licenses.

</details>


### [265] [Motion 3-to-4: 3D Motion Reconstruction for 4D Synthesis](https://arxiv.org/abs/2601.14253)
*Hongyuan Chen,Xingyu Chen,Youjia Zhang,Zexiang Xu,Anpei Chen*

Main category: cs.CV

TL;DR: Motion 3-to-4 是一种从单目视频合成高质量4D动态对象的框架，通过分解任务为静态3D形状生成和运动重建，解决了数据有限和视角模糊的挑战。


<details>
  <summary>Details</summary>
Motivation: 4D合成由于训练数据有限和从单目视角恢复几何与运动的固有模糊性而具有挑战性。Motion 3-to-4旨在解决这些问题。

Method: 该框架利用规范参考网格学习紧凑的运动潜在表示，并通过逐帧顶点轨迹预测恢复完整的时间相干几何。可扩展的逐帧变换器增强了模型对不同序列长度的鲁棒性。

Result: 在标准基准和新数据集上的评估表明，Motion 3-to-4在保真度和空间一致性上优于先前的工作。

Conclusion: Motion 3-to-4 提供了一种高效的方法，通过分解4D合成任务为静态3D形状生成和运动重建，显著提升了从单目视频生成4D动态对象的保真度和空间一致性。

Abstract: We present Motion 3-to-4, a feed-forward framework for synthesising high-quality 4D dynamic objects from a single monocular video and an optional 3D reference mesh. While recent advances have significantly improved 2D, video, and 3D content generation, 4D synthesis remains difficult due to limited training data and the inherent ambiguity of recovering geometry and motion from a monocular viewpoint. Motion 3-to-4 addresses these challenges by decomposing 4D synthesis into static 3D shape generation and motion reconstruction. Using a canonical reference mesh, our model learns a compact motion latent representation and predicts per-frame vertex trajectories to recover complete, temporally coherent geometry. A scalable frame-wise transformer further enables robustness to varying sequence lengths. Evaluations on both standard benchmarks and a new dataset with accurate ground-truth geometry show that Motion 3-to-4 delivers superior fidelity and spatial consistency compared to prior work. Project page is available at https://motion3-to-4.github.io/.

</details>


### [266] [Implicit Neural Representation Facilitates Unified Universal Vision Encoding](https://arxiv.org/abs/2601.14256)
*Matthew Gwilliam,Xiao Wang,Xuefeng Hu,Zhenheng Yang*

Main category: cs.CV

TL;DR: 提出了一种新型模型，通过学习同时适用于识别和生成的表示，实现了图像表示学习的统一，并在性能和生成能力上表现出色。


<details>
  <summary>Details</summary>
Motivation: 统一识别和生成两个方向的模型，学习同时适用于识别和生成的表示。

Method: 训练模型作为隐式神经表示的超级网络，学习将图像映射到模型权重以实现快速准确的重建，并结合知识蒸馏以提高泛化和性能。

Result: 模型学习到一个前所未有的压缩嵌入空间，在各种视觉任务中表现出色。

Conclusion: 该模型在图像表示学习方面与最先进的结果竞争，同时通过高质量的小嵌入实现生成能力。

Abstract: Models for image representation learning are typically designed for either recognition or generation. Various forms of contrastive learning help models learn to convert images to embeddings that are useful for classification, detection, and segmentation. On the other hand, models can be trained to reconstruct images with pixel-wise, perceptual, and adversarial losses in order to learn a latent space that is useful for image generation. We seek to unify these two directions with a first-of-its-kind model that learns representations which are simultaneously useful for recognition and generation. We train our model as a hyper-network for implicit neural representation, which learns to map images to model weights for fast, accurate reconstruction. We further integrate our INR hyper-network with knowledge distillation to improve its generalization and performance. Beyond the novel training design, the model also learns an unprecedented compressed embedding space with outstanding performance for various visual tasks. The complete model competes with state-of-the-art results for image representation learning, while also enabling generative capabilities with its high-quality tiny embeddings. The code is available at https://github.com/tiktok/huvr.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [267] [An Efficient and Explainable KAN Framework forWireless Radiation Field Prediction](https://arxiv.org/abs/2601.11656)
*Jingzhou Shen,Xuyu Wang*

Main category: cs.NI

TL;DR: 论文提出了一种结合KAN和Transformer的新方法，通过全局学习射线表示提升无线信道建模性能，实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 当前神经网络在无线信道建模中独立处理每个体素，缺乏全局上下文和环境因素的考虑，限制了建模的准确性。

Method: 结合KAN架构与Transformer模块，学习完整射线的综合表示，而非独立处理单个体素，以捕捉更详细的环境特征。

Result: 实验结果表明，该方法在现实和合成场景中均优于现有方法，且保持了计算效率。

Conclusion: 该论文提出的基于Kolmogorov-Arnold网络（KAN）和Transformer模块的新方法，能够更全面地学习无线信道的完整射线表示，显著提升了性能，并通过消融实验验证了各模块的有效性。

Abstract: Modeling wireless channels accurately remains a challenge due to environmental variations and signal uncertainties. Recent neural networks can learn radio frequency~(RF) signal propagation patterns, but they process each voxel on the ray independently, without considering global context or environmental factors. Our paper presents a new approach that learns comprehensive representations of complete rays rather than individual points, capturing more detailed environmental features. We integrate a Kolmogorov-Arnold network (KAN) architecture with transformer modules to achieve better performance across realistic and synthetic scenes while maintaining computational efficiency. Our experimental results show that this approach outperforms existing methods in various scenarios. Ablation studies confirm that each component of our model contributes to its effectiveness. Additional experiments provide clear explanations for our model's performance.

</details>


### [268] [Cascaded Transformer for Robust and Scalable SLA Decomposition via Amortized Optimization](https://arxiv.org/abs/2601.11859)
*Cyril Shih-Huan Hsu*

Main category: cs.NI

TL;DR: Casformer是一种级联Transformer架构，用于快速、无优化的SLA分解，优于现有方法，适合实时SLA管理。


<details>
  <summary>Details</summary>
Motivation: 解决当前解决方案在分解端到端服务级别协议（SLAs）时计算密集、迭代优化过程导致的延迟和复杂性高的问题。

Method: Casformer采用级联Transformer架构，第一层通过领域特定的Transformer编码器利用历史领域反馈，第二层通过基于Transformer的聚合器整合跨领域依赖关系。模型在领域知情神经网络（DINNs）的学习范式下训练，结合风险知情建模和摊销优化，学习稳定的前向SLA分解策略。

Result: Casformer在SLA分解质量上优于现有优化框架，同时在波动和嘈杂的网络条件下展现出更强的可扩展性和鲁棒性，其前向设计降低了运行时复杂性，简化了部署和维护。

Conclusion: Casformer通过结合摊销优化和基于Transformer的序列建模，为高级5G及以后的网络环境提供了可扩展且高效的实时SLA管理解决方案。

Abstract: The evolution toward 6G networks increasingly relies on network slicing to provide tailored, End-to-End (E2E) logical networks over shared physical infrastructures. A critical challenge is effectively decomposing E2E Service Level Agreements (SLAs) into domain-specific SLAs, which current solutions handle through computationally intensive, iterative optimization processes that incur substantial latency and complexity. To address this, we introduce Casformer, a cascaded Transformer architecture designed for fast, optimization-free SLA decomposition. Casformer leverages historical domain feedback encoded through domain-specific Transformer encoders in its first layer, and integrates cross-domain dependencies using a Transformer-based aggregator in its second layer. The model is trained under a learning paradigm inspired by Domain-Informed Neural Networks (DINNs), incorporating risk-informed modeling and amortized optimization to learn a stable, forward-only SLA decomposition policy. Extensive evaluations demonstrate that Casformer achieves improved SLA decomposition quality against state-of-the-art optimization-based frameworks, while exhibiting enhanced scalability and robustness under volatile and noisy network conditions. In addition, its forward-only design reduces runtime complexity and simplifies deployment and maintenance. These insights reveal the potential of combining amortized optimization with Transformer-based sequence modeling to advance network automation, providing a scalable and efficient solution suitable for real-time SLA management in advanced 5G-and-beyond network environments.

</details>


### [269] [A Method for Detecting Spatio-temporal Correlation Anomalies of WSN Nodes Based on Topological Information Enhancement and Time-frequency Feature Extraction](https://arxiv.org/abs/2601.11951)
*Miao Ye,Ziheng Wang,Yong Wang,Junqi Chen*

Main category: cs.NI

TL;DR: 提出TE-MSTAD方法，通过跨模态特征提取和时频域特征融合，显著提升WSN异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 现有WSN异常检测方法在时空相关性特征提取不足、仅依赖时域或频域信息、计算开销大等方面存在局限。

Method: 提出了TE-MSTAD方法，包括基于RWKV模型的跨模态特征提取模块、联合学习时空相关性的邻接矩阵构建策略，以及双分支网络设计用于时频域特征融合。

Result: TE-MSTAD模型在公开和真实数据集上表现优异，F1分数分别为92.52%和93.28%。

Conclusion: TE-MSTAD模型在公开和真实数据集上分别实现了92.52%和93.28%的F1分数，表现出优于现有方法的检测性能和泛化能力。

Abstract: Existing anomaly detection methods for Wireless Sensor Networks (WSNs) generally suffer from insufficient ex-traction of spatio-temporal correlation features, reliance on either time-domain or frequency-domain information alone, and high computational overhead. To address these limitations, this paper proposes a topology-enhanced spatio-temporal feature fusion anomaly detection method, TE-MSTAD. First, building upon the RWKV model with linear attention mechanisms, a Cross-modal Feature Extraction (CFE) module is introduced to fully extract spatial correlation features among multiple nodes while reducing computational resource consumption. Second, a strategy is designed to construct an adjacency matrix by jointly learning spatial correlation from time-frequency domain features. Different graph neural networks are integrated to enhance spatial correlation feature extraction, thereby fully capturing spatial relationships among multiple nodes. Finally, a dual-branch network TE-MSTAD is designed for time-frequency domain feature fusion, overcoming the limitations of relying solely on the time or frequency domain to improve WSN anomaly detection performance. Testing on both public and real-world datasets demonstrates that the TE-MSTAD model achieves F1 scores of 92.52% and 93.28%, respectively, exhibiting superior detection performance and generalization capabilities compared to existing methods.

</details>


### [270] [Noisy Neighbor Influence in the Data Plane of Beyond 5G Networks](https://arxiv.org/abs/2601.12106)
*Rodrigo Moreira,Larissa Ferreira Rodrigues Moreira,Tereza C. Carvalho,Flavio de Oliveira Silva*

Main category: cs.NI

TL;DR: B5G网络中共享硬件导致的噪声邻居效应会影响切片性能，内核级UPF工具化显示优先切片也会受延迟影响。


<details>
  <summary>Details</summary>
Motivation: 随着B5G网络解决网络切片隔离的挑战，共享底层硬件可能导致切片间的数据平面争用，引发噪声邻居效应，威胁网络切片和服务级别协议。

Method: 提出了一种内核级的用户平面功能（UPF）工具化方法，用于评估噪声切片对数据平面处理的影响。

Result: 研究发现，优先切片也会因噪声邻居效应而性能下降，用户体验相关的延迟指标受到影响。

Conclusion: 内核级UPF工具化揭示了即使在优先切片中，噪声邻居效应也会导致数据平面处理性能下降，影响用户体验相关的延迟指标。

Abstract: Virtualization and containerization enhance the modularity and scalability of mobile network architectures, facilitating customized user services and improving management and orchestration across the network. In the context of the 5th Generation Mobile Network (5G), these advancements contribute to reduced Operational Expenditures (OPEX) and enable sliced-based networking for novel applications and services. However, as beyond fifth-generation (B5G) networks aim to address the remaining challenges regarding network slice isolation, the shared underlying hardware can lead to data plane contention among slices, resulting in the Noisy Neighbor (NN) effect, which may compromise network slicing and Service-Level Agreements (SLAs). We propose a kernel-level instrumentation of the User Plane Function (UPF) to assess the impact of noisy slices on data plane processing. Our findings reveal that even prioritized slices are susceptible to degradation induced by NN, with observable effects on latency metrics pertinent to user experience.

</details>


### [271] [A Tutorial on Controlling Metasurfaces from the Network Perspective](https://arxiv.org/abs/2601.12118)
*Christos Liaskos,Evangelos Papapetrou,Kostas Katsalis,Dimitrios Tyrovolas,Alexandros Papadopoulos,Stavros Tsimpoukis,Arash Pourdamghani,Max Franke,Stefan Schmid*

Main category: cs.NI

TL;DR: 本文综述了超表面的物理原理、制造方法及网络化控制，提出图论建模和优化框架，并展望了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 超表面在无线通信中具有实时控制波传播的潜力，可提升数据速率、隐私保护、能效和环境感知能力。

Method: 通过回顾超表面的物理原理和制造方法，将其建模为波路由器，并利用图论描述超表面系统，开发性能优化框架。

Result: 提出了基于图论的超表面系统建模方法，讨论了启发式和路径查找算法作为实际求解器，并探讨了与网络模拟器的集成。

Conclusion: 本文探讨了将超表面作为网络系统组件的控制方法，并提出了基于图论的性能优化框架，同时讨论了与通信系统集成的未来研究方向。

Abstract: Metasurfaces have emerged as transformative electromagnetic structures for wireless communications, enabling the real-time control over wave propagation, yielding potential for improved data rates, privacy, energy efficiency and even precise environmental sensing. This tutorial offers a perspective on controlling metasurfaces by treating them as components of a larger networked system. Towards this end, we first review the physical principles of metasurfaces and their various applications, followed by an exploration of manufacturing approaches for creating these structures. Then, aligning with standard network layer concepts, we describe the modeling of metasurfaces as wave routers, enabling us to describe systems of metasurfaces using graph theory. This approach enables the development of a performance objective framework for optimizing these systems, while classes of heuristic and path-finding-driven algorithms are discussed as practical solvers. The paper also examines the integration of metasurfaces with communication systems, by presenting their overall workflow, discussing its relation to ongoing standardization efforts, as well as defining a context for their integration to network simulators, using Omnet++ as a driving example. Finally, the paper explores future directions for research in this field, identifying graph-theoretic, standardization and integration challenges, relating to several networking disciplines including AI-driven applications.

</details>


### [272] [Understanding Partial Reachability in the Internet Core](https://arxiv.org/abs/2601.12196)
*Guillermo Baltra,Tarang Saluja,Yuri Pradkin,John Heidemann*

Main category: cs.NI

TL;DR: 本文定义了互联网核心的中立概念，发现半岛和岛屿现象普遍存在，对测量系统有显著影响，并提出了改进方法。


<details>
  <summary>Details</summary>
Motivation: 互联网的连通性面临政治压力、架构变化和商业争议的威胁，导致部分可达性成为常态，但这一问题尚未被充分研究。

Method: 首先基于连通性而非权威性定义了互联网核心概念，随后开发了观察半岛和岛屿的算法，并在Trinocular和RIPE Atlas两个测量系统中应用。通过三年数据的交叉验证，并与CAIDA Ark对比验证了结果的稳定性。

Result: 研究发现半岛现象比互联网中断更常见，且大部分半岛事件是路由瞬态（45%），但半岛时间主要由少数（7%）长寿命事件主导（90%）。去除这些噪声可显著提升现有测量系统的性能。

Conclusion: 本文提出了互联网核心的中立定义，并展示了半岛和岛屿现象的普遍性及其对现有测量系统的影响，为互联网政策和治理提供了新的视角。

Abstract: Routing strives to connect all the Internet, but compete: political pressure threatens routing fragmentation; architectural changes such as private clouds, carrier-grade NAT, and firewalls make connectivity conditional; and commercial disputes create partial reachability for days or years. This paper suggests *persistent, partial reachability is fundamental to the Internet* and an underexplored problem. We first *derive a conceptual definition of the Internet core* based on connectivity, not authority. We identify *peninsulas*: persistent, partial connectivity; and *islands*: when computers are partitioned from the Internet core. Second, we develop algorithms to observe each across the Internet, and apply them to two existing measurement systems: Trinocular, where 6 locations observe 5M networks frequently, and RIPE Atlas, where 13k locations scan the DNS roots frequently. Cross-validation shows our findings are stable over *three years of data*, and consistent with as few as 3 geographically-distributed observers. We validate peninsulas and islands against CAIDA Ark, showing good recall (0.94) and bounding precision between 0.42 and 0.82. Finally, our work has broad practical impact: we show that *peninsulas are more common than Internet outages*. Factoring out peninsulas and islands as noise can *improve existing measurement systems*; their ``noise'' is $5\times$ to $9.7\times$ larger than the operational events in RIPE's DNSmon. We show that most peninsula events are routing transients (45\%), but most peninsula-time (90\%) is due to a few (7\%) long-lived events. Our work helps inform Internet policy and governance, with our neutral definition showing no single country or organization can unilaterally control the Internet core.

</details>


### [273] [Cross-reality Location Privacy Protection in 6G-enabled Vehicular Metaverses: An LLM-enhanced Hybrid Generative Diffusion Model-based Approach](https://arxiv.org/abs/2601.12311)
*Xiaofeng Luo,Jiayi He,Jiawen Kang,Ruichen Zhang,Zhaoshui He,Ekram Hossain,Dong In Kim*

Main category: cs.NI

TL;DR: 论文提出了一种混合动作框架（LHDPPO算法）保护6G车载元宇宙中AVs的位置隐私，平衡隐私保护、服务延迟和服务质量。


<details>
  <summary>Details</summary>
Motivation: 6G车载元宇宙中，自动驾驶车辆（AVs）通过物理和虚拟空间的交互可能引发严重的位置隐私风险，因为攻击者可以通过关联现实中的位置服务请求和虚拟中AI代理部署的位置来推断AV轨迹。

Method: 设计了基于混合动作的跨现实位置隐私保护框架，包括现实中的连续位置扰动和虚拟中的离散隐私感知AI代理迁移。提出了一种新的隐私度量标准——跨现实位置熵，并开发了LLM增强的混合扩散近端策略优化（LHDPPO）算法来解决复杂的混合整数优化问题。

Result: 在真实数据集上的大量实验表明，所提出的框架有效减少了跨现实位置隐私泄露，同时保持了低服务延迟和高服务质量。

Conclusion: 该论文提出的跨现实位置隐私保护框架（基于混合动作）有效缓解了6G车载元宇宙中自动驾驶车辆的位置隐私泄露问题，同时保持了良好的用户体验。

Abstract: The emergence of 6G-enabled vehicular metaverses enables Autonomous Vehicles (AVs) to operate across physical and virtual spaces through space-air-ground-sea integrated networks. The AVs can deploy AI agents powered by large AI models as personalized assistants, on edge servers to support intelligent driving decision making and enhanced on-board experiences. However, such cross-reality interactions may cause serious location privacy risks, as adversaries can infer AV trajectories by correlating the location reported when AVs request LBS in reality with the location of the edge servers on which their corresponding AI agents are deployed in virtuality. To address this challenge, we design a cross-reality location privacy protection framework based on hybrid actions, including continuous location perturbation in reality and discrete privacy-aware AI agent migration in virtuality. In this framework, a new privacy metric, termed cross-reality location entropy, is proposed to effectively quantify the privacy levels of AVs. Based on this metric, we formulate an optimization problem to optimize the hybrid action, focusing on achieving a balance between location protection, service latency reduction, and quality of service maintenance. To solve the complex mixed-integer problem, we develop a novel LLM-enhanced Hybrid Diffusion Proximal Policy Optimization (LHDPPO) algorithm, which integrates LLM-driven informative reward design to enhance environment understanding with double Generative Diffusion Models-based policy exploration to handle high-dimensional action spaces, thereby enabling reliable determination of optimal hybrid actions. Extensive experiments on real-world datasets demonstrate that the proposed framework effectively mitigates cross-reality location privacy leakage for AVs while maintaining strong user immersion within 6G-enabled vehicular metaverse scenarios.

</details>


### [274] [LiQSS: Post-Transformer Linear Quantum-Inspired State-Space Tensor Networks for Real-Time 6G](https://arxiv.org/abs/2601.12375)
*Farhad Rezazadeh,Hatim Chergui,Mehdi Bennis,Houbing Song,Lingjia Liu,Dusit Niyato,Merouane Debbah*

Main category: cs.NI

TL;DR: 提出LiQSS模型，通过量子启发的张量网络实现高效序列建模，显著优于Transformer和现有基线。


<details>
  <summary>Details</summary>
Motivation: Transformer模型在Near-RT RAN Intelligent Controller分析中因二次复杂度难以扩展，需高效序列建模方法。

Method: 提出了一种量子启发的多体状态空间张量网络，用稳定的结构化状态空间动态核替代自注意力机制，实现线性时间序列建模。采用Tensor Train/Matrix Product State表示减少参数化和数据移动。

Result: LiQSS模型比现有结构化状态空间基线小10.8x-15.8x，快1.4x；相比Transformer模型，参数减少155x，推理快2.74x。

Conclusion: LiQSS模型在保持预测精度的同时，显著减少了参数数量和推理时间，适用于6G O-RAN的Near-RT RIC分析。

Abstract: Proactive and agentic control in Sixth-Generation (6G) Open Radio Access Networks (O-RAN) requires control-grade prediction under stringent Near-Real-Time (Near-RT) latency and computational constraints. While Transformer-based models are effective for sequence modeling, their quadratic complexity limits scalability in Near-RT RAN Intelligent Controller (RIC) analytics. This paper investigates a post-Transformer design paradigm for efficient radio telemetry forecasting. We propose a quantum-inspired many-body state-space tensor network that replaces self-attention with stable structured state-space dynamics kernels, enabling linear-time sequence modeling. Tensor-network factorizations in the form of Tensor Train (TT) / Matrix Product State (MPS) representations are employed to reduce parameterization and data movement in both input projections and prediction heads, while lightweight channel gating and mixing layers capture non-stationary cross-Key Performance Indicator (KPI) dependencies. The proposed model is instantiated as an agentic perceive-predict xApp and evaluated on a bespoke O-RAN KPI time-series dataset comprising 59,441 sliding windows across 13 KPIs, using Reference Signal Received Power (RSRP) forecasting as a representative use case. Our proposed Linear Quantum-Inspired State-Space (LiQSS) model is 10.8x-15.8x smaller and approximately 1.4x faster than prior structured state-space baselines. Relative to Transformer-based models, LiQSS achieves up to a 155x reduction in parameter count and up to 2.74x faster inference, without sacrificing forecasting accuracy.

</details>


### [275] [SDN-Blockchain Based Security Routing for UAV Communication via Reinforcement Learning](https://arxiv.org/abs/2601.12774)
*Yulu Han,Ziye Jia,Jingjing Zhao,Lijun He,Yao Wu,Qihui Wu*

Main category: cs.NI

TL;DR: 论文提出BSPPO算法，结合SDN和区块链，显著提升无人机网络的安全性和性能。


<details>
  <summary>Details</summary>
Motivation: 无人机网络在应急通信中至关重要，但设计低延迟、高能效且安全的路由策略在动态和易受攻击的环境中具有挑战性。

Method: 设计了集成SDN和区块链的安全路由架构，引入安全度度量标准，并提出BSPPO算法（结合波束搜索和近端策略优化）。

Result: 在不同攻击密度、数据包大小和重路由事件下的模拟显示，BSPPO在延迟、能耗和传输成功率上优于PPO、BS-Q学习和BS-actor critic。

Conclusion: 论文提出了一种结合SDN和区块链的安全路由架构，以及BSPPO算法，显著提升了无人机网络在动态和易受攻击环境中的性能表现。

Abstract: The unmanned aerial vehicle (UAV) network plays important roles in emergency communications. However, it is challenging to design reliable routing strategies that ensure low latency, energy efficiency, and security in the dynamic and attack-prone environments. To this end, we design a secure routing architecture integrating software-defined networking (SDN) for centralized control and blockchain for tamper-proof trust management. In particular, a novel security degree metric is introduced to quantify the UAV trustworthiness. Based on this architecture, we propose a beam search-proximal policy optimization (BSPPO) algorithm, where beam search (BS) pre-screens the high-security candidate paths, and proximal policy optimization (PPO) performs hop-by-hop routing decisions to support dynamic rerouting upon attack detections. Finally, extensive simulations under varying attack densities, packet sizes, and rerouting events demonstrate that BSPPO outperforms PPO, BS-Q learning, and BS-actor critic in terms of delay, energy consumption, and transmission success rate, showing the outstanding robustness and adaptability.

</details>


### [276] [Path to Diversity: A Primer on ISAC-izing Commodity Wi-Fi for Practical Deployments](https://arxiv.org/abs/2601.12980)
*Hongbo Wang,Xin Li,Yinghui He,Jingzhi Hu,Mingming Xu,Zhe Chen,Fu Xiao,Jun Luo*

Main category: cs.NI

TL;DR: 本教程从物理层多样性角度分析Wi-Fi技术进步对ISAC的增益，围绕时间、频率、链路和空间四个维度构建框架，填补现有文献的空白，为未来标准化提供指南。


<details>
  <summary>Details</summary>
Motivation: 现有文献多采用自上而下的视角，强调上层应用或深度学习模型，而将物理层视为不透明的抽象，缺乏对信号形成底层和克服物理障碍的技术指导。本教程旨在填补这一空白。

Method: 本教程采用自下而上的方法，围绕四个正交维度（时间多样性、频率多样性、链路多样性和空间多样性）构建框架，解决时间、距离和空间中的基本模糊性问题。

Result: 通过综合四个正交维度，本教程解决了时间、距离和空间中的基本模糊性问题，将物理能力与具有挑战性的感知多样性联系起来。

Conclusion: 本教程通过从物理层多样性的角度系统分析Wi-Fi技术进步带来的感知增益，为‘ISAC化’商用Wi-Fi提供了全面指南，为未来的标准化和稳健部署铺平了道路。

Abstract: Integrated Sensing and Communication (ISAC) has emerged as a key paradigm in next-generation wireless networks. While the ubiquity and low cost of commodity Wi-Fi make it an ideal platform for wide-scale sensing, it is the continuous evolution of Wi-Fi standards-towards higher frequency bands, wider bandwidths, and larger antenna arrays-that fundamentally unlocks the physical resources required for high-performance ISAC. To structure this rapidly expanding field, numerous surveys have appeared. However, prevailing literature predominantly adopts a top-down perspective, emphasizing upper-layer applications or deep learning models while treating the physical layer as an opaque abstraction. Consequently, these works often fail to touch the bottom layer of signal formation and lack technical guidance on overcoming the physical barriers that constrain sensing performance. To bridge this gap, this tutorial takes a bottom-up approach, systematically analyzing the sensing gains brought by Wi-Fi advancements through the lens of physical-layer diversity. We organize the framework around four orthogonal dimensions: i) Temporal Diversity addresses synchronization gaps to enable absolute ranging; ii) Frequency Diversity expands the effective bandwidth to sharpen range resolution; iii) Link Diversity leverages distributed topologies and digital feedback to achieve ubiquitous observability; and iv) Spatial Diversity utilizes multi-antenna arrays to combine passive angular discrimination with active directional control. Collectively, these orthogonal dimensions resolve fundamental ambiguities in time, range, and space, bridging physical capabilities with challenging sensing diversities. By synthesizing these dimensions, this tutorial provides a comprehensive guide for "ISAC-izing" commodity Wi-Fi, paving the way for future standardization and robust deployment.

</details>


### [277] [No Traffic to Cry: Traffic-Oblivious Link Deactivation for Green Traffic Engineering](https://arxiv.org/abs/2601.13087)
*Max Ilsen,Daniel Otten,Nils Aschenbruck,Markus Chimani*

Main category: cs.NI

TL;DR: 论文提出了一种流量无关的绿色流量工程方法，通过近似算法和后处理启发式方法，实现了骨干网络的高效节能，且无需频繁重新配置。


<details>
  <summary>Details</summary>
Motivation: 随着互联网流量的增长，底层基础设施的能耗不断增加。在非高峰时段，网络的大部分资源未被充分利用，存在显著的节能潜力。现有方法在流量变化时需要快速适应，但由于问题的复杂性难以实现。

Method: 论文提出了一种最大（1/(ϱ⋅λ_min), 2）近似算法，用于解决在保证任何可路由的流量矩阵下激活最少连接的问题，并提出了两种后处理启发式方法以进一步提高解的质量。

Result: 评估结果表明，该方法能够快速生成接近最优的解，且设计上避免了频繁重新配置的需求。

Conclusion: 该论文提出了一种基于流量无关路由方案的绿色流量工程方法，能够在不频繁重新配置的情况下实现骨干网络的节能，并通过评估验证了其快速生成接近最优解的能力。

Abstract: As internet traffic grows, the underlying infrastructure consumes increasing amounts of energy. During off-peak hours, large parts of the networks remain underutilized, presenting significant potential for energy savings. Existing Green Traffic Engineering approaches attempt to leverage this potential by switching off those parts of the networks that are not required for the routing of specific traffic matrices. When traffic changes, the approaches need to adapt rapidly, which is hard to achieve given the complexity of the problem. We take a fundamentally different approach: instead of considering a specific traffic matrix, we rely on a traffic-oblivious routing scheme. We discuss the NP-hard problem of activating as few connections as possible while still guaranteeing that any down-scaled traffic matrix $\varrho\cdot T$ can be routed, where $\varrho \in (0,1)$ and $T$ is any traffic matrix routable in the original network. We present a $\max(\frac{1}{\varrho\cdotλ_{\text{min}}},2)$-approximation algorithm for this problem, with $λ_{\text{min}}$ denoting the minimum number of connections between any two connected routers. Additionally, we propose two post-processing heuristics to further improve solution quality. Our evaluation shows that we can quickly generate near-optimal solutions. By design, our method avoids the need for frequent reconfigurations and offers a promising direction to achieve practical energy savings in backbone networks.

</details>


### [278] [IntAgent: NWDAF-Based Intent LLM Agent Towards Advanced Next Generation Networks](https://arxiv.org/abs/2601.13114)
*Abdelrahman Soliman,Ahmed Refaey,Aiman Erbad,Amr Mohamed*

Main category: cs.NI

TL;DR: IntAgent是一个智能意图LLM代理，通过NWDAF实时分析和工具集成，成功自动化处理网络运营商意图。


<details>
  <summary>Details</summary>
Motivation: 意图网络（IBNs）作为一种创新技术，通过高级请求语句自动化网络操作，但现有方法缺乏实时网络分析的集成。

Method: 开发了一个直接嵌入NWDAF分析引擎的意图工具引擎，结合3GPP兼容数据源和MCP工具服务器。

Result: 通过ML流量预测和计划策略执行两个用例，验证了IntAgent自主实现复杂网络意图的能力。

Conclusion: IntAgent通过整合NWDAF分析和工具，成功实现了网络运营商意图的自动化处理，并通过实际用例验证了其有效性。

Abstract: Intent-based networks (IBNs) are gaining prominence as an innovative technology that automates network operations through high-level request statements, defining what the network should achieve. In this work, we introduce IntAgent, an intelligent intent LLM agent that integrates NWDAF analytics and tools to fulfill the network operator's intents. Unlike previous approaches, we develop an intent tools engine directly within the NWDAF analytics engine, allowing our agent to utilize live network analytics to inform its reasoning and tool selection. We offer an enriched, 3GPP-compliant data source that enhances the dynamic, context-aware fulfillment of network operator goals, along with an MCP tools server for scheduling, monitoring, and analytics tools. We demonstrate the efficacy of our framework through two practical use cases: ML-based traffic prediction and scheduled policy enforcement, which validate IntAgent's ability to autonomously fulfill complex network intents.

</details>


### [279] [Conflict Detection in AI-RAN: Efficient Interaction Learning and Autonomous Graph Reconstruction](https://arxiv.org/abs/2601.13213)
*Joao F. Santos,Arshia Zolghadr,Scott Kuzdeba,Jacek Kibiłda*

Main category: cs.NI

TL;DR: 本文提出了一种AI原生移动网络冲突检测的系统化框架，利用两塔编码器和数据驱动机制，实现了高效的冲突图自动重构。


<details>
  <summary>Details</summary>
Motivation: AI原生移动网络中多个AI代理优化网络时可能产生冲突，现有方法依赖复杂且计算昂贵的GNN和手动阈值设定，亟需更高效的解决方案。

Method: 采用两塔编码器架构学习RAN数据中的交互，并引入数据驱动的稀疏性机制来自主重构冲突图。

Result: 提出的框架能够有效检测冲突，并通过数据驱动方法自动重构冲突图，减少了对人工干预的依赖。

Conclusion: 本文提出了一个系统化的框架，用于AI原生移动网络中的冲突检测，通过两塔编码器架构和数据驱动的稀疏性机制，实现了无需手动调整的冲突图重构。

Abstract: Artificial Intelligence (AI)-native mobile networks represent a fundamental step toward 6G, where learning, inference, and decision making are embedded into the Radio Access Network (RAN) itself. In such networks, multiple AI agents optimize the network to achieve distinct and often competing objectives. As such, conflicts become inevitable and have the potential to degrade performance, cause instability, and disrupt service. Current approaches for conflict detection rely on conflict graphs created based on relationships between AI agents, parameters, and Key Performance Indicators (KPIs). Existing works often rely on complex and computationally expensive Graph Neural Networks (GNNs) and depend on manually chosen thresholds to create conflict graphs. In this work, we present the first systematic framework for conflict detection in AI-native mobile networks, propose a two-tower encoder architecture for learning interactions based on data from the RAN, and introduce a data-driven sparsity-based mechanism for autonomously reconstructing conflict graphs without manual fine-tuning.

</details>


### [280] [Spectrum & RAN Sharing: A Measurement-based Case Study of Commercial 5G Networks in Spain](https://arxiv.org/abs/2601.13484)
*Rostand A. K. Fezeu,Lilian C. Freitas,Eman Ramadan,Jason Carpenter,Claudio Fiandrino,Joerg Widmer,Zhi-Li Zhang*

Main category: cs.NI

TL;DR: 首次实证测量商业5G频谱和RAN共享，分析其对用户感知性能和QoE的影响，为未来网络演进提供蓝图。


<details>
  <summary>Details</summary>
Motivation: 探索RAN共享对用户感知性能的影响，尤其是在实际商业部署中。

Method: 通过实证测量研究，分析了商业5G频谱和RAN共享的实际部署情况。

Result: 研究发现共享5G频谱和RAN部署对用户感知性能和QoE有显著影响。

Conclusion: 该研究为5G、6G及未来的网络演进提供了资源管理和频谱效率的蓝图与启示。

Abstract: Radio Access Network (RAN) sharing, which often also includes spectrum sharing, is a strategic cooperative agreement among two or more mobile operators, where one operator may use another's RAN infrastructure to provide mobile services to its users. By mutually sharing physical sites, radio elements, licensed spectrum and other parts of the RAN infrastructure, participating operators can significantly reduce the capital (and operational) expenditure in deploying and operating cellular networks, while accelerating coverage expansion -- thereby addressing the spectrum scarcity and infrastructure cost challenges in the 5G era and beyond. While the economic benefits of RAN sharing are well understood, the impact of such resource pooling on user-perceived performance remains underexplored, especially in real-world commercial deployments. We present, to the best of our knowledge, the first empirical measurement study of commercial 5G spectrum and RAN sharing. Our measurement study is unique in that, beyond identifying real-world instances of shared 5G spectrum and RAN deployment "in the wild", we also analyze users' perceived performance and its implication on Quality of Experience (QoE). Our study provides critical insights into resource management (i.e., pooling) and spectrum efficiency, offering a blueprint (and implications) for network evolution in 5G, 6G and beyond.

</details>


### [281] [Reinforcement Learning for Opportunistic Routing in Software-Defined LEO-Terrestrial Systems](https://arxiv.org/abs/2601.13662)
*Sivaram Krishnan,Zhouyou Gu,Jihong Park,Sung-Min Oh,Jinho Choi*

Main category: cs.NI

TL;DR: 本文提出一种基于残差强化学习的机遇路由策略，用于动态LEO网络，显著降低延迟和队列长度。


<details>
  <summary>Details</summary>
Motivation: 大规模LEO卫星星座的普及需要智能路由策略，以在快速变化的拓扑结构和间歇性网关可见性下有效传输数据。

Method: 利用GEO驻留的SDN控制器的全局控制能力，提出机遇路由策略，并通过约束随机优化问题和残差强化学习框架进行优化。

Result: 模拟多天的轨道数据表明，该方法在队列长度减少方面取得了显著改进。

Conclusion: 本文提出的基于残差强化学习的机遇路由策略在高度动态的LEO网络中显著降低了传输延迟和队列长度，优于传统的背压算法和其他知名排队算法。

Abstract: The proliferation of large-scale low Earth orbit (LEO) satellite constellations is driving the need for intelligent routing strategies that can effectively deliver data to terrestrial networks under rapidly time-varying topologies and intermittent gateway visibility. Leveraging the global control capabilities of a geostationary (GEO)-resident software-defined networking (SDN) controller, we introduce opportunistic routing, which aims to minimize delivery delay by forwarding packets to any currently available ground gateways rather than fixed destinations. This makes it a promising approach for achieving low-latency and robust data delivery in highly dynamic LEO networks. Specifically, we formulate a constrained stochastic optimization problem and employ a residual reinforcement learning framework to optimize opportunistic routing for reducing transmission delay. Simulation results over multiple days of orbital data demonstrate that our method achieves significant improvements in queue length reduction compared to classical backpressure and other well-known queueing algorithms.

</details>


### [282] [Generative Intent Prediction Agentic AI empowered Edge Service Function Chain Orchestration](https://arxiv.org/abs/2601.13694)
*Yan Sun,Shaoyong Guo,Sai Huang,Zhiyong Feng,Feng Qi,Xuesong Qiu*

Main category: cs.NI

TL;DR: 提出GIPA框架，通过生成式意图预测和主动编排优化边缘网络中的SFC管理，实验显示其在高动态场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统基于大语言模型的代理AI（AAI）在网络管理中被动响应，难以应对边缘网络环境中的高用户移动性和隐式服务意图。

Method: 构建多维意图空间，设计基于生成扩散模型（GDM）的意图预测模型，并将预测的隐式意图嵌入SFC编排模型。

Result: 实验结果表明，GIPA在高度并发和动态场景中优于现有基线方法。

Conclusion: GIPA框架通过生成式意图预测和主动编排，显著提升了边缘网络环境中服务功能链（SFC）的管理效率，尤其在高度并发和动态场景下优于现有基线方法。

Abstract: With the development of artificial intelligence (AI), Agentic AI (AAI) based on large language models (LLMs) is gradually being applied to network management. However, in edge network environments, high user mobility and implicit service intents pose significant challenges to the passive and reactive management of traditional AAI. To address the limitations of existing approaches in handling dynamic demands and predicting users' implicit intents, in this paper we propose an edge service function chain (SFC) orchestration framework empowered by a Generative Intent Prediction Agent (GIPA). Our GIPA aims to shift the paradigm from passive execution to proactive prediction and orchestration. First, we construct a multidimensional intent space that includes functional preferences, QoS sensitivity, and resource requirements, enabling the mapping from unstructured natural language to quantifiable physical resource demands. Second, to cope with the complexity and randomness of intent sequences, we design an intent prediction model based on a Generative Diffusion Model (GDM), which reconstructs users' implicit intents from multidimensional context through a reverse denoising process. Finally, the predicted implicit intents are embedded as global prompts into the SFC orchestration model to guide the network in proactively and ahead-of-time optimizing SFC deployment strategies. Experiment results show that GIPA outperforms existing baseline methods in highly concurrent and highly dynamic scenarios.

</details>


### [283] [IGAA: Intent-Driven General Agentic AI for Edge Services Scheduling using Generative Meta Learning](https://arxiv.org/abs/2601.13702)
*Yan Sun,Yinqiu Liu,Shaoyong Guo,Ruichen Zhang,Feng Qi,Xuesong Qiu,Weifeng Gong,Dusit Niyato,Qihui Wu*

Main category: cs.NI

TL;DR: IGAA是一种基于元学习的Agentic AI框架，通过三种核心机制提升边缘服务调度的泛化能力，实验验证其在动态场景下的高效适应性。


<details>
  <summary>Details</summary>
Motivation: 用户移动性导致边缘网络服务需求高度动态化，现有服务调度代理缺乏对新场景的泛化能力，因此需要一种能持续学习并适应新场景的框架。

Method: IGAA框架设计了Network-Service-Intent矩阵映射方法、易到难的泛化学习方案（包括RCETL和APOTL算法），以及Generative Intent Replay机制，并结合场景评估与修正模型来优化LLM生成的场景。

Result: 实验表明IGAA具有强大的泛化性和扩展性，能够快速适应新场景，并将学习策略迁移到类似任务中，如将实时计算的延迟敏感模式优化应用于新型车联网服务。

Conclusion: IGAA框架通过元学习范式，结合三种核心机制，显著提升了Agentic AI在边缘网络中的泛化能力和适应性，尤其在用户移动性导致的高动态服务需求场景下表现优异。

Abstract: Agentic AI (AAI), which extends Large Language Models with enhanced reasoning capabilities, has emerged as a promising paradigm for autonomous edge service scheduling. However, user mobility creates highly dynamic service demands in edge networks, and existing service scheduling agents often lack generalization capabilities for new scenarios. Therefore, this paper proposes a novel Intent-Driven General Agentic AI (IGAA) framework. Leveraging a meta-learning paradigm, IGAA enables AAI to continuously learn from prior service scheduling experiences to achieve generalized scheduling capabilities. Particularly, IGAA incorporates three core mechanisms. First, we design a Network-Service-Intent matrix mapping method to allow agents to simulate novel scenarios and generate training datasets. Second, we present an easy-to-hard generalization learning scheme with two customized algorithms, namely Resource Causal Effect-aware Transfer Learning (RCETL) and Action Potential Optimality-aware Transfer Learning (APOTL). These algorithms help IGAA adapt to new scenarios. Furthermore, to prevent catastrophic forgetting during continual IGAA learning, we propose a Generative Intent Replay (GIR) mechanism that synthesizes historical service data to consolidate prior capabilities. Finally, to mitigate the effect of LLM hallucinations on scenario simulation, we incorporate a scenario evaluation and correction model to guide agents in generating rational scenarios and datasets. Extensive experiments demonstrate IGAA's strong generalization and scalability. Specifically, IGAA enables rapid adaptation by transferring learned policies to analogous new ones, such as applying latency-sensitive patterns from real-time computing to optimize novel Internet of Vehicles (IoV) services. Compared to scenario-specific methods, IGAA maintains the intent-satisfaction rate gap within 3.81%.

</details>


### [284] [Variational Dual-path Attention Network for CSI-Based Gesture Recognition](https://arxiv.org/abs/2601.13745)
*N. Zhang*

Main category: cs.NI

TL;DR: 提出VDAN模块，通过频域滤波和时域检测优化CSI手势识别，变分推理增强抗噪性，实验验证其可解释性和高效性。


<details>
  <summary>Details</summary>
Motivation: 现有端到端模型将特征提取与分类紧密耦合，忽视了CSI固有的时频稀疏性，导致冗余和泛化能力差。

Method: 提出了轻量级特征预处理模块VDAN，通过频域滤波和时域检测进行结构化特征细化，并引入变分推理来建模注意力权重的不确定性。

Result: 在公共数据集上的实验表明，VDAN模块的注意力权重与CSI的物理稀疏特性一致，验证了其可解释性。

Conclusion: VDAN模块为资源受限的无线感知系统提供了一种高效且可解释的前端处理解决方案，其学习的注意力权重与CSI的物理稀疏特性一致，验证了其可解释性。

Abstract: Wi-Fi gesture recognition based on Channel State Information (CSI) is challenged by high-dimensional noise and resource constraints on edge devices. Prevailing end-to-end models tightly couple feature extraction with classification, overlooking the inherent time-frequency sparsity of CSI and leading to redundancy and poor generalization. To address this, this paper proposes a lightweight feature preprocessing module--the Variational Dual-path Attention Network (VDAN). It performs structured feature refinement through frequency-domain filtering and temporal detection. Variational inference is introduced to model the uncertainty in attention weights, thereby enhancing robustness to noise. The design principles of the module are explained from the perspectives of the information bottleneck and regularization. Experiments on a public dataset demonstrate that the learned attention weights align with the physical sparse characteristics of CSI, verifying its interpretability. This work provides an efficient and explainable front-end processing solution for resource-constrained wireless sensing systems.

</details>


### [285] [Interoperable rApp/xApp Control over O-RAN for Mobility-aware Dynamic Spectrum Allocation](https://arxiv.org/abs/2601.13769)
*Anastasios Giannopoulos,Sotirios Spantideas,Maria Lamprini Bartsioka,Panagiotis Trakadas*

Main category: cs.NI

TL;DR: 论文提出了一种基于图论的O-RAN互操作rApp/xApp驱动动态频谱分配框架，通过非实时和近实时RIC协同优化，显著提升了PRB分配成功率和公平性。


<details>
  <summary>Details</summary>
Motivation: 解决在密集多小区干扰和异构服务需求下，设计能够同时利用长期流量感知和近实时无线资源优化的互操作控制方案的挑战性问题。

Method: 基于图论的物理资源块（PRB）分配方法，结合非实时RIC rApp进行流量预测和频谱策略生成，以及近实时RIC xApp构建用户中心冲突图并进行公平感知的PRB分配。

Result: 仿真结果表明，该框架在不同信道配置和用户需求下显著提高了PRB分配的成功率和服务共享公平性。

Conclusion: 该论文提出的框架显著提高了PRB分配的成功率（超过90%）和服务共享公平性（超过85%），同时保持了O-RAN原则下的架构分离和rApp/xApp互操作性。

Abstract: Open Radio Access Networks (O-RAN) enable the disaggregation of radio access functions and the deployment of control applications across different timescales. However, designing interoperable control schemes that jointly exploit long-term traffic awareness and near-real-time radio resource optimization remains a challenging problem, particularly under dense multi-cell interference and heterogeneous service demands. This paper proposes an interoperable rApp/xApp-driven dynamic spectrum allocation (DSA) framework for O-RAN, based on a graph-theoretic formulation of physical resource block (PRB) assignment. The proposed architecture leverages a non-real-time radio intelligent controller (Non-RT RIC) rApp to predict aggregated traffic evolution and generate high-level spectrum policies at the minutes timescale, while a near-real-time RIC (Near-RT RIC) xApp constructs a user-centric conflict graph and performs fairness-aware PRB allocation at sub-second timescales. To mitigate persistent user starvation, a conflict-aware modified proportional fair (MPF) scheduling mechanism is applied, enabling controlled interference-free PRB time-sharing. Extensive simulation results demonstrate that the proposed framework significantly improves the PRB assignment success rate (above 90%) and service-share fairness (above 85%) across different channel configurations and user demands, while maintaining architectural separation and rApp/xApp interoperability in accordance with O-RAN principles.

</details>


### [286] [Demystifying Starlink Network Performance under Vehicular Mobility with Dynamic Beam Switching](https://arxiv.org/abs/2601.13790)
*Jinwei Zhao,Jack Baude,Ali Ahangarpour,Vaibhava Krishna Devulapalli,Sree Ganesh Lalitaditya Divakarla,Zhi-Li Zhang,Jianping Pan*

Main category: cs.NI

TL;DR: 本文研究了移动环境下Starlink网络性能下降的原因，提出动态波束切换感知的卫星识别方法，为提升网络性能提供新视角。


<details>
  <summary>Details</summary>
Motivation: 现有Starlink卫星识别方法仅适用于静止、无障碍场景，无法应对用户终端移动、障碍物或动态波束切换事件，导致移动环境下网络性能下降的原因尚未被充分研究。

Method: 提出了一种移动感知的Starlink卫星识别方法，结合用户终端诊断数据和连接的卫星信息，检测动态波束切换事件。

Result: 研究发现用户终端在链路质量下降时会尝试多次动态波束切换以连接不同卫星，揭示了移动环境下性能下降的机制。

Conclusion: 本文揭示了移动环境下Starlink网络性能下降的原因，并提出了一种动态波束切换感知的卫星识别方法，为提升端到端性能和多样化应用场景提供了关键见解。

Abstract: In the last few years, considerable research efforts have focused on measuring and improving Starlink network performance, especially for user terminals (UTs) in stationary scenarios. However, the performance of Starlink networks in mobility settings, particularly with frequent changes in the UT's orientation, and the impact of environmental factors, such as transient obstructions, has not been thoroughly studied, leaving gaps in understanding the causes of performance degradation. Recently, researchers have started identifying the communicating satellites to evaluate satellite selection strategies and the impact on network performance. However, existing Starlink satellite identification methods only work in stationary, obstruction-free scenarios, as they do not account for UT mobility, obstructions or detect dynamic beam switching events. In this paper, we reveal that the UT can perform multiple dynamic beam switching attempts to connect to different satellites when the UT-satellite link is degraded. This degradation can occur either due to the loss of line-of-sight (LoS) from changes in the FOV or obstructions, or due to poor signal quality, extending UT-satellite handovers beyond the well-known 15-second regular handover interval. We propose a mobility-aware Starlink satellite identification method that detects dynamic beam switching events, and plausibly explain network performance using UT's diagnostic data and connected satellite information. Our findings demystifies the mobile Starlink network performance degradations, which is crucial to enhance the end-to-end performance of transport layer protocols and in diverse application scenarios.

</details>


### [287] [A Predictive and Preventive Digital Twin Framework for Indoor Wireless Networks](https://arxiv.org/abs/2601.13838)
*Jiunn-Tsair Chen*

Main category: cs.NI

TL;DR: 论文提出数字孪生框架预测Wi-Fi网络性能问题，通过梯度搜索优化配置，仿真验证其有效性。


<details>
  <summary>Details</summary>
Motivation: Wi-Fi网络因竞争性信道访问、密集部署和自管理操作导致的性能下降问题日益严重，需要一种预测性和预防性的管理方法。

Method: 论文提出了一个数字孪生（DT）框架，捕捉无线信道和流量模式的时空特征，并结合香农容量和CSMA-CA延迟行为的性能上限进行高效评估。

Result: 仿真结果表明，该方法能成功预测时间相关的网络拥塞并提前缓解，展示了其在预测性和预防性Wi-Fi网络管理中的潜力。

Conclusion: 该论文提出的数字孪生框架能够有效预测Wi-Fi网络的未来性能问题，并通过梯度搜索优化网络配置，提前避免性能下降。

Abstract: Wi-Fi networks increasingly suffer from performance degradation caused by contention-based channel access, dense deployments, and largely self-managed operation among mutually interfering access points (APs). In this paper, we propose a Digital Twin (DT) framework that captures the essential spatial and temporal characteristics of wireless channels and traffic patterns, enabling the prediction of likely future network scenarios while respecting physical constraints. Leveraging this predictive capability, we introduce two analytically derived performance upper bounds-one based on Shannon capacity and the other on latency behavior under CSMA-CA (Carrier Sense Multiple Access with Collision Avoidance)-that can be evaluated efficiently without time-consuming network simulations. By applying importance sampling to DT-generated scenarios, potentially risky network conditions can be identified within large stochastic scenario spaces. These same performance bounds are then used to proactively guide a gradient-based search for improved network configurations, with the objective of avoiding imminent performance degradation rather than pursuing globally optimal but fragile solutions. Simulation results demonstrate that the proposed approach can successfully predict time-dependent network congestion and mitigate it in advance, highlighting its potential for predictive and preventive Wi-Fi network management.

</details>


### [288] [Capacity and Energy Trade-Offs in FR3 6G Networks Using Real Deployment Data](https://arxiv.org/abs/2601.13993)
*David López-Pérez,Nicola Piovesan,Matteo Bernabè*

Main category: cs.NI

TL;DR: 基于真实数据，6G在非共址部署中表现更优，吞吐量提升显著但能耗增加，需战略规划。


<details>
  <summary>Details</summary>
Motivation: 通过实际数据评估6G策略，而非依赖3GPP模板，以更贴近现实的方式分析6G网络的性能。

Method: 利用Giulia模型，基于中国商用4G/5G网络的真实部署和流量数据，进行系统级异构网络分析。

Result: 6G可将中位数吞吐量提升至4G+5G异构部署的9.5倍，但能耗增加59%；共址部署增益有限且能耗高。

Conclusion: 6G网络在非共址、流量感知部署中能实现更高的吞吐量与能耗效率，强调了基于用户设备热点的战略规划的重要性。

Abstract: This article presents a data-driven system-level analysis of multi-layer 6G networks operating in the upper mid-band (FR3: 7-24 GHz). Unlike most prior studies based on 3rd Generation Partnership Project (3GPP) templates, we leverage real-world deployment and traffic data from a commercial 4G/5G network in China to evaluate practical 6G strategies. Using Giulia-a deployment-informed system-level heterogeneous network model-we show that 6G can boost median throughput by up to 9.5x over heterogeneous 4G+5G deployments, but also increases power usage by up to 59%. Critically, co-locating 6G with existing sites delivers limited gains while incurring high energy cost. In contrast, non-co-located, traffic-aware deployments achieve superior throughput-to-watt efficiency, highlighting the need for strategic, user equipment (UE) hotspot-focused 6G planning.

</details>


### [289] [MANATEE: A DevOps Platform for xApp Lifecycle Management and Testing in Open RAN](https://arxiv.org/abs/2601.14009)
*Sofia Montebugnoli,Leonardo Bonati,Andrea Sabbioni,Luca Foschini,Paolo Bellavista,Salvatore D'Oro,Michele Polese,Tommaso Melodia*

Main category: cs.NI

TL;DR: MANATEE平台利用DevOps和服务网格技术优化xApp生命周期管理，实验显示低延迟且可靠的部署效果。


<details>
  <summary>Details</summary>
Motivation: Open RAN生态缺乏对xApp生命周期的自动化管理和测试能力，导致部署缓慢且易出错。

Method: 提出MANATEE平台，集成CI/CD流水线和服务网格技术（如金丝雀发布和A/B测试），并在Kubernetes集群上原型化，结合O-RAN软件社区的近实时RIC进行测试。

Result: 实验证明，服务网格集成仅引入低于1毫秒的延迟，同时支持细粒度流量控制和冲突无关的A/B测试。

Conclusion: MANATEE平台通过结合DevOps实践和服务网格技术，显著简化了xApp的生产部署流程，提升了异构O-RAN环境中的性能和可靠性。

Abstract: The shift to disaggregated 5G architectures introduces unprecedented flexibility but also significant complexity in Beyond 5G Radio Access Networks (RANs). Open RAN enables programmability through xApps, yet deploying and validating these applications is critical given the nature of the systems they aim to control. Current Open RAN ecosystems lack robust lifecycle management of xApps that enable automated testing, seamless migration, and production-grade observability, resulting in slow, error-prone xApp delivery. To address these issues, DevOps practices can streamline the xApp lifecycle by integrating Continuous Integration/Continuous Deployment (CI/CD) pipelines with advanced traffic management and monitoring, such as leveraging service mesh technologies to enable progressive deployment strategies (e.g., canary releases and A/B testing) to ensure fine-grained observability and resilience. The solution presented in this article, MANATEE (Mesh Architecture for Radio Access Network Automation and TEsting Ecosystems), is the first platform that combines these principles to simplify xApp delivery into production, accelerate innovation, and guarantee performance across heterogeneous O-RAN environments. We prototyped MANATEE on a Kubernetes cluster integrated with the O-RAN Software Community Near-Real Time RAN Intelligent Controller (RIC), as well as with service mesh technologies, to facilitate testing of xApps across simulated, emulated, and real testbed environments. Our experimental results demonstrate that service mesh integration introduces minimal overhead (below 1 ms latency), while enabling reliable canary deployments with fine-grained traffic control and conflict-free A/B testing through circuit-breaking mechanisms.

</details>


### [290] [Communication Technologies for Intelligent Transportation Systems: From Railways to UAVs and Beyond](https://arxiv.org/abs/2601.14106)
*Shrief Rizkalla,Adrian Kliks,Nila Bagheri,Miguel A. Bellido-Manganell,Aniruddha Chandra,Anja Dakic,Laura Finarelli,Davy Gaillot,Matti Hamalainen,Ruisi He,Markus Hofer,Sandaruwan Jayaweera,Francesco Linsalata,Konstantin Mikhaylov,Jon M. Peha,Ibrahim Rashdan,Gianluca Rizzo,Abdul Saboor,Martin Schmidhammer,Michal Sybis,Fredrik Tufvesson,Paul Unterhuber,Fernando J. Velez,Evgenii Vinogradov,Michael Walter,Thomas Zemen,Haibin Zhang,Zhengyu Zhang*

Main category: cs.NI

TL;DR: 白皮书分析了现代和未来ICT支持的通信技术现状，旨在通过新兴技术和统一框架提升交通系统的互操作性和可靠性，并促进多方合作。


<details>
  <summary>Details</summary>
Motivation: 建立对通信解决方案如何支持多交通领域（如铁路、公路车辆、飞机和无人机）自动化、安全性和效率的共同理解，并推动通信建模、测试和标准化的统一框架。

Method: 通过分析当前系统的局限性，并提出整合新兴技术（如5G、6G和AI驱动的网络控制）的路径，以及探索可重构智能表面、集成感知与通信及数字孪生概念在ITS中的应用。

Result: 强调了准确信道建模和实证验证的重要性，以及频谱管理和标准化工作在确保多样化通信系统互操作性中的作用。

Conclusion: 该白皮书旨在促进学术界、工业界和标准化机构之间的合作，以设计未来交通系统的弹性和自适应通信基础设施。

Abstract: This white paper aims to comprehensively analyze and consolidate the state of the art in communication technologies supporting modern and future Information and Communication Technology (ICT). Its primary objective is to establish a common understanding of how communication solutions enable automation, safety, and efficiency across multiple transport domains, including railways, road vehicles, aircraft, and unmanned aerial vehicles. The document seeks to identify key communication requirements and technological enablers necessary for interoperable and reliable ITS operation. It also assesses the limitations of current systems and proposes pathways for integrating emerging technologies such as 5G, Sixth Generation (6G), and Artificial Intelligence (AI)-driven network control. The white paper also intends to support harmonization between different transport modes through a unified framework for communication modeling, testing, and standardization. It highlights the importance of accurate channel modeling and empirical validation to design efficient, robust, and scalable systems. Another objective is to explore the use of reconfigurable intelligent surfaces, integrated sensing and communication, and digital twin concepts within ITS. The document emphasizes the role of spectrum management and standardization efforts in ensuring interoperability among diverse communication systems. Finally, the paper seeks to stimulate collaboration among academia, industry, and standardization bodies to advance the design of resilient and adaptive communication infrastructures for future transportation systems.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [291] [RobotDesignGPT: Automated Robot Design Synthesis using Vision Language Models](https://arxiv.org/abs/2601.11801)
*Nitish Sontakke,K. Niranjan Kumar,Sehoon Ha*

Main category: cs.RO

TL;DR: RobotDesignGPT 利用视觉语言模型自动化机器人设计，减少人工干预，生成高质量设计。


<details>
  <summary>Details</summary>
Motivation: 当前机器人设计过程依赖领域专业知识和大量人工，且多数方法基于规则，限制了设计的灵活性和创新性。

Method: 利用预训练的视觉语言模型，结合用户简单提示和参考图像，自动合成机器人设计，并通过视觉反馈机制优化设计质量。

Result: 框架能够设计出受自然启发的、视觉吸引且运动学有效的机器人，并通过消融研究和用户研究验证了其有效性。

Conclusion: RobotDesignGPT 框架通过结合大型预训练视觉语言模型，实现了机器人设计的自动化，显著减少了人工干预，并能生成视觉吸引且运动学有效的设计。

Abstract: Robot design is a nontrivial process that involves careful consideration of multiple criteria, including user specifications, kinematic structures, and visual appearance. Therefore, the design process often relies heavily on domain expertise and significant human effort. The majority of current methods are rule-based, requiring the specification of a grammar or a set of primitive components and modules that can be composed to create a design. We propose a novel automated robot design framework, RobotDesignGPT, that leverages the general knowledge and reasoning capabilities of large pre-trained vision-language models to automate the robot design synthesis process. Our framework synthesizes an initial robot design from a simple user prompt and a reference image. Our novel visual feedback approach allows us to greatly improve the design quality and reduce unnecessary manual feedback. We demonstrate that our framework can design visually appealing and kinematically valid robots inspired by nature, ranging from legged animals to flying creatures. We justify the proposed framework by conducting an ablation study and a user study.

</details>


### [292] [Optimal Thruster Configuration for 6-DOF Control of a Small Satellite](https://arxiv.org/abs/2601.11802)
*Suguru Sato,Jinaykumar Patel,Kamesh Subbarao*

Main category: cs.RO

TL;DR: 论文研究了小型卫星在低地球轨道的推进器配置优化，提出了一组可实现全六自由度控制的配置，并通过任务验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 随着小型卫星在低地球轨道的广泛应用，轨道维持和姿态控制的需求日益增长，研究如何优化推进器配置以提高效率和机动性。

Method: 从24推进器配置出发，提出了一组可实现全六自由度控制的可行推进器配置组，并从中筛选出需要最小总推力的配置组。

Result: 研究发现，通过优化配置组，即使推进器数量减少，仍能实现足够的机动性，并通过典型的交会对接任务验证了其姿态控制性能。

Conclusion: 论文展示了通过优化推进器配置，即使减少推进器数量，也能实现足够的机动性，满足低地球轨道小型卫星的轨道维持和姿态控制需求。

Abstract: With the growing deployment of small satellites (such as CubeSats, Nanosats, Picosats, and Femtosats) in Low Earth Orbit (LEO) for targeted applications like imaging, communication, data storage, and rendezvous-docking mission, there is increasing attention on orbit maintenance and attitude control. A common approach for active orbit control involves the use of multiple thrusters, which, when properly arranged, can also generate the required torque for attitude control. Starting from a 24-thruster configuration, this paper presents a set of thruster configurations (referred to as a viable configuration group) that enable full six degrees of freedom (6-DOF) control. Further, configuration group that requires minimum total thrust to achieve 6-DOF commands are found among the viable configuration group. One configuration from each of these groups is further evaluated for its attitude control performance through a representative rendezvous-docking mission, demonstrating that even with a reduced thruster count, sufficient maneuverability can be achieved.

</details>


### [293] [Three Dimensional Hydrodynamic Flow-Based Collision Avoidance for UAV Formations Facing Emergent Dynamic Obstacles](https://arxiv.org/abs/2601.11832)
*Suguru Sato,Kamesh Subbarao*

Main category: cs.RO

TL;DR: A fluid dynamics-inspired 3D collision avoidance method for UAV formations, using velocity fields from obstacle models and VRB strategy, proven effective in simulations.


<details>
  <summary>Details</summary>
Motivation: To address the challenges of real-time, collision-free UAV navigation in dynamic environments without trajectory discontinuities or replanning, inspired by fluid dynamics for smooth and interpretable behavior.

Method: The framework models moving obstacles as 3D doublets or ellipsoids generating local velocity fields, leveraging Laplace's equation for fluid flow properties. It integrates a Virtual Rigid Body (VRB) formation strategy for coordination.

Result: Simulation results confirm the method's feasibility and scalability for individual and multi-UAV scenarios, achieving safe, smooth, and computationally efficient avoidance maneuvers.

Conclusion: The proposed three-dimensional, hydrodynamics-inspired collision avoidance framework successfully enables UAV formations to perform smooth, collision-free maneuvers in dynamic environments, maintaining formation geometry and trajectory tracking efficiently.

Abstract: This paper presents a three-dimensional, hydrodynamics-inspired collision avoidance framework for uncrewed aerial vehicle (UAV) formations operating in dynamic environments. When moving obstacles enter a UAV's sensing region, they are modeled as three dimensional doublets or ellipsoids that generate local velocity fields, guiding nearby UAVs to execute smooth, collision-free maneuvers without trajectory discontinuities or explicit trajectory replanning. This flow-based approach enables real-time operation and interpretable behavior by leveraging the nature of fluid flow around obstacles via the harmonic properties of Laplace's equation, inherently avoiding local minima common in traditional potential field methods. To establish and maintain coordination among the UAVs, a Virtual Rigid Body (VRB) formation strategy is integrated, ensuring that formation geometry and trajectory tracking are preserved. Simulation results demonstrate the feasibility and scalability of the method for both individual and multi-UAV scenarios with multiple formation geometries encountering moving obstacles. The proposed approach achieves safe, smooth, and computationally efficient avoidance maneuvers suitable for real-time and practical applications.

</details>


### [294] [AI for Green Spaces: Leveraging Autonomous Navigation and Computer Vision for Park Litter Removal](https://arxiv.org/abs/2601.11876)
*Christopher Kao,Akhil Pathapati,James Davis*

Main category: cs.RO

TL;DR: 提出自主导航、识别和拾取草地垃圾的机器人，使用STC算法、RTK GPS和ResNet50 CNN，总体成功率80%。


<details>
  <summary>Details</summary>
Motivation: 解决美国50亿件垃圾问题，尤其是草地上野餐者遗留的垃圾。

Method: 使用Spanning Tree Coverage (STC)算法生成覆盖路径，Real-Time Kinematic (RTK) GPS进行厘米级导航，ResNet50卷积神经网络(CNN)进行垃圾检测（准确率94.52%），并设计了针对草地垃圾的拾取机制。

Result: 机器人总体成功率为80%，证明自主捡垃圾机器人在草地上的可行性。

Conclusion: 自主捡垃圾机器人在草地上是可行的解决方案，总体成功率达到80%。

Abstract: There are 50 billion pieces of litter in the U.S. alone. Grass fields contribute to this problem because picnickers tend to leave trash on the field. We propose building a robot that can autonomously navigate, identify, and pick up trash in parks. To autonomously navigate the park, we used a Spanning Tree Coverage (STC) algorithm to generate a coverage path the robot could follow. To navigate this path, we successfully used Real-Time Kinematic (RTK) GPS, which provides a centimeter-level reading every second. For computer vision, we utilized the ResNet50 Convolutional Neural Network (CNN), which detects trash with 94.52% accuracy. For trash pickup, we tested multiple design concepts. We select a new pickup mechanism that specifically targets the trash we encounter on the field. Our solution achieved an overall success rate of 80%, demonstrating that autonomous trash pickup robots on grass fields are a viable solution.

</details>


### [295] [Visual-Language-Guided Task Planning for Horticultural Robots](https://arxiv.org/abs/2601.11906)
*Jose Cuaran,Kendall Koe,Aditya Potnis,Naveen Kumar Uppalapati,Girish Chowdhary*

Main category: cs.RO

TL;DR: 研究提出基于VLM的模块化框架用于农业机器人任务，短时任务表现良好，但长时任务和噪声环境下存在局限。


<details>
  <summary>Details</summary>
Motivation: 当前作物监测系统缺乏高级推理能力，需要一种更智能的解决方案来提升精准农业的效率。

Method: 提出了一种模块化框架，结合视觉语言模型（VLM）和机器人任务规划，通过交替输入查询与动作原语实现作物监测。

Result: VLM在短时任务中表现稳健（接近人类水平），但在挑战性长时任务中性能显著下降，尤其是在依赖噪声语义地图时系统会失败。

Conclusion: 该研究提供了一个可部署的框架，并深入分析了视觉语言模型（VLM）在复杂农业机器人任务中的能力与局限。

Abstract: Crop monitoring is essential for precision agriculture, but current systems lack high-level reasoning. We introduce a novel, modular framework that uses a Visual Language Model (VLM) to guide robotic task planning, interleaving input queries with action primitives. We contribute a comprehensive benchmark for short- and long-horizon crop monitoring tasks in monoculture and polyculture environments. Our main results show that VLMs perform robustly for short-horizon tasks (comparable to human success), but exhibit significant performance degradation in challenging long-horizon tasks. Critically, the system fails when relying on noisy semantic maps, demonstrating a key limitation in current VLM context grounding for sustained robotic operations. This work offers a deployable framework and critical insights into VLM capabilities and shortcomings for complex agricultural robotics.

</details>


### [296] [Model selection and real-time skill assessment for suturing in robotic surgery](https://arxiv.org/abs/2601.12012)
*Zhaoyang Jacopo Hu,Alex Ranne,Alaa Eldin Abdelaal,Kiran Bhattacharyya,Etienne Burdet,Allison M. Okamura,Ferdinando Rodriguez y Baena*

Main category: cs.RO

TL;DR: 本研究通过多模态深度学习模型实时预测手术技能水平，发现融合模型表现最佳，且高技能训练数据有助于模型泛化。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过自动化反馈系统实现基于OSATS分数的实时手术技能水平预测，以提供客观的技能评估。

Method: 评估了多模态深度学习模型的有效性，包括单模态基线模型和融合架构，使用平均Spearman相关系数进行性能评估。

Result: 融合模型在实时预测中始终优于单模态模型，高技能演示数据训练的模型表现更好且能更好地泛化到类似技能水平的参与者。

Conclusion: 多模态学习能够更稳定地进行手术表现的细粒度评估，并突显了专家级训练数据对模型泛化的重要性。

Abstract: Automated feedback systems have the potential to provide objective skill assessment for training and evaluation in robot-assisted surgery. In this study, we examine methods to achieve real-time prediction of surgical skill level in real-time based on Objective Structured Assessment of Technical Skills (OSATS) scores. Using data acquired from the da Vinci Surgical System, we carry out three main analyses, focusing on model design, their real-time performance, and their skill-level-based cross-validation training. For the model design, we evaluate the effectiveness of multimodal deep learning models for predicting surgical skill levels using synchronized kinematic and vision data. Our models include separate unimodal baselines and fusion architectures that integrate features from both modalities and are evaluated using mean Spearman's correlation coefficients, demonstrating that the fusion model consistently outperforms unimodal models for real-time predictions. For the real-time performance, we observe the prediction's trend over time and highlight correlation with the surgeon's gestures. For the skill-level-based cross-validation, we separately trained models on surgeons with different skill levels, which showed that high-skill demonstrations allow for better performance than those trained on low-skilled ones and generalize well to similarly skilled participants. Our findings show that multimodal learning allows more stable fine-grained evaluation of surgical performance and highlights the value of expert-level training data for model generalization.

</details>


### [297] [BiKC+: Bimanual Hierarchical Imitation with Keypose-Conditioned Coordination-Aware Consistency Policies](https://arxiv.org/abs/2601.12116)
*Hang Xu,Yizhou Chen,Dongjie Yu,Yi Ren,Jia PanI*

Main category: cs.RO

TL;DR: 本文提出一种关键姿势协调感知一致性策略，通过分层模仿学习和一致性模型提升双臂操作效率，实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 双臂操作在工业制造中面临协调和效率挑战，现有方法未能充分考虑多阶段任务特性及推理速度的重要性。

Method: 采用分层模仿学习方法，包括高层关键姿势预测器和低层轨迹生成器。轨迹生成器作为一致性模型，基于历史观察和预测的关键姿势在单次推理步骤中生成动作序列。

Result: 仿真和实际实验表明，该方法在成功率和操作效率上显著优于基线方法。

Conclusion: 本文提出的基于关键姿势协调感知一致性策略的双臂操作框架，通过分层模仿学习和一致性模型，显著提高了任务成功率和操作效率。

Abstract: Robots are essential in industrial manufacturing due to their reliability and efficiency. They excel in performing simple and repetitive unimanual tasks but still face challenges with bimanual manipulation. This difficulty arises from the complexities of coordinating dual arms and handling multi-stage processes. Recent integration of generative models into imitation learning (IL) has made progress in tackling specific challenges. However, few approaches explicitly consider the multi-stage nature of bimanual tasks while also emphasizing the importance of inference speed. In multi-stage tasks, failures or delays at any stage can cascade over time, impacting the success and efficiency of subsequent sub-stages and ultimately hindering overall task performance. In this paper, we propose a novel keypose-conditioned coordination-aware consistency policy tailored for bimanual manipulation. Our framework instantiates hierarchical imitation learning with a high-level keypose predictor and a low-level trajectory generator. The predicted keyposes serve as sub-goals for trajectory generation, indicating targets for individual sub-stages. The trajectory generator is formulated as a consistency model, generating action sequences based on historical observations and predicted keyposes in a single inference step. In particular, we devise an innovative approach for identifying bimanual keyposes, considering both robot-centric action features and task-centric operation styles. Simulation and real-world experiments illustrate that our approach significantly outperforms baseline methods in terms of success rates and operational efficiency. Implementation codes can be found at https://github.com/JoanaHXU/BiKC-plus.

</details>


### [298] [Active Semantic Mapping of Horticultural Environments Using Gaussian Splatting](https://arxiv.org/abs/2601.12122)
*Jose Cuaran,Naveen K. Upalapati,Girish Chowdhary*

Main category: cs.RO

TL;DR: 提出移动机械臂驱动的主动3D重建框架，结合Octomap与3D高斯泼溅技术，显著提升农业场景语义重建的精度与效率，尤其在果实计数和体积估计中表现突出。


<details>
  <summary>Details</summary>
Motivation: 传统依赖手动扫描或固定相机的方法在农业场景语义重建中存在效率瓶颈，亟需一种高效且精准的自动化解决方案。

Method: 系统整合了低分辨率Octomap（提供概率占用信息以支持视角选择和避障规划）与3D高斯泼溅（利用几何、光度和语义信息优化3D高斯分布以实现高保真重建），并引入了抗分割噪声和降低内存消耗的策略。

Result: 仿真实验表明，该方法在运行效率和重建精度上均优于纯占用方法：无噪声条件下果实级F1分数提升6.6%，分割噪声下最高提升28.6%，且运行时间减少50%。

Conclusion: 本文提出的基于移动机械臂的主动3D重建框架，通过结合Octomap和3D高斯泼溅技术，显著提升了农业场景语义重建的精度和效率，尤其在果实计数和体积估计任务中表现优异。

Abstract: Semantic reconstruction of agricultural scenes plays a vital role in tasks such as phenotyping and yield estimation. However, traditional approaches that rely on manual scanning or fixed camera setups remain a major bottleneck in this process. In this work, we propose an active 3D reconstruction framework for horticultural environments using a mobile manipulator. The proposed system integrates the classical Octomap representation with 3D Gaussian Splatting to enable accurate and efficient target-aware mapping. While a low-resolution Octomap provides probabilistic occupancy information for informative viewpoint selection and collision-free planning, 3D Gaussian Splatting leverages geometric, photometric, and semantic information to optimize a set of 3D Gaussians for high-fidelity scene reconstruction. We further introduce simple yet effective strategies to enhance robustness against segmentation noise and reduce memory consumption. Simulation experiments demonstrate that our method outperforms purely occupancy-based approaches in both runtime efficiency and reconstruction accuracy, enabling precise fruit counting and volume estimation. Compared to a 0.01m-resolution Octomap, our approach achieves an improvement of 6.6% in fruit-level F1 score under noise-free conditions, and up to 28.6% under segmentation noise. Additionally, it achieves a 50% reduction in runtime, highlighting its potential for scalable, real-time semantic reconstruction in agricultural robotics.

</details>


### [299] [Neural Process-Based Reactive Controller for Autonomous Racing](https://arxiv.org/abs/2601.12143)
*Devin Hunter,Chinwendu Enyioha*

Main category: cs.RO

TL;DR: 本文提出了一种基于AttNP和PI-AttNP的实时控制框架，通过CBF确保安全性，并在模拟赛车环境中验证了其高效性。


<details>
  <summary>Details</summary>
Motivation: 随着数据驱动模型在安全关键领域的应用增加，需要确保其决策的统计基础和可证明安全性。

Method: 采用Attentive Neural Process（AttNP）及其物理信息扩展PI-AttNP，结合控制屏障函数（CBF）实现安全过滤。

Result: PI-AttNP通过物理先验加速收敛并提升预测精度，CBF机制确保了广泛的碰撞避免约束。

Conclusion: 本文提出了一种结合注意力神经过程（AttNP）和物理信息扩展（PI-AttNP）的实时非线性控制框架，通过控制屏障函数（CBF）确保安全性，并在模拟环境中验证了其高效性和安全性。

Abstract: Attention-based neural architectures have become central to state-of-the-art methods in real-time nonlinear control. As these data-driven models continue to be integrated into increasingly safety-critical domains, ensuring statistically grounded and provably safe decision-making becomes essential. This paper introduces a novel reactive control framework for gap-based navigation using the Attentive Neural Process (AttNP) and a physics-informed extension, the PI-AttNP. Both models are evaluated in a simulated F1TENTH-style Ackermann steering racecar environment, chosen as a fast-paced proxy for safety-critical autonomous driving scenarios. The PI-AttNP augments the AttNP architecture with approximate model-based priors to inject physical inductive bias, enabling faster convergence and improved prediction accuracy suited for real-time control. To further ensure safety, we derive and implement a control barrier function (CBF)-based filtering mechanism that analytically enforces collision avoidance constraints. This CBF formulation is fully compatible with the learned AttNP controller and generalizes across a wide range of racing scenarios, providing a lightweight and certifiable safety layer. Our results demonstrate competitive closed-loop performance while ensuring real-time constraint satisfaction.

</details>


### [300] [Learning Legged MPC with Smooth Neural Surrogates](https://arxiv.org/abs/2601.12169)
*Samuel A. Moore,Easop Lee,Boyuan Chen*

Main category: cs.RO

TL;DR: 通过平滑神经代理模型和鲁棒学习，解决了学习型腿部MPC的刚性过渡和非高斯误差问题，显著提升了复杂任务中的性能和可靠性。


<details>
  <summary>Details</summary>
Motivation: 解决将学习模型与在线规划结合时的三个关键挑战：（1）接触事件中的刚性过渡，（2）非物理局部非光滑性，（3）训练数据导致的非高斯模型误差。

Method: 引入平滑神经代理模型（一种具有可调平滑性的神经网络）以处理接触事件中的刚性过渡和非物理局部非光滑性，并使用重尾似然函数训练模型以更好地匹配腿部机器人动力学中的经验误差分布。

Result: 在零样本运动任务中，平滑神经代理模型在简单行为上降低10-50%的累积成本，在标准神经动力学常失败的复杂任务中实现可靠执行（成功率从0/5提升至5/5）并降低2-50倍的累积成本。

Conclusion: 平滑神经代理模型与鲁棒学习方法显著提升了学习型腿部模型预测控制的可靠性、可扩展性和泛化能力，在复杂任务中实现了从完全失败到可靠执行的转变，并带来了数量级的性能提升。

Abstract: Deep learning and model predictive control (MPC) can play complementary roles in legged robotics. However, integrating learned models with online planning remains challenging. When dynamics are learned with neural networks, three key difficulties arise: (1) stiff transitions from contact events may be inherited from the data; (2) additional non-physical local nonsmoothness can occur; and (3) training datasets can induce non-Gaussian model errors due to rapid state changes. We address (1) and (2) by introducing the smooth neural surrogate, a neural network with tunable smoothness designed to provide informative predictions and derivatives for trajectory optimization through contact. To address (3), we train these models using a heavy-tailed likelihood that better matches the empirical error distributions observed in legged-robot dynamics. Together, these design choices substantially improve the reliability, scalability, and generalizability of learned legged MPC. Across zero-shot locomotion tasks of increasing difficulty, smooth neural surrogates with robust learning yield consistent reductions in cumulative cost on simple, well-conditioned behaviors (typically 10-50%), while providing substantially larger gains in regimes where standard neural dynamics often fail outright. In these regimes, smoothing enables reliable execution (from 0/5 to 5/5 success) and produces about 2-50x lower cumulative cost, reflecting orders-of-magnitude absolute improvements in robustness rather than incremental performance gains.

</details>


### [301] [A Comprehensive Review of Bio-Inspired Approaches to Coordination, Communication, and System Architecture in Underwater Swarm Robotics](https://arxiv.org/abs/2601.12244)
*Shyalan Ramesh,Scott Mann,Alex Stumpf*

Main category: cs.RO

TL;DR: 该综述整合了水下群体机器人的生物启发算法、通信和系统设计，指出了实际部署的挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 海洋操作的复杂性增加，需要智能机器人系统支持海洋观测、探索和资源管理，而水下群体机器人通过集体协调扩展了单个自主平台的能力。

Method: 通过多维分类框架评估现有方法，包括通信依赖性、环境适应性、能源效率和群体可扩展性。

Result: 综述了生物启发的协调机制、通信策略和系统设计考虑，分析了海洋特定算法及其应用，并评估了通信约束和新兴解决方案。

Conclusion: 该综述整合了生物启发的协调算法、通信方式和系统设计方法，并指出了水下群体系统实际部署中的趋同趋势、关键挑战和未来研究方向。

Abstract: The increasing complexity of marine operations has intensified the need for intelligent robotic systems to support ocean observation, exploration, and resource management. Underwater swarm robotics offers a promising framework that extends the capabilities of individual autonomous platforms through collective coordination. Inspired by natural systems, such as fish schools and insect colonies, bio-inspired swarm approaches enable distributed decision-making, adaptability, and resilience under challenging marine conditions. Yet research in this field remains fragmented, with limited integration across algorithmic, communication, and hardware design perspectives. This review synthesises bio-inspired coordination mechanisms, communication strategies, and system design considerations for underwater swarm robotics. It examines key marine-specific algorithms, including the Artificial Fish Swarm Algorithm, Whale Optimisation Algorithm, Coral Reef Optimisation, and Marine Predators Algorithm, highlighting their applications in formation control, task allocation, and environmental interaction. The review also analyses communication constraints unique to the underwater domain and emerging acoustic, optical, and hybrid solutions that support cooperative operation. Additionally, it examines hardware and system design advances that enhance system efficiency and scalability. A multi-dimensional classification framework evaluates existing approaches across communication dependency, environmental adaptability, energy efficiency, and swarm scalability. Through this integrated analysis, the review unifies bio-inspired coordination algorithms, communication modalities, and system design approaches. It also identifies converging trends, key challenges, and future research directions for real-world deployment of underwater swarm systems.

</details>


### [302] [An Efficient and Multi-Modal Navigation System with One-Step World Model](https://arxiv.org/abs/2601.12277)
*Wangtian Shen,Ziyang Meng,Jinming Ma,Mingliang Zhou,Diyun Xiang*

Main category: cs.RO

TL;DR: 提出轻量级导航世界模型，通过一步生成和高效注意力机制降低延迟，结合优化规划框架，显著提升导航效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的导航策略在3D空间推理和对物理世界动态理解方面存在不足，且传统世界模型因计算延迟高而难以实时部署。

Method: 采用3D U-Net骨干网络和高效的时空注意力机制，构建轻量级导航世界模型，并结合基于锚点初始化的优化规划框架。

Result: 在仿真和真实环境中的闭环实验表明，该系统在效率和鲁棒性上优于现有基线方法。

Conclusion: 提出的轻量级导航世界模型通过一步生成范式和高效的时空注意力机制，显著降低了计算延迟，实现了高频控制，并在优化规划框架中展示了卓越的效率和鲁棒性。

Abstract: Navigation is a fundamental capability for mobile robots. While the current trend is to use learning-based approaches to replace traditional geometry-based methods, existing end-to-end learning-based policies often struggle with 3D spatial reasoning and lack a comprehensive understanding of physical world dynamics. Integrating world models-which predict future observations conditioned on given actions-with iterative optimization planning offers a promising solution due to their capacity for imagination and flexibility. However, current navigation world models, typically built on pure transformer architectures, often rely on multi-step diffusion processes and autoregressive frame-by-frame generation. These mechanisms result in prohibitive computational latency, rendering real-time deployment impossible. To address this bottleneck, we propose a lightweight navigation world model that adopts a one-step generation paradigm and a 3D U-Net backbone equipped with efficient spatial-temporal attention. This design drastically reduces inference latency, enabling high-frequency control while achieving superior predictive performance. We also integrate this model into an optimization-based planning framework utilizing anchor-based initialization to handle multi-modal goal navigation tasks. Extensive closed-loop experiments in both simulation and real-world environments demonstrate our system's superior efficiency and robustness compared to state-of-the-art baselines.

</details>


### [303] [OpenNavMap: Structure-Free Topometric Mapping via Large-Scale Collaborative Localization](https://arxiv.org/abs/2601.12291)
*Jianhao Jiao,Changkun Liu,Jingwen Yu,Boyi Liu,Qianyi Zhang,Yue Wang,Dimitrios Kanoulas*

Main category: cs.RO

TL;DR: OPENNAVMAP通过3D几何基础模型和优化方法，提升了视觉导航的准确性和实用性，适用于无特征环境和多会话数据。


<details>
  <summary>Details</summary>
Motivation: 解决传统基于结构的方法在高维护成本、无特征环境或显著视角变化下的局限性。

Method: 结合动态规划序列匹配、几何验证和置信度校准优化，实现鲁棒的从粗到精的子图对齐。

Result: 在Map-Free基准测试中，平均平移误差为0.62m；在多会话数据中保持全局一致性，绝对轨迹误差低于3m。

Conclusion: OPENNAVMAP 是一种轻量级、无结构的拓扑系统，利用3D几何基础模型进行按需重建，显著提升了大规模视觉导航的准确性和实用性。

Abstract: Scalable and maintainable map representations are fundamental to enabling large-scale visual navigation and facilitating the deployment of robots in real-world environments. While collaborative localization across multi-session mapping enhances efficiency, traditional structure-based methods struggle with high maintenance costs and fail in feature-less environments or under significant viewpoint changes typical of crowd-sourced data. To address this, we propose OPENNAVMAP, a lightweight, structure-free topometric system leveraging 3D geometric foundation models for on-demand reconstruction. Our method unifies dynamic programming-based sequence matching, geometric verification, and confidence-calibrated optimization to robust, coarse-to-fine submap alignment without requiring pre-built 3D models. Evaluations on the Map-Free benchmark demonstrate superior accuracy over structure-from-motion and regression baselines, achieving an average translation error of 0.62m. Furthermore, the system maintains global consistency across 15km of multi-session data with an absolute trajectory error below 3m for map merging. Finally, we validate practical utility through 12 successful autonomous image-goal navigation tasks on simulated and physical robots. Code and datasets will be publicly available in https://rpl-cs-ucl.github.io/OpenNavMap_page.

</details>


### [304] [From Shallow Waters to Mariana Trench: A Survey of Bio-inspired Underwater Soft Robots](https://arxiv.org/abs/2601.12353)
*Jie Wang,Peng Du,Yiyuan Zhang,Zhexin Xie,Cecilia Laschi*

Main category: cs.RO

TL;DR: 本文综述了水下仿生软体机器人的最新进展，分析了设计考虑因素，并探讨了从原理到应用的进展，提出了未来发展方向。


<details>
  <summary>Details</summary>
Motivation: 探索海洋环境在资源勘探和生态保护等领域具有重要意义。传统水下机器人面临极端水压和对生态系统的噪音与破坏问题，而仿生软体机器人通过模仿水生生物的特性来应对这些挑战。

Method: 回顾了水下仿生软体机器人的最新进展，并分析了设计时需考虑的不同功能、仿生灵感、环境压力、温度、光照和生物多样性等因素。

Result: 仿生软体机器人能够承受高水压、减少阻力、高效操作与感知，并以环保方式与环境互动，成为海洋探索的有前景领域。

Conclusion: 本文总结了水下仿生软体机器人的最新进展，分析了其设计考虑因素，并探讨了从仿生原理到实际应用的进展，提出了下一代水下软体机器人开发的潜在方向。

Abstract: Sample Exploring the ocean environment holds profound significance in areas such as resource exploration and ecological protection. Underwater robots struggle with extreme water pressure and often cause noise and damage to the underwater ecosystem, while bio-inspired soft robots draw inspiration from aquatic creatures to address these challenges. These bio-inspired approaches enable robots to withstand high water pressure, minimize drag, operate with efficient manipulation and sensing systems, and interact with the environment in an eco-friendly manner. Consequently, bio-inspired soft robots have emerged as a promising field for ocean exploration. This paper reviews recent advancements in underwater bio-inspired soft robots, analyses their design considerations when facing different desired functions, bio-inspirations, ambient pressure, temperature, light, and biodiversity , and finally explores the progression from bio-inspired principles to practical applications in the field and suggests potential directions for developing the next generation of underwater soft robots.

</details>


### [305] [R-VoxelMap: Accurate Voxel Mapping with Recursive Plane Fitting for Online LiDAR Odometry](https://arxiv.org/abs/2601.12377)
*Haobo Xi,Shiyong Zhang,Qianli Dong,Yunze Tong,Songyang Wu,Jing Yuan,Xuebo Zhang*

Main category: cs.RO

TL;DR: R-VoxelMap通过递归平面拟合和异常值处理，提升了LiDAR里程计的定位精度，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决传统体素地图方法因异常值导致的平面参数偏差、大平面过度分割及不同物理平面错误合并的问题。

Method: 采用基于随机样本一致性（RANSAC）的异常值检测与重用管道，结合点分布的有效性检查算法，递归处理异常点以避免平面参数偏差和错误合并。

Result: 在多样化的开源LiDAR(-惯性)SLAM数据集上，R-VoxelMap实现了比其他最先进方法更高的精度，同时保持了相当的效率和内存使用。

Conclusion: R-VoxelMap通过几何驱动的递归平面拟合策略，显著提高了在线LiDAR里程计的定位精度，并在多样化的开源LiDAR(-惯性)SLAM数据集上验证了其优越性。

Abstract: This paper proposes R-VoxelMap, a novel voxel mapping method that constructs accurate voxel maps using a geometry-driven recursive plane fitting strategy to enhance the localization accuracy of online LiDAR odometry. VoxelMap and its variants typically fit and check planes using all points in a voxel, which may lead to plane parameter deviation caused by outliers, over segmentation of large planes, and incorrect merging across different physical planes. To address these issues, R-VoxelMap utilizes a geometry-driven recursive construction strategy based on an outlier detect-and-reuse pipeline. Specifically, for each voxel, accurate planes are first fitted while separating outliers using random sample consensus (RANSAC). The remaining outliers are then propagated to deeper octree levels for recursive processing, ensuring a detailed representation of the environment. In addition, a point distribution-based validity check algorithm is devised to prevent erroneous plane merging. Extensive experiments on diverse open-source LiDAR(-inertial) simultaneous localization and mapping (SLAM) datasets validate that our method achieves higher accuracy than other state-of-the-art approaches, with comparable efficiency and memory usage. Code will be available on GitHub.

</details>


### [306] [VR$^2$: A Co-Located Dual-Headset Platform for Touch-Enabled Human-Robot Interaction Research](https://arxiv.org/abs/2601.12395)
*Chao Wang,Anna Belardinelli,Michael Gienger*

Main category: cs.RO

TL;DR: VR2VR是一个双VR头显平台，通过共享物理空间和虚拟化身，低成本、高效地研究触摸丰富的HRI，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有HRI研究方法成本高、耗时长，且VR原型常忽略物理接触或破坏身体与触感的紧密耦合，VR2VR旨在解决这些问题。

Method: 采用双VR头显平台，操作者和参与者共享物理空间但体验不同的虚拟化身，通过运动追踪和面部信号实时映射机器人行为，并利用逆运动学实现精确接触。

Result: VR2VR成功实现了机器人行为的精确映射和物理接触的保持，支持非语言通道的选择性启用，为HRI研究提供了高效工具。

Conclusion: VR2VR平台通过双VR头显设计，有效降低了研究触摸丰富人机交互（HRI）的成本和复杂性，同时保持了物理接触的真实性，为快速原型设计和严格评估提供了新途径。

Abstract: Touch-rich human-robot interaction (HRI) is difficult to study: building and programming physical robots is costly and slow, while VR-based robot prototypes often remove physical contact or break the tight coupling between an agent's body and the user's felt touch. We present VR2VR, a co-located dual VR-headset platform for HRI research in which a participant and a hidden operator share the same physical space while experiencing different virtual embodiments. The participant sees an expressive virtual robot that interacts face-to-face in a shared virtual environment. In real time, the robot's upper-body gestures, head and gaze behaviors, and facial expressions are mapped from the operator's tracked motion and face signals. Because the operator is physically co-present and calibrated into the same coordinate frame, the operator can also physically touch the participant, enabling the participant to perceive robot touch aligned with the robot's hands; finger and hand motion are mapped to the robot using inverse kinematics to support precise contact. Beyond faithful motion retargeting for limb teleoperation, our VR2VR system supports experimental control by retargeting or selectively enabling nonverbal channels (e.g., head only vs. head+eyes vs. head+eyes+facial expressions) while keeping physical interaction constant. We detail the system design, calibration workflow, and safety considerations, and demonstrate the platform through a touch-based Wizard-of-Oz HRI study, illustrating how VR2VR lowers barriers for rapidly prototyping and rigorously evaluating embodied, touch-centric robot behaviors.

</details>


### [307] [Learning Diverse Skills for Behavior Models with Mixture of Experts](https://arxiv.org/abs/2601.12397)
*Wangtian Shen,Jinming Ma,Mingliang Zhou,Ziyang Meng*

Main category: cs.RO

TL;DR: Di-BM通过专家混合模型解决多任务模仿学习中的干扰问题，提升性能和数据效率。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习模型在多任务设置中性能下降，因任务间干扰导致平均效应。

Method: 采用基于能量的模型表示专家特定的观察分布，并与相应的动作模型联合训练。

Result: Di-BM在多个真实机器人操作任务中显著优于现有基线，且在新任务上微调时表现出更高的数据效率和知识复用性。

Conclusion: Di-BM通过专家混合模型学习多样化技能，显著提升了多任务场景下的性能，并在新任务上展现出高效的数据利用和知识复用能力。

Abstract: Imitation learning has demonstrated strong performance in robotic manipulation by learning from large-scale human demonstrations. While existing models excel at single-task learning, it is observed in practical applications that their performance degrades in the multi-task setting, where interference across tasks leads to an averaging effect. To address this issue, we propose to learn diverse skills for behavior models with Mixture of Experts, referred to as Di-BM. Di-BM associates each expert with a distinct observation distribution, enabling experts to specialize in sub-regions of the observation space. Specifically, we employ energy-based models to represent expert-specific observation distributions and jointly train them alongside the corresponding action models. Our approach is plug-and-play and can be seamlessly integrated into standard imitation learning methods. Extensive experiments on multiple real-world robotic manipulation tasks demonstrate that Di-BM significantly outperforms state-of-the-art baselines. Moreover, fine-tuning the pretrained Di-BM on novel tasks exhibits superior data efficiency and the reusable of expert-learned knowledge. Code is available at https://github.com/robotnav-bot/Di-BM.

</details>


### [308] [ReWorld: Multi-Dimensional Reward Modeling for Embodied World Models](https://arxiv.org/abs/2601.12428)
*Baorui Peng,Wenyao Zhang,Liang Xu,Zekun Qi,Jiazhao Zhang,Hongsi Liu,Wenjun Zeng,Xin Jin*

Main category: cs.RO

TL;DR: ReWorld通过强化学习优化视频世界模型，提升物理真实性和任务逻辑，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前视频世界模型主要关注视觉生成质量，忽视了物理真实性、动态一致性和任务逻辑，特别是在接触丰富的操作任务中，限制了其在下游任务中的应用。

Method: 构建大规模视频偏好数据集（约235K），训练分层奖励模型以捕捉与人类偏好一致的多维奖励；提出一种实用的对齐算法，通过计算高效的PPO风格算法对基于流的世界模型进行后训练。

Result: ReWorld显著提高了生成rollouts的物理真实性、逻辑一致性、具身合理性和视觉质量。

Conclusion: ReWorld框架通过强化学习显著提升了视频世界模型在物理真实性、任务完成能力、具身合理性和视觉质量方面的表现，优于现有方法。

Abstract: Recently, video-based world models that learn to simulate the dynamics have gained increasing attention in robot learning. However, current approaches primarily emphasize visual generative quality while overlooking physical fidelity, dynamic consistency, and task logic, especially for contact-rich manipulation tasks, which limits their applicability to downstream tasks. To this end, we introduce ReWorld, a framework aimed to employ reinforcement learning to align the video-based embodied world models with physical realism, task completion capability, embodiment plausibility and visual quality. Specifically, we first construct a large-scale (~235K) video preference dataset and employ it to train a hierarchical reward model designed to capture multi-dimensional reward consistent with human preferences. We further propose a practical alignment algorithm that post-trains flow-based world models using this reward through a computationally efficient PPO-style algorithm. Comprehensive experiments and theoretical analysis demonstrate that ReWorld significantly improves the physical fidelity, logical coherence, embodiment and visual quality of generated rollouts, outperforming previous methods.

</details>


### [309] [KILO-EKF: Koopman-Inspired Learned Observations Extended Kalman Filter](https://arxiv.org/abs/2601.12463)
*Zi Cong Guo,James R. Forbes,Timothy D. Barfoot*

Main category: cs.RO

TL;DR: KILO-EKF结合EKF与Koopman启发的学习测量模型，提升传感器数据处理能力，在四旋翼定位中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决复杂或校准不佳传感器的灵活建模问题，同时保留递归滤波的结构和效率。

Method: 结合标准EKF预测步骤与基于数据学习的Koopman启发的测量模型，通过将测量提升到特征空间实现线性高斯测量模型的闭式学习。

Result: 在真实四旋翼定位任务中，KILO-EKF比数据校准基线具有更高的准确性和一致性，显著优于依赖不完美几何模型的EKF。

Conclusion: KILO-EKF通过Koopman启发的测量学习，提供了一种可扩展的替代方案，优于传统基于模型的校准方法，同时保持实时推理和快速训练。

Abstract: We present the Koopman-Inspired Learned Observations Extended Kalman Filter (KILO-EKF), which combines a standard EKF prediction step with a correction step based on a Koopman-inspired measurement model learned from data. By lifting measurements into a feature space where they are linear in the state, KILO-EKF enables flexible modeling of complex or poorly calibrated sensors while retaining the structure and efficiency of recursive filtering. The resulting linear-Gaussian measurement model is learned in closed form from groundtruth training data, without iterative optimization or reliance on an explicit parametric sensor model. At inference, KILO-EKF performs a standard EKF update using Jacobians obtained via the learned lifting. We validate the approach on a real-world quadrotor localization task using an IMU, ultra-wideband (UWB) sensors, and a downward-facing laser. We compare against multiple EKF baselines with varying levels of sensor calibration. KILO-EKF achieves better accuracy and consistency compared to data-calibrated baselines, and significantly outperforms EKFs that rely on imperfect geometric models, while maintaining real-time inference and fast training. These results demonstrate the effectiveness of Koopman-inspired measurement learning as a scalable alternative to traditional model-based calibration.

</details>


### [310] [Language-Based Swarm Perception: Decentralized Person Re-Identification via Natural Language Descriptions](https://arxiv.org/abs/2601.12479)
*Miquel Kegeleirs,Lorenzo Garattoni,Gianpiero Francesca,Mauro Birattari*

Main category: cs.RO

TL;DR: 提出一种基于自然语言的分散式人员重识别方法，通过文本描述代替视觉嵌入，提升透明度和可解释性，实验性能与嵌入方法相当。


<details>
  <summary>Details</summary>
Motivation: 传统方法依赖高维视觉嵌入特征向量，缺乏可解释性和透明度。本文旨在通过自然语言表示提升机器人群体协作的透明度和可解释性。

Method: 利用视觉-语言模型（VLM）在机器人本地检测并生成人类可读的文本描述，代替传统的视觉嵌入特征向量。这些描述在群体中无需集中协调即可进行比较和聚类，最终通过语言模型生成代表性描述。

Result: 初步实验表明，该方法在身份一致性和可解释性方面与基于嵌入的方法性能相当，尽管文本相似性和计算负载仍需改进。

Conclusion: 该方法通过自然语言作为主要表示模态，实现了机器人群体中分散式的人员重识别，具有可解释性和透明度，尽管在文本相似性和计算负载方面存在局限，但初步实验显示了与基于嵌入的方法相当的性能。未来工作将探索改进相似性度量、语义导航及基于语言的环境感知扩展。

Abstract: We introduce a method for decentralized person re-identification in robot swarms that leverages natural language as the primary representational modality. Unlike traditional approaches that rely on opaque visual embeddings -- high-dimensional feature vectors extracted from images -- the proposed method uses human-readable language to represent observations. Each robot locally detects and describes individuals using a vision-language model (VLM), producing textual descriptions of appearance instead of feature vectors. These descriptions are compared and clustered across the swarm without centralized coordination, allowing robots to collaboratively group observations of the same individual. Each cluster is distilled into a representative description by a language model, providing an interpretable, concise summary of the swarm's collective perception. This approach enables natural-language querying, enhances transparency, and supports explainable swarm behavior. Preliminary experiments demonstrate competitive performance in identity consistency and interpretability compared to embedding-based methods, despite current limitations in text similarity and computational load. Ongoing work explores refined similarity metrics, semantic navigation, and the extension of language-based perception to environmental elements. This work prioritizes decentralized perception and communication, while active navigation remains an open direction for future study.

</details>


### [311] [Enabling High-Curvature Navigation in Eversion Robots through Buckle-Inducing Constrictive Bands](https://arxiv.org/abs/2601.12523)
*Cem Suulker,Muhie Al Haimus,Thomas Mack,Mohammad Sheikhsofla,Neri Niccolò Dei,Reza Kashef,Hadi Sadati,Federica Barontini,Fanny Ficuciello,Alberto Arezzo,Bruno Siciliano,Sebastien Ourselin,Kaspar Althoefer*

Main category: cs.RO

TL;DR: 提出一种被动方法，通过在翻转机器人外壁引入屈曲点来降低弯曲刚度，显著提高了在复杂路径中的导航能力，同时保持了柔软性和合规性。


<details>
  <summary>Details</summary>
Motivation: 解决翻转机器人在狭窄通道中可靠导航的挑战，同时避免增加结构复杂性和牺牲其柔软性和合规性。

Method: 在被动机器人外壁定期集成不可伸展的直径减小环带，利用Cosserat杆模型量化局部刚度降低及其对整体弯曲力学的影响。

Result: 实验结果显示，这些环带将机器人尖端弯曲时的刚度降低了91%，使其能够以低至25毫米的弯曲半径通过180度弯道，优于标准翻转机器人的35毫米。

Conclusion: 通过在被动机器人外壁引入屈曲点，显著降低了弯曲刚度，提高了在复杂路径中的导航能力，同时保持了柔软性和合规性，拓展了翻转机器人在管道检查和医疗程序中的应用。

Abstract: Tip-growing eversion robots are renowned for their ability to access remote spaces through narrow passages. However, achieving reliable navigation remains a significant challenge. Existing solutions often rely on artificial muscles integrated into the robot body or active tip-steering mechanisms. While effective, these additions introduce structural complexity and compromise the defining advantages of eversion robots: their inherent softness and compliance. In this paper, we propose a passive approach to reduce bending stiffness by purposefully introducing buckling points along the robot's outer wall. We achieve this by integrating inextensible diameter-reducing circumferential bands at regular intervals along the robot body facilitating forward motion through tortuous, obstacle cluttered paths. Rather than relying on active steering, our approach leverages the robot's natural interaction with the environment, allowing for smooth, compliant navigation. We present a Cosserat rod-based mathematical model to quantify this behavior, capturing the local stiffness reductions caused by the constricting bands and their impact on global bending mechanics. Experimental results demonstrate that these bands reduce the robot's stiffness when bent at the tip by up to 91 percent, enabling consistent traversal of 180 degree bends with a bending radius of as low as 25 mm-notably lower than the 35 mm achievable by standard eversion robots under identical conditions. The feasibility of the proposed method is further demonstrated through a case study in a colon phantom. By significantly improving maneuverability without sacrificing softness or increasing mechanical complexity, this approach expands the applicability of eversion robots in highly curved pathways, whether in relation to pipe inspection or medical procedures such as colonoscopy.

</details>


### [312] [RPT*: Global Planning with Probabilistic Terminals for Target Search in Complex Environments](https://arxiv.org/abs/2601.12701)
*Yunpeng Lyu,Chao Cao,Ji Zhang,Howie Choset,Zhongqiang Ren*

Main category: cs.RO

TL;DR: The paper proposes RPT* and HATS to solve the HPP-PT problem, leveraging dynamic programming and novel heuristics to handle uncertainty and history dependency, showing superior performance in target search scenarios.


<details>
  <summary>Details</summary>
Motivation: The motivation stems from the need to solve routing problems under uncertainty, specifically the HPP-PT variant, which is crucial for applications like target object search where prior knowledge of object locations is probabilistic. Existing methods fail to efficiently handle the history dependency inherent in such problems.

Method: The paper introduces a search-based approach called RPT*, which uses dynamic programming in a novel state space to handle history dependency and incorporates new heuristics for faster computation. Additionally, the HATS system integrates RPT* with Bayesian filtering or autonomous exploration for different scenarios.

Result: Experimental results demonstrate that RPT* and HATS can naturally balance exploitation and exploration, leading to faster target finding compared to baseline methods in both simulated and real robot environments.

Conclusion: The paper concludes that the proposed RPT* approach and HATS system effectively address the HPP-PT problem by balancing exploitation and exploration, outperforming baseline methods in both simulation and real-world robot experiments.

Abstract: Routing problems such as Hamiltonian Path Problem (HPP), seeks a path to visit all the vertices in a graph while minimizing the path cost. This paper studies a variant, HPP with Probabilistic Terminals (HPP-PT), where each vertex has a probability representing the likelihood that the robot's path terminates there, and the objective is to minimize the expected path cost. HPP-PT arises in target object search, where a mobile robot must visit all candidate locations to find an object, and prior knowledge of the object's location is expressed as vertex probabilities. While routing problems have been studied for decades, few of them consider uncertainty as required in this work. The challenge lies not only in optimally ordering the vertices, as in standard HPP, but also in handling history dependency: the expected path cost depends on the order in which vertices were previously visited. This makes many existing methods inefficient or inapplicable. To address the challenge, we propose a search-based approach RPT* with solution optimality guarantees, which leverages dynamic programming in a new state space to bypass the history dependency and novel heuristics to speed up the computation. Building on RPT*, we design a Hierarchical Autonomous Target Search (HATS) system that combines RPT* with either Bayesian filtering for lifelong target search with noisy sensors, or autonomous exploration to find targets in unknown environments. Experiments in both simulation and real robot show that our approach can naturally balance between exploitation and exploration, thereby finding targets more quickly on average than baseline methods.

</details>


### [313] [AirHunt: Bridging VLM Semantics and Continuous Planning for Efficient Aerial Object Navigation](https://arxiv.org/abs/2601.12742)
*Xuecheng Chen,Zongzhuo Liu,Jianfa Ma,Bang Du,Tiantian Zhang,Xueqian Wang,Boyu Zhou*

Main category: cs.RO

TL;DR: AirHunt是一种无人机导航系统，通过融合视觉语言模型的语义推理与路径规划，高效定位开放集对象，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有系统难以将视觉语言模型集成到实时规划中，且缺乏统一的机制在大规模环境中平衡语义引导与运动效率。

Method: AirHunt采用双路径异步架构，结合主动双任务推理模块和语义-几何一致规划模块，动态平衡语义优先级与运动效率。

Result: 实验表明，AirHunt在多样化的对象导航任务和环境中表现优异，成功率高、导航误差低且飞行时间短。

Conclusion: AirHunt通过融合视觉语言模型的语义推理与连续路径规划，成功解决了无人机在户外环境中定位开放集对象的挑战，实现了更高的成功率和更低的导航误差。

Abstract: Recent advances in large Vision-Language Models (VLMs) have provided rich semantic understanding that empowers drones to search for open-set objects via natural language instructions. However, prior systems struggle to integrate VLMs into practical aerial systems due to orders-of-magnitude frequency mismatch between VLM inference and real-time planning, as well as VLMs' limited 3D scene understanding. They also lack a unified mechanism to balance semantic guidance with motion efficiency in large-scale environments. To address these challenges, we present AirHunt, an aerial object navigation system that efficiently locates open-set objects with zero-shot generalization in outdoor environments by seamlessly fusing VLM semantic reasoning with continuous path planning. AirHunt features a dual-pathway asynchronous architecture that establishes a synergistic interface between VLM reasoning and path planning, enabling continuous flight with adaptive semantic guidance that evolves through motion. Moreover, we propose an active dual-task reasoning module that exploits geometric and semantic redundancy to enable selective VLM querying, and a semantic-geometric coherent planning module that dynamically reconciles semantic priorities and motion efficiency in a unified framework, enabling seamless adaptation to environmental heterogeneity. We evaluate AirHunt across diverse object navigation tasks and environments, demonstrating a higher success rate with lower navigation error and reduced flight time compared to state-of-the-art methods. Real-world experiments further validate AirHunt's practical capability in complex and challenging environments. Code and dataset will be made publicly available before publication.

</details>


### [314] [FocusNav: Spatial Selective Attention with Waypoint Guidance for Humanoid Local Navigation](https://arxiv.org/abs/2601.12790)
*Yang Zhang,Jianming Ma,Liyun Yan,Zhanxiang Cao,Yazhou Zhang,Haoyang Li,Yue Gao*

Main category: cs.RO

TL;DR: FocusNav通过自适应感知调节和稳定性增强，提升了人形机器人在复杂环境中的导航性能。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人在非结构化和动态环境中稳健导航的挑战，需平衡长距离导航目标和即时运动稳定性。

Method: 提出了FocusNav框架，包括Waypoint-Guided Spatial Cross-Attention (WGSCA)机制和Stability-Aware Selective Gating (SASG)模块，用于自适应调节机器人的感知范围和稳定性。

Result: 在Unitree G1人形机器人上的实验表明，FocusNav在避障和运动稳定性方面优于基线方法。

Conclusion: FocusNav显著提高了人形机器人在动态和复杂环境中的导航成功率，优于基线方法，实现了稳健的导航。

Abstract: Robust local navigation in unstructured and dynamic environments remains a significant challenge for humanoid robots, requiring a delicate balance between long-range navigation targets and immediate motion stability. In this paper, we propose FocusNav, a spatial selective attention framework that adaptively modulates the robot's perceptual field based on navigational intent and real-time stability. FocusNav features a Waypoint-Guided Spatial Cross-Attention (WGSCA) mechanism that anchors environmental feature aggregation to a sequence of predicted collision-free waypoints, ensuring task-relevant perception along the planned trajectory. To enhance robustness in complex terrains, the Stability-Aware Selective Gating (SASG) module autonomously truncates distal information when detecting instability, compelling the policy to prioritize immediate foothold safety. Extensive experiments on the Unitree G1 humanoid robot demonstrate that FocusNav significantly improves navigation success rates in challenging scenarios, outperforming baselines in both collision avoidance and motion stability, achieving robust navigation in dynamic and complex environments.

</details>


### [315] [Contact-Aware Neural Dynamics](https://arxiv.org/abs/2601.12796)
*Changwei Jing,Jai Krishna Bandi,Jianglong Ye,Yan Duan,Pieter Abbeel,Xiaolong Wang,Sha Yi*

Main category: cs.RO

TL;DR: 论文提出了一种隐式模拟对齐框架，通过神经动力学模型结合触觉数据改进模拟器动态预测，缩小模拟与现实差距。


<details>
  <summary>Details</summary>
Motivation: 高保真物理模拟对机器人学习至关重要，但模拟与现实的差距在涉及复杂、动态和不连续交互（如物理接触）的任务中尤为明显。显式系统识别方法通常不足以对齐真实世界的高维、状态依赖的动态特性。

Method: 该方法利用现成的模拟器作为基础先验，学习一个接触感知的神经动力学模型，通过真实世界观测数据来优化模拟状态。

Result: 研究表明，使用机器人手的触觉接触信息可以有效建模接触丰富任务中的非平滑不连续性，从而提升状态预测准确性，并可用于优化仅在标准模拟器中训练的策略。

Conclusion: 该论文提出了一种基于隐式模拟对齐的框架，通过结合触觉接触信息来改进模拟器的动态预测，从而有效缩小模拟与现实的差距。

Abstract: High-fidelity physics simulation is essential for scalable robotic learning, but the sim-to-real gap persists, especially for tasks involving complex, dynamic, and discontinuous interactions like physical contacts. Explicit system identification, which tunes explicit simulator parameters, is often insufficient to align the intricate, high-dimensional, and state-dependent dynamics of the real world. To overcome this, we propose an implicit sim-to-real alignment framework that learns to directly align the simulator's dynamics with contact information. Our method treats the off-the-shelf simulator as a base prior and learns a contact-aware neural dynamics model to refine simulated states using real-world observations. We show that using tactile contact information from robotic hands can effectively model the non-smooth discontinuities inherent in contact-rich tasks, resulting in a neural dynamics model grounded by real-world data. We demonstrate that this learned forward dynamics model improves state prediction accuracy and can be effectively used to predict policy performance and refine policies trained purely in standard simulators, offering a scalable, data-driven approach to sim-to-real alignment.

</details>


### [316] [FRoM-W1: Towards General Humanoid Whole-Body Control with Language Instructions](https://arxiv.org/abs/2601.12799)
*Peng Li,Zihan Zhuang,Yangfan Gao,Yi Dong,Sixian Li,Changhao Jiang,Shihan Dou,Zhiheng Xi,Enyu Zhou,Jixuan Huang,Hui Li,Jingjing Gong,Xingjun Ma,Tao Gui,Zuxuan Wu,Qi Zhang,Xuanjing Huang,Yu-Gang Jiang,Xipeng Qiu*

Main category: cs.RO

TL;DR: FRoM-W1是一个开源框架，通过自然语言控制人形机器人全身运动，结合语言模型和强化学习，显著提升了运动生成和执行的性能。


<details>
  <summary>Details</summary>
Motivation: 人形机器人的动作通常是通过硬编码或专门训练的，这限制了其多功能性。FRoM-W1旨在通过自然语言实现通用的人形机器人全身运动控制。

Method: FRoM-W1分为两个阶段：(a) H-GPT：利用大规模人类数据训练语言驱动的人体全身运动生成模型，并通过Chain-of-Thought技术提升指令理解的泛化能力；(b) H-ACT：将生成的运动重定向为机器人特定动作，通过强化学习在物理仿真中预训练和微调运动控制器，最终通过模块化仿真到现实模块部署到真实机器人上。

Result: 在Unitree H1和G1机器人上的广泛评估显示，FRoM-W1在HumanML3D-X基准测试中表现出色，强化学习微调显著提高了运动跟踪精度和任务成功率。

Conclusion: FRoM-W1框架的开源有望推动人形机器人智能的发展。

Abstract: Humanoid robots are capable of performing various actions such as greeting, dancing and even backflipping. However, these motions are often hard-coded or specifically trained, which limits their versatility. In this work, we present FRoM-W1, an open-source framework designed to achieve general humanoid whole-body motion control using natural language. To universally understand natural language and generate corresponding motions, as well as enable various humanoid robots to stably execute these motions in the physical world under gravity, FRoM-W1 operates in two stages: (a) H-GPT: utilizing massive human data, a large-scale language-driven human whole-body motion generation model is trained to generate diverse natural behaviors. We further leverage the Chain-of-Thought technique to improve the model's generalization in instruction understanding. (b) H-ACT: After retargeting generated human whole-body motions into robot-specific actions, a motion controller that is pretrained and further fine-tuned through reinforcement learning in physical simulation enables humanoid robots to accurately and stably perform corresponding actions. It is then deployed on real robots via a modular simulation-to-reality module. We extensively evaluate FRoM-W1 on Unitree H1 and G1 robots. Results demonstrate superior performance on the HumanML3D-X benchmark for human whole-body motion generation, and our introduced reinforcement learning fine-tuning consistently improves both motion tracking accuracy and task success rates of these humanoid robots. We open-source the entire FRoM-W1 framework and hope it will advance the development of humanoid intelligence.

</details>


### [317] [Sparse ActionGen: Accelerating Diffusion Policy with Real-time Pruning](https://arxiv.org/abs/2601.12894)
*Kangye Ji,Yuan Meng,Zhou Jianbo,Ye Li,Hanyun Cui,Zhi Wang*

Main category: cs.RO

TL;DR: SAG提出了一种稀疏动作生成方法，通过剪枝-重用机制和高效设计，在不牺牲性能的情况下显著提升生成速度。


<details>
  <summary>Details</summary>
Motivation: 现有基于缓存的加速方法通常依赖静态调度，无法适应机器人-环境交互的动态变化，导致性能不佳。SAG旨在解决这一问题，实现实时高效的稀疏动作生成。

Method: SAG采用了一种基于滚动适应的剪枝-然后重用机制，全局识别可剪枝计算，并在动作扩散过程中重用缓存激活。此外，SAG参数化了一个观察条件扩散剪枝器，用于环境感知适应，并通过高效的参数和推理设计实现实时预测。

Result: 在多个机器人基准测试中，SAG实现了高达4倍的生成速度提升，且性能未受影响。

Conclusion: SAG（稀疏动作生成）通过其创新的剪枝-重用机制和高效的参数化设计，在不牺牲性能的情况下实现了高达4倍的生成速度提升，适用于实时视觉运动控制。

Abstract: Diffusion Policy has dominated action generation due to its strong capabilities for modeling multi-modal action distributions, but its multi-step denoising processes make it impractical for real-time visuomotor control. Existing caching-based acceleration methods typically rely on $\textit{static}$ schedules that fail to adapt to the $\textit{dynamics}$ of robot-environment interactions, thereby leading to suboptimal performance. In this paper, we propose $\underline{\textbf{S}}$parse $\underline{\textbf{A}}$ction$\underline{\textbf{G}}$en ($\textbf{SAG}$) for extremely sparse action generation. To accommodate the iterative interactions, SAG customizes a rollout-adaptive prune-then-reuse mechanism that first identifies prunable computations globally and then reuses cached activations to substitute them during action diffusion. To capture the rollout dynamics, SAG parameterizes an observation-conditioned diffusion pruner for environment-aware adaptation and instantiates it with a highly parameter- and inference-efficient design for real-time prediction. Furthermore, SAG introduces a one-for-all reusing strategy that reuses activations across both timesteps and blocks in a zig-zag manner, minimizing the global redundancy. Extensive experiments on multiple robotic benchmarks demonstrate that SAG achieves up to 4$\times$ generation speedup without sacrificing performance. Project Page: https://sparse-actiongen.github.io/.

</details>


### [318] [PlannerRFT: Reinforcing Diffusion Planners through Closed-Loop and Sample-Efficient Fine-Tuning](https://arxiv.org/abs/2601.12901)
*Hongchen Li,Tianyu Li,Jiazhi Yang,Haochen Tian,Caojun Wang,Lei Shi,Mingyang Shang,Zengrong Lin,Gaoqiang Wu,Zhihui Hao,Xianpeng Lang,Jia Hu,Hongyang Li*

Main category: cs.RO

TL;DR: PlannerRFT是一种高效的强化微调框架，通过双分支优化和快速模拟器nuMax，提升了扩散规划器的多模态轨迹生成能力。


<details>
  <summary>Details</summary>
Motivation: 现有扩散规划器在强化微调中难以生成多模态、场景自适应的轨迹，导致信息奖励的利用效率低。

Method: PlannerRFT采用双分支优化方法，同时优化轨迹分布并自适应引导去噪过程，结合nuMax模拟器实现高效并行学习。

Result: 实验表明PlannerRFT在性能上达到最先进水平，并在学习过程中展现出多样化行为。

Conclusion: PlannerRFT框架通过双分支优化和nuMax模拟器，显著提升了扩散规划器的样本效率和性能，实现了多模态、场景自适应的轨迹生成。

Abstract: Diffusion-based planners have emerged as a promising approach for human-like trajectory generation in autonomous driving. Recent works incorporate reinforcement fine-tuning to enhance the robustness of diffusion planners through reward-oriented optimization in a generation-evaluation loop. However, they struggle to generate multi-modal, scenario-adaptive trajectories, hindering the exploitation efficiency of informative rewards during fine-tuning. To resolve this, we propose PlannerRFT, a sample-efficient reinforcement fine-tuning framework for diffusion-based planners. PlannerRFT adopts a dual-branch optimization that simultaneously refines the trajectory distribution and adaptively guides the denoising process toward more promising exploration, without altering the original inference pipeline. To support parallel learning at scale, we develop nuMax, an optimized simulator that achieves 10 times faster rollout compared to native nuPlan. Extensive experiments shows that PlannerRFT yields state-of-the-art performance with distinct behaviors emerging during the learning process.

</details>


### [319] [Dynamic Hand Gesture Recognition for Robot Manipulator Tasks](https://arxiv.org/abs/2601.12918)
*Dharmendra Sharma,Peeyush Thakur,Sandeep Gupta,Narendra Kumar Dhar,Laxmidhar Behera*

Main category: cs.RO

TL;DR: An unsupervised Gaussian Mixture model-based approach for real-time recognition of dynamic hand gestures, enhancing human-robot interaction with high accuracy.


<details>
  <summary>Details</summary>
Motivation: To facilitate seamless human-robot interaction by assigning specific dynamic hand gestures to various robot manipulator tasks, addressing the challenge of recognizing multiple gesture variations.

Method: The paper introduces an unsupervised model utilizing the Gaussian Mixture model to accurately recognize dynamic hand gestures, even with variations, in real-time.

Result: The model achieves high accuracy in recognizing dynamic hand gestures during both training and real-time testing, demonstrating its practical applicability.

Conclusion: The proposed unsupervised model based on the Gaussian Mixture model effectively recognizes dynamic hand gestures in real-time, proving its efficacy through high accuracy in both training and testing phases.

Abstract: This paper proposes a novel approach to recognizing dynamic hand gestures facilitating seamless interaction between humans and robots. Here, each robot manipulator task is assigned a specific gesture. There may be several such tasks, hence, several gestures. These gestures may be prone to several dynamic variations. All such variations for different gestures shown to the robot are accurately recognized in real-time using the proposed unsupervised model based on the Gaussian Mixture model. The accuracy during training and real-time testing prove the efficacy of this methodology.

</details>


### [320] [ForeDiffusion: Foresight-Conditioned Diffusion Policy via Future View Construction for Robot Manipulation](https://arxiv.org/abs/2601.12925)
*Weize Xie,Yi Ding,Ying He,Leilei Wang,Binwen Bai,Zheyi Zhao,Chenyang Wang,F. Richard Yu*

Main category: cs.RO

TL;DR: ForeDiffusion通过前瞻性条件和双损失机制，显著提升复杂任务中的机器人操作成功率（80%）和稳定性，比现有方法高23%。


<details>
  <summary>Details</summary>
Motivation: 现有扩散策略仅依赖短期观察作为条件，且训练目标局限于单一去噪损失，导致误差累积和抓取偏差。

Method: 提出Foresight-Conditioned Diffusion (ForeDiffusion)，在扩散过程中注入预测的未来视图表示，并采用双损失机制（传统去噪损失与未来观测一致性损失）进行统一优化。

Result: 在Adroit套件和MetaWorld基准测试中，ForeDiffusion整体任务平均成功率达80%，复杂任务中比现有方法高出23%，且性能更稳定。

Conclusion: ForeDiffusion通过引入前瞻性条件（预测的未来视图表示）和双损失机制（去噪损失与未来观测一致性损失），显著提升了复杂任务中的成功率（平均80%）和稳定性，比现有主流扩散方法在复杂任务中表现高出23%。

Abstract: Diffusion strategies have advanced visual motor control by progressively denoising high-dimensional action sequences, providing a promising method for robot manipulation. However, as task complexity increases, the success rate of existing baseline models decreases considerably. Analysis indicates that current diffusion strategies are confronted with two limitations. First, these strategies only rely on short-term observations as conditions. Second, the training objective remains limited to a single denoising loss, which leads to error accumulation and causes grasping deviations. To address these limitations, this paper proposes Foresight-Conditioned Diffusion (ForeDiffusion), by injecting the predicted future view representation into the diffusion process. As a result, the policy is guided to be forward-looking, enabling it to correct trajectory deviations. Following this design, ForeDiffusion employs a dual loss mechanism, combining the traditional denoising loss and the consistency loss of future observations, to achieve the unified optimization. Extensive evaluation on the Adroit suite and the MetaWorld benchmark demonstrates that ForeDiffusion achieves an average success rate of 80% for the overall task, significantly outperforming the existing mainstream diffusion methods by 23% in complex tasks, while maintaining more stable performance across the entire tasks.

</details>


### [321] [Active Inference-Driven World Modeling for Adaptive UAV Swarm Trajectory Design](https://arxiv.org/abs/2601.12939)
*Kaleem Arshid,Ali Krayani,Lucio Marcenaro,David Martin Gomez,Carlo Regazzoni*

Main category: cs.RO

TL;DR: 该论文提出一种基于主动推理的无人机群自主轨迹设计框架，结合GA-RF训练分层世界模型，实现动态环境自适应，仿真显示其性能优于Q-Learning。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决无人机群在动态环境中自主轨迹设计的挑战，通过集成概率推理和自学习，提升分布式任务分配、路径排序和运动规划的效率和适应性。

Method: 该方法结合概率推理和自学习，通过遗传算法与排斥力（GA-RF）生成专家轨迹，训练一个分层的世界模型，捕捉任务、路径和运动层面的群体行为。在线操作中，无人机通过最小化当前信念与模型预测状态之间的差异来推断动作，从而实现对动态环境的自适应响应。

Result: 仿真结果表明，该方法在收敛速度、稳定性和导航安全性方面优于Q-Learning，验证了框架的可扩展性和认知基础。

Conclusion: 该论文提出的基于主动推理的框架在无人机群自主轨迹设计中展现出快速收敛、高稳定性和更安全的导航性能，优于Q-Learning方法，证明了其在智能无人机群控制中的可扩展性和认知基础。

Abstract: This paper proposes an Active Inference-based framework for autonomous trajectory design in UAV swarms. The method integrates probabilistic reasoning and self-learning to enable distributed mission allocation, route ordering, and motion planning. Expert trajectories generated using a Genetic Algorithm with Repulsion Forces (GA-RF) are employed to train a hierarchical World Model capturing swarm behavior across mission, route, and motion levels. During online operation, UAVs infer actions by minimizing divergence between current beliefs and model-predicted states, enabling adaptive responses to dynamic environments. Simulation results show faster convergence, higher stability, and safer navigation than Q-Learning, demonstrating the scalability and cognitive grounding of the proposed framework for intelligent UAV swarm control.

</details>


### [322] [Imitation learning-based spacecraft rendezvous and docking method with Expert Demonstration](https://arxiv.org/abs/2601.12952)
*Shibo Shao,Dong Zhou,Guanghui Sun,Liwen Zhang,Mingxuan Jiang*

Main category: cs.RO

TL;DR: 本文提出了一种基于模仿学习的航天器交会对接控制框架（IL-SRD），通过锚定解码器目标和时间聚合机制，实现了高效、鲁棒的控制，减少了对精确建模的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有的航天器交会对接控制方法主要依赖预定义的动态模型，在实际轨道环境中鲁棒性有限。本文旨在解决这一问题。

Method: 提出了锚定解码器目标机制，通过将解码器查询条件限制在与状态相关的锚点上，显式约束控制生成过程，确保物理一致的控制演化。此外，引入了时间聚合机制以减少基于Transformer模型的序列预测中误差累积的影响。

Result: 仿真结果表明，IL-SRD框架实现了准确且能量高效的无模型交会对接控制，并在显著未知干扰下保持了竞争力。

Conclusion: 论文提出了一种基于模仿学习的航天器交会对接控制框架（IL-SRD），通过直接从专家演示中学习控制策略，减少了对精确建模的依赖，并在仿真实验中验证了其准确性和能量效率。

Abstract: Existing spacecraft rendezvous and docking control methods largely rely on predefined dynamic models and often exhibit limited robustness in realistic on-orbit environments. To address this issue, this paper proposes an Imitation Learning-based spacecraft rendezvous and docking control framework (IL-SRD) that directly learns control policies from expert demonstrations, thereby reducing dependence on accurate modeling. We propose an anchored decoder target mechanism, which conditions the decoder queries on state-related anchors to explicitly constrain the control generation process. This mechanism enforces physically consistent control evolution and effectively suppresses implausible action deviations in sequential prediction, enabling reliable six-degree-of-freedom (6-DOF) rendezvous and docking control. To further enhance stability, a temporal aggregation mechanism is incorporated to mitigate error accumulation caused by the sequential prediction nature of Transformer-based models, where small inaccuracies at each time step can propagate and amplify over long horizons. Extensive simulation results demonstrate that the proposed IL-SRD framework achieves accurate and energy-efficient model-free rendezvous and docking control. Robustness evaluations further confirm its capability to maintain competitive performance under significant unknown disturbances. The source code is available at https://github.com/Dongzhou-1996/IL-SRD.

</details>


### [323] [Being-H0.5: Scaling Human-Centric Robot Learning for Cross-Embodiment Generalization](https://arxiv.org/abs/2601.12993)
*Hao Luo,Ye Wang,Wanpeng Zhang,Sipeng Zheng,Ziheng Xi,Chaoyi Xu,Haiweng Xu,Haoqi Yuan,Chi Zhang,Yiqing Wang,Yicheng Feng,Zongqing Lu*

Main category: cs.RO

TL;DR: Being-H0.5是一种基于人类交互数据的VLA模型，通过统一动作空间和混合变换器设计，实现了跨机器人平台的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有VLA模型在形态异构性和数据稀缺性方面的挑战，通过人类交互痕迹作为物理交互的通用“母语”。

Method: 采用人类中心的学习范式，提出Unified Action Space和Mixture-of-Transformers设计，结合Mixture-of-Flow框架和Manifold-Preserving Gating技术。

Result: 在LIBERO（98.9%）和RoboCasa（53.9%）等模拟基准测试中表现优异，并在多个机器人平台上实现跨体现泛化。

Conclusion: Being-H0.5在模拟基准测试中取得了最先进的结果，并在五个机器人平台上展示了强大的跨体现能力。

Abstract: We introduce Being-H0.5, a foundational Vision-Language-Action (VLA) model designed for robust cross-embodiment generalization across diverse robotic platforms. While existing VLAs often struggle with morphological heterogeneity and data scarcity, we propose a human-centric learning paradigm that treats human interaction traces as a universal "mother tongue" for physical interaction. To support this, we present UniHand-2.0, the largest embodied pre-training recipe to date, comprising over 35,000 hours of multimodal data across 30 distinct robotic embodiments. Our approach introduces a Unified Action Space that maps heterogeneous robot controls into semantically aligned slots, enabling low-resource robots to bootstrap skills from human data and high-resource platforms. Built upon this human-centric foundation, we design a unified sequential modeling and multi-task pre-training paradigm to bridge human demonstrations and robotic execution. Architecturally, Being-H0.5 utilizes a Mixture-of-Transformers design featuring a novel Mixture-of-Flow (MoF) framework to decouple shared motor primitives from specialized embodiment-specific experts. Finally, to make cross-embodiment policies stable in the real world, we introduce Manifold-Preserving Gating for robustness under sensory shift and Universal Async Chunking to universalize chunked control across embodiments with different latency and control profiles. We empirically demonstrate that Being-H0.5 achieves state-of-the-art results on simulated benchmarks, such as LIBERO (98.9%) and RoboCasa (53.9%), while also exhibiting strong cross-embodiment capabilities on five robotic platforms.

</details>


### [324] [Static Is Not Enough: A Comparative Study of VR and SpaceMouse in Static and Dynamic Teleoperation Tasks](https://arxiv.org/abs/2601.13042)
*Yijun Zhou,Muhan Hou,Kim Baraka*

Main category: cs.RO

TL;DR: VR控制器在动态任务中优于SpaceMouse，具有更高成功率和更低工作负荷，研究填补了动态任务遥操作界面的空白。


<details>
  <summary>Details</summary>
Motivation: 模仿学习依赖于高质量的演示，而遥操作是收集这些演示的主要方式。现有研究主要集中在静态任务上，但演示还包括需要反应控制的动态任务，动态任务对界面的需求与静态任务不同，因此需要专门研究。

Method: 通过一项受试者内研究，比较了VR控制器和SpaceMouse在两项静态和两项动态任务中的表现（N=25），评估了成功率、任务持续时间、累积成功率，以及NASA-TLX、SUS和开放式反馈。

Result: 结果显示VR控制器在动态任务中具有统计显著的优势：更高的成功率、更短的成功执行时间、更早的成功尝试，以及显著更低的工作负荷和更高的可用性。

Conclusion: VR控制器在动态任务中表现出显著优势，包括更高的成功率、更短的任务执行时间以及更低的工作负荷和更高的可用性。

Abstract: Imitation learning relies on high-quality demonstrations, and teleoperation is a primary way to collect them, making teleoperation interface choice crucial for the data. Prior work mainly focused on static tasks, i.e., discrete, segmented motions, yet demonstrations also include dynamic tasks requiring reactive control. As dynamic tasks impose fundamentally different interface demands, insights from static-task evaluations cannot generalize. To address this gap, we conduct a within-subjects study comparing a VR controller and a SpaceMouse across two static and two dynamic tasks ($N=25$). We assess success rate, task duration, cumulative success, alongside NASA-TLX, SUS, and open-ended feedback. Results show statistically significant advantages for VR: higher success rates, particularly on dynamic tasks, shorter successful execution times across tasks, and earlier successes across attempts, with significantly lower workload and higher usability. As existing VR teleoperation systems are rarely open-source or suited for dynamic tasks, we release our VR interface to fill this gap.

</details>


### [325] [Exploiting Light To Enhance The Endurance and Navigation of Lighter-Than-Air Micro-Drones](https://arxiv.org/abs/2601.13088)
*Harry Huang,Talia Xu,Marco Zúñiga Zamalloa*

Main category: cs.RO

TL;DR: 提出一种自持LTA无人机，结合太阳能和光导航技术，实现持久自主运行。


<details>
  <summary>Details</summary>
Motivation: 解决微型无人机（UAVs）在GPS缺失环境中续航短和导航不可靠的问题，同时简化LTA无人机的设计以实现持续自主运行。

Method: 提出了一种紧凑型自持LTA无人机，结合高保真模拟框架分析LTA空气动力学、集成太阳能电池的框架以及基于单一光信标的光导航系统。

Result: 在80klux光照下，每4分钟能量采集可支持1分钟飞行时间，并能在室内外环境中实现7米范围内的单光信标导航。

Conclusion: 该研究为轻于空气（LTA）无人机提供了一种自持久的解决方案，结合太阳能采集和光导航技术，为室内外监测提供了持久自主运行的可行路径。

Abstract: Micro-Unmanned Aerial Vehicles (UAVs) are rapidly expanding into tasks from inventory to environmental sensing, yet their short endurance and unreliable navigation in GPS-denied spaces limit deployment. Lighter-Than-Air (LTA) drones offer an energy-efficient alternative: they use a helium envelope to provide buoyancy, which enables near-zero-power drain during hovering and much longer operation. LTAs are promising, but their design is complex, and they lack integrated solutions to enable sustained autonomous operations and navigation with simple, low-infrastructure.
  We propose a compact, self-sustaining LTA drone that uses light for both energy harvesting and navigation. Our contributions are threefold: (i) a high-fidelity simulation framework to analyze LTA aerodynamics and select a stable, efficient configuration; (ii) a framework to integrate solar cells on the envelope to provide net-positive energy; and (iii) a point-and-go navigation system with three light-seeking algorithms operating on a single light beacon.
  Our LTA-analysis, together with the integrated solar panels, not only saves energy while flying, but also enables sustainable operation: providing 1 minute of flying time for every 4 minutes of energy harvesting, under illuminations of 80klux. We also demonstrate robust single-beacon navigation towards a light source that can be up to 7m away, in indoor and outdoor environments, even with moderate winds. The resulting system indicates a plausible path toward persistent, autonomous operation for indoor and outdoor monitoring. More broadly, this work provides a practical pathway for translating the promise of LTA drones into a persistent, self-sustaining aerial system.

</details>


### [326] [LLM-VLM Fusion Framework for Autonomous Maritime Port Inspection using a Heterogeneous UAV-USV System](https://arxiv.org/abs/2601.13096)
*Muhayy Ud Din,Waseem Akram,Ahsan B. Bakht,Irfan Hussain*

Main category: cs.RO

TL;DR: 研究提出了一种结合LLMs和VLMs的自主海事港口检查框架，通过符号规划和语义检查提升检查效率，验证了其在模拟和真实环境中的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有海事港口检查方法依赖人工操作和传统计算机视觉技术，缺乏可扩展性和上下文理解能力，亟需一种更智能、自适应的解决方案。

Method: 研究引入了一种新颖的集成工程框架，利用LLMs进行符号规划，VLMs进行语义检查，取代了传统状态机任务规划器。LLM模块将自然语言任务指令转换为可执行的符号计划，VLM模块实时进行语义检查和合规性评估。

Result: 该框架在扩展的MBZIRC海事模拟器中验证，并在真实机器人检查试验中进一步评估，证明了其有效性和实用性。

Conclusion: 该研究提出的集成工程框架通过结合大型语言模型（LLMs）和视觉语言模型（VLMs），实现了自主海事港口检查，显著提升了检查的上下文感知和适应性。轻量级设计使其适用于资源受限的海事平台，推动了智能自主检查系统的发展。

Abstract: Maritime port inspection plays a critical role in ensuring safety, regulatory compliance, and operational efficiency in complex maritime environments. However, existing inspection methods often rely on manual operations and conventional computer vision techniques that lack scalability and contextual understanding. This study introduces a novel integrated engineering framework that utilizes the synergy between Large Language Models (LLMs) and Vision Language Models (VLMs) to enable autonomous maritime port inspection using cooperative aerial and surface robotic platforms. The proposed framework replaces traditional state-machine mission planners with LLM-driven symbolic planning and improved perception pipelines through VLM-based semantic inspection, enabling context-aware and adaptive monitoring. The LLM module translates natural language mission instructions into executable symbolic plans with dependency graphs that encode operational constraints and ensure safe UAV-USV coordination. Meanwhile, the VLM module performs real-time semantic inspection and compliance assessment, generating structured reports with contextual reasoning. The framework was validated using the extended MBZIRC Maritime Simulator with realistic port infrastructure and further assessed through real-world robotic inspection trials. The lightweight on-board design ensures suitability for resource-constrained maritime platforms, advancing the development of intelligent, autonomous inspection systems. Project resources (code and videos) can be found here: https://github.com/Muhayyuddin/llm-vlm-fusion-port-inspection

</details>


### [327] [Helical Tendon-Driven Continuum Robot with Programmable Follow-the-Leader Operation](https://arxiv.org/abs/2601.13177)
*Behnam Moradkhani,Raghav Sankaranarayanan,Pejman Kheradmand,Harshith Jella,Nicholas Ahn,Ajmal Zemmar,Yash Chitalia*

Main category: cs.RO

TL;DR: ExoNav是一种可转向机器人工具，通过Cosserat杆框架建模，能够精确导航至脊髓腹侧和外侧硬膜外空间，实验验证了其在重力影响下的路径跟踪能力。


<details>
  <summary>Details</summary>
Motivation: 当前手动导向的脊髓刺激（SCS）在精确导航至脊髓腹侧和外侧硬膜外空间存在挑战，因此开发了ExoNav这一可转向机器人工具以提高导航精度。

Method: 研究采用Cosserat杆框架建立肌腱驱动力与机器人整体形状的关系，并考虑重力等外部载荷的影响。通过仿真和实验验证了模型的准确性。

Result: 实验结果显示原型机的RMSE值在1.33mm至2.33mm之间，仿真和实验验证了ExoNav能够执行跟随领导者（FTL）运动，并在重力影响下保持路径跟踪能力。

Conclusion: ExoNav的静态建模方法展示了其在精确导航至脊髓腹侧和外侧硬膜外空间的潜力，同时具备在重力影响下计算最佳肌腱张力的能力，为脊髓刺激（SCS）在运动功能恢复和疼痛管理中的应用提供了新工具。

Abstract: Spinal cord stimulation (SCS) is primarily utilized for pain management and has recently demonstrated efficacy in promoting functional recovery in patients with spinal cord injury. Effective stimulation of motor neurons ideally requires the placement of SCS leads in the ventral or lateral epidural space where the corticospinal and rubrospinal motor fibers are located. This poses significant challenges with the current standard of manual steering. In this study, we present a static modeling approach for the ExoNav, a steerable robotic tool designed to facilitate precise navigation to the ventral and lateral epidural space. Cosserat rod framework is employed to establish the relationship between tendon actuation forces and the robot's overall shape. The effects of gravity, as an example of an external load, are investigated and implemented in the model and simulation. The experimental results indicate RMSE values of 1.76mm, 2.33mm, 2.18mm, and 1.33mm across four tested prototypes. Based on the helical shape of the ExoNav upon actuation, it is capable of performing follow-the-leader (FTL) motion by adding insertion and rotation DoFs to this robotic system, which is shown in simulation and experimentally. The proposed simulation has the capability to calculate optimum tendon tensions to follow the desired FTL paths while gravity-induced robot deformations are present. Three FTL experimental trials are conducted and the end-effector position showed repeatable alignments with the desired path with maximum RMSE value of 3.75mm. Ultimately, a phantom model demonstration is conducted where the teleoperated robot successfully navigated to the lateral and ventral spinal cord targets. Additionally, the user was able to navigate to the dorsal root ganglia, illustrating ExoNav's potential in both motor function recovery and pain management.

</details>


### [328] [Active Informative Planning for UAV-based Weed Mapping using Discrete Gaussian Process Representations](https://arxiv.org/abs/2601.13196)
*Jacob Swindell,Marija Popović,Riccardo Polvara*

Main category: cs.RO

TL;DR: 本文研究了离散化GP表示对无人机杂草测绘的影响，发现表示选择是关键设计因素，影响规划效率和计算负载。


<details>
  <summary>Details</summary>
Motivation: 探讨不同离散GP表示如何影响无人机杂草测绘的绘图质量和任务级性能。

Method: 本文采用后退视野IPP策略，基于地图不确定性、旅行成本和覆盖惩罚选择采样位置，并研究了多种离散化策略用于表示GP后验。

Result: 实验表明，表示选择显著影响探索行为和效率。

Conclusion: 离散化表示不仅是表示细节，而是影响规划动态、覆盖效率和计算负载的关键设计选择。

Abstract: Accurate agricultural weed mapping using unmanned aerial vehicles (UAVs) is crucial for precision farming. While traditional methods rely on rigid, pre-defined flight paths and intensive offline processing, informative path planning (IPP) offers a way to collect data adaptively where it is most needed. Gaussian process (GP) mapping provides a continuous model of weed distribution with built-in uncertainty. However, GPs must be discretised for practical use in autonomous planning. Many discretisation techniques exist, but the impact of discrete representation choice remains poorly understood. This paper investigates how different discrete GP representations influence both mapping quality and mission-level performance in UAV-based weed mapping. Considering a UAV equipped with a downward-facing camera, we implement a receding-horizon IPP strategy that selects sampling locations based on the map uncertainty, travel cost, and coverage penalties. We investigate multiple discretisation strategies for representing the GP posterior and use their induced map partitions to generate candidate viewpoints for planning. Experiments on real-world weed distributions show that representation choice significantly affects exploration behaviour and efficiency. Overall, our results demonstrate that discretisation is not only a representational detail but a key design choice that shapes planning dynamics, coverage efficiency, and computational load in online UAV weed mapping.

</details>


### [329] [MATTERIX: toward a digital twin for robotics-assisted chemistry laboratory automation](https://arxiv.org/abs/2601.13232)
*Kourosh Darvish,Arjun Sohal,Abhijoy Mandal,Hatem Fakhruldeen,Nikola Radulov,Zhengxue Zhou,Satheeshkumar Veeramani,Joshua Choi,Sijie Han,Brayden Zhang,Jeeyeoun Chae,Alex Wright,Yijie Wang,Hossein Darvish,Yuchi Zhao,Gary Tom,Han Hao,Miroslav Bogdanovic,Gabriella Pizzuto,Andrew I. Cooper,Alán Aspuru-Guzik,Florian Shkurti,Animesh Garg*

Main category: cs.RO

TL;DR: MATTERIX是一个GPU加速的机器人模拟框架，用于创建高保真数字孪生化学实验室，加速材料发现工作流程的开发。


<details>
  <summary>Details</summary>
Motivation: 加速材料发现以应对全球挑战，减少依赖现实实验的物理迭代，提高工作流程开发的可扩展性。

Method: 整合了真实物理模拟、逼真渲染与模块化GPU加速语义引擎，模拟化学工作流程在不同抽象层次上的逻辑状态和连续行为。

Result: 实现了从模拟到现实的转移，在机器人化学设置中验证了框架的有效性。

Conclusion: MATTERIX框架通过创建高保真数字孪生实验室，显著加速了材料发现的工作流程开发，减少了对昂贵现实实验的依赖，并支持在虚拟环境中测试自动化工作流程。

Abstract: Accelerated materials discovery is critical for addressing global challenges. However, developing new laboratory workflows relies heavily on real-world experimental trials, and this can hinder scalability because of the need for numerous physical make-and-test iterations. Here we present MATTERIX, a multiscale, graphics processing unit-accelerated robotic simulation framework designed to create high-fidelity digital twins of chemistry laboratories, thus accelerating workflow development. This multiscale digital twin simulates robotic physical manipulation, powder and liquid dynamics, device functionalities, heat transfer and basic chemical reaction kinetics. This is enabled by integrating realistic physics simulation and photorealistic rendering with a modular graphics processing unit-accelerated semantics engine, which models logical states and continuous behaviors to simulate chemistry workflows across different levels of abstraction. MATTERIX streamlines the creation of digital twin environments through open-source asset libraries and interfaces, while enabling flexible workflow design via hierarchical plan definition and a modular skill library that incorporates learning-based methods. Our approach demonstrates sim-to-real transfer in robotic chemistry setups, reducing reliance on costly real-world experiments and enabling the testing of hypothetical automated workflows in silico. The project website is available at https://accelerationconsortium.github.io/Matterix/ .

</details>


### [330] [Diffusion-based Inverse Model of a Distributed Tactile Sensor for Object Pose Estimation](https://arxiv.org/abs/2601.13250)
*Ante Marić,Giammarco Caroleo,Alessandro Albini,Julius Jankowski,Perla Maiolino,Sylvain Calinon*

Main category: cs.RO

TL;DR: 该论文提出了一种基于去噪扩散的逆触觉传感器模型，用于在视觉受限的操纵场景中高效估计物体姿态，显著提高了采样效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 触觉传感在视觉信息受限（如遮挡或环境影响）的操纵场景中为物体姿态估计提供了有前景的感知方式，但如何有效利用触觉数据仍是一个挑战。

Method: 通过学习一个基于去噪扩散的逆触觉传感器模型，该模型利用几何传感器模型（基于有符号距离场）在模拟中进行训练，并通过单步投影在推理过程中强制执行接触约束。

Result: 在模拟和真实世界的平面姿态估计实验中，该方法表现出色，尤其在采样效率和估计准确性方面优于局部采样基线。

Conclusion: 该论文提出的基于去噪扩散的逆触觉传感器模型在模拟和真实世界的平面姿态估计场景中表现出色，无需视觉数据或严格的初始姿态先验，显著提高了采样效率和估计准确性。

Abstract: Tactile sensing provides a promising sensing modality for object pose estimation in manipulation settings where visual information is limited due to occlusion or environmental effects. However, efficiently leveraging tactile data for estimation remains a challenge due to partial observability, with single observations corresponding to multiple possible contact configurations. This limits conventional estimation approaches largely tailored to vision. We propose to address these challenges by learning an inverse tactile sensor model using denoising diffusion. The model is conditioned on tactile observations from a distributed tactile sensor and trained in simulation using a geometric sensor model based on signed distance fields. Contact constraints are enforced during inference through single-step projection using distance and gradient information from the signed distance field. For online pose estimation, we integrate the inverse model with a particle filter through a proposal scheme that combines generated hypotheses with particles from the prior belief. Our approach is validated in simulated and real-world planar pose estimation settings, without access to visual data or tight initial pose priors. We further evaluate robustness to unmodeled contact and sensor dynamics for pose tracking in a box-pushing scenario. Compared to local sampling baselines, the inverse sensor model improves sampling efficiency and estimation accuracy while preserving multimodal beliefs across objects with varying tactile discriminability.

</details>


### [331] [Autonomous Navigation at the Nano-Scale: Algorithms, Architectures, and Constraints](https://arxiv.org/abs/2601.13252)
*Mahmud S. Zango,Jianglin Lan*

Main category: cs.RO

TL;DR: 本文综述了纳米无人机在极端SWaP限制下的自主导航技术，分析了从传统方法到边缘AI的转变，并指出了当前研究的不足与未来方向。


<details>
  <summary>Details</summary>
Motivation: 纳米级无人机的自主导航受到极端的尺寸、重量和功率（SWaP）限制，这与标准机器人范式有根本区别。

Method: 本文综述了专为100mW以下计算环境设计的传感、计算和控制架构的最新技术，分析了从经典几何方法到新兴“边缘AI”范式的转变。

Result: 尽管在视觉导航和相对姿态估计方面取得了显著进展，但在长期续航、动态环境中的鲁棒避障以及强化学习策略的“模拟到现实”转移方面仍存在差距。

Conclusion: 本文提出了一种混合架构，将轻量级经典控制与数据驱动感知相结合，以实现在GPS受限环境中完全自主、灵活的纳米无人机。

Abstract: Autonomous navigation for nano-scale unmanned aerial vehicles (nano-UAVs) is governed by extreme Size, Weight, and Power (SWaP) constraints (with the weight < 50 g and sub-100 mW onboard processor), distinguishing it fundamentally from standard robotic paradigms. This review synthesizes the state-of-the-art in sensing, computing, and control architectures designed specifically for these sub- 100mW computational envelopes. We critically analyse the transition from classical geometry-based methods to emerging "Edge AI" paradigms, including quantized deep neural networks deployed on ultra-low-power System-on-Chips (SoCs) and neuromorphic event-based control. Beyond algorithms, we evaluate the hardware-software co-design requisite for autonomy, covering advancements in dense optical flow, optimized Simultaneous Localization and Mapping (SLAM), and learning-based flight control. While significant progress has been observed in visual navigation and relative pose estimation, our analysis reveals persistent gaps in long-term endurance, robust obstacle avoidance in dynamic environments, and the "Sim-to-Real" transfer of reinforcement learning policies. This survey provides a roadmap for bridging these gaps, advocating for hybrid architectures that fuse lightweight classical control with data-driven perception to enable fully autonomous, agile nano-UAVs in GPS-denied environments.

</details>


### [332] [CLEAR: A Semantic-Geometric Terrain Abstraction for Large-Scale Unstructured Environments](https://arxiv.org/abs/2601.13361)
*Pranay Meshram,Charuvahan Adhivarahan,Ehsan Tarkesh Esfahani,Souma Chowdhury,Chen Wang,Karthik Dantu*

Main category: cs.RO

TL;DR: CLEAR通过边界感知分解和递归平面拟合，解决了大范围地形抽象的挑战，规划速度更快，路径更优。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法同时满足大范围（数十平方公里）地形抽象的需求，既保持语义和几何结构，又支持实时规划。网格方法扩展性差，四叉树与地形边界不对齐，且均缺乏对土地覆盖语义的编码，导致路径规划不可行或不可靠。

Method: CLEAR结合边界感知的空间分解与递归平面拟合，生成凸的、语义对齐的区域，并编码为地形感知图。

Result: 在9-100平方公里的地图上评估，CLEAR比原始网格规划快10倍，成本仅增加6.7%，且路径比其他基线方法短6-9%，更可靠。

Conclusion: CLEAR方法在长距离导航中展现出卓越的可扩展性和实用性，适用于灾害响应、国防和行星探索等应用。

Abstract: Long-horizon navigation in unstructured environments demands terrain abstractions that scale to tens of km$^2$ while preserving semantic and geometric structure, a combination existing methods fail to achieve. Grids scale poorly; quadtrees misalign with terrain boundaries; neither encodes landcover semantics essential for traversability-aware planning. This yields infeasible or unreliable paths for autonomous ground vehicles operating over 10+ km$^2$ under real-time constraints. CLEAR (Connected Landcover Elevation Abstract Representation) couples boundary-aware spatial decomposition with recursive plane fitting to produce convex, semantically aligned regions encoded as a terrain-aware graph. Evaluated on maps spanning 9-100~km$^2$ using a physics-based simulator, CLEAR achieves up to 10x faster planning than raw grids with only 6.7% cost overhead and delivers 6-9% shorter, more reliable paths than other abstraction baselines. These results highlight CLEAR's scalability and utility for long-range navigation in applications such as disaster response, defense, and planetary exploration.

</details>


### [333] [Robustness and Resilience Evaluation of Eco-Driving Strategies at Signalized Intersections](https://arxiv.org/abs/2601.13389)
*Zhaohui Liang,Chengyuan Ma,Keke Long,Xiaopeng Li*

Main category: cs.RO

TL;DR: 研究通过真实车辆实验评估生态驾驶策略，发现优化型控制器在多变干扰下更稳定，分析型控制器对执行和时间变化更敏感。


<details>
  <summary>Details</summary>
Motivation: 生态驾驶策略在信号交叉口能显著提升能效和减少排放，但现有评估多基于简化模拟或实验条件，缺乏对实际复杂环境的考量。

Method: 研究定义了两个互补标准：控制鲁棒性和环境韧性，并通过真实车辆实验评估多种生态驾驶控制器。

Result: 结果显示优化型控制器在不同干扰水平下表现更一致，而分析型控制器在名义条件下表现相当但对执行和时间变化更敏感。

Conclusion: 本研究通过统一框架评估了生态驾驶策略的控制鲁棒性和环境韧性，揭示了优化型控制器在多变干扰下表现更稳定，而分析型控制器在名义条件下表现相当但对执行和时间变化更敏感。

Abstract: Eco-driving strategies have demonstrated substantial potential for improving energy efficiency and reducing emissions, especially at signalized intersections. However, evaluations of eco-driving methods typically rely on simplified simulation or experimental conditions, where certain assumptions are made to manage complexity and experimental control. This study introduces a unified framework to evaluate eco-driving strategies through the lens of two complementary criteria: control robustness and environmental resilience. We define formal indicators that quantify performance degradation caused by internal execution variability and external environmental disturbances, respectively. These indicators are then applied to assess multiple eco-driving controllers through real-world vehicle experiments. The results reveal key tradeoffs between tracking accuracy and adaptability, showing that optimization-based controllers offer more consistent performance across varying disturbance levels, while analytical controllers may perform comparably under nominal conditions but exhibit greater sensitivity to execution and timing variability.

</details>


### [334] [Event-based Heterogeneous Information Processing for Online Vision-based Obstacle Detection and Localization](https://arxiv.org/abs/2601.13451)
*Reza Ahmadvand,Sarah Safura Sharif,Yaser Mike Banad*

Main category: cs.RO

TL;DR: 本文提出了一种结合HNN和SNN过滤的机器人视觉导航框架，通过双路径方法实现高效的环境理解和实时处理，仿真显示其在保持资源效率的同时具备良好检测精度。


<details>
  <summary>Details</summary>
Motivation: 通过整合HNNs和SNN过滤，增强未建模障碍物检测和定位的情境感知能力。

Method: 提出的架构采用双路径方法：ANN组件以低频处理静态空间特征，而SNN组件实时处理基于事件的动态传感器数据。

Result: 仿真结果表明，该方法在保持接近纯SNN实现的资源效率的同时，提供了可接受的检测精度。

Conclusion: 该框架代表了神经形态导航系统在不可预测和动态环境中操作的机器人方面的重大进展。

Abstract: This paper introduces a novel framework for robotic vision-based navigation that integrates Hybrid Neural Networks (HNNs) with Spiking Neural Network (SNN)-based filtering to enhance situational awareness for unmodeled obstacle detection and localization. By leveraging the complementary strengths of Artificial Neural Networks (ANNs) and SNNs, the system achieves both accurate environmental understanding and fast, energy-efficient processing. The proposed architecture employs a dual-pathway approach: an ANN component processes static spatial features at low frequency, while an SNN component handles dynamic, event-based sensor data in real time. Unlike conventional hybrid architectures that rely on domain conversion mechanisms, our system incorporates a pre-developed SNN-based filter that directly utilizes spike-encoded inputs for localization and state estimation. Detected anomalies are validated using contextual information from the ANN pathway and continuously tracked to support anticipatory navigation strategies. Simulation results demonstrate that the proposed method offers acceptable detection accuracy while maintaining computational efficiency close to SNN-only implementations, which operate at a fraction of the resource cost. This framework represents a significant advancement in neuromorphic navigation systems for robots operating in unpredictable and dynamic environments.

</details>


### [335] [The OncoReach Stylet for Brachytherapy: Design Evaluation and Pilot Study](https://arxiv.org/abs/2601.13529)
*Pejman Kheradmand,Kent K. Yamamoto,Emma Webster,Keith Sowards,Gianna Hatheway,Katharine L. Jackson,Sabino Zani,Julie A. Raffi,Diandra N. Ayala-Peacock,Scott R. Silva,Joanna Deaton Bertram,Yash Chitalia*

Main category: cs.RO

TL;DR: OncoReach可操纵性针头通过优化设计和实验验证，成功实现了在宫颈癌治疗中从内侧入口转向外侧目标的能力，提升了治疗灵活性。


<details>
  <summary>Details</summary>
Motivation: 传统的直线针头限制了手术规划的线性路径，无法有效到达侧向目标，因此需要开发可操纵性针头以提高治疗精度和效果。

Method: 通过评估设计参数（如针头规格、球形关节数量和位置）并开发不对称盘设计，优化了弯曲顺从性和轴向刚度。使用自由空间实验量化尖端偏转，并采用两管Cosserat杆模型预测针头中心线形状。最佳配置被集成到可重复使用的手持原型中。

Result: 实验表明，OncoReach可操纵性针头能够从微创内侧入口转向到达最外侧目标，验证了其临床应用的可行性。

Conclusion: OncoReach steerable stylet展示了在宫颈癌间质近距离放射治疗中通过可操纵性针头达到侧向目标的潜力，强调了可操纵性针头在临床中的重要性。

Abstract: Cervical cancer accounts for a significant portion of the global cancer burden among women. Interstitial brachytherapy (ISBT) is a standard procedure for treating cervical cancer; it involves placing a radioactive source through a straight hollow needle within or in close proximity to the tumor and surrounding tissue. However, the use of straight needles limits surgical planning to a linear needle path. We present the OncoReach stylet, a handheld, tendon-driven steerable stylet designed for compatibility with standard ISBT 15- and 13-gauge needles. Building upon our prior work, we evaluated design parameters like needle gauge, spherical joint count and spherical joint placement, including an asymmetric disk design to identify a configuration that maximizes bending compliance while retaining axial stiffness. Free space experiments quantified tip deflection across configurations, and a two-tube Cosserat rod model accurately predicted the centerline shape of the needle for most trials. The best performing configuration was integrated into a reusable handheld prototype that enables manual actuation. A patient-derived, multi-composite phantom model of the uterus and pelvis was developed to conduct a pilot study of the OncoReach steerable stylet with one expert user. Results showed the ability to steer from less-invasive, medial entry points to reach the lateral-most targets, underscoring the significance of steerable stylets.

</details>


### [336] [LogicEnvGen: Task-Logic Driven Generation of Diverse Simulated Environments for Embodied AI](https://arxiv.org/abs/2601.13556)
*Jianan Wang,Siyang Zhang,Bin Li,Juan Chen,Jingtao Qi,Zhuo Zhang,Chen Qian*

Main category: cs.RO

TL;DR: LogicEnvGen利用LLM生成逻辑多样化的模拟环境，显著提升代理测试效果。


<details>
  <summary>Details</summary>
Motivation: 现有环境生成方法过于关注视觉真实性，忽视了逻辑多样性，限制了代理适应性和规划鲁棒性的全面评估。

Method: 采用LLM分析任务执行逻辑，构建决策树行为计划，生成逻辑轨迹并通过启发式算法优化，最终实例化为具体环境。

Result: 实验证明LogicEnvGen的逻辑多样性比基线高1.04-2.61倍，显著提升了代理故障检测性能。

Conclusion: LogicEnvGen通过LLM驱动的自上而下方法生成逻辑多样化的模拟环境，显著提升了代理故障检测性能（4.00%-68.00%）。

Abstract: Simulated environments play an essential role in embodied AI, functionally analogous to test cases in software engineering. However, existing environment generation methods often emphasize visual realism (e.g., object diversity and layout coherence), overlooking a crucial aspect: logical diversity from the testing perspective. This limits the comprehensive evaluation of agent adaptability and planning robustness in distinct simulated environments. To bridge this gap, we propose LogicEnvGen, a novel method driven by Large Language Models (LLMs) that adopts a top-down paradigm to generate logically diverse simulated environments as test cases for agents. Given an agent task, LogicEnvGen first analyzes its execution logic to construct decision-tree-structured behavior plans and then synthesizes a set of logical trajectories. Subsequently, it adopts a heuristic algorithm to refine the trajectory set, reducing redundant simulation. For each logical trajectory, which represents a potential task situation, LogicEnvGen correspondingly instantiates a concrete environment. Notably, it employs constraint solving for physical plausibility. Furthermore, we introduce LogicEnvEval, a novel benchmark comprising four quantitative metrics for environment evaluation. Experimental results verify the lack of logical diversity in baselines and demonstrate that LogicEnvGen achieves 1.04-2.61x greater diversity, significantly improving the performance in revealing agent faults by 4.00%-68.00%.

</details>


### [337] [Highly Deformable Proprioceptive Membrane for Real-Time 3D Shape Reconstruction](https://arxiv.org/abs/2601.13574)
*Guanyu Xu,Jiaqi Wang,Dezhong Tong,Xiaonan Huang*

Main category: cs.RO

TL;DR: 该论文提出了一种基于光学波导的膜传感器，通过解码光强信号实时重建3D几何形状，适用于可变形机器人系统的形状感知。


<details>
  <summary>Details</summary>
Motivation: 视觉方法在低光照或遮挡条件下不可靠，传统形状感知膜存在结构复杂、大变形适应性差和易受电磁干扰等挑战，这促使设计一种新型膜传感器。

Method: 通过集成边缘安装的LED和中心分布的光电二极管（PDs），并通过多层弹性复合材料中的液态金属迹线连接，利用数据驱动模型解码丰富的变形依赖光强信号，恢复膜的三维点云几何形状。

Result: 在140毫米方形膜上，实现了90 Hz的大规模平面外变形实时重建，平均重建误差为1.3毫米，且在25毫米凹陷范围内保持准确性。

Conclusion: 该研究提出了一种基于光学波导传感的柔软、灵活且可拉伸的膜传感器，为可变形机器人系统提供了一种可扩展、稳健且低成本的全局形状感知解决方案。

Abstract: Reconstructing the three-dimensional (3D) geometry of object surfaces is essential for robot perception, yet vision-based approaches are generally unreliable under low illumination or occlusion. This limitation motivates the design of a proprioceptive membrane that conforms to the surface of interest and infers 3D geometry by reconstructing its own deformation. Conventional shape-aware membranes typically rely on resistive, capacitive, or magneto-sensitive mechanisms. However, these methods often encounter challenges such as structural complexity, limited compliance during large-scale deformation, and susceptibility to electromagnetic interference. This work presents a soft, flexible, and stretchable proprioceptive silicone membrane based on optical waveguide sensing. The membrane sensor integrates edge-mounted LEDs and centrally distributed photodiodes (PDs), interconnected via liquid-metal traces embedded within a multilayer elastomeric composite. Rich deformation-dependent light intensity signals are decoded by a data-driven model to recover the membrane geometry as a 3D point cloud. On a customized 140 mm square membrane, real-time reconstruction of large-scale out-of-plane deformation is achieved at 90 Hz with an average reconstruction error of 1.3 mm, measured by Chamfer distance, while maintaining accuracy for indentations up to 25 mm. The proposed framework provides a scalable, robust, and low-profile solution for global shape perception in deformable robotic systems.

</details>


### [338] [A General One-Shot Multimodal Active Perception Framework for Robotic Manipulation: Learning to Predict Optimal Viewpoint](https://arxiv.org/abs/2601.13639)
*Deyun Qin,Zezhi Liu,Hanqian Luo,Xiao Liang,Yongchun Fang*

Main category: cs.RO

TL;DR: 提出了一种通用的单次多模态主动感知框架，通过数据收集和预测网络直接推断最优视点，显著提升抓取成功率并实现无缝仿真到现实迁移。


<details>
  <summary>Details</summary>
Motivation: 现有主动感知方法依赖迭代优化，时间和运动成本高，且与任务特定目标紧密耦合，限制了其可迁移性。

Method: 框架包括数据收集流程和最优视点预测网络，通过系统采样和评估候选视点定义最优视点，并利用跨注意力对齐和融合多模态特征直接预测相机姿态调整。

Result: 实验结果表明，框架引导的主动感知显著提高了抓取成功率，真实世界评估中抓取成功率几乎翻倍。

Conclusion: 所提出的框架显著提高了抓取成功率，并实现了无缝的仿真到现实的迁移，无需额外微调，证明了其有效性。

Abstract: Active perception in vision-based robotic manipulation aims to move the camera toward more informative observation viewpoints, thereby providing high-quality perceptual inputs for downstream tasks. Most existing active perception methods rely on iterative optimization, leading to high time and motion costs, and are tightly coupled with task-specific objectives, which limits their transferability. In this paper, we propose a general one-shot multimodal active perception framework for robotic manipulation. The framework enables direct inference of optimal viewpoints and comprises a data collection pipeline and an optimal viewpoint prediction network. Specifically, the framework decouples viewpoint quality evaluation from the overall architecture, supporting heterogeneous task requirements. Optimal viewpoints are defined through systematic sampling and evaluation of candidate viewpoints, after which large-scale training datasets are constructed via domain randomization. Moreover, a multimodal optimal viewpoint prediction network is developed, leveraging cross-attention to align and fuse multimodal features and directly predict camera pose adjustments. The proposed framework is instantiated in robotic grasping under viewpoint-constrained environments. Experimental results demonstrate that active perception guided by the framework significantly improves grasp success rates. Notably, real-world evaluations achieve nearly double the grasp success rate and enable seamless sim-to-real transfer without additional fine-tuning, demonstrating the effectiveness of the proposed framework.

</details>


### [339] [Communication-Free Collective Navigation for a Swarm of UAVs via LiDAR-Based Deep Reinforcement Learning](https://arxiv.org/abs/2601.13657)
*Myong-Yol Choi,Hankyoul Ko,Hanse Cho,Changseung Kim,Seunghwan Kim,Jaemin Seo,Hyondong Oh*

Main category: cs.RO

TL;DR: 提出基于DRL的无人机群无通信集体导航方法，结合LiDAR和扩展卡尔曼滤波，实验验证了鲁棒性和实际应用效果。


<details>
  <summary>Details</summary>
Motivation: 受生物群体中无需显式通信即可导航的启发，旨在解决无人机群在通信受限环境中的集体导航问题。

Method: 采用深度强化学习（DRL）控制器，结合LiDAR点聚类和扩展卡尔曼滤波进行邻居跟踪，无需外部定位系统。训练在Nvidia Isaac Sim中完成，利用GPU加速。

Result: 通过仿真和五架无人机的真实实验验证了方法的鲁棒性和从仿真到现实的迁移能力，成功在多样化的室内外环境中实现集体导航。

Conclusion: 该论文提出了一种基于深度强化学习（DRL）的控制方法，成功实现了无人机群在无通信环境下的集体导航，并在复杂、多障碍环境中展现了鲁棒性。通过仿真和真实实验验证了方法的有效性。

Abstract: This paper presents a deep reinforcement learning (DRL) based controller for collective navigation of unmanned aerial vehicle (UAV) swarms in communication-denied environments, enabling robust operation in complex, obstacle-rich environments. Inspired by biological swarms where informed individuals guide groups without explicit communication, we employ an implicit leader-follower framework. In this paradigm, only the leader possesses goal information, while follower UAVs learn robust policies using only onboard LiDAR sensing, without requiring any inter-agent communication or leader identification. Our system utilizes LiDAR point clustering and an extended Kalman filter for stable neighbor tracking, providing reliable perception independent of external positioning systems. The core of our approach is a DRL controller, trained in GPU-accelerated Nvidia Isaac Sim, that enables followers to learn complex emergent behaviors - balancing flocking and obstacle avoidance - using only local perception. This allows the swarm to implicitly follow the leader while robustly addressing perceptual challenges such as occlusion and limited field-of-view. The robustness and sim-to-real transfer of our approach are confirmed through extensive simulations and challenging real-world experiments with a swarm of five UAVs, which successfully demonstrated collective navigation across diverse indoor and outdoor environments without any communication or external localization.

</details>


### [340] [SUNSET -- A Sensor-fUsioN based semantic SegmEnTation exemplar for ROS-based self-adaptation](https://arxiv.org/abs/2601.13732)
*Andreas Wiedholz,Rafael Paintner,Julian Gleißner,Alwin Hoffmann,Tobias Huber*

Main category: cs.RO

TL;DR: SUNSET是一个ROS2示例，用于评估动态环境中机器人软件的自我适应能力，通过传感器融合和ML模型模拟性能下降，支持并发不确定性研究。


<details>
  <summary>Details</summary>
Motivation: 随着机器人在动态环境中的部署增加及其软件系统复杂性的提升，需要自我适应方法来应对（1）症状易观察但根本原因模糊的不确定性，或（2）多个不确定性并发出现的情况。

Method: SUNSET实现了一个由机器学习模型驱动的传感器融合语义分割管道，其输入预处理可被扰动以模拟性能下降。它提供了五个可观察症状，每个症状可能由不同根本原因引起，并支持并发的不确定性，涵盖自我修复和自我优化。

Result: SUNSET包含分割管道、训练好的ML模型、不确定性注入脚本、基线控制器以及逐步集成和评估文档，以支持可重复研究和公平比较。

Conclusion: SUNSET是一个基于ROS2的示例，旨在为架构驱动的自我适应提供严格且可重复的评估，特别适用于动态环境中机器人软件系统面临的不确定性和并发性问题。

Abstract: The fact that robots are getting deployed more often in dynamic environments, together with the increasing complexity of their software systems, raises the need for self-adaptive approaches. In these environments robotic software systems increasingly operate amid (1) uncertainties, where symptoms are easy to observe but root causes are ambiguous, or (2) multiple uncertainties appear concurrently. We present SUNSET, a ROS2-based exemplar that enables rigorous, repeatable evaluation of architecture-based self-adaptation in such conditions. It implements a sensor fusion semantic-segmentation pipeline driven by a trained Machine Learning (ML) model whose input preprocessing can be perturbed to induce realistic performance degradations. The exemplar exposes five observable symptoms, where each can be caused by different root causes and supports concurrent uncertainties spanning self-healing and self-optimisation. SUNSET includes the segmentation pipeline, a trained ML model, uncertainty-injection scripts, a baseline controller, and step-by-step integration and evaluation documentation to facilitate reproducible studies and fair comparison.

</details>


### [341] [RIM Hand : A Robotic Hand with an Accurate Carpometacarpal Joint and Nitinol-Supported Skeletal Structure](https://arxiv.org/abs/2601.13737)
*Joon Lee,Jeongyoon Han,Doyoung Kim,Seokhwan Jeong*

Main category: cs.RO

TL;DR: RIM Hand 是一种仿生机器人手，通过Nitinol线和腱驱动设计实现高灵活性和负载能力，适用于假肢和机器人服务。


<details>
  <summary>Details</summary>
Motivation: 设计一种能够精确复制人类手腕关节并增强关节恢复和骨骼结构支持的仿生机器人手。

Method: 通过建模完整的腕骨到掌骨解剖结构，采用超弹性Nitinol线作为骨骼框架，并结合腱驱动手指和柔性硅胶皮肤。

Result: 实验显示，手掌变形可达28%，匹配人类手的灵活性，同时负载能力和接触面积分别是刚性手掌设计的两倍和三倍。

Conclusion: RIM Hand 提供了更高的灵活性、顺从性和拟人化特性，适用于假肢和服务机器人应用。

Abstract: This paper presents the flexible RIM Hand, a biomimetic robotic hand that precisely replicates the carpometacarpal (CMC) joints and employs superelastic Nitinol wires throughout its skeletal framework. By modeling the full carpal-to-metacarpal anatomy, the design enables realistic palm deformation through tendon-driven fingers while enhancing joint restoration and supports skeletal structure with Nitinol-based dorsal extensors. A flexible silicone skin further increases contact friction and contact area, enabling stable grasps for diverse objects. Experiments show that the palm can deform up to 28%, matching human hand flexibility, while achieving more than twice the payload capacity and three times the contact area compared to a rigid palm design. The RIM Hand thus offers improved dexterity, compliance, and anthropomorphism, making it promising for prosthetic and service-robot applications.

</details>


### [342] [Sample Efficient Learning of Body-Environment Interaction of an Under-Actuated System](https://arxiv.org/abs/2601.13777)
*Zvi Chapnik,Yizhar Or,Shai Revzen*

Main category: cs.RO

TL;DR: 比较了四种学习‘运动图’的方法，发现简单方法在小数据集上更优，复杂方法在大数据集上更优。


<details>
  <summary>Details</summary>
Motivation: 通过几何力学研究生物和机器人系统如何利用形状变化与环境机械交互来移动，特别是在高摩擦环境中。

Method: 比较了四种建模方法，评估它们在同一步态、跨步态和跨速度下从形状变化预测身体速度的能力。

Result: 结果显示，不同方法在预测身体速度方面表现各异，取决于训练数据量的大小。

Conclusion: 研究表明，在训练数据量不同时，简单方法与复杂方法之间存在权衡：简单方法在小数据集上表现更优，而复杂方法在大数据集上表现更佳。

Abstract: Geometric mechanics provides valuable insights into how biological and robotic systems use changes in shape to move by mechanically interacting with their environment. In high-friction environments it provides that the entire interaction is captured by the ``motility map''. Here we compare methods for learning the motility map from motion tracking data of a physical robot created specifically to test these methods by having under-actuated degrees of freedom and a hard to model interaction with its substrate. We compared four modeling approaches in terms of their ability to predict body velocity from shape change within the same gait, across gaits, and across speeds. Our results show a trade-off between simpler methods which are superior on small training datasets, and more sophisticated methods, which are superior when more training data is available.

</details>


### [343] [HoverAI: An Embodied Aerial Agent for Natural Human-Drone Interaction](https://arxiv.org/abs/2601.13801)
*Yuhua Jin,Nikita Kuzmin,Georgii Demianchuk,Mariya Lezina,Fawad Mehboob,Issatay Tokmurziyev,Miguel Altamirano Cabrera,Muhammad Ahsan Mustafa,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: HoverAI是一种集成了无人机移动性、视觉投影和对话AI的实体代理，通过多模态技术实现高精度的命令识别和个性化交互。


<details>
  <summary>Details</summary>
Motivation: 无人机在人类活动空间中运行时，由于通信机制不足，导致其意图不明确，这促使了HoverAI的开发。

Method: HoverAI采用多模态管道，结合语音活动检测（VAD）、自动语音识别（ASR，使用Whisper）、基于LLM的意图分类、RAG对话、面部分析个性化以及语音合成（XTTS v2）。系统配备了MEMS激光投影仪、半刚性屏幕和RGB摄像头。

Result: 评估显示，HoverAI在命令识别（F1: 0.90）、人口统计估计（性别F1: 0.89，年龄MAE: 5.14岁）和语音转录（WER: 0.181）方面表现出高准确性。

Conclusion: HoverAI通过整合无人机移动性、独立于基础设施的视觉投影和实时对话AI，创造了一种新型的空间感知、社会响应型实体代理，适用于引导、辅助和以人为中心的交互应用。

Abstract: Drones operating in human-occupied spaces suffer from insufficient communication mechanisms that create uncertainty about their intentions. We present HoverAI, an embodied aerial agent that integrates drone mobility, infrastructure-independent visual projection, and real-time conversational AI into a unified platform. Equipped with a MEMS laser projector, onboard semi-rigid screen, and RGB camera, HoverAI perceives users through vision and voice, responding via lip-synced avatars that adapt appearance to user demographics. The system employs a multimodal pipeline combining VAD, ASR (Whisper), LLM-based intent classification, RAG for dialogue, face analysis for personalization, and voice synthesis (XTTS v2). Evaluation demonstrates high accuracy in command recognition (F1: 0.90), demographic estimation (gender F1: 0.89, age MAE: 5.14 years), and speech transcription (WER: 0.181). By uniting aerial robotics with adaptive conversational AI and self-contained visual output, HoverAI introduces a new class of spatially-aware, socially responsive embodied agents for applications in guidance, assistance, and human-centered interaction.

</details>


### [344] [DroneVLA: VLA based Aerial Manipulation](https://arxiv.org/abs/2601.13809)
*Fawad Mehboob,Monijesu James,Amir Habel,Jeffrin Sam,Miguel Altamirano Cabrera,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: 提出了一种基于自然语言命令的自主空中操作系统，结合VLA模型和实时姿态估计，实现了高效安全的物体抓取与交付。


<details>
  <summary>Details</summary>
Motivation: 设计直观的自然语言接口，使非专业用户能轻松操控主动式空中平台。

Method: 结合Grounding DINO和动态A*规划算法进行导航与抓取，采用MediaPipe实现实时人体姿态估计以优化交互。

Result: 实验显示定位与导航的最大、平均欧几里得和均方根误差分别为0.164m、0.070m和0.084m。

Conclusion: 该系统通过自然语言命令实现了高效的空中抓取与交付操作，验证了VLA模型在无人机操作中的可行性。

Abstract: As aerial platforms evolve from passive observers to active manipulators, the challenge shifts toward designing intuitive interfaces that allow non-expert users to command these systems naturally. This work introduces a novel concept of autonomous aerial manipulation system capable of interpreting high-level natural language commands to retrieve objects and deliver them to a human user. The system is intended to integrate a MediaPipe based on Grounding DINO and a Vision-Language-Action (VLA) model with a custom-built drone equipped with a 1-DOF gripper and an Intel RealSense RGB-D camera. VLA performs semantic reasoning to interpret the intent of a user prompt and generates a prioritized task queue for grasping of relevant objects in the scene. Grounding DINO and dynamic A* planning algorithm are used to navigate and safely relocate the object. To ensure safe and natural interaction during the handover phase, the system employs a human-centric controller driven by MediaPipe. This module provides real-time human pose estimation, allowing the drone to employ visual servoing to maintain a stable, distinct position directly in front of the user, facilitating a comfortable handover. We demonstrate the system's efficacy through real-world experiments for localization and navigation, which resulted in a 0.164m, 0.070m, and 0.084m of max, mean euclidean, and root-mean squared errors, respectively, highlighting the feasibility of VLA for aerial manipulation operations.

</details>


### [345] [GuideTouch: An Obstacle Avoidance Device for Visually Impaired](https://arxiv.org/abs/2601.13813)
*Timofei Kozlov,Artem Trandofilov,Georgii Gazaryan,Issatay Tokmurziyev,Miguel Altamirano Cabrera,Dzmitry Tsetserukou*

Main category: cs.RO

TL;DR: GuideTouch是一款经济实惠的独立可穿戴设备，通过ToF传感器和触觉反馈帮助视障用户避开障碍物，实验证明其高识别准确率和实用性。


<details>
  <summary>Details</summary>
Motivation: 针对视障人士在导航中难以检测头部高度障碍物的关键挑战，传统辅助工具无法满足需求。

Method: 系统集成了两个垂直排列的ToF传感器和四个振动触觉执行器，通过4点触觉反馈系统传达障碍物的接近和方向信息，并配备了自清洁光学盖和声音警报功能。

Result: 在22名参与者中，系统对单双电机（主要方向）模式的识别准确率平均达92.9%；14名视障用户的初步实验显示主要方向线索识别准确率为93.75%。

Conclusion: GuideTouch通过直观的触觉反馈系统显著提升了视障用户的导航安全性和自主性，验证了其在实际应用中的有效性。

Abstract: Safe navigation for the visually impaired individuals remains a critical challenge, especially concerning head-level obstacles, which traditional mobility aids often fail to detect. We introduce GuideTouch, a compact, affordable, standalone wearable device designed for autonomous obstacle avoidance. The system integrates two vertically aligned Time-of-Flight (ToF) sensors, enabling three-dimensional environmental perception, and four vibrotactile actuators that provide directional haptic feedback. Proximity and direction information is communicated via an intuitive 4-point vibrotactile feedback system located across the user's shoulders and upper chest. For real-world robustness, the device includes a unique centrifugal self-cleaning optical cover mechanism and a sound alarm system for location if the device is dropped. We evaluated the haptic perception accuracy across 22 participants (17 male and 5 female, aged 21-48, mean 25.7, sd 6.1). Statistical analysis confirmed a significant difference between the perception accuracy of different patterns. The system demonstrated high recognition accuracy, achieving an average of 92.9% for single and double motor (primary directional) patterns. Furthermore, preliminary experiments with 14 visually impaired users validated this interface, showing a recognition accuracy of 93.75% for primary directional cues. The results demonstrate that GuideTouch enables intuitive spatial perception and could significantly improve the safety, confidence, and autonomy of users with visual impairments during independent navigation.

</details>


### [346] [Efficient Coordination with the System-Level Shared State: An Embodied-AI Native Modular Framework](https://arxiv.org/abs/2601.13945)
*Yixuan Deng,Tongrun Wu,Donghao Wu,Zeyu Wei,Jiayuan Wang,Zhenglong Sun,Yuqing Tang,Xiaoqiang Ji*

Main category: cs.RO

TL;DR: ANCHOR 是一个模块化框架，通过明确解耦和鲁棒性作为系统级原语，解决了 Embodied AI 系统部署中的接口漂移和脆弱恢复问题。


<details>
  <summary>Details</summary>
Motivation: 随着 Embodied AI 系统从研究原型转向实际部署，它们需要快速演化并在工作负载变化和部分故障下保持可靠。实践中，许多部署仅部分解耦，导致接口漂移、跨模块干扰和大规模下的脆弱恢复。

Method: ANCHOR 分离了 (i) 可演化的标准化共享状态合同（Canonical Records）和 (ii) 用于多对多传播和反馈导向协调的通信总线，形成可检查的端到端循环。

Result: 通过去标识化的工作流实例验证了闭环可行性，表征了不同负载大小和发布速率下的延迟分布，并展示了在共享内存丢失后自动流恢复的能力。

Conclusion: ANCHOR 将临时集成粘合剂转化为明确的合同，实现了在负载下的可控降级和自我修复恢复，为闭环AI系统的可扩展部署提供了支持。

Abstract: As Embodied AI systems move from research prototypes to real world deployments, they tend to evolve rapidly while remaining reliable under workload changes and partial failures. In practice, many deployments are only partially decoupled: middleware moves messages, but shared context and feedback semantics are implicit, causing interface drift, cross-module interference, and brittle recovery at scale. We present ANCHOR, a modular framework that makes decoupling and robustness explicit system-level primitives. ANCHOR separates (i) Canonical Records, an evolvable contract for the standardized shared state, from (ii) a communication bus for many-to-many dissemination and feedback-oriented coordination, forming an inspectable end-to-end loop. We validate closed-loop feasibility on a de-identified workflow instantiation, characterize latency distributions under varying payload sizes and publish rates, and demonstrate automatic stream resumption after hard crashes and restarts even with shared-memory loss. Overall, ANCHOR turns ad-hoc integration glue into explicit contracts, enabling controlled degradation under load and self-healing recovery for scalable deployment of closed-loop AI systems.

</details>


### [347] [Active Cross-Modal Visuo-Tactile Perception of Deformable Linear Objects](https://arxiv.org/abs/2601.13979)
*Raffaele Mazza,Ciro Natale,Pietro Falco*

Main category: cs.RO

TL;DR: 提出了一种结合视觉与触觉的跨模态感知框架，用于在严重遮挡下重建电缆3D形状，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖视觉，在光照变化、背景杂乱或部分可见性差的情况下性能下降，因此需要一种能结合视觉与触觉的鲁棒方法。

Method: 提出了一种基于基础模型的视觉感知与自适应触觉探索相结合的框架，包括视觉实例分割、语义细化、骨架化、端点检测、点云提取，以及触觉探索后的点云融合与B样条插值。

Result: 实验验证表明，该框架能准确重建简单或高度弯曲的单根或多根电缆形状，即使大部分被遮挡。

Conclusion: 该框架通过结合视觉与触觉感知，成功实现了在严重视觉遮挡情况下对可变形线性物体（如电缆）的3D形状重建，展示了跨模态感知在机器人操作可变形物体中的潜力。

Abstract: This paper presents a novel cross-modal visuo-tactile perception framework for the 3D shape reconstruction of deformable linear objects (DLOs), with a specific focus on cables subject to severe visual occlusions. Unlike existing methods relying predominantly on vision, whose performance degrades under varying illumination, background clutter, or partial visibility, the proposed approach integrates foundation-model-based visual perception with adaptive tactile exploration. The visual pipeline exploits SAM for instance segmentation and Florence for semantic refinement, followed by skeletonization, endpoint detection, and point-cloud extraction. Occluded cable segments are autonomously identified and explored with a tactile sensor, which provides local point clouds that are merged with the visual data through Euclidean clustering and topology-preserving fusion. A B-spline interpolation driven by endpoint-guided point sorting yields a smooth and complete reconstruction of the cable shape. Experimental validation using a robotic manipulator equipped with an RGB-D camera and a tactile pad demonstrates that the proposed framework accurately reconstructs both simple and highly curved single or multiple cable configurations, even when large portions are occluded. These results highlight the potential of foundation-model-enhanced cross-modal perception for advancing robotic manipulation of deformable objects.

</details>


### [348] [Group-Invariant Unsupervised Skill Discovery: Symmetry-aware Skill Representations for Generalizable Behavior](https://arxiv.org/abs/2601.14000)
*Junwoo Chang,Joseph Park,Roberto Horowitz,Jongmin Lee,Jongeun Choi*

Main category: cs.RO

TL;DR: GISD框架通过群结构嵌入技能发现目标，解决了对称性忽视问题，提升了样本效率和下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有无监督技能发现方法常忽视物理环境的几何对称性，导致行为冗余和样本效率低下。

Method: 提出了Group-Invariant Skill Discovery (GISD)框架，通过群不变Wasserstein依赖度量优化对称感知子空间，并利用群傅里叶表示参数化评分函数。

Result: 在基于状态和像素的运动基准测试中，GISD相比强基线实现了更广泛的状态空间覆盖和下游任务学习效率的提升。

Conclusion: GISD框架通过显式嵌入群结构到技能发现目标中，解决了现有方法忽视物理环境几何对称性的问题，实现了更广泛的状态空间覆盖和下游任务学习效率的提升。

Abstract: Unsupervised skill discovery aims to acquire behavior primitives that improve exploration and accelerate downstream task learning. However, existing approaches often ignore the geometric symmetries of physical environments, leading to redundant behaviors and sample inefficiency. To address this, we introduce Group-Invariant Skill Discovery (GISD), a framework that explicitly embeds group structure into the skill discovery objective. Our approach is grounded in a theoretical guarantee: we prove that in group-symmetric environments, the standard Wasserstein dependency measure admits a globally optimal solution comprised of an equivariant policy and a group-invariant scoring function. Motivated by this, we formulate the Group-Invariant Wasserstein dependency measure, which restricts the optimization to this symmetry-aware subspace without loss of optimality. Practically, we parameterize the scoring function using a group Fourier representation and define the intrinsic reward via the alignment of equivariant latent features, ensuring that the discovered skills generalize systematically under group transformations. Experiments on state-based and pixel-based locomotion benchmarks demonstrate that GISD achieves broader state-space coverage and improved efficiency in downstream task learning compared to a strong baseline.

</details>


### [349] [Zero-shot adaptable task planning for autonomous construction robots: a comparative study of lightweight single and multi-AI agent systems](https://arxiv.org/abs/2601.14091)
*Hossein Naderi,Alireza Shojaei,Lifu Huang,Philip Agee,Kereshmeh Afsari,Abiola Akanmu*

Main category: cs.RO

TL;DR: 研究利用轻量级LLMs/VLMs构建多智能体团队，显著提升建筑机器人任务规划的适应性和成本效益，优于GPT-4o。


<details>
  <summary>Details</summary>
Motivation: 建筑机器人因高成本和动态任务适应性差而面临挑战，研究旨在通过基础模型提升其任务规划的适应性和泛化能力。

Method: 提出了四种模型，包括一个单智能体和三个多智能体团队，利用轻量级开源大型语言模型（LLMs）和视觉语言模型（VLMs）实现机器人动作规划。

Result: 四智能体团队在多数指标上优于GPT-4o，且成本效益高出十倍；三和四智能体团队表现出更好的泛化能力。

Conclusion: 本研究通过探索基础模型在建筑机器人任务规划中的应用，证明了多智能体团队在提升适应性和泛化能力方面的潜力，为未来在非结构化环境中的AI团队研究提供了支持。

Abstract: Robots are expected to play a major role in the future construction industry but face challenges due to high costs and difficulty adapting to dynamic tasks. This study explores the potential of foundation models to enhance the adaptability and generalizability of task planning in construction robots. Four models are proposed and implemented using lightweight, open-source large language models (LLMs) and vision language models (VLMs). These models include one single agent and three multi-agent teams that collaborate to create robot action plans. The models are evaluated across three construction roles: Painter, Safety Inspector, and Floor Tiling. Results show that the four-agent team outperforms the state-of-the-art GPT-4o in most metrics while being ten times more cost-effective. Additionally, teams with three and four agents demonstrate the improved generalizability. By discussing how agent behaviors influence outputs, this study enhances the understanding of AI teams and supports future research in diverse unstructured environments beyond construction.

</details>


### [350] [Diffusion-Guided Backdoor Attacks in Real-World Reinforcement Learning](https://arxiv.org/abs/2601.14104)
*Tairan Huang,Qingqing Ye,Yulin Jin,Jiawei Lian,Yi Wang,Haibo Hu*

Main category: cs.RO

TL;DR: DGBA通过扩散模型生成视觉触发器，结合优势投毒策略，在真实RL系统中实现高效后门攻击，克服安全约束导致的攻击衰减问题。


<details>
  <summary>Details</summary>
Motivation: 现有后门攻击主要在仿真环境中验证，真实机器人系统中因安全约束控制管道（如速度限制、碰撞避免）导致攻击效果衰减，需研究适用于真实RL的后门攻击框架。

Method: 设计了小型可打印视觉补丁触发器，利用条件扩散模型生成多样化外观；采用基于优势的投毒策略，仅在决策关键状态注入触发器。

Result: 在TurtleBot3移动机器人上验证，DGBA能可靠激活目标攻击且不影响正常任务性能。

Conclusion: DGBA框架通过扩散模型生成多样化视觉触发器，结合基于优势的投毒策略，在真实机器人系统中实现了可靠的后门攻击激活，同时保持正常任务性能。

Abstract: Backdoor attacks embed hidden malicious behaviors in reinforcement learning (RL) policies and activate them using triggers at test time. Most existing attacks are validated only in simulation, while their effectiveness in real-world robotic systems remains unclear. In physical deployment, safety-constrained control pipelines such as velocity limiting, action smoothing, and collision avoidance suppress abnormal actions, causing strong attenuation of conventional backdoor attacks. We study this previously overlooked problem and propose a diffusion-guided backdoor attack framework (DGBA) for real-world RL. We design small printable visual patch triggers placed on the floor and generate them using a conditional diffusion model that produces diverse patch appearances under real-world visual variations. We treat the robot control stack as a black-box system. We further introduce an advantage-based poisoning strategy that injects triggers only at decision-critical training states. We evaluate our method on a TurtleBot3 mobile robot and demonstrate reliable activation of targeted attacks while preserving normal task performance. Demo videos and code are available in the supplementary material.

</details>


### [351] [SandWorm: Event-based Visuotactile Perception with Active Vibration for Screw-Actuated Robot in Granular Media](https://arxiv.org/abs/2601.14128)
*Shoujie Li,Changqing Guo,Junhao Gong,Chenxin Liang,Wenhua Ding,Wenbo Ding*

Main category: cs.RO

TL;DR: SandWorm和SWTac系统通过生物仿生设计和事件驱动传感器，显著提升了在颗粒介质中的移动和感知性能。


<details>
  <summary>Details</summary>
Motivation: 解决颗粒介质中不可预测的粒子动态带来的感知挑战。

Method: 提出了SandWorm生物仿生螺旋驱动机器人，结合蠕动运动增强移动性；开发了SWTac事件驱动的视觉触觉传感器，采用弹簧隔离机制和主动振动弹性体。设计了IMU引导的时间滤波器优化成像，并通过振动参数、事件相机设置和弹性体特性系统优化SWTac。

Result: SWTac实现了0.2毫米的纹理分辨率、98%的石头分类准确率和0.15 N的力估计误差；SandWorm在复杂地形中展示了高达12.5毫米/秒的移动性，管道疏浚和地下探索成功率达90%。

Conclusion: SandWorm和SWTac系统在复杂颗粒介质中表现出卓越的移动性和感知能力，验证了其在实际应用中的潜力。

Abstract: Perception in granular media remains challenging due to unpredictable particle dynamics. To address this challenge, we present SandWorm, a biomimetic screw-actuated robot augmented by peristaltic motion to enhance locomotion, and SWTac, a novel event-based visuotactile sensor with an actively vibrated elastomer. The event camera is mechanically decoupled from vibrations by a spring isolation mechanism, enabling high-quality tactile imaging of both dynamic and stationary objects. For algorithm design, we propose an IMU-guided temporal filter to enhance imaging consistency, improving MSNR by 24%. Moreover, we systematically optimize SWTac with vibration parameters, event camera settings and elastomer properties. Motivated by asymmetric edge features, we also implement contact surface estimation by U-Net. Experimental validation demonstrates SWTac's 0.2 mm texture resolution, 98% stone classification accuracy, and 0.15 N force estimation error, while SandWorm demonstrates versatile locomotion (up to 12.5 mm/s) in challenging terrains, successfully executes pipeline dredging and subsurface exploration in complex granular media (observed 90% success rate). Field experiments further confirm the system's practical performance.

</details>


### [352] [TwinBrainVLA: Unleashing the Potential of Generalist VLMs for Embodied Tasks via Asymmetric Mixture-of-Transformers](https://arxiv.org/abs/2601.14133)
*Bin Yu,Shijie Lian,Xiaopeng Lin,Yuliang Wei,Zhaolong Shen,Changti Wu,Yuzhuo Miao,Xinming Wang,Bailing Wang,Cong Huang,Kai Chen*

Main category: cs.RO

TL;DR: TwinBrainVLA通过协调通用和专用视觉语言模型，解决了传统VLA模型的“灾难性遗忘”问题，实现了高级语义理解和低级运动控制的平衡，并在实验中表现出色。


<details>
  <summary>Details</summary>
Motivation: 传统VLA模型在微调过程中往往导致“灾难性遗忘”，即模型在追求低级传感器运动技能时丧失高级语义理解能力。TwinBrainVLA旨在解决这一冲突。

Method: TwinBrainVLA采用了一种新颖的非对称混合变换器（AsyMoT）机制，将冻结的“左脑”（保留通用视觉推理能力）与可训练的“右脑”（专注于具体感知）协同工作，动态查询语义知识并与本体感觉状态融合。

Result: 在SimplerEnv和RoboCasa基准测试中，TwinBrainVLA表现出优于现有基线的操作性能，同时明确保留了预训练VLM的全面视觉理解能力。

Conclusion: TwinBrainVLA通过协调通用视觉语言模型和专用视觉语言模型，解决了传统VLA模型在保持高级语义理解和学习低级传感器运动技能之间的冲突，为构建同时具备高级语义理解和低级物理灵活性的通用机器人提供了有前景的方向。

Abstract: Standard Vision-Language-Action (VLA) models typically fine-tune a monolithic Vision-Language Model (VLM) backbone explicitly for robotic control. However, this approach creates a critical tension between maintaining high-level general semantic understanding and learning low-level, fine-grained sensorimotor skills, often leading to "catastrophic forgetting" of the model's open-world capabilities. To resolve this conflict, we introduce TwinBrainVLA, a novel architecture that coordinates a generalist VLM retaining universal semantic understanding and a specialist VLM dedicated to embodied proprioception for joint robotic control. TwinBrainVLA synergizes a frozen "Left Brain", which retains robust general visual reasoning, with a trainable "Right Brain", specialized for embodied perception, via a novel Asymmetric Mixture-of-Transformers (AsyMoT) mechanism. This design allows the Right Brain to dynamically query semantic knowledge from the frozen Left Brain and fuse it with proprioceptive states, providing rich conditioning for a Flow-Matching Action Expert to generate precise continuous controls. Extensive experiments on SimplerEnv and RoboCasa benchmarks demonstrate that TwinBrainVLA achieves superior manipulation performance compared to state-of-the-art baselines while explicitly preserving the comprehensive visual understanding capabilities of the pre-trained VLM, offering a promising direction for building general-purpose robots that simultaneously achieve high-level semantic understanding and low-level physical dexterity.

</details>


<div id='cs.OS'></div>

# cs.OS [[Back]](#toc)

### [353] [Nixie: Efficient, Transparent Temporal Multiplexing for Consumer GPUs](https://arxiv.org/abs/2601.11743)
*Yechen Xu,Yifei Wang,Nathanael Ren,Yiran Chen,Danyang Zhuo*

Main category: cs.OS

TL;DR: Nixie是一个优化消费级GPU运行大型ML工作负载的系统，通过协调内存分配和调度，显著降低延迟并节省内存。


<details>
  <summary>Details</summary>
Motivation: 消费级GPU在运行大型ML工作负载时，由于单用户、快速变化的工作负载和内存占满问题，现有共享机制（如NVIDIA统一虚拟内存）性能不佳。

Method: 设计了Nixie系统，该系统作为一个服务协调GPU内存分配和内核启动行为，并采用轻量级调度器（基于MLFQ技术）优先处理延迟敏感的交互任务。

Result: 评估显示，Nixie将交互式代码补全任务的延迟最高降低了3.8倍，并在相同延迟要求下节省了66.8%的CPU固定内存使用。

Conclusion: Nixie系统通过高效的GPU内存分配和内核启动协调，显著提升了消费级GPU在运行大型ML工作负载时的性能和资源利用率，同时减少了CPU固定内存的使用。

Abstract: Consumer machines are increasingly running large ML workloads such as large language models (LLMs), text-to-image generation, and interactive image editing. Unlike datacenter GPUs, consumer GPUs serve single-user, rapidly changing workloads, and each model's working set often nearly fills the GPU memory. As a result, existing sharing mechanisms (e.g., NVIDIA Unified Virtual Memory) perform poorly due to memory thrashing and excessive use of CPU pinned memory when multiple applications are active.
  We design and implement Nixie, a system that enables efficient and transparent temporal multiplexing on consumer GPUs without requiring any application or driver changes. Nixie is a system service that coordinates GPU memory allocation and kernel launch behavior to efficiently utilize the CPU-GPU bi-directional bandwidth and CPU pinned memory. A lightweight scheduler in Nixie further improves responsiveness by automatically prioritizing latency-sensitive interactive jobs using MLFQ-inspired techniques. Our evaluations show that Nixie improves latency of real interactive code-completion tasks by up to $3.8\times$ and saves up to 66.8% CPU pinned memory usage given the same latency requirement.

</details>


### [354] [ContiguousKV: Accelerating LLM Prefill with Granularity-Aligned KV Cache Management](https://arxiv.org/abs/2601.13631)
*Jing Zou,Shangyu Wu,Hancong Duan,Qiao Li,Chun Jason Xue*

Main category: cs.OS

TL;DR: ContiguousKV通过统一数据管理粒度和异步预取技术，显著提升大语言模型服务中KV缓存卸载的效率。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型服务中因KV缓存卸载导致的I/O瓶颈问题，包括读取放大和资源利用率低。

Method: 提出了ContiguousKV系统，包括ContiguousChunk统一数据管理粒度、层间和层内异步预取技术，以及注意力引导的缓存管理。

Result: 在Qwen2.5系列模型上验证，ContiguousKV在Re-Prefill阶段实现了3.85倍的加速。

Conclusion: ContiguousKV显著提升了Re-Prefill阶段的性能，比现有最优卸载系统IMPRESS快3.85倍，同时保持了高输出质量。

Abstract: Efficiently serving Large Language Models (LLMs) with persistent Prefix Key-Value (KV) Cache is critical for applications like conversational search and multi-turn dialogue. Serving a request requires loading the pre-computed prefix KV cache and generating the first token, defined as the Re-Prefill Phase. Offloading this shared prefix cache to secondary storage is essential for memory scalability. Re-Prefill with offloading suffers from severe I/O bottlenecks in two aspects. First, semantic-aware KV cache pruning algorithms select important tokens in fine granularity, while systems manage I/O in coarse, fixed-size blocks, causing severe read amplification. Second, the sequential dependency between identifying important tokens and loading KV cache creates idle I/O and compute bubbles, under-utilizing system resources.
  This paper proposes \textit{ContiguousKV}, a high-performance prefix KV cache offloading system that bridges algorithmic semantics with I/O efficiency to accelerate the Re-Prefill phase. We first introduce \textit{ContiguousChunk}, a unified data management granularity that aligns KV cache pruning with I/O operations. All the mechanisms critical for I/O performance are performed at the granularity of ContiguousChunk, thereby eliminating read amplification. By exploiting the high similarity in important ContiguousChunk indices across layers, we propose intra- and inter-period asynchronous prefetching to break the sequential dependency between I/O and compute, effectively eliminating idle bubbles. Finally, we propose attention-guided cache management to retain semantically critical prefix data in memory. Evaluations on Qwen2.5 series models show that ContiguousKV achieves a 3.85x speedup in the Re-Prefill phase over the state-of-the-art offloading system IMPRESS, while maintaining high output quality.

</details>


### [355] ["Range as a Key" is the Key! Fast and Compact Cloud Block Store Index with RASK](https://arxiv.org/abs/2601.14129)
*Haoru Zhao,Mingkai Dong,Erci Xu,Zhongyu Wang,Haibo Chen*

Main category: cs.OS

TL;DR: RASK是一种内存高效、高性能的范围索引树结构，通过创新设计解决范围重叠和碎片问题，显著降低内存使用并提升性能。


<details>
  <summary>Details</summary>
Motivation: 随着用户规模扩大和存储介质密度增加，传统按块索引成为内存消耗的主要来源，而生产跟踪分析显示写入请求倾向于连续块范围，因此提出直接索引块范围以节省内存。

Method: RASK采用树状结构索引范围，结合日志结构的叶子节点、范围定制搜索和垃圾回收机制处理范围重叠问题，并通过范围感知的分裂和合并机制减少范围碎片。

Result: 在四个生产跟踪上的评估显示，RASK相比现有索引减少了高达98.9%的内存占用，并提升了高达31.0倍的吞吐量。

Conclusion: RASK通过创新的范围索引设计，显著减少了内存占用并提高了吞吐量，为解决云存储中的索引内存压力问题提供了有效方案。

Abstract: In cloud block store, indexing is on the critical path of I/O operations and typically resides in memory. With the scaling of users and the emergence of denser storage media, the index has become a primary memory consumer, causing memory strain. Our extensive analysis of production traces reveals that write requests exhibit a strong tendency to target continuous block ranges in cloud storage systems. Thus, compared to current per-block indexing, our insight is that we should directly index block ranges (i.e., range-as-a-key) to save memory.
  In this paper, we propose RASK, a memory-efficient and high-performance tree-structured index that natively indexes ranges. While range-as-a-key offers the potential to save memory and improve performance, realizing this idea is challenging due to the range overlap and range fragmentation issues. To handle range overlap efficiently, RASK introduces the log-structured leaf, combined with range-tailored search and garbage collection. To reduce range fragmentation, RASK employs range-aware split and merge mechanisms. Our evaluations on four production traces show that RASK reduces memory footprint by up to 98.9% and increases throughput by up to 31.0x compared to ten state-of-the-art indexes.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [356] [Proc3D: Procedural 3D Generation and Parametric Editing of 3D Shapes with Large Language Models](https://arxiv.org/abs/2601.12234)
*Fadlullah Raji,Stefano Petrangeli,Matheus Gadelha,Yu Shen,Uttaran Bhattacharya,Gang Wu*

Main category: cs.GR

TL;DR: Proc3D 是一种生成可编辑3D模型的系统，通过PCG图和LLM支持实时修改，效率提升400倍，文本对齐分数提高28%。


<details>
  <summary>Details</summary>
Motivation: 现有生成式AI方法产生的3D模型不可编辑（如网格或点云），限制了迭代设计的灵活性。

Method: Proc3D 采用程序化紧凑图（PCG）表示3D模型，支持通过滑块、复选框和自然语言提示（基于GPT-4o和LLAMA-3）进行实时修改。

Result: Proc3D 在编辑效率上比传统方法快400倍，ULIP分数（文本对齐指标）提升28%。

Conclusion: Proc3D 通过引入可编辑的3D模型生成系统，显著提升了编辑效率和文本对齐能力，为迭代设计和文本驱动的3D编辑提供了高效工具。

Abstract: Generating 3D models has traditionally been a complex task requiring specialized expertise. While recent advances in generative AI have sought to automate this process, existing methods produce non-editable representation, such as meshes or point clouds, limiting their adaptability for iterative design. In this paper, we introduce Proc3D, a system designed to generate editable 3D models while enabling real-time modifications. At its core, Proc3D introduces procedural compact graph (PCG), a graph representation of 3D models, that encodes the algorithmic rules and structures necessary for generating the model. This representation exposes key parameters, allowing intuitive manual adjustments via sliders and checkboxes, as well as real-time, automated modifications through natural language prompts using Large Language Models (LLMs). We demonstrate Proc3D's capabilities using two generative approaches: GPT-4o with in-context learning (ICL) and a fine-tuned LLAMA-3 model. Experimental results show that Proc3D outperforms existing methods in editing efficiency, achieving more than 400x speedup over conventional approaches that require full regeneration for each modification. Additionally, Proc3D improves ULIP scores by 28%, a metric that evaluates the alignment between generated 3D models and text prompts. By enabling text-aligned 3D model generation along with precise, real-time parametric edits, Proc3D facilitates highly accurate text-based image editing applications.

</details>


### [357] [Copy-Trasform-Paste: Zero-Shot Object-Object Alignment Guided by Vision-Language and Geometric Constraints](https://arxiv.org/abs/2601.14207)
*Rotem Gatenyo,Ohad Fried*

Main category: cs.GR

TL;DR: 通过CLIP驱动梯度和几何感知目标直接优化3D对齐，无需训练新模型，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 研究零样本3D对齐，以支持内容创建和场景组装，弥补现有方法依赖几何对齐或预训练2D扩散模型的不足。

Method: 通过可微分渲染器直接优化相对姿态（平移、旋转和各向同性缩放），利用CLIP驱动的梯度，结合几何感知目标（软迭代最近点变体和穿透损失）和分阶段调度。

Result: 提出的方法在多样类别和关系的基准测试中表现优于所有基线。

Conclusion: 该方法在语义忠实性和物理合理性方面优于所有基线，实现了零样本3D对齐的优化。

Abstract: We study zero-shot 3D alignment of two given meshes, using a text prompt describing their spatial relation -- an essential capability for content creation and scene assembly. Earlier approaches primarily rely on geometric alignment procedures, while recent work leverages pretrained 2D diffusion models to model language-conditioned object-object spatial relationships. In contrast, we directly optimize the relative pose at test time, updating translation, rotation, and isotropic scale with CLIP-driven gradients via a differentiable renderer, without training a new model. Our framework augments language supervision with geometry-aware objectives: a variant of soft-Iterative Closest Point (ICP) term to encourage surface attachment and a penetration loss to discourage interpenetration. A phased schedule strengthens contact constraints over time, and camera control concentrates the optimization on the interaction region. To enable evaluation, we curate a benchmark containing diverse categories and relations, and compare against baselines. Our method outperforms all alternatives, yielding semantically faithful and physically plausible alignments.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [358] [PerCache: Predictive Hierarchical Cache for RAG Applications on Mobile Devices](https://arxiv.org/abs/2601.11553)
*Kaiwei Liu,Liekang Zeng,Lilin Xu,Bufang Yang,Zhenyu Yan*

Main category: cs.DC

TL;DR: PerCache 是一种移动端 RAG 应用的层次化缓存方案，通过重用中间结果和预测查询，显著降低延迟并适应动态资源变化。


<details>
  <summary>Details</summary>
Motivation: 移动设备上的 RAG 系统因冗长提示和资源限制导致高延迟，现有方法（如 KV 缓存重用和语义缓存重用）针对云环境设计，在移动场景中表现不佳。

Method: PerCache 采用层次化架构，逐步匹配相似查询和 QKV 缓存，以最大化不同计算阶段的中间结果重用。同时，通过预测方法预填充未来可能出现的查询以提高缓存命中率，并能动态调整配置以适应系统负载变化。

Result: 实验表明，PerCache 在多种应用中比最佳基线降低 34.4% 的延迟，并在动态资源变化下保持最优性能。

Conclusion: PerCache 是一种针对移动平台上个性化 RAG 应用的层次化缓存解决方案，能够显著降低端到端延迟，并在动态资源变化下保持最佳性能。

Abstract: Retrieval-augmented generation (RAG) has been extensively used as a de facto paradigm in various large language model (LLM)-driven applications on mobile devices, such as mobile assistants leveraging personal emails or meeting records. However, due to the lengthy prompts and the resource constraints, mobile RAG systems exhibit significantly high response latency. On this issue, one promising approach is to reuse intermediate computational results across different queries to eliminate redundant computation. But most existing approaches, such as KV cache reuse and semantic cache reuse, are designed for cloud settings and perform poorly, overlooking the distinctive characteristics of mobile RAG.
  We propose PerCache, a novel hierarchical cache solution designed for reducing end-to-end latency of personalized RAG applications on mobile platforms. PerCache adopts a hierarchical architecture that progressively matches similar queries and QKV cache to maximize the reuse of intermediate results at different computing stages. To improve cache hit rate, PerCache applies a predictive method to populate cache with queries that are likely to be raised in the future. In addition, PerCache can adapt its configurations to dynamic system loads, aiming at maximizing the caching utility with minimal resource consumption. We implement PerCache on top of an existing mobile LLM inference engine with commodity mobile phones. Extensive evaluations show that PerCache can surpass the best-performing baseline by 34.4% latency reduction across various applications and maintain optimal latency performance under dynamic resource changes.

</details>


### [359] [Computation-Bandwidth-Memory Trade-offs: A Unified Paradigm for AI Infrastructure](https://arxiv.org/abs/2601.11577)
*Yuankai Fan,Qizhen Weng,Xuelong Li*

Main category: cs.DC

TL;DR: AI Trinity是一个统一框架，通过动态平衡计算、带宽和内存资源来优化AI系统性能，解决了单一资源瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 大规模AI模型在硬件上面临计算、带宽和内存的相互制约问题，孤立优化效果有限，需要一种统一的方法来平衡这些资源。

Method: 引入AI Trinity框架，将计算、带宽和内存视为同等重要的支柱，并通过动态资源分配来缓解单一资源瓶颈。

Result: AI Trinity通过三种基本权衡（计算与带宽、带宽与内存、内存与计算）有效优化了系统性能，并在边缘-云通信、大规模分布式训练和模型推理等场景中展示了其有效性。

Conclusion: AI Trinity提出了一种新的可扩展AI基础设施范式，通过动态资源分配优化系统性能，为广泛的应用场景提供了概念基础和实践指导。

Abstract: Large-scale artificial intelligence models are transforming industries and redefining human machine collaboration. However, continued scaling exposes critical limitations in hardware, including constraints on computation, bandwidth, and memory. These dimensions are tightly interconnected, so improvements in one often create bottlenecks in others, making isolated optimizations less effective. Balancing them to maximize system efficiency remains a central challenge in scalable AI design. To address this challenge, we introduce {Computation-Bandwidth-Memory Trade-offs}, termed the {AI Trinity}, a unified paradigm that positions {computation}, {bandwidth}, and {memory} as coequal pillars for next-generation AI infrastructure. AI Trinity enables dynamic allocation of resources across these pillars, alleviating single-resource bottlenecks and adapting to diverse scenarios to optimize system performance. Within this framework, AI Trinity identifies three fundamental trade-offs: (1) {More Computation$\rightarrow$Less Bandwidth}, wherein computational resources are exploited to reduce data transmission under limited bandwidth conditions, (2) {More Bandwidth$\rightarrow$Less Memory}, which exploits abundant communication capacity to populate or refresh memory when local storage resources are constrained, and (3) {More Memory$\rightarrow$Less Computation}, whereby storage capacity are utilized to mitigate redundant computation when computational costs are prohibitive. We illustrate the effectiveness of AI Trinity through representative system designs spanning edge-cloud communication, large-scale distributed training, and model inference. The innovations embodied in AI Trinity advance a new paradigm for scalable AI infrastructure, providing both a conceptual foundation and practical guidance for a broad range of application scenarios.

</details>


### [360] [Cost-Aware Logging: Measuring the Financial Impact of Excessive Log Retention in Small-Scale Cloud Deployments](https://arxiv.org/abs/2601.11584)
*Jody Almaida Putra*

Main category: cs.DC

TL;DR: 研究发现，适度减少日志保留窗口（如从90天减至14天）可显著降低成本（78%）且几乎不影响操作有用性（保留97%日志），为小型团队提供成本效益优化框架。


<details>
  <summary>Details</summary>
Motivation: 小型和早期云部署中，日志保留策略常被配置为远超实际需求（如默认90天），导致隐藏且重复的成本增加。本研究旨在从成本意识角度探讨日志保留窗口选择的财务和操作影响。

Method: 使用合成日志数据集，模拟真实世界中日志量和访问模式的变异性，评估了7、14、30和90天的保留窗口。分析聚焦于三个指标：存储成本、操作有用日志比例及每个有用日志的成本。

Result: 将日志保留从90天减少到14天可降低存储成本高达78%，同时保留超过97%的操作有用日志。较长的保留窗口带来递减的操作回报，同时不成比例地增加存储成本和查询开销。

Conclusion: 适度调整日志保留窗口（如从90天减少到14天）可以显著降低存储成本（高达78%），同时保留超过97%的操作有用日志。这一发现为小型工程团队提供了一个轻量级且易于使用的框架，以成本效益的角度来优化日志保留策略。

Abstract: Log data plays a critical role in observability, debugging, and performance monitoring in modern cloud-native systems. In small and early-stage cloud deployments, however, log retention policies are frequently configured far beyond operational requirements, often defaulting to 90 days or more, without explicit consideration of their financial and performance implications. As a result, excessive log retention becomes a hidden and recurring cost.
  This study examines the financial and operational impact of log retention window selection from a cost-aware perspective. Using synthetic log datasets designed to reflect real-world variability in log volume and access patterns, we evaluate retention windows of 7, 14, 30, and 90 days. The analysis focuses on three metrics: storage cost, operationally useful log ratio, and cost per useful log. Operational usefulness is defined as log data accessed during simulated debugging and incident analysis tasks.
  The results show that reducing log retention from 90 days to 14 days can lower log storage costs by up to 78 percent while preserving more than 97 percent of operationally useful logs. Longer retention windows provide diminishing operational returns while disproportionately increasing storage cost and query overhead. These findings suggest that modest configuration changes can yield significant cost savings without compromising system reliability.
  Rather than proposing new logging mechanisms, this work offers a lightweight and accessible framework to help small engineering teams reason about log retention policies through a cost-effectiveness lens. The study aims to encourage more deliberate observability configurations, particularly in resource-constrained cloud environments.

</details>


### [361] [PLA-Serve: A Prefill-Length-Aware LLM Serving System](https://arxiv.org/abs/2601.11589)
*Jianshu She,Zonghang Li,Hongchao Du,Shangyu Wu,Wenhao Zheng,Eric Xing,Zhengzhong Liu,Huaxiu Yao,Jason Xue,Qirong Ho*

Main category: cs.DC

TL;DR: PLA-Serve通过自适应调度和智能批处理优化异构LLM服务，降低延迟并提升吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有系统依赖统一的调度策略，无法适应异构工作负载特性，尤其是提示长度变化导致的性能瓶颈。

Method: PLA-Serve采用双队列设计，支持单预填充实例的时间解耦或多实例的空间解耦，并引入长度感知的智能批处理机制和CUDA Graph-based聚类。

Result: 在真实多轮工作负载中，PLA-Serve将预填充延迟降低30%以上，SLO违规减少28%，并在多GPU设置中进一步降低12%。高并发下，吞吐量提升35%。

Conclusion: PLA-Serve通过自适应调度策略和智能批处理机制，显著降低了LLM服务中的TTFT延迟，并在高并发和混合请求场景下提升了吞吐量。

Abstract: PLA-Serve identifies and disaggregates requests with different prompt lengths in LLM serving to reduce TTFT latency. While recent systems have decoupled the prefill and decode stages to improve throughput, they still rely on unified scheduling policies that fail to adapt to heterogeneous workload characteristics. We observe that prompt-length variations lead to distinct performance bottlenecks, motivating an adaptive scheduling strategy. PLA-Serve disaggregates multi-turn long-prefill requests from short-prefill ones and introduces a length-aware smart batching mechanism for short-prefill workloads. It adopts a dual-queue design that supports temporal disaggregation on a single prefill instance or spatial disaggregation across multiple instances. For short-prefill batches, a batch waiting window and CUDA Graph-based clustering mitigate interference from heterogeneous computation, reducing batching delay and lowering average latency. In real multi-turn workloads, PLA-Serve reduces prefill latency by over 30% compared to vanilla SGLang under prefill**--**decode disaggregation, and further decreases SLO violations by 28% in multi-instance deployments with vanilla data-parallel configuration. Compared to the SGLang router with load balancing, it further lowers SLO violations by 12% in multi-GPU settings. Under high concurrency and mixed-request scenarios, PLA-Serve improves request throughput by 35% serving Qwen2.5-32B model for prefill instance, demonstrating its effectiveness in optimizing heterogeneous LLM serving workloads.

</details>


### [362] [EPD-Serve: A Flexible Multimodal EPD Disaggregation Inference Serving System On Ascend](https://arxiv.org/abs/2601.11590)
*Fan Bai,Pai Peng,Zhengzhi Tang,Zhe Wang,Gong Chen,Xiang Lu,Yinuo Li,Huan Lin,Weizhe Lin,Yaoyuan Wang,Xiaosong Li*

Main category: cs.DC

TL;DR: EPD-Serve是一种阶段级解耦的多模态模型推理服务系统，通过动态编排和优化通信机制，显著提升系统吞吐量和效率。


<details>
  <summary>Details</summary>
Motivation: 现有多模态推理系统采用单一架构，忽略了各阶段的异构计算特性，导致资源利用率低下和系统吞吐量受限。

Method: EPD-Serve将推理流程解耦为独立的Encode、Prefill和Decode阶段，并利用Ascend互连拓扑实现异步特征预取和分层分组KV缓存传输机制。

Result: 在高并发场景下，EPD-Serve相比PD解耦部署，端到端吞吐量提升了57.37-69.48%，且满足TTFT低于2000毫秒和TPOT低于50毫秒的SLO约束。

Conclusion: EPD-Serve通过阶段级解耦和动态编排，显著提升了多模态大模型推理系统的吞吐量和效率，满足了严格的SLO约束。

Abstract: With the widespread adoption of large multimodal models, efficient inference across text, image, audio, and video modalities has become critical. However, existing multimodal inference systems typically employ monolithic architectures that tightly couple the Encode, Prefill, and Decode stages on homogeneous hardware, neglecting the heterogeneous computational characteristics of each stage. This design leads to inefficient resource utilization and limited system throughput. To address these issues, we propose EPD-Serve, a stage-level disaggregated inference serving system for multimodal models. EPD-Serve decouples the inference pipeline into independent Encode, Prefill, and Decode stages, enabling logical isolation and flexible co-located deployment through dynamic orchestration. Leveraging the Ascend interconnect topology, EPD-Serve introduces asynchronous feature prefetching between Encode and Prefill stages and a hierarchical grouped KV cache transmission mechanism between Prefill and Decode stages to improve cross-node communication efficiency. In addition, EPD-Serve incorporates multi-route scheduling, instance-level load balancing, and multi-stage hardware co-location with spatial multiplexing to better support diverse multimodal workloads. Comprehensive experiments on multimodal understanding models demonstrate that, under high-concurrency scenarios, EPD-Serve improves end-to-end throughput by 57.37-69.48% compared to PD-disaggregated deployment, while satisfying strict SLO constraints, including TTFT below 2000 ms and TPOT below 50 ms. These results highlight the effectiveness of stage-level disaggregation for optimizing multimodal large model inference systems.

</details>


### [363] [Enhancing Model Context Protocol (MCP) with Context-Aware Server Collaboration](https://arxiv.org/abs/2601.11595)
*Meenakshi Amulya Jayanti,X. Y. Han*

Main category: cs.DC

TL;DR: CA-MCP通过共享上下文存储提升多智能体系统效率，减少LLM调用和响应失败。


<details>
  <summary>Details</summary>
Motivation: 传统MCP缺乏全局上下文，导致多智能体工作流效率低下；共享上下文存储（SCS）可减少冗余并促进知识转移。

Method: 设计了上下文感知的MCP（CA-MCP），通过共享上下文内存实现实时自主协调，管理中间状态和共享变量。

Result: 在TravelPlanner和REALM-Bench数据集上的实验表明，CA-MCP显著优于传统MCP。

Conclusion: CA-MCP通过共享上下文存储显著提升了多智能体系统的效率和响应能力，减少了LLM调用次数和响应失败频率。

Abstract: The Model Context Protocol (MCP) has emerged as a widely used framework for enabling LLM-based agents to communicate with external tools and services. The most common implementation of MCP, proposed by Anthropic, heavily relies on a Large Language Model (LLM) to decompose tasks and issue instructions to servers, which act as stateless executors. In particular, the agents, models, and servers are stateless and do not have access to a global context. However, in tasks involving LLM-driven coordination, it is natural that a Shared Context Store (SCS) could improve the efficiency and coherence of multi-agent workflows by reducing redundancy and enabling knowledge transfer between servers. Thus, in this work, we design and assess the performance of a Context-Aware MCP (CA-MCP) that offloads execution logic to specialized MCP servers that read from and write to a shared context memory, allowing them to coordinate more autonomously in real time. In this design, context management serves as the central mechanism that maintains continuity across task executions by tracking intermediate states and shared variables, thereby enabling persistent collaboration among agents without repeated prompting. We present experiments showing that the CA-MCP can outperform the traditional MCP by reducing the number of LLM calls required for complex tasks and decreasing the frequency of response failures when task conditions are not satisfied, thereby improving overall efficiency and responsiveness. In particular, we conducted experiments on the TravelPlanner and REALM-Bench benchmark datasets and observed statistically significant results indicating the potential advantages of incorporating a shared context store via CA-MCP in LLM-driven multi-agent systems.

</details>


### [364] [Hardware-Aware Reformulation of Convolutions for Efficient Execution on Specialized AI Hardware: A Case Study on NVIDIA Tensor Cores](https://arxiv.org/abs/2601.11608)
*Ganesh Bikshandi*

Main category: cs.DC

TL;DR: 通过硬件感知的重写规则优化CNN计算，无需修改权重即可满足硬件对齐要求，为高效部署奠定基础。


<details>
  <summary>Details</summary>
Motivation: 解决传统零填充方法在硬件对齐上的低效问题，提升CNN在专用硬件上的执行效率。

Method: 使用重写规则对CNN计算进行硬件感知的重新表述，满足硬件对齐要求，且无需修改网络权重。

Result: 成功实现了对Tensor Cores的单一变换，验证了该方法在CPU和加速器上的通用性。

Conclusion: 本研究提出了‘语义调优’的概念，通过硬件感知的重写规则重新表述CNN计算，为CNN模型在专用AI硬件上的高效部署奠定了基础。

Abstract: Convolutional Neural Networks (CNNs) are central to modern AI, but their performance is often limited by hardware constraints. NVIDIA Tensor Cores, for instance, require input channels to be multiples of 8 and sometimes 512 for efficient execution. {\em oneDNN} framework for CPU imposes such a requirement for the blocked format. Traditional approaches address such alignment issue using zero-padding, which can be inefficient. In this work, we present a first-step, hardware-aware reformulation of CNN computations using rewrite rules, restructuring the underlying math to satisfy hardware alignment entirely {\bf post-training} without modifying network weights. While our current implementation focuses on a single transformation for Tensor Cores, this approach is generalizable, laying the foundation to explore additional transformations for CPU and accelerators. This study represents an initial step toward {\em semantic tuning}, a systematic, hardware-aware optimization strategy for efficient deployment of CNN models on specialized AI hardware.

</details>


### [365] [Radio Labeling of Strong Prismatic Network With Star](https://arxiv.org/abs/2601.11624)
*Liming Wang,Feng Li,Linlin Cui*

Main category: cs.DC

TL;DR: 本文研究了星形强棱柱网络的无线电标记问题，提出了相关定理和并行算法，以提高大规模网络中的计算效率。


<details>
  <summary>Details</summary>
Motivation: 无线通信的快速发展使得高效的频谱分配成为提升网络性能的关键因素。无线电标记作为信道分配的组合优化模型，是一个NP难问题，因此研究特定图类的无线电标记具有重要意义。

Method: 将频谱分配问题转化为图的无线电标记问题，研究了特定图类的无线电标记。通过定义无线电标记的span，并利用强积作为构建规则网络的关键工具，提出了并行算法。

Result: 提出了星形强棱柱网络的无线电标记相关定理和示例，并设计了一种并行算法以提高计算效率。

Conclusion: 本文研究了星形强棱柱网络的无线电标记问题，提出了相关定理和示例，并设计了一种并行算法以提高大规模网络场景下的计算效率。

Abstract: The rapid development of wireless communication has made efficient spectrum assignment a crucial factor in enhancing network performance. As a combinatorial optimization model for channel assignment, the radio labeling is recognized as an NP-hard problem. Therefore, converting the spectrum assignment problem into the radio labeling of graphs and studying the radio labeling of specific graph classes is of great significance. For $G$, a radio labeling $\varphi: V(G) \to \{0, 1, 2, \ldots\}$ is required to satisfy $|\varphi(u) - \varphi(v)| \geq \text{diam}(G) + 1 -d_G(u, v)$, where ${diam(G)}$ and $d_G(u, v)$ are diameter and distance between $u$ and $v$. For a radio labeling $\varphi$, its $\text{span}$ is defined as the largest integer assigned by $\varphi$ to the vertices of $G$; the radio labeling specifically denotes the labeling with the minimal span among possible radio labeling. The strong product is a crucial tool for constructing regular networks, and studying its radio labeling is necessary for the design of optimal channel assignment in wireless networks. Within this manuscript, we discuss the radio labeling of strong prismatic network with star, present the relevant theorems and examples, and propose a parallel algorithm to improve computational efficiency in large-scale network scenarios.

</details>


### [366] [A Forward Simulation-Based Hierarchy of Linearizable Concurrent Objects](https://arxiv.org/abs/2601.11646)
*Chao Wang,Ruijia Li,Yang Zhou,Peng Wu,Yi Lv,Jianwei Liao,Jim Woodcock,Zhiming Liu*

Main category: cs.DC

TL;DR: 论文研究了线性化对象与向前模拟的关系，证明了其在特定条件下的结构性质，并提出了验证线性化的新方法。


<details>
  <summary>Details</summary>
Motivation: 探讨线性化对象与向前模拟之间的理论联系，为线性化验证提供新方法。

Method: 通过系统研究线性化对象与向前模拟的关系，提出等效特征，并通过实例验证。

Result: 证明了线性化对象在向前模拟关系下的结构性质，以及时间戳队列与Herlihy-Wing队列之间的模拟关系。

Conclusion: 论文证明了线性化对象在向前模拟关系下形成有界半格或有界格，并提出了通过对象$\mathcal{U}_{Spec}$来检查线性化的等效特征。

Abstract: In this paper, we systematically investigate the connection between linearizable objects and forward simulation. We prove that the sets of linearizable objects satisfying wait-freedom (resp., lock-freedom or obstruction-freedom) form a bounded join-semilattice under the forward simulation relation, and that the sets of linearizable objects without liveness constraints form a bounded lattice under the same relation. As part of our lattice result, we propose an equivalent characterization of linearizability by reducing checking linearizability w.r.t. sequential specification $Spec$ into checking forward simulation by an object $\mathcal{U}_{Spec}$. To demonstrate the forward simulation relation between linearizable objects, we prove that the objects that are strongly linearizable w.r.t. the same sequential specification and are wait-free (resp., lock-free, obstruction-free) simulate each other, and we prove that the time-stamped queue simulates the Herlihy-Wing queue. We also prove that the Herlihy-Wing queue is simulated by $\mathcal{U}_{Spec}$, and thus, our equivalent characterization of linearizability can be used in the verification of linearizability.

</details>


### [367] [WISP: Waste- and Interference-Suppressed Distributed Speculative LLM Serving at the Edge via Dynamic Drafting and SLO-Aware Batching](https://arxiv.org/abs/2601.11652)
*Xiangchen Li,Jiakun Fan,Qingyuan Wang,Dimitrios Spatharakis,Saeid Ghafouri,Hans Vandierendonck,Deepu John,Bo Ji,Ali R. Butt,Dimitrios S. Nikolopoulos*

Main category: cs.DC

TL;DR: WISP系统通过优化分布式LLM推理中的推测解码，显著提升系统效率和资源利用率。


<details>
  <summary>Details</summary>
Motivation: 随着LLM推理请求从边缘设备向集中式GPU集群转移，导致数据中心压力增大而边缘设备资源利用率低，亟需一种平衡负载的方法。

Method: 提出了WISP系统，包含智能推测控制器、验证时间估计器和验证批调度器，以优化推测解码过程中的效率。

Result: WISP相比集中式服务和SLED，系统容量提升最高达2.1倍和4.1倍，吞吐量提升最高达1.94倍和3.7倍。

Conclusion: WISP通过智能推测控制器、验证时间估计器和验证批调度器，有效解决了分布式推测LLM推理中的两个关键瓶颈，显著提升了系统容量和吞吐量。

Abstract: As Large Language Models (LLMs) become increasingly accessible to end users, an ever-growing number of inference requests are initiated from edge devices and computed on centralized GPU clusters. However, the resulting exponential growth in computation workload is placing significant strain on data centers, while edge devices remain largely underutilized, leading to imbalanced workloads and resource inefficiency across the network. Integrating edge devices into the LLM inference process via speculative decoding helps balance the workload between the edge and the cloud, while maintaining lossless prediction accuracy. In this paper, we identify and formalize two critical bottlenecks that limit the efficiency and scalability of distributed speculative LLM serving: Wasted Drafting Time and Verification Interference. To address these challenges, we propose WISP, an efficient and SLO-aware distributed LLM inference system that consists of an intelligent speculation controller, a verification time estimator, and a verification batch scheduler. These components collaboratively enhance drafting efficiency and optimize verification request scheduling on the server. Extensive numerical results show that WISP improves system capacity by up to 2.1x and 4.1x, and increases system goodput by up to 1.94x and 3.7x, compared to centralized serving and SLED, respectively.

</details>


### [368] [HALO: Semantic-Aware Distributed LLM Inference in Lossy Edge Network](https://arxiv.org/abs/2601.11676)
*Peirong Zheng,Wenchao Xu,Haozhao Wang,Jinyu Chen,Xuemin Shen*

Main category: cs.DC

TL;DR: HALO是一种提升边缘网络中分布式LLM推理效率的框架，通过放松同步要求并优化资源分配，显著加速推理过程。


<details>
  <summary>Details</summary>
Motivation: 边缘节点资源有限，现有分布式推理方法需要严格同步，在不可靠网络条件下难以实现。

Method: HALO框架包含三个关键机制：语义感知预测器评估神经元组重要性、并行执行神经元组加载、负载均衡调度器协调异构设备资源。

Result: 在Raspberry Pi集群上的实验表明，HALO在不可靠网络条件下为LLaMA系列LLM实现了3.41倍的端到端加速。

Conclusion: HALO框架通过放松同步要求，在不可靠的边缘网络中显著提升了分布式LLM推理的效率，保持了接近最优条件的性能，并在多种场景下优于现有技术。

Abstract: The deployment of large language models' (LLMs) inference at the edge can facilitate prompt service responsiveness while protecting user privacy. However, it is critically challenged by the resource constraints of a single edge node. Distributed inference has emerged to aggregate and leverage computational resources across multiple devices. Yet, existing methods typically require strict synchronization, which is often infeasible due to the unreliable network conditions. In this paper, we propose HALO, a novel framework that can boost the distributed LLM inference in lossy edge network. The core idea is to enable a relaxed yet effective synchronization by strategically allocating less critical neuron groups to unstable devices, thus avoiding the excessive waiting time incurred by delayed packets. HALO introduces three key mechanisms: (1) a semantic-aware predictor to assess the significance of neuron groups prior to activation. (2) a parallel execution scheme of neuron group loading during the model inference. (3) a load-balancing scheduler that efficiently orchestrates multiple devices with heterogeneous resources. Experimental results from a Raspberry Pi cluster demonstrate that HALO achieves a 3.41x end-to-end speedup for LLaMA-series LLMs under unreliable network conditions. It maintains performance comparable to optimal conditions and significantly outperforms the state-of-the-art in various scenarios.

</details>


### [369] [RAPID-Serve: Resource-efficient and Accelerated P/D Intra-GPU Disaggregation](https://arxiv.org/abs/2601.11822)
*Amna Masood,Pratishtha Gaur,Nuwan Jayasena*

Main category: cs.DC

TL;DR: RAPID-Serve 是一种新的 LLM 推理服务技术，通过并发执行预填充和解码优化吞吐量和延迟，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有混合批处理和分解服务技术存在资源利用率低或延迟增加的局限性。

Method: 提出 RAPID-Serve 技术，通过在同一 GPU 上并发执行预填充和解码阶段，并结合自适应资源管理和 CU 掩码技术。

Result: RAPID-Serve 在无约束条件下吞吐量提升达4.1倍（平均1.7倍），在 SLO 约束下提升达32倍以上（平均4.9倍）。

Conclusion: RAPID-Serve 是一种有效策略，在资源受限环境中显著优于现有技术，提供高达4.1倍的吞吐量提升。

Abstract: Two widely adopted techniques for LLM inference serving systems today are hybrid batching and disaggregated serving. A hybrid batch combines prefill and decode tokens of different requests in the same batch to improve resource utilization and throughput at the cost of increased latency per token. In contrast, disaggregated serving decouples compute-bound prefill and bandwidth-bound decode phases to optimize for service level objectives (SLOs) at the cost of resource under-utilization and KV-cache transfer overheads. To address the limitations of these techniques, we propose RAPID-Serve: a technique to concurrently execute prefill and decode on the same GPU(s) to meet latency SLOs while maintaining high throughput and efficient resource utilization. Furthermore, we propose Adaptive Resource Management for runtime compute resource allocation, optionally leveraging CU masking (a fine-grained Compute Unit partitioning feature on AMD Instinct\textsuperscript{TM} GPUs). RAPID-Serve provides up to 4.1x (average 1.7x) unconstrained throughput improvement and 32x and higher (average 4.9x) throughput improvement under SLO constraints, showing it as an effective strategy compared to the state-of-the-art approaches, particularly in resource-constrained environments.

</details>


### [370] [Big Data Workload Profiling for Energy-Aware Cloud Resource Management](https://arxiv.org/abs/2601.11935)
*Milan Parikh,Aniket Abhishek Soni,Sneja Mitinbhai Shah,Ayush Raj Jha*

Main category: cs.DC

TL;DR: 本文提出了一种能源高效的工作负载感知调度框架，通过分析和预测虚拟机放置的能源和性能影响，实现了显著的能源节省。


<details>
  <summary>Details</summary>
Motivation: 随着大数据工作负载规模和复杂性的增加，云数据中心面临减少运营能源消耗的压力。

Method: 提出了一种基于工作负载感知和能源效率的调度框架，结合历史执行日志和实时遥测数据，预测候选虚拟机放置的能源和性能影响。

Result: 实验结果显示，与基线调度器相比，能实现15%至20%的能源节省，且性能下降可忽略不计。

Conclusion: 研究结果表明，通过工作负载分析和预测，可以有效提升云数据中心的能源效率，同时保持服务级别协议的合规性。

Abstract: Cloud data centers face increasing pressure to reduce operational energy consumption as big data workloads continue to grow in scale and complexity. This paper presents a workload aware and energy efficient scheduling framework that profiles CPU utilization, memory demand, and storage IO behavior to guide virtual machine placement decisions. By combining historical execution logs with real time telemetry, the proposed system predicts the energy and performance impact of candidate placements and enables adaptive consolidation while preserving service level agreement compliance. The framework is evaluated using representative Hadoop MapReduce, Spark MLlib, and ETL workloads deployed on a multi node cloud testbed. Experimental results demonstrate consistent energy savings of 15 to 20 percent compared to a baseline scheduler, with negligible performance degradation. These findings highlight workload profiling as a practical and scalable strategy for improving the sustainability of cloud based big data processing environments.

</details>


### [371] [DaggerFFT: A Distributed FFT Framework Using Task Scheduling in Julia](https://arxiv.org/abs/2601.12209)
*Sana Taghipour Anvari,Julian Samaroo,Matin Raayai Ardakani,David Kaeli*

Main category: cs.DC

TL;DR: DaggerFFT是一个动态调度的分布式FFT框架，在CPU和GPU集群上性能优于现有库，并成功应用于实际模拟。


<details>
  <summary>Details</summary>
Motivation: 随着科学模拟试图利用百亿亿次系统，对能够有效利用现代异构高性能计算系统的分布式FFT算法的需求日益增长。传统FFT算法在异构平台上常遇到性能瓶颈。

Method: DaggerFFT是一个基于Julia开发的分布式FFT框架，将并行FFT计算视为动态调度的任务图，每个FFT阶段操作于单独定义的分布式数组上。

Result: DaggerFFT在CPU集群上实现了2.6倍的加速，在GPU集群上实现了1.35倍的加速，并成功集成到Oceananigans.jl中。

Conclusion: DaggerFFT通过动态任务调度在CPU和GPU集群上实现了显著的性能提升，并在实际应用中展示了其高性能和模块化优势。

Abstract: The Fast Fourier Transform (FFT) is a fundamental numerical technique with widespread application in a range of scientific problems. As scientific simulations attempt to exploit exascale systems, there has been a growing demand for distributed FFT algorithms that can effectively utilize modern heterogeneous high-performance computing (HPC) systems. Conventional FFT algorithms commonly encounter performance bottlenecks, especially when run on heterogeneous platforms. Most distributed FFT approaches rely on static task distribution and require synchronization barriers, limiting scalability and impacting overall resource utilization. In this paper we present DaggerFFT, a distributed FFT framework, developed in Julia, that treats highly parallel FFT computations as a dynamically scheduled task graph. Each FFT stage operates on a separately defined distributed array. FFT operations are expressed as DTasks operating on pencil or slab partitioned DArrays. Each FFT stage owns its own DArray, and the runtime assigns DTasks across devices using Dagger's dynamic scheduler that uses work stealing. We demonstrate how DaggerFFT's dynamic scheduler can outperform state-of-the-art distributed FFT libraries on both CPU and GPU backends, achieving up to a 2.6x speedup on CPU clusters and up to a 1.35x speedup on GPU clusters. We have integrated DaggerFFT into Oceananigans.jl, a geophysical fluid dynamics framework, demonstrating that high-level, task-based runtimes can deliver both superior performance and modularity in large-scale, real-world simulations.

</details>


### [372] [Power Aware Dynamic Reallocation For Inference](https://arxiv.org/abs/2601.12241)
*Yiwei Jiang,Sangeeta Chowdhary,Nathaniel Morris,Rutwik Jain,Srilatha Manne,Sam Bayliss*

Main category: cs.DC

TL;DR: RAPID是一种功率感知的分散推理框架，通过动态管理GPU和功率预算，在功率限制下显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 随着模型和集群规模的扩大，功率成为限制整体性能和成本效率的主要因素，需要一种能有效管理功率的分散推理框架。

Method: RAPID采用静态和动态功率重新分配以及GPU重新分配的策略，优化固定功率限制下的性能。

Result: RAPID在峰值负载下相比静态分配方案，SLO达成率提升了2倍。

Conclusion: RAPID框架通过联合管理GPU角色和功率预算，在严格的功率限制下维持良好的吞吐量，显著提升了SLO达成率，且未增加复杂性或成本。

Abstract: Disaggregation has emerged as a powerful strategy for optimizing large language model (LLM) inference by separating compute-intensive prefill and memory-bound decode phases across specialized GPUs. This separation improves utilization and throughput under fixed hardware capacity. However, as model and cluster scales grow, power, rather than compute, has become the dominant limiter of overall performance and cost efficiency. In this paper, we propose RAPID, a power-aware disaggregated inference framework that jointly manages GPU roles and power budgets to sustain goodput within strict power caps. RAPID utilizes static and dynamic power reallocation in addition to GPU reallocation to improve performance under fixed power bounds. RAPID improves overall performance and application consistency beyond what is achievable in current disaggregation solutions, resulting in up to a 2x improvement in SLO attainment at peak load when compared to a static assignment without an increase in complexity or cost.

</details>


### [373] [Opportunistic Scheduling for Optimal Spot Instance Savings in the Cloud](https://arxiv.org/abs/2601.12266)
*Neelkamal Bhuyan,Randeep Bhatia,Murali Kodialam,TV Lakshman*

Main category: cs.DC

TL;DR: 本文研究了在满足平均延迟约束下调度延迟敏感型作业到云实例以最小化成本的问题，通过排队论和优化方法，提出了一个自适应算法，实证显示其近乎最优。


<details>
  <summary>Details</summary>
Motivation: 研究如何在满足平均延迟约束的同时，通过调度延迟敏感型作业到云实例上以最小化平均成本。作业以一般随机过程到达，并根据实例类型产生不同的成本。

Method: 使用排队论、随机过程和优化的工具，推导了一般策略的成本表达式，证明了在低目标延迟下队列长度为一是最优的，并刻画了最优等待时间分布。对于高目标延迟，识别了一个背包结构并设计了利用该结构的调度策略。

Result: 推导了一般策略的成本表达式，证明了在低目标延迟下队列长度为一是最优的，并刻画了最优等待时间分布。对于高目标延迟，识别了一个背包结构并设计了利用该结构的调度策略。提出了一个自适应算法，实证结果证实了其近乎最优的性能。

Conclusion: 本文通过排队论、随机过程和优化的方法，首次对调度延迟敏感型作业的问题进行了分析，提出了一个自适应算法，该算法能够充分利用允许的延迟，实证结果证实了其近乎最优的性能。

Abstract: We study the problem of scheduling delay-sensitive jobs over spot and on-demand cloud instances to minimize average cost while meeting an average delay constraint. Jobs arrive as a general stochastic process, and incur different costs based on the instance type. This work provides the first analytical treatment of this problem using tools from queuing theory, stochastic processes, and optimization. We derive cost expressions for general policies, prove queue length one is optimal for low target delays, and characterize the optimal wait-time distribution. For high target delays, we identify a knapsack structure and design a scheduling policy that exploits it. An adaptive algorithm is proposed to fully utilize the allowed delay, and empirical results confirm its near-optimality.

</details>


### [374] [RIPPLE++: An Incremental Framework for Efficient GNN Inference on Evolving Graphs](https://arxiv.org/abs/2601.12347)
*Pranjal Naman,Parv Agarwal,Hrishikesh Haritas,Yogesh Simmhan*

Main category: cs.DC

TL;DR: RIPPLE++ 是一个针对动态图的流式 GNN 推理框架，通过增量更新显著提升了效率和吞吐量，适用于实时应用。


<details>
  <summary>Details</summary>
Motivation: 动态图的频繁变化对图神经网络（GNNs）的高效推理提出了挑战，现有方法存在冗余计算、高通信成本和非确定性等问题，无法满足实时应用的低延迟需求。

Method: RIPPLE++ 引入了一种通用的增量编程模型，能够捕捉 GNN 聚合函数的语义，并增量传播受影响的邻域更新。

Result: 在单机环境下，RIPPLE++ 在稀疏图和密集图上分别实现了高达 56K 和 7.6K 更新/秒的吞吐量，延迟范围为 0.06--960ms，比现有基线高出 2.2--24 倍。在分布式环境下，吞吐量提升约 25 倍，通信成本降低 20 倍。

Conclusion: RIPPLE++ 是一个高效的流式图神经网络推理框架，能够动态更新图结构和特征的嵌入，显著提升了单机和分布式环境下的吞吐量和通信效率。

Abstract: Real-world graphs are dynamic, with frequent updates to their structure and features due to evolving vertex and edge properties. These continual changes pose significant challenges for efficient inference in graph neural networks (GNNs). Existing vertex-wise and layer-wise inference approaches are ill-suited for dynamic graphs, as they incur redundant computations, large neighborhood traversals, and high communication costs, especially in distributed settings. Additionally, while sampling-based approaches can be adopted to approximate final layer embeddings, these are often not preferred in critical applications due to their non-determinism. These limitations hinder low-latency inference required in real-time applications. To address this, we propose RIPPLE++, a framework for streaming GNN inference that efficiently and accurately updates embeddings in response to changes in the graph structure or features. RIPPLE++ introduces a generalized incremental programming model that captures the semantics of GNN aggregation functions and incrementally propagates updates to affected neighborhoods. RIPPLE++ accommodates all common graph updates, including vertex/edge addition/deletions and vertex feature updates. RIPPLE++ supports both single-machine and distributed deployments. On a single machine, it achieves up to $56$K updates/sec on sparse graphs like Arxiv ($169$K vertices, $1.2$M edges), and about $7.6$K updates/sec on denser graphs like Products ($2.5$M vertices, $123.7$M edges), with latencies of $0.06$--$960$ms, and outperforming state-of-the-art baselines by $2.2$--$24\times$ on throughput. In distributed settings, RIPPLE++ offers up to $\approx25\times$ higher throughput and $20\times$ lower communication costs compared to recomputing baselines.

</details>


### [375] [ASAS-BridgeAMM: Trust-Minimized Cross-Chain Bridge AMM with Failure Containment](https://arxiv.org/abs/2601.12434)
*Shengwei You,Aditya Joshi,Andrey Kuehlkamp,Jarek Nabrzyski*

Main category: cs.DC

TL;DR: ASAS-BridgeAMM通过动态风险调整机制，显著提升跨链桥的安全性和稳健性，减少系统性风险。


<details>
  <summary>Details</summary>
Motivation: 现有跨链桥安全模型的二元性（完全运行或完全崩溃）是DeFi中系统性风险的主要来源，导致巨额损失。

Method: 采用桥接自动做市商（AMM）模型，通过量化跨链消息延迟作为执行风险，动态调整抵押折扣、滑点限制和提款限额。

Result: 在历史回放测试中，ASAS-BridgeAMM将最坏情况下的桥接破产风险降低了73%，并在压力时期保持了104.5%的交易量。对抗性模拟中，协议保持偿付能力的概率>0.9999，每周期坏账限制在总抵押品的0.2%以内。

Conclusion: ASAS-BridgeAMM通过引入‘受限降级’机制，显著降低了跨链桥的系统性风险，并在对抗性模拟中表现出极高的稳健性。

Abstract: Cross-chain bridges constitute the single largest vector of systemic risk in Decentralized Finance (DeFi), accounting for over \$2.8 billion in losses since 2021. The fundamental vulnerability lies in the binary nature of existing bridge security models: a bridge is either fully operational or catastrophically compromised, with no intermediate state to contain partial failures. We present ASAS-BridgeAMM, a bridge-coupled automated market maker that introduces Contained Degradation: a formally specified operational state where the system gracefully degrades functionality in response to adversarial signals. By treating cross-chain message latency as a quantifiable execution risk, the protocol dynamically adjusts collateral haircuts, slippage bounds, and withdrawal limits. Across 18 months of historical replay on Ethereum and two auxiliary chains, ASAS-BridgeAMM reduces worst-case bridge-induced insolvency by 73% relative to baseline mint-and-burn architectures, while preserving 104.5% of transaction volume during stress periods. In rigorous adversarial simulations involving delayed finality, oracle manipulation, and liquidity griefing, the protocol maintains solvency with probability $>0.9999$ and bounds per-epoch bad debt to $<0.2%$ of total collateral. We provide a reference implementation in Solidity and formally prove safety (bounded debt), liveness (settlement completion), and manipulation resistance under a Byzantine relayer model.

</details>


### [376] [SGCP: A Self-Organized Game-Theoretic Framework For Collaborative Perception](https://arxiv.org/abs/2601.12524)
*Zechuan Gong,Hui Zhang,Yuquan Yang,Wenyu Lu*

Main category: cs.DC

TL;DR: 提出去中心化协作感知框架，通过两阶段博弈实现高效车辆自组织与数据选择传输，降低通信开销并提升感知性能。


<details>
  <summary>Details</summary>
Motivation: 在密集交通中，协作感知可提高自动驾驶安全性，但在通信带宽有限且无路边基础设施的情况下，大规模部署仍具挑战性。

Method: 该方法将问题分解为两个顺序博弈论阶段：车辆通过评估相互感知互补性和运动一致性形成稳定集群，并选举协调员；协调员引导成员通过非合作潜在博弈选择性地传输感知显著区域的点云片段，实现高效局部融合。

Result: 在CARLA-OpenCDA-NS3联合仿真平台上的实验表明，该方法在降低通信开销的同时，提供了更高的感知精度和更广的有效覆盖范围。

Conclusion: 该论文提出了一种完全去中心化的协作感知框架，通过车辆自组织成合作组，显著降低了通信开销，同时提高了感知精度和有效覆盖范围。

Abstract: Collaborative perception holds great promise for improving safety in autonomous driving, particularly in dense traffic where vehicles can share sensory information to overcome individual blind spots and extend awareness. However, deploying such collaboration at scale remains difficult when communication bandwidth is limited and no roadside infrastructure is available. To overcome these limitations, we introduce a fully decentralized framework that enables vehicles to self organize into cooperative groups using only vehicle to vehicle communication. The approach decomposes the problem into two sequential game theoretic stages. In the first stage, vehicles form stable clusters by evaluating mutual sensing complementarity and motion coherence, and each cluster elects a coordinator. In the second stage, the coordinator guides its members to selectively transmit point cloud segments from perceptually salient regions through a non cooperative potential game, enabling efficient local fusion. Global scene understanding is then achieved by exchanging compact detection messages across clusters rather than raw sensor data. We design distributed algorithms for both stages that guarantee monotonic improvement of the system wide potential function. Comprehensive experiments on the CARLA-OpenCDA-NS3 co-simulation platform show that our method reduces communication overhead while delivering higher perception accuracy and wider effective coverage compared to existing baselines.

</details>


### [377] [Dynamic Detection of Inefficient Data Mapping Patterns in Heterogeneous OpenMP Applications](https://arxiv.org/abs/2601.12713)
*Luke Marzen,Junhyung Shim,Ali Jannesari*

Main category: cs.DC

TL;DR: OMPDataPerf是一个低开销的动态分析工具，用于检测和优化异构OpenMP应用中的数据转移低效问题。


<details>
  <summary>Details</summary>
Motivation: 异构计算中设备间的数据转移成为性能瓶颈，现有工具需要大量人工干预来诊断低效问题。

Method: 利用OpenMP Tools Interface (OMPT)实现动态分析技术，开发了OMPDataPerf工具。

Result: OMPDataPerf能详细追踪问题数据映射、源代码归因，并评估优化潜力，运行时开销低。

Conclusion: OMPDataPerf通过动态分析技术有效检测和分析了异构应用中的数据转移和分配低效问题，且运行时开销仅为5%。

Abstract: With the growing prevalence of heterogeneous computing, CPUs are increasingly being paired with accelerators to achieve new levels of performance and energy efficiency. However, data movement between devices remains a significant bottleneck, complicating application development. Existing performance tools require considerable programmer intervention to diagnose and locate data transfer inefficiencies. To address this, we propose dynamic analysis techniques to detect and profile inefficient data transfer and allocation patterns in heterogeneous applications. We implemented these techniques into OMPDataPerf, which provides detailed traces of problematic data mappings, source code attribution, and assessments of optimization potential in heterogeneous OpenMP applications. OMPDataPerf uses the OpenMP Tools Interface (OMPT) and incurs only a 5 % geometric-mean runtime overhead.

</details>


### [378] [Efficient Local-to-Global Collaborative Perception via Joint Communication and Computation Optimization](https://arxiv.org/abs/2601.12749)
*Hui Zhang,Yuquan Yang,Zechuan Gong,Xiaohua Xu,Dan Keun Sung*

Main category: cs.DC

TL;DR: LGCP框架通过分区协作和RSU集中调度，显著减少数据传输量并保持性能。


<details>
  <summary>Details</summary>
Motivation: 解决协作感知中因冗余数据传输和高计算延迟导致的通信和计算效率问题。

Method: 提出了一种本地到全局协作感知框架（LGCP），通过将道路划分为非重叠区域并为每个区域分配专用CAV组进行本地感知，再由RSU集中调度和聚合全局视图。

Result: 实验结果表明，LGCP平均减少了44倍的数据传输量，同时保持或提升了协作性能。

Conclusion: LGCP框架通过本地到全局的协作感知方法，显著减少了数据传输量，同时保持或提升了协作感知性能。

Abstract: Autonomous driving relies on accurate perception to ensure safe driving. Collaborative perception improves accuracy by mitigating the sensing limitations of individual vehicles, such as limited perception range and occlusion-induced blind spots. However, collaborative perception often suffers from high communication overhead due to redundant data transmission, as well as increasing computation latency caused by excessive load with growing connected and autonomous vehicles (CAVs) participation. To address these challenges, we propose a novel local-to-global collaborative perception framework (LGCP) to achieve collaboration in a communication- and computation-efficient manner. The road of interest is partitioned into non-overlapping areas, each of which is assigned a dedicated CAV group to perform localized perception. A designated leader in each group collects and fuses perception data from its members, and uploads the perception result to the roadside unit (RSU), establishing a link between local perception and global awareness. The RSU aggregates perception results from all groups and broadcasts a global view to all CAVs. LGCP employs a centralized scheduling strategy via the RSU, which assigns CAV groups to each area, schedules their transmissions, aggregates area-level local perception results, and propagates the global view to all CAVs. Experimental results demonstrate that the proposed LGCP framework achieves an average 44 times reduction in the amount of data transmission, while maintaining or even improving the overall collaborative performance.

</details>


### [379] [Unleashing Efficient Asynchronous RL Post-Training via Staleness-Constrained Rollout Coordination](https://arxiv.org/abs/2601.12784)
*Haoyang Li,Sheng Lin,Fangcheng Fu,Yuming Zhou,Xiaodong Ji,Yanfeng Zhao,Lefeng Wang,Jie Jiang,Bin Cui*

Main category: cs.DC

TL;DR: StaleFlow是一种RL后训练系统，通过联合控制数据陈旧性和偏斜，显著提升系统性能且不影响收敛性。


<details>
  <summary>Details</summary>
Motivation: 现有系统无法统一解决数据陈旧性和偏斜问题，导致性能与收敛性之间的权衡。

Method: StaleFlow引入全局一致性协议跟踪轨迹生命周期以控制陈旧性，并重新设计系统架构，通过数据服务器实现灵活的rollout协调。

Result: StaleFlow在吞吐量上比现有系统提升1.42-2.68倍（平均1.17-2.01倍），且不影响收敛性。

Conclusion: StaleFlow通过联合解决数据陈旧性和偏斜问题，显著提升了RL后训练系统的性能，同时保持了收敛性。

Abstract: Reinforcement learning (RL) post-training has become pivotal for enhancing the capabilities of modern large models. A recent trend is to develop RL systems with a fully disaggregated architecture, which decouples the three RL phases (rollout, reward, and training) onto separate resources and executes them asynchronously. However, two critical data-level concerns arise: (1) asynchronous execution leads to data staleness in trajectories (the data generated by rollout) as the model parameters used in rollout may not be up to date, which impairs RL convergence; and (2) the length variation of trajectories introduces severe data skewness, leading to workload imbalance and degraded system performance.
  Existing systems fail to address these two concerns in a unified manner. Techniques that tightly control data staleness often constrain effective data skewness mitigation, while aggressive data skewness mitigation tends to exacerbate data staleness. As a result, systems are forced to trade off convergence for performance, or vice versa. To address this, we propose StaleFlow, an RL post-training system that jointly tackles data staleness and skewness. First, to control staleness, StaleFlow introduces a global consistency protocol that tracks the full lifecycle of each trajectory and constrains staleness. Second, to mitigate skewness, StaleFlow re-designs the RL system architecture by constructing data servers for trajectories and parameters to achieve flexible rollout coordination. Subsequently, we develop a suite of staleness-aware, throughput-oriented strategies to enhance system performance. Evaluations show that StaleFlow achieves up to 1.42-2.68$\times$ (1.17-2.01$\times$ on average) higher throughput than state-of-the-art systems, without compromising convergence.

</details>


### [380] [From Design to Deorbit: A Solar-Electric Autonomous Module for Multi-Debris Remediation](https://arxiv.org/abs/2601.12830)
*Om Mishra,Jayesh Patil,Sathwik Narkedimilli,G Srikantha Sharma,Ananda S,Manjunath K Vanahalli*

Main category: cs.DC

TL;DR: 研究提出太阳能推进的轨道碎片清除方案，模拟验证高效脱轨和导航性能，减少燃料依赖。


<details>
  <summary>Details</summary>
Motivation: 轨道碎片的持续积累威胁太空操作的可持续性，当前依赖燃料的方法存在局限性，亟需创新解决方案。

Method: 采用高保真模拟验证了架构性能，包括机械夹持系统、太阳能NEXT推进器和基于雷达的EKF导航协议。

Result: 模拟结果显示，成功实现从800公里至100公里的逆行脱轨，位置RMSE小于10米，数据传递效率达93%（1秒内通过DTN协议）。

Conclusion: 该研究通过整合机械夹持系统、太阳能推进器和自主导航协议，为轨道碎片主动清除提供了一种创新解决方案，显著减少了传统燃料依赖并延长了任务寿命。

Abstract: The escalating accumulation of orbital debris threatens the sustainability of space operations, necessitating active removal solutions that overcome the limitations of current fuel-dependent methods. To address this, this study introduces a novel remediation architecture that integrates a mechanical clamping system for secure capture with a high-efficiency, solar-powered NASA Evolutionary Xenon Thruster (NEXT) and autonomous navigation protocols. High-fidelity simulations validate the architecture's capabilities, demonstrating a successful retrograde deorbit from 800 km to 100 km, <10m position Root Mean Square Errors (RMSE) via radar-based Extended Kalman Filter (EKF) navigation, and a 93\% data delivery efficiency within 1 second using Delay/Disruption Tolerant Network (DTN) protocols. This approach significantly advances orbital management by establishing a benchmark for renewable solar propulsion that minimizes reliance on conventional fuels and extends mission longevity for multi-target removal.

</details>


### [381] [On Resilient and Efficient Linear Secure Aggregation in Hierarchical Federated Learning](https://arxiv.org/abs/2601.12853)
*Shudi Weng,Xiang Zhang,Yizhou Zhao,Giuseppe Caire,Ming Xiao,Mikael Skoglund*

Main category: cs.DC

TL;DR: 本文研究了不可靠通信下分层安全聚合的基本限制，提出了一个最优协议，并改进了问题表述以更好地适应实际联邦学习场景。


<details>
  <summary>Details</summary>
Motivation: 研究在不可靠通信环境下实现鲁棒安全聚合的最小通信和随机性成本，并填补现有信息论安全聚合协议与实际联邦学习问题之间的差距。

Method: 研究了一个分层网络模型，其中客户端连接到多个中继，且客户端到中继和中继到服务器的链路都是间歇性的。提出了一个最优协议，并通过匹配的逆证明确认其最优性。

Result: 确定了最小通信和随机性成本，提出了一个最优协议，并通过改进的问题表述填补了理论与实践的差距。

Conclusion: 本文确定了在不可靠通信下分层安全聚合的基本限制，并提出了一个达到这些限制的最优协议。

Abstract: In this paper, we study the fundamental limits of hierarchical secure aggregation under unreliable communication. We consider a hierarchical network where each client connects to multiple relays, and both client-to-relay and relay-to-server links are intermittent. Under this setting, we characterize the minimum communication and randomness costs required to achieve robust secure aggregation. We then propose an optimal protocol that attains these minimum costs, and establish its optimality through a matching converse proof. In addition, we introduce an improved problem formulation that bridges the gap between existing information-theoretic secure aggregation protocols and practical real-world federated learning problems.

</details>


### [382] [Sutradhara: An Intelligent Orchestrator-Engine Co-design for Tool-based Agentic Inference](https://arxiv.org/abs/2601.12967)
*Anish Biswas,Kanishk Goel,Jayashree Mohan,Alind Khare,Anjaly Parayil,Ramachandran Ramjee,Chetan Bansal*

Main category: cs.DC

TL;DR: SUTRADHARA通过协同设计优化代理系统的延迟，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 代理应用中工具调用导致的延迟、KV缓存命中率下降和顺序编排浪费并行性是主要瓶颈，现有设计缺乏跨层优化。

Method: 提出了SUTRADHARA，一个集成了编排与LLM服务的代理推理系统，通过工具感知的提示分割、流式工具执行和编排感知的缓存管理三种优化。

Result: 在A100 GPU上，SUTRADHARA将中位FTR延迟降低了15%，端到端延迟降低了10%。

Conclusion: SUTRADHARA通过协同设计优化，显著降低了代理系统的延迟，证明了协同设计在代理系统中的有效性。

Abstract: Agentic applications are LLMs that iteratively invoke external tools to accomplish complex tasks. Such tool-based agents are rapidly becoming the dominant paradigm for deploying language models in production. Unlike traditional single-turn inference, agentic workloads chain together multiple LLM calls and tool executions before producing a final response, creating a new performance bottleneck that manifests as increased latency in First Token Rendered (FTR) of the final answer. Through analysis of synthetic requests at production scale, we reveal three critical challenges: tool calls account for 30-80% of FTR latency, KV cache hit rates collapse despite substantial context reuse across iterations, and sequential orchestration wastes potential intra-request parallelism by sequentially executing LLM calls and tools. These bottlenecks stem from a design gap in which orchestrators and LLM engines operate as decoupled black boxes, preventing cross-layer optimizations. We present SUTRADHARA, a co-designed agentic inference system that integrates orchestration with LLM serving through a thin API enabling three optimizations: overlap tool execution with subsequent LLM prefill using tool-aware prompt splitting, streaming tool execution to dispatch tools incrementally during decode rather than waiting for complete output, and orchestrator-aware cache management that uses semantic hints to improve hit rates and reduce thrashing. Implemented on vLLM, SUTRADHARA reduces median FTR latency by 15% and end-to-end latency by 10% across workloads on A100 GPUs, demonstrating that co-design can systematically tame latency in agentic systems.

</details>


### [383] [Enshrined Proposer Builder Separation in the presence of Maximal Extractable Value](https://arxiv.org/abs/2601.12989)
*Yitian Wang,Yebo Feng,Yingjiu Li,Jiahua Xu*

Main category: cs.DC

TL;DR: ePBS通过拍卖机制加剧利润集中化，提议者获大部分收益，需改进机制设计。


<details>
  <summary>Details</summary>
Motivation: 在PoS共识机制下，MEV的出现加剧了经济集中化和内容操纵的担忧，ePBS被提出以解决这些漏洞。

Method: 结合数学分析和基于代理的模拟，开发了一个正式框架来评估ePBS的拍卖式区块构建机制。

Result: ePBS下利润的基尼系数从0.1749升至0.8358，95.4%的区块价值奖励给提议者，显示经济偏见。

Conclusion: ePBS虽然重新分配了构建者和提议者的责任，但显著加剧了利润和内容集中化，表明需要未来研究更平衡去中心化、公平性和MEV缓解的机制设计。

Abstract: In blockchain systems operating under the Proof-of-Stake (PoS) consensus mechanism, fairness in transaction processing is essential to preserving decentralization and maintaining user trust. However, with the emergence of Maximal Extractable Value (MEV), concerns about economic centralization and content manipulation have intensified. To address these vulnerabilities, the Ethereum community has introduced Proposer Builder Separation (PBS), which separates block construction from block proposal. Later, enshrined Proposer Builder Separation (ePBS) was also proposed in EIP-7732, which embeds PBS directly into the Ethereum consensus layer.
  Our work identifies key limitations of ePBS by developing a formal framework that combines mathematical analysis and agent-based simulations to evaluate its auction-based block-building mechanism, with particular emphasis on MEV dynamics. Our results reveal that, although ePBS redistributes responsibilities between builders and proposers, it significantly amplifies profit and content centralization: the Gini coefficient for profits rises from 0.1749 under standard PoS without ePBS to 0.8358 under ePBS. This sharp increase indicates that a small number of efficient builders capture most value via MEV-driven auctions. Moreover, 95.4% of the block value is rewarded to proposers in ePBS, revealing a strong economic bias despite their limited role in block assembly. These findings highlight that ePBS exacerbates incentives for builders to adopt aggressive MEV strategies, suggesting the need for future research into mechanism designs that better balance decentralization, fairness, and MEV mitigation.

</details>


### [384] [CPU-less parallel execution of lambda calculus in digital logic](https://arxiv.org/abs/2601.13040)
*Harry Fitchett,Charles Fox*

Main category: cs.DC

TL;DR: 论文探索了将函数式语言直接编译为数字逻辑以实现并行计算的方法，通过lambda演算作为源语言进行了概念验证，展示了可行性。


<details>
  <summary>Details</summary>
Motivation: 随着晶体管密度的增加而时钟速度不再提升，需要寻找新的并行架构。

Method: 使用基于树的表示方法，将数据局部化于节点中，并通过消息传递进行通信。节点类型和行为对应于lambda语法形式，并行执行beta归约。

Result: 实现了概念验证系统，并通过模拟结果展示了lambda表达式的成功执行，表明该方法可扩展至更大的函数式语言。

Conclusion: 论文提出了一种将函数式语言直接编译为数字逻辑的方法，以最大化并行性，并通过概念验证系统展示了其可行性。

Abstract: While transistor density is still increasing, clock speeds are not, motivating the search for new parallel architectures. One approach is to completely abandon the concept of CPU -- and thus serial imperative programming -- and instead to specify and execute tasks in parallel, compiling from programming languages to data flow digital logic. It is well-known that pure functional languages are inherently parallel, due to the Church-Rosser theorem, and CPU-based parallel compilers exist for many functional languages. However, these still rely on conventional CPUs and their von Neumann bottlenecks. An alternative is to compile functional languages directly into digital logic to maximize available parallelism. It is difficult to work with complete modern functional languages due to their many features, so we demonstrate a proof-of-concept system using lambda calculus as the source language and compiling to digital logic. We show how functional hardware can be tailored to a simplistic functional language, forming the ground for a new model of CPU-less functional computation. At the algorithmic level, we use a tree-based representation, with data localized within nodes and communicated data passed between them. This is implemented by physical digital logic blocks corresponding to nodes, and buses enabling message passing. Node types and behaviors correspond to lambda grammar forms, and beta-reductions are performed in parallel allowing branches independent from one another to perform transformations simultaneously. As evidence for this approach, we present an implementation, along with simulation results, showcasing successful execution of lambda expressions. This suggests that the approach could be scaled to larger functional languages. Successful execution of a test suite of lambda expressions suggests that the approach could be scaled to larger functional languages.

</details>


### [385] [Exploration on Highly Dynamic Graphs](https://arxiv.org/abs/2601.13047)
*Ashish Saxena,Kaushik Mondal*

Main category: cs.DC

TL;DR: 本文强化了动态图中探索问题的不可能性结果，证明了严格代理数量下限，并提出了一个基于特定条件的探索算法。


<details>
  <summary>Details</summary>
Motivation: 研究动态图中移动代理的探索问题，尤其是在1-Interval Connectivity和Connectivity Time两种模型下的探索限制和可能性。

Method: 通过理论分析和算法设计，本文首先在1-Interval Connectivity模型中强化了不可能性结果，然后在Connectivity Time动态图中证明了探索问题的严格代理数量下限，并提出了一个基于特定条件的探索算法。

Result: 在Connectivity Time动态图中，探索需要至少(n-1)(n-2)/2 + 1个代理，且1-hop可见性是必要条件。本文还提出了一个满足条件的探索算法。

Conclusion: 本文在1-Interval Connectivity模型中强化了现有的不可能性结果，并在Connectivity Time动态图中证明了探索问题需要更多代理的严格下限。此外，提出了一个使用特定数量代理的探索算法，前提是满足全局通信、1-hop可见性和O(log n)内存的条件。

Abstract: We study the exploration problem by mobile agents in two prominent models of dynamic graphs: $1$-Interval Connectivity and Connectivity Time. The $1$-Interval Connectivity model was introduced by Kuhn et al.~[STOC 2010], and the Connectivity Time model was proposed by Michail et al.~[JPDC 2014]. Recently, Saxena et al.~[TCS 2025] investigated the exploration problem under both models. In this work, we first strengthen the existing impossibility results for the $1$-Interval Connectivity model. We then show that, in Connectivity Time dynamic graphs, exploration is impossible with $\frac{(n-1)(n-2)}{2}$ mobile agents, even when the agents have full knowledge of all system parameters, global communication, full visibility, and infinite memory. This significantly improves the previously known bound of $n$. Moreover, we prove that to solve exploration with $\frac{(n-1)(n-2)}{2}+1$ agents, $1$-hop visibility is necessary. Finally, we present an exploration algorithm that uses $\frac{(n-1)(n-2)}{2}+1$ agents, assuming global communication, $1$-hop visibility, and $O(\log n)$ memory per agent.

</details>


### [386] [OPTIMUM-DERAM: Highly Consistent, Scalable, and Secure Multi-Object Memory using RLNC](https://arxiv.org/abs/2601.13146)
*Nicolas Nicolaou,Kishori M. Konwar,Moritz Grundei,Aleksandr Bezobchuk,Muriel Médard,Sriram Vishwanath*

Main category: cs.DC

TL;DR: OPTIMUM-DERAM 是一种去中心化共享内存方案，通过 RLNC、一致性哈希环和区块链预言机实现高性能和可扩展性，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统分布式共享内存实现因资源需求过高而在实际系统中难以应用，OPTIMUM-DERAM 旨在解决这一问题，提供更高效的解决方案。

Method: OPTIMUM-DERAM 结合了随机线性网络编码（RLNC）、一致性哈希环的对象放置与发现方法、区块链预言机作为注册服务，以及拜占庭容错机制。

Result: 实验结果表明，OPTIMUM-DERAM 在性能和可扩展性上优于传统方案。

Conclusion: OPTIMUM-DERAM 是一种高效、可扩展、安全且去中心化的共享内存解决方案，通过实验验证其在性能和可扩展性上优于传统分布式共享内存实现（如 ABD 算法）。

Abstract: This paper introduces OPTIMUM-DERAM, a highly consistent, scalable, secure, and decentralized shared memory solution. Traditional distributed shared memory implementations offer multi-object support by multi-threading a single object memory instance over the same set of data hosts. While theoretically sound, the amount of resources required made such solutions prohibitively expensive in practical systems. OPTIMUM-DERAM proposes a decentralized, reconfigurable, atomic read/write shared memory (DeRAM) that: (i) achieves improved performance and storage scalability by leveraging Random Linear Network Codes (RLNC); (ii) scales in the number of supported atomic objects by introducing a new object placement and discovery approach based on a consistent hashing ring; (iii) scales in the number of participants by allowing dynamic joins and departures leveraging a blockchain oracle to serve as a registry service; and (iv) is secure against malicious behavior by tolerating Byzantine failures.
  Experimental results over a globally distributed set of nodes, help us realize the performance and scalability gains of OPTIMUM-DERAM over previous distributed shared memory solutions (i.e., the ABD algorithm [3])

</details>


### [387] [Towards Scalable Federated Container Orchestration: The CODECO Approach](https://arxiv.org/abs/2601.13351)
*Rute C. Sofia,Josh Salomon,Ray Carrol,Luis Garcés-Erice,Peter Urbanetz,Jürgen Gesswein,Rizkallah Touma,Alejandro Espinosa,Luis M. Contreras,Vasileios Theodorou,George Papathanail,Georgios Koukis,Vassilis Tsaoussidis,Alberto del Rio,David Jimenez,Efterpi Paraskevoulakou,Panagiotis Karamolegkos,John Soldatos,Borja Dorado Nogales,Alejandro Tjaarda*

Main category: cs.DC

TL;DR: CODECO是一个Kubernetes联邦编排框架，通过数据-计算-网络协同编排支持异构基础设施和移动性，扩展了Kubernetes功能并引入AI辅助决策。


<details>
  <summary>Details</summary>
Motivation: 解决云中心化部署在异构基础设施、移动性和多提供商操作中的局限性。

Method: CODECO扩展了Kubernetes，引入了语义应用模型、基于分区的联邦和AI辅助决策支持，实现了跨联邦环境的上下文感知应用放置和自适应管理。

Result: CODECO的架构和核心组件支持上下文感知应用放置和自适应管理，混合治理模型结合了集中策略执行与分散执行和学习。

Conclusion: CODECO通过数据-计算-网络协同编排的方法，解决了云中心化部署的局限性，支持异构基础设施、移动性和多提供商操作。

Abstract: This paper presents CODECO, a federated orchestration framework for Kubernetes that addresses the limitations of cloud-centric deployment. CODECO adopts a data-compute-network co-orchestration approach to support heterogeneous infrastructures, mobility, and multi-provider operation.
  CODECO extends Kubernetes with semantic application models, partition-based federation, and AI-assisted decision support, enabling context-aware placement and adaptive management of applications and their micro-services across federated environments. A hybrid governance model combines centralized policy enforcement with decentralized execution and learning to preserve global coherence while supporting far Edge autonomy. The paper describes the architecture and core components of CODECO, outlines representative orchestration workflows, and introduces a software-based experimentation framework for reproducible evaluation in federated Edge-Cloud infrastructure environments.

</details>


### [388] [Driving Computational Efficiency in Large-Scale Platforms using HPC Technologies](https://arxiv.org/abs/2601.13424)
*Alexander Martinez Mendez,Antonio J. Rubio-Montero,Carlos J. Barrios H.,Hernán Asorey,Rafael Mayo-García,Luis A. Núñez*

Main category: cs.DC

TL;DR: LAGO项目通过分析HPC资源使用效率，发现高CPU效率与短测试作业的负面影响，并提出优化建议以提升科学产出。


<details>
  <summary>Details</summary>
Motivation: LAGO项目依赖高性能计算资源进行复杂的宇宙线物理模拟，资源利用效率对科学生产力和可持续性至关重要。

Method: 通过分析EGI FedCloud平台的历史作业会计数据，识别主要工作负载类别（蒙特卡洛模拟、数据处理、用户分析/测试），并使用关键效率指标（CPU利用率、walltime利用率、I/O模式）评估其性能。

Result: 分析揭示了显著的模式，包括单个模拟任务中的高CPU效率与短测试作业对整体指标的扭曲影响。

Conclusion: 本研究通过分析LAGO项目中的HPC资源使用效率，提出了优化资源请求和改进工作流管理的具体建议，旨在最大化科学产出。

Abstract: The Latin American Giant Observatory (LAGO) project utilizes extensive High-Performance Computing (HPC) resources for complex astroparticle physics simulations, making resource efficiency critical for scientific productivity and sustainability. This article presents a detailed analysis focused on quantifying and improving HPC resource utilization efficiency specifically within the LAGO computational environment. The core objective is to understand how LAGO's distinct computational workloads-characterized by a prevalent coarse-grained, task-parallel execution model-consume resources in practice. To achieve this, we analyze historical job accounting data from the EGI FedCloud platform, identifying primary workload categories (Monte Carlo simulations, data processing, user analysis/testing) and evaluating their performance using key efficiency metrics (CPU utilization, walltime utilization, and I/O patterns). Our analysis reveals significant patterns, including high CPU efficiency within individual simulation tasks contrasted with the distorting impact of short test jobs on aggregate metrics. This work pinpoints specific inefficiencies and provides data-driven insights into LAGO's HPC usage. The findings directly inform recommendations for optimizing resource requests, refining workflow management strategies, and guiding future efforts to enhance computational throughput, ultimately maximizing the scientific return from LAGO's HPC investments.

</details>


### [389] [RASC: Enhancing Observability & Programmability in Smart Spaces](https://arxiv.org/abs/2601.13496)
*Anna Karanika,Kai-Siang Wang,Han-Ting Liang,Shalni Sundram,Indranil Gupta*

Main category: cs.DC

TL;DR: RASC是一种针对IoT设备的新抽象，提升动作可观察性和可编程性，实际表现优于现有方案。


<details>
  <summary>Details</summary>
Motivation: 现有RPC抽象在用户面向的IoT设备集合（如家庭、仓库、办公室）中表现不足，需提升动作的可观察性和可编程性。

Method: 提出了RASC（Request-Acknowledge-Start-Complete）抽象，并在开源IoT框架Home Assistant中实现。

Result: RASC能够准确预测动作完成时间、快速检测动作失败、支持细粒度依赖编程和调度，且在长动作（O(mins)）中满足延迟SLO，调度策略优于现有方案10%-55%。

Conclusion: RASC是一种更适合IoT设备的抽象，能够提升可观察性和可编程性，并在实际应用中表现出色，尤其在长时间动作和调度策略上优于现有方案。

Abstract: While RPCs form the bedrock of systems stacks, we posit that IoT device collections in smart spaces like homes, warehouses, and office buildings--which are all "user-facing"--require a more expressive abstraction. Orthogonal to prior work, which improved the reliability of IoT communication, our work focuses on improving the observability and programmability of IoT actions. We present the RASC (Request-Acknowledge-Start-Complete) abstraction, which provides acknowledgments at critical points after an IoT device action is initiated. RASC is a better fit for IoT actions, which naturally vary in length spatially (across devices) and temporally (across time, for a given device). RASC also enables the design of several new features: predicting action completion times accurately, detecting failures of actions faster, allowing fine-grained dependencies in programming, and scheduling. RASC is intended to be implemented atop today's available RPC mechanisms, rather than as a replacement. We integrated RASC into a popular and open-source IoT framework called Home Assistant. Our trace-driven evaluation finds that RASC meets latency SLOs, especially for long actions that last O(mins), which are common in smart spaces. Our scheduling policies for home automations (e.g., routines) outperform state-of-the-art counterparts by 10%-55%.

</details>


### [390] [A Kubernetes custom scheduler based on reinforcement learning for compute-intensive pods](https://arxiv.org/abs/2601.13579)
*Hanlin Zhou,Huah Yong Chan,Shun Yao Zhang,Meie Lin,Jingfei Ni*

Main category: cs.DC

TL;DR: 提出两种基于DQN的Kubernetes调度器SDQN和SDQN-n，在计算密集型场景中显著降低CPU利用率，SDQN-n更节省资源。


<details>
  <summary>Details</summary>
Motivation: 针对计算密集型工作负载（如容器化机器学习训练），默认Kubernetes调度器无法实现最优放置。

Method: 提出了两种基于深度Q网络（DQN）的定制调度器SDQN和SDQN-n。

Result: 在计算密集型场景中，SDQN和SDQN-n表现优于默认调度器及基于Transformer和LSTM的替代方案，分别降低集群节点平均CPU利用率10%和20%以上。SDQN-n通过将pod整合到更少节点进一步节省资源。

Conclusion: Pod scheduling should采用定制策略以适应不同场景，以提升性能。SDQN和SDQN-n架构的强化学习组件可通过参数调整适应未来需求。

Abstract: With the rise of cloud computing and lightweight containers, Docker has emerged as a leading technology for rapid service deployment, with Kubernetes responsible for pod orchestration. However, for compute-intensive workloads-particularly web services executing containerized machine-learning training-the default Kubernetes scheduler does not always achieve optimal placement. To address this, we propose two custom, reinforcement-learning-based schedulers, SDQN and SDQN-n, both built on the Deep Q-Network (DQN) framework. In compute-intensive scenarios, these models outperform the default Kubernetes scheduler as well as Transformer-and LSTM-based alternatives, reducing average CPU utilization per cluster node by 10%, and by over 20% when using SDQN-n. Moreover, our results show that SDQN-n approach of consolidating pods onto fewer nodes further amplifies resource savings and helps advance greener, more energy-efficient data centers.Therefore, pod scheduling must employ different strategies tailored to each scenario in order to achieve better performance.Since the reinforcement-learning components of the SDQN and SDQN-n architectures proposed in this paper can be easily tuned by adjusting their parameters, they can accommodate the requirements of various future scenarios.

</details>


### [391] [Device Association and Resource Allocation for Hierarchical Split Federated Learning in Space-Air-Ground Integrated Network](https://arxiv.org/abs/2601.13817)
*Haitao Zhao,Xiaoyu Tang,Bo Xu,Jinlong Sun,Linghao Zhang*

Main category: cs.DC

TL;DR: 论文提出HSFL框架及优化算法，解决SAGIN中FL的资源与数据不平衡问题，通过迭代优化平衡效率与准确性。


<details>
  <summary>Details</summary>
Motivation: 解决6G环境下SAGIN中FL面临的资源受限和数据分布不平衡等挑战。

Method: 通过分解原始问题为多个子问题，提出了一种基于暴力搜索分割点的迭代优化算法，用于设备关联和资源分配。

Result: 仿真结果表明，所提算法能有效平衡SAGIN中FL的训练效率和模型准确性。

Conclusion: 该论文提出的HSFL框架及其优化算法在SAGIN中有效平衡了训练效率和模型准确性。

Abstract: 6G facilitates deployment of Federated Learning (FL) in the Space-Air-Ground Integrated Network (SAGIN), yet FL confronts challenges such as resource constrained and unbalanced data distribution. To address these issues, this paper proposes a Hierarchical Split Federated Learning (HSFL) framework and derives its upper bound of loss function. To minimize the weighted sum of training loss and latency, we formulate a joint optimization problem that integrates device association, model split layer selection, and resource allocation. We decompose the original problem into several subproblems, where an iterative optimization algorithm for device association and resource allocation based on brute-force split point search is proposed. Simulation results demonstrate that the proposed algorithm can effectively balance training efficiency and model accuracy for FL in SAGIN.

</details>


### [392] [torch-sla: Differentiable Sparse Linear Algebra with Adjoint Solvers and Sparse Tensor Parallelism for PyTorch](https://arxiv.org/abs/2601.13994)
*Mingyuan Chi*

Main category: cs.DC

TL;DR: torchsla 是一个支持 GPU 加速、可扩展且可微分的稀疏线性代数库，解决了工业科学计算中的关键问题。


<details>
  <summary>Details</summary>
Motivation: 工业科学计算中稀疏矩阵广泛应用于非结构化数据（如有限元网格、图、点云），但现有工具在 GPU 加速、可扩展性和微分支持方面存在不足。

Method: 通过多 GPU 扩展（域分解与 halo 交换）和基于伴随的微分技术，实现了高效的稀疏线性求解、非线性求解和特征值计算。

Result: 实现了 4 亿自由度线性求解（3 GPU），并支持 O(1) 计算图节点和 O(nnz) 内存的微分。

Conclusion: torchsla 是一个开源的 PyTorch 库，支持 GPU 加速、可扩展且可微分的稀疏线性代数运算，解决了稀疏线性代数在工业科学计算中的关键挑战。

Abstract: Industrial scientific computing predominantly uses sparse matrices to represent unstructured data -- finite element meshes, graphs, point clouds. We present \torchsla{}, an open-source PyTorch library that enables GPU-accelerated, scalable, and differentiable sparse linear algebra. The library addresses three fundamental challenges: (1) GPU acceleration for sparse linear solves, nonlinear solves (Newton, Picard, Anderson), and eigenvalue computation; (2) Multi-GPU scaling via domain decomposition with halo exchange, reaching \textbf{400 million DOF linear solve on 3 GPUs}; and (3) Adjoint-based differentiation} achieving $\mathcal{O}(1)$ computational graph nodes (for autograd) and $\mathcal{O}(\text{nnz})$ memory -- independent of solver iterations. \torchsla{} supports multiple backends (SciPy, cuDSS, PyTorch-native) and seamlessly integrates with PyTorch autograd for end-to-end differentiable simulations. Code is available at https://github.com/walkerchi/torch-sla.

</details>


### [393] [Multi-Partner Project: Multi-GPU Performance Portability Analysis for CFD Simulations at Scale](https://arxiv.org/abs/2601.14159)
*Panagiotis-Eleftherios Eleftherakis,George Anagnostopoulos,Anastassis Kapetanakis,Mohammad Umair,Jean-Yves Vet,Konstantinos Iliakis,Jonathan Vincent,Jing Gong,Akshay Patil,Clara García-Sánchez,Gerardo Zampino,Ricardo Vinuesa,Sotirios Xydis*

Main category: cs.DC

TL;DR: 本文研究了SOD2D在AMD和NVIDIA GPU上的性能可移植性，发现内存优化对加速效果影响显著（0.69×-3.91×），并指出多级调优的必要性。


<details>
  <summary>Details</summary>
Motivation: 随着异构超级计算架构（如GPU）在高性能计算（HPC）中的核心地位日益突出，确保计算流体动力学（CFD）模拟能高效利用此类硬件变得至关重要。

Method: 研究首先讨论了SOD2D的物理和数值模型，识别其计算热点；随后通过多级方式（涵盖应用、软件和硬件基础设施参数）评估其性能和可扩展性。

Result: 单GPU性能测试显示内存访问优化对加速性能有显著影响，而在LUMI多GPU集群上的分析进一步揭示了性能变化的相似性。

Conclusion: 论文分析了SOD2D在AMD和NVIDIA GPU架构上的性能可移植性，揭示了内存访问优化对加速性能的显著影响（0.69×至3.91×的偏差），并强调了在多级、信息化的调优中性能预测的局限性。

Abstract: As heterogeneous supercomputing architectures leveraging GPUs become increasingly central to high-performance computing (HPC), it is crucial for computational fluid dynamics (CFD) simulations, a de-facto HPC workload, to efficiently utilize such hardware. One of the key challenges of HPC codes is performance portability, i.e. the ability to maintain near-optimal performance across different accelerators. In the context of the \textbf{REFMAP} project, which targets scalable, GPU-enabled multi-fidelity CFD for urban airflow prediction, this paper analyzes the performance portability of SOD2D, a state-of-the-art Spectral Elements simulation framework across AMD and NVIDIA GPU architectures. We first discuss the physical and numerical models underlying SOD2D, highlighting its computational hotspots. Then, we examine its performance and scalability in a multi-level manner, i.e. defining and characterizing an extensive full-stack design space spanning across application, software and hardware infrastructure related parameters. Single-GPU performance characterization across server-grade NVIDIA and AMD GPU architectures and vendor-specific compiler stacks, show the potential as well as the diverse effect of memory access optimizations, i.e. 0.69$\times$ - 3.91$\times$ deviations in acceleration speedup. Performance variability of SOD2D at scale is further examined on the LUMI multi-GPU cluster, where profiling reveals similar throughput variations, highlighting the limits of performance projections and the need for multi-level, informed tuning.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [394] [MIMIC-RD: Can LLMs differentially diagnose rare diseases in real-world clinical settings?](https://arxiv.org/abs/2601.11559)
*Zilal Eiz AlDin,John Wu,Jeffrey Paul Fung,Jennifer King,Mya Watts,Lauren ONeill,Adam Richard Cross,Jimeng Sun*

Main category: cs.AI

TL;DR: 构建MIMIC-RD基准评估LLMs罕见病诊断能力，发现现有模型表现不足，需改进。


<details>
  <summary>Details</summary>
Motivation: 由于罕见病影响十分之一的美国人，但其鉴别诊断仍具挑战性。现有评估LLM罕见病诊断的方法存在两个关键局限。

Method: 我们探索了MIMIC-RD，一个通过直接将临床文本实体映射到Orphanet构建的罕见病鉴别诊断基准。方法包括初始的LLM挖掘过程和四位医学注释者的验证。

Result: 在145名患者的数据集上评估多种模型，发现当前LLMs表现不佳。

Conclusion: 当前最先进的大型语言模型在罕见病鉴别诊断上表现不佳，凸显了现有能力与临床需求之间的巨大差距。

Abstract: Despite rare diseases affecting 1 in 10 Americans, their differential diagnosis remains challenging. Due to their impressive recall abilities, large language models (LLMs) have been recently explored for differential diagnosis. Existing approaches to evaluating LLM-based rare disease diagnosis suffer from two critical limitations: they rely on idealized clinical case studies that fail to capture real-world clinical complexity, or they use ICD codes as disease labels, which significantly undercounts rare diseases since many lack direct mappings to comprehensive rare disease databases like Orphanet. To address these limitations, we explore MIMIC-RD, a rare disease differential diagnosis benchmark constructed by directly mapping clinical text entities to Orphanet. Our methodology involved an initial LLM-based mining process followed by validation from four medical annotators to confirm identified entities were genuine rare diseases. We evaluated various models on our dataset of 145 patients and found that current state-of-the-art LLMs perform poorly on rare disease differential diagnosis, highlighting the substantial gap between existing capabilities and clinical needs. From our findings, we outline several future steps towards improving differential diagnosis of rare diseases.

</details>


### [395] [A Mind Cannot Be Smeared Across Time](https://arxiv.org/abs/2601.11620)
*Michael Timothy Bennett*

Main category: cs.AI

TL;DR: 论文探讨机器意识的可能性，指出顺序硬件上无法实现软件意识，需硬件架构支持。通过理论扩展和证据分析，支持强同步假设。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探讨机器是否能具备意识，特别是考虑到人工系统通常通过顺序或时间复用更新实现功能，而意识体验则表现为统一和同时。

Method: 作者扩展了Stack Theory，引入了代数定律和时间窗口约束满足与合取的关系，并提出了精确的时间语义。

Result: 结果表明，存在时间实现（◇Δ）不保留合取，系统可以在时间上实现所有体验的组成部分，而无需实例化体验的合取本身。

Conclusion: 论文得出结论，严格的顺序硬件上无法实现软件意识，尤其是当内容需要两个或更多同时贡献者时。意识归因需要硬件架构检查，而不仅仅是功能性能。

Abstract: Whether machines can be conscious depends not only on what they compute, but \emph{when} they compute it. Most deployed artificial systems realise their functions via sequential or time-multiplexed updates. Conscious experience appears unified and simultaneous. I show that this difference matters formally. I augment Stack Theory with algebraic laws relating within time-window constraint satisfaction to conjunction. I introduce a precise temporal semantics over windowed trajectories $τ^{Δ,s}$ and prove that existential temporal realisation $\Diamond_Δ$ does not preserve conjunction. A system can realise all the ingredients of experience across time without ever instantiating the experienced conjunction itself. I then distinguish two postulates. StrongSync requires objective co-instantiation of the grounded conjunction within the window, while WeakSync permits temporal ``smearing''. I formalise concurrency-capacity to measure what is needed to satisfy StrongSync. Finally, I review neurophysiological evidence suggesting that consciousness depends on phase synchrony and effective connectivity, and that loss of consciousness is often associated with its breakdown. This evidence makes WeakSync less plausible. Under StrongSync, software consciousness on strictly sequential substrates is impossible for contents whose grounding requires two or more simultaneous contributors. The more parts from which simultaneous contribution required, the more concurrency capacity is required. The hardware matters. Consciousness attribution therefore requires architectural inspection, not just functional performance.

</details>


### [396] [Dynamical Systems Analysis Reveals Functional Regimes in Large Language Models](https://arxiv.org/abs/2601.11622)
*Hassan Ugail,Newton Howard*

Main category: cs.AI

TL;DR: 论文提出了一种受神经科学启发的动态指标，用于量化大型语言模型在不同功能状态下的计算组织差异，结果显示结构化推理条件下的动态特性显著优于其他条件。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的内部动态机制尚未被充分理解，尤其是其时间组织。本研究旨在填补这一空白，借鉴神经科学中的时间整合和亚稳态概念，探索变压器模型的动态特性。

Method: 研究者提出了一种复合动态指标，通过分析自回归生成过程中的激活时间序列来评估模型的动态特性。该方法在GPT-2-medium模型上进行了五种条件的测试：结构化推理、强制重复、高温噪声采样、注意力头剪枝和权重噪声注入。

Result: 结构化推理条件下的动态指标显著高于重复、噪声和扰动条件，统计差异显著（通过单因素方差分析验证），且关键比较中效应量大。这些结果对层选择、通道子采样和随机种子具有鲁棒性。

Conclusion: 研究结果表明，受神经科学启发的动态指标能够可靠地描述大型语言模型中不同功能状态下的计算组织差异。

Abstract: Large language models perform text generation through high-dimensional internal dynamics, yet the temporal organisation of these dynamics remains poorly understood. Most interpretability approaches emphasise static representations or causal interventions, leaving temporal structure largely unexplored. Drawing on neuroscience, where temporal integration and metastability are core markers of neural organisation, we adapt these concepts to transformer models and discuss a composite dynamical metric, computed from activation time-series during autoregressive generation. We evaluate this metric in GPT-2-medium across five conditions: structured reasoning, forced repetition, high-temperature noisy sampling, attention-head pruning, and weight-noise injection. Structured reasoning consistently exhibits elevated metric relative to repetitive, noisy, and perturbed regimes, with statistically significant differences confirmed by one-way ANOVA and large effect sizes in key comparisons. These results are robust to layer selection, channel subsampling, and random seeds. Our findings demonstrate that neuroscience-inspired dynamical metrics can reliably characterise differences in computational organisation across functional regimes in large language models. We stress that the proposed metric captures formal dynamical properties and does not imply subjective experience.

</details>


### [397] [Reasoning Stabilization Point: A Training-Time Signal for Stable Evidence and Shortcut Reliance](https://arxiv.org/abs/2601.11625)
*Sahil Rajesh Dhayalkar*

Main category: cs.AI

TL;DR: 提出解释漂移概念，用于监控微调过程中模型依赖证据的变化，并识别推理稳定点（RSP），实验表明漂移早期稳定且与验证准确率变化无关。


<details>
  <summary>Details</summary>
Motivation: 微调预训练语言模型可以提高任务性能，但会微妙地改变模型依赖的证据。研究旨在监控和诊断微调过程中决策依据的演变。

Method: 提出了一种训练时解释性视角，通过跟踪微调周期中令牌级别的归因变化，定义解释漂移为固定探测集上归一化令牌归因的周期间变化，并引入了推理稳定点（RSP），即漂移持续保持低水平的最早周期。RSP通过内部漂移动态计算，无需调整分布外数据。

Result: 在多个轻量级Transformer分类器和基准分类任务中，漂移通常在训练早期就进入低且稳定的状态，而验证准确率仅发生微小变化。在带有标签相关触发令牌的受控捷径设置中，归因动态揭示了模型对捷径的依赖增加，即使验证准确率保持竞争力。

Conclusion: 解释漂移（explanation drift）提供了一种简单、低成本的方法来监控微调过程中决策依据的演变，并选择在稳定证据状态下的检查点。

Abstract: Fine-tuning pretrained language models can improve task performance while subtly altering the evidence a model relies on. We propose a training-time interpretability view that tracks token-level attributions across finetuning epochs. We define explanation driftas the epoch-to-epoch change in normalized token attributions on a fixed probe set, and introduce the Reasoning Stabilization Point(RSP), the earliest epoch after which drift remains consistently low. RSP is computed from within-run drift dynamics and requires no tuning on out-of-distribution data. Across multiple lightweight transformer classifiers and benchmark classification tasks, drift typically collapses into a low, stable regime early in training, while validation accuracy continues to change only marginally. In a controlled shortcut setting with label-correlated trigger tokens, attribution dynamics expose increasing reliance on the shortcut even when validation accuracy remains competitive. Overall, explanation drift provides a simple, low-cost diagnostic for monitoring how decision evidence evolves during fine-tuning and for selecting checkpoints in a stable-evidence regime.

</details>


### [398] [PRISM: Learning Design Knowledge from Data for Stylistic Design Improvement](https://arxiv.org/abs/2601.11747)
*Huaxiaoyue Wang,Sunav Choudhary,Franck Dernoncourt,Yu Shen,Stefano Petrangeli*

Main category: cs.AI

TL;DR: PRISM利用设计数据构建知识库，通过聚类、总结和检索三阶段实现风格改进，实验和用户研究均验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决非专业人士在图形设计中探索不同风格方向时耗时的问题，并利用设计数据（隐含设计师原则的真实设计集合）来学习和指导风格改进。

Method: PRISM通过三个阶段构建和应用设计知识库：(1)聚类高方差设计以捕捉风格多样性，(2)将每个聚类总结为可操作的设计知识，(3)在推理过程中检索相关知识以实现风格感知的改进。

Result: 在Crello数据集上，PRISM在风格对齐方面取得了1.49的平均排名（越接近1越好），优于基线方法。用户研究进一步验证了PRISM的优越性。

Conclusion: PRISM方法通过构建和应用设计知识库，显著提升了基于自然语言指令的图形设计风格改进效果，并在用户研究中获得设计师的一致认可。

Abstract: Graphic design often involves exploring different stylistic directions, which can be time-consuming for non-experts. We address this problem of stylistically improving designs based on natural language instructions. While VLMs have shown initial success in graphic design, their pretrained knowledge on styles is often too general and misaligned with specific domain data. For example, VLMs may associate minimalism with abstract designs, whereas designers emphasize shape and color choices. Our key insight is to leverage design data -- a collection of real-world designs that implicitly capture designer's principles -- to learn design knowledge and guide stylistic improvement. We propose PRISM (PRior-Informed Stylistic Modification) that constructs and applies a design knowledge base through three stages: (1) clustering high-variance designs to capture diversity within a style, (2) summarizing each cluster into actionable design knowledge, and (3) retrieving relevant knowledge during inference to enable style-aware improvement. Experiments on the Crello dataset show that PRISM achieves the highest average rank of 1.49 (closer to 1 is better) over baselines in style alignment. User studies further validate these results, showing that PRISM is consistently preferred by designers.

</details>


### [399] [Risk-Aware Human-in-the-Loop Framework with Adaptive Intrusion Response for Autonomous Vehicles](https://arxiv.org/abs/2601.11781)
*Dawood Wasif,Terrence J. Moore,Seunghyun Yoon,Hyuk Lim,Dan Dongseong Kim,Frederica F. Nelson,Jin-Hee Cho*

Main category: cs.AI

TL;DR: RAIL是一种风险感知的人机协作框架，通过动态风险评估和防护策略选择，显著提升自动驾驶的安全性和性能，尤其在入侵和罕见场景下表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶在罕见长尾场景或网络物理入侵时的安全性和有效性挑战。

Method: RAIL融合了三种信号（曲率执行完整性、碰撞时间接近度和观测偏移一致性）通过加权Noisy-OR生成入侵风险评分（IRS），并结合上下文多臂老虎机动态选择防护策略。采用SAC算法，结合风险优先回放和双重奖励机制。

Result: 在MetaDrive中，RAIL实现了360.65的测试回报、0.85的成功率、0.75的安全违规率和0.0027的干扰率；在CAN注入和LiDAR欺骗攻击下，成功率提升至0.68和0.80。在CARLA中，仅用8000步就达到1609.70的测试回报和0.41的成功率。

Conclusion: RAIL框架在自动驾驶中表现出色，通过风险感知和人机协作机制，显著提升了安全性和成功率，尤其在面对网络物理入侵和长尾场景时。

Abstract: Autonomous vehicles must remain safe and effective when encountering rare long-tailed scenarios or cyber-physical intrusions during driving. We present RAIL, a risk-aware human-in-the-loop framework that turns heterogeneous runtime signals into calibrated control adaptations and focused learning. RAIL fuses three cues (curvature actuation integrity, time-to-collision proximity, and observation-shift consistency) into an Intrusion Risk Score (IRS) via a weighted Noisy-OR. When IRS exceeds a threshold, actions are blended with a cue-specific shield using a learned authority, while human override remains available; when risk is low, the nominal policy executes. A contextual bandit arbitrates among shields based on the cue vector, improving mitigation choices online. RAIL couples Soft Actor-Critic (SAC) with risk-prioritized replay and dual rewards so that takeovers and near misses steer learning while nominal behavior remains covered. On MetaDrive, RAIL achieves a Test Return (TR) of 360.65, a Test Success Rate (TSR) of 0.85, a Test Safety Violation (TSV) of 0.75, and a Disturbance Rate (DR) of 0.0027, while logging only 29.07 training safety violations, outperforming RL, safe RL, offline/imitation learning, and prior HITL baselines. Under Controller Area Network (CAN) injection and LiDAR spoofing attacks, it improves Success Rate (SR) to 0.68 and 0.80, lowers the Disengagement Rate under Attack (DRA) to 0.37 and 0.03, and reduces the Attack Success Rate (ASR) to 0.34 and 0.11. In CARLA, RAIL attains a TR of 1609.70 and TSR of 0.41 with only 8000 steps.

</details>


### [400] [A self-evolving multi-role collaborative framework with fine-grained difficulty guidance for innovative mathematical problem generation](https://arxiv.org/abs/2601.11792)
*Yifei Sun,Yongan Li,A. K. Qin,Sicheng Hou,Tamas Pflanzner*

Main category: cs.AI

TL;DR: 本文提出了一种自演化的多角色协作框架，通过改进难度模型和多阶段训练，显著提升了数学问题生成的创新性，同时保持高正确率。


<details>
  <summary>Details</summary>
Motivation: 现有大语言模型（LLMs）在数学问题生成（MPG）任务中虽然正确率高，但缺乏创新性和区分度，因此提出了创新性数学问题生成（IMPG）任务。

Method: 本文提出了一种自演化的多角色协作框架，包含采样器、生成器、评估器、状态机和记忆模块，并通过迭代优化确保生成问题的正确性。同时，引入了改进的难度模型和DAPS算法来增强语义合理性。此外，采用了多阶段训练流程（CPT、SFT、GRPO）和蒸馏技术实现系统自演化。

Result: 构建了HSM3K-CN数据集，并通过实验验证了方法的有效性，显著提升了问题的创新性。

Conclusion: 实验结果表明，与基线模型相比，本文提出的方法在保持高正确率的同时显著提升了生成问题的创新性。

Abstract: Mathematical problem generation (MPG) is a significant research direction in the field of intelligent education. In recent years, the rapid development of large language models (LLMs) has enabled new technological approaches to problem-generation tasks. Although existing LLMs can achieve high correctness rates, they generally lack innovation and exhibit poor discrimination. In this paper, we propose the task of innovative math problem generation (IMPG). To solve the IMPG task, this paper proposes a self-evolving, multi-role collaborative framework with fine-grained difficulty guidance. First, a multi-role collaborative mechanism comprising a sampler, generator, evaluator, state machine, and memory is constructed, ensuring the correctness of generated problems through iterative optimization informed by self-assessment and external feedback. Second, we introduce an improved difficulty model to quantify difficulty and provide fine-grained guidance. We adopt the data-driven association-guided path sampling (DAPS) algorithm to enhance the semantic rationality of sampled encodings. Third, we construct the HSM3K-CN dataset, which comprises high-quality high school math problems. A multi-stage training pipeline is adopted, incorporating continual pre-training (CPT), supervised fine-tuning (SFT), and group relative policy optimization (GRPO), to enhance the generation and evaluation capabilities of the base model. Finally, system self-evolution is achieved by transferring evaluation capabilities from the expert model to the apprentice model via distillation. Experiments show that, compared to baseline models, our proposed method significantly improves the innovation of the generated problems while maintaining a high correctness rate.

</details>


### [401] [Multi-agent DRL-based Lane Change Decision Model for Cooperative Planning in Mixed Traffic](https://arxiv.org/abs/2601.11809)
*Zeyu Mu,Shangtong Zhang,B. Brian Park*

Main category: cs.AI

TL;DR: 研究提出CNN-QMIX模型，通过多智能体协作提升CAV编队率，优化早期部署交通效率。


<details>
  <summary>Details</summary>
Motivation: CAV在早期部署阶段分布稀疏，难以形成有效协作编队，需提升其参与率以最大化效益。

Method: 采用QMIX框架结合卷积神经网络（CNN-QMIX）处理交通数据，并设计了轨迹规划器和模型预测控制器以确保安全执行车道变更。

Result: 模型在微观仿真环境中表现优于基于规则的基准模型，能高效应对交通参与者数量波动。

Conclusion: 该研究提出的混合多智能体车道变更决策模型（CNN-QMIX）在动态交通场景中表现优异，显著提高了CAV的协作编队率（最高达26.2%），优化了早期部署阶段的交通效率。

Abstract: Connected automated vehicles (CAVs) possess the ability to communicate and coordinate with one another, enabling cooperative platooning that enhances both energy efficiency and traffic flow. However, during the initial stage of CAV deployment, the sparse distribution of CAVs among human-driven vehicles reduces the likelihood of forming effective cooperative platoons. To address this challenge, this study proposes a hybrid multi-agent lane change decision model aimed at increasing CAV participation in cooperative platooning and maximizing its associated benefits. The proposed model employs the QMIX framework, integrating traffic data processed through a convolutional neural network (CNN-QMIX). This architecture addresses a critical issue in dynamic traffic scenarios by enabling CAVs to make optimal decisions irrespective of the varying number of CAVs present in mixed traffic. Additionally, a trajectory planner and a model predictive controller are designed to ensure smooth and safe lane-change execution. The proposed model is trained and evaluated within a microsimulation environment under varying CAV market penetration rates. The results demonstrate that the proposed model efficiently manages fluctuating traffic agent numbers, significantly outperforming the baseline rule-based models. Notably, it enhances cooperative platooning rates up to 26.2\%, showcasing its potential to optimize CAV cooperation and traffic dynamics during the early stage of deployment.

</details>


### [402] [POLARIS: Typed Planning and Governed Execution for Agentic AI in Back-Office Automation](https://arxiv.org/abs/2601.11816)
*Zahra Moslemi,Keerthi Koneru,Yen-Ting Lee,Sheethal Kumar,Ramesh Radhakrishnan*

Main category: cs.AI

TL;DR: POLARIS是一个政策对齐的LLM代理框架，通过类型化计划和验证执行实现企业自动化，显著提升任务效率和可审计性。


<details>
  <summary>Details</summary>
Motivation: 企业后台工作流程需要可审计、政策对齐且操作可预测的代理系统，而通用多代理设置往往无法满足这些需求。

Method: POLARIS框架通过类型化计划合成和验证执行来治理LLM代理，包括计划生成、合规性选择和执行验证。

Result: 在文档中心财务任务中，POLARIS减少了人工干预，同时在SROIE数据集上实现了0.81的微F1分数，在合成测试中实现了0.95至1.00的异常路由精度。

Conclusion: POLARIS提供了一个方法论和基准参考，用于政策对齐的代理AI，展示了其在企业自动化中的高效性和可审计性。

Abstract: Enterprise back office workflows require agentic systems that are auditable, policy-aligned, and operationally predictable, capabilities that generic multi-agent setups often fail to deliver. We present POLARIS (Policy-Aware LLM Agentic Reasoning for Integrated Systems), a governed orchestration framework that treats automation as typed plan synthesis and validated execution over LLM agents. A planner proposes structurally diverse, type checked directed acyclic graphs (DAGs), a rubric guided reasoning module selects a single compliant plan, and execution is guarded by validator gated checks, a bounded repair loop, and compiled policy guardrails that block or route side effects before they occur. Applied to document centric finance tasks, POLARIS produces decision grade artifacts and full execution traces while reducing human intervention. Empirically, POLARIS achieves a micro F1 of 0.81 on the SROIE dataset and, on a controlled synthetic suite, achieves 0.95 to 1.00 precision for anomaly routing with preserved audit trails. These evaluations constitute an initial benchmark for governed Agentic AI. POLARIS provides a methodological and benchmark reference for policy-aligned Agentic AI. Keywords Agentic AI, Enterprise Automation, Back-Office Tasks, Benchmarks, Governance, Typed Planning, Evaluation

</details>


### [403] [AI Co-Scientist for Knowledge Synthesis in Medical Contexts: A Proof of Concept](https://arxiv.org/abs/2601.11825)
*Arya Rahgozar,Pouria Mortezaagha*

Main category: cs.AI

TL;DR: AI辅助科学家平台通过PICOS感知和NLP技术，显著提升证据合成的效率和透明度，减少生物医学研究浪费。


<details>
  <summary>Details</summary>
Motivation: 生物医学科学中的研究浪费由冗余研究、不完整报告和传统证据合成工作流的有限可扩展性驱动，促使开发可扩展且透明的知识合成AI平台。

Method: 平台整合了关系存储、基于向量的语义检索和Neo4j知识图谱，并采用Bidirectional LSTM和基于PubMedBERT微调的多任务分类器进行自动化PICOS合规性和研究设计分类。全文合成采用检索增强生成，结合向量和图检索，BERTopic用于识别主题结构、冗余和证据缺口。

Result: 转换器模型在研究设计分类上达到95.7%的准确率，Bi-LSTM在PICOS合规性检测上达到87%的准确率。检索增强生成在需要结构化约束、跨研究整合和图推理的查询上表现优于非检索生成。主题建模揭示了显著的主题冗余和未充分探索的研究领域。

Conclusion: 该研究提出的AI辅助科学家平台通过PICOS感知和可解释的自然语言处理，提高了证据合成的可扩展性、透明度和效率，为减少生物医学领域的研究浪费提供了实用框架。

Abstract: Research waste in biomedical science is driven by redundant studies, incomplete reporting, and the limited scalability of traditional evidence synthesis workflows. We present an AI co-scientist for scalable and transparent knowledge synthesis based on explicit formalization of Population, Intervention, Comparator, Outcome, and Study design (PICOS). The platform integrates relational storage, vector-based semantic retrieval, and a Neo4j knowledge graph. Evaluation was conducted on dementia-sport and non-communicable disease corpora. Automated PICOS compliance and study design classification from titles and abstracts were performed using a Bidirectional Long Short-Term Memory baseline and a transformer-based multi-task classifier fine-tuned from PubMedBERT. Full-text synthesis employed retrieval-augmented generation with hybrid vector and graph retrieval, while BERTopic was used to identify thematic structure, redundancy, and evidence gaps. The transformer model achieved 95.7% accuracy for study design classification with strong agreement against expert annotations, while the Bi-LSTM achieved 87% accuracy for PICOS compliance detection. Retrieval-augmented generation outperformed non-retrieval generation for queries requiring structured constraints, cross-study integration, and graph-based reasoning, whereas non-retrieval approaches remained competitive for high-level summaries. Topic modeling revealed substantial thematic redundancy and identified underexplored research areas. These results demonstrate that PICOS-aware and explainable natural language processing can improve the scalability, transparency, and efficiency of evidence synthesis. The proposed architecture is domain-agnostic and offers a practical framework for reducing research waste across biomedical disciplines.

</details>


### [404] [Imandra CodeLogician: Neuro-Symbolic Reasoning for Precise Analysis of Software Logic](https://arxiv.org/abs/2601.11840)
*Hongyu Lin,Samer Abdallah,Makar Valentinov,Paul Brennan,Elijah Kagan,Christoph M. Wintersteiger,Denis Ignatovich,Grant Passmore*

Main category: cs.AI

TL;DR: CodeLogician结合LLMs和形式化方法，显著提升软件逻辑推理准确性，填补了现有基准测试的不足。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在代码理解任务上表现优异，但其缺乏对程序行为进行精确、全面数学推理的能力，现有基准测试要么脱离实际软件，要么缺乏语义严谨性。

Method: CodeLogician是一种神经符号代理，与工业自动推理引擎ImandraX集成，利用LLMs构建软件系统的显式形式化模型，支持自动推理回答丰富的语义问题。

Result: 与纯LLM推理相比，CodeLogician的形式化增强显著提升了推理准确性，缩小了41-47个百分点的差距。

Conclusion: 神经符号集成对于实现严格、自主的软件理解至关重要，CodeLogician通过结合LLMs和形式化方法显著提升了程序分析的准确性和范围。

Abstract: Large Language Models (LLMs) have shown strong performance on code understanding tasks, yet they fundamentally lack the ability to perform precise, exhaustive mathematical reasoning about program behavior. Existing benchmarks either focus on mathematical proof automation, largely disconnected from real-world software, or on engineering tasks that do not require semantic rigor.
  We present CodeLogician, a neurosymbolic agent for precise analysis of software logic, integrated with ImandraX, an industrial automated reasoning engine deployed in financial markets and safety-critical systems. Unlike prior approaches that use formal methods primarily to validate LLM outputs, CodeLogician uses LLMs to construct explicit formal models of software systems, enabling automated reasoning to answer rich semantic questions beyond binary verification outcomes.
  To rigorously evaluate mathematical reasoning about software logic, we introduce code-logic-bench, a benchmark targeting the middle ground between theorem proving and software engineering benchmarks. It measures reasoning correctness about program state spaces, control flow, coverage constraints, and edge cases, with ground truth defined via formal modeling and region decomposition.
  Comparing LLM-only reasoning against LLMs augmented with CodeLogician, formal augmentation yields substantial improvements, closing a 41-47 percentage point gap in reasoning accuracy. These results demonstrate that neurosymbolic integration is essential for scaling program analysis toward rigorous, autonomous software understanding.

</details>


### [405] [Human-AI Collaborative Inductive Thematic Analysis: AI Guided Analysis and Human Interpretive Authority](https://arxiv.org/abs/2601.11850)
*Matthew Nyaaba,Min SungEun,Mary Abiswin Apam,Kwame Owoahene Acheampong,Emmanuel Dwamena,Xiaoming Zhai*

Main category: cs.AI

TL;DR: 研究探讨AI辅助定性分析工具ITA-GPT如何支持归纳主题分析，发现工具增强流程透明度，但人类保持解释权。


<details>
  <summary>Details</summary>
Motivation: 探讨生成式人工智能在定性研究中的应用对分析实践和解释权威的影响。

Method: 三位经验丰富的定性研究人员使用ITA-GPT工具对加纳教师教育背景的访谈转录进行分析，工具支持熟悉化、逐字编码、描述性编码和主题开发。

Result: ITA-GPT作为程序性支架，结构化分析工作流程并增强透明度，但解释权威仍由人类研究者掌握。

Conclusion: 本研究展示了通过负责任的人与AI协作如何实施归纳主题分析，强调人类研究者保持解释权威。

Abstract: The increasing use of generative artificial intelligence (GenAI) in qualitative research raises important questions about analytic practice and interpretive authority. This study examines how researchers interact with an Inductive Thematic Analysis GPT (ITA-GPT), a purpose-built AI tool designed to support inductive thematic analysis through structured, semi-automated prompts aligned with reflexive thematic analysis and verbatim coding principles. Guided by a Human-Artificial Intelligence Collaborative Inductive Thematic Analysis (HACITA) framework, the study focuses on analytic process rather than substantive findings. Three experienced qualitative researchers conducted ITA-GPT assisted analyses of interview transcripts from education research in the Ghanaian teacher education context. The tool supported familiarization, verbatim in vivo coding, gerund-based descriptive coding, and theme development, while enforcing trace to text integrity, coverage checks, and auditability. Data sources included interaction logs, AI-generated tables, researcher revisions, deletions, insertions, comments, and reflexive memos. Findings show that ITA-GPT functioned as a procedural scaffold that structured analytic workflow and enhanced transparency. However, interpretive authority remained with human researchers, who exercised judgment through recurrent analytic actions including modification, deletion, rejection, insertion, and commenting. The study demonstrates how inductive thematic analysis is enacted through responsible human AI collaboration.

</details>


### [406] [MyGram: Modality-aware Graph Transformer with Global Distribution for Multi-modal Entity Alignment](https://arxiv.org/abs/2601.11885)
*Zhifei Li,Ziyue Qin,Xiangyu Luo,Xiaoju Hou,Yue Zhao,Miao Zhang,Zhifang Huang,Kui Xiao,Bing Yang*

Main category: cs.AI

TL;DR: MyGram是一种多模态实体对齐方法，通过模态扩散学习和Gram Loss提升性能，实验显示其显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法可能忽略模态内的结构上下文信息，易受浅层特征干扰，因此需要一种能捕获深度结构信息并实现细粒度多模态融合的方法。

Method: 提出MyGram，一种具有全局分布感知的模态感知图变换器，包括模态扩散学习模块和Gram Loss正则化约束。

Result: 在五个公共数据集上，MyGram优于基线模型，FBDB15K、FBYG15K和DBP15K的Hits@1分别最大提升4.8%、9.9%和4.3%。

Conclusion: MyGram通过模态扩散学习模块和Gram Loss，在多模态实体对齐任务中显著提升了性能，证明了其有效性和优越性。

Abstract: Multi-modal entity alignment aims to identify equivalent entities between two multi-modal Knowledge graphs by integrating multi-modal data, such as images and text, to enrich the semantic representations of entities. However, existing methods may overlook the structural contextual information within each modality, making them vulnerable to interference from shallow features. To address these challenges, we propose MyGram, a modality-aware graph transformer with global distribution for multi-modal entity alignment. Specifically, we develop a modality diffusion learning module to capture deep structural contextual information within modalities and enable fine-grained multi-modal fusion. In addition, we introduce a Gram Loss that acts as a regularization constraint by minimizing the volume of a 4-dimensional parallelotope formed by multi-modal features, thereby achieving global distribution consistency across modalities. We conduct experiments on five public datasets. Results show that MyGram outperforms baseline models, achieving a maximum improvement of 4.8% in Hits@1 on FBDB15K, 9.9% on FBYG15K, and 4.3% on DBP15K.

</details>


### [407] [AEMA: Verifiable Evaluation Framework for Trustworthy and Controlled Agentic LLM Systems](https://arxiv.org/abs/2601.11903)
*YenTing Lee,Keerthi Koneru,Zahra Moslemi,Sheethal Kumar,Ramesh Radhakrishnan*

Main category: cs.AI

TL;DR: AEMA框架通过多步骤评估和人类监督，提升了LLM多智能体系统的评估稳定性与透明度。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法在单响应评分或狭窄基准上缺乏稳定性、可扩展性和自动化，难以满足企业级多智能体系统的需求。

Method: 提出了AEMA（自适应评估多智能体）框架，该框架在人类监督下规划、执行并聚合异构智能体工作流的多步骤评估。

Result: AEMA相比单一LLM评估，在稳定性、人类对齐和可追溯记录方面表现更优，适用于企业级智能体工作流。

Conclusion: AEMA框架为基于LLM的多智能体系统提供了一种透明且可复现的评估路径，支持可靠的自动化和人类监督。

Abstract: Evaluating large language model (LLM)-based multi-agent systems remains a critical challenge, as these systems must exhibit reliable coordination, transparent decision-making, and verifiable performance across evolving tasks. Existing evaluation approaches often limit themselves to single-response scoring or narrow benchmarks, which lack stability, extensibility, and automation when deployed in enterprise settings at multi-agent scale. We present AEMA (Adaptive Evaluation Multi-Agent), a process-aware and auditable framework that plans, executes, and aggregates multi-step evaluations across heterogeneous agentic workflows under human oversight. Compared to a single LLM-as-a-Judge, AEMA achieves greater stability, human alignment, and traceable records that support accountable automation. Our results on enterprise-style agent workflows simulated using realistic business scenarios demonstrate that AEMA provides a transparent and reproducible pathway toward responsible evaluation of LLM-based multi-agent systems.
  Keywords Agentic AI, Multi-Agent Systems, Trustworthy AI, Verifiable Evaluation, Human Oversight

</details>


### [408] [LIBRA: Language Model Informed Bandit Recourse Algorithm for Personalized Treatment Planning](https://arxiv.org/abs/2601.11905)
*Junyu Cao,Ruijiang Gao,Esmaeil Keyvanshokooh,Jianhao Ma*

Main category: cs.AI

TL;DR: 论文提出了结合LLMs和赌博机学习的LIBRA算法，用于高风险决策，实验证明其在降低遗憾和提高效率方面优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决在高风险设置（如个性化医疗）中，决策者需要同时选择治疗行动和可行的最小患者特征修改的问题。

Method: 论文提出了广义线性资源赌博机（GLRB）算法，并在此基础上开发了LIBRA算法，该算法结合了大型语言模型（LLMs）的领域知识和赌博机学习的统计严谨性。

Result: 实验证明，GLRB和LIBRA在合成环境和真实高血压管理案例中，相比标准上下文赌博机和纯LLM基准，显著改善了遗憾、治疗质量和样本效率。

Conclusion: 该论文展示了GLRB和LIBRA算法在个性化高风险决策中的有效性，特别是在降低初始遗憾、提高治疗质量和样本效率方面优于标准上下文赌博机和纯LLM基准。

Abstract: We introduce a unified framework that seamlessly integrates algorithmic recourse, contextual bandits, and large language models (LLMs) to support sequential decision-making in high-stakes settings such as personalized medicine. We first introduce the recourse bandit problem, where a decision-maker must select both a treatment action and a feasible, minimal modification to mutable patient features. To address this problem, we develop the Generalized Linear Recourse Bandit (GLRB) algorithm. Building on this foundation, we propose LIBRA, a Language Model-Informed Bandit Recourse Algorithm that strategically combines domain knowledge from LLMs with the statistical rigor of bandit learning. LIBRA offers three key guarantees: (i) a warm-start guarantee, showing that LIBRA significantly reduces initial regret when LLM recommendations are near-optimal; (ii) an LLM-effort guarantee, proving that the algorithm consults the LLM only $O(\log^2 T)$ times, where $T$ is the time horizon, ensuring long-term autonomy; and (iii) a robustness guarantee, showing that LIBRA never performs worse than a pure bandit algorithm even when the LLM is unreliable. We further establish matching lower bounds that characterize the fundamental difficulty of the recourse bandit problem and demonstrate the near-optimality of our algorithms. Experiments on synthetic environments and a real hypertension-management case study confirm that GLRB and LIBRA improve regret, treatment quality, and sample efficiency compared with standard contextual bandits and LLM-only benchmarks. Our results highlight the promise of recourse-aware, LLM-assisted bandit algorithms for trustworthy LLM-bandits collaboration in personalized high-stakes decision-making.

</details>


### [409] [Thinking Traps in Long Chain-of-Thought: A Measurable Study and Trap-Aware Adaptive Restart](https://arxiv.org/abs/2601.11940)
*Kang Chen,Fan Yu,Junjie Nian,Shihan Zhao,Zhuoka Feng,Zijun Yao,Heng Wang,Minshen Yu,Yixin Cao*

Main category: cs.AI

TL;DR: TAAR框架通过动态截断和重启解码，解决了Long-CoT中的思考陷阱问题，提升了数学和科学推理任务的准确性。


<details>
  <summary>Details</summary>
Motivation: Long-CoT虽通过扩展生成增强推理能力，但早期错误可能导致模型陷入自我一致但错误的思考陷阱（89%的失败案例）。为解决这一问题，需要一种动态干预机制。

Method: 通过细粒度轨迹分析识别思考陷阱，并引入TAAR框架，训练诊断策略预测陷阱位置（截断点）和逃逸概率（干预强度）。在推理时，TAAR根据预测截断轨迹并自适应重启解码，对严重陷阱情况应用更强扰动（如高温重采样和结构化重启后缀）。

Result: 在AIME24、AIME25、GPQA-Diamond、HMMT25、BRUMO25等数学和科学推理基准测试中，TAAR显著提升了模型性能。

Conclusion: TAAR（Trap-Aware Adaptive Restart）作为一种测试时控制框架，通过诊断策略预测陷阱位置和逃逸概率，有效解决了Long-CoT中的思考陷阱问题，显著提升了模型在数学和科学推理任务中的表现，且无需调整基础模型参数。

Abstract: Scaling test-time compute via Long Chain-of-Thought (Long-CoT) significantly enhances reasoning capabilities, yet extended generation does not guarantee correctness: after an early wrong commitment, models may keep elaborating a self-consistent but incorrect prefix. Through fine-grained trajectory analysis, we identify Thinking Traps, prefix-dominant deadlocks where later reflection, alternative attempts, or verification fails to revise the root error. On a curated subset of DAPO-MATH, 89\% of failures exhibit such traps. To solve this problem, we introduce TAAR (Trap-Aware Adaptive Restart), a test-time control framework that trains a diagnostic policy to predict two signals from partial trajectories: a trap index for where to truncate and an escape probability for whether and how strongly to intervene. At inference time, TAAR truncates the trajectory before the predicted trap segment and adaptively restarts decoding; for severely trapped cases, it applies stronger perturbations, including higher-temperature resampling and an optional structured reboot suffix. Experiments on challenging mathematical and scientific reasoning benchmarks (AIME24, AIME25, GPQA-Diamond, HMMT25, BRUMO25) show that TAAR improves reasoning performance without fine-tuning base model parameters.

</details>


### [410] [Learn Like Humans: Use Meta-cognitive Reflection for Efficient Self-Improvement](https://arxiv.org/abs/2601.11974)
*Xinmeng Hou,Peiliang Gong,Bohao Qu,Wuqi Wang,Qing Guo,Yang Liu*

Main category: cs.AI

TL;DR: MARS框架通过单次递归循环实现高效自进化，优于现有系统并降低计算成本。


<details>
  <summary>Details</summary>
Motivation: 当前基于静态人工设计提示的LLM代理适应性有限，现有自改进框架依赖低效的多轮递归循环，计算成本高。

Method: MARS结合了基于原则的反思（抽象规范规则以避免错误）和程序性反思（推导逐步成功的策略），通过合成这些见解生成优化指令。

Result: MARS在六个基准测试中表现优于现有自进化系统，同时显著减少计算开销。

Conclusion: MARS框架通过单次递归循环实现了高效的自进化，显著降低了计算开销，并在六个基准测试中优于现有的自进化系统。

Abstract: While Large Language Models (LLMs) enable complex autonomous behavior, current agents remain constrained by static, human-designed prompts that limit adaptability. Existing self-improving frameworks attempt to bridge this gap but typically rely on inefficient, multi-turn recursive loops that incur high computational costs. To address this, we propose Metacognitive Agent Reflective Self-improvement (MARS), a framework that achieves efficient self-evolution within a single recurrence cycle. Inspired by educational psychology, MARS mimics human learning by integrating principle-based reflection (abstracting normative rules to avoid errors) and procedural reflection (deriving step-by-step strategies for success). By synthesizing these insights into optimized instructions, MARS allows agents to systematically refine their reasoning logic without continuous online feedback. Extensive experiments on six benchmarks demonstrate that MARS outperforms state-of-the-art self-evolving systems while significantly reducing computational overhead.

</details>


### [411] [Process In-Context Learning: Enhancing Mathematical Reasoning via Dynamic Demonstration Insertion](https://arxiv.org/abs/2601.11979)
*Ang Gao,Changshuo Zhang,Xiao Zhang,Deyang Li,Minjun Zhao,Fangchao Liu,Xinyu Zhang*

Main category: cs.AI

TL;DR: PICL框架动态插入示例，有效提升数学推理准确性。


<details>
  <summary>Details</summary>
Motivation: 现有ICL方法在数学推理等需要逐步逻辑推导的任务中表现不足，主要因静态示例无法适应推理过程中的动态混淆点。

Method: PICL采用两阶段方法：1) 通过分析推理过程中的语义和熵识别潜在混淆点；2) 实时检索并插入匹配上下文的示例。

Result: 实验表明PICL通过减少推理中的混淆点，显著优于基线方法。

Conclusion: PICL框架通过动态插入相关示例显著提升了数学推理任务的准确性，验证了自适应演示在复杂推理中的价值。

Abstract: In-context learning (ICL) has proven highly effective across diverse large language model (LLM) tasks. However, its potential for enhancing tasks that demand step-by-step logical deduction, such as mathematical reasoning, remains underexplored. A core limitation of existing ICL approaches is their static use of demonstrations: examples are pre-selected before inference and remain fixed, failing to adapt to the dynamic confusion points that often arise during multi-step reasoning such as ambiguous calculations or logical gaps. These unresolved confusion points can lead to cascading errors that degrade final accuracy. To tackle this issue, we propose Process In-Context Learning (PICL), a dynamic demonstration integration framework designed to boost mathematical reasoning by responding to real-time inference needs. PICL operates in two stages: 1)~it identifies potential confusion points by analyzing semantics and entropy in the reasoning process and summarizes their core characteristics; 2)~upon encountering these points, it retrieves relevant demonstrations from the demonstration pool that match the confusion context and inserts them directly into the ongoing reasoning process to guide subsequent steps. Experiments show that PICL outperforms baseline methods by mitigating mid-inference confusion, highlighting the value of adaptive demonstration insertion in complex mathematical reasoning.

</details>


### [412] [Kernel-Based Learning of Safety Barriers](https://arxiv.org/abs/2601.12002)
*Oliver Schön,Zhengang Zhong,Sadegh Soudjani*

Main category: cs.AI

TL;DR: 本文提出了一种数据驱动的方法，通过控制屏障证书和RKHS模糊集，解决了AI驱动系统安全验证的挑战，并在案例研究中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: AI算法在自动驾驶和医疗等安全关键应用中的快速集成引发了对其满足严格安全标准能力的担忧，传统工具因黑盒性质和缺乏灵活性而难以应对现实应用的复杂性。

Method: 采用控制屏障证书的概念，直接从系统轨迹中学习证书，并利用条件均值嵌入将数据嵌入到再生核希尔伯特空间（RKHS），构建RKHS模糊集以增强对分布外行为的鲁棒性。通过有限傅里叶展开将半无限优化问题转化为线性规划，利用快速傅里叶变换高效生成松弛问题。

Result: 该方法在理论上适用于超越安全性的一般时间逻辑规范类别，并通过两个案例研究（包括具有神经网络控制器的黑盒系统）验证了其有效性。

Conclusion: 本文提出了一种数据驱动的方法，用于验证和合成具有离散时间随机动态的黑盒系统的安全性，通过控制屏障证书和学习证书，解决了传统工具在AI驱动系统中的局限性。

Abstract: The rapid integration of AI algorithms in safety-critical applications such as autonomous driving and healthcare is raising significant concerns about the ability to meet stringent safety standards. Traditional tools for formal safety verification struggle with the black-box nature of AI-driven systems and lack the flexibility needed to scale to the complexity of real-world applications. In this paper, we present a data-driven approach for safety verification and synthesis of black-box systems with discrete-time stochastic dynamics. We employ the concept of control barrier certificates, which can guarantee safety of the system, and learn the certificate directly from a set of system trajectories. We use conditional mean embeddings to embed data from the system into a reproducing kernel Hilbert space (RKHS) and construct an RKHS ambiguity set that can be inflated to robustify the result to out-of-distribution behavior. We provide the theoretical results on how to apply the approach to general classes of temporal logic specifications beyond safety. For the data-driven computation of safety barriers, we leverage a finite Fourier expansion to cast a typically intractable semi-infinite optimization problem as a linear program. The resulting spectral barrier allows us to leverage the fast Fourier transform to generate the relaxed problem efficiently, offering a scalable yet distributionally robust framework for verifying safety. Our work moves beyond restrictive assumptions on system dynamics and uncertainty, as demonstrated on two case studies including a black-box system with a neural network controller.

</details>


### [413] [Are LLMs Ready for TOON? Benchmarking Structural Correctness-Sustainability Trade-offs in Novel Structured Output Formats](https://arxiv.org/abs/2601.12014)
*Elio Masciari,Vincenzo Moscato,Enea Vincenzo Napolitano,Gian Marco Orlando,Marco Perillo,Diego Russo*

Main category: cs.AI

TL;DR: 论文提出了一种结合结构正确性和碳排放效率的评估框架，发现TOON格式在紧凑性和低碳方面表现优越，但需模型支持以提升正确性。


<details>
  <summary>Details</summary>
Motivation: 评估结构化输出格式时，除了正确性外，还应考虑其环境效率，以促进可持续发展。

Method: 提出了一个可持续性评估框架，包括测量令牌使用、生成时间和估计碳排放，并引入了环境感知生成正确性分数（GCS_env）。

Result: TOON格式在输出紧凑性和碳排放方面表现优异，但在模型缺乏原生支持时结构正确性较低；增加模型容量可缩小这一差距。

Conclusion: 研究表明，紧凑型表示格式（如TOON）在大规模、注重碳足迹的LLM部署中具有实际优势，强调了可持续性评估的必要性。

Abstract: Large Language Models (LLMs) are increasingly required to generate structured, machine-readable outputs for downstream systems. While recent benchmarks have focused on evaluating the structural correctness of such outputs, the environmental impact of inference for different output formats has largely been overlooked. In this paper, we argue that structured output formats should be assessed not only in terms of correctness, but also with respect to their environmental efficiency. To this end, we introduce a sustainability-aware evaluation framework for structured generation that measures token usage, generation time, and estimated carbon emissions. Within this framework, we propose the Environment-Aware Generation Correctness Score (GCS_env), a unified metric that integrates structural correctness with carbon-aware efficiency. Using this framework, we systematically benchmark the novel TOON format against established representations (JSON, XML, YAML) across multiple LLMs spanning different architectures and parameter scales.
  Our results reveal a consistent trade-off: TOON yields markedly more compact outputs and lower emissions, but lower structural correctness when models lack native support. We show that increased model capacity reduces this gap and that environment-aware scoring can shift format rankings depending on deployment priorities. highlighting the need for sustainability-inclusive benchmarking and provides empirical evidence that compact representations such as TOON can offer practical advantages in large-scale, carbon-conscious LLM deployments.

</details>


### [414] [A Multi-Agent System for Generating Actionable Business Advice](https://arxiv.org/abs/2601.12024)
*Kartikey Singh Bhandari,Tanish Jain,Archit Agrawal,Dhruv Kumar,Praveen Kumar,Pratik Narang*

Main category: cs.AI

TL;DR: 多代理LLM框架将评论转化为可操作建议，优于传统方法，中型模型表现接近大型模型。


<details>
  <summary>Details</summary>
Motivation: 现有分析方法多停留在情感分析或方面提取等描述性任务，而大型语言模型（LLMs）生成的建议常缺乏准确性和深度推理。

Method: 框架包含四个组件：聚类选择代表性评论、建议生成、迭代评估和基于可行性的排名，结合语料蒸馏与反馈驱动的建议优化。

Result: 在三个服务领域和多种模型家族的实验中，该框架在可操作性、特异性和非冗余性上一致优于单一模型基线，中型模型性能接近大型模型框架。

Conclusion: 该论文提出的多代理、基于LLM的框架在将大规模评论语料转化为可操作的商业建议方面表现优异，尤其在可操作性、特异性和非冗余性上优于单一模型基线。

Abstract: Customer reviews contain rich signals about product weaknesses and unmet user needs, yet existing analytic methods rarely move beyond descriptive tasks such as sentiment analysis or aspect extraction. While large language models (LLMs) can generate free-form suggestions, their outputs often lack accuracy and depth of reasoning. In this paper, we present a multi-agent, LLM-based framework for prescriptive decision support, which transforms large scale review corpora into actionable business advice. The framework integrates four components: clustering to select representative reviews, generation of advices, iterative evaluation, and feasibility based ranking. This design couples corpus distillation with feedback driven advice refinement to produce outputs that are specific, actionable, and practical. Experiments across three service domains and multiple model families show that our framework consistently outperform single model baselines on actionability, specificity, and non-redundancy, with medium sized models approaching the performance of large model frameworks.

</details>


### [415] [ARC: Active and Reflection-driven Context Management for Long-Horizon Information Seeking Agents](https://arxiv.org/abs/2601.12030)
*Yilun Yao,Shan Huang,Elsie Dai,Zhewen Tan,Zhenyu Duan,Shousheng Jia,Yanbing Jiang,Tong Yang*

Main category: cs.AI

TL;DR: ARC框架通过动态上下文管理，显著提升长程信息搜索任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要通过原始积累或被动摘要管理上下文，导致早期错误或不当强调持续存在，性能随交互历史增长而下降。

Method: 提出了ARC框架，将上下文管理视为一个动态的内部推理状态，通过反思驱动的监控和修订来主动重组工作上下文。

Result: 在BrowseComp-ZH基准测试中，ARC相比被动上下文压缩方法实现了11%的绝对准确率提升。

Conclusion: ARC框架通过主动的反思驱动监控和修订，显著提升了大型语言模型在长程信息搜索任务中的性能，证明了动态上下文管理的有效性。

Abstract: Large language models are increasingly deployed as research agents for deep search and long-horizon information seeking, yet their performance often degrades as interaction histories grow. This degradation, known as context rot, reflects a failure to maintain coherent and task-relevant internal states over extended reasoning horizons. Existing approaches primarily manage context through raw accumulation or passive summarization, treating it as a static artifact and allowing early errors or misplaced emphasis to persist. Motivated by this perspective, we propose ARC, which is the first framework to systematically formulate context management as an active, reflection-driven process that treats context as a dynamic internal reasoning state during execution. ARC operationalizes this view through reflection-driven monitoring and revision, allowing agents to actively reorganize their working context when misalignment or degradation is detected. Experiments on challenging long-horizon information-seeking benchmarks show that ARC consistently outperforms passive context compression methods, achieving up to an 11% absolute improvement in accuracy on BrowseComp-ZH with Qwen2.5-32B-Instruct.

</details>


### [416] [Abstract Argumentation with Subargument Relations](https://arxiv.org/abs/2601.12038)
*Beishui Liao*

Main category: cs.AI

TL;DR: 本文研究了带有显式子论点关系的抽象论证框架，分析了子论点与攻击的相互作用及其对语义的影响，为结构信息提供了原理性抽象。


<details>
  <summary>Details</summary>
Motivation: 现有抽象论证框架仅通过攻击关系表征论点的可接受性，无法表示结构化论证形式中的核心结构依赖关系（如子论点关系），限制了其表达能力。

Method: 研究抽象论证框架，通过引入显式子论点关系，与攻击关系一同作为基本关系进行分析。

Result: 分析了子论点关系如何与攻击关系相互作用，并考察了它们对基本语义属性的影响。

Conclusion: 该框架提供了结构信息的原理性抽象，并阐明了子论点在抽象可接受性推理中的作用。

Abstract: Dung's abstract argumentation framework characterises argument acceptability solely via an attack relation, deliberately abstracting from the internal structure of arguments. While this level of abstraction has enabled a rich body of results, it limits the ability to represent structural dependencies that are central in many structured argumentation formalisms, in particular subargument relations. Existing extensions, including bipolar argumentation frameworks, introduce support relations, but these do not capture the asymmetric and constitutive nature of subarguments or their interaction with attacks. In this paper, we study abstract argumentation frameworks enriched with an explicit subargument relation, treated alongside attack as a basic relation. We analyse how subargument relations interact with attacks and examine their impact on fundamental semantic properties. This framework provides a principled abstraction of structural information and clarifies the role of subarguments in abstract acceptability reasoning.

</details>


### [417] [Partial Reasoning in Language Models: Search and Refinement Guided by Uncertainty](https://arxiv.org/abs/2601.12040)
*Murilo da Luz,Bruno Brandão,Luana Martins,Gustavo Oliveira,Bryan de Oliveira,Luckeciano Melo,Telma Soares*

Main category: cs.AI

TL;DR: PREGU通过熵监控和局部搜索优化LLMs的多步推理，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在推理和规划任务中取得了显著进展，但在多步推理场景（尤其是数学和逻辑推理）中仍存在局限性。

Method: PREGU在自回归生成过程中监控输出分布的熵，当熵超过阈值时暂停生成，并在潜在空间进行局部搜索以优化部分推理，使用Soft Reasoning方法选择最连贯的答案。

Result: 在LLaMA-3-8B、Mistral-7B和Qwen2-7B上进行的实验显示，PREGU在四个推理基准（GSM8K、GSM-Hard、SVAMP和StrategyQA）上的表现优于或类似于Soft Reasoning。

Conclusion: PREGU通过监控自回归生成过程中的熵，并在不确定性超过阈值时触发局部搜索，有效提升了LLMs在多步推理任务中的表现。

Abstract: The use of Large Language Models (LLMs) for reasoning and planning tasks has drawn increasing attention in Artificial Intelligence research. Despite their remarkable progress, these models still exhibit limitations in multi-step inference scenarios, particularly in mathematical and logical reasoning. We introduce PREGU (Partial Reasoning Guided by Uncertainty). PREGU monitors the entropy of the output distribution during autoregressive generation and halts the process whenever entropy exceeds a defined threshold, signaling uncertainty. From that point, a localized search is performed in the latent space to refine the partial reasoning and select the most coherent answer, using the Soft Reasoning method. Experiments conducted with LLaMA-3-8B, Mistral-7B, and Qwen2-7B across four reasoning benchmarks (GSM8K, GSM-Hard, SVAMP, and StrategyQA) showed performance greater than or similar to Soft Reasoning, indicating that entropy can serve as an effective signal to trigger selective refinement during reasoning.

</details>


### [418] [UniMo: Unified Motion Generation and Understanding with Chain of Thought](https://arxiv.org/abs/2601.12126)
*Guocun Wang,Kenkun Liu,Jing Lin,Guorui Song,Jian Li,Xiaoguang Han*

Main category: cs.AI

TL;DR: UniMo通过运动-语言整合与GRPO强化学习，解决了现有方法的可解释性和累积误差问题，在3D运动任务中实现SOTA性能。


<details>
  <summary>Details</summary>
Motivation: 现有3D人体运动生成与理解方法可解释性不足，且基于LLM的统一框架存在语义对齐和任务连贯性挑战，以及运动序列预测中的累积误差问题。

Method: 提出UniMo框架，通过监督微调（SFT）将运动-语言信息和可解释的CoT推理整合到LLM中，并引入基于GRPO的强化学习作为后训练策略，优化令牌组以增强结构正确性和语义对齐。

Result: UniMo在广泛实验中显著优于现有统一和任务特定模型，在运动生成和理解任务中均达到最优性能。

Conclusion: UniMo框架通过整合运动-语言信息和可解释的链式思维推理，结合监督微调和GRPO强化学习策略，显著提升了3D人体运动生成与理解的性能，实现了当前最佳效果。

Abstract: Existing 3D human motion generation and understanding methods often exhibit limited interpretability, restricting effective mutual enhancement between these inherently related tasks. While current unified frameworks based on large language models (LLMs) leverage linguistic priors, they frequently encounter challenges in semantic alignment and task coherence. Moreover, the next-token prediction paradigm in LLMs is ill-suited for motion sequences, causing cumulative prediction errors. To address these limitations, we propose UniMo, a novel framework that integrates motion-language information and interpretable chain of thought (CoT) reasoning into the LLM via supervised fine-tuning (SFT). We further introduce reinforcement learning with Group Relative Policy Optimization (GRPO) as a post-training strategy that optimizes over groups of tokens to enforce structural correctness and semantic alignment, mitigating cumulative errors in motion token prediction. Extensive experiments demonstrate that UniMo significantly outperforms existing unified and task-specific models, achieving state-of-the-art performance in both motion generation and understanding.

</details>


### [419] [DriveSafe: A Hierarchical Risk Taxonomy for Safety-Critical LLM-Based Driving Assistants](https://arxiv.org/abs/2601.12138)
*Abhishek Kumar,Riya Tapwal,Carsten Maple*

Main category: cs.AI

TL;DR: DriveSafe提出了一种针对LLM驾驶助手的安全风险分类法，评估显示现有模型在驾驶场景中的安全对齐存在不足。


<details>
  <summary>Details</summary>
Motivation: LLM在车载数字助手中的应用日益增多，但不安全、模糊或法律错误的响应可能导致严重的安全、伦理和监管后果。现有分类法和评估框架多为通用目的，未能捕捉驾驶场景特有的风险。

Method: 通过构建包含129个细粒度原子风险类别的分类法，涵盖技术、法律、社会和伦理维度，并基于真实驾驶法规和安全原则，经领域专家评审。

Result: 评估六个广泛部署的LLM的拒绝行为，显示模型常未能适当拒绝不安全或不合规的驾驶相关查询。

Conclusion: DriveSafe 提供了一个层次化的四级别风险分类法，系统地描述了基于LLM的驾驶助手的安全关键故障模式。评估显示，现有模型在驾驶相关查询中未能适当拒绝不安全或不合规的请求，凸显了通用安全对齐在驾驶场景中的局限性。

Abstract: Large Language Models (LLMs) are increasingly integrated into vehicle-based digital assistants, where unsafe, ambiguous, or legally incorrect responses can lead to serious safety, ethical, and regulatory consequences. Despite growing interest in LLM safety, existing taxonomies and evaluation frameworks remain largely general-purpose and fail to capture the domain-specific risks inherent to real-world driving scenarios. In this paper, we introduce DriveSafe, a hierarchical, four-level risk taxonomy designed to systematically characterize safety-critical failure modes of LLM-based driving assistants. The taxonomy comprises 129 fine-grained atomic risk categories spanning technical, legal, societal, and ethical dimensions, grounded in real-world driving regulations and safety principles and reviewed by domain experts. To validate the safety relevance and realism of the constructed prompts, we evaluate their refusal behavior across six widely deployed LLMs. Our analysis shows that the evaluated models often fail to appropriately refuse unsafe or non-compliant driving-related queries, underscoring the limitations of general-purpose safety alignment in driving contexts.

</details>


### [420] [TIDE: A Trace-Informed Depth-First Exploration for Planning with Temporally Extended Goals](https://arxiv.org/abs/2601.12141)
*Yuliia Suprun,Khen Elimelech,Lydia E. Kavraki,Moshe Y. Vardi*

Main category: cs.AI

TL;DR: TIDE通过分解时序目标为子问题并结合启发式搜索，提升了规划效率，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 传统基于LTLf的任务规划方法缺乏针对时序目标的启发式引导搜索，导致效率不足。TIDE旨在通过分解问题和引入启发式搜索解决这一局限性。

Method: TIDE将时序规划问题分解为一系列较小的可达-规避子问题，利用成本驱动的启发式搜索优先探索有潜力的自动机轨迹，并通过自适应回溯机制从失败计划中恢复。

Result: 实验结果表明，TIDE在时序扩展目标规划中表现出色，兼具效率与完整性。

Conclusion: TIDE（Trace-Informed Depth-first Exploration）通过分解时序问题为一系列可管理的子问题，并结合成本驱动的启发式搜索和自适应回溯机制，显著提升了时序目标规划的效率与完整性，成为时序扩展目标规划方法中的重要补充。

Abstract: Task planning with temporally extended goals (TEGs) is a critical challenge in AI and robotics, enabling agents to achieve complex sequences of objectives over time rather than addressing isolated, immediate tasks. Linear Temporal Logic on finite traces (LTLf ) provides a robust formalism for encoding these temporal goals. Traditional LTLf task planning approaches often transform the temporal planning problem into a classical planning problem with reachability goals, which are then solved using off-the-shelf planners. However, these methods often lack informed heuristics to provide a guided search for temporal goals. We introduce TIDE (Trace-Informed Depth-first Exploration), a novel approach that addresses this limitation by decomposing a temporal problem into a sequence of smaller, manageable reach-avoid sub-problems, each solvable using an off-the-shelf planner. TIDE identifies and prioritizes promising automaton traces within the domain graph, using cost-driven heuristics to guide exploration. Its adaptive backtracking mechanism systematically recovers from failed plans by recalculating costs and penalizing infeasible transitions, ensuring completeness and efficiency. Experimental results demonstrate that TIDE achieves promising performance and is a valuable addition to the portfolio of planning methods for temporally extended goals.

</details>


### [421] [Optimal Power Allocation and Sub-Optimal Channel Assignment for Downlink NOMA Systems Using Deep Reinforcement Learning](https://arxiv.org/abs/2601.12242)
*WooSeok Kim,Jeonghoon Lee,Sangho Kim,Taesun An,WonMin Lee,Dowon Kim,Kyungseop Shin*

Main category: cs.AI

TL;DR: 本文提出了一种结合深度强化学习的NOMA资源分配框架，解决了信道分配问题，并通过仿真验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着物联网（IoT）的扩展导致网络资源稀缺，需要优化网络资源利用率，NOMA通过功率复用允许多用户同时接入网络，但其存在局限性，尤其是信道分配问题尚未明确。

Method: 提出了一种结合重放记忆和on-policy算法的深度强化学习框架，用于优化NOMA系统中的资源分配。

Result: 通过仿真验证了所提框架在不同参数下的性能表现。

Conclusion: 本文提出了一个结合重放记忆和on-policy算法的深度强化学习框架，用于NOMA系统中的网络资源分配，并通过大量仿真验证了不同参数（如学习率、批次大小、模型类型和状态特征数量）的影响。

Abstract: In recent years, Non-Orthogonal Multiple Access (NOMA) system has emerged as a promising candidate for multiple access frameworks due to the evolution of deep machine learning, trying to incorporate deep machine learning into the NOMA system. The main motivation for such active studies is the growing need to optimize the utilization of network resources as the expansion of the internet of things (IoT) caused a scarcity of network resources. The NOMA addresses this need by power multiplexing, allowing multiple users to access the network simultaneously. Nevertheless, the NOMA system has few limitations. Several works have proposed to mitigate this, including the optimization of power allocation known as joint resource allocation(JRA) method, and integration of the JRA method and deep reinforcement learning (JRA-DRL). Despite this, the channel assignment problem remains unclear and requires further investigation. In this paper, we propose a deep reinforcement learning framework incorporating replay memory with an on-policy algorithm, allocating network resources in a NOMA system to generalize the learning. Also, we provide extensive simulations to evaluate the effects of varying the learning rate, batch size, type of model, and the number of features in the state.

</details>


### [422] [Improving Large Molecular Language Model via Relation-aware Multimodal Collaboration](https://arxiv.org/abs/2601.12256)
*Jinyoung Park,Minseong Bae,Jeehye Na,Hyunwoo J. Kim*

Main category: cs.AI

TL;DR: CoLLaMo通过多模态协作机制提升分子语言模型的泛化能力，解决现有模型的幻觉和鲁棒性问题，并在多个任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有LMLMs常因对1D序列、2D分子图和3D构象等多样分子模态的整合不足而出现幻觉和鲁棒性有限的问题。

Method: 提出了CoLLaMo，一个基于大型语言模型的分子助手，配备了多级分子模态协作投影器，通过关系感知的模态协作注意力机制促进原子间的细粒度和关系引导的信息交换。

Result: 实验表明，CoLLaMo在分子描述、计算性质QA、描述性质QA、基序计数和IUPAC名称预测等多个任务上表现最佳。

Conclusion: CoLLaMo通过多级分子模态协作投影器和关系感知的模态协作注意力机制，显著提升了LMLMs的分子模态泛化能力，在多个任务上取得了最佳性能。

Abstract: Large language models (LLMs) have demonstrated their instruction-following capabilities and achieved powerful performance on various tasks. Inspired by their success, recent works in the molecular domain have led to the development of large molecular language models (LMLMs) that integrate 1D molecular strings or 2D molecular graphs into the language models. However, existing LMLMs often suffer from hallucination and limited robustness, largely due to inadequate integration of diverse molecular modalities such as 1D sequences, 2D molecular graphs, and 3D conformations. To address these limitations, we propose CoLLaMo, a large language model-based molecular assistant equipped with a multi-level molecular modality-collaborative projector. The relation-aware modality-collaborative attention mechanism in the projector facilitates fine-grained and relation-guided information exchange between atoms by incorporating 2D structural and 3D spatial relations. Furthermore, we present a molecule-centric new automatic measurement, including a hallucination assessment metric and GPT-based caption quality evaluation to address the limitations of token-based generic evaluation metrics (i.e., BLEU) widely used in assessing molecular comprehension of LMLMs. Our extensive experiments demonstrate that our CoLLaMo enhances the molecular modality generalization capabilities of LMLMs, achieving the best performance on multiple tasks, including molecule captioning, computed property QA, descriptive property QA, motif counting, and IUPAC name prediction.

</details>


### [423] [Vision Language Models for Optimization-Driven Intent Processing in Autonomous Networks](https://arxiv.org/abs/2601.12744)
*Tasnim Ahmed,Yifan Zhu,Salimur Choudhury*

Main category: cs.AI

TL;DR: 研究评估了视觉语言模型在基于意图的网络中生成优化代码的能力，发现视觉输入和开源模型表现较差，为IBN系统提供了基准能力分析。


<details>
  <summary>Details</summary>
Motivation: 网络从业者通常通过图表进行结构化思考，但现有系统仅支持文本意图表达，缺乏对视觉语言模型处理网络草图生成优化代码能力的探索。

Method: 提出了IntentOpt基准测试，包含85个优化问题和17个类别，评估了四种VLMs在三种提示策略下的表现。

Result: 视觉参数提取导致执行成功率下降12-21个百分点，程序思维提示策略降低性能高达13个百分点，开源模型表现显著落后于闭源模型。

Conclusion: 当前视觉语言模型（VLMs）在基于意图的网络（IBN）系统中生成优化代码的能力存在局限性，尤其是在处理视觉参数提取时表现下降。开源模型性能显著落后于闭源模型。

Abstract: Intent-Based Networking (IBN) allows operators to specify high-level network goals rather than low-level configurations. While recent work demonstrates that large language models can automate configuration tasks, a distinct class of intents requires generating optimization code to compute provably optimal solutions for traffic engineering, routing, and resource allocation. Current systems assume text-based intent expression, requiring operators to enumerate topologies and parameters in prose. Network practitioners naturally reason about structure through diagrams, yet whether Vision-Language Models (VLMs) can process annotated network sketches into correct optimization code remains unexplored. We present IntentOpt, a benchmark of 85 optimization problems across 17 categories, evaluating four VLMs (GPT-5-Mini, Claude-Haiku-4.5, Gemini-2.5-Flash, Llama-3.2-11B-Vision) under three prompting strategies on multimodal versus text-only inputs. Our evaluation shows that visual parameter extraction reduces execution success by 12-21 percentage points (pp), with GPT-5-Mini dropping from 93% to 72%. Program-of-thought prompting decreases performance by up to 13 pp, and open-source models lag behind closed-source ones, with Llama-3.2-11B-Vision reaching 18% compared to 75% for GPT-5-Mini. These results establish baseline capabilities and limitations of current VLMs for optimization code generation within an IBN system. We also demonstrate practical feasibility through a case study that deploys VLM-generated code to network testbed infrastructure using Model Context Protocol.

</details>


### [424] [FutureX-Pro: Extending Future Prediction to High-Value Vertical Domains](https://arxiv.org/abs/2601.12259)
*Jiashuo Liu,Siyuan Chen,Zaiyuan Wang,Zhiyuan Zeng,Jiacheng Guo,Liang Hu,Lingyue Yin,Suozhi Huang,Wenxin Hao,Yang Yang,Zerui Cheng,Zixin Yao,Lingyue Yin,Haoxin Liu,Jiayi Cheng,Yuzhen Li,Zezhong Ma,Bingjie Wang,Bingsen Qiu,Xiao Liu,Zeyang Zhang,Zijian Liu,Jinpeng Wang,Mingren Yin,Tianci He,Yali Liao,Yixiao Tian,Zhenwei Zhu,Anqi Dai,Ge Zhang,Jingkai Liu,Kaiyuan Zhang,Wenlong Wu,Xiang Gao,Xinjie Chen,Zhixin Yao,Zhoufutu Wen,B. Aditya Prakash,Jose Blanchet,Mengdi Wang,Nian Si,Wenhao Huang*

Main category: cs.AI

TL;DR: FutureX-Pro 扩展了 FutureX，专注于金融、零售、公共卫生和自然灾害等高价值垂直领域，评估了代理性 LLMs 的领域基础能力，发现其与工业需求存在差距。


<details>
  <summary>Details</summary>
Motivation: 尽管通用代理在开放领域搜索中表现出色，但在资本密集和安全关键领域的可靠性尚未充分探索，因此 FutureX-Pro 针对金融、零售、公共卫生和自然灾害这四个经济和社会关键垂直领域进行了扩展。

Method: 通过适应 FutureX 的无污染实时评估流程，评估当前最先进的代理性大型语言模型（LLMs）是否具备工业部署所需的领域基础。

Result: 研究发现，通用推理与高价值垂直应用所需的精度之间存在显著性能差距。

Conclusion: FutureX-Pro 揭示了通用推理与高价值垂直应用所需精度之间的性能差距，强调了领域基础对于工业部署的重要性。

Abstract: Building upon FutureX, which established a live benchmark for general-purpose future prediction, this report introduces FutureX-Pro, including FutureX-Finance, FutureX-Retail, FutureX-PublicHealth, FutureX-NaturalDisaster, and FutureX-Search. These together form a specialized framework extending agentic future prediction to high-value vertical domains. While generalist agents demonstrate proficiency in open-domain search, their reliability in capital-intensive and safety-critical sectors remains under-explored. FutureX-Pro targets four economically and socially pivotal verticals: Finance, Retail, Public Health, and Natural Disaster. We benchmark agentic Large Language Models (LLMs) on entry-level yet foundational prediction tasks -- ranging from forecasting market indicators and supply chain demands to tracking epidemic trends and natural disasters. By adapting the contamination-free, live-evaluation pipeline of FutureX, we assess whether current State-of-the-Art (SOTA) agentic LLMs possess the domain grounding necessary for industrial deployment. Our findings reveal the performance gap between generalist reasoning and the precision required for high-value vertical applications.

</details>


### [425] [Docs2Synth: A Synthetic Data Trained Retriever Framework for Scanned Visually Rich Documents Understanding](https://arxiv.org/abs/2601.12260)
*Yihao Ding,Qiang Sun,Puzhen Wu,Sirui Li,Siwen Luo,Wei Liu*

Main category: cs.AI

TL;DR: Docs2Synth是一个合成监督框架，通过检索引导推理提升低资源领域的文档理解，减少幻觉并增强领域泛化。


<details>
  <summary>Details</summary>
Motivation: 解决在受监管领域中，扫描文档缺乏手动标注和预训练模型难以跟上领域特定知识更新的挑战。

Method: Docs2Synth通过自动处理原始文档集合，生成和验证多样化的QA对，并训练轻量级视觉检索器提取领域相关证据。推理时，检索器与MLLM通过迭代检索-生成循环协作。

Result: 在多个VRDU基准测试中，Docs2Synth显著提升了模型的领域泛化和响应一致性，且无需人工标注。

Conclusion: Docs2Synth框架通过合成监督和检索引导推理，显著提升了在低资源和隐私领域的文档理解能力，无需人工标注即可实现领域泛化和减少幻觉。

Abstract: Document understanding (VRDU) in regulated domains is particularly challenging, since scanned documents often contain sensitive, evolving, and domain specific knowledge. This leads to two major challenges: the lack of manual annotations for model adaptation and the difficulty for pretrained models to stay up-to-date with domain-specific facts. While Multimodal Large Language Models (MLLMs) show strong zero-shot abilities, they still suffer from hallucination and limited domain grounding. In contrast, discriminative Vision-Language Pre-trained Models (VLPMs) provide reliable grounding but require costly annotations to cover new domains. We introduce Docs2Synth, a synthetic-supervision framework that enables retrieval-guided inference for private and low-resource domains. Docs2Synth automatically processes raw document collections, generates and verifies diverse QA pairs via an agent-based system, and trains a lightweight visual retriever to extract domain-relevant evidence. During inference, the retriever collaborates with an MLLM through an iterative retrieval--generation loop, reducing hallucination and improving response consistency. We further deliver Docs2Synth as an easy-to-use Python package, enabling plug-and-play deployment across diverse real-world scenarios. Experiments on multiple VRDU benchmarks show that Docs2Synth substantially enhances grounding and domain generalization without requiring human annotations.

</details>


### [426] [ToolPRMBench: Evaluating and Advancing Process Reward Models for Tool-using Agents](https://arxiv.org/abs/2601.12294)
*Dawei Li,Yuguang Yao,Zhen Tan,Huan Liu,Ruocheng Guo*

Main category: cs.AI

TL;DR: 本文介绍了ToolPRMBench，一个用于评估工具使用代理PRMs的大规模基准测试，通过实验验证了专用PRMs的优势。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏系统可靠的评估基准来测试工具使用场景中的过程奖励模型（PRMs），因此本文旨在填补这一空白。

Method: 本文基于多个代表性工具使用基准测试构建了ToolPRMBench，将代理轨迹转化为步骤级测试用例，并采用离线采样和在线采样方法分别捕获单步和多步错误。此外，还提出了多LLM验证流程以减少标签噪声。

Result: 实验结果表明，PRMs在工具使用场景中的有效性存在明显差异，专用PRMs表现出更强的潜力。

Conclusion: 本文提出了ToolPRMBench基准测试，专门用于评估工具使用代理的过程奖励模型（PRMs），并通过实验揭示了PRMs的有效性差异，突出了专用PRMs的潜力。

Abstract: Reward-guided search methods have demonstrated strong potential in enhancing tool-using agents by effectively guiding sampling and exploration over complex action spaces. As a core design, those search methods utilize process reward models (PRMs) to provide step-level rewards, enabling more fine-grained monitoring. However, there is a lack of systematic and reliable evaluation benchmarks for PRMs in tool-using settings. In this paper, we introduce ToolPRMBench, a large-scale benchmark specifically designed to evaluate PRMs for tool-using agents. ToolPRMBench is built on top of several representative tool-using benchmarks and converts agent trajectories into step-level test cases. Each case contains the interaction history, a correct action, a plausible but incorrect alternative, and relevant tool metadata. We respectively utilize offline sampling to isolate local single-step errors and online sampling to capture realistic multi-step failures from full agent rollouts. A multi-LLM verification pipeline is proposed to reduce label noise and ensure data quality. We conduct extensive experiments across large language models, general PRMs, and tool-specialized PRMs on ToolPRMBench. The results reveal clear differences in PRM effectiveness and highlight the potential of specialized PRMs for tool-using. Code and data will be released at https://github.com/David-Li0406/ToolPRMBench.

</details>


### [427] [Survival is the Only Reward: Sustainable Self-Training Through Environment-Mediated Selection](https://arxiv.org/abs/2601.12310)
*Jennifer Dodgson,Alfath Daryl Alhajir,Michael Joedhitya,Akira Rafhael Janson Pattirane,Surender Suresh Kumar,Joseph Lim,C. H. Peh,Adith Ramdas,Steven Zhang Zhexu*

Main category: cs.AI

TL;DR: 该论文提出了一种基于环境生存能力的自训练架构，避免奖励黑客问题，通过负空间学习实现可持续自我改进，为自主系统提供新路径。


<details>
  <summary>Details</summary>
Motivation: 解决自训练系统因缺乏外部数据质量判断标准而导致的奖励黑客和语义漂移问题，探索在稀疏外部反馈和有限内存下的稳定自训练方法。

Method: 提出了一种自训练架构，其中学习完全由环境生存能力调节，而非奖励或外部定义的适应标准。候选行为在真实资源约束下执行，仅那些环境效应持久且保留未来交互可能性的行为被传播。

Result: 分析表明，改进主要通过有效和可重复策略在巩固和剪枝机制下的持久性实现（称为负空间学习），模型无需显式指令即可发展元学习策略。

Conclusion: 该论文证明了基于环境生存能力的自训练架构能够实现可持续的开放式自我改进，为不依赖人类标注数据或复杂奖励塑造的自主系统提供了一条可行路径。

Abstract: Self-training systems often degenerate due to the lack of an external criterion for judging data quality, leading to reward hacking and semantic drift. This paper provides a proof-of-concept system architecture for stable self-training under sparse external feedback and bounded memory, and empirically characterises its learning dynamics and failure modes.
  We introduce a self-training architecture in which learning is mediated exclusively by environmental viability, rather than by reward, objective functions, or externally defined fitness criteria. Candidate behaviours are executed under real resource constraints, and only those whose environmental effects both persist and preserve the possibility of future interaction are propagated. The environment does not provide semantic feedback, dense rewards, or task-specific supervision; selection operates solely through differential survival of behaviours as world-altering events, making proxy optimisation impossible and rendering reward-hacking evolutionarily unstable.
  Analysis of semantic dynamics shows that improvement arises primarily through the persistence of effective and repeatable strategies under a regime of consolidation and pruning, a paradigm we refer to as negative-space learning (NSL), and that models develop meta-learning strategies (such as deliberate experimental failure in order to elicit informative error messages) without explicit instruction. This work establishes that environment-grounded selection enables sustainable open-ended self-improvement, offering a viable path toward more robust and generalisable autonomous systems without reliance on human-curated data or complex reward shaping.

</details>


### [428] [Beyond Human Annotation: Recent Advances in Data Generation Methods for Document Intelligence](https://arxiv.org/abs/2601.12318)
*Dehao Ying,Fengchang Yu,Haihua Chen,Changjiang Jiang,Yurong Li,Wei Lu*

Main category: cs.AI

TL;DR: 本文通过系统化数据生成领域，提出了一个统一的技术框架和分类法，解决了DI中数据生成的碎片化问题，并揭示了关键挑战和前沿方向。


<details>
  <summary>Details</summary>
Motivation: 文档智能（DI）的进展需要大规模、高质量的培训数据，但手动标注仍然是关键瓶颈。现有调查局限于对单一模态或特定任务的碎片化关注，缺乏与现实工作流程统一视角。

Method: 建立了一个全面的数据生成技术地图，将数据生成重新定义为监督信号生产，并基于“数据和标签的可用性”引入了一种新的分类法。该方法论分为四个资源中心范式：数据增强、从零开始的数据生成、自动化数据标注和自监督信号构建。

Result: 建立了一个多级评估框架，整合了内在质量和外在效用，并汇编了各种DI基准的性能增益。

Conclusion: 数据生成被定位为下一代文档智能（DI）的核心引擎，通过系统化这一分散领域，揭示了保真度差距等关键挑战和共进化生态系统等前沿问题。

Abstract: The advancement of Document Intelligence (DI) demands large-scale, high-quality training data, yet manual annotation remains a critical bottleneck. While data generation methods are evolving rapidly, existing surveys are constrained by fragmented focuses on single modalities or specific tasks, lacking a unified perspective aligned with real-world workflows. To fill this gap, this survey establishes the first comprehensive technical map for data generation in DI. Data generation is redefined as supervisory signal production, and a novel taxonomy is introduced based on the "availability of data and labels." This framework organizes methodologies into four resource-centric paradigms: Data Augmentation, Data Generation from Scratch, Automated Data Annotation, and Self-Supervised Signal Construction. Furthermore, a multi-level evaluation framework is established to integrate intrinsic quality and extrinsic utility, compiling performance gains across diverse DI benchmarks. Guided by this unified structure, the methodological landscape is dissected to reveal critical challenges such as fidelity gaps and frontiers including co-evolutionary ecosystems. Ultimately, by systematizing this fragmented field, data generation is positioned as the central engine for next-generation DI.

</details>


### [429] [MARO: Learning Stronger Reasoning from Social Interaction](https://arxiv.org/abs/2601.12323)
*Yin Cai,Zhouhong Gu,Juntao Zhang,Ping Chen*

Main category: cs.AI

TL;DR: MARO通过多智能体社交环境训练，提升LLMs的推理能力，并实现能力迁移。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型训练方法缺乏在真实社交场景中的互动、协商和竞争经验，无法有效提升模型的推理能力。

Method: MARO通过分解交互过程中的行为、平衡角色训练样本权重及直接评估行为效用，解决了稀疏学习信号、角色分布不均和环境不稳定问题。

Result: MARO显著提升了社交推理能力，且这些能力能有效迁移至数学推理和指令遵循等任务。

Conclusion: MARO展示了多智能体社交学习在提升LLMs通用推理能力方面的巨大潜力。

Abstract: Humans face countless scenarios that require reasoning and judgment in daily life. However, existing large language model training methods primarily allow models to learn from existing textual content or solve predetermined problems, lacking experience in real scenarios involving interaction, negotiation, and competition with others. To address this, this paper proposes Multi-Agent Reward Optimization (MARO), a method that enables large language models (LLMs) to acquire stronger reasoning abilities by learning and practicing in multi-agent social environments. Specifically, MARO first addresses the sparse learning signal problem by decomposing final success or failure outcomes into each specific behavior during the interaction process; second, it handles the uneven role distribution problem by balancing the training sample weights of different roles; finally, it addresses environmental instability issues by directly evaluating the utility of each behavior. Experimental results demonstrate that MARO not only achieves significant improvements in social reasoning capabilities, but also that the abilities acquired through social simulation learning can effectively transfer to other tasks such as mathematical reasoning and instruction following. This reveals the tremendous potential of multi-agent social learning in enhancing the general reasoning capabilities of LLMs.

</details>


### [430] [Actionable Advice from Reviews via Mixture of LoRA Experts: A Two-LLM Pipeline for Issue Extraction and Business Recommendations](https://arxiv.org/abs/2601.12338)
*Kartikey Singh Bhandari,Manav Ganesh,Yashwant Viswanathan,Archit Agrawal,Dhruv Kumar,Pratik Narang*

Main category: cs.AI

TL;DR: 论文提出双LLM框架，结合LoRA专家混合策略，从客户评论生成可操作建议，效果优于基线。


<details>
  <summary>Details</summary>
Motivation: 客户评论包含丰富的服务失败和用户期望信号，但将其转化为可操作决策仍具挑战性。研究旨在解决评论到行动的生成问题。

Method: 采用模块化双LLM框架：Issue模型提取关键问题并分配粗粒度主题，Advice模型基于问题表示生成针对性操作建议。通过LoRA专家混合策略实现专业化，避免昂贵全微调。

Result: 在航空和餐饮领域的Yelp评论上构建合成三元组进行训练，评估显示该方法在操作性、特异性等八个维度上均优于基线。

Conclusion: 该论文提出的模块化双LLM框架，结合LoRA专家混合策略，在从客户评论生成可操作建议方面表现优异，显著优于仅提示和单一适配器的基线方法。

Abstract: Customer reviews contain detailed, domain specific signals about service failures and user expectations, but converting this unstructured feedback into actionable business decisions remains difficult. We study review-to-action generation: producing concrete, implementable recommendations grounded in review text. We propose a modular two-LLM framework in which an Issue model extracts salient issues and assigns coarse themes, and an Advice model generates targeted operational fixes conditioned on the extracted issue representation. To enable specialization without expensive full fine-tuning, we adapt the Advice model using a mixture of LoRA experts strategy: multiple low-rank adapters are trained and a lightweight gating mechanism performs token-level expert mixing at inference, combining complementary expertise across issue types. We construct synthetic review-issue-advice triples from Yelp reviews (airlines and restaurants) to supervise training, and evaluate recommendations using an eight dimension operational rubric spanning actionability, specificity, feasibility, expected impact, novelty, non-redundancy, bias, and clarity. Across both domains, our approach consistently outperforms prompting-only and single-adapter baselines, yielding higher actionability and specificity while retaining favorable efficiency-quality trade-offs.

</details>


### [431] [PsychēChat: An Empathic Framework Focused on Emotion Shift Tracking and Safety Risk Analysis in Psychological Counseling](https://arxiv.org/abs/2601.12392)
*Zhentao Xia,Yongqi Fan,Yuxiang Chu,Yichao Yin,Liangliang Chen,Tong Ruan,Weiyan Zhang*

Main category: cs.AI

TL;DR: PsychēChat整合情感转移与安全风险分析，通过两种模式在心理咨询中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有模型未明确建模咨询者的情感转移，且如何使咨询模型响应与情感转移对齐并主动降低安全风险尚未充分探索。

Method: 提出了PsychēChat，包含情感管理模块和风险控制模块，采用Agent Mode和LLM Mode两种建模范式。

Result: 实验表明PsychēChat在情感洞察和安全控制方面优于现有方法。

Conclusion: PsychēChat通过明确整合情感转移跟踪和安全风险分析，在心理咨询中表现出色，超越了现有方法。

Abstract: Large language models (LLMs) have demonstrated notable advancements in psychological counseling. However, existing models generally do not explicitly model seekers' emotion shifts across counseling sessions, a core focus in classical psychological schools. Moreover, how to align counselor models' responses with these emotion shifts while proactively mitigating safety risks remains underexplored. To bridge these gaps, we propose PsychēChat, which explicitly integrates emotion shift tracking and safety risk analysis for psychological counseling. Specifically, we employ interactive role-playing to synthesize counselor--seeker dialogues, incorporating two modules: Emotion Management Module, to capture seekers' current emotions and emotion shifts; and Risk Control Module, to anticipate seekers' subsequent reactions and identify potential risks. Furthermore, we introduce two modeling paradigms. The Agent Mode structures emotion management, risk control, and counselor responses into a collaborative multi-agent pipeline. The LLM Mode integrates these stages into a unified chain-of-thought for end-to-end inference, balancing efficiency and performance. Extensive experiments, including interactive scoring, dialogue-level evaluation, and human assessment, demonstrate that PsychēChat outperforms existing methods for emotional insight and safety control.

</details>


### [432] [Are LLMs Smarter Than Chimpanzees? An Evaluation on Perspective Taking and Knowledge State Estimation](https://arxiv.org/abs/2601.12410)
*Dingyi Yang,Junqi Zhao,Xue Li,Ce Li,Boyang Li*

Main category: cs.AI

TL;DR: 论文评估LLMs在知识状态跟踪和估计任务中的表现，发现其性能接近随机，远不如人类，呼吁未来研究重视相关能力。


<details>
  <summary>Details</summary>
Motivation: 评估LLMs在知识状态跟踪和估计方面的表现，基于认知人类学对人类与黑猩猩智力差异的观察。

Method: 设计了两个任务：(1)检测故事角色是否通过行动展示了不应拥有的知识；(2)预测角色基于自身知识与未知客观事实的下一步行动。

Result: 大多数LLMs在两个任务上表现接近随机，显著低于人类水平。

Conclusion: 当前最先进的LLMs在知识状态跟踪和估计任务上表现接近随机，远不及人类。未来LLM研究应更重视知识估计和意图理解能力。

Abstract: Cognitive anthropology suggests that the distinction of human intelligence lies in the ability to infer other individuals' knowledge states and understand their intentions. In comparison, our closest animal relative, chimpanzees, lack the capacity to do so. With this paper, we aim to evaluate LLM performance in the area of knowledge state tracking and estimation. We design two tasks to test (1) if LLMs can detect when story characters, through their actions, demonstrate knowledge they should not possess, and (2) if LLMs can predict story characters' next actions based on their own knowledge vs. objective truths they do not know. Results reveal that most current state-of-the-art LLMs achieve near-random performance on both tasks, and are substantially inferior to humans. We argue future LLM research should place more weight on the abilities of knowledge estimation and intention understanding.

</details>


### [433] [Large Language Model for OWL Proofs](https://arxiv.org/abs/2601.12444)
*Hui Yang,Jiaoyan Chen,Uli Sattler*

Main category: cs.AI

TL;DR: 研究LLMs在OWL本体论中生成逻辑证明的能力，发现其在复杂或不完美条件下表现受限，但整体具有潜力。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在OWL本体论背景下生成忠实、人类可读的证明（解释）能力，这一领域尚未充分探索。

Method: 开发了一个自动化数据集构建和评估框架，涵盖提取、简化和解释三个连续任务，以及评估前提的逻辑完整性。

Result: 实验发现：(1) 部分模型整体表现强，但在复杂案例中受限；(2) 逻辑复杂性（而非表示格式）是影响性能的主要因素；(3) 输入数据的噪声和不完整性显著降低LLMs表现。

Conclusion: 大型语言模型（LLMs）在逻辑严谨的解释生成方面展现出潜力，但在处理复杂或不完美条件下的推理时仍存在不足。

Abstract: The ability of Large Language Models (LLMs) to perform reasoning tasks such as deduction has been widely investigated in recent years. Yet, their capacity to generate proofs-faithful, human-readable explanations of why conclusions follow-remains largely under explored. In this work, we study proof generation in the context of OWL ontologies, which are widely adopted for representing and reasoning over complex knowledge, by developing an automated dataset construction and evaluation framework. Our evaluation encompassing three sequential tasks for complete proving: Extraction, Simplification, and Explanation, as well as an additional task of assessing Logic Completeness of the premise. Through extensive experiments on widely used reasoning LLMs, we achieve important findings including: (1) Some models achieve overall strong results but remain limited on complex cases; (2) Logical complexity, rather than representation format (formal logic language versus natural language), is the dominant factor shaping LLM performance; and (3) Noise and incompleteness in input data substantially diminish LLMs' performance. Together, these results underscore both the promise of LLMs for explanation with rigorous logics and the gap of supporting resilient reasoning under complex or imperfect conditions. Code and data are available at https://github.com/HuiYang1997/LLMOwlR.

</details>


### [434] [Failure Modes in Multi-Hop QA: The Weakest Link Law and the Recognition Bottleneck](https://arxiv.org/abs/2601.12499)
*Meiru Zhang,Zaiqiao Meng,Nigel Collier*

Main category: cs.AI

TL;DR: LLMs多跳推理失败由绝对位置决定，MFAI可改善识别瓶颈，系统2推理模型能有效处理长上下文。


<details>
  <summary>Details</summary>
Motivation: 探究LLMs在多跳推理中失败的原因，是识别失败还是合成失败。

Method: 引入多焦点注意力指令（MFAI）作为语义探针，通过显式引导注意力来区分识别和合成失败。

Result: 提出'最弱链接法则'，发现多跳推理性能取决于最不可见证据的性能，且失败由绝对位置决定。匹配MFAI可提升低可见位置准确率11.5%，误导MFAI在真实任务中引发混淆。

Conclusion: LLMs的推理性能受绝对位置而非线性距离影响，系统2推理模型能有效定位和整合信息。

Abstract: Despite scaling to massive context windows, Large Language Models (LLMs) struggle with multi-hop reasoning due to inherent position bias, which causes them to overlook information at certain positions. Whether these failures stem from an inability to locate evidence (recognition failure) or integrate it (synthesis failure) is unclear. We introduce Multi-Focus Attention Instruction (MFAI), a semantic probe to disentangle these mechanisms by explicitly steering attention towards selected positions. Across 5 LLMs on two multi-hop QA tasks (MuSiQue and NeoQA), we establish the "Weakest Link Law": multi-hop reasoning performance collapses to the performance level of the least visible evidence. Crucially, this failure is governed by absolute position rather than the linear distance between facts (performance variance $<3%$). We further identify a duality in attention steering: while matched MFAI resolves recognition bottlenecks, improving accuracy by up to 11.5% in low-visibility positions, misleading MFAI triggers confusion in real-world tasks but is successfully filtered in synthetic tasks. Finally, we demonstrate that "thinking" models that utilize System-2 reasoning, effectively locate and integrate the required information, matching gold-only baselines even in noisy, long-context settings.

</details>


### [435] [Agentic Reasoning for Large Language Models](https://arxiv.org/abs/2601.12538)
*Tianxin Wei,Ting-Wei Li,Zhining Liu,Xuying Ning,Ze Yang,Jiaru Zou,Zhichen Zeng,Ruizhong Qiu,Xiao Lin,Dongqi Fu,Zihao Li,Mengting Ai,Duo Zhou,Wenxuan Bao,Yunzhe Li,Gaotang Li,Cheng Qian,Yu Wang,Xiangru Tang,Yin Xiao,Liri Fang,Hui Liu,Xianfeng Tang,Yuji Zhang,Chi Wang,Jiaxuan You,Heng Ji,Hanghang Tong,Jingrui He*

Main category: cs.AI

TL;DR: 该论文综述了代理推理方法，将其分为基础、自我进化和集体多代理推理三个维度，并探讨了实际应用、开放挑战和未来方向。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在封闭环境中表现出强大的推理能力，但在开放和动态环境中表现不佳，因此需要研究代理推理以提升其自主性和适应性。

Method: 论文通过三个互补的维度组织代理推理：基础代理推理、自我进化代理推理和集体多代理推理，并区分了上下文推理和后训练推理。

Result: 论文综述了代理推理框架在科学、机器人、医疗、自主研究和数学等实际应用和基准测试中的代表性成果。

Conclusion: 该论文总结了代理推理方法的统一路线图，并提出了开放挑战和未来方向，如个性化、长时程交互、世界建模、可扩展的多代理训练以及现实世界部署的治理。

Abstract: Reasoning is a fundamental cognitive process underlying inference, problem-solving, and decision-making. While large language models (LLMs) demonstrate strong reasoning capabilities in closed-world settings, they struggle in open-ended and dynamic environments. Agentic reasoning marks a paradigm shift by reframing LLMs as autonomous agents that plan, act, and learn through continual interaction. In this survey, we organize agentic reasoning along three complementary dimensions. First, we characterize environmental dynamics through three layers: foundational agentic reasoning, which establishes core single-agent capabilities including planning, tool use, and search in stable environments; self-evolving agentic reasoning, which studies how agents refine these capabilities through feedback, memory, and adaptation; and collective multi-agent reasoning, which extends intelligence to collaborative settings involving coordination, knowledge sharing, and shared goals. Across these layers, we distinguish in-context reasoning, which scales test-time interaction through structured orchestration, from post-training reasoning, which optimizes behaviors via reinforcement learning and supervised fine-tuning. We further review representative agentic reasoning frameworks across real-world applications and benchmarks, including science, robotics, healthcare, autonomous research, and mathematics. This survey synthesizes agentic reasoning methods into a unified roadmap bridging thought and action, and outlines open challenges and future directions, including personalization, long-horizon interaction, world modeling, scalable multi-agent training, and governance for real-world deployment.

</details>


### [436] [MemeLens: Multilingual Multitask VLMs for Memes](https://arxiv.org/abs/2601.12539)
*Ali Ezzat Shahroor,Mohamed Bayan Kmainasi,Abul Hasnat,Dimitar Dimitrov,Giovanni Da San Martino,Preslav Nakov,Firoj Alam*

Main category: cs.AI

TL;DR: MemeLens是一个统一的多语言、多任务解释增强视觉语言模型，通过整合多个数据集和任务，提升了模因理解的跨领域泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的模因研究分散在不同任务和语言中，限制了跨领域泛化能力。为了解决这一问题，提出了一个统一的多语言、多任务模型。

Method: 提出了MemeLens模型，整合了38个公共模因数据集，并将数据集特定标签映射到一个包含20个任务的共享分类法中。通过跨模型范式、任务类别和数据集的全面实证分析，验证了模型的有效性。

Result: 研究发现，稳健的模因理解需要多模态训练，且在统一训练环境下表现更佳。模型对单个数据集的过度专业化敏感。

Conclusion: MemeLens作为一个统一的多语言、多任务解释增强视觉语言模型，能够有效提升对网络模因的理解能力，尤其在多模态训练和统一训练环境下表现更优。

Abstract: Memes are a dominant medium for online communication and manipulation because meaning emerges from interactions between embedded text, imagery, and cultural context. Existing meme research is distributed across tasks (hate, misogyny, propaganda, sentiment, humour) and languages, which limits cross-domain generalization. To address this gap we propose MemeLens, a unified multilingual and multitask explanation-enhanced Vision Language Model (VLM) for meme understanding. We consolidate 38 public meme datasets, filter and map dataset-specific labels into a shared taxonomy of $20$ tasks spanning harm, targets, figurative/pragmatic intent, and affect. We present a comprehensive empirical analysis across modeling paradigms, task categories, and datasets. Our findings suggest that robust meme understanding requires multimodal training, exhibits substantial variation across semantic categories, and remains sensitive to over-specialization when models are fine-tuned on individual datasets rather than trained in a unified setting. We will make the experimental resources and datasets publicly available for the community.

</details>


### [437] [Rethinking the AI Scientist: Interactive Multi-Agent Workflows for Scientific Discovery](https://arxiv.org/abs/2601.12542)
*Lukas Weidener,Marko Brkić,Mihailo Jovanović,Ritvik Singh,Chiara Baccin,Emre Ulgac,Alex Dobrin,Aakaash Meduri*

Main category: cs.AI

TL;DR: Deep Research 是一个多智能体系统，能在几分钟内完成交互式科学研究，显著提升效率，但在文献获取和新颖性评估方面仍有改进空间。


<details>
  <summary>Details</summary>
Motivation: 现有AI科学发现系统多为专有且批处理模式，无法实现实时研究指导，因此需要开发交互式系统以缩短研究周期。

Method: 采用多智能体架构，包括规划、数据分析、文献搜索和新颖性检测智能体，通过持久化世界状态保持上下文。支持半自主和全自主两种工作模式。

Result: 在BixBench计算生物学基准测试中表现优异，开放回答准确率达48.8%，多项选择达64.5%，超越基线14至26个百分点。

Conclusion: Deep Research 架构通过多智能体系统实现了交互式科学研究，显著提升了研究效率，但在开放性文献获取和自动化新颖性评估方面仍存在挑战。

Abstract: Artificial intelligence systems for scientific discovery have demonstrated remarkable potential, yet existing approaches remain largely proprietary and operate in batch-processing modes requiring hours per research cycle, precluding real-time researcher guidance. This paper introduces Deep Research, a multi-agent system enabling interactive scientific investigation with turnaround times measured in minutes. The architecture comprises specialized agents for planning, data analysis, literature search, and novelty detection, unified through a persistent world state that maintains context across iterative research cycles. Two operational modes support different workflows: semi-autonomous mode with selective human checkpoints, and fully autonomous mode for extended investigations. Evaluation on the BixBench computational biology benchmark demonstrated state-of-the-art performance, achieving 48.8% accuracy on open response and 64.5% on multiple-choice evaluation, exceeding existing baselines by 14 to 26 percentage points. Analysis of architectural constraints, including open access literature limitations and challenges inherent to automated novelty assessment, informs practical deployment considerations for AI-assisted scientific workflows.

</details>


### [438] [How Clinicians Think and What AI Can Learn From It](https://arxiv.org/abs/2601.12547)
*Dipayan Sengupta,Saumya Panda*

Main category: cs.AI

TL;DR: 论文主张临床AI应采用序数和非补偿性决策方法，以更贴近临床医生的实际推理过程，并提出了一种结合丰富模型和稳健序数规则的AI框架。


<details>
  <summary>Details</summary>
Motivation: 临床AI系统通常作为预测引擎运行，但真实的临床推理是一个时间受限、序列化的控制问题，涉及不确定性和不可逆行动。论文旨在探索更符合临床医生决策方式的AI方法。

Method: 论文通过分析临床决策的特点，提出了一种基于序数、非补偿性决策的AI框架，包括使用丰富的模型进行信念和轨迹预测，但通过稳健的序数规则选择行动。

Result: 研究表明，在医学决策中，序数和非补偿性决策方法（如快速节俭启发式）不仅是一种有限理性的捷径，而且在认识论上具有优势，特别是在信号和偏好获取存在噪声的情况下。

Conclusion: 论文提出了一种与临床医生思维方式对齐的AI蓝图，强调在医学决策中采用稳健的序数规则，而非传统的基数优化方法。

Abstract: Most clinical AI systems operate as prediction engines -- producing labels or risk scores -- yet real clinical reasoning is a time-bounded, sequential control problem under uncertainty. Clinicians interleave information gathering with irreversible actions, guided by regret, constraints and patient values. We argue that the dominant computational substrate of clinician reasoning is not cardinal optimization but ordinal, non-compensatory decision-making: Clinicians frequently rely on fast-and-frugal, lexicographic heuristics (e.g., fast-and-frugal trees) that stop early after checking a small, fixed sequence of cues. We provide a normative rationale for why such algorithms are not merely bounded rationality shortcuts, but can be epistemically preferred in medicine. First, many clinical trade-offs are constructed through human judgment and are only weakly measurable on absolute scales; without strong measurement axioms, only orderings are invariant, motivating an ordinal-by-default stance. Second, preference and signal elicitation are structurally crude: The mapping from truth $\to$ perception $\to$ inference $\to$ recorded variables introduces layered noise, leaving a persistent uncertainty floor. When this 'crudeness' overwhelms the decision margin, plug-in expected-utility optimization becomes brittle (high flip probability under small perturbations), whereas robust dominance/filtering rules ($ε$-dominance, maximin) stabilize decisions.Finally, we outline a clinician-aligned AI blueprint: Use rich models for beliefs and trajectories, but choose actions through robust ordinal rules; treat heuristics as the low-dimensional special case; and deploy AI as 'selective complexity' -- invoked mainly for tie-breaking when decisions are fragile and information has positive expected impact.

</details>


### [439] [Agentic Artificial Intelligence (AI): Architectures, Taxonomies, and Evaluation of Large Language Model Agents](https://arxiv.org/abs/2601.12560)
*Arunkumar V,Gangadharan G. R.,Rajkumar Buyya*

Main category: cs.AI

TL;DR: 本文系统化地分类了Agentic AI的架构，提出了统一框架，并探讨了技术演变、应用场景及未来挑战。


<details>
  <summary>Details</summary>
Motivation: 随着AI从单纯生成文本向Agentic AI（具有自主感知、推理、规划和行为能力的系统）转变，现有设计多样但缺乏统一框架，亟需系统化的分类和评估方法。

Method: 通过分析现有架构，提出一个基于感知、大脑、规划、行动、工具使用和协作的统一分类法，并以此分类法为视角描述技术演变。

Result: 提出了一个涵盖感知、大脑、规划等六部分的统一分类法，并总结了当前Agentic AI的应用环境和评估实践。

Conclusion: 本文提出了一个统一的Agentic AI分类法，并探讨了从线性推理到原生推理模型的转变，以及从固定API调用到开放标准的过渡。同时，文章指出了当前面临的挑战（如幻觉行为、无限循环等）并提出了未来研究方向。

Abstract: Artificial Intelligence is moving from models that only generate text to Agentic AI, where systems behave as autonomous entities that can perceive, reason, plan, and act. Large Language Models (LLMs) are no longer used only as passive knowledge engines but as cognitive controllers that combine memory, tool use, and feedback from their environment to pursue extended goals. This shift already supports the automation of complex workflows in software engineering, scientific discovery, and web navigation, yet the variety of emerging designs, from simple single loop agents to hierarchical multi agent systems, makes the landscape hard to navigate. In this paper, we investigate architectures and propose a unified taxonomy that breaks agents into Perception, Brain, Planning, Action, Tool Use, and Collaboration. We use this lens to describe the move from linear reasoning procedures to native inference time reasoning models, and the transition from fixed API calls to open standards like the Model Context Protocol (MCP) and Native Computer Use. We also group the environments in which these agents operate, including digital operating systems, embodied robotics, and other specialized domains, and we review current evaluation practices. Finally, we highlight open challenges, such as hallucination in action, infinite loops, and prompt injection, and outline future research directions toward more robust and reliable autonomous systems.

</details>


### [440] [STEP-LLM: Generating CAD STEP Models from Natural Language with Large Language Models](https://arxiv.org/abs/2601.12641)
*Xiangyu Shi,Junyang Ding,Xu Zhao,Sinong Zhan,Payal Mohapatra,Daniel Quispe,Kojo Welbeck,Jian Cao,Wei Chen,Ping Guo,Qi Zhu*

Main category: cs.AI

TL;DR: STEP-LLM通过创新预处理和强化学习，显著提升了从自然语言生成STEP模型的几何保真度，为降低CAD设计门槛提供了新途径。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统文本到CAD方法依赖内核且缺乏通用性的问题，研究探索了使用广泛兼容的STEP文件格式，并克服其图结构特性对自回归大语言模型的挑战。

Method: 研究通过预处理STEP文件的图结构格式（包括深度优先搜索重新序列化和链式思维结构注释）、检索增强生成以及基于Chamfer Distance的几何奖励强化学习，优化了模型生成质量。

Result: 实验表明，STEP-LLM在几何保真度上优于Text2CAD基线，其各阶段优化（如RAG模块、DFS重新序列化和RL）均对提升生成质量有显著贡献。

Conclusion: 该研究表明，通过结合检索增强生成、深度优先搜索重新序列化和强化学习，STEP-LLM能够显著提高从自然语言生成STEP模型的几何保真度，展示了其在降低CAD设计门槛方面的潜力。

Abstract: Computer-aided design (CAD) is vital to modern manufacturing, yet model creation remains labor-intensive and expertise-heavy. To enable non-experts to translate intuitive design intent into manufacturable artifacts, recent large language models-based text-to-CAD efforts focus on command sequences or script-based formats like CadQuery. However, these formats are kernel-dependent and lack universality for manufacturing. In contrast, the Standard for the Exchange of Product Data (STEP, ISO 10303) file is a widely adopted, neutral boundary representation (B-rep) format directly compatible with manufacturing, but its graph-structured, cross-referenced nature poses unique challenges for auto-regressive LLMs. To address this, we curate a dataset of ~40K STEP-caption pairs and introduce novel preprocessing tailored for the graph-structured format of STEP, including a depth-first search-based reserialization that linearizes cross-references while preserving locality and chain-of-thought(CoT)-style structural annotations that guide global coherence. We integrate retrieval-augmented generation to ground predictions in relevant examples for supervised fine-tuning, and refine generation quality through reinforcement learning with a specific Chamfer Distance-based geometric reward. Experiments demonstrate consistent gains of our STEP-LLM in geometric fidelity over the Text2CAD baseline, with improvements arising from multiple stages of our framework: the RAG module substantially enhances completeness and renderability, the DFS-based reserialization strengthens overall accuracy, and the RL further reduces geometric discrepancy. Both metrics and visual comparisons confirm that STEP-LLM generates shapes with higher fidelity than Text2CAD. These results show the feasibility of LLM-driven STEP model generation from natural language, showing its potential to democratize CAD design for manufacturing.

</details>


### [441] [MedConsultBench: A Full-Cycle, Fine-Grained, Process-Aware Benchmark for Medical Consultation Agents](https://arxiv.org/abs/2601.12661)
*Chuhan Qiao,Jianghua Huang,Daxing Zhao,Ziding Liu,Yanjun Shen,Bing Cheng,Wei Lin,Kai Wu*

Main category: cs.AI

TL;DR: MedConsultBench 是一个评估在线医疗咨询全周期的框架，通过细粒度指标揭示AI模型在临床实践中的不足。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法过于关注结果导向任务，忽略了端到端流程完整性和临床安全性，且动态场景评估往往碎片化、粗粒度。

Method: 提出 MedConsultBench 框架，通过 Atomic Information Units (AIUs) 在子轮次级别追踪临床信息获取，使用 22 个细粒度指标评估完整在线咨询周期。

Result: 对 19 个大语言模型的系统评估显示，高诊断准确性常掩盖信息收集效率和用药安全的显著缺陷。

Conclusion: MedConsultBench 提供了一个严格的评估基础，用于将医疗AI与真实临床护理的细致要求对齐，揭示了高诊断准确性背后在信息收集效率和用药安全方面的显著不足。

Abstract: Current evaluations of medical consultation agents often prioritize outcome-oriented tasks, frequently overlooking the end-to-end process integrity and clinical safety essential for real-world practice. While recent interactive benchmarks have introduced dynamic scenarios, they often remain fragmented and coarse-grained, failing to capture the structured inquiry logic and diagnostic rigor required in professional consultations. To bridge this gap, we propose MedConsultBench, a comprehensive framework designed to evaluate the complete online consultation cycle by covering the entire clinical workflow from history taking and diagnosis to treatment planning and follow-up Q\&A. Our methodology introduces Atomic Information Units (AIUs) to track clinical information acquisition at a sub-turn level, enabling precise monitoring of how key facts are elicited through 22 fine-grained metrics. By addressing the underspecification and ambiguity inherent in online consultations, the benchmark evaluates uncertainty-aware yet concise inquiry while emphasizing medication regimen compatibility and the ability to handle realistic post-prescription follow-up Q\&A via constraint-respecting plan revisions. Systematic evaluation of 19 large language models reveals that high diagnostic accuracy often masks significant deficiencies in information-gathering efficiency and medication safety. These results underscore a critical gap between theoretical medical knowledge and clinical practice ability, establishing MedConsultBench as a rigorous foundation for aligning medical AI with the nuanced requirements of real-world clinical care.

</details>


### [442] [Empowering All-in-Loop Health Management of Spacecraft Power System in the Mega-Constellation Era via Human-AI Collaboration](https://arxiv.org/abs/2601.12667)
*Yi Di,Zhibin Zhao,Fujin Wang,Xue Liu,Jiafeng Tang,Jiaxin Ren,Zhi Zhai,Xuefeng Chen*

Main category: cs.AI

TL;DR: 本文针对卫星巨型星座时代的航天器电力系统健康管理挑战，提出AUC原则并开发了SpaceHMchat框架，实验证明其高效且开源了首个AIL HM数据集。


<details>
  <summary>Details</summary>
Motivation: 随着卫星数量的指数级增长，航天器电力系统的健康管理变得至关重要，传统方法难以适应大规模需求。

Method: 提出AUC原则并开发SpaceHMchat框架，这是一个开源的人机协作框架，覆盖工作状态识别、异常检测、故障定位和维护决策全流程。建立了硬件真实的故障注入实验平台及其仿真模型。

Result: SpaceHMchat在23项定量指标上表现优异，如工作状态逻辑推理结论准确率100%，异常检测工具调用成功率超99%，故障定位精度超90%，维护决策知识库搜索时间低于3分钟。并发布了首个AIL HM数据集。

Conclusion: 本文提出了AUC原则并开发了SpaceHMchat框架，成功应对了卫星巨型星座时代的航天器电力系统健康管理挑战，通过实验验证了其卓越性能，并发布了首个AIL HM数据集。

Abstract: It is foreseeable that the number of spacecraft will increase exponentially, ushering in an era dominated by satellite mega-constellations (SMC). This necessitates a focus on energy in space: spacecraft power systems (SPS), especially their health management (HM), given their role in power supply and high failure rates. Providing health management for dozens of SPS and for thousands of SPS represents two fundamentally different paradigms. Therefore, to adapt the health management in the SMC era, this work proposes a principle of aligning underlying capabilities (AUC principle) and develops SpaceHMchat, an open-source Human-AI collaboration (HAIC) framework for all-in-loop health management (AIL HM). SpaceHMchat serves across the entire loop of work condition recognition, anomaly detection, fault localization, and maintenance decision making, achieving goals such as conversational task completion, adaptive human-in-the-loop learning, personnel structure optimization, knowledge sharing, efficiency enhancement, as well as transparent reasoning and improved interpretability. Meanwhile, to validate this exploration, a hardware-realistic fault injection experimental platform is established, and its simulation model is built and open-sourced, both fully replicating the real SPS. The corresponding experimental results demonstrate that SpaceHMchat achieves excellent performance across 23 quantitative metrics, such as 100% conclusion accuracy in logical reasoning of work condition recognition, over 99% success rate in anomaly detection tool invocation, over 90% precision in fault localization, and knowledge base search time under 3 minutes in maintenance decision-making. Another contribution of this work is the release of the first-ever AIL HM dataset of SPS. This dataset contains four sub-datasets, involving 4 types of AIL HM sub-tasks, 17 types of faults, and over 700,000 timestamps.

</details>


### [443] [Logic-Guided Multistage Inference for Explainable Multidefendant Judgment Prediction](https://arxiv.org/abs/2601.12688)
*Xu Zhang,Qinghua Wang,Mengyang Zhao,Fang Wang,Cunquan Qu*

Main category: cs.AI

TL;DR: 论文提出MMSI框架，结合Transformer和量刑逻辑，有效区分多被告案件中的角色责任，提升智能司法系统的准确性。


<details>
  <summary>Details</summary>
Motivation: 多被告案件中，司法表述常常模糊被告角色，影响AI分析的准确性，因此需要一种能精确区分角色责任的方法。

Method: 采用预训练的Transformer编码器框架，结合定向掩码机制和比较数据构建策略，增强了模型对主犯和从犯责任区分的敏感性。

Result: 在自定义的IMLJP数据集上，MMSI框架在角色责任区分方面表现优异，显著优于基线模型。

Conclusion: 该论文提出了一种名为MMSI的框架，通过结合量刑逻辑和Transformer编码器，显著提高了多被告案件中角色责任的区分准确性，为智能司法系统提供了有力支持。

Abstract: Crime disrupts societal stability, making law essential for balance. In multidefendant cases, assigning responsibility is complex and challenges fairness, requiring precise role differentiation. However, judicial phrasing often obscures the roles of the defendants, hindering effective AI-driven analyses. To address this issue, we incorporate sentencing logic into a pretrained Transformer encoder framework to enhance the intelligent assistance in multidefendant cases while ensuring legal interpretability. Within this framework an oriented masking mechanism clarifies roles and a comparative data construction strategy improves the model's sensitivity to culpability distinctions between principals and accomplices. Predicted guilt labels are further incorporated into a regression model through broadcasting, consolidating crime descriptions and court views. Our proposed masked multistage inference (MMSI) framework, evaluated on the custom IMLJP dataset for intentional injury cases, achieves significant accuracy improvements, outperforming baselines in role-based culpability differentiation. This work offers a robust solution for enhancing intelligent judicial systems, with publicly code available.

</details>


### [444] [Neurosymbolic LoRA: Why and When to Tune Weights vs. Rewrite Prompts](https://arxiv.org/abs/2601.12711)
*Kevin Wang,Neel P. Bhatt,Cong Liu,Junbo Li,Runjin Chen,Yihan Xi,Timothy Barclay,Alvaro Velasquez,Ufuk Topcu,Zhangyang Wang*

Main category: cs.AI

TL;DR: 神经符号LoRA框架动态结合数值和符号更新策略，通过统一监控和奖励分类器优化微调，实验证明其优于纯数值或符号方法。


<details>
  <summary>Details</summary>
Motivation: 数值微调擅长注入新事实知识，而符号更新提供了无需重新训练的灵活控制和风格调整，两者的结合有望提升语言模型的适应性和性能。

Method: 提出了一个统一的监控信号和基于奖励的分类器，动态决定何时使用LoRA进行深度事实重构，何时应用TextGrad进行标记级编辑。

Result: 在多个LLM骨干上的广泛实验表明，神经符号LoRA始终优于纯数值或纯符号基线。

Conclusion: 神经符号LoRA框架通过动态结合数值和符号更新策略，展示了在语言模型微调中的卓越适应性和性能提升，强调了两种策略交替使用的重要性。

Abstract: Large language models (LLMs) can be adapted either through numerical updates that alter model parameters or symbolic manipulations that work on discrete prompts or logical constraints. While numerical fine-tuning excels at injecting new factual knowledge, symbolic updates offer flexible control of style and alignment without retraining. We introduce a neurosymbolic LoRA framework that dynamically combines these two complementary strategies. Specifically, we present a unified monitoring signal and a reward-based classifier to decide when to employ LoRA for deeper factual reconstruction and when to apply TextGrad for token-level edits. Our approach remains memory-efficient by offloading the symbolic transformations to an external LLM only when needed. Additionally, the refined prompts produced during symbolic editing serve as high-quality, reusable training data, an important benefit in data-scarce domains like mathematical reasoning. Extensive experiments across multiple LLM backbones show that neurosymbolic LoRA consistently outperforms purely numerical or purely symbolic baselines, demonstrating superior adaptability and improved performance. Our findings highlight the value of interleaving numerical and symbolic updates to unlock a new level of versatility in language model fine-tuning.

</details>


### [445] [Teaching Large Reasoning Models Effective Reflection](https://arxiv.org/abs/2601.12720)
*Hanbin Wang,Jingwei Song,Jinpeng Li,Qi Zhu,Fei Mi,Ganqu Cui,Yasheng Wang,Lifeng Shang*

Main category: cs.AI

TL;DR: 提出SCFT和RLERR方法，有效提升大型推理模型的反思质量和推理准确性。


<details>
  <summary>Details</summary>
Motivation: 解决大型推理模型中存在的表面反思问题，这些反思往往对原始答案改进有限且增加计算开销。

Method: 提出了自我批判微调（SCFT）和基于有效反思奖励的强化学习（RLERR）。SCFT通过自我生成的批判来增强模型的反思能力，RLERR则利用SCFT初始化的高质量反思构建奖励信号。

Result: 在两个挑战性基准测试AIME2024和AIME2025上，SCFT和RLERR显著提升了推理准确性和反思质量。

Conclusion: SCFT和RLERR显著提升了大型推理模型的推理准确性和反思质量，优于现有基线。

Abstract: Large Reasoning Models (LRMs) have recently shown impressive performance on complex reasoning tasks, often by engaging in self-reflective behaviors such as self-critique and backtracking. However, not all reflections are beneficial-many are superficial, offering little to no improvement over the original answer and incurring computation overhead. In this paper, we identify and address the problem of superficial reflection in LRMs. We first propose Self-Critique Fine-Tuning (SCFT), a training framework that enhances the model's reflective reasoning ability using only self-generated critiques. SCFT prompts models to critique their own outputs, filters high-quality critiques through rejection sampling, and fine-tunes the model using a critique-based objective. Building on this strong foundation, we further introduce Reinforcement Learning with Effective Reflection Rewards (RLERR). RLERR leverages the high-quality reflections initialized by SCFT to construct reward signals, guiding the model to internalize the self-correction process via reinforcement learning. Experiments on two challenging benchmarks, AIME2024 and AIME2025, show that SCFT and RLERR significantly improve both reasoning accuracy and reflection quality, outperforming state-of-the-art baselines. All data and codes are available at https://github.com/wanghanbinpanda/SCFT.

</details>


### [446] [VIRO: Robust and Efficient Neuro-Symbolic Reasoning with Verification for Referring Expression Comprehension](https://arxiv.org/abs/2601.12781)
*Hyejin Park,Junhyuk Kwon,Suha Kwak,Jungseul Ok*

Main category: cs.AI

TL;DR: VIRO框架通过操作级验证器增强REC任务的鲁棒性，解决了级联错误问题，实现了高准确率、高效计算和低失败率。


<details>
  <summary>Details</summary>
Motivation: 现有的神经符号REC方法假设中间推理步骤准确，导致级联错误（如错误检测和无效关系传播），即使在图像中无目标时也会产生高置信度误报。VIRO旨在解决这一问题。

Method: 引入了Verification-Integrated Reasoning Operators (VIRO)框架，通过在推理步骤中嵌入轻量级操作级验证器，确保每一步的输出（如对象存在性或空间关系）经过验证。

Result: VIRO在目标存在和无目标场景下达到61.1%的平衡准确率，在真实世界第一人称数据上表现出泛化能力，计算吞吐量高效，程序失败率低于0.3%。

Conclusion: VIRO框架通过嵌入轻量级操作级验证器，显著提升了REC任务的鲁棒性和准确性，实现了最先进的性能表现，并在计算效率、可靠性和可扩展性方面展现出优势。

Abstract: Referring Expression Comprehension (REC) aims to localize the image region corresponding to a natural-language query. Recent neuro-symbolic REC approaches leverage large language models (LLMs) and vision-language models (VLMs) to perform compositional reasoning, decomposing queries 4 structured programs and executing them step-by-step. While such approaches achieve interpretable reasoning and strong zero-shot generalization, they assume that intermediate reasoning steps are accurate. However, this assumption causes cascading errors: false detections and invalid relations propagate through the reasoning chain, yielding high-confidence false positives even when no target is present in the image. To address this limitation, we introduce Verification-Integrated Reasoning Operators (VIRO), a neuro-symbolic framework that embeds lightweight operator-level verifiers within reasoning steps. Each operator executes and validates its output, such as object existence or spatial relationship, thereby allowing the system to robustly handle no-target cases when verification conditions are not met. Our framework achieves state-of-the-art performance, reaching 61.1% balanced accuracy across target-present and no-target settings, and demonstrates generalization to real-world egocentric data. Furthermore, VIRO shows superior computational efficiency in terms of throughput, high reliability with a program failure rate of less than 0.3%, and scalability through decoupled program generation from execution.

</details>


### [447] [SL-CBM: Enhancing Concept Bottleneck Models with Semantic Locality for Better Interpretability](https://arxiv.org/abs/2601.12804)
*Hanwei Zhang,Luo Cheng,Rui Wen,Yang Zhang,Lijun Zhang,Holger Hermanns*

Main category: cs.AI

TL;DR: SL-CBM是一种新型概念瓶颈模型，通过语义局部性增强显著图的空间一致性，提升了解释质量和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有概念瓶颈模型（CBMs）在局部忠实性上表现不佳，无法将概念与有意义的图像区域空间对齐，限制了其可解释性和可靠性。

Method: SL-CBM通过整合1x1卷积层和交叉注意力机制，增强概念、图像区域和最终预测之间的对齐，生成空间一致的概念和类别级显著图。

Result: 实验证明，SL-CBM显著提升了局部忠实性、解释质量和干预效果，同时保持了竞争力的分类准确率。

Conclusion: SL-CBM通过结合语义局部性，显著提升了概念瓶颈模型在局部忠实性、解释质量和干预效果上的表现，同时保持了竞争力的分类准确率，为可解释和可信赖的概念模型设定了新标准。

Abstract: Explainable AI (XAI) is crucial for building transparent and trustworthy machine learning systems, especially in high-stakes domains. Concept Bottleneck Models (CBMs) have emerged as a promising ante-hoc approach that provides interpretable, concept-level explanations by explicitly modeling human-understandable concepts. However, existing CBMs often suffer from poor locality faithfulness, failing to spatially align concepts with meaningful image regions, which limits their interpretability and reliability. In this work, we propose SL-CBM (CBM with Semantic Locality), a novel extension that enforces locality faithfulness by generating spatially coherent saliency maps at both concept and class levels. SL-CBM integrates a 1x1 convolutional layer with a cross-attention mechanism to enhance alignment between concepts, image regions, and final predictions. Unlike prior methods, SL-CBM produces faithful saliency maps inherently tied to the model's internal reasoning, facilitating more effective debugging and intervention. Extensive experiments on image datasets demonstrate that SL-CBM substantially improves locality faithfulness, explanation quality, and intervention efficacy while maintaining competitive classification accuracy. Our ablation studies highlight the importance of contrastive and entropy-based regularization for balancing accuracy, sparsity, and faithfulness. Overall, SL-CBM bridges the gap between concept-based reasoning and spatial explainability, setting a new standard for interpretable and trustworthy concept-based models.

</details>


### [448] [MirrorGuard: Toward Secure Computer-Use Agents via Simulation-to-Real Reasoning Correction](https://arxiv.org/abs/2601.12822)
*Wenqi Zhang,Yulin Shen,Changyue Jiang,Jiarun Dai,Geng Hong,Xudong Pan*

Main category: cs.AI

TL;DR: MirrorGuard通过模拟训练提升CUA安全性，显著降低不安全率并保持低误拒率。


<details>
  <summary>Details</summary>
Motivation: 大型基础模型集成到CUA中带来严重安全风险，现有防御方法如基于检测的阻断会提前终止任务，降低代理效用。

Method: 提出MirrorGuard，一种即插即用的防御框架，通过基于神经符号的模拟管道生成高风险GUI交互轨迹，无需执行真实操作即可捕获不安全推理模式。

Result: 在真实测试中，MirrorGuard显著降低了安全风险，例如在ByteDance UI-TARS系统上，不安全率从66.5%降至13.0%，且误拒率（FRR）极低。

Conclusion: MirrorGuard通过模拟训练显著提升了计算机使用代理（CUA）的安全性，同时保持了其基本实用性，证明了基于模拟的防御方法在实际应用中的有效性。

Abstract: Large foundation models are integrated into Computer Use Agents (CUAs), enabling autonomous interaction with operating systems through graphical user interfaces (GUIs) to perform complex tasks. This autonomy introduces serious security risks: malicious instructions or visual prompt injections can trigger unsafe reasoning and cause harmful system-level actions. Existing defenses, such as detection-based blocking, prevent damage but often abort tasks prematurely, reducing agent utility. In this paper, we present MirrorGuard, a plug-and-play defense framework that uses simulation-based training to improve CUA security in the real world. To reduce the cost of large-scale training in operating systems, we propose a novel neural-symbolic simulation pipeline, which generates realistic, high-risk GUI interaction trajectories entirely in a text-based simulated environment, which captures unsafe reasoning patterns and potential system hazards without executing real operations. In the simulation environment, MirrorGuard learns to intercept and rectify insecure reasoning chains of CUAs before they produce and execute unsafe actions. In real-world testing, extensive evaluations across diverse benchmarks and CUA architectures show that MirrorGuard significantly mitigates security risks. For instance, on the ByteDance UI-TARS system, it reduces the unsafe rate from 66.5% to 13.0% while maintaining a marginal false refusal rate (FRR). In contrast, the state-of-the-art GuardAgent only achieves a reduction to 53.9% and suffers from a 15.4% higher FRR. Our work proves that simulation-derived defenses can provide robust, real-world protection while maintaining the fundamental utility of the agent. Our code and model are publicly available at https://bmz-q-q.github.io/MirrorGuard/.

</details>


### [449] [SCULPT: Constraint-Guided Pruned MCTS that Carves Efficient Paths for Mathematical Reasoning](https://arxiv.org/abs/2601.12842)
*Qitong Fang,Haotian Li,Xu Wang*

Main category: cs.AI

TL;DR: SCULPT通过领域感知约束引导MCTS，提升LLM的推理路径合理性，在多个数据集上表现稳定且高效。


<details>
  <summary>Details</summary>
Motivation: 当前的代理工作流搜索策略依赖随机探索，常遍历不合理的分支，因为现有流程从通用提示或弱领域先验的学习策略中采样候选步骤，导致对操作、单位和格式的近随机遍历。

Method: 本文提出了SCULPT，一种用于蒙特卡洛树搜索（MCTS）的约束引导方法，将领域感知评分集成到选择、扩展、模拟和反向传播中。

Result: 在匹配的LLM配置下，SCULPT在多个数据集上实现了稳定的改进；GPT-5.2的额外结果评估了执行器的可转移性和前沿推理模型的性能。

Conclusion: 领域感知约束可以在保持效率和推理稳定性的同时提高准确性。

Abstract: Automated agent workflows can enhance the problem-solving ability of large language models (LLMs), but common search strategies rely on stochastic exploration and often traverse implausible branches. This occurs because current pipelines sample candidate steps from generic prompts or learned policies with weak domain priors, yielding near-random walks over operators, units, and formats. To promote ordered exploration, this paper introduces SCULPT, a constraint-guided approach for Monte Carlo Tree Search (MCTS) that integrates domain-aware scoring into selection, expansion, simulation, and backpropagation. SCULPT scores and prunes actions using a combination of symbolic checks (dimensional consistency, type compatibility, magnitude sanity, depth control, and diversity) and structural pattern guidance, thereby steering the search toward plausible reasoning paths. Under matched LLM configurations, SCULPT yields stable improvements on multiple datasets; additional results with GPT-5.2 assess executor transferability and performance on frontier reasoning models. Overall, domain-aware constraints can improve accuracy while maintaining efficiency and reasoning stability.

</details>


### [450] [Mining Citywide Dengue Spread Patterns in Singapore Through Hotspot Dynamics from Open Web Data](https://arxiv.org/abs/2601.12856)
*Liping Huang,Gaoxi Xiao,Stefan Ma,Hechang Chen,Shisong Tang,Flora Salim*

Main category: cs.AI

TL;DR: 研究通过挖掘登革热病例数据揭示城市间潜在传播链，预测热点并验证传播模式，为公共卫生提供低成本工具。


<details>
  <summary>Details</summary>
Motivation: 登革热在热带城市如新加坡持续构成公共卫生挑战，需要预测传播风险以主动部署干预措施。

Method: 研究提出了一种新颖框架，通过梯度下降优化隐藏的传播链，并利用这些链不仅预测热点状态，还验证传播模式的一致性。

Result: 在新加坡2013-2018和2020年的案例研究中，四周的热点历史足以实现平均F-score 0.79，学习到的传播链与通勤流高度一致。

Conclusion: 该研究通过挖掘公开可用的登革热病例数据，揭示并利用了城市区域间的潜在传播链，为公共卫生规划和早期干预提供了可扩展、低成本的工具。

Abstract: Dengue, a mosquito-borne disease, continues to pose a persistent public health challenge in urban areas, particularly in tropical regions such as Singapore. Effective and affordable control requires anticipating where transmission risks are likely to emerge so that interventions can be deployed proactively rather than reactively. This study introduces a novel framework that uncovers and exploits latent transmission links between urban regions, mined directly from publicly available dengue case data. Instead of treating cases as isolated reports, we model how hotspot formation in one area is influenced by epidemic dynamics in neighboring regions. While mosquito movement is highly localized, long-distance transmission is often driven by human mobility, and in our case study, the learned network aligns closely with commuting flows, providing an interpretable explanation for citywide spread. These hidden links are optimized through gradient descent and used not only to forecast hotspot status but also to verify the consistency of spreading patterns, by examining the stability of the inferred network across consecutive weeks. Case studies on Singapore during 2013-2018 and 2020 show that four weeks of hotspot history are sufficient to achieve an average F-score of 0.79. Importantly, the learned transmission links align with commuting flows, highlighting the interpretable interplay between hidden epidemic spread and human mobility. By shifting from simply reporting dengue cases to mining and validating hidden spreading dynamics, this work transforms open web-based case data into a predictive and explanatory resource. The proposed framework advances epidemic modeling while providing a scalable, low-cost tool for public health planning, early intervention, and urban resilience.

</details>


### [451] [Human Emotion Verification by Action Languages via Answer Set Programming](https://arxiv.org/abs/2601.12912)
*Andreas Brännström,Juan Carlos Nieves*

Main category: cs.AI

TL;DR: The paper introduces C-MT, an action language built on ASP and transition systems, to model mental state evolution. It extends C-MT with new rules for controlled behaviors and evaluates mental state dynamics using transition constraints, applied to emotion verification.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the need for controlled agent behaviors and to restrict unwanted mental side-effects of actions by formalizing mental states and their evolution based on psychological theories like the Appraisal Theory of Emotion.

Method: The method involves extending the C-MT language with a novel causal rule (forbids to cause) and specialized expressions for mental state dynamics, translating principles of mental change into transition constraints and properties of invariance, and evaluating these using transition systems.

Result: The result is a framework that enables controlled reasoning about the dynamic evolution of human mental states and supports the comparison of different dynamics of change by analyzing trajectories adhering to various psychological principles.

Conclusion: The paper concludes by applying the C-MT language to design models for emotion verification, demonstrating its practical utility in controlled reasoning about mental state evolution.

Abstract: In this paper, we introduce the action language C-MT (Mind Transition Language). It is built on top of answer set programming (ASP) and transition systems to represent how human mental states evolve in response to sequences of observable actions. Drawing on well-established psychological theories, such as the Appraisal Theory of Emotion, we formalize mental states, such as emotions, as multi-dimensional configurations. With the objective to address the need for controlled agent behaviors and to restrict unwanted mental side-effects of actions, we extend the language with a novel causal rule, forbids to cause, along with expressions specialized for mental state dynamics, which enables the modeling of principles for valid transitions between mental states. These principles of mental change are translated into transition constraints, and properties of invariance, which are rigorously evaluated using transition systems in terms of so-called trajectories. This enables controlled reasoning about the dynamic evolution of human mental states. Furthermore, the framework supports the comparison of different dynamics of change by analyzing trajectories that adhere to different psychological principles. We apply the action language to design models for emotion verification. Under consideration in Theory and Practice of Logic Programming (TPLP).

</details>


### [452] [Actionable Interpretability Must Be Defined in Terms of Symmetries](https://arxiv.org/abs/2601.12913)
*Pietro Barbiero,Mateo Espinosa Zarlenga,Francesco Giannini,Alberto Termine,Filippo Bonchi,Mateja Jamnik,Giuseppe Marra*

Main category: cs.AI

TL;DR: 论文指出AI可解释性研究定义不当，提出基于对称性的新定义框架，假设四种对称性足以统一解释性推理。


<details>
  <summary>Details</summary>
Motivation: 现有的人工智能可解释性定义缺乏可操作性，无法为具体建模和推理规则提供形式化原则，因此需要一种新的定义方式。

Method: 通过引入对称性概念，论文提出了一种新的可解释性定义框架，并假设四种对称性足以覆盖可解释性的核心方面。

Result: 论文提出了基于对称性的可解释性定义框架，并展示了其如何统一解释性推理的不同形式。

Conclusion: 该论文认为，人工智能中的可解释性研究从根本上来说是定义不当的，因为现有的可解释性定义缺乏可操作性。作者提出，一个可操作的可解释性定义应基于对称性，并假设四种对称性足以（i）激发核心可解释性属性，（ii）刻画可解释模型的类别，（iii）推导出可解释推理的统一形式（如对齐、干预和反事实）作为一种贝叶斯逆问题。

Abstract: This paper argues that interpretability research in Artificial Intelligence is fundamentally ill-posed as existing definitions of interpretability are not *actionable*: they fail to provide formal principles from which concrete modelling and inferential rules can be derived. We posit that for a definition of interpretability to be actionable, it must be given in terms of *symmetries*. We hypothesise that four symmetries suffice to (i) motivate core interpretability properties, (ii) characterize the class of interpretable models, and (iii) derive a unified formulation of interpretable inference (e.g., alignment, interventions, and counterfactuals) as a form of Bayesian inversion.

</details>


### [453] [MagicGUI-RMS: A Multi-Agent Reward Model System for Self-Evolving GUI Agents via Automated Feedback Reflux](https://arxiv.org/abs/2601.13060)
*Zecheng Li,Zhihui Cao,Wenke Huang,Yudong Zhang,Keying Qi,Rui Wang,Zeyu Zheng,Jian Zhao,Hao Zhu,Hengxin Wu,Yuran Wang,Guitao Fan,Guokun Wu,Yicong Liu,Zhilin Gao,Haikun Xu,He Yang,Minqi Xiang,Xingyu Liu,Zuojian Wang*

Main category: cs.AI

TL;DR: MagicGUI-RMS 是一个多代理奖励模型系统，通过自动化评估和反馈机制提升 GUI 代理的性能，解决了现有方法在扩展性和适应性上的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前 GUI 代理的评估和训练数据生成依赖人工标注或静态规则验证，限制了扩展性和动态环境中的适应性。MagicGUI-RMS 旨在解决这些问题，实现自动化评估和高质量数据生成。

Method: MagicGUI-RMS 结合了领域特定奖励模型（DS-RM）和通用奖励模型（GP-RM），支持细粒度动作评估和跨异构 GUI 任务的泛化能力。此外，系统设计了一个结构化数据构建流程，自动生成平衡且多样的奖励数据集。

Result: 实验表明，MagicGUI-RMS 显著提升了任务准确性和行为鲁棒性，同时降低了标注成本。

Conclusion: MagicGUI-RMS 被证明是一个基于奖励的自适应系统，能够有效提升 GUI 代理的任务准确性和行为鲁棒性，为构建自我改进的 GUI 代理提供了可靠基础。

Abstract: Graphical user interface (GUI) agents are rapidly progressing toward autonomous interaction and reliable task execution across diverse applications. However, two central challenges remain unresolved: automating the evaluation of agent trajectories and generating high-quality training data at scale to enable continual improvement. Existing approaches often depend on manual annotation or static rule-based verification, which restricts scalability and limits adaptability in dynamic environments. We present MagicGUI-RMS, a multi-agent reward model system that delivers adaptive trajectory evaluation, corrective feedback, and self-evolving learning capabilities. MagicGUI-RMS integrates a Domain-Specific Reward Model (DS-RM) with a General-Purpose Reward Model (GP-RM), enabling fine-grained action assessment and robust generalization across heterogeneous GUI tasks. To support reward learning at scale, we design a structured data construction pipeline that automatically produces balanced and diverse reward datasets, effectively reducing annotation costs while maintaining sample fidelity. During execution, the reward model system identifies erroneous actions, proposes refined alternatives, and continuously enhances agent behavior through an automated data-reflux mechanism. Extensive experiments demonstrate that MagicGUI-RMS yields substantial gains in task accuracy, behavioral robustness. These results establish MagicGUI-RMS as a principled and effective foundation for building self-improving GUI agents driven by reward-based adaptation.

</details>


### [454] [Responsible AI for General-Purpose Systems: Overview, Challenges, and A Path Forward](https://arxiv.org/abs/2601.13122)
*Gourab K Patro,Himanshi Agrawal,Himanshu Gharat,Supriya Panigrahi,Nim Sherpa,Vishal Vaddina,Dagnachew Birru*

Main category: cs.AI

TL;DR: 现代通用AI存在高风险，需通过C2V2框架重新设计以满足负责任AI要求。


<details>
  <summary>Details</summary>
Motivation: 现代通用AI系统虽然功能强大，但其输出存在幻觉、毒性和刻板印象等风险，导致不可信。作者旨在探讨如何重新思考RAI方法以应对通用AI的高自由度输出问题。

Method: 本文回顾了现代通用AI的八大RAI原则（公平性、隐私性、可解释性、鲁棒性、安全性、真实性、治理和可持续性），并与传统任务专用AI进行比较，提出了C2V2框架。

Result: 研究发现通用AI因输出自由度（DoFo）高而风险更大，提出C2V2框架作为未来通用AI系统满足RAI要求的解决方案。

Conclusion: 作者认为，通过沿C2V2维度（控制、一致性、价值、真实性）建模应用或领域相关的RAI要求，并采用系统设计方法结合多种技术，可以实现负责任通用AI的目标。

Abstract: Modern general-purpose AI systems made using large language and vision models, are capable of performing a range of tasks like writing text articles, generating and debugging codes, querying databases, and translating from one language to another, which has made them quite popular across industries. However, there are risks like hallucinations, toxicity, and stereotypes in their output that make them untrustworthy. We review various risks and vulnerabilities of modern general-purpose AI along eight widely accepted responsible AI (RAI) principles (fairness, privacy, explainability, robustness, safety, truthfulness, governance, and sustainability) and compare how they are non-existent or less severe and easily mitigable in traditional task-specific counterparts. We argue that this is due to the non-deterministically high Degree of Freedom in output (DoFo) of general-purpose AI (unlike the deterministically constant or low DoFo of traditional task-specific AI systems), and there is a need to rethink our approach to RAI for general-purpose AI. Following this, we derive C2V2 (Control, Consistency, Value, Veracity) desiderata to meet the RAI requirements for future general-purpose AI systems, and discuss how recent efforts in AI alignment, retrieval-augmented generation, reasoning enhancements, etc. fare along one or more of the desiderata. We believe that the goal of developing responsible general-purpose AI can be achieved by formally modeling application- or domain-dependent RAI requirements along C2V2 dimensions, and taking a system design approach to suitably combine various techniques to meet the desiderata.

</details>


### [455] [Prompt Injection Mitigation with Agentic AI, Nested Learning, and AI Sustainability via Semantic Caching](https://arxiv.org/abs/2601.13186)
*Diego Gosmar,Deborah A. Dahl*

Main category: cs.AI

TL;DR: 本文扩展了TIVS框架，提出TIVS-O，结合语义缓存和OSR，在多智能体环境中实现了安全性和透明性的最优权衡，同时显著降低了计算成本和环境影响。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在多智能体环境中的提示注入问题，特别是在中间输出可能传播或放大恶意指令的情况下。

Method: 本文提出了一种结合代理管道和连续记忆系统的方法，利用语义相似性缓存和301个合成生成的攻击提示进行评估，并通过五个关键性能指标进行安全分析。

Result: 实验结果显示，系统实现了零高风险漏洞的安全响应，语义缓存显著减少了41.6%的LLM调用，并降低了延迟、能耗和碳排放。

Conclusion: 该研究表明，通过结合语义相似性缓存和可观察性评分比（OSR）的TIVS-O框架，能够在多智能体架构中实现安全性和透明性的最优权衡，同时显著降低计算成本和环境影响。

Abstract: Prompt injection remains a central obstacle to the safe deployment of large language models, particularly in multi-agent settings where intermediate outputs can propagate or amplify malicious instructions. Building on earlier work that introduced a four-metric Total Injection Vulnerability Score (TIVS), this paper extends the evaluation framework with semantic similarity-based caching and a fifth metric (Observability Score Ratio) to yield TIVS-O, investigating how defence effectiveness interacts with transparency in a HOPE-inspired Nested Learning architecture. The proposed system combines an agentic pipeline with Continuum Memory Systems that implement semantic similarity-based caching across 301 synthetically generated injection-focused prompts drawn from ten attack families, while a fourth agent performs comprehensive security analysis using five key performance indicators. In addition to traditional injection metrics, OSR quantifies the richness and clarity of security-relevant reasoning exposed by each agent, enabling an explicit analysis of trade-offs between strict mitigation and auditability. Experiments show that the system achieves secure responses with zero high-risk breaches, while semantic caching delivers substantial computational savings, achieving a 41.6% reduction in LLM calls and corresponding decreases in latency, energy consumption, and carbon emissions. Five TIVS-O configurations reveal optimal trade-offs between mitigation strictness and forensic transparency. These results indicate that observability-aware evaluation can reveal non-monotonic effects within multi-agent pipelines and that memory-augmented agents can jointly maximize security robustness, real-time performance, operational cost savings, and environmental sustainability without modifying underlying model weights, providing a production-ready pathway for secure and green LLM deployments.

</details>


### [456] [Real-Time Deadlines Reveal Temporal Awareness Failures in LLM Strategic Dialogues](https://arxiv.org/abs/2601.13206)
*Neil K. R. Sehgal,Sharath Chandra Guntuku,Lyle Ungar*

Main category: cs.AI

TL;DR: LLMs在实时截止时间下表现不佳，但在回合制限制下表现良好，揭示其时间跟踪而非策略推理的缺陷。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs在实时截止时间约束下的时间意识行为，因为现有架构和评估协议很少测试时间感知能力。

Method: 通过模拟严格截止时间下的配对代理谈判，比较了全局时间限制和时间感知条件下的表现。

Result: 时间感知条件下，交易达成率显著提高（32% vs. 4%），且报价接受率高出六倍；但在回合制限制下，LLMs表现接近完美（≥95%）。

Conclusion: LLMs在时间敏感的应用中表现出系统性的时间意识不足，这限制了其在许多实时场景中的部署。

Abstract: Large Language Models (LLMs) generate text token-by-token in discrete time, yet real-world communication, from therapy sessions to business negotiations, critically depends on continuous time constraints. Current LLM architectures and evaluation protocols rarely test for temporal awareness under real-time deadlines. We use simulated negotiations between paired agents under strict deadlines to investigate how LLMs adjust their behavior in time-sensitive settings. In a control condition, agents know only the global time limit. In a time-aware condition, they receive remaining-time updates at each turn. Deal closure rates are substantially higher (32\% vs. 4\% for GPT-5.1) and offer acceptances are sixfold higher in the time-aware condition than in the control, suggesting LLMs struggle to internally track elapsed time. However, the same LLMs achieve near-perfect deal closure rates ($\geq$95\%) under turn-based limits, revealing the failure is in temporal tracking rather than strategic reasoning. These effects replicate across negotiation scenarios and models, illustrating a systematic lack of LLM time awareness that will constrain LLM deployment in many time-sensitive applications.

</details>


### [457] [RAG: A Random-Forest-Based Generative Design Framework for Uncertainty-Aware Design of Metamaterials with Complex Functional Response Requirements](https://arxiv.org/abs/2601.13233)
*Bolin Chen,Dex Doksoo Lee,Wei "Wayne'' Chen,Wei Chen*

Main category: cs.AI

TL;DR: RAG是一种基于随机森林的生成方法，用于高效逆设计高维功能响应，解决了现有方法的挑战，并在超材料设计中验证了其数据高效性和可信赖性。


<details>
  <summary>Details</summary>
Motivation: 解决现有设计方法在功能响应逆设计中的挑战，如高维性、设计要求的复杂性、可行解的不存在或非唯一性，以及生成设计方法的数据需求大、处理要求启发式且可能生成不可行设计的问题。

Method: RAG利用随机森林的小数据兼容性，实现了高维功能响应的数据高效预测。在逆设计过程中，框架通过集成估计可能性，量化生成设计的可信度，并反映不同需求的相对难度。通过从条件可能性中采样，解决了一对多映射问题。

Result: RAG在声学超材料和机械超材料的设计中展示了其数据高效性，分别使用了500和1057个样本。与神经网络相比，RAG在公共机械超材料数据集上的表现更优。

Conclusion: RAG框架为涉及功能响应、昂贵模拟和复杂设计要求的逆设计提供了一种轻量级、可信赖的路径，不仅适用于超材料。

Abstract: Metamaterials design for advanced functionality often entails the inverse design on nonlinear and condition-dependent responses (e.g., stress-strain relation and dispersion relation), which are described by continuous functions. Most existing design methods focus on vector-valued responses (e.g., Young's modulus and bandgap width), while the inverse design of functional responses remains challenging due to their high-dimensionality, the complexity of accommodating design requirements in inverse-design frameworks, and non-existence or non-uniqueness of feasible solutions. Although generative design approaches have shown promise, they are often data-hungry, handle design requirements heuristically, and may generate infeasible designs without uncertainty quantification. To address these challenges, we introduce a RAndom-forest-based Generative approach (RAG). By leveraging the small-data compatibility of random forests, RAG enables data-efficient predictions of high-dimensional functional responses. During the inverse design, the framework estimates the likelihood through the ensemble which quantifies the trustworthiness of generated designs while reflecting the relative difficulty across different requirements. The one-to-many mapping is addressed through single-shot design generation by sampling from the conditional likelihood. We demonstrate RAG on: 1) acoustic metamaterials with prescribed partial passbands/stopbands, and 2) mechanical metamaterials with targeted snap-through responses, using 500 and 1057 samples, respectively. Its data-efficiency is benchmarked against neural networks on a public mechanical metamaterial dataset with nonlinear stress-strain relations. Our framework provides a lightweight, trustworthy pathway to inverse design involving functional responses, expensive simulations, and complex design requirements, beyond metamaterials.

</details>


### [458] [CURE-Med: Curriculum-Informed Reinforcement Learning for Multilingual Medical Reasoning](https://arxiv.org/abs/2601.13262)
*Eric Onyame,Akash Ghosh,Subhadip Baidya,Sriparna Saha,Xiuying Chen,Chirag Agarwal*

Main category: cs.AI

TL;DR: CURE-MED通过课程强化学习框架提升多语言医疗推理性能，在13种语言中显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在多语言医疗推理中的不可靠性问题，以促进其在多语言医疗环境中的部署。

Method: 提出了CURE-MED框架，结合代码切换感知的监督微调和群体相对策略优化，以联合提升逻辑正确性和语言稳定性。

Result: 在13种语言中，CURE-MED在7B和32B参数规模下分别实现了85.21%/54.35%和94.96%/70.04%的语言一致性和逻辑正确性。

Conclusion: CURE-MED框架通过课程强化的强化学习方法，显著提升了多语言医疗推理的可靠性和公平性，特别是在低资源语言中表现优异。

Abstract: While large language models (LLMs) have shown to perform well on monolingual mathematical and commonsense reasoning, they remain unreliable for multilingual medical reasoning applications, hindering their deployment in multilingual healthcare settings. We address this by first introducing CUREMED-BENCH, a high-quality multilingual medical reasoning dataset with open-ended reasoning queries with a single verifiable answer, spanning thirteen languages, including underrepresented languages such as Amharic, Yoruba, and Swahili. Building on this dataset, we propose CURE-MED, a curriculum-informed reinforcement learning framework that integrates code-switching-aware supervised fine-tuning and Group Relative Policy Optimization to jointly improve logical correctness and language stability. Across thirteen languages, our approach consistently outperforms strong baselines and scales effectively, achieving 85.21% language consistency and 54.35% logical correctness at 7B parameters, and 94.96% language consistency and 70.04% logical correctness at 32B parameters. These results support reliable and equitable multilingual medical reasoning in LLMs. The code and dataset are available at https://cure-med.github.io/

</details>


### [459] [Improving the Safety and Trustworthiness of Medical AI via Multi-Agent Evaluation Loops](https://arxiv.org/abs/2601.13268)
*Zainab Ghafoor,Md Shafiqul Islam,Koushik Howlader,Md Rasel Khondokar,Tanusree Bhattacharjee,Sayantan Chakraborty,Adrito Roy,Ushashi Bhattacharjee,Tirtho Roy*

Main category: cs.AI

TL;DR: 提出多代理框架提升医疗LLMs安全性，结合生成与评估模型，显著减少伦理违规和风险。


<details>
  <summary>Details</summary>
Motivation: 确保医疗领域大型语言模型（LLMs）的伦理完整性和安全性合规性，以促进其临床部署。

Method: 结合DeepSeek R1和Med-PaLM两种生成模型，以及LLaMA 3.1和Phi-4两种评估代理，通过AMA医学伦理原则和SRA-5协议评估响应。

Result: 迭代多代理循环实现了89%的伦理违规减少和92%的风险降级率，DeepSeek R1收敛更快，Med-PaLM在隐私敏感场景中表现更优。

Conclusion: 本研究提出了一种可扩展、符合监管要求且成本效益高的范式，用于管理医疗AI的安全性。

Abstract: Large Language Models (LLMs) are increasingly applied in healthcare, yet ensuring their ethical integrity and safety compliance remains a major barrier to clinical deployment. This work introduces a multi-agent refinement framework designed to enhance the safety and reliability of medical LLMs through structured, iterative alignment. Our system combines two generative models - DeepSeek R1 and Med-PaLM - with two evaluation agents, LLaMA 3.1 and Phi-4, which assess responses using the American Medical Association's (AMA) Principles of Medical Ethics and a five-tier Safety Risk Assessment (SRA-5) protocol. We evaluate performance across 900 clinically diverse queries spanning nine ethical domains, measuring convergence efficiency, ethical violation reduction, and domain-specific risk behavior. Results demonstrate that DeepSeek R1 achieves faster convergence (mean 2.34 vs. 2.67 iterations), while Med-PaLM shows superior handling of privacy-sensitive scenarios. The iterative multi-agent loop achieved an 89% reduction in ethical violations and a 92% risk downgrade rate, underscoring the effectiveness of our approach. This study presents a scalable, regulator-aligned, and cost-efficient paradigm for governing medical AI safety.

</details>


### [460] [PepEDiff: Zero-Shot Peptide Binder Design via Protein Embedding Diffusion](https://arxiv.org/abs/2601.13327)
*Po-Yu Liang,Tobo Duran,Jun Bai*

Main category: cs.AI

TL;DR: PepEDiff是一种新型肽结合剂生成器，通过潜在空间直接生成序列，无需结构预测，提高了多样性和性能。


<details>
  <summary>Details</summary>
Motivation: 现有肽结合剂生成方法过度依赖中间结构预测，增加了复杂性并限制了序列多样性，PepEDiff旨在解决这一问题。

Method: 通过预训练蛋白质嵌入模型在连续潜在空间中直接生成结合序列，结合潜在空间探索和扩散采样，避免依赖预测结构。

Result: 在TIGIT等挑战性目标上，PepEDiff表现优于现有最先进方法。

Conclusion: PepEDiff 作为一种无需依赖结构预测的零射击肽结合剂设计框架，展现出在挑战性目标（如TIGIT）上的优越性能，具有广泛应用的潜力。

Abstract: We present PepEDiff, a novel peptide binder generator that designs binding sequences given a target receptor protein sequence and its pocket residues. Peptide binder generation is critical in therapeutic and biochemical applications, yet many existing methods rely heavily on intermediate structure prediction, adding complexity and limiting sequence diversity. Our approach departs from this paradigm by generating binder sequences directly in a continuous latent space derived from a pretrained protein embedding model, without relying on predicted structures, thereby improving structural and sequence diversity. To encourage the model to capture binding-relevant features rather than memorizing known sequences, we perform latent-space exploration and diffusion-based sampling, enabling the generation of peptides beyond the limited distribution of known binders. This zero-shot generative strategy leverages the global protein embedding manifold as a semantic prior, allowing the model to propose novel peptide sequences in previously unseen regions of the protein space. We evaluate PepEDiff on TIGIT, a challenging target with a large, flat protein-protein interaction interface that lacks a druggable pocket. Despite its simplicity, our method outperforms state-of-the-art approaches across benchmark tests and in the TIGIT case study, demonstrating its potential as a general, structure-free framework for zero-shot peptide binder design. The code for this research is available at GitHub: https://github.com/LabJunBMI/PepEDiff-An-Peptide-binder-Embedding-Diffusion-Model

</details>


### [461] [The Geometry of Thought: How Scale Restructures Reasoning In Large Language Models](https://arxiv.org/abs/2601.13358)
*Samuel Cyrenius Anderson*

Main category: cs.AI

TL;DR: 规模扩展重构推理能力，法律推理结晶化，科学数学推理保持液态，代码推理形成格点结构，神经推理操作符有效预测推理终点。


<details>
  <summary>Details</summary>
Motivation: 探讨神经网络规模扩展对推理能力的影响，揭示推理能力的重构而非均匀提升的现象，并提出加速推理的新方法。

Method: 分析了25,000+条思维链轨迹，覆盖法律、科学、代码和数学四个领域及两种规模（8B和70B参数），通过几何分析和学习映射方法研究推理行为。

Result: 发现法律推理呈现结晶化现象（维度减少45%，轨迹对齐增加31%），科学和数学推理保持液态（几何不变），代码推理形成离散格点结构。神经推理操作符在法律推理中达到63.6%准确率，并发现跨领域的振荡特征。

Conclusion: 研究发现，神经网络的规模扩展并不均匀提升推理能力，而是重构了推理方式。通过分析不同领域和规模的思维链轨迹，揭示了领域特定的相变现象，并提出了神经推理操作符的概念，为推理加速提供了理论依据。

Abstract: Scale does not uniformly improve reasoning - it restructures it. Analyzing 25,000+ chain-of-thought trajectories across four domains (Law, Science, Code, Math) and two scales (8B, 70B parameters), we discover that neural scaling laws trigger domain-specific phase transitions rather than uniform capability gains. Legal reasoning undergoes Crystallization: 45% collapse in representational dimensionality (d95: 501 -> 274), 31% increase in trajectory alignment, and 10x manifold untangling. Scientific and mathematical reasoning remain Liquid - geometrically invariant despite 9x parameter increase. Code reasoning forms a discrete Lattice of strategic modes (silhouette: 0.13 -> 0.42). This geometry predicts learnability. We introduce Neural Reasoning Operators - learned mappings from initial to terminal hidden states. In crystalline legal reasoning, our operator achieves 63.6% accuracy on held-out tasks via probe decoding, predicting reasoning endpoints without traversing intermediate states. We further identify a universal oscillatory signature (coherence ~ -0.4) invariant across domains and scales, suggesting attention and feedforward layers drive reasoning through opposing dynamics. These findings establish that the cost of thought is determined not by task difficulty but by manifold geometry - offering a blueprint for inference acceleration where topology permits.

</details>


### [462] [A Lightweight Modular Framework for Constructing Autonomous Agents Driven by Large Language Models: Design, Implementation, and Applications in AgentForge](https://arxiv.org/abs/2601.13383)
*Akbar Anbar Jafari,Cagri Ozcinar,Gholamreza Anbarjafari*

Main category: cs.AI

TL;DR: AgentForge是一个轻量级开源Python框架，通过模块化架构和三大创新（技能抽象、统一LLM接口、YAML配置）简化LLM驱动自主代理的构建，显著提升开发效率并降低延迟。


<details>
  <summary>Details</summary>
Motivation: 现有代理框架存在架构刚性、供应商锁定和复杂性高的问题，阻碍了快速原型设计和部署。

Method: AgentForge引入了三个关键创新：(1)可组合的技能抽象，(2)统一的LLM后端接口，(3)声明性YAML配置系统。通过DAG形式化技能组合机制，并证明其对任意顺序和并行任务工作流的表达能力。

Result: 在四个基准场景的综合实验评估中，AgentForge实现了竞争性的任务完成率，同时与LangChain和直接API集成相比，开发时间分别减少了62%和78%。延迟测量确认了低于100ms的编排开销。

Conclusion: AgentForge填补了LLM代理生态系统的关键空白，为研究人员和实践者提供了一个生产就绪的基础，用于构建、评估和部署自主代理，而无需牺牲灵活性或性能。

Abstract: The emergence of LLMs has catalyzed a paradigm shift in autonomous agent development, enabling systems capable of reasoning, planning, and executing complex multi-step tasks. However, existing agent frameworks often suffer from architectural rigidity, vendor lock-in, and prohibitive complexity that impedes rapid prototyping and deployment. This paper presents AgentForge, a lightweight, open-source Python framework designed to democratize the construction of LLM-driven autonomous agents through a principled modular architecture. AgentForge introduces three key innovations: (1) a composable skill abstraction that enables fine-grained task decomposition with formally defined input-output contracts, (2) a unified LLM backend interface supporting seamless switching between cloud-based APIs and local inference engines, and (3) a declarative YAML-based configuration system that separates agent logic from implementation details. We formalize the skill composition mechanism as a directed acyclic graph (DAG) and prove its expressiveness for representing arbitrary sequential and parallel task workflows. Comprehensive experimental evaluation across four benchmark scenarios demonstrates that AgentForge achieves competitive task completion rates while reducing development time by 62% compared to LangChain and 78% compared to direct API integration. Latency measurements confirm sub-100ms orchestration overhead, rendering the framework suitable for real-time applications. The modular design facilitates extension: we demonstrate the integration of six built-in skills and provide comprehensive documentation for custom skill development. AgentForge addresses a critical gap in the LLM agent ecosystem by providing researchers and practitioners with a production-ready foundation for constructing, evaluating, and deploying autonomous agents without sacrificing flexibility or performance.

</details>


### [463] [Explicit Cognitive Allocation: A Principle for Governed and Auditable Inference in Large Language Models](https://arxiv.org/abs/2601.13443)
*Héctor Manuel Manzanilla-Granados,Zaira Navarrete-Cazales,Miriam Pescador-Rojas,Tonahtiu Ramírez-Romero*

Main category: cs.AI

TL;DR: ECA原则和CUA架构通过结构化AI推理过程，显著提升了认知控制和工具透明度，优于传统LLM推理。


<details>
  <summary>Details</summary>
Motivation: 当前大型语言模型（LLMs）的使用在认知上缺乏结构化，导致推理过程中的问题框架、知识探索、检索等方法论意识模糊，限制了可追溯性和可重复性。

Method: 研究提出了ECA原则，并通过CUA架构实现，将推理过程分为探索与框架、认知锚定、工具与方法映射及解释性合成四个阶段，并引入Universal Cognitive Instruments (UCIs) 来形式化多样化工具。

Result: 在农业领域的多组提示实验中，CUA推理展现出更早且结构化的认知收敛、更高的语义扩展下的认知对齐，并能系统性揭示查询的工具结构，而基线LLM推理则表现更差。

Conclusion: Explicit Cognitive Allocation (ECA) 和 Cognitive Universal Agent (CUA) 架构通过明确分离和组织认知功能，显著提升了AI辅助推理的可追溯性、认知控制和可重复性，特别是在高责任场景中。

Abstract: The rapid adoption of large language models (LLMs) has enabled new forms of AI-assisted reasoning across scientific, technical, and organizational domains. However, prevailing modes of LLM use remain cognitively unstructured: problem framing, knowledge exploration, retrieval, methodological awareness, and explanation are typically collapsed into a single generative process. This cognitive collapse limits traceability, weakens epistemic control, and undermines reproducibility, particularly in high-responsibility settings.
  We introduce Explicit Cognitive Allocation, a general principle for structuring AI-assisted inference through the explicit separation and orchestration of epistemic functions. We instantiate this principle in the Cognitive Universal Agent (CUA), an architecture that organizes inference into distinct stages of exploration and framing, epistemic anchoring, instrumental and methodological mapping, and interpretive synthesis. Central to this framework is the notion of Universal Cognitive Instruments (UCIs), which formalize heterogeneous means, including computational, experimental, organizational, regulatory, and educational instruments, through which abstract inquiries become investigable.
  We evaluate the effects of explicit cognitive and instrumental allocation through controlled comparisons between CUA-orchestrated inference and baseline LLM inference under matched execution conditions. Across multiple prompts in the agricultural domain, CUA inference exhibits earlier and structurally governed epistemic convergence, higher epistemic alignment under semantic expansion, and systematic exposure of the instrumental landscape of inquiry. In contrast, baseline LLM inference shows greater variability in alignment and fails to explicitly surface instrumental structure.

</details>


### [464] [SpatialBench-UC: Uncertainty-Aware Evaluation of Spatial Prompt Following in Text-to-Image Generation](https://arxiv.org/abs/2601.13462)
*Amine Rostane*

Main category: cs.AI

TL;DR: SpatialBench-UC基准测试表明，grounding方法改善空间指令遵循，但检测缺失仍是主要挑战。


<details>
  <summary>Details</summary>
Motivation: 自动化评估文本到图像模型是否遵循空间指令存在困难，因目标检测可能遗漏或返回模糊结果，需选择性预测和置信度报告。

Method: 引入了SpatialBench-UC基准，包含200个提示（50个对象对×4种关系），并提供了可复现的测试包、版本化提示和校准工具。

Result: 测试了三个基线模型（Stable Diffusion 1.5、SD 1.5 BoxDiff、SD 1.4 GLIGEN），结果显示grounding方法显著提升通过率和覆盖率，但检测缺失导致大量弃权。

Conclusion: 文本到图像模型在遵循显式空间指令方面仍有挑战，尤其是检测缺失和模糊边界情况。通过基准测试发现，基于grounding的方法显著提高了通过率和覆盖率，但检测缺失仍是主要问题。

Abstract: Evaluating whether text-to-image models follow explicit spatial instructions is difficult to automate. Object detectors may miss targets or return multiple plausible detections, and simple geometric tests can become ambiguous in borderline cases. Spatial evaluation is naturally a selective prediction problem, the checker may abstain when evidence is weak and report confidence so that results can be interpreted as a risk coverage tradeoff rather than a single score. We introduce SpatialBench-UC, a small, reproducible benchmark for pairwise spatial relations. The benchmark contains 200 prompts (50 object pairs times 4 relations) grouped into 100 counterfactual pairs obtained by swapping object roles. We release a benchmark package, versioned prompts, pinned configs, per-sample checker outputs, and report tables, enabling reproducible and auditable comparisons across models. We also include a lightweight human audit used to calibrate the checker's abstention margin and confidence threshold. We evaluate three baselines, Stable Diffusion 1.5, SD 1.5 BoxDiff, and SD 1.4 GLIGEN. The checker reports pass rate and coverage as well as conditional pass rates on decided samples. The results show that grounding methods substantially improve both pass rate and coverage, while abstention remains a dominant factor due mainly to missing detections.

</details>


### [465] [Context and Transcripts Improve Detection of Deepfake Audios of Public Figures](https://arxiv.org/abs/2601.13464)
*Chongyang Gao,Marco Postiglione,Julian Baldwin,Natalia Denisenko,Isabel Gortner,Luke Fosdick,Chiara Pulice,Sarit Kraus,V. S. Subrahmanian*

Main category: cs.AI

TL;DR: 论文提出了一种基于上下文的音频深度伪造检测器(CADD)，通过利用上下文和转录文本显著提升了检测性能，并展示了其在对抗攻击下的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有音频深度伪造检测器仅分析音频文件，忽略了上下文和转录文本的重要性。

Method: 创建并分析了Journalist-provided Deepfake Dataset (JDD)和合成音频数据集(SYN)，提出了Context-based Audio Deepfake Detector (CADD)架构，并在ITW和P$^2$V数据集上进行了评估。

Result: 使用上下文和/或转录文本可将基线检测器的F1分数提升5%-37.58%，AUC提升3.77%-42.79%，EER降低6.17%-47.83%。CADD对5种对抗规避策略的鲁棒性更强，性能下降平均仅为-0.71%。

Conclusion: 结合上下文和/或转录文本可以显著提升音频深度伪造检测器的性能，CADD架构通过利用这些信息，表现出更强的鲁棒性。

Abstract: Humans use context to assess the veracity of information. However, current audio deepfake detectors only analyze the audio file without considering either context or transcripts. We create and analyze a Journalist-provided Deepfake Dataset (JDD) of 255 public deepfakes which were primarily contributed by over 70 journalists since early 2024. We also generate a synthetic audio dataset (SYN) of dead public figures and propose a novel Context-based Audio Deepfake Detector (CADD) architecture. In addition, we evaluate performance on two large-scale datasets: ITW and P$^2$V. We show that sufficient context and/or the transcript can significantly improve the efficacy of audio deepfake detectors. Performance (measured via F1 score, AUC, and EER) of multiple baseline audio deepfake detectors and traditional classifiers can be improved by 5%-37.58% in F1-score, 3.77%-42.79% in AUC, and 6.17%-47.83% in EER. We additionally show that CADD, via its use of context and/or transcripts, is more robust to 5 adversarial evasion strategies, limiting performance degradation to an average of just -0.71% across all experiments. Code, models, and datasets are available at our project page: https://sites.northwestern.edu/nsail/cadd-context-based-audio-deepfake-detection (access restricted during review).

</details>


### [466] [Graph Neural Networks are Heuristics](https://arxiv.org/abs/2601.13465)
*Yimeng Min,Carla P. Gomes*

Main category: cs.AI

TL;DR: 单训练轨迹可将图神经网络转化为组合优化的无监督启发式方法，无需搜索或监督即可生成解决方案，通过dropout和集成减少最优性差距。


<details>
  <summary>Details</summary>
Motivation: 探索图神经网络是否可以在无需监督训练或显式搜索的情况下，直接作为组合优化的启发式方法。

Method: 通过将全局结构约束编码为归纳偏置，使非自回归模型能够通过直接前向传递生成解决方案，无需搜索、监督或顺序决策。在推理时，通过dropout和快照集成使单个模型作为隐式集成，通过增加解决方案多样性来减少最优性差距。

Result: 结果表明，图神经网络能够内化全局组合结构并作为强大的学习启发式方法，无需监督训练或显式搜索即可有效。

Conclusion: 图神经网络无需监督训练或显式搜索即可有效，能够内化全局组合结构并作为强大的学习启发式方法。这重新定义了学习在组合优化中的作用：从增强经典算法到直接实例化新的启发式方法。

Abstract: We demonstrate that a single training trajectory can transform a graph neural network into an unsupervised heuristic for combinatorial optimization. Focusing on the Travelling Salesman Problem, we show that encoding global structural constraints as an inductive bias enables a non-autoregressive model to generate solutions via direct forward passes, without search, supervision, or sequential decision-making. At inference time, dropout and snapshot ensembling allow a single model to act as an implicit ensemble, reducing optimality gaps through increased solution diversity. Our results establish that graph neural networks do not require supervised training nor explicit search to be effective. Instead, they can internalize global combinatorial structure and function as strong, learned heuristics. This reframes the role of learning in combinatorial optimization: from augmenting classical algorithms to directly instantiating new heuristics.

</details>


### [467] [Towards Efficient and Robust Linguistic Emotion Diagnosis for Mental Health via Multi-Agent Instruction Refinement](https://arxiv.org/abs/2601.13481)
*Jian Zhang,Zhangqi Wang,Zhiyuan Wang,Weiping Fu,Yu He,Haiping Zhu,Qika Lin,Jun Liu*

Main category: cs.AI

TL;DR: APOLO是一个自动化提示优化框架，通过多智能体协作和闭环优化提升语言情感诊断的准确性和鲁棒性，适用于心理健康领域。


<details>
  <summary>Details</summary>
Motivation: 临床笔记、心理咨询对话和在线心理健康社区中情感表达的普遍性，以及现有方法在情感共病和临床相关线索探索效率上的不足，促使了APOLO的开发。

Method: APOLO采用部分可观察马尔可夫决策过程和多智能体协作机制（包括Planner、Teacher、Critic、Student和Target角色），通过闭环框架迭代优化提示设计。

Result: 实验结果表明，APOLO在领域特定和分层基准测试中均能持续提升诊断准确性和鲁棒性。

Conclusion: APOLO框架通过系统性探索更广泛和细粒度的提示空间，显著提升了语言情感诊断的准确性和鲁棒性，为心理健康领域提供了可信赖的大语言模型应用范式。

Abstract: Linguistic expressions of emotions such as depression, anxiety, and trauma-related states are pervasive in clinical notes, counseling dialogues, and online mental health communities, and accurate recognition of these emotions is essential for clinical triage, risk assessment, and timely intervention. Although large language models (LLMs) have demonstrated strong generalization ability in emotion analysis tasks, their diagnostic reliability in high-stakes, context-intensive medical settings remains highly sensitive to prompt design. Moreover, existing methods face two key challenges: emotional comorbidity, in which multiple intertwined emotional states complicate prediction, and inefficient exploration of clinically relevant cues. To address these challenges, we propose APOLO (Automated Prompt Optimization for Linguistic Emotion Diagnosis), a framework that systematically explores a broader and finer-grained prompt space to improve diagnostic efficiency and robustness. APOLO formulates instruction refinement as a Partially Observable Markov Decision Process and adopts a multi-agent collaboration mechanism involving Planner, Teacher, Critic, Student, and Target roles. Within this closed-loop framework, the Planner defines an optimization trajectory, while the Teacher-Critic-Student agents iteratively refine prompts to enhance reasoning stability and effectiveness, and the Target agent determines whether to continue optimization based on performance evaluation. Experimental results show that APOLO consistently improves diagnostic accuracy and robustness across domain-specific and stratified benchmarks, demonstrating a scalable and generalizable paradigm for trustworthy LLM applications in mental healthcare.

</details>


### [468] [AgenticRed: Optimizing Agentic Systems for Automated Red-teaming](https://arxiv.org/abs/2601.13518)
*Jiayi Yuan,Jonathan Nöther,Natasha Jaques,Goran Radanović*

Main category: cs.AI

TL;DR: AgenticRed是一种自动化红队系统设计方法，通过LLM和进化选择实现高效漏洞检测，显著提升攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 解决现有自动化红队方法依赖人工设计工作流的问题，减少人为偏见并降低探索设计空间的成本。

Method: 利用LLM的上下文学习能力，通过进化选择方法迭代设计和优化红队系统。

Result: AgenticRed设计的红队系统在多个模型上表现优异，攻击成功率显著提升，尤其在Llama-2-7B上达到96%（提升36%），并在专有模型上展现出强迁移性。

Conclusion: AgenticRed展示了自动化系统设计在AI安全评估中的强大潜力，能够跟上快速发展的模型步伐。

Abstract: While recent automated red-teaming methods show promise for systematically exposing model vulnerabilities, most existing approaches rely on human-specified workflows. This dependence on manually designed workflows suffers from human biases and makes exploring the broader design space expensive. We introduce AgenticRed, an automated pipeline that leverages LLMs' in-context learning to iteratively design and refine red-teaming systems without human intervention. Rather than optimizing attacker policies within predefined structures, AgenticRed treats red-teaming as a system design problem. Inspired by methods like Meta Agent Search, we develop a novel procedure for evolving agentic systems using evolutionary selection, and apply it to the problem of automatic red-teaming. Red-teaming systems designed by AgenticRed consistently outperform state-of-the-art approaches, achieving 96% attack success rate (ASR) on Llama-2-7B (36% improvement) and 98% on Llama-3-8B on HarmBench. Our approach exhibits strong transferability to proprietary models, achieving 100% ASR on GPT-3.5-Turbo and GPT-4o-mini, and 60% on Claude-Sonnet-3.5 (24% improvement). This work highlights automated system design as a powerful paradigm for AI safety evaluation that can keep pace with rapidly evolving models.

</details>


### [469] [Reasoning While Recommending: Entropy-Guided Latent Reasoning in Generative Re-ranking Models](https://arxiv.org/abs/2601.13533)
*Changshuo Zhang*

Main category: cs.AI

TL;DR: EGLR模型通过实时推理和熵引导的动态调整，优化生成式重排序的探索-利用平衡，提升性能且易于部署。


<details>
  <summary>Details</summary>
Motivation: 现有生成方法难以适应列表生成中模型难度的动态熵变化，无法准确捕捉复杂偏好。

Method: 提出Entropy-Guided Latent Reasoning (EGLR)推荐模型，结合上下文感知推理令牌和动态温度调整，实现实时推理与推荐。

Result: 在两个真实数据集上的实验验证了模型的有效性，且兼容现有生成式重排序模型以提升性能。

Conclusion: EGLR模型通过引入潜在推理机制和熵引导的动态调整，有效提升了生成式重排序的性能，并展示了实际部署价值和研究潜力。

Abstract: Reinforcement learning plays a crucial role in generative re-ranking scenarios due to its exploration-exploitation capabilities, but existing generative methods mostly fail to adapt to the dynamic entropy changes in model difficulty during list generation, making it challenging to accurately capture complex preferences. Given that language models have achieved remarkable breakthroughs by integrating reasoning capabilities, we draw on this approach to introduce a latent reasoning mechanism, and experimental validation demonstrates that this mechanism effectively reduces entropy in the model's decision-making process. Based on these findings, we introduce the Entropy-Guided Latent Reasoning (EGLR) recommendation model, which has three core advantages. First, it abandons the "reason first, recommend later" paradigm to achieve "reasoning while recommending", specifically designed for the high-difficulty nature of list generation by enabling real-time reasoning during generation. Second, it implements entropy-guided variable-length reasoning using context-aware reasoning token alongside dynamic temperature adjustment, expanding exploration breadth in reasoning and boosting exploitation precision in recommending to achieve a more precisely adapted exploration-exploitation trade-off. Third, the model adopts a lightweight integration design with no complex independent modules or post-processing, enabling easy adaptation to existing models. Experimental results on two real-world datasets validate the model's effectiveness, and its notable advantage lies in being compatible with existing generative re-ranking models to enhance their performance. Further analyses also demonstrate its practical deployment value and research potential.

</details>


### [470] [TruthTensor: Evaluating LLMs Human Imitation through Prediction Market Drift and Holistic Reasoning](https://arxiv.org/abs/2601.13545)
*Shirin Shahabi,Spencer Graham,Haruna Isah*

Main category: cs.AI

TL;DR: TruthTensor 是一种新的 LLM 评估框架，通过实时预测市场和多维度指标（如校准、漂移）弥补静态基准的不足，实验证明其能有效区分模型行为差异。


<details>
  <summary>Details</summary>
Motivation: 静态基准测试无法捕捉现实世界的不确定性、分布变化及孤立任务准确性与人类对齐决策之间的差距，因此需要一种更全面的评估方法。

Method: 构建了基于实时预测市场的框架，结合概率评分和多维度诊断（如漂移、鲁棒性检查），并明确人类与自动化评估角色、标注协议及统计测试流程。

Result: 在 500+ 个真实市场（政治、经济、文化、技术）的实验中，TruthTensor 显示模型在预测准确性相似的情况下，校准、漂移和风险敏感性可能显著不同。

Conclusion: TruthTensor 提供了一种新颖、可复现的评估范式，通过多维度（准确性、校准、叙事稳定性、成本与资源效率）评估 LLMs，强调了在现代评估实践中操作化最佳实践的重要性。

Abstract: Evaluating language models and AI agents remains fundamentally challenging because static benchmarks fail to capture real-world uncertainty, distribution shift, and the gap between isolated task accuracy and human-aligned decision-making under evolving conditions. This paper introduces TruthTensor, a novel, reproducible evaluation paradigm that measures Large Language Models (LLMs) not only as prediction engines but as human-imitation systems operating in socially-grounded, high-entropy environments. Building on forward-looking, contamination-free tasks, our framework anchors evaluation to live prediction markets and combines probabilistic scoring to provide a holistic view of model behavior. TruthTensor complements traditional correctness metrics with drift-centric diagnostics and explicit robustness checks for reproducibility. It specify human vs. automated evaluation roles, annotation protocols, and statistical testing procedures to ensure interpretability and replicability of results. In experiments across 500+ real markets (political, economic, cultural, technological), TruthTensor demonstrates that models with similar forecast accuracy can diverge markedly in calibration, drift, and risk-sensitivity, underscoring the need to evaluate models along multiple axes (accuracy, calibration, narrative stability, cost, and resource efficiency). TruthTensor therefore operationalizes modern evaluation best practices, clear hypothesis framing, careful metric selection, transparent compute/cost reporting, human-in-the-loop validation, and open, versioned evaluation contracts, to produce defensible assessments of LLMs in real-world decision contexts. We publicly release TruthTensor at https://truthtensor.com

</details>


### [471] [ChatAD: Reasoning-Enhanced Time-Series Anomaly Detection with Multi-Turn Instruction Evolution](https://arxiv.org/abs/2601.13546)
*Hui Sun,Chang Xu,Haonan Xie,Hao Li,Yuhao Huang,Chuheng Zhang,Ming Jin,Xiaoguang Liu,Gang Wang,Jiang Bian*

Main category: cs.AI

TL;DR: 提出TSEvol算法、TSEData-20K数据集及ChatAD系列模型，通过TKTO优化显著提升时间序列异常检测性能，并在多任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法在推理能力、多轮对话能力和泛化性方面存在不足，需提升时间序列异常检测的解释性和性能。

Method: 1) 提出基于多代理的时间序列演化算法TSEvol；2) 引入TSEData-20K数据集及ChatAD系列模型；3) 提出TKTO优化方法增强跨任务泛化能力；4) 设计LLADBench基准评估性能。

Result: ChatAD模型在准确率、F1分数和假阳性率上分别提升高达34.50%、34.71%和37.42%，优化后的ChatAD在多任务中表现优异。

Conclusion: LLM驱动的异常检测（AD）通过TSEvol算法、TSEData-20K数据集、ChatAD系列模型及TKTO优化方法，显著提升了时间序列异常检测的性能和泛化能力，并在多任务中表现优异。

Abstract: LLM-driven Anomaly Detection (AD) helps enhance the understanding and explanatory abilities of anomalous behaviors in Time Series (TS). Existing methods face challenges of inadequate reasoning ability, deficient multi-turn dialogue capability, and narrow generalization. To this end, we 1) propose a multi-agent-based TS Evolution algorithm named TSEvol. On top of it, we 2) introduce the AD reasoning and multi-turn dialogue Dataset TSEData-20K and contribute the Chatbot family for AD, including ChatAD-Llama3-8B, Qwen2.5-7B, and Mistral-7B. Furthermore, 3) we propose the TS Kahneman-Tversky Optimization (TKTO) to enhance ChatAD's cross-task generalization capability. Lastly, 4) we propose a LLM-driven Learning-based AD Benchmark LLADBench to evaluate the performance of ChatAD and nine baselines across seven datasets and tasks. Our three ChatAD models achieve substantial gains, up to 34.50% in accuracy, 34.71% in F1, and a 37.42% reduction in false positives. Besides, via KTKO, our optimized ChatAD achieves competitive performance in reasoning and cross-task generalization on classification, forecasting, and imputation.

</details>


### [472] [Leveraging ChatGPT and Other NLP Methods for Identifying Risk and Protective Behaviors in MSM: Social Media and Dating apps Text Analysis](https://arxiv.org/abs/2601.13558)
*Mehrab Beikzadeh,Chenglin Hong,Cory J Cascalheira,Callisto Boka,Majid Sarrafzadeh,Ian W Holloway*

Main category: cs.AI

TL;DR: 研究顯示，社交媒體和約會應用文本能有效預測MSM的風險行為，機器學習模型表現良好，支持個性化公共衛生干預。


<details>
  <summary>Details</summary>
Motivation: 男男性行為者（MSM）相對於異性戀男性面臨更高的性傳播感染和有害飲酒風險，社交媒體和約會應用的文本數據可能為個性化公共衛生干預提供新機會。

Method: 通過參與者同意收集文本數據，並使用ChatGPT嵌入、BERT嵌入、LIWC和基於字典的風險詞方法訓練機器學習模型。

Result: 模型在預測每月酗酒和超過五個性伴侶方面表現強勁（F1分數0.78），在預測PrEP使用和重度飲酒方面表現中等（F1分數0.64和0.63）。

Conclusion: 社交媒體和約會應用程序的文本數據能夠提供有關風險和保護行為的寶貴見解，並展示了基於大型語言模型的方法在支持可擴展和個性化公共衛生干預方面的潛力。

Abstract: Men who have sex with men (MSM) are at elevated risk for sexually transmitted infections and harmful drinking compared to heterosexual men. Text data collected from social media and dating applications may provide new opportunities for personalized public health interventions by enabling automatic identification of risk and protective behaviors. In this study, we evaluated whether text from social media and dating apps can be used to predict sexual risk behaviors, alcohol use, and pre-exposure prophylaxis (PrEP) uptake among MSM. With participant consent, we collected textual data and trained machine learning models using features derived from ChatGPT embeddings, BERT embeddings, LIWC, and a dictionary-based risk term approach. The models achieved strong performance in predicting monthly binge drinking and having more than five sexual partners, with F1 scores of 0.78, and moderate performance in predicting PrEP use and heavy drinking, with F1 scores of 0.64 and 0.63. These findings demonstrate that social media and dating app text data can provide valuable insights into risk and protective behaviors and highlight the potential of large language model-based methods to support scalable and personalized public health interventions for MSM.

</details>


### [473] [AgentGC: Evolutionary Learning-based Lossless Compression for Genomics Data with LLM-driven Multiple Agent](https://arxiv.org/abs/2601.13559)
*Sun Hui,Ding Yanfeng,Huidong Ma,Chang Xu,Keyan Jin,Lizheng Zu,Cheng Zhong,xiaoguang Liu,Gang Wang,Wentong Cai*

Main category: cs.AI

TL;DR: AgentGC是一种基于代理的进化型基因组数据压缩器，通过三层架构和三种模式显著提升压缩率和吞吐量。


<details>
  <summary>Details</summary>
Motivation: 现有基于学习的方法在基因组数据压缩中存在低层次建模、适应性差和用户界面不友好等问题，因此提出了AgentGC。

Method: AgentGC采用三层架构：用户层（通过Leader与LLM结合提供用户友好界面）、认知层（Leader驱动，结合LLM优化算法-数据集-系统）和压缩层（Worker主导，基于自动化多知识学习框架进行压缩与解压）。设计了三种模式（CP、TP、BM）以适应不同场景。

Result: 在9个数据集上与14个基线相比，平均压缩率提升16.66%、16.11%和16.33%，吞吐量提升4.73倍、9.23倍和9.15倍。

Conclusion: AgentGC是一种进化型基于代理的基因组数据压缩器，通过三层架构（用户层、认知层和压缩层）解决了现有学习方法的局限性，显著提升了压缩率和吞吐量。

Abstract: Lossless compression has made significant advancements in Genomics Data (GD) storage, sharing and management. Current learning-based methods are non-evolvable with problems of low-level compression modeling, limited adaptability, and user-unfriendly interface. To this end, we propose AgentGC, the first evolutionary Agent-based GD Compressor, consisting of 3 layers with multi-agent named Leader and Worker. Specifically, the 1) User layer provides a user-friendly interface via Leader combined with LLM; 2) Cognitive layer, driven by the Leader, integrates LLM to consider joint optimization of algorithm-dataset-system, addressing the issues of low-level modeling and limited adaptability; and 3) Compression layer, headed by Worker, performs compression & decompression via a automated multi-knowledge learning-based compression framework. On top of AgentGC, we design 3 modes to support diverse scenarios: CP for compression-ratio priority, TP for throughput priority, and BM for balanced mode. Compared with 14 baselines on 9 datasets, the average compression ratios gains are 16.66%, 16.11%, and 16.33%, the throughput gains are 4.73x, 9.23x, and 9.15x, respectively.

</details>


### [474] [Reasoning is a Modality](https://arxiv.org/abs/2601.13562)
*Zhiguang Liu,Yi Shang*

Main category: cs.AI

TL;DR: 论文提出角色分离Transformer块，通过分离控制器与工作区令牌提升视觉推理能力，在ARC-1任务上超越人类表现。


<details>
  <summary>Details</summary>
Motivation: 研究抽象推理能力，填补现代AI系统与人类行为之间的差距，即AI缺乏可解码的内部状态。

Method: 设计了角色分离的Transformer块，分离全局控制器令牌和网格工作区令牌，支持迭代规则执行。

Result: 在VARC视觉中心协议下训练和评估，模型在ARC-1任务上达到62.6%的准确率，超过人类平均表现（60.2%）并显著优于现有方法。

Conclusion: 论文提出了一种新型的角色分离Transformer块，通过将全局控制器令牌与网格工作区令牌分离，实现了迭代规则执行，从而在视觉推理问题上超越了人类平均表现和现有方法。

Abstract: The Abstraction and Reasoning Corpus (ARC) provides a compact laboratory for studying abstract reasoning, an ability central to human intelligence. Modern AI systems, including LLMs and ViTs, largely operate as sequence-of-behavior prediction machines: they match observable behaviors by modeling token statistics without a persistent, readable mental state. This creates a gap with human-like behavior: humans can explain an action by decoding internal state, while AI systems can produce fluent post-hoc rationalizations that are not grounded in such a state. We hypothesize that reasoning is a modality: reasoning should exist as a distinct channel separate from the low-level workspace on which rules are applied. To test this hypothesis, on solving ARC tasks as a visual reasoning problem, we designed a novel role-separated transformer block that splits global controller tokens from grid workspace tokens, enabling iterative rule execution. Trained and evaluated within the VARC vision-centric protocol, our method achieved 62.6% accuracy on ARC-1, surpassing average human performance (60.2%) and outperforming prior methods significantly. Qualitatively, our models exhibit more coherent rule-application structure than the dense ViT baseline, consistent with a shift away from plausible probability blobs toward controller-driven reasoning.

</details>


### [475] [SCRIPTMIND: Crime Script Inference and Cognitive Evaluation for LLM-based Social Engineering Scam Detection System](https://arxiv.org/abs/2601.13581)
*Heedou Kim,Changsik Kim,Sanghwa Shin,Jaewoo Kang*

Main category: cs.AI

TL;DR: ScriptMind是一个LLM框架，通过犯罪脚本推理和认知模拟提升诈骗检测性能，实验证明其在多个指标上优于商业模型，并增强了用户的认知意识。


<details>
  <summary>Details</summary>
Motivation: 传统检测方法在应对个性化、多轮欺骗的社会工程诈骗时存在局限，而大型语言模型（LLMs）在识别欺骗方面的潜力尚未充分探索。

Method: 提出了ScriptMind框架，包括犯罪脚本推理任务（CSIT）、犯罪脚本感知推理数据集（CSID）和基于认知模拟的社会工程防御评估（CSED），并使用571个韩国电话诈骗案例构建了22,712个结构化诈骗序列训练实例。

Result: 实验结果显示，经过ScriptMind微调的11B小型LLM在检测准确性、减少误报、诈骗者话语预测和理由质量方面优于GPT-4o 13%，并在电话诈骗模拟实验中显著提升并维持了用户的怀疑水平。

Conclusion: ScriptMind是一个迈向以人为中心、认知自适应的LLM用于诈骗防御的步骤，展示了其在检测准确性、减少误报、诈骗者话语预测和理由质量方面的优越性能。

Abstract: Social engineering scams increasingly employ personalized, multi-turn deception, exposing the limits of traditional detection methods. While Large Language Models (LLMs) show promise in identifying deception, their cognitive assistance potential remains underexplored. We propose ScriptMind, an integrated framework for LLM-based scam detection that bridges automated reasoning and human cognition. It comprises three components: the Crime Script Inference Task (CSIT) for scam reasoning, the Crime Script-Aware Inference Dataset (CSID) for fine-tuning small LLMs, and the Cognitive Simulation-based Evaluation of Social Engineering Defense (CSED) for assessing real-time cognitive impact. Using 571 Korean phone scam cases, we built 22,712 structured scammer-sequence training instances. Experimental results show that the 11B small LLM fine-tuned with ScriptMind outperformed GPT-4o by 13%, achieving superior performance over commercial models in detection accuracy, false-positive reduction, scammer utterance prediction, and rationale quality. Moreover, in phone scam simulation experiments, it significantly enhanced and sustained users' suspicion levels, improving their cognitive awareness of scams. ScriptMind represents a step toward human-centered, cognitively adaptive LLMs for scam defense.

</details>


### [476] [Motion-to-Response Content Generation via Multi-Agent AI System with Real-Time Safety Verification](https://arxiv.org/abs/2601.13589)
*HyeYoung Lee*

Main category: cs.AI

TL;DR: 该论文提出了一种多智能体AI系统，通过协作智能体实时生成安全、适龄的媒体内容，实验显示高准确率和合规性，适用于儿童媒体和智能设备。


<details>
  <summary>Details</summary>
Motivation: 传统语音情感识别研究主要关注分类准确性，而本研究强调将推断的情感状态转化为安全、适龄且可控的响应内容。

Method: 系统由四个协作智能体组成：情感识别智能体（基于CNN的声学特征提取）、响应策略决策智能体（情感到响应模式的映射）、内容参数生成智能体（生成媒体控制参数）和安全验证智能体（确保内容适龄且合规）。

Result: 在公共数据集上的实验结果显示，系统实现了73.2%的情感识别准确率、89.4%的响应模式一致性和100%的安全合规性，同时保持低于100ms的推理延迟。

Conclusion: 该论文提出了一种模块化、可解释且可扩展的多智能体AI系统，能够实时生成基于音频情感信号的安全、适龄且可控的媒体内容，适用于儿童相关媒体、治疗应用和情感响应智能设备。

Abstract: This paper proposes a multi-agent artificial intelligence system that generates response-oriented media content in real time based on audio-derived emotional signals. Unlike conventional speech emotion recognition studies that focus primarily on classification accuracy, our approach emphasizes the transformation of inferred emotional states into safe, age-appropriate, and controllable response content through a structured pipeline of specialized AI agents. The proposed system comprises four cooperative agents: (1) an Emotion Recognition Agent with CNN-based acoustic feature extraction, (2) a Response Policy Decision Agent for mapping emotions to response modes, (3) a Content Parameter Generation Agent for producing media control parameters, and (4) a Safety Verification Agent enforcing age-appropriateness and stimulation constraints. We introduce an explicit safety verification loop that filters generated content before output, ensuring compliance with predefined rules. Experimental results on public datasets demonstrate that the system achieves 73.2% emotion recognition accuracy, 89.4% response mode consistency, and 100% safety compliance while maintaining sub-100ms inference latency suitable for on-device deployment. The modular architecture enables interpretability and extensibility, making it applicable to child-adjacent media, therapeutic applications, and emotionally responsive smart devices.

</details>


### [477] [DSAEval: Evaluating Data Science Agents on a Wide Range of Real-World Data Science Problems](https://arxiv.org/abs/2601.13591)
*Maojun Sun,Yifei Xie,Yue Wu,Ruijian Han,Binyan Jiang,Defeng Sun,Yancheng Yuan,Jian Huang*

Main category: cs.AI

TL;DR: DSAEval基准评估11种LLM代理，Claude-Sonnet-4.5表现最佳，多模态感知提升视觉任务性能，非结构化领域仍存挑战。


<details>
  <summary>Details</summary>
Motivation: 解决开放性问题评估的挑战，因真实世界数据科学问题常跨多个分类且缺乏标准答案。

Method: 引入DSAEval基准，包含641个真实世界数据科学问题，基于285个多样化数据集，涵盖结构化和非结构化数据。DSAEval具有三个特征：多模态环境感知、多查询交互和多维评估。

Result: Claude-Sonnet-4.5表现最佳，GPT-5.2最高效，MiMo-V2-Flash最具成本效益。多模态感知在视觉任务中提升2.04%至11.30%。

Conclusion: 当前的数据科学代理在结构化数据和常规数据分析工作流上表现良好，但在非结构化领域仍存在重大挑战。文章提供了关键见解并概述了未来研究方向。

Abstract: Recent LLM-based data agents aim to automate data science tasks ranging from data analysis to deep learning. However, the open-ended nature of real-world data science problems, which often span multiple taxonomies and lack standard answers, poses a significant challenge for evaluation. To address this, we introduce DSAEval, a benchmark comprising 641 real-world data science problems grounded in 285 diverse datasets, covering both structured and unstructured data (e.g., vision and text). DSAEval incorporates three distinctive features: (1) Multimodal Environment Perception, which enables agents to interpret observations from multiple modalities including text and vision; (2) Multi-Query Interactions, which mirror the iterative and cumulative nature of real-world data science projects; and (3) Multi-Dimensional Evaluation, which provides a holistic assessment across reasoning, code, and results. We systematically evaluate 11 advanced agentic LLMs using DSAEval. Our results show that Claude-Sonnet-4.5 achieves the strongest overall performance, GPT-5.2 is the most efficient, and MiMo-V2-Flash is the most cost-effective. We further demonstrate that multimodal perception consistently improves performance on vision-related tasks, with gains ranging from 2.04% to 11.30%. Overall, while current data science agents perform well on structured data and routine data anlysis workflows, substantial challenges remain in unstructured domains. Finally, we offer critical insights and outline future research directions to advance the development of data science agents.

</details>


### [478] [Foundations of Global Consistency Checking with Noisy LLM Oracles](https://arxiv.org/abs/2601.13600)
*Paul He,Elke Kirschbaum,Shiva Kasiviswanathan*

Main category: cs.AI

TL;DR: 论文提出了一种自适应分治算法，用于高效检测和修复自然语言事实集合中的不一致性，适用于基于LLM的评估任务。


<details>
  <summary>Details</summary>
Motivation: 确保自然语言事实集合的全局一致性对于事实核查、摘要和知识库构建等任务至关重要。尽管大型语言模型（LLMs）可以评估小规模事实子集的一致性，但其判断存在噪声，且成对检查不足以保证全局一致性。

Method: 采用自适应分治算法，识别事实的最小不一致子集（MUSes），并可选地通过命中集计算最小修复方案。该方法具有低次多项式查询复杂度。

Result: 实验表明，该方法能有效检测和定位不一致性，为基于LLM的评估者提供了一个可扩展的语言一致性验证框架。

Conclusion: 该论文提出了一种自适应分治算法，用于识别事实的最小不一致子集（MUSes），并通过命中集计算最小修复方案，为基于LLM的评估者提供了一个可扩展的语言一致性验证框架。

Abstract: Ensuring that collections of natural-language facts are globally consistent is essential for tasks such as fact-checking, summarization, and knowledge base construction. While Large Language Models (LLMs) can assess the consistency of small subsets of facts, their judgments are noisy, and pairwise checks are insufficient to guarantee global coherence. We formalize this problem and show that verifying global consistency requires exponentially many oracle queries in the worst case. To make the task practical, we propose an adaptive divide-and-conquer algorithm that identifies minimal inconsistent subsets (MUSes) of facts and optionally computes minimal repairs through hitting-sets. Our approach has low-degree polynomial query complexity. Experiments with both synthetic and real LLM oracles show that our method efficiently detects and localizes inconsistencies, offering a scalable framework for linguistic consistency verification with LLM-based evaluators.

</details>


### [479] [Resilient Routing: Risk-Aware Dynamic Routing in Smart Logistics via Spatiotemporal Graph Learning](https://arxiv.org/abs/2601.13632)
*Zhiming Xue,Sichen Zhao,Yalun Qi,Xianling Zeng,Zihan Yu*

Main category: cs.AI

TL;DR: 提出RADR框架，结合ST-GNN和组合优化，显著降低拥堵风险并平衡效率与安全。


<details>
  <summary>Details</summary>
Motivation: 电子商务快速发展导致物流网络压力剧增，传统静态路由策略难以应对交通拥堵和需求波动。

Method: 构建物流拓扑图，采用结合图卷积网络（GCN）和门控循环单元（GRU）的混合深度学习模型预测未来拥堵风险，并通过动态边权重机制进行路径规划。

Result: 在Smart Logistics Dataset 2024上的实验表明，RADR算法在高拥堵场景下将潜在拥堵风险降低了19.3%，运输距离仅增加2.1%。

Conclusion: 本文提出的RADR框架通过结合时空图神经网络和组合优化，有效平衡了物流网络的交付效率和运营安全，显著提升了供应链的韧性。

Abstract: With the rapid development of the e-commerce industry, the logistics network is experiencing unprecedented pressure. The traditional static routing strategy most time cannot tolerate the traffic congestion and fluctuating retail demand. In this paper, we propose a Risk-Aware Dynamic Routing(RADR) framework which integrates Spatiotemporal Graph Neural Networks (ST-GNN) with combinatorial optimization. We first construct a logistics topology graph by using the discrete GPS data using spatial clustering methods. Subsequently, a hybrid deep learning model combining Graph Convolutional Network (GCN) and Gated Recurrent Unit (GRU) is adopted to extract spatial correlations and temporal dependencies for predicting future congestion risks. These prediction results are then integrated into a dynamic edge weight mechanism to perform path planning. We evaluated the framework on the Smart Logistics Dataset 2024, which contains real-world Internet of Things(IoT) sensor data. The experimental results show that the RADR algorithm significantly enhances the resilience of the supply chain. Particularly in the case study of high congestion scenarios, our method reduces the potential congestion risk exposure by 19.3% while only increasing the transportation distance by 2.1%. This empirical evidence confirms that the proposed data-driven approach can effectively balance delivery efficiency and operational safety.

</details>


### [480] [Understanding Mental States to Guide Social Influence in Multi-Person Group Dialogue](https://arxiv.org/abs/2601.13687)
*Zhichao Liang,Satoshi Nakamura*

Main category: cs.AI

TL;DR: SocialMindChange是一个新的基准测试，用于评估语言模型在社交互动中主动改变他人心理状态的能力，结果显示当前模型表现远低于人类。


<details>
  <summary>Details</summary>
Motivation: 现有的动态心理理论（ToM）基准测试大多让语言模型处于被动角色，而实际社交互动中ToM还用于主动改变他人心理状态。

Method: 通过构建一个包含1,200个社交情境、6,000个场景和超过90,000个问题的基准测试SocialMindChange，采用结构化四步框架，评估模型在生成对话以达成目标时的表现。

Result: 十种最先进的大语言模型在SocialMindChange上的平均表现仅为人类水平的54.2%以下。

Conclusion: 当前的大语言模型在维持和改变长链互动中的心理状态表征方面仍存在困难，其平均表现比人类低54.2%。

Abstract: Existing dynamic Theory of Mind (ToM) benchmarks mostly place language models in a passive role: the model reads a sequence of connected scenarios and reports what people believe, feel, intend, and do as these states change. In real social interaction, ToM is also used for action: a speaker plans what to say in order to shift another person's mental-state trajectory toward a goal. We introduce SocialMindChange, a benchmark that moves from tracking minds to changing minds in social interaction. Each instance defines a social context with 4 characters and five connected scenes. The model plays one character and generates dialogue across the five scenes to reach the target while remaining consistent with the evolving states of all participants. SocialMindChange also includes selected higher-order states. Using a structured four-step framework, we construct 1,200 social contexts, covering 6000 scenarios and over 90,000 questions, each validated for realism and quality. Evaluations on ten state-of-the-art LLMs show that their average performance is 54.2% below human performance. This gap suggests that current LLMs still struggle to maintain and change mental-state representations across long, linked interactions.

</details>


### [481] [Hidden in Plain Text: Measuring LLM Deception Quality Against Human Baselines Using Social Deduction Games](https://arxiv.org/abs/2601.13709)
*Christopher Kao,Vanshika Vats,James Davis*

Main category: cs.AI

TL;DR: LLM在Mafia游戏中比人类更擅长欺骗，且更难被检测到，突显其社交欺骗的复杂性与风险。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM在自然语言社交环境中的欺骗能力，弥补现有研究对社交背景下LLM欺骗行为理解的不足。

Method: 研究采用异步多智能体框架模拟35场Mafia游戏，使用GPT-4o LLM代理，并开发基于GPT-4-Turbo的Mafia Detector分析游戏记录以预测欺骗行为。

Result: Mafia Detector在LLM游戏中的预测准确率低于人类游戏，表明LLM能更有效地融入并欺骗。

Conclusion: LLMs在社交环境中展现出更高的欺骗能力，且比人类更难以被检测到，这突显了LLM在社交环境中欺骗的复杂性和潜在风险。

Abstract: Large Language Model (LLM) agents are increasingly used in many applications, raising concerns about their safety. While previous work has shown that LLMs can deceive in controlled tasks, less is known about their ability to deceive using natural language in social contexts. In this paper, we study deception in the Social Deduction Game (SDG) Mafia, where success is dependent on deceiving others through conversation. Unlike previous SDG studies, we use an asynchronous multi-agent framework which better simulates realistic social contexts. We simulate 35 Mafia games with GPT-4o LLM agents. We then create a Mafia Detector using GPT-4-Turbo to analyze game transcripts without player role information to predict the mafia players. We use prediction accuracy as a surrogate marker for deception quality. We compare this prediction accuracy to that of 28 human games and a random baseline. Results show that the Mafia Detector's mafia prediction accuracy is lower on LLM games than on human games. The result is consistent regardless of the game days and the number of mafias detected. This indicates that LLMs blend in better and thus deceive more effectively. We also release a dataset of LLM Mafia transcripts to support future research. Our findings underscore both the sophistication and risks of LLM deception in social contexts.

</details>


### [482] [Reasoning or Fluency? Dissecting Probabilistic Confidence in Best-of-N Selection](https://arxiv.org/abs/2601.13735)
*Hojin Kim,Jaehyung Kim*

Main category: cs.AI

TL;DR: 研究发现概率置信度指标主要依赖表面流畅性而非逻辑结构，提出新对比因果度量以改进选择准确性。


<details>
  <summary>Details</summary>
Motivation: 挑战概率置信度指标是否能真正捕捉到有效推理所需的步骤间因果依赖的假设。

Method: 引入三类步骤间因果关系扰动，系统性地破坏推理步骤间的依赖关系，同时保持局部流畅性。

Result: 发现即使在严重干预下，选择准确性仅略有下降，表明当前概率指标对逻辑结构不敏感。

Conclusion: 当前的基于概率的置信度指标主要捕捉的是表面流畅性或分布内先验，而非逻辑结构。提出的对比因果度量能更有效地隔离步骤间因果依赖，从而提供更可靠的输出选择。

Abstract: Probabilistic confidence metrics are increasingly adopted as proxies for reasoning quality in Best-of-N selection, under the assumption that higher confidence reflects higher reasoning fidelity. In this work, we challenge this assumption by investigating whether these metrics truly capture inter-step causal dependencies necessary for valid reasoning. We introduce three classes of inter-step causality perturbations that systematically disrupt dependencies between reasoning steps while preserving local fluency. Surprisingly, across diverse model families and reasoning benchmarks, we find that selection accuracy degrades only marginally under these disruptions. Even severe interventions, such as applying hard attention masks that directly prevent the model from attending to prior reasoning steps, do not substantially reduce selection performance. These findings provide strong evidence that current probabilistic metrics are largely insensitive to logical structure, and primarily capture surface-level fluency or in-distribution priors instead. Motivated by this gap, we propose a contrastive causality metric that explicitly isolates inter-step causal dependencies, and demonstrate that it yields more faithful output selection than existing probability-based approaches.

</details>


### [483] [Finding RELIEF: Shaping Reasoning Behavior without Reasoning Supervision via Belief Engineering](https://arxiv.org/abs/2601.13752)
*Chak Tou Leong,Dingwei Chen,Heming Xia,Qingyu Yin,Sunbowen Lee,Jian Wang,Wenjie Li*

Main category: cs.AI

TL;DR: RELIEF通过调整模型的自我认知与目标信念对齐，无需推理轨迹监督，高效塑造大型推理模型行为，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型（LRMs）在复杂问题解决中表现出色，但存在计算冗余或推理不忠实的问题，当前方法依赖强化学习或黄金标准推理轨迹微调，计算成本高且难以扩展。

Method: 提出了Reasoning Belief Engineering (RELIEF)框架，通过简单logit探测捕获模型的潜在推理信念，并利用合成的自反问答对进行微调，以内部化目标信念。

Result: RELIEF在效率和忠实度任务上匹配或优于基于行为监督和偏好的基线方法，同时训练成本更低。进一步分析表明，调整模型的推理信念能有效塑造其实际行为。

Conclusion: RELIEF框架通过调整模型的自我认知与目标信念蓝图对齐，有效塑造了大型推理模型的行为，无需推理轨迹监督，且在效率和忠实度任务上表现优异。

Abstract: Large reasoning models (LRMs) have achieved remarkable success in complex problem-solving, yet they often suffer from computational redundancy or reasoning unfaithfulness. Current methods for shaping LRM behavior typically rely on reinforcement learning or fine-tuning with gold-standard reasoning traces, a paradigm that is both computationally expensive and difficult to scale. In this paper, we reveal that LRMs possess latent \textit{reasoning beliefs} that internally track their own reasoning traits, which can be captured through simple logit probing. Building upon this insight, we propose Reasoning Belief Engineering (RELIEF), a simple yet effective framework that shapes LRM behavior by aligning the model's self-concept with a target belief blueprint. Crucially, RELIEF completely bypasses the need for reasoning-trace supervision. It internalizes desired traits by fine-tuning on synthesized, self-reflective question-answering pairs that affirm the target belief. Extensive experiments on efficiency and faithfulness tasks demonstrate that RELIEF matches or outperforms behavior-supervised and preference-based baselines while requiring lower training costs. Further analysis validates that shifting a model's reasoning belief effectively shapes its actual behavior.

</details>


### [484] [DARC: Decoupled Asymmetric Reasoning Curriculum for LLM Evolution](https://arxiv.org/abs/2601.13761)
*Shengda Fan,Xuyan Ye,Yankai Lin*

Main category: cs.AI

TL;DR: DARC通过两阶段解耦框架（Questioner难度校准训练+Solver非对称自蒸馏）解决了自演优化不稳定问题，显著提升推理性能且无需人工标注。


<details>
  <summary>Details</summary>
Motivation: 现有的自演框架存在优化不稳定的问题，主要源于（i）依赖于求解器的奖励反馈导致的非平稳目标，以及（ii）自生成伪标签带来的自举误差。

Method: DARC采用两阶段框架：首先训练Questioner生成难度校准的问题，其次通过非对称自蒸馏机制训练Solver，利用文档增强的教师模型生成高质量伪标签来监督学生Solver。

Result: DARC在九个推理基准测试和三个骨干模型上平均提升了10.9分，表现优于所有基线方法，且接近完全监督模型的性能。

Conclusion: DARC框架通过解耦非对称推理课程，显著提升了自演化的稳定性，并在多个推理基准测试中取得了平均10.9分的提升，接近完全监督模型的性能，且无需依赖人工标注。

Abstract: Self-play with large language models has emerged as a promising paradigm for achieving self-improving artificial intelligence. However, existing self-play frameworks often suffer from optimization instability, due to (i) non-stationary objectives induced by solver-dependent reward feedback for the Questioner, and (ii) bootstrapping errors from self-generated pseudo-labels used to supervise the Solver. To mitigate these challenges, we introduce DARC (Decoupled Asymmetric Reasoning Curriculum), a two-stage framework that stabilizes the self-evolution process. First, we train the Questioner to synthesize difficulty-calibrated questions, conditioned on explicit difficulty levels and external corpora. Second, we train the Solver with an asymmetric self-distillation mechanism, where a document-augmented teacher generates high-quality pseudo-labels to supervise the student Solver that lacks document access. Empirical results demonstrate that DARC is model-agnostic, yielding an average improvement of 10.9 points across nine reasoning benchmarks and three backbone models. Moreover, DARC consistently outperforms all baselines and approaches the performance of fully supervised models without relying on human annotations.The code is available at https://github.com/RUCBM/DARC.

</details>


### [485] [Look-Ahead-Bench: a Standardized Benchmark of Look-ahead Bias in Point-in-Time LLMs for Finance](https://arxiv.org/abs/2601.13770)
*Mostapha Benhenda*

Main category: cs.AI

TL;DR: Look-Ahead-Bench是一个评估金融LLMs前瞻偏见的标准化基准，结果显示PiT模型优于标准LLMs，适合实际部署。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要通过问答测试内部前瞻知识，本研究旨在评估模型在实际场景中的行为，区分真实预测能力与基于记忆的表现。

Method: 通过分析不同时间市场制度下的性能衰减，结合多个量化基线来建立性能阈值，评估开源LLMs与PiT-LLMs的表现。

Result: 结果显示标准LLMs存在显著的前瞻偏见，而PiT模型随着规模扩大展现出更好的泛化和推理能力。

Conclusion: 本研究为金融领域LLMs的时间偏见标准化评估奠定了基础，并提供了一个识别适合实际部署模型的实用框架。

Abstract: We introduce Look-Ahead-Bench, a standardized benchmark measuring look-ahead bias in Point-in-Time (PiT) Large Language Models (LLMs) within realistic and practical financial workflows. Unlike most existing approaches that primarily test inner lookahead knowledge via Q\\&A, our benchmark evaluates model behavior in practical scenarios. To distinguish genuine predictive capability from memorization-based performance, we analyze performance decay across temporally distinct market regimes, incorporating several quantitative baselines to establish performance thresholds. We evaluate prominent open-source LLMs -- Llama 3.1 (8B and 70B) and DeepSeek 3.2 -- against a family of Point-in-Time LLMs (Pitinf-Small, Pitinf-Medium, and frontier-level model Pitinf-Large) from PiT-Inference. Results reveal significant lookahead bias in standard LLMs, as measured with alpha decay, unlike Pitinf models, which demonstrate improved generalization and reasoning abilities as they scale in size. This work establishes a foundation for the standardized evaluation of temporal bias in financial LLMs and provides a practical framework for identifying models suitable for real-world deployment. Code is available on GitHub: https://github.com/benstaf/lookaheadbench

</details>


### [486] [Virtual Urbanism: An AI-Driven Framework for Quantifying Urban Identity. A Tokyo-Based Pilot Study Using Diffusion-Generated Synthetic Environments](https://arxiv.org/abs/2601.13846)
*Glinskaya Maria*

Main category: cs.AI

TL;DR: VU框架通过AI生成合成城市序列，量化都市身份，实验验证其有效性，并识别核心身份元素。


<details>
  <summary>Details</summary>
Motivation: 旨在通过合成城市复制品推进计算上可处理的都市身份度量。

Method: 研究整合了Stable Diffusion和LoRA模型，生成东京九个区域的动态合成城市序列，并通过人类评估实验验证了复制品的感知合法性、区域身份量化及核心身份形成元素。

Result: 结果显示平均识别准确率约为81%，验证了复制品的有效性。Urban Identity Level (UIL) 指标能够评估不同区域的身份水平，语义分析揭示了文化嵌入的类型学作为核心身份形成元素。

Conclusion: Virtual Urbanism (VU) 被证实为一种可行的AI增强城市分析框架，为自动化、多参数的城市身份度量提供了路径。

Abstract: This paper introduces Virtual Urbanism (VU), a multimodal AI-driven analytical framework for quantifying urban identity through the medium of synthetic urban replicas. The framework aims to advance computationally tractable urban identity metrics. To demonstrate feasibility, the pilot study Virtual Urbanism and Tokyo Microcosms is presented. A pipeline integrating Stable Diffusion and LoRA models was used to produce synthetic replicas of nine Tokyo areas rendered as dynamic synthetic urban sequences, excluding existing orientation markers to elicit core identity-forming elements. Human-evaluation experiments (I) assessed perceptual legitimacy of replicas; (II) quantified area-level identity; (III) derived core identity-forming elements. Results showed a mean identification accuracy of ~81%, confirming the validity of the replicas. Urban Identity Level (UIL) metric enabled assessment of identity levels across areas, while semantic analysis revealed culturally embedded typologies as core identity-forming elements, positioning VU as a viable framework for AI-augmented urban analysis, outlining a path toward automated, multi-parameter identity metrics.

</details>


### [487] [LifeAgentBench: A Multi-dimensional Benchmark and Agent for Personal Health Assistants in Digital Health](https://arxiv.org/abs/2601.13880)
*Ye Tian,Zihao Wang,Onat Gungor,Xiaoran Fan,Tajana Rosing*

Main category: cs.AI

TL;DR: LifeAgentBench是一个用于评估LLM在健康助理领域表现的大规模QA基准测试，通过系统评估发现关键瓶颈，并提出了改进的LifeAgent基线代理。


<details>
  <summary>Details</summary>
Motivation: 当前LLM在个性化数字健康支持中的能力尚不明确，缺乏系统性基准测试。LifeAgentBench旨在填补这一空白，评估LLM在长时程、跨维度健康推理中的表现。

Method: 引入了LifeAgentBench，一个包含22,573个问题的大规模QA基准测试，覆盖从基础检索到复杂推理的多种任务。提出了一个可扩展的基准构建流程和标准化评估协议。

Result: 系统评估了11个领先的LLM，发现长时程聚合和跨维度推理是主要瓶颈。提出的LifeAgent基线代理显著优于两个广泛使用的基线。

Conclusion: LifeAgentBench作为一个大规模QA基准测试，为评估LLM在健康助理领域的表现提供了可靠和可扩展的方法。LifeAgent通过整合多步证据检索与确定性聚合，显著提升了性能，展示了在实际生活场景中的潜力。

Abstract: Personalized digital health support requires long-horizon, cross-dimensional reasoning over heterogeneous lifestyle signals, and recent advances in mobile sensing and large language models (LLMs) make such support increasingly feasible. However, the capabilities of current LLMs in this setting remain unclear due to the lack of systematic benchmarks. In this paper, we introduce LifeAgentBench, a large-scale QA benchmark for long-horizon, cross-dimensional, and multi-user lifestyle health reasoning, containing 22,573 questions spanning from basic retrieval to complex reasoning. We release an extensible benchmark construction pipeline and a standardized evaluation protocol to enable reliable and scalable assessment of LLM-based health assistants. We then systematically evaluate 11 leading LLMs on LifeAgentBench and identify key bottlenecks in long-horizon aggregation and cross-dimensional reasoning. Motivated by these findings, we propose LifeAgent as a strong baseline agent for health assistant that integrates multi-step evidence retrieval with deterministic aggregation, achieving significant improvements compared with two widely used baselines. Case studies further demonstrate its potential in realistic daily-life scenarios. The benchmark is publicly available at https://anonymous.4open.science/r/LifeAgentBench-CE7B.

</details>


### [488] [Human Simulation Computation: A Human-Inspired Framework for Adaptive AI Systems](https://arxiv.org/abs/2601.13887)
*Hong Su*

Main category: cs.AI

TL;DR: HSC框架通过模拟人类闭环推理过程，增强语言模型在现实环境中的适应性和交互能力。


<details>
  <summary>Details</summary>
Motivation: 现有大型语言模型仅依赖文本数据，限制了其在开放动态现实环境中的适应性和推理验证能力。

Method: 提出了Human Simulation Computation (HSC)框架，模拟人类的连续闭环推理过程，包括思考、行动、学习、反思和活动调度。

Result: 通过理论分析表明，人类模拟策略无法仅从语言材料中学习，需要人类式推理过程和基于行动的推理方法。

Conclusion: HSC框架提出了一种受人类启发的计算模型，强调通过闭环的内部推理过程和与环境的互动来增强语言模型的适应性和交互能力。

Abstract: Large language models (LLMs) have demonstrated strong capabilities in knowledge representation and reasoning based on textual data. However, their reliance on language material alone limits their ability to adapt, verify reasoning outcomes, and operate effectively in open and dynamic real-world environments. In this paper, we propose Human Simulation Computation (HSC), a human-inspired computational framework that models intelligence as a continuous, closed-loop process involving thinking, action, learning, reflection, and activity scheduling, collectively referred to as the internal reasoning process. HSC emphasizes active participation both within the internal reasoning process and in interactions with the environment, where actions are used not only to achieve goals but also to automatically refine and improve internal reasoning mechanisms without external intervention. Furthermore, HSC incorporates commonly used human thinking strategies across all stages of the internal reasoning process, such as main-feature-oriented reasoning, scope expansion through action, and on-time learning driven by environmental feedback. Through theoretical analysis, we argue that human simulation strategies cannot be fully learned from language material alone, and that human-like reasoning processes and action-grounded reasoning methods are essential for robust adaptation and effective interaction with real-world environments.

</details>


### [489] [PREFAB: PREFerence-based Affective Modeling for Low-Budget Self-Annotation](https://arxiv.org/abs/2601.13904)
*Jaeyoung Moon,Youjin Choi,Yucheon Park,David Melhart,Georgios N. Yannakakis,Kyung-Joong Kim*

Main category: cs.AI

TL;DR: PREFAB是一种低预算回顾性自注释方法，通过偏好学习模型和预览机制，有效减轻注释负担并保持质量。


<details>
  <summary>Details</summary>
Motivation: 现有情感计算中的自注释方法通常需要用户在整个会话过程中连续标记情感状态，虽然能获得细粒度数据，但耗时、认知负荷高且易疲劳和出错。PREFAB旨在解决这些问题。

Method: PREFAB基于峰值-结束规则和情感的有序表示，采用偏好学习模型检测相对情感变化，仅选择部分片段进行注释，其余部分通过插值处理。此外，还引入了预览机制提供上下文提示辅助注释。

Result: 技术性能研究和25名参与者的用户研究表明，PREFAB在建模情感变化方面优于基线方法，同时减轻了工作负担（并在某些情况下减轻了时间负担），且提高了注释者的信心而不降低注释质量。

Conclusion: PREFAB是一种有效的低预算回顾性自注释方法，通过针对情感变化区域而非完整注释，减轻了注释者的工作负担，同时保持了注释质量。

Abstract: Self-annotation is the gold standard for collecting affective state labels in affective computing. Existing methods typically rely on full annotation, requiring users to continuously label affective states across entire sessions. While this process yields fine-grained data, it is time-consuming, cognitively demanding, and prone to fatigue and errors. To address these issues, we present PREFAB, a low-budget retrospective self-annotation method that targets affective inflection regions rather than full annotation. Grounded in the peak-end rule and ordinal representations of emotion, PREFAB employs a preference-learning model to detect relative affective changes, directing annotators to label only selected segments while interpolating the remainder of the stimulus. We further introduce a preview mechanism that provides brief contextual cues to assist annotation. We evaluate PREFAB through a technical performance study and a 25-participant user study. Results show that PREFAB outperforms baselines in modeling affective inflections while mitigating workload (and conditionally mitigating temporal burden). Importantly PREFAB improves annotator confidence without degrading annotation quality.

</details>


### [490] [Autonomous Knowledge Graph Exploration with Adaptive Breadth-Depth Retrieval](https://arxiv.org/abs/2601.13969)
*Joaquín Polonuer,Lucas Vittor,Iñaki Arango,Ayush Noori,David A. Clifton,Luciano Del Corro,Marinka Zitnik*

Main category: cs.AI

TL;DR: ARK是一种自适应知识图谱检索方法，结合全局搜索与邻域探索，动态调整策略以优化检索效果，并通过模仿学习实现小模型的高效迁移。


<details>
  <summary>Details</summary>
Motivation: 解决现有知识图谱检索方法在覆盖广度和多跳遍历深度之间的权衡问题，避免因种子选择不当或查询跨越多实体关系而失败。

Method: ARK采用两阶段工具集（全局词汇搜索和一跳邻域探索），动态平衡广度与深度检索，无需依赖脆弱的种子选择或预设跳数。

Result: 在STaRK上，ARK的平均Hit@1达到59.1%，MRR达到67.4，显著优于其他无训练检索方法；通过模仿学习，8B模型在多个数据集上性能接近教师模型。

Conclusion: ARK通过动态调整检索策略（广度优先搜索与深度优先探索的结合），显著提升了知识图谱检索的准确性和效率，并通过无标签模仿学习将大模型的能力迁移到小模型中，保持了高性能。

Abstract: Retrieving evidence for language model queries from knowledge graphs requires balancing broad search across the graph with multi-hop traversal to follow relational links. Similarity-based retrievers provide coverage but remain shallow, whereas traversal-based methods rely on selecting seed nodes to start exploration, which can fail when queries span multiple entities and relations. We introduce ARK: Adaptive Retriever of Knowledge, an agentic KG retriever that gives a language model control over this breadth-depth tradeoff using a two-operation toolset: global lexical search over node descriptors and one-hop neighborhood exploration that composes into multi-hop traversal. ARK alternates between breadth-oriented discovery and depth-oriented expansion without depending on a fragile seed selection, a pre-set hop depth, or requiring retrieval training. ARK adapts tool use to queries, using global search for language-heavy queries and neighborhood exploration for relation-heavy queries. On STaRK, ARK reaches 59.1% average Hit@1 and 67.4 average MRR, improving average Hit@1 by up to 31.4% and average MRR by up to 28.0% over retrieval-based and agentic training-free methods. Finally, we distill ARK's tool-use trajectories from a large teacher into an 8B model via label-free imitation, improving Hit@1 by +7.0, +26.6, and +13.5 absolute points over the base 8B model on AMAZON, MAG, and PRIME datasets, respectively, while retaining up to 98.5% of the teacher's Hit@1 rate.

</details>


### [491] [Numina-Lean-Agent: An Open and General Agentic Reasoning System for Formal Mathematics](https://arxiv.org/abs/2601.14027)
*Junqi Liu,Zihao Zhou,Zekai Zhu,Marco Dos Santos,Weikun He,Jiawei Liu,Ran Wang,Yunzhou Xie,Junqiao Zhao,Qiufeng Wang,Lihong Zhi,Jia Li,Wenda Li*

Main category: cs.AI

TL;DR: 该论文提出通用编码代理作为形式数学推理的新范式，通过 Numina-Lean-Agent 实现高性能自主证明，并在基准测试和实际案例中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 通用编码代理为形式数学推理提供了自然接口，无需训练即可通过替换基础模型提升性能，且能灵活扩展工具调用。

Method: 基于通用编码代理范式，引入 Numina-Lean-Agent，结合 Claude Code 与 Numina-Lean-MCP，实现自主工具调用与扩展。

Result: Numina-Lean-Agent 在 Putnam 2025 中解决了全部问题（12/12），并与数学家合作成功形式化了 Brascamp-Lieb 定理。

Conclusion: Numina-Lean-Agent 通过结合 Claude Code 和 Numina-Lean-MCP，成功实现了与 Lean 的自主交互、相关定理检索及非正式证明，展示了其在形式数学推理中的强大能力。

Abstract: Agentic systems have recently become the dominant paradigm for formal theorem proving, achieving strong performance by coordinating multiple models and tools. However, existing approaches often rely on task-specific pipelines and trained formal provers, limiting their flexibility and reproducibility. In this paper, we propose the paradigm that directly uses a general coding agent as a formal math reasoner. This paradigm is motivated by (1) A general coding agent provides a natural interface for diverse reasoning tasks beyond proving, (2) Performance can be improved by simply replacing the underlying base model, without training, and (3) MCP enables flexible extension and autonomous calling of specialized tools, avoiding complex design. Based on this paradigm, we introduce Numina-Lean-Agent, which combines Claude Code with Numina-Lean-MCP to enable autonomous interaction with Lean, retrieval of relevant theorems, informal proving and auxiliary reasoning tools. Using Claude Opus 4.5 as the base model, Numina-Lean-Agent solves all problems in Putnam 2025 (12 / 12), matching the best closed-source system. Beyond benchmark evaluation, we further demonstrate its generality by interacting with mathematicians to successfully formalize the Brascamp-Lieb theorem. We release Numina-Lean-Agent and all solutions at https://github.com/project-numina/numina-lean-agent.

</details>


### [492] [Remapping and navigation of an embedding space via error minimization: a fundamental organizational principle of cognition in natural and artificial systems](https://arxiv.org/abs/2601.14096)
*Benedikt Hartl,Léo Pio-Lopez,Chris Fields,Michael Levin*

Main category: cs.AI

TL;DR: 本文提出认知的统一框架，通过嵌入空间的重映射和导航揭示生物与AI系统的深层相似性。


<details>
  <summary>Details</summary>
Motivation: 探索不同来源、组成和基质的智能体在问题解决中的统一视角，发现决策的尺度不变原则。

Method: 提出了一个双原则框架，即通过嵌入空间的重映射和导航来表征和理解自然与合成系统中的认知。

Result: 揭示了生物集体和现代AI系统在重映射和导航嵌入空间方面的深层相似性。

Conclusion: 本文认为，通过迭代误差最小化实现嵌入空间的重映射和导航，是认知的基质独立不变性，为跨尺度的适应性智能工程提供了统一框架。

Abstract: The emerging field of diverse intelligence seeks an integrated view of problem-solving in agents of very different provenance, composition, and substrates. From subcellular chemical networks to swarms of organisms, and across evolved, engineered, and chimeric systems, it is hypothesized that scale-invariant principles of decision-making can be discovered. We propose that cognition in both natural and synthetic systems can be characterized and understood by the interplay between two equally important invariants: (1) the remapping of embedding spaces, and (2) the navigation within these spaces. Biological collectives, from single cells to entire organisms (and beyond), remap transcriptional, morphological, physiological, or 3D spaces to maintain homeostasis and regenerate structure, while navigating these spaces through distributed error correction. Modern Artificial Intelligence (AI) systems, including transformers, diffusion models, and neural cellular automata enact analogous processes by remapping data into latent embeddings and refining them iteratively through contextualization. We argue that this dual principle - remapping and navigation of embedding spaces via iterative error minimization - constitutes a substrate-independent invariant of cognition. Recognizing this shared mechanism not only illuminates deep parallels between living systems and artificial models, but also provides a unifying framework for engineering adaptive intelligence across scales.

</details>


### [493] [Paper2Rebuttal: A Multi-Agent Framework for Transparent Author Response Assistance](https://arxiv.org/abs/2601.14171)
*Qianli Ma,Chang Guo,Zhiheng Tian,Siyu Wang,Jipeng Xiao,Yuanhao Yue,Zhipeng Zhang*

Main category: cs.AI

TL;DR: RebuttalAgent是多智能体框架，通过证据驱动的规划生成反驳信，解决了现有方案的幻觉和缺乏 grounding问题，实验显示其性能优于基线。


<details>
  <summary>Details</summary>
Motivation: 现有反驳信生成方案存在幻觉、忽视批评和缺乏可验证基础的问题，需一种更精准对齐审稿人意图与稿件细节的方法。

Method: 引入多智能体框架RebuttalAgent，将反驳信生成重构为证据驱动的规划任务，包括分解复杂反馈为原子问题、动态构建混合上下文（结合压缩摘要与高保真文本），并集成自主按需的外部搜索模块。

Result: 在RebuttalBench上的验证表明，RebuttalAgent在覆盖性、忠实性和策略一致性上优于基线模型。

Conclusion: RebuttalAgent通过证据驱动的规划任务，显著提升了反驳信生成的覆盖性、忠实性和策略一致性，为同行评审提供了透明且可控的辅助工具。

Abstract: Writing effective rebuttals is a high-stakes task that demands more than linguistic fluency, as it requires precise alignment between reviewer intent and manuscript details. Current solutions typically treat this as a direct-to-text generation problem, suffering from hallucination, overlooked critiques, and a lack of verifiable grounding. To address these limitations, we introduce $\textbf{RebuttalAgent}$, the first multi-agents framework that reframes rebuttal generation as an evidence-centric planning task. Our system decomposes complex feedback into atomic concerns and dynamically constructs hybrid contexts by synthesizing compressed summaries with high-fidelity text while integrating an autonomous and on-demand external search module to resolve concerns requiring outside literature. By generating an inspectable response plan before drafting, $\textbf{RebuttalAgent}$ ensures that every argument is explicitly anchored in internal or external evidence. We validate our approach on the proposed $\textbf{RebuttalBench}$ and demonstrate that our pipeline outperforms strong baselines in coverage, faithfulness, and strategic coherence, offering a transparent and controllable assistant for the peer review process. Code will be released.

</details>


### [494] [Toward Efficient Agents: Memory, Tool learning, and Planning](https://arxiv.org/abs/2601.14192)
*Xiaofang Yang,Lijun Li,Heng Zhou,Tong Zhu,Xiaoye Qu,Yuchen Fan,Qianshan Wei,Rui Ye,Li Kang,Yiran Qin,Zhiqiang Kou,Daizong Liu,Qi Li,Ning Ding,Siheng Chen,Jing Shao*

Main category: cs.AI

TL;DR: 本文研究了智能代理系统的效率问题，从内存、工具学习和规划三个核心组件出发，提出了效率评估方法，并探讨了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型向智能代理系统的扩展，效率问题（对实际部署至关重要）往往被忽视。因此，本文旨在填补这一研究空白，全面探讨智能代理系统本身的效率。

Method: 本文从智能代理系统的三个核心组件（内存、工具学习和规划）出发，全面研究了效率问题，包括延迟、代币、步骤等成本因素。通过综述多种方法，总结了共享的高层原则，并详细讨论了这些原则的应用。

Result: 研究提出了两种互补的效率评估方法：固定成本预算下的有效性比较，以及同等有效性水平下的成本比较。此外，还通过帕累托前沿分析了效率与成本的权衡，并总结了评估协议和常用效率指标。

Conclusion: 本文总结了智能代理系统效率研究的现状，提出了评估效率的两种互补方法，并探讨了未来的研究方向，旨在为这一领域提供有价值的见解。

Abstract: Recent years have witnessed increasing interest in extending large language models into agentic systems. While the effectiveness of agents has continued to improve, efficiency, which is crucial for real-world deployment, has often been overlooked. This paper therefore investigates efficiency from three core components of agents: memory, tool learning, and planning, considering costs such as latency, tokens, steps, etc. Aimed at conducting comprehensive research addressing the efficiency of the agentic system itself, we review a broad range of recent approaches that differ in implementation yet frequently converge on shared high-level principles including but not limited to bounding context via compression and management, designing reinforcement learning rewards to minimize tool invocation, and employing controlled search mechanisms to enhance efficiency, which we discuss in detail. Accordingly, we characterize efficiency in two complementary ways: comparing effectiveness under a fixed cost budget, and comparing cost at a comparable level of effectiveness. This trade-off can also be viewed through the Pareto frontier between effectiveness and cost. From this perspective, we also examine efficiency oriented benchmarks by summarizing evaluation protocols for these components and consolidating commonly reported efficiency metrics from both benchmark and methodological studies. Moreover, we discuss the key challenges and future directions, with the goal of providing promising insights.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [495] [Reinforcement Learning for Dynamic Workflow Optimization in CI/CD Pipelines](https://arxiv.org/abs/2601.11647)
*Aniket Abhishek Soni,Milan Parikh,Rashi Nimesh Kumar Dhenia,Jubin Abhishek Soni,Ayush Raj Jha,Sneja Mitinbhai Shah*

Main category: cs.SE

TL;DR: 论文提出用强化学习动态优化CI/CD管道，实验显示吞吐量提升30%，测试时间减少25%，缺陷率低于5%。


<details>
  <summary>Details</summary>
Motivation: 现代软件交付中，CI/CD管道的静态工作流在系统扩展时常常引入低效问题，因此需要动态优化方法。

Method: 论文提出了一种基于强化学习的方法，将CI/CD管道建模为马尔可夫决策过程，并训练RL代理在运行时做出决策（如选择完整、部分或不执行测试），以最大化吞吐量并最小化测试开销。开发了一个可配置的CI/CD模拟环境来评估该方法。

Result: 实验结果显示，RL优化的管道在吞吐量上提高了30%，测试执行时间减少了约25%，同时缺陷遗漏率保持在5%以下。代理学会选择性跳过或简化低风险提交的测试，加速反馈周期而不显著增加失败风险。

Conclusion: 该论文展示了强化学习在优化CI/CD管道工作流中的潜力，提供了一条实现更高效、弹性和可持续的CI/CD自动化的实用途径。

Abstract: Continuous Integration and Continuous Deployment (CI/CD) pipelines are central to modern software delivery, yet their static workflows often introduce inefficiencies as systems scale. This paper proposes a reinforcement learning (RL) based approach to dynamically optimize CI/CD pipeline workflows. The pipeline is modeled as a Markov Decision Process, and an RL agent is trained to make runtime decisions such as selecting full, partial, or no test execution in order to maximize throughput while minimizing testing overhead.
  A configurable CI/CD simulation environment is developed to evaluate the approach across build, test, and deploy stages. Experimental results show that the RL optimized pipeline achieves up to a 30 percent improvement in throughput and approximately a 25 percent reduction in test execution time compared to static baselines, while maintaining a defect miss rate below 5 percent. The agent learns to selectively skip or abbreviate tests for low risk commits, accelerating feedback cycles without significantly increasing failure risk.
  These results demonstrate the potential of reinforcement learning to enable adaptive and intelligent DevOps workflows, providing a practical pathway toward more efficient, resilient, and sustainable CI/CD automation.

</details>


### [496] [Advances and Frontiers of LLM-based Issue Resolution in Software Engineering: A Comprehensive Survey](https://arxiv.org/abs/2601.11655)
*Caihua Li,Lianghong Guo,Yanlin Wang,Daya Guo,Wei Tao,Zhenyu Shan,Mingwei Liu,Jiachi Chen,Haoyu Song,Duyu Tang,Hongyu Zhang,Zibin Zheng*

Main category: cs.SE

TL;DR: 本文系统调查了问题解决领域，分析了数据构建、方法论、数据质量和代理行为，并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 问题解决是软件工程中的一项复杂任务，对人工智能构成挑战，促使了自主编码代理的快速发展。

Method: 系统调查了问题解决领域，包括数据构建管道、方法论分析（训练免费框架和基于训练的技术）、数据质量和代理行为分析。

Result: 提供了对新兴领域的全面分析，包括方法论、数据质量和实际应用，并维护了一个开源资源库。

Conclusion: 本文总结了问题解决领域的关键挑战，并提出了未来研究的潜在方向。

Abstract: Issue resolution, a complex Software Engineering (SWE) task integral to real-world development, has emerged as a compelling challenge for artificial intelligence. The establishment of benchmarks like SWE-bench revealed this task as profoundly difficult for large language models, thereby significantly accelerating the evolution of autonomous coding agents. This paper presents a systematic survey of this emerging domain. We begin by examining data construction pipelines, covering automated collection and synthesis approaches. We then provide a comprehensive analysis of methodologies, spanning training-free frameworks with their modular components to training-based techniques, including supervised fine-tuning and reinforcement learning. Subsequently, we discuss critical analyses of data quality and agent behavior, alongside practical applications. Finally, we identify key challenges and outline promising directions for future research. An open-source repository is maintained at https://github.com/DeepSoftwareAnalytics/Awesome-Issue-Resolution to serve as a dynamic resource in this field.

</details>


### [497] [The Llama 4 Herd: Architecture, Training, Evaluation, and Deployment Notes](https://arxiv.org/abs/2601.11659)
*Aaron Adcock,Aayushi Srivastava,Abhimanyu Dubey,Abhinav Jauhri,Abhinav Pande,Abhinav Pandey,Abhinav Sharma,Abhishek Kadian,Abhishek Kumawat,Adam Kelsey,Adam Stelle,Adeel Cheema,Adela Kabiljo,Adina Katz,Adithya Gangidi,Aditya Tayade,Adolfo Victoria,Adrian Samatan Alastuey,Adrien Conrath,Afroz Mohiuddin,Ahmed Sharif,Ahnaf Siddiqui,Ahuva Goldstand,Aijung Li,Aidan Boyd,Aidin Kazemi Daliri,Aisha Iqbal,Ajay Menon,Ajit Mathews,Akhil Mathur,Akshat Agarwal,Alan Schelten,Alana Shine,Alejandro Castillejo Muñoz,Aleksei Guliaev,Alex Radovic,Alex Song,Alex Vaughan,Alexander Simeonov,Alexandre Rezende,Alexandre Rezende,Alexei Baevski,Alexey Roubaud,Allen Ma,Alvin Lee,Alyssa Pereira,Aman Ahmed,Aman Shankar,Amanda Kallet,Amar Budhiraja,Ameya Khandekar,Amine Benhalloum,Amir Gershman,Amit Nagpal,Amit Zohar,Amr Sharaf,Anant Desai,Anastasia Razdaibiedina,Anca Agape,Andranik Kurghinyan,Andre Perunicic,Andrea Madotto,Andrei Darabanov,Andrés Alvarado,Andrew Brown,Andrew Cohen,Andrew Fang,Andrew Freeman,Andrew Gallagher,Andrew Gu,Andrew Prasetyo Jo,Andrew Ryan,Andrew Steffen,Andrew Wei,Andrey Rusakov,Andrii Golovei,Andy Shang,Angela Fan,Angela Fan,Angela Flewellen,Animesh Pathak,Anirudh Goyal,Ankit Ramchandani,Ankur Pai,Ankur Singh,Ankush Garg,Anlu Xing,Anna Cai,Anna Grosul,Anna Prochowska,Anna Sun,Annie Dong,Annie Franco,Anqi Hu,Anshul Chawla,Anthony Hartshorn,Antonia Sheng,Antony Thomas,Anuj Goyal,Anusha De,Anvit Bodiwala,Anvit Bodiwala,Aobo Yang,Aparajita Saraf,Apurva Samudra,Aran Mun,Arash Rahnama,Archi Mitra,Archie Sravankumar,Archit Gupta,Aria Haghighi,Ariel Stolerman,Arkabandhu Chowdhury,Arnab Choudhury,Artem Korenev,Arthur Guo,Arthur Hinsvark,Arun Mallya,Arvind Neelakantan,Arya Talebzadeh,Ashish Shah,Ashmitha Jeevaraj Shetty,Ashwin Bharambe,Asif Islam,Aston Zhang,Austen Gregerson,Avi Lewis,Aya Ibrahim,Ayaz Minhas,Ayelet Dahan,Ayelet Regev Dabah,Bangsheng Tang,Bar Ulman,Bardiya Sadeghi,Bartosz Jedrzejewski,Barys Skarabahaty,Beibei Zhu,Beibin Li,Ben Bharier,Benjamin Leonhardi,Benjamin Muller,Bennett Plessala,Bernie Huang,Beth Loyd,Bhargavi Paranjape,Bhavik Sheth,Bill Bonner,Bill Holland,Bill Wang,Bingzhe Liu,Binh Tang,Bo Liu,Bo Wu,Boduo Li,Bokai Yu,Bor-Chun Chen,Boris Araya,Boris Vidolov,Botao Chen,Boya Peng,Boyu Ni,Bradley Davis,Bram Wasti,Brandon Adams,Brandon Taylor,Brandon Wu,Brant Swidler,Brian Chiang,Brian Clerkin,Brian Fuller,Brooks Cutter,Bruno Novais,Bryan Gmyrek,Bysshe Easton,Cait Campos,Canaan Case,Carl Chengyan Fu,Carly Burton,Caro Diaz,Catherine Cole,Ce Liu,Cedric Fougerat,Cen Peng,Cen Peng,Cen Zhao,Changhan Wang,Changkyu Kim,Chantal Shaib,Chao Zhou,Charlotte Caucheteux,Chau Nguyen,Chawin Sitawarin,Chaya Nayak,Chelsea Asher,Chen Fan,Chen Zhu,Cheng Cheng,Cheng Zhang,Chenguang Zhu,Chengxiong Ruan,Chengzhu Yu,Chenheli Hua,Chenxi Whitehouse,Cheryl Holloway,Ching-Hsiang Chu,Ching-Yao Chuang,Chinmay Karande,Chirag Nagpal,Chloé Bakalar,Chloe Bi,Chris Cai,Chris Marra,Chris McConnell,Chris Thi,Chris Tindal,Chris Waterson,Christian Deverall,Christian Fuegen,Christian Keller,Christine Cheng,Christine Jou,Christine Smith,Christine Wang,Christoph Feichtenhofer,Christophe Touret,Christopher Luc,Christy Sauper,Chuanhao Zhuge,Chun-Yi Sung,Chunqiang Tang,Chunyang Wu,Clara Siegel,Cody Heale,Cody Wilbourn,Colin White,Congying Xia,Corinne Wong,Cornel Rat,Cristian Canton Ferrer,Cyrille Habis,Cyrus Nikolaidis,D Lohachov,Da Ju,Dalton Flanagan,Damien Allonsius,Damon Civin,Dan Johnson,Daniel Bolya,Daniel Francisco,Daniel Fried,Daniel Hawthorne,Daniel Haziza,Daniel Ho,Daniel Kreymer,Daniel Li,Daniel Machlab,Daniel McKinnon,Daniel Obenshain,Daniel Rodriguez,Daniel Song,Daniel Tse,Danielle Pintz,Danny Livshits,Daryl James Rodrigo,Dat Huynh,Daulet Askarov,David Brandfonbrener,David Esiobu,David Kant,David Levin,David Renardy,David Soofian,David Stevens,David Xu,David Zhang,Deep Shah,Delia David,Demi Douglas,Denis Boyda,Desh Raj,Devamanyu Hazarika,Dheeraj Mekala,Dhruv Choudhary,Dhruv Mahajan,Di Jin,Didac Suris Coll-Vinent,Didem Foss,Diego Garcia-Olano,Diego Perino,Dieuwke Hupkes,DiJia Su,Dilip Madathil,Dinesh Govindasamy,Dinesh Yeduguru,Dmitry Vengertsev,Dong He,Dong Li,Dong Wang,Dongzhuo Li,Duc Le,Dunant Hin,Dustin Holland,Duy Nguyen,Duy Nguyen,Ed Dowling,Eden Litt,Egor Lakomkin,Ehab AlBadawy,Ehsan K. Ardestani,Elad Eckstein,Elahe Dabir,Elaine Montgomery,Elina Lobanova,Elior Abramoviz,Eliot Hedeman,Elissa Li,Elizabeth Hilbert,Ellen Xiaoqing Tan,Elliot Yun,Elodie Stener,Emilian Stoimenov,Emilien Garreau,Emily Dinan,Emily Hahn,Emily Wood,Emma Li,Emmanuel Ademuwagun,Emrah Seker,Eric Alamillo,Eric Gan,Eric Han,Eric Huang,Eric Michael Smith,Eric-Tuan Le,Ernie Chang,Eryk Helenowski,Eslam Elnikety,Esteban Arcaute,Ethan Myers,Eugene Nho,Eugene Poliukhovych,Evan Dunbar,Evgeniy Litvinenko,Evrim Altıntaş,Eyal Hochman,Eyal Shtrauch,Fabian Mastenbroek,Faiza Zeb,Faizan Ahmad,Farhad Farahbakhshian,Fei Kou,Fei Sun,Feiyu Chen,Felix Chung,Feng Tian,Feng Xu,Filip Radenovic,Filippos Kokkinos,Francesco Barbieri,Francesco Caggioni,Francisco Esparza,Francisco Guzmán,Frank Kanayet,Frank Seide,Frank Zhang,Fred Lewis,Freda Huang,Fulton Wang,Gabriel Synnaeve,Gabriela Jacques-Silva,Gabriella Schwarz,Gaganjit Ghardhora,Gal Elfer,Garrett Dickson,Gaurav Chaurasia,Gautam Sewani,Geet Shingi,Gefei Zuo,Geonhwa Jeong,George Puthanpurackal,Georgia Swee,Gerard Moreno-Torres Bertran,Gil Keren,Gina Ling,Gjergji Stasa,Gobinda Saha,Gor Safran,Gordy French,Goutham Rajendran,Govind Thattai,Grace Cineas,Graeme Nail,Greg Fletcher,Grégoire Mialon,Griffin Adams,Grigory Sizov,Guan Pang,Hady Elsahar,Hai Dang Tran,Hailey Nguyen,Haiping Wu,Hakan Inan,Hamid Eghbalzadeh,Han Fang,Han Zou,Hannah Doyle,Hannah Korevaar,Hannah Wang,Hannah Werbel,Hanwen Zha,Hany Morsy,Hao Ma,Haoci Zhang,Haonan Sun,Haozhu Wang,Hardik Shah,Haroun Habeeb,Harrison Rudolph,Harsh Gupta,Harsh Poddar,Harshil Parikh,Hejia Zhang,Heming Wang,Hengduo Li,Himanshu Sharma,Hoang Phi Nguyen,Hongbo Zhang,Honghao Qiu,Hongjiang Lv,Hongli Xu,Hongyuan Zhan,Hossein Hamooni,Howard Huang,Hu Xu,Hugo Laurençon,Hugo Touvron,Hung Dinh,Hunter Goldman,Hussein Mehanna,Huy Nguyen,Hweimi Tsuo,Ian Graves,Ian Yu,Ibrahim Damlaj,Idan Cohen,Igor Tufanov,Ilan Goldenstein,Ilias Leontiadis,Iliyan Zarov,Imad Ahmed,Innocent Djiofack,Iosif Spulber,Irina-Elena Veliche,Isabella Ramos,Ishan Misra,Itai Gal,Ivan Evtimov,Ivan Evtimov,Ivan Obraztsov,Jack Wu,Jacqueline Romero Vertino,Jaemo Koo,Jaewon Lee,Jake Jung,Jake Weissman,James Beldock,James Crnkovich,James Grinage,James Hongyi Zeng,James Kohli,James Tian,Jamie Cahill,Jan Geffert,Jan Seidel,Jan Seidel,Janey Tracey,Jang Hyun Cho,Janice Wei,Jarrod Kahn,Jasmyn Howell,Jason Long Vu,Jason Park,Jason Yan,Jason Yip,Jay Li,Jay Mahadeokar,Jaya Bharath R Goluguri,Jayasi Mehar,Jean-Baptiste Gaya,Jeet Shah,Jeff Hanson,Jeff Marcus,Jeff Walsh,Jeff Yang,Jelmer van der Linde,Jemma Fan,Jennifer Chan,Jenny Zhen,Jenya Lee,Jeremy Fu,Jeremy Reizenstein,Jeremy Teboul,Jesse He,Jessica Zhong,Ji Hou,Ji Yang,Jia Ding,Jiabo Hu,Jiacheng Zhu,Jiadong Guo,Jialiang Wang,Jialin Ouyang,Jianfeng Chi,Jianyu Huang,Jianyun Zhao,Jiaowen Yang,Jiatong Zhou,Jiawei Zhao,Jiawen Liu,Jie Wang,Jie You,Jiecao Yu,Jillian Schwiep,Jilong Wu,Jing Huang,Jing Li,Jing Yu Koh,Jing Zhang,Jingxiang Chen,Jingyi Yang,Jingyue Shen,Jinho Hwang,Jinxi Guo,Jiwan Khatiwada,Joanna Bitton,Joe Li,Joe Quanaim,Joel Beales,Johan Schuijt,John Chang,John Quan,Johnnie Chan,Jon Shepard,Jona Harris,Jonah Rubin,Jonathan Janzen,Jonathan Kaldor,Jorge Lopez Silva,Jose Leitao,Joseph Greer,Joseph Moon,Joseph Rocca,Joseph Tighe,Josh Fromm,Joshua Deng,Joshua Fernandes,Joshua Saxe,Joyce Zheng,Juan Pino,Julien Prigent,Jun Chen,Junjiao Tian,Junjie Qi,Junjie Wang,Junteng Jia,Kade Baker,Kai Londenberg,Kai Wang,Kainan Peng,Kaiyan Peng,Kaiyue Yang,Kalyan Vasudev Alwala,Kam Hou Yu,Kanika Narang,Karan Chadha,Karan Sikka,Karen Zhang,Karina Schuberts,Karishma Mandyam,Karthik Abinav Sankararaman,Karthik Padthe,Karthik Prasad,Karthik Sivakumar,Kartikeya Upasani,Kate Plawiak,Kate Saenko,Kateřina Žmolíková,Kathryn Stadler,Kathy Matosich,Katie Doulgass,Kaveh Hassani,Kay Ji,Ke Li,Kenneth Heafield,Kenny Yu,Keqian Li,Kevin Chih-Yao Ma,Kevin Hannan,Keyu Man,Kezhen Chen,Khalid El-Arini,Khrystyna Hutsulyak,Kieran Nash,Kiran Jagadeesh,Kody Bartelt,Konstantin Topaloglou-Mundy,Konstantinos Chatziioannou,Konstantinos Karanasos,Konstantinos Vougioukas,Kostas Tsiampouris,Kristen Hamill,Kristy Choi,Krithika Iyer,Kshitiz Malik,Kuenley Chiu,Kun Huang,Kunal Bhalla,Kunal Chawla,Kunpeng Li,Kushal Lakhotia,Kyle Monk,Lakshya Garg,Lalit Chourey,Lars Hamre,Laura Gustafson,Lauren Deason,Laurence Rouesnel,Laurens van der Maaten,Lavender A,Lawrence Chen,Lawrence Jang,Leandro Silva,Leda Sari,Lee Hetherington,Lei Zhang,Leiyu Zhao,Lele Chen,Leo Chenghui Li,Leon Yang,Leon Zhan,Levi Corallo,Liang Tan,Licheng Yu,Lijuan Liu,Lilach Mor,Lincoln Lin,Linfeng Li,Lisa Titus,Liz Jenkins,Lovish Madaan,Lu Fang,Lu Yuan,Lucas Nava,Lucas Pasqualin,Lucas Switzer,Lucia Fang,Lucy Sun,Luka Tadic,Lukas Blecher,Lukas Landzaat,Luxin Zhang,Madhavi Rao,Madian Khabsa,Mahalia Miller,Mahendra Kariya,Mahesh Pasupuleti,Mahi Luthra,Manaal Faruqui,Manav Avlani,Manchen Wang,Mannat Singh,Manohar Paluri,Manoj Chakkaravarthy,Manoj Nair,Maquelle Tiffany,Marcin Pawlowski,Marcus Wu,Maria Lomeli,Mario Consuegra,Marion Boiteux,Marios Andreas Galanis,Marshall Chen,Martin Gleize,Maryam Fazel-Zarandi,Matan Hasson,Mathew Oldham,Mathieu Rita,Matt Dordal,Matt Setzler,Matt Staats,Matt Staats,Matt Wilde,Matthew Clark,Matthew Grange,Matthew Lennie,Matthew Schmohl,Max Raphael,Maxim Naumov,Maxim Samoylov,Maxime Lecanu,Maya Pavlova,Md Taha Bin Jawaid,Meghan Keneally,Melanie Kambadur,Meng Zhang,Mengchen Liu,Mengdi Lin,Mengjiao Wang,Mervyn Abraham,Miao Liu,Michael Au-Yeung,Michael Feldergraf,Michael Man,Michael Matheny,Michael Suo,Michael Tontchev,Michel Meyer,Michelle Ma,Mihir Patel,Mihir Sanjay Kale,Mik Vyatskov,Mikayla Alexander,Mike Andersland,Mike Clark,Mike Lewis,Mike Li,Mike Macey,Mike Macey,Mike Seltzer,Mikel Jimenez Fernandez,Mikhail Antonov,Mikhail Plekhanov,Milan Zhou,Min Si,Ming Qiao,Mingbo Ma,Mingjun Zhang,Mingyi Liang,Miquel Jubert Hermoso,Mirac Suzgun,Mirjam Skarica,Mitesh Kumar Singh,Mohammad Kabbani,Mohammad Rastegari,Mona Sarantakos,Monica Sim,Monika Gangapuram,Mor Moshe,Morrie Doulaty,Morvarid Metanat,Moya Chen,Mrinal Kumar,Munish Bansal,Murali Ramarao,Na Li,Nadav Azaria,Nahiyan Malik,Naman Goyal,Nancy Vargas Balderas,Nanshu Wang,Naoyuki Kanda,Natalia Gimelshein,Natalia Neverova,Nathan Aclander,Natt Sithiviraporn,Navneet Madhu Kumar,Ned Newton,Neeraj Bahl,Negar Ghorbani,Neil Patel,Neta-lee Golan,Nicholas Longenbaugh,Nick Egebo,Nikhil Johri,Nikhil Mehta,Nikhil Naik,Niko Moritz,Nikolay Bashlykov,Nikolay Bogoychev,Nikolay Pavlovich Laptev,Niladri Chatterji,Nile Jones,Nimish Shah,Ning Dong,Ning Li,Ning Li,Ning Zhang,Nishant Yadav,Noam Paz,Norman Cheng,Norman Cheng,Olaoluwa Adesanya,Oleg Repin,Oleksandr Maksymets,Omkar Salpekar,Omri Harosh,Onkar Pednekar,Onur Çelebi,Oran Gafni,Oren Edinger,Osama Hanna,Owais Khan Mohammed,Ozlem Kalinli,Paden Tomasello,Pankaj Singh,Paola Quevedo,Parag Jain,Paria Rashidinejad,Parker Tooley,Parth Parekh,Parth Thakkar,Parvin Taheri,Pasan Hapuarachchi,Pascal Kesseli,Patrick Alrassy,Paulo de Rezende Pinatti,Pavan Balaji,Pawan Sisodiya,Pedro Jose Ferreira Moreira,Pedro Rittner,Pedro Valenzuela,Peize Sun,Peizhao Zhang,Peng-Jen Chen,Pengchao Wang,Pengchuan Zhang,Pengwei Li,Petar Vasic,Peter Carras,Peter Ney,Peter Weng,Petru Dumea,Phil Hayes,Philip Woods,Pierre Andrews,Pierre Ménard,Ping-Hao Wu,Pingchuan Liu,Piotr Dollar,Plamen Dzhelepov,Polina Zvyagina,Posten A,Prabhav Agrawal,Pradhapan Rajendran,Pradyot Prakash,Prajjwal Bhargava,Pramono,Pranay Shah,Pranshu Dave,Prash Jain,Pratik Dubal,Praveen Gollakota,Praveen Krishnan,Pritish Yuvraj,Projjal Ghosh,Punit Singh Koura,Puxin Xu,Qi Qi,Qi Zhou,Qian Guan,Qian Sun,Qiang Liu,Qing He,Qinqing Zheng,Qirui Yang,Qizhen Guo,Quanzeng You,Quentin Carbonneaux,Quentin Carbonneaux,Quentin Duval,Quintin Fettes,Rachad Alao,Rachel Batish,Rachel Guo,Rachel Rodriguez,Radhika Bhargava,Rafael Asuncion,Raghotham Murthy,Rahul Dutta,Rahul Jha,Rahul Kindi,Rahul Mitra,Raj Ganapathy,Raj Shah,Rajarshi Das,Rajat Shrivastava,Rajesh Nishtala,Ramakant Shankar,Raman Shukhau,Ramon Calderer,Rangaprabhu Parthasarathy,Ranjan Subramanian,Raphael Bensadoun,Rares Bostan,Rashnil Chaturvedi,Ravi Agrawal,Ray Gao,Raymond Li,Rebecca Kogen,Ricardo Juan Palma Duran,Ricardo Silveira Cabral,Richard Lee,Richard Yuanzhe Pang,Riddhish Bhalodia,Riham Mansour,Rishabh Singh,Rishi Godugu,Ritun Patney,Rob Boyle,Robbie Goldfarb,Robert Caldwell,Robert Kuo,Roberta Raileanu,Robin Battey,Robin Sharma,Rochit Sapra,Rocky Wang,Rodolfo Granata,Rodrigo De Castro,Rodrigo Paim,Rohan Maheshwari,Rohan Varma,Rohit Girdhar,Rohit Patel,Roshan Sumbaly,Roy Sheaffer,Ruan Silva,Ruben Rodriguez Buchillon,Rui Hou,Ruiming Xie,Ruslan Mavlyutov,Ruslan Semenov,Rustam Dinov,Ruxiao Bao,Ryan Fox,Ryan Kilpatrick,Ryan Kwan,Ryan Lim,Ryan Smith,Saaketh Narayan,Sabrina Qiao,Sachin Mehta,Sachin Siby,Sagar Jain,Saghar Hosseini,Sagie Gur-Ari,Sahana Chennabasappa,Sahin Geyik,Sai Jayesh Bondu,Sai Mounika Chowdhary Nekkalapudi,Saif Hasan,Saisuke Okabayashi,Saketh Rambhatla,Salil Sawhney,Sam Dunster,Sam Zhao,Saman Keon,Samaneh Azadi,Sameet Sapra,Samuel Dooley,Samyak Datta,Sandeep Parab,Sang Michael Xie,Sanjay Singh,Sanyuan Chen,Sara Behn,Sara Khodeir,Sarah Shirazyan,Sargun Dhillon,Sarunya Pumma,Sasha Sidorov,Saskia Adaime,Saurabh Khanna,Sayem Wani,Scott Brenton,Sean Bell,Sean Kelly,Sean Koger,Sean Nunley,Sean Perry,Sebastian Caicedo,Sebastian Dahlgren,Sebastian Ruder,Seiji Yamamoto,Selam Mehretu,Selvan Sunitha Ravi,Sen Lyu,Senthil Chellapan,Serafeim Mellos,Sergey Edunov,Sergey Royt,Shaina Cohen,Shangfu Peng,Shannon Adams,Shaoliang Nie,Sharadh Ramaswamy,Sharan Narang,Shashank Pisupati,Shashi Gandham,Shaun Lim,Shaun Lindsay,Sheena Artrip,Shelly Sheynin,Shen Yan,Sheng Feng,Sheng Shen,Shengbao Zheng,Shenghao Lin,Shengjie Bi,Shengxin Cindy Zha,Shengye Wan,Shengyi Qian,Shengyong Cai,Shengzhi Shao,Shervin Shahidi,Shikai Li,Shimon Bernholtz,Shiqi Wang,Shishir G. Patil,Shiv Verma,Shiva Shankar P,Shiyang Chen,Sho Yaida,Shoubhik Debnath,Shreyas Siravara,Shruti Bhosale,Shuang Ma,Shun Zhang,Shuo Tang,Shuqiang Zhang,Shuyan Zhou,Sicong Che,Sidd Srinivisan,Siddharth Bhattacharya,Siddharth Patki,Sijia Chen,Sili Chen,Simon Vandenhende,Simone Merello,Sinong Wang,Sivan Barzily,Sixian Yi,Siyu Lin,SK Bong,Sky Yin,Sneha Agarwal,Sneha Agarwal,Soerian Lieve,Soji Sajuyigbe,Song Jiang,Songlin Li,Sonia Kim,Sopan Khosla,Soumi Maiti,Spencer Whitman,Sravya Popuri,Sreen Tallam,Srinivas Vaidyanathan,Srinivas Vaidyanathan,Sten Sootla,Stephane Collot,Stephanie Ding,Stephen Chen,Steven Cai,Suchin Gururangan,Sudarshan Govindaprasad,Sue Young,Suganthi Dewakar,Sujan Kumar Gonugondla,Sujeet Bhandari,Suman Gumudavelli,Suman Gumudavelli,Sumit Gupta,Summer Deng,Sungmin Cho,Suresh Ganapathy,Surjyendu Dhal,Susan Fedynak,Susana Contrera,Suyoun Kim,Sylvestre Rebuffi,Takshak Chahande,Tamar Herman,Tan Li,Tao Xu,Tara Fowler,Tarek Sheasha,Tarun Anand,Tarun Kalluri,Tarun Singh,Tatiana Shavrina,Ted Li,Teja Rao,Tejas Patil,Teng Li,Thach Bui,Thai Quach,Thamer Alharbash,Thanh Vinh Vo,Thawan Kooburat,Thilo Koehler,Thomas Georgiou,Thomas Scialom,Tian Ye,Tianhe Li,Tianjun Zhang,Tianyu Li,Tijmen Blankevoort,Timon Willi,Timothy Chou,Timothy Leung,TJ Lee,Todor Mihaylov,Tom Heatwole,Tong Xiao,Tony Cao,Tony Lee,Trang Le,Tristan Rice,Tsz Kei Serena Chan,Tuan Tran,Tudor Tiplea,Tyler Baumgartner,Uday Savagaonkar,Ujjwal Karn,Ulises Martinez Araiza,Umar Farooq,Uriel Cohen,Usman Sharif,Utkarsh Murarka,Van Phung,Varun Joginpalli,Varun Saravagi,Vasu Sharma,Vasudha Viswamurthy,Vedanuj Goswami,Vedika Seth,Venkat Ramesh,Venkat Ramesh,Vibhor Gupta,Victoria Montanez,Vidhya Natarajan,Vidya Sarma,Vignesh Ramanathan,Viktor Kerkez,Vinay Rao,Vincent Gonguet,Vincent Mauge,Virginie Do,Vish Vogeti,Vishrav Chaudhary,Viswesh Sankaran,Vítor Albiero,Vivek Miglani,Vivek Pai,Vlad Cojanu,Vlad Shubin,Vlad Tiberiu Mihailescu,Vladan Petrovic,Vladimir Ivanov,Vladislav Vorotilov,Vrushali Bhutada,Wai I Ng,Wei Cheng,Wei Sun,Wei Tu,Wei Wei,Wei Zhou,Wei-Ning Hsu,Weiwei Chu,Weizhe Yuan,Wenchen Wang,Wenjun Zhao,Wenwen Jiang,Wenyin Fu,Wenzhe Jiang,Whitney Meers,Will Constable,Will Wang,William R. Wong,Xavier Martinet,Xi Victoria Lin,Xi Yan,Xi Yin,Xian Li,Xianfeng Rui,Xianjun Yang,Xiaocheng Tang,Xiaodong Wang,Xiaofang Wang,Xiaolan Wang,Xiaoliang Dai,Xiaoliang Peng,Xiaopeng Li,Xiaozhu Meng,Xibei Zhang,Xide Xia,Xin Jin,xinbo Gao,Xinfeng Xie,Xingyi Zhou,Xu Ma,Xuan Ju,Xuanyi Zhao,Xubo Liu,Xuchao Jia,Xuedong Zhang,Xuefei Cao,Xuewei Wang,Xuewei Wu,Xunnan Xu,Xutai Ma,Xuyang Wang,Yan Cui,Yang Chen,Yang Li,Yang Shu,Yang Xia,Yanjun Chen,Yanjun Zhou,Yash Mehta,Yash Patel,Yash Tekena,Yashesh Gaur,Yasmine Babaei,Yaxuan Zhou,Ye Hu,Ye Qi,Yejin Lee,Yeming Wen,Yen-Cheng Liu,Yexin Bruce Wu,Yi Pan,Yi Yang,Yi-Hui Lin,Yifan Wang,Yifan Wu,Yifan Yang,Yifei Huang,Yiftah Ben Aharon,Yilin Yang,Yiling You,Ying Xu,Ying Zhang,Yingquan Yuan,Yingru Liu,Yingyi Ma,Yining Yang,Yiting Lu,Yonatan Komornik,Yongjie Lin,Yoni Goyhman,Yossi Moran Mamo,Youngjin Nam,Yu Wang,Yu Lu,Yu Zhao,Yu-Ho Hsieh,Yu-Jung Lo,Yuandong Tian,Yuanhan Zhang,Yuanhao Xiong,Yuanshun Yao,Yuchen Hao,Yuchen Zhang,Yuchuan Li,Yue Cao,Yue Yu,Yue Zhao,Yuhan Guo,Yuhao Wang,Yuheng Huang,Yujie Lu,Yujun Shi,Yulun Wang,Yun He,Yun Wang,Yundi Qian,Yunfan Wang,Yunhao Tang,Yuning Mao,Yunlu Li,Yuqi Dai,Yuriy Hulovatyy,Yushi Hu,Yuxuan Sun,Zach Rait,Zach Wentz,Zacharie Delpierre Coudert,Zachary Collins,Zahra Hankir,Zecheng He,Zeeshan Ahmed,Zeeshan Ahmed,Zef RosnBrick,Zhan Shu,Zhanna Rohalska,Zhaoduo Wen,Zhe Liu,Zhe Liu,Zhen Qiao,Zhenggang Xu,Zhengwen Zhou,Zhengxing Chen,Zhenyu Tang,Zhichen Wu,Zhicheng Ouyang,Zhihong Lei,Zhipeng Hong,Zhiping Xiu,Zhiwei Zhao,Zhong Meng,Zhou Jin,Zhouhao Zeng,Zichang Liu,Zihang Meng,Zihuan Qiao,Zinnia Zheng,Zixi Qi,Ziyi Luo,Zoe Foulkes Birkhead,Zoey Sun,Zohar Achdut*

Main category: cs.SE

TL;DR: 本文总结了Metas Llama 4模型家族的技术细节，包括变体、架构、训练方法、基准测试和部署限制，旨在为研究人员和实践者提供参考。


<details>
  <summary>Details</summary>
Motivation: 为需要关于Llama 4精确、有来源支持的事实的研究人员和实践者提供参考。

Method: 通过整合公开报告的技术细节，包括模型变体、架构特性、训练方法、基准测试和部署约束。

Result: 总结了Llama 4的多个方面，包括模型变体、架构设计、训练方法、性能结果和实际部署中的限制。

Conclusion: 本文旨在为研究人员和实践者提供一个关于Llama 4模型的紧凑技术参考，涵盖其变体、架构、训练方法、基准测试结果及部署限制。

Abstract: This document consolidates publicly reported technical details about Metas Llama 4 model family. It summarizes (i) released variants (Scout and Maverick) and the broader herd context including the previewed Behemoth teacher model, (ii) architectural characteristics beyond a high-level MoE description covering routed/shared-expert structure, early-fusion multimodality, and long-context design elements reported for Scout (iRoPE and length generalization strategies), (iii) training disclosures spanning pre-training, mid-training for long-context extension, and post-training methodology (lightweight SFT, online RL, and lightweight DPO) as described in release materials, (iv) developer-reported benchmark results for both base and instruction-tuned checkpoints, and (v) practical deployment constraints observed across major serving environments, including provider-specific context limits and quantization packaging. The manuscript also summarizes licensing obligations relevant to redistribution and derivative naming, and reviews publicly described safeguards and evaluation practices. The goal is to provide a compact technical reference for researchers and practitioners who need precise, source-backed facts about Llama 4.

</details>


### [498] [From Everything-is-a-File to Files-Are-All-You-Need: How Unix Philosophy Informs the Design of Agentic AI Systems](https://arxiv.org/abs/2601.11672)
*Deepak Babu Piskala*

Main category: cs.SE

TL;DR: 本文探讨了类似Unix'一切都是文件'的抽象如何应用于智能代理系统，提出文件类和代码为中心的模型可提升系统的可维护性和稳健性。


<details>
  <summary>Details</summary>
Motivation: 探索当代智能代理系统中是否可以实现类似Unix'一切都是文件'的统一抽象，以提升系统的可维护性和操作稳健性。

Method: 通过追溯从Unix到DevOps、基础设施即代码（Infrastructure-as-Code）再到自主软件代理的演变过程，分析文件类抽象和基于代码的规范如何统一多样化资源。

Result: 研究发现，文件类和代码为中心的交互模型有望使智能代理系统更易于维护、审计和操作。

Conclusion: 采用类似Unix的'一切都是文件'抽象和基于代码的规范，可以提升智能代理系统的可维护性、可审计性和操作稳健性。

Abstract: A core abstraction in early Unix systems was the principle that 'everything is a file', enabling heterogeneous devices and kernel resources to be manipulated via uniform read/write interfaces. This paper explores how an analogous unification is emerging in contemporary agentic AI. We trace the evolution from Unix to DevOps, Infrastructure-as-Code, and finally autonomous software agents, highlighting how file-like abstractions and code-based specifications collapse diverse resources into consistent, composable interfaces. The resulting perspective suggests that adopting file- and code-centric interaction models may enable agentic systems that are more maintainable, auditable, and operationally robust.

</details>


### [499] [Semantic Caching and Intent-Driven Context Optimization for Multi-Agent Natural Language to Code Systems](https://arxiv.org/abs/2601.11687)
*Harmohit Singh*

Main category: cs.SE

TL;DR: 本文提出了一种优化的多智能体系统，通过语义缓存、双阈值决策和动态提示组装，高效地将自然语言查询转换为Python代码，已在实际生产中验证其高准确性和低成本。


<details>
  <summary>Details</summary>
Motivation: 解决依赖昂贵前沿模型的系统在成本和效率上的不足，实现高准确性和成本效益的自然语言查询到Python代码的转换。

Method: 1. 基于LLM的语义缓存系统，提供67%的缓存命中率；2. 双阈值决策机制，分离精确匹配检索和参考引导生成；3. 意图驱动的动态提示组装系统，通过表感知上下文过滤减少40-60%的token消耗。

Result: 系统在企业库存管理中部署，处理了超过10,000次查询，平均延迟为8.2秒，语义准确率为94.3%。

Conclusion: 本文介绍了一种生产优化的多智能体系统，通过语义缓存、双阈值决策机制和意图驱动的动态提示组装系统，实现了高准确性和成本效益的自然语言查询到Python代码的转换。系统已在企业库存管理中部署，处理了超过10,000次查询，平均延迟为8.2秒，语义准确率为94.3%。

Abstract: We present a production-optimized multi-agent system designed to translate natural language queries into executable Python code for structured data analytics. Unlike systems that rely on expensive frontier models, our approach achieves high accuracy and cost efficiency through three key innovations: (1) a semantic caching system with LLM-based equivalence detection and structured adaptation hints that provides cache hit rates of 67% on production queries; (2) a dual-threshold decision mechanism that separates exact-match retrieval from reference-guided generation; and (3) an intent-driven dynamic prompt assembly system that reduces token consumption by 40-60% through table-aware context filtering. The system has been deployed in production for enterprise inventory management, processing over 10,000 queries with an average latency of 8.2 seconds and 94.3% semantic accuracy. We describe the architecture, present empirical results from production deployment, and discuss practical considerations for deploying LLM-based analytics systems at scale.

</details>


### [500] [SpecMap: Hierarchical LLM Agent for Datasheet-to-Code Traceability Link Recovery in Systems Engineering](https://arxiv.org/abs/2601.11688)
*Vedant Nipane,Pulkit Agrawal,Amit Singh*

Main category: cs.SE

TL;DR: 提出了一种基于大型语言模型的分层数据表到代码映射方法，显著提升了嵌入式系统软件的可追溯性，并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 解决嵌入式系统数据表与代码实现之间精确可追溯性的挑战，特别是在低级软件中，手动映射不可行。

Method: 采用大型语言模型进行语义分析，并通过多级抽象层次结构化追溯过程，包括仓库级结构推断、文件级相关性估计和细粒度符号级对齐。

Result: 在多个开源嵌入式系统仓库上评估，文件映射准确率高达73.3%，LLM令牌消耗降低84%，端到端运行时间减少约80%。

Conclusion: 该论文提出了一种分层的数据表到代码映射方法，显著提高了嵌入式系统软件中规范与代码之间的可追溯性，并大幅降低了计算开销。

Abstract: Establishing precise traceability between embedded systems datasheets and their corresponding code implementations remains a fundamental challenge in systems engineering, particularly for low-level software where manual mapping between specification documents and large code repositories is infeasible. Existing Traceability Link Recovery approaches primarily rely on lexical similarity and information retrieval techniques, which struggle to capture the semantic, structural, and symbol level relationships prevalent in embedded systems software. We present a hierarchical datasheet-to-code mapping methodology that employs large language models for semantic analysis while explicitly structuring the traceability process across multiple abstraction levels. Rather than performing direct specification-to-code matching, the proposed approach progressively narrows the search space through repository-level structure inference, file-level relevance estimation, and fine-grained symbollevel alignment. The method extends beyond function-centric mapping by explicitly covering macros, structs, constants, configuration parameters, and register definitions commonly found in systems-level C/C++ codebases. We evaluate the approach on multiple open-source embedded systems repositories using manually curated datasheet-to-code ground truth. Experimental results show substantial improvements over traditional information-retrieval-based baselines, achieving up to 73.3% file mapping accuracy. We significantly reduce computational overhead, lowering total LLM token consumption by 84% and end-to-end runtime by approximately 80%. This methodology supports automated analysis of large embedded software systems and enables downstream applications such as training data generation for systems-aware machine learning models, standards compliance verification, and large-scale specification coverage analysis.

</details>


### [501] [Technical Lag as Latent Technical Debt: A Rapid Review](https://arxiv.org/abs/2601.11693)
*Shane K. Panter,Nasir U. Eisty*

Main category: cs.SE

TL;DR: 本文通过快速综述整合技术滞后研究，明确其定义、检测方法及影响，提出将其作为潜在技术债务指标，并指出未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 技术滞后（technical lag）在软件系统未能跟上技术进步时积累，导致软件质量下降。本文旨在整合现有研究，明确定义，探索检测与量化方法，分析原因与后果，回顾当前管理实践，并将其作为被动积累技术债务的指标提出愿景。

Method: 采用快速综述（Rapid Review）结合滚雪球法筛选合适的同行评审研究，主要数据源包括ACM Digital Library、IEEE Xplore、Scopus和Springer。

Result: 技术滞后被动积累，常因缺乏检测指标和工具而被忽视。它通过过时的依赖、废弃的API、不受支持的平台和老化基础设施对软件质量产生负面影响。管理策略主要包括自动化依赖更新、持续集成流程和定期审计。

Conclusion: 增强和扩展当前的标准指标、检测方法及实证研究，将技术滞后作为潜在债务积累的指示，可以极大改善依赖外部包的大型代码库的维护过程。本文还指出了研究空白，并为研究人员和从业者勾勒了未来探索的愿景。

Abstract: Context: Technical lag accumulates when software systems fail to keep pace with technological advancements, leading to a deterioration in software quality. Objective: This paper aims to consolidate existing research on technical lag, clarify definitions, explore its detection and quantification methods, examine underlying causes and consequences, review current management practices, and lay out a vision as an indicator of passively accumulated technical debt. Method: We conducted a Rapid Review with snowballing to select the appropriate peer-reviewed studies. We leveraged the ACM Digital Library, IEEE Xplore, Scopus, and Springer as our primary source databases. Results: Technical lag accumulates passively, often unnoticed due to inadequate detection metrics and tools. It negatively impacts software quality through outdated dependencies, obsolete APIs, unsupported platforms, and aging infrastructure. Strategies to manage technical lag primarily involve automated dependency updates, continuous integration processes, and regular auditing. Conclusions: Enhancing and extending the current standardized metrics, detection methods, and empirical studies to use technical lag as an indication of accumulated latent debt can greatly improve the process of maintaining large codebases that are heavily dependent on external packages. We have identified the research gaps and outlined a future vision for researchers and practitioners to explore.

</details>


### [502] [The Stability Trap: Evaluating the Reliability of LLM-Based Instruction Adherence Auditing](https://arxiv.org/abs/2601.11783)
*Murtuza N. Shergadwala*

Main category: cs.SE

TL;DR: 研究发现LLM法官在裁决上高度一致（>99%），但推理稳定性因指令类型差异显著，建议将确定性逻辑交由代码处理，LLM仅用于复杂语义评估。


<details>
  <summary>Details</summary>
Motivation: 研究企业治理中生成式AI（GenAI）的可扩展且可复现的审计机制，特别是在人力资源（HR）等受监管领域，验证LLM作为法官方法在评估不同类型系统指令时的可靠性。

Method: 引入了范围指令分解框架（Scoped Instruction Decomposition Framework），将应用指令分类为目标型和主观型，并评估了四种法官架构在不同运行中的稳定性。

Result: 揭示了‘稳定性陷阱’现象：裁决稳定性与推理稳定性之间存在差异。目标型指令在离散实体提取上表现出高推理稳定性（>90%），而定量分析的推理稳定性低至≈19%。主观型指令的推理稳定性因证据粒度差异而波动（35%--83%）。

Conclusion: 高裁决稳定性可能掩盖脆弱的推理过程，建议审计员严格限定自动化评估协议的范围：将所有可确定性验证的逻辑委托给代码，而将LLM法官保留用于复杂的语义评估。

Abstract: The enterprise governance of Generative AI (GenAI) in regulated sectors, such as Human Resources (HR), demands scalable yet reproducible auditing mechanisms. While Large Language Model (LLM)-as-a-Judge approaches offer scalability, their reliability in evaluating adherence of different types of system instructions remains unverified. This study asks: To what extent does the instruction type of an Application Under Test (AUT) influence the stability of judge evaluations? To address this, we introduce the Scoped Instruction Decomposition Framework to classify AUT instructions into Objective and Subjective types, isolating the factors that drive judge instability. We applied this framework to two representative HR GenAI applications, evaluating the stability of four judge architectures over variable runs. Our results reveal a ``Stability Trap'' characterized by a divergence between Verdict Stability and Reasoning Stability. While judges achieved near-perfect verdict agreement ($>99\%$) for both objective and subjective evaluations, their accompanying justification traces diverged significantly. Objective instructions requiring quantitative analysis, such as word counting, exhibited reasoning stability as low as $\approx19\%$, driven by variances in numeric justifications. Similarly, reasoning stability for subjective instructions varied widely ($35\%$--$83\%$) based on evidence granularity, with feature-specific checks failing to reproduce consistent rationale. Conversely, objective instructions focusing on discrete entity extraction achieved high reasoning stability ($>90\%$). These findings demonstrate that high verdict stability can mask fragile reasoning. Thus, we suggest that auditors scope automated evaluation protocols strictly: delegate all deterministically verifiable logic to code, while reserving LLM judges for complex semantic evaluation.

</details>


### [503] [Changes in Coding Behavior and Performance Since the Introduction of LLMs](https://arxiv.org/abs/2601.11835)
*Yufan Zhang,Jaromir Savelka,Seth Goldstein,Michael Conway*

Main category: cs.SE

TL;DR: 研究发现ChatGPT发布后，学生编码行为变化（如代码长度增加、编辑距离增大）可能与LLM过度依赖有关，导致生产力和学习效果下降，呼吁教育者和雇主重新评估评估标准。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型（LLMs）的普及如何改变学生的编码和问题解决行为，以及对教学评估的潜在影响。

Method: 通过分析一门研究生云计算课程中五年内学生提交的源代码，特别是对ChatGPT发布前后五个学期的作业提交行为进行对比研究。

Result: 学生提交的代码长度增加，但连续提交间的平均编辑距离增大，而平均分数提升减少，表明生产力和学习效果均有所下降。这些行为变化与整体表现存在显著相关性。

Conclusion: 研究发现，自ChatGPT发布以来，学生的编码行为和整体表现发生了显著变化，这可能与学生过度依赖大型语言模型（LLMs）有关。这为教育者和雇主敲响了警钟，需要重新评估对真实专业知识和生产力的衡量标准。

Abstract: The widespread availability of large language models (LLMs) has changed how students engage with coding and problem-solving. While these tools may increase student productivity, they also make it more difficult for instructors to assess students' learning and effort. In this quasi-longitudinal study, we analyze five years of student source code submissions in a graduate-level cloud computing course, focusing on an assignment that remained unchanged and examining students' behavior during the period spanning five semesters before the release of ChatGPT and five semesters after.
  Student coding behavior has changed significantly since Fall 2022. The length of their final submissions increased. Between consecutive submissions, average edit distances increased while average score improvement decreased, suggesting that both student productivity and learning have decreased after ChatGPT's release. Additionally, there are statistically significant correlations between these behavioral changes and their overall performance. Although we cannot definitively attribute them to LLM misuse, they are consistent with our hypothesis that some students are over-reliant on LLMs, which is negatively affecting their learning outcomes. Our findings raise an alarm around the first generation of graduates in the age of LLMs, calling upon both educators and employers to reflect on their evaluation methods for genuine expertise and productivity.

</details>


### [504] [Trace Validation of Unmodified Concurrent Systems with OmniLink](https://arxiv.org/abs/2601.11836)
*Finn Hackett,Evan Wrench,Peter Macko,A. Jesse Jiryu Davis,Yuanhao Wei,Ivan Beschastnikh*

Main category: cs.SE

TL;DR: OmniLink是一种新的并发系统验证方法，通过TLA+规范和时间框求解动作顺序，优于现有工具，并发现了多个bug。


<details>
  <summary>Details</summary>
Motivation: 并发系统验证困难，现有工具常需要侵入性插桩或不现实的执行模型，OmniLink旨在提供一种更灵活且高效的验证方法。

Method: OmniLink将系统事件视为黑盒，利用TLA+规范和时间框来求解动作的逻辑总顺序，并提供基于现成模型检查的不同线性化检查方法。

Result: OmniLink成功验证了WiredTiger、BAT和ConcurrentQueue，发现了已知和两个未知的bug。

Conclusion: OmniLink是一种新的验证并发实现的方法，能够发现已知和未知的bug，并在大规模验证任务中表现优于现有技术。

Abstract: Concurrent systems are notoriously difficult to validate: subtle bugs may only manifest under rare thread interleavings, and existing tools often require intrusive instrumentation or unrealistic execution models. We present OmniLink, a new methodology for validating concurrent implementations against high-level specifications in TLA+. Unlike prior TLA+ based approaches which use a technique called trace validation, OmniLink treats system events as black boxes with a timebox in which they occurred and a meaning in TLA+, solving for a logical total order of actions. Unlike prior approaches based on linearizability checking, which already solves for total orders of actions with timeboxes, OmniLink uses a flexible specification language, and offers a different linearizability checking method based on off-the-shelf model checking. OmniLink offers different features compared existing linearizability checking tools, and we show that it outperforms the state of the art on large scale validation tasks.
  Our evaluation validates WiredTiger, a state-of-the-art industrial database storage layer, as well as Balanced Augmented Tree (BAT), a state-of-the art lock-free data structure from the research community, and ConcurrentQueue, a popular lock-free queue featuring aggressive performance optimizations. We use OmniLink to improve WiredTiger's existing TLA+ model, as well as develop new TLA+ models that closely match the behavior of the modeled systems, including non-linearizable behaviors. OmniLink is able to find known bugs injected into the systems under test, as well as help discover two previously unknown bugs (1 in BAT, 1 in ConcurrentQueue), which we have confirmed with the authors of those systems.

</details>


### [505] [Terminal-Bench: Benchmarking Agents on Hard, Realistic Tasks in Command Line Interfaces](https://arxiv.org/abs/2601.11868)
*Mike A. Merrill,Alexander G. Shaw,Nicholas Carlini,Boxuan Li,Harsh Raj,Ivan Bercovich,Lin Shi,Jeong Yeon Shin,Thomas Walshe,E. Kelly Buchanan,Junhong Shen,Guanghao Ye,Haowei Lin,Jason Poulos,Maoyu Wang,Marianna Nezhurina,Jenia Jitsev,Di Lu,Orfeas Menis Mastromichalakis,Zhiwei Xu,Zizhao Chen,Yue Liu,Robert Zhang,Leon Liangyu Chen,Anurag Kashyap,Jan-Lucas Uslu,Jeffrey Li,Jianbo Wu,Minghao Yan,Song Bian,Vedang Sharma,Ke Sun,Steven Dillmann,Akshay Anand,Andrew Lanpouthakoun,Bardia Koopah,Changran Hu,Etash Guha,Gabriel H. S. Dreiman,Jiacheng Zhu,Karl Krauth,Li Zhong,Niklas Muennighoff,Robert Amanfu,Shangyin Tan,Shreyas Pimpalgaonkar,Tushar Aggarwal,Xiangning Lin,Xin Lan,Xuandong Zhao,Yiqing Liang,Yuanli Wang,Zilong Wang,Changzhi Zhou,David Heineman,Hange Liu,Harsh Trivedi,John Yang,Junhong Lin,Manish Shetty,Michael Yang,Nabil Omi,Negin Raoof,Shanda Li,Terry Yue Zhuo,Wuwei Lin,Yiwei Dai,Yuxin Wang,Wenhao Chai,Shang Zhou,Dariush Wahdany,Ziyu She,Jiaming Hu,Zhikang Dong,Yuxuan Zhu,Sasha Cui,Ahson Saiyed,Arinbjörn Kolbeinsson,Jesse Hu,Christopher Michael Rytting,Ryan Marten,Yixin Wang,Alex Dimakis,Andy Konwinski,Ludwig Schmidt*

Main category: cs.SE

TL;DR: Terminal-Bench 2.0是一个硬基准测试，包含89个终端任务，用于评估AI代理在真实世界任务中的表现，结果显示前沿模型得分低于65%。


<details>
  <summary>Details</summary>
Motivation: 当前基准测试要么无法衡量真实世界任务，要么难度不足以有效评估前沿模型，因此需要一个新的、更具挑战性的基准测试。

Method: 论文通过精心设计的89个计算机终端环境任务，每个任务包含独特的环境、人工编写的解决方案和全面的验证测试，构建了一个硬基准测试。

Result: 前沿模型和代理在Terminal-Bench 2.0上的得分低于65%，通过错误分析指出了模型和代理需要改进的方向。

Conclusion: 该论文提出了Terminal-Bench 2.0，一个用于评估AI代理在真实世界任务中表现的硬基准测试，并展示了前沿模型和代理在该基准上的表现不足65%，同时提供了数据集和评估工具以支持未来研究。

Abstract: AI agents may soon become capable of autonomously completing valuable, long-horizon tasks in diverse domains. Current benchmarks either do not measure real-world tasks, or are not sufficiently difficult to meaningfully measure frontier models. To this end, we present Terminal-Bench 2.0: a carefully curated hard benchmark composed of 89 tasks in computer terminal environments inspired by problems from real workflows. Each task features a unique environment, human-written solution, and comprehensive tests for verification. We show that frontier models and agents score less than 65\% on the benchmark and conduct an error analysis to identify areas for model and agent improvement. We publish the dataset and evaluation harness to assist developers and researchers in future work at https://www.tbench.ai/ .

</details>


### [506] [Harmonica: A Self-Adaptation Exemplar for Sustainable MLOps](https://arxiv.org/abs/2601.11926)
*Ananya Halgatti,Shaunak Biswas,Hiya Bhatt,Srinivasan Rakhunathan,Karthik Vaidhyanathan*

Main category: cs.SE

TL;DR: Harmonica是一个基于HarmonE的自适应范例，通过MAPE-K循环和动态适应边界监控，提升依赖MLOps管道的机器学习系统的可持续性和稳定性。


<details>
  <summary>Details</summary>
Motivation: 机器学习系统（MLS）在运行过程中常遇到环境变化带来的不确定性，这可能导致模型行为退化、运营成本增加和系统实用性下降。尽管MLOps简化了ML模型的生命周期管理，但对影响MLS长期可持续性的运行时不确定性支持有限。

Method: Harmonica基于HarmonE方法构建，通过MAPE-K循环引入结构化自适应控制，将高级适应策略与低级战术执行分离。它持续监控可持续性指标，根据动态适应边界评估这些指标，并在阈值被违反时自动触发架构战术。

Result: 通过时间序列回归和计算机视觉的案例研究，Harmonica展示了其提高系统稳定性和减少人工干预的能力。

Conclusion: Harmonica提供了一个实用且可重用的基础，支持依赖MLOps管道的机器学习系统实现自适应行为，从而提高系统稳定性并减少人工干预。

Abstract: Machine learning enabled systems (MLS) often operate in settings where they regularly encounter uncertainties arising from changes in their surrounding environment. Without structured oversight, such changes can degrade model behavior, increase operational cost, and reduce the usefulness of deployed systems. Although Machine Learning Operations (MLOps) streamlines the lifecycle of ML models, it provides limited support for addressing runtime uncertainties that influence the longer term sustainability of MLS. To support continued viability, these systems need a mechanism that detects when execution drifts outside acceptable bounds and adjusts system behavior in response. Despite the growing interest in sustainable and self-adaptive MLS, there has been limited work towards exemplars that allow researchers to study these challenges in MLOps pipelines. This paper presents Harmonica, a self-adaptation exemplar built on the HarmonE approach, designed to enable the sustainable operation of such pipelines. Harmonica introduces structured adaptive control through MAPE-K loop, separating high-level adaptation policy from low-level tactic execution. It continuously monitors sustainability metrics, evaluates them against dynamic adaptation boundaries, and automatically triggers architectural tactics when thresholds are violated. We demonstrate the tool through case studies in time series regression and computer vision, examining its ability to improve system stability and reduce manual intervention. The results show that Harmonica offers a practical and reusable foundation for enabling adaptive behavior in MLS that rely on MLOps pipelines for sustained operation.

</details>


### [507] [Enhancing Fuzz Testing Efficiency through Automated Fuzz Target Generation](https://arxiv.org/abs/2601.11972)
*Chi Thien Tran*

Main category: cs.SE

TL;DR: 本文提出了一种基于静态分析的自动化模糊目标生成方法，显著提升了模糊测试的覆盖率和效率。


<details>
  <summary>Details</summary>
Motivation: 在大规模软件项目和库中，手动创建模糊目标既耗时又费力，因此需要自动化技术来生成模糊目标并简化其执行和结果分析。

Method: 该方法通过分析源代码结构来构建函数调用和生成模糊目标，将模糊输入数据映射到函数参数，合成模糊目标的编译信息，并自动收集和分析执行结果。

Result: 通过将该方法应用于C/C++库的模糊目标生成，证明了其有效性。

Conclusion: 本文提出了一种通过静态分析库源代码来改进模糊目标生成的方法，显著提高了模糊测试的覆盖率和效率。

Abstract: Fuzzing continues to be the most effective method for identifying security vulnerabilities in software. In the context of fuzz testing, the fuzzer supplies varied inputs to fuzz targets, which are designed to comprehensively exercise critical sections of the client code. Various studies have focused on optimizing and developing advanced fuzzers, such as AFL++, libFuzzer, Honggfuzz, syzkaller, ISP-Fuzzer, which have substantially enhanced vulnerability detection in widely used software and libraries. Nevertheless, achieving greater coverage necessitates improvements in both the quality and quantity of fuzz targets. In large-scale software projects and libraries -- characterized by numerous user defined functions and data types -- manual creation of fuzz targets is both labor-intensive and time-consuming. This challenge underscores the need for automated techniques not only to generate fuzz targets but also to streamline the execution and analysis of their results. In this paper, we introduce an approach to improving fuzz target generation through static analysis of library source code. The proposed method encompasses several key aspects: it analyzes source code structures to accurately construct function calls and generate fuzz targets; it maps fuzzer input data to the corresponding function parameters; it synthesizes compilation information for the fuzz targets; and it automatically collects and analyzes execution results. Our findings are demonstrated through the application of this approach to the generation of fuzz targets for C/C++ libraries.

</details>


### [508] [From LLMs to Agents in Programming: The Impact of Providing an LLM with a Compiler](https://arxiv.org/abs/2601.12146)
*Viktor Kjellberg,Miroslaw Staron,Farnaz Fotrousi*

Main category: cs.SE

TL;DR: LLMs with compiler access show significant improvements in generating runnable code, reducing errors, and sometimes outperforming larger models, highlighting the importance of tool integration for efficiency.


<details>
  <summary>Details</summary>
Motivation: To study how access to software development tools (e.g., a compiler) improves LLMs' ability to generate runnable programs by shifting from passive generation to active, iterative development based on compiler feedback.

Method: A computational experiment on the RosettaCode dataset with 699 C programming tasks, evaluating 16 language models of varying sizes (135M to 70B) integrated with a GCC compiler.

Result: Access to a compiler improved compilation success by 5.3 to 79.4 percentage points, reduced syntax errors by 75%, and undefined reference errors by 87%. Smaller models with a compiler sometimes outperformed larger models.

Conclusion: LLMs benefit significantly from access to software development tools like a compiler, enhancing performance and reducing the need for large models, thereby lowering energy consumption.

Abstract: Large Language Models have demonstrated a remarkable capability in natural language and program generation and software development. However, the source code generated by the LLMs does not always meet quality requirements and may fail to compile. Therefore, many studies evolve into agents that can reason about the problem before generating the source code for the solution. The goal of this paper is to study the degree to which such agents benefit from access to software development tools, in our case, a \texttt{gcc} compiler. We conduct a computational experiment on the RosettaCode dataset, on 699 programming tasks in C. We evaluate how the integration with a compiler shifts the role of the language model from a passive generator to an active agent capable of iteratively developing runnable programs based on feedback from the compiler. We evaluated 16 language models with sizes ranging from small (135 million) to medium (3 billion) and large (70 billion). Our results show that access to a compiler improved the compilation success by 5.3 to 79.4 percentage units in compilation without affecting the semantics of the generated program. Syntax errors dropped by 75\%, and errors related to undefined references dropped by 87\% for the tasks where the agents outperformed the baselines. We also observed that in some cases, smaller models with a compiler outperform larger models with a compiler. We conclude that it is essential for LLMs to have access to software engineering tools to enhance their performance and reduce the need for large models in software engineering, such as reducing our energy footprint.

</details>


### [509] [Many Hands Make Light Work: An LLM-based Multi-Agent System for Detecting Malicious PyPI Packages](https://arxiv.org/abs/2601.12148)
*Muhammad Umar Zeshan,Motunrayo Ibiyo,Claudio Di Sipio,Phuong T. Nguyen,Davide Di Ruscio*

Main category: cs.SE

TL;DR: LAMPS is a multi-agent system using LLMs to detect malicious PyPI packages, achieving high accuracy on two datasets and demonstrating the benefits of modular designs in security.


<details>
  <summary>Details</summary>
Motivation: Traditional rule-based tools often overlook semantic patterns in source code crucial for identifying adversarial components, while LLMs' use in interpretable and modular security pipelines remains limited.

Method: The system employs four role-specific agents for package retrieval, file extraction, classification, and verdict aggregation, coordinated through the CrewAI framework. A prototype combines a fine-tuned CodeBERT model for classification with LLaMA-3 agents for contextual reasoning.

Result: On dataset D1, LAMPS achieves 97.7% accuracy, surpassing state-of-the-art approaches. On dataset D2, it reaches 99.5% accuracy and 99.5% balanced accuracy, outperforming RAG-based approaches and fine-tuned single-agent baselines.

Conclusion: LAMPS demonstrates the feasibility of distributed LLM reasoning for malicious code detection and highlights the benefits of modular multi-agent designs in software supply chain security.

Abstract: Malicious code in open-source repositories such as PyPI poses a growing threat to software supply chains. Traditional rule-based tools often overlook the semantic patterns in source code that are crucial for identifying adversarial components. Large language models (LLMs) show promise for software analysis, yet their use in interpretable and modular security pipelines remains limited. This paper presents LAMPS, a multi-agent system that employs collaborative LLMs to detect malicious PyPI packages. The system consists of four role-specific agents for package retrieval, file extraction, classification, and verdict aggregation, coordinated through the CrewAI framework. A prototype combines a fine-tuned CodeBERT model for classification with LLaMA-3 agents for contextual reasoning. LAMPS has been evaluated on two complementary datasets: D1, a balanced collection of 6,000 setup.py files, and D2, a realistic multi-file dataset with 1,296 files and natural class imbalance. On D1, LAMPS achieves 97.7% accuracy, surpassing MPHunter--one of the state-of-the-art approaches. On D2, it reaches 99.5% accuracy and 99.5% balanced accuracy, outperforming RAG-based approaches and fine-tuned single-agent baselines. McNemar's test confirmed these improvements as highly significant. The results demonstrate the feasibility of distributed LLM reasoning for malicious code detection and highlight the benefits of modular multi-agent designs in software supply chain security.

</details>


### [510] [Aletheia: What Makes RLVR For Code Verifiers Tick?](https://arxiv.org/abs/2601.12186)
*Vatsal Venkatkrishna,Indraneil Paul,Iryna Gurevych*

Main category: cs.SE

TL;DR: RLVR-based code verifiers are effective, with on-policy learning vital for small models and thinking-based training for larger ones, using the Aletheia testbed.


<details>
  <summary>Details</summary>
Motivation: Code verifiers are valuable when execution feedback is hard to obtain, yet their adoption in code generation is sparse. This work aims to assess and simplify the RLVR training recipe.

Method: The study evaluates RLVR-based verifier training components (intermediate thinking traces, learning from negative samples, on-policy training) using Aletheia, a controlled testbed.

Result: RLVR proves optimal, with on-policy learning key at small verifier sizes and thinking-based training most important at larger scales.

Conclusion: RLVR-based verifiers are optimal for code generation, with on-policy learning being crucial at small scales and thinking-based training at larger scales.

Abstract: Multi-domain thinking verifiers trained via Reinforcement Learning from Verifiable Rewards (RLVR) are a prominent fixture of the Large Language Model (LLM) post-training pipeline, owing to their ability to robustly rate and rerank model outputs. However, the adoption of such verifiers towards code generation has been comparatively sparse, with execution feedback constituting the dominant signal. Nonetheless, code verifiers remain valuable toward judging model outputs in scenarios where execution feedback is hard to obtain and are a potentially powerful addition to the code generation post-training toolbox. To this end, we create and open-source Aletheia, a controlled testbed that enables execution-grounded evaluation of code verifiers' robustness across disparate policy models and covariate shifts. We examine components of the RLVR-based verifier training recipe widely credited for its success: (1) intermediate thinking traces, (2) learning from negative samples, and (3) on-policy training. While experiments show the optimality of RLVR, we uncover important opportunities to simplify the recipe. Particularly, despite code verification exhibiting positive training- and inference-time scaling, on-policy learning stands out as the key component at small verifier sizes, and thinking-based training emerges as the most important component at larger scales.

</details>


### [511] [Environment-Aware Code Generation: How far are We?](https://arxiv.org/abs/2601.12262)
*Tongtong Wu,Rongyi Chen,Wenjie Du,Suyu Ma,Guilin Qi,Zhenchang Xing,Shahram Khadivi,Ramesh Periyathambi,Gholamreza Haffari*

Main category: cs.SE

TL;DR: 首次系统研究环境感知代码生成（EACG），引入VersiBCB基准，发现当前LLMs在此任务上表现不佳，但通过特定适应策略可提升性能。


<details>
  <summary>Details</summary>
Motivation: 大多数评估仍测试孤立、小规模代码（如单个函数），且默认或未指定软件环境。因此，LLMs是否能可靠生成针对用户特定环境的可执行代码尚不明确。

Method: 引入VersiBCB基准，该基准是多包、执行验证和过时感知的，能够捕捉复杂且不断变化的环境。研究数据、参数和缓存三个适应轴，并开发了针对每个轴的策略。

Result: 当前LLMs在环境特定代码生成方面表现不佳，但通过提出的适应策略，环境兼容性和可执行性得到改善。

Conclusion: 当前的大型语言模型在环境感知代码生成方面存在挑战，但通过数据、参数和缓存三个互补的适应轴策略，可以显著提升环境兼容性和可执行性。这为实际软件工程工作流中部署LLMs提供了关键挑战和机遇。

Abstract: Recent progress in large language models (LLMs) has improved code generation, but most evaluations still test isolated, small-scale code (e.g., a single function) under default or unspecified software environments. As a result, it is unclear whether LLMs can reliably generate executable code tailored to a user's specific environment. We present the first systematic study of Environment-Aware Code Generation (EACG), where generated code must be functionally correct and directly executable under arbitrary software configurations. To enable realistic evaluation, we introduce VersiBCB, a benchmark that is multi-package, execution-verified, and deprecation-aware, capturing complex and evolving environments that prior datasets often overlook. Using VersiBCB, we investigate three complementary adaptation axes: data, parameters, and cache, and develop representative strategies for each. Our results show that current LLMs struggle with environment-specific code generation, while our adaptations improve environment compatibility and executability. These findings highlight key challenges and opportunities for deploying LLMs in practical software engineering workflows.

</details>


### [512] [Leveraging Mutation Analysis for LLM-based Repair of Quantum Programs](https://arxiv.org/abs/2601.12273)
*Chihiro Yoshida,Yuta Ishimoto,Olivier Nourry,Masanari Kondo,Makoto Matsushita,Yasutaka Kamei,Yoshiki Higo*

Main category: cs.SE

TL;DR: 本研究利用LLM构建量子程序自动修复框架，通过突变分析增强提示的上下文信息，显著提高修复成功率（94.4%）和解释质量，为量子程序APR的可靠性与可解释性发展提供新思路。


<details>
  <summary>Details</summary>
Motivation: 现有的量子程序自动修复（APR）技术存在修复成功率低或生成补丁可理解性差的问题。本研究旨在探索如何通过提示中的上下文信息提升LLM在量子程序APR中的表现。

Method: 研究构建了一个框架，利用大型语言模型（LLM）生成代码修复及其自然语言解释。设计了四种提示配置，结合静态信息、动态信息和突变分析结果，以探究上下文信息对量子程序APR性能的影响。突变分析通过评估程序特定部分的小改动对执行结果的影响，提供比简单执行输出（如堆栈跟踪）更详细的动态信息。

Result: 实验显示，突变分析能为基于LLM的量子程序APR提供有价值的上下文信息，修复成功率显著提升（达94.4%），且在某些情况下改善了生成解释的质量。

Conclusion: 研究结果表明，基于LLM的量子程序自动修复（APR）技术中，突变分析能提供有价值的上下文信息，显著提高修复成功率（实验中达到94.4%），并在某些情况下提升生成解释的质量。这为开发兼具可靠性和可解释性的量子程序APR技术指明了新方向。

Abstract: In recent years, Automated Program Repair (APR) techniques specifically designed for quantum programs have been proposed. However, existing approaches often suffer from low repair success rates or poor understandability of the generated patches. In this study, we construct a framework in which a large language model (LLM) generates code repairs along with a natural language explanation of the applied repairs. To investigate how the contextual information included in prompts influences APR performance for quantum programs, we design four prompt configurations with different combinations of static information, dynamic information, and mutation analysis results. Mutation analysis evaluates how small changes to specific parts of a program affect its execution results and provides more detailed dynamic information than simple execution outputs such as stack traces. Our experimental results show that mutation analysis can provide valuable contextual information for LLM-based APR of quantum programs, improving repair success rates (achieving 94.4% in our experiment) and in some cases also improving the quality of generated explanations. Our findings point toward new directions for developing APR techniques for quantum programs that enhance both reliability and explainability.

</details>


### [513] [Hybrid Concolic Testing with Large Language Models for Guided Path Exploration](https://arxiv.org/abs/2601.12274)
*Mahdi Eslamimehr*

Main category: cs.SE

TL;DR: 本文提出了一种结合符号执行和LLMs的混合测试方法，有效解决了路径爆炸和约束求解成本问题，显著提升了测试效率和覆盖率。


<details>
  <summary>Details</summary>
Motivation: 传统符号测试存在路径爆炸和约束求解成本高的根本性限制，阻碍了其在大规模实际软件系统中的应用。

Method: 提出了一种新型算法框架，将符号执行与LLMs结合，利用LLMs的语义推理能力指导路径探索、优先处理有趣路径并辅助约束求解。

Result: 实验表明，该方法在分支覆盖率、路径覆盖率和覆盖时间上均显著优于传统符号测试、随机测试和基于遗传算法的方法。

Conclusion: 通过结合符号执行和大型语言模型（LLMs），本文提出的方法显著提升了程序状态空间的探索效率和错误检测能力，验证了其在金融科技等实际应用中的优越性。

Abstract: Concolic testing, a powerful hybrid software testing technique, has historically been plagued by fundamental limitations such as path explosion and the high cost of constraint solving, which hinder its practical application in large-scale, real-world software systems. This paper introduces a novel algorithmic framework that synergistically integrates concolic execution with Large Language Models (LLMs) to overcome these challenges. Our hybrid approach leverages the semantic reasoning capabilities of LLMs to guide path exploration, prioritize interesting execution paths, and assist in constraint solving. We formally define the system architecture and algorithms that constitute this new paradigm. Through a series of experiments on both synthetic and real-world Fintech applications, we demonstrate that our approach significantly outperforms traditional concolic testing, random testing, and genetic algorithm-based methods in terms of branch coverage, path coverage, and time-to-coverage. The results indicate that by combining the strengths of both concolic execution and LLMs, our method achieves a more efficient and effective exploration of the program state space, leading to improved bug detection capabilities.

</details>


### [514] [The Expert Validation Framework (EVF): Enabling Domain Expert Control in AI Engineering](https://arxiv.org/abs/2601.12327)
*Lucas Gren,Felix Dobslaw*

Main category: cs.SE

TL;DR: 提出了一个专家验证框架，通过四个阶段确保GenAI在企业中的质量与信任。


<details>
  <summary>Details</summary>
Motivation: 生成式AI系统在知识工作中具有广泛应用潜力，但在企业环境中的部署因缺乏系统化的质量保证机制而受阻。

Method: 框架包括四个阶段的实施过程：规范制定、系统创建、验证和生产监控。

Result: 通过专家驱动的严格方法，该框架能够在多样化的GenAI应用中确保质量。

Conclusion: 该论文提出了一个专家验证框架，通过将领域专家置于构建GenAI组件的核心位置，确保系统行为的权威控制，从而弥合AI能力与组织信任之间的关键差距。

Abstract: Generative AI (GenAI) systems promise to transform knowledge work by automating a range of tasks, yet their deployment in enterprise settings remains hindered by the lack of systematic quality assurance mechanisms. We present an Expert Validation Framework that places domain experts at the center of building software with GenAI components, enabling them to maintain authoritative control over system behavior through structured specification, testing, validation, and continuous monitoring processes. Our framework addresses the critical gap between AI capabilities and organizational trust by establishing a rigorous, expert-driven methodology for ensuring quality across diverse GenAI applications. Through a four-stage implementation process encompassing specification, system creation, validation, and production monitoring, the framework enables organizations to leverage GenAI capabilities while maintaining expert oversight and quality standards.

</details>


### [515] [Discovering 100+ Compiler Defects in 72 Hours via LLM-Driven Semantic Logic Recomposition](https://arxiv.org/abs/2601.12360)
*Xinabang He,Yuanwei Chen,Hao Wu,Jikang Zhang,Zicheng Wang,Ligeng Chen,Junjie Peng,Haiyang Wei,Yi Qian,Tiantai Zhang,Linzhang Wang,Bing Mao*

Main category: cs.SE

TL;DR: FeatureFuzz通过语义特征组合生成程序，显著提升编译器模糊测试效果，发现并确认大量关键缺陷。


<details>
  <summary>Details</summary>
Motivation: 现有方法（基于语法变异或通用LLM微调）难以保留触发错误的程序语义，导致生成的程序多样性受限。

Method: FeatureFuzz采用三阶段工作流程：从历史错误报告中提取特征，合成特征组，并将这些组实例化为有效程序用于编译器模糊测试。

Result: 在GCC和LLVM上评估显示，FeatureFuzz在24小时内发现167次独特崩溃（比次优方法多2.78倍），并在72小时内确认了76个编译器错误。

Conclusion: FeatureFuzz通过结合语义特征生成程序，显著提升了编译器模糊测试的效果，成功发现并确认了大量编译器中的关键缺陷。

Abstract: Compilers constitute the foundational root-of-trust in software supply chains; however, their immense complexity inevitably conceals critical defects. Recent research has attempted to leverage historical bugs to design new mutation operators or fine-tune models to increase program diversity for compiler fuzzing.We observe, however, that bugs manifest primarily based on the semantics of input programs rather than their syntax. Unfortunately, current approaches, whether relying on syntactic mutation or general Large Language Model (LLM) fine-tuning, struggle to preserve the specific semantics found in the logic of bug-triggering programs. Consequently, these critical semantic triggers are often lost, resulting in a limitation of the diversity of generated programs.
  To explicitly reuse such semantics, we propose FeatureFuzz, a compiler fuzzer that combines features to generate programs. We define a feature as a decoupled primitive that encapsulates a natural language description of a bug-prone invariant, such as an out-of-bounds array access, alongside a concrete code witness of its realization. FeatureFuzz operates via a three-stage workflow: it first extracts features from historical bug reports, synthesizes coherent groups of features, and finally instantiates these groups into valid programs for compiler fuzzing.
  We evaluated FeatureFuzz on GCC and LLVM. Over 24-hour campaigns, FeatureFuzz uncovered 167 unique crashes, which is 2.78x more than the second-best fuzzer. Furthermore, through a 72-hour fuzzing campaign, FeatureFuzz identified 106 bugs in GCC and LLVM, 76 of which have already been confirmed by compiler developers, validating the approach's ability to stress-test modern compilers effectively.

</details>


### [516] [Evaluating Large Language Models for Time Series Anomaly Detection in Aerospace Software](https://arxiv.org/abs/2601.12448)
*Yang Liu,Yixing Luo,Xiaofeng Li,Xiaogang Dong,Bin Gu,Zhi Jin*

Main category: cs.SE

TL;DR: ATSADBench是首个航空航天TSAD基准，评估LLMs在单/多变量任务中的表现，发现few-shot学习有效但RAG无效，为未来研究提供指导。


<details>
  <summary>Details</summary>
Motivation: 解决航空航天软件系统中时间序列异常检测（TSAD）的复杂性和领域知识缺失问题，评估LLMs在此领域的有效性。

Method: 引入了ATSADBench基准，包含9个任务，结合了三种异常类型、单变量和多变量信号，以及两种反馈场景，共108,000个数据点。评估了两种范式（直接和基于预测）下的开源LLMs，并提出了三个用户导向的指标（AA、AL、AC）。

Result: （1）LLMs在单变量任务中表现良好，但在多变量任务中接近随机猜测；（2）few-shot学习有适度提升，而RAG无显著改进；（3）LLMs能检测真实异常起始点，但有时会误报。

Conclusion: 研究发现为未来基于LLM的航空航天软件时间序列异常检测提供了指导。

Abstract: Time series anomaly detection (TSAD) is essential for ensuring the safety and reliability of aerospace software systems. Although large language models (LLMs) provide a promising training-free alternative to unsupervised approaches, their effectiveness in aerospace settings remains under-examined because of complex telemetry, misaligned evaluation metrics, and the absence of domain knowledge. To address this gap, we introduce ATSADBench, the first benchmark for aerospace TSAD. ATSADBench comprises nine tasks that combine three pattern-wise anomaly types, univariate and multivariate signals, and both in-loop and out-of-loop feedback scenarios, yielding 108,000 data points. Using this benchmark, we systematically evaluate state-of-the-art open-source LLMs under two paradigms: Direct, which labels anomalies within sliding windows, and Prediction-Based, which detects anomalies from prediction errors. To reflect operational needs, we reformulate evaluation at the window level and propose three user-oriented metrics: Alarm Accuracy (AA), Alarm Latency (AL), and Alarm Contiguity (AC), which quantify alarm correctness, timeliness, and credibility. We further examine two enhancement strategies, few-shot learning and retrieval-augmented generation (RAG), to inject domain knowledge. The evaluation results show that (1) LLMs perform well on univariate tasks but struggle with multivariate telemetry, (2) their AA and AC on multivariate tasks approach random guessing, (3) few-shot learning provides modest gains whereas RAG offers no significant improvement, and (4) in practice LLMs can detect true anomaly onsets yet sometimes raise false alarms, which few-shot prompting mitigates but RAG exacerbates. These findings offer guidance for future LLM-based TSAD in aerospace software.

</details>


### [517] [Improved Bug Localization with AI Agents Leveraging Hypothesis and Dynamic Cognition](https://arxiv.org/abs/2601.12522)
*Asif Mohammed Samir,Mohammad Masudur Rahman*

Main category: cs.SE

TL;DR: CogniGent是一种新型代理技术，通过因果推理和调用图分析提升缺陷定位性能，实验显示其显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统缺陷定位方法通常孤立分析代码组件的可疑性，忽视了代码库中组件间的联系；而现有的大型语言模型（LLMs）和代理AI技术在代码探索中缺乏因果推理能力，且难以有效管理日益增长的上下文，限制了其能力。

Method: 提出了一种新型代理技术CogniGent，利用多个具备因果推理能力的AI代理，基于调用图的根本原因分析和上下文工程，模拟开发者的动态认知调试过程，并进行假设测试以支持缺陷定位。

Result: 在591个缺陷报告的测试数据集上，CogniGent在文档和方法级别上均显著优于现有传统和基于LLM的技术，MAP提升23.33-38.57%，MRR提升25.14-53.74%，统计显著性测试也证实了其优越性。

Conclusion: CogniGent通过结合因果推理、调用图分析和上下文工程，显著提升了缺陷定位的性能，将人类认知与自动化代理相结合，推动了该领域的进步。

Abstract: Software bugs cost technology providers (e.g., AT&T) billions annually and cause developers to spend roughly 50% of their time on bug resolution. Traditional methods for bug localization often analyze the suspiciousness of code components (e.g., methods, documents) in isolation, overlooking their connections with other components in the codebase. Recent advances in Large Language Models (LLMs) and agentic AI techniques have shown strong potential for code understanding, but still lack causal reasoning during code exploration and struggle to manage growing context effectively, limiting their capability. In this paper, we present a novel agentic technique for bug localization -- CogniGent -- that overcomes the limitations above by leveraging multiple AI agents capable of causal reasoning, call-graph-based root cause analysis and context engineering. It emulates developers-inspired debugging practices (a.k.a., dynamic cognitive debugging) and conducts hypothesis testing to support bug localization. We evaluate CogniGent on a curated dataset of 591 bug reports using three widely adopted performance metrics and compare it against six established baselines from the literature. Experimental results show that our technique consistently outperformed existing traditional and LLM-based techniques, achieving MAP improvements of 23.33-38.57% at the document and method levels. Similar gains were observed in MRR, with increases of 25.14-53.74% at both granularity levels. Statistical significance tests also confirm the superiority of our technique. By addressing the reasoning, dependency, and context limitations, CogniGent advances the state of bug localization, bridging human-like cognition with agentic automation for improved performance.

</details>


### [518] [Automated Tool Support for Category-Partition Testing: Design Decisions, UI and Examples of Use](https://arxiv.org/abs/2601.12559)
*Yvan Labiche*

Main category: cs.SE

TL;DR: 论文介绍了一个自动化工具，用于简化Category-Partition测试技术，通过图形界面生成测试用例，并通过案例研究验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 旨在自动化Category-Partition测试技术的多个步骤，减少手动操作，提高测试效率和准确性。

Method: 论文提出了一种自动化工具，支持用户通过图形界面定义参数、环境变量、类别和选择，并自动生成测试框架和测试用例。

Result: 通过九个案例研究验证了工具的有效性，展示了其在生成测试用例和框架方面的能力。

Conclusion: 该论文展示了自动化工具在功能测试中的潜力，通过图形用户界面支持，显著提高了Category-Partition测试技术的效率和可操作性。

Abstract: Category-Partition is a functional testing technique that is based on the idea that the input domain of the system under test can be divided into sub-domains, with the assumption that inputs that belong to the same sub-domain trigger a similar behaviour and that therefore it is sufficient to select one input from each sub-domain. Category-Partition proceeds in several steps, from the identification of so-called categories and choices, possibly constrained, which are subsequently used to form test frames, i.e., combinations of choices, and eventually test cases. This paper reports on an ongoing attempt to automate as many of those steps as possible, with graphical-user interface tool support. Specifically, the user interface allows the user to specify parameters as well as so-called environment variables, further specify categories and choices with optional constraints. Choices are provided with precise specifications with operations specific to their types (e.g., Boolean, Integer, Real, String). Then, the tool automates the construction of test frames, which are combinations of choices, according to alternative selection criteria, and the identification of input values for parameters and environment variables for these test frames, thereby producing test cases. The paper illustrates the capabilities of the tool with the use of nine different case studies.

</details>


### [519] [OpenAI for OpenAPI: Automated generation of REST API specification via LLMs](https://arxiv.org/abs/2601.12735)
*Hao Chen,Yunchun Li,Chen Chen,Fengxu Lin,Wei Li*

Main category: cs.SE

TL;DR: OOPS是一种基于LLM的静态分析方法，用于高效生成高质量OAS，适用于多种技术栈，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 开发者在编写和维护OAS时面临挑战，现有静态分析方法受限于特定语言和框架，LLM虽具潜力但受上下文限制和幻觉问题制约。

Method: OOPS通过构建API依赖图解决LLM的上下文限制问题，采用多阶段生成和自优化机制减轻语法和语义幻觉。

Result: 在12个真实REST API上的实验显示，OOPS在端点方法推断、请求参数和响应推断、参数约束推断方面分别达到98%、97%、92%的F1分数，输入和输出token数均保持在较低水平。

Conclusion: OOPS是一种技术无关的基于LLM的静态分析方法，能够高效生成高质量的OAS，适用于多种编程语言和开发框架，显著减少了技术特定规则和人工干预的需求。

Abstract: REST APIs, based on the REpresentational State Transfer (REST) architecture, are the primary type of Web API. The OpenAPI Specification (OAS) serves as the de facto standard for describing REST APIs and is crucial for multiple software engineering tasks. However, developers face challenges in writing and maintaining OAS. Although static analysis shows potential for OAS generation, it is limited to specific programming languages and development frameworks. The powerful code understanding capabilities of LLMs offer new opportunities for OAS generation, yet they are constrained by context limitations and hallucinations. To address these challenges, we propose the OpenAI OpenAPI Project Scanner (OOPS), the first technology-agnostic LLM-based static analysis method for OAS generation, requiring fewer technology-specific rules and less human expert intervention. OOPS is implemented as an LLM agent workflow comprising two key steps: endpoint method extraction and OAS generation. By constructing an API dependency graph, it establishes necessary file associations to address LLMs' context limitations. Through multi-stage generation and self-refine, it mitigates both syntactic and semantic hallucinations during OAS generation. We evaluated OOPS on 12 real-world REST APIs spanning 5 programming languages and 8 development frameworks. Experimental results demonstrate that OOPS accurately generates high-quality OAS for REST APIs implemented with diverse technologies, achieving an average F1-score exceeding 98% for endpoint method inference, 97% for both request parameter and response inference, and 92% for parameter constraint inference. The input tokens average below 5.6K with a maximum of 16.2K, while the output tokens average below 0.9K with a maximum of 7.7K.

</details>


### [520] [Teaching LLMs to Learn Tool Trialing and Execution through Environment Interaction](https://arxiv.org/abs/2601.12762)
*Xingjie Gao,Pengcheng Huang,Zhenghao Liu,Yukun Yan,Shuo Wang,Zulong Chen,Chen Qian,Ge Yu,Yu Gu*

Main category: cs.SE

TL;DR: ToolMaster是一个通过主动交互学习工具使用的框架，显著提升LLMs对新工具的适应能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于记忆静态解决方案路径的方法限制了LLMs对新工具使用的泛化能力，因此需要一种更主动的学习框架。

Method: ToolMaster采用模仿教师生成的轨迹和强化学习相结合的方法，通过试错执行范式训练LLMs，使其能够自主探索正确的工具使用方式。

Result: 实验结果显示，ToolMaster在未见或陌生工具上的泛化和鲁棒性方面显著优于现有基线方法。

Conclusion: ToolMaster通过主动学习与环境交互的方式，显著提升了LLMs在工具使用上的泛化能力和鲁棒性，尤其在面对新工具时表现优异。

Abstract: Equipping Large Language Models (LLMs) with external tools enables them to solve complex real-world problems. However, the robustness of existing methods remains a critical challenge when confronting novel or evolving tools. Existing trajectory-centric paradigms primarily rely on memorizing static solution paths during training, which limits the ability of LLMs to generalize tool usage to newly introduced or previously unseen tools. In this paper, we propose ToolMaster, a framework that shifts tool use from imitating golden tool-calling trajectories to actively learning tool usage through interaction with the environment. To optimize LLMs for tool planning and invocation, ToolMaster adopts a trial-and-execution paradigm, which trains LLMs to first imitate teacher-generated trajectories containing explicit tool trials and self-correction, followed by reinforcement learning to coordinate the trial and execution phases jointly. This process enables agents to autonomously explore correct tool usage by actively interacting with environments and forming experiential knowledge that benefits tool execution. Experimental results demonstrate that ToolMaster significantly outperforms existing baselines in terms of generalization and robustness across unseen or unfamiliar tools. All code and data are available at https://github.com/NEUIR/ToolMaster.

</details>


### [521] [Docker Does Not Guarantee Reproducibility](https://arxiv.org/abs/2601.12811)
*Julien Malka,Stefano Zacchiroli,Théo Zimmermann*

Main category: cs.SE

TL;DR: 研究通过文献综述和实证分析探讨Docker的实际可复现性，填补理论与实践间的空白。


<details>
  <summary>Details</summary>
Motivation: 探讨Docker在实际应用中的可复现性，填补理论保证与实践限制之间的研究空白。

Method: 通过系统性文献综述分析Docker在科学讨论中的定位，并识别编写可复现Dockerfile的最佳实践；随后对5298个GitHub工作流中的Docker构建进行大规模实证研究，通过重建镜像并与历史版本对比评估实际可复现性。

Result: 实证研究揭示了Docker镜像的实际可复现性，并验证了文献中识别的最佳实践的有效性。

Conclusion: Docker的理论可复现性在实践中存在未充分探索的保证和限制，本研究通过文献综述和实证分析填补了这一空白。

Abstract: The reproducibility of software environments is a critical concern in modern software engineering, with ramifications ranging from the effectiveness of collaboration workflows to software supply chain security and scientific reproducibility. Containerization technologies like Docker address this problem by encapsulating software environments into shareable filesystem snapshots known as images. While Docker is frequently cited in the literature as a tool that enables reproducibility in theory, the extent of its guarantees and limitations in practice remains under-explored.
  In this work, we address this gap through two complementary approaches. First, we conduct a systematic literature review to examine how Docker is framed in scientific discourse on reproducibility and to identify documented best practices for writing Dockerfiles enabling reproducible image building. Then, we perform a large-scale empirical study of 5298 Docker builds collected from GitHub workflows. By rebuilding these images and comparing the results with their historical counterparts, we assess the real reproducibility of Docker images and evaluate the effectiveness of the best practices identified in the literature.

</details>


### [522] [Automatic Generation of Formal Specification and Verification Annotations Using LLMs and Test Oracles](https://arxiv.org/abs/2601.12845)
*João Pascoal Faria,Emanuel Trigo,Vinicius Honorato,Rui Abreu*

Main category: cs.SE

TL;DR: LLMs结合多模型和验证器反馈，能高效自动生成Dafny程序的形式化注释，正确率达98.2%，并集成到IDE中。


<details>
  <summary>Details</summary>
Motivation: 尽管形式化验证工具自动化程度提高，但为程序添加形式化注释仍需大量手动工作和专业知识，因此探索LLMs自动生成注释的可行性。

Method: 采用多模型方法（Claude Opus 4.5和GPT-5.2），结合验证器反馈进行最多8次修复迭代，生成Dafny程序的注释。测试用例中的断言作为静态验证工具。

Result: 在110个Dafny程序上实验，多模型方法在最多8次修复迭代内为98.2%的程序生成正确注释。逻辑回归分析显示，证明辅助注释对当前LLMs最具挑战性。

Conclusion: 本文展示了LLMs在自动生成Dafny程序的形式化注释方面的潜力，通过多模型结合和验证器反馈，实现了高正确率。同时，IDE扩展的实用性得到了积极反馈。

Abstract: Recent verification tools aim to make formal verification more accessible to software engineers by automating most of the verification process. However, annotating conventional programs with the formal specification and verification constructs (preconditions, postconditions, loop invariants, auxiliary predicates and functions and proof helpers) required to prove their correctness still demands significant manual effort and expertise. This paper investigates how LLMs can automatically generate such annotations for programs written in Dafny, a verification-aware programming language, starting from conventional code accompanied by natural language specifications (in comments) and test code. In experiments on 110 Dafny programs, a multimodel approach combining Claude Opus 4.5 and GPT-5.2 generated correct annotations for 98.2% of the programs within at most 8 repair iterations, using verifier feedback. A logistic regression analysis shows that proof-helper annotations contribute disproportionately to problem difficulty for current LLMs. Assertions in the test cases served as static oracles to automatically validate the generated pre/postconditions. We also compare generated and manual solutions and present an extension for Visual Studio Code to incorporate automatic generation into the IDE, with encouraging usability feedback.

</details>


### [523] [Efficient Code Analysis via Graph-Guided Large Language Models](https://arxiv.org/abs/2601.12890)
*Hang Gao,Tao Peng,Baoquan Cui,Hong Huang,Fengge Wu,Junsuo Zhao,Jian Zhang*

Main category: cs.SE

TL;DR: 提出图中心注意力管道，结合LLM和GNN提升恶意代码检测能力，实验证明其优于现有方法且适合实际部署。


<details>
  <summary>Details</summary>
Motivation: 恶意行为常隐藏在大型复杂代码库中易被忽视的小代码片段中，跨文件依赖使得即使是强大的LLM也难以可靠检测。

Method: 提出了一种图中心注意力获取管道，将项目解析为代码图，利用LLM编码节点语义和结构信号，并在稀疏监督下训练GNN进行初步检测，通过回溯预测识别关键代码段以指导LLM深入分析。

Result: 实验表明，该方法在多个公共和自建数据集上始终优于现有方法，显著减少了无关上下文的干扰并保持了低标注成本。

Conclusion: 该方法通过图中心注意力获取管道显著提升了LLM定位恶意行为的能力，并在多个数据集上优于现有方法，展示了其在软件安全场景中的实际部署潜力。

Abstract: Malicious behavior is often hidden in small, easily overlooked code fragments, especially within large and complex codebases. The cross-file dependencies of these fragments make it difficult for even powerful large language models (LLMs) to detect them reliably. We propose a graph-centric attention acquisition pipeline that enhances LLMs' ability to localize malicious behavior. The approach parses a project into a code graph, uses an LLM to encode nodes with semantic and structural signals, and trains a Graph Neural Network (GNN) under sparse supervision. The GNN performs an initial detection, and through backtracking of its predictions, identifies key code sections that are most likely to contain malicious behavior. These influential regions are then used to guide the LLM's attention for in-depth analysis. This strategy significantly reduces interference from irrelevant context while maintaining low annotation costs. Extensive experiments show that the method consistently outperforms existing methods on multiple public and self-built datasets, highlighting its potential for practical deployment in software security scenarios.

</details>


### [524] [A Benchmark for Language Models in Real-World System Building](https://arxiv.org/abs/2601.12927)
*Weilin Jin,Chenyu Zhao,Zeshun Huang,Chaoyun Zhang,Qingwei Lin,Chetan Bansal,Saravan Rajmohan,Shenglin Zhang,Yongqian Sun,Dan Pei,Yifan Wu,Tong Jia,Ying Li,Zhonghai Wu,Minghua Ma*

Main category: cs.SE

TL;DR: 该论文提出了一个跨ISA和语言的软件包构建修复基准，评估了六种LLM，发现该问题仍具挑战性，为未来研究奠定了基础。


<details>
  <summary>Details</summary>
Motivation: 解决跨指令集架构（ISA）和异构编程语言的软件包构建修复问题，此前研究主要局限于单一ISA和同质语言。

Method: 引入了一个包含268个真实世界软件包构建失败的新基准，并评估了六种最先进的LLM。

Result: 结果表明，跨ISA软件包修复仍然具有挑战性，需要进一步的技术进步。

Conclusion: 该基准测试为未来改进软件可移植性和弥合架构差距的方法奠定了基础。

Abstract: During migration across instruction set architectures (ISAs), software package build repair is a critical task for ensuring the reliability of software deployment and the stability of modern operating systems. While Large Language Models (LLMs) have shown promise in tackling this challenge, prior work has primarily focused on single instruction set architecture (ISA) and homogeneous programming languages. To address this limitation, we introduce a new benchmark designed for software package build repair across diverse architectures and languages. Comprising 268 real-world software package build failures, the benchmark provides a standardized evaluation pipeline. We evaluate six state-of-the-art LLMs on the benchmark, and the results show that cross-ISA software package repair remains difficult and requires further advances. By systematically exposing this challenge, the benchmark establishes a foundation for advancing future methods aimed at improving software portability and bridging architectural gaps.

</details>


### [525] [Beyond Accuracy: Characterizing Code Comprehension Capabilities in (Large) Language Models](https://arxiv.org/abs/2601.12951)
*Felix Mächtle,Jan-Niclas Serr,Nils Loose,Thomas Eisenbarth*

Main category: cs.SE

TL;DR: 论文提出诊断框架评估LLM代码理解能力，发现其性能与传统人类指标相关性低，影子模型表现更优，强调需转向实例级诊断。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs的代码理解性能是否与传统的人类中心软件指标一致，还是反映了独特的非人类规律。

Method: 引入了一个诊断框架，将代码理解重新定义为二元输入-输出一致性任务，支持分类和生成模型的评估。使用大规模数据集，将模型性能与传统的人类中心复杂性指标（如词汇量、控制流复杂性和抽象语法树结构）相关联。

Result: 分析显示人类定义的指标与LLM成功之间的相关性极小（AUROC 0.63），而影子模型实现了显著更高的预测性能（AUROC 0.86），捕捉到了超越传统软件测量的复杂、部分可预测模式。

Conclusion: LLM的理解能力反映了模型特有的规律，这些规律仅部分可通过人工设计或学习特征获取，强调了基准方法需要超越总体准确性，转向实例级诊断，同时承认预测正确结果的基本限制。

Abstract: Large Language Models (LLMs) are increasingly integrated into software engineering workflows, yet current benchmarks provide only coarse performance summaries that obscure the diverse capabilities and limitations of these models. This paper investigates whether LLMs' code-comprehension performance aligns with traditional human-centric software metrics or instead reflects distinct, non-human regularities. We introduce a diagnostic framework that reframes code understanding as a binary input-output consistency task, enabling the evaluation of classification and generative models. Using a large-scale dataset, we correlate model performance with traditional, human-centric complexity metrics, such as lexical size, control-flow complexity, and abstract syntax tree structure. Our analyses reveal minimal correlation between human-defined metrics and LLM success (AUROC 0.63), while shadow models achieve substantially higher predictive performance (AUROC 0.86), capturing complex, partially predictable patterns beyond traditional software measures. These findings suggest that LLM comprehension reflects model-specific regularities only partially accessible through either human-designed or learned features, emphasizing the need for benchmark methodologies that move beyond aggregate accuracy and toward instance-level diagnostics, while acknowledging fundamental limits in predicting correct outcomes.

</details>


### [526] [ArchAgent: Scalable Legacy Software Architecture Recovery with LLMs](https://arxiv.org/abs/2601.13007)
*Rusheng Pan,Bingcheng Mao,Tianyi Ma,Zhenhua Ling*

Main category: cs.SE

TL;DR: ArchAgent是一个基于代理的框架，通过静态分析、代码分割和LLM合成，有效恢复大规模遗留软件的架构，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决大规模遗留软件架构恢复中的架构漂移、缺失关系和LLM上下文有限的问题。

Method: ArchAgent是一个基于代理的可扩展框架，结合静态分析、自适应代码分割和LLM驱动的合成，支持从跨仓库代码库中重建多视图、业务对齐的架构。

Result: 评估显示，ArchAgent在典型的大规模GitHub项目上显著优于现有基准，消融研究证实依赖上下文提升了生成架构的准确性。

Conclusion: ArchAgent通过结合静态分析、自适应代码分割和LLM驱动的合成，显著提升了大规模遗留软件架构的恢复准确性，并在实际案例中成功恢复了关键业务逻辑。

Abstract: Recovering accurate architecture from large-scale legacy software is hindered by architectural drift, missing relations, and the limited context of Large Language Models (LLMs). We present ArchAgent, a scalable agent-based framework that combines static analysis, adaptive code segmentation, and LLM-powered synthesis to reconstruct multiview, business-aligned architectures from cross-repository codebases. ArchAgent introduces scalable diagram generation with contextual pruning and integrates cross-repository data to identify business-critical modules. Evaluations of typical large-scale GitHub projects show significant improvements over existing benchmarks. An ablation study confirms that dependency context improves the accuracy of generated architectures of production-level repositories, and a real-world case study demonstrates effective recovery of critical business logics from legacy projects. The dataset is available at https://github.com/panrusheng/arch-eval-benchmark.

</details>


### [527] [MeltRTL: Multi-Expert LLMs with Inference-time Intervention for RTL Code Generation](https://arxiv.org/abs/2601.13015)
*Nowfel Mashnoor,Mohammad Akyash,Hadi Kamali,Kimia Azar*

Main category: cs.SE

TL;DR: MeltRTL通过多专家注意力与推理时干预，显著提升LLM生成RTL代码的准确性，无需重新训练，计算开销低。


<details>
  <summary>Details</summary>
Motivation: 当前基于LLM的RTL代码生成方法在复杂数字设计中难以生成语法和功能正确的代码，因此需要一种无需重新训练基础模型即可提升准确率的解决方案。

Method: MeltRTL结合了多专家注意力架构和推理时干预（ITI）机制，通过动态路由设计规范到专家网络、非线性探针检测硬件特定错误，以及选择性操作专家特定注意力头来实现高效干预。

Result: 在VerilogEval基准测试中，MeltRTL实现了96%的可综合性和60%的功能正确性，显著优于基础LLM的85.3%和45.3%，且仅增加27%的计算开销。

Conclusion: MeltRTL框架通过多专家注意力架构和推理时干预机制，显著提升了基于LLM的RTL代码生成准确率，且无需重新训练基础模型，具有即插即用的优势。

Abstract: The automated generation of hardware register-transfer level (RTL) code with large language models (LLMs) shows promise, yet current solutions struggle to produce syntactically and functionally correct code for complex digital designs. This paper introduces MeltRTL, a novel framework that integrates multi-expert attention with inference-time intervention (ITI) to significantly improve LLM-based RTL code generation accuracy without retraining the base model. MeltRTL introduces three key innovations: (1) A multi-expert attention architecture that dynamically routes design specifications to specialized expert networks, enabling targeted reasoning across various hardware categories; (2) An inference-time intervention mechanism that employs non-linear probes to detect and correct hardware-specific inaccuracies during generation; and (3) An efficient intervention framework that selectively operates on expert-specific attention heads with minimal computational overhead. We evaluate MeltRTL on the VerilogEval benchmark, achieving 96% synthesizability and 60% functional correctness, compared to the base LLM's 85.3% and 45.3%, respectively. These improvements are obtained entirely at inference time, with only 27% computational overhead and no model fine-tuning, making MeltRTL immediately deployable on existing pre-trained LLMs. Ablation studies further show the complementary benefits of multi-expert architecture and ITI, highlighting their synergistic effects when combined.

</details>


### [528] [RM -RF: Reward Model for Run-Free Unit Test Evaluation](https://arxiv.org/abs/2601.13097)
*Elena Bruches,Daniil Grebenkin,Mikhail Klementev,Vadim Alperovich,Roman Derunets,Dari Baturova,Georgy Mkrtchyan,Oleg Sedukhin,Ivan Bondarenko,Nikolay Bushkov,Stanislav Moiseev*

Main category: cs.SE

TL;DR: RM-RF是一种轻量级奖励模型，通过预测执行衍生信号（编译运行成功、代码覆盖率提升、突变杀死率改进）替代传统编译执行，显著降低延迟和成本，适用于大规模测试生成和代码优化。


<details>
  <summary>Details</summary>
Motivation: 为了解决传统编译和执行工具的高延迟和高基础设施成本问题，提出RM-RF模型，以实现快速、可扩展的反馈，适用于大规模测试生成和基于RL的代码优化。

Method: 通过多语言数据集（Java、Python、Go）训练和评估RM-RF，测试了多种模型家族和调优机制（零样本、全微调和通过LoRA的PEFT），平均F1得分为0.69。

Result: RM-RF在三个目标上的平均F1得分为0.69，相比传统工具，提供了显著更低的延迟和基础设施成本，同时保持竞争力的预测准确性。

Conclusion: RM-RF是一种轻量级奖励模型，能够在不重复编译和执行候选测试的情况下，通过源代码和测试代码预测三个执行衍生信号，显著降低了延迟和基础设施成本，同时保持了竞争力的预测准确性。

Abstract: We present RM-RF, a lightweight reward model for run-free evaluation of automatically generated unit tests. Instead of repeatedly compiling and executing candidate tests, RM-RF predicts - from source and test code alone - three execution-derived signals: (1) whether the augmented test suite compiles and runs successfully, (2) whether the generated test cases increase code coverage, and (3) whether the generated test cases improve the mutation kill rate. To train and evaluate RM-RF we assemble a multilingual dataset (Java, Python, Go) of focal files, test files, and candidate test additions labeled by an execution-based pipeline, and we release an associated dataset and methodology for comparative evaluation. We tested multiple model families and tuning regimes (zero-shot, full fine-tuning, and PEFT via LoRA), achieving an average F1 of 0.69 across the three targets. Compared to conventional compile-and-run instruments, RM-RF provides substantially lower latency and infrastructure cost while delivering competitive predictive fidelity, enabling fast, scalable feedback for large-scale test generation and RL-based code optimization.

</details>


### [529] [Guidelines to Prompt Large Language Models for Code Generation: An Empirical Characterization](https://arxiv.org/abs/2601.13118)
*Alessandro Midolo,Alessandro Giagnorio,Fiorella Zampetti,Rosalia Tufano,Gabriele Bavota,Massimiliano Di Penta*

Main category: cs.SE

TL;DR: 本研究通过迭代测试驱动方法，提炼出10条代码生成提示优化指南，并经实践者评估证实其有效性。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏针对代码生成的提示编写指南，本研究旨在填补这一空白，帮助开发者编写更有效的提示。

Method: 采用迭代、测试驱动的方法自动优化代码生成提示，并分析结果以识别导致测试通过的提示改进项。

Result: 通过实践者评估，发现提出的提示改进模式在实际使用中具有价值，但其感知有用性与实际使用情况并不完全一致。

Conclusion: 本研究提出了10条针对代码生成的提示优化指南，并通过实践者评估验证了其有效性，为开发者、教育者及LLM辅助软件开发工具的设计者提供了实用建议。

Abstract: Large Language Models (LLMs) are nowadays extensively used for various types of software engineering tasks, primarily code generation. Previous research has shown how suitable prompt engineering could help developers in improving their code generation prompts. However, so far, there do not exist specific guidelines driving developers towards writing suitable prompts for code generation. In this work, we derive and evaluate development-specific prompt optimization guidelines. First, we use an iterative, test-driven approach to automatically refine code generation prompts, and we analyze the outcome of this process to identify prompt improvement items that lead to test passes. We use such elements to elicit 10 guidelines for prompt improvement, related to better specifying I/O, pre-post conditions, providing examples, various types of details, or clarifying ambiguities. We conduct an assessment with 50 practitioners, who report their usage of the elicited prompt improvement patterns, as well as their perceived usefulness, which does not always correspond to the actual usage before knowing our guidelines. Our results lead to implications not only for practitioners and educators, but also for those aimed at creating better LLM-aided software development tools.

</details>


### [530] [Earth Embeddings as Products: Taxonomy, Ecosystem, and Standardized Access](https://arxiv.org/abs/2601.13134)
*Heng Fang,Adam J. Stewart,Isaac Corley,Xiao Xiang Zhu,Hossein Azizpour*

Main category: cs.SE

TL;DR: 为解决地理空间基础模型高成本和嵌入产品碎片化问题，研究提出三层分类法并扩展TorchGeo，开发统一API标准化嵌入产品处理，促进地球观测工作流的透明和可访问性。


<details>
  <summary>Details</summary>
Motivation: 解决地理空间基础模型（GFMs）高计算成本和嵌入产品生态系统碎片化问题，促进模型比较和可重复性。

Method: 提出三层分类法（数据、工具、价值）并扩展TorchGeo以标准化嵌入产品的加载和查询。

Result: 开发了一个统一API，标准化了嵌入产品的加载和查询，将嵌入视为一等地理空间数据集。

Conclusion: 通过扩展TorchGeo并引入统一API，我们为地球观测工作流提供了更透明和可访问的路线图，解决了嵌入产品互操作性问题。

Abstract: Geospatial Foundation Models (GFMs) provide powerful representations, but high compute costs hinder their widespread use. Pre-computed embedding data products offer a practical "frozen" alternative, yet they currently exist in a fragmented ecosystem of incompatible formats and resolutions. This lack of standardization creates an engineering bottleneck that prevents meaningful model comparison and reproducibility. We formalize this landscape through a three-layer taxonomy: Data, Tools, and Value. We survey existing products to identify interoperability barriers. To bridge this gap, we extend TorchGeo with a unified API that standardizes the loading and querying of diverse embedding products. By treating embeddings as first-class geospatial datasets, we decouple downstream analysis from model-specific engineering, providing a roadmap for more transparent and accessible Earth observation workflows.

</details>


### [531] [From Human to Machine Refactoring: Assessing GPT-4's Impact on Python Class Quality and Readability](https://arxiv.org/abs/2601.13139)
*Alessandro Midolo,Emiliano Tramontana,Massimiliano Di Penta*

Main category: cs.SE

TL;DR: GPT-4o在自动化代码重构中表现良好，能提升代码质量但降低可读性，为LLM在实际重构中的应用提供了新见解。


<details>
  <summary>Details</summary>
Motivation: 尽管自动化重构工具已广泛研究，但其实际应用仍有限。LLM的最新进展为自动化代码重构带来了新机会，但其对代码质量的影响尚不明确。

Method: 使用GPT-4o对ClassEval基准中的100个Python类进行全面的实证研究，探索了Fowler目录启发的多种类级别重构，并从行为正确性、代码质量和可读性三个互补角度评估其效果。

Result: GPT-4o通常生成行为保持的重构，减少代码异味并提升质量指标，但可读性有所下降。

Conclusion: GPT-4o能够生成行为保持的代码重构，减少代码异味并提升质量指标，但会降低可读性。研究结果为LLM在自动化软件重构中的能力和局限性提供了新证据，并指出了将LLM集成到实际重构工作流中的方向。

Abstract: Refactoring is a software engineering practice that aims to improve code quality without altering program behavior. Although automated refactoring tools have been extensively studied, their practical applicability remains limited. Recent advances in Large Language Models (LLMs) have introduced new opportunities for automated code refactoring. The evaluation of such an LLM-driven approach, however, leaves unanswered questions about its effects on code quality. In this paper, we present a comprehensive empirical study on LLM-driven refactoring using GPT-4o, applied to 100 Python classes from the ClassEval benchmark. Unlike prior work, our study explores a wide range of class-level refactorings inspired by Fowler's catalog and evaluates their effects from three complementary perspectives: (i) behavioral correctness, verified through unit tests; (ii) code quality, assessed via Pylint, Flake8, and SonarCloud; and (iii) readability, measured using a state-of-the-art readability tool. Our findings show that GPT-4o generally produces behavior-preserving refactorings that reduce code smells and improve quality metrics, albeit at the cost of decreased readability. Our results provide new evidence on the capabilities and limitations of LLMs in automated software refactoring, highlighting directions for integrating LLMs into practical refactoring workflows.

</details>


### [532] [KOCO-BENCH: Can Large Language Models Leverage Domain Knowledge in Software Development?](https://arxiv.org/abs/2601.13240)
*Xue Jiang,Jiaru Qian,Xianjie Shi,Chenjie Li,Hao Zhu,Ziyu Wang,Jielun Zhang,Zheyu Zhao,Kechi Zhang,Jia Li,Wenpin Jiao,Zhi Jin,Ge Li,Yihong Dong*

Main category: cs.SE

TL;DR: KOCO-BENCH是一个评估LLMs领域专业化方法的新基准，包含多领域知识库和任务，结果显示现有方法效果有限。


<details>
  <summary>Details</summary>
Motivation: 现有领域特定代码基准无法评估领域专业化方法的有效性，因为它们侧重于评估LLMs具备的知识而非如何获取和应用新知识，且缺乏明确的知识库。

Method: 提出了KOCO-BENCH，一个包含6个新兴领域、11个软件框架和25个项目的新基准，配备精心策划的知识库和多粒度评估任务（从函数级到项目级的代码生成及领域知识理解的多选题）。

Result: 评估显示KOCO-BENCH对最先进的LLMs构成显著挑战，即使应用领域专业化方法，改进效果仍有限，最佳编码代理Claude Code仅达到34.2%。

Conclusion: KOCO-BENCH 揭示了当前领域专业化方法在提升LLMs性能方面的局限性，即使应用了最先进的方法（如SFT、RAG、kNN-LM），改进效果仍有限，最佳编码代理Claude Code仅达到34.2%。

Abstract: Large language models (LLMs) excel at general programming but struggle with domain-specific software development, necessitating domain specialization methods for LLMs to learn and utilize domain knowledge and data. However, existing domain-specific code benchmarks cannot evaluate the effectiveness of domain specialization methods, which focus on assessing what knowledge LLMs possess rather than how they acquire and apply new knowledge, lacking explicit knowledge corpora for developing domain specialization methods. To this end, we present KOCO-BENCH, a novel benchmark designed for evaluating domain specialization methods in real-world software development. KOCO-BENCH contains 6 emerging domains with 11 software frameworks and 25 projects, featuring curated knowledge corpora alongside multi-granularity evaluation tasks including domain code generation (from function-level to project-level with rigorous test suites) and domain knowledge understanding (via multiple-choice Q&A). Unlike previous benchmarks that only provide test sets for direct evaluation, KOCO-BENCH requires acquiring and applying diverse domain knowledge (APIs, rules, constraints, etc.) from knowledge corpora to solve evaluation tasks. Our evaluations reveal that KOCO-BENCH poses significant challenges to state-of-the-art LLMs. Even with domain specialization methods (e.g., SFT, RAG, kNN-LM) applied, improvements remain marginal. Best-performing coding agent, Claude Code, achieves only 34.2%, highlighting the urgent need for more effective domain specialization methods. We release KOCO-BENCH, evaluation code, and baselines to advance further research at https://github.com/jiangxxxue/KOCO-bench.

</details>


### [533] [SEER: Spectral Entropy Encoding of Roles for Context-Aware Attention-Based Design Pattern Detection](https://arxiv.org/abs/2601.13334)
*Tarik Houichime,Younes El Amrani*

Main category: cs.SE

TL;DR: SEER通过光谱熵角色编码和时间加权调用上下文改进GoF设计模式检测，显著提升性能并减少误报。


<details>
  <summary>Details</summary>
Motivation: 改进先前方法中缺乏明确的角色区分和调用边统一处理的问题，以更精确地捕捉代码中的“谁做什么”和“重要性”。

Method: SEER在原有方法基础上增加了两个关键组件：(i) 光谱熵角色编码器，通过类交互图的拉普拉斯谱生成每个成员的角色嵌入；(ii) 时间加权调用上下文，为不同方法类别分配经验校准的持续时间先验。

Result: 在PyDesignNet数据集上，SEER的macro-F1从92.47%提升至93.20%，准确率从92.52%提升至93.98%，并减少近20%的误报。

Conclusion: SEER通过引入光谱熵角色编码器和时间加权调用上下文，显著提升了GoF设计模式检测的准确性和鲁棒性，同时保持了跨语言的可移植性和与Transformer编码器的兼容性。

Abstract: This paper presents SEER, an upgraded version of our prior method Context Is All You Need for detecting Gang of Four (GoF) design patterns from source code. The earlier approach modeled code as attention-ready sequences that blended lightweight structure with behavioral context; however, it lacked explicit role disambiguation within classes and treated call edges uniformly. SEER addresses these limitations with two principled additions: (i) a spectral-entropy role encoder that derives per-member role embeddings from the Laplacian spectrum of each class's interaction graph, and (ii) a time-weighted calling context that assigns empirically calibrated duration priors to method categories (e.g., constructors, getters/setters, static calls, virtual dispatch, cloning). Together, these components sharpen the model's notion of "who does what" and "how much it matters," while remaining portable across languages with minimal adaptation and fully compatible with Transformer-based sequence encoders. Importantly, SEER does not "force" a win by capacity or data; it nudges the classifier, steering attention toward role-consistent and temporally calibrated signals that matter most. We evaluate SEER on PyDesignNet (1,832 files, 35,000 sequences, 23 GoF patterns) and observe consistent gains over our previous system: macro-F1 increases from 92.47% to 93.20% and accuracy from 92.52% to 93.98%, with macro-precision 93.98% and macro-recall 92.52%. Beyond aggregate metrics, SEER reduces false positives by nearly 20%, a decisive improvement that strengthens its robustness and practical reliability. Moreover, SEER yields interpretable, symbol-level attributions aligned with canonical roles, exhibits robustness under small graph perturbations, and shows stable calibration.

</details>


### [534] [FlipFlop: A Static Analysis-based Energy Optimization Framework for GPU Kernels](https://arxiv.org/abs/2601.13345)
*Saurabhsingh Rajput,Alexander Brandt,Vadim Elisseev,Tushar Sharma*

Main category: cs.SE

TL;DR: FlipFlop框架通过静态分析预测GPU能耗并推荐优化配置，显著提升能效和性能，减少开发者工作量。


<details>
  <summary>Details</summary>
Motivation: GPU程序（内核）消耗大量能源，但开发者通常缺乏硬件专业知识来优化能效。

Method: FlipFlop使用静态代码分析预测能耗，并推荐考虑功耗和执行时间的Pareto最优线程块配置，无需运行时执行，分析PTX代码。

Result: FlipFlop在多样化GPU和内核上验证，识别局部最优能效配置的准确率达83%，优化搜索空间减少93.4%，多头部注意力内核节能达79%，吞吐量提升106%。

Conclusion: FlipFlop框架通过静态代码分析和实时监控，帮助开发者创建既高性能又环保的GPU软件，显著减少环境和计算成本。

Abstract: Artificial Intelligence (AI) applications, such as Large Language Models, are primarily driven and executed by Graphics Processing Units (GPUs). These GPU programs (kernels) consume substantial amounts of energy, yet software developers often lack the hardware expertise and ad hoc knowledge required to optimize for power efficiency. We propose FlipFlop, a framework using static code analysis to predict energy consumption and recommend Pareto-optimal thread block configurations considering both power consumption and execution time. Our framework requires no runtime execution and analyzes PTX code, a low-level instruction set for CUDA-enabled GPUs. It is validated across a diverse set of GPUs and kernels, including multi-head attention, convolution, and matrix multiplication. FlipFlop achieves 83% accuracy in identifying locally optimal energy-efficient configurations, while also minimizing developer effort by reducing the optimization search space by 93.4%. For multi-head attention kernels, it yields up to 79% energy savings and 106% throughput gains relative to NVIDIA's occupancy heuristic. By integrating static analysis with real-time monitoring and providing explainable optimization guidance, FlipFlop empowers developers to create sustainable, high-performance GPU software which minimizes environmental and computational costs.

</details>


### [535] [Why Does the LLM Stop Computing: An Empirical Study of User-Reported Failures in Open-Source LLMs](https://arxiv.org/abs/2601.13655)
*Guangba Yu,Zirui Wang,Yujie Huang,Renyi Zhong,Yuedong Zhong,Yilun Wang,Michael R. Lyu*

Main category: cs.SE

TL;DR: 开源LLM部署的可靠性瓶颈从算法转向系统脆弱性，研究发现诊断分歧、系统同质性和生命周期升级是关键问题。


<details>
  <summary>Details</summary>
Motivation: 开源LLM的普及使用户能够在本地基础设施上微调和部署模型，但用户管理的编排可靠性成为关键盲点。

Method: 通过对开源DeepSeek、Llama和Qwen生态系统的705个真实故障进行大规模实证研究。

Result: 研究发现三个关键现象：诊断分歧、系统同质性和生命周期升级，揭示了部署栈的系统脆弱性。

Conclusion: 研究揭示了开源大语言模型（LLM）部署中的可靠性瓶颈从算法缺陷转向系统脆弱性，并提出了改善可靠性的具体建议。

Abstract: The democratization of open-source Large Language Models (LLMs) allows users to fine-tune and deploy models on local infrastructure but exposes them to a First Mile deployment landscape. Unlike black-box API consumption, the reliability of user-managed orchestration remains a critical blind spot. To bridge this gap, we conduct the first large-scale empirical study of 705 real-world failures from the open-source DeepSeek, Llama, and Qwen ecosystems.
  Our analysis reveals a paradigm shift: white-box orchestration relocates the reliability bottleneck from model algorithmic defects to the systemic fragility of the deployment stack. We identify three key phenomena: (1) Diagnostic Divergence: runtime crashes distinctively signal infrastructure friction, whereas incorrect functionality serves as a signature for internal tokenizer defects. (2) Systemic Homogeneity: Root causes converge across divergent series, confirming reliability barriers are inherent to the shared ecosystem rather than specific architectures. (3) Lifecycle Escalation: Barriers escalate from intrinsic configuration struggles during fine-tuning to compounded environmental incompatibilities during inference. Supported by our publicly available dataset, these insights provide actionable guidance for enhancing the reliability of the LLM landscape.

</details>


### [536] [From Completion to Editing: Unlocking Context-Aware Code Infilling via Search-and-Replace Instruction Tuning](https://arxiv.org/abs/2601.13384)
*Jiajun Zhang,Zeyu Cui,Jiaxi Yang,Lei Zhang,Yuheng Jing,Zeyao Ma,Tianyi Bai,Zilei Wang,Qiang Liu,Liang Wang,Binyuan Hui,Junyang Lin*

Main category: cs.SE

TL;DR: SRI框架通过结合代理验证和编辑机制，解决了FIM范式的局限性，使Chat模型在少量数据下超越基础模型的完成性能，同时保持低延迟和通用编码能力。


<details>
  <summary>Details</summary>
Motivation: 解决FIM范式在纠正上下文错误和依赖未对齐、不安全的基础模型方面的刚性限制，同时避免Chat LLMs的性能下降和代理工作流程的高延迟问题。

Method: 提出了Search-and-Replace Infilling (SRI)框架，通过显式搜索阶段结构化地定位编辑，将完成任务与Chat LLMs的指令遵循先验相结合。

Result: 通过SRI-200K数据集和SRI-Coder系列的微调，实验证明SRI-Coder使Chat模型在少量数据（20k样本）下超越其基础模型的完成性能。

Conclusion: SRI框架通过将代理验证和编辑机制内部化为统一的单次推理过程，成功解决了FIM范式的局限性，同时保持了推理延迟与标准FIM相当，并保留了通用的编码能力。

Abstract: The dominant Fill-in-the-Middle (FIM) paradigm for code completion is constrained by its rigid inability to correct contextual errors and reliance on unaligned, insecure Base models. While Chat LLMs offer safety and Agentic workflows provide flexibility, they suffer from performance degradation and prohibitive latency, respectively. To resolve this dilemma, we propose Search-and-Replace Infilling (SRI), a framework that internalizes the agentic verification-and-editing mechanism into a unified, single-pass inference process. By structurally grounding edits via an explicit search phase, SRI harmonizes completion tasks with the instruction-following priors of Chat LLMs, extending the paradigm from static infilling to dynamic context-aware editing. We synthesize a high-quality dataset, SRI-200K, and fine-tune the SRI-Coder series. Extensive evaluations demonstrate that with minimal data (20k samples), SRI-Coder enables Chat models to surpass the completion performance of their Base counterparts. Crucially, unlike FIM-style tuning, SRI preserves general coding competencies and maintains inference latency comparable to standard FIM. We empower the entire Qwen3-Coder series with SRI, encouraging the developer community to leverage this framework for advanced auto-completion and assisted development.

</details>


### [537] [A Blockchain-Oriented Software Engineering Architecture for Carbon Credit Certification Systems](https://arxiv.org/abs/2601.13772)
*Matteo Vaccargiu,Azmat Ullah,Pierluigi Gallo*

Main category: cs.SE

TL;DR: 本文提出了一种基于区块链的碳信用认证架构，整合物联网和智能合约，适用于中小型可再生能源装置，符合欧洲法规和碳市场标准。


<details>
  <summary>Details</summary>
Motivation: 现有区块链和物联网技术在排放监测和交易中的应用对认证过程支持有限，特别是针对中小型可再生能源装置。

Method: 通过整合实时物联网数据收集、边缘级聚合以及在许可区块链上的安全链上存储与智能合约，构建了一个区块链碳信用认证架构，并以100千瓦光伏案例研究进行演示。

Result: 该架构为光伏运营商明确了实际要求和约束，提供了一种结构化路径来生成可验证的碳信用记录。

Conclusion: 本文提出的基于区块链的碳信用认证架构为中小型可再生能源装置提供了一种可验证的碳信用记录生成路径，并支持第三方验证，符合欧洲立法和自愿碳市场标准。

Abstract: Carbon credit systems have emerged as a policy tool to incentivize emission reductions and support the transition to clean energy. Reliable carbon-credit certification depends on mechanisms that connect actual, measured renewable-energy production to verifiable emission-reduction records. Although blockchain and IoT technologies have been applied to emission monitoring and trading, existing work offers limited support for certification processes, particularly for small and medium-scale renewable installations. This paper introduces a blockchain-based carbon-credit certification architecture, demonstrated through a 100 kWp photovoltaic case study, that integrates real-time IoT data collection, edge-level aggregation, and secure on-chain storage on a permissioned blockchain with smart contracts. Unlike approaches focused on trading mechanisms, the proposed system aligns with European legislation and voluntary carbon-market standards, clarifying the practical requirements and constraints that apply to photovoltaic operators. The resulting architecture provides a structured pathway for generating verifiable carbon-credit records and supporting third-party verification.

</details>


### [538] [A Tool for Automatically Cataloguing and Selecting Pre-Trained Models and Datasets for Software Engineering](https://arxiv.org/abs/2601.13460)
*Alexandra González,Oscar Cerezo,Xavier Franch,Silverio Martínez-Fernández*

Main category: cs.SE

TL;DR: MLAssetSelection是一个Web应用，帮助软件工程师高效选择机器学习资产，具备排行榜、需求选择、实时更新和用户功能。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习资产的快速增长，软件工程师难以高效识别适合其需求的模型和数据集，传统方法耗时且易出错。

Method: 开发了一个名为MLAssetSelection的Web应用程序，具备可配置的排行榜、基于需求的选择、实时自动更新以及用户中心功能。

Result: MLAssetSelection支持四项关键功能，包括可配置排行榜、需求选择、实时更新和用户中心功能，显著提升了资产选择的效率和准确性。

Conclusion: MLAssetSelection是一个有效的工具，帮助软件工程师快速识别和选择适合其需求的机器学习模型和数据集，解决了传统方法耗时且易出错的问题。

Abstract: The rapid growth of machine learning assets has made it increasingly difficult for software engineers to identify models and datasets that match their specific needs. Browsing large registries, such as Hugging Face, is time-consuming, error-prone, and rarely tailored to Software Engineering (SE) tasks. We present MLAssetSelection, a web application that automatically extracts SE assets and supports four key functionalities: (i) a configurable leaderboard for ranking models across multiple benchmarks and metrics; (ii) requirements-based selection of models and datasets; (iii) real-time automated updates through scheduled jobs that keep asset information current; and (iv) user-centric features including login, personalized asset lists, and configurable alert notifications. A demonstration video is available at https://youtu.be/t6CJ6P9asV4.

</details>


### [539] [Governance Matters: Lessons from Restructuring the data.table OSS Project](https://arxiv.org/abs/2601.13466)
*Pedro Oliveira,Doris Amoakohene,Toby Hocking,Marco Gerosa,Igor Steinmacher*

Main category: cs.SE

TL;DR: 本文通过data.table案例展示了社区主导的治理改革如何显著提升开源项目的贡献者招募、问题解决效率和社区满意度，为类似项目提供了参考。


<details>
  <summary>Details</summary>
Motivation: 开源软件（OSS）项目常因非正式或集中化治理面临运营风险，data.table项目通过社区主导的治理改革解决了可扩展性和可持续性问题。

Method: 采用混合方法，结合贡献者调查（n=17）和项目仓库数据挖掘。

Result: 改革后，项目新贡献者招募增加了200%，拉取请求解决时间从700多天降至一周内，贡献者留存率提高了3倍。社区对透明度、入门和项目动力的情感有所改善，但对公平性和冲突解决的担忧仍然存在。

Conclusion: 本案例研究为维护者、公司和基金会提供了增强开源软件治理的实用指南。

Abstract: Open source software (OSS) forms the backbone of industrial data workflows and enterprise systems. However, many OSS projects face operational risks due to informal or centralized governance. This paper presents a practical case study of data.table, a high-performance R package widely adopted in production analytics pipelines, which underwent a community-led governance reform to address scalability and sustainability concerns. Before the reform, data.table faced a growing backlog of unresolved issues and open pull requests, unclear contributor pathways, and bottlenecks caused by reliance on a single core maintainer. In response, the community initiated a redesign of its governance structure. In this paper, we evaluated the impact of this transition through a mixed-methods approach, combining a contributor survey (n=17) with mining project repository data. Our results show that following the reform, the project experienced a 200% increase in new contributor recruitment, a drop in pull request resolution time from over 700 days to under a week, and a 3x increase in contributor retention. Community sentiment improved around transparency, onboarding, and project momentum, though concerns around fairness and conflict resolution remain. This case study provides practical guidance for maintainers, companies, and foundations seeking to enhance OSS governance.

</details>


### [540] [AI IDEs or Autonomous Agents? Measuring the Impact of Coding Agents on Software Development](https://arxiv.org/abs/2601.13597)
*Shyam Agarwal,Hao He,Bogdan Vasilescu*

Main category: cs.SE

TL;DR: LLM编码代理在无AI工具的项目中显著提速但增加质量风险；已有AI工具的项目受益有限，需平衡速度与维护性。


<details>
  <summary>Details</summary>
Motivation: 探究LLM编码代理对开源项目的实际影响，尤其是与广泛使用的IDE AI助手相比。

Method: 采用纵向因果研究，利用交错差分法和匹配对照分析AIDev数据集中的代理采用情况。

Result: 代理首次采用的项目开发速度显著提升，但质量风险（如静态分析警告和认知复杂度）持续增加；已有AI工具的项目速度提升有限。

Conclusion: 研究表明，基于LLM的编码代理在无先前AI工具的项目中能显著提升开发速度，但质量风险普遍存在，需平衡速度与可维护性。

Abstract: Large language model (LLM)-based coding agents increasingly act as autonomous contributors that generate and merge pull requests, yet their real-world effects on software projects are unclear, especially relative to widely adopted IDE-based AI assistants. We present a longitudinal causal study of agent adoption in open-source repositories using staggered difference-in-differences with matched controls. Using the AIDev dataset, we define adoption as the first agent-generated pull request and analyze monthly repository-level outcomes spanning development velocity (commits, lines added) and software quality (static-analysis warnings, cognitive complexity, duplication, and comment density). Results show large, front-loaded velocity gains only when agents are the first observable AI tool in a project; repositories with prior AI IDE usage experience minimal or short-lived throughput benefits. In contrast, quality risks are persistent across settings, with static-analysis warnings and cognitive complexity rising roughly 18% and 35%, indicating sustained agent-induced complexity debt even when velocity advantages fade. These heterogeneous effects suggest diminishing returns to AI assistance and highlight the need for quality safeguards, provenance tracking, and selective deployment of autonomous agents. Our findings establish an empirical basis for understanding how agentic and IDE-based tools interact, and motivate research on balancing acceleration with maintainability in AI-integrated development workflows.

</details>


### [541] [CodeContests-O: Powering LLMs via Feedback-Driven Iterative Test Case Generation](https://arxiv.org/abs/2601.13682)
*Jianfeng Cai,Jinhua Zhu,Ruopei Sun,Kangwen Zhao,Dongyun Xue,Mingxiao Feng,Wengang Zhou,Houqiang Li*

Main category: cs.SE

TL;DR: 论文提出反馈驱动框架优化测试案例生成，构建高质量数据集CodeContests-O，显著提升性能并开源资源。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法依赖LLM内在生成能力而缺乏外部反馈，导致测试案例多样性不足的问题。

Method: 利用大型语言模型（LLM）生成初始测试案例，通过执行已知正确和错误解决方案并利用失败结果作为反馈，迭代优化测试案例的保真度和区分度。

Result: CodeContests-O数据集在TPR和TNR上分别达到89.37%和90.89%，显著优于基准数据集，且微调模型在LiveCodeBench上提升9.52%。

Conclusion: 该论文提出的反馈驱动迭代框架显著提升了测试案例的质量，通过CodeContests-O数据集验证了其高效性，并开源了代码和数据集以支持未来研究。

Abstract: The rise of reasoning models necessitates large-scale verifiable data, for which programming tasks serve as an ideal source. However, while competitive programming platforms provide abundant problems and solutions, high-quality test cases for verification remain scarce. Existing approaches attempt to synthesize test cases using Large Language Models (LLMs), but rely solely on the model's intrinsic generation capabilities without external feedback, frequently resulting in insufficiently diverse cases. To address this limitation, we propose a $\textbf{Feedback-Driven Iterative Framework}$ for comprehensive test case construction. Specifically, our method leverages the LLM to generate initial test cases, executes them against known correct and incorrect solutions, and utilizes the failed results as feedback to guide the LLM in refining the test cases toward high fidelity and discriminability. We then apply this method to the CodeContests dataset to construct an optimized high-quality derivative, $\textbf{CodeContests-O}$. Evaluating against the entire pool of solutions ($1.1 \times 10^7$ in total), our dataset achieves an average True Positive Rate (TPR) of $89.37\%$ and True Negative Rate (TNR) of $90.89\%$, significantly outperforming the CodeContests and CodeContests+ by margins of $4.32\%$ and $9.37\%$, respectively. Furthermore, fine-tuning the Qwen2.5-7B model on CodeContests-O results in a $9.52\%$ improvement on LiveCodeBench (Pass@1). Experiments demonstrate the effectiveness of our framework and the quality of CodeContests-O. To support reproducibility and facilitate future research, we release the $\href{https://github.com/cai-jianfeng/CodeContests-O}{code}$ and $\href{https://huggingface.co/datasets/caijanfeng/CodeContests-O}{dataset}$.

</details>


### [542] [SWE-Tester: Training Open-Source LLMs for Issue Reproduction in Real-World Repositories](https://arxiv.org/abs/2601.13713)
*Aditya Bharat Soni,Rajat Ghosh,Vaishnavi Bhargava,Valerie Chen,Debojyoti Dutta*

Main category: cs.SE

TL;DR: 提出SWE-Tester框架，通过开源LLMs生成问题复现测试，提升开发者效率。微调模型在基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 自动化生成问题复现测试可提升开发者效率，促进测试驱动开发，并增强自动化问题解决系统的效果。现有方法主要依赖闭源LLMs，开源模型探索有限。

Method: 首先从2.6K个开源GitHub仓库中筛选出41K个高质量训练实例，用于训练不同规模和家族的LLMs。

Result: 微调模型在SWT-Bench Verified上成功率提升10%，变更覆盖率提升21%。分析显示，增加推理计算、数据量和模型规模能带来持续改进。

Conclusion: SWE-Tester框架在提升开源LLMs生成问题复现测试方面表现出色，展示了其在领域内的有效性。

Abstract: Software testing is crucial for ensuring the correctness and reliability of software systems. Automated generation of issue reproduction tests from natural language issue descriptions enhances developer productivity by simplifying root cause analysis, promotes test-driven development -- "test first, write code later", and can be used for improving the effectiveness of automated issue resolution systems like coding agents. Existing methods proposed for this task predominantly rely on closed-source LLMs, with limited exploration of open models. To address this, we propose SWE-Tester -- a novel pipeline for training open-source LLMs to generate issue reproduction tests. First, we curate a high-quality training dataset of 41K instances from 2.6K open-source GitHub repositories and use it to train LLMs of varying sizes and families. The fine-tuned models achieve absolute improvements of up to 10\% in success rate and 21\% in change coverage on SWT-Bench Verified. Further analysis shows consistent improvements with increased inference-time compute, more data, and larger models. These results highlight the effectiveness of our framework for advancing open-source LLMs in this domain.

</details>


### [543] [Counterexample Classification against Signal Temporal Logic Specifications](https://arxiv.org/abs/2601.13743)
*Zhenya Zhang,Parv Kapoor,Jie An,Eunsuk Kang*

Main category: cs.SE

TL;DR: 提出基于PSTL的反例分类标准，优化查询效率，实验验证有效性。


<details>
  <summary>Details</summary>
Motivation: 实践中，反例可能由不同原因引起，需分类以理解违规模式及其分布。

Method: 通过PSTL表示每个类别，并利用参数值确定反例所属类别。进一步推导类别间的包含关系，提出类似二分搜索的方法以优化查询效率。

Result: 实现原型工具并在两个广泛研究的系统中验证了方法的有效性。

Conclusion: 本文提出了一种基于参数信号时序逻辑（PSTL）的分类标准，用于有效分类混合系统中的反例，并通过实验验证了其有效性。

Abstract: Signal Temporal Logic (STL) has been widely adopted as a specification language for specifying desirable behaviors of hybrid systems. By monitoring a given STL specification, we can detect the executions that violate it, which are often referred to as counterexamples. In practice, these counterexamples may arise from different causes and thus are relevant to different system defects. To effectively address this, we need a proper criterion for classifying these counterexamples, by which we can comprehend the possible violation patterns and the distributions of these counterexamples with respect to the patterns. In this paper, we propose a classification criterion by using parametric signal temporal logic (PSTL) to represent each class. Due to this formalism, identifying the classes of a counterexample requires finding proper parameter values of PSTL that enable a class to include the counterexample. To improve the efficiency of class identification, we further derive an inclusion relation between different classes, and then propose a binary search-like approach over it that significantly prunes the classes needed to query. We implement a prototype tool and experimentally evaluate its effectiveness on two widely-studied systems.

</details>


### [544] [On Autopilot? An Empirical Study of Human-AI Teaming and Review Practices in Open Source](https://arxiv.org/abs/2601.13754)
*Haoyu Gao,Peerachai Banyongrakkul,Hao Guan,Mansooreh Zahedi,Christoph Treude*

Main category: cs.SE

TL;DR: 研究分析了AI协作PRs的开发者交互模式，发现其合并速度更快且反馈极少，大多数仓库缺乏AI使用指南。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在软件工程任务中日益自动化，且"AI作为队友"在开源软件中加速采用，但开发者交互模式尚未深入探索。

Method: 研究通过扩展AIDev数据集，包括更细粒度的贡献者代码所有权和人类创建PRs的比较基线，分析了项目级指南和开发者与AI辅助PRs的交互。

Result: 研究发现67.5%的AI协作PRs来自无代码所有权贡献者，且大多数仓库缺乏AI使用指南。AI协作PRs合并速度更快，反馈极少，80%的非所有者AI协作PRs未经明确审查即被合并。

Conclusion: 论文讨论了开发者与AI辅助拉取请求（PRs）的交互模式，并指出尽管大多数AI协作的PRs来自无代码所有权贡献者，但大多数仓库缺乏AI编码代理的使用指南。AI协作的PRs合并速度显著更快且反馈极少，这与人类创建的PRs形成鲜明对比。

Abstract: Large Language Models (LLMs) increasingly automate software engineering tasks. While recent studies highlight the accelerated adoption of ``AI as a teammate'' in Open Source Software (OSS), developer interaction patterns remain under-explored. In this work, we investigated project-level guidelines and developers' interactions with AI-assisted pull requests (PRs) by expanding the AIDev dataset to include finer-grained contributor code ownership and a comparative baseline of human-created PRs. We found that over 67.5\% of AI-co-authored PRs originate from contributors without prior code ownership. Despite this, the majority of repositories lack guidelines for AI-coding agent usage. Notably, we observed a distinct interaction pattern: AI-co-authored PRs are merged significantly faster with minimal feedback. In contrast to human-created PRs where non-owner developers receive the most feedback, AI-co-authored PRs from non-owners receive the least, with approximately 80\% merged without any explicit review. Finally, we discuss implications for developers and researchers.

</details>


### [545] [Multi-Location Software Model Completion](https://arxiv.org/abs/2601.13894)
*Alisa Welter,Christof Tinnes,Sven Apel*

Main category: cs.SE

TL;DR: 提出NextFocus方法，首次实现多位置模型补全，显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 当前LLM支持的软件模型补全仅支持单位置变更，无法处理跨多位置的协调变更，因此需要开发能处理复杂模型中多位置变更的方法。

Method: 提出了一种基于全局嵌入的下一个焦点预测器NextFocus，利用带有注意力机制的神经网络，通过历史软件模型演化数据进行训练。

Result: NextFocus在多位置模型变更中表现优异，Precision@k得分平均达到0.98（k≤10），显著优于基线方法。

Conclusion: NextFocus在跨多位置的模型补全中表现出色，显著优于基线方法，为软件建模自动化提供了新的可能性。

Abstract: In model-driven engineering and beyond, software models are key development artifacts. In practice, they often grow to substantial size and complexity, undergoing thousands of modifications over time due to evolution, refactoring, and maintenance. The rise of AI has sparked interest in how software modeling activities can be automated. Recently, LLM-based approaches for software model completion have been proposed, however, the state of the art supports only single-location model completion by predicting changes at a specific location. Going beyond, we aim to bridge the gap toward handling coordinated changes that span multiple locations across large, complex models. Specifically, we propose a novel global embedding-based next focus predictor, NextFocus, which is capable of multi-location model completion for the first time. The predictor consists of a neural network with an attention mechanism that is trained on historical software model evolution data. Starting from an existing change, it predicts further model elements to change, potentially spanning multiple parts of the model. We evaluate our approach on multi-location model changes that have actually been performed by developers in real-world projects. NextFocus achieves promising results for multi-location model completion, even when changes are heavily spread across the model. It achieves an average Precision@k score of 0.98 for $k \leq 10$, significantly outperforming the three baseline approaches.

</details>


### [546] [VulnResolver: A Hybrid Agent Framework for LLM-Based Automated Vulnerability Issue Resolution](https://arxiv.org/abs/2601.13933)
*Mingming Zhang,Xu Wang,Jian Zhang,Xiangxin Meng,Jiayi Zhang,Chunming Hu*

Main category: cs.SE

TL;DR: VulnResolver是一个基于LLM的混合代理框架，通过两个专用代理（CPCAgent和SPAAgent）实现自动化漏洞问题解决，在SEC-bench基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 随着软件系统复杂度的增加，安全漏洞日益普遍，带来严重风险和经济成本。现有的自动化漏洞修复方法依赖手动提供的注释，这些注释难以获取，同时忽略了开发者问题报告中丰富的自然语义上下文。

Method: VulnResolver结合了自主代理的适应性和工作流引导修复的稳定性，通过两个专用代理（CPCAgent和SPAAgent）来收集依赖和上下文信息，并生成和验证被漏洞违反的安全属性。

Result: 在SEC-bench基准测试中，VulnResolver在SEC-bench Lite上解决了75%的问题，表现最佳；在SEC-bench Full上也显著优于基线方法OpenHands。

Conclusion: VulnResolver提供了一个自适应且安全感知的框架，通过工作流稳定性和专用代理在上下文推理和基于属性的分析方面的能力，推进了端到端的自动化漏洞问题解决。

Abstract: As software systems grow in complexity, security vulnerabilities have become increasingly prevalent, posing serious risks and economic costs. Although automated detection tools such as fuzzers have advanced considerably, effective resolution still often depends on human expertise. Existing automated vulnerability repair (AVR) methods rely heavily on manually provided annotations (e.g., fault locations or CWE labels), which are often difficult and time-consuming to obtain, while overlooking the rich, naturally embedded semantic context found in issue reports from developers.
  In this paper, we present VulnResolver, the first LLM-based hybrid agent framework for automated vulnerability issue resolution. VulnResolver unites the adaptability of autonomous agents with the stability of workflow-guided repair through two specialized agents. The Context Pre-Collection Agent (CPCAgent) adaptively explores the repository to gather dependency and contextual information, while the Safety Property Analysis Agent (SPAAgent) generates and validates the safety properties violated by vulnerabilities. Together, these agents produce structured analyses that enrich the original issue reports, enabling more accurate vulnerability localization and patch generation.
  Evaluations on the SEC-bench benchmark show that VulnResolver resolves 75% of issues on SEC-bench Lite, achieving the best resolution performance. On SEC-bench Full, VulnResolver also significantly outperforms the strongest baseline, the agent-based OpenHands, confirming its effectiveness. Overall, VulnResolver delivers an adaptive and security-aware framework that advances end-to-end automated vulnerability issue resolution through workflow stability and the specialized agents' capabilities in contextual reasoning and property-based analysis.

</details>


### [547] [RepoGenesis: Benchmarking End-to-End Microservice Generation from Readme to Repository](https://arxiv.org/abs/2601.13943)
*Zhiyuan Peng,Xin Yin,Pu Zhao,Fangkai Yang,Lu Wang,Ran Jia,Xu Chen,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang*

Main category: cs.SE

TL;DR: RepoGenesis 是首个多语言仓库级别微服务生成基准测试，评估显示现有工具在完整仓库生成上仍有不足，但微调后的 GenesisAgent-8B 表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的基准测试集中在孤立的函数/类级别生成或对现有代码库的修改，忽略了反映真实世界 0 到 1 开发流程的完整微服务仓库生成。

Method: 引入了 RepoGenesis 基准测试，包含 106 个仓库（60 Python，46 Java），覆盖 18 个领域和 11 个框架，通过“review-rebuttal”质量保证流程验证了 1,258 个 API 端点和 2,335 个测试用例。评估了开源代理和商业 IDE 的性能。

Result: 尽管 API 覆盖率（AC）和部署成功率（DSR）较高，最佳系统的 Pass@1 在 Python 和 Java 上分别仅为 23.67% 和 21.45%，揭示了在架构一致性、依赖管理和跨文件一致性方面的不足。GenesisAgent-8B 的表现与 GPT-5 mini 相当。

Conclusion: RepoGenesis 是一个多语言的仓库级别端到端微服务生成基准测试，展示了其在推动微服务生成方面的质量，并通过 GenesisAgent-8B 的表现证明了其有效性。

Abstract: Large language models and agents have achieved remarkable progress in code generation. However, existing benchmarks focus on isolated function/class-level generation (e.g., ClassEval) or modifications to existing codebases (e.g., SWE-Bench), neglecting complete microservice repository generation that reflects real-world 0-to-1 development workflows. To bridge this gap, we introduce RepoGenesis, the first multilingual benchmark for repository-level end-to-end web microservice generation, comprising 106 repositories (60 Python, 46 Java) across 18 domains and 11 frameworks, with 1,258 API endpoints and 2,335 test cases verified through a "review-rebuttal" quality assurance process. We evaluate open-source agents (e.g., DeepCode) and commercial IDEs (e.g., Cursor) using Pass@1, API Coverage (AC), and Deployment Success Rate (DSR). Results reveal that despite high AC (up to 73.91%) and DSR (up to 100%), the best-performing system achieves only 23.67% Pass@1 on Python and 21.45% on Java, exposing deficiencies in architectural coherence, dependency management, and cross-file consistency. Notably, GenesisAgent-8B, fine-tuned on RepoGenesis (train), achieves performance comparable to GPT-5 mini, demonstrating the quality of RepoGenesis for advancing microservice generation. We release our benchmark at https://github.com/pzy2000/RepoGenesis.

</details>


### [548] [Software Testing in the Quantum World](https://arxiv.org/abs/2601.13996)
*Rui Abreu,Shaukat Ali,Paolo Arcaini,Jose Campos,Michael Felderer,Claude Gravel,Fuyuki Ishikawa,Stefan Klikovits,Andriy Miranskyy,Mohammad Mousavi,Masaomi Yamaguchi,Lei Zhang,Jianjun Zhao,Anila Mjeda*

Main category: cs.SE

TL;DR: 本文探讨了量子软件测试的挑战，并提出了软件工程解决方案。


<details>
  <summary>Details</summary>
Motivation: 随着量子软件复杂度的增加，传统的经典模拟方法变得不可行，需要新的质量保证方法直接在真实量子计算机上操作。

Method: 分析了量子软件测试的关键挑战，并提出了软件工程方法。

Result: 识别了大规模量子软件测试的主要挑战，并提供了相应的解决方案。

Conclusion: 本文提出了解决大规模量子软件测试关键挑战的软件工程视角。

Abstract: Quantum computing offers significant speedups for simulating physical, chemical, and biological systems, and for optimization and machine learning. As quantum software grows in complexity, the classical simulation of quantum computers, which has long been essential for quality assurance, becomes infeasible. This shift requires new quality-assurance methods that operate directly on real quantum computers. This paper presents the key challenges in testing large-scale quantum software and offers software engineering perspectives for addressing them.

</details>


### [549] [Analyzing the Availability of E-Mail Addresses for PyPI Libraries](https://arxiv.org/abs/2601.14034)
*Alexandros Tsakpinis,Alexander Pretschner*

Main category: cs.SE

TL;DR: 研究发现Python库中维护者联系信息的有效性较高，但仍有改进空间，如优化打包指导和引入验证机制。


<details>
  <summary>Details</summary>
Motivation: 探讨开源软件库的长期可持续性依赖于维护者的可达性，特别是联系信息的有效性。

Method: 通过实证分析686,034个PyPI上的Python库及其关联的GitHub仓库，评估联系信息的有效性和覆盖范围。

Result: 81.6%的库包含至少一个有效电子邮件地址，PyPI是主要来源（79.5%）。依赖链中直接和间接依赖的有效联系信息覆盖率分别高达97.8%和97.7%，但也发现了698,000多个无效条目。

Conclusion: 研究结果表明，Python生态系统中的维护者可达性较高，但仍存在改进空间，如提供更清晰的打包指导和引入电子邮件地址验证机制。

Abstract: Open Source Software (OSS) libraries form the backbone of modern software systems, yet their long-term sustainability often depends on maintainers being reachable for support, coordination, and security reporting. In this paper, we empirically analyze the availability of contact information - specifically e-mail addresses - across 686,034 Python libraries on the Python Package Index (PyPI) and their associated GitHub repositories. We examine how and where maintainers provide this information, assess its validity, and explore coverage across individual libraries and their dependency chains. Our findings show that 81.6% of libraries include at least one valid e-mail address, with PyPI serving as the primary source (79.5%). When analyzing dependency chains, we observe that up to 97.8% of direct and 97.7% of transitive dependencies provide valid contact information. At the same time, we identify over 698,000 invalid entries, primarily due to missing fields. These results demonstrate strong maintainer reachability across the ecosystem, while highlighting opportunities for improvement - such as offering clearer guidance to maintainers during the packaging process and introducing opt-in validation mechanisms for existing e-mail addresses.

</details>


### [550] [Feature-Aware Test Generation for Deep Learning Models](https://arxiv.org/abs/2601.14081)
*Xingcheng Chen,Oliver Weissl,Andrea Stocco*

Main category: cs.SE

TL;DR: Detect是一个特征感知测试生成框架，通过扰动潜在特征揭示模型行为，提升测试质量和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有基于生成AI的测试生成方法缺乏对输入语义的细粒度控制和行为异常的深入解释。

Method: Detect利用潜在空间中解耦的语义属性，通过受控扰动生成测试输入，并结合视觉语言模型进行语义归因。

Result: Detect在图像分类和检测任务中生成高质量测试用例，优于现有方法，并揭示了卷积模型和Transformer模型的不同捷径行为。

Conclusion: Detect框架通过特征感知测试生成，显著提升了深度学习模型的可靠性和可解释性，揭示了不同架构模型的潜在缺陷。

Abstract: As deep learning models are widely used in software systems, test generation plays a crucial role in assessing the quality of such models before deployment. To date, the most advanced test generators rely on generative AI to synthesize inputs; however, these approaches remain limited in providing semantic insight into the causes of misbehaviours and in offering fine-grained semantic controllability over the generated inputs. In this paper, we introduce Detect, a feature-aware test generation framework for vision-based deep learning (DL) models that systematically generates inputs by perturbing disentangled semantic attributes within the latent space. Detect perturbs individual latent features in a controlled way and observes how these changes affect the model's output. Through this process, it identifies which features lead to behavior shifts and uses a vision-language model for semantic attribution. By distinguishing between task-relevant and irrelevant features, Detect applies feature-aware perturbations targeted for both generalization and robustness. Empirical results across image classification and detection tasks show that Detect generates high-quality test cases with fine-grained control, reveals distinct shortcut behaviors across model architectures (convolutional and transformer-based), and bugs that are not captured by accuracy metrics. Specifically, Detect outperforms a state-of-the-art test generator in decision boundary discovery and a leading spurious feature localization method in identifying robustness failures. Our findings show that fully fine-tuned convolutional models are prone to overfitting on localized cues, such as co-occurring visual traits, while weakly supervised transformers tend to rely on global features, such as environmental variances. These findings highlight the value of interpretable and feature-aware testing in improving DL model reliability.

</details>


### [551] [Practitioner Views on Mobile App Accessibility: Practices and Challenges](https://arxiv.org/abs/2601.14131)
*Amila Indika,Rick Kazman,Anthony Peruma*

Main category: cs.SE

TL;DR: 本研究通过调查110名全球开发者，发现尽管可访问性被重视，但实践受限于平台指南和组织约束，提出了促进包容性开发的建议。


<details>
  <summary>Details</summary>
Motivation: 移动应用在日常生活中无处不在，但缺乏跨平台、全球代表性的开发者实践可访问性的洞察，这促使本研究填补这一空白。

Method: 本文采用混合方法调查了来自43个国家的110名移动应用开发者，分析了iOS与Android平台生态系统及开发者经验如何影响可访问性实践。

Result: 结果显示，开发者依赖平台特定指南，通常在开发后期进行合规测试，主要实现文本相关功能，但受限于API和组织约束。跨平台比较揭示了新的平台特定障碍及开发者经验水平对实践的差异影响。

Conclusion: 本文的结论是，尽管开发者认识到可访问性的重要性，但在实践中仍面临平台特定障碍和组织约束。研究结果为各利益相关者提供了促进更一致和包容性应用开发的实际步骤。

Abstract: As mobile applications (apps) become ubiquitous in everyday life, it is crucial for developers to prioritize accessibility for users with diverse abilities. While previous research has identified widespread accessibility issues and raised awareness of developer challenges, there remains a lack of cross-platform, globally representative insights into how practitioners approach accessibility in practice. This paper presents findings from a mixed-methods survey of 110 mobile app developers across 43 countries, examining how platform ecosystems (iOS vs. Android) and developer experience shape accessibility practices. Results show that while developers recognize the importance of accessibility, they often rely on platform-specific guidelines and typically perform compliance testing late in the development process. Developers primarily implement text-focused features while struggling with API limitations and organizational constraints. Through systematic cross-platform comparison, we identify novel platform-specific barriers and demonstrate how accessibility practices differ across developer experience levels. Our findings offer new insights into the challenges of achieving accessibility in practice and provide actionable steps for various stakeholders to promote more consistent and inclusive app development.

</details>


### [552] [Toward self-coding information systems](https://arxiv.org/abs/2601.14132)
*Rodrigo Falcão,Frank Elberzhager,Karthik Vaidhyanathan*

Main category: cs.SE

TL;DR: 本文介绍自我编码信息系统，一种能动态适应、生成代码并自主部署的AI系统，旨在缩短新功能上市时间并探讨未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 减少新功能上市时间，通过自主运行时适应和代码生成提高系统灵活性和效率。

Method: 通过形式化定义自我编码信息系统，并探讨其动态适应、源代码生成、测试和部署的能力。

Result: 提出了自我编码信息系统的概念，并展望了其在代理AI领域的潜在应用和影响。

Conclusion: 本文提出了自我编码信息系统作为代理AI领域的一个新颖研究方向，并讨论了其潜在影响和未来研究方向。

Abstract: In this extended abstract, we propose a novel research topic in the field of agentic AI, which we refer to as self-coding information systems. These systems will be able to dynamically adapt their structure or behavior by evaluating potential adaptation decisions, generate source code, test, and (re)deploy their source code autonomously, at runtime, reducing the time to market of new features. Here we motivate the topic, provide a formal definition of self-coding information systems, discuss some expected impacts of the new technology, and indicate potential research directions.

</details>


### [553] [An Empirical Study on Remote Code Execution in Machine Learning Model Hosting Ecosystems](https://arxiv.org/abs/2601.14163)
*Mohammed Latif Siddiq,Tanzim Hossain Romel,Natalie Sekerak,Beatrice Casey,Joanna C. S. Santos*

Main category: cs.SE

TL;DR: 研究了模型共享平台中自定义模型加载实践的安全问题，发现普遍存在不安全默认设置和开发者困惑，提出了改进建议。


<details>
  <summary>Details</summary>
Motivation: 模型共享平台的灵活性引入了关键的安全问题：在模型加载过程中执行不受信任的代码。

Method: 首先量化了模型需要自定义代码的频率，并识别了在加载过程中执行任意Python文件的模型。随后应用了三种互补的静态分析工具（Bandit、CodeQL、Semgrep）来检测安全异味和潜在漏洞，并通过CWE标识符对发现进行分类。同时使用YARA识别恶意模式和有效载荷签名。此外，还系统分析了每个平台的文档、API设计和安全机制。最后，对来自多个论坛的600多个开发者讨论进行了定性分析。

Result: 研究发现普遍依赖不安全的默认设置，平台间安全执行不均衡，开发者对执行远程代码的含义存在持续困惑。

Conclusion: 提出了可操作的建议，旨在设计更安全的模型共享基础设施，并在未来的AI生态系统中平衡可用性与安全性。

Abstract: Model-sharing platforms, such as Hugging Face, ModelScope, and OpenCSG, have become central to modern machine learning development, enabling developers to share, load, and fine-tune pre-trained models with minimal effort. However, the flexibility of these ecosystems introduces a critical security concern: the execution of untrusted code during model loading (i.e., via trust_remote_code or trust_repo). In this work, we conduct the first large-scale empirical study of custom model loading practices across five major model-sharing platforms to assess their prevalence, associated risks, and developer perceptions. We first quantify the frequency with which models require custom code to function and identify those that execute arbitrary Python files during loading. We then apply three complementary static analysis tools: Bandit, CodeQL, and Semgrep, to detect security smells and potential vulnerabilities, categorizing our findings by CWE identifiers to provide a standardized risk taxonomy. We also use YARA to identify malicious patterns and payload signatures. In parallel, we systematically analyze the documentation, API design, and safety mechanisms of each platform to understand their mitigation strategies and enforcement levels. Finally, we conduct a qualitative analysis of over 600 developer discussions from GitHub, Hugging Face, and PyTorch Hub forums, as well as Stack Overflow, to capture community concerns and misconceptions regarding security and usability. Our findings reveal widespread reliance on unsafe defaults, uneven security enforcement across platforms, and persistent confusion among developers about the implications of executing remote code. We conclude with actionable recommendations for designing safer model-sharing infrastructures and striking a balance between usability and security in future AI ecosystems.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [554] [Exact Computation of the Catalan Number $C(2,050,572,903)$](https://arxiv.org/abs/2601.11621)
*Mahesh Ramani*

Main category: cs.DS

TL;DR: 论文提出两阶段算法，首次精确计算了n=2,050,572,903的卡塔兰数，解决了大阶乘内存限制问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决大阶乘计算中的内存限制问题，并实现前所未有的卡塔兰数精确计算规模。

Method: 算法分为两个阶段：第一阶段使用并行分段筛法枚举素数并应用Legendre公式确定卡塔兰数的素数分解；第二阶段通过内存高效平衡乘积树重构最终整数。

Result: 成功计算了n=2,050,572,903的卡塔兰数，结果具有1,234,567,890位十进制数字，是迄今为止最大的精确卡塔兰数。

Conclusion: 该论文提出了一种两阶段算法，成功计算了迄今为止最大的精确卡塔兰数，并通过验证策略确保了结果的可靠性。

Abstract: This paper presents a two-phase algorithm for computing exact Catalan numbers at an unprecedented scale. The method is demonstrated by computing $C(n)$ for $n = 2,050,572,903$ yielding a result with a targeted $1,234,567,890$ decimal digits. To circumvent the memory limitations associated with evaluating large factorials, the algorithm operates exclusively in the prime-exponent domain. Phase 1 employs a parallel segmented sieve to enumerate primes up to $2n$ and applies Legendre's formula to determine the precise prime factorization of $C(n)$. The primes are grouped by exponent and serialized to disk. Phase 2 reconstructs the final integer using a memory-efficient balanced product tree with chunking. The algorithm runs on a time complexity of $Θ(n(\log n)^2)$ bit-operations and a space complexity of $Θ(n \log n)$ bits. This result represents the largest exact Catalan number computed to date. Performance statistics for a single-machine execution are reported, and verification strategies -- including modular checks and SHA-256 hash validation -- are discussed. The source code and factorization data are provided to ensure reproducibility.

</details>


### [555] [Bicriteria Algorithms for Submodular Cover with Partition and Fairness Constraints](https://arxiv.org/abs/2601.11755)
*Wenjing Chen,Yixin Chen,Victoria G. Crawford*

Main category: cs.DS

TL;DR: 论文系统地研究了带分区约束的子模覆盖问题，提出了高效的双准则近似算法，并在理论和实验上验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 在许多子模优化应用中，数据集自然划分为不相交的子集，而现有研究忽视了这种分区结构，因此需要系统地研究带分区约束的子模覆盖问题。

Method: 开发并分析了针对单调和非单调目标的SCP问题的双准则近似算法，特别针对单调情况提出了具有最优近似保证且显著降低查询复杂度的算法。

Result: 提出的算法在单调情况下实现了最优近似保证，并显著降低了查询复杂度。实证评估进一步验证了算法在真实和合成数据集上的高效性。

Conclusion: 论文提出了针对分区约束的子模覆盖问题（SCP）的可扩展双准则近似算法，并在理论和实验上验证了其高效性和有效性。

Abstract: In many submodular optimization applications, datasets are naturally partitioned into disjoint subsets. These scenarios give rise to submodular optimization problems with partition-based constraints, where the desired solution set should be in some sense balanced, fair, or resource-constrained across these partitions. While existing work on submodular cover largely overlooks this structure, we initiate a comprehensive study of the problem of Submodular Cover with Partition Constraints (SCP) and its key variants. Our main contributions are the development and analysis of scalable bicriteria approximation algorithms for these NP-hard optimization problems for both monotone and nonmonotone objectives. Notably, the algorithms proposed for the monotone case achieve optimal approximation guarantees while significantly reducing query complexity compared to existing methods. Finally, empirical evaluations on real-world and synthetic datasets further validate the efficiency and effectiveness of the proposed algorithms.

</details>


### [556] [Sum Estimation via Vector Similarity Search](https://arxiv.org/abs/2601.11765)
*Stephen Mussmann,Mehul Smriti Raje,Kavya Tumkur,Oumayma Messoussi,Cyprien Hachem,Seby Jacob*

Main category: cs.DS

TL;DR: 提出一种仅需$\mathcal{O}(\log(n))$最相似向量的高效和估计算法，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的和估计方法（如核密度估计和softmax分布的归一化常数计算）需要获取$\mathcal{O}(\sqrt{n})$个最相似向量，计算成本高。本文旨在开发一种更高效的算法，减少所需相似向量的数量。

Method: 通过随机将对象分配到具有指数衰减概率的层级，并为每个层级构建向量相似性搜索数据结构。利用每个层级的top-$k$对象，提出无偏和估计，并证明了高概率相对误差界。

Result: 在OpenImages和Amazon Reviews数据集上的实验表明，新算法能以更低误差和更少计算时间完成密度估计、softmax分母计算和球内向量计数等任务。

Conclusion: 本文提出了一种新颖的算法，仅需$\mathcal{O}(\log(n))$个最相似向量即可完成集合中所有对象的和估计任务，相比现有方法的$\mathcal{O}(\sqrt{n})$要求，显著提升了效率。实验证明，该方法在OpenImages和Amazon Reviews数据集上能以更低误差和更少计算时间完成任务。

Abstract: Semantic embeddings to represent objects such as image, text and audio are widely used in machine learning and have spurred the development of vector similarity search methods for retrieving semantically related objects. In this work, we study the sibling task of estimating a sum over all objects in a set, such as the kernel density estimate (KDE) and the normalizing constant for softmax distributions. While existing solutions provably reduce the sum estimation task to acquiring $\mathcal{O}(\sqrt{n})$ most similar vectors, where $n$ is the number of objects, we introduce a novel algorithm that only requires $\mathcal{O}(\log(n))$ most similar vectors. Our approach randomly assigns objects to levels with exponentially-decaying probabilities and constructs a vector similarity search data structure for each level. With the top-$k$ objects from each level, we propose an unbiased estimate of the sum and prove a high-probability relative error bound. We run experiments on OpenImages and Amazon Reviews with a vector similar search implementation to show that our method can achieve lower error using less computational time than existing reductions. We show results on applications in estimating densities, computing softmax denominators, and counting the number of vectors within a ball.

</details>


### [557] [Analysis of a Random Local Search Algorithm for Dominating Set](https://arxiv.org/abs/2601.11841)
*Hendrik Higl*

Main category: cs.DS

TL;DR: 本文分析了随机局部搜索算法在循环图上寻找最小支配集的性能，证明了其预期运行时间的上界，并引入了新的分析方法和模型。


<details>
  <summary>Details</summary>
Motivation: 支配集问题在计算生物学和移动通信中有广泛应用，但现有启发式算法的理论基础薄弱，缺乏对其运行时间和结果质量的保证。本文旨在填补这一理论空白。

Method: 采用随机局部搜索（RLS）算法，结合循环图的特性，引入多种模型来表示支配集，并利用随机算法分析技术和可逆马尔可夫链分析方法。

Result: 证明了RLS算法在循环图上寻找最小支配集的预期运行时间上界为O(n^4 log^2(n))，并引入新模型和方法以理解算法如何探索搜索空间。

Conclusion: 本文通过严格分析随机局部搜索（RLS）算法在循环图上的表现，为其在最小支配集问题中的应用提供了理论支持，证明了其预期运行时间的上界为O(n^4 log^2(n))。

Abstract: Dominating Set is a well-known combinatorial optimization problem which finds application in computational biology or mobile communication. Because of its $\mathrm{NP}$-hardness, one often turns to heuristics for good solutions. Many such heuristics have been empirically tested and perform rather well. However, it is not well understood why their results are so good or even what guarantees they can offer regarding their runtime or the quality of their results. For this, a strong theoretical foundation has to be established. We contribute to this by rigorously analyzing a Random Local Search (RLS) algorithm that aims to find a minimum dominating set on a graph. We consider its performance on cycle graphs with $n$ vertices. We prove an upper bound for the expected runtime until an optimum is found of $\mathcal{O}\left(n^4\log^2(n)\right)$. In doing so, we introduce several models to represent dominating sets on cycles that help us understand how RLS explores the search space to find an optimum. For our proof we use techniques which are already quite popular for the analysis of randomized algorithms. We further apply a special method to analyze a reversible Markov Chain, which arises as a result of our modeling. This method has not yet found wide application in this kind of runtime analysis.

</details>


### [558] [Parameterized Complexity of Scheduling Problems in Robotic Process Automation](https://arxiv.org/abs/2601.11984)
*Michal Dvořák,Antonín Novák,Přemysl Šůcha,Dušan Knop,Claire Hanen*

Main category: cs.DS

TL;DR: 研究了RPA中的单机调度问题，证明了某些参数下的难解性，并提出了有效的算法。


<details>
  <summary>Details</summary>
Motivation: 受RPA中调度问题的启发，研究单机调度问题的参数化复杂性。

Method: 研究了与RPA系统自然关联的参数，包括链式优先关系、不同处理时间的数量以及时间窗口的结构。

Result: 证明了问题在链数参数下是W[2]-难解的，但在其他参数下提出了多项式时间算法和FPT算法。

Conclusion: 该论文研究了RPA系统中的单机调度问题的参数化复杂性，证明了在特定参数下问题的W[2]-难解性，并在其他参数下提出了多项式时间算法和FPT算法。

Abstract: This paper studies the growing domain of Robotic Process Automation (RPA) problems. Motivated by scheduling problems arising in RPA, we study the parameterized complexity of the single-machine problem $1|\text{prec},r_j,d_j|*$. We focus on parameters naturally linked to RPA systems, including chain-like precedences, the number of distinct processing times, and the structure of the time windows. We show that the problem is W[2]-hard parameterized by the number of chains, even with only two prescribed processing times and two distinct time-window lengths. This hardness remains even for distinct processing times and time windows under prec-consistent time windows. On the positive side, we obtain polynomial-time algorithm when all jobs share a single time-window length and FPT when the processing times, release times and deadlines are chain-uniform. We also show that the problem lies in XP when parameterized by the width of the precedence relation.

</details>


### [559] [Computing Maximal Repeating Subsequences in a String](https://arxiv.org/abs/2601.12200)
*Mingyang Gong,Adiesha Liyanage,Braeden Sopp,Binhai Zhu*

Main category: cs.DS

TL;DR: 本文提出高效算法，用于计算单字符串中的最大重复模式，显著提升时间效率，尤其在约束条件下表现优异。


<details>
  <summary>Details</summary>
Motivation: 研究动机源于现有方法仅适用于两个或多个输入字符串，且时间效率较低。本文旨在填补单字符串最大重复模式计算的空白，并提升效率。

Method: 通过算法优化，将计算最大平方子序列的时间从O(n²)降低到O(n log n)，并针对k-重复子序列提出了O(f(k)n log n)的时间复杂度，其中f(k) < k·4^k。

Result: 结果表明，新方法在计算最大平方子序列和k-重复子序列时，时间效率显著优于现有方法，尤其在约束条件下。

Conclusion: 本文提出了在单个输入字符串中计算最大（不一定是最大）重复模式的新方法，显著提高了时间效率，尤其是在处理约束情况时。

Abstract: In this paper we initiate the study of computing a maximal (not necessarily maximum) repeating pattern in a single input string, where the corresponding problems have been studied (e.g., a maximal common subsequence) only in two or more input strings by Hirota and Sakai starting 2019. Given an input string $S$ of length $n$, we can compute a maximal square subsequence of $S$ in $O(n\log n)$ time, greatly improving the $O(n^2)$ bound for computing the longest square subsequence of $S$. For a maximal $k$-repeating subsequence, our bound is $O(f(k)n\log n)$, where \(f(k)\) is a computable function such that $f(k) < k\cdot 4^k$. This greatly improves the $O(n^{2k-1})$ bound for computing a longest $k$-repeating subsequence of $S$, for $k\geq 3$. Both results hold for the constrained case, i.e., when the solution must contain a subsequence $X$ of $S$, though with higher running times.

</details>


### [560] [Analyzing Collection Strategies: A Computational Perspective on the Coupon Collector Problem](https://arxiv.org/abs/2601.12351)
*Hadas Abraham,Ido Feldman,Eitan Yaakobi*

Main category: cs.DS

TL;DR: 本文提出三种算法解决通用优惠券收集问题，基于马尔可夫模型和动态编程，能精确计算期望和方差，适用于均匀和任意分布。


<details>
  <summary>Details</summary>
Motivation: 优惠券收集问题在工程领域有广泛应用，但数值结果的推导常受计算挑战阻碍。本文旨在解决这一问题。

Method: 第一种算法提供了计算期望、方差和第二矩的基础模型；第二种算法在均匀分布下以多项式时间计算相同值；第三种算法扩展到任意分布。所有算法均基于马尔可夫模型，采用动态编程方法。

Result: 三种算法均能精确计算期望和方差，其中第二种算法在均匀分布下具有多项式时间复杂度，第三种算法适用于任意分布。

Conclusion: 本文提出了三种算法来解决最通用的优惠券收集问题（CCP），这些算法能够精确计算收集过程的期望和方差，并通过动态编程方法实现高效计算。

Abstract: The Coupon Collector Problem (CCP) is a well-known combinatorial problem that seeks to estimate the number of random draws required to complete a collection of $n$ distinct coupon types. Various generalizations of this problem have been applied in numerous engineering domains. However, practical applications are often hindered by the computational challenges associated with deriving numerical results for moments and distributions. In this work, we present three algorithms for solving the most general form of the CCP, where coupons are collected under any arbitrary drawing probability, with the objective of obtaining $t$ copies of a subset of $k$ coupons from a total of $n$. The First algorithm provides the base model to compute the expectation, variance, and the second moment of the collection process. The second algorithm utilizes the construction of the base model and computes the same values in polynomial time with respect to $n$ under the uniform drawing distribution, and the third algorithm extends to any general drawing distribution. All algorithms leverage Markov models specifically designed to address computational challenges, ensuring exact computation of the expectation and variance of the collection process. Their implementation uses a dynamic programming approach that follows from the Markov models framework, and their time complexity is analyzed accordingly.

</details>


### [561] [Approximation Schemes for Sequential Hiring Problems](https://arxiv.org/abs/2601.12750)
*Danny Segev,Uri Stein*

Main category: cs.DS

TL;DR: 本文针对顺序招聘问题，提出块响应策略和递归枚举框架，首次实现多项式时间近似方案，性能接近最优。


<details>
  <summary>Details</summary>
Motivation: 现有研究在顺序招聘问题中的近似算法存在常数因子损失，且自适应策略的表示存在固有障碍，需要新的方法突破。

Method: 提出块响应策略，结合递归枚举框架，构建半自适应策略，其性能接近最优。

Result: 首次建立了顺序招聘问题的多项式时间近似方案，提出了性能接近最优的半自适应策略。

Conclusion: 本文通过引入块响应策略和递归枚举框架，解决了顺序招聘问题中的近似算法挑战，首次实现了多项式时间近似方案。

Abstract: The main contribution of this paper resides in providing novel algorithmic advances and analytical insights for the sequential hiring problem, a recently introduced dynamic optimization model where a firm adaptively fills a limited number of positions from a pool of applicants with known values and acceptance probabilities. While earlier research established a strong foundation -- notably an LP-based $(1 - \frac{e^{-k}k^k}{k!})$-approximation by Epstein and Ma (Operations Research, 2024) -- the attainability of superior approximation guarantees has remained a central open question.
  Our work addresses this challenge by establishing the first polynomial-time approximation scheme for sequential hiring, proposing an $O(n^{O(1)} \cdot T^{2^{\tilde{O}(1/ε^{2})}})$-time construction of semi-adaptive policies whose expected reward is within factor $1 - ε$ of optimal. To overcome the constant-factor optimality loss inherent to earlier literature, and to circumvent intrinsic representational barriers of adaptive policies, our approach is driven by the following innovations:
  -- The block-responsive paradigm: We introduce block-responsive policies, a new class of decision-making strategies, selecting ordered sets (blocks) of applicants rather than single individuals, while still allowing for internal reactivity.
  -- Adaptivity and efficiency: We prove that these policies can nearly match the performance of general adaptive policies while utilizing polynomially-sized decision trees.
  -- Efficient construction: By developing a recursive enumeration-based framework, we resolve the problematic ``few-positions'' regime, bypassing a fundamental hurdle that hindered previous approaches.

</details>


### [562] [Kd-tree Based Wasserstein Distance Approximation for High-Dimensional Data](https://arxiv.org/abs/2601.12975)
*Kanata Teshigawara,Keisho Oh,Ken Kobayashi,Kazuhide Nakata*

Main category: cs.DS

TL;DR: kd-Flowtree 是一种基于 kd 树的 Wasserstein 距离近似方法，在高维情况下表现优异，预处理和计算效率更高。


<details>
  <summary>Details</summary>
Motivation: 现有基于树的近似方法在高维空间中预处理时间长且近似精度差，无法满足大规模数据集的需求。

Method: 提出 kd-Flowtree 方法，利用 kd 树进行数据嵌入，以解决高维空间中标准四叉树深度不足的问题。

Result: 数值实验表明，kd-Flowtree 在真实数据检索任务中优于现有的 Wasserstein 距离近似方法。

Conclusion: kd-Flowtree 是一种基于 kd 树的 Wasserstein 距离近似方法，在高维情况下仍能保持良好的近似精度，并且在预处理和计算时间上优于现有方法。

Abstract: The Wasserstein distance is a discrepancy measure between probability distributions, defined by an optimal transport problem. It has been used for various tasks such as retrieving similar items in high-dimensional images or text data. In retrieval applications, however, the Wasserstein distance is calculated repeatedly, and its cubic time complexity with respect to input size renders it unsuitable for large-scale datasets. Recently, tree-based approximation methods have been proposed to address this bottleneck. For example, the Flowtree algorithm computes transport on a quadtree and evaluates cost using the ground metric, and clustering-tree approaches have been reported to achieve high accuracy. However, these existing trees often incur significant construction time for preprocessing, and crucially, standard quadtrees cannot grow deep enough in high-dimensional spaces, resulting in poor approximation accuracy. In this paper, we propose kd-Flowtree, a kd-tree-based Wasserstein distance approximation method that uses a kd-tree for data embedding. Since kd-trees can grow sufficiently deep and adaptively even in high-dimensional cases, kd-Flowtree is capable of maintaining good approximation accuracy for such cases. In addition, kd-trees can be constructed quickly than quadtrees, which contributes to reducing the computation time required for nearest neighbor search, including preprocessing. We provide a probabilistic upper bound on the nearest-neighbor search accuracy of kd-Flowtree, and show that this bound is independent of the dataset size. In the numerical experiments, we demonstrated that kd-Flowtree outperformed the existing Wasserstein distance approximation methods for retrieval tasks with real-world data.

</details>


### [563] [The Energy-Throughput Trade-off in Lossless-Compressed Source Code Storage](https://arxiv.org/abs/2601.13220)
*Paolo Ferragina,Francesco Tosoni*

Main category: cs.DS

TL;DR: 研究通过压缩键值存储系统，展示了空间、时间和能源效率的权衡，为大规模源代码存储提供了高效、可持续的解决方案。


<details>
  <summary>Details</summary>
Motivation: 从大规模源代码档案中检索数据对AI训练、基于神经网络的软件分析和信息检索至关重要，因此需要高效、可持续的存储解决方案。

Method: 设计并实验了一种压缩键值存储系统，用于大规模源代码数据集的索引，评估了压缩空间占用、时间和能源效率之间的权衡。

Result: 实验表明，高压缩比可显著提高检索吞吐量和能源效率，但数据并行性在提升速度的同时难以同等提升能源效率。

Conclusion: 本研究通过实验展示了不同压缩配置在空间占用、时间和能源效率之间的权衡，为大规模源代码数据集的高效存储提供了实用指南和绿色基准测试方法。

Abstract: Retrieving data from large-scale source code archives is vital for AI training, neural-based software analysis, and information retrieval, to cite a few. This paper studies and experiments with the design of a compressed key-value store for the indexing of large-scale source code datasets, evaluating its trade-off among three primary computational resources: (compressed) space occupancy, time, and energy efficiency. Extensive experiments on a national high-performance computing infrastructure demonstrate that different compression configurations yield distinct trade-offs, with high compression ratios and order-of-magnitude gains in retrieval throughput and energy efficiency. We also study data parallelism and show that, while it significantly improves speed, scaling energy efficiency is more difficult, reflecting the known non-energy-proportionality of modern hardware and challenging the assumption of a direct time-energy correlation. This work streamlines automation in energy-aware configuration tuning and standardized green benchmarking deployable in CI/CD pipelines, thus empowering system architects with a spectrum of Pareto-optimal energy-compression-throughput trade-offs and actionable guidelines for building sustainable, efficient storage backends for massive open-source code archival.

</details>


### [564] [Learning-Augmented Online TRP on a Line](https://arxiv.org/abs/2601.13494)
*Swapnil Guragain,Gokarna Sharma*

Main category: cs.DS

TL;DR: 首个预测增强框架下的在线旅行维修工问题研究，提出竞争比优化的确定性算法。


<details>
  <summary>Details</summary>
Motivation: 探索预测增强框架如何改善在线旅行维修工问题的算法性能，特别是在预测存在误差时的鲁棒性。

Method: 研究采用确定性算法，结合预测模型（可能包含误差）来优化请求的完成时间总和或平均值。

Result: 完美预测下算法的竞争比为$(2+\sqrt{3})\approx 3.732$，预测误差为$δ$时竞争比提升至$\min\{3.732+4δ,4\}$。

Conclusion: 本文提出了在线旅行维修工问题在预测增强框架下的首个结果，展示了预测对算法性能的影响。

Abstract: We study the online traveling repairperson problem on a line within the recently proposed learning-augmented framework, which provides predictions on the requests to be served via machine learning. In the original model (with no predictions), there is a stream of requests released over time along the line. The goal is to minimize the sum (or average) of the completion times of the requests. In the original model, the state-of-the-art competitive ratio lower bound is $1+\sqrt{2} > 2.414$ for any deterministic algorithm and the state-of-the-art competitive ratio upper bound is 4 for a deterministic algorithm. Our prediction model involves predicted positions, possibly error-prone, of each request in the stream known a priori but the arrival times of requests are not known until their arrival. We first establish a 3-competitive lower bound which extends to the original model. We then design a deterministic algorithm that is $(2+\sqrt{3})\approx 3.732$-competitive when predictions are perfect. With imperfect predictions (maximum error $δ> 0$), we show that our deterministic algorithm becomes $\min\{3.732+4δ,4\}$-competitive, knowing $δ$. To the best of our knowledge, these are the first results for online traveling repairperson problem in the learning-augmented framework.

</details>


### [565] [Zero-free regions and concentration inequalities for hypergraph colorings in the local lemma regime](https://arxiv.org/abs/2601.13796)
*Jingcheng Liu,Yixiao Yu*

Main category: cs.DS

TL;DR: 论文证明了高维超图着色中配分函数的零自由区域存在性，并展示了其在均匀随机着色中的统计性质和应用。


<details>
  <summary>Details</summary>
Motivation: 研究高维超图的q-着色问题，探索其配分函数的零自由区域及其在均匀枚举和随机着色中的应用。

Method: 通过扩展Liu等人（STOC 2025）的工作，将约束满足问题（CSP）的配分函数引入外部场变量，并采用投影-提升方案将实线上的信息渗透分析提升到复平面。

Result: 当k≥50且q≥700Δ^(5/(k-10))时，证明了配分函数在[0,1]区间周围存在Lee-Yang零自由带，并推导出Berry-Esseen型不等式和渐近正态性。

Conclusion: 论文证明了在高维超图中，当颜色数满足特定条件时，存在Lee-Yang零自由带，并由此推导出Berry-Esseen型不等式，展示了均匀随机着色中颜色类大小的渐近正态性。此外，框架还扩展到Fisher零点的研究，提出了确定性算法来近似零自由区域的配分函数。

Abstract: We show that for $q$-colorings in $k$-uniform hypergraphs with maximum degree $Δ$, if $k\ge 50$ and $q\ge 700Δ^{\frac{5}{k-10}}$, there is a "Lee-Yang" zero-free strip around the interval $[0,1]$ of the partition function, which includes the special case of uniform enumeration of hypergraph colorings. As an immediate consequence, we obtain Berry-Esseen type inequalities for hypergraph $q$-colorings under such conditions, demonstrating the asymptotic normality for the size of any color class in a uniformly random coloring. Our framework also extends to the study of "Fisher zeros", leading to deterministic algorithms for approximating the partition function in the zero-free region.
  Our approach is based on extending the recent work of [Liu, Wang, Yin, Yu, STOC 2025] to general constraint satisfaction problems (CSP). We focus on partition functions defined for CSPs by introducing external fields to the variables. A key component in our approach is a projection-lifting scheme, which enables us to essentially lift information percolation type analysis for Markov chains from the real line to the complex plane. Last but not least, we also show a Chebyshev-type inequality under the sampling LLL condition for atomic CSPs.

</details>


### [566] [Efficient Parallel $(Δ+1)$-Edge-Coloring](https://arxiv.org/abs/2601.13822)
*Michael Elkin,Ariel Khuzman*

Main category: cs.DS

TL;DR: 本文提出了一种更快的并行算法来解决$(Δ+1)$-边着色问题，显著提升了时间和处理器效率。


<details>
  <summary>Details</summary>
Motivation: 研究$(Δ+1)$-边着色问题在并行计算模型中的高效解决方案，以改进现有算法的性能。

Method: 设计了一种新的并行算法，优化了时间和处理器使用，并提供了多种时间与处理器数量的权衡方案。

Result: 新算法在时间上优于现有方法，如$O(Δ^4 \cdot \log^4 n)$时间和$O(m \cdot Δ)$处理器，同时提供了其他变体以适应不同需求。

Conclusion: 本文提出了一种更快的并行算法来解决$(Δ+1)$-边着色问题，显著提升了时间和处理器效率，并改进了小树性图的算法。

Abstract: We study the $(Δ+1)$-edge-coloring problem in the parallel $\left(\mathrm{PRAM}\right)$ model of computation. The celebrated Vizing's theorem [Viz64] states that every simple graph $G = (V,E)$ can be properly $(Δ+1)$-edge-colored. In a seminal paper, Karloff and Shmoys [KS87] devised a parallel algorithm with time $O\left(Δ^5\cdot\log n\cdot\left(\log^3 n+Δ^2\right)\right)$ and $O(m\cdotΔ)$ processors. This result was improved by Liang et al. [LSH96] to time $O\left(Δ^{4.5}\cdot \log^3Δ\cdot \log n + Δ^4 \cdot\log^4 n\right)$ and $O\left(n\cdotΔ^{3} +n^2\right)$ processors. [LSH96] claimed $O\left(Δ^{3.5} \cdot\log^3Δ\cdot \log n + Δ^3\cdot \log^4 n\right)$ time, but we point out a flaw in their analysis, which once corrected, results in the above bound. We devise a faster parallel algorithm for this fundamental problem. Specifically, our algorithm uses $O\left(Δ^4\cdot \log^4 n\right)$ time and $O(m\cdot Δ)$ processors. Another variant of our algorithm requires $O\left(Δ^{4+o(1)}\cdot\log^2 n\right)$ time, and $O\left(m\cdotΔ\cdot\log n\cdot\log^δΔ\right)$ processors, for an arbitrarily small $δ>0$. We also devise a few other tradeoffs between the time and the number of processors, and devise an improved algorithm for graphs with small arboricity. On the way to these results, we also provide a very fast parallel algorithm for updating $(Δ+1)$-edge-coloring. Our algorithm for this problem is dramatically faster and simpler than the previous state-of-the-art algorithm (due to [LSH96]) for this problem.

</details>


### [567] [Nemesis, an Escape Game in Graphs](https://arxiv.org/abs/2601.13841)
*Pierre Bergé,Antoine Dailly,Yan Gerard*

Main category: cs.DS

TL;DR: Nemesis逃逸游戏在树和最大度为3的图中可线性解决，任意图中PSPACE完全。Blizzard变体也有线性解。Cat Herding问题同样PSPACE完全，全二叉逃逸树策略查找NP完全。


<details>
  <summary>Details</summary>
Motivation: 探索图论中的新型逃逸游戏，分析其在不同图结构中的计算复杂性和解决策略。

Method: 定义了Nemesis游戏，研究其在树、最大度为3的图、任意图和平面多重图中的复杂性。同时探讨了Blizzard变体和Cat Herding问题的复杂性。

Result: 在树和最大度为3的图中，Nemesis游戏可线性时间解决；任意图中为PSPACE完全，平面多重图中为NP难。Blizzard变体也有线性时间解。Cat Herding问题为PSPACE完全，基于全二叉逃逸树的策略查找为NP完全。

Conclusion: 在树和最大度为3的图中，Nemesis游戏可以在线性时间内解决。对于任意图，Nemesis是PSPACE完全的，在平面多重图中是NP难的。Blizzard变体也有线性时间解。Cat Herding问题同样被证明是PSPACE完全的，而基于全二叉逃逸树的策略查找是NP完全的。

Abstract: We define a new escape game in graphs that we call Nemesis. The game is played on a graph having a subset of vertices labeled as exits and the goal of one of the two players, called the fugitive, is to reach one of these exit vertices. The second player, i.e. the fugitive adversary, is called the Nemesis. Her goal is to trap the fugitive in a connected component which does not contain any exit. At each round of the game, the fugitive moves from one vertex to an adjacent vertex. Then the Nemesis deletes one edge anywhere in the graph. The game ends when either the fugitive reached an exit or when he is in a connected component that does not contain any exit. In trees and graphs of maximum degree bounded by 3, Nemesis can be solved in linear time. We also show that a variant of the game called Blizzard where only edges adjacent to the position of the fugitive can be deleted also admits a linear time solution. For arbitrary graphs, we show that Nemesis is PSPACE-complete, and that it is NP-hard on planar multigraphs. We extend our results to the related Cat Herding problem, proving its PSPACE-completeness. We also prove that finding a strategy based on a full binary escape tree whose leaves are exists is NP-complete.

</details>
