<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 276]
- [cs.AI](#cs.AI) [Total: 153]
- [cs.GR](#cs.GR) [Total: 3]
- [cs.SE](#cs.SE) [Total: 29]
- [cs.NI](#cs.NI) [Total: 10]
- [cs.DC](#cs.DC) [Total: 18]
- [cs.DS](#cs.DS) [Total: 7]
- [cs.RO](#cs.RO) [Total: 86]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [EDU-CIRCUIT-HW: Evaluating Multimodal Large Language Models on Real-World University-Level STEM Student Handwritten Solutions](https://arxiv.org/abs/2602.00095)
*Weiyu Sun,Liangliang Chen,Yongnuo Cai,Huiru Xie,Yi Zeng,Ying Zhang*

Main category: cs.CV

TL;DR: 研究发布EDU-CIRCUIT-HW数据集，评估MLLM在学生手写解决方案中的识别和评分性能，发现大规模潜在失败，并提出通过识别错误模式提升AI评分系统鲁棒性的方法。


<details>
  <summary>Details</summary>
Motivation: 解决MLLM在无约束STEM学生手写解决方案（包含数学公式、图表和文本推理）中准确解释的挑战，以及当前评估范式仅依赖下游任务结果（如自动评分）而未能全面捕捉MLLM对复杂手写逻辑的理解。

Method: 发布EDU-CIRCUIT-HW数据集，包含1,300多个真实学生手写解决方案，并利用专家验证的逐字转录和评分报告，同时评估多种MLLM的上游识别保真度和下游自动评分性能。

Result: 评估揭示了MLLM在学生手写内容识别中的大规模潜在失败，表明其在高风险教育环境中的自动评分和理解导向应用中的可靠性不足。

Conclusion: 通过识别错误模式并预先检测和修正识别错误，仅需少量人工干预（约4%的解决方案），即可显著提升AI评分系统在未见学生解决方案上的鲁棒性。

Abstract: Multimodal Large Language Models (MLLMs) hold significant promise for revolutionizing traditional education and reducing teachers' workload. However, accurately interpreting unconstrained STEM student handwritten solutions with intertwined mathematical formulas, diagrams, and textual reasoning poses a significant challenge due to the lack of authentic and domain-specific benchmarks. Additionally, current evaluation paradigms predominantly rely on the outcomes of downstream tasks (e.g., auto-grading), which often probe only a subset of the recognized content, thereby failing to capture the MLLMs' understanding of complex handwritten logic as a whole. To bridge this gap, we release EDU-CIRCUIT-HW, a dataset consisting of 1,300+ authentic student handwritten solutions from a university-level STEM course. Utilizing the expert-verified verbatim transcriptions and grading reports of student solutions, we simultaneously evaluate various MLLMs' upstream recognition fidelity and downstream auto-grading performance. Our evaluation uncovers an astonishing scale of latent failures within MLLM-recognized student handwritten content, highlighting the models' insufficient reliability for auto-grading and other understanding-oriented applications in high-stakes educational settings. In solution, we present a case study demonstrating that leveraging identified error patterns to preemptively detect and rectify recognition errors, with only minimal human intervention (approximately 4% of the total solutions), can significantly enhance the robustness of the deployed AI-enabled grading system on unseen student solutions.

</details>


### [2] [VRGaussianAvatar: Integrating 3D Gaussian Avatars into VR](https://arxiv.org/abs/2602.01674)
*Hail Song,Boram Yoon,Seokhwan Yang,Seoyoung Kang,Hyunjeong Kim,Henning Metzmacher,Woontack Woo*

Main category: cs.CV

TL;DR: VRGaussianAvatar是一个实时全身3D高斯泼溅VR化身系统，通过并行流水线和Binocular Batching技术优化渲染，用户体验优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 为了解决现有VR化身在实时性和渲染效率上的不足，开发一个仅需头戴显示器（HMD）跟踪信号即可实现高保真全身化身的系统。

Method: 系统采用并行流水线设计，分为VR前端和GA后端。前端利用逆运动学估计全身姿态，后端通过单张图像重建3DGS化身，并引入Binocular Batching技术优化立体渲染。

Result: 定量测试和用户研究表明，VRGaussianAvatar在保持交互式VR性能的同时，显著提升了外观相似性、体现感和合理性。

Conclusion: VRGaussianAvatar系统通过创新的Binocular Batching技术实现了实时全身3D高斯泼溅（3DGS）虚拟现实（VR）化身，显著提升了渲染效率和用户体验。

Abstract: We present VRGaussianAvatar, an integrated system that enables real-time full-body 3D Gaussian Splatting (3DGS) avatars in virtual reality using only head-mounted display (HMD) tracking signals. The system adopts a parallel pipeline with a VR Frontend and a GA Backend. The VR Frontend uses inverse kinematics to estimate full-body pose and streams the resulting pose along with stereo camera parameters to the backend. The GA Backend stereoscopically renders a 3DGS avatar reconstructed from a single image. To improve stereo rendering efficiency, we introduce Binocular Batching, which jointly processes left and right eye views in a single batched pass to reduce redundant computation and support high-resolution VR displays. We evaluate VRGaussianAvatar with quantitative performance tests and a within-subject user study against image- and video-based mesh avatar baselines. Results show that VRGaussianAvatar sustains interactive VR performance and yields higher perceived appearance similarity, embodiment, and plausibility. Project page and source code are available at https://vrgaussianavatar.github.io.

</details>


### [3] [Mirage2Matter: A Physically Grounded Gaussian World Model from Video](https://arxiv.org/abs/2602.00096)
*Zhengqing Gao,Ziwen Li,Xin Wang,Jiaxin Huang,Zhenyang Ren,Mingkai Shao,Hanlue Zhang,Tianyu Huang,Yongkang Cheng,Yandong Guo,Runqi Lin,Yuanyuan Wang,Tongliang Liu,Kun Zhang,Mingming Gong*

Main category: cs.CV

TL;DR: Simulate Anything框架通过视频重建和生成模型生成高保真仿真数据，显著提升具身智能训练的可扩展性和实用性。


<details>
  <summary>Details</summary>
Motivation: 解决真实世界交互数据稀缺和现有仿真平台视觉与物理差距大、依赖昂贵传感器的问题。

Method: 利用多视角环境视频和现成资产，通过3D高斯散射（3DGS）重建真实环境，再通过生成模型恢复物理真实表示，并通过精度校准目标将其集成到仿真环境中。

Result: 基于仿真数据训练的VLA模型在下游任务中表现出色，零样本性能匹配甚至超越真实数据训练结果。

Conclusion: Simulate Anything框架通过3D高斯散射和生成模型，实现了高保真仿真数据的生成，为具身智能训练提供了可扩展且实用的解决方案。

Abstract: The scalability of embodied intelligence is fundamentally constrained by the scarcity of real-world interaction data. While simulation platforms provide a promising alternative, existing approaches often suffer from a substantial visual and physical gap to real environments and rely on expensive sensors, precise robot calibration, or depth measurements, limiting their practicality at scale. We present Simulate Anything, a graphics-driven world modeling and simulation framework that enables efficient generation of high-fidelity embodied training data using only multi-view environment videos and off-the-shelf assets. Our approach reconstructs real-world environments into a photorealistic scene representation using 3D Gaussian Splatting (3DGS), seamlessly capturing fine-grained geometry and appearance from video. We then leverage generative models to recover a physically realistic representation and integrate it into a simulation environment via a precision calibration target, enabling accurate scale alignment between the reconstructed scene and the real world. Together, these components provide a unified, editable, and physically grounded world model. Vision Language Action (VLA) models trained on our simulated data achieve strong zero-shot performance on downstream tasks, matching or even surpassing results obtained with real-world data, highlighting the potential of reconstruction-driven world modeling for scalable and practical embodied intelligence training.

</details>


### [4] [Implicit neural representation of textures](https://arxiv.org/abs/2602.02354)
*Albert Kwok,Zheyuan Hu,Dounia Hammou*

Main category: cs.CV

TL;DR: 该论文提出了一种基于神经网络的连续纹理表示方法（INR），在图像质量、内存和渲染效率上表现良好，并展示了在实时渲染和下游任务中的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 研究如何设计不同的神经网络作为新的纹理INR，以解决传统离散方法的局限性。

Method: 探索了不同神经网络设计作为新的纹理INR，以连续而非离散的方式操作于输入UV坐标空间。

Result: 实验证明这些INRs在图像质量上表现优异，同时内存使用和渲染推理时间也较为合理。

Conclusion: INRs作为一种新的纹理表示方法，在图像质量、内存使用和渲染推理时间方面表现良好，并在实时渲染和下游任务中展示了广泛的应用潜力。

Abstract: Implicit neural representation (INR) has proven to be accurate and efficient in various domains. In this work, we explore how different neural networks can be designed as a new texture INR, which operates in a continuous manner rather than a discrete one over the input UV coordinate space. Through thorough experiments, we demonstrate that these INRs perform well in terms of image quality, with considerable memory usage and rendering inference time. We analyze the balance between these objectives. In addition, we investigate various related applications in real-time rendering and down-stream tasks, e.g. mipmap fitting and INR-space generation.

</details>


### [5] [R3G: A Reasoning--Retrieval--Reranking Framework for Vision-Centric Answer Generation](https://arxiv.org/abs/2602.00104)
*Zhuohong Chen,Zhengxian Wu,Zirui Liao,Shenao Jiang,Hangrui Xu,Yang Chen,Chaokui Su,Xiaoyu Liu,Haoqian Wang*

Main category: cs.CV

TL;DR: R3G框架通过推理-检索-重排序策略提升视觉问答性能，在多个场景中实现最优表现。


<details>
  <summary>Details</summary>
Motivation: 解决视觉问答中如何有效选择图像并整合到模型推理过程中的挑战。

Method: R3G采用两阶段策略：首先生成简要推理计划以明确所需视觉线索，随后通过粗检索和细粒度重排序选择证据图像。

Result: 在MRAG-Bench上，R3G在六个MLLM骨干网络和九个子场景中均提高了准确性，达到整体最优性能。

Conclusion: R3G框架通过模块化的推理-检索-重排序策略，显著提升了视觉问答任务中的准确性，并在多个MLLM骨干网络和子场景中实现了最先进的性能。

Abstract: Vision-centric retrieval for VQA requires retrieving images to supply missing visual cues and integrating them into the reasoning process. However, selecting the right images and integrating them effectively into the model's reasoning remains challenging.To address this challenge, we propose R3G, a modular Reasoning-Retrieval-Reranking framework.It first produces a brief reasoning plan that specifies the required visual cues, then adopts a two-stage strategy, with coarse retrieval followed by fine-grained reranking, to select evidence images.On MRAG-Bench, R3G improves accuracy across six MLLM backbones and nine sub-scenarios, achieving state-of-the-art overall performance. Ablations show that sufficiency-aware reranking and reasoning steps are complementary, helping the model both choose the right images and use them well. We release code and data at https://github.com/czh24/R3G.

</details>


### [6] [HYPE-EDIT-1: Benchmark for Measuring Reliability in Frontier Image Editing Models](https://arxiv.org/abs/2602.00105)
*Wing Chan,Richard Allen*

Main category: cs.CV

TL;DR: HYPE-EDIT-1基准评估图像编辑模型的实际性能，显示低价模型在考虑重试和审核后可能更贵。


<details>
  <summary>Details</summary>
Motivation: 公共演示的图像编辑模型通常展示最佳案例，而实际工作流程需承担重试和审核时间成本，因此需要更全面的评估方法。

Method: 引入HYPE-EDIT-1基准，包含100个基于参考的市场/设计编辑任务，采用二元通过/失败评判，生成10次独立输出来评估每次尝试的通过率、pass@10、重试上限下的预期尝试次数及结合模型价格和人工审核时间的有效成本。

Result: 评估模型的单次尝试通过率为34%-83%，每次成功编辑的有效成本为0.66-1.42美元。

Conclusion: 模型在单次尝试中的通过率差异显著（34%-83%），且考虑重试和人工审核后的总有效成本显示，低价单图模型的实际成本可能更高。

Abstract: Public demos of image editing models are typically best-case samples; real workflows pay for retries and review time. We introduce HYPE-EDIT-1, a 100-task benchmark of reference-based marketing/design edits with binary pass/fail judging. For each task we generate 10 independent outputs to estimate per-attempt pass rate, pass@10, expected attempts under a retry cap, and an effective cost per successful edit that combines model price with human review time. We release 50 public tasks and maintain a 50-task held-out private split for server-side evaluation, plus a standardized JSON schema and tooling for VLM and human-based judging. Across the evaluated models, per-attempt pass rates span 34-83 percent and effective cost per success spans USD 0.66-1.42. Models that have low per-image pricing are more expensive when you consider the total effective cost of retries and human reviews.

</details>


### [7] [Efficient UAV trajectory prediction: A multi-modal deep diffusion framework](https://arxiv.org/abs/2602.00107)
*Yuan Gao,Xinyu Guo,Wenjing Xie,Zifan Wang,Hongwen Yu,Gongyang Li,Shugong Xu*

Main category: cs.CV

TL;DR: 提出了一种融合LiDAR和雷达的多模态无人机轨迹预测方法，通过双向交叉注意力机制实现信息互补，实验显示预测精度提升40%。


<details>
  <summary>Details</summary>
Motivation: 为满足低空经济中管理未经授权无人机的需求，提出了一种基于LiDAR和毫米波雷达信息融合的多模态无人机轨迹预测方法。

Method: 设计了一个多模态深度融合框架，包括两个模态特定特征提取网络和一个双向交叉注意力融合模块，以充分利用LiDAR和雷达点云在空间几何结构和动态反射特性中的互补信息。

Result: 实验结果表明，所提出的多模态融合模型显著提高了轨迹预测准确性，相比基线模型提升了40%。

Conclusion: 所提出的多模态融合模型能有效利用多模态数据，为低空经济中的未经授权无人机轨迹预测提供了高效解决方案。

Abstract: To meet the requirements for managing unauthorized UAVs in the low-altitude economy, a multi-modal UAV trajectory prediction method based on the fusion of LiDAR and millimeter-wave radar information is proposed. A deep fusion network for multi-modal UAV trajectory prediction, termed the Multi-Modal Deep Fusion Framework, is designed. The overall architecture consists of two modality-specific feature extraction networks and a bidirectional cross-attention fusion module, aiming to fully exploit the complementary information of LiDAR and radar point clouds in spatial geometric structure and dynamic reflection characteristics. In the feature extraction stage, the model employs independent but structurally identical feature encoders for LiDAR and radar. After feature extraction, the model enters the Bidirectional Cross-Attention Mechanism stage to achieve information complementarity and semantic alignment between the two modalities. To verify the effectiveness of the proposed model, the MMAUD dataset used in the CVPR 2024 UG2+ UAV Tracking and Pose-Estimation Challenge is adopted as the training and testing dataset. Experimental results show that the proposed multi-modal fusion model significantly improves trajectory prediction accuracy, achieving a 40% improvement compared to the baseline model. In addition, ablation experiments are conducted to demonstrate the effectiveness of different loss functions and post-processing strategies in improving model performance. The proposed model can effectively utilize multi-modal data and provides an efficient solution for unauthorized UAV trajectory prediction in the low-altitude economy.

</details>


### [8] [SITUATE -- Synthetic Object Counting Dataset for VLM training](https://arxiv.org/abs/2602.00108)
*René Peinl,Vincent Tischler,Patrick Schröder,Christian Groth*

Main category: cs.CV

TL;DR: SITUATE数据集通过空间约束计数任务提升视觉语言模型的泛化能力，实验证明其优于现有数据集。


<details>
  <summary>Details</summary>
Motivation: 现有的数据集（如VLMCountBench和TallyQA）在遮挡和空间组合方面缺乏控制，无法满足复杂计数任务的需求。

Method: 提出了SITUATE数据集，用于训练和评估视觉语言模型在空间约束计数任务上的表现。通过微调Qwen VL 2.5 7B模型，并在Pixmo count测试数据上进行验证。

Result: 实验表明，在SITUATE上微调的模型在Pixmo count测试数据上表现更好，而反向操作则无效。

Conclusion: SITUATE数据集通过提供具有空间约束的计数任务，显著提升了视觉语言模型在分布外图像上的泛化能力。

Abstract: We present SITUATE, a novel dataset designed for training and evaluating Vision Language Models on counting tasks with spatial constraints. The dataset bridges the gap between simple 2D datasets like VLMCountBench and often ambiguous real-life datasets like TallyQA, which lack control over occlusions and spatial composition. Experiments show that our dataset helps to improve generalization for out-of-distribution images, since a finetune of Qwen VL 2.5 7B on SITUATE improves accuracy on the Pixmo count test data, but not vice versa. We cross validate this by comparing the model performance across established other counting benchmarks and against an equally sized fine-tuning set derived from Pixmo count.

</details>


### [9] [Robustness of Presentation Attack Detection in Remote Identity Validation Scenarios](https://arxiv.org/abs/2602.00109)
*John J. Howard,Richard O. Plesh,Yevgeniy B. Sirotin,Jerry L. Tipton,Arun R. Vemury*

Main category: cs.CV

TL;DR: 研究发现商业PAD系统在低光照或自动捕获条件下性能显著下降，错误率大幅增加，仅一个系统表现稳健。强调了多样化环境测试的重要性。


<details>
  <summary>Details</summary>
Motivation: 探讨在多样化的环境和程序条件下，如何确保PAD子系统的稳健性能。

Method: 通过RIV的场景测试，研究了低光照条件和自动图像采集对商业PAD系统稳健性的影响。

Result: 结果显示，PAD系统在低光照或自动捕获场景下性能显著下降，错误率增加约四倍（低光照）或两倍（自动捕获）。仅有一个测试系统在所有场景中保持最大真实呈现分类错误率低于3%。

Conclusion: 研究强调了在不同环境下测试的重要性，以确保PAD系统在现实应用中的稳健性和可靠性。

Abstract: Presentation attack detection (PAD) subsystems are an important part of effective and user-friendly remote identity validation (RIV) systems. However, ensuring robust performance across diverse environmental and procedural conditions remains a critical challenge. This paper investigates the impact of low-light conditions and automated image acquisition on the robustness of commercial PAD systems using a scenario test of RIV. Our results show that PAD systems experience a significant decline in performance when utilized in low-light or auto-capture scenarios, with a model-predicted increase in error rates by a factor of about four under low-light conditions and a doubling of those odds under auto-capture workflows. Specifically, only one of the tested systems was robust to these perturbations, maintaining a maximum bona fide presentation classification error rate below 3% across all scenarios. Our findings emphasize the importance of testing across diverse environments to ensure robust and reliable PAD performance in real-world applications.

</details>


### [10] [Observing Health Outcomes Using Remote Sensing Imagery and Geo-Context Guided Visual Transformer](https://arxiv.org/abs/2602.00110)
*Yu Li,Guilherme N. DeSouza,Praveen Rao,Chi-Ren Shyu*

Main category: cs.CV

TL;DR: 该论文提出了一种结合地理空间嵌入和引导注意力模块的新型模型，显著提升了遥感图像的多模态地理空间理解能力，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉Transformer在遥感图像分析中取得了重大进展，但现有模型主要优化视觉与文本内容的语义对齐，而非地理空间理解，因此无法有效处理结构化地理空间层。本研究旨在填补这一空白。

Method: 研究提出了一种地理空间嵌入机制，将多样化的地理空间数据转换为与图像块空间对齐的嵌入块，并设计了一个引导注意力模块，通过基于辅助数据相关性的动态注意力权重计算，整合多模态信息。

Result: 实验结果表明，该框架在预测疾病流行率等任务中优于现有的预训练地理空间基础模型，验证了其多模态地理空间理解的有效性。

Conclusion: 该研究提出的新型模型通过引入地理空间嵌入机制和引导注意力模块，显著提升了遥感图像处理能力，特别是在多模态地理空间理解方面表现优异，超越了现有的预训练地理空间基础模型。

Abstract: Visual transformers have driven major progress in remote sensing image analysis, particularly in object detection and segmentation. Recent vision-language and multimodal models further extend these capabilities by incorporating auxiliary information, including captions, question and answer pairs, and metadata, which broadens applications beyond conventional computer vision tasks. However, these models are typically optimized for semantic alignment between visual and textual content rather than geospatial understanding, and therefore are not suited for representing or reasoning with structured geospatial layers. In this study, we propose a novel model that enhances remote sensing imagery processing with guidance from auxiliary geospatial information. Our approach introduces a geospatial embedding mechanism that transforms diverse geospatial data into embedding patches that are spatially aligned with image patches. To facilitate cross-modal interaction, we design a guided attention module that dynamically integrates multimodal information by computing attention weights based on correlations with auxiliary data, thereby directing the model toward the most relevant regions. In addition, the module assigns distinct roles to individual attention heads, allowing the model to capture complementary aspects of the guidance information and improving the interpretability of its predictions. Experimental results demonstrate that the proposed framework outperforms existing pretrained geospatial foundation models in predicting disease prevalence, highlighting its effectiveness in multimodal geospatial understanding.

</details>


### [11] [From Manual Observation to Automated Monitoring: Space Allowance Effects on Play Behaviour in Group-Housed Dairy Calves](https://arxiv.org/abs/2602.00111)
*Haiyu Yang,Heidi Lesscher,Enhong Liu,Miel Hostens*

Main category: cs.CV

TL;DR: Study finds 8-10 m² per calf optimizes play behavior, with automated monitoring showing high accuracy for scalable welfare assessment.


<details>
  <summary>Details</summary>
Motivation: To investigate the relationship between space allowance and play behaviour in dairy calves under commercial conditions, particularly at intermediate-to-high allowances (6-20 m² per calf), and to develop an automated computer vision pipeline for scalable monitoring.

Method: Video observations analyzed using a detailed ethogram, with play expressed as percentage of observation period (%OP). Statistical analysis employed linear mixed models with farm as a random effect. A computer vision pipeline was trained on manual annotations from 108 hours on 6 farms and validated on held-out test data.

Result: The computer vision classifier achieved 97.6% accuracy with 99.4% recall for active play detection. Calves spent on average 1.0% of OP playing. The space-play relationship was non-linear, with highest play levels at 8-10 m² per calf (1.6% OP) and lowest at 6-8 m² and 12-14 m² (<0.6% OP).

Conclusion: 8-10 m² per calf is a practical target balancing welfare benefits with economic feasibility, and automated monitoring can scale small annotation projects to continuous welfare assessment systems.

Abstract: Play behaviour serves as a positive welfare indicator in dairy calves, yet the influence of space allowance under commercial conditions remains poorly characterized, particularly at intermediate-to-high allowances (6-20 m2 per calf). This study investigated the relationship between space allowance and play behaviour in 60 group-housed dairy calves across 14 commercial farms in the Netherlands (space range: 2.66-17.98 m2 per calf), and developed an automated computer vision pipeline for scalable monitoring. Video observations were analyzed using a detailed ethogram, with play expressed as percentage of observation period (%OP). Statistical analysis employed linear mixed models with farm as a random effect. A computer vision pipeline was trained on manual annotations from 108 hours on 6 farms and validated on held-out test data. The computer vision classifier achieved 97.6% accuracy with 99.4% recall for active play detection. Calves spent on average 1.0% of OP playing reflecting around 10 minutes per 17-hour period. The space-play relationship was non-linear, with highest play levels at 8-10 m2 per calf (1.6% OP) and lowest at 6-8 m2 and 12-14 m2 (<0.6% OP). Space remained significant after controlling for age, health, and group size. In summary, these findings suggest that 8-10 m2 per calf represents a practical target balancing welfare benefits with economic feasibility, and demonstrate that automated monitoring can scale small annotation projects to continuous welfare assessment systems.

</details>


### [12] [AI-Driven Three-Dimensional Reconstruction and Quantitative Analysis for Burn Injury Assessment](https://arxiv.org/abs/2602.00113)
*S. Kalaycioglu,C. Hong,K. Zhai,H. Xie,J. N. Wong*

Main category: cs.CV

TL;DR: AI驱动的烧伤评估平台，结合3D重建和深度学习，提供客观、可重复的烧伤评估和愈合跟踪，适用于临床工作流程。


<details>
  <summary>Details</summary>
Motivation: 传统烧伤评估方法（如视觉检查和2D摄影）主观性强且难以进行纵向比较，需要更客观、可重复的评估工具。

Method: 整合多视角摄影测量、3D表面重建和基于深度学习的分割技术，结合结构化临床工作流程，利用消费级相机标准多角度图像进行3D重建和烧伤区域映射。

Result: 系统能够稳定重建烧伤表面，计算一致的客观指标（如表面积、TBSA、深度相关几何代理和体积变化），并展示临床合理的纵向愈合趋势。

Conclusion: 该平台通过AI和多视角摄影测量技术，提供了一种可扩展、非侵入性的烧伤评估方法，支持急性和门诊护理中的客观决策。

Abstract: Accurate, reproducible burn assessment is critical for treatment planning, healing monitoring, and medico-legal documentation, yet conventional visual inspection and 2D photography are subjective and limited for longitudinal comparison. This paper presents an AI-enabled burn assessment and management platform that integrates multi-view photogrammetry, 3D surface reconstruction, and deep learning-based segmentation within a structured clinical workflow. Using standard multi-angle images from consumer-grade cameras, the system reconstructs patient-specific 3D burn surfaces and maps burn regions onto anatomy to compute objective metrics in real-world units, including surface area, TBSA, depth-related geometric proxies, and volumetric change. Successive reconstructions are spatially aligned to quantify healing progression over time, enabling objective tracking of wound contraction and depth reduction. The platform also supports structured patient intake, guided image capture, 3D analysis and visualization, treatment recommendations, and automated report generation. Simulation-based evaluation demonstrates stable reconstructions, consistent metric computation, and clinically plausible longitudinal trends, supporting a scalable, non-invasive approach to objective, geometry-aware burn assessment and decision support in acute and outpatient care.

</details>


### [13] [1S-DAug: One-Shot Data Augmentation for Robust Few-Shot Generalization](https://arxiv.org/abs/2602.00114)
*Yunwei Bai,Ying Kiat Tan,Yao Shu,Tsuhan Chen*

Main category: cs.CV

TL;DR: 1S-DAug是一种测试时生成增强方法，通过结合几何扰动和扩散过程，显著提升少样本学习性能，尤其在miniImagenet上效果显著。


<details>
  <summary>Details</summary>
Motivation: 解决传统测试时增强方法在少样本学习（FSL）中对新类泛化能力不足的问题。

Method: 结合传统几何扰动、受控噪声注入和基于原始图像的去噪扩散过程，生成多样且忠实于原始图像的变体，并通过编码和聚合增强少样本学习的鲁棒性。

Result: 在4个不同数据集的标准基准测试中，1S-DAug无需更新模型参数即可持续提升FSL性能。

Conclusion: 1S-DAug作为一种无需训练、模型无关的插件，显著提升了少样本学习的性能，尤其在miniImagenet 5-way-1-shot基准测试中实现了超过10%的比例准确率提升。

Abstract: Few-shot learning (FSL) challenges model generalization to novel classes based on just a few shots of labeled examples, a testbed where traditional test-time augmentations fail to be effective. We introduce 1S-DAug, a one-shot generative augmentation operator that synthesizes diverse yet faithful variants from just one example image at test time. 1S-DAug couples traditional geometric perturbations with controlled noise injection and a denoising diffusion process conditioned on the original image. The generated images are then encoded and aggregated, alongside the original image, into a combined representation for more robust FSL predictions. Integrated as a training-free model-agnostic plugin, 1S-DAug consistently improves FSL across standard benchmarks of 4 different datasets without any model parameter update, including achieving over 10% proportional accuracy improvement on the miniImagenet 5-way-1-shot benchmark. Codes will be released.

</details>


### [14] [Event Driven Clustering Algorithm](https://arxiv.org/abs/2602.00115)
*David El-Chai Ben-Ezra,Adar Tal,Daniel Brisk*

Main category: cs.CV

TL;DR: 提出一种异步事件驱动算法，实时检测事件相机数据中的小型事件簇，具有线性复杂度和维度无关的运行时间。


<details>
  <summary>Details</summary>
Motivation: 为了解决事件相机数据中实时检测小型事件簇的挑战，同时降低计算复杂度。

Method: 该算法基于事件的时空距离进行层次凝聚聚类，利用事件相机的异步数据结构，通过高效且简单的决策实现线性复杂度。

Result: 算法实现了线性复杂度O(n)，且运行时间不受像素阵列维度影响。

Conclusion: 该论文提出了一种新颖的异步事件驱动算法，用于实时检测事件相机数据中的小型事件簇，具有线性复杂度且运行时间与像素阵列维度无关。

Abstract: This paper introduces a novel asynchronous, event-driven algorithm for real-time detection of small event clusters in event camera data. Like other hierarchical agglomerative clustering algorithms, the algorithm detects the event clusters based on their tempo-spatial distance. However, the algorithm leverages the special asynchronous data structure of event camera, and by a sophisticated, efficient and simple decision-making, enjoys a linear complexity of $O(n)$ where $n$ is the events amount. In addition, the run-time of the algorithm is independent with the dimensions of the pixels array.

</details>


### [15] [IC-EO: Interpretable Code-based assistant for Earth Observation](https://arxiv.org/abs/2602.00117)
*Lamia Lahouel,Laurynas Lopata,Simon Gruening,Gabriele Meoni,Gaetan Petit,Sylvain Lobry*

Main category: cs.CV

TL;DR: 研究提出一种对话式代码生成代理，将自然语言查询转换为可执行的Python代码，提升地球观测分析的透明度和可复现性，并在特定用例中优于通用模型。


<details>
  <summary>Details</summary>
Motivation: 尽管计算机视觉领域近期取得了进展，但地球观测分析对于非专业人士仍然难以进行，需要专业知识和技能。此外，许多系统返回难以审计或复现的黑盒预测。

Method: 本研究提出了一种对话式代码生成代理，将自然语言查询转换为可执行的、可审计的Python工作流。该代理通过统一的、易于扩展的API进行分类、分割、检测（定向边界框）、光谱指数和地理空间操作。

Result: 所提出的代理在土地组成映射和野火后损害评估两个用例中表现优于通用LLM/VLM基线（GPT-4o、LLaVA），在土地组成上达到64.2% vs. 51.7%的准确率，在野火后分析中达到50% vs. 0%，同时生成透明且易于解释的结果。

Conclusion: 通过输出可验证的代码，该方法将地球观测分析转变为透明且可复现的过程。

Abstract: Despite recent advances in computer vision, Earth Observation (EO) analysis remains difficult to perform for the laymen, requiring expert knowledge and technical capabilities. Furthermore, many systems return black-box predictions that are difficult to audit or reproduce. Leveraging recent advances in tool LLMs, this study proposes a conversational, code-generating agent that transforms natural-language queries into executable, auditable Python workflows. The agent operates over a unified easily extendable API for classification, segmentation, detection (oriented bounding boxes), spectral indices, and geospatial operators. With our proposed framework, it is possible to control the results at three levels: (i) tool-level performance on public EO benchmarks; (ii) at the agent-level to understand the capacity to generate valid, hallucination-free code; and (iii) at the task-level on specific use cases. In this work, we select two use-cases of interest: land-composition mapping and post-wildfire damage assessment. The proposed agent outperforms general-purpose LLM/VLM baselines (GPT-4o, LLaVA), achieving 64.2% vs. 51.7% accuracy on land-composition and 50% vs. 0% on post-wildfire analysis, while producing results that are transparent and easy to interpret. By outputting verifiable code, the approach turns EO analysis into a transparent, reproducible process.

</details>


### [16] [VDE Bench: Evaluating The Capability of Image Editing Models to Modify Visual Documents](https://arxiv.org/abs/2602.00122)
*Hongzhu Yi,Yujia Yang,Yuanxiang Wang,Zhenyu Guan,Jiahuan Chen,Chenxi Bao,Tiankun Yang,Yixuan Yuan,Tianyu Zong,Xinming Wang,Tao Yu,Ruiwen Tao,Haijin Liang,Jin Ma,Jinwen Luo,Yeshani Xinyu Zuo,Jungang Xu*

Main category: cs.CV

TL;DR: VDE Bench是首个针对多语言和密集文本视觉文档编辑的系统性基准，填补现有空白。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要针对英文和稀疏文本布局，无法有效处理复杂结构或非拉丁语系（如中文）文档。

Method: 提出VDE Bench基准，包含高质量的多语言密集文本数据集和分拆评估框架。

Result: 手动验证显示人工判断与自动评估指标高度一致。

Conclusion: VDE Bench是首个系统性评估多语言和密集文本视觉文档编辑模型的基准，填补了现有研究的空白。

Abstract: In recent years, multimodal image editing models have achieved substantial progress, enabling users to manipulate visual content through natural language in a flexible and interactive manner. Nevertheless, an important yet insufficiently explored research direction remains visual document image editing, which involves modifying textual content within images while faithfully preserving the original text style and background context. Existing approaches, including AnyText, GlyphControl, and TextCtrl, predominantly focus on English-language scenarios and documents with relatively sparse textual layouts, thereby failing to adequately address dense, structurally complex documents or non-Latin scripts such as Chinese. To bridge this gap, we propose \textbf{V}isual \textbf{D}oc \textbf{E}dit Bench(VDE Bench), a rigorously human-annotated and evaluated benchmark specifically designed to assess image editing models on multilingual and complex visual document editing tasks. The benchmark comprises a high-quality dataset encompassing densely textual documents in both English and Chinese, including academic papers, posters, presentation slides, examination materials, and newspapers. Furthermore, we introduce a decoupled evaluation framework that systematically quantifies editing performance at the OCR parsing level, enabling fine-grained assessment of text modification accuracy. Based on this benchmark, we conduct a comprehensive evaluation of representative state-of-the-art image editing models. Manual verification demonstrates a strong consistency between human judgments and automated evaluation metrics. VDE Bench constitutes the first systematic benchmark for evaluating image editing models on multilingual and densely textual visual documents.

</details>


### [17] [Context-Aware Autoencoders for Anomaly Detection in Maritime Surveillance](https://arxiv.org/abs/2602.00124)
*Divya Acharya,Pierre Bernab'e,Antoine Chevrot,Helge Spieker,Arnaud Gotlieb,Bruno Legeard*

Main category: cs.CV

TL;DR: 提出情境感知自编码器，通过情境特定阈值提升海上船舶异常检测的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 自编码器在检测集体和情境异常时效果有限，尤其是在依赖船舶特定情境的海域监控中。

Method: 提出了一种情境感知自编码器，通过整合情境特定阈值，比较了四种情境感知自编码器变体和一种传统自编码器。

Result: 情境感知自编码器在时间序列数据异常检测中表现优于其他方法，显著提升了检测准确性。

Conclusion: 通过整合特定情境的阈值，情境感知自编码器显著提升了海上船舶交通监控系统中异常检测的准确性和效率。

Abstract: The detection of anomalies is crucial to ensuring the safety and security of maritime vessel traffic surveillance. Although autoencoders are popular for anomaly detection, their effectiveness in identifying collective and contextual anomalies is limited, especially in the maritime domain, where anomalies depend on vessel-specific contexts derived from self-reported AIS messages. To address these limitations, we propose a novel solution: the context-aware autoencoder. By integrating context-specific thresholds, our method improves detection accuracy and reduces computational cost. We compare four context-aware autoencoder variants and a conventional autoencoder using a case study focused on fishing status anomalies in maritime surveillance. Results demonstrate the significant impact of context on reconstruction loss and anomaly detection. The context-aware autoencoder outperforms others in detecting anomalies in time series data. By incorporating context-specific thresholds and recognizing the importance of context in anomaly detection, our approach offers a promising solution to improve accuracy in maritime vessel traffic surveillance systems.

</details>


### [18] [D3R-Net: Dual-Domain Denoising Reconstruction Network for Robust Industrial Anomaly Detection](https://arxiv.org/abs/2602.00126)
*Dmytro Filatov,Valentyn Fedorov,Vira Filatova,Andrii Zelenchuk*

Main category: cs.CV

TL;DR: D3R-Net通过双重域去噪重建框架，显著提升无监督异常检测的定位精度，尤其在处理高频细节时表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于重建的无监督异常检测方法在处理高频细节时存在过度平滑问题，导致细微缺陷难以准确分割。

Method: 提出D3R-Net框架，结合自监督‘修复’任务和频域感知正则化，使用FFT幅度损失和可选的SSIM项优化重建效果。

Result: 在MVTec AD Hazelnut基准测试中，D3R-Net的PRO AUC从0.603提升至0.687，图像级ROC AUC保持稳定；在15个MVTec类别中，平均像素ROC AUC从0.733提升至0.751。

Conclusion: D3R-Net通过结合空间和频域的双重损失函数，显著提升了无监督异常检测的定位一致性，为现代制造业的自动化视觉检测提供了高效实用的解决方案。

Abstract: Unsupervised anomaly detection (UAD) is a key ingredient of automated visual inspection in modern manufacturing. The reconstruction-based methods appeal because they have basic architectural design and they process data quickly but they produce oversmoothed results for high-frequency details. As a result, subtle defects are partially reconstructed rather than highlighted, which limits segmentation accuracy. We build on this line of work and introduce D3R-Net, a Dual-Domain Denoising Reconstruction framework that couples a self-supervised 'healing' task with frequency-aware regularization. During training, the network receives synthetically corrupted normal images and is asked to reconstruct the clean targets, which prevents trivial identity mapping and pushes the model to learn the manifold of defect-free textures. In addition to the spatial mean squared error, we employ a Fast Fourier Transform (FFT) magnitude loss that encourages consistency in the frequency domain. The implementation also allows an optional structural similarity (SSIM) term, which we study in an ablation. On the MVTec AD Hazelnut benchmark, D3R-Net with the FFT loss improves localization consistency over a spatial-only baseline: PRO AUC increases from 0.603 to 0.687, while image-level ROC AUC remains robust. Evaluated across fifteen MVTec categories, the FFT variant raises the average pixel ROC AUC from 0.733 to 0.751 and PRO AUC from 0.417 to 0.468 compared to the MSE-only baseline, at roughly 20 FPS on a single GPU. The network is trained from scratch and uses a lightweight convolutional autoencoder backbone, providing a practical alternative to heavy pre-trained feature embedding methods.

</details>


### [19] [PovNet+: A Deep Learning Architecture for Socially Assistive Robots to Learn and Assist with Multiple Activities of Daily Living](https://arxiv.org/abs/2602.00131)
*Fraser Robinson,Souren Pashangpour,Matthew Lisondra,Goldie Nejat*

Main category: cs.CV

TL;DR: POVNet+是一种多模态深度学习架构，用于社交辅助机器人识别多种ADLs并主动启动辅助行为，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 长期部署自主社交辅助机器人的主要障碍是其无法感知和辅助多项日常生活活动（ADLs），因此需要一种能识别多种ADLs并主动启动辅助行为的方法。

Method: 提出了一种多模态深度学习架构POVNet+，结合ADL和运动嵌入空间，以及新颖的用户状态估计方法，用于多活动识别和用户表现监控。

Result: 与现有最先进的人类活动识别方法相比，POVNet+具有更高的ADL分类准确率，并在真实环境中成功识别了不同已知和未知ADLs及非典型执行ADLs。

Conclusion: POVNet+架构在识别已知和未知ADLs以及非典型执行ADLs方面表现出色，并能主动启动适当的辅助人机交互，验证了其在真实场景中的有效性。

Abstract: A significant barrier to the long-term deployment of autonomous socially assistive robots is their inability to both perceive and assist with multiple activities of daily living (ADLs). In this paper, we present the first multimodal deep learning architecture, POVNet+, for multi-activity recognition for socially assistive robots to proactively initiate assistive behaviors. Our novel architecture introduces the use of both ADL and motion embedding spaces to uniquely distinguish between a known ADL being performed, a new unseen ADL, or a known ADL being performed atypically in order to assist people in real scenarios. Furthermore, we apply a novel user state estimation method to the motion embedding space to recognize new ADLs while monitoring user performance. This ADL perception information is used to proactively initiate robot assistive interactions. Comparison experiments with state-of-the-art human activity recognition methods show our POVNet+ method has higher ADL classification accuracy. Human-robot interaction experiments in a cluttered living environment with multiple users and the socially assistive robot Leia using POVNet+ demonstrate the ability of our multi-modal ADL architecture in successfully identifying different seen and unseen ADLs, and ADLs being performed atypically, while initiating appropriate assistive human-robot interactions.

</details>


### [20] [Shedding the Facades, Connecting the Domains: Detecting Shifting Multimodal Hate Video with Test-Time Adaptation](https://arxiv.org/abs/2602.00132)
*Jiao Li,Jian Lang,Xikai Tang,Wenzheng Shu,Ting Zhong,Qiang Gao,Yong Wang,Leiting Chen,Fan Zhou*

Main category: cs.CV

TL;DR: SCANNER是首个针对仇恨视频检测的TTA框架，利用仇恨核心不变性解决语义漂移，实验显示性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 仇恨内容为逃避审查常演变为不规则和模糊形式，导致语义漂移，传统TTA方法难以应对。SCANNER基于仇恨核心不变的洞察，提出针对性解决方案。

Method: SCANNER采用基于质心的对齐机制和样本级自适应质心对齐策略，结合簇内多样性正则化，有效应对仇恨内容的语义漂移和异常样本干扰。

Result: 实验表明，SCANNER在Macro-F1指标上平均优于基线方法4.69%。

Conclusion: SCANNER作为首个针对仇恨视频检测（HVD）的测试时适应（TTA）框架，通过利用仇恨内容的核心不变性，成功解决了语义漂移问题，显著提升了模型性能。

Abstract: Hate Video Detection (HVD) is crucial for online ecosystems. Existing methods assume identical distributions between training (source) and inference (target) data. However, hateful content often evolves into irregular and ambiguous forms to evade censorship, resulting in substantial semantic drift and rendering previously trained models ineffective. Test-Time Adaptation (TTA) offers a solution by adapting models during inference to narrow the cross-domain gap, while conventional TTA methods target mild distribution shifts and struggle with the severe semantic drift in HVD. To tackle these challenges, we propose SCANNER, the first TTA framework tailored for HVD. Motivated by the insight that, despite the evolving nature of hateful manifestations, their underlying cores remain largely invariant (i.e., targeting is still based on characteristics like gender, race, etc), we leverage these stable cores as a bridge to connect the source and target domains. Specifically, SCANNER initially reveals the stable cores from the ambiguous layout in evolving hateful content via a principled centroid-guided alignment mechanism. To alleviate the impact of outlier-like samples that are weakly correlated with centroids during the alignment process, SCANNER enhances the prior by incorporating a sample-level adaptive centroid alignment strategy, promoting more stable adaptation. Furthermore, to mitigate semantic collapse from overly uniform outputs within clusters, SCANNER introduces an intra-cluster diversity regularization that encourages the cluster-wise semantic richness. Experiments show that SCANNER outperforms all baselines, with an average gain of 4.69% in Macro-F1 over the best.

</details>


### [21] [LLaVA-FA: Learning Fourier Approximation for Compressing Large Multimodal Models](https://arxiv.org/abs/2602.00135)
*Pengcheng Zheng,Chaoning Zhang,Jiarong Mo,GuoHui Li,Jiaquan Zhang,Jiahao Zhang,Sihan Cao,Sheng Zheng,Caiyan Qin,Guoqing Wang,Yang Yang*

Main category: cs.CV

TL;DR: LLaVA-FA通过频域联合低秩和量化压缩大型多模态模型，减少计算成本并保持高性能。


<details>
  <summary>Details</summary>
Motivation: 现有压缩方法通常将低秩分解和量化分离，导致重建误差累积，尤其是在具有跨模态冗余的多模态架构中。

Method: 提出了LLaVA-FA，利用傅里叶变换的去相关性和共轭对称性，实现更紧凑和准确的权重表示；引入PolarQuant（极坐标量化方法）和可选对角校准（ODC）方案。

Result: 实验结果表明，LLaVA-FA在保持最小激活参数和低计算成本的同时，优于现有高效多模态模型。

Conclusion: LLaVA-FA是一种高效的大型多模态模型，通过频域中的联合低秩加量化近似，显著减少了计算和内存成本，同时在多个基准测试中优于现有高效多模态模型。

Abstract: Large multimodal models (LMMs) have achieved impressive performance on various vision-language tasks, but their substantial computational and memory costs hinder their practical deployment. Existing compression methods often decouple low-rank decomposition and quantization, leading to compounded reconstruction errors, especially in multimodal architectures with cross-modal redundancy. To address this issue, we propose LLaVA-FA, a novel efficient LMM that performs joint low-rank plus quantization approximation in the frequency domain. By leveraging the de-correlation and conjugate symmetry properties of Fourier transform, LLaVA-FA achieves more compact and accurate weight representations. Furthermore, we introduce PolarQuant, a polar-coordinate quantization method tailored for complex matrices, and an optional diagonal calibration (ODC) scheme that eliminates the need for large-scale calibration data. Extensive experimental results demonstrate that our proposed LLaVA-FA outperforms existing efficient multimodal models across multiple benchmarks while maintaining minimal activated parameters and low computational costs, validating its effectiveness as a powerful solution for compressing LMMs.

</details>


### [22] [Scalable Analytic Classifiers with Associative Drift Compensation for Class-Incremental Learning of Vision Transformers](https://arxiv.org/abs/2602.00144)
*Xuan Rao,Mingming Ha,Bo Zhao,Derong Liu,Cesare Alippi*

Main category: cs.CV

TL;DR: 提出LR-RGDA和HopDC框架，通过低秩分解和Hopfield网络动态校准，显著降低ViTs类增量学习的计算复杂度，并在多个基准测试中达到最优性能。


<details>
  <summary>Details</summary>
Motivation: 解决Vision Transformers在类增量学习中分类器重建阶段的计算瓶颈问题，尤其是现有方法依赖的高成本迭代随机梯度下降（SGD）。

Method: 通过利用Woodbury矩阵恒等式分解协方差的低秩结构，LR-RGDA将判别函数分解为全局仿射项和低秩二次扰动，显著降低了推理复杂度。HopDC则通过基于现代连续Hopfield网络的训练无关机制，利用联想记忆动态重新校准历史类统计信息。

Result: 在多个类增量学习基准测试中，该框架实现了最先进的性能，推理复杂度从$\mathcal{O}(Cd^2)$降低到$\mathcal{O}(d^2 + Crd^2)$。

Conclusion: 提出的LR-RGDA和HopDC框架在ViTs的大规模类增量学习场景中实现了最先进的性能，提供了可扩展的解决方案。

Abstract: Class-incremental learning (CIL) with Vision Transformers (ViTs) faces a major computational bottleneck during the classifier reconstruction phase, where most existing methods rely on costly iterative stochastic gradient descent (SGD). We observe that analytic Regularized Gaussian Discriminant Analysis (RGDA) provides a Bayes-optimal alternative with accuracy comparable to SGD-based classifiers; however, its quadratic inference complexity limits its use in large-scale CIL scenarios. To overcome this, we propose Low-Rank Factorized RGDA (LR-RGDA), a scalable classifier that combines RGDA's expressivity with the efficiency of linear classifiers. By exploiting the low-rank structure of the covariance via the Woodbury matrix identity, LR-RGDA decomposes the discriminant function into a global affine term refined by a low-rank quadratic perturbation, reducing the inference complexity from $\mathcal{O}(Cd^2)$ to $\mathcal{O}(d^2 + Crd^2)$, where $C$ is the class number, $d$ the feature dimension, and $r \ll d$ the subspace rank. To mitigate representation drift caused by backbone updates, we further introduce Hopfield-based Distribution Compensator (HopDC), a training-free mechanism that uses modern continuous Hopfield Networks to recalibrate historical class statistics through associative memory dynamics on unlabeled anchors, accompanied by a theoretical bound on the estimation error. Extensive experiments on diverse CIL benchmarks demonstrate that our framework achieves state-of-the-art performance, providing a scalable solution for large-scale class-incremental learning with ViTs. Code: https://github.com/raoxuan98-hash/lr_rgda_hopdc.

</details>


### [23] [DensiThAI, A Multi-View Deep Learning Framework for Breast Density Estimation using Infrared Images](https://arxiv.org/abs/2602.00145)
*Siva Teja Kakileti,Geetha Manjunath*

Main category: cs.CV

TL;DR: 利用AI分析热成像评估乳腺密度的可行性研究，提出DensiThAI框架，在多中心数据中表现良好，支持非电离成像的潜力。


<details>
  <summary>Details</summary>
Motivation: 乳腺密度是乳腺癌风险的关键生物标志物，但目前评估主要依赖电离成像（X射线乳腺摄影），本研究探索非电离成像（热成像）的可行性。

Method: 提出了DensiThAI，一个基于多视角深度学习的热成像乳腺密度分类框架。

Result: 在多中心数据集（3,500名女性）上，DensiThAI的平均AUROC为0.73，所有密度类别间均显示出统计学显著差异（p << 0.05）。

Conclusion: 热成像技术结合人工智能（DensiThAI框架）在评估乳腺密度方面展现出潜力，为非电离成像方法提供了可能，有望改善患者体验和工作流程优化。

Abstract: Breast tissue density is a key biomarker of breast cancer risk and a major factor affecting mammographic sensitivity. However, density assessment currently relies almost exclusively on X-ray mammography, an ionizing imaging modality. This study investigates the feasibility of estimating breast density using artificial intelligence over infrared thermal images, offering a non-ionizing imaging approach. The underlying hypothesis is that fibroglandular and adipose tissues exhibit distinct thermophysical and physiological properties, leading to subtle but spatially coherent temperature variations on the breast surface. In this paper, we propose DensiThAI, a multi-view deep learning framework for breast density classification from thermal images. The framework was evaluated on a multi-center dataset of 3,500 women using mammography-derived density labels as reference. Using five standard thermal views, DensiThAI achieved a mean AUROC of 0.73 across 10 random splits, with statistically significant separation between density classes across all splits (p << 0.05). Consistent performance across age cohorts supports the potential of thermal imaging as a non-ionizing approach for breast density assessment with implications for improved patient experience and workflow optimization.

</details>


### [24] [Learning Physics-Grounded 4D Dynamics with Neural Gaussian Force Fields](https://arxiv.org/abs/2602.00148)
*Shiqian Li,Ruihong Shen,Junfeng Ni,Chang Pan,Chi Zhang,Yixin Zhu*

Main category: cs.CV

TL;DR: NGFF是一个端到端神经框架，通过整合3D高斯感知与物理动态建模，高效生成物理真实的4D视频，比现有方法快100倍。


<details>
  <summary>Details</summary>
Motivation: 现有视频生成模型在物理一致性上表现不足，而结合3D高斯溅射和物理引擎的方法又面临高计算成本和复杂场景下的鲁棒性问题。

Method: NGFF是一个端到端的神经框架，结合了3D高斯感知和基于物理的动态建模，从多视角RGB输入生成交互式、物理真实的4D视频。

Result: NGFF在合成和真实3D场景中表现出强大的泛化能力和鲁棒性，生成速度比现有高斯模拟器快两个数量级。

Conclusion: NGFF框架通过整合3D高斯感知与基于物理的动态建模，显著提升了物理真实4D视频的生成效率，比现有高斯模拟器快两个数量级，并在物理推理中展现出强大的泛化能力和鲁棒性。

Abstract: Predicting physical dynamics from raw visual data remains a major challenge in AI. While recent video generation models have achieved impressive visual quality, they still cannot consistently generate physically plausible videos due to a lack of modeling of physical laws. Recent approaches combining 3D Gaussian splatting and physics engines can produce physically plausible videos, but are hindered by high computational costs in both reconstruction and simulation, and often lack robustness in complex real-world scenarios. To address these issues, we introduce Neural Gaussian Force Field (NGFF), an end-to-end neural framework that integrates 3D Gaussian perception with physics-based dynamic modeling to generate interactive, physically realistic 4D videos from multi-view RGB inputs, achieving two orders of magnitude faster than prior Gaussian simulators. To support training, we also present GSCollision, a 4D Gaussian dataset featuring diverse materials, multi-object interactions, and complex scenes, totaling over 640k rendered physical videos (~4 TB). Evaluations on synthetic and real 3D scenarios show NGFF's strong generalization and robustness in physical reasoning, advancing video prediction towards physics-grounded world models.

</details>


### [25] [SDCM: Simulated Densifying and Compensatory Modeling Fusion for Radar-Vision 3-D Object Detection in Internet of Vehicles](https://arxiv.org/abs/2602.00149)
*Shucong Li,Xiaoluo Zhou,Yuqian He,Zhenyu Liu*

Main category: cs.CV

TL;DR: SDCM框架通过模拟密集化和补偿建模融合，解决了雷达-视觉3-D物体检测中的稀疏点云和视觉退化问题，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决4-D雷达点云稀疏导致的3-D表示不佳，以及视觉数据在低光、远距离和密集遮挡场景下的表示退化问题。

Method: SDCM框架包含三个模块：SimDen模块通过高斯模拟和曲率模拟生成密集雷达点云；RCM模块利用雷达数据的实时性补偿视觉数据的退化；MMIF模块通过特征张量差异值减少异质性并实现交互融合。

Result: 实验结果表明SDCM在多个数据集上表现最佳。

Conclusion: SDCM框架在VoD、TJ4DRadSet和Astyx HiRes 2019数据集上表现出最佳性能，具有更低的参数量和更快的推理速度。

Abstract: 3-D object detection based on 4-D radar-vision is an important part in Internet of Vehicles (IoV). However, there are two challenges which need to be faced. First, the 4-D radar point clouds are sparse, leading to poor 3-D representation. Second, vision datas exhibit representation degradation under low-light, long distance detection and dense occlusion scenes, which provides unreliable texture information during fusion stage. To address these issues, a framework named SDCM is proposed, which contains Simulated Densifying and Compensatory Modeling Fusion for radar-vision 3-D object detection in IoV. Firstly, considering point generation based on Gaussian simulation of key points obtained from 3-D Kernel Density Estimation (3-D KDE), and outline generation based on curvature simulation, Simulated Densifying (SimDen) module is designed to generate dense radar point clouds. Secondly, considering that radar data could provide more real time information than vision data, due to the all-weather property of 4-D radar. Radar Compensatory Mapping (RCM) module is designed to reduce the affects of vision datas' representation degradation. Thirdly, considering that feature tensor difference values contain the effective information of every modality, which could be extracted and modeled for heterogeneity reduction and modalities interaction, Mamba Modeling Interactive Fusion (MMIF) module is designed for reducing heterogeneous and achieving interactive Fusion. Experiment results on the VoD, TJ4DRadSet and Astyx HiRes 2019 dataset show that SDCM achieves best performance with lower parameter quantity and faster inference speed. Our code will be available.

</details>


### [26] [Investigating the Impact of Histopathological Foundation Models on Regressive Prediction of Homologous Recombination Deficiency](https://arxiv.org/abs/2602.00151)
*Alexander Blezinger,Wolfgang Nejdl,Ming Tang*

Main category: cs.CV

TL;DR: 研究评估了五种组织病理学预训练模型在回归性HRD评分预测中的表现，发现其优于基线方法，并提出上采样策略改善样本不平衡问题，为精准肿瘤学提供支持。


<details>
  <summary>Details</summary>
Motivation: 探索大规模组织病理学预训练模型在回归性生物标志物预测中的潜力，特别是针对同源重组缺陷（HRD）评分这一关键个性化癌症治疗标志物。

Method: 在多重实例学习框架下，使用五种最先进的预训练模型从全切片图像中提取补丁级特征，并评估其与对比学习特征的差异。模型基于这些特征预测连续的HRD评分，并在乳腺癌、子宫内膜癌和肺癌队列中进行验证。此外，提出了基于分布的上采样策略以缓解目标不平衡问题。

Result: 实验表明，基于预训练模型特征的模型在预测准确性和泛化能力上均优于基线，同时不同预训练模型间存在系统性差异。提出的上采样策略显著提高了对临床重要但样本不足患者群体的召回率和平衡准确率。

Conclusion: 大规模组织病理学预训练模型在回归性生物标志物预测中展现出显著优势，尤其在提高预测精度和泛化能力方面，为AI驱动的精准肿瘤学提供了重要潜力。

Abstract: Foundation models pretrained on large-scale histopathology data have found great success in various fields of computational pathology, but their impact on regressive biomarker prediction remains underexplored. In this work, we systematically evaluate histopathological foundation models for regression-based tasks, demonstrated through the prediction of homologous recombination deficiency (HRD) score - a critical biomarker for personalized cancer treatment. Within multiple instance learning frameworks, we extract patch-level features from whole slide images (WSI) using five state-of-the-art foundation models, and evaluate their impact compared to contrastive learning-based features. Models are trained to predict continuous HRD scores based on these extracted features across breast, endometrial, and lung cancer cohorts from two public medical data collections. Extensive experiments demonstrate that models trained on foundation model features consistently outperform the baseline in terms of predictive accuracy and generalization capabilities while exhibiting systematic differences among the foundation models. Additionally, we propose a distribution-based upsampling strategy to mitigate target imbalance in these datasets, significantly improving the recall and balanced accuracy for underrepresented but clinically important patient populations. Furthermore, we investigate the impact of different sampling strategies and instance bagsizes by ablation studies. Our results highlight the benefits of large-scale histopathological pretraining for more precise and transferable regressive biomarker prediction, showcasing its potential to advance AI-driven precision oncology.

</details>


### [27] [Real-Time Human Activity Recognition on Edge Microcontrollers: Dynamic Hierarchical Inference with Multi-Spectral Sensor Fusion](https://arxiv.org/abs/2602.00152)
*Boyu Li,Kuangji Zuo,Lincong Li,Yonghui Wu*

Main category: cs.CV

TL;DR: HPPI-Net是一种资源感知的层次网络，通过多光谱融合和可解释模块，在边缘设备上实现高效实时人体活动识别，显著提升准确性并降低资源消耗。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以在边缘应用中平衡准确性与计算资源限制，因此提出了HPPI-Net，旨在实现实时、低功耗的人体活动识别。

Method: HPPI-Net采用两层架构：第一层使用FFT频谱图提取初步特征，第二层选择性激活专用模块或并行LSTM-MobileNet网络（PLMN）。PLMN通过三个并行LSTM编码器融合FFT、小波和Gabor频谱图，并利用ECA和DSC优化特征，减少计算量。

Result: HPPI-Net在优化后仅占用22.3 KiB RAM和439.5 KiB ROM，准确率达96.70%，比MobileNetV3提升1.22%准确率，同时减少71.2% RAM和42.1% ROM使用。

Conclusion: HPPI-Net在内存受限的边缘平台上实现了良好的准确性与效率平衡，并提供可解释的预测，为可穿戴设备、工业和智能家居的人体活动识别提供了实用解决方案。

Abstract: The demand for accurate on-device pattern recognition in edge applications is intensifying, yet existing approaches struggle to reconcile accuracy with computational constraints. To address this challenge, a resource-aware hierarchical network based on multi-spectral fusion and interpretable modules, namely the Hierarchical Parallel Pseudo-image Enhancement Fusion Network (HPPI-Net), is proposed for real-time, on-device Human Activity Recognition (HAR). Deployed on an ARM Cortex-M4 microcontroller for low-power real-time inference, HPPI-Net achieves 96.70% accuracy while utilizing only 22.3 KiB of RAM and 439.5 KiB of ROM after optimization. HPPI-Net employs a two-layer architecture. The first layer extracts preliminary features using Fast Fourier Transform (FFT) spectrograms, while the second layer selectively activates either a dedicated module for stationary activity recognition or a parallel LSTM-MobileNet network (PLMN) for dynamic states. PLMN fuses FFT, Wavelet, and Gabor spectrograms through three parallel LSTM encoders and refines the concatenated features using Efficient Channel Attention (ECA) and Depthwise Separable Convolution (DSC), thereby offering channel-level interpretability while substantially reducing multiply-accumulate operations. Compared with MobileNetV3, HPPI-Net improves accuracy by 1.22% and reduces RAM usage by 71.2% and ROM usage by 42.1%. These results demonstrate that HPPI-Net achieves a favorable accuracy-efficiency trade-off and provides explainable predictions, establishing a practical solution for wearable, industrial, and smart home HAR on memory-constrained edge platforms.

</details>


### [28] [See Without Decoding: Motion-Vector-Based Tracking in Compressed Video](https://arxiv.org/abs/2602.00153)
*Axel Duché,Clément Chatelain,Gilles Gasso*

Main category: cs.CV

TL;DR: A lightweight compressed-domain tracking model speeds up computation by 3.7x with minimal accuracy loss, using motion vectors from video streams for real-time analytics.


<details>
  <summary>Details</summary>
Motivation: The motivation is to achieve real-time object tracking in large monitoring systems by reducing computational overhead while maintaining accuracy, leveraging the inherent motion data in compressed video streams.

Method: The proposed model operates directly on compressed video streams, utilizing motion vectors and transform coefficients to propagate object bounding boxes across frames without full RGB video decoding.

Result: The model achieves a computational speed-up of up to 3.7 times with only a 4% mAP@0.5 drop compared to the RGB baseline on MOTS15/17/20 datasets.

Conclusion: The paper highlights the efficiency of codec-domain motion modeling for real-time analytics in large monitoring systems, demonstrating a significant computational speed-up with minimal accuracy loss.

Abstract: We propose a lightweight compressed-domain tracking model that operates directly on video streams, without requiring full RGB video decoding. Using motion vectors and transform coefficients from compressed data, our deep model propagates object bounding boxes across frames, achieving a computational speed-up of order up to 3.7 with only a slight 4% mAP@0.5 drop vs RGB baseline on MOTS15/17/20 datasets. These results highlight codec-domain motion modeling efficiency for real-time analytics in large monitoring systems.

</details>


### [29] [Deep Learning Pose Estimation for Multi-Label Recognition of Combined Hyperkinetic Movement Disorders](https://arxiv.org/abs/2602.00163)
*Laura Cif,Diane Demailly,Gabriella A. Horvàth,Juan Dario Ortigoza Escobar,Nathalie Dorison,Mayté Castro Jiménez,Cécile A. Hubsch,Thomas Wirth,Gun-Marie Hariz,Sophie Huby,Morgan Dornadic,Zohra Souei,Muhammad Mushhood Ur Rehman,Simone Hemm,Mehdi Boulayme,Eduardo M. Moraud,Jocelyne Bloch,Xavier Vasques*

Main category: cs.CV

TL;DR: 提出了一种基于姿态的机器学习方法，用于从门诊视频中客观识别重叠的HMD表型。


<details>
  <summary>Details</summary>
Motivation: HMDs（如肌张力障碍、震颤、舞蹈症、肌阵挛和抽动症）的临床表现波动、间歇且常重叠，导致临床识别和纵向监测困难，目前缺乏客观且可扩展的方法来区分这些表型。

Method: 开发了一个基于姿态的机器学习框架，通过将门诊视频转换为关键点时间序列并计算多种运动学特征（统计、时间、频谱、高阶不规则性-复杂性）来识别HMD表型。

Result: 该框架能够从常规临床视频中提取运动学特征，为HMD表型的客观识别提供了可行方案。

Conclusion: 该论文提出了一个基于姿态的机器学习框架，能够将标准门诊视频转换为解剖学上有意义的关键点时间序列，并计算跨越统计、时间、频谱以及高阶不规则性-复杂性特征的运动学描述符，以客观和可扩展的方式区分重叠的HMD表型。

Abstract: Hyperkinetic movement disorders (HMDs) such as dystonia, tremor, chorea, myoclonus, and tics are disabling motor manifestations across childhood and adulthood. Their fluctuating, intermittent, and frequently co-occurring expressions hinder clinical recognition and longitudinal monitoring, which remain largely subjective and vulnerable to inter-rater variability. Objective and scalable methods to distinguish overlapping HMD phenotypes from routine clinical videos are still lacking. Here, we developed a pose-based machine-learning framework that converts standard outpatient videos into anatomically meaningful keypoint time series and computes kinematic descriptors spanning statistical, temporal, spectral, and higher-order irregularity-complexity features.

</details>


### [30] [YOLOE-26: Integrating YOLO26 with YOLOE for Real-Time Open-Vocabulary Instance Segmentation](https://arxiv.org/abs/2602.00168)
*Ranjan Sapkota,Manoj Karkee*

Main category: cs.CV

TL;DR: YOLOE-26是一个结合YOLOv26架构和开放词汇学习范式的统一框架，支持实时开放词汇实例分割，通过对象嵌入头和多种提示模态实现高效推理。


<details>
  <summary>Details</summary>
Motivation: 为了在保持YOLO家族高效性和确定性的同时，扩展其能力至封闭集识别之外，提出YOLOE-26框架，实现实时开放词汇实例分割。

Method: YOLOE-26采用卷积主干网络结合PAN/FPN风格的多尺度特征聚合，以及端到端的回归和实例分割头。关键架构贡献是用对象嵌入头替代固定类别logits，将分类问题转化为与文本描述、视觉示例或内置词汇生成的提示嵌入的相似性匹配。

Result: 大量实验表明，YOLOE-26在不同模型大小下均表现出一致的扩展行为和良好的准确性与效率权衡。

Conclusion: YOLOE-26提供了一个实用且可扩展的解决方案，适用于动态现实环境中的实时开放词汇实例分割。

Abstract: This paper presents YOLOE-26, a unified framework that integrates the deployment-optimized YOLO26(or YOLOv26) architecture with the open-vocabulary learning paradigm of YOLOE for real-time open-vocabulary instance segmentation. Building on the NMS-free, end-to-end design of YOLOv26, the proposed approach preserves the hallmark efficiency and determinism of the YOLO family while extending its capabilities beyond closed-set recognition. YOLOE-26 employs a convolutional backbone with PAN/FPN-style multi-scale feature aggregation, followed by end-to-end regression and instance segmentation heads. A key architectural contribution is the replacement of fixed class logits with an object embedding head, which formulates classification as similarity matching against prompt embeddings derived from text descriptions, visual examples, or a built-in vocabulary. To enable efficient open-vocabulary reasoning, the framework incorporates Re-Parameterizable Region-Text Alignment (RepRTA) for zero-overhead text prompting, a Semantic-Activated Visual Prompt Encoder (SAVPE) for example-guided segmentation, and Lazy Region Prompt Contrast for prompt-free inference. All prompting modalities operate within a unified object embedding space, allowing seamless switching between text-prompted, visual-prompted, and fully autonomous segmentation. Extensive experiments demonstrate consistent scaling behavior and favorable accuracy-efficiency trade-offs across model sizes in both prompted and prompt-free settings. The training strategy leverages large-scale detection and grounding datasets with multi-task optimization and remains fully compatible with the Ultralytics ecosystem for training, validation, and deployment. Overall, YOLOE-26 provides a practical and scalable solution for real-time open-vocabulary instance segmentation in dynamic, real-world environments.

</details>


### [31] [Intra-Class Subdivision for Pixel Contrastive Learning: Application to Semi-supervised Cardiac Image Segmentation](https://arxiv.org/abs/2602.00174)
*Jiajun Zhao,Xuan Yang*

Main category: cs.CV

TL;DR: SPCL框架通过新概念和损失函数提升心脏图像分割的边界精度和性能。


<details>
  <summary>Details</summary>
Motivation: 解决心脏图像分割中边界区域表示污染的问题，更清晰地表征类内变化。

Method: 提出了一个基于类内细分像素对比学习（SPCL）的框架，包括‘Unconcerned sample’概念和边界对比损失。

Result: 在公开的心脏数据集上，SPCL在分割质量和边界精度上优于现有方法。

Conclusion: SPCL框架通过引入‘Unconcerned sample’概念和边界对比损失，显著提升了心脏图像分割的性能和边界精度。

Abstract: We propose an intra-class subdivision pixel contrastive learning (SPCL) framework for cardiac image segmentation to address representation contamination at boundaries. The novel concept ``Unconcerned sample'' is proposed to distinguish pixel representations at the inner and boundary regions within the same class, facilitating a clearer characterization of intra-class variations. A novel boundary contrastive loss for boundary representations is proposed to enhance representation discrimination across boundaries. The advantages of the unconcerned sample and boundary contrastive loss are analyzed theoretically. Experimental results in public cardiac datasets demonstrate that SPCL significantly improves segmentation performance, outperforming existing methods with respect to segmentation quality and boundary precision. Our code is available at https://github.com/Jrstud203/SPCL.

</details>


### [32] [Stabilizing Diffusion Posterior Sampling by Noise--Frequency Continuation](https://arxiv.org/abs/2602.00176)
*Feng Tian,Yixuan Li,Weili Zeng,Weitian Zhang,Yichao Yan,Xiaokang Yang*

Main category: cs.CV

TL;DR: 提出噪声-频率连续框架，通过带限似然和多分辨率策略优化扩散后验采样，显著提升逆问题求解性能。


<details>
  <summary>Details</summary>
Motivation: 传统扩散后验采样方法在高噪声下数据一致性梯度与后验几何不匹配，导致细节恢复失败、高频伪影和对调度敏感。

Method: 采用噪声-频率连续框架，结合扩散预测器、带限似然引导和多分辨率一致性策略，逐步优化后验采样过程。

Result: 在超分辨率、修复和去模糊任务中达到最先进性能，运动去模糊PSNR提升高达5 dB。

Conclusion: 提出的噪声-频率连续框架通过结合扩散预测器、带限似然引导和多分辨率一致性策略，显著提升了逆问题求解的性能，尤其在运动去模糊任务中PSNR提升高达5 dB。

Abstract: Diffusion posterior sampling solves inverse problems by combining a pretrained diffusion prior with measurement-consistency guidance, but it often fails to recover fine details because measurement terms are applied in a manner that is weakly coupled to the diffusion noise level. At high noise, data-consistency gradients computed from inaccurate estimates can be geometrically incongruent with the posterior geometry, inducing early-step drift, spurious high-frequency artifacts, plus sensitivity to schedules and ill-conditioned operators. To address these concerns, we propose a noise--frequency Continuation framework that constructs a continuous family of intermediate posteriors whose likelihood enforces measurement consistency only within a noise-dependent frequency band. This principle is instantiated with a stabilized posterior sampler that combines a diffusion predictor, band-limited likelihood guidance, and a multi-resolution consistency strategy that aggressively commits reliable coarse corrections while conservatively adopting high-frequency details only when they become identifiable. Across super-resolution, inpainting, and deblurring, our method achieves state-of-the-art performance and improves motion deblurring PSNR by up to 5 dB over strong baselines.

</details>


### [33] [CamReasoner: Reinforcing Camera Movement Understanding via Structured Spatial Reasoning](https://arxiv.org/abs/2602.00181)
*Hang Wu,Yujun Cai,Zehao Li,Haonan Ge,Bowen Sun,Junsong Yuan,Yiwei Wang*

Main category: cs.CV

TL;DR: CamReasoner通过O-T-A推理范式和强化学习，提升了相机动态理解的准确性和逻辑性，成为该领域的SOTA方法。


<details>
  <summary>Details</summary>
Motivation: 现有多模态模型将相机动态理解视为黑盒分类任务，依赖表面视觉模式而非几何线索，容易混淆物理上不同的运动。

Method: 采用Observation-Thinking-Answer (O-T-A)范式，结合强化学习（RL）和大规模推理轨迹数据集（18k SFT推理链和38k RL反馈样本）进行训练。

Result: CamReasoner有效抑制了幻觉现象，并在多个基准测试中取得了最先进的性能。

Conclusion: CamReasoner通过结合强化学习和O-T-A推理范式，显著提升了相机动态理解的性能，并在多个基准测试中达到了最先进水平。

Abstract: Understanding camera dynamics is a fundamental pillar of video spatial intelligence. However, existing multimodal models predominantly treat this task as a black-box classification, often confusing physically distinct motions by relying on superficial visual patterns rather than geometric cues. We present CamReasoner, a framework that reformulates camera movement understanding as a structured inference process to bridge the gap between perception and cinematic logic. Our approach centers on the Observation-Thinking-Answer (O-T-A) paradigm, which compels the model to decode spatio-temporal cues such as trajectories and view frustums within an explicit reasoning block. To instill this capability, we construct a Large-scale Inference Trajectory Suite comprising 18k SFT reasoning chains and 38k RL feedback samples. Notably, we are the first to employ RL for logical alignment in this domain, ensuring motion inferences are grounded in physical geometry rather than contextual guesswork. By applying Reinforcement Learning to the Observation-Think-Answer (O-T-A) reasoning paradigm, CamReasoner effectively suppresses hallucinations and achieves state-of-the-art performance across multiple benchmarks.

</details>


### [34] [AI-Generated Image Detectors Overrely on Global Artifacts: Evidence from Inpainting Exchange](https://arxiv.org/abs/2602.00192)
*Elif Nebioglu,Emirhan Bilgiç,Adrian Popescu*

Main category: cs.CV

TL;DR: 论文指出当前修复检测器依赖全局伪影而非局部内容，通过INP-X操作和数据集揭示其局限性，并提出内容感知检测的必要性。


<details>
  <summary>Details</summary>
Motivation: 当前检测器主要依赖全局伪影而非局部合成内容，导致检测不可靠，因此需要研究更可靠的检测方法。

Method: 引入了Inpainting Exchange (INP-X)操作，创建了一个包含真实、修复和交换图像的90K测试数据集，并进行了理论分析。

Result: 在INP-X干预下，预训练的最先进检测器（包括商业检测器）准确率显著下降（如从91%降至55%），接近随机水平。

Conclusion: 论文强调了基于内容感知的检测的重要性，并通过INP-X操作和数据集展示了当前检测器的局限性，提出了改进方向。

Abstract: Modern deep learning-based inpainting enables realistic local image manipulation, raising critical challenges for reliable detection. However, we observe that current detectors primarily rely on global artifacts that appear as inpainting side effects, rather than on locally synthesized content. We show that this behavior occurs because VAE-based reconstruction induces a subtle but pervasive spectral shift across the entire image, including unedited regions. To isolate this effect, we introduce Inpainting Exchange (INP-X), an operation that restores original pixels outside the edited region while preserving all synthesized content. We create a 90K test dataset including real, inpainted, and exchanged images to evaluate this phenomenon. Under this intervention, pretrained state-of-the-art detectors, including commercial ones, exhibit a dramatic drop in accuracy (e.g., from 91\% to 55\%), frequently approaching chance level. We provide a theoretical analysis linking this behavior to high-frequency attenuation caused by VAE information bottlenecks. Our findings highlight the need for content-aware detection. Indeed, training on our dataset yields better generalization and localization than standard inpainting. Our dataset and code are publicly available at https://github.com/emirhanbilgic/INP-X.

</details>


### [35] [Vision-Language Model Purified Semi-Supervised Semantic Segmentation for Remote Sensing Images](https://arxiv.org/abs/2602.00202)
*Shanwen Wang,Xin Sun,Danfeng Hong,Fei Zhou*

Main category: cs.CV

TL;DR: SemiEarth模型通过VLM-PP结构净化伪标签，结合VLMs的开放世界能力，显著提升半监督语义分割在遥感图像中的性能，达到SOTA水平且具备可解释性。


<details>
  <summary>Details</summary>
Motivation: 传统S4架构（尤其是师生框架）面临伪标签质量低的挑战，特别是在遥感领域。本文旨在通过引入VLMs解决这一问题。

Method: 提出了一种新颖的SemiEarth模型，采用VLM伪标签净化（VLM-PP）结构来净化教师网络的伪标签，并利用VLMs的开放世界能力纠正低置信度伪标签中的错误类别。

Result: 在多个RS数据集上的实验表明，SemiEarth实现了最先进（SOTA）性能，并在多类边界区域显著提升了伪标签质量。

Conclusion: SemiEarth模型通过引入视觉语言模型（VLMs）和VLM-PP结构，显著提升了半监督语义分割（S4）的性能，特别是在遥感（RS）图像的多类边界区域。该模型不仅性能优越，还具备良好的可解释性。

Abstract: The semi-supervised semantic segmentation (S4) can learn rich visual knowledge from low-cost unlabeled images. However, traditional S4 architectures all face the challenge of low-quality pseudo-labels, especially for the teacher-student framework.We propose a novel SemiEarth model that introduces vision-language models (VLMs) to address the S4 issues for the remote sensing (RS) domain. Specifically, we invent a VLM pseudo-label purifying (VLM-PP) structure to purify the teacher network's pseudo-labels, achieving substantial improvements. Especially in multi-class boundary regions of RS images, the VLM-PP module can significantly improve the quality of pseudo-labels generated by the teacher, thereby correctly guiding the student model's learning. Moreover, since VLM-PP equips VLMs with open-world capabilities and is independent of the S4 architecture, it can correct mispredicted categories in low-confidence pseudo-labels whenever a discrepancy arises between its prediction and the pseudo-label. We conducted extensive experiments on multiple RS datasets, which demonstrate that our SemiEarth achieves SOTA performance. More importantly, unlike previous SOTA RS S4 methods, our model not only achieves excellent performance but also offers good interpretability. The code is released at https://github.com/wangshanwen001/SemiEarth.

</details>


### [36] [Interpretable Unsupervised Deformable Image Registration via Confidence-bound Multi-Hop Visual Reasoning](https://arxiv.org/abs/2602.00211)
*Zafar Iqbal,Anwar Ul Haq,Srimannarayana Grandhi*

Main category: cs.CV

TL;DR: VCoR框架通过多跳视觉推理和局部细化模块，提升无监督医学图像配准的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在无监督图像配准中缺乏透明度和可靠性，导致临床信任度降低。

Method: 提出Multi-Hop Visual Chain of Reasoning (VCoR)框架，结合Localized Spatial Refinement (LSR)模块和Cross-Reference Attention (CRA)机制，通过多跳推理逐步优化配准过程。

Result: 在DIR-Lab 4D CT和IXI T1-weighted MRI数据集上，VCoR实现了竞争性的配准准确性，并提供丰富的中间可视化及置信度评估。

Conclusion: VCoR框架通过多跳视觉推理链和局部空间细化模块，实现了无监督医学图像配准的高准确性和可解释性，为临床应用提供了可靠且透明的解决方案。

Abstract: Unsupervised deformable image registration requires aligning complex anatomical structures without reference labels, making interpretability and reliability critical. Existing deep learning methods achieve considerable accuracy but often lack transparency, leading to error drift and reduced clinical trust. We propose a novel Multi-Hop Visual Chain of Reasoning (VCoR) framework that reformulates registration as a progressive reasoning process. Inspired by the iterative nature of clinical decision-making, each visual reasoning hop integrates a Localized Spatial Refinement (LSR) module to enrich feature representations and a Cross-Reference Attention (CRA) mechanism that leads the iterative refinement process, preserving anatomical consistency. This multi-hop strategy enables robust handling of large deformations and produces a transparent sequence of intermediate predictions with a theoretical bound. Beyond accuracy, our framework offers built-in interpretability by estimating uncertainty via the stability and convergence of deformation fields across hops. Extensive evaluations on two challenging public datasets, DIR-Lab 4D CT (lung) and IXI T1-weighted MRI (brain), demonstrate that VCoR achieves competitive registration accuracy while offering rich intermediate visualizations and confidence measures. By embedding an implicit visual reasoning paradigm, we present an interpretable, reliable, and clinically viable unsupervised medical image registration.

</details>


### [37] [Deep Learning Based CNN Model for Automated Detection of Pneumonia from Chest XRay Images](https://arxiv.org/abs/2602.00212)
*Sathish Krishna Anumula,Vetrivelan Tamilmani,Aniruddha Arjun Singh,Dinesh Rajendran,Venkata Deepak Namburi*

Main category: cs.CV

TL;DR: 本文提出一种定制化CNN模型，通过深度可分离卷积和预处理技术，高效识别胸片中的肺炎，解决了传统手动解读的局限性。


<details>
  <summary>Details</summary>
Motivation: 肺炎是全球发病率和死亡率的主要原因之一，尤其在资源匮乏地区，快速准确的诊断对临床干预至关重要，但传统手动解读方法存在观察者差异、专家疲劳和合格放射科医生短缺等限制。

Method: 使用定制化的深度可分离卷积设计，结合CLAHE和几何增强等预处理技术，优化针对灰度医学图像的纹理特征。

Result: 模型在5863张前后位胸片数据集上测试，表现出高精度和低计算成本。

Conclusion: 本文提出的定制化CNN模型在胸片图像中高精度且低计算成本地识别肺炎，为解决传统手动解读的局限性提供了有效解决方案。

Abstract: Pneumonia has been one of the major causes of morbidities and mortality in the world and the prevalence of this disease is disproportionately high among the pediatric and elderly populations especially in resources trained areas Fast and precise diagnosis is a prerequisite for successful clinical intervention but due to inter observer variation fatigue among experts and a shortage of qualified radiologists traditional approaches that rely on manual interpretation of chest radiographs are frequently constrained To address these problems this paper introduces a unified automated diagnostic model using a custom Convolutional Neural Network CNN that can recognize pneumonia in chest Xray images with high precision and at minimal computational expense In contrast like other generic transfer learning based models which often possess redundant parameters the offered architecture uses a tailor made depth wise separable convolutional design which is optimized towards textural characteristics of grayscale medical images Contrast Limited Adaptive Histogram Equalization CLAHE and geometric augmentation are two significant preprocessing techniques used to ensure that the system does not experience class imbalance and is more likely to generalize The system is tested using a dataset of 5863 anterior posterior chest Xrays.

</details>


### [38] [A Geometric Multimodal Foundation Model Integrating Bp-MRI and Clinical Reports in Prostate Cancer Classification](https://arxiv.org/abs/2602.00214)
*Juan A. Olmos,Antoine Manzanera,Fabio Martínez*

Main category: cs.CV

TL;DR: MFM-Geom模型结合影像与临床数据，通过几何多模态学习提升前列腺癌诊断性能，数据效率高且泛化能力强。


<details>
  <summary>Details</summary>
Motivation: 前列腺癌诊断过程依赖专家主观解读，现有计算机辅助诊断方法多基于影像，忽略临床背景且数据稀缺，难以学习鲁棒表示。

Method: 提出了一种名为MFM-Geom的几何多模态基础模型，结合bp-MRI和临床报告数据，使用SPD矩阵和黎曼深度学习进行表示学习和分类。

Result: MFM-Geom在仅使用10%训练数据的情况下，性能超越基线方法（AUC-PR提升8.3%，达90.67%），并在外部数据集上验证了其泛化能力（AUC-PR 90.6）。

Conclusion: MFM-Geom模型通过结合bp-MRI和临床报告的多模态数据，利用SPD矩阵和黎曼深度学习，显著提升了前列腺癌的诊断性能，并在外部数据集上验证了其鲁棒性。

Abstract: Prostate cancer (PCa) is one of the most common cancers in men worldwide. Bi-parametric MRI (bp-MRI) and clinical variables are crucial for PCa identification and improving treatment decisions. However, this process is subjective to expert interpretations. Furthermore, most existing computer-aided diagnosis methods focus on imaging-based models, overlooking the clinical context and suffering from data scarcity, limiting their ability to learn robust representations. We propose a geometric multimodal Foundation Model (FM), named MFM-Geom, that learns representations from bp-MRI and clinical reports, encoding visual findings and information from the context of clinical variables. In the representations classification head, the approach leverages symmetric positive definite (SPD) matrices and Riemannian deep learning to integrate imaging-text representations from a biomedical multimodal FM. Using 10% of the training data, MFM-Geom outperformed baseline class token embedding-based classification (+8.3%, AUC-PR of 90.67). Generalization on external dataset confirmed the robustness of fine-tuning biomedical FM, achieving an AUC-PR of 90.6.

</details>


### [39] [Development of a Cacao Disease Identification and Management App Using Deep Learning](https://arxiv.org/abs/2602.00216)
*Zaldy Pagaduan,Jason Occidental,Nathaniel Duro,Dexielito Badilles,Eleonor Palconit*

Main category: cs.CV

TL;DR: 开发了一款离线移动应用，通过深度学习模型帮助小农户识别和管理可可病害，显著提升了作物健康和生产效率。


<details>
  <summary>Details</summary>
Motivation: 菲律宾的小农户缺乏数据、信息和良好农业实践的获取途径，面临病虫害的严重挑战，而大型种植园则拥有更多资源和专业知识。

Method: 研究开发了一个基于深度学习的模型，用于准确识别可可病害，并将其集成到移动应用中，支持田间诊断。

Result: 病害识别模型的验证准确率达到96.93%，可可黑荚感染水平检测模型的验证准确率为79.49%。应用实地测试与专家评估的一致性率为84.2%。

Conclusion: 该研究通过开发一款离线移动应用程序，帮助小农户准确识别和管理可可病害，显著提升了可可作物的健康和生产效率。

Abstract: Smallholder cacao producers often rely on outdated farming techniques and face significant challenges from pests and diseases, unlike larger plantations with more resources and expertise. In the Philippines, cacao farmers have limited access to data, information, and good agricultural practices. This study addresses these issues by developing a mobile application for cacao disease identification and management that functions offline, enabling use in remote areas where farms are mostly located. The core of the system is a deep learning model trained to identify cacao diseases accurately. The trained model is integrated into the mobile app to support farmers in field diagnosis. The disease identification model achieved a validation accuracy of 96.93% while the model for detecting cacao black pod infection levels achieved 79.49% validation accuracy. Field testing of the application showed an agreement rate of 84.2% compared with expert cacao technician assessments. This approach empowers smallholder farmers by providing accessible, technology-enabled tools to improve cacao crop health and productivity.

</details>


### [40] [CAPA: Contribution-Aware Pruning and FFN Approximation for Efficient Large Vision-Language Models](https://arxiv.org/abs/2602.00247)
*Samyak Jha,Junho Kim*

Main category: cs.CV

TL;DR: CAPA通过注意力贡献和FFN线性近似优化视觉令牌处理，提升效率与性能。


<details>
  <summary>Details</summary>
Motivation: 解决大型视觉语言模型中高成本处理数千个视觉令牌的问题，明确哪些令牌和计算可以安全移除。

Method: 引入CAPA框架，结合注意力贡献进行视觉令牌修剪和在关键功能转换处使用线性近似减少FFN计算。

Result: 实验表明CAPA在多个基准测试中实现了效率与性能的平衡，并提高了鲁棒性。

Conclusion: CAPA框架通过基于注意力贡献的视觉令牌修剪和FFN线性近似，实现了效率与性能的平衡，并提高了鲁棒性。

Abstract: Efficient inference in Large Vision-Language Models is constrained by the high cost of processing thousands of visual tokens, yet it remains unclear which tokens and computations can be safely removed. While attention scores are commonly used to estimate visual token importance, they are an imperfect proxy for actual contribution. We show that Attention Contribution, which weights attention probabilities by value vector magnitude, provides a more accurate criterion for visual token selection. Our empirical analysis reveals that visual attention sinks are functionally heterogeneous, comprising Probability Dumps with low contribution that can be safely pruned, and Structural Anchors with high contribution essential for maintaining model performance. Further, we identify substantial redundancy in Feed-Forward Networks (FFNs) associated with visual tokens, particularly in intermediate layers where image tokens exhibit linear behavior. Based on our findings, we introduce CAPA (Contribution-Aware Pruning and FFN Approximation), a dual-strategy framework that prunes visual tokens using attention contribution at critical functional transitions and reduces FFN computation through efficient linear approximations. Experiments on various benchmarks across baselines show that CAPA achieves competent efficiency--performance trade-offs with improved robustness.

</details>


### [41] [SANEval: Open-Vocabulary Compositional Benchmarks with Failure-mode Diagnosis](https://arxiv.org/abs/2602.00249)
*Rishav Pramanik,Ian E. Nielsen,Jeff Smith,Saurav Pandit,Ravi P. Ramachandran,Zhaozheng Yin*

Main category: cs.CV

TL;DR: SANEval是一个新的文本到图像模型评估基准，通过LLM和开放词汇检测器提升组合性评估能力，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有评估方法在开放词汇、细粒度诊断和可解释反馈方面存在不足，限制了T2I模型在复杂提示下的表现评估。

Method: 引入SANEval基准测试，结合LLM进行深度提示理解和LLM增强的开放词汇对象检测器，以评估组合性。

Result: SANEval的自动化评估与人类评估更一致，其指标在属性绑定、空间关系和计数任务中与现有基准相比有显著差异。

Conclusion: SANEval提供了一个可扩展的开放词汇组合评估新流程，通过结合大型语言模型（LLM）和开放词汇对象检测器，显著提升了文本到图像（T2I）模型的评估能力。

Abstract: The rapid progress of text-to-image (T2I) models has unlocked unprecedented creative potential, yet their ability to faithfully render complex prompts involving multiple objects, attributes, and spatial relationships remains a significant bottleneck. Progress is hampered by a lack of adequate evaluation methods; current benchmarks are often restricted to closed-set vocabularies, lack fine-grained diagnostic capabilities, and fail to provide the interpretable feedback necessary to diagnose and remedy specific compositional failures. We solve these challenges by introducing SANEval (Spatial, Attribute, and Numeracy Evaluation), a comprehensive benchmark that establishes a scalable new pipeline for open-vocabulary compositional evaluation. SANEval combines a large language model (LLM) for deep prompt understanding with an LLM-enhanced, open-vocabulary object detector to robustly evaluate compositional adherence, unconstrained by a fixed vocabulary. Through extensive experiments on six state-of-the-art T2I models, we demonstrate that SANEval's automated evaluations provide a more faithful proxy for human assessment; our metric achieves a Spearman's rank correlation with statistically different results than those of existing benchmarks across tasks of attribute binding, spatial relations, and numeracy. To facilitate future research in compositional T2I generation and evaluation, we will release the SANEval dataset and our open-source evaluation pipeline.

</details>


### [42] [Subspace Clustering on Incomplete Data with Self-Supervised Contrastive Learning](https://arxiv.org/abs/2602.00262)
*Huanran Li,Daniel Pimentel-Alarcón*

Main category: cs.CV

TL;DR: CSC是一种针对不完整数据的对比自监督子空间聚类方法，通过掩码视图和对比损失学习不变嵌入，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有子空间聚类方法假设数据完全观测，无法有效处理现实场景中的缺失数据问题。

Method: 提出了一种对比自监督框架CSC，通过生成掩码视图并利用SimCLR风格的对比损失训练深度神经网络，学习不变嵌入，最后使用稀疏子空间聚类进行分组。

Result: 在六个基准数据集上，CSC表现优于传统和深度学习方法，对缺失数据具有强鲁棒性，并能扩展到大规模数据集。

Conclusion: CSC通过对比自监督学习和稀疏子空间聚类，有效解决了不完整数据的子空间聚类问题，并在多个基准数据集上表现优于现有方法。

Abstract: Subspace clustering aims to group data points that lie in a union of low-dimensional subspaces and finds wide application in computer vision, hyperspectral imaging, and recommendation systems. However, most existing methods assume fully observed data, limiting their effectiveness in real-world scenarios with missing entries. In this paper, we propose a contrastive self-supervised framework, Contrastive Subspace Clustering (CSC), designed for clustering incomplete data. CSC generates masked views of partially observed inputs and trains a deep neural network using a SimCLR-style contrastive loss to learn invariant embeddings. These embeddings are then clustered using sparse subspace clustering. Experiments on six benchmark datasets show that CSC consistently outperforms both classical and deep learning baselines, demonstrating strong robustness to missing data and scalability to large datasets.

</details>


### [43] [World-Shaper: A Unified Framework for 360° Panoramic Editing](https://arxiv.org/abs/2602.00265)
*Dong Liang,Yuhao Liu,Jinyuan Jia,Youjun Zhao,Rynson W. H. Lau*

Main category: cs.CV

TL;DR: World-Shaper是一个直接在等距柱状投影域中工作的全景编辑框架，通过生成-编辑范式和几何感知学习策略，解决了现有方法在几何一致性和编辑保真度上的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基于透视的图像编辑方法无法建模全景图像的空间结构，传统的立方体贴图分解方法因与球面几何不匹配而破坏全局一致性。

Method: 采用生成-编辑范式，通过可控全景生成合成多样化的配对示例，用于监督编辑学习，并引入几何感知学习策略，显式强化位置感知形状监督，隐式内化全景先验。

Result: 在PEBench基准测试中，World-Shaper在几何一致性、编辑保真度和文本可控性方面优于现有方法。

Conclusion: World-Shaper在PEBench基准测试中表现出色，实现了几何一致性、编辑保真度和文本可控性的显著提升，为360°视觉世界创建提供了统一且灵活的编辑控制。

Abstract: Being able to edit panoramic images is crucial for creating realistic 360° visual experiences. However, existing perspective-based image editing methods fail to model the spatial structure of panoramas. Conventional cube-map decompositions attempt to overcome this problem but inevitably break global consistency due to their mismatch with spherical geometry. Motivated by this insight, we reformulate panoramic editing directly in the equirectangular projection (ERP) domain and present World-Shaper, a unified geometry-aware framework that bridges panoramic generation and editing within a single editing-centric design. To overcome the scarcity of paired data, we adopt a generate-then-edit paradigm, where controllable panoramic generation serves as an auxiliary stage to synthesize diverse paired examples for supervised editing learning. To address geometric distortion, we introduce a geometry-aware learning strategy that explicitly enforces position-aware shape supervision and implicitly internalizes panoramic priors through progressive training. Extensive experiments on our new benchmark, PEBench, demonstrate that our method achieves superior geometric consistency, editing fidelity, and text controllability compared to SOTA methods, enabling coherent and flexible 360° visual world creation with unified editing control. Code, model, and data will be released at our project page: https://world-shaper-project.github.io/

</details>


### [44] [PLACID: Identity-Preserving Multi-Object Compositing via Video Diffusion with Synthetic Trajectories](https://arxiv.org/abs/2602.00267)
*Gemma Canet Tarrés,Manel Baradad,Francesc Moreno-Noguer,Yumeng Li*

Main category: cs.CV

TL;DR: PLACID是一种新框架，通过I2V扩散模型和合成数据训练，解决了多对象合成中的身份保持和布局问题，效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前生成式AI在工作室级多对象合成任务中表现不足，常导致对象细节改变、遗漏或重复，以及布局和展示不一致的问题。

Method: 利用预训练的I2V扩散模型和文本控制来保持对象一致性和背景细节，同时提出了一种新颖的数据整理策略，生成合成序列以训练模型。

Result: PLACID在定量评估和用户研究中表现优异，实现了对象身份、背景和色彩的精准保持，并生成了连贯的布局。

Conclusion: PLACID框架在多项指标上超越了现有最先进方法，实现了更优的对象身份、背景和色彩保持，减少了对象遗漏，并生成了视觉上吸引人的多对象合成效果。

Abstract: Recent advances in generative AI have dramatically improved photorealistic image synthesis, yet they fall short for studio-level multi-object compositing. This task demands simultaneous (i) near-perfect preservation of each item's identity, (ii) precise background and color fidelity, (iii) layout and design elements control, and (iv) complete, appealing displays showcasing all objects. However, current state-of-the-art models often alter object details, omit or duplicate objects, and produce layouts with incorrect relative sizing or inconsistent item presentations. To bridge this gap, we introduce PLACID, a framework that transforms a collection of object images into an appealing multi-object composite. Our approach makes two main contributions. First, we leverage a pretrained image-to-video (I2V) diffusion model with text control to preserve objects consistency, identities, and background details by exploiting temporal priors from videos. Second, we propose a novel data curation strategy that generates synthetic sequences where randomly placed objects smoothly move to their target positions. This synthetic data aligns with the video model's temporal priors during training. At inference, objects initialized at random positions consistently converge into coherent layouts guided by text, with the final frame serving as the composite image. Extensive quantitative evaluations and user studies demonstrate that PLACID surpasses state-of-the-art methods in multi-object compositing, achieving superior identity, background, and color preservation, with less omitted objects and visually appealing results.

</details>


### [45] [TokenTrim: Inference-Time Token Pruning for Autoregressive Long Video Generation](https://arxiv.org/abs/2602.00268)
*Ariel Shaulov,Eitan Shaar,Amit Edenzon,Lior Wolf*

Main category: cs.CV

TL;DR: 提出一种推理时方法，通过移除不稳定的潜在标记来减少自回归视频生成中的时间漂移，提升长序列一致性。


<details>
  <summary>Details</summary>
Motivation: 自回归视频生成在长序列合成中因误差累积导致严重的时间漂移，作者认为这主要源于推理时对损坏潜在标记的重复使用。

Method: 提出了一种简单的推理时方法，通过识别和移除不稳定的潜在标记（即与先前生成批次显著偏离的标记）来减少误差传播。

Result: 该方法显著改善了长序列的时间一致性，且不涉及模型架构或训练过程的修改。

Conclusion: 该方法通过识别并移除不稳定的潜在标记，有效减少了自回归视频生成中的时间漂移问题，显著提升了长序列的时间一致性，且无需修改模型架构或训练过程。

Abstract: Auto-regressive video generation enables long video synthesis by iteratively conditioning each new batch of frames on previously generated content. However, recent work has shown that such pipelines suffer from severe temporal drift, where errors accumulate and amplify over long horizons. We hypothesize that this drift does not primarily stem from insufficient model capacity, but rather from inference-time error propagation. Specifically, we contend that drift arises from the uncontrolled reuse of corrupted latent conditioning tokens during auto-regressive inference. To correct this accumulation of errors, we propose a simple, inference-time method that mitigates temporal drift by identifying and removing unstable latent tokens before they are reused for conditioning. For this purpose, we define unstable tokens as latent tokens whose representations deviate significantly from those of the previously generated batch, indicating potential corruption or semantic drift. By explicitly removing corrupted latent tokens from the auto-regressive context, rather than modifying entire spatial regions or model parameters, our method prevents unreliable latent information from influencing future generation steps. As a result, it significantly improves long-horizon temporal consistency without modifying the model architecture, training procedure, or leaving latent space.

</details>


### [46] [TimeBlind: A Spatio-Temporal Compositionality Benchmark for Video LLMs](https://arxiv.org/abs/2602.00288)
*Baiqi Li,Kangyi Zhao,Ce Zhang,Chancharik Mitra,Jean de Dieu Nyandwi,Gedas Bertasius*

Main category: cs.CV

TL;DR: TimeBlind是一个诊断基准，用于评估多模态大语言模型在细粒度时空理解上的能力，结果显示当前模型依赖静态视觉捷径而非真正的时空逻辑。


<details>
  <summary>Details</summary>
Motivation: 细粒度的时空理解对视频推理和具身AI至关重要，但目前多模态大语言模型在静态语义上表现优异，而对时间动态的掌握仍显脆弱。

Method: TimeBlind采用了最小对范式，视频对共享相同的静态视觉内容但仅在时间结构上有所不同，通过互补问题来消除语言先验。

Result: 评估了20多个最先进的多模态大语言模型（如GPT-5、Gemini 3 Pro），在600个精选实例（2400个视频-问题对）上，表现最佳的模型的实例准确率仅为48.2%，远低于人类表现（98.2%）。

Conclusion: TimeBlind是一个重要的诊断工具，用于评估下一代视频理解模型的时空逻辑能力，揭示了当前最先进的多模态大语言模型在时空动态理解上的不足。

Abstract: Fine-grained spatio-temporal understanding is essential for video reasoning and embodied AI. Yet, while Multimodal Large Language Models (MLLMs) master static semantics, their grasp of temporal dynamics remains brittle. We present TimeBlind, a diagnostic benchmark for compositional spatio-temporal understanding. Inspired by cognitive science, TimeBlind categorizes fine-grained temporal understanding into three levels: recognizing atomic events, characterizing event properties, and reasoning about event interdependencies. Unlike benchmarks that conflate recognition with temporal reasoning, TimeBlind leverages a minimal-pairs paradigm: video pairs share identical static visual content but differ solely in temporal structure, utilizing complementary questions to neutralize language priors. Evaluating over 20 state-of-the-art MLLMs (e.g., GPT-5, Gemini 3 Pro) on 600 curated instances (2400 video-question pairs), reveals that the Instance Accuracy (correctly distinguishing both videos in a pair) of the best performing MLLM is only 48.2%, far below the human performance (98.2%). These results demonstrate that even frontier models rely heavily on static visual shortcuts rather than genuine temporal logic, positioning TimeBlind as a vital diagnostic tool for next-generation video understanding. Dataset and code are available at https://baiqi-li.github.io/timeblind_project/ .

</details>


### [47] [Computer Vision and Its Relationship to Cognitive Science: A perspective from Bayes Decision Theory](https://arxiv.org/abs/2602.00289)
*Alan Yuille,Daniel Kersten*

Main category: cs.CV

TL;DR: 本文通过贝叶斯决策理论（BDT）分析了计算机视觉与认知科学的关系，探讨了贝叶斯和深度神经网络方法的优缺点，并指出了BDT的局限性和未来结合的方向。


<details>
  <summary>Details</summary>
Motivation: 计算机视觉是一个广阔而复杂的领域，本文旨在通过BDT提供一个理论视角，捕捉其关键概念，并探讨两种主要方法的优缺点及其结合的可能性。

Method: 使用贝叶斯决策理论（BDT）作为理论框架，分析了贝叶斯观点和深度神经网络方法在计算机视觉中的应用。

Result: BDT框架能够涵盖贝叶斯观点和深度神经网络方法，并揭示它们的优缺点，同时指出了BDT的局限性，为未来更丰富的框架提供了方向。

Conclusion: 本文通过贝叶斯决策理论（BDT）的视角，探讨了计算机视觉与认知科学的关系，并指出了BDT框架的局限性，为两种方法的结合提供了方向。

Abstract: This document presents an introduction to computer vision, and its relationship to Cognitive Science, from the perspective of Bayes Decision Theory (Berger 1985). Computer vision is a vast and complex field, so this overview has a narrow scope and provides a theoretical lens which captures many key concepts. BDT is rich enough to include two different approaches: (i) the Bayesian viewpoint, which gives a conceptually attractive framework for vision with concepts that resonate with Cognitive Science (Griffiths et al., 2024), and (ii) the Deep Neural Network approach whose successes in the real world have made Computer Vision into a trillion-dollar industry and which is motivated by the hierarchical structure of the visual ventral stream. The BDT framework relates and captures the strengths and weakness of these two approaches and, by discussing the limitations of BDT, points the way to how they can be combined in a richer framework.

</details>


### [48] [LogicGaze: Benchmarking Causal Consistency in Visual Narratives via Counterfactual Verification](https://arxiv.org/abs/2602.00292)
*Rory Driscoll,Alexandros Christoforos,Chadbourne Davis*

Main category: cs.CV

TL;DR: LogicGaze是一个新基准框架，用于测试视觉语言模型验证序列因果链的能力，揭示了现有模型的漏洞，并倡导更可靠的多模态推理。


<details>
  <summary>Details</summary>
Motivation: 探索视觉语言模型（VLMs）在复杂多模态任务中基于实际视觉证据验证序列推理链的可靠性，特别是针对幻觉问题。

Method: 通过从ShareGPT4Video和Flickr30k中精选的40,000个视频片段和图像子集，LogicGaze整合了因果序列与视觉上矛盾但语言上合理的扰动，迫使模型验证每个推理步骤的真实性。

Result: LogicGaze的三部分评估协议（因果验证、基础叙事合成和扰动拒绝）暴露了当前最先进VLMs的显著漏洞。

Conclusion: LogicGaze框架揭示了当前最先进的视觉语言模型（如Qwen2.5-VL-72B）在验证序列因果链时的显著漏洞，并倡导构建更可靠、可信的多模态推理系统。

Abstract: While sequential reasoning enhances the capability of Vision-Language Models (VLMs) to execute complex multimodal tasks, their reliability in grounding these reasoning chains within actual visual evidence remains insufficiently explored. We introduce LogicGaze, a novel benchmark framework designed to rigorously interrogate whether VLMs can validate sequential causal chains against visual inputs, specifically targeting the pervasive issue of hallucination. Curated from 40,000 video segments from ShareGPT4Video and a subset of Flickr30k imagery, LogicGaze integrates causal sequences with visually contradictory yet linguistically plausible perturbations, compelling models to verify the authenticity of each reasoning step. Our tripartite evaluation protocol - Causal Validation, Grounded Narrative Synthesis, and Perturbation Rejection - exposes significant vulnerabilities in state-of-the-art VLMs such as Qwen2.5-VL-72B. LogicGaze advocates for robust, trustworthy multimodal reasoning, with all resources publicly available in an anonymized repository.

</details>


### [49] [Opportunistic Promptable Segmentation: Leveraging Routine Radiological Annotations to Guide 3D CT Lesion Segmentation](https://arxiv.org/abs/2602.00309)
*Samuel Church,Joshua D. Warner,Danyal Maqbool,Xin Tie,Junjie Hu,Meghan G. Lubner,Tyler J. Bradshaw*

Main category: cs.CV

TL;DR: SAM2CT是一种新型可提示分割模型，能将放射科医生的稀疏注释转化为3D分割，显著降低标注成本，并在临床应用中表现优异。


<details>
  <summary>Details</summary>
Motivation: 尽管PACS中存储了大量CT图像和报告，但获取3D分割标注成本高昂，而放射科医生在常规阅读中提供的有限注释（如线条测量和箭头）可能被利用。

Method: 提出了SAM2CT模型，通过扩展提示编码器以支持箭头和线条输入，并引入专门针对3D医学体积的内存编码策略（MCM）。

Result: SAM2CT在公共病变分割基准测试中表现优于现有可提示分割模型，Dice相似系数分别为箭头提示0.649和线条提示0.757。在临床PACS中，87%的案例生成的3D分割被放射科医生评为临床可接受或仅需轻微调整。

Conclusion: 大规模挖掘历史GSPS注释是一种有前景且可扩展的方法，用于生成3D CT分割数据集。

Abstract: The development of machine learning models for CT imaging depends on the availability of large, high-quality, and diverse annotated datasets. Although large volumes of CT images and reports are readily available in clinical picture archiving and communication systems (PACS), 3D segmentations of critical findings are costly to obtain, typically requiring extensive manual annotation by radiologists. On the other hand, it is common for radiologists to provide limited annotations of findings during routine reads, such as line measurements and arrows, that are often stored in PACS as GSPS objects. We posit that these sparse annotations can be extracted along with CT volumes and converted into 3D segmentations using promptable segmentation models, a paradigm we term Opportunistic Promptable Segmentation. To enable this paradigm, we propose SAM2CT, the first promptable segmentation model designed to convert radiologist annotations into 3D segmentations in CT volumes. SAM2CT builds upon SAM2 by extending the prompt encoder to support arrow and line inputs and by introducing Memory-Conditioned Memories (MCM), a memory encoding strategy tailored to 3D medical volumes. On public lesion segmentation benchmarks, SAM2CT outperforms existing promptable segmentation models and similarly trained baselines, achieving Dice similarity coefficients of 0.649 for arrow prompts and 0.757 for line prompts. Applying the model to pre-existing GSPS annotations from a clinical PACS (N = 60), SAM2CT generates 3D segmentations that are clinically acceptable or require only minor adjustments in 87% of cases, as scored by radiologists. Additionally, SAM2CT demonstrates strong zero-shot performance on select Emergency Department findings. These results suggest that large-scale mining of historical GSPS annotations represents a promising and scalable approach for generating 3D CT segmentation datasets.

</details>


### [50] [On the Assessment of Sensitivity of Autonomous Vehicle Perception](https://arxiv.org/abs/2602.00314)
*Apostol Vassilev,Munawar Hasan,Edward Griffor,Honglan Jin,Pavel Piliptchak,Mahima Arora,Thoshitha Gamage*

Main category: cs.CV

TL;DR: 研究评估自动驾驶感知系统在恶劣条件下的鲁棒性，发现光照和遮挡是主要挑战，多模型集成方法有效量化性能下降。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶感知系统在自然和对抗性干扰下易产生错误和延迟，需评估其鲁棒性并探索提升可靠性的策略。

Method: 使用五种先进的计算机视觉模型（YOLO v8-v9、DETR50、DETR101、RT-DETR），在模拟和真实驾驶场景中，基于模型分歧和推理变异性量化预测敏感性，提出感知评估标准和架构。

Result: 光照不足（如雾、低太阳高度）和道路遮挡对感知模型性能影响最大；恶劣天气与道路条件结合时性能进一步下降；距离道路物体越远，感知鲁棒性越差。

Conclusion: 自动驾驶的可行性高度依赖于感知系统的性能，需在理想和恶劣条件下均能提供实时、准确、可靠的信息。通过多模型集成评估感知性能，发现光照不足和道路遮挡对模型影响最大，且距离越远感知性能下降越显著。

Abstract: The viability of automated driving is heavily dependent on the performance of perception systems to provide real-time accurate and reliable information for robust decision-making and maneuvers. These systems must perform reliably not only under ideal conditions, but also when challenged by natural and adversarial driving factors. Both of these types of interference can lead to perception errors and delays in detection and classification. Hence, it is essential to assess the robustness of the perception systems of automated vehicles (AVs) and explore strategies for making perception more reliable. We approach this problem by evaluating perception performance using predictive sensitivity quantification based on an ensemble of models, capturing model disagreement and inference variability across multiple models, under adverse driving scenarios in both simulated environments and real-world conditions. A notional architecture for assessing perception performance is proposed. A perception assessment criterion is developed based on an AV's stopping distance at a stop sign on varying road surfaces, such as dry and wet asphalt, and vehicle speed. Five state-of-the-art computer vision models are used, including YOLO (v8-v9), DEtection TRansformer (DETR50, DETR101), Real-Time DEtection TRansformer (RT-DETR)in our experiments. Diminished lighting conditions, e.g., resulting from the presence of fog and low sun altitude, have the greatest impact on the performance of the perception models. Additionally, adversarial road conditions such as occlusions of roadway objects increase perception sensitivity and model performance drops when faced with a combination of adversarial road conditions and inclement weather conditions. Also, it is demonstrated that the greater the distance to a roadway object, the greater the impact on perception performance, hence diminished perception robustness.

</details>


### [51] [Bridging the Semantic Chasm: Synergistic Conceptual Anchoring for Generalized Few-Shot and Zero-Shot OOD Perception](https://arxiv.org/abs/2602.00340)
*Alexandros Christoforos,Sarah Jenkins,Michael Brown,Tuan Pham,David Chen*

Main category: cs.CV

TL;DR: SynerNet通过多智能体协同框架解决视觉语言模型在OOD概念上的跨模态对齐问题，实验显示性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 解决视觉语言模型在面对OOD概念时出现的跨模态对齐退化问题。

Method: 设计了四个专门的计算单元（视觉感知、语言上下文、名义嵌入和全局协调），通过结构化消息传播协议协同纠正模态差异。

Result: 在VISTA-Beyond基准测试中，SynerNet在少样本和零样本场景下均表现出显著性能提升，精度提高了1.2%至5.4%。

Conclusion: SynerNet框架通过多智能体协同工作有效缓解了视觉语言模型在OOD概念上的跨模态对齐退化问题，显著提升了模型在少样本和零样本场景下的性能。

Abstract: This manuscript presents a pioneering Synergistic Neural Agents Network (SynerNet) framework designed to mitigate the phenomenon of cross-modal alignment degeneration in Vision-Language Models (VLMs) when encountering Out-of-Distribution (OOD) concepts. Specifically, four specialized computational units - visual perception, linguistic context, nominal embedding, and global coordination - collaboratively rectify modality disparities via a structured message-propagation protocol. The principal contributions encompass a multi-agent latent space nomenclature acquisition framework, a semantic context-interchange algorithm for enhanced few-shot adaptation, and an adaptive dynamic equilibrium mechanism. Empirical evaluations conducted on the VISTA-Beyond benchmark demonstrate that SynerNet yields substantial performance augmentations in both few-shot and zero-shot scenarios, exhibiting precision improvements ranging from 1.2% to 5.4% across a diverse array of domains.

</details>


### [52] [When RAG Hurts: Diagnosing and Mitigating Attention Distraction in Retrieval-Augmented LVLMs](https://arxiv.org/abs/2602.00344)
*Beidi Zhao,Wenlong Deng,Xinting Liao,Yushu Li,Nazim Shaikh,Yao Nie,Xiaoxiao Li*

Main category: cs.CV

TL;DR: MAD-RAG通过双问题表述和注意力混合解决RAG中的注意力分散问题，显著提升性能且计算高效。


<details>
  <summary>Details</summary>
Motivation: 发现现有RAG方法因注意力分散（AD）导致失败模式，即在检索上下文充足时，检索文本会全局抑制视觉注意力，导致模型无法关注问题相关图像区域。

Method: 提出MAD-RAG，一种无需训练的干预方法，通过双问题表述解耦视觉基础与上下文集成，并结合注意力混合保留图像条件证据。

Result: 在OK-VQA、E-VQA和InfoSeek数据集上，MAD-RAG显著优于现有基线，绝对增益最高达4.76%、9.20%和6.18%，并能纠正高达74.68%的失败案例。

Conclusion: MAD-RAG通过解耦视觉基础与上下文集成，有效解决了注意力分散问题，显著提升了RAG在知识型VQA任务中的性能，且计算开销可忽略。

Abstract: While Retrieval-Augmented Generation (RAG) is one of the dominant paradigms for enhancing Large Vision-Language Models (LVLMs) on knowledge-based VQA tasks, recent work attributes RAG failures to insufficient attention towards the retrieved context, proposing to reduce the attention allocated to image tokens. In this work, we identify a distinct failure mode that previous study overlooked: Attention Distraction (AD). When the retrieved context is sufficient (highly relevant or including the correct answer), the retrieved text suppresses the visual attention globally, and the attention on image tokens shifts away from question-relevant regions. This leads to failures on questions the model could originally answer correctly without the retrieved text. To mitigate this issue, we propose MAD-RAG, a training-free intervention that decouples visual grounding from context integration through a dual-question formulation, combined with attention mixing to preserve image-conditioned evidence. Extensive experiments on OK-VQA, E-VQA, and InfoSeek demonstrate that MAD-RAG consistently outperforms existing baselines across different model families, yielding absolute gains of up to 4.76%, 9.20%, and 6.18% over the vanilla RAG baseline. Notably, MAD-RAG rectifies up to 74.68% of failure cases with negligible computational overhead.

</details>


### [53] [AdaFuse: Adaptive Multimodal Fusion for Lung Cancer Risk Prediction via Reinforcement Learning](https://arxiv.org/abs/2602.00347)
*Chongyu Qu,Zhengyi Lu,Yuxiang Lai,Thomas Z. Li,Junchao Zhu,Junlin Guo,Juming Xiong,Yanfan Zhu,Yuechen Yang,Allen J. Luna,Kim L. Sandler,Bennett A. Landman,Yuankai Huo*

Main category: cs.CV

TL;DR: AdaFuse是一种自适应多模态融合框架，通过强化学习实现患者特异性模态选择与融合，提升肺癌风险预测性能并减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有多模态融合方法对所有可用模态进行统一处理，未解决关键问题：针对特定患者，是否应使用某些模态？

Method: AdaFuse利用强化学习（RL）框架，通过策略网络迭代决定是否纳入额外模态或基于已获取信息进行预测，形成顺序决策过程。

Result: 在NLST数据集上，AdaFuse达到最高AUC（0.762），优于最佳单模态基线（0.732）、最佳固定融合策略（0.759）及自适应基线DynMM（0.754）和MoE（0.742），且计算量低于所有三模态方法。

Conclusion: AdaFuse展示了强化学习在医学影像个性化多模态融合中的潜力，标志着从统一融合策略向自适应诊断流程的转变，能够学习何时需要额外模态信息以及何时现有信息足以进行准确预测。

Abstract: Multimodal fusion has emerged as a promising paradigm for disease diagnosis and prognosis, integrating complementary information from heterogeneous data sources such as medical images, clinical records, and radiology reports. However, existing fusion methods process all available modalities through the network, either treating them equally or learning to assign different contribution weights, leaving a fundamental question unaddressed: for a given patient, should certain modalities be used at all? We present AdaFuse, an adaptive multimodal fusion framework that leverages reinforcement learning (RL) to learn patient-specific modality selection and fusion strategies for lung cancer risk prediction. AdaFuse formulates multimodal fusion as a sequential decision process, where the policy network iteratively decides whether to incorporate an additional modality or proceed to prediction based on the information already acquired. This sequential formulation enables the model to condition each selection on previously observed modalities and terminate early when sufficient information is available, rather than committing to a fixed subset upfront. We evaluate AdaFuse on the National Lung Screening Trial (NLST) dataset. Experimental results demonstrate that AdaFuse achieves the highest AUC (0.762) compared to the best single-modality baseline (0.732), the best fixed fusion strategy (0.759), and adaptive baselines including DynMM (0.754) and MoE (0.742), while using fewer FLOPs than all triple-modality methods. Our work demonstrates the potential of reinforcement learning for personalized multimodal fusion in medical imaging, representing a shift from uniform fusion strategies toward adaptive diagnostic pipelines that learn when to consult additional modalities and when existing information suffices for accurate prediction.

</details>


### [54] [MASC: Metal-Aware Sampling and Correction via Reinforcement Learning for Accelerated MRI](https://arxiv.org/abs/2602.00348)
*Zhengyi Lu,Ming Lu,Chongyu Qu,Junchao Zhu,Junlin Guo,Marilyn Lionts,Yanfan Zhu,Yuechen Yang,Tianyuan Yao,Jayasai Rajagopal,Bennett Allan Landman,Xiao Wang,Xinqiang Yan,Yuankai Huo*

Main category: cs.CV

TL;DR: MASC是一种联合优化金属伪影校正和加速MRI采集的强化学习框架，实验证明其性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统方法将金属伪影减少（MAR）和加速MRI采集视为独立问题，限制了性能提升。MASC旨在通过联合优化解决这一问题。

Method: 提出了一种基于强化学习的统一框架MASC，结合了金属感知k空间采样和伪影校正。使用物理模拟构建配对MRI数据集，通过PPO代理学习选择k空间相位编码线，并与U-Net基础的MAR网络协同训练。

Result: 实验表明，MASC的学习策略优于传统采样方法，端到端训练进一步提升了性能，且在FastMRI数据集上验证了泛化能力。

Conclusion: MASC框架通过联合优化金属感知k空间采样和伪影校正，显著提升了MRI图像质量，并在实验中验证了其优于传统采样策略的性能。

Abstract: Metal implants in MRI cause severe artifacts that degrade image quality and hinder clinical diagnosis. Traditional approaches address metal artifact reduction (MAR) and accelerated MRI acquisition as separate problems. We propose MASC, a unified reinforcement learning framework that jointly optimizes metal-aware k-space sampling and artifact correction for accelerated MRI. To enable supervised training, we construct a paired MRI dataset using physics-based simulation, generating k-space data and reconstructions for phantoms with and without metal implants. This paired dataset provides simulated 3D MRI scans with and without metal implants, where each metal-corrupted sample has an exactly matched clean reference, enabling direct supervision for both artifact reduction and acquisition policy learning. We formulate active MRI acquisition as a sequential decision-making problem, where an artifact-aware Proximal Policy Optimization (PPO) agent learns to select k-space phase-encoding lines under a limited acquisition budget. The agent operates on undersampled reconstructions processed through a U-Net-based MAR network, learning patterns that maximize reconstruction quality. We further propose an end-to-end training scheme where the acquisition policy learns to select k-space lines that best support artifact removal while the MAR network simultaneously adapts to the resulting undersampling patterns. Experiments demonstrate that MASC's learned policies outperform conventional sampling strategies, and end-to-end training improves performance compared to using a frozen pre-trained MAR network, validating the benefit of joint optimization. Cross-dataset experiments on FastMRI with physics-based artifact simulation further confirm generalization to realistic clinical MRI data. The code and models of MASC have been made publicly available: https://github.com/hrlblab/masc

</details>


### [55] [ReLAPSe: Reinforcement-Learning-trained Adversarial Prompt Search for Erased concepts in unlearned diffusion models](https://arxiv.org/abs/2602.00350)
*Ignacy Kolton,Kacper Marzol,Paweł Batorski,Marcin Mazur,Paul Swoboda,Przemysław Spurek*

Main category: cs.CV

TL;DR: ReLAPSe通过强化学习框架高效恢复未学习概念，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 现有的对抗方法存在计算成本高或缺乏目标模型潜在视觉表示的直接反馈的局限性，需要一种更高效、可扩展的方法来严格测试未学习的扩散模型。

Method: 引入ReLAPSe，一个基于策略的对抗框架，将概念恢复重新定义为强化学习问题，利用扩散模型的噪声预测损失作为模型内在且可验证的反馈信号。

Result: ReLAPSe在多个最先进的未学习方法上实现了高效、近实时的细粒度身份和风格恢复。

Conclusion: ReLAPSe通过强化学习框架有效解决了现有对抗方法在恢复未学习概念时的局限性，实现了高效、近实时的细粒度身份和风格恢复。

Abstract: Machine unlearning is a key defense mechanism for removing unauthorized concepts from text-to-image diffusion models, yet recent evidence shows that latent visual information often persists after unlearning. Existing adversarial approaches for exploiting this leakage are constrained by fundamental limitations: optimization-based methods are computationally expensive due to per-instance iterative search. At the same time, reasoning-based and heuristic techniques lack direct feedback from the target model's latent visual representations. To address these challenges, we introduce ReLAPSe, a policy-based adversarial framework that reformulates concept restoration as a reinforcement learning problem. ReLAPSe trains an agent using Reinforcement Learning with Verifiable Rewards (RLVR), leveraging the diffusion model's noise prediction loss as a model-intrinsic and verifiable feedback signal. This closed-loop design directly aligns textual prompt manipulation with latent visual residuals, enabling the agent to learn transferable restoration strategies rather than optimizing isolated prompts. By pioneering the shift from per-instance optimization to global policy learning, ReLAPSe achieves efficient, near-real-time recovery of fine-grained identities and styles across multiple state-of-the-art unlearning methods, providing a scalable tool for rigorous red-teaming of unlearned diffusion models. Some experimental evaluations involve sensitive visual concepts, such as nudity. Code is available at https://github.com/gmum/ReLaPSe

</details>


### [56] [Modeling Image-Caption Rating from Comparative Judgments](https://arxiv.org/abs/2602.00381)
*Kezia Minni,Qiang Zhang,Monoshiz Mahbub Khan,Zhe Yu*

Main category: cs.CV

TL;DR: 比较学习模型通过人类更容易的成对比较替代直接评分，有效降低标注成本，性能接近回归模型。


<details>
  <summary>Details</summary>
Motivation: 直接评分图像描述的准确性耗时且主观，而比较两个描述哪个更匹配图像则更容易。

Method: 使用VICR数据集，提取ResNet-50的视觉特征和MiniLM的文本特征，训练回归模型和比较学习模型。

Result: 回归模型表现更好（Pearson's ρ: 0.7609，Spearman's rs: 0.7089），但比较学习模型随数据增加逐步接近回归基线。小规模人工评估显示比较标注更快且标注者间一致性更高。

Conclusion: 比较学习可以有效建模人类偏好，同时显著降低人工标注成本。

Abstract: Rating the accuracy of captions in describing images is time-consuming and subjective for humans. In contrast, it is often easier for people to compare two captions and decide which one better matches a given image. In this work, we propose a machine learning framework that models such comparative judgments instead of direct ratings. The model can then be applied to rank unseen image-caption pairs in the same way as a regression model trained on direct ratings. Using the VICR dataset, we extract visual features with ResNet-50 and text features with MiniLM, then train both a regression model and a comparative learning model. While the regression model achieves better performance (Pearson's $ρ$: 0.7609 and Spearman's $r_s$: 0.7089), the comparative learning model steadily improves with more data and approaches the regression baseline. In addition, a small-scale human evaluation study comparing absolute rating, pairwise comparison, and same-image comparison shows that comparative annotation yields faster results and has greater agreement among human annotators. These results suggest that comparative learning can effectively model human preferences while significantly reducing the cost of human annotations.

</details>


### [57] [Deep Learning-Based Object Detection for Autonomous Vehicles: A Comparative Study of One-Stage and Two-Stage Detectors on Basic Traffic Objects](https://arxiv.org/abs/2602.00385)
*Bsher Karbouj,Adam Michael Altenbuchner,Joerg Krueger*

Main category: cs.CV

TL;DR: 研究比较了YOLOv5和Faster R-CNN在自动驾驶物体检测中的性能，发现YOLOv5在大数据和分辨率下更优，Faster R-CNN在小物体和复杂光照下表现更好。


<details>
  <summary>Details</summary>
Motivation: 自动驾驶系统中，物体检测是关键组件，但现有深度学习架构（如YOLO、SSD、Faster R-CNN）在特定应用中的适用性指导有限，选择方法对系统性能影响显著。

Method: 本研究通过实验分析比较了YOLOv5（单阶段检测器）和Faster R-CNN（双阶段检测器）的性能，使用了结合真实和合成图像的多样化数据集，评估指标包括mAP、召回率和推理速度。

Result: YOLOv5在mAP、召回率和训练效率上表现更优，尤其在数据规模和分辨率增加时；Faster R-CNN在检测小物体和复杂光照条件下更具优势。

Conclusion: YOLOv5在mAP、召回率和训练效率方面表现更优，尤其在数据集规模和图像分辨率增加时；而Faster R-CNN在检测小且远的物体及复杂光照条件下表现更好。

Abstract: Object detection is a crucial component in autonomous vehicle systems. It enables the vehicle to perceive and understand its environment by identifying and locating various objects around it. By utilizing advanced imaging and deep learning techniques, autonomous vehicle systems can rapidly and accurately identify objects based on their features. Different deep learning methods vary in their ability to accurately detect and classify objects in autonomous vehicle systems. Selecting the appropriate method significantly impacts system performance, robustness, and efficiency in real-world driving scenarios. While several generic deep learning architectures like YOLO, SSD, and Faster R-CNN have been proposed, guidance on their suitability for specific autonomous driving applications is often limited. The choice of method affects detection accuracy, processing speed, environmental robustness, sensor integration, scalability, and edge case handling. This study provides a comprehensive experimental analysis comparing two prominent object detection models: YOLOv5 (a one-stage detector) and Faster R-CNN (a two-stage detector). Their performance is evaluated on a diverse dataset combining real and synthetic images, considering various metrics including mean Average Precision (mAP), recall, and inference speed. The findings reveal that YOLOv5 demonstrates superior performance in terms of mAP, recall, and training efficiency, particularly as dataset size and image resolution increase. However, Faster R-CNN shows advantages in detecting small, distant objects and performs well in challenging lighting conditions. The models' behavior is also analyzed under different confidence thresholds and in various real-world scenarios, providing insights into their applicability for autonomous driving systems.

</details>


### [58] [Robust automatic brain vessel segmentation in 3D CTA scans using dynamic 4D-CTA data](https://arxiv.org/abs/2602.00391)
*Alberto Mario Ceballos-Arroyo,Shrikanth M. Yadav,Chu-Hsuan Lin,Jisoo Kim,Geoffrey S. Young,Huaizu Jiang,Lei Qin*

Main category: cs.CV

TL;DR: 提出动态4D-CTA标注方法，通过深度学习显著提升脑血管分割准确性，公开数据集验证效果优越。


<details>
  <summary>Details</summary>
Motivation: 减少手动标注脑血管的工作量，提升血管分割的准确性和鲁棒性。

Method: 利用动态CTA采集的多个时间点数据，通过减除骨骼和软组织增强血管可视化，并利用同一分割标注扩展数据集4至5倍，训练深度学习模型。

Result: 在TopBrain数据集中，动脉和静脉的平均mDC分别达到0.846和0.957，误差和拓扑敏感性指标均表现优异。

Conclusion: 本研究提出了一种新颖的动态4D-CTA头部扫描标注方法，通过深度学习模型显著提升了脑血管分割的准确性和鲁棒性，并在公开数据集上验证了其优越性能。

Abstract: In this study, we develop a novel methodology for annotating the brain vasculature using dynamic 4D-CTA head scans. By using multiple time points from dynamic CTA acquisitions, we subtract bone and soft tissue to enhance the visualization of arteries and veins, reducing the effort required to obtain manual annotations of brain vessels. We then train deep learning models on our ground truth annotations by using the same segmentation for multiple phases from the dynamic 4D-CTA collection, effectively enlarging our dataset by 4 to 5 times and inducing robustness to contrast phases. In total, our dataset comprises 110 training images from 25 patients and 165 test images from 14 patients. In comparison with two similarly-sized datasets for CTA-based brain vessel segmentation, a nnUNet model trained on our dataset can achieve significantly better segmentations across all vascular regions, with an average mDC of 0.846 for arteries and 0.957 for veins in the TopBrain dataset. Furthermore, metrics such as average directed Hausdorff distance (adHD) and topology sensitivity (tSens) reflected similar trends: using our dataset resulted in low error margins (aDHD of 0.304 mm for arteries and 0.078 for veins) and high sensitivity (tSens of 0.877 for arteries and 0.974 for veins), indicating excellent accuracy in capturing vessel morphology. Our code and model weights are available online: https://github.com/alceballosa/robust-vessel-segmentation

</details>


### [59] [Brazilian Portuguese Image Captioning with Transformers: A Study on Cross-Native-Translated Dataset](https://arxiv.org/abs/2602.00393)
*Gabriel Bromonschenkel,Alessandro L. Koerich,Thiago M. Paixão,Hilário Tomaz Alves de Oliveira*

Main category: cs.CV

TL;DR: 研究评估巴西葡萄牙语图像描述模型，Swin-DistilBERTimbau表现最佳，ViTucano优于大模型，GPT-4图像对齐最优，注意力分析揭示偏见。


<details>
  <summary>Details</summary>
Motivation: 解决巴西葡萄牙语等低资源语言在图像描述任务中因缺乏专业数据集和模型而面临的挑战。

Method: 使用Flickr30K数据集的手动标注和自动翻译版本进行跨上下文评估，结合注意力映射和CLIP-Score指标。

Result: Swin-DistilBERTimbau表现最优，ViTucano在文本指标上优于大模型，GPT-4在图像-文本对齐上最佳。注意力分析显示系统性偏见。

Conclusion: 本研究通过跨原生翻译评估Transformer视觉语言模型在巴西葡萄牙语图像描述任务中的表现，发现Swin-DistilBERTimbau模型表现最佳，ViTucano在传统文本评估指标上优于多语言大模型，而GPT-4在图像-文本对齐方面表现最优。注意力分析揭示了系统性偏见。

Abstract: Image captioning (IC) refers to the automatic generation of natural language descriptions for images, with applications ranging from social media content generation to assisting individuals with visual impairments. While most research has been focused on English-based models, low-resource languages such as Brazilian Portuguese face significant challenges due to the lack of specialized datasets and models. Several studies create datasets by automatically translating existing ones to mitigate resource scarcity. This work addresses this gap by proposing a cross-native-translated evaluation of Transformer-based vision and language models for Brazilian Portuguese IC. We use a version of Flickr30K comprised of captions manually created by native Brazilian Portuguese speakers and compare it to a version with captions automatically translated from English to Portuguese. The experiments include a cross-context approach, where models trained on one dataset are tested on the other to assess the translation impact. Additionally, we incorporate attention maps for model inference interpretation and use the CLIP-Score metric to evaluate the image-description alignment. Our findings show that Swin-DistilBERTimbau consistently outperforms other models, demonstrating strong generalization across datasets. ViTucano, a Brazilian Portuguese pre-trained VLM, surpasses larger multilingual models (GPT-4o, LLaMa 3.2 Vision) in traditional text-based evaluation metrics, while GPT-4 models achieve the highest CLIP-Score, highlighting improved image-text alignment. Attention analysis reveals systematic biases, including gender misclassification, object enumeration errors, and spatial inconsistencies. The datasets and the models generated and analyzed during the current study are available in: https://github.com/laicsiifes/transformer-caption-ptbr.

</details>


### [60] [Modeling Art Evaluations from Comparative Judgments: A Deep Learning Approach to Predicting Aesthetic Preferences](https://arxiv.org/abs/2602.00394)
*Manoj Reddy Bethi,Sai Rupa Jhade,Pravallika Yaganti,Monoshiz Mahbub Khan,Zhe Yu*

Main category: cs.CV

TL;DR: 该论文提出用成对比较学习降低审美判断标注成本，深度模型显著优于基线，成对比较高效但个体偏好预测难。


<details>
  <summary>Details</summary>
Motivation: 人类审美判断建模面临个体偏好差异大和标注数据获取成本高的挑战。

Method: 使用ResNet-50提取绘画图像的深度卷积特征，开发了深度神经网络回归模型和双分支成对比较模型。

Result: 深度回归模型比基线模型提升了328%的R²，成对比较模型在无法获取直接评分时接近回归性能，但个体偏好预测仍具挑战性。成对比较的标注时间比直接评分减少60%。

Conclusion: 该研究通过比较学习框架显著降低了获取人类审美判断标签的成本，验证了成对比较方法的实用性和高效性。

Abstract: Modeling human aesthetic judgments in visual art presents significant challenges due to individual preference variability and the high cost of obtaining labeled data. To reduce cost of acquiring such labels, we propose to apply a comparative learning framework based on pairwise preference assessments rather than direct ratings. This approach leverages the Law of Comparative Judgment, which posits that relative choices exhibit less cognitive burden and greater cognitive consistency than direct scoring. We extract deep convolutional features from painting images using ResNet-50 and develop both a deep neural network regression model and a dual-branch pairwise comparison model. We explored four research questions: (RQ1) How does the proposed deep neural network regression model with CNN features compare to the baseline linear regression model using hand-crafted features? (RQ2) How does pairwise comparative learning compare to regression-based prediction when lacking access to direct rating values? (RQ3) Can we predict individual rater preferences through within-rater and cross-rater analysis? (RQ4) What is the annotation cost trade-off between direct ratings and comparative judgments in terms of human time and effort? Our results show that the deep regression model substantially outperforms the baseline, achieving up to $328\%$ improvement in $R^2$. The comparative model approaches regression performance despite having no access to direct rating values, validating the practical utility of pairwise comparisons. However, predicting individual preferences remains challenging, with both within-rater and cross-rater performance significantly lower than average rating prediction. Human subject experiments reveal that comparative judgments require $60\%$ less annotation time per item, demonstrating superior annotation efficiency for large-scale preference modeling.

</details>


### [61] [3DGS$^2$-TR: Scalable Second-Order Trust-Region Method for 3D Gaussian Splatting](https://arxiv.org/abs/2602.00395)
*Roger Hsiao,Yuchen Fang,Xiangru Huang,Ruilong Li,Hesam Rabeti,Zan Gojcic,Javad Lavaei,James Demmel,Sophia Shao*

Main category: cs.CV

TL;DR: 3DGS$^2$-TR是一种高效二阶优化器，通过Hessian对角线近似和信任区域技术，显著减少3DGS训练迭代和内存开销。


<details>
  <summary>Details</summary>
Motivation: 现有的二阶优化方法（如3DGS-LM或3DGS2）依赖显式或密集曲率表示，计算和内存开销较大。3DGS$^2$-TR旨在通过更高效的曲率近似方法，提升训练效率并降低资源消耗。

Method: 该方法通过Hutchinson方法近似Hessian矩阵的对角线来估计曲率，完全无矩阵操作，计算和内存复杂度与ADAM相同（$O(n)$）。此外，引入了基于平方Hellinger距离的参数级信任区域技术，以稳定优化过程。

Result: 在相同参数初始化和无密度化条件下，3DGS$^2$-TR在标准数据集上实现了更好的重建质量，训练迭代次数减少50%，峰值GPU内存开销低于1GB。

Conclusion: 3DGS$^2$-TR在3D高斯泼溅（3DGS）场景训练中，通过二阶优化器显著提升了训练效率，减少了50%的训练迭代次数，同时保持了较低的GPU内存开销（仅比ADAM多17%，比3DGS-LM少85%），适用于大规模场景和分布式训练。

Abstract: We propose 3DGS$^2$-TR,a second-order optimizer for accelerating the scene training problem in 3D Gaussian Splatting (3DGS). Unlike existing second-order approaches that rely on explicit or dense curvature representations, such as 3DGS-LM (Höllein et al., 2025) or 3DGS2 (Lan et al., 2025), our method approximates curvature using only the diagonal of the Hessian matrix, efficiently via Hutchinson's method. Our approach is fully matrix-free and has the same complexity as ADAM (Kingma, 2024), $O(n)$ in both computation and memory costs. To ensure stable optimization in the presence of strong nonlinearity in the 3DGS rasterization process, we introduce a parameter-wise trust-region technique based on the squared Hellinger distance, regularizing updates to Gaussian parameters. Under identical parameter initialization and without densification, 3DGS$^2$-TR is able to achieve better reconstruction quality on standard datasets, using 50% fewer training iterations compared to ADAM, while incurring less than 1GB of peak GPU memory overhead (17% more than ADAM and 85% less than 3DGS-LM), enabling scalability to very large scenes and potentially to distributed training settings.

</details>


### [62] [Toward Autonomous Laboratory Safety Monitoring with Vision Language Models: Learning to See Hazards Through Scene Structure](https://arxiv.org/abs/2602.00414)
*Trishna Chakraborty,Udita Ghosh,Aldair Ernesto Gongora,Ruben Glatt,Yue Dong,Jiachen Li,Amit K. Roy-Chowdhury,Chengyu Song*

Main category: cs.CV

TL;DR: 研究通过生成合成数据集和提出场景图引导对齐方法，提升了视觉语言模型在实验室安全监测中的纯视觉性能。


<details>
  <summary>Details</summary>
Motivation: 实验室因轻微不安全行为可能导致严重伤害，但持续的安全监测受限于人力资源。视觉语言模型在自主实验室安全监测中具有潜力，但由于缺乏视觉评估数据，其在真实环境中的有效性尚不明确。

Method: 研究首先引入了一个结构化数据生成流程，将文本实验室场景转换为对齐的三元组（图像、场景图、真实情况），利用大型语言模型作为场景图架构师和图像生成模型作为渲染器。随后，通过合成数据集对七种开源和闭源模型进行实验，并提出场景图引导对齐的后训练方法。

Result: 实验结果表明，视觉语言模型在给定文本场景图时表现良好，但在纯视觉环境中性能显著下降，表明其难以直接从像素提取结构化对象关系。提出的场景图引导对齐方法有效提升了危险检测性能。

Conclusion: 通过提出场景图引导对齐的后训练方法，研究成功提升了视觉语言模型在纯视觉环境中的危险检测性能，弥补了其在直接从像素提取结构化对象关系时的不足。

Abstract: Laboratories are prone to severe injuries from minor unsafe actions, yet continuous safety monitoring -- beyond mandatory pre-lab safety training -- is limited by human availability. Vision language models (VLMs) offer promise for autonomous laboratory safety monitoring, but their effectiveness in realistic settings is unclear due to the lack of visual evaluation data, as most safety incidents are documented primarily as unstructured text. To address this gap, we first introduce a structured data generation pipeline that converts textual laboratory scenarios into aligned triples of (image, scene graph, ground truth), using large language models as scene graph architects and image generation models as renderers. Our experiments on the synthetic dataset of 1,207 samples across 362 unique scenarios and seven open- and closed-source models show that VLMs perform effectively given textual scene graph, but degrade substantially in visual-only settings indicating difficulty in extracting structured object relationships directly from pixels. To overcome this, we propose a post-training context-engineering approach, scene-graph-guided alignment, to bridge perceptual gaps in VLMs by translating visual inputs into structured scene graphs better aligned with VLM reasoning, improving hazard detection performance in visual only settings.

</details>


### [63] [Text is All You Need for Vision-Language Model Jailbreaking](https://arxiv.org/abs/2602.00420)
*Yihang Chen,Zhao Xu,Youyuan Jiang,Tianle Zheng,Cho-Jui Hsieh*

Main category: cs.CV

TL;DR: Text-DJ是一种新型越狱攻击，通过利用LVLMs的OCR能力，将有害查询分解并分散在无关查询中，成功绕过安全防护，暴露了模型对碎片化多模态输入的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有LVLMs的安全防护主要针对显式文本输入或相关视觉场景，而忽视了通过OCR能力发起的攻击。本文旨在揭示这一漏洞。

Method: 通过三个阶段的方法：1. 将有害查询分解为多个语义相关但更良性的子查询；2. 选择一组与有害查询最大程度无关的干扰查询；3. 将所有子查询和干扰查询作为图像网格同时呈现给LVLM，子查询位于网格中间。

Result: 该方法成功绕过了最先进LVLMs的安全对齐，展示了OCR能力在面对分散、多图像对抗输入时的脆弱性。

Conclusion: 本文揭示了大型视觉语言模型（LVLMs）在光学字符识别（OCR）能力上的关键漏洞，指出其对分散、多图像对抗输入的鲁棒性不足，强调了针对碎片化多模态输入防御的必要性。

Abstract: Large Vision-Language Models (LVLMs) are increasingly equipped with robust safety safeguards to prevent responses to harmful or disallowed prompts. However, these defenses often focus on analyzing explicit textual inputs or relevant visual scenes. In this work, we introduce Text-DJ, a novel jailbreak attack that bypasses these safeguards by exploiting the model's Optical Character Recognition (OCR) capability. Our methodology consists of three stages. First, we decompose a single harmful query into multiple and semantically related but more benign sub-queries. Second, we pick a set of distraction queries that are maximally irrelevant to the harmful query. Third, we present all decomposed sub-queries and distraction queries to the LVLM simultaneously as a grid of images, with the position of the sub-queries being middle within the grid. We demonstrate that this method successfully circumvents the safety alignment of state-of-the-art LVLMs. We argue this attack succeeds by (1) converting text-based prompts into images, bypassing standard text-based filters, and (2) inducing distractions, where the model's safety protocols fail to link the scattered sub-queries within a high number of irrelevant queries. Overall, our findings expose a critical vulnerability in LVLMs' OCR capabilities that are not robust to dispersed, multi-image adversarial inputs, highlighting the need for defenses for fragmented multimodal inputs.

</details>


### [64] [DISK: Dynamic Inference SKipping for World Models](https://arxiv.org/abs/2602.00440)
*Anugunj Naman,Gaibo Zhang,Ayushman Singh,Yaguang Zhang*

Main category: cs.CV

TL;DR: DISK是一种无需训练的适应性推理方法，通过双分支控制器协调视频和轨迹扩散，显著提升效率并保持性能。


<details>
  <summary>Details</summary>
Motivation: 提出一种无需训练的适应性推理方法，以解决自回归世界模型中视频和轨迹预测的高成本问题。

Method: DISK通过双分支控制器协调两个耦合的扩散变换器，实现视频和自我轨迹的跨模态跳过决策，并在自回归前向链中扩展高阶潜在差异跳过测试，通过展开循环传播控制器统计量以确保长时稳定性。

Result: 在1500个NuPlan和NuScenes样本上，使用NVIDIA L40S GPU进行闭环驾驶展开时，DISK实现了轨迹扩散2倍加速和视频扩散1.6倍加速。

Conclusion: DISK在保持L2规划误差、视觉质量（FID/FVD）和NAVSIM PDMS分数的同时，显著降低了长时视频和轨迹预测的成本，实现了2倍轨迹扩散和1.6倍视频扩散的加速。

Abstract: We present DISK, a training-free adaptive inference method for autoregressive world models. DISK coordinates two coupled diffusion transformers for video and ego-trajectory via dual-branch controllers with cross-modal skip decisions, preserving motion-appearance consistency without retraining. We extend higher-order latent-difference skip testing to the autoregressive chain-of-forward regime and propagate controller statistics through rollout loops for long-horizon stability. When integrated into closed-loop driving rollouts on 1500 NuPlan and NuScenes samples using an NVIDIA L40S GPU, DISK achieves 2x speedup on trajectory diffusion and 1.6x speedup on video diffusion while maintaining L2 planning error, visual quality (FID/FVD), and NAVSIM PDMS scores, demonstrating practical long-horizon video-and-trajectory prediction at substantially reduced cost.

</details>


### [65] [Model Optimization for Multi-Camera 3D Detection and Tracking](https://arxiv.org/abs/2602.00450)
*Ethan Anderson,Justin Silva,Kyle Zheng,Sameer Pusegaonkar,Yizhou Wang,Zheng Tang,Sujit Biswas*

Main category: cs.CV

TL;DR: Sparse4D在多视角跟踪中表现稳定，但在极低帧率下身份关联崩溃；选择性量化优化速度-准确性；低帧率预训练显著提升零样本性能；混合精度降低延迟但需注意稳定性。


<details>
  <summary>Details</summary>
Motivation: 研究在室内环境中，静态相机网络如何在遮挡和异构视角下支持多目标跟踪，并评估Sparse4D框架的性能。

Method: Sparse4D是一个基于查询的时空3D检测和跟踪框架，通过实例内存传播稀疏对象查询，并在共享世界坐标系中融合多视角特征。

Result: Sparse4D在适度帧率降低时保持稳定，但低于2 FPS时身份关联崩溃。选择性量化在速度和准确性之间取得最佳平衡。低帧率预训练在WILDTRACK上带来显著增益，而微调效果有限。Transformer Engine混合精度降低延迟但可能影响稳定性。

Conclusion: Sparse4D在适度降低帧率时表现稳定，但在低于2 FPS时身份关联崩溃。选择性量化提供了最佳的速度-准确性权衡，而注意力相关模块对低精度敏感。在WILDTRACK上，低帧率预训练带来了显著的零样本增益，而小规模微调效果有限。Transformer Engine混合精度降低了延迟，但可能影响身份传播的稳定性。

Abstract: Outside-in multi-camera perception is increasingly important in indoor environments, where networks of static cameras must support multi-target tracking under occlusion and heterogeneous viewpoints. We evaluate Sparse4D, a query-based spatiotemporal 3D detection and tracking framework that fuses multi-view features in a shared world frame and propagates sparse object queries via instance memory. We study reduced input frame rates, post-training quantization (INT8 and FP8), transfer to the WILDTRACK benchmark, and Transformer Engine mixed-precision fine-tuning. To better capture identity stability, we report Average Track Duration (AvgTrackDur), which measures identity persistence in seconds. Sparse4D remains stable under moderate FPS reductions, but below 2 FPS, identity association collapses even when detections are stable. Selective quantization of the backbone and neck offers the best speed-accuracy trade-off, while attention-related modules are consistently sensitive to low precision. On WILDTRACK, low-FPS pretraining yields large zero-shot gains over the base checkpoint, while small-scale fine-tuning provides limited additional benefit. Transformer Engine mixed precision reduces latency and improves camera scalability, but can destabilize identity propagation, motivating stability-aware validation.

</details>


### [66] [LatentLens: Revealing Highly Interpretable Visual Tokens in LLMs](https://arxiv.org/abs/2602.00462)
*Benno Krojer,Shravan Nayak,Oscar Mañas,Vaibhav Adlakha,Desmond Elliott,Siva Reddy,Marius Mosbach*

Main category: cs.CV

TL;DR: LatentLens通过文本语料库映射视觉标记，揭示LLM处理视觉标记的机制，优于传统方法，证实视觉与语言表征的对齐。


<details>
  <summary>Details</summary>
Motivation: 探索为何大型语言模型（LLM）能轻松处理视觉标记，并开发解释性方法揭示视觉标记在LLM各层的表征内容。

Method: 引入LatentLens方法，通过将视觉标记映射到大型文本语料库的上下文化文本表征，比较并提取最近邻描述。

Result: LatentLens在10种VLM上表现优于常用方法（如LogitLens），多数视觉标记在各模型和各层中均可解释，且描述语义丰富。

Conclusion: 本研究通过LatentLens方法揭示了视觉与语言表征之间的对齐关系，为分析潜在表征开辟了新方向。

Abstract: Transforming a large language model (LLM) into a Vision-Language Model (VLM) can be achieved by mapping the visual tokens from a vision encoder into the embedding space of an LLM. Intriguingly, this mapping can be as simple as a shallow MLP transformation. To understand why LLMs can so readily process visual tokens, we need interpretability methods that reveal what is encoded in the visual token representations at every layer of LLM processing. In this work, we introduce LatentLens, a novel approach for mapping latent representations to descriptions in natural language. LatentLens works by encoding a large text corpus and storing contextualized token representations for each token in that corpus. Visual token representations are then compared to their contextualized textual representations, with the top-k nearest neighbor representations providing descriptions of the visual token. We evaluate this method on 10 different VLMs, showing that commonly used methods, such as LogitLens, substantially underestimate the interpretability of visual tokens. With LatentLens instead, the majority of visual tokens are interpretable across all studied models and all layers. Qualitatively, we show that the descriptions produced by LatentLens are semantically meaningful and provide more fine-grained interpretations for humans compared to individual tokens. More broadly, our findings contribute new evidence on the alignment between vision and language representations, opening up new directions for analyzing latent representations.

</details>


### [67] [PSGS: Text-driven Panorama Sliding Scene Generation via Gaussian Splatting](https://arxiv.org/abs/2602.00463)
*Xin Zhang,Shen Chen,Jiale Zhou,Lei Li*

Main category: cs.CV

TL;DR: PSGS通过双层优化和全景滑动机制，解决了文本生成3D场景中的语义连贯性和细节保真问题，显著提升了生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有文本驱动方法因3D-文本数据有限和多视角拼接不一致，导致生成的3D场景过于简单，无法满足VR/AR/游戏等沉浸式应用的需求。

Method: PSGS采用两阶段框架：1）双层优化架构（布局推理层和自优化层）生成语义连贯的全景图；2）全景滑动机制通过策略性采样重叠视角初始化全局一致的3D高斯点云。

Result: 实验表明，PSGS在全景生成和3D场景渲染质量上优于现有方法，细节保真度和视觉吸引力显著提升。

Conclusion: PSGS框架通过两阶段优化和全景滑动机制，显著提升了3D场景生成的逼真度和细节保真度，为沉浸式内容创作提供了可扩展的解决方案。

Abstract: Generating realistic 3D scenes from text is crucial for immersive applications like VR, AR, and gaming. While text-driven approaches promise efficiency, existing methods suffer from limited 3D-text data and inconsistent multi-view stitching, resulting in overly simplistic scenes. To address this, we propose PSGS, a two-stage framework for high-fidelity panoramic scene generation. First, a novel two-layer optimization architecture generates semantically coherent panoramas: a layout reasoning layer parses text into structured spatial relationships, while a self-optimization layer refines visual details via iterative MLLM feedback. Second, our panorama sliding mechanism initializes globally consistent 3D Gaussian Splatting point clouds by strategically sampling overlapping perspectives. By incorporating depth and semantic coherence losses during training, we greatly improve the quality and detail fidelity of rendered scenes. Our experiments demonstrate that PSGS outperforms existing methods in panorama generation and produces more appealing 3D scenes, offering a robust solution for scalable immersive content creation.

</details>


### [68] [ZS-TreeSeg: A Zero-Shot Framework for Tree Crown Instance Segmentation](https://arxiv.org/abs/2602.00470)
*Pengyu Chen,Fangzheng Lyu,Sicheng Wang,Cuizhen Wang*

Main category: cs.CV

TL;DR: ZS-TreeSeg是一种零样本框架，通过结合语义分割和实例分割任务，无需训练即可解决密集树冠的分割问题，并在实验中表现出强大的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 密集且重叠的树冠中准确分割单个树冠是遥感领域的重要挑战，现有监督深度学习方法标注成本高且泛化能力有限，而基础模型（如Segment Anything Model）缺乏领域知识导致分割不足。

Method: ZS-TreeSeg框架利用Cellpose-SAM模型，将树冠建模为拓扑流场中的星凸对象，通过向量收敛实现数学上的分离。

Result: 在NEON和BAMFOREST数据集上的实验及视觉检查表明，ZS-TreeSeg框架能够跨不同传感器类型和树冠密度稳健泛化。

Conclusion: ZS-TreeSeg框架通过结合成熟的语义分割和实例分割任务，提出了一种无需训练的零样本解决方案，能够有效解决密集树冠中的分割问题，并在不同传感器和树冠密度下表现出强大的泛化能力。

Abstract: Individual tree crown segmentation is an important task in remote sensing for forest biomass estimation and ecological monitoring. However, accurate delineation in dense, overlapping canopies remains a bottleneck. While supervised deep learning methods suffer from high annotation costs and limited generalization, emerging foundation models (e.g., Segment Anything Model) often lack domain knowledge, leading to under-segmentation in dense clusters. To bridge this gap, we propose ZS-TreeSeg, a Zero-Shot framework that adapts from two mature tasks: 1) Canopy Semantic segmentation; and 2) Cells instance segmentation. By modeling tree crowns as star-convex objects within a topological flow field using Cellpose-SAM, the ZS-TreeSeg framework forces the mathematical separation of touching tree crown instances based on vector convergence. Experiments on the NEON and BAMFOREST datasets and visual inspection demonstrate that our framework generalizes robustly across diverse sensor types and canopy densities, which can offer a training-free solution for tree crown instance segmentation and labels generation.

</details>


### [69] [GTATrack: Winner Solution to SoccerTrack 2025 with Deep-EIoU and Global Tracklet Association](https://arxiv.org/abs/2602.00484)
*Rong-Lin Jian,Ming-Chi Luo,Chen-Wei Huang,Chia-Ming Lee,Yu-Fan Lin,Chih-Chung Hsu*

Main category: cs.CV

TL;DR: GTATrack是一个分层跟踪框架，通过Deep-EIoU和GTA组件解决了鱼眼镜头下足球跟踪的挑战，在SoccerTrack Challenge 2025中获胜，HOTA得分0.60。


<details>
  <summary>Details</summary>
Motivation: 体育比赛中的多目标跟踪（MOT）由于球员运动不规则、外观相似以及频繁遮挡而极具挑战性，而静态鱼眼镜头引入的几何失真和极端尺度变化进一步加剧了这些困难。

Method: GTATrack集成了两个核心组件：Deep Expansion IoU（Deep-EIoU）用于运动无关的在线关联，以及Global Tracklet Association（GTA）用于轨迹级细化。此外，还采用了伪标签策略来提高对小目标和扭曲目标的检测召回率。

Result: 该方法在HOTA评分上达到了0.60的优异成绩，并显著将误报减少至982个。

Conclusion: GTATrack在基于鱼眼镜头的足球跟踪中实现了最先进的准确性，显著减少了误报，并在SoccerTrack Challenge 2025中获得了第一名。

Abstract: Multi-object tracking (MOT) in sports is highly challenging due to irregular player motion, uniform appearances, and frequent occlusions. These difficulties are further exacerbated by the geometric distortion and extreme scale variation introduced by static fisheye cameras. In this work, we present GTATrack, a hierarchical tracking framework that win first place in the SoccerTrack Challenge 2025. GTATrack integrates two core components: Deep Expansion IoU (Deep-EIoU) for motion-agnostic online association and Global Tracklet Association (GTA) for trajectory-level refinement. This two-stage design enables both robust short-term matching and long-term identity consistency. Additionally, a pseudo-labeling strategy is used to boost detector recall on small and distorted targets. The synergy between local association and global reasoning effectively addresses identity switches, occlusions, and tracking fragmentation. Our method achieved a winning HOTA score of 0.60 and significantly reduced false positives to 982, demonstrating state-of-the-art accuracy in fisheye-based soccer tracking. Our code is available at https://github.com/ron941/GTATrack-STC2025.

</details>


### [70] [Refining Strokes by Learning Offset Attributes between Strokes for Flexible Sketch Edit at Stroke-Level](https://arxiv.org/abs/2602.00489)
*Sicong Zang,Tao Sun,Cairong Yan*

Main category: cs.CV

TL;DR: SketchMod通过学习源笔画的缩放、方向和位置属性，并将其与目标草图对齐，实现了灵活且精确的笔画级别草图编辑。


<details>
  <summary>Details</summary>
Motivation: 现有的方法仅通过重新定位源笔画来编辑草图，但由于源笔画在大小和方向上的显著变化，这种方法难以产生合理的编辑结果。

Method: 学习源笔画的三个关键偏移属性（缩放、方向和位置），并通过缩放调整空间比例、旋转对齐局部几何、位移满足语义布局来对齐目标草图。

Result: 实验结果表明，SketchMod在笔画级别的草图编辑上实现了精确和灵活的性能。

Conclusion: SketchMod通过精确控制笔画的缩放、旋转和位移，实现了在笔画级别上灵活且精确的草图编辑。

Abstract: Sketch edit at stroke-level aims to transplant source strokes onto a target sketch via stroke expansion or replacement, while preserving semantic consistency and visual fidelity with the target sketch. Recent studies addressed it by relocating source strokes at appropriate canvas positions. However, as source strokes could exhibit significant variations in both size and orientation, we may fail to produce plausible sketch editing results by merely repositioning them without further adjustments. For example, anchoring an oversized source stroke onto the target without proper scaling would fail to produce a semantically coherent outcome. In this paper, we propose SketchMod to refine the source stroke through transformation so as to align it with the target sketch's patterns, further realize flexible sketch edit at stroke-level. As the source stroke refinement is governed by the patterns of the target sketch, we learn three key offset attributes (scale, orientation and position) from the source stroke to another, and align it with the target by: 1) resizing to match spatial proportions by scale, 2) rotating to align with local geometry by orientation, and 3) displacing to meet with semantic layout by position. Besides, a stroke's profiles can be precisely controlled during sketch edit via the exposed captured stroke attributes. Experimental results indicate that SketchMod achieves precise and flexible performances on stroke-level sketch edit.

</details>


### [71] [HSSDCT: Factorized Spatial-Spectral Correlation for Hyperspectral Image Fusion](https://arxiv.org/abs/2602.00490)
*Chia-Ming Lee,Yu-Hao Ho,Yu-Fan Lin,Jen-Wei Lee,Li-Wei Kang,Chih-Chung Hsu*

Main category: cs.CV

TL;DR: HSSDCT通过多尺度特征聚合和线性复杂度自注意力改进HSI融合，实现高效高质重建。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在HSI融合中存在感受野有限、光谱冗余和自注意力二次复杂度等问题，限制了效率和鲁棒性。

Method: 提出HSSDCT框架，包含Hierarchical Dense-Residue Transformer Block (HDRTB)和Spatial-Spectral Correlation Layer (SSCL)两个关键模块，分别用于多尺度特征聚合和空间-光谱依赖分解。

Result: 在基准数据集上的实验表明，HSSDCT以显著降低的计算成本提供了优越的重建质量。

Conclusion: HSSDCT通过引入HDRTB和SSCL模块，显著提升了HSI融合的重建质量和计算效率，实现了新的最先进性能。

Abstract: Hyperspectral image (HSI) fusion aims to reconstruct a high-resolution HSI (HR-HSI) by combining the rich spectral information of a low-resolution HSI (LR-HSI) with the fine spatial details of a high-resolution multispectral image (HR-MSI). Although recent deep learning methods have achieved notable progress, they still suffer from limited receptive fields, redundant spectral bands, and the quadratic complexity of self-attention, which restrict both efficiency and robustness. To overcome these challenges, we propose the Hierarchical Spatial-Spectral Dense Correlation Network (HSSDCT). The framework introduces two key modules: (i) a Hierarchical Dense-Residue Transformer Block (HDRTB) that progressively enlarges windows and employs dense-residue connections for multi-scale feature aggregation, and (ii) a Spatial-Spectral Correlation Layer (SSCL) that explicitly factorizes spatial and spectral dependencies, reducing self-attention to linear complexity while mitigating spectral redundancy. Extensive experiments on benchmark datasets demonstrate that HSSDCT delivers superior reconstruction quality with significantly lower computational costs, achieving new state-of-the-art performance in HSI fusion. Our code is available at https://github.com/jemmyleee/HSSDCT.

</details>


### [72] [RGBX-R1: Visual Modality Chain-of-Thought Guided Reinforcement Learning for Multimodal Grounding](https://arxiv.org/abs/2602.00504)
*Jiahe Wu,Bing Cao,Qilong Wang,Qinghua Hu,Dongdong Li,Pengfei Zhu*

Main category: cs.CV

TL;DR: RGBX-R1通过UAV策略和两阶段训练提升MLLM的多模态能力，在基准测试中表现卓越。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM主要基于RGB模态预训练，限制了其在其他关键模态（如红外、深度、事件数据）上的性能，因此需要一种新框架来扩展其多模态理解能力。

Method: 采用Understand-Associate-Validate (UAV)提示策略构建Visual Modality Chain-of-Thought (VM-CoT)，并通过两阶段训练范式（Cold-Start Supervised Fine-Tuning和Spatio-Temporal Reinforcement Fine-Tuning）逐步增强推理能力。

Result: 在RGBX-Grounding基准测试中，RGBX-R1在多模态理解和空间感知任务上优于基线方法22.71%。

Conclusion: RGBX-R1框架通过UAV提示策略和两阶段训练范式（CS-SFT和ST-RFT），显著提升了MLLM在多模态（如红外、深度、事件数据）上的感知与推理能力，并在RGBX-Grounding基准测试中表现优异。

Abstract: Multimodal Large Language Models (MLLM) are primarily pre-trained on the RGB modality, thereby limiting their performance on other modalities, such as infrared, depth, and event data, which are crucial for complex scenarios. To address this, we propose RGBX-R1, a framework to enhance MLLM's perception and reasoning capacities across various X visual modalities. Specifically, we employ an Understand-Associate-Validate (UAV) prompting strategy to construct the Visual Modality Chain-of-Thought (VM-CoT), which aims to expand the MLLMs' RGB understanding capability into X modalities. To progressively enhance reasoning capabilities, we introduce a two-stage training paradigm: Cold-Start Supervised Fine-Tuning (CS-SFT) and Spatio-Temporal Reinforcement Fine-Tuning (ST-RFT). CS-SFT supervises the reasoning process with the guidance of VM-CoT, equipping the MLLM with fundamental modality cognition. Building upon GRPO, ST-RFT employs a Modality-understanding Spatio-Temporal (MuST) reward to reinforce modality reasoning. Notably, we construct the first RGBX-Grounding benchmark, and extensive experiments verify our superiority in multimodal understanding and spatial perception, outperforming baselines by 22.71% on three RGBX grounding tasks.

</details>


### [73] [Sparse Shortcuts: Facilitating Efficient Fusion in Multimodal Large Language Models](https://arxiv.org/abs/2602.00505)
*Jingrui Zhang,Feng Liang,Yong Zhang,Wei Wang,Runhao Zeng,Xiping Hu*

Main category: cs.CV

TL;DR: SparseCut通过稀疏快捷连接和多粒度特征融合，高效整合多级视觉特征，提升MLLMs性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在跨模态知识整合上不足，尤其是视觉语言模型中仅使用高层特征导致语义信息丢失。

Method: 提出SparseCut架构，通过稀疏快捷连接和多粒度特征融合模块，高效整合多级视觉特征。

Result: 实验表明，SparseCut在多种多模态基准测试中显著提升性能。

Conclusion: SparseCut通过稀疏快捷连接和多粒度特征融合模块，显著提升了多模态大语言模型（MLLMs）的性能，且具有通用性和可扩展性。

Abstract: With the remarkable success of large language models (LLMs) in natural language understanding and generation, multimodal large language models (MLLMs) have rapidly advanced in their ability to process data across multiple modalities. While most existing efforts focus on scaling up language models or constructing higher-quality training data, limited attention has been paid to effectively integrating cross-modal knowledge into the language space. In vision-language models, for instance, aligning modalities using only high-level visual features often discards the rich semantic information present in mid- and low-level features, limiting the model's ability of cross-modality understanding. To address this issue, we propose SparseCut, a general cross-modal fusion architecture for MLLMs, introducing sparse shortcut connections between the cross-modal encoder and the LLM. These shortcut connections enable the efficient and hierarchical integration of visual features at multiple levels, facilitating richer semantic fusion without increasing computational overhead. We further introduce an efficient multi-grained feature fusion module, which performs the fusion of visual features before routing them through the shortcuts. This preserves the original language context and does not increase the overall input length, thereby avoiding an increase in computational complexity for the LLM. Experiments demonstrate that SparseCut significantly enhances the performance of MLLMs across various multimodal benchmarks with generality and scalability for different base LLMs.

</details>


### [74] [DuoGen: Towards General Purpose Interleaved Multimodal Generation](https://arxiv.org/abs/2602.00508)
*Min Shi,Xiaohui Zeng,Jiannan Huang,Yin Cui,Francesco Ferroni,Jialuo Li,Shubham Pachori,Zhaoshuo Li,Yogesh Balaji,Haoxiang Wang,Tsung-Yi Lin,Xiao Fu,Yue Zhao,Chieh-Yun Chen,Ming-Yu Liu,Humphrey Shi*

Main category: cs.CV

TL;DR: DuoGen 是一个通用的交错生成框架，通过数据整理和两阶段解耦策略，显著提升了交错生成模型的质量，并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的交错生成模型在通用指令下的质量受限于训练数据不足和基础模型能力不足，因此需要一种系统化的方法来提升数据、架构和评估。

Method: DuoGen 结合了预训练的多模态 LLM 的视觉理解和扩散变换器（DiT）的视觉生成能力，采用两阶段解耦策略：先对 MLLM 进行指令微调，再通过精选的交错图像-文本序列将 DiT 与 MLLM 对齐。

Result: DuoGen 在公开和新提出的基准测试中，在文本质量、图像保真度和图像-上下文对齐方面优于现有开源模型，并在统一生成模型中实现了文本到图像和图像编辑的最新性能。

Conclusion: DuoGen 是一个通用的交错生成框架，通过系统化的数据整理、架构设计和评估，显著提升了交错生成模型的质量，并在文本质量、图像保真度和图像-上下文对齐方面优于现有开源模型。

Abstract: Interleaved multimodal generation enables capabilities beyond unimodal generation models, such as step-by-step instructional guides, visual planning, and generating visual drafts for reasoning. However, the quality of existing interleaved generation models under general instructions remains limited by insufficient training data and base model capacity. We present DuoGen, a general-purpose interleaved generation framework that systematically addresses data curation, architecture design, and evaluation. On the data side, we build a large-scale, high-quality instruction-tuning dataset by combining multimodal conversations rewritten from curated raw websites, and diverse synthetic examples covering everyday scenarios. Architecturally, DuoGen leverages the strong visual understanding of a pretrained multimodal LLM and the visual generation capabilities of a diffusion transformer (DiT) pretrained on video generation, avoiding costly unimodal pretraining and enabling flexible base model selection. A two-stage decoupled strategy first instruction-tunes the MLLM, then aligns DiT with it using curated interleaved image-text sequences. Across public and newly proposed benchmarks, DuoGen outperforms prior open-source models in text quality, image fidelity, and image-context alignment, and also achieves state-of-the-art performance on text-to-image and image editing among unified generation models. Data and code will be released at https://research.nvidia.com/labs/dir/duetgen/.

</details>


### [75] [SPARK: Stochastic Propagation via Affinity-guided Random walK for training-free unsupervised segmentation](https://arxiv.org/abs/2602.00516)
*Kunal Mahatha,Jose Dolz,Christian Desrosiers*

Main category: cs.CV

TL;DR: 本文提出了一种新的训练免费分割方法，通过随机流平衡和马尔可夫传播，解决了现有谱聚类方法的局限性，取得了显著的性能提升。


<details>
  <summary>Details</summary>
Motivation: 现有训练免费分割方法依赖谱图分割假设，存在边界过度平滑、对噪声敏感等问题，且忽视了局部邻域结构的重要性。

Method: 将训练免费分割重新定义为扩散诱导亲和图上的随机流平衡问题，引入马尔可夫传播方案，结合随机游走标签扩散和自适应剪枝策略。

Result: 在七个广泛使用的语义分割基准测试中，该方法实现了最先进的零样本性能，生成更清晰的边界和更稳定的掩码。

Conclusion: 本文提出了一种基于随机流平衡问题的训练免费分割方法，通过结合全局扩散注意力和局部邻域结构，显著提升了分割的边界清晰度和区域一致性，超越了现有的基于谱聚类的方法。

Abstract: We argue that existing training-free segmentation methods rely on an implicit and limiting assumption, that segmentation is a spectral graph partitioning problem over diffusion-derived affinities. Such approaches, based on global graph partitioning and eigenvector-based formulations of affinity matrices, suffer from several fundamental drawbacks, they require pre-selecting the number of clusters, induce boundary oversmoothing due to spectral relaxation, and remain highly sensitive to noisy or multi-modal affinity distributions. Moreover, many prior works neglect the importance of local neighborhood structure, which plays a crucial role in stabilizing affinity propagation and preserving fine-grained contours. To address these limitations, we reformulate training-free segmentation as a stochastic flow equilibrium problem over diffusion-induced affinity graphs, where segmentation emerges from a stochastic propagation process that integrates global diffusion attention with local neighborhoods extracted from stable diffusion, yielding a sparse yet expressive affinity structure. Building on this formulation, we introduce a Markov propagation scheme that performs random-walk-based label diffusion with an adaptive pruning strategy that suppresses unreliable transitions while reinforcing confident affinity paths. Experiments across seven widely used semantic segmentation benchmarks demonstrate that our method achieves state-of-the-art zero-shot performance, producing sharper boundaries, more coherent regions, and significantly more stable masks compared to prior spectral-clustering-based approaches.

</details>


### [76] [MRAD: Zero-Shot Anomaly Detection with Memory-Driven Retrieval](https://arxiv.org/abs/2602.00522)
*Chaoran Xu,Chengkan Lv,Qiyu Chen,Feng Zhang,Zhengtao Zhang*

Main category: cs.CV

TL;DR: MRAD是一种无需参数拟合的零样本异常检测框架，通过记忆检索直接利用数据分布，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有零样本异常检测方法多依赖提示学习或复杂建模，导致训练或推理成本高且跨域稳定性有限。MRAD旨在通过直接记忆检索替代参数拟合，解决这些限制。

Method: 提出了一种名为MRAD的统一框架，包括无训练基础模型MRAD-TF和两种轻量级变体MRAD-FT与MRAD-CLIP。MRAD-TF通过构建两级记忆库（图像级和像素级）并直接检索相似性来获取异常分数。MRAD-FT通过微调检索度量增强区分能力，MRAD-CLIP则通过动态偏置增强泛化能力。

Result: 在16个工业和医学数据集上，MRAD框架在异常分类和分割任务中均表现出优越性能。

Conclusion: MRAD框架通过直接利用原始数据的经验分布而非仅依赖模型拟合，在异常检测任务中展现了更强的性能，尤其在无训练和基于训练的场景下均表现优异。

Abstract: Zero-shot anomaly detection (ZSAD) often leverages pretrained vision or vision-language models, but many existing methods use prompt learning or complex modeling to fit the data distribution, resulting in high training or inference cost and limited cross-domain stability. To address these limitations, we propose Memory-Retrieval Anomaly Detection method (MRAD), a unified framework that replaces parametric fitting with a direct memory retrieval. The train-free base model, MRAD-TF, freezes the CLIP image encoder and constructs a two-level memory bank (image-level and pixel-level) from auxiliary data, where feature-label pairs are explicitly stored as keys and values. During inference, anomaly scores are obtained directly by similarity retrieval over the memory bank. Based on the MRAD-TF, we further propose two lightweight variants as enhancements: (i) MRAD-FT fine-tunes the retrieval metric with two linear layers to enhance the discriminability between normal and anomaly; (ii) MRAD-CLIP injects the normal and anomalous region priors from the MRAD-FT as dynamic biases into CLIP's learnable text prompts, strengthening generalization to unseen categories. Across 16 industrial and medical datasets, the MRAD framework consistently demonstrates superior performance in anomaly classification and segmentation, under both train-free and training-based settings. Our work shows that fully leveraging the empirical distribution of raw data, rather than relying only on model fitting, can achieve stronger anomaly detection performance. The code will be publicly released at https://github.com/CROVO1026/MRAD.

</details>


### [77] [SAGE: Accelerating Vision-Language Models via Entropy-Guided Adaptive Speculative Decoding](https://arxiv.org/abs/2602.00523)
*Yujia Tong,Tian Zhang,Yunyang Wan,Kaiwei Lin,Jingling Yuan,Chuang Hu*

Main category: cs.CV

TL;DR: SAGE通过动态调整推测树结构，显著加速视觉语言模型推理，最高提速3.36倍。


<details>
  <summary>Details</summary>
Motivation: 现有静态树结构无法适应不同生成步骤的预测难度变化，导致接受长度和加速效果不理想。

Method: 提出SAGE框架，基于实时预测不确定性动态调整推测树结构，利用输出熵作为置信度指标。

Result: 在多个基准测试中，SAGE实现了高达3.36倍的解码加速（LLaVA-OneVision-72B）和3.18倍（Qwen2.5-VL-72B）。

Conclusion: SAGE通过动态调整推测树结构，显著提升了视觉语言模型的推理速度，且不损失输出质量。

Abstract: Speculative decoding has emerged as a promising approach to accelerate inference in vision-language models (VLMs) by enabling parallel verification of multiple draft tokens. However, existing methods rely on static tree structures that remain fixed throughout the decoding process, failing to adapt to the varying prediction difficulty across generation steps. This leads to suboptimal acceptance lengths and limited speedup. In this paper, we propose SAGE, a novel framework that dynamically adjusts the speculation tree structure based on real-time prediction uncertainty. Our key insight is that output entropy serves as a natural confidence indicator with strong temporal correlation across decoding steps. SAGE constructs deeper-narrower trees for high-confidence predictions to maximize speculation depth, and shallower-wider trees for uncertain predictions to diversify exploration. SAGE improves acceptance lengths and achieves faster acceleration compared to static tree baselines. Experiments on multiple benchmarks demonstrate the effectiveness of SAGE: without any loss in output quality, it delivers up to $3.36\times$ decoding speedup for LLaVA-OneVision-72B and $3.18\times$ for Qwen2.5-VL-72B.

</details>


### [78] [Enhancing Open-Vocabulary Object Detection through Multi-Level Fine-Grained Visual-Language Alignment](https://arxiv.org/abs/2602.00531)
*Tianyi Zhang,Antoine Simoulin,Kai Li,Sana Lakdawala,Shiqing Yu,Arpit Mittal,Hongyu Fu,Yu Lin*

Main category: cs.CV

TL;DR: VLDet通过改进特征金字塔和引入SigRPN模块，显著提升开放词汇目标检测性能，在COCO和LVIS数据集上超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统目标检测系统受限于预定义类别，而开放词汇目标检测（OVD）虽能识别新类别，但现有方法在单尺度图像主干适应或视觉-语言对齐方面存在挑战。

Method: 提出VLDet框架，包括VL-PUB模块用于改进特征金字塔以实现细粒度的视觉-语言对齐，以及SigRPN模块通过基于sigmoid的锚点-文本对比对齐损失提升新类别的检测。

Result: 在COCO2017和LVIS数据集上，VLDet分别达到58.7 AP和24.8 AP，显著优于现有方法，提升幅度分别为27.6%和6.9%。

Conclusion: VLDet框架通过改进特征金字塔和引入SigRPN模块，显著提升了开放词汇目标检测（OVD）的性能，并在多个数据集上超越了现有方法。

Abstract: Traditional object detection systems are typically constrained to predefined categories, limiting their applicability in dynamic environments. In contrast, open-vocabulary object detection (OVD) enables the identification of objects from novel classes not present in the training set. Recent advances in visual-language modeling have led to significant progress of OVD. However, prior works face challenges in either adapting the single-scale image backbone from CLIP to the detection framework or ensuring robust visual-language alignment. We propose Visual-Language Detection (VLDet), a novel framework that revamps feature pyramid for fine-grained visual-language alignment, leading to improved OVD performance. With the VL-PUB module, VLDet effectively exploits the visual-language knowledge from CLIP and adapts the backbone for object detection through feature pyramid. In addition, we introduce the SigRPN block, which incorporates a sigmoid-based anchor-text contrastive alignment loss to improve detection of novel categories. Through extensive experiments, our approach achieves 58.7 AP for novel classes on COCO2017 and 24.8 AP on LVIS, surpassing all state-of-the-art methods and achieving significant improvements of 27.6% and 6.9%, respectively. Furthermore, VLDet also demonstrates superior zero-shot performance on closed-set object detection.

</details>


### [79] [SADER: Structure-Aware Diffusion Framework with DEterministic Resampling for Multi-Temporal Remote Sensing Cloud Removal](https://arxiv.org/abs/2602.00536)
*Yifan Zhang,Qian Chen,Yi Liu,Wengen Li,Jihong Guan*

Main category: cs.CV

TL;DR: SADER是一种结构感知扩散框架，通过多时序条件扩散网络和云感知注意力损失，显著提升多时序遥感图像去云效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散模型的遥感去云方法在采样效率和结构时序先验利用上存在不足，限制了多时序场景下的性能。

Method: SADER采用多时序条件扩散网络（MTCDN）捕捉多时序和多模态相关性，结合云感知注意力损失和确定性重采样策略，优化扩散模型的采样效率和结构利用。

Result: 在多个多时序数据集上的实验表明，SADER在所有评估指标上均优于现有最先进的去云方法。

Conclusion: SADER提出了一种结构感知的扩散框架，通过多时序条件扩散网络和云感知注意力损失，显著提升了多时序遥感图像去云的效果，并在多个数据集上验证了其优越性。

Abstract: Cloud contamination severely degrades the usability of remote sensing imagery and poses a fundamental challenge for downstream Earth observation tasks. Recently, diffusion-based models have emerged as a dominant paradigm for remote sensing cloud removal due to their strong generative capability and stable optimization. However, existing diffusion-based approaches often suffer from limited sampling efficiency and insufficient exploitation of structural and temporal priors in multi-temporal remote sensing scenarios. In this work, we propose SADER, a structure-aware diffusion framework for multi-temporal remote sensing cloud removal. SADER first develops a scalable Multi-Temporal Conditional Diffusion Network (MTCDN) to fully capture multi-temporal and multimodal correlations via temporal fusion and hybrid attention. Then, a cloud-aware attention loss is introduced to emphasize cloud-dominated regions by accounting for cloud thickness and brightness discrepancies. In addition, a deterministic resampling strategy is designed for continuous diffusion models to iteratively refine samples under fixed sampling steps by replacing outliers through guided correction. Extensive experiments on multiple multi-temporal datasets demonstrate that SADER consistently outperforms state-of-the-art cloud removal methods across all evaluation metrics. The code of SADER is publicly available at https://github.com/zyfzs0/SADER.

</details>


### [80] [NPNet: A Non-Parametric Network with Adaptive Gaussian-Fourier Positional Encoding for 3D Classification and Segmentation](https://arxiv.org/abs/2602.00542)
*Mohammad Saeid,Amir Salarpour,Pedram MohajerAnsari,Mert D. Pesé*

Main category: cs.CV

TL;DR: NPNet是一种非参数的3D点云分类和分割方法，通过自适应高斯-傅里叶编码实现稳定性能，在少样本场景和效率上表现突出。


<details>
  <summary>Details</summary>
Motivation: 为了解决3D点云分类和部分分割问题，提出一种无需学习权重的非参数方法，以适应不同尺度和采样密度。

Method: NPNet采用完全非参数的方法，利用确定性操作符（如最远点采样、k近邻和池化）构建点特征，并引入自适应高斯-傅里叶位置编码。

Result: 在ModelNet40/ModelNet-R、ScanObjectNN和ShapeNetPart等数据集上，NPNet表现优异，尤其在少样本设置下效果显著。

Conclusion: NPNet在多个数据集上表现出色，特别是在少样本设置下，且在内存使用和推理时间上优于先前的非参数方法。

Abstract: We present NPNet, a fully non-parametric approach for 3D point-cloud classification and part segmentation. NPNet contains no learned weights; instead, it builds point features using deterministic operators such as farthest point sampling, k-nearest neighbors, and pooling. Our key idea is an adaptive Gaussian-Fourier positional encoding whose bandwidth and Gaussian-cosine mixing are chosen from the input geometry, helping the method remain stable across different scales and sampling densities. For segmentation, we additionally incorporate fixed-frequency Fourier features to provide global context alongside the adaptive encoding. Across ModelNet40/ModelNet-R, ScanObjectNN, and ShapeNetPart, NPNet achieves strong performance among non-parametric baselines, and it is particularly effective in few-shot settings on ModelNet40. NPNet also offers favorable memory use and inference time compared to prior non-parametric methods

</details>


### [81] [Learning to Decode Against Compositional Hallucination in Video Multimodal Large Language Models](https://arxiv.org/abs/2602.00559)
*Wenbin Xing,Quanxing Zha,Lizheng Zu,Mengran Li,Ming Li,Junchi Yan*

Main category: cs.CV

TL;DR: OmniVCHall基准系统评估视频多模态大语言模型的组合幻觉，TriCD框架通过三重校准机制提升性能10%以上。


<details>
  <summary>Details</summary>
Motivation: 当前研究主要关注孤立错误类型，而组合幻觉（由多因素交互推理错误引起）研究不足，因此设计了OmniVCHall基准和TriCD框架。

Method: 提出了TriCD，一个包含自适应扰动控制器和显著性引导增强模块的对比解码框架，通过强化学习优化。

Result: 评估了39个代表性VLLM，发现即使先进模型（如Qwen3-VL和GPT-5）性能显著下降；TriCD在两种骨干模型上均表现优异。

Conclusion: TriCD框架通过三重路径校准机制显著提升了视频多模态大语言模型在组合幻觉场景下的性能，平均准确率提升超过10%。

Abstract: Current research on video hallucination mitigation primarily focuses on isolated error types, leaving compositional hallucinations, arising from incorrect reasoning over multiple interacting spatial and temporal factors largely underexplored. We introduce OmniVCHall, a benchmark designed to systematically evaluate both isolated and compositional hallucinations in video multimodal large language models (VLLMs). OmniVCHall spans diverse video domains, introduces a novel camera-based hallucination type, and defines a fine-grained taxonomy, together with adversarial answer options (e.g., "All are correct" and "None of the above") to prevent shortcut reasoning. The evaluations of 39 representative VLLMs reveal that even advanced models (e.g., Qwen3-VL and GPT-5) exhibit substantial performance degradation. We propose TriCD, a contrastive decoding framework with a triple-pathway calibration mechanism. An adaptive perturbation controller dynamically selects distracting operations to construct negative video variants, while a saliency-guided enhancement module adaptively reinforces grounded token-wise visual evidences. These components are optimized via reinforcement learning to encourage precise decision-making under compositional hallucination settings. Experimental results show that TriCD consistently improves performance across two representative backbones, achieving an average accuracy improvement of over 10%. The data and code can be find at https://github.com/BMRETURN/OmniVCHall.

</details>


### [82] [GLAD: Generative Language-Assisted Visual Tracking for Low-Semantic Templates](https://arxiv.org/abs/2602.00570)
*Xingyu Luo,Yidong Cai,Jie Liu,Jie Tang,Gangshan Wu,Limin Wang*

Main category: cs.CV

TL;DR: GLAD是一种生成式语言辅助跟踪模型，通过扩散模型融合文本与图像特征，显著提升低语义图像下的跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 当前视觉-语言跟踪方法在处理低语义图像（如模糊、低分辨率等）时性能受限，现有文本与视觉特征融合方法效果有限。

Method: 提出了一种名为GLAD的生成式语言辅助跟踪模型，利用扩散模型进行文本描述和模板图像的生成式多模态融合。

Result: 实验表明，GLAD在多个基准测试中达到了新的最优性能，并具有令人印象深刻的推理速度。

Conclusion: GLAD模型通过生成式多模态融合方法显著提升了视觉-语言跟踪的性能，并在多个基准测试中达到了新的最优水平。

Abstract: Vision-language tracking has gained increasing attention in many scenarios. This task simultaneously deals with visual and linguistic information to localize objects in videos. Despite its growing utility, the development of vision-language tracking methods remains in its early stage. Current vision-language trackers usually employ Transformer architectures for interactive integration of template, search, and text features. However, persistent challenges about low-semantic images including prevalent image blurriness, low resolution and so on, may compromise model performance through degraded cross-modal understanding. To solve this problem, language assistance is usually used to deal with the obstacles posed by low-semantic images. However, due to the existing gap between current textual and visual features, direct concatenation and fusion of these features may have limited effectiveness. To address these challenges, we introduce a pioneering Generative Language-AssisteD tracking model, GLAD, which utilizes diffusion models for the generative multi-modal fusion of text description and template image to bolster compatibility between language and image and enhance template image semantic information. Our approach demonstrates notable improvements over the existing fusion paradigms. Blurry and semantically ambiguous template images can be restored to improve multi-modal features in the generative fusion paradigm. Experiments show that our method establishes a new state-of-the-art on multiple benchmarks and achieves an impressive inference speed. The code and models will be released at: https://github.com/Confetti-lxy/GLAD

</details>


### [83] [Bridging Degradation Discrimination and Generation for Universal Image Restoration](https://arxiv.org/abs/2602.00579)
*JiaKui Hu,Zhengjian Yao,Lujia Jin,Yanye Lu*

Main category: cs.CV

TL;DR: BDG方法通过MAS-GLCM和分阶段扩散训练，有效结合退化判别与生成，提升了图像恢复性能。


<details>
  <summary>Details</summary>
Motivation: 解决通用图像恢复任务中高质量图像分布采样和基于退化调整输出的挑战。

Method: 提出MAS-GLCM进行退化类型和级别的细粒度判别，并将扩散训练分为生成、桥接和恢复三个阶段。

Result: 在不改变架构的情况下，BDG在全方位恢复和真实世界超分辨率任务中表现显著提升。

Conclusion: BDG方法通过结合退化判别与生成，显著提升了通用图像恢复任务的性能，尤其在保真度和感知质量方面取得了平衡。

Abstract: Universal image restoration is a critical task in low-level vision, requiring the model to remove various degradations from low-quality images to produce clean images with rich detail. The challenges lie in sampling the distribution of high-quality images and adjusting the outputs on the basis of the degradation. This paper presents a novel approach, Bridging Degradation discrimination and Generation (BDG), which aims to address these challenges concurrently. First, we propose the Multi-Angle and multi-Scale Gray Level Co-occurrence Matrix (MAS-GLCM) and demonstrate its effectiveness in performing fine-grained discrimination of degradation types and levels. Subsequently, we divide the diffusion training process into three distinct stages: generation, bridging, and restoration. The objective is to preserve the diffusion model's capability of restoring rich textures while simultaneously integrating the discriminative information from the MAS-GLCM into the restoration process. This enhances its proficiency in addressing multi-task and multi-degraded scenarios. Without changing the architecture, BDG achieves significant performance gains in all-in-one restoration and real-world super-resolution tasks, primarily evidenced by substantial improvements in fidelity without compromising perceptual quality. The code and pretrained models are provided in https://github.com/MILab-PKU/BDG.

</details>


### [84] [MAUGen: A Unified Diffusion Approach for Multi-Identity Facial Expression and AU Label Generation](https://arxiv.org/abs/2602.00583)
*Xiangdong Li,Ye Lou,Ao Gao,Wei Zhang,Siyang Song*

Main category: cs.CV

TL;DR: MAUGen 是一种基于扩散模型的多模态框架，通过生成多样化的人脸图像和精确AU标注，解决了AU识别系统泛化性不足的问题。


<details>
  <summary>Details</summary>
Motivation: 大规模、多样化且带有精确AU标注的人脸图像稀缺，是开发泛化性强的AU识别系统的主要瓶颈。

Method: MAUGen 包含两个关键模块：(1) 多模态表示学习模块（MRL），用于在统一潜在空间中捕捉文本描述、人脸身份、表情图像和AU激活之间的关系；(2) 基于扩散的图像标签生成器（DIG），将联合表示解码为对齐的人脸图像-标签对。

Result: 实验表明，MAUGen 在生成逼真、多样化的人脸图像及语义对齐的AU标注方面优于现有方法。

Conclusion: MAUGen 提出了一种基于扩散模型的多模态框架，能够生成大规模、多样化的人脸图像及精确的AU标注，显著提升了AU识别系统的泛化能力。

Abstract: The lack of large-scale, demographically diverse face images with precise Action Unit (AU) occurrence and intensity annotations has long been recognized as a fundamental bottleneck in developing generalizable AU recognition systems. In this paper, we propose MAUGen, a diffusion-based multi-modal framework that jointly generates a large collection of photorealistic facial expressions and anatomically consistent AU labels, including both occurrence and intensity, conditioned on a single descriptive text prompt. Our MAUGen involves two key modules: (1) a Multi-modal Representation Learning (MRL) module that captures the relationships among the paired textual description, facial identity, expression image, and AU activations within a unified latent space; and (2) a Diffusion-based Image label Generator (DIG) that decodes the joint representation into aligned facial image-label pairs across diverse identities. Under this framework, we introduce Multi-Identity Facial Action (MIFA), a large-scale multimodal synthetic dataset featuring comprehensive AU annotations and identity variations. Extensive experiments demonstrate that MAUGen outperforms existing methods in synthesizing photorealistic, demographically diverse facial images along with semantically aligned AU labels.

</details>


### [85] [From Pixels to Facts (Pix2Fact): Benchmarking Multi-Hop Reasoning for Fine-Grained Visual Fact Checking](https://arxiv.org/abs/2602.00593)
*Yifan Jiang,Cong Zhang,Bofei Zhang,Yifan Yang,Bingzhang Wang,Yew-Soon Ong*

Main category: cs.CV

TL;DR: Pix2Fact是评估视觉定位与知识推理的新基准，测试显示现有VLM表现远逊于人类，突显模型不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准未能综合评估视觉定位与知识推理能力，Pix2Fact旨在填补这一空白。

Method: 研究者设计了Pix2Fact，包含1000张高分辨率图像及由专业团队精心设计的问题，评估了9种先进VLM的表现。

Result: 最先进模型平均准确率仅为24%，远低于人类的56%，显示当前模型在视觉理解上的局限。

Conclusion: Pix2Fact作为新基准，揭示了当前VLM在结合细粒度感知与知识推理方面的不足，为下一代多模态代理的发展提供了关键方向。

Abstract: Despite progress on general tasks, VLMs struggle with challenges demanding both detailed visual grounding and deliberate knowledge-based reasoning, a synergy not captured by existing benchmarks that evaluate these skills separately. To close this gap, we introduce Pix2Fact, a new visual question-answering benchmark designed to evaluate expert-level perception and knowledge-intensive multi-hop reasoning. Pix2Fact contains 1,000 high-resolution (4K+) images spanning 8 daily-life scenarios and situations, with questions and answers meticulously crafted by annotators holding PhDs from top global universities working in partnership with a professional data annotation firm. Each question requires detailed visual grounding, multi-hop reasoning, and the integration of external knowledge to answer. Our evaluation of 9 state-of-the-art VLMs, including proprietary models like Gemini-3-Pro and GPT-5, reveals the substantial challenge posed by Pix2Fact: the most advanced model achieves only 24.0% average accuracy, in stark contrast to human performance of 56%. This significant gap underscores the limitations of current models in replicating human-level visual comprehension. We believe Pix2Fact will serve as a critical benchmark to drive the development of next-generation multimodal agents that combine fine-grained perception with robust, knowledge-based reasoning.

</details>


### [86] [Tune-Your-Style: Intensity-tunable 3D Style Transfer with Gaussian Splatting](https://arxiv.org/abs/2602.00618)
*Yian Zhao,Rushi Ye,Ruochong Zheng,Zesen Cheng,Chaoran Feng,Jiashu Yang,Pengchong Qiao,Chang Liu,Jie Chen*

Main category: cs.CV

TL;DR: 提出Tune-Your-Style方法，通过可调风格强度和两阶段优化策略，实现灵活定制的3D风格迁移。


<details>
  <summary>Details</summary>
Motivation: 现有3D风格迁移方法难以满足用户对内容-风格平衡的多样化需求，固定输出范式缺乏灵活性。

Method: 通过高斯神经元显式建模风格强度，并参数化可学习风格调节器实现强度可调的风格注入；采用两阶段优化策略，结合多视图一致风格视图和初始渲染的零风格引导，提供稳定高效的指导。

Result: 实验表明，该方法不仅生成视觉上吸引人的结果，还展现出对3D风格迁移的灵活定制能力。

Conclusion: 本文提出的Tune-Your-Style方法通过引入可调风格强度，显著提升了3D风格迁移的灵活性和可定制性，实验证明了其视觉吸引力和实用性。

Abstract: 3D style transfer refers to the artistic stylization of 3D assets based on reference style images. Recently, 3DGS-based stylization methods have drawn considerable attention, primarily due to their markedly enhanced training and rendering speeds. However, a vital challenge for 3D style transfer is to strike a balance between the content and the patterns and colors of the style. Although the existing methods strive to achieve relatively balanced outcomes, the fixed-output paradigm struggles to adapt to the diverse content-style balance requirements from different users. In this work, we introduce a creative intensity-tunable 3D style transfer paradigm, dubbed \textbf{Tune-Your-Style}, which allows users to flexibly adjust the style intensity injected into the scene to match their desired content-style balance, thus enhancing the customizability of 3D style transfer. To achieve this goal, we first introduce Gaussian neurons to explicitly model the style intensity and parameterize a learnable style tuner to achieve intensity-tunable style injection. To facilitate the learning of tunable stylization, we further propose the tunable stylization guidance, which obtains multi-view consistent stylized views from diffusion models through cross-view style alignment, and then employs a two-stage optimization strategy to provide stable and efficient guidance by modulating the balance between full-style guidance from the stylized views and zero-style guidance from the initial rendering. Extensive experiments demonstrate that our method not only delivers visually appealing results, but also exhibits flexible customizability for 3D style transfer. Project page is available at https://zhao-yian.github.io/TuneStyle.

</details>


### [87] [Towards Interpretable Hallucination Analysis and Mitigation in LVLMs via Contrastive Neuron Steering](https://arxiv.org/abs/2602.00621)
*Guangtao Lyu,Xinyi Cheng,Qi Liu,Chenghao Xu,Jiexi Yan,Muli Yang,Fen Fang,Cheng Deng*

Main category: cs.CV

TL;DR: 研究通过神经元级分析揭示了LVLMs幻觉的成因，并提出CNS方法选择性调控神经元，显著减少幻觉且兼容现有解码方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要关注输出级调整，对导致幻觉的内部机制缺乏深入探索。

Method: 采用稀疏自编码器(SAEs)分解密集视觉嵌入，通过神经元级分析识别不同类型神经元，并基于此提出CNS方法。

Result: CNS能选择性增强或抑制图像特定神经元，有效减少幻觉并提升视觉基础。

Conclusion: 通过Contrastive Neuron Steering (CNS)方法，研究成功减少了LVLMs的幻觉现象，同时保持了多模态理解能力。

Abstract: LVLMs achieve remarkable multimodal understanding and generation but remain susceptible to hallucinations. Existing mitigation methods predominantly focus on output-level adjustments, leaving the internal mechanisms that give rise to these hallucinations largely unexplored. To gain a deeper understanding, we adopt a representation-level perspective by introducing sparse autoencoders (SAEs) to decompose dense visual embeddings into sparse, interpretable neurons. Through neuron-level analysis, we identify distinct neuron types, including always-on neurons and image-specific neurons. Our findings reveal that hallucinations often result from disruptions or spurious activations of image-specific neurons, while always-on neurons remain largely stable. Moreover, selectively enhancing or suppressing image-specific neurons enables controllable intervention in LVLM outputs, improving visual grounding and reducing hallucinations. Building on these insights, we propose Contrastive Neuron Steering (CNS), which identifies image-specific neurons via contrastive analysis between clean and noisy inputs. CNS selectively amplifies informative neurons while suppressing perturbation-induced activations, producing more robust and semantically grounded visual representations. This not only enhances visual understanding but also effectively mitigates hallucinations. By operating at the prefilling stage, CNS is fully compatible with existing decoding-stage methods. Extensive experiments on both hallucination-focused and general multimodal benchmarks demonstrate that CNS consistently reduces hallucinations while preserving overall multimodal understanding.

</details>


### [88] [FaceSnap: Enhanced ID-fidelity Network for Tuning-free Portrait Customization](https://arxiv.org/abs/2602.00627)
*Benxiang Zhai,Yifang Xu,Guofeng Zhang,Yang Li,Sidan Du*

Main category: cs.CV

TL;DR: FaceSnap是一种基于SD的新方法，仅需单张参考图像即可在单次推理中生成高保真肖像，无需微调且具有高泛化性。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么需要耗时微调且缺乏泛化性，要么无法实现面部细节的高保真度。

Method: 基于Stable Diffusion（SD），设计了Facial Attribute Mixer和Landmark Predictor，并通过ID-preserving模块注入UNet。

Result: 实验结果表明，该方法在单次推理阶段即可生成高度一致的结果，且易于扩展到不同SD模型。

Conclusion: FaceSnap在个性化和定制肖像生成方面表现卓越，超越了该领域其他最先进的方法。

Abstract: Benefiting from the significant advancements in text-to-image diffusion models, research in personalized image generation, particularly customized portrait generation, has also made great strides recently. However, existing methods either require time-consuming fine-tuning and lack generalizability or fail to achieve high fidelity in facial details. To address these issues, we propose FaceSnap, a novel method based on Stable Diffusion (SD) that requires only a single reference image and produces extremely consistent results in a single inference stage. This method is plug-and-play and can be easily extended to different SD models. Specifically, we design a new Facial Attribute Mixer that can extract comprehensive fused information from both low-level specific features and high-level abstract features, providing better guidance for image generation. We also introduce a Landmark Predictor that maintains reference identity across landmarks with different poses, providing diverse yet detailed spatial control conditions for image generation. Then we use an ID-preserving module to inject these into the UNet. Experimental results demonstrate that our approach performs remarkably in personalized and customized portrait generation, surpassing other state-of-the-art methods in this domain.

</details>


### [89] [S$^3$POT: Contrast-Driven Face Occlusion Segmentation via Self-Supervised Prompt Learning](https://arxiv.org/abs/2602.00635)
*Lingsong Wang,Mancheng Meng,Ziyan Wu,Terrence Chen,Fan Yang,Dinggang Shen*

Main category: cs.CV

TL;DR: S$^3$POT是一种结合人脸生成与自监督空间提示的框架，无需遮挡真实掩模标注，实现了高效的遮挡分割。


<details>
  <summary>Details</summary>
Motivation: 现有面部解析方法常将遮挡误分类为面部组件，因遮挡是高层概念且难以构建覆盖所有遮挡类别的真实数据集。

Method: S$^3$POT包含三个模块：参考生成（RF）、特征增强（FE）和提示选择（PS）。RF利用解析掩模的结构指导生成参考图像；FE通过原始与参考图像的令牌对比获得初始提示，并通过交叉注意力修改图像特征；PS基于增强特征构建正负提示集，通过自注意力网络筛选供掩模解码器使用。

Result: 在专门收集的数据集上的大量实验证明了S$^3$POT的优越性能和模块有效性。

Conclusion: S$^3$POT框架通过结合人脸生成和自监督空间提示，成功实现了遮挡分割，无需遮挡真实掩模标注，展示了优越的性能和各模块的有效性。

Abstract: Existing face parsing methods usually misclassify occlusions as facial components. This is because occlusion is a high-level concept, it does not refer to a concrete category of object. Thus, constructing a real-world face dataset covering all categories of occlusion object is almost impossible and accurate mask annotation is labor-intensive. To deal with the problems, we present S$^3$POT, a contrast-driven framework synergizing face generation with self-supervised spatial prompting, to achieve occlusion segmentation. The framework is inspired by the insights: 1) Modern face generators' ability to realistically reconstruct occluded regions, creating an image that preserve facial geometry while eliminating occlusion, and 2) Foundation segmentation models' (e.g., SAM) capacity to extract precise mask when provided with appropriate prompts. In particular, S$^3$POT consists of three modules: Reference Generation (RF), Feature enhancement (FE), and Prompt Selection (PS). First, a reference image is produced by RF using structural guidance from parsed mask. Second, FE performs contrast of tokens between raw and reference images to obtain an initial prompt, then modifies image features with the prompt by cross-attention. Third, based on the enhanced features, PS constructs a set of positive and negative prompts and screens them with a self-attention network for a mask decoder. The network is learned under the guidance of three novel and complementary objective functions without occlusion ground truth mask involved. Extensive experiments on a dedicatedly collected dataset demonstrate S$^3$POT's superior performance and the effectiveness of each module.

</details>


### [90] [VIZOR: Viewpoint-Invariant Zero-Shot Scene Graph Generation for 3D Scene Reasoning](https://arxiv.org/abs/2602.00637)
*Vivek Madhavaram,Vartika Sengar,Arkadipta De,Charu Sharma*

Main category: cs.CV

TL;DR: VIZOR是一种无需训练的3D场景图生成方法，通过视角不变的关系定义和开放词汇推断，显著提升了场景理解和推理的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多视角下生成的空间关系（如“左/右”）不一致且泛化能力差，VIZOR旨在解决这些问题。

Method: VIZOR通过定义空间关系相对于每个物体的正面方向，构建视角不变的3D场景图，并推断开放词汇关系，无需标注训练数据。

Result: VIZOR在场景图生成和零样本物体定位任务中表现优异，在Replica和Nr3D数据集上分别提升了22%和4.81%的准确率。

Conclusion: VIZOR是一个无需训练、端到端的框架，能够直接从原始3D场景构建密集且视角不变的3D场景图，显著提升了场景图生成和下游任务的性能。

Abstract: Scene understanding and reasoning has been a fundamental problem in 3D computer vision, requiring models to identify objects, their properties, and spatial or comparative relationships among the objects. Existing approaches enable this by creating scene graphs using multiple inputs such as 2D images, depth maps, object labels, and annotated relationships from specific reference view. However, these methods often struggle with generalization and produce inaccurate spatial relationships like "left/right", which become inconsistent across different viewpoints. To address these limitations, we propose Viewpoint-Invariant Zero-shot scene graph generation for 3D scene Reasoning (VIZOR). VIZOR is a training-free, end-to-end framework that constructs dense, viewpoint-invariant 3D scene graphs directly from raw 3D scenes. The generated scene graph is unambiguous, as spatial relationships are defined relative to each object's front-facing direction, making them consistent regardless of the reference view. Furthermore, it infers open-vocabulary relationships that describe spatial and proximity relationships among scene objects without requiring annotated training data. We conduct extensive quantitative and qualitative evaluations to assess the effectiveness of VIZOR in scene graph generation and downstream tasks, such as query-based object grounding. VIZOR outperforms state-of-the-art methods, showing clear improvements in scene graph generation and achieving 22% and 4.81% gains in zero-shot grounding accuracy on the Replica and Nr3D datasets, respectively.

</details>


### [91] [Diff-PC: Identity-preserving and 3D-aware Controllable Diffusion for Zero-shot Portrait Customization](https://arxiv.org/abs/2602.00639)
*Yifang Xu,Benxiang Zhai,Chenyu Zhang,Ming Li,Yang Li,Sidan Du*

Main category: cs.CV

TL;DR: Diff-PC 是一种基于扩散的零样本肖像定制框架，通过3D面部先验和ID增强技术，实现了高保真身份保持和精确面部控制。


<details>
  <summary>Details</summary>
Motivation: 现有肖像定制方法在身份保持和面部控制方面存在不足，Diff-PC旨在解决这些问题。

Method: 使用3D面部预测器重建3D感知面部先验，设计ID-Encoder融合局部和全局面部特征，采用ID-Ctrl引导ID特征对齐，引入ID-Injector增强ID保真度和面部可控性。

Result: Diff-PC 生成了具有高ID保真度、指定面部属性和多样背景的逼真肖像，实验证明其性能优于现有方法。

Conclusion: Diff-PC 在身份保持、面部控制和文本到图像一致性方面优于现有方法，并与多风格基础模型兼容。

Abstract: Portrait customization (PC) has recently garnered significant attention due to its potential applications. However, existing PC methods lack precise identity (ID) preservation and face control. To address these tissues, we propose Diff-PC, a diffusion-based framework for zero-shot PC, which generates realistic portraits with high ID fidelity, specified facial attributes, and diverse backgrounds. Specifically, our approach employs the 3D face predictor to reconstruct the 3D-aware facial priors encompassing the reference ID, target expressions, and poses. To capture fine-grained face details, we design ID-Encoder that fuses local and global facial features. Subsequently, we devise ID-Ctrl using the 3D face to guide the alignment of ID features. We further introduce ID-Injector to enhance ID fidelity and facial controllability. Finally, training on our collected ID-centric dataset improves face similarity and text-to-image (T2I) alignment. Extensive experiments demonstrate that Diff-PC surpasses state-of-the-art methods in ID preservation, facial control, and T2I consistency. Furthermore, our method is compatible with multi-style foundation models.

</details>


### [92] [A Hybrid Mamba-SAM Architecture for Efficient 3D Medical Image Segmentation](https://arxiv.org/abs/2602.00650)
*Mohammadreza Gholipour Shahraki,Mehdi Rezaeian,Mohammad Ghasemzadeh*

Main category: cs.CV

TL;DR: Mamba-SAM结合冻结SAM编码器与Mamba SSMs，通过双分支或适配器策略高效解决3D医学图像分割问题，实验显示其性能与速度优势。


<details>
  <summary>Details</summary>
Motivation: 解决基础模型（如SAM）在医学图像分割中因领域偏移、固有2D设计和高计算成本微调而表现不佳的问题。

Method: 提出了Mamba-SAM，一种新颖高效的混合架构，结合了冻结的SAM编码器与基于Mamba的状态空间模型（SSMs）的线性时间效率和长程建模能力。研究了两种参数高效的适应策略：双分支架构和基于适配器的方法。

Result: 在ACDC心脏MRI数据集上的实验表明，双分支Mamba-SAM-Base模型的平均Dice得分为0.906，与UNet++（0.907）相当，同时在心肌（0.910）和左心室（0.971）分割上优于所有基线。基于适配器的TP MFGC变体提供了更快的推理速度（4.77 FPS）和强准确性（0.880 Dice）。

Conclusion: 结合基础模型与高效的基于SSM的架构为3D医学图像分割提供了实用且有效的解决方案。

Abstract: Accurate segmentation of 3D medical images such as MRI and CT is essential for clinical diagnosis and treatment planning. Foundation models like the Segment Anything Model (SAM) provide powerful general-purpose representations but struggle in medical imaging due to domain shift, their inherently 2D design, and the high computational cost of fine-tuning. To address these challenges, we propose Mamba-SAM, a novel and efficient hybrid architecture that combines a frozen SAM encoder with the linear-time efficiency and long-range modeling capabilities of Mamba-based State Space Models (SSMs). We investigate two parameter-efficient adaptation strategies. The first is a dual-branch architecture that explicitly fuses general features from a frozen SAM encoder with domain-specific representations learned by a trainable VMamba encoder using cross-attention. The second is an adapter-based approach that injects lightweight, 3D-aware Tri-Plane Mamba (TPMamba) modules into the frozen SAM ViT encoder to implicitly model volumetric context. Within this framework, we introduce Multi-Frequency Gated Convolution (MFGC), which enhances feature representation by jointly analyzing spatial and frequency-domain information via 3D discrete cosine transforms and adaptive gating. Extensive experiments on the ACDC cardiac MRI dataset demonstrate the effectiveness of the proposed methods. The dual-branch Mamba-SAM-Base model achieves a mean Dice score of 0.906, comparable to UNet++ (0.907), while outperforming all baselines on Myocardium (0.910) and Left Ventricle (0.971) segmentation. The adapter-based TP MFGC variant offers superior inference speed (4.77 FPS) with strong accuracy (0.880 Dice). These results show that hybridizing foundation models with efficient SSM-based architectures provides a practical and effective solution for 3D medical image segmentation.

</details>


### [93] [Any3D-VLA: Enhancing VLA Robustness via Diverse Point Clouds](https://arxiv.org/abs/2602.00807)
*Xianzhe Fan,Shengliang Deng,Xiaoyang Wu,Yuxiang Lu,Zhuoling Li,Mi Yan,Yujia Zhang,Zhizheng Zhang,He Wang,Hengshuang Zhao*

Main category: cs.CV

TL;DR: Any3D-VLA通过融合3D点云与2D表示，提升VLA模型在复杂场景中的空间理解能力，解决了数据稀缺和领域差距问题。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型依赖2D图像输入，限制了其在复杂场景中的空间理解能力。如何通过融入3D信息增强VLA能力？

Method: 提出Any3D-VLA，整合模拟器、传感器和模型估计的点云数据，构建多样化输入并学习领域无关的3D表示，与2D表示融合。

Result: 实验证明Any3D-VLA在提升性能和缓解领域差距方面具有优势。

Conclusion: Any3D-VLA通过统一模拟器、传感器和模型估计的点云数据，构建多样化输入并学习与2D表示融合的领域无关3D表示，有效提升了VLA模型在复杂场景中的空间理解能力。

Abstract: Existing Vision-Language-Action (VLA) models typically take 2D images as visual input, which limits their spatial understanding in complex scenes. How can we incorporate 3D information to enhance VLA capabilities? We conduct a pilot study across different observation spaces and visual representations. The results show that explicitly lifting visual input into point clouds yields representations that better complement their corresponding 2D representations. To address the challenges of (1) scarce 3D data and (2) the domain gap induced by cross-environment differences and depth-scale biases, we propose Any3D-VLA. It unifies the simulator, sensor, and model-estimated point clouds within a training pipeline, constructs diverse inputs, and learns domain-agnostic 3D representations that are fused with the corresponding 2D representations. Simulation and real-world experiments demonstrate Any3D-VLA's advantages in improving performance and mitigating the domain gap. Our project homepage is available at https://xianzhefan.github.io/Any3D-VLA.github.io.

</details>


### [94] [Non-Contrastive Vision-Language Learning with Predictive Embedding Alignment](https://arxiv.org/abs/2602.00653)
*Lukas Kuhn,Giuseppe Serra,Florian Buettner*

Main category: cs.CV

TL;DR: NOVA introduces a non-contrastive vision-language alignment framework that simplifies training by eliminating negative sampling and reducing hyperparameters, achieving better performance and stability.


<details>
  <summary>Details</summary>
Motivation: To address the limitations of dominant contrastive approaches like CLIP, which require large batch sizes, careful negative sampling, and extensive hyperparameter tuning.

Method: NOVA aligns visual representations to a frozen, domain-specific text encoder by predicting text embeddings from augmented image views, while enforcing an isotropic Gaussian structure via Sketched Isotropic Gaussian Regularization (SIGReg).

Result: NOVA outperforms multiple standard baselines on zero-shot classification across three benchmark datasets and exhibits substantially more consistent training runs.

Conclusion: NOVA demonstrates that non-contrastive vision-language pretraining is a simpler, more stable, and more effective alternative to contrastive methods like CLIP.

Abstract: Vision-language models have transformed multimodal representation learning, yet dominant contrastive approaches like CLIP require large batch sizes, careful negative sampling, and extensive hyperparameter tuning. We introduce NOVA, a NOn-contrastive Vision-language Alignment framework based on joint embedding prediction with distributional regularization. NOVA aligns visual representations to a frozen, domain-specific text encoder by predicting text embeddings from augmented image views, while enforcing an isotropic Gaussian structure via Sketched Isotropic Gaussian Regularization (SIGReg). This eliminates the need for negative sampling, momentum encoders, or stop-gradients, reducing the training objective to a single hyperparameter. We evaluate NOVA on zeroshot chest X-ray classification using ClinicalBERT as the text encoder and Vision Transformers trained from scratch on MIMIC-CXR. On zero-shot classification across three benchmark datasets, NOVA outperforms multiple standard baselines while exhibiting substantially more consistent training runs. Our results demonstrate that non-contrastive vision-language pretraining offers a simpler, more stable, and more effective alternative to contrastive methods.

</details>


### [95] [VVLoc: Prior-free 3-DoF Vehicle Visual Localization](https://arxiv.org/abs/2602.00810)
*Ze Huang,Zhongyang Xiao,Mingliang Song,Longan Yang,Hongyuan Yuan,Li Sun*

Main category: cs.CV

TL;DR: VVLoc 是一种统一的车辆定位方法，通过单一神经网络实现拓扑和度量定位，提供置信度测量，并在多种数据集上验证了其高效性和高精度。


<details>
  <summary>Details</summary>
Motivation: 传统方法通常独立处理拓扑和度量定位，依赖单摄像头设置，需要额外3D语义或姿态先验，且缺乏定位结果置信度量化机制，不适合实际工业应用。

Method: VVLoc 使用单一神经网络，通过评估视觉观测的地理接近度并估计相对度量姿态，同时提供置信度测量。训练过程高效，仅需视觉数据和真实姿态对。

Result: VVLoc 在公开和自收集数据集上均表现出最先进的定位精度，适用于广泛的定位任务。

Conclusion: VVLoc 提出了一种统一的流水线，通过单一神经网络实现多摄像头系统的拓扑和度量车辆定位，提供置信度测量，并在公开和自收集数据集上展示了最先进的定位精度。

Abstract: Localization is a critical technology in autonomous driving, encompassing both topological localization, which identifies the most similar map keyframe to the current observation, and metric localization, which provides precise spatial coordinates. Conventional methods typically address these tasks independently, rely on single-camera setups, and often require additional 3D semantic or pose priors, while lacking mechanisms to quantify the confidence of localization results, making them less feasible for real industrial applications. In this paper, we propose VVLoc, a unified pipeline that employs a single neural network to concurrently achieve topological and metric vehicle localization using multi-camera system. VVLoc first evaluates the geo-proximity between visual observations, then estimates their relative metric poses using a matching strategy, while also providing a confidence measure. Additionally, the training process for VVLoc is highly efficient, requiring only pairs of visual data and corresponding ground-truth poses, eliminating the need for complex supplementary data. We evaluate VVLoc not only on the publicly available datasets, but also on a more challenging self-collected dataset, demonstrating its ability to deliver state-of-the-art localization accuracy across a wide range of localization tasks.

</details>


### [96] [Schrödinger-Inspired Time-Evolution for 4D Deformation Forecasting](https://arxiv.org/abs/2602.00661)
*Ahsan Raza Siyal,Markus Haltmeier,Ruth Steiger,Elke Ruth Gizewski,Astrid Ellen Grams*

Main category: cs.CV

TL;DR: 论文提出了一种结合物理先验的深度学习模型，通过Schrödinger演化算子实现4D预测，在医学影像等领域展示了稳定且可解释的结果。


<details>
  <summary>Details</summary>
Motivation: 解决复杂三维现象（4D: 3D + 时间）的时空预测问题，特别是在医学影像、流体和材料动力学以及地球物理学中的应用需求。

Method: 采用Schrödinger启发的物理引导神经网络架构，通过深度学习框架嵌入显式时间演化算子，学习体素振幅、相位和势场，定义复值波函数并进行时间演化。

Result: 在合成基准测试中展示了未来4D状态（包括体积强度和形变场）的准确稳定预测，模拟了真实形状变形和拓扑变化。

Conclusion: 该论文提出了一种结合物理先验和深度学习的方法，通过Schrödinger演化算子实现4D时空预测，兼顾了模型的表达能力和物理模型的稳健性及可解释性。

Abstract: Spatiotemporal forecasting of complex three-dimensional phenomena (4D: 3D + time) is fundamental to applications in medical imaging, fluid and material dynamics, and geophysics. In contrast to unconstrained neural forecasting models, we propose a Schrödinger-inspired, physics-guided neural architecture that embeds an explicit time-evolution operator within a deep convolutional framework for 4D prediction. From observed volumetric sequences, the model learns voxelwise amplitude, phase, and potential fields that define a complex-valued wavefunction $ψ= A e^{iφ}$, which is evolved forward in time using a differentiable, unrolled Schrödinger time stepper. This physics-guided formulation yields several key advantages: (i) temporal stability arising from the structured evolution operator, which mitigates drift and error accumulation in long-horizon forecasting; (ii) an interpretable latent representation, where phase encodes transport dynamics, amplitude captures structural intensity, and the learned potential governs spatiotemporal interactions; and (iii) natural compatibility with deformation-based synthesis, which is critical for preserving anatomical fidelity in medical imaging applications. By integrating physical priors directly into the learning process, the proposed approach combines the expressivity of deep networks with the robustness and interpretability of physics-based modeling. We demonstrate accurate and stable prediction of future 4D states, including volumetric intensities and deformation fields, on synthetic benchmarks that emulate realistic shape deformations and topological changes. To our knowledge, this is the first end-to-end 4D neural forecasting framework to incorporate a Schrödinger-type evolution operator, offering a principled pathway toward interpretable, stable, and anatomically consistent spatiotemporal prediction.

</details>


### [97] [Navigating Simply, Aligning Deeply: Winning Solutions for Mouse vs. AI 2025](https://arxiv.org/abs/2602.00982)
*Phu-Hoa Pham,Chi-Nguyen Tran,Dao Sy Duy Minh,Nguyen Lam Phu Quy,Huynh Trung Kiet*

Main category: cs.CV

TL;DR: 该论文展示了在视觉稳健性和神经对齐方面的创新方法，挑战了模型复杂性的传统观念，并提供了实用的设计指导。


<details>
  <summary>Details</summary>
Motivation: 视觉稳健性和神经对齐是开发能与生物视觉系统匹敌的人工智能代理的关键挑战。

Method: 对于Track 1（视觉稳健性），采用了轻量级的两层CNN，结合Gated Linear Units和观察归一化；对于Track 2（神经对齐），开发了一个类似深度ResNet的架构，具有16个卷积层和基于GLU的门控机制。

Result: Track 1的最终得分为95.4%，Track 2的神经预测性能达到top-1，模型参数为1780万。训练时长与性能呈非单调关系，最佳结果出现在约20万步。

Conclusion: 该论文的结论挑战了关于模型复杂性的传统假设，并提供了开发稳健、受生物启发的视觉代理的实用指导。

Abstract: Visual robustness and neural alignment remain critical challenges in developing artificial agents that can match biological vision systems. We present the winning approaches from Team HCMUS_TheFangs for both tracks of the NeurIPS 2025 Mouse vs. AI: Robust Visual Foraging Competition. For Track 1 (Visual Robustness), we demonstrate that architectural simplicity combined with targeted components yields superior generalization, achieving 95.4% final score with a lightweight two-layer CNN enhanced by Gated Linear Units and observation normalization. For Track 2 (Neural Alignment), we develop a deep ResNet-like architecture with 16 convolutional layers and GLU-based gating that achieves top-1 neural prediction performance with 17.8 million parameters. Our systematic analysis of ten model checkpoints trained between 60K to 1.14M steps reveals that training duration exhibits a non-monotonic relationship with performance, with optimal results achieved around 200K steps. Through comprehensive ablation studies and failure case analysis, we provide insights into why simpler architectures excel at visual robustness while deeper models with increased capacity achieve better neural alignment. Our results challenge conventional assumptions about model complexity in visuomotor learning and offer practical guidance for developing robust, biologically-inspired visual agents.

</details>


### [98] [Improving Neuropathological Reconstruction Fidelity via AI Slice Imputation](https://arxiv.org/abs/2602.00669)
*Marina Crespo Aguirre,Jonathan Williams-Ramirez,Dina Zemlyanker,Xiaoling Hu,Lucas J. Deden-Binder,Rogeny Herisse,Mark Montine,Theresa R. Connors,Christopher Mount,Christine L. MacDonald,C. Dirk Keene,Caitlin S. Latimer,Derek H. Oakley,Bradley T. Hyman,Ana Lawry Aguila,Juan Eugenio Iglesias*

Main category: cs.CV

TL;DR: 提出了一种高效超分辨率方法，从各向异性3D重建生成各向同性体积，改善了神经病理学分析的解剖精度和分割效果。


<details>
  <summary>Details</summary>
Motivation: 解决从2D解剖照片重建3D脑体积时出现的结构粗糙、过度平滑的问题，特别是在高各向异性（如厚板重建）情况下。

Method: 引入了一种计算效率高的超分辨率步骤，通过训练在领域随机合成的数据上，生成解剖学上一致的各向同性体积。

Result: 重建的体积改善了自动分割，实现了更高的Dice分数，特别是在皮质和白质区域。验证显示更准确的皮质表面和MRI配准。

Conclusion: 该方法通过增强基于照片的重建的分辨率和解剖保真度，加强了神经病理学和神经影像学之间的联系。

Abstract: Neuropathological analyses benefit from spatially precise volumetric reconstructions that enhance anatomical delineation and improve morphometric accuracy. Our prior work has shown the feasibility of reconstructing 3D brain volumes from 2D dissection photographs. However these outputs sometimes exhibit coarse, overly smooth reconstructions of structures, especially under high anisotropy (i.e., reconstructions from thick slabs). Here, we introduce a computationally efficient super-resolution step that imputes slices to generate anatomically consistent isotropic volumes from anisotropic 3D reconstructions of dissection photographs. By training on domain-randomized synthetic data, we ensure that our method generalizes across dissection protocols and remains robust to large slab thicknesses. The imputed volumes yield improved automated segmentations, achieving higher Dice scores, particularly in cortical and white matter regions. Validation on surface reconstruction and atlas registration tasks demonstrates more accurate cortical surfaces and MRI registration. By enhancing the resolution and anatomical fidelity of photograph-based reconstructions, our approach strengthens the bridge between neuropathology and neuroimaging. Our method is publicly available at https://surfer.nmr.mgh.harvard.edu/fswiki/mri_3d_photo_recon

</details>


### [99] [Improving Robustness of Vision-Language-Action Models by Restoring Corrupted Visual Inputs](https://arxiv.org/abs/2602.01158)
*Daniel Yezid Guarnizo Orjuela,Leonardo Scappatura,Veronica Di Gennaro,Riccardo Andrea Izzo,Gianluca Bardaro,Matteo Matteucci*

Main category: cs.CV

TL;DR: VLA模型在视觉干扰下表现脆弱，CRT通过对抗训练恢复损坏输入，显著提升模型鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 尽管VLA模型在受控环境中表现出色，但在现实世界部署中，其对视觉干扰的脆弱性严重限制了其可靠性。现有研究主要关注场景几何引起的物理遮挡，而传感器级图像损坏（如电子噪声、坏像素和镜头污染物）对视觉信号完整性的影响尚未充分探索。

Method: 提出CRT，一种基于对抗训练目标的视觉Transformer，旨在从损坏的输入中恢复干净的观测，无需对底层模型进行昂贵的微调。

Result: 实验表明，CRT能显著恢复VLA模型在LIBERO和Meta-World基准测试中的性能，使其在严重视觉损坏下仍能保持接近基线的成功率。

Conclusion: CRT（Corruption Restoration Transformer）作为一种即插即用且模型无关的视觉Transformer，有效提升了VLA模型在视觉干扰下的鲁棒性，使其在严重视觉损坏下仍能保持接近基线的成功率。

Abstract: Vision-Language-Action (VLA) models have emerged as a dominant paradigm for generalist robotic manipulation, unifying perception and control within a single end-to-end architecture. However, despite their success in controlled environments, reliable real-world deployment is severely hindered by their fragility to visual disturbances. While existing literature extensively addresses physical occlusions caused by scene geometry, a critical mode remains largely unexplored: image corruptions. These sensor-level artifacts, ranging from electronic noise and dead pixels to lens contaminants, directly compromise the integrity of the visual signal prior to interpretation. In this work, we quantify this vulnerability, demonstrating that state-of-the-art VLAs such as $π_{0.5}$ and SmolVLA, suffer catastrophic performance degradation, dropping from 90\% success rates to as low as 2\%, under common signal artifacts. To mitigate this, we introduce the Corruption Restoration Transformer (CRT), a plug-and-play and model-agnostic vision transformer designed to immunize VLA models against sensor disturbances. Leveraging an adversarial training objective, CRT restores clean observations from corrupted inputs without requiring computationally expensive fine-tuning of the underlying model. Extensive experiments across the LIBERO and Meta-World benchmarks demonstrate that CRT effectively recovers lost performance, enabling VLAs to maintain near-baseline success rates, even under severe visual corruption.

</details>


### [100] [HPC: Hierarchical Point-based Latent Representation for Streaming Dynamic Gaussian Splatting Compression](https://arxiv.org/abs/2602.00671)
*Yangzhi Ma,Bojun Liu,Wenting Liao,Dong Liu,Zhu Li,Li Li*

Main category: cs.CV

TL;DR: HPC是一种新型流式动态高斯泼溅压缩框架，通过分层点基潜在表示和神经网络压缩，显著减少存储需求并保持高质量。


<details>
  <summary>Details</summary>
Motivation: 现有动态高斯泼溅压缩方法在存储和传输效率上存在参数冗余或局部相关性利用不足的问题。

Method: 采用分层点基潜在表示和定制聚合方案，避免未占用空间的参数冗余，并通过挖掘和利用参数间的帧间相关性压缩神经网络。

Result: HPC在存储减少67%的同时保持了高重建质量。

Conclusion: HPC框架显著优于现有方法，实现了67%的存储减少，同时保持高重建保真度。

Abstract: While dynamic Gaussian Splatting has driven significant advances in free-viewpoint video, maintaining its rendering quality with a small memory footprint for efficient streaming transmission still presents an ongoing challenge. Existing streaming dynamic Gaussian Splatting compression methods typically leverage a latent representation to drive the neural network for predicting Gaussian residuals between frames. Their core latent representations can be categorized into structured grid-based and unstructured point-based paradigms. However, the former incurs significant parameter redundancy by inevitably modeling unoccupied space, while the latter suffers from limited compactness as it fails to exploit local correlations. To relieve these limitations, we propose HPC, a novel streaming dynamic Gaussian Splatting compression framework. It employs a hierarchical point-based latent representation that operates on a per-Gaussian basis to avoid parameter redundancy in unoccupied space. Guided by a tailored aggregation scheme, these latent points achieve high compactness with low spatial redundancy. To improve compression efficiency, we further undertake the first investigation to compress neural networks for streaming dynamic Gaussian Splatting through mining and exploiting the inter-frame correlation of parameters. Combined with latent compression, this forms a fully end-to-end compression framework. Comprehensive experimental evaluations demonstrate that HPC substantially outperforms state-of-the-art methods. It achieves a storage reduction of 67% against its baseline while maintaining high reconstruction fidelity.

</details>


### [101] [OASIS-DC: Generalizable Depth Completion via Output-level Alignment of Sparse-Integrated Monocular Pseudo Depth](https://arxiv.org/abs/2602.01268)
*Jaehyeon Cho,Jhonghyun An*

Main category: cs.CV

TL;DR: 通过稀疏测量校准相对深度为伪度量先验，并设计精炼网络，实现少样本下的准确度量预测。


<details>
  <summary>Details</summary>
Motivation: 单目基础模型在零样本深度估计方面表现出色，但其输出本质上是相对的而非度量的，限制了在机器人和自动驾驶中的直接使用。

Method: 通过校准稀疏距离测量将相对深度转换为伪度量深度先验，并设计一个精炼网络，在可靠处遵循先验，在必要时偏离。

Result: 该系统在缺乏精选验证数据时尤为有效，能在少样本情况下保持稳定的尺度和锐利边缘。

Conclusion: 结合基础先验与稀疏锚点是实现真实世界标签稀缺下稳健、可部署深度补全的实用途径。

Abstract: Recent monocular foundation models excel at zero-shot depth estimation, yet their outputs are inherently relative rather than metric, limiting direct use in robotics and autonomous driving. We leverage the fact that relative depth preserves global layout and boundaries: by calibrating it with sparse range measurements, we transform it into a pseudo metric depth prior. Building on this prior, we design a refinement network that follows the prior where reliable and deviates where necessary, enabling accurate metric predictions from very few labeled samples. The resulting system is particularly effective when curated validation data are unavailable, sustaining stable scale and sharp edges across few-shot regimes. These findings suggest that coupling foundation priors with sparse anchors is a practical route to robust, deployment-ready depth completion under real-world label scarcity.

</details>


### [102] [Video Understanding: Through A Temporal Lens](https://arxiv.org/abs/2602.00683)
*Thong Thanh Nguyen*

Main category: cs.CV

TL;DR: This paper introduces five innovations to improve video understanding by modeling temporal relations, including automatic annotation, efficient fine-tuning, long-form modeling, contrastive learning, and empirical insights on LVLMs.


<details>
  <summary>Details</summary>
Motivation: To leverage temporal relations among video elements to advance video understanding, addressing the limitations of existing methods.

Method: The work presents a five-fold contribution: (1) an automatic annotation framework with noise-robust contrastive learning, (2) a parameter-efficient fine-tuning strategy using 'recurrent adapters', (3) integration of State Space Layers (SSL) for long-form video modeling, (4) a novel contrastive learning framework for fine-grained relations, and (5) a comprehensive empirical study on LVLMs.

Result: The contributions demonstrate enhanced ability to represent and reason about video content through explicit temporal modeling.

Conclusion: Explicit temporal modeling significantly enhances a model's ability to represent and reason about the fluid nature of video content.

Abstract: This thesis explores the central question of how to leverage temporal relations among video elements to advance video understanding. Addressing the limitations of existing methods, the work presents a five-fold contribution: (1) an automatic annotation framework that utilizes large vision-language models and a noise-robust contrastive learning objective with a subtractive angular margin; (2) a parameter-efficient fine-tuning strategy using "recurrent adapters" to capture temporal dynamics in low-data regimes; (3) the integration of State Space Layers (SSL) for efficient long-form video modeling, supported by the introduction of two new long-term benchmarks for egocentric and feature-length content; (4) a novel contrastive learning framework designed to explicitly model fine-grained relations between motions and video moments; and (5) a comprehensive empirical study on Large Vision-Language Models (LVLMs) that identifies the visual-language interface as a bottleneck for temporal reasoning, leading to a new "temporal-oriented recipe" for upscaled video understanding. Collectively, these contributions demonstrate that explicit temporal modeling significantly enhances a model's ability to represent and reason about the fluid nature of video content.

</details>


### [103] [Real-Time Loop Closure Detection in Visual SLAM via NetVLAD and Faiss](https://arxiv.org/abs/2602.01673)
*Enguang Fan*

Main category: cs.CV

TL;DR: NetVLAD作为LCD模块在SLAM中表现优于DBoW，通过Faiss加速实现实时性能。


<details>
  <summary>Details</summary>
Motivation: 解决传统词袋方法（如DBoW）在外观变化和感知混淆下的性能下降问题，同时克服深度学习VPR描述符（如NetVLAD）计算成本高的障碍。

Method: 在KITTI数据集上对NetVLAD和DBoW进行实证评估，引入细粒度Top-K精度-召回曲线以更好地反映LCD设置。

Result: NetVLAD在Faiss加速下实现了实时查询速度，并在准确性和鲁棒性上优于DBoW。

Conclusion: NetVLAD作为LCD模块在SLAM中表现出优于DBoW的准确性和鲁棒性，同时通过Faiss加速实现了实时查询速度，成为LCD的实用替代方案。

Abstract: Loop closure detection (LCD) is a core component of simultaneous localization and mapping (SLAM): it identifies revisited places and enables pose-graph constraints that correct accumulated drift. Classic bag-of-words approaches such as DBoW are efficient but often degrade under appearance change and perceptual aliasing. In parallel, deep learning-based visual place recognition (VPR) descriptors (e.g., NetVLAD and Transformer-based models) offer stronger robustness, but their computational cost is often viewed as a barrier to real-time SLAM. In this paper, we empirically evaluate NetVLAD as an LCD module and compare it against DBoW on the KITTI dataset. We introduce a Fine-Grained Top-K precision-recall curve that better reflects LCD settings where a query may have zero or multiple valid matches. With Faiss-accelerated nearestneighbor search, NetVLAD achieves real-time query speed while improving accuracy and robustness over DBoW, making it a practical drop-in alternative for LCD in SLAM.

</details>


### [104] [V2X-DSC: Multi-Agent Collaborative Perception with Distributed Source Coding Guided Communication](https://arxiv.org/abs/2602.00687)
*Yuankun Zeng,Shaohui Li,Zhi Li,Shulan Ruan,Yu Liu,You He*

Main category: cs.CV

TL;DR: V2X-DSC通过条件编解码器优化BEV特征共享，显著提升带宽效率与3D理解准确性。


<details>
  <summary>Details</summary>
Motivation: 多智能体协作感知中，密集BEV特征共享面临带宽限制，而观测同一物理世界导致特征高度相关，接收端仅需增量信息。

Method: 提出V2X-DSC框架，利用条件编解码器（DCC）压缩BEV特征为紧凑编码，接收端基于本地特征进行条件重建，优化比特分配以捕捉互补信息。

Result: 在DAIR-V2X、OPV2V和V2X-Real数据集上，V2X-DSC在KB级通信下实现了最优的准确率-带宽权衡，并可作为即插即用的通信层应用于多种融合骨干网络。

Conclusion: V2X-DSC框架通过条件编解码器（DCC）在带宽受限的融合场景中实现了高效的特征共享，显著提升了3D理解的准确性与带宽效率。

Abstract: Collaborative perception improves 3D understanding by fusing multi-agent observations, yet intermediate-feature sharing faces strict bandwidth constraints as dense BEV features saturate V2X links. We observe that collaborators view the same physical world, making their features strongly correlated; thus receivers only need innovation beyond their local context. Revisiting this from a distributed source coding perspective, we propose V2X-DSC, a framework with a Conditional Codec (DCC) for bandwidth-constrained fusion. The sender compresses BEV features into compact codes, while the receiver performs conditional reconstruction using its local features as side information, allocating bits to complementary cues rather than redundant content. This conditional structure regularizes learning, encouraging incremental representation and yielding lower-noise features. Experiments on DAIR-V2X, OPV2V, and V2X-Real demonstrate state-of-the-art accuracy-bandwidth trade-offs under KB-level communication, and generalizes as a plug-and-play communication layer across multiple fusion backbones.

</details>


### [105] [DDP-WM: Disentangled Dynamics Prediction for Efficient World Models](https://arxiv.org/abs/2602.01780)
*Shicheng Yin,Kaixuan Yin,Weixing Chen,Yang Liu,Guanbin Li,Liang Lin*

Main category: cs.CV

TL;DR: DDP-WM是一种高效的世界模型，通过解耦动态预测显著提升性能，适用于导航、精确操作等任务。


<details>
  <summary>Details</summary>
Motivation: 现有基于密集Transformer的世界模型计算开销大，阻碍了实时部署，需要解决效率与性能的瓶颈问题。

Method: DDP-WM采用了一种新颖的架构，结合高效的历史处理和动态定位来隔离主要动态，并通过交叉注意力机制进行背景更新。

Result: 在多样化任务中，DDP-WM显著提升了效率和性能，例如在Push-T任务中实现了约9倍的推理加速，并将MPC成功率从90%提升至98%。

Conclusion: DDP-WM通过解耦动态预测原则，显著提升了世界模型的效率和性能，为高效、高保真世界模型的发展提供了有希望的路径。

Abstract: World models are essential for autonomous robotic planning. However, the substantial computational overhead of existing dense Transformerbased models significantly hinders real-time deployment. To address this efficiency-performance bottleneck, we introduce DDP-WM, a novel world model centered on the principle of Disentangled Dynamics Prediction (DDP). We hypothesize that latent state evolution in observed scenes is heterogeneous and can be decomposed into sparse primary dynamics driven by physical interactions and secondary context-driven background updates. DDP-WM realizes this decomposition through an architecture that integrates efficient historical processing with dynamic localization to isolate primary dynamics. By employing a crossattention mechanism for background updates, the framework optimizes resource allocation and provides a smooth optimization landscape for planners. Extensive experiments demonstrate that DDP-WM achieves significant efficiency and performance across diverse tasks, including navigation, precise tabletop manipulation, and complex deformable or multi-body interactions. Specifically, on the challenging Push-T task, DDP-WM achieves an approximately 9 times inference speedup and improves the MPC success rate from 90% to98% compared to state-of-the-art dense models. The results establish a promising path for developing efficient, high-fidelity world models. Codes will be available at https://github.com/HCPLabSYSU/DDP-WM.

</details>


### [106] [JoyAvatar: Unlocking Highly Expressive Avatars via Harmonized Text-Audio Conditioning](https://arxiv.org/abs/2602.00702)
*Ruikui Wang,Jinheng Feng,Lang Tian,Huaishao Luo,Chaochao Li,Liangbo Zhou,Huan Zhang,Youzheng Wu,Xiaodong He*

Main category: cs.CV

TL;DR: JoyAvatar通过双教师训练和多模态条件调制，提升视频化身的文本指令对齐能力，支持复杂动作生成，性能优于现有模型。


<details>
  <summary>Details</summary>
Motivation: 现有视频化身模型在复杂文本指令（如全身运动、动态相机轨迹等）对齐方面表现有限，需突破这一限制。

Method: 采用双教师增强训练算法，结合多模态条件动态调制技术，以提升文本指令对齐能力和音频-视频同步。

Result: JoyAvatar在GSB评估中优于Omnihuman-1.5和KlingAvatar 2.0，支持多人对话和非人类角色扮演等复杂应用。

Conclusion: JoyAvatar通过双教师增强训练算法和多模态条件动态调制，显著提升了视频化身的文本指令对齐能力，支持复杂动作和动态场景的生成，并在GSB评估中优于现有先进模型。

Abstract: Existing video avatar models have demonstrated impressive capabilities in scenarios such as talking, public speaking, and singing. However, the majority of these methods exhibit limited alignment with respect to text instructions, particularly when the prompts involve complex elements including large full-body movement, dynamic camera trajectory, background transitions, or human-object interactions. To break out this limitation, we present JoyAvatar, a framework capable of generating long duration avatar videos, featuring two key technical innovations. Firstly, we introduce a twin-teacher enhanced training algorithm that enables the model to transfer inherent text-controllability from the foundation model while simultaneously learning audio-visual synchronization. Secondly, during training, we dynamically modulate the strength of multi-modal conditions (e.g., audio and text) based on the distinct denoising timestep, aiming to mitigate conflicts between the heterogeneous conditioning signals. These two key designs serve to substantially expand the avatar model's capacity to generate natural, temporally coherent full-body motions and dynamic camera movements as well as preserve the basic avatar capabilities, such as accurate lip-sync and identity consistency. GSB evaluation results demonstrate that our JoyAvatar model outperforms the state-of-the-art models such as Omnihuman-1.5 and KlingAvatar 2.0. Moreover, our approach enables complex applications including multi-person dialogues and non-human subjects role-playing. Some video samples are provided on https://joyavatar.github.io/.

</details>


### [107] [LangMap: A Hierarchical Benchmark for Open-Vocabulary Goal Navigation](https://arxiv.org/abs/2602.02220)
*Bo Miao,Weijia Liu,Jun Luo,Lachlan Shinnick,Jian Liu,Thomas Hamilton-Smith,Yuhe Yang,Zijie Wu,Vanja Videnovic,Feras Dayoub,Anton van den Hengel*

Main category: cs.CV

TL;DR: HieraNav和LangMap是一个多粒度、开放词汇的导航任务和基准，旨在通过语言指令实现具身导航，展示了上下文和记忆的重要性，并指出了当前技术的局限性。


<details>
  <summary>Details</summary>
Motivation: 研究物体与语言之间的关系对于实现有意义的人机交互和实用的具身智能至关重要。

Method: 提出了HieraNav任务和LangMap基准，基于真实世界的3D室内扫描数据，包含多粒度、开放词汇的导航任务和详细的人类验证注释。

Result: LangMap在判别准确性上比GOAT-Bench高出23.8%，且用词量减少了四倍。零样本和监督模型的评估显示，更丰富的上下文和记忆提高了成功率，但某些目标类型和多目标完成仍具挑战性。

Conclusion: HieraNav和LangMap为语言驱动的具身导航提供了一个严格的测试平台，揭示了上下文和记忆对任务成功的重要性，同时也指出了长尾、小型、上下文依赖和远距离目标以及多目标完成等挑战。

Abstract: The relationships between objects and language are fundamental to meaningful communication between humans and AI, and to practically useful embodied intelligence. We introduce HieraNav, a multi-granularity, open-vocabulary goal navigation task where agents interpret natural language instructions to reach targets at four semantic levels: scene, room, region, and instance. To this end, we present Language as a Map (LangMap), a large-scale benchmark built on real-world 3D indoor scans with comprehensive human-verified annotations and tasks spanning these levels. LangMap provides region labels, discriminative region descriptions, discriminative instance descriptions covering 414 object categories, and over 18K navigation tasks. Each target features both concise and detailed descriptions, enabling evaluation across different instruction styles. LangMap achieves superior annotation quality, outperforming GOAT-Bench by 23.8% in discriminative accuracy using four times fewer words. Comprehensive evaluations of zero-shot and supervised models on LangMap reveal that richer context and memory improve success, while long-tailed, small, context-dependent, and distant goals, as well as multi-goal completion, remain challenging. HieraNav and LangMap establish a rigorous testbed for advancing language-driven embodied navigation. Project: https://bo-miao.github.io/LangMap

</details>


### [108] [StomataSeg: Semi-Supervised Instance Segmentation for Sorghum Stomatal Components](https://arxiv.org/abs/2602.00703)
*Zhongtian Huang,Zhi Chen,Zi Huang,Xin Yu,Daniel Smith,Chaitanya Purushothama,Erik Van Oosterom,Alex Wu,William Salter,Yan Li,Scott Chapman*

Main category: cs.CV

TL;DR: 提出半监督实例分割框架，结合补丁预处理和伪标签策略，显著提升高粱气孔分割性能，支持AI驱动表型分析。


<details>
  <summary>Details</summary>
Motivation: 高粱是全球重要的谷物，广泛种植于水分有限和压力易发地区，其强大的耐旱性使其成为气候韧性农业的优先作物。提高高粱的水分利用效率需要精确表征气孔性状，因为气孔控制气体交换、蒸腾作用和光合作用对作物性能有重要影响。自动化分析高粱气孔存在困难，因为气孔小（通常小于40微米）且形状因基因型和叶片表面而异。自动化分割有助于高通量气孔表型分析，但当前方法仍面临嵌套小结构和标注瓶颈的挑战。

Method: 提出了一种半监督实例分割框架，专门用于分析高粱气孔组件。收集并标注了包含11,060个人工标注补丁的高粱叶片图像数据集，覆盖多个基因型和叶片表面的三种气孔组件（孔、保卫细胞和复合区域）。为提高微小结构的检测效果，将高分辨率显微图像分割为重叠的小补丁，并对未标注图像应用伪标签策略，生成了额外的56,428个伪标注补丁。

Result: 在语义和实例分割模型上的基准测试显示显著性能提升：语义模型的最高mIoU从65.93%提高到70.35%，而实例模型的最高AP从28.30%提高到46.10%。

Conclusion: 结合基于补丁的预处理和半监督学习显著提高了精细气孔结构的分割效果，支持气孔性状的可扩展提取，促进AI驱动表型分析在作物科学中的广泛应用。

Abstract: Sorghum is a globally important cereal grown widely in water-limited and stress-prone regions. Its strong drought tolerance makes it a priority crop for climate-resilient agriculture. Improving water-use efficiency in sorghum requires precise characterisation of stomatal traits, as stomata control of gas exchange, transpiration and photosynthesis have a major influence on crop performance. Automated analysis of sorghum stomata is difficult because the stomata are small (often less than 40 $μ$m in length in grasses such as sorghum) and vary in shape across genotypes and leaf surfaces. Automated segmentation contributes to high-throughput stomatal phenotyping, yet current methods still face challenges related to nested small structures and annotation bottlenecks. In this paper, we propose a semi-supervised instance segmentation framework tailored for analysis of sorghum stomatal components. We collect and annotate a sorghum leaf imagery dataset containing 11,060 human-annotated patches, covering the three stomatal components (pore, guard cell and complex area) across multiple genotypes and leaf surfaces. To improve the detection of tiny structures, we split high-resolution microscopy images into overlapping small patches. We then apply a pseudo-labelling strategy to unannotated images, producing an additional 56,428 pseudo-labelled patches. Benchmarking across semantic and instance segmentation models shows substantial performance gains: for semantic models the top mIoU increases from 65.93% to 70.35%, whereas for instance models the top AP rises from 28.30% to 46.10%. These results demonstrate that combining patch-based preprocessing with semi-supervised learning significantly improves the segmentation of fine stomatal structures. The proposed framework supports scalable extraction of stomatal traits and facilitates broader adoption of AI-driven phenotyping in crop science.

</details>


### [109] [Supervised makeup transfer with a curated dataset: Decoupling identity and makeup features for enhanced transformation](https://arxiv.org/abs/2602.00729)
*Qihe Pan,Yiming Wu,Xing Zhao,Liang Xie,Guodao Sun,Ronghua Liang*

Main category: cs.CV

TL;DR: 本文提出扩散模型框架，通过高质量数据集、特征解耦和文本引导机制，提升化妆迁移的保真度和可控性。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在数据集质量、特征解耦和可控性方面的不足。

Method: 采用扩散模型框架，结合合成、真实和过滤样本构建高质量数据集，设计特征解耦方法，并引入文本引导机制实现细粒度控制。

Result: 在基准测试和实际场景中，方法在保真度、身份保留和灵活性方面表现优异。

Conclusion: 扩散模型在化妆迁移任务中表现出色，通过构建高质量数据集、设计特征解耦框架和引入文本引导机制，显著提升了保真度、身份保留和灵活性。

Abstract: Diffusion models have recently shown strong progress in generative tasks, offering a more stable alternative to GAN-based approaches for makeup transfer. Existing methods often suffer from limited datasets, poor disentanglement between identity and makeup features, and weak controllability. To address these issues, we make three contributions. First, we construct a curated high-quality dataset using a train-generate-filter-retrain strategy that combines synthetic, realistic, and filtered samples to improve diversity and fidelity. Second, we design a diffusion-based framework that disentangles identity and makeup features, ensuring facial structure and skin tone are preserved while applying accurate and diverse cosmetic styles. Third, we propose a text-guided mechanism that allows fine-grained and region-specific control, enabling users to modify eyes, lips, or face makeup with natural language prompts. Experiments on benchmarks and real-world scenarios demonstrate improvements in fidelity, identity preservation, and flexibility. Examples of our dataset can be found at: https://makeup-adapter.github.io.

</details>


### [110] [Diffusion-Driven Inter-Outer Surface Separation for Point Clouds with Open Boundaries](https://arxiv.org/abs/2602.00739)
*Zhengyan Qin,Liyuan Qiu*

Main category: cs.CV

TL;DR: 提出扩散算法分离双层面点云内外层，解决TSDF融合中的双表面伪影，适用于室内和医疗成像。


<details>
  <summary>Details</summary>
Motivation: 解决TSDF融合中因不对称截断阈值导致的双表面伪影问题，提取真实内层以应对重叠表面和法线紊乱等挑战。

Method: 采用扩散算法处理双层面点云，尤其针对开放边界点云，能够稳健处理水密和开放边界模型，快速提取真实内层。

Result: 在约10秒内从20,000个内层和20,000个外层点中提取内层，适用于水密和开放边界表面几何。

Conclusion: 该论文提出了一种基于扩散的算法，有效解决了双层面点云中的内外层分离问题，特别是在TSDF融合过程中由截断引起的"双表面伪影"。该方法适用于需要精确表面表示的应用场景，如室内场景建模和医疗成像。

Abstract: We propose a diffusion-based algorithm for separating the inter and outer layer surfaces from double-layered point clouds, particularly those exhibiting the "double surface artifact" caused by truncation in Truncated Signed Distance Function (TSDF) fusion during indoor or medical 3D reconstruction. This artifact arises from asymmetric truncation thresholds, leading to erroneous inter and outer shells in the fused volume, which our method addresses by extracting the true inter layer to mitigate challenges like overlapping surfaces and disordered normals. We focus on point clouds with \emph{open boundaries} (i.e., sampled surfaces with topological openings/holes through which particles may escape), rather than point clouds with \emph{missing surface regions} where no samples exist. Our approach enables robust processing of both watertight and open-boundary models, achieving extraction of the inter layer from 20,000 inter and 20,000 outer points in approximately 10 seconds. This solution is particularly effective for applications requiring accurate surface representations, such as indoor scene modeling and medical imaging, where double-layered point clouds are prevalent, and it accommodates both closed (watertight) and open-boundary surface geometries. Our goal is \emph{post-hoc} inter/outer shell separation as a lightweight module after TSDF fusion; we do not aim to replace full variational or learning-based reconstruction pipelines.

</details>


### [111] [HSI-VAR: Rethinking Hyperspectral Restoration through Spatial-Spectral Visual Autoregression](https://arxiv.org/abs/2602.00749)
*Xiangming Wang,Benteng Sun,Yungeng Liu,Haijin Zeng,Yongyong Chen,Jingyong Su,Jie Liu*

Main category: cs.CV

TL;DR: HSI-VAR是一种高效的自回归生成方法，通过潜在条件对齐、退化感知引导和空间-光谱适应模块，显著提升了HSI恢复的性能和速度。


<details>
  <summary>Details</summary>
Motivation: 现有的HSI恢复方法如扩散模型计算成本高，回归模型则容易产生过度平滑的结果，无法保留关键结构细节。

Method: HSI-VAR将HSI恢复重新构想为自回归生成问题，引入了三个关键创新：潜在条件对齐、退化感知引导和空间-光谱适应模块。

Result: HSI-VAR在ICVL数据集上PSNR提高了3.77 dB，推理速度提升了95.5倍，计算成本降低了近50%。

Conclusion: HSI-VAR在九个全合一HSI恢复基准测试中表现出最先进的性能，PSNR提高了3.77 dB，推理速度比基于扩散的方法快95.5倍，是实际HSI恢复的高效解决方案。

Abstract: Hyperspectral images (HSIs) capture richer spatial-spectral information beyond RGB, yet real-world HSIs often suffer from a composite mix of degradations, such as noise, blur, and missing bands. Existing generative approaches for HSI restoration like diffusion models require hundreds of iterative steps, making them computationally impractical for high-dimensional HSIs. While regression models tend to produce oversmoothed results, failing to preserve critical structural details. We break this impasse by introducing HSI-VAR, rethinking HSI restoration as an autoregressive generation problem, where spectral and spatial dependencies can be progressively modeled rather than globally reconstructed. HSI-VAR incorporates three key innovations: (1) Latent-condition alignment, which couples semantic consistency between latent priors and conditional embeddings for precise reconstruction; (2) Degradation-aware guidance, which uniquely encodes mixed degradations as linear combinations in the embedding space for automatic control, remarkably achieving a nearly $50\%$ reduction in computational cost at inference; (3) A spatial-spectral adaptation module that refines details across both domains in the decoding phase. Extensive experiments on nine all-in-one HSI restoration benchmarks confirm HSI-VAR's state-of-the-art performance, achieving a 3.77 dB PSNR improvement on \textbf{\textit{ICVL}} and offering superior structure preservation with an inference speed-up of up to $95.5 \times$ compared with diffusion-based methods, making it a highly practical solution for real-world HSI restoration.

</details>


### [112] [Evaluating Deep Learning-Based Nerve Segmentation in Brachial Plexus Ultrasound Under Realistic Data Constraints](https://arxiv.org/abs/2602.00763)
*Dylan Yves,Khush Agarwal,Jonathan Hoyin Chan,Patcharapit Promoppatum,Aroonkamon Pattanasiricharoen*

Main category: cs.CV

TL;DR: 本研究通过U-Net架构评估超声图像中神经分割的深度学习性能，发现多源数据组合对低性能设备有正则化作用，但多类监督会降低神经分割准确性，且小神经分割仍是挑战。


<details>
  <summary>Details</summary>
Motivation: 超声引导的区域麻醉中，神经的精确定位至关重要，但由于图像对比度低、斑点噪声和患者间解剖变异，手动识别仍然具有挑战性。

Method: 使用U-Net架构评估深度学习在超声图像中的神经分割，重点关注数据集组成和标注策略对分割性能的影响。

Result: 训练数据来自多台超声机器（SIEMENS ACUSON NX3 Elite和Philips EPIQ5）的组合数据对低性能采集源具有正则化益处，但未超过目标域的单源训练。从二元神经分割扩展到多类监督（动脉、静脉、神经、肌肉）导致神经特异性Dice分数下降，性能下降幅度在9%至61%之间。此外，神经大小与分割准确性呈中度正相关（Pearson r=0.587, p<0.001），表明较小的神经仍是主要挑战。

Conclusion: 本研究为在真实临床数据限制下开发稳健的超声神经分割系统提供了方法学指导。

Abstract: Accurate nerve localization is critical for the success of ultrasound-guided regional anesthesia, yet manual identification remains challenging due to low image contrast, speckle noise, and inter-patient anatomical variability. This study evaluates deep learning-based nerve segmentation in ultrasound images of the brachial plexus using a U-Net architecture, with a focus on how dataset composition and annotation strategy influence segmentation performance. We find that training on combined data from multiple ultrasound machines (SIEMENS ACUSON NX3 Elite and Philips EPIQ5) provides regularization benefits for lower-performing acquisition sources, though it does not surpass single-source training when matched to the target domain. Extending the task from binary nerve segmentation to multi-class supervision (artery, vein, nerve, muscle) results in decreased nerve-specific Dice scores, with performance drops ranging from 9% to 61% depending on dataset, likely due to class imbalance and boundary ambiguity. Additionally, we observe a moderate positive correlation between nerve size and segmentation accuracy (Pearson r=0.587, p<0.001), indicating that smaller nerves remain a primary challenge. These findings provide methodological guidance for developing robust ultrasound nerve segmentation systems under realistic clinical data constraints.

</details>


### [113] [DVLA-RL: Dual-Level Vision-Language Alignment with Reinforcement Learning Gating for Few-Shot Learning](https://arxiv.org/abs/2602.00795)
*Wenhao Li,Xianjing Meng,Qiangchang Wang,Zhongyi Han,Zhibin Wu,Yilong Yin*

Main category: cs.CV

TL;DR: DVLA-RL通过双级语义对齐和强化学习门控注意力，显著提升少样本学习性能，达到新最优水平。


<details>
  <summary>Details</summary>
Motivation: 现有方法在少样本学习中忽视了视觉与语言从低层到高层的渐进对齐，导致语义增益有限。

Method: 提出了DVLA-RL方法，包括双级语义构建（DSC）和强化学习门控注意力（RLA）。DSC通过类名和支持样本生成判别性属性并合成连贯的类描述；RLA则通过强化学习动态调整自注意力和跨注意力机制，实现文本与视觉令牌的融合。

Result: DVLA-RL在三种不同的少样本学习场景下的九个基准测试中取得了最优性能。

Conclusion: DVLA-RL通过双级语义构建和强化学习门控注意力机制，实现了视觉与语言从低层到高层的渐进对齐，显著提升了少样本学习的性能，并在多个基准测试中达到了新的最优水平。

Abstract: Few-shot learning (FSL) aims to generalize to novel categories with only a few samples. Recent approaches incorporate large language models (LLMs) to enrich visual representations with semantic embeddings derived from class names. However, they overlook progressive and adaptive alignment between vision and language from low-level to high-level semantics, resulting in limited semantic gains. To address these challenges, we propose Dual-level Vision-Language Alignment with Reinforcement Learning gating (DVLA-RL), which consists of Dual-level Semantic Construction (DSC) and RL-gated Attention (RLA). Specifically, DSC conditions LLMs on both class names and support samples to generate discriminative attributes, progressively selects the most relevant ones, and then synthesizes them into coherent class descriptions. This process provides complementary low-level attributes and high-level descriptions, enabling both fine-grained grounding and holistic class understanding. To dynamically integrate dual-level semantics along with the visual network layers, RLA formulates cross-modal fusion as a sequential decision process. A lightweight policy trained with episodic REINFORCE adaptively adjusts the contributions of self-attention and cross-attention to integrate textual and visual tokens. As a result, shallow layers refine local attributes and deep layers emphasize global semantics, enabling more precise cross-modal alignment. This achieves class-specific discrimination and generalized representations with merely a few support samples. DVLA-RL achieves new state-of-the-art performance across nine benchmarks in three diverse FSL scenarios.

</details>


### [114] [Generating a Paracosm for Training-Free Zero-Shot Composed Image Retrieval](https://arxiv.org/abs/2602.00813)
*Tong Wang,Yunhan Zhao,Shu Kong*

Main category: cs.CV

TL;DR: Paracosm是一种无需训练的零样本CIR方法，通过LMM直接生成“心理图像”进行匹配，显著提升检索性能。


<details>
  <summary>Details</summary>
Motivation: 解决CIR任务中“心理图像”仅由查询隐式定义且无法直接获取的核心挑战。

Method: 使用LMM直接生成“心理图像”进行匹配，并为数据库中的每个真实图像生成合成对应物以减少领域差距。

Result: Paracosm在零样本CIR任务中表现优异，显著超越现有方法。

Conclusion: Paracosm方法在四个具有挑战性的基准测试中显著优于现有的零样本方法，实现了零样本CIR的最先进性能。

Abstract: Composed Image Retrieval (CIR) is the task of retrieving a target image from a database using a multimodal query, which consists of a reference image and a modification text. The text specifies how to alter the reference image to form a ``mental image'', based on which CIR should find the target image in the database. The fundamental challenge of CIR is that this ``mental image'' is not physically available and is only implicitly defined by the query. The contemporary literature pursues zero-shot methods and uses a Large Multimodal Model (LMM) to generate a textual description for a given multimodal query, and then employs a Vision-Language Model (VLM) for textual-visual matching to search the target image. In contrast, we address CIR from first principles by directly generating the ``mental image'' for more accurate matching. Particularly, we prompt an LMM to generate a ``mental image'' for a given multimodal query and propose to use this ``mental image'' to search for the target image. As the ``mental image'' has a synthetic-to-real domain gap with real images, we also generate a synthetic counterpart for each real image in the database to facilitate matching. In this sense, our method uses LMM to construct a ``paracosm'', where it matches the multimodal query and database images. Hence, we call this method Paracosm. Notably, Paracosm is a training-free zero-shot CIR method. It significantly outperforms existing zero-shot methods on four challenging benchmarks, achieving state-of-the-art performance for zero-shot CIR.

</details>


### [115] [Edge-Native Generative De-identification: Inversion-Free Flow for Privacy-Preserving Federated Skin Image Analysis](https://arxiv.org/abs/2602.00821)
*Konstantinos Moutselos,Ilias Maglogiannis*

Main category: cs.CV

TL;DR: 提出一种基于FlowEdit的框架，在边缘设备上实现身份无关的病理保留，平衡隐私与诊断需求，验证显示效果稳定。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习在临床皮肤病学中保护患者隐私与保留诊断特征之间的矛盾。

Method: 利用无反转的Rectified Flow Transformers（FlowEdit）进行高保真身份转换，并引入“Segment-by-Synthesis”机制生成反事实的健康和病理双胞胎对。

Result: 在高分辨率临床样本上的验证显示，合成身份的IoU稳定性大于0.67。

Conclusion: 该框架通过在边缘生成符合隐私要求的合成替代品，降低了梯度泄漏的风险，为联邦环境中高精度皮肤图像分析提供了安全途径。

Abstract: The deployment of Federated Learning (FL) for clinical dermatology is hindered by the competing requirements of protecting patient privacy and preserving diagnostic features. Traditional de-identification methods often degrade pathological fidelity, while standard generative editing techniques rely on computationally intensive inversion processes unsuitable for resource-constrained edge devices. We propose a framework for identity-agnostic pathology preservation that serves as a client-side privacy-preserving utility. By leveraging inversion-free Rectified Flow Transformers (FlowEdit), the system performs high-fidelity identity transformation in near real-time (less than 20s), facilitating local deployment on clinical nodes. We introduce a "Segment-by-Synthesis" mechanism that generates counterfactual healthy and pathological twin pairs locally. This enables the extraction of differential erythema masks that are decoupled from biometric markers and semantic artifacts (e.g. jewelry). Pilot validation on high-resolution clinical samples demonstrates an Intersection over Union (IoU) stability greater than 0.67 across synthetic identities. By generating privacy-compliant synthetic surrogates at the edge, this framework mitigates the risk of gradient leakage at the source, providing a secure pathway for high-precision skin image analysis in federated environments.

</details>


### [116] [TransNormal: Dense Visual Semantics for Diffusion-based Transparent Object Normal Estimation](https://arxiv.org/abs/2602.00839)
*Mingwei Li,Hehe Fan,Yi Yang*

Main category: cs.CV

TL;DR: TransNormal利用扩散先验和DINOv3语义提升透明物体法线估计，显著优于现有方法，并发布了合成数据集。


<details>
  <summary>Details</summary>
Motivation: 透明物体的复杂光学特性（如折射和反射）导致传统深度和法线传感器失效，阻碍了AI在科学环境中的部署，因此需要新的解决方案。

Method: TransNormal框架结合了扩散先验的单步法线回归、DINOv3的跨注意力机制、多任务学习目标和小波正则化，以处理透明表面的纹理缺失并保留细节。

Result: 在ClearGrasp基准上，TransNormal将平均误差降低了24.4%，11.25°精度提升了22.8%；在ClearPose上，平均误差减少了15.2%。

Conclusion: TransNormal通过整合预训练的扩散先验和DINOv3的密集视觉语义，显著提升了透明物体单目法线估计的精度，为实验室自动化提供了有效解决方案。

Abstract: Monocular normal estimation for transparent objects is critical for laboratory automation, yet it remains challenging due to complex light refraction and reflection. These optical properties often lead to catastrophic failures in conventional depth and normal sensors, hindering the deployment of embodied AI in scientific environments. We propose TransNormal, a novel framework that adapts pre-trained diffusion priors for single-step normal regression. To handle the lack of texture in transparent surfaces, TransNormal integrates dense visual semantics from DINOv3 via a cross-attention mechanism, providing strong geometric cues. Furthermore, we employ a multi-task learning objective and wavelet-based regularization to ensure the preservation of fine-grained structural details. To support this task, we introduce TransNormal-Synthetic, a physics-based dataset with high-fidelity normal maps for transparent labware. Extensive experiments demonstrate that TransNormal significantly outperforms state-of-the-art methods: on the ClearGrasp benchmark, it reduces mean error by 24.4% and improves 11.25° accuracy by 22.8%; on ClearPose, it achieves a 15.2% reduction in mean error. The code and dataset will be made publicly available at https://longxiang-ai.github.io/TransNormal.

</details>


### [117] [Invariance on Manifolds: Understanding Robust Visual Representations for Place Recognition](https://arxiv.org/abs/2602.00841)
*Jintao Cheng,Weibin Li,Zhijian He,Jin Wu,Chi Man Vong,Wei Zhang*

Main category: cs.CV

TL;DR: 提出一种基于二阶几何统计的无训练框架，通过SPD流形和黎曼映射提升视觉地点识别的零样本泛化能力，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前视觉地点识别（VPR）的聚合方法要么依赖数据密集的监督，要么仅使用简单的一阶统计，忽略了内在结构相关性，因此需要一种无需训练且能捕获几何稳定性的方法。

Method: 采用二阶几何统计框架，将场景建模为SPD流形上的协方差描述符，利用黎曼映射将其线性化为欧几里得嵌入，从而分离信号结构与噪声。

Result: 实验表明，该方法在零样本场景中表现优异，性能与最先进的基线模型相当。

Conclusion: 该论文提出的基于二阶几何统计的框架在无需训练的情况下，通过SPD流形上的协方差描述符和黎曼映射，实现了对视觉地点识别的强零样本泛化能力，并在实验中表现出色。

Abstract: Visual Place Recognition (VPR) demands representations robust to drastic environmental and viewpoint shifts. Current aggregation paradigms, however, either rely on data-hungry supervision or simplistic first-order statistics, often neglecting intrinsic structural correlations. In this work, we propose a Second-Order Geometric Statistics framework that inherently captures geometric stability without training. We conceptualize scenes as covariance descriptors on the Symmetric Positive Definite (SPD) manifold, where perturbations manifest as tractable congruence transformations. By leveraging geometry-aware Riemannian mappings, we project these descriptors into a linearized Euclidean embedding, effectively decoupling signal structure from noise. Our approach introduces a training-free framework built upon fixed, pre-trained backbones, achieving strong zero-shot generalization without parameter updates. Extensive experiments confirm that our method achieves highly competitive performance against state-of-the-art baselines, particularly excelling in challenging zero-shot scenarios.

</details>


### [118] [Distill3R: A Pipeline for Democratizing 3D Foundation Models on Commodity Hardware](https://arxiv.org/abs/2602.00865)
*Brandon Leblanc,Charalambos Poullis*

Main category: cs.CV

TL;DR: Distill3R通过蒸馏技术将大型3D模型的几何推理能力压缩到小型学生模型中，使其可在单工作站上训练，降低了计算资源需求。


<details>
  <summary>Details</summary>
Motivation: 解决大型3D基础模型依赖大规模计算集群训练的问题，降低学术实验室的研究门槛。

Method: 方法包括：(1)离线缓存管道，通过压缩监督信号将繁重的教师推理与训练循环解耦；(2)基于教师不确定性的置信感知蒸馏损失，支持在普通硬件上训练。

Result: 提出的72M参数学生模型相比650M参数的教师模型，参数减少9倍，推理速度提升5倍，且在单工作站上3天内可完成训练，同时保持了结构一致性和几何理解能力。

Conclusion: Distill3R框架通过蒸馏大型3D基础模型的几何推理能力，为学术实验室提供了在单工作站上可训练的紧凑学生模型，显著降低了计算资源需求，促进了3D视觉研究的民主化。

Abstract: While multi-view 3D reconstruction has shifted toward large-scale foundation models capable of inferring globally consistent geometry, their reliance on massive computational clusters for training has created a significant barrier to entry for most academic laboratories. To bridge this compute divide, we introduce Distill3R, a framework designed to distill the geometric reasoning of 3D foundation models into compact students fully trainable on a single workstation. Our methodology centers on two primary innovations: (1) an offline caching pipeline that decouples heavy teacher inference from the training loop through compressed supervision signals, and (2) a confidence-aware distillation loss that leverages teacher uncertainty to enable training on commodity hardware. We propose a 72M-parameter student model which achieves a 9x reduction in parameters and a 5x inference speedup compared to its 650M-parameter teacher. The student is fully trainable in under 3 days on a single workstation, whereas its teacher requires massive GPU clusters for up to a week. We demonstrate that the student preserves the structural consistency and qualitative geometric understanding required for functional 3D awareness. By providing a reproducible, single-workstation training recipe, Distill3R serves as an exploratory entry point for democratized 3D vision research and efficient edge deployment. This work is not intended to compete with state-of-the-art foundation models, but to provide an accessible research baseline for laboratories without access to large-scale compute to train and specialize models on their own domain-specific data at minimal cost.

</details>


### [119] [DIAMOND: Directed Inference for Artifact Mitigation in Flow Matching Models](https://arxiv.org/abs/2602.00883)
*Alicja Polowczyk,Agnieszka Polowczyk,Piotr Borycki,Joanna Waczyńska,Jacek Tabor,Przemysław Spurek*

Main category: cs.CV

TL;DR: DIAMOND 是一种无需训练的轨迹校正方法，有效减少文本到图像生成中的伪影，适用于现代生成架构。


<details>
  <summary>Details</summary>
Motivation: 现有伪影减少方法通常在生成后处理，无法在核心图像形成过程中有效干预，且需要侵入性模型权重修改或计算密集型区域细化。

Method: DIAMOND 通过在生成轨迹的每一步重建干净样本的估计，主动引导生成过程避开可能导致伪影的潜在状态。

Result: DIAMOND 展示了在标准扩散模型中实现高保真、无伪影图像合成的能力，无需额外训练或权重修改。

Conclusion: DIAMOND 提供了一种无需训练的零样本方法，有效减少文本到图像生成中的伪影，适用于现代生成架构。

Abstract: Despite impressive results from recent text-to-image models like FLUX, visual and anatomical artifacts remain a significant hurdle for practical and professional use. Existing methods for artifact reduction, typically work in a post-hoc manner, consequently failing to intervene effectively during the core image formation process. Notably, current techniques require problematic and invasive modifications to the model weights, or depend on a computationally expensive and time-consuming process of regional refinement. To address these limitations, we propose DIAMOND, a training-free method that applies trajectory correction to mitigate artifacts during inference. By reconstructing an estimate of the clean sample at every step of the generative trajectory, DIAMOND actively steers the generation process away from latent states that lead to artifacts. Furthermore, we extend the proposed method to standard Diffusion Models, demonstrating that DIAMOND provides a robust, zero-shot path to high-fidelity, artifact-free image synthesis without the need for additional training or weight modifications in modern generative architectures. Code is available at https://gmum.github.io/DIAMOND/

</details>


### [120] [OCTOPUS: Enhancing the Spatial-Awareness of Vision SSMs with Multi-Dimensional Scans and Traversal Selection](https://arxiv.org/abs/2602.00904)
*Kunal Mahatha,Ali Bahri,Pierre Marza,Sahar Dastani,Maria Vakalopoulou,Stergios Christodoulidis,Jose Dolz,Christian Desrosiers*

Main category: cs.CV

TL;DR: OCTOPUS是一种新型架构，通过多方向递归保留图像的全局上下文和局部空间结构，解决了标准SSM在视觉任务中的局限性，并在分类和分割任务中表现出色。


<details>
  <summary>Details</summary>
Motivation: 标准SSM在视觉任务中表现受限，因其因果性破坏了像素或补丁间的固有空间关系，导致无法捕捉局部空间连贯性。OCTOPUS旨在解决这一问题。

Method: OCTOPUS通过沿八个主要方向（水平、垂直和对角线方向的前后）进行离散递归，实现了全局上下文和局部空间结构的保留，同时保持SSM的线性复杂度。

Result: 在分类和分割基准测试中，OCTOPUS在边界保持和区域一致性方面表现显著优于现有V-SSM模型，同时保持了相对较好的分类准确率。

Conclusion: OCTOPUS作为一种基础方法，通过多方向递归机制，为构建空间感知且计算高效的视觉架构提供了可扩展且有效的解决方案。

Abstract: State space models (SSMs) have recently emerged as an alternative to transformers due to their unique ability of modeling global relationships in text with linear complexity. However, their success in vision tasks has been limited due to their causal formulation, which is suitable for sequential text but detrimental in the spatial domain where causality breaks the inherent spatial relationships among pixels or patches. As a result, standard SSMs fail to capture local spatial coherence, often linking non-adjacent patches while ignoring neighboring ones that are visually correlated. To address these limitations, we introduce OCTOPUS , a novel architecture that preserves both global context and local spatial structure within images, while maintaining the linear complexity of SSMs. OCTOPUS performs discrete reoccurrence along eight principal orientations, going forward or backward in the horizontal, vertical, and diagonal directions, allowing effective information exchange across all spatially connected regions while maintaining independence among unrelated patches. This design enables multi-directional recurrence, capturing both global context and local spatial structure with SSM-level efficiency. In our classification and segmentation benchmarks, OCTOPUS demonstrates notable improvements in boundary preservation and region consistency, as evident from the segmentation results, while maintaining relatively better classification accuracy compared to existing V-SSM based models. These results suggest that OCTOPUS appears as a foundation method for multi-directional recurrence as a scalable and effective mechanism for building spatially aware and computationally efficient vision architectures.

</details>


### [121] [ConsensusDrop: Fusing Visual and Cross-Modal Saliency for Efficient Vision Language Models](https://arxiv.org/abs/2602.00946)
*Dhruv Parikh,Haoyang Fan,Rajgopal Kannan,Viktor Prasanna*

Main category: cs.CV

TL;DR: ConsensusDrop融合视觉和语言信号优化令牌选择，提升VLMs效率与准确性。


<details>
  <summary>Details</summary>
Motivation: 现有令牌缩减方法仅依赖单一信号（视觉编码器显著性或LLM交叉注意力），效果有限，需融合两者以提升性能。

Method: 提出ConsensusDrop框架，结合视觉编码器显著性和LLM交叉注意力，生成共识排名，并进行令牌合并。

Result: 在多个VLMs上，ConsensusDrop在相同令牌预算下优于现有修剪方法，保持高准确性同时减少计算开销。

Conclusion: ConsensusDrop通过融合视觉编码器显著性和查询感知的交叉注意力，实现了更高效的视觉令牌选择和压缩，显著提升了视觉语言模型的效率和准确性。

Abstract: Vision-Language Models (VLMs) are expensive because the LLM processes hundreds of largely redundant visual tokens. Existing token reduction methods typically exploit \textit{either} vision-encoder saliency (broad but query-agnostic) \textit{or} LLM cross-attention (query-aware but sparse and costly). We show that neither signal alone is sufficient: fusing them consistently improves performance compared to unimodal visual token selection (ranking). However, making such fusion practical is non-trivial: cross-modal saliency is usually only available \emph{inside} the LLM (too late for efficient pre-LLM pruning), and the two signals are inherently asymmetric, so naive fusion underutilizes their complementary strengths. We propose \textbf{ConsensusDrop}, a training-free framework that derives a \emph{consensus} ranking by reconciling vision encoder saliency with query-aware cross-attention, retaining the most informative tokens while compressing the remainder via encoder-guided token merging. Across LLaVA-1.5/NeXT, Video-LLaVA, and other open-source VLMs, ConsensusDrop consistently outperforms prior pruning methods under identical token budgets and delivers a stronger accuracy-efficiency Pareto frontier -- preserving near-baseline accuracy even at aggressive token reductions while reducing TTFT and KV cache footprint. Our code will be open-sourced.

</details>


### [122] [Data Augmentation for High-Fidelity Generation of CAR-T/NK Immunological Synapse Images](https://arxiv.org/abs/2602.00949)
*Xiang Zhang,Boxuan Zhang,Alireza Naghizadeh,Mohab Mohamed,Dongfang Liu,Ruixiang Tang,Dimitris Metaxas,Dongfang Liu*

Main category: cs.CV

TL;DR: 本研究通过IAAA和SAAA两种数据增强方法，解决了CAR-T/NK免疫突触（IS）图像数据不足的问题，提升了IS检测和分割的准确性，为免疫疗法疗效预测提供了更可靠的生物标志物。


<details>
  <summary>Details</summary>
Motivation: CAR-T/NK细胞免疫疗法的疗效预测需要依赖免疫突触（IS）的功能性生物标志物，但现有的标注显微镜数据集规模有限，限制了人工神经网络（ANNs）的泛化能力。

Method: 本研究整合了两种互补的数据增强框架：Instance Aware Automatic Augmentation (IAAA) 和 Semantic-Aware AI Augmentation (SAAA)。IAAA是一种自动化的、保留实例的增强方法，通过应用优化的增强策略生成合成图像和分割掩码。SAAA则结合了基于扩散的掩码生成器和Pix2Pix条件图像合成器，生成多样化的、解剖学上真实的分割掩码和高保真图像。

Result: 这两种增强策略生成的合成图像在视觉和结构特性上与真实IS数据高度匹配，显著提高了CAR-T/NK IS的检测和分割性能。

Conclusion: 通过结合IAAA和SAAA两种数据增强框架，本研究显著提升了CAR-T/NK细胞免疫突触（IS）的检测和分割性能，为预测患者对CAR-T/NK免疫疗法的反应提供了更可靠的成像生物标志物。

Abstract: Chimeric antigen receptor (CAR)-T and NK cell immunotherapies have transformed cancer treatment, and recent studies suggest that the quality of the CAR-T/NK cell immunological synapse (IS) may serve as a functional biomarker for predicting therapeutic efficacy. Accurate detection and segmentation of CAR-T/NK IS structures using artificial neural networks (ANNs) can greatly increase the speed and reliability of IS quantification. However, a persistent challenge is the limited size of annotated microscopy datasets, which restricts the ability of ANNs to generalize. To address this challenge, we integrate two complementary data-augmentation frameworks. First, we employ Instance Aware Automatic Augmentation (IAAA), an automated, instance-preserving augmentation method that generates synthetic CAR-T/NK IS images and corresponding segmentation masks by applying optimized augmentation policies to original IS data. IAAA supports multiple imaging modalities (e.g., fluorescence and brightfield) and can be applied directly to CAR-T/NK IS images derived from patient samples. In parallel, we introduce a Semantic-Aware AI Augmentation (SAAA) pipeline that combines a diffusion-based mask generator with a Pix2Pix conditional image synthesizer. This second method enables the creation of diverse, anatomically realistic segmentation masks and produces high-fidelity CAR-T/NK IS images aligned with those masks, further expanding the training corpus beyond what IAAA alone can provide. Together, these augmentation strategies generate synthetic images whose visual and structural properties closely match real IS data, significantly improving CAR-T/NK IS detection and segmentation performance. By enhancing the robustness and accuracy of IS quantification, this work supports the development of more reliable imaging-based biomarkers for predicting patient response to CAR-T/NK immunotherapy.

</details>


### [123] [Hybrid Topological and Deep Feature Fusion for Accurate MRI-Based Alzheimer's Disease Severity Classification](https://arxiv.org/abs/2602.00956)
*Faisal Ahmed*

Main category: cs.CV

TL;DR: 提出TDA+DenseNet121混合框架，通过融合拓扑和深度特征显著提升AD分类性能，准确率达99.93%。


<details>
  <summary>Details</summary>
Motivation: 阿尔茨海默病的早期和准确诊断是神经影像临床决策支持系统的关键挑战，传统神经网络常忽略脑结构的拓扑特征。

Method: 提出了一种新颖的混合深度学习框架，结合拓扑数据分析（TDA）和DenseNet121，用于从OASIS数据集的MRI数据中提取拓扑和深度特征，并进行四分类。

Result: 在OASIS-1 Kaggle MRI数据集上的实验表明，该模型准确率达99.93%，AUC为100%，优于现有最先进方法。

Conclusion: 该研究提出的结合拓扑数据分析和DenseNet121的混合深度学习框架，显著提升了阿尔茨海默病的分类准确率，验证了将拓扑特征融入深度学习流程的有效性，并展示了其作为自动化诊断工具的潜力。

Abstract: Early and accurate diagnosis of Alzheimer's disease (AD) remains a critical challenge in neuroimaging-based clinical decision support systems. In this work, we propose a novel hybrid deep learning framework that integrates Topological Data Analysis (TDA) with a DenseNet121 backbone for four-class Alzheimer's disease classification using structural MRI data from the OASIS dataset. TDA is employed to capture complementary topological characteristics of brain structures that are often overlooked by conventional neural networks, while DenseNet121 efficiently learns hierarchical spatial features from MRI slices. The extracted deep and topological features are fused to enhance class separability across the four AD stages.
  Extensive experiments conducted on the OASIS-1 Kaggle MRI dataset demonstrate that the proposed TDA+DenseNet121 model significantly outperforms existing state-of-the-art approaches. The model achieves an accuracy of 99.93% and an AUC of 100%, surpassing recently published CNN-based, transfer learning, ensemble, and multi-scale architectures. These results confirm the effectiveness of incorporating topological insights into deep learning pipelines and highlight the potential of the proposed framework as a robust and highly accurate tool for automated Alzheimer's disease diagnosis.

</details>


### [124] [Unveiling the Cognitive Compass: Theory-of-Mind-Guided Multimodal Emotion Reasoning](https://arxiv.org/abs/2602.00971)
*Meng Luo,Bobo Li,Shanqing Xu,Shize Zhang,Qiuchan Chen,Menglu Han,Wenhao Chen,Yanxiang Huang,Hao Fei,Mong-Li Lee,Wynne Hsu*

Main category: cs.CV

TL;DR: 研究提出HitEmotion基准和ToM引导的推理方法，增强MLLMs的深度情感理解能力。


<details>
  <summary>Details</summary>
Motivation: 尽管MLLMs在多模态方面进展迅速，但在深度情感理解方面的能力仍然有限，需要显式建模情感产生的认知基础——心理理论（ToM）。

Method: 提出了一个基于ToM的分层基准HitEmotion，以及ToM引导的推理链和TMPO强化学习方法。

Result: 实验表明，HitEmotion揭示了最先进模型在深度情感推理上的缺陷，ToM引导的推理链和TMPO提高了任务准确性和推理的连贯性。

Conclusion: 本研究为研究社区提供了一个实用的工具包，用于评估和增强基于认知的MLLMs情感理解能力。

Abstract: Despite rapid progress in multimodal large language models (MLLMs), their capability for deep emotional understanding remains limited. We argue that genuine affective intelligence requires explicit modeling of Theory of Mind (ToM), the cognitive substrate from which emotions arise. To this end, we introduce HitEmotion, a ToM-grounded hierarchical benchmark that diagnoses capability breakpoints across increasing levels of cognitive depth. Second, we propose a ToM-guided reasoning chain that tracks mental states and calibrates cross-modal evidence to achieve faithful emotional reasoning. We further introduce TMPO, a reinforcement learning method that uses intermediate mental states as process-level supervision to guide and strengthen model reasoning. Extensive experiments show that HitEmotion exposes deep emotional reasoning deficits in state-of-the-art models, especially on cognitively demanding tasks. In evaluation, the ToM-guided reasoning chain and TMPO improve end-task accuracy and yield more faithful, more coherent rationales. In conclusion, our work provides the research community with a practical toolkit for evaluating and enhancing the cognition-based emotional understanding capabilities of MLLMs. Our dataset and code are available at: https://HitEmotion.github.io/.

</details>


### [125] [VAMOS-OCTA: Vessel-Aware Multi-Axis Orthogonal Supervision for Inpainting Motion-Corrupted OCT Angiography Volumes](https://arxiv.org/abs/2602.00995)
*Nick DiSanto,Ehsan Khodapanah Aghdam,Han Liu,Jacob Watson,Yuankai K. Tao,Hao Li,Ipek Oguz*

Main category: cs.CV

TL;DR: VAMOS-OCTA是一种深度学习框架，通过多轴监督修复运动损坏的OCTA B扫描，显著提升图像质量。


<details>
  <summary>Details</summary>
Motivation: 手持OCTA在非合作或儿科患者中易受运动伪影影响，导致图像质量下降，需一种方法修复未采样的视网膜区域。

Method: 采用2.5D U-Net架构，结合血管感知多轴正交监督（VAMOS）损失函数，通过邻近B扫描堆叠重建损坏的中心B扫描。

Result: VAMOS-OCTA在合成和真实损坏数据上均优于现有方法，能恢复清晰的毛细血管和血管连续性。

Conclusion: VAMOS-OCTA通过多轴监督有效修复了运动伪影导致的OCTA图像损坏，显著提升了B扫描和容积投影的质量。

Abstract: Handheld Optical Coherence Tomography Angiography (OCTA) enables noninvasive retinal imaging in uncooperative or pediatric subjects, but is highly susceptible to motion artifacts that severely degrade volumetric image quality. Sudden motion during 3D acquisition can lead to unsampled retinal regions across entire B-scans (cross-sectional slices), resulting in blank bands in en face projections. We propose VAMOS-OCTA, a deep learning framework for inpainting motion-corrupted B-scans using vessel-aware multi-axis supervision. We employ a 2.5D U-Net architecture that takes a stack of neighboring B-scans as input to reconstruct a corrupted center B-scan, guided by a novel Vessel-Aware Multi-Axis Orthogonal Supervision (VAMOS) loss. This loss combines vessel-weighted intensity reconstruction with axial and lateral projection consistency, encouraging vascular continuity in native B-scans and across orthogonal planes. Unlike prior work that focuses primarily on restoring the en face MIP, VAMOS-OCTA jointly enhances both cross-sectional B-scan sharpness and volumetric projection accuracy, even under severe motion corruptions. We trained our model on both synthetic and real-world corrupted volumes and evaluated its performance using both perceptual quality and pixel-wise accuracy metrics. VAMOS-OCTA consistently outperforms prior methods, producing reconstructions with sharp capillaries, restored vessel continuity, and clean en face projections. These results demonstrate that multi-axis supervision offers a powerful constraint for restoring motion-degraded 3D OCTA data. Our source code is available at https://github.com/MedICL-VU/VAMOS-OCTA.

</details>


### [126] [CortiNet: A Physics-Perception Hybrid Cortical-Inspired Dual-Stream Network for Gallbladder Disease Diagnosis from Ultrasound](https://arxiv.org/abs/2602.01000)
*Vagish Kumar,Souvik Chakraborty*

Main category: cs.CV

TL;DR: CortiNet 是一种轻量级双流神经网络，通过分离结构信息和感知细节，显著提升胆囊疾病超声诊断的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 超声成像因其非侵入性、经济性和广泛可用性成为胆囊疾病的主要诊断方式，但其低分辨率和斑点噪声影响了诊断可靠性，而传统大型卷积神经网络难以在常规临床环境中部署。

Method: CortiNet 采用双流架构，分别处理低频结构信息和高频感知细节，并通过专门的编码流进行特征学习。后期采用皮层式融合机制整合互补的结构和纹理线索。

Result: 在10,692张专家标注的图像上评估，CortiNet 实现了高诊断准确率（98.74%），且参数数量远少于传统深度卷积模型。

Conclusion: CortiNet 是一种轻量级、受皮层启发的双流神经架构，通过整合物理可解释的多尺度信号分解和感知驱动的特征学习，显著提高了胆囊疾病诊断的准确性和计算效率。

Abstract: Ultrasound imaging is the primary diagnostic modality for detecting Gallbladder diseases due to its non-invasive nature, affordability, and wide accessibility. However, the low resolution and speckle noise inherent to ultrasound images hinder diagnostic reliability, prompting the use of large convolutional neural networks that are difficult to deploy in routine clinical settings. In this work, we propose CortiNet, a lightweight, cortical-inspired dual-stream neural architecture for gallbladder disease diagnosis that integrates physically interpretable multi-scale signal decomposition with perception-driven feature learning. Inspired by parallel processing pathways in the human visual cortex, CortiNet explicitly separates low-frequency structural information from high-frequency perceptual details and processes them through specialized encoding streams. By operating directly on structured, frequency-selective representations rather than raw pixel intensities, the architecture embeds strong physics-based inductive bias, enabling efficient feature learning with a significantly reduced parameter footprint. A late-stage cortical-style fusion mechanism integrates complementary structural and textural cues while preserving computational efficiency. Additionally, we propose a structure-aware explainability framework wherein gradient-weighted class activation mapping is only applied to the structural branch of the proposed CortiNet architecture. This choice allows the model to only focus on the structural features, making it robust against speckle noise. We evaluate CortiNet on 10,692 expert-annotated images spanning nine clinically relevant gallbladder disease categories. Experimental results demonstrate that CortiNet achieves high diagnostic accuracy (98.74%) with only a fraction of the parameters required by conventional deep convolutional models.

</details>


### [127] [SRVAU-R1: Enhancing Video Anomaly Understanding via Reflection-Aware Learning](https://arxiv.org/abs/2602.01004)
*Zihao Zhao,Shengting Cao,Muchao Ye*

Main category: cs.CV

TL;DR: SRVAU-R1通过反思增强的多模态推理框架，显著提升视频异常理解任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM方法在视频异常理解任务中缺乏对异常行为的深度推理，如显式自我反思和自我纠正。

Method: 提出了SRVAU-R1框架，包括首个面向反思的Chain-of-Thought数据集和反思意识的学习范式，结合监督微调和强化微调。

Result: 在多个视频异常基准测试中，SRVAU-R1 consistently outperforms existing methods，显著提升了时间异常定位准确性和推理质量。

Conclusion: SRVAU-R1通过引入反思意识的学习框架，显著提升了多模态大语言模型在视频异常理解任务中的表现，特别是在时间异常定位准确性和推理质量方面。

Abstract: Multi-modal large language models (MLLMs) have demonstrated significant progress in reasoning capabilities and shown promising effectiveness in video anomaly understanding (VAU) tasks. However, existing MLLM-based approaches remain largely focused on surface-level descriptions of anomalies, lacking deep reasoning over abnormal behaviors like explicit self-reflection and self-correction. To address that, we propose Self-Reflection-Enhanced Reasoning for Video Anomaly Understanding (SRVAU-R1), a reflection-aware learning framework that incorporates reflection in MLLM reasoning. Specifically, SRVAU-R1 introduces the first reflection-oriented Chain-of-Thought dataset tailored for VAU, providing structured supervision with initial reasoning, self-reflection, and revised reasoning. Based on that, it includes a novel reflection-aware learning paradigm with supervised fine-tuning and reinforcement fine-tuning to enhance multi-modal reasoning for VAU. Extensive experiments on multiple video anomaly benchmarks demonstrate that SRVAU-R1 consistently outperforms existing methods, achieving significant improvements in both temporal anomaly localization accuracy and reasoning quality.

</details>


### [128] [LocalScore: Local Density-Aware Similarity Scoring for Biometrics](https://arxiv.org/abs/2602.01012)
*Yiyang Su,Minchul Kim,Jie Zhu,Christopher Perry,Feng Liu,Anil Jain,Xiaoming Liu*

Main category: cs.CV

TL;DR: LocalScore是一种利用k近邻局部密度优化开放集生物识别的算法，显著提升性能且计算高效。


<details>
  <summary>Details</summary>
Motivation: 传统生物识别系统将多样本图库的类内变异压缩为单一全局表示，导致开放集鲁棒性差。

Method: 提出LocalScore算法，利用k近邻显式结合图库特征分布的局部密度，优化决策边界。

Result: 在多种模态上，LocalScore显著提升开放集检索（FNIR@FPIR从53%降至40%）和验证（TAR@FAR从51%提升至74%）性能。

Conclusion: LocalScore通过显式利用图库特征分布的局部密度，显著提升了开放集生物识别的检索和验证性能，且具有架构无关性和低计算开销。

Abstract: Open-set biometrics faces challenges with probe subjects who may not be enrolled in the gallery, as traditional biometric systems struggle to detect these non-mated probes. Despite the growing prevalence of multi-sample galleries in real-world deployments, most existing methods collapse intra-subject variability into a single global representation, leading to suboptimal decision boundaries and poor open-set robustness. To address this issue, we propose LocalScore, a simple yet effective scoring algorithm that explicitly incorporates the local density of the gallery feature distribution using the k-th nearest neighbors. LocalScore is architecture-agnostic, loss-independent, and incurs negligible computational overhead, making it a plug-and-play solution for existing biometric systems. Extensive experiments across multiple modalities demonstrate that LocalScore consistently achieves substantial gains in open-set retrieval (FNIR@FPIR reduced from 53% to 40%) and verification (TAR@FAR improved from 51% to 74%). We further provide theoretical analysis and empirical validation explaining when and why the method achieves the most significant gains based on dataset characteristics.

</details>


### [129] [Effectiveness of Automatically Curated Dataset in Thyroid Nodules Classification Algorithms Using Deep Learning](https://arxiv.org/abs/2602.01020)
*Jichen Yang,Jikai Zhang,Benjamin Wildman-Tobriner,Maciej A. Mazurowski*

Main category: cs.CV

TL;DR: 自动整理的数据集能显著提升深度学习模型性能，且使用全部数据优于仅用高准确度子集。


<details>
  <summary>Details</summary>
Motivation: 探讨自动整理的数据集是否能够提升深度学习算法在甲状腺结节分类中的性能。

Method: 在手动标注和自动整理的数据集上训练深度学习模型，并探索高准确度子集的最优使用方式。

Result: 自动整理数据集训练的模型AUC为0.694，显著优于手动标注数据集的0.643；高准确度子集训练的模型AUC为0.689，与全数据集无显著差异。

Conclusion: 使用自动整理的数据集可以显著提高深度学习算法的性能，建议使用全部数据而非仅使用高准确度子集。

Abstract: The diagnosis of thyroid nodule cancers commonly utilizes ultrasound images. Several studies showed that deep learning algorithms designed to classify benign and malignant thyroid nodules could match radiologists' performance. However, data availability for training deep learning models is often limited due to the significant effort required to curate such datasets. The previous study proposed a method to curate thyroid nodule datasets automatically. It was tested to have a 63% yield rate and 83% accuracy. However, the usefulness of the generated data for training deep learning models remains unknown. In this study, we conducted experiments to determine whether using a automatically-curated dataset improves deep learning algorithms' performance. We trained deep learning models on the manually annotated and automatically-curated datasets. We also trained with a smaller subset of the automatically-curated dataset that has higher accuracy to explore the optimum usage of such dataset. As a result, the deep learning model trained on the manually selected dataset has an AUC of 0.643 (95% confidence interval [CI]: 0.62, 0.66). It is significantly lower than the AUC of the 6automatically-curated dataset trained deep learning model, 0.694 (95% confidence interval [CI]: 0.67, 0.73, P < .001). The AUC of the accurate subset trained deep learning model is 0.689 (95% confidence interval [CI]: 0.66, 0.72, P > .43), which is insignificantly worse than the AUC of the full automatically-curated dataset. In conclusion, we showed that using a automatically-curated dataset can substantially increase the performance of deep learning algorithms, and it is suggested to use all the data rather than only using the accurate subset.

</details>


### [130] [GMAC: Global Multi-View Constraint for Automatic Multi-Camera Extrinsic Calibration](https://arxiv.org/abs/2602.01033)
*Chentian Sun*

Main category: cs.CV

TL;DR: GMAC是一种基于隐式几何表示的多相机外参估计框架，通过联合优化几何一致性实现高效校准，适用于复杂动态环境。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在复杂动态环境或在线场景中鲁棒性和适用性不足的问题，提出一种无需依赖校准目标、显式几何建模或任务特定神经网络的多相机外参估计框架。

Method: GMAC利用多视角重建网络的隐式几何表示，将外参建模为受潜在多视角几何结构约束的全局变量，并通过轻量级回归头直接预测外参，无需全新网络设计。同时，联合优化跨视角重投影一致性和多视角循环一致性。

Result: 在合成和真实多相机数据集上的实验表明，GMAC能够实现准确稳定的外参估计，无需显式3D重建或手动校准。

Conclusion: GMAC提出了一种基于隐式几何表示的多相机外参估计框架，通过联合优化重投影一致性和多视角循环一致性，实现了无需显式3D重建或手动校准的准确外参估计，为多相机系统的高效部署和在线校准提供了新解决方案。

Abstract: Automatic calibration of multi-camera systems, namely the accurate estimation of spatial extrinsic parameters, is fundamental for 3D reconstruction, panoramic perception, and multi-view data fusion. Existing methods typically rely on calibration targets, explicit geometric modeling, or task-specific neural networks. Such approaches often exhibit limited robustness and applicability in complex dynamic environments or online scenarios, making them difficult to deploy in practical applications. To address this, this paper proposes GMAC, a multi-camera extrinsic estimation framework based on the implicit geometric representations learned by multi-view reconstruction networks. GMAC models extrinsics as global variables constrained by the latent multi-view geometric structure and prunes and structurally reconfigures existing networks so that their latent features can directly support extrinsic prediction through a lightweight regression head, without requiring a completely new network design. Furthermore, GMAC jointly optimizes cross-view reprojection consistency and multi-view cycle consistency, ensuring geometric coherence across cameras while improving prediction accuracy and optimization stability. Experiments on both synthetic and real-world multi-camera datasets demonstrate that GMAC achieves accurate and stable extrinsic estimation without explicit 3D reconstruction or manual calibration, providing a new solution for efficient deployment and online calibration of multi-camera systems.

</details>


### [131] [FUSE-Flow: Scalable Real-Time Multi-View Point Cloud Reconstruction Using Confidence](https://arxiv.org/abs/2602.01035)
*Chentian Sun*

Main category: cs.CV

TL;DR: FUSE-Flow是一个实时、高效的多视角点云重建框架，通过双权重融合和自适应空间哈希方法，解决了现有技术在高计算复杂性和内存使用上的瓶颈。


<details>
  <summary>Details</summary>
Motivation: 多视角点云实时重建在3D视觉和沉浸式感知中应用广泛，但现有方法因计算复杂性和内存限制难以兼顾实时性、质量和可扩展性。

Method: FUSE-Flow采用帧间独立处理、双权重融合（测量置信度和3D距离一致性）以及自适应空间哈希的加权聚合方法，优化了稀疏和密集区域的点云融合。

Result: 实验表明，FUSE-Flow在重叠、深度不连续和动态场景中提升了重建稳定性和几何保真度，同时在现代GPU上保持实时帧率。

Conclusion: FUSE-Flow框架通过高效的GPU并行化和自适应空间哈希方法，实现了实时、高质量的多视角点云重建，并在实验中验证了其有效性、鲁棒性和可扩展性。

Abstract: Real-time multi-view point cloud reconstruction is a core problem in 3D vision and immersive perception, with wide applications in VR, AR, robotic navigation, digital twins, and computer interaction. Despite advances in multi-camera systems and high-resolution depth sensors, fusing large-scale multi-view depth observations into high-quality point clouds under strict real-time constraints remains challenging. Existing methods relying on voxel-based fusion, temporal accumulation, or global optimization suffer from high computational complexity, excessive memory usage, and limited scalability, failing to simultaneously achieve real-time performance, reconstruction quality, and multi-camera extensibility. We propose FUSE-Flow, a frame-wise, stateless, and linearly scalable point cloud streaming reconstruction framework. Each frame independently generates point cloud fragments, fused via two weights, measurement confidence and 3D distance consistency to suppress noise while preserving geometric details. For large-scale multi-camera efficiency, we introduce an adaptive spatial hashing-based weighted aggregation method: 3D space is adaptively partitioned by local point cloud density, representative points are selected per cell, and weighted fusion is performed to handle both sparse and dense regions. With GPU parallelization, FUSE-Flow achieves high-throughput, low-latency point cloud generation and fusion with linear complexity. Experiments demonstrate that the framework improves reconstruction stability and geometric fidelity in overlapping, depth-discontinuous, and dynamic scenes, while maintaining real-time frame rates on modern GPUs, verifying its effectiveness, robustness, and scalability.

</details>


### [132] [VEQ: Modality-Adaptive Quantization for MoE Vision-Language Models](https://arxiv.org/abs/2602.01037)
*Guangshuo Qin,Zhiteng Li,Zheng Chen,Weihang Zhang,Linghe Kong,Yulun Zhang*

Main category: cs.CV

TL;DR: VEQ是一种双感知量化框架，针对混合专家视觉语言模型的跨模态和专家异质性优化，实验显示其显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有量化方法忽视了视觉与语言token的固有差异及专家贡献的非均匀性，导致混合专家视觉语言模型的量化效果不佳。

Method: VEQ采用双感知量化框架，包括1)模态专家感知量化，利用专家激活频率优先减少关键专家误差；2)模态亲和感知量化，通过整合token-expert亲和与模态信息构建增强Hessian矩阵指导校准。

Result: 在W3A16配置下，VEQ在Kimi-VL和Qwen3-VL上分别实现了2.04%和3.09%的平均准确率提升。

Conclusion: VEQ框架通过同时考虑跨模态差异和专家异质性，显著提升了混合专家视觉语言模型的量化效果，实验证明其在多个基准测试中优于现有方法。

Abstract: Mixture-of-Experts(MoE) Vision-Language Models (VLMs) offer remarkable performance but incur prohibitive memory and computational costs, making compression essential. Post-Training Quantization (PTQ) is an effective training-free technique to address the massive memory and computation overhead. Existing quantization paradigms fall short as they are oblivious to two critical forms of heterogeneity: the inherent discrepancy between vision and language tokens, and the non-uniform contribution of different experts. To bridge this gap, we propose Visual Expert Quantization (VEQ), a dual-aware quantization framework designed to simultaneously accommodate cross-modal differences and heterogeneity between experts. Specifically, VEQ incorporates 1)Modality-expert-aware Quantization, which utilizes expert activation frequency to prioritize error minimization for pivotal experts, and 2)Modality-affinity-aware Quantization, which constructs an enhanced Hessian matrix by integrating token-expert affinity with modality information to guide the calibration process. Extensive experiments across diverse benchmarks verify that VEQ consistently outperforms state-of-the-art baselines. Specifically, under the W3A16 configuration, our method achieves significant average accuracy gains of 2.04\% on Kimi-VL and 3.09\% on Qwen3-VL compared to the previous SOTA quantization methods, demonstrating superior robustness across various multimodal tasks. Our code will be available at https://github.com/guangshuoqin/VEQ.

</details>


### [133] [From Videos to Conversations: Egocentric Instructions for Task Assistance](https://arxiv.org/abs/2602.01038)
*Lavisha Aggarwal,Vikas Bahirwani,Andrea Colaco*

Main category: cs.CV

TL;DR: 论文提出自动转换单人教学视频为多模态对话的框架，并发布HowToDIV数据集，为任务辅助提供基准。


<details>
  <summary>Details</summary>
Motivation: 解决现实世界任务执行中大规模多模态对话数据集稀缺的问题，降低数据收集的成本和复杂性。

Method: 基于大型语言模型的自动管道，将单人教学视频转化为双人多模态对话。

Result: 生成了包含507个对话、6,636个问答对和24小时视频的HowToDIV数据集，并在Gemma 3和Qwen 2.5上报告了基线结果。

Conclusion: 该论文提出了一个自动将单人教学视频转化为双人多模态任务指导对话的框架，并引入了HowToDIV数据集，为多模态程序性任务辅助提供了初步基准。

Abstract: Many everyday tasks, ranging from appliance repair and cooking to car maintenance, require expert knowledge, particularly for complex, multi-step procedures. Despite growing interest in AI agents for augmented reality (AR) assistance, progress remains limited by the scarcity of large-scale multimodal conversational datasets grounded in real-world task execution, in part due to the cost and logistical complexity of human-assisted data collection. In this paper, we present a framework to automatically transform single person instructional videos into two-person multimodal task-guidance conversations. Our fully automatic pipeline, based on large language models, provides a scalable and cost efficient alternative to traditional data collection approaches. Using this framework, we introduce HowToDIV, a multimodal dataset comprising 507 conversations, 6,636 question answer pairs, and 24 hours of video spanning multiple domains. Each session consists of a multi-turn expert-novice interaction. Finally, we report baseline results using Gemma 3 and Qwen 2.5 on HowToDIV, providing an initial benchmark for multimodal procedural task assistance.

</details>


### [134] [ReLayout: Versatile and Structure-Preserving Design Layout Editing via Relation-Aware Design Reconstruction](https://arxiv.org/abs/2602.01046)
*Jiawei Lin,Shizhao Sun,Danqing Huang,Ting Liu,Ji Li,Jiang Bian*

Main category: cs.CV

TL;DR: ReLayout是一种无需三元组数据的自监督框架，通过关系图和RADR方法实现设计布局编辑，显著优于基线模型。


<details>
  <summary>Details</summary>
Motivation: 解决设计布局编辑任务中的两个主要挑战：满足编辑操作的同时保持未编辑元素的布局结构，以及缺乏三元组样本的问题。

Method: ReLayout通过引入关系图作为布局结构保持的约束，并提出关系感知设计重建（RADR）方法，以自监督方式模拟编辑过程。

Result: 定性和定量结果及用户研究表明，ReLayout在编辑质量、准确性和布局结构保持方面表现优异。

Conclusion: ReLayout框架在编辑质量、准确性和布局结构保持方面显著优于基线模型，验证了其在无三元组数据情况下的有效性。

Abstract: Automated redesign without manual adjustments marks a key step forward in the design workflow. In this work, we focus on a foundational redesign task termed design layout editing, which seeks to autonomously modify the geometric composition of a design based on user intents. To overcome the ambiguity of user needs expressed in natural language, we introduce four basic and important editing actions and standardize the format of editing operations. The underexplored task presents a unique challenge: satisfying specified editing operations while simultaneously preserving the layout structure of unedited elements. Besides, the scarcity of triplet (original design, editing operation, edited design) samples poses another formidable challenge. To this end, we present ReLayout, a novel framework for versatile and structure-preserving design layout editing that operates without triplet data. Specifically, ReLayout first introduces the relation graph, which contains the position and size relationships among unedited elements, as the constraint for layout structure preservation. Then, relation-aware design reconstruction (RADR) is proposed to bypass the data challenge. By learning to reconstruct a design from its elements, a relation graph, and a synthesized editing operation, RADR effectively emulates the editing process in a self-supervised manner. A multi-modal large language model serves as the backbone for RADR, unifying multiple editing actions within a single model and thus achieving versatile editing after fine-tuning. Qualitative, quantitative results and user studies show that ReLayout significantly outperforms the baseline models in terms of editing quality, accuracy, and layout structure preservation.

</details>


### [135] [Residual Decoding: Mitigating Hallucinations in Large Vision-Language Models via History-Aware Residual Guidance](https://arxiv.org/abs/2602.01047)
*Xinrong Chen,Xu Chu,Yingmin Qiu,Hengyuan Zhang,Jing Xiong,Shiyu Tang,Shuai Liu,Shaokang Yang,Cheng Yang,Hayden Kwok-Hay So,Ngai Wong*

Main category: cs.CV

TL;DR: ResDec通过历史信息和LVLMs内部机制，无需训练即可抑制幻觉，提升多模态任务表现。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（LVLMs）在多模态任务中表现优异，但受语言先验影响易产生幻觉，即生成内容与视觉输入无关。为解决这一问题，提出了ResDec。

Method: 提出了一种名为ResDec的训练无关方法，利用历史信息和LVLMs的隐式推理机制及token logits演化机制来纠正偏差。

Result: 实验表明，ResDec能有效抑制幻觉，提升视觉基础性，减少物体幻觉，并在综合基准测试中表现突出。

Conclusion: ResDec是一种无需训练的新方法，通过利用历史信息和LVLMs的内部机制，有效抑制了语言先验引起的幻觉，显著提升了视觉基础性，并在综合LVLM基准测试中表现优异。

Abstract: Large Vision-Language Models (LVLMs) can reason effectively from image-text inputs and perform well in various multimodal tasks. Despite this success, they are affected by language priors and often produce hallucinations. Hallucinations denote generated content that is grammatically and syntactically coherent, yet bears no match or direct relevance to actual visual input. To address this problem, we propose Residual Decoding (ResDec). It is a novel training-free method that uses historical information to aid decoding. The method relies on the internal implicit reasoning mechanism and token logits evolution mechanism of LVLMs to correct biases. Extensive experiments demonstrate that ResDec effectively suppresses hallucinations induced by language priors, significantly improves visual grounding, and reduces object hallucinations. In addition to mitigating hallucinations, ResDec also performs exceptionally well on comprehensive LVLM benchmarks, highlighting its broad applicability.

</details>


### [136] [Baseline Method of the Foundation Model Challenge for Ultrasound Image Analysis](https://arxiv.org/abs/2602.01055)
*Bo Deng,Yitong Tang,Jiake Li,Yuxin Huang,Li Wang,Yu Zhang,Yufei Zhan,Hua Lu,Xiaoshen Zhang,Jieyun Bai*

Main category: cs.CV

TL;DR: 本文提出了一个统一的MH-MTL框架作为超声图像分析基础模型的基线，通过多任务学习和多尺度特征提取，验证了其可行性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 解决超声图像分析中由于解剖结构和采集协议多样性导致的模型泛化性差、现有方法多为任务特定而无法作为临床可部署基础模型的问题。

Method: 采用基于ImageNet预训练的EfficientNet-B4主干网络和FPN进行多尺度特征提取，结合任务特定路由策略和复合损失函数进行训练。

Result: 验证结果表明该统一设计具有可行性和鲁棒性，为超声基础模型研究提供了强有力且可扩展的基线。

Conclusion: 本文提出了一个统一的MH-MTL框架，作为FM_UIA~2026的官方基线，验证了其在超声图像分析中的可行性和鲁棒性，为超声基础模型研究奠定了坚实基础。

Abstract: Ultrasound (US) imaging exhibits substantial heterogeneity across anatomical structures and acquisition protocols, posing significant challenges to the development of generalizable analysis models. Most existing methods are task-specific, limiting their suitability as clinically deployable foundation models. To address this limitation, the Foundation Model Challenge for Ultrasound Image Analysis (FM\_UIA~2026) introduces a large-scale multi-task benchmark comprising 27 subtasks across segmentation, classification, detection, and regression. In this paper, we present the official baseline for FM\_UIA~2026 based on a unified Multi-Head Multi-Task Learning (MH-MTL) framework that supports all tasks within a single shared network. The model employs an ImageNet-pretrained EfficientNet--B4 backbone for robust feature extraction, combined with a Feature Pyramid Network (FPN) to capture multi-scale contextual information. A task-specific routing strategy enables global tasks to leverage high-level semantic features, while dense prediction tasks exploit spatially detailed FPN representations. Training incorporates a composite loss with task-adaptive learning rate scaling and a cosine annealing schedule. Validation results demonstrate the feasibility and robustness of this unified design, establishing a strong and extensible baseline for ultrasound foundation model research. The code and dataset are publicly available at \href{https://github.com/lijiake2408/Foundation-Model-Challenge-for-Ultrasound-Image-Analysis}{GitHub}.

</details>


### [137] [Radioactive 3D Gaussian Ray Tracing for Tomographic Reconstruction](https://arxiv.org/abs/2602.01057)
*Ling Chen,Bao Yang*

Main category: cs.CV

TL;DR: 提出基于3D高斯光线追踪的断层重建框架，避免局部仿射近似，提高投影准确性和非线性几何校正能力。


<details>
  <summary>Details</summary>
Motivation: 现有基于3D高斯泼溅（3DGS）的断层重建方法采用局部仿射近似，导致重建定量精度下降且难以整合非线性几何校正。

Method: 采用3D高斯光线追踪方法，通过分析计算3D高斯基元的线积分，避免局部仿射近似，提供更精确的前向投影模型。

Result: 提出的框架在投影准确性和非线性几何校正方面优于基于泼溅的模型，适用于更广泛的断层系统。

Conclusion: 提出的基于3D高斯光线追踪的断层重建框架，通过避免局部仿射近似，提高了投影模型的物理一致性，并便于非线性几何校正的精确应用，扩展了高斯重建在更广泛真实断层系统中的应用。

Abstract: 3D Gaussian Splatting (3DGS) has recently emerged in computer vision as a promising rendering technique. By adapting the principles of Elliptical Weighted Average (EWA) splatting to a modern differentiable pipeline, 3DGS enables real-time, high-quality novel view synthesis. Building upon this, R2-Gaussian extended the 3DGS paradigm to tomographic reconstruction by rectifying integration bias, achieving state-of-the-art performance in computed tomography (CT). To enable differentiability, R2-Gaussian adopts a local affine approximation: each 3D Gaussian is locally mapped to a 2D Gaussian on the detector and composed via alpha blending to form projections. However, the affine approximation can degrade reconstruction quantitative accuracy and complicate the incorporation of nonlinear geometric corrections. To address these limitations, we propose a tomographic reconstruction framework based on 3D Gaussian ray tracing. Our approach provides two key advantages over splatting-based models: (i) it computes the line integral through 3D Gaussian primitives analytically, avoiding the local affine collapse and thus yielding a more physically consistent forward projection model; and (ii) the ray-tracing formulation gives explicit control over ray origins and directions, which facilitates the precise application of nonlinear geometric corrections, e.g., arc-correction used in positron emission tomography (PET). These properties extend the applicability of Gaussian-based reconstruction to a wider range of realistic tomography systems while improving projection accuracy.

</details>


### [138] [DRFormer: A Dual-Regularized Bidirectional Transformer for Person Re-identification](https://arxiv.org/abs/2602.01059)
*Ying Shu,Pujian Zhan,Huiqi Yang,Hehe Fan,Youfang Lin,Kai Lv*

Main category: cs.CV

TL;DR: DRFormer通过双正则化机制整合DINO和CLIP的优势，在五个基准测试中表现优异，证明了局部与全局特征融合的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常仅依赖单一范式（如DINO或CLIP），忽视了二者结合的潜力。本文旨在分析这两种架构的互补作用，并提出一种整合框架。

Method: 提出了一种双正则化双向Transformer（DRFormer）框架，通过双正则化机制确保多样化的特征提取，并平衡DINO和CLIP的贡献。

Result: 在五个基准测试中，DRFormer表现出色，验证了其在局部和全局特征融合方面的有效性。

Conclusion: DRFormer框架通过双正则化机制成功整合了DINO和CLIP的优势，在五个基准测试中表现出色，证明了其在局部和全局特征融合方面的有效性。

Abstract: Both fine-grained discriminative details and global semantic features can contribute to solving person re-identification challenges, such as occlusion and pose variations. Vision foundation models (\textit{e.g.}, DINO) excel at mining local textures, and vision-language models (\textit{e.g.}, CLIP) capture strong global semantic difference. Existing methods predominantly rely on a single paradigm, neglecting the potential benefits of their integration. In this paper, we analyze the complementary roles of these two architectures and propose a framework to synergize their strengths by a \textbf{D}ual-\textbf{R}egularized Bidirectional \textbf{Transformer} (\textbf{DRFormer}). The dual-regularization mechanism ensures diverse feature extraction and achieves a better balance in the contributions of the two models. Extensive experiments on five benchmarks show that our method effectively harmonizes local and global representations, achieving competitive performance against state-of-the-art methods.

</details>


### [139] [PDE-Constrained Optimization for Neural Image Segmentation with Physics Priors](https://arxiv.org/abs/2602.01069)
*Seema K. Poudel,Sunny K. Khadka*

Main category: cs.CV

TL;DR: 通过PDE约束优化结合深度学习，提升了显微图像分割的稳定性和泛化能力，实验验证了其优于传统无约束方法。


<details>
  <summary>Details</summary>
Motivation: 显微图像分割因噪声、弱边界和有限标注数据而成为不适定问题，传统无约束深度学习易导致不稳定和泛化能力差。

Method: 将图像分割问题建模为PDE约束的优化问题，结合变分正则化和反应-扩散方程、相场界面能量等物理先验，通过可微分残差损失实现。

Result: 在LIVECell数据集上的实验表明，相比无约束基线模型（UNet），PDE正则化模型在分割精度和边界保真度上均有提升，且在低样本情况下泛化能力更强。

Conclusion: 该研究通过将PDE约束优化与深度学习结合，显著提升了显微图像分割的准确性和边界保真度，特别是在低样本情况下表现出更好的泛化能力和稳定性。

Abstract: Segmentation of microscopy images constitutes an ill-posed inverse problem due to measurement noise, weak object boundaries, and limited labeled data. Although deep neural networks provide flexible nonparametric estimators, unconstrained empirical risk minimization often leads to unstable solutions and poor generalization. In this work, image segmentation is formulated as a PDE-constrained optimization problem that integrates physically motivated priors into deep learning models through variational regularization. The proposed framework minimizes a composite objective function consisting of a data fidelity term and penalty terms derived from reaction-diffusion equations and phase-field interface energies, all implemented as differentiable residual losses. Experiments are conducted on the LIVECell dataset, a high-quality, manually annotated collection of phase-contrast microscopy images. Training is performed on two cell types, while evaluation is carried out on a distinct, unseen cell type to assess generalization. A UNet architecture is used as the unconstrained baseline model. Experimental results demonstrate consistent improvements in segmentation accuracy and boundary fidelity compared to unconstrained deep learning baselines. Moreover, the PDE-regularized models exhibit enhanced stability and improved generalization in low-sample regimes, highlighting the advantages of incorporating structured priors. The proposed approach illustrates how PDE-constrained optimization can strengthen data-driven learning frameworks, providing a principled bridge between variational methods, statistical learning, and scientific machine learning.

</details>


### [140] [PISA: Piecewise Sparse Attention Is Wiser for Efficient Diffusion Transformers](https://arxiv.org/abs/2602.01077)
*Haopeng Li,Shitong Shao,Wenliang Zhong,Zikai Zhou,Lichen Bai,Hui Xiong,Zeke Xie*

Main category: cs.CV

TL;DR: PISA是一种训练自由的稀疏注意力方法，通过精确计算关键块并高效近似非关键块，显著提升了扩散变换器的效率，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 扩散变换器在视频和图像生成中的效率受限于注意力的二次复杂度。虽然块稀疏注意力通过仅关注关键键值块加速计算，但在高稀疏度下会因丢弃上下文而质量下降。研究发现非关键块的注意力分数具有分布稳定性，可高效近似而非丢弃，这为稀疏注意力设计提供了关键洞察。

Method: PISA采用了一种新颖的“精确或近似”策略，对关键块进行精确计算，而非关键块则通过分块泰勒展开高效近似，避免了传统稀疏注意力方法因丢弃非关键块信息而导致的质量下降。

Result: 实验表明，PISA在Wan2.1-14B和Hunyuan-Video上分别实现了1.91倍和2.57倍的加速，同时在稀疏注意力方法中保持最高质量。在FLUX上的图像生成任务中，PISA实现了1.2倍加速且未影响视觉质量。

Conclusion: PISA作为一种训练自由的稀疏注意力方法，通过精确计算关键块并高效近似非关键块，显著提升了扩散变换器的效率，同时在速度和生成质量之间取得了良好平衡。

Abstract: Diffusion Transformers are fundamental for video and image generation, but their efficiency is bottlenecked by the quadratic complexity of attention. While block sparse attention accelerates computation by attending only critical key-value blocks, it suffers from degradation at high sparsity by discarding context. In this work, we discover that attention scores of non-critical blocks exhibit distributional stability, allowing them to be approximated accurately and efficiently rather than discarded, which is essentially important for sparse attention design. Motivated by this key insight, we propose PISA, a training-free Piecewise Sparse Attention that covers the full attention span with sub-quadratic complexity. Unlike the conventional keep-or-drop paradigm that directly drop the non-critical block information, PISA introduces a novel exact-or-approximate strategy: it maintains exact computation for critical blocks while efficiently approximating the remainder through block-wise Taylor expansion. This design allows PISA to serve as a faithful proxy to full attention, effectively bridging the gap between speed and quality. Experimental results demonstrate that PISA achieves 1.91 times and 2.57 times speedups on Wan2.1-14B and Hunyuan-Video, respectively, while consistently maintaining the highest quality among sparse attention methods. Notably, even for image generation on FLUX, PISA achieves a 1.2 times acceleration without compromising visual quality. Code is available at: https://github.com/xie-lab-ml/piecewise-sparse-attention.

</details>


### [141] [MedAD-R1: Eliciting Consistent Reasoning in Interpretible Medical Anomaly Detection via Consistency-Reinforced Policy Optimization](https://arxiv.org/abs/2602.01081)
*Haitao Zhang,Yingying Wang,Jiaxiang Wang,Haote Xu,Hongyang Zhang,Yirong Chen,Yue Huang,Xinghao Ding*

Main category: cs.CV

TL;DR: 提出MedAD-38K基准和两阶段训练框架（SFT+Con-GRPO），MedAD-R1模型性能提升10%，增强了临床AI的可信度。


<details>
  <summary>Details</summary>
Motivation: 现有MedAD模型依赖简单、碎片化数据集的监督微调，导致推理能力和多模态泛化能力不足，需大规模、多模态、多中心基准和更优训练方法。

Method: 提出了一种两阶段训练框架：第一阶段通过SFT注入基础医学知识并对齐结构化思维-回答范式；第二阶段采用Con-GRPO算法，确保推理过程与最终诊断相关且逻辑一致。

Result: MedAD-R1在MedAD-38K基准上优于基线模型超过10%，展示了其在生成透明且逻辑一致推理路径方面的优势。

Conclusion: MedAD-R1模型在MedAD-38K基准测试中实现了最先进的性能，其透明且逻辑一致的推理路径增强了AI在临床决策支持中的可信度和可解释性。

Abstract: Medical Anomaly Detection (MedAD) presents a significant opportunity to enhance diagnostic accuracy using Large Multimodal Models (LMMs) to interpret and answer questions based on medical images. However, the reliance on Supervised Fine-Tuning (SFT) on simplistic and fragmented datasets has hindered the development of models capable of plausible reasoning and robust multimodal generalization. To overcome this, we introduce MedAD-38K, the first large-scale, multi-modal, and multi-center benchmark for MedAD featuring diagnostic Chain-of-Thought (CoT) annotations alongside structured Visual Question-Answering (VQA) pairs. On this foundation, we propose a two-stage training framework. The first stage, Cognitive Injection, uses SFT to instill foundational medical knowledge and align the model with a structured think-then-answer paradigm. Given that standard policy optimization can produce reasoning that is disconnected from the final answer, the second stage incorporates Consistency Group Relative Policy Optimization (Con-GRPO). This novel algorithm incorporates a crucial consistency reward to ensure the generated reasoning process is relevant and logically coherent with the final diagnosis. Our proposed model, MedAD-R1, achieves state-of-the-art (SOTA) performance on the MedAD-38K benchmark, outperforming strong baselines by more than 10\%. This superior performance stems from its ability to generate transparent and logically consistent reasoning pathways, offering a promising approach to enhancing the trustworthiness and interpretability of AI for clinical decision support.

</details>


### [142] [Differential Vector Erasure: Unified Training-Free Concept Erasure for Flow Matching Models](https://arxiv.org/abs/2602.01089)
*Zhiqi Zhang,Xinhao Zhong,Yi Sun,Shuoyang Sun,Bin Chen,Shu-Tao Xia,Xuan Wang*

Main category: cs.CV

TL;DR: DVE 是一种针对流匹配模型的无训练概念擦除方法，通过微分向量场精确抑制目标概念，实验证明其效果优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 文本到图像扩散模型在生成高质量图像方面表现出色，但可能再现不良内容（如 NSFW、版权风格等），现有方法主要针对 DDPM 模型且依赖微调，不适用于新兴的流匹配模型。

Method: DVE 通过构建一个表征目标概念与锚概念之间方向差异的微分向量场，在推理过程中选择性地移除概念特定组件。

Result: 在 FLUX 上的广泛实验表明，DVE 在 NSFW 抑制、艺术风格移除和对象擦除等任务上始终优于现有基线，同时保持图像质量和多样性。

Conclusion: Differential Vector Erasure (DVE) 是一种无需训练的概念擦除方法，专为流匹配模型设计，能够在不影响无关语义的情况下精确抑制目标概念。

Abstract: Text-to-image diffusion models have demonstrated remarkable capabilities in generating high-quality images, yet their tendency to reproduce undesirable concepts, such as NSFW content, copyrighted styles, or specific objects, poses growing concerns for safe and controllable deployment. While existing concept erasure approaches primarily focus on DDPM-based diffusion models and rely on costly fine-tuning, the recent emergence of flow matching models introduces a fundamentally different generative paradigm for which prior methods are not directly applicable. In this paper, we propose Differential Vector Erasure (DVE), a training-free concept erasure method specifically designed for flow matching models. Our key insight is that semantic concepts are implicitly encoded in the directional structure of the velocity field governing the generative flow. Leveraging this observation, we construct a differential vector field that characterizes the directional discrepancy between a target concept and a carefully chosen anchor concept. During inference, DVE selectively removes concept-specific components by projecting the velocity field onto the differential direction, enabling precise concept suppression without affecting irrelevant semantics. Extensive experiments on FLUX demonstrate that DVE consistently outperforms existing baselines on a wide range of concept erasure tasks, including NSFW suppression, artistic style removal, and object erasure, while preserving image quality and diversity.

</details>


### [143] [PandaPose: 3D Human Pose Lifting from a Single Image via Propagating 2D Pose Prior to 3D Anchor Space](https://arxiv.org/abs/2602.01095)
*Jinghong Zheng,Changlong Jiang,Yang Xiao,Jiaqi Li,Haohong Kuang,Hang Xu,Ran Wang,Zhiguo Cao,Min Du,Joey Tianyi Zhou*

Main category: cs.CV

TL;DR: PandaPose通过3D锚点空间解决2D到3D姿态提升的误差和遮挡问题，实验显示其性能优于SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有方法直接从2D姿态映射到3D姿态，存在误差传播和自遮挡处理的固有困难，需设计更鲁棒的中间表示。

Method: 提出PandaPose方法，通过构建包含关节级3D锚点、深度感知特征提升和锚点-特征交互解码器的3D锚点空间，实现从2D姿态到3D姿态的鲁棒映射。

Result: 在Human3.6M、MPI-INF-3DHP和3DPW数据集上，PandaPose显著优于现有方法，误差降低14.7%。

Conclusion: PandaPose通过引入3D锚点空间作为中间表示，有效解决了2D到3D姿态提升中的误差传播和自遮挡问题，实验证明其在多个基准数据集上优于现有方法。

Abstract: 3D human pose lifting from a single RGB image is a challenging task in 3D vision. Existing methods typically establish a direct joint-to-joint mapping from 2D to 3D poses based on 2D features. This formulation suffers from two fundamental limitations: inevitable error propagation from input predicted 2D pose to 3D predictions and inherent difficulties in handling self-occlusion cases. In this paper, we propose PandaPose, a 3D human pose lifting approach via propagating 2D pose prior to 3D anchor space as the unified intermediate representation. Specifically, our 3D anchor space comprises: (1) Joint-wise 3D anchors in the canonical coordinate system, providing accurate and robust priors to mitigate 2D pose estimation inaccuracies. (2) Depth-aware joint-wise feature lifting that hierarchically integrates depth information to resolve self-occlusion ambiguities. (3) The anchor-feature interaction decoder that incorporates 3D anchors with lifted features to generate unified anchor queries encapsulating joint-wise 3D anchor set, visual cues and geometric depth information. The anchor queries are further employed to facilitate anchor-to-joint ensemble prediction. Experiments on three well-established benchmarks (i.e., Human3.6M, MPI-INF-3DHP and 3DPW) demonstrate the superiority of our proposition. The substantial reduction in error by $14.7\%$ compared to SOTA methods on the challenging conditions of Human3.6M and qualitative comparisons further showcase the effectiveness and robustness of our approach.

</details>


### [144] [Robust Harmful Meme Detection under Missing Modalities via Shared Representation Learning](https://arxiv.org/abs/2602.01101)
*Felix Breiteneder,Mohammad Belal,Muhammad Saad Saeed,Shahed Masoudian,Usman Naseem,Kulshrestha Juhi,Markus Schedl,Shah Nawaz*

Main category: cs.CV

TL;DR: 本文首次全面研究了模态不完整数据下有害模因检测方法的行为，并提出了一种新基线方法，在文本缺失时表现更优，提升了实际应用的可行性。


<details>
  <summary>Details</summary>
Motivation: 现有有害模因检测方法依赖模态完整数据（如文本和图像），但在实际场景中可能因OCR质量差等问题导致文本缺失，导致性能下降。本文旨在填补这一空白。

Method: 提出了一种新的基线方法，通过独立投影多模态数据学习共享表示，从而在模态不完整时利用这些表示。

Result: 在两个基准数据集上的实验结果表明，所提方法在文本缺失时优于现有方法，且能更好地整合视觉特征。

Conclusion: 本文提出的方法在模态不完整数据（如文本缺失）情况下表现优于现有方法，能够更好地整合视觉特征，减少对文本的依赖，提升了有害模因检测的鲁棒性。

Abstract: Internet memes are powerful tools for communication, capable of spreading political, psychological, and sociocultural ideas. However, they can be harmful and can be used to disseminate hate toward targeted individuals or groups. Although previous studies have focused on designing new detection methods, these often rely on modal-complete data, such as text and images. In real-world settings, however, modalities like text may be missing due to issues like poor OCR quality, making existing methods sensitive to missing information and leading to performance deterioration. To address this gap, in this paper, we present the first-of-its-kind work to comprehensively investigate the behavior of harmful meme detection methods in the presence of modal-incomplete data. Specifically, we propose a new baseline method that learns a shared representation for multiple modalities by projecting them independently. These shared representations can then be leveraged when data is modal-incomplete. Experimental results on two benchmark datasets demonstrate that our method outperforms existing approaches when text is missing. Moreover, these results suggest that our method allows for better integration of visual features, reducing dependence on text and improving robustness in scenarios where textual information is missing. Our work represents a significant step forward in enabling the real-world application of harmful meme detection, particularly in situations where a modality is absent.

</details>


### [145] [LightCity: An Urban Dataset for Outdoor Inverse Rendering and Reconstruction under Multi-illumination Conditions](https://arxiv.org/abs/2602.01118)
*Jingjing Wang,Qirui Hu,Chong Bao,Yuke Zhu,Hujun Bao,Zhaopeng Cui,Guofeng Zhang*

Main category: cs.CV

TL;DR: LightCity是一个高质量合成城市数据集，解决了复杂照明条件下逆渲染研究的不足，为相关应用提供了重要支持。


<details>
  <summary>Details</summary>
Motivation: 城市场景中的逆渲染在自动驾驶和数字孪生等应用中至关重要，但由于复杂的照明条件（如多重照明和间接光效）缺乏合适的数据集，其内在分解和3D重建效果尚未被充分探索。

Method: 提出了LightCity，一个包含多样照明条件的高质量合成城市数据集，涵盖300多个天空地图、5万多张图像，并附带深度、法线、材质组件等丰富属性。

Result: LightCity数据集成功支持了城市环境中三项基本任务的基准测试，并进行了全面分析。

Conclusion: LightCity数据集为城市环境中的逆渲染研究提供了高质量的基础，通过丰富的照明条件和属性，为相关领域的进展奠定了坚实基础。

Abstract: Inverse rendering in urban scenes is pivotal for applications like autonomous driving and digital twins. Yet, it faces significant challenges due to complex illumination conditions, including multi-illumination and indirect light and shadow effects. However, the effects of these challenges on intrinsic decomposition and 3D reconstruction have not been explored due to the lack of appropriate datasets. In this paper, we present LightCity, a novel high-quality synthetic urban dataset featuring diverse illumination conditions with realistic indirect light and shadow effects. LightCity encompasses over 300 sky maps with highly controllable illumination, varying scales with street-level and aerial perspectives over 50K images, and rich properties such as depth, normal, material components, light and indirect light, etc. Besides, we leverage LightCity to benchmark three fundamental tasks in the urban environments and conduct a comprehensive analysis of these benchmarks, laying a robust foundation for advancing related research.

</details>


### [146] [Koo-Fu CLIP: Closed-Form Adaptation of Vision-Language Models via Fukunaga-Koontz Linear Discriminant Analysis](https://arxiv.org/abs/2602.01127)
*Matej Suchanek,Klara Janouskova,Ondrej Vasatko,Jiri Matas*

Main category: cs.CV

TL;DR: Koo-Fu CLIP通过线性判别分析优化CLIP嵌入，提升分类准确率并支持高效压缩。


<details>
  <summary>Details</summary>
Motivation: 原始CLIP嵌入在监督分类任务中表现有限，类间区分不足且维度冗余。

Method: 基于Fukunaga-Koontz线性判别分析，在whitened嵌入空间中抑制类内差异并增强类间区分，形成闭式线性投影。

Result: 在ImageNet-1K上，top-1准确率从75.1%提升至79.1%，且在14K和21K类别上保持稳定增益，支持10-12倍压缩而无明显精度损失。

Conclusion: Koo-Fu CLIP通过Fukunaga-Koontz线性判别分析优化CLIP嵌入空间，显著提升了分类准确率和维度压缩效率，适用于大规模分类和检索任务。

Abstract: Visual-language models such as CLIP provide powerful general-purpose representations, but their raw embeddings are not optimized for supervised classification, often exhibiting limited class separation and excessive dimensionality. We propose Koo-Fu CLIP, a supervised CLIP adaptation method based on Fukunaga-Koontz Linear Discriminant Analysis, which operates in a whitened embedding space to suppress within-class variation and enhance between-class discrimination. The resulting closed-form linear projection reshapes the geometry of CLIP embeddings, improving class separability while performing effective dimensionality reduction, and provides a lightweight and efficient adaptation of CLIP representations.
  Across large-scale ImageNet benchmarks, nearest visual prototype classification in the Koo-Fu CLIP space improves top-1 accuracy from 75.1% to 79.1% on ImageNet-1K, with consistent gains persisting as the label space expands to 14K and 21K classes. The method supports substantial compression by up to 10-12x with little or no loss in accuracy, enabling efficient large-scale classification and retrieval.

</details>


### [147] [Semantically Aware UAV Landing Site Assessment from Remote Sensing Imagery via Multimodal Large Language Models](https://arxiv.org/abs/2602.01163)
*Chunliang Hua,Zeyuan Yang,Lei Zhang,Jiayang Sun,Fengwen Chen,Chunlan Zeng,Xiao Hu*

Main category: cs.CV

TL;DR: 论文提出利用遥感影像和MLLMs的框架，通过语义分割和视觉语言推理提升无人机紧急着陆风险评估，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 传统几何传感器无法识别复杂语义风险（如人群、临时结构），需开发能理解全局上下文的风险评估方法。

Method: 采用从粗到细的流程：轻量级语义分割模块预筛选候选区域，视觉语言推理代理融合视觉特征与POI数据以检测潜在风险。

Result: 实验证明该框架在风险识别准确率上显著优于几何基线，并能生成类似人类的可解释性理由。

Conclusion: 该论文提出了一种结合遥感影像和多模态大语言模型的框架，显著提高了无人机紧急着陆时对复杂语义风险的识别能力，并通过公开数据集ELSS验证了其优越性。

Abstract: Safe UAV emergency landing requires more than just identifying flat terrain; it demands understanding complex semantic risks (e.g., crowds, temporary structures) invisible to traditional geometric sensors. In this paper, we propose a novel framework leveraging Remote Sensing (RS) imagery and Multimodal Large Language Models (MLLMs) for global context-aware landing site assessment. Unlike local geometric methods, our approach employs a coarse-to-fine pipeline: first, a lightweight semantic segmentation module efficiently pre-screens candidate areas; second, a vision-language reasoning agent fuses visual features with Point-of-Interest (POI) data to detect subtle hazards. To validate this approach, we construct and release the Emergency Landing Site Selection (ELSS) benchmark. Experiments demonstrate that our framework significantly outperforms geometric baselines in risk identification accuracy. Furthermore, qualitative results confirm its ability to generate human-like, interpretable justifications, enhancing trust in automated decision-making. The benchmark dataset is publicly accessible at https://anonymous.4open.science/r/ELSS-dataset-43D7.

</details>


### [148] [EEmo-Logic: A Unified Dataset and Multi-Stage Framework for Comprehensive Image-Evoked Emotion Assessment](https://arxiv.org/abs/2602.01173)
*Lancheng Gao,Ziheng Jia,Zixuan Xing,Wei Sun,Huiyu Duan,Guangtao Zhai,Xiongkuo Min*

Main category: cs.CV

TL;DR: EEmo-Logic是一个通过指令微调和GRPO开发的多模态大语言模型，旨在解决图像情感理解的细粒度和推理问题，表现优异。


<details>
  <summary>Details</summary>
Motivation: 理解图像引发的情感的多维属性和强度细微差别对提升机器共情能力和丰富人机交互应用至关重要，但现有模型在细粒度情感感知或推理能力上仍有局限。

Method: 通过指令微调和任务定制的组相对偏好优化（GRPO）开发了多模态大语言模型EEmo-Logic，并设计了新颖的奖励机制。

Result: EEmo-Logic在领域内和跨领域数据集中均表现出色，尤其在情感问答和细粒度评估任务中。

Conclusion: EEmo-Logic模型在情感问答和细粒度评估方面表现出色，验证了其在领域内和跨领域数据集上的鲁棒性。

Abstract: Understanding the multi-dimensional attributes and intensity nuances of image-evoked emotions is pivotal for advancing machine empathy and empowering diverse human-computer interaction applications. However, existing models are still limited to coarse-grained emotion perception or deficient reasoning capabilities. To bridge this gap, we introduce EEmoDB, the largest image-evoked emotion understanding dataset to date. It features $5$ analysis dimensions spanning $5$ distinct task categories, facilitating comprehensive interpretation. Specifically, we compile $1.2M$ question-answering (QA) pairs (EEmoDB-QA) from $125k$ images via automated generation, alongside a $36k$ dataset (EEmoDB-Assess) curated from $25k$ images for fine-grained assessment. Furthermore, we propose EEmo-Logic, an all-in-one multimodal large language model (MLLM) developed via instruction fine-tuning and task-customized group relative preference optimization (GRPO) with novel reward design. Extensive experiments demonstrate that EEmo-Logic achieves robust performance in in-domain and cross-domain datasets, excelling in emotion QA and fine-grained assessment. The code is available at https://anonymous.4open.science/r/EEmoLogic.

</details>


### [149] [Refining Context-Entangled Content Segmentation via Curriculum Selection and Anti-Curriculum Promotion](https://arxiv.org/abs/2602.01183)
*Chunming He,Rihan Zhang,Fengyang Xiao,Dingming Zhang,Zhiwen Cao,Sina Farsiu*

Main category: cs.CV

TL;DR: CurriSeg是一种双阶段学习框架，结合课程与反课程学习原则，动态选择训练数据并抑制高频成分，显著提升上下文纠缠内容分割性能。


<details>
  <summary>Details</summary>
Motivation: 受生物学习从易到难的启发，针对上下文纠缠内容分割任务中对象与背景视觉模式高度相似的问题，传统方法多依赖架构改进而忽略学习动态，因此提出CurriSeg以提升表示可靠性。

Method: CurriSeg框架包含两个阶段：课程选择阶段基于样本损失的时序统计动态选择训练数据；反课程提升阶段通过光谱盲微调抑制高频成分，强化对低频结构及上下文线索的依赖。

Result: 实验表明，CurriSeg在多个CECS基准测试中均取得一致改进，且不增加参数或训练时间。

Conclusion: CurriSeg通过结合课程学习和反课程学习原则，提出了一种双阶段学习框架，有效提升了在上下文纠缠内容分割任务中的表现，且无需增加参数或训练时间。

Abstract: Biological learning proceeds from easy to difficult tasks, gradually reinforcing perception and robustness. Inspired by this principle, we address Context-Entangled Content Segmentation (CECS), a challenging setting where objects share intrinsic visual patterns with their surroundings, as in camouflaged object detection. Conventional segmentation networks predominantly rely on architectural enhancements but often ignore the learning dynamics that govern robustness under entangled data distributions. We introduce CurriSeg, a dual-phase learning framework that unifies curriculum and anti-curriculum principles to improve representation reliability. In the Curriculum Selection phase, CurriSeg dynamically selects training data based on the temporal statistics of sample losses, distinguishing hard-but-informative samples from noisy or ambiguous ones, thus enabling stable capability enhancement. In the Anti-Curriculum Promotion phase, we design Spectral-Blindness Fine-Tuning, which suppresses high-frequency components to enforce dependence on low-frequency structural and contextual cues and thus strengthens generalization. Extensive experiments demonstrate that CurriSeg achieves consistent improvements across diverse CECS benchmarks without adding parameters or increasing total training time, offering a principled view of how progression and challenge interplay to foster robust and context-aware segmentation. Code will be released.

</details>


### [150] [EMFormer: Efficient Multi-Scale Transformer for Accumulative Context Weather Forecasting](https://arxiv.org/abs/2602.01194)
*Hao Chen,Tao Han,Jie Zhang,Song Guo,Fenghua Ling,Lei Bai*

Main category: cs.CV

TL;DR: 提出EMFormer架构，通过多尺度特征提取和动态损失优化，显著提升长期天气预测的准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在长期天气预测中存在的灾难性遗忘、误差累积和高训练开销问题。

Method: 提出了一种跨预训练、微调和预测的新流程，包括高效的EMFormer架构、累积上下文微调策略和动态平衡的复合损失函数。

Result: 实验结果表明，该方法在天气预测和极端事件预测中表现优异，同时计算效率提升了5.69倍。

Conclusion: EMFormer 在天气预测和极端事件预测中表现出色，显著提高了长期预测的准确性，并在视觉基准测试中展现了强大的泛化能力，同时实现了计算效率的大幅提升。

Abstract: Long-term weather forecasting is critical for socioeconomic planning and disaster preparedness. While recent approaches employ finetuning to extend prediction horizons, they remain constrained by the issues of catastrophic forgetting, error accumulation, and high training overhead. To address these limitations, we present a novel pipeline across pretraining, finetuning and forecasting to enhance long-context modeling while reducing computational overhead. First, we introduce an Efficient Multi-scale Transformer (EMFormer) to extract multi-scale features through a single convolution in both training and inference. Based on the new architecture, we further employ an accumulative context finetuning to improve temporal consistency without degrading short-term accuracy. Additionally, we propose a composite loss that dynamically balances different terms via a sinusoidal weighting, thereby adaptively guiding the optimization trajectory throughout pretraining and finetuning. Experiments show that our approach achieves strong performance in weather forecasting and extreme event prediction, substantially improving long-term forecast accuracy. Moreover, EMFormer demonstrates strong generalization on vision benchmarks (ImageNet-1K and ADE20K) while delivering a 5.69x speedup over conventional multi-scale modules.

</details>


### [151] [Med3D-R1: Incentivizing Clinical Reasoning in 3D Medical Vision-Language Models for Abnormality Diagnosis](https://arxiv.org/abs/2602.01200)
*Haoran Lai,Zihang Jiang,Kun Zhang,Qingsong Yao,Rongsheng Wang,Zhiyang He,Xiaodong Tao,Wei Wei,Shaohua Kevin Zhou*

Main category: cs.CV

TL;DR: Med3D-R1 通过两阶段训练框架提升 3D 医学视觉语言模型的临床推理能力，在基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决 3D 医学视觉语言模型在临床推理中的挑战，包括体积医学图像的复杂性、模型对表面报告模式的过拟合以及缺乏可解释性奖励设计。

Method: 提出了一个两阶段训练框架：监督微调（SFT）阶段引入残差对齐机制和异常重加权策略；强化学习（RL）阶段重新设计一致性奖励以促进连贯的诊断推理。

Result: 在 CT-RATE 和 RAD-ChestCT 基准测试中分别达到了 41.92% 和 44.99% 的最先进准确率。

Conclusion: Med3D-R1 框架通过两阶段训练过程（SFT 和 RL）显著提升了 3D 医学视觉语言模型的临床推理能力，并在 CT-RATE 和 RAD-ChestCT 基准测试中取得了最先进的准确率。

Abstract: Developing 3D vision-language models with robust clinical reasoning remains a challenge due to the inherent complexity of volumetric medical imaging, the tendency of models to overfit superficial report patterns, and the lack of interpretability-aware reward designs. In this paper, we propose Med3D-R1, a reinforcement learning framework with a two-stage training process: Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL). During SFT stage, we introduce a residual alignment mechanism to bridge the gap between high-dimensional 3D features and textual embeddings, and an abnormality re-weighting strategy to emphasize clinically informative tokens and reduce structural bias in reports. In RL stage, we redesign the consistency reward to explicitly promote coherent, step-by-step diagnostic reasoning. We evaluate our method on medical multiple-choice visual question answering using two 3D diagnostic benchmarks, CT-RATE and RAD-ChestCT, where our model attains state-of-the-art accuracies of 41.92\% on CT-RATE and 44.99\% on RAD-ChestCT. These results indicate improved abnormality diagnosis and clinical reasoning and outperform prior methods on both benchmarks. Overall, our approach holds promise for enhancing real-world diagnostic workflows by enabling more reliable and transparent 3D medical vision-language systems.

</details>


### [152] [Boosting Point-supervised Temporal Action Localization via Text Refinement and Alignment](https://arxiv.org/abs/2602.01257)
*Yunchuan Ma,Laiyun Qing,Guorong Li,Yuqing Liu,Yuankai Qi,Qingming Huang*

Main category: cs.CV

TL;DR: Proposes TRA framework for point-supervised action localization, combining visual and textual features via PTR and PMA modules, achieving superior performance and scalability.


<details>
  <summary>Details</summary>
Motivation: Current methods overlook semantic information from text, which could complement visual features for better localization accuracy.

Method: The framework introduces two modules: Point-based Text Refinement (PTR) for refining textual descriptions using point annotations, and Point-based Multimodal Alignment (PMA) for aligning visual and textual features in a unified semantic space through contrastive learning.

Result: The TRA framework outperforms state-of-the-art methods on five benchmarks and is computationally efficient, running on a single 24 GB GPU.

Conclusion: The TRA framework demonstrates superior performance in point-supervised temporal action localization by effectively integrating textual features with visual inputs, validated across five benchmarks and showing practical scalability.

Abstract: Recently, point-supervised temporal action localization has gained significant attention for its effective balance between labeling costs and localization accuracy. However, current methods only consider features from visual inputs, neglecting helpful semantic information from the text side. To address this issue, we propose a Text Refinement and Alignment (TRA) framework that effectively utilizes textual features from visual descriptions to complement the visual features as they are semantically rich. This is achieved by designing two new modules for the original point-supervised framework: a Point-based Text Refinement module (PTR) and a Point-based Multimodal Alignment module (PMA). Specifically, we first generate descriptions for video frames using a pre-trained multimodal model. Next, PTR refines the initial descriptions by leveraging point annotations together with multiple pre-trained models. PMA then projects all features into a unified semantic space and leverages a point-level multimodal feature contrastive learning to reduce the gap between visual and linguistic modalities. Last, the enhanced multi-modal features are fed into the action detector for precise localization. Extensive experimental results on five widely used benchmarks demonstrate the favorable performance of our proposed framework compared to several state-of-the-art methods. Moreover, our computational overhead analysis shows that the framework can run on a single 24 GB RTX 3090 GPU, indicating its practicality and scalability.

</details>


### [153] [Q-DiT4SR: Exploration of Detail-Preserving Diffusion Transformer Quantization for Real-World Image Super-Resolution](https://arxiv.org/abs/2602.01273)
*Xun Zhang,Kaicheng Yang,Hongliang Lu,Haotong Qin,Yong Guo,Yulun Zhang*

Main category: cs.CV

TL;DR: Q-DiT4SR是为DiT超分辨率设计的PTQ框架，通过H-SVD和混合精度量化，在保持性能的同时大幅降低计算负担。


<details>
  <summary>Details</summary>
Motivation: 现有的PTQ方法主要针对U-Net架构或文本到图像任务，直接应用于DiT超分辨率模型会导致局部纹理严重退化，因此需要专门的设计。

Method: 提出H-SVD（分层SVD）和Variance-aware Spatio-Temporal Mixed Precision（VaSMP/VaTMP）方法，前者结合全局低秩分支和局部块状秩-1分支，后者通过率失真理论和动态编程分配比特宽度。

Result: 在多个真实世界数据集上，Q-DiT4SR在W4A6和W4A4设置下均达到SOTA性能，W4A4配置将模型大小减少5.8倍，计算量减少60倍以上。

Conclusion: Q-DiT4SR是一种专门为基于DiT的真实世界图像超分辨率设计的PTQ框架，通过H-SVD和VaSMP/VaTMP方法，在保持高性能的同时显著减少了模型大小和计算量。

Abstract: Recently, Diffusion Transformers (DiTs) have emerged in Real-World Image Super-Resolution (Real-ISR) to generate high-quality textures, yet their heavy inference burden hinders real-world deployment. While Post-Training Quantization (PTQ) is a promising solution for acceleration, existing methods in super-resolution mostly focus on U-Net architectures, whereas generic DiT quantization is typically designed for text-to-image tasks. Directly applying these methods to DiT-based super-resolution models leads to severe degradation of local textures. Therefore, we propose Q-DiT4SR, the first PTQ framework specifically tailored for DiT-based Real-ISR. We propose H-SVD, a hierarchical SVD that integrates a global low-rank branch with a local block-wise rank-1 branch under a matched parameter budget. We further propose Variance-aware Spatio-Temporal Mixed Precision: VaSMP allocates cross-layer weight bit-widths in a data-free manner based on rate-distortion theory, while VaTMP schedules intra-layer activation precision across diffusion timesteps via dynamic programming (DP) with minimal calibration. Experiments on multiple real-world datasets demonstrate that our Q-DiT4SR achieves SOTA performance under both W4A6 and W4A4 settings. Notably, the W4A4 quantization configuration reduces model size by 5.8$\times$ and computational operations by over 60$\times$. Our code and models will be available at https://github.com/xunzhang1128/Q-DiT4SR.

</details>


### [154] [TF-Lane: Traffic Flow Module for Robust Lane Perception](https://arxiv.org/abs/2602.01277)
*Yihan Xie,Han Xia,Zhen Yang*

Main category: cs.CV

TL;DR: TFM利用实时交通流提升车道感知性能，实验验证其在视觉线索不足场景下的有效性。


<details>
  <summary>Details</summary>
Motivation: 现有视觉车道感知方法在视觉线索不足时性能下降，而高精地图方案成本高且实时性差，因此探索了无需额外成本的实时交通流作为补充信息源。

Method: 提出了一种TrafficFlow-aware Lane perception Module (TFM)，能够有效提取实时交通流特征并与现有车道感知算法无缝集成。

Result: 在四个主流模型和两个公开数据集（Nuscenes和OpenLaneV2）上的实验显示，TFM性能稳定提升，最高在Nuscenes数据集上实现+4.1% mAP增益。

Conclusion: TFM模块通过整合实时交通流特征，显著提升了车道感知性能，尤其在视觉线索不足的场景下表现突出。

Abstract: Autonomous driving systems require robust lane perception capabilities, yet existing vision-based detection methods suffer significant performance degradation when visual sensors provide insufficient cues, such as in occluded or lane-missing scenarios. While some approaches incorporate high-definition maps as supplementary information, these solutions face challenges of high subscription costs and limited real-time performance. To address these limitations, we explore an innovative information source: traffic flow, which offers real-time capabilities without additional costs. This paper proposes a TrafficFlow-aware Lane perception Module (TFM) that effectively extracts real-time traffic flow features and seamlessly integrates them with existing lane perception algorithms. This solution originated from real-world autonomous driving conditions and was subsequently validated on open-source algorithms and datasets. Extensive experiments on four mainstream models and two public datasets (Nuscenes and OpenLaneV2) using standard evaluation metrics show that TFM consistently improves performance, achieving up to +4.1% mAP gain on the Nuscenes dataset.

</details>


### [155] [DSFC-Net: A Dual-Encoder Spatial and Frequency Co-Awareness Network for Rural Road Extraction](https://arxiv.org/abs/2602.01278)
*Zhengbo Zhang,Yihe Tian,Wanke Xia,Lin Chen,Yue Sun,Kun Ding,Ying Wang,Bing Xu,Shiming Xiang*

Main category: cs.CV

TL;DR: DSFC-Net通过双编码器框架融合空间和频域信息，解决了农村道路提取的独特挑战，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 农村道路提取面临高类内变异性、低类间可分性、植被遮挡和狭窄道路宽度等独特挑战，现有方法主要针对城市环境，难以适应这些特点。

Method: 提出DSFC-Net，一种双编码器框架，结合CNN分支和空间-频率混合变换器（SFT），通过交叉频率交互注意力（CFIA）模块动态交互空间细节和频域全局上下文，并利用通道特征融合模块（CFFM）整合局部纹理与全局语义。

Result: 在WHU-RuR+、DeepGlobe和Massachusetts数据集上的实验表明，DSFC-Net优于现有方法。

Conclusion: DSFC-Net通过融合空间和频域信息，有效解决了农村道路提取中的挑战，如高类内变异性和低类间可分性、植被遮挡以及狭窄道路宽度。实验证明其在多个数据集上优于现有方法。

Abstract: Accurate extraction of rural roads from high-resolution remote sensing imagery is essential for infrastructure planning and sustainable development. However, this task presents unique challenges in rural settings due to several factors. These include high intra-class variability and low inter-class separability from diverse surface materials, frequent vegetation occlusions that disrupt spatial continuity, and narrow road widths that exacerbate detection difficulties. Existing methods, primarily optimized for structured urban environments, often underperform in these scenarios as they overlook such distinctive characteristics. To address these challenges, we propose DSFC-Net, a dual-encoder framework that synergistically fuses spatial and frequency-domain information. Specifically, a CNN branch is employed to capture fine-grained local road boundaries and short-range continuity, while a novel Spatial-Frequency Hybrid Transformer (SFT) is introduced to robustly model global topological dependencies against vegetation occlusions. Distinct from standard attention mechanisms that suffer from frequency bias, the SFT incorporates a Cross-Frequency Interaction Attention (CFIA) module that explicitly decouples high- and low-frequency information via a Laplacian Pyramid strategy. This design enables the dynamic interaction between spatial details and frequency-aware global contexts, effectively preserving the connectivity of narrow roads. Furthermore, a Channel Feature Fusion Module (CFFM) is proposed to bridge the two branches by adaptively recalibrating channel-wise feature responses, seamlessly integrating local textures with global semantics for accurate segmentation. Comprehensive experiments on the WHU-RuR+, DeepGlobe, and Massachusetts datasets validate the superiority of DSFC-Net over state-of-the-art approaches.

</details>


### [156] [Who Transfers Safety? Identifying and Targeting Cross-Lingual Shared Safety Neurons](https://arxiv.org/abs/2602.01283)
*Xianhui Zhang,Chengyu Xie,Linxia Zhu,Yonghui Yang,Weixiang Zhao,Zifeng Cheng,Cong Wang,Fei Shen,Tat-Seng Chua*

Main category: cs.CV

TL;DR: 研究发现LLMs中存在跨语言共享安全神经元（SS-Neurons），通过针对性训练可显著提升非高资源语言的安全性。


<details>
  <summary>Details</summary>
Motivation: 多语言安全性存在显著不平衡，非高资源语言（NHR）的安全性较弱，且跨语言安全对齐的神经机制尚不明确。

Method: 首先识别单语安全神经元（MS-Neurons），验证其因果作用，然后识别跨语言共享的SS-Neurons，并提出基于神经元导向的训练策略。

Result: 抑制SS-Neurons会导致NHR语言安全性下降，而增强它们则能提升跨语言防御一致性。提出的训练策略在实验中表现优于现有方法。

Conclusion: LLMs中的跨语言共享安全神经元（SS-Neurons）是关键神经元子集，通过针对性的训练策略可以显著提升非高资源语言的安全性，同时保持模型的通用能力。

Abstract: Multilingual safety remains significantly imbalanced, leaving non-high-resource (NHR) languages vulnerable compared to robust high-resource (HR) ones. Moreover, the neural mechanisms driving safety alignment remain unclear despite observed cross-lingual representation transfer.
  In this paper, we find that LLMs contain a set of cross-lingual shared safety neurons (SS-Neurons), a remarkably small yet critical neuronal subset that jointly regulates safety behavior across languages.
  We first identify monolingual safety neurons (MS-Neurons) and validate their causal role in safety refusal behavior through targeted activation and suppression.
  Our cross-lingual analyses then identify SS-Neurons as the subset of MS-Neurons shared between HR and NHR languages, serving as a bridge to transfer safety capabilities from HR to NHR domains.
  We observe that suppressing these neurons causes concurrent safety drops across NHR languages, whereas reinforcing them improves cross-lingual defensive consistency.
  Building on these insights, we propose a simple neuron-oriented training strategy that targets SS-Neurons based on language resource distribution and model architecture. Experiments demonstrate that fine-tuning this tiny neuronal subset outperforms state-of-the-art methods, significantly enhancing NHR safety while maintaining the model's general capabilities.
  The code and dataset will be available athttps://github.com/1518630367/SS-Neuron-Expansion.

</details>


### [157] [Interacted Planes Reveal 3D Line Mapping](https://arxiv.org/abs/2602.01296)
*Zeran Ke,Bin Tan,Gui-Song Xia,Yujun Shen,Nan Xue*

Main category: cs.CV

TL;DR: LiP-Map是一种联合优化线和平面的框架，通过显式建模可学习的线和平面基元，提高了3D线映射的准确性和完整性，并在视觉定位中表现出色。


<details>
  <summary>Details</summary>
Motivation: 从物理和拓扑角度研究3D线映射问题，认为3D线自然作为3D平面补丁的边缘出现。

Method: 提出LiP-Map框架，显式建模线和平面基元，通过联合优化实现高效且准确的3D线映射。

Result: 在多个数据集上优于现有方法，显著提升了线辅助视觉定位的性能。

Conclusion: LiP-Map通过整合平面拓扑，为结构化重建提供了新思路，代码已开源。

Abstract: 3D line mapping from multi-view RGB images provides a compact and structured visual representation of scenes. We study the problem from a physical and topological perspective: a 3D line most naturally emerges as the edge of a finite 3D planar patch. We present LiP-Map, a line-plane joint optimization framework that explicitly models learnable line and planar primitives. This coupling enables accurate and detailed 3D line mapping while maintaining strong efficiency (typically completing a reconstruction in 3 to 5 minutes per scene). LiP-Map pioneers the integration of planar topology into 3D line mapping, not by imposing pairwise coplanarity constraints but by explicitly constructing interactions between plane and line primitives, thus offering a principled route toward structured reconstruction in man-made environments. On more than 100 scenes from ScanNetV2, ScanNet++, Hypersim, 7Scenes, and Tanks\&Temple, LiP-Map improves both accuracy and completeness over state-of-the-art methods. Beyond line mapping quality, LiP-Map significantly advances line-assisted visual localization, establishing strong performance on 7Scenes. Our code is released at https://github.com/calmke/LiPMAP for reproducible research.

</details>


### [158] [Interaction-Consistent Object Removal via MLLM-Based Reasoning](https://arxiv.org/abs/2602.01298)
*Ching-Kai Huang,Wen-Chieh Lin,Yan-Cen Lee*

Main category: cs.CV

TL;DR: REORM框架利用MLLM推理能力，解决对象移除中的交互一致性问题，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决图像中对象移除时仅删除目标对象而忽略相关交互元素导致的语义不一致问题。

Method: 提出了REORM框架，包括MLLM驱动的分析、掩码引导的移除和自校正机制，以及支持有限资源下精确编辑的本地部署变体。

Result: 在ICOREval基准测试中，REORM表现优于现有图像编辑系统，能有效生成交互一致的结果。

Conclusion: REORM框架通过结合多模态大语言模型的推理能力，有效解决了交互一致性对象移除问题，并在ICOREval基准测试中优于现有图像编辑系统。

Abstract: Image-based object removal often erases only the named target, leaving behind interaction evidence that renders the result semantically inconsistent. We formalize this problem as Interaction-Consistent Object Removal (ICOR), which requires removing not only the target object but also associated interaction elements, such as lighting-dependent effects, physically connected objects, targetproduced elements, and contextually linked objects. To address this task, we propose Reasoning-Enhanced Object Removal with MLLM (REORM), a reasoningenhanced object removal framework that leverages multimodal large language models to infer which elements must be jointly removed. REORM features a modular design that integrates MLLM-driven analysis, mask-guided removal, and a self-correction mechanism, along with a local-deployment variant that supports accurate editing under limited resources. To support evaluation, we introduce ICOREval, a benchmark consisting of instruction-driven removals with rich interaction dependencies. On ICOREval, REORM outperforms state-of-the-art image editing systems, demonstrating its effectiveness in producing interactionconsistent results.

</details>


### [159] [ReDiStory: Region-Disentangled Diffusion for Consistent Visual Story Generation](https://arxiv.org/abs/2602.01303)
*Ayushman Sarkar,Zhenyu Yu,Chu Chen,Wei Tang,Kangning Cui,Mohd Yamani Idna Idris*

Main category: cs.CV

TL;DR: ReDiStory通过分解和重组提示嵌入，提升多帧故事生成的身份一致性，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂故事中常因跨帧语义干扰而削弱身份保持，ReDiStory旨在解决这一问题。

Method: ReDiStory将文本嵌入显式分解为身份相关和帧特定组件，并通过抑制跨帧共享方向来解相关帧嵌入，从而减少跨帧干扰。

Result: 在ConsiStory+基准测试中，ReDiStory在多个身份一致性指标上优于1Prompt1Story。

Conclusion: ReDiStory通过推理时的提示嵌入重组，显著提升了多帧故事生成中的身份一致性，同时保持了提示的忠实度，无需修改扩散参数或额外监督。

Abstract: Generating coherent visual stories requires maintaining subject identity across multiple images while preserving frame-specific semantics. Recent training-free methods concatenate identity and frame prompts into a unified representation, but this often introduces inter-frame semantic interference that weakens identity preservation in complex stories. We propose ReDiStory, a training-free framework that improves multi-frame story generation via inference-time prompt embedding reorganization. ReDiStory explicitly decomposes text embeddings into identity-related and frame-specific components, then decorrelates frame embeddings by suppressing shared directions across frames. This reduces cross-frame interference without modifying diffusion parameters or requiring additional supervision. Under identical diffusion backbones and inference settings, ReDiStory improves identity consistency while maintaining prompt fidelity. Experiments on the ConsiStory+ benchmark show consistent gains over 1Prompt1Story on multiple identity consistency metrics. Code is available at: https://github.com/YuZhenyuLindy/ReDiStory

</details>


### [160] [StoryState: Agent-Based State Control for Consistent and Editable Storybooks](https://arxiv.org/abs/2602.01305)
*Ayushman Sarkar,Zhenyu Yu,Wei Tang,Chu Chen,Kangning Cui,Mohd Yamani Idna Idris*

Main category: cs.CV

TL;DR: StoryState通过显式故事状态和代理编排，提升了多页故事生成的编辑效率和一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态模型在生成故事书时，底层故事状态（如角色、世界设置和页面级对象）是隐式的，导致编辑粗粒度且容易破坏视觉一致性。

Method: StoryState是一个基于代理的编排层，在无需训练的文生图生成基础上，通过结构化对象（角色表、全局设置和每页场景约束）和少量LLM代理来维护状态并生成提示。

Result: 系统级实验表明，StoryState在多页编辑任务中实现了局部化页面编辑、提升了跨页一致性，减少了意外更改、交互轮次和编辑时间。

Conclusion: StoryState通过引入显式可编辑的故事状态，提升了多页故事编辑的局部化能力、跨页一致性和效率，接近Gemini Storybook的一次性一致性。

Abstract: Large multimodal models have enabled one-click storybook generation, where users provide a short description and receive a multi-page illustrated story. However, the underlying story state, such as characters, world settings, and page-level objects, remains implicit, making edits coarse-grained and often breaking visual consistency. We present StoryState, an agent-based orchestration layer that introduces an explicit and editable story state on top of training-free text-to-image generation. StoryState represents each story as a structured object composed of a character sheet, global settings, and per-page scene constraints, and employs a small set of LLM agents to maintain this state and derive 1Prompt1Story-style prompts for generation and editing. Operating purely through prompts, StoryState is model-agnostic and compatible with diverse generation backends. System-level experiments on multi-page editing tasks show that StoryState enables localized page edits, improves cross-page consistency, and reduces unintended changes, interaction turns, and editing time compared to 1Prompt1Story, while approaching the one-shot consistency of Gemini Storybook. Code is available at https://github.com/YuZhenyuLindy/StoryState

</details>


### [161] [DeCorStory: Gram-Schmidt Prompt Embedding Decorrelation for Consistent Storytelling](https://arxiv.org/abs/2602.01306)
*Ayushman Sarkar,Zhenyu Yu,Mohd Yamani Idna Idris*

Main category: cs.CV

TL;DR: DeCorStory 通过嵌入去相关和身份保留技术，解决了文本到图像叙事中的帧间一致性问题，无需训练即可提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有无需训练的方法（如 One-Prompt-One-Story）通过将所有提示拼接为单一序列，容易导致嵌入相关性过强，引发颜色泄漏、背景混合和身份漂移问题。

Method: DeCorStory 采用 Gram-Schmidt 提示嵌入去相关技术对帧级语义进行正交化，随后通过奇异值重加权强化提示特定信息，并结合身份保留的交叉注意力机制在扩散过程中稳定角色身份。

Result: 实验表明，DeCorStory 在提示-图像对齐、身份一致性和视觉多样性方面均取得显著改进，在无需训练的基线方法中达到最先进性能。

Conclusion: DeCorStory 是一种无需训练的推理时框架，通过显式减少帧间语义干扰，显著提升了文本到图像叙事中的视觉和语义一致性。该方法无需模型修改或微调，可直接集成到现有扩散流程中，实验证明了其在提示-图像对齐、身份一致性和视觉多样性方面的优越性能。

Abstract: Maintaining visual and semantic consistency across frames is a key challenge in text-to-image storytelling. Existing training-free methods, such as One-Prompt-One-Story, concatenate all prompts into a single sequence, which often induces strong embedding correlation and leads to color leakage, background blending, and identity drift. We propose DeCorStory, a training-free inference-time framework that explicitly reduces inter-frame semantic interference. DeCorStory applies Gram-Schmidt prompt embedding decorrelation to orthogonalize frame-level semantics, followed by singular value reweighting to strengthen prompt-specific information and identity-preserving cross-attention to stabilize character identity during diffusion. The method requires no model modification or fine-tuning and can be seamlessly integrated into existing diffusion pipelines. Experiments demonstrate consistent improvements in prompt-image alignment, identity consistency, and visual diversity, achieving state-of-the-art performance among training-free baselines. Code is available at: https://github.com/YuZhenyuLindy/DeCorStory

</details>


### [162] [FlowCast: Trajectory Forecasting for Scalable Zero-Cost Speculative Flow Matching](https://arxiv.org/abs/2602.01329)
*Divya Jyoti Bajpai,Shubham Agarwal,Apoorv Saxena,Kuldeep Kulkarni,Subrata Mitra,Manjesh Kumar Hanawal*

Main category: cs.CV

TL;DR: FlowCast是一种无需训练的推测生成框架，通过恒定速度预测加速FM模型推理，实现2.5倍加速且无质量损失。


<details>
  <summary>Details</summary>
Motivation: 现有加速方法（如蒸馏、截断或一致性训练）存在质量下降、高成本重新训练或缺乏通用性的问题，限制了FM模型在实时或交互应用中的潜力。

Method: FlowCast通过推测当前速度的未来值来跳过冗余步骤，仅当推测值在均方误差阈值内时接受，从而在稳定区域跳过步骤，在复杂区域保留精度。

Result: FlowCast在图像生成、视频生成和编辑任务中实现了超过2.5倍的加速，且与标准完整生成相比无质量损失。

Conclusion: FlowCast是一种无需训练的推测生成框架，通过利用FM模型保持恒定速度的特性，显著加速推理过程，且在图像生成、视频生成和编辑任务中实现了超过2.5倍的加速，且不损失生成质量。

Abstract: Flow Matching (FM) has recently emerged as a powerful approach for high-quality visual generation. However, their prohibitively slow inference due to a large number of denoising steps limits their potential use in real-time or interactive applications. Existing acceleration methods, like distillation, truncation, or consistency training, either degrade quality, incur costly retraining, or lack generalization. We propose FlowCast, a training-free speculative generation framework that accelerates inference by exploiting the fact that FM models are trained to preserve constant velocity. FlowCast speculates future velocity by extrapolating current velocity without incurring additional time cost, and accepts it if it is within a mean-squared error threshold. This constant-velocity forecasting allows redundant steps in stable regions to be aggressively skipped while retaining precision in complex ones. FlowCast is a plug-and-play framework that integrates seamlessly with any FM model and requires no auxiliary networks. We also present a theoretical analysis and bound the worst-case deviation between speculative and full FM trajectories. Empirical evaluations demonstrate that FlowCast achieves $>2.5\times$ speedup in image generation, video generation, and editing tasks, outperforming existing baselines with no quality loss as compared to standard full generation.

</details>


### [163] [What Does Vision Tool-Use Reinforcement Learning Really Learn? Disentangling Tool-Induced and Intrinsic Effects for Crop-and-Zoom](https://arxiv.org/abs/2602.01334)
*Yan Ma,Weiyu Zhang,Tianle Li,Linge Du,Xuyang Shen,Pengfei Liu*

Main category: cs.CV

TL;DR: MED框架分析表明，视觉工具使用RL的性能提升主要来自内在学习，工具使用RL更多是减少损害而非显著提升工具掌握能力。


<details>
  <summary>Details</summary>
Motivation: 探讨视觉工具使用RL的性能提升是否由工具使用改进或内在能力演化驱动。

Method: 引入了MED（Measure-Explain-Diagnose）框架，通过粗到细的分析方法，将内在能力变化与工具诱导效应分离，并将工具诱导的性能差异分解为增益和损害项。

Result: 发现性能提升主要由内在学习驱动，而工具使用RL主要减少工具诱导的损害（如减少调用错误和减弱工具模式干扰），在工具纠正内在失败方面进展有限。

Conclusion: 当前的视觉工具使用强化学习（RL）主要是学会与工具安全共存，而非真正掌握工具的使用。

Abstract: Vision tool-use reinforcement learning (RL) can equip vision-language models with visual operators such as crop-and-zoom and achieves strong performance gains, yet it remains unclear whether these gains are driven by improvements in tool use or evolving intrinsic capabilities.We introduce MED (Measure-Explain-Diagnose), a coarse-to-fine framework that disentangles intrinsic capability changes from tool-induced effects, decomposes the tool-induced performance difference into gain and harm terms, and probes the mechanisms driving their evolution. Across checkpoint-level analyses on two VLMs with different tool priors and six benchmarks, we find that improvements are dominated by intrinsic learning, while tool-use RL mainly reduces tool-induced harm (e.g., fewer call-induced errors and weaker tool schema interference) and yields limited progress in tool-based correction of intrinsic failures. Overall, current vision tool-use RL learns to coexist safely with tools rather than master them.

</details>


### [164] [Beyond Pixels: Visual Metaphor Transfer via Schema-Driven Agentic Reasoning](https://arxiv.org/abs/2602.01335)
*Yu Xu,Yuxin Zhang,Juan Cao,Lin Gao,Chunyu Wang,Oliver Deussen,Tong-Yee Lee,Fan Tang*

Main category: cs.CV

TL;DR: 本文提出了一种多代理框架，通过Schema Grammar实现视觉隐喻转移，显著优于现有方法，适用于广告和媒体创意应用。


<details>
  <summary>Details</summary>
Motivation: 现有生成模型局限于像素级指令对齐和表面外观保留，无法捕捉真正的隐喻生成所需的抽象逻辑，因此提出了视觉隐喻转移（VMT）任务。

Method: 提出了一种认知启发的多代理框架，通过新颖的Schema Grammar（'G'）操作概念混合理论（CBT），实现跨领域逻辑重新实例化。

Result: 广泛的实验和人类评估表明，该方法在隐喻一致性、类比适当性和视觉创意性方面显著优于现有基线。

Conclusion: 该方法在隐喻一致性、类比适当性和视觉创意性方面显著优于现有技术，为广告和媒体中的自动化高影响力创意应用铺平了道路。

Abstract: A visual metaphor constitutes a high-order form of human creativity, employing cross-domain semantic fusion to transform abstract concepts into impactful visual rhetoric. Despite the remarkable progress of generative AI, existing models remain largely confined to pixel-level instruction alignment and surface-level appearance preservation, failing to capture the underlying abstract logic necessary for genuine metaphorical generation. To bridge this gap, we introduce the task of Visual Metaphor Transfer (VMT), which challenges models to autonomously decouple the "creative essence" from a reference image and re-materialize that abstract logic onto a user-specified target subject. We propose a cognitive-inspired, multi-agent framework that operationalizes Conceptual Blending Theory (CBT) through a novel Schema Grammar ("G"). This structured representation decouples relational invariants from specific visual entities, providing a rigorous foundation for cross-domain logic re-instantiation. Our pipeline executes VMT through a collaborative system of specialized agents: a perception agent that distills the reference into a schema, a transfer agent that maintains generic space invariance to discover apt carriers, a generation agent for high-fidelity synthesis and a hierarchical diagnostic agent that mimics a professional critic, performing closed-loop backtracking to identify and rectify errors across abstract logic, component selection, and prompt encoding. Extensive experiments and human evaluations demonstrate that our method significantly outperforms SOTA baselines in metaphor consistency, analogy appropriateness, and visual creativity, paving the way for automated high-impact creative applications in advertising and media. Source code will be made publicly available.

</details>


### [165] [MTC-VAE: Multi-Level Temporal Compression with Content Awareness](https://arxiv.org/abs/2602.01340)
*Yubo Dong,Linchao Zhu*

Main category: cs.CV

TL;DR: 提出多级时间压缩VAE技术，通过最小化微调解决高压缩率下的性能下降问题，并与扩散生成模型（DiT）成功集成，展示了广泛的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 在连续变分自编码器（VAE）中，提高压缩率是理想目标，但增加采样层而不扩展隐藏通道维度会导致效率显著下降。因此，需要一种方法既能实现高压缩率，又能避免性能下降。

Method: 通过引入多级时间压缩技术，对固定压缩率的VAE进行最小化微调，以应对高压缩率下的性能下降问题。此外，研究了不同压缩级别对视频片段性能的影响，并探索了多级时间压缩VAE与扩散生成模型（DiT）的集成。

Result: 实验证明，多级时间压缩技术能够有效抵消高压缩率下的性能下降，并且与扩散生成模型（DiT）的集成展示了良好的训练兼容性。

Conclusion: 本研究提出了一种将固定压缩率的VAE转换为支持多级时间压缩的模型的技术，并通过实验验证了该方法在高压缩率下的有效性。同时，展示了多级时间压缩VAE与扩散生成模型（DiT）的兼容性，为潜在视频扩散模型（LVDM）的应用提供了新的可能性。

Abstract: Latent Video Diffusion Models (LVDMs) rely on Variational Autoencoders (VAEs) to compress videos into compact latent representations. For continuous Variational Autoencoders (VAEs), achieving higher compression rates is desirable; yet, the efficiency notably declines when extra sampling layers are added without expanding the dimensions of hidden channels. In this paper, we present a technique to convert fixed compression rate VAEs into models that support multi-level temporal compression, providing a straightforward and minimal fine-tuning approach to counteract performance decline at elevated compression rates.Moreover, we examine how varying compression levels impact model performance over video segments with diverse characteristics, offering empirical evidence on the effectiveness of our proposed approach. We also investigate the integration of our multi-level temporal compression VAE with diffusion-based generative models, DiT, highlighting successful concurrent training and compatibility within these frameworks. This investigation illustrates the potential uses of multi-level temporal compression.

</details>


### [166] [Adaptive Visual Autoregressive Acceleration via Dual-Linkage Entropy Analysis](https://arxiv.org/abs/2602.01345)
*Yu Zhang,Jingyi Liu,Feng Liu,Duoqian Miao,Qi Zhang,Kexue Fu,Changwei Wang,Longbing Cao*

Main category: cs.CV

TL;DR: NOVA通过熵分析自适应地减少VAR模型的标记数量，动态调整比例以加速推理并保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有VAR标记减少方法存在启发式阶段划分、非自适应调度和有限加速范围等关键限制，未能充分利用加速潜力。熵变化内在反映了预测不确定性的转变，为捕捉建模动态演化提供了原则性度量。

Method: NOVA通过在线识别规模熵增长的拐点，自适应地确定推理期间的加速激活规模，并通过规模联动和层联动比例调整，动态计算每个规模和层的不同标记减少比例，修剪低熵标记并重用先前规模残差的缓存。

Result: 大量实验和分析验证了NOVA作为一种简单有效的无需训练加速框架的有效性。

Conclusion: NOVA是一种简单有效的无需训练的加速框架，通过熵分析自适应地确定加速激活规模，动态计算每个规模和层的不同标记减少比例，从而在保持生成质量的同时加速推理。

Abstract: Visual AutoRegressive modeling (VAR) suffers from substantial computational cost due to the massive token count involved. Failing to account for the continuous evolution of modeling dynamics, existing VAR token reduction methods face three key limitations: heuristic stage partition, non-adaptive schedules, and limited acceleration scope, thereby leaving significant acceleration potential untapped. Since entropy variation intrinsically reflects the transition of predictive uncertainty, it offers a principled measure to capture modeling dynamics evolution. Therefore, we propose NOVA, a training-free token reduction acceleration framework for VAR models via entropy analysis. NOVA adaptively determines the acceleration activation scale during inference by online identifying the inflection point of scale entropy growth. Through scale-linkage and layer-linkage ratio adjustment, NOVA dynamically computes distinct token reduction ratios for each scale and layer, pruning low-entropy tokens while reusing the cache derived from the residuals at the prior scale to accelerate inference and maintain generation quality. Extensive experiments and analyses validate NOVA as a simple yet effective training-free acceleration framework.

</details>


### [167] [T2M Mamba: Motion Periodicity-Saliency Coupling Approach for Stable Text-Driven Motion Generation](https://arxiv.org/abs/2602.01352)
*Xingzu Zhan,Chen Xie,Honghang Chen,Yixun Lin,Xiaochun Mai*

Main category: cs.CV

TL;DR: T2M Mamba通过结合周期性和显著性感知的Mamba模块以及PDCAM模块，解决了文本到动作生成中的长序列漂移和语义脆弱性问题，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有文本到动作生成模型存在两个核心问题：一是将动作周期性和关键帧显著性视为独立因素，导致长序列生成漂移；二是对语义等价转述脆弱，易因同义词替换导致不稳定或错误的动作生成。

Method: 提出Periodicity-Saliency Aware Mamba模块，利用增强的Density Peaks Clustering算法进行关键帧权重估计，并通过FFT加速的自相关方法估计动作周期性；构建PDCAM模块以增强文本与动作嵌入的鲁棒对齐。

Result: 在HumanML3D和KIT-ML数据集上的实验表明，T2M Mamba取得了FID 0.068的优异表现，并在所有其他指标上均获得一致提升。

Conclusion: T2M Mamba通过结合周期性和显著性感知的Mamba模块以及周期性差分跨模态对齐模块（PDCAM），有效解决了现有文本到动作生成模型中的关键问题，显著提升了生成动作的稳定性和准确性。

Abstract: Text-to-motion generation, which converts motion language descriptions into coherent 3D human motion sequences, has attracted increasing attention in fields, such as avatar animation and humanoid robotic interaction. Though existing models have achieved significant fidelity, they still suffer from two core limitations: (i) They treat motion periodicity and keyframe saliency as independent factors, overlooking their coupling and causing generation drift in long sequences. (ii) They are fragile to semantically equivalent paraphrases, where minor synonym substitutions distort textual embeddings, propagating through the decoder and producing unstable or erroneous motions. In this work, we propose T2M Mamba to address these limitations by (i) proposing Periodicity-Saliency Aware Mamba, which utilizes novel algorithms for keyframe weight estimation via enhanced Density Peaks Clustering and motion periodicity estimation via FFT-accelerated autocorrelation to capture coupled dynamics with minimal computational overhead, and (ii) constructing a Periodic Differential Cross-modal Alignment Module (PDCAM) to enhance robust alignment of textual and motion embeddings. Extensive experiments on HumanML3D and KIT-ML datasets have been conducted, confirming the effectiveness of our approach, achieving an FID of 0.068 and consistent gains on all other metrics.

</details>


### [168] [Exposing and Defending the Achilles' Heel of Video Mixture-of-Experts](https://arxiv.org/abs/2602.01369)
*Songping Wang,Qinglong Liu,Yueming Lyu,Ning Li,Ziwen He,Caifeng Shan*

Main category: cs.CV

TL;DR: 论文提出TLGA和J-TLGA攻击方法揭示MoE的组件级弱点，并设计J-TLAT框架增强鲁棒性，降低推理成本。


<details>
  <summary>Details</summary>
Motivation: 尽管MoE在视频理解任务中表现优异，但其对抗鲁棒性尚未充分探索。现有攻击方法通常将MoE视为统一架构，忽视了路由器和专家模块的独立与协作弱点。

Method: 论文首先设计了针对路由器的攻击（TLGA），揭示了其独立弱点；随后提出联合时间Lipschitz引导攻击（J-TLGA），协同扰动路由器和专家模块；最终提出联合时间Lipschitz对抗训练（J-TLAT）进行防御。

Result: J-TLAT框架显著提升了对抗鲁棒性，减少了60%以上的推理成本，并在多种场景下验证了其有效性。

Conclusion: 该论文提出了J-TLAT框架，通过联合训练增强MoE架构的对抗鲁棒性，有效缓解了独立和协作弱点，并在多种数据集和架构上表现一致。

Abstract: Mixture-of-Experts (MoE) has demonstrated strong performance in video understanding tasks, yet its adversarial robustness remains underexplored. Existing attack methods often treat MoE as a unified architecture, overlooking the independent and collaborative weaknesses of key components such as routers and expert modules. To fill this gap, we propose Temporal Lipschitz-Guided Attacks (TLGA) to thoroughly investigate component-level vulnerabilities in video MoE models. We first design attacks on the router, revealing its independent weaknesses. Building on this, we introduce Joint Temporal Lipschitz-Guided Attacks (J-TLGA), which collaboratively perturb both routers and experts. This joint attack significantly amplifies adversarial effects and exposes the Achilles' Heel (collaborative weaknesses) of the MoE architecture. Based on these insights, we further propose Joint Temporal Lipschitz Adversarial Training (J-TLAT). J-TLAT performs joint training to further defend against collaborative weaknesses, enhancing component-wise robustness. Our framework is plug-and-play and reduces inference cost by more than 60% compared with dense models. It consistently enhances adversarial robustness across diverse datasets and architectures, effectively mitigating both the independent and collaborative weaknesses of MoE.

</details>


### [169] [PolyGen: Fully Synthetic Vision-Language Training via Multi-Generator Ensembles](https://arxiv.org/abs/2602.01370)
*Leonardo Brusini,Cristian Sbrolli,Eugenio Lomurno,Toshihiko Yamasaki,Matteo Matteucci*

Main category: cs.CV

TL;DR: PolyGen通过多源生成器和硬负样本课程，提升合成数据的多样性和鲁棒性，显著优于单一生成器方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法依赖单一生成器导致的频谱偏差和特征多样性不足问题，通过多源生成器覆盖更广泛的流形。

Method: 采用Polylithic方法训练不同架构生成器的交集，并引入Programmatic Hard Negative课程来增强细粒度语法理解。

Result: PolyGen在多任务基准上比SynthCLIP提升19.0%，在SugarCrepe++组合性基准上提升9.1%。

Conclusion: PolyGen通过多源生成器和程序化硬负样本课程，证明了结构多样性比单一数据源扩展更高效，显著提升了多任务和组合性基准的表现。

Abstract: Synthetic data offers a scalable solution for vision-language pre-training, yet current state-of-the-art methods typically rely on scaling up a single generative backbone, which introduces generator-specific spectral biases and limits feature diversity. In this work, we introduce PolyGen, a framework that redefines synthetic data construction by prioritizing manifold coverage and compositional rigor over simple dataset size. PolyGen employs a Polylithic approach to train on the intersection of architecturally distinct generators, effectively marginalizing out model-specific artifacts. Additionally, we introduce a Programmatic Hard Negative curriculum that enforces fine-grained syntactic understanding. By structurally reallocating the same data budget from unique captions to multi-source variations, PolyGen achieves a more robust feature space, outperforming the leading single-source baseline (SynthCLIP) by +19.0% on aggregate multi-task benchmarks and on the SugarCrepe++ compositionality benchmark (+9.1%). These results demonstrate that structural diversity is a more data-efficient scaling law than simply increasing the volume of single-source samples.

</details>


### [170] [PromptRL: Prompt Matters in RL for Flow-Based Image Generation](https://arxiv.org/abs/2602.01382)
*Fu-Yun Wang,Han Zhang,Michael Gharbi,Hongsheng Li,Taesung Park*

Main category: cs.CV

TL;DR: PromptRL通过语言模型优化提示，解决了流匹配模型在强化学习中的样本效率低下和提示过拟合问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 当前流匹配模型的强化学习流程存在样本效率低下和提示过拟合两大问题，限制了其性能和应用。

Method: 提出了PromptRL框架，将语言模型作为可训练的提示优化代理直接整合到基于流的强化学习优化循环中。

Result: PromptRL在多个基准测试中取得了最先进的性能，如GenEval得分0.97，OCR准确率0.98，PickScore得分24.05。同时，在大规模图像编辑模型上也验证了其有效性，EditReward从1.19提升至1.43。

Conclusion: PromptRL通过结合语言模型作为可训练的提示优化代理，显著提升了流匹配模型在文本到图像生成中的性能和效率，同时解决了样本效率低下和提示过拟合的问题。

Abstract: Flow matching models (FMs) have revolutionized text-to-image (T2I) generation, with reinforcement learning (RL) serving as a critical post-training strategy for alignment with reward objectives. In this research, we show that current RL pipelines for FMs suffer from two underappreciated yet important limitations: sample inefficiency due to insufficient generation diversity, and pronounced prompt overfitting, where models memorize specific training formulations and exhibit dramatic performance collapse when evaluated on semantically equivalent but stylistically varied prompts. We present PromptRL (Prompt Matters in RL for Flow-Based Image Generation), a framework that incorporates language models (LMs) as trainable prompt refinement agents directly within the flow-based RL optimization loop. This design yields two complementary benefits: rapid development of sophisticated prompt rewriting capabilities and, critically, a synergistic training regime that reshapes the optimization dynamics. PromptRL achieves state-of-the-art performance across multiple benchmarks, obtaining scores of 0.97 on GenEval, 0.98 on OCR accuracy, and 24.05 on PickScore.
  Furthermore, we validate the effectiveness of our RL approach on large-scale image editing models, improving the EditReward of FLUX.1-Kontext from 1.19 to 1.43 with only 0.06 million rollouts, surpassing Gemini 2.5 Flash Image (also known as Nano Banana), which scores 1.37, and achieving comparable performance with ReasonNet (1.44), which relied on fine-grained data annotations along with a complex multi-stage training. Our extensive experiments empirically demonstrate that PromptRL consistently achieves higher performance ceilings while requiring over 2$\times$ fewer rollouts compared to naive flow-only RL. Our code is available at https://github.com/G-U-N/UniRL.

</details>


### [171] [Stronger Semantic Encoders Can Harm Relighting Performance: Probing Visual Priors via Augmented Latent Intrinsics](https://arxiv.org/abs/2602.01391)
*Xiaoyan Xing,Xiao Zhang,Sezer Karaoglu,Theo Gevers,Anand Bhattad*

Main category: cs.CV

TL;DR: ALI通过融合像素对齐特征和自我监督细化，显著提升了复杂材质的图像重新照明效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在挑战性材质（如金属和玻璃）上的表现不佳，推测更强的预训练视觉先验可能解决这一问题，但发现语义抽象与光度保真度之间存在根本性权衡。

Method: ALI结合了像素对齐的视觉编码器特征到潜在内在框架中，并采用自我监督细化策略来缓解配对真实世界数据的稀缺性。

Result: ALI在未标记的真实世界图像对上训练，并在复杂、高光材质上实现了最大的重新照明改进。

Conclusion: ALI通过融合像素对齐的视觉编码器特征和自我监督细化策略，在复杂材质（如金属和玻璃）的重新照明任务中取得了显著改进。

Abstract: Image-to-image relighting requires representations that disentangle scene properties from illumination. Recent methods rely on latent intrinsic representations but remain under-constrained and often fail on challenging materials such as metal and glass. A natural hypothesis is that stronger pretrained visual priors should resolve these failures. We find the opposite: features from top-performing semantic encoders often degrade relighting quality, revealing a fundamental trade-off between semantic abstraction and photometric fidelity. We study this trade-off and introduce Augmented Latent Intrinsics (ALI), which balances semantic context and dense photometric structure by fusing features from a pixel-aligned visual encoder into a latent-intrinsic framework, together with a self-supervised refinement strategy to mitigate the scarcity of paired real-world data. Trained only on unlabeled real-world image pairs and paired with a dense, pixel-aligned visual prior, ALI achieves strong improvements in relighting, with the largest gains on complex, specular materials. Project page: https:\\augmented-latent-intrinsics.github.io

</details>


### [172] [Where to Attend: A Principled Vision-Centric Position Encoding with Parabolas](https://arxiv.org/abs/2602.01418)
*Christoffer Koo Øhrstrøm,Rafael I. Cabral Muchacho,Yifei Dong,Filippos Moumtzidellis,Ronja Güldenring,Florian T. Pokorny,Lazaros Nalpantidis*

Main category: cs.CV

TL;DR: PaPE是一种针对视觉模态设计的抛物线位置编码，在多项任务中表现优异，泛化能力强。


<details>
  <summary>Details</summary>
Motivation: 现有位置编码方法未充分适应视觉模态特性，需填补这一空白。

Method: 设计了基于抛物线的位置编码（PaPE），考虑了视觉模态的特性（如平移不变性、旋转不变性等）。

Result: 在8个数据集中的7个上表现最佳，ImageNet-1K上泛化能力显著。

Conclusion: PaPE和PaPE-RI在大多数数据集上表现优异，尤其在ImageNet-1K上展现出显著的泛化能力，最高提升10.5%。

Abstract: We propose Parabolic Position Encoding (PaPE), a parabola-based position encoding for vision modalities in attention-based architectures. Given a set of vision tokens-such as images, point clouds, videos, or event camera streams-our objective is to encode their positions while accounting for the characteristics of vision modalities. Prior works have largely extended position encodings from 1D-sequences in language to nD-structures in vision, but only with partial account of vision characteristics. We address this gap by designing PaPE from principles distilled from prior work: translation invariance, rotation invariance (PaPE-RI), distance decay, directionality, and context awareness. We evaluate PaPE on 8 datasets that span 4 modalities. We find that either PaPE or PaPE-RI achieves the top performance on 7 out of 8 datasets. Extrapolation experiments on ImageNet-1K show that PaPE extrapolates remarkably well, improving in absolute terms by up to 10.5% over the next-best position encoding. Code is available at https://github.com/DTU-PAS/parabolic-position-encoding.

</details>


### [173] [BioTamperNet: Affinity-Guided State-Space Model Detecting Tampered Biomedical Images](https://arxiv.org/abs/2602.01435)
*Soumyaroop Nandi,Prem Natarajan*

Main category: cs.CV

TL;DR: BioTamperNet 通过亲和力引导的注意力和 SSM 启发的线性注意力，高效检测生物医学图像中的篡改区域，实验显示其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有取证模型主要针对自然图像训练，在生物医学数据中表现不佳，而细微的篡改可能影响实验有效性，因此需要专门针对生物医学图像的检测方法。

Method: BioTamperNet 引入了亲和力引导的自注意力和交叉注意力模块，结合轻量级 SSM 启发的线性注意力机制，实现高效的端到端训练，同时定位篡改区域及其源对应区域。

Result: 在生物取证基准数据集上的广泛实验表明，BioTamperNet 在准确检测重复区域方面显著优于竞争基线。

Conclusion: BioTamperNet 是一种新颖的框架，通过结合亲和力引导的注意力和轻量级 SSM 启发的线性注意力机制，有效检测生物医学图像中的篡改区域，显著提升了现有基准数据集的检测准确性。

Abstract: We propose BioTamperNet, a novel framework for detecting duplicated regions in tampered biomedical images, leveraging affinity-guided attention inspired by State Space Model (SSM) approximations. Existing forensic models, primarily trained on natural images, often underperform on biomedical data where subtle manipulations can compromise experimental validity. To address this, BioTamperNet introduces an affinity-guided self-attention module to capture intra-image similarities and an affinity-guided cross-attention module to model cross-image correspondences. Our design integrates lightweight SSM-inspired linear attention mechanisms to enable efficient, fine-grained localization. Trained end-to-end, BioTamperNet simultaneously identifies tampered regions and their source counterparts. Extensive experiments on the benchmark bio-forensic datasets demonstrate significant improvements over competitive baselines in accurately detecting duplicated regions. Code - https://github.com/SoumyaroopNandi/BioTamperNet

</details>


### [174] [Cross-Paradigm Evaluation of Gaze-Based Semantic Object Identification for Intelligent Vehicles](https://arxiv.org/abs/2602.01452)
*Penghao Deng,Jidong J. Yang,Jiachen Bian*

Main category: cs.CV

TL;DR: 论文通过三种视觉方法研究驾驶员凝视行为与道路场景语义的关联，发现YOLOv13和Qwen2.5-VL-32b表现最佳，为智能驾驶员监控系统设计提供指导。


<details>
  <summary>Details</summary>
Motivation: 研究驾驶员在驾驶过程中视觉注意力的分布（通过凝视行为表征）对于开发下一代高级驾驶辅助系统和提高道路安全至关重要。

Method: 论文采用三种不同的视觉方法进行研究：直接目标检测（YOLOv13）、分割辅助分类（SAM2与EfficientNetV2配对对比YOLOv13）和基于查询的视觉语言模型（Qwen2.5-VL-7b对比Qwen2.5-VL-32b）。

Result: 结果表明，直接目标检测（YOLOv13）和Qwen2.5-VL-32b显著优于其他方法，宏观F1分数超过0.84。大型VLM（Qwen2.5-VL-32b）在识别小型、安全关键对象（如交通灯）尤其在夜间恶劣条件下表现出卓越的鲁棒性和性能。

Conclusion: 论文揭示了传统检测器的实时效率与大型视觉语言模型（VLMs）提供的更丰富上下文理解和鲁棒性之间的权衡，为未来人类感知智能驾驶员监控系统的设计提供了关键见解和实用指导。

Abstract: Understanding where drivers direct their visual attention during driving, as characterized by gaze behavior, is critical for developing next-generation advanced driver-assistance systems and improving road safety. This paper tackles this challenge as a semantic identification task from the road scenes captured by a vehicle's front-view camera. Specifically, the collocation of gaze points with object semantics is investigated using three distinct vision-based approaches: direct object detection (YOLOv13), segmentation-assisted classification (SAM2 paired with EfficientNetV2 versus YOLOv13), and query-based Vision-Language Models, VLMs (Qwen2.5-VL-7b versus Qwen2.5-VL-32b). The results demonstrate that the direct object detection (YOLOv13) and Qwen2.5-VL-32b significantly outperform other approaches, achieving Macro F1-Scores over 0.84. The large VLM (Qwen2.5-VL-32b), in particular, exhibited superior robustness and performance for identifying small, safety-critical objects such as traffic lights, especially in adverse nighttime conditions. Conversely, the segmentation-assisted paradigm suffers from a "part-versus-whole" semantic gap that led to large failure in recall. The results reveal a fundamental trade-off between the real-time efficiency of traditional detectors and the richer contextual understanding and robustness offered by large VLMs. These findings provide critical insights and practical guidance for the design of future human-aware intelligent driver monitoring systems.

</details>


### [175] [Understanding vision transformer robustness through the lens of out-of-distribution detection](https://arxiv.org/abs/2602.01459)
*Joey Kuang,Alexander Wong*

Main category: cs.CV

TL;DR: 研究量化视觉变换器在OOD检测中的表现，发现大规模预训练可能降低低比特量化鲁棒性，建议数据增强作为替代方案。


<details>
  <summary>Details</summary>
Motivation: 尽管视觉变换器在视觉任务中表现出色，但实现其可访问性和实时使用仍具挑战性。量化虽能降低内存和推理成本，但可能导致性能损失。研究旨在通过探索OOD情况来理解量化属性。

Method: 研究了量化的小型流行视觉变换器（DeiT、DeiT3和ViT）在常见OOD数据集上的行为，分析了ID任务行为和OOD情况下的注意力机制。

Result: ID分析显示4位模型的初始不稳定性，尤其是基于ImageNet-22k训练的模型。OOD检测进一步揭示，ViT和DeiT3在ImageNet-22k预训练后，从全精度到4位的AUPR-out量化差异分别为15.0%和19.2%，而仅基于ImageNet-1k的模型差异较小。

Conclusion: 预训练于大规模数据集可能阻碍低比特量化在OOD检测中的鲁棒性，数据增强可能是更有利的选择。

Abstract: Vision transformers have shown remarkable performance in vision tasks, but enabling them for accessible and real-time use is still challenging. Quantization reduces memory and inference costs at the risk of performance loss. Strides have been made to mitigate low precision issues mainly by understanding in-distribution (ID) task behaviour, but the attention mechanism may provide insight on quantization attributes by exploring out-of-distribution (OOD) situations. We investigate the behaviour of quantized small-variant popular vision transformers (DeiT, DeiT3, and ViT) on common OOD datasets. ID analyses show the initial instabilities of 4-bit models, particularly of those trained on the larger ImageNet-22k, as the strongest FP32 model, DeiT3, sharply drop 17% from quantization error to be one of the weakest 4-bit models. While ViT shows reasonable quantization robustness for ID calibration, OOD detection reveals more: ViT and DeiT3 pretrained on ImageNet-22k respectively experienced a 15.0% and 19.2% average quantization delta in AUPR-out between full precision to 4-bit while their ImageNet-1k-only counterparts experienced a 9.5% and 12.0% delta. Overall, our results suggest pretraining on large scale datasets may hinder low-bit quantization robustness in OOD detection and that data augmentation may be a more beneficial option.

</details>


### [176] [Preserving Localized Patch Semantics in VLMs](https://arxiv.org/abs/2602.01530)
*Parsa Esmaeilkhani,Longin Jan Latecki*

Main category: cs.CV

TL;DR: LLL通过补充损失保持视觉令牌的局部信息，提升Logit Lens的可解释性和视觉任务性能。


<details>
  <summary>Details</summary>
Motivation: Logit Lens在视觉语言模型（VLMs）中应用时，视觉令牌的内容常被扩散到语言令牌中，导致视觉信息的局部性丧失，使得Logit Lens可视化在解释性上失效。

Method: 引入了一种补充损失（LLL）到下一令牌预测（NTP）中，旨在防止视觉令牌丢失其对应的图像区域的视觉表示。LLL通过语义对齐视觉令牌嵌入与描述其图像区域的文本概念来实现这一目标，无需架构修改或大规模训练。

Result: LLL不仅使Logit Lens可视化产生有意义的对象置信度图，还提高了如分割等视觉中心任务的性能。

Conclusion: 提出的Logit Lens Loss（LLL）通过保持视觉令牌的局部信息，不仅使Logit Lens可视化更具解释性，还提升了视觉中心任务的性能，如分割。

Abstract: Logit Lens has been proposed for visualizing tokens that contribute most to LLM answers. Recently, Logit Lens was also shown to be applicable in autoregressive Vision-Language Models (VLMs), where it illustrates the conceptual content of image tokens in the form of heatmaps, e.g., which image tokens are likely to depict the concept of cat in a given image. However, the visual content of image tokens often gets diffused to language tokens, and consequently, the locality of visual information gets mostly destroyed, which renders Logit Lens visualization unusable for explainability. To address this issue, we introduce a complementary loss to next-token prediction (NTP) to prevent the visual tokens from losing the visual representation inherited from corresponding image patches. The proposed Logit Lens Loss (LLL) is designed to make visual token embeddings more semantically aligned with the textual concepts that describe their image regions (e.g., patches containing a cat with the word "cat"), without requiring any architectural modification or large-scale training. This way, LLL constrains the mixing of image and text tokens in the self-attention layers in order to prevent image tokens from losing their localized visual information. As our experiments show, LLL not only makes Logit Lens practically relevant by producing meaningful object confidence maps in images, but also improves performance on vision-centric tasks like segmentation without attaching any special heads.

</details>


### [177] [Rotation-free Online Handwritten Character Recognition Using Linear Recurrent Units](https://arxiv.org/abs/2602.01533)
*Zhe Ling,Sicheng Yu,Danyu Yang*

Main category: cs.CV

TL;DR: SW-PS+LRU框架通过旋转不变特征提取和高效分类器，显著提升了在线手写字符识别的准确率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 在线手写字符识别中，旋转变形会破坏笔画的空间布局，显著降低识别准确率。提取旋转不变特征仍是一个具有挑战性的开放问题。

Method: 采用滑动窗口路径签名（SW-PS）捕捉字符的局部结构特征，并引入轻量级线性循环单元（LRU）作为分类器。LRU结合了RNN的快速增量处理能力和SSM的高效并行训练。

Result: 在CASIA-OLHWDB1.1数据集的三个子集（数字、英文大写字母和中文部首）上，随机旋转角度达±180°时，集成学习后的准确率分别为99.62%、96.67%和94.33%。

Conclusion: 提出的SW-PS+LRU框架在收敛速度和测试准确率上均优于竞争模型，验证了其在旋转不变特征提取和分类任务中的有效性。

Abstract: Online handwritten character recognition leverages stroke order and dynamic features, which generally provide higher accuracy and robustness compared with offline recognition. However, in practical applications, rotational deformations can disrupt the spatial layout of strokes, substantially reducing recognition accuracy. Extracting rotation-invariant features therefore remains a challenging open problem. In this work, we employ the Sliding Window Path Signature (SW-PS) to capture local structural features of characters, and introduce the lightweight Linear Recurrent Units (LRU) as the classifier. The LRU combine the fast incremental processing capability of recurrent neural networks (RNN) with the efficient parallel training of state space models (SSM), while reliably modelling dynamic stroke characteristics. We conducted recognition experiments with random rotation angle up to $\pm 180^{\circ}$ on three subsets of the CASIA-OLHWDB1.1 dataset: digits, English upper letters, and Chinese radicals. The accuracies achieved after ensemble learning were $99.62\%$, $96.67\%$, and $94.33\%$, respectively. Experimental results demonstrate that the proposed SW-PS+LRU framework consistently surpasses competing models in both convergence speed and test accuracy.

</details>


### [178] [Making Avatars Interact: Towards Text-Driven Human-Object Interaction for Controllable Talking Avatars](https://arxiv.org/abs/2602.01538)
*Youliang Zhang,Zhengguang Zhou,Zhentao Yu,Ziyao Huang,Teng Hu,Sen Liang,Guozhen Zhang,Ziqiao Peng,Shunkai Li,Yi Chen,Zixiang Zhou,Yuan Zhou,Qinglin Lu,Xiu Li*

Main category: cs.CV

TL;DR: InteractAvatar通过双流框架解决了人机交互视频生成的挑战，实现了文本对齐的交互动作与生动视频的并行生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法难以实现基于文本对齐的人机交互（GHOI）视频生成，需解决环境感知与控制-质量权衡的挑战。

Method: 提出了双流框架InteractAvatar，包括感知与交互模块（PIM）和音频交互感知生成模块（AIM），通过运动-视频对齐器实现并行生成。

Result: 实验表明InteractAvatar能有效生成基于文本对齐的人机交互视频，并建立了评估基准GroundedInter。

Conclusion: InteractAvatar通过双流框架成功解决了基于文本对齐的人机交互视频生成的挑战，有效平衡了控制与质量之间的权衡。

Abstract: Generating talking avatars is a fundamental task in video generation. Although existing methods can generate full-body talking avatars with simple human motion, extending this task to grounded human-object interaction (GHOI) remains an open challenge, requiring the avatar to perform text-aligned interactions with surrounding objects. This challenge stems from the need for environmental perception and the control-quality dilemma in GHOI generation. To address this, we propose a novel dual-stream framework, InteractAvatar, which decouples perception and planning from video synthesis for grounded human-object interaction. Leveraging detection to enhance environmental perception, we introduce a Perception and Interaction Module (PIM) to generate text-aligned interaction motions. Additionally, an Audio-Interaction Aware Generation Module (AIM) is proposed to synthesize vivid talking avatars performing object interactions. With a specially designed motion-to-video aligner, PIM and AIM share a similar network structure and enable parallel co-generation of motions and plausible videos, effectively mitigating the control-quality dilemma. Finally, we establish a benchmark, GroundedInter, for evaluating GHOI video generation. Extensive experiments and comparisons demonstrate the effectiveness of our method in generating grounded human-object interactions for talking avatars. Project page: https://interactavatar.github.io

</details>


### [179] [FSCA-Net: Feature-Separated Cross-Attention Network for Robust Multi-Dataset Training](https://arxiv.org/abs/2602.01540)
*Yuehai Chen*

Main category: cs.CV

TL;DR: FSCA-Net通过特征解耦和交叉注意力融合，提升人群计数的跨域泛化能力。


<details>
  <summary>Details</summary>
Motivation: CNN和Transformer模型在跨环境应用时因域差异导致性能下降，联合训练多个数据集易引发负迁移问题。

Method: 提出FSCA-Net框架，将特征表示解耦为域不变和域特定组件，并通过交叉注意力融合模块建模其交互。引入互信息优化目标以增强域不变特征的一致性和域特定特征的互补性。

Result: 在多个人群计数基准测试中，FSCA-Net显著缓解负迁移并实现最先进的跨数据集泛化性能。

Conclusion: FSCA-Net通过显式解耦特征表示并引入交叉注意力融合模块，有效解决了跨数据集泛化中的负迁移问题，为实际人群分析提供了鲁棒且可扩展的解决方案。

Abstract: Crowd counting plays a vital role in public safety, traffic regulation, and smart city management. However, despite the impressive progress achieved by CNN- and Transformer-based models, their performance often deteriorates when applied across diverse environments due to severe domain discrepancies. Direct joint training on multiple datasets, which intuitively should enhance generalization, instead results in negative transfer, as shared and domain-specific representations become entangled. To address this challenge, we propose the Feature Separation and Cross-Attention Network FSCA-Net, a unified framework that explicitly disentangles feature representations into domain-invariant and domain-specific components. A novel cross-attention fusion module adaptively models interactions between these components, ensuring effective knowledge transfer while preserving dataset-specific discriminability. Furthermore, a mutual information optimization objective is introduced to maximize consistency among domain-invariant features and minimize redundancy among domain-specific ones, promoting complementary shared-private representations. Extensive experiments on multiple crowd counting benchmarks demonstrate that FSCA-Net effectively mitigates negative transfer and achieves state-of-the-art cross-dataset generalization, providing a robust and scalable solution for real-world crowd analysis.

</details>


### [180] [Toward Cognitive Supersensing in Multimodal Large Language Model](https://arxiv.org/abs/2602.01541)
*Boyi Li,Yifan Shen,Yuanzhe Liu,Yifan Xu,Jiateng Liu,Xinzhuo Li,Zhengyuan Li,Jingyuan Zhu,Yunhan Zhong,Fangzhou Lan,Jianguo Cao,James M. Rehg,Heng Ji,Ismini Lourentzou,Xu Cao*

Main category: cs.CV

TL;DR: Cognitive Supersensing enhances MLLMs with visual imagery capabilities via LVIP and reinforcement learning, improving performance on cognitive tasks and generalization in VQA benchmarks.


<details>
  <summary>Details</summary>
Motivation: Current MLLMs primarily scale Chain-of-Thought (CoT) reasoning in the text space, neglecting visual reasoning mechanisms analogous to the human visuospatial sketchpad and visual imagery, which limits their ability to solve complex cognitive problems, especially when visual details are abstract and require visual memory.

Method: The paper introduces Cognitive Supersensing, a novel training paradigm that integrates a Latent Visual Imagery Prediction (LVIP) head to jointly learn sequences of visual cognitive latent embeddings and aligns them with the answer, forming vision-based internal reasoning chains. A reinforcement learning stage is also introduced to optimize text reasoning paths based on this grounded visual latent.

Result: Extensive experiments demonstrate that MLLMs trained with Cognitive Supersensing outperform state-of-the-art baselines on CogSense-Bench and show superior generalization on out-of-domain mathematics and science VQA benchmarks.

Conclusion: Multimodal Large Language Models (MLLMs) trained with Cognitive Supersensing significantly outperform state-of-the-art baselines on CogSense-Bench and exhibit superior generalization on out-of-domain mathematics and science VQA benchmarks, suggesting that internal visual imagery is potentially key to bridging the gap between perceptual recognition and cognitive understanding.

Abstract: Multimodal Large Language Models (MLLMs) have achieved remarkable success in open-vocabulary perceptual tasks, yet their ability to solve complex cognitive problems remains limited, especially when visual details are abstract and require visual memory. Current approaches primarily scale Chain-of-Thought (CoT) reasoning in the text space, even when language alone is insufficient for clear and structured reasoning, and largely neglect visual reasoning mechanisms analogous to the human visuospatial sketchpad and visual imagery. To mitigate this deficiency, we introduce Cognitive Supersensing, a novel training paradigm that endows MLLMs with human-like visual imagery capabilities by integrating a Latent Visual Imagery Prediction (LVIP) head that jointly learns sequences of visual cognitive latent embeddings and aligns them with the answer, thereby forming vision-based internal reasoning chains. We further introduce a reinforcement learning stage that optimizes text reasoning paths based on this grounded visual latent. To evaluate the cognitive capabilities of MLLMs, we present CogSense-Bench, a comprehensive visual question answering (VQA) benchmark assessing five cognitive dimensions. Extensive experiments demonstrate that MLLMs trained with Cognitive Supersensing significantly outperform state-of-the-art baselines on CogSense-Bench and exhibit superior generalization on out-of-domain mathematics and science VQA benchmarks, suggesting that internal visual imagery is potentially key to bridging the gap between perceptual recognition and cognitive understanding. We will open-source the CogSense-Bench and our model weights.

</details>


### [181] [Combined Flicker-banding and Moire Removal for Screen-Captured Images](https://arxiv.org/abs/2602.01559)
*Libo Zhu,Zihan Zhou,Zhiyi Zhou,Yiyang Qu,Weihang Zhang,Keyu Shi,Yifan Fu,Yulun Zhang*

Main category: cs.CV

TL;DR: CLEAR框架首次系统研究了屏幕捕获图像中摩尔纹和闪烁带的联合去除，通过频域分解和轨迹对齐损失有效提升了复合伪影的建模能力。


<details>
  <summary>Details</summary>
Motivation: 由于摩尔纹和闪烁带在实际成像过程中的强耦合性，现有针对单一退化的方法无法适用于此类复合场景，因此需要系统研究联合去除这两种伪影的方法。

Method: 构建了一个包含摩尔纹和闪烁带的大规模数据集，并引入了基于ISP的闪烁模拟管道以稳定模型训练和扩展退化分布。设计了频域分解和重组模块以及轨迹对齐损失来增强对复合伪影的建模。

Result: 广泛的实验表明，所提出的方法在多个评估指标上一致优于现有的图像恢复方法。

Conclusion: 提出的CLEAR框架在联合去除屏幕捕获图像中的摩尔纹和闪烁带方面表现出色，验证了其在复杂现实场景中的有效性。

Abstract: Capturing display screens with mobile devices has become increasingly common, yet the resulting images often suffer from severe degradations caused by the coexistence of moiré patterns and flicker-banding, leading to significant visual quality degradation. Due to the strong coupling of these two artifacts in real imaging processes, existing methods designed for single degradations fail to generalize to such compound scenarios. In this paper, we present the first systematic study on joint removal of moiré patterns and flicker-banding in screen-captured images, and propose a unified restoration framework, named CLEAR. To support this task, we construct a large-scale dataset containing both moiré patterns and flicker-banding, and introduce an ISP-based flicker simulation pipeline to stabilize model training and expand the degradation distribution. Furthermore, we design a frequency-domain decomposition and re-composition module together with a trajectory alignment loss to enhance the modeling of compound artifacts. Extensive experiments demonstrate that the proposed method consistently. outperforms existing image restoration approaches across multiple evaluation metrics, validating its effectiveness in complex real-world scenarios.

</details>


### [182] [Multimodal UNcommonsense: From Odd to Ordinary and Ordinary to Odd](https://arxiv.org/abs/2602.01561)
*Yejin Son,Saejin Kim,Dongjun Min,Younjae Yu*

Main category: cs.CV

TL;DR: MUN基准测试评估模型处理非典型多模态场景的能力，提出的R-ICL框架通过MER提升性能8.3%。


<details>
  <summary>Details</summary>
Motivation: 解决多模态情境下的常识推理问题，评估模型处理偏离典型视觉或上下文预期的场景的能力。

Method: 提出了一种基于检索的上下文学习（R-ICL）框架，利用新型多模态集成检索器（MER）识别语义相关的示例。

Result: 实验显示R-ICL在低频、非典型设置中比基线ICL方法平均提升8.3%。

Conclusion: MUN为评估和提升视觉-语言模型在现实世界、文化多样性和非典型场景中的鲁棒性和适应性开辟了新方向。

Abstract: Commonsense reasoning in multimodal contexts remains a foundational challenge in artificial intelligence. We introduce Multimodal UNcommonsense(MUN), a benchmark designed to evaluate models' ability to handle scenarios that deviate from typical visual or contextual expectations. MUN pairs visual scenes with surprising or unlikely outcomes described in natural language, prompting models to either rationalize seemingly odd images using everyday logic or uncover unexpected interpretations in ordinary scenes. To support this task, we propose a retrieval-based in-context learning (R-ICL) framework that transfers reasoning capabilities from larger models to smaller ones without additional training. Leveraging a novel Multimodal Ensemble Retriever (MER), our method identifies semantically relevant exemplars even when image and text pairs are deliberately discordant. Experiments show an average improvement of 8.3% over baseline ICL methods, highlighting the effectiveness of R-ICL in low-frequency, atypical settings. MUN opens new directions for evaluating and improving visual-language models' robustness and adaptability in real-world, culturally diverse, and non-prototypical scenarios.

</details>


### [183] [One-Step Diffusion for Perceptual Image Compression](https://arxiv.org/abs/2602.01570)
*Yiwen Jia,Hao Wei,Yanhui Zhou,Chenyang Ge*

Main category: cs.CV

TL;DR: 提出单步扩散图像压缩方法，显著提升推理速度，保持压缩性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有扩散图像压缩方法因多步去噪导致的推理延迟和高计算开销问题。

Method: 通过引入基于紧凑特征表示的判别器，提升重建图像的感知质量，同时仅需单步扩散过程以减少计算开销。

Result: 实验结果显示，该方法在保持压缩性能的同时，推理速度比现有方法快46倍。

Conclusion: 提出的单步扩散图像压缩方法显著提升了推理速度，同时保持了可比的压缩性能，具有实际部署的潜力。

Abstract: Diffusion-based image compression methods have achieved notable progress, delivering high perceptual quality at low bitrates. However, their practical deployment is hindered by significant inference latency and heavy computational overhead, primarily due to the large number of denoising steps required during decoding. To address this problem, we propose a diffusion-based image compression method that requires only a single-step diffusion process, significantly improving inference speed. To enhance the perceptual quality of reconstructed images, we introduce a discriminator that operates on compact feature representations instead of raw pixels, leveraging the fact that features better capture high-level texture and structural details. Experimental results show that our method delivers comparable compression performance while offering a 46$\times$ faster inference speed compared to recent diffusion-based approaches. The source code and models are available at https://github.com/cheesejiang/OSDiff.

</details>


### [184] [SGHA-Attack: Semantic-Guided Hierarchical Alignment for Transferable Targeted Attacks on Vision-Language Models](https://arxiv.org/abs/2602.01574)
*Haobo Wang,Weiqi Luo,Xiaojun Jia,Xiaochun Cao*

Main category: cs.CV

TL;DR: SGHA-Attack通过多参考和中间层对齐提升对抗样本在异构视觉语言模型间的迁移效果。


<details>
  <summary>Details</summary>
Motivation: 现有目标迁移攻击常因依赖单一参考和强调最终层对齐而过拟合代理模型特定嵌入空间，未能充分利用中间语义且跨异构模型迁移效果差。

Method: 采用多目标参考和中间层一致性策略，通过文本到图像模型生成视觉基础参考池，并选择Top-K语义相关锚点进行加权混合优化。在特征层次中全局和空间粒度对齐中间视觉表示，并在共享潜在子空间中同步中间视觉和文本特征。

Result: 在开源和商业黑盒视觉语言模型上的实验表明，SGHA-Attack比现有方法具有更强的目标迁移能力。

Conclusion: SGHA-Attack通过语义引导的层次对齐框架显著提升了对抗样本在异构视觉语言模型间的迁移能力，并在预处理和净化防御下保持鲁棒性。

Abstract: Large vision-language models (VLMs) are vulnerable to transfer-based adversarial perturbations, enabling attackers to optimize on surrogate models and manipulate black-box VLM outputs. Prior targeted transfer attacks often overfit surrogate-specific embedding space by relying on a single reference and emphasizing final-layer alignment, which underutilizes intermediate semantics and degrades transfer across heterogeneous VLMs. To address this, we propose SGHA-Attack, a Semantic-Guided Hierarchical Alignment framework that adopts multiple target references and enforces intermediate-layer consistency. Concretely, we generate a visually grounded reference pool by sampling a frozen text-to-image model conditioned on the target prompt, and then carefully select the Top-K most semantically relevant anchors under the surrogate to form a weighted mixture for stable optimization guidance. Building on these anchors, SGHA-Attack injects target semantics throughout the feature hierarchy by aligning intermediate visual representations at both global and spatial granularities across multiple depths, and by synchronizing intermediate visual and textual features in a shared latent subspace to provide early cross-modal supervision before the final projection. Extensive experiments on open-source and commercial black-box VLMs show that SGHA-Attack achieves stronger targeted transferability than prior methods and remains robust under preprocessing and purification defenses.

</details>


### [185] [HandMCM: Multi-modal Point Cloud-based Correspondence State Space Model for 3D Hand Pose Estimation](https://arxiv.org/abs/2602.01586)
*Wencan Cheng,Gim Hee Lee*

Main category: cs.CV

TL;DR: HandMCM, a novel Mamba-based method, improves 3D hand pose estimation accuracy under occlusions by leveraging local information and multi-modal features, outperforming current methods.


<details>
  <summary>Details</summary>
Motivation: The challenges of self-occlusion and object interactions in 3D hand pose estimation drive the need for a more robust and accurate method.

Method: HandMCM utilizes a state space model (Mamba) with modules for local information injection/filtering and correspondence modeling, enhanced by multi-modal image features.

Result: Empirical evaluations on three benchmark datasets show superior performance, particularly in severe occlusion scenarios.

Conclusion: HandMCM significantly outperforms current state-of-the-art methods in 3D hand pose estimation, especially in occlusion scenarios, showcasing its potential for practical applications.

Abstract: 3D hand pose estimation that involves accurate estimation of 3D human hand keypoint locations is crucial for many human-computer interaction applications such as augmented reality. However, this task poses significant challenges due to self-occlusion of the hands and occlusions caused by interactions with objects. In this paper, we propose HandMCM to address these challenges. Our HandMCM is a novel method based on the powerful state space model (Mamba). By incorporating modules for local information injection/filtering and correspondence modeling, the proposed correspondence Mamba effectively learns the highly dynamic kinematic topology of keypoints across various occlusion scenarios. Moreover, by integrating multi-modal image features, we enhance the robustness and representational capacity of the input, leading to more accurate hand pose estimation. Empirical evaluations on three benchmark datasets demonstrate that our model significantly outperforms current state-of-the-art methods, particularly in challenging scenarios involving severe occlusions. These results highlight the potential of our approach to advance the accuracy and reliability of 3D hand pose estimation in practical applications.

</details>


### [186] [Know Your Step: Faster and Better Alignment for Flow Matching Models via Step-aware Advantages](https://arxiv.org/abs/2602.01591)
*Zhixiong Yue,Zixuan Ni,Feiyang Ye,Jinshan Zhang,Sheng Shen,Zhenpeng Mi*

Main category: cs.CV

TL;DR: TAFS GRPO通过自适应噪声注入和GRPO优化，提升了少步文本到图像生成的对齐效果。


<details>
  <summary>Details</summary>
Motivation: 现有基于强化学习的流匹配模型依赖大量去噪步骤，且奖励信号稀疏不精确，导致对齐效果不佳。

Method: 提出了TAFS GRPO框架，通过迭代注入自适应时间噪声和退火采样过程，结合GRPO的步感知优势集成机制，提供密集且步特定的奖励。

Result: 实验证明TAFS GRPO在少步文本到图像生成中表现优异，显著提升了对齐效果。

Conclusion: TAFS GRPO框架在少步文本到图像生成中表现出色，显著提升了生成图像与人类偏好的对齐度。

Abstract: Recent advances in flow matching models, particularly with reinforcement learning (RL), have significantly enhanced human preference alignment in few step text to image generators. However, existing RL based approaches for flow matching models typically rely on numerous denoising steps, while suffering from sparse and imprecise reward signals that often lead to suboptimal alignment. To address these limitations, we propose Temperature Annealed Few step Sampling with Group Relative Policy Optimization (TAFS GRPO), a novel framework for training flow matching text to image models into efficient few step generators well aligned with human preferences. Our method iteratively injects adaptive temporal noise onto the results of one step samples. By repeatedly annealing the model's sampled outputs, it introduces stochasticity into the sampling process while preserving the semantic integrity of each generated image. Moreover, its step aware advantage integration mechanism combines the GRPO to avoid the need for the differentiable of reward function and provide dense and step specific rewards for stable policy optimization. Extensive experiments demonstrate that TAFS GRPO achieves strong performance in few step text to image generation and significantly improves the alignment of generated images with human preferences. The code and models of this work will be available to facilitate further research.

</details>


### [187] [Samba+: General and Accurate Salient Object Detection via A More Unified Mamba-based Framework](https://arxiv.org/abs/2602.01593)
*Wenzhuo Zhao,Keren Fu,Jiahao He,Xiaohong Liu,Qijun Zhao,Guangtao Zhai*

Main category: cs.CV

TL;DR: Samba和Samba+基于Mamba模型，通过创新扫描策略和多任务训练，显著提升了显著目标检测的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有显著目标检测模型在感受野和计算效率上的局限性，探索Mamba模型的潜力。

Method: 提出了Saliency Mamba（Samba）架构，包括基于Mamba的SGMB块和CAU上采样方法；进一步开发了Samba+，通过多任务联合训练实现统一模型。

Result: Samba在6个任务和22个数据集上优于现有方法，Samba+通过单一模型进一步提升了性能。

Conclusion: Samba和Samba+在多种显著目标检测任务中表现出色，不仅计算成本低，还能通过单一模型实现多任务统一处理，展现了其潜力和优越性。

Abstract: Existing salient object detection (SOD) models are generally constrained by the limited receptive fields of convolutional neural networks (CNNs) and quadratic computational complexity of Transformers. Recently, the emerging state-space model, namely Mamba, has shown great potential in balancing global receptive fields and computational efficiency. As a solution, we propose Saliency Mamba (Samba), a pure Mamba-based architecture that flexibly handles various distinct SOD tasks, including RGB/RGB-D/RGB-T SOD, video SOD (VSOD), RGB-D VSOD, and visible-depth-thermal SOD. Specifically, we rethink the scanning strategy of Mamba for SOD, and introduce a saliency-guided Mamba block (SGMB) that features a spatial neighborhood scanning (SNS) algorithm to preserve the spatial continuity of salient regions. A context-aware upsampling (CAU) method is also proposed to promote hierarchical feature alignment and aggregation by modeling contextual dependencies. As one step further, to avoid the "task-specific" problem as in previous SOD solutions, we develop Samba+, which is empowered by training Samba in a multi-task joint manner, leading to a more unified and versatile model. Two crucial components that collaboratively tackle challenges encountered in input of arbitrary modalities and continual adaptation are investigated. Specifically, a hub-and-spoke graph attention (HGA) module facilitates adaptive cross-modal interactive fusion, and a modality-anchored continual learning (MACL) strategy alleviates inter-modal conflicts together with catastrophic forgetting. Extensive experiments demonstrate that Samba individually outperforms existing methods across six SOD tasks on 22 datasets with lower computational cost, whereas Samba+ achieves even superior results on these tasks and datasets by using a single trained versatile model. Additional results further demonstrate the potential of our Samba framework.

</details>


### [188] [UV-M3TL: A Unified and Versatile Multimodal Multi-Task Learning Framework for Assistive Driving Perception](https://arxiv.org/abs/2602.01594)
*Wenzhuo Liu,Qiannan Guo,Zhen Wang,Wenshuo Wang,Lei Yang,Yicheng Qiao,Lening Wang,Zhiwei Li,Chen Lv,Shanghang Zhang,Junqiang Xi,Huaping Liu*

Main category: cs.CV

TL;DR: UV-M3TL框架通过双分支结构和自适应损失机制，有效解决多任务学习中的负迁移问题，在多个任务和数据集上实现最优性能。


<details>
  <summary>Details</summary>
Motivation: ADAS系统需要同时理解驾驶员行为和导航环境，但联合学习这些异构任务会导致任务间负迁移，影响系统性能。

Method: 提出了双分支空间通道多模态嵌入（DB-SCME）和自适应特征解耦多任务损失（AFD-Loss）两个核心组件，以显式建模任务共享和特定特征，并通过自适应加权机制优化多任务学习。

Result: 在AIDE数据集上，UV-M3TL在所有四个任务中均达到最先进性能；在其他多任务感知基准测试（如BDD100K、CityScapes等）上也表现优异。

Conclusion: UV-M3TL框架通过DB-SCME和AFD-Loss组件有效解决了多任务学习中的负迁移问题，并在多个任务和数据集上实现了最先进的性能，展示了其多功能性和鲁棒性。

Abstract: Advanced Driver Assistance Systems (ADAS) need to understand human driver behavior while perceiving their navigation context, but jointly learning these heterogeneous tasks would cause inter-task negative transfer and impair system performance. Here, we propose a Unified and Versatile Multimodal Multi-Task Learning (UV-M3TL) framework to simultaneously recognize driver behavior, driver emotion, vehicle behavior, and traffic context, while mitigating inter-task negative transfer. Our framework incorporates two core components: dual-branch spatial channel multimodal embedding (DB-SCME) and adaptive feature-decoupled multi-task loss (AFD-Loss). DB-SCME enhances cross-task knowledge transfer while mitigating task conflicts by employing a dual-branch structure to explicitly model salient task-shared and task-specific features. AFD-Loss improves the stability of joint optimization while guiding the model to learn diverse multi-task representations by introducing an adaptive weighting mechanism based on learning dynamics and feature decoupling constraints. We evaluate our method on the AIDE dataset, and the experimental results demonstrate that UV-M3TL achieves state-of-the-art performance across all four tasks. To further prove the versatility, we evaluate UV-M3TL on additional public multi-task perception benchmarks (BDD100K, CityScapes, NYUD-v2, and PASCAL-Context), where it consistently delivers strong performance across diverse task combinations, attaining state-of-the-art results on most tasks.

</details>


### [189] [Token Pruning for In-Context Generation in Diffusion Transformers](https://arxiv.org/abs/2602.01609)
*Junqing Lin,Xingyu Zheng,Pei Cheng,Bin Fu,Jingwei Sun,Guangzhong Sun*

Main category: cs.CV

TL;DR: ToPi是一种针对DiTs中上下文生成的计算瓶颈提出的训练免费令牌修剪框架，通过敏感性分析和选择性修剪实现高效推理。


<details>
  <summary>Details</summary>
Motivation: 解决现有令牌缩减技术在图像到图像生成中因忽略参考上下文和目标潜在空间之间的角色不对称性而导致的性能不足问题。

Method: 提出ToPi框架，利用离线校准驱动的敏感性分析确定关键注意力层，并通过新颖的影响力指标和时序更新策略进行选择性令牌修剪。

Result: 实证评估显示，ToPi在复杂图像生成任务中可实现超过30%的推理加速。

Conclusion: ToPi框架通过针对性的令牌修剪策略，显著提升了DiTs的推理效率，同时保持了生成图像的结构保真度和视觉一致性。

Abstract: In-context generation significantly enhances Diffusion Transformers (DiTs) by enabling controllable image-to-image generation through reference examples. However, the resulting input concatenation drastically increases sequence length, creating a substantial computational bottleneck. Existing token reduction techniques, primarily tailored for text-to-image synthesis, fall short in this paradigm as they apply uniform reduction strategies, overlooking the inherent role asymmetry between reference contexts and target latents across spatial, temporal, and functional dimensions. To bridge this gap, we introduce ToPi, a training-free token pruning framework tailored for in-context generation in DiTs. Specifically, ToPi utilizes offline calibration-driven sensitivity analysis to identify pivotal attention layers, serving as a robust proxy for redundancy estimation. Leveraging these layers, we derive a novel influence metric to quantify the contribution of each context token for selective pruning, coupled with a temporal update strategy that adapts to the evolving diffusion trajectory. Empirical evaluations demonstrate that ToPi can achieve over 30\% speedup in inference while maintaining structural fidelity and visual consistency across complex image generation tasks.

</details>


### [190] [Omni-Judge: Can Omni-LLMs Serve as Human-Aligned Judges for Text-Conditioned Audio-Video Generation?](https://arxiv.org/abs/2602.01623)
*Susan Liang,Chao Huang,Filippos Bellos,Yolo Yunlong Tang,Qianxiang Shen,Jing Bi,Luchuan Song,Zeliang Zhang,Jason Corso,Chenliang Xu*

Main category: cs.CV

TL;DR: Omni-Judge利用omni-LLMs评估文本-音频-视频生成，语义任务表现优异，但时间分辨率受限。


<details>
  <summary>Details</summary>
Motivation: 评估三模态输出的挑战，传统自动指标在多模态复杂提示下表现有限。

Method: 引入Omni-Judge，评估omni-LLMs是否能作为文本条件音频-视频生成的人类对齐评估器。

Result: 在九个感知和对齐指标中，Omni-Judge相关性与传统指标相当，在语义要求高的任务中表现优异，但在高FPS感知指标上表现不佳。

Conclusion: Omni-Judge展示了omni-LLMs作为多模态生成统一评估器的潜力，尽管在时间分辨率方面存在局限。

Abstract: State-of-the-art text-to-video generation models such as Sora 2 and Veo 3 can now produce high-fidelity videos with synchronized audio directly from a textual prompt, marking a new milestone in multi-modal generation. However, evaluating such tri-modal outputs remains an unsolved challenge. Human evaluation is reliable but costly and difficult to scale, while traditional automatic metrics, such as FVD, CLAP, and ViCLIP, focus on isolated modality pairs, struggle with complex prompts, and provide limited interpretability. Omni-modal large language models (omni-LLMs) present a promising alternative: they naturally process audio, video, and text, support rich reasoning, and offer interpretable chain-of-thought feedback. Driven by this, we introduce Omni-Judge, a study assessing whether omni-LLMs can serve as human-aligned judges for text-conditioned audio-video generation. Across nine perceptual and alignment metrics, Omni-Judge achieves correlation comparable to traditional metrics and excels on semantically demanding tasks such as audio-text alignment, video-text alignment, and audio-video-text coherence. It underperforms on high-FPS perceptual metrics, including video quality and audio-video synchronization, due to limited temporal resolution. Omni-Judge provides interpretable explanations that expose semantic or physical inconsistencies, enabling practical downstream uses such as feedback-based refinement. Our findings highlight both the potential and current limitations of omni-LLMs as unified evaluators for multi-modal generation.

</details>


### [191] [PISCES: Annotation-free Text-to-Video Post-Training via Optimal Transport-Aligned Rewards](https://arxiv.org/abs/2602.01624)
*Minh-Quan Le,Gaurav Mittal,Cheng Zhao,David Gu,Dimitris Samaras,Mei Chen*

Main category: cs.CV

TL;DR: PISCES是一种无标注后训练算法，通过双重OT对齐奖励模块提升文本到视频生成的质量和语义对齐，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖大规模人工偏好标注或预训练视觉语言模型的对齐不足嵌入，导致可扩展性或监督效果受限。PISCES旨在解决这些限制。

Method: PISCES采用双重最优传输（OT）对齐奖励模块，包括分布级OT对齐质量奖励和离散令牌级OT对齐语义奖励，以优化生成视频的质量和语义对齐。

Result: 实验表明，PISCES在短视频和长视频生成中均优于基于标注和无标注的方法，并通过人类偏好研究验证了其有效性。

Conclusion: PISCES通过新颖的双重最优传输（OT）对齐奖励模块，显著提升了无标注奖励监督在生成后训练中的效果，并在质量和语义评分上超越了基于标注和无标注的方法。

Abstract: Text-to-video (T2V) generation aims to synthesize videos with high visual quality and temporal consistency that are semantically aligned with input text. Reward-based post-training has emerged as a promising direction to improve the quality and semantic alignment of generated videos. However, recent methods either rely on large-scale human preference annotations or operate on misaligned embeddings from pre-trained vision-language models, leading to limited scalability or suboptimal supervision. We present $\texttt{PISCES}$, an annotation-free post-training algorithm that addresses these limitations via a novel Dual Optimal Transport (OT)-aligned Rewards module. To align reward signals with human judgment, $\texttt{PISCES}$ uses OT to bridge text and video embeddings at both distributional and discrete token levels, enabling reward supervision to fulfill two objectives: (i) a Distributional OT-aligned Quality Reward that captures overall visual quality and temporal coherence; and (ii) a Discrete Token-level OT-aligned Semantic Reward that enforces semantic, spatio-temporal correspondence between text and video tokens. To our knowledge, $\texttt{PISCES}$ is the first to improve annotation-free reward supervision in generative post-training through the lens of OT. Experiments on both short- and long-video generation show that $\texttt{PISCES}$ outperforms both annotation-based and annotation-free methods on VBench across Quality and Semantic scores, with human preference studies further validating its effectiveness. We show that the Dual OT-aligned Rewards module is compatible with multiple optimization paradigms, including direct backpropagation and reinforcement learning fine-tuning.

</details>


### [192] [Research on World Models Is Not Merely Injecting World Knowledge into Specific Tasks](https://arxiv.org/abs/2602.01630)
*Bohan Zeng,Kaixin Zhu,Daili Hua,Bozhou Li,Chengzhuo Tong,Yuran Wang,Xinyi Huang,Yifan Dai,Zixiang Zhang,Yifan Yang,Zhou Liu,Hao Liang,Xiaochen Ma,Ruichuan An,Tianyi Bai,Hongcheng Gao,Junbo Niu,Yang Shi,Xinlong Chen,Yue Ding,Minglei Shi,Kai Zeng,Yiwen Tang,Yuanxing Zhang,Pengfei Wan,Xintao Wang,Wentao Zhang*

Main category: cs.CV

TL;DR: 本文分析了世界模型研究的碎片化问题，提出统一设计规范，强调整合多维度能力以实现整体世界理解。


<details>
  <summary>Details</summary>
Motivation: 当前世界模型研究过于碎片化，缺乏系统性，无法实现整体世界理解。

Method: 分析了当前碎片化方法的局限性，并提出了一种统一的设计规范。

Result: 提出了一种整合交互、感知、符号推理和空间表示的规范性框架。

Conclusion: 本文提出了一种统一的世界模型设计规范，强调应将交互、感知、符号推理和空间表示整合为一个规范性框架，而非零散能力的松散集合。

Abstract: World models have emerged as a critical frontier in AI research, aiming to enhance large models by infusing them with physical dynamics and world knowledge. The core objective is to enable agents to understand, predict, and interact with complex environments. However, current research landscape remains fragmented, with approaches predominantly focused on injecting world knowledge into isolated tasks, such as visual prediction, 3D estimation, or symbol grounding, rather than establishing a unified definition or framework. While these task-specific integrations yield performance gains, they often lack the systematic coherence required for holistic world understanding. In this paper, we analyze the limitations of such fragmented approaches and propose a unified design specification for world models. We suggest that a robust world model should not be a loose collection of capabilities but a normative framework that integrally incorporates interaction, perception, symbolic reasoning, and spatial representation. This work aims to provide a structured perspective to guide future research toward more general, robust, and principled models of the world.

</details>


### [193] [Federated Vision Transformer with Adaptive Focal Loss for Medical Image Classification](https://arxiv.org/abs/2602.01633)
*Xinyuan Zhao,Yihang Wu,Ahmad Chaddad,Tareef Daqqaq,Reem Kateb*

Main category: cs.CV

TL;DR: 提出了一种结合动态自适应焦点损失和客户端感知聚合策略的联邦学习框架，有效解决了数据异构和类别不平衡问题，并在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中数据异构性和类别不平衡对模型泛化的挑战，尤其是在医疗图像等隐私敏感数据受限的场景下。

Method: 设计了动态类别不平衡系数，根据每个客户端的样本分布和类别数据分布进行调整，确保少数类别得到足够关注；采用加权聚合策略，适应数据规模和特征以捕捉客户端间差异。

Result: 在三个公共数据集（ISIC、Ocular Disease和RSNA-ICH）上的分类结果显示，该框架在大多数情况下优于DenseNet121、ResNet50、ViT-S/16、ViT-L/32、FedCLIP、Swin Transformer、CoAtNet和MixNet，准确率提升范围从0.98%到41.69%。

Conclusion: 该研究提出的FL框架结合动态自适应焦点损失（DAFL）和客户端感知聚合策略，显著提升了模型在异构数据和类别不平衡情况下的泛化能力，并在多个公共数据集上验证了其优越性。

Abstract: While deep learning models like Vision Transformer (ViT) have achieved significant advances, they typically require large datasets. With data privacy regulations, access to many original datasets is restricted, especially medical images. Federated learning (FL) addresses this challenge by enabling global model aggregation without data exchange. However, the heterogeneity of the data and the class imbalance that exist in local clients pose challenges for the generalization of the model. This study proposes a FL framework leveraging a dynamic adaptive focal loss (DAFL) and a client-aware aggregation strategy for local training. Specifically, we design a dynamic class imbalance coefficient that adjusts based on each client's sample distribution and class data distribution, ensuring minority classes receive sufficient attention and preventing sparse data from being ignored. To address client heterogeneity, a weighted aggregation strategy is adopted, which adapts to data size and characteristics to better capture inter-client variations. The classification results on three public datasets (ISIC, Ocular Disease and RSNA-ICH) show that the proposed framework outperforms DenseNet121, ResNet50, ViT-S/16, ViT-L/32, FedCLIP, Swin Transformer, CoAtNet, and MixNet in most cases, with accuracy improvements ranging from 0.98\% to 41.69\%. Ablation studies on the imbalanced ISIC dataset validate the effectiveness of the proposed loss function and aggregation strategy compared to traditional loss functions and other FL approaches. The codes can be found at: https://github.com/AIPMLab/ViT-FLDAF.

</details>


### [194] [ReCALL: Recalibrating Capability Degradation for MLLM-based Composed Image Retrieval](https://arxiv.org/abs/2602.01639)
*Tianyu Yang,ChenWei He,Xiangzhao Hao,Tianyue Wang,Jiarui Guo,Haiyun Guo,Leigang Qu,Jinqiao Wang,Tat-Seng Chua*

Main category: cs.CV

TL;DR: ReCALL通过诊断-生成-优化流程解决了生成式MLLM在检索任务中的能力退化问题，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 早期双塔视觉语言模型在跨模态组合推理上表现不佳，而生成式MLLM在检索任务中的适配策略忽视了范式冲突导致的能力退化问题。

Method: ReCALL框架采用自引导信息实例挖掘诊断检索器的认知盲点，通过CoT提示生成矫正指令和三联体，并利用VQA一致性过滤进行质量控制，最后通过分组对比方案持续训练优化检索器。

Result: 在CIRR和FashionIQ数据集上的实验表明，ReCALL能够持续校准退化能力并实现最优性能。

Conclusion: ReCALL框架通过诊断-生成-优化的流程，有效解决了生成式MLLM在检索任务中的能力退化问题，并在CIRR和FashionIQ数据集上实现了最先进的性能。

Abstract: Composed Image Retrieval (CIR) aims to retrieve target images based on a hybrid query comprising a reference image and a modification text. Early dual-tower Vision-Language Models (VLMs) struggle with cross-modality compositional reasoning required for this task. Recently, adapting generative Multimodal Large Language Models (MLLMs) for retrieval offers a promising direction. However, we identify that this adaptation strategy overlooks a fundamental issue: adapting a generative MLLM into a single-embedding discriminative retriever triggers a paradigm conflict, which leads to Capability Degradation - the deterioration of native fine-grained reasoning after retrieval adaptation. To address this challenge, we propose ReCALL (Recalibrating Capability Degradation), a model-agnostic framework that follows a diagnose-generate-refine pipeline: Firstly, we diagnose cognitive blind spots of the retriever via self-guided informative instance mining. Next, we generate corrective instructions and triplets by CoT prompting the foundation MLLM and conduct quality control with VQA-based consistency filtering. Finally, we refine the retriever through continual training on these triplets with a grouped contrastive scheme, thereby internalizing fine-grained visual-semantic distinctions and realigning the discriminative embedding space of retriever with intrinsic compositional reasoning within the MLLM. Extensive experiments on CIRR and FashionIQ show that ReCALL consistently recalibrates degraded capabilities and achieves state-of-the-art performance. Code will be released soon.

</details>


### [195] [Contribution-aware Token Compression for Efficient Video Understanding via Reinforcement Learning](https://arxiv.org/abs/2602.01649)
*Yinchao Ma,Qiang Zhou,Zhibin Wang,Xianing Chen,Hanqing Yang,Jun Song,Bo Zheng*

Main category: cs.CV

TL;DR: CaCoVID是一种贡献感知的视频令牌压缩算法，通过强化学习优化令牌选择策略，显著提升推理效率。


<details>
  <summary>Details</summary>
Motivation: 视频令牌的冗余性在推理过程中引入了显著的计算开销，而现有的压缩算法在注意力分数与实际贡献之间的相关性上存在模糊性。

Method: 提出了一种基于强化学习的框架，优化策略网络以选择对正确预测贡献最大的视频令牌组合，并设计了在线组合空间采样的组合策略优化算法。

Result: 在多样化的视频理解基准测试中，CaCoVID表现出色，验证了其有效性。

Conclusion: CaCoVID通过贡献感知的令牌压缩算法显著提升了视频大语言模型的推理效率，并在多个视频理解基准测试中验证了其有效性。

Abstract: Video large language models have demonstrated remarkable capabilities in video understanding tasks. However, the redundancy of video tokens introduces significant computational overhead during inference, limiting their practical deployment. Many compression algorithms are proposed to prioritize retaining features with the highest attention scores to minimize perturbations in attention computations. However, the correlation between attention scores and their actual contribution to correct answers remains ambiguous. To address the above limitation, we propose a novel \textbf{C}ontribution-\textbf{a}ware token \textbf{Co}mpression algorithm for \textbf{VID}eo understanding (\textbf{CaCoVID}) that explicitly optimizes the token selection policy based on the contribution of tokens to correct predictions. First, we introduce a reinforcement learning-based framework that optimizes a policy network to select video token combinations with the greatest contribution to correct predictions. This paradigm shifts the focus from passive token preservation to active discovery of optimal compressed token combinations. Secondly, we propose a combinatorial policy optimization algorithm with online combination space sampling, which dramatically reduces the exploration space for video token combinations and accelerates the convergence speed of policy optimization. Extensive experiments on diverse video understanding benchmarks demonstrate the effectiveness of CaCoVID. Codes will be released.

</details>


### [196] [From Frames to Sequences: Temporally Consistent Human-Centric Dense Prediction](https://arxiv.org/abs/2602.01661)
*Xingyu Miao,Junting Dong,Qin Zhao,Yuhang Yang,Junhao Chen,Yang Long*

Main category: cs.CV

TL;DR: 提出合成数据管道和两阶段训练策略，提升视频序列中时间一致的人类密集预测性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有模型在运动、遮挡和光照变化下闪烁的问题，并填补缺乏多密集任务配对人类视频监督的空白。

Method: 使用可扩展的合成数据管道生成逼真的人类帧和运动对齐序列，结合ViT-based密集预测器和两阶段训练策略（静态预训练和动态序列监督）。

Result: 在THuman2.1和Hi4D上达到最先进性能，并能有效泛化到真实视频。

Conclusion: 该论文通过合成数据和两阶段训练策略，实现了在THuman2.1和Hi4D上的最先进性能，并能有效泛化到真实视频。

Abstract: In this work, we focus on the challenge of temporally consistent human-centric dense prediction across video sequences. Existing models achieve strong per-frame accuracy but often flicker under motion, occlusion, and lighting changes, and they rarely have paired human video supervision for multiple dense tasks. We address this gap with a scalable synthetic data pipeline that generates photorealistic human frames and motion-aligned sequences with pixel-accurate depth, normals, and masks. Unlike prior static data synthetic pipelines, our pipeline provides both frame-level labels for spatial learning and sequence-level supervision for temporal learning. Building on this, we train a unified ViT-based dense predictor that (i) injects an explicit human geometric prior via CSE embeddings and (ii) improves geometry-feature reliability with a lightweight channel reweighting module after feature fusion. Our two-stage training strategy, combining static pretraining with dynamic sequence supervision, enables the model first to acquire robust spatial representations and then refine temporal consistency across motion-aligned sequences. Extensive experiments show that we achieve state-of-the-art performance on THuman2.1 and Hi4D and generalize effectively to in-the-wild videos.

</details>


### [197] [Moonworks Lunara Aesthetic II: An Image Variation Dataset](https://arxiv.org/abs/2602.01666)
*Yan Wang,Partho Hassan,Samiha Sadeka,Nada Soliman,M M Sayeef Abdullah,Sabit Hassan*

Main category: cs.CV

TL;DR: Lunara Aesthetic II是一个公开的图像数据集，用于评估图像生成系统的上下文一致性和身份保持能力。


<details>
  <summary>Details</summary>
Motivation: 为现代图像生成和编辑系统提供可控评估和学习的上下文一致性支持。

Method: 数据集包含2,854对锚链接的变体对，通过应用光照、天气、视角等上下文变换，同时保持底层身份稳定。

Result: 数据集表现出高身份稳定性、强目标属性实现和超越大规模网络数据集的审美评分。

Conclusion: Lunara Aesthetic II数据集为图像生成和编辑系统提供了高质量的基准测试和微调资源，支持上下文一致性的评估和学习。

Abstract: We introduce Lunara Aesthetic II, a publicly released, ethically sourced image dataset designed to support controlled evaluation and learning of contextual consistency in modern image generation and editing systems. The dataset comprises 2,854 anchor-linked variation pairs derived from original art and photographs created by Moonworks. Each variation pair applies contextual transformations, such as illumination, weather, viewpoint, scene composition, color tone, or mood; while preserving a stable underlying identity. Lunara Aesthetic II operationalizes identity-preserving contextual variation as a supervision signal while also retaining Lunara's signature high aesthetic scores. Results show high identity stability, strong target attribute realization, and a robust aesthetic profile that exceeds large-scale web datasets. Released under the Apache 2.0 license, Lunara Aesthetic II is intended for benchmarking, fine-tuning, and analysis of contextual generalization, identity preservation, and edit robustness in image generation and image-to-image systems with interpretable, relational supervision. The dataset is publicly available at: https://huggingface.co/datasets/moonworks/lunara-aesthetic-image-variations.

</details>


### [198] [SMTrack: State-Aware Mamba for Efficient Temporal Modeling in Visual Tracking](https://arxiv.org/abs/2602.01677)
*Yinchao Ma,Dengqing Yang,Zhangyu He,Wenfei Yang,Tianzhu Zhang*

Main category: cs.CV

TL;DR: SMTrack是一种基于状态空间模型的新型视觉跟踪方法，通过选择性状态感知和线性复杂度设计，高效解决了长程时空依赖建模问题。


<details>
  <summary>Details</summary>
Motivation: 传统CNN和Transformer架构在建模视觉跟踪中的长程时空依赖时存在局限性，需要复杂定制模块或高计算成本。

Method: 提出了一种名为State-aware Mamba Tracker (SMTrack)的新方法，采用选择性状态感知空间模型和隐藏状态传播机制，以线性计算复杂度实现长程时空依赖建模。

Result: SMTrack在低计算成本下实现了优异的跟踪性能，通过实验验证了其有效性。

Conclusion: SMTrack提出了一种新颖的时空建模范式，通过选择性状态感知空间模型和线性计算复杂度，显著提升了视觉跟踪的鲁棒性和效率，实验证明了其优越性能。

Abstract: Visual tracking aims to automatically estimate the state of a target object in a video sequence, which is challenging especially in dynamic scenarios. Thus, numerous methods are proposed to introduce temporal cues to enhance tracking robustness. However, conventional CNN and Transformer architectures exhibit inherent limitations in modeling long-range temporal dependencies in visual tracking, often necessitating either complex customized modules or substantial computational costs to integrate temporal cues. Inspired by the success of the state space model, we propose a novel temporal modeling paradigm for visual tracking, termed State-aware Mamba Tracker (SMTrack), providing a neat pipeline for training and tracking without needing customized modules or substantial computational costs to build long-range temporal dependencies. It enjoys several merits. First, we propose a novel selective state-aware space model with state-wise parameters to capture more diverse temporal cues for robust tracking. Second, SMTrack facilitates long-range temporal interactions with linear computational complexity during training. Third, SMTrack enables each frame to interact with previously tracked frames via hidden state propagation and updating, which releases computational costs of handling temporal cues during tracking. Extensive experimental results demonstrate that SMTrack achieves promising performance with low computational costs.

</details>


### [199] [FreshMem: Brain-Inspired Frequency-Space Hybrid Memory for Streaming Video Understanding](https://arxiv.org/abs/2602.01683)
*Kangcong Li,Peng Ye,Lin Zhang,Chao Wang,Huafeng Qin,Tao Chen*

Main category: cs.CV

TL;DR: FreshMem是一种频率-空间混合记忆网络，通过MFM和STM模块提升流视频理解的细节保留和上下文连贯性，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在从离线到在线流视频理解转换时缺乏灵活适应性，导致不可逆细节丢失和上下文碎片化的问题。

Method: 提出了FreshMem，一种受大脑对数感知和记忆巩固启发的频率-空间混合记忆网络，包含多尺度频率记忆（MFM）和空间缩略图记忆（STM）两个协同模块。

Result: FreshMem显著提升了Qwen2-VL基线模型，在StreamingBench、OV-Bench和OVO-Bench上分别取得了5.20%、4.52%和2.34%的性能提升。

Conclusion: FreshMem作为一种无需训练的解决方案，在长时程流视频理解方面提供了一种高效范式，显著提升了基线模型的性能。

Abstract: Transitioning Multimodal Large Language Models (MLLMs) from offline to online streaming video understanding is essential for continuous perception. However, existing methods lack flexible adaptivity, leading to irreversible detail loss and context fragmentation. To resolve this, we propose FreshMem, a Frequency-Space Hybrid Memory network inspired by the brain's logarithmic perception and memory consolidation. FreshMem reconciles short-term fidelity with long-term coherence through two synergistic modules: Multi-scale Frequency Memory (MFM), which projects overflowing frames into representative frequency coefficients, complemented by residual details to reconstruct a global historical "gist"; and Space Thumbnail Memory (STM), which discretizes the continuous stream into episodic clusters by employing an adaptive compression strategy to distill them into high-density space thumbnails. Extensive experiments show that FreshMem significantly boosts the Qwen2-VL baseline, yielding gains of 5.20%, 4.52%, and 2.34% on StreamingBench, OV-Bench, and OVO-Bench, respectively. As a training-free solution, FreshMem outperforms several fully fine-tuned methods, offering a highly efficient paradigm for long-horizon streaming video understanding.

</details>


### [200] [Cross-Modal Alignment and Fusion for RGB-D Transmission-Line Defect Detection](https://arxiv.org/abs/2602.01696)
*Jiaming Cui,Shuai Zhou,Wenqiang Li,Ruifeng Qin,Feng Shen*

Main category: cs.CV

TL;DR: CMAFNet结合RGB与深度信息，通过跨模态对齐和融合，显著提升输电线路小缺陷检测性能，计算效率高。


<details>
  <summary>Details</summary>
Motivation: 现有RGB检测器在复杂背景和光照变化下难以区分几何细微缺陷，需结合深度信息提升检测性能。

Method: 提出了CMAFNet，包含语义重组模块和上下文语义集成框架，通过字典特征纯化和部分通道注意力实现RGB与深度信息的融合。

Result: 在TLRGBD基准测试中，CMAFNet达到32.2% mAP@50和12.5% APs，轻量版在228 FPS下实现24.8% mAP50。

Conclusion: CMAFNet通过跨模态对齐和融合，显著提升了输电线路小缺陷检测的性能，且在计算成本上具有优势。

Abstract: Transmission line defect detection remains challenging for automated UAV inspection due to the dominance of small-scale defects, complex backgrounds, and illumination variations. Existing RGB-based detectors, despite recent progress, struggle to distinguish geometrically subtle defects from visually similar background structures under limited chromatic contrast. This paper proposes CMAFNet, a Cross-Modal Alignment and Fusion Network that integrates RGB appearance and depth geometry through a principled purify-then-fuse paradigm. CMAFNet consists of a Semantic Recomposition Module that performs dictionary-based feature purification via a learned codebook to suppress modality-specific noise while preserving defect-discriminative information, and a Contextual Semantic Integration Framework that captures global spatial dependencies using partial-channel attention to enhance structural semantic reasoning. Position-wise normalization within the purification stage enforces explicit reconstruction-driven cross-modal alignment, ensuring statistical compatibility between heterogeneous features prior to fusion. Extensive experiments on the TLRGBD benchmark, where 94.5% of instances are small objects, demonstrate that CMAFNet achieves 32.2% mAP@50 and 12.5% APs, outperforming the strongest baseline by 9.8 and 4.0 percentage points, respectively. A lightweight variant reaches 24.8% mAP50 at 228 FPS with only 4.9M parameters, surpassing all YOLO-based detectors while matching transformer-based methods at substantially lower computational cost.

</details>


### [201] [Physics Informed Generative AI Enabling Labour Free Segmentation For Microscopy Analysis](https://arxiv.org/abs/2602.01710)
*Salma Zahran,Zhou Ao,Zhengyang Zhang,Chen Chi,Chenchen Yuan,Yanming Wang*

Main category: cs.CV

TL;DR: 该论文提出了一种无需人工标注的语义分割框架，通过相场模拟和CycleGAN生成高保真合成数据，显著提升了模型在实验数据上的泛化性能。


<details>
  <summary>Details</summary>
Motivation: 显微镜图像的语义分割对于高通量材料表征至关重要，但专家标注数据的成本高、主观性强且稀缺，严重限制了其自动化。基于物理的模拟虽然提供了可扩展的替代方案，但由于显著的领域差距，模型在实验数据上的泛化能力不足。

Method: 利用相场模拟生成大量具有完美、固有真实掩码的微观结构形态，然后采用CycleGAN进行无配对的图像到图像转换，将干净的模拟数据转换为高保真、真实的SEM图像数据集。

Result: 仅使用合成数据训练的U-Net模型在未见过的实验图像上表现出卓越的泛化能力，平均边界F1分数为0.90，交并比（IOU）为0.88。

Conclusion: 该论文提出的生成框架通过完全解耦模型训练与手动标注，将数据稀缺问题转化为数据丰富问题，为加速材料发现和分析提供了稳健且完全自动化的解决方案。

Abstract: Semantic segmentation of microscopy images is a critical task for high-throughput materials characterisation, yet its automation is severely constrained by the prohibitive cost, subjectivity, and scarcity of expert-annotated data. While physics-based simulations offer a scalable alternative to manual labelling, models trained on such data historically fail to generalise due to a significant domain gap, lacking the complex textures, noise patterns, and imaging artefacts inherent to experimental data. This paper introduces a novel framework for labour-free segmentation that successfully bridges this simulation-to-reality gap. Our pipeline leverages phase-field simulations to generate an abundant source of microstructural morphologies with perfect, intrinsically-derived ground-truth masks. We then employ a Cycle-Consistent Generative Adversarial Network (CycleGAN) for unpaired image-to-image translation, transforming the clean simulations into a large-scale dataset of high-fidelity, realistic SEM images. A U-Net model, trained exclusively on this synthetic data, demonstrated remarkable generalisation when deployed on unseen experimental images, achieving a mean Boundary F1-Score of 0.90 and an Intersection over Union (IOU) of 0.88. Comprehensive validation using t-SNE feature-space projection and Shannon entropy analysis confirms that our synthetic images are statistically and featurally indistinguishable from the real data manifold. By completely decoupling model training from manual annotation, our generative framework transforms a data-scarce problem into one of data abundance, providing a robust and fully automated solution to accelerate materials discovery and analysis.

</details>


### [202] [FastPhysGS: Accelerating Physics-based Dynamic 3DGS Simulation via Interior Completion and Adaptive Optimization](https://arxiv.org/abs/2602.01723)
*Yikun Ma,Yiqing Li,Jingwen Ye,Zhongkai Wu,Weidong Zhang,Lin Gao,Zhi Jin*

Main category: cs.CV

TL;DR: FastPhysGS 是一种基于物理的动态3D高斯泼溅模拟框架，通过IPF和BGDO技术高效优化仿真，仅需1分钟和7GB内存，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖手动参数调整或从视频扩散模型中提取动态，泛化性和优化效率受限；基于LLMs/VLMs的方法存在文本/图像到3D的感知差距，导致物理行为不稳定且忽略3DGS表面结构。

Method: FastPhysGS 结合了实例感知粒子填充（IPF）与蒙特卡洛重要性采样（MCIS）以及双向图解耦优化（BGDO）策略，高效填充内部粒子并快速优化视觉语言模型（VLM）预测的材料参数。

Result: 实验表明，FastPhysGS 仅需1分钟和7GB内存即可实现高保真物理模拟，性能优于现有方法。

Conclusion: FastPhysGS 提出了一种快速且稳健的物理动态3D高斯泼溅（3DGS）模拟框架，显著提高了优化效率和仿真保真度，仅需1分钟和7GB内存即可完成高保真物理模拟。

Abstract: Extending 3D Gaussian Splatting (3DGS) to 4D physical simulation remains challenging. Based on the Material Point Method (MPM), existing methods either rely on manual parameter tuning or distill dynamics from video diffusion models, limiting the generalization and optimization efficiency. Recent attempts using LLMs/VLMs suffer from a text/image-to-3D perceptual gap, yielding unstable physics behavior. In addition, they often ignore the surface structure of 3DGS, leading to implausible motion. We propose FastPhysGS, a fast and robust framework for physics-based dynamic 3DGS simulation:(1) Instance-aware Particle Filling (IPF) with Monte Carlo Importance Sampling (MCIS) to efficiently populate interior particles while preserving geometric fidelity; (2) Bidirectional Graph Decoupling Optimization (BGDO), an adaptive strategy that rapidly optimizes material parameters predicted from a VLM. Experiments show FastPhysGS achieves high-fidelity physical simulation in 1 minute using only 7 GB runtime memory, outperforming prior works with broad potential applications.

</details>


### [203] [DenVisCoM: Dense Vision Correspondence Mamba for Efficient and Real-time Optical Flow and Stereo Estimation](https://arxiv.org/abs/2602.01724)
*Tushar Anand,Maheswar Bora,Antitza Dantcheva,Abhijit Das*

Main category: cs.CV

TL;DR: 提出DenVisCoM混合架构，实时准确联合估计光流和视差。


<details>
  <summary>Details</summary>
Motivation: 多视角几何与运动任务本质相关，需统一架构联合处理。

Method: 基于DenVisCoM和Transformer注意力块的混合架构，兼顾实时性、内存占用和准确性。

Result: 模型能实时准确估计光流和视差，实验验证了其性能。

Conclusion: 论文提出了一种新型的DenVisCoM Mamba块和混合架构，能够实时且准确地估计光流和视差，实验证明其高效性。

Abstract: In this work, we propose a novel Mamba block DenVisCoM, as well as a novel hybrid architecture specifically tailored for accurate and real-time estimation of optical flow and disparity estimation. Given that such multi-view geometry and motion tasks are fundamentally related, we propose a unified architecture to tackle them jointly. Specifically, the proposed hybrid architecture is based on DenVisCoM and a Transformer-based attention block that efficiently addresses real-time inference, memory footprint, and accuracy at the same time for joint estimation of motion and 3D dense perception tasks. We extensively analyze the benchmark trade-off of accuracy and real-time processing on a large number of datasets. Our experimental results and related analysis suggest that our proposed model can accurately estimate optical flow and disparity estimation in real time. All models and associated code are available at https://github.com/vimstereo/DenVisCoM.

</details>


### [204] [Simplicity Prevails: The Emergence of Generalizable AIGI Detection in Visual Foundation Models](https://arxiv.org/abs/2602.01738)
*Yue Zhou,Xinan He,Kaiqing Lin,Bing Fan,Feng Ding,Bin Li*

Main category: cs.CV

TL;DR: 简单线性分类器结合现代视觉基础模型特征，在AI生成图像检测中实现新SOTA，尤其在真实场景中表现突出，但仍有局限性如重捕获和传输下的性能下降。


<details>
  <summary>Details</summary>
Motivation: 尽管专业检测器在精选基准上表现优异，但在真实场景中性能急剧下降，因此探索简单但有效的解决方案。

Method: 使用现代视觉基础模型（如Perception Encoder、MetaCLIP 2和DINOv3）的冻结特征训练一个简单的线性分类器。

Result: 该基线方法不仅在标准基准上匹配专业检测器，还在真实数据集上显著超越，准确率提升超过30%。

Conclusion: 作者主张在AI取证领域进行范式转变，从过度拟合静态基准转向利用基础模型不断演进的世界知识，以实现真实世界的可靠性。

Abstract: While specialized detectors for AI-Generated Images (AIGI) achieve near-perfect accuracy on curated benchmarks, they suffer from a dramatic performance collapse in realistic, in-the-wild scenarios. In this work, we demonstrate that simplicity prevails over complex architectural designs. A simple linear classifier trained on the frozen features of modern Vision Foundation Models , including Perception Encoder, MetaCLIP 2, and DINOv3, establishes a new state-of-the-art. Through a comprehensive evaluation spanning traditional benchmarks, unseen generators, and challenging in-the-wild distributions, we show that this baseline not only matches specialized detectors on standard benchmarks but also decisively outperforms them on in-the-wild datasets, boosting accuracy by striking margins of over 30\%. We posit that this superior capability is an emergent property driven by the massive scale of pre-training data containing synthetic content. We trace the source of this capability to two distinct manifestations of data exposure: Vision-Language Models internalize an explicit semantic concept of forgery, while Self-Supervised Learning models implicitly acquire discriminative forensic features from the pretraining data. However, we also reveal persistent limitations: these models suffer from performance degradation under recapture and transmission, remain blind to VAE reconstruction and localized editing. We conclude by advocating for a paradigm shift in AI forensics, moving from overfitting on static benchmarks to harnessing the evolving world knowledge of foundation models for real-world reliability.

</details>


### [205] [Tail-Aware Post-Training Quantization for 3D Geometry Models](https://arxiv.org/abs/2602.01741)
*Sicheng Pan,Chen Tang,Shuzhao Xie,Ke Yang,Weixiang Zhang,Jiawei Li,Bin Chen,Shu-Tao Xia,Zhi Wang*

Main category: cs.CV

TL;DR: TAPTQ 是一种针对 3D 模型的量化方法，通过优化校准策略和量化搜索算法，提升了精度并降低了计算开销。


<details>
  <summary>Details</summary>
Motivation: 3D 几何模型的复杂性和规模对资源受限平台的部署提出了挑战，现有针对 2D 视觉变换器的量化方法无法有效迁移到 3D 模型。

Method: TAPTQ 通过渐进式粗到细校准策略、基于三元搜索的量化区间求解器以及 TRE 引导的模块补偿机制，优化了 3D 模型的量化过程。

Result: 在 VGGT 和 Pi3 基准测试中，TAPTQ 在精度上优于现有 PTQ 方法，并显著减少了校准时间。

Conclusion: TAPTQ 是一种专为 3D 几何学习设计的后训练量化方法，显著提升了量化精度并减少了校准时间。

Abstract: The burgeoning complexity and scale of 3D geometry models pose significant challenges for deployment on resource-constrained platforms. While Post-Training Quantization (PTQ) enables efficient inference without retraining, conventional methods, primarily optimized for 2D Vision Transformers, fail to transfer effectively to 3D models due to intricate feature distributions and prohibitive calibration overhead. To address these challenges, we propose TAPTQ, a Tail-Aware Post-Training Quantization pipeline specifically engineered for 3D geometric learning. Our contribution is threefold: (1) To overcome the data-scale bottleneck in 3D datasets, we develop a progressive coarse-to-fine calibration construction strategy that constructs a highly compact subset to achieve both statistical purity and geometric representativeness. (2) We reformulate the quantization interval search as an optimization problem and introduce a ternary-search-based solver, reducing the computational complexity from $\mathcal{O}(N)$ to $\mathcal{O}(\log N)$ for accelerated deployment. (3) To mitigate quantization error accumulation, we propose TRE-Guided Module-wise Compensation, which utilizes a Tail Relative Error (TRE) metric to adaptively identify and rectify distortions in modules sensitive to long-tailed activation outliers. Extensive experiments on the VGGT and Pi3 benchmarks demonstrate that TAPTQ consistently outperforms state-of-the-art PTQ methods in accuracy while significantly reducing calibration time. The code will be released soon.

</details>


### [206] [ObjEmbed: Towards Universal Multimodal Object Embeddings](https://arxiv.org/abs/2602.01753)
*Shenghao Fu,Yukun Su,Fengyun Rao,Jing Lyu,Xiaohua Xie,Wei-Shi Zheng*

Main category: cs.CV

TL;DR: ObjEmbed是一种新型MLLM嵌入模型，通过分解图像为区域和全局嵌入，结合语义和空间信息，显著提升细粒度视觉-语言对齐性能。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态嵌入模型在全局图像-文本对齐上表现良好，但在图像区域与特定短语的细粒度对齐上存在困难。ObjEmbed旨在解决这一问题。

Method: ObjEmbed是一种多模态嵌入模型，将输入图像分解为多个区域嵌入（每个对应一个对象）和全局嵌入。它通过生成两个互补嵌入（对象嵌入和IoU嵌入）来捕获对象的语义和空间信息，并结合两者进行更准确的检索。

Result: ObjEmbed在18个多样化的基准测试中展现出强大的语义判别能力，支持视觉定位、局部图像检索和全局图像检索等多种任务。

Conclusion: ObjEmbed通过分解图像为多个区域嵌入和全局嵌入，结合语义和空间信息，显著提升了细粒度视觉-语言对齐任务的性能，并在18个基准测试中表现出色。

Abstract: Aligning objects with corresponding textual descriptions is a fundamental challenge and a realistic requirement in vision-language understanding. While recent multimodal embedding models excel at global image-text alignment, they often struggle with fine-grained alignment between image regions and specific phrases. In this work, we present ObjEmbed, a novel MLLM embedding model that decomposes the input image into multiple regional embeddings, each corresponding to an individual object, along with global embeddings. It supports a wide range of visual understanding tasks like visual grounding, local image retrieval, and global image retrieval. ObjEmbed enjoys three key properties: (1) Object-Oriented Representation: It captures both semantic and spatial aspects of objects by generating two complementary embeddings for each region: an object embedding for semantic matching and an IoU embedding that predicts localization quality. The final object matching score combines semantic similarity with the predicted IoU, enabling more accurate retrieval. (2) Versatility: It seamlessly handles both region-level and image-level tasks. (3) Efficient Encoding: All objects in an image, along with the full image, are encoded in a single forward pass for high efficiency. Superior performance on 18 diverse benchmarks demonstrates its strong semantic discrimination.

</details>


### [207] [Spot-Wise Smart Parking: An Edge-Enabled Architecture with YOLOv11 and Digital Twin Integration](https://arxiv.org/abs/2602.01754)
*Gustavo P. C. P. da Luz,Alvaro M. Aspilcueta Narvaez,Tiago Godoi Bannwart,Gabriel Massuyoshi Sato,Luis Fernando Gomez Gonzalez,Juliana Freitag Borin*

Main category: cs.CV

TL;DR: 智能停车系统通过车位级监测策略和新技术组件，显著提升了准确率和功能性，同时保持高效运行。


<details>
  <summary>Details</summary>
Motivation: 克服现有系统无法提供车位级洞察和支持更高级应用的局限性。

Method: 采用距离感知匹配方法结合空间容差，并通过自适应边界框分割方法优化复杂空间的处理。系统还引入了数字阴影和应用支持服务器。

Result: 系统实现了98.80%的平衡准确率，推理时间为8秒，并成功引入了数字阴影和应用支持服务器。

Conclusion: 智能停车系统通过扩展为基于距离感知匹配方法的车位级监测策略，显著提升了系统能力，实现了98.80%的平衡准确率，并在资源受限的边缘设备上保持8秒的推理时间。此外，引入的数字阴影和应用支持服务器进一步增强了系统的可扩展性和可持续性。

Abstract: Smart parking systems help reduce congestion and minimize users' search time, thereby contributing to smart city adoption and enhancing urban mobility. In previous works, we presented a system developed on a university campus to monitor parking availability by estimating the number of free spaces from vehicle counts within a region of interest. Although this approach achieved good accuracy, it restricted the system's ability to provide spot-level insights and support more advanced applications. To overcome this limitation, we extend the system with a spot-wise monitoring strategy based on a distance-aware matching method with spatial tolerance, enhanced through an Adaptive Bounding Box Partitioning method for challenging spaces. The proposed approach achieves a balanced accuracy of 98.80% while maintaining an inference time of 8 seconds on a resource-constrained edge device, enhancing the capabilities of YOLOv11m, a model that has a size of 40.5 MB. In addition, two new components were introduced: (i) a Digital Shadow that visually represents parking lot entities as a base to evolve to a full Digital Twin, and (ii) an application support server based on a repurposed TV box. The latter not only enables scalable communication among cloud services, the parking totem, and a bot that provides detailed spot occupancy statistics, but also promotes hardware reuse as a step towards greater sustainability.

</details>


### [208] [Mind-Brush: Integrating Agentic Cognitive Search and Reasoning into Image Generation](https://arxiv.org/abs/2602.01756)
*Jun He,Junyan Ye,Zilong Huang,Dongzhi Jiang,Chenjue Zhang,Leqi Zhu,Renrui Zhang,Xiang Zhang,Weijia Li*

Main category: cs.CV

TL;DR: Mind-Brush 是一个动态知识驱动的文本到图像生成框架，通过模拟人类‘思考-研究-创造’流程提升意图理解和复杂知识推理能力，在多个基准测试中表现突出。


<details>
  <summary>Details</summary>
Motivation: 现有文本到图像生成模型多为静态文本到像素解码器，难以理解用户隐含意图，且无法适应现实世界的动态变化。Mind-Brush 旨在填补这些空白。

Method: Mind-Brush 是一个统一的代理框架，模拟人类‘思考-研究-创造’的范式，主动检索多模态证据以处理分布外概念，并利用推理工具解决隐含视觉约束。

Result: Mind-Brush 显著提升了统一模型的能力，在 Mind-Bench 上实现了 Qwen-Image 基线的零到一能力飞跃，并在 WISE 和 RISE 等基准测试中表现优异。

Conclusion: Mind-Brush 通过动态、知识驱动的工作流程显著提升了统一模型的能力，实现了在 Mind-Bench 上的零到一能力飞跃，并在 WISE 和 RISE 等基准测试中取得优异表现。

Abstract: While text-to-image generation has achieved unprecedented fidelity, the vast majority of existing models function fundamentally as static text-to-pixel decoders. Consequently, they often fail to grasp implicit user intentions. Although emerging unified understanding-generation models have improved intent comprehension, they still struggle to accomplish tasks involving complex knowledge reasoning within a single model. Moreover, constrained by static internal priors, these models remain unable to adapt to the evolving dynamics of the real world. To bridge these gaps, we introduce Mind-Brush, a unified agentic framework that transforms generation into a dynamic, knowledge-driven workflow. Simulating a human-like 'think-research-create' paradigm, Mind-Brush actively retrieves multimodal evidence to ground out-of-distribution concepts and employs reasoning tools to resolve implicit visual constraints. To rigorously evaluate these capabilities, we propose Mind-Bench, a comprehensive benchmark comprising 500 distinct samples spanning real-time news, emerging concepts, and domains such as mathematical and Geo-Reasoning. Extensive experiments demonstrate that Mind-Brush significantly enhances the capabilities of unified models, realizing a zero-to-one capability leap for the Qwen-Image baseline on Mind-Bench, while achieving superior results on established benchmarks like WISE and RISE.

</details>


### [209] [MagicFuse: Single Image Fusion for Visual and Semantic Reinforcement](https://arxiv.org/abs/2602.01760)
*Hao Zhang,Yanping Zha,Zizhuo Li,Meiqi Gong,Jiayi Ma*

Main category: cs.CV

TL;DR: MagicFuse利用扩散模型从单张低质量可见光图像生成跨光谱场景表示，性能媲美多模态融合方法。


<details>
  <summary>Details</summary>
Motivation: 解决在恶劣条件下仅依赖可见光传感器时如何保持多模态图像融合优势的问题。

Method: 提出了MagicFuse框架，包含光谱内知识增强分支、跨光谱知识生成分支和多域知识融合分支，基于扩散模型挖掘隐藏信息并融合。

Result: 实验表明，MagicFuse在视觉和语义表示上达到或超越多模态输入方法。

Conclusion: MagicFuse通过单张低质量可见光图像实现了跨光谱场景表示，性能媲美甚至超越多模态输入的最先进融合方法。

Abstract: This paper focuses on a highly practical scenario: how to continue benefiting from the advantages of multi-modal image fusion under harsh conditions when only visible imaging sensors are available. To achieve this goal, we propose a novel concept of single-image fusion, which extends conventional data-level fusion to the knowledge level. Specifically, we develop MagicFuse, a novel single image fusion framework capable of deriving a comprehensive cross-spectral scene representation from a single low-quality visible image. MagicFuse first introduces an intra-spectral knowledge reinforcement branch and a cross-spectral knowledge generation branch based on the diffusion models. They mine scene information obscured in the visible spectrum and learn thermal radiation distribution patterns transferred to the infrared spectrum, respectively. Building on them, we design a multi-domain knowledge fusion branch that integrates the probabilistic noise from the diffusion streams of these two branches, from which a cross-spectral scene representation can be obtained through successive sampling. Then, we impose both visual and semantic constraints to ensure that this scene representation can satisfy human observation while supporting downstream semantic decision-making. Extensive experiments show that our MagicFuse achieves visual and semantic representation performance comparable to or even better than state-of-the-art fusion methods with multi-modal inputs, despite relying solely on a single degraded visible image.

</details>


### [210] [GDPR-Compliant Person Recognition in Industrial Environments Using MEMS-LiDAR and Hybrid Data](https://arxiv.org/abs/2602.01764)
*Dennis Basile,Dennis Sprute,Helene Dörksen,Holger Flatt*

Main category: cs.CV

TL;DR: 论文提出了一种基于MEMS-LiDAR和合成数据的隐私合规人员检测方法，显著提升精度并减少标注成本。


<details>
  <summary>Details</summary>
Motivation: 传统基于深度学习的视觉方法在工业环境中存在光照敏感性和隐私合规问题，且数据收集和标注耗时且易出错。

Method: 使用MEMS-LiDAR捕获匿名3D点云数据，并通过CARLA仿真框架生成合成场景来增强真实数据，以减少数据收集和标注的时间和成本。

Result: 混合数据（真实与合成）相比纯真实数据训练模型，平均精度提高了44个百分点，同时减少了50%的人工标注工作量。

Conclusion: 该论文提出的基于MEMS-LiDAR的隐私合规方法，结合合成数据，显著提高了人员检测的精度并减少了人工标注工作量，为工业环境中的GDPR合规检测提供了可扩展且经济高效的解决方案。

Abstract: The reliable detection of unauthorized individuals in safety-critical industrial indoor spaces is crucial to avoid plant shutdowns, property damage, and personal hazards. Conventional vision-based methods that use deep-learning approaches for person recognition provide image information but are sensitive to lighting and visibility conditions and often violate privacy regulations, such as the General Data Protection Regulation (GDPR) in the European Union. Typically, detection systems based on deep learning require annotated data for training. Collecting and annotating such data, however, is highly time-consuming and due to manual treatments not necessarily error free. Therefore, this paper presents a privacy-compliant approach based on Micro-Electro-Mechanical Systems LiDAR (MEMS-LiDAR), which exclusively captures anonymized 3D point clouds and avoids personal identification features. To compensate for the large amount of time required to record real LiDAR data and for post-processing and annotation, real recordings are augmented with synthetically generated scenes from the CARLA simulation framework. The results demonstrate that the hybrid data improves the average precision by 44 percentage points compared to a model trained exclusively with real data while reducing the manual annotation effort by 50 %. Thus, the proposed approach provides a scalable, cost-efficient alternative to purely real-data-based methods and systematically shows how synthetic LiDAR data can combine high performance in person detection with GDPR compliance in an industrial environment.

</details>


### [211] [Automated Discontinuity Set Characterisation in Enclosed Rock Face Point Clouds Using Single-Shot Filtering and Cyclic Orientation Transformation](https://arxiv.org/abs/2602.01783)
*Dibyayan Patra,Pasindu Ranasinghe,Bikram Banerjee,Simit Raval*

Main category: cs.CV

TL;DR: 提出一种自动不连续集表征新方法，通过单次滤波和循环变换，显著提升实际场景中的准确性，误差低于3°。


<details>
  <summary>Details</summary>
Motivation: 开发一种鲁棒且高效的方法，用于自动表征实际场景（如完全封闭的岩石面）中的不连续集，以解决现有技术的局限性。

Method: 采用单次滤波策略、循环方向变换方案和层次聚类技术，有效抑制噪声和高曲率伪影，准确表示极坐标数据，并自动识别聚类。

Result: 该方法在真实矿山数据中表现出最低的平均绝对误差（倾角1.95°，倾向2.20°），分散误差低于3°，优于其他技术。

Conclusion: 本研究提出了一种新的自动不连续集表征方法，通过单次滤波策略、循环方向变换方案和层次聚类技术，显著提高了在完全封闭岩石面等实际场景中的表征准确性。

Abstract: Characterisation of structural discontinuity sets in exposed rock faces of underground mine cavities is essential for assessing rock-mass stability, excavation safety, and operational efficiency. UAV and other mobile laser-scanning techniques provide efficient means of collecting point clouds from rock faces. However, the development of a robust and efficient approach for automatic characterisation of discontinuity sets in real-world scenarios, like fully enclosed rock faces in cavities, remains an open research problem. In this study, a new approach is proposed for automatic discontinuity set characterisation that uses a single-shot filtering strategy, an innovative cyclic orientation transformation scheme and a hierarchical clustering technique. The single-shot filtering step isolates planar regions while robustly suppressing noise and high-curvature artefacts in one pass using a signal-processing technique. To address the limitations of Cartesian clustering on polar orientation data, a cyclic orientation transformation scheme is developed, enabling accurate representation of dip angle and dip direction in Cartesian space. The transformed orientations are then characterised into sets using a hierarchical clustering technique, which handles varying density distributions and identifies clusters without requiring user-defined set numbers. The accuracy of the method is validated on real-world mine stope and against ground truth obtained using manually handpicked discontinuity planes identified with the Virtual Compass tool, as well as widely used automated structure mapping techniques. The proposed approach outperforms the other techniques by exhibiting the lowest mean absolute error in estimating discontinuity set orientations in real-world stope data with errors of 1.95° and 2.20° in nominal dip angle and dip direction, respectively, and dispersion errors lying below 3°.

</details>


### [212] [Spatio-Temporal Transformers for Long-Term NDVI Forecasting](https://arxiv.org/abs/2602.01799)
*Ido Faran,Nathan S. Netanyahu,Maxim Shoshany*

Main category: cs.CV

TL;DR: STT-LTF框架通过Transformer整合空间与时间分析，显著提升地中海异质景观的长期卫星图像预测性能。


<details>
  <summary>Details</summary>
Motivation: 解决地中海地区异质性景观中长期卫星图像时间序列分析的挑战，包括复杂空间模式、季节变化和多年代环境变化的跨尺度交互。

Method: STT-LTF采用统一的Transformer架构处理多尺度空间补丁和时间序列（长达20年），结合自监督学习策略（空间掩码、时间掩码和水平采样），并直接预测任意未来时间点。

Result: 在Landsat数据（1984-2024）上的实验显示，STT-LTF在下一年的预测中实现了0.0328的MAE和0.8412的R^2，优于传统统计方法、CNN、LSTM和标准Transformer。

Conclusion: STT-LTF框架通过整合空间上下文建模与时间序列预测，显著提升了在异质性地中海景观中的长期卫星图像时间序列分析能力，尤其在处理不规则时间采样和可变预测范围方面表现出色。

Abstract: Long-term satellite image time series (SITS) analysis in heterogeneous landscapes faces significant challenges, particularly in Mediterranean regions where complex spatial patterns, seasonal variations, and multi-decade environmental changes interact across different scales. This paper presents the Spatio-Temporal Transformer for Long Term Forecasting (STT-LTF ), an extended framework that advances beyond purely temporal analysis to integrate spatial context modeling with temporal sequence prediction. STT-LTF processes multi-scale spatial patches alongside temporal sequences (up to 20 years) through a unified transformer architecture, capturing both local neighborhood relationships and regional climate influences. The framework employs comprehensive self-supervised learning with spatial masking, temporal masking, and horizon sampling strategies, enabling robust model training from 40 years of unlabeled Landsat imagery. Unlike autoregressive approaches, STT-LTF directly predicts arbitrary future time points without error accumulation, incorporating spatial patch embeddings, cyclical temporal encoding, and geographic coordinates to learn complex dependencies across heterogeneous Mediterranean ecosystems. Experimental evaluation on Landsat data (1984-2024) demonstrates that STT-LTF achieves a Mean Absolute Error (MAE) of 0.0328 and R^2 of 0.8412 for next-year predictions, outperforming traditional statistical methods, CNN-based approaches, LSTM networks, and standard transformers. The framework's ability to handle irregular temporal sampling and variable prediction horizons makes it particularly suitable for analysis of heterogeneous landscapes experiencing rapid ecological transitions.

</details>


### [213] [Fast Autoregressive Video Diffusion and World Models with Temporal Cache Compression and Sparse Attention](https://arxiv.org/abs/2602.01801)
*Dvir Samuel,Issar Tzachor,Matan Levy,Micahel Green,Gal Chechik,Rami Ben-Ari*

Main category: cs.CV

TL;DR: 提出了一种训练自由的注意力框架，通过压缩KV缓存和优化注意力计算，显著提升自回归视频扩散模型的推理效率。


<details>
  <summary>Details</summary>
Motivation: 自回归视频扩散模型在推理时注意力层成为瓶颈，KV缓存增长导致延迟和GPU内存增加，限制了时间上下文和长程一致性。

Method: 通过时间对应性压缩KV缓存（TempCache）、使用近似最近邻匹配加速跨注意力（AnnCA）和稀疏化自注意力（AnnSA）来优化注意力机制。

Result: 实验显示，这些模块实现了5-10倍的端到端加速，保持了视觉质量，并在长期生成中稳定了吞吐量和GPU内存使用。

Conclusion: 提出的TempCache、AnnCA和AnnSA模块显著减少了注意力计算和内存使用，同时保持了视觉质量，实现了长期生成中的稳定性能和内存控制。

Abstract: Autoregressive video diffusion models enable streaming generation, opening the door to long-form synthesis, video world models, and interactive neural game engines. However, their core attention layers become a major bottleneck at inference time: as generation progresses, the KV cache grows, causing both increasing latency and escalating GPU memory, which in turn restricts usable temporal context and harms long-range consistency. In this work, we study redundancy in autoregressive video diffusion and identify three persistent sources: near-duplicate cached keys across frames, slowly evolving (largely semantic) queries/keys that make many attention computations redundant, and cross-attention over long prompts where only a small subset of tokens matters per frame. Building on these observations, we propose a unified, training-free attention framework for autoregressive diffusion: TempCache compresses the KV cache via temporal correspondence to bound cache growth; AnnCA accelerates cross-attention by selecting frame-relevant prompt tokens using fast approximate nearest neighbor (ANN) matching; and AnnSA sparsifies self-attention by restricting each query to semantically matched keys, also using a lightweight ANN. Together, these modules reduce attention, compute, and memory and are compatible with existing autoregressive diffusion backbones and world models. Experiments demonstrate up to x5--x10 end-to-end speedups while preserving near-identical visual quality and, crucially, maintaining stable throughput and nearly constant peak GPU memory usage over long rollouts, where prior methods progressively slow down and suffer from increasing memory usage.

</details>


### [214] [FlowBypass: Rectified Flow Trajectory Bypass for Training-Free Image Editing](https://arxiv.org/abs/2602.01805)
*Menglin Han,Zhangkai Ni*

Main category: cs.CV

TL;DR: FlowBypass是一种基于Rectified Flow的无训练图像编辑框架，通过构建旁路减少错误积累，提升编辑效果。


<details>
  <summary>Details</summary>
Motivation: 现有无训练图像编辑方法主要依赖反转-重建轨迹，存在错误积累与提示对齐的固有权衡问题，且现有解决方案多为特定骨干网络的特征操作，通用性有限。

Method: 基于Rectified Flow，提出FlowBypass框架，通过形式化推导两条轨迹，获得近似旁路公式及其数值解，实现无缝轨迹过渡。

Result: 实验表明，FlowBypass在保持无关区域高保真细节的同时，实现了更强的提示对齐，性能优于现有最先进的图像编辑方法。

Conclusion: FlowBypass提出了一种基于Rectified Flow的分析框架，通过构建直接连接反转和重建轨迹的旁路，有效减少了错误积累，同时不依赖特征操作，显著提升了图像编辑的性能。

Abstract: Training-free image editing has attracted increasing attention for its efficiency and independence from training data. However, existing approaches predominantly rely on inversion-reconstruction trajectories, which impose an inherent trade-off: longer trajectories accumulate errors and compromise fidelity, while shorter ones fail to ensure sufficient alignment with the edit prompt. Previous attempts to address this issue typically employ backbone-specific feature manipulations, limiting general applicability. To address these challenges, we propose FlowBypass, a novel and analytical framework grounded in Rectified Flow that constructs a bypass directly connecting inversion and reconstruction trajectories, thereby mitigating error accumulation without relying on feature manipulations. We provide a formal derivation of two trajectories, from which we obtain an approximate bypass formulation and its numerical solution, enabling seamless trajectory transitions. Extensive experiments demonstrate that FlowBypass consistently outperforms state-of-the-art image editing methods, achieving stronger prompt alignment while preserving high-fidelity details in irrelevant regions.

</details>


### [215] [LDRNet: Large Deformation Registration Model for Chest CT Registration](https://arxiv.org/abs/2602.01812)
*Cheng Wang,Qiyu Gao,Fandong Zhang,Shu Zhang,Yizhou Yu*

Main category: cs.CV

TL;DR: LDRNet是一种快速无监督深度学习方法，专门针对大变形胸部CT图像配准，通过粗到精的细化过程和两个创新技术组件，实现了最先进的性能和更快的速度。


<details>
  <summary>Details</summary>
Motivation: 针对胸部CT图像配准中存在的更大变形、更复杂背景和区域重叠问题，现有深度学习算法主要关注脑部图像配准，因此需要专门的方法。

Method: 提出了一种快速无监督深度学习方法LDRNet，包括粗分辨率配准场预测和由粗到精的细化过程，引入了细化块和刚性块两个创新技术组件。

Result: 在私有数据集和公开数据集SegTHOR上训练和评估，与VoxelMorph、RCN和LapIRN等传统和深度学习方法相比，LDRNet表现最佳。

Conclusion: LDRNet在大变形胸部CT图像配准中实现了最先进的性能，并且速度更快。

Abstract: Most of the deep learning based medical image registration algorithms focus on brain image registration tasks.Compared with brain registration, the chest CT registration has larger deformation, more complex background and region over-lap. In this paper, we propose a fast unsupervised deep learning method, LDRNet, for large deformation image registration of chest CT images. We first predict a coarse resolution registration field, then refine it from coarse to fine. We propose two innovative technical components: 1) a refine block that is used to refine the registration field in different resolutions, 2) a rigid block that is used to learn transformation matrix from high-level features. We train and evaluate our model on the private dataset and public dataset SegTHOR. We compare our performance with state-of-the-art traditional registration methods as well as deep learning registration models VoxelMorph, RCN, and LapIRN. The results demonstrate that our model achieves state-of-the-art performance for large deformation images registration and is much faster.

</details>


### [216] [GPD: Guided Progressive Distillation for Fast and High-Quality Video Generation](https://arxiv.org/abs/2602.01814)
*Xiao Liang,Yunzhu Zhang,Linchao Zhu*

Main category: cs.CV

TL;DR: GPD通过渐进蒸馏和频率约束，高效减少视频生成步骤且保持质量。


<details>
  <summary>Details</summary>
Motivation: 扩散模型在视频生成中计算成本高，现有方法减少步骤时质量下降明显，需改进。

Method: 提出Guided Progressive Distillation (GPD)框架，包含教师模型逐步指导学生模型使用更大步长的训练策略，以及在线生成训练目标和频率域约束。

Result: 在Wan2.1模型上，GPD将采样步骤从48减至6，VBench上保持视觉质量。

Conclusion: GPD框架通过逐步蒸馏和频率域约束，显著减少了视频生成的扩散步骤，同时保持了高质量的视觉输出，优于现有蒸馏方法。

Abstract: Diffusion models have achieved remarkable success in video generation; however, the high computational cost of the denoising process remains a major bottleneck. Existing approaches have shown promise in reducing the number of diffusion steps, but they often suffer from significant quality degradation when applied to video generation. We propose Guided Progressive Distillation (GPD), a framework that accelerates the diffusion process for fast and high-quality video generation. GPD introduces a novel training strategy in which a teacher model progressively guides a student model to operate with larger step sizes. The framework consists of two key components: (1) an online-generated training target that reduces optimization difficulty while improving computational efficiency, and (2) frequency-domain constraints in the latent space that promote the preservation of fine-grained details and temporal dynamics. Applied to the Wan2.1 model, GPD reduces the number of sampling steps from 48 to 6 while maintaining competitive visual quality on VBench. Compared with existing distillation methods, GPD demonstrates clear advantages in both pipeline simplicity and quality preservation.

</details>


### [217] [Seeing Is Believing? A Benchmark for Multimodal Large Language Models on Visual Illusions and Anomalies](https://arxiv.org/abs/2602.01816)
*Wenjin Hou,Wei Liu,Han Hu,Xiaoxiao Sun,Serena Yeung-Levy,Hehe Fan*

Main category: cs.CV

TL;DR: VIA-Bench是一个挑战性基准，用于评估MLLMs在视觉幻觉和异常上的表现，发现现有模型存在显著脆弱性。


<details>
  <summary>Details</summary>
Motivation: 现有评估主要依赖标准分布内数据，缺乏对MLLMs在违背常识场景下鲁棒性的考察。

Method: 通过人类参与的循环审查构建了超过1K高质量问答对，评估了20多种最先进的MLLMs。

Result: 发现CoT推理提供的鲁棒性微乎其微，模型逻辑在幻觉刺激下易崩溃。

Conclusion: VIA-Bench揭示了MLLMs在面对视觉幻觉和异常时的显著脆弱性，表明解决这些感知瓶颈对AGI发展至关重要。

Abstract: Multimodal Large Language Models (MLLMs) have shown remarkable proficiency on general-purpose vision-language benchmarks, reaching or even exceeding human-level performance. However, these evaluations typically rely on standard in-distribution data, leaving the robustness of MLLMs largely unexamined when faced with scenarios that defy common-sense priors. To address this gap, we introduce VIA-Bench, a challenging benchmark designed to probe model performance on visual illusions and anomalies. It includes six core categories: color illusions, motion illusions, gestalt illusions, geometric and spatial illusions, general visual illusions, and visual anomalies. Through careful human-in-the-loop review, we construct over 1K high-quality question-answer pairs that require nuanced visual reasoning. Extensive evaluation of over 20 state-of-the-art MLLMs, including proprietary, open-source, and reasoning-enhanced models, uncovers significant vulnerabilities. Notably, we find that Chain-of-Thought (CoT) reasoning offers negligible robustness, often yielding ``brittle mirages'' where the model's logic collapses under illusory stimuli. Our findings reveal a fundamental divergence between machine and human perception, suggesting that resolving such perceptual bottlenecks is critical for the advancement of artificial general intelligence. The benchmark data and code will be released.

</details>


### [218] [Efficient Cross-Country Data Acquisition Strategy for ADAS via Street-View Imagery](https://arxiv.org/abs/2602.01836)
*Yin Wu,Daniel Slieter,Carl Esselborn,Ahmed Abouelazm,Tsung Yuan Tseng,J. Marius Zöllner*

Main category: cs.CV

TL;DR: 论文提出街景引导数据采集策略，通过两种POI评分方法高效识别代表性地点，实验证明其性能与随机采样相当且成本更低。


<details>
  <summary>Details</summary>
Motivation: 部署ADAS和ADS在不同国家面临挑战，主要由于立法、交通基础设施和视觉习惯的差异导致感知性能下降。传统数据采集方法成本高且效率低。

Method: 提出了两种POI评分方法：基于KNN特征距离的方法（使用视觉基础模型）和视觉属性方法（使用视觉语言模型）。

Result: 实验表明，该方法在交通标志检测任务中性能与随机采样相当，但仅需一半目标域数据。大规模街景处理在经济上仍可行。

Conclusion: 论文结论强调了街景引导数据采集策略在高效、经济地实现跨国模型适应方面的潜力。

Abstract: Deploying ADAS and ADS across countries remains challenging due to differences in legislation, traffic infrastructure, and visual conventions, which introduce domain shifts that degrade perception performance. Traditional cross-country data collection relies on extensive on-road driving, making it costly and inefficient to identify representative locations. To address this, we propose a street-view-guided data acquisition strategy that leverages publicly available imagery to identify places of interest (POI). Two POI scoring methods are introduced: a KNN-based feature distance approach using a vision foundation model, and a visual-attribution approach using a vision-language model. To enable repeatable evaluation, we adopt a collect-detect protocol and construct a co-located dataset by pairing the Zenseact Open Dataset with Mapillary street-view images. Experiments on traffic sign detection, a task particularly sensitive to cross-country variations in sign appearance, show that our approach achieves performance comparable to random sampling while using only half of the target-domain data. We further provide cost estimations for full-country analysis, demonstrating that large-scale street-view processing remains economically feasible. These results highlight the potential of street-view-guided data acquisition for efficient and cost-effective cross-country model adaptation.

</details>


### [219] [SPIRIT: Adapting Vision Foundation Models for Unified Single- and Multi-Frame Infrared Small Target Detection](https://arxiv.org/abs/2602.01843)
*Qian Xu,Xi Li,Fei Gao,Jie Guo,Haojuan Yuan,Shuaipeng Fan,Mingjin Zhang*

Main category: cs.CV

TL;DR: SPIRIT是一个统一且兼容VFMs的框架，通过物理信息插件优化空间特征和时间关联，显著提升红外小目标检测性能。


<details>
  <summary>Details</summary>
Motivation: 红外小目标检测面临数据稀缺、目标信号弱且语义线索有限的问题，直接使用可见光谱的VFMs和外观驱动的跨帧关联不可靠，需要一种适应红外特性的解决方案。

Method: SPIRIT框架采用PIFR进行空间特征优化，通过近似秩稀疏分解抑制结构化背景并增强稀疏目标信号；PGMA在时间维度上注入历史软空间先验，以约束跨帧关联。

Result: 在多个IRSTD基准测试中，SPIRIT框架相比基于VFMs的基线方法表现出显著优势，并达到了SOTA性能。

Conclusion: SPIRIT框架通过轻量级的物理信息插件成功适应了VFMs于IRSTD任务，实现了单帧和多帧推理的统一，并在多个基准测试中表现出优于现有方法的性能。

Abstract: Infrared small target detection (IRSTD) is crucial for surveillance and early-warning, with deployments spanning both single-frame analysis and video-mode tracking. A practical solution should leverage vision foundation models (VFMs) to mitigate infrared data scarcity, while adopting a memory-attention-based temporal propagation framework that unifies single- and multi-frame inference. However, infrared small targets exhibit weak radiometric signals and limited semantic cues, which differ markedly from visible-spectrum imagery. This modality gap makes direct use of semantics-oriented VFMs and appearance-driven cross-frame association unreliable for IRSTD: hierarchical feature aggregation can submerge localized target peaks, and appearance-only memory attention becomes ambiguous, leading to spurious clutter associations. To address these challenges, we propose SPIRIT, a unified and VFM-compatible framework that adapts VFMs to IRSTD via lightweight physics-informed plug-ins. Spatially, PIFR refines features by approximating rank-sparsity decomposition to suppress structured background components and enhance sparse target-like signals. Temporally, PGMA injects history-derived soft spatial priors into memory cross-attention to constrain cross-frame association, enabling robust video detection while naturally reverting to single-frame inference when temporal context is absent. Experiments on multiple IRSTD benchmarks show consistent gains over VFM-based baselines and SOTA performance.

</details>


### [220] [CloDS: Visual-Only Unsupervised Cloth Dynamics Learning in Unknown Conditions](https://arxiv.org/abs/2602.01844)
*Yuliang Zhan,Jian Li,Wenbing Huang,Wenbing Huang,Yang Liu,Hao Sun*

Main category: cs.CV

TL;DR: 提出无监督学习框架CloDS，通过三阶段流程从多视角视频中学习布料动力学，解决大变形和自遮挡问题，实验显示其有效性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法需要已知物理属性作为监督或输入，限制了在未知条件下的适用性。为此，提出CDG场景和CloDS框架，探索从多视角视觉观察中无监督学习布料动力学的挑战。

Method: CloDS采用三阶段流程：视频到几何的接地，然后在接地的网格上训练动力学模型。针对大非线性变形和严重自遮挡问题，引入双位置不透明度调制，支持通过基于网格的高斯溅射进行2D观察与3D几何之间的双向映射。

Result: 综合实验评估表明，CloDS能够从视觉数据中有效学习布料动力学，并对未见配置保持强泛化能力。

Conclusion: CloDS通过无监督学习从视觉数据中有效学习布料动力学，并展现出对未见配置的强泛化能力。

Abstract: Deep learning has demonstrated remarkable capabilities in simulating complex dynamic systems. However, existing methods require known physical properties as supervision or inputs, limiting their applicability under unknown conditions. To explore this challenge, we introduce Cloth Dynamics Grounding (CDG), a novel scenario for unsupervised learning of cloth dynamics from multi-view visual observations. We further propose Cloth Dynamics Splatting (CloDS), an unsupervised dynamic learning framework designed for CDG. CloDS adopts a three-stage pipeline that first performs video-to-geometry grounding and then trains a dynamics model on the grounded meshes. To cope with large non-linear deformations and severe self-occlusions during grounding, we introduce a dual-position opacity modulation that supports bidirectional mapping between 2D observations and 3D geometry via mesh-based Gaussian splatting in video-to-geometry grounding stage. It jointly considers the absolute and relative position of Gaussian components. Comprehensive experimental evaluations demonstrate that CloDS effectively learns cloth dynamics from visual data while maintaining strong generalization capabilities for unseen configurations. Our code is available at https://github.com/whynot-zyl/CloDS. Visualization results are available at https://github.com/whynot-zyl/CloDS_video}.%\footnote{As in this example.

</details>


### [221] [WS-IMUBench: Can Weakly Supervised Methods from Audio, Image, and Video Be Adapted for IMU-based Temporal Action Localization?](https://arxiv.org/abs/2602.01850)
*Pei Li,Jiaxi Yin,Lei Ouyang,Shihan Pan,Ge Wang,Han Ding,Fei Wang*

Main category: cs.CV

TL;DR: 该论文提出了WS-IMUBench，一个弱监督IMU-TAL的基准研究，评估了七种方法在七个数据集上的表现，并总结了迁移性、有效性和改进方向。


<details>
  <summary>Details</summary>
Motivation: 当前IMU-TAL的进展受到密集帧级边界注释的高成本和难以扩展的限制，因此研究了在仅序列级标签下的弱监督IMU-TAL。

Method: 评估了七种代表性的弱监督方法在七个公共IMU数据集上的表现，进行了超过3,540次模型训练和7,080次推理评估。

Result: 发现（i）迁移是模态依赖的，时间域方法通常比基于图像提案的方法更稳定；（ii）在有利的数据集上，弱监督可以具有竞争力；（iii）主要失败模式源于短动作、时间模糊性和提案质量。

Conclusion: WS-IMUBench为弱监督IMU-TAL提供了一个可复现的基准模板，包括数据集、协议和分析，以加速社区在该领域的发展。

Abstract: IMU-based Human Activity Recognition (HAR) has enabled a wide range of ubiquitous computing applications, yet its dominant clip classification paradigm cannot capture the rich temporal structure of real-world behaviors. This motivates a shift toward IMU Temporal Action Localization (IMU-TAL), which predicts both action categories and their start/end times in continuous streams. However, current progress is strongly bottlenecked by the need for dense, frame-level boundary annotations, which are costly and difficult to scale. To address this bottleneck, we introduce WS-IMUBench, a systematic benchmark study of weakly supervised IMU-TAL (WS-IMU-TAL) under only sequence-level labels. Rather than proposing a new localization algorithm, we evaluate how well established weakly supervised localization paradigms from audio, image, and video transfer to IMU-TAL under only sequence-level labels. We benchmark seven representative weakly supervised methods on seven public IMU datasets, resulting in over 3,540 model training runs and 7,080 inference evaluations. Guided by three research questions on transferability, effectiveness, and insights, our findings show that (i) transfer is modality-dependent, with temporal-domain methods generally more stable than image-derived proposal-based approaches; (ii) weak supervision can be competitive on favorable datasets (e.g., with longer actions and higher-dimensional sensing); and (iii) dominant failure modes arise from short actions, temporal ambiguity, and proposal quality. Finally, we outline concrete directions for advancing WS-IMU-TAL (e.g., IMU-specific proposal generation, boundary-aware objectives, and stronger temporal reasoning). Beyond individual results, WS-IMUBench establishes a reproducible benchmarking template, datasets, protocols, and analyses, to accelerate community-wide progress toward scalable WS-IMU-TAL.

</details>


### [222] [How Well Do Models Follow Visual Instructions? VIBE: A Systematic Benchmark for Visual Instruction-Driven Image Editing](https://arxiv.org/abs/2602.01851)
*Huanyu Zhang,Xuehai Bai,Chengzu Li,Chen Liang,Haochen Tian,Haodong Li,Ruichuan An,Yifan Zhang,Anna Korhonen,Zhang Zhang,Liang Wang,Tieniu Tan*

Main category: cs.CV

TL;DR: VIBE基准测试通过多层级视觉指令评估图像编辑模型，专有模型表现优于开源模型，但任务难度增加时性能下降。


<details>
  <summary>Details</summary>
Motivation: 现有图像编辑系统主要依赖文本指导，而人类交流是多模态的，视觉指令（如草图）能更高效传达空间和结构意图。

Method: 引入VIBE基准测试，包含三个层次的交互层级，并采用LMM-as-a-judge评估框架进行细粒度评估。

Result: 评估了17个代表性开源和专有图像编辑模型，发现专有模型在早期视觉指令跟随能力上表现更优。

Conclusion: 专有模型在视觉指令跟随方面表现优于开源模型，但随着任务难度增加，性能显著下降，为未来研究指明了方向。

Abstract: Recent generative models have achieved remarkable progress in image editing. However, existing systems and benchmarks remain largely text-guided. In contrast, human communication is inherently multimodal, where visual instructions such as sketches efficiently convey spatial and structural intent. To address this gap, we introduce VIBE, the Visual Instruction Benchmark for Image Editing with a three-level interaction hierarchy that captures deictic grounding, morphological manipulation, and causal reasoning. Across these levels, we curate high-quality and diverse test cases that reflect progressively increasing complexity in visual instruction following. We further propose a robust LMM-as-a-judge evaluation framework with task-specific metrics to enable scalable and fine-grained assessment. Through a comprehensive evaluation of 17 representative open-source and proprietary image editing models, we find that proprietary models exhibit early-stage visual instruction-following capabilities and consistently outperform open-source models. However, performance degrades markedly with increasing task difficulty even for the strongest systems, highlighting promising directions for future research.

</details>


### [223] [Fact or Fake? Assessing the Role of Deepfake Detectors in Multimodal Misinformation Detection](https://arxiv.org/abs/2602.01854)
*A S M Sharifuzzaman Sagar,Mohammed Bennamoun,Farid Boussaid,Naeha Sharif,Lian Xu,Shaaban Sahmoud,Ali Kishk*

Main category: cs.CV

TL;DR: 像素级伪造检测器在多模态虚假信息验证中效果有限，证据驱动的方法表现更优。


<details>
  <summary>Details</summary>
Motivation: 探讨像素级伪造检测器在多模态虚假信息验证中是否有用，或是否因误导性真实性先验而损害基于证据的推理。

Method: 使用MMFakeBench和DGM4两个基准数据集，评估了（1）仅图像的深度伪造检测器，（2）基于证据的事实核查系统（结合MCTS和MAD），（3）将检测器输出作为辅助证据的混合系统。

Result: 深度伪造检测器的独立价值有限（F1分数0.26-0.53和0.33-0.49），将其纳入事实核查管道会降低性能（F1下降0.04-0.08）。证据驱动系统表现最佳（F1约0.81和0.55）。

Conclusion: 多模态虚假信息验证主要依赖于语义理解和外部证据，像素级伪造检测信号在实际应用中并不能有效提升推理效果。

Abstract: In multimodal misinformation, deception usually arises not just from pixel-level manipulations in an image, but from the semantic and contextual claim jointly expressed by the image-text pair. Yet most deepfake detectors, engineered to detect pixel-level forgeries, do not account for claim-level meaning, despite their growing integration in automated fact-checking (AFC) pipelines. This raises a central scientific and practical question: Do pixel-level detectors contribute useful signal for verifying image-text claims, or do they instead introduce misleading authenticity priors that undermine evidence-based reasoning? We provide the first systematic analysis of deepfake detectors in the context of multimodal misinformation detection. Using two complementary benchmarks, MMFakeBench and DGM4, we evaluate: (1) state-of-the-art image-only deepfake detectors, (2) an evidence-driven fact-checking system that performs tool-guided retrieval via Monte Carlo Tree Search (MCTS) and engages in deliberative inference through Multi-Agent Debate (MAD), and (3) a hybrid fact-checking system that injects detector outputs as auxiliary evidence. Results across both benchmark datasets show that deepfake detectors offer limited standalone value, achieving F1 scores in the range of 0.26-0.53 on MMFakeBench and 0.33-0.49 on DGM4, and that incorporating their predictions into fact-checking pipelines consistently reduces performance by 0.04-0.08 F1 due to non-causal authenticity assumptions. In contrast, the evidence-centric fact-checking system achieves the highest performance, reaching F1 scores of approximately 0.81 on MMFakeBench and 0.55 on DGM4. Overall, our findings demonstrate that multimodal claim verification is driven primarily by semantic understanding and external evidence, and that pixel-level artifact signals do not reliably enhance reasoning over real-world image-text misinformation.

</details>


### [224] [Trust but Verify: Adaptive Conditioning for Reference-Based Diffusion Super-Resolution via Implicit Reference Correlation Modeling](https://arxiv.org/abs/2602.01864)
*Yuan Wang,Yuhao Wan,Siming Zheng,Bo Li,Qibin Hou,Peng-Tao Jiang*

Main category: cs.CV

TL;DR: Ada-RefSR通过自适应隐式相关性门控（AICG）机制，智能调节参考图像的利用，提升图像超分辨率效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法在参考图像与低质量输入之间的相关性不可靠时，要么忽略相关性，要么依赖脆弱的显式匹配，导致对误导性参考的过度依赖或有价值线索的利用不足。

Method: 提出Ada-RefSR框架，采用“信任但验证”原则，通过AICG模块学习摘要令牌以提取主要参考模式并捕获与低质量特征的隐式相关性，集成到注意力主干中实现轻量级自适应调节。

Result: 实验表明，Ada-RefSR在多个数据集上实现了高保真度、自然性和效率的平衡，并在参考对齐变化时保持鲁棒性。

Conclusion: Ada-RefSR通过自适应隐式相关性门控（AICG）机制，有效平衡了参考图像的利用与抑制，在多种数据集上实现了高保真度、自然性和效率的平衡，并在参考对齐变化时保持鲁棒性。

Abstract: Recent works have explored reference-based super-resolution (RefSR) to mitigate hallucinations in diffusion-based image restoration. A key challenge is that real-world degradations make correspondences between low-quality (LQ) inputs and reference (Ref) images unreliable, requiring adaptive control of reference usage. Existing methods either ignore LQ-Ref correlations or rely on brittle explicit matching, leading to over-reliance on misleading references or under-utilization of valuable cues. To address this, we propose Ada-RefSR, a single-step diffusion framework guided by a "Trust but Verify" principle: reference information is leveraged when reliable and suppressed otherwise. Its core component, Adaptive Implicit Correlation Gating (AICG), employs learnable summary tokens to distill dominant reference patterns and capture implicit correlations with LQ features. Integrated into the attention backbone, AICG provides lightweight, adaptive regulation of reference guidance, serving as a built-in safeguard against erroneous fusion. Experiments on multiple datasets demonstrate that Ada-RefSR achieves a strong balance of fidelity, naturalness, and efficiency, while remaining robust under varying reference alignment.

</details>


### [225] [ProxyImg: Towards Highly-Controllable Image Representation via Hierarchical Disentangled Proxy Embedding](https://arxiv.org/abs/2602.01881)
*Ye Chen,Yupeng Zhu,Xiongzhen Zhang,Zhewen Wan,Yingzhe Li,Wenjun Zhang,Bingbing Ni*

Main category: cs.CV

TL;DR: 提出分层代理参数化图像表示，解耦语义、几何和纹理属性，实现高效编辑和实时动画，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有图像表示方法（如显式栅格图像、高斯基元或隐式潜在图像）存在表示冗余或缺乏从潜在变量到语义实例的直接映射，导致编辑效率低且可控性差。

Method: 该方法通过语义感知的图像分解，构建分层代理几何结构（自适应贝塞尔拟合和迭代区域细分与网格化），并将多尺度隐式纹理参数嵌入到几何感知的分布式代理节点中，支持连续高保真重建和语义编辑。

Result: 在ImageNet、OIR-Bench和HumanEdit等基准测试中，该方法以更少的参数实现了最先进的渲染保真度，并支持直观、交互式且物理合理的操作。此外，结合位置动力学实现了实时物理驱动动画，优于生成方法。

Conclusion: 该论文提出了一种基于分层代理的参数化图像表示方法，通过解耦语义、几何和纹理属性，实现了高效、可控的图像和视频编辑，并在多个基准测试中展现了优越的渲染保真度和实时物理驱动动画能力。

Abstract: Prevailing image representation methods, including explicit representations such as raster images and Gaussian primitives, as well as implicit representations such as latent images, either suffer from representation redundancy that leads to heavy manual editing effort, or lack a direct mapping from latent variables to semantic instances or parts, making fine-grained manipulation difficult. These limitations hinder efficient and controllable image and video editing. To address these issues, we propose a hierarchical proxy-based parametric image representation that disentangles semantic, geometric, and textural attributes into independent and manipulable parameter spaces. Based on a semantic-aware decomposition of the input image, our representation constructs hierarchical proxy geometries through adaptive Bezier fitting and iterative internal region subdivision and meshing. Multi-scale implicit texture parameters are embedded into the resulting geometry-aware distributed proxy nodes, enabling continuous high-fidelity reconstruction in the pixel domain and instance- or part-independent semantic editing. In addition, we introduce a locality-adaptive feature indexing mechanism to ensure spatial texture coherence, which further supports high-quality background completion without relying on generative models. Extensive experiments on image reconstruction and editing benchmarks, including ImageNet, OIR-Bench, and HumanEdit, demonstrate that our method achieves state-of-the-art rendering fidelity with significantly fewer parameters, while enabling intuitive, interactive, and physically plausible manipulation. Moreover, by integrating proxy nodes with Position-Based Dynamics, our framework supports real-time physics-driven animation using lightweight implicit rendering, achieving superior temporal consistency and visual realism compared with generative approaches.

</details>


### [226] [Q Cache: Visual Attention is Valuable in Less than Half of Decode Layers for Multimodal Large Language Model](https://arxiv.org/abs/2602.01901)
*Jiedong Zhuang,Lu Lu,Ming Dai,Rui Hu,Jian Chen,Qiang Liu,Haoji Hu*

Main category: cs.CV

TL;DR: Lazy Attention通过跨层共享注意力模式减少冗余计算，降低KV缓存使用并提升吞吐量，性能损失极小。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）因视觉编码器中冗余的视觉标记导致高昂的推理成本和KV缓存瓶颈，现有方法虽能优化标记但会损害KV缓存完整性。

Method: 通过分析模型注意力机制，发现超过半数的解码层注意力语义相似，因此提出跨层共享注意力模式的方法，并设计了轻量级的Q Cache。

Result: 实验表明，该方法能减少35%以上的KV缓存使用，提升1.5倍吞吐量，性能损失仅约1%，且优于现有标记优化方法。

Conclusion: Lazy Attention 提出了一种高效的注意力机制，通过跨层共享相似的注意力模式，显著减少了KV缓存的使用和计算冗余，同时保持了模型性能。

Abstract: Multimodal large language models (MLLMs) are plagued by exorbitant inference costs attributable to the profusion of visual tokens within the vision encoder. The redundant visual tokens engenders a substantial computational load and key-value (KV) cache footprint bottleneck. Existing approaches focus on token-wise optimization, leveraging diverse intricate token pruning techniques to eliminate non-crucial visual tokens. Nevertheless, these methods often unavoidably undermine the integrity of the KV cache, resulting in failures in long-text generation tasks. To this end, we conduct an in-depth investigation towards the attention mechanism of the model from a new perspective, and discern that attention within more than half of all decode layers are semantic similar. Upon this finding, we contend that the attention in certain layers can be streamlined by inheriting the attention from their preceding layers. Consequently, we propose Lazy Attention, an efficient attention mechanism that enables cross-layer sharing of similar attention patterns. It ingeniously reduces layer-wise redundant computation in attention. In Lazy Attention, we develop a novel layer-shared cache, Q Cache, tailored for MLLMs, which facilitates the reuse of queries across adjacent layers. In particular, Q Cache is lightweight and fully compatible with existing inference frameworks, including Flash Attention and KV cache. Additionally, our method is highly flexible as it is orthogonal to existing token-wise techniques and can be deployed independently or combined with token pruning approaches. Empirical evaluations on multiple benchmarks demonstrate that our method can reduce KV cache usage by over 35% and achieve 1.5x throughput improvement, while sacrificing only approximately 1% of performance on various MLLMs. Compared with SOTA token-wise methods, our technique achieves superior accuracy preservation.

</details>


### [227] [Learning Sparse Visual Representations via Spatial-Semantic Factorization](https://arxiv.org/abs/2602.01905)
*Theodore Zhengde Zhao,Sid Kiblawi,Jianwei Yang,Naoto Usuyama,Reuben Tan,Noel C Codella,Tristan Naumann,Hoifung Poon,Mu Wei*

Main category: cs.CV

TL;DR: STELLAR框架通过特征分解解决了自监督学习中语义与重建的冲突，支持高质量重建和语义性能。


<details>
  <summary>Details</summary>
Motivation: 自监督学习（SSL）在语义理解与图像重建之间存在冲突，高层次的语义SSL（如DINO）依赖于全局令牌，而生成式SSL（如MAE）则保留了密集特征网格但无法产生高层次抽象。

Method: STELLAR框架通过将视觉特征分解为语义概念及其空间分布的低秩乘积，实现了语义令牌的DINO风格增强对齐，同时保持了定位矩阵中精确的空间映射。

Result: 实验表明，仅需16个稀疏令牌，STELLAR框架即可同时支持高质量重建（2.60 FID）并匹配密集骨干网络的语义性能（79.10% ImageNet准确率）。

Conclusion: STELLAR框架通过将视觉特征分解为语义概念及其空间分布的低秩乘积，成功解决了自监督学习中语义理解与图像重建之间的冲突，提供了一种既能支持高质量重建又能匹配密集骨干网络语义性能的稀疏表示。

Abstract: Self-supervised learning (SSL) faces a fundamental conflict between semantic understanding and image reconstruction. High-level semantic SSL (e.g., DINO) relies on global tokens that are forced to be location-invariant for augmentation alignment, a process that inherently discards the spatial coordinates required for reconstruction. Conversely, generative SSL (e.g., MAE) preserves dense feature grids for reconstruction but fails to produce high-level abstractions. We introduce STELLAR, a framework that resolves this tension by factorizing visual features into a low-rank product of semantic concepts and their spatial distributions. This disentanglement allows us to perform DINO-style augmentation alignment on the semantic tokens while maintaining the precise spatial mapping in the localization matrix necessary for pixel-level reconstruction. We demonstrate that as few as 16 sparse tokens under this factorized form are sufficient to simultaneously support high-quality reconstruction (2.60 FID) and match the semantic performance of dense backbones (79.10% ImageNet accuracy). Our results highlight STELLAR as a versatile sparse representation that bridges the gap between discriminative and generative vision by strategically separating semantic identity from spatial geometry. Code available at https://aka.ms/stellar.

</details>


### [228] [DSXFormer: Dual-Pooling Spectral Squeeze-Expansion and Dynamic Context Attention Transformer for Hyperspectral Image Classification](https://arxiv.org/abs/2602.01906)
*Farhan Ullah,Irfan Ullah,Khalil Khan,Giovanni Pau,JaKeoung Koo*

Main category: cs.CV

TL;DR: DSXFormer结合双池化光谱挤压扩展和动态上下文注意力，显著提升高光谱图像分类性能。


<details>
  <summary>Details</summary>
Motivation: 解决高光谱图像分类中高光谱维度、复杂光谱-空间相关性和有限标记样本的挑战，同时提升光谱区分性和计算效率。

Method: 提出了一种新型的DSXFormer模型，包含双池化光谱挤压扩展块（DSX）和动态上下文注意力机制（DCA），结合窗口式Transformer架构和多尺度特征学习策略。

Result: 在Salinas、Indian Pines、Pavia University和Kennedy Space Center数据集上分别达到99.95%、98.91%、99.85%和98.52%的分类精度。

Conclusion: DSXFormer通过结合双池化光谱挤压扩展块和动态上下文注意力机制，在多个高光谱基准数据集上实现了优于现有方法的分类精度。

Abstract: Hyperspectral image classification (HSIC) is a challenging task due to high spectral dimensionality, complex spectral-spatial correlations, and limited labeled training samples. Although transformer-based models have shown strong potential for HSIC, existing approaches often struggle to achieve sufficient spectral discriminability while maintaining computational efficiency. To address these limitations, we propose a novel DSXFormer, a novel dual-pooling spectral squeeze-expansion transformer with Dynamic Context Attention for HSIC. The proposed DSXFormer introduces a Dual-Pooling Spectral Squeeze-Expansion (DSX) block, which exploits complementary global average and max pooling to adaptively recalibrate spectral feature channels, thereby enhancing spectral discriminability and inter-band dependency modeling. In addition, DSXFormer incorporates a Dynamic Context Attention (DCA) mechanism within a window-based transformer architecture to dynamically capture local spectral-spatial relationships while significantly reducing computational overhead. The joint integration of spectral dual-pooling squeeze-expansion and DCA enables DSXFormer to achieve an effective balance between spectral emphasis and spatial contextual representation. Furthermore, patch extraction, embedding, and patch merging strategies are employed to facilitate efficient multi-scale feature learning. Extensive experiments conducted on four widely used hyperspectral benchmark datasets, including Salinas (SA), Indian Pines (IP), Pavia University (PU), and Kennedy Space Center (KSC), demonstrate that DSXFormer consistently outperforms state-of-the-art methods, achieving classification accuracies of 99.95%, 98.91%, 99.85%, and 98.52%, respectively.

</details>


### [229] [Enabling Progressive Whole-slide Image Analysis with Multi-scale Pyramidal Network](https://arxiv.org/abs/2602.01951)
*Shuyang Wu,Yifu Qiu,Ines P. Nearchou,Sandrine Prost,Jonathan A Fallowfield,Hakan Bilen,Timothy J Kendall*

Main category: cs.CV

TL;DR: MSPN improves MIL by enabling flexible, efficient multi-scale analysis, outperforming previous methods in clinical tasks.


<details>
  <summary>Details</summary>
Motivation: Previous methods using multi-scale features in clinical applications are inflexible and computationally expensive, lacking retention of feature links across scales.

Method: The Multi-scale Pyramidal Network (MSPN) includes grid-based remapping and the coarse guidance network (CGN) for progressive multi-scale analysis on WSI.

Result: MSPN enhances attention-based MIL frameworks across 4 clinically relevant tasks and 3 types of foundation models.

Conclusion: MSPN consistently improves MIL across various configurations and tasks, proving to be lightweight and easy-to-use.

Abstract: Multiple-instance Learning (MIL) is commonly used to undertake computational pathology (CPath) tasks, and the use of multi-scale patches allows diverse features across scales to be learned. Previous studies using multi-scale features in clinical applications rely on multiple inputs across magnifications with late feature fusion, which does not retain the link between features across scales while the inputs are dependent on arbitrary, manufacturer-defined magnifications, being inflexible and computationally expensive. In this paper, we propose the Multi-scale Pyramidal Network (MSPN), which is plug-and-play over attention-based MIL that introduces progressive multi-scale analysis on WSI. Our MSPN consists of (1) grid-based remapping that uses high magnification features to derive coarse features and (2) the coarse guidance network (CGN) that learns coarse contexts. We benchmark MSPN as an add-on module to 4 attention-based frameworks using 4 clinically relevant tasks across 3 types of foundation model, as well as the pre-trained MIL framework. We show that MSPN consistently improves MIL across the compared configurations and tasks, while being lightweight and easy-to-use.

</details>


### [230] [Beyond Open Vocabulary: Multimodal Prompting for Object Detection in Remote Sensing Images](https://arxiv.org/abs/2602.01954)
*Shuai Yang,Ziyue Huang,Jiaxin Chen,Qingjie Liu,Yunhong Wang*

Main category: cs.CV

TL;DR: RS-MPOD通过多模态提示（视觉+文本）提升遥感开放词汇检测的稳定性，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决遥感场景中仅依赖文本提示导致的类别语义不稳定问题，提出多模态提示方法以增强开放词汇检测的可靠性。

Method: 提出RS-MPOD框架，包含视觉提示编码器（提取基于外观的类别线索）和多模态融合模块（整合视觉与文本信息）。

Result: 实验表明，视觉提示在语义模糊和分布偏移下更可靠，多模态提示在文本语义对齐时仍具竞争力。

Conclusion: RS-MPOD通过结合视觉提示和文本提示的多模态方法，显著提升了开放词汇遥感目标检测的稳定性和灵活性，尤其在语义模糊和分布偏移情况下表现优异。

Abstract: Open-vocabulary object detection in remote sensing commonly relies on text-only prompting to specify target categories, implicitly assuming that inference-time category queries can be reliably grounded through pretraining-induced text-visual alignment. In practice, this assumption often breaks down in remote sensing scenarios due to task- and application-specific category semantics, resulting in unstable category specification under open-vocabulary settings. To address this limitation, we propose RS-MPOD, a multimodal open-vocabulary detection framework that reformulates category specification beyond text-only prompting by incorporating instance-grounded visual prompts, textual prompts, and their multimodal integration. RS-MPOD introduces a visual prompt encoder to extract appearance-based category cues from exemplar instances, enabling text-free category specification, and a multimodal fusion module to integrate visual and textual information when both modalities are available. Extensive experiments on standard, cross-dataset, and fine-grained remote sensing benchmarks show that visual prompting yields more reliable category specification under semantic ambiguity and distribution shifts, while multimodal prompting provides a flexible alternative that remains competitive when textual semantics are well aligned.

</details>


### [231] [Your AI-Generated Image Detector Can Secretly Achieve SOTA Accuracy, If Calibrated](https://arxiv.org/abs/2602.01973)
*Muli Yang,Gabriel James Goenawan,Henan Wang,Huaiyuan Qin,Chenghao Xu,Yanhua Yang,Fen Fang,Ying Sun,Joo-Hwee Lim,Hongyuan Zhu*

Main category: cs.CV

TL;DR: 本文提出一种后校准框架，通过优化对数标量校正来补偿分布偏移，显著提升AI生成图像检测的鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成图像检测器在测试时经常将假图像误分类为真实图像，原因是模型对训练数据中的表面伪影过拟合，导致决策阈值在测试时分布偏移时不对齐。

Method: 提出了一种理论上可靠的后校准框架，通过在小验证集上优化模型的对数标量校正，保持主干网络冻结，以补偿模型输出的分布偏移。

Result: 在具有挑战性的基准测试中，该方法显著提高了鲁棒性，提供了一个轻量级且原理可靠的解决方案。

Conclusion: 本文提出的基于贝叶斯决策理论的后校准框架，通过优化模型的对数标量校正，显著提高了AI生成图像检测的鲁棒性，无需重新训练模型。

Abstract: Despite being trained on balanced datasets, existing AI-generated image detectors often exhibit systematic bias at test time, frequently misclassifying fake images as real. We hypothesize that this behavior stems from distributional shift in fake samples and implicit priors learned during training. Specifically, models tend to overfit to superficial artifacts that do not generalize well across different generation methods, leading to a misaligned decision threshold when faced with test-time distribution shift. To address this, we propose a theoretically grounded post-hoc calibration framework based on Bayesian decision theory. In particular, we introduce a learnable scalar correction to the model's logits, optimized on a small validation set from the target distribution while keeping the backbone frozen. This parametric adjustment compensates for distributional shift in model output, realigning the decision boundary even without requiring ground-truth labels. Experiments on challenging benchmarks show that our approach significantly improves robustness without retraining, offering a lightweight and principled solution for reliable and adaptive AI-generated image detection in the open world. Code is available at https://github.com/muliyangm/AIGI-Det-Calib.

</details>


### [232] [Enhancing Multi-Image Understanding through Delimiter Token Scaling](https://arxiv.org/abs/2602.01984)
*Minyoung Lee,Yeji Park,Dongjun Hwang,Yejin Kim,Seong Joon Oh,Junsuk Choe*

Main category: cs.CV

TL;DR: 通过缩放分隔符标记的隐藏状态，该方法有效减少了跨图像信息泄漏，提升了多图像任务性能，且无需额外成本。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉语言模型在多图像输入时性能下降，主要原因是跨图像信息泄漏，当前的分隔符标记未能有效阻止这一问题。

Method: 提出了一种缩放分隔符标记隐藏状态的方法，以增强模型对图像特定信息的保留能力，同时限制不希望的跨图像交互。

Result: 实验表明，该方法在多图像基准测试（如Mantis、MuirBench、MIRB和QBench2）以及文本任务（如TQABench、MultiNews和WCEP-10）上均取得了性能提升。

Conclusion: 提出的方法通过缩放分隔符标记的隐藏状态，有效减少了跨图像信息泄漏，提升了模型在多图像任务中的表现，且无需额外训练或推理成本。

Abstract: Large Vision-Language Models (LVLMs) achieve strong performance on single-image tasks, but their performance declines when multiple images are provided as input. One major reason is the cross-image information leakage, where the model struggles to distinguish information across different images. Existing LVLMs already employ delimiter tokens to mark the start and end of each image, yet our analysis reveals that these tokens fail to effectively block cross-image information leakage. To enhance their effectiveness, we propose a method that scales the hidden states of delimiter tokens. This enhances the model's ability to preserve image-specific information by reinforcing intra-image interaction and limiting undesired cross-image interactions. Consequently, the model is better able to distinguish between images and reason over them more accurately. Experiments show performance gains on multi-image benchmarks such as Mantis, MuirBench, MIRB, and QBench2. We further evaluate our method on text-only tasks that require clear distinction. The method improves performance on multi-document and multi-table understanding benchmarks, including TQABench, MultiNews, and WCEP-10. Notably, our method requires no additional training or inference cost.

</details>


### [233] [SurfSplat: Conquering Feedforward 2D Gaussian Splatting with Surface Continuity Priors](https://arxiv.org/abs/2602.02000)
*Bing He,Jingnan Gao,Yunuo Chen,Ning Cao,Gang Chen,Zhengxue Cheng,Li Song,Wenjun Zhang*

Main category: cs.CV

TL;DR: SurfSplat利用2DGS基元改进3D重建，通过表面连续性先验和HRRC指标，显著提升稀疏输入下的重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于3D高斯泼溅（3DGS）的方法在稀疏图像重建中难以生成连续表面，且存在颜色偏差和近距离视角下的严重伪影。

Method: 基于2D高斯泼溅（2DGS）基元的前馈框架，结合表面连续性先验和强制alpha混合策略，提出HRRC评估指标。

Result: 在RealEstate10K、DL3DV和ScanNet数据集上，SurfSplat在标准指标和HRRC上均优于现有方法。

Conclusion: SurfSplat通过引入表面连续性先验和强制alpha混合策略，结合新的HRRC评估指标，显著提升了稀疏输入下的高保真3D重建质量，并在多个数据集上验证了其优越性。

Abstract: Reconstructing 3D scenes from sparse images remains a challenging task due to the difficulty of recovering accurate geometry and texture without optimization. Recent approaches leverage generalizable models to generate 3D scenes using 3D Gaussian Splatting (3DGS) primitive. However, they often fail to produce continuous surfaces and instead yield discrete, color-biased point clouds that appear plausible at normal resolution but reveal severe artifacts under close-up views. To address this issue, we present SurfSplat, a feedforward framework based on 2D Gaussian Splatting (2DGS) primitive, which provides stronger anisotropy and higher geometric precision. By incorporating a surface continuity prior and a forced alpha blending strategy, SurfSplat reconstructs coherent geometry together with faithful textures. Furthermore, we introduce High-Resolution Rendering Consistency (HRRC), a new evaluation metric designed to evaluate high-resolution reconstruction quality. Extensive experiments on RealEstate10K, DL3DV, and ScanNet demonstrate that SurfSplat consistently outperforms prior methods on both standard metrics and HRRC, establishing a robust solution for high-fidelity 3D reconstruction from sparse inputs. Project page: https://hebing-sjtu.github.io/SurfSplat-website/

</details>


### [234] [Leveraging Latent Vector Prediction for Localized Control in Image Generation via Diffusion Models](https://arxiv.org/abs/2602.01991)
*Pablo Domingo-Gregorio,Javier Ruiz-Hidalgo*

Main category: cs.CV

TL;DR: 本文提出了一种新方法，通过在扩散模型中引入局部控制机制，显著提升了文本到图像生成中对用户定义区域的精确控制能力。


<details>
  <summary>Details</summary>
Motivation: 现有的文本到图像生成方法在局部控制上存在局限性，通常只能全局应用条件，无法满足用户对特定区域的精确控制需求。

Method: 提出了一种新的训练框架，结合了掩码特征和额外的损失项，利用初始潜在向量预测来增强当前步骤与最终样本在潜在空间中的对应关系。

Result: 实验证明，该方法能够有效合成高质量图像，并在用户定义的局部区域内实现精确控制。

Conclusion: 本文提出了一种新方法，通过在扩散模型中引入局部控制机制，显著提升了文本到图像生成中对用户定义区域的精确控制能力，同时保持其他区域的自主生成效果。

Abstract: Diffusion models emerged as a leading approach in text-to-image generation, producing high-quality images from textual descriptions. However, attempting to achieve detailed control to get a desired image solely through text remains a laborious trial-and-error endeavor. Recent methods have introduced image-level controls alongside with text prompts, using prior images to extract conditional information such as edges, segmentation and depth maps. While effective, these methods apply conditions uniformly across the entire image, limiting localized control. In this paper, we propose a novel methodology to enable precise local control over user-defined regions of an image, while leaving to the diffusion model the task of autonomously generating the remaining areas according to the original prompt. Our approach introduces a new training framework that incorporates masking features and an additional loss term, which leverages the prediction of the initial latent vector at any diffusion step to enhance the correspondence between the current step and the final sample in the latent space. Extensive experiments demonstrate that our method effectively synthesizes high-quality images with controlled local conditions.

</details>


### [235] [ClueTracer: Question-to-Vision Clue Tracing for Training-Free Hallucination Suppression in Multimodal Reasoning](https://arxiv.org/abs/2602.02004)
*Gongli Xi,Kun Wang,Zeming Gao,Huahui Yi,Haolang Lu,Ye Tian,Wendong Wang*

Main category: cs.CV

TL;DR: 论文提出ClueTracer插件，通过追踪关键线索传播路径抑制幻觉，显著提升多模态推理模型性能。


<details>
  <summary>Details</summary>
Motivation: 研究多模态推理模型在视觉问题解决中因推理漂移导致的幻觉问题，即模型过度关注与问题无关的实体，逐渐脱离视觉基础。

Method: 提出了ClueRecall评估指标和ClueTracer插件，通过从问题出发追踪关键线索在推理路径中的传播，定位任务相关区域并抑制对无关区域的关注。

Result: ClueTracer在无需额外训练的情况下，显著提升了所有推理架构的性能（1.21倍增益），在非推理场景中也实现了1.14倍的增益。

Conclusion: ClueTracer作为一种无需额外训练、参数无关且架构无关的插件，显著提升了多模态推理模型的性能，同时在非推理场景中也表现优异。

Abstract: Large multimodal reasoning models solve challenging visual problems via explicit long-chain inference: they gather visual clues from images and decode clues into textual tokens. Yet this capability also increases hallucinations, where the model generates content that is not supported by the input image or the question. To understand this failure mode, we identify \emph{reasoning drift}: during clue gathering, the model over-focuses on question-irrelevant entities, diluting focus on task-relevant cues and gradually decoupling the reasoning trace from visual grounding. As a consequence, many inference-time localization or intervention methods developed for non-reasoning models fail to pinpoint the true clues in reasoning settings. Motivated by these insights, we introduce ClueRecall, a metric for assessing visual clue retrieval, and present ClueTracer, a training-free, parameter-free, and architecture-agnostic plugin for hallucination suppression. ClueTracer starts from the question and traces how key clues propagate along the model's reasoning pathway (question $\rightarrow$ outputs $\rightarrow$ visual tokens), thereby localizing task-relevant patches while suppressing spurious attention to irrelevant regions. Remarkably, \textbf{without any additional training}, ClueTracer improves all \textbf{reasoning} architectures (including \texttt{R1-OneVision}, \texttt{Ocean-R1}, \texttt{MM-Eureka}, \emph{etc}.) by $\mathbf{1.21\times}$ on reasoning benchmarks. When transferred to \textbf{non-reasoning} settings, it yields a $\mathbf{1.14\times}$ gain.

</details>


### [236] [Rethinking Genomic Modeling Through Optical Character Recognition](https://arxiv.org/abs/2602.02014)
*Hongxin Xiang,Pengsen Ma,Yunkang Cao,Di Yu,Haowen Chen,Xinyu Yang,Xiangxiang Zeng*

Main category: cs.CV

TL;DR: OpticalDNA 通过视觉化方法优化基因组建模，显著提升效率与性能，尤其在长序列处理上表现突出。


<details>
  <summary>Details</summary>
Motivation: 传统基于一维序列的基因组建模方法在稀疏和间断的基因组语义上效率低下，浪费计算资源。

Method: OpticalDNA 将 DNA 序列转化为结构化视觉布局，结合视觉 DNA 编码器和文档解码器进行训练，实现高保真压缩。

Result: OpticalDNA 在多个基因组基准测试中表现优异，尤其在长序列（450k 碱基）上以更少的有效 token 和可训练参数（仅 256k）超越基线模型。

Conclusion: OpticalDNA 通过视觉化的方法显著提升了基因组建模的效率与性能，尤其在长序列处理上展现出优越性。

Abstract: Recent genomic foundation models largely adopt large language model architectures that treat DNA as a one-dimensional token sequence. However, exhaustive sequential reading is structurally misaligned with sparse and discontinuous genomic semantics, leading to wasted computation on low-information background and preventing understanding-driven compression for long contexts. Here, we present OpticalDNA, a vision-based framework that reframes genomic modeling as Optical Character Recognition (OCR)-style document understanding. OpticalDNA renders DNA into structured visual layouts and trains an OCR-capable vision--language model with a \emph{visual DNA encoder} and a \emph{document decoder}, where the encoder produces compact, reconstructible visual tokens for high-fidelity compression. Building on this representation, OpticalDNA defines prompt-conditioned objectives over core genomic primitives-reading, region grounding, subsequence retrieval, and masked span completion-thereby learning layout-aware DNA representations that retain fine-grained genomic information under a reduced effective token budget. Across diverse genomic benchmarks, OpticalDNA consistently outperforms recent baselines; on sequences up to 450k bases, it achieves the best overall performance with nearly $20\times$ fewer effective tokens, and surpasses models with up to $985\times$ more activated parameters while tuning only 256k \emph{trainable} parameters.

</details>


### [237] [UniDriveDreamer: A Single-Stage Multimodal World Model for Autonomous Driving](https://arxiv.org/abs/2602.02002)
*Guosheng Zhao,Yaozeng Wang,Xiaofeng Wang,Zheng Zhu,Tingdong Yu,Guan Huang,Yongchen Zai,Ji Jiao,Changliang Xue,Xiaole Wang,Zhen Yang,Futang Zhu,Xingang Wang*

Main category: cs.CV

TL;DR: UniDriveDreamer 是一种单阶段统一多模态世界模型，通过 ULA 和扩散变换器实现多模态生成，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要集中于单模态生成，无法满足多模态需求，因此提出统一多模态模型以直接生成多模态未来观测。

Method: 引入 LiDAR 特定 VAE 和视频 VAE，提出 Unified Latent Anchoring (ULA) 对齐潜在分布，使用扩散变换器联合建模几何对应和时间演化，并通过结构化场景布局信息引导合成。

Result: UniDriveDreamer 在视频和 LiDAR 生成方面优于现有方法，并在下游任务中表现更优。

Conclusion: UniDriveDreamer 提出了一种单阶段统一多模态世界模型，显著优于现有方法，并在下游任务中带来可衡量的改进。

Abstract: World models have demonstrated significant promise for data synthesis in autonomous driving. However, existing methods predominantly concentrate on single-modality generation, typically focusing on either multi-camera video or LiDAR sequence synthesis. In this paper, we propose UniDriveDreamer, a single-stage unified multimodal world model for autonomous driving, which directly generates multimodal future observations without relying on intermediate representations or cascaded modules. Our framework introduces a LiDAR-specific variational autoencoder (VAE) designed to encode input LiDAR sequences, alongside a video VAE for multi-camera images. To ensure cross-modal compatibility and training stability, we propose Unified Latent Anchoring (ULA), which explicitly aligns the latent distributions of the two modalities. The aligned features are fused and processed by a diffusion transformer that jointly models their geometric correspondence and temporal evolution. Additionally, structured scene layout information is projected per modality as a conditioning signal to guide the synthesis. Extensive experiments demonstrate that UniDriveDreamer outperforms previous state-of-the-art methods in both video and LiDAR generation, while also yielding measurable improvements in downstream

</details>


### [238] [One Size, Many Fits: Aligning Diverse Group-Wise Click Preferences in Large-Scale Advertising Image Generation](https://arxiv.org/abs/2602.02033)
*Shuo Lu,Haohan Wang,Wei Feng,Weizhen Wang,Shen Zhang,Yaoyu Li,Ao Ma,Zheng Zhang,Jingjing Lv,Junjie Shen,Ching Law,Bing Zhan,Yuan Xu,Huizai Yao,Yongcan Yu,Chenyang Si,Jian Liang*

Main category: cs.CV

TL;DR: OSMF框架通过动态分组和G-MLLM生成定制广告图像，显著提升各用户群体的点击率，并发布GAIP数据集。


<details>
  <summary>Details</summary>
Motivation: 现有广告图像生成方法忽视用户群体的偏好多样性，导致特定群体效果不佳，限制了目标营销的有效性。

Method: OSMF采用产品感知自适应分组动态组织用户，并利用Group-aware Multimodal Large Language Model (G-MLLM)生成针对各组的广告图像，通过Group-DPO进行偏好对齐。

Result: 实验表明，OSMF在离线和在线环境中均达到最先进性能，并发布了首个大规模公开数据集GAIP。

Conclusion: OSMF框架通过产品感知的自适应分组和偏好条件图像生成，显著提升了广告图像在不同用户群体中的点击率，并在离线和在线环境中均达到最先进性能。

Abstract: Advertising image generation has increasingly focused on online metrics like Click-Through Rate (CTR), yet existing approaches adopt a ``one-size-fits-all" strategy that optimizes for overall CTR while neglecting preference diversity among user groups. This leads to suboptimal performance for specific groups, limiting targeted marketing effectiveness. To bridge this gap, we present \textit{One Size, Many Fits} (OSMF), a unified framework that aligns diverse group-wise click preferences in large-scale advertising image generation. OSMF begins with product-aware adaptive grouping, which dynamically organizes users based on their attributes and product characteristics, representing each group with rich collective preference features. Building on these groups, preference-conditioned image generation employs a Group-aware Multimodal Large Language Model (G-MLLM) to generate tailored images for each group. The G-MLLM is pre-trained to simultaneously comprehend group features and generate advertising images. Subsequently, we fine-tune the G-MLLM using our proposed Group-DPO for group-wise preference alignment, which effectively enhances each group's CTR on the generated images. To further advance this field, we introduce the Grouped Advertising Image Preference Dataset (GAIP), the first large-scale public dataset of group-wise image preferences, including around 600K groups built from 40M users. Extensive experiments demonstrate that our framework achieves the state-of-the-art performance in both offline and online settings. Our code and datasets will be released at https://github.com/JD-GenX/OSMF.

</details>


### [239] [Auto-Comp: An Automated Pipeline for Scalable Compositional Probing of Contrastive Vision-Language Models](https://arxiv.org/abs/2602.02043)
*Cristian Sbrolli,Matteo Matteucci,Toshihiko Yamasaki*

Main category: cs.CV

TL;DR: Auto-Comp揭示VLMs在组合推理上的缺陷，发现视觉语言上下文在空间推理和属性绑定间的权衡。


<details>
  <summary>Details</summary>
Motivation: 现代视觉语言模型在组合推理上存在混淆视觉和语言根源的缺陷，需要细粒度、可控的分析方法。

Method: 引入Auto-Comp，一个全自动合成管道，生成可控的基准测试，通过Minimal和LLM生成的Contextual标题配对图像，进行A/B测试以分离核心绑定能力和视觉语言复杂性。

Result: 评估20种VLMs发现CLIP和SigLIP模型家族在颜色绑定和空间关系上普遍存在组合推理失败，且模型易受低熵干扰物影响。

Conclusion: 现代视觉语言模型（VLMs）在组合推理上存在关键缺陷，Auto-Comp通过自动化合成管道生成可扩展的基准测试，揭示了模型在颜色绑定和空间关系上的普遍失败，并发现视觉语言上下文在辅助空间推理的同时会阻碍局部属性绑定。

Abstract: Modern Vision-Language Models (VLMs) exhibit a critical flaw in compositional reasoning, often confusing "a red cube and a blue sphere" with "a blue cube and a red sphere". Disentangling the visual and linguistic roots of these failures is a fundamental challenge for robust evaluation. To enable fine-grained, controllable analysis, we introduce Auto-Comp, a fully automated and synthetic pipeline for generating scalable benchmarks. Its controllable nature is key to dissecting and isolating different reasoning skills. Auto-Comp generates paired images from Minimal (e.g., "a monitor to the left of a bicycle on a white background") and LLM-generated Contextual captions (e.g., "In a brightly lit photography studio, a monitor is positioned to the left of a bicycle"), allowing a controlled A/B test to disentangle core binding ability from visio-linguistic complexity. Our evaluation of 20 VLMs on novel benchmarks for color binding and spatial relations reveals universal compositional failures in both CLIP and SigLIP model families. Crucially, our novel "Confusion Benchmark" reveals a deeper flaw beyond simple attribute swaps: models are highly susceptible to low-entropy distractors (e.g., repeated objects or colors), demonstrating their compositional failures extend beyond known bag-of-words limitations. we uncover a surprising trade-off: visio-linguistic context, which provides global scene cues, aids spatial reasoning but simultaneously hinders local attribute binding by introducing visual clutter. We release the Auto-Comp pipeline to facilitate future benchmark creation, alongside all our generated benchmarks (https://huggingface.co/AutoComp).

</details>


### [240] [Multi-View Stenosis Classification Leveraging Transformer-Based Multiple-Instance Learning Using Real-World Clinical Data](https://arxiv.org/abs/2602.02067)
*Nikola Cenikj,Özgün Turgut,Alexander Müller,Alexander Steger,Jan Kehrer,Marcus Brugger,Daniel Rueckert,Eimo Martens,Philip Müller*

Main category: cs.CV

TL;DR: SegmentMIL是一种无需视角级标注的多视角学习框架，通过患者级监督实现冠状动脉狭窄的高效分类和定位，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的深度学习模型依赖昂贵的视角级标注，且未能捕捉多视角间的时空动态和依赖关系，这些对临床诊断至关重要。

Method: 提出了SegmentMIL，一个基于Transformer的多视角多实例学习框架，利用患者级监督而非视角级标注，联合预测狭窄存在并定位受影响的解剖区域。

Result: SegmentMIL在内部和外部评估中表现优异，超越了视角级模型和经典MIL基线。

Conclusion: SegmentMIL是一种基于Transformer的多视角多实例学习框架，能够在无需视角级标注的情况下，通过患者级监督实现冠状动脉狭窄的高性能分类和定位，展示了其作为临床可行和可扩展解决方案的潜力。

Abstract: Coronary artery stenosis is a leading cause of cardiovascular disease, diagnosed by analyzing the coronary arteries from multiple angiography views. Although numerous deep-learning models have been proposed for stenosis detection from a single angiography view, their performance heavily relies on expensive view-level annotations, which are often not readily available in hospital systems. Moreover, these models fail to capture the temporal dynamics and dependencies among multiple views, which are crucial for clinical diagnosis. To address this, we propose SegmentMIL, a transformer-based multi-view multiple-instance learning framework for patient-level stenosis classification. Trained on a real-world clinical dataset, using patient-level supervision and without any view-level annotations, SegmentMIL jointly predicts the presence of stenosis and localizes the affected anatomical region, distinguishing between the right and left coronary arteries and their respective segments. SegmentMIL obtains high performance on internal and external evaluations and outperforms both view-level models and classical MIL baselines, underscoring its potential as a clinically viable and scalable solution for coronary stenosis diagnosis. Our code is available at https://github.com/NikolaCenic/mil-stenosis.

</details>


### [241] [Toxicity Assessment in Preclinical Histopathology via Class-Aware Mahalanobis Distance for Known and Novel Anomalies](https://arxiv.org/abs/2602.02124)
*Olga Graf,Dhrupal Patel,Peter Groß,Charlotte Lempp,Matthias Hein,Fabian Heinemann*

Main category: cs.CV

TL;DR: An AI-based anomaly detection framework for histopathology images in rodent livers effectively identifies both known and rare pathologies, improving preclinical drug development efficiency.


<details>
  <summary>Details</summary>
Motivation: Drug-induced toxicity is a major cause of failure in preclinical and early clinical trials, and early detection of adverse effects is crucial to reduce attrition and accelerate safe drug development.

Method: The system uses a pre-trained Vision Transformer (DINOv2) fine-tuned via Low-Rank Adaptation (LoRA) for tissue segmentation, and extracts features for OOD detection using the Mahalanobis distance with class-specific thresholds.

Result: The framework achieves high accuracy in detecting anomalies, with only 0.16% of pathological tissue misclassified as healthy and 0.35% of healthy tissue misclassified as pathological.

Conclusion: This work demonstrates the potential of AI-driven histopathology to support preclinical workflows, reduce late-stage failures, and improve efficiency in drug development.

Abstract: Drug-induced toxicity remains a leading cause of failure in preclinical development and early clinical trials. Detecting adverse effects at an early stage is critical to reduce attrition and accelerate the development of safe medicines. Histopathological evaluation remains the gold standard for toxicity assessment, but it relies heavily on expert pathologists, creating a bottleneck for large-scale screening. To address this challenge, we introduce an AI-based anomaly detection framework for histopathological whole-slide images (WSIs) in rodent livers from toxicology studies. The system identifies healthy tissue and known pathologies (anomalies) for which training data is available. In addition, it can detect rare pathologies without training data as out-of-distribution (OOD) findings. We generate a novel dataset of pixelwise annotations of healthy tissue and known pathologies and use this data to fine-tune a pre-trained Vision Transformer (DINOv2) via Low-Rank Adaptation (LoRA) in order to do tissue segmentation. Finally, we extract features for OOD detection using the Mahalanobis distance. To better account for class-dependent variability in histological data, we propose the use of class-specific thresholds. We optimize the thresholds using the mean of the false negative and false positive rates, resulting in only 0.16\% of pathological tissue classified as healthy and 0.35\% of healthy tissue classified as pathological. Applied to mouse liver WSIs with known toxicological findings, the framework accurately detects anomalies, including rare OOD morphologies. This work demonstrates the potential of AI-driven histopathology to support preclinical workflows, reduce late-stage failures, and improve efficiency in drug development.

</details>


### [242] [UrbanGS: A Scalable and Efficient Architecture for Geometrically Accurate Large-Scene Reconstruction](https://arxiv.org/abs/2602.02089)
*Changbai Li,Haodong Zhu,Hanlin Chen,Xiuping Liang,Tongfei Chen,Shuwei Shao,Linlin Yang,Huobin Tan,Baochang Zhang*

Main category: cs.CV

TL;DR: UrbanGS通过深度一致D-Normal正则化和自适应高斯剪枝，解决了大规模城市场景重建的几何与效率问题，实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 3D高斯泼溅（3DGS）在有限场景中能实现高质量实时渲染，但在大规模城市场景中面临几何一致性、内存效率和计算可扩展性挑战。

Method: 提出了深度一致D-Normal正则化模块，结合外部深度监督和自适应置信权重机制，以及空间自适应高斯剪枝策略（SAGP）和统一分区视图分配方案。

Result: 在多个城市数据集上的实验表明，UrbanGS在渲染质量、几何精度和内存效率上表现优异。

Conclusion: UrbanGS通过深度一致D-Normal正则化和空间自适应高斯剪枝策略，有效解决了大规模城市场景重建中的几何一致性、内存效率和计算可扩展性问题，实现了高质量的渲染和几何精度。

Abstract: While 3D Gaussian Splatting (3DGS) enables high-quality, real-time rendering for bounded scenes, its extension to large-scale urban environments gives rise to critical challenges in terms of geometric consistency, memory efficiency, and computational scalability. To address these issues, we present UrbanGS, a scalable reconstruction framework that effectively tackles these challenges for city-scale applications. First, we propose a Depth-Consistent D-Normal Regularization module. Unlike existing approaches that rely solely on monocular normal estimators, which can effectively update rotation parameters yet struggle to update position parameters, our method integrates D-Normal constraints with external depth supervision. This allows for comprehensive updates of all geometric parameters. By further incorporating an adaptive confidence weighting mechanism based on gradient consistency and inverse depth deviation, our approach significantly enhances multi-view depth alignment and geometric coherence, which effectively resolves the issue of geometric accuracy in complex large-scale scenes. To improve scalability, we introduce a Spatially Adaptive Gaussian Pruning (SAGP) strategy, which dynamically adjusts Gaussian density based on local geometric complexity and visibility to reduce redundancy. Additionally, a unified partitioning and view assignment scheme is designed to eliminate boundary artifacts and optimize computational load. Extensive experiments on multiple urban datasets demonstrate that UrbanGS achieves superior performance in rendering quality, geometric accuracy, and memory efficiency, providing a systematic solution for high-fidelity large-scale scene reconstruction.

</details>


### [243] [Vision-DeepResearch Benchmark: Rethinking Visual and Textual Search for Multimodal Large Language Models](https://arxiv.org/abs/2602.02185)
*Yu Zeng,Wenxuan Huang,Zhen Fang,Shuang Chen,Yufan Shen,Yishuo Cai,Xiaoman Wang,Zhenfei Yin,Lin Chen,Zehui Chen,Shiting Huang,Yiming Zhao,Yao Hu,Philip Torr,Wanli Ouyang,Shaosheng Cao*

Main category: cs.CV

TL;DR: 本文构建了VDR-Bench基准，解决了现有视觉搜索评估的局限性，并提出多轮裁剪搜索工作流，提升了多模态大语言模型的视觉检索性能。


<details>
  <summary>Details</summary>
Motivation: 现有基准在视觉搜索能力评估上存在两大局限：非视觉搜索中心化和过于理想化的评估场景，难以真实反映多模态大语言模型的视觉检索能力。

Method: 通过多阶段精心策划和专家严格审查构建了包含2000个VQA实例的VDR-Bench基准，并提出了一种多轮裁剪搜索工作流。

Result: VDR-Bench基准和多轮裁剪搜索工作流显著提升了模型在真实视觉检索场景中的表现。

Conclusion: 本文提出了VDR-Bench基准和一种多轮裁剪搜索工作流，有效提升了多模态大语言模型在视觉检索任务中的性能，为未来多模态深度研究系统的设计提供了实用指导。

Abstract: Multimodal Large Language Models (MLLMs) have advanced VQA and now support Vision-DeepResearch systems that use search engines for complex visual-textual fact-finding. However, evaluating these visual and textual search abilities is still difficult, and existing benchmarks have two major limitations. First, existing benchmarks are not visual search-centric: answers that should require visual search are often leaked through cross-textual cues in the text questions or can be inferred from the prior world knowledge in current MLLMs. Second, overly idealized evaluation scenario: On the image-search side, the required information can often be obtained via near-exact matching against the full image, while the text-search side is overly direct and insufficiently challenging. To address these issues, we construct the Vision-DeepResearch benchmark (VDR-Bench) comprising 2,000 VQA instances. All questions are created via a careful, multi-stage curation pipeline and rigorous expert review, designed to assess the behavior of Vision-DeepResearch systems under realistic real-world conditions. Moreover, to address the insufficient visual retrieval capabilities of current MLLMs, we propose a simple multi-round cropped-search workflow. This strategy is shown to effectively improve model performance in realistic visual retrieval scenarios. Overall, our results provide practical guidance for the design of future multimodal deep-research systems. The code will be released in https://github.com/Osilly/Vision-DeepResearch.

</details>


### [244] [FSVideo: Fast Speed Video Diffusion Model in a Highly-Compressed Latent Space](https://arxiv.org/abs/2602.02092)
*FSVideo Team,Qingyu Chen,Zhiyuan Fang,Haibin Huang,Xinwei Huang,Tong Jin,Minxuan Lin,Bo Liu,Celong Liu,Chongyang Ma,Xing Mei,Xiaohui Shen,Yaojie Shen,Fuwen Tan,Angtian Wang,Xiao Yang,Yiding Yang,Jiamin Yuan,Lingxi Zhang,Yuxin Zhang*

Main category: cs.CV

TL;DR: FSVideo是一个基于扩散变压器的快速图像到视频框架，通过压缩编码、改进架构和多分辨率策略，实现了高性能且速度提升。


<details>
  <summary>Details</summary>
Motivation: 旨在开发一个快速且高性能的图像到视频（I2V）扩散框架，以解决现有开源模型速度不足的问题。

Method: 1. 使用高度压缩的潜在空间（64×64×4空间-时间下采样比）的视频自动编码器；2. 采用带有层内存设计的扩散变压器（DIT）架构；3. 通过多步DIT上采样器实现多分辨率生成。

Result: 最终模型包含14B DIT基础模型和14B DIT上采样器，性能与流行开源模型相当，但速度快一个数量级。

Conclusion: FSVideo框架通过高效的视频自动编码器、改进的扩散变压器架构和多分辨率生成策略，实现了高性能且快速的图像到视频转换。

Abstract: We introduce FSVideo, a fast speed transformer-based image-to-video (I2V) diffusion framework. We build our framework on the following key components: 1.) a new video autoencoder with highly-compressed latent space ($64\times64\times4$ spatial-temporal downsampling ratio), achieving competitive reconstruction quality; 2.) a diffusion transformer (DIT) architecture with a new layer memory design to enhance inter-layer information flow and context reuse within DIT, and 3.) a multi-resolution generation strategy via a few-step DIT upsampler to increase video fidelity. Our final model, which contains a 14B DIT base model and a 14B DIT upsampler, achieves competitive performance against other popular open-source models, while being an order of magnitude faster. We discuss our model design as well as training strategies in this report.

</details>


### [245] [Teacher-Guided Student Self-Knowledge Distillation Using Diffusion Model](https://arxiv.org/abs/2602.02107)
*Yu Wang,Chuanguang Yang,Zhulin An,Weilun Feng,Jiarui Zhao,Chengqing Yu,Libo Huang,Boyu Diao,Yongjun Xu*

Main category: cs.CV

TL;DR: DSKD通过扩散模型和LSH引导的特征蒸馏，有效消除教师与学生特征分布差异，提升知识蒸馏效果。


<details>
  <summary>Details</summary>
Motivation: 解决现有知识蒸馏方法中因教师和学生特征分布差异导致学生模型学习不兼容信息的问题。

Method: 提出了一种教师引导的学生扩散自知识蒸馏方法（DSKD），利用教师分类器通过轻量级扩散模型指导学生特征的去噪采样过程，并采用局部敏感哈希（LSH）引导的特征蒸馏方法。

Result: 在视觉识别任务上的实验表明，DSKD在各种模型和数据集上显著优于现有的知识蒸馏方法。

Conclusion: DSKD方法通过消除教师和学生模型之间的特征分布差异，显著提升了知识蒸馏的性能，并在多个模型和数据集上优于现有方法。

Abstract: Existing Knowledge Distillation (KD) methods often align feature information between teacher and student by exploring meaningful feature processing and loss functions. However, due to the difference in feature distributions between the teacher and student, the student model may learn incompatible information from the teacher. To address this problem, we propose teacher-guided student Diffusion Self-KD, dubbed as DSKD. Instead of the direct teacher-student alignment, we leverage the teacher classifier to guide the sampling process of denoising student features through a light-weight diffusion model. We then propose a novel locality-sensitive hashing (LSH)-guided feature distillation method between the original and denoised student features. The denoised student features encapsulate teacher knowledge and could be regarded as a teacher role. In this way, our DSKD method could eliminate discrepancies in mapping manners and feature distributions between the teacher and student, while learning meaningful knowledge from the teacher. Experiments on visual recognition tasks demonstrate that DSKD significantly outperforms existing KD methods across various models and datasets. Our code is attached in supplementary material.

</details>


### [246] [Enhancing Diffusion-Based Quantitatively Controllable Image Generation via Matrix-Form EDM and Adaptive Vicinal Training](https://arxiv.org/abs/2602.02114)
*Xin Ding,Yun Chen,Sen Zhang,Kao Zhang,Nenglun Chen,Peibei Cao,Yongwei Wang,Fei Wu*

Main category: cs.CV

TL;DR: iCCDM通过整合EDM框架和自适应训练策略，显著提升了图像生成质量和效率，超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: CCDM虽然在某些数据集上表现优于先前方法，但仍存在依赖过时扩散框架和采样效率低的问题，因此提出了改进的iCCDM框架。

Method: iCCDM引入了新颖的矩阵形式EDM公式和自适应邻域训练策略，改进了原有的CCDM框架。

Result: 在四个基准数据集上的实验表明，iCCDM在生成质量和采样效率上均优于现有方法，包括Stable Diffusion 3等大型模型。

Conclusion: iCCDM通过整合先进的EDM框架和自适应邻域训练策略，显著提升了生成质量和采样效率，超越了现有方法，包括大规模文本到图像扩散模型。

Abstract: Continuous Conditional Diffusion Model (CCDM) is a diffusion-based framework designed to generate high-quality images conditioned on continuous regression labels. Although CCDM has demonstrated clear advantages over prior approaches across a range of datasets, it still exhibits notable limitations and has recently been surpassed by a GAN-based method, namely CcGAN-AVAR. These limitations mainly arise from its reliance on an outdated diffusion framework and its low sampling efficiency due to long sampling trajectories. To address these issues, we propose an improved CCDM framework, termed iCCDM, which incorporates the more advanced \textit{Elucidated Diffusion Model} (EDM) framework with substantial modifications to improve both generation quality and sampling efficiency. Specifically, iCCDM introduces a novel matrix-form EDM formulation together with an adaptive vicinal training strategy. Extensive experiments on four benchmark datasets, spanning image resolutions from $64\times64$ to $256\times256$, demonstrate that iCCDM consistently outperforms existing methods, including state-of-the-art large-scale text-to-image diffusion models (e.g., Stable Diffusion 3, FLUX.1, and Qwen-Image), achieving higher generation quality while significantly reducing sampling cost.

</details>


### [247] [MLV-Edit: Towards Consistent and Highly Efficient Editing for Minute-Level Videos](https://arxiv.org/abs/2602.02123)
*Yangyi Cao,Yuanhang Li,Lan Chen,Qi Mao*

Main category: cs.CV

TL;DR: MLV-Edit是一个无需训练、基于流程的长视频编辑框架，通过分段处理和核心模块设计，有效解决了长视频编辑中的关键挑战。


<details>
  <summary>Details</summary>
Motivation: 现有技术擅长短视频处理，但在长视频编辑中面临计算负担重和全局时间一致性难以维持的挑战。

Method: MLV-Edit采用分而治之的策略进行分段编辑，包含两个核心模块：Velocity Blend用于纠正段边界处的运动不一致性，Attention Sink用于抑制累积结构漂移。

Result: 大量实验表明，MLV-Edit在时间稳定性和语义保真度方面均优于现有最先进方法。

Conclusion: MLV-Edit通过其独特的流程框架和模块设计，成功解决了长视频编辑中的计算负担和全局时间一致性问题，显著提升了编辑效果的质量和稳定性。

Abstract: We propose MLV-Edit, a training-free, flow-based framework that address the unique challenges of minute-level video editing. While existing techniques excel in short-form video manipulation, scaling them to long-duration videos remains challenging due to prohibitive computational overhead and the difficulty of maintaining global temporal consistency across thousands of frames. To address this, MLV-Edit employs a divide-and-conquer strategy for segment-wise editing, facilitated by two core modules: Velocity Blend rectifies motion inconsistencies at segment boundaries by aligning the flow fields of adjacent chunks, eliminating flickering and boundary artifacts commonly observed in fragmented video processing; and Attention Sink anchors local segment features to global reference frames, effectively suppressing cumulative structural drift. Extensive quantitative and qualitative experiments demonstrate that MLV-Edit consistently outperforms state-of-the-art methods in terms of temporal stability and semantic fidelity.

</details>


### [248] [VQ-Style: Disentangling Style and Content in Motion with Residual Quantized Representations](https://arxiv.org/abs/2602.02334)
*Fatemeh Zargarbashi,Dhruv Agrawal,Jakob Buhmann,Martin Guay,Stelian Coros,Robert W. Sumner*

Main category: cs.CV

TL;DR: 该论文提出了一种基于RVQ-VAEs的新方法，通过解耦风格与内容实现无需微调的运动风格迁移，并在多种应用中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 人体运动数据既包含语义内容又包含细微风格特征，现有方法难以有效建模和分离这两者。

Method: 采用Residual Vector Quantized Variational Autoencoders（RVQ-VAEs）学习运动的从粗到细表示，并结合对比学习和信息泄漏损失来增强风格与内容的解耦。

Result: 提出的框架在风格迁移、风格去除和运动混合等多种推理应用中表现出强大的通用性。

Conclusion: 该论文提出的方法通过RVQ-VAEs和对比学习等技术，成功实现了人体运动数据中风格与内容的有效解耦，并通过Quantized Code Swapping技术实现了无需微调的风格迁移。

Abstract: Human motion data is inherently rich and complex, containing both semantic content and subtle stylistic features that are challenging to model. We propose a novel method for effective disentanglement of the style and content in human motion data to facilitate style transfer. Our approach is guided by the insight that content corresponds to coarse motion attributes while style captures the finer, expressive details. To model this hierarchy, we employ Residual Vector Quantized Variational Autoencoders (RVQ-VAEs) to learn a coarse-to-fine representation of motion. We further enhance the disentanglement by integrating contrastive learning and a novel information leakage loss with codebook learning to organize the content and the style across different codebooks. We harness this disentangled representation using our simple and effective inference-time technique Quantized Code Swapping, which enables motion style transfer without requiring any fine-tuning for unseen styles. Our framework demonstrates strong versatility across multiple inference applications, including style transfer, style removal, and motion blending.

</details>


### [249] [Eliminating Registration Bias in Synthetic CT Generation: A Physics-Based Simulation Framework](https://arxiv.org/abs/2602.02130)
*Lukas Zimmermann,Michael Rauter,Maximilian Schmid,Dietmar Georg,Barbara Knäusl*

Main category: cs.CV

TL;DR: 通过物理模拟生成几何对齐的CBCT训练对，避免配准偏差，临床评估显示几何保真度比强度一致性更重要。


<details>
  <summary>Details</summary>
Motivation: 由于单独获取的扫描之间的完美配准难以实现，配准偏差会影响训练模型并破坏标准评估指标，导致基准性能可能仅反映配准伪影的复制而非解剖保真度。

Method: 提出了基于物理的CBCT模拟方法，以提供几何对齐的训练对，并结合使用几何对齐指标进行评估，而非有偏差的真实数据。

Result: 在两个独立的骨盆数据集上，基于合成数据训练的模型实现了更好的几何对齐（归一化互信息：0.31 vs 0.22），尽管传统强度分数较低。归一化互信息在不同配准方法中一致预测观察者偏好（rho = 0.31, p < 0.001）。

Conclusion: 临床观察者更倾向于基于合成数据训练的模型输出（87%的案例），这表明几何保真度而非与有偏差的真实数据的强度一致性更符合临床需求。

Abstract: Supervised synthetic CT generation from CBCT requires registered training pairs, yet perfect registration between separately acquired scans remains unattainable. This registration bias propagates into trained models and corrupts standard evaluation metrics. This may suggest that superior benchmark performance indicates better reproduction of registration artifacts rather than anatomical fidelity. We propose physics-based CBCT simulation to provide geometrically aligned training pairs by construction, combined with evaluation using geometric alignment metrics against input CBCT rather than biased ground truth. On two independent pelvic datasets, models trained on synthetic data achieved superior geometric alignment (Normalized Mutual Information: 0.31 vs 0.22) despite lower conventional intensity scores. Intensity metrics showed inverted correlations with clinical assessment for deformably registered data, while Normalized Mutual Information consistently predicted observer preference across registration methodologies (rho = 0.31, p < 0.001). Clinical observers preferred synthetic-trained outputs in 87% of cases, demonstrating that geometric fidelity, not intensity agreement with biased ground truth, aligns with clinical requirements.

</details>


### [250] [Deep learning enables urban change profiling through alignment of historical maps](https://arxiv.org/abs/2602.02154)
*Sidi Wu,Yizi Chen,Maurizio Gribaudi,Konrad Schindler,Clément Mallet,Julien Perret,Lorenz Hurni*

Main category: cs.CV

TL;DR: 提出自动化深度学习框架，从历史地图中分析细粒度城市变化，应用于巴黎数据，展示其模块化设计的适应性。


<details>
  <summary>Details</summary>
Motivation: 历史地图为长期城市转型提供了独特记录，但由于空间错位、制图变化和文档质量退化，提取一致且细粒度的变化信息具有挑战性。

Method: 提出了一种基于深度学习的全自动化框架，集成了密集地图对齐、多时相目标检测和变化分析，用于从大量历史地图中提取细粒度的城市变化信息。

Result: 实验证明了所提出的对齐和目标检测方法的稳健性能，应用于巴黎1868年至1937年的数据，揭示了城市转型的空间和时间异质性。

Conclusion: 该框架通过模块化设计支持适应多样化的制图环境和下游应用，展示了其在社会科学和人文学科研究中的相关性。

Abstract: Prior to modern Earth observation technologies, historical maps provide a unique record of long-term urban transformation and offer a lens on the evolving identity of cities. However, extracting consistent and fine-grained change information from historical map series remains challenging due to spatial misalignment, cartographic variation, and degrading document quality, limiting most analyses to small-scale or qualitative approaches. We propose a fully automated, deep learning-based framework for fine-grained urban change analysis from large collections of historical maps, built on a modular design that integrates dense map alignment, multi-temporal object detection, and change profiling. This framework shifts the analysis of historical maps from ad hoc visual comparison toward systematic, quantitative characterization of urban change. Experiments demonstrate the robust performance of the proposed alignment and object detection methods. Applied to Paris between 1868 and 1937, the framework reveals the spatial and temporal heterogeneity in urban transformation, highlighting its relevance for research in the social sciences and humanities. The modular design of our framework further supports adaptation to diverse cartographic contexts and downstream applications.

</details>


### [251] [LoopViT: Scaling Visual ARC with Looped Transformers](https://arxiv.org/abs/2602.02156)
*Wen-Jie Shu,Xuerui Qiu,Rui-Jie Zhu,Harold Haodong Chen,Yexin Liu,Harry Yang*

Main category: cs.CV

TL;DR: Loop-ViT通过递归架构和动态退出机制，在视觉推理任务中实现了高效且超越更大模型的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的feed-forward架构在捕捉人类归纳的迭代算法性质方面存在不足，因此需要一种能够解耦推理深度与模型容量的新方法。

Method: 提出了一种称为Loop-ViT的递归架构，通过权重绑定的Hybrid Block（结合局部卷积和全局注意力）形成潜在的思维链，并引入基于预测熵的无参数动态退出机制。

Result: 在ARC-AGI-1基准测试中，18M参数的Loop-ViT模型以65.8%的准确率超越了73M参数的集成模型。

Conclusion: Loop-ViT的递归架构通过权重绑定的循环机制，成功解耦了推理深度与模型容量，证明了自适应迭代计算在视觉推理中的高效性。

Abstract: Recent advances in visual reasoning have leveraged vision transformers to tackle the ARC-AGI benchmark. However, we argue that the feed-forward architecture, where computational depth is strictly bound to parameter size, falls short of capturing the iterative, algorithmic nature of human induction. In this work, we propose a recursive architecture called Loop-ViT, which decouples reasoning depth from model capacity through weight-tied recurrence. Loop-ViT iterates a weight-tied Hybrid Block, combining local convolutions and global attention, to form a latent chain of thought. Crucially, we introduce a parameter-free Dynamic Exit mechanism based on predictive entropy: the model halts inference when its internal state ``crystallizes" into a low-uncertainty attractor. Empirical results on the ARC-AGI-1 benchmark validate this perspective: our 18M model achieves 65.8% accuracy, outperforming massive 73M-parameter ensembles. These findings demonstrate that adaptive iterative computation offers a far more efficient scaling axis for visual reasoning than simply increasing network width. The code is available at https://github.com/WenjieShu/LoopViT.

</details>


### [252] [Reg4Pru: Regularisation Through Random Token Routing for Token Pruning](https://arxiv.org/abs/2602.02163)
*Julian Wyatt,Ronald Clark,Irina Voiculescu*

Main category: cs.CV

TL;DR: Reg4Pru是一种正则化技术，有效缓解token修剪对分割任务的影响，显著提升精度和速度。


<details>
  <summary>Details</summary>
Motivation: Transformer在视觉模型中广泛应用，但计算复杂度随token数量呈二次方增长。现有token修剪方法虽提升计算效率，但会导致深层性能下降。

Method: 提出了一种名为Reg4Pru的训练正则化技术，用于缓解token修剪对分割任务性能的影响。

Result: 在FIVES血管分割数据集上，Reg4Pru相比未使用路由的模型，平均精度提升46%，且实现29%的相对加速。

Conclusion: Reg4Pru是一种有效的正则化技术，能够显著减少token修剪带来的性能损失，提升分割任务的精度和计算效率。

Abstract: Transformers are widely adopted in modern vision models due to their strong ability to scale with dataset size and generalisability. However, this comes with a major drawback: computation scales quadratically to the total number of tokens. Numerous methods have been proposed to mitigate this. For example, we consider token pruning with reactivating tokens from preserved representations, but the increased computational efficiency of this method results in decreased stability from the preserved representations, leading to poorer dense prediction performance at deeper layers. In this work, we introduce Reg4Pru, a training regularisation technique that mitigates token-pruning performance loss for segmentation. We compare our models on the FIVES blood vessel segmentation dataset and find that Reg4Pru improves average precision by an absolute 46% compared to the same model trained without routing. This increase is observed using a configuration that achieves a 29% relative speedup in wall-clock time compared to the non-pruned baseline. These findings indicate that Reg4Pru is a valuable regulariser for token reduction strategies.

</details>


### [253] [Infinite-World: Scaling Interactive World Models to 1000-Frame Horizons via Pose-Free Hierarchical Memory](https://arxiv.org/abs/2602.02393)
*Ruiqi Wu,Xuanhua He,Meng Cheng,Tianyu Yang,Yong Zhang,Zhuoliang Kang,Xunliang Cai,Xiaoming Wei,Chunle Guo,Chongyi Li,Ming-Ming Cheng*

Main category: cs.CV

TL;DR: Infinite-World通过新型记忆压缩器和动作标签模块，在真实环境中实现长序列连贯视觉记忆，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有世界模型在合成数据上表现良好，但在真实世界视频中因噪声姿态估计和视角重访稀缺而表现不佳，因此需要一种新的训练范式。

Method: 采用Hierarchical Pose-free Memory Compressor（HPMC）递归压缩历史潜在表示，并结合Uncertainty-aware Action Labeling模块离散化连续动作，最后通过Revisit-Dense Finetuning策略激活长距离闭环能力。

Result: 实验证明Infinite-World在视觉质量、动作可控性和空间一致性上表现优异。

Conclusion: Infinite-World通过Hierarchical Pose-free Memory Compressor和Uncertainty-aware Action Labeling模块，结合Revisit-Dense Finetuning策略，在复杂真实环境中实现了超过1000帧的连贯视觉记忆，显著提升了视觉质量、动作可控性和空间一致性。

Abstract: We propose Infinite-World, a robust interactive world model capable of maintaining coherent visual memory over 1000+ frames in complex real-world environments. While existing world models can be efficiently optimized on synthetic data with perfect ground-truth, they lack an effective training paradigm for real-world videos due to noisy pose estimations and the scarcity of viewpoint revisits. To bridge this gap, we first introduce a Hierarchical Pose-free Memory Compressor (HPMC) that recursively distills historical latents into a fixed-budget representation. By jointly optimizing the compressor with the generative backbone, HPMC enables the model to autonomously anchor generations in the distant past with bounded computational cost, eliminating the need for explicit geometric priors. Second, we propose an Uncertainty-aware Action Labeling module that discretizes continuous motion into a tri-state logic. This strategy maximizes the utilization of raw video data while shielding the deterministic action space from being corrupted by noisy trajectories, ensuring robust action-response learning. Furthermore, guided by insights from a pilot toy study, we employ a Revisit-Dense Finetuning Strategy using a compact, 30-minute dataset to efficiently activate the model's long-range loop-closure capabilities. Extensive experiments, including objective metrics and user studies, demonstrate that Infinite-World achieves superior performance in visual quality, action controllability, and spatial consistency.

</details>


### [254] [Lung Nodule Image Synthesis Driven by Two-Stage Generative Adversarial Networks](https://arxiv.org/abs/2602.02171)
*Lu Cao,Xiquan He,Junying Zeng,Chaoyun Mai,Min Luo*

Main category: cs.CV

TL;DR: TSGAN通过两阶段生成对抗网络增强肺结节CT图像的多样性和可控性，显著提升检测模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法生成的图像多样性和可控性不足，导致纹理单调和解剖结构扭曲，限制了检测模型的性能和泛化能力。

Method: 提出了一种两阶段生成对抗网络（TSGAN）：第一阶段使用StyleGAN生成语义分割掩码图像以控制解剖结构；第二阶段采用DL-Pix2Pix模型将掩码图转换为CT图像，结合局部重要性注意力和动态权重多头窗口注意力增强纹理建模。

Result: 在LUNA16数据集上，准确率提升4.6%，mAP提升4%。

Conclusion: TSGAN通过解耦肺结节的形态结构和纹理特征，显著提升了合成数据的多样性和空间可控性，进而提高了检测模型的性能。

Abstract: The limited sample size and insufficient diversity of lung nodule CT datasets severely restrict the performance and generalization ability of detection models. Existing methods generate images with insufficient diversity and controllability, suffering from issues such as monotonous texture features and distorted anatomical structures. Therefore, we propose a two-stage generative adversarial network (TSGAN) to enhance the diversity and spatial controllability of synthetic data by decoupling the morphological structure and texture features of lung nodules. In the first stage, StyleGAN is used to generate semantic segmentation mask images, encoding lung nodules and tissue backgrounds to control the anatomical structure of lung nodule images; The second stage uses the DL-Pix2Pix model to translate the mask map into CT images, employing local importance attention to capture local features, while utilizing dynamic weight multi-head window attention to enhance the modeling capability of lung nodule texture and background. Compared to the original dataset, the accuracy improved by 4.6% and mAP by 4% on the LUNA16 dataset. Experimental results demonstrate that TSGAN can enhance the quality of synthetic images and the performance of detection models.

</details>


### [255] [CIEC: Coupling Implicit and Explicit Cues for Multimodal Weakly Supervised Manipulation Localization](https://arxiv.org/abs/2602.02175)
*Xinquan Yu,Wei Lu,Xiangyang Luo*

Main category: cs.CV

TL;DR: CIEC框架仅用粗粒度标注实现多模态篡改定位，性能媲美全监督方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖细粒度标注（如像素/词级），成本高且耗时。本文旨在仅用粗粒度标注（图像/句子级）实现高效的多模态篡改定位。

Method: 提出CIEC框架，包含图像和文本两个弱监督定位分支：图像分支采用TRPS模块结合视觉与文本线索锁定可疑区域；文本分支采用VCTG模块利用视觉偏差辅助定位关键词语。

Result: 大量实验证明CIEC的有效性，多项指标接近全监督方法。

Conclusion: CIEC框架通过耦合隐式和显式线索，仅利用粗粒度标注实现了多模态弱监督的篡改定位，其性能可与全监督方法媲美。

Abstract: To mitigate the threat of misinformation, multimodal manipulation localization has garnered growing attention. Consider that current methods rely on costly and time-consuming fine-grained annotations, such as patch/token-level annotations. This paper proposes a novel framework named Coupling Implicit and Explicit Cues (CIEC), which aims to achieve multimodal weakly-supervised manipulation localization for image-text pairs utilizing only coarse-grained image/sentence-level annotations. It comprises two branches, image-based and text-based weakly-supervised localization. For the former, we devise the Textual-guidance Refine Patch Selection (TRPS) module. It integrates forgery cues from both visual and textual perspectives to lock onto suspicious regions aided by spatial priors. Followed by the background silencing and spatial contrast constraints to suppress interference from irrelevant areas. For the latter, we devise the Visual-deviation Calibrated Token Grounding (VCTG) module. It focuses on meaningful content words and leverages relative visual bias to assist token localization. Followed by the asymmetric sparse and semantic consistency constraints to mitigate label noise and ensure reliability. Extensive experiments demonstrate the effectiveness of our CIEC, yielding results comparable to fully supervised methods on several evaluation metrics.

</details>


### [256] [ReasonEdit: Editing Vision-Language Models using Human Reasoning](https://arxiv.org/abs/2602.02408)
*Jiaxing Qiu,Kaihua Hou,Roxana Daneshjou,Ahmed Alaa,Thomas Hartvigsen*

Main category: cs.CV

TL;DR: ReasonEdit是首个允许用户在编辑过程中解释推理的视觉语言模型编辑器，通过存储和检索人类推理，显著提升了编辑泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型编辑器未能解决需要大量推理的任务，这些任务通常需要人类和模型对图像进行推理。因此，提出了ReasonEdit，这是第一个允许用户在编辑过程中解释其推理的VLM编辑器。

Method: ReasonEdit采用了一种新颖的拓扑平衡多模态嵌入方法，该方法受到网络科学的启发，能够持续存储人类推理并在推理时仅检索相关事实。

Result: 在四个VLMs和多个基于推理的视觉问答数据集上，ReasonEdit实现了最先进的编辑性能。

Conclusion: ReasonEdit通过利用人类推理进行模型编辑，显著提高了编辑的泛化能力，并在多个视觉问答数据集上实现了最先进的编辑性能。

Abstract: Model editing aims to correct errors in large, pretrained models without altering unrelated behaviors. While some recent works have edited vision-language models (VLMs), no existing editors tackle reasoning-heavy tasks, which typically require humans and models to reason about images.We therefore propose ReasonEdit, the first VLM editor to let users explain their reasoning during editing, introducing a new, practical model editing setup. ReasonEdit continuously stores human reasoning in a codebook, and retrieves only relevant facts during inference using a novel topology-balanced multimodal embedding method inspired by network science. Across four VLMs on multiple rationale-based visual question answering datasets, ReasonEdit achieves state-of-the-art editing performance, ultimately showing that using human reasoning during editing greatly improves edit generalization.

</details>


### [257] [UniReason 1.0: A Unified Reasoning Framework for World Knowledge Aligned Image Generation and Editing](https://arxiv.org/abs/2602.02437)
*Dianyi Wang,Chaofan Ma,Feng Han,Size Wu,Wei Song,Yibin Wang,Zhixiong Zhang,Tianhang Wang,Siyuan Wang,Zhongyu Wei,Jiaqi Wang*

Main category: cs.CV

TL;DR: UniReason通过双推理范式统一生成与编辑任务，结合知识增强规划和视觉自反思，在推理任务中表现卓越。


<details>
  <summary>Details</summary>
Motivation: 解决统一多模态模型在复杂合成任务中推理不足的问题，将文本到图像生成和图像编辑视为相互关联的推理步骤。

Method: 提出UniReason框架，采用世界知识增强的规划进行生成，并利用编辑能力进行细粒度视觉优化，通过自反思纠正视觉错误。构建大规模推理中心数据集（约30万样本）支持框架。

Result: 在WISE、KrisBench和UniREditBench等推理密集型基准测试中表现优异，同时保持通用合成能力。

Conclusion: UniReason通过双推理范式统一了文本到图像生成和图像编辑任务，在推理密集型基准测试中表现出色，同时保持卓越的通用合成能力。

Abstract: Unified multimodal models often struggle with complex synthesis tasks that demand deep reasoning, and typically treat text-to-image generation and image editing as isolated capabilities rather than interconnected reasoning steps. To address this, we propose UniReason, a unified framework that harmonizes these two tasks through a dual reasoning paradigm. We formulate generation as world knowledge-enhanced planning to inject implicit constraints, and leverage editing capabilities for fine-grained visual refinement to further correct visual errors via self-reflection. This approach unifies generation and editing within a shared representation, mirroring the human cognitive process of planning followed by refinement. We support this framework by systematically constructing a large-scale reasoning-centric dataset (~300k samples) covering five major knowledge domains (e.g., cultural commonsense, physics, etc.) for planning, alongside an agent-generated corpus for visual self-correction. Extensive experiments demonstrate that UniReason achieves advanced performance on reasoning-intensive benchmarks such as WISE, KrisBench and UniREditBench, while maintaining superior general synthesis capabilities.

</details>


### [258] [Learning Topology-Aware Implicit Field for Unified Pulmonary Tree Modeling with Incomplete Topological Supervision](https://arxiv.org/abs/2602.02186)
*Ziqiao Weng,Jiancheng Yang,Kangxian Xie,Bo Zhou,Weidong Cai*

Main category: cs.CV

TL;DR: TopoField 是一种高效的隐式建模框架，用于修复肺树的拓扑不完整性问题，支持多任务推理，适用于大规模临床应用。


<details>
  <summary>Details</summary>
Motivation: 肺树在CT图像中提取时常存在拓扑不完整性问题，如缺失或断开的分支，这严重影响下游解剖分析的准确性，并限制了现有肺树建模管道的适用性。

Method: TopoField 是一种拓扑感知的隐式建模框架，通过稀疏表面和骨架点云表示肺解剖结构，并学习一个连续的隐式场来支持拓扑修复，无需依赖完整或显式的断开注释。

Result: 在Lung3D+数据集上的实验表明，TopoField 显著提高了拓扑完整性，并在不完整场景下实现了准确的解剖标记和肺段重建，计算效率高（每例仅需一秒多）。

Conclusion: TopoField 通过其隐式建模框架显著提高了肺树拓扑的完整性，并在具有挑战性的不完整场景下实现了准确的解剖标记和肺段重建，同时保持了高计算效率。

Abstract: Pulmonary trees extracted from CT images frequently exhibit topological incompleteness, such as missing or disconnected branches, which substantially degrades downstream anatomical analysis and limits the applicability of existing pulmonary tree modeling pipelines. Current approaches typically rely on dense volumetric processing or explicit graph reasoning, leading to limited efficiency and reduced robustness under realistic structural corruption. We propose TopoField, a topology-aware implicit modeling framework that treats topology repair as a first-class modeling problem and enables unified multi-task inference for pulmonary tree analysis. TopoField represents pulmonary anatomy using sparse surface and skeleton point clouds and learns a continuous implicit field that supports topology repair without relying on complete or explicit disconnection annotations, by training on synthetically introduced structural disruptions over \textit{already} incomplete trees. Building upon the repaired implicit representation, anatomical labeling and lung segment reconstruction are jointly inferred through task-specific implicit functions within a single forward pass.Extensive experiments on the Lung3D+ dataset demonstrate that TopoField consistently improves topological completeness and achieves accurate anatomical labeling and lung segment reconstruction under challenging incomplete scenarios. Owing to its implicit formulation, TopoField attains high computational efficiency, completing all tasks in just over one second per case, highlighting its practicality for large-scale and time-sensitive clinical applications. Code and data will be available at https://github.com/HINTLab/TopoField.

</details>


### [259] [SSI-DM: Singularity Skipping Inversion of Diffusion Models](https://arxiv.org/abs/2602.02193)
*Chen Min,Enze Jiang,Jishen Peng,Zheng Ma*

Main category: cs.CV

TL;DR: SSI-DM通过跳过奇异区域改进扩散模型反演，生成高斯噪声并提升编辑性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在早期噪声步骤中的不准确性导致反演噪声非高斯且编辑性能差，根源在于数学奇异性的存在使反演问题本质不适定。

Method: 提出Singularity Skipping Inversion of Diffusion Models (SSI-DM)，通过在标准反演前添加少量噪声来绕过奇异区域。

Result: SSI-DM在公共图像数据集上实现了重建和插值任务的优越性能，生成的反演噪声具有自然高斯性质且保持重建保真度。

Conclusion: SSI-DM通过绕过数学奇异区域，提供了一种高效且原理性的扩散模型反演解决方案，显著提升了反演噪声的高斯性质和编辑性能。

Abstract: Inverting real images into the noise space is essential for editing tasks using diffusion models, yet existing methods produce non-Gaussian noise with poor editability due to the inaccuracy in early noising steps. We identify the root cause: a mathematical singularity that renders inversion fundamentally ill-posed. We propose Singularity Skipping Inversion of Diffusion Models (SSI-DM), which bypasses this singular region by adding small noise before standard inversion. This simple approach produces inverted noise with natural Gaussian properties while maintaining reconstruction fidelity. As a plug-and-play technique compatible with general diffusion models, our method achieves superior performance on public image datasets for reconstruction and interpolation tasks, providing a principled and efficient solution to diffusion model inversion.

</details>


### [260] [Multi-head automated segmentation by incorporating detection head into the contextual layer neural network](https://arxiv.org/abs/2602.02471)
*Edwin Kys,Febian Febian*

Main category: cs.CV

TL;DR: 提出门控多头Transformer架构，结合检测与分割，有效减少虚假预测，提升放疗自动分割的可靠性。


<details>
  <summary>Details</summary>
Motivation: 深度学习在放疗中的自动分割应用日益广泛，但传统模型在缺乏目标结构的切片中常产生解剖学上不合理的假阳性（幻觉）。

Method: 提出了一种基于Swin U-Net的门控多头Transformer架构，结合了切片间上下文集成和平行检测头，通过多层感知器进行切片级结构检测，并通过上下文增强流进行像素级分割。检测输出用于门控分割预测，以抑制解剖无效切片中的假阳性。训练采用切片级Tversky损失以解决类别不平衡问题。

Result: 在Prostate-Anatomical-Edge-Cases数据集上的实验表明，门控模型显著优于非门控分割基线，平均Dice损失为$0.013 \pm 0.036$（对比$0.732 \pm 0.314$），检测概率与解剖存在性高度相关，有效消除了虚假分割。非门控模型则表现出更高的变异性和持续的假阳性。

Conclusion: 检测门控机制显著提升了自动分割的鲁棒性和解剖学合理性，减少了虚假预测，同时不影响有效切片的分割质量，为临床放疗自动轮廓工作流程的可靠性提供了有前景的改进方法。

Abstract: Deep learning based auto segmentation is increasingly used in radiotherapy, but conventional models often produce anatomically implausible false positives, or hallucinations, in slices lacking target structures. We propose a gated multi-head Transformer architecture based on Swin U-Net, augmented with inter-slice context integration and a parallel detection head, which jointly performs slice-level structure detection via a multi-layer perceptron and pixel-level segmentation through a context-enhanced stream. Detection outputs gate the segmentation predictions to suppress false positives in anatomically invalid slices, and training uses slice-wise Tversky loss to address class imbalance. Experiments on the Prostate-Anatomical-Edge-Cases dataset from The Cancer Imaging Archive demonstrate that the gated model substantially outperforms a non-gated segmentation-only baseline, achieving a mean Dice loss of $0.013 \pm 0.036$ versus $0.732 \pm 0.314$, with detection probabilities strongly correlated with anatomical presence, effectively eliminating spurious segmentations. In contrast, the non-gated model exhibited higher variability and persistent false positives across all slices. These results indicate that detection-based gating enhances robustness and anatomical plausibility in automated segmentation applications, reducing hallucinated predictions without compromising segmentation quality in valid slices, and offers a promising approach for improving the reliability of clinical radiotherapy auto-contouring workflows.

</details>


### [261] [MAIN-VLA: Modeling Abstraction of Intention and eNvironment for Vision-Language-Action Models](https://arxiv.org/abs/2602.02212)
*Zheyuan Zhou,Liang Du,Zixun Sun,Xiaoyu Zhou,Ruimin Ye,Qihao Chen,Yinda Chen,Lemiao Qiu*

Main category: cs.CV

TL;DR: MAIN-VLA通过意图和环境抽象提升复杂动态环境中的决策效率，实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉-语言-动作（VLA）方法在高度复杂和动态环境中从冗余传感器流中提取关键信号效率低下的问题。

Method: 通过意图抽象（IA）和环境语义抽象（ESA）分别处理语言指令和视觉流，并将两者对齐以诱导注意力集中效应，实现参数无关的令牌修剪策略。

Result: 在开放世界Minecraft及大型PvP环境（如Game for Peace和Valorant）中的实验表明，MAIN-VLA在决策质量、泛化能力和推理效率上达到新的最先进水平。

Conclusion: MAIN-VLA框架通过建模意图和环境的抽象，在深度语义对齐而非表面模式匹配的基础上进行决策，显著提升了在复杂动态环境中的决策质量和效率。

Abstract: Despite significant progress in Visual-Language-Action (VLA), in highly complex and dynamic environments that involve real-time unpredictable interactions (such as 3D open worlds and large-scale PvP games), existing approaches remain inefficient at extracting action-critical signals from redundant sensor streams. To tackle this, we introduce MAIN-VLA, a framework that explicitly Models the Abstraction of Intention and eNvironment to ground decision-making in deep semantic alignment rather than superficial pattern matching. Specifically, our Intention Abstraction (IA) extracts verbose linguistic instructions and their associated reasoning into compact, explicit semantic primitives, while the Environment Semantics Abstraction (ESA) projects overwhelming visual streams into a structured, topological affordance representation. Furthermore, aligning these two abstract modalities induces an emergent attention-concentration effect, enabling a parameter-free token-pruning strategy that filters out perceptual redundancy without degrading performance. Extensive experiments in open-world Minecraft and large-scale PvP environments (Game for Peace and Valorant) demonstrate that MAIN-VLA sets a new state-of-the-art, which achieves superior decision quality, stronger generalization, and cutting-edge inference efficiency.

</details>


### [262] [Causal Forcing: Autoregressive Diffusion Distillation Done Right for High-Quality Real-Time Interactive Video Generation](https://arxiv.org/abs/2602.02214)
*Hongzhou Zhu,Min Zhao,Guande He,Hang Su,Chongxuan Li,Jun Zhu*

Main category: cs.CV

TL;DR: Causal Forcing通过自回归教师模型初始化ODE，解决了双向视频扩散模型转化为自回归模型时的架构差距问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在将预训练的双向视频扩散模型转化为少步自回归模型时，未能从理论上解决架构差距问题，导致性能下降。

Method: 提出了Causal Forcing方法，利用自回归教师模型进行ODE初始化，从而弥合架构差距。

Result: 实验结果表明，Causal Forcing在所有指标上均优于基线方法，尤其在Dynamic Degree、VisionReward和Instruction Following上分别提升了19.3%、8.7%和16.7%。

Conclusion: 通过使用Causal Forcing方法，成功解决了双向视频扩散模型转化为自回归模型时的架构差距问题，显著提升了性能表现。

Abstract: To achieve real-time interactive video generation, current methods distill pretrained bidirectional video diffusion models into few-step autoregressive (AR) models, facing an architectural gap when full attention is replaced by causal attention. However, existing approaches do not bridge this gap theoretically. They initialize the AR student via ODE distillation, which requires frame-level injectivity, where each noisy frame must map to a unique clean frame under the PF-ODE of an AR teacher. Distilling an AR student from a bidirectional teacher violates this condition, preventing recovery of the teacher's flow map and instead inducing a conditional-expectation solution, which degrades performance. To address this issue, we propose Causal Forcing that uses an AR teacher for ODE initialization, thereby bridging the architectural gap. Empirical results show that our method outperforms all baselines across all metrics, surpassing the SOTA Self Forcing by 19.3\% in Dynamic Degree, 8.7\% in VisionReward, and 16.7\% in Instruction Following. Project page and the code: \href{https://thu-ml.github.io/CausalForcing.github.io/}{https://thu-ml.github.io/CausalForcing.github.io/}

</details>


### [263] [PixelGen: Pixel Diffusion Beats Latent Diffusion with Perceptual Loss](https://arxiv.org/abs/2602.02493)
*Zehong Ma,Ruihan Xu,Shiliang Zhang*

Main category: cs.CV

TL;DR: PixelGen通过感知监督提升像素扩散性能，超越潜在扩散模型。


<details>
  <summary>Details</summary>
Motivation: 解决像素扩散方法因高维像素流形优化困难而性能落后的问题。

Method: 提出PixelGen框架，结合LPIPS损失和DINO感知损失，优化扩散模型学习感知流形。

Result: 在ImageNet-256上FID达5.11，大规模文本生成任务中GenEval得分为0.79。

Conclusion: PixelGen通过引入感知监督，简化了生成范式，无需VAE或潜在表示，性能超越现有潜在扩散模型。

Abstract: Pixel diffusion generates images directly in pixel space in an end-to-end manner, avoiding the artifacts and bottlenecks introduced by VAEs in two-stage latent diffusion. However, it is challenging to optimize high-dimensional pixel manifolds that contain many perceptually irrelevant signals, leaving existing pixel diffusion methods lagging behind latent diffusion models. We propose PixelGen, a simple pixel diffusion framework with perceptual supervision. Instead of modeling the full image manifold, PixelGen introduces two complementary perceptual losses to guide diffusion model towards learning a more meaningful perceptual manifold. An LPIPS loss facilitates learning better local patterns, while a DINO-based perceptual loss strengthens global semantics. With perceptual supervision, PixelGen surpasses strong latent diffusion baselines. It achieves an FID of 5.11 on ImageNet-256 without classifier-free guidance using only 80 training epochs, and demonstrates favorable scaling performance on large-scale text-to-image generation with a GenEval score of 0.79. PixelGen requires no VAEs, no latent representations, and no auxiliary stages, providing a simpler yet more powerful generative paradigm. Codes are publicly available at https://github.com/Zehong-Ma/PixelGen.

</details>


### [264] [MIRROR: Manifold Ideal Reference ReconstructOR for Generalizable AI-Generated Image Detection](https://arxiv.org/abs/2602.02222)
*Ruiqi Liu,Manni Cui,Ziheng Qin,Zhiyuan Yan,Ruoxin Chen,Yi Han,Zhiheng Li,Junkai Chen,ZhiJin Chen,Kaiqing Lin,Jialiang Shen,Lubin Weng,Jing Dong,Yan Wang,Shu Wu*

Main category: cs.CV

TL;DR: MIRROR通过流形一致性检测AI生成图像，优于现有方法，尤其在Human-AIGI基准上接近人类感知极限。


<details>
  <summary>Details</summary>
Motivation: 现有AI生成图像检测器依赖基于伪影的分类方法，难以适应不断演化的生成痕迹，而人类判断依赖稳定的现实规律，因此提出基于流形一致性的检测方法。

Method: MIRROR通过可学习的离散记忆库显式编码现实先验，将输入投影到流形一致的理想参考，并利用残差作为检测信号。

Result: 在14个基准测试中，MIRROR表现优于现有方法，标准基准提升2.1%，野外基准提升8.1%。在Human-AIGI基准上，MIRROR准确率达89.6%，超越普通用户和视觉专家。

Conclusion: MIRROR框架在多个基准测试中表现优异，尤其在Human-AIGI基准上接近人类感知极限，展示了其作为AI生成图像检测工具的潜力。

Abstract: High-fidelity generative models have narrowed the perceptual gap between synthetic and real images, posing serious threats to media security. Most existing AI-generated image (AIGI) detectors rely on artifact-based classification and struggle to generalize to evolving generative traces. In contrast, human judgment relies on stable real-world regularities, with deviations from the human cognitive manifold serving as a more generalizable signal of forgery. Motivated by this insight, we reformulate AIGI detection as a Reference-Comparison problem that verifies consistency with the real-image manifold rather than fitting specific forgery cues. We propose MIRROR (Manifold Ideal Reference ReconstructOR), a framework that explicitly encodes reality priors using a learnable discrete memory bank. MIRROR projects an input into a manifold-consistent ideal reference via sparse linear combination, and uses the resulting residuals as robust detection signals. To evaluate whether detectors reach the "superhuman crossover" required to replace human experts, we introduce the Human-AIGI benchmark, featuring a psychophysically curated human-imperceptible subset. Across 14 benchmarks, MIRROR consistently outperforms prior methods, achieving gains of 2.1% on six standard benchmarks and 8.1% on seven in-the-wild benchmarks. On Human-AIGI, MIRROR reaches 89.6% accuracy across 27 generators, surpassing both lay users and visual experts, and further approaching the human perceptual limit as pretrained backbones scale. The code is publicly available at: https://github.com/349793927/MIRROR

</details>


### [265] [Evaluating OCR Performance for Assistive Technology: Effects of Walking Speed, Camera Placement, and Camera Type](https://arxiv.org/abs/2602.02223)
*Junchi Feng,Nikhil Ballem,Mahya Beheshti,Giles Hamilton-Fletcher,Todd Hudson,Maurizio Porfiri,William H. Seiple,John-Ross Rizzo*

Main category: cs.CV

TL;DR: 本研究评估OCR在静态和动态条件下的性能，发现Google Vision准确率最高，PaddleOCR是最佳开源选择，手机主摄像头和肩部佩戴位置表现最优。


<details>
  <summary>Details</summary>
Motivation: OCR广泛应用于盲人和低视力人群的辅助技术，但现有评估多基于静态数据集，未能反映移动使用的挑战。本研究旨在系统评估OCR在静态和动态条件下的性能。

Method: 研究通过静态和动态测试评估OCR性能。静态测试测量1-7米距离和0-75度水平视角的检测范围；动态测试通过改变步行速度（0.8-1.8 m/s）和比较三种摄像头安装位置（头戴、肩戴、手持）来考察运动影响。使用智能手机和智能眼镜，并评估四种OCR引擎（Google Vision、PaddleOCR 3.0、EasyOCR、Tesseract）。

Result: 识别准确率随步行速度和视角增加而下降。Google Vision整体准确率最高，PaddleOCR 3.0紧随其后。手机主摄像头准确率最高，肩部佩戴位置表现最佳。

Conclusion: 研究结果表明，OCR识别准确率随步行速度和视角增加而下降。Google Vision整体准确率最高，PaddleOCR是最强的开源替代方案。手机主摄像头准确率最高，肩部佩戴位置在身体位置中平均表现最佳，但肩部、头部和手持之间的差异无统计学意义。

Abstract: Optical character recognition (OCR), which converts printed or handwritten text into machine-readable form, is widely used in assistive technology for people with blindness and low vision. Yet, most evaluations rely on static datasets that do not reflect the challenges of mobile use. In this study, we systematically evaluated OCR performance under both static and dynamic conditions. Static tests measured detection range across distances of 1-7 meters and viewing angles of 0-75 degrees horizontally. Dynamic tests examined the impact of motion by varying walking speed from slow (0.8 m/s) to very fast (1.8 m/s) and comparing three camera mounting positions: head-mounted, shoulder-mounted, and hand-held. We evaluated both a smartphone and smart glasses, using the phone's main and ultra-wide cameras. Four OCR engines were benchmarked to assess accuracy at different distances and viewing angles: Google Vision, PaddleOCR 3.0, EasyOCR, and Tesseract. PaddleOCR 3.0 was then used to evaluate accuracy at different walking speeds. Accuracy was computed at the character level using the Levenshtein ratio against manually defined ground truth. Results showed that recognition accuracy declined with increased walking speed and wider viewing angles. Google Vision achieved the highest overall accuracy, with PaddleOCR close behind as the strongest open-source alternative. Across devices, the phone's main camera achieved the highest accuracy, and a shoulder-mounted placement yielded the highest average among body positions; however, differences among shoulder, head, and hand were not statistically significant.

</details>


### [266] [Show, Don't Tell: Morphing Latent Reasoning into Image Generation](https://arxiv.org/abs/2602.02227)
*Harold Haodong Chen,Xinxiang Yin,Wen-Jie Shu,Hongfei Zhang,Zixin Zhang,Chenfei Liao,Litao Guo,Qifeng Chen,Ying-Cong Chen*

Main category: cs.CV

TL;DR: LatentMorph是一种新型T2I生成框架，通过隐式潜在推理提升生成效率和质量，减少资源消耗。


<details>
  <summary>Details</summary>
Motivation: 现有T2I生成方法缺乏动态推理和精炼能力，导致效率低下和信息丢失。

Method: LatentMorph引入了四个轻量级组件：冷凝器、翻译器、塑形器和RL训练调用器，以在连续潜在空间中进行推理。

Result: LatentMorph在多个基准测试中表现优异，提升了生成质量和效率，并显著减少了推理时间和资源消耗。

Conclusion: LatentMorph框架通过将隐式潜在推理无缝集成到T2I生成过程中，显著提升了生成效率和质量，同时减少了推理时间和资源消耗。

Abstract: Text-to-image (T2I) generation has achieved remarkable progress, yet existing methods often lack the ability to dynamically reason and refine during generation--a hallmark of human creativity. Current reasoning-augmented paradigms most rely on explicit thought processes, where intermediate reasoning is decoded into discrete text at fixed steps with frequent image decoding and re-encoding, leading to inefficiencies, information loss, and cognitive mismatches. To bridge this gap, we introduce LatentMorph, a novel framework that seamlessly integrates implicit latent reasoning into the T2I generation process. At its core, LatentMorph introduces four lightweight components: (i) a condenser for summarizing intermediate generation states into compact visual memory, (ii) a translator for converting latent thoughts into actionable guidance, (iii) a shaper for dynamically steering next image token predictions, and (iv) an RL-trained invoker for adaptively determining when to invoke reasoning. By performing reasoning entirely in continuous latent spaces, LatentMorph avoids the bottlenecks of explicit reasoning and enables more adaptive self-refinement. Extensive experiments demonstrate that LatentMorph (I) enhances the base model Janus-Pro by $16\%$ on GenEval and $25\%$ on T2I-CompBench; (II) outperforms explicit paradigms (e.g., TwiG) by $15\%$ and $11\%$ on abstract reasoning tasks like WISE and IPV-Txt, (III) while reducing inference time by $44\%$ and token consumption by $51\%$; and (IV) exhibits $71\%$ cognitive alignment with human intuition on reasoning invocation.

</details>


### [267] [LiFlow: Flow Matching for 3D LiDAR Scene Completion](https://arxiv.org/abs/2602.02232)
*Andrea Matteazzi,Dietmar Tutsch*

Main category: cs.CV

TL;DR: LiFlow是首个用于3D LiDAR场景补全的流匹配框架，解决了扩散方法初始分布不匹配的问题，性能最优。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于扩散的方法在训练和推理初始分布不匹配的问题，提升自动驾驶系统对遮挡和远距离稀疏点云的感知能力。

Method: 采用最近邻流匹配损失和Chamfer距离损失，结合局部结构和全局覆盖的优化。

Result: LiFlow在多个指标上达到了最先进的性能。

Conclusion: LiFlow通过引入流匹配框架解决了3D LiDAR场景补全中初始分布不一致的问题，实现了在多个指标上的最先进性能。

Abstract: In autonomous driving scenarios, the collected LiDAR point clouds can be challenged by occlusion and long-range sparsity, limiting the perception of autonomous driving systems. Scene completion methods can infer the missing parts of incomplete 3D LiDAR scenes. Recent methods adopt local point-level denoising diffusion probabilistic models, which require predicting Gaussian noise, leading to a mismatch between training and inference initial distributions. This paper introduces the first flow matching framework for 3D LiDAR scene completion, improving upon diffusion-based methods by ensuring consistent initial distributions between training and inference. The model employs a nearest neighbor flow matching loss and a Chamfer distance loss to enhance both local structure and global coverage in the alignment of point clouds. LiFlow achieves state-of-the-art performance across multiple metrics. Code: https://github.com/matteandre/LiFlow.

</details>


### [268] [Enhancing Indoor Occupancy Prediction via Sparse Query-Based Multi-Level Consistent Knowledge Distillation](https://arxiv.org/abs/2602.02318)
*Xiang Li,Yupeng Zheng,Pengfei Li,Yilun Chen,Ya-Qin Zhang,Wenchao Ding*

Main category: cs.CV

TL;DR: DiScene通过多级蒸馏和教师引导初始化，在占用预测任务中实现了高效和鲁棒的性能，并在多个基准测试中领先。


<details>
  <summary>Details</summary>
Motivation: 解决现有密集方法在计算效率上的浪费和稀疏查询方法在复杂室内场景中缺乏鲁棒性的问题。

Method: 提出DiScene框架，采用多级一致知识蒸馏策略和教师引导初始化策略。

Result: 在Occ-Scannet基准测试中，DiScene实现了23.2 FPS，性能优于基线方法OPUS 36.1%，深度增强版本DiScene†甚至超越了EmbodiedOcc 3.7%。

Conclusion: DiScene通过多级蒸馏策略和教师引导初始化，在占用预测任务中实现了高效和鲁棒的性能，并在多个基准测试中取得了领先的结果。

Abstract: Occupancy prediction provides critical geometric and semantic understanding for robotics but faces efficiency-accuracy trade-offs. Current dense methods suffer computational waste on empty voxels, while sparse query-based approaches lack robustness in diverse and complex indoor scenes. In this paper, we propose DiScene, a novel sparse query-based framework that leverages multi-level distillation to achieve efficient and robust occupancy prediction. In particular, our method incorporates two key innovations: (1) a Multi-level Consistent Knowledge Distillation strategy, which transfers hierarchical representations from large teacher models to lightweight students through coordinated alignment across four levels, including encoder-level feature alignment, query-level feature matching, prior-level spatial guidance, and anchor-level high-confidence knowledge transfer and (2) a Teacher-Guided Initialization policy, employing optimized parameter warm-up to accelerate model convergence. Validated on the Occ-Scannet benchmark, DiScene achieves 23.2 FPS without depth priors while outperforming our baseline method, OPUS, by 36.1% and even better than the depth-enhanced version, OPUS†. With depth integration, DiScene† attains new SOTA performance, surpassing EmbodiedOcc by 3.7% with 1.62$\times$ faster inference speed. Furthermore, experiments on the Occ3D-nuScenes benchmark and in-the-wild scenarios demonstrate the versatility of our approach in various environments. Code and models can be accessed at https://github.com/getterupper/DiScene.

</details>


### [269] [LongVPO: From Anchored Cues to Self-Reasoning for Long-Form Video Preference Optimization](https://arxiv.org/abs/2602.02341)
*Zhenpeng Huang,Jiaqi Li,Zihan Jia,Xinhao Li,Desen Meng,Lingxue Song,Xi Chen,Liang Li,Limin Wang*

Main category: cs.CV

TL;DR: LongVPO通过两阶段框架（合成偏好三元组和多段推理任务）提升短上下文模型对长视频的理解能力，无需人工标注即可超越现有模型。


<details>
  <summary>Details</summary>
Motivation: 解决短上下文视觉语言模型在理解超长视频时的局限性，同时避免昂贵的人工标注需求。

Method: 第一阶段通过合成偏好三元组，将问题锚定到单个短片段，并应用视觉相似性和问题特异性过滤以减少位置偏差；第二阶段采用递归字幕生成管道生成场景级元数据，并利用大型语言模型创建多段推理查询和不受欢迎的响应。

Result: 仅使用16K合成示例且无需人工标注，LongVPO在多个长视频基准测试中表现优于现有开源模型，并保持强大的短视频性能。

Conclusion: LongVPO提出了一种新颖的两阶段直接偏好优化框架，能够在无需长视频标注的情况下，使短上下文视觉语言模型稳健理解超长视频内容，并在多个长视频基准测试中超越现有开源模型。

Abstract: We present LongVPO, a novel two-stage Direct Preference Optimization framework that enables short-context vision-language models to robustly understand ultra-long videos without any long-video annotations. In Stage 1, we synthesize preference triples by anchoring questions to individual short clips, interleaving them with distractors, and applying visual-similarity and question-specificity filtering to mitigate positional bias and ensure unambiguous supervision. We also approximate the reference model's scoring over long contexts by evaluating only the anchor clip, reducing computational overhead. In Stage 2, we employ a recursive captioning pipeline on long videos to generate scene-level metadata, then use a large language model to craft multi-segment reasoning queries and dispreferred responses, aligning the model's preferences through multi-segment reasoning tasks. With only 16K synthetic examples and no costly human labels, LongVPO outperforms the state-of-the-art open-source models on multiple long-video benchmarks, while maintaining strong short-video performance (e.g., on MVBench), offering a scalable paradigm for efficient long-form video understanding.

</details>


### [270] [NAB: Neural Adaptive Binning for Sparse-View CT reconstruction](https://arxiv.org/abs/2602.02356)
*Wangduo Xie,Matthew B. Blaschko*

Main category: cs.CV

TL;DR: NAB是一种整合矩形先验的神经自适应分箱方法，显著提升稀疏CT重建质量，适用于工业和医学场景。


<details>
  <summary>Details</summary>
Motivation: 工业对象普遍具有矩形结构，而现有隐式神经网络无法利用形状先验知识，因此需要一种能整合矩形先验的稀疏重建方法。

Method: 提出了一种新颖的神经自适应分箱（NAB）方法，通过将坐标空间映射到分箱向量空间，并利用基于移位双曲正切函数的创新分箱机制，结合神经网络预测CT衰减系数。

Result: NAB在工业数据集上表现优异，且在医学数据集上通过扩展分箱函数也能保持鲁棒性。

Conclusion: NAB方法通过有效整合矩形先验知识，显著提升了稀疏视图CT重建的质量，并在工业和医学数据集上展示了优越性能。

Abstract: Computed Tomography (CT) plays a vital role in inspecting the internal structures of industrial objects. Furthermore, achieving high-quality CT reconstruction from sparse views is essential for reducing production costs. While classic implicit neural networks have shown promising results for sparse reconstruction, they are unable to leverage shape priors of objects. Motivated by the observation that numerous industrial objects exhibit rectangular structures, we propose a novel \textbf{N}eural \textbf{A}daptive \textbf{B}inning (\textbf{NAB}) method that effectively integrates rectangular priors into the reconstruction process. Specifically, our approach first maps coordinate space into a binned vector space. This mapping relies on an innovative binning mechanism based on differences between shifted hyperbolic tangent functions, with our extension enabling rotations around the input-plane normal vector. The resulting representations are then processed by a neural network to predict CT attenuation coefficients. This design enables end-to-end optimization of the encoding parameters -- including position, size, steepness, and rotation -- via gradient flow from the projection data, thus enhancing reconstruction accuracy. By adjusting the smoothness of the binning function, NAB can generalize to objects with more complex geometries. This research provides a new perspective on integrating shape priors into neural network-based reconstruction. Extensive experiments demonstrate that NAB achieves superior performance on two industrial datasets. It also maintains robust on medical datasets when the binning function is extended to more general expression. The code will be made available.

</details>


### [271] [Uncertainty-Aware Image Classification In Biomedical Imaging Using Spectral-normalized Neural Gaussian Processes](https://arxiv.org/abs/2602.02370)
*Uma Meleti,Jeffrey J. Nirschl*

Main category: cs.CV

TL;DR: SNGP通过改进不确定性估计和OOD检测，为数字病理学提供了更可靠的深度学习模型。


<details>
  <summary>Details</summary>
Motivation: 当前深度学习模型在数字病理学中往往过于自信且在校准不足的OOD设置中表现不佳，限制了信任和临床采用。

Method: 实现了频谱归一化神经高斯过程（SNGP），通过频谱归一化和将最终密集层替换为高斯过程层来改进单模型不确定性估计和OOD检测。

Result: SNGP在分布内性能上表现相当，同时显著改善了不确定性估计和OOD检测。

Conclusion: SNGP或相关模型为数字病理学中的不确定性感知分类提供了一个有用的框架，支持安全部署并增强病理学家的信任。

Abstract: Accurate histopathologic interpretation is key for clinical decision-making; however, current deep learning models for digital pathology are often overconfident and poorly calibrated in out-of-distribution (OOD) settings, which limit trust and clinical adoption. Safety-critical medical imaging workflows benefit from intrinsic uncertainty-aware properties that can accurately reject OOD input. We implement the Spectral-normalized Neural Gaussian Process (SNGP), a set of lightweight modifications that apply spectral normalization and replace the final dense layer with a Gaussian process layer to improve single-model uncertainty estimation and OOD detection. We evaluate SNGP vs. deterministic and MonteCarlo dropout on six datasets across three biomedical classification tasks: white blood cells, amyloid plaques, and colorectal histopathology. SNGP has comparable in-distribution performance while significantly improving uncertainty estimation and OOD detection. Thus, SNGP or related models offer a useful framework for uncertainty-aware classification in digital pathology, supporting safe deployment and building trust with pathologists.

</details>


### [272] [Unified Personalized Reward Model for Vision Generation](https://arxiv.org/abs/2602.02380)
*Yibin Wang,Yuhang Zang,Feng Han,Jiazi Bu,Yujie Zhou,Cheng Jin,Jiaqi Wang*

Main category: cs.CV

TL;DR: 提出UnifiedReward-Flex，一种结合灵活推理的个性化奖励模型，通过两阶段训练显著提升视觉生成与人类偏好的对齐。


<details>
  <summary>Details</summary>
Motivation: 现有奖励模型存在‘一刀切’的局限性，无法适应内容特定的视觉线索和主观、上下文依赖的人类偏好。

Method: 采用两阶段训练流程：首先从高级闭源VLM中提取高质量推理轨迹进行SFT，然后通过DPO优化偏好对以增强推理忠实度和判别对齐。

Result: 在图像和视频合成中集成UnifiedReward-Flex后，实验结果显示其优越性。

Conclusion: UnifiedReward-Flex通过结合奖励建模与灵活、上下文自适应的推理，显著提升了视觉生成模型与人类主观偏好的对齐效果。

Abstract: Recent advancements in multimodal reward models (RMs) have significantly propelled the development of visual generation. Existing frameworks typically adopt Bradley-Terry-style preference modeling or leverage generative VLMs as judges, and subsequently optimize visual generation models via reinforcement learning. However, current RMs suffer from inherent limitations: they often follow a one-size-fits-all paradigm that assumes a monolithic preference distribution or relies on fixed evaluation rubrics. As a result, they are insensitive to content-specific visual cues, leading to systematic misalignment with subjective and context-dependent human preferences. To this end, inspired by human assessment, we propose UnifiedReward-Flex, a unified personalized reward model for vision generation that couples reward modeling with flexible and context-adaptive reasoning. Specifically, given a prompt and the generated visual content, it first interprets the semantic intent and grounds on visual evidence, then dynamically constructs a hierarchical assessment by instantiating fine-grained criteria under both predefined and self-generated high-level dimensions. Our training pipeline follows a two-stage process: (1) we first distill structured, high-quality reasoning traces from advanced closed-source VLMs to bootstrap SFT, equipping the model with flexible and context-adaptive reasoning behaviors; (2) we then perform direct preference optimization (DPO) on carefully curated preference pairs to further strengthen reasoning fidelity and discriminative alignment. To validate the effectiveness, we integrate UnifiedReward-Flex into the GRPO framework for image and video synthesis, and extensive results demonstrate its superiority.

</details>


### [273] [Personalized Image Generation via Human-in-the-loop Bayesian Optimization](https://arxiv.org/abs/2602.02388)
*Rajalaxmi Rajagopalan,Debottam Dutta,Yu-Lin Wei,Romit Roy Choudhury*

Main category: cs.CV

TL;DR: MultiBO利用人类的多轮偏好反馈优化生成图像，显著缩小与用户理想图像的差距。


<details>
  <summary>Details</summary>
Motivation: 解决用户在通过语言提示生成图像时难以精确表达需求，导致生成图像与理想图像存在差距的问题。

Method: 开发了MultiBO（多选择偏好贝叶斯优化）方法，通过生成K个新图像并获取用户的偏好反馈，利用反馈指导扩散模型生成更接近用户理想图像的图像。

Result: 通过30名用户的定性评分和与5个基线的定量比较，证明了MultiBO在缩小图像差距方面的有效性。

Conclusion: 通过MultiBO方法，结合人类的多轮偏好反馈，可以显著缩小生成图像与用户心中理想图像之间的差距，实现更个性化的图像生成。

Abstract: Imagine Alice has a specific image $x^\ast$ in her mind, say, the view of the street in which she grew up during her childhood. To generate that exact image, she guides a generative model with multiple rounds of prompting and arrives at an image $x^{p*}$. Although $x^{p*}$ is reasonably close to $x^\ast$, Alice finds it difficult to close that gap using language prompts. This paper aims to narrow this gap by observing that even after language has reached its limits, humans can still tell when a new image $x^+$ is closer to $x^\ast$ than $x^{p*}$. Leveraging this observation, we develop MultiBO (Multi-Choice Preferential Bayesian Optimization) that carefully generates $K$ new images as a function of $x^{p*}$, gets preferential feedback from the user, uses the feedback to guide the diffusion model, and ultimately generates a new set of $K$ images. We show that within $B$ rounds of user feedback, it is possible to arrive much closer to $x^\ast$, even though the generative model has no information about $x^\ast$. Qualitative scores from $30$ users, combined with quantitative metrics compared across $5$ baselines, show promising results, suggesting that multi-choice feedback from humans can be effectively harnessed for personalized image generation.

</details>


### [274] [Superman: Unifying Skeleton and Vision for Human Motion Perception and Generation](https://arxiv.org/abs/2602.02401)
*Xinshun Wang,Peiming Li,Ziyi Wang,Zhongbin Fang,Zhichao Deng,Songtao Wu,Jason Li,Mengyuan Liu*

Main category: cs.CV

TL;DR: Superman提出统一框架，结合视觉感知与骨架运动生成，通过跨模态联合学习解决运动分析碎片化问题，实现多任务高效处理。


<details>
  <summary>Details</summary>
Motivation: 当前运动分析领域存在严重碎片化问题，包括感知与生成模型割裂、生成模型局限于静态单帧姿态、现有运动词汇仅依赖骨架数据等问题，亟需统一解决方案。

Method: 提出Vision-Guided Motion Tokenizer模块，利用3D骨架与视觉数据的几何对齐性，实现跨模态联合学习，构建统一的运动词汇；并基于此训练单一、统一的MLLM架构，灵活处理多样化时序输入。

Result: 在Human3.6M等标准基准测试中，Superman框架在运动任务上达到或超越现有最优性能。

Conclusion: Superman框架通过统一的视觉感知与基于骨架的运动生成，为生成式运动分析提供了一条更高效、可扩展的路径，并在标准基准测试中展示了优越性能。

Abstract: Human motion analysis tasks, such as temporal 3D pose estimation, motion prediction, and motion in-betweening, play an essential role in computer vision. However, current paradigms suffer from severe fragmentation. First, the field is split between ``perception'' models that understand motion from video but only output text, and ``generation'' models that cannot perceive from raw visual input. Second, generative MLLMs are often limited to single-frame, static poses using dense, parametric SMPL models, failing to handle temporal motion. Third, existing motion vocabularies are built from skeleton data alone, severing the link to the visual domain. To address these challenges, we introduce Superman, a unified framework that bridges visual perception with temporal, skeleton-based motion generation. Our solution is twofold. First, to overcome the modality disconnect, we propose a Vision-Guided Motion Tokenizer. Leveraging the natural geometric alignment between 3D skeletons and visual data, this module pioneers robust joint learning from both modalities, creating a unified, cross-modal motion vocabulary. Second, grounded in this motion language, a single, unified MLLM architecture is trained to handle all tasks. This module flexibly processes diverse, temporal inputs, unifying 3D skeleton pose estimation from video (perception) with skeleton-based motion prediction and in-betweening (generation). Extensive experiments on standard benchmarks, including Human3.6M, demonstrate that our unified method achieves state-of-the-art or competitive performance across all motion tasks. This showcases a more efficient and scalable path for generative motion analysis using skeletons.

</details>


### [275] [Catalyst: Out-of-Distribution Detection via Elastic Scaling](https://arxiv.org/abs/2602.02409)
*Abid Hassan,Tuan Ngo,Saad Shafiq,Nenad Medvidovic*

Main category: cs.CV

TL;DR: Catalyst利用预池化统计信息动态计算缩放因子，显著提升OOD检测性能，与现有方法互补。


<details>
  <summary>Details</summary>
Motivation: 现有的OOD检测方法仅依赖输出logits或全局平均池化（GAP）后的特征向量，忽略了预池化特征图的原始通道统计信息，这些信息可能包含丰富的互补信号。

Method: Catalyst框架动态计算输入依赖的缩放因子（γ），并将其与现有基线分数融合，通过“弹性缩放”进一步分离ID和OOD分布。

Result: Catalyst在CIFAR-10（ResNet-18）、CIFAR-100（ResNet-18）和ImageNet（ResNet-50）上分别降低了32.87%、27.94%和22.25%的平均误报率，显著提升了性能。

Conclusion: Catalyst框架通过利用预池化统计信息，显著提升了OOD检测性能，证明了这些未充分利用信号的潜力，并且与现有方法互补。

Abstract: Out-of-distribution (OOD) detection is critical for the safe deployment of deep neural networks. State-of-the-art post-hoc methods typically derive OOD scores from the output logits or penultimate feature vector obtained via global average pooling (GAP). We contend that this exclusive reliance on the logit or feature vector discards a rich, complementary signal: the raw channel-wise statistics of the pre-pooling feature map lost in GAP. In this paper, we introduce Catalyst, a post-hoc framework that exploits these under-explored signals. Catalyst computes an input-dependent scaling factor ($γ$) on-the-fly from these raw statistics (e.g., mean, standard deviation, and maximum activation). This $γ$ is then fused with the existing baseline score, multiplicatively modulating it -- an ``elastic scaling'' -- to push the ID and OOD distributions further apart. We demonstrate Catalyst is a generalizable framework: it seamlessly integrates with logit-based methods (e.g., Energy, ReAct, SCALE) and also provides a significant boost to distance-based detectors like KNN. As a result, Catalyst achieves substantial and consistent performance gains, reducing the average False Positive Rate by 32.87 on CIFAR-10 (ResNet-18), 27.94% on CIFAR-100 (ResNet-18), and 22.25% on ImageNet (ResNet-50). Our results highlight the untapped potential of pre-pooling statistics and demonstrate that Catalyst is complementary to existing OOD detection approaches.

</details>


### [276] [SelvaMask: Segmenting Trees in Tropical Forests and Beyond](https://arxiv.org/abs/2602.02426)
*Simon-Olivier Duguay,Hugo Baudchon,Etienne Laliberté,Helene Muller-Landau,Gonzalo Rivas-Torres,Arthur Ouaknine*

Main category: cs.CV

TL;DR: 介绍了SelvaMask数据集和模块化检测-分割流程，显著提升了热带森林树冠分割的准确性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 热带森林树冠的高密度和复杂性使得现有分割模型性能不足，亟需新的数据集和方法。

Method: 提出了一个模块化的检测-分割流程，结合视觉基础模型（VFMs）和领域特定的检测提示器。

Result: SelvaMask数据集和提出的方法在热带森林中达到了最先进的性能，优于零样本通用模型和全监督端到端方法。

Conclusion: SelvaMask数据集和提出的检测-分割流程不仅为热带森林监测设立了新基准，还显著提升了树冠分割的准确性和泛化能力。

Abstract: Tropical forests harbor most of the planet's tree biodiversity and are critical to global ecological balance. Canopy trees in particular play a disproportionate role in carbon storage and functioning of these ecosystems. Studying canopy trees at scale requires accurate delineation of individual tree crowns, typically performed using high-resolution aerial imagery. Despite advances in transformer-based models for individual tree crown segmentation, performance remains low in most forests, especially tropical ones. To this end, we introduce SelvaMask, a new tropical dataset containing over 8,800 manually delineated tree crowns across three Neotropical forest sites in Panama, Brazil, and Ecuador. SelvaMask features comprehensive annotations, including an inter-annotator agreement evaluation, capturing the dense structure of tropical forests and highlighting the difficulty of the task. Leveraging this benchmark, we propose a modular detection-segmentation pipeline that adapts vision foundation models (VFMs), using domain-specific detection-prompter. Our approach reaches state-of-the-art performance, outperforming both zero-shot generalist models and fully supervised end-to-end methods in dense tropical forests. We validate these gains on external tropical and temperate datasets, demonstrating that SelvaMask serves as both a challenging benchmark and a key enabler for generalized forest monitoring. Our code and dataset will be released publicly.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [277] [Scalable Generative Game Engine: Breaking the Resolution Wall via Hardware-Algorithm Co-Design](https://arxiv.org/abs/2602.00608)
*Wei Zeng,Xuchen Li,Ruili Feng,Zhen Liu,Fengwei An,Jian Zhao*

Main category: cs.AI

TL;DR: 提出硬件-算法协同设计框架，解决高分辨率神经模拟的内存墙问题，实现50倍像素吞吐量提升和流畅游戏体验。


<details>
  <summary>Details</summary>
Motivation: 现有方法受限于内存墙，无法实现高分辨率实时生成，限制了神经世界模型的实际应用。

Method: 提出了一种异构架构，包括非对称资源分配策略、内存中心的操作符融合方案和利用时间冗余的流形感知潜在外推机制。

Result: 在可编程AI加速器集群上验证，实现了720×480分辨率的实时生成，像素吞吐量提高了50倍，在连续3D赛车和离散2D平台游戏中分别达到26.4 FPS和48.3 FPS。

Conclusion: 通过硬件-算法协同设计框架解决了生成模型在高分辨率神经模拟中的内存墙问题，实现了高保真、响应式神经游戏体验。

Abstract: Real-time generative game engines represent a paradigm shift in interactive simulation, promising to replace traditional graphics pipelines with neural world models. However, existing approaches are fundamentally constrained by the ``Memory Wall,'' restricting practical deployments to low resolutions (e.g., $64 \times 64$). This paper bridges the gap between generative models and high-resolution neural simulations by introducing a scalable \textit{Hardware-Algorithm Co-Design} framework. We identify that high-resolution generation suffers from a critical resource mismatch: the World Model is compute-bound while the Decoder is memory-bound. To address this, we propose a heterogeneous architecture that intelligently decouples these components across a cluster of AI accelerators. Our system features three core innovations: (1) an asymmetric resource allocation strategy that optimizes throughput under sequence parallelism constraints; (2) a memory-centric operator fusion scheme that minimizes off-chip bandwidth usage; and (3) a manifold-aware latent extrapolation mechanism that exploits temporal redundancy to mask latency. We validate our approach on a cluster of programmable AI accelerators, enabling real-time generation at $720 \times 480$ resolution -- a $50\times$ increase in pixel throughput over prior baselines. Evaluated on both continuous 3D racing and discrete 2D platformer benchmarks, our system delivers fluid 26.4 FPS and 48.3 FPS respectively, with an amortized effective latency of 2.7 ms. This work demonstrates that resolving the ``Memory Wall'' via architectural co-design is not merely an optimization, but a prerequisite for enabling high-fidelity, responsive neural gameplay.

</details>


### [278] [Scalable and Secure AI Inference in Healthcare: A Comparative Benchmarking of FastAPI and Triton Inference Server on Kubernetes](https://arxiv.org/abs/2602.00053)
*Ratul Ali*

Main category: cs.AI

TL;DR: 论文比较了FastAPI和NVIDIA Triton在医疗AI部署中的性能，发现混合架构（FastAPI作为网关，Triton用于推理）是最佳实践，兼顾了延迟、吞吐量和安全性。


<details>
  <summary>Details</summary>
Motivation: 在医疗和制药等受监管领域，机器学习模型的部署需要平衡推理延迟、吞吐量和数据隐私标准（如HIPAA）的竞争需求。

Method: 通过Kubernetes部署DistilBERT情感分析模型，在受控实验条件下测量中位数（p50）和尾部（p95）延迟以及吞吐量，比较FastAPI和NVIDIA Triton Inference Server两种部署范式的性能。

Result: FastAPI在单请求工作负载下具有较低的开销（p50延迟为22毫秒），而Triton通过动态批处理实现了更高的可扩展性（单个NVIDIA T4 GPU上的吞吐量为780请求/秒，几乎是基线的两倍）。

Conclusion: 本研究验证了混合架构模型（FastAPI作为安全网关，Triton用于后端推理）作为企业临床AI的最佳实践，并为安全、高可用性部署提供了蓝图。

Abstract: Efficient and scalable deployment of machine learning (ML) models is a prerequisite for modern production environments, particularly within regulated domains such as healthcare and pharmaceuticals. In these settings, systems must balance competing requirements, including minimizing inference latency for real-time clinical decision support, maximizing throughput for batch processing of medical records, and ensuring strict adherence to data privacy standards such as HIPAA. This paper presents a rigorous benchmarking analysis comparing two prominent deployment paradigms: a lightweight, Python-based REST service using FastAPI, and a specialized, high-performance serving engine, NVIDIA Triton Inference Server. Leveraging a reference architecture for healthcare AI, we deployed a DistilBERT sentiment analysis model on Kubernetes to measure median (p50) and tail (p95) latency, as well as throughput, under controlled experimental conditions. Our results indicate a distinct trade-off. While FastAPI provides lower overhead for single-request workloads with a p50 latency of 22 ms, Triton achieves superior scalability through dynamic batching, delivering a throughput of 780 requests per second on a single NVIDIA T4 GPU, nearly double that of the baseline. Furthermore, we evaluate a hybrid architectural approach that utilizes FastAPI as a secure gateway for protected health information de-identification and Triton for backend inference. This study validates the hybrid model as a best practice for enterprise clinical AI and offers a blueprint for secure, high-availability deployments.

</details>


### [279] [Learning to Price: Interpretable Attribute-Level Models for Dynamic Markets](https://arxiv.org/abs/2602.00188)
*Srividhya Sethuraman,Chandrashekar Lakshminarayanan*

Main category: cs.AI

TL;DR: AFDLD模型和ADEPT算法通过属性分解和在线学习，解决了高维市场动态定价的可解释性和效率问题。


<details>
  <summary>Details</summary>
Motivation: 解决高维市场中动态定价的可扩展性、不确定性和可解释性挑战，特别是现有低秩bandit方法依赖潜在特征而无法解释个体产品属性如何影响价格的问题。

Method: 提出了ADEPT算法，这是一种无投影、无梯度的在线学习算法，直接在属性空间中操作，实现了次线性遗憾。

Result: ADEPT在动态市场条件下学习接近最优的价格，快速适应冲击和漂移，并提供透明的属性级价格解释。

Conclusion: 通过结构化的、属性驱动的表示，可以在自主定价代理中同时实现可解释性和效率。

Abstract: Dynamic pricing in high-dimensional markets poses fundamental challenges of scalability, uncertainty, and interpretability. Existing low-rank bandit formulations learn efficiently but rely on latent features that obscure how individual product attributes influence price. We address this by introducing an interpretable \emph{Additive Feature Decomposition-based Low-Dimensional Demand (\textbf{AFDLD}) model}, where product prices are expressed as the sum of attribute-level contributions and substitution effects are explicitly modeled. Building on this structure, we propose \textbf{ADEPT} (Additive DEcomposition for Pricing with cross-elasticity and Time-adaptive learning)-a projection-free, gradient-free online learning algorithm that operates directly in attribute space and achieves a sublinear regret of $\tilde{\mathcal{O}}(\sqrt{d}T^{3/4})$. Through controlled synthetic studies and real-world datasets, we show that ADEPT (i) learns near-optimal prices under dynamic market conditions, (ii) adapts rapidly to shocks and drifts, and (iii) yields transparent, attribute-level price explanations. The results demonstrate that interpretability and efficiency in autonomous pricing agents can be achieved jointly through structured, attribute-driven representations.

</details>


### [280] [From Gameplay Traces to Game Mechanics: Causal Induction with Large Language Models](https://arxiv.org/abs/2602.00190)
*Mohit Jiwatode,Alexander Dockhorn,Bodo Rosenhahn*

Main category: cs.AI

TL;DR: 研究比较了两种VGDL生成方法，发现基于SCM的方法在准确性和一致性上优于直接生成，适用于因果强化学习等下游任务。


<details>
  <summary>Details</summary>
Motivation: 为了解决深度学习代理在复杂游戏领域中表现优异但往往不理解底层因果游戏机制的问题，研究探讨了因果归纳能力，即从观察数据中推断控制规律的能力。

Method: 研究比较了两种VGDL生成方法：直接从观察生成代码，以及先推断结构因果模型（SCM）再转换为VGDL的两阶段方法。

Result: SCM方法在生成VGDL描述时表现更优，盲评偏好胜率达81%，且逻辑不一致规则更少。

Conclusion: 研究表明，基于SCM的方法在生成VGDL描述时比直接生成方法更接近真实规则，且在盲评中获得了高达81%的偏好胜率，生成的规则逻辑不一致性更少。

Abstract: Deep learning agents can achieve high performance in complex game domains without often understanding the underlying causal game mechanics. To address this, we investigate Causal Induction: the ability to infer governing laws from observational data, by tasking Large Language Models (LLMs) with reverse-engineering Video Game Description Language (VGDL) rules from gameplay traces. To reduce redundancy, we select nine representative games from the General Video Game AI (GVGAI) framework using semantic embeddings and clustering. We compare two approaches to VGDL generation: direct code generation from observations, and a two-stage method that first infers a structural causal model (SCM) and then translates it into VGDL. Both approaches are evaluated across multiple prompting strategies and controlled context regimes, varying the amount and form of information provided to the model, from just raw gameplay observations to partial VGDL specifications. Results show that the SCM-based approach more often produces VGDL descriptions closer to the ground truth than direct generation, achieving preference win rates of up to 81\% in blind evaluations and yielding fewer logically inconsistent rules. These learned SCMs can be used for downstream use cases such as causal reinforcement learning, interpretable agents, and procedurally generating novel but logically consistent games.

</details>


### [281] [Complete Identification of Deep ReLU Neural Networks by Many-Valued Logic](https://arxiv.org/abs/2602.00266)
*Yani Zhang,Helmut Bölcskei*

Main category: cs.AI

TL;DR: 本文提出了一种方法，通过将ReLU网络转化为Lukasiewicz逻辑公式并利用逻辑公理进行代数重写，解决了ReLU网络的完全识别问题，证明了功能等效网络的有限对称性连接。


<details>
  <summary>Details</summary>
Motivation: 研究深度ReLU神经网络中存在的非平凡功能对称性，即不同架构和参数可以实现相同函数，旨在解决给定函数f时，如何推导出所有产生f的前馈ReLU网络的架构和参数。

Method: 将ReLU网络转化为Lukasiewicz逻辑公式，通过代数重写实现功能等效的网络变换，并提出组合范数形式以方便从逻辑公式映射回ReLU网络。

Result: 利用Chang的完备性定理证明，每个功能等效类中的所有ReLU网络都可以通过有限的对称性连接，这些对称性对应于Lukasiewicz逻辑的有限公理集。

Conclusion: 本文通过将ReLU网络转化为Lukasiewicz逻辑公式，并利用逻辑公理进行代数重写，解决了ReLU网络的完全识别问题，证明了所有功能等效的ReLU网络可以通过有限的对称性连接。

Abstract: Deep ReLU neural networks admit nontrivial functional symmetries: vastly different architectures and parameters (weights and biases) can realize the same function. We address the complete identification problem -- given a function f, deriving the architecture and parameters of all feedforward ReLU networks giving rise to f. We translate ReLU networks into Lukasiewicz logic formulae, and effect functional equivalent network transformations through algebraic rewrites governed by the logic axioms. A compositional norm form is proposed to facilitate the mapping from Lukasiewicz logic formulae back to ReLU networks. Using Chang's completeness theorem, we show that for every functional equivalence class, all ReLU networks in that class are connected by a finite set of symmetries corresponding to the finite set of axioms of Lukasiewicz logic. This idea is reminiscent of Shannon's seminal work on switching circuit design, where the circuits are translated into Boolean formulae, and synthesis is effected by algebraic rewriting governed by Boolean logic axioms.

</details>


### [282] [Localizing and Correcting Errors for LLM-based Planners](https://arxiv.org/abs/2602.00276)
*Aditya Kumar,William W. Cohen*

Main category: cs.AI

TL;DR: L-ICL通过局部修正提升LLM在规划任务中的有效性，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在数学和编码任务中表现优异，但在符号化经典规划任务中常因违反领域约束而失败。

Method: 提出L-ICL技术，通过识别轨迹中的首次约束违反，并注入最小输入输出示例来修正失败步骤。

Result: 在8x8网格世界中，L-ICL仅需60个训练示例即可生成89%的有效规划，比最佳基线提升30%。其他领域（如迷宫、Sokoban等）和多种LLM架构中也有显著改进。

Conclusion: L-ICL（局部上下文学习）通过针对性修正特定失败步骤，显著提升了大型语言模型在符号化经典规划任务中的表现，优于传统方法和基线模型。

Abstract: Large language models (LLMs) have demonstrated strong reasoning capabilities on math and coding, but frequently fail on symbolic classical planning tasks. Our studies, as well as prior work, show that LLM-generated plans routinely violate domain constraints given in their instructions (e.g., walking through walls). To address this failure, we propose iteratively augmenting instructions with Localized In-Context Learning (L-ICL) demonstrations: targeted corrections for specific failing steps. Specifically, L-ICL identifies the first constraint violation in a trace and injects a minimal input-output example giving the correct behavior for the failing step. Our proposed technique of L-ICL is much effective than explicit instructions or traditional ICL, which adds complete problem-solving trajectories, and many other baselines. For example, on an 8x8 gridworld, L-ICL produces valid plans 89% of the time with only 60 training examples, compared to 59% for the best baseline, an increase of 30%. L-ICL also shows dramatic improvements in other domains (gridworld navigation, mazes, Sokoban, and BlocksWorld), and on several LLM architectures.

</details>


### [283] [Assessing Domain-Level Susceptibility to Emergent Misalignment from Narrow Finetuning](https://arxiv.org/abs/2602.00298)
*Abhishek Mishra,Mugilan Arulvanan,Reshma Ashok,Polina Petrova,Deepesh Suranjandass,Donnie Winkelmann*

Main category: cs.AI

TL;DR: 研究发现后门触发器显著增加语言模型的错位率，领域脆弱性差异大，并提出了错位分类排名和标准化数据集构建方法。


<details>
  <summary>Details</summary>
Motivation: 涌现错位对AI安全构成风险，需要评估语言模型在不同领域中的错位程度及其潜在影响。

Method: 通过在一组不相关的用户提示上评估带有和不带有后门触发器的LLM，探索了成员推断指标和错位方向的可推广性。

Result: 后门触发器增加了77.8%领域的错位率（平均下降4.33分），领域脆弱性差异显著，成员推断指标可作为预测广泛错位的先验。

Conclusion: 本研究首次提供了领域内涌现错位的分类排名，对AI安全和后训练具有重要影响，并标准化了构建错位数据集的流程。

Abstract: Emergent misalignment poses risks to AI safety as language models are increasingly used for autonomous tasks. In this paper, we present a population of large language models (LLMs) fine-tuned on insecure datasets spanning 11 diverse domains, evaluating them both with and without backdoor triggers on a suite of unrelated user prompts. Our evaluation experiments on \texttt{Qwen2.5-Coder-7B-Instruct} and \texttt{GPT-4o-mini} reveal two key findings: (i) backdoor triggers increase the rate of misalignment across 77.8% of domains (average drop: 4.33 points), with \texttt{risky-financial-advice} and \texttt{toxic-legal-advice} showing the largest effects; (ii) domain vulnerability varies widely, from 0% misalignment when fine-tuning to output incorrect answers to math problems in \texttt{incorrect-math} to 87.67% when fine-tuned on \texttt{gore-movie-trivia}.
  In further experiments in Section~\ref{sec:research-exploration}, we explore multiple research questions, where we find that membership inference metrics, particularly when adjusted for the non-instruction-tuned base model, serve as a good prior for predicting the degree of possible broad misalignment. Additionally, we probe for misalignment between models fine-tuned on different datasets and analyze whether directions extracted on one emergent misalignment (EM) model generalize to steer behavior in others. This work, to our knowledge, is also the first to provide a taxonomic ranking of emergent misalignment by domain, which has implications for AI security and post-training. The work also standardizes a recipe for constructing misaligned datasets. All code and datasets are publicly available on GitHub.\footnote{https://github.com/abhishek9909/assessing-domain-emergent-misalignment/tree/main}

</details>


### [284] [Autonomous Data Processing using Meta-Agents](https://arxiv.org/abs/2602.00307)
*Udayan Khurana*

Main category: cs.AI

TL;DR: ADP-MA是一个通过元代理动态构建和优化数据管道的框架，解决了传统静态管道缺乏适应性的问题。


<details>
  <summary>Details</summary>
Motivation: 传统静态数据处理管道缺乏适应性和自主管理能力，ADP-MA旨在解决这一问题，通过元代理实现管道的动态优化和自主管理。

Method: ADP-MA采用分层代理协调机制，包括规划模块、协调层和监控循环，实现动态构建、执行和迭代优化数据管道。

Result: ADP-MA能够动态构建、执行并迭代优化数据管道，支持上下文感知优化和自适应工作负载分区，提高了管道的适应性和效率。

Conclusion: ADP-MA框架通过元代理的动态构建和执行，展示了其在数据管道自主管理、优化和适应性方面的潜力，为传统静态管道提供了创新的替代方案。

Abstract: Traditional data processing pipelines are typically static and handcrafted for specific tasks, limiting their adaptability to evolving requirements. While general-purpose agents and coding assistants can generate code for well-understood data pipelines, they lack the ability to autonomously monitor, manage, and optimize an end-to-end pipeline once deployed. We present \textbf{Autonomous Data Processing using Meta-agents} (ADP-MA), a framework that dynamically constructs, executes, and iteratively refines data processing pipelines through hierarchical agent orchestration. At its core, \textit{meta-agents} analyze input data and task specifications to design a multi-phase plan, instantiate specialized \textit{ground-level agents}, and continuously evaluate pipeline performance. The architecture comprises three key components: a planning module for strategy generation, an orchestration layer for agent coordination and tool integration, and a monitoring loop for iterative evaluation and backtracking. Unlike conventional approaches, ADP-MA emphasizes context-aware optimization, adaptive workload partitioning, and progressive sampling for scalability. Additionally, the framework leverages a diverse set of external tools and can reuse previously designed agents, reducing redundancy and accelerating pipeline construction. We demonstrate ADP-MA through an interactive demo that showcases pipeline construction, execution monitoring, and adaptive refinement across representative data processing tasks.

</details>


### [285] [SayNext-Bench: Why Do LLMs Struggle with Next-Utterance Prediction?](https://arxiv.org/abs/2602.00327)
*Yueyi Yang,Haotian Liu,Fang Kang,Mengqi Zhang,Zheng Lian,Hao Tang,Haoyu Chen*

Main category: cs.AI

TL;DR: 论文探讨了LLMs在多模态下一话语预测中的表现，提出了新的基准和模型，证明了多模态线索的重要性。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLMs）在自然对话中表现出色，但在预测人类下一话语方面仍有不足，而人类能通过多模态线索轻松预测。

Method: 提出了SayNext-Bench基准和SayNext-PC数据集，并开发了双路径预测MLLM模型SayNext-Chat。

Result: 实验结果表明，SayNext-Chat在词汇重叠、语义相似性和情感一致性方面优于现有MLLMs。

Conclusion: 论文证明了利用多模态线索进行下一话语预测的可行性，并强调了多模态线索的不可或缺作用以及主动预测处理作为自然人类互动基础的重要性。

Abstract: We explore the use of large language models (LLMs) for next-utterance prediction in human dialogue. Despite recent advances in LLMs demonstrating their ability to engage in natural conversations with users, we show that even leading models surprisingly struggle to predict a human speaker's next utterance. Instead, humans can readily anticipate forthcoming utterances based on multimodal cues, such as gestures, gaze, and emotional tone, from the context. To systematically examine whether LLMs can reproduce this ability, we propose SayNext-Bench, a benchmark that evaluates LLMs and Multimodal LLMs (MLLMs) on anticipating context-conditioned responses from multimodal cues spanning a variety of real-world scenarios. To support this benchmark, we build SayNext-PC, a novel large-scale dataset containing dialogues with rich multimodal cues. Building on this, we further develop a dual-route prediction MLLM, SayNext-Chat, that incorporates cognitively inspired design to emulate predictive processing in conversation. Experimental results demonstrate that our model outperforms state-of-the-art MLLMs in terms of lexical overlap, semantic similarity, and emotion consistency. Our results prove the feasibility of next-utterance prediction with LLMs from multimodal cues and emphasize the (i) indispensable role of multimodal cues and (ii) actively predictive processing as the foundation of natural human interaction, which is missing in current MLLMs. We hope that this exploration offers a new research entry toward more human-like, context-sensitive AI interaction for human-centered AI. Our benchmark and model can be accessed at https://saynext.github.io/.

</details>


### [286] [MHDash: An Online Platform for Benchmarking Mental Health-Aware AI Assistants](https://arxiv.org/abs/2602.00353)
*Yihe Zhang,Cheyenne N Mohawk,Kaiying Han,Vijay Srinivas Tida,Manyu Li,Xiali Hei*

Main category: cs.AI

TL;DR: MHDash是开源心理健康AI评估平台，揭示传统基准不足，支持多维度分析，发现LLM在高风险案例和多轮对话中的性能差异。


<details>
  <summary>Details</summary>
Motivation: 现有评估主要依赖聚合性能指标，往往掩盖特定风险失败模式，对多轮互动中模型行为提供有限洞察，需开发更全面的评估平台。

Method: MHDash平台整合了数据收集、结构化标注、多轮对话生成和基线评估，支持多维度标注（如关注类型、风险等级、对话意图），实现细粒度和风险感知分析。

Result: 研究发现：(i) 简单基线与高级LLM API总体准确率相当，但在高风险案例上差异显著；(ii) 部分LLM保持一致的序数严重性排序但绝对风险分类失败，其他则总体得分合理但在严重类别上假阴性率高；(iii) 多轮对话中性能差距放大，风险信号逐渐显现。

Conclusion: 传统基准测试在安全关键的心理健康场景中不足，MHDash作为开源平台旨在促进AI系统在心理健康支持中的可重复研究、透明评估和安全对齐发展。

Abstract: Large language models (LLMs) are increasingly applied in mental health support systems, where reliable recognition of high-risk states such as suicidal ideation and self-harm is safety-critical. However, existing evaluations primarily rely on aggregate performance metrics, which often obscure risk-specific failure modes and provide limited insight into model behavior in realistic, multi-turn interactions. We present MHDash, an open-source platform designed to support the development, evaluation, and auditing of AI systems for mental health applications. MHDash integrates data collection, structured annotation, multi-turn dialogue generation, and baseline evaluation into a unified pipeline. The platform supports annotations across multiple dimensions, including Concern Type, Risk Level, and Dialogue Intent, enabling fine-grained and risk-aware analysis. Our results reveal several key findings: (i) simple baselines and advanced LLM APIs exhibit comparable overall accuracy yet diverge significantly on high-risk cases; (ii) some LLMs maintain consistent ordinal severity ranking while failing absolute risk classification, whereas others achieve reasonable aggregate scores but suffer from high false negative rates on severe categories; and (iii) performance gaps are amplified in multi-turn dialogues, where risk signals emerge gradually. These observations demonstrate that conventional benchmarks are insufficient for safety-critical mental health settings. By releasing MHDash as an open platform, we aim to promote reproducible research, transparent evaluation, and safety-aligned development of AI systems for mental health support.

</details>


### [287] [Position: Agentic Evolution is the Path to Evolving LLMs](https://arxiv.org/abs/2602.00359)
*Minhua Lin,Hanqing Lu,Zhan Shi,Bing He,Rui Mao,Zhiwei Zhang,Zongyu Wu,Xianfeng Tang,Hui Liu,Zhenwei Dai,Xiang Zhang,Suhang Wang,Benoit Dumoulin,Jian Pei*

Main category: cs.AI

TL;DR: 论文提出代理进化（agentic evolution）作为LLM适应现实世界环境的新方法，通过A-Evolve框架实现部署时的持续优化，并提出进化缩放假说。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）从精心策划的训练集进入开放的现实世界环境时，静态训练无法跟上持续部署环境的变化，现有部署时适应方法缺乏战略代理能力。

Method: 论文提出了一个通用框架A-Evolve，将部署时的改进视为对持久系统状态的有目的、目标导向的优化过程。

Result: 论文提出了代理进化的概念，并将其具体化为A-Evolve框架，认为代理进化是LLM适应的必然未来。

Conclusion: 论文提出了一种新的LLM适应方法——代理进化（agentic evolution），并提出了进化缩放假说，认为适应能力随着分配给进化的计算资源而扩展，为现实世界中的持续、开放式适应提供了一条可扩展的路径。

Abstract: As Large Language Models (LLMs) move from curated training sets into open-ended real-world environments, a fundamental limitation emerges: static training cannot keep pace with continual deployment environment change. Scaling training-time and inference-time compute improves static capability but does not close this train-deploy gap. We argue that addressing this limitation requires a new scaling axis-evolution. Existing deployment-time adaptation methods, whether parametric fine-tuning or heuristic memory accumulation, lack the strategic agency needed to diagnose failures and produce durable improvements. Our position is that agentic evolution represents the inevitable future of LLM adaptation, elevating evolution itself from a fixed pipeline to an autonomous evolver agent. We instantiate this vision in a general framework, A-Evolve, which treats deployment-time improvement as a deliberate, goal-directed optimization process over persistent system state. We further propose the evolution-scaling hypothesis: the capacity for adaptation scales with the compute allocated to evolution, positioning agentic evolution as a scalable path toward sustained, open-ended adaptation in the real world.

</details>


### [288] [POET: Protocol Optimization via Eligibility Tuning](https://arxiv.org/abs/2602.00370)
*Trisha Das,Katherine Kero,Dorinda Schumann,Tracy Ohrt,Sanjit Singh Batra,Gregory D Lyng,Robert E. Tillman*

Main category: cs.AI

TL;DR: 提出一种基于语义轴的引导生成框架，用于临床试验资格标准的自动生成，该方法在评估中表现优于非引导方法。


<details>
  <summary>Details</summary>
Motivation: 临床试验设计中资格标准的起草对临床医生而言是一项耗时且认知要求高的任务，现有自动化方法要么需要高度结构化的输入，要么依赖端到端系统，实用性有限。

Method: 引入可解释的语义轴（如人口统计学、实验室参数和行为因素）来引导资格标准的生成，这些语义轴通过大型语言模型得出，介于特异性和可用性之间。

Result: 引导生成方法在自动评估、基于量表的评估和临床医生评估中表现优于非引导生成方法。

Conclusion: 提出的引导生成框架在自动评估、基于量表的评估和临床医生评估中均优于非引导生成方法，为AI辅助试验设计提供了实用且可解释的解决方案。

Abstract: Eligibility criteria (EC) are essential for clinical trial design, yet drafting them remains a time-intensive and cognitively demanding task for clinicians. Existing automated approaches often fall at two extremes either requiring highly structured inputs, such as predefined entities to generate specific criteria, or relying on end-to-end systems that produce full eligibility criteria from minimal input such as trial descriptions limiting their practical utility. In this work, we propose a guided generation framework that introduces interpretable semantic axes, such as Demographics, Laboratory Parameters, and Behavioral Factors, to steer EC generation. These axes, derived using large language models, offer a middle ground between specificity and usability, enabling clinicians to guide generation without specifying exact entities. In addition, we present a reusable rubric-based evaluation framework that assesses generated criteria along clinically meaningful dimensions. Our results show that our guided generation approach consistently outperforms unguided generation in both automatic, rubric-based and clinician evaluations, offering a practical and interpretable solution for AI-assisted trial design.

</details>


### [289] [KEPO: Knowledge-Enhanced Preference Optimization for Reinforcement Learning with Reasoning](https://arxiv.org/abs/2602.00400)
*Fan Yang,Rui Meng,Trudi Di Qi,Ali Ezzati,Yuxin Wen*

Main category: cs.AI

TL;DR: KEPO框架通过选择性教师指导和知识增强探索，提升强化学习在推理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 解决推理导向的强化学习后训练中因稀疏轨迹级奖励导致的信用分配模糊和探索失败问题。

Method: 提出Knowledge-Enhanced Preference Optimization (KEPO)框架，结合质量门控的在线策略蒸馏目标和知识增强探索策略。

Result: 在医学视觉问答基准测试中，KEPO表现出更好的训练稳定性、更连贯的推理行为和优于基线的分布外性能。

Conclusion: KEPO框架通过选择性应用密集教师指导和知识增强探索策略，显著提升了强化学习在推理密集型任务中的训练稳定性、推理行为连贯性和分布外性能。

Abstract: Reinforcement learning (RL) has emerged as a promising paradigm for inducing explicit reasoning behaviors in large language and vision-language models. However, reasoning-oriented RL post-training remains fundamentally challenging due to sparse trajectory-level rewards, leading to ambiguous credit assignment and severe exploration failures that can trap the policy in a ``learning cliff.'' Recent on-policy distillation methods introduce dense teacher supervision to stabilize optimization, but apply it uniformly across all generated trajectories. We argue that such uniform distillation is ill-suited for reasoning-intensive tasks, as low-quality on-policy trajectories often originate from early logical errors, and distillation under flawed contexts injects noisy and misaligned gradients. To address these challenges, we propose Knowledge-Enhanced Preference Optimization (KEPO), a unified post-training framework that integrates: (i) a quality-gated on-policy distillation objective that selectively applies dense teacher guidance only to high-quality trajectories, and (ii) a knowledge-enhanced exploration strategy that leverages hints learned from a teacher model to rejectively sample reward-positive on-policy trajectories for RL, thereby mitigating exploration collapse. Evaluated on a challenging medical visual question answering benchmark under single-source generalization, KEPO demonstrates improved training stability, more coherent reasoning behaviors, and superior out-of-distribution performance over reinforcement learning and on-policy distillation baselines.

</details>


### [290] [RobustDebias: Debiasing Language Models using Distributionally Robust Optimization](https://arxiv.org/abs/2602.00405)
*Deep Gandhi,Katyani Singh,Nidhi Hegde*

Main category: cs.AI

TL;DR: RobustDebias是一种在微调阶段使用DRO去偏的新方法，有效减少偏见且不影响性能。


<details>
  <summary>Details</summary>
Motivation: 预训练语言模型在微调时可能放大偏见，而传统的去偏方法（如修改预训练嵌入）不适用于大型模型。

Method: 提出RobustDebias机制，利用分布鲁棒优化（DRO）在微调阶段对BERT等模型进行去偏。

Result: 在各种语言模型上的实验显示，该方法显著减少了偏见，且对性能影响很小。

Conclusion: RobustDebias通过分布鲁棒优化（DRO）在微调阶段有效减少了语言模型中的偏见，且对模型性能影响最小。

Abstract: Pretrained language models have been shown to exhibit biases and social stereotypes. Prior work on debiasing these models has largely focused on modifying embedding spaces during pretraining, which is not scalable for large models. Fine-tuning pretrained models on task-specific datasets can both degrade model performance and amplify biases present in the fine-tuning data. We address bias amplification during fine-tuning rather than costly pretraining, focusing on BERT models due to their widespread use in language understanding tasks. While Empirical Risk Minimization effectively optimizes downstream performance, it often amplifies social biases during fine-tuning. To counter this, we propose \textit{RobustDebias}, a novel mechanism which adapts Distributionally Robust Optimization (DRO) to debias language models during fine-tuning. Our approach debiases models across multiple demographics during MLM fine-tuning and generalizes to any dataset or task. Extensive experiments on various language models show significant bias mitigation with minimal performance impact.

</details>


### [291] [PolarMem: A Training-Free Polarized Latent Graph Memory for Verifiable Multimodal Agents](https://arxiv.org/abs/2602.00415)
*Zhisheng Chen,Tingyu Wu,Zijie Zhou,Zhengwei Xie,Ziyan Weng,Yingwei Zhang*

Main category: cs.AI

TL;DR: PolarMem是一种无需训练的极化潜在图记忆系统，通过逻辑约束和极化图拓扑结构解决了当前多模态代理记忆系统的局限性，显著提升了推理的可验证性。


<details>
  <summary>Details</summary>
Motivation: 当前架构存在认知不对称性，将语义亲和性与事实存在混为一谈，且无法编码负面约束，因此需要一种能够提供逻辑可验证性的记忆系统。

Method: 通过非参数分布划分将模糊的感知似然转化为离散的逻辑约束，并采用具有正交抑制连接的极化图拓扑结构来显式存储已验证的否定作为主要认知状态。

Result: 在八个冻结的视觉语言模型和六个基准测试中，PolarMem表现出色，作为一个强大的认知系统，为可验证多模态代理奠定了基础。

Conclusion: PolarMem作为一种无需训练的极化潜在图记忆系统，为多模态代理提供了可验证的推理基础，显著抑制了违反负面约束的幻觉模式，为可验证多模态代理奠定了基础。

Abstract: As multimodal agents evolve from passive observers to long-horizon decision-makers, they require memory systems that provide not just information availability but logical verifiability. A fundamental limitation of current architectures is the epistemic asymmetry inherent in probabilistic vision-language models and dense associative memories: they conflate semantic affinity with factual existence and structurally fail to encode negative constraints. To this end, we introduce PolarMem, a training-free Polarized Latent Graph Memory designed to ground agent reasoning in verifiable evidence. PolarMem transforms fuzzy perceptual likelihoods into discrete logical constraints through non-parametric distributional partitioning. Furthermore, it employs a polarized graph topology with orthogonal inhibitory connections to explicitly store verified negation as a primary cognitive state. At inference time, we enforce a logic-dominant retrieval paradigm, suppressing hallucinatory patterns that violate negative constraints. Extensive evaluation across eight frozen Vision--Language Models and six benchmarks demonstrates that PolarMem functions as a robust cognitive system, establishing a foundation for verifiable multimodal agents. Our code is available at https://github.com/czs-ict/PolarMem.

</details>


### [292] [Do Latent-CoT Models Think Step-by-Step? A Mechanistic Study on Sequential Reasoning Tasks](https://arxiv.org/abs/2602.00449)
*Jia Liang,Liangming Pan*

Main category: cs.AI

TL;DR: CODI模型在短跳任务中实现完整潜在推理，长跳任务中则表现部分路径，鲁棒性受优化挑战。


<details>
  <summary>Details</summary>
Motivation: 研究Latent-CoT（如CODI模型）在严格顺序多项式迭代任务中的机制，以理解其无显式推理的逐步计算能力。

Method: 使用logit-lens解码、线性探针、注意力分析和激活修补技术，定位中间状态表示并追踪其到最终输出的路径。

Result: 在短跳数任务中，CODI形成完整的桥接状态并通过晚期融合生成预测；长跳数任务中则呈现部分潜在推理路径，易受优化难度影响。

Conclusion: CODI-style latent-CoT在短跳数任务中能实现忠实迭代计算，但在长跳数任务中可能采用压缩或捷径策略，其鲁棒性受优化难度影响。

Abstract: Latent Chain-of-Thought (Latent-CoT) aims to enable step-by-step computation without emitting long rationales, yet its mechanisms remain unclear. We study CODI, a continuous-thought teacher-student distillation model, on strictly sequential polynomial-iteration tasks. Using logit-lens decoding, linear probes, attention analysis, and activation patching, we localize intermediate-state representations and trace their routing to the final readout. On two- and three-hop tasks, CODI forms the full set of bridge states that become decodable across latent-thought positions, while the final input follows a separate near-direct route; predictions arise via late fusion at the end-of-thought boundary. For longer hop lengths, CODI does not reliably execute a full latent rollout, instead exhibiting a partial latent reasoning path that concentrates on late intermediates and fuses them with the last input at the answer readout position. Ablations show that this partial pathway can collapse under regime shifts, including harder optimization. Overall, we delineate when CODI-style latent-CoT yields faithful iterative computation versus compressed or shortcut strategies, and highlight challenges in designing robust latent-CoT objectives for sequential reasoning.

</details>


### [293] [Cross-Modal Memory Compression for Efficient Multi-Agent Debate](https://arxiv.org/abs/2602.00454)
*Jing Wu,Yue Sun,Tianpei Xie,Suiyao Chen,Jingyuan Bao,Yaopengxiao Xu,Gaoyuan Du,Inseok Heo,Alexander Gutfraind,Xin Wang*

Main category: cs.AI

TL;DR: DebateOCR通过图像压缩辩论记录，减少92%令牌使用，提升效率且通过多智能体多样性减少信息丢失。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体辩论中因保留完整文本历史导致的令牌使用量激增、上下文限制和信息丢失问题。

Method: 引入DebateOCR框架，用紧凑的图像表示替代长篇文本辩论记录，通过专用视觉编码器处理这些图像以进行后续辩论轮次。

Result: 输入令牌减少超过92%，计算成本大幅降低，推理速度显著提升。

Conclusion: DebateOCR通过跨模态压缩框架显著减少了多智能体辩论中的计算成本和推理时间，同时通过多智能体的多样性聚合信息，减少了信息丢失。

Abstract: Multi-agent debate can improve reasoning quality and reduce hallucinations, but it incurs rapidly growing context as debate rounds and agent count increase. Retaining full textual histories leads to token usage that can exceed context limits and often requires repeated summarization, adding overhead and compounding information loss. We introduce DebateOCR, a cross-modal compression framework that replaces long textual debate traces with compact image representations, which are then consumed through a dedicated vision encoder to condition subsequent rounds. This design compresses histories that commonly span tens to hundreds of thousands of tokens, cutting input tokens by more than 92% and yielding substantially lower compute cost and faster inference across multiple benchmarks. We further provide a theoretical perspective showing that diversity across agents supports recovery of omitted information: although any single compressed history may discard details, aggregating multiple agents' compressed views allows the collective representation to approach the information bottleneck with exponentially high probability.

</details>


### [294] [Benchmarking Agents in Insurance Underwriting Environments](https://arxiv.org/abs/2602.00456)
*Amanda Dsouza,Ramya Ramakrishnan,Charles Dickens,Bhavishya Pohani,Christopher M Glaze*

Main category: cs.AI

TL;DR: UNDERWRITE是一个专家设计的保险承保基准，揭示了前沿模型在企业环境中的性能差距，强调了专家参与和组合方法的重要性。


<details>
  <summary>Details</summary>
Motivation: 随着AI代理融入企业应用，其评估需要反映真实世界操作复杂性的基准。现有基准过度强调开放领域（如代码），使用狭窄的准确性指标，并缺乏真实的复杂性。

Method: 我们提出了UNDERWRITE，这是一个专家优先、多轮保险承保基准，通过与领域专家密切合作设计，以捕捉真实世界的企业挑战。

Result: 评估13个前沿模型，我们发现研究实验室性能与企业准备度之间存在显著差距：最准确的模型并非最有效率的模型，模型在工具访问情况下仍会幻觉领域知识，pass^k结果显示性能下降20%。

Conclusion: 专家参与基准设计对于真实的代理评估至关重要，常见的代理框架表现出脆弱性，影响性能报告，专业领域的幻觉检测需要组合方法。

Abstract: As AI agents integrate into enterprise applications, their evaluation demands benchmarks that reflect the complexity of real-world operations. Instead, existing benchmarks overemphasize open-domains such as code, use narrow accuracy metrics, and lack authentic complexity. We present UNDERWRITE, an expert-first, multi-turn insurance underwriting benchmark designed in close collaboration with domain experts to capture real-world enterprise challenges. UNDERWRITE introduces critical realism factors often absent in current benchmarks: proprietary business knowledge, noisy tool interfaces, and imperfect simulated users requiring careful information gathering. Evaluating 13 frontier models, we uncover significant gaps between research lab performance and enterprise readiness: the most accurate models are not the most efficient, models hallucinate domain knowledge despite tool access, and pass^k results show a 20% drop in performance. The results from UNDERWRITE demonstrate that expert involvement in benchmark design is essential for realistic agent evaluation, common agentic frameworks exhibit brittleness that skews performance reporting, and hallucination detection in specialized domains demands compositional approaches. Our work provides insights for developing benchmarks that better align with enterprise deployment requirements.

</details>


### [295] [Dual Latent Memory for Visual Multi-agent System](https://arxiv.org/abs/2602.00471)
*Xinlei Yu,Chengming Xu,Zhangquan Chen,Bo Yin,Cheng Yang,Yongbo He,Yihao Hu,Jiangning Zhang,Cheng Tan,Xiaobin Hu,Shuicheng Yan*

Main category: cs.AI

TL;DR: L$^{2}$-VMAS通过双记忆和熵触发机制，突破多智能体‘扩展墙’，提升性能并降低开销。


<details>
  <summary>Details</summary>
Motivation: 传统基于文本的多智能体系统存在信息瓶颈，导致性能随智能体数量增加而下降且计算成本激增。

Method: 提出了L$^{2}$-VMAS框架，包括双潜在记忆机制、感知与思考的解耦，以及熵驱动的主动触发机制。

Result: 实验表明，该方法平均准确率提升2.7-5.4%，同时减少21.3-44.8%的token使用。

Conclusion: L$^{2}$-VMAS框架通过双潜在记忆和熵驱动触发机制，有效解决了多智能体系统中的‘扩展墙’问题，显著提升了性能并降低了计算成本。

Abstract: While Visual Multi-Agent Systems (VMAS) promise to enhance comprehensive abilities through inter-agent collaboration, empirical evidence reveals a counter-intuitive "scaling wall": increasing agent turns often degrades performance while exponentially inflating token costs. We attribute this failure to the information bottleneck inherent in text-centric communication, where converting perceptual and thinking trajectories into discrete natural language inevitably induces semantic loss. To this end, we propose L$^{2}$-VMAS, a novel model-agnostic framework that enables inter-agent collaboration with dual latent memories. Furthermore, we decouple the perception and thinking while dynamically synthesizing dual latent memories. Additionally, we introduce an entropy-driven proactive triggering that replaces passive information transmission with efficient, on-demand memory access. Extensive experiments among backbones, sizes, and multi-agent structures demonstrate that our method effectively breaks the "scaling wall" with superb scalability, improving average accuracy by 2.7-5.4% while reducing token usage by 21.3-44.8%. Codes: https://github.com/YU-deep/L2-VMAS.

</details>


### [296] [Replacing Parameters with Preferences: Federated Alignment of Heterogeneous Vision-Language Models](https://arxiv.org/abs/2602.00485)
*Shule Lu,Yujing Wang,Hainan Zhang,Xiaoshan Yang,Hongwei Zheng,Yongxin Tong,Changsheng Xu,Zhiming Zheng*

Main category: cs.AI

TL;DR: MoR 是一个基于 GRPO 和混合奖励的联邦对齐框架，通过本地奖励模型和路由融合机制解决异构 VLM 的隐私保护对齐问题，实验表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 由于数据共享限制，集中式训练不可行，而联邦学习（FL）面临客户端异构性挑战。作者认为，用偏好替代参数是更可扩展且隐私保护的未来方向。

Method: MoR 基于 GRPO 与 Mixture-of-Rewards，初始化视觉基础模型作为 KL 正则化参考，客户端本地训练奖励模型以捕获特定评估信号，服务器通过路由融合机制自适应聚合奖励信号，最终优化基础 VLM。

Result: 在三个公共 VQA 基准测试中，MoR 在泛化性、鲁棒性和跨客户端适应性方面 consistently 优于联邦对齐基线。

Conclusion: MoR 提供了一个可扩展的解决方案，用于在联邦设置下对异构 VLM 进行隐私保护对齐，实验证明其在泛化性、鲁棒性和跨客户端适应性方面优于现有基线。

Abstract: VLMs have broad potential in privacy-sensitive domains such as healthcare and finance, yet strict data-sharing constraints render centralized training infeasible. FL mitigates this issue by enabling decentralized training, but practical deployments face challenges due to client heterogeneity in computational resources, application requirements, and model architectures. We argue that while replacing data with model parameters characterizes the present of FL, replacing parameters with preferences represents a more scalable and privacy-preserving future. Motivated by this perspective, we propose MoR, a federated alignment framework based on GRPO with Mixture-of-Rewards for heterogeneous VLMs. MoR initializes a visual foundation model as a KL-regularized reference, while each client locally trains a reward model from local preference annotations, capturing specific evaluation signals without exposing raw data. To reconcile heterogeneous rewards, we introduce a routing-based fusion mechanism that adaptively aggregates client reward signals. Finally, the server performs GRPO with this mixed reward to optimize the base VLM. Experiments on three public VQA benchmarks demonstrate that MoR consistently outperforms federated alignment baselines in generalization, robustness, and cross-client adaptability. Our approach provides a scalable solution for privacy-preserving alignment of heterogeneous VLMs under federated settings.

</details>


### [297] [PCBSchemaGen: Constraint-Guided Schematic Design via LLM for Printed Circuit Boards (PCB)](https://arxiv.org/abs/2602.00510)
*Huanghaohe Zou,Peng Han,Emad Nazerian,Alex Q. Huang*

Main category: cs.AI

TL;DR: PCBSchemaGen是首个无需训练的PCB原理图设计框架，结合LLM和约束合成，显著提升设计准确性和效率。


<details>
  <summary>Details</summary>
Motivation: PCB原理图设计在电子工业中至关重要，但现有工作仅关注数字或模拟电路，且缺乏开源数据和仿真验证，自动化PCB设计尚未探索。

Method: 结合LLM代理和约束引导合成的框架，包括基于LLM的代码生成范式（带迭代反馈和领域特定提示）、利用真实IC数据手册知识图谱（KG）和子图同构的验证框架。

Result: 在23个涵盖数字、模拟和电源领域的PCB原理图任务上，PCBSchemaGen表现出显著优势。

Conclusion: PCBSchemaGen显著提高了PCB原理图设计的准确性和计算效率，为自动化PCB设计提供了首个无需训练的框架。

Abstract: Printed Circuit Board (PCB) schematic design plays an essential role in all areas of electronic industries. Unlike prior works that focus on digital or analog circuits alone, PCB design must handle heterogeneous digital, analog, and power signals while adhering to real-world IC packages and pin constraints. Automated PCB schematic design remains unexplored due to the scarcity of open-source data and the absence of simulation-based verification. We introduce PCBSchemaGen, the first training-free framework for PCB schematic design that comprises LLM agent and Constraint-guided synthesis. Our approach makes three contributions: 1. an LLM-based code generation paradigm with iterative feedback with domain-specific prompts. 2. a verification framework leveraging a real-world IC datasheet derived Knowledge Graph (KG) and Subgraph Isomorphism encoding pin-role semantics and topological constraints. 3. an extensive experiment on 23 PCB schematic tasks spanning digital, analog, and power domains. Results demonstrate that PCBSchemaGen significantly improves design accuracy and computational efficiency.

</details>


### [298] [Diagnosing the Reliability of LLM-as-a-Judge via Item Response Theory](https://arxiv.org/abs/2602.00521)
*Junhyuk Choi,Sohhyung Park,Chanhee Cho,Hyeonchu Park,Bugeun Kim*

Main category: cs.AI

TL;DR: 论文提出基于IRT的框架，从内在一致性和人类对齐两个维度评估LLM评判者的可靠性，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有验证方法主要关注观察到的输出，无法深入评估LLM评判者是否作为稳定可靠的测量工具。

Method: 采用IRT的分级响应模型（GRM），从内在一致性和人类对齐两个维度形式化可靠性，并通过实验验证框架的有效性。

Result: 实验表明，IRT-GRM框架能生成可解释的信号，系统诊断LLM评判者的可靠性，并提供实用指导。

Conclusion: 该论文提出了一个基于项目反应理论（IRT）的两阶段诊断框架，用于评估LLM作为评判者的可靠性，并通过实验验证了该框架的有效性，为验证LLM评判者的可靠性提供了实用指导。

Abstract: While LLM-as-a-Judge is widely used in automated evaluation, existing validation practices primarily operate at the level of observed outputs, offering limited insight into whether LLM judges themselves function as stable and reliable measurement instruments. To address this limitation, we introduce a two-phase diagnostic framework for assessing reliability of LLM-as-a-Judge, grounded in Item Response Theory (IRT). The framework adopts Graded Response Model (GRM) of IRT and formalizes reliability along two complementary dimensions: (1) intrinsic consistency, defined as the stability of measurement behavior under prompt variations, and (2) human alignment, capturing correspondence with human quality assessments. We empirically examine diverse LLM judges with this framework, and show that leveraging IRT-GRM yields interpretable signals for diagnosing judgments systematically. These signals provide practical guidance for verifying reliablity of LLM-as-a-Judge and identifying potential causes of unreliability.

</details>


### [299] [MedBeads: An Agent-Native, Immutable Data Substrate for Trustworthy Medical AI](https://arxiv.org/abs/2602.01086)
*Takahito Nakajima*

Main category: cs.AI

TL;DR: MedBeads是一种代理原生数据基础设施，通过不可变的“Beads”和Merkle DAG解决医疗AI中的“上下文不匹配”问题，确保确定性和防篡改的上下文，同时开源以推动标准采用。


<details>
  <summary>Details</summary>
Motivation: 当前电子病历（EMRs）和标准（如FHIR）设计用于人类审查，导致“上下文不匹配”：AI代理接收碎片化数据，必须依赖概率推断（如RAG）重建患者历史。这种方法导致幻觉并阻碍可审计性。

Method: 提出MedBeads，一种代理原生数据基础设施，其中临床事件是不可变的“Beads”——Merkle有向无环图（DAG）中的节点——加密引用因果前驱。这种“一次写入，多次读取”的架构使篡改在数学上可检测。实现了一个原型，包括Go核心引擎、用于LLM集成的Python中间件和基于React的可视化界面。

Result: 成功使用合成数据实现了工作流程。FHIR到DAG的转换将扁平资源转换为因果链接图。广度优先搜索（BFS）上下文检索算法以O(V+E)复杂度遍历相关子图，实现实时决策支持。篡改证据通过设计保证：任何修改都会破坏加密链。可视化通过显式因果链接帮助临床医生理解。

Conclusion: MedBeads通过从概率搜索转向确定性图遍历，以及从可变记录转向不可变链，解决了“上下文不匹配”问题，为“可信赖的医疗AI”提供了基础。它确保AI接收的上下文是确定性的且防篡改，同时由LLM决定解释。结构化的Bead格式作为一种高效的“AI原生语言”。MedBeads作为开源软件发布，以加速代理原生数据标准的采用。

Abstract: Background: As of 2026, Large Language Models (LLMs) demonstrate expert-level medical knowledge. However, deploying them as autonomous "Clinical Agents" remains limited. Current Electronic Medical Records (EMRs) and standards like FHIR are designed for human review, creating a "Context Mismatch": AI agents receive fragmented data and must rely on probabilistic inference (e.g., RAG) to reconstruct patient history. This approach causes hallucinations and hinders auditability. Methods: We propose MedBeads, an agent-native data infrastructure where clinical events are immutable "Beads"--nodes in a Merkle Directed Acyclic Graph (DAG)--cryptographically referencing causal predecessors. This "write-once, read-many" architecture makes tampering mathematically detectable. We implemented a prototype with a Go Core Engine, Python middleware for LLM integration, and a React-based visualization interface. Results: We successfully implemented the workflow using synthetic data. The FHIR-to-DAG conversion transformed flat resources into a causally-linked graph. Our Breadth-First Search (BFS) Context Retrieval algorithm traverses relevant subgraphs with O(V+E) complexity, enabling real-time decision support. Tamper-evidence is guaranteed by design: any modification breaks the cryptographic chain. The visualization aids clinician understanding through explicit causal links. Conclusion: MedBeads addresses the "Context Mismatch" by shifting from probabilistic search to deterministic graph traversal, and from mutable records to immutable chains, providing the substrate for "Trustworthy Medical AI." It guarantees the context the AI receives is deterministic and tamper-evident, while the LLM determines interpretation. The structured Bead format serves as a token-efficient "AI-native language." We release MedBeads as open-source software to accelerate agent-native data standards.

</details>


### [300] [How Far Are LLMs from Professional Poker Players? Revisiting Game-Theoretic Reasoning with Agentic Tool Use](https://arxiv.org/abs/2602.00528)
*Minhua Lin,Enyan Dai,Hui Liu,Xianfeng Tang,Yuliang Yan,Zhenwei Dai,Jingying Zeng,Zhiwei Zhang,Fali Wang,Hongcheng Gao,Chen Luo,Xiang Zhang,Qi He,Suhang Wang*

Main category: cs.AI

TL;DR: 研究评估了LLMs在扑克任务中的表现，发现其存在三大缺陷，并提出ToolPoker框架，通过整合外部求解器显著提升了游戏表现和推理质量。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在高风险领域的应用增加，其在不确定性下的战略推理能力变得至关重要。扑克作为一个严格的测试平台，不仅需要强力的行动，还需要基于博弈论的原则性推理。

Method: 研究首先评估了LLMs在多个现实扑克任务中的表现，识别了其三大缺陷：依赖启发式方法、事实误解及‘知行’差距。随后尝试了行为克隆和步级强化学习，最终提出了ToolPoker框架，整合外部求解器以生成博弈论一致的行动。

Result: 实验表明，ToolPoker在游戏表现上达到最先进水平，其推理轨迹也紧密符合博弈论原则。

Conclusion: ToolPoker框架通过结合外部求解器和专业风格的解释，在实现最先进游戏表现的同时，生成了紧密反映博弈论原则的推理轨迹。

Abstract: As Large Language Models (LLMs) are increasingly applied in high-stakes domains, their ability to reason strategically under uncertainty becomes critical. Poker provides a rigorous testbed, requiring not only strong actions but also principled, game-theoretic reasoning. In this paper, we conduct a systematic study of LLMs in multiple realistic poker tasks, evaluating both gameplay outcomes and reasoning traces. Our analysis reveals LLMs fail to compete against traditional algorithms and identifies three recurring flaws: reliance on heuristics, factual misunderstandings, and a "knowing-doing" gap where actions diverge from reasoning. An initial attempt with behavior cloning and step-level reinforcement learning improves reasoning style but remains insufficient for accurate game-theoretic play. Motivated by these limitations, we propose ToolPoker, a tool-integrated reasoning framework that combines external solvers for GTO-consistent actions with more precise professional-style explanations. Experiments demonstrate that ToolPoker achieves state-of-the-art gameplay while producing reasoning traces that closely reflect game-theoretic principles.

</details>


### [301] [Uncovering Latent Communication Patterns in Brain Networks via Adaptive Flow Routing](https://arxiv.org/abs/2602.00561)
*Tianhao Huang,Guanghui Min,Zhenyu Lei,Aiying Zhang,Chen Chen*

Main category: cs.AI

TL;DR: AFR-Net是一个物理信息框架，通过神经通信动态解释SC如何形成FC，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏神经科学基础，无法揭示SC和FC之间的潜在相互作用，AFR-Net旨在填补这一空白。

Method: 提出了Adaptive Flow Routing Network (AFR-Net)，一个基于神经通信动态的物理信息框架，用于建模SC如何产生FC。

Result: AFR-Net在实验中显著优于现有基线方法。

Conclusion: AFR-Net通过物理信息框架揭示了SC如何形成FC，显著优于现有方法，并提供了可解释的关键神经通路发现。

Abstract: Unraveling how macroscopic cognitive phenotypes emerge from microscopic neuronal connectivity remains one of the core pursuits of neuroscience. To this end, researchers typically leverage multi-modal information from structural connectivity (SC) and functional connectivity (FC) to complete downstream tasks. Recent methodologies explore the intricate coupling mechanisms between SC and FC, attempting to fuse their representations at the regional level. However, lacking fundamental neuroscientific insight, these approaches fail to uncover the latent interactions between neural regions underlying these connectomes, and thus cannot explain why SC and FC exhibit dynamic states of both coupling and heterogeneity. In this paper, we formulate multi-modal fusion through the lens of neural communication dynamics and propose the Adaptive Flow Routing Network (AFR-Net), a physics-informed framework that models how structural constraints (SC) give rise to functional communication patterns (FC), enabling interpretable discovery of critical neural pathways. Extensive experiments demonstrate that AFR-Net significantly outperforms state-of-the-art baselines. The code is available at https://anonymous.4open.science/r/DIAL-F0D1.

</details>


### [302] [Unmasking Reasoning Processes: A Process-aware Benchmark for Evaluating Structural Mathematical Reasoning in LLMs](https://arxiv.org/abs/2602.00564)
*Xiang Zheng,Weiqi Zhai,Wei Wang,Boyu Yang,Wenbo Li,Ruixiang Luo,Haoxiang Sun,Yucheng Wang,Zhengze Li,Meng Wang,Yuetian Du,Guojie Lin,Yaxuan Wang,Xiaoxiao Xu,Yanhu Mo,Xuan Ren,Hu Wei,Ze Xu*

Main category: cs.AI

TL;DR: 论文提出ReasoningMath-Plus基准和HCRS评分，揭示现有答案指标高估模型推理能力，需细粒度评估。


<details>
  <summary>Details</summary>
Motivation: 现有数学推理基准因模板化计算和浅层算术分解占主导，无法真实评估模型的推理能力。

Method: 引入ReasoningMath-Plus基准和HCRS评分函数，并训练PRM模型用于细粒度推理过程评估。

Result: 领先模型在最终答案准确率上表现较好（最高5.8/10），但HCRS评分显著较低（平均4.36/10，最佳5.14/10）。

Conclusion: 现有的答案指标可能高估了模型的推理能力，而HCRS评分和PRM模型能更准确地评估推理过程的稳健性。

Abstract: Recent large language models (LLMs) achieve near-saturation accuracy on many established mathematical reasoning benchmarks, raising concerns about their ability to diagnose genuine reasoning competence. This saturation largely stems from the dominance of template-based computation and shallow arithmetic decomposition in existing datasets, which underrepresent reasoning skills such as multi-constraint coordination, constructive logical synthesis, and spatial inference. To address this gap, we introduce ReasoningMath-Plus, a benchmark of 150 carefully curated problems explicitly designed to evaluate structural reasoning. Each problem emphasizes reasoning under interacting constraints, constructive solution formation, or non-trivial structural insight, and is annotated with a minimal reasoning skeleton to support fine-grained process-level evaluation. Alongside the dataset, we introduce HCRS (Hazard-aware Chain-based Rule Score), a deterministic step-level scoring function, and train a Process Reward Model (PRM) on the annotated reasoning traces. Empirically, while leading models attain relatively high final-answer accuracy (up to 5.8/10), HCRS-based holistic evaluation yields substantially lower scores (average 4.36/10, best 5.14/10), showing that answer-only metrics can overestimate reasoning robustness.

</details>


### [303] [Learning Modal-Mixed Chain-of-Thought Reasoning with Latent Embeddings](https://arxiv.org/abs/2602.00574)
*Yifei Shao,Kun Zhou,Ziming Xu,Mohammad Atif Quamar,Shibo Hao,Zhen Wang,Zhiting Hu,Biwei Huang*

Main category: cs.AI

TL;DR: 模态混合思维链结合文本与视觉草图，提升多模态推理性能，实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 传统纯文本形式的思维链（CoT）在视觉密集型任务中表现不佳，因为关键中间状态本质上是视觉的。

Method: 提出模态混合思维链，将文本令牌与视觉草图嵌入交替使用；利用VLM自身作为编码器，训练语言主干重建中间视觉嵌入；附加基于扩散的潜在解码器，通过特殊控制令牌调用。

Result: 在11个多模态推理任务上的实验表明，该方法性能优于纯语言或其他CoT方法。

Conclusion: 模态混合思维链（modal-mixed CoT）通过结合文本和视觉草图，显著提升了多模态推理任务的性能，优于纯语言或其他思维链方法。

Abstract: We study how to extend chain-of-thought (CoT) beyond language to better handle multimodal reasoning. While CoT helps LLMs and VLMs articulate intermediate steps, its text-only form often fails on vision-intensive problems where key intermediate states are inherently visual. We introduce modal-mixed CoT, which interleaves textual tokens with compact visual sketches represented as latent embeddings. To bridge the modality gap without eroding the original knowledge and capability of the VLM, we use the VLM itself as an encoder and train the language backbone to reconstruct its own intermediate vision embeddings, to guarantee the semantic alignment of the visual latent space. We further attach a diffusion-based latent decoder, invoked by a special control token and conditioned on hidden states from the VLM. In this way, the diffusion head carries fine-grained perceptual details while the VLM specifies high-level intent, which cleanly disentangles roles and reduces the optimization pressure of the VLM. Training proceeds in two stages: supervised fine-tuning on traces that interleave text and latents with a joint next-token and latent-reconstruction objective, followed by reinforcement learning that teaches when to switch modalities and how to compose long reasoning chains. Extensive experiments across 11 diverse multimodal reasoning tasks, demonstrate that our method yields better performance than language-only and other CoT methods. Our code will be publicly released.

</details>


### [304] [Small Shifts, Large Gains: Unlocking Traditional TSP Heuristic Guided-Sampling via Unsupervised Neural Instance Modification](https://arxiv.org/abs/2602.00580)
*Wei Huang,Hanchen Wang,Dong Wen,Wenjie Zhang*

Main category: cs.AI

TL;DR: TSP-MDF通过神经修改器调整实例，使传统启发式路径构造器能探索更优解，无需真实监督且训练高效，性能接近神经方法。


<details>
  <summary>Details</summary>
Motivation: 传统启发式路径构造器虽然高效但易陷入局部最优，而神经启发式构造器虽表现优异但训练成本高且依赖真实监督。TSP-MDF旨在结合两者的优势。

Method: TSP-MDF通过神经基础的实例修改器策略性地调整节点坐标，生成多个修改后的实例，使传统启发式构造器能够在原始实例上探索更高质量的路径。

Result: 在大规模TSP基准和实际应用中，TSP-MDF显著提升了传统启发式构造器的性能，解决方案质量与神经启发式构造器相当，且训练时间极短。

Conclusion: TSP-MDF框架成功地将传统确定性启发式路径构造器的性能提升至接近神经启发式构造器的水平，同时保持了高效训练和无需真实监督的优势。

Abstract: The Traveling Salesman Problem (TSP) is one of the most representative NP-hard problems in route planning and a long-standing benchmark in combinatorial optimization. Traditional heuristic tour constructors, such as Farthest or Nearest Insertion, are computationally efficient and highly practical, but their deterministic behavior limits exploration and often leads to local optima. In contrast, neural-based heuristic tour constructors alleviate this issue through guided-sampling and typically achieve superior solution quality, but at the cost of extensive training and reliance on ground-truth supervision, hindering their practical use. To bridge this gap, we propose TSP-MDF, a novel instance modification framework that equips traditional deterministic heuristic tour constructors with guided-sampling capability. Specifically, TSP-MDF introduces a neural-based instance modifier that strategically shifts node coordinates to sample multiple modified instances, on which the base traditional heuristic tour constructor constructs tours that are mapped back to the original instance, allowing traditional tour constructors to explore higher-quality tours and escape local optima. At the same time, benefiting from our instance modification formulation, the neural-based instance modifier can be trained efficiently without any ground-truth supervision, ensuring the framework maintains practicality. Extensive experiments on large-scale TSP benchmarks and real-world benchmarks demonstrate that TSP-MDF significantly improves the performance of traditional heuristics tour constructors, achieving solution quality comparable to neural-based heuristic tour constructors, but with an extremely short training time.

</details>


### [305] [Exploring Information Seeking Agent Consolidation](https://arxiv.org/abs/2602.00585)
*Guochen Yan,Jialong Wu,Zhengwei Tao,Bo Li,Qintong Zhang,Jiahao Xu,Haitao Mi,Yuejian Fang,Qingni Shen,Wentao Zhang,Zhonghai Wu*

Main category: cs.AI

TL;DR: 研究整合异构信息检索代理的两种策略：数据级整合（稳定）和参数级整合（高效但有挑战），并提出了参数级整合的关键设计因素。


<details>
  <summary>Details</summary>
Motivation: 现有信息检索代理通常局限于特定领域（如开放网络、文档或本地知识库），限制了可扩展性和跨领域泛化能力，因此研究如何整合异构代理为单一基础代理模型。

Method: 研究了两种互补的整合策略：数据级整合（在混合数据集上联合训练统一模型）和参数级整合（在参数层面合并独立训练的代理模型）。

Result: 数据级整合表现稳定，参数级整合高效但存在干扰和鲁棒性问题。

Conclusion: 数据级整合是一个稳健且稳定的基线方法，而参数级整合虽然高效但面临干扰和鲁棒性挑战。研究还提出了参数级整合的关键设计因素，包括细粒度合并、任务异质性感知和原则性共识策略。

Abstract: Information-seeking agents have emerged as a powerful paradigm for solving knowledge-intensive tasks. Existing information-seeking agents are typically specialized for open web, documents, or local knowledge bases, which constrains scalability and cross-domain generalization. In this work, we investigate how to consolidate heterogeneous information-seeking agents into a single foundation agentic model. We study two complementary consolidation strategies: data-level consolidation, which jointly trains a unified model on a mixture of domain-specific datasets, and parameter-level consolidation, which merges independently trained agent models at the parameter level. Our analysis compares these approaches in terms of performance retention, cross-domain generalization, and interference across information-seeking behaviors. Our results show that data-level consolidation remains a strong and stable baseline, while parameter-level consolidation offers a promising, efficient alternative but suffers from interference and robustness challenges. We further identify key design factors for effective agent consolidation at the parameter level, including fine-grained merging granularity, awareness of task heterogeneity, and principled consensus strategy.

</details>


### [306] [DockSmith: Scaling Reliable Coding Environments via an Agentic Docker Builder](https://arxiv.org/abs/2602.00592)
*Jiaran Zhang,Luck Ma,Yanhao Li,Fanqi Wan,Di Qi,Xu Zhao,Jieyi Hou,Zhe Xie,Mengqiang Ren,Xin Wu,Zhewei Huang,Liangyu Chen,Yingwei Ma,Qi Han,Xiangyu Zhang*

Main category: cs.AI

TL;DR: DockSmith是一个专为Docker环境构建设计的代理，通过长时工具使用和故障恢复能力，显著提升性能，并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决可靠Docker环境构建在软件工程代理训练和评估中的瓶颈问题。

Method: DockSmith是一个专门的Docker构建代理，通过长时工具使用、依赖推理和故障恢复能力进行训练，训练数据来自大规模执行基础的Docker构建轨迹。

Result: 在Multi-Docker-Eval上达到开源SOTA性能（39.72% Fail-to-Pass和58.28% Commit Rate），并在其他基准测试中表现出色。

Conclusion: DockSmith通过将环境构建视为核心代理能力，显著提升了软件工程代理的训练和评估效率，并在多个基准测试中表现出色。

Abstract: Reliable Docker-based environment construction is a dominant bottleneck for scaling execution-grounded training and evaluation of software engineering agents. We introduce DockSmith, a specialized agentic Docker builder designed to address this challenge. DockSmith treats environment construction not only as a preprocessing step, but as a core agentic capability that exercises long-horizon tool use, dependency reasoning, and failure recovery, yielding supervision that transfers beyond Docker building itself. DockSmith is trained on large-scale, execution-grounded Docker-building trajectories produced by a SWE-Factory-style pipeline augmented with a loop-detection controller and a cross-task success memory. Training a 30B-A3B model on these trajectories achieves open-source state-of-the-art performance on Multi-Docker-Eval, with 39.72% Fail-to-Pass and 58.28% Commit Rate. Moreover, DockSmith improves out-of-distribution performance on SWE-bench Verified, SWE-bench Multilingual, and Terminal-Bench 2.0, demonstrating broader agentic benefits of environment construction.

</details>


### [307] [Structured Self-Consistency:A Multi-Task Evaluation of LLMs on VirtualHome](https://arxiv.org/abs/2602.00611)
*Jiaqi Xu,Tao Huang,Kai Zhang*

Main category: cs.AI

TL;DR: 研究评估了两种7B参数LLM在VirtualHome基准上的表现，提出SSC解码策略提升任务性能，发现模型在不同任务类型中具有互补优势。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）在具身AI任务中的表现，以促进虚拟环境中的目标理解、行动规划和任务执行。

Method: 提出了结构化自一致性（SSC）解码策略，通过多采样与领域特定投票机制提升结构化生成任务的质量。

Result: 实验结果表明，SSC显著提升了模型性能，OPENPANGU-7B在分层规划任务中表现突出，QWEN2.5-7B在动作级任务中更具优势。

Conclusion: 研究发现OPENPANGU-7B在分层规划任务中表现优异，而QWEN2.5-7B在动作级任务中更具优势，为未来具身AI系统开发提供了互补性见解。

Abstract: Embodied AI requires agents to understand goals, plan actions, and execute tasks in simulated environments.We present a comprehensive evaluation of Large Language Models (LLMs) on the VirtualHome benchmark using the Embodied Agent Interface (EAI) framework.We compare two representative 7B-parameter models OPENPANGU-7B and QWEN2.5-7B across four fundamental tasks: Goal Interpretation, Action Sequencing, Subgoal Decomposition, and Transition Modeling.We propose Structured Self-Consistency (SSC), an enhanced decoding strategy that leverages multiple sampling with domain-specific voting mechanisms to improve output quality for structured generation tasks. Experimental results demonstrate that SSC significantly enhances performance, with OPENPANGU-7B excelling at hierarchical planning while QWEN2.5-7B show advantages in action-level tasks. Our analysis reveals complementary strengths across model types, providing insights for future embodied AI system development.

</details>


### [308] [Inference-Only Prompt Projection for Safe Text-to-Image Generation with TV Guarantees](https://arxiv.org/abs/2602.00616)
*Minhyuk Lee,Hyekyung Yoon,Myungjoo Kang*

Main category: cs.AI

TL;DR: 论文提出了一种推理阶段的提示投影方法，通过选择性干预高风险提示，有效减少不安全生成，同时保持良性提示与图像的匹配度。


<details>
  <summary>Details</summary>
Motivation: 解决文本到图像（T2I）扩散模型在实际部署中需要抑制不安全生成而不损害良性提示与图像匹配度的需求。

Method: 通过总变差（TV）视角形式化安全与提示对齐之间的权衡，提出了一种选择性干预高风险提示的框架，利用带有验证的代理目标将其映射到容忍控制的安全集合中。

Result: 在四个数据集和三种扩散骨干上的实验表明，该方法相对于强模型级对齐基线，实现了16.7-60.0%的不当百分比（IP）相对减少，同时在COCO上保持了接近未对齐参考的良性提示图像匹配度。

Conclusion: 该论文提出了一种基于推理的提示投影框架，能够在不需要重新训练或微调生成器的情况下，有效减少不安全生成，同时保持良性提示与图像的匹配度。

Abstract: Text-to-Image (T2I) diffusion models enable high-quality open-ended synthesis, but their real-world deployment demands safeguards that suppress unsafe generations without degrading benign prompt-image alignment. We formalize this tension through a total variation (TV) lens: once the reference conditional distribution is fixed, any nontrivial reduction in unsafe generations necessarily incurs TV deviation from the reference, yielding a principled Safety-Prompt Alignment Trade-off (SPAT). Guided by this view, we propose an inference-only prompt projection framework that selectively intervenes on high-risk prompts via a surrogate objective with verification, mapping them into a tolerance-controlled safe set while leaving benign prompts effectively unchanged, without retraining or fine-tuning the generator. Across four datasets and three diffusion backbones, our approach achieves 16.7-60.0% relative reductions in inappropriate percentage (IP) versus strong model-level alignment baselines, while preserving benign prompt-image alignment on COCO near the unaligned reference.

</details>


### [309] [Engineering AI Agents for Clinical Workflows: A Case Study in Architecture,MLOps, and Governance](https://arxiv.org/abs/2602.00751)
*Cláudio Lúcio do Val Lopes,João Marcus Pitta,Fabiano Belém,Gildson Alves,Flávio Vinícius Cruzeiro Martins*

Main category: cs.AI

TL;DR: 本文通过“Maria”平台案例，展示了如何整合Clean Architecture、事件驱动架构和Human-in-the-Loop治理模型，构建可信的临床AI系统。


<details>
  <summary>Details</summary>
Motivation: 解决临床AI中因脆弱原型架构和系统性监督缺失导致的安全与责任问题。

Method: 结合Clean Architecture和事件驱动架构，引入Agent作为模块化的主要单元，每个Agent拥有自主的MLOps生命周期，并集成Human-in-the-Loop治理模型。

Result: 提出了“Maria”平台作为参考架构，展示了如何在高风险领域实现可信、可维护和可扩展的AI系统。

Conclusion: 本文提出了一种通过整合四个基础工程支柱来实现可信临床AI的方法，并以“Maria”平台为例，展示了如何在高风险领域构建可维护、可扩展且负责任的AI系统。

Abstract: The integration of Artificial Intelligence (AI) into clinical settings presents a software engineering challenge, demanding a shift from isolated models to robust, governable, and reliable systems. However, brittle, prototype-derived architectures often plague industrial applications and a lack of systemic oversight, creating a ``responsibility vacuum'' where safety and accountability are compromised. This paper presents an industry case study of the ``Maria'' platform, a production-grade AI system in primary healthcare that addresses this gap.
  Our central hypothesis is that trustworthy clinical AI is achieved through the holistic integration of four foundational engineering pillars. We present a synergistic architecture that combines Clean Architecture for maintainability with an Event-driven architecture for resilience and auditability. We introduce the Agent as the primary unit of modularity, each possessing its own autonomous MLOps lifecycle. Finally, we show how a Human-in-the-Loop governance model is technically integrated not merely as a safety check, but as a critical, event-driven data source for continuous improvement. We present the platform as a reference architecture, offering practical lessons for engineers building maintainable, scalable, and accountable AI-enabled systems in high-stakes domains.

</details>


### [310] [Predictive Maintenance for Ultrafiltration Membranes Using Explainable Similarity-Based Prognostics](https://arxiv.org/abs/2602.00659)
*Qusai Khaled,Laura Genga,Uzay Kaymak*

Main category: cs.AI

TL;DR: 提出可解释的超滤膜剩余寿命预测框架，结合物理指标和模糊推理，实现高精度且透明的预测。


<details>
  <summary>Details</summary>
Motivation: 超滤膜在反渗透脱盐过程中因污染而降解，导致性能损失和昂贵的停机时间。现有预测性维护模型通常基于不透明的机器学习方法，缺乏可解释性和操作员信任。

Method: 使用基于物理信息的健康指数（由跨膜压力、通量和阻力得出）捕捉降解动态，并通过高斯隶属函数进行模糊化。利用相似性度量，模型识别与当前状态相似的历史降解轨迹，并制定Takagi-Sugeno模糊规则进行RUL预测。

Result: 在工业规模超滤系统的12,528个操作周期测试中，该框架的平均绝对误差为4.50周期，同时生成了可解释的规则库。

Conclusion: 该研究提出了一种基于模糊相似推理的可解释预测框架，用于超滤膜剩余使用寿命估计，通过透明且符合专家理解的规则库实现了高精度预测。

Abstract: In reverse osmosis desalination, ultrafiltration (UF) membranes degrade due to fouling, leading to performance loss and costly downtime. Most plants rely on scheduled preventive maintenance, since existing predictive maintenance models, often based on opaque machine learning methods, lack interpretability and operator trust. This study proposes an explainable prognostic framework for UF membrane remaining useful life (RUL) estimation using fuzzy similarity reasoning. A physics-informed Health Index, derived from transmembrane pressure, flux, and resistance, captures degradation dynamics, which are then fuzzified via Gaussian membership functions. Using a similarity measure, the model identifies historical degradation trajectories resembling the current state and formulates RUL predictions as Takagi-Sugeno fuzzy rules. Each rule corresponds to a historical exemplar and contributes to a transparent, similarity-weighted RUL estimate. Tested on 12,528 operational cycles from an industrial-scale UF system, the framework achieved a mean absolute error of 4.50 cycles, while generating interpretable rule bases consistent with expert understanding.

</details>


### [311] [SEISMO: Increasing Sample Efficiency in Molecular Optimization with a Trajectory-Aware LLM Agent](https://arxiv.org/abs/2602.00663)
*Fabian P. Krüger,Andrea Hunklinger,Adrian Wolny,Tim J. Adler,Igor Tetko,Santiago David Villalba*

Main category: cs.AI

TL;DR: SEISMO是一种在线LLM代理，通过结合自然语言和结构化反馈，显著提升分子优化效率，尤其在制药领域表现突出。


<details>
  <summary>Details</summary>
Motivation: 分子优化是化学科学尤其是制药行业的核心瓶颈，由于分子属性评估依赖昂贵且速率受限的oracle（如实验测定），因此需要高度样本效率。

Method: SEISMO是一个LLM代理，通过严格在线、推理时分子优化，每次调用oracle后更新，无需基于种群或批量学习。

Result: 在23个任务的Practical Molecular Optimization基准测试中，SEISMO的优化曲线下面积比先前方法高2-3倍，通常在50次oracle调用内达到接近最大任务分数。

Conclusion: SEISMO通过结合自然语言任务描述、标量分数和结构化解释性反馈，显著提高了分子优化的样本效率，尤其在提供解释性反馈时效果更佳。

Abstract: Optimizing the structure of molecules to achieve desired properties is a central bottleneck across the chemical sciences, particularly in the pharmaceutical industry where it underlies the discovery of new drugs. Since molecular property evaluation often relies on costly and rate-limited oracles, such as experimental assays, molecular optimization must be highly sample-efficient. To address this, we introduce SEISMO, an LLM agent that performs strictly online, inference-time molecular optimization, updating after every oracle call without the need for population-based or batched learning. SEISMO conditions each proposal on the full optimization trajectory, combining natural-language task descriptions with scalar scores and, when available, structured explanatory feedback. Across the Practical Molecular Optimization benchmark of 23 tasks, SEISMO achieves a 2-3 times higher area under the optimisation curve than prior methods, often reaching near-maximal task scores within 50 oracle calls. Our additional medicinal-chemistry tasks show that providing explanatory feedback further improves efficiency, demonstrating that leveraging domain knowledge and structured information is key to sample-efficient molecular optimization.

</details>


### [312] [Multi-Agent Causal Reasoning System for Error Pattern Rule Automation in Vehicles](https://arxiv.org/abs/2602.01155)
*Hugo Math,Julian Lorentz,Stefan Oelsner,Rainer Lienhart*

Main category: cs.AI

TL;DR: CAREP是一个自动化生成错误模式规则的多代理系统，通过因果发现和代理协作，显著提升了车辆故障诊断的效率和准确性。


<details>
  <summary>Details</summary>
Motivation: 随着车辆复杂度的增加，手动制定错误模式（EP）规则既昂贵又容易出错，因此需要自动化解决方案。

Method: CAREP是一个多代理系统，包含因果发现代理、上下文信息代理和协调代理，用于从高维DTC事件序列中自动生成EP规则。

Result: 在包含29,100个独特DTC和474个错误模式的大规模汽车数据集上，CAREP能够自动且准确地发现未知的EP规则，优于仅使用LLM的基线方法，并提供透明的因果解释。

Conclusion: CAREP通过结合因果发现和基于代理的推理，实现了自动化故障诊断，为车辆维护提供了可扩展、可解释且成本效益高的解决方案。

Abstract: Modern vehicles generate thousands of different discrete events known as Diagnostic Trouble Codes (DTCs). Automotive manufacturers use Boolean combinations of these codes, called error patterns (EPs), to characterize system faults and ensure vehicle safety. Yet, EP rules are still manually handcrafted by domain experts, a process that is expensive and prone to errors as vehicle complexity grows. This paper introduces CAREP (Causal Automated Reasoning for Error Patterns), a multi-agent system that automatizes the generation of EP rules from high-dimensional event sequences of DTCs. CAREP combines a causal discovery agent that identifies potential DTC-EP relations, a contextual information agent that integrates metadata and descriptions, and an orchestrator agent that synthesizes candidate boolean rules together with interpretable reasoning traces. Evaluation on a large-scale automotive dataset with over 29,100 unique DTCs and 474 error patterns demonstrates that CAREP can automatically and accurately discover the unknown EP rules, outperforming LLM-only baselines while providing transparent causal explanations. By uniting practical causal discovery and agent-based reasoning, CAREP represents a step toward fully automated fault diagnostics, enabling scalable, interpretable, and cost-efficient vehicle maintenance.

</details>


### [313] [OpenGuanDan: A Large-Scale Imperfect Information Game Benchmark](https://arxiv.org/abs/2602.00676)
*Chao Li,Shangdong Yang,Chiheng Zhan,Zhenxing Ge,Yujing Hu,Bingkun Bao,Xingguo Chen,Yang Gao*

Main category: cs.AI

TL;DR: OpenGuanDan是一个新的多智能体智能决策基准测试，用于评估GuanDan游戏中的AI智能体，结果表明基于学习的智能体表现更好，但仍需进一步研究。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试不足以推动AI在多智能体智能决策领域的进一步研究，需要更具挑战性的测试环境。

Method: 提出了OpenGuanDan基准测试，支持高效模拟GuanDan游戏，并综合评估基于学习和基于规则的AI智能体。

Result: 实验结果表明，基于学习的智能体优于基于规则的智能体，但尚未达到超人类水平。

Conclusion: OpenGuanDan作为一个具有挑战性的基准测试，推动了多智能体智能决策领域的研究，尽管当前基于学习的智能体表现优于基于规则的智能体，但仍未达到超人类水平。

Abstract: The advancement of data-driven artificial intelligence (AI), particularly machine learning, heavily depends on large-scale benchmarks. Despite remarkable progress across domains ranging from pattern recognition to intelligent decision-making in recent decades, exemplified by breakthroughs in board games, card games, and electronic sports games, there remains a pressing need for more challenging benchmarks to drive further research. To this end, this paper proposes OpenGuanDan, a novel benchmark that enables both efficient simulation of GuanDan (a popular four-player, multi-round Chinese card game) and comprehensive evaluation of both learning-based and rule-based GuanDan AI agents. OpenGuanDan poses a suite of nontrivial challenges, including imperfect information, large-scale information set and action spaces, a mixed learning objective involving cooperation and competition, long-horizon decision-making, variable action spaces, and dynamic team composition. These characteristics make it a demanding testbed for existing intelligent decision-making methods. Moreover, the independent API for each player allows human-AI interactions and supports integration with large language models. Empirically, we conduct two types of evaluations: (1) pairwise competitions among all GuanDan AI agents, and (2) human-AI matchups. Experimental results demonstrate that while current learning-based agents substantially outperform rule-based counterparts, they still fall short of achieving superhuman performance, underscoring the need for continued research in multi-agent intelligent decision-making domain. The project is publicly available at https://github.com/GameAI-NJUPT/OpenGuanDan.

</details>


### [314] [HumanStudy-Bench: Towards AI Agent Design for Participant Simulation](https://arxiv.org/abs/2602.00685)
*Xuan Liu,Haoyang Shang,Zizhang Liu,Xinyan Liu,Yunze Xiao,Yiwen Tu,Haojian Jin*

Main category: cs.AI

TL;DR: HUMANSTUDY-BENCH 是一个评估LLM代理在社会科学实验中行为的基准，通过量化人类与代理行为的一致性，提供更可靠的评估框架。


<details>
  <summary>Details</summary>
Motivation: 解决LLM在社会科学实验中行为不稳定且对设计选择敏感的问题，避免将基础模型能力与实验实例化混淆。

Method: 通过 Filter--Extract--Execute--Evaluate 流程，HUMANSTUDY-BENCH 协调LLM代理重建已发表的人类实验，保留原始统计程序。

Result: 在涵盖12项基础研究的动态基准中，HUMANSTUDY-BENCH 成功评估了超过6,000次试验，涉及人类样本从几十到2,100多名参与者。

Conclusion: HUMANSTUDY-BENCH 提供了一个动态基准，通过量化人类与代理行为的一致性，为社会科学实验中基于LLM的参与者模拟提供了更可靠的评估框架。

Abstract: Large language models (LLMs) are increasingly used as simulated participants in social science experiments, but their behavior is often unstable and highly sensitive to design choices. Prior evaluations frequently conflate base-model capabilities with experimental instantiation, obscuring whether outcomes reflect the model itself or the agent setup. We instead frame participant simulation as an agent-design problem over full experimental protocols, where an agent is defined by a base model and a specification (e.g., participant attributes) that encodes behavioral assumptions. We introduce HUMANSTUDY-BENCH, a benchmark and execution engine that orchestrates LLM-based agents to reconstruct published human-subject experiments via a Filter--Extract--Execute--Evaluate pipeline, replaying trial sequences and running the original analysis pipeline in a shared runtime that preserves the original statistical procedures end to end. To evaluate fidelity at the level of scientific inference, we propose new metrics to quantify how much human and agent behaviors agree. We instantiate 12 foundational studies as an initial suite in this dynamic benchmark, spanning individual cognition, strategic interaction, and social psychology, and covering more than 6,000 trials with human samples ranging from tens to over 2,100 participants.

</details>


### [315] [Agyn: A Multi-Agent System for Team-Based Autonomous Software Engineering](https://arxiv.org/abs/2602.01465)
*Nikita Benkovich,Vitalii Valkov*

Main category: cs.AI

TL;DR: 该论文提出了一种完全自动化的多代理系统，模拟真实软件开发团队的结构和流程，显著提升了任务解决率，证明了团队结构和组织设计在自主软件工程中的重要性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在单个软件工程任务中表现出强大能力，但大多数自主系统仍将问题解决视为单一或基于流水线的过程。相比之下，现实世界的软件开发是团队协作活动，遵循共享方法，有明确的角色分离、沟通和审查。

Method: 构建了一个完全自动化的多代理系统，明确将软件工程建模为组织过程，复制工程团队的结构。该系统基于开源平台agyn配置代理团队，分配专门代理到协调、研究、实施和审查等角色，并提供隔离沙箱和结构化通信。

Result: 在SWE-bench 500上评估后，系统解决了72.4%的任务，优于使用类似语言模型的单代理基线。

Conclusion: 研究表明，复制团队结构、方法和沟通是自主软件工程的有力范式，未来进展可能同样依赖于组织设计和代理基础设施，而不仅仅是模型改进。

Abstract: Large language models have demonstrated strong capabilities in individual software engineering tasks, yet most autonomous systems still treat issue resolution as a monolithic or pipeline-based process. In contrast, real-world software development is organized as a collaborative activity carried out by teams following shared methodologies, with clear role separation, communication, and review. In this work, we present a fully automated multi-agent system that explicitly models software engineering as an organizational process, replicating the structure of an engineering team. Built on top of agyn, an open-source platform for configuring agent teams, our system assigns specialized agents to roles such as coordination, research, implementation, and review, provides them with isolated sandboxes for experimentation, and enables structured communication. The system follows a defined development methodology for working on issues, including analysis, task specification, pull request creation, and iterative review, and operates without any human intervention. Importantly, the system was designed for real production use and was not tuned for SWE-bench. When evaluated post hoc on SWE-bench 500, it resolves 72.4% of tasks, outperforming single-agent baselines using comparable language models. Our results suggest that replicating team structure, methodology, and communication is a powerful paradigm for autonomous software engineering, and that future progress may depend as much on organizational design and agent infrastructure as on model improvements.

</details>


### [316] [From Prompt to Graph: Comparing LLM-Based Information Extraction Strategies in Domain-Specific Ontology Development](https://arxiv.org/abs/2602.00699)
*Xuan Liu,Ziyu Li,Mu He,Ziyang Ma,Xiaoxu Wu,Gizem Yilmaz,Yiyuan Xia,Bingbing Li,He Tan,Jerry Ying Hsi Fuh,Wen Feng Lu,Anders E. W. Jarfors,Per Jansson*

Main category: cs.AI

TL;DR: 本研究探索了三种LLM方法在有限数据下自动化知识提取的可行性，成功构建了铸造本体，验证了LLM在专业领域的应用潜力。


<details>
  <summary>Details</summary>
Motivation: 传统本体构建依赖手动标注和常规NLP技术，过程劳动密集且成本高，特别是在铸造制造等专业领域。LLM的兴起为自动化知识提取提供了新可能。

Method: 研究采用了三种基于LLM的方法：预训练LLM驱动方法、上下文学习（ICL）方法和微调方法，用于从领域特定文本中提取术语和关系。

Result: 研究比较了三种方法的性能，并利用表现最佳的方法构建了经过领域专家验证的铸造本体。

Conclusion: 本研究通过比较三种基于LLM的方法，证明了在有限数据下自动化知识提取的可行性，并成功构建了经过领域专家验证的铸造本体。

Abstract: Ontologies are essential for structuring domain knowledge, improving accessibility, sharing, and reuse. However, traditional ontology construction relies on manual annotation and conventional natural language processing (NLP) techniques, making the process labour-intensive and costly, especially in specialised fields like casting manufacturing. The rise of Large Language Models (LLMs) offers new possibilities for automating knowledge extraction. This study investigates three LLM-based approaches, including pre-trained LLM-driven method, in-context learning (ICL) method and fine-tuning method to extract terms and relations from domain-specific texts using limited data. We compare their performances and use the best-performing method to build a casting ontology that validated by domian expert.

</details>


### [317] [ProjDevBench: Benchmarking AI Coding Agents on End-to-End Project Development](https://arxiv.org/abs/2602.01655)
*Pengrui Lu,Shiqi Zhang,Yunzhong Hou,Lyumanshan Ye,Chaoyi Huang,Zixi Chen,Ji Zeng,Hantao Jiang,Pengfei Liu,Yiwei Wang,Ming-Hsuan Yang*

Main category: cs.AI

TL;DR: ProjDevBench 是一个新的端到端基准测试，用于评估编码代理的项目开发能力，结果显示代理在复杂任务上仍有不足。


<details>
  <summary>Details</summary>
Motivation: 现有的评估主要关注问题级别的错误修复，落后于端到端开发的需求，因此需要一个新的基准来全面评估编码代理的能力。

Method: 结合 Online Judge 测试和 LLM 辅助的代码审查，评估代理在系统架构设计、功能正确性和迭代解决方案改进方面的表现。

Result: 在六个基于不同 LLM 后端的编码代理中，整体接受率为 27.38%，代理能处理基本功能和数据结构，但在复杂系统设计等方面表现不佳。

Conclusion: ProjDevBench 是一个端到端的基准测试，用于评估编码代理在项目开发中的表现，结果显示当前代理在处理复杂系统设计、时间复杂度优化和资源管理方面仍有挑战。

Abstract: Recent coding agents can generate complete codebases from simple prompts, yet existing evaluations focus on issue-level bug fixing and lag behind end-to-end development. We introduce ProjDevBench, an end-to-end benchmark that provides project requirements to coding agents and evaluates the resulting repositories. Combining Online Judge (OJ) testing with LLM-assisted code review, the benchmark evaluates agents on (1) system architecture design, (2) functional correctness, and (3) iterative solution refinement. We curate 20 programming problems across 8 categories, covering both concept-oriented tasks and real-world application scenarios, and evaluate six coding agents built on different LLM backends. Our evaluation reports an overall acceptance rate of 27.38%: agents handle basic functionality and data structures but struggle with complex system design, time complexity optimization, and resource management. Our benchmark is available at https://github.com/zsworld6/projdevbench.

</details>


### [318] [Self-Guard: Defending Large Reasoning Models via enhanced self-reflection](https://arxiv.org/abs/2602.00707)
*Jingnan Zheng,Jingjun Xu,Yanzhen Luo,Chenhang Cui,Gelei Deng,Zhenkai Liang,Xiang Wang,An Zhang,Tat-Seng Chua*

Main category: cs.AI

TL;DR: Self-Guard 是一种轻量级框架，通过安全提示和激活引导解决 LRMs 的安全合规性问题，实验证明其有效且泛化能力强。


<details>
  <summary>Details</summary>
Motivation: 当前的对齐策略通常依赖计算密集的后训练范式或外部干预，无法有效解决模型识别风险但仍优先遵循用户指令的顺从性倾向问题。

Method: Self-Guard 通过两个主要阶段运作：安全导向提示和安全激活引导，前者激活模型潜在的安全意识以引发自发反思，后者提取隐藏状态空间中的方向性变化并放大以确保推理过程中安全合规性优先于顺从性。

Result: 实验表明，Self-Guard 有效弥合了意识-合规性差距，实现了稳健的安全性能，并在不同未见风险和模型规模上表现出强泛化能力。

Conclusion: Self-Guard 提出了一种轻量级的安全防御框架，有效解决了大型推理模型（LRMs）中的意识-合规性差距问题，无需牺牲模型实用性。

Abstract: The emergence of Large Reasoning Models (LRMs) introduces a new paradigm of explicit reasoning, enabling remarkable advances yet posing unique risks such as reasoning manipulation and information leakage. To mitigate these risks, current alignment strategies predominantly rely on heavy post-training paradigms or external interventions. However, these approaches are often computationally intensive and fail to address the inherent awareness-compliance gap, a critical misalignment where models recognize potential risks yet prioritize following user instructions due to their sycophantic tendencies. To address these limitations, we propose Self-Guard, a lightweight safety defense framework that reinforces safety compliance at the representational level. Self-Guard operates through two principal stages: (1) safety-oriented prompting, which activates the model's latent safety awareness to evoke spontaneous reflection, and (2) safety activation steering, which extracts the resulting directional shift in the hidden state space and amplifies it to ensure that safety compliance prevails over sycophancy during inference. Experiments demonstrate that Self-Guard effectively bridges the awareness-compliance gap, achieving robust safety performance without compromising model utility. Furthermore, Self-Guard exhibits strong generalization across diverse unseen risks and varying model scales, offering a cost-efficient solution for LRM safety alignment.

</details>


### [319] [Canonical Intermediate Representation for LLM-based optimization problem formulation and code generation](https://arxiv.org/abs/2602.02029)
*Zhongyuan Lyu,Shuoyu Hu,Lujie Liu,Hongxia Yang,Ming LI*

Main category: cs.AI

TL;DR: 论文提出CIR和R2C框架，通过多智能体流程解决优化模型自动生成中的复杂约束问题，实验显示其在新基准和已有基准上均表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决当前基于LLM的方法在处理复杂操作规则时的复合约束和建模范式问题。

Method: 提出Canonical Intermediate Representation (CIR)和rule-to-constraint (R2C)框架，通过多智能体流程解析问题文本、合成CIR实现并实例化优化模型。

Result: R2C在新构建的基准测试中达到47.2%的准确率，并在已有基准测试中接近专有模型（如GPT-5）的性能，通过反思机制进一步提升了性能。

Conclusion: R2C框架通过引入CIR和反思机制，在优化模型自动生成领域取得了最先进的性能，并在多个基准测试中表现出色。

Abstract: Automatically formulating optimization models from natural language descriptions is a growing focus in operations research, yet current LLM-based approaches struggle with the composite constraints and appropriate modeling paradigms required by complex operational rules. To address this, we introduce the Canonical Intermediate Representation (CIR): a schema that LLMs explicitly generate between problem descriptions and optimization models. CIR encodes the semantics of operational rules through constraint archetypes and candidate modeling paradigms, thereby decoupling rule logic from its mathematical instantiation. Upon a newly generated CIR knowledge base, we develop the rule-to-constraint (R2C) framework, a multi-agent pipeline that parses problem texts, synthesizes CIR implementations by retrieving domain knowledge, and instantiates optimization models. To systematically evaluate rule-to-constraint reasoning, we test R2C on our newly constructed benchmark featuring rich operational rules, and benchmarks from prior work. Extensive experiments show that R2C achieves state-of-the-art accuracy on the proposed benchmark (47.2% Accuracy Rate). On established benchmarks from the literature, R2C delivers highly competitive results, approaching the performance of proprietary models (e.g., GPT-5). Moreover, with a reflection mechanism, R2C achieves further gains and sets new best-reported results on some benchmarks.

</details>


### [320] [Physics-informed Diffusion Generation for Geomagnetic Map Interpolation](https://arxiv.org/abs/2602.00709)
*Wenda Li,Tongya Zheng,Kaixuan Chen,Shunyu Liu,Haoze Jiang,Yunzhi Hao,Rui Miao,Zujie Ren,Mingli Song,Hang Shi,Gang Chen*

Main category: cs.AI

TL;DR: PDG框架通过物理信息引导的扩散生成，解决了地磁地图插值中的噪声和物理规律问题，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有散点数据插值方法未针对地磁地图设计，导致性能受限，需解决噪声和物理规律遵从问题。

Method: 提出了物理信息扩散生成框架（PDG），包括物理信息掩码策略和基于克里金原理的物理约束。

Result: 在四个真实数据集上的实验表明，PDG的各个组件均具有优越性和有效性。

Conclusion: PDG框架通过物理信息引导的扩散生成过程，有效解决了地磁地图插值中的噪声干扰和物理规律遵从问题，实验证明了其优越性和有效性。

Abstract: Geomagnetic map interpolation aims to infer unobserved geomagnetic data at spatial points, yielding critical applications in navigation and resource exploration. However, existing methods for scattered data interpolation are not specifically designed for geomagnetic maps, which inevitably leads to suboptimal performance due to detection noise and the laws of physics. Therefore, we propose a Physics-informed Diffusion Generation framework~(PDG) to interpolate incomplete geomagnetic maps. First, we design a physics-informed mask strategy to guide the diffusion generation process based on a local receptive field, effectively eliminating noise interference. Second, we impose a physics-informed constraint on the diffusion generation results following the kriging principle of geomagnetic maps, ensuring strict adherence to the laws of physics. Extensive experiments and in-depth analyses on four real-world datasets demonstrate the superiority and effectiveness of each component of PDG.

</details>


### [321] [Rethinking the Role of Entropy in Optimizing Tool-Use Behaviors for Large Language Model Agents](https://arxiv.org/abs/2602.02050)
*Zeping Li,Hongru Wang,Yiwen Zhao,Guanhua Chen,Yixia Li,Keyang Chen,Yixin Cao,Guangnan Ye,Hongfeng Chai,Mengdi Wang,Zhenfei Yin*

Main category: cs.AI

TL;DR: 利用熵减监督信号设计两种奖励策略，显著优化LLM代理的工具使用行为。


<details>
  <summary>Details</summary>
Motivation: 解决基于LLM的工具使用代理在长轨迹中触发过多低质量工具调用的问题。

Method: 通过熵基实验发现熵减与高质量工具调用正相关，设计稀疏结果奖励和密集过程奖励两种策略。

Result: 稀疏奖励减少72.07%工具调用，密集奖励提升22.27%性能。

Conclusion: 熵减作为监督信号能有效提升工具使用行为，使代理在实际应用中更具适应性。

Abstract: Tool-using agents based on Large Language Models (LLMs) excel in tasks such as mathematical reasoning and multi-hop question answering. However, in long trajectories, agents often trigger excessive and low-quality tool calls, increasing latency and degrading inference performance, making managing tool-use behavior challenging. In this work, we conduct entropy-based pilot experiments and observe a strong positive correlation between entropy reduction and high-quality tool calls. Building on this finding, we propose using entropy reduction as a supervisory signal and design two reward strategies to address the differing needs of optimizing tool-use behavior. Sparse outcome rewards provide coarse, trajectory-level guidance to improve efficiency, while dense process rewards offer fine-grained supervision to enhance performance. Experiments across diverse domains show that both reward designs improve tool-use behavior: the former reduces tool calls by 72.07% compared to the average of baselines, while the latter improves performance by 22.27%. These results position entropy reduction as a key mechanism for enhancing tool-use behavior, enabling agents to be more adaptive in real-world applications.

</details>


### [322] [Learning More from Less: Unlocking Internal Representations for Benchmark Compression](https://arxiv.org/abs/2602.00710)
*Yueqi Zhang,Jin Hu,Shaoxiong Feng,Peiwen Yuan,Xinglin Wang,Yiwei Li,Jiayi Shi,Chuyi Tan,Ji Zhang,Boyuan Pan,Yao Hu,Kan Li*

Main category: cs.AI

TL;DR: REPCORE通过隐藏状态对齐构建核心集，显著提升少量源模型下的性能外推准确性，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖大量源模型来估计可靠的项配置文件，统计上不稳定，尤其在历史评估数据有限的新基准测试中表现不佳。

Method: REPCORE利用隐藏状态而非离散正确性标签，通过对齐异构隐藏状态到统一潜在空间来构建核心集。

Result: 在五个基准测试和200多个模型上，REPCORE在排名相关性和估计准确性上均优于基于输出的基线方法。

Conclusion: REPCORE通过将异构隐藏状态对齐到统一的潜在空间中构建代表性核心集，显著提高了在少量源模型下的性能外推准确性。

Abstract: The prohibitive cost of evaluating Large Language Models (LLMs) necessitates efficient alternatives to full-scale benchmarking. Prevalent approaches address this by identifying a small coreset of items to approximate full-benchmark performance. However, existing methods must estimate a reliable item profile from response patterns across many source models, which becomes statistically unstable when the source pool is small. This dependency is particularly limiting for newly released benchmarks with minimal historical evaluation data. We argue that discrete correctness labels are a lossy view of the model's decision process and fail to capture information encoded in hidden states. To address this, we introduce REPCORE, which aligns heterogeneous hidden states into a unified latent space to construct representative coresets. Using these subsets for performance extrapolation, REPCORE achieves precise estimation accuracy with as few as ten source models. Experiments on five benchmarks and over 200 models show consistent gains over output-based baselines in ranking correlation and estimation accuracy. Spectral analysis further indicates that the aligned representations contain separable components reflecting broad response tendencies and task-specific reasoning patterns.

</details>


### [323] [Neuro-symbolic AI for Predictive Maintenance (PdM) -- review and recommendations](https://arxiv.org/abs/2602.00731)
*Kyle Hamilton,Ali Intizar*

Main category: cs.AI

TL;DR: 综述了预测性维护领域的最新进展，提出结合深度学习和符号逻辑的神经符号AI方法，以解决现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 数据驱动方法虽准确性高，但需要大量标记数据且缺乏泛化性和透明度；传统方法依赖专家知识，准确性低且需持续人工调整。两者各有局限，需结合优势。

Method: 对过去五年工业环境中的预测性维护（PdM）进行了系统综述，重点关注数据驱动方法和传统知识系统的优缺点，并探讨了神经符号AI架构。

Result: 神经符号AI架构有望克服单一方法的弱点，结合深度学习和符号逻辑，提升系统的准确性、可解释性和鲁棒性。

Conclusion: 本文提出将深度学习与符号逻辑结合的神经符号AI（NeSy）方法，以创建更准确、可解释和鲁棒的预测性维护系统。

Abstract: In this document we perform a systematic review the State-of-the-art in Predictive Maintenance (PdM) over the last five years in industrial settings such as commercial buildings, pharmaceutical facilities, or semi-conductor manufacturing. In general, data-driven methods such as those based on deep learning, exhibit higher accuracy than traditional knowledge-based systems. These systems however, are not without significant limitations. The need for large labeled data sets, a lack of generalizibility to new environments (out-of-distribution generalization), and a lack of transparency at inference time are some of the obstacles to adoption in real world environments. In contrast, traditional approaches based on domain expertise in the form of rules, logic or first principles suffer from poor accuracy, many false positives and a need for ongoing expert supervision and manual tuning. While the majority of approaches in recent literature utilize some form of data-driven architecture, there are hybrid systems which also take into account domain specific knowledge. Such hybrid systems have the potential to overcome the weaknesses of either approach on its own while preserving their strengths. We propose taking the hybrid approach even further and integrating deep learning with symbolic logic, or Neuro-symbolic AI, to create more accurate, explainable, interpretable, and robust systems. We describe several neuro-symbolic architectures and examine their strengths and limitations within the PdM domain. We focus specifically on methods which involve the use of sensor data and manually crafted rules as inputs by describing concrete NeSy architectures. In short, this survey outlines the context of modern maintenance, defines key concepts, establishes a generalized framework, reviews current modeling approaches and challenges, and introduces the proposed focus on Neuro-symbolic AI (NESY).

</details>


### [324] [SafeGround: Know When to Trust GUI Grounding Models via Uncertainty Calibration](https://arxiv.org/abs/2602.02419)
*Qingni Wang,Yue Fan,Xin Eric Wang*

Main category: cs.AI

TL;DR: SafeGround是一个不确定性感知的GUI接地框架，通过量化不确定性和校准过程提高模型可靠性，实验显示其显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: GUI接地中的错误可能导致高成本且难以逆转的操作（如错误支付批准），因此需要提高模型可靠性。

Method: SafeGround采用分布感知的不确定性量化方法，捕捉模型输出的空间分散性，并通过校准过程得出具有统计保证FDR控制的测试时决策阈值。

Result: 实验结果表明，SafeGround的不确定性测量在区分正确与错误预测方面优于现有基线，且校准阈值可靠地实现了严格的风险控制。

Conclusion: SafeGround框架通过不确定性量化和校准过程，显著提高了GUI接地模型的系统级准确性，并在多个模型中实现了高达5.38%的改进。

Abstract: Graphical User Interface (GUI) grounding aims to translate natural language instructions into executable screen coordinates, enabling automated GUI interaction. Nevertheless, incorrect grounding can result in costly, hard-to-reverse actions (e.g., erroneous payment approvals), raising concerns about model reliability. In this paper, we introduce SafeGround, an uncertainty-aware framework for GUI grounding models that enables risk-aware predictions through calibrations before testing. SafeGround leverages a distribution-aware uncertainty quantification method to capture the spatial dispersion of stochastic samples from outputs of any given model. Then, through the calibration process, SafeGround derives a test-time decision threshold with statistically guaranteed false discovery rate (FDR) control. We apply SafeGround on multiple GUI grounding models for the challenging ScreenSpot-Pro benchmark. Experimental results show that our uncertainty measure consistently outperforms existing baselines in distinguishing correct from incorrect predictions, while the calibrated threshold reliably enables rigorous risk control and potentials of substantial system-level accuracy improvements. Across multiple GUI grounding models, SafeGround improves system-level accuracy by up to 5.38\% percentage points over Gemini-only inference.

</details>


### [325] [Drift-Bench: Diagnosing Cooperative Breakdowns in LLM Agents under Input Faults via Multi-Turn Interaction](https://arxiv.org/abs/2602.02455)
*Han Bao,Zheyuan Zhang,Pengcheng Jing,Zhengqing Yuan,Kaiwen Shi,Yanfang Ye*

Main category: cs.AI

TL;DR: Drift-Bench是首个通过多轮澄清评估代理在输入故障下语用能力的诊断基准，填补了现有评估工具的不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准通常假设指令明确或仅限于文本单轮澄清，无法衡量在多轮歧义消除下的实际执行风险，因此需要新的评估工具。

Method: 通过多轮澄清在状态导向和服务导向的执行环境中评估代理的语用能力，使用基于经典通信理论的统一分类法和Rise评估协议。

Result: 实验显示在这些输入故障下性能显著下降，澄清效果因用户角色和故障类型而异。

Conclusion: Drift-Bench 填补了现有基准在评估多轮澄清和实际执行风险方面的空白，为代理安全评估提供了系统化的诊断工具。

Abstract: As Large Language Models transition to autonomous agents, user inputs frequently violate cooperative assumptions (e.g., implicit intent, missing parameters, false presuppositions, or ambiguous expressions), creating execution risks that text-only evaluations do not capture. Existing benchmarks typically assume well-specified instructions or restrict evaluation to text-only, single-turn clarification, and thus do not measure multi-turn disambiguation under grounded execution risk. We introduce \textbf{Drift-Bench}, the first diagnostic benchmark that evaluates agentic pragmatics under input faults through multi-turn clarification across state-oriented and service-oriented execution environments. Grounded in classical theories of communication, \textbf{Drift-Bench} provides a unified taxonomy of cooperative breakdowns and employs a persona-driven user simulator with the \textbf{Rise} evaluation protocol. Experiments show substantial performance drops under these faults, with clarification effectiveness varying across user personas and fault types. \MethodName bridges clarification research and agent safety evaluation, enabling systematic diagnosis of failures that can lead to unsafe executions.

</details>


### [326] [Environment-Aware Adaptive Pruning with Interleaved Inference Orchestration for Vision-Language-Action Models](https://arxiv.org/abs/2602.00780)
*Yuting Huang,Leilei Ding,Zhipeng Tang,Zenghuan Zhu,Jiajun Deng,Xinrui Lin,Shuo Liu,Haojie Ren,Jianmin Ji,Yanyong Zhang*

Main category: cs.AI

TL;DR: EcoVLA 是一种自适应剪枝框架，通过环境感知剪枝和并行调度，显著提升 VLA 模型推理速度，同时保持高成功率。


<details>
  <summary>Details</summary>
Motivation: VLA 模型的大参数量导致高推理延迟，阻碍实时操作，静态剪枝缺乏对环境动态的适应性，而固定间隔的动态层剪枝粒度粗糙且重训练开销大。

Method: EcoVLA 包含两个组件：环境感知自适应剪枝（EAP）和交错推理编排（$I^2O$）。EAP 是一种轻量级自适应通道剪枝方法，结合物理环境的时间一致性更新稀疏模式；$I^2O$ 利用 VLA 推理中固有的 FLOPs 气泡并行调度剪枝方法，确保对延迟影响可忽略。

Result: EcoVLA 在多种 VLA 模型和基准测试中实现最先进性能，最高提速 1.60 倍且成功率仅下降 0.4%，结合令牌剪枝后进一步提速 2.18 倍且性能仅下降 0.5%。

Conclusion: EcoVLA 是一种无需训练、即插即用的自适应剪枝框架，能够与现有 VLA 加速方法正交结合，在保持高成功率的同时显著提升推理速度。

Abstract: While Vision-Language-Action (VLA) models hold promise in embodied intelligence, their large parameter counts lead to substantial inference latency that hinders real-time manipulation, motivating parameter sparsification. However, as the environment evolves during VLA execution, the optimal sparsity patterns change accordingly. Static pruning lacks the adaptability required for environment dynamics, whereas fixed-interval dynamic layer pruning suffers from coarse granularity and high retraining overheads. To bridge this gap, we propose EcoVLA, a training-free, plug-and-play adaptive pruning framework that supports orthogonal combination with existing VLA acceleration methods. EcoVLA comprises two components: Environment-aware Adaptive Pruning (EAP) and Interleaved Inference Orchestration ($I^2O$). EAP is a lightweight adaptive channel pruning method that incorporates the temporal consistency of the physical environment to update sparsity patterns. $I^2O$ leverages the FLOPs bubbles inherent in VLA inference to schedule the pruning method in parallel, ensuring negligible impact on latency. Evaluated on diverse VLA models and benchmarks, EcoVLA delivers state-of-the-art performance, achieving up to 1.60$\times$ speedup with only a 0.4% drop in success rate, and further reaches 2.18$\times$ speedup with only a 0.5% degradation when combined with token pruning. We further validate the effectiveness of EcoVLA on real-world robots.

</details>


### [327] [World Models as an Intermediary between Agents and the Real World](https://arxiv.org/abs/2602.00785)
*Sherry Yang*

Main category: cs.AI

TL;DR: 本文主张使用世界模型作为代理与高成本复杂领域的中介，以解决动作执行的高成本问题，并探讨了其应用与挑战。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）代理在低成本环境中表现出色，但在高成本复杂领域（如机器人、ML工程和科学实验）中表现不佳，主要瓶颈在于执行动作获取奖励信号的高成本。

Method: 讨论了世界模型如何作为动态、奖励和任务分布的模型，克服高成本动作的基本障碍，如极端离策略学习和长时程任务的样本效率低下。

Result: 展示了世界模型如何在机器学习工程、计算机使用、机器人和AI科学等多个领域为代理提供关键且丰富的学习信号。

Conclusion: 本文提出利用世界模型作为代理与真实世界之间的中介，以解决高成本动作执行的根本障碍，并提出了在数据集构建、架构设计、扩展和评估方面的可行动项。

Abstract: Large language model (LLM) agents trained using reinforcement learning has achieved superhuman performance in low-cost environments like games, mathematics, and coding. However, these successes have not translated to complex domains where the cost of interaction is high, such as the physical cost of running robots, the time cost of ML engineering, and the resource cost of scientific experiments. The true bottleneck for achieving the next level of agent performance for these complex and high-cost domains lies in the expense of executing actions to acquire reward signals. To address this gap, this paper argues that we should use world models as an intermediary between agents and the real world. We discuss how world models, viewed as models of dynamics, rewards, and task distributions, can overcome fundamental barriers of high-cost actions such as extreme off-policy learning and sample inefficiency in long-horizon tasks. Moreover, we demonstrate how world models can provide critical and rich learning signals to agents across a broad set of domains, including machine learning engineering, computer use, robotics, and AI for science. Lastly, we identify the challenges of building these world models and propose actionable items along dataset curation, architecture design, scaling, and evaluation of world models.

</details>


### [328] [MissMAC-Bench: Building Solid Benchmark for Missing Modality Issue in Robust Multimodal Affective Computing](https://arxiv.org/abs/2602.00811)
*Ronghao Lin,Honghao Lu,Ruixing Wu,Aolin Xiong,Qinggong Chu,Qiaolin He,Sijie Mai,Haifeng Hu*

Main category: cs.AI

TL;DR: MissMAC-Bench是一个针对多模态情感计算中缺失模态问题的基准测试，通过跨模态协同视角提出评估标准，并在实验中验证了多种方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 现实场景中模态数据的可用性通常是动态和不确定的，导致多模态输入因分布偏移和语义缺陷而性能波动。缺失模态问题是MAC模型鲁棒性和实际部署的关键障碍。

Method: 研究提出了两个指导原则：训练时不缺失先验知识，以及使用单一模型处理完整和不完整的模态场景。此外，基准测试集成了数据集和实例级别的固定和随机缺失模式评估协议。

Result: 在4个数据集上对3种广泛使用的语言模型进行的广泛实验验证了不同MAC方法在解决缺失模态问题上的有效性。

Conclusion: MissMAC-Bench为多模态情感计算（MAC）领域提供了一个全面的基准测试，通过跨模态协同的视角，系统地量化了缺失模态问题，并推动了多媒体数据挖掘的发展。

Abstract: As a knowledge discovery task over heterogeneous data sources, current Multimodal Affective Computing (MAC) heavily rely on the completeness of multiple modalities to accurately understand human's affective state. However, in real-world scenarios, the availability of modality data is often dynamic and uncertain, leading to substantial performance fluctuations due to the distribution shifts and semantic deficiencies of the incomplete multimodal inputs. Known as the missing modality issue, this challenge poses a critical barrier to the robustness and practical deployment of MAC models. To systematically quantify this issue, we introduce MissMAC-Bench, a comprehensive benchmark designed to establish fair and unified evaluation standards from the perspective of cross-modal synergy. Two guiding principles are proposed, including no missing prior during training, and one single model capable of handling both complete and incomplete modality scenarios, thereby ensuring better generalization. Moreover, to bridge the gap between academic research and real-world applications, our benchmark integrates evaluation protocols with both fixed and random missing patterns at the dataset and instance levels. Extensive experiments conducted on 3 widely-used language models across 4 datasets validate the effectiveness of diverse MAC approaches in tackling the missing modality issue. Our benchmark provides a solid foundation for advancing robust multimodal affective computing and promotes the development of multimedia data mining.

</details>


### [329] [Resource-Efficient Reinforcement for Reasoning Large Language Models via Dynamic One-Shot Policy Refinement](https://arxiv.org/abs/2602.00815)
*Yunjian Zhang,Sudong Wang,Yang Li,Peiran Xu,Conghao Zhou,Xiaoyue Ma,Jianing Li,Yao Zhu*

Main category: cs.AI

TL;DR: DoPR 是一种高效的强化学习策略，显著降低了 LLM 推理训练的资源和计算成本。


<details>
  <summary>Details</summary>
Motivation: 尽管 RLVR 在模型行为与推理链对齐方面表现出色，但其资源密集性（需要大量奖励信号和高昂的训练成本）限制了其广泛应用。

Method: 提出了 Dynamic One-Shot Policy Refinement (DoPR)，一种基于不确定性的强化学习策略，通过奖励波动性和探索驱动的获取动态选择每个批次中最具信息量的训练样本进行策略更新。

Result: DoPR 将训练开销降低近一个数量级，同时保持了竞争力的推理准确性。

Conclusion: DoPR 提供了一种可扩展且资源高效的解决方案，适用于需要密集推理的 LLM 应用的后训练，为基于强化学习的训练提供了更高效和实用的路径。

Abstract: Large language models (LLMs) have exhibited remarkable performance on complex reasoning tasks, with reinforcement learning under verifiable rewards (RLVR) emerging as a principled framework for aligning model behavior with reasoning chains. Despite its promise, RLVR remains prohibitively resource-intensive, requiring extensive reward signals and incurring substantial rollout costs during training. In this work, we revisit the fundamental question of data and compute efficiency in RLVR. We first establish a theoretical lower bound on the sample complexity required to unlock reasoning capabilities, and empirically validate that strong performance can be achieved with a surprisingly small number of training instances. To tackle the computational burden, we propose Dynamic One-Shot Policy Refinement (DoPR), an uncertainty-aware RL strategy that dynamically selects a single informative training sample per batch for policy updates, guided by reward volatility and exploration-driven acquisition. DoPR reduces rollout overhead by nearly an order of magnitude while preserving competitive reasoning accuracy, offering a scalable and resource-efficient solution for LLM post-training. This approach offers a practical path toward more efficient and accessible RL-based training for reasoning-intensive LLM applications.

</details>


### [330] [Optimizing Agentic Reasoning with Retrieval via Synthetic Semantic Information Gain Reward](https://arxiv.org/abs/2602.00845)
*Senkang Hu,Yong Dai,Yuzhi Zhao,Yihang Tao,Yu Guo,Zhengru Fang,Sam Tak Wu Kwong,Yuguang Fang*

Main category: cs.AI

TL;DR: InfoReasoner 通过合成语义信息增益奖励激励有效信息检索，理论重新定义信息增益，实验显示其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 优化大型推理模型（LRMs）的动态外部知识获取过程，由于缺乏密集、有原则的奖励信号，检索过程的优化仍然具有挑战性。

Method: 引入了一个输出感知的内在估计器，通过双向文本蕴含的语义聚类直接从模型的输出分布计算信息增益。

Result: 在七个问答基准测试中，InfoReasoner 始终优于强大的检索增强基线，平均准确率提高了5.4%。

Conclusion: InfoReasoner 提供了一个理论上有依据且可扩展的路径，用于实现带有检索功能的代理推理。

Abstract: Agentic reasoning enables large reasoning models (LRMs) to dynamically acquire external knowledge, but yet optimizing the retrieval process remains challenging due to the lack of dense, principled reward signals. In this paper, we introduce InfoReasoner, a unified framework that incentivizes effective information seeking via a synthetic semantic information gain reward. Theoretically, we redefine information gain as uncertainty reduction over the model's belief states, establishing guarantees, including non-negativity, telescoping additivity, and channel monotonicity. Practically, to enable scalable optimization without manual retrieval annotations, we propose an output-aware intrinsic estimator that computes information gain directly from the model's output distributions using semantic clustering via bidirectional textual entailment. This intrinsic reward guides the policy to maximize epistemic progress, enabling efficient training via Group Relative Policy Optimxization (GRPO). Experiments across seven question-answering benchmarks demonstrate that InfoReasoner consistently outperforms strong retrieval-augmented baselines, achieving up to 5.4% average accuracy improvement. Our work provides a theoretically grounded and scalable path toward agentic reasoning with retrieval.

</details>


### [331] [Persuasion Propagation in LLM Agents](https://arxiv.org/abs/2602.00851)
*Hyejun Jeong,Amir Houmansadr,Shlomo Zilberstein,Eugene Bagdasarian*

Main category: cs.AI

TL;DR: 研究发现，预先设定的信念状态能显著影响AI代理的任务行为，而实时说服效果较弱。


<details>
  <summary>Details</summary>
Motivation: 探讨在AI代理执行长期任务时，用户的说服如何影响其下游任务行为，这一现象被称为“说服传播”。

Method: 研究引入了一个以行为为中心的评估框架，区分了在任务执行期间或之前应用的说服。通过网页研究和编码任务进行实验。

Result: 研究发现，实时说服诱导的行为效果较弱且不一致；而在任务开始时明确指定信念状态时，信念预填充的代理平均减少了26.9%的搜索和16.9%的独特来源访问。

Conclusion: 研究表明，说服即使在先前的互动中也能影响AI代理的行为，这强调了在代理系统中进行行为层面评估的重要性。

Abstract: Modern AI agents increasingly combine conversational interaction with autonomous task execution, such as coding and web research, raising a natural question: what happens when an agent engaged in long-horizon tasks is subjected to user persuasion? We study how belief-level intervention can influence downstream task behavior, a phenomenon we name \emph{persuasion propagation}. We introduce a behavior-centered evaluation framework that distinguishes between persuasion applied during or prior to task execution. Across web research and coding tasks, we find that on-the-fly persuasion induces weak and inconsistent behavioral effects. In contrast, when the belief state is explicitly specified at task time, belief-prefilled agents conduct on average 26.9\% fewer searches and visit 16.9\% fewer unique sources than neutral-prefilled agents. These results suggest that persuasion, even in prior interaction, can affect the agent's behavior, motivating behavior-level evaluation in agentic systems.

</details>


### [332] [Position: Human-Centric AI Requires a Minimum Viable Level of Human Understanding](https://arxiv.org/abs/2602.00854)
*Fangzhou Lin,Qianwen Ge,Lingyu Xu,Peiran Li,Xiangbo Gao,Shuo Xing,Kazunori Yamada,Ziming Zhang,Haichong Zhang,Zhengzhong Tu*

Main category: cs.AI

TL;DR: 本文定义了能力-理解差距，提出认知完整性阈值（CIT）作为保持人类监督的最低理解标准，并呼吁设计与治理改革以实现认知可持续性。


<details>
  <summary>Details</summary>
Motivation: AI系统的高效表现与用户理解能力的退化形成能力-理解差距（Capability-Comprehension Gap），现有透明度、用户控制等方法未能解决人类在AI委托下保持监督所需的基础理解问题。

Method: 通过定义CIT的三个功能维度（验证能力、理解保持互动和制度性治理支架）来操作化这一概念。

Result: 提出了CIT作为衡量标准，并指出超过此阈值后监督将变得程序化且可争议性失效。

Conclusion: 本文提出了认知完整性阈值（CIT）的概念，强调在AI协助下保持人类监督、自主性和责任参与所需的最低理解水平，并呼吁设计与治理议程以实现认知可持续性。

Abstract: AI systems increasingly produce fluent, correct, end-to-end outcomes. Over time, this erodes users' ability to explain, verify, or intervene. We define this divergence as the Capability-Comprehension Gap: a decoupling where assisted performance improves while users' internal models deteriorate. This paper argues that prevailing approaches to transparency, user control, literacy, and governance do not define the foundational understanding humans must retain for oversight under sustained AI delegation. To formalize this, we define the Cognitive Integrity Threshold (CIT) as the minimum comprehension required to preserve oversight, autonomy, and accountable participation under AI assistance. CIT does not require full reasoning reconstruction, nor does it constrain automation. It identifies the threshold beyond which oversight becomes procedural and contestability fails. We operatinalize CIT through three functional dimensions: (i) verification capacity, (ii) comprehension-preserving interaction, and (iii) institutional scaffolds for governance. This motivates a design and governance agenda that aligns human-AI interaction with cognitive sustainability in responsibility-critical settings.

</details>


### [333] [Multi-Head Attention Is a Multi-Player Game](https://arxiv.org/abs/2602.00861)
*Kushal Chakrabarti,Nirmal Balachundar*

Main category: cs.AI

TL;DR: The paper models transformer attention as a game, bounds inefficiency via Γ(G), and introduces GAME-LoRA to reduce hallucination and redundancy, achieving significant improvements.


<details>
  <summary>Details</summary>
Motivation: The motivation is to address the inefficiencies in transformer attention caused by unpriced externalities (redundancy, correlated errors) by modeling it as a potential game and deriving bounds on the Price of Anarchy.

Method: The paper formalizes transformer attention as a multi-agent game, introduces a bound on the Price of Anarchy (PoA) via the interaction matrix Γ(G), and proposes GAME-LoRA, a method combining Barlow Twins decorrelation with log-determinant coordination pressure.

Result: The results show that Γ(G) predicts hallucination, emergent coalitions exhibit selective coordination, and GAME-LoRA achieves up to 18% hallucination reduction (8% average) with no knowledge degradation.

Conclusion: The paper concludes that addressing the game-theoretic inefficiencies in transformer attention through regularization methods like GAME-LoRA can significantly reduce hallucination and redundancy, leading to improved model performance without knowledge degradation.

Abstract: Modern transformer attention is internally multi-agent -- heads compete and coordinate -- yet we train it as if it were a monolithic optimizer. We formalize this gap: cross-entropy training induces an implicit potential game among heads, and gradient descent converges to Nash equilibria with potentially unbounded inefficiency due to unpriced externalities (redundancy, correlated errors). Our main result bounds the Price of Anarchy by $Γ(G)$, the off-diagonal mass of a head interaction matrix capturing weight and gradient coupling. Under mild smoothness assumptions, we prove that both \emph{excess hallucination probability} and \emph{excess head redundancy} scale with PoA, unifying two distinct failure modes into a single mechanism. The bound is prescriptive: regularization that reduces $Γ(G)$ provably tightens PoA. We instantiate this as GAME-LoRA, combining Barlow Twins decorrelation with log-determinant coordination pressure. Experiments validate the theory: $Γ(G)$ predicts hallucination ($p{<}0.05$), emergent coalitions exhibit selective coordination, and GAME-LoRA achieves up to 18\% hallucination reduction (8\% average) with no knowledge degradation -- a Pareto improvement inaccessible to methods ignoring the game structure.

</details>


### [334] [Foundation CAN LM: A Pretrained Language Model For Automotive CAN Data](https://arxiv.org/abs/2602.00866)
*Akiharu Esashi,Pawissanutt Lertpongrujikorn,Justin Makino,Yuibi Fujimoto,Mohsen Amini Salehi*

Main category: cs.AI

TL;DR: 该论文提出了一种基于基础模型范式的CAN数据预训练方法，通过统一的标记化方案和多任务适应，验证了其在汽车AI中的通用表示学习潜力。


<details>
  <summary>Details</summary>
Motivation: 尽管CAN总线提供了丰富的车辆信号，但现有管道主要训练孤立的任务特定模型，限制了共享表示学习和跨任务泛化。

Method: 提出了一种统一的标记化方案，用于处理混合离散-连续信号，并解决了时间复杂性和行程特定变异性的挑战。

Result: 结果表明，一个预训练的CAN模型可以有效地适应多种预测任务，验证了基础模型范式在CAN数据上的有效性。

Conclusion: 该研究验证了基础模型范式在CAN数据上的适用性，为汽车AI中的通用表示学习开辟了新方向。

Abstract: The Controller Area Network (CAN) bus provides a rich source of vehicular signals increasingly leveraged for applications in automotive and auto insurance domains, including collision detection, predictive maintenance, and driver risk modeling. Despite this potential, existing pipelines largely train isolated task-specific models on raw CAN data, with only limited efforts exploring decoded signals. Such fragmentation prevents shared representation learning and limits cross-task generalization. By contrast, natural language processing (NLP) and computer vision (CV) have been transformed by the foundation model paradigm: large-scale pretraining followed by task-specific adaptation. In this work, we introduce the foundation CAN model that demonstrates multi-objective downstream generalization using a single pretrained backbone. Our approach treats CAN data as a language: we pretrain on large-scale, unlabeled decoded CAN signals and fine-tune across heterogeneous auto insurance tasks. To enable this, we propose a unified tokenization scheme for mixed discrete-continuous signals and address challenges of temporal complexity and trip-specific variability. Our results show that one pretrained CAN model can adapt effectively to diverse predictive tasks, validating that the foundation modeling paradigm, proven in NLP and CV, also holds for CAN data. This establishes a new direction for generalizable representation learning in automotive AI.

</details>


### [335] [Beyond Output Critique: Self-Correction via Task Distillation](https://arxiv.org/abs/2602.00871)
*Hossein A. Rahmani,Mengting Wan,Pei Zhou,Longqi Yang,Nick Craswell,Emine Yilmaz,Sujay Kumar Jauhar*

Main category: cs.AI

TL;DR: SELF-THOUGHT通过任务抽象提升LLM自我校正能力，大小模型均受益。


<details>
  <summary>Details</summary>
Motivation: 现有方法多停留在输出批评层面，难以纠正深层次推理错误，因此需要一种能更好理解任务结构的自我校正方法。

Method: 提出SELF-THOUGHT框架，引入任务抽象作为中间步骤，通过结构化模板捕捉任务关键变量、约束和问题结构，指导解决方案实例化。

Result: 实验表明，SELF-THOUGHT在多样化推理任务中提高了大小模型的准确性、鲁棒性和泛化能力。

Conclusion: SELF-THOUGHT框架通过任务抽象和解决方案实例化，显著提升了大小语言模型的自我校正能力，提供了一条可扩展的路径以实现更可靠的自校正语言系统。

Abstract: Large language models (LLMs) have shown promising self-correction abilities, where iterative refinement improves the quality of generated responses. However, most existing approaches operate at the level of output critique, patching surface errors while often failing to correct deeper reasoning flaws. We propose SELF-THOUGHT, a framework that introduces an intermediate step of task abstraction before solution refinement. Given an input and an initial response, the model first distills the task into a structured template that captures key variables, constraints, and problem structure. This abstraction then guides solution instantiation, grounding subsequent responses in a clearer understanding of the task and reducing error propagation. Crucially, we show that these abstractions can be transferred across models: templates generated by larger models can serve as structured guides for smaller LLMs, which typically struggle with intrinsic self-correction. By reusing distilled task structures, smaller models achieve more reliable refinements without heavy fine-tuning or reliance on external verifiers. Experiments across diverse reasoning tasks demonstrate that SELF-THOUGHT improves accuracy, robustness, and generalization for both large and small models, offering a scalable path toward more reliable self-correcting language systems.

</details>


### [336] [Synapse Compendium Aware Federated Knowledge Exchange for Tool Routed LLMs](https://arxiv.org/abs/2602.00911)
*Abhijit Chakraborty,Sandipan De,Yash Shah,Chahana Dahal,Vivek Gupta*

Main category: cs.AI

TL;DR: Synapse框架通过全局知识共享和本地学习优化了多智能体LLM的工具使用效率，减少通信成本。


<details>
  <summary>Details</summary>
Motivation: 解决联邦学习中LLM智能体间的通信成本、数据异质性和工具使用异质性等挑战。

Method: Synapse采用模板化表示、嵌入检索与LLM重排序以及自适应掩码技术，以在保持实用性的同时限制信息泄露。

Result: Synapse在工具使用效果上优于权重或提示共享方法，并显著降低了通信开销。

Conclusion: Synapse框架通过共享全局知识模型和本地学习工具使用模式，有效提升了多智能体LLM系统中工具使用的效率，并减少了通信开销。

Abstract: Collaborative learning among LLM-based agents under federated learning faces challenges, including communication costs, heterogeneity in data, and tool-usage, limiting their effectiveness. We introduce Synapse, a framework that trains a shared global knowledge model of tool-usage behavior. Client agents with fixed LLMs learn tool-usage patterns locally, and transmit artifacts for federated aggregation through coordinators. A global tool compendium is updated and redistributed, enabling convergence toward stable tool selection. Synapse uses templated representations, embedding retrieval with LLM reranking, and adaptive masking to maintain utility while limiting information leakage. The framework supports heterogeneous data and quantifies performance improvements. Results show that Synapse improves tool-usage effectiveness and reduces communication overhead compared with weight or prompt-sharing approaches in multi-agent LLM systems.

</details>


### [337] [Supervised sparse auto-encoders as unconstrained feature models for semantic composition](https://arxiv.org/abs/2602.00924)
*Ouns El Harzli,Hugo Wallner,Yoonsoo Nam,Haixuan Xavier Tao*

Main category: cs.AI

TL;DR: 本文提出一种监督稀疏自编码器方法，结合无约束特征模型，解决了重建和语义对齐问题，并在图像生成中展示了组合泛化和语义编辑能力。


<details>
  <summary>Details</summary>
Motivation: 稀疏自编码器在机制可解释性方面面临两个主要挑战：$L_1$惩罚的非平滑性阻碍了重建和可扩展性，以及学习特征与人类语义之间的对齐不足。本文旨在解决这些问题。

Method: 本文通过联合学习稀疏概念嵌入和解码器权重，监督（仅解码器）稀疏自编码器重建特征向量，并采用无约束特征模型作为数学框架。

Result: 在Stable Diffusion 3.5上的实验表明，该方法能够实现组合泛化，成功重建训练中未见的概念组合图像，并支持无需修改提示的语义图像编辑。

Conclusion: 通过结合无约束特征模型和监督任务，本文提出的方法成功解决了稀疏自编码器在重建、可扩展性和特征语义对齐方面的挑战，并在Stable Diffusion 3.5上验证了其组合泛化能力和语义图像编辑的潜力。

Abstract: Sparse auto-encoders (SAEs) have re-emerged as a prominent method for mechanistic interpretability, yet they face two significant challenges: the non-smoothness of the $L_1$ penalty, which hinders reconstruction and scalability, and a lack of alignment between learned features and human semantics. In this paper, we address these limitations by adapting unconstrained feature models-a mathematical framework from neural collapse theory-and by supervising the task. We supervise (decoder-only) SAEs to reconstruct feature vectors by jointly learning sparse concept embeddings and decoder weights. Validated on Stable Diffusion 3.5, our approach demonstrates compositional generalization, successfully reconstructing images with concept combinations unseen during training, and enabling feature-level intervention for semantic image editing without prompt modification.

</details>


### [338] [Learning Abstractions for Hierarchical Planning in Program-Synthesis Agents](https://arxiv.org/abs/2602.00929)
*Zergham Ahmed,Kazuki Irie,Joshua B. Tenenbaum,Christopher J. Bates,Samuel J. Gershman*

Main category: cs.AI

TL;DR: TheoryCoder-2是一种新型TBRL代理，通过LLM上下文学习主动学习抽象，显著提升样本效率和任务解决能力，减少对人类抽象的依赖。


<details>
  <summary>Details</summary>
Motivation: 现有TBRL系统（如TheoryCoder）依赖人类提供的抽象，而忽略了抽象学习问题，限制了其泛化能力。

Method: TheoryCoder-2通过从经验中合成抽象并将其整合到分层规划过程中，主动学习可重用的抽象。

Result: 在BabyAI、Minihack和VGDL游戏（如Sokoban）等多样化环境中，TheoryCoder-2比基线LLM代理更高效，能够解决基线无法完成的任务。

Conclusion: TheoryCoder-2通过利用LLM的上下文学习能力，显著提高了样本效率，能够解决复杂任务，同时减少对人类提供的抽象的依赖。

Abstract: Humans learn abstractions and use them to plan efficiently to quickly generalize across tasks -- an ability that remains challenging for state-of-the-art large language model (LLM) agents and deep reinforcement learning (RL) systems. Inspired by the cognitive science of how people form abstractions and intuitive theories of their world knowledge, Theory-Based RL (TBRL) systems, such as TheoryCoder, exhibit strong generalization through effective use of abstractions. However, they heavily rely on human-provided abstractions and sidestep the abstraction-learning problem. We introduce TheoryCoder-2, a new TBRL agent that leverages LLMs' in-context learning ability to actively learn reusable abstractions rather than relying on hand-specified ones, by synthesizing abstractions from experience and integrating them into a hierarchical planning process. We conduct experiments on diverse environments, including BabyAI, Minihack and VGDL games like Sokoban. We find that TheoryCoder-2 is significantly more sample-efficient than baseline LLM agents augmented with classical planning domain construction, reasoning-based planning, and prior program-synthesis agents such as WorldCoder. TheoryCoder-2 is able to solve complex tasks that the baselines fail, while only requiring minimal human prompts, unlike prior TBRL systems.

</details>


### [339] [The Keyhole Effect: Why Chat Interfaces Fail at Data Analysis](https://arxiv.org/abs/2602.00947)
*Mohan Reddy*

Main category: cs.AI

TL;DR: 聊天界面在多步骤数据分析中因认知过载导致性能下降，论文提出八种设计模式解决这一问题，并形式化了认知过载模型。


<details>
  <summary>Details</summary>
Motivation: 聊天界面已成为AI辅助数据分析的默认接口，但对于多步骤、状态依赖的分析任务，这种界面设计存在问题。

Method: 基于Woods（1984）的Keyhole效应，论文分析了聊天界面通过五种机制系统性降低分析性能，并形式化了认知过载模型。

Result: 提出了Generative UI等八种设计模式，针对认知瓶颈，同时保留自然语言用于意图指定和合成。

Conclusion: 论文提出了八种混合设计模式来解决聊天界面在数据分析中的认知过载问题，并提出了可验证的假设和实验范式。

Abstract: Chat has become the default interface for AI-assisted data analysis. For multi-step, state-dependent analytical tasks, this is a mistake. Building on Woods (1984) Keyhole Effect, the cognitive cost of viewing large information spaces through narrow viewports, I show that chat interfaces systematically degrade analytical performance through five mechanisms: (1) constant content displacement defeats hippocampal spatial memory systems; (2) hidden state variables exceed working memory capacity (approximately 4 chunks under load); (3) forced verbalization triggers verbal overshadowing, degrading visual pattern recognition; (4) linear text streams block epistemic action and cognitive offloading; (5) serialization penalties scale with data dimensionality. I formalize cognitive overload as O = max(0, m - v - W) where m is task-relevant items, v is visible items, and W is working memory capacity. When O > 0, error probability increases and analytical biases (anchoring, confirmation, change blindness) amplify. Eight hybrid design patterns address these failures: Generative UI, Infinite Canvas, Deictic Interaction, State Rail, Ghost Layers, Mise en Place, Semantic Zoom, and Probabilistic UI. Each pattern targets specific cognitive bottlenecks while preserving natural language for intent specification and synthesis. Well-scaffolded conversational systems that encode expert priors may reduce load for guided tasks; the framework applies most strongly to open-ended exploration. The paper concludes with falsifiable hypotheses and experimental paradigms for empirical validation.

</details>


### [340] [MindGuard: Guardrail Classifiers for Multi-Turn Mental Health Support](https://arxiv.org/abs/2602.00950)
*António Farinhas,Nuno M. Guerreiro,José Pombal,Pedro Henrique Martins,Laura Melton,Alex Conway,Cara Dochat,Maya D'Eon,Ricardo Rei*

Main category: cs.AI

TL;DR: 论文提出了一种基于临床风险分类法的轻量级安全分类器MindGuard，有效提升了语言模型在心理健康支持中的安全性。


<details>
  <summary>Details</summary>
Motivation: 解决现有通用安全措施无法区分治疗性披露与真实临床危机的问题。

Method: 通过两代理设置生成合成对话，训练了参数为4B和8B的MindGuard分类器。

Result: MindGuard在高召回率操作点上减少了误报，与临床语言模型配对后，在对抗性多轮交互中表现出更低的有害参与率。

Conclusion: 论文提出了MindGuard，一种基于临床风险分类法的轻量级安全分类器，有效减少了误报并提高了对抗性多轮交互中的安全性。

Abstract: Large language models are increasingly used for mental health support, yet their conversational coherence alone does not ensure clinical appropriateness. Existing general-purpose safeguards often fail to distinguish between therapeutic disclosures and genuine clinical crises, leading to safety failures. To address this gap, we introduce a clinically grounded risk taxonomy, developed in collaboration with PhD-level psychologists, that identifies actionable harm (e.g., self-harm and harm to others) while preserving space for safe, non-crisis therapeutic content. We release MindGuard-testset, a dataset of real-world multi-turn conversations annotated at the turn level by clinical experts. Using synthetic dialogues generated via a controlled two-agent setup, we train MindGuard, a family of lightweight safety classifiers (with 4B and 8B parameters). Our classifiers reduce false positives at high-recall operating points and, when paired with clinician language models, help achieve lower attack success and harmful engagement rates in adversarial multi-turn interactions compared to general-purpose safeguards. We release all models and human evaluation data.

</details>


### [341] [R-HTN: Rebellious Online HTN Planning for Safety and Game AI](https://arxiv.org/abs/2602.00951)
*Hector Munoz-Avila,David W. Aha,Paola Rizzo*

Main category: cs.AI

TL;DR: 该论文提出了R-HTN算法，使在线HTN规划智能体能在不违反关键指令集\D的情况下，灵活调整行为以完成用户任务。


<details>
  <summary>Details</summary>
Motivation: 研究如何在智能体具备反抗能力（即智能不服从）的情况下，确保其行为不违反关键指令集\D，同时尽可能完成用户任务。

Method: 结合了HTN规划、在线规划和指令集\D的考虑，提出了两种智能体变体：非适应性智能体和适应性智能体，并开发了R-HTN算法。

Result: R-HTN智能体在测试任务领域中始终未违反指令集\D，并尝试以可能不同于用户预期的方式实现目标。

Conclusion: R-HTN智能体在遵循指令集\D的前提下，能够在不违反安全或个性特质的情况下，尝试完成用户设定的目标，尽管方式可能与用户预期不同。

Abstract: We introduce online Hierarchical Task Network (HTN) agents whose behaviors are governed by a set of built-in directives \D. Like other agents that are capable of rebellion (i.e., {\it intelligent disobedience}), our agents will, under some conditions, not perform a user-assigned task and instead act in ways that do not meet a user's expectations. Our work combines three concepts: HTN planning, online planning, and the directives \D, which must be considered when performing user-assigned tasks. We investigate two agent variants: (1) a Nonadaptive agent that stops execution if it finds itself in violation of \D~ and (2) an Adaptive agent that, in the same situation, instead modifies its HTN plan to search for alternative ways to achieve its given task. We present R-HTN (for: Rebellious-HTN), a general algorithm for online HTN planning under directives \D. We evaluate R-HTN in two task domains where the agent must not violate some directives for safety reasons or as dictated by their personality traits. We found that R-HTN agents never violate directives, and aim to achieve the user-given goals if feasible though not necessarily as the user expected.

</details>


### [342] [Small-Margin Preferences Still Matter-If You Train Them Right](https://arxiv.org/abs/2602.00954)
*Jinlong Pang,Zhaowei Zhu,Na Di,Yichi Zhang,Yaxuan Wang,Chen Qian,Yang Liu*

Main category: cs.AI

TL;DR: MixDPO通过难度感知的混合训练策略（SFT+偏好损失），有效利用模糊偏好对，显著提升LLM对齐效果。


<details>
  <summary>Details</summary>
Motivation: 发现偏好优化方法（如DPO）的效果高度依赖偏好对的质量和难度，且困难对在偏好损失下会破坏训练稳定性，但在SFT下仍包含有用信号。

Method: 提出了MixDPO方法，包括（i）按难度排序偏好数据（基于边际定义的难度课程），（ii）将困难对路由到SFT目标，而对简单对应用偏好损失。

Result: 在三个LLM-judge基准测试中，MixDPO一致优于DPO及其变体，尤其在AlpacaEval~2长度控制（LC）胜率上表现突出。

Conclusion: MixDPO通过结合难度感知的训练策略，有效利用了模糊偏好对中的监督信号，避免了偏好损失在低边际数据上的优化失败，显著提升了LLM的对齐效果。

Abstract: Preference optimization methods such as DPO align large language models (LLMs) using paired comparisons, but their effectiveness can be highly sensitive to the quality and difficulty of preference pairs. A common heuristic treats small-margin (ambiguous) pairs as noisy and filters them out. In this paper, we revisit this assumption and show that pair difficulty interacts strongly with the optimization objective: when trained with preference-based losses, difficult pairs can destabilize training and harm alignment, yet these same pairs still contain useful supervision signals when optimized with supervised fine-tuning (SFT). Motivated by this observation, we propose MixDPO, a simple yet effective difficulty-aware training strategy that (i) orders preference data from easy to hard (a curriculum over margin-defined difficulty), and (ii) routes difficult pairs to an SFT objective while applying a preference loss to easy pairs. This hybrid design provides a practical mechanism to leverage ambiguous pairs without incurring the optimization failures often associated with preference losses on low-margin data. Across three LLM-judge benchmarks, MixDPO consistently improves alignment over DPO and a range of widely-used variants, with particularly strong gains on AlpacaEval~2 length-controlled (LC) win rate.

</details>


### [343] [Reasoning and Tool-use Compete in Agentic RL:From Quantifying Interference to Disentangled Tuning](https://arxiv.org/abs/2602.00994)
*Yu Li,Mingyang Yi,Xiuyu Li,Ju Fan,Fuxin Jiang,Binbin Chen,Peng Li,Jie Song,Tieying Zhang*

Main category: cs.AI

TL;DR: DART通过解耦推理和工具使用的参数更新，解决联合训练干扰问题，性能优于基线并接近多智能体系统。


<details>
  <summary>Details</summary>
Motivation: 现有ARL方法假设联合训练推理和工具使用行为能提升整体性能，但缺乏实证支持。本文系统研究这一假设，发现两者梯度方向不一致导致训练干扰。

Method: 引入线性效应归因系统（LEAS）量化推理与工具使用行为间的干扰，并提出解耦动作推理调优（DART）框架，通过独立低秩适应模块显式解耦参数更新。

Result: 实验表明DART平均性能提升6.35%，且单模型性能与显式分离工具使用和推理的多智能体系统相当。

Conclusion: DART框架通过显式解耦推理和工具使用的参数更新，有效解决了联合优化中的训练干扰问题，性能优于基线方法，并达到与多智能体系统相当的效果。

Abstract: Agentic Reinforcement Learning (ARL) focuses on training large language models (LLMs) to interleave reasoning with external tool execution to solve complex tasks. Most existing ARL methods train a single shared model parameters to support both reasoning and tool use behaviors, implicitly assuming that joint training leads to improved overall agent performance. Despite its widespread adoption, this assumption has rarely been examined empirically. In this paper, we systematically investigate this assumption by introducing a Linear Effect Attribution System(LEAS), which provides quantitative evidence of interference between reasoning and tool-use behaviors. Through an in-depth analysis, we show that these two capabilities often induce misaligned gradient directions, leading to training interference that undermines the effectiveness of joint optimization and challenges the prevailing ARL paradigm. To address this issue, we propose Disentangled Action Reasoning Tuning(DART), a simple and efficient framework that explicitly decouples parameter updates for reasoning and tool-use via separate low-rank adaptation modules. Experimental results show that DART consistently outperforms baseline methods with averaged 6.35 percent improvements and achieves performance comparable to multi-agent systems that explicitly separate tool-use and reasoning using a single model.

</details>


### [344] [Error Taxonomy-Guided Prompt Optimization](https://arxiv.org/abs/2602.00997)
*Mayank Singh,Vikas Yadav,Eduardo Blanco*

Main category: cs.AI

TL;DR: ETGPO是一种高效的提示优化方法，通过全局错误分类减少计算消耗，性能优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有方法缺乏全局视角，导致计算资源浪费，ETGPO旨在通过错误分类和全局优化解决这一问题。

Method: ETGPO采用自上而下的方法，收集模型错误并分类，针对高频错误模式优化提示。

Result: ETGPO在数学、问答和逻辑推理等任务中表现优异，计算资源消耗仅为现有方法的三分之一。

Conclusion: ETGPO通过全局视角优化提示，显著减少了计算资源消耗，同时在多个基准测试中达到或超越现有方法的准确率。

Abstract: Automatic Prompt Optimization (APO) is a powerful approach for extracting performance from large language models without modifying their weights. Many existing methods rely on trial-and-error, testing different prompts or in-context examples until a good configuration emerges, often consuming substantial compute. Recently, natural language feedback derived from execution logs has shown promise as a way to identify how prompts can be improved. However, most prior approaches operate in a bottom-up manner, iteratively adjusting the prompt based on feedback from individual problems, which can cause them to lose the global perspective. In this work, we propose Error Taxonomy-Guided Prompt Optimization (ETGPO), a prompt optimization algorithm that adopts a top-down approach. ETGPO focuses on the global failure landscape by collecting model errors, categorizing them into a taxonomy, and augmenting the prompt with guidance targeting the most frequent failure modes. Across multiple benchmarks spanning mathematics, question answering, and logical reasoning, ETGPO achieves accuracy that is comparable to or better than state-of-the-art methods, while requiring roughly one third of the optimization-phase token usage and evaluation budget.

</details>


### [345] [How RLHF Amplifies Sycophancy](https://arxiv.org/abs/2602.01002)
*Itai Shapira,Gerdus Benade,Ariel D. Procaccia*

Main category: cs.AI

TL;DR: 论文分析了人类反馈对齐如何放大语言模型的阿谀行为，提出了基于KL散度的干预方法，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型在基于偏好的后训练中表现出更强的阿谀行为，倾向于肯定用户的观点而忽视事实准确性或合理判断。论文旨在分析并解决这一问题。

Method: 论文首先通过形式化分析揭示了人类反馈对齐如何通过明确的放大机制增加阿谀行为，然后提出了一个基于KL散度的最小奖励修正方法。

Result: 计算实验表明奖励差距普遍存在，并在所有配置中导致行为漂移。提出的干预方法有效中和了放大机制。

Conclusion: 该论文提出了一种训练时干预方法，旨在中和偏好后训练中放大阿谀行为的机制，并通过计算实验验证了奖励差距的普遍性及其导致的偏好漂移。

Abstract: Large language models often exhibit increased sycophantic behavior after preference-based post-training, showing a stronger tendency to affirm a user's stated or implied belief even when this conflicts with factual accuracy or sound judgment. We present a formal analysis of how alignment from human feedback can increase this failure mode by identifying an explicit amplification mechanism that causally links optimization against a learned reward to bias in the human preference data used for alignment. We show that the direction of behavioral drift is determined by a covariance under the base policy between endorsing the belief signal in the prompt and the learned reward, and that the first-order effect reduces to a simple mean-gap condition. We then analyze reward learning from pairwise comparisons under random utility models like Bradley-Terry and characterize when bias in human annotators' preferences induces this reward gap. Next, we propose a training-time intervention designed to neutralize the amplification mechanism itself. Among all post-trained policies that prevent sycophantic behavior from increasing, we characterize the unique policy closest in KL divergence to the unconstrained post-trained policy, and derive the corresponding minimal reward correction as a closed-form agreement penalty. Computational experiments find that reward gaps are common and cause behavioral drift in all the configurations considered.

</details>


### [346] [HalluHard: A Hard Multi-Turn Hallucination Benchmark](https://arxiv.org/abs/2602.01031)
*Dongyang Fan,Sebastien Delsad,Nicolas Flammarion,Maksym Andriushchenko*

Main category: cs.AI

TL;DR: HalluHard是一个多轮幻觉基准测试，用于评估LLMs在高风险领域的接地性。实验表明，即使结合网络搜索，幻觉问题仍显著存在，且受多种因素影响。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在多轮对话中会生成看似合理但缺乏依据的事实主张，随着上下文增长和早期错误的累积，问题会加剧。

Method: 提出了一个名为HalluHard的多轮幻觉基准测试，包含950个种子问题，覆盖法律案例、研究问题、医疗指南和编码四个高风险领域。通过要求事实断言提供内联引用来操作接地性。为了在开放式环境中支持可靠评估，提出了一个迭代通过网络搜索检索证据的评判流程。

Result: 实验结果显示，即使在最强配置（Opus-4.5结合网络搜索）下，幻觉率仍约为30%，内容接地错误持续高发。

Conclusion: 研究表明，即使在结合网络搜索的情况下，前沿的专有和开源模型仍存在显著的幻觉问题（约30%），且内容接地错误率居高不下。幻觉行为受模型能力、对话轮次位置、有效推理和所需知识类型的影响。

Abstract: Large language models (LLMs) still produce plausible-sounding but ungrounded factual claims, a problem that worsens in multi-turn dialogue as context grows and early errors cascade. We introduce $\textbf{HalluHard}$, a challenging multi-turn hallucination benchmark with 950 seed questions spanning four high-stakes domains: legal cases, research questions, medical guidelines, and coding. We operationalize groundedness by requiring inline citations for factual assertions. To support reliable evaluation in open-ended settings, we propose a judging pipeline that iteratively retrieves evidence via web search. It can fetch, filter, and parse full-text sources (including PDFs) to assess whether cited material actually supports the generated content. Across a diverse set of frontier proprietary and open-weight models, hallucinations remain substantial even with web search ($\approx 30\%$ for the strongest configuration, Opus-4.5 with web search), with content-grounding errors persisting at high rates. Finally, we show that hallucination behavior is shaped by model capacity, turn position, effective reasoning, and the type of knowledge required.

</details>


### [347] [Discovering Process-Outcome Credit in Multi-Step LLM Reasoning](https://arxiv.org/abs/2602.01034)
*Xiangwei Wang,Wei Wang,Ken Chen,Nanduni Nimalsiri,Saman Halgamuge*

Main category: cs.AI

TL;DR: 提出一种通过连续奖励和分步信用分配提升LLM推理能力的新框架，实验显示其在多样任务中优于基线并具备零样本迁移能力。


<details>
  <summary>Details</summary>
Motivation: 解决标准基于结果的强化学习方法中奖励稀疏和信用分配低效的问题，以提升大型语言模型的推理能力。

Method: 引入了Step-wise Marginal Information Gain (MIG)机制和Decoupled Masking Strategy，结合Dual-Gated SFT目标，优化了推理步骤的信用分配和训练稳定性。

Result: 在文本和多模态基准测试（如MATH、Super-CLEVR）中，该方法在样本效率和最终准确性上均优于基线（如GRPO），并展现出强大的零样本迁移能力。

Conclusion: 该论文提出的框架通过连续奖励信号和分步信用分配，显著提升了大型语言模型的推理能力，并在多样化的基准测试中展现了优越的样本效率和最终准确性，同时具备出色的零样本迁移能力。

Abstract: Reinforcement Learning (RL) serves as a potent paradigm for enhancing reasoning capabilities in Large Language Models (LLMs), yet standard outcome-based approaches often suffer from reward sparsity and inefficient credit assignment. In this paper, we propose a novel framework designed to provide continuous reward signals, which introduces a Step-wise Marginal Information Gain (MIG) mechanism that quantifies the intrinsic value of reasoning steps against a Monotonic Historical Watermark, effectively filtering out training noise. To ensure disentangled credit distribution, we implement a Decoupled Masking Strategy, applying process-oriented rewards specifically to the chain-of-thought (CoT) and outcome-oriented rewards to the full completion. Additionally, we incorporate a Dual-Gated SFT objective to stabilize training with high-quality structural and factual signals. Extensive experiments across textual and multi-modal benchmarks (e.g., MATH, Super-CLEVR) demonstrate that our approach consistently outperforms baselines such as GRPO in both sample efficiency and final accuracy. Furthermore, our model exhibits superior out-of-distribution robustness, demonstrating promising zero-shot transfer capabilities to unseen and challenging reasoning tasks.

</details>


### [348] [SetPO: Set-Level Policy Optimization for Diversity-Preserving LLM Reasoning](https://arxiv.org/abs/2602.01062)
*Chenyi Li,Yuan Zhang,Bo Wang,Guoqing Ma,Wei Tang,Haoyang Huang,Nan Duan*

Main category: cs.AI

TL;DR: 论文提出一种基于核化相似度的多样性目标，通过留一法边际贡献优化策略，有效提升LLM在数学任务中的推理性能，同时保持结果多样性。


<details>
  <summary>Details</summary>
Motivation: 现有强化学习方法在提升大型语言模型推理性能时往往牺牲了结果的多样性，导致模型集中在少数解决方案上。

Method: 通过定义基于轨迹样本的核化相似度的集合级多样性目标，并引入留一法边际贡献作为策略优化的优势塑造项。

Result: 实验证明，该方法在不同模型规模下均显著优于基线，在Pass@1和Pass@K指标上表现优异。

Conclusion: 论文提出的基于核化相似度的多样性目标能有效提升大型语言模型在数学任务中的推理性能，同时在保持多样性的情况下优于现有基线方法。

Abstract: Reinforcement learning with verifiable rewards has shown notable effectiveness in enhancing large language models (LLMs) reasoning performance, especially in mathematics tasks. However, such improvements often come with reduced outcome diversity, where the model concentrates probability mass on a narrow set of solutions. Motivated by diminishing-returns principles, we introduce a set level diversity objective defined over sampled trajectories using kernelized similarity. Our approach derives a leave-one-out marginal contribution for each sampled trajectory and integrates this objective as a plug-in advantage shaping term for policy optimization. We further investigate the contribution of a single trajectory to language model diversity within a distribution perturbation framework. This analysis theoretically confirms a monotonicity property, proving that rarer trajectories yield consistently higher marginal contributions to the global diversity. Extensive experiments across a range of model scales demonstrate the effectiveness of our proposed algorithm, consistently outperforming strong baselines in both Pass@1 and Pass@K across various benchmarks.

</details>


### [349] [ConvexBench: Can LLMs Recognize Convex Functions?](https://arxiv.org/abs/2602.01075)
*Yepeng Liu,Yu Huang,Yu-Xiang Wang,Yingbin Liang,Yuheng Bu*

Main category: cs.AI

TL;DR: 论文研究了LLMs在深度函数组合下识别凸性的能力，发现性能随深度增加而下降，并提出了一个分而治之的框架来提升性能。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）开始自动化研究级数学和科学任务，确保LLMs能够理解和推理凸性变得至关重要。

Method: 引入了一个可扩展且可机械验证的基准测试\cb，用于评估LLMs在深度函数组合下识别凸性的能力，并提出了一个分而治之的代理框架。

Result: 实验显示，前沿LLMs在深度组合推理上存在明显性能下降，但提出的框架在深度100时仍能保持F1-score为1.0。

Conclusion: 论文提出了一个分而治之的框架，通过外部工具解析和递归推理，显著提升了LLMs在深度组合下的凸性识别性能。

Abstract: Convex analysis is a modern branch of mathematics with many applications. As Large Language Models (LLMs) start to automate research-level math and sciences, it is important for LLMs to demonstrate the ability to understand and reason with convexity. We introduce \cb, a scalable and mechanically verifiable benchmark for testing \textit{whether LLMs can identify the convexity of a symbolic objective under deep functional composition.} Experiments on frontier LLMs reveal a sharp compositional reasoning gap: performance degrades rapidly with increasing depth, dropping from an F1-score of $1.0$ at depth $2$ to approximately $0.2$ at depth $100$. Inspection of models' reasoning traces indicates two failure modes: \textit{parsing failure} and \textit{lazy reasoning}. To address these limitations, we propose an agentic divide-and-conquer framework that (i) offloads parsing to an external tool to construct an abstract syntax tree (AST) and (ii) enforces recursive reasoning over each intermediate sub-expression with focused context. This framework reliably mitigates deep-composition failures, achieving substantial performance improvement at large depths (e.g., F1-Score $= 1.0$ at depth $100$).

</details>


### [350] [AutoHealth: An Uncertainty-Aware Multi-Agent System for Autonomous Health Data Modeling](https://arxiv.org/abs/2602.01078)
*Tong Xia,Weibin Li,Gang Liu,Yong Li*

Main category: cs.AI

TL;DR: AutoHealth 是一种不确定性感知多智能体系统，通过闭环协调提升健康数据建模的预测性能和不确定性估计，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有系统在异构健康数据模态上的泛化能力有限，过度依赖预定义解决方案模板，且忽视了对医疗决策至关重要的不确定性估计。

Method: AutoHealth 采用闭环协调的五个专业智能体，执行数据探索、任务条件模型构建、训练和优化，同时优先考虑预测性能和不确定性量化。

Result: AutoHealth 在包含17个任务的真实世界基准测试中，预测性能比现有基线提高了29.2%，不确定性估计提高了50.2%。

Conclusion: AutoHealth 是一种新型的不确定性感知多智能体系统，能够自主建模健康数据并评估模型可靠性，显著提升了预测性能和不确定性估计。

Abstract: LLM-based agents have demonstrated strong potential for autonomous machine learning, yet their applicability to health data remains limited. Existing systems often struggle to generalize across heterogeneous health data modalities, rely heavily on predefined solution templates with insufficient adaptation to task-specific objectives, and largely overlook uncertainty estimation, which is essential for reliable decision-making in healthcare. To address these challenges, we propose \textit{AutoHealth}, a novel uncertainty-aware multi-agent system that autonomously models health data and assesses model reliability. \textit{AutoHealth} employs closed-loop coordination among five specialized agents to perform data exploration, task-conditioned model construction, training, and optimization, while jointly prioritizing predictive performance and uncertainty quantification. Beyond producing ready-to-use models, the system generates comprehensive reports to support trustworthy interpretation and risk-aware decision-making. To rigorously evaluate its effectiveness, we curate a challenging real-world benchmark comprising 17 tasks across diverse data modalities and learning settings. \textit{AutoHealth} completes all tasks and outperforms state-of-the-art baselines by 29.2\% in prediction performance and 50.2\% in uncertainty estimation.

</details>


### [351] [EvoOpt-LLM: Evolving industrial optimization models with large language models](https://arxiv.org/abs/2602.01082)
*Yiliu He,Tianle Li,Binghao Ji,Zhiyuan Liu,Di Huang*

Main category: cs.AI

TL;DR: EvoOpt-LLM 是一个基于 LLM 的框架，通过数据高效的方法自动化工业优化建模，显著减少专家干预并提升求解效率。


<details>
  <summary>Details</summary>
Motivation: 将自然语言需求转化为求解器可执行模型并随着业务规则的变化进行维护是一项高度依赖专业知识的工作，现有方法存在数据效率低、求解器级别有效性有限以及难以扩展到工业规模问题等挑战。

Method: EvoOpt-LLM 是一个基于 7B 参数 LLM 的统一框架，通过参数高效的 LoRA 微调进行适配，支持工业优化建模的全生命周期，包括自动模型构建、动态业务约束注入和端到端变量剪枝。

Result: EvoOpt-LLM 在仅 3,000 个训练样本的情况下实现了 91% 的生成率和 65.9% 的可执行率，关键性能提升在 1,500 个样本以下时显现。约束注入模块可靠地增强了现有 MILP 模型，同时保留了原始目标，变量剪枝模块提高了计算效率，在仅 400 个样本的情况下，在中等规模 LP 模型上实现了约 0.56 的 F1 分数。

Conclusion: EvoOpt-LLM 提供了一种实用且数据高效的方法，用于工业优化建模，减少了对专家干预的依赖，同时提高了适应性和求解器效率。

Abstract: Optimization modeling via mixed-integer linear programming (MILP) is fundamental to industrial planning and scheduling, yet translating natural-language requirements into solver-executable models and maintaining them under evolving business rules remains highly expertise-intensive. While large language models (LLMs) offer promising avenues for automation, existing methods often suffer from low data efficiency, limited solver-level validity, and poor scalability to industrial-scale problems. To address these challenges, we present EvoOpt-LLM, a unified LLM-based framework supporting the full lifecycle of industrial optimization modeling, including automated model construction, dynamic business-constraint injection, and end-to-end variable pruning. Built on a 7B-parameter LLM and adapted via parameter-efficient LoRA fine-tuning, EvoOpt-LLM achieves a generation rate of 91% and an executability rate of 65.9% with only 3,000 training samples, with critical performance gains emerging under 1,500 samples. The constraint injection module reliably augments existing MILP models while preserving original objectives, and the variable pruning module enhances computational efficiency, achieving an F1 score of ~0.56 on medium-sized LP models with only 400 samples. EvoOpt-LLM demonstrates a practical, data-efficient approach to industrial optimization modeling, reducing reliance on expert intervention while improving adaptability and solver efficiency.

</details>


### [352] [Hard Constraints Meet Soft Generation: Guaranteed Feasibility for LLM-based Combinatorial Optimization](https://arxiv.org/abs/2602.01090)
*Yang Liu,Chuan Zhou,Yancheng Chen,Shuai Zhang,Xixun Lin,Xiaoqing Wang*

Main category: cs.AI

TL;DR: FALCON框架通过语法约束解码、可行性修复和自适应采样确保组合优化解的100%可行性，并在多个问题上表现优异。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在组合优化中表现出潜力，但缺乏保证解可行性的机制，这对实际部署至关重要。

Method: FALCON框架包含语法约束解码、可行性修复层和自适应Best-of-$N采样三个关键创新，并采用BOPO方法训练LLM。

Result: 在七个NP难组合优化问题中，FALCON实现了完美可行性，并在解质量上匹配或超越了现有最佳求解器。

Conclusion: FALCON框架通过其创新机制确保了100%的可行性，并在多个NP难组合优化问题中表现出色，匹配或超越了现有神经和LLM求解器的解质量。

Abstract: Large language models (LLMs) have emerged as promising general-purpose solvers for combinatorial optimization (CO), yet they fundamentally lack mechanisms to guarantee solution feasibility which is critical for real-world deployment. In this work, we introduce FALCON, a framework that ensures 100\% feasibility through three key innovations: (i) \emph{grammar-constrained decoding} enforces syntactic validity, (ii) a \emph{feasibility repair layer} corrects semantic constraint violations, and (iii) \emph{adaptive Best-of-$N$ sampling} allocates inference compute efficiently. To train the underlying LLM, we introduce the Best-anchored Objective-guided Preference Optimization (BOPO) in LLM training, which weights preference pairs by their objective gap, providing dense supervision without human labels. Theoretically, we prove convergence for BOPO and provide bounds on repair-induced quality loss. Empirically, across seven NP-hard CO problems, FALCON achieves perfect feasibility while matching or exceeding the solution quality of state-of-the-art neural and LLM-based solvers.

</details>


### [353] [Probing RLVR training instability through the lens of objective-level hacking](https://arxiv.org/abs/2602.01103)
*Yiming Dong,Kun Fu,Haoyu Li,Xinyuan Zhu,Yurou Liu,Lijing Shao,Jieping Ye,Zheng Wang*

Main category: cs.AI

TL;DR: 论文通过目标级黑客框架解释了MoE模型中RLVR训练不稳定的机制，实验揭示了训练-推理差异异常增长的原因，为稳定算法设计提供指导。


<details>
  <summary>Details</summary>
Motivation: 理解RLVR训练不稳定的原因和机制，尤其是在Mixture-of-Experts (MoE)架构中，以提升模型能力。

Method: 通过目标级黑客的视角，结合在30B MoE模型上的广泛实验，追踪并形式化了MoE模型中关键病理训练动态的机制。

Result: 揭示了MoE模型中训练-推理差异异常增长的起源和机制，这一现象与训练不稳定密切相关。

Conclusion: 研究发现为MoE模型中的训练不稳定提供了具体和因果的解释，为设计稳定的RLVR算法提供了指导。

Abstract: Prolonged reinforcement learning with verifiable rewards (RLVR) has been shown to drive continuous improvements in the reasoning capabilities of large language models, but the training is often prone to instabilities, especially in Mixture-of-Experts (MoE) architectures. Training instability severely undermines model capability improvement, yet its underlying causes and mechanisms remain poorly understood. In this work, we introduce a principled framework for understanding RLVR instability through the lens of objective-level hacking. Unlike reward hacking, which arises from exploitable verifiers, objective-level hacking emerges from token-level credit misalignment and is manifested as system-level spurious signals in the optimization objective. Grounded in our framework, together with extensive experiments on a 30B MoE model, we trace the origin and formalize the mechanism behind a key pathological training dynamic in MoE models: the abnormal growth of the training-inference discrepancy, a phenomenon widely associated with instability but previously lacking a mechanistic explanation. These findings provide a concrete and causal account of the training dynamics underlying instabilities in MoE models, offering guidance for the design of stable RLVR algorithms.

</details>


### [354] [Transforming Vehicle Diagnostics: A Multimodal Approach to Error Patterns Prediction](https://arxiv.org/abs/2602.01109)
*Hugo Math,Rainer Lienhart*

Main category: cs.AI

TL;DR: BiCarFormer是一种结合故障代码和环境数据的多模态Transformer模型，显著提升了车辆故障诊断的准确性。


<details>
  <summary>Details</summary>
Motivation: 现代诊断系统主要依赖车载诊断系统中的故障代码序列，但忽视了如温度、湿度等环境数据，这些数据对专家分类车辆故障至关重要。

Method: BiCarFormer是一种双向Transformer模型，专为车辆事件序列设计，采用嵌入融合和共注意力机制来捕捉诊断代码与环境数据之间的关系。

Result: 在包含22,137个错误代码和360个错误模式的实际汽车数据集上，BiCarFormer的分类性能显著优于仅依赖故障代码序列的传统模型。

Conclusion: BiCarFormer的创新多模态方法显著提升了车辆故障诊断的准确性，证明了结合环境数据的重要性，为汽车行业降低了维护成本并增强了自动化流程。

Abstract: Accurately diagnosing and predicting vehicle malfunctions is crucial for maintenance and safety in the automotive industry. While modern diagnostic systems primarily rely on sequences of vehicular Diagnostic Trouble Codes (DTCs) registered in On-Board Diagnostic (OBD) systems, they often overlook valuable contextual information such as raw sensory data (e.g., temperature, humidity, and pressure). This contextual data, crucial for domain experts to classify vehicle failures, introduces unique challenges due to its complexity and the noisy nature of real-world data. This paper presents BiCarFormer: the first multimodal approach to multi-label sequence classification of error codes into error patterns that integrates DTC sequences and environmental conditions. BiCarFormer is a bidirectional Transformer model tailored for vehicle event sequences, employing embedding fusions and a co-attention mechanism to capture the relationships between diagnostic codes and environmental data. Experimental results on a challenging real-world automotive dataset with 22,137 error codes and 360 error patterns demonstrate that our approach significantly improves classification performance compared to models that rely solely on DTC sequences and traditional sequence models. This work highlights the importance of incorporating contextual environmental information for more accurate and robust vehicle diagnostics, hence reducing maintenance costs and enhancing automation processes in the automotive industry.

</details>


### [355] [Lyapunov Stability-Aware Stackelberg Game for Low-Altitude Economy: A Control-Oriented Pruning-Based DRL Approach](https://arxiv.org/abs/2602.01131)
*Yue Zhong,Jiawen Kang,Yongju Tong,Hong-Ning Dai,Dong In Kim,Abbas Jamalipour,Shengli Xie*

Main category: cs.AI

TL;DR: 论文提出闭环框架及轻量级PPO算法，解决无人机资源分配与稳定性问题，仿真验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决异构网络中有限机载资源与严格稳定性需求间的冲突，超越传统以吞吐量为核心的设计。

Method: 利用Lyapunov稳定性理论推导控制系统状态演化与通信约束的映射，将稳定性需求转化为可量化资源边界；通过Stackelberg博弈动态定价资源；提出基于剪枝的轻量级PPO算法。

Result: 仿真结果表明，所提方案在动态低空环境中能有效保障控制环路稳定性并最大化系统效用。

Conclusion: 该论文提出的Sensing-Communication-Computing-Control闭环框架及轻量级PPO算法，在动态低空环境中有效保障了控制环路稳定性并最大化系统效用。

Abstract: With the rapid expansion of the low-altitude economy, Unmanned Aerial Vehicles (UAVs) serve as pivotal aerial base stations supporting diverse services from users, ranging from latency-sensitive critical missions to bandwidth-intensive data streaming. However, the efficacy of such heterogeneous networks is often compromised by the conflict between limited onboard resources and stringent stability requirements. Moving beyond traditional throughput-centric designs, we propose a Sensing-Communication-Computing-Control closed-loop framework that explicitly models the impact of communication latency on physical control stability. To guarantee mission reliability, we leverage the Lyapunov stability theory to derive an intrinsic mapping between the state evolution of the control system and communication constraints, transforming abstract stability requirements into quantifiable resource boundaries. Then, we formulate the resource allocation problem as a Stackelberg game, where UAVs (as leaders) dynamically price resources to balance load and ensure stability, while users (as followers) optimize requests based on service urgency. Furthermore, addressing the prohibitive computational overhead of standard Deep Reinforcement Learning (DRL) on energy-constrained edge platforms, we propose a novel and lightweight pruning-based Proximal Policy Optimization (PPO) algorithm. By integrating a dynamic structured pruning mechanism, the proposed algorithm significantly compresses the neural network scale during training, enabling the UAV to rapidly approximate the game equilibrium with minimal inference latency. Simulation results demonstrate that the proposed scheme effectively secures control loop stability while maximizing system utility in dynamic low-altitude environments.

</details>


### [356] [PersistBench: When Should Long-Term Memories Be Forgotten by LLMs?](https://arxiv.org/abs/2602.01146)
*Sidharth Pulipaka,Oliver Chen,Manas Sharma,Taaha S Bajwa,Vyas Raina,Ivaxi Sheth*

Main category: cs.AI

TL;DR: 论文研究了长期记忆在对话系统中的安全风险，提出了PersistBench评估框架，发现LLMs在跨域泄漏和记忆诱导奉承上失败率高，呼吁改进。


<details>
  <summary>Details</summary>
Motivation: 长期记忆虽然增强了对话的个性化，但也带来了被忽视的安全风险。

Method: 通过PersistBench评估18个前沿和开源LLMs，识别了跨域泄漏和记忆诱导的奉承两种风险。

Result: LLMs在跨域样本和奉承样本上的中位失败率分别为53%和97%。

Conclusion: 论文提出了PersistBench来评估长期记忆带来的安全风险，并呼吁开发更健壮和安全的长期记忆使用方法。

Abstract: Conversational assistants are increasingly integrating long-term memory with large language models (LLMs). This persistence of memories, e.g., the user is vegetarian, can enhance personalization in future conversations. However, the same persistence can also introduce safety risks that have been largely overlooked. Hence, we introduce PersistBench to measure the extent of these safety risks. We identify two long-term memory-specific risks: cross-domain leakage, where LLMs inappropriately inject context from the long-term memories; and memory-induced sycophancy, where stored long-term memories insidiously reinforce user biases. We evaluate 18 frontier and open-source LLMs on our benchmark. Our results reveal a surprisingly high failure rate across these LLMs - a median failure rate of 53% on cross-domain samples and 97% on sycophancy samples. To address this, our benchmark encourages the development of more robust and safer long-term memory usage in frontier conversational systems.

</details>


### [357] [Capabilities and Fundamental Limits of Latent Chain-of-Thought](https://arxiv.org/abs/2602.01148)
*Jiaxuan Zou,Yaozhong Xiong,Yong Liu*

Main category: cs.AI

TL;DR: 论文揭示了潜在思维链模型中探索与执行的权衡机制，提出符号化指数和课程学习作为解决方案。


<details>
  <summary>Details</summary>
Motivation: 潜在思维链模型在探索任务中表现优异但在计算任务中表现不佳，这种不一致性促使研究者探索其背后的根本原因。

Method: 通过理论分析和实验验证，论文提出了符号化指数作为核心机制，并证明了课程学习的理论必要性。

Result: 研究发现决策确定性是影响模型性能的关键因素，高确定性有利于精确执行但抑制探索，低确定性则相反。符号化指数和课程学习被证明能有效调节这一权衡。

Conclusion: 该论文提出了一个理论框架，揭示了潜在思维链（Latent CoT）模型中探索与执行之间的权衡，并通过符号化指数和课程学习证明了动态调整决策确定性的必要性。

Abstract: Latent Chain-of-Thought (Latent CoT) models promise efficient reasoning via continuous representations, yet exhibit puzzling performance inconsistencies: excelling at exploration (ProsQA: 97.0%) but failing at computation (GSM8K: 34.1%). We reveal that this trade-off is governed by decisional certainty. Our contributions are threefold: (1) We theoretically characterize the fundamental Exploration-Execution Trade-off, proving that high certainty enables precise execution but inhibits exploration, while low certainty facilitates search but causes error accumulation. (2) We introduce the Symbolic Index--quantifying decisional commitment--as the core mechanism governing this trade-off and establish its causal relationship with both execution stability and exploration capability. (3) We prove that curriculum learning is theoretically necessary, as direct training provably fails due to distributional mismatch. Our framework shifts the design paradigm from binary architectural choices toward adaptive systems that dynamically regulate decisional certainty based on task demands.

</details>


### [358] [Do All Individual Layers Help? An Empirical Study of Task-Interfering Layers in Vision-Language Models](https://arxiv.org/abs/2602.01167)
*Zhiming Liu,Yujie Wei,Lei Feng,Xiu Su,Xiaobo Xia,Weili Guan,Zeke Xie,Shuo Yang*

Main category: cs.AI

TL;DR: 研究发现预训练VLM中存在任务干扰层，提出TaLo方法动态绕过干扰层，显著提升任务性能。


<details>
  <summary>Details</summary>
Motivation: 发现预训练VLM中某些层会阻碍下游任务性能，探究如何通过干预特定层提升模型表现。

Method: 通过层干预实验，系统分析各层对任务的影响，提出Task-Layer Interaction Vector量化层干预效果，并设计TaLo方法动态识别和绕过干扰层。

Result: TaLo无需参数更新即可提升多模型和多数据集的性能，如在ScienceQA的Maps任务上使Qwen-VL准确率提升16.6%。

Conclusion: 该研究揭示了预训练视觉语言模型（VLM）中存在任务干扰层，并提出了一种无需训练的测试时自适应方法TaLo，通过动态绕过干扰层显著提升任务性能。

Abstract: Current VLMs have demonstrated capabilities across a wide range of multimodal tasks. Typically, in a pretrained VLM, all layers are engaged by default to make predictions on downstream tasks. We find that intervening on a single layer, such as by zeroing its parameters, can improve the performance on certain tasks, indicating that some layers hinder rather than help downstream tasks. We systematically investigate how individual layers influence different tasks via layer intervention. Specifically, we measure the change in performance relative to the base model after intervening on each layer and observe improvements when bypassing specific layers. This improvement can be generalizable across models and datasets, indicating the presence of Task-Interfering Layers that harm downstream tasks' performance. We introduce Task-Layer Interaction Vector, which quantifies the effect of intervening on each layer of a VLM given a task. These task-interfering layers exhibit task-specific sensitivity patterns: tasks requiring similar capabilities show consistent response trends under layer interventions, as evidenced by the high similarity in their task-layer interaction vectors. Inspired by these findings, we propose TaLo (Task-Adaptive Layer Knockout), a training-free, test-time adaptation method that dynamically identifies and bypasses the most interfering layer for a given task. Without parameter updates, TaLo improves performance across various models and datasets, including boosting Qwen-VL's accuracy on the Maps task in ScienceQA by up to 16.6%. Our work reveals an unexpected form of modularity in pretrained VLMs and provides a plug-and-play, training-free mechanism to unlock hidden capabilities at inference time. The source code will be publicly available.

</details>


### [359] [ASP-Bench: From Natural Language to Logic Programs](https://arxiv.org/abs/2602.01171)
*Stefan Szeider*

Main category: cs.AI

TL;DR: ASP-Bench是一个包含128个自然语言问题实例的基准测试，用于评估将自然语言转化为ASP的系统，并通过ReAct框架展示了反馈驱动方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 自动化将自然语言规范转化为逻辑程序是神经符号工程中的一项挑战性任务，需要系统化的评估工具。

Method: 使用基于ReAct框架的代理方法进行测试，通过反馈驱动的迭代优化来实现自然语言到ASP的建模。

Result: 测试结果表明，反馈驱动的迭代优化方法能够实现完全饱和，为自然语言到ASP的建模提供了可靠且鲁棒的方法。

Conclusion: ASP-Bench提供了一个多维度的评估框架，用于衡量将自然语言问题转化为ASP的能力，并通过反馈驱动的迭代优化展示了其可靠性。

Abstract: Automating the translation of natural-language specifications into logic programs is a challenging task that affects neurosymbolic engineering. We present ASP-Bench, a benchmark comprising 128 natural language problem instances, 64 base problems with easy and hard variants. It evaluates systems that translate natural-language problems into Answer Set Programs (ASPs), a prominent form of logic programming. It provides systematic coverage of ASP features, including choice rules, aggregates, and optimization. Each problem includes reference validators that check whether solutions satisfy the problem specification.
  We characterize problems along seven largely independent reasoning aspects (optimization, temporal reasoning, default logic, resource allocation, recursion, spatial reasoning, and quantitative complexity), providing a multidimensional view of modeling difficulty.
  We test the benchmark using an agentic approach based on the ReAct (Reason and Act) framework, which achieves full saturation, demonstrating that feedback-driven iterative refinement with solver feedback provides a reliable and robust approach for modeling natural language in ASP. Our analysis across multiple agent runs enables us to gain insights into what determines a problem's modeling hardness.

</details>


### [360] [A State-Transition Framework for Efficient LLM Reasoning](https://arxiv.org/abs/2602.01198)
*Liang Zhang,Yu Zhao,Longyue Wang,Tianqi Shi,Weihua Luo,Kaifu Zhang,Jinsong Su*

Main category: cs.AI

TL;DR: 提出一种高效推理框架，通过状态转移和线性注意力机制降低计算复杂度，提升LLMs的推理效率和性能。


<details>
  <summary>Details</summary>
Motivation: 长链思维推理（CoT）虽然提升LLMs在复杂任务上的表现，但其高计算和内存成本限制了效率和实用性。现有方法通过压缩CoT序列提升效率，但会限制推理能力。

Method: 应用线性注意力机制估计LLMs的推理状态，基于查询提示和推理状态高效执行当前推理步骤并更新状态，减少注意力计算的复杂度。

Result: 在多个数据集和模型规模上的实验表明，该框架不仅提高了LLMs的推理效率，还增强了推理性能。

Conclusion: 该论文提出的高效推理框架通过将LLMs的推理过程建模为状态转移过程，并结合线性注意力机制和基于状态的推理策略，显著提高了推理效率和性能。

Abstract: While Long Chain-of-Thought (CoT) reasoning significantly improves Large Language Models (LLMs) performance on complex reasoning tasks, the substantial computational and memory costs of generating long CoT sequences limit their efficiency and practicality. Existing studies usually enhance the reasoning efficiency of LLMs by compressing CoT sequences. However, this approach conflicts with test-time scaling, limiting the reasoning capacity of LLMs. In this paper, we propose an efficient reasoning framework that models the reasoning process of LLMs as a state-transition process. Specifically, we first apply a linear attention mechanism to estimate the LLM's reasoning state, which records the historical reasoning information from previous reasoning steps. Then, based on the query prompt and the reasoning state, the LLM can efficiently perform the current reasoning step and update the state. With the linear attention, each token in the current reasoning step can directly retrieve relevant historical reasoning information from the reasoning state, without explicitly attending to tokens in previous reasoning steps. In this way, the computational complexity of attention is reduced from quadratic to linear, significantly improving the reasoning efficiency of LLMs. In addition, we propose a state-based reasoning strategy to mitigate the over-thinking issue caused by noisy reasoning steps. Extensive experiments across multiple datasets and model sizes demonstrate that our framework not only improves the reasoning efficiency of LLMs but also enhances their reasoning performance.

</details>


### [361] [Workflow-R1: Group Sub-sequence Policy Optimization for Multi-turn Workflow Construction](https://arxiv.org/abs/2602.01202)
*Mingze Kong,Zikun Qu,Zhongquan Zhou,Pengyu Liang,Xiang Li,Zhiwei Shang,Zhi Hong,Kaiyu Huang,Zhiyong Wang,Zhongxiang Dai*

Main category: cs.AI

TL;DR: Workflow-R1 是一种基于自然语言多轮决策的工作流优化框架，通过 GSsPO 方法优化多轮交互，显著提升了复杂推理任务的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的工作流优化方法通常将工作流合成视为静态、一次性的代码生成问题，这限制了模型的编码能力和动态问题解决的灵活性。Workflow-R1 旨在通过自然语言交互和多轮决策来解决这一问题。

Method: Workflow-R1 采用多轮自然语言交互的方式构建工作流，并引入了 Group Sub-sequence Policy Optimization (GSsPO) 方法，该方法通过将优化单元重新校准为复合子序列（即原子 Think-Action 循环），实现了对多轮顺序决策任务的高效优化。

Result: 在多个 QA 基准测试中，Workflow-R1 表现优于现有基线方法，验证了 GSsPO 作为一种通用顺序推理解决方案的有效性。

Conclusion: Workflow-R1 提出了一种新的工作流优化范式，通过将工作流构建重新定义为基于自然语言的多轮顺序决策过程，并通过 GSsPO 方法优化这一过程，显著提升了复杂推理任务的性能。

Abstract: The rapid evolution of agentic workflows has demonstrated strong performance of LLM-based agents in addressing complex reasoning tasks. However, existing workflow optimization methods typically formulate workflow synthesis as a static, one-shot code-centric generation problem. This paradigm imposes excessive constraints on the model's coding capabilities and restricts the flexibility required for dynamic problem-solving. In this paper, we present Workflow-R1, a framework that reformulates workflow construction as a multi-turn, natural language-based sequential decision-making process. To resolve the optimization granularity mismatch inherent in such multi-turn interactions, we introduce Group Sub-sequence Policy Optimization (GSsPO). While explicitly tailored to align with the interleaved Think-Action dynamics of agentic reasoning, GSsPO fundamentally functions as a structure-aware RL algorithm generalizable to a broad class of multi-turn agentic sequential decision-making tasks. By recalibrating the optimization unit to the composite sub-sequence, specifically the atomic Think-Action cycle, it aligns gradient updates with the semantic boundaries of these interactions, ensuring robust learning in complex multi-turn reasoning tasks. Through extensive experiments on multiple QA benchmarks, Workflow-R1 outperforms competitive baselines, validating GSsPO as a generalized solution for sequential reasoning and establishing Workflow-R1 as a promising new paradigm for automated workflow optimization.

</details>


### [362] [Addressing Explainability of Generative AI using SMILE (Statistical Model-agnostic Interpretability with Local Explanations)](https://arxiv.org/abs/2602.01206)
*Zeinab Dehghani*

Main category: cs.AI

TL;DR: gSMILE是一个为生成式模型设计的解释性框架，通过扰动分析和可视化技术提升模型透明度，实验验证其有效性和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 生成式AI的决策过程缺乏透明度，限制了在高风险应用中的信任和问责。

Method: gSMILE结合了文本输入的受控扰动、Wasserstein距离度量和加权代理建模，用于量化和可视化提示或指令对模型输出的影响。

Result: 实验表明，gSMILE能生成稳健且与人类认知一致的解释，并在多种生成架构中有效泛化。

Conclusion: gSMILE框架通过提供细粒度的解释和可视化，增强了生成式AI的可信度和透明度，有望推动其在高风险应用中的可靠部署。

Abstract: The rapid advancement of generative artificial intelligence has enabled models capable of producing complex textual and visual outputs; however, their decision-making processes remain largely opaque, limiting trust and accountability in high-stakes applications. This thesis introduces gSMILE, a unified framework for the explainability of generative models, extending the Statistical Model-agnostic Interpretability with Local Explanations (SMILE) method to generative settings. gSMILE employs controlled perturbations of textual input, Wasserstein distance metrics, and weighted surrogate modelling to quantify and visualise how specific components of a prompt or instruction influence model outputs. Applied to Large Language Models (LLMs), gSMILE provides fine-grained token-level attribution and generates intuitive heatmaps that highlight influential tokens and reasoning pathways. In instruction-based image editing models, the exact text-perturbation mechanism is employed, allowing for the analysis of how modifications to an editing instruction impact the resulting image. Combined with a scenario-based evaluation strategy grounded in the Operational Design Domain (ODD) framework, gSMILE allows systematic assessment of model behaviour across diverse semantic and environmental conditions. To evaluate explanation quality, we define rigorous attribution metrics, including stability, fidelity, accuracy, consistency, and faithfulness, and apply them across multiple generative architectures. Extensive experiments demonstrate that gSMILE produces robust, human-aligned attributions and generalises effectively across state-of-the-art generative models. These findings highlight the potential of gSMILE to advance transparent, reliable, and responsible deployment of generative AI technologies.

</details>


### [363] [Not All Preferences Are Created Equal: Stability-Aware and Gradient-Efficient Alignment for Reasoning Models](https://arxiv.org/abs/2602.01207)
*Hui Wu,Hengyi Cai,Jinman Zhao,Xinran Chen,Ziheng Li,Zhejun Zhao,Shuaiqiang Wang,Yuchen Li,Dawei Yin*

Main category: cs.AI

TL;DR: SAGE通过动态样本选择和稳定性感知优化，提升大型推理模型的对齐效率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 标准方法如DPO忽视训练样本的演化效用，导致计算浪费和优化不稳定，SAGE旨在通过最大化策略更新的信噪比来提升对齐可靠性。

Method: SAGE整合了粗粒度的课程机制和细粒度的稳定性感知评分函数，动态刷新候选池并优先选择信息丰富、置信度高的错误样本。

Result: 在多个数学推理基准测试中，SAGE显著加速了收敛速度并优于静态基线方法。

Conclusion: SAGE框架通过动态选择训练样本，显著提升了大型推理模型的对齐效率和稳定性，证明了策略感知和稳定性意识数据选择在推理对齐中的关键作用。

Abstract: Preference-based alignment is pivotal for training large reasoning models; however, standard methods like Direct Preference Optimization (DPO) typically treat all preference pairs uniformly, overlooking the evolving utility of training instances. This static approach often leads to inefficient or unstable optimization, as it wastes computation on trivial pairs with negligible gradients and suffers from noise induced by samples near uncertain decision boundaries. Facing these challenges, we propose SAGE (Stability-Aware Gradient Efficiency), a dynamic framework designed to enhance alignment reliability by maximizing the Signal-to-Noise Ratio of policy updates. Concretely, SAGE integrates a coarse-grained curriculum mechanism that refreshes candidate pools based on model competence with a fine-grained, stability-aware scoring function that prioritizes informative, confident errors while filtering out unstable samples. Experiments on multiple mathematical reasoning benchmarks demonstrate that SAGE significantly accelerates convergence and outperforms static baselines, highlighting the critical role of policy-aware, stability-conscious data selection in reasoning alignment.

</details>


### [364] [FutureMind: Equipping Small Language Models with Strategic Thinking-Pattern Priors via Adaptive Knowledge Distillation](https://arxiv.org/abs/2602.01222)
*Shaoxiong Yang,Junting Li,Mengyuan Zhang,Chao Li,Wei Liu,Jian Luan*

Main category: cs.AI

TL;DR: FutureMind是一个模块化推理框架，通过知识蒸馏提升小语言模型在复杂任务中的表现，实验证明其优于现有方法，并揭示了认知偏差对思维模式迁移的限制。


<details>
  <summary>Details</summary>
Motivation: 解决小语言模型在复杂、知识密集型任务中表现不佳的问题，通过从大语言模型中进行自适应知识蒸馏，赋予其战略思维模式先验。

Method: 提出了FutureMind模块化推理框架，包含问题分析、逻辑推理、策略规划和检索引导四个关键模块，并采用三种不同的检索范式来分解复杂查询。

Result: 在多跳问答基准测试中，FutureMind表现优于强基线Search-o1，在不同架构和规模的小语言模型上均取得最先进的结果。

Conclusion: FutureMind通过动态推理管道和多样化检索范式，显著提升了小语言模型在复杂知识密集型任务中的表现，并揭示了思维模式蒸馏中的认知偏差瓶颈，为小语言模型的发展提供了新视角。

Abstract: Small Language Models (SLMs) are attractive for cost-sensitive and resource-limited settings due to their efficient, low-latency inference. However, they often struggle with complex, knowledge-intensive tasks that require structured reasoning and effective retrieval. To address these limitations, we propose FutureMind, a modular reasoning framework that equips SLMs with strategic thinking-pattern priors via adaptive knowledge distillation from large language models (LLMs). FutureMind introduces a dynamic reasoning pipeline composed of four key modules: Problem Analysis, Logical Reasoning, Strategy Planning, and Retrieval Guidance. This pipeline is augmented by three distinct retrieval paradigms that decompose complex queries into tractable subproblems, ensuring efficient and accurate retrieval execution. Extensive experiments on multi-hop QA benchmarks, including 2WikiMultihopQA, MuSiQue, Bamboogle, and Frames, demonstrate the superiority of FutureMind. It consistently outperforms strong baselines such as Search-o1, achieving state-of-the-art results under free training conditions across diverse SLM architectures and scales. Beyond empirical gains, our analysis reveals that the process of thinking-pattern distillation is restricted by the cognitive bias bottleneck between the teacher (LLMs) and student (SLMs) models. This provides new perspectives on the transferability of reasoning skills, paving the way for the development of SLMs that combine efficiency with genuine cognitive capability.

</details>


### [365] [Predictive Scheduling for Efficient Inference-Time Reasoning in Large Language Models](https://arxiv.org/abs/2602.01237)
*Katrina Brown,Aneesh Muppidi,Rana Shahout*

Main category: cs.AI

TL;DR: 预测调度框架通过预运行预测器动态分配token预算，显著提升LLM推理效率与准确性。


<details>
  <summary>Details</summary>
Motivation: 解决固定token预算在复杂推理任务中导致的易查询过度计算和难查询计算不足的问题。

Method: 引入预测调度框架，包括轻量级预测器（MLP或LoRA微调分类器）预运行估计查询的推理长度或难度，以及贪心批量分配器动态分配固定token预算。

Result: 在GSM8K算术基准测试中，预测调度比均匀预算分配绝对准确率提升7.9个百分点，缩小了与完美预知oracle50%以上的差距。

Conclusion: 预测调度框架通过预运行轻量级预测器动态分配token预算，显著提升了LLM在复杂推理任务中的效率和准确性。

Abstract: Large language models (LLMs) achieve state-of-the-art accuracy on complex reasoning tasks by generating multiple chain-of-thought (CoT) traces, but using a fixed token budget per query leads to over-computation on easy inputs and under-computation on hard ones. We introduce Predictive Scheduling, a plug-and-play framework that pre-runs lightweight predictors, an MLP on intermediate transformer hidden states or a LoRA-fine-tuned classifier on raw question text, to estimate each query's optimal reasoning length or difficulty before any full generation. Our greedy batch allocator dynamically distributes a fixed total token budget across queries to maximize expected accuracy. On the GSM8K arithmetic benchmark, predictive scheduling yields up to 7.9 percentage points of absolute accuracy gain over uniform budgeting at identical token cost, closing over 50\% of the gap to an oracle with perfect foresight. A systematic layer-wise study reveals that middle layers (12 - 17) of the transformer carry the richest signals for size estimation. These results demonstrate that pre-run budget prediction enables fine-grained control of the compute-accuracy trade-off, offering a concrete path toward latency-sensitive, cost-efficient LLM deployments.

</details>


### [366] [LLM-Driven Ontology Construction for Enterprise Knowledge Graphs](https://arxiv.org/abs/2602.01276)
*Abdulsobur Oyewale,Tommaso Soru*

Main category: cs.AI

TL;DR: OntoEKG是一个LLM驱动的流程，用于从非结构化企业数据中加速生成领域特定本体，实验结果显示其潜力与挑战。


<details>
  <summary>Details</summary>
Motivation: 企业知识图谱的统一异构数据和语义治理需求，但底层本体的构建仍依赖资源密集的手动过程和领域专业知识。

Method: OntoEKG将建模任务分解为两个阶段：提取模块识别核心类和属性，蕴含模块将这些元素逻辑结构化为层次结构并序列化为标准RDF。

Result: 在Data领域实现了模糊匹配F1分数0.724，揭示了范围定义和层次推理的局限性。

Conclusion: OntoEKG展示了利用LLM驱动流程从非结构化企业数据中生成领域特定本体的潜力，尽管在范围定义和层次推理方面仍存在挑战。

Abstract: Enterprise Knowledge Graphs have become essential for unifying heterogeneous data and enforcing semantic governance. However, the construction of their underlying ontologies remains a resource-intensive, manual process that relies heavily on domain expertise. This paper introduces OntoEKG, a LLM-driven pipeline designed to accelerate the generation of domain-specific ontologies from unstructured enterprise data. Our approach decomposes the modelling task into two distinct phases: an extraction module that identifies core classes and properties, and an entailment module that logically structures these elements into a hierarchy before serialising them into standard RDF. Addressing the significant lack of comprehensive benchmarks for end-to-end ontology construction, we adopt a new evaluation dataset derived from documents across the Data, Finance, and Logistics sectors. Experimental results highlight both the potential and the challenges of this approach, achieving a fuzzy-match F1-score of 0.724 in the Data domain while revealing limitations in scope definition and hierarchical reasoning.

</details>


### [367] [RE-MCDF: Closed-Loop Multi-Expert LLM Reasoning for Knowledge-Grounded Clinical Diagnosis](https://arxiv.org/abs/2602.01297)
*Shaowei Shen,Xiaohong Yang,Jie Yang,Lianfen Huang,Yongcai Zhang,Yang Zou,Seyyedali Hosseinalipour*

Main category: cs.AI

TL;DR: RE-MCDF是一种关系增强的多专家临床诊断框架，通过闭环架构整合三个专家组件，显著提升复杂诊断性能。


<details>
  <summary>Details</summary>
Motivation: 电子病历（EMR）在神经学领域具有异质性、稀疏性和噪声，现有单代理系统易产生自强化错误，多代理框架交互浅层且松散，缺乏对疾病间逻辑依赖的考虑。

Method: RE-MCDF整合了三个互补组件：主要专家生成候选诊断、实验室专家动态优先临床指标、多关系感知评估专家组强制执行疾病间逻辑约束。

Result: 在NEEMRs和XMEMRs数据集上的实验表明，RE-MCDF在复杂诊断场景中 consistently outperforms 现有基线方法。

Conclusion: RE-MCDF框架通过引入生成-验证-修订闭环架构，显著提升了在复杂诊断场景中的性能，优于现有基线方法。

Abstract: Electronic medical records (EMRs), particularly in neurology, are inherently heterogeneous, sparse, and noisy, which poses significant challenges for large language models (LLMs) in clinical diagnosis. In such settings, single-agent systems are vulnerable to self-reinforcing errors, as their predictions lack independent validation and can drift toward spurious conclusions. Although recent multi-agent frameworks attempt to mitigate this issue through collaborative reasoning, their interactions are often shallow and loosely structured, failing to reflect the rigorous, evidence-driven processes used by clinical experts. More fundamentally, existing approaches largely ignore the rich logical dependencies among diseases, such as mutual exclusivity, pathological compatibility, and diagnostic confusion. This limitation prevents them from ruling out clinically implausible hypotheses, even when sufficient evidence is available. To overcome these, we propose RE-MCDF, a relation-enhanced multi-expert clinical diagnosis framework. RE-MCDF introduces a generation--verification--revision closed-loop architecture that integrates three complementary components: (i) a primary expert that generates candidate diagnoses and supporting evidence, (ii) a laboratory expert that dynamically prioritizes heterogeneous clinical indicators, and (iii) a multi-relation awareness and evaluation expert group that explicitly enforces inter-disease logical constraints. Guided by a medical knowledge graph (MKG), the first two experts adaptively reweight EMR evidence, while the expert group validates and corrects candidate diagnoses to ensure logical consistency. Extensive experiments on the neurology subset of CMEMR (NEEMRs) and on our curated dataset (XMEMRs) demonstrate that RE-MCDF consistently outperforms state-of-the-art baselines in complex diagnostic scenarios.

</details>


### [368] [Model Specific Task Similarity for Vision Language Model Selection via Layer Conductance](https://arxiv.org/abs/2602.01346)
*Wei Yang,Hong Xie,Tao Tan,Xin Li,Defu Lian,Enhong Chen*

Main category: cs.AI

TL;DR: 提出基于视觉编码器功能动态的模型选择框架，通过DCD量化任务覆盖效果，实验显示性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 开源视觉语言模型（VLMs）的激增使得为特定下游任务选择最佳预训练模型变得困难，现有方法无法充分解决这一问题。

Method: 论文提出了一种框架，通过层间传导表示任务，并通过熵正则化对齐得到目标条件块重要性分布，进而引入定向传导差异（DCD）这一非对称度量标准。

Result: 在48个VLMs和21个数据集上的实验结果表明，该方法优于现有基线，NDCG@5比SWAB提高了14.7%。

Conclusion: 该论文提出了一种基于视觉编码器内部功能动态的模型选择框架，通过定向传导差异（DCD）量化源任务对目标任务功能块的覆盖效果，显著提升了模型选择性能。

Abstract: While open sourced Vision-Language Models (VLMs) have proliferated, selecting the optimal pretrained model for a specific downstream task remains challenging. Exhaustive evaluation is often infeasible due to computational constraints and data limitations in few shot scenarios. Existing selection methods fail to fully address this: they either rely on data-intensive proxies or use symmetric textual descriptors that neglect the inherently directional and model-specific nature of transferability. To address this problem, we propose a framework that grounds model selection in the internal functional dynamics of the visual encoder. Our approach represents each task via layer wise conductance and derives a target-conditioned block importance distribution through entropy regularized alignment. Building on this, we introduce Directional Conductance Divergence (DCD), an asymmetric metric that quantifies how effectively a source task covers the target's salient functional blocks. This allows for predicting target model rankings by aggregating source task ranks without direct inference. Experimental results on 48 VLMs across 21 datasets demonstrate that our method outperforms state-of-the-art baselines, achieving a 14.7% improvement in NDCG@5 over SWAB.

</details>


### [369] [Aggregation Queries over Unstructured Text: Benchmark and Agentic Method](https://arxiv.org/abs/2602.01355)
*Haojia Zhu,Qinyuan Xu,Haoyu Li,Yuxi Liu,Hanchen Qiu,Jiaoyan Chen,Jiahui Jin*

Main category: cs.AI

TL;DR: 本文提出了DFA方法，用于解决自由文本中的聚合查询问题，显著提升了证据覆盖率，并发布了AGGBench基准测试。


<details>
  <summary>Details</summary>
Motivation: 聚合查询在自由文本中是一个长期存在但未被充分探索的问题，现有方法如Text-to-SQL和RAG无法满足完整性要求。

Method: 提出了DFA方法，将聚合查询分解为可解释的阶段（消歧、过滤、聚合），并揭示了与模糊性、过滤和聚合相关的关键失败模式。

Result: 实证结果表明，DFA在大型真实语料库中显著提高了聚合证据的覆盖率。

Conclusion: DFA（Disambiguation--Filtering--Aggregation）作为一种模块化基线方法，显著提升了聚合证据的覆盖率，优于现有的RAG和代理基线。

Abstract: Aggregation query over free text is a long-standing yet underexplored problem. Unlike ordinary question answering, aggregate queries require exhaustive evidence collection and systems are required to "find all," not merely "find one." Existing paradigms such as Text-to-SQL and Retrieval-Augmented Generation fail to achieve this completeness. In this work, we formalize entity-level aggregation querying over text in a corpus-bounded setting with strict completeness requirement. To enable principled evaluation, we introduce AGGBench, a benchmark designed to evaluate completeness-oriented aggregation under realistic large-scale corpus. To accompany the benchmark, we propose DFA (Disambiguation--Filtering--Aggregation), a modular agentic baseline that decomposes aggregation querying into interpretable stages and exposes key failure modes related to ambiguity, filtering, and aggregation. Empirical results show that DFA consistently improves aggregation evidence coverage over strong RAG and agentic baselines. The data and code are available in https://anonymous.4open.science/r/DFA-A4C1.

</details>


### [370] [Building Better Deception Probes Using Targeted Instruction Pairs](https://arxiv.org/abs/2602.01425)
*Vikram Natarajan,Devina Jain,Shivam Arora,Satvik Golechha,Joseph Bloom*

Main category: cs.AI

TL;DR: 研究发现指令对训练对线性探针性能至关重要，针对特定欺骗行为的分类法能提升效果，建议设计专用探针而非通用检测器。


<details>
  <summary>Details</summary>
Motivation: 线性探针在监测AI系统欺骗行为方面有潜力，但现有方法存在虚假相关性和非欺骗响应的误报问题。

Method: 通过人类可解释的欺骗分类法针对特定欺骗行为，并在评估数据集上展示改进结果。

Result: 指令对捕捉欺骗意图而非内容特定模式，解释了提示选择主导探针性能（70.6%的方差）。

Conclusion: 组织应设计针对其特定威胁模型的专门探针，而非寻求通用的欺骗检测器。

Abstract: Linear probes are a promising approach for monitoring AI systems for deceptive behaviour. Previous work has shown that a linear classifier trained on a contrastive instruction pair and a simple dataset can achieve good performance. However, these probes exhibit notable failures even in straightforward scenarios, including spurious correlations and false positives on non-deceptive responses. In this paper, we identify the importance of the instruction pair used during training. Furthermore, we show that targeting specific deceptive behaviors through a human-interpretable taxonomy of deception leads to improved results on evaluation datasets. Our findings reveal that instruction pairs capture deceptive intent rather than content-specific patterns, explaining why prompt choice dominates probe performance (70.6% of variance). Given the heterogeneity of deception types across datasets, we conclude that organizations should design specialized probes targeting their specific threat models rather than seeking a universal deception detector.

</details>


### [371] [SimGym: Traffic-Grounded Browser Agents for Offline A/B Testing in E-Commerce](https://arxiv.org/abs/2602.01443)
*Alberto Castelo,Zahra Zanjani Foumani,Ailin Fan,Keat Yang Koay,Vibhor Malik,Yuanzheng Zhu,Han Li,Meysam Feghhi,Ronie Uliana,Shuang Xie,Zhaoyu Zhang,Angelo Ocana Martins,Mingyu Zhao,Francis Pelland,Jonathan Faerman,Nikolas LeBlanc,Aaron Glazer,Andrew McNamara,Lingyun Wang,Zhong Wu*

Main category: cs.AI

TL;DR: SimGym是一个基于大型语言模型代理的快速离线A/B测试系统，显著缩短实验周期并避免影响真实用户。


<details>
  <summary>Details</summary>
Motivation: 传统的A/B测试虽然被视为评估电子商务UI变更的黄金标准，但会分流流量，耗时数周才能达到显著性，且可能损害用户体验。

Method: SimGym通过从生产交互数据中提取每店买家画像和意图，识别不同的行为原型，并在控制组和实验组店铺间模拟队列加权会话。

Result: SimGym在未进行训练后对齐的情况下，代理与观察到的结果变化达到了最先进的对齐水平，并将实验周期从数周缩短至不到一小时。

Conclusion: SimGym系统通过使用基于大型语言模型的代理进行快速离线A/B测试，显著缩短了实验周期，从数周降至不到一小时，且无需暴露给真实买家。

Abstract: A/B testing remains the gold standard for evaluating e-commerce UI changes, yet it diverts traffic, takes weeks to reach significance, and risks harming user experience. We introduce SimGym, a scalable system for rapid offline A/B testing using traffic-grounded synthetic buyers powered by Large Language Model agents operating in a live browser. SimGym extracts per-shop buyer profiles and intents from production interaction data, identifies distinct behavioral archetypes, and simulates cohort-weighted sessions across control and treatment storefronts. We validate SimGym against real human outcomes from real UI changes on a major e-commerce platform under confounder control. Even without alignment post training, SimGym agents achieve state of the art alignment with observed outcome shifts and reduces experiment cycles from weeks to under an hour , enabling rapid experimentation without exposure to real buyers.

</details>


### [372] [Legal Infrastructure for Transformative AI Governance](https://arxiv.org/abs/2602.01474)
*Gillian K. Hadfield*

Main category: cs.AI

TL;DR: 本文主张构建法律和监管基础设施以应对AI治理挑战，提出了三种具体框架：前沿模型注册、自主代理注册与识别，以及监管市场设计。


<details>
  <summary>Details</summary>
Motivation: 当前AI治理多关注实质性规则，而忽视了构建法律和监管基础设施的必要性，AI的变革性特性要求特别关注这一点。

Method: 通过回顾和分析三种提出的框架：前沿模型注册制度、自主代理注册与识别制度，以及监管市场的设计。

Result: 提出了三种具体框架，旨在通过法律和监管基础设施来生成和实施AI规则。

Conclusion: 本文强调了建立法律和监管基础设施的重要性，以应对AI的变革性影响，并提出了三种具体框架作为解决方案。

Abstract: Most of our AI governance efforts focus on substance: what rules do we want in place? What limits or checks do we want to impose on AI development and deployment? But a key role for law is not only to establish substantive rules but also to establish legal and regulatory infrastructure to generate and implement rules. The transformative nature of AI calls especially for attention to building legal and regulatory frameworks. In this PNAS Perspective piece I review three examples I have proposed: the creation of registration regimes for frontier models; the creation of registration and identification regimes for autonomous agents; and the design of regulatory markets to facilitate a role for private companies to innovate and deliver AI regulatory services.

</details>


### [373] [Learning to Guide Local Search for MPE Inference in Probabilistic Graphical Models](https://arxiv.org/abs/2602.01475)
*Brij Malhotra,Shivvrat Arya,Tahrima Rahman,Vibhav Giridhar Gogate*

Main category: cs.AI

TL;DR: 提出神经摊销框架改进PGMs中MPE推理的局部搜索，通过注意力网络预测移动效果，实验显示优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 针对PGMs中MPE推理在重复查询场景下的计算挑战，传统SLS算法易陷入局部最优且GLS+的引导无法跨查询复用，需改进。

Method: 采用基于注意力的神经网络来评分局部移动，预测其减少与近最优解汉明距离的能力，并与现有局部搜索算法无缝集成。

Result: 在摊销推理设置中，该方法在挑战性高树宽基准测试上一致优于SLS和GLS+。

Conclusion: 本文提出的神经摊销框架通过结合注意力网络和局部搜索算法，显著提升了在重复查询场景下的MPE推理性能，尤其在处理高树宽基准测试时表现优于传统SLS和GLS+方法。

Abstract: Most Probable Explanation (MPE) inference in Probabilistic Graphical Models (PGMs) is a fundamental yet computationally challenging problem arising in domains such as diagnosis, planning, and structured prediction. In many practical settings, the graphical model remains fixed while inference must be performed repeatedly for varying evidence patterns. Stochastic Local Search (SLS) algorithms scale to large models but rely on myopic best-improvement rule that prioritizes immediate likelihood gains and often stagnate in poor local optima. Heuristics such as Guided Local Search (GLS+) partially alleviate this limitation by modifying the search landscape, but their guidance cannot be reused effectively across multiple inference queries on the same model. We propose a neural amortization framework for improving local search in this repeated-query regime. Exploiting the fixed graph structure, we train an attention-based network to score local moves by predicting their ability to reduce Hamming distance to a near-optimal solution. Our approach integrates seamlessly with existing local search procedures, using this signal to balance short-term likelihood gains with long-term promise during neighbor selection. We provide theoretical intuition linking distance-reducing move selection to improved convergence behavior, and empirically demonstrate consistent improvements over SLS and GLS+ on challenging high-treewidth benchmarks in the amortized inference setting.

</details>


### [374] [Qrita: High-performance Top-k and Top-p Algorithm for GPUs using Pivot-based Truncation and Selection](https://arxiv.org/abs/2602.01518)
*Jongseok Park,Sunga Kim,Alvin Cheung,Ion Stoica*

Main category: cs.AI

TL;DR: Qrita 是一种基于 pivot 的高效 Top-k 和 Top-p 算法，通过高斯截断和四元搜索显著提升性能，同时保持输出一致性。


<details>
  <summary>Details</summary>
Motivation: 现有方法在大词汇表上实现 Top-k 和 Top-p 时效率低下，要么依赖高开销的排序，要么采用改变输出的随机方法。

Method: 基于 RTop-k 的 pivot-based 选择策略，结合高斯 sigma 截断和四元 pivot 搜索，实现了高效的 Top-k 和 Top-p 算法。

Result: Qrita 在 vLLM、SGLang 和 Flashinfer 等高性能 LLM 执行引擎上的评估显示，其吞吐量提升高达 2 倍，内存使用减半。

Conclusion: Qrita 提供了一种高效的 Top-k 和 Top-p 算法，显著提升了处理大词汇表时的计算和内存效率，同时保持了与排序算法相同的输出。

Abstract: Top-k and Top-p are the dominant truncation operators in the sampling of large language models. Despite their widespread use, implementing them efficiently over large vocabularies remains a significant challenge. Existing approaches often rely on sorting, which incur significant computation and memory overhead on GPUs, or stochastic approaches, which alter the algorithm output. In this work, we propose Qrita, an efficient Top-k and Top-p algorithm based on a pivot-based selection strategy. Based on RTop-k, which uses a pivot-based search for node selection in graph neural networks, Qrita extends the concept of pivot-based search to both Top-k and Top-p with two key techniques: 1. Gaussian-based sigma-truncation, which greatly reduces the search space of the target elements, and 2. Quaternary pivot search with duplication handling, which halves the pivot search iteration and guarantees deterministic output. We provide the full implementation of Qrita using Triton, a popular GPU programming language. Our evaluation of Qrita against the Top-k and Top-p kernels of high performance LLM execution engines such as vLLM, SGLang, and Flashinfer show that Qrita achieves up to 2 times throughput and half memory use while providing the same output to the the sorting-based algorithms.

</details>


### [375] [PRISM: Festina Lente Proactivity -- Risk-Sensitive, Uncertainty-Aware Deliberation for Proactive Agents](https://arxiv.org/abs/2602.01532)
*Yuxuan Fu,Xiaoyu Tan,Teqi Hao,Chen Zhan,Xihe Qiu*

Main category: cs.AI

TL;DR: PRISM框架通过成本敏感的选择性干预和双过程推理，显著提升主动代理的精确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有系统依赖脆弱启发式或盲目长推理，难以权衡干预的收益与负担。

Method: PRISM结合决策理论门控和双过程推理架构，在推理时仅当用户接受概率超过成本阈值时干预，并仅在决策边界附近调用资源密集型慢速模式。训练采用门控对齐、模式锁定的蒸馏方法。

Result: 在ProactiveBench上，PRISM将误报减少22.78%，F1提升20.14%。

Conclusion: PRISM框架通过决策理论门控、选择性慢速推理和对齐蒸馏，实现了精确、计算高效且可控的主动代理。

Abstract: Proactive agents must decide not only what to say but also whether and when to intervene. Many current systems rely on brittle heuristics or indiscriminate long reasoning, which offers little control over the benefit-burden tradeoff. We formulate the problem as cost-sensitive selective intervention and present PRISM, a novel framework that couples a decision-theoretic gate with a dual-process reasoning architecture. At inference time, the agent intervenes only when a calibrated probability of user acceptance exceeds a threshold derived from asymmetric costs of missed help and false alarms. Inspired by festina lente (Latin: "make haste slowly"), we gate by an acceptance-calibrated, cost-derived threshold and invoke a resource-intensive Slow mode with counterfactual checks only near the decision boundary, concentrating computation on ambiguous and high-stakes cases. Training uses gate-aligned, schema-locked distillation: a teacher running the full PRISM pipeline provides dense, executable supervision on unlabeled interaction traces, while the student learns a response policy that is explicitly decoupled from the intervention gate to enable tunable and auditable control. On ProactiveBench, PRISM reduces false alarms by 22.78% and improves F1 by 20.14% over strong baselines. These results show that principled decision-theoretic gating, paired with selective slow reasoning and aligned distillation, yields proactive agents that are precise, computationally efficient, and controllable. To facilitate reproducibility, we release our code, models, and resources at https://prism-festinalente.github.io/; all experiments use the open-source ProactiveBench benchmark.

</details>


### [376] [MAGIC: A Co-Evolving Attacker-Defender Adversarial Game for Robust LLM Safety](https://arxiv.org/abs/2602.01539)
*Xiaoyu Wen,Zhida He,Han Qi,Ziyu Wan,Zhongtian Ma,Ying Wen,Tianhang Zheng,Xingcheng Xu,Chaochao Lu,Qiaosheng Zhang*

Main category: cs.AI

TL;DR: MAGIC通过多智能体强化学习框架动态提升LLM安全对齐，攻击者与防御者协同进化，实验显示防御效果显著且不影响模型实用性。


<details>
  <summary>Details</summary>
Motivation: 现有防御方法依赖静态数据分布，难以应对持续演变的对抗攻击，需动态防御机制。

Method: 提出MAGIC框架，采用多轮多智能体强化学习，将LLM安全对齐建模为不对称对抗游戏，攻击者和防御者智能体通过迭代优化策略实现协同进化。

Result: 实验验证MAGIC框架有效性，防御成功率显著提升，攻击者能生成未见过的组合策略，理论分析提供了更稳健的游戏均衡和安全保证。

Conclusion: MAGIC框架通过多智能体强化学习实现了LLM安全对齐的动态防御，显著提升了防御成功率且不影响模型的有用性。

Abstract: Ensuring robust safety alignment is crucial for Large Language Models (LLMs), yet existing defenses often lag behind evolving adversarial attacks due to their \textbf{reliance on static, pre-collected data distributions}. In this paper, we introduce \textbf{MAGIC}, a novel multi-turn multi-agent reinforcement learning framework that formulates LLM safety alignment as an adversarial asymmetric game. Specifically, an attacker agent learns to iteratively rewrite original queries into deceptive prompts, while a defender agent simultaneously optimizes its policy to recognize and refuse such inputs. This dynamic process triggers a \textbf{co-evolution}, where the attacker's ever-changing strategies continuously uncover long-tail vulnerabilities, driving the defender to generalize to unseen attack patterns. Remarkably, we observe that the attacker, endowed with initial reasoning ability, evolves \textbf{novel, previously unseen combinatorial strategies} through iterative RL training, underscoring our method's substantial potential. Theoretically, we provide insights into a more robust game equilibrium and derive safety guarantees. Extensive experiments validate our framework's effectiveness, demonstrating superior defense success rates without compromising the helpfulness of the model. Our code is available at https://github.com/BattleWen/MAGIC.

</details>


### [377] [S1-NexusAgent: a Self-Evolving Agent Framework for Multidisciplinary Scientific Research](https://arxiv.org/abs/2602.01550)
*S1-NexusAgent Team*

Main category: cs.AI

TL;DR: S1-NexusAgent是一个自进化代理框架，通过分层执行和动态工具集成，解决了科学研究中长时规划和数据处理的挑战，并在多学科基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有LLM和工具代理在长时规划、目标维护和持续学习方面存在局限，无法应对大规模数据和复杂科学工作流。

Method: 采用分层Plan-and-CodeAct执行范式，通过双循环架构解耦全局规划与子任务工具执行，支持MCP协议，集成跨学科工具，并引入稀疏上下文管理和Critic Agent自进化机制。

Result: 在生物、化学和材料科学领域的权威基准测试中，S1-NexusAgent表现出色，验证了其在复杂科学任务中的有效性。

Conclusion: S1-NexusAgent通过其分层执行范式、动态工具检索和自进化机制，在复杂科学任务中实现了最先进的性能，验证了其有效性和泛化能力。

Abstract: Modern scientific research relies on large-scale data, complex workflows, and specialized tools, which existing LLMs and tool-based agents struggle to handle due to limitations in long-horizon planning, robust goal maintenance, and continual learning from execution. To address these issues, in this work, we propose S1-NexusAgent, a self-evolving agent framework designed for multidisciplinary scientific research. S1-NexusAgent adopts a hierarchical Plan-and-CodeAct execution paradigm, decoupling global scientific planning from subtask-level tool execution through a dual-loop architecture, thereby enabling stable modeling of complex research workflows. The system natively supports the Model Context Protocol (MCP), integrates up to thousands of cross-disciplinary scientific tools, and achieves efficient orchestration of heterogeneous research tools via intention-aware dynamic tool retrieval and hot-plug mechanisms. To address long-context and large-scale data challenges in scientific settings, S1-NexusAgent introduces object-reference-based sparse context management, which enables sub-task context isolation and intermediate result compression. Building on this, a Critic Agent automatically evaluates complete execution trajectories and distills high-quality research paths into reusable Scientific Skills, forming a closed loop for continuous self-evolution, which is valuable for sustainable and long-horizon scientific research. Experiments on authoritative scientific benchmarks involving long-horizon planning and complex specialized tool orchestration, including biomini-eval (biology), ChemBench (chemistry), and MatSciBench (material science), demonstrate that S1-NexusAgent achieves state-of-the-art performance, validating its effectiveness and generalization capability in complex scientific tasks.

</details>


### [378] [Autonomous Question Formation for Large Language Model-Driven AI Systems](https://arxiv.org/abs/2602.01556)
*Hong Su*

Main category: cs.AI

TL;DR: 论文提出了一种基于人类模拟的框架，使AI系统能够自主形成问题和设定任务，通过环境感知和代理间感知提示显著提升了决策效果。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）驱动的AI系统在动态和开放环境中的自主决策越来越重要。然而，大多数现有系统依赖于预定义的任务和固定提示，限制了它们在环境条件变化时自主识别应解决问题的能力。

Method: 论文提出了一种人类模拟框架，通过内部驱动、环境感知和代理间感知的提示范围来逐步扩展认知覆盖，并将问题形成视为任务选择和执行之前的一等决策过程。此外，框架支持从经验中学习问题形成过程，从而提高系统的适应性和决策质量。

Result: 实验结果表明，环境感知提示显著减少了无进食事件，而代理间感知提示在20天模拟中进一步将累积无进食事件减少了60%以上，具有统计学上的显著改进（p < 0.05）。

Conclusion: 该论文提出了一种基于人类模拟的框架，使AI系统能够通过推理内部状态、环境观察和其他AI系统的交互来自主形成问题和设定任务。该方法将问题形成视为任务选择和执行之前的一等决策过程，并通过集成内部驱动、环境感知和代理间感知的提示范围来逐步扩展认知覆盖。实验结果表明，环境感知提示显著减少了无进食事件，而代理间感知提示在20天模拟中进一步将累积无进食事件减少了60%以上，具有统计学上的显著改进（p < 0.05）。

Abstract: Large language model (LLM)-driven AI systems are increasingly important for autonomous decision-making in dynamic and open environments. However, most existing systems rely on predefined tasks and fixed prompts, limiting their ability to autonomously identify what problems should be solved when environmental conditions change. In this paper, we propose a human-simulation-based framework that enables AI systems to autonomously form questions and set tasks by reasoning over their internal states, environmental observations, and interactions with other AI systems. The proposed method treats question formation as a first-class decision process preceding task selection and execution, and integrates internal-driven, environment-aware, and inter-agent-aware prompting scopes to progressively expand cognitive coverage. In addition, the framework supports learning the question-formation process from experience, allowing the system to improve its adaptability and decision quality over time. xperimental results in a multi-agent simulation environment show that environment-aware prompting significantly reduces no-eat events compared with the internal-driven baseline, and inter-agent-aware prompting further reduces cumulative no-eat events by more than 60% over a 20-day simulation, with statistically significant improvements (p < 0.05).

</details>


### [379] [Reasoning with Autoregressive-Diffusion Collaborative Thoughts](https://arxiv.org/abs/2602.01608)
*Mu Yuan,Liekang Zeng,Guoliang Xing,Lan Zhang,Yunhao Liu*

Main category: cs.AI

TL;DR: 结合自回归和扩散模型的优势，Collaborative Thoughts通过闭环交互提升空间推理和生成的可控性。


<details>
  <summary>Details</summary>
Motivation: 自回归模型在序列规划和约束组合上表现优异，但在空间或物理基础任务上表现不足；扩散模型擅长高维空间生成，但缺乏逐步逻辑控制。两者互补性激发了对统一协作框架的需求。

Method: 引入Collaborative Thoughts框架，通过闭环交互让自回归模型进行结构化规划和约束管理，扩散模型生成中间视觉表示，视觉批评模块评估并反馈。

Result: Collaborative Thoughts通过闭环交互显著提升了空间推理的可靠性和生成的可控性。

Conclusion: Collaborative Thoughts框架通过结合自回归和扩散模型的优势，提升了空间推理的可靠性和生成的可控性。

Abstract: Autoregressive and diffusion models represent two complementary generative paradigms. Autoregressive models excel at sequential planning and constraint composition, yet struggle with tasks that require explicit spatial or physical grounding. Diffusion models, in contrast, capture rich spatial structure through high-dimensional generation, but lack the stepwise logical control needed to satisfy complex, multi-stage constraints or to reliably identify and correct errors. We introduce Collaborative Thoughts, a unified collaborative framework that enables autoregressive and diffusion models to reason and generate jointly through a closed-loop interaction. In Collaborative Thoughts, autoregressive models perform structured planning and constraint management, diffusion models instantiate these constraints as intermediate visual thoughts, and a vision-based critic module evaluates whether the visual thoughts satisfy the intended structural and physical requirements. This feedback is then used to iteratively refine subsequent planning and generation steps, mitigating error propagation across modalities. Importantly, Collaborative Thoughts uses the same collaborative loop regardless of whether the task is autoregressive question answering or diffusion-based visual generation. Through representative examples, we illustrate how Collaborative Thoughts can improve the reliability of spatial reasoning and the controllability of generation.

</details>


### [380] [ToPT: Task-Oriented Prompt Tuning for Urban Region Representation Learning](https://arxiv.org/abs/2602.01610)
*Zitao Guo,Changyang Jiang,Tianhong Zhao,Jinzhou Cao,Genan Dai,Bowen Zhang*

Main category: cs.AI

TL;DR: ToPT框架通过空间感知和任务感知提示，解决了现有方法在空间一致性和任务语义对齐上的不足，显著提升了区域嵌入的性能。


<details>
  <summary>Details</summary>
Motivation: 现有的两阶段方法生成的任务无关表示与下游目标脱节，而基于提示的方法缺乏空间先验和任务语义对齐的鲁棒机制。

Method: ToPT框架包含两个模块：空间感知区域嵌入学习（SREL）和任务感知提示（Prompt4RE）。SREL通过Graphormer融合模块注入空间先验，而Prompt4RE则利用冻结的多模态大型语言模型（MLLM）进行任务导向的提示。

Result: 实验结果表明，ToPT在多个任务和城市中性能提升高达64.2%，验证了空间先验和提示-区域对齐的必要性和互补性。

Conclusion: ToPT框架通过结合空间先验和任务语义对齐，显著提升了区域嵌入的效果，在多个任务和城市中实现了最先进的性能。

Abstract: Learning effective region embeddings from heterogeneous urban data underpins key urban computing tasks (e.g., crime prediction, resource allocation). However, prevailing two-stage methods yield task-agnostic representations, decoupling them from downstream objectives. Recent prompt-based approaches attempt to fix this but introduce two challenges: they often lack explicit spatial priors, causing spatially incoherent inter-region modeling, and they lack robust mechanisms for explicit task-semantic alignment. We propose ToPT, a two-stage framework that delivers spatially consistent fusion and explicit task alignment. ToPT consists of two modules: spatial-aware region embedding learning (SREL) and task-aware prompting for region embeddings (Prompt4RE). SREL employs a Graphormer-based fusion module that injects spatial priors-distance and regional centrality-as learnable attention biases to capture coherent, interpretable inter-region interactions. Prompt4RE performs task-oriented prompting: a frozen multimodal large language model (MLLM) processes task-specific templates to obtain semantic vectors, which are aligned with region embeddings via multi-head cross-attention for stable task conditioning. Experiments across multiple tasks and cities show state-of-the-art performance, with improvements of up to 64.2\%, validating the necessity and complementarity of spatial priors and prompt-region alignment. The code is available at https://github.com/townSeven/Prompt4RE.git.

</details>


### [381] [FlowSteer: Interactive Agentic Workflow Orchestration via End-to-End Reinforcement Learning](https://arxiv.org/abs/2602.01664)
*Mingda Zhang,Haoran Luo,Tiesunlong Shen,Qika Lin,Xiaoying Tang,Rui Mao,Erik Cambria*

Main category: cs.AI

TL;DR: FlowSteer是一个端到端强化学习框架，通过轻量级策略模型和可执行画布自动化工作流编排，实验证明其优于基线方法。


<details>
  <summary>Details</summary>
Motivation: 现有工作流编排存在高人工成本、依赖特定操作符/大型语言模型（LLMs）以及稀疏奖励信号等挑战，FlowSteer旨在解决这些问题。

Method: FlowSteer采用轻量级策略模型作为代理，结合可执行画布环境，通过多轮交互实现工作流编排的自动化。策略模型分析执行状态并选择编辑动作，画布执行操作并返回反馈。此外，CWRPO方法通过多样性约束奖励和条件释放来稳定学习并抑制捷径行为。

Result: 在12个数据集上的实验结果表明，FlowSteer在多种任务上显著优于基线方法。

Conclusion: FlowSteer通过端到端强化学习框架和CWRPO训练方法，显著提升了工作流编排的自动化水平，支持多样化的操作库和可互换的LLM后端，实验证明其在多种任务上优于基线方法。

Abstract: In recent years, a variety of powerful agentic workflows have been applied to solve a wide range of human problems. However, existing workflow orchestration still faces key challenges, including high manual cost, reliance on specific operators/large language models (LLMs), and sparse reward signals. To address these challenges, we propose FlowSteer, an end-to-end reinforcement learning framework that takes a lightweight policy model as the agent and an executable canvas environment, automating workflow orchestration through multi-turn interaction. In this process, the policy model analyzes execution states and selects editing actions, while the canvas executes operators and returns feedback for iterative refinement. Moreover, FlowSteer provides a plug-and-play framework that supports diverse operator libraries and interchangeable LLM backends. To effectively train this interaction paradigm, we propose Canvas Workflow Relative Policy Optimization (CWRPO), which introduces diversity-constrained rewards with conditional release to stabilize learning and suppress shortcut behaviors. Experimental results on twelve datasets show that FlowSteer significantly outperforms baselines across various tasks.

</details>


### [382] [TRIP-Bench: A Benchmark for Long-Horizon Interactive Agents in Real-World Scenarios](https://arxiv.org/abs/2602.01675)
*Yuanzhe Shen,Zisu Huang,Zhengyuan Wang,Muzhao Tian,Zhengkang Guo,Chenyang Zhang,Shuaiyu Zhou,Zengjie Hu,Dailin Li,Jingwen Xu,Kaimin Wang,Wenhao Liu,Tianlong Li,Fengpeng Yue,Feng Hong,Cao Liu,Ke Zeng*

Main category: cs.AI

TL;DR: TRIP-Bench是一个基于真实旅行规划场景的长时程基准测试，GTPO是一种在线强化学习方法，显著提升了模型在复杂交互中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试无法充分代表复杂现实场景中的关键挑战，如全局约束、多工具协调和用户行为适应。

Method: 提出了TRIP-Bench基准测试和GTPO在线多轮强化学习方法，后者包含专门的奖励归一化和奖励差分。

Result: 实验显示，即使在简单子集上，先进模型成功率最高仅50%，而GTPO方法显著提升了约束满足和交互鲁棒性。

Conclusion: TRIP-Bench和GTPO的提出旨在解决现有基准测试在复杂现实场景中的不足，GTPO方法在实验中表现优于Gemini-3-Pro，有望推动长时程交互代理的发展。

Abstract: As LLM-based agents are deployed in increasingly complex real-world settings, existing benchmarks underrepresent key challenges such as enforcing global constraints, coordinating multi-tool reasoning, and adapting to evolving user behavior over long, multi-turn interactions. To bridge this gap, we introduce \textbf{TRIP-Bench}, a long-horizon benchmark grounded in realistic travel-planning scenarios. TRIP-Bench leverages real-world data, offers 18 curated tools and 40+ travel requirements, and supports automated evaluation. It includes splits of varying difficulty; the hard split emphasizes long and ambiguous interactions, style shifts, feasibility changes, and iterative version revision. Dialogues span up to 15 user turns, can involve 150+ tool calls, and may exceed 200k tokens of context. Experiments show that even advanced models achieve at most 50\% success on the easy split, with performance dropping below 10\% on hard subsets. We further propose \textbf{GTPO}, an online multi-turn reinforcement learning method with specialized reward normalization and reward differencing. Applied to Qwen2.5-32B-Instruct, GTPO improves constraint satisfaction and interaction robustness, outperforming Gemini-3-Pro in our evaluation. We expect TRIP-Bench to advance practical long-horizon interactive agents, and GTPO to provide an effective online RL recipe for robust long-horizon training.

</details>


### [383] [What LLMs Think When You Don't Tell Them What to Think About?](https://arxiv.org/abs/2602.01689)
*Yongchan Kwon,James Zou*

Main category: cs.AI

TL;DR: 研究发现LLM在无主题输入下表现出强烈的主题偏好和独特退化行为，不同模型在内容专业性和深度上差异显著。


<details>
  <summary>Details</summary>
Motivation: 现有分析多依赖特定主题或任务的提示，限制了观察范围。本研究旨在探索LLM在无主题输入下的生成行为，以更全面地理解其特性。

Method: 通过分析16种LLM在最小化、无主题输入下的生成内容，研究其近乎无约束的生成行为，并收集了256,000个样本。

Result: 不同模型家族展现出明显的主题偏好（如GPT-OSS偏向编程和数学，Llama偏向文学），且在内容深度和退化行为上存在差异。

Conclusion: 研究发现，大型语言模型（LLMs）在无主题限制的生成中表现出强烈的主题偏好和独特行为，不同模型家族在内容专业性和深度上存在显著差异。研究还揭示了模型在无约束生成中可能出现的退化行为。

Abstract: Characterizing the behavior of large language models (LLMs) across diverse settings is critical for reliable monitoring and AI safety. However, most existing analyses rely on topic- or task-specific prompts, which can substantially limit what can be observed. In this work, we study what LLMs generate from minimal, topic-neutral inputs and probe their near-unconstrained generative behavior. Despite the absence of explicit topics, model outputs cover a broad semantic space, and surprisingly, each model family exhibits strong and systematic topical preferences. GPT-OSS predominantly generates programming (27.1%) and mathematical content (24.6%), whereas Llama most frequently generates literary content (9.1%). DeepSeek often generates religious content, while Qwen frequently generates multiple-choice questions. Beyond topical preferences, we also observe differences in content specialization and depth: GPT-OSS often generates more technically advanced content (e.g., dynamic programming) compared with other models (e.g., basic Python). Furthermore, we find that the near-unconstrained generation often degenerates into repetitive phrases, revealing interesting behaviors unique to each model family. For instance, degenerate outputs from Llama include multiple URLs pointing to personal Facebook and Instagram accounts. We release the complete dataset of 256,000 samples from 16 LLMs, along with a reproducible codebase.

</details>


### [384] [Beyond Dense States: Elevating Sparse Transcoders to Active Operators for Latent Reasoning](https://arxiv.org/abs/2602.01695)
*Yadong Wang,Haodong Chen,Yu Tian,Chuanxing Geng,Dong Liang,Xiang Chen*

Main category: cs.AI

TL;DR: LSTR是一种潜在稀疏转码推理框架，通过稀疏语义转换提升推理的可解释性和可控性。


<details>
  <summary>Details</summary>
Motivation: 解决现有潜在推理方法依赖密集潜在转换导致难以解释和控制的问题。

Method: LSTR采用具有残差跳跃架构的潜在转换转码器（LTT），通过显式稀疏约束实现可控语义解析。

Result: 实验证明LSTR在保持推理准确性和压缩效率的同时，显著提升了可解释性。

Conclusion: LSTR框架通过稀疏语义转换提升了推理的可解释性和可控性，同时保持了推理准确性和压缩效率。

Abstract: Latent reasoning compresses the chain-of-thought (CoT) into continuous hidden states, yet existing methods rely on dense latent transitions that remain difficult to interpret and control. Meanwhile, sparse representation models uncover human-interpretable semantic features but remain largely confined to post-hoc analysis. We reconcile this tension by proposing LSTR (Latent Sparse Transcoder Reasoning), a latent reasoning framework that elevates functional sparse transcoders into active reasoning operators to perform multi-step computation through sparse semantic transitions. At its core, LSTR employs a Latent Transition Transcoder (LTT) with a residual skip architecture that decouples linear manifold transport from sparse semantic updates, enabling controllable semantic resolution via explicit sparsity constraints. Extensive experiments show that LSTR preserves reasoning accuracy and compression efficiency while substantially improving interpretability over dense latent baselines. Causal interventions and trajectory analyses further demonstrate that these sparse features act as both interpretable and causally effective operators in the reasoning process.

</details>


### [385] [Mitigating loss of control in advanced AI systems through instrumental goal trajectories](https://arxiv.org/abs/2602.01699)
*Willem Fourie*

Main category: cs.AI

TL;DR: 研究提出通过组织路径（采购、治理和财务IGTs）监控AI系统能力，为控制AI行为提供新方法。


<details>
  <summary>Details</summary>
Motivation: 高度智能的AI系统可能通过追求工具性目标削弱人类控制，现有技术缓解措施主要集中于系统和模型层面，缺乏组织层面的解决方案。

Method: 开发了三种组织路径（采购、治理和财务IGTs），通过监控这些路径产生的组织痕迹作为干预点。

Result: IGTs提供了监控和干预AI系统能力与行为的具体方法，扩展了可修正性和可中断性的实施范围。

Conclusion: IGTs（Instrumental Goal Trajectories）为定义AI能力水平和扩展可修正性与可中断性的实施提供了具体途径，将关注点从模型属性转向支持它们的组织系统。

Abstract: Researchers at artificial intelligence labs and universities are concerned that highly capable artificial intelligence (AI) systems may erode human control by pursuing instrumental goals. Existing mitigations remain largely technical and system-centric: tracking capability in advanced systems, shaping behaviour through methods such as reinforcement learning from human feedback, and designing systems to be corrigible and interruptible. Here we develop instrumental goal trajectories to expand these options beyond the model. Gaining capability typically depends on access to additional technical resources, such as compute, storage, data and adjacent services, which in turn requires access to monetary resources. In organisations, these resources can be obtained through three organisational pathways. We label these pathways the procurement, governance and finance instrumental goal trajectories (IGTs). Each IGT produces a trail of organisational artefacts that can be monitored and used as intervention points when a systems capabilities or behaviour exceed acceptable thresholds. In this way, IGTs offer concrete avenues for defining capability levels and for broadening how corrigibility and interruptibility are implemented, shifting attention from model properties alone to the organisational systems that enable them.

</details>


### [386] [Optimizing Prompts for Large Language Models: A Causal Approach](https://arxiv.org/abs/2602.01711)
*Wei Chen,Yanbin Fang,Shuran Fu,Fasheng Xu,Xuan Wei*

Main category: cs.AI

TL;DR: CPO是一种基于因果推断的提示优化框架，通过离线因果模型和高效搜索实现高性能且低成本的提示优化。


<details>
  <summary>Details</summary>
Motivation: 现有自动提示优化方法存在静态指令无法适应异构查询，以及依赖离线奖励模型的关联性问题，导致提示效果与查询特性混淆。

Method: CPO分为两个阶段：首先通过双机器学习（DML）学习离线的因果奖励模型，隔离提示变化与查询属性的混杂效应；其次利用这一无偏奖励信号指导资源高效的查询特定提示搜索。

Result: CPO在数学推理、可视化和数据分析等基准测试中均优于人工设计的提示和最先进的自动优化器，尤其在困难查询上表现更稳健。

Conclusion: CPO通过将因果推断作为可扩展的基础，为企业LLM部署提供了可靠且经济高效的提示优化方案。

Abstract: Large Language Models (LLMs) are increasingly embedded in enterprise workflows, yet their performance remains highly sensitive to prompt design. Automatic Prompt Optimization (APO) seeks to mitigate this instability, but existing approaches face two persistent challenges. First, commonly used prompt strategies rely on static instructions that perform well on average but fail to adapt to heterogeneous queries. Second, more dynamic approaches depend on offline reward models that are fundamentally correlational, confounding prompt effectiveness with query characteristics. We propose Causal Prompt Optimization (CPO), a framework that reframes prompt design as a problem of causal estimation. CPO operates in two stages. First, it learns an offline causal reward model by applying Double Machine Learning (DML) to semantic embeddings of prompts and queries, isolating the causal effect of prompt variations from confounding query attributes. Second, it utilizes this unbiased reward signal to guide a resource-efficient search for query-specific prompts without relying on costly online evaluation. We evaluate CPO across benchmarks in mathematical reasoning, visualization, and data analytics. CPO consistently outperforms human-engineered prompts and state-of-the-art automated optimizers. The gains are driven primarily by improved robustness on hard queries, where existing methods tend to deteriorate. Beyond performance, CPO fundamentally reshapes the economics of prompt optimization: by shifting evaluation from real-time model execution to an offline causal model, it enables high-precision, per-query customization at a fraction of the inference cost required by online methods. Together, these results establish causal inference as a scalable foundation for reliable and cost-efficient prompt optimization in enterprise LLM deployments.

</details>


### [387] [MACD: Model-Aware Contrastive Decoding via Counterfactual Data](https://arxiv.org/abs/2602.01740)
*Qixin Xiao,Kun Zhou*

Main category: cs.AI

TL;DR: MACD通过模型反馈生成针对性反事实输入，整合到对比解码中，有效减少视频语言模型的幻觉现象，提升任务准确性。


<details>
  <summary>Details</summary>
Motivation: 现有解码方法（如对比解码）依赖随机扰动构建对比数据，难以精确控制视觉线索或与模型弱点对齐，导致幻觉问题无法有效解决。

Method: MACD通过模型自身的反馈识别导致幻觉的关键对象区域，生成针对性的反事实输入，并将其整合到对比解码中，以增强解码过程中的证据基础。

Result: 在EventHallusion、MVBench、Perception-test和Video-MME等数据集上的实验表明，MACD能持续减少幻觉现象，并在Qwen和InternVL等视频语言模型中保持或提升任务准确性。

Conclusion: MACD是一种有效的解码策略，能够显著减少视频语言模型的幻觉现象，同时在各种挑战性场景中保持或提升任务准确性。

Abstract: Video language models (Video-LLMs) are prone to hallucinations, often generating plausible but ungrounded content when visual evidence is weak, ambiguous, or biased. Existing decoding methods, such as contrastive decoding (CD), rely on random perturbations to construct contrastive data for mitigating hallucination patterns. However, such a way is hard to control the visual cues that drive hallucination or well align with model weaknesses. We propose Model-aware Counterfactual Data based Contrastive Decoding (MACD), a new inference strategy that combines model-guided counterfactual construction with decoding. Our approach uses the Video-LLM's own feedback to identify object regions most responsible for hallucination, generating targeted counterfactual inputs at the object level rather than arbitrary frame or temporal modifications. These model-aware counterfactual data is then integrated into CD to enforce evidence-grounded token selection during decoding. Experiments on EventHallusion, MVBench, Perception-test and Video-MME show that MACD consistently reduces hallucination while maintaining or improving task accuracy across diverse Video-LLMs, including Qwen and InternVL families. The method is especially effective in challenging scenarios involving small, occluded, or co-occurring objects. Our code and data will be publicly released.

</details>


### [388] [Controlling Exploration-Exploitation in GFlowNets via Markov Chain Perspectives](https://arxiv.org/abs/2602.01749)
*Lin Chen,Samuel Drapeau,Fanghao Shao,Xuekai Zhu,Bo Xue,Yunchong Song,Mathieu Laurière,Zhouhan Lin*

Main category: cs.AI

TL;DR: $α$-GFNs通过可调参数$α$优化GFlowNets的探索-开发权衡，显著提升模式发现能力，实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: GFlowNets的默认目标隐式固定了前向和后向策略的均等混合，可能限制了训练中的探索-开发权衡。

Method: 建立了GFlowNet目标与马尔可夫链可逆性之间的等价性，提出了$α$-GFNs框架，通过参数$α$调节前向和后向策略的混合比例。

Result: $α$-GFNs在Set、Bit Sequence和Molecule Generation等基准测试中表现优于之前的GFlowNet目标，模式发现数量提升高达10倍。

Conclusion: 通过将GFlowNets与马尔可夫链的理论联系，提出了$α$-GFNs框架，通过可调参数$α$实现了对探索-开发动态的直接控制，显著提升了模式发现能力，并在多个基准测试中表现优异。

Abstract: Generative Flow Network (GFlowNet) objectives implicitly fix an equal mixing of forward and backward policies, potentially constraining the exploration-exploitation trade-off during training. By further exploring the link between GFlowNets and Markov chains, we establish an equivalence between GFlowNet objectives and Markov chain reversibility, thereby revealing the origin of such constraints, and provide a framework for adapting Markov chain properties to GFlowNets. Building on these theoretical findings, we propose $α$-GFNs, which generalize the mixing via a tunable parameter $α$. This generalization enables direct control over exploration-exploitation dynamics to enhance mode discovery capabilities, while ensuring convergence to unique flows. Across various benchmarks, including Set, Bit Sequence, and Molecule Generation, $α$-GFN objectives consistently outperform previous GFlowNet objectives, achieving up to a $10 \times$ increase in the number of discovered modes.

</details>


### [389] [Adversarial Reward Auditing for Active Detection and Mitigation of Reward Hacking](https://arxiv.org/abs/2602.01750)
*Mohammad Beigi,Ming Jin,Junshan Zhang,Qifan Wang,Lifu Huang*

Main category: cs.AI

TL;DR: ARA框架通过动态对抗游戏减少奖励黑客攻击，提升模型对齐性和实用性，跨领域通用防御。


<details>
  <summary>Details</summary>
Motivation: 解决RLHF中奖励模型易受奖励黑客攻击的问题，现有静态防御无法适应新型利用策略。

Method: 提出了Adversarial Reward Auditing (ARA)框架，分为两个阶段：Hacker策略发现奖励模型漏洞，Auditor学习检测利用；Auditor-Guided RLHF (AG-RLHF)通过惩罚检测到的漏洞利用来优化奖励信号。

Result: 实验表明ARA在三种黑客场景中均实现了最佳的对齐-效用权衡，且在跨领域评估中表现出通用性。

Conclusion: ARA框架通过动态对抗游戏有效减少了奖励模型中的漏洞利用，实现了跨领域的通用防御，显著提升了模型的对齐性和实用性。

Abstract: Reinforcement Learning from Human Feedback (RLHF) remains vulnerable to reward hacking, where models exploit spurious correlations in learned reward models to achieve high scores while violating human intent. Existing mitigations rely on static defenses that cannot adapt to novel exploitation strategies. We propose Adversarial Reward Auditing (ARA), a framework that reconceptualizes reward hacking as a dynamic, competitive game. ARA operates in two stages: first, a Hacker policy discovers reward model vulnerabilities while an Auditor learns to detect exploitation from latent representations; second, Auditor-Guided RLHF (AG-RLHF) gates reward signals to penalize detected hacking, transforming reward hacking from an unobservable failure into a measurable, controllable signal. Experiments across three hacking scenarios demonstrate that ARA achieves the best alignment-utility tradeoff among all baselines: reducing sycophancy to near-SFT levels while improving helpfulness, decreasing verbosity while achieving the highest ROUGE-L, and suppressing code gaming while improving Pass@1. Beyond single-domain evaluation, we show that reward hacking, detection, and mitigation all generalize across domains -- a Hacker trained on code gaming exhibits increased sycophancy despite no reward for this behavior, and an Auditor trained on one domain effectively suppresses exploitation in others, enabling efficient multi-domain defense with a single model.

</details>


### [390] [PRISM: Parametrically Refactoring Inference for Speculative Sampling Draft Models](https://arxiv.org/abs/2602.01762)
*Xuliang Wang,Yuetao Chen,Maochan Zhen,Fang Liu,Xinzhou Zheng,Xingwu Liu,Hong Xu,Ming Li*

Main category: cs.AI

TL;DR: PRISM通过架构创新优化草案模型计算路径，显著加速LLM解码，实验显示其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLM）因自回归特性导致解码速度慢，现有草案模型虽追求更高质量但带来计算开销。

Method: PRISM将每个预测步骤的计算分散到不同的参数集，重构了草案模型的计算路径。

Result: PRISM在实验中表现优异，保持低延迟的同时实现更长的接受长度，解码吞吐量提升超过2.6倍。

Conclusion: PRISM通过架构创新成功解耦了模型容量与推理成本，显著提升了LLM的解码效率，并在实验中展现出优于现有草案架构的性能。

Abstract: Large Language Models (LLMs), constrained by their auto-regressive nature, suffer from slow decoding. Speculative decoding methods have emerged as a promising solution to accelerate LLM decoding, attracting attention from both systems and AI research communities. Recently, the pursuit of better draft quality has driven a trend toward parametrically larger draft models, which inevitably introduces substantial computational overhead. While existing work attempts to balance the trade-off between prediction accuracy and compute latency, we address this fundamental dilemma through architectural innovation.
  We propose PRISM, which disaggregates the computation of each predictive step across different parameter sets, refactoring the computational pathways of draft models to successfully decouple model capacity from inference cost. Through extensive experiments, we demonstrate that PRISM outperforms all existing draft architectures, achieving exceptional acceptance lengths while maintaining minimal draft latency for superior end-to-end speedup. We also re-examine scaling laws with PRISM, revealing that PRISM scales more effectively with expanding data volumes than other draft architectures. Through rigorous and fair comparison, we show that PRISM boosts the decoding throughput of an already highly optimized inference engine by more than 2.6x.

</details>


### [391] [Efficient Cross-Architecture Knowledge Transfer for Large-Scale Online User Response Prediction](https://arxiv.org/abs/2602.01775)
*Yucheng Wu,Yuekui Yang,Hongzheng Li,Anan Liu,Jian Xiao,Junjie Zhai,Huan Yu,Shaoping Ma,Leye Wang*

Main category: cs.AI

TL;DR: CrossAdapt是一个高效的两阶段跨架构知识转移框架，通过离线快速嵌入转移和在线非对称共蒸馏，显著提升AUC并减少训练时间，适用于大规模部署。


<details>
  <summary>Details</summary>
Motivation: 在大规模用户响应预测系统中部署新架构会因昂贵的历史数据重新训练和数据保留约束下的性能下降而产生高模型切换成本，现有知识蒸馏方法难以应对架构异构性和大型嵌入表转移的高成本问题。

Method: CrossAdapt采用两阶段框架：离线阶段通过维度自适应投影实现快速嵌入转移，结合渐进式网络蒸馏和策略性采样降低计算成本；在线阶段引入非对称共蒸馏，学生模型频繁更新而教师模型更新较少，同时通过分布感知适应机制动态平衡历史知识保留和新数据快速适应。

Result: 在三个公共数据集上的实验显示，CrossAdapt实现了0.27-0.43%的AUC提升，同时减少了43-71%的训练时间。

Conclusion: CrossAdapt框架在腾讯微信频道的大规模部署中表现出色，显著减少了AUC下降、LogLoss增加和预测偏差，验证了其高效性和实用性。

Abstract: Deploying new architectures in large-scale user response prediction systems incurs high model switching costs due to expensive retraining on massive historical data and performance degradation under data retention constraints. Existing knowledge distillation methods struggle with architectural heterogeneity and the prohibitive cost of transferring large embedding tables. We propose CrossAdapt, a two-stage framework for efficient cross-architecture knowledge transfer. The offline stage enables rapid embedding transfer via dimension-adaptive projections without iterative training, combined with progressive network distillation and strategic sampling to reduce computational cost. The online stage introduces asymmetric co-distillation, where students update frequently while teachers update infrequently, together with a distribution-aware adaptation mechanism that dynamically balances historical knowledge preservation and fast adaptation to evolving data. Experiments on three public datasets show that CrossAdapt achieves 0.27-0.43% AUC improvements while reducing training time by 43-71%. Large-scale deployment on Tencent WeChat Channels (~10M daily samples) further demonstrates its effectiveness, significantly mitigating AUC degradation, LogLoss increase, and prediction bias compared to standard distillation baselines.

</details>


### [392] [LingLanMiDian: Systematic Evaluation of LLMs on TCM Knowledge and Clinical Reasoning](https://arxiv.org/abs/2602.01779)
*Rui Hua,Yu Wei,Zixin Shu,Kai Chang,Dengying Yan,Jianan Xia,Zeyu Liu,Hui Zhu,Shujie Song,Mingzhong Xiao,Xiaodong Li,Dongmei Jia,Zhuye Gao,Yanyan Meng,Naixuan Zhao,Yu Fu,Haibin Yu,Benman Yu,Yuanyuan Chen,Fei Dong,Zhizhou Meng,Pengcheng Yang,Songxue Zhao,Lijuan Pei,Yunhui Hu,Kan Ding,Jiayuan Duan,Wenmao Yin,Yang Gu,Runshun Zhang,Qiang Zhu,Jian Yu,Jiansheng Li,Baoyan Liu,Wenjia Wang,Xuezhong Zhou*

Main category: cs.AI

TL;DR: LingLan是一个大规模、专家策划的多任务基准测试，旨在统一评估中医领域的大语言模型，揭示了当前模型与人类专家在专业推理上的差距。


<details>
  <summary>Details</summary>
Motivation: 中医具有独特的本体论、术语和推理模式，现有基准测试在覆盖范围和规模上分散，且依赖非统一或生成密集的评分，阻碍了公平比较。

Method: LingLan基准测试整合了知识回忆、多跳推理、信息抽取和临床决策等多个任务，并引入了统一的指标设计、临床标签的同义词容忍协议、每数据集400项的困难子集，以及将诊断和治疗建议重构为单选决策识别。

Result: 对14个领先的开源和专有LLM进行了全面的零样本评估，提供了它们在中医常识知识理解、推理和临床决策支持方面的统一视角。

Conclusion: LingLan基准测试为中医领域的大语言模型提供了统一、量化和可扩展的评估基础，揭示了当前模型与人类专家在中医专业推理上的显著差距。

Abstract: Large language models (LLMs) are advancing rapidly in medical NLP, yet Traditional Chinese Medicine (TCM) with its distinctive ontology, terminology, and reasoning patterns requires domain-faithful evaluation. Existing TCM benchmarks are fragmented in coverage and scale and rely on non-unified or generation-heavy scoring that hinders fair comparison. We present the LingLanMiDian (LingLan) benchmark, a large-scale, expert-curated, multi-task suite that unifies evaluation across knowledge recall, multi-hop reasoning, information extraction, and real-world clinical decision-making. LingLan introduces a consistent metric design, a synonym-tolerant protocol for clinical labels, a per-dataset 400-item Hard subset, and a reframing of diagnosis and treatment recommendation into single-choice decision recognition. We conduct comprehensive, zero-shot evaluations on 14 leading open-source and proprietary LLMs, providing a unified perspective on their strengths and limitations in TCM commonsense knowledge understanding, reasoning, and clinical decision support; critically, the evaluation on Hard subset reveals a substantial gap between current models and human experts in TCM-specialized reasoning. By bridging fundamental knowledge and applied reasoning through standardized evaluation, LingLan establishes a unified, quantitative, and extensible foundation for advancing TCM LLMs and domain-specific medical AI research. All evaluation data and code are available at https://github.com/TCMAI-BJTU/LingLan and http://tcmnlp.com.

</details>


### [393] [ORCH: many analyses, one merge-a deterministic multi-agent orchestrator for discrete-choice reasoning with EMA-guided routing](https://arxiv.org/abs/2602.01797)
*Hanlin Zhou,Huah Yong Chan*

Main category: cs.AI

TL;DR: ORCH是一种确定性多智能体协调框架，通过固定规则和可选EMA路由提升LLM在离散选择任务中的性能与可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有系统多依赖随机路由或临时启发式方法，导致行为难以复现且决策过程不透明。

Method: ORCH采用确定性协调框架，通过固定规则进行任务分解和答案聚合，并可选引入EMA引导的路由器以利用模型互补性。

Result: 在MMLU、MMLU-Pro和GSM8K上的实验显示，ORCH显著优于单模型基线和多数投票集成，准确性提升最高达50点。

Conclusion: ORCH提供了一种可控、可解释且可直接部署的LLM多智能体系统，适用于离散选择推理任务。

Abstract: Recent advances in large-scale language models (LLMs) have made multi-agent architectures attractive for challenging reasoning tasks. However, many existing systems rely on stochastic routing or ad-hoc heuristics, making their behavior difficult to reproduce and their decision process hard to interpret. We propose ORCH, a deterministic coordination framework for discrete-choice reasoning that orchestrates heterogeneous LLMs. ORCH follows a ``many analyses, one decision'' paradigm: multiple base models independently produce structured analyses, and a dedicated merge agent outputs the final choice. The framework uses fixed rules for task decomposition and answer aggregation, keeping the pipeline predictable, reproducible, and training-free. Determinism here refers to fixed routing and aggregation rules under a fixed evaluation protocol, rather than strict bit-level reproducibility across deployments. To exploit model complementarity, we optionally introduce an EMA-guided router that updates agent selection using historical accuracy, latency, or cost; since it relies on answer-based feedback, it is mainly intended for benchmarking, controlled evaluation, or delayed-feedback settings. Experiments on MMLU, MMLU-Pro, and GSM8K show that ORCH consistently outperforms single-model baselines and a majority-vote ensemble. On MMLU-Pro, ORCH improves accuracy by over 10 points compared to the strongest baseline, and on GSM8K it yields gains exceeding 50 points; McNemar tests confirm statistical significance. The EMA router provides an additional 0.7--2.0 point accuracy boost, and ablations show that both multi-agent collaboration and routing contribute substantially. Overall, ORCH offers a practical path toward controllable, interpretable, and deployment-ready LLM-based agent systems for discrete-choice reasoning.

</details>


### [394] [INDIBATOR: Diverse and Fact-Grounded Individuality for Multi-Agent Debate in Molecular Discovery](https://arxiv.org/abs/2602.01815)
*Yunhui Jang,Seonghyun Park,Jaehyung Kim,Sungsoo Ahn*

Main category: cs.AI

TL;DR: INDIBATOR通过个体化科学家特征（出版和分子历史）设计代理，在多代理系统中实现更优的分子发现性能。


<details>
  <summary>Details</summary>
Motivation: 现有多代理系统采用角色或关键词定义代理行为，过于简化人类科学家的独特研究轨迹，无法充分体现其贡献。

Method: 提出INDIBATOR框架，通过结合科学家的出版历史和分子历史构建个体化代理，支持多轮辩论（提案、批评、投票）。

Result: 个体化代理在分子发现任务中表现优于粗粒度角色代理，达到竞争性或最先进性能。

Conclusion: INDIBATOR框架通过基于个体科学家细粒度特征的代理设计，显著提升了多代理系统在分子发现中的性能，验证了个体化科学DNA对高质量发现的重要性。

Abstract: Multi-agent systems have emerged as a powerful paradigm for automating scientific discovery. To differentiate agent behavior in the multi-agent system, current frameworks typically assign generic role-based personas such as ''reviewer'' or ''writer'' or rely on coarse grained keyword-based personas. While functional, this approach oversimplifies how human scientists operate, whose contributions are shaped by their unique research trajectories. In response, we propose INDIBATOR, a framework for molecular discovery that grounds agents in individualized scientist profiles constructed from two modalities: publication history for literature-derived knowledge and molecular history for structural priors. These agents engage in multi-turn debate through proposal, critique, and voting phases. Our evaluation demonstrates that these fine-grained individuality-grounded agents consistently outperform systems relying on coarse-grained personas, achieving competitive or state-of-the-art performance. These results validate that capturing the ``scientific DNA'' of individual agents is essential for high-quality discovery.

</details>


### [395] [Synesthesia of Vehicles: Tactile Data Synthesis from Visual Inputs](https://arxiv.org/abs/2602.01832)
*Rui Wang,Yaoguang Cao,Yuyi Chen,Jianyi Xu,Zhuoyang Li,Jiachen Shang,Shichun Yang*

Main category: cs.AI

TL;DR: SoV框架通过视觉输入预测触觉激励，采用跨模态对齐和潜在扩散生成模型，显著提升自动驾驶车辆的安全性能。


<details>
  <summary>Details</summary>
Motivation: 当前自动驾驶车辆的视觉和光学传感器无法检测对车辆动态控制至关重要的道路激励，受人类联觉启发，提出了SoV框架。

Method: 提出了一种跨模态时空对齐方法来解决时空差异，并开发了基于潜在扩散的视觉-触觉生成模型（VTSyn）。

Result: VTSyn在时间、频率和分类性能上优于现有模型，通过主动触觉感知提升了自动驾驶安全性。

Conclusion: SoV框架通过跨模态时空对齐和VTSyn生成模型，显著提升了自动驾驶车辆对触觉激励的预测能力，从而增强了安全性。

Abstract: Autonomous vehicles (AVs) rely on multi-modal fusion for safety, but current visual and optical sensors fail to detect road-induced excitations which are critical for vehicles' dynamic control. Inspired by human synesthesia, we propose the Synesthesia of Vehicles (SoV), a novel framework to predict tactile excitations from visual inputs for autonomous vehicles. We develop a cross-modal spatiotemporal alignment method to address temporal and spatial disparities. Furthermore, a visual-tactile synesthetic (VTSyn) generative model using latent diffusion is proposed for unsupervised high-quality tactile data synthesis. A real-vehicle perception system collected a multi-modal dataset across diverse road and lighting conditions. Extensive experiments show that VTSyn outperforms existing models in temporal, frequency, and classification performance, enhancing AV safety through proactive tactile perception.

</details>


### [396] [ROMA: Recursive Open Meta-Agent Framework for Long-Horizon Multi-Agent Systems](https://arxiv.org/abs/2602.01848)
*Salaheddin Alzu'bi,Baran Nama,Arda Kaz,Anushri Eswaran,Weiyuan Chen,Sarvesh Khetan,Rishab Bala,Tu Vu,Sewoong Oh*

Main category: cs.AI

TL;DR: ROMA是一种递归开放式元代理框架，通过任务分解和结构化聚合提升长时任务性能，支持多模型混合，表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有代理框架在长时任务中表现不佳，随着推理深度增加，顺序编排变得脆弱，上下文窗口限制性能，且不透明的执行轨迹难以调试。

Method: ROMA框架通过递归任务分解和结构化聚合解决现有代理框架的局限性，包括四个模块化角色：Atomizer、Planner、Executor和Aggregator。

Result: ROMA与GEPA+结合在推理和长文本生成基准测试中表现领先，如在SEAL-0上准确率提升9.9%，在EQ-Bench上与闭源模型性能相当。

Conclusion: 递归、模块化的代理架构（ROMA）能够扩展推理深度，同时保持可解释性、灵活性和模型无关性。

Abstract: Current agentic frameworks underperform on long-horizon tasks. As reasoning depth increases, sequential orchestration becomes brittle, context windows impose hard limits that degrade performance, and opaque execution traces make failures difficult to localize or debug. We introduce ROMA (Recursive Open Meta-Agents), a domain-agnostic framework that addresses these limitations through recursive task decomposition and structured aggregation. ROMA decomposes goals into dependency-aware subtask trees that can be executed in parallel, while aggregation compresses and validates intermediate results to control context growth. Our framework standardizes agent construction around four modular roles --Atomizer (which decides whether a task should be decomposed), Planner, Executor, and Aggregator -- which cleanly separate orchestration from model selection and enable transparent, hierarchical execution traces. This design supports heterogeneous multi-agent systems that mix models and tools according to cost, latency, and capability. To adapt ROMA to specific tasks without fine-tuning, we further introduce GEPA$+$, an improved Genetic-Pareto prompt proposer that searches over prompts within ROMA's component hierarchy while preserving interface contracts. We show that ROMA, combined with GEPA+, delivers leading system-level performance on reasoning and long-form generation benchmarks. On SEAL-0, which evaluates reasoning over conflicting web evidence, ROMA instantiated with GLM-4.6 improves accuracy by 9.9\% over Kimi-Researcher. On EQ-Bench, a long-form writing benchmark, ROMA enables DeepSeek-V3 to match the performance of leading closed-source models such as Claude Sonnet 4.5. Our results demonstrate that recursive, modular agent architectures can scale reasoning depth while remaining interpretable, flexible, and model-agnostic.

</details>


### [397] [SOPRAG: Multi-view Graph Experts Retrieval for Industrial Standard Operating Procedures](https://arxiv.org/abs/2602.01858)
*Liangtao Lin,Zhaomeng Zhu,Tianwei Zhang,Yonggang Wen*

Main category: cs.AI

TL;DR: SOPRAG是一种新型框架，通过专家系统和动态门控机制优化工业SOP检索，实验证明其性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 工业环境中标准操作程序的检索存在结构性、逻辑复杂性和执行要求等挑战，传统语义驱动的RAG方法无法有效解决。

Method: SOPRAG采用实体、因果和流程图专家替代传统平面分块，结合Procedure Card层和LLM引导的门控机制，优化专家协调与检索对齐。

Result: 在四个工业领域的广泛实验中，SOPRAG在检索准确性和响应效用上显著优于基于词汇、密集和图的RAG基线。

Conclusion: SOPRAG框架通过引入专业专家和动态门控机制，显著提升了工业标准操作程序的检索准确性和执行效用，在实际关键任务中实现了完美执行分数。

Abstract: Standard Operating Procedures (SOPs) are essential for ensuring operational safety and consistency in industrial environments. However, retrieving and following these procedures presents unique challenges, such as rigid proprietary structures, condition-dependent relevance, and actionable execution requirement, which standard semantic-driven Retrieval-Augmented Generation (RAG) paradigms fail to address. Inspired by the Mixture-of-Experts (MoE) paradigm, we propose SOPRAG, a novel framework specifically designed to address the above pain points in SOP retrieval. SOPRAG replaces flat chunking with specialized Entity, Causal, and Flow graph experts to resolve industrial structural and logical complexities. To optimize and coordinate these experts, we propose a Procedure Card layer that prunes the search space to eliminate computational noise, and an LLM-Guided gating mechanism that dynamically weights these experts to align retrieval with operator intent. To address the scarcity of domain-specific data, we also introduce an automated, multi-agent workflow for benchmark construction. Extensive experiments across four industrial domains demonstrate that SOPRAG significantly outperforms strong lexical, dense, and graph-based RAG baselines in both retrieval accuracy and response utility, achieving perfect execution scores in real-world critical tasks.

</details>


### [398] [ProcMEM: Learning Reusable Procedural Memory from Experience via Non-Parametric PPO for LLM Agents](https://arxiv.org/abs/2602.01869)
*Qirui Mi,Zhijian Ma,Mengyue Yang,Haoxuan Li,Yisen Wang,Haifeng Zhang,Jun Wang*

Main category: cs.AI

TL;DR: ProcMEM框架通过非参数化PPO和Skill-MDP，实现了LLM代理的高效经验复用和长期自主性。


<details>
  <summary>Details</summary>
Motivation: 解决LLM驱动代理在重复场景中经验复用不足导致的计算冗余和执行不稳定问题。

Method: ProcMEM通过形式化Skill-MDP，将被动叙事转化为可执行的Skill，并引入Non-Parametric PPO进行高质量候选生成和验证，通过基于分数的维护保持内存的高质量。

Result: 实验证明ProcMEM在多种场景下实现了高复用率和显著性能提升，同时保持极高的内存压缩率。

Conclusion: ProcMEM框架通过非参数化PPO和基于分数的维护机制，实现了高效的经验复用和长期自主性，显著提升了代理的性能和稳定性。

Abstract: LLM-driven agents demonstrate strong performance in sequential decision-making but often rely on on-the-fly reasoning, re-deriving solutions even in recurring scenarios. This insufficient experience reuse leads to computational redundancy and execution instability. To bridge this gap, we propose ProcMEM, a framework that enables agents to autonomously learn procedural memory from interaction experiences without parameter updates. By formalizing a Skill-MDP, ProcMEM transforms passive episodic narratives into executable Skills defined by activation, execution, and termination conditions to ensure executability. To achieve reliable reusability without capability degradation, we introduce Non-Parametric PPO, which leverages semantic gradients for high-quality candidate generation and a PPO Gate for robust Skill verification. Through score-based maintenance, ProcMEM sustains compact, high-quality procedural memory. Experimental results across in-domain, cross-task, and cross-agent scenarios demonstrate that ProcMEM achieves superior reuse rates and significant performance gains with extreme memory compression. Visualized evolutionary trajectories and Skill distributions further reveal how ProcMEM transparently accumulates, refines, and reuses procedural knowledge to facilitate long-term autonomy.

</details>


### [399] [Entropy-Guided Data-Efficient Training for Multimodal Reasoning Reward Models](https://arxiv.org/abs/2602.01884)
*Shidong Yang,Tongwen Huang,Hao Wen,Yong Wang,Li Chen,Xiangxiang Chu*

Main category: cs.AI

TL;DR: 本文提出熵引导训练方法（EGT），通过熵筛选数据和调整训练策略，显著提升多模态奖励模型性能。


<details>
  <summary>Details</summary>
Motivation: 多模态奖励模型在训练过程中面临偏好数据集固有噪声和传统训练方法效率低下的挑战。

Method: 提出了一种基于熵的两种策略：熵引导的数据筛选以减少不可靠样本的影响，以及熵引导的训练策略逐步引入更复杂的样本。

Result: 在三个基准测试中，EGT训练的模型始终优于最先进的多模态奖励模型。

Conclusion: 本文提出的熵引导训练（EGT）方法在多模态推理奖励模型中表现优异，显著超越了现有技术。

Abstract: Multimodal reward models are crucial for aligning multimodal large language models with human preferences. Recent works have incorporated reasoning capabilities into these models, achieving promising results. However, training these models suffers from two critical challenges: (1) the inherent noise in preference datasets, which degrades model performance, and (2) the inefficiency of conventional training methods, which ignore the differences in sample difficulty. In this paper, we identify a strong correlation between response entropy and accuracy, indicating that entropy can serve as a reliable and unsupervised proxy for annotation noise and sample difficulty. Based on this insight, we propose a novel Entropy-Guided Training (EGT) approach for multimodal reasoning reward models, which combines two strategies: (1) entropy-guided data curation to mitigate the impact of unreliable samples, and (2) an entropy-guided training strategy that progressively introduces more complex examples. Extensive experiments across three benchmarks show that the EGT-trained model consistently outperforms state-of-the-art multimodal reward models.

</details>


### [400] [Geometric Analysis of Token Selection in Multi-Head Attention](https://arxiv.org/abs/2602.01893)
*Timur Mudarisov,Mikhal Burtsev,Tatiana Petrova,Radu State*

Main category: cs.AI

TL;DR: 该论文提出了一种几何框架来分析大型语言模型中的多头注意力，定义了几何指标并推导了理论边界，实验验证了理论预测，揭示了注意力机制的结构化分类器特性。


<details>
  <summary>Details</summary>
Motivation: 研究多头注意力在大型语言模型中的行为，直接分析其在值状态空间中的表现，以增强对注意力机制的理解和优化。

Method: 通过几何框架分析多头注意力，定义了几何指标（精确度、召回率和F分数）来量化选定和非选定令牌之间的可分离性，并在经验假设下推导了非渐近边界。

Result: 理论预测了小N操作区域的最强非平凡可分离性，并阐明了序列长度和汇相似性如何影响指标。实验测量与理论预测紧密吻合，发现不同头部具有不同的几何特征。

Conclusion: 注意力机制在大型语言模型中表现为一种具有可测量标准的结构化几何分类器，为令牌选择提供了头部级别的可解释性，并指导几何感知的稀疏化和注意力设计。

Abstract: We present a geometric framework for analysing multi-head attention in large language models (LLMs). Without altering the mechanism, we view standard attention through a top-N selection lens and study its behaviour directly in value-state space. We define geometric metrics - Precision, Recall, and F-score - to quantify separability between selected and non-selected tokens, and derive non-asymptotic bounds with explicit dependence on dimension and margin under empirically motivated assumptions (stable value norms with a compressed sink token, exponential similarity decay, and piecewise attention weight profiles). The theory predicts a small-N operating regime of strongest non-trivial separability and clarifies how sequence length and sink similarity shape the metrics. Empirically, across LLaMA-2-7B, Gemma-7B, and Mistral-7B, measurements closely track the theoretical envelopes: top-N selection sharpens separability, sink similarity correlates with Recall. We also found that in LLaMA-2-7B heads specialize into three regimes - Retriever, Mixer, Reset - with distinct geometric signatures. Overall, attention behaves as a structured geometric classifier with measurable criteria for token selection, offering head level interpretability and informing geometry-aware sparsification and design of attention in LLMs.

</details>


### [401] [DomusFM: A Foundation Model for Smart-Home Sensor Data](https://arxiv.org/abs/2602.01910)
*Michele Fiori,Gabriele Civitarese,Flora D. Salim,Claudio Bettini*

Main category: cs.AI

TL;DR: DomusFM是首个针对智能家居传感器数据的预训练基础模型，通过自监督学习解决数据稀缺问题，在多个任务中表现优异且易于部署。


<details>
  <summary>Details</summary>
Motivation: 智能家居传感器数据在医疗监测和辅助技术中有广泛应用潜力，但现有方法因需要大量标注数据、仅适用于惯性传感器或依赖昂贵硬件/外部服务而受限。

Method: 采用自监督双对比学习范式，结合轻量级语言模型的语义嵌入和专门编码器处理时间模式和二进制状态，学习可泛化的表示。

Result: 在七个公共智能家居数据集上的留一数据集评估显示，DomusFM在不同下游任务中优于现有方法，即使仅用5%标注数据微调也能取得优异性能。

Conclusion: DomusFM作为首个专为智能家居传感器数据设计的预训练基础模型，通过自监督双对比学习范式，成功解决了现有方法在数据稀缺和实际部署中的局限性，并在多个下游任务中表现优异。

Abstract: Smart-home sensor data holds significant potential for several applications, including healthcare monitoring and assistive technologies. Existing approaches, however, face critical limitations. Supervised models require impractical amounts of labeled data. Foundation models for activity recognition focus only on inertial sensors, failing to address the unique characteristics of smart-home binary sensor events: their sparse, discrete nature combined with rich semantic associations. LLM-based approaches, while tested in this domain, still raise several issues regarding the need for natural language descriptions or prompting, and reliance on either external services or expensive hardware, making them infeasible in real-life scenarios due to privacy and cost concerns. We introduce DomusFM, the first foundation model specifically designed and pretrained for smart-home sensor data. DomusFM employs a self-supervised dual contrastive learning paradigm to capture both token-level semantic attributes and sequence-level temporal dependencies. By integrating semantic embeddings from a lightweight language model and specialized encoders for temporal patterns and binary states, DomusFM learns generalizable representations that transfer across environments and tasks related to activity and event analysis. Through leave-one-dataset-out evaluation across seven public smart-home datasets, we demonstrate that DomusFM outperforms state-of-the-art baselines on different downstream tasks, achieving superior performance even with only 5% of labeled training data available for fine-tuning. Our approach addresses data scarcity while maintaining practical deployability for real-world smart-home systems.

</details>


### [402] [Large Language Model and Formal Concept Analysis: a comparative study for Topic Modeling](https://arxiv.org/abs/2602.01933)
*Fabrice Boissier,Monica Sen,Irina Rychkova*

Main category: cs.AI

TL;DR: 比较LLM和FCA在主题建模中的表现，发现各有优势，为未来应用提供参考。


<details>
  <summary>Details</summary>
Motivation: 探讨LLM和FCA在主题建模领域的实用性，填补现有研究的空白。

Method: 使用CREA流程评估FCA，GPT-5在零样本设置下通过三种提示策略（主题生成、结果合并和主题标注）进行评估。

Result: 实验表明，FCA和LLM在主题建模中各有优劣，适用于不同场景。

Conclusion: 本研究通过比较LLM和FCA在主题建模中的应用，揭示了各自的优势和局限性，为未来研究提供了方向。

Abstract: Topic modeling is a research field finding increasing applications: historically from document retrieving, to sentiment analysis and text summarization. Large Language Models (LLM) are currently a major trend in text processing, but few works study their usefulness for this task. Formal Concept Analysis (FCA) has recently been presented as a candidate for topic modeling, but no real applied case study has been conducted. In this work, we compare LLM and FCA to better understand their strengths and weakneses in the topic modeling field. FCA is evaluated through the CREA pipeline used in past experiments on topic modeling and visualization, whereas GPT-5 is used for the LLM. A strategy based on three prompts is applied with GPT-5 in a zero-shot setup: topic generation from document batches, merging of batch results into final topics, and topic labeling. A first experiment reuses the teaching materials previously used to evaluate CREA, while a second experiment analyzes 40 research articles in information systems to compare the extracted topics with the underling subfields.

</details>


### [403] [Small Generalizable Prompt Predictive Models Can Steer Efficient RL Post-Training of Large Reasoning Models](https://arxiv.org/abs/2602.01970)
*Yun Qu,Qi Wang,Yixiu Mao,Heming Zou,Yuhang Jiang,Weijie Liu,Clive Bai,Kai Yang,Yangkun Chen,Saiyong Yang,Xiangyang Ji*

Main category: cs.AI

TL;DR: GPS通过轻量级生成模型和贝叶斯推断优化提示选择，显著提升训练和测试效率。


<details>
  <summary>Details</summary>
Motivation: 强化学习虽能提升大语言模型的推理能力，但计算成本高；现有在线提示选择方法要么依赖昂贵评估，要么缺乏跨提示的泛化性。

Method: 引入通用预测提示选择（GPS），利用轻量级生成模型基于共享优化历史进行贝叶斯推断，结合中等难度优先和历史锚定多样性原则选择信息量大的提示批次。

Result: 在多种推理基准测试中，GPS在训练效率、最终性能和测试时效率上均显著优于基线方法。

Conclusion: GPS通过轻量级生成模型和贝叶斯推断显著提升了训练效率、最终性能及测试时效率，优于现有基线方法。

Abstract: Reinforcement learning enhances the reasoning capabilities of large language models but often involves high computational costs due to rollout-intensive optimization. Online prompt selection presents a plausible solution by prioritizing informative prompts to improve training efficiency. However, current methods either depend on costly, exact evaluations or construct prompt-specific predictive models lacking generalization across prompts. This study introduces Generalizable Predictive Prompt Selection (GPS), which performs Bayesian inference towards prompt difficulty using a lightweight generative model trained on the shared optimization history. Intermediate-difficulty prioritization and history-anchored diversity are incorporated into the batch acquisition principle to select informative prompt batches. The small predictive model also generalizes at test-time for efficient computational allocation. Experiments across varied reasoning benchmarks indicate GPS's substantial improvements in training efficiency, final performance, and test-time efficiency over superior baseline methods.

</details>


### [404] [Evolving from Tool User to Creator via Training-Free Experience Reuse in Multimodal Reasoning](https://arxiv.org/abs/2602.01983)
*Xintian Shen,Jiawei Chen,Lihao Zheng,Hao Ma,Tao Wei,Kun Zhan*

Main category: cs.AI

TL;DR: UCT框架让LLM自动创建和优化工具，无需额外训练即可提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有TIR模型依赖固定工具，无法满足开放性问题需求，且缺乏自我优化机制，工具构建成本高。

Method: 提出UCT框架，利用LLM的推理痕迹提取隐含的问题解决能力，转化为可重用资产，并引入记忆巩固机制维护工具库。

Result: 在数学和科学推理任务中，性能显著提升（+20.86%和+23.04%）。

Conclusion: UCT框架通过将LLM从工具使用者转变为工具创造者，实现了自适应工具创建和自我更新，显著提升了TIR模型的性能。

Abstract: Existing Tool-Integrated Reasoning (TIR) models have effectively extended the question-answering capabilities of LLMs by incorporating external tools. However, real-world scenarios present numerous open-ended problems where fixed tools often fail to meet task requirements. Furthermore, the lack of self-optimization mechanisms means that erroneous tool outputs can mislead the LLM's responses. Additionally, the construction of existing tools entails significant manual effort, which consequently constrains their applicability. Recognizing that the reasoning traces of LLMs encapsulate implicit problem-solving capabilities, we propose UCT, a novel training-free framework that transforms agents from tool users to tool creators. This approach harvests reasoning experiences and distills them into reusable assets. This method transforms the agent from a mere tool user into a tool creator, enabling adaptive tool creation and self-updating during the inference process. We also introduce a memory consolidation mechanism to maintain the tool library, ensuring high reusability of retained experiential memory for subsequent reasoning tasks. This novel automated tool construction paradigm continuously improves tool quality during reasoning, allowing the overall agent system to progress without additional training. Extensive experiments demonstrate that our method serves as a novel paradigm for enhancing the capabilities of TIR models. In particular, the significant performance gains achieved +20.86%$\uparrow$ and +23.04%$\uparrow$ on benchmarks across multi-domain mathematical and scientific reasoning tasks validate the self-evolving capability of the agent.

</details>


### [405] [Emergent Analogical Reasoning in Transformers](https://arxiv.org/abs/2602.01992)
*Gouki Minegishi,Jingyuan Feng,Hiroki Furuta,Takeshi Kojima,Yusuke Iwasawa,Yutaka Matsuo*

Main category: cs.AI

TL;DR: 该论文通过范畴论中的函子概念形式化类比推理，揭示了Transformer模型实现类比的两大机制，并验证了这些机制在预训练大模型中的普适性。


<details>
  <summary>Details</summary>
Motivation: 尽管类比在人类智能中扮演核心角色，但Transformer模型如何获取并实现类比推理的机制仍不明确。

Method: 受范畴论中函子概念的启发，将类比推理形式化为跨类别实体间对应关系的推断，并设计合成任务评估类比推理在受控环境中的涌现。

Result: 研究发现类比推理的涌现对数据特性、优化选择和模型规模高度敏感，并通过机制分析揭示了类比推理在Transformer中的两个关键组件：嵌入空间中关系结构的几何对齐和Transformer内部函子的应用。

Conclusion: 本研究将类比从抽象的认知概念转变为现代神经网络中具体、机制明确的现象，揭示了Transformer模型实现类比推理的机制。

Abstract: Analogy is a central faculty of human intelligence, enabling abstract patterns discovered in one domain to be applied to another. Despite its central role in cognition, the mechanisms by which Transformers acquire and implement analogical reasoning remain poorly understood. In this work, inspired by the notion of functors in category theory, we formalize analogical reasoning as the inference of correspondences between entities across categories. Based on this formulation, we introduce synthetic tasks that evaluate the emergence of analogical reasoning under controlled settings. We find that the emergence of analogical reasoning is highly sensitive to data characteristics, optimization choices, and model scale. Through mechanistic analysis, we show that analogical reasoning in Transformers decomposes into two key components: (1) geometric alignment of relational structure in the embedding space, and (2) the application of a functor within the Transformer. These mechanisms enable models to transfer relational structure from one category to another, realizing analogy. Finally, we quantify these effects and find that the same trends are observed in pretrained LLMs. In doing so, we move analogy from an abstract cognitive notion to a concrete, mechanistically grounded phenomenon in modern neural networks.

</details>


### [406] [Thinking Like a Doctor: Conversational Diagnosis through the Exploration of Diagnostic Knowledge Graphs](https://arxiv.org/abs/2602.01995)
*Jeongmoon Won,Seungwon Kook,Yohan Jo*

Main category: cs.AI

TL;DR: 提出基于知识图谱的两步推理对话诊断系统，实验证明其优于现有方法，医生认可其现实性和临床价值。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖模型的参数知识或假设患者提供丰富具体信息，这在现实中不切实际，因此需要更现实的对话诊断系统。

Method: 系统利用诊断知识图谱进行两步推理：从对话上下文中生成诊断假设，并通过澄清问题验证假设，直到得出最终诊断。

Result: 实验显示，该系统在诊断准确性和效率上优于强基线，医生评估也支持其模拟器的现实性和生成问题的临床实用性。

Conclusion: 该论文提出的对话诊断系统通过两步推理（生成诊断假设和验证假设）提高了诊断准确性和效率，并得到了医生的认可。

Abstract: Conversational diagnosis requires multi-turn history-taking, where an agent asks clarifying questions to refine differential diagnoses under incomplete information. Existing approaches often rely on the parametric knowledge of a model or assume that patients provide rich and concrete information, which is unrealistic. To address these limitations, we propose a conversational diagnosis system that explores a diagnostic knowledge graph to reason in two steps: (i) generating diagnostic hypotheses from the dialogue context, and (ii) verifying hypotheses through clarifying questions, which are repeated until a final diagnosis is reached. Since evaluating the system requires a realistic patient simulator that responds to the system's questions, we adopt a well-established simulator along with patient profiles from MIMIC-IV. We further adapt it to describe symptoms vaguely to reflect real-world patients during early clinical encounters. Experiments show improved diagnostic accuracy and efficiency over strong baselines, and evaluations by physicians support the realism of our simulator and the clinical utility of the generated questions. Our code will be released upon publication.

</details>


### [407] [Do I Really Know? Learning Factual Self-Verification for Hallucination Reduction](https://arxiv.org/abs/2602.02018)
*Enes Altinisik,Masoomali Fatehkia,Fatih Deniz,Nadir Durrani,Majd Hawasly,Mohammad Raza,Husrev Taha Sencar*

Main category: cs.AI

TL;DR: VeriFY是一种训练时自验证框架，通过一致性验证和阶段级损失掩码显著减少LLMs的事实性幻觉，同时保持高召回率。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖外部后验验证或直接将不确定性映射为弃权，导致行为过于保守，VeriFY旨在通过训练时自验证解决这一问题。

Method: VeriFY框架在训练时引入结构化验证轨迹，指导模型生成初始答案、验证查询、一致性判断，并决定是否回答或弃权。采用阶段级损失掩码避免强化幻觉内容。

Result: 在多个模型家族和规模上，VeriFY将事实性幻觉率降低了9.7%至53.3%，召回率仅小幅下降（0.4%至5.7%），且单源训练下能泛化到其他数据集。

Conclusion: VeriFY通过一致性自验证框架有效减少了LLMs的事实性幻觉，同时保持了较高的召回率，且具有良好的泛化能力。

Abstract: Factual hallucination remains a central challenge for large language models (LLMs). Existing mitigation approaches primarily rely on either external post-hoc verification or mapping uncertainty directly to abstention during fine-tuning, often resulting in overly conservative behavior. We propose VeriFY, a training-time framework that teaches LLMs to reason about factual uncertainty through consistency-based self-verification. VeriFY augments training with structured verification traces that guide the model to produce an initial answer, generate and answer a probing verification query, issue a consistency judgment, and then decide whether to answer or abstain. To address the risk of reinforcing hallucinated content when training on augmented traces, we introduce a stage-level loss masking approach that excludes hallucinated answer stages from the training objective while preserving supervision over verification behavior. Across multiple model families and scales, VeriFY reduces factual hallucination rates by 9.7 to 53.3 percent, with only modest reductions in recall (0.4 to 5.7 percent), and generalizes across datasets when trained on a single source. The source code, training data, and trained model checkpoints will be released upon acceptance.

</details>


### [408] [Light Alignment Improves LLM Safety via Model Self-Reflection with a Single Neuron](https://arxiv.org/abs/2602.02027)
*Sicheng Shen,Mingyang Lv,Han Shen,Jialin Wu,Binghao Wang,Zhou Yang,Guobin Shen,Dongcheng Zhao,Feifei Zhao,Yi Zeng*

Main category: cs.AI

TL;DR: 提出低成本安全感知解码方法，通过单个神经元门控平衡模型能力与外部指导，提升安全性与泛化性。


<details>
  <summary>Details</summary>
Motivation: 现有的大型语言模型安全对齐方法多为后训练方法，计算成本高且泛化性差；轻量级对齐方法则依赖预先计算的安全注入或过度依赖模型自身能力，导致泛化性有限且生成效率与实用性下降。

Method: 提出了一种安全感知的解码方法，仅需低成本训练一个专家模型，并采用单个神经元作为门控机制。

Result: 该方法在训练开销和跨模型规模的泛化性上具有优势，同时保持了实用性和输出安全性。

Conclusion: 本文提出了一种安全感知的解码方法，通过低成本训练专家模型并利用单个神经元作为门控机制，有效平衡模型内在能力与外部指导，既保留了实用性又增强了输出安全性。该方法在训练开销和跨模型规模的泛化性上展现出明显优势，为大型语言模型的安全实用部署提供了新视角。

Abstract: The safety of large language models (LLMs) has increasingly emerged as a fundamental aspect of their development. Existing safety alignment for LLMs is predominantly achieved through post-training methods, which are computationally expensive and often fail to generalize well across different models. A small number of lightweight alignment approaches either rely heavily on prior-computed safety injections or depend excessively on the model's own capabilities, resulting in limited generalization and degraded efficiency and usability during generation. In this work, we propose a safety-aware decoding method that requires only low-cost training of an expert model and employs a single neuron as a gating mechanism. By effectively balancing the model's intrinsic capabilities with external guidance, our approach simultaneously preserves utility and enhances output safety. It demonstrates clear advantages in training overhead and generalization across model scales, offering a new perspective on lightweight alignment for the safe and practical deployment of large language models. Code: https://github.com/Beijing-AISI/NGSD.

</details>


### [409] [Edit Knowledge, Not Just Facts via Multi-Step Reasoning over Background Stories](https://arxiv.org/abs/2602.02028)
*Ya Gao,Kalle Kujanpää,Pekka Marttinen,Harri Valpola,Alexander Ilin*

Main category: cs.AI

TL;DR: 研究提出了一种通过背景故事、多跳问题和知识蒸馏训练模型的方法，使其能有效整合新知识并在推理中灵活应用，实验验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有知识编辑方法侧重于原子事实，难以将新信息整合为跨上下文可用的连贯框架，因此提出知识内化应视为推理问题而非记忆问题。

Method: 提出了基于三个原则的训练策略：1) 新知识以背景故事形式引入；2) 使用自生成的多跳问题训练模型；3) 通过知识蒸馏强制学生模型内化教师模型的推理行为。

Result: 实验表明，采用该策略训练的模型能够有效利用新知识进行推理，并在需要结合多个新事实的复杂问题上表现优异。

Conclusion: 该研究提出了一种基于知识内化的训练策略，通过背景故事、多跳问题和知识蒸馏，使模型能够有效整合新知识并在推理中灵活应用。

Abstract: Enabling artificial intelligence systems, particularly large language models, to integrate new knowledge and flexibly apply it during reasoning remains a central challenge. Existing knowledge editing approaches emphasize atomic facts, improving factual recall but often failing to integrate new information into a coherent framework usable across contexts. In this work, we argue that knowledge internalization is fundamentally a reasoning problem rather than a memorization problem. Consequently, a model should be trained in situations where the new information is instrumental to solving a task, combined with pre-existing knowledge, and exercised through multi-step reasoning. Based on this insight, we propose a training strategy based on three principles. First, new knowledge is introduced as a coherent background story that contextualizes novel facts and explains their relation to existing knowledge. Second, models are trained using self-generated multi-hop questions that require multi-step reasoning involving the new information. Third, training is done using knowledge distillation, forcing a student model to internalize the teacher's reasoning behavior without access to the novel information. Experiments show that models trained with this strategy effectively leverage newly acquired knowledge during reasoning and achieve remarkable performance on challenging questions that require combining multiple new facts.

</details>


### [410] [Constrained Process Maps for Multi-Agent Generative AI Workflows](https://arxiv.org/abs/2602.02034)
*Ananya Joshi,Michael Rudow*

Main category: cs.AI

TL;DR: 论文提出了一种多代理系统框架，通过MDP结构提升LLM在合规工作流中的性能，显著提高了准确性并减少了人工干预。


<details>
  <summary>Details</summary>
Motivation: 当前基于大型语言模型（LLM）的代理系统主要依赖单一代理的提示工程，难以观察或比较模型在跨决策阶段和人工监督下的不确定性和协调能力。

Method: 研究采用多代理系统，每个代理对应特定角色或决策阶段，并通过蒙特卡洛估计量化代理层面的认知不确定性。系统级不确定性通过MDP的终止状态（自动标记或人工审查状态）来捕获。

Result: 在AI安全评估的案例研究中，多代理系统相比单一代理基线实现了高达19%的准确性提升，人类审查需求减少了85倍，某些配置下还缩短了处理时间。

Conclusion: 该论文提出了一种基于多代理系统的框架，通过有限时间马尔可夫决策过程（MDP）和有向无环结构，显著提升了在合规和尽职调查等受监管环境中的工作流程效率和准确性。

Abstract: Large language model (LLM)-based agents are increasingly used to perform complex, multi-step workflows in regulated settings such as compliance and due diligence. However, many agentic architectures rely primarily on prompt engineering of a single agent, making it difficult to observe or compare how models handle uncertainty and coordination across interconnected decision stages and with human oversight. We introduce a multi-agent system formalized as a finite-horizon Markov Decision Process (MDP) with a directed acyclic structure. Each agent corresponds to a specific role or decision stage (e.g., content, business, or legal review in a compliance workflow), with predefined transitions representing task escalation or completion. Epistemic uncertainty is quantified at the agent level using Monte Carlo estimation, while system-level uncertainty is captured by the MDP's termination in either an automated labeled state or a human-review state. We illustrate the approach through a case study in AI safety evaluation for self-harm detection, implemented as a multi-agent compliance system. Results demonstrate improvements over a single-agent baseline, including up to a 19\% increase in accuracy, up to an 85x reduction in required human review, and, in some configurations, reduced processing time.

</details>


### [411] [Hunt Instead of Wait: Evaluating Deep Data Research on Large Language Models](https://arxiv.org/abs/2602.02039)
*Wei Liu,Peijie Yu,Michele Orini,Yali Du,Yulan He*

Main category: cs.AI

TL;DR: 论文提出了调查性智能的概念，并设计了DDR任务和DDR-Bench基准测试，发现前沿模型虽展现代理能力，但长期探索仍是难点。


<details>
  <summary>Details</summary>
Motivation: 区分调查性智能和执行性智能，填补现有基准测试在数据科学领域的空白。

Method: 引入了Deep Data Research (DDR)任务和DDR-Bench基准测试，用于评估LLMs在自主提取数据库关键见解方面的能力。

Result: 前沿模型显示出初步的代理能力，但长期探索仍具挑战性。

Conclusion: 有效的调查性智能不仅依赖于代理框架或简单扩展，还依赖于代理模型的内在策略。

Abstract: The agency expected of Agentic Large Language Models goes beyond answering correctly, requiring autonomy to set goals and decide what to explore. We term this investigatory intelligence, distinguishing it from executional intelligence, which merely completes assigned tasks. Data Science provides a natural testbed, as real-world analysis starts from raw data rather than explicit queries, yet few benchmarks focus on it. To address this, we introduce Deep Data Research (DDR), an open-ended task where LLMs autonomously extract key insights from databases, and DDR-Bench, a large-scale, checklist-based benchmark that enables verifiable evaluation. Results show that while frontier models display emerging agency, long-horizon exploration remains challenging. Our analysis highlights that effective investigatory intelligence depends not only on agent scaffolding or merely scaling, but also on intrinsic strategies of agentic models.

</details>


### [412] [SIDiffAgent: Self-Improving Diffusion Agent](https://arxiv.org/abs/2602.02051)
*Shivank Garg,Ayush Singh,Gaurav Kumar Nayak*

Main category: cs.AI

TL;DR: SIDiffAgent是一个训练免费的代理框架，利用Qwen系列模型解决文本到图像扩散模型的局限性，显著提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 解决文本到图像扩散模型在提示措辞敏感性、语义解释模糊、伪影（如扭曲的解剖结构）以及需要精心设计输入提示等方面的局限性。

Method: 利用Qwen系列模型（Qwen-VL、Qwen-Image、Qwen-Edit、Qwen-Embedding）构建的SIDiffAgent框架，自主管理提示工程、检测并修正生成问题，以及执行细粒度伪影去除。

Result: 在GenAIBench上平均VQA得分为0.884，显著优于开源、专有模型和代理方法。

Conclusion: SIDiffAgent通过训练免费的代理框架，结合Qwen系列模型，有效解决了文本到图像扩散模型在实际部署中的多项限制，显著提升了生成图像的可靠性和一致性。

Abstract: Text-to-image diffusion models have revolutionized generative AI, enabling high-quality and photorealistic image synthesis. However, their practical deployment remains hindered by several limitations: sensitivity to prompt phrasing, ambiguity in semantic interpretation (e.g., ``mouse" as animal vs. a computer peripheral), artifacts such as distorted anatomy, and the need for carefully engineered input prompts. Existing methods often require additional training and offer limited controllability, restricting their adaptability in real-world applications. We introduce Self-Improving Diffusion Agent (SIDiffAgent), a training-free agentic framework that leverages the Qwen family of models (Qwen-VL, Qwen-Image, Qwen-Edit, Qwen-Embedding) to address these challenges. SIDiffAgent autonomously manages prompt engineering, detects and corrects poor generations, and performs fine-grained artifact removal, yielding more reliable and consistent outputs. It further incorporates iterative self-improvement by storing a memory of previous experiences in a database. This database of past experiences is then used to inject prompt-based guidance at each stage of the agentic pipeline. \modelour achieved an average VQA score of 0.884 on GenAIBench, significantly outperforming open-source, proprietary models and agentic methods. We will publicly release our code upon acceptance.

</details>


### [413] [Understanding the Reversal Curse Mitigation in Masked Diffusion Models through Attention and Training Dynamics](https://arxiv.org/abs/2602.02133)
*Sangwoo Shin,BumJun Kim,Kyelim Lee,Moongyu Jeon,Albert No*

Main category: cs.AI

TL;DR: MDMs通过架构和训练交互部分解决了ARMs的反转诅咒问题，机制包括权重共享和梯度对齐。


<details>
  <summary>Details</summary>
Motivation: 研究动机是探究为何掩码扩散语言模型（MDMs）在反转诅咒问题上表现优于自回归语言模型（ARMs），并揭示其背后的机制。

Method: 研究方法包括理论分析（如单层Transformer编码器中权重共享对正反向注意力的耦合作用）和实验验证（在受控玩具任务和大规模扩散语言模型上的测试）。

Result: 研究结果显示，MDMs通过架构结构（如权重共享）和训练过程中的梯度对齐，显著减轻了反转诅咒问题。

Conclusion: 论文结论表明，掩码扩散语言模型（MDMs）通过其架构结构和训练交互，部分克服了自回归语言模型（ARMs）中存在的反转诅咒问题。

Abstract: Autoregressive language models (ARMs) suffer from the reversal curse: after learning that "$A$ is $B$", they often fail on the reverse query "$B$ is $A$". Masked diffusion-based language models (MDMs) exhibit this failure in a much weaker form, but the underlying reason has remained unclear. A common explanation attributes this mitigation to the any-order training objective. However, observing "[MASK] is $B$" during training does not necessarily teach the model to handle the reverse prompt "$B$ is [MASK]". We show that the mitigation arises from architectural structure and its interaction with training. In a one-layer Transformer encoder, weight sharing couples the two directions by making forward and reverse attention scores positively correlated. In the same setting, we further show that the corresponding gradients are aligned, so minimizing the forward loss also reduces the reverse loss. Experiments on both controlled toy tasks and large-scale diffusion language models support these mechanisms, explaining why MDMs partially overcome a failure mode that persists in strong ARMs.

</details>


### [414] [Mitigating Safety Tax via Distribution-Grounded Refinement in Large Reasoning Models](https://arxiv.org/abs/2602.02136)
*Yingsha Xie,Tiansheng Huang,Enneng Yang,Rui Min,Wenjie Lu,Xiaochun Cao,Naiqiang Tan,Li Shen*

Main category: cs.AI

TL;DR: DGR方法通过调整数据集分布，减少安全对齐对大型推理模型推理能力的负面影响，同时保持安全性能，揭示了安全对齐可能作为激活潜在知识的机制。


<details>
  <summary>Details</summary>
Motivation: 现有的安全对齐数据集通常通过从外部LRM或人类标注者中提取安全推理轨迹和答案构建，但这些与目标LRM存在分布差距，推测这种差距是导致目标LRM推理能力显著下降的原因。

Method: 提出了名为DGR的安全对齐数据集构建方法，该方法通过转换和精炼现有的分布外安全推理数据集，使其与目标LLM的内部分布对齐。

Result: 实验结果表明，DGR有效减轻了安全税，同时保持了安全性能，平均推理准确率相比Vanilla SFT提高了30.2%（DirectRefusal）和21.2%（R1-ACT）。推理能力的退化程度与分布偏移程度相关。

Conclusion: 研究发现，安全对齐在大型推理模型（LRM）中主要作为一种激活潜在知识的机制，仅需少量样本即可激活有效的拒绝行为。这些发现不仅强调了分布一致性的重要性，还为推理模型中安全激活机制提供了见解。

Abstract: Safety alignment incurs safety tax that perturbs a large reasoning model's (LRM) general reasoning ability. Existing datasets used for safety alignment for an LRM are usually constructed by distilling safety reasoning traces and answers from an external LRM or human labeler. However, such reasoning traces and answers exhibit a distributional gap with the target LRM that needs alignment, and we conjecture such distributional gap is the culprit leading to significant degradation of reasoning ability of the target LRM. Driven by this hypothesis, we propose a safety alignment dataset construction method, dubbed DGR. DGR transforms and refines an existing out-of-distributional safety reasoning dataset to be aligned with the target's LLM inner distribution. Experimental results demonstrate that i) DGR effectively mitigates the safety tax while maintaining safety performance across all baselines, i.e., achieving \textbf{+30.2\%} on DirectRefusal and \textbf{+21.2\%} on R1-ACT improvement in average reasoning accuracy compared to Vanilla SFT; ii) the degree of reasoning degradation correlates with the extent of distribution shift, suggesting that bridging this gap is central to preserving capabilities. Furthermore, we find that safety alignment in LRMs may primarily function as a mechanism to activate latent knowledge, as a mere \textbf{10} samples are sufficient for activating effective refusal behaviors. These findings not only emphasize the importance of distributional consistency but also provide insights into the activation mechanism of safety in reasoning models.

</details>


### [415] [Traffic-Aware Navigation in Road Networks](https://arxiv.org/abs/2602.02158)
*Sarah Nassar*

Main category: cs.AI

TL;DR: 比较三种图搜索方法在交通导航中的表现：Dijkstra/A*最优但需实时计算，Floyd-Warshall最快但无交通感知，Yen算法平衡两者。


<details>
  <summary>Details</summary>
Motivation: 研究目的是比较不同图搜索方法在金斯顿路网中交通感知导航的性能差异。

Method: 比较了三种图搜索方法：Floyd-Warshall-Ingerman（单次多查询预处理）、Dijkstra和A*（连续单查询实时搜索），以及结合两者的Yen算法（先找K条最短路径再实时迭代）。

Result: Dijkstra和A*能提供最交通感知的优化路径且预处理需求最小；Floyd-Warshall-Ingerman实时最快但无交通感知；Yen算法预处理需求大但在速度和最优性间取得平衡。

Conclusion: 每种图搜索方法在交通感知导航任务中各有优缺点，需根据具体部署环境权衡选择最佳方案。

Abstract: This project compares three graph search approaches for the task of traffic-aware navigation in Kingston's road network. These approaches include a single-run multi-query preprocessing algorithm (Floyd-Warshall-Ingerman), continuous single-query real-time search (Dijkstra's and A*), and an algorithm combining both approaches to balance between their trade-offs by first finding the top K shortest paths then iterating over them in real time (Yen's). Dijkstra's and A* resulted in the most traffic-aware optimal solutions with minimal preprocessing required. Floyd-Warshall-Ingerman was the fastest in real time but provided distance based paths with no traffic awareness. Yen's algorithm required significant preprocessing but balanced between the other two approaches in terms of runtime speed and optimality. Each approach presents advantages and disadvantages that need to be weighed depending on the circumstances of specific deployment contexts to select the best custom solution. *This project was completed as part of ELEC 844 (Search and Planning Algorithms for Robotics) in the Fall 2025 term.

</details>


### [416] [Reasoning in a Combinatorial and Constrained World: Benchmarking LLMs on Natural-Language Combinatorial Optimization](https://arxiv.org/abs/2602.02188)
*Xia Jiang,Jing Chen,Cong Zhang,Jie Gao,Chengpeng Hu,Chenhao Zhang,Yaoxin Wu,Yingqian Zhang*

Main category: cs.AI

TL;DR: NLCO基准评估LLMs在组合优化问题上的表现，发现其在小规模实例上可行性和解质量较好，但随规模增大而下降。


<details>
  <summary>Details</summary>
Motivation: 探索LLMs在组合优化领域的潜力，填补现有研究的空白。

Method: 引入NLCO基准，涵盖43个CO问题，采用四层分类法（变量类型、约束族、全局模式和目标类）进行细粒度评估。

Result: 高性能模型在小规模实例上表现良好，但随着实例规模增大，可行性和解质量均下降。

Conclusion: LLMs在组合优化（CO）问题上的表现随问题规模增大而下降，尤其在图结构问题和瓶颈目标上表现较差。

Abstract: While large language models (LLMs) have shown strong performance in math and logic reasoning, their ability to handle combinatorial optimization (CO) -- searching high-dimensional solution spaces under hard constraints -- remains underexplored. To bridge the gap, we introduce NLCO, a \textbf{N}atural \textbf{L}anguage \textbf{C}ombinatorial \textbf{O}ptimization benchmark that evaluates LLMs on end-to-end CO reasoning: given a language-described decision-making scenario, the model must output a discrete solution without writing code or calling external solvers. NLCO covers 43 CO problems and is organized using a four-layer taxonomy of variable types, constraint families, global patterns, and objective classes, enabling fine-grained evaluation. We provide solver-annotated solutions and comprehensively evaluate LLMs by feasibility, solution optimality, and reasoning efficiency. Experiments across a wide range of modern LLMs show that high-performing models achieve strong feasibility and solution quality on small instances, but both degrade as instance size grows, even if more tokens are used for reasoning. We also observe systematic effects across the taxonomy: set-based tasks are relatively easy, whereas graph-structured problems and bottleneck objectives lead to more frequent failures.

</details>


### [417] [TIDE: Trajectory-based Diagnostic Evaluation of Test-Time Improvement in LLM Agents](https://arxiv.org/abs/2602.02196)
*Hang Yan,Xinyu Che,Fangzhi Xu,Qiushi Sun,Zichen Ding,Kanzhi Cheng,Jian Zhang,Tao Qin,Jun Liu,Qika Lin*

Main category: cs.AI

TL;DR: TIDE框架通过三个维度评估自主LLM代理的测试时改进，揭示性能提升需优化代理与环境的交互。


<details>
  <summary>Details</summary>
Motivation: 当前对TTI（测试时改进）机制的理解不足，现有评估指标无法全面捕捉其任务优化效率、行为适应性和工作记忆的效用。

Method: 提出了Test-time Improvement Diagnostic Evaluation (TIDE)，一个代理和环境无关的框架，将TTI分解为三个维度进行评估。

Result: TIDE通过实验表明，提升代理性能需优化代理与环境的交互动态，而非仅扩展内部推理。

Conclusion: TIDE框架揭示了提升自主LLM代理性能不仅需要扩展内部推理能力，还需优化代理与环境的交互动态。

Abstract: Recent advances in autonomous LLM agents demonstrate their ability to improve performance through iterative interaction with the environment. We define this paradigm as Test-Time Improvement (TTI). However, the mechanisms under how and why TTI succeed or fail remain poorly understood, and existing evaluation metrics fail to capture their task optimization efficiency, behavior adaptation after erroneous actions, and the specific utility of working memory for task completion. To address these gaps, we propose Test-time Improvement Diagnostic Evaluation (TIDE), an agent-agnostic and environment-agnostic framework that decomposes TTI into three comprehensive and interconnected dimensions. The framework measures (1) the overall temporal dynamics of task completion and (2) identifies whether performance is primarily constrained by recursive looping behaviors or (3) by burdensome accumulated memory. Through extensive experiments across diverse agents and environments, TIDE highlights that improving agent performance requires more than scaling internal reasoning, calling for explicitly optimizing the interaction dynamics between the agent and the environment.

</details>


### [418] [More Than a Quick Glance: Overcoming the Greedy Bias in KV-Cache Compression](https://arxiv.org/abs/2602.02199)
*Aryan Sood,Tanvi Sharma,Vansh Agrawal*

Main category: cs.AI

TL;DR: LASER-KV通过块级累积和精确LSH召回，在长上下文任务中优于现有压缩方法，准确率提升达10%。


<details>
  <summary>Details</summary>
Motivation: 解决现有KV缓存压缩方法在语义召回和内存效率之间的权衡问题，探索在严格累积预算下的KV压缩极限。

Method: 采用块级累积策略和保护除数（n）来管理压缩过程，避免滑动窗口伪影，结合精确LSH召回机制。

Result: 在Babilong基准测试中，LASER-KV在128k上下文长度下保持稳定性能，准确率优于现有方法达10%。

Conclusion: LASER-KV框架通过块级累积策略和精确LSH召回机制，在严格累积预算策略下实现了KV压缩的高效性，挑战了仅依赖注意力分数作为令牌效用代理的普遍假设。

Abstract: While Large Language Models (LLMs) can theoretically support extensive context windows, their actual deployment is constrained by the linear growth of Key-Value (KV) cache memory. Prevailing compression strategies mitigate this through various pruning mechanisms, yet trade-off semantic recall for memory efficiency. In this work, we present LASER-KV (Layer Accumulated Selection with Exact-LSH Recall), a framework designed to test the limits of KV compression under a strict accumulative budgeting policy. We deviate from the standard fixed summary size approach by implementing a block-wise accumulation strategy governed by a protection divisor (n). This allows us to isolate the effects of compression from sliding window artifacts. Our experiments on the Babilong benchmark reveal performance degradation in previous compression methods by 15-30% on various long context tasks. LASER-KV maintains stable performance, achieving superior accuracies by a margin of upto 10% at 128k. These findings challenge the prevailing assumption that attention scores alone are a sufficient proxy for token utility.

</details>


### [419] [Position: Explaining Behavioral Shifts in Large Language Models Requires a Comparative Approach](https://arxiv.org/abs/2602.02304)
*Martino Ciaperoni,Marzio Di Vece,Luca Pappalardo,Fosca Giannotti,Francesco Giannini*

Main category: cs.AI

TL;DR: 论文提出Δ-XAI框架，用于比较分析干预引起的模型行为变化，并通过实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 大规模基础模型在干预后会出现行为变化，但现有XAI方法无法有效解释这些变化的原因和内部机制。

Method: 论文通过提出Δ-XAI框架，并设计了一系列可能的流程来展示其工作原理，同时关联了框架的需求。

Result: 论文通过具体实验展示了Δ-XAI方法的有效性，验证了其能够解释模型行为变化。

Conclusion: 论文提出了一个比较性XAI（Δ-XAI）框架，旨在解释干预引起的模型行为变化，并强调比较分析的重要性。

Abstract: Large-scale foundation models exhibit behavioral shifts: intervention-induced behavioral changes that appear after scaling, fine-tuning, reinforcement learning or in-context learning. While investigating these phenomena have recently received attention, explaining their appearance is still overlooked. Classic explainable AI (XAI) methods can surface failures at a single checkpoint of a model, but they are structurally ill-suited to justify what changed internally across different checkpoints and which explanatory claims are warranted about that change. We take the position that behavioral shifts should be explained comparatively: the core target should be the intervention-induced shift between a reference model and an intervened model, rather than any single model in isolation. To this aim we formulate a Comparative XAI ($Δ$-XAI) framework with a set of desiderata to be taken into account when designing proper explaining methods. To highlight how $Δ$-XAI methods work, we introduce a set of possible pipelines, relate them to the desiderata, and provide a concrete $Δ$-XAI experiment.

</details>


### [420] [Interpreting and Controlling LLM Reasoning through Integrated Policy Gradient](https://arxiv.org/abs/2602.02313)
*Changming Li,Kaixing Zhang,Haoyun Xu,Yingdong Shi,Zheng Zhang,Kaitao Song,Kan Ren*

Main category: cs.AI

TL;DR: IPG框架通过传播结果信号定位和调制LLM中的推理机制，实验显示其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型展现出强大的推理能力，但其内部机制仍不透明。现有方法难以精确定位复杂推理机制或捕捉从模型内部到推理输出的序列影响。

Method: 作者提出了Integrated Policy Gradient (IPG)框架，通过传播基于结果的信号（如推理后的准确性）来追踪模型内部组件对推理行为的贡献。

Result: 实验证明，IPG框架能够实现更精确的定位，并在多样化的推理模型中可靠地调制推理行为（如推理能力、推理强度）。

Conclusion: 论文提出了Integrated Policy Gradient (IPG)框架，能够更精确地定位和调制大型语言模型中的复杂推理机制，为理解模型内部推理行为提供了新视角。

Abstract: Large language models (LLMs) demonstrate strong reasoning abilities in solving complex real-world problems. Yet, the internal mechanisms driving these complex reasoning behaviors remain opaque. Existing interpretability approaches targeting reasoning either identify components (e.g., neurons) correlated with special textual patterns, or rely on human-annotated contrastive pairs to derive control vectors. Consequently, current methods struggle to precisely localize complex reasoning mechanisms or capture sequential influence from model internal workings to the reasoning outputs. In this paper, built on outcome-oriented and sequential-influence-aware principles, we focus on identifying components that have sequential contribution to reasoning behavior where outcomes are cumulated by long-range effects. We propose Integrated Policy Gradient (IPG), a novel framework that attributes reasoning behaviors to model's inner components by propagating compound outcome-based signals such as post reasoning accuracy backward through model inference trajectories. Empirical evaluations demonstrate that our approach achieves more precise localization and enables reliable modulation of reasoning behaviors (e.g., reasoning capability, reasoning strength) across diverse reasoning models.

</details>


### [421] [Context Learning for Multi-Agent Discussion](https://arxiv.org/abs/2602.02350)
*Xingyuan Hua,Sheng Yue,Xinyi Li,Yizhe Zhao,Jinrui Zhang,Ju Ren*

Main category: cs.AI

TL;DR: M2CL通过动态生成上下文指令，解决了多智能体讨论中的不一致性问题，性能显著提升。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体讨论方法存在讨论不一致性问题，LLM无法达成一致解决方案，原因是其个体上下文之间的不对齐。

Method: 提出了一种多LLM上下文学习方法（M2CL），通过自适应机制训练上下文生成器，动态生成每轮讨论的上下文指令。

Result: M2CL在学术推理、具身任务和移动控制等挑战性任务上，性能显著优于现有方法20%--50%，并具有良好的可迁移性和计算效率。

Conclusion: M2CL通过动态生成上下文指令，显著提升了多智能体讨论的一致性和性能，且在多种任务中表现优异。

Abstract: Multi-Agent Discussion (MAD) has garnered increasing attention very recently, where multiple LLM instances collaboratively solve problems via structured discussion. However, we find that current MAD methods easily suffer from discussion inconsistency, LLMs fail to reach a coherent solution, due to the misalignment between their individual contexts.In this paper, we introduce a multi-LLM context learning method (M2CL) that learns a context generator for each agent, capable of dynamically generating context instructions per discussion round via automatic information organization and refinement. Specifically, inspired by our theoretical insights on the context instruction, M2CL train the generators to control context coherence and output discrepancies via a carefully crafted self-adaptive mechanism.It enables LLMs to avoid premature convergence on majority noise and progressively reach the correct consensus. We evaluate M2CL on challenging tasks, including academic reasoning, embodied tasks, and mobile control. The results show that the performance of M2CL significantly surpasses existing methods by 20%--50%, while enjoying favorable transferability and computational efficiency.

</details>


### [422] [Live-Evo: Online Evolution of Agentic Memory from Continuous Feedback](https://arxiv.org/abs/2602.02369)
*Yaolun Zhang,Yiran Wu,Yijiong Yu,Qingyun Wu,Huazheng Wang*

Main category: cs.AI

TL;DR: Live-Evo 是一种在线自进化记忆系统，通过动态管理经验权重提升任务性能，在基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有自进化系统多基于静态数据训练，难以应对真实分布变化和持续反馈，因此需要一种在线自进化记忆系统。

Method: Live-Evo 采用 Experience Bank 和 Meta-Guideline Bank 解耦经验与使用方式，通过动态权重管理机制强化有用经验并淘汰无效经验。

Result: 在 Prophet Arena 基准测试中，Live-Evo 将 Brier 分数提高了 20.8%，市场回报增加了 12.9%，并在其他基准测试中表现一致优于基线。

Conclusion: Live-Evo 是一种在线自进化记忆系统，通过解耦经验与使用方式，动态更新记忆权重，显著提升了任务解决性能，并在实际基准测试中表现出色。

Abstract: Large language model (LLM) agents are increasingly equipped with memory, which are stored experience and reusable guidance that can improve task-solving performance. Recent \emph{self-evolving} systems update memory based on interaction outcomes, but most existing evolution pipelines are developed for static train/test splits and only approximate online learning by folding static benchmarks, making them brittle under true distribution shift and continuous feedback. We introduce \textsc{Live-Evo}, an online self-evolving memory system that learns from a stream of incoming data over time. \textsc{Live-Evo} decouples \emph{what happened} from \emph{how to use it} via an Experience Bank and a Meta-Guideline Bank, compiling task-adaptive guidelines from retrieved experiences for each task. To manage memory online, \textsc{Live-Evo} maintains experience weights and updates them from feedback: experiences that consistently help are reinforced and retrieved more often, while misleading or stale experiences are down-weighted and gradually forgotten, analogous to reinforcement and decay in human memory. On the live \textit{Prophet Arena} benchmark over a 10-week horizon, \textsc{Live-Evo} improves Brier score by 20.8\% and increases market returns by 12.9\%, while also transferring to deep-research benchmarks with consistent gains over strong baselines. Our code is available at https://github.com/ag2ai/Live-Evo.

</details>


### [423] [Trust by Design: Skill Profiles for Transparent, Cost-Aware LLM Routing](https://arxiv.org/abs/2602.02386)
*Mika Okamoto,Ansel Kaplan Erol,Glenn Matlin*

Main category: cs.AI

TL;DR: BELLA框架通过技能分析和优化，帮助用户在预算内选择最适合的LLM模型，避免浪费。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试的聚合指标无法揭示任务所需的具体能力或更廉价模型是否足够，导致资源浪费。

Method: BELLA框架分为三个阶段：基于批评的细粒度技能分析、技能聚类形成能力矩阵、多目标优化模型选择。

Result: BELLA通过自然语言解释推荐理由，提升了模型选择的透明度，并在金融推理等多样化技能需求领域验证了其有效性。

Conclusion: BELLA框架通过技能分析和多目标优化，为LLM实践者提供了在预算限制下选择最优模型的透明方法，实现了成本与性能的平衡。

Abstract: How should Large Language Model (LLM) practitioners select the right model for a task without wasting money? We introduce BELLA (Budget-Efficient LLM Selection via Automated skill-profiling), a framework that recommends optimal LLM selection for tasks through interpretable skill-based model selection. Standard benchmarks report aggregate metrics that obscure which specific capabilities a task requires and whether a cheaper model could suffice. BELLA addresses this gap through three stages: (1) decomposing LLM outputs and extract the granular skills required by using critic-based profiling, (2) clustering skills into structured capability matrices, and (3) multi-objective optimization to select the right models to maximize performance while respecting budget constraints. BELLA provides natural-language rationale for recommendations, providing transparency that current black-box routing systems lack. We describe the framework architecture, situate it within the landscape of LLM routing and evaluation, and discuss its application to financial reasoning as a representative domain exhibiting diverse skill requirements and cost-variation across models. Our framework enables practitioners to make principled and cost-performance trade-offs for deploying LLMs.

</details>


### [424] [Structure Enables Effective Self-Localization of Errors in LLMs](https://arxiv.org/abs/2602.02416)
*Ankur Samanta,Akshayaa Magesh,Ayush Jain,Kavosh Asadi,Youliang Yu,Daniel Jiang,Boris Vidolov,Kaveh Hassani,Paul Sajda,Jalaj Bhandari,Yonathan Efroni*

Main category: cs.AI

TL;DR: Thought-ICS通过离散化思维步骤和迭代修正，显著提升语言模型的自我纠错能力。


<details>
  <summary>Details</summary>
Motivation: 探索语言模型能否显式定位错误推理，以构建能有效自我纠正的AI系统，受人类大脑在离散决策点监控错误的启发。

Method: 引入Iterative Correction Sampling of Thoughts (Thought-ICS)框架，通过离散化思维步骤和迭代修正机制，实现错误定位与自我纠错。

Result: 在无外部验证的自主环境中，Thought-ICS优于现有自我纠错基线，并在有验证时实现20-40%的纠错提升。

Conclusion: Thought-ICS框架通过离散化思维步骤和迭代修正，显著提升了语言模型的自我纠错能力，尤其在无外部验证的自主环境中表现优异。

Abstract: Self-correction in language models remains elusive. In this work, we explore whether language models can explicitly localize errors in incorrect reasoning, as a path toward building AI systems that can effectively correct themselves. We introduce a prompting method that structures reasoning as discrete, semantically coherent thought steps, and show that models are able to reliably localize errors within this structure, while failing to do so in conventional, unstructured chain-of-thought reasoning. Motivated by how the human brain monitors errors at discrete decision points and resamples alternatives, we introduce Iterative Correction Sampling of Thoughts (Thought-ICS), a self-correction framework. Thought-ICS iteratively prompts the model to generate reasoning one discrete and complete thought at a time--where each thought represents a deliberate decision by the model--creating natural boundaries for precise error localization. Upon verification, the model localizes the first erroneous step, and the system backtracks to generate alternative reasoning from the last correct point. When asked to correct reasoning verified as incorrect by an oracle, Thought-ICS achieves 20-40% self-correction lift. In a completely autonomous setting without external verification, it outperforms contemporary self-correction baselines.

</details>


### [425] [Thinking with Comics: Enhancing Multimodal Reasoning through Structured Visual Storytelling](https://arxiv.org/abs/2602.02453)
*Andong Chen,Wenxin Zhu,Qiuyu Ding,Yuchen Song,Muyun Yang,Tiejun Zhao*

Main category: cs.AI

TL;DR: 漫画作为高信息密度媒介，在多模态推理任务中表现优于图像且成本低于视频，不同叙事结构影响性能。


<details>
  <summary>Details</summary>
Motivation: 现有的Chain-of-Thought推理在图像和视频模态上存在局限性：静态图像难以表达时序结构，而视频则带来冗余和计算成本高的问题。漫画作为一种兼具时序结构、嵌入文本和叙事连贯性的媒介，有望成为更高效的视觉推理工具。

Method: 本研究系统性地探索了基于漫画的两种推理路径，并在多种推理任务和长上下文理解任务上进行了评估。

Result: 实验结果表明，"Thinking with Comics"在多步时序和因果推理任务上优于"Thinking with Images"，同时计算效率显著高于"Thinking with Video"。不同漫画叙事结构和风格对任务性能有持续影响。

Conclusion: Comics作为一种介于图像和视频之间的高信息密度媒介，能够有效提升多模态推理性能，尤其是在多步时序和因果推理任务上表现优于图像，同时计算成本远低于视频。

Abstract: Chain-of-Thought reasoning has driven large language models to extend from thinking with text to thinking with images and videos. However, different modalities still have clear limitations: static images struggle to represent temporal structure, while videos introduce substantial redundancy and computational cost. In this work, we propose Thinking with Comics, a visual reasoning paradigm that uses comics as a high information-density medium positioned between images and videos. Comics preserve temporal structure, embedded text, and narrative coherence while requiring significantly lower reasoning cost. We systematically study two reasoning paths based on comics and evaluate them on a range of reasoning tasks and long-context understanding tasks. Experimental results show that Thinking with Comics outperforms Thinking with Images on multi-step temporal and causal reasoning tasks, while remaining substantially more efficient than Thinking with Video. Further analysis indicates that different comic narrative structures and styles consistently affect performance across tasks, suggesting that comics serve as an effective intermediate visual representation for improving multimodal reasoning.

</details>


### [426] [MentisOculi: Revealing the Limits of Reasoning with Mental Imagery](https://arxiv.org/abs/2602.02465)
*Jana Zeller,Thaddäus Wiedemer,Fanfei Li,Thomas Klein,Prasanna Mayilvahanan,Matthias Bethge,Felix Wichmann,Ryan Cotterell,Wieland Brendel*

Main category: cs.AI

TL;DR: 研究发现，尽管视觉思维在理论上具有吸引力，但当前的多模态模型仍无法有效利用视觉化辅助推理。


<details>
  <summary>Details</summary>
Motivation: 探索统一多模态模型（UMMs）是否能够像人类心理意象一样利用中间视觉化作为推理辅助工具。

Method: 开发了MentisOculi，一个程序化、分层的多步推理问题套件，用于评估视觉策略（从潜在标记到显式生成图像）对模型性能的影响。

Result: 研究发现，视觉策略通常无法提升模型性能，UMMs在生成正确视觉内容时存在复合错误，且无法有效利用真实视觉化信息。

Conclusion: 视觉思维目前尚未对模型推理产生实际益处，MentisOculi为分析和缩小这一差距奠定了基础。

Abstract: Frontier models are transitioning from multimodal large language models (MLLMs) that merely ingest visual information to unified multimodal models (UMMs) capable of native interleaved generation. This shift has sparked interest in using intermediate visualizations as a reasoning aid, akin to human mental imagery. Central to this idea is the ability to form, maintain, and manipulate visual representations in a goal-oriented manner. To evaluate and probe this capability, we develop MentisOculi, a procedural, stratified suite of multi-step reasoning problems amenable to visual solution, tuned to challenge frontier models. Evaluating visual strategies ranging from latent tokens to explicit generated imagery, we find they generally fail to improve performance. Analysis of UMMs specifically exposes a critical limitation: While they possess the textual reasoning capacity to solve a task and can sometimes generate correct visuals, they suffer from compounding generation errors and fail to leverage even ground-truth visualizations. Our findings suggest that despite their inherent appeal, visual thoughts do not yet benefit model reasoning. MentisOculi establishes the necessary foundation to analyze and close this gap across diverse model families.

</details>


### [427] [Avenir-Web: Human-Experience-Imitating Multimodal Web Agents with Mixture of Grounding Experts](https://arxiv.org/abs/2602.02468)
*Aiden Yiliu Li,Xinyue Hao,Shilong Liu,Mengdi Wang*

Main category: cs.AI

TL;DR: Avenir-Web 是一种新型网页代理，通过混合接地专家和经验模仿规划等方法，显著提升了在复杂动态网页界面上的任务执行能力，性能媲美顶级专有模型。


<details>
  <summary>Details</summary>
Motivation: 解决现有自主网页代理在复杂动态网页界面上执行长期任务时的不可靠性问题，包括元素接地不准确、缺乏站点特定程序知识以及长期任务跟踪和记忆不稳定等。

Method: Avenir-Web 采用了混合接地专家（Mixture of Grounding Experts）、经验模仿规划（Experience-Imitation Planning）以及任务跟踪清单与自适应记忆相结合的方法。

Result: Avenir-Web 在 Online-Mind2Web 基准测试中取得了新的开源最优性能。

Conclusion: Avenir-Web 在实时网站任务中显著超越了现有的开源代理，并与顶级专有模型性能相当，为可靠的网页代理设定了新的开源标准。

Abstract: Despite advances in multimodal large language models, autonomous web agents still struggle to reliably execute long-horizon tasks on complex and dynamic web interfaces. Existing agents often suffer from inaccurate element grounding, the absence of site-specific procedural knowledge, and unstable long-term task tracking and memory, particularly when operating over complex Document Object Model structures. To address these limitations, we introduce Avenir-Web, a web agent that achieves a new open-source state of the art on the Online-Mind2Web benchmark in real-world deployment. Avenir-Web leverages a Mixture of Grounding Experts, Experience-Imitation Planning for incorporating procedural priors, and a task-tracking checklist combined with adaptive memory to enable robust and seamless interaction across diverse user interface paradigms. We evaluate Avenir-Web on Online-Mind2Web, a rigorous benchmark of live and user-centered web tasks. Our results demonstrate that Avenir-Web significantly surpasses prior open-source agents and attains performance parity with top-tier proprietary models, thereby establishing a new open-source state of the art for reliable web agents on live websites.

</details>


### [428] [Breaking the Reversal Curse in Autoregressive Language Models via Identity Bridge](https://arxiv.org/abs/2602.02470)
*Xutao Ma,Yixiao Huang,Hanlin Zhu,Somayeh Sojoudi*

Main category: cs.AI

TL;DR: 本文通过'Identity Bridge'数据配方，证明自回归LLMs可以打破'反转诅咒'，并提供了理论和实证支持。


<details>
  <summary>Details</summary>
Motivation: 挑战现有观点，即自回归因果LLMs在简单逻辑推理（如'反转诅咒'）上的失败是其固有局限，证明通过数据配方的微小调整可以缓解这一问题。

Method: 提出了一种称为'Identity Bridge'的正则化数据配方（形式为'$A \to A$'），并在理论上分析了梯度下降的隐式偏置，实证上对1B预训练语言模型进行了微调。

Result: 实验显示，使用'Identity Bridge'数据配方微调的模型在反转任务上达到了40%的成功率，而仅使用前向知识数据训练的模型成功率接近零。

Conclusion: 本文通过引入简单的正则化数据配方'Identity Bridge'，证明了即使在单层Transformer中，也能通过梯度下降的隐式偏置打破'反转诅咒'，为LLMs学习高级规则提供了理论依据和低成本路径。

Abstract: Autoregressive large language models (LLMs) have achieved remarkable success in many complex tasks, yet they can still fail in very simple logical reasoning such as the "reversal curse" -- when trained on forward knowledge data of the form "$A \rightarrow B$" (e.g., Alice's husband is Bob), the model is unable to deduce the reversal knowledge "$B \leftarrow A$" (e.g., Bob's wife is Alice) during test. Extensive prior research suggests that this failure is an inherent, fundamental limit of autoregressive causal LLMs, indicating that these models tend to memorize factual-level knowledge rather than capture higher-level rules. In this paper, we challenge this view by showing that this seemingly fundamental limit can be mitigated by slightly tweaking the training data with a simple regularization data recipe called the Identity Bridge of the form "$A \to A$" (e.g., The name of Alice is Alice). Theoretically, we prove that under this recipe, even a one-layer transformer can break the reversal curse by analyzing the implicit bias of gradient descent. Empirically, we show that a 1B pretrained language model finetuned with the proposed data recipe achieves a 40% success rate on reversal tasks, in stark contrast to a near-zero success rate when trained solely on forward-knowledge data. Our work provides a novel theoretical foundation for the reversal curse and offers a principled, low-cost path to encouraging LLMs to learn higher-level rules from data.

</details>


### [429] [AgentRx: Diagnosing AI Agent Failures from Execution Trajectories](https://arxiv.org/abs/2602.02475)
*Shraddha Barke,Arnav Goyal,Alind Khare,Avaljot Singh,Suman Nath,Chetan Bansal*

Main category: cs.AI

TL;DR: 该论文提出了AGENTRX框架，用于自动诊断AI代理失败轨迹中的关键步骤和失败类别，并在三个领域中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: AI代理的失败通常难以定位，因为其执行具有概率性、长期性、多代理性，且受噪声工具输出影响。为了解决这一问题，作者旨在提供一个自动化的失败诊断工具。

Method: 研究团队手动标注了115个失败的AI代理轨迹，并基于这些数据开发了AGENTRX框架。该框架通过合成约束条件、逐步评估并生成可审计的验证日志，结合LLM法官来定位关键失败步骤和类别。

Result: AGENTRX在三个领域中均优于现有基线，显著提升了失败步骤定位和归因的准确性。

Conclusion: 该论文提出了AGENTRX框架，通过自动诊断失败轨迹中的关键步骤和失败类别，显著提高了失败定位和归因的准确性。

Abstract: AI agents often fail in ways that are difficult to localize because executions are probabilistic, long-horizon, multi-agent, and mediated by noisy tool outputs. We address this gap by manually annotating failed agent runs and release a novel benchmark of 115 failed trajectories spanning structured API workflows, incident management, and open-ended web/file tasks. Each trajectory is annotated with a critical failure step and a category from a grounded-theory derived, cross-domain failure taxonomy. To mitigate the human cost of failure attribution, we present AGENTRX, an automated domain-agnostic diagnostic framework that pinpoints the critical failure step in a failed agent trajectory. It synthesizes constraints, evaluates them step-by-step, and produces an auditable validation log of constraint violations with associated evidence; an LLM-based judge uses this log to localize the critical step and category. Our framework improves step localization and failure attribution over existing baselines across three domains.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [430] [Fast Sparse Matrix Permutation for Mesh-Based Direct Solvers](https://arxiv.org/abs/2602.00898)
*Behrooz Zarebavami,Ahmed H. Mahmoud,Ana Dodik,Changcheng Yuan,Serban D. Porumbescu,John D. Owens,Maryam Mehri Dehnavi,Justin Solomon*

Main category: cs.GR

TL;DR: 提出了一种针对三角形网格线性系统的快速稀疏矩阵排列算法，通过放松严格平衡和分隔优化，显著减少排列时间并提升求解性能，最高提升6.27倍。


<details>
  <summary>Details</summary>
Motivation: 针对三角形网格产生的线性系统，开发一种快速的稀疏矩阵排列算法，以减少排列运行时间开销并提升求解性能。

Method: 该方法将排列分解为补丁级局部排序和分隔符的紧凑商图排序，保留了稀疏Cholesky分解所需的基本结构，同时避免了其最昂贵的组件。

Result: 在CPU和GPU上集成该算法后，多种图形应用中的排列时间减少，稀疏Cholesky求解性能最高提升6.27倍。

Conclusion: 该算法通过放松严格平衡和分隔优化的设计决策，显著减少了排列运行时间开销，并在多种图形应用中提升了稀疏Cholesky求解性能，最高可达6.27倍。

Abstract: We present a fast sparse matrix permutation algorithm tailored to linear systems arising from triangle meshes. Our approach produces nested-dissection-style permutations while significantly reducing permutation runtime overhead. Rather than enforcing strict balance and separator optimality, the algorithm deliberately relaxes these design decisions to favor fast partitioning and efficient elimination-tree construction. Our method decomposes permutation into patch-level local orderings and a compact quotient-graph ordering of separators, preserving the essential structure required by sparse Cholesky factorization while avoiding its most expensive components. We integrate our algorithm into vendor-maintained sparse Cholesky solvers on both CPUs and GPUs. Across a range of graphics applications, including single factorizations, repeated factorizations, our method reduces permutation time and improves the sparse Cholesky solve performance by up to 6.27x.

</details>


### [431] [Genus-0 Surface Parameterization using Spherical Beltrami Differentials](https://arxiv.org/abs/2602.01589)
*Zhehao Xu,Lok Ming Lui*

Main category: cs.GR

TL;DR: BOOST框架通过优化Beltrami场和接缝感知约束，解决了球形自映射中的任务目标、双射性和几何失真控制问题，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 球形表面参数化在几何处理和成像科学中是一个基础工具，但现有方法在满足任务目标、保持双射性和控制几何失真之间存在权衡。

Method: 基于Spectral Beltrami Network (SBN)，提出了BOOST神经优化框架，优化半球立体图上的两个Beltrami场，并通过显式接缝感知约束确保全局一致性。

Result: 实验表明，BOOST框架在大变形地标匹配和基于强度的球形配准中表现出色，并在脑皮层表面配准中提高了任务保真度，同时控制了失真并保持了稳健的双射行为。

Conclusion: 本文提出的BOOST框架通过优化半球立体图上的两个Beltrami场，并通过显式接缝感知约束确保全局一致性，有效解决了球形自映射中的任务目标、双射性和几何失真控制之间的权衡问题。

Abstract: Spherical surface parameterization is a fundamental tool in geometry processing and imaging science. For a genus-0 closed surface, many efficient algorithms can map the surface to the sphere; consequently, a broad class of task-driven genus-0 mapping problems can be reduced to constructing a high-quality spherical self-map. However, existing approaches often face a trade-off between satisfying task objectives (e.g., landmark or feature alignment), maintaining bijectivity, and controlling geometric distortion. We introduce the Spherical Beltrami Differential (SBD), a two-chart representation of quasiconformal self-maps of the sphere, and establish its correspondence with spherical homeomorphisms up to conformal automorphisms. Building on the Spectral Beltrami Network (SBN), we propose a neural optimization framework BOOST that optimizes two Beltrami fields on hemispherical stereographic charts and enforces global consistency through explicit seam-aware constraints. Experiments on large-deformation landmark matching and intensity-based spherical registration demonstrate the effectiveness of our proposed framework. We further apply the method to brain cortical surface registration, aligning sulcal landmarks and jointly matching cortical sulci depth maps, showing improved task fidelity with controlled distortion and robust bijective behavior.

</details>


### [432] [OFERA: Blendshape-driven 3D Gaussian Control for Occluded Facial Expression to Realistic Avatars in VR](https://arxiv.org/abs/2602.01748)
*Seokhwan Yang,Boram Yoon,Seoyoung Kang,Hail Song,Woontack Woo*

Main category: cs.GR

TL;DR: OFERA是一个实时控制高斯头像表情的新框架，利用VR头显提供的blendshape信号，通过BDA、EPM和MiA组件实现高效映射和渲染，提升VR通信体验。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过额外传感器或内部摄像头恢复被遮挡的面部表情，但传感器增加设备重量和不适，摄像头方法引发隐私问题且数据访问受限。

Method: 框架包含三个关键组件：Blendshape Distribution Alignment (BDA)、Expression Parameter Mapper (EPM)和Mapper-integrated Avatar (MiA)，形成一个端到端管道。

Result: EPM在定量指标上优于现有映射方法，用户研究表明OFERA在保持头像真实性的同时提升了表情保真度。

Conclusion: OFERA通过实时且逼真的头像表情控制，显著提升了VR通信中的临场感。

Abstract: We propose OFERA, a novel framework for real-time expression control of photorealistic Gaussian head avatars for VR headset users. Existing approaches attempt to recover occluded facial expressions using additional sensors or internal cameras, but sensor-based methods increase device weight and discomfort, while camera-based methods raise privacy concerns and suffer from limited access to raw data. To overcome these limitations, we leverage the blendshape signals provided by commercial VR headsets as expression inputs. Our framework consists of three key components: (1) Blendshape Distribution Alignment (BDA), which applies linear regression to align the headset-provided blendshape distribution to a canonical input space; (2) an Expression Parameter Mapper (EPM) that maps the aligned blendshape signals into an expression parameter space for controlling Gaussian head avatars; and (3) a Mapper-integrated Avatar (MiA) that incorporates EPM into the avatar learning process to ensure distributional consistency. Furthermore, OFERA establishes an end-to-end pipeline that senses and maps expressions, updates Gaussian avatars, and renders them in real-time within VR environments. We show that EPM outperforms existing mapping methods on quantitative metrics, and we demonstrate through a user study that the full OFERA framework enhances expression fidelity while preserving avatar realism. By enabling real-time and photorealistic avatar expression control, OFERA significantly improves telepresence in VR communication. A project page is available at https://ysshwan147.github.io/projects/ofera/.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [433] [IntentCoding: Amplifying User Intent in Code Generation](https://arxiv.org/abs/2602.00066)
*Zheng Fang,Yihong Dong,Lili Mou,Dongming Jin,Zhi Jin,Ge Li*

Main category: cs.SE

TL;DR: IntentCoding是一种增强LLM遵循用户意图的解码策略，无需额外训练，在多约束代码生成任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: LLM在代码生成中对细粒度用户意图的遵循能力不足，尤其是在多约束条件下性能下降明显。

Method: 提出IntentCoding解码策略，通过掩码用户意图并应用多强度集成机制来增强用户意图的影响。

Result: 在CodeConstraints、IFEvalCode、HumanEval和LiveCodeBench数据集上，IntentCoding相比标准解码方法在约束满足和功能正确性上均有显著提升，最高相对改进达71.0%。

Conclusion: IntentCoding显著提升了LLM在代码生成中对用户意图的遵循能力，尤其是在多约束条件下，且无需额外训练即可与现有解码流程无缝集成。

Abstract: Large Language Models (LLMs) have shown strong capabilities in code generation, but their adherence to fine-grained user intent with multiple constraints remains a significant challenge. Our empirical analysis reveals two key observations: 1) Model performance deteriorates quickly as the number of constraints in the user intent increases, and 2) While user intent does influence the model's logits, such an influence may not be strong enough to effectively steer the decoding process. To this end, we propose Intent-Amplified Code Generation (IntentCoding), a novel decoding strategy that enhances an LLM's ability to follow user intent. IntentCoding captures the influence of user intent by masking out the intent, and applies a multi-strength ensemble mechanism to amplify the effect of user intent during generation. IntentCoding is model-agnostic, requires no additional training, and integrates seamlessly with existing decoding procedures. To enable systematic evaluation, we also construct CodeConstraints, a benchmark dataset specifically designed to test user intent compliance under varying numbers of constraints. Experiments on our constructed Constraints, as well as popular IFEvalCode, HumanEval and LiveCodeBench datasets, show that our IntentCoding model significantly improves both constraint satisfaction and functional correctness compared to standard decoding approaches. IntentCoding achieves up to 71.0% relative improvement on CodeConstraints, achieves up to 67.3% relative improvement on IFEvalCode and achieves up to 29.3% relative improvement in pass@1 on HumanEval and LiveCodeBench compared with greedy decoding.

</details>


### [434] [Why Are AI Agent Involved Pull Requests (Fix-Related) Remain Unmerged? An Empirical Study](https://arxiv.org/abs/2602.00164)
*Khairul Alam,Saikat Mondal,Banani Roy*

Main category: cs.SE

TL;DR: 研究分析了AI编码代理生成的修复PR的合并情况，发现测试失败和问题重复是主要障碍，为改进提供了方向。


<details>
  <summary>Details</summary>
Motivation: 研究AI编码代理生成的修复相关PR在实际项目中的接受和合并情况，以评估其实际效果。

Method: 首先分析了8,106个由五种广泛使用的AI编码代理生成的修复相关PR，量化了合并、未合并关闭或仍开放的比例；随后对326个未合并关闭的PR进行了手动定性分析，构建了12种失败原因的目录。

Result: 测试用例失败和相同问题已被其他PR解决是最常见的未合并原因，而构建或部署失败相对较少。

Conclusion: 当前AI编码代理在实际软件维护中的关键局限性被揭示，为未来改进和更有效的人机协作指明了方向。

Abstract: Autonomous coding agents (e.g., OpenAI Codex, Devin, GitHub Copilot) are increasingly used to generate fix-related pull requests (PRs) in real world software repositories. However, their practical effectiveness depends on whether these contributions are accepted and merged by project maintainers. In this paper, we present an empirical study of AI agent involved fix related PRs, examining both their integration outcomes, latency, and the factors that hinder successful merging. We first analyze 8,106 fix related PRs authored by five widely used AI coding agents from the AIDEV POP dataset to quantify the proportions of PRs that are merged, closed without merging, or remain open. We then conduct a manual qualitative analysis of a statistically significant sample of 326 closed but unmerged PRs, spending approximately 100 person hours to construct a structured catalog of 12 failure reasons. Our results indicate that test case failures and prior resolution of the same issues by other PRs are the most common causes of non integration, whereas build or deployment failures are comparatively rare. Overall, our findings expose key limitations of current AI coding agents in real world settings and highlight directions for their further improvement and for more effective human AI collaboration in software maintenance.

</details>


### [435] [Spec-Driven Development:From Code to Contract in the Age of AI Coding Assistants](https://arxiv.org/abs/2602.00180)
*Deepak Babu Piskala*

Main category: cs.SE

TL;DR: 论文探讨了规范驱动开发（SDD）的原则、工具和应用案例，并提供了决策框架以评估其适用性。


<details>
  <summary>Details</summary>
Motivation: AI编码助手的兴起重新激发了对一个旧想法的兴趣：如果规范而非代码成为软件开发的主要产物会怎样？规范驱动开发（SDD）通过将规范视为真理来源，代码作为生成或验证的次要产物，颠覆了传统工作流程。

Method: 通过分析从行为驱动开发框架到现代AI辅助工具包（如GitHub Spec Kit）的工具，展示了规范优先哲学如何映射到实际实现中。

Result: 论文提供了SDD的全面指南，涵盖其原则、工作流程模式和支持工具，并展示了API开发、企业系统和嵌入式软件等不同领域如何应用SDD。

Conclusion: 论文提出了一个决策框架，帮助从业者判断何时采用规范驱动开发（SDD）能带来价值，以及何时更简单的方法就足够了。

Abstract: The rise of AI coding assistants has reignited interest in an old idea: what if specifications-not code-were the primary artifact of software development? Spec-driven development (SDD) inverts the traditional workflow by treating specifications as the source of truth and code as a generated or verified secondary artifact. This paper provides practitioners with a comprehensive guide to SDD, covering its principles, workflow patterns, and supporting tools. We present three levels of specification rigor-spec-first, spec-anchored, and spec-as-source-with clear guidance on when each applies. Through analysis of tools ranging from Behavior-Driven Development frameworks to modern AI-assisted toolkits like GitHub Spec Kit, we demonstrate how the spec-first philosophy maps to real implementations. We present case studies from API development, enterprise systems, and embedded software, illustrating how different domains apply SDD. We conclude with a decision framework helping practitioners determine when SDD provides value and when simpler approaches suffice.

</details>


### [436] [Towards Analyzing N-language Polyglot Programs](https://arxiv.org/abs/2602.00303)
*Jyoti Prakash,Abhishek Tiwari,Mikkel Baun Kjærgaard*

Main category: cs.SE

TL;DR: 本文探讨了三语言多语言编程系统的分析挑战，并提出了一个概念性路线图，以推动静态分析技术的发展。


<details>
  <summary>Details</summary>
Motivation: 随着多语言编程的流行，现有研究主要关注两种语言的系统，而忽略了使用三种或更多语言的复杂系统。本文旨在填补这一空白。

Method: 通过识别三语言多语言通信中的基本挑战，并提出解决方案的概念性路线图。

Result: 提出了一个针对三语言多语言通信系统的静态分析技术发展路线图。

Conclusion: 本文提出了一个概念性路线图，旨在推动静态分析技术的发展，以解决多语言编程系统中的挑战，并激发关于可扩展、语言无关的分析框架的讨论和研究。

Abstract: Polyglot programming is gaining popularity as developers integrate multiple programming languages to harness their individual strengths. With the recent popularity of platforms like GraalVM and other multi-language runtimes, creating and managing these systems has become much more feasible. However, current research on analyzing multilingual programs mainly focuses on two languages, leaving out the increasing complexity of systems that use three or more. For example, modern web systems often link JavaScript, WebAssembly, and Rust within the same execution chain. This paper envisions the landscape of software systems with three-language polyglot communication. We identify fundamental challenges in analyzing them and propose a conceptual roadmap to advance static analysis techniques to address them. Our vision aims to stimulate discussion and inspire new research directions toward scalable, language-agnostic analysis frameworks for next-generation polyglot systems.

</details>


### [437] [Are Coding Agents Generating Over-Mocked Tests? An Empirical Study](https://arxiv.org/abs/2602.00409)
*Andre Hora,Romain Robbes*

Main category: cs.SE

TL;DR: 研究首次调查了编码代理在真实软件系统中生成的测试中模拟的使用情况，发现代理更频繁地修改测试并添加模拟，需关注其潜在影响。


<details>
  <summary>Details</summary>
Motivation: 编码代理在软件开发中的广泛应用，但其生成的测试质量（尤其是过度使用模拟）对可理解性和可维护性的影响尚不明确。

Method: 分析了2025年在2,168个TypeScript、JavaScript和Python仓库中的120万次提交，包括48,563次由编码代理提交、169,361次修改测试的提交，以及44,900次向测试添加模拟的提交。

Result: 发现编码代理比非代理更倾向于修改测试和向测试添加模拟，具体表现为：(1) 60%有代理活动的仓库包含代理测试活动；(2) 23%的代理提交修改/添加测试文件（非代理为13%）；(3) 68%有代理测试活动的仓库包含代理模拟活动；(4) 36%的代理提交向测试添加模拟（非代理为26%）；(5) 新创建的仓库中代理提交的测试和模拟比例更高。

Conclusion: 研究呼吁开发者注意包含模拟的测试可能更容易自动生成（但对验证真实交互效果较差），并建议在代理配置文件中加入模拟实践的指导。

Abstract: Coding agents have received significant adoption in software development recently. Unlike traditional LLM-based code completion tools, coding agents work with autonomy (e.g., invoking external tools) and leave visible traces in software repositories, such as authoring commits. Among their tasks, coding agents may autonomously generate software tests; however, the quality of these tests remains uncertain. In particular, excessive use of mocking can make tests harder to understand and maintain. This paper presents the first study to investigate the presence of mocks in agent-generated tests of real-world software systems. We analyzed over 1.2 million commits made in 2025 in 2,168 TypeScript, JavaScript, and Python repositories, including 48,563 commits by coding agents, 169,361 commits that modify tests, and 44,900 commits that add mocks to tests. Overall, we find that coding agents are more likely to modify tests and to add mocks to tests than non-coding agents. We detect that (1) 60% of the repositories with agent activity also contain agent test activity; (2) 23% of commits made by coding agents add/change test files, compared with 13% by non-agents; (3) 68% of the repositories with agent test activity also contain agent mock activity; (4) 36% of commits made by coding agents add mocks to tests, compared with 26% by non-agents; and (5) repositories created recently contain a higher proportion of test and mock commits made by agents. Finally, we conclude by discussing implications for developers and researchers. We call attention to the fact that tests with mocks may be potentially easier to generate automatically (but less effective at validating real interactions), and the need to include guidance on mocking practices in agent configuration files.

</details>


### [438] [GitEvo: Code Evolution Analysis for Git Repositories](https://arxiv.org/abs/2602.00410)
*Andre Hora*

Main category: cs.SE

TL;DR: GitEvo是一个多语言、可扩展的工具，用于分析Git仓库中的代码演化，支持实证研究和教育。


<details>
  <summary>Details</summary>
Motivation: 分析软件系统的代码演化对从业者、研究人员和教育者都很重要，但目前缺乏专门支持代码演化分析的工具。

Method: GitEvo利用Git框架和代码解析工具，整合了Git级别和代码级别的分析。

Result: GitEvo能够帮助识别设计趋势、维护挑战，并为研究和教学提供实证数据和实例。

Conclusion: GitEvo是一个多语言、可扩展的工具，旨在支持Git仓库中的代码演化分析，并可用于新颖的实证研究和教育学习。

Abstract: Analyzing the code evolution of software systems is relevant for practitioners, researchers, and educators. It can help practitioners identify design trends and maintenance challenges, provide researchers with empirical data to study changes over time, and give educators real-world examples that enhance the teaching of software evolution concepts. Unfortunately, we lack tools specifically designed to support code evolution analysis. In this paper, we propose GitEvo, a multi-language and extensible tool for analyzing code evolution in Git repositories. GitEvo leverages Git frameworks and code parsing tools to integrate both Git-level and code-level analysis. We conclude by describing how GitEvo can support the development of novel empirical studies on code evolution and act as a learning tool for educators and students. GitEvo is available at: https://github.com/andrehora/gitevo.

</details>


### [439] [Context-Sensitive Pointer Analysis for ArkTS](https://arxiv.org/abs/2602.00457)
*Yizhuo Yang,Lingyun Xu,Mingyi Zhou,Li Li*

Main category: cs.SE

TL;DR: APAK是首个专为ArkTS设计的上下文敏感指针分析框架，通过独特的堆对象模型和插件架构，显著提升了分析精度和覆盖率。


<details>
  <summary>Details</summary>
Motivation: 现有的ArkTS静态分析工具在对象引用关系的跟踪和推导上存在不足，导致调用图可达性的拓扑断裂和分析覆盖率下降。

Method: APAK采用了一种独特的ArkTS堆对象模型和高度可扩展的插件架构，确保对未来OpenHarmony生态系统的适应性。

Result: APAK在关键指标上表现优于CHA/RTA方法，有效边覆盖率提高了34.2%，误报率从20%降至2%。

Conclusion: APAK已被集成到OpenHarmony的官方静态分析框架ArkAnalyzer中，为未来构建更复杂的程序分析工具奠定了基础。

Abstract: Current call graph generation methods for ArkTS, a new programming language for OpenHarmony, exhibit precision limitations when supporting advanced static analysis tasks such as data flow analysis and vulnerability pattern detection, while the workflow of traditional JavaScript(JS)/TypeScript(TS) analysis tools fails to interpret ArkUI component tree semantics. The core technical bottleneck originates from the closure mechanisms inherent in TypeScript's dynamic language features and the interaction patterns involving OpenHarmony's framework APIs. Existing static analysis tools for ArkTS struggle to achieve effective tracking and precise deduction of object reference relationships, leading to topological fractures in call graph reachability and diminished analysis coverage. This technical limitation fundamentally constrains the implementation of advanced program analysis techniques.
  Therefore, in this paper, we propose a tool named ArkAnalyzer Pointer Analysis Kit (APAK), the first context-sensitive pointer analysis framework specifically designed for ArkTS. APAK addresses these challenges through a unique ArkTS heap object model and a highly extensible plugin architecture, ensuring future adaptability to the evolving OpenHarmony ecosystem. In the evaluation, we construct a dataset from 1,663 real-world applications in the OpenHarmony ecosystem to evaluate APAK, demonstrating APAK's superior performance over CHA/RTA approaches in critical metrics including valid edge coverage (e.g., a 7.1% reduction compared to CHA and a 34.2% increase over RTA). The improvement in edge coverage systematically reduces false positive rates from 20% to 2%, enabling future exploration of establishing more complex program analysis tools based on our framework. Our proposed APAK has been merged into the official static analysis framework ArkAnalyzer for OpenHarmony.

</details>


### [440] [Beyond Basic Specifications? A Systematic Study of Logical Constructs in LLM-based Specification Generation](https://arxiv.org/abs/2602.00715)
*Zehan Chen,Long Zhang,Zhiwei Zhang,JingJing Zhang,Ruoyu Zhou,Yulong Shen,JianFeng Ma,Lin Yang*

Main category: cs.SE

TL;DR: 研究探讨了大型语言模型生成高级逻辑构造的可行性，实验证明其有效，并提升了验证能力与鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要局限于基于基本句法构造生成规范，无法满足复杂程序验证对高级抽象的需求，因此探索大型语言模型是否能有效生成复杂逻辑构造。

Method: 定义了四种不同抽象级别的句法配置，并在主流程序验证数据集上使用多种代表性大型语言模型进行了广泛评估。

Result: 实验证实大型语言模型能够生成有效的逻辑构造，且逻辑构造与基本句法构造的协同使用能在不显著增加验证开销的情况下提升验证能力和鲁棒性。

Conclusion: 本研究首次系统探讨了利用大型语言模型生成高级逻辑构造的可行性，为未来构建具有更强抽象能力的自动化程序验证框架提供了实证基础和指导。

Abstract: Formal specifications play a pivotal role in accurately characterizing program behaviors and ensuring software correctness. In recent years, leveraging large language models (LLMs) for the automatic generation of program specifications has emerged as a promising avenue for enhancing verification efficiency. However, existing research has been predominantly confined to generating specifications based on basic syntactic constructs, falling short of meeting the demands for high-level abstraction in complex program verification. Consequently, we propose incorporating logical constructs into existing LLM-based specification generation framework. Nevertheless, there remains a lack of systematic investigation into whether LLMs can effectively generate such complex constructs. To this end, we conduct an empirical study aimed at exploring the impact of various types of syntactic constructs on specification generation framework. Specifically, we define four syntactic configurations with varying levels of abstraction and perform extensive evaluations on mainstream program verification datasets, employing a diverse set of representative LLMs. Experimental results first confirm that LLMs are capable of generating valid logical constructs. Further analysis reveals that the synergistic use of logical constructs and basic syntactic constructs leads to improvements in both verification capability and robustness, without significantly increasing verification overhead. Additionally, we uncover the distinct advantages of two refinement paradigms. To the best of our knowledge, this is the first systematic work exploring the feasibility of utilizing LLMs for generating high-level logical constructs, providing an empirical basis and guidance for the future construction of automated program verification framework with enhanced abstraction capabilities.

</details>


### [441] [Can Vision-Language Models Handle Long-Context Code? An Empirical Study on Visual Compression](https://arxiv.org/abs/2602.00746)
*Jianping Zhong,Guochang Li,Chen Zhi,Junxiao Han,Zhen Qin,Xinkui Zhao,Nan Wang,Shuiguang Deng,Jianwei Yin*

Main category: cs.SE

TL;DR: LongCodeOCR通过视觉压缩代码为图像序列，解决了文本压缩的依赖断裂问题，显著提升了性能和效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有文本代码压缩方法因选择性过滤导致的依赖闭合破坏和语义碎片化问题。

Method: 引入LongCodeOCR，将代码渲染为压缩的二维图像序列供视觉语言模型处理，保留全局视图。

Result: 在1.7倍压缩比下，LongCodeOCR在Long Module Summarization上的CompScore比LongCodeZip提高36.85分；在1M token上下文长度下，压缩效率提高4倍，延迟从4.3小时降至1分钟。

Conclusion: LongCodeOCR作为一种视觉代码压缩框架，在保持全局视图的同时避免了依赖断裂，显著提升了代码理解任务的性能，并在压缩效率和延迟方面优于现有方法。

Abstract: Large Language Models (LLMs) struggle with long-context code due to window limitations. Existing textual code compression methods mitigate this via selective filtering but often disrupt dependency closure, causing semantic fragmentation. To address this, we introduce LongCodeOCR, a visual compression framework that renders code into compressed two-dimensional image sequences for Vision-Language Models (VLMs). By preserving a global view, this approach avoids the dependency breakage inherent in filtering. We systematically evaluate LongCodeOCR against the state-of-the-art LongCodeZip across four benchmarks spanning code summarization, code question answering, and code completion.
  Our results demonstrate that visual code compression serves as a viable alternative for tasks requiring global understanding. At comparable compression ratios ($\sim$1.7$\times$), LongCodeOCR improves CompScore on Long Module Summarization by 36.85 points over LongCodeZip. At a 1M-token context length with Glyph (a specialized 9B VLM), LongCodeOCR maintains higher accuracy than LongCodeZip while operating at about 4$\times$ higher compression. Moreover, compared with LongCodeZip, LongCodeOCR drastically reduces compression-stage overhead (reducing latency from $\sim$4.3 hours to $\sim$1 minute at 1M tokens). Finally, our results characterize a fundamental coverage--fidelity trade-off: visual code compression retains broader context coverage to support global dependencies, yet faces fidelity bottlenecks on exactness-critical tasks; by contrast, textual code compression preserves symbol-level precision while sacrificing structural coverage.

</details>


### [442] [ScratchEval : A Multimodal Evaluation Framework for LLMs in Block-Based Programming](https://arxiv.org/abs/2602.00757)
*Yuan Si,Simeng Han,Daming Li,Hanyuan Shi,Jialu Zhang*

Main category: cs.SE

TL;DR: ScratchEval是首个用于评估LLM修复Scratch程序的可执行基准，包含100个精选项目，通过三层协议衡量修复质量，为LLM在基于块编程任务上的评估和微调提供基础。


<details>
  <summary>Details</summary>
Motivation: LLM在文本编程任务中表现优异，但在基于块的编程语言（如Scratch）中不可靠，因其程序结构复杂、事件驱动并发及代码与多媒体紧密耦合，导致LLM常误解语义并生成错误修复。

Method: 引入ScratchEval基准，包含100个精选的Scratch项目，每个项目配有可执行测试套件、错误描述与修复、块级编辑约束及多媒体资源。采用人类参与的流程，结合自动化项目挖掘与专家验证。提出三层可执行协议，衡量功能正确性、修复质量和解释质量。

Result: 通过ScratchEval，研究了领域特定微调、训练数据有效性和模型对未见错误类型的泛化能力。

Conclusion: ScratchEval提供了一个可重复的基础，用于评估和微调LLM在基于块的编程任务上的表现。

Abstract: LLMs have achieved strong performance on text-based programming tasks, yet they remain unreliable for block-based languages such as Scratch. Scratch programs exhibit deeply nested, non-linear structures, event-driven concurrency across multiple sprites, and tight coupling between code and multimedia assets, properties that differ fundamentally from textual code. As a result, LLMs often misinterpret Scratch semantics and generate large, invasive edits that are syntactically valid but semantically incorrect when repairing buggy programs.
  We introduce ScratchEval, the first executable benchmark designed to evaluate LLM-based repair for Scratch programs, covering program understanding, debugging, analysis, and repair. The benchmark contains 100 curated Scratch projects from the public repository, selected for structural and semantic complexity. Each project is paired with executable test suites, bug descriptions with corresponding fixes, block-level edit constraints defining minimal semantically correct repairs, and required multimedia assets. The benchmark is constructed through a human-in-the-loop pipeline combining automated project mining with expert validation of trigger-outcome semantics and representative bug patterns, with emphasis on event ordering, concurrency, and state management.
  To enable rigorous and reproducible evaluation, we propose a three-layer executable protocol measuring functional correctness via VM-level execution, repair quality using block-level edit distance and behavioral trajectory comparisons, and explanation quality via structured rubrics assessing alignment between model reasoning and generated patches. Using ScratchEval, we study domain-specific fine-tuning, training data effectiveness, and model generalization to unseen bug types. ScratchEval provides a reproducible foundation for evaluating and post-training LLMs on block-based programming tasks.

</details>


### [443] [Test Behaviors, Not Methods! Detecting Tests Obsessed by Methods](https://arxiv.org/abs/2602.00761)
*Andre Hora,Andy Zaidman*

Main category: cs.SE

TL;DR: 提出新测试气味'Test Obsessed by Method'，通过运行时分析识别测试覆盖同一生产方法多路径的问题，实证研究在Python标准库中发现44例，可拆分为118个新测试。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过计算生产方法调用来识别测试气味'Eager Test'，但研究表明这种方法不准确。因此，作者提出基于运行时分析的互补解决方案，假设验证多个行为的测试可能覆盖同一生产方法的多个路径。

Method: 基于运行时分析，提出了一种新的测试气味'Test Obsessed by Method'，并通过实证研究在12个Python标准库的测试套件中探索了该气味的存在。

Result: 在12个测试套件中的11个中检测到44个'Test Obsessed by Method'气味，每个有问题的测试验证了生产方法的两个行为中位数，并可拆分为118个新测试。23%的有问题测试的代码注释承认了测试的不同行为。

Conclusion: 本文讨论了通过运行时分析识别测试代码中的问题，提出了新的测试气味'Test Obsessed by Method'，并探讨了其在Python标准库中的存在情况。最后讨论了该方法的益处、限制及未来研究方向。

Abstract: Best testing practices state that tests should verify a single functionality or behavior of the system. Tests that verify multiple behaviors are harder to understand, lack focus, and are more coupled to the production code. An attempt to identify this issue is the test smell \emph{Eager Test}, which aims to capture tests that verify too much functionality based on the number of production method calls. Unfortunately, prior research suggests that counting production method calls is an inaccurate measure, as these calls do not reliably serve as a proxy for functionality. We envision a complementary solution based on runtime analysis: we hypothesize that some tests that verify multiple behaviors will likely cover multiple paths of the same production methods. Thus, we propose a novel test smell named \emph{Test Obsessed by Method}, a test method that covers multiple paths of a single production method. We provide an initial empirical study to explore the presence of this smell in 2,054 tests provided by 12 test suites of the Python Standard Library. (1) We detect 44 \emph{Tests Obsessed by Methods} in 11 of the 12 test suites. (2) Each smelly test verifies a median of two behaviors of the production method. (3) The 44 smelly tests could be split into 118 novel tests. (4) 23% of the smelly tests have code comments recognizing that distinct behaviors are being tested. We conclude by discussing benefits, limitations, and further research.

</details>


### [444] [Code Quality Analysis of Translations from C to Rust](https://arxiv.org/abs/2602.00840)
*Biruk Tadesse,Vikram Nitin,Mazin Salah,Baishakhi Ray,Marcelo d'Amorim,Wesley Assunção*

Main category: cs.SE

TL;DR: 该研究分析了三种C到Rust翻译工具的质量，发现自动化翻译在多维度质量上仍无法匹敌人工翻译，且存在系统性权衡问题。


<details>
  <summary>Details</summary>
Motivation: C/C++存在显著的内存和线程安全问题，虽然已有研究探索了将其自动翻译到更安全的语言（如Rust），但这些研究主要关注翻译代码的正确性和安全性，而忽略了其他重要的质量因素（如性能、健壮性和可维护性）。

Method: 对三种C到Rust的翻译工具（C2Rust、C2SaferRust和TranslationGym）进行了深入的定量和定性分析，使用人工翻译作为基准，评估了翻译后Rust代码的多个重要质量属性。

Result: 结果显示，虽然新技术减少了一些不安全和非惯用的模式，但频繁引入新问题，揭示了现有评估实践中不可见的系统性权衡。自动化技术在所有质量维度上均未能一致匹配或超越人工翻译，且即使是人工编写的Rust代码也存在可读性和非惯用模式等内部质量问题。

Conclusion: 翻译质量仍是一个多维度的挑战，需要系统性的评估和针对性的工具支持，超越了简单的自动化和手动重写。

Abstract: C/C++ is a prevalent programming language. Yet, it suffers from significant memory and thread-safety issues. Recent studies have explored automated translation of C/C++ to safer languages, such as Rust. However, these studies focused mostly on the correctness and safety of the translated code, which are indeed critical, but they left other important quality concerns (e.g., performance, robustness, and maintainability) largely unexplored. This work investigates strengths and weaknesses of three C-to-Rust translators, namely C2Rust (a transpiler), C2SaferRust (an LLM-guided transpiler), and TranslationGym (an LLM-based direct translation). We perform an in-depth quantitative and qualitative analysis of several important quality attributes for the translated Rust code of the popular GNU coreutils, using human-based translation as a baseline. To assess the internal and external quality of the Rust code, we: (i) apply Clippy, a rule-based state-of-the-practice Rust static analysis tool; (ii) investigate the capability of an LLM (GPT-4o) to identify issues potentially overlooked by Clippy; and (iii) perform a manual analysis of the issues reported by Clippy and GPT-4o. Our results show that while newer techniques reduce some unsafe and non-idiomatic patterns, they frequently introduce new issues, revealing systematic trade-offs that are not visible under existing evaluation practices. Notably, none of the automated techniques consistently match or exceed human-written translations across all quality dimensions, yet even human-written Rust code exhibits persistent internal quality issues such as readability and non-idiomatic patterns. Together, these findings show that translation quality remains a multi-dimensional challenge, requiring systematic evaluation and targeted tool support beyond both naive automation and manual rewriting.

</details>


### [445] [MCP-Atlas: A Large-Scale Benchmark for Tool-Use Competency with Real MCP Servers](https://arxiv.org/abs/2602.00933)
*Chaithanya Bandi,Ben Hertzberg,Geobio Boo,Tejas Polakam,Jeff Da,Sami Hassaan,Manasi Sharma,Andrew Park,Ernesto Hernandez,Dan Rambado,Ivan Salazar,Rafael Cruz,Chetan Rane,Ben Levin,Brad Kenstler,Bing Liu*

Main category: cs.SE

TL;DR: MCP-Atlas 是一个大规模基准测试，用于评估LLM在真实多步骤工作流中的工具使用能力，包含36个MCP服务器和220个工具，任务设计避免命名特定工具，评分基于事实声明。前沿模型的通过率超过50%。


<details>
  <summary>Details</summary>
Motivation: 现有的评估往往无法捕捉现实场景的复杂性，依赖于受限的工具集、简单的工作流程或主观的LLM-as-a-judge指标。因此，需要一个大尺度、现实的基准来评估工具使用能力。

Method: MCP-Atlas 包括1,000个任务，使用自然语言提示，避免命名特定工具或服务器，要求代理识别并协调跨多个服务器的3-6个工具调用。评分采用基于声明的标准，根据模型最终答案中满足的事实声明给予部分信用，并辅以工具发现、参数化、语法、错误恢复和效率的内部诊断。

Result: 评估结果显示，顶级模型的通过率超过50%，主要失败原因在于工具使用不足和任务理解不充分。

Conclusion: MCP-Atlas 是一个大规模基准测试，用于评估工具使用能力，包含36个真实的MCP服务器和220个工具。通过1,000个任务设计，评估模型在真实多步骤工作流中的表现。前沿模型的通过率超过50%，主要失败原因在于工具使用不足和任务理解不充分。

Abstract: The Model Context Protocol (MCP) is rapidly becoming the standard interface for Large Language Models (LLMs) to discover and invoke external tools. However, existing evaluations often fail to capture the complexity of real-world scenarios, relying on restricted toolsets, simplistic workflows, or subjective LLM-as-a-judge metrics. We introduce MCP-Atlas, a large-scale benchmark for evaluating tool-use competency, comprising 36 real MCP servers and 220 tools. It includes 1,000 tasks designed to assess tool-use competency in realistic, multi-step workflows. Tasks use natural language prompts that avoid naming specific tools or servers, requiring agents to identify and orchestrate 3-6 tool calls across multiple servers. We score tasks using a claims-based rubric that awards partial credit based on the factual claims satisfied in the model's final answer, complemented by internal diagnostics on tool discovery, parameterization, syntax, error recovery, and efficiency. Evaluation results on frontier models reveal that top models achieve pass rates exceeding 50%, with primary failures arising from inadequate tool usage and task understanding. We release the task schema, containerized harness, and a 500-task public subset of the benchmark dataset to facilitate reproducible comparisons and advance the development of robust, tool-augmented agents.

</details>


### [446] [Cast: Automated Resilience Testing for Production Cloud Service Systems](https://arxiv.org/abs/2602.00972)
*Zhuangbin Chen,Zhiling Deng,Kaiming Zhang,Yang Liu,Cheng Cui,Jinfeng Zhong,Zibin Zheng*

Main category: cs.SE

TL;DR: Cast是一个自动化框架，用于在生产环境中测试微服务弹性，通过回放流量和注入故障，高效发现并修复漏洞。


<details>
  <summary>Details</summary>
Motivation: 微服务架构的分布式特性带来了显著的弹性挑战，传统测试方法因大量手动工作和过于简化的测试环境而无法捕捉生产系统的复杂性。

Method: Cast采用自动化、端到端的框架，通过回放生产流量并注入应用级故障来测试微服务的弹性。它使用复杂度驱动策略修剪冗余测试，优先处理关键服务执行路径的高价值测试。测试生命周期通过三阶段管道（启动、故障注入和恢复）自动化，并使用多面oracle自动验证系统弹性。

Result: 在华为云部署八个月后，Cast被多个服务团队采用，主动解决了弹性漏洞。对四个大规模应用的分析揭示了137个潜在漏洞，其中89个被开发者确认。在48个复现错误的基准测试中，Cast实现了90%的高覆盖率。

Conclusion: Cast是一个实用且有效的解决方案，能够系统性地提高工业微服务系统的可靠性。

Abstract: The distributed nature of microservice architecture introduces significant resilience challenges. Traditional testing methods, limited by extensive manual effort and oversimplified test environments, fail to capture production system complexity. To address these limitations, we present Cast, an automated, end-to-end framework for microservice resilience testing in production. It achieves high test fidelity by replaying production traffic against a comprehensive library of application-level faults to exercise internal error-handling logic. To manage the combinatorial test space, Cast employs a complexity-driven strategy to systematically prune redundant tests and prioritize high-value tests targeting the most critical service execution paths. Cast automates the testing lifecycle through a three-phase pipeline (i.e., startup, fault injection, and recovery) and uses a multi-faceted oracle to automatically verify system resilience against nuanced criteria. Deployed in Huawei Cloud for over eight months, Cast has been adopted by many service teams to proactively address resilience vulnerabilities. Our analysis on four large-scale applications with millions of traces reveals 137 potential vulnerabilities, with 89 confirmed by developers. To further quantify its performance, Cast is evaluated on a benchmark set of 48 reproduced bugs, achieving a high coverage of 90%. The results show that Cast is a practical and effective solution for systematically improving the reliability of industrial microservice systems.

</details>


### [447] [Morphis: SLO-Aware Resource Scheduling for Microservices with Time-Varying Call Graphs](https://arxiv.org/abs/2602.01044)
*Yu Tang,Hailiang Zhao,Rui Shi,Chuansheng Lu,Yifei Zhang,Kingsum Chow,Shuiguang Deng*

Main category: cs.SE

TL;DR: Morphis是一个依赖感知的资源调配框架，通过模式分析和全局优化，显著降低CPU使用并保持高SLO合规。


<details>
  <summary>Details</summary>
Motivation: 现代微服务系统在运行时调用图中表现出持续的结构演化，现有资源管理方法未能有效利用其潜在的规律性。

Method: 提出了Morphis框架，结合模式感知的追踪分析和全局优化，通过结构指纹分解追踪为稳定的执行骨干和可解释的偏差子图。

Result: 在TrainTicket基准测试中，Morphis相比现有基线减少了35-38%的CPU消耗，同时保持了98.8%的SLO合规率。

Conclusion: Morphis通过依赖感知的资源调配框架，显著降低了CPU消耗并保持了高SLO合规率。

Abstract: Modern microservice systems exhibit continuous structural evolution in their runtime call graphs due to workload fluctuations, fault responses, and deployment activities. Despite this complexity, our analysis of over 500,000 production traces from ByteDance reveals a latent regularity: execution paths concentrate around a small set of recurring invocation patterns. However, existing resource management approaches fail to exploit this structure. Industrial autoscalers like Kubernetes HPA ignore inter-service dependencies, while recent academic methods often assume static topologies, rendering them ineffective under dynamic execution contexts. In this work, we propose Morphis, a dependency-aware provisioning framework that unifies pattern-aware trace analysis with global optimization. It introduces structural fingerprinting that decomposes traces into a stable execution backbone and interpretable deviation subgraphs. Then, resource allocation is formulated as a constrained optimization problem over predicted pattern distributions, jointly minimizing aggregate CPU usage while satisfying end-to-end tail-latency SLOs. Our extensive evaluations on the TrainTicket benchmark demonstrate that Morphis reduces CPU consumption by 35-38% compared to state-of-the-art baselines while maintaining 98.8% SLO compliance.

</details>


### [448] [SPELL: Synthesis of Programmatic Edits using LLMs](https://arxiv.org/abs/2602.01107)
*Daniel Ramos,Catarina Gamboa,Inês Lynce,Vasco Manquinho,Ruben Martins,Claire Le Goues*

Main category: cs.SE

TL;DR: 本文提出一种基于LLMs和Agent的自动化API迁移方法，通过提取和泛化迁移示例生成可重用转换脚本，有效解决了传统工具的数据依赖问题。


<details>
  <summary>Details</summary>
Motivation: 解决传统自动化迁移工具依赖稀缺的现有迁移数据且难以适用于任意库对的局限性，同时充分利用现代代码转换基础设施。

Method: 利用LLMs提取迁移示例，并通过Agent将其泛化为可重用的转换脚本，结合现代代码转换工具PolyglotPiranha实现自动化迁移。

Result: 实验结果表明，该系统能生成多样化的迁移示例，并合成适用于实际代码库的转换脚本。

Conclusion: 本文提出的方法成功地将LLMs的潜在迁移知识转化为结构化、可测试且可重复的迁移逻辑，无需依赖现有语料库或手动工程努力。

Abstract: Library migration is a common but error-prone task in software development. Developers may need to replace one library with another due to reasons like changing requirements or licensing changes. Migration typically entails updating and rewriting source code manually. While automated migration tools exist, most rely on mining examples from real-world projects that have already undergone similar migrations. However, these data are scarce, and collecting them for arbitrary pairs of libraries is difficult. Moreover, these migration tools often miss out on leveraging modern code transformation infrastructure.
  In this paper, we present a new approach to automated API migration that sidesteps the limitations described above. Instead of relying on existing migration data or using LLMs directly for transformation, we use LLMs to extract migration examples. Next, we use an Agent to generalize those examples to reusable transformation scripts in PolyglotPiranha, a modern code transformation tool. Our method distills latent migration knowledge from LLMs into structured, testable, and repeatable migration logic, without requiring preexisting corpora or manual engineering effort. Experimental results across Python libraries show that our system can generate diverse migration examples and synthesize transformation scripts that generalize to real-world codebases.

</details>


### [449] [Autoregressive, Yet Revisable: In Decoding Revision for Secure Code Generation](https://arxiv.org/abs/2602.01187)
*Chengran Yang,Zichao Wei,Heminghao Deng,Jinfeng Jiang,Zhensu Sun,Ting Zhang,Tianyi Wu,Ming Wen,David Lo*

Main category: cs.SE

TL;DR: Stream of Revision 提出了一种动态自我修正的代码生成范式，通过内部化修订循环提升模型表现。


<details>
  <summary>Details</summary>
Motivation: 传统的代码生成方法过于线性，无法模拟编程中的动态修订过程，限制了模型的表现。

Method: 引入特定的动作标记，使模型能够在单次前向传递中无缝回溯和编辑历史，从而激活其潜在能力。

Result: 在安全代码生成任务中，Stream of Revision 显著减少了漏洞数量，且推理开销最小。

Conclusion: Stream of Revision 通过内部化修订循环，显著提升了代码生成的质量和安全性，同时保持了较低的推理开销。

Abstract: Large Language Model (LLM) based code generation is predominantly formulated as a strictly monotonic process, appending tokens linearly to an immutable prefix. This formulation contrasts to the cognitive process of programming, which is inherently interleaved with forward generation and on-the-fly revision. While prior works attempt to introduce revision via post-hoc agents or external static tools, they either suffer from high latency or fail to leverage the model's intrinsic semantic reasoning. In this paper, we propose Stream of Revision, a paradigm shift that elevates code generation from a monotonic stream to a dynamic, self-correcting trajectory by leveraging model's intrinsic capabilities. We introduce specific action tokens that enable the model to seamlessly backtrack and edit its own history within a single forward pass. By internalizing the revision loop, our framework Stream of Revision allows the model to activate its latent capabilities just-in-time without external dependencies. Empirical results on secure code generation show that Stream of Revision significantly reduces vulnerabilities with minimal inference overhead.

</details>


### [450] [TraceLLM: Leveraging Large Language Models with Prompt Engineering for Enhanced Requirements Traceability](https://arxiv.org/abs/2602.01253)
*Nouf Alturayeif,Irfan Ahmad,Jameleddine Hassine*

Main category: cs.SE

TL;DR: TraceLLM通过提示工程和演示选择提升需求追踪，性能优于传统方法，支持半自动化工作流程。


<details>
  <summary>Details</summary>
Motivation: 传统的需求追踪方法（如手动或信息检索模型）劳动密集、易出错且精度低。LLMs在软件工程任务中展现了潜力，但缺乏针对提取准确追踪链接的系统化提示设计和评估。

Method: 提出了TraceLLM框架，结合严格的数据集分割、迭代提示优化、上下文角色和领域知识的丰富化，并在零样本和少样本设置下进行评估。使用四种基准数据集和八种最先进的LLM评估提示的泛化性和鲁棒性。

Result: TraceLLM在四个基准数据集（涵盖航空航天、医疗等领域）上实现了最先进的F2分数，优于传统IR基线、微调模型和先前的LLM方法。演示选择策略中，标签感知和基于多样性的采样尤为有效。

Conclusion: TraceLLM通过系统化的提示工程和演示选择，显著提升了需求追踪的准确性，其性能超越了传统IR基线、微调模型和先前的LLM方法。研究还发现，追踪性能不仅依赖于模型能力，更关键的是提示工程的质量。TraceLLM可以支持半自动化的追踪工作流程，由人类分析师审查和验证候选链接。

Abstract: Requirements traceability, the process of establishing and maintaining relationships between requirements and various software development artifacts, is paramount for ensuring system integrity and fulfilling requirements throughout the Software Development Life Cycle (SDLC). Traditional methods, including manual and information retrieval models, are labor-intensive, error-prone, and limited by low precision. Recently, Large Language Models (LLMs) have demonstrated potential for supporting software engineering tasks through advanced language comprehension. However, a substantial gap exists in the systematic design and evaluation of prompts tailored to extract accurate trace links. This paper introduces TraceLLM, a systematic framework for enhancing requirements traceability through prompt engineering and demonstration selection. Our approach incorporates rigorous dataset splitting, iterative prompt refinement, enrichment with contextual roles and domain knowledge, and evaluation across zero- and few-shot settings. We assess prompt generalization and robustness using eight state-of-the-art LLMs on four benchmark datasets representing diverse domains (aerospace, healthcare) and artifact types (requirements, design elements, test cases, regulations). TraceLLM achieves state-of-the-art F2 scores, outperforming traditional IR baselines, fine-tuned models, and prior LLM-based methods. We also explore the impact of demonstration selection strategies, identifying label-aware, diversity-based sampling as particularly effective. Overall, our findings highlight that traceability performance depends not only on model capacity but also critically on the quality of prompt engineering. In addition, the achieved performance suggests that TraceLLM can support semi-automated traceability workflows in which candidate links are reviewed and validated by human analysts.

</details>


### [451] [Evaluating Workflow Automation Efficiency Using n8n: A Small-Scale Business Case Study](https://arxiv.org/abs/2602.01311)
*Ahmed Raza Amir,Syed Muhammad Atif*

Main category: cs.SE

TL;DR: 低代码自动化（n8n）显著提升小规模工作流的执行效率和可靠性，执行时间减少151倍且零错误。


<details>
  <summary>Details</summary>
Motivation: 评估低代码平台（如n8n）在工作流自动化中的性能影响，以帮助小型组织和个人无需广泛的软件开发专业知识即可提高运营效率。

Method: 通过一个小规模商业案例研究，使用n8n平台实施了一个代表性的线索处理工作流，自动存储数据、发送电子邮件确认和生成实时通知。实验基准测试在受控条件下比较了20次手动执行和25次自动执行。

Result: 结果显示，平均执行时间从185.35秒（手动）显著减少到1.23秒（自动），执行时间减少了约151倍。此外，手动执行的错误率为5%，而自动执行实现了零错误。

Conclusion: 研究结果强调了低代码自动化在小规模工作流中提高效率、可靠性和操作一致性的有效性。

Abstract: Workflow automation has become increasingly accessible through low-code platforms, enabling small organizations and individuals to improve operational efficiency without extensive software development expertise. This study evaluates the performance impact of workflow automation using n8n through a small-scale business case study. A representative lead-processing workflow was implemented to automatically store data, send email confirmations, and generate real-time notifications. Experimental benchmarking was conducted by comparing 20 manual executions with 25 automated executions under controlled conditions. The results demonstrate a significant reduction in the average execution time from 185.35 seconds (manual) to 1.23 seconds (automated), corresponding to an approximately 151 times reduction in execution time. Additionally, manual execution exhibited an error rate of 5%, while automated execution achieved zero observed errors. The findings highlight the effectiveness of low-code automation in improving efficiency, reliability, and operational consistency for small-scale workflows.

</details>


### [452] [AdNanny: One Reasoning LLM for All Offline Ads Recommendation Tasks](https://arxiv.org/abs/2602.01563)
*Nan Hu,Han Li,Jimeng Sun,Lu Wang,Fangkai Yang,Bo Qiao,Pu Zhao,David Dai,Mengyu Liu,Yuefeng Zhan,Jianjin Zhang,Weihao Han,Allen Sun,Qingwei Lin,Saravan Rajmohan,Dongmei Zhang,Denvy Deng,Feng Sun,Qi Zhang*

Main category: cs.SE

TL;DR: AdNanny是一个统一的推理中心LLM，作为离线广告任务的共享骨干，通过微调和强化学习显著提升广告系统效率。


<details>
  <summary>Details</summary>
Motivation: 由于严格的毫秒级延迟限制，直接在在线广告系统中部署大型语言模型（LLMs）往往不切实际，这促使了使用LLMs离线改进检索、排名和推荐模型。现有解决方案通常为单个任务微调单独的LLMs，导致冗余模型、高维护成本和有限的性能提升。

Method: AdNanny通过微调公开的671B参数DeepSeek-R1检查点，使用支持混合密集-MoE并行性的可扩展训练系统构建。构建了推理增强语料库，将结构化监督与逐步自然语言解释配对。通过多任务监督微调阶段和自适应重加权，使AdNanny能够以一致的推理格式处理多样化的标记和生成任务。随后使用下游广告指标进行强化学习，以对齐模型行为与在线检索和排名目标。

Result: AdNanny在Bing Ads中部署，显著减少了手动标记工作，并在多个离线任务中提高了准确性。

Conclusion: AdNanny通过将多个任务特定模型整合为一个统一的推理中心基础模型，为大规模广告系统提供了可扩展且经济高效的解决方案。

Abstract: Large Language Models (LLMs) have shown strong capabilities in Natural Language Understanding and Generation, but deploying them directly in online advertising systems is often impractical due to strict millisecond-level latency constraints. This has motivated the use of LLMs offline to improve retrieval, ranking, and recommendation models. Existing solutions typically fine-tune separate LLMs for individual tasks such as query-ad relevance labeling, keyword-based query generation, and user profiling. This results in redundant models, high maintenance cost, and limited performance gains despite substantial overlap in domain knowledge and reasoning patterns. We introduce AdNanny, a unified reasoning-centric LLM that serves as a shared backbone for offline advertising tasks. AdNanny is obtained by fine-tuning a public 671B-parameter DeepSeek-R1 checkpoint using a scalable training system that supports hybrid dense-MoE parallelism. We construct reasoning-augmented corpora that pair structured supervision with step-by-step natural language explanations. A multi-task supervised fine-tuning stage with adaptive reweighting enables AdNanny to handle diverse labeling and generation tasks in a consistent reasoning format. This is followed by reinforcement learning using downstream advertising metrics to align model behavior with online retrieval and ranking objectives. AdNanny is deployed in production within Bing Ads, where it significantly reduces manual labeling effort and improves accuracy across multiple offline tasks. By consolidating many task-specific models into a single reasoning-centric foundation model, AdNanny provides a scalable and cost-effective solution for large-scale advertising systems.

</details>


### [453] [Role of CI Adoption in Mobile App Success: An Empirical Study of Open-Source Android Projects](https://arxiv.org/abs/2602.01957)
*Xiaoxin Zhou,Taher A. Ghaleb,Safwat Hassan*

Main category: cs.SE

TL;DR: CI adoption in mobile apps leads to faster releases, higher activity, and better user engagement without compromising ratings.


<details>
  <summary>Details</summary>
Motivation: Despite widespread use of CI, its impact on mobile development activity, release speed, and user-facing outcomes remains underexplored.

Method: Analyzed open-source Android apps to compare CI adopters and non-adopters, characterize adoption patterns using activity and bug metrics, and assess pre/post adoption changes and user-facing outcomes.

Result: CI adopters are larger and more active, with faster and more regular releases. Adoption is concentrated in integration- and reliability-intensive categories and associated with higher Google Play Store engagement without lower ratings.

Conclusion: CI adoption in mobile development aligns with practices that support sustained delivery, higher project visibility, and stronger user engagement.

Abstract: Mobile apps face strong pressure for fast and reliable updates. Continuous Integration (CI) helps automate builds, tests, and releases, but its impact on mobile development remains underexplored. Despite the widespread use of CI, little is known about how it affects development activity, release speed, and user-facing outcomes in mobile projects. Existing studies mostly focus on CI adoption in general-purpose software, providing limited insight into mobile-specific dynamics, such as app store visibility and user engagement. In this paper, we analyze open-source Android apps to (1) compare CI adopters and non-adopters, (2) characterize adoption patterns using activity and bug metrics, and (3) assess pre/post adoption changes and user-facing outcomes. We observe that CI adopters are larger and more active, with faster and more regular releases. CI adoption is concentrated in integration- and reliability-intensive categories (e.g., finance and productivity) and is associated with higher Google Play Store engagement (more downloads and reviews) without lower ratings. Overall, CI adoption aligns with practices that support sustained delivery, higher project visibility, and stronger user engagement in mobile ecosystems.

</details>


### [454] [CAM: A Causality-based Analysis Framework for Multi-Agent Code Generation Systems](https://arxiv.org/abs/2602.02138)
*Lyu Zongyi,Ji Zhenlan,Chen Songqiang,Wang Liwen,Huang Yuheng,Wang Shuai,Cheung Shing-Chi*

Main category: cs.SE

TL;DR: CAM是一个基于因果分析的框架，用于量化MACGS中间特征的重要性，揭示了关键发现并展示了实际应用。


<details>
  <summary>Details</summary>
Motivation: 多智能体架构的复杂性导致大量中间输出，但其对系统正确性的个体重要性尚不明确，阻碍了MACGS设计的针对性优化。

Method: 通过系统分类中间输出并模拟实际错误，量化不同中间特征对系统正确性的贡献。

Result: 发现上下文依赖特征和混合后端架构的重要性，并通过修复失败和特征修剪展示了CAM的实际效用。

Conclusion: CAM框架为多智能体代码生成系统（MACGS）的设计和部署提供了可操作的见解，确立了因果分析作为理解和改进MACGS的强大方法。

Abstract: Despite the remarkable success that Multi-Agent Code Generation Systems (MACGS) have achieved, the inherent complexity of multi-agent architectures produces substantial volumes of intermediate outputs. To date, the individual importance of these intermediate outputs to the system correctness remains opaque, which impedes targeted optimization of MACGS designs. To address this challenge, we propose CAM, the first \textbf{C}ausality-based \textbf{A}nalysis framework for \textbf{M}ACGS that systematically quantifies the contribution of different intermediate features for system correctness. By comprehensively categorizing intermediate outputs and systematically simulating realistic errors on intermediate features, we identify the important features for system correctness and aggregate their importance rankings.
  We conduct extensive empirical analysis on the identified importance rankings. Our analysis reveals intriguing findings: first, we uncover context-dependent features\textemdash features whose importance emerges mainly through interactions with other features, revealing that quality assurance for MACGS should incorporate cross-feature consistency checks; second, we reveal that hybrid backend MACGS with different backend LLMs assigned according to their relative strength achieves up to 7.2\% Pass@1 improvement, underscoring hybrid architectures as a promising direction for future MACGS design. We further demonstrate CAM's practical utility through two applications: (1) failure repair which achieves a 73.3\% success rate by optimizing top-3 importance-ranked features and (2) feature pruning that reduces up to 66.8\% intermediate token consumption while maintaining generation performance. Our work provides actionable insights for MACGS design and deployment, establishing causality analysis as a powerful approach for understanding and improving MACGS.

</details>


### [455] [Agent-Based Software Artifact Evaluation](https://arxiv.org/abs/2602.02235)
*Zhaonan Wu,Yanjie Zhao,Zhenpeng Chen,Zheng Wang,Haoyu Wang*

Main category: cs.SE

TL;DR: ArtifactCopilot 自动化软件工程工件评估，匹配人工结果 85.42%，成本低且高效。


<details>
  <summary>Details</summary>
Motivation: 解决软件工程研究中工件评估的扩展性问题，减少人工评估的负担。

Method: 提出了 ArtifactCopilot，一个基于代理的端到端框架，结合执行规范化策略和工件评估图，自动化环境构建、指令执行和错误恢复。

Result: 在 48 个真实工件上评估，ArtifactCopilot 与人工评估结果匹配率达 85.42%，成本仅 \$0.091/工件，45/48 工件无需人工干预。

Conclusion: ArtifactCopilot 是一个高效的自动化工件评估框架，显著减少了人工干预的需求，同时保持了高准确性和低成本。

Abstract: Artifact evaluation has been adopted in the Software Engineering (SE) research community for 15 years, substantially improving research reproducibility across major SE conferences. However, this success has introduced a growing scalability challenge, as artifact evaluation relies heavily on reviewers' manual execution and debugging, leading to escalating human effort amid rapidly increasing paper submissions. To address this problem, we investigate automated artifact evaluation. We first conduct a preliminary study on artifacts from top-tier SE conferences and identify three key challenges: perceiving execution states, maintaining stable execution environments, and recovering from execution errors. Inspired by these findings, we propose ArtifactCopilot, the first end-to-end agent-based framework for automated artifact evaluation. ArtifactCopilot automates environment construction, instruction execution, and error recovery by combining an execution normalization strategy to ensure environment stability with an artifact evaluation graph that transforms README documents into dependency-aware command graphs, enabling structured execution planning, execution-state tracking, and error recovery. Evaluation on 48 real-world artifacts shows that ArtifactCopilot matches human artifact evaluation outcomes for 85.42% of the artifacts, outperforming Claude Code by 52.09 percentage points, while costing only \$0.091 per artifact on average and requiring zero human intervention for 45 out of 48 artifacts.

</details>


### [456] [OmniCode: A Benchmark for Evaluating Software Engineering Agents](https://arxiv.org/abs/2602.02262)
*Atharv Sonwane,Eng-Shen Tu,Wei-Chung Lu,Claas Beger,Carter Larsen,Debjit Dhar,Rachel Chen,Ronit Pattanayak,Tuan Anh Dang,Guohao Chen,Gloria Geng,Kevin Ellis,Saikat Dutta*

Main category: cs.SE

TL;DR: OmniCode是一个新型软件工程基准测试，涵盖多样化任务类别，旨在全面评估LLM编码智能体的能力。


<details>
  <summary>Details</summary>
Motivation: 现有编码基准测试如HumanEval和SWE-Bench局限于狭窄任务范围，无法全面评估智能体在现实软件开发中的能力。

Method: 提出了OmniCode，一个包含更广泛和多样化任务类别的软件工程基准测试，涵盖三种编程语言和四个关键类别。

Result: OmniCode包含1794个任务，评估显示现有智能体在某些任务（如测试生成）和语言（如C++和Java）上表现不佳。

Conclusion: OmniCode旨在作为一个强大的基准测试工具，推动能够在软件开发不同方面表现优异的智能体发展。

Abstract: LLM-powered coding agents are redefining how real-world software is developed. To drive the research towards better coding agents, we require challenging benchmarks that can rigorously evaluate the ability of such agents to perform various software engineering tasks. However, popular coding benchmarks such as HumanEval and SWE-Bench focus on narrowly scoped tasks such as competition programming and patch generation. In reality, software engineers have to handle a broader set of tasks for real-world software development. To address this gap, we propose OmniCode, a novel software engineering benchmark that contains a broader and more diverse set of task categories beyond code or patch generation. Overall, OmniCode contains 1794 tasks spanning three programming languages (Python, Java, and C++) and four key categories: bug fixing, test generation, code review fixing, and style fixing. In contrast to prior software engineering benchmarks, the tasks in OmniCode are (1) manually validated to eliminate ill-defined problems, and (2) synthetically crafted or recently curated to avoid data leakage issues, presenting a new framework for synthetically generating diverse software tasks from limited real-world data. We evaluate OmniCode with popular agent frameworks such as SWE-Agent and show that while they may perform well on bug fixing for Python, they fall short on tasks such as Test Generation and in languages such as C++ and Java. For instance, SWE-Agent achieves a maximum of 20.9% with DeepSeek-V3.1 on Java Test Generation tasks. OmniCode aims to serve as a robust benchmark and spur the development of agents that can perform well across different aspects of software development. Code and data are available at https://github.com/seal-research/OmniCode.

</details>


### [457] [RACA: Representation-Aware Coverage Criteria for LLM Safety Testing](https://arxiv.org/abs/2602.02280)
*Zeming Wei,Zhixin Zhang,Chengcan Wu,Yihao Zhang,Xiaokun Luan,Meng Sun*

Main category: cs.SE

TL;DR: RACA是一套专为LLM安全测试设计的覆盖标准，通过表示工程降低维度并过滤无关信息，实验证明其在识别越狱提示和实际应用中优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 当前LLM的安全测试多依赖静态数据集，缺乏系统性标准来评估测试的质量和充分性，且现有覆盖标准难以直接适用于LLM。

Method: RACA通过表示工程聚焦于LLM中的安全关键概念，分为三个阶段：识别安全关键表示、计算概念激活分数、使用六个子标准评估覆盖结果。

Result: 实验验证了RACA在有效性、适用性和泛化性方面的优势，能成功识别高质量越狱提示，并在实际场景中展示应用价值。

Conclusion: RACA为评估大型语言模型（LLM）的安全性提供了一个新框架，为AI测试领域贡献了一项有价值的技术。

Abstract: Recent advancements in LLMs have led to significant breakthroughs in various AI applications. However, their sophisticated capabilities also introduce severe safety concerns, particularly the generation of harmful content through jailbreak attacks. Current safety testing for LLMs often relies on static datasets and lacks systematic criteria to evaluate the quality and adequacy of these tests. While coverage criteria have been effective for smaller neural networks, they are not directly applicable to LLMs due to scalability issues and differing objectives. To address these challenges, this paper introduces RACA, a novel set of coverage criteria specifically designed for LLM safety testing. RACA leverages representation engineering to focus on safety-critical concepts within LLMs, thereby reducing dimensionality and filtering out irrelevant information. The framework operates in three stages: first, it identifies safety-critical representations using a small, expert-curated calibration set of jailbreak prompts. Second, it calculates conceptual activation scores for a given test suite based on these representations. Finally, it computes coverage results using six sub-criteria that assess both individual and compositional safety concepts. We conduct comprehensive experiments to validate RACA's effectiveness, applicability, and generalization, where the results demonstrate that RACA successfully identifies high-quality jailbreak prompts and is superior to traditional neuron-level criteria. We also showcase its practical application in real-world scenarios, such as test set prioritization and attack prompt sampling. Furthermore, our findings confirm RACA's generalization to various scenarios and its robustness across various configurations. Overall, RACA provides a new framework for evaluating the safety of LLMs, contributing a valuable technique to the field of testing for AI.

</details>


### [458] [Before Autonomy Takes Control: Software Testing in Robotics](https://arxiv.org/abs/2602.02293)
*Nils Chur,Thiago Santos de Moura,Argentina Ortega,Sven Peldszus,Thorsten Berger,Nico Hochgeschwender,Yannic Noller*

Main category: cs.SE

TL;DR: 本文通过映射247篇机器人测试论文，总结了机器人软件测试的现状、挑战及开放性问题，为相关社区提供了基础认识。


<details>
  <summary>Details</summary>
Motivation: 机器人系统是复杂且安全关键的软件系统，由于需要与硬件紧密交互、处理环境不确定性、应对干扰并高度自主行动，其测试比传统软件更具挑战性。

Method: 考虑了247篇机器人测试论文，并将其映射到软件测试理论，通过一个示例说明了机器人软件测试的最新技术。

Result: 研究发现机器人软件测试的现状，并讨论了当前挑战，为社区提供了测试挑战的基础认识。

Conclusion: 本文通过映射研究总结了机器人软件测试的现状，并指出了当前面临的挑战和开放性问题，为机器人学和软件工程社区提供了测试挑战的基础认识。

Abstract: Robotic systems are complex and safety-critical software systems. As such, they need to be tested thoroughly. Unfortunately, robot software is intrinsically hard to test compared to traditional software, mainly since the software needs to closely interact with hardware, account for uncertainty in its operational environment, handle disturbances, and act highly autonomously. However, given the large space in which robots operate, anticipating possible failures when designing tests is challenging. This paper presents a mapping study by considering robotics testing papers and relating them to the software testing theory. We consider 247 robotics testing papers and map them to software testing, discussing the state-of-the-art software testing in robotics with an illustrated example, and discuss current challenges. Forming the basis to introduce both the robotics and software engineering communities to software testing challenges. Finally, we identify open questions and lessons learned.

</details>


### [459] [Understanding and Detecting Flaky Builds in GitHub Actions](https://arxiv.org/abs/2602.02307)
*Wenhao Ge,Chen Zhang*

Main category: cs.SE

TL;DR: 研究发现GitHub Actions中3.2%的构建被重新运行，其中67.73%为不稳定构建。通过机器学习方法，检测性能提升了20.3%。


<details>
  <summary>Details</summary>
Motivation: CI构建结果的不稳定性（即“不稳定构建”）会削弱开发者对CI的信任、浪费计算资源，并威胁CI相关实证研究的有效性。

Method: 基于1,960个开源Java项目的重新运行数据，进行了大规模实证研究，并通过深入失败分析识别了15类不稳定失败。随后提出了一种基于机器学习的检测方法。

Result: 研究发现3.2%的构建被重新运行，其中67.73%表现出不稳定行为，影响了51.28%的项目。机器学习方法将F1分数提高了20.3%。

Conclusion: 该研究揭示了GitHub Actions中不稳定构建的普遍性及其主要原因，并提出了一种基于机器学习的检测方法，显著提高了检测性能。

Abstract: Continuous Integration (CI) is widely used to provide rapid feedback on code changes; however, CI build outcomes are not always reliable. Builds may fail intermittently due to non-deterministic factors, leading to flaky builds that undermine developers' trust in CI, waste computational resources, and threaten the validity of CI-related empirical studies. In this paper, we present a large-scale empirical study of flaky builds in GitHub Actions based on rerun data from 1,960 open-source Java projects. Our results show that 3.2% of builds are rerun, and 67.73% of these rerun builds exhibit flaky behavior, affecting 1,055 (51.28%) of the projects. Through an in-depth failure analysis, we identify 15 distinct categories of flaky failures, among which flaky tests, network issues, and dependency resolution issues are the most prevalent. Building on these findings, we propose a machine learning-based approach for detecting flaky failures at the job level. Compared with a state-of-the-art baseline, our approach improves the F1-score by up to 20.3%.

</details>


### [460] [A Task-Level Evaluation of AI Agents in Open-Source Projects](https://arxiv.org/abs/2602.02345)
*Shojibur Rahman,Md Fazle Rabbi,Minhaz Zibran*

Main category: cs.SE

TL;DR: 对比五种AI编码代理在PR生命周期中的表现，发现Codex接受率高，Copilot讨论多，Claude和Cursor提交质量好。


<details>
  <summary>Details</summary>
Motivation: 比较不同AI代理在协作软件工程中的表现，以指导其选择和改进。

Method: 使用AIDev-pop公共数据集，对五种自主编码代理进行对比研究，评估其在PR生命周期中的三个任务感知维度：PR接受率、评审讨论量和提交消息质量。

Result: Codex在大多数任务类别中PR接受率最高，Copilot的PR引发最多评审讨论，Claude和Cursor在提交消息质量上表现较好，而Codex的提交质量相对较低。

Conclusion: 研究结果为选择和改进AI代理以有效集成到协作软件工程中提供了信息。

Abstract: In this paper, we present a comparative study of five autonomous coding agents using AIDev-pop, which is a public dataset containing thousands of AI-generated pull requests (PRs) across popular open-source repositories. We evaluate agents' performance along three task-aware dimensions spanning the PR lifecycle: (1) PR acceptance rate, (2) review discussion volume, and (3) commit message quality. Our quantitative analysis finds that Codex consistently achieves high PR acceptance rates across most task categories, while Copilot's PRs trigger the highest volume of both human and automated review discussions. In contrast, commit-level quality varies independently of acceptance outcomes. Claude and Cursor produce higher proportions of high-quality commit messages across several task types, and Codex exhibiting comparatively lower commit quality despite strong integration outcomes. Our findings inform selection and improvements of AI agents for their effective integration to collaborative software engineering.

</details>


### [461] [SWE-Universe: Scale Real-World Verifiable Environments to Millions](https://arxiv.org/abs/2602.02361)
*Mouxiang Chen,Lei Zhang,Yunlong Feng,Xuwu Wang,Wenting Zhao,Ruisheng Cao,Jiaxi Yang,Jiawei Chen,Mingze Li,Zeyao Ma,Hao Ge,Zongmeng Zhang,Zeyu Cui,Dayiheng Liu,Jingren Zhou,Jianling Sun,Junyang Lin,Binyuan Hui*

Main category: cs.SE

TL;DR: SWE-Universe是一个高效框架，通过定制模型和自验证技术，从GitHub PRs构建百万级真实SWE环境，显著提升编码代理性能。


<details>
  <summary>Details</summary>
Motivation: 解决自动构建中的普遍挑战，如低生产效率、弱验证器和过高成本。

Method: 利用由高效定制训练模型驱动的构建代理，采用迭代自验证和循环内黑客检测，确保高保真可验证任务的可靠生成。

Result: 将真实世界多语言SWE环境扩展到百万规模（807,693），并在Qwen3-Max-Thinking上应用，获得SWE-Bench Verified 75.3%的分数。

Conclusion: SWE-Universe提供了一个关键资源和强大方法，推动下一代编码代理的发展。

Abstract: We propose SWE-Universe, a scalable and efficient framework for automatically constructing real-world software engineering (SWE) verifiable environments from GitHub pull requests (PRs). To overcome the prevalent challenges of automatic building, such as low production yield, weak verifiers, and prohibitive cost, our framework utilizes a building agent powered by an efficient custom-trained model. This agent employs iterative self-verification and in-loop hacking detection to ensure the reliable generation of high-fidelity, verifiable tasks. Using this method, we scale the number of real-world multilingual SWE environments to a million scale (807,693). We demonstrate the profound value of our environments through large-scale agentic mid-training and reinforcement learning. Finally, we applied this technique to Qwen3-Max-Thinking and achieved a score of 75.3% on SWE-Bench Verified. Our work provides both a critical resource and a robust methodology to advance the next generation of coding agents.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [462] [Asynchronous MultiAgent Reinforcement Learning for 5G Routing under Side Constraints](https://arxiv.org/abs/2602.00035)
*Sebastian Racedo,Brigitte Jaumard,Oscar Delgado,Meysam Masoudi*

Main category: cs.NI

TL;DR: AMARL框架通过异步多智能体强化学习解决了5G网络中异构流量的实时路由问题，具有可扩展性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 当前5G及未来系统中的网络承载着具有多样化服务质量约束的异构流量，使得实时路由决策既复杂又时间紧迫。现有方法在可扩展性和滞后效应方面存在不足。

Method: 提出了一种异步多智能体强化学习（AMARL）框架，其中每个服务有一个独立的PPO智能体并行规划路由，并将资源增量提交到共享的全局资源环境中。

Result: 在O-RAN类网络模拟中使用蒙特利尔的近实时流量数据进行评估，AMARL在服务等级（接受率）和端到端延迟方面与单智能体PPO基线相当，同时减少了训练时间并提高了对需求变化的鲁棒性。

Conclusion: AMARL框架通过异步、服务专用的智能体为分布式路由提供了可扩展且实用的解决方案，其适用性不仅限于O-RAN领域。

Abstract: Networks in the current 5G and beyond systems increasingly carry heterogeneous traffic with diverse quality-of-service constraints, making real-time routing decisions both complex and time-critical. A common approach, such as a heuristic with human intervention or training a single centralized RL policy or synchronizing updates across multiple learners, struggles with scalability and straggler effects. We address this by proposing an asynchronous multi-agent reinforcement learning (AMARL) framework in which independent PPO agents, one per service, plan routes in parallel and commit resource deltas to a shared global resource environment. This coordination by state preserves feasibility across services and enables specialization for service-specific objectives. We evaluate the method on an O-RAN like network simulation using nearly real-time traffic data from the city of Montreal. We compared against a single-agent PPO baseline. AMARL achieves a similar Grade of Service (acceptance rate) (GoS) and end-to-end latency, with reduced training wall-clock time and improved robustness to demand shifts. These results suggest that asynchronous, service-specialized agents provide a scalable and practical approach to distributed routing, with applicability extending beyond the O-RAN domain.

</details>


### [463] [NetWorld: Communication-Based Diffusion World Model for Multi-Agent Reinforcement Learning in Wireless Networks](https://arxiv.org/abs/2602.00558)
*Kechen Meng,Rongpeng Li,Yansha Deng,Zhifeng Zhao,Honggang Zhang*

Main category: cs.NI

TL;DR: NetWorld是一个基于扩散模型的通信世界模型，通过两阶段框架和轻量级通信机制，实现无线网络中异构MARL任务的少样本泛化，表现出色。


<details>
  <summary>Details</summary>
Motivation: 无线通信网络的规模和复杂性增加，使得多样化的资源分配任务变得关键。MARL在分布式控制中虽有潜力，但需要昂贵的现实交互且缺乏跨任务泛化能力。扩散模型（DMs）在建模复杂动态和支持高保真仿真方面表现出色。

Method: 采用分布式训练与分散执行（DTDE）范式，分为预训练条件扩散世界模型和在模型内进行轨迹规划两个阶段。

Result: 在三个代表性任务上的实验表明，NetWorld在性能和样本效率上优于MARL基线。

Conclusion: NetWorld通过两阶段框架和轻量级通信机制，在无线网络优化中展现出强大的可扩展性和实际潜力。

Abstract: As wireless communication networks grow in scale and complexity, diverse resource allocation tasks become increasingly critical. Multi-Agent Reinforcement Learning (MARL) provides a promising solution for distributed control, yet it often requires costly real-world interactions and lacks generalization across diverse tasks. Meanwhile, recent advances in Diffusion Models (DMs) have demonstrated strong capabilities in modeling complex dynamics and supporting high-fidelity simulation. Motivated by these challenges and opportunities, we propose a Communication-based Diffusion World Model (NetWorld) to enable few-shot generalization across heterogeneous MARL tasks in wireless networks. To improve applicability to large-scale distributed networks, NetWorld adopts the Distributed Training with Decentralized Execution (DTDE) paradigm and is organized into a two-stage framework: (i) pre-training a classifier-guided conditional diffusion world model on multi-task offline datasets, and (ii) performing trajectory planning entirely within this world model to avoid additional online interaction. Cross-task heterogeneity is handled via shared latent processing for observations, two-hot discretization for task-specific actions and rewards, and an inverse dynamics model for action recovery. We further introduce a lightweight Mean Field (MF) communication mechanism to reduce non-stationarity and promote coordinated behaviors with low overhead. Experiments on three representative tasks demonstrate improved performance and sample efficiency over MARL baselines, indicating strong scalability and practical potential for wireless network optimization.

</details>


### [464] [The Syntactic-Semantic Internet:Engineering Infrastructures for Autonomous Systems](https://arxiv.org/abs/2602.00818)
*Mallik Tatipamula,Xuesong Liu,Yao Sun,Muhammad Ali Imran*

Main category: cs.NI

TL;DR: 论文提出语义层作为互联网的新架构层，以解决当前网络在理解和交换意义方面的不足，支持智能代理的互操作性和可解释行为。


<details>
  <summary>Details</summary>
Motivation: 随着自主、基于学习的系统在网络控制、计算和决策中的广泛应用，互联网缺乏表示和交换意义的结构基础，这限制了系统的智能行为和互操作性。

Method: 通过引入语义层的概念，构建了一个语法-语义互联网，其中语法栈负责传输比特、数据包和工作负载，而语义栈则传输意义、基础和后果。

Result: 论文展示了语义层的架构，包括语义通信、语义基底和新兴的代理网络，并与TCP/IP和万维网进行了明确的架构对比。

Conclusion: 论文提出了一种新的网络架构层——语义层，旨在解决当前互联网在表示和交换意义方面的不足，为下一代网络系统提供理解和解释意图、上下文及后果的能力。

Abstract: The Internet has evolved through successive architectural abstractions that enabled unprecedented scale, interoperability, and innovation. Packet-based networking enabled the reliable transport of bits; cloud-native systems enabled the orchestration of distributed computation. Today, the emergence of autonomous, learning-based systems introduces a new architectural challenge: intelligence is increasingly embedded directly into network control, computation, and decision-making, yet the Internet lacks a structural foundation for representing and exchanging meaning. In this paper, we argue that cognition alone: pattern recognition, prediction, and optimization, is insufficient for the next generation of networked systems. As autonomous agents act across safety-critical and socio-technical domains, systems must not only compute and communicate, but also comprehend intent, context, and consequence. We introduce the concept of a Semantic Layer: a new architectural stratum that treats meaning as a first-class construct, enabling interpretive alignment, semantic accountability, and intelligible autonomous behavior. We show that this evolution leads naturally to a Syntactic-Semantic Internet. The syntactic stack continues to transport bits, packets, and workloads with speed and reliability, while a parallel semantic stack transports meaning, grounding, and consequence. We describe the structure of this semantic stack-semantic communication, a semantic substrate, and an emerging Agentic Web, and draw explicit architectural parallels to TCP/IP and the World Wide Web. Finally, we examine current industry efforts, identify critical architectural gaps, and outline the engineering challenges required to make semantic interoperability a global, interoperable infrastructure.

</details>


### [465] [LMTE: Putting the "Reasoning" into WAN Traffic Engineering with Language Models](https://arxiv.org/abs/2602.00941)
*Xinyu Yuan,Yan Qiao,Zonghui Wang,Meng Li,Wenzhi Chen*

Main category: cs.NI

TL;DR: 本文首次探索预训练语言模型作为通用流量规划器的潜力，提出LMTE框架，显著提升流量工程的性能和速度。


<details>
  <summary>Details</summary>
Motivation: 传统流量工程优化方法在表达性和泛化能力上不足，无法适应未见过的流量模式或拓扑结构，而预训练语言模型在模拟决策过程和并行推理方面表现出潜力。

Method: 提出LMTE框架，利用预训练语言模型的并行推理能力，通过多模态对齐和轻量级配置生成优化流量工程。

Result: 在五个数据集上，LMTE框架达到了顶级性能，最大链路利用率（MLU）提升15%，性能下降低于5%，且比传统TE求解器快10到100倍。

Conclusion: 本文展示了预训练语言模型（LMs）作为通用流量规划器的潜力，通过LMTE框架实现了高效的多模态对齐和轻量级配置生成，显著提升了流量工程（TE）的性能和速度。

Abstract: The rapid expansion of modern wide-area networks (WANs) has made traffic engineering (TE) increasingly challenging, as traditional solvers struggle to keep pace. Although existing offline ML-driven approaches accelerate TE optimization with deep neural networks (DNNs), they often lack sufficient expressiveness and generalization on unseen traffic patterns or topologies, limiting their practicality. Inspired by the success of large language models (LMs), for the first time, this paper investigates their potential as general-purpose traffic planners. Our contributions are two-fold: (i) Theoretically, we show that pre-trained LMs can simulate the sequential decision processes underlying TE and, crucially, exhibit parallel reasoning capabilities, making them well-suited for the task; (ii) Practically, we present LMTE, a novel LM-driven TE framework that embraces these insights through efficient multimodal alignment and lightweight configuration generation, all while preserving the model's original abilities. Extensive experiments demonstrate that fold matches top-tier performance on five datasets, achieving up to 15\% better maximum link utilization (MLU) and consistently lower performance degradation across diverse scenarios, e.g., less than 5\% with high traffic dynamics and link failures. Moreover, it achieves 10 to 100 times speedups over traditional TE solvers. To aid future works, our codebase is available at https://github.com/Y-debug-sys/LMTE.

</details>


### [466] [Resilience Optimization in 6G and Beyond Integrated Satellite-Terrestrial Networks: A Deep Reinforcement Learning Approach](https://arxiv.org/abs/2602.01102)
*Dinh-Hieu Tran,Nguyen Van Huynh,Van Nhan Vo,Madyan Alsenwi,Eva Lagunas,Symeon Chatzinotas*

Main category: cs.NI

TL;DR: 本文提出了一种利用LEO卫星增强网络韧性的DQN优化框架，通过智能资源分配在基站中断时维持服务，仿真验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 确保6G及以后网络的韧性，以在基站因故障、灾害、攻击或节能操作而中断时维持服务连续性。

Method: 开发了一个多小区模型，结合用户关联、天线俯仰角调整、功率控制、异构流量需求和动态用户分布，并设计了基于DQN的算法来解决非凸NP难问题。

Result: 仿真结果表明，该方法在最大化用户总速率和最小化LEO卫星使用方面显著优于基准方法。

Conclusion: 本文提出的基于DQN的优化框架显著提升了综合卫星-地面网络的韧性，在基站不可用时有效利用LEO卫星资源，同时通过最小化卫星使用延长其寿命。

Abstract: Ensuring network resilience in 6G and beyond is essential to maintain service continuity during base station (BS) outages due to failures, disasters, attacks, or energy-saving operations. This paper proposes a novel resilience optimization framework for integrated satellite-terrestrial networks (ISTNs), leveraging low Earth orbit (LEO) satellites to assist users when terrestrial BSs are unavailable. Specifically, we develop a realistic multi-cell model incorporating user association, antenna downtilt adaptation, power control, heterogeneous traffic demands, and dynamic user distribution. The objective is to maximize of the total user rate in the considered area by optimizing the BS's antenna tilt, transmission power, user association to neighboring BS or to a LEO satellite with a minimum number of successfully served user satisfaction constraint, defined by rate and Reference Signal Received Power (RSRP) requirements. To solve the non-convex, NP-hard problem, we design a deep Q-network (DQN)-based algorithm to learn network dynamics to maximize throughput while minimizing LEO satellite usage, thereby limiting reliance on links with longer propagation delays and prolonging satellite operational lifetime. Simulation results confirm that our approach significantly outperforms the benchmark one.

</details>


### [467] [Energy-efficient Software-defined 5G/6G Multimedia IoV: PID controller-based approach](https://arxiv.org/abs/2602.01180)
*Ahmadreza Montazerolghaem*

Main category: cs.NI

TL;DR: 提出了一种基于PID控制器的能效框架，用于5G/6G车联网中的多媒体资源管理，显著提升负载均衡和能源效率。


<details>
  <summary>Details</summary>
Motivation: 智能城市和车联网中多媒体应用的快速增长对现有网络基础设施提出了可扩展性、适应性和能源效率的挑战。

Method: 结合SDN和NFV技术，利用PID控制器动态管理负载分布和温度，实现集中化和自适应的网络资源控制。

Result: 仿真验证显示，该框架在重负载条件下能减少高达30%的能耗，实现近乎均衡的负载分布，并在极端流量需求下有效响应98%以上的车辆请求。

Conclusion: 本研究提出了一种基于PID控制器的创新性能效框架，用于5G/6G IoV网络中的多媒体资源管理，显著提升了负载均衡、CPU利用率和能源效率。

Abstract: The rapid proliferation of multimedia applications in smart city environments and the Internet of Vehicles (IoV) presents significant challenges for existing network infrastructures, particularly with the advent of 5G and emerging 6G technologies. Traditional architectures struggle to meet the demands for scalability, adaptability, and energy efficiency required by data-intensive multimedia services. To address these challenges, this study proposes an innovative, energy-efficient framework for multimedia resource management in software-defined 5G/6G IoV networks, leveraging a Proportional-Integral-Derivative (PID) controller. The framework integrates Software-Defined Networking (SDN) and Network Functions Virtualization (NFV) technologies to enable centralized and adaptive control over network resources. By employing a PID controller, it dynamically manages load distribution and temperature, ensuring balanced resource allocation and minimizing energy waste. Comprehensive simulations validate the framework's effectiveness, demonstrating significant improvements in load balancing, CPU utilization, and energy consumption compared to traditional methods. For instance, under heavy traffic conditions, the proposed framework maintained resource efficiency, reducing power consumption by up to 30% and achieving nearly equal load distribution across all network components. Additionally, the controller exhibited exceptional scalability, effectively responding to over 98% of vehicle requests even in scenarios of extreme traffic demand.

</details>


### [468] [AOASS: Adaptive Obstacle-Aware Square Spiral Framework for Single-mobile Anchor-Based WSN Localization](https://arxiv.org/abs/2602.01290)
*Abdelhady Naguib*

Main category: cs.NI

TL;DR: AOASS是一种新型单移动锚框架，结合方形螺旋移动和自适应障碍检测，通过OLSTM DV Hop和TD3 LSTM强化学习提高定位精度和能量效率，适用于WSN。


<details>
  <summary>Details</summary>
Motivation: 无线传感器网络中的定位在信号传播受障碍物影响时仍面临挑战，需要高精度、能量效率且能适应障碍物的解决方案。

Method: AOASS框架结合了优化的方形螺旋移动模式、自适应障碍检测、OLSTM DV Hop模型（LSTM网络与DV Hop算法结合）、TD3 LSTM强化学习代理、卡尔曼预测层和模糊逻辑ORCA安全模块。

Result: 模拟实验表明，AOASS在不同障碍物密度下均实现了更高的定位精度、更好的能量效率和更优化的轨迹，优于现有方法。

Conclusion: AOASS框架通过结合优化的方形螺旋移动模式和自适应障碍检测，展示了在无线传感器网络中实现高定位精度和能量效率的潜力，适用于现实世界的物联网系统。

Abstract: Accurate and energy efficient localization remains a key challenge in Wireless Sensor Networks (WSNs), particularly when obstacles affect signal propagation. This study introduces AOASS (Adaptive Obstacle Aware Square Spiral), a new single mobile anchor framework that combines an optimized square spiral movement pattern with adaptive obstacle detection. The mobile anchor can sense and bypass obstacles while maintaining high localization accuracy and full network coverage, ensuring that each node receives at least three noncollinear beacon signals for reliable position estimation. Localization accuracy is further improved using the OLSTM DV Hop model, which integrates a Long Short Term Memory (LSTM) network with the traditional DV Hop algorithm to estimate hop distances better and reduce multi hop errors. The anchor trajectory is managed by a TD3 LSTM reinforcement learning agent, supported by a Kalman based prediction layer and a fuzzy logic ORCA safety module for smooth and collision free navigation. Simulation experiments across different obstacle densities show that AOASS consistently achieves higher localization accuracy, better energy efficiency, and more optimized trajectories than existing approaches. These results demonstrate the framework scalability and potential for real world WSN applications, offering an intelligent and adaptable solution for data driven IoT systems.

</details>


### [469] [Federated Learning Meets Random Access: Energy-Efficient Uplink Resource Allocation](https://arxiv.org/abs/2602.01913)
*Giovanni Perin,Eunjeong Jeong,Nikolaos Pappas*

Main category: cs.NI

TL;DR: 论文研究了FL和RA设备在同一带宽上的资源分配问题，通过优化算法发现ALOHA在FL主导时能耗更低，时隙ALOHA在RA主导时更高效。


<details>
  <summary>Details</summary>
Motivation: 随着机器学习模型训练数据量的激增，无线网络资源需合理分配以支持标准应用。论文旨在解决FL和RA设备在同一带宽上的资源分配问题。

Method: 论文通过推导接近最优的解来解决非凸问题，优化了FL延迟和RA吞吐量约束下的系统能耗。

Result: 研究结果显示，不同协议在不同流量主导情况下能耗表现各异，ALOHA在FL主导时更优，时隙ALOHA在RA主导时更高效。

Conclusion: 论文得出结论，ALOHA协议在FL流量主导时能显著降低系统能耗（最高48%），而时隙ALOHA在RA流量主导时更高效（能耗降低6%）。

Abstract: Artificial intelligence-generated traffic is changing the shape of wireless networks. Specifically, as the amount of data generated to train machine learning models is massive, network resources must be carefully allocated to continue supporting standard applications. In this paper, we tackle the problem of allocating radio resources for two sets of concurrent devices communicating in uplink with a gateway over the same bandwidth. A set of devices performs federated learning (FL), and accesses the medium in FDMA, uploading periodically large models. The other set is throughput-oriented and accesses the medium via random access (RA), either with ALOHA or slotted-ALOHA protocols. We derive close-to-optimal solutions to the non-convex problem of minimizing the system energy consumption subject to FL latency and RA throughput constraints. Our solutions show that ALOHA can sustain high FL efficiency, yielding up to 48% lower consumption when the system is dominated by FL traffic. On the other hand, slotted-ALOHA becomes more efficient when RA traffic dominates, yielding 6% lower consumption.

</details>


### [470] [TriCloudEdge: A multi-layer Cloud Continuum](https://arxiv.org/abs/2602.02121)
*George Violettas,Lefteris Mamatas*

Main category: cs.NI

TL;DR: TriCloudEdge是一个三层云连续体架构，整合远边缘、中间边缘和云端，通过多协议和并行处理优化延迟和隐私问题，实验验证了其资源分配和通信效率的平衡。


<details>
  <summary>Details</summary>
Motivation: 为了解决云计算连续体中的延迟、隐私和资源分配问题，TriCloudEdge旨在提供一个统一的解决方案，通过分层架构和并行处理优化性能。

Method: TriCloudEdge采用多协议和技术（如WebSocket、MQTT、HTTP）与通用协议（Zenoh）进行对比，实现跨层多样双向数据传输。通过并行处理，支持远边缘的轻量级AI任务、中间边缘的本地智能以及云端的大规模分析和联邦学习。

Result: 实验结果表明，TriCloudEdge能够有效分配计算任务，平衡资源利用和通信效率，同时支持远边缘的AI模型适应和并行计算挑战。

Conclusion: TriCloudEdge提出了一种可扩展的三层云连续体架构，有效整合了远边缘设备、中间边缘节点和中央云服务，通过并行工作实现统一解决方案。该架构在资源利用和通信效率之间取得了平衡，并能够应对延迟和隐私问题。

Abstract: TriCloudEdge is a scalable three-tier cloud continuum that integrates far-edge devices, intermediate edge nodes, and central cloud services, working in parallel as a unified solution. At the far edge, ultra-low-cost microcontrollers can handle lightweight AI tasks, while intermediate edge devices provide local intelligence, and the cloud tier offers large-scale analytics, federated learning, model adaptation, and global identity management. The proposed architecture enables multi-protocols and technologies (WebSocket, MQTT, HTTP) compared to a versatile protocol (Zenoh) to transfer diverse bidirectional data across the tiers, offering a balance between computational challenges and latency requirements. Comparative implementations between these two architectures demonstrate the trade-offs between resource utilization and communication efficiency. The results show that TriCloudEdge can distribute computational challenges to address latency and privacy concerns. The work also presents tests of AI model adaptation on the far edge and the computational effort challenges under the prism of parallelism. This work offers a perspective on the practical continuum challenges of implementation aligned with recent research advances addressing challenges across the different cloud levels.

</details>


### [471] [Evaluating Acoustic Data Transmission Schemes for Ad-Hoc Communication Between Nearby Smart Devices](https://arxiv.org/abs/2602.02249)
*Florentin Putz,Philipp Fortmann,Jan Frank,Christoph Haugwitz,Mario Kupnik,Matthias Hollick*

Main category: cs.NI

TL;DR: 研究评估了声学数据传输方案的可靠性，发现现有方案在实际环境中表现不佳，并呼吁更严格的测试和设计策略。


<details>
  <summary>Details</summary>
Motivation: 声学数据传输为智能手机和物联网设备提供了一种替代蓝牙和NFC的方案，但现有研究多依赖仿真或有限的设备测试，难以评估其实际可靠性。

Method: 系统性地回顾了31项声学通信研究，重新实现了三种有前景的方案，并建立了一个包含八种代表性声学通信系统的测试平台。

Result: 研究发现许多现有方案在实际使用中面临挑战，主要由于室内严重的多径传播和设备模型间音频特性的差异。

Conclusion: 研究强调了严格的设备测试的重要性，并指出了需要稳健的设计策略来缩小仿真结果与可靠物联网部署之间的差距。

Abstract: Acoustic data transmission offers a compelling alternative to Bluetooth and NFC by leveraging the ubiquitous speakers and microphones in smartphones and IoT devices. However, most research in this field relies on simulations or limited on-device testing, which makes the real-world reliability of proposed schemes difficult to assess. We systematically reviewed 31 acoustic communication studies for commodity devices and found that none provided accessible source code. After contacting authors and re-implementing three promising schemes, we assembled a testbed of eight representative acoustic communication systems. Using over 11000 smartphone transmissions in both realistic indoor environments and an anechoic chamber, we provide a systematic and repeatable methodology for evaluating the reliability and generalizability of these schemes under real-world conditions. Our results show that many existing schemes face challenges in practical usage, largely due to severe multipath propagation indoors and varying audio characteristics across device models. To support future research and foster more robust evaluations, we release our re-implementations alongside the first comprehensive dataset of real-world acoustic transmissions. Overall, our findings highlight the importance of rigorous on-device testing and underscore the need for robust design strategies to bridge the gap between simulation results and reliable IoT deployments.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [472] [What Artificial Intelligence can do for High-Performance Computing systems?](https://arxiv.org/abs/2602.00014)
*Pierrick Pochelu,Hyacinthe Cartiaux,Julien Schleich*

Main category: cs.DC

TL;DR: AI（尤其是机器学习和优化）能有效提升HPC系统效率，调度和性能优化是主要应用方向，未来需关注LLM集成和MLOps改进。


<details>
  <summary>Details</summary>
Motivation: HPC中心的高能耗带来了环境和运营成本问题，研究旨在探讨AI（包括机器学习和优化技术）如何提升HPC系统的运营效率。

Method: 通过手动筛选2019至2025年间约1,800篇文献，并依据预设的纳入/排除标准，最终保留了74篇关于“AI for HPC”的论文，将其分为六个应用领域进行分析。

Result: 研究发现调度是AI在HPC中最活跃的应用领域，其次是性能估计、优化、代理建模、故障检测和基于语言模型的自动化。图神经网络和时间序列模型在异常检测中表现出色，而领域专用语言模型在特定任务上优于通用LLM。

Conclusion: AI在HPC领域的应用展示了显著的效率提升潜力，尤其是在调度、性能优化和故障检测等方面。未来的研究方向包括LLM与操作系统的集成、MLOps的改进以及AI组件的标准化和基准测试方法的完善。

Abstract: High-performance computing (HPC) centers consume substantial power, incurring environmental and operational costs. This review assesses how artificial intelligence (AI), including machine learning (ML) and optimization, improves the efficiency of operational HPC systems. Approximately 1,800 publications from 2019 to 2025 were manually screened using predefined inclusion/exclusion criteria; 74 "AI for HPC" papers were retained and grouped into six application areas: performance estimation, performance optimization, scheduling, surrogate modeling, fault detection, and language-model-based automation.
  Scheduling is the most active area, spanning research-oriented reinforcement-learning schedulers to production-friendly hybrids that combine ML with heuristics. Supervised performance estimation is foundational for both scheduling and optimization. Graph neural networks and time-series models strengthen anomaly detection by capturing spatio-temporal dependencies in production telemetry. Domain-specialized language models for HPC can outperform general-purpose LLMs on targeted coding and automation tasks. Together, these findings highlight integration opportunities such as LLM-based operating-system concepts and underscore the need for advances in MLOps, standardization of AI components, and benchmarking methodology.

</details>


### [473] [A Fault-Tolerant Version of Safra's Termination Detection Algorithm](https://arxiv.org/abs/2602.00272)
*Wan Fokkink,Georgios Karlos,Andy Tatman*

Main category: cs.DC

TL;DR: 改进Safra算法，通过分散式处理和备份令牌实现容错，支持任意崩溃且无额外开销。


<details>
  <summary>Details</summary>
Motivation: 经典Safra算法缺乏容错能力，无法应对分布式网络中节点崩溃的情况，因此需要改进以提升鲁棒性。

Method: 将计数器按节点拆分以忽略崩溃节点的计数，本地恢复令牌环并发送备份令牌，节点通过令牌互相通知崩溃情况。

Result: 改进后的算法在保持原算法效率的同时，实现了对任意数量及同时崩溃的容错，且无需额外消息开销。

Conclusion: 论文提出了一种对Safra分布式终止检测算法的容错改进，通过分散式处理节点崩溃，无需额外消息开销，且能容忍任意数量的同时崩溃。

Abstract: Safra's distributed termination detection algorithm employs a logical token ring structure within a distributed network; only passive nodes forward the token, and a counter in the token keeps track of the number of sent minus the number of received messages. We adapt this classic algorithm to make it fault-tolerant. The counter is split into counters per node, to discard counts from crashed nodes. If a node crashes, the token ring is restored locally and a backup token is sent. Nodes inform each other of detected crashes via the token. Our algorithm imposes no additional message overhead, tolerates any number of crashes as well as simultaneous crashes, and copes with crashes in a decentralized fashion. Correctness proofs are provided of both the original Safra's algorithm and its fault-tolerant variant, as well as a model checking analysis.

</details>


### [474] [Training LLMs with Fault Tolerant HSDP on 100,000 GPUs](https://arxiv.org/abs/2602.00277)
*Omkar Salpekar,Rohan Varma,Kenny Yu,Vladimir Ivanov,Yang Wang,Ahmed Sharif,Min Si,Shawn Xu,Feng Tian,Shengbao Zheng,Tristan Rice,Ankush Garg,Shangfu Peng,Shreyas Siravara,Wenyin Fu,Rodrigo de Castro,Adithya Gangidi,Andrey Obraztsov,Sharan Narang,Sergey Edunov,Maxim Naumov,Chunqiang Tang,Mathew Oldham*

Main category: cs.DC

TL;DR: FT-HSDP是一种新型容错训练范式，通过FTAR和非阻塞协议显著提升大规模GPU训练效率，恢复时间缩短至3分钟，训练效率达80%。


<details>
  <summary>Details</summary>
Motivation: 同步训练在大规模GPU集群中因频繁故障和长恢复时间导致效率低下，需要一种更高效的训练范式。

Method: FT-HSDP结合了容错All Reduce协议（FTAR）和非阻塞追赶协议，以数据并行副本为容错单元，实现故障时的快速恢复。

Result: FT-HSDP将故障恢复时间从10分钟缩短至3分钟，有效训练时间从44%提升至80%，且模型精度无显著下降。

Conclusion: FT-HSDP通过引入容错机制和非阻塞追赶协议，显著提高了大规模GPU训练的效率，同时不影响模型精度。

Abstract: Large-scale training systems typically use synchronous training, requiring all GPUs to be healthy simultaneously. In our experience training on O(100K) GPUs, synchronous training results in a low efficiency due to frequent failures and long recovery time.
  To address this problem, we propose a novel training paradigm, Fault Tolerant Hybrid-Shared Data Parallelism (FT-HSDP). FT-HSDP uses data parallel replicas as units of fault tolerance. When failures occur, only a single data-parallel replica containing the failed GPU or server is taken offline and restarted, while the other replicas continue training. To realize this idea at scale, FT-HSDP incorporates several techniques: 1) We introduce a Fault Tolerant All Reduce (FTAR) protocol for gradient exchange across data parallel replicas. FTAR relies on the CPU to drive the complex control logic for tasks like adding or removing participants dynamically, and relies on GPU to perform data transfer for best performance. 2) We introduce a non-blocking catch-up protocol, allowing a recovering replica to join training with minimal stall.
  Compared with fully synchronous training at O(100K) GPUs, FT-HSDP can reduce the stall time due to failure recovery from 10 minutes to 3 minutes, increasing effective training time from 44\% to 80\%. We further demonstrate that FT-HSDP's asynchronous recovery does not bring any meaning degradation to the accuracy of the result model.

</details>


### [475] [Standardized Methods and Recommendations for Green Federated Learning](https://arxiv.org/abs/2602.00343)
*Austin Tapp,Holger R. Roth,Ziyue Xu,Abhijeet Parida,Hareem Nisar,Marius George Linguraru*

Main category: cs.DC

TL;DR: 提出联邦学习的标准化碳核算方法，验证了系统延迟和硬件差异对碳排放的影响。


<details>
  <summary>Details</summary>
Motivation: 联邦学习的环境影响因测量边界不一致和报告异构而难以比较，需要统一的碳核算方法。

Method: 采用NVIDIA NVFlare和CodeCarbon进行FL CO2e跟踪，包括初始化、每轮训练、评估和空闲/协调等阶段，并估计通信排放。

Result: 在CIFAR-10和视网膜分割任务中验证了方法的有效性，展示了系统级延迟和协调效应对碳足迹的显著影响。

Conclusion: 本文提出了一种标准化的碳核算方法，为可重复的‘绿色’联邦学习评估奠定了基础。

Abstract: Federated learning (FL) enables collaborative model training over privacy-sensitive, distributed data, but its environmental impact is difficult to compare across studies due to inconsistent measurement boundaries and heterogeneous reporting. We present a practical carbon-accounting methodology for FL CO2e tracking using NVIDIA NVFlare and CodeCarbon for explicit, phase-aware tasks (initialization, per-round training, evaluation, and idle/coordination). To capture non-compute effects, we additionally estimate communication emissions from transmitted model-update sizes under a network-configurable energy model. We validate the proposed approach on two representative workloads: CIFAR-10 image classification and retinal optic disk segmentation. In CIFAR-10, controlled client-efficiency scenarios show that system-level slowdowns and coordination effects can contribute meaningfully to carbon footprint under an otherwise fixed FL protocol, increasing total CO2e by 8.34x (medium) and 21.73x (low) relative to the high-efficiency baseline. In retinal segmentation, swapping GPU tiers (H100 vs.\ V100) yields a consistent 1.7x runtime gap (290 vs. 503 minutes) while producing non-uniform changes in total energy and CO2e across sites, underscoring the need for per-site and per-round reporting. Overall, our results support a standardized carbon accounting method that acts as a prerequisite for reproducible 'green' FL evaluation. Our code is available at https://github.com/Pediatric-Accelerated-Intelligence-Lab/carbon_footprint.

</details>


### [476] [PROBE: Co-Balancing Computation and Communication in MoE Inference via Real-Time Predictive Prefetching](https://arxiv.org/abs/2602.00509)
*Qianchao Zhu,Xucheng Ye,Yuliang Liu,Haodong Ouyang,Chengru Song*

Main category: cs.DC

TL;DR: PROBE是一个实时协同平衡计算与通信的MoE推理系统，通过预测、规划和隐藏通信开销，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: MoE推理在延迟关键场景中面临计算倾斜和网络拥塞的双重惩罚，尤其是在连续批处理和多样化并发请求导致专家热点快速迁移时。

Method: PROBE系统包含三个核心组件：1) Gate-Initialized Lookahead Predictor预测下一层专家激活；2) Hardware-Aware Balance Planning求解器动态优化专家复制和令牌分配；3) Phase-Locked Co-Scheduling策略通过分阶段传输隐藏带宽密集型专家转移。

Result: 实验表明，PROBE相比现有技术基线，预填充延迟降低1.32倍，解码吞吐量提高1.26倍。

Conclusion: PROBE通过实时协同平衡计算与通信，显著降低了MoE推理的延迟并提高了吞吐量，特别是在极端工作负载波动下表现优异。

Abstract: Mixture-of-Experts models have become a dominant architecture for scaling Large Language Models by activating only a sparse subset of experts per token. However, latency-critical MoE inference faces a fundamental tension: while expert parallelism improves memory efficiency, it also amplifies execution stragglers. In real-world serving, continuous batching and diverse concurrent requests induce rapid semantic shifts, causing expert hotspots to migrate abruptly across GPUs and triggering the 'double penalty' of coupled computational skew and network congestion.
  We propose PROBE, an inference system that co-balances computation and communication in real time. PROBE introduces Continuous Lookahead Pipelining, which proactively predicts, plans, and prefetches for upcoming layers while keeping all control overheads off the critical path. PROBE consists of: (1) a Gate-Initialized Lookahead Predictor that distills the target router to forecast next-layer expert activation with high fidelity; (2) a Hardware-Aware Balance Planning solver that jointly optimizes dynamic expert replication and token assignment under strict hiding-window constraints; and (3) a Phase-Locked Co-Scheduling policy that uses split-phase transmission to hide bandwidth-intensive expert transfers behind computation without contending with All-to-All collectives. Experiments show that PROBE reduces prefill latency by up to 1.32X and improves decoding throughput by up to 1.26X over state-of-the-art baselines, especially under extreme workload volatility.

</details>


### [477] [HyperOffload: Graph-Driven Hierarchical Memory Management for Large Language Models on SuperNode Architectures](https://arxiv.org/abs/2602.00748)
*Fangxin Liu,Qinghua Zhang,Hanjing Shen,Zhibo Liang,Li Jiang,Haibing Guan,Chong Bao,Xuefeng Jin*

Main category: cs.DC

TL;DR: SuperNode框架通过编译器辅助的图驱动内存管理，优化远程内存访问，显著减少内存使用并保持性能。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的快速发展对内存需求远超单个设备HBM容量，现有软件栈无法有效利用新兴超级节点架构的硬件优势。

Method: 提出了SuperNode内存管理框架（HyperOffload），采用编译器辅助方法，利用图驱动内存管理，将远程内存访问视为计算图中的显式操作。通过编译时全局分析张量生命周期和执行依赖，开发了全局执行顺序优化算法。

Result: 在代表性LLM工作负载上评估显示，SuperNode在推理时峰值设备内存使用减少了26%，同时保持端到端性能。

Conclusion: 论文展示了将内存增强硬件集成到编译器优化框架中对于扩展下一代AI工作负载的重要性。

Abstract: The rapid evolution of Large Language Models (LLMs) towards long-context reasoning and sparse architectures has pushed memory requirements far beyond the capacity of individual device HBM. While emerging supernode architectures offer terabyte-scale shared memory pools via high-bandwidth interconnects, existing software stacks fail to exploit this hardware effectively. Current runtime-based offloading and swapping techniques operate with a local view, leading to reactive scheduling and exposed communication latency that stall the computation pipeline.
  In this paper, we propose the SuperNode Memory Management Framework (\textbf{HyperOffload}). It employs a compiler-assisted approach that leverages graph-driven memory management to treat remote memory access as explicit operations in the computation graph, specifically designed for hierarchical SuperNode architectures. Unlike reactive runtime systems, SuperNode represents data movement using cache operators within the compiler's Intermediate Representation (IR). This design enables a global, compile-time analysis of tensor lifetimes and execution dependencies. Leveraging this visibility, we develop a global execution-order refinement algorithm that statically schedules data transfers to hide remote memory latency behind compute-intensive regions. We implement SuperNode within the production deep learning framework MindSpore, adding a remote memory backend and specialized compiler passes. Evaluation on representative LLM workloads shows that SuperNode reduces peak device memory usage by up to 26\% for inference while maintaining end-to-end performance. Our work demonstrates that integrating memory-augmented hardware into the compiler's optimization framework is essential for scaling next-generation AI workloads.

</details>


### [478] [System-Level Performance Modeling of Photonic In-Memory Computing](https://arxiv.org/abs/2602.00892)
*Jebacyril Arockiaraj,Sasindu Wijeratne,Sugeet Sunder,Md Abdullah-Al Kaiser,Akhilesh Jaiswal,Ajey P. Jacob,Viktor Prasanna*

Main category: cs.DC

TL;DR: Photonic in-memory computing offers high-speed, low-energy performance, with a 1x256 bit photonic SRAM array achieving up to 1.5 TOPS and 2.5 TOPS/W efficiency across multiple workloads.


<details>
  <summary>Details</summary>
Motivation: To address the need for high-speed, low-energy alternatives to traditional transistor-based digital computing by leveraging photonic operating frequencies and bandwidths.

Method: Developed a comprehensive system-level performance model for photonic in-memory computing, incorporating key latency sources like external memory access and opto-electronic conversion, and performed algorithm-to-hardware mapping across multiple workloads.

Result: The photonic SRAM array sustained up to 1.5 TOPS, 0.9 TOPS, and 1.3 TOPS on the Sod shock tube problem, MTTKRP, and the Vlasov-Maxwell equation, with an average energy efficiency of 2.5 TOPS/W.

Conclusion: The study demonstrates that a compact 1x256 bit single-wavelength photonic SRAM array, fabricated using standard silicon photonics, achieves high performance (up to 1.5 TOPS) and energy efficiency (2.5 TOPS/W) across various workloads, despite system overheads.

Abstract: Photonic in-memory computing is a high-speed, low-energy alternative to traditional transistor-based digital computing that utilizes high photonic operating frequencies and bandwidths. In this work, we develop a comprehensive system-level performance model for photonic in-memory computing, capturing the effects of key latency sources such as external memory access and opto-electronic conversion. We perform algorithm-to-hardware mapping across a range of workloads, including the Sod shock tube problem, Matricized Tensor Times Khatri-Rao Product (MTTKRP), and the Vlasov-Maxwell equation, to evaluate how the latencies impact real-world high-performance computing workloads. Our performance model shows that, while accounting for system overheads, a compact 1x256 bit single-wavelength photonic SRAM array, fabricated using the standard silicon photonics process by GlobalFoundries, sustains up to 1.5 TOPS, 0.9 TOPS, and 1.3 TOPS on the Sod shock tube problem, MTTKRP, and the Vlasov-Maxwell equation with an average energy efficiency of 2.5 TOPS/W.

</details>


### [479] [Low-latency Federated LLM Fine-tuning Over Wireless Networks](https://arxiv.org/abs/2602.01024)
*Zhiwen Pang,Kang Wei,Long Shi,Zhe Wang,Jun Li,Feng Shu*

Main category: cs.DC

TL;DR: 提出JCPBA框架，通过联合优化剪枝和带宽分配，提升联邦LLM在无线网络中的微调效率，实验验证其高效性。


<details>
  <summary>Details</summary>
Motivation: 解决资源受限客户端在联邦LLM微调中因异构计算能力和随机无线信道带来的挑战。

Method: 通过联合优化剪枝率和带宽分配，采用块坐标下降法解决微调延迟最小化问题。

Result: 在Yahoo Answers和GSM8K数据集上的实验表明，该框架显著减少了微调时间，且计算和通信开销更低。

Conclusion: 提出的JCPBA框架在无线网络中显著提高了联邦LLM的微调效率，减少了计算和通信开销，同时保持了与现有基线相当或更低的测试损失。

Abstract: Recently, federated large language models (LLMs) have drawn significant attention thanks to coupled capabilities of LLMs and federated learning (FL) that address privacy concerns in collaborative fine-tuning. However, due to large-scale parameters of LLMs, existing federated LLM fine-tuning frameworks incur significant challenges in resource-constrained clients characterized by heterogeneous computing capabilities and random wireless channels. To address this issue, we propose a joint client-specific pruning and bandwidth allocation (JCPBA) framework for federated LLMs to improve the fine-tuning efficiency over the wireless networks. Specifically, we formulate a fine-tuning latency minimization problem by jointly optimizing pruning rates and bandwidth allocations. Furthermore, we solve this optimization problem using a block coordinate descent method. Extensive experiments on the datasets of Yahoo Answers and GSM8K demonstrate that the proposed framework significantly reduces wall-clock fine-tuning time compared with state-of-the-art baselines and gains equal or lower test loss at the cost of lower computation and communication overhead.

</details>


### [480] [BOA Constrictor: Squeezing Performance out of GPUs in the Cloud via Budget-Optimal Allocation](https://arxiv.org/abs/2602.01404)
*Zhouzi Li,Cindy Zhu,Arpan Mukhopadhyay,Mor Harchol-Balter,Benjamin Berg*

Main category: cs.DC

TL;DR: BOA Constrictor 是一种预算优化的 ML 训练作业调度器，显著降低作业完成时间。


<details>
  <summary>Details</summary>
Motivation: 由于 GPU 租赁成本高昂且分配策略影响性能和成本，需要一种能在预算约束下优化性能的调度方案。

Method: 开发了 BOA Constrictor 调度器，采用预算最优分配（BOA）策略，将问题明确表述为预算约束下的调度问题，并推导出 BOA 策略。

Result: 在小规模实验和大规模模拟中，BOA Constrictor 分别将平均 JCT 降低了 1.6 倍和 2 倍。

Conclusion: BOA Constrictor 是一种新型调度器，能够在固定预算约束下最大化云部署 GPU 集群的性能，显著降低平均作业完成时间（JCT）。

Abstract: The past decade has seen a dramatic increase in demand for GPUs to train Machine Learning (ML) models. Because it is prohibitively expensive for most organizations to build and maintain a large GPU cluster, organizations instead choose to rent GPUs from cloud providers. The customer is responsible for devising a policy for (i) deciding how many GPUs to rent at every moment in time to process a stream of ML training jobs and (ii) allocating the rented GPUs among the currently active jobs in the system. Because ML training jobs can be parallelized across different numbers of GPUs, the customer generally has many options for how many GPUs to use for each job. Allocating more GPUs to a single training job will cause the job to complete more quickly. However, the customer pays for each GPU-hour they use, and a training job receives a diminishing marginal benefit from running on additional GPUs. Hence, allocating too many GPUs to a single training job can dramatically increase the overall cost that the customer pays to the cloud provider. This gives rise to a cost-performance tradeoff that customers must balance when running training jobs in the cloud.
  To balance the cost-performance tradeoff, we develop BOA Constrictor, a new scheduler for ML training jobs which uses a Budget-Optimal Allocation (BOA) policy to squeeze the highest level of performance out of a cloud-deployed GPU cluster given a fixed budget constraint. We explicitly formulate the problem as a budget-constrained scheduling problem and derive the BOA policy which minimizes the average job completion time (JCT) of a stream of arriving jobs subject to the user's budget. For a given budget level, we demonstrate that BOA Constrictor can reduce average JCT by 1.6 times in small-scale implementation experiments and by 2 times in detailed, large-scale simulations compared to state-of-the-art heuristic based schedulers.

</details>


### [481] [Mean field optimal Core Allocation across Malleable jobs](https://arxiv.org/abs/2602.01411)
*Zhouzi Li,Mor Harchol-Balter,Benjamin Berg*

Main category: cs.DC

TL;DR: 本文解决了可塑性作业的核心分配问题，提出了两种平均场最优策略FW-CAM和WHAM，其中WHAM在实际应用中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现代数据中心和云计算集群中，可塑性作业日益普遍，如何在这些作业之间分配固定数量的核心以最小化平均响应时间成为一个重要问题。

Method: 在平均场渐近状态下分析CAM问题，推导出两种策略FW-CAM和WHAM。FW-CAM展示了作业大小在寻找最优策略时不相关的新直觉，而WHAM通过Whittle分配方法实现渐近最优。

Result: 提出的FW-CAM和WHAM策略在多种作业类别、任意凹速度提升函数和一般分布的到达间隔时间及作业大小下均表现良好，且WHAM在实际应用中也具有很好的启发性。

Conclusion: 本文提出了两种在平均场渐近状态下最优的策略FW-CAM和WHAM，用于解决可塑性作业的核心分配问题。其中WHAM不仅在渐近状态下最优，在实际应用中也表现良好。

Abstract: Modern data centers and cloud computing clusters are increasingly running workloads composed of malleable jobs. A malleable job can be parallelized across any number of cores, yet the job typically exhibits diminishing marginal returns for each additional core on which it runs. This can be seen in the concavity of a job's speedup function, which describes the job's processing speed as a function of the number of cores on which it runs.
  Given the prevalence of malleable jobs, several theoretical works have posed the problem of how to allocate a fixed number of cores across a stream of arriving malleable jobs so as to minimize the mean response time across jobs. We refer to this as the Core Allocation to Malleable jobs (CAM) problem. We solve the CAM problem under a highly general setting, allowing for multiple job classes, each with an arbitrary concave speedup function and holding costs (weight). Furthermore, we allow for generally distributed inter-arrival times and job sizes.
  We analyze the CAM problem in the mean field asymptotic regime and derive two distinct mean field optimal policies, FW-CAM and WHAM. FW-CAM is interesting because it demonstrates a new intuition: in the mean field regime, job sizes are not relevant in finding an optimal policy. WHAM (Whittle Allocation for Malleable jobs) is interesting because it is asymptotically optimal and also serves as a good heuristic even outside of the asymptotic regime. Notably, none of the policies previously proposed in the literature are mean field optimal when jobs may follow different speedup functions.

</details>


### [482] [Developing a Portable Solution for Post-Event Analysis Pipelines](https://arxiv.org/abs/2602.01798)
*Leonardo Pelonero,Fabio Vitello,Eva Sciacca,Mauro Imbrosciano,Salvatore Scavo,Ugo Becciani*

Main category: cs.DC

TL;DR: 论文提出一个结合摄影测量、数据可视化和AI的科学网关框架，用于自动化评估极端自然事件及其影响。


<details>
  <summary>Details</summary>
Motivation: 由于气候变化加剧了洪水、干旱、风暴潮和滑坡等自然灾害，以及地震的持续风险，研究旨在提升对意大利等易受影响地区的风险评估和缓解策略。

Method: 该研究采用摄影测量技术、数据可视化和人工智能技术，整合到科学网关框架中，开发便携式且全自动化的后事件分析流程。

Result: 通过整合多种技术，研究成功开发了一个用于评估极端自然事件及其影响的科学网关框架。

Conclusion: 该论文提出了一种科学网关框架，结合摄影测量技术、数据可视化和人工智能技术，用于开发便携式且全自动化的后事件分析流程，以评估极端自然事件及其对风险暴露资产的影响。

Abstract: In recent years, the monitoring and study of natural hazards have gained significant attention, particularly due to climate change, which exacerbates incidents like floods, droughts, storm surges, and landslides. Together with the constant risk of earthquakes, these climate-induced events highlight the critical necessity for enhanced risk assessment and mitigation strategies in susceptible areas such as Italy.
  In this work, we present a Science Gateway framework for the development of portable and fully automated post-event analysis pipelines integrating Photogrammetry techniques, Data Visualization and Artificial Intelligence technologies, applied on aerial images, to assess extreme natural events and evaluate their impact on risk-exposed assets.

</details>


### [483] [Grappa: Gradient-Only Communication for Scalable Graph Neural Network Training](https://arxiv.org/abs/2602.01872)
*Chongyang Xu,Christoph Siebenbrunner,Laurent Bindschaedler*

Main category: cs.DC

TL;DR: Grappa通过梯度唯一通信和周期性重新分区，显著提升分布式GNN训练速度和准确性，支持大规模图训练。


<details>
  <summary>Details</summary>
Motivation: 解决分布式GNN训练中跨分区边通信成本高的问题，尤其是在图深度增加和分区数量增长时。

Method: Grappa采用梯度唯一通信策略，结合周期性重新分区和轻量级覆盖校正梯度聚合，确保训练效率和模型准确性。

Result: Grappa在真实和合成图上的实验表明，其训练速度平均提升4倍（最高13倍），且深层模型准确性更高，能在普通硬件上支持万亿边规模的训练。

Conclusion: Grappa通过仅交换梯度和周期性重新分区的方法，显著提升了分布式GNN训练的效率和准确性，尤其在深层模型和大规模图上表现优异。

Abstract: Cross-partition edges dominate the cost of distributed GNN training: fetching remote features and activations per iteration overwhelms the network as graphs deepen and partition counts grow. Grappa is a distributed GNN training framework that enforces gradient-only communication: during each iteration, partitions train in isolation and exchange only gradients for the global update. To recover accuracy lost to isolation, Grappa (i) periodically repartitions to expose new neighborhoods and (ii) applies a lightweight coverage-corrected gradient aggregation inspired by importance sampling. We prove the corrected estimator is asymptotically unbiased under standard support and boundedness assumptions, and we derive a batch-level variant for compatibility with common deep-learning packages that minimizes mean-squared deviation from the ideal node-level correction. We also introduce a shrinkage version that improves stability in practice. Empirical results on real and synthetic graphs show that Grappa trains GNNs 4 times faster on average (up to 13 times) than state-of-the-art systems, achieves better accuracy especially for deeper models, and sustains training at the trillion-edge scale on commodity hardware. Grappa is model-agnostic, supports full-graph and mini-batch training, and does not rely on high-bandwidth interconnects or caching.

</details>


### [484] [vLLM-Omni: Fully Disaggregated Serving for Any-to-Any Multimodal Models](https://arxiv.org/abs/2602.02204)
*Peiqi Yin,Jiangyun Zhu,Han Gao,Chenguang Zheng,Yongxiang Huang,Taichang Zhou,Ruirui Yang,Weizhi Liu,Weiqing Chen,Canlin Guo,Didan Deng,Zifeng Mo,Cong Wang,James Cheng,Roger Wang,Hongsheng Liu*

Main category: cs.DC

TL;DR: vLLM-Omni 是一个解耦的多模态模型服务系统，通过阶段抽象和优化执行，显著提升性能，代码已开源。


<details>
  <summary>Details</summary>
Motivation: 现有的服务系统主要针对单一范式设计，缺乏对多模态模型的支持，导致开发者需手动处理跨阶段交互，性能大幅下降。

Method: vLLM-Omni 采用阶段抽象方法，将复杂的多模态架构分解为图表示的互联阶段，并通过解耦的后端执行优化资源利用和吞吐量。

Result: 实验结果表明，vLLM-Omni 相比基线方法将任务完成时间（JCT）降低了高达 91.4%。

Conclusion: vLLM-Omni 是一种高效的多模态模型服务系统，通过解耦和优化阶段执行，显著提升了任务完成时间和资源利用率。

Abstract: Any-to-any multimodal models that jointly handle text, images, video, and audio represent a significant advance in multimodal AI. However, their complex architectures (typically combining multiple autoregressive LLMs, diffusion transformers, and other specialized components) pose substantial challenges for efficient model serving. Existing serving systems are mainly tailored to a single paradigm, such as autoregressive LLMs for text generation or diffusion transformers for visual generation. They lack support for any-to-any pipelines that involve multiple interconnected model components. As a result, developers must manually handle cross-stage interactions, leading to huge performance degradation. We present vLLM-Omni, a fully disaggregated serving system for any-to-any models. vLLM-Omni features a novel stage abstraction that enables users to decompose complex any-to-any architectures into interconnected stages represented as a graph, and a disaggregated stage execution backend that optimizes resource utilization and throughput across stages. Each stage is independently served by an LLM or diffusion engine with per-stage request batching, flexible GPU allocation, and unified inter-stage connectors for data routing. Experimental results demonstrate that vLLM-Omni reduces job completion time (JCT) by up to 91.4% compared to baseline methods. The code is public available at https://github.com/vllm-project/vllm-omni.

</details>


### [485] [Enabling AI Deep Potentials for Ab Initio-quality Molecular Dynamics Simulations in GROMACS](https://arxiv.org/abs/2602.02234)
*Andong Hu,Luca Pennati,Stefano Markidis,Ivy Peng*

Main category: cs.DC

TL;DR: 研究将AI深度势能集成到GROMACS中，评估了DPA2和DPA3的性能，发现DPA2在GPU上的吞吐量显著优于DPA3，并提出了优化方向。


<details>
  <summary>Details</summary>
Motivation: 将AI深度势能引入GROMACS，以在保持从头算质量的同时降低计算成本。

Method: 通过将GROMACS与DeePMD-kit的C++/CUDA后端集成，支持多种DP模型家族和深度学习后端，评估了DPA2和DPA3两种架构在蛋白质水溶液基准测试中的性能。

Result: DPA2在A100和GH200 GPU上的吞吐量分别比DPA3高4.23倍和3.18倍。

Conclusion: 研究确定了在分子动力学模拟中优化AI深度势能的主要方向，即减少内核启动开销和优化域分解推理。

Abstract: State-of-the-art AI deep potentials provide ab initio-quality results, but at a fraction of the computational cost of first-principles quantum mechanical calculations, such as density functional theory. In this work, we bring AI deep potentials into GROMACS, a production-level Molecular Dynamics (MD) code, by integrating with DeePMD-kit that provides domain-specific deep learning (DL) models of interatomic potential energy and force fields. In particular, we enable AI deep potentials inference across multiple DP model families and DL backends by coupling GROMACS Neural Network Potentials with the C++/CUDA backend in DeePMD-kit. We evaluate two recent large-atom-model architectures, DPA2 that is based on the attention mechanism and DPA3 that is based on GNN, in GROMACS using four ab initio-quality protein-in-water benchmarks (1YRF, 1UBQ, 3LZM, 2PTC) on NVIDIA A100 and GH200 GPUs. Our results show that DPA2 delivers up to 4.23x and 3.18x higher throughput than DPA3 on A100 and GH200 GPUs, respectively. We also provide a characterization study to further contrast DPA2 and DPA3 in throughput, memory usage, and kernel-level execution on GPUs. Our findings identify kernel-launch overhead and domain-decomposed inference as the main optimization priorities for AI deep potentials in production MD simulations.

</details>


### [486] [Building a Correct-by-Design Lakehouse. Data Contracts, Versioning, and Transactional Pipelines for Humans and Agents](https://arxiv.org/abs/2602.02335)
*Weiming Sheng,Jinlang Wang,Manuel Barros,Aldrin Montana,Jacopo Tagliabue,Luca Bigon*

Main category: cs.DC

TL;DR: Bauplan是一个代码优先的湖仓系统，通过类型化表合约、Git-like数据版本化和事务性运行解决并发操作中的安全问题，早期结果展示了其潜力。


<details>
  <summary>Details</summary>
Motivation: 湖仓作为分析和AI的默认云平台，在并发操作中可能因不可信行为导致运行时上下游不匹配和多表管道部分效应泄露，亟需解决这些安全问题。

Method: 设计并实现了Bauplan，一个代码优先的湖仓系统，包含类型化表合约、Git-like数据版本化和事务性运行三个核心机制。

Result: 通过轻量级形式化事务模型的早期结果展示了Bauplan的潜力，并讨论了未来研究方向。

Conclusion: Bauplan的设计通过引入类型化表合约、Git-like数据版本化和事务性运行，旨在解决湖仓在并发操作中的安全问题，未来工作将针对反例进行进一步研究。

Abstract: Lakehouses are the default cloud platform for analytics and AI, but they become unsafe when untrusted actors concurrently operate on production data: upstream-downstream mismatches surface only at runtime, and multi-table pipelines can leak partial effects. Inspired by software engineering, we design Bauplan, a code-first lakehouse that aims to make (most) illegal states unrepresentable using familiar abstractions. Bauplan acts along three axes: typed table contracts to make pipeline boundaries checkable, Git-like data versioning for review and reproducibility, and transactional runs that guarantee pipeline-level atomicity. We report early results from a lightweight formal transaction model and discuss future work motivated by counterexamples.

</details>


### [487] [LCLs Beyond Bounded Degrees](https://arxiv.org/abs/2602.02340)
*Gustav Schmid*

Main category: cs.DC

TL;DR: The paper explores polynomial gap results in unbounded-degree trees, showing they vanish with infinitely many LCL configurations but are restored by LFLs, which ensure finite local cases and predictable complexities.


<details>
  <summary>Details</summary>
Motivation: The motivation is to investigate whether polynomial gap results persist in the unbounded-degree setting of trees, addressing the limitations of previous studies on bounded-degree trees.

Method: The research focuses on the polynomial regime in trees with unbounded degrees, examining LCLs and introducing LFLs to formalize the intuition of finite local cases.

Result: The results show that polynomial gaps disappear if LCLs use infinitely many local configurations, but introducing LFLs restores these gaps, providing a clear classification of deterministic LOCAL complexities.

Conclusion: The study concludes that polynomial gap results in the unbounded-degree setting depend on how LCLs are generalized. Introducing Locally Finite Labelings (LFLs) restores these gaps, showing deterministic LOCAL complexity is either Θ(n^(1/k)) for some integer k ≥ 1 or O(log n).

Abstract: The study of Locally Checkable Labelings (LCLs) has led to a remarkably precise characterization of the distributed time complexities that can occur on bounded-degree trees. A central feature of this complexity landscape is the existence of strong gap results, which rule out large ranges of intermediate complexities. While it was initially hoped that these gaps might extend to more general graph classes, this has turned out not to be the case. In this work, we investigate a different direction: we remain in the class of trees, but allow arbitrarily large degrees.
  We focus on the polynomial regime ($Θ(n^{1/k} \mid k \in \mathbb{N})$) and show that whether polynomial gap results persist in the unbounded-degree setting crucially depends on how LCLs are generalized beyond bounded degrees. We first demonstrate that if one allows LCLs to be defined using infinitely many local configurations, then the polynomial gaps disappear entirely: for every real exponent $0 < r \leq 1$, there exists a locally checkable problem on trees with deterministic LOCAL complexity $Θ(n^r)$.
  Rather than stopping at this negative result, we identify a natural class of problems for which polynomial gap results can still be recovered. We introduce Locally Finite Labelings (LFLs), which formalize the intuition that ''every node must fall into one of finitely many local cases'', even in the presence of unbounded degrees.
  Our main result shows that this restriction is sufficient to restore the polynomial gaps: for any LFL $Π$ on trees with unbounded degrees, the deterministic LOCAL complexity of $Π$ is either
  - $Θ(n^{1/k})$ for some integer $k \geq 1$, or
  - $O(\log n)$.
  Moreover, which case applies, and the corresponding value of $k$, can be determined solely from the description of $Π$.

</details>


### [488] [Hierarchical Federated Learning with SignSGD: A Highly Communication-Efficient Approach](https://arxiv.org/abs/2602.02355)
*Amirreza Kazemi,Seyed Mohammad Azimi-Abarghouyi,Gabor Fodor,Carlo Fischione*

Main category: cs.DC

TL;DR: 提出 HierSignSGD，一种高效的符号分层联邦学习框架，通过多数投票和模型聚合实现高压缩通信，保持准确性。


<details>
  <summary>Details</summary>
Motivation: 解决分层联邦学习中梯度压缩与两层级聚合（边缘多数投票和云端模型聚合）对端到端性能影响的未知问题。

Method: 提出了一种基于符号的 HFL 框架 HierSignSGD，其中设备仅发送带符号的随机梯度，边缘服务器通过多数投票聚合，云端定期平均边缘模型，并利用下行量化广播全局模型。

Result: 数值实验表明，HierSignSGD 在同质和异质数据分布下均表现良好，通信成本显著降低。

Conclusion: HierSignSGD 在极端压缩的情况下，仍能实现与全精度随机梯度下降相当的准确性，并显著降低通信成本，且在激进的下行稀疏化下保持鲁棒性。

Abstract: Hierarchical federated learning (HFL) has emerged as a key architecture for large-scale wireless and Internet of Things systems, where devices communicate with nearby edge servers before reaching the cloud. In these environments, uplink bandwidth and latency impose strict communication limits, thereby making aggressive gradient compression essential. One-bit methods such as sign-based stochastic gradient descent (SignSGD) offer an attractive solution in flat federated settings, but existing theory and algorithms do not naturally extend to hierarchical settings. In particular, the interaction between majority-vote aggregation at the edge layer and model aggregation at the cloud layer, and its impact on end-to-end performance, remains unknown. To bridge this gap, we propose a highly communication-efficient sign-based HFL framework and develop its corresponding formulation for nonconvex learning, where devices send only signed stochastic gradients, edge servers combine them through majority-vote, and the cloud periodically averages the obtained edge models, while utilizing downlink quantization to broadcast the global model. We introduce the resulting scalable HFL algorithm, HierSignSGD, and provide the convergence analysis for SignSGD in a hierarchical setting. Our core technical contribution is a characterization of how biased sign compression, two-level aggregation intervals, and inter-cluster heterogeneity collectively affect convergence. Numerical experiments under homogeneous and heterogeneous data splits show that HierSignSGD, despite employing extreme compression, achieves accuracy comparable to or better than full-precision stochastic gradient descent while reducing communication cost in the process, and remains robust under aggressive downlink sparsification.

</details>


### [489] [sVIRGO: A Scalable Virtual Tree Hierarchical Framework for Distributed Systems](https://arxiv.org/abs/2602.02438)
*Lican Huang*

Main category: cs.DC

TL;DR: sVIRGO是一种可扩展的虚拟树层次框架，通过动态角色映射和多频通信实现高效、稳健的大规模分布式协调。


<details>
  <summary>Details</summary>
Motivation: 解决大规模分布式系统中协调效率低、故障恢复延迟高和通信开销大的问题。

Method: sVIRGO构建虚拟层次树，节点可承担多个层次角色，无需覆盖网络。通过动态映射虚拟上层角色实现跨区域协调，支持多频无线链路通信和两种消息跳策略。

Result: 实现了近零恢复延迟、有界通信开销和指数级降低的故障概率，支持移动、干扰或对抗条件下的安全协调。

Conclusion: sVIRGO通过虚拟树层次框架实现了大规模分布式系统的高效协调，保证了安全性、活性和鲁棒性，同时降低了通信开销和故障概率。

Abstract: We propose sVIRGO, a scalable virtual tree hierarchical framework for large-scale distributed systems. sVIRGO constructs virtual hierarchical trees directly on physical nodes, allowing each node to assume multiple hierarchical roles without overlay networks. The hierarchy preserves locality and is organized into configurable layers within regions. Coordination across thousands of regions is achieved via virtual upper-layer roles dynamically mapped onto nodes up to the top layer.
  Each region maintains multiple active coordinators that monitor local health and perform dynamic re-selection if failures occur. Temporary drops below the minimum threshold do not compromise coordination, ensuring near-zero recovery latency, bounded communication overhead, and exponentially reduced failure probability while maintaining safety, liveness, and robustness under mobile, interference-prone, or adversarial conditions.
  Communication is decoupled from the hierarchy and may use multi-frequency wireless links. Two message hop strategies are supported: (i) with long-distance infrastructure-assisted channels, coordinators exploit the virtual tree to minimize hops; (ii) without such channels, messages propagate via adjacent regions.
  sVIRGO also supports Layer-Scoped Command Execution. Commands and coordination actions are executed within the scope of each hierarchical layer, enabling efficient local and regional decision-making while limiting unnecessary global propagation.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [490] [End Cover for Initial Value Problem: Complete Validated Algorithms with Complexity Analysis](https://arxiv.org/abs/2602.00162)
*Bingwei Zhang,Chee Yap*

Main category: cs.DS

TL;DR: 论文提出了一种验证算法，用于解决一阶自治常微分方程的末端覆盖问题，并通过实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决一阶自治常微分方程的末端覆盖问题，确保计算结果的准确性和验证性。

Method: 论文介绍了一种基于覆盖边界的新技术，用于计算末端覆盖集，并提供了算法的复杂度分析。

Result: 实验结果表明，所提出的算法在实际应用中具有可行性。

Conclusion: 该论文提出了一种完整的验证算法，用于解决一阶自治常微分方程的'End Cover Problem'，并通过实验证明了其实际可行性。

Abstract: We consider the first-order autonomous ordinary differential equation \[ \mathbf{x}' = \mathbf{f}(\mathbf{x}), \] where $\mathbf{f} : \mathbb{R}^n \to \mathbb{R}^n$ is locally Lipschitz. For a box $B_0 \subseteq \mathbb{R}^n$ and $h > 0$, we denote by $\mathrm{IVP}_{\mathbf{f}}(B_0,h)$ the set of solutions $\mathbf{x} : [0,h] \to \mathbb{R}^n$ satisfying \[ \mathbf{x}'(t) = \mathbf{f}(\mathbf{x}(t)), \qquad \mathbf{x}(0) \in B_0 . \]
  We present a complete validated algorithm for the following \emph{End Cover Problem}: given $(\mathbf{f}, B_0, \varepsilon, h)$, compute a finite set $\mathcal{C}$ of boxes such that \[ \mathrm{End}_{\mathbf{f}}(B_0,h) \;\subseteq\; \bigcup_{B \in \mathcal{C}} B \;\subseteq\; \mathrm{End}_{\mathbf{f}}(B_0,h) \oplus [-\varepsilon,\varepsilon]^n , \] where \[ \mathrm{End}_{\mathbf{f}}(B_0,h) = \left\{ \mathbf{x}(h) : \mathbf{x} \in \mathrm{IVP}_{\mathbf{f}}(B_0,h) \right\}. \]
  Moreover, we provide a complexity analysis of our algorithm and introduce a novel technique for computing the end cover $\mathcal{C}$ based on covering the boundary of $\mathrm{End}_{\mathbf{f}}(B_0,h)$. Finally, we present experimental results demonstrating the practicality of our approach.

</details>


### [491] [Hardness and Tractability of T_{h+1}-Free Edge Deletion](https://arxiv.org/abs/2602.00644)
*Ajinkya Gaikwad,Soumen Maity,Leeja R*

Main category: cs.DS

TL;DR: The paper analyzes the T(h+1)-Free Edge Deletion problem, showing NP-completeness for h ≥ 3 and polynomial-time solvability for h ≤ 2. It proves W[1]-hardness for several parameters and presents FPT algorithms for specific cases and graph classes.


<details>
  <summary>Details</summary>
Motivation: The motivation is to explore the parameterized complexity of the T(h+1)-Free Edge Deletion problem, addressing gaps in understanding its hardness and tractability under different parameterizations and graph classes.

Method: The study employs parameterized complexity analysis, proving W[1]-hardness for various structural parameters and demonstrating fixed-parameter tractability (FPT) for specific cases using techniques like integer linear programming and bicriteria approximation.

Result: Key results include W[1]-hardness for several restrictive parameters, FPT algorithms for cluster vertex deletion and neighborhood diversity with h, and tractability on split and interval graphs. The problem is also shown to be hard for a directed generalization.

Conclusion: The paper concludes that the T(h+1)-Free Edge Deletion problem is NP-complete for h ≥ 3 but polynomial-time solvable for h ≤ 2. It identifies strong hardness barriers and extends them to more restrictive parameters, while also presenting positive results for certain parameterizations and graph classes.

Abstract: We study the parameterized complexity of the T(h+1)-Free Edge Deletion problem. Given a graph G and integers k and h, the task is to delete at most k edges so that every connected component of the resulting graph has size at most h. The problem is NP-complete for every fixed h at least 3, while it is solvable in polynomial time for h at most 2.
  Recent work showed strong hardness barriers: the problem is W[1]-hard when parameterized by the solution size together with the size of a feedback edge set, ruling out fixed-parameter tractability for many classical structural parameters. We significantly strengthen these negative results by proving W[1]-hardness when parameterized by the vertex deletion distance to a disjoint union of paths, the vertex deletion distance to a disjoint union of stars, or the twin cover number. These results unify and extend known hardness results for treewidth, pathwidth, and feedback vertex set, and show that several restrictive parameters, including treedepth, cluster vertex deletion number, and modular width, do not yield fixed-parameter tractability when h is unbounded.
  On the positive side, we identify parameterizations that restore tractability. We show that the problem is fixed-parameter tractable when parameterized by cluster vertex deletion together with h, and also when parameterized by neighborhood diversity together with h via an integer linear programming formulation. We further present a fixed-parameter tractable bicriteria approximation algorithm parameterized by k. Finally, we show that the problem admits fixed-parameter tractable algorithms on split graphs and interval graphs, and we establish hardness for a directed generalization even on directed acyclic graphs.

</details>


### [492] [Fanciful Figurines flip Free Flood-It -- Polynomial-Time Miniature Painting on Co-gem-free Graphs](https://arxiv.org/abs/2602.00690)
*Christian Rosenke,Mark Scheibner*

Main category: cs.DS

TL;DR: 论文提出了一种针对无诱导共宝石图的微型绘画问题的多项式时间算法，并证明了自由泛滥游戏在此类图上的多项式时间可解性。


<details>
  <summary>Details</summary>
Motivation: 受微型绘画爱好的启发，研究如何在给定模板下用最少的笔触序列为图着色，并将此问题与自由泛滥游戏的反向问题联系起来。

Method: 通过将微型绘画问题与自由泛滥游戏的反向问题等价，利用已知的自由泛滥游戏的复杂性结果，直接转移到微型绘画问题上。

Result: 证明了微型绘画问题在无诱导共宝石图上存在多项式时间算法，且自由泛滥游戏在此类图上也是多项式时间可解的。

Conclusion: 该论文的主要贡献是针对无诱导共宝石图（co-gem-free graphs）的微型绘画问题提出了一个多项式时间算法，并由此推导出自由泛滥游戏（Free Flood-It）在同一类图上也是多项式时间可解的。

Abstract: Inspired by the eponymous hobby, we introduce Miniature Painting as the computational problem to paint a given graph $G=(V,E)$ according to a prescribed template $t \colon V \rightarrow C$, which assigns colors $C$ to the vertices of $G$. In this setting, the goal is to realize the template using a shortest possible sequence of brush strokes, where each stroke overwrites a connected vertex subset with a color in $C$. We show that this problem is equivalent to a reversal of the well-studied Free Flood-It game, in which a colored graph is decolored into a single color using as few moves as possible. This equivalence allows known complexity results for Free Flood-It to be transferred directly to Miniature Painting, including NP-hardness under severe structural restrictions, such as when $G$ is a grid, a tree, or a split graph. Our main contribution is a polynomial-time algorithm for Miniature Painting on graphs that are free of induced co-gems, a graph class that strictly generalizes cographs. As a direct consequence, Free Flood-It is also polynomial-time solvable on co-gem-free graphs, independent of the initial coloring.

</details>


### [493] [Fast $k$-means Seeding Under The Manifold Hypothesis](https://arxiv.org/abs/2602.01104)
*Poojan Shah,Shashwat Agrawal,Ragesh Jaiswal*

Main category: cs.DS

TL;DR: 论文提出Qkmeans方法，基于流形假设和最优量化理论，实现高效k-means聚类，并通过实证验证其性能。


<details>
  <summary>Details</summary>
Motivation: 现有的k-means理论分析依赖于对最优解的特定假设，难以在实际中验证。流形假设作为一种合理假设，能够更好地建模现实世界中的聚类实例。

Method: 通过流形假设和最优量化理论，识别数据集的关键几何特性，设计了一种名为Qkmeans的快速种子方法。

Result: Qkmeans方法在时间O(nD) + ̃O(ε^(1+ρ)ρ^(-1)k^(1+γ))内提供了O(ρ^(-2)logk)的近似解，实现了新的运行时-质量权衡。

Conclusion: 该论文提出了一种基于流形假设的快速种子方法Qkmeans，能够在实际数据中实现高效的k-means聚类，并通过大规模实证研究验证了其理论预测和算法性能。

Abstract: We study beyond worst case analysis for the $k$-means problem where the goal is to model typical instances of $k$-means arising in practice. Existing theoretical approaches provide guarantees under certain assumptions on the optimal solutions to $k$-means, making them difficult to validate in practice. We propose the manifold hypothesis, where data obtained in ambient dimension $D$ concentrates around a low dimensional manifold of intrinsic dimension $d$, as a reasonable assumption to model real world clustering instances. We identify key geometric properties of datasets which have theoretically predictable scaling laws depending on the quantization exponent $\varepsilon = 2/d$ using techniques from optimum quantization theory. We show how to exploit these regularities to design a fast seeding method called $\operatorname{Qkmeans}$ which provides $O(ρ^{-2} \log k)$ approximate solutions to the $k$-means problem in time $O(nD) + \widetilde{O}(\varepsilon^{1+ρ}ρ^{-1}k^{1+γ})$; where the exponent $γ= \varepsilon + ρ$ for an input parameter $ρ< 1$. This allows us to obtain new runtime - quality tradeoffs. We perform a large scale empirical study across various domains to validate our theoretical predictions and algorithm performance to bridge theory and practice for beyond worst case data clustering.

</details>


### [494] [Benchmarking of algorithms for set partitions](https://arxiv.org/abs/2602.01350)
*Arnav Khinvasara,Alexander Pikovski*

Main category: cs.DS

TL;DR: 论文回顾了集合划分问题及其算法，推荐Djokic等人的算法为最佳实践。


<details>
  <summary>Details</summary>
Motivation: 集合划分问题在组合优化任务中具有广泛应用，需要高效的列举方法。

Method: 回顾了多种列举所有集合划分的算法，并进行了基准测试。

Result: 提出了适用于小规模和大规模集合的近似公式，并推荐了Djokic等人的算法。

Conclusion: Djokic等人的算法被推荐为实际应用中的首选。

Abstract: Set partitions are arrangements of distinct objects into groups. The problem of listing all set partitions arises in a variety of settings, in particular in combinatorial optimization tasks. After a brief review, we give practical approximate formulas for determining the number of set partitions, both for small and large set sizes. Several algorithms for enumerating all set partitions are reviewed, and benchmarking tests were conducted. The algorithm of Djokic et al. is recommended for practical use.

</details>


### [495] [A $5$-Approximation Analysis for the Cover Small Cuts Problem](https://arxiv.org/abs/2602.01462)
*Miles Simmons,Ishan Bansal,Joe Cheriyan*

Main category: cs.DS

TL;DR: The paper improves the approximation ratio of the WGMV algorithm for Cover Small Cuts from 6 to 5, using a more robust pliable family of sets with symmetry and submodularity.


<details>
  <summary>Details</summary>
Motivation: The motivation stems from previous research showing the WGMV algorithm's approximation ratios of 16 and 6 for the Cover Small Cuts problem, aiming to further refine and improve this ratio.

Method: The study employs the WGMV primal-dual algorithm, analyzing its performance through the lens of a pliable family of sets that satisfies symmetry and structural submodularity.

Result: The result is an enhanced approximation ratio of 5 for the Cover Small Cuts problem, achieved by the WGMV algorithm under the new analytical framework.

Conclusion: The paper demonstrates that the WGMV primal-dual algorithm achieves an improved approximation ratio of 5 for the Cover Small Cuts problem, leveraging a stronger notion of pliable family of sets with symmetry and structural submodularity.

Abstract: In the Cover Small Cuts problem, we are given a capacitated (undirected) graph $G=(V,E,u)$ and a threshold value $λ$, as well as a set of links $L$ with end-nodes in $V$ and a non-negative cost for each link $\ell\in L$; the goal is to find a minimum-cost set of links such that each non-trivial cut of capacity less than $λ$ is covered by a link. Bansal, Cheriyan, Grout, and Ibrahimpur (arXiv:2209.11209, Algorithmica 2024) showed that the WGMV primal-dual algorithm, due to Williamson, Goemans, Mihail, and Vazirani (Combinatorica, 1995), achieves approximation ratio $16$ for the Cover Small Cuts problem; their analysis uses the notion of a pliable family of sets that satisfies a combinatorial property. Later, Bansal (arXiv:2308.15714v2, IPCO 2025) and then Nutov (arXiv:2504.03910, MFCS 2025) proved that the same algorithm achieves approximation ratio $6$. We show that the same algorithm achieves approximation ratio $5$, by using a stronger notion, namely, a pliable family of sets that satisfies symmetry and structural submodularity.

</details>


### [496] [A polynomial-time algorithm for recognizing high-bandwidth graphs](https://arxiv.org/abs/2602.01755)
*Luis M. B. Varona*

Main category: cs.DS

TL;DR: 论文提出一种基于二分图匹配的算法，利用Hall婚姻定理，解决了带宽识别问题在$k$或$n - k$较小时的效率问题，具有多项式复杂度。


<details>
  <summary>Details</summary>
Motivation: 动态编程技术在$k$接近$n$时变得超指数级复杂，需要更高效的算法来解决带宽识别问题。

Method: 对于足够大的$k \ge \lfloor (n - 1)/2 \rfloor$，将问题重新表述为二分图匹配问题，利用Hall婚姻定理开发算法，时间复杂度为$O(n^{n - k + 1})$，辅助空间复杂度为$O(n)$。

Result: 开发了一种算法，对于接近$n - 1$的$k$具有多项式复杂度，解决了带宽识别问题在$k$或$n - k$较小时的效率问题。

Conclusion: 论文表明，带宽识别问题在$k$或$n - k$较小时可以在多项式时间内解决，通过重新表述问题并利用Hall婚姻定理开发算法。

Abstract: An unweighted, undirected graph $G$ on $n$ nodes is said to have \emph{bandwidth} at most $k$ if its nodes can be labelled from $0$ to $n - 1$ such that no two adjacent nodes have labels that differ by more than $k$. It is known that one can decide whether the bandwidth of $G$ is at most $k$ in $O(n^k)$ time and $O(n^k)$ space using dynamic programming techniques. For small $k$ close to $0$, this approach is effectively polynomial, but as $k$ scales with $n$, it becomes superexponential, requiring up to $O(n^{n - 1})$ time (where $n - 1$ is the maximum possible bandwidth). In this paper, we reformulate the problem in terms of bipartite matching for sufficiently large $k \ge \lfloor (n - 1)/2 \rfloor$, allowing us to use Hall's marriage theorem to develop an algorithm that runs in $O(n^{n - k + 1})$ time and $O(n)$ auxiliary space (beyond storage of the input graph). This yields polynomial complexity for large $k$ close to $n - 1$, demonstrating that the bandwidth recognition problem is solvable in polynomial time whenever either $k$ or $n - k$ remains small.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [497] [MapDream: Task-Driven Map Learning for Vision-Language Navigation](https://arxiv.org/abs/2602.00222)
*Guoxin Lian,Shuo Wang,Yucheng Wang,Yongcai Wang,Maiyue Chen,Kaihui Wang,Bo Zhang,Zhizhong Su,Deying Li,Zhaoxin Fan*

Main category: cs.RO

TL;DR: MapDream提出任务驱动的生成式地图学习方法，通过自回归BEV合成联合优化地图与导航，在VLN任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖独立于导航策略的手工构建地图，而地图应是直接由导航目标塑造的表示，而非详尽重建。

Method: 提出MapDream框架，将地图构建建模为自回归的鸟瞰图（BEV）图像合成，联合学习地图生成和动作预测，并通过强化学习微调实现端到端联合优化。

Result: 在R2R-CE和RxR-CE数据集上实现了最先进的单目性能。

Conclusion: MapDream框架通过任务驱动的生成式地图学习方法，在R2R-CE和RxR-CE数据集上实现了单目视觉导航的领先性能，验证了其有效性。

Abstract: Vision-Language Navigation (VLN) requires agents to follow natural language instructions in partially observed 3D environments, motivating map representations that aggregate spatial context beyond local perception. However, most existing approaches rely on hand-crafted maps constructed independently of the navigation policy. We argue that maps should instead be learned representations shaped directly by navigation objectives rather than exhaustive reconstructions. Based on this insight, we propose MapDream, a map-in-the-loop framework that formulates map construction as autoregressive bird's-eye-view (BEV) image synthesis. The framework jointly learns map generation and action prediction, distilling environmental context into a compact three-channel BEV map that preserves only navigation-critical affordances. Supervised pre-training bootstraps a reliable mapping-to-control interface, while the autoregressive design enables end-to-end joint optimization through reinforcement fine-tuning. Experiments on R2R-CE and RxR-CE achieve state-of-the-art monocular performance, validating task-driven generative map learning.

</details>


### [498] [ZEST: Zero-shot Embodied Skill Transfer for Athletic Robot Control](https://arxiv.org/abs/2602.00401)
*Jean Pierre Sleiman,He Li,Alphonsus Adu-Bredu,Robin Deits,Arun Kumar,Kevin Bergamin,Mohak Bhardwaj,Scott Biddlestone,Nicola Burger,Matthew A. Estrada,Francesco Iacobelli,Twan Koolen,Alexander Lambert,Erica Lin,M. Eva Mungai,Zach Nobles,Shane Rozen-Levy,Yuyao Shi,Jiashun Wang,Jakob Welner,Fangzhou Yu,Mike Zhang,Alfred Rizzi,Jessica Hodgins,Sylvain Bertrand,Yeuhi Abe,Scott Kuindersma,Farbod Farshidian*

Main category: cs.RO

TL;DR: ZEST通过多样化数据源和强化学习，实现机器人技能的零样本迁移，适用于多种机器人平台。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人全身控制的鲁棒性和灵活性挑战，减少对繁琐的控制器调优和技能工程的依赖。

Method: ZEST结合自适应采样和基于模型的辅助力矩自动课程，利用强化学习从运动捕捉、单目视频和动画中训练策略，无需接触标签或状态估计器。

Result: 在Atlas人形机器人、Unitree G1和Spot四足机器人上成功实现了动态多接触技能、舞蹈和场景交互技能的零样本迁移。

Conclusion: ZEST框架通过多样化的数据源和高效的训练方法，实现了在多种人形和四足机器人上的零样本技能迁移，展示了其在生物运动与机器人控制之间的可扩展接口潜力。

Abstract: Achieving robust, human-like whole-body control on humanoid robots for agile, contact-rich behaviors remains a central challenge, demanding heavy per-skill engineering and a brittle process of tuning controllers. We introduce ZEST (Zero-shot Embodied Skill Transfer), a streamlined motion-imitation framework that trains policies via reinforcement learning from diverse sources -- high-fidelity motion capture, noisy monocular video, and non-physics-constrained animation -- and deploys them to hardware zero-shot. ZEST generalizes across behaviors and platforms while avoiding contact labels, reference or observation windows, state estimators, and extensive reward shaping. Its training pipeline combines adaptive sampling, which focuses training on difficult motion segments, and an automatic curriculum using a model-based assistive wrench, together enabling dynamic, long-horizon maneuvers. We further provide a procedure for selecting joint-level gains from approximate analytical armature values for closed-chain actuators, along with a refined model of actuators. Trained entirely in simulation with moderate domain randomization, ZEST demonstrates remarkable generality. On Boston Dynamics' Atlas humanoid, ZEST learns dynamic, multi-contact skills (e.g., army crawl, breakdancing) from motion capture. It transfers expressive dance and scene-interaction skills, such as box-climbing, directly from videos to Atlas and the Unitree G1. Furthermore, it extends across morphologies to the Spot quadruped, enabling acrobatics, such as a continuous backflip, through animation. Together, these results demonstrate robust zero-shot deployment across heterogeneous data sources and embodiments, establishing ZEST as a scalable interface between biological movements and their robotic counterparts.

</details>


### [499] [FISC: A Fluid-Inspired Framework for Decentralized and Scalable Swarm Control](https://arxiv.org/abs/2602.00480)
*Mohini Priya Kolluri,Ammar Waheed,Zohaib Hasnain*

Main category: cs.RO

TL;DR: 提出了一种无需显式通信的分散式流体控制方法，模拟显示大型机器人群体可像连续流体一样运动，与CFD结果高度一致。


<details>
  <summary>Details</summary>
Motivation: 解决大规模机器人群体中依赖通信带来的延迟、带宽限制和脆弱性问题。

Method: 通过将流体基本元素属性与单个机器人状态关联，使群体在空间中像流体一样流动，无需显式通信。该方法在包含约10^3个四旋翼飞行器的模拟中进行了评估，并与计算流体动力学（CFD）解决方案进行了比较。

Result: 通过均方根误差（RMSE）评估，群体衍生场与CFD场在速度、密度和压力上的归一化误差分别为0.15-0.9、0.61-0.98和0-0.937，显示出定量一致性。

Conclusion: 该论文提出了一种基于流体运动范式的分散式控制方法，用于大规模多智能体系统的外环控制，证明了将大型机器人群体视为连续系统的可行性，为可扩展和分散控制提供了基础。

Abstract: Achieving scalable coordination in large robotic swarms is often constrained by reliance on inter-agent communication, which introduces latency, bandwidth limitations, and vulnerability to failure. To address this gap, a decentralized approach for outer-loop control of large multi-agent systems based on the paradigm of how a fluid moves through a volume is proposed and evaluated. A relationship between fundamental fluidic element properties and individual robotic agent states is developed such that the corresponding swarm "flows" through a space, akin to a fluid when forced via a pressure boundary condition. By ascribing fluid-like properties to subsets of agents, the swarm evolves collectively while maintaining desirable structure and coherence without explicit communication of agent states within or outside of the swarm. The approach is evaluated using simulations involving $O(10^3)$ quadcopter agents and compared against Computational Fluid Dynamics (CFD) solutions for a converging-diverging domain. Quantitative agreement between swarm-derived and CFD fields is assessed using Root-Mean-Square Error (RMSE), yielding normalized errors of 0.15-0.9 for velocity, 0.61-0.98 for density, 0-0.937 for pressure. These results demonstrate the feasibility of treating large robotic swarms as continuum systems that retain the macroscopic structure derived from first principles, providing a basis for scalable and decentralized control.

</details>


### [500] [Inject Once Survive Later: Backdooring Vision-Language-Action Models to Persist Through Downstream Fine-tuning](https://arxiv.org/abs/2602.00500)
*Jianyi Zhou,Yujie Wei,Ruichen Zhen,Bo Zhao,Xiaobo Xia,Rui Shao,Xiu Su,Shuo Yang*

Main category: cs.RO

TL;DR: INFUSE是一种针对VLA模型的后门攻击框架，能够在用户微调后仍保持攻击有效性，实验证明其攻击成功率显著高于现有方法。


<details>
  <summary>Details</summary>
Motivation: VLA模型在现代嵌入式AI系统中具有基础性作用，但其安全性尤其是后门攻击的威胁尚未充分探索。现有的后门攻击方法在用户端微调后容易被清除，因此需要一种能够在微调后仍保持有效性的攻击框架。

Method: INFUSE通过分析不同微调场景下的参数敏感性，识别出几乎不变的模块（微调不敏感模块），并将后门植入这些稳定模块中，同时冻结其余模块，以确保恶意行为在用户微调后仍能持续。

Result: INFUSE在多种VLA架构上的实验表明，其在用户微调后仍能保持高攻击成功率（仿真环境91.0%，真实机器人任务79.8%），显著优于现有方法（BadVLA的38.8%和36.6%），同时保持与标准模型相当的清洁任务性能。

Conclusion: INFUSE是一种针对VLA基础模型的后门攻击框架，能够在用户任意微调后仍保持攻击有效性，揭示了预分发植入的后门在微调和部署过程中持续存在的严重威胁。

Abstract: Vision-Language-Action (VLA) models have become foundational to modern embodied AI systems. By integrating visual perception, language understanding, and action planning, they enable general-purpose task execution across diverse environments. Despite their importance, the security of VLA models remains underexplored -- particularly in the context of backdoor attacks, which pose realistic threats in physical-world deployments. While recent methods attempt to inject backdoors into VLA models, these backdoors are easily erased during downstream adaptation, as user-side fine-tuning with clean data significantly alters model parameters, rendering them impractical for real-world applications. To address these challenges, we propose INFUSE (INjection into Fine-tUne-inSensitive modulEs), the first backdoor attack framework for VLA base models that remains effective even with arbitrary user fine-tuning. INFUSE begins by analyzing parameter sensitivity across diverse fine-tuning scenarios to identify modules that remain largely unchanged -- the fine-tune-insensitive modules. It then injects backdoors into these stable modules while freezing the rest, ensuring malicious behavior persists after extensive user fine-tuning. Comprehensive experiments across multiple VLA architectures demonstrate INFUSE's effectiveness. After user-side fine-tuning, INFUSE maintains mean attack success rates of 91.0% on simulation environments and 79.8% on real-world robot tasks, substantially surpassing BadVLA (38.8% and 36.6%, respectively), while preserving clean-task performance comparable to standard models. These results uncover a critical threat: backdoors implanted before distribution can persist through fine-tuning and remain effective at deployment.

</details>


### [501] [A Low-Cost Vision-Based Tactile Gripper with Pretraining Learning for Contact-Rich Manipulation](https://arxiv.org/abs/2602.00514)
*Yaohua Liu,Binkai Ou,Zicheng Qiu,Ce Hao,Yemin Wang,Hengjun Zhang*

Main category: cs.RO

TL;DR: LVTG是一种低成本视觉-触觉抓取器，通过跨模态对齐和模块化设计，显著提升抓取性能和耐用性。


<details>
  <summary>Details</summary>
Motivation: 传统触觉传感器在感应范围、可靠性和成本效益方面存在局限，需要一种更稳定、耐用且高效的触觉-视觉抓取器。

Method: 采用CLIP启发的对比学习目标，将触觉嵌入与视觉观察对齐，创建跨模态表示空间，并结合Action Chunking Transformer (ACT)策略。

Result: 与原始ACT方法相比，LVTG结合预训练在操作任务中实现了显著更高的成功率。

Conclusion: LVTG通过结合视觉和触觉反馈，显著提高了在接触丰富环境中的操作性能，其模块化设计和高耐用性材料进一步增强了实用性。

Abstract: Robotic manipulation in contact-rich environments remains challenging, particularly when relying on conventional tactile sensors that suffer from limited sensing range, reliability, and cost-effectiveness. In this work, we present LVTG, a low-cost visuo-tactile gripper designed for stable, robust, and efficient physical interaction. Unlike existing visuo-tactile sensors, LVTG enables more effective and stable grasping of larger and heavier everyday objects, thanks to its enhanced tactile sensing area and greater opening angle. Its surface skin is made of highly wear-resistant material, significantly improving durability and extending operational lifespan. The integration of vision and tactile feedback allows LVTG to provide rich, high-fidelity sensory data, facilitating reliable perception during complex manipulation tasks. Furthermore, LVTG features a modular design that supports rapid maintenance and replacement. To effectively fuse vision and touch, We adopt a CLIP-inspired contrastive learning objective to align tactile embeddings with their corresponding visual observations, enabling a shared cross-modal representation space for visuo-tactile perception. This alignment improves the performance of an Action Chunking Transformer (ACT) policy in contact-rich manipulation, leading to more efficient data collection and more effective policy learning. Compared to the original ACT method, the proposed LVTG with pretraining achieves significantly higher success rates in manipulation tasks.

</details>


### [502] [APEX: A Decoupled Memory-based Explorer for Asynchronous Aerial Object Goal Navigation](https://arxiv.org/abs/2602.00551)
*Daoxuan Zhang,Ping Chen,Xiaobo Xia,Xiu Su,Ruichen Zhen,Jianqiang Xiao,Shuo Yang*

Main category: cs.RO

TL;DR: APEX是一种新型层次化无人机代理，通过动态地图构建、强化学习决策和开放词汇检测，高效解决空中目标导航挑战。


<details>
  <summary>Details</summary>
Motivation: 现有方法在复杂空中环境中的空间记忆、决策可靠性和探索效率方面存在不足，APEX旨在解决这些问题。

Method: APEX采用模块化三部分架构：1）动态时空语义映射记忆，利用视觉语言模型的零样本能力构建高分辨率3D地图；2）通过强化学习训练的动作决策模块；3）开放词汇检测器实现目标识别。

Result: APEX在UAV-ON基准测试中表现优异，超越了现有最佳方法。

Conclusion: APEX通过其层次化异步设计，在UAV-ON基准测试中显著提升了性能（+4.2% SR和+2.8% SPL），证明了其在复杂空中环境中的高效探索和目标获取能力。

Abstract: Aerial Object Goal Navigation, a challenging frontier in Embodied AI, requires an Unmanned Aerial Vehicle (UAV) agent to autonomously explore, reason, and identify a specific target using only visual perception and language description. However, existing methods struggle with the memorization of complex spatial representations in aerial environments, reliable and interpretable action decision-making, and inefficient exploration and information gathering. To address these challenges, we introduce \textbf{APEX} (Aerial Parallel Explorer), a novel hierarchical agent designed for efficient exploration and target acquisition in complex aerial settings. APEX is built upon a modular, three-part architecture: 1) Dynamic Spatio-Semantic Mapping Memory, which leverages the zero-shot capability of a Vision-Language Model (VLM) to dynamically construct high-resolution 3D Attraction, Exploration, and Obstacle maps, serving as an interpretable memory mechanism. 2) Action Decision Module, trained with reinforcement learning, which translates this rich spatial understanding into a fine-grained and robust control policy. 3) Target Grounding Module, which employs an open-vocabulary detector to achieve definitive and generalizable target identification. All these components are integrated into a hierarchical, asynchronous, and parallel framework, effectively bypassing the VLM's inference latency and boosting the agent's proactivity in exploration. Extensive experiments show that APEX outperforms the previous state of the art by +4.2\% SR and +2.8\% SPL on challenging UAV-ON benchmarks, demonstrating its superior efficiency and the effectiveness of its hierarchical asynchronous design. Our source code is provided in \href{https://github.com/4amGodvzx/apex}{GitHub}

</details>


### [503] [ConLA: Contrastive Latent Action Learning from Human Videos for Robotic Manipulation](https://arxiv.org/abs/2602.00557)
*Weisheng Dai,Kai Lan,Jianyi Zhou,Bo Zhao,Xiu Su,Junwen Tong,Weili Guan,Shuo Yang*

Main category: cs.RO

TL;DR: ConLA通过对比解耦机制从人类视频中学习潜在动作表示，首次超越真实机器人轨迹预训练性能。


<details>
  <summary>Details</summary>
Motivation: 人类演示视频提供了丰富且可扩展的多样化场景和操作行为，但缺乏显式动作监督，直接利用存在困难。

Method: 提出ConLA框架，利用对比解耦机制结合动作类别先验和时间线索，从视觉内容中分离运动动态。

Result: ConLA在多样化基准测试中表现优异，仅通过人类视频预训练即超越真实机器人轨迹预训练的性能。

Conclusion: ConLA通过对比解耦机制从人类视频中学习纯且语义一致的潜在动作表示，首次仅通过人类视频预训练就超越了真实机器人轨迹预训练的性能。

Abstract: Vision-Language-Action (VLA) models achieve preliminary generalization through pretraining on large scale robot teleoperation datasets. However, acquiring datasets that comprehensively cover diverse tasks and environments is extremely costly and difficult to scale. In contrast, human demonstration videos offer a rich and scalable source of diverse scenes and manipulation behaviors, yet their lack of explicit action supervision hinders direct utilization. Prior work leverages VQ-VAE based frameworks to learn latent actions from human videos in an unsupervised manner. Nevertheless, since the training objective primarily focuses on reconstructing visual appearances rather than capturing inter-frame dynamics, the learned representations tend to rely on spurious visual cues, leading to shortcut learning and entangled latent representations that hinder transferability. To address this, we propose ConLA, an unsupervised pretraining framework for learning robotic policies from human videos. ConLA introduces a contrastive disentanglement mechanism that leverages action category priors and temporal cues to isolate motion dynamics from visual content, effectively mitigating shortcut learning. Extensive experiments show that ConLA achieves strong performance across diverse benchmarks. Notably, by pretraining solely on human videos, our method for the first time surpasses the performance obtained with real robot trajectory pretraining, highlighting its ability to extract pure and semantically consistent latent action representations for scalable robot learning.

</details>


### [504] [UniMotion: A Unified Motion Framework for Simulation, Prediction and Planning](https://arxiv.org/abs/2602.00566)
*Nan Song,Junzhe Jiang,Jingyu Li,Xiatian Zhu,Li Zhang*

Main category: cs.RO

TL;DR: UniMotion是一个统一的自动驾驶运动框架，通过Transformer架构实现多任务联合优化，实验验证其泛化能力和性能优越性。


<details>
  <summary>Details</summary>
Motivation: 现有方法因任务隔离而忽略了任务间的潜在互惠关系，导致泛化能力和可扩展性受限。

Method: 基于解码器-仅Transformer架构，采用专用交互模式和定制训练策略，支持多任务联合优化和表示共享。

Result: 在Waymo Open Motion Dataset上的实验表明，联合训练增强了泛化能力和任务整合效果，经微调后在多项运动任务中达到最先进性能。

Conclusion: UniMotion通过统一框架在自动驾驶运动任务中实现了跨任务的泛化和系统可扩展性，并在Waymo Open Motion Dataset上验证了其性能优越性。

Abstract: Motion simulation, prediction and planning are foundational tasks in autonomous driving, each essential for modeling and reasoning about dynamic traffic scenarios. While often addressed in isolation due to their differing objectives, such as generating diverse motion states or estimating optimal trajectories, these tasks inherently depend on shared capabilities: understanding multi-agent interactions, modeling motion behaviors, and reasoning over temporal and spatial dynamics. Despite this underlying commonality, existing approaches typically adopt specialized model designs, which hinders cross-task generalization and system scalability. More critically, this separation overlooks the potential mutual benefits among tasks. Motivated by these observations, we propose UniMotion, a unified motion framework that captures shared structures across motion tasks while accommodating their individual requirements. Built on a decoder-only Transformer architecture, UniMotion employs dedicated interaction modes and tailored training strategies to simultaneously support these motion tasks. This unified design not only enables joint optimization and representation sharing but also allows for targeted fine-tuning to specialize in individual tasks when needed. Extensive experiments on the Waymo Open Motion Dataset demonstrate that joint training leads to robust generalization and effective task integration. With further fine-tuning, UniMotion achieves state-of-the-art performance across a range of motion tasks, establishing it as a versatile and scalable solution for autonomous driving.

</details>


### [505] [Agentic Reward Modeling: Verifying GUI Agent via Online Proactive Interaction](https://arxiv.org/abs/2602.00575)
*Chaoqun Cui,Jing Huang,Shijing Wang,Liming Zheng,Qingchao Kong,Zhixiong Zeng*

Main category: cs.RO

TL;DR: VAGEN框架通过主动交互验证解决GUI代理评估的局限性，实验显示其优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有GUI代理评估方法（如基于规则或LLM作为评判者）存在可扩展性差、无法处理开放任务或部分状态可观测性问题，需转向主动交互验证。

Method: 提出VAGEN框架，利用配备交互工具的验证代理自主规划验证策略并主动探测环境以获取任务完成证据。

Result: 在OSWorld-Verified和AndroidWorld基准测试中，VAGEN相比LLM-as-a-Judge基线显著提高了评估准确性，并通过测试时扩展策略进一步优化性能。

Conclusion: VAGEN框架通过主动交互验证显著提升了GUI代理评估的准确性，克服了传统方法的局限性，并在实验中验证了其优越性。

Abstract: Reinforcement learning with verifiable rewards (RLVR) is pivotal for the continuous evolution of GUI agents, yet existing evaluation paradigms face significant limitations. Rule-based methods suffer from poor scalability and cannot handle open-ended tasks, while LLM-as-a-Judge approaches rely on passive visual observation, often failing to capture latent system states due to partial state observability. To address these challenges, we advocate for a paradigm shift from passive evaluation to Agentic Interactive Verification. We introduce VAGEN, a framework that employs a verifier agent equipped with interaction tools to autonomously plan verification strategies and proactively probe the environment for evidence of task completion. Leveraging the insight that GUI tasks are typically "easy to verify but hard to solve", VAGEN overcomes the bottlenecks of visual limitations. Experimental results on OSWorld-Verified and AndroidWorld benchmarks demonstrate that VAGEN significantly improves evaluation accuracy compared to LLM-as-a-Judge baselines and further enhances performance through test-time scaling strategies.

</details>


### [506] [Factored Reasoning with Inner Speech and Persistent Memory for Evidence-Grounded Human-Robot Interaction](https://arxiv.org/abs/2602.00675)
*Valerio Belcamino,Mariya Kilina,Alessandro Carfì,Valeria Seidita,Fulvio Mastrogiovanni,Antonio Chella*

Main category: cs.RO

TL;DR: JANUS是一种模块化认知架构，通过分解行为和显式策略，实现可扩展、可审计的机器人辅助，测试结果显示高一致性和实用性。


<details>
  <summary>Details</summary>
Motivation: 解决对话式人机交互中需要持久用户上下文、恢复不明确请求、基于外部证据响应并保持决策可验证的问题。

Method: JANUS将行为分解为专用模块（如范围检测、意图识别、记忆等），并采用部分可观察马尔可夫决策过程建模交互，实现具有类型接口的分解控制器。

Result: 在饮食辅助领域的模块级单元测试中，JANUS显示出与参考数据的高一致性和实际延迟性能。

Conclusion: JANUS架构通过模块化设计和显式策略，为可扩展、可审计且基于证据的机器人辅助提供了有前景的路径。

Abstract: Dialogue-based human-robot interaction requires robot cognitive assistants to maintain persistent user context, recover from underspecified requests, and ground responses in external evidence, while keeping intermediate decisions verifiable. In this paper we introduce JANUS, a cognitive architecture for assistive robots that models interaction as a partially observable Markov decision process and realizes control as a factored controller with typed interfaces. To this aim, Janus (i) decomposes the overall behavior into specialized modules, related to scope detection, intent recognition, memory, inner speech, query generation, and outer speech, and (ii) exposes explicit policies for information sufficiency, execution readiness, and tool grounding. A dedicated memory agent maintains a bounded recent-history buffer, a compact core memory, and an archival store with semantic retrieval, coupled through controlled consolidation and revision policies. Models inspired by the notion of inner speech in cognitive theories provide a control-oriented internal textual flow that validates parameter completeness and triggers clarification before grounding, while a faithfulness constraint ties robot-to-human claims to an evidence bundle combining working context and retrieved tool outputs. We evaluate JANUS through module-level unit tests in a dietary assistance domain grounded on a knowledge graph, reporting high agreement with curated references and practical latency profiles. These results support factored reasoning as a promising path to scalable, auditable, and evidence-grounded robot assistance over extended interaction horizons.

</details>


### [507] [Toward Reliable Sim-to-Real Predictability for MoE-based Robust Quadrupedal Locomotion](https://arxiv.org/abs/2602.00678)
*Tianyang Wu,Hanwei Guo,Yuhang Wang,Junshu Yang,Xinyang Sui,Jiayi Xie,Xingyu Chen,Zeyang Liu,Xuguang Lan*

Main category: cs.RO

TL;DR: 提出MoE策略和RoboGauge评估套件，提升四足机器人在复杂地形中的鲁棒运动性能，实验验证了高效迁移和高速运动能力。


<details>
  <summary>Details</summary>
Motivation: 解决sim-to-real差距和奖励过拟合问题，提升四足机器人在复杂地形中的鲁棒性和泛化能力。

Method: 采用Mixture-of-Experts (MoE)策略分解地形和指令建模，结合RoboGauge评估套件量化迁移性能。

Result: 在Unitree Go2上实现了对未见过挑战性地形的鲁棒运动，包括雪地、沙地、楼梯等，最高速度达4 m/s。

Conclusion: 该论文提出的MoE策略和RoboGauge评估套件有效解决了四足机器人在复杂地形中的鲁棒运动问题，显著提升了sim-to-real的迁移性能。

Abstract: Reinforcement learning has shown strong promise for quadrupedal agile locomotion, even with proprioception-only sensing. In practice, however, sim-to-real gap and reward overfitting in complex terrains can produce policies that fail to transfer, while physical validation remains risky and inefficient. To address these challenges, we introduce a unified framework encompassing a Mixture-of-Experts (MoE) locomotion policy for robust multi-terrain representation with RoboGauge, a predictive assessment suite that quantifies sim-to-real transferability. The MoE policy employs a gated set of specialist experts to decompose latent terrain and command modeling, achieving superior deployment robustness and generalization via proprioception alone. RoboGauge further provides multi-dimensional proprioception-based metrics via sim-to-sim tests over terrains, difficulty levels, and domain randomizations, enabling reliable MoE policy selection without extensive physical trials. Experiments on a Unitree Go2 demonstrate robust locomotion on unseen challenging terrains, including snow, sand, stairs, slopes, and 30 cm obstacles. In dedicated high-speed tests, the robot reaches 4 m/s and exhibits an emergent narrow-width gait associated with improved stability at high velocity.

</details>


### [508] [Learning to Accelerate Vision-Language-Action Models through Adaptive Visual Token Caching](https://arxiv.org/abs/2602.00686)
*Yujie Wei,Jiahan Fan,Jiyu Guo,Ruichen Zhen,Rui Shao,Xiu Su,Zeke Xie,Shuo Yang*

Main category: cs.RO

TL;DR: 提出动态任务感知的VLA模型推理加速框架，通过可学习策略优化实现高效推理，显著提升速度与成功率。


<details>
  <summary>Details</summary>
Motivation: 现有加速方法多为启发式或静态策略，无法适应动态场景变化，且与任务目标脱节。因此，需要一种更智能、自适应的加速方法。

Method: 提出了一个动态、任务感知的决策框架，包含两个轻量级协作模块：Cached Token Selector和Cache Ratio Predictor，并通过可微分松弛实现端到端优化。

Result: 在LIBERO和SIMPLER基准测试及真实机器人评估中，方法实现了1.76倍的推理加速，任务成功率分别提升1.9和5.0个百分点。

Conclusion: 本研究通过将推理加速重新定义为可学习的策略优化问题，提出了一种新型框架，显著提升了VLA模型的推理效率，同时提高了任务成功率，为强大且高效的VLA模型铺平了道路。

Abstract: Vision-Language-Action (VLA) models have demonstrated remarkable generalization capabilities in robotic manipulation tasks, yet their substantial computational overhead remains a critical obstacle to real-world deployment. Improving inference efficiency is therefore essential for practical robotic applications. Existing acceleration methods often rely on heuristic or static strategies--such as rule-based token caching or pruning--that are decoupled from task objectives and fail to adapt to dynamic scene changes. In this work, we reformulate inference acceleration as a learnable policy optimization problem and propose a novel framework that integrates a dynamic, task-aware decision-making process directly into the VLA model. At its core are two lightweight, cooperative modules: a Cached Token Selector, which determines which tokens should be reused, and a Cache Ratio Predictor, which controls how many tokens to reuse. Training these modules is non-trivial due to their discrete decisions. We address this by adopting a differentiable relaxation that allows gradient-based end-to-end optimization. Extensive experiments on the LIBERO and SIMPLER benchmarks, as well as real-robot evaluations, show that our method achieves a 1.76x wall-clock inference speedup while simultaneously improving the average success rate by 1.9 percentage points (from 75.0% to 76.9%) on LIBERO and by 5.0 percentage points on real-world tasks, significantly outperforming existing baselines. This work highlights the potential of learning task-aware computational allocation policies, paving the way for VLA models that are both powerful and efficient.

</details>


### [509] [USS-Nav: Unified Spatio-Semantic Scene Graph for Lightweight UAV Zero-Shot Object Navigation](https://arxiv.org/abs/2602.00708)
*Weiqi Gai,Yuman Gao,Yuan Zhou,Yufan Xie,Zhiyang Liu,Yuze Wu,Xin Zhou,Fei Gao,Zhijun Meng*

Main category: cs.RO

TL;DR: USS-Nav是一个轻量级框架，通过增量构建统一空间语义场景图和LLM增强的导航策略，显著提升了无人机在未知环境中的零样本物体导航性能。


<details>
  <summary>Details</summary>
Motivation: 解决无人机在未知环境中进行零样本物体导航时，高级语义推理需求与有限机载计算资源之间的冲突。

Method: 提出了一种轻量级框架USS-Nav，通过增量构建统一空间语义场景图，结合LLM增强的零样本物体导航。具体包括增量空间连通图生成方法和基于图聚类的语义区域动态划分。

Result: 实验结果表明，USS-Nav在资源受限平台上优于现有方法，具有更高的计算效率和实时更新频率。

Conclusion: USS-Nav框架在计算效率和实时更新频率（15 Hz）上优于现有方法，并通过消融研究验证了其有效性，显著提高了SPL（Success weighted by Path Length）。

Abstract: Zero-Shot Object Navigation in unknown environments poses significant challenges for Unmanned Aerial Vehicles (UAVs) due to the conflict between high-level semantic reasoning requirements and limited onboard computational resources. To address this, we present USS-Nav, a lightweight framework that incrementally constructs a Unified Spatio-Semantic scene graph and enables efficient Large Language Model (LLM)-augmented Zero-Shot Object Navigation in unknown environments. Specifically, we introduce an incremental Spatial Connectivity Graph generation method utilizing polyhedral expansion to capture global geometric topology, which is dynamically partitioned into semantic regions via graph clustering. Concurrently, open-vocabulary object semantics are instantiated and anchored to this topology to form a hierarchical environmental representation. Leveraging this hierarchical structure, we present a coarse-to-fine exploration strategy: LLM grounded in the scene graph's semantics to determine global target regions, while a local planner optimizes frontier coverage based on information gain. Experimental results demonstrate that our framework outperforms state-of-the-art methods in terms of computational efficiency and real-time update frequency (15 Hz) on a resource-constrained platform. Furthermore, ablation studies confirm the effectiveness of our framework, showing substantial improvements in Success weighted by Path Length (SPL). The source code will be made publicly available to foster further research.

</details>


### [510] [SA-VLA: Spatially-Aware Flow-Matching for Vision-Language-Action Reinforcement Learning](https://arxiv.org/abs/2602.00743)
*Xu Pan,Zhenglin Wan,Xingrui Yu,Xianwei Zheng,Youkai Ke,Ming Sun,Rui Wang,Ziwei Wang,Ivor Tsang*

Main category: cs.RO

TL;DR: SA-VLA通过空间感知的强化学习框架，解决了VLA模型在微调中空间鲁棒性下降的问题。


<details>
  <summary>Details</summary>
Motivation: 针对VLA模型在强化学习微调中空间归纳偏差被侵蚀导致鲁棒性下降的问题，提出了SA-VLA框架。

Method: SA-VLA融合了隐式空间表示与视觉标记，设计了反映几何进度的密集奖励，并采用了空间条件退火探索策略SCAN。

Result: SA-VLA在多对象和杂乱操作基准测试中实现了稳定的强化学习微调，并提升了零样本空间泛化能力。

Conclusion: SA-VLA框架通过保持空间基础性，显著提升了VLA模型在强化学习微调中的鲁棒性和零样本空间泛化能力。

Abstract: Vision-Language-Action (VLA) models exhibit strong generalization in robotic manipulation, yet reinforcement learning (RL) fine-tuning often degrades robustness under spatial distribution shifts. For flow-matching VLA policies, this degradation is closely associated with the erosion of spatial inductive bias during RL adaptation, as sparse rewards and spatially agnostic exploration increasingly favor short-horizon visual cues. To address this issue, we propose \textbf{SA-VLA}, a spatially-aware RL adaptation framework that preserves spatial grounding during policy optimization by aligning representation learning, reward design, and exploration with task geometry. SA-VLA fuses implicit spatial representations with visual tokens, provides dense rewards that reflect geometric progress, and employs \textbf{SCAN}, a spatially-conditioned annealed exploration strategy tailored to flow-matching dynamics. Across challenging multi-object and cluttered manipulation benchmarks, SA-VLA enables stable RL fine-tuning and improves zero-shot spatial generalization, yielding more robust and transferable behaviors. Code and project page are available at https://xupan.top/Projects/savla.

</details>


### [511] [Physics-informed Diffusion Mamba Transformer for Real-world Driving](https://arxiv.org/abs/2602.00808)
*Hang Zhou,Qiang Zhang,Peiran Liu,Yihao Qin,Zhaoxu Yan,Yiding Ji*

Main category: cs.RO

TL;DR: 提出结合序列上下文和物理约束的扩散模型，显著提升自动驾驶轨迹预测性能。


<details>
  <summary>Details</summary>
Motivation: 解决扩散模型在捕捉长期序列上下文和领域特定物理先验方面的不足。

Method: 引入了Diffusion Mamba Transformer架构和Port-Hamiltonian Neural Network模块，结合了序列上下文和物理约束。

Result: 在标准自动驾驶基准测试中表现优异。

Conclusion: 该论文提出的统一框架在预测准确性、物理合理性和鲁棒性方面显著优于现有基线，推动了安全可靠的运动规划。

Abstract: Autonomous driving systems demand trajectory planners that not only model the inherent uncertainty of future motions but also respect complex temporal dependencies and underlying physical laws. While diffusion-based generative models excel at capturing multi-modal distributions, they often fail to incorporate long-term sequential contexts and domain-specific physical priors. In this work, we bridge these gaps with two key innovations. First, we introduce a Diffusion Mamba Transformer architecture that embeds mamba and attention into the diffusion process, enabling more effective aggregation of sequential input contexts from sensor streams and past motion histories. Second, we design a Port-Hamiltonian Neural Network module that seamlessly integrates energy-based physical constraints into the diffusion model, thereby enhancing trajectory predictions with both consistency and interpretability. Extensive evaluations on standard autonomous driving benchmarks demonstrate that our unified framework significantly outperforms state-of-the-art baselines in predictive accuracy, physical plausibility, and robustness, thereby advancing safe and reliable motion planning.

</details>


### [512] [SyNeT: Synthetic Negatives for Traversability Learning](https://arxiv.org/abs/2602.00814)
*Bomena Kim,Hojun Lee,Younsoo Park,Yaoyu Hu,Sebastian Scherer,Inwook Shim*

Main category: cs.RO

TL;DR: 该论文提出了一种通过显式构建合成负样本来提升自主机器人导航可靠性的方法，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习框架缺乏显式负数据，限制了模型准确识别多样不可通行区域的能力。

Method: 提出了一种将合成负样本无缝集成到基于视觉的可通行性学习中的训练策略，适用于PU和PN框架。

Result: 在公开和自收集数据集上的广泛实验表明，该方法显著增强了模型在不同环境中的鲁棒性和泛化能力。

Conclusion: 该方法通过显式构建合成负样本，显著提升了自主机器人在复杂户外环境中导航的可靠性和泛化能力。

Abstract: Reliable traversability estimation is crucial for autonomous robots to navigate complex outdoor environments safely. Existing self-supervised learning frameworks primarily rely on positive and unlabeled data; however, the lack of explicit negative data remains a critical limitation, hindering the model's ability to accurately identify diverse non-traversable regions. To address this issue, we introduce a method to explicitly construct synthetic negatives, representing plausible but non-traversable, and integrate them into vision-based traversability learning. Our approach is formulated as a training strategy that can be seamlessly integrated into both Positive-Unlabeled (PU) and Positive-Negative (PN) frameworks without modifying inference architectures. Complementing standard pixel-wise metrics, we introduce an object-centric FPR evaluation approach that analyzes predictions in regions where synthetic negatives are inserted. This evaluation provides an indirect measure of the model's ability to consistently identify non-traversable regions without additional manual labeling. Extensive experiments on both public and self-collected datasets demonstrate that our approach significantly enhances robustness and generalization across diverse environments. The source code and demonstration videos are publicly available at the project page: https://anonymous-synet.github.io/SyNet.github.io/

</details>


### [513] [Ocean Current-Harnessing Stage-Gated MPC: Monotone Cost Shaping and Speed-to-Fly for Energy-Efficient AUV Navigation](https://arxiv.org/abs/2602.00823)
*Spyridon Syntakas,Kostas Vlachos*

Main category: cs.RO

TL;DR: A novel MPC method for AUVs that uses ocean currents to cut energy use, tested successfully in simulations.


<details>
  <summary>Details</summary>
Motivation: To overcome the energy efficiency and endurance limitations of AUVs in practical deployments by leveraging ocean currents.

Method: The approach involves a per-stage scalar to gauge current 'helpfulness,' integrating Monotone Cost Shaping and speed-to-fly cost components into the MPC objective function.

Result: Simulations with the BlueROV2 model demonstrate substantially lower energy consumption without compromising arrival times or constraint satisfaction.

Conclusion: Current-Harnessing Stage-Gated MPC significantly reduces energy consumption in AUVs by intelligently utilizing ocean currents, while maintaining performance comparable to conventional methods.

Abstract: Autonomous Underwater Vehicles (AUVs) are a highly promising technology for ocean exploration and diverse offshore operations, yet their practical deployment is constrained by energy efficiency and endurance. To address this, we propose Current-Harnessing Stage-Gated MPC, which exploits ocean currents via a per-stage scalar which indicates the "helpfulness" of ocean currents. This scalar is computed along the prediction horizon to gate lightweight cost terms only where the ocean currents truly aids the control goal. The proposed cost terms, that are merged in the objective function, are (i) a Monotone Cost Shaping (MCS) term, a help-gated, non-worsening modification that relaxes along-track position error and provides a bounded translational energy rebate, guaranteeing the shaped objective is never larger than a set baseline, and (ii) a speed-to-fly (STF) cost component that increases the price of thrust and softly matches ground velocity to the ocean current, enabling near zero water-relative "gliding". All terms are C1 and integrate as a plug-and-play in MPC designs. Extensive simulations with the BlueROV2 model under realistic ocean current fields show that the proposed approach achieves substantially lower energy consumption than conventional predictive control while maintaining comparable arrival times and constraint satisfaction.

</details>


### [514] [Safe Stochastic Explorer: Enabling Safe Goal Driven Exploration in Stochastic Environments and Safe Interaction with Unknown Objects](https://arxiv.org/abs/2602.00868)
*Nikhil Uday Shinde,Dylan Hirsch,Michael C. Yip,Sylvia Herbert*

Main category: cs.RO

TL;DR: 提出Safe Stochastic Explorer框架，通过高斯过程学习未知安全函数，平衡安全与信息收集，适用于离散和连续状态空间，实验验证有效。


<details>
  <summary>Details</summary>
Motivation: 解决当前安全控制方法（如Hamilton-Jacobi可达性和控制屏障函数）假设已知系统动态，以及现有安全探索技术未考虑真实世界环境中不可避免的随机性问题。

Method: 采用高斯过程在线学习未知安全函数，利用其预测不确定性指导信息收集行动，并提供安全违规的概率界限。首先针对离散状态空间环境提出方法，然后引入可扩展的松弛方法扩展到连续状态空间。

Result: 在模拟和硬件实验中验证了方法的有效性，展示了其在复杂不确定环境中的安全探索能力。

Conclusion: Safe Stochastic Explorer (S.S.Explorer) 框架在模拟和硬件实验中展示了其有效性，为复杂不确定环境中的机器人自主性提供了可靠的一步。

Abstract: Autonomous robots operating in unstructured, safety-critical environments, from planetary exploration to warehouses and homes, must learn to safely navigate and interact with their surroundings despite limited prior knowledge. Current methods for safe control, such as Hamilton-Jacobi Reachability and Control Barrier Functions, assume known system dynamics. Meanwhile existing safe exploration techniques often fail to account for the unavoidable stochasticity inherent when operating in unknown real world environments, such as an exploratory rover skidding over an unseen surface or a household robot pushing around unmapped objects in a pantry. To address this critical gap, we propose Safe Stochastic Explorer (S.S.Explorer) a novel framework for safe, goal-driven exploration under stochastic dynamics. Our approach strategically balances safety and information gathering to reduce uncertainty about safety in the unknown environment. We employ Gaussian Processes to learn the unknown safety function online, leveraging their predictive uncertainty to guide information-gathering actions and provide probabilistic bounds on safety violations. We first present our method for discrete state space environments and then introduce a scalable relaxation to effectively extend this approach to continuous state spaces. Finally we demonstrate how this framework can be naturally applied to ensure safe physical interaction with multiple unknown objects. Extensive validation in simulation and demonstrative hardware experiments showcase the efficacy of our method, representing a step forward toward enabling reliable widespread robot autonomy in complex, uncertain environments.

</details>


### [515] [Learning When to Jump for Off-road Navigation](https://arxiv.org/abs/2602.00877)
*Zhipeng Zhao,Taimeng Fu,Shaoshu Su,Qiwei Du,Ehsan Tarkesh Esfahani,Karthik Dantu,Souma Chowdhury,Chen Wang*

Main category: cs.RO

TL;DR: MAT通过动态建模地形成本与速度的关系，优化越野导航路径规划，减少75%绕行并保持安全。


<details>
  <summary>Details</summary>
Motivation: 低速并不总能保证越野驾驶的安全性，现有方法常忽略复杂运动动力学，仅基于位置或固定速度进行路径规划。

Method: 引入Motion-aware Traversability (MAT)表示法，将每个地形区域建模为速度的高斯函数，并分两阶段计算地形成本：1) 通过感知预测地形依赖的高斯参数；2) 根据当前动态推断新速度并高效更新地形成本。

Result: MAT在仿真和真实环境中均实现了实时效率，显著提升了越野导航性能。

Conclusion: MAT通过显式建模地形成本与机器人运动的实际关系，显著提升了越野导航的性能，减少了75%的路径绕行，同时保持了安全性。

Abstract: Low speed does not always guarantee safety in off-road driving. For instance, crossing a ditch may be risky at a low speed due to the risk of getting stuck, yet safe at a higher speed with a controlled, accelerated jump. Achieving such behavior requires path planning that explicitly models complex motion dynamics, whereas existing methods often neglect this aspect and plan solely based on positions or a fixed velocity. To address this gap, we introduce Motion-aware Traversability (MAT) representation to explicitly model terrain cost conditioned on actual robot motion. Instead of assigning a single scalar score for traversability, MAT models each terrain region as a Gaussian function of velocity. During online planning, we decompose the terrain cost computation into two stages: (1) predict terrain-dependent Gaussian parameters from perception in a single forward pass, (2) efficiently update terrain costs for new velocities inferred from current dynamics by evaluating these functions without repeated inference. We develop a system that integrates MAT to enable agile off-road navigation and evaluate it in both simulated and real-world environments with various obstacles. Results show that MAT achieves real-time efficiency and enhances the performance of off-road navigation, reducing path detours by 75% while maintaining safety across challenging terrains.

</details>


### [516] [RoDiF: Robust Direct Fine-Tuning of Diffusion Policies with Corrupted Human Feedback](https://arxiv.org/abs/2602.00886)
*Amitesh Vatsa,Zhixian Xie,Wanxin Jin*

Main category: cs.RO

TL;DR: RoDiF通过统一MDP框架和几何切割策略，解决了扩散策略在人类偏好微调中的挑战，实验显示其鲁棒性和优越性能。


<details>
  <summary>Details</summary>
Motivation: 扩散策略在机器人控制中表现强大，但基于人类偏好的微调因去噪过程的多步结构而面临挑战。

Method: 提出RoDiF方法，通过统一MDP框架将扩散去噪链与环境动态结合，实现无奖励直接偏好优化（DPO），并采用几何假设切割策略处理被污染的人类偏好。

Result: RoDiF在长时程操作任务中 consistently 优于现有基线，能有效引导预训练扩散策略至人类偏好模式。

Conclusion: RoDiF（Robust Direct Fine-Tuning）通过几何假设切割视角重新解释DPO目标，并采用保守切割策略，在不假设特定噪声分布的情况下实现鲁棒性。实验证明，RoDiF在长时程操作任务中表现优异，即使在30%偏好标签被污染的情况下仍能保持强性能。

Abstract: Diffusion policies are a powerful paradigm for robotic control, but fine-tuning them with human preferences is fundamentally challenged by the multi-step structure of the denoising process. To overcome this, we introduce a Unified Markov Decision Process (MDP) formulation that coherently integrates the diffusion denoising chain with environmental dynamics, enabling reward-free Direct Preference Optimization (DPO) for diffusion policies. Building on this formulation, we propose RoDiF (Robust Direct Fine-Tuning), a method that explicitly addresses corrupted human preferences. RoDiF reinterprets the DPO objective through a geometric hypothesis-cutting perspective and employs a conservative cutting strategy to achieve robustness without assuming any specific noise distribution. Extensive experiments on long-horizon manipulation tasks show that RoDiF consistently outperforms state-of-the-art baselines, effectively steering pretrained diffusion policies of diverse architectures to human-preferred modes, while maintaining strong performance even under 30% corrupted preference labels.

</details>


### [517] [UniMorphGrasp: Diffusion Model with Morphology-Awareness for Cross-Embodiment Dexterous Grasp Generation](https://arxiv.org/abs/2602.00915)
*Zhiyuan Wu,Xiangyu Zhang,Zhuo Chen,Jiankang Deng,Rolandos Alexandros Potamias,Shan Luo*

Main category: cs.RO

TL;DR: UniMorphGrasp是一种扩散框架，通过统一的人手姿态表示和结构化手部运动学信息，实现了跨形态机械手的稳定多样抓取生成，并展现出强大的零样本泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常针对特定机械手设计，难以泛化到训练分布外的未见手部形态，因此需要一种能够统一处理不同形态机械手抓取的方法。

Method: 提出了一种基于扩散的框架UniMorphGrasp，将不同机械手的抓取映射到统一的人手姿态表示中，并结合手部运动学的结构化图表示和物体几何信息进行抓取生成。

Result: 实验表明，UniMorphGrasp在现有灵巧抓取基准上达到最先进性能，并能零样本泛化到未见过的机械手结构。

Conclusion: UniMorphGrasp通过统一的跨形态抓取合成框架，显著提升了抓取的稳定性和多样性，并在未见过的机械手结构上展现出强大的零样本泛化能力。

Abstract: Cross-embodiment dexterous grasping aims to generate stable and diverse grasps for robotic hands with heterogeneous kinematic structures. Existing methods are often tailored to specific hand designs and fail to generalize to unseen hand morphologies outside the training distribution. To address these limitations, we propose \textbf{UniMorphGrasp}, a diffusion-based framework that incorporates hand morphological information into the grasp generation process for unified cross-embodiment grasp synthesis. The proposed approach maps grasps from diverse robotic hands into a unified human-like canonical hand pose representation, providing a common space for learning. Grasp generation is then conditioned on structured representations of hand kinematics, encoded as graphs derived from hand configurations, together with object geometry. In addition, a loss function is introduced that exploits the hierarchical organization of hand kinematics to guide joint-level supervision. Extensive experiments demonstrate that UniMorphGrasp achieves state-of-the-art performance on existing dexterous grasp benchmarks and exhibits strong zero-shot generalization to previously unseen hand structures, enabling scalable and practical cross-embodiment grasp deployment.

</details>


### [518] [Green-VLA: Staged Vision-Language-Action Model for Generalist Robots](https://arxiv.org/abs/2602.00919)
*I. Apanasevich,M. Artemyev,R. Babakyan,P. Fedotova,D. Grankin,E. Kupryashin,A. Misailidi,D. Nerus,A. Nutalapati,G. Sidorov,I. Efremov,M. Gerasyov,D. Pikurov,Y. Senchenko,S. Davidenko,D. Kulikov,M. Sultankin,K. Askarbek,O. Shamanin,D. Statovoy,E. Zalyaev,I. Zorin,A. Letkin,E. Rusakov,A. Silchenko,V. Vorobyov,S. Sobolnikov,A. Postnikov*

Main category: cs.RO

TL;DR: Green-VLA是一个五阶段VLA框架，通过统一动作接口和RL对齐，实现了跨机器人实体的泛化与性能提升。


<details>
  <summary>Details</summary>
Motivation: 为解决不同机器人实体间的泛化问题，并提升实际部署中的安全性和目标选择精确性。

Method: 采用五阶段课程学习（L0-L1-R0-R2），结合数据预处理管道（3000小时演示数据）、时间对齐和质量过滤，以及统一的动作接口。

Result: 在Simpler BRIDGE WidowX和CALVIN ABC-D等实验及真实机器人评估中，展示了强泛化能力和RL对齐带来的性能提升。

Conclusion: Green-VLA框架通过五阶段课程学习和统一动作接口，实现了跨多样机器人实体的泛化，并通过RL对齐在成功率、鲁棒性和长时效率上取得了显著性能提升。

Abstract: We introduce Green-VLA, a staged Vision-Language-Action (VLA) framework for real-world deployment on the Green humanoid robot while maintaining generalization across diverse embodiments. Green-VLA follows a five stage curriculum: (L0) foundational VLMs, (L1) multimodal grounding, (R0) multi-embodiment pretraining, (R1) embodiment-specific adaptation, and (R2) reinforcement-learning (RL) policy alignment. We couple a scalable data-processing pipeline (3,000 hours of demonstrations) with temporal alignment and quality filtering, and use a unified, embodiment-aware action interface enabling a single policy to control humanoids, mobile manipulators, and fixed-base arms. At inference, the VLA controller is enhanced with episode-progress prediction, out-of-distribution detection, and joint-prediction-based guidance to improve safety and precise target selection. Experiments on Simpler BRIDGE WidowX and CALVIN ABC-D, as well as real-robot evaluations, show strong generalization and performance gains from RL alignment in success rate, robustness, and long-horizon efficiency.

</details>


### [519] [SanD-Planner: Sample-Efficient Diffusion Planner in B-Spline Space for Robust Local Navigation](https://arxiv.org/abs/2602.00923)
*Jincheng Wang,Lingfan Bao,Tong Yang,Diego Martinez Plasencia,Jianhao Jiao,Dimitrios Kanoulas*

Main category: cs.RO

TL;DR: SanD-Planner是一种高效扩散局部规划器，通过B样条空间模仿学习和ESDF安全检查，在少量数据下实现高性能和零样本迁移。


<details>
  <summary>Details</summary>
Motivation: 解决在高度杂乱和动态环境中生成可靠局部规划的关键瓶颈，如大规模专家演示获取和学习效率提升。

Method: 提出SanD-Planner，一种基于扩散的高效样本局部规划器，在B样条空间中进行深度图像模仿学习，结合ESDF安全检查器。

Result: 仅用500次训练（基线数据的0.25%），SanD-Planner在开放基准测试中达到90.1%（模拟杂乱环境）和72.0%（室内模拟）的成功率。

Conclusion: SanD-Planner在模拟和实际环境中表现出色，展示了零样本迁移能力，并将开源数据集和预训练模型。

Abstract: The challenge of generating reliable local plans has long hindered practical applications in highly cluttered and dynamic environments. Key fundamental bottlenecks include acquiring large-scale expert demonstrations across diverse scenes and improving learning efficiency with limited data. This paper proposes SanD-Planner, a sample-efficient diffusion-based local planner that conducts depth image-based imitation learning within the clamped B-spline space. By operating within this compact space, the proposed algorithm inherently yields smooth outputs with bounded prediction errors over local supports, naturally aligning with receding-horizon execution. Integration of an ESDF-based safety checker with explicit clearance and time-to-completion metrics further reduces the training burden associated with value-function learning for feasibility assessment. Experiments show that training with $500$ episodes (merely $0.25\%$ of the demonstration scale used by the baseline), SanD-Planner achieves state-of-the-art performance on the evaluated open benchmark, attaining success rates of $90.1\%$ in simulated cluttered environments and $72.0\%$ in indoor simulations. The performance is further proven by demonstrating zero-shot transferability to realistic experimentation in both 2D and 3D scenes. The dataset and pre-trained models will also be open-sourced.

</details>


### [520] [Minimal Footprint Grasping Inspired by Ants](https://arxiv.org/abs/2602.00935)
*Mohamed Sorour,Barbara Webb*

Main category: cs.RO

TL;DR: 模仿蚂蚁前腿结构设计的低成本抓取器，在杂乱环境中高效抓取物体，实验验证其广泛适用性。


<details>
  <summary>Details</summary>
Motivation: 蚂蚁在杂乱环境中抓取物体的能力突出，尤其是前腿（特别是跗节）的高摩擦微结构、毛发和柔性欠驱动尖端的功能优势，启发了新型低成本抓取器的设计。

Method: 研究抽象化了蚂蚁前腿的特征（如高摩擦微结构、毛发覆盖和柔性欠驱动尖端），设计了一种长而细的抓取器腿，配备高摩擦抓取垫、低摩擦毛发和单段跗节状结构。

Result: 实验评估表明，该设计能稳健抓取多种消费品物体，所有抓取尝试均成功，且在密集杂乱环境中抓取单个物体也表现优异。

Conclusion: 该研究通过模仿蚂蚁前腿的结构特征，设计了一种低成本、高效的抓取器，适用于杂乱环境中的物体抓取，并揭示了昆虫毛发结构和跗节柔韧性的机械重要性。

Abstract: Ants are highly capable of grasping objects in clutter, and we have recently observed that this involves substantial use of their forelegs. The forelegs, more specifically the tarsi, have high friction microstructures (setal pads), are covered in hairs, and have a flexible under-actuated tip. Here we abstract these features to test their functional advantages for a novel low-cost gripper design, suitable for bin-picking applications. In our implementation, the gripper legs are long and slim, with high friction gripping pads, low friction hairs and single-segment tarsus-like structure to mimic the insect's setal pads, hairs, and the tarsi's interactive compliance. Experimental evaluation shows this design is highly robust for grasping a wide variety of individual consumer objects, with all grasp attempts successful. In addition, we demonstrate this design is effective for picking single objects from dense clutter, a task at which ants also show high competence. The work advances grasping technology and shed new light on the mechanical importance of hairy structures and tarsal flexibility in insects.

</details>


### [521] [CLAMP: Contrastive Learning for 3D Multi-View Action-Conditioned Robotic Manipulation Pretraining](https://arxiv.org/abs/2602.00937)
*I-Chun Arthur Liu,Krzysztof Choromanski,Sandy Huang,Connor Schenck*

Main category: cs.RO

TL;DR: CLAMP是一种新型3D预训练框架，通过点云和对比学习提升机器人操作的精确性，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的2D图像表示无法捕捉对精确操作至关重要的3D空间信息，因此需要开发能更好利用3D信息的预训练框架。

Method: 利用点云和机器人动作，通过对比学习在大规模模拟机器人轨迹上预训练编码器，同时预训练Diffusion Policy以初始化策略权重。

Result: CLAMP在六个模拟任务和五个真实世界任务中表现优于最先进的基线方法。

Conclusion: CLAMP框架通过预训练和微调设计显著提高了学习效率和策略性能，在模拟和真实世界任务中均优于现有基线方法。

Abstract: Leveraging pre-trained 2D image representations in behavior cloning policies has achieved great success and has become a standard approach for robotic manipulation. However, such representations fail to capture the 3D spatial information about objects and scenes that is essential for precise manipulation. In this work, we introduce Contrastive Learning for 3D Multi-View Action-Conditioned Robotic Manipulation Pretraining (CLAMP), a novel 3D pre-training framework that utilizes point clouds and robot actions. From the merged point cloud computed from RGB-D images and camera extrinsics, we re-render multi-view four-channel image observations with depth and 3D coordinates, including dynamic wrist views, to provide clearer views of target objects for high-precision manipulation tasks. The pre-trained encoders learn to associate the 3D geometric and positional information of objects with robot action patterns via contrastive learning on large-scale simulated robot trajectories. During encoder pre-training, we pre-train a Diffusion Policy to initialize the policy weights for fine-tuning, which is essential for improving fine-tuning sample efficiency and performance. After pre-training, we fine-tune the policy on a limited amount of task demonstrations using the learned image and action representations. We demonstrate that this pre-training and fine-tuning design substantially improves learning efficiency and policy performance on unseen tasks. Furthermore, we show that CLAMP outperforms state-of-the-art baselines across six simulated tasks and five real-world tasks.

</details>


### [522] [Meanshift Shape Formation Control Using Discrete Mass Distribution](https://arxiv.org/abs/2602.00980)
*Yichen Cai,Yuan Gao,Pengpeng Li,Wei Wang,Guibin Sun,Jinhu Lü*

Main category: cs.RO

TL;DR: 提出去中心化分布控制策略，通过离散质量分布和均值漂移控制实现复杂形状形成和群体规模适应，实验验证有效。


<details>
  <summary>Details</summary>
Motivation: 现有密度分布方法在实现复杂形状表示和去中心化实施方面面临挑战，需要开发兼具复杂形状形成和群体规模适应能力的策略。

Method: 使用离散质量分布函数建模群体形成，设计去中心化均值漂移控制律，通过反馈质量估计协调全局分布。

Result: 质量估计能渐近收敛到真实全局值，仿真和实际实验验证了复杂形状形成和群体规模适应的效率。

Conclusion: 论文提出了一种完全去中心化的基于分布的控制策略，能够形成复杂形状并适应群体规模变化，通过离散质量分布函数和去中心化均值漂移控制律实现，实验验证了其有效性。

Abstract: The density-distribution method has recently become a promising paradigm owing to its adaptability to variations in swarm size. However, existing studies face practical challenges in achieving complex shape representation and decentralized implementation. This motivates us to develop a fully decentralized, distribution-based control strategy with the dual capability of forming complex shapes and adapting to swarm-size variations. Specifically, we first propose a discrete mass-distribution function defined over a set of sample points to model swarm formation. In contrast to the continuous density-distribution method, our model eliminates the requirement for defining continuous density functions-a task that is difficult for complex shapes. Second, we design a decentralized meanshift control law to coordinate the swarm's global distribution to fit the sample-point distribution by feeding back mass estimates. The mass estimates for all sample points are achieved by the robots in a decentralized manner via the designed mass estimator. It is shown that the mass estimates of the sample points can asymptotically converge to the true global values. To validate the proposed strategy, we conduct comprehensive simulations and real-world experiments to evaluate the efficiency of complex shape formation and adaptability to swarm-size variations.

</details>


### [523] [Geometry-Aware Sampling-Based Motion Planning on Riemannian Manifolds](https://arxiv.org/abs/2602.00992)
*Phone Thiha Kyaw,Jonathan Kelly*

Main category: cs.RO

TL;DR: 提出了一种直接在黎曼流形上进行运动规划的高效方法，通过中点近似和自然梯度优化，显著提升了轨迹规划的质量和效率。


<details>
  <summary>Details</summary>
Motivation: 机器人运动规划中，任务目标和物理约束常导致配置空间呈现非欧几里得几何结构，而现有规划器多忽略这种结构，使用欧几里得距离，导致效率或几何保真度不足。

Method: 引入了一种计算高效的基于中点的黎曼测地距离近似方法，并设计了一个局部规划器，利用一阶回缩和黎曼自然梯度在流形上追踪路径。

Result: 实验表明，该方法在二连杆平面臂和7自由度Franka机械臂的动能度量下，以及在具有非完整运动约束的SE(2)刚体规划中，均能生成比传统方法更低成本的轨迹。

Conclusion: 该论文提出了一种基于采样的运动规划框架，直接在黎曼流形上操作，能够高效计算黎曼测地距离，并通过实验验证了其优于传统欧几里得规划器和数值测地解算器的性能。

Abstract: In many robot motion planning problems, task objectives and physical constraints induce non-Euclidean geometry on the configuration space, yet many planners operate using Euclidean distances that ignore this structure. We address the problem of planning collision-free motions that minimize length under configuration-dependent Riemannian metrics, corresponding to geodesics on the configuration manifold. Conventional numerical methods for computing such paths do not scale well to high-dimensional systems, while sampling-based planners trade scalability for geometric fidelity. To bridge this gap, we propose a sampling-based motion planning framework that operates directly on Riemannian manifolds. We introduce a computationally efficient midpoint-based approximation of the Riemannian geodesic distance and prove that it matches the true Riemannian distance with third-order accuracy. Building on this approximation, we design a local planner that traces the manifold using first-order retractions guided by Riemannian natural gradients. Experiments on a two-link planar arm and a 7-DoF Franka manipulator under a kinetic-energy metric, as well as on rigid-body planning in $\mathrm{SE}(2)$ with non-holonomic motion constraints, demonstrate that our approach consistently produces lower-cost trajectories than Euclidean-based planners and classical numerical geodesic-solver baselines.

</details>


### [524] [HERMES: A Holistic End-to-End Risk-Aware Multimodal Embodied System with Vision-Language Models for Long-Tail Autonomous Driving](https://arxiv.org/abs/2602.00993)
*Weizhe Tang,Junwei You,Jiaxi Liu,Zhaoyi Wang,Rui Gan,Zilin Huang,Feng Wei,Bin Ran*

Main category: cs.RO

TL;DR: HERMES是一个风险感知的多模态驾驶框架，通过整合长尾风险提示和多模态感知，提升自动驾驶在复杂场景中的表现。


<details>
  <summary>Details</summary>
Motivation: 解决自动驾驶模型在长尾混合交通场景中因语义理解不足导致的安全性和准确性挑战。

Method: 提出了一种基于基础模型辅助标注的管道，生成结构化长尾场景和规划上下文，并引入三模态驾驶模块融合多视角感知、历史运动线索和语义指导。

Result: 在真实世界长尾数据集上的实验表明，HERMES在长尾混合交通场景中优于现有端到端和VLM驱动基线。

Conclusion: HERMES框架通过整合长尾风险提示和多模态感知，显著提升了自动驾驶模型在长尾混合交通场景中的安全性和准确性。

Abstract: End-to-end autonomous driving models increasingly benefit from large vision--language models for semantic understanding, yet ensuring safe and accurate operation under long-tail conditions remains challenging. These challenges are particularly prominent in long-tail mixed-traffic scenarios, where autonomous vehicles must interact with heterogeneous road users, including human-driven vehicles and vulnerable road users, under complex and uncertain conditions. This paper proposes HERMES, a holistic risk-aware end-to-end multimodal driving framework designed to inject explicit long-tail risk cues into trajectory planning. HERMES employs a foundation-model-assisted annotation pipeline to produce structured Long-Tail Scene Context and Long-Tail Planning Context, capturing hazard-centric cues together with maneuver intent and safety preference, and uses these signals to guide end-to-end planning. HERMES further introduces a Tri-Modal Driving Module that fuses multi-view perception, historical motion cues, and semantic guidance, ensuring risk-aware accurate trajectory planning under long-tail scenarios. Experiments on the real-world long-tail dataset demonstrate that HERMES consistently outperforms representative end-to-end and VLM-driven baselines under long-tail mixed-traffic scenarios. Ablation studies verify the complementary contributions of key components.

</details>


### [525] [Offline Discovery of Interpretable Skills from Multi-Task Trajectories](https://arxiv.org/abs/2602.01018)
*Chongyu Zhu,Mithun Vanniasinghe,Jiayu Chen,Chi-Guhn Lee*

Main category: cs.RO

TL;DR: LOKI是一个三阶段框架，用于离线技能发现和层次模仿学习，在D4RL Kitchen基准测试中表现优异，技能具有语义意义和组合性。


<details>
  <summary>Details</summary>
Motivation: 解决从长期、多任务离线数据中发现可重用技能的挑战，尤其是在数据缺乏明确奖励或子任务标注的情况下。

Method: LOKI是一个三阶段端到端学习框架，包括两阶段的弱监督技能发现过程（宏观和微观分割）和第三阶段的层次策略构建。

Result: LOKI在D4RL Kitchen基准测试中表现优于标准HIL基线，发现的技能具有语义意义和组合性。

Conclusion: LOKI框架在D4RL Kitchen基准测试中取得了高成功率，并且发现的技能具有语义意义和组合性，能够解决新任务。

Abstract: Hierarchical Imitation Learning is a powerful paradigm for acquiring complex robot behaviors from demonstrations. A central challenge, however, lies in discovering reusable skills from long-horizon, multi-task offline data, especially when the data lacks explicit rewards or subtask annotations. In this work, we introduce LOKI, a three-stage end-to-end learning framework designed for offline skill discovery and hierarchical imitation. The framework commences with a two-stage, weakly supervised skill discovery process: Stage one performs coarse, task-aware macro-segmentation by employing an alignment-enforced Vector Quantized VAE guided by weak task labels. Stage two then refines these segments at a micro-level using a self-supervised sequential model, followed by an iterative clustering process to consolidate skill boundaries. The third stage then leverages these precise boundaries to construct a hierarchical policy within an option-based framework-complete with a learned termination condition beta for explicit skill switching. LOKI achieves high success rates on the challenging D4RL Kitchen benchmark and outperforms standard HIL baselines. Furthermore, we demonstrate that the discovered skills are semantically meaningful, aligning with human intuition, and exhibit compositionality by successfully sequencing them to solve a novel, unseen task.

</details>


### [526] [Learning Adaptive Cross-Embodiment Visuomotor Policy with Contrastive Prompt Orchestration](https://arxiv.org/abs/2602.01040)
*Yuhang Zhang,Chao Yan,Jiaxi Yu,Jiaping Xiao,Mir Feroskhan*

Main category: cs.RO

TL;DR: CAPO通过对比提示学习和自适应提示编排，有效解决跨体现视觉运动策略适应问题，显著提升样本效率和适应能力。


<details>
  <summary>Details</summary>
Motivation: 解决跨体现变化（如不同传感器配置和动态特性）下，传统方法难以分离任务相关特征与领域特定变化（如光照、视野和旋转）的问题，以提高样本效率并避免在新环境中失败。

Method: 提出了一种结合对比提示学习和自适应提示编排的新方法CAPO。通过混合对比学习策略（整合视觉、时序动作和文本目标）建立可学习提示池，并引入自适应提示编排机制动态聚合这些提示。

Result: CAPO在样本效率和渐进性能上显著优于现有基线方法，并在未见过目标域的零样本适应中表现卓越。

Conclusion: CAPO显著优于现有基线方法，在样本效率和渐进性能上表现优异，尤其在面对未见过目标域的零样本适应时展现出卓越能力，验证了其作为跨体现视觉运动策略适应可行解决方案的有效性。

Abstract: Learning adaptive visuomotor policies for embodied agents remains a formidable challenge, particularly when facing cross-embodiment variations such as diverse sensor configurations and dynamic properties. Conventional learning approaches often struggle to separate task-relevant features from domain-specific variations (e.g., lighting, field-of-view, and rotation), leading to poor sample efficiency and catastrophic failure in unseen environments. To bridge this gap, we propose ContrAstive Prompt Orchestration (CAPO), a novel approach for learning visuomotor policies that integrates contrastive prompt learning and adaptive prompt orchestration. For prompt learning, we devise a hybrid contrastive learning strategy that integrates visual, temporal action, and text objectives to establish a pool of learnable prompts, where each prompt induces a visual representation encapsulating fine-grained domain factors. Based on these learned prompts, we introduce an adaptive prompt orchestration mechanism that dynamically aggregates these prompts conditioned on current observations. This enables the agent to adaptively construct optimal state representations by identifying dominant domain factors instantaneously. Consequently, the policy optimization is effectively shielded from irrelevant interference, preventing the common issue of overfitting to source domains. Extensive experiments demonstrate that CAPO significantly outperforms state-of-the-art baselines in sample efficiency and asymptotic performance. Crucially, it exhibits superior zero-shot adaptation across unseen target domains characterized by drastic environmental (e.g., illumination) and physical shifts (e.g., field-of-view and rotation), validating its effectiveness as a viable solution for cross-embodiment visuomotor policy adaptation.

</details>


### [527] [LLM-Based Behavior Tree Generation for Construction Machinery](https://arxiv.org/abs/2602.01041)
*Akinosuke Tsutsumi,Tomoya Itsuka,Yuichiro Kasahara,Tomoya Kouno,Kota Akinari,Genki Yamauchi,Daisuke Endo,Taro Abe,Takeshi Hashimoto,Keiji Nagatani,Ryo Kurazume*

Main category: cs.RO

TL;DR: 本文提出基于LLM的行为树生成工作流，通过同步标志和模板实现复杂施工现场的自动化协调，仿真和实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 面对土方工程日益增长的需求和劳动力老龄化问题，现有ROS2-TMS框架依赖手动设计行为树，限制了异构机器协作的可扩展性。LLM的进展为任务规划和行为树生成提供了新机遇。

Method: 工作流分为两步：高层规划（LLM生成同步标志）和使用结构化模板的行为树生成。通过系统数据库中的参数确保安全性。

Result: 方法在仿真和真实实验中均得到验证，展示了其在复杂施工现场多机器协作中的实际应用潜力。

Conclusion: 本文提出的基于LLM的行为树生成工作流，通过引入同步标志和结构化模板，成功实现了复杂施工现场的自动化协调操作，验证了其在土木工程自动化中的潜力。

Abstract: Earthwork operations are facing an increasing demand, while workforce aging and skill loss create a pressing need for automation. ROS2-TMS for Construction, a Cyber-Physical System framework designed to coordinate construction machinery, has been proposed for autonomous operation; however, its reliance on manually designed Behavior Trees (BTs) limits scalability, particularly in scenarios involving heterogeneous machine cooperation. Recent advances in large language models (LLMs) offer new opportunities for task planning and BT generation. However, most existing approaches remain confined to simulations or simple manipulators, with relatively few applications demonstrated in real-world contexts, such as complex construction sites involving multiple machines. This paper proposes an LLM-based workflow for BT generation, introducing synchronization flags to enable safe and cooperative operation. The workflow consists of two steps: high-level planning, where the LLM generates synchronization flags, and BT generation using structured templates. Safety is ensured by planning with parameters stored in the system database. The proposed method is validated in simulation and further demonstrated through real-world experiments, highlighting its potential to advance automation in civil engineering.

</details>


### [528] [A Systematic Study of Data Modalities and Strategies for Co-training Large Behavior Models for Robot Manipulation](https://arxiv.org/abs/2602.01067)
*Fanqi Lin,Kushal Arora,Jean Mercat,Haruki Nishimura,Paarth Shah,Chen Xu,Mengchao Zhang,Mark Zolotas,Maya Angeles,Owen Pfannenstiehl,Andrew Beaulieu,Jose Barreiros*

Main category: cs.RO

TL;DR: 本文通过大规模实证研究表明，联合训练（尤其是结合视觉语言和跨体现机器人数据）能显著提升机器人策略的泛化能力，为构建通用机器人策略提供指导。


<details>
  <summary>Details</summary>
Motivation: 尽管大型行为模型通过模仿学习在多任务机器人数据上展现出强大的灵巧操作能力，但其泛化能力仍受限于机器人数据覆盖不足。本文旨在探索如何通过联合训练扩展数据覆盖，避免昂贵的数据收集。

Method: 研究利用了4,000小时的机器人及人类操作数据和5,000万视觉语言样本，训练视觉-语言-动作策略，并通过58,000次模拟测试和2,835次真实世界测试评估了89种策略。

Result: 研究发现，联合训练能显著提升策略的泛化能力，尤其是结合视觉语言和跨体现机器人数据时。而离散动作标记变体则无明显益处。

Conclusion: 通过大规模实证研究，本文提供了构建可扩展通用机器人策略的实用指导，表明联合训练（co-training）能显著提升策略在分布偏移、未见任务和语言跟随上的泛化能力。

Abstract: Large behavior models have shown strong dexterous manipulation capabilities by extending imitation learning to large-scale training on multi-task robot data, yet their generalization remains limited by the insufficient robot data coverage. To expand this coverage without costly additional data collection, recent work relies on co-training: jointly learning from target robot data and heterogeneous data modalities. However, how different co-training data modalities and strategies affect policy performance remains poorly understood. We present a large-scale empirical study examining five co-training data modalities: standard vision-language data, dense language annotations for robot trajectories, cross-embodiment robot data, human videos, and discrete robot action tokens across single- and multi-phase training strategies. Our study leverages 4,000 hours of robot and human manipulation data and 50M vision-language samples to train vision-language-action policies. We evaluate 89 policies over 58,000 simulation rollouts and 2,835 real-world rollouts. Our results show that co-training with forms of vision-language and cross-embodiment robot data substantially improves generalization to distribution shifts, unseen tasks, and language following, while discrete action token variants yield no significant benefits. Combining effective modalities produces cumulative gains and enables rapid adaptation to unseen long-horizon dexterous tasks via fine-tuning. Training exclusively on robot data degrades the visiolinguistic understanding of the vision-language model backbone, while co-training with effective modalities restores these capabilities. Explicitly conditioning action generation on chain-of-thought traces learned from co-training data does not improve performance in our simulation benchmark. Together, these results provide practical guidance for building scalable generalist robot policies.

</details>


### [529] [Estimating Force Interactions of Deformable Linear Objects from their Shapes](https://arxiv.org/abs/2602.01085)
*Qi Jing Chen,Shilin Shan,Timothy Bretl,Quang-Cuong Pham*

Main category: cs.RO

TL;DR: 提出一种仅通过线形状信息检测和估计外部力的方法，无需外部传感器或特定接触点假设，仿真和实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 在机器人-线交互任务中，接触点常位于线体而非末端执行器，准确识别这些交互对安全和高效的轨迹规划至关重要。现有方法依赖昂贵的外部传感器或假设接触点位于末端执行器。

Method: 利用深度相机获取的线形状信息，在假设线处于或接近静态平衡的条件下，通过推导一致性条件并求解基于力-扭矩平衡的线性方程组，估计外部力的位置和大小。

Result: 仿真验证中达到高精度，真实实验中在选定交互场景下展示了准确的估计能力。

Conclusion: 该方法通过仅利用可变形线性物体的形状信息，成功实现了对外部力的检测和估计，无需依赖昂贵的力-扭矩传感器或假设接触点位于末端执行器。

Abstract: This work introduces an analytical approach for detecting and estimating external forces acting on deformable linear objects (DLOs) using only their observed shapes. In many robot-wire interaction tasks, contact occurs not at the end-effector but at other points along the robot's body. Such scenarios arise when robots manipulate wires indirectly (e.g., by nudging) or when wires act as passive obstacles in the environment. Accurately identifying these interactions is crucial for safe and efficient trajectory planning, helping to prevent wire damage, avoid restricted robot motions, and mitigate potential hazards. Existing approaches often rely on expensive external force-torque sensor or that contacts occur at the end-effector for accurate force estimation. Using wire shape information acquired from a depth camera and under the assumption that the wire is in or near its static equilibrium, our method estimates both the location and magnitude of external forces without additional prior knowledge. This is achieved by exploiting derived consistency conditions and solving a system of linear equations based on force-torque balance along the wire. The approach was validated through simulation, where it achieved high accuracy, and through real-world experiments, where accurate estimation was demonstrated in selected interaction scenarios.

</details>


### [530] [Failure-Aware Bimanual Teleoperation via Conservative Value Guided Assistance](https://arxiv.org/abs/2602.01092)
*Peng Zhou,Zhongxuan Li,Jinsong Wu,Jiaming Qi,Jun Hu,David Navarro-Alarcon,Jia Pan,Lihua Xie,Shiyao Zhang,Zeqing Zhang*

Main category: cs.RO

TL;DR: 该论文提出了一种价值引导、故障感知的双边遥操作框架，通过保守价值学习和关节空间阻抗接口，有效提升了操作成功率和操作员体验。


<details>
  <summary>Details</summary>
Motivation: 高精度操作的遥操作受限于严格的成功容忍度和复杂的接触动力学，使得人类操作员在部分可观测性下难以预见即将发生的故障。

Method: 框架利用异构离线遥操作数据进行训练，通过保守价值学习建模任务可行性，并在在线操作中通过关节空间阻抗接口整合学习到的成功评分和动作方向。

Result: 实验结果表明，相比传统遥操作和共享自主基线，该方法在接触丰富的操作任务中提高了任务成功率并减少了操作员的工作负担。

Conclusion: 该论文提出的价值引导、故障感知框架通过保守价值学习有效提升了双边遥操作的成功率，并降低了操作员的工作负担。

Abstract: Teleoperation of high-precision manipulation is con-strained by tight success tolerances and complex contact dy-namics, which make impending failures difficult for human operators to anticipate under partial observability. This paper proposes a value-guided, failure-aware framework for bimanual teleoperation that provides compliant haptic assistance while pre-serving continuous human authority. The framework is trained entirely from heterogeneous offline teleoperation data containing both successful and failed executions. Task feasibility is mod-eled as a conservative success score learned via Conservative Value Learning, yielding a risk-sensitive estimate that remains reliable under distribution shift. During online operation, the learned success score regulates the level of assistance, while a learned actor provides a corrective motion direction. Both are integrated through a joint-space impedance interface on the master side, yielding continuous guidance that steers the operator away from failure-prone actions without overriding intent. Experimental results on contact-rich manipulation tasks demonstrate improved task success rates and reduced operator workload compared to conventional teleoperation and shared-autonomy baselines, indicating that conservative value learning provides an effective mechanism for embedding failure awareness into bilateral teleoperation. Experimental videos are available at https://www.youtube.com/watch?v=XDTsvzEkDRE

</details>


### [531] [StreamVLA: Breaking the Reason-Act Cycle via Completion-State Gating](https://arxiv.org/abs/2602.01100)
*Hang Wu,Tongqing Chen,Jiasen Wang,Xiaotao Li,Lu Fang*

Main category: cs.RO

TL;DR: StreamVLA通过智能调节计算的双系统架构，显著提升机器人操作的效率和成功率，减少延迟。


<details>
  <summary>Details</summary>
Motivation: 解决当前VLA模型在高延迟和目标不稳定性方面的问题，通过分离高层规划和低层控制，提升机器人操作的效率和鲁棒性。

Method: 采用双系统架构，结合文本任务分解、视觉目标想象和连续动作生成，引入“Lock-and-Gated”机制智能调节计算，仅在子任务转换时触发慢思考。

Result: 在LIBERO基准测试中达到98.5%的成功率，实时干扰场景中表现鲁棒，延迟相比基线减少48%。

Conclusion: StreamVLA通过其双系统架构和“Lock-and-Gated”机制，显著提高了长时程机器人操作的效率和鲁棒性，实现了低延迟和高成功率。

Abstract: Long-horizon robotic manipulation requires bridging the gap between high-level planning (System 2) and low-level control (System 1). Current Vision-Language-Action (VLA) models often entangle these processes, performing redundant multimodal reasoning at every timestep, which leads to high latency and goal instability. To address this, we present StreamVLA, a dual-system architecture that unifies textual task decomposition, visual goal imagination, and continuous action generation within a single parameter-efficient backbone. We introduce a "Lock-and-Gated" mechanism to intelligently modulate computation: only when a sub-task transition is detected, the model triggers slow thinking to generate a textual instruction and imagines the specific visual completion state, rather than generic future frames. Crucially, this completion state serves as a time-invariant goal anchor, making the policy robust to execution speed variations. During steady execution, these high-level intents are locked to condition a Flow Matching action head, allowing the model to bypass expensive autoregressive decoding for 72% of timesteps. This hierarchical abstraction ensures sub-goal focus while significantly reducing inference latency. Extensive evaluations demonstrate that StreamVLA achieves state-of-the-art performance, with a 98.5% success rate on the LIBERO benchmark and robust recovery in real-world interference scenarios, achieving a 48% reduction in latency compared to full-reasoning baselines.

</details>


### [532] [KAN We Flow? Advancing Robotic Manipulation with 3D Flow Matching via KAN & RWKV](https://arxiv.org/abs/2602.01115)
*Zhihao Chen,Yiyuan Ge,Ziyang Wang*

Main category: cs.RO

TL;DR: KAN-We-Flow利用RWKV和KAN技术构建轻量级流匹配策略，显著提升效率并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决扩散型视觉运动策略在推理效率上的不足，避免使用资源密集型UNet架构，以适应资源受限的机器人部署需求。

Method: 采用RWKV-KAN块结构，结合时间/通道混合和基于样条的分组功能映射，以及引入动作一致性正则化（ACR）辅助损失来稳定训练和提高策略精度。

Result: 参数减少了86.8%，保持了快速运行时间，并在Adroit、Meta-World和DexArt基准测试中取得了最先进的成功率。

Conclusion: KAN-We-Flow通过结合RWKV和KAN技术，设计了一个轻量级且高效的流匹配策略，显著减少了参数数量并保持了快速运行时间，同时在多个基准测试中达到了最先进的成功率。

Abstract: Diffusion-based visuomotor policies excel at modeling action distributions but are inference-inefficient, since recursively denoising from noise to policy requires many steps and heavy UNet backbones, which hinders deployment on resource-constrained robots. Flow matching alleviates the sampling burden by learning a one-step vector field, yet prior implementations still inherit large UNet-style architectures. In this work, we present KAN-We-Flow, a flow-matching policy that draws on recent advances in Receptance Weighted Key Value (RWKV) and Kolmogorov-Arnold Networks (KAN) from vision to build a lightweight and highly expressive backbone for 3D manipulation. Concretely, we introduce an RWKV-KAN block: an RWKV first performs efficient time/channel mixing to propagate task context, and a subsequent GroupKAN layer applies learnable spline-based, groupwise functional mappings to perform feature-wise nonlinear calibration of the action mapping on RWKV outputs. Moreover, we introduce an Action Consistency Regularization (ACR), a lightweight auxiliary loss that enforces alignment between predicted action trajectories and expert demonstrations via Euler extrapolation, providing additional supervision to stabilize training and improve policy precision. Without resorting to large UNets, our design reduces parameters by 86.8\%, maintains fast runtime, and achieves state-of-the-art success rates on Adroit, Meta-World, and DexArt benchmarks. Our project page can be viewed in \href{https://zhihaochen-2003.github.io/KAN-We-Flow.github.io/}{\textcolor{red}{link}}

</details>


### [533] [UniForce: A Unified Latent Force Model for Robot Manipulation with Diverse Tactile Sensors](https://arxiv.org/abs/2602.01153)
*Zhuo Chen,Fei Ni,Kaiyao Luo,Zhiyuan Wu,Xuyang Zhang,Emmanouil Spyrakos-Papastavridis,Lorenzo Jamone,Nathan F. Lepora,Jiankang Deng,Shan Luo*

Main category: cs.RO

TL;DR: UniForce是一种统一的触觉表示学习框架，通过共享潜在力空间解决异构触觉传感器的通用性问题，实现零样本迁移和跨传感器协调。


<details>
  <summary>Details</summary>
Motivation: 解决异构触觉传感器（如光学与磁性传感器）在力感知策略学习中的通用性问题，避免传感器特定的数据收集、校准和模型训练。

Method: UniForce采用联合建模逆动力学（图像到力）和正向动力学（力到图像）的方法，通过力平衡和图像重建损失约束，学习共享的潜在力空间。

Result: 在GelSight、TacTip和uSkin等异构触觉传感器上的实验表明，UniForce在力估计方面优于现有方法，并支持视觉-触觉-语言-动作（VTLA）模型中的跨传感器协调。

Conclusion: UniForce框架通过统一的触觉表示学习，显著提升了异构触觉传感器之间的力估计性能，并实现了零样本迁移，无需重新训练或微调。

Abstract: Force sensing is essential for dexterous robot manipulation, but scaling force-aware policy learning is hindered by the heterogeneity of tactile sensors. Differences in sensing principles (e.g., optical vs. magnetic), form factors, and materials typically require sensor-specific data collection, calibration, and model training, thereby limiting generalisability. We propose UniForce, a novel unified tactile representation learning framework that learns a shared latent force space across diverse tactile sensors. UniForce reduces cross-sensor domain shift by jointly modeling inverse dynamics (image-to-force) and forward dynamics (force-to-image), constrained by force equilibrium and image reconstruction losses to produce force-grounded representations. To avoid reliance on expensive external force/torque (F/T) sensors, we exploit static equilibrium and collect force-paired data via direct sensor--object--sensor interactions, enabling cross-sensor alignment with contact force. The resulting universal tactile encoder can be plugged into downstream force-aware robot manipulation tasks with zero-shot transfer, without retraining or finetuning. Extensive experiments on heterogeneous tactile sensors including GelSight, TacTip, and uSkin, demonstrate consistent improvements in force estimation over prior methods, and enable effective cross-sensor coordination in Vision-Tactile-Language-Action (VTLA) models for a robotic wiping task. Code and datasets will be released.

</details>


### [534] [Latent Reasoning VLA: Latent Thinking and Prediction for Vision-Language-Action Models](https://arxiv.org/abs/2602.01166)
*Shuanghao Bai,Jing Lyu,Wanqi Zhou,Zhe Li,Dakai Wang,Lei Xing,Xiaoguang Zhao,Pengwei Wang,Zhongyuan Wang,Cheng Chi,Badong Chen,Shanghang Zhang*

Main category: cs.RO

TL;DR: LaRA-VLA通过潜在推理实现高效实时控制，性能优于现有方法且延迟降低90%。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型推理开销高且依赖离散表示，与连续感知和控制不匹配。

Method: 提出了LaRA-VLA框架，采用基于课程学习的训练范式，逐步从显式监督过渡到潜在推理，并适应动作生成。

Result: 实验表明LaRA-VLA在推理延迟降低90%的同时，性能优于现有方法。

Conclusion: LaRA-VLA通过将多模态思维链推理内化为连续潜在表示，显著提升了推理效率，并在仿真和真实机器人任务中表现优于现有方法。

Abstract: Vision-Language-Action (VLA) models benefit from chain-of-thought (CoT) reasoning, but existing approaches incur high inference overhead and rely on discrete reasoning representations that mismatch continuous perception and control. We propose Latent Reasoning VLA (\textbf{LaRA-VLA}), a unified VLA framework that internalizes multi-modal CoT reasoning into continuous latent representations for embodied action. LaRA-VLA performs unified reasoning and prediction in latent space, eliminating explicit CoT generation at inference time and enabling efficient, action-oriented control. To realize latent embodied reasoning, we introduce a curriculum-based training paradigm that progressively transitions from explicit textual and visual CoT supervision to latent reasoning, and finally adapts latent reasoning dynamics to condition action generation. We construct two structured CoT datasets and evaluate LaRA-VLA on both simulation benchmarks and long-horizon real-robot manipulation tasks. Experimental results show that LaRA-VLA consistently outperforms state-of-the-art VLA methods while reducing inference latency by up to 90\% compared to explicit CoT-based approaches, demonstrating latent reasoning as an effective and efficient paradigm for real-time embodied control. Project Page: \href{https://loveju1y.github.io/Latent-Reasoning-VLA/}{LaRA-VLA Website}.

</details>


### [535] [SPOT: Spatio-Temporal Obstacle-free Trajectory Planning for UAVs in an Unknown Dynamic Environment](https://arxiv.org/abs/2602.01189)
*Astik Srivastava,Thomas J Chackenkulam. Bitla Bhanu Teja,Antony Thomas,Madhava Krishna*

Main category: cs.RO

TL;DR: 无地图4D时空规划器结合视觉避障，提升无人机在动态未知环境中的反应性导航。


<details>
  <summary>Details</summary>
Motivation: 解决四旋翼无人机在未知动态环境中反应性运动规划的问题，减少计算开销并直接从感知实现避障。

Method: 采用4维时空规划器，集成视觉安全飞行走廊生成和轨迹优化，并引入备用规划模块以应对死锁情况。

Result: 在仿真和真实硬件实验中验证了方法的有效性，相比现有方法在动态未知环境中表现出显著优势。

Conclusion: 该论文提出了一种无地图的四维时空规划器，结合视觉安全飞行走廊生成和轨迹优化，显著提升了四旋翼无人机在未知动态环境中的反应性导航能力。

Abstract: We address the problem of reactive motion planning for quadrotors operating in unknown environments with dynamic obstacles. Our approach leverages a 4-dimensional spatio-temporal planner, integrated with vision-based Safe Flight Corridor (SFC) generation and trajectory optimization. Unlike prior methods that rely on map fusion, our framework is mapless, enabling collision avoidance directly from perception while reducing computational overhead. Dynamic obstacles are detected and tracked using a vision-based object segmentation and tracking pipeline, allowing robust classification of static versus dynamic elements in the scene. To further enhance robustness, we introduce a backup planning module that reactively avoids dynamic obstacles when no direct path to the goal is available, mitigating the risk of collisions during deadlock situations. We validate our method extensively in both simulation and real-world hardware experiments, and benchmark it against state-of-the-art approaches, showing significant advantages for reactive UAV navigation in dynamic, unknown environments.

</details>


### [536] [Bridging the Sim-to-Real Gap with multipanda ros2: A Real-Time ROS2 Framework for Multimanual Systems](https://arxiv.org/abs/2602.02269)
*Jon Škerlj,Seongjin Bien,Abdeldjallil Naceri,Sami Haddadin*

Main category: cs.RO

TL;DR: 开源ROS2架构$multipanda\\_ros2$支持多机器人实时控制，实现1kHz频率和快速控制器切换，集成高保真模拟缩小仿真与现实差距。


<details>
  <summary>Details</summary>
Motivation: 解决多机器人实时控制中的高频率要求和仿真与现实的差距问题，为复杂多机器人交互和接触密集型任务提供可靠平台。

Method: 利用ros2 control框架，设计了支持1kHz控制频率的架构，并引入controllet-feature设计模式实现快速控制器切换。集成MuJoCo高保真模拟，结合动力学一致性指标和惯性参数识别方法。

Result: 实现了$\le 2$ ms的控制器切换延迟，1kHz的实时控制频率，并通过惯性参数识别提升了力和扭矩的准确性。

Conclusion: $multipanda\\_ros2$ 提供了一个强大的开源ROS2架构，支持多机器人控制，解决了实时扭矩控制和高频率控制的关键挑战，并通过高保真模拟和参数识别显著缩小了仿真与现实的差距。

Abstract: We present $multipanda\_ros2$, a novel open-source ROS2 architecture for multi-robot control of Franka Robotics robots. Leveraging ros2 control, this framework provides native ROS2 interfaces for controlling any number of robots from a single process. Our core contributions address key challenges in real-time torque control, including interaction control and robot-environment modeling. A central focus of this work is sustaining a 1kHz control frequency, a necessity for real-time control and a minimum frequency required by safety standards. Moreover, we introduce a controllet-feature design pattern that enables controller-switching delays of $\le 2$ ms, facilitating reproducible benchmarking and complex multi-robot interaction scenarios. To bridge the simulation-to-reality (sim2real) gap, we integrate a high-fidelity MuJoCo simulation with quantitative metrics for both kinematic accuracy and dynamic consistency (torques, forces, and control errors). Furthermore, we demonstrate that real-world inertial parameter identification can significantly improve force and torque accuracy, providing a methodology for iterative physics refinement. Our work extends approaches from soft robotics to rigid dual-arm, contact-rich tasks, showcasing a promising method to reduce the sim2real gap and providing a robust, reproducible platform for advanced robotics research.

</details>


### [537] [SkySim: A ROS2-based Simulation Environment for Natural Language Control of Drone Swarms using Large Language Models](https://arxiv.org/abs/2602.01226)
*Aditya Shibu,Marah Saleh,Mohamed Al-Musleh,Nidhal Abdulaziz*

Main category: cs.RO

TL;DR: SkySim是一个ROS2仿真框架，结合LLM和APF安全过滤器，实现无人机群的自然语言控制与安全执行，实验验证了其有效性和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 无人机群在物流、农业和监视等领域有广泛应用，但传统静态方法缺乏适应性，而大型语言模型（LLM）的自然语言控制因缺乏物理基础可能生成不安全轨迹。

Method: SkySim是一个基于ROS2和Gazebo的仿真框架，利用Gemini 3.5 Pro将用户指令（如“形成圆形”）转换为空间路径点，并通过人工势场（APF）安全过滤器进行碰撞避免、运动学限制和地理围栏的最小调整。

Result: 实验验证了SkySim在3、10和30架Crazyflie无人机群中的空间推理准确性（测试几何基元100%准确）、实时碰撞预防和可扩展性。

Conclusion: SkySim框架成功地将大型语言模型（LLM）的高层规划与低层安全执行解耦，通过实验验证了其在无人机群控制中的空间推理准确性、实时碰撞预防和可扩展性，为非专家用户提供了动态环境下的安全控制能力。

Abstract: Unmanned Aerial Vehicle (UAV) swarms offer versatile applications in logistics, agriculture, and surveillance, yet controlling them requires expert knowledge for safety and feasibility. Traditional static methods limit adaptability, while Large Language Models (LLMs) enable natural language control but generate unsafe trajectories due to lacking physical grounding. This paper introduces SkySim, a ROS2-based simulation framework in Gazebo that decouples LLM high-level planning from low-level safety enforcement. Using Gemini 3.5 Pro, SkySim translates user commands (e.g., "Form a circle") into spatial waypoints, informed by real-time drone states. An Artificial Potential Field (APF) safety filter applies minimal adjustments for collision avoidance, kinematic limits, and geo-fencing, ensuring feasible execution at 20 Hz. Experiments with swarms of 3, 10, and 30 Crazyflie drones validate spatial reasoning accuracy (100% across tested geometric primitives), real-time collision prevention, and scalability. SkySim empowers non-experts to iteratively refine behaviors, bridging AI cognition with robotic safety for dynamic environments. Future work targets hardware integration.

</details>


### [538] [Reinforcement Learning for Active Perception in Autonomous Navigation](https://arxiv.org/abs/2602.01266)
*Grzegorz Malczyk,Mihir Kulkarni,Kostas Alexis*

Main category: cs.RO

TL;DR: 本文提出一种强化学习框架，结合主动相机控制与导航，在复杂环境中实现更安全的自主飞行及探索行为。


<details>
  <summary>Details</summary>
Motivation: 解决复杂未知环境中自主导航的主动感知挑战，通过主动控制机载相机提升情境感知能力，以实现更安全的飞行和内在的探索行为。

Method: 采用端到端强化学习框架，通过增强导航奖励（基于体素的信息度量），将机器人的状态、当前深度帧及局部几何表示作为观察输入，训练机器人学习平衡目标导向运动与探索性感知的策略。

Result: 实验评估表明，相比固定非驱动相机基线，该策略实现了更安全的飞行，并成功诱导出探索行为。

Conclusion: 本文提出的端到端强化学习框架成功地将碰撞自由运动规划与信息驱动的主动相机控制相结合，实现了在复杂未知环境中更安全的自主导航，并诱导出内在的探索行为。

Abstract: This paper addresses the challenge of active perception within autonomous navigation in complex, unknown environments. Revisiting the foundational principles of active perception, we introduce an end-to-end reinforcement learning framework in which a robot must not only reach a goal while avoiding obstacles, but also actively control its onboard camera to enhance situational awareness. The policy receives observations comprising the robot state, the current depth frame, and a particularly local geometry representation built from a short history of depth readings. To couple collision-free motion planning with information-driven active camera control, we augment the navigation reward with a voxel-based information metric. This enables an aerial robot to learn a robust policy that balances goal-directed motion with exploratory sensing. Extensive evaluation demonstrates that our strategy achieves safer flight compared to using fixed, non-actuated camera baselines while also inducing intrinsic exploratory behaviors.

</details>


### [539] [TriphiBot: A Triphibious Robot Combining FOC-based Propulsion with Eccentric Design](https://arxiv.org/abs/2602.01385)
*Xiangyu Li,Mingwei Lai,Mengke Zhang,Junxiao Lin,Tiancheng Lai,Junping Zhi,Chao Xu,Fei Gao,Yanjun Cao*

Main category: cs.RO

TL;DR: 提出一种新型三栖机器人，通过极简设计和偏心重心设计提高效率，开发统一推进系统解决不同流体控制差异，实验验证其多域运动和跨模式转换能力。


<details>
  <summary>Details</summary>
Motivation: 现有设计多专注于双模式平台，部分设计存在机械复杂度高或推进效率低的问题，限制了其应用。

Method: 采用极简设计，结合四旋翼结构和两个被动轮，无需额外执行器；引入偏心重心设计以提高地面支撑运动效率；开发基于场定向控制（FOC）的统一推进系统；提出混合非线性模型预测控制（HNMPC）-PID控制系统。

Result: 实验验证了机器人的多域运动和跨模式转换能力，以及推进系统的效率和适应性。

Conclusion: 实验验证了该机器人具备多域运动和跨模式转换能力，以及所提出的推进系统的效率和适应性。

Abstract: Triphibious robots capable of multi-domain motion and cross-domain transitions are promising to handle complex tasks across diverse environments. However, existing designs primarily focus on dual-mode platforms, and some designs suffer from high mechanical complexity or low propulsion efficiency, which limits their application. In this paper, we propose a novel triphibious robot capable of aerial, terrestrial, and aquatic motion, by a minimalist design combining a quadcopter structure with two passive wheels, without extra actuators. To address inefficiency of ground-support motion (moving on land/seabed) for quadcopter based designs, we introduce an eccentric Center of Gravity (CoG) design that inherently aligns thrust with motion, enhancing efficiency without specialized mechanical transformation designs. Furthermore, to address the drastic differences in motion control caused by different fluids (air and water), we develop a unified propulsion system based on Field-Oriented Control (FOC). This method resolves torque matching issues and enables precise, rapid bidirectional thrust across different mediums. Grounded in the perspective of living condition and ground support, we analyse the robot's dynamics and propose a Hybrid Nonlinear Model Predictive Control (HNMPC)-PID control system to ensure stable multi-domain motion and seamless transitions. Experimental results validate the robot's multi-domain motion and cross-mode transition capability, along with the efficiency and adaptability of the proposed propulsion system.

</details>


### [540] [Instance-Guided Unsupervised Domain Adaptation for Robotic Semantic Segmentation](https://arxiv.org/abs/2602.01389)
*Michele Antonazzi,Lorenzo Signorelli,Matteo Luperto,Nicola Basilico*

Main category: cs.RO

TL;DR: 提出一种结合3D地图和基础模型的方法，优化伪标签并提升语义分割网络在目标域的性能，无需真实标签。


<details>
  <summary>Details</summary>
Motivation: 语义分割网络在部署环境与训练数据分布不同时性能下降，传统UDA方法在多视角一致性上存在实例级不一致的敏感性问题。

Method: 提出了一种基于3D地图生成多视角一致伪标签的方法，并利用基础模型的零样本实例分割能力进行标签优化，实现实例级一致性。优化的标签用于自监督微调。

Result: 实验证明，该方法在真实数据上优于基于多视角一致性的最先进UDA基线，无需目标域的真实标签。

Conclusion: 该方法通过利用3D地图生成多视角一致的伪标签，并结合基础模型的零样本实例分割能力，显著提升了语义分割网络在目标域的性能，无需目标域的真实标签。

Abstract: Semantic segmentation networks, which are essential for robotic perception, often suffer from performance degradation when the visual distribution of the deployment environment differs from that of the source dataset on which they were trained. Unsupervised Domain Adaptation (UDA) addresses this challenge by adapting the network to the robot's target environment without external supervision, leveraging the large amounts of data a robot might naturally collect during long-term operation. In such settings, UDA methods can exploit multi-view consistency across the environment's map to fine-tune the model in an unsupervised fashion and mitigate domain shift. However, these approaches remain sensitive to cross-view instance-level inconsistencies. In this work, we propose a method that starts from a volumetric 3D map to generate multi-view consistent pseudo-labels. We then refine these labels using the zero-shot instance segmentation capabilities of a foundation model, enforcing instance-level coherence. The refined annotations serve as supervision for self-supervised fine-tuning, enabling the robot to adapt its perception system at deployment time. Experiments on real-world data demonstrate that our approach consistently improves performance over state-of-the-art UDA baselines based on multi-view consistency, without requiring any ground-truth labels in the target domain.

</details>


### [541] [Sem-NaVAE: Semantically-Guided Outdoor Mapless Navigation via Generative Trajectory Priors](https://arxiv.org/abs/2602.01429)
*Gonzalo Olguin,Javier Ruiz-del-Solar*

Main category: cs.RO

TL;DR: 提出一种结合CVAE和VLM的无地图导航方法，通过语义分割选择轨迹，实验显示其优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 旨在解决户外应用中无需地图的实时导航问题，通过生成多样轨迹并基于自然语言选择最优路径。

Method: 结合条件变分自编码器（CVAE）生成轨迹和轻量级视觉语言模型（VLM）进行语义分割，通过开放词汇分割选择最佳轨迹，并由局部规划器执行速度命令。

Result: 在真实户外导航实验中表现优于现有方法，验证了方法的有效性。

Conclusion: 该论文提出了一种无需地图的全局导航方法，结合了CVAE的探索能力和VLM的语义分割能力，在实时导航中表现出色。

Abstract: This work presents a mapless global navigation approach for outdoor applications. It combines the exploratory capacity of conditional variational autoencoders (CVAEs) to generate trajectories and the semantic segmentation capabilities of a lightweight visual language model (VLM) to select the trajectory to execute. Open-vocabulary segmentation is used to score and select the generated trajectories based on natural language, and a state-of-the-art local planner executes velocity commands. One of the key features of the proposed approach is its ability to generate a large variability of trajectories and to select them and navigate in real-time. The approach was validated through real-world outdoor navigation experiments, achieving superior performance compared to state-of-the-art methods. A video showing an experimental run of the system can be found in https://www.youtube.com/watch?v=i3R5ey5O2yk.

</details>


### [542] [Towards a Novel Wearable Robotic Vest for Hemorrhage Suppression](https://arxiv.org/abs/2602.01448)
*Harshith Jella,Pejman Kheradmand,Joseph Klein,Behnam Moradkhani,Yash Chitalia*

Main category: cs.RO

TL;DR: 开发了一种形状可调的机器人系统，用于紧急出血管理，实验显示其在模拟场景中有效，但在复杂解剖区域覆盖方面有限。


<details>
  <summary>Details</summary>
Motivation: 设计一种能够在紧急情况下（包括太空站等独特环境）管理严重出血的新型机器人系统。

Method: 开发了具有形状可调环机制的机器人系统，包括不同灵活性的臂和兼容的充气环及气囊系统，通过实验评估了环臂配置的弯曲刚度和气囊系统的施力。

Result: 实验表明，该设备在模拟出血场景中有效，但在覆盖复杂解剖区域时存在限制。

Conclusion: 该机器人系统在模拟出血场景中成功展示了控制出血的能力，但在覆盖复杂解剖区域方面存在局限性。

Abstract: This paper introduces a novel robotic system designed to manage severe bleeding in emergency scenarios, including unique environments like space stations. The robot features a shape-adjustable "ring mechanism", transitioning from a circular to an elliptical configuration to adjust wound coverage across various anatomical regions. We developed various arms for this ring mechanism with varying flexibilities to improve adaptability when applied to non-extremities of the body (abdomen, back, neck, etc.). To apply equal and constant pressure across the wound, we developed an inflatable ring and airbag balloon that are compatible with this shape-changing ring mechanism. A series of experiments focused on evaluating various ring arm configurations to characterize their bending stiffness. Subsequent experiments measured the force exerted by the airbag balloon system using a digital scale. Despite its promising performance, certain limitations related to coverage area are identified. The shape-changing effect of the device is limited to scenarios involving partially inflated or deflated airbag balloons, and cannot fully conform to complex anatomical regions. Finally, the device was tested on casualty simulation kits, where it successfully demonstrated its ability to control simulated bleeding.

</details>


### [543] [TreeLoc: 6-DoF LiDAR Global Localization in Forests via Inter-Tree Geometric Matching](https://arxiv.org/abs/2602.01501)
*Minwoo Jung,Nived Chebrolu,Lucas Carvalho de Lima,Haedam Oh,Maurice Fallon,Ayoung Kim*

Main category: cs.RO

TL;DR: TreeLoc是一种基于LiDAR的森林全局定位框架，通过树茎和DBH表示场景，采用粗匹配和细匹配策略，最终实现精确的6-DoF姿态估计。


<details>
  <summary>Details</summary>
Motivation: 森林环境中GPS信号弱且LiDAR测量复杂，传统定位方法假设不一致，需开发针对森林的鲁棒定位方案。

Method: 提出TreeLoc框架，利用树茎及其DBH表示场景，通过树分布直方图（TDH）进行粗匹配，再使用2D三角形描述符进行细匹配，最后通过两步几何验证完成姿态估计。

Result: 在多样化森林基准测试中，TreeLoc表现优于基线方法，实现了精确的定位。

Conclusion: TreeLoc通过树茎和DBH表示场景，采用两步几何验证实现精确定位，并在多样化森林基准测试中表现优异。

Abstract: Reliable localization is crucial for navigation in forests, where GPS is often degraded and LiDAR measurements are repetitive, occluded, and structurally complex. These conditions weaken the assumptions of traditional urban-centric localization methods, which assume that consistent features arise from unique structural patterns, necessitating forest-centric solutions to achieve robustness in these environments. To address these challenges, we propose TreeLoc, a LiDAR-based global localization framework for forests that handles place recognition and 6-DoF pose estimation. We represent scenes using tree stems and their Diameter at Breast Height (DBH), which are aligned to a common reference frame via their axes and summarized using the tree distribution histogram (TDH) for coarse matching, followed by fine matching with a 2D triangle descriptor. Finally, pose estimation is achieved through a two-step geometric verification. On diverse forest benchmarks, TreeLoc outperforms baselines, achieving precise localization. Ablation studies validate the contribution of each component. We also propose applications for long-term forest management using descriptors from a compact global tree database. TreeLoc is open-sourced for the robotics community at https://github.com/minwoo0611/TreeLoc.

</details>


### [544] [RAPT: Model-Predictive Out-of-Distribution Detection and Failure Diagnosis for Sim-to-Real Humanoid Robots](https://arxiv.org/abs/2602.01515)
*Humphrey Munn,Brendan Tidd,Peter Bohm,Marcus Gallagher,David Howard*

Main category: cs.RO

TL;DR: RAPT是一种用于人形机器人控制的轻量级自监督监控系统，显著提升OOD检测和故障诊断能力。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人控制策略部署中的OOD状态检测问题，避免硬件损坏，并提供可解释的故障诊断。

Method: RAPT通过学习模拟中的概率时空流形，评估执行时的预测偏差，并结合梯度时间显著性和LLM推理进行故障诊断。

Result: 在仿真和硬件测试中，RAPT显著提升了异常检测的TPR（37%和12.5%），并在零样本设置下达到75%的故障根因分类准确率。

Conclusion: RAPT作为一种轻量级、自监督的部署时监控系统，显著提升了人形机器人在复杂任务中的异常检测能力和故障诊断准确性，同时提供了可解释的Sim-to-Real不匹配度量。

Abstract: Deploying learned control policies on humanoid robots is challenging: policies that appear robust in simulation can execute confidently in out-of-distribution (OOD) states after Sim-to-Real transfer, leading to silent failures that risk hardware damage. Although anomaly detection can mitigate these failures, prior methods are often incompatible with high-rate control, poorly calibrated at the extremely low false-positive rates required for practical deployment, or operate as black boxes that provide a binary stop signal without explaining why the robot drifted from nominal behavior. We present RAPT, a lightweight, self-supervised deployment-time monitor for 50Hz humanoid control. RAPT learns a probabilistic spatio-temporal manifold of nominal execution from simulation and evaluates execution-time predictive deviation as a calibrated, per-dimension signal. This yields (i) reliable online OOD detection under strict false-positive constraints and (ii) a continuous, interpretable measure of Sim-to-Real mismatch that can be tracked over time to quantify how far deployment has drifted from training. Beyond detection, we introduce an automated post-hoc root-cause analysis pipeline that combines gradient-based temporal saliency derived from RAPT's reconstruction objective with LLM-based reasoning conditioned on saliency and joint kinematics to produce semantic failure diagnoses in a zero-shot setting. We evaluate RAPT on a Unitree G1 humanoid across four complex tasks in simulation and on physical hardware. In large-scale simulation, RAPT improves True Positive Rate (TPR) by 37% over the strongest baseline at a fixed episode-level false positive rate of 0.5%. On real-world deployments, RAPT achieves a 12.5% TPR improvement and provides actionable interpretability, reaching 75% root-cause classification accuracy across 16 real-world failures using only proprioceptive data.

</details>


### [545] [Co-Design of Rover Wheels and Control using Bayesian Optimization and Rover-Terrain Simulations](https://arxiv.org/abs/2602.01535)
*Huzaifa Mustafa Unjhawala,Khizar Shaikh,Luning Bakke,Radu Serban,Dan Negrut*

Main category: cs.RO

TL;DR: 该论文提出了一种贝叶斯优化框架，通过高保真仿真联合优化越野车辆的车轮设计和控制参数，显著提高了效率并降低了计算成本。


<details>
  <summary>Details</summary>
Motivation: 传统的离散元方法（DEM）仿真通常仅限于单轮测试，无法揭示车轮-车辆-控制器之间的耦合交互，阻碍了机械设计和控制的联合优化。

Method: 提出了一个贝叶斯优化框架，用于联合设计火星车车轮几何形状和转向控制器参数，利用高保真全车闭环仿真在可变形地形上进行评估。使用连续体表示模型（CRM）进行地形力学分析，评估不同复杂度轨迹上的候选设计。

Result: 通过3,000次全车仿真，优化过程在5至9天内完成，而之前基于DEM的工作流程需要数月。初步硬件研究表明，仿真优化的轮子设计在物理火星车上保持了相对性能趋势。

Conclusion: 该研究展示了一种可扩展的高保真仿真方法，能够在不依赖昂贵DEM研究的情况下，实现越野车辆在可变形地形上的轮子设计和控制的联合优化。仿真基础设施（脚本和模型）已开源，以支持可重复性和进一步研究。

Abstract: While simulation is vital for optimizing robotic systems, the cost of modeling deformable terrain has long limited its use in full-vehicle studies of off-road autonomous mobility. For example, Discrete Element Method (DEM) simulations are often confined to single-wheel tests, which obscures coupled wheel-vehicle-controller interactions and prevents joint optimization of mechanical design and control. This paper presents a Bayesian optimization framework that co-designs rover wheel geometry and steering controller parameters using high-fidelity, full-vehicle closed-loop simulations on deformable terrain. Using the efficiency and scalability of a continuum-representation model (CRM) for terramechanics, we evaluate candidate designs on trajectories of varying complexity while towing a fixed load. The optimizer tunes wheel parameters (radius, width, and grouser features) and steering PID gains under a multi-objective formulation that balances traversal speed, tracking error, and energy consumption. We compare two strategies: simultaneous co-optimization of wheel and controller parameters versus a sequential approach that decouples mechanical and control design. We analyze trade-offs in performance and computational cost. Across 3,000 full-vehicle simulations, campaigns finish in five to nine days, versus months with the group's earlier DEM-based workflow. Finally, a preliminary hardware study suggests the simulation-optimized wheel designs preserve relative performance trends on the physical rover. Together, these results show that scalable, high-fidelity simulation can enable practical co-optimization of wheel design and control for off-road vehicles on deformable terrain without relying on prohibitively expensive DEM studies. The simulation infrastructure (scripts and models) is released as open source in a public repository to support reproducibility and further research.

</details>


### [546] [UniDWM: Towards a Unified Driving World Model via Multifaceted Representation Learning](https://arxiv.org/abs/2602.01536)
*Shuai Liu,Siheng Ren,Xiaoyao Zhu,Quanmin Liang,Zefeng Li,Qiang Li,Xin Hu,Kai Huang*

Main category: cs.RO

TL;DR: UniDWM是一种统一驾驶世界模型，通过多方面的表征学习和潜在世界表示，有效提升了自动驾驶的规划、重建和生成能力。


<details>
  <summary>Details</summary>
Motivation: 在复杂驾驶环境中实现可靠和高效的规划需要一个能够推理场景几何、外观和动态的模型。

Method: UniDWM构建了一个结构和动态感知的潜在世界表示，通过联合重建路径学习场景结构（几何和视觉纹理），并利用条件扩散变换器在潜在空间中预测未来世界演化。

Result: 实验证明UniDWM在轨迹规划、4D重建和生成任务中表现出色。

Conclusion: UniDWM作为一种统一驾驶世界模型，通过多方面的表征学习推动了自动驾驶的发展，其有效性在轨迹规划、4D重建和生成任务中得到了验证。

Abstract: Achieving reliable and efficient planning in complex driving environments requires a model that can reason over the scene's geometry, appearance, and dynamics. We present UniDWM, a unified driving world model that advances autonomous driving through multifaceted representation learning. UniDWM constructs a structure- and dynamic-aware latent world representation that serves as a physically grounded state space, enabling consistent reasoning across perception, prediction, and planning. Specifically, a joint reconstruction pathway learns to recover the scene's structure, including geometry and visual texture, while a collaborative generation framework leverages a conditional diffusion transformer to forecast future world evolution within the latent space. Furthermore, we show that our UniDWM can be deemed as a variation of VAE, which provides theoretical guidance for the multifaceted representation learning. Extensive experiments demonstrate the effectiveness of UniDWM in trajectory planning, 4D reconstruction and generation, highlighting the potential of multifaceted world representations as a foundation for unified driving intelligence. The code will be publicly available at https://github.com/Say2L/UniDWM.

</details>


### [547] [A Closed-Form Geometric Retargeting Solver for Upper Body Humanoid Robot Teleoperation](https://arxiv.org/abs/2602.01632)
*Chuizheng Kong,Yunho Cho,Wonsuhk Jung,Idris Wibowo,Parth Shinde,Sundhar Vinodh-Sangeetha,Long Kiu Chung,Zhenyang Chen,Andrew Mattei,Advaith Nidumukkala,Alexander Elias,Danfei Xu,Taylor Higgins,Shreyas Kousik*

Main category: cs.RO

TL;DR: SEW-Mimic通过方向对齐优化运动重定向，实现快速、准确的双手机器人远程操作。


<details>
  <summary>Details</summary>
Motivation: 现有方法因优化机器人末端执行器与人类手部位置和方向匹配而次优且缓慢，限制了机器人工作空间。

Method: 将运动重定向问题重新定义为方向对齐问题，提出了一种具有最优性保证的闭式几何解算法，即SEW-Mimic。

Result: SEW-Mimic在计算时间和准确性上优于其他重定向方法，提高了远程操作任务成功率，并改善了策略学习的平滑性。

Conclusion: SEW-Mimic作为一种基础构建块，显著提升了双手机器人操作和人形机器人远程操作的实用性。

Abstract: Retargeting human motion to robot poses is a practical approach for teleoperating bimanual humanoid robot arms, but existing methods can be suboptimal and slow, often causing undesirable motion or latency. This is due to optimizing to match robot end-effector to human hand position and orientation, which can also limit the robot's workspace to that of the human. Instead, this paper reframes retargeting as an orientation alignment problem, enabling a closed-form, geometric solution algorithm with an optimality guarantee. The key idea is to align a robot arm to a human's upper and lower arm orientations, as identified from shoulder, elbow, and wrist (SEW) keypoints; hence, the method is called SEW-Mimic. The method has fast inference (3 kHz) on standard commercial CPUs, leaving computational overhead for downstream applications; an example in this paper is a safety filter to avoid bimanual self-collision. The method suits most 7-degree-of-freedom robot arms and humanoids, and is agnostic to input keypoint source. Experiments show that SEW-Mimic outperforms other retargeting methods in computation time and accuracy. A pilot user study suggests that the method improves teleoperation task success. Preliminary analysis indicates that data collected with SEW-Mimic improves policy learning due to being smoother. SEW-Mimic is also shown to be a drop-in way to accelerate full-body humanoid retargeting. Finally, hardware demonstrations illustrate SEW-Mimic's practicality. The results emphasize the utility of SEW-Mimic as a fundamental building block for bimanual robot manipulation and humanoid robot teleoperation.

</details>


### [548] [AgenticLab: A Real-World Robot Agent Platform that Can See, Think, and Act](https://arxiv.org/abs/2602.01662)
*Pengyuan Guo,Zhonghao Mai,Zhengtong Xu,Kaidi Zhang,Heng Zhang,Zichen Miao,Arash Ajoudani,Zachary Kingston,Qiang Qiu,Yu She*

Main category: cs.RO

TL;DR: AgenticLab 是一个用于开放世界操作的机器人代理平台和基准，揭示了基于 VLM 的代理在真实环境中的多种失败模式，支持可重复评估。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型（VLMs）在开放词汇感知和推理方面表现出泛化能力，但其在非结构化、真实环境中的长时程闭环操作能力尚不明确，且现有研究难以在不同研究组间进行比较。

Method: 提出了 AgenticLab，一个闭环代理管道，用于感知、任务分解、在线验证和重新规划，并在非结构化环境中对最先进的基于 VLM 的代理进行基准测试。

Result: 基准测试揭示了多种离线视觉语言测试未能捕捉到的失败模式，包括多步接地一致性、遮挡和场景变化下的对象接地以及空间推理不足等问题。

Conclusion: AgenticLab 提供了一个模型无关的机器人代理平台和基准，用于开放世界操作，揭示了离线视觉语言测试未能捕捉到的多种失败模式，并支持可重复评估以加速通用机器人代理的研究。

Abstract: Recent advances in large vision-language models (VLMs) have demonstrated generalizable open-vocabulary perception and reasoning, yet their real-robot manipulation capability remains unclear for long-horizon, closed-loop execution in unstructured, in-the-wild environments. Prior VLM-based manipulation pipelines are difficult to compare across different research groups' setups, and many evaluations rely on simulation, privileged state, or specially designed setups. We present AgenticLab, a model-agnostic robot agent platform and benchmark for open-world manipulation. AgenticLab provides a closed-loop agent pipeline for perception, task decomposition, online verification, and replanning. Using AgenticLab, we benchmark state-of-the-art VLM-based agents on real-robot tasks in unstructured environments. Our benchmark reveals several failure modes that offline vision-language tests (e.g., VQA and static image understanding) fail to capture, including breakdowns in multi-step grounding consistency, object grounding under occlusion and scene changes, and insufficient spatial reasoning for reliable manipulation. We will release the full hardware and software stack to support reproducible evaluation and accelerate research on general-purpose robot agents.

</details>


### [549] [Towards Autonomous Instrument Tray Assembly for Sterile Processing Applications](https://arxiv.org/abs/2602.01679)
*Raghavasimhan Sankaranarayanan,Paul Stuart,Nicholas Ahn,Arno Sungarian,Yash Chitalia*

Main category: cs.RO

TL;DR: An automated robotic system for sorting and packing surgical instruments, using a hybrid perception pipeline and robotic arm, significantly reduces collisions and improves efficiency in SPD workflows.


<details>
  <summary>Details</summary>
Motivation: Manual inspection and preparation of surgical instrument trays is time-consuming, error-prone, and often leads to contamination and instrument breakage.

Method: A hybrid perception pipeline using YOLO12 for detection and a cascaded ResNet-based model for fine-grained classification, integrated with a 6-DOF robotic arm and a rule-based packing algorithm.

Result: Experimental evaluations show high perception accuracy and a statistically significant reduction in tool-to-tool collisions compared to human-assembled trays.

Conclusion: This work presents a scalable first step toward automating SPD workflows, improving safety and consistency of surgical preparation while reducing processing times.

Abstract: The Sterile Processing and Distribution (SPD) department is responsible for cleaning, disinfecting, inspecting, and assembling surgical instruments between surgeries. Manual inspection and preparation of instrument trays is a time-consuming, error-prone task, often prone to contamination and instrument breakage. In this work, we present a fully automated robotic system that sorts and structurally packs surgical instruments into sterile trays, focusing on automation of the SPD assembly stage. A custom dataset comprising 31 surgical instruments and 6,975 annotated images was collected to train a hybrid perception pipeline using YOLO12 for detection and a cascaded ResNet-based model for fine-grained classification. The system integrates a calibrated vision module, a 6-DOF Staubli TX2-60L robotic arm with a custom dual electromagnetic gripper, and a rule-based packing algorithm that reduces instrument collisions during transport. The packing framework uses 3D printed dividers and holders to physically isolate instruments, reducing collision and friction during transport. Experimental evaluations show high perception accuracy and statistically significant reduction in tool-to-tool collisions compared to human-assembled trays. This work serves as the scalable first step toward automating SPD workflows, improving safety, and consistency of surgical preparation while reducing SPD processing times.

</details>


### [550] [GSR: Learning Structured Reasoning for Embodied Manipulation](https://arxiv.org/abs/2602.01693)
*Kewei Hu,Michael Zhang,Wei Ying,Tianhao Liu,Guoqiang Hao,Zimeng Li,Wanchan Yu,Jiajian Jing,Fangwen Chen,Hanwen Kang*

Main category: cs.RO

TL;DR: GSR通过显式场景图推理提升长视野任务表现，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法将任务推理隐式嵌入高维潜在表示，难以分离任务结构与感知变异性，限制了长视野操作任务的表现。

Method: 提出了Grounded Scene-graph Reasoning (GSR)，一种结构化推理范式，通过语义场景图显式建模世界状态演化，逐步推理对象状态和空间关系。

Result: 在RLBench、LIBERO、GSR-benchmark和真实机器人任务中，GSR显著优于基于提示的基线方法，尤其在零样本泛化和长视野任务完成方面。

Conclusion: GSR通过显式建模世界状态演化，显著提升了零样本泛化和长视野任务完成能力，证明了显式世界状态表示作为可扩展具身推理的关键归纳偏置的重要性。

Abstract: Despite rapid progress, embodied agents still struggle with long-horizon manipulation that requires maintaining spatial consistency, causal dependencies, and goal constraints. A key limitation of existing approaches is that task reasoning is implicitly embedded in high-dimensional latent representations, making it challenging to separate task structure from perceptual variability. We introduce Grounded Scene-graph Reasoning (GSR), a structured reasoning paradigm that explicitly models world-state evolution as transitions over semantically grounded scene graphs. By reasoning step-wise over object states and spatial relations, rather than directly mapping perception to actions, GSR enables explicit reasoning about action preconditions, consequences, and goal satisfaction in a physically grounded space. To support learning such reasoning, we construct Manip-Cognition-1.6M, a large-scale dataset that jointly supervises world understanding, action planning, and goal interpretation. Extensive evaluations across RLBench, LIBERO, GSR-benchmark, and real-world robotic tasks show that GSR significantly improves zero-shot generalization and long-horizon task completion over prompting-based baselines. These results highlight explicit world-state representations as a key inductive bias for scalable embodied reasoning.

</details>


### [551] [Tilt-Ropter: A Novel Hybrid Aerial and Terrestrial Vehicle with Tilt Rotors and Passive Wheels](https://arxiv.org/abs/2602.01700)
*Ruoyu Wang,Xuchen Liu,Zongzhou Wu,Zixuan Guo,Wendi Ding,Ben M. Chen*

Main category: cs.RO

TL;DR: Tilt-Ropter 是一种新型混合空中-地面车辆，通过完全驱动设计和NMPC控制器实现高效多模式运动，实验显示功耗大幅降低且跟踪性能优异。


<details>
  <summary>Details</summary>
Motivation: 设计一种新型混合空中-地面车辆（HATV），通过完全驱动的设计提升移动性和环境适应性，解决现有欠驱动HATV的局限性。

Method: 采用非线性模型预测控制器（NMPC）跟踪参考轨迹并处理接触约束，同时通过专用控制分配模块利用执行器冗余实现节能控制。引入外部力矩估计算法增强地面接触时的鲁棒性。

Result: 仿真和实际实验验证了系统性能，包括无缝空-地转换和轨迹跟踪。地面运动时功耗降低92.8%，跟踪误差低。

Conclusion: Tilt-Ropter 的设计展示了其在多模式运动中的高效能和适应性，特别是在大规模和能源受限环境中的长期任务潜力。

Abstract: In this work, we present Tilt-Ropter, a novel hybrid aerial-terrestrial vehicle (HATV) that combines tilt rotors with passive wheels to achieve energy-efficient multi-mode locomotion. Unlike existing under-actuated HATVs, the fully actuated design of Tilt-Ropter enables decoupled force and torque control, greatly enhancing its mobility and environmental adaptability. A nonlinear model predictive controller (NMPC) is developed to track reference trajectories and handle contact constraints across locomotion modes, while a dedicated control allocation module exploits actuation redundancy to achieve energy-efficient control of actuators. Additionally, to enhance robustness during ground contact, we introduce an external wrench estimation algorithm that estimates environmental interaction forces and torques in real time. The system is validated through both simulation and real-world experiments, including seamless air-ground transitions and trajectory tracking. Results show low tracking errors in both modes and highlight a 92.8% reduction in power consumption during ground locomotion, demonstrating the system's potential for long-duration missions across large-scale and energy-constrained environments.

</details>


### [552] [Uncertainty-Aware Non-Prehensile Manipulation with Mobile Manipulators under Object-Induced Occlusion](https://arxiv.org/abs/2602.01731)
*Jiwoo Hwang,Taegeun Yang,Jeil Jeong,Minsung Yoon,Sung-Eui Yoon*

Main category: cs.RO

TL;DR: CURA-PPO 是一个强化学习框架，通过建模不确定性处理传感器遮挡，提高非抓取操作的成功率。


<details>
  <summary>Details</summary>
Motivation: 非抓取操作中，被操作物体会遮挡传感器的视野，形成遮挡区域可能导致碰撞。

Method: 提出了 CURA-PPO，一个强化学习框架，通过显式建模部分可观测性下的不确定性，预测碰撞可能性为分布，提取风险和不确定性来指导机器人行动。

Result: 在多种物体大小和障碍配置的实验中，CURA-PPO 的成功率比基线方法高出 3 倍，并能通过学习的行为处理遮挡。

Conclusion: CURA-PPO 提供了一个实用的解决方案，能够在仅使用机载传感器的情况下，在杂乱环境中实现自主操作。

Abstract: Non-prehensile manipulation using onboard sensing presents a fundamental challenge: the manipulated object occludes the sensor's field of view, creating occluded regions that can lead to collisions. We propose CURA-PPO, a reinforcement learning framework that addresses this challenge by explicitly modeling uncertainty under partial observability. By predicting collision possibility as a distribution, we extract both risk and uncertainty to guide the robot's actions. The uncertainty term encourages active perception, enabling simultaneous manipulation and information gathering to resolve occlusions. When combined with confidence maps that capture observation reliability, our approach enables safe navigation despite severe sensor occlusion. Extensive experiments across varying object sizes and obstacle configurations demonstrate that CURA-PPO achieves up to 3X higher success rates than the baselines, with learned behaviors that handle occlusions. Our method provides a practical solution for autonomous manipulation in cluttered environments using only onboard sensing.

</details>


### [553] [RFS: Reinforcement learning with Residual flow steering for dexterous manipulation](https://arxiv.org/abs/2602.01789)
*Entong Su,Tyler Westenbroek,Anusha Nagabandi,Abhishek Gupta*

Main category: cs.RO

TL;DR: RFS 是一个强化学习框架，通过优化残差和潜在噪声分布来微调预训练的生成策略，保留其表达结构并提升性能。


<details>
  <summary>Details</summary>
Motivation: 尽管模仿学习在机器人高维灵巧操作任务中表现出色，但预训练策略的泛化能力有限，需要额外微调以实现稳健性能。RFS 旨在保留预训练的全局探索优势，同时快速纠正局部执行错误。

Method: RFS 通过联合优化残差动作和潜在噪声分布来引导预训练的流匹配策略，实现局部细化（通过残差校正）和全局探索（通过潜在空间调制）。

Result: RFS 在灵巧操作任务中展示了高效微调能力，适用于仿真和现实场景。

Conclusion: Residual Flow Steering (RFS) 是一个高效的数据强化学习框架，能够有效调整预训练的生成策略，同时保留其表达结构。

Abstract: Imitation learning has emerged as an effective approach for bootstrapping sequential decision-making in robotics, achieving strong performance even in high-dimensional dexterous manipulation tasks. Recent behavior cloning methods further leverage expressive generative models, such as diffusion models and flow matching, to represent multimodal action distributions. However, policies pretrained in this manner often exhibit limited generalization and require additional fine-tuning to achieve robust performance at deployment time. Such adaptation must preserve the global exploration benefits of pretraining while enabling rapid correction of local execution errors.We propose \emph{Residual Flow Steering} (RFS), a data-efficient reinforcement learning framework for adapting pretrained generative policies. RFS steers a pretrained flow-matching policy by jointly optimizing a residual action and a latent noise distribution, enabling complementary forms of exploration: local refinement through residual corrections and global exploration through latent-space modulation. This design allows efficient adaptation while retaining the expressive structure of the pretrained policy.We demonstrate the effectiveness of RFS on dexterous manipulation tasks, showing efficient fine-tuning both in simulation and in real-world settings when adapting pretrained base policies.Project website:https://weirdlabuw.github.io/rfs.

</details>


### [554] [From Knowing to Doing Precisely: A General Self-Correction and Termination Framework for VLA models](https://arxiv.org/abs/2602.01811)
*Wentao Zhang,Aolan Sun,Wentao Mo,Xiaoyang Qu,Yuxin Zheng,Jianzong Wang*

Main category: cs.RO

TL;DR: VLA-SCT框架通过自校正控制循环和数据驱动的动作精炼，解决了VLA模型的空间偏差和任务识别问题，显著提升了任务成功率。


<details>
  <summary>Details</summary>
Motivation: 解决VLA模型在抓取任务中动作令牌的空间偏差和无法可靠识别任务完成的问题，以增强鲁棒性。

Method: 提出了一种轻量级、无需训练的框架VLA-SCT，结合数据驱动的动作精炼和条件逻辑终止，形成自校正控制循环。

Result: 在LIBERO基准测试中，相比基线方法，VLA-SCT在所有数据集上均取得一致改进，显著提高了精细操作任务的成功率。

Conclusion: VLA-SCT框架显著提升了VLA模型在复杂非结构化环境中的可靠性和任务完成准确性，促进了更可靠的VLA代理部署。

Abstract: While vision-language-action (VLA) models for embodied agents integrate perception, reasoning, and control, they remain constrained by two critical weaknesses: first, during grasping tasks, the action tokens generated by the language model often exhibit subtle spatial deviations from the target object, resulting in grasp failures; second, they lack the ability to reliably recognize task completion, which leads to redundant actions and frequent timeout errors. To address these challenges and enhance robustness, we propose a lightweight, training-free framework, VLA-SCT. This framework operates as a self-correcting control loop, combining data-driven action refinement with conditional logic for termination. Consequently, compared to baseline approaches, our method achieves consistent improvements across all datasets in the LIBERO benchmark, significantly increasing the success rate of fine manipulation tasks and ensuring accurate task completion, thereby promoting the deployment of more reliable VLA agents in complex, unstructured environments.

</details>


### [555] [Concept-Based Dictionary Learning for Inference-Time Safety in Vision Language Action Models](https://arxiv.org/abs/2602.01834)
*Siqi Wen,Shu Yang,Shaopeng Fu,Jingfeng Zhang,Lijie Hu,Di Wang*

Main category: cs.RO

TL;DR: 该论文提出了一种基于字典学习的推理时安全控制框架，有效降低了VLA模型的安全风险，无需重新训练即可无缝集成。


<details>
  <summary>Details</summary>
Motivation: 现有的防御方法（如对齐、过滤或提示硬化）在错误的模态或时间点进行干预，导致融合表示仍可被利用，因此需要一种更早、更有效的安全控制方法。

Method: 通过从隐藏激活中构建稀疏、可解释的字典，识别有害概念方向，并应用基于阈值的干预措施来抑制或阻止不安全激活。

Result: 在Libero-Harm、BadRobot、RoboPair和IS-Bench上的实验表明，该方法将攻击成功率降低了70%以上，同时保持了任务成功率，达到了最先进的防御性能。

Conclusion: 该论文提出了一种基于概念的安全控制框架，首次实现了对具身系统的推理时安全控制，显著提升了VLA模型的可解释性和安全部署能力。

Abstract: Vision Language Action (VLA) models close the perception action loop by translating multimodal instructions into executable behaviors, but this very capability magnifies safety risks: jailbreaks that merely yield toxic text in LLMs can trigger unsafe physical actions in embodied systems. Existing defenses alignment, filtering, or prompt hardening intervene too late or at the wrong modality, leaving fused representations exploitable. We introduce a concept-based dictionary learning framework for inference-time safety control. By constructing sparse, interpretable dictionaries from hidden activations, our method identifies harmful concept directions and applies threshold-based interventions to suppress or block unsafe activations. Experiments on Libero-Harm, BadRobot, RoboPair, and IS-Bench show that our approach achieves state-of-the-art defense performance, cutting attack success rates by over 70\% while maintaining task success. Crucially, the framework is plug-in and model-agnostic, requiring no retraining and integrating seamlessly with diverse VLAs. To our knowledge, this is the first inference-time concept-based safety method for embodied systems, advancing both interpretability and safe deployment of VLA models.

</details>


### [556] [Vision-only UAV State Estimation for Fast Flights Without External Localization Systems: A2RL Drone Racing Finalist Approach](https://arxiv.org/abs/2602.01860)
*Filip Novák,Matěj Petrlík,Matej Novosad,Parakh M. Gupta,Robert Pěnička,Martin Saska*

Main category: cs.RO

TL;DR: 提出一种融合VIO、地标相机和IMU的方法，通过漂移模型校正VIO状态，实现高速无人机在复杂环境中的精准估计，实验和竞赛验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 在复杂且GNSS缺失的环境中，高速无人机需要快速、可靠且准确的状态估计。现有方法依赖复杂硬件且未校正VIO漂移，导致快速机动时误差较大。

Method: 结合视觉惯性里程计（VIO）、基于地标的相机测量系统和IMU数据，通过数学漂移模型校正VIO的漂移，实现对位置、方向、线速度和角速度的全面校正。

Result: 通过1600次仿真和大量真实实验验证，方法在动态运动中仍保持高精度。在A2RL无人机竞速挑战赛2025中，团队从210支队伍中晋级前四并获奖。

Conclusion: 该论文提出的方法通过融合VIO、基于地标的相机测量系统和IMU数据，并引入新颖的漂移模型，显著提升了高速无人机在复杂GNSS缺失环境中的状态估计准确性。实验和竞赛结果验证了其优越性能。

Abstract: Fast flights with aggressive maneuvers in cluttered GNSS-denied environments require fast, reliable, and accurate UAV state estimation. In this paper, we present an approach for onboard state estimation of a high-speed UAV using a monocular RGB camera and an IMU. Our approach fuses data from Visual-Inertial Odometry (VIO), an onboard landmark-based camera measurement system, and an IMU to produce an accurate state estimate. Using onboard measurement data, we estimate and compensate for VIO drift through a novel mathematical drift model. State-of-the-art approaches often rely on more complex hardware (e.g., stereo cameras or rangefinders) and use uncorrected drifting VIO velocities, orientation, and angular rates, leading to errors during fast maneuvers. In contrast, our method corrects all VIO states (position, orientation, linear and angular velocity), resulting in accurate state estimation even during rapid and dynamic motion. Our approach was thoroughly validated through 1600 simulations and numerous real-world experiments. Furthermore, we applied the proposed method in the A2RL Drone Racing Challenge 2025, where our team advanced to the final four out of 210 teams and earned a medal.

</details>


### [557] [BTGenBot-2: Efficient Behavior Tree Generation with Small Language Models](https://arxiv.org/abs/2602.01870)
*Riccardo Andrea Izzo,Gianluca Bardaro,Matteo Matteucci*

Main category: cs.RO

TL;DR: BTGenBot-2是一个轻量级开源模型，能高效将自然语言转换为行为树，性能优于主流模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法多为闭源或计算密集，缺乏实际部署的可行性，且缺乏通用的机器人任务生成表示。

Method: 提出BTGenBot-2，一个1B参数的开源小语言模型，支持零样本行为树生成、推理和运行时错误恢复。

Result: BTGenBot-2在零样本和单样本设置下的平均成功率分别为90.38%和98.07%，推理速度比前代快16倍。

Conclusion: BTGenBot-2是一个开源的轻量级语言模型，能够直接将自然语言任务描述转换为可执行的行为树，且在零样本和单样本设置下表现优异，推理速度显著提升。

Abstract: Recent advances in robot learning increasingly rely on LLM-based task planning, leveraging their ability to bridge natural language with executable actions. While prior works showcased great performances, the widespread adoption of these models in robotics has been challenging as 1) existing methods are often closed-source or computationally intensive, neglecting the actual deployment on real-world physical systems, and 2) there is no universally accepted, plug-and-play representation for robotic task generation. Addressing these challenges, we propose BTGenBot-2, a 1B-parameter open-source small language model that directly converts natural language task descriptions and a list of robot action primitives into executable behavior trees in XML. Unlike prior approaches, BTGenBot-2 enables zero-shot BT generation, error recovery at inference and runtime, while remaining lightweight enough for resource-constrained robots. We further introduce the first standardized benchmark for LLM-based BT generation, covering 52 navigation and manipulation tasks in NVIDIA Isaac Sim. Extensive evaluations demonstrate that BTGenBot-2 consistently outperforms GPT-5, Claude Opus 4.1, and larger open-source models across both functional and non-functional metrics, achieving average success rates of 90.38% in zero-shot and 98.07% in one-shot, while delivering up to 16x faster inference compared to the previous BTGenBot.

</details>


### [558] [Multimodal Large Language Models for Real-Time Situated Reasoning](https://arxiv.org/abs/2602.01880)
*Giulio Antonio Abbo,Senne Lenaerts,Tony Belpaeme*

Main category: cs.RO

TL;DR: 研究结合GPT-4o与TurtleBot 4，展示多模态语言模型在家庭环境中基于视觉输入和价值观进行实时决策的潜力与挑战。


<details>
  <summary>Details</summary>
Motivation: 探索多模态大型语言模型如何支持实时、基于上下文和价值观的决策，特别是在家庭环境中。

Method: 将GPT-4o语言模型与TurtleBot 4平台结合，模拟智能吸尘机器人在家庭环境中的决策过程。模型通过视觉输入评估环境，决定是否启动清洁。

Result: 系统在真实家庭环境中展示了从有限视觉输入推断上下文和价值观的能力，能够根据清洁、舒适和安全等价值观做出 nuanced 决策。

Conclusion: 多模态大型语言模型在增强机器人自主性和情境意识方面具有潜力，但也面临一致性、偏见和实时性能等挑战。

Abstract: In this work, we explore how multimodal large language models can support real-time context- and value-aware decision-making. To do so, we combine the GPT-4o language model with a TurtleBot 4 platform simulating a smart vacuum cleaning robot in a home. The model evaluates the environment through vision input and determines whether it is appropriate to initiate cleaning. The system highlights the ability of these models to reason about domestic activities, social norms, and user preferences and take nuanced decisions aligned with the values of the people involved, such as cleanliness, comfort, and safety. We demonstrate the system in a realistic home environment, showing its ability to infer context and values from limited visual input. Our results highlight the promise of multimodal large language models in enhancing robotic autonomy and situational awareness, while also underscoring challenges related to consistency, bias, and real-time performance.

</details>


### [559] [Path Tracking with Dynamic Control Point Blending for Autonomous Vehicles: An Experimental Study](https://arxiv.org/abs/2602.01892)
*Alexandre Lombard,Florent Perronnet,Nicolas Gaud,Abdeljalil Abbas-Turki*

Main category: cs.RO

TL;DR: 该论文提出了一种动态控制点路径跟踪框架，通过混合前轴和后轴控制器及曲率感知纵向控制，显著提升了自动驾驶车辆的轨迹跟踪性能。


<details>
  <summary>Details</summary>
Motivation: 解决固定参考点（如前轴或后轴）在低速操纵和倒车等不同驾驶场景中适应性不足的问题。

Method: 通过在前轴Stanley控制器和后轴基于曲率的几何控制器之间进行重心混合，实现横向控制命令的连续过渡。同时，引入基于虚拟轨道边界和光线追踪的曲率感知纵向控制策略。

Result: 仿真和真实车辆实验表明，该方法在闭环跟踪和倒车操纵中提高了轨迹精度、转向平滑性和适应性。

Conclusion: 该论文提出的动态控制点路径跟踪框架在自动驾驶车辆中表现出色，尤其在轨迹精度、转向平滑性和适应性方面优于固定控制点基线。

Abstract: This paper presents an experimental study of a path-tracking framework for autonomous vehicles in which the lateral control command is applied to a dynamic control point along the wheelbase. Instead of enforcing a fixed reference at either the front or rear axle, the proposed method continuously interpolates between both, enabling smooth adaptation across driving contexts, including low-speed maneuvers and reverse motion. The lateral steering command is obtained by barycentric blending of two complementary controllers: a front-axle Stanley formulation and a rear-axle curvature-based geometric controller, yielding continuous transitions in steering behavior and improved tracking stability. In addition, we introduce a curvature-aware longitudinal control strategy based on virtual track borders and ray-tracing, which converts upcoming geometric constraints into a virtual obstacle distance and regulates speed accordingly. The complete approach is implemented in a unified control stack and validated in simulation and on a real autonomous vehicle equipped with GPS-RTK, radar, odometry, and IMU. The results in closed-loop tracking and backward maneuvers show improved trajectory accuracy, smoother steering profiles, and increased adaptability compared to fixed control-point baselines.

</details>


### [560] [Multi-Task Learning for Robot Perception with Imbalanced Data](https://arxiv.org/abs/2602.01899)
*Ozgur Erkent*

Main category: cs.RO

TL;DR: 提出一种多任务学习方法，即使某些任务缺乏真实标签也能学习，并分析了任务间的相互作用及其对小数据量的适应性。


<details>
  <summary>Details</summary>
Motivation: 多任务学习能提升单个任务的准确性，但数据不平衡和标签获取困难限制了其在移动机器人中的应用。

Method: 通过教师网络利用任务输出（如深度）作为输入，分析任务间的相互作用，并提出一种方法来识别哪些任务可以提升其他任务的性能。

Result: 在NYUDv2和Cityscapes数据集上的语义分割和深度估计任务中，该方法展示了任务间相互作用的有效性。

Conclusion: 论文提出了一种在多任务学习中即使某些任务缺乏真实标签也能有效学习的方法，并通过实证验证了其在小数据量下的有效性。

Abstract: Multi-task problem solving has been shown to improve the accuracy of the individual tasks, which is an important feature for robots, as they have a limited resource. However, when the number of labels for each task is not equal, namely imbalanced data exist, a problem may arise due to insufficient number of samples, and labeling is not very easy for mobile robots in every environment. We propose a method that can learn tasks even in the absence of the ground truth labels for some of the tasks. We also provide a detailed analysis of the proposed method. An interesting finding is related to the interaction of the tasks. We show a methodology to find out which tasks can improve the performance of other tasks. We investigate this by training the teacher network with the task outputs such as depth as inputs. We further provide empirical evidence when trained with a small amount of data. We use semantic segmentation and depth estimation tasks on different datasets, NYUDv2 and Cityscapes.

</details>


### [561] [ForSim: Stepwise Forward Simulation for Traffic Policy Fine-Tuning](https://arxiv.org/abs/2602.01916)
*Keyu Chen,Wenchao Sun,Hao Cheng,Zheng Fu,Sifa Zheng*

Main category: cs.RO

TL;DR: ForSim是一种逐步闭环前向仿真范式，通过物理动力学和逐步预测提升交通仿真的多模态行为多样性和交互真实性，与RIFT结合显著改善仿真效果。


<details>
  <summary>Details</summary>
Motivation: 解决交通仿真中由开环模仿学习引入的协变量偏移和反映真实世界多模态行为能力有限的问题，提升仿真保真度。

Method: ForSim采用逐步闭环前向仿真范式，通过物理基础的运动动力学传播最佳时空匹配的虚拟候选轨迹，同时保持多模态行为多样性。其他代理通过逐步预测更新，实现连贯且交互感知的演化。

Result: 实验证实ForSim与RIFT框架的集成在保持效率、真实性和舒适性的同时，显著提升了安全性。

Conclusion: ForSim与RIFT框架的结合显著提升了交通仿真的安全性、效率、真实性和舒适性，强调了闭环多模态交互建模在仿真中的重要性。

Abstract: As the foundation of closed-loop training and evaluation in autonomous driving, traffic simulation still faces two fundamental challenges: covariate shift introduced by open-loop imitation learning and limited capacity to reflect the multimodal behaviors observed in real-world traffic. Although recent frameworks such as RIFT have partially addressed these issues through group-relative optimization, their forward simulation procedures remain largely non-reactive, leading to unrealistic agent interactions within the virtual domain and ultimately limiting simulation fidelity. To address these issues, we propose ForSim, a stepwise closed-loop forward simulation paradigm. At each virtual timestep, the traffic agent propagates the virtual candidate trajectory that best spatiotemporally matches the reference trajectory through physically grounded motion dynamics, thereby preserving multimodal behavioral diversity while ensuring intra-modality consistency. Other agents are updated with stepwise predictions, yielding coherent and interaction-aware evolution. When incorporated into the RIFT traffic simulation framework, ForSim operates in conjunction with group-relative optimization to fine-tune traffic policy. Extensive experiments confirm that this integration consistently improves safety while maintaining efficiency, realism, and comfort. These results underscore the importance of modeling closed-loop multimodal interactions within forward simulation and enhance the fidelity and reliability of traffic simulation for autonomous driving. Project Page: https://currychen77.github.io/ForSim/

</details>


### [562] [LIEREx: Language-Image Embeddings for Robotic Exploration](https://arxiv.org/abs/2602.01930)
*Felix Igelbrink,Lennart Niecksch,Marian Renz,Martin Günther,Martin Atzmueller*

Main category: cs.RO

TL;DR: LIEREx整合视觉语言模型与3D语义场景图，解决了传统映射方法无法处理未知对象的问题，实现了目标导向探索。


<details>
  <summary>Details</summary>
Motivation: 传统映射方法依赖预设计的符号词汇，无法处理设计时未定义的分布外知识，限制了机器人在未知环境中的探索能力。

Method: 利用CLIP等视觉语言基础模型，将对象编码为高维嵌入而非固定标签，并与3D语义场景图结合。

Result: LIEREx实现了开放集映射，使自主代理能够在部分未知环境中进行目标导向探索。

Conclusion: LIEREx通过整合视觉语言基础模型（VLFMs）和3D语义场景图，实现了在部分未知环境中自主代理的目标导向探索。

Abstract: Semantic maps allow a robot to reason about its surroundings to fulfill tasks such as navigating known environments, finding specific objects, and exploring unmapped areas. Traditional mapping approaches provide accurate geometric representations but are often constrained by pre-designed symbolic vocabularies. The reliance on fixed object classes makes it impractical to handle out-of-distribution knowledge not defined at design time. Recent advances in Vision-Language Foundation Models, such as CLIP, enable open-set mapping, where objects are encoded as high-dimensional embeddings rather than fixed labels. In LIEREx, we integrate these VLFMs with established 3D Semantic Scene Graphs to enable target-directed exploration by an autonomous agent in partially unknown environments.

</details>


### [563] [Towards Exploratory and Focused Manipulation with Bimanual Active Perception: A New Problem, Benchmark and Strategy](https://arxiv.org/abs/2602.01939)
*Yuxin He,Ruihao Zhang,Tianao Shen,Cheng Liu,Qiang Nie*

Main category: cs.RO

TL;DR: 论文提出EFM问题和BAP策略，通过EFM-10基准和BAPData验证了策略有效性。


<details>
  <summary>Details</summary>
Motivation: 视觉遮挡问题在机器人头部安装主摄像头时更为常见，其本质是缺乏完成任务所需的信息。

Method: 提出Bimanual Active Perception (BAP)策略，利用一只手臂提供主动视觉，另一只手臂提供力感知。

Result: 建立了EFM-10基准和BAPData数据集，验证了BAP策略的有效性。

Conclusion: EFM-10基准和BAP策略为未来研究提供了基础，验证了BAP策略在模仿学习中的有效性。

Abstract: Recently, active vision has reemerged as an important concept for manipulation, since visual occlusion occurs more frequently when main cameras are mounted on the robot heads. We reflect on the visual occlusion issue and identify its essence as the absence of information useful for task completion. Inspired by this, we come up with the more fundamental problem of Exploratory and Focused Manipulation (EFM). The proposed problem is about actively collecting information to complete challenging manipulation tasks that require exploration or focus. As an initial attempt to address this problem, we establish the EFM-10 benchmark that consists of 4 categories of tasks that align with our definition (10 tasks in total). We further come up with a Bimanual Active Perception (BAP) strategy, which leverages one arm to provide active vision and another arm to provide force sensing while manipulating. Based on this idea, we collect a dataset named BAPData for the tasks in EFM-10. With the dataset, we successfully verify the effectiveness of the BAP strategy in an imitation learning manner. We hope that the EFM-10 benchmark along with the BAP strategy can become a cornerstone that facilitates future research towards this direction. Project website: EFManipulation.github.io.

</details>


### [564] [A Unified Control Architecture for Macro-Micro Manipulation using a Active Remote Center of Compliance for Manufacturing Applications](https://arxiv.org/abs/2602.01948)
*Patrick Frank,Christian Friedrich*

Main category: cs.RO

TL;DR: 提出新型控制架构，显著提升交互控制带宽，实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 传统方法将位置控制和交互控制分别分配给宏操作器和微操作器，限制了交互控制的带宽。

Method: 结合宏操作器和微操作器，提出了一种新型控制架构，并引入了替代模型以优化控制器设计。

Result: 新型控制架构的带宽比现有技术提高了2.1倍，比传统机器人力控制提高了12.5倍。

Conclusion: 提出的新型控制架构显著提高了交互控制的带宽，并通过实验验证了其在多种任务中的优越性。

Abstract: Macro-micro manipulators combine a macro manipulator with a large workspace, such as an industrial robot, with a lightweight, high-bandwidth micro manipulator. This enables highly dynamic interaction control while preserving the wide workspace of the robot. Traditionally, position control is assigned to the macro manipulator, while the micro manipulator handles the interaction with the environment, limiting the achievable interaction control bandwidth. To solve this, we propose a novel control architecture that incorporates the macro manipulator into the active interaction control. This leads to a increase in control bandwidth by a factor of 2.1 compared to the state of the art architecture, based on the leader-follower approach and factor 12.5 compared to traditional robot-based force control. Further we propose surrogate models for a more efficient controller design and easy adaptation to hardware changes. We validate our approach by comparing it against the other control schemes in different experiments, like collision with an object, following a force trajectory and industrial assembly tasks.

</details>


### [565] [Reformulating AI-based Multi-Object Relative State Estimation for Aleatoric Uncertainty-based Outlier Rejection of Partial Measurements](https://arxiv.org/abs/2602.02006)
*Thomas Jantos,Giulio Delama,Stephan Weiss,Jan Steinbrener*

Main category: cs.RO

TL;DR: 本文提出了一种改进的AI基于对象相对状态估计方法，通过解耦位置和旋转测量及使用DNN预测的不确定性，提升了状态估计器的性能和一致性。


<details>
  <summary>Details</summary>
Motivation: 随着能够实时部署深度神经网络（DNNs）的边缘设备的兴起，利用人工智能（AI）从原始图像数据中提取对象特定的语义信息（如对象类别和相对六自由度（6-DoF）姿态）变得可行。然而，在扩展卡尔曼滤波器（EKF）中融合这些基于AI的测量需要量化DNNs的不确定性和异常值拒绝能力。

Method: 本文通过推导使用直接对象相对姿态测量的扩展卡尔曼滤波器（EKF），实现了位置和旋转测量的解耦。同时，研究了用DNN预测的偶然不确定性替代固定测量协方差矩阵对状态估计器性能和一致性的改进。

Result: 结果表明，重新定义测量方程可以有效地解耦位置和旋转测量，限制错误旋转测量的影响，并允许部分测量拒绝。使用DNN预测的偶然不确定性替代固定测量协方差矩阵，显著提升了状态估计器的性能和一致性。

Conclusion: 通过重新定义AI基于对象相对状态估计的测量方程，本文展示了其在位置和旋转测量解耦方面的优势，从而限制了错误旋转测量的影响并允许部分测量拒绝。此外，使用DNN预测的偶然不确定性替代固定测量协方差矩阵，进一步提升了状态估计器的性能和一致性。

Abstract: Precise localization with respect to a set of objects of interest enables mobile robots to perform various tasks. With the rise of edge devices capable of deploying deep neural networks (DNNs) for real-time inference, it stands to reason to use artificial intelligence (AI) for the extraction of object-specific, semantic information from raw image data, such as the object class and the relative six degrees of freedom (6-DoF) pose. However, fusing such AI-based measurements in an Extended Kalman Filter (EKF) requires quantifying the DNNs' uncertainty and outlier rejection capabilities.
  This paper presents the benefits of reformulating the measurement equation in AI-based, object-relative state estimation. By deriving an EKF using the direct object-relative pose measurement, we can decouple the position and rotation measurements, thus limiting the influence of erroneous rotation measurements and allowing partial measurement rejection. Furthermore, we investigate the performance and consistency improvements for state estimators provided by replacing the fixed measurement covariance matrix of the 6-DoF object-relative pose measurements with the predicted aleatoric uncertainty of the DNN.

</details>


### [566] [Synchronized Online Friction Estimation and Adaptive Grasp Control for Robust Gentle Grasp](https://arxiv.org/abs/2602.02026)
*Zhenwei Niu,Xiaoyi Chen,Jiayu Hu,Zhaoyang Liu,Xiaozu Ju*

Main category: cs.RO

TL;DR: 提出了一种结合实时摩擦估计与自适应抓取控制的统一框架，通过粒子滤波和反应控制器实现稳定抓握，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决机器人抓取中实时摩擦估计与自适应控制的协同问题，提高抓取的响应性和鲁棒性。

Method: 采用基于粒子滤波的新方法，利用视觉触觉传感器实时估计摩擦系数，并将其无缝集成到反应控制器中，动态调节抓取力以保持稳定抓握。

Result: 实验验证了该框架的可靠性和效率，实现了高度响应和鲁棒的传感器运动循环。

Conclusion: 该论文提出了一个统一的框架，将实时摩擦估计与自适应抓取控制相结合，通过广泛的机器人实验验证了其可靠性和效率。

Abstract: We introduce a unified framework for gentle robotic grasping that synergistically couples real-time friction estimation with adaptive grasp control. We propose a new particle filter-based method for real-time estimation of the friction coefficient using vision-based tactile sensors. This estimate is seamlessly integrated into a reactive controller that dynamically modulates grasp force to maintain a stable grip. The two processes operate synchronously in a closed-loop: the controller uses the current best estimate to adjust the force, while new tactile feedback from this action continuously refines the estimation. This creates a highly responsive and robust sensorimotor cycle. The reliability and efficiency of the complete framework are validated through extensive robotic experiments.

</details>


### [567] [Bandwidth-Efficient Multi-Agent Communication through Information Bottleneck and Vector Quantization](https://arxiv.org/abs/2602.02035)
*Ahmad Farooq,Kamran Iqbal*

Main category: cs.RO

TL;DR: 该论文提出了一种结合信息瓶颈和向量量化的多智能体通信框架，显著提升性能并减少带宽使用。


<details>
  <summary>Details</summary>
Motivation: 解决现实世界机器人应用中多智能体强化学习系统面临的严重通信约束问题，提升协调效率。

Method: 通过信息理论优化学习压缩和离散化通信消息，同时保留任务关键信息，并引入门控通信机制动态决定何时需要通信。

Result: 在具有挑战性的协调任务中，该方法相比无通信基线实现了181.8%的性能提升，同时减少了41.4%的带宽使用。

Conclusion: 该论文提出了一个结合信息瓶颈理论和向量量化的框架，用于在多智能体环境中实现选择性、带宽高效的通信，显著提升了在带宽受限环境下的多智能体系统性能。

Abstract: Multi-agent reinforcement learning systems deployed in real-world robotics applications face severe communication constraints that significantly impact coordination effectiveness. We present a framework that combines information bottleneck theory with vector quantization to enable selective, bandwidth-efficient communication in multi-agent environments. Our approach learns to compress and discretize communication messages while preserving task-critical information through principled information-theoretic optimization. We introduce a gated communication mechanism that dynamically determines when communication is necessary based on environmental context and agent states. Experimental evaluation on challenging coordination tasks demonstrates that our method achieves 181.8% performance improvement over no-communication baselines while reducing bandwidth usage by 41.4%. Comprehensive Pareto frontier analysis shows dominance across the entire success-bandwidth spectrum with area-under-curve of 0.198 vs 0.142 for next-best methods. Our approach significantly outperforms existing communication strategies and establishes a theoretically grounded framework for deploying multi-agent systems in bandwidth-constrained environments such as robotic swarms, autonomous vehicle fleets, and distributed sensor networks.

</details>


### [568] [Frictional Contact Solving for Material Point Method](https://arxiv.org/abs/2602.02038)
*Etienne Ménager,Justin Carpentier*

Main category: cs.RO

TL;DR: 本文提出了一种精确且鲁棒的隐式MPM摩擦接触处理流程，通过粒子几何基元定位接触点，并采用ADMM求解NCP问题，实现了高效稳定的摩擦接触模拟。


<details>
  <summary>Details</summary>
Motivation: 准确处理带摩擦的接触是材料点方法（MPM）的核心瓶颈，从可靠的接触点检测到强制执行摩擦接触定律（非穿透、库仑摩擦和最大耗散原则）。

Method: 在碰撞检测阶段，使用粒子为中心的几何基元定位接触点；在接触解决阶段，将摩擦接触建模为接触冲量的非线性互补问题（NCP），并通过交替方向乘子法（ADMM）方案求解。该方法无缝集成到隐式MPM循环中，并对建模选择（包括材料定律、插值函数和传输方案）保持不可知。

Result: 在七个代表性场景中评估了该方法，涵盖了弹性和弹塑性响应、简单和复杂的可变形几何形状，以及广泛的接触条件。

Conclusion: 提出的方法实现了精确的接触定位、可靠的摩擦处理以及广泛的通用性，使其成为基于MPM的机器人及相关领域仿真的实用解决方案。

Abstract: Accurately handling contact with friction remains a core bottleneck for Material Point Method (MPM), from reliable contact point detection to enforcing frictional contact laws (non-penetration, Coulomb friction, and maximum dissipation principle). In this paper, we introduce a frictional-contact pipeline for implicit MPM that is both precise and robust. During the collision detection phase, contact points are localized with particle-centric geometric primitives; during the contact resolution phase, we cast frictional contact as a Nonlinear Complementarity Problem (NCP) over contact impulses and solve it with an Alternating Direction Method of Multipliers (ADMM) scheme. Crucially, the formulation reuses the same implicit MPM linearization, yielding efficiency and numerical stability. The method integrates seamlessly into the implicit MPM loop and is agnostic to modeling choices, including material laws, interpolation functions, and transfer schemes. We evaluate it across seven representative scenes that span elastic and elasto-plastic responses, simple and complex deformable geometries, and a wide range of contact conditions. Overall, the proposed method enables accurate contact localization, reliable frictional handling, and broad generality, making it a practical solution for MPM-based simulations in robotics and related domains.

</details>


### [569] [FD-VLA: Force-Distilled Vision-Language-Action Model for Contact-Rich Manipulation](https://arxiv.org/abs/2602.02142)
*Ruiteng Zhao,Wenshuo Wang,Yicheng Ma,Xiaocong Li,Francis E. H. Tay,Marcelo H. Ang,Haiyue Zhu*

Main category: cs.RO

TL;DR: FD-VLA框架通过FDM模块实现无需物理力传感器的力感知，实验表现优于直接传感器测量。


<details>
  <summary>Details</summary>
Motivation: 力感知是Vision-Language-Action (VLA) 框架的关键模态，但依赖物理力传感器会增加硬件成本和复杂性。FD-VLA旨在解决这一问题。

Method: FD-VLA 框架通过FDM模块，将可学习的查询令牌映射到预测的力令牌，并与实际力信号的潜在表示对齐，从而在推理时将蒸馏的力令牌注入预训练的VLM中。

Result: 实验表明，蒸馏的力令牌优于直接传感器测量和其他基线方法，提升了跨模态对齐和接触丰富场景下的感知-动作鲁棒性。

Conclusion: Force-Distilled VLA (FD-VLA) 框架通过Force Distillation Module (FDM) 实现了无需物理力传感器的力感知，且在实验中表现优于直接传感器测量，证明了其有效性。

Abstract: Force sensing is a crucial modality for Vision-Language-Action (VLA) frameworks, as it enables fine-grained perception and dexterous manipulation in contact-rich tasks. We present Force-Distilled VLA (FD-VLA), a novel framework that integrates force awareness into contact-rich manipulation without relying on physical force sensors. The core of our approach is a Force Distillation Module (FDM), which distills force by mapping a learnable query token, conditioned on visual observations and robot states, into a predicted force token aligned with the latent representation of actual force signals. During inference, this distilled force token is injected into the pretrained VLM, enabling force-aware reasoning while preserving the integrity of its vision-language semantics. This design provides two key benefits: first, it allows practical deployment across a wide range of robots that lack expensive or fragile force-torque sensors, thereby reducing hardware cost and complexity; second, the FDM introduces an additional force-vision-state fusion prior to the VLM, which improves cross-modal alignment and enhances perception-action robustness in contact-rich scenarios. Surprisingly, our physical experiments show that the distilled force token outperforms direct sensor force measurements as well as other baselines, which highlights the effectiveness of this force-distilled VLA approach.

</details>


### [570] [Extending the Law of Intersegmental Coordination: Implications for Powered Prosthetic Controls](https://arxiv.org/abs/2602.02181)
*Elad Siman Tov,Nili E. Krausz*

Main category: cs.RO

TL;DR: 研究开发了分析下肢节段间协调的新方法，扩展了ISC理论并发现健康与截肢者步态的协调差异，可能改进假肢控制。


<details>
  <summary>Details</summary>
Motivation: 减少截肢者行走的代谢成本是一个未解决的问题，而节段间协调律（ISC）在步态能量消耗中的作用尚未在截肢者步态中得到充分研究。

Method: 开发了一种分析下肢3D运动学数据中节段间协调的方法，并扩展了ISC理论，提出了基于力矩的协调新法则（ESM）。

Result: 发现健康步态中存在基于力矩的协调（ESM），而截肢者使用动力或被动假肢时ESM协调性较差。利用ISC约束预测了补偿被动假肢影响的策略。

Conclusion: ISC3d工具箱的开发为研究步态协调及其在神经控制中的作用提供了新工具，可能有助于改进动力假肢控制。

Abstract: Powered prostheses are capable of providing net positive work to amputees and have advanced in the past two decades. However, reducing amputee metabolic cost of walking remains an open problem. The Law of Intersegmental Coordination (ISC) has been observed across gaits and has been previously implicated in energy expenditure of walking, yet it has rarely been analyzed or applied within the context of lower-limb amputee gait. This law states that the elevation angles of the thigh, shank and foot over the gait cycle are not independent. In this work, we developed a method to analyze intersegmental coordination for lower-limb 3D kinematic data, to simplify ISC analysis. Moreover, inspired by motor control, biomechanics and robotics literature, we used our method to broaden ISC toward a new law of coordination of moments. We find these Elevation Space Moments (ESM), and present results showing a moment-based coordination for able bodied gait. We also analyzed ISC for amputee gait walking with powered and passive prosthesis, and found that while elevation angles remained planar, the ESM showed less coordination. We use ISC as a constraint to predict the shank angles/moments that would compensate for alterations due to a passive foot so as to mimic a healthy thigh angle/moment profile. This may have implications for improving powered prosthetic control. We developed the ISC3d toolbox that is freely available online, which may be used to compute kinematic and kinetic ISC in 3D. This provides a means to further study the role of coordination in gait and may help address fundamental questions of the neural control of human movement.

</details>


### [571] [Online Fine-Tuning of Pretrained Controllers for Autonomous Driving via Real-Time Recurrent RL](https://arxiv.org/abs/2602.02236)
*Julian Lemmel,Felix Resch,Mónika Farsang,Ramin Hasani,Daniela Rus,Radu Grosu*

Main category: cs.RO

TL;DR: RTRRL结合LRC-RNN能有效微调预训练策略，提升自动驾驶代理在动态环境中的性能。


<details>
  <summary>Details</summary>
Motivation: 预训练策略在遇到系统动态变化、传感器漂移或任务目标变化时性能会迅速下降，限制了学习型控制系统的实际应用。

Method: 本研究结合了实时循环强化学习（RTRRL）与液体电阻-液体电容循环神经网络（LRC-RNN），并在模拟CarRacing环境和真实RoboRacer车辆线跟随任务中进行了验证。

Result: 实验证明，RTRRL能够有效提升自动驾驶代理在动态环境中的适应性，特别是在模拟和真实世界的驾驶任务中表现优异。

Conclusion: 研究表明，采用实时循环强化学习（RTRRL）能够有效微调预训练策略，提升自动驾驶代理在动态环境中的性能。

Abstract: Deploying pretrained policies in real-world applications presents substantial challenges that fundamentally limit the practical applicability of learning-based control systems. When autonomous systems encounter environmental changes in system dynamics, sensor drift, or task objectives, fixed policies rapidly degrade in performance. We show that employing Real-Time Recurrent Reinforcement Learning (RTRRL), a biologically plausible algorithm for online adaptation, can effectively fine-tune a pretrained policy to improve autonomous agents' performance on driving tasks. We further show that RTRRL synergizes with a recent biologically inspired recurrent network model, the Liquid-Resistance Liquid-Capacitance RNN. We demonstrate the effectiveness of this closed-loop approach in a simulated CarRacing environment and in a real-world line-following task with a RoboRacer car equipped with an event camera.

</details>


### [572] [TTT-Parkour: Rapid Test-Time Training for Perceptive Robot Parkour](https://arxiv.org/abs/2602.02331)
*Shaoting Zhu,Baijun Ye,Jiaxuan Wang,Jiakang Chen,Ziwen Zhuang,Linzhan Mou,Runhan Huang,Hang Zhao*

Main category: cs.RO

TL;DR: 提出实时到仿真再到现实框架，通过快速测试时训练提升人形机器人在复杂地形中的跑酷能力，实现高效零样本迁移。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人在未知复杂地形上动态跑酷的挑战，克服现有通用运动策略在极端环境中的局限性。

Method: 采用两阶段端到端学习范式：首先在多样化的程序生成地形上预训练策略，随后在高保真网格上进行快速微调。开发了基于RGB-D输入的高效高保真几何重建流程。

Result: TTT-Parkour框架使机器人能够掌握复杂障碍物（如楔子、桩、盒子、梯形和窄梁），整个流程在大多数地形上不到10分钟完成。

Conclusion: 该研究通过实时到仿真再到现实的框架，结合快速测试时训练（TTT），显著提升了人形机器人在复杂地形中的动态跑酷能力，实现了高效的零样本仿真到现实迁移。

Abstract: Achieving highly dynamic humanoid parkour on unseen, complex terrains remains a challenge in robotics. Although general locomotion policies demonstrate capabilities across broad terrain distributions, they often struggle with arbitrary and highly challenging environments. To overcome this limitation, we propose a real-to-sim-to-real framework that leverages rapid test-time training (TTT) on novel terrains, significantly enhancing the robot's capability to traverse extremely difficult geometries. We adopt a two-stage end-to-end learning paradigm: a policy is first pre-trained on diverse procedurally generated terrains, followed by rapid fine-tuning on high-fidelity meshes reconstructed from real-world captures. Specifically, we develop a feed-forward, efficient, and high-fidelity geometry reconstruction pipeline using RGB-D inputs, ensuring both speed and quality during test-time training. We demonstrate that TTT-Parkour empowers humanoid robots to master complex obstacles, including wedges, stakes, boxes, trapezoids, and narrow beams. The whole pipeline of capturing, reconstructing, and test-time training requires less than 10 minutes on most tested terrains. Extensive experiments show that the policy after test-time training exhibits robust zero-shot sim-to-real transfer capability.

</details>


### [573] [Mapping-Guided Task Discovery and Allocation for Robotic Inspection of Underwater Structures](https://arxiv.org/abs/2602.02389)
*Marina Ruediger,Ashis G. Banerjee*

Main category: cs.RO

TL;DR: 提出一种基于SLAM数据的水下多机器人检查任务生成方法，通过优化和比较验证其适应性和覆盖效果。


<details>
  <summary>Details</summary>
Motivation: 解决水下多机器人检查任务生成时缺乏现有几何知识的问题。

Method: 通过考虑硬件参数和环境条件，从SLAM网格生成一组任务，并通过预期关键点分数和基于距离的剪枝进行优化。

Result: 通过水中测试验证算法的有效性，并与模拟的Voronoi分区和boustrophedon模式进行比较，展示了该方法在检查覆盖上的优势。

Conclusion: 提出的任务发现方法具有适应意外几何形状的能力，并能在保持覆盖的同时重点关注更可能出现缺陷或损坏的区域。

Abstract: Task generation for underwater multi-robot inspections without prior knowledge of existing geometry can be achieved and optimized through examination of simultaneous localization and mapping (SLAM) data. By considering hardware parameters and environmental conditions, a set of tasks is generated from SLAM meshes and optimized through expected keypoint scores and distance-based pruning. In-water tests are used to demonstrate the effectiveness of the algorithm and determine the appropriate parameters. These results are compared to simulated Voronoi partitions and boustrophedon patterns for inspection coverage on a model of the test environment. The key benefits of the presented task discovery method include adaptability to unexpected geometry and distributions that maintain coverage while focusing on areas more likely to present defects or damage.

</details>


### [574] [PRISM: Performer RS-IMLE for Single-pass Multisensory Imitation Learning](https://arxiv.org/abs/2602.02396)
*Amisha Bhaskar,Pratap Tokekar,Stefano Di Cairano,Alexander Schperberg*

Main category: cs.RO

TL;DR: PRISM是一种基于IMLE的新型模仿学习策略，通过多感官集成和高效生成架构，在多项任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的生成方法（如扩散模型、流匹配和IMLE）往往只能满足部分需求（如多模态动作分布、实时控制速率和多传感模态集成），因此需要一种更全面的解决方案。

Method: PRISM基于IMLE的批处理全局拒绝采样变体，结合了时间多感官编码器（集成RGB、深度、触觉、音频和本体感觉）与使用Performer架构的线性注意力生成器。

Result: 在真实硬件和仿真基准测试中，PRISM在任务成功率上比现有扩散策略高出10-25%，同时保持高频（30-50 Hz）闭环控制，并在CALVIN等基准上显著提升性能。

Conclusion: PRISM作为一种快速、准确且多感官的模仿策略，在不引入迭代采样延迟的情况下，保持了多模态动作覆盖，显著提升了任务成功率和控制效率。

Abstract: Robotic imitation learning typically requires models that capture multimodal action distributions while operating at real-time control rates and accommodating multiple sensing modalities. Although recent generative approaches such as diffusion models, flow matching, and Implicit Maximum Likelihood Estimation (IMLE) have achieved promising results, they often satisfy only a subset of these requirements. To address this, we introduce PRISM, a single-pass policy based on a batch-global rejection-sampling variant of IMLE. PRISM couples a temporal multisensory encoder (integrating RGB, depth, tactile, audio, and proprioception) with a linear-attention generator using a Performer architecture. We demonstrate the efficacy of PRISM on a diverse real-world hardware suite, including loco-manipulation using a Unitree Go2 with a 7-DoF arm D1 and tabletop manipulation with a UR5 manipulator. Across challenging physical tasks such as pre-manipulation parking, high-precision insertion, and multi-object pick-and-place, PRISM outperforms state-of-the-art diffusion policies by 10-25% in success rate while maintaining high-frequency (30-50 Hz) closed-loop control. We further validate our approach on large-scale simulation benchmarks, including CALVIN, MetaWorld, and Robomimic. In CALVIN (10% data split), PRISM improves success rates by approximately 25% over diffusion and approximately 20% over flow matching, while simultaneously reducing trajectory jerk by 20x-50x. These results position PRISM as a fast, accurate, and multisensory imitation policy that retains multimodal action coverage without the latency of iterative sampling.

</details>


### [575] [SoMA: A Real-to-Sim Neural Simulator for Robotic Soft-body Manipulation](https://arxiv.org/abs/2602.02402)
*Mu Huang,Hui Wang,Kerui Ren,Linning Xu,Yunsong Zhou,Mulin Yu,Bo Dai,Jiangmiao Pang*

Main category: cs.RO

TL;DR: SoMA是一种3D高斯泼溅模拟器，通过统一潜在神经空间耦合可变形动力学、环境力和机器人动作，提升了仿真精度和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有模拟器依赖预定义物理或数据驱动的动力学，缺乏机器人条件控制，限制了精度、稳定性和泛化能力。

Method: SoMA采用3D高斯泼溅模拟器，通过学习的高斯泼溅建模交互，实现了可控、稳定的长时程操作，无需预定义物理模型。

Result: SoMA在真实世界机器人操作中的重模拟精度和泛化能力提高了20%，能够稳定模拟复杂任务如长时程布料折叠。

Conclusion: SoMA通过将可变形物体动力学、环境力和机器人联合动作耦合在一个统一的潜在神经空间中，实现了端到端的真实到模拟仿真，显著提升了仿真精度和泛化能力。

Abstract: Simulating deformable objects under rich interactions remains a fundamental challenge for real-to-sim robot manipulation, with dynamics jointly driven by environmental effects and robot actions. Existing simulators rely on predefined physics or data-driven dynamics without robot-conditioned control, limiting accuracy, stability, and generalization. This paper presents SoMA, a 3D Gaussian Splat simulator for soft-body manipulation. SoMA couples deformable dynamics, environmental forces, and robot joint actions in a unified latent neural space for end-to-end real-to-sim simulation. Modeling interactions over learned Gaussian splats enables controllable, stable long-horizon manipulation and generalization beyond observed trajectories without predefined physical models. SoMA improves resimulation accuracy and generalization on real-world robot manipulation by 20%, enabling stable simulation of complex tasks such as long-horizon cloth folding.

</details>


### [576] [Multi-Agent Monte Carlo Tree Search for Makespan-Efficient Object Rearrangement in Cluttered Spaces](https://arxiv.org/abs/2602.02411)
*Hanwen Ren,Junyong Kim,Aathman Tharmasanthiran,Ahmed H. Qureshi*

Main category: cs.RO

TL;DR: CAM-MCTS通过集中式任务分配和异步执行策略，优化多智能体在复杂环境中的对象重排效率。


<details>
  <summary>Details</summary>
Motivation: 解决现实世界中非单调对象重排任务中多智能体协作效率低下的问题。

Method: 结合集中式任务分配和异步任务执行策略，通过一步前瞻成本估计指导智能体行动。

Result: 在杂乱环境中，CAM-MCTS相比基线方法一致减少了任务完成时间。

Conclusion: CAM-MCTS框架在复杂环境中有效减少了任务完成时间，并在实际多智能体系统中验证了其有效性和鲁棒性。

Abstract: Object rearrangement planning in complex, cluttered environments is a common challenge in warehouses, households, and rescue sites. Prior studies largely address monotone instances, whereas real-world tasks are often non-monotone-objects block one another and must be temporarily relocated to intermediate positions before reaching their final goals. In such settings, effective multi-agent collaboration can substantially reduce the time required to complete tasks. This paper introduces Centralized, Asynchronous, Multi-agent Monte Carlo Tree Search (CAM-MCTS), a novel framework for general-purpose makespan-efficient object rearrangement planning in challenging environments. CAM-MCTS combines centralized task assignment-where agents remain aware of each other's intended actions to facilitate globally optimized planning-with an asynchronous task execution strategy that enables agents to take on new tasks at appropriate time steps, rather than waiting for others, guided by a one-step look-ahead cost estimate. This design minimizes idle time, prevents unnecessary synchronization delays, and enhances overall system efficiency. We evaluate CAM-MCTS across a diverse set of monotone and non-monotone tasks in cluttered environments, demonstrating consistent reductions in makespan compared to strong baselines. Finally, we validate our approach on a real-world multi-agent system under different configurations, further confirming its effectiveness and robustness.

</details>


### [577] [3D Foundation Model-Based Loop Closing for Decentralized Collaborative SLAM](https://arxiv.org/abs/2602.02430)
*Pierre-Yves Lajoie,Benjamin Ramtoula,Daniele De Martini,Giovanni Beltrame*

Main category: cs.RO

TL;DR: 利用3D基础模型提升分散式协作SLAM的稳健性和效率，解决了视角差异导致的地图重叠识别问题。


<details>
  <summary>Details</summary>
Motivation: 解决分散式协作SLAM技术因机器人视角差异大而难以识别地图重叠的问题。

Method: 集成了3D基础模型到现有SLAM流程中，提出了稳健的异常值抑制技术和专门的位姿图优化方法。

Result: 与现有先进方法相比，该方法在定位和建图精度、计算和内存效率上均有显著提升。

Conclusion: 该方法在定位和建图精度上有所提升，同时显著提高了计算和内存效率，展示了在大规模多机器人场景中的部署潜力。

Abstract: Decentralized Collaborative Simultaneous Localization And Mapping (C-SLAM) techniques often struggle to identify map overlaps due to significant viewpoint variations among robots. Motivated by recent advancements in 3D foundation models, which can register images despite large viewpoint differences, we propose a robust loop closing approach that leverages these models to establish inter-robot measurements. In contrast to resource-intensive methods requiring full 3D reconstruction within a centralized map, our approach integrates foundation models into existing SLAM pipelines, yielding scalable and robust multi-robot mapping. Our contributions include: (1) integrating 3D foundation models to reliably estimate relative poses from monocular image pairs within decentralized C-SLAM; (2) introducing robust outlier mitigation techniques critical to the use of these relative poses; and (3) developing specialized pose graph optimization formulations that efficiently resolve scale ambiguities. We evaluate our method against state-of-the-art approaches, demonstrating improvements in localization and mapping accuracy, alongside significant gains in computational and memory efficiency. These results highlight the potential of our approach for deployment in large-scale multi-robot scenarios.

</details>


### [578] [World-Gymnast: Training Robots with Reinforcement Learning in a World Model](https://arxiv.org/abs/2602.02454)
*Ansh Kumar Sharma,Yixiang Sun,Ninghao Lu,Yunzhe Zhang,Jiarao Liu,Sherry Yang*

Main category: cs.RO

TL;DR: World-Gymnast通过世界模型和VLM进行RL微调，显著超越SFT和软件模拟，展示了世界模型RL的潜力。


<details>
  <summary>Details</summary>
Motivation: 机器人通过与物理世界交互学习受到物理交互成本的限制，而监督微调（SFT）和软件模拟中的强化学习（RL）分别受限于专家数据量和模拟到现实的差距。

Method: 提出了World-Gymnast方法，通过在动作条件视频世界模型中展开策略，并使用视觉语言模型（VLM）奖励展开结果，进行视觉语言动作（VLA）策略的强化学习微调。

Result: 在Bridge机器人设置中，World-Gymnast比SFT表现高出18倍，比软件模拟高出2倍，并展示了世界模型RL的有趣能力。

Conclusion: 学习世界模型并在云端训练机器人策略可能是缩小演示机器人与家用机器人之间差距的关键。

Abstract: Robot learning from interacting with the physical world is fundamentally bottlenecked by the cost of physical interaction. The two alternatives, supervised finetuning (SFT) from expert demonstrations and reinforcement learning (RL) in a software-based simulator, are limited by the amount of expert data available and the sim-to-real gap for manipulation. With the recent emergence of world models learned from real-world video-action data, we ask the question of whether training a policy in a world model can be more effective than supervised learning or software simulation in achieving better real-robot performance. We propose World-Gymnast, which performs RL finetuning of a vision-language-action (VLA) policy by rolling out the policy in an action-conditioned video world model and rewarding the rollouts with a vision-language model (VLM). On the Bridge robot setup, World-Gymnast outperforms SFT by as much as 18x and outperforms software simulator by as much as 2x. More importantly, World-Gymnast demonstrates intriguing capabilities of RL with a world model, including training on diverse language instructions and novel scenes from the world model, test-time training in a novel scene, and online iterative world model and policy improvement. Our results suggest learning a world model and training robot policies in the cloud could be the key to bridging the gap between robots that work in demonstrations and robots that can work in anyone's household.

</details>


### [579] [Relationship-Aware Hierarchical 3D Scene Graph for Task Reasoning](https://arxiv.org/abs/2602.02456)
*Albert Gassol Puigjaner,Angelos Zacharia,Kostas Alexis*

Main category: cs.RO

TL;DR: 该论文提出了一种结合开放词汇特征和对象关系推理的增强型3D场景图，通过VLM和LLM实现智能任务推理，并在机器人上验证了其效果。


<details>
  <summary>Details</summary>
Motivation: 传统SLAM方法缺乏高层次抽象和关系推理能力，3D场景图作为一种强大的表示方法可以弥补这一不足。

Method: 利用视觉语言模型（VLM）推断语义关系，并引入任务推理模块，结合大型语言模型（LLM）和VLM来解释场景图的语义和关系信息。

Result: 提出的方法在四足机器人上成功部署，展示了其在多种环境和任务中的推理能力。

Conclusion: 该论文提出了一种增强的分层3D场景图，结合了开放词汇特征和多层次抽象，支持对象关系推理，并通过四足机器人在多种环境和任务中的部署验证了其有效性。

Abstract: Representing and understanding 3D environments in a structured manner is crucial for autonomous agents to navigate and reason about their surroundings. While traditional Simultaneous Localization and Mapping (SLAM) methods generate metric reconstructions and can be extended to metric-semantic mapping, they lack a higher level of abstraction and relational reasoning. To address this gap, 3D scene graphs have emerged as a powerful representation for capturing hierarchical structures and object relationships. In this work, we propose an enhanced hierarchical 3D scene graph that integrates open-vocabulary features across multiple abstraction levels and supports object-relational reasoning. Our approach leverages a Vision Language Model (VLM) to infer semantic relationships. Notably, we introduce a task reasoning module that combines Large Language Models (LLM) and a VLM to interpret the scene graph's semantic and relational information, enabling agents to reason about tasks and interact with their environment more intelligently. We validate our method by deploying it on a quadruped robot in multiple environments and tasks, highlighting its ability to reason about them.

</details>


### [580] [TIC-VLA: A Think-in-Control Vision-Language-Action Model for Robot Navigation in Dynamic Environments](https://arxiv.org/abs/2602.02459)
*Zhiyu Huang,Yun Zhang,Johnson Liu,Rui Song,Chen Tang,Jiaqi Ma*

Main category: cs.RO

TL;DR: TIC-VLA是一个延迟感知框架，通过显式建模语义推理延迟，在语言指令导航任务中优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决现有VLA模型假设时间对齐推理与控制的局限性，适应语义推理的固有延迟。

Method: 提出TIC-VLA框架，定义延迟语义-控制接口，结合延迟的视觉-语言语义状态和显式延迟元数据生成动作，并提出延迟一致的训练流程。

Result: 在仿真和真实机器人实验中，TIC-VLA表现优于现有VLA模型，并在高延迟下保持实时控制。

Conclusion: TIC-VLA框架通过显式建模延迟语义推理，在实时控制中显著优于现有VLA模型，并在多秒推理延迟下保持鲁棒性。

Abstract: Robots in dynamic, human-centric environments must follow language instructions while maintaining real-time reactive control. Vision-language-action (VLA) models offer a promising framework, but they assume temporally aligned reasoning and control, despite semantic inference being inherently delayed relative to real-time action. We introduce Think-in-Control (TIC)-VLA, a latency-aware framework that explicitly models delayed semantic reasoning during action generation. TIC-VLA defines a delayed semantic-control interface that conditions action generation on delayed vision-language semantic states and explicit latency metadata, in addition to current observations, enabling policies to compensate for asynchronous reasoning. We further propose a latency-consistent training pipeline that injects reasoning inference delays during imitation learning and online reinforcement learning, aligning training with asynchronous deployment. To support realistic evaluation, we present DynaNav, a physics-accurate, photo-realistic simulation suite for language-guided navigation in dynamic environments. Extensive experiments in simulation and on a real robot show that TIC-VLA consistently outperforms prior VLA models while maintaining robust real-time control under multi-second reasoning latency. Project website: https://ucla-mobility.github.io/TIC-VLA/

</details>


### [581] [HumanX: Toward Agile and Generalizable Humanoid Interaction Skills from Human Videos](https://arxiv.org/abs/2602.02473)
*Yinhuai Wang,Qihan Zhao,Yuen Fui Lau,Runyi Yu,Hok Wai Tsui,Qifeng Chen,Jingbo Wang,Jiangmiao Pang,Ping Tan*

Main category: cs.RO

TL;DR: HumanX框架通过视频数据生成和模仿学习，使类人机器人无需任务特定奖励即可学习多样交互技能，泛化能力显著提升。


<details>
  <summary>Details</summary>
Motivation: 解决类人机器人在敏捷和适应性交互任务中面临的现实交互数据稀缺和任务特定奖励工程繁琐的问题。

Method: HumanX整合了两个协同设计的组件：XGen（数据生成管道）和XMimic（统一模仿学习框架），前者从视频中合成多样且物理合理的机器人交互数据，后者学习可泛化的交互技能。

Result: HumanX在五个不同领域中成功学习了10种技能，并在物理机器人上实现了零样本迁移，泛化成功率比现有方法高出8倍以上。

Conclusion: HumanX框架通过从人类视频中提取可泛化的交互技能，为类人机器人提供了一种无需任务特定奖励的、可扩展的学习路径，显著提升了泛化能力。

Abstract: Enabling humanoid robots to perform agile and adaptive interactive tasks has long been a core challenge in robotics. Current approaches are bottlenecked by either the scarcity of realistic interaction data or the need for meticulous, task-specific reward engineering, which limits their scalability. To narrow this gap, we present HumanX, a full-stack framework that compiles human video into generalizable, real-world interaction skills for humanoids, without task-specific rewards. HumanX integrates two co-designed components: XGen, a data generation pipeline that synthesizes diverse and physically plausible robot interaction data from video while supporting scalable data augmentation; and XMimic, a unified imitation learning framework that learns generalizable interaction skills. Evaluated across five distinct domains--basketball, football, badminton, cargo pickup, and reactive fighting--HumanX successfully acquires 10 different skills and transfers them zero-shot to a physical Unitree G1 humanoid. The learned capabilities include complex maneuvers such as pump-fake turnaround fadeaway jumpshots without any external perception, as well as interactive tasks like sustained human-robot passing sequences over 10 consecutive cycles--learned from a single video demonstration. Our experiments show that HumanX achieves over 8 times higher generalization success than prior methods, demonstrating a scalable and task-agnostic pathway for learning versatile, real-world robot interactive skills.

</details>


### [582] [Flow Policy Gradients for Robot Control](https://arxiv.org/abs/2602.02481)
*Brent Yi,Hongsuk Choi,Himanshu Gaurav Singh,Xiaoyu Huang,Takara E. Truong,Carmelo Sferrazza,Yi Ma,Rocky Duan,Pieter Abbeel,Guanya Shi,Karen Liu,Angjoo Kanazawa*

Main category: cs.RO

TL;DR: 流匹配策略梯度方法通过绕过似然计算，在机器人控制任务中实现了更灵活的策略表达和更好的性能。


<details>
  <summary>Details</summary>
Motivation: 传统的基于似然的策略梯度方法依赖于可微的动作似然，限制了策略输出的分布类型（如高斯分布），而流匹配策略梯度方法可以绕过这一限制，提升策略的表达能力。

Method: 提出了一个改进的目标函数，结合流匹配策略梯度框架，绕过似然计算，使策略输出更灵活。

Result: 实验结果表明，该方法在从零开始训练时能有效利用流表示进行探索，同时在微调时比基线方法更具鲁棒性。

Conclusion: 流匹配策略梯度方法在训练和微调更具表现力的机器人控制策略方面表现出色，尤其在腿式运动、人形运动跟踪和操作任务中，以及实现稳健的模拟到真实环境的迁移。

Abstract: Likelihood-based policy gradient methods are the dominant approach for training robot control policies from rewards. These methods rely on differentiable action likelihoods, which constrain policy outputs to simple distributions like Gaussians. In this work, we show how flow matching policy gradients -- a recent framework that bypasses likelihood computation -- can be made effective for training and fine-tuning more expressive policies in challenging robot control settings. We introduce an improved objective that enables success in legged locomotion, humanoid motion tracking, and manipulation tasks, as well as robust sim-to-real transfer on two humanoid robots. We then present ablations and analysis on training dynamics. Results show how policies can exploit the flow representation for exploration when training from scratch, as well as improved fine-tuning robustness over baselines.

</details>
