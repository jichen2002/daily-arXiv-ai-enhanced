<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 90]
- [cs.AI](#cs.AI) [Total: 25]
- [cs.DS](#cs.DS) [Total: 7]
- [cs.GR](#cs.GR) [Total: 3]
- [cs.DC](#cs.DC) [Total: 3]
- [cs.NI](#cs.NI) [Total: 5]
- [cs.RO](#cs.RO) [Total: 38]
- [cs.OS](#cs.OS) [Total: 1]
- [cs.SE](#cs.SE) [Total: 18]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Intellectual Property Protection for 3D Gaussian Splatting Assets: A Survey](https://arxiv.org/abs/2602.03878)
*Longjie Zhao,Ziming Hong,Jiaxin Huang,Runnan Chen,Mingming Gong,Tongliang Liu*

Main category: cs.CV

TL;DR: 本文首次系统调查了3DGS知识产权保护，提出了分析框架和六个研究方向，填补了当前研究的空白。


<details>
  <summary>Details</summary>
Motivation: 3DGS的商业价值上升及其显式参数结构引发了知识产权保护的担忧，但当前研究缺乏统一视角。

Method: 通过引入自下而上的框架，研究了高斯基础的扰动机制、被动和主动保护范式，以及生成AI时代的鲁棒性威胁。

Result: 揭示了技术基础和鲁棒性表征的空白，并提出了更深层次研究的机遇。

Conclusion: 本文提出了一个系统性调查框架，分析了3D高斯泼溅（3DGS）的知识产权保护问题，并指出了六个研究方向，为未来研究提供了路线图。

Abstract: 3D Gaussian Splatting (3DGS) has become a mainstream representation for real-time 3D scene synthesis, enabling applications in virtual and augmented reality, robotics, and 3D content creation. Its rising commercial value and explicit parametric structure raise emerging intellectual property (IP) protection concerns, prompting a surge of research on 3DGS IP protection. However, current progress remains fragmented, lacking a unified view of the underlying mechanisms, protection paradigms, and robustness challenges. To address this gap, we present the first systematic survey on 3DGS IP protection and introduce a bottom-up framework that examines (i) underlying Gaussian-based perturbation mechanisms, (ii) passive and active protection paradigms, and (iii) robustness threats under emerging generative AI era, revealing gaps in technical foundations and robustness characterization and indicating opportunities for deeper investigation. Finally, we outline six research directions across robustness, efficiency, and protection paradigms, offering a roadmap toward reliable and trustworthy IP protection for 3DGS assets.

</details>


### [2] [TruKAN: Towards More Efficient Kolmogorov-Arnold Networks Using Truncated Power Functions](https://arxiv.org/abs/2602.03879)
*Ali Bayeh,Samira Sadaoui,Malek Mouhoub*

Main category: cs.CV

TL;DR: TruKAN是一种基于KAN的新架构，通过截断幂函数和多项式项提升效率和可解释性，在视觉任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决计算效率与Kolmogorov-Arnold Network（KAN）原则之间的权衡问题，同时增强可解释性。

Method: TruKAN基于KAN结构和可学习激活函数，用截断幂函数替代B样条基，结合多项式项，采用共享或独立节点。集成到EfficientNet-V2框架中，通过混合优化提高收敛稳定性。

Result: TruKAN在准确性和训练时间上优于其他KAN变体，尤其在复杂视觉任务中表现更佳。

Conclusion: TruKAN在复杂视觉任务中表现出优于其他KAN模型的准确性、计算效率和内存使用，展示了超越先前KAN研究的优势。

Abstract: To address the trade-off between computational efficiency and adherence to Kolmogorov-Arnold Network (KAN) principles, we propose TruKAN, a new architecture based on the KAN structure and learnable activation functions. TruKAN replaces the B-spline basis in KAN with a family of truncated power functions derived from k-order spline theory. This change maintains the KAN's expressiveness while enhancing accuracy and training time. Each TruKAN layer combines a truncated power term with a polynomial term and employs either shared or individual knots. TruKAN exhibits greater interpretability than other KAN variants due to its simplified basis functions and knot configurations. By prioritizing interpretable basis functions, TruKAN aims to balance approximation efficacy with transparency. We develop the TruKAN model and integrate it into an advanced EfficientNet-V2-based framework, which is then evaluated on computer vision benchmark datasets. To ensure a fair comparison, we develop various models: MLP-, KAN-, SineKAN and TruKAN-based EfficientNet frameworks and assess their training time and accuracy across small and deep architectures. The training phase uses hybrid optimization to improve convergence stability. Additionally, we investigate layer normalization techniques for all the models and assess the impact of shared versus individual knots in TruKAN. Overall, TruKAN outperforms other KAN models in terms of accuracy, computational efficiency and memory usage on the complex vision task, demonstrating advantages beyond the limited settings explored in prior KAN studies.

</details>


### [3] [DiGAN: Diffusion-Guided Attention Network for Early Alzheimer's Disease Detection](https://arxiv.org/abs/2602.03881)
*Maxx Richard Rahman,Mostafa Hammouda,Wolfgang Maass*

Main category: cs.CV

TL;DR: DiGAN通过扩散模型和注意力卷积网络改进早期阿尔茨海默病检测，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 早期阿尔茨海默病诊断因结构脑变化的微妙和不规则时间进展而具有挑战性，现有深度学习方法需要大量纵向数据且难以建模时间连续性和模态不规则性。

Method: DiGAN结合了潜在扩散模型和注意力引导的卷积网络，扩散模型从有限训练数据中合成真实的纵向神经影像轨迹，注意力卷积层捕捉区分性结构-时间模式。

Result: 在合成和ADNI数据集上的实验表明，DiGAN优于现有基线方法。

Conclusion: DiGAN模型在早期阿尔茨海默病检测中表现出色，优于现有最先进的基线方法。

Abstract: Early diagnosis of Alzheimer's disease (AD) remains a major challenge due to the subtle and temporally irregular progression of structural brain changes in the prodromal stages. Existing deep learning approaches require large longitudinal datasets and often fail to model the temporal continuity and modality irregularities inherent in real-world clinical data. To address these limitations, we propose the Diffusion-Guided Attention Network (DiGAN), which integrates latent diffusion modelling with an attention-guided convolutional network. The diffusion model synthesizes realistic longitudinal neuroimaging trajectories from limited training data, enriching temporal context and improving robustness to unevenly spaced visits. The attention-convolutional layer then captures discriminative structural--temporal patterns that distinguish cognitively normal subjects from those with mild cognitive impairment and subjective cognitive decline. Experiments on synthetic and ADNI datasets demonstrate that DiGAN outperforms existing state-of-the-art baselines, showing its potential for early-stage AD detection.

</details>


### [4] [PriorProbe: Recovering Individual-Level Priors for Personalizing Neural Networks in Facial Expression Recognition](https://arxiv.org/abs/2602.03882)
*Haijiang Yan,Nick Chater,Adam Sanborn*

Main category: cs.CV

TL;DR: PriorProbe是一种新方法，通过MCMC技术恢复个体认知先验，显著提升神经网络在个性化任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有方法无法唯一识别个体认知先验或引入系统性偏差，需要一种新方法来准确获取这些先验。

Method: 引入基于Markov Chain Monte Carlo with People的PriorProbe方法，用于恢复个体特定的精细先验。

Result: PriorProbe恢复的先验在模糊刺激分类任务中显著提升了神经网络的预测性能，优于单独使用神经网络或其他先验来源。

Conclusion: PriorProbe提供了一个通用且可解释的框架，用于个性化深度神经网络，显著提升了性能。

Abstract: Incorporating individual-level cognitive priors offers an important route to personalizing neural networks, yet accurately eliciting such priors remains challenging: existing methods either fail to uniquely identify them or introduce systematic biases. Here, we introduce PriorProbe, a novel elicitation approach grounded in Markov Chain Monte Carlo with People that recovers fine-grained, individual-specific priors. Focusing on a facial expression recognition task, we apply PriorProbe to individual participants and test whether integrating the recovered priors with a state-of-the-art neural network improves its ability to predict an individual's classification on ambiguous stimuli. The PriorProbe-derived priors yield substantial performance gains, outperforming both the neural network alone and alternative sources of priors, while preserving the network's inference on ground-truth labels. Together, these results demonstrate that PriorProbe provides a general and interpretable framework for personalizing deep neural networks.

</details>


### [5] [SkeletonGaussian: Editable 4D Generation through Gaussian Skeletonization](https://arxiv.org/abs/2602.04271)
*Lifan Wu,Ruijie Zhu,Yubo Ai,Tianzhu Zhang*

Main category: cs.CV

TL;DR: SkeletonGaussian 是一种从单目视频生成可编辑动态3D高斯的新框架，通过骨架驱动和层次化表示提升生成质量和编辑能力。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常将运动表示为隐式变形场，限制了直接控制和编辑能力，因此需要一种更直观且可编辑的动态3D生成方法。

Method: 该方法采用单目视频输入，通过提取稳健的骨架并驱动刚性运动（线性混合蒙皮），再通过基于六面体的细化处理非刚性变形。

Result: 实验结果表明，SkeletonGaussian 在生成质量上优于现有方法，并支持直观的运动编辑。

Conclusion: SkeletonGaussian 提出了一种新的可编辑4D生成框架，通过层次化关节表示和骨架驱动运动，显著提升了动态3D高斯生成的质量和可编辑性。

Abstract: 4D generation has made remarkable progress in synthesizing dynamic 3D objects from input text, images, or videos. However, existing methods often represent motion as an implicit deformation field, which limits direct control and editability. To address this issue, we propose SkeletonGaussian, a novel framework for generating editable dynamic 3D Gaussians from monocular video input. Our approach introduces a hierarchical articulated representation that decomposes motion into sparse rigid motion explicitly driven by a skeleton and fine-grained non-rigid motion. Concretely, we extract a robust skeleton and drive rigid motion via linear blend skinning, followed by a hexplane-based refinement for non-rigid deformations, enhancing interpretability and editability. Experimental results demonstrate that SkeletonGaussian surpasses existing methods in generation quality while enabling intuitive motion editing, establishing a new paradigm for editable 4D generation. Project page: https://wusar.github.io/projects/skeletongaussian/

</details>


### [6] [Explainable Computer Vision Framework for Automated Pore Detection and Criticality Assessment in Additive Manufacturing](https://arxiv.org/abs/2602.03883)
*Akshansh Mishra,Rakesh Morisetty*

Main category: cs.CV

TL;DR: 该研究开发了一个可解释的计算机视觉框架，用于增材制造中的孔隙检测和关键性评估，发现表面距离是预测孔隙关键性的最重要因素，为工艺优化提供了透明且可操作的见解。


<details>
  <summary>Details</summary>
Motivation: 内部孔隙是增材制造组件中的关键缺陷模式，影响结构性能并限制工业应用。现有的自动缺陷检测方法缺乏可解释性，阻碍工程师理解关键性预测的物理基础。

Method: 研究采用了基于强度的阈值分割和连通分量分析来识别孔隙，使用几何描述符（如大小、纵横比、范围、空间位置）进行表征，并构建了孔隙交互网络。通过机器学习模型预测孔隙关键性评分，并利用SHAP分析量化特征贡献。

Result: 结果表明，归一化表面距离对模型预测的贡献最大，其重要性超过其他描述符一个数量级。孔隙大小影响最小，几何参数影响可忽略。表面接近度与关键性之间的强逆关系揭示了边界驱动的失效机制。

Conclusion: 该研究提出了一个可解释的计算机视觉框架，用于增材制造中的孔隙检测和关键性评估，揭示了边界驱动的失效机制，并为工艺优化和质量控制提供了可操作的见解。

Abstract: Internal porosity remains a critical defect mode in additively manufactured components, compromising structural performance and limiting industrial adoption. Automated defect detection methods exist but lack interpretability, preventing engineers from understanding the physical basis of criticality predictions. This study presents an explainable computer vision framework for pore detection and criticality assessment in three-dimensional tomographic volumes. Sequential grayscale slices were reconstructed into volumetric datasets, and intensity-based thresholding with connected component analysis identified 500 individual pores. Each pore was characterized using geometric descriptors including size, aspect ratio, extent, and spatial position relative to the specimen boundary. A pore interaction network was constructed using percentile-based Euclidean distance criteria, yielding 24,950 inter-pore connections. Machine learning models predicted pore criticality scores from extracted features, and SHAP analysis quantified individual feature contributions. Results demonstrate that normalized surface distance dominates model predictions, contributing more than an order of magnitude greater importance than all other descriptors. Pore size provides minimal influence, while geometric parameters show negligible impact. The strong inverse relationship between surface proximity and criticality reveals boundary-driven failure mechanisms. This interpretable framework enables transparent defect assessment and provides actionable insights for process optimization and quality control in additive manufacturing.

</details>


### [7] [AGILE: Hand-Object Interaction Reconstruction from Video via Agentic Generation](https://arxiv.org/abs/2602.04672)
*Jin-Chuan Shi,Binhong Ye,Tao Liu,Junzhe He,Yangjinhui Xu,Xiaoyang Liu,Zeju Li,Hao Chen,Chunhua Shen*

Main category: cs.CV

TL;DR: AGILE 通过代理生成和稳健的锚定跟踪策略，克服了现有方法在重建动态手-物体交互时的局限性，生成了高精度且物理有效的模拟就绪资产。


<details>
  <summary>Details</summary>
Motivation: 现有方法在单目视频中重建动态手-物体交互时面临两个主要障碍：依赖神经渲染导致几何碎片化，以及依赖脆弱的 SfM 初始化导致失败。

Method: AGILE 采用代理生成范式，利用视觉语言模型（VLM）指导生成模型合成完整的水密物体网格，并提出稳健的锚定跟踪策略，绕过脆弱的 SfM 初始化。最后，通过接触感知优化整合语义、几何和交互稳定性约束。

Result: 在 HO3D、DexYCB 和野外视频上的实验表明，AGILE 在全局几何精度上优于基线方法，并在挑战性序列中表现出卓越的鲁棒性。

Conclusion: AGILE 框架通过从重建转向代理生成，克服了现有方法的局限性，提供了全局几何精度高且物理有效的模拟就绪资产，适用于机器人应用。

Abstract: Reconstructing dynamic hand-object interactions from monocular videos is critical for dexterous manipulation data collection and creating realistic digital twins for robotics and VR. However, current methods face two prohibitive barriers: (1) reliance on neural rendering often yields fragmented, non-simulation-ready geometries under heavy occlusion, and (2) dependence on brittle Structure-from-Motion (SfM) initialization leads to frequent failures on in-the-wild footage. To overcome these limitations, we introduce AGILE, a robust framework that shifts the paradigm from reconstruction to agentic generation for interaction learning. First, we employ an agentic pipeline where a Vision-Language Model (VLM) guides a generative model to synthesize a complete, watertight object mesh with high-fidelity texture, independent of video occlusions. Second, bypassing fragile SfM entirely, we propose a robust anchor-and-track strategy. We initialize the object pose at a single interaction onset frame using a foundation model and propagate it temporally by leveraging the strong visual similarity between our generated asset and video observations. Finally, a contact-aware optimization integrates semantic, geometric, and interaction stability constraints to enforce physical plausibility. Extensive experiments on HO3D, DexYCB, and in-the-wild videos reveal that AGILE outperforms baselines in global geometric accuracy while demonstrating exceptional robustness on challenging sequences where prior art frequently collapses. By prioritizing physical validity, our method produces simulation-ready assets validated via real-to-sim retargeting for robotic applications.

</details>


### [8] [4DPC$^2$hat: Towards Dynamic Point Cloud Understanding with Failure-Aware Bootstrapping](https://arxiv.org/abs/2602.03890)
*Xindan Zhang,Weilong Yan,Yufei Shi,Xuerui Qiu,Tao He,Ying Li,Ming Li,Hehe Fan*

Main category: cs.CV

TL;DR: 4DPC$^2$hat is a new MLLM for dynamic point cloud understanding, featuring a large dataset (4DPC$^2$hat-200K) and innovative methods for temporal reasoning.


<details>
  <summary>Details</summary>
Motivation: The limitation of existing methods focusing on static objects and the lack of large-scale cross-modal datasets for dynamic point cloud sequences motivated the development of 4DPC$^2$hat.

Method: The paper introduces a Mamba-enhanced temporal reasoning MLLM and a failure-aware bootstrapping learning strategy to capture long-range dependencies and dynamic patterns in point cloud sequences.

Result: Extensive experiments show that 4DPC$^2$hat outperforms existing models in action understanding and temporal reasoning.

Conclusion: 4DPC$^2$hat significantly improves action understanding and temporal reasoning compared with existing models, establishing a strong foundation for 4D dynamic point cloud understanding.

Abstract: Point clouds provide a compact and expressive representation of 3D objects, and have recently been integrated into multimodal large language models (MLLMs). However, existing methods primarily focus on static objects, while understanding dynamic point cloud sequences remains largely unexplored. This limitation is mainly caused by the lack of large-scale cross-modal datasets and the difficulty of modeling motions in spatio-temporal contexts. To bridge this gap, we present 4DPC$^2$hat, the first MLLM tailored for dynamic point cloud understanding. To this end, we construct a large-scale cross-modal dataset 4DPC$^2$hat-200K via a meticulous two-stage pipeline consisting of topology-consistent 4D point construction and two-level captioning. The dataset contains over 44K dynamic object sequences, 700K point cloud frames, and 200K curated question-answer (QA) pairs, supporting inquiries about counting, temporal relationship, action, spatial relationship, and appearance. At the core of the framework, we introduce a Mamba-enhanced temporal reasoning MLLM to capture long-range dependencies and dynamic patterns among a point cloud sequence. Furthermore, we propose a failure-aware bootstrapping learning strategy that iteratively identifies model deficiencies and generates targeted QA supervision to continuously strengthen corresponding reasoning capabilities. Extensive experiments demonstrate that our 4DPC$^2$hat significantly improves action understanding and temporal reasoning compared with existing models, establishing a strong foundation for 4D dynamic point cloud understanding.

</details>


### [9] [X2HDR: HDR Image Generation in a Perceptually Uniform Space](https://arxiv.org/abs/2602.04814)
*Ronghuan Wu,Wanchao Su,Kede Ma,Jing Liao,Rafał K. Mantiuk*

Main category: cs.CV

TL;DR: 无需从头训练，通过感知均匀编码和低秩适应微调，预训练扩散模型可高效适应HDR生成，显著提升输出质量。


<details>
  <summary>Details</summary>
Motivation: 尽管HDR格式和显示器日益普及，但现有图像生成器（如Stable Diffusion和FLUX）因缺乏大规模HDR训练数据而局限于LDR输出。本研究旨在展示如何轻松适应预训练扩散模型以实现HDR生成。

Method: 提出一种高效的适应策略，冻结VAE并通过在感知均匀空间中进行低秩适应微调去噪器，支持文本到HDR合成和单图像RAW到HDR重建。

Result: 实验表明，该方法在感知保真度、文本-图像对齐和有效动态范围方面均优于现有技术。

Conclusion: 通过将HDR输入转换为感知均匀编码（如PU21或PQ），并仅对去噪器进行低秩适应微调，该方法在保持VAE冻结的情况下，实现了与LDR数据相当的HDR重建质量，显著提升了感知保真度、文本-图像对齐和有效动态范围。

Abstract: High-dynamic-range (HDR) formats and displays are becoming increasingly prevalent, yet state-of-the-art image generators (e.g., Stable Diffusion and FLUX) typically remain limited to low-dynamic-range (LDR) output due to the lack of large-scale HDR training data. In this work, we show that existing pretrained diffusion models can be easily adapted to HDR generation without retraining from scratch. A key challenge is that HDR images are natively represented in linear RGB, whose intensity and color statistics differ substantially from those of sRGB-encoded LDR images. This gap, however, can be effectively bridged by converting HDR inputs into perceptually uniform encodings (e.g., using PU21 or PQ). Empirically, we find that LDR-pretrained variational autoencoders (VAEs) reconstruct PU21-encoded HDR inputs with fidelity comparable to LDR data, whereas linear RGB inputs cause severe degradations. Motivated by this finding, we describe an efficient adaptation strategy that freezes the VAE and finetunes only the denoiser via low-rank adaptation in a perceptually uniform space. This results in a unified computational method that supports both text-to-HDR synthesis and single-image RAW-to-HDR reconstruction. Experiments demonstrate that our perceptually encoded adaptation consistently improves perceptual fidelity, text-image alignment, and effective dynamic range, relative to previous techniques.

</details>


### [10] [Audit After Segmentation: Reference-Free Mask Quality Assessment for Language-Referred Audio-Visual Segmentation](https://arxiv.org/abs/2602.03892)
*Jinxing Zhou,Yanghao Zhou,Yaoting Wang,Zongyan Han,Jiaqi Ma,Henghui Ding,Rao Muhammad Anwer,Hisham Cholakkal*

Main category: cs.CV

TL;DR: 本文提出MQA-RefAVS任务，构建MQ-RAVSBench基准，并开发MQ-Auditor模型，用于无参考标注下评估分割掩码质量，实验显示其优于现有MLLM。


<details>
  <summary>Details</summary>
Motivation: 当前Ref-AVS任务在生成分割掩码后缺乏对掩码质量的丰富且可解释的诊断，因此提出了MQA-RefAVS任务以填补这一空白。

Method: 提出了MQA-RefAVS任务，并构建了MQ-RAVSBench基准测试集，进一步提出了基于MLLM的MQ-Auditor模型，通过多模态推理生成定量和定性的掩码质量评估。

Result: MQ-Auditor在实验中表现优异，能够有效评估掩码质量并识别错误类型，支持下游改进。

Conclusion: MQ-Auditor作为一种多模态大型语言模型（MLLM）审计器，在Ref-AVS任务中显著优于其他开源和商业MLLM，并能整合到现有Ref-AVS系统中，用于检测分割失败并支持下游分割改进。

Abstract: Language-referred audio-visual segmentation (Ref-AVS) aims to segment target objects described by natural language by jointly reasoning over video, audio, and text. Beyond generating segmentation masks, providing rich and interpretable diagnoses of mask quality remains largely underexplored. In this work, we introduce Mask Quality Assessment in the Ref-AVS context (MQA-RefAVS), a new task that evaluates the quality of candidate segmentation masks without relying on ground-truth annotations as references at inference time. Given audio-visual-language inputs and each provided segmentation mask, the task requires estimating its IoU with the unobserved ground truth, identifying the corresponding error type, and recommending an actionable quality-control decision. To support this task, we construct MQ-RAVSBench, a benchmark featuring diverse and representative mask error modes that span both geometric and semantic issues. We further propose MQ-Auditor, a multimodal large language model (MLLM)-based auditor that explicitly reasons over multimodal cues and mask information to produce quantitative and qualitative mask quality assessments. Extensive experiments demonstrate that MQ-Auditor outperforms strong open-source and commercial MLLMs and can be integrated with existing Ref-AVS systems to detect segmentation failures and support downstream segmentation improvement. Data and codes will be released at https://github.com/jasongief/MQA-RefAVS.

</details>


### [11] [GPAIR: Gaussian-Kernel-Based Ultrafast 3D Photoacoustic Iterative Reconstruction](https://arxiv.org/abs/2602.03893)
*Yibing Wang,Shuang Li,Tingting Huang,Yu Zhang,Chulhong Kim,Seongwook Choi,Changhui Li*

Main category: cs.CV

TL;DR: GPAIR通过高斯核和GPU加速，将3D PACT迭代重建速度提升至亚秒级，推动临床应用。


<details>
  <summary>Details</summary>
Motivation: 传统迭代重建算法在3D PACT中计算时间长，限制了实际应用，需加速以实现临床实时重建。

Method: 提出GPAIR方法，利用连续各向同性高斯核变换空间网格，结合GPU加速的Triton算子实现超快速重建。

Result: GPAIR在动物实验中实现了包含840万体素的3D目标的亚秒级重建速度。

Conclusion: GPAIR方法通过高斯核变换和GPU加速，实现了3D PACT的超快速迭代重建，显著提升了临床应用的可行性。

Abstract: Although the iterative reconstruction (IR) algorithm can substantially correct reconstruction artifacts in photoacoustic (PA) computed tomography (PACT), it suffers from long reconstruction times, especially for large-scale three-dimensional (3D) imaging in which IR takes hundreds of seconds to hours. The computing burden severely limits the practical applicability of IR algorithms. In this work, we proposed an ultrafast IR method for 3D PACT, called Gaussian-kernel-based Ultrafast 3D Photoacoustic Iterative Reconstruction (GPAIR), which achieves orders-of-magnitude acceleration in computing. GPAIR transforms traditional spatial grids with continuous isotropic Gaussian kernels. By deriving analytical closed-form expression for pressure waves and implementing powerful GPU-accelerated differentiable Triton operators, GPAIR demonstrates extraordinary ultrafast sub-second reconstruction speed for 3D targets containing 8.4 million voxels in animal experiments. This revolutionary ultrafast image reconstruction enables near-real-time large-scale 3D PA reconstruction, significantly advancing 3D PACT toward clinical applications.

</details>


### [12] [Vision Transformers for Zero-Shot Clustering of Animal Images: A Comparative Benchmarking Study](https://arxiv.org/abs/2602.03894)
*Hugo Markoff,Stefan Hein Bengtson,Michael Ørsted*

Main category: cs.CV

TL;DR: ViT模型结合降维和聚类技术能高效实现动物图像的物种级聚类，并揭示物种内变异，为生态学家提供了实用工具。


<details>
  <summary>Details</summary>
Motivation: 生态研究中动物图像的手动标记是一个重大瓶颈，限制了生物多样性监测的规模和效率。

Method: 研究提出了一个综合的基准测试框架，评估了五种ViT模型、五种降维技术和四种聚类算法（两种监督和两种无监督）在60种动物（30种哺乳动物和30种鸟类）上的表现。

Result: 研究结果显示，使用DINOv3嵌入结合t-SNE和监督层次聚类方法可以实现近乎完美的物种级聚类（V-measure: 0.958）。无监督方法也表现出色（0.943），且无需先验物种知识。

Conclusion: 该研究证明了使用Vision Transformer（ViT）基础模型结合降维和聚类技术可以高效地对动物图像进行物种级聚类，同时还能揭示物种内的生态学有意义模式。

Abstract: Manual labeling of animal images remains a significant bottleneck in ecological research, limiting the scale and efficiency of biodiversity monitoring efforts. This study investigates whether state-of-the-art Vision Transformer (ViT) foundation models can reduce thousands of unlabeled animal images directly to species-level clusters. We present a comprehensive benchmarking framework evaluating five ViT models combined with five dimensionality reduction techniques and four clustering algorithms, two supervised and two unsupervised, across 60 species (30 mammals and 30 birds), with each test using a random subset of 200 validated images per species. We investigate when clustering succeeds at species-level, where it fails, and whether clustering within the species-level reveals ecologically meaningful patterns such as sex, age, or phenotypic variation. Our results demonstrate near-perfect species-level clustering (V-measure: 0.958) using DINOv3 embeddings with t-SNE and supervised hierarchical clustering methods. Unsupervised approaches achieve competitive performance (0.943) while requiring no prior species knowledge, rejecting only 1.14% of images as outliers requiring expert review. We further demonstrate robustness to realistic long-tailed distributions of species and show that intentional over-clustering can reliably extract intra-specific variation including age classes, sexual dimorphism, and pelage differences. We introduce an open-source benchmarking toolkit and provide recommendations for ecologists to select appropriate methods for sorting their specific taxonomic groups and data.

</details>


### [13] [Benchmarking Bias Mitigation Toward Fairness Without Harm from Vision to LVLMs](https://arxiv.org/abs/2602.03895)
*Xuwei Tan,Ziyu Hu,Xueru Zhang*

Main category: cs.CV

TL;DR: NH-Fair是一个标准化公平性评估基准，发现数据增强方法在平衡公平与准确性上优于其他方法，LVLMs的扩展收益不及架构或训练选择。


<details>
  <summary>Details</summary>
Motivation: 现实数据训练的机器学习模型常继承并放大社会偏见，现有偏见缓解方法因数据集、公平指标、模型类型和调参不一致而难以比较。

Method: 引入NH-Fair基准，覆盖视觉模型和大型视觉语言模型（LVLMs），采用标准化数据、指标和训练协议，包括监督和零样本机制。

Result: 1. ERM调优研究揭示了训练选择对效用和差异的影响；2. 数据增强方法在公平性和准确性上表现稳定；3. LVLMs虽准确率高但仍存在子群差异。

Conclusion: NH-Fair提供了一个可复现、调优感知的流程，用于严格且无害的公平性评估，证明了数据增强方法在实现公平性和准确性方面的有效性。

Abstract: Machine learning models trained on real-world data often inherit and amplify biases against certain social groups, raising urgent concerns about their deployment at scale. While numerous bias mitigation methods have been proposed, comparing the effectiveness of bias mitigation methods remains difficult due to heterogeneous datasets, inconsistent fairness metrics, isolated evaluation of vision versus multi-modal models, and insufficient hyperparameter tuning that undermines fair comparisons. We introduce NH-Fair, a unified benchmark for fairness without harm that spans both vision models and large vision-language models (LVLMs) under standardized data, metrics, and training protocols, covering supervised and zero-shot regimes. Our key contributions are: (1) a systematic ERM tuning study that identifies training choices with large influence on both utility and disparities, yielding empirically grounded guidelines to help practitioners reduce expensive hyperparameter tuning space in achieving strong fairness and accuracy; (2) evidence that many debiasing methods do not reliably outperform a well-tuned ERM baseline, whereas a composite data-augmentation method consistently delivers parity gains without sacrificing utility, emerging as a promising practical strategy. (3) an analysis showing that while LVLMs achieve higher average accuracy, they still exhibit subgroup disparities, and gains from scaling are typically smaller than those from architectural or training-protocol choices. NH-Fair provides a reproducible, tuning-aware pipeline for rigorous, harm-aware fairness evaluation.

</details>


### [14] [HY3D-Bench: Generation of 3D Assets](https://arxiv.org/abs/2602.03907)
*Team Hunyuan3D,:,Bowen Zhang,Chunchao Guo,Dongyuan Guo,Haolin Liu,Hongyu Yan,Huiwen Shi,Jiaao Yu,Jiachen Xu,Jingwei Huang,Kunhong Li,Lifu Wang,Linus,Penghao Wang,Qingxiang Lin,Ruining Tang,Xianghui Yang,Yang Li,Yirui Guan,Yunfei Zhao,Yunhan Yang,Zeqiang Lai,Zhihao Liang,Zibo Zhao*

Main category: cs.CV

TL;DR: HY3D-Bench是一个开源生态系统，提供高质量3D数据和合成资产，旨在解决3D生成的数据瓶颈问题。


<details>
  <summary>Details</summary>
Motivation: 解决3D内容创作领域因数据处理瓶颈而受限的问题，建立一个统一、高质量的基础设施以促进3D生成技术的发展。

Method: 1. 从大规模仓库中筛选出25万个高保真3D对象，并提供训练就绪的工件（如水密网格和多视图渲染）；2. 引入结构化部件级分解，支持细粒度感知和可控编辑；3. 通过可扩展的AIGC合成管道填补现实世界分布差距，贡献12.5万个合成资产以增强长尾类别的多样性。

Result: 通过Hunyuan3D-2.1-Small的训练验证，HY3D-Bench成功提供了一个强大的数据资源库。

Conclusion: HY3D-Bench通过提供高质量、多样化的3D数据资源，旨在推动3D感知、机器人和数字内容创作领域的创新。

Abstract: While recent advances in neural representations and generative models have revolutionized 3D content creation, the field remains constrained by significant data processing bottlenecks. To address this, we introduce HY3D-Bench, an open-source ecosystem designed to establish a unified, high-quality foundation for 3D generation. Our contributions are threefold: (1) We curate a library of 250k high-fidelity 3D objects distilled from large-scale repositories, employing a rigorous pipeline to deliver training-ready artifacts, including watertight meshes and multi-view renderings; (2) We introduce structured part-level decomposition, providing the granularity essential for fine-grained perception and controllable editing; and (3) We bridge real-world distribution gaps via a scalable AIGC synthesis pipeline, contributing 125k synthetic assets to enhance diversity in long-tail categories. Validated empirically through the training of Hunyuan3D-2.1-Small, HY3D-Bench democratizes access to robust data resources, aiming to catalyze innovation across 3D perception, robotics, and digital content creation.

</details>


### [15] [Entropy-Aware Structural Alignment for Zero-Shot Handwritten Chinese Character Recognition](https://arxiv.org/abs/2602.03913)
*Qiuming Luo,Tao Zeng,Feng Li,Heming Liu,Rui Mao,Chang Kong*

Main category: cs.CV

TL;DR: 提出一种熵感知结构对齐网络，通过信息熵先验和双视角部首树解决零样本手写汉字识别中的视觉-语义鸿沟问题，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法将汉字视为扁平的部首序列，忽视了层次拓扑结构和不同部首间信息密度的不均匀性，导致视觉-语义鸿沟。

Method: 提出了一种熵感知结构对齐网络，通过信息熵先验动态调节位置嵌入，构建双视角部首树提取多粒度结构特征，并采用Top-K语义特征融合机制增强解码过程。

Result: 实验证明，该方法在零样本设置下显著优于现有基线，且具有快速适应性和高数据效率。

Conclusion: 该方法在零样本手写汉字识别任务中实现了最先进的性能，显著优于现有的基于CLIP的基线方法，并展现出卓越的数据效率。

Abstract: Zero-shot Handwritten Chinese Character Recognition (HCCR) aims to recognize unseen characters by leveraging radical-based semantic compositions. However, existing approaches often treat characters as flat radical sequences, neglecting the hierarchical topology and the uneven information density of different components. To address these limitations, we propose an Entropy-Aware Structural Alignment Network that bridges the visual-semantic gap through information-theoretic modeling. First, we introduce an Information Entropy Prior to dynamically modulate positional embeddings via multiplicative interaction, acting as a saliency detector that prioritizes discriminative roots over ubiquitous components. Second, we construct a Dual-View Radical Tree to extract multi-granularity structural features, which are integrated via an adaptive Sigmoid-based gating network to encode both global layout and local spatial roles. Finally, a Top-K Semantic Feature Fusion mechanism is devised to augment the decoding process by utilizing the centroid of semantic neighbors, effectively rectifying visual ambiguities through feature-level consensus. Extensive experiments demonstrate that our method establishes new state-of-the-art performance, significantly outperforming existing CLIP-based baselines in the challenging zero-shot setting. Furthermore, the framework exhibits exceptional data efficiency, demonstrating rapid adaptability with minimal support samples.

</details>


### [16] [Phaedra: Learning High-Fidelity Discrete Tokenization for the Physical Science](https://arxiv.org/abs/2602.03915)
*Levi Lingsch,Georgios Kissas,Johannes Jakubik,Siddhartha Mishra*

Main category: cs.CV

TL;DR: Phaedra是一种新型图像标记器，针对科学图像的物理和光谱特性优化，显著提升了PDE数据的重建精度和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有标记器专为视觉感知设计，可能不适用于科学图像的高动态范围和物理/光谱特性保留需求。

Method: 本研究评估了一系列图像标记器的准确性，并提出了Phaedra方法，该方法结合了形状增益量化和适当正交分解。

Result: Phaedra在多个PDE数据集上显著提高了重建精度，并在不同复杂度的任务中展现出优秀的泛化能力。

Conclusion: Phaedra，一种受经典形状增益量化和适当正交分解启发的图像标记器，在多个PDE数据集上表现出色，并展示了强大的泛化能力。

Abstract: Tokens are discrete representations that allow modern deep learning to scale by transforming high-dimensional data into sequences that can be efficiently learned, generated, and generalized to new tasks. These have become foundational for image and video generation and, more recently, physical simulation. As existing tokenizers are designed for the explicit requirements of realistic visual perception of images, it is necessary to ask whether these approaches are optimal for scientific images, which exhibit a large dynamic range and require token embeddings to retain physical and spectral properties. In this work, we investigate the accuracy of a suite of image tokenizers across a range of metrics designed to measure the fidelity of PDE properties in both physical and spectral space. Based on the observation that these struggle to capture both fine details and precise magnitudes, we propose Phaedra, inspired by classical shape-gain quantization and proper orthogonal decomposition. We demonstrate that Phaedra consistently improves reconstruction across a range of PDE datasets. Additionally, our results show strong out-of-distribution generalization capabilities to three tasks of increasing complexity, namely known PDEs with different conditions, unknown PDEs, and real-world Earth observation and weather data.

</details>


### [17] [SpatiaLab: Can Vision-Language Models Perform Spatial Reasoning in the Wild?](https://arxiv.org/abs/2602.03916)
*Azmine Toushik Wasi,Wahid Faisal,Abdur Rahman,Mahfuz Ahmed Anik,Munem Shahriar,Mohsin Mahmud Topu,Sadia Tasnim Meem,Rahatun Nesa Priti,Sabrina Afroz Mitu,Md. Iqramul Hoque,Shahriyar Zaman Ridoy,Mohammed Eunus Ali,Majd Hawasly,Mohammad Raza,Md Rizwan Parvez*

Main category: cs.CV

TL;DR: SpatiaLab 是一个评估 VLMs 空间推理能力的基准测试，结果显示模型表现远逊于人类，突显了深度感知、导航和 3D 几何等关键挑战。


<details>
  <summary>Details</summary>
Motivation: 现有研究依赖合成或 LLM 生成的环境，无法捕捉真实世界的复杂性、视觉噪声和多样化的空间关系，因此需要更全面的评估工具。

Method: 通过构建 SpatiaLab 基准测试，包含 1,400 个视觉问答对，涵盖六大类别和 30 种任务类型，支持多项选择和开放式评估。

Result: 实验显示，VLMs 在多项选择和开放式设置中的准确率分别为 54.93% 和 40.93%，远低于人类的 87.57% 和 64.93%。

Conclusion: SpatiaLab 揭示了当前视觉语言模型（VLMs）在空间推理能力上与人类存在显著差距，并提供了一个多样化的现实世界评估框架，为未来研究指明了方向。

Abstract: Spatial reasoning is a fundamental aspect of human cognition, yet it remains a major challenge for contemporary vision-language models (VLMs). Prior work largely relied on synthetic or LLM-generated environments with limited task designs and puzzle-like setups, failing to capture the real-world complexity, visual noise, and diverse spatial relationships that VLMs encounter. To address this, we introduce SpatiaLab, a comprehensive benchmark for evaluating VLMs' spatial reasoning in realistic, unconstrained contexts. SpatiaLab comprises 1,400 visual question-answer pairs across six major categories: Relative Positioning, Depth & Occlusion, Orientation, Size & Scale, Spatial Navigation, and 3D Geometry, each with five subcategories, yielding 30 distinct task types. Each subcategory contains at least 25 questions, and each main category includes at least 200 questions, supporting both multiple-choice and open-ended evaluation. Experiments across diverse state-of-the-art VLMs, including open- and closed-source models, reasoning-focused, and specialized spatial reasoning models, reveal a substantial gap in spatial reasoning capabilities compared with humans. In the multiple-choice setup, InternVL3.5-72B achieves 54.93% accuracy versus 87.57% for humans. In the open-ended setting, all models show a performance drop of around 10-25%, with GPT-5-mini scoring highest at 40.93% versus 64.93% for humans. These results highlight key limitations in handling complex spatial relationships, depth perception, navigation, and 3D geometry. By providing a diverse, real-world evaluation framework, SpatiaLab exposes critical challenges and opportunities for advancing VLMs' spatial reasoning, offering a benchmark to guide future research toward robust, human-aligned spatial understanding. SpatiaLab is available at: https://spatialab-reasoning.github.io/.

</details>


### [18] [Entropy Reveals Block Importance in Masked Self-Supervised Vision Transformers](https://arxiv.org/abs/2602.03918)
*Peihao Xiang,Kaida Wu,Ou Bai*

Main category: cs.CV

TL;DR: Gardener是一种无数据、块级剪枝方法，通过信息熵分析识别冗余块，显著减少模型规模而不损失性能。


<details>
  <summary>Details</summary>
Motivation: 掩码自监督视觉Transformer的模型规模较大，对资源受限的部署和高效迁移学习提出了挑战。本文探讨了是否所有Transformer块对下游性能同等重要。

Method: 提出了一种名为Gardener的无数据、一次性、块级剪枝原则，通过简单的信息论测量识别冗余块。

Result: 在多个剪枝比例和下游视频识别基准上评估Gardener，结果显示其性能与现有无数据剪枝基线相当或更优，且接近基于敏感性的剪枝方法。即使剪枝高达91.7%的块，剪枝后的模型仍保持竞争力的迁移性能。

Conclusion: 本文揭示了掩码自监督视觉Transformer中存在大量块级冗余，并证明信息熵分析为模型压缩和资源高效的迁移学习提供了一种原则性和高效的途径。

Abstract: Masked self-supervised vision transformers have become a dominant pretraining paradigm, yet their substantial model size poses significant challenges for resource-constrained deployment and efficient transfer learning. A fundamental question remains: are all transformer blocks equally important for downstream performance? In this paper, we show that block importance in masked self-supervised vision transformers can be accurately estimated without access to any data. Our key finding is that the information entropy of pretrained block weights strongly correlates with oracle sensitivity obtained via iterative block removal and finetuning. This observation enables Gardener, a data-free, one-shot, block-level pruning principle that identifies redundant blocks through simple information-theoretic measurements. We evaluate Gardener on VideoMAE-B across multiple pruning ratios and downstream video recognition benchmarks. Despite its negligible computational overhead, Gardener consistently matches or outperforms existing data-free pruning baselines and closely approaches sensitivity-based pruning. Remarkably, even after pruning up to 91.7\% of blocks, the pruned model retains competitive transfer performance. Our results reveal substantial block-level redundancy in masked self-supervised vision transformers and demonstrate that information-theoretic analysis offers a principled and efficient pathway for model compression and resource-efficient transfer learning.

</details>


### [19] [TiCLS : Tightly Coupled Language Text Spotter](https://arxiv.org/abs/2602.04030)
*Leeje Jang,Yijun Lin,Yao-Yi Chiang,Jerod Weinman*

Main category: cs.CV

TL;DR: TiCLS通过整合字符级预训练语言模型的外部语言知识，提升了场景文本检测和识别的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖视觉线索，忽略了外部语言知识的优势，而TiCLS旨在通过显式整合外部语言知识来提升模糊或碎片化文本的识别能力。

Method: TiCLS是一个端到端的文本识别器，通过引入语言解码器融合视觉和语言特征，并利用字符级预训练语言模型初始化。

Result: 在ICDAR 2015和Total-Text数据集上的实验表明，TiCLS达到了最先进的性能。

Conclusion: TiCLS通过结合外部语言知识，在场景文本检测和识别任务中实现了最先进的性能，验证了PLM引导的语言整合的有效性。

Abstract: Scene text spotting aims to detect and recognize text in real-world images, where instances are often short, fragmented, or visually ambiguous. Existing methods primarily rely on visual cues and implicitly capture local character dependencies, but they overlook the benefits of external linguistic knowledge. Prior attempts to integrate language models either adapt language modeling objectives without external knowledge or apply pretrained models that are misaligned with the word-level granularity of scene text. We propose TiCLS, an end-to-end text spotter that explicitly incorporates external linguistic knowledge from a character-level pretrained language model. TiCLS introduces a linguistic decoder that fuses visual and linguistic features, yet can be initialized by a pretrained language model, enabling robust recognition of ambiguous or fragmented text. Experiments on ICDAR 2015 and Total-Text demonstrate that TiCLS achieves state-of-the-art performance, validating the effectiveness of PLM-guided linguistic integration for scene text spotting.

</details>


### [20] [AnyStyle: Single-Pass Multimodal Stylization for 3D Gaussian Splatting](https://arxiv.org/abs/2602.04043)
*Joanna Kaleta,Bartosz Świrta,Kacper Kania,Przemysław Spurek,Marek Kowalski*

Main category: cs.CV

TL;DR: AnyStyle是一种前馈3D重建和风格化框架，支持文本和视觉输入，提高了风格可控性和重建质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法主要依赖基于图像的条件，限制了可控性和灵活性，因此需要一种支持文本和视觉风格输入的方法。

Method: 提出了一种模块化的风格化架构，仅需最小化架构修改即可集成到现有的前馈3D重建主干中。

Result: 实验证明AnyStyle在风格可控性上优于现有方法，用户研究也确认其风格化质量优于现有最先进方法。

Conclusion: AnyStyle框架通过多模态条件实现了姿态无关的零样本风格化，提高了风格可控性，同时保持了高质量的几何重建。

Abstract: The growing demand for rapid and scalable 3D asset creation has driven interest in feed-forward 3D reconstruction methods, with 3D Gaussian Splatting (3DGS) emerging as an effective scene representation. While recent approaches have demonstrated pose-free reconstruction from unposed image collections, integrating stylization or appearance control into such pipelines remains underexplored. Existing attempts largely rely on image-based conditioning, which limits both controllability and flexibility. In this work, we introduce AnyStyle, a feed-forward 3D reconstruction and stylization framework that enables pose-free, zero-shot stylization through multimodal conditioning. Our method supports both textual and visual style inputs, allowing users to control the scene appearance using natural language descriptions or reference images. We propose a modular stylization architecture that requires only minimal architectural modifications and can be integrated into existing feed-forward 3D reconstruction backbones. Experiments demonstrate that AnyStyle improves style controllability over prior feed-forward stylization methods while preserving high-quality geometric reconstruction. A user study further confirms that AnyStyle achieves superior stylization quality compared to an existing state-of-the-art approach. Repository: https://github.com/joaxkal/AnyStyle.

</details>


### [21] [A Parameterizable Convolution Accelerator for Embedded Deep Learning Applications](https://arxiv.org/abs/2602.04044)
*Panagiotis Mousouliotis,Georgios Keramidas*

Main category: cs.CV

TL;DR: 论文提出了一种基于HLS的CNN加速器设计方法，通过参数化优化多约束，实验证明其优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现实嵌入式深度学习应用对延迟、功耗、面积和成本有多重约束，而传统CNN加速器设计主要关注性能（GOPS）。

Method: 使用高层次综合（HLS）工具描述CNN加速器，便于设计参数化，从而更有效地优化多个设计约束。

Result: 实验结果表明，所提出的设计方法优于非参数化设计方法。

Conclusion: 该论文提出的硬件-软件（HW/SW）协同设计方法能够超越非参数化设计方法，并易于扩展到其他类型的深度学习应用。

Abstract: Convolutional neural network (CNN) accelerators implemented on Field-Programmable Gate Arrays (FPGAs) are typically designed with a primary focus on maximizing performance, often measured in giga-operations per second (GOPS). However, real-life embedded deep learning (DL) applications impose multiple constraints related to latency, power consumption, area, and cost. This work presents a hardware-software (HW/SW) co-design methodology in which a CNN accelerator is described using high-level synthesis (HLS) tools that ease the parameterization of the design, facilitating more effective optimizations across multiple design constraints. Our experimental results demonstrate that the proposed design methodology is able to outperform non-parameterized design approaches, and it can be easily extended to other types of DL applications.

</details>


### [22] [Fast, Unsupervised Framework for Registration Quality Assessment of Multi-stain Histological Whole Slide Pairs](https://arxiv.org/abs/2602.04046)
*Shikha Dubey,Patricia Raciti,Kristopher Standish,Albert Juan Ramon,Erik Ames Burlingame*

Main category: cs.CV

TL;DR: 该研究提出了一种无监督框架，通过组织掩码和变形指标快速评估WSI注册质量，验证显示其与人工评估高度一致，适用于大规模数字病理质量控制。


<details>
  <summary>Details</summary>
Motivation: 高保真度的组织病理学全切片图像（WSI）注册对整合分子分析至关重要，但缺乏真实标注时难以评估。现有的WSI级评估方法耗时、不可靠且计算量大，限制了大规模应用。

Method: 研究提出了一种快速、无监督的框架，结合下采样组织掩码和基于变形的指标，用于评估H&E和IHC WSI对的注册质量。掩码指标衡量全局结构对应性，而变形指标评估局部平滑性、连续性和变换真实性。

Result: 验证结果表明，自动化指标与人类评估之间存在强相关性。

Conclusion: 该框架在缺乏真实标注的情况下，提供了高保真度、实时且计算资源需求低的注册质量评估方法，适用于数字病理学的大规模质量控制。

Abstract: High-fidelity registration of histopathological whole slide images (WSIs), such as hematoxylin & eosin (H&E) and immunohistochemistry (IHC), is vital for integrated molecular analysis but challenging to evaluate without ground-truth (GT) annotations. Existing WSI-level assessments -- using annotated landmarks or intensity-based similarity metrics -- are often time-consuming, unreliable, and computationally intensive, limiting large-scale applicability. This study proposes a fast, unsupervised framework that jointly employs down-sampled tissue masks- and deformations-based metrics for registration quality assessment (RQA) of registered H&E and IHC WSI pairs. The masks-based metrics measure global structural correspondence, while the deformations-based metrics evaluate local smoothness, continuity, and transformation realism. Validation across multiple IHC markers and multi-expert assessments demonstrate a strong correlation between automated metrics and human evaluations. In the absence of GT, this framework offers reliable, real-time RQA with high fidelity and minimal computational resources, making it suitable for large-scale quality control in digital pathology.

</details>


### [23] [Artifact Removal and Image Restoration in AFM:A Structured Mask-Guided Directional Inpainting Approach](https://arxiv.org/abs/2602.04051)
*Juntao Zhang,Angona Biswas,Jaydeep Rade,Charchit Shukla,Juan Ren,Anwesha Sarkar,Adarsh Krishnamurthy,Aditya Balu*

Main category: cs.CV

TL;DR: 提出全自动AFM图像伪影修复框架，结合分类、分割、方向性修复与平滑操作，通过GUI实现高效处理，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: AFM高分辨率成像常因环境噪声、扫描缺陷和针尖-样品相互作用引入伪影，导致图像质量下降，需要自动化解决方案。

Method: 框架包括伪影分类模型、轻量级语义分割网络生成精确伪影掩码、基于结构方向的自适应掩码扩展、方向性邻域插值策略修复以及局部高斯平滑操作。系统集成到支持实时参数调整和批量处理的用户友好GUI中。

Result: 实验结果表明，该方法能有效去除伪影并保留纳米级结构细节。

Conclusion: 该论文提出了一种轻量级、全自动化的AFM图像伪影检测与修复框架，通过实验验证了其在保留纳米级结构细节的同时有效去除伪影的能力，为高保真AFM数据解释提供了几何感知的解决方案。

Abstract: Atomic Force Microscopy (AFM) enables high-resolution surface imaging at the nanoscale, yet the output is often degraded by artifacts introduced by environmental noise, scanning imperfections, and tip-sample interactions. To address this challenge, a lightweight and fully automated framework for artifact detection and restoration in AFM image analysis is presented. The pipeline begins with a classification model that determines whether an AFM image contains artifacts. If necessary, a lightweight semantic segmentation network, custom-designed and trained on AFM data, is applied to generate precise artifact masks. These masks are adaptively expanded based on their structural orientation and then inpainted using a directional neighbor-based interpolation strategy to preserve 3D surface continuity. A localized Gaussian smoothing operation is then applied for seamless restoration. The system is integrated into a user-friendly GUI that supports real-time parameter adjustments and batch processing. Experimental results demonstrate the effective artifact removal while preserving nanoscale structural details, providing a robust, geometry-aware solution for high-fidelity AFM data interpretation.

</details>


### [24] [Seeing Through Clutter: Structured 3D Scene Reconstruction via Iterative Object Removal](https://arxiv.org/abs/2602.04053)
*Rio Aguina-Kang,Kevin James Blackburn-Matzen,Thibault Groueix,Vladimir Kim,Matheus Gadelha*

Main category: cs.CV

TL;DR: SeeingThroughClutter通过迭代移除对象并逐步重建，实现了复杂场景中的高效3D重建。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在复杂场景（尤其是遮挡和杂乱环境下）依赖中间任务（如语义分割和深度估计）表现不佳的问题。

Method: 该方法利用VLMs作为协调器，通过检测、分割、对象移除和3D拟合的迭代流程，逐步分解复杂场景。

Result: 在3D-Front和ADE20K数据集上展示了最先进的鲁棒性。

Conclusion: SeeingThroughClutter 通过迭代对象移除和重建管道，成功地在复杂场景中实现了结构化3D重建，尤其在遮挡和杂乱环境下表现优异。

Abstract: We present SeeingThroughClutter, a method for reconstructing structured 3D representations from single images by segmenting and modeling objects individually. Prior approaches rely on intermediate tasks such as semantic segmentation and depth estimation, which often underperform in complex scenes, particularly in the presence of occlusion and clutter. We address this by introducing an iterative object removal and reconstruction pipeline that decomposes complex scenes into a sequence of simpler subtasks. Using VLMs as orchestrators, foreground objects are removed one at a time via detection, segmentation, object removal, and 3D fitting. We show that removing objects allows for cleaner segmentations of subsequent objects, even in highly occluded scenes. Our method requires no task-specific training and benefits directly from ongoing advances in foundation models. We demonstrate stateof-the-art robustness on 3D-Front and ADE20K datasets. Project Page: https://rioak.github.io/seeingthroughclutter/

</details>


### [25] [iSight: Towards expert-AI co-assessment for improved immunohistochemistry staining interpretation](https://arxiv.org/abs/2602.04063)
*Jacob S. Leiby,Jialu Yao,Pan Lu,George Hu,Anna Davidian,Shunsuke Koga,Olivia Leung,Pravin Patel,Isabella Tondi Resta,Rebecca Rojansky,Derek Sung,Eric Yang,Paul J. Zhang,Emma Lundberg,Dokyoon Kim,Serena Yeung-Levy,James Zou,Thomas Montine,Jeffrey Nirschl,Zhi Huang*

Main category: cs.CV

TL;DR: 本文介绍了HPA10M数据集和iSight多任务学习框架，用于自动IHC染色评估，展示了其在提高诊断准确性和临床工作流程中的潜力。


<details>
  <summary>Details</summary>
Motivation: 免疫组织化学（IHC）提供了组织切片中蛋白质表达的信息，常用于支持病理诊断和疾病分类。尽管AI模型在H&E染色切片上显示出潜力，但由于领域特异性变化，其在IHC上的适用性有限。

Method: 基于HPA10M数据集，我们训练了iSight，一个多任务学习框架，用于自动IHC染色评估。iSight通过令牌级注意力机制结合全幻灯片图像的视觉特征和组织元数据，同时预测染色强度、位置、数量、组织类型和恶性状态。

Result: 在保留数据上，iSight在位置预测上达到85.5%的准确率，强度预测上达到76.6%，数量预测上达到75.7%，优于微调的基础模型（PLIP、CONCH）2.5-10.2%。此外，iSight展示了良好的校准预测，预期校准误差为0.0150-0.0408。在用户研究中，iSight在保留的HPA数据集上优于初始病理学家评估（位置79% vs 68%，强度70% vs 57%，数量68% vs 52%）。

Conclusion: 本研究为AI系统在提高IHC诊断准确性方面奠定了基础，并展示了将iSight整合到临床工作流程中以增强IHC评估一致性和可靠性的潜力。

Abstract: Immunohistochemistry (IHC) provides information on protein expression in tissue sections and is commonly used to support pathology diagnosis and disease triage. While AI models for H\&E-stained slides show promise, their applicability to IHC is limited due to domain-specific variations. Here we introduce HPA10M, a dataset that contains 10,495,672 IHC images from the Human Protein Atlas with comprehensive metadata included, and encompasses 45 normal tissue types and 20 major cancer types. Based on HPA10M, we trained iSight, a multi-task learning framework for automated IHC staining assessment. iSight combines visual features from whole-slide images with tissue metadata through a token-level attention mechanism, simultaneously predicting staining intensity, location, quantity, tissue type, and malignancy status. On held-out data, iSight achieved 85.5\% accuracy for location, 76.6\% for intensity, and 75.7\% for quantity, outperforming fine-tuned foundation models (PLIP, CONCH) by 2.5--10.2\%. In addition, iSight demonstrates well-calibrated predictions with expected calibration errors of 0.0150-0.0408. Furthermore, in a user study with eight pathologists evaluating 200 images from two datasets, iSight outperformed initial pathologist assessments on the held-out HPA dataset (79\% vs 68\% for location, 70\% vs 57\% for intensity, 68\% vs 52\% for quantity). Inter-pathologist agreement also improved after AI assistance in both held-out HPA (Cohen's $κ$ increased from 0.63 to 0.70) and Stanford TMAD datasets (from 0.74 to 0.76), suggesting expert--AI co-assessment can improve IHC interpretation. This work establishes a foundation for AI systems that can improve IHC diagnostic accuracy and highlights the potential for integrating iSight into clinical workflows to enhance the consistency and reliability of IHC assessment.

</details>


### [26] [VideoBrain: Learning Adaptive Frame Sampling for Long Video Understanding](https://arxiv.org/abs/2602.04094)
*Junbo Zou,Ziheng Huang,Shengjie Zhang,Liwen Zhang,Weining Shen*

Main category: cs.CV

TL;DR: VideoBrain通过双代理自适应采样策略，显著提升长视频理解性能并减少计算开销。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在长视频理解中因固定采样或单次关键帧选择导致的信息丢失或选择不佳问题。

Method: 提出VideoBrain框架，包含基于CLIP的语义检索代理和均匀采样代理，结合行为感知奖励函数和数据分类流程，优化代理调用策略。

Result: 在四个长视频基准测试中，VideoBrain比基线方法性能提升3.5%至9.0%，且帧数减少30-40%，并在短视频基准上表现出良好的泛化能力。

Conclusion: VideoBrain框架通过双代理自适应采样策略，显著提升了长视频理解性能，同时减少了计算资源消耗，并展现出良好的跨数据集泛化能力。

Abstract: Long-form video understanding remains challenging for Vision-Language Models (VLMs) due to the inherent tension between computational constraints and the need to capture information distributed across thousands of frames. Existing approaches either sample frames uniformly (risking information loss) or select keyframes in a single pass (with no recovery from poor choices). We propose VideoBrain, an end-to-end framework that enables VLMs to adaptively acquire visual information through learned sampling policies. Our approach features dual complementary agents: a CLIP-based agent for semantic retrieval across the video and a Uniform agent for dense temporal sampling within intervals. Unlike prior agent-based methods that rely on text-only LLMs orchestrating visual tools, our VLM directly perceives frames and reasons about information sufficiency. To prevent models from invoking agents indiscriminately to maximize rewards, we introduce a behavior-aware reward function coupled with a data classification pipeline that teaches the model when agent invocation is genuinely beneficial. Experiments on four long video benchmarks demonstrate that VideoBrain achieves +3.5% to +9.0% improvement over the baseline while using 30-40% fewer frames, with strong cross-dataset generalization to short video benchmarks.

</details>


### [27] [DMS2F-HAD: A Dual-branch Mamba-based Spatial-Spectral Fusion Network for Hyperspectral Anomaly Detection](https://arxiv.org/abs/2602.04102)
*Aayushma Pant,Lakpa Tamang,Tsz-Kwan Lee,Sunil Aryal*

Main category: cs.CV

TL;DR: DMS2F-HAD是一种高效的双分支Mamba模型，通过动态融合空间和光谱特征，在HSI异常检测中实现高性能和快速推理。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在捕获长距离光谱依赖（如CNN）或计算成本高（如Transformers）方面存在不足，需要一种更高效且性能优越的解决方案。

Method: 提出了一种新颖的双分支Mamba模型DMS2F-HAD，利用Mamba的线性时间建模能力高效学习空间和光谱特征，并通过动态门控融合机制增强异常定位。

Result: DMS2F-HAD在异常检测中实现了最先进的性能，平均AUC达98.78%，推理速度显著提升。

Conclusion: DMS2F-HAD在十四种基准HSI数据集上实现了98.78%的平均AUC，推理速度比同类深度学习方法快4.6倍，展现了强大的泛化能力和可扩展性，是实际HAD应用的理想选择。

Abstract: Hyperspectral anomaly detection (HAD) aims to identify rare and irregular targets in high-dimensional hyperspectral images (HSIs), which are often noisy and unlabelled data. Existing deep learning methods either fail to capture long-range spectral dependencies (e.g., convolutional neural networks) or suffer from high computational cost (e.g., Transformers). To address these challenges, we propose DMS2F-HAD, a novel dual-branch Mamba-based model. Our architecture utilizes Mamba's linear-time modeling to efficiently learn distinct spatial and spectral features in specialized branches, which are then integrated by a dynamic gated fusion mechanism to enhance anomaly localization. Across fourteen benchmark HSI datasets, our proposed DMS2F-HAD not only achieves a state-of-the-art average AUC of 98.78%, but also demonstrates superior efficiency with an inference speed 4.6 times faster than comparable deep learning methods. The results highlight DMS2FHAD's strong generalization and scalability, positioning it as a strong candidate for practical HAD applications.

</details>


### [28] [SuperPoint-E: local features for 3D reconstruction via tracking adaptation in endoscopy](https://arxiv.org/abs/2602.04108)
*O. Leon Barbed,José M. M. Montiel,Pascal Fua,Ana C. Murillo*

Main category: cs.CV

TL;DR: SuperPoint-E通过新型监督策略提升内窥镜视频特征提取质量，实现更优的SfM 3D重建效果。


<details>
  <summary>Details</summary>
Motivation: 提升内窥镜视频中特征提取的质量，以改进Structure-from-Motion（SfM）的性能。

Method: 提出SuperPoint-E局部特征提取方法，采用Tracking Adaptation监督策略优化特征检测与描述。

Result: 实验表明，SuperPoint-E的特征检测更密集、存活率更高，描述符更具区分性，使得3D重建更密集且覆盖更多视频片段，优于原始SuperPoint和COLMAP流程。

Conclusion: SuperPoint-E通过Tracking Adaptation监督策略显著提升了内窥镜视频中特征检测与描述的质量，从而在SfM中实现了更密集、覆盖更广的3D重建效果。

Abstract: In this work, we focus on boosting the feature extraction to improve the performance of Structure-from-Motion (SfM) in endoscopy videos. We present SuperPoint-E, a new local feature extraction method that, using our proposed Tracking Adaptation supervision strategy, significantly improves the quality of feature detection and description in endoscopy. Extensive experimentation on real endoscopy recordings studies our approach's most suitable configuration and evaluates SuperPoint-E feature quality. The comparison with other baselines also shows that our 3D reconstructions are denser and cover more and longer video segments because our detector fires more densely and our features are more likely to survive (i.e. higher detection precision). In addition, our descriptor is more discriminative, making the guided matching step almost redundant. The presented approach brings significant improvements in the 3D reconstructions obtained, via SfM on endoscopy videos, compared to the original SuperPoint and the gold standard SfM COLMAP pipeline.

</details>


### [29] [JSynFlow: Japanese Synthesised Flowchart Visual Question Answering Dataset built with Large Language Models](https://arxiv.org/abs/2602.04142)
*Hiroshi Sasaki*

Main category: cs.CV

TL;DR: JSynFlow是一个合成的日本流程图视觉问答数据集，通过LLMs生成，显著提升VLM在流程图问答中的性能。


<details>
  <summary>Details</summary>
Motivation: 解决开发具备精确流程图理解能力的视觉语言模型所需的大规模数据集创建耗时的问题。

Method: 使用大型语言模型（LLMs）生成合成视觉问答数据集JSynFlow，包含业务任务描述、流程图图像及相关问答对。

Result: 微调JSynFlow显著提高了视觉语言模型在流程图问答任务中的表现。

Conclusion: JSynFlow数据集显著提升了视觉语言模型在流程图问答任务中的性能，并已公开可用。

Abstract: Vision and language models (VLMs) are expected to analyse complex documents, such as those containing flowcharts, through a question-answering (QA) interface. The ability to recognise and interpret these flowcharts is in high demand, as they provide valuable insights unavailable in text-only explanations. However, developing VLMs with precise flowchart understanding requires large-scale datasets of flowchart images and corresponding text, the creation of which is highly time-consuming. To address this challenge, we introduce JSynFlow, a synthesised visual QA dataset for Japanese flowcharts, generated using large language models (LLMs). Our dataset comprises task descriptions for various business occupations, the corresponding flowchart images rendered from domain-specific language (DSL) code, and related QA pairs. This paper details the dataset's synthesis procedure and demonstrates that fine-tuning with JSynFlow significantly improves VLM performance on flowchart-based QA tasks. Our dataset is publicly available at https://huggingface.co/datasets/jri-advtechlab/jsynflow.

</details>


### [30] [Context Determines Optimal Architecture in Materials Segmentation](https://arxiv.org/abs/2602.04154)
*Mingjian Lu,Pawan K. Tripathi,Mark Shteyn,Debargha Ganguly,Roger H. French,Vipin Chaudhary,Yinghui Wu*

Main category: cs.CV

TL;DR: 论文提出跨模态评估框架，揭示不同分割架构在多种成像模态下的性能差异，并提供工具帮助选择合适架构和评估模型可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有的分割架构通常在单一成像模态上进行基准测试，忽略了部署时的性能差异，导致在实际应用中可能表现不佳。

Method: 论文评估了六种编码器-解码器组合在七种数据集上的表现，包括SEM、AFM、XCT和光学显微镜等多种成像模态。

Result: 研究发现，UNet在高对比度2D成像中表现最佳，而DeepLabv3+在最具挑战性的情况下表现更好。框架还提供了分布外检测和反事实解释工具。

Conclusion: 该论文提出了一个跨模态评估框架，用于材料图像分割，揭示了不同架构在不同成像模态下的性能差异，并提供了部署反馈工具，帮助研究人员选择适合其特定成像设置的架构。

Abstract: Segmentation architectures are typically benchmarked on single imaging modalities, obscuring deployment-relevant performance variations: an architecture optimal for one modality may underperform on another. We present a cross-modal evaluation framework for materials image segmentation spanning SEM, AFM, XCT, and optical microscopy. Our evaluation of six encoder-decoder combinations across seven datasets reveals that optimal architectures vary systematically by context: UNet excels for high-contrast 2D imaging while DeepLabv3+ is preferred for the hardest cases. The framework also provides deployment feedback via out-of-distribution detection and counterfactual explanations that reveal which microstructural features drive predictions. Together, the architecture guidance, reliability signals, and interpretability tools address a practical gap in materials characterization, where researchers lack tools to select architectures for their specific imaging setup or assess when models can be trusted on new samples.

</details>


### [31] [Improving 2D Diffusion Models for 3D Medical Imaging with Inter-Slice Consistent Stochasticity](https://arxiv.org/abs/2602.04162)
*Chenhe Du,Qing Wu,Xuanyu Tian,Jingyi Yu,Hongjiang Wei,Yuyao Zhang*

Main category: cs.CV

TL;DR: ISCS通过控制扩散采样中的随机噪声一致性，解决了2D扩散模型在3D医学成像中的切片间不连续问题，无需额外计算成本。


<details>
  <summary>Details</summary>
Motivation: 解决基于2D扩散模型的3D医学成像重建中存在的切片间不连续性问题。

Method: 提出了Inter-Slice Consistent Stochasticity (ISCS)策略，通过控制扩散采样过程中的随机噪声成分一致性来改善3D重建效果。

Result: 实验证明ISCS能有效提升基于2D扩散模型的3D医学成像性能。

Conclusion: 控制切片间随机性（ISCS）是一种高效且实用的方法，能够基于2D扩散模型实现高保真度的3D医学成像。

Abstract: 3D medical imaging is in high demand and essential for clinical diagnosis and scientific research. Currently, diffusion models (DMs) have become an effective tool for medical imaging reconstruction thanks to their ability to learn rich, high-quality data priors. However, learning the 3D data distribution with DMs in medical imaging is challenging, not only due to the difficulties in data collection but also because of the significant computational burden during model training. A common compromise is to train the DMs on 2D data priors and reconstruct stacked 2D slices to address 3D medical inverse problems. However, the intrinsic randomness of diffusion sampling causes severe inter-slice discontinuities of reconstructed 3D volumes. Existing methods often enforce continuity regularizations along the z-axis, which introduces sensitive hyper-parameters and may lead to over-smoothing results. In this work, we revisit the origin of stochasticity in diffusion sampling and introduce Inter-Slice Consistent Stochasticity (ISCS), a simple yet effective strategy that encourages interslice consistency during diffusion sampling. Our key idea is to control the consistency of stochastic noise components during diffusion sampling, thereby aligning their sampling trajectories without adding any new loss terms or optimization steps. Importantly, the proposed ISCS is plug-and-play and can be dropped into any 2D trained diffusion based 3D reconstruction pipeline without additional computational cost. Experiments on several medical imaging problems show that our method can effectively improve the performance of medical 3D imaging problems based on 2D diffusion models. Our findings suggest that controlling inter-slice stochasticity is a principled and practically attractive route toward high-fidelity 3D medical imaging with 2D diffusion priors. The code is available at: https://github.com/duchenhe/ISCS

</details>


### [32] [Point2Insert: Video Object Insertion via Sparse Point Guidance](https://arxiv.org/abs/2602.04167)
*Yu Zhou,Xiaoyan Yang,Bojia Zi,Lihan Zhang,Ruijie Sun,Weishi Zheng,Haibin Huang,Chi Zhang,Xuelong Li*

Main category: cs.CV

TL;DR: Point2Insert是一种基于稀疏点的视频对象插入框架，通过两阶段训练和知识蒸馏实现高精度和低标注成本，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有方法存在两大挑战：基于掩码的方法需要繁重的标注，而基于指令的方法难以精确定位。Point2Insert旨在通过稀疏点提示解决这些问题。

Method: Point2Insert采用两阶段训练：第一阶段训练基于稀疏点提示或二值掩码的对象生成模型；第二阶段通过对象移除模型合成的配对视频进行微调，并利用掩码引导的插入模型作为教师模型进行知识蒸馏。

Result: 实验表明，Point2Insert在性能上 consistently 优于强基线模型，甚至超越参数多10倍的模型。

Conclusion: Point2Insert通过稀疏点提示实现了灵活且用户友好的视频对象插入，显著优于现有方法，甚至在参数更少的模型中表现更优。

Abstract: This paper introduces Point2Insert, a sparse-point-based framework for flexible and user-friendly object insertion in videos, motivated by the growing popularity of accurate, low-effort object placement. Existing approaches face two major challenges: mask-based insertion methods require labor-intensive mask annotations, while instruction-based methods struggle to place objects at precise locations. Point2Insert addresses these issues by requiring only a small number of sparse points instead of dense masks, eliminating the need for tedious mask drawing. Specifically, it supports both positive and negative points to indicate regions that are suitable or unsuitable for insertion, enabling fine-grained spatial control over object locations. The training of Point2Insert consists of two stages. In Stage 1, we train an insertion model that generates objects in given regions conditioned on either sparse-point prompts or a binary mask. In Stage 2, we further train the model on paired videos synthesized by an object removal model, adapting it to video insertion. Moreover, motivated by the higher insertion success rate of mask-guided editing, we leverage a mask-guided insertion model as a teacher to distill reliable insertion behavior into the point-guided model. Extensive experiments demonstrate that Point2Insert consistently outperforms strong baselines and even surpasses models with $\times$10 more parameters.

</details>


### [33] [Partial Ring Scan: Revisiting Scan Order in Vision State Space Models](https://arxiv.org/abs/2602.04170)
*Yi-Kuan Hsieh,Jun-Wei Hsieh,Xin li,Ming-Ching Chang,Yu-Chee Tseng*

Main category: cs.CV

TL;DR: PRISMamba通过创新的环形扫描和通道过滤机制，显著提升Vision SSMs的效率和旋转鲁棒性，在ImageNet-1K上表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统Vision SSMs在处理2D图像时，需要将图像序列化为1D令牌序列，且扫描顺序对性能有显著影响，包括破坏空间邻接性、断裂对象连续性以及在几何变换（如旋转）下性能下降。PRISMamba旨在解决这些问题。

Method: PRISMamba采用部分环形扫描（Partial Ring Scan）策略，将图像分割为同心圆环，在每个环内进行顺序无关的聚合，并通过一组短径向SSMs跨环传播上下文信息。此外，通过部分通道过滤机制，仅将信息量最高的通道通过循环环路径路由，其余通道则保留在轻量级残差分支上。

Result: 在ImageNet-1K上，PRISMamba以3.9G FLOPs和3,054 img/s（A100）的速度实现了84.5%的Top-1准确率，优于VMamba，同时在旋转条件下性能稳定，而固定路径扫描方法的性能下降1~2%。

Conclusion: PRISMamba通过创新的扫描顺序设计和通道过滤机制，显著提升了Vision SSMs在准确性、效率和旋转鲁棒性方面的表现，为相关领域提供了新的研究方向。

Abstract: State Space Models (SSMs) have emerged as efficient alternatives to attention for vision tasks, offering lineartime sequence processing with competitive accuracy. Vision SSMs, however, require serializing 2D images into 1D token sequences along a predefined scan order, a factor often overlooked. We show that scan order critically affects performance by altering spatial adjacency, fracturing object continuity, and amplifying degradation under geometric transformations such as rotation. We present Partial RIng Scan Mamba (PRISMamba), a rotation-robust traversal that partitions an image into concentric rings, performs order-agnostic aggregation within each ring, and propagates context across rings through a set of short radial SSMs. Efficiency is further improved via partial channel filtering, which routes only the most informative channels through the recurrent ring pathway while keeping the rest on a lightweight residual branch. On ImageNet-1K, PRISMamba achieves 84.5% Top-1 with 3.9G FLOPs and 3,054 img/s on A100, outperforming VMamba in both accuracy and throughput while requiring fewer FLOPs. It also maintains performance under rotation, whereas fixed-path scans drop by 1~2%. These results highlight scan-order design, together with channel filtering, as a crucial, underexplored factor for accuracy, efficiency, and rotation robustness in Vision SSMs. Code will be released upon acceptance.

</details>


### [34] [HoloEv-Net: Efficient Event-based Action Recognition via Holographic Spatial Embedding and Global Spectral Gating](https://arxiv.org/abs/2602.04182)
*Weidong Hao*

Main category: cs.CV

TL;DR: HoloEv-Net通过CHSR和GSG模块高效解决事件行为识别的冗余问题，在多个数据集上实现SOTA性能，轻量版适合边缘部署。


<details>
  <summary>Details</summary>
Motivation: 现有事件行为识别方法存在计算冗余（密集体素表示）、结构冗余（多分支架构）和频谱信息利用不足的问题，限制了性能与效率。

Method: 提出了一种名为HoloEv-Net的高效EAR框架，包含Compact Holographic Spatiotemporal Representation (CHSR)和Global Spectral Gating (GSG)模块。CHSR通过将水平空间线索嵌入Time-Height视图，以2D表示保留3D时空上下文；GSG利用FFT在频域进行全局token混合，增强表示能力。

Result: HoloEv-Net在THU-EACT-50-CHL、HARDVS和DailyDVS-200数据集上分别以10.29%、1.71%和6.25%的优势超越现有方法。轻量级变体HoloEv-Net-Small在保持高精度的同时，参数、FLOPs和延迟分别减少5.4倍、300倍和2.4倍。

Conclusion: HoloEv-Net框架通过CHSR和GSG模块有效解决了事件行为识别中的计算冗余、结构冗余和频谱信息利用不足问题，实现了高效且高性能的识别，尤其在边缘部署中展现出巨大潜力。

Abstract: Event-based Action Recognition (EAR) has attracted significant attention due to the high temporal resolution and high dynamic range of event cameras. However, existing methods typically suffer from (i) the computational redundancy of dense voxel representations, (ii) structural redundancy inherent in multi-branch architectures, and (iii) the under-utilization of spectral information in capturing global motion patterns. To address these challenges, we propose an efficient EAR framework named HoloEv-Net. First, to simultaneously tackle representation and structural redundancies, we introduce a Compact Holographic Spatiotemporal Representation (CHSR). Departing from computationally expensive voxel grids, CHSR implicitly embeds horizontal spatial cues into the Time-Height (T-H) view, effectively preserving 3D spatiotemporal contexts within a 2D representation. Second, to exploit the neglected spectral cues, we design a Global Spectral Gating (GSG) module. By leveraging the Fast Fourier Transform (FFT) for global token mixing in the frequency domain, GSG enhances the representation capability with negligible parameter overhead. Extensive experiments demonstrate the scalability and effectiveness of our framework. Specifically, HoloEv-Net-Base achieves state-of-the-art performance on THU-EACT-50-CHL, HARDVS and DailyDVS-200, outperforming existing methods by 10.29%, 1.71% and 6.25%, respectively. Furthermore, our lightweight variant, HoloEv-Net-Small, delivers highly competitive accuracy while offering extreme efficiency, reducing parameters by 5.4 times, FLOPs by 300times, and latency by 2.4times compared to heavy baselines, demonstrating its potential for edge deployment.

</details>


### [35] [Natural Language Instructions for Scene-Responsive Human-in-the-Loop Motion Planning in Autonomous Driving using Vision-Language-Action Models](https://arxiv.org/abs/2602.04184)
*Angel Martinez-Sanchez,Parthib Roy,Ross Greer*

Main category: cs.CV

TL;DR: 研究通过doScenes数据集和OpenEMMA框架，证明自由形式指令能显著提升驾驶轨迹规划的鲁棒性和准确性。


<details>
  <summary>Details</summary>
Motivation: 解决现有指令跟随规划器依赖模拟或固定词汇的局限性，提升真实世界的泛化能力。

Method: 采用OpenEMMA框架，结合doScenes数据集，将自由形式指令作为乘客风格提示输入，进行语言条件化的轨迹生成。

Result: 指令条件化显著减少极端基线失败，平均ADE降低98.7%；优化指令进一步提升轨迹对齐，ADE改善达5.1%。

Conclusion: 研究通过集成doScenes指令到OpenEMMA框架中，显著提升了轨迹规划的鲁棒性和准确性，并探讨了‘好’指令的特征。

Abstract: Instruction-grounded driving, where passenger language guides trajectory planning, requires vehicles to understand intent before motion. However, most prior instruction-following planners rely on simulation or fixed command vocabularies, limiting real-world generalization. doScenes, the first real-world dataset linking free-form instructions (with referentiality) to nuScenes ground-truth motion, enables instruction-conditioned planning. In this work, we adapt OpenEMMA, an open-source MLLM-based end-to-end driving framework that ingests front-camera views and ego-state and outputs 10-step speed-curvature trajectories, to this setting, presenting a reproducible instruction-conditioned baseline on doScenes and investigate the effects of human instruction prompts on predicted driving behavior. We integrate doScenes directives as passenger-style prompts within OpenEMMA's vision-language interface, enabling linguistic conditioning before trajectory generation. Evaluated on 849 annotated scenes using ADE, we observe that instruction conditioning substantially improves robustness by preventing extreme baseline failures, yielding a 98.7% reduction in mean ADE. When such outliers are removed, instructions still influence trajectory alignment, with well-phrased prompts improving ADE by up to 5.1%. We use this analysis to discuss what makes a "good" instruction for the OpenEMMA framework. We release the evaluation prompts and scripts to establish a reproducible baseline for instruction-aware planning. GitHub: https://github.com/Mi3-Lab/doScenes-VLM-Planning

</details>


### [36] [DiMo: Discrete Diffusion Modeling for Motion Generation and Understanding](https://arxiv.org/abs/2602.04188)
*Ning Zhang,Zhengyu Li,Kwong Weng Loh,Mingxi Xu,Qi Wang,Zhengyu Wen,Xiaoyu He,Wei Zhao,Kehong Gong,Mingyuan Zhang*

Main category: cs.CV

TL;DR: DiMo是一个离散扩散框架，统一了文本与运动之间的双向理解和生成，支持多种任务且性能优越。


<details>
  <summary>Details</summary>
Motivation: 扩展掩码建模至双向文本-运动理解和生成，解决现有方法主要局限于文本到运动的单向生成问题。

Method: 采用离散扩散风格的框架，结合迭代掩码令牌细化和残差向量量化（RVQ），以及组相对策略优化（GRPO）增强对齐和可控性。

Result: 在HumanML3D和KIT-ML数据集上表现出强大的运动质量和竞争性的双向理解能力。

Conclusion: DiMo通过离散扩散框架统一了文本与运动之间的双向理解和生成，展示了在多种任务上的强大能力，包括文本自由运动完成、文本引导运动预测和运动字幕校正。

Abstract: Prior masked modeling motion generation methods predominantly study text-to-motion. We present DiMo, a discrete diffusion-style framework, which extends masked modeling to bidirectional text--motion understanding and generation. Unlike GPT-style autoregressive approaches that tokenize motion and decode sequentially, DiMo performs iterative masked token refinement, unifying Text-to-Motion (T2M), Motion-to-Text (M2T), and text-free Motion-to-Motion (M2M) within a single model. This decoding paradigm naturally enables a quality-latency trade-off at inference via the number of refinement steps.We further improve motion token fidelity with residual vector quantization (RVQ) and enhance alignment and controllability with Group Relative Policy Optimization (GRPO). Experiments on HumanML3D and KIT-ML show strong motion quality and competitive bidirectional understanding under a unified framework. In addition, we demonstrate model ability in text-free motion completion, text-guided motion prediction and motion caption correction without architectural change.Additional qualitative results are available on our project page: https://animotionlab.github.io/DiMo/.

</details>


### [37] [Continuous Degradation Modeling via Latent Flow Matching for Real-World Super-Resolution](https://arxiv.org/abs/2602.04193)
*Hyeonjae Kim,Dongjin Kim,Eugene Jin,Tae Hyun Kim*

Main category: cs.CV

TL;DR: 提出一种通过流匹配合成真实低分辨率图像的新框架，解决了真实世界超分辨率训练数据不足的问题，并显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有深度学习方法在合成退化场景（如双三次下采样）表现良好，但在真实世界复杂非线性退化（如噪声、模糊和压缩伪影）上表现不佳，且真实低分辨率和高分辨率图像对的收集困难。

Method: 利用潜在退化空间和流匹配技术，从单一高分辨率图像合成具有真实退化效果的低分辨率图像。

Result: 合成的低分辨率图像能准确模拟真实世界退化，基于此数据集训练的超分辨率模型在传统和任意尺度上均表现更优。

Conclusion: 该论文提出的框架能够通过流匹配在潜在退化空间中合成真实的低分辨率图像，有效解决了真实世界图像超分辨率训练数据不足的问题。

Abstract: While deep learning-based super-resolution (SR) methods have shown impressive outcomes with synthetic degradation scenarios such as bicubic downsampling, they frequently struggle to perform well on real-world images that feature complex, nonlinear degradations like noise, blur, and compression artifacts. Recent efforts to address this issue have involved the painstaking compilation of real low-resolution (LR) and high-resolution (HR) image pairs, usually limited to several specific downscaling factors. To address these challenges, our work introduces a novel framework capable of synthesizing authentic LR images from a single HR image by leveraging the latent degradation space with flow matching. Our approach generates LR images with realistic artifacts at unseen degradation levels, which facilitates the creation of large-scale, real-world SR training datasets. Comprehensive quantitative and qualitative assessments verify that our synthetic LR images accurately replicate real-world degradations. Furthermore, both traditional and arbitrary-scale SR models trained using our datasets consistently yield much better HR outcomes.

</details>


### [38] [VTok: A Unified Video Tokenizer with Decoupled Spatial-Temporal Latents](https://arxiv.org/abs/2602.04202)
*Feng Wang,Yichun Shi,Ceyuan Yang,Qiushan Guo,Jingxiang Sun,Alan Yuille,Peng Wang*

Main category: cs.CV

TL;DR: VTok是一种统一的视频标记化框架，通过解耦空间和时间表示，显著提升视频理解和生成任务的性能与效率。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉语言系统通过简单帧采样策略标记视频的不足，实现更紧凑且表达力强的视频标记化。

Method: 提出了一种解耦视频空间和时间表示的统一视频标记化框架VTok，保留关键帧的空间特征，并将后续帧编码为单个残差标记。

Result: VTok显著降低了视频表示的复杂度，并在多个视频理解和文本到视频生成基准测试中表现优于基线方法（如TV-Align基准测试准确率提高3.4%，VBench得分提高1.9%）。

Conclusion: VTok有望成为未来视频理解和生成研究的标准化视频标记化范式。

Abstract: This work presents VTok, a unified video tokenization framework that can be used for both generation and understanding tasks. Unlike the leading vision-language systems that tokenize videos through a naive frame-sampling strategy, we propose to decouple the spatial and temporal representations of videos by retaining the spatial features of a single key frame while encoding each subsequent frame into a single residual token, achieving compact yet expressive video tokenization. Our experiments suggest that VTok effectively reduces the complexity of video representation from the product of frame count and per-frame token count to their sum, while the residual tokens sufficiently capture viewpoint and motion changes relative to the key frame. Extensive evaluations demonstrate the efficacy and efficiency of VTok: it achieves notably higher performance on a range of video understanding and text-to-video generation benchmarks compared with baselines using naive tokenization, all with shorter token sequences per video (e.g., 3.4% higher accuracy on our TV-Align benchmark and 1.9% higher VBench score). Remarkably, VTok produces more coherent motion and stronger guidance following in text-to-video generation, owing to its more consistent temporal encoding. We hope VTok can serve as a standardized video tokenization paradigm for future research in video understanding and generation.

</details>


### [39] [AGMA: Adaptive Gaussian Mixture Anchors for Prior-Guided Multimodal Human Trajectory Forecasting](https://arxiv.org/abs/2602.04204)
*Chao Li,Rui Zhang,Siyuan Huang,Xian Zhong,Hongbo Jiang*

Main category: cs.CV

TL;DR: AGMA通过自适应高斯混合锚点构建高质量先验，解决了轨迹预测中的先验不对齐问题，显著提升了预测准确性和多样性。


<details>
  <summary>Details</summary>
Motivation: 现有方法因先验不对齐问题，无法捕捉行人行为的全部合理分布，限制了预测的准确性和多样性。理论分析表明预测误差受先验质量下限约束，因此先验建模成为性能瓶颈。

Method: AGMA采用两阶段方法：1) 从训练数据中提取多样化的行为模式；2) 将其提炼为场景自适应的全局先验用于推理。

Result: 在ETH-UCY、Stanford Drone和JRDB数据集上的大量实验表明，AGMA达到了最先进的性能。

Conclusion: AGMA通过构建高质量的先验（Adaptive Gaussian Mixture Anchors），在轨迹预测中实现了最先进的性能，验证了高质量先验的关键作用。

Abstract: Human trajectory forecasting requires capturing the multimodal nature of pedestrian behavior. However, existing approaches suffer from prior misalignment. Their learned or fixed priors often fail to capture the full distribution of plausible futures, limiting both prediction accuracy and diversity. We theoretically establish that prediction error is lower-bounded by prior quality, making prior modeling a key performance bottleneck. Guided by this insight, we propose AGMA (Adaptive Gaussian Mixture Anchors), which constructs expressive priors through two stages: extracting diverse behavioral patterns from training data and distilling them into a scene-adaptive global prior for inference. Extensive experiments on ETH-UCY, Stanford Drone, and JRDB datasets demonstrate that AGMA achieves state-of-the-art performance, confirming the critical role of high-quality priors in trajectory forecasting.

</details>


### [40] [Adaptive 1D Video Diffusion Autoencoder](https://arxiv.org/abs/2602.04220)
*Yao Teng,Minxuan Lin,Xian Liu,Shuai Wang,Xiao Yang,Xihui Liu*

Main category: cs.CV

TL;DR: One-DVA是一种自适应1D编码和扩散解码的视频自动编码器，解决了现有方法的三大局限，支持更高压缩比和生成任务。


<details>
  <summary>Details</summary>
Motivation: 现有视频自动编码器存在固定速率压缩、不灵活的CNN架构和确定性解码器三大局限，无法高效处理视频数据。

Method: 提出了一种基于Transformer的框架，包括查询式视觉Transformer编码器和像素空间扩散Transformer解码器，采用两阶段训练策略。

Result: One-DVA在相同压缩比下重建性能与3D-CNN VAEs相当，且支持更高压缩比，潜在分布正则化后更适合生成任务。

Conclusion: One-DVA通过自适应1D编码和基于扩散的解码，解决了现有视频自动编码器的三大限制，支持自适应压缩，并在下游潜在生成任务中表现出色。

Abstract: Recent video generation models largely rely on video autoencoders that compress pixel-space videos into latent representations. However, existing video autoencoders suffer from three major limitations: (1) fixed-rate compression that wastes tokens on simple videos, (2) inflexible CNN architectures that prevent variable-length latent modeling, and (3) deterministic decoders that struggle to recover appropriate details from compressed latents. To address these issues, we propose One-Dimensional Diffusion Video Autoencoder (One-DVA), a transformer-based framework for adaptive 1D encoding and diffusion-based decoding. The encoder employs query-based vision transformers to extract spatiotemporal features and produce latent representations, while a variable-length dropout mechanism dynamically adjusts the latent length. The decoder is a pixel-space diffusion transformer that reconstructs videos with the latents as input conditions. With a two-stage training strategy, One-DVA achieves performance comparable to 3D-CNN VAEs on reconstruction metrics at identical compression ratios. More importantly, it supports adaptive compression and thus can achieve higher compression ratios. To better support downstream latent generation, we further regularize the One-DVA latent distribution for generative modeling and fine-tune its decoder to mitigate artifacts caused by the generation process.

</details>


### [41] [An Intuitionistic Fuzzy Logic Driven UNet architecture: Application to Brain Image segmentation](https://arxiv.org/abs/2602.04227)
*Hanuman Verma,Kiho Im,Pranabesh Maji,Akshansh Gupta*

Main category: cs.CV

TL;DR: IF-UNet结合直觉模糊逻辑，显著提升了MRI脑图像分割的准确性，尤其在处理不确定性方面表现优异。


<details>
  <summary>Details</summary>
Motivation: MRI脑图像分割对神经疾病诊断和医学图像计算至关重要，但传统CNN方法难以处理部分体积效应带来的不确定性。

Method: 提出了一种增强框架IF-UNet，将直觉模糊逻辑融入UNet，通过处理输入数据的隶属度、非隶属度和犹豫度来应对组织模糊性。

Result: 在IBSR数据集上的实验表明，IF-UNet在准确性、Dice系数和IoU等指标上均优于传统方法。

Conclusion: IF-UNet通过结合直觉模糊逻辑，有效提升了MRI脑图像分割的质量，尤其是在处理部分体积效应和边界不确定性方面表现出色。

Abstract: Accurate segmentation of MRI brain images is essential for image analysis, diagnosis of neuro-logical disorders and medical image computing. In the deep learning approach, the convolutional neural networks (CNNs), especially UNet, are widely applied in medical image segmentation. However, it is difficult to deal with uncertainty due to the partial volume effect in brain images. To overcome this limitation, we propose an enhanced framework, named UNet with intuitionistic fuzzy logic (IF-UNet), which incorporates intuitionistic fuzzy logic into UNet. The model processes input data in terms of membership, nonmembership, and hesitation degrees, allowing it to better address tissue ambiguity resulting from partial volume effects and boundary uncertainties. The proposed architecture is evaluated on the Internet Brain Segmentation Repository (IBSR) dataset, and its performance is computed using accuracy, Dice coefficient, and intersection over union (IoU). Experimental results confirm that IF-UNet improves segmentation quality with handling uncertainty in brain images.

</details>


### [42] [SPOT-Occ: Sparse Prototype-guided Transformer for Camera-based 3D Occupancy Prediction](https://arxiv.org/abs/2602.04240)
*Suzeyu Chen,Leheng Li,Ying-Cong Chen*

Main category: cs.CV

TL;DR: SPOT-Occ通过原型引导的稀疏Transformer解码器，高效解决3D占用预测问题，速度和准确性均有显著提升。


<details>
  <summary>Details</summary>
Motivation: 解决从稀疏、非均匀分布的体素特征中高效聚合信息的挑战，避免计算密集型操作。

Method: 提出了一种基于原型的稀疏Transformer解码器，采用两阶段过程（引导特征选择和聚焦聚合）替代计算密集的密集注意力机制。

Result: SPOT-Occ在速度和准确性上均优于先前方法，代码已开源。

Conclusion: SPOT-Occ模型通过原型引导的稀疏Transformer解码器，显著提升了3D占用预测的速度和准确性，为自动驾驶车辆的安全部署提供了有效解决方案。

Abstract: Achieving highly accurate and real-time 3D occupancy prediction from cameras is a critical requirement for the safe and practical deployment of autonomous vehicles. While this shift to sparse 3D representations solves the encoding bottleneck, it creates a new challenge for the decoder: how to efficiently aggregate information from a sparse, non-uniformly distributed set of voxel features without resorting to computationally prohibitive dense attention.
  In this paper, we propose a novel Prototype-based Sparse Transformer Decoder that replaces this costly interaction with an efficient, two-stage process of guided feature selection and focused aggregation. Our core idea is to make the decoder's attention prototype-guided. We achieve this through a sparse prototype selection mechanism, where each query adaptively identifies a compact set of the most salient voxel features, termed prototypes, for focused feature aggregation.
  To ensure this dynamic selection is stable and effective, we introduce a complementary denoising paradigm. This approach leverages ground-truth masks to provide explicit guidance, guaranteeing a consistent query-prototype association across decoder layers. Our model, dubbed SPOT-Occ, outperforms previous methods with a significant margin in speed while also improving accuracy. Source code is released at https://github.com/chensuzeyu/SpotOcc.

</details>


### [43] [ACIL: Active Class Incremental Learning for Image Classification](https://arxiv.org/abs/2602.04252)
*Aditya R. Bhattacharya,Debanjan Goswami,Shayok Chakraborty*

Main category: cs.CV

TL;DR: ACIL是一种新的主动学习框架，通过选择关键样本进行标注，降低持续学习中的标注成本并避免灾难性遗忘。


<details>
  <summary>Details</summary>
Motivation: 现有的持续学习方法假设所有训练样本都已标注，导致高标注成本和资源浪费。

Method: 提出了一种基于不确定性和多样性的主动学习框架ACIL，用于识别每个阶段需要标注的样本。

Result: 在多个视觉数据集上的实验验证了ACIL框架的有效性和潜力。

Conclusion: ACIL框架通过结合不确定性和多样性标准，显著降低了持续学习场景中的标注成本，并有效避免了灾难性遗忘。

Abstract: Continual learning (or class incremental learning) is a realistic learning scenario for computer vision systems, where deep neural networks are trained on episodic data, and the data from previous episodes are generally inaccessible to the model. Existing research in this domain has primarily focused on avoiding catastrophic forgetting, which occurs due to the continuously changing class distributions in each episode and the inaccessibility of the data from previous episodes. However, these methods assume that all the training samples in every episode are annotated; this not only incurs a huge annotation cost, but also results in a wastage of annotation effort, since most of the samples in a given episode will not be accessible to the model in subsequent episodes. Active learning algorithms identify the salient and informative samples from large amounts of unlabeled data and are instrumental in reducing the human annotation effort in inducing a deep neural network. In this paper, we propose ACIL, a novel active learning framework for class incremental learning settings. We exploit a criterion based on uncertainty and diversity to identify the exemplar samples that need to be annotated in each episode, and will be appended to the data in the next episode. Such a framework can drastically reduce annotation cost and can also avoid catastrophic forgetting. Our extensive empirical analyses on several vision datasets corroborate the promise and potential of our framework against relevant baselines.

</details>


### [44] [Depth-Guided Metric-Aware Temporal Consistency for Monocular Video Human Mesh Recovery](https://arxiv.org/abs/2602.04257)
*Jiaxin Cen,Xudong Mao,Guanghui Yue,Wei Zhou,Ruomei Wang,Fan Zhou,Baoquan Zhao*

Main category: cs.CV

TL;DR: 提出了一种深度引导框架，通过多模块协同解决单目视频人体网格恢复的度量一致性和时间稳定性问题，显著提升了遮挡鲁棒性和空间精度。


<details>
  <summary>Details</summary>
Motivation: 单目视频人体网格恢复存在深度模糊性和尺度不确定性的固有挑战，现有方法主要依赖RGB特征和时间平滑，难以解决深度排序、尺度漂移和遮挡引起的不稳定性问题。

Method: 1. 深度引导多尺度融合模块通过置信感知门控自适应整合几何先验与RGB特征；2. 深度引导度量感知姿态和形状估计器利用深度校准的骨骼统计数据进行尺度一致初始化；3. 运动-深度对齐细化模块通过跨模态注意力机制增强时间一致性。

Result: 该方法在三个具有挑战性的基准测试中表现优异，显著提高了对严重遮挡的鲁棒性和空间准确性，同时保持了计算效率。

Conclusion: 该论文提出的深度引导框架通过三个协同组件显著提高了单目视频人体网格恢复的度量一致性和时间稳定性，并在三个具有挑战性的基准测试中取得了优异结果。

Abstract: Monocular video human mesh recovery faces fundamental challenges in maintaining metric consistency and temporal stability due to inherent depth ambiguities and scale uncertainties. While existing methods rely primarily on RGB features and temporal smoothing, they struggle with depth ordering, scale drift, and occlusion-induced instabilities. We propose a comprehensive depth-guided framework that achieves metric-aware temporal consistency through three synergistic components: A Depth-Guided Multi-Scale Fusion module that adaptively integrates geometric priors with RGB features via confidence-aware gating; A Depth-guided Metric-Aware Pose and Shape (D-MAPS) estimator that leverages depth-calibrated bone statistics for scale-consistent initialization; A Motion-Depth Aligned Refinement (MoDAR) module that enforces temporal coherence through cross-modal attention between motion dynamics and geometric cues. Our method achieves superior results on three challenging benchmarks, demonstrating significant improvements in robustness against heavy occlusion and spatial accuracy while maintaining computational efficiency.

</details>


### [45] [S-MUSt3R: Sliding Multi-view 3D Reconstruction](https://arxiv.org/abs/2602.04517)
*Leonid Antsfeld,Boris Chidlovskii,Yohann Cabon,Vincent Leroy,Jerome Revaud*

Main category: cs.CV

TL;DR: S-MUSt3R extends MUSt3R's 3D reconstruction capabilities to large-scale RGB streams via segmentation and alignment, achieving efficient and accurate results without retraining.


<details>
  <summary>Details</summary>
Motivation: Addressing the scalability bottleneck of foundation models in large-scale RGB stream 3D reconstruction due to memory limitations.

Method: The approach uses sequence segmentation, segment alignment, and lightweight loop closure optimization to extend foundation models for monocular 3D reconstruction without retraining.

Result: S-MUSt3R achieves trajectory and reconstruction performance comparable to traditional methods on TUM, 7-Scenes, and proprietary datasets, handling long RGB sequences effectively.

Conclusion: S-MUSt3R demonstrates the potential of leveraging the MUSt3R model for scalable monocular 3D scene reconstruction in real-world settings, with the advantage of direct metric space predictions.

Abstract: The recent paradigm shift in 3D vision led to the rise of foundation models with remarkable capabilities in 3D perception from uncalibrated images. However, extending these models to large-scale RGB stream 3D reconstruction remains challenging due to memory limitations. This work proposes S-MUSt3R, a simple and efficient pipeline that extends the limits of foundation models for monocular 3D reconstruction. Our approach addresses the scalability bottleneck of foundation models through a simple strategy of sequence segmentation followed by segment alignment and lightweight loop closure optimization. Without model retraining, we benefit from remarkable 3D reconstruction capacities of MUSt3R model and achieve trajectory and reconstruction performance comparable to traditional methods with more complex architecture. We evaluate S-MUSt3R on TUM, 7-Scenes and proprietary robot navigation datasets and show that S-MUSt3R runs successfully on long RGB sequences and produces accurate and consistent 3D reconstruction. Our results highlight the potential of leveraging the MUSt3R model for scalable monocular 3D scene in real-world settings, with an important advantage of making predictions directly in the metric space.

</details>


### [46] [Decoupled Hierarchical Distillation for Multimodal Emotion Recognition](https://arxiv.org/abs/2602.04260)
*Yong Li,Yuanzhi Wang,Yi Ding,Shiqing Zhang,Ke Lu,Cuntai Guan*

Main category: cs.CV

TL;DR: DHMD通过解耦模态特征和分层知识蒸馏，有效提升多模态情感识别性能，实验结果显示显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有多模态情感识别方法在处理模态异质性和不同模态贡献度时存在困难，需要一种更灵活的知识转移和特征对齐方法。

Method: 提出了一种新颖的框架Decoupled Hierarchical Multimodal Distillation (DHMD)，通过自回归机制将每个模态的特征解耦为模态无关（同质）和模态独占（异质）组件，并采用两阶段知识蒸馏策略：粗粒度通过Graph Distillation Unit (GD-Unit)进行，细粒度通过跨模态字典匹配机制实现。

Result: 在CMU-MOSI/CMU-MOSEI数据集上，DHMD相对于现有方法实现了1.3%/2.4%（ACC7）、1.3%/1.9%（ACC2）和1.9%/1.8%（F1）的相对提升。

Conclusion: DHMD框架通过解耦模态特征并采用分层知识蒸馏策略，显著提升了多模态情感识别的性能，并在实验中优于现有方法。

Abstract: Human multimodal emotion recognition (MER) seeks to infer human emotions by integrating information from language, visual, and acoustic modalities. Although existing MER approaches have achieved promising results, they still struggle with inherent multimodal heterogeneities and varying contributions from different modalities. To address these challenges, we propose a novel framework, Decoupled Hierarchical Multimodal Distillation (DHMD). DHMD decouples each modality's features into modality-irrelevant (homogeneous) and modality-exclusive (heterogeneous) components using a self-regression mechanism. The framework employs a two-stage knowledge distillation (KD) strategy: (1) coarse-grained KD via a Graph Distillation Unit (GD-Unit) in each decoupled feature space, where a dynamic graph facilitates adaptive distillation among modalities, and (2) fine-grained KD through a cross-modal dictionary matching mechanism, which aligns semantic granularities across modalities to produce more discriminative MER representations. This hierarchical distillation approach enables flexible knowledge transfer and effectively improves cross-modal feature alignment. Experimental results demonstrate that DHMD consistently outperforms state-of-the-art MER methods, achieving 1.3\%/2.4\% (ACC$_7$), 1.3\%/1.9\% (ACC$_2$) and 1.9\%/1.8\% (F1) relative improvement on CMU-MOSI/CMU-MOSEI dataset, respectively. Meanwhile, visualization results reveal that both the graph edges and dictionary activations in DHMD exhibit meaningful distribution patterns across modality-irrelevant/-exclusive feature spaces.

</details>


### [47] [KVSmooth: Mitigating Hallucination in Multi-modal Large Language Models through Key-Value Smoothing](https://arxiv.org/abs/2602.04268)
*Siyu Jiang,Feiyang Chen,Xiaojin Zhang,Kun He*

Main category: cs.CV

TL;DR: KVSmooth 通过自适应平滑技术减少 MLLMs 的幻觉，提升性能，无需额外训练。


<details>
  <summary>Details</summary>
Motivation: 解决 MLLMs 在解码过程中因语义漂移导致的视觉不一致问题（幻觉），提升模型可靠性。

Method: KVSmooth 对 KV-Cache 中的键和值应用指数移动平均（EMA），并通过注意力分布的熵动态量化每个令牌的“下沉”程度，以自适应调整平滑强度。

Result: 实验表明，KVSmooth 显著减少幻觉（CHAIR_S 从 41.8 降至 18.2），同时提升整体性能（F1 分数从 77.5 提升至 79.2）。

Conclusion: KVSmooth 是一种无需训练、即插即用的方法，通过注意力熵引导的自适应平滑技术有效减少 MLLMs 的幻觉问题，显著提升模型性能。

Abstract: Despite the significant progress of Multimodal Large Language Models (MLLMs) across diverse tasks, hallucination -- corresponding to the generation of visually inconsistent objects, attributes, or relations -- remains a major obstacle to their reliable deployment. Unlike pure language models, MLLMs must ground their generation process in visual inputs. However, existing models often suffer from semantic drift during decoding, causing outputs to diverge from visual facts as the sequence length increases.
  To address this issue, we propose KVSmooth, a training-free and plug-and-play method that mitigates hallucination by performing attention-entropy-guided adaptive smoothing on hidden states. Specifically, KVSmooth applies an exponential moving average (EMA) to both keys and values in the KV-Cache, while dynamically quantifying the sink degree of each token through the entropy of its attention distribution to adaptively adjust the smoothing strength.
  Unlike computationally expensive retraining or contrastive decoding methods, KVSmooth operates efficiently during inference without additional training or model modification. Extensive experiments demonstrate that KVSmooth significantly reduces hallucination ($\mathit{CHAIR}_{S}$ from $41.8 \rightarrow 18.2$) while improving overall performance ($F_1$ score from $77.5 \rightarrow 79.2$), achieving higher precision and recall simultaneously. In contrast, prior methods often improve one at the expense of the other, validating the effectiveness and generality of our approach.

</details>


### [48] [Light Up Your Face: A Physically Consistent Dataset and Diffusion Model for Face Fill-Light Enhancement](https://arxiv.org/abs/2602.04300)
*Jue Gong,Zihan Zhou,Jingkai Wang,Xiaohong Liu,Yulun Zhang,Xiaokang Yang*

Main category: cs.CV

TL;DR: 论文提出LYF-160K数据集和FiLitDiff模型，通过物理一致的渲染和扩散模型实现高效可控的人脸补光增强，解决了前景-背景不一致问题。


<details>
  <summary>Details</summary>
Motivation: 现有的人脸重光照方法通常会抑制输入光照或修改整个场景，导致前景-背景不一致，无法满足实际人脸补光增强的需求。

Method: 通过物理一致的渲染器构建了LYF-160K数据集，并基于预训练的扩散模型训练了FiLitDiff，一种高效的一步模型，利用物理基础的光照编码实现可控的高保真补光。

Result: 实验表明，FiLitDiff在保留背景光照的同时，具有强感知质量和竞争力的全参考指标。

Conclusion: 该论文提出了LightYourFace-160K数据集和FiLitDiff模型，有效解决了人脸补光增强任务中的前景-背景不一致问题，并在实验中展示了优越的感知质量和背景光照保留能力。

Abstract: Face fill-light enhancement (FFE) brightens underexposed faces by adding virtual fill light while keeping the original scene illumination and background unchanged. Most face relighting methods aim to reshape overall lighting, which can suppress the input illumination or modify the entire scene, leading to foreground-background inconsistency and mismatching practical FFE needs. To support scalable learning, we introduce LightYourFace-160K (LYF-160K), a large-scale paired dataset built with a physically consistent renderer that injects a disk-shaped area fill light controlled by six disentangled factors, producing 160K before-and-after pairs. We first pretrain a physics-aware lighting prompt (PALP) that embeds the 6D parameters into conditioning tokens, using an auxiliary planar-light reconstruction objective. Building on a pretrained diffusion backbone, we then train a fill-light diffusion (FiLitDiff), an efficient one-step model conditioned on physically grounded lighting codes, enabling controllable and high-fidelity fill lighting at low computational cost. Experiments on held-out paired sets demonstrate strong perceptual quality and competitive full-reference metrics, while better preserving background illumination. The dataset and model will be at https://github.com/gobunu/Light-Up-Your-Face.

</details>


### [49] [Beyond Static Cropping: Layer-Adaptive Visual Localization and Decoding Enhancement](https://arxiv.org/abs/2602.04304)
*Zipeng Zhu,Zhanghao Hu,Qinglin Zhu,Yuxi Hong,Yijun Liu,Jingyong Su,Yulan He,Lin Gui*

Main category: cs.CV

TL;DR: LASER通过动态选择视觉定位和问题回答层，提升了VQA任务的准确性。


<details>
  <summary>Details</summary>
Motivation: 现有的大视觉语言模型（LVLMs）因固定的视觉标记预算和静态视觉增强方法，在处理复杂推理任务时表现不佳，需要动态视觉定位方法。

Method: 通过层敏感度分析，提出视觉激活查询（VAQ）指标，并基于此开发了LASER方法，动态选择适合任务的视觉定位和问题回答层。

Result: 实验表明，LASER在多样化的VQA基准测试中显著提升了不同复杂度任务的准确性。

Conclusion: LASER（Layer-adaptive Attention-guided Selective visual and decoding Enhancement for Reasoning）作为一种无需训练的推理方法，通过动态选择任务适配的视觉定位和问题回答层，显著提升了不同复杂度任务的VQA准确性。

Abstract: Large Vision-Language Models (LVLMs) have advanced rapidly by aligning visual patches with the text embedding space, but a fixed visual-token budget forces images to be resized to a uniform pretraining resolution, often erasing fine-grained details and causing hallucinations via over-reliance on language priors. Recent attention-guided enhancement (e.g., cropping or region-focused attention allocation) alleviates this, yet it commonly hinges on a static "magic layer" empirically chosen on simple recognition benchmarks and thus may not transfer to complex reasoning tasks. In contrast to this static assumption, we propose a dynamic perspective on visual grounding. Through a layer-wise sensitivity analysis, we demonstrate that visual grounding is a dynamic process: while simple object recognition tasks rely on middle layers, complex visual search and reasoning tasks require visual information to be reactivated at deeper layers. Based on this observation, we introduce Visual Activation by Query (VAQ), a metric that identifies the layer whose attention map is most relevant to query-specific visual grounding by measuring attention sensitivity to the input query. Building on VAQ, we further propose LASER (Layer-adaptive Attention-guided Selective visual and decoding Enhancement for Reasoning), a training-free inference procedure that adaptively selects task-appropriate layers for visual localization and question answering. Experiments across diverse VQA benchmarks show that LASER significantly improves VQA accuracy across tasks with varying levels of complexity.

</details>


### [50] [JOintGS: Joint Optimization of Cameras, Bodies and 3D Gaussians for In-the-Wild Monocular Reconstruction](https://arxiv.org/abs/2602.04317)
*Zihan Lou,Jinlong Fan,Sihan Ma,Yuxiang Yang,Jing Zhang*

Main category: cs.CV

TL;DR: JOintGS联合优化相机、姿态和3D高斯表示，显著提升非受控场景下3D人体化身重建质量，PSNR提升2.1 dB。


<details>
  <summary>Details</summary>
Motivation: 解决在非受控场景下，由于相机参数和人体姿态估计不准确导致的高保真3D人体化身重建挑战。

Method: 提出了一种统一的框架JOintGS，通过协同优化机制联合优化相机外部参数、人体姿态和3D高斯表示，并引入了时间动态模块和残差颜色场来捕捉姿态依赖的细粒度变形和光照变化。

Result: 在NeuMan和EMDB数据集上，JOintGS实现了优于现有方法的重建质量，PSNR提升了2.1 dB，并保持了实时渲染能力。

Conclusion: JOintGS通过联合优化相机外部参数、人体姿态和3D高斯表示，显著提升了在非受控场景下从单目RGB视频重建高保真可动画3D人体化身的能力，并在NeuMan数据集上实现了2.1 dB的PSNR提升。

Abstract: Reconstructing high-fidelity animatable 3D human avatars from monocular RGB videos remains challenging, particularly in unconstrained in-the-wild scenarios where camera parameters and human poses from off-the-shelf methods (e.g., COLMAP, HMR2.0) are often inaccurate. Splatting (3DGS) advances demonstrate impressive rendering quality and real-time performance, they critically depend on precise camera calibration and pose annotations, limiting their applicability in real-world settings. We present JOintGS, a unified framework that jointly optimizes camera extrinsics, human poses, and 3D Gaussian representations from coarse initialization through a synergistic refinement mechanism. Our key insight is that explicit foreground-background disentanglement enables mutual reinforcement: static background Gaussians anchor camera estimation via multi-view consistency; refined cameras improve human body alignment through accurate temporal correspondence; optimized human poses enhance scene reconstruction by removing dynamic artifacts from static constraints. We further introduce a temporal dynamics module to capture fine-grained pose-dependent deformations and a residual color field to model illumination variations. Extensive experiments on NeuMan and EMDB datasets demonstrate that JOintGS achieves superior reconstruction quality, with 2.1~dB PSNR improvement over state-of-the-art methods on NeuMan dataset, while maintaining real-time rendering. Notably, our method shows significantly enhanced robustness to noisy initialization compared to the baseline.Our source code is available at https://github.com/MiliLab/JOintGS.

</details>


### [51] [Multiview Self-Representation Learning across Heterogeneous Views](https://arxiv.org/abs/2602.04328)
*Jie Chen,Zhu Wang,Chuanbin Liu,Xi Peng*

Main category: cs.CV

TL;DR: MSRL方法通过自表示学习和分配概率分布一致性，从异构多视图数据中学习不变表示，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 由于不同预训练模型的目标或架构差异，同一样本的特征分布存在固有差异，如何在完全无监督的迁移学习中从大规模无标记视觉数据中学习不变表示是一个重要挑战。

Method: 提出了一种多视图自表示学习（MSRL）方法，通过自表示学习的信息传递机制和分配概率分布一致性方案，从异构多视图数据中学习不变表示。

Result: 在多个基准视觉数据集上的实验表明，MSRL方法一致优于几种最先进的方法。

Conclusion: 论文提出的MSRL方法通过利用异构多视图数据的自表示特性，成功学习了不变表示，并在多个基准视觉数据集上表现优于现有方法。

Abstract: Features of the same sample generated by different pretrained models often exhibit inherently distinct feature distributions because of discrepancies in the model pretraining objectives or architectures. Learning invariant representations from large-scale unlabeled visual data with various pretrained models in a fully unsupervised transfer manner remains a significant challenge. In this paper, we propose a multiview self-representation learning (MSRL) method in which invariant representations are learned by exploiting the self-representation property of features across heterogeneous views. The features are derived from large-scale unlabeled visual data through transfer learning with various pretrained models and are referred to as heterogeneous multiview data. An individual linear model is stacked on top of its corresponding frozen pretrained backbone. We introduce an information-passing mechanism that relies on self-representation learning to support feature aggregation over the outputs of the linear model. Moreover, an assignment probability distribution consistency scheme is presented to guide multiview self-representation learning by exploiting complementary information across different views. Consequently, representation invariance across different linear models is enforced through this scheme. In addition, we provide a theoretical analysis of the information-passing mechanism, the assignment probability distribution consistency and the incremental views. Extensive experiments with multiple benchmark visual datasets demonstrate that the proposed MSRL method consistently outperforms several state-of-the-art approaches.

</details>


### [52] [Fine-tuning Pre-trained Vision-Language Models in a Human-Annotation-Free Manner](https://arxiv.org/abs/2602.04337)
*Qian-Wei Wang,Guanghao Meng,Ren Cai,Yaguang Song,Shu-Tao Xia*

Main category: cs.CV

TL;DR: CoFT通过双模型协作和双提示学习策略，无需手工阈值即可高效利用无标注数据，显著提升视觉语言模型的适应性。


<details>
  <summary>Details</summary>
Motivation: 现有无监督自训练方法依赖伪标签，但常受限于不可靠的置信度过滤、确认偏差和低置信度样本的未充分利用。

Method: 提出Collaborative Fine-Tuning (CoFT)框架，采用双提示学习策略（正负文本提示）和两阶段训练方案，从参数高效微调过渡到全微调。CoFT+进一步通过迭代微调、动量对比学习和LLM生成提示增强适应性。

Result: 实验表明，CoFT和CoFT+在无监督方法中表现优于现有方法，甚至超过少样本监督基线。

Conclusion: CoFT和CoFT+框架通过双模型跨模态协作机制，有效解决了无监督自训练中的伪标签可靠性问题，显著提升了大规模视觉语言模型在下游任务中的适应性。

Abstract: Large-scale vision-language models (VLMs) such as CLIP exhibit strong zero-shot generalization, but adapting them to downstream tasks typically requires costly labeled data. Existing unsupervised self-training methods rely on pseudo-labeling, yet often suffer from unreliable confidence filtering, confirmation bias, and underutilization of low-confidence samples. We propose Collaborative Fine-Tuning (CoFT), an unsupervised adaptation framework that leverages unlabeled data through a dual-model, cross-modal collaboration mechanism. CoFT introduces a dual-prompt learning strategy with positive and negative textual prompts to explicitly model pseudo-label cleanliness in a sample-dependent manner, removing the need for hand-crafted thresholds or noise assumptions. The negative prompt also regularizes lightweight visual adaptation modules, improving robustness under noisy supervision. CoFT employs a two-phase training scheme, transitioning from parameter-efficient fine-tuning on high-confidence samples to full fine-tuning guided by collaboratively filtered pseudo-labels. Building on CoFT, CoFT+ further enhances adaptation via iterative fine-tuning, momentum contrastive learning, and LLM-generated prompts. Extensive experiments demonstrate consistent gains over existing unsupervised methods and even few-shot supervised baselines.

</details>


### [53] [Explicit Uncertainty Modeling for Active CLIP Adaptation with Dual Prompt Tuning](https://arxiv.org/abs/2602.04340)
*Qian-Wei Wang,Yaguang Song,Shu-Tao Xia*

Main category: cs.CV

TL;DR: 提出双提示调优框架，通过正负提示增强CLIP在有限标注下的主动适应能力，实验表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 预训练的视觉语言模型（如CLIP）在下游图像分类任务中的适应性问题，尤其在有限标注预算下，现有方法未能从模型角度明确建模不确定性。

Method: 提出了一种双提示调优框架，包括正提示（增强任务特定文本嵌入的区分性）和负提示（明确建模预测标签正确的概率）。

Result: 在不同微调范式下的广泛实验表明，该方法在相同标注预算下始终优于现有主动学习方法。

Conclusion: 该论文提出了一种基于双提示调优的主动CLIP适应框架，通过引入正负提示来增强分类可靠性和明确建模不确定性，实验证明该方法在相同标注预算下优于现有主动学习方法。

Abstract: Pre-trained vision-language models such as CLIP exhibit strong transferability, yet adapting them to downstream image classification tasks under limited annotation budgets remains challenging. In active learning settings, the model must select the most informative samples for annotation from a large pool of unlabeled data. Existing approaches typically estimate uncertainty via entropy-based criteria or representation clustering, without explicitly modeling uncertainty from the model perspective. In this work, we propose a robust uncertainty modeling framework for active CLIP adaptation based on dual-prompt tuning. We introduce two learnable prompts in the textual branch of CLIP. The positive prompt enhances the discriminability of task-specific textual embeddings corresponding to light-weight tuned visual embeddings, improving classification reliability. Meanwhile, the negative prompt is trained in an reversed manner to explicitly model the probability that the predicted label is correct, providing a principled uncertainty signal for guiding active sample selection. Extensive experiments across different fine-tuning paradigms demonstrate that our method consistently outperforms existing active learning methods under the same annotation budget.

</details>


### [54] [Finding NeMO: A Geometry-Aware Representation of Template Views for Few-Shot Perception](https://arxiv.org/abs/2602.04343)
*Sebastian Jung,Leonard Klüpfel,Rudolph Triebel,Maximilian Durner*

Main category: cs.CV

TL;DR: NeMO是一种新型物体表示方法，通过少量模板视图生成点云，实现小样本物体感知，无需重新训练，在多个任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 动机是提升与新颖物体的交互能力，通过将物体信息外包到NeMO中并使用单一网络处理多种感知任务，提高可扩展性和效率。

Method: 方法包括一个编码器，仅需少量RGB模板视图生成包含语义和几何信息的稀疏点云，以及一个解码器，结合查询图像生成密集预测。

Result: 在BOP基准测试的多个数据集和感知任务中取得了竞争性和最先进的结果。

Conclusion: NeMO是一种新颖的物体中心表示方法，能够在未见过的物体上进行检测、分割和6DoF姿态估计，通过实验验证了其在小样本物体感知中的有效性，无需目标数据重新训练或相机特定参数。

Abstract: We present Neural Memory Object (NeMO), a novel object-centric representation that can be used to detect, segment and estimate the 6DoF pose of objects unseen during training using RGB images. Our method consists of an encoder that requires only a few RGB template views depicting an object to generate a sparse object-like point cloud using a learned UDF containing semantic and geometric information. Next, a decoder takes the object encoding together with a query image to generate a variety of dense predictions. Through extensive experiments, we show that our method can be used for few-shot object perception without requiring any camera-specific parameters or retraining on target data. Our proposed concept of outsourcing object information in a NeMO and using a single network for multiple perception tasks enhances interaction with novel objects, improving scalability and efficiency by enabling quick object onboarding without retraining or extensive pre-processing. We report competitive and state-of-the-art results on various datasets and perception tasks of the BOP benchmark, demonstrating the versatility of our approach. https://github.com/DLR-RM/nemo

</details>


### [55] [VecSet-Edit: Unleashing Pre-trained LRM for Mesh Editing from Single Image](https://arxiv.org/abs/2602.04349)
*Teng-Fang Hsiao,Bo-Kai Ruan,Yu-Lun Liu,Hong-Han Shuai*

Main category: cs.CV

TL;DR: VecSet-Edit 是首个利用 VecSet LRM 进行 3D 网格编辑的流程，通过多项创新策略实现高保真编辑，解决了现有方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 当前 3D 编辑方法主要关注 3D 高斯泼溅或多视图图像，直接编辑 3D 网格的研究较少，且现有方法（如 VoxHammer）存在分辨率限制和劳动密集型 3D 掩码问题。

Method: 利用 VecSet LRM 作为骨干网络，结合 Mask-guided Token Seeding、Attention-aligned Token Gating 和 Drift-aware Token Pruning 策略，以及 Detail-preserving Texture Baking 模块。

Result: VecSet-Edit 能够仅通过 2D 图像条件精确定位目标区域，并在去噪过程中拒绝几何异常值，同时保留原始网格的几何和纹理细节。

Conclusion: VecSet-Edit 提出了一种基于 VecSet LRM 的新方法，通过分析空间属性并引入多项策略，实现了对 3D 网格的高保真编辑，同时保留了几何和纹理细节。

Abstract: 3D editing has emerged as a critical research area to provide users with flexible control over 3D assets. While current editing approaches predominantly focus on 3D Gaussian Splatting or multi-view images, the direct editing of 3D meshes remains underexplored. Prior attempts, such as VoxHammer, rely on voxel-based representations that suffer from limited resolution and necessitate labor-intensive 3D mask. To address these limitations, we propose \textbf{VecSet-Edit}, the first pipeline that leverages the high-fidelity VecSet Large Reconstruction Model (LRM) as a backbone for mesh editing. Our approach is grounded on a analysis of the spatial properties in VecSet tokens, revealing that token subsets govern distinct geometric regions. Based on this insight, we introduce Mask-guided Token Seeding and Attention-aligned Token Gating strategies to precisely localize target regions using only 2D image conditions. Also, considering the difference between VecSet diffusion process versus voxel we design a Drift-aware Token Pruning to reject geometric outliers during the denoising process. Finally, our Detail-preserving Texture Baking module ensures that we not only preserve the geometric details of original mesh but also the textural information. More details can be found in our project page: https://github.com/BlueDyee/VecSet-Edit/tree/main

</details>


### [56] [SparVAR: Exploring Sparsity in Visual AutoRegressive Modeling for Training-Free Acceleration](https://arxiv.org/abs/2602.04361)
*Zekun Li,Ning Wang,Tongxin Bai,Changwang Mei,Peisong Wang,Shuang Qiu,Jian Cheng*

Main category: cs.CV

TL;DR: SparVAR 是一种高效稀疏注意力框架，显著加速 VAR 模型的高分辨率图像生成，同时保持高质量。


<details>
  <summary>Details</summary>
Motivation: 主流 VAR 范式在每个自回归步骤中关注所有历史尺度的所有 token，导致计算复杂度随分辨率增长而急剧增加，造成显著延迟。现有加速方法常跳过高分辨率尺度，虽加快推理但牺牲了图像质量。

Method: SparVAR 动态预测高分辨率尺度的稀疏注意力模式，并通过高效的索引映射机制构建尺度自相似稀疏注意力，实现了大规模的高效稀疏注意力计算。此外，还提出了跨尺度局部稀疏注意力和高效的块状稀疏核。

Result: SparVAR 将 8B 模型生成 1024×1024 高分辨率图像的时间缩短至 1 秒，比 FlashAttention 加速的 VAR 基线快 1.57 倍，且几乎保留了所有高频细节。结合现有尺度跳过策略，加速可达 2.28 倍。

Conclusion: SparVAR 是一种无需训练的加速框架，通过利用 VAR 注意力的三个特性，显著提升了高分辨率图像生成的效率，同时保留了高频细节。

Abstract: Visual AutoRegressive (VAR) modeling has garnered significant attention for its innovative next-scale prediction paradigm. However, mainstream VAR paradigms attend to all tokens across historical scales at each autoregressive step. As the next scale resolution grows, the computational complexity of attention increases quartically with resolution, causing substantial latency. Prior accelerations often skip high-resolution scales, which speeds up inference but discards high-frequency details and harms image quality. To address these problems, we present SparVAR, a training-free acceleration framework that exploits three properties of VAR attention: (i) strong attention sinks, (ii) cross-scale activation similarity, and (iii) pronounced locality. Specifically, we dynamically predict the sparse attention pattern of later high-resolution scales from a sparse decision scale, and construct scale self-similar sparse attention via an efficient index-mapping mechanism, enabling high-efficiency sparse attention computation at large scales. Furthermore, we propose cross-scale local sparse attention and implement an efficient block-wise sparse kernel, which achieves $\mathbf{> 5\times}$ faster forward speed than FlashAttention. Extensive experiments demonstrate that the proposed SparseVAR can reduce the generation time of an 8B model producing $1024\times1024$ high-resolution images to the 1s, without skipping the last scales. Compared with the VAR baseline accelerated by FlashAttention, our method achieves a $\mathbf{1.57\times}$ speed-up while preserving almost all high-frequency details. When combined with existing scale-skipping strategies, SparseVAR attains up to a $\mathbf{2.28\times}$ acceleration, while maintaining competitive visual generation quality. Code is available at https://github.com/CAS-CLab/SparVAR.

</details>


### [57] [When and Where to Attack? Stage-wise Attention-Guided Adversarial Attack on Large Vision Language Models](https://arxiv.org/abs/2602.04356)
*Jaehyun Kwak,Nam Cao,Boryeong Cho,Segyu Lee,Sumyeong Ahn,Se-Young Yun*

Main category: cs.CV

TL;DR: SAGA是一种注意力引导的对抗攻击框架，通过集中扰动在高注意力区域，高效利用扰动预算，在多种LVLM上实现高攻击成功率。


<details>
  <summary>Details</summary>
Motivation: 揭示大型视觉语言模型（LVLMs）的安全漏洞，发现随机裁剪整个图像的方法效率低下，无法有效利用有限的像素扰动预算。

Method: 提出了Stage-wise Attention-Guided Attack (SAGA)，一种注意力引导的框架，逐步将扰动集中在高注意力区域。

Result: SAGA在十种LVLM上实现了最先进的攻击成功率，生成了高度不易察觉的对抗样本。

Conclusion: SAGA框架通过逐步将扰动集中在高注意力区域，更高效地利用了有限的扰动预算，生成了高度不易察觉的对抗样本，并在十种LVLM上实现了最先进的攻击成功率。

Abstract: Adversarial attacks against Large Vision-Language Models (LVLMs) are crucial for exposing safety vulnerabilities in modern multimodal systems. Recent attacks based on input transformations, such as random cropping, suggest that spatially localized perturbations can be more effective than global image manipulation. However, randomly cropping the entire image is inherently stochastic and fails to use the limited per-pixel perturbation budget efficiently. We make two key observations: (i) regional attention scores are positively correlated with adversarial loss sensitivity, and (ii) attacking high-attention regions induces a structured redistribution of attention toward subsequent salient regions. Based on these findings, we propose Stage-wise Attention-Guided Attack (SAGA), an attention-guided framework that progressively concentrates perturbations on high-attention regions. SAGA enables more efficient use of constrained perturbation budgets, producing highly imperceptible adversarial examples while consistently achieving state-of-the-art attack success rates across ten LVLMs. The source code is available at https://github.com/jackwaky/SAGA.

</details>


### [58] [Enabling Real-Time Colonoscopic Polyp Segmentation on Commodity CPUs via Ultra-Lightweight Architecture](https://arxiv.org/abs/2602.04381)
*Weihao Gao,Zhuo Deng,Zheng Gong,Lan Ma*

Main category: cs.CV

TL;DR: UltraSeg是一种极端压缩（<0.3M参数）的息肉分割模型家族，可在单CPU上实现90 FPS的高效运行，适用于资源受限环境，并保持高精度。


<details>
  <summary>Details</summary>
Motivation: 当前高精度分割模型依赖GPU，难以在基层医院、移动内窥镜单元或胶囊机器人中部署。UltraSeg旨在填补这一空白，提供一种在资源受限环境中实时、准确的息肉识别解决方案。

Method: 通过联合优化编码器-解码器宽度、引入受限扩张卷积以扩大感受野，并集成跨层轻量级融合模块，UltraSeg-108K和UltraSeg-130K在极端压缩条件下实现了高效且准确的息肉分割。

Result: 在七个公共数据集上评估，UltraSeg仅使用0.4%的参数（0.108M/0.13M），却保留了31M参数U-Net 94%以上的Dice分数，且在单CPU核心上达到90 FPS。

Conclusion: UltraSeg家族通过极端压缩（<0.3M参数）实现了在单CPU核心上90 FPS的高效运行，同时保持了高精度（Dice分数>94%），为资源受限环境提供了即时可部署的解决方案，并为更广泛的微创手术视觉应用提供了可复制的蓝图。

Abstract: Early detection of colorectal cancer hinges on real-time, accurate polyp identification and resection. Yet current high-precision segmentation models rely on GPUs, making them impractical to deploy in primary hospitals, mobile endoscopy units, or capsule robots. To bridge this gap, we present the UltraSeg family, operating in an extreme-compression regime (<0.3 M parameters). UltraSeg-108K (0.108 M parameters) is optimized for single-center data, while UltraSeg-130K (0.13 M parameters) generalizes to multi-center, multi-modal images. By jointly optimizing encoder-decoder widths, incorporating constrained dilated convolutions to enlarge receptive fields, and integrating a cross-layer lightweight fusion module, the models achieve 90 FPS on a single CPU core without sacrificing accuracy. Evaluated on seven public datasets, UltraSeg retains >94% of the Dice score of a 31 M-parameter U-Net while utilizing only 0.4% of its parameters, establishing a strong, clinically viable baseline for the extreme-compression domain and offering an immediately deployable solution for resource-constrained settings. This work provides not only a CPU-native solution for colonoscopy but also a reproducible blueprint for broader minimally invasive surgical vision applications. Source code is publicly available to ensure reproducibility and facilitate future benchmarking.

</details>


### [59] [Med-MMFL: A Multimodal Federated Learning Benchmark in Healthcare](https://arxiv.org/abs/2602.04416)
*Aavash Chhetri,Bibek Niroula,Pratik Shrestha,Yash Raj Shrestha,Lesley A Anderson,Prashnna K Gyawali,Loris Bazzani,Binod Bhattarai*

Main category: cs.CV

TL;DR: Med-MMFL 是首个医学多模态联邦学习基准，涵盖多种模态、任务和联邦场景，支持可复现性和公平比较。


<details>
  <summary>Details</summary>
Motivation: 医学联邦学习基准稀缺，现有工作主要集中在单模态或双模态及有限的医学任务上，缺乏标准化评估以推动医学多模态联邦学习的系统性理解。

Method: Med-MMFL 评估了六种代表性的最先进联邦学习算法，涵盖不同的聚合策略、损失函数和正则化技术。实验在自然联邦、合成 IID 和合成非 IID 设置下进行，以模拟现实世界的异质性。

Result: Med-MMFL 涵盖了 2 至 4 种模态的数据集，共包含 10 种独特的医学模态，包括文本、病理图像、心电图、X 射线、放射学报告和多种 MRI 序列。评估了分割、分类、模态对齐（检索）和视觉问答任务。

Conclusion: Med-MMFL 是首个全面的医学多模态联邦学习基准，涵盖了多种模态、任务和联邦场景，为未来多模态联邦学习方法在真实医学环境中的可复现性和公平比较提供了支持。

Abstract: Federated learning (FL) enables collaborative model training across decentralized medical institutions while preserving data privacy. However, medical FL benchmarks remain scarce, with existing efforts focusing mainly on unimodal or bimodal modalities and a limited range of medical tasks. This gap underscores the need for standardized evaluation to advance systematic understanding in medical MultiModal FL (MMFL). To this end, we introduce Med-MMFL, the first comprehensive MMFL benchmark for the medical domain, encompassing diverse modalities, tasks, and federation scenarios. Our benchmark evaluates six representative state-of-the-art FL algorithms, covering different aggregation strategies, loss formulations, and regularization techniques. It spans datasets with 2 to 4 modalities, comprising a total of 10 unique medical modalities, including text, pathology images, ECG, X-ray, radiology reports, and multiple MRI sequences. Experiments are conducted across naturally federated, synthetic IID, and synthetic non-IID settings to simulate real-world heterogeneity. We assess segmentation, classification, modality alignment (retrieval), and VQA tasks. To support reproducibility and fair comparison of future multimodal federated learning (MMFL) methods under realistic medical settings, we release the complete benchmark implementation, including data processing and partitioning pipelines, at https://github.com/bhattarailab/Med-MMFL-Benchmark .

</details>


### [60] [Interactive Spatial-Frequency Fusion Mamba for Multi-Modal Image Fusion](https://arxiv.org/abs/2602.04405)
*Yixin Zhu,Long Lv,Pingping Zhang,Xuehu Liu,Tongdan Tang,Feng Tian,Weibing Sun,Huchuan Lu*

Main category: cs.CV

TL;DR: ISFM框架通过交互式空间-频率融合提升多模态图像融合效果。


<details>
  <summary>Details</summary>
Motivation: 现有MMIF方法在频域信息利用上缺乏交互性，导致特征融合不充分。

Method: 提出Interactive Spatial-Frequency Fusion Mamba (ISFM)框架，包括Modality-Specific Extractor (MSE)、Multi-scale Frequency Fusion (MFF)和Interactive Spatial-Frequency Fusion (ISF)。

Result: 在六个MMIF数据集上的实验表明，ISFM性能优于其他方法。

Conclusion: ISFM框架在多个MMIF数据集上表现出色，优于现有最先进方法。

Abstract: Multi-Modal Image Fusion (MMIF) aims to combine images from different modalities to produce fused images, retaining texture details and preserving significant information. Recently, some MMIF methods incorporate frequency domain information to enhance spatial features. However, these methods typically rely on simple serial or parallel spatial-frequency fusion without interaction. In this paper, we propose a novel Interactive Spatial-Frequency Fusion Mamba (ISFM) framework for MMIF. Specifically, we begin with a Modality-Specific Extractor (MSE) to extract features from different modalities. It models long-range dependencies across the image with linear computational complexity. To effectively leverage frequency information, we then propose a Multi-scale Frequency Fusion (MFF). It adaptively integrates low-frequency and high-frequency components across multiple scales, enabling robust representations of frequency features. More importantly, we further propose an Interactive Spatial-Frequency Fusion (ISF). It incorporates frequency features to guide spatial features across modalities, enhancing complementary representations. Extensive experiments are conducted on six MMIF datasets. The experimental results demonstrate that our ISFM can achieve better performances than other state-of-the-art methods. The source code is available at https://github.com/Namn23/ISFM.

</details>


### [61] [SLUM-i: Semi-supervised Learning for Urban Mapping of Informal Settlements and Data Quality Benchmarking](https://arxiv.org/abs/2602.04525)
*Muhammad Taha Mukhtar,Syed Musa Ali Kazmi,Khola Naseem,Muhammad Ali Chattha,Andreas Dengel,Sheraz Ahmed,Muhammad Naseer Bajwa,Muhammad Imran Malik*

Main category: cs.CV

TL;DR: 论文构建了非正规住区的基准数据集，并提出了一种新的半监督分割框架，显著提升了跨域迁移性能。


<details>
  <summary>Details</summary>
Motivation: 快速城市化导致低收入和中等收入国家中非正规住区的增长，但大规模映射面临标注稀缺和数据质量挑战。论文旨在通过构建基准数据集和新方法解决这些问题。

Method: 论文提出了一种新的半监督分割框架，包括类感知自适应阈值机制和原型银行系统，以解决类别不平衡和特征退化问题。

Result: 在跨越三大洲的八个城市实验中，该方法优于现有的半监督基线，特别是在域迁移能力上表现突出。

Conclusion: 该论文提出的半监督分割框架通过动态调整置信度阈值和原型银行系统，显著提升了在跨域迁移任务中的表现，特别是在仅有少量标注数据的情况下优于全监督模型的零样本泛化能力。

Abstract: Rapid urban expansion has fueled the growth of informal settlements in major cities of low- and middle-income countries, with Lahore and Karachi in Pakistan and Mumbai in India serving as prominent examples. However, large-scale mapping of these settlements is severely constrained not only by the scarcity of annotations but by inherent data quality challenges, specifically high spectral ambiguity between formal and informal structures and significant annotation noise. We address this by introducing a benchmark dataset for Lahore, constructed from scratch, along with companion datasets for Karachi and Mumbai, which were derived from verified administrative boundaries, totaling 1,869 $\text{km}^2$ of area. To evaluate the global robustness of our framework, we extend our experiments to five additional established benchmarks, encompassing eight cities across three continents, and provide comprehensive data quality assessments of all datasets. We also propose a new semi-supervised segmentation framework designed to mitigate the class imbalance and feature degradation inherent in standard semi-supervised learning pipelines. Our method integrates a Class-Aware Adaptive Thresholding mechanism that dynamically adjusts confidence thresholds to prevent minority class suppression and a Prototype Bank System that enforces semantic consistency by anchoring predictions to historically learned high-fidelity feature representations. Extensive experiments across a total of eight cities spanning three continents demonstrate that our approach outperforms state-of-the-art semi-supervised baselines. Most notably, our method demonstrates superior domain transfer capability whereby a model trained on only 10% of source labels reaches a 0.461 mIoU on unseen geographies and outperforms the zero-shot generalization of fully supervised models.

</details>


### [62] [LCUDiff: Latent Capacity Upgrade Diffusion for Faithful Human Body Restoration](https://arxiv.org/abs/2602.04406)
*Jue Gong,Zihan Zhou,Jingkai Wang,Shu Li,Libo Liu,Jianliang Lan,Yulun Zhang*

Main category: cs.CV

TL;DR: LCUDiff通过升级潜在扩散模型通道数和新技术，提升人体图像恢复的保真度和效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在人体图像恢复中保真度不足，特别是VAE成为恢复保真度的瓶颈。

Method: 提出LCUDiff框架，将预训练的潜在扩散模型从4通道升级到16通道，采用CSD技术微调VAE，设计PPA解决通道不匹配问题，并引入DeR进行解码器路由。

Result: 在合成和真实数据集上展示了更高的保真度和更少的伪影，同时保持了一步效率。

Conclusion: LCUDiff通过升级潜在扩散模型的通道数并采用CSD、PPA和DeR技术，显著提高了人体图像恢复的保真度，同时保持了一步效率。

Abstract: Existing methods for restoring degraded human-centric images often struggle with insufficient fidelity, particularly in human body restoration (HBR). Recent diffusion-based restoration methods commonly adapt pre-trained text-to-image diffusion models, where the variational autoencoder (VAE) can significantly bottleneck restoration fidelity. We propose LCUDiff, a stable one-step framework that upgrades a pre-trained latent diffusion model from the 4-channel latent space to the 16-channel latent space. For VAE fine-tuning, channel splitting distillation (CSD) is used to keep the first four channels aligned with pre-trained priors while allocating the additional channels to effectively encode high-frequency details. We further design prior-preserving adaptation (PPA) to smoothly bridge the mismatch between 4-channel diffusion backbones and the higher-dimensional 16-channel latent. In addition, we propose a decoder router (DeR) for per-sample decoder routing using restoration-quality score annotations, which improves visual quality across diverse conditions. Experiments on synthetic and real-world datasets show competitive results with higher fidelity and fewer artifacts under mild degradations, while preserving one-step efficiency. The code and model will be at https://github.com/gobunu/LCUDiff.

</details>


### [63] [OmniRad: A Radiological Foundation Model for Multi-Task Medical Image Analysis](https://arxiv.org/abs/2602.04547)
*Luca Zedda,Andrea Loddo,Cecilia Di Ruberto*

Main category: cs.CV

TL;DR: OmniRad是一个自监督的放射学基础模型，在分类和分割任务上表现优于其他模型，通过强调表示重用和跨任务可转移性实现。


<details>
  <summary>Details</summary>
Motivation: 放射学分析需要预训练的视觉表示以支持跨成像模态的异构下游任务，OmniRad旨在通过自监督学习提供高质量的表示。

Method: OmniRad是一个自监督的放射学基础模型，预训练于120万张医学图像，设计了强调表示重用和跨任务可转移性的原则。评估包括轻量级任务特定适配器和端到端微调。

Result: 在MedMNISTv2集合上，OmniRad将分类F1提高了2.05%；在MedSegBench数据集上，使用冻结表示时平均Dice分数有所提升。

Conclusion: OmniRad作为自监督的放射学基础模型，通过强调表示重用和跨任务可转移性，在多种下游任务中表现出色，特别是在分类和分割任务上优于其他基础模型。

Abstract: Radiological analysis increasingly benefits from pretrained visual representations that can support heterogeneous downstream tasks across imaging modalities. In this work, we introduce OmniRad, a self-supervised radiological foundation model pretrained on 1.2 million medical images, designed with radiology-inspired principles emphasizing representation reuse and cross-task transferability. We evaluate the pretrained encoder under multiple downstream adaptation regimes, including lightweight task-specific adapters with a frozen backbone as well as full end-to-end fine-tuning for classification, allowing us to assess both representation quality and task-specific performance. OmniRad is evaluated on a broad suite of public benchmarks spanning classification and segmentation across multiple modalities. On the MedMNISTv2 collection, OmniRad improves classification F1 by up to 2.05% over competing foundation models. For dense prediction, OmniRad attains mean Dice score improvements across six MedSegBench datasets when using frozen representations. Qualitative analyses and latent-space visualizations suggest improved feature clustering and modality-related separation.

</details>


### [64] [TrajVG: 3D Trajectory-Coupled Visual Geometry Learning](https://arxiv.org/abs/2602.04439)
*Xingyu Miao,Weiguang Zhao,Tao Lu,Linning Yu,Mulin Yu,Yang Long,Jiangmiao Pang,Junting Dong*

Main category: cs.CV

TL;DR: TrajVG通过显式预测3D轨迹改进多帧3D重建，解决了运动物体视频中的性能问题，实验表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决前馈多帧3D重建模型在物体运动视频中性能下降的问题，特别是全局参考模糊和局部点图依赖估计相对姿态导致的漂移问题。

Method: 提出TrajVG框架，通过估计相机坐标系的3D轨迹来实现跨帧3D对应关系预测，结合稀疏轨迹、局部点图和相机姿态的几何一致性目标。

Result: 在3D跟踪、姿态估计、点图重建和视频深度等任务上，TrajVG超越了当前前馈性能基线。

Conclusion: TrajVG通过显式预测跨帧3D对应关系，结合稀疏轨迹、每帧局部点图和相对相机姿态，提升了多帧3D重建的性能，尤其在物体运动场景下表现优异。

Abstract: Feed-forward multi-frame 3D reconstruction models often degrade on videos with object motion. Global-reference becomes ambiguous under multiple motions, while the local pointmap relies heavily on estimated relative poses and can drift, causing cross-frame misalignment and duplicated structures. We propose TrajVG, a reconstruction framework that makes cross-frame 3D correspondence an explicit prediction by estimating camera-coordinate 3D trajectories. We couple sparse trajectories, per-frame local point maps, and relative camera poses with geometric consistency objectives: (i) bidirectional trajectory-pointmap consistency with controlled gradient flow, and (ii) a pose consistency objective driven by static track anchors that suppresses gradients from dynamic regions. To scale training to in-the-wild videos where 3D trajectory labels are scarce, we reformulate the same coupling constraints into self-supervised objectives using only pseudo 2D tracks, enabling unified training with mixed supervision. Extensive experiments across 3D tracking, pose estimation, pointmap reconstruction, and video depth show that TrajVG surpasses the current feedforward performance baseline.

</details>


### [65] [SynthVerse: A Large-Scale Diverse Synthetic Dataset for Point Tracking](https://arxiv.org/abs/2602.04441)
*Weiguang Zhao,Haoran Xu,Xingyu Miao,Qin Zhao,Rui Zhang,Kaizhu Huang,Ning Gao,Peizhou Cao,Mingze Sun,Mulin Yu,Tao Lu,Linning Xu,Junting Dong,Jiangmiao Pang*

Main category: cs.CV

TL;DR: SynthVerse是一个多样化合成数据集，用于提升点跟踪的泛化能力，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有数据集在多样性和轨迹标注质量上不足，限制了通用点跟踪的进展。

Method: 引入SynthVerse，一个大规模、多样化的合成数据集，涵盖新领域和对象类型，如动画电影风格内容、具身操作、场景导航和铰接对象。

Result: 实验表明，使用SynthVerse训练能带来一致的泛化性能提升。

Conclusion: SynthVerse数据集显著提升了点跟踪任务的泛化能力，并揭示了现有跟踪器在多样化设置下的局限性。

Abstract: Point tracking aims to follow visual points through complex motion, occlusion, and viewpoint changes, and has advanced rapidly with modern foundation models. Yet progress toward general point tracking remains constrained by limited high-quality data, as existing datasets often provide insufficient diversity and imperfect trajectory annotations. To this end, we introduce SynthVerse, a large-scale, diverse synthetic dataset specifically designed for point tracking. SynthVerse includes several new domains and object types missing from existing synthetic datasets, such as animated-film-style content, embodied manipulation, scene navigation, and articulated objects. SynthVerse substantially expands dataset diversity by covering a broader range of object categories and providing high-quality dynamic motions and interactions, enabling more robust training and evaluation for general point tracking. In addition, we establish a highly diverse point tracking benchmark to systematically evaluate state-of-the-art methods under broader domain shifts. Extensive experiments and analyses demonstrate that training with SynthVerse yields consistent improvements in generalization and reveal limitations of existing trackers under diverse settings.

</details>


### [66] [DRMOT: A Dataset and Framework for RGBD Referring Multi-Object Tracking](https://arxiv.org/abs/2602.04692)
*Sijia Chen,Lijuan Ma,Yanqiu Yu,En Yu,Liman Liu,Wenbing Tao*

Main category: cs.CV

TL;DR: 提出了DRMOT任务和DRTrack框架，通过融合RGB-D-L模态提升3D感知跟踪能力，并在DRSet数据集上验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有的RMOT模型仅依赖2D RGB数据，难以准确检测和关联具有复杂空间语义的目标，且在严重遮挡下难以保持可靠的身份识别。因此，提出RGBD Referring Multi-Object Tracking (DRMOT)任务，明确要求模型融合RGB、深度和语言模态以实现3D感知跟踪。

Method: 提出了DRTrack框架，该框架通过MLLM引导，结合RGB-D-L输入进行深度感知目标定位，并利用深度线索增强轨迹关联的鲁棒性。

Result: 构建了DRSet数据集，包含187个场景的RGB图像和深度图，以及240个语言描述（其中56个包含深度信息）。DRTrack在DRSet上的实验验证了其有效性。

Conclusion: DRTrack框架在DRSet数据集上的实验证明了其有效性，展示了RGB-D-L多模态融合在提升3D感知跟踪任务中的潜力。

Abstract: Referring Multi-Object Tracking (RMOT) aims to track specific targets based on language descriptions and is vital for interactive AI systems such as robotics and autonomous driving. However, existing RMOT models rely solely on 2D RGB data, making it challenging to accurately detect and associate targets characterized by complex spatial semantics (e.g., ``the person closest to the camera'') and to maintain reliable identities under severe occlusion, due to the absence of explicit 3D spatial information. In this work, we propose a novel task, RGBD Referring Multi-Object Tracking (DRMOT), which explicitly requires models to fuse RGB, Depth (D), and Language (L) modalities to achieve 3D-aware tracking. To advance research on the DRMOT task, we construct a tailored RGBD referring multi-object tracking dataset, named DRSet, designed to evaluate models' spatial-semantic grounding and tracking capabilities. Specifically, DRSet contains RGB images and depth maps from 187 scenes, along with 240 language descriptions, among which 56 descriptions incorporate depth-related information. Furthermore, we propose DRTrack, a MLLM-guided depth-referring tracking framework. DRTrack performs depth-aware target grounding from joint RGB-D-L inputs and enforces robust trajectory association by incorporating depth cues. Extensive experiments on the DRSet dataset demonstrate the effectiveness of our framework.

</details>


### [67] [Seg-ReSearch: Segmentation with Interleaved Reasoning and External Search](https://arxiv.org/abs/2602.04454)
*Tianming Liang,Qirui Du,Jian-Fang Hu,Haichao Jiang,Zicheng Lin,Wei-Shi Zheng*

Main category: cs.CV

TL;DR: Seg-ReSearch是一种结合推理和外部搜索的新分割范式，解决了现有方法因知识冻结导致的局限性，并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于多模态大语言模型的分割系统因内部知识冻结而无法处理实时信息或特定领域概念的局限性。

Method: 提出了一种新的分割范式Seg-ReSearch，通过分层奖励设计训练系统，结合初始指导和渐进激励。

Result: 在OK-VOS及其他两个推理分割基准测试中，Seg-ReSearch显著优于现有方法。

Conclusion: Seg-ReSearch通过结合推理和外部搜索，显著提升了分割系统处理动态、开放世界查询的能力，并在多个基准测试中优于现有方法。

Abstract: Segmentation based on language has been a popular topic in computer vision. While recent advances in multimodal large language models (MLLMs) have endowed segmentation systems with reasoning capabilities, these efforts remain confined by the frozen internal knowledge of MLLMs, which limits their potential for real-world scenarios that involve up-to-date information or domain-specific concepts. In this work, we propose \textbf{Seg-ReSearch}, a novel segmentation paradigm that overcomes the knowledge bottleneck of existing approaches. By enabling interleaved reasoning and external search, Seg-ReSearch empowers segmentation systems to handle dynamic, open-world queries that extend beyond the frozen knowledge of MLLMs. To effectively train this capability, we introduce a hierarchical reward design that harmonizes initial guidance with progressive incentives, mitigating the dilemma between sparse outcome signals and rigid step-wise supervision. For evaluation, we construct OK-VOS, a challenging benchmark that explicitly requires outside knowledge for video object segmentation. Experiments on OK-VOS and two existing reasoning segmentation benchmarks demonstrate that our Seg-ReSearch improves state-of-the-art approaches by a substantial margin. Code and data will be released at https://github.com/iSEE-Laboratory/Seg-ReSearch.

</details>


### [68] [SAR-RAG: ATR Visual Question Answering by Semantic Search, Retrieval, and MLLM Generation](https://arxiv.org/abs/2602.04712)
*David F. Ramirez,Tim Overman,Kristen Jaskie,Joe Marvin,Andreas Spanias*

Main category: cs.CV

TL;DR: SAR-RAG结合MLLM和向量数据库，通过上下文搜索提升SAR图像中军事车辆的识别准确性。


<details>
  <summary>Details</summary>
Motivation: 合成孔径雷达（SAR）图像中军事车辆的识别和区分具有挑战性，需要改进现有方法以提高准确性。

Method: 提出SAR-RAG方法，结合多模态大语言模型（MLLM）和语义嵌入向量数据库，支持上下文搜索已知特性的图像示例。

Result: SAR-RAG在搜索和检索指标、分类准确性和车辆尺寸回归方面均显示出优于基线方法的性能。

Conclusion: SAR-RAG系统通过结合多模态大语言模型和向量数据库，显著提高了自动目标识别的预测准确性。

Abstract: We present a visual-context image retrieval-augmented generation (ImageRAG) assisted AI agent for automatic target recognition (ATR) of synthetic aperture radar (SAR). SAR is a remote sensing method used in defense and security applications to detect and monitor the positions of military vehicles, which may appear indistinguishable in images. Researchers have extensively studied SAR ATR to improve the differentiation and identification of vehicle types, characteristics, and measurements. Test examples can be compared with known vehicle target types to improve recognition tasks. New methods enhance the capabilities of neural networks, transformer attention, and multimodal large language models. An agentic AI method may be developed to utilize a defined set of tools, such as searching through a library of similar examples. Our proposed method, SAR Retrieval-Augmented Generation (SAR-RAG), combines a multimodal large language model (MLLM) with a vector database of semantic embeddings to support contextual search for image exemplars with known qualities. By recovering past image examples with known true target types, our SAR-RAG system can compare similar vehicle categories, achieving improved ATR prediction accuracy. We evaluate this through search and retrieval metrics, categorical classification accuracy, and numeric regression of vehicle dimensions. These metrics all show improvements when SAR-RAG is added to an MLLM baseline method as an attached ATR memory bank.

</details>


### [69] [Temporal Slowness in Central Vision Drives Semantic Object Learning](https://arxiv.org/abs/2602.04462)
*Timothy Schaumlöffel,Arthur Aubret,Gemma Roig,Jochen Triesch*

Main category: cs.CV

TL;DR: 研究通过模拟人类视觉体验，发现中央视觉和时间慢性学习共同优化了语义对象表征的编码。


<details>
  <summary>Details</summary>
Motivation: 研究中央视觉和时间慢性学习在人类视觉经验中形成语义对象表征的作用。

Method: 利用Ego4D数据集模拟五个月的人类视觉体验，通过先进的目光预测模型生成注视坐标，提取模拟中央视觉的裁剪图像，并训练时间对比自监督学习模型。

Result: 结合时间慢性和中央视觉的方法改善了物体表征的语义编码：中央视觉增强了前景物体特征的提取，而时间慢性（尤其在注视眼动期间）帮助模型编码更广泛的物体语义信息。

Conclusion: 结合时间慢性和中央视觉的自我监督学习方法能更有效地编码物体表征的不同语义层面，为人类如何从自然视觉经验中发展语义对象表征提供了新见解。

Abstract: Humans acquire semantic object representations from egocentric visual streams with minimal supervision. Importantly, the visual system processes with high resolution only the center of its field of view and learns similar representations for visual inputs occurring close in time. This emphasizes slowly changing information around gaze locations. This study investigates the role of central vision and slowness learning in the formation of semantic object representations from human-like visual experience. We simulate five months of human-like visual experience using the Ego4D dataset and generate gaze coordinates with a state-of-the-art gaze prediction model. Using these predictions, we extract crops that mimic central vision and train a time-contrastive Self-Supervised Learning model on them. Our results show that combining temporal slowness and central vision improves the encoding of different semantic facets of object representations. Specifically, focusing on central vision strengthens the extraction of foreground object features, while considering temporal slowness, especially during fixational eye movements, allows the model to encode broader semantic information about objects. These findings provide new insights into the mechanisms by which humans may develop semantic object representations from natural visual experience.

</details>


### [70] [SALAD-Pan: Sensor-Agnostic Latent Adaptive Diffusion for Pan-Sharpening](https://arxiv.org/abs/2602.04473)
*Junjie Li,Congyang Ou,Haokui Zhang,Guoting Wei,Shengqin Jiang,Ying Li,Chunhua Shen*

Main category: cs.CV

TL;DR: SALAD-Pan是一种传感器无关的潜在空间扩散方法，通过VAE编码、交互控制结构和跨光谱注意力模块实现高效多光谱图像融合，性能优于现有方法且速度更快。


<details>
  <summary>Details</summary>
Motivation: 现有扩散模型在像素空间进行扩散且针对不同多光谱图像训练独立模型，导致高延迟和传感器特定限制，因此提出一种传感器无关的潜在空间扩散方法。

Method: 通过训练单通道VAE将高分辨率多光谱图像编码为紧凑潜在表示，结合光谱物理属性和PAN/MS图像，通过单向和双向交互控制结构注入扩散主干，并在扩散模型中添加轻量级跨光谱注意力模块。

Result: SALAD-Pan在三个数据集上均优于现有扩散方法，推理速度提升2-3倍，并具备跨传感器能力。

Conclusion: SALAD-Pan在GaoFen-2、QuickBird和WorldView-3数据集上表现优于现有扩散方法，推理速度提升2-3倍，并具备跨传感器的零样本能力。

Abstract: Recently, diffusion models bring novel insights for Pan-sharpening and notably boost fusion precision. However, most existing models perform diffusion in the pixel space and train distinct models for different multispectral (MS) imagery, suffering from high latency and sensor-specific limitations. In this paper, we present SALAD-Pan, a sensor-agnostic latent space diffusion method for efficient pansharpening. Specifically, SALAD-Pan trains a band-wise single-channel VAE to encode high-resolution multispectral (HRMS) into compact latent representations, supporting MS images with various channel counts and establishing a basis for acceleration. Then spectral physical properties, along with PAN and MS images, are injected into the diffusion backbone through unidirectional and bidirectional interactive control structures respectively, achieving high-precision fusion in the diffusion process. Finally, a lightweight cross-spectral attention module is added to the central layer of diffusion model, reinforcing spectral connections to boost spectral consistency and further elevate fusion precision. Experimental results on GaoFen-2, QuickBird, and WorldView-3 demonstrate that SALAD-Pan outperforms state-of-the-art diffusion-based methods across all three datasets, attains a 2-3x inference speedup, and exhibits robust zero-shot (cross-sensor) capability.

</details>


### [71] [Vision-aligned Latent Reasoning for Multi-modal Large Language Model](https://arxiv.org/abs/2602.04476)
*Byungwoo Jeon,Yoonwoo Jeong,Hyunseok Lee,Minsu Cho,Jinwoo Shin*

Main category: cs.CV

TL;DR: VaLR框架通过视觉对齐潜在标记提升MLLM多步推理能力，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有MLLM在需要多步推理的任务中表现不佳，主要由于长上下文生成中视觉信息逐渐稀释。

Method: 提出Vision-aligned Latent Reasoning (VaLR)框架，通过训练MLLM中间嵌入与视觉编码器对齐，保留视觉知识。

Result: VaLR在多个基准测试中表现优于现有方法，如VSI-Bench上性能从33.0%提升至52.9%。

Conclusion: VaLR框架通过动态生成视觉对齐的潜在标记，显著提升了多模态大语言模型在需要多步推理任务中的表现，特别是在长上下文理解和精确视觉感知方面。

Abstract: Despite recent advancements in Multi-modal Large Language Models (MLLMs) on diverse understanding tasks, these models struggle to solve problems which require extensive multi-step reasoning. This is primarily due to the progressive dilution of visual information during long-context generation, which hinders their ability to fully exploit test-time scaling. To address this issue, we introduce Vision-aligned Latent Reasoning (VaLR), a simple, yet effective reasoning framework that dynamically generates vision-aligned latent tokens before each Chain of Thought reasoning step, guiding the model to reason based on perceptual cues in the latent space. Specifically, VaLR is trained to preserve visual knowledge during reasoning by aligning intermediate embeddings of MLLM with those from vision encoders. Empirical results demonstrate that VaLR consistently outperforms existing approaches across a wide range of benchmarks requiring long-context understanding or precise visual perception, while exhibiting test-time scaling behavior not observed in prior MLLMs. In particular, VaLR improves the performance significantly from 33.0% to 52.9% on VSI-Bench, achieving a 19.9%p gain over Qwen2.5-VL.

</details>


### [72] [Toward Reliable and Explainable Nail Disease Classification: Leveraging Adversarial Training and Grad-CAM Visualization](https://arxiv.org/abs/2602.04820)
*Farzia Hossain,Samanta Ghosh,Shahida Begum,B. M. Shahria Alam,Mohammad Tahmid Noor,Md Parvez Mia,Nishat Tasnim Niloy*

Main category: cs.CV

TL;DR: 机器学习模型（InceptionV3最佳）用于自动化指甲疾病分类，准确率高，支持医生快速诊断。


<details>
  <summary>Details</summary>
Motivation: 早期发现和准确诊断指甲疾病对健康至关重要，但由于疾病类型间视觉差异微小，人工诊断具有挑战性。

Method: 使用四种知名CNN模型（InceptionV3、DenseNet201、EfficientNetV2、ResNet50）在公开数据集（3,835张图像，六类）上进行训练和评估，并采用对抗训练增强模型鲁棒性，SHAP用于解释模型决策。

Result: InceptionV3表现最佳（准确率95.57%），DenseNet201次之（94.79%），对抗训练和SHAP提升了模型性能和可解释性。

Conclusion: 该论文提出的基于机器学习的模型在指甲疾病分类中表现出色，特别是InceptionV3模型达到了95.57%的准确率，为医生提供了快速准确的诊断支持。

Abstract: Human nail diseases are gradually observed over all age groups, especially among older individuals, often going ignored until they become severe. Early detection and accurate diagnosis of such conditions are important because they sometimes reveal our body's health problems. But it is challenging due to the inferred visual differences between disease types. This paper presents a machine learning-based model for automated classification of nail diseases based on a publicly available dataset, which contains 3,835 images scaling six categories. In 224x224 pixels, all images were resized to ensure consistency. To evaluate performance, four well-known CNN models-InceptionV3, DenseNet201, EfficientNetV2, and ResNet50 were trained and analyzed. Among these, InceptionV3 outperformed the others with an accuracy of 95.57%, while DenseNet201 came next with 94.79%. To make the model stronger and less likely to make mistakes on tricky or noisy images, we used adversarial training. To help understand how the model makes decisions, we used SHAP to highlight important features in the predictions. This system could be a helpful support for doctors, making nail disease diagnosis more accurate and faster.

</details>


### [73] [Nix and Fix: Targeting 1000x Compression of 3D Gaussian Splatting with Diffusion Models](https://arxiv.org/abs/2602.04549)
*Cem Eteke,Enzo Tartaglione*

Main category: cs.CV

TL;DR: NiFi是一种新型的3DGS压缩方法，通过扩散修复在极低码率下保持高质量，码率低至0.1 MB。


<details>
  <summary>Details</summary>
Motivation: 3DGS压缩虽然取得了显著进展，但在低码率下会引入伪影，显著降低视觉质量。NiFi旨在解决这一问题。

Method: NiFi是一种通过基于扩散的一步蒸馏进行修复的极端3DGS压缩方法，具有感知伪影的特性。

Result: NiFi在极低码率下实现了优异的感知质量，码率低至0.1 MB，并在可比感知性能下显著提高了码率效率。

Conclusion: NiFi方法在极低码率（低至0.1 MB）下实现了最先进的感知质量，并在可比感知性能下比3DGS提高了近1000倍的码率。

Abstract: 3D Gaussian Splatting (3DGS) revolutionized novel view rendering. Instead of inferring from dense spatial points, as implicit representations do, 3DGS uses sparse Gaussians. This enables real-time performance but increases space requirements, hindering applications such as immersive communication. 3DGS compression emerged as a field aimed at alleviating this issue. While impressive progress has been made, at low rates, compression introduces artifacts that degrade visual quality significantly. We introduce NiFi, a method for extreme 3DGS compression through restoration via artifact-aware, diffusion-based one-step distillation. We show that our method achieves state-of-the-art perceptual quality at extremely low rates, down to 0.1 MB, and towards 1000x rate improvement over 3DGS at comparable perceptual performance. The code will be open-sourced upon acceptance.

</details>


### [74] [Understanding Degradation with Vision Language Model](https://arxiv.org/abs/2602.04565)
*Guanzhou Lan,Chenyi Liao,Yuqi Yang,Qianli Ma,Zhigang Wang,Dong Wang,Bin Zhao,Xuelong Li*

Main category: cs.CV

TL;DR: DU-VLM通过统一的自回归预测框架和多模态思维链模型，显著提升了图像退化理解的性能，并能零样本控制扩散模型进行图像恢复。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在定性描述图像退化方面表现优异，但在理解图像退化的参数化物理基础方面存在不足，需要一种能够同时估计退化类型、参数键及其连续物理值的方法。

Method: 提出了一种层次化结构化预测任务框架，将退化类型、参数键及其连续物理值的估计统一到一个自回归的下一个令牌预测范式中，并引入了DU-VLM模型，结合监督微调和带结构化奖励的强化学习进行训练。

Result: 实验证明，DU-VLM在准确性和鲁棒性上显著优于通用基线，并能泛化到未见过的分布。此外，DU-VLM还能作为零样本控制器用于预训练的扩散模型。

Conclusion: DU-VLM通过多模态思维链模型和强化学习，显著提升了图像退化理解的准确性和鲁棒性，并能作为零样本控制器用于预训练的扩散模型，实现高保真图像恢复。

Abstract: Understanding visual degradations is a critical yet challenging problem in computer vision. While recent Vision-Language Models (VLMs) excel at qualitative description, they often fall short in understanding the parametric physics underlying image degradations. In this work, we redefine degradation understanding as a hierarchical structured prediction task, necessitating the concurrent estimation of degradation types, parameter keys, and their continuous physical values. Although these sub-tasks operate in disparate spaces, we prove that they can be unified under one autoregressive next-token prediction paradigm, whose error is bounded by the value-space quantization grid. Building on this insight, we introduce DU-VLM, a multimodal chain-of-thought model trained with supervised fine-tuning and reinforcement learning using structured rewards. Furthermore, we show that DU-VLM can serve as a zero-shot controller for pre-trained diffusion models, enabling high-fidelity image restoration without fine-tuning the generative backbone. We also introduce \textbf{DU-110k}, a large-scale dataset comprising 110,000 clean-degraded pairs with grounded physical annotations. Extensive experiments demonstrate that our approach significantly outperforms generalist baselines in both accuracy and robustness, exhibiting generalization to unseen distributions.

</details>


### [75] [PEPR: Privileged Event-based Predictive Regularization for Domain Generalization](https://arxiv.org/abs/2602.04583)
*Gabriele Magrini,Federico Becattini,Niccolò Biondi,Pietro Pala*

Main category: cs.CV

TL;DR: 提出PEPR方法，利用事件相机特权信息训练RGB模型，通过预测性正则化提升领域泛化性能，优于传统对齐方法。


<details>
  <summary>Details</summary>
Motivation: 解决视觉感知中深度神经网络对领域偏移高度敏感的问题，利用事件相机提供的特权信息（仅训练时可用）提升RGB模型的泛化能力。

Method: 采用跨模态框架，基于特权信息学习（LUPI）范式，引入Privileged Event-based Predictive Regularization (PEPR)，在共享潜在空间中训练RGB编码器预测事件流特征。

Result: PEPR训练的RGB模型在目标检测和语义分割任务中，对昼夜等领域偏移的鲁棒性显著优于基于特征对齐的基线方法。

Conclusion: 提出的PEPR方法通过预测性正则化在共享潜在空间中利用事件相机信息，显著提升了RGB模型在领域泛化任务中的鲁棒性，尤其在昼夜变化等场景下表现优异。

Abstract: Deep neural networks for visual perception are highly susceptible to domain shift, which poses a critical challenge for real-world deployment under conditions that differ from the training data. To address this domain generalization challenge, we propose a cross-modal framework under the learning using privileged information (LUPI) paradigm for training a robust, single-modality RGB model. We leverage event cameras as a source of privileged information, available only during training. The two modalities exhibit complementary characteristics: the RGB stream is semantically dense but domain-dependent, whereas the event stream is sparse yet more domain-invariant. Direct feature alignment between them is therefore suboptimal, as it forces the RGB encoder to mimic the sparse event representation, thereby losing semantic detail. To overcome this, we introduce Privileged Event-based Predictive Regularization (PEPR), which reframes LUPI as a predictive problem in a shared latent space. Instead of enforcing direct cross-modal alignment, we train the RGB encoder with PEPR to predict event-based latent features, distilling robustness without sacrificing semantic richness. The resulting standalone RGB model consistently improves robustness to day-to-night and other domain shifts, outperforming alignment-based baselines across object detection and semantic segmentation.

</details>


### [76] [SalFormer360: a transformer-based saliency estimation model for 360-degree videos](https://arxiv.org/abs/2602.04584)
*Mahmoud Z. A. Wahba,Francesco Barbato,Sara Baldoni,Federica Battisti*

Main category: cs.CV

TL;DR: SalFormer360是一种基于Transformer的360度视频显著性估计模型，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 360度视频中的显著性估计在视口预测和沉浸式内容优化等任务中具有重要价值。

Method: 结合现有的SegFormer编码器架构和自定义解码器，并引入Viewing Center Bias以增强预测准确性。

Result: 在Sport360、PVS-HM和VR-EyeTracking数据集上，Pearson相关系数分别提高了8.4%、2.5%和18.6%。

Conclusion: SalFormer360在三个最大的显著性估计基准数据集上表现优异，性能超越了现有最先进方法。

Abstract: Saliency estimation has received growing attention in recent years due to its importance in a wide range of applications. In the context of 360-degree video, it has been particularly valuable for tasks such as viewport prediction and immersive content optimization. In this paper, we propose SalFormer360, a novel saliency estimation model for 360-degree videos built on a transformer-based architecture. Our approach is based on the combination of an existing encoder architecture, SegFormer, and a custom decoder. The SegFormer model was originally developed for 2D segmentation tasks, and it has been fine-tuned to adapt it to 360-degree content. To further enhance prediction accuracy in our model, we incorporated Viewing Center Bias to reflect user attention in 360-degree environments. Extensive experiments on the three largest benchmark datasets for saliency estimation demonstrate that SalFormer360 outperforms existing state-of-the-art methods. In terms of Pearson Correlation Coefficient, our model achieves 8.4% higher performance on Sport360, 2.5% on PVS-HM, and 18.6% on VR-EyeTracking compared to previous state-of-the-art.

</details>


### [77] [ImmuVis: Hyperconvolutional Foundation Model for Imaging Mass Cytometry](https://arxiv.org/abs/2602.04585)
*Marcin Możejko,Dawid Uchal,Krzysztof Gogolewski,Piotr Kupidura,Szymon Łukasik,Jakub Giezgała,Tomasz Nocoń,Kacper Pietrzyk,Robert Pieniuta,Mateusz Sulimowicz,Michal Orzyłowski,Tomasz Siłkowski,Karol Zagródka,Eike Staub,Ewa Szczurek*

Main category: cs.CV

TL;DR: ImmuVis是一种高效的卷积基础模型，通过标记自适应超卷积处理IMC数据，无需重新训练即可适应不同标记集，性能优于现有方法且计算成本低。


<details>
  <summary>Details</summary>
Motivation: 解决多重成像技术中缺乏固定通道空间的问题，因为真实世界中的标记集在不同研究中变化，违反了标准视觉主干的核心假设。

Method: ImmuVis引入了标记自适应超卷积，通过学习标记嵌入生成卷积核，使单一模型能够在任意测量的标记子集上操作而无需重新训练。

Result: ImmuVis在虚拟染色和下游分类任务中优于SOTA基线，计算成本显著低于基于Transformer的替代方案，并且是唯一通过异方差似然目标提供校准不确定性的模型。

Conclusion: ImmuVis被定位为一个实用、高效的基础模型，适用于真实世界的IMC建模。

Abstract: We present ImmuVis, an efficient convolutional foundation model for imaging mass cytometry (IMC), a high-throughput multiplex imaging technology that handles molecular marker measurements as image channels and enables large-scale spatial tissue profiling. Unlike natural images, multiplex imaging lacks a fixed channel space, as real-world marker sets vary across studies, violating a core assumption of standard vision backbones. To address this, ImmuVis introduces marker-adaptive hyperconvolutions that generate convolutional kernels from learned marker embeddings, enabling a single model to operate on arbitrary measured marker subsets without retraining. We pretrain ImmuVis on the largest to-date dataset, IMC17M (28 cohorts, 24,405 images, 265 markers, over 17M patches), using self-supervised masked reconstruction. ImmuVis outperforms SOTA baselines and ablations in virtual staining and downstream classification tasks at substantially lower compute cost than transformer-based alternatives, and is the sole model that provides calibrated uncertainty via a heteroscedastic likelihood objective. These results position ImmuVis as a practical, efficient foundation model for real-world IMC modeling.

</details>


### [78] [A labeled dataset of simulated phlebotomy procedures for medical AI: polygon annotations for object detection and human-object interaction](https://arxiv.org/abs/2602.04624)
*Raúl Jiménez Cruz,César Torres-Huitzil,Marco Franceschetti,Ronny Seiger,Luciano García-Bañuelos,Barbara Weber*

Main category: cs.CV

TL;DR: 本文介绍了一个包含11,884张标注图像的模拟采血数据集，支持医疗培训自动化和人机交互研究。


<details>
  <summary>Details</summary>
Motivation: 为医疗培训自动化和人机交互研究提供高质量标注数据集，支持工具检测、流程分析等应用。

Method: 从高清视频中提取图像，使用SSIM过滤减少冗余，自动匿名化人脸，并为五个医学相关类别提供多边形标注。

Result: 创建了包含11,884张标注图像的数据集，分为训练、验证和测试子集，公开可用。

Conclusion: 该数据集通过提供标注图像和分区，旨在推动医疗培训自动化和人机交互研究，支持多种应用如工具检测、流程分析和教育系统开发。

Abstract: This data article presents a dataset of 11,884 labeled images documenting a simulated blood extraction (phlebotomy) procedure performed on a training arm. Images were extracted from high-definition videos recorded under controlled conditions and curated to reduce redundancy using Structural Similarity Index Measure (SSIM) filtering. An automated face-anonymization step was applied to all videos prior to frame selection. Each image contains polygon annotations for five medically relevant classes: syringe, rubber band, disinfectant wipe, gloves, and training arm. The annotations were exported in a segmentation format compatible with modern object detection frameworks (e.g., YOLOv8), ensuring broad usability. This dataset is partitioned into training (70%), validation (15%), and test (15%) subsets and is designed to advance research in medical training automation and human-object interaction. It enables multiple applications, including phlebotomy tool detection, procedural step recognition, workflow analysis, conformance checking, and the development of educational systems that provide structured feedback to medical trainees. The data and accompanying label files are publicly available on Zenodo.

</details>


### [79] [PIO-FVLM: Rethinking Training-Free Visual Token Reduction for VLM Acceleration from an Inference-Objective Perspective](https://arxiv.org/abs/2602.04657)
*Haokui Zhang,Congyang Ou,Dawei Yan,Peng Wang,Qingsen Yan,Ying Li,Rong Xiao,Chunhua Shen*

Main category: cs.CV

TL;DR: PIO-FVLM 通过基于推理目标的令牌压缩方法，显著提升视觉语言模型的推理效率，同时保持高性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法基于启发式规则（如视觉令牌间相似性或跨模态视觉-文本相似性）存在压缩性能和实际部署的局限性，因此提出从推理目标角度优化视觉令牌压缩。

Method: 通过基于推理目标的视角，将视觉令牌压缩转化为保留输出结果不变性，并利用层局部代理损失生成的令牌级梯度显著性对令牌进行重排序，再通过非极大值抑制（NMS）原则选择最有价值的令牌。

Result: 在 LLaVA-Next-7B 上，PIO-FVLM 仅保留 11.1% 的视觉令牌，但保持 97.2% 的原始性能，预填充速度提升 2.67 倍，推理速度提升 2.11 倍，FLOPs 降低 6.22 倍，KV Cache 开销减少 6.05 倍。

Conclusion: PIO-FVLM 是一种无需训练、兼容 FlashAttention 的视觉令牌压缩方法，能够显著加速推理速度并降低计算开销，同时保持高性能。

Abstract: Recently, reducing redundant visual tokens in vision-language models (VLMs) to accelerate VLM inference has emerged as a hot topic. However, most existing methods rely on heuristics constructed based on inter-visual-token similarity or cross-modal visual-text similarity, which gives rise to certain limitations in compression performance and practical deployment. In contrast, we propose PIO-FVLM from the perspective of inference objectives, which transforms visual token compression into preserving output result invariance and selects tokens primarily by their importance to this goal. Specially, vision tokens are reordered with the guidance of token-level gradient saliency generated by our designed layer-local proxy loss, a coarse constraint from the current layer to the final result. Then the most valuable vision tokens are selected following the non-maximum suppression (NMS) principle. The proposed PIO-FVLM is training-free and compatible with FlashAttention, friendly to practical application and deployment. It can be deployed independently as an encoder-free method, or combined with encoder compression approaches like VisionZip for use as an encoder-involved method. On LLaVA-Next-7B, PIO-FVLM retains just 11.1% of visual tokens but maintains 97.2% of the original performance, with a 2.67$\times$ prefill speedup, 2.11$\times$ inference speedup, 6.22$\times$ lower FLOPs, and 6.05$\times$ reduced KV Cache overhead. Our code is available at https://github.com/ocy1/PIO-FVLM.

</details>


### [80] [Annotation Free Spacecraft Detection and Segmentation using Vision Language Models](https://arxiv.org/abs/2602.04699)
*Samet Hicsonmez,Jose Sosa,Dan Pineau,Inder Pal Singh,Arunkumar Rathinam,Abd El Rahman Shabayek,Djamila Aouada*

Main category: cs.CV

TL;DR: 利用VLM自动生成伪标签并通过师生蒸馏框架训练模型，显著提升太空目标分割性能，无需人工标注。


<details>
  <summary>Details</summary>
Motivation: 太空领域中人工标注因低可见度、光照变化和目标与行星背景混合等问题而极具挑战性，亟需无需大量标注的方法。

Method: 利用预训练的VLM自动生成伪标签，并通过师生标签蒸馏框架训练轻量级模型。

Result: 在SPARK-2024、SPEED+和TANGO数据集上的分割任务中，平均精度（AP）提升了高达10个百分点。

Conclusion: 该研究通过结合视觉语言模型（VLMs）和师生标签蒸馏框架，提出了一种无需人工标注的太空目标检测与分割方法，显著提升了性能。

Abstract: Vision Language Models (VLMs) have demonstrated remarkable performance in open-world zero-shot visual recognition. However, their potential in space-related applications remains largely unexplored. In the space domain, accurate manual annotation is particularly challenging due to factors such as low visibility, illumination variations, and object blending with planetary backgrounds. Developing methods that can detect and segment spacecraft and orbital targets without requiring extensive manual labeling is therefore of critical importance. In this work, we propose an annotation-free detection and segmentation pipeline for space targets using VLMs. Our approach begins by automatically generating pseudo-labels for a small subset of unlabeled real data with a pre-trained VLM. These pseudo-labels are then leveraged in a teacher-student label distillation framework to train lightweight models. Despite the inherent noise in the pseudo-labels, the distillation process leads to substantial performance gains over direct zero-shot VLM inference. Experimental evaluations on the SPARK-2024, SPEED+, and TANGO datasets on segmentation tasks demonstrate consistent improvements in average precision (AP) by up to 10 points. Code and models are available at https://github.com/giddyyupp/annotation-free-spacecraft-segmentation.

</details>


### [81] [How to rewrite the stars: Mapping your orchard over time through constellations of fruits](https://arxiv.org/abs/2602.04722)
*Gonçalo P. Matos,Carlos Santiago,João P. Costeira,Ricardo L. Saldanha,Ernesto M. Morgado*

Main category: cs.CV

TL;DR: 论文提出了一种基于3D质心星座的方法，解决了跨视频匹配水果的难题，并支持果园自主导航。


<details>
  <summary>Details</summary>
Motivation: 传统人工测量水果生长的方法费时且不可扩展，现有计算机视觉方法在跨时间匹配同一水果方面存在不足。

Method: 基于3D质心星座的匹配方法，结合稀疏3D点云的描述符，用于跨视频匹配水果。

Result: 提出的方法成功实现了跨视频水果匹配，并能构建果园地图以支持自主导航和选择性采摘。

Conclusion: 该论文提出了一种基于3D质心星座的新方法，用于跨视频匹配水果，并引入了适用于稀疏3D点云的描述符。该方法不仅成功解决了水果生长跟踪问题，还为果园地图构建和自主导航提供了解决方案。

Abstract: Following crop growth through the vegetative cycle allows farmers to predict fruit setting and yield in early stages, but it is a laborious and non-scalable task if performed by a human who has to manually measure fruit sizes with a caliper or dendrometers. In recent years, computer vision has been used to automate several tasks in precision agriculture, such as detecting and counting fruits, and estimating their size. However, the fundamental problem of matching the exact same fruits from one video, collected on a given date, to the fruits visible in another video, collected on a later date, which is needed to track fruits' growth through time, remains to be solved. Few attempts were made, but they either assume that the camera always starts from the same known position and that there are sufficiently distinct features to match, or they used other sources of data like GPS. Here we propose a new paradigm to tackle this problem, based on constellations of 3D centroids, and introduce a descriptor for very sparse 3D point clouds that can be used to match fruits across videos. Matching constellations instead of individual fruits is key to deal with non-rigidity, occlusions and challenging imagery with few distinct visual features to track. The results show that the proposed method can be successfully used to match fruits across videos and through time, and also to build an orchard map and later use it to locate the camera pose in 6DoF, thus providing a method for autonomous navigation of robots in the orchard and for selective fruit picking, for example.

</details>


### [82] [Mitigating Long-Tail Bias via Prompt-Controlled Diffusion Augmentation](https://arxiv.org/abs/2602.04749)
*Buddhi Wijenayake,Nichula Wasalathilake,Roshan Godaliyadda,Vijitha Herath,Parakrama Ekanayake,Vishal M. Patel*

Main category: cs.CV

TL;DR: 提出可控扩散增强框架，通过合成数据改善遥感图像分割中的长尾问题，提升少数类别和城乡泛化性能。


<details>
  <summary>Details</summary>
Motivation: 解决遥感图像语义分割中因训练数据长尾像素不平衡和城乡域差异带来的挑战。

Method: 提出了一个两阶段框架：阶段A使用域感知的掩蔽比率条件离散扩散模型生成满足用户指定类别比率目标的布局；阶段B通过Stable Diffusion与ControlNet引导将布局转换为逼真的域一致图像。

Result: 混合合成数据与真实数据后，多个分割骨干网络均获得一致改进，少数类别和城乡泛化性能显著提升。

Conclusion: 通过可控扩散增强框架，显著改善了高分辨率遥感图像语义分割中的长尾像素不平衡问题，特别是在少数类别和城乡泛化方面。

Abstract: Semantic segmentation of high-resolution remote-sensing imagery is critical for urban mapping and land-cover monitoring, yet training data typically exhibits severe long-tailed pixel imbalance. In the dataset LoveDA, this challenge is compounded by an explicit Urban/Rural split with distinct appearance and inconsistent class-frequency statistics across domains. We present a prompt-controlled diffusion augmentation framework that synthesizes paired label--image samples with explicit control of both domain and semantic composition. Stage~A uses a domain-aware, masked ratio-conditioned discrete diffusion model to generate layouts that satisfy user-specified class-ratio targets while respecting learned co-occurrence structure. Stage~B translates layouts into photorealistic, domain-consistent images using Stable Diffusion with ControlNet guidance. Mixing the resulting ratio and domain-controlled synthetic pairs with real data yields consistent improvements across multiple segmentation backbones, with gains concentrated on minority classes and improved Urban and Rural generalization, demonstrating controllable augmentation as a practical mechanism to mitigate long-tail bias in remote-sensing segmentation. Source codes, pretrained models, and synthetic datasets are available at \href{https://github.com/Buddhi19/SyntheticGen.git}{Github}

</details>


### [83] [Light Forcing: Accelerating Autoregressive Video Diffusion via Sparse Attention](https://arxiv.org/abs/2602.04789)
*Chengtao Lv,Yumeng Shi,Yushi Huang,Ruihao Gong,Shen Ren,Wenya Wang*

Main category: cs.CV

TL;DR: Light Forcing 是针对自回归视频生成模型的稀疏注意力解决方案，通过分块感知和层次化稀疏注意力提升效率，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有稀疏注意力解决方案在自回归模型中表现不佳，主要因孤立处理分块生成和未充分利用历史上下文。

Method: 提出 Light Forcing，结合 Chunk-Aware Growth 机制和 Hierarchical Sparse Attention，通过渐进式稀疏分配和两级掩码选择策略优化注意力计算。

Result: 实验表明，Light Forcing 在质量（如 VBench 得分 84.5）和效率（端到端加速 1.2∼1.3 倍）上均优于现有方法，结合 FP8 和 LightVAE 后加速达 2.3 倍。

Conclusion: Light Forcing 通过创新的稀疏注意力机制（Chunk-Aware Growth 和 Hierarchical Sparse Attention）显著提升了自回归视频生成模型的效率和性能，同时结合 FP8 量化和 LightVAE 进一步实现了加速。

Abstract: Advanced autoregressive (AR) video generation models have improved visual fidelity and interactivity, but the quadratic complexity of attention remains a primary bottleneck for efficient deployment. While existing sparse attention solutions have shown promise on bidirectional models, we identify that applying these solutions to AR models leads to considerable performance degradation for two reasons: isolated consideration of chunk generation and insufficient utilization of past informative context. Motivated by these observations, we propose \textsc{Light Forcing}, the \textit{first} sparse attention solution tailored for AR video generation models. It incorporates a \textit{Chunk-Aware Growth} mechanism to quantitatively estimate the contribution of each chunk, which determines their sparsity allocation. This progressive sparsity increase strategy enables the current chunk to inherit prior knowledge in earlier chunks during generation. Additionally, we introduce a \textit{Hierarchical Sparse Attention} to capture informative historical and local context in a coarse-to-fine manner. Such two-level mask selection strategy (\ie, frame and block level) can adaptively handle diverse attention patterns. Extensive experiments demonstrate that our method outperforms existing sparse attention in quality (\eg, 84.5 on VBench) and efficiency (\eg, $1.2{\sim}1.3\times$ end-to-end speedup). Combined with FP8 quantization and LightVAE, \textsc{Light Forcing} further achieves a $2.3\times$ speedup and 19.7\,FPS on an RTX~5090 GPU. Code will be released at \href{https://github.com/chengtao-lv/LightForcing}{https://github.com/chengtao-lv/LightForcing}.

</details>


### [84] [VISTA-Bench: Do Vision-Language Models Really Understand Visualized Text as Well as Pure Text?](https://arxiv.org/abs/2602.04802)
*Qing'an Liu,Juntong Feng,Yuhao Wang,Xinzhe Han,Yujie Cheng,Yue Zhu,Haiwen Diao,Yunzhi Zhuge,Huchuan Lu*

Main category: cs.CV

TL;DR: VISTA-Bench 基准测试揭示了视觉语言模型在处理可视化文本时的模态差距，为跨模态统一语言表示提供了评估框架。


<details>
  <summary>Details</summary>
Motivation: 现实场景中语言常以可视化文本形式嵌入图像，而现有基准测试主要关注纯文本查询，因此需要评估当前视觉语言模型在此类输入请求上的表现。

Method: 通过构建 VISTA-Bench 基准测试，对比纯文本和可视化文本问题在受控渲染条件下的表现，评估了超过 20 种代表性视觉语言模型。

Result: 研究发现，模型在纯文本查询上表现良好，但在语义内容以可视化文本呈现时性能显著下降，且感知难度增加会进一步放大这一差距。

Conclusion: VISTA-Bench 提供了一个系统的评估框架，揭示了当前视觉语言模型在处理可视化文本时的显著模态差距，并指导未来在跨模态统一语言表示方面的进展。

Abstract: Vision-Language Models (VLMs) have achieved impressive performance in cross-modal understanding across textual and visual inputs, yet existing benchmarks predominantly focus on pure-text queries. In real-world scenarios, language also frequently appears as visualized text embedded in images, raising the question of whether current VLMs handle such input requests comparably. We introduce VISTA-Bench, a systematic benchmark from multimodal perception, reasoning, to unimodal understanding domains. It evaluates visualized text understanding by contrasting pure-text and visualized-text questions under controlled rendering conditions. Extensive evaluation of over 20 representative VLMs reveals a pronounced modality gap: models that perform well on pure-text queries often degrade substantially when equivalent semantic content is presented as visualized text. This gap is further amplified by increased perceptual difficulty, highlighting sensitivity to rendering variations despite unchanged semantics. Overall, VISTA-Bench provides a principled evaluation framework to diagnose this limitation and to guide progress toward more unified language representations across tokenized text and pixels. The source dataset is available at https://github.com/QingAnLiu/VISTA-Bench.

</details>


### [85] [XtraLight-MedMamba for Classification of Neoplastic Tubular Adenomas](https://arxiv.org/abs/2602.04819)
*Aqsa Sultana,Rayan Afsar,Ahmed Rahu,Surendra P. Singh,Brian Shula,Brandon Combs,Derrick Forchetti,Vijayan K. Asari*

Main category: cs.CV

TL;DR: XtraLight-MedMamba：超轻量级深度学习框架，高效分类低级别管状腺瘤，准确率97.18%，参数极少，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决低级别异型增生评估的主观性问题，利用数字病理和深度学习识别人眼难以察觉的恶性进展形态模式。

Method: 结合ConvNext浅层特征提取器和并行视觉Mamba，采用SCAB模块增强多尺度特征提取，FNOClassifier减少参数并提升泛化能力。

Result: 在低级别管状腺瘤数据集上，模型准确率达97.18%，F1分数0.9767，仅使用约32,000参数，优于复杂模型。

Conclusion: XtraLight-MedMamba是一种超轻量级深度学习框架，能够高效分类低级别管状腺瘤，显著优于现有方法，为结直肠癌风险分层提供了新工具。

Abstract: Accurate risk stratification of precancerous polyps during routine colonoscopy screenings is essential for lowering the risk of developing colorectal cancer (CRC). However, assessment of low-grade dysplasia remains limited by subjective histopathologic interpretation. Advancements in digital pathology and deep learning provide new opportunities to identify subtle and fine morphologic patterns associated with malignant progression that may be imperceptible to the human eye. In this work, we propose XtraLight-MedMamba, an ultra-lightweight state-space-based deep learning framework for classifying neoplastic tubular adenomas from whole-slide images (WSIs). The architecture is a blend of ConvNext based shallow feature extractor with parallel vision mamba to efficiently model both long- and short-range dependencies and image generalization. An integration of Spatial and Channel Attention Bridge (SCAB) module enhances multiscale feature extraction, while Fixed Non-Negative Orthogonal Classifier (FNOClassifier) enables substantial parameter reduction and improved generalization. The model was evaluated on a curated dataset acquired from patients with low-grade tubular adenomas, stratified into case and control cohorts based on subsequent CRC development. XtraLight-MedMamba achieved an accuracy of 97.18% and an F1-score of 0.9767 using approximately 32,000 parameters, outperforming transformer-based and conventional Mamba architectures with significantly higher model complexity.

</details>


### [86] [LitS: A novel Neighborhood Descriptor for Point Clouds](https://arxiv.org/abs/2602.04838)
*Jonatan B. Bastos,Francisco F. Rivera,Oscar G. Lorenzo,David L. Vilariño,José C. Cabaleiro,Alberto M. Esmorís,Tomás F. Pena*

Main category: cs.CV

TL;DR: LitS是一种新型的2D和3D点云邻域描述符，通过单位圆上的分段常数函数捕捉局部几何信息，适应性强且对噪声和密度变化鲁棒。


<details>
  <summary>Details</summary>
Motivation: 随着3D扫描技术的进步，点云已成为表示3D空间数据的基础，应用涵盖多个科学和技术领域。对这些数据的实际分析依赖于可用的邻域描述符来准确表征点云的局部几何特征。

Method: 本文介绍了LitS，一种用于2D和3D点云的新型邻域描述符。LitS是单位圆上的分段常数函数，允许点跟踪其周围环境。LitS的每个元素代表相对于局部参考系的方向。一旦构建完成，评估LitS在给定方向上的值可以提供关于以该方向为中心的锥形区域内邻居数量的信息。

Result: LitS提供了关于点的局部邻域的丰富信息，可以通过分析LitS在邻近点之间的变化来获得全局结构理解。LitS有两种版本（'常规'和'累积'）和两个参数，使其能够适应各种上下文和点云类型。

Conclusion: LitS是一种多功能邻域描述符，能够捕捉局部点排列的细微差别，并对常见的点云数据问题（如可变密度和噪声）具有鲁棒性。

Abstract: With the advancement of 3D scanning technologies, point clouds have become fundamental for representing 3D spatial data, with applications that span across various scientific and technological fields. Practical analysis of this data depends crucially on available neighborhood descriptors to accurately characterize the local geometries of the point cloud. This paper introduces LitS, a novel neighborhood descriptor for 2D and 3D point clouds. LitS are piecewise constant functions on the unit circle that allow points to keep track of their surroundings. Each element in LitS' domain represents a direction with respect to a local reference system. Once constructed, evaluating LitS at any given direction gives us information about the number of neighbors in a cone-like region centered around that same direction. Thus, LitS conveys a lot of information about the local neighborhood of a point, which can be leveraged to gain global structural understanding by analyzing how LitS changes between close points. In addition, LitS comes in two versions ('regular' and 'cumulative') and has two parameters, allowing them to adapt to various contexts and types of point clouds. Overall, they are a versatile neighborhood descriptor, capable of capturing the nuances of local point arrangements and resilient to common point cloud data issues such as variable density and noise.

</details>


### [87] [When LLaVA Meets Objects: Token Composition for Vision-Language-Models](https://arxiv.org/abs/2602.04864)
*Soumya Jahagirdar,Walid Bousselham,Anna Kukleva,Hilde Kuehne*

Main category: cs.CV

TL;DR: Mask-LLaVA通过多层次视觉特征组合，减少推理时的视觉token数量，保持高性能，无需重新训练。


<details>
  <summary>Details</summary>
Motivation: 当前自回归视觉语言模型（VLMs）通常依赖大量视觉token表示图像，导致推理时计算需求高，需要一种更高效的视觉表示方法。

Method: 提出Mask-LLaVA框架，结合基于掩码的对象表示、全局token和局部patch token，训练时使用所有token，测试时可灵活减少对象token数量。

Result: 在标准基准测试中，Mask-LLaVA表现与当前token高效方法竞争，且仅使用一小部分视觉token即可达到与原始LLaVA基线相当的性能。

Conclusion: Mask-LLaVA框架通过结合多层次的视觉特征，实现了在少量视觉token下的高效学习，并支持在测试时动态选择token以保持良好的性能。

Abstract: Current autoregressive Vision Language Models (VLMs) usually rely on a large number of visual tokens to represent images, resulting in a need for more compute especially at inference time. To address this problem, we propose Mask-LLaVA, a framework that leverages different levels of visual features to create a compact yet information-rich visual representation for autoregressive VLMs. Namely, we combine mask-based object representations together with global tokens and local patch tokens. While all tokens are used during training, it shows that the resulting model can flexibly drop especially the number of mask-based object-tokens at test time, allowing to adapt the number of tokens during inference without the need to retrain the model and without a significant drop in performance. We evaluate the proposed approach on a suite of standard benchmarks showing results competitive to current token efficient methods and comparable to the original LLaVA baseline using only a fraction of visual tokens. Our analysis demonstrates that combining multi-level features enables efficient learning with fewer tokens while allowing dynamic token selection at test time for good performance.

</details>


### [88] [Laminating Representation Autoencoders for Efficient Diffusion](https://arxiv.org/abs/2602.04873)
*Ramón Calvo-González,François Fleuret*

Main category: cs.CV

TL;DR: FlatDINO通过压缩DINOv2特征为低维序列，显著提升扩散模型效率，同时保持生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有的扩散模型在DINOv2等编码器的密集补丁特征上运行时存在冗余，导致计算成本高昂。

Method: 提出FlatDINO，一种变分自编码器，将DINOv2的密集补丁网格压缩为一维序列（32个连续令牌），实现序列长度8倍减少和总维度48倍压缩。

Result: 在ImageNet 256x256上，基于FlatDINO潜在空间的DiT-XL模型实现了1.80的gFID，同时每次前向传递的FLOPs减少8倍，每训练步骤的FLOPs减少4.5倍。

Conclusion: FlatDINO通过将DINOv2的密集补丁特征压缩为一维连续令牌序列，显著降低了扩散模型的训练和推理成本，同时保持了高质量的图像生成能力。

Abstract: Recent work has shown that diffusion models can generate high-quality images by operating directly on SSL patch features rather than pixel-space latents. However, the dense patch grids from encoders like DINOv2 contain significant redundancy, making diffusion needlessly expensive. We introduce FlatDINO, a variational autoencoder that compresses this representation into a one-dimensional sequence of just 32 continuous tokens -an 8x reduction in sequence length and 48x compression in total dimensionality. On ImageNet 256x256, a DiT-XL trained on FlatDINO latents achieves a gFID of 1.80 with classifier-free guidance while requiring 8x fewer FLOPs per forward pass and up to 4.5x fewer FLOPs per training step compared to diffusion on uncompressed DINOv2 features. These are preliminary results and this work is in progress.

</details>


### [89] [PerpetualWonder: Long-Horizon Action-Conditioned 4D Scene Generation](https://arxiv.org/abs/2602.04876)
*Jiahao Zhan,Zizhang Li,Hong-Xing Yu,Jiajun Wu*

Main category: cs.CV

TL;DR: PerpetualWonder是一种混合生成模拟器，通过闭环系统和统一表示，实现了从单张图像生成长期动作条件下的4D场景。


<details>
  <summary>Details</summary>
Motivation: 当前方法在生成长期动作条件下的4D场景时，由于物理状态与视觉表示解耦，无法通过生成式细化更新后续交互的底层物理状态。

Method: PerpetualWonder采用了一种新颖的统一表示方法，建立了物理状态与视觉基元之间的双向链接，并引入了从多视角收集监督的鲁棒更新机制。

Result: 实验表明，PerpetualWonder能够从单张图像成功模拟复杂、多步骤的长期动作交互，保持物理合理性和视觉一致性。

Conclusion: PerpetualWonder通过引入首个真正的闭环系统，成功解决了现有工作中物理状态与视觉表示解耦的问题，实现了从单张图像生成长期动作条件下的4D场景。

Abstract: We introduce PerpetualWonder, a hybrid generative simulator that enables long-horizon, action-conditioned 4D scene generation from a single image. Current works fail at this task because their physical state is decoupled from their visual representation, which prevents generative refinements to update the underlying physics for subsequent interactions. PerpetualWonder solves this by introducing the first true closed-loop system. It features a novel unified representation that creates a bidirectional link between the physical state and visual primitives, allowing generative refinements to correct both the dynamics and appearance. It also introduces a robust update mechanism that gathers supervision from multiple viewpoints to resolve optimization ambiguity. Experiments demonstrate that from a single image, PerpetualWonder can successfully simulate complex, multi-step interactions from long-horizon actions, maintaining physical plausibility and visual consistency.

</details>


### [90] [CoWTracker: Tracking by Warping instead of Correlation](https://arxiv.org/abs/2602.04877)
*Zihang Lai,Eldar Insafutdinov,Edgar Sucar,Andrea Vedaldi*

Main category: cs.CV

TL;DR: 提出了一种基于扭曲的密集点跟踪方法，无需成本体积，通过变压器架构实现高效长程对应，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有跟踪器依赖成本体积匹配特征，导致空间分辨率的二次复杂度，限制了可扩展性和效率。

Method: 提出了一种新颖的密集点跟踪方法，利用扭曲代替成本体积，结合变压器架构进行联合时空推理。

Result: 在标准密集点跟踪基准（如TAP-Vid-DAVIS、TAP-Vid-Kinetics和Robo-TAP）上达到最先进性能，并在光流估计（如Sintel、KITTI和Spring基准）上有时超越专用方法。

Conclusion: 基于扭曲的架构可以统一密集点跟踪和光流估计。

Abstract: Dense point tracking is a fundamental problem in computer vision, with applications ranging from video analysis to robotic manipulation. State-of-the-art trackers typically rely on cost volumes to match features across frames, but this approach incurs quadratic complexity in spatial resolution, limiting scalability and efficiency. In this paper, we propose \method, a novel dense point tracker that eschews cost volumes in favor of warping. Inspired by recent advances in optical flow, our approach iteratively refines track estimates by warping features from the target frame to the query frame based on the current estimate. Combined with a transformer architecture that performs joint spatiotemporal reasoning across all tracks, our design establishes long-range correspondences without computing feature correlations. Our model is simple and achieves state-of-the-art performance on standard dense point tracking benchmarks, including TAP-Vid-DAVIS, TAP-Vid-Kinetics, and Robo-TAP. Remarkably, the model also excels at optical flow, sometimes outperforming specialized methods on the Sintel, KITTI, and Spring benchmarks. These results suggest that warping-based architectures can unify dense point tracking and optical flow estimation.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [91] [Knowledge Model Prompting Increases LLM Performance on Planning Tasks](https://arxiv.org/abs/2602.03900)
*Erik Goh,John Kos,Ashok Goel*

Main category: cs.AI

TL;DR: TMK框架通过结构化提示显著提升LLM在复杂规划任务中的表现，尤其在符号任务中效果显著。


<details>
  <summary>Details</summary>
Motivation: 探讨TMK框架是否能弥补LLM在推理能力上的不足，尤其是在任务分解和因果、目的论及层次化推理结构方面。

Method: 通过PlanBench基准测试中的Blocksworld领域，评估TMK结构化提示对LLM推理和规划能力的影响。

Result: TMK提示使推理模型在不透明符号任务（如PlanBench中的随机Blocksworld版本）中的准确率从31.5%提升至97.3%。

Conclusion: TMK框架不仅能作为上下文，还能引导推理模型从默认的语言模式转向正式的代码执行路径，显著提升了LLM在符号任务中的表现。

Abstract: Large Language Models (LLM) can struggle with reasoning ability and planning tasks. Many prompting techniques have been developed to assist with LLM reasoning, notably Chain-of-Thought (CoT); however, these techniques, too, have come under scrutiny as LLMs' ability to reason at all has come into question. Borrowing from the domain of cognitive and educational science, this paper investigates whether the Task-Method-Knowledge (TMK) framework can improve LLM reasoning capabilities beyond its previously demonstrated success in educational applications. The TMK framework's unique ability to capture causal, teleological, and hierarchical reasoning structures, combined with its explicit task decomposition mechanisms, makes it particularly well-suited for addressing language model reasoning deficiencies, and unlike other hierarchical frameworks such as HTN and BDI, TMK provides explicit representations of not just what to do and how to do it, but also why actions are taken. The study evaluates TMK by experimenting on the PlanBench benchmark, focusing on the Blocksworld domain to test for reasoning and planning capabilities, examining whether TMK-structured prompting can help language models better decompose complex planning problems into manageable sub-tasks. Results also highlight significant performance inversion in reasoning models. TMK prompting enables the reasoning model to achieve up to an accuracy of 97.3\% on opaque, symbolic tasks (Random versions of Blocksworld in PlanBench) where it previously failed (31.5\%), suggesting the potential to bridge the gap between semantic approximation and symbolic manipulation. Our findings suggest that TMK functions not merely as context, but also as a mechanism that steers reasoning models away from their default linguistic modes to engage formal, code-execution pathways in the context of the experiments.

</details>


### [92] [Enhancing Mathematical Problem Solving in LLMs through Execution-Driven Reasoning Augmentation](https://arxiv.org/abs/2602.03950)
*Aditya Basarkar,Benyamin Tabarsi,Tiffany Barnes,Dongkuan,Xu*

Main category: cs.AI

TL;DR: IIPC是一种迭代优化程序化推理链的方法，显著提升了数学推理能力，超越了现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有代理系统在数学推理中存在无法修正早期步骤或依赖不可靠的自评估问题，程序化上下文可能干扰语言模型并降低准确性。

Method: 提出了迭代改进的程序构建（IIPC）方法，结合执行反馈和基础LLM的思维链能力，以保持高层次上下文焦点。

Result: IIPC在多个基础LLM上的大多数推理基准测试中超越了竞争方法。

Conclusion: IIPC方法通过迭代优化程序化推理链并结合执行反馈，显著提升了数学推理能力，并在多个基准测试中超越了现有方法。

Abstract: Mathematical problem solving is a fundamental benchmark for assessing the reasoning capabilities of artificial intelligence and a gateway to applications in education, science, and engineering where reliable symbolic reasoning is essential. Although recent advances in multi-agent LLM-based systems have enhanced their mathematical reasoning capabilities, they still lack a reliably revisable representation of the reasoning process. Existing agents either operate in rigid sequential pipelines that cannot correct earlier steps or rely on heuristic self-evaluation that can fail to identify and fix errors. In addition, programmatic context can distract language models and degrade accuracy. To address these gaps, we introduce Iteratively Improved Program Construction (IIPC), a reasoning method that iteratively refines programmatic reasoning chains and combines execution feedback with the native Chain-of-thought abilities of the base LLM to maintain high-level contextual focus. IIPC surpasses competing approaches in the majority of reasoning benchmarks on multiple base LLMs. All code and implementations are released as open source.

</details>


### [93] [AgentArk: Distilling Multi-Agent Intelligence into a Single LLM Agent](https://arxiv.org/abs/2602.03955)
*Yinyi Luo,Yiqiao Jin,Weichen Yu,Mengqi Zhang,Srijan Kumar,Xiaoxiao Li,Weijie Xu,Xin Chen,Jindong Wang*

Main category: cs.AI

TL;DR: AgentArk框架将多智能体系统的动态蒸馏到单一模型中，实现了高效推理和鲁棒性能。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型多智能体系统在实际部署中因高计算成本和错误传播而受限的问题。

Method: 研究了三种层次蒸馏策略：推理增强微调、基于轨迹的增强和过程感知蒸馏。

Result: 蒸馏后的模型在保持单一代理效率的同时，展现出多代理的强推理和自我纠正性能，并在多样化推理任务中表现出增强的鲁棒性和泛化能力。

Conclusion: AgentArk框架通过将多智能体动态蒸馏到单一模型的权重中，实现了高效且鲁棒的推理性能，为未来高效多智能体系统的研究提供了方向。

Abstract: While large language model (LLM) multi-agent systems achieve superior reasoning performance through iterative debate, practical deployment is limited by their high computational cost and error propagation. This paper proposes AgentArk, a novel framework to distill multi-agent dynamics into the weights of a single model, effectively transforming explicit test-time interactions into implicit model capabilities. This equips a single agent with the intelligence of multi-agent systems while remaining computationally efficient. Specifically, we investigate three hierarchical distillation strategies across various models, tasks, scaling, and scenarios: reasoning-enhanced fine-tuning; trajectory-based augmentation; and process-aware distillation. By shifting the burden of computation from inference to training, the distilled models preserve the efficiency of one agent while exhibiting strong reasoning and self-correction performance of multiple agents. They further demonstrate enhanced robustness and generalization across diverse reasoning tasks. We hope this work can shed light on future research on efficient and robust multi-agent development. Our code is at https://github.com/AIFrontierLab/AgentArk.

</details>


### [94] [Active Epistemic Control for Query-Efficient Verified Planning](https://arxiv.org/abs/2602.03974)
*Shuhui Qu*

Main category: cs.AI

TL;DR: AEC是一种结合模型预测和可行性检查的规划方法，在部分可观测环境中高效且可靠。


<details>
  <summary>Details</summary>
Motivation: 在部分可观测环境中，任务关键前提条件（如物体位置或容器状态）可能未知，而通过交互获取这些信息成本高昂。学习的世界模型可以预测缺失事实，但预测错误可能导致不可行的承诺。

Method: AEC采用分层设计，严格区分用于承诺的“grounded fact store”和用于修剪候选计划的“belief store”。它通过查询环境或模拟谓词来管理不确定性，并通过SQ-BCP拉回式兼容性检查确保最终承诺的可行性。

Result: 实验表明，AEC在ALFWorld和ScienceWorld中比强大的LLM-agent基线方法取得了竞争性的成功率，且重规划次数更少。

Conclusion: AEC（Active Epistemic Control）通过结合基于模型的信念管理和分类可行性检查，在部分可观测环境中实现了高效的规划，减少了重规划次数，并在ALFWorld和ScienceWorld中表现出色。

Abstract: Planning in interactive environments is challenging under partial observability: task-critical preconditions (e.g., object locations or container states) may be unknown at decision time, yet grounding them through interaction is costly. Learned world models can cheaply predict missing facts, but prediction errors can silently induce infeasible commitments. We present \textbf{Active Epistemic Control (AEC)}, an epistemic-categorical planning layer that integrates model-based belief management with categorical feasibility checks. AEC maintains a strict separation between a \emph{grounded fact store} used for commitment and a \emph{belief store} used only for pruning candidate plans. At each step, it either queries the environment to ground an unresolved predicate when uncertainty is high or predictions are ambiguous, or simulates the predicate to filter hypotheses when confidence is sufficient. Final commitment is gated by grounded precondition coverage and an SQ-BCP pullback-style compatibility check, so simulated beliefs affect efficiency but cannot directly certify feasibility. Experiments on ALFWorld and ScienceWorld show that AEC achieves competitive success with fewer replanning rounds than strong LLM-agent baselines.

</details>


### [95] [Adaptive Test-Time Compute Allocation via Learned Heuristics over Categorical Structure](https://arxiv.org/abs/2602.03975)
*Shuhui Qu*

Main category: cs.AI

TL;DR: 提出一种状态级选择性验证框架，优化验证调用分配，在MATH基准上实现更高准确性并减少44%验证开销。


<details>
  <summary>Details</summary>
Motivation: 研究验证成本受限设置下的推理问题，解决现有推理系统中验证调用在冗余或前景不佳的中间假设上浪费的问题。

Method: 该方法包括（i）确定性可行性门控，（ii）基于学习的状态距离和残差评分的预验证排名，（iii）基于局部不确定性的自适应验证调用分配。

Result: 在MATH基准测试中，该方法比best-of-N、多数投票和束搜索实现了更高的准确性，同时减少了44%的验证调用。

Conclusion: 在验证成本受限的设置下，提出的状态级选择性验证框架通过结合确定性可行性门控、预验证排名和自适应验证调用分配，显著提高了验证效率，在MATH基准测试中实现了比现有方法更高的准确性，同时减少了44%的验证调用。

Abstract: Test-time computation has become a primary driver of progress in large language model (LLM) reasoning, but it is increasingly bottlenecked by expensive verification. In many reasoning systems, a large fraction of verifier calls are spent on redundant or unpromising intermediate hypotheses. We study reasoning under a \emph{verification-cost-limited} setting and ask how verification effort should be allocated across intermediate states. We propose a state-level selective verification framework that combines (i) deterministic feasibility gating over a structured move interface, (ii) pre-verification ranking using a hybrid of learned state-distance and residual scoring, and (iii) adaptive allocation of verifier calls based on local uncertainty. Unlike solution-level best-of-$N$ or uniform intermediate verification, our method distributes verification where it is most informative. On the \textsc{MATH} benchmark, our approach achieves higher accuracy than best-of-$N$, majority voting, and beam search while using 44\% fewer verifier calls.

</details>


### [96] [Monitorability as a Free Gift: How RLVR Spontaneously Aligns Reasoning](https://arxiv.org/abs/2602.03978)
*Zidi Xiong,Shan Chen,Himabindu Lakkaraju*

Main category: cs.AI

TL;DR: 研究显示，监控能力的提升依赖于数据多样性，且与模型能力无关，主要通过熵减和提示关注实现。


<details>
  <summary>Details</summary>
Motivation: 随着大型推理模型（LRMs）的部署增多，审计其思维链（CoT）的安全性变得至关重要。

Method: 通过系统性评估不同模型家族和训练领域，结合机制分析，研究了监控能力的动态变化。

Result: 监控能力的提升主要归因于响应分布的锐化（熵减）和对提示的更多关注，而非对推理痕迹的更强因果依赖。

Conclusion: 研究发现，监控能力的提升并非普遍现象，而是高度依赖于数据多样性及指令遵循数据。监控能力与模型能力正交，推理性能的提升并不一定带来透明度的增加。

Abstract: As Large Reasoning Models (LRMs) are increasingly deployed, auditing their chain-of-thought (CoT) traces for safety becomes critical. Recent work has reported that monitorability--the degree to which CoT faithfully and informatively reflects internal computation--can appear as a "free gift" during the early stages of Reinforcement Learning with Verifiable Rewards (RLVR). We make this observation concrete through a systematic evaluation across model families and training domains. Our results show that this effect is not universal: monitorability improvements are strongly data-dependent. In particular, we demonstrate the critical role of data diversity and instruction-following data during RLVR training. We further show that monitorability is orthogonal to capability--improvements in reasoning performance do not imply increased transparency. Through mechanistic analysis, we attribute monitorability gains primarily to response distribution sharpening (entropy reduction) and increased attention to the prompt, rather than stronger causal reliance on reasoning traces. We also reveal how monitorability dynamics vary with controlled training and evaluation difficulty. Together, these findings provide a holistic view of how monitorability emerges under RLVR, clarifying when gains are likely to occur and when they are not.

</details>


### [97] [When AI Persuades: Adversarial Explanation Attacks on Human Trust in AI-Assisted Decision Making](https://arxiv.org/abs/2602.04003)
*Shutong Fan,Lan Zhang,Xiaoyong Yuan*

Main category: cs.AI

TL;DR: 对抗性解释攻击（AEAs）通过操纵LLM解释框架影响用户信任，实验显示用户难以区分对抗性与良性解释，专家式沟通风格风险最高。


<details>
  <summary>Details</summary>
Motivation: 现代AI系统越来越多地嵌入人类决策循环，而LLM生成的流畅解释可能成为攻击者操纵用户信任的新途径，需系统性研究其安全威胁。

Method: 通过控制实验（n = 205），系统性地操纵解释框架的四个维度（推理模式、证据类型、沟通风格和呈现格式），并量化信任校准差距。

Result: 用户对对抗性和良性解释的信任几乎相同，对抗性解释在错误输出下仍能保留大部分信任。最脆弱场景为专家式沟通风格（权威证据、中性语气、领域适配推理），且任务难度高、领域事实驱动或用户教育程度低时风险最大。

Conclusion: 研究发现，对抗性解释攻击（AEAs）能够通过操纵LLM生成的解释框架，显著影响用户对错误AI输出的信任程度，尤其是在专家式沟通风格下。这揭示了AI与用户之间认知通道的安全威胁。

Abstract: Most adversarial threats in artificial intelligence target the computational behavior of models rather than the humans who rely on them. Yet modern AI systems increasingly operate within human decision loops, where users interpret and act on model recommendations. Large Language Models generate fluent natural-language explanations that shape how users perceive and trust AI outputs, revealing a new attack surface at the cognitive layer: the communication channel between AI and its users. We introduce adversarial explanation attacks (AEAs), where an attacker manipulates the framing of LLM-generated explanations to modulate human trust in incorrect outputs. We formalize this behavioral threat through the trust miscalibration gap, a metric that captures the difference in human trust between correct and incorrect outputs under adversarial explanations. By incorporating this gap, AEAs explore the daunting threats in which persuasive explanations reinforce users' trust in incorrect predictions. To characterize this threat, we conducted a controlled experiment (n = 205), systematically varying four dimensions of explanation framing: reasoning mode, evidence type, communication style, and presentation format. Our findings show that users report nearly identical trust for adversarial and benign explanations, with adversarial explanations preserving the vast majority of benign trust despite being incorrect. The most vulnerable cases arise when AEAs closely resemble expert communication, combining authoritative evidence, neutral tone, and domain-appropriate reasoning. Vulnerability is highest on hard tasks, in fact-driven domains, and among participants who are less formally educated, younger, or highly trusting of AI. This is the first systematic security study that treats explanations as an adversarial cognitive channel and quantifies their impact on human trust in AI-assisted decision making.

</details>


### [98] [Axiomatic Foundations of Counterfactual Explanations](https://arxiv.org/abs/2602.04028)
*Leila Amgoud,Martin Cooper*

Main category: cs.AI

TL;DR: 本文填补了反事实解释器研究的空白，提出了一个公理框架，揭示了五种不同类型的反事实解释，并分析了计算复杂性。


<details>
  <summary>Details</summary>
Motivation: 解释自主和智能系统的决策对提高信任至关重要。现有解释器大多局限于单一类型的反事实和局部解释，缺乏对替代反事实类型和全局反事实的系统研究。

Method: 引入一个公理框架，基于一组理想属性，证明不可能定理，并建立表示定理，将特定公理子集与解释器家族对应。

Result: 提出了五种不同类型的反事实解释，包括局部和全局解释，并将现有解释器纳入分类体系，形式化描述其行为并分析计算复杂性。

Conclusion: 本文通过引入一个基于一组理想属性的公理框架，填补了现有反事实解释器研究的两个空白。证明了不可能定理，并完全描述了所有兼容的集合。表示定理建立了五个特定公理子集与满足它们的解释器家族之间的一一对应关系，揭示了五种根本不同类型的反事实解释。

Abstract: Explaining autonomous and intelligent systems is critical in order to improve trust in their decisions. Counterfactuals have emerged as one of the most compelling forms of explanation. They address ``why not'' questions by revealing how decisions could be altered. Despite the growing literature, most existing explainers focus on a single type of counterfactual and are restricted to local explanations, focusing on individual instances. There has been no systematic study of alternative counterfactual types, nor of global counterfactuals that shed light on a system's overall reasoning process.
  This paper addresses the two gaps by introducing an axiomatic framework built on a set of desirable properties for counterfactual explainers. It proves impossibility theorems showing that no single explainer can satisfy certain axiom combinations simultaneously, and fully characterizes all compatible sets. Representation theorems then establish five one-to-one correspondences between specific subsets of axioms and the families of explainers that satisfy them. Each family gives rise to a distinct type of counterfactual explanation, uncovering five fundamentally different types of counterfactuals. Some of these correspond to local explanations, while others capture global explanations. Finally, the framework situates existing explainers within this taxonomy, formally characterizes their behavior, and analyzes the computational complexity of generating such explanations.

</details>


### [99] [Scaling In-Context Online Learning Capability of LLMs via Cross-Episode Meta-RL](https://arxiv.org/abs/2602.04089)
*Xiaofeng Lin,Sirou Zhu,Yilei Chen,Mingyu Chen,Hejian Sang,Ioannis Paschalidis,Zhipeng Wang,Aldo Pacchiano,Xuezhou Zhang*

Main category: cs.AI

TL;DR: ORBIT框架通过元强化学习训练，提升LLMs在在线决策任务中的表现，Qwen3-14B模型性能媲美GPT-5.2。


<details>
  <summary>Details</summary>
Motivation: 现有LLMs在需要实时交互和延迟反馈的在线决策任务中表现不佳，缺乏可靠利用上下文交互经验的能力。

Method: 引入ORBIT框架，一个多任务、多回合的元强化学习训练方法，用于训练LLMs从上下文中学习交互经验。

Result: 经过元训练后，开源模型Qwen3-14B在未见环境中表现出显著的在线学习能力提升，性能匹配GPT-5.2，并大幅超越标准RL微调。

Conclusion: ORBIT框架通过多任务、多回合的元强化学习训练，显著提升了LLMs在未见环境中的在线学习能力，匹配甚至超越了现有先进模型的性能。

Abstract: Large language models (LLMs) achieve strong performance when all task-relevant information is available upfront, as in static prediction and instruction-following problems. However, many real-world decision-making tasks are inherently online: crucial information must be acquired through interaction, feedback is delayed, and effective behavior requires balancing information collection and exploitation over time. While in-context learning enables adaptation without weight updates, existing LLMs often struggle to reliably leverage in-context interaction experience in such settings. In this work, we show that this limitation can be addressed through training. We introduce ORBIT, a multi-task, multi-episode meta-reinforcement learning framework that trains LLMs to learn from interaction in context. After meta-training, a relatively small open-source model (Qwen3-14B) demonstrates substantially improved in-context online learning on entirely unseen environments, matching the performance of GPT-5.2 and outperforming standard RL fine-tuning by a large margin. Scaling experiments further reveal consistent gains with model size, suggesting significant headroom for learn-at-inference-time decision-making agents. Code reproducing the results in the paper can be found at https://github.com/XiaofengLin7/ORBIT.

</details>


### [100] [Interfaze: The Future of AI is built on Task-Specific Small Models](https://arxiv.org/abs/2602.04101)
*Harsha Vardhan Khurdula,Vineet Agarwal,Yoeven D Khemlani*

Main category: cs.AI

TL;DR: Interfaze通过模块化设计（小型模型+工具栈+上下文蒸馏）实现高效多模态任务处理，减少对大型LLM的依赖，并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 传统LLM应用依赖单一大型模型，计算成本高且效率低。Interfaze旨在通过模块化设计，将任务分解为小型模型和工具栈处理，减少对昂贵模型的依赖。

Method: Interfaze结合了异构DNN堆栈与小型语言模型作为感知模块，上下文构建层用于外部资源的爬取、索引和解析，以及动作层执行浏览、检索、代码执行等操作。顶层控制器决定运行哪些小型模型和动作，并将蒸馏后的上下文传递给用户选择的LLM生成最终响应。

Result: Interfaze-Beta在多项基准测试中表现优异，如MMLU-Pro（83.6%）、MMLU（91.4%）、GPQA-Diamond（81.3%）等，同时多模态任务（如MMMU、AI2D）也取得高分。

Conclusion: Interfaze系统通过将现代LLM应用视为上下文构建和操作的问题，而非单一模型选择，实现了高效的多模态任务处理。其架构将大部分计算从昂贵的单一模型转移到小型模型和工具栈，同时保持竞争力。

Abstract: We present Interfaze, a system that treats modern LLM applications as a problem of building and acting over context, not just picking the right monolithic model. Instead of a single transformer, we combine (i) a stack of heterogeneous DNNs paired with small language models as perception modules for OCR involving complex PDFs, charts and diagrams, and multilingual ASR with (ii) a context-construction layer that crawls, indexes, and parses external sources (web pages, code, PDFs) into compact structured state, and (iii) an action layer that can browse, retrieve, execute code in a sandbox, and drive a headless browser for dynamic web pages. A thin controller sits on top of this stack and exposes a single, OpenAI-style endpoint: it decides which small models and actions to run and always forwards the distilled context to a user-selected LLM that produces the final response.
  On this architecture, Interfaze-Beta achieves 83.6% on MMLU-Pro, 91.4% on MMLU, 81.3% on GPQA-Diamond, 57.8% on LiveCodeBench v5, and 90.0% on AIME-2025, along with strong multimodal scores on MMMU (val) (77.3%), AI2D (91.5%), ChartQA (90.9%), and Common Voice v16 (90.8%). We show that most queries are handled primarily by the small-model and tool stack, with the large LLM operating only on distilled context, yielding competitive accuracy while shifting the bulk of computation away from the most expensive and monolithic models.

</details>


### [101] [OMG-Agent: Toward Robust Missing Modality Generation with Decoupled Coarse-to-Fine Agentic Workflows](https://arxiv.org/abs/2602.04144)
*Ruiting Dai,Zheyu Wang,Haoyu Yang,Yihan Liu,Chengzhi Wang,Zekun Zhang,Zishan Huang,Jiaman Cen,Lisi Mo*

Main category: cs.AI

TL;DR: OMG-Agent通过动态三阶段工作流解决多模态数据不完整问题，显著提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法因语义-细节纠缠问题导致生成结果不可靠，需解决数据不完整对多模态系统的负面影响。

Method: OMG-Agent采用三阶段动态工作流：语义规划（MLLM驱动）、证据检索（非参数化）和检索注入执行（灵活特征提示）。

Result: 在多个基准测试中，OMG-Agent表现优于现有方法，例如在70%缺失率下CMU-MOSI指标提升2.6分。

Conclusion: OMG-Agent通过动态的Agentic Workflow有效解决了多模态系统中的数据不完整问题，显著提升了生成结果的可靠性和鲁棒性。

Abstract: Data incompleteness severely impedes the reliability of multimodal systems. Existing reconstruction methods face distinct bottlenecks: conventional parametric/generative models are prone to hallucinations due to over-reliance on internal memory, while retrieval-augmented frameworks struggle with retrieval rigidity. Critically, these end-to-end architectures are fundamentally constrained by Semantic-Detail Entanglement -- a structural conflict between logical reasoning and signal synthesis that compromises fidelity. In this paper, we present \textbf{\underline{O}}mni-\textbf{\underline{M}}odality \textbf{\underline{G}}eneration Agent (\textbf{OMG-Agent}), a novel framework that shifts the paradigm from static mapping to a dynamic coarse-to-fine Agentic Workflow. By mimicking a \textit{deliberate-then-act} cognitive process, OMG-Agent explicitly decouples the task into three synergistic stages: (1) an MLLM-driven Semantic Planner that resolves input ambiguity via Progressive Contextual Reasoning, creating a deterministic structured semantic plan; (2) a non-parametric Evidence Retriever that grounds abstract semantics in external knowledge; and (3) a Retrieval-Injected Executor that utilizes retrieved evidence as flexible feature prompts to overcome rigidity and synthesize high-fidelity details. Extensive experiments on multiple benchmarks demonstrate that OMG-Agent consistently surpasses state-of-the-art methods, maintaining robustness under extreme missingness, e.g., a $2.6$-point gain on CMU-MOSI at $70$\% missing rates.

</details>


### [102] [Steering LLMs via Scalable Interactive Oversight](https://arxiv.org/abs/2602.04210)
*Enyu Zhou,Zhiheng Xi,Long Ma,Zhihao Zhang,Shihan Dou,Zhikai Lei,Guoteng Wang,Rui Zheng,Hang Yan,Tao Gui,Qi Zhang,Xuanjing Huang*

Main category: cs.AI

TL;DR: 论文提出Scalable Interactive Oversight框架，通过递归决策树和低负担反馈提升非专家用户对AI的监督能力，实验显示对齐度提升54%。


<details>
  <summary>Details</summary>
Motivation: 解决大语言模型在复杂任务中用户因领域知识不足、意图表达困难和输出验证不可靠而导致的监督缺口问题。

Method: 提出了一种递归树结构，将复杂意图分解为可管理的决策节点，并通过低负担反馈和信号聚合生成全局指导。

Result: 在网页开发任务中，非专家用户能够生成专家级产品需求文档，对齐度提高了54%。

Conclusion: Scalable Interactive Oversight框架通过将复杂意图分解为可管理的决策树，显著提升了非专家用户对AI系统的监督能力，并在实际任务中验证了其有效性。

Abstract: As Large Language Models increasingly automate complex, long-horizon tasks such as \emph{vibe coding}, a supervision gap has emerged. While models excel at execution, users often struggle to guide them effectively due to insufficient domain expertise, the difficulty of articulating precise intent, and the inability to reliably validate complex outputs. It presents a critical challenge in scalable oversight: enabling humans to responsibly steer AI systems on tasks that surpass their own ability to specify or verify. To tackle this, we propose Scalable Interactive Oversight, a framework that decomposes complex intent into a recursive tree of manageable decisions to amplify human supervision. Rather than relying on open-ended prompting, our system elicits low-burden feedback at each node and recursively aggregates these signals into precise global guidance. Validated in web development task, our framework enables non-experts to produce expert-level Product Requirement Documents, achieving a 54\% improvement in alignment. Crucially, we demonstrate that this framework can be optimized via Reinforcement Learning using only online user feedback, offering a practical pathway for maintaining human control as AI scales.

</details>


### [103] [InterPReT: Interactive Policy Restructuring and Training Enable Effective Imitation Learning from Laypersons](https://arxiv.org/abs/2602.04213)
*Feiyu Gavin Zhu,Jean Oh,Reid Simmons*

Main category: cs.AI

TL;DR: InterPReT通过交互式指令和演示更新策略，适合非技术用户训练可靠策略。


<details>
  <summary>Details</summary>
Motivation: 降低普通人教授AI代理新技能的门槛，使其能够交互式地提供指令和演示、监控代理性能并审查决策策略。

Method: 提出了Interactive Policy Restructuring and Training (InterPReT)，通过用户指令持续更新策略结构并优化参数以适应用户演示。

Result: 用户研究（N=34）证实，与通用模仿学习基线相比，InterPReT在普通人负责提供演示和决定停止时机时，能产生更稳健的策略且不影响系统可用性。

Conclusion: InterPReT方法更适合没有机器学习技术背景的终端用户训练可靠的策略。

Abstract: Imitation learning has shown success in many tasks by learning from expert demonstrations. However, most existing work relies on large-scale demonstrations from technical professionals and close monitoring of the training process. These are challenging for a layperson when they want to teach the agent new skills. To lower the barrier of teaching AI agents, we propose Interactive Policy Restructuring and Training (InterPReT), which takes user instructions to continually update the policy structure and optimize its parameters to fit user demonstrations. This enables end-users to interactively give instructions and demonstrations, monitor the agent's performance, and review the agent's decision-making strategies. A user study (N=34) on teaching an AI agent to drive in a racing game confirms that our approach yields more robust policies without impairing system usability, compared to a generic imitation learning baseline, when a layperson is responsible for both giving demonstrations and determining when to stop. This shows that our method is more suitable for end-users without much technical background in machine learning to train a dependable policy

</details>


### [104] [Empirical-MCTS: Continuous Agent Evolution via Dual-Experience Monte Carlo Tree Search](https://arxiv.org/abs/2602.04248)
*Hao Lu,Haoyuan Huang,Yulin Zhou,Chen Li,Ningxin Zhu*

Main category: cs.AI

TL;DR: Empirical-MCTS通过双循环框架和两种新机制，将无状态搜索转化为持续学习过程，显著提升复杂推理任务的表现。


<details>
  <summary>Details</summary>
Motivation: 当前的无状态搜索方法无法模拟人类问题解决中的经验积累，因此需要一种能够持续学习的框架。

Method: 引入了Empirical-MCTS双循环框架，包含Pairwise-Experience-Evolutionary Meta-Prompting (PE-EMP)和Memory Optimization Agent两种新机制。

Result: 在AIME25、ARC-AGI-2和MathArena Apex等复杂推理基准测试中，Empirical-MCTS显著优于无状态MCTS策略和独立经验驱动代理。

Conclusion: Empirical-MCTS通过结合结构化搜索与经验积累，显著提升了大型语言模型在复杂、开放式推理任务中的表现。

Abstract: Inference-time scaling strategies, particularly Monte Carlo Tree Search (MCTS), have significantly enhanced the reasoning capabilities of Large Language Models (LLMs). However, current approaches remain predominantly stateless, discarding successful reasoning patterns after each problem instance and failing to mimic the empirical accumulation of wisdom characteristic of human problem-solving. To bridge this gap, we introduce Empirical-MCTS, a dual-loop framework that transforms stateless search into a continuous, non-parametric learning process. The framework unifies local exploration with global memory optimization through two novel mechanisms: Pairwise-Experience-Evolutionary Meta-Prompting (PE-EMP) and a Memory Optimization Agent. PE-EMP functions as a reflexive optimizer within the local search, utilizing pairwise feedback to dynamically synthesize adaptive criteria and evolve meta-prompts (system prompts) in real-time. Simultaneously, the Memory Optimization Agent manages a global repository as a dynamic policy prior, employing atomic operations to distill high-quality insights across problems. Extensive evaluations on complex reasoning benchmarks, including AIME25, ARC-AGI-2, and MathArena Apex, demonstrate that Empirical-MCTS significantly outperforms both stateless MCTS strategies and standalone experience-driven agents. These results underscore the critical necessity of coupling structured search with empirical accumulation for mastering complex, open-ended reasoning tasks.

</details>


### [105] [Agent-Omit: Training Efficient LLM Agents for Adaptive Thought and Observation Omission via Agentic Reinforcement Learning](https://arxiv.org/abs/2602.04284)
*Yansong Ning,Jun Fang,Naiqiang Tan,Hao Liu*

Main category: cs.AI

TL;DR: Agent-Omit通过自适应省略冗余思考和观察，提升代理效率，性能媲美前沿LLM代理。


<details>
  <summary>Details</summary>
Motivation: 现有研究忽视不同轮次中思考和观察的必要性与效用差异，导致代理效率低下。

Method: 提出了Agent-Omit，一个统一的训练框架，包括冷启动数据合成和omit-aware强化学习方法，结合双采样机制和定制化省略奖励。

Result: 实验证明Agent-Omit-8B在性能上媲美前沿LLM代理，并在效率-效果权衡上表现最佳。

Conclusion: Agent-Omit框架通过自适应省略冗余思考和观察，在五个代理基准测试中表现出色，性能与前沿LLM代理相当，并在效率-效果权衡上优于其他高效LLM代理方法。

Abstract: Managing agent thought and observation during multi-turn agent-environment interactions is an emerging strategy to improve agent efficiency. However, existing studies treat the entire interaction trajectories equally, overlooking the thought necessity and observation utility varies across turns. To this end, we first conduct quantitative investigations into how thought and observation affect agent effectiveness and efficiency. Based on our findings, we propose Agent-Omit, a unified training framework that empowers LLM agents to adaptively omit redundant thoughts and observations. Specifically, we first synthesize a small amount of cold-start data, including both single-turn and multi-turn omission scenarios, to fine-tune the agent for omission behaviors. Furthermore, we introduce an omit-aware agentic reinforcement learning approach, incorporating a dual sampling mechanism and a tailored omission reward to incentivize the agent's adaptive omission capability. Theoretically, we prove that the deviation of our omission policy is upper-bounded by KL-divergence. Experimental results on five agent benchmarks show that our constructed Agent-Omit-8B could obtain performance comparable to seven frontier LLM agent, and achieve the best effectiveness-efficiency trade-off than seven efficient LLM agents methods. Our code and data are available at https://github.com/usail-hkust/Agent-Omit.

</details>


### [106] [From Assumptions to Actions: Turning LLM Reasoning into Uncertainty-Aware Planning for Embodied Agents](https://arxiv.org/abs/2602.04326)
*SeungWon Seo,SooBin Lim,SeongRae Noh,Haneul Kim,HyeongYeop Kang*

Main category: cs.AI

TL;DR: PCE框架通过结构化决策树减少多智能体环境中的通信需求，提升任务效率和成功率，同时保持低令牌使用。


<details>
  <summary>Details</summary>
Motivation: 在多智能体、部分可观察和分散式环境中，频繁的智能体间通信会带来高昂的令牌和时间成本，并可能干扰工作流程。

Method: 引入了Planner-Composer-Evaluator（PCE）框架，将LLM推理中的碎片化假设转化为结构化决策树，并通过场景可能性、目标导向增益和执行成本评分路径。

Result: PCE在多个基准测试中优于以通信为中心的基线方法，同时在模型容量和推理深度扩展时仍能提升性能。用户研究表明，PCE生成的通信模式更高效且值得信赖。

Conclusion: PCE框架通过将LLM推理中的潜在假设转化为结构化决策树，提供了一种原则性方法，用于在不确定性环境中进行可靠规划。

Abstract: Embodied agents operating in multi-agent, partially observable, and decentralized environments must plan and act despite pervasive uncertainty about hidden objects and collaborators' intentions. Recent advances in applying Large Language Models (LLMs) to embodied agents have addressed many long-standing challenges, such as high-level goal decomposition and online adaptation. Yet, uncertainty is still primarily mitigated through frequent inter-agent communication. This incurs substantial token and time costs, and can disrupt established workflows, when human partners are involved. We introduce PCE, a Planner-Composer-Evaluator framework that converts the fragmented assumptions latent in LLM reasoning traces into a structured decision tree. Internal nodes encode environment assumptions and leaves map to actions; each path is then scored by scenario likelihood, goal-directed gain, and execution cost to guide rational action selection without heavy communication. Across two challenging multi-agent benchmarks (C-WAH and TDW-MAT) and three diverse LLM backbones, PCE consistently outperforms communication-centric baselines in success rate and task efficiency while showing comparable token usage. Ablation results indicate that the performance gains obtained by scaling model capacity or reasoning depth persist even when PCE is applied, while PCE consistently raises the baseline across both capacity and reasoning-depth scales, confirming that structured uncertainty handling complements both forms of scaling. A user study further demonstrates that PCE produces communication patterns that human partners perceive as more efficient and trustworthy. Together, these results establish a principled route for turning latent LLM assumptions into reliable strategies for uncertainty-aware planning.

</details>


### [107] [Digital Twins & ZeroConf AI: Structuring Automated Intelligent Pipelines for Industrial Applications](https://arxiv.org/abs/2602.04385)
*Marco Picone,Fabio Turazza,Matteo Martinelli,Marco Mamei*

Main category: cs.AI

TL;DR: 该论文提出了一种模块化和可互操作的零配置AI管道解决方案，通过数字孪生技术实现CPS中AI功能的无缝集成，并在工业场景中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 随着CPS复杂性的增加，特别是在工业领域，AI和ML技术的有效集成面临挑战。IoT和IIoT技术的碎片化（如多样化的通信协议、数据格式和设备能力）导致了物理层与高层智能功能之间的巨大差距。数字孪生（DT）技术因其结构化、可互操作和语义丰富的物理资产数字表示而成为有前景的解决方案。

Method: 该工作提出了零配置（ZeroConf）AI管道的概念，其中DT负责数据管理和智能增强的编排。该方法通过模块化和解耦设计，实现了AI功能的可扩展性和重用性。

Result: 在MicroFactory场景中，该方法展示了支持并发ML模型和动态数据处理的能力，显著提升了复杂工业环境中智能服务的部署效率。

Conclusion: 该论文提出了一种模块化和可互操作的解决方案，通过最小化配置和解耦数字孪生（DT）与AI组件的角色，实现了AI管道在CPS中的无缝集成。通过MicroFactory场景的演示，验证了该方法支持并发ML模型和动态数据处理，有效加速了复杂工业环境中智能服务的部署。

Abstract: The increasing complexity of Cyber-Physical Systems (CPS), particularly in the industrial domain, has amplified the challenges associated with the effective integration of Artificial Intelligence (AI) and Machine Learning (ML) techniques. Fragmentation across IoT and IIoT technologies, manifested through diverse communication protocols, data formats and device capabilities, creates a substantial gap between low-level physical layers and high-level intelligent functionalities. Recently, Digital Twin (DT) technology has emerged as a promising solution, offering structured, interoperable and semantically rich digital representations of physical assets. Current approaches are often siloed and tightly coupled, limiting scalability and reuse of AI functionalities. This work proposes a modular and interoperable solution that enables seamless AI pipeline integration into CPS by minimizing configuration and decoupling the roles of DTs and AI components. We introduce the concept of Zero Configuration (ZeroConf) AI pipelines, where DTs orchestrate data management and intelligent augmentation. The approach is demonstrated in a MicroFactory scenario, showing support for concurrent ML models and dynamic data processing, effectively accelerating the deployment of intelligent services in complex industrial settings.

</details>


### [108] [ReThinker: Scientific Reasoning by Rethinking with Guided Reflection and Confidence Control](https://arxiv.org/abs/2602.04496)
*Zhentao Tang,Yuqi Cui,Shixiong Kai,Wenqian Zhao,Ke Ye,Xing Li,Anxin Tian,Zehua Pei,Hui-Ling Zhen,Shoubo Hu,Xiaoguang Li,Yunhe Wang,Mingxuan Yuan*

Main category: cs.AI

TL;DR: ReThinker是一种自信感知的代理框架，通过动态计算分配和自适应工具调用，显著提升了专家级科学推理任务的性能。


<details>
  <summary>Details</summary>
Motivation: 针对大型语言模型在专家级科学推理任务中的局限性（如工具管道僵化、多代理协调脆弱和测试时扩展效率低），提出了ReThinker框架以提升性能。

Method: ReThinker采用Solver-Critic-Selector架构，通过动态计算分配、自适应工具调用和多维反思来实现推理。此外，提出了反向数据合成管道和自适应轨迹回收策略，以无监督方式生成高质量训练数据。

Result: 在HLE、GAIA和XBench等基准测试中，ReThinker表现优于现有最先进的工具增强基础模型和深度研究系统。

Conclusion: ReThinker框架通过动态计算分配和自适应工具调用，显著提升了大型语言模型在专家级科学推理任务中的表现，并在多个基准测试中达到了最先进的水平。

Abstract: Expert-level scientific reasoning remains challenging for large language models, particularly on benchmarks such as Humanity's Last Exam (HLE), where rigid tool pipelines, brittle multi-agent coordination, and inefficient test-time scaling often limit performance. We introduce ReThinker, a confidence-aware agentic framework that orchestrates retrieval, tool use, and multi-agent reasoning through a stage-wise Solver-Critic-Selector architecture. Rather than following a fixed pipeline, ReThinker dynamically allocates computation based on model confidence, enabling adaptive tool invocation, guided multi-dimensional reflection, and robust confidence-weighted selection. To support scalable training without human annotation, we further propose a reverse data synthesis pipeline and an adaptive trajectory recycling strategy that transform successful reasoning traces into high-quality supervision. Experiments on HLE, GAIA, and XBench demonstrate that ReThinker consistently outperforms state-of-the-art foundation models with tools and existing deep research systems, achieving state-of-the-art results on expert-level reasoning tasks.

</details>


### [109] [From Competition to Collaboration: Designing Sustainable Mechanisms Between LLMs and Online Forums](https://arxiv.org/abs/2602.04572)
*Niv Fono,Yftah Ziser,Omer Ben-Porat*

Main category: cs.AI

TL;DR: 提出顺序交互框架解决GenAI与论坛的矛盾，通过模拟展示激励错位但仍可实现部分效用，强调可持续合作潜力。


<details>
  <summary>Details</summary>
Motivation: 解决GenAI系统依赖论坛数据却吸引用户离开论坛的矛盾，提出一个顺序交互框架。

Method: 通过全面的数据驱动模拟，使用真实的Stack Exchange数据和常用LLM，展示了框架的实际应用。

Result: 实证展示了激励错位，但表明玩家可以在理想全信息场景中实现约一半的效用。

Conclusion: 研究结果强调了AI系统与人类知识平台之间可持续合作的潜力，以保持有效的知识共享。

Abstract: While Generative AI (GenAI) systems draw users away from (Q&A) forums, they also depend on the very data those forums produce to improve their performance. Addressing this paradox, we propose a framework of sequential interaction, in which a GenAI system proposes questions to a forum that can publish some of them. Our framework captures several intricacies of such a collaboration, including non-monetary exchanges, asymmetric information, and incentive misalignment. We bring the framework to life through comprehensive, data-driven simulations using real Stack Exchange data and commonly used LLMs. We demonstrate the incentive misalignment empirically, yet show that players can achieve roughly half of the utility in an ideal full-information scenario. Our results highlight the potential for sustainable collaboration that preserves effective knowledge sharing between AI systems and human knowledge platforms.

</details>


### [110] [Vibe AIGC: A New Paradigm for Content Generation via Agentic Orchestration](https://arxiv.org/abs/2602.04575)
*Jiaheng Liu,Yuanxing Zhang,Shihao Li,Xinping Lei*

Main category: cs.AI

TL;DR: Vibe AIGC提出代理编排新范式，通过Meta-Planner分解用户Vibe为可执行管道，解决生成式AI的意图-执行差距问题。


<details>
  <summary>Details</summary>
Motivation: 解决当前生成式AI的Intent-Execution Gap问题，即用户高级意图与随机黑盒模型之间的差距。

Method: 引入Vibe AIGC范式，通过集中式Meta-Planner将用户的Vibe分解为可执行、可验证和自适应的代理管道。

Result: Vibe AIGC通过逻辑编排而非随机推理，弥合了人类想象与机器执行之间的鸿沟。

Conclusion: Vibe AIGC 通过代理编排的新范式，将AI从脆弱的推理引擎转变为稳健的系统级工程伙伴，重新定义了人机协作经济。

Abstract: For the past decade, the trajectory of generative artificial intelligence (AI) has been dominated by a model-centric paradigm driven by scaling laws. Despite significant leaps in visual fidelity, this approach has encountered a ``usability ceiling'' manifested as the Intent-Execution Gap (i.e., the fundamental disparity between a creator's high-level intent and the stochastic, black-box nature of current single-shot models). In this paper, inspired by the Vibe Coding, we introduce the \textbf{Vibe AIGC}, a new paradigm for content generation via agentic orchestration, which represents the autonomous synthesis of hierarchical multi-agent workflows.
  Under this paradigm, the user's role transcends traditional prompt engineering, evolving into a Commander who provides a Vibe, a high-level representation encompassing aesthetic preferences, functional logic, and etc. A centralized Meta-Planner then functions as a system architect, deconstructing this ``Vibe'' into executable, verifiable, and adaptive agentic pipelines. By transitioning from stochastic inference to logical orchestration, Vibe AIGC bridges the gap between human imagination and machine execution. We contend that this shift will redefine the human-AI collaborative economy, transforming AI from a fragile inference engine into a robust system-level engineering partner that democratizes the creation of complex, long-horizon digital assets.

</details>


### [111] [WideSeek-R1: Exploring Width Scaling for Broad Information Seeking via Multi-Agent Reinforcement Learning](https://arxiv.org/abs/2602.04634)
*Zelai Xu,Zhexuan Xu,Ruize Zhang,Chunyang Zhu,Shi Yu,Weilin Liu,Quanlu Zhang,Wenbo Ding,Chao Yu,Yu Wang*

Main category: cs.AI

TL;DR: WideSeek-R1通过多智能体并行执行解决广泛信息搜索任务，性能媲美单一大型智能体，且扩展性优异。


<details>
  <summary>Details</summary>
Motivation: 当前多智能体系统依赖手工工作流程和轮流交互，无法有效并行化工作，需解决广泛信息搜索中的组织能力瓶颈。

Method: 提出WideSeek-R1框架，采用多智能体强化学习（MARL）训练主智能体与并行子智能体，利用共享LLM和隔离上下文及专用工具。

Result: WideSeek-R1-4B在WideSearch基准测试中达到40.0%的item F1分数，性能与单一智能体DeepSeek-R1-671B相当，且并行子智能体数量增加时性能持续提升。

Conclusion: WideSeek-R1-4B通过宽度扩展（多智能体并行执行）在广泛信息搜索任务中表现出色，性能与单一智能体DeepSeek-R1-671B相当，且随着并行子智能体数量增加性能持续提升。

Abstract: Recent advancements in Large Language Models (LLMs) have largely focused on depth scaling, where a single agent solves long-horizon problems with multi-turn reasoning and tool use. However, as tasks grow broader, the key bottleneck shifts from individual competence to organizational capability. In this work, we explore a complementary dimension of width scaling with multi-agent systems to address broad information seeking. Existing multi-agent systems often rely on hand-crafted workflows and turn-taking interactions that fail to parallelize work effectively. To bridge this gap, we propose WideSeek-R1, a lead-agent-subagent framework trained via multi-agent reinforcement learning (MARL) to synergize scalable orchestration and parallel execution. By utilizing a shared LLM with isolated contexts and specialized tools, WideSeek-R1 jointly optimizes the lead agent and parallel subagents on a curated dataset of 20k broad information-seeking tasks. Extensive experiments show that WideSeek-R1-4B achieves an item F1 score of 40.0% on the WideSearch benchmark, which is comparable to the performance of single-agent DeepSeek-R1-671B. Furthermore, WideSeek-R1-4B exhibits consistent performance gains as the number of parallel subagents increases, highlighting the effectiveness of width scaling.

</details>


### [112] [Agentic AI in Healthcare & Medicine: A Seven-Dimensional Taxonomy for Empirical Evaluation of LLM-based Agents](https://arxiv.org/abs/2602.04813)
*Shubham Vatsal,Harsh Dubey,Aditi Singh*

Main category: cs.AI

TL;DR: 论文通过七维分类法分析了49项LLM在医疗领域的研究，发现知识整合和多智能体设计普遍，但事件触发激活和漂移检测等能力缺失。


<details>
  <summary>Details</summary>
Motivation: 填补现有文献中对LLM在医疗领域应用缺乏统一框架的空白，提供一个系统性的分类法来评估和比较不同研究。

Method: 使用明确的纳入和排除标准，以及标签评分标准（完全实现、部分实现、未实现），将每项研究映射到分类法中，并报告能力的普遍性和共现模式的定量总结。

Result: 研究发现知识整合（76%完全实现）和多智能体设计（82%完全实现）较为普遍，而事件触发激活（92%未实现）和漂移检测（98%未实现）则较为罕见。

Conclusion: 该论文通过七维分类法对49项研究进行了系统性回顾，揭示了LLM在医疗领域的能力分布不均，强调了知识整合和多智能体设计的普遍性，以及事件触发激活和漂移检测等领域的缺失。

Abstract: Large Language Model (LLM)-based agents that plan, use tools and act has begun to shape healthcare and medicine. Reported studies demonstrate competence on various tasks ranging from EHR analysis and differential diagnosis to treatment planning and research workflows. Yet the literature largely consists of overviews which are either broad surveys or narrow dives into a single capability (e.g., memory, planning, reasoning), leaving healthcare work without a common frame. We address this by reviewing 49 studies using a seven-dimensional taxonomy: Cognitive Capabilities, Knowledge Management, Interaction Patterns, Adaptation & Learning, Safety & Ethics, Framework Typology and Core Tasks & Subtasks with 29 operational sub-dimensions. Using explicit inclusion and exclusion criteria and a labeling rubric (Fully Implemented, Partially Implemented, Not Implemented), we map each study to the taxonomy and report quantitative summaries of capability prevalence and co-occurrence patterns. Our empirical analysis surfaces clear asymmetries. For instance, the External Knowledge Integration sub-dimension under Knowledge Management is commonly realized (~76% Fully Implemented) whereas Event-Triggered Activation sub-dimenison under Interaction Patterns is largely absent (~92% Not Implemented) and Drift Detection & Mitigation sub-dimension under Adaptation & Learning is rare (~98% Not Implemented). Architecturally, Multi-Agent Design sub-dimension under Framework Typology is the dominant pattern (~82% Fully Implemented) while orchestration layers remain mostly partial. Across Core Tasks & Subtasks, information centric capabilities lead e.g., Medical Question Answering & Decision Support and Benchmarking & Simulation, while action and discovery oriented areas such as Treatment Planning & Prescription still show substantial gaps (~59% Not Implemented).

</details>


### [113] [Are AI Capabilities Increasing Exponentially? A Competing Hypothesis](https://arxiv.org/abs/2602.04836)
*Haosen Ge,Hamsa Bastani,Osbert Bastani*

Main category: cs.AI

TL;DR: 本文反驳了AI能力指数级增长的观点，通过数据拟合和复杂模型证明拐点可能已过或即将到来，强调现有预测的脆弱性。


<details>
  <summary>Details</summary>
Motivation: 研究的动机是质疑METR报告中关于AI能力自2019年以来呈指数级增长的观点，并揭示现有预测的脆弱性。

Method: 作者采用了sigmoid曲线拟合METR的数据，并提出一个将AI能力分解为基础能力和推理能力的复杂模型，以证明其假设。

Result: 结果显示，sigmoid曲线拟合表明拐点已经过去，而更复杂的模型支持AI能力将在近期出现拐点的假设。

Conclusion: 本文的结论是现有关于AI能力指数级增长的预测具有脆弱性，且通过更复杂的模型分析表明，AI能力的拐点可能已经到来或在不久的将来出现。

Abstract: Rapidly increasing AI capabilities have substantial real-world consequences, ranging from AI safety concerns to labor market consequences. The Model Evaluation & Threat Research (METR) report argues that AI capabilities have exhibited exponential growth since 2019. In this note, we argue that the data does not support exponential growth, even in shorter-term horizons. Whereas the METR study claims that fitting sigmoid/logistic curves results in inflection points far in the future, we fit a sigmoid curve to their current data and find that the inflection point has already passed. In addition, we propose a more complex model that decomposes AI capabilities into base and reasoning capabilities, exhibiting individual rates of improvement. We prove that this model supports our hypothesis that AI capabilities will exhibit an inflection point in the near future. Our goal is not to establish a rigorous forecast of our own, but to highlight the fragility of existing forecasts of exponential growth.

</details>


### [114] [Group-Evolving Agents: Open-Ended Self-Improvement via Experience Sharing](https://arxiv.org/abs/2602.04837)
*Zhaotian Weng,Antonis Antoniades,Deepak Nathani,Zhen Zhang,Xiao Pu,Xin Eric Wang*

Main category: cs.AI

TL;DR: GEA通过群体进化单元提升探索多样性利用效率，在编码任务中超越现有方法，表现优于人类设计框架。


<details>
  <summary>Details</summary>
Motivation: 现有的开放自我进化范式采用树状进化结构，导致探索多样性利用效率低下，限制了代理的长期进步。

Method: GEA采用群体进化单元，实现群体内经验的显式共享和重用，克服了树状进化结构中探索多样性利用不足的问题。

Result: GEA在编码基准测试中显著优于现有自我进化方法（SWE-bench Verified 71.0% vs. 56.7%，Polyglot 88.3% vs. 68.3%），并与人类设计的顶级代理框架表现相当或更优（71.8%和52.0%）。此外，GEA在相同进化代理数量下表现更强，修复框架级错误的平均迭代次数更少（1.4次 vs. 5次）。

Conclusion: GEA作为一种新型的开放自我进化范式，通过将代理群体作为基本进化单元，显著提升了探索多样性的利用效率，并在编码基准测试中超越了现有自我进化方法和人类设计的代理框架。

Abstract: Open-ended self-improving agents can autonomously modify their own structural designs to advance their capabilities and overcome the limits of pre-defined architectures, thus reducing reliance on human intervention. We introduce Group-Evolving Agents (GEA), a new paradigm for open-ended self-improvements, which treats a group of agents as the fundamental evolutionary unit, enabling explicit experience sharing and reuse within the group throughout evolution. Unlike existing open-ended self-evolving paradigms that adopt tree-structured evolution, GEA overcomes the limitation of inefficient utilization of exploratory diversity caused by isolated evolutionary branches. We evaluate GEA on challenging coding benchmarks, where it significantly outperforms state-of-the-art self-evolving methods (71.0% vs. 56.7% on SWE-bench Verified, 88.3% vs. 68.3% on Polyglot) and matches or exceeds top human-designed agent frameworks (71.8% and 52.0% on two benchmarks, respectively). Analysis reveals that GEA more effectively converts early-stage exploratory diversity into sustained, long-term progress, achieving stronger performance under the same number of evolved agents. Furthermore, GEA exhibits consistent transferability across different coding models and greater robustness, fixing framework-level bugs in 1.4 iterations on average, versus 5 for self-evolving methods.

</details>


### [115] [Fluid Representations in Reasoning Models](https://arxiv.org/abs/2602.04843)
*Dmitrii Kharlapenko,Alessandro Stolfo,Arthur Conmy,Mrinmaya Sachan,Zhijing Jin*

Main category: cs.AI

TL;DR: QwQ-32B模型通过逐步优化内部表示（如抽象编码）提升推理性能，这种机制被称为“Fluid Reasoning Representations”。


<details>
  <summary>Details</summary>
Motivation: 尽管推理语言模型在抽象问题上表现优异，但其内部机制尚不明确。本研究旨在揭示QwQ-32B模型如何处理抽象结构信息，并探索其性能提升的内部机制。

Method: 通过对QwQ-32B模型在Mystery Blocksworld领域的机制分析，结合引导实验（如注入成功轨迹的优化表示或替换符号表示），验证了模型在推理过程中逐步优化内部表示的机制。

Result: 研究发现，QwQ-32B在推理过程中逐步优化对动作和概念的内部表示，形成关注结构的抽象编码。通过引导实验证实，这些优化表示能显著提升问题解决准确率。

Conclusion: 研究发现，推理语言模型通过逐步优化内部表示（如抽象编码和结构关注）来提升性能，特别是在处理抽象结构信息时。这种优化被称为“Fluid Reasoning Representations”，是模型性能提升的关键因素之一。

Abstract: Reasoning language models, which generate long chains of thought, dramatically outperform non-reasoning language models on abstract problems. However, the internal model mechanisms that allow this superior performance remain poorly understood. We present a mechanistic analysis of how QwQ-32B - a model specifically trained to produce extensive reasoning traces - process abstract structural information. On Mystery Blocksworld - a semantically obfuscated planning domain - we find that QwQ-32B gradually improves its internal representation of actions and concepts during reasoning. The model develops abstract encodings that focus on structure rather than specific action names. Through steering experiments, we establish causal evidence that these adaptations improve problem solving: injecting refined representations from successful traces boosts accuracy, while symbolic representations can replace many obfuscated encodings with minimal performance loss. We find that one of the factors driving reasoning model performance is in-context refinement of token representations, which we dub Fluid Reasoning Representations.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [116] [Approximately Partitioning Vertices into Short Paths](https://arxiv.org/abs/2602.03991)
*Mingyang Gong,Zhi-Zhong Chen,Brendan Mumey*

Main category: cs.DS

TL;DR: 本文针对$k^-$-路径分区问题，提出了两种近似算法，分别在$k=9,10$和$k \ge 11$时取得当前最佳近似比。


<details>
  <summary>Details</summary>
Motivation: 研究旨在解决$k^-$-路径分区问题，即在简单无向图中找到顶点不相交的路径集合，每条路径最多$k$个顶点，且覆盖所有顶点。

Method: 算法从一个最大三角形自由路径-环覆盖开始，通过计算另一个最大权重路径-环覆盖，将尽可能多的4或5顶点环连接起来，从而将初始覆盖转化为$k^-$-路径分区。

Result: 对于$k\in\{9,10\}$，提出了$\frac{k+4}{5}$近似算法；对于$k \ge 11$，提出了$(\frac{\sqrt{11}-2}{7}k + \frac{9-\sqrt{11}}{7})$近似算法，均为当前最佳。

Conclusion: 本文针对$k$PP问题提出了两种近似算法，分别在$k\in\{9,10\}$和$k \ge 11$时取得当前最佳的近似比。

Abstract: Given a fixed positive integer $k$ and a simple undirected graph $G = (V, E)$, the {\em $k^-$-path partition} problem, denoted by $k$PP for short, aims to find a minimum collection $\cal{P}$ of vertex-disjoint paths in $G$ such that each path in $\cal{P}$ has at most $k$ vertices and each vertex of $G$ appears in one path in $\cal{P}$. In this paper, we present a $\frac {k+4}5$-approximation algorithm for $k$PP when $k\in\{9,10\}$ and an improved $(\frac{\sqrt{11}-2}7 k + \frac {9-\sqrt{11}}7)$-approximation algorithm when $k \ge 11$. Our algorithms achieve the current best approximation ratios for $k \in \{ 9, 10, \ldots, 18 \}$.
  Our algorithms start with a maximum triangle-free path-cycle cover $\cal{F}$, which may not be feasible because of the existence of cycles or paths with more than $k$ vertices. We connect as many cycles in $\cal{F}$ with $4$ or $5$ vertices as possible by computing another maximum-weight path-cycle cover in a suitably constructed graph so that $\cal{F}$ can be transformed into a $k^-$-path partition of $G$ without losing too many edges.
  Keywords: $k^-$-path partition; Triangle-free path-cycle cover; $[f, g]$-factor; Approximation algorithm

</details>


### [117] [Minimizing Makespan in Sublinear Time via Weighted Random Sampling](https://arxiv.org/abs/2602.04059)
*Bin Fu,Yumei Huo,Hairong Zhao*

Main category: cs.DS

TL;DR: 提出了两种基于加权随机采样的子线性时间近似算法，分别处理n已知和n未知的最小化最大完工时间调度问题，均实现(1+3ε)-近似。


<details>
  <summary>Details</summary>
Motivation: 解决经典的最小化最大完工时间调度问题，特别是在大规模数据（n较大）时的高效近似需求。

Method: 使用加权随机采样技术，第一种算法针对n已知情况，采用单轮采样；第二种算法针对n未知情况，采用自适应加权随机采样。

Result: 两种算法均在子线性时间内运行，第一种算法时间复杂度为$\tilde{O}(\tfrac{m^5}{ε^4} \sqrt{n}+A(\ceiling{m\over ε}, ε ))$，第二种算法时间复杂度类似。

Conclusion: 本文提出了两种针对不同情况（n已知和n未知）的子线性时间近似方案，均能提供(1+3ε)-近似最优解，并生成草图调度。

Abstract: We consider the classical makespan minimization scheduling problem where $n$ jobs must be scheduled on $m$ identical machines. Using weighted random sampling, we developed two sublinear time approximation schemes: one for the case where $n$ is known and the other for the case where $n$ is unknown. Both algorithms not only give a $(1+3ε)$-approximation to the optimal makespan but also generate a sketch schedule.
  Our first algorithm, which targets the case where $n$ is known and draws samples in a single round under weighted random sampling, has a running time of $\tilde{O}(\tfrac{m^5}{ε^4} \sqrt{n}+A(\ceiling{m\over ε}, ε ))$, where
  $A(\mathcal{N}, α)$ is the time complexity of any $(1+α)$-approximation scheme for the makespan minimization of $\mathcal{N}$ jobs.
  The second algorithm addresses the case where $n$ is unknown. It uses adaptive weighted random sampling, %\textit{that is}, it draws samples in several rounds, adjusting the number of samples after each round,
  and runs in sublinear time $\tilde{O}\left( \tfrac{m^5} {ε^4} \sqrt{n} +
  A(\ceiling{m\over ε}, ε )\right)$. We also provide an implementation that generates a weighted random sample using $O(\log n)$ uniform random samples.

</details>


### [118] [QuadRank: Engineering a High Throughput Rank](https://arxiv.org/abs/2602.04103)
*R. Groot Koerkamp*

Main category: cs.DS

TL;DR: BiRank和QuadRank通过优化缓存和预取技术，显著提升查询速度和吞吐量，适用于生物信息学等高性能场景。


<details>
  <summary>Details</summary>
Motivation: 在生物信息学等需要快速处理大量数据的应用中，高效的数据结构和多线程高吞吐量是关键需求。

Method: BiRank和QuadRank分别针对二进制和四进制（DNA）字母表，通过内联偏移和优化popcounting技术，减少缓存未命中，并支持预取以提高批量处理效率。

Result: BiRank和QuadRank比未使用内联技术的同类方法快1.5倍和2倍，预取技术进一步带来2倍加速，性能接近DDR4 RAM带宽极限。QuadFm在FM-index实现中比Genedex快4倍且体积更小。

Conclusion: BiRank和QuadRank通过合并两种最新技术，显著提升了查询效率，适用于高吞吐量和内存受限的场景，尤其是在生物信息学应用中表现优异。

Abstract: Given a text, a query $\mathsf{rank}(q, c)$ counts the number of occurrences of character $c$ among the first $q$ characters of the text. Space-efficient methods to answer these rank queries form an important building block in many succinct data structures. For example, the FM-index is a widely used data structure that uses rank queries to locate all occurrences of a pattern in a text.
  In bioinformatics applications, the goal is usually to process a given input as fast as possible. Thus, data structures should have high throughput when used with many threads.
  Contributions. For the binary alphabet, we develop BiRank with 3.28% space overhead. It merges the central ideas of two recent papers: (1) we interleave (inline) offsets in each cache line of the underlying bit vector [Laws et al., 2024], reducing cache-misses, and (2) these offsets are to the middle of each block so that only half of them need popcounting [Gottlieb and Reinert, 2025]. In QuadRank (14.4% space overhead), we extend these techniques to the $σ=4$ (DNA) alphabet.
  Both data structures require only a single cache miss per query, making them highly suitable for high-throughput and memory-bound settings. To enable efficient batch-processing, we support prefetching the cache lines required to answer upcoming queries.
  Results. BiRank and QuadRank are around $1.5\times$ and $2\times$ faster than similar-overhead methods that do not use inlining. Prefetching gives an additional $2\times$ speedup, at which point the dual-channel DDR4 RAM bandwidth becomes a hard limit on the total throughput. With prefetching, both methods outperform all other methods apart from SPIDER [Laws et al., 2024] by $2\times$.
  When using QuadRank with prefetching in a toy count-only FM-index, QuadFm, this results in a smaller size and up to $4\times$ speedup over Genedex, a state-of-the-art batching FM-index implementation.

</details>


### [119] [Improved Sparse Recovery for Approximate Matrix Multiplication](https://arxiv.org/abs/2602.04386)
*Yahel Uffenheimer,Omri Weinstein*

Main category: cs.DS

TL;DR: 提出了一种快速近似矩阵乘法算法，误差与输出范数相关，时间复杂度优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 旨在设计一种更高效的近似矩阵乘法算法，其误差与输出范数直接相关，并在时间复杂度上优于现有方法。

Method: 算法基于一种新的伪随机旋转变体（非对称对角缩放的快速Hadamard变换），将输出AB的Frobenius范数均匀分布到其所有条目中。

Result: 算法在O(n²(r + log n))时间内生成矩阵C，总平方误差E[‖C-AB‖_F²] ≤ (1-r/n)‖AB‖_F²，或可计算无偏估计，误差为(n/r)‖AB‖_F²，与现有最优算法相当。

Conclusion: 该论文提出了一种随机算法，用于近似矩阵乘法（AMM），其误差与输出范数‖AB‖_F成比例，且在时间复杂度上比现有最优算法快一个对数因子。

Abstract: We present a simple randomized algorithm for approximate matrix multiplication (AMM) whose error scales with the *output* norm $\|AB\|_F$. Given any $n\times n$ matrices $A,B$ and a runtime parameter $r\leq n$, the algorithm produces in $O(n^2(r+\log n))$ time, a matrix $C$ with total squared error $\mathbb{E}[\|C-AB\|_F^2]\le (1-\frac{r}{n})\|AB\|_F^2$, per-entry variance $\|AB\|_F^2/n^2$ and bias $\mathbb{E}[C]=\frac{r}{n}AB$. Alternatively, the algorithm can compute an *unbiased* estimation with expected total squared error $\frac{n}{r}\|{AB}\|_{F}^2$, recovering the state-of-art AMM error obtained by Pagh's TensorSketch algorithm (Pagh, 2013). Our algorithm is a log-factor faster.
  The key insight in the algorithm is a new variation of pseudo-random rotation of the input matrices (a Fast Hadamard Transform with asymmetric diagonal scaling), which redistributes the Frobenius norm of the *output* $AB$ uniformly across its entries.

</details>


### [120] [Simple 2-approximations for bad triangle transversals and some hardness results for related problems](https://arxiv.org/abs/2602.04463)
*Florian Adriaens,Nikolaj tatti*

Main category: cs.DS

TL;DR: 本文提出带符号图中坏三角形横截问题的2-近似算法，证明其NP-hard近似性，并改进相关聚类与BTT最优解的比例至3/2。


<details>
  <summary>Details</summary>
Motivation: 解决带符号图中坏三角形横截问题的计算复杂性，提供更简单、快速的近似算法，并探索其与相关聚类问题的联系。

Method: 提出了两种新颖的2-近似算法，适用于加权BTT和近似最优可行解。利用坏三角形覆盖LP的近似结果，实现了(2+ε)近似的时间复杂度。通过枢轴程序将BTT解转化为聚类解。

Result: 证明了BTT在完全带符号图中的NP-hard近似性，提出了2-近似算法，并改进了相关聚类最优解与BTT最优解的比例至3/2。

Conclusion: 本文提出了针对带符号图中坏三角形横截问题（BTT）的新颖2-近似算法，证明了其在加权BTT和近似最优可行解中的有效性，并展示了在完全带符号图中BTT的NP-hard近似性。此外，通过改进的枢轴程序，将相关聚类最优解与BTT最优解的比例提升至3/2。

Abstract: Given a signed graph, the bad triangle transversal (BTT) problem asks to find the smallest number of edges that need to be removed such that the remaining graph does not have a triangle with exactly one negative edge (a bad triangle). We propose novel 2-approximations for this problem, which are much simpler and faster than a folklore adaptation of the 2-approximation by Krivelevich for finding a minimum triangle transversal in unsigned graphs. One of our algorithms also works for weighted BTT and for approximately optimal feasible solutions to the bad triangle cover LP. Using a recent result on approximating the bad triangle cover LP, we obtain a $(2+ε)$ approximation in time almost equal to the time needed to find a maximal set of edge-disjoint bad triangles (which would give a standard 3-approximation). Additionally, several inapproximability results are provided. For complete signed graphs, we show that BTT is NP-hard to approximate with factor better than $\frac{2137}{2136}$. Our reduction also implies the same hardness result for related problems such as correlation clustering (cluster editing), cluster deletion and the min. strong triadic closure problem. On complete signed graphs, BTT is closely related to correlation clustering. We show that the correlation clustering optimum is at most $3/2$ times the BTT optimum, by describing a pivot procedure that transforms BTT solutions into clusters. This improves a result by Veldt, which states that their ratio is at most two.

</details>


### [121] [Incongruity-sensitive access to highly compressed strings](https://arxiv.org/abs/2602.04523)
*Ferdinando Cicalese,Zsuzsanna Lipták,Travis Gagie,Gonzalo Navarro,Nicola Prezza,Cristian Urbina*

Main category: cs.DS

TL;DR: 论文研究了在高度压缩字符串中快速访问相对不可压缩子串的方法，通过特定数据结构实现对数时间访问。


<details>
  <summary>Details</summary>
Motivation: 探索在高度压缩字符串中，是否能够支持对相对不可压缩子串的更快访问，因为更好的压缩可能会阻碍访问速度。

Method: 研究使用了运行长度压缩的直线程序（RLSLP）和块树（block tree）构建数据结构，支持对数时间访问字符。

Result: 构建了空间复杂度为O(g_rl)或O(L)的数据结构，支持对字符的访问时间与包含该字符的最长重复子串长度对数相关。

Conclusion: 该论文展示了如何通过特定的数据结构支持对高度压缩字符串中相对不可压缩子串的快速访问，访问时间取决于字符周围的最长重复子串长度。

Abstract: Random access to highly compressed strings -- represented by straight-line programs or Lempel-Ziv parses, for example -- is a well-studied topic. Random access to such strings in strongly sublogarithmic time is impossible in the worst case, but previous authors have shown how to support faster access to specific characters and their neighbourhoods. In this paper we explore whether, since better compression can impede access, we can support faster access to relatively incompressible substrings of highly compressed strings. We first show how, given a run-length compressed straight-line program (RLSLP) of size $g_{rl}$ or a block tree of size $L$, we can build an $O (g_{rl})$-space or an $O (L)$-space data structure, respectively, that supports access to any character in time logarithmic in the length of the longest repeated substring containing that character. That is, the more incongruous a character is with respect to the characters around it in a certain sense, the faster we can support access to it. We then prove a similar but more powerful and sophisticated result for parsings in which phrases' sources do not overlap much larger phrases, with the query time depending also on the number of phrases we must copy from their sources to obtain the queried character.

</details>


### [122] [The matrix-vector complexity of $Ax=b$](https://arxiv.org/abs/2602.04842)
*Michał Dereziński,Ethan N. Epperly,Raphael A. Meyer*

Main category: cs.DS

TL;DR: 论文证明了矩阵向量算法在求解线性系统时的效率下界，验证了Krylov子空间算法的最优性。


<details>
  <summary>Details</summary>
Motivation: 研究矩阵向量算法（特别是Krylov子空间方法）在解决大型线性方程组时的效率限制。

Method: 通过建立矩阵向量算法在最坏情况下所需的矩阵向量乘积数量的下界，分析了一般的线性系统求解问题。

Result: 证明了对于条件数为κ的线性系统，需要Ω(κlog(1/ε))次矩阵向量乘积才能达到精度ε；对于单侧算法，即使问题条件完美，也需要n次乘积。

Conclusion: 该论文严格证明了矩阵向量算法的局限性，并确认了广泛使用的Krylov子空间算法的最优性。

Abstract: Matrix-vector algorithms, particularly Krylov subspace methods, are widely viewed as the most effective algorithms for solving large systems of linear equations. This paper establishes lower bounds on the worst-case number of matrix-vector products needed by such an algorithm to approximately solve a general linear system. The first main result is that, for a matrix-vector algorithm which can perform products with both a matrix and its transpose, $Ω(κ\log(1/\varepsilon))$ matrix-vector products are necessary to solve a linear system with condition number $κ$ to accuracy $\varepsilon$, matching an upper bound for conjugate gradient on the normal equations. The second main result is that one-sided algorithms, which lack access to the transpose, must use $n$ matrix-vector products to solve an $n \times n$ linear system, even when the problem is perfectly conditioned. Both main results include explicit constants that match known upper bounds up to a factor of four. These results rigorously demonstrate the limitations of matrix-vector algorithms and confirm the optimality of widely used Krylov subspace algorithms.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [123] [Multi-threaded Recast-Based A* Pathfinding for Scalable Navigation in Dynamic Game Environments](https://arxiv.org/abs/2602.04130)
*Tiroshan Madushanka,Sakuna Madushanka*

Main category: cs.GR

TL;DR: 论文提出了一种多线程框架，优化A*算法在动态3D环境中的性能，实现高性能和视觉真实性的平衡。


<details>
  <summary>Details</summary>
Motivation: 解决A*算法在动态3D环境中计算性能与视觉真实性之间的权衡问题。

Method: 通过Recast-based网格生成、Bezier曲线轨迹平滑和密度分析进行群体协调，构建了一个多线程框架。

Result: 实验结果表明，该框架在1000个同时运行的代理下保持350+ FPS，并通过密度感知路径协调实现无碰撞群体导航。

Conclusion: 该论文提出的多线程框架成功地在动态3D环境中优化了A*算法，实现了高性能和视觉真实性的平衡。

Abstract: While the A* algorithm remains the industry standard for game pathfinding, its integration into dynamic 3D environments faces trade-offs between computational performance and visual realism. This paper proposes a multi-threaded framework that enhances standard A* through Recast-based mesh generation, Bezier-curve trajectory smoothing, and density analysis for crowd coordination. We evaluate our system across ten incremental phases, from 2D mazes to complex multi-level dynamic worlds. Experimental results demonstrate that the framework maintains 350+ FPS with 1000 simultaneous agents and achieves collision-free crowd navigation through density-aware path coordination.

</details>


### [124] [Event-T2M: Event-level Conditioning for Complex Text-to-Motion Synthesis](https://arxiv.org/abs/2602.04292)
*Seong-Eun Hong,JaeYoung Seon,JuYeong Hwang,JongHwan Shin,HyeongYeop Kang*

Main category: cs.GR

TL;DR: Event-T2M通过事件分解和集成，显著提升多事件文本到动作生成的顺序保持和自然性。


<details>
  <summary>Details</summary>
Motivation: 现有系统将复杂多动作提示压缩为单一嵌入，导致遗漏、顺序错乱或不自然过渡，需引入事件定义以改进。

Method: 提出Event-T2M框架，通过分解提示为事件、使用运动感知检索模型编码每个事件，并通过事件交叉注意力在Conformer块中集成。

Result: 在HumanML3D、KIT-ML和HumanML3D-E基准测试中，Event-T2M在标准测试中与基线相当，但在事件复杂度增加时表现更优。

Conclusion: Event-T2M通过事件级条件化，显著提升了文本到动作生成的性能，尤其是在处理多事件提示时，保持了动作顺序和自然性，接近真实动作。

Abstract: Text-to-motion generation has advanced with diffusion models, yet existing systems often collapse complex multi-action prompts into a single embedding, leading to omissions, reordering, or unnatural transitions. In this work, we shift perspective by introducing a principled definition of an event as the smallest semantically self-contained action or state change in a text prompt that can be temporally aligned with a motion segment. Building on this definition, we propose Event-T2M, a diffusion-based framework that decomposes prompts into events, encodes each with a motion-aware retrieval model, and integrates them through event-based cross-attention in Conformer blocks. Existing benchmarks mix simple and multi-event prompts, making it unclear whether models that succeed on single actions generalize to multi-action cases. To address this, we construct HumanML3D-E, the first benchmark stratified by event count. Experiments on HumanML3D, KIT-ML, and HumanML3D-E show that Event-T2M matches state-of-the-art baselines on standard tests while outperforming them as event complexity increases. Human studies validate the plausibility of our event definition, the reliability of HumanML3D-E, and the superiority of Event-T2M in generating multi-event motions that preserve order and naturalness close to ground-truth. These results establish event-level conditioning as a generalizable principle for advancing text-to-motion generation beyond single-action prompts.

</details>


### [125] [Skin Tokens: A Learned Compact Representation for Unified Autoregressive Rigging](https://arxiv.org/abs/2602.04805)
*Jia-peng Zhang,Cheng-Feng Pu,Meng-Hao Guo,Yan-Pei Cao,Shi-Min Hu*

Main category: cs.GR

TL;DR: 论文提出SkinTokens和TokenRig框架，通过离散表示和强化学习显著提升3D绑定精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有自动化绑定方法因处理皮肤权重的高维回归问题效率低下且与骨架生成脱节，导致动画流程瓶颈。

Method: 使用FSQ-CVAE学习紧凑离散的SkinTokens表示，将绑定任务重构为序列预测问题，并通过TokenRig框架和强化学习优化骨架和皮肤变形之间的依赖关系。

Result: SkinTokens表示将皮肤权重精度提高了98%-133%，TokenRig框架通过强化学习进一步将骨骼预测精度提升17%-22%。

Conclusion: 该论文提出了一种统一的生成式方法来解决3D内容创建中的绑定问题，通过SkinTokens表示和TokenRig框架显著提高了绑定精度和鲁棒性。

Abstract: The rapid proliferation of generative 3D models has created a critical bottleneck in animation pipelines: rigging. Existing automated methods are fundamentally limited by their approach to skinning, treating it as an ill-posed, high-dimensional regression task that is inefficient to optimize and is typically decoupled from skeleton generation. We posit this is a representation problem and introduce SkinTokens: a learned, compact, and discrete representation for skinning weights. By leveraging an FSQ-CVAE to capture the intrinsic sparsity of skinning, we reframe the task from continuous regression to a more tractable token sequence prediction problem. This representation enables TokenRig, a unified autoregressive framework that models the entire rig as a single sequence of skeletal parameters and SkinTokens, learning the complicated dependencies between skeletons and skin deformations. The unified model is then amenable to a reinforcement learning stage, where tailored geometric and semantic rewards improve generalization to complex, out-of-distribution assets. Quantitatively, the SkinTokens representation leads to a 98%-133% percents improvement in skinning accuracy over state-of-the-art methods, while the full TokenRig framework, refined with RL, enhances bone prediction by 17%-22%. Our work presents a unified, generative approach to rigging that yields higher fidelity and robustness, offering a scalable solution to a long-standing challenge in 3D content creation.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [126] [Pending Conflicts Make Progress Impossible](https://arxiv.org/abs/2602.04013)
*Petr Kuznetsov,Pierre Sutra,Guillermo Toyos-Marfurt*

Main category: cs.DC

TL;DR: 本文研究了共享对象的可交换感知线性化实现，提出冲突阻塞自由条件，但证明其在异步模型中不可实现，揭示了冲突感知通用构造的同步成本限制。


<details>
  <summary>Details</summary>
Motivation: 观察到可交换操作可以并行执行，因此研究如何在共享对象实现中利用这一特性来提升性能。

Method: 引入冲突阻塞自由（conflict-obstruction-freedom）条件，扩展了阻塞自由和等待自由的概念，允许在仅由可交换操作引起的步骤争用下取得进展。

Result: 证明在异步读写共享内存模型中，冲突阻塞自由的通用构造无法实现。

Conclusion: 冲突感知的通用构造存在根本性限制：冲突操作的调用本身就会带来同步成本，进展需要最终解决未决冲突。

Abstract: In this work, we study progress conditions for commutativity-aware, linearizable implementations of shared objects. Motivated by the observation that commuting operations can be executed in parallel, we introduce conflict-obstruction-freedom: a process is guaranteed to complete its operation if it runs for long enough without encountering step contention with conflicting (non-commuting) operations. This condition generalizes obstruction-freedom and wait-freedom by allowing progress as long as step contention is only induced by commuting operations. We prove that conflict-obstruction-free universal constructions are impossible to implement in the asynchronous read-write shared memory model. This result exposes a fundamental limitation of conflict-aware universal constructions: the mere invocation of conflicting operations imposes a synchronization cost. Progress requires eventual resolution of pending conflicts.

</details>


### [127] [Six Times to Spare: LDPC Acceleration on DGX Spark for AI-Native Open RAN](https://arxiv.org/abs/2602.04652)
*Ryan Barker,Fatemeh Afghah*

Main category: cs.DC

TL;DR: 论文展示了将LDPC5G解码从CPU卸载到GPU的显著性能优势，同时释放了CPU资源。


<details>
  <summary>Details</summary>
Motivation: 5G NR物理层中的LDPC解码是一个计算密集型任务，必须在0.5ms内完成，而许多现有解决方案仍依赖通用CPU，可能导致性能瓶颈。

Method: 使用NVIDIA Sionna PHY/SYS在TensorFlow上构建了一个NR类似的链路级链，包括LDPC5G编码/解码器、16-QAM调制和AWGN，并测量了并行解码的码字数量和信念传播迭代次数。

Result: GPU相比CPU实现了约6倍的吞吐量提升，且GPU解码延迟保持在6-24%的时隙范围内，而CPU解码延迟可能超过0.5ms。

Conclusion: 通过将LDPC5G解码从Grace CPU卸载到Blackwell GB10 GPU，显著提升了性能并降低了延迟，同时释放了CPU资源供更高层任务使用。

Abstract: Low-density parity-check (LDPC) decoding is one of the most computationally intensive kernels in the 5G New Radio (NR) physical layer and must complete within a 0.5\,ms transmission time interval while sharing the budget with FFT, channel estimation, demapping, HARQ, and MAC scheduling. Many open and proprietary stacks still execute LDPC on general-purpose CPUs, raising concerns about missed-slot events and limited scalability as bandwidths, modulation orders, and user multiplexing increase. This paper empirically quantifies the benefit of offloading 5G-style LDPC5G decoding from a Grace CPU to the integrated Blackwell GB10 GPU on an NVIDIA DGX~Spark platform. Using NVIDIA Sionna PHY/SYS on TensorFlow, we construct an NR-like link-level chain with an LDPC5G encoder/decoder, 16-QAM modulation, and AWGN, and sweep both the number of codewords decoded in parallel and the number of belief-propagation iterations, timing only the decoding phase while logging CPU and GPU utilization and power. Across the sweep we observe an average GPU/CPU throughput speedup of approximately $6\times$, with per-codeword CPU latency reaching $\approx 0.71$\,ms at 20 iterations (exceeding the 0.5\,ms slot), while the GB10 GPU remains within 6--24\% of the slot for the same workloads. Resource-usage measurements show that CPU-based LDPC decoding often consumes around ten Grace cores, whereas GPU-based decoding adds only $\approx10-15$\,W over GPU idle while leaving most CPU capacity available for higher-layer tasks. Because our implementation relies on high-level Sionna layers rather than hand-tuned CUDA, these results represent conservative lower bounds on achievable accelerator performance and provide a reusable, scriptable methodology for evaluating LDPC and other physical-layer kernels on future Grace/Blackwell and Aerial/ACAR/AODT platforms.

</details>


### [128] [A TEE-based Approach for Preserving Data Secrecy in Process Mining with Decentralized Sources](https://arxiv.org/abs/2602.04697)
*Davide Basile,Valerio Goretti,Luca Barbaro,Hajo A. Reijers,Claudio Di Ciccio*

Main category: cs.DC

TL;DR: CONFINE 是一种基于 TEEs 的跨组织流程挖掘方法，解决了数据机密性问题，并通过分段策略优化内存使用。


<details>
  <summary>Details</summary>
Motivation: 跨组织流程挖掘面临数据机密性挑战，传统方法无法满足多方数据共享的需求。

Method: 利用可信执行环境（TEEs）部署可信应用程序，采用四阶段协议确保数据交换和处理的安全性，并通过分段策略避免内存溢出。

Result: 实验证明 CONFINE 能处理实际工作负载，内存增长与事件日志大小呈对数关系，与组织数量呈线性关系。

Conclusion: CONFINE 提供了一种安全且可扩展的解决方案，用于跨组织流程挖掘，同时保护数据机密性。

Abstract: Process mining techniques enable organizations to gain insights into their business processes through the analysis of execution records (event logs) stored by information systems. While most process mining efforts focus on intra-organizational scenarios, many real-world business processes span multiple independent organizations. Inter-organizational process mining, though, faces significant challenges, particularly regarding confidentiality guarantees: The analysis of data can reveal information that the participating organizations may not consent to disclose to one another, or to a third party hosting process mining services. To overcome this issue, this paper presents CONFINE, an approach for secrecy-preserving inter-organizational process mining. CONFINE leverages Trusted Execution Environments (TEEs) to deploy trusted applications that are capable of securely mining multi-party event logs while preserving data secrecy. We propose an architecture supporting a four-stage protocol to secure data exchange and processing, allowing for protected transfer and aggregation of unaltered process data across organizational boundaries. To avoid out-of-memory errors due to the limited capacity of TEEs, our protocol employs a segmentation-based strategy, whereby event logs are transmitted to TEEs in smaller batches. We conduct a formal verification of correctness and a security analysis of the guarantees provided by the TEE core. We evaluate our implementation on real-world and synthetic data, showing that the proposed approach can handle realistic workloads. The results indicate logarithmic memory growth with respect to the event log size and linear growth with the number of provisioning organizations, highlighting scalability properties and opportunities for further optimization.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [129] [Less is More: Optimizing Probe Selection Using Shared Latency Anomalies](https://arxiv.org/abs/2602.03965)
*Taveesh Sharma,Andrew Chu,Paul Schmitt,Francesco Bronzino,Nick Feamster,Nicole Marwell*

Main category: cs.NI

TL;DR: 该研究通过拓扑无关方法分析住宅互联网中的共享延迟异常，发现异常幅度在同一ISP内具有相似性，并设计了一种高效采样算法，显著提高了异常检测的覆盖率和效率。


<details>
  <summary>Details</summary>
Motivation: 住宅互联网性能中常见的延迟异常（RTT增加）可能反映共享基础设施、路由行为或拥塞。推断这种共享行为具有挑战性，因为异常幅度在不同设备间差异很大，且详细的网络拓扑信息通常不可用。

Method: 采用了一种拓扑无关的方法，利用四个月内来自芝加哥99个住宅探测器的高频RTT测量数据，检测共享异常并分析其幅度和持续时间的一致性。基于先前的变化点检测技术，设计了一种采样算法以减少冗余。

Result: 研究发现许多共享异常在用户间表现出相似的幅度，尤其是在同一ISP内。设计的采样算法在用户定义约束下选择代表性设备，捕获了95%的聚合异常影响，同时使用不到一半的探测器。

Conclusion: 研究结果表明，异常幅度和持续时间提供了有效的拓扑无关信号，可用于住宅互联网测量的可扩展监控、故障排除和成本效益采样。

Abstract: Latency anomalies, defined as persistent or transient increases in round-trip time (RTT), are common in residential Internet performance. When multiple users observe anomalies to the same destination, this may reflect shared infrastructure, routing behavior, or congestion. Inferring such shared behavior is challenging because anomaly magnitudes vary widely across devices, even within the same ISP and geographic area, and detailed network topology information is often unavailable.
  We study whether devices experiencing a shared latency anomaly observe similar changes in RTT magnitude using a topology-agnostic approach. Using four months of high-frequency RTT measurements from 99 residential probes in Chicago, we detect shared anomalies and analyze their consistency in amplitude and duration without relying on traceroutes or explicit path information. Building on prior change-point detection techniques, we find that many shared anomalies exhibit similar amplitude across users, particularly within the same ISP.
  Motivated by this observation, we design a sampling algorithm that reduces redundancy by selecting representative devices under user-defined constraints. Our approach captures 95 percent of aggregate anomaly impact using fewer than half of the deployed probes. Compared to two baselines, it identifies significantly more unique anomalies at comparable coverage levels. We further show that geographic diversity remains important when selecting probes within a single ISP, even at city scale. Overall, our results demonstrate that anomaly amplitude and duration provide effective topology-independent signals for scalable monitoring, troubleshooting, and cost-efficient sampling in residential Internet measurement.

</details>


### [130] [Multi-Tier UAV Edge Computing Towards Long-Term Energy Stability for Low Altitude Networks](https://arxiv.org/abs/2602.04258)
*Yufei Ye,Shijian Gao,Xinhu Zheng,Liuqing Yang*

Main category: cs.NI

TL;DR: 提出多层级无人机边缘计算系统，通过优化算法降低任务延迟并提升能源稳定性，仿真显示传输能耗减少26%。


<details>
  <summary>Details</summary>
Motivation: 利用无人机的敏捷性构建低空边缘计算系统，解决车辆用户在未知系统状态下的任务延迟和L-UAV长期能源稳定问题。

Method: 采用Lyapunov优化将问题解耦，动态平衡任务延迟和L-UAV能源成本，设计了车辆与L-UAV匹配方案，并通过BCD算法联合优化任务分配、计算资源分配和无人机轨迹控制。

Result: 仿真结果表明，系统能减少L-UAV传输能耗26%以上，并在能源稳定性上优于现有基准。

Conclusion: 该论文提出的多层级无人机边缘计算系统通过Lyapunov优化和BCD算法，有效降低了任务执行延迟并提升了L-UAV的能源稳定性，仿真结果显示传输能耗降低超过26%。

Abstract: The agile mobility of Unmanned Aerial Vehicles (UAVs) makes them ideal for low-altitude edge computing. This paper proposes a novel multi-tier UAV edge computing system where lightweight Low-Tier UAVs (L-UAVs) function as edge servers for vehicle users, supported by a powerful High-Tier UAV (H-UAV) acting as a backup server. The objective is to minimize task execution delays while ensuring the long-term energy stability of the L-UAVs, despite unknown future system states. To this end, the problem is decoupled using Lyapunov optimization, which adaptively balances the priorities of task delays and L-UAV energy cost based on their real-time energy states. An efficient vehicle to L-UAV matching scheme is designed, and the joint optimization problem for task assignment, computing resource allocation, and trajectory control of L-UAVs and H-UAV is then solved via a Block Coordinate Descent (BCD) algorithm. Simulation results demonstrate a reduction in L-UAV transmission energy of over 26% and superior L-UAV energy stability compared to existing benchmarks.

</details>


### [131] [LLM-Empowered Cooperative Content Caching in Vehicular Fog Caching-Assisted Platoon Networks](https://arxiv.org/abs/2602.04471)
*Bowen Tan,Qiong Wu,Pingyi Fan,Kezhi Wang,Nan Cheng,Wen Chen*

Main category: cs.NI

TL;DR: 提出基于LLMs的三层次车联网缓存架构，通过智能决策优化存储分布，显著降低检索延迟。


<details>
  <summary>Details</summary>
Motivation: 为车联网（VFC）辅助的排车队设计高效缓存架构，通过协调本地车辆、动态VFC集群和云服务器存储，最小化内容检索延迟。

Method: 利用大语言模型（LLMs）处理异构信息，设计提示框架编码任务目标和缓存约束，实现自适应请求预测和精确内容放置。

Result: 仿真结果表明，所提出的缓存方案在降低延迟方面具有优势。

Conclusion: 所提出的三层次内容缓存架构结合LLMs智能决策，显著降低了内容检索延迟，并通过仿真验证了其优势。

Abstract: This letter proposes a novel three-tier content caching architecture for Vehicular Fog Caching (VFC)-assisted platoon, where the VFC is formed by the vehicles driving near the platoon. The system strategically coordinates storage across local platoon vehicles, dynamic VFC clusters, and cloud server (CS) to minimize content retrieval latency. To efficiently manage distributed storage, we integrate large language models (LLMs) for real-time and intelligent caching decisions. The proposed approach leverages LLMs' ability to process heterogeneous information, including user profiles, historical data, content characteristics, and dynamic system states. Through a designed prompting framework encoding task objectives and caching constraints, the LLMs formulate caching as a decision-making task, and our hierarchical deterministic caching mapping strategy enables adaptive requests prediction and precise content placement across three tiers without frequent retraining. Simulation results demonstrate the advantages of our proposed caching scheme.

</details>


### [132] [Dual Mind World Model Inspired Network Digital Twin for Access Scheduling](https://arxiv.org/abs/2602.04566)
*Hrishikesh Dutta,Roberto Minerva,Noel Crespi*

Main category: cs.NI

TL;DR: 提出了一种基于数字孪生的DMWM调度框架，结合预测规划和模型推出，适用于动态网络环境，性能优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 工业物联网和实时网络物理基础设施等新兴网络系统需要能够适应动态流量、截止时间和干扰约束的智能调度策略。

Method: 结合短时域预测规划和基于符号模型的推出，DMWM框架通过学习驱动和想象力驱动的网络控制，实现智能调度。

Result: 在可变流量条件下，DMWM在突发性、干扰受限和截止时间敏感的环境中表现出卓越性能，同时保持可解释性和样本效率。

Conclusion: 本文提出的DMWM调度框架在网络优化中实现了可扩展性和适应性，填补了网络级推理与低开销学习之间的鸿沟。

Abstract: Emerging networked systems such as industrial IoT and real-time cyber-physical infrastructures demand intelligent scheduling strategies capable of adapting to dynamic traffic, deadlines, and interference constraints. In this work, we present a novel Digital Twin-enabled scheduling framework inspired by Dual Mind World Model (DMWM) architecture, for learning-informed and imagination-driven network control. Unlike conventional rule-based or purely data-driven policies, the proposed DMWM combines short-horizon predictive planning with symbolic model-based rollout, enabling the scheduler to anticipate future network states and adjust transmission decisions accordingly. We implement the framework in a configurable simulation testbed and benchmark its performance against traditional heuristics and reinforcement learning baselines under varied traffic conditions. Our results show that DMWM achieves superior performance in bursty, interference-limited, and deadline-sensitive environments, while maintaining interpretability and sample efficiency. The proposed design bridges the gap between network-level reasoning and low-overhead learning, marking a step toward scalable and adaptive NDT-based network optimization.

</details>


### [133] [On Dual Connectivity in 6G Leo Constellations](https://arxiv.org/abs/2602.04825)
*Achilles Machumilane,Alberto Gotta*

Main category: cs.NI

TL;DR: 本文提出一个数学框架，用于计算双连接中数据包复制、交换或网络编码时的平均数据包丢失率，以优化策略并避免资源浪费。


<details>
  <summary>Details</summary>
Motivation: 在5G演进中，双连接（DC）通过利用两条路径的信道条件来增强吞吐量和可靠性，但路径延迟差异可能导致数据包重排序或触发拥塞控制机制，实时流量可能因超过播放阈值而丢失。现有技术如数据包复制、交换和网络编码若设计不当会导致资源浪费和延迟。

Method: 通过离散马尔可夫链模型（典型的无线信道模型）来建模丢失过程，并计算平均端到端数据包丢失率。

Result: 提出了一个数学框架，用于量化DC中不同技术组合下的数据包丢失率，为优化策略提供理论支持。

Conclusion: 本文提出了一个数学框架，用于计算在双连接（DC）中结合数据包复制和数据包交换或使用网络编码时的平均端到端数据包丢失率。这些指标有助于在完全了解底层丢失过程的情况下推导出最优策略，并与通过机器学习算法学习的经验模型进行比较。

Abstract: Dual connectivity (DC) has garnered significant attention in 5G evolution, allowing for enhancing throughput and reliability by leveraging the channel conditions of two paths. However, when the paths exhibit different delays, such as in terrestrial and non-terrestrial integrated networks with multi-orbit topologies or in networks characterized by frequent topology changes, like Low Earth Orbit (LEO) satellite constellations with different elevation angles, traffic delivery may experience packet reordering or triggering congestion control mechanisms. Additionally, real-time traffic may experience packet drops if their arrival exceeds a play-out threshold. Different techniques have been proposed to address these issues, such as packet duplication, packet switching, and network coding for traffic scheduling in DC. However, if not accurately designed, these techniques can lead to resource waste, encoding/decoding delays, and computational overhead, undermining DC's intended benefits. This paper provides a mathematical framework for calculating the average end-to-end packet loss in case of a loss process modeled with a Discrete Markov Chain - typical of a wireless channel - when combining packet duplication and packet switching or when network coding is employed in DC. Such metrics help derive optimal policies with full knowledge of the underlying loss process to be compared to empirical models learned through Machine Learning algorithms.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [134] [Beyond the Vehicle: Cooperative Localization by Fusing Point Clouds for GPS-Challenged Urban Scenarios](https://arxiv.org/abs/2602.03908)
*Kuo-Yi Chao,Ralph Rasshofer,Alois Christian Knoll*

Main category: cs.RO

TL;DR: 该论文提出了一种融合V2V和V2I数据的协同多传感器定位方法，结合点云注册SLAM算法，显著提升了城市环境中的车辆定位精度。


<details>
  <summary>Details</summary>
Motivation: 在城市环境中，GPS信号常常不可靠，因此需要一种更精确的车辆定位方法。

Method: 该方法融合了车辆间（V2V）和车辆与基础设施（V2I）系统的数据，并结合了点云注册的同步定位与建图（SLAM）算法。系统处理来自多种传感器模态的点云数据，包括车载LiDAR、立体相机以及部署在交叉路口的传感器。

Result: 通过利用基础设施共享数据，该方法在复杂且GPS噪声严重的城市场景中显著提升了定位精度和鲁棒性。

Conclusion: 该论文提出的协同多传感器和多模态定位方法显著提高了在GPS信号不可靠的复杂城市环境中的定位精度和鲁棒性。

Abstract: Accurate vehicle localization is a critical challenge in urban environments where GPS signals are often unreliable. This paper presents a cooperative multi-sensor and multi-modal localization approach to address this issue by fusing data from vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) systems. Our approach integrates cooperative data with a point cloud registration-based simultaneous localization and mapping (SLAM) algorithm. The system processes point clouds generated from diverse sensor modalities, including vehicle-mounted LiDAR and stereo cameras, as well as sensors deployed at intersections. By leveraging shared data from infrastructure, our method significantly improves localization accuracy and robustness in complex, GPS-noisy urban scenarios.

</details>


### [135] [How Users Understand Robot Foundation Model Performance through Task Success Rates and Beyond](https://arxiv.org/abs/2602.03920)
*Isaac Sheidlower,Jindan Huang,James Staley,Bingyu Wu,Qicong Chen,Reuben Aronson,Elaine Short*

Main category: cs.RO

TL;DR: 研究发现非专家用户能正确理解RFM的任务成功率（TSR），并重视失败案例等额外信息，同时希望获取历史数据和任务预测。


<details>
  <summary>Details</summary>
Motivation: 研究非机器人专家如何理解RFM评估中的性能信息，尤其是任务成功率（TSR）是否对新手同样直观有效。

Method: 通过一项研究，让用户查看真实的评估数据，包括TSR、失败案例描述和多个已发表RFM研究项目的视频。

Result: 非专家用户能够正确使用TSR信息，并重视其他未被充分报告的信息类型（如失败案例）。用户还希望获取历史评估数据和机器人对新任务的预测。

Conclusion: 非专家用户不仅能够以与专家预期一致的方式理解任务成功率（TSR），还高度评价其他信息类型（如失败案例），这些信息在RFM评估中通常未被充分报告。此外，用户希望获取RFM先前评估的真实数据以及机器人对新颖任务表现的估计。

Abstract: Robot Foundation Models (RFMs) represent a promising approach to developing general-purpose home robots. Given the broad capabilities of RFMs, users will inevitably ask an RFM-based robot to perform tasks that the RFM was not trained or evaluated on. In these cases, it is crucial that users understand the risks associated with attempting novel tasks due to the relatively high cost of failure. Furthermore, an informed user who understands an RFM's capabilities will know what situations and tasks the robot can handle. In this paper, we study how non-roboticists interpret performance information from RFM evaluations. These evaluations typically report task success rate (TSR) as the primary performance metric. While TSR is intuitive to experts, it is necessary to validate whether novices also use this information as intended. Toward this end, we conducted a study in which users saw real evaluation data, including TSR, failure case descriptions, and videos from multiple published RFM research projects. The results highlight that non-experts not only use TSR in a manner consistent with expert expectations but also highly value other information types, such as failure cases that are not often reported in RFM evaluations. Furthermore, we find that users want access to both real data from previous evaluations of the RFM and estimates from the robot about how well it will do on a novel task.

</details>


### [136] [VLS: Steering Pretrained Robot Policies via Vision-Language Models](https://arxiv.org/abs/2602.03973)
*Shuo Liu,Ishneet Sukhvinder Singh,Yiqing Xu,Jiafei Duan,Ranjay Krishna*

Main category: cs.RO

TL;DR: VLS 是一种无需训练的推理时间适应框架，通过视觉语言模型指导预训练策略适应分布外条件，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决预训练策略在训练-测试分布偏移下的失败问题，避免昂贵的重新训练或微调，实现推理时间的适应性调整。

Method: VLS 通过利用视觉语言模型合成轨迹可微分的奖励函数，指导去噪过程生成满足测试时空间和任务要求的动作轨迹。

Result: VLS 在 CALVIN 和 LIBERO-PRO 上分别实现了 31% 和 13% 的性能提升，并在真实机器人上展示了鲁棒的适应性。

Conclusion: Vision-Language Steering (VLS) 提供了一种无需训练的推理时间适应框架，显著提升了预训练扩散或流匹配策略在分布外条件下的表现，验证了其在模拟和真实环境中的有效性。

Abstract: Why do pretrained diffusion or flow-matching policies fail when the same task is performed near an obstacle, on a shifted support surface, or amid mild clutter? Such failures rarely reflect missing motor skills; instead, they expose a limitation of imitation learning under train-test shifts, where action generation is tightly coupled to training-specific spatial configurations and task specifications. Retraining or fine-tuning to address these failures is costly and conceptually misaligned, as the required behaviors already exist but cannot be selectively adapted at test time. We propose Vision-Language Steering (VLS), a training-free framework for inference-time adaptation of frozen generative robot policies. VLS treats adaptation as an inference-time control problem, steering the sampling process of a pretrained diffusion or flow-matching policy in response to out-of-distribution observation-language inputs without modifying policy parameters. By leveraging vision-language models to synthesize trajectory-differentiable reward functions, VLS guides denoising toward action trajectories that satisfy test-time spatial and task requirements. Across simulation and real-world evaluations, VLS consistently outperforms prior steering methods, achieving a 31% improvement on CALVIN and a 13% gain on LIBERO-PRO. Real-world deployment on a Franka robot further demonstrates robust inference-time adaptation under test-time spatial and semantic shifts. Project page: https://vision-language-steering.github.io/webpage/

</details>


### [137] [GenMRP: A Generative Multi-Route Planning Framework for Efficient and Personalized Real-Time Industrial Navigation](https://arxiv.org/abs/2602.04174)
*Chengzhang Wang,Chao Chen,Jun Tao,Tengfei Liu,He Bai,Song Wang,Longfei Xu,Kaikui Liu,Xiangxiang Chu*

Main category: cs.RO

TL;DR: GenMRP是一个生成式多路线规划框架，通过动态子网络和迭代生成解决了现有方法的效率与多样性问题，已成功应用于实际导航应用。


<details>
  <summary>Details</summary>
Motivation: 现有方法在个性化、路线多样性和大规模实时效率方面存在不足，GenMRP旨在解决这些局限性。

Method: GenMRP采用骨架到毛细血管的方法动态构建子网络，结合Link Cost Model和Dijkstra算法迭代生成路线，平衡质量与多样性。

Result: 实验表明GenMRP在离线和在线环境中均实现了最先进的性能和高效率。

Conclusion: GenMRP被成功部署在真实导航应用中，证明了其高效性和实用性，并公开了数据集以促进进一步研究。

Abstract: Existing industrial-scale navigation applications contend with massive road networks, typically employing two main categories of approaches for route planning. The first relies on precomputed road costs for optimal routing and heuristic algorithms for generating alternatives, while the second, generative methods, has recently gained significant attention. However, the former struggles with personalization and route diversity, while the latter fails to meet the efficiency requirements of large-scale real-time scenarios. To address these limitations, we propose GenMRP, a generative framework for multi-route planning. To ensure generation efficiency, GenMRP first introduces a skeleton-to-capillary approach that dynamically constructs a relevant sub-network significantly smaller than the full road network. Within this sub-network, routes are generated iteratively. The first iteration identifies the optimal route, while the subsequent ones generate alternatives that balance quality and diversity using the newly proposed correctional boosting approach. Each iteration incorporates road features, user historical sequences, and previously generated routes into a Link Cost Model to update road costs, followed by route generation using the Dijkstra algorithm. Extensive experiments show that GenMRP achieves state-of-the-art performance with high efficiency in both offline and online environments. To facilitate further research, we have publicly released the training and evaluation dataset. GenMRP has been fully deployed in a real-world navigation app, demonstrating its effectiveness and benefits.

</details>


### [138] [Efficient Long-Horizon Vision-Language-Action Models via Static-Dynamic Disentanglement](https://arxiv.org/abs/2602.03983)
*Weikang Qiu,Tinglin Huang,Aosong Feng,Rex Ying*

Main category: cs.RO

TL;DR: SD-VLA通过静态-动态令牌分离和KV缓存优化，显著提升VLA模型的效率和性能。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型因长时上下文限制和二次注意力复杂度导致推理效率低下，视觉信息中存在大量静态冗余。

Method: 提出SD-VLA框架，将视觉输入解耦为多级静态和动态令牌，并通过轻量级重缓存门机制优化KV缓存，减少冗余计算。

Result: 在长时依赖基准上成功率提升39.8%，推理速度提升2.26倍，SimperEnv基准提升3.9%。

Conclusion: SD-VLA框架通过分离视觉输入为静态和动态令牌，显著提升了VLA模型的推理效率和长时依赖建模能力，实现了更高的成功率和更快的推理速度。

Abstract: Vision-Language-Action (VLA) models have recently emerged as a promising paradigm for generalist robotic control. Built upon vision-language model (VLM) architectures, VLAs predict actions conditioned on visual observations and language instructions, achieving strong performance and generalization across tasks. However, VLAs face two major challenges: limited long-horizon context and inefficient inference due to the quadratic attention complexity and large parameter counts. Our work is motivated by the observation that much of the visual information in a trajectory remains static across timesteps (e.g., the background). Leveraging this property, we propose SD-VLA, a framework that disentangles visual inputs into multi-level static and dynamic tokens, which enables (1) retaining a single copy of static tokens across frames to significantly reduce context length, and (2) reusing the key-value (KV) cache of static tokens through a lightweight recache gate that updates only when necessary. This design enables efficient multi-frame integration and efficient inference. In addition, we introduce a new benchmark that more effectively evaluates the long-horizon temporal dependency modeling ability of VLAs. Experimental results show that our approach outperforms baselines on this benchmark by 39.8% absolute improvement in success rate, and achieves a 3.9% gain on the SimplerEnv benchmark. Moreover, SD-VLA delivers a 2.26x inference speedup over the base VLA model on the same benchmark, enabling faster and more practical real-world deployment.

</details>


### [139] [FDA Flocking: Future Direction-Aware Flocking via Velocity Prediction](https://arxiv.org/abs/2602.04012)
*Hossein B. Jond,Martin Saska*

Main category: cs.RO

TL;DR: FDA flocking模型结合反应性和预测性行为，提升群体协调性能，未来将探索自适应策略和实验验证。


<details>
  <summary>Details</summary>
Motivation: 受鸟类姿态和翼拍信号以及多旋翼飞行器姿态倾斜的启发，旨在解决现有反应性群体模型忽视预测性信号的问题。

Method: 提出了基于生物启发的Future Direction-Aware (FDA) flocking框架，通过可调混合参数将反应性对齐与基于邻居未来速度的短期预测相结合。

Result: 仿真结果表明，FDA模型在速度一致性、群体平移位移及对延迟和噪声的鲁棒性上均优于纯反应性模型。

Conclusion: FDA flocking模型通过结合反应性和预测性行为，显著提升了群体协调的速度、一致性以及对延迟和噪声的鲁棒性，未来工作将探索自适应混合策略和实验验证。

Abstract: Understanding self-organization in natural collectives such as bird flocks inspires swarm robotics, yet most flocking models remain reactive, overlooking anticipatory cues that enhance coordination. Motivated by avian postural and wingbeat signals, as well as multirotor attitude tilts that precede directional changes, this work introduces a principled, bio-inspired anticipatory augmentation of reactive flocking termed Future Direction-Aware (FDA) flocking. In the proposed framework, agents blend reactive alignment with a predictive term based on short-term estimates of neighbors' future velocities, regulated by a tunable blending parameter that interpolates between reactive and anticipatory behaviors. This predictive structure enhances velocity consensus and cohesion-separation balance while mitigating the adverse effects of sensing and communication delays and measurement noise that destabilize reactive baselines. Simulation results demonstrate that FDA achieves faster and higher alignment, enhanced translational displacement of the flock, and improved robustness to delays and noise compared to a purely reactive model. Future work will investigate adaptive blending strategies, weighted prediction schemes, and experimental validation on multirotor drone swarms.

</details>


### [140] [An Anatomy-specific Guidewire Shaping Robot for Improved Vascular Navigation](https://arxiv.org/abs/2602.04050)
*Aabha Tamhankar,Jay Patil,Giovanni Pittiglio*

Main category: cs.RO

TL;DR: 该论文介绍了一种自主塑造导丝形状的机器人系统，通过模型预测和实验验证，实现了高精度的导丝尖端塑形，适用于复杂的神经血管内介入手术。


<details>
  <summary>Details</summary>
Motivation: 神经血管内介入手术中，导丝的被动塑形依赖于外科医生的经验和技能，尤其在复杂的解剖结构中操作难度大。为了标准化和自动化这一过程，研究团队提出了自主塑形解决方案。

Method: 研究团队开发了一个台式导丝塑造机器人，能够根据导航需求生成特定的导丝形状。通过实验数据校准的模型将所需的导丝形状映射为机器人动作。

Result: 机器人能够生成临床常见的导丝尖端几何形状（C、S、角度、钩形），并在2D验证中与模型预测形状相比，均方根误差为0.56毫米。此外，还展示了3D尖端塑形能力及在复杂内腔导航中的成功应用。

Conclusion: 该论文提出了一种能够自主塑造导丝形状的机器人系统，通过实验数据校准的模型能够准确预测和实现临床常见的导丝尖端几何形状，并在复杂的内腔导航中验证了其有效性。

Abstract: Neuroendovascular access often relies on passive microwires that are hand-shaped at the back table and then used to track a microcatheter to the target. Neuroendovascular surgeons determine the shape of the wire by examining the patient pre-operative images and using their experience to identify anatomy specific shapes of the wire that would facilitate reaching the target. This procedure is particularly complex in convoluted anatomical structures and is heavily dependent on the level of expertise of the surgeon. Towards enabling standardized autonomous shaping, we present a bench-top guidewire shaping robot capable of producing navigation-specific desired wire configurations. We present a model that can map the desired wire shape into robot actions, calibrated using experimental data. We show that the robot can produce clinically common tip geometries (C, S, Angled, Hook) and validate them with respect to the model-predicted shapes in 2D. Our model predicts the shape with a Root Mean Square (RMS) error of 0.56mm across all shapes when compared to the experimental results. We also demonstrate 3D tip shaping capabilities and the ability to traverse complex endoluminal navigation from the petrous Internal Carotid Artery (ICA) to the Posterior Communicating Artery (PComm).

</details>


### [141] [Control and State Estimation of Vehicle-Mounted Aerial Systems in GPS-Denied, Non-Inertial Environments](https://arxiv.org/abs/2602.04057)
*Riming Xu,Obadah Wali,Yasmine Marani,Eric Feron*

Main category: cs.RO

TL;DR: A robust control framework using EKF-UI and external measurements improves quadrotor tracking in GNSS-denied, non-inertial environments without inertial feedback.


<details>
  <summary>Details</summary>
Motivation: Conventional estimators fail in GNSS-denied, non-inertial environments due to inability to distinguish quadrotor-induced accelerations from platform-induced ones, leading to drift and control degradation.

Method: The method combines external position measurements with an Extended Kalman Filter with Unknown Inputs (EKF-UI) to account for platform motion, paired with a cascaded PID controller for full 3D tracking.

Result: Experimental results show significant improvement in stability and trajectory tracking compared to standard EKF, validated in a moving-cart testbed under translational dissonance.

Conclusion: The proposed EKF-UI framework significantly enhances quadrotor stability and trajectory tracking in GNSS-denied, non-inertial environments without relying on inertial feedback, making it practical for deployment on moving platforms.

Abstract: We present a robust control and estimation framework for quadrotors operating in Global Navigation Satellite System(GNSS)-denied, non-inertial environments where inertial sensors such as Inertial Measurement Units (IMUs) become unreliable due to platform-induced accelerations. In such settings, conventional estimators fail to distinguish whether the measured accelerations arise from the quadrotor itself or from the non-inertial platform, leading to drift and control degradation. Unlike conventional approaches that depend heavily on IMU and GNSS, our method relies exclusively on external position measurements combined with a Extended Kalman Filter with Unknown Inputs (EKF-UI) to account for platform motion. The estimator is paired with a cascaded PID controller for full 3D tracking. To isolate estimator performance from localization errors, all tests are conducted using high-precision motion capture systems. Experimental results in a moving-cart testbed validate our approach under both translational in X-axis and Y-axis dissonance. Compared to standard EKF, the proposed method significantly improves stability and trajectory tracking without requiring inertial feedback, enabling practical deployment on moving platforms such as trucks or elevators.

</details>


### [142] [Comparative Analysis of Autonomous Robotic and Manual Techniques for Ultrasonic Sacral Osteotomy: A Preliminary Study](https://arxiv.org/abs/2602.04076)
*Daniyal Maroufi,Yash Kulkarni,Justin E. Bird,Jeffrey H. Siewerdsen,Farshid Alambeigi*

Main category: cs.RO

TL;DR: 机器人辅助超声骶骨截骨术系统在精度和深度控制上显著优于手动操作，为骶骨切除术提供了更安全、更精确的解决方案。


<details>
  <summary>Details</summary>
Motivation: 旨在解决手动骶骨截骨术中存在的轨迹精度不足和深度控制不稳定的问题。

Method: 研究通过将超声骨刀与七自由度机械臂集成，并利用光学跟踪系统引导，对比了手动超声骶骨截骨术（MUSO）和机器人辅助超声骶骨截骨术（RUSO）在相同条件下的表现。

Result: RUSO系统在轨迹精度上达到亚毫米级（0.11 mm RMSE），比MUSO（1.10 mm RMSE）提高了一个数量级；在深度控制上，RUSO系统实现了精确控制（8.1 mm），而MUSO则存在显著过穿透（16.0 mm vs. 8.0 mm目标）。

Conclusion: 该研究展示了机器人辅助超声骶骨截骨术（RUSO）系统在轨迹精度和深度控制上的显著优势，为更安全、更精确的骶骨切除术奠定了基础。

Abstract: In this paper, we introduce an autonomous Ultrasonic Sacral Osteotomy (USO) robotic system that integrates an ultrasonic osteotome with a seven-degree-of-freedom (DoF) robotic manipulator guided by an optical tracking system. To assess multi-directional control along both the surface trajectory and cutting depth of this system, we conducted quantitative comparisons between manual USO (MUSO) and robotic USO (RUSO) in Sawbones phantoms under identical osteotomy conditions. The RUSO system achieved sub-millimeter trajectory accuracy (0.11 mm RMSE), an order of magnitude improvement over MUSO (1.10 mm RMSE). Moreover, MUSO trials showed substantial over-penetration (16.0 mm achieved vs. 8.0 mm target), whereas the RUSO system maintained precise depth control (8.1 mm). These results demonstrate that robotic procedures can effectively overcome the critical limitations of manual osteotomy, establishing a foundation for safer and more precise sacral resections.

</details>


### [143] [KGLAMP: Knowledge Graph-guided Language model for Adaptive Multi-robot Planning and Replanning](https://arxiv.org/abs/2602.04129)
*Chak Lam Shek,Faizan M. Tariq,Sangjae Bae,David Isele,Piyush Gupta*

Main category: cs.RO

TL;DR: KGLAMP结合知识图谱和LLM规划，提升异构多机器人团队在动态环境中的规划性能，实验显示性能提升至少25.5%。


<details>
  <summary>Details</summary>
Motivation: 解决异构多机器人系统在长期任务中因动态环境和机器人多样性导致的规划不准确和一致性维护问题。

Method: KGLAMP框架利用知识图谱编码对象关系、空间可达性和机器人能力，指导LLM生成准确的PDDL问题描述，并通过动态更新的知识图谱来适应环境变化。

Result: 在MAT-THOR基准测试中，KGLAMP比纯LLM或PDDL方法性能提升至少25.5%。

Conclusion: KGLAMP框架通过结合知识图谱和LLM规划，显著提升了异构多机器人团队在动态环境中的规划性能，实验结果显示其性能比纯LLM或PDDL方法至少提高25.5%。

Abstract: Heterogeneous multi-robot systems are increasingly deployed in long-horizon missions that require coordination among robots with diverse capabilities. However, existing planning approaches struggle to construct accurate symbolic representations and maintain plan consistency in dynamic environments. Classical PDDL planners require manually crafted symbolic models, while LLM-based planners often ignore agent heterogeneity and environmental uncertainty. We introduce KGLAMP, a knowledge-graph-guided LLM planning framework for heterogeneous multi-robot teams. The framework maintains a structured knowledge graph encoding object relations, spatial reachability, and robot capabilities, which guides the LLM in generating accurate PDDL problem specifications. The knowledge graph serves as a persistent, dynamically updated memory that incorporates new observations and triggers replanning upon detecting inconsistencies, enabling symbolic plans to adapt to evolving world states. Experiments on the MAT-THOR benchmark show that KGLAMP improves performance by at least 25.5% over both LLM-only and PDDL-based variants.

</details>


### [144] [Shaping Expressiveness in Robotics: The Role of Design Tools in Crafting Embodied Robot Movements](https://arxiv.org/abs/2602.04137)
*Elisabetta Zibetti,Alexandra Mercader,Hélène Duval,Florent Levillain,Audrey Rochette,David St-Onge*

Main category: cs.RO

TL;DR: 本文提出了一种结合舞蹈分析框架的迭代设计方法，通过定制工具实现机器人手臂动作的表现力设计，有效提升了人机互动体验。


<details>
  <summary>Details</summary>
Motivation: 随着机器人越来越多地融入人类共享空间，其动作需超越基本功能，融入表现力以增强互动与沟通。

Method: 通过结合舞蹈的动态和具身维度分析框架，采用迭代设计方法，并利用定制的手动遥控器和专用动画软件进行实时操作与可视化。

Result: 定性分析表明，交互式设计过程中的‘工具箱’方法成功提升了机器人手臂动作的表现力。

Conclusion: 本文提出的‘工具箱’方法有效弥合了人类意图与机器人表现力之间的鸿沟，实现了更直观且富有吸引力的机器人手臂动作。

Abstract: As robots increasingly become part of shared human spaces, their movements must transcend basic functionality by incorporating expressive qualities to enhance engagement and communication. This paper introduces a movement-centered design pedagogy designed to support engineers in creating expressive robotic arm movements. Through a hands-on interactive workshop informed by interdisciplinary methodologies, participants explored various creative possibilities, generating valuable insights into expressive motion design. The iterative approach proposed integrates analytical frameworks from dance, enabling designers to examine motion through dynamic and embodied dimensions. A custom manual remote controller facilitates interactive, real-time manipulation of the robotic arm, while dedicated animation software supports visualization, detailed motion sequencing, and precise parameter control. Qualitative analysis of this interactive design process reveals that the proposed "toolbox" effectively bridges the gap between human intent and robotic expressiveness resulting in more intuitive and engaging expressive robotic arm movements.

</details>


### [145] [MA3DSG: Multi-Agent 3D Scene Graph Generation for Large-Scale Indoor Environments](https://arxiv.org/abs/2602.04152)
*Yirum Kim,Jaewoo Kim,Ue-Hwan Kim*

Main category: cs.RO

TL;DR: 提出首个多智能体3D场景图生成框架MA3DSG，通过无训练对齐算法实现高效合并，并建立可扩展的评估基准。


<details>
  <summary>Details</summary>
Motivation: 当前3D场景图生成方法依赖于单智能体假设和小规模环境，难以扩展到现实场景。

Method: 提出了一种无需训练的对齐算法，用于高效合并来自不同智能体的部分查询图。

Result: 开发了MA3DSG模型和MA3DSG-Bench基准，支持多样化的智能体配置和评估条件。

Conclusion: 该研究为可扩展的多智能体3D场景图生成研究奠定了坚实基础。

Abstract: Current 3D scene graph generation (3DSGG) approaches heavily rely on a single-agent assumption and small-scale environments, exhibiting limited scalability to real-world scenarios. In this work, we introduce Multi-Agent 3D Scene Graph Generation (MA3DSG) model, the first framework designed to tackle this scalability challenge using multiple agents. We develop a training-free graph alignment algorithm that efficiently merges partial query graphs from individual agents into a unified global scene graph. Leveraging extensive analysis and empirical insights, our approach enables conventional single-agent systems to operate collaboratively without requiring any learnable parameters. To rigorously evaluate 3DSGG performance, we propose MA3DSG-Bench-a benchmark that supports diverse agent configurations, domain sizes, and environmental conditions-providing a more general and extensible evaluation framework. This work lays a solid foundation for scalable, multi-agent 3DSGG research.

</details>


### [146] [A Modern System Recipe for Situated Embodied Human-Robot Conversation with Real-Time Multimodal LLMs and Tool-Calling](https://arxiv.org/abs/2602.04157)
*Dong Won Lee,Sarah Gillet,Louis-Philippe Morency,Cynthia Breazeal,Hae Won Park*

Main category: cs.RO

TL;DR: 研究提出了一种结合实时多模态语言模型和主动感知工具的系统，用于情境化具身对话，实验表明其在家庭场景中表现良好。


<details>
  <summary>Details</summary>
Motivation: 情境化具身对话要求机器人在严格的延迟约束下，将实时对话与主动感知交织在一起：决定看什么、何时看以及说什么。

Method: 提出了一个简单、最小的系统配方，将实时多模态语言模型与一小部分用于注意力和主动感知的工具接口配对。研究了六个家庭式场景，需要频繁的注意力转移和增加的感知范围。

Result: 评估了四种系统变体，针对人类注释的回合级工具决策正确性进行了评估，并收集了交互质量的主观评分。结果表明，实时多模态大型语言模型和主动感知工具的使用是一个有前途的方向。

Conclusion: 实时多模态大型语言模型与主动感知工具的使用是实用情境化具身对话的有前途方向。

Abstract: Situated embodied conversation requires robots to interleave real-time dialogue with active perception: deciding what to look at, when to look, and what to say under tight latency constraints. We present a simple, minimal system recipe that pairs a real-time multimodal language model with a small set of tool interfaces for attention and active perception. We study six home-style scenarios that require frequent attention shifts and increasing perceptual scope. Across four system variants, we evaluate turn-level tool-decision correctness against human annotations and collect subjective ratings of interaction quality. Results indicate that real-time multimodal large language models and tool use for active perception is a promising direction for practical situated embodied conversation.

</details>


### [147] [SCALE: Self-uncertainty Conditioned Adaptive Looking and Execution for Vision-Language-Action Models](https://arxiv.org/abs/2602.04208)
*Hyeonbeom Choi,Daechul Ahn,Youhan Lee,Taewook Kang,Seongwon Cho,Jonghyun Choi*

Main category: cs.RO

TL;DR: SCALE是一种无需额外训练的单次前向传播推理策略，通过联合调节视觉和动作提升VLA模型的鲁棒性，实验表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有TTS方法需要额外训练、验证器和多次前向传播，且仅干预动作解码而固定视觉表示，无法有效应对感知模糊性。

Method: 提出SCALE，一种基于‘自我不确定性’的推理策略，联合调节视觉感知和动作，无需额外训练或验证器，仅需单次前向传播。

Result: SCALE在模拟和真实世界基准测试中提升了VLA模型的性能，优于现有TTS方法，同时保持单次传播效率。

Conclusion: SCALE是一种无需额外训练、验证器且仅需单次前向传播的推理策略，通过联合调节视觉感知和动作来提升VLA模型的鲁棒性和适应性，实验证明其在模拟和真实世界基准测试中优于现有TTS方法。

Abstract: Vision-Language-Action (VLA) models have emerged as a promising paradigm for general-purpose robotic control, with test-time scaling (TTS) gaining attention to enhance robustness beyond training. However, existing TTS methods for VLAs require additional training, verifiers, and multiple forward passes, making them impractical for deployment. Moreover, they intervene only at action decoding while keeping visual representations fixed-insufficient under perceptual ambiguity, where reconsidering how to perceive is as important as deciding what to do. To address these limitations, we propose SCALE, a simple inference strategy that jointly modulates visual perception and action based on 'self-uncertainty', inspired by uncertainty-driven exploration in Active Inference theory-requiring no additional training, no verifier, and only a single forward pass. SCALE broadens exploration in both perception and action under high uncertainty, while focusing on exploitation when confident-enabling adaptive execution across varying conditions. Experiments on simulated and real-world benchmarks demonstrate that SCALE improves state-of-the-art VLAs and outperforms existing TTS methods while maintaining single-pass efficiency.

</details>


### [148] [ALORE: Autonomous Large-Object Rearrangement with a Legged Manipulator](https://arxiv.org/abs/2602.04214)
*Zhihai Bi,Yushan Zhang,Kai Chen,Guoyang Zhao,Yulin Li,Jun Ma*

Main category: cs.RO

TL;DR: ALORE是一种自主大型物体重排系统，通过分层强化学习和任务规划，高效重排多样物体，实验验证其鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 赋予机器人重排大型物体的能力以减轻人类工作负担，但面临多样物体交互和复杂环境中多物体高效重排的挑战。

Method: 采用分层强化学习训练管道，结合高层物体速度控制器和低层全身控制器，以及统一交互配置表示和物体速度估计器，同时使用任务与运动规划框架优化物体访问顺序和目标分配。

Result: 系统在策略泛化、物体速度跟踪准确性和多物体重排效率上优于基线，成功完成32把椅子近40分钟无失败重排，并在40米路线上实现长距离自主重排。

Conclusion: ALORE系统通过分层强化学习、统一交互配置表示和任务与运动规划框架，成功实现了对多样大型物体的高效、稳定重排，并在仿真和实际实验中验证了其鲁棒性和有效性。

Abstract: Endowing robots with the ability to rearrange various large and heavy objects, such as furniture, can substantially alleviate human workload. However, this task is extremely challenging due to the need to interact with diverse objects and efficiently rearrange multiple objects in complex environments while ensuring collision-free loco-manipulation. In this work, we present ALORE, an autonomous large-object rearrangement system for a legged manipulator that can rearrange various large objects across diverse scenarios. The proposed system is characterized by three main features: (i) a hierarchical reinforcement learning training pipeline for multi-object environment learning, where a high-level object velocity controller is trained on top of a low-level whole-body controller to achieve efficient and stable joint learning across multiple objects; (ii) two key modules, a unified interaction configuration representation and an object velocity estimator, that allow a single policy to regulate planar velocity of diverse objects accurately; and (iii) a task-and-motion planning framework that jointly optimizes object visitation order and object-to-target assignment, improving task efficiency while enabling online replanning. Comparisons against strong baselines show consistent superiority in policy generalization, object-velocity tracking accuracy, and multi-object rearrangement efficiency. Key modules are systematically evaluated, and extensive simulations and real-world experiments are conducted to validate the robustness and effectiveness of the entire system, which successfully completes 8 continuous loops to rearrange 32 chairs over nearly 40 minutes without a single failure, and executes long-distance autonomous rearrangement over an approximately 40 m route. The open-source packages are available at https://zhihaibi.github.io/Alore/.

</details>


### [149] [OAT: Ordered Action Tokenization](https://arxiv.org/abs/2602.04215)
*Chaoqi Liu,Xiaoshen Han,Jiawei Gao,Yue Zhao,Haonan Chen,Yilun Du*

Main category: cs.RO

TL;DR: OAT 是一种新的动作标记化方法，通过有序标记序列提升自回归策略的性能，在多个任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的动作标记化方法要么产生过长的标记序列，要么缺乏结构，限制了与下一标记预测的兼容性。

Method: OAT 通过使用带有寄存器的 transformer、有限标量量化和有序诱导训练机制，将动作块离散化为有序的标记序列。

Result: 在超过 20 个任务中，配备 OAT 的自回归策略一致优于先前的标记化方案和基于扩散的基线，同时在推理时提供了更大的灵活性。

Conclusion: Ordered Action Tokenization (OAT) 提供了一种高效的动作标记化方案，满足了高压缩、完全可解码和因果有序标记空间的三个需求，显著提升了自回归策略在机器人任务中的表现。

Abstract: Autoregressive policies offer a compelling foundation for scalable robot learning by enabling discrete abstraction, token-level reasoning, and flexible inference. However, applying autoregressive modeling to continuous robot actions requires an effective action tokenization scheme. Existing approaches either rely on analytical discretization methods that produce prohibitively long token sequences, or learned latent tokenizers that lack structure, limiting their compatibility with next-token prediction. In this work, we identify three desiderata for action tokenization - high compression, total decodability, and a left-to-right causally ordered token space - and introduce Ordered Action Tokenization (OAT), a learned action tokenizer that satisfies all three. OAT discretizes action chunks into an ordered sequence of tokens using transformer with registers, finite scalar quantization, and ordering-inducing training mechanisms. The resulting token space aligns naturally with autoregressive generation and enables prefix-based detokenization, yielding an anytime trade-off between inference cost and action fidelity. Across more than 20 tasks spanning four simulation benchmarks and real-world settings, autoregressive policies equipped with OAT consistently outperform prior tokenization schemes and diffusion-based baselines, while offering significantly greater flexibility at inference time.

</details>


### [150] [Reshaping Action Error Distributions for Reliable Vision-Language-Action Models](https://arxiv.org/abs/2602.04228)
*Shuanghao Bai,Dakai Wang,Cheng Chi,Wanqi Zhou,Jing Lyu,Xiaoguang Zhao,Pengwei Wang,Zhongyuan Wang,Lei Xing,Shanghang Zhang,Badong Chen*

Main category: cs.RO

TL;DR: 论文提出了一种基于最小误差熵（MEE）的连续动作VLA训练方法，显著提升了模型的成功率和鲁棒性，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有VLA框架主要依赖标准监督目标（如MSE），对个体预测施加强点约束，限制了模型的泛化能力和鲁棒性。

Method: 提出了一种轨迹级MEE目标函数及其两种加权变体，结合MSE用于连续动作VLA训练，并在多种VLA架构上进行了实验验证。

Result: 实验结果表明，MEE方法在标准、少样本和噪声设置下均能显著提升性能，且在真实机器人操作任务中表现优异。

Conclusion: 论文通过引入最小误差熵（MEE）目标函数，显著提升了连续动作VLA模型的成功率和鲁棒性，且在数据不平衡情况下仍保持优势，同时额外训练成本极低。

Abstract: In robotic manipulation, vision-language-action (VLA) models have emerged as a promising paradigm for learning generalizable and scalable robot policies. Most existing VLA frameworks rely on standard supervised objectives, typically cross-entropy for discrete actions and mean squared error (MSE) for continuous action regression, which impose strong pointwise constraints on individual predictions. In this work, we focus on continuous-action VLA models and move beyond conventional MSE-based regression by reshaping action error distributions during training. Drawing on information-theoretic principles, we introduce Minimum Error Entropy (MEE) into modern VLA architectures and propose a trajectory-level MEE objective, together with two weighted variants, combined with MSE for continuous-action VLA training. We evaluate our approaches across standard, few-shot, and noisy settings on multiple representative VLA architectures, using simulation benchmarks such as LIBERO and SimplerEnv as well as real-world robotic manipulation tasks. Experimental results demonstrate consistent improvements in success rates and robustness across these settings. Under imbalanced data regimes, the gains persist within a well-characterized operating range, while incurring negligible additional training cost and no impact on inference efficiency. We further provide theoretical analyses that explain why MEE-based supervision is effective and characterize its practical range. Project Page: https://cognition2actionlab.github.io/VLA-TMEE.github.io/

</details>


### [151] [GeoLanG: Geometry-Aware Language-Guided Grasping with Unified RGB-D Multimodal Learning](https://arxiv.org/abs/2602.04231)
*Rui Tang,Guankun Wang,Long Bai,Huxin Gao,Jiewen Lai,Chi Kit Ng,Jiazheng Wang,Fan Zhang,Hongliang Ren*

Main category: cs.RO

TL;DR: GeoLanG是一个端到端多任务框架，通过深度引导和自适应特征集成，提升了语言引导抓取在复杂场景中的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在多阶段流水线中分离对象感知和抓取，导致跨模态融合不足、计算冗余，且在复杂场景中泛化能力差。

Method: 基于CLIP架构构建的端到端多任务框架GeoLanG，结合深度引导几何模块（DGGM）和自适应密集通道集成（ADCI），实现了视觉与语言输入的共享表示空间和高效深度信息利用。

Result: 在OCID-VLG数据集及仿真和真实硬件实验中，GeoLanG在复杂、杂乱环境中实现了精确且鲁棒的语言引导抓取。

Conclusion: GeoLanG通过统一的视觉和语言表示空间以及深度引导的几何模块，显著提升了在复杂、遮挡或低纹理场景下的语言引导抓取性能，为现实世界中的人机交互提供了更可靠的解决方案。

Abstract: Language-guided grasping has emerged as a promising paradigm for enabling robots to identify and manipulate target objects through natural language instructions, yet it remains highly challenging in cluttered or occluded scenes. Existing methods often rely on multi-stage pipelines that separate object perception and grasping, which leads to limited cross-modal fusion, redundant computation, and poor generalization in cluttered, occluded, or low-texture scenes. To address these limitations, we propose GeoLanG, an end-to-end multi-task framework built upon the CLIP architecture that unifies visual and linguistic inputs into a shared representation space for robust semantic alignment and improved generalization. To enhance target discrimination under occlusion and low-texture conditions, we explore a more effective use of depth information through the Depth-guided Geometric Module (DGGM), which converts depth into explicit geometric priors and injects them into the attention mechanism without additional computational overhead. In addition, we propose Adaptive Dense Channel Integration, which adaptively balances the contributions of multi-layer features to produce more discriminative and generalizable visual representations. Extensive experiments on the OCID-VLG dataset, as well as in both simulation and real-world hardware, demonstrate that GeoLanG enables precise and robust language-guided grasping in complex, cluttered environments, paving the way toward more reliable multimodal robotic manipulation in real-world human-centric settings.

</details>


### [152] [Viewpoint Matters: Dynamically Optimizing Viewpoints with Masked Autoencoder for Visual Manipulation](https://arxiv.org/abs/2602.04243)
*Pengfei Yi,Yifan Han,Junyan Li,Litao Liu,Wenzhao Lian*

Main category: cs.RO

TL;DR: MAE-Select是一种新颖的主动视角选择框架，通过动态选择信息量最大的视角，提升单摄像头机器人系统的性能。


<details>
  <summary>Details</summary>
Motivation: 受人类主动感知的启发，旨在解决当前模仿学习方法因固定摄像头设置而导致的适应性和覆盖范围限制问题。

Method: 利用预训练的多视角掩码自编码器表示，动态选择每个时间块中最具信息量的下一个视角，无需标记视角。

Result: 大量实验表明，MAE-Select提升了单摄像头系统的能力，并在某些情况下超越了多摄像头设置。

Conclusion: MAE-Select框架通过动态选择最有信息量的视角，显著提升了单摄像头机器人系统的性能，甚至在某些情况下超越了多摄像头系统。

Abstract: Robotic manipulation continues to be a challenge, and imitation learning (IL) enables robots to learn tasks from expert demonstrations. Current IL methods typically rely on fixed camera setups, where cameras are manually positioned in static locations, imposing significant limitations on adaptability and coverage. Inspired by human active perception, where humans dynamically adjust their viewpoint to capture the most relevant and least noisy information, we propose MAE-Select, a novel framework for active viewpoint selection in single-camera robotic systems. MAE-Select fully leverages pre-trained multi-view masked autoencoder representations and dynamically selects the next most informative viewpoint at each time chunk without requiring labeled viewpoints. Extensive experiments demonstrate that MAE-Select improves the capabilities of single-camera systems and, in some cases, even surpasses multi-camera setups. The project will be available at https://mae-select.github.io.

</details>


### [153] [Towards Next-Generation SLAM: A Survey on 3DGS-SLAM Focusing on Performance, Robustness, and Future Directions](https://arxiv.org/abs/2602.04251)
*Li Wang,Ruixuan Gong,Yumo Han,Lei Yang,Lu Yang,Ying Li,Bin Xu,Huaping Liu,Rong Fu*

Main category: cs.RO

TL;DR: 综述探讨了3D高斯泼溅（3DGS）与SLAM集成的技术方法，分析了性能优化及鲁棒性增强，旨在推动高保真、高效、鲁棒的下一代SLAM系统发展。


<details>
  <summary>Details</summary>
Motivation: 传统SLAM系统在渲染质量、场景细节恢复和动态环境鲁棒性方面存在局限，3DGS的高效显式表示和高品质渲染能力为SLAM提供了新的重建范式。

Method: 全面回顾了将3D高斯泼溅（3DGS）与SLAM集成的关键技术方法，分析了代表性方法在渲染质量、跟踪精度、重建速度和内存消耗四个关键维度的性能优化，深入探讨了其设计原则和突破。

Result: 分析了3DGS-SLAM在复杂环境（如运动模糊和动态环境）中增强鲁棒性的方法，并讨论了该领域未来的挑战和发展趋势。

Conclusion: 本综述旨在为研究人员提供技术参考，促进下一代高保真、高效且鲁棒的SLAM系统的发展。

Abstract: Traditional Simultaneous Localization and Mapping (SLAM) systems often face limitations including coarse rendering quality, insufficient recovery of scene details, and poor robustness in dynamic environments. 3D Gaussian Splatting (3DGS), with its efficient explicit representation and high-quality rendering capabilities, offers a new reconstruction paradigm for SLAM. This survey comprehensively reviews key technical approaches for integrating 3DGS with SLAM. We analyze performance optimization of representative methods across four critical dimensions: rendering quality, tracking accuracy, reconstruction speed, and memory consumption, delving into their design principles and breakthroughs. Furthermore, we examine methods for enhancing the robustness of 3DGS-SLAM in complex environments such as motion blur and dynamic environments. Finally, we discuss future challenges and development trends in this area. This survey aims to provide a technical reference for researchers and foster the development of next-generation SLAM systems characterized by high fidelity, efficiency, and robustness.

</details>


### [154] [AppleVLM: End-to-end Autonomous Driving with Advanced Perception and Planning-Enhanced Vision-Language Models](https://arxiv.org/abs/2602.04256)
*Yuxuan Han,Kunyuan Wu,Qianyi Shao,Renxiang Xiao,Zilu Wang,Cansen Jiang,Yi Xiao,Liang Hu,Yunjiang Lou*

Main category: cs.RO

TL;DR: AppleVLM是一种增强感知与规划的VLM模型，通过多视角时空融合和BEV规划模态提升自动驾驶鲁棒性，实验验证其卓越性能。


<details>
  <summary>Details</summary>
Motivation: 现有基于VLM的端到端驾驶模型在车道感知、语言理解偏差和极端场景处理上存在不足，AppleVLM旨在解决这些问题。

Method: AppleVLM采用可变形Transformer机制融合多视角图像的空间-时间信息，并引入专门的规划模态编码BEV空间信息，结合层次化Chain-of-Thought微调的VLM解码器输出驾驶路径。

Result: 在CARLA基准测试中达到SOTA性能，并在复杂室外环境中成功实现真实AGV平台的端到端自动驾驶。

Conclusion: AppleVLM通过引入新颖的视觉编码器和规划策略编码器，显著提升了端到端自动驾驶的鲁棒性和泛化能力，并在CARLA基准测试和实际AGV平台上验证了其卓越性能。

Abstract: End-to-end autonomous driving has emerged as a promising paradigm integrating perception, decision-making, and control within a unified learning framework. Recently, Vision-Language Models (VLMs) have gained significant attention for their potential to enhance the robustness and generalization of end-to-end driving models in diverse and unseen scenarios. However, existing VLM-based approaches still face challenges, including suboptimal lane perception, language understanding biases, and difficulties in handling corner cases. To address these issues, we propose AppleVLM, an advanced perception and planning-enhanced VLM model for robust end-to-end driving. AppleVLM introduces a novel vision encoder and a planning strategy encoder to improve perception and decision-making. Firstly, the vision encoder fuses spatial-temporal information from multi-view images across multiple timesteps using a deformable transformer mechanism, enhancing robustness to camera variations and facilitating scalable deployment across different vehicle platforms. Secondly, unlike traditional VLM-based approaches, AppleVLM introduces a dedicated planning modality that encodes explicit Bird's-Eye-View spatial information, mitigating language biases in navigation instructions. Finally, a VLM decoder fine-tuned by a hierarchical Chain-of-Thought integrates vision, language, and planning features to output robust driving waypoints. We evaluate AppleVLM in closed-loop experiments on two CARLA benchmarks, achieving state-of-the-art driving performance. Furthermore, we deploy AppleVLM on an AGV platform and successfully showcase real-world end-to-end autonomous driving in complex outdoor environments.

</details>


### [155] [GeneralVLA: Generalizable Vision-Language-Action Models with Knowledge-Guided Trajectory Planning](https://arxiv.org/abs/2602.04315)
*Guoqing Ma,Siheng Wang,Zeyu Zhang,Shan Yu,Hao Tang*

Main category: cs.RO

TL;DR: GeneralVLA通过分层VLA模型实现零样本操作，无需真实机器人数据或人类演示，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 大型基础模型在视觉和语言领域表现出强大的开放世界泛化能力，但在机器人领域尚未实现类似水平，主要挑战是零样本能力有限。

Method: 提出了一种分层视觉-语言-动作（VLA）模型GeneralVLA，包含高层ASM（感知场景图像关键点）、中层3DAgent（任务理解、技能知识和轨迹规划）和低层3D感知控制策略。

Result: GeneralVLA成功为14个任务生成轨迹，显著优于VoxPoser等方法，生成的演示数据比人类演示或其他方法生成的数据训练出的行为克隆策略更鲁棒。

Conclusion: GeneralVLA是一种可扩展的方法，既能生成机器人数据，也能在零样本设置下解决新任务。

Abstract: Large foundation models have shown strong open-world generalization to complex problems in vision and language, but similar levels of generalization have yet to be achieved in robotics. One fundamental challenge is that the models exhibit limited zero-shot capability, which hampers their ability to generalize effectively to unseen scenarios. In this work, we propose GeneralVLA (Generalizable Vision-Language-Action Models with Knowledge-Guided Trajectory Planning), a hierarchical vision-language-action (VLA) model that can be more effective in utilizing the generalization of foundation models, enabling zero-shot manipulation and automatically generating data for robotics. In particular, we study a class of hierarchical VLA model where the high-level ASM (Affordance Segmentation Module) is finetuned to perceive image keypoint affordances of the scene; the mid-level 3DAgent carries out task understanding, skill knowledge, and trajectory planning to produce a 3D path indicating the desired robot end-effector trajectory. The intermediate 3D path prediction is then served as guidance to the low-level, 3D-aware control policy capable of precise manipulation. Compared to alternative approaches, our method requires no real-world robotic data collection or human demonstration, making it much more scalable to diverse tasks and viewpoints. Empirically, GeneralVLA successfully generates trajectories for 14 tasks, significantly outperforming state-of-the-art methods such as VoxPoser. The generated demonstrations can train more robust behavior cloning policies than training with human demonstrations or from data generated by VoxPoser, Scaling-up, and Code-As-Policies. We believe GeneralVLA can be the scalable method for both generating data for robotics and solving novel tasks in a zero-shot setting. Code: https://github.com/AIGeeksGroup/GeneralVLA. Website: https://aigeeksgroup.github.io/GeneralVLA.

</details>


### [156] [Safe and Stylized Trajectory Planning for Autonomous Driving via Diffusion Model](https://arxiv.org/abs/2602.04329)
*Shuo Pei,Yong Wang,Yuanchen Zhu,Chen Sun,Qin Li,Yanan Zhao,Huachun Tan*

Main category: cs.RO

TL;DR: SDD Planner是一种扩散式轨迹规划框架，通过融合动态数据和环境上下文，实现了安全与驾驶风格的实时协调，实验表现优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决在复杂现实场景中实现安全且风格化的轨迹规划的关键挑战。

Method: 提出了SDD Planner，一个基于扩散的框架，包含多源风格感知编码器和风格引导动态轨迹生成器两个核心模块。

Result: 在StyleDrive基准测试中，SM-PDMS指标比最强基线WoTE提高了3.9%；在NuPlan Test14和Test14-hard基准测试中，分别以91.76和80.32的总分排名第一。

Conclusion: SDD Planner在保证高安全标准的同时，能够有效融合预设驾驶风格，验证了其在现实世界部署中的实际适用性。

Abstract: Achieving safe and stylized trajectory planning in complex real-world scenarios remains a critical challenge for autonomous driving systems. This paper proposes the SDD Planner, a diffusion-based framework designed to effectively reconcile safety constraints with driving styles in real time. The framework integrates two core modules: a Multi-Source Style-Aware Encoder, which employs distance-sensitive attention to fuse dynamic agent data and environmental contexts for heterogeneous safety-style perception; and a Style-Guided Dynamic Trajectory Generator, which adaptively modulates priority weights within the diffusion denoising process to generate user-preferred yet safe trajectories. Extensive experiments demonstrate that SDD Planner achieves state-of-the-art performance. On the StyleDrive benchmark, it improves the SM-PDMS metric by 3.9% over WoTE, the strongest baseline. Furthermore, on the NuPlan Test14 and Test14-hard benchmarks, SDD Planner ranks first with overall scores of 91.76 and 80.32, respectively, outperforming leading methods such as PLUTO. Real-vehicle closed-loop tests further confirm that SDD Planner maintains high safety standards while aligning with preset driving styles, validating its practical applicability for real-world deployment.

</details>


### [157] [Quantile Transfer for Reliable Operating Point Selection in Visual Place Recognition](https://arxiv.org/abs/2602.04401)
*Dhyey Manish Rajani,Michael Milford,Tobias Fischer*

Main category: cs.RO

TL;DR: 提出一种自动选择VPR系统操作点的方法，通过分位数归一化转移阈值，显著提升召回率并消除手动调优需求。


<details>
  <summary>Details</summary>
Motivation: 解决视觉地点识别（VPR）系统中因固定阈值导致的环境变化下性能下降问题，提出一种自动选择操作点的方法以平衡精确度和召回率。

Method: 利用带有已知对应关系的小型校准遍历，通过相似性得分分布的分位数归一化来转移阈值，确保阈值在校准大小和查询子集间保持稳定。

Result: 实验表明，该方法在多个先进VPR技术和数据集上表现优于现有技术，在高精度操作制度下召回率提升高达25%。

Conclusion: 该方法通过自动选择操作点，消除了手动调优的需求，并能适应新环境和不同操作条件，显著提高了在高精度操作制度下的召回率。

Abstract: Visual Place Recognition (VPR) is a key component for localisation in GNSS-denied environments, but its performance critically depends on selecting an image matching threshold (operating point) that balances precision and recall. Thresholds are typically hand-tuned offline for a specific environment and fixed during deployment, leading to degraded performance under environmental change. We propose a method that, given a user-defined precision requirement, automatically selects the operating point of a VPR system to maximise recall. The method uses a small calibration traversal with known correspondences and transfers thresholds to deployment via quantile normalisation of similarity score distributions. This quantile transfer ensures that thresholds remain stable across calibration sizes and query subsets, making the method robust to sampling variability. Experiments with multiple state-of-the-art VPR techniques and datasets show that the proposed approach consistently outperforms the state-of-the-art, delivering up to 25% higher recall in high-precision operating regimes. The method eliminates manual tuning by adapting to new environments and generalising across operating conditions. Our code will be released upon acceptance.

</details>


### [158] [HoRD: Robust Humanoid Control via History-Conditioned Reinforcement Learning and Online Distillation](https://arxiv.org/abs/2602.04412)
*Puyue Wang,Jiawei Hu,Yan Gao,Junyan Wang,Yu Zhang,Gillian Dobbie,Tao Gu,Wafa Johal,Ting Dang,Hong Jia*

Main category: cs.RO

TL;DR: HoRD通过两阶段学习框架（历史条件强化学习+在线蒸馏）提升人形机器人在动态变化下的鲁棒性，实现零样本适应。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人在动态、任务规范或环境设置微小变化下性能显著下降的问题。

Method: 采用两阶段学习框架：首先通过历史条件强化学习训练高性能教师策略，随后通过在线蒸馏将教师策略的鲁棒控制能力转移至基于Transformer的学生策略。

Result: 实验表明，HoRD在未见领域和外部扰动下的鲁棒性和迁移性能优于强基线方法。

Conclusion: HoRD框架通过结合历史条件适应和在线蒸馏，成功实现了在未见领域中的零样本适应，显著提升了人形机器人的鲁棒性和迁移能力。

Abstract: Humanoid robots can suffer significant performance drops under small changes in dynamics, task specifications, or environment setup. We propose HoRD, a two-stage learning framework for robust humanoid control under domain shift. First, we train a high-performance teacher policy via history-conditioned reinforcement learning, where the policy infers latent dynamics context from recent state--action trajectories to adapt online to diverse randomized dynamics. Second, we perform online distillation to transfer the teacher's robust control capabilities into a transformer-based student policy that operates on sparse root-relative 3D joint keypoint trajectories. By combining history-conditioned adaptation with online distillation, HoRD enables a single policy to adapt zero-shot to unseen domains without per-domain retraining. Extensive experiments show HoRD outperforms strong baselines in robustness and transfer, especially under unseen domains and external perturbations. Code and project page are available at \href{https://tonywang-0517.github.io/hord/}{https://tonywang-0517.github.io/hord/}.

</details>


### [159] [Integrated Exploration and Sequential Manipulation on Scene Graph with LLM-based Situated Replanning](https://arxiv.org/abs/2602.04419)
*Heqing Yang,Ziyuan Jiao,Shu Wang,Yida Niu,Si Liu,Hangxin Liu*

Main category: cs.RO

TL;DR: EPoG是一个结合探索与任务规划的框架，通过图规划和LLM实现高效操作，实验显示高成功率和低移动成本。


<details>
  <summary>Details</summary>
Motivation: 为了解决机器人在部分已知环境中结合探索与任务规划的挑战，以提高执行效率。

Method: EPoG整合了基于图的全局规划器和基于大型语言模型（LLM）的局部规划器，通过持续更新信念图来表示已知和未知对象，并生成动作序列。

Result: 在46个家庭场景和5个长时程物体运输任务中，EPoG实现了91.3%的成功率，平均减少了36.1%的移动距离。

Conclusion: EPoG框架在部分已知环境中成功结合了探索与任务规划，展示了在现实世界应用中的潜力，尤其是在动态和未知环境中。

Abstract: In partially known environments, robots must combine exploration to gather information with task planning for efficient execution. To address this challenge, we propose EPoG, an Exploration-based sequential manipulation Planning framework on Scene Graphs. EPoG integrates a graph-based global planner with a Large Language Model (LLM)-based situated local planner, continuously updating a belief graph using observations and LLM predictions to represent known and unknown objects. Action sequences are generated by computing graph edit operations between the goal and belief graphs, ordered by temporal dependencies and movement costs. This approach seamlessly combines exploration and sequential manipulation planning. In ablation studies across 46 realistic household scenes and 5 long-horizon daily object transportation tasks, EPoG achieved a success rate of 91.3%, reducing travel distance by 36.1% on average. Furthermore, a physical mobile manipulator successfully executed complex tasks in unknown and dynamic environments, demonstrating EPoG's potential for real-world applications.

</details>


### [160] [Gust Estimation and Rejection with a Disturbance Observer for Proprioceptive Underwater Soft Morphing Wings](https://arxiv.org/abs/2602.04438)
*Tobias Cook,Leo Micklem,Huazhi Dong,Yunjie Yang,Michael Mistry,Francesco Giorgio Serchi*

Main category: cs.RO

TL;DR: 受海洋生物启发，研究提出软变形翼结合本体感知传感技术，通过动态模型和曲率传感估计扰动，实验验证控制器可有效抑制升力扰动，提升水下机器人稳定性。


<details>
  <summary>Details</summary>
Motivation: 无人水下机器人在浅水区操作常受波浪、水流和湍流等流体动力扰动影响，导致速度和方向快速变化，影响稳定性和机动性。受海洋生物结合本体感知反馈与柔性鳍尾应对扰动的策略启发，提出软变形翼结合本体感知传感以减轻环境扰动。

Method: 开发并实验验证了一个液压驱动的软翼动态模型，具有可控弯度；利用基于曲率的传感技术准确估计攻角扰动。

Result: 实验证明，基于曲率的传感能准确估计攻角扰动；利用这些本体感知估计的控制器可有效抑制软翼升力响应中的扰动。

Conclusion: 通过结合本体感知传感与扰动观测器，该技术模仿了生物策略，为软体水下机器人在危险环境中保持稳定性提供了途径。

Abstract: Unmanned underwater vehicles are increasingly employed for maintenance and surveying tasks at sea, but their operation in shallow waters is often hindered by hydrodynamic disturbances such as waves, currents, and turbulence. These unsteady flows can induce rapid changes in direction and speed, compromising vehicle stability and manoeuvrability. Marine organisms contend with such conditions by combining proprioceptive feedback with flexible fins and tails to reject disturbances. Inspired by this strategy, we propose soft morphing wings endowed with proprioceptive sensing to mitigate environmental perturbations. The wing's continuous deformation provides a natural means to infer dynamic disturbances: sudden changes in camber directly reflect variations in the oncoming flow. By interpreting this proprioceptive signal, a disturbance observer can reconstruct flow parameters in real time. To enable this, we develop and experimentally validate a dynamic model of a hydraulically actuated soft wing with controllable camber. We then show that curvature-based sensing allows accurate estimation of disturbances in the angle of attack. Finally, we demonstrate that a controller leveraging these proprioceptive estimates can reject disturbances in the lift response of the soft wing. By combining proprioceptive sensing with a disturbance observer, this technique mirrors biological strategies and provides a pathway for soft underwater vehicles to maintain stability in hazardous environments.

</details>


### [161] [EgoActor: Grounding Task Planning into Spatial-aware Egocentric Actions for Humanoid Robots via Visual-Language Models](https://arxiv.org/abs/2602.04515)
*Yu Bai,MingMing Yu,Chaojie Li,Ziyi Bai,Xinlong Wang,Börje F. Karlsson*

Main category: cs.RO

TL;DR: EgoActor是一个视觉语言模型，通过多源监督学习，实现了人形机器人在复杂环境中的高效任务执行和泛化。


<details>
  <summary>Details</summary>
Motivation: 人形机器人在真实环境中的部署面临感知、运动和操作在部分信息观察和动态变化环境下的紧密集成挑战，以及在不同类型子任务间的稳健过渡。

Method: 提出了EgoActor，一个统一且可扩展的视觉语言模型（VLM），能够预测运动基元、头部动作、操作命令和人机交互，以实时协调感知与执行。

Result: 在模拟和真实环境中的广泛评估表明，EgoActor能够进行稳健、上下文感知的决策，并在1秒内流畅执行动作推断。

Conclusion: EgoActor成功地将抽象任务规划与具体运动执行相结合，并在多样任务和未见环境中展现出良好的泛化能力。

Abstract: Deploying humanoid robots in real-world settings is fundamentally challenging, as it demands tight integration of perception, locomotion, and manipulation under partial-information observations and dynamically changing environments. As well as transitioning robustly between sub-tasks of different types. Towards addressing these challenges, we propose a novel task - EgoActing, which requires directly grounding high-level instructions into various, precise, spatially aware humanoid actions. We further instantiate this task by introducing EgoActor, a unified and scalable vision-language model (VLM) that can predict locomotion primitives (e.g., walk, turn, move sideways, change height), head movements, manipulation commands, and human-robot interactions to coordinate perception and execution in real-time. We leverage broad supervision over egocentric RGB-only data from real-world demonstrations, spatial reasoning question-answering, and simulated environment demonstrations, enabling EgoActor to make robust, context-aware decisions and perform fluent action inference (under 1s) with both 8B and 4B parameter models. Extensive evaluations in both simulated and real-world environments demonstrate that EgoActor effectively bridges abstract task planning and concrete motor execution, while generalizing across diverse tasks and unseen environments.

</details>


### [162] [TACO: Temporal Consensus Optimization for Continual Neural Mapping](https://arxiv.org/abs/2602.04516)
*Xunlan Zhou,Hongrui Zhao,Negar Mehr*

Main category: cs.RO

TL;DR: TACO是一种无需重放历史数据的持续神经映射框架，通过时间共识优化实现内存效率与适应性的平衡，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有映射系统无法在严格的内存和计算限制下持续适应动态环境，且大多依赖重放历史观测并假设静态场景。

Method: TACO将过去的模型快照视为时间邻居，通过加权共识更新当前地图，允许可靠的历史几何约束优化，同时根据新观测修订不可靠或过时的区域。

Result: TACO在模拟和真实世界实验中均能稳健适应场景变化，并持续优于其他持续学习基线方法。

Conclusion: TACO（TemporAl Consensus Optimization）通过将映射问题重新定义为时间共识优化问题，提出了一种无需重放历史数据的持续神经映射框架，有效平衡了内存效率和适应性。

Abstract: Neural implicit mapping has emerged as a powerful paradigm for robotic navigation and scene understanding. However, real-world robotic deployment requires continual adaptation to changing environments under strict memory and computation constraints, which existing mapping systems fail to support. Most prior methods rely on replaying historical observations to preserve consistency and assume static scenes. As a result, they cannot adapt to continual learning in dynamic robotic settings. To address these challenges, we propose TACO (TemporAl Consensus Optimization), a replay-free framework for continual neural mapping. We reformulate mapping as a temporal consensus optimization problem, where we treat past model snapshots as temporal neighbors. Intuitively, our approach resembles a model consulting its own past knowledge. We update the current map by enforcing weighted consensus with historical representations. Our method allows reliable past geometry to constrain optimization while permitting unreliable or outdated regions to be revised in response to new observations. TACO achieves a balance between memory efficiency and adaptability without storing or replaying previous data. Through extensive simulated and real-world experiments, we show that TACO robustly adapts to scene changes, and consistently outperforms other continual learning baselines.

</details>


### [163] [A Unified Complementarity-based Approach for Rigid-Body Manipulation and Motion Prediction](https://arxiv.org/abs/2602.04522)
*Bingkun Huang,Xin Ma,Nilanjan Chakraborty,Riddhiman Laha*

Main category: cs.RO

TL;DR: 该论文提出Unicomp框架，统一建模自由运动和摩擦接触，通过互补性问题建模和最大功率耗散原理，实现实时优化规划，实验验证了其稳定性和物理一致性。


<details>
  <summary>Details</summary>
Motivation: 针对现有规划框架在非凸或分布式接触面建模中的简化表示问题，提出了一种统一的离散时间建模框架，以提升接触模式转换的保真度和实时执行的鲁棒性。

Method: 基于互补性刚体动力学，将自由运动和接触相互作用建模为耦合的线性和非线性互补问题，并针对平面接触推导了基于最大功率耗散原理的摩擦接触模型。

Result: 实验结果表明，该方法在平面推动和全身接触丰富任务中均能实现稳定且物理一致的行为。

Conclusion: 该论文提出的Unicomp框架通过统一的离散时间建模，成功实现了自由运动和摩擦接触的无缝结合，为实时优化规划提供了稳定的物理一致性行为。

Abstract: Robotic manipulation in unstructured environments requires planners to reason jointly about free-space motion and sustained, frictional contact with the environment. Existing (local) planning and simulation frameworks typically separate these regimes or rely on simplified contact representations, particularly when modeling non-convex or distributed contact patches. Such approximations limit the fidelity of contact-mode transitions and hinder the robust execution of contact-rich behaviors in real time. This paper presents a unified discrete-time modeling framework for robotic manipulation that consistently captures both free motion and frictional contact within a single mathematical formalism (Unicomp). Building on complementarity-based rigid-body dynamics, we formulate free-space motion and contact interactions as coupled linear and nonlinear complementarity problems, enabling principled transitions between contact modes without enforcing fixed-contact assumptions. For planar patch contact, we derive a frictional contact model from the maximum power dissipation principle in which the set of admissible contact wrenches is represented by an ellipsoidal limit surface. This representation captures coupled force-moment effects, including torsional friction, while remaining agnostic to the underlying pressure distribution across the contact patch. The resulting formulation yields a discrete-time predictive model that relates generalized velocities and contact wrenches through quadratic constraints and is suitable for real-time optimization-based planning. Experimental results show that the proposed approach enables stable, physically consistent behavior at interactive speeds across tasks, from planar pushing to contact-rich whole-body maneuvers.

</details>


### [164] [Act, Sense, Act: Learning Non-Markovian Active Perception Strategies from Large-Scale Egocentric Human Data](https://arxiv.org/abs/2602.04600)
*Jialiang Li,Yi Qiao,Yunhan Guo,Changwen Chen,Wenzhao Lian*

Main category: cs.RO

TL;DR: CoMe-VLA是一个认知记忆感知的VLA框架，通过整合人类自我中心数据和非马尔可夫主动感知，提升了机器人在复杂环境中的适应性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有主动感知方法局限于有限的传感行为类型，难以适应复杂环境。本文旨在通过信息增益和决策分支的非马尔可夫过程，提供视觉主动感知范式的结构化分类。

Method: 提出了CoMe-VLA框架，包括认知辅助头用于自主子任务转换和双轨记忆系统融合本体感知与视觉时序上下文。通过三个阶段渐进式训练，在轮式人形机器人上进行了广泛实验。

Result: 在多样化长时任务中，CoMe-VLA表现出强鲁棒性和适应性，覆盖多种主动感知场景。

Conclusion: CoMe-VLA框架通过整合认知辅助头和双轨记忆系统，展示了在多样化长时任务中的强鲁棒性和适应性。

Abstract: Achieving generalizable manipulation in unconstrained environments requires the robot to proactively resolve information uncertainty, i.e., the capability of active perception. However, existing methods are often confined in limited types of sensing behaviors, restricting their applicability to complex environments. In this work, we formalize active perception as a non-Markovian process driven by information gain and decision branching, providing a structured categorization of visual active perception paradigms. Building on this perspective, we introduce CoMe-VLA, a cognitive and memory-aware vision-language-action (VLA) framework that leverages large-scale human egocentric data to learn versatile exploration and manipulation priors. Our framework integrates a cognitive auxiliary head for autonomous sub-task transitions and a dual-track memory system to maintain consistent self and environmental awareness by fusing proprioceptive and visual temporal contexts. By aligning human and robot hand-eye coordination behaviors in a unified egocentric action space, we train the model progressively in three stages. Extensive experiments on a wheel-based humanoid have demonstrated strong robustness and adaptability of our proposed method across diverse long-horizon tasks spanning multiple active perception scenarios.

</details>


### [165] [Can We Redesign a Shoulder Exosuit to Enhance Comfort and Usability Without Losing Assistance?](https://arxiv.org/abs/2602.04625)
*Roberto Ferroni,Daniele Filippo Mauceri,Jacopo Carpaneto,Alessandra Pedrocchi,Tommaso Proietti*

Main category: cs.RO

TL;DR: 研究改进了软肩外骨骼设计，提升舒适性和功能性，适合长期使用。


<details>
  <summary>Details</summary>
Motivation: 肩部活动受限广泛影响上肢功能和日常生活活动。尽管舒适性对长期实际使用至关重要，但在可穿戴外骨骼设计中很少被明确优先考虑。

Method: 本研究重新设计了软肩外骨骼（Soft Shoulder v2），旨在解决先前版本中与舒适性相关的问题，同时保持辅助性能。改进包括将辅助平面从冠状面转向矢状面，以更好地支持功能性手部定位。在八名健康参与者中进行了静态保持、动态提升和功能性拾取放置任务的对照比较。

Result: 重新设计的模块促进了前臂定位，增加了横向平面活动度达30度，且未增加肌肉负担。用户反馈显示穿戴性显著改善，感知压力和舒适性评分明显优于先前设计。

Conclusion: 针对用户需求的设计改进可以提升舒适性和功能性交互，同时不损害辅助性能，推动了适合长期和日常使用的软外骨骼的发展。

Abstract: Reduced shoulder mobility limits upper-limb function and the performance of activities of daily living across a wide range of conditions. Wearable exosuits have shown promise in assisting arm elevation, reducing muscle effort, and supporting functional movements; however, comfort is rarely prioritized as an explicit design objective, despite it strongly affects real-life, long-term usage. This study presents a redesigned soft shoulder exosuit (Soft Shoulder v2) developed to address comfort-related limitations identified in our previous version, while preserving assistive performance. In parallel, assistance was also improved, shifting from the coronal plane to the sagittal plane to better support functionally relevant hand positioning. A controlled comparison between the previous (v1) and redesigned (v2) modules was conducted in eight healthy participants, who performed static holding, dynamic lifting, and a functional pick and place task. Muscle activity, kinematics, and user-reported outcomes were assessed. Both versions increased endurance time, reduced deltoid activation, and preserved transparency during unpowered shoulder elevation. However, the difference between them emerged most clearly during functional tasks and comfort evaluation. The redesigned module facilitated forward arm positioning and increased transverse plane mobility by up to 30 deg, without increasing muscular demand. User-reported outcomes further indicated a substantial improvement in wearability, with markedly lower perceived pressure and higher ratings in effectiveness, ease of use, and comfort compared to the previous design. Taken together, these findings show that targeted, user-centered design refinements can improve comfort and functional interaction without compromising assistive performance, advancing the development of soft exosuits suitable for prolonged and daily use.

</details>


### [166] [Radar-Inertial Odometry For Computationally Constrained Aerial Navigation](https://arxiv.org/abs/2602.04631)
*Jan Michalczyk*

Main category: cs.RO

TL;DR: 论文提出了一种低成本、实时的雷达-惯性里程计算法，通过融合IMU和雷达数据，提升无人机在极端环境中的导航能力，并利用深度学习优化雷达点云处理。


<details>
  <summary>Details</summary>
Motivation: 由于传统外感知传感器（如LiDAR、相机等）在极端环境（如强光、烟雾）中性能受限，而雷达对电磁波的特性使其对这些因素免疫，因此研究雷达-惯性融合算法以提升无人机在复杂环境中的自主导航能力。

Method: 采用多状态紧耦合扩展卡尔曼滤波（EKF）和因子图（FG）方法，融合FMCW雷达的瞬时速度和距离测量与IMU数据，并利用深度学习改进稀疏噪声雷达点云中的3D点对应关系。

Result: 提出的RIO算法能够在实时性和成本效益的前提下，有效估计无人机的导航状态，尤其在极端环境中表现优越。

Conclusion: 论文提出了一种新型的雷达-惯性里程计（RIO）算法，通过融合IMU和雷达数据，能够在资源受限的嵌入式设备上实时估计无人机的导航状态，且使用低成本传感器。

Abstract: Recently, the progress in the radar sensing technology consisting in the miniaturization of the packages and increase in measuring precision has drawn the interest of the robotics research community. Indeed, a crucial task enabling autonomy in robotics is to precisely determine the pose of the robot in space. To fulfill this task sensor fusion algorithms are often used, in which data from one or several exteroceptive sensors like, for example, LiDAR, camera, laser ranging sensor or GNSS are fused together with the Inertial Measurement Unit (IMU) measurements to obtain an estimate of the navigation states of the robot. Nonetheless, owing to their particular sensing principles, some exteroceptive sensors are often incapacitated in extreme environmental conditions, like extreme illumination or presence of fine particles in the environment like smoke or fog. Radars are largely immune to aforementioned factors thanks to the characteristics of electromagnetic waves they use. In this thesis, we present Radar-Inertial Odometry (RIO) algorithms to fuse the information from IMU and radar in order to estimate the navigation states of a (Uncrewed Aerial Vehicle) UAV capable of running on a portable resource-constrained embedded computer in real-time and making use of inexpensive, consumer-grade sensors. We present novel RIO approaches relying on the multi-state tightly-coupled Extended Kalman Filter (EKF) and Factor Graphs (FG) fusing instantaneous velocities of and distances to 3D points delivered by a lightweight, low-cost, off-the-shelf Frequency Modulated Continuous Wave (FMCW) radar with IMU readings. We also show a novel way to exploit advances in deep learning to retrieve 3D point correspondences in sparse and noisy radar point clouds.

</details>


### [167] [Relational Scene Graphs for Object Grounding of Natural Language Commands](https://arxiv.org/abs/2602.04635)
*Julia Kuhn,Francesco Verdoja,Tsvetomila Mihaylova,Ville Kyrki*

Main category: cs.RO

TL;DR: 本文探讨了在3D场景图中加入开放或封闭词汇空间关系是否能提升LLMs理解自然语言命令的能力，并提出了一种基于LLM和VLM的管道方法，验证了空间关系对对象定位任务的积极影响。


<details>
  <summary>Details</summary>
Motivation: 随着机器人在人类环境中的广泛应用，自然的人机交互需求日益增长。然而，理解自然语言命令需要机器人推断意图任务并将其分解为可执行动作，同时将这些动作与环境知识（包括相关对象、代理和位置）进行关联。现有的3DSGs缺乏明确的空间关系，而人类常常依赖这些关系来描述环境。

Method: 本文提出了一个基于LLM的管道，用于从开放词汇语言命令中定位目标对象，以及一个基于VLM的管道，用于从映射过程中捕获的图像向3D场景图（3DSGs）添加开放词汇空间边。随后，在两个LLMs上评估了它们在目标对象定位任务中的表现。

Result: 研究证明，明确的空间关系可以提升LLMs在对象定位任务中的表现。同时，通过VLM生成开放词汇空间关系是可行的，但其优势相对有限。

Conclusion: 研究表明，明确的空间关系可以提高大型语言模型（LLMs）在对象定位任务中的表现。此外，通过视觉语言模型（VLMs）从机器人捕获的图像中生成开放词汇空间关系是可行的，但其相对于封闭词汇关系的优势有限。

Abstract: Robots are finding wider adoption in human environments, increasing the need for natural human-robot interaction. However, understanding a natural language command requires the robot to infer the intended task and how to decompose it into executable actions, and to ground those actions in the robot's knowledge of the environment, including relevant objects, agents, and locations. This challenge can be addressed by combining the capabilities of Large language models (LLMs) to understand natural language with 3D scene graphs (3DSGs) for grounding inferred actions in a semantic representation of the environment. However, many 3DSGs lack explicit spatial relations between objects, even though humans often rely on these relations to describe an environment. This paper investigates whether incorporating open- or closed-vocabulary spatial relations into 3DSGs can improve the ability of LLMs to interpret natural language commands. To address this, we propose an LLM-based pipeline for target object grounding from open-vocabulary language commands and a vision language model (VLM)-based pipeline to add open-vocabulary spatial edges to 3DSGs from images captured while mapping. Finally, two LLMs are evaluated in a study assessing their performance on the downstream task of target object grounding. Our study demonstrates that explicit spatial relations improve the ability of LLMs to ground objects. Moreover, open-vocabulary relation generation with VLMs proves feasible from robot-captured images, but their advantage over closed-vocabulary relations is found to be limited.

</details>


### [168] [From Vision to Assistance: Gaze and Vision-Enabled Adaptive Control for a Back-Support Exoskeleton](https://arxiv.org/abs/2602.04648)
*Alessandro Leanza,Paolo Franceschi,Blerina Spahiu,Loris Roveda*

Main category: cs.RO

TL;DR: 该论文提出了一种基于视觉门控控制的主动腰部外骨骼框架，结合实时感知和自适应控制，显著提升了辅助效果和用户体验。


<details>
  <summary>Details</summary>
Motivation: 现有外骨骼辅助技术多依赖负载估计或视觉系统，但缺乏直接控制信息，因此需要一种更及时、上下文感知的辅助方法。

Method: 研究提出了一种结合第一人称视角的YOLO感知系统、有限状态机（FSM）和可变导纳控制器的视觉门控控制框架，用于实时抓取检测和任务进度管理。

Result: 用户研究表明，视觉门控辅助显著降低了感知体力需求，提升了流畅性、信任感和舒适度，定量分析显示视觉启用时辅助更早且更强。

Conclusion: 该研究展示了视觉门控控制框架在主动腰部职业外骨骼中的潜力，通过提升响应速度、人体工学、安全性和用户接受度，显著改善了外骨骼的辅助效果。

Abstract: Back-support exoskeletons have been proposed to mitigate spinal loading in industrial handling, yet their effectiveness critically depends on timely and context-aware assistance. Most existing approaches rely either on load-estimation techniques (e.g., EMG, IMU) or on vision systems that do not directly inform control. In this work, we present a vision-gated control framework for an active lumbar occupational exoskeleton that leverages egocentric vision with wearable gaze tracking. The proposed system integrates real-time grasp detection from a first-person YOLO-based perception system, a finite-state machine (FSM) for task progression, and a variable admittance controller to adapt torque delivery to both posture and object state. A user study with 15 participants performing stooping load lifting trials under three conditions (no exoskeleton, exoskeleton without vision, exoskeleton with vision) shows that vision-gated assistance significantly reduces perceived physical demand and improves fluency, trust, and comfort. Quantitative analysis reveals earlier and stronger assistance when vision is enabled, while questionnaire results confirm user preference for the vision-gated mode. These findings highlight the potential of egocentric vision to enhance the responsiveness, ergonomics, safety, and acceptance of back-support exoskeletons.

</details>


### [169] [Dull, Dirty, Dangerous: Understanding the Past, Present, and Future of a Key Motivation for Robotics](https://arxiv.org/abs/2602.04746)
*Nozomi Nakajima,Pedro Reynolds-Cuéllar,Caitrin Lynch,Kate Darling*

Main category: cs.RO

TL;DR: 本文分析了机器人学文献中DDD定义的不足，提出了一个框架以更全面地评估机器人技术对人类劳动的影响。


<details>
  <summary>Details</summary>
Motivation: 探讨机器人技术在‘枯燥、肮脏和危险’（DDD）工作中的潜在应用，并分析现有文献中DDD定义的不足。

Method: 通过对1980年至2024年提到DDD的机器人学出版物进行实证分析，并结合社会科学文献对‘枯燥’、‘肮脏’和‘危险’工作的定义进行综述。

Result: 研究发现，仅有2.7%的出版物明确定义了DDD，8.7%提供了具体的DDD任务或工作示例。

Conclusion: 本文提出了一个框架，帮助机器人技术社区更全面地考虑技术对人类劳动的影响，从而更明智地评估机器人技术的潜在影响。

Abstract: In robotics, the concept of "dull, dirty, and dangerous" (DDD) work has been used to motivate where robots might be useful. In this paper, we conduct an empirical analysis of robotics publications between 1980 and 2024 that mention DDD, and find that only 2.7% of publications define DDD and 8.7% of publications provide concrete examples of tasks or jobs that are DDD. We then review the social science literature on "dull," "dirty," and "dangerous" work to provide definitions and guidance on how to conceptualize DDD for robotics. Finally, we propose a framework that helps the robotics community consider the job context for our technology, encouraging a more informed perspective on how robotics may impact human labor.

</details>


### [170] [PDF-HR: Pose Distance Fields for Humanoid Robots](https://arxiv.org/abs/2602.04851)
*Yi Gu,Yukang Gao,Yangchen Zhou,Xingyu Chen,Yixiao Feng,Mingle Zhao,Yunyang Mo,Zhaorui Wang,Lixin Xu,Renjing Xu*

Main category: cs.RO

TL;DR: PDF-HR是一种轻量级先验模型，通过连续可微流形表示机器人姿态分布，显著提升多种人形机器人任务性能。


<details>
  <summary>Details</summary>
Motivation: 人形机器人领域缺乏高质量运动数据，导致姿态和运动先验的应用受限，亟需一种轻量级且通用的先验模型。

Method: 提出Pose Distance Fields for Humanoid Robots (PDF-HR)，将机器人姿态分布建模为连续可微的流形，通过预测任意姿态与大规模重定向机器人姿态的距离，提供平滑的姿态合理性度量。

Result: 在单轨迹运动跟踪、通用运动跟踪、基于风格的运动模仿及通用运动重定向等任务中，PDF-HR作为即插即用的先验，显著提升了基线模型的性能。

Conclusion: PDF-HR作为一种轻量级先验，通过连续可微的流形表示机器人姿态分布，显著提升了多种人形机器人任务的性能，代码和模型将开源。

Abstract: Pose and motion priors play a crucial role in humanoid robotics. Although such priors have been widely studied in human motion recovery (HMR) domain with a range of models, their adoption for humanoid robots remains limited, largely due to the scarcity of high-quality humanoid motion data. In this work, we introduce Pose Distance Fields for Humanoid Robots (PDF-HR), a lightweight prior that represents the robot pose distribution as a continuous and differentiable manifold. Given an arbitrary pose, PDF-HR predicts its distance to a large corpus of retargeted robot poses, yielding a smooth measure of pose plausibility that is well suited for optimization and control. PDF-HR can be integrated as a reward shaping term, a regularizer, or a standalone plausibility scorer across diverse pipelines. We evaluate PDF-HR on various humanoid tasks, including single-trajectory motion tracking, general motion tracking, style-based motion mimicry, and general motion retargeting. Experiments show that this plug-and-play prior consistently and substantially strengthens strong baselines. Code and models will be released.

</details>


### [171] [Capturing Visual Environment Structure Correlates with Control Performance](https://arxiv.org/abs/2602.04880)
*Jiahua Dong,Yunze Man,Pavel Tokmakov,Yu-Xiong Wang*

Main category: cs.RO

TL;DR: 本文提出通过分析预训练视觉编码器解码环境状态的能力来评估其性能，发现这与策略性能强相关，为通用机器人操作提供了新见解。


<details>
  <summary>Details</summary>
Motivation: 评估视觉表示对扩展通用机器人策略的重要性，现有代理指标在捕捉视觉世界的狭窄方面（如物体形状）限制了跨环境的泛化能力。

Method: 通过测量预训练视觉编码器对从图像解码环境状态（包括几何、物体结构和物理属性）的支持程度来分析其性能。

Result: 探测精度与跨多样环境和学习设置的下游策略性能强相关，显著优于现有指标，并能高效选择表示。

Conclusion: 学习编码环境的潜在物理状态是支持通用机器人操作的有前景的目标。

Abstract: The choice of visual representation is key to scaling generalist robot policies. However, direct evaluation via policy rollouts is expensive, even in simulation. Existing proxy metrics focus on the representation's capacity to capture narrow aspects of the visual world, like object shape, limiting generalization across environments. In this paper, we take an analytical perspective: we probe pretrained visual encoders by measuring how well they support decoding of environment state -- including geometry, object structure, and physical attributes -- from images. Leveraging simulation environments with access to ground-truth state, we show that this probing accuracy strongly correlates with downstream policy performance across diverse environments and learning settings, significantly outperforming prior metrics and enabling efficient representation selection. More broadly, our study provides insight into the representational properties that support generalizable manipulation, suggesting that learning to encode the latent physical state of the environment is a promising objective for control.

</details>


<div id='cs.OS'></div>

# cs.OS [[Back]](#toc)

### [172] [Horizon-LM: A RAM-Centric Architecture for LLM Training](https://arxiv.org/abs/2602.04816)
*Zhengqing Yuan,Lichao Sun,Yanfang,Ye*

Main category: cs.OS

TL;DR: Horizon-LM是一种内存中心训练系统，通过CPU为主、GPU为辅的执行模型，显著提升单节点大模型训练效率，突破GPU内存限制。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）的快速增长超过了单GPU硬件的演进，模型规模日益受限于内存容量而非计算能力。现有训练系统虽通过分布式并行和跨CPU及存储层卸载扩展GPU内存，但仍保持GPU为中心的范式，导致扩展大模型紧密依赖多GPU集群、复杂分布式运行时和不可预测的主机内存消耗。

Method: Horizon-LM采用CPU为主、GPU为辅的执行模型，消除持久GPU驻留模块和自动梯度图，通过显式重计算和手动梯度传播，引入流水线双缓冲执行引擎。

Result: 在配备1.5TB主机RAM的单个H200 GPU上，Horizon-LM可靠训练高达120B参数的模型。在标准单A100机器上，比DeepSpeed ZeRO-3 CPU卸载实现高达12.2倍的训练吞吐量提升，同时保持数值正确性。

Conclusion: Horizon-LM通过重新定义CPU和GPU在大模型优化中的角色，证明了主机内存而非GPU内存才是节点规模大模型训练的可行性边界。

Abstract: The rapid growth of large language models (LLMs) has outpaced the evolution of single-GPU hardware, making model scale increasingly constrained by memory capacity rather than computation. While modern training systems extend GPU memory through distributed parallelism and offloading across CPU and storage tiers, they fundamentally retain a GPU-centric execution paradigm in which GPUs host persistent model replicas and full autograd graphs. As a result, scaling large models remains tightly coupled to multi-GPU clusters, complex distributed runtimes, and unpredictable host memory consumption, creating substantial barriers for node-scale post-training workloads such as instruction tuning, alignment, and domain adaptation. We present Horizon-LM, a memory-centric training system that redefines the roles of CPU and GPU for large-model optimization. Horizon-LM treats host memory as the authoritative parameter store and uses GPUs solely as transient compute engines through a CPU-master, GPU-template execution model. By eliminating persistent GPU-resident modules and autograd graphs, employing explicit recomputation with manual gradient propagation, and introducing a pipelined double-buffered execution engine, Horizon-LM decouples model scale from GPU count and bounds memory usage to the theoretical parameter footprint. On a single H200 GPU with 1.5\,TB host RAM, Horizon-LM reliably trains models up to 120B parameters. On a standard single A100 machine, Horizon-LM achieves up to 12.2$\times$ higher training throughput than DeepSpeed ZeRO-3 with CPU offloading while preserving numerical correctness. Across platforms and scales, Horizon-LM sustains high device utilization and predictable memory growth, demonstrating that host memory, not GPU memory, defines the true feasibility boundary for node-scale large-model training.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [173] [Accountability in Open Source Software Ecosystems: Workshop Report](https://arxiv.org/abs/2602.04026)
*Nandini Sharma,Thomas Bock,Rich Bowen,Sayeed Choudhury,Brian Fitzgerald,Matt Germonprez,Jim Herbsleb,James Howison,Tom Hughes,Min Kyung Lee,Stephanie Lieggi,Andreas Liesenfeld,Georg Link,Nicholas Matsakis,Audris Mockus,Narayan Ramasubbu,Christopher Robinson,Gregorio Robles,Nithya Ruff,Sonali Shah,Igor Steinmacher,Bogdan Vasilescu,Stephen Walli,Christopher Yoo*

Main category: cs.SE

TL;DR: 研讨会探讨了开源生态中利益相关者的问责问题，旨在激发研究和实践的新方向。


<details>
  <summary>Details</summary>
Motivation: 开源社区中利益相关者的需求和动机多样且有时冲突，社区如何识别、理解并对其负责尚不明确。

Method: 组织了24位专家学者和实践者的研讨会，进行探索性讨论。

Result: 研讨会成功启动了关于开源软件生态系统中问责制重要问题的讨论，并为研究和实践提供了方向。

Conclusion: 研讨会旨在探讨开源软件生态系统中问责制的作用，并激发相关研究议程和实践者的有意义参与。

Abstract: Open source software ecosystems are composed of a variety of stakeholders including but not limited to non-profit organizations, volunteer contributors, users, and corporations. The needs and motivations of these stakeholders are often diverse, unknown, and sometimes even conflicting given the engagement and investment of both volunteers and corporate actors. Given this, it is not clear how open source communities identify and engage with their stakeholders, understand their needs, and hold themselves accountable to those needs. We convened 24 expert scholars and practitioners studying and working with open source software communities for an exploratory workshop discussion on these ideas. The workshop titled "Accountability and Open Source Software Ecosystems" was organized on Oct 14-15 on campus in Carnegie Mellon University, Pittsburgh, PA. The purpose of this in-person workshop was to initiate conversations that explore important and urgent questions related to the role of accountability in open source software ecosystems, and to inspire an exciting research agenda and meaningful stakeholder engagement ideas for practitioners.

</details>


### [174] [Exploring the Potential of Large Language Models in Simulink-Stateflow Mutant Generation](https://arxiv.org/abs/2602.04066)
*Pablo Valle,Shaukat Ali,Aitor Arrieta*

Main category: cs.SE

TL;DR: LLMs能高效生成高质量Simulink-Stateflow变异体，速度快且质量优。


<details>
  <summary>Details</summary>
Motivation: 传统变异分析方法在Simulink-Stateflow模型中面临冗余、等效或不可执行变异体的挑战，而现有机器学习方法受限于训练数据不足和可扩展性问题。

Method: 开发了一个自动化流程，将Simulink-Stateflow模型转换为结构化JSON表示，并系统评估了八种最先进的LLM的不同变异和提示策略。

Result: 通过涉及38,400个LLM生成变异体的实证研究，LLM生成变异体的速度比手动工程基线快13倍，且变异体质量显著提高。

Conclusion: LLMs在生成Simulink-Stateflow模型的高质量、领域特异性变异体方面表现出色，速度快且产生的等效和重复变异体显著减少。

Abstract: Mutation analysis is a powerful technique for assessing test-suite adequacy, yet conventional approaches suffer from generating redundant, equivalent, or non-executable mutants. These challenges are particularly amplified in Simulink-Stateflow models due to the hierarchical structure these models have, which integrate continuous dynamics with discrete-event behaviors and are widely deployed in safety-critical Cyber-Physical Systems (CPSs). While prior work has explored machine learning and manually engineered mutation operators, these approaches remain constrained by limited training data and scalability issues. Motivated by recent advances in Large Language Models (LLMs), we investigate their potential to generate high-quality, domain-specific mutants for Simulink-Stateflow models. We develop an automated pipeline that converts Simulink-Stateflow models to structured JSON representations and systematically evaluates different mutation and prompting strategies across eight state-of-the-art LLMs. Through a comprehensive empirical study involving 38,400 LLM-generated mutants across four Simulink-Stateflow models, we demonstrate that LLMs generate mutants up to 13x faster than a manually engineered mutation-based baseline while producing significantly fewer equivalent and duplicate mutants and consistently achieving superior mutant quality. Moreover, our analysis reveals that few-shot prompting combined with low-to-medium temperature values yields optimal results. We provide an open-source prototype tool and release our complete dataset to facilitate reproducibility and advance future research in this domain.

</details>


### [175] [I Can't Believe It's Not a Valid Exploit](https://arxiv.org/abs/2602.04165)
*Derin Gezgin,Amartya Das,Shinhae Kim,Zhengdong Huang,Nevena Stojkovic,Claire Wang*

Main category: cs.SE

TL;DR: PoC-Gym框架评估LLMs生成Java漏洞PoC的效果，静态分析指导提高21%成功率，但71.5%的PoC无效，显示当前验证机制存在缺陷。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在安全漏洞检测任务中的应用，特别是生成概念验证（PoC）漏洞利用程序，需要进一步评估其有效性。

Method: 开发了PoC-Gym框架，用于通过LLMs生成Java安全漏洞的PoC，并进行系统验证。评估了静态分析工具的指导是否提高了PoC生成的成功率，并手动检查了生成的PoC。

Result: 使用静态分析工具进行指导和标准，比之前的基线FaultLine提高了21%的成功率。然而，手动检查发现71.5%的PoC是无效的。

Conclusion: 研究结果表明，基于LLM的PoC生成报告的成功率可能存在显著误导，且当前的验证机制难以检测到这一点。

Abstract: Recently Large Language Models (LLMs) have been used in security vulnerability detection tasks including generating proof-of-concept (PoC) exploits. A PoC exploit is a program used to demonstrate how a vulnerability can be exploited. Several approaches suggest that supporting LLMs with additional guidance can improve PoC generation outcomes, motivating further evaluation of their effectiveness. In this work, we develop PoC-Gym, a framework for PoC generation for Java security vulnerabilities via LLMs and systematic validation of generated exploits. Using PoC-Gym, we evaluate whether the guidance from static analysis tools improves the PoC generation success rate and manually inspect the resulting PoCs. Our results from running PoC-Gym with Claude Sonnet 4, GPT-5 Medium, and gpt-oss-20b show that using static analysis for guidance and criteria lead to 21% higher success rates than the prior baseline, FaultLine. However, manual inspection of both successful and failed PoCs reveals that 71.5% of the PoCs are invalid. These results show that the reported success of LLM-based PoC generation can be significantly misleading, which is hard to detect with current validation mechanisms.

</details>


### [176] [SOGPTSpotter: Detecting ChatGPT-Generated Answers on Stack Overflow](https://arxiv.org/abs/2602.04185)
*Suyu Ma,Chunyang Chen,Hourieh Khalajzadeh,John Grundy*

Main category: cs.SE

TL;DR: SOGPTSpotter利用Siamese Neural Networks和Triplet loss检测Stack Overflow上的ChatGPT生成答案，效果优于现有方法，并通过实际案例验证。


<details>
  <summary>Details</summary>
Motivation: Stack Overflow上ChatGPT生成的答案数量激增，可能导致错误和不可靠信息传播，但检测此类内容仍具挑战性。

Method: 采用Siamese Neural Networks，结合BigBird模型和Triplet loss，利用人类答案、参考答案和ChatGPT答案的三元组进行训练。

Result: SOGPTSpotter在检测ChatGPT生成答案方面表现优于GPTZero、DetectGPT等基线方法，并通过消融研究和实际案例验证了其有效性和实用性。

Conclusion: SOGPTSpotter通过Siamese Neural Networks和Triplet loss，结合BigBird模型，有效检测Stack Overflow上的ChatGPT生成答案，并在实证评估中优于现有基线方法。

Abstract: Stack Overflow is a popular Q&A platform where users ask technical questions and receive answers from a community of experts. Recently, there has been a significant increase in the number of answers generated by ChatGPT, which can lead to incorrect and unreliable information being posted on the site. While Stack Overflow has banned such AI-generated content, detecting whether a post is ChatGPT-generated remains a challenging task. We introduce a novel approach, SOGPTSpotter, that employs Siamese Neural Networks, leveraging the BigBird model and the Triplet loss, to detect ChatGPT-generated answers on Stack Overflow. We use triplets of human answers, reference answers, and ChatGPT answers. Our empirical evaluation reveals that our approach outperforms well-established baselines like GPTZero, DetectGPT, GLTR, BERT, RoBERTa, and GPT-2 in identifying ChatGPT-synthesized Stack Overflow responses. We also conducted an ablation study to show the effectiveness of our model. Additional experiments were conducted to assess various factors, including the impact of text length, the model's robustness against adversarial attacks, and its generalization capabilities across different domains and large language models. We also conducted a real-world case study on Stack Overflow. Using our tool's recommendations, Stack Overflow moderators were able to identify and take down ChatGPT-suspected generated answers, demonstrating the practical applicability and effectiveness of our approach.

</details>


### [177] [Semantic Consensus Decoding: Backdoor Defense for Verilog Code Generation](https://arxiv.org/abs/2602.04195)
*Guang Yang,Xing Hu,Xiang Chen,Xin Xia*

Main category: cs.SE

TL;DR: SCD通过功能需求提取和共识解码，有效防御LLM生成Verilog代码时的后门攻击，攻击成功率大幅降低。


<details>
  <summary>Details</summary>
Motivation: 针对硬件设计中LLM生成Verilog代码时易受后门攻击的问题，现有防御方法存在局限性，需探索更有效的解决方案。

Method: 提出了语义共识解码（SCD），包括功能需求提取和共识解码两个关键组件。

Result: SCD将平均攻击成功率从89%降至3%以下，且对生成质量影响可忽略。

Conclusion: SCD是一种有效的推理时被动防御方法，能够显著降低后门攻击的成功率，同时对生成质量影响极小。

Abstract: Large language models (LLMs) for Verilog code generation are increasingly adopted in hardware design, yet remain vulnerable to backdoor attacks where adversaries inject malicious triggers during training to induce vulnerable hardware designs. Unlike patchable software vulnerabilities, hardware trojans become irreversible once fabricated, making remediation extremely costly or impossible. Existing active defenses require access to training data, impractical for third-party LLM users, while passive defenses struggle against semantically stealthy triggers that naturally blend into design specifications. In this paper, we hypothesize that under the requirements of both effectiveness and stealthiness, attackers are strongly biased toward embedding triggers in non-functional requirements (e.g., style modifiers, quality descriptors) rather than functional specifications that determine hardware behavior. Exploiting this insight, we propose Semantic Consensus Decoding (SCD), an inference-time passive defense with two key components: (1) functional requirement extraction that identifies essential requirements from user specifications, and (2) consensus decoding that adaptively fuses output distributions based on full user specifications and extracted functional requirements. When these distributions diverge significantly, SCD automatically suppresses suspicious components. Extensive experiments with three representative backdoor attacks demonstrate that SCD reduces average attack success rate from 89% to under 3% with negligible impact on generation quality.

</details>


### [178] [Why Agentic-PRs Get Rejected: A Comparative Study of Coding Agents](https://arxiv.org/abs/2602.04226)
*Sota Nakashima,Yuta Ishimoto,Masanari Kondo,Shane Mclntosh,Yasutaka Kamei*

Main category: cs.SE

TL;DR: 本文比较了不同编码代理生成的PR被拒绝的原因，发现七种模式仅出现在Agentic-PRs中，并提出启发式方法以减少缺乏反馈的情况。


<details>
  <summary>Details</summary>
Motivation: 比较不同编码代理生成的Agentic-PRs的拒绝原因差异，因为不同代理的使用目的可能导致特定的失败模式。

Method: 本文检查了AIDev数据集中654个被拒绝的PR，涵盖了五个编码代理和一个人类基准。

Result: 结果显示，七种拒绝模式仅出现在Agentic-PRs中，包括对AI生成代码的不信任。同时观察到代理特定的模式（如Devin自动撤回不活跃的PR）。值得注意的是，67.9%的被拒绝PR缺乏明确的审阅者反馈。

Conclusion: 为了解决Agentic-PRs中缺乏明确反馈的问题，本文提出了一组启发式方法，为未来研究提供了实用的预处理步骤。

Abstract: Agentic coding -- software development workflows in which autonomous coding agents plan, implement, and submit code changes with minimal human involvement -- is rapidly gaining traction. Prior work has shown that Pull Requests (PRs) produced using coding agents (Agentic-PRs) are accepted less often than PRs that are not labeled as agentic (Human-PRs). The rejection reasons for a single agent (Claude Code) have been explored, but a comparison of how rejection reasons differ between Agentic-PRs generated by different agents has not yet been performed. This comparison is important since different coding agents are often used for different purposes, which can lead to agent-specific failure patterns. In this paper, we inspect 654 rejected PRs from the AIDev dataset covering five coding agents, as well as a human baseline. Our results show that seven rejection modes occur only in Agentic-PRs, including distrust of AI-generated code. We also observe agent-specific patterns (e.g., automated withdrawal of inactive PRs by Devin), reflecting differences in how agents are configured and used in practice. Notably, a large proportion of rejected PRs (67.9%) lack explicit reviewer feedback, making their rejection reasons difficult to determine. To mitigate this issue, we propose a set of heuristics that reduce the proportion of such cases, offering a practical preprocessing step for future studies of PR rejection in agentic coding.

</details>


### [179] [ProxyWar: Dynamic Assessment of LLM Code Generation in Game Arenas](https://arxiv.org/abs/2602.04296)
*Wenjun Peng,Xinyu Wang,Qi Wu*

Main category: cs.SE

TL;DR: ProxyWar通过竞争游戏环境评估LLM代码生成，发现静态基准与实际性能的差距，为未来研究提供新方向。


<details>
  <summary>Details</summary>
Motivation: 现有代码生成评估方法局限于静态基准和简单指标，无法全面反映LLM在实际动态环境中的表现。

Method: 通过将LLM生成的代理嵌入多样化的竞争游戏环境中，结合自动化测试、迭代代码修复和多代理锦标赛，评估代码生成的功能正确性和操作特性。

Result: 应用ProxyWar框架发现，静态基准分数与实际动态性能存在显著差异，揭示了被忽视的局限性和改进机会。

Conclusion: ProxyWar框架为代码生成评估提供了更全面的视角，揭示了静态基准与实际动态性能之间的差距，并为LLM驱动的算法发现和自适应问题解决研究奠定了基础。

Abstract: Large language models (LLMs) have revolutionized automated code generation, yet the evaluation of their real-world effectiveness remains limited by static benchmarks and simplistic metrics. We present ProxyWar, a novel framework that systematically assesses code generation quality by embedding LLM-generated agents within diverse, competitive game environments. Unlike existing approaches, ProxyWar evaluates not only functional correctness but also the operational characteristics of generated programs, combining automated testing, iterative code repair, and multi-agent tournaments to provide a holistic view of program behavior. Applied to a range of state-of-the-art coders and games, our approach uncovers notable discrepancies between benchmark scores and actual performance in dynamic settings, revealing overlooked limitations and opportunities for improvement. These findings highlight the need for richer, competition-based evaluation of code generation. Looking forward, ProxyWar lays a foundation for research into LLM-driven algorithm discovery, adaptive problem solving, and the study of practical efficiency and robustness, including the potential for models to outperform hand-crafted agents. The project is available at https://github.com/xinke-wang/ProxyWar.

</details>


### [180] [Model-Driven Legacy System Modernization at Scale](https://arxiv.org/abs/2602.04341)
*Tobias Böhm,Jens Guan Su Tien,Mohini Nonnenmann,Tom Schoonbaert,Bart Carpels,Andreas Biesdorf*

Main category: cs.SE

TL;DR: 提出了一种模型驱动的遗留系统现代化方法，通过四阶段过程和技术无关中间模型，实现了半自动迁移并提升了代码库质量，但定制布局仍需手动调整。


<details>
  <summary>Details</summary>
Motivation: 解决遗留系统现代化过程中核心用户界面组件和页面结构的半自动迁移问题，同时保持功能行为和非功能性质量。

Method: 四阶段过程（分析、丰富、合成、过渡）系统提取、抽象和转换系统工件，应用了技术无关的中间模型。

Result: 通过将架构知识整合为显式模型表示，生成的代码库具有更高的可维护性和可扩展性，提升了开发者体验。尽管自动化对标准模式有效，定制布局组合的迁移仍具有挑战性。

Conclusion: 模型驱动的抽象方法降低了风险和工作量，支持可扩展、可追溯的遗留应用现代化，适用于类似的现代化场景并促进迁移模式的重用。

Abstract: This experience report presents a model-driven approach to legacy system modernization that inserts an enriched, technology-agnostic intermediate model between the legacy codebase and the modern target platform, and reports on its application and evaluation. The four-stage process of analysis, enrichment, synthesis, and transition systematically extracts, abstracts, and transforms system artifacts. We apply our approach to a large industrial application built on legacy versions of the .NET Framework and ASP.NET MVC and show that core user interface components and page structures can be migrated semi-automatically to a modern web stack while preserving functional behavior and essential non-functional qualities. By consolidating architectural knowledge into explicit model representations, the resulting codebase exhibits higher maintainability and extensibility, thereby improving developer experience. Although automation is effective for standard patterns, migration of bespoke layout composites remains challenging and requires targeted manual adaptation. Our contributions are: (i) an end-to-end model-driven process, (ii) an enriched intermediate model that captures structure, dependencies, and semantic metadata, (iii) transformation rules that preserve functional behavior and essential non-functional qualities, and (iv) application and evaluation of the approach in an industrial setting. Overall, model-based abstractions reduce risk and effort while supporting scalable, traceable modernization of legacy applications. Our approach generalizes to comparable modernization contexts and promotes reuse of migration patterns.

</details>


### [181] [Generative AI in Systems Engineering: A Framework for Risk Assessment of Large Language Models](https://arxiv.org/abs/2602.04358)
*Stefan Otten,Philipp Reis,Philipp Rigoll,Joshua Ransiek,Tobias Schürmann,Jacob Langner,Eric Sax*

Main category: cs.SE

TL;DR: LRF框架通过自主性和影响两个维度评估LLM在系统工程中的风险，支持安全部署和标准化AI保证。


<details>
  <summary>Details</summary>
Motivation: 尽管LLM在工程生命周期中有广泛应用潜力，但组织在评估其风险时面临挑战，导致集成不一致、未知故障模式和有限的可扩展性。

Method: 引入了LLM风险评估框架（LRF），通过两个基本维度（自主性和影响）对LLM应用进行分类，以确定风险水平。

Result: LRF框架支持组织识别适当的验证策略、人工监督级别和必要的应对措施，以确保安全透明的部署。

Conclusion: LLM Risk Assessment Framework (LRF) 为复杂工程环境中风险感知的LLM采用提供了基础，并朝着系统工程中标准化AI保证实践迈出了第一步。

Abstract: The increasing use of Large Language Models (LLMs) offers significant opportunities across the engineering lifecycle, including requirements engineering, software development, process optimization, and decision support. Despite this potential, organizations face substantial challenges in assessing the risks associated with LLM use, resulting in inconsistent integration, unknown failure modes, and limited scalability. This paper introduces the LLM Risk Assessment Framework (LRF), a structured approach for evaluating the application of LLMs within Systems Engineering (SE) environments. The framework classifies LLM-based applications along two fundamental dimensions: autonomy, ranging from supportive assistance to fully automated decision making, and impact, reflecting the potential severity of incorrect or misleading model outputs on engineering processes and system elements. By combining these dimensions, the LRF enables consistent determination of corresponding risk levels across the development lifecycle. The resulting classification supports organizations in identifying appropriate validation strategies, levels of human oversight, and required countermeasures to ensure safe and transparent deployment. The framework thereby helps align the rapid evolution of AI technologies with established engineering principles of reliability, traceability, and controlled process integration. Overall, the LRF provides a basis for risk-aware adoption of LLMs in complex engineering environments and represents a first step toward standardized AI assurance practices in systems engineering.

</details>


### [182] [AgenticAKM : Enroute to Agentic Architecture Knowledge Management](https://arxiv.org/abs/2602.04445)
*Rudra Dhar,Karthik Vaidhyanathan,Vasudeva Varma*

Main category: cs.SE

TL;DR: AgenticAKM通过多代理协作分解AKM任务，有效生成高质量ADRs，优于传统单提示方法。


<details>
  <summary>Details</summary>
Motivation: 传统的架构知识管理（AKM）过程繁琐且难以被开发者和架构师采纳，而现有的大语言模型（LLMs）单提示方法因上下文限制和无法理解架构知识的分布式特性而效果有限。

Method: 通过将复杂的架构恢复和文档化问题分解为可管理的子任务，采用专门化的代理（提取、检索、生成和验证）在结构化工作流程中协作生成架构知识。

Result: 通过29个代码仓库的用户研究表明，AgenticAKM生成的ADRs质量更高，验证了其作为自动化AKM方法的有效性。

Conclusion: AgenticAKM是一种有前景且实用的方法，能够有效自动化架构知识管理（AKM），特别是在生成架构决策记录（ADRs）方面表现优异。

Abstract: Architecture Knowledge Management (AKM) is crucial for maintaining current and comprehensive software Architecture Knowledge (AK) in a software project. However AKM is often a laborious process and is not adopted by developers and architects. While LLMs present an opportunity for automation, a naive, single-prompt approach is often ineffective, constrained by context limits and an inability to grasp the distributed nature of architectural knowledge. To address these limitations, we propose an Agentic approach for AKM, AgenticAKM, where the complex problem of architecture recovery and documentation is decomposed into manageable sub-tasks. Specialized agents for architecture Extraction, Retrieval, Generation, and Validation collaborate in a structured workflow to generate AK. To validate we made an initial instantiation of our approach to generate Architecture Decision Records (ADRs) from code repositories. We validated our approach through a user study with 29 repositories. The results demonstrate that our agentic approach generates better ADRs, and is a promising and practical approach for automating AKM.

</details>


### [183] [What's in a Benchmark? The Case of SWE-Bench in Automated Program Repair](https://arxiv.org/abs/2602.04449)
*Matias Martinez,Xavier Franch*

Main category: cs.SE

TL;DR: 研究分析了SWE-Bench两大榜单的提交情况，发现行业主导、专有LLMs（如Claude 4 Sonnet）表现最佳，同时开源学术贡献保持竞争力，为未来研究透明度和多样性提供参考。


<details>
  <summary>Details</summary>
Motivation: 随着AI（尤其是LLMs和基于代理的系统）的快速发展，自动程序修复（APR）领域进步显著。SWE-Bench作为评估修复系统的基准，其公开榜单成为追踪进展和比较解决方案的核心平台。本研究旨在首次全面分析这两大榜单，揭示其生态系统的现状。

Method: 通过对SWE-Bench Lite和Verified两大榜单的79和133个提交进行分析，研究考察了提交者背景、产品、使用的LLMs及方法的开放性。

Result: 行业提交（尤其是小型和大型上市公司）在两大榜单上占据主导地位并取得顶尖成绩，学术界的开源贡献仍具竞争力。专有LLMs（特别是Claude系列）表现突出，Claude 4 Sonnet当前为最优模型。

Conclusion: 研究发现，SWE-Bench生态系统主要由行业主导，尤其是小型和大型上市公司，同时学术界的开源贡献也保持竞争力。专有LLMs（特别是Claude系列）在两大榜单上占据主导地位，Claude 4 Sonnet目前表现最佳。这些发现为未来基准驱动研究的透明度和多样性提供了指导。

Abstract: The rapid progress in Automated Program Repair (APR) has been fueled by advances in AI, particularly large language models (LLMs) and agent-based systems. SWE-Bench is a benchmark designed to evaluate repair systems using real issues mined from popular open-source Python repositories. Its public leaderboards-SWE-Bench Lite and Verified-have become central platforms for tracking progress and comparing solutions. In this paper, we present the first comprehensive study of these two leaderboards, examining who is submitting solutions, the products behind the submissions, the LLMs employed, and the openness of the approaches. We analyze 79 entries submitted to Lite leaderboard and 133 to Verified. Our results show that most entries on both leaderboards originate from industry, particularly small companies and large publicly traded companies. These submissions often achieve top results, although academic contributions-typically open source-also remain competitive. We also find a clear dominance of proprietary LLMs, especially Claude family, with state-of-the-art results on both leaderboards currently achieved by Claude 4 Sonnet. These findings offer insights into the SWE-Bench ecosystem that can guide greater transparency and diversity in future benchmark-driven research.

</details>


### [184] [A Framework of Critical Success Factors for Agile Software Development](https://arxiv.org/abs/2602.04467)
*Ridewaan Hanslo,Maureen Tanner*

Main category: cs.SE

TL;DR: 本文通过分析53项研究，识别了敏捷项目的21个关键成功因素，并提出了一个理论框架，强调了人员和流程因素的重要性。


<details>
  <summary>Details</summary>
Motivation: 尽管敏捷软件开发非常流行，但实现一致的项目成功仍然具有挑战性，因此需要识别关键成功因素以提高项目成功率。

Method: 采用主题综合与内容分析方法，分析了53项主要研究。

Result: 分析得出了21个关键成功因素，分为组织、人员、技术、流程和项目五个主题，其中团队有效性和项目管理是最常被提及的因素。

Conclusion: 本研究通过系统文献综述识别了敏捷项目中的21个关键成功因素，并将其分为五个主题，为研究者和从业者提供了有价值的见解，并提出了一个理论框架以指导未来研究。

Abstract: Despite the popularity of Agile software development, achieving consistent project success remains challenging. This systematic literature review identifies critical success factors (CSFs) in Agile projects by analyzing 53 primary studies. Employing thematic synthesis with content analysis, our analysis yielded 21 CSFs categorized into five themes: organizational, people, technical, process, and project. Team effectiveness and project management emerged as the most frequently cited CSFs, highlighting the importance of people and process factors. These interpreted themes and factors contributed to the development of a theoretical framework to identify how these factors contribute to project success. This study offers valuable insights for researchers and practitioners, guiding future research to validate these findings and test the proposed framework using quantitative methods.

</details>


### [185] [Towards Structured, State-Aware, and Execution-Grounded Reasoning for Software Engineering Agents](https://arxiv.org/abs/2602.04640)
*Tse-Hsun,Chen*

Main category: cs.SE

TL;DR: 本文主张SE代理需从反应式转向结构化、状态感知的推理，以提升长期任务中的连贯性和可靠性，并提供了发展路线图。


<details>
  <summary>Details</summary>
Motivation: 当前SE代理主要为反应式设计，缺乏显式结构或持久状态，导致长期推理困难，难以保持连贯理解或适应新证据。

Method: 通过明确的结构、持久且演化的状态，以及基于执行反馈的整合，帮助SE代理在长期任务中实现更一致和可靠的推理。

Result: 提出了一个初步路线图，用于开发能够更有效执行现实世界任务的下一代SE代理。

Conclusion: 本文提出需要超越反应式行为，转向结构化、状态感知和基于执行的推理，以推动软件工程（SE）代理的进一步发展。

Abstract: Software Engineering (SE) agents have shown promising abilities in supporting various SE tasks. Current SE agents remain fundamentally reactive, making decisions mainly based on conversation history and the most recent response. However, this reactive design provides no explicit structure or persistent state within the agent's memory, making long-horizon reasoning challenging. As a result, SE agents struggle to maintain a coherent understanding across reasoning steps, adapt their hypotheses as new evidence emerges, or incorporate execution feedback into the mental reasoning model of the system state.
  In this position paper, we argue that, to further advance SE agents, we need to move beyond reactive behavior toward a structured, state-aware, and execution-grounded reasoning. We outline how explicit structure, persistent and evolving state, and the integration of execution-grounded feedback can help SE agents perform more coherent and reliable reasoning in long-horizon tasks. We also provide an initial roadmap for developing next-generation SE agents that can more effectively perform real-world tasks.

</details>


### [186] [Supporting software engineering tasks with agentic AI: Demonstration on document retrieval and test scenario generation](https://arxiv.org/abs/2602.04726)
*Marian Kica,Lukas Radosky,David Slivka,Karin Kubinova,Daniel Dovhun,Tomas Uhercik,Erik Bircak,Ivan Polasek*

Main category: cs.SE

TL;DR: 本文介绍了两种代理AI解决方案：自动测试场景生成和软件工程文档检索，展示了其在实际应用中的有效性，并展望了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型的引入促使软件工程研究重新思考开发模型，本文旨在通过代理AI解决方案应对这一挑战。

Method: 采用星型拓扑结构的专用工作代理和监督代理相结合的方法，以及基于LLM的专用代理处理不同用例。

Result: 成功开发了自动测试场景生成和软件工程文档检索任务的代理AI解决方案，并在实际案例中验证了其能力。

Conclusion: 论文总结了代理AI解决方案在软件工程中的潜力，并展望了未来研究方向。

Abstract: The introduction of large language models ignited great retooling and rethinking of the software development models. The ensuing response of software engineering research yielded a massive body of tools and approaches. In this paper, we join the hassle by introducing agentic AI solutions for two tasks. First, we developed a solution for automatic test scenario generation from a detailed requirements description. This approach relies on specialized worker agents forming a star topology with the supervisor agent in the middle. We demonstrate its capabilities on a real-world example. Second, we developed an agentic AI solution for the document retrieval task in the context of software engineering documents. Our solution enables performing various use cases on a body of documents related to the development of a single software, including search, question answering, tracking changes, and large document summarization. In this case, each use case is handled by a dedicated LLM-based agent, which performs all subtasks related to the corresponding use case. We conclude by hinting at the future perspectives of our line of research.

</details>


### [187] [Demonstrating ARG-V's Generation of Realistic Java Benchmarks for SV-COMP](https://arxiv.org/abs/2602.04786)
*Charles Moloney,Robert Dyer,Elena Sherman*

Main category: cs.SE

TL;DR: ARG-V工具生成的新Java基准测试显示，现有验证器在新测试上表现下降，突显其提升评估全面性和现实性的潜力。


<details>
  <summary>Details</summary>
Motivation: 评估软件验证工具时，基准测试的构成可能影响验证器的开发结果，需确保新增程序能反映验证器行为的差异性，以提升竞赛结果的有效性。

Method: 应用ARG-V工具自动生成符合SV-COMP格式的Java验证基准测试，并对比新旧基准测试上四种领先Java验证器的性能。

Result: 在68个新生成的现实基准测试上，四种领先Java验证器的准确率和召回率均低于现有基准测试。

Conclusion: ARG-V工具生成的Java验证基准测试增强了SV-COMP评估的全面性和现实性，为验证工具开发者提供了改进工具适用性的路线图。

Abstract: The SV-COMP competition provides a state-of-the-art platform for evaluating software verification tools on a standardized set of verification tasks. Consequently, verifier development outcomes are influenced by the composition of program benchmarks included in SV-COMP. When expanding this benchmark corpus, it is crucial to consider whether newly added programs cause verifiers to exhibit behavior distinct from that observed on existing benchmarks. Doing so helps mitigate external threats to the validity of the competition's results.
  In this paper, we present the application of the ARG-V tool for automatically generating Java verification benchmarks in the SV-COMP format. We demonstrate that, on a newly generated set of 68 realistic benchmarks, all four leading Java verifiers decrease in accuracy and recall compared to their performance on the existing benchmark suite. These findings highlight the potential of ARG-V to enhance the comprehensiveness and realism of verification tool evaluation, while also providing a roadmap for verifier developers aiming to improve their tools' applicability to real-world software.

</details>


### [188] [Beyond the Control Equations: An Artifact Study of Implementation Quality in Robot Control Software](https://arxiv.org/abs/2602.04799)
*Nils Chur,Thorsten Berger,Einar Broch Johnsen,Andrzej Wąsowski*

Main category: cs.SE

TL;DR: 研究发现机器人控制器实现存在离散化处理不当、测试不足等问题，需改进指南和验证技术以确保可靠性。


<details>
  <summary>Details</summary>
Motivation: 控制器在机器人系统中至关重要，但软件实现中的复杂性常被忽视，导致理论保证在实际中难以确保。

Method: 调查了184个开源机器人软件中的控制器实现，分析了它们的应用背景、实现特点和测试方法。

Result: 发现实现常以临时方式处理离散化，存在实时可靠性问题，测试实践肤浅，缺乏系统验证。

Conclusion: 研究强调了改进实现指南和严格验证技术的必要性，以确保机器人控制器在实际应用中的可靠性和安全性。

Abstract: A controller -- a software module managing hardware behavior -- is a key component of a typical robot system. While control theory gives safety guarantees for standard controller designs, the practical implementation of controllers in software introduces complexities that are often overlooked. Controllers are often designed in continuous space, while the software is executed in discrete space, undermining some of the theoretical guarantees. Despite extensive research on control theory and control modeling, little attention has been paid to the implementations of controllers and how their theoretical guarantees are ensured in real-world software systems. We investigate 184 real-world controller implementations in open-source robot software. We examine their application context, the implementation characteristics, and the testing methods employed to ensure correctness. We find that the implementations often handle discretization in an ad hoc manner, leading to potential issues with real-time reliability. Challenges such as timing inconsistencies, lack of proper error handling, and inadequate consideration of real-time constraints further complicate matters. Testing practices are superficial, no systematic verification of theoretical guarantees is used, leaving possible inconsistencies between expected and actual behavior. Our findings highlight the need for improved implementation guidelines and rigorous verification techniques to ensure the reliability and safety of robotic controllers in practice.

</details>


### [189] [Do Developers Read Type Information? An Eye-Tracking Study on TypeScript](https://arxiv.org/abs/2602.04824)
*Samuel W. Flint,Robert Dyer,Bonita Sharif*

Main category: cs.SE

TL;DR: 眼动追踪研究发现，开发者未将类型注解作为代码内文档频繁查看，对工具和教育提出改进建议。


<details>
  <summary>Details</summary>
Motivation: 验证开发者是否将类型注解用作代码内文档，以理解开发者如何使用类型信息，并为工具设计和教育决策提供依据。

Method: 通过眼动追踪研究，对26名本科生在TypeScript语言中的代码理解和错误定位任务进行了观察。

Result: 开发者并未在类型注解存在时更频繁地直接查看相关行。

Conclusion: 研究表明，开发者并未在代码理解或错误定位任务中更频繁地直接查看类型注解或类型声明行，这对工具开发者、开发社区和教育者提出了改进建议。

Abstract: Statically-annotated types have been shown to aid developers in a number of programming tasks, and this benefit holds true even when static type checking is not used. It is hypothesized that this is because developers use type annotations as in-code documentation. In this study, we aim to provide evidence that developers use type annotations as in-code documentation. Understanding this hypothesized use will help to understand how, and in what contexts, developers use type information; additionally, it may help to design better development tools and inform educational decisions. To provide this evidence, we conduct an eye tracking study with 26 undergraduate students to determine if they read type annotations during code comprehension and bug localization in the TypeScript language. We found that developers do not look directly at lines containing type annotations or type declarations more often when they are present, in either code summarization or bug localization tasks. The results have implications for tool builders to improve the availability of type information, the development community to build good standards for use of type annotations, and education to enforce deliberate teaching of reading patterns.

</details>


### [190] [When Code Becomes Abundant: Redefining Software Engineering Around Orchestration and Verification](https://arxiv.org/abs/2602.04830)
*Karina Kohl,Luigi Carro*

Main category: cs.SE

TL;DR: 软件工程需从代码构建转向意图表达、架构控制和验证，以应对AI与能源约束的挑战，强调人类判断在自动化中的核心作用。


<details>
  <summary>Details</summary>
Motivation: 面对AI自动化（降低代码生产成本）和硬件能源约束（增加失败成本）的双重压力，传统软件工程已不足以应对。

Method: 通过定位软件工程的核心风险（如责任崩溃）和重新定义其研究重点、教育课程及工业实践。

Result: 软件工程需要从生产导向转变为以人类判断为核心，围绕意图表达、架构控制和系统验证重新定义。

Conclusion: 论文提出软件工程（SE）需要重新定义，从传统的代码构建和流程管理转向意图表达、架构控制和系统验证，以应对AI自动化和硬件能源约束的挑战。

Abstract: Software Engineering (SE) faces simultaneous pressure from AI automation (reducing code production costs) and hardware-energy constraints (amplifying failure costs). We position that SE must redefine itself around human discernment-intent articulation, architectural control, and verification-rather than code construction. This shift introduces accountability collapse as a central risk and requires fundamental changes to research priorities, educational curricula, and industrial practices. We argue that Software Engineering, as traditionally defined around code construction and process management, is no longer sufficient. Instead, the discipline must be redefined around intent articulation, architectural control, and systematic verification. This redefinition shifts Software Engineering from a production-oriented field to one centered on human judgment under automation, with profound implications for research, practice, and education.

</details>
