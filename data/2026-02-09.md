<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 79]
- [cs.GR](#cs.GR) [Total: 1]
- [cs.AI](#cs.AI) [Total: 28]
- [cs.RO](#cs.RO) [Total: 37]
- [cs.SE](#cs.SE) [Total: 9]
- [cs.NI](#cs.NI) [Total: 3]
- [cs.DC](#cs.DC) [Total: 15]
- [cs.DS](#cs.DS) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [From Blurry to Believable: Enhancing Low-quality Talking Heads with 3D Generative Priors](https://arxiv.org/abs/2602.06122)
*Ding-Jiun Huang,Yuanhao Wang,Shao-Ji Yuan,Albert Mosella-Montoro,Francisco Vicente Carrasco,Cheng Zhang,Fernando De la Torre*

Main category: cs.CV

TL;DR: SuperHead通过动态感知3D反演提升低分辨率3D头像质量，生成高保真动画头像，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决低质量图像或视频源导致的3D重建效果差的问题，提升可动画3D头部头像的几何和纹理质量，同时保持3D和时间一致性以及主体身份。

Method: 利用预训练的3D生成模型的丰富先验，通过动态感知3D反演方案优化生成模型的潜在表示，生成超分辨率的3D高斯泼溅（3DGS）头部模型，并将其绑定到参数化头部模型（如FLAME）以实现动画。

Result: 实验表明，SuperHead在动态运动中生成具有精细面部细节的头像，视觉质量显著优于基线方法。

Conclusion: SuperHead通过创新的动态感知3D反演方案，成功提升了低分辨率3D头像的质量，并在动态面部运动中保持了高真实感，显著优于基线方法。

Abstract: Creating high-fidelity, animatable 3D talking heads is crucial for immersive applications, yet often hindered by the prevalence of low-quality image or video sources, which yield poor 3D reconstructions. In this paper, we introduce SuperHead, a novel framework for enhancing low-resolution, animatable 3D head avatars. The core challenge lies in synthesizing high-quality geometry and textures, while ensuring both 3D and temporal consistency during animation and preserving subject identity. Despite recent progress in image, video and 3D-based super-resolution (SR), existing SR techniques are ill-equipped to handle dynamic 3D inputs. To address this, SuperHead leverages the rich priors from pre-trained 3D generative models via a novel dynamics-aware 3D inversion scheme. This process optimizes the latent representation of the generative model to produce a super-resolved 3D Gaussian Splatting (3DGS) head model, which is subsequently rigged to an underlying parametric head model (e.g., FLAME) for animation. The inversion is jointly supervised using a sparse collection of upscaled 2D face renderings and corresponding depth maps, captured from diverse facial expressions and camera viewpoints, to ensure realism under dynamic facial motions. Experiments demonstrate that SuperHead generates avatars with fine-grained facial details under dynamic motions, significantly outperforming baseline methods in visual quality.

</details>


### [2] [EgoAVU: Egocentric Audio-Visual Understanding](https://arxiv.org/abs/2602.06139)
*Ashish Seth,Xinhao Mei,Changsheng Zhao,Varun Nagaraja,Ernie Chang,Gregory P. Meyer,Gael Le Lan,Yunyang Xiong,Vikas Chandra,Yangyang Shi,Dinesh Manocha,Zhipeng Cai*

Main category: cs.CV

TL;DR: EgoAVU通过自动生成多模态数据，显著提升MLLMs在自我中心视频中的音频-视觉联合理解能力，性能提升显著。


<details>
  <summary>Details</summary>
Motivation: 解决因缺乏连贯多模态文本标签而导致的MLLMs在自我中心视频中联合理解音频和视觉信息的不足。

Method: 引入EgoAVU数据引擎，通过跨模态相关性建模生成音频-视觉叙述，并采用基于令牌的视频过滤和模块化图式筛选确保数据多样性和质量。

Result: EgoAVU-Instruct（300万样本训练数据集）和EgoAVU-Bench（人工验证评估集）的构建，使MLLMs在EgoAVU-Bench上的性能提升高达113%，并在其他基准测试中实现相对28%的性能增益。

Conclusion: EgoAVU通过自动生成多模态叙述、问题和答案，显著提升了多模态大语言模型（MLLMs）在自我中心视频中的音频-视觉联合理解能力，并在多个基准测试中展现了性能提升。

Abstract: Understanding egocentric videos plays a vital role for embodied intelligence. Recent multi-modal large language models (MLLMs) can accept both visual and audio inputs. However, due to the challenge of obtaining text labels with coherent joint-modality information, whether MLLMs can jointly understand both modalities in egocentric videos remains under-explored. To address this problem, we introduce EgoAVU, a scalable data engine to automatically generate egocentric audio-visual narrations, questions, and answers. EgoAVU enriches human narrations with multimodal context and generates audio-visual narrations through cross-modal correlation modeling. Token-based video filtering and modular, graph-based curation ensure both data diversity and quality. Leveraging EgoAVU, we construct EgoAVU-Instruct, a large-scale training dataset of 3M samples, and EgoAVU-Bench, a manually verified evaluation split covering diverse tasks. EgoAVU-Bench clearly reveals the limitations of existing MLLMs: they bias heavily toward visual signals, often neglecting audio cues or failing to correspond audio with the visual source. Finetuning MLLMs on EgoAVU-Instruct effectively addresses this issue, enabling up to 113% performance improvement on EgoAVU-Bench. Such benefits also transfer to other benchmarks such as EgoTempo and EgoIllusion, achieving up to 28% relative performance gain. Code will be released to the community.

</details>


### [3] [MGP-KAD: Multimodal Geometric Priors and Kolmogorov-Arnold Decoder for Single-View 3D Reconstruction in Complex Scenes](https://arxiv.org/abs/2602.06158)
*Luoxi Zhang,Chun Xie,Itaru Kitahara*

Main category: cs.CV

TL;DR: MGP-KAD通过融合RGB和几何先验，结合KAN混合解码器，显著提升了复杂场景下的单视图3D重建效果。


<details>
  <summary>Details</summary>
Motivation: 解决复杂真实场景下单视图3D重建中存在的噪声、物体多样性和数据集有限等挑战。

Method: 提出了一种多模态特征融合框架MGP-KAD，整合RGB和几何先验，通过采样和聚类真实物体数据生成类级特征，并引入基于Kolmogorov-Arnold Networks（KAN）的混合解码器。

Result: 在Pix3D数据集上的实验表明，MGP-KAD实现了最先进的性能。

Conclusion: MGP-KAD 提供了一种稳健且有效的解决方案，显著提升了复杂场景下单视图3D重建的几何完整性、平滑度和细节保留。

Abstract: Single-view 3D reconstruction in complex real-world scenes is challenging due to noise, object diversity, and limited dataset availability. To address these challenges, we propose MGP-KAD, a novel multimodal feature fusion framework that integrates RGB and geometric prior to enhance reconstruction accuracy. The geometric prior is generated by sampling and clustering ground-truth object data, producing class-level features that dynamically adjust during training to improve geometric understanding. Additionally, we introduce a hybrid decoder based on Kolmogorov-Arnold Networks (KAN) to overcome the limitations of traditional linear decoders in processing complex multimodal inputs. Extensive experiments on the Pix3D dataset demonstrate that MGP-KAD achieves state-of-the-art (SOTA) performance, significantly improving geometric integrity, smoothness, and detail preservation. Our work provides a robust and effective solution for advancing single-view 3D reconstruction in complex scenes.

</details>


### [4] [Driving with DINO: Vision Foundation Features as a Unified Bridge for Sim-to-Real Generation in Autonomous Driving](https://arxiv.org/abs/2602.06159)
*Xuyang Chen,Conglang Zhang,Chuanheng Fu,Zihao Yang,Kaixuan Zhou,Yizhi Zhang,Jianan He,Yanfeng Zhang,Mingwei Sun,Zengmao Wang,Zhen Dong,Xiaoxiao Long,Liqiu Meng*

Main category: cs.CV

TL;DR: DwD利用DINOv3特征和多种技术（如Principal Subspace Projection、Random Channel Tail Drop等）解决了Sim2Real视频生成中的Consistency-Realism Dilemma，实现了高真实感和控制一致性。


<details>
  <summary>Details</summary>
Motivation: 现有的Sim2Real方法在视频生成中面临Consistency-Realism Dilemma，即低层信号控制精确但缺乏真实感，高层先验真实感强但缺乏结构细节。DwD旨在通过Vision Foundation Module特征统一桥梁解决这一问题。

Method: DwD框架利用DINOv3的高分辨率特征，通过Principal Subspace Projection和Random Channel Tail Drop处理特征，同时引入Spatial Alignment Module和Causal Temporal Aggregator来增强控制精度和时间稳定性。

Result: DwD框架在视频生成中实现了高真实感和控制一致性的平衡，有效解决了运动模糊和时间稳定性问题。

Conclusion: DwD框架通过结合Vision Foundation Module特征、Principal Subspace Projection、Random Channel Tail Drop、Spatial Alignment Module和Causal Temporal Aggregator，成功解决了Sim2Real视频生成中的Consistency-Realism Dilemma问题，实现了高真实感和控制一致性的平衡。

Abstract: Driven by the emergence of Controllable Video Diffusion, existing Sim2Real methods for autonomous driving video generation typically rely on explicit intermediate representations to bridge the domain gap. However, these modalities face a fundamental Consistency-Realism Dilemma. Low-level signals (e.g., edges, blurred images) ensure precise control but compromise realism by "baking in" synthetic artifacts, whereas high-level priors (e.g., depth, semantics, HDMaps) facilitate photorealism but lack the structural detail required for consistent guidance. In this work, we present Driving with DINO (DwD), a novel framework that leverages Vision Foundation Module (VFM) features as a unified bridge between the simulation and real-world domains. We first identify that these features encode a spectrum of information, from high-level semantics to fine-grained structure. To effectively utilize this, we employ Principal Subspace Projection to discard the high-frequency elements responsible for "texture baking," while concurrently introducing Random Channel Tail Drop to mitigate the structural loss inherent in rigid dimensionality reduction, thereby reconciling realism with control consistency. Furthermore, to fully leverage DINOv3's high-resolution capabilities for enhancing control precision, we introduce a learnable Spatial Alignment Module that adapts these high-resolution features to the diffusion backbone. Finally, we propose a Causal Temporal Aggregator employing causal convolutions to explicitly preserve historical motion context when integrating frame-wise DINO features, which effectively mitigates motion blur and guarantees temporal stability. Project page: https://albertchen98.github.io/DwD-project/

</details>


### [5] [MetaSSP: Enhancing Semi-supervised Implicit 3D Reconstruction through Meta-adaptive EMA and SDF-aware Pseudo-label Evaluation](https://arxiv.org/abs/2602.06163)
*Luoxi Zhang,Chun Xie,Itaru Kitahara*

Main category: cs.CV

TL;DR: MetaSSP是一种半监督框架，利用未标记数据提升单视图3D重建性能，通过梯度参数重要性估计和SDF感知伪标签加权机制，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的隐式SDF方法依赖大量标记数据，限制了可扩展性，因此需要利用未标记数据提升性能。

Method: 提出MetaSSP框架，包括梯度参数重要性估计和SDF感知伪标签加权机制，结合增强一致性和SDF方差，通过10%监督预热后联合优化标记和未标记数据。

Result: 在Pix3D基准测试中，Chamfer Distance降低了约20.61%，IoU提高了约24.09%，优于现有半监督基线。

Conclusion: MetaSSP通过结合梯度参数重要性估计和SDF感知伪标签加权机制，显著提升了单视图3D重建的性能，在Pix3D基准测试中取得了新的最优结果。

Abstract: Implicit SDF-based methods for single-view 3D reconstruction achieve high-quality surfaces but require large labeled datasets, limiting their scalability. We propose MetaSSP, a novel semi-supervised framework that exploits abundant unlabeled images. Our approach introduces gradient-based parameter importance estimation to regularize adaptive EMA updates and an SDF-aware pseudo-label weighting mechanism combining augmentation consistency with SDF variance. Beginning with a 10% supervised warm-up, the unified pipeline jointly refines labeled and unlabeled data. On the Pix3D benchmark, our method reduces Chamfer Distance by approximately 20.61% and increases IoU by around 24.09% compared to existing semi-supervised baselines, setting a new state of the art.

</details>


### [6] [M3: High-fidelity Text-to-Image Generation via Multi-Modal, Multi-Agent and Multi-Round Visual Reasoning](https://arxiv.org/abs/2602.06166)
*Bangji Yang,Ruihan Guo,Jiajun Fan,Chaoran Cheng,Ge Liu*

Main category: cs.CV

TL;DR: M3框架通过多智能体协作提升文本到图像合成的组合提示处理能力，开源模型性能超越商业系统。


<details>
  <summary>Details</summary>
Motivation: 解决生成模型在复杂组合提示下的合成失败问题，提升开源模型的性能。

Method: M3采用多模态、多智能体、多轮次的训练免费框架，通过Planner分解提示为可验证清单，Checker、Refiner和Editor智能体逐一修正约束，Verifier确保单调改进。

Result: 在OneIG-EN基准测试中，Qwen-Image+M3达到0.532的SOTA性能，超越Imagen4和Seedream 3.0；在GenEval组合指标上显著提升，空间推理性能翻倍。

Conclusion: M3框架通过多智能体协作显著提升了开源模型在复杂组合提示下的生成能力，超越了商业旗舰系统，为无需重新训练的合成生成设立了新范式。

Abstract: Generative models have achieved impressive fidelity in text-to-image synthesis, yet struggle with complex compositional prompts involving multiple constraints. We introduce \textbf{M3 (Multi-Modal, Multi-Agent, Multi-Round)}, a training-free framework that systematically resolves these failures through iterative inference-time refinement. M3 orchestrates off-the-shelf foundation models in a robust multi-agent loop: a Planner decomposes prompts into verifiable checklists, while specialized Checker, Refiner, and Editor agents surgically correct constraints one at a time, with a Verifier ensuring monotonic improvement. Applied to open-source models, M3 achieves remarkable results on the challenging OneIG-EN benchmark, with our Qwen-Image+M3 surpassing commercial flagship systems including Imagen4 (0.515) and Seedream 3.0 (0.530), reaching state-of-the-art performance (0.532 overall). This demonstrates that intelligent multi-agent reasoning can elevate open-source models beyond proprietary alternatives. M3 also substantially improves GenEval compositional metrics, effectively doubling spatial reasoning performance on hardened test sets. As a plug-and-play module compatible with any pre-trained T2I model, M3 establishes a new paradigm for compositional generation without costly retraining.

</details>


### [7] [Unsupervised Anomaly Detection of Diseases in the Female Pelvis for Real-Time MR Imaging](https://arxiv.org/abs/2602.06179)
*Anika Knupfer,Johanna P. Müller,Jordina A. Verdera,Martin Fenske,Claudius S. Mathy,Smiti Tripathy,Sebastian Arndt,Matthias May,Michael Uder,Matthias W. Beckmann,Stefanie Burghaus,Jana Hutter*

Main category: cs.CV

TL;DR: 提出一种无监督异常检测框架，用于女性骨盆MRI，无需异常数据标注，支持实时处理。


<details>
  <summary>Details</summary>
Motivation: 解决现有AI方法疾病特异性强、缺乏实时兼容性及临床集成的问题。

Method: 使用残差变分自编码器，仅通过健康矢状T2加权扫描训练，结合扩散生成合成数据增强鲁棒性。

Result: 在公开的子宫肌瘤MRI数据集上平均AUC值为0.736，灵敏度0.828，特异性0.692。

Conclusion: 该框架为女性骨盆的无监督异常检测建立了基准，支持未来实时MRI的集成。

Abstract: Pelvic diseases in women of reproductive age represent a major global health burden, with diagnosis frequently delayed due to high anatomical variability, complicating MRI interpretation. Existing AI approaches are largely disease-specific and lack real-time compatibility, limiting generalizability and clinical integration. To address these challenges, we establish a benchmark framework for disease- and parameter-agnostic, real-time-compatible unsupervised anomaly detection in pelvic MRI. The method uses a residual variational autoencoder trained exclusively on healthy sagittal T2-weighted scans acquired across diverse imaging protocols to model normal pelvic anatomy. During inference, reconstruction error heatmaps indicate deviations from learned healthy structure, enabling detection of pathological regions without labeled abnormal data. The model is trained on 294 healthy scans and augmented with diffusion-generated synthetic data to improve robustness. Quantitative evaluation on the publicly available Uterine Myoma MRI Dataset yields an average area-under-the-curve (AUC) value of 0.736, with 0.828 sensitivity and 0.692 specificity. Additional inter-observer clinical evaluation extends analysis to endometrial cancer, endometriosis, and adenomyosis, revealing the influence of anatomical heterogeneity and inter-observer variability on performance interpretation. With a reconstruction time of approximately 92.6 frames per second, the proposed framework establishes a baseline for unsupervised anomaly detection in the female pelvis and supports future integration into real-time MRI. Code is available upon request (https://github.com/AniKnu/UADPelvis), prospective data sets are available for academic collaboration.

</details>


### [8] [PhenoLIP: Integrating Phenotype Ontology Knowledge into Medical Vision-Language Pretraining](https://arxiv.org/abs/2602.06184)
*Cheng Liang,Chaoyi Wu,Weike Zhao,Ya Zhang,Yanfeng Wang,Weidi Xie*

Main category: cs.CV

TL;DR: PhenoLIP通过整合结构化表型知识，显著提升医学VLMs性能，构建了PhenoKG知识图谱和PhenoBench评估基准。


<details>
  <summary>Details</summary>
Motivation: 现有医学VLMs依赖粗粒度的图像-文本对比目标，未能捕捉医学表型本体中编码的系统视觉知识。为解决这一问题，构建了PhenoKG（首个大规模表型中心多模态知识图谱）并开发PhenoLIP框架。

Method: 提出PhenoLIP预训练框架，通过两阶段过程将结构化表型知识融入医学VLMs：首先从文本本体数据学习知识增强的表型嵌入空间，然后通过教师引导的知识蒸馏目标将该知识融入多模态预训练。

Result: PhenoLIP在表型分类准确率上比BiomedCLIP提升8.85%，在跨模态检索上比BIOMEDICA提升15.03%。

Conclusion: PhenoLIP通过整合表型中心先验知识，显著提升了医学视觉语言模型（VLMs）在表型分类和跨模态检索上的性能，证明了结构化知识在医学图像理解中的价值。

Abstract: Recent progress in large-scale CLIP-like vision-language models(VLMs) has greatly advanced medical image analysis. However, most existing medical VLMs still rely on coarse image-text contrastive objectives and fail to capture the systematic visual knowledge encoded in well-defined medical phenotype ontologies. To address this gap, we construct PhenoKG, the first large-scale, phenotype-centric multimodal knowledge graph that encompasses over 520K high-quality image-text pairs linked to more than 3,000 phenotypes. Building upon PhenoKG, we propose PhenoLIP, a novel pretraining framework that explicitly incorporates structured phenotype knowledge into medical VLMs through a two-stage process. We first learn a knowledge-enhanced phenotype embedding space from textual ontology data and then distill this structured knowledge into multimodal pretraining via a teacher-guided knowledge distillation objective. To support evaluation, we further introduce PhenoBench, an expert-verified benchmark designed for phenotype recognition, comprising over 7,800 image--caption pairs covering more than 1,000 phenotypes. Extensive experiments demonstrate that PhenoLIP outperforms previous state-of-the-art baselines, improving upon BiomedCLIP in phenotype classification accuracy by 8.85\% and BIOMEDICA in cross-modal retrieval by 15.03%, underscoring the value of integrating phenotype-centric priors into medical VLMs for structured and interpretable medical image understanding.

</details>


### [9] [DeDPO: Debiased Direct Preference Optimization for Diffusion Models](https://arxiv.org/abs/2602.06195)
*Khiem Pham,Quang Nguyen,Tung Nguyen,Jingsen Zhu,Michele Santacatterina,Dimitris Metaxas,Ramin Zabih*

Main category: cs.CV

TL;DR: DeDPO通过整合去偏估计技术，利用合成AI反馈增强有限人类数据，解决了DPO的成本和可扩展性问题，性能媲美人工标注。


<details>
  <summary>Details</summary>
Motivation: 解决DPO依赖大规模高质量人类偏好标签带来的成本和可扩展性瓶颈。

Method: 提出了一种半监督框架，通过成本效益高的合成AI反馈增强有限的人类数据，并整合了因果推断中的去偏估计技术到DPO目标中。

Result: 实验表明，DeDPO对合成标注方法的变化具有鲁棒性，性能与完全人工标注数据训练的模型的理论上限相当甚至偶尔超越。

Conclusion: DeDPO作为一种可扩展的人类-AI对齐解决方案，利用廉价的合成监督实现了与完全人工标注数据训练模型相媲美甚至偶尔超越的性能。

Abstract: Direct Preference Optimization (DPO) has emerged as a predominant alignment method for diffusion models, facilitating off-policy training without explicit reward modeling. However, its reliance on large-scale, high-quality human preference labels presents a severe cost and scalability bottleneck. To overcome this, We propose a semi-supervised framework augmenting limited human data with a large corpus of unlabeled pairs annotated via cost-effective synthetic AI feedback. Our paper introduces Debiased DPO (DeDPO), which uniquely integrates a debiased estimation technique from causal inference into the DPO objective. By explicitly identifying and correcting the systematic bias and noise inherent in synthetic annotators, DeDPO ensures robust learning from imperfect feedback sources, including self-training and Vision-Language Models (VLMs). Experiments demonstrate that DeDPO is robust to the variations in synthetic labeling methods, achieving performance that matches and occasionally exceeds the theoretical upper bound of models trained on fully human-labeled data. This establishes DeDPO as a scalable solution for human-AI alignment using inexpensive synthetic supervision.

</details>


### [10] [AnyThermal: Towards Learning Universal Representations for Thermal Perception](https://arxiv.org/abs/2602.06203)
*Parv Maheshwari,Jay Karhade,Yogesh Chawla,Isaiah Adu,Florian Heisen,Andrew Porco,Andrew Jong,Yifei Liu,Santosh Pitla,Sebastian Scherer,Wenshan Wang*

Main category: cs.CV

TL;DR: AnyThermal 是一种通用热成像骨干网络，通过特征蒸馏和多样化数据集 TartanRGBT，无需任务特定训练即可在多种任务中实现最优性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有热成像骨干网络因小规模数据和任务特定训练导致的通用性受限问题。

Method: 通过从视觉基础模型（如 DINOv2）中提取特征表示到热编码器，并利用 TartanRGBT 平台收集的多样化热数据。

Result: 在多种环境和下游任务中实现了最高达 36% 的性能提升。

Conclusion: AnyThermal 和 TartanRGBT 平台展示了在多种环境和任务中无需特定训练即可实现最先进性能的能力，显著提升了现有数据集的性能。

Abstract: We present AnyThermal, a thermal backbone that captures robust task-agnostic thermal features suitable for a variety of tasks such as cross-modal place recognition, thermal segmentation, and monocular depth estimation using thermal images. Existing thermal backbones that follow task-specific training from small-scale data result in utility limited to a specific environment and task. Unlike prior methods, AnyThermal can be used for a wide range of environments (indoor, aerial, off-road, urban) and tasks, all without task-specific training. Our key insight is to distill the feature representations from visual foundation models such as DINOv2 into a thermal encoder using thermal data from these multiple environments. To bridge the diversity gap of the existing RGB-Thermal datasets, we introduce the TartanRGBT platform, the first open-source data collection platform with synced RGB-Thermal image acquisition. We use this payload to collect the TartanRGBT dataset - a diverse and balanced dataset collected in 4 environments. We demonstrate the efficacy of AnyThermal and TartanRGBT, achieving state-of-the-art results with improvements of up to 36% across diverse environments and downstream tasks on existing datasets.

</details>


### [11] [DroneKey++: A Size Prior-free Method and New Benchmark for Drone 3D Pose Estimation from Sequential Images](https://arxiv.org/abs/2602.06211)
*Seo-Bin Hwang,Yeong-Jun Cho*

Main category: cs.CV

TL;DR: DroneKey++ 是一个无需先验信息的无人机3D姿态估计框架，结合关键点检测和分类，利用合成数据集6DroneSyn验证了其泛化能力和实时性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖于无人机的先验信息（如物理尺寸或3D网格），且当前数据集规模小、局限于单一模型和受限环境，难以可靠验证泛化能力。

Method: 该框架采用关键点编码器进行同时的关键点检测和分类，以及姿态解码器利用基于射线的几何推理和类别嵌入来估计3D姿态。

Result: 实验结果显示，DroneKey++ 在旋转误差（MAE 17.34度，MedAE 17.1度）和位移误差（MAE 0.135米，MedAE 0.242米）上表现优异，推理速度达19.25 FPS（CPU）和414.07 FPS（GPU）。

Conclusion: DroneKey++ 是一个无需先验信息的框架，能够同时进行关键点检测、无人机分类和3D姿态估计，展示了强大的泛化能力和实时应用潜力。

Abstract: Accurate 3D pose estimation of drones is essential for security and surveillance systems. However, existing methods often rely on prior drone information such as physical sizes or 3D meshes. At the same time, current datasets are small-scale, limited to single models, and collected under constrained environments, which makes reliable validation of generalization difficult. We present DroneKey++, a prior-free framework that jointly performs keypoint detection, drone classification, and 3D pose estimation. The framework employs a keypoint encoder for simultaneous keypoint detection and classification, and a pose decoder that estimates 3D pose using ray-based geometric reasoning and class embeddings. To address dataset limitations, we construct 6DroneSyn, a large-scale synthetic benchmark with over 50K images covering 7 drone models and 88 outdoor backgrounds, generated using 360-degree panoramic synthesis. Experiments show that DroneKey++ achieves MAE 17.34 deg and MedAE 17.1 deg for rotation, MAE 0.135 m and MedAE 0.242 m for translation, with inference speeds of 19.25 FPS (CPU) and 414.07 FPS (GPU), demonstrating both strong generalization across drone models and suitability for real-time applications. The dataset is publicly available.

</details>


### [12] [Addressing the Waypoint-Action Gap in End-to-End Autonomous Driving via Vehicle Motion Models](https://arxiv.org/abs/2602.06214)
*Jorge Daniel Rodríguez-Vidal,Gabriel Villalonga,Diego Porres,Antonio M. López Peña*

Main category: cs.CV

TL;DR: 论文提出了一种可微分车辆模型框架，弥合了基于路径点和基于动作的自动驾驶系统之间的差距，并在多个基准测试中表现出色。


<details>
  <summary>Details</summary>
Motivation: 现有的端到端自动驾驶系统主要分为基于路径点和基于动作的两类，但大多数基准协议和训练流程都是基于路径点的，这使得基于动作的策略难以训练和比较，阻碍了其发展。

Method: 论文提出了一种可微分车辆模型框架，该框架能够将预测的动作序列转换为对应的自车坐标系路径点轨迹，并在路径点空间中进行监督。

Result: 论文的方法在多个具有挑战性的基准测试中表现一致优于基线方法，特别是在NAVSIM navhard上实现了最先进的性能。

Conclusion: 该论文提出了一种新颖的、可微分车辆模型框架，成功弥合了基于路径点和基于动作的自动驾驶系统之间的差距，并在多个基准测试中实现了性能提升，特别是在NAVSIM navhard上达到了最先进的性能。

Abstract: End-to-End Autonomous Driving (E2E-AD) systems are typically grouped by the nature of their outputs: (i) waypoint-based models that predict a future trajectory, and (ii) action-based models that directly output throttle, steer and brake. Most recent benchmark protocols and training pipelines are waypoint-based, which makes action-based policies harder to train and compare, slowing their progress. To bridge this waypoint-action gap, we propose a novel, differentiable vehicle-model framework that rolls out predicted action sequences to their corresponding ego-frame waypoint trajectories while supervising in waypoint space. Our approach enables action-based architectures to be trained and evaluated, for the first time, within waypoint-based benchmarks without modifying the underlying evaluation protocol. We extensively evaluate our framework across multiple challenging benchmarks and observe consistent improvements over the baselines. In particular, on NAVSIM \texttt{navhard} our approach achieves state-of-the-art performance. Our code will be made publicly available upon acceptance.

</details>


### [13] [Cross-Modal Redundancy and the Geometry of Vision-Language Embeddings](https://arxiv.org/abs/2602.06218)
*Grégoire Dhimoïla,Thomas Fel,Victor Boutin,Agustin Picard*

Main category: cs.CV

TL;DR: 通过Iso-Energy假设和对齐SAE，研究发现VLMs共享嵌入空间的几何结构具有清晰模式，稀疏双模态原子是关键，单模态原子可移除而不影响性能。


<details>
  <summary>Details</summary>
Motivation: 探究视觉语言模型（VLMs）共享嵌入空间的几何结构，以理解其跨模态对齐机制。

Method: 采用对齐稀疏自编码器（SAE）来鼓励训练过程中的能量一致性，同时保持重构能力。

Result: 揭示了稀疏双模态原子携带全部跨模态对齐信号，单模态原子作为模态特定偏差完全解释了模态间隙。移除单模态原子可消除间隙而不影响性能。

Conclusion: 研究发现适当的归纳偏置既能保持模型保真度，又能使潜在几何结构可解释且可操作。

Abstract: Vision-language models (VLMs) align images and text with remarkable success, yet the geometry of their shared embedding space remains poorly understood. To probe this geometry, we begin from the Iso-Energy Assumption, which exploits cross-modal redundancy: a concept that is truly shared should exhibit the same average energy across modalities. We operationalize this assumption with an Aligned Sparse Autoencoder (SAE) that encourages energy consistency during training while preserving reconstruction. We find that this inductive bias changes the SAE solution without harming reconstruction, giving us a representation that serves as a tool for geometric analysis. Sanity checks on controlled data with known ground truth confirm that alignment improves when Iso-Energy holds and remains neutral when it does not. Applied to foundational VLMs, our framework reveals a clear structure with practical consequences: (i) sparse bimodal atoms carry the entire cross-modal alignment signal; (ii) unimodal atoms act as modality-specific biases and fully explain the modality gap; (iii) removing unimodal atoms collapses the gap without harming performance; (iv) restricting vector arithmetic to the bimodal subspace yields in-distribution edits and improved retrieval. These findings suggest that the right inductive bias can both preserve model fidelity and render the latent geometry interpretable and actionable.

</details>


### [14] [ForeHOI: Feed-forward 3D Object Reconstruction from Daily Hand-Object Interaction Videos](https://arxiv.org/abs/2602.06226)
*Yuantao Chen,Jiahao Chang,Chongjie Ye,Chaoran Zhang,Zhaojie Fang,Chenghong Li,Xiaoguang Han*

Main category: cs.CV

TL;DR: ForeHOI是一种前馈模型，通过联合2D和3D形状补全，高效重建单目手-物体交互视频中的3D物体几何，性能显著提升且速度极快。


<details>
  <summary>Details</summary>
Motivation: 解决单目视频中因严重遮挡和复杂耦合运动导致的3D物体重建难题。

Method: 提出了一种新颖的前馈模型ForeHOI，直接在单目手-物体交互视频中重建3D物体几何，无需预处理步骤。关键创新在于联合2D遮罩修复和3D形状补全的预测。

Result: ForeHOI在物体重建上达到最先进性能，显著优于优化方法，并提供100倍加速。

Conclusion: ForeHOI模型通过联合预测2D遮罩修复和3D形状补全，在单目手-物体交互视频中实现了高效的3D物体几何重建，显著优于现有方法，并提供了100倍的加速。

Abstract: The ubiquity of monocular videos capturing daily hand-object interactions presents a valuable resource for embodied intelligence. While 3D hand reconstruction from in-the-wild videos has seen significant progress, reconstructing the involved objects remains challenging due to severe occlusions and the complex, coupled motion of the camera, hands, and object. In this paper, we introduce ForeHOI, a novel feed-forward model that directly reconstructs 3D object geometry from monocular hand-object interaction videos within one minute of inference time, eliminating the need for any pre-processing steps. Our key insight is that, the joint prediction of 2D mask inpainting and 3D shape completion in a feed-forward framework can effectively address the problem of severe occlusion in monocular hand-held object videos, thereby achieving results that outperform the performance of optimization-based methods. The information exchanges between the 2D and 3D shape completion boosts the overall reconstruction quality, enabling the framework to effectively handle severe hand-object occlusion. Furthermore, to support the training of our model, we contribute the first large-scale, high-fidelity synthetic dataset of hand-object interactions with comprehensive annotations. Extensive experiments demonstrate that ForeHOI achieves state-of-the-art performance in object reconstruction, significantly outperforming previous methods with around a 100x speedup. Code and data are available at: https://github.com/Tao-11-chen/ForeHOI.

</details>


### [15] [ASMa: Asymmetric Spatio-temporal Masking for Skeleton Action Representation Learning](https://arxiv.org/abs/2602.06251)
*Aman Anand,Amir Eskandari,Elyas Rahsno,Farhana Zulkernine*

Main category: cs.CV

TL;DR: ASMa通过互补掩码策略和特征对齐提升骨架动作识别性能，并通过蒸馏实现高效部署。


<details>
  <summary>Details</summary>
Motivation: 现有自监督学习方法在骨架动作识别中依赖对高运动帧和高自由度关节的掩码，导致特征表示存在偏差且不完整。

Method: 提出了不对称时空掩码（ASMa）策略，结合两种互补的掩码方式，并引入可学习特征对齐模块和知识蒸馏压缩模型。

Result: 在NTU RGB+D 60、NTU RGB+D 120和PKU-MMD数据集上，ASMa在微调任务中平均提升2.7-4.4%，在迁移学习中提升达5.9%，且蒸馏模型参数减少91.4%，推理速度提升3倍。

Conclusion: ASMa方法通过不对称时空掩码策略和可学习特征对齐模块，显著提升了骨架动作识别的性能，并在资源受限环境下实现了高效部署。

Abstract: Self-supervised learning (SSL) has shown remarkable success in skeleton-based action recognition by leveraging data augmentations to learn meaningful representations. However, existing SSL methods rely on data augmentations that predominantly focus on masking high-motion frames and high-degree joints such as joints with degree 3 or 4. This results in biased and incomplete feature representations that struggle to generalize across varied motion patterns. To address this, we propose Asymmetric Spatio-temporal Masking (ASMa) for Skeleton Action Representation Learning, a novel combination of masking to learn a full spectrum of spatio-temporal dynamics inherent in human actions. ASMa employs two complementary masking strategies: one that selectively masks high-degree joints and low-motion, and another that masks low-degree joints and high-motion frames. These masking strategies ensure a more balanced and comprehensive skeleton representation learning. Furthermore, we introduce a learnable feature alignment module to effectively align the representations learned from both masked views. To facilitate deployment in resource-constrained settings and on low-resource devices, we compress the learned and aligned representation into a lightweight model using knowledge distillation. Extensive experiments on NTU RGB+D 60, NTU RGB+D 120, and PKU-MMD datasets demonstrate that our approach outperforms existing SSL methods with an average improvement of 2.7-4.4% in fine-tuning and up to 5.9% in transfer learning to noisy datasets and achieves competitive performance compared to fully supervised baselines. Our distilled model achieves 91.4% parameter reduction and 3x faster inference on edge devices while maintaining competitive accuracy, enabling practical deployment in resource-constrained scenarios.

</details>


### [16] [An Interpretable Vision Transformer as a Fingerprint-Based Diagnostic Aid for Kabuki and Wiedemann-Steiner Syndromes](https://arxiv.org/abs/2602.06282)
*Marilyn Lionts,Arnhildur Tomasdottir,Viktor I. Agustsson,Yuankai Huo,Hans T. Bjornsson,Lotta M. Ellingsen*

Main category: cs.CV

TL;DR: 研究开发了一种基于指纹图像的AI模型，可区分Kabuki综合征和Wiedemann-Steiner综合征，展示了指纹在诊断罕见遗传病中的实用性。


<details>
  <summary>Details</summary>
Motivation: 尽管KS和WSS是两种不同的发育障碍，但临床特征重叠且诊断困难。指纹异常作为遗传综合征的标志之一，未被充分利用。研究旨在开发一种非侵入性、可解释的AI工具，辅助早期诊断。

Method: 研究采用基于视觉Transformer的深度学习模型，利用指纹图像进行三类二元分类任务（对照组 vs. KS、对照组 vs. WSS、KS vs. WSS），并通过注意力可视化增强模型的可解释性。

Result: 模型在三类分类任务中分别取得AUC分数0.80、0.73和0.85，F1分数0.71、0.72和0.83，表明指纹特征具有区分能力。注意力可视化揭示了与预测最相关的指纹区域。

Conclusion: 该研究表明，指纹图像可以通过基于视觉Transformer的深度学习模型，有效区分Kabuki综合征（KS）和Wiedemann-Steiner综合征（WSS），展示了指纹特征在诊断罕见遗传综合征中的潜力。

Abstract: Kabuki syndrome (KS) and Wiedemann-Steiner syndrome (WSS) are rare but distinct developmental disorders that share overlapping clinical features, including neurodevelopmental delay, growth restriction, and persistent fetal fingertip pads. While genetic testing remains the diagnostic gold standard, many individuals with KS or WSS remain undiagnosed due to barriers in access to both genetic testing and expertise. Dermatoglyphic anomalies, despite being established hallmarks of several genetic syndromes, remain an underutilized diagnostic signal in the era of molecular testing. This study presents a vision transformer-based deep learning model that leverages fingerprint images to distinguish individuals with KS and WSS from unaffected controls and from one another. We evaluate model performance across three binary classification tasks. Across the three classification tasks, the model achieved AUC scores of 0.80 (control vs. KS), 0.73 (control vs. WSS), and 0.85 (KS vs. WSS), with corresponding F1 scores of 0.71, 0.72, and 0.83, respectively. Beyond classification, we apply attention-based visualizations to identify fingerprint regions most salient to model predictions, enhancing interpretability. Together, these findings suggest the presence of syndrome-specific fingerprint features, demonstrating the feasibility of a fingerprint-based artificial intelligence (AI) tool as a noninvasive, interpretable, and accessible future diagnostic aid for the early diagnosis of underdiagnosed genetic syndromes.

</details>


### [17] [MMEarth-Bench: Global Model Adaptation via Multimodal Test-Time Training](https://arxiv.org/abs/2602.06285)
*Lucia Gordon,Serge Belongie,Christian Igel,Nico Lang*

Main category: cs.CV

TL;DR: MMEarth-Bench是一个多模态地理空间基准数据集，结合TTT-MMR方法，提升了模型在有限数据和地理泛化场景下的表现。


<details>
  <summary>Details</summary>
Motivation: 现有地理空间基准数据集模态单一且全球代表性不足，无法全面评估多模态预训练模型的性能。

Method: 提出了TTT-MMR（测试时多模态重建训练）方法，利用测试时可用的所有模态作为辅助任务，提升模型性能。

Result: TTT-MMR方法在随机和地理测试分割上均提升了模型性能，地理批处理在正则化和专业化之间取得了良好平衡。

Conclusion: MMEarth-Bench填补了现有地理空间基准数据集的不足，通过引入多模态任务和全球分布数据，提升了模型评估的全面性。提出的TTT-MMR方法有效提升了模型在有限数据下的鲁棒性和地理泛化能力。

Abstract: Recent research in geospatial machine learning has demonstrated that models pretrained with self-supervised learning on Earth observation data can perform well on downstream tasks with limited training data. However, most of the existing geospatial benchmark datasets have few data modalities and poor global representation, limiting the ability to evaluate multimodal pretrained models at global scales. To fill this gap, we introduce MMEarth-Bench, a collection of five new multimodal environmental tasks with 12 modalities, globally distributed data, and both in- and out-of-distribution test splits. We benchmark a diverse set of pretrained models and find that while (multimodal) pretraining tends to improve model robustness in limited data settings, geographic generalization abilities remain poor. In order to facilitate model adaptation to new downstream tasks and geographic domains, we propose a model-agnostic method for test-time training with multimodal reconstruction (TTT-MMR) that uses all the modalities available at test time as auxiliary tasks, regardless of whether a pretrained model accepts them as input. Our method improves model performance on both the random and geographic test splits, and geographic batching leads to a good trade-off between regularization and specialization during TTT. Our dataset, code, and visualization tool are linked from the project page at lgordon99.github.io/mmearth-bench.

</details>


### [18] [Unsupervised MRI-US Multimodal Image Registration with Multilevel Correlation Pyramidal Optimization](https://arxiv.org/abs/2602.06288)
*Jiazheng Wang,Zeyu Liu,Min Liu,Xiang Chen,Hang Zhang*

Main category: cs.CV

TL;DR: 提出了一种基于多级相关金字塔优化的无监督多模态医学图像配准方法，解决了术中图像变形和模态差异的挑战，在Learn2Reg 2025任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决多模态图像配准中由于模态间差异和术中组织位移及切除导致的图像变形带来的挑战。

Method: 基于多级相关金字塔优化（MCPO）的无监督多模态医学图像配准方法，首先基于模态独立邻域描述符提取各模态特征并映射到特征空间，然后通过多级金字塔融合优化机制实现位移场的全局优化和局部细节补充。

Result: 在Learn2Reg 2025的ReMIND2Reg任务中取得第一名，并在Resect数据集上实现平均TRE为1.798 mm。

Conclusion: 该方法在Learn2Reg 2025的ReMIND2Reg任务中取得了验证阶段和测试阶段的第一名，并在Resect数据集上实现了平均TRE为1.798 mm，展示了其在术前到术中图像配准中的广泛适用性。

Abstract: Surgical navigation based on multimodal image registration has played a significant role in providing intraoperative guidance to surgeons by showing the relative position of the target area to critical anatomical structures during surgery. However, due to the differences between multimodal images and intraoperative image deformation caused by tissue displacement and removal during the surgery, effective registration of preoperative and intraoperative multimodal images faces significant challenges. To address the multimodal image registration challenges in Learn2Reg 2025, an unsupervised multimodal medical image registration method based on multilevel correlation pyramidal optimization (MCPO) is designed to solve these problems. First, the features of each modality are extracted based on the modality independent neighborhood descriptor, and the multimodal images is mapped to the feature space. Second, a multilevel pyramidal fusion optimization mechanism is designed to achieve global optimization and local detail complementation of the displacement field through dense correlation analysis and weight-balanced coupled convex optimization for input features at different scales. Our method focuses on the ReMIND2Reg task in Learn2Reg 2025. Based on the results, our method achieved the first place in the validation phase and test phase of ReMIND2Reg. The MCPO is also validated on the Resect dataset, achieving an average TRE of 1.798 mm. This demonstrates the broad applicability of our method in preoperative-to-intraoperative image registration. The code is avaliable at https://github.com/wjiazheng/MCPO.

</details>


### [19] [Accelerating Vision Transformers on Brain Processing Unit](https://arxiv.org/abs/2602.06300)
*Jinchi Tang,Yan Guo*

Main category: cs.CV

TL;DR: 论文提出了一种将Vision Transformer的线性层替换为卷积算子的方法，使其适配BPU硬件，在保持高准确率的同时显著提升推理速度。


<details>
  <summary>Details</summary>
Motivation: 由于CNN优化硬件（如BPU）与Vision Transformer的计算特性（如线性层处理三维数据）不匹配，难以利用BPU的优势部署Vision Transformer。

Method: 通过将Vision Transformer中的线性层和层归一化操作替换为精心设计的卷积算子，使其能够适配CNN优化的硬件架构（如BPU）。

Result: 量化后的DeiT-Base模型在ImageNet上达到80.4%的准确率（原为81.8%），推理速度提升3.8倍。在花卉分类数据集上微调的DeiT模型也表现优异，准确率仅下降0.5%。

Conclusion: 该论文提出了一种新颖的方法，通过将Vision Transformer中的线性层和层归一化操作替换为精心设计的卷积算子，使其能够充分利用BPU的加速能力，同时在无需重新训练或微调的情况下继承原始权重参数。实验结果表明，该方法在保持较高准确率的同时显著提升了推理速度。

Abstract: With the advancement of deep learning technologies, specialized neural processing hardware such as Brain Processing Units (BPUs) have emerged as dedicated platforms for CNN acceleration, offering optimized INT8 computation capabilities for convolutional operations. Meanwhile, Vision Transformer (ViT) models, such as the Data-efficient Image Transformer (DeiT), have demonstrated superior performance and play increasingly crucial roles in computer vision tasks. However, due to the architectural mismatch between CNN-optimized hardware and Vision Transformer computation characteristics--namely, that linear layers in Transformers operate on three-dimensional data while BPU acceleration is designed for four-dimensional convolution operations-it is difficult or even impossible to leverage BPU's advantages when deploying Vision Transformers. To address this challenge, we propose a novel approach that restructures the Vision Transformer by replacing linear layers and layer normalization operations with carefully designed convolutional operators. This enables DeiT to fully utilize the acceleration capabilities of BPUs, while allowing the original weight parameters to be inherited by the restructured models without retraining or fine-tuning. To the best of our knowledge, this is the first successful deployment of Vision Transformers that fully leverages BPU classification datasets demonstrate the effectiveness of our approach. Specifically, the quantized DeiT-Base model achieves 80.4% accuracy on ImageNet, compared to the original 81.8%, while obtaining up to a 3.8* inference speedup. Our finetuned DeiT model on the flower classification dataset also achieves excellent performance, with only a 0.5% accuracy drop for the DeiT-Base model, further demonstrating the effectiveness of our method.

</details>


### [20] [Adaptive and Balanced Re-initialization for Long-timescale Continual Test-time Domain Adaptation](https://arxiv.org/abs/2602.06328)
*Yanshuo Wang,Jinguang Tong,Jun Lan,Weiqiang Wang,Huijia Zhu,Haoxing Chen,Xuesong Li,Jie Hong*

Main category: cs.CV

TL;DR: 本研究提出ABR策略，通过自适应权重重初始化提升模型在持续变化环境中的长期适应能力，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 探索如何在长期运行中提升模型对持续变化环境的适应能力，解决现有方法在长期性能上的不足。

Method: 提出了一种基于标签翻转轨迹模式的自适应间隔权重重初始化策略（ABR），通过监测标签翻转变化动态调整重初始化间隔。

Result: 在多种CTTA基准测试中，ABR策略显著提升了模型的长期性能，表现优于现有方法。

Conclusion: 通过自适应和平衡的重初始化策略（ABR），本研究成功提升了模型在持续测试时域适应（CTTA）中的长期性能，验证了其在多种CTTA基准测试中的优越性。

Abstract: Continual test-time domain adaptation (CTTA) aims to adjust models so that they can perform well over time across non-stationary environments. While previous methods have made considerable efforts to optimize the adaptation process, a crucial question remains: Can the model adapt to continually changing environments over a long time? In this work, we explore facilitating better CTTA in the long run using a re-initialization (or reset) based method. First, we observe that the long-term performance is associated with the trajectory pattern in label flip. Based on this observed correlation, we propose a simple yet effective policy, Adaptive-and-Balanced Re-initialization (ABR), towards preserving the model's long-term performance. In particular, ABR performs weight re-initialization using adaptive intervals. The adaptive interval is determined based on the change in label flip. The proposed method is validated on extensive CTTA benchmarks, achieving superior performance.

</details>


### [21] [Halt the Hallucination: Decoupling Signal and Semantic OOD Detection Based on Cascaded Early Rejection](https://arxiv.org/abs/2602.06330)
*Ningkang Peng,Chuanjie Cheng,Jingyang Mao,Xiaoqian Peng,Feng Xing,Bo Zhang,Chao Tan,Zhichao Zheng,Peiheng Li,Yanhui Gu*

Main category: cs.CV

TL;DR: CER框架通过分层过滤实现高效异常检测，减少计算开销并显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在低级统计噪声上执行全规模推断，导致资源浪费和语义幻觉，即深度网络将物理异常强制解释为高置信度语义特征。

Method: CER框架包括两个核心模块：1) Structural Energy Sieve (SES)，使用拉普拉斯算子在网络入口建立非参数屏障，高效拦截物理信号异常；2) Semantically-aware Hyperspherical Energy (SHE)检测器，在中间层解耦特征大小和方向，识别细粒度语义偏差。

Result: CER不仅减少32%的计算开销，还在CIFAR-100基准测试中显著提升性能：平均FPR95从33.58%降至22.84%，AUROC提升至93.97%。

Conclusion: CER框架作为一种通用插件，可以无缝集成到各种SOTA模型中，提供性能提升，尤其在模拟传感器故障的真实场景中表现卓越。

Abstract: Efficient and robust Out-of-Distribution (OOD) detection is paramount for safety-critical applications.However, existing methods still execute full-scale inference on low-level statistical noise. This computational mismatch not only incurs resource waste but also induces semantic hallucination, where deep networks forcefully interpret physical anomalies as high-confidence semantic features.To address this, we propose the Cascaded Early Rejection (CER) framework, which realizes hierarchical filtering for anomaly detection via a coarse-to-fine logic.CER comprises two core modules: 1)Structural Energy Sieve (SES), which establishes a non-parametric barrier at the network entry using the Laplacian operator to efficiently intercept physical signal anomalies; and 2) the Semantically-aware Hyperspherical Energy (SHE) detector, which decouples feature magnitude from direction in intermediate layers to identify fine-grained semantic deviations. Experimental results demonstrate that CER not only reduces computational overhead by 32% but also achieves a significant performance leap on the CIFAR-100 benchmark:the average FPR95 drastically decreases from 33.58% to 22.84%, and AUROC improves to 93.97%. Crucially, in real-world scenarios simulating sensor failures, CER exhibits performance far exceeding state-of-the-art methods. As a universal plugin, CER can be seamlessly integrated into various SOTA models to provide performance gains.

</details>


### [22] [Taming SAM3 in the Wild: A Concept Bank for Open-Vocabulary Segmentation](https://arxiv.org/abs/2602.06333)
*Gensheng Pei,Xiruo Jiang,Yazhou Yao,Xiangbo Shu,Fumin Shen,Byeungwoo Jeon*

Main category: cs.CV

TL;DR: 	extsc{ConceptBank} 是一个无参数校准框架，通过动态构建目标域概念库，解决了 	exttt{SAM3} 在数据漂移和概念漂移下的对齐问题，提升了开放词汇分割的适应性。


<details>
  <summary>Details</summary>
Motivation: 	exttt{SAM3} 依赖预定义概念进行提示分割，在面对数据漂移和概念漂移时，视觉证据与提示的对齐会失效，导致性能下降。

Method: 通过构建特定数据集的概念库，利用类视觉原型锚定目标域证据，挖掘代表性支持以抑制数据漂移中的异常值，并融合候选概念以纠正概念漂移。

Result: 实验证明，	extsc{ConceptBank} 能有效适应分布漂移，包括自然场景和遥感场景，为 OVS 的鲁棒性和效率设定了新基准。

Conclusion: 	extsc{ConceptBank} 成功地为 	exttt{SAM3} 提供了针对数据漂移和概念漂移的动态校准能力，显著提升了开放词汇分割（OVS）的鲁棒性和效率。

Abstract: The recent introduction of \texttt{SAM3} has revolutionized Open-Vocabulary Segmentation (OVS) through \textit{promptable concept segmentation}, which grounds pixel predictions in flexible concept prompts. However, this reliance on pre-defined concepts makes the model vulnerable: when visual distributions shift (\textit{data drift}) or conditional label distributions evolve (\textit{concept drift}) in the target domain, the alignment between visual evidence and prompts breaks down. In this work, we present \textsc{ConceptBank}, a parameter-free calibration framework to restore this alignment on the fly. Instead of adhering to static prompts, we construct a dataset-specific concept bank from the target statistics. Our approach (\textit{i}) anchors target-domain evidence via class-wise visual prototypes, (\textit{ii}) mines representative supports to suppress outliers under data drift, and (\textit{iii}) fuses candidate concepts to rectify concept drift. We demonstrate that \textsc{ConceptBank} effectively adapts \texttt{SAM3} to distribution drifts, including challenging natural-scene and remote-sensing scenarios, establishing a new baseline for robustness and efficiency in OVS. Code and model are available at https://github.com/pgsmall/ConceptBank.

</details>


### [23] [SPDA-SAM: A Self-prompted Depth-Aware Segment Anything Model for Instance Segmentation](https://arxiv.org/abs/2602.06335)
*Yihan Shang,Wei Wang,Chao Huang,Xinghui Dong*

Main category: cs.CV

TL;DR: SPDA-SAM通过自提示和深度感知改进SAM，显著提升实例分割性能。


<details>
  <summary>Details</summary>
Motivation: 解决SAM对人工提示质量的依赖及RGB图像缺乏深度信息的问题，提升空间结构感知和对象边界划分能力。

Method: 设计了语义-空间自提示模块（SSSPM）和粗到细的RGB-D融合模块（C2FFM），结合SAM的编码器和解码器特性，以及深度图的结构信息。

Result: 在十二个不同数据集上表现优于现有最佳方法。

Conclusion: SPDA-SAM通过自提示和深度感知的方式显著提升了实例分割的性能，在十二个不同数据集上超越了现有最佳方法。

Abstract: Recently, Segment Anything Model (SAM) has demonstrated strong generalizability in various instance segmentation tasks. However, its performance is severely dependent on the quality of manual prompts. In addition, the RGB images that instance segmentation methods normally use inherently lack depth information. As a result, the ability of these methods to perceive spatial structures and delineate object boundaries is hindered. To address these challenges, we propose a Self-prompted Depth-Aware SAM (SPDA-SAM) for instance segmentation. Specifically, we design a Semantic-Spatial Self-prompt Module (SSSPM) which extracts the semantic and spatial prompts from the image encoder and the mask decoder of SAM, respectively. Furthermore, we introduce a Coarse-to-Fine RGB-D Fusion Module (C2FFM), in which the features extracted from a monocular RGB image and the depth map estimated from it are fused. In particular, the structural information in the depth map is used to provide coarse-grained guidance to feature fusion, while local variations in depth are encoded in order to fuse fine-grained feature representations. To our knowledge, SAM has not been explored in such self-prompted and depth-aware manners. Experimental results demonstrate that our SPDA-SAM outperforms its state-of-the-art counterparts across twelve different data sets. These promising results should be due to the guidance of the self-prompts and the compensation for the spatial information loss by the coarse-to-fine RGB-D fusion operation.

</details>


### [24] [Uncertainty-Aware 4D Gaussian Splatting for Monocular Occluded Human Rendering](https://arxiv.org/abs/2602.06343)
*Weiquan Wang,Feifei Shao,Lin Li,Zhen Wang,Jun Xiao,Long Chen*

Main category: cs.CV

TL;DR: U-4DGS通过概率变形网络和双重光栅化管线，显著提升遮挡情况下动态人体渲染的保真度。


<details>
  <summary>Details</summary>
Motivation: 现有方法在遮挡情况下表现不佳，要么通过生成模型产生时间闪烁，要么因几何启发式方法无法捕捉多样化外观。

Method: 提出U-4DGS框架，整合概率变形网络和双重光栅化管线，生成像素对齐的不确定性图作为自适应梯度调制器。

Result: 在ZJU-MoCap和OcMotion数据集上的实验表明，U-4DGS实现了最先进的渲染保真度和鲁棒性。

Conclusion: U-4DGS通过概率变形网络和双重光栅化管线的结合，成功提升了动态人体单目视频渲染的保真度和鲁棒性，尤其在遮挡情况下表现优异。

Abstract: High-fidelity rendering of dynamic humans from monocular videos typically degrades catastrophically under occlusions. Existing solutions incorporate external priors-either hallucinating missing content via generative models, which induces severe temporal flickering, or imposing rigid geometric heuristics that fail to capture diverse appearances. To this end, we reformulate the task as a Maximum A Posteriori estimation problem under heteroscedastic observation noise. In this paper, we propose U-4DGS, a framework integrating a Probabilistic Deformation Network and a Double Rasterization pipeline. This architecture renders pixel-aligned uncertainty maps that act as an adaptive gradient modulator, automatically attenuating artifacts from unreliable observations. Furthermore, to prevent geometric drift in regions lacking reliable visual cues, we enforce Confidence-Aware Regularizations, which leverage the learned uncertainty to selectively propagate spatial-temporal validity. Extensive experiments on ZJU-MoCap and OcMotion demonstrate that U-4DGS achieves SOTA rendering fidelity and robustness.

</details>


### [25] [FlowConsist: Make Your Flow Consistent with Real Trajectory](https://arxiv.org/abs/2602.06346)
*Tianyi Zhang,Chengcheng Liu,Jinwei Chen,Chun-Le Guo,Chongyi Li,Ming-Ming Cheng,Bo Li,Peng-Tao Jiang*

Main category: cs.CV

TL;DR: FlowConsist通过轨迹一致性和校正策略，解决了快速流模型的轨迹漂移和误差累积问题，实现了高效单步生成。


<details>
  <summary>Details</summary>
Motivation: 当前快速流训练范式存在两个问题：随机配对噪声-数据样本构建的条件速度导致轨迹漂移，以及模型近似误差随时间步长累积。

Method: 提出了FlowConsist训练框架，包括用模型自身预测的边际速度替代条件速度，以及通过轨迹校正策略对齐生成样本与真实样本的边际分布。

Result: 在ImageNet 256×256上达到FID 1.52（仅1步采样），创下新纪录。

Conclusion: FlowConsist通过强制轨迹一致性和引入轨迹校正策略，显著提升了快速流模型的性能，在ImageNet 256×256上实现了1.52的FID（仅需1步采样）。

Abstract: Fast flow models accelerate the iterative sampling process by learning to directly predict ODE path integrals, enabling one-step or few-step generation. However, we argue that current fast-flow training paradigms suffer from two fundamental issues. First, conditional velocities constructed from randomly paired noise-data samples introduce systematic trajectory drift, preventing models from following a consistent ODE path. Second, the model's approximation errors accumulate over time steps, leading to severe deviations across long time intervals. To address these issues, we propose FlowConsist, a training framework designed to enforce trajectory consistency in fast flows. We propose a principled alternative that replaces conditional velocities with the marginal velocities predicted by the model itself, aligning optimization with the true trajectory. To further address error accumulation over time steps, we introduce a trajectory rectification strategy that aligns the marginal distributions of generated and real samples at every time step along the trajectory. Our method establishes a new state-of-the-art on ImageNet 256$\times$256, achieving an FID of 1.52 with only 1 sampling step.

</details>


### [26] [Di3PO -- Diptych Diffusion DPO for Targeted Improvements in Image](https://arxiv.org/abs/2602.06355)
*Sanjana Reddy,Ishaan Malhi,Sally Ma,Praneet Dutta*

Main category: cs.CV

TL;DR: Di3PO通过隔离目标区域构建正负对，提升文本到图像扩散模型的偏好调整效率，优于SFT和DPO。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖计算密集型生成步骤，导致训练对差异不明显、采样过滤成本高或无关像素区域方差大，影响训练效率。

Method: 提出了一种名为Di3PO的新方法，通过隔离目标改进区域并保持周围图像上下文稳定来构建正负对。

Result: 在文本渲染任务中，Di3PO展示了优于SFT和DPO基线方法的性能。

Conclusion: Di3PO方法通过隔离特定区域构建正负对，显著提升了文本到图像扩散模型的偏好调整效率，优于基线方法SFT和DPO。

Abstract: Existing methods for preference tuning of text-to-image (T2I) diffusion models often rely on computationally expensive generation steps to create positive and negative pairs of images. These approaches frequently yield training pairs that either lack meaningful differences, are expensive to sample and filter, or exhibit significant variance in irrelevant pixel regions, thereby degrading training efficiency. To address these limitations, we introduce "Di3PO", a novel method for constructing positive and negative pairs that isolates specific regions targeted for improvement during preference tuning, while keeping the surrounding context in the image stable. We demonstrate the efficacy of our approach by applying it to the challenging task of text rendering in diffusion models, showcasing improvements over baseline methods of SFT and DPO.

</details>


### [27] [Robust Pedestrian Detection with Uncertain Modality](https://arxiv.org/abs/2602.06363)
*Qian Bie,Xiao Wang,Bin Yang,Zhixi Yu,Jun Chen,Xin Xu*

Main category: cs.CV

TL;DR: 论文提出AUNet解决多模态行人检测中模态输入不确定性问题，通过UMVR和MAI模块提升检测鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有跨模态行人检测方法在输入模态组合不确定时性能下降，无法充分利用可用信息。

Method: 提出了Adaptive Uncertainty-aware Network (AUNet)，包含Unified Modality Validation Refinement (UMVR)和Modality-Aware Interaction (MAI)模块，用于验证模态可用性并自适应融合可用信息。

Result: 构建了TRNT数据集，提出的AUNet在不确定输入下显著提升了检测性能。

Conclusion: 论文提出了AUNet，通过UMVR和MAI模块有效解决了多模态输入不确定性问题，提升了行人检测的鲁棒性和准确性。

Abstract: Existing cross-modal pedestrian detection (CMPD) employs complementary information from RGB and thermal-infrared (TIR) modalities to detect pedestrians in 24h-surveillance systems.RGB captures rich pedestrian details under daylight, while TIR excels at night. However, TIR focuses primarily on the person's silhouette, neglecting critical texture details essential for detection. While the near-infrared (NIR) captures texture under low-light conditions, which effectively alleviates performance issues of RGB and detail loss in TIR, thereby reducing missed detections. To this end, we construct a new Triplet RGB-NIR-TIR (TRNT) dataset, comprising 8,281 pixel-aligned image triplets, establishing a comprehensive foundation for algorithmic research. However, due to the variable nature of real-world scenarios, imaging devices may not always capture all three modalities simultaneously. This results in input data with unpredictable combinations of modal types, which challenge existing CMPD methods that fail to extract robust pedestrian information under arbitrary input combinations, leading to significant performance degradation. To address these challenges, we propose the Adaptive Uncertainty-aware Network (AUNet) for accurately discriminating modal availability and fully utilizing the available information under uncertain inputs. Specifically, we introduce Unified Modality Validation Refinement (UMVR), which includes an uncertainty-aware router to validate modal availability and a semantic refinement to ensure the reliability of information within the modality. Furthermore, we design a Modality-Aware Interaction (MAI) module to adaptively activate or deactivate its internal interaction mechanisms per UMVR output, enabling effective complementary information fusion from available modalities.

</details>


### [28] [Revisiting Salient Object Detection from an Observer-Centric Perspective](https://arxiv.org/abs/2602.06369)
*Fuxi Zhang,Yifan Wang,Hengrun Zhao,Zhuohan Sun,Changxing Xia,Lijun Wang,Huchuan Lu,Yangrui Shao,Chen Yang,Long Teng*

Main category: cs.CV

TL;DR: 提出观察者为中心的显著目标检测方法（OC-SOD），结合视觉和观察者因素，构建数据集和基线模型，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有方法将显著目标检测视为单一真值分割图的客观预测任务，忽略了人类感知的主观性和多样性。

Method: 提出OC-SOD方法，结合视觉线索和观察者特定因素（如偏好或意图），并基于多模态大语言模型构建OC-SODBench数据集和OC-SODAgent基线模型。

Result: 在OC-SODBench数据集上的实验验证了OC-SOD方法的有效性，实现了个性化和上下文感知的显著性预测。

Conclusion: 通过观察者为中心的显著目标检测（OC-SOD）方法，本研究成功弥合了人类感知与计算建模之间的差距，提供了更现实、灵活的显著目标理解。

Abstract: Salient object detection is inherently a subjective problem, as observers with different priors may perceive different objects as salient. However, existing methods predominantly formulate it as an objective prediction task with a single groundtruth segmentation map for each image, which renders the problem under-determined and fundamentally ill-posed. To address this issue, we propose Observer-Centric Salient Object Detection (OC-SOD), where salient regions are predicted by considering not only the visual cues but also the observer-specific factors such as their preferences or intents. As a result, this formulation captures the intrinsic ambiguity and diversity of human perception, enabling personalized and context-aware saliency prediction. By leveraging multi-modal large language models, we develop an efficient data annotation pipeline and construct the first OC-SOD dataset named OC-SODBench, comprising 33k training, validation and test images with 152k textual prompts and object pairs. Built upon this new dataset, we further design OC-SODAgent, an agentic baseline which performs OC-SOD via a human-like "Perceive-Reflect-Adjust" process. Extensive experiments on our proposed OC-SODBench have justified the effectiveness of our contribution. Through this observer-centric perspective, we aim to bridge the gap between human perception and computational modeling, offering a more realistic and flexible understanding of what makes an object truly "salient." Code and dataset are publicly available at: https://github.com/Dustzx/OC_SOD

</details>


### [29] [EUGens: Efficient, Unified, and General Dense Layers](https://arxiv.org/abs/2410.09771)
*Sang Min Kim,Byeongchan Kim,Arijit Sehanobish,Somnath Basu Roy Chowdhury,Rahul Kidambi,Dongseok Shim,Avinava Dubey,Snigdha Chaturvedi,Min-hwan Oh,Krzysztof Choromanski*

Main category: cs.CV

TL;DR: EUGens 是一种新型密集层，通过随机特征和输入范数依赖优化全连接前馈层，显著提升推理速度和内存效率，适用于大规模神经网络部署。


<details>
  <summary>Details</summary>
Motivation: 全连接前馈层（FFLs）在神经网络中引入了计算和参数数量的瓶颈，限制了实时应用和资源受限环境中的模型扩展。

Method: 提出了一种新的密集层类别 EUGens，利用随机特征近似标准 FFLs，并通过输入范数直接依赖计算，将推理复杂度从二次降低到线性。

Result: 实验表明，将 EUGens 集成到 Transformers 和 MLPs 中，在图像分类、语言模型预训练和 3D 场景重建等任务中，推理速度提升高达 27%，内存效率提升高达 30%。

Conclusion: EUGens 提供了一种可扩展的解决方案，用于在现实场景中大规模部署神经网络，显著提升了推理速度和内存效率。

Abstract: Efficient neural networks are essential for scaling machine learning models to real-time applications and resource-constrained environments. Fully-connected feedforward layers (FFLs) introduce computation and parameter count bottlenecks within neural network architectures. To address this challenge, in this work, we propose a new class of dense layers that generalize standard fully-connected feedforward layers, \textbf{E}fficient, \textbf{U}nified and \textbf{Gen}eral dense layers (EUGens). EUGens leverage random features to approximate standard FFLs and go beyond them by incorporating a direct dependence on the input norms in their computations. The proposed layers unify existing efficient FFL extensions and improve efficiency by reducing inference complexity from quadratic to linear time. They also lead to \textbf{the first} unbiased algorithms approximating FFLs with arbitrary polynomial activation functions. Furthermore, EuGens reduce the parameter count and computational overhead while preserving the expressive power and adaptability of FFLs. We also present a layer-wise knowledge transfer technique that bypasses backpropagation, enabling efficient adaptation of EUGens to pre-trained models. Empirically, we observe that integrating EUGens into Transformers and MLPs yields substantial improvements in inference speed (up to \textbf{27}\%) and memory efficiency (up to \textbf{30}\%) across a range of tasks, including image classification, language model pre-training, and 3D scene reconstruction. Overall, our results highlight the potential of EUGens for the scalable deployment of large-scale neural networks in real-world scenarios.

</details>


### [30] [POINTS-GUI-G: GUI-Grounding Journey](https://arxiv.org/abs/2602.06391)
*Zhongyin Zhao,Yuan Liu,Yikun Liu,Haicheng Wang,Le Tian,Xiao Zhou,Yangxiu You,Zilin Yu,Yang Yu,Jie Zhou*

Main category: cs.CV

TL;DR: POINTS-GUI-G-8B通过数据工程、训练策略和强化学习优化，在GUI基础任务中达到SOTA性能，验证了RL在感知任务中的有效性。


<details>
  <summary>Details</summary>
Motivation: GUI基础能力是端到端任务执行的前提，现有方法多基于已具备强空间感知的模型微调，本研究旨在从基础模型（如POINTS-1.5）开始掌握完整技术流程。

Method: 1. 精炼数据工程：统一多样化的开源数据集格式，采用增强、过滤和难度分级策略。2. 改进训练策略：持续微调视觉编码器以提升感知准确性，保持训练与推理的分辨率一致性。3. 强化学习（RL）与可验证奖励：传统用于推理的RL在此任务中显著提升了感知精度。

Result: POINTS-GUI-G-8B在多个基准测试中取得领先成绩：ScreenSpot-Pro（59.9）、OSWorld-G（66.0）、ScreenSpot-v2（95.7）、UI-Vision（49.9）。

Conclusion: POINTS-GUI-G-8B通过精炼的数据工程、改进的训练策略和强化学习，在GUI基础任务上实现了最先进的性能，展示了强化学习在感知密集型任务中的潜力。

Abstract: The rapid advancement of vision-language models has catalyzed the emergence of GUI agents, which hold immense potential for automating complex tasks, from online shopping to flight booking, thereby alleviating the burden of repetitive digital workflows. As a foundational capability, GUI grounding is typically established as a prerequisite for end-to-end task execution. It enables models to precisely locate interface elements, such as text and icons, to perform accurate operations like clicking and typing. Unlike prior works that fine-tune models already possessing strong spatial awareness (e.g., Qwen3-VL), we aim to master the full technical pipeline by starting from a base model with minimal grounding ability, such as POINTS-1.5. We introduce POINTS-GUI-G-8B, which achieves state-of-the-art performance with scores of 59.9 on ScreenSpot-Pro, 66.0 on OSWorld-G, 95.7 on ScreenSpot-v2, and 49.9 on UI-Vision. Our model's success is driven by three key factors: (1) Refined Data Engineering, involving the unification of diverse open-source datasets format alongside sophisticated strategies for augmentation, filtering, and difficulty grading; (2) Improved Training Strategies, including continuous fine-tuning of the vision encoder to enhance perceptual accuracy and maintaining resolution consistency between training and inference; and (3) Reinforcement Learning (RL) with Verifiable Rewards. While RL is traditionally used to bolster reasoning, we demonstrate that it significantly improves precision in the perception-intensive GUI grounding task. Furthermore, GUI grounding provides a natural advantage for RL, as rewards are easily verifiable and highly accurate.

</details>


### [31] [TFusionOcc: Student's t-Distribution Based Object-Centric Multi-Sensor Fusion Framework for 3D Occupancy Prediction](https://arxiv.org/abs/2602.06400)
*Zhenxing Ming,Julie Stephany Berrio,Mao Shan,Stewart Worrall*

Main category: cs.CV

TL;DR: TFusionOcc是一种新型多传感器融合框架，通过几何灵活基元和高级统计模型，显著提升了3D语义占据预测的精度和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有3D语义占据预测方法依赖3D体素或高斯分布，难以高效捕捉细粒度几何细节。

Method: 提出了TFusionOcc，一种基于对象的多传感器融合框架，利用多阶段多传感器融合、学生t分布和TMM，以及可变形超二次曲面等几何灵活基元。

Result: 在nuScenes基准测试中达到SOTA性能，并在nuScenes-C数据集上验证了不同传感器损坏场景下的鲁棒性。

Conclusion: TFusionOcc通过多阶段多传感器融合、学生t分布和T混合模型（TMM）以及几何灵活的基元（如可变形超二次曲面），在nuScenes基准测试中实现了最先进的性能，并在不同传感器损坏场景下表现出鲁棒性。

Abstract: 3D semantic occupancy prediction enables autonomous vehicles (AVs) to perceive fine-grained geometric and semantic structure of their surroundings from onboard sensors, which is essential for safe decision-making and navigation. Recent models for 3D semantic occupancy prediction have successfully addressed the challenge of describing real-world objects with varied shapes and classes. However, the intermediate representations used by existing methods for 3D semantic occupancy prediction rely heavily on 3D voxel volumes or a set of 3D Gaussians, hindering the model's ability to efficiently and effectively capture fine-grained geometric details in the 3D driving environment. This paper introduces TFusionOcc, a novel object-centric multi-sensor fusion framework for predicting 3D semantic occupancy. By leveraging multi-stage multi-sensor fusion, Student's t-distribution, and the T-Mixture model (TMM), together with more geometrically flexible primitives, such as the deformable superquadric (superquadric with inverse warp), the proposed method achieved state-of-the-art (SOTA) performance on the nuScenes benchmark. In addition, extensive experiments were conducted on the nuScenes-C dataset to demonstrate the robustness of the proposed method in different camera and lidar corruption scenarios. The code will be available at: https://github.com/DanielMing123/TFusionOcc

</details>


### [32] [MeDocVL: A Visual Language Model for Medical Document Understanding and Parsing](https://arxiv.org/abs/2602.06402)
*Wenjie Wang,Wei Wu,Ying Liu,Yuan Zhao,Xiaole Lv,Liang Diao,Zengjian Fan,Wenfeng Xie,Ziling Lin,De Shi,Lin Huang,Kaihe Xu,Hong Li*

Main category: cs.CV

TL;DR: MeDocVL是一个后训练的视觉语言模型，通过标签精炼和混合训练策略，在嘈杂的医疗文档OCR任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 医疗文档OCR由于复杂的布局、领域特定术语和嘈杂的注释而具有挑战性，同时需要严格的字段级精确匹配。现有的OCR系统和通用视觉语言模型往往无法可靠地解析此类文档。

Method: 提出了MeDocVL，一个后训练的视觉语言模型，用于查询驱动的医疗文档解析。该方法结合了训练驱动的标签精炼（从嘈杂的注释中构建高质量监督）和噪声感知的混合后训练策略（集成强化学习和监督微调），以实现鲁棒且精确的提取。

Result: 在医疗发票基准测试中，MeDocVL始终优于传统OCR系统和强大的VLM基线，在嘈杂的监督下实现了最先进的性能。

Conclusion: MeDocVL通过结合训练驱动的标签精炼和噪声感知的混合后训练策略，在嘈杂的监督下实现了最先进的性能，显著优于传统OCR系统和强大的VLM基线。

Abstract: Medical document OCR is challenging due to complex layouts, domain-specific terminology, and noisy annotations, while requiring strict field-level exact matching. Existing OCR systems and general-purpose vision-language models often fail to reliably parse such documents. We propose MeDocVL, a post-trained vision-language model for query-driven medical document parsing. Our framework combines Training-driven Label Refinement to construct high-quality supervision from noisy annotations, with a Noise-aware Hybrid Post-training strategy that integrates reinforcement learning and supervised fine-tuning to achieve robust and precise extraction. Experiments on medical invoice benchmarks show that MeDocVL consistently outperforms conventional OCR systems and strong VLM baselines, achieving state-of-the-art performance under noisy supervision.

</details>


### [33] [A neuromorphic model of the insect visual system for natural image processing](https://arxiv.org/abs/2602.06405)
*Adam D. Hines,Karin Nordström,Andrew B. Barron*

Main category: cs.CV

TL;DR: 本文提出了一种生物启发的视觉模型，通过自监督对比学习生成稀疏编码，在多种任务中表现优异，并展示了其在模拟定位任务中的性能优势。


<details>
  <summary>Details</summary>
Motivation: 当前许多计算模型过于注重任务性能而忽略了生物基础的视觉处理路径，本研究旨在填补这一空白，提出更接近昆虫视觉系统的计算模型。

Method: 采用完全自监督的对比学习目标训练模型，无需标记数据，并实现了人工神经网络和脉冲神经网络两种实现方式。

Result: 模型在花朵识别任务和自然图像基准测试中表现一致，生成的稀疏编码能有效区分视觉相似的输入，并在模拟定位任务中优于简单的图像降采样基线方法。

Conclusion: 该研究通过提出一种生物启发的视觉模型，成功地将昆虫视觉系统的处理原则应用于稀疏、判别性编码的生成，展示了在多种任务中的通用性和性能优势。

Abstract: Insect vision supports complex behaviors including associative learning, navigation, and object detection, and has long motivated computational models for understanding biological visual processing. However, many contemporary models prioritize task performance while neglecting biologically grounded processing pathways. Here, we introduce a bio-inspired vision model that captures principles of the insect visual system to transform dense visual input into sparse, discriminative codes. The model is trained using a fully self-supervised contrastive objective, enabling representation learning without labeled data and supporting reuse across tasks without reliance on domain-specific classifiers. We evaluated the resulting representations on flower recognition tasks and natural image benchmarks. The model consistently produced reliable sparse codes that distinguish visually similar inputs. To support different modelling and deployment uses, we have implemented the model as both an artificial neural network and a spiking neural network. In a simulated localization setting, our approach outperformed a simple image downsampling comparison baseline, highlighting the functional benefit of incorporating neuromorphic visual processing pathways. Collectively, these results advance insect computational modelling by providing a generalizable bio-inspired vision model capable of sparse computation across diverse tasks.

</details>


### [34] [Point Virtual Transformer](https://arxiv.org/abs/2602.06406)
*Veerain Sood,Bnalin,Gaurav Pandey*

Main category: cs.CV

TL;DR: PointViT通过选择性融合LiDAR与虚拟点，优化远距离3D检测，KITTI测试表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决LiDAR远距离点云稀疏导致几何线索不足的问题，同时避免直接引入所有虚拟点带来的计算成本增加和融合挑战。

Method: 提出PointViT框架，结合Transformer和稀疏卷积技术，采用多种融合策略（从早期点级融合到BEV门控融合）处理原始LiDAR点与虚拟点，并通过稀疏卷积形成BEV表示，最终通过Transformer模块优化物体查询。

Result: 在KITTI基准测试中，Car类别的3D AP达到91.16%，BEV AP达到95.94%，2D检测AP达到99.36%。

Conclusion: PointViT通过联合处理原始LiDAR点和选择性采样的虚拟点，显著提升了远距离3D物体检测的性能，并在KITTI基准测试中取得了优异的成绩。

Abstract: LiDAR-based 3D object detectors often struggle to detect far-field objects due to the sparsity of point clouds at long ranges, which limits the availability of reliable geometric cues. To address this, prior approaches augment LiDAR data with depth-completed virtual points derived from RGB images; however, directly incorporating all virtual points leads to increased computational cost and introduces challenges in effectively fusing real and virtual information. We present Point Virtual Transformer (PointViT), a transformer-based 3D object detection framework that jointly reasons over raw LiDAR points and selectively sampled virtual points. The framework examines multiple fusion strategies, ranging from early point-level fusion to BEV-based gated fusion, and analyses their trade-offs in terms of accuracy and efficiency. The fused point cloud is voxelized and encoded using sparse convolutions to form a BEV representation, from which a compact set of high-confidence object queries is initialised and refined through a transformer-based context aggregation module. Experiments on the KITTI benchmark report 91.16% 3D AP, 95.94% BEV AP, and 99.36% AP on the KITTI 2D detection benchmark for the Car class.

</details>


### [35] [Learning Human Visual Attention on 3D Surfaces through Geometry-Queried Semantic Priors](https://arxiv.org/abs/2602.06419)
*Soham Pahari,Sandeep C. Kumain*

Main category: cs.CV

TL;DR: SemGeo-AttentionNet通过双流架构和跨模态融合，有效建模人类在3D物体上的视觉注意力。


<details>
  <summary>Details</summary>
Motivation: 现有3D显著性方法缺乏语义感知，无法解释人类为何注视语义重要但几何不显著的区域。

Method: 采用双流架构（几何处理和语义识别），结合扩散式语义先验和点云变换器，通过跨注意力机制实现几何特征与语义内容的交互。

Result: 在SAL3D、NUS3D和3DVA数据集上评估显示显著改进，验证了架构的有效性。

Conclusion: SemGeo-AttentionNet通过双流架构和跨模态融合，显著提升了三维物体上人类视觉注意力的建模效果，验证了认知驱动架构的有效性。

Abstract: Human visual attention on three-dimensional objects emerges from the interplay between bottom-up geometric processing and top-down semantic recognition. Existing 3D saliency methods rely on hand-crafted geometric features or learning-based approaches that lack semantic awareness, failing to explain why humans fixate on semantically meaningful but geometrically unremarkable regions. We introduce SemGeo-AttentionNet, a dual-stream architecture that explicitly formalizes this dichotomy through asymmetric cross-modal fusion, leveraging diffusion-based semantic priors from geometry-conditioned multi-view rendering and point cloud transformers for geometric processing. Cross-attention ensures geometric features query semantic content, enabling bottom-up distinctiveness to guide top-down retrieval. We extend our framework to temporal scanpath generation through reinforcement learning, introducing the first formulation respecting 3D mesh topology with inhibition-of-return dynamics. Evaluation on SAL3D, NUS3D and 3DVA datasets demonstrates substantial improvements, validating how cognitively motivated architectures effectively model human visual attention on three-dimensional surfaces.

</details>


### [36] [Alleviating Sparse Rewards by Modeling Step-Wise and Long-Term Sampling Effects in Flow-Based GRPO](https://arxiv.org/abs/2602.06422)
*Yunze Tong,Mushui Liu,Canyu Zhao,Wanggui He,Shiyi Zhang,Hongwei Zhang,Peng Zhang,Jinlong Liu,Ju Huang,Jiamang Wang,Hao Jiang,Pipei Huang*

Main category: cs.CV

TL;DR: TP-GRPO通过增量奖励和转折点检测优化GRPO框架，提升了文本到图像生成的性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法在文本到图像生成中未能区分每一步的局部效果，且忽略了轨迹内依赖关系。

Method: TP-GRPO采用增量奖励替代基于结果的奖励，并通过检测增量奖励的符号变化识别转折点，从而分配长期奖励。

Result: 实验表明，TP-GRPO能更有效地利用奖励信号，并持续改进生成效果。

Conclusion: TP-GRPO通过引入增量奖励和转折点检测，有效缓解了奖励稀疏性问题，并显著提升了文本到图像生成的性能。

Abstract: Deploying GRPO on Flow Matching models has proven effective for text-to-image generation. However, existing paradigms typically propagate an outcome-based reward to all preceding denoising steps without distinguishing the local effect of each step. Moreover, current group-wise ranking mainly compares trajectories at matched timesteps and ignores within-trajectory dependencies, where certain early denoising actions can affect later states via delayed, implicit interactions. We propose TurningPoint-GRPO (TP-GRPO), a GRPO framework that alleviates step-wise reward sparsity and explicitly models long-term effects within the denoising trajectory. TP-GRPO makes two key innovations: (i) it replaces outcome-based rewards with step-level incremental rewards, providing a dense, step-aware learning signal that better isolates each denoising action's "pure" effect, and (ii) it identifies turning points-steps that flip the local reward trend and make subsequent reward evolution consistent with the overall trajectory trend-and assigns these actions an aggregated long-term reward to capture their delayed impact. Turning points are detected solely via sign changes in incremental rewards, making TP-GRPO efficient and hyperparameter-free. Extensive experiments also demonstrate that TP-GRPO exploits reward signals more effectively and consistently improves generation. Demo code is available at https://github.com/YunzeTong/TurningPoint-GRPO.

</details>


### [37] [POPL-KF: A Pose-Only Geometric Representation-Based Kalman Filter for Point-Line-Based Visual-Inertial Odometry](https://arxiv.org/abs/2602.06425)
*Aiping Wang,Zhaolong Yang,Shuwen Chen,Hai Zhang*

Main category: cs.CV

TL;DR: POPL-KF通过姿态几何表示和线特征优化，提升VIO性能，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 主流VIO系统在挑战性场景下性能下降，且MSCKF-based系统存在线性化误差和测量延迟问题。

Method: 提出了基于姿态的几何表示方法，开发了POPL-KF系统，采用统一的基帧选择算法和线特征过滤器。

Result: POPL-KF在公开数据集和实际实验中表现优于SOTA方法，保持实时性能。

Conclusion: POPL-KF 通过消除点线特征坐标的线性化误差，显著提升了VIO系统在挑战性场景下的性能，并在实时性上优于现有方法。

Abstract: Mainstream Visual-inertial odometry 
(VIO) systems rely on point features for motion estimation and localization. However, their performance degrades in challenging scenarios. Moreover, the localization accuracy of multi-state constraint Kalman filter (MSCKF)-based VIO systems suffers from linearization errors associated with feature 3D coordinates and delayed measurement updates. To improve the performance of VIO in challenging scenes, we first propose a pose-only geometric representation for line features. Building on this, we develop POPL-KF, a Kalman filter-based VIO system that employs a pose-only geometric representation for both point and line features. POPL-KF mitigates linearization errors by explicitly eliminating both point and line feature coordinates from the measurement equations, while enabling immediate update of visual measurements. We also design a unified base-frames selection algorithm for both point and line features to ensure optimal constraints on camera poses within the pose-only measurement model. To further improve line feature quality, a line feature filter based on image grid segmentation and bidirectional optical flow consistency is proposed. Our system is evaluated on public datasets and real-world experiments, demonstrating that POPL-KF outperforms the state-of-the-art (SOTA) filter-based methods (OpenVINS, PO-KF) and optimization-based methods (PL-VINS, EPLF-VINS), while maintaining real-time performance.

</details>


### [38] [Bridging the Indoor-Outdoor Gap: Vision-Centric Instruction-Guided Embodied Navigation for the Last Meters](https://arxiv.org/abs/2602.06427)
*Yuxiang Zhao,Yirong Yang,Yanqing Zhu,Yanfen Shen,Chiyu Wang,Zhining Gu,Pei Shi,Wei Guo,Mu Xu*

Main category: cs.CV

TL;DR: 提出了一种不依赖外部先验的室外到室内导航任务及解决方案，通过视觉中心框架和开源数据集实现了优越性能。


<details>
  <summary>Details</summary>
Motivation: 现有的导航方法局限于室内或室外环境，且依赖精确坐标系统，无法实现室外到室内的无缝过渡。

Method: 引入了一种基于图像提示的视觉中心导航框架，并开发了一个开源数据集，该数据集通过轨迹条件视频合成生成数据。

Result: 实验表明，该方法在成功率和路径效率等关键指标上优于现有基线。

Conclusion: 提出的视觉中心导航框架在关键指标上持续优于现有基线，为无缝的室外到室内导航提供了实用解决方案。

Abstract: Embodied navigation holds significant promise for real-world applications such as last-mile delivery. However, most existing approaches are confined to either indoor or outdoor environments and rely heavily on strong assumptions, such as access to precise coordinate systems. While current outdoor methods can guide agents to the vicinity of a target using coarse-grained localization, they fail to enable fine-grained entry through specific building entrances, critically limiting their utility in practical deployment scenarios that require seamless outdoor-to-indoor transitions. To bridge this gap, we introduce a novel task: out-to-in prior-free instruction-driven embodied navigation. This formulation explicitly eliminates reliance on accurate external priors, requiring agents to navigate solely based on egocentric visual observations guided by instructions. To tackle this task, we propose a vision-centric embodied navigation framework that leverages image-based prompts to drive decision-making. Additionally, we present the first open-source dataset for this task, featuring a pipeline that integrates trajectory-conditioned video synthesis into the data generation process. Through extensive experiments, we demonstrate that our proposed method consistently outperforms state-of-the-art baselines across key metrics including success rate and path efficiency.

</details>


### [39] [ChatUMM: Robust Context Tracking for Conversational Interleaved Generation](https://arxiv.org/abs/2602.06442)
*Wenxun Dai,Zhiyuan Zhao,Yule Zhong,Yiji Cheng,Jianwei Zhang,Linqing Wang,Shiyi Zhang,Yunlong Lin,Runze He,Fellix Song,Wayne Zhuang,Yong Liu,Haoji Zhang,Yansong Tang,Qinglin Lu,Chunyu Wang*

Main category: cs.CV

TL;DR: ChatUMM通过创新训练策略和数据合成，实现了多模态连续对话，性能领先且鲁棒性强。


<details>
  <summary>Details</summary>
Motivation: 解决现有统一多模态模型（UMMs）局限于单轮交互的问题，提升其在连续对话中的表现。

Method: 通过交错多轮训练策略和系统化的对话数据合成流程，将单轮数据集转化为流畅对话。

Result: ChatUMM在视觉理解和指令引导编辑基准测试中达到开源统一模型的最先进性能，同时在文本到图像生成中保持竞争力。

Conclusion: ChatUMM作为对话式统一模型，在复杂多轮场景中展现出卓越的鲁棒性，实现了流畅、上下文感知的对话。

Abstract: Unified multimodal models (UMMs) have achieved remarkable progress yet remain constrained by a single-turn interaction paradigm, effectively functioning as solvers for independent requests rather than assistants in continuous dialogue. To bridge this gap, we present ChatUMM. As a conversational unified model, it excels at robust context tracking to sustain interleaved multimodal generation. ChatUMM derives its capabilities from two key innovations: an interleaved multi-turn training strategy that models serialized text-image streams as a continuous conversational flow, and a systematic conversational data synthesis pipeline. This pipeline transforms a diverse set of standard single-turn datasets into fluid dialogues through three progressive stages: constructing basic stateful dialogues, enforcing long-range dependency resolution via ``distractor'' turns with history-dependent query rewriting, and synthesizing naturally interleaved multimodal responses. Extensive evaluations demonstrate that ChatUMM achieves state-of-the-art performance among open-source unified models on visual understanding and instruction-guided editing benchmarks, while maintaining competitive fidelity in text-to-image generation. Notably, ChatUMM exhibits superior robustness in complex multi-turn scenarios, ensuring fluid, context-aware dialogues.

</details>


### [40] [What Is Wrong with Synthetic Data for Scene Text Recognition? A Strong Synthetic Engine with Diverse Simulations and Self-Evolution](https://arxiv.org/abs/2602.06450)
*Xingsong Ye,Yongkun Du,JiaXin Zhang,Chen Li,Jing LYU,Zhineng Chen*

Main category: cs.CV

TL;DR: UnionST-S合成数据集和SEL框架显著提升STR模型性能，减少对真实数据标签的依赖。


<details>
  <summary>Details</summary>
Motivation: 解决现有合成数据在语料、字体和布局多样性不足的问题，以缩小与真实数据的领域差距。

Method: 提出了UnionST数据引擎和UnionST-S合成数据集，以及自进化学习（SEL）框架。

Result: 实验显示，UnionST-S训练的模型优于现有合成数据集，并在某些场景超越真实数据性能；SEL仅需9%的真实标签即可达到竞争性表现。

Conclusion: UnionST-S和SEL框架显著提升了STR模型的性能，甚至在特定场景下超越了真实数据训练的效果，同时大幅减少了所需真实数据标签量。

Abstract: Large-scale and categorical-balanced text data is essential for training effective Scene Text Recognition (STR) models, which is hard to achieve when collecting real data. Synthetic data offers a cost-effective and perfectly labeled alternative. However, its performance often lags behind, revealing a significant domain gap between real and current synthetic data. In this work, we systematically analyze mainstream rendering-based synthetic datasets and identify their key limitations: insufficient diversity in corpus, font, and layout, which restricts their realism in complex scenarios. To address these issues, we introduce UnionST, a strong data engine synthesizes text covering a union of challenging samples and better aligns with the complexity observed in the wild. We then construct UnionST-S, a large-scale synthetic dataset with improved simulations in challenging scenarios. Furthermore, we develop a self-evolution learning (SEL) framework for effective real data annotation. Experiments show that models trained on UnionST-S achieve significant improvements over existing synthetic datasets. They even surpass real-data performance in certain scenarios. Moreover, when using SEL, the trained models achieve competitive performance by only seeing 9% of real data labels.

</details>


### [41] [Exploring Specular Reflection Inconsistency for Generalizable Face Forgery Detection](https://arxiv.org/abs/2602.06452)
*Hongyan Fei,Zexi Jia,Chuanwei Huang,Jinchao Zhang,Jie Zhou*

Main category: cs.CV

TL;DR: 论文提出了一种基于镜面反射不一致性的Deepfake检测方法（SRI-Net），通过分析面部纹理与光照的复杂关系，显著提升了检测性能，尤其在扩散模型生成的伪造面部中表现突出。


<details>
  <summary>Details</summary>
Motivation: 随着AI生成方法（尤其是扩散模型）合成的伪造面部质量和分辨率达到前所未有的水平，现有的基于空间和频率特征的伪造检测方法对高质量、完全合成的伪造效果有限。

Method: 论文提出了一种基于Retinex理论的快速准确的面部纹理估计方法，用于精确分离镜面反射，并设计了SRI-Net网络，采用两阶段交叉注意力机制捕捉镜面反射与面部纹理及直射光的关系。

Result: 实验结果表明，该方法在传统和生成式Deepfake数据集上均取得了优越性能，特别是在包含扩散生成伪造面部的数据集中。

Conclusion: 该论文提出的基于镜面反射不一致性的检测方法（SRI-Net）在传统和生成式Deepfake数据集上均表现出优越性能，尤其在扩散模型生成的伪造面部检测中效果显著。

Abstract: Detecting deepfakes has become increasingly challenging as forgery faces synthesized by AI-generated methods, particularly diffusion models, achieve unprecedented quality and resolution. Existing forgery detection approaches relying on spatial and frequency features demonstrate limited efficacy against high-quality, entirely synthesized forgeries. In this paper, we propose a novel detection method grounded in the observation that facial attributes governed by complex physical laws and multiple parameters are inherently difficult to replicate. Specifically, we focus on illumination, particularly the specular reflection component in the Phong illumination model, which poses the greatest replication challenge due to its parametric complexity and nonlinear formulation. We introduce a fast and accurate face texture estimation method based on Retinex theory to enable precise specular reflection separation. Furthermore, drawing from the mathematical formulation of specular reflection, we posit that forgery evidence manifests not only in the specular reflection itself but also in its relationship with corresponding face texture and direct light. To address this issue, we design the Specular-Reflection-Inconsistency-Network (SRI-Net), incorporating a two-stage cross-attention mechanism to capture these correlations and integrate specular reflection related features with image features for robust forgery detection. Experimental results demonstrate that our method achieves superior performance on both traditional deepfake datasets and generative deepfake datasets, particularly those containing diffusion-generated forgery faces.

</details>


### [42] [LAB-Det: Language as a Domain-Invariant Bridge for Training-Free One-Shot Domain Generalization in Object Detection](https://arxiv.org/abs/2602.06474)
*Xu Zhang,Zhe Chen,Jing Zhang,Dacheng Tao*

Main category: cs.CV

TL;DR: LAB-Det是一种无需训练的领域适应方法，通过语言描述指导冻结检测器，在数据稀缺的专业领域检测中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决通用检测器在专业领域（如水下或工业缺陷）数据稀缺时性能下降的问题，探索无需训练、仅需每类一个样本的冻结检测器适应方法。

Method: 提出了LAB-Det方法，利用语言作为领域不变桥梁，将每个样本投影为描述性文本，以此指导和条件冻结的检测器，替代基于梯度的适应。

Result: 在UODD和NEU-DET基准测试中，LAB-Det相比最先进的微调基线实现了最高5.4 mAP的提升，且无需更新任何参数。

Conclusion: LAB-Det通过语言作为领域不变桥梁的方法，在数据稀缺的专业领域检测中实现了无需参数更新的高效适应，展示了语言适应作为微调替代方案的潜力和可解释性。

Abstract: Foundation object detectors such as GLIP and Grounding DINO excel on general-domain data but often degrade in specialized and data-scarce settings like underwater imagery or industrial defects. Typical cross-domain few-shot approaches rely on fine-tuning scarce target data, incurring cost and overfitting risks. We instead ask: Can a frozen detector adapt with only one exemplar per class without training? To answer this, we introduce training-free one-shot domain generalization for object detection, where detectors must adapt to specialized domains with only one annotated exemplar per class and no weight updates. To tackle this task, we propose LAB-Det, which exploits Language As a domain-invariant Bridge. Instead of adapting visual features, we project each exemplar into a descriptive text that conditions and guides a frozen detector. This linguistic conditioning replaces gradient-based adaptation, enabling robust generalization in data-scarce domains. We evaluate on UODD (underwater) and NEU-DET (industrial defects), two widely adopted benchmarks for data-scarce detection, where object boundaries are often ambiguous, and LAB-Det achieves up to 5.4 mAP improvement over state-of-the-art fine-tuned baselines without updating a single parameter. These results establish linguistic adaptation as an efficient and interpretable alternative to fine-tuning in specialized detection settings.

</details>


### [43] [DriveWorld-VLA: Unified Latent-Space World Modeling with Vision-Language-Action for Autonomous Driving](https://arxiv.org/abs/2602.06521)
*Feiyang jia,Lin Liu,Ziying Song,Caiyan Jia,Hangjun Ye,Xiaoshuai Hao,Long Chen*

Main category: cs.CV

TL;DR: DriveWorld-VLA是一个新型框架，通过潜在空间统一世界建模和规划，提升了自动驾驶的决策效率和前瞻性，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法因潜在状态共享不足，无法有效统一未来场景演化和动作规划，限制了视觉想象对动作决策的影响。

Method: 提出了DriveWorld-VLA框架，通过在表示层面紧密集成VLA和世界模型，在潜在空间中统一进行世界建模和规划，支持特征级的可控想象。

Result: 在NAVSIMv1和NAVSIMv2上分别达到91.3 PDMS和86.8 EPDMS，nuScenes上的3秒平均碰撞率为0.16。

Conclusion: DriveWorld-VLA通过将世界建模和规划统一在潜在空间中，显著提升了自动驾驶决策的前瞻性和效率，实现了在多个基准测试中的最先进性能。

Abstract: End-to-end (E2E) autonomous driving has recently attracted increasing interest in unifying Vision-Language-Action (VLA) with World Models to enhance decision-making and forward-looking imagination. However, existing methods fail to effectively unify future scene evolution and action planning within a single architecture due to inadequate sharing of latent states, limiting the impact of visual imagination on action decisions. To address this limitation, we propose DriveWorld-VLA, a novel framework that unifies world modeling and planning within a latent space by tightly integrating VLA and world models at the representation level, which enables the VLA planner to benefit directly from holistic scene-evolution modeling and reducing reliance on dense annotated supervision. Additionally, DriveWorld-VLA incorporates the latent states of the world model as core decision-making states for the VLA planner, facilitating the planner to assess how candidate actions impact future scene evolution. By conducting world modeling entirely in the latent space, DriveWorld-VLA supports controllable, action-conditioned imagination at the feature level, avoiding expensive pixel-level rollouts. Extensive open-loop and closed-loop evaluations demonstrate the effectiveness of DriveWorld-VLA, which achieves state-of-the-art performance with 91.3 PDMS on NAVSIMv1, 86.8 EPDMS on NAVSIMv2, and 0.16 3-second average collision rate on nuScenes. Code and models will be released in https://github.com/liulin815/DriveWorld-VLA.git.

</details>


### [44] [Efficient-LVSM: Faster, Cheaper, and Better Large View Synthesis Model via Decoupled Co-Refinement Attention](https://arxiv.org/abs/2602.06478)
*Xiaosong Jia,Yihang Sun,Junqi You,Songbur Wong,Zichen Zou,Junchi Yan,Zuxuan Wu,Yu-Gang Jiang*

Main category: cs.CV

TL;DR: Efficient-LVSM通过解耦的双流架构优化了新视角合成的效率和性能，显著提升了速度和精度。


<details>
  <summary>Details</summary>
Motivation: LVSM的全自注意力设计存在二次复杂度问题和异构令牌间的参数共享问题，Efficient-LVSM旨在解决这些问题。

Method: 提出了Efficient-LVSM，一种双流架构，采用解耦的共优化机制，分别对输入视角和目标视角应用自注意力和自后交叉注意力。

Result: 在RealEstate10K上，Efficient-LVSM以2个输入视角实现了29.86 dB PSNR，比LVSM高0.2 dB，训练收敛速度快2倍，推理速度快4.4倍。

Conclusion: Efficient-LVSM通过解耦设计实现了高效的新视角合成，在多个基准测试中达到了最先进的性能，并展示了强大的零样本泛化能力。

Abstract: Feedforward models for novel view synthesis (NVS) have recently advanced by transformer-based methods like LVSM, using attention among all input and target views. In this work, we argue that its full self-attention design is suboptimal, suffering from quadratic complexity with respect to the number of input views and rigid parameter sharing among heterogeneous tokens. We propose Efficient-LVSM, a dual-stream architecture that avoids these issues with a decoupled co-refinement mechanism. It applies intra-view self-attention for input views and self-then-cross attention for target views, eliminating unnecessary computation. Efficient-LVSM achieves 29.86 dB PSNR on RealEstate10K with 2 input views, surpassing LVSM by 0.2 dB, with 2x faster training convergence and 4.4x faster inference speed. Efficient-LVSM achieves state-of-the-art performance on multiple benchmarks, exhibits strong zero-shot generalization to unseen view counts, and enables incremental inference with KV-cache, thanks to its decoupled designs.

</details>


### [45] [LIBERO-X: Robustness Litmus for Vision-Language-Action Models](https://arxiv.org/abs/2602.06556)
*Guodong Wang,Chenkai Zhang,Qingjie Liu,Jinjin Zhang,Jiancheng Cai,Junjie Liu,Xinmin Liu*

Main category: cs.CV

TL;DR: LIBERO-X是一个针对VLA模型的新基准，通过分层评估和多样化训练数据，更可靠地评估模型性能，揭示其局限性。


<details>
  <summary>Details</summary>
Motivation: 现有基准由于评估协议不足，无法充分捕捉真实世界的分布变化，导致评估结果有限或误导性。

Method: 引入LIBERO-X基准，包括分层评估协议（针对空间泛化、物体识别和任务指令理解）和通过人类远程操作收集的高多样性训练数据集。

Result: 实验显示代表性VLA模型在累积扰动下性能显著下降，暴露了场景理解和指令基础的持续局限性。

Conclusion: LIBERO-X通过整合分层评估与多样化训练数据，为评估和推进VLA模型的发展提供了更可靠的基础。

Abstract: Reliable benchmarking is critical for advancing Vision-Language-Action (VLA) models, as it reveals their generalization, robustness, and alignment of perception with language-driven manipulation tasks. However, existing benchmarks often provide limited or misleading assessments due to insufficient evaluation protocols that inadequately capture real-world distribution shifts. This work systematically rethinks VLA benchmarking from both evaluation and data perspectives, introducing LIBERO-X, a benchmark featuring: 1) A hierarchical evaluation protocol with progressive difficulty levels targeting three core capabilities: spatial generalization, object recognition, and task instruction understanding. This design enables fine-grained analysis of performance degradation under increasing environmental and task complexity; 2) A high-diversity training dataset collected via human teleoperation, where each scene supports multiple fine-grained manipulation objectives to bridge the train-evaluation distribution gap. Experiments with representative VLA models reveal significant performance drops under cumulative perturbations, exposing persistent limitations in scene comprehension and instruction grounding. By integrating hierarchical evaluation with diverse training data, LIBERO-X offers a more reliable foundation for assessing and advancing VLA development.

</details>


### [46] [Instance-Free Domain Adaptive Object Detection](https://arxiv.org/abs/2602.06484)
*Hengfu Yu,Jinhong Deng,Lixin Duan,Wen Li*

Main category: cs.CV

TL;DR: 论文提出了一种无需目标实例的域适应目标检测方法RSCN，通过背景特征原型和对齐策略实现稳健适应，并在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 许多实际场景中（如野生动物监测、病变检测），收集包含目标实例的目标域数据成本高昂，而仅含背景的数据却很丰富。这导致传统域适应方法难以应用。

Method: 提出了Relational and Structural Consistency Network (RSCN)，通过背景特征原型对齐和源域前景与背景特征关系的一致性来实现域适应。

Result: RSCN在三个专门设计的基准测试（模拟自动驾驶检测、野生动物检测和肺结节检测）中显著优于现有方法。

Conclusion: RSCN提出了一种基于背景特征原型的对齐策略，能够在没有目标实例的情况下实现稳健的域适应，显著优于现有DAOD方法。

Abstract: While Domain Adaptive Object Detection (DAOD) has made significant strides, most methods rely on unlabeled target data that is assumed to contain sufficient foreground instances. However, in many practical scenarios (e.g., wildlife monitoring, lesion detection), collecting target domain data with objects of interest is prohibitively costly, whereas background-only data is abundant. This common practical constraint introduces a significant technical challenge: the difficulty of achieving domain alignment when target instances are unavailable, forcing adaptation to rely solely on the target background information. We formulate this challenge as the novel problem of Instance-Free Domain Adaptive Object Detection. To tackle this, we propose the Relational and Structural Consistency Network (RSCN) which pioneers an alignment strategy based on background feature prototypes while simultaneously encouraging consistency in the relationship between the source foreground features and the background features within each domain, enabling robust adaptation even without target instances. To facilitate research, we further curate three specialized benchmarks, including simulative auto-driving detection, wildlife detection, and lung nodule detection. Extensive experiments show that RSCN significantly outperforms existing DAOD methods across all three benchmarks in the instance-free scenario. The code and benchmarks will be released soon.

</details>


### [47] [Rebenchmarking Unsupervised Monocular 3D Occupancy Prediction](https://arxiv.org/abs/2602.06488)
*Zizhan Guo,Yi Feng,Mengtan Zhang,Haoran Zhang,Wei Ye,Rui Fan*

Main category: cs.CV

TL;DR: 本文提出无监督单目3D占用预测新基准和遮挡感知机制，解决训练-评估不一致和遮挡模糊问题，性能媲美监督方法。


<details>
  <summary>Details</summary>
Motivation: 现有无监督方法在训练与评估协议间存在不一致性，且2D真值无法揭示遮挡区域的固有模糊性。本文旨在解决这些问题。

Method: 通过重新解释体积渲染过程中的变量，确定最物理一致的占用概率表示，并改进评估协议以对齐3D体素占用真值。引入遮挡感知极化机制，结合多视角视觉线索增强遮挡区域的区分能力。

Result: 实验表明，该方法显著优于现有无监督方法，性能与监督方法相当。

Conclusion: 本文提出的无监督单目3D占用预测基准和遮挡感知极化机制显著提升了性能，不仅超越现有无监督方法，甚至与监督方法媲美。

Abstract: Inferring the 3D structure from a single image, particularly in occluded regions, remains a fundamental yet unsolved challenge in vision-centric autonomous driving. Existing unsupervised approaches typically train a neural radiance field and treat the network outputs as occupancy probabilities during evaluation, overlooking the inconsistency between training and evaluation protocols. Moreover, the prevalent use of 2D ground truth fails to reveal the inherent ambiguity in occluded regions caused by insufficient geometric constraints. To address these issues, this paper presents a reformulated benchmark for unsupervised monocular 3D occupancy prediction. We first interpret the variables involved in the volume rendering process and identify the most physically consistent representation of the occupancy probability. Building on these analyses, we improve existing evaluation protocols by aligning the newly identified representation with voxel-wise 3D occupancy ground truth, thereby enabling unsupervised methods to be evaluated in a manner consistent with that of supervised approaches. Additionally, to impose explicit constraints in occluded regions, we introduce an occlusion-aware polarization mechanism that incorporates multi-view visual cues to enhance discrimination between occupied and free spaces in these regions. Extensive experiments demonstrate that our approach not only significantly outperforms existing unsupervised approaches but also matches the performance of supervised ones. Our source code and evaluation protocol will be made available upon publication.

</details>


### [48] [DreamHome-Pano: Design-Aware and Conflict-Free Panoramic Interior Generation](https://arxiv.org/abs/2602.06494)
*Lulu Chen,Yijiang Hu,Yuanqing Liu,Yulong Li,Yue Yang*

Main category: cs.CV

TL;DR: DreamHome-Pano 是一个可控的全景生成框架，通过语义桥梁和多条件解耦策略，解决了风格与结构冲突问题，实现了高质量的室内合成。


<details>
  <summary>Details</summary>
Motivation: 解决现有多条件生成框架在协调建筑结构约束与风格偏好时的‘条件冲突’问题。

Method: 引入 Prompt-LLM 作为语义桥梁，开发 Conflict-Free Control 架构，结合结构感知几何先验和多条件解耦策略，并采用多阶段训练流程。

Result: 实验结果表明，DreamHome-Pano 在美学质量与结构一致性上取得了优越的平衡。

Conclusion: DreamHome-Pano 提供了一个平衡美学质量与结构一致性的解决方案，适用于全景室内可视化。

Abstract: In modern interior design, the generation of personalized spaces frequently necessitates a delicate balance between rigid architectural structural constraints and specific stylistic preferences. However, existing multi-condition generative frameworks often struggle to harmonize these inputs, leading to "condition conflicts" where stylistic attributes inadvertently compromise the geometric precision of the layout. To address this challenge, we present DreamHome-Pano, a controllable panoramic generation framework designed for high-fidelity interior synthesis. Our approach introduces a Prompt-LLM that serves as a semantic bridge, effectively translating layout constraints and style references into professional descriptive prompts to achieve precise cross-modal alignment. To safeguard architectural integrity during the generative process, we develop a Conflict-Free Control architecture that incorporates structural-aware geometric priors and a multi-condition decoupling strategy, effectively suppressing stylistic interference from eroding the spatial layout. Furthermore, we establish a comprehensive panoramic interior benchmark alongside a multi-stage training pipeline, encompassing progressive Supervised Fine-Tuning (SFT) and Reinforcement Learning (RL). Experimental results demonstrate that DreamHome-Pano achieves a superior balance between aesthetic quality and structural consistency, offering a robust and professional-grade solution for panoramic interior visualization.

</details>


### [49] [SPARC: Separating Perception And Reasoning Circuits for Test-time Scaling of VLMs](https://arxiv.org/abs/2602.06566)
*Niccolo Avogaro,Nayanika Debnath,Li Mi,Thomas Frick,Junling Wang,Zexue He,Hang Hua,Konrad Schindler,Mattia Rigotti*

Main category: cs.CV

TL;DR: SPARC通过分离视觉感知与推理，优化计算资源分配，显著提升视觉语言模型的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 当前视觉语言模型在测试时动态调整计算资源（如token预算）时表现脆弱，感知与推理的耦合导致错误累积和性能下降。

Method: SPARC采用两阶段流水线：首先进行显式视觉搜索以定位问题相关区域，然后基于这些区域进行推理生成最终答案。

Result: SPARC在多个视觉推理基准测试中表现优异，例如在V* VQA基准上将Qwen3VL-4B的准确率提高了6.7个百分点，并在OOD任务中以200倍更低的token预算超越了“thinking with images”。

Conclusion: SPARC框架通过明确分离视觉感知与推理，实现了在测试时灵活调整计算资源分配，显著提升了视觉语言模型的性能和效率。

Abstract: Despite recent successes, test-time scaling - i.e., dynamically expanding the token budget during inference as needed - remains brittle for vision-language models (VLMs): unstructured chains-of-thought about images entangle perception and reasoning, leading to long, disorganized contexts where small perceptual mistakes may cascade into completely wrong answers. Moreover, expensive reinforcement learning with hand-crafted rewards is required to achieve good performance. Here, we introduce SPARC (Separating Perception And Reasoning Circuits), a modular framework that explicitly decouples visual perception from reasoning. Inspired by sequential sensory-to-cognitive processing in the brain, SPARC implements a two-stage pipeline where the model first performs explicit visual search to localize question-relevant regions, then conditions its reasoning on those regions to produce the final answer. This separation enables independent test-time scaling with asymmetric compute allocation (e.g., prioritizing perceptual processing under distribution shift), supports selective optimization (e.g., improving the perceptual stage alone when it is the bottleneck for end-to-end performance), and accommodates compressed contexts by running global search at lower image resolutions and allocating high-resolution processing only to selected regions, thereby reducing total visual tokens count and compute. Across challenging visual reasoning benchmarks, SPARC outperforms monolithic baselines and strong visual-grounding approaches. For instance, SPARC improves the accuracy of Qwen3VL-4B on the $V^*$ VQA benchmark by 6.7 percentage points, and it surpasses "thinking with images" by 4.6 points on a challenging OOD task despite requiring a 200$\times$ lower token budget.

</details>


### [50] [Forest canopy height estimation from satellite RGB imagery using large-scale airborne LiDAR-derived training data and monocular depth estimation](https://arxiv.org/abs/2602.06503)
*Yongkang Lai,Xihan Mu,Tim R. McVicar,Dasheng Fan,Donghui Xie,Shanxin Guo,Wenli Huang,Tianjie Zhao,Guangjian Yan*

Main category: cs.CV

TL;DR: 利用航空LiDAR数据训练单目深度估计模型Depth2CHM，通过卫星RGB图像实现高精度、连续的森林冠层高度估算，显著优于现有全球产品。


<details>
  <summary>Details</summary>
Motivation: 解决星载LiDAR数据稀疏和不确定性问题，利用公开的航空LiDAR数据和高分辨率RGB图像，实现高精度、连续的森林冠层高度估算。

Method: 使用约16,000 km²的航空LiDAR点云和3米分辨率的PlanetScope及航空RGB图像，训练Depth Anything V2模型，生成Depth2CHM模型。

Result: Depth2CHM在两个验证点（中国约1 km²和美国约116 km²）的偏差分别为0.59 m和0.41 m，RMSE为2.54 m和5.75 m，相比现有全球米级CHM产品，MAE和RMSE分别降低了约1.5 m和2 m。

Conclusion: 训练单目深度估计模型Depth2CHM，利用大规模航空LiDAR数据，为高分辨率、空间连续的森林冠层高度估算提供了一条可行且可扩展的途径。

Abstract: Large-scale, high-resolution forest canopy height mapping plays a crucial role in understanding regional and global carbon and water cycles. Spaceborne LiDAR missions, including the Ice, Cloud, and Land Elevation Satellite-2 (ICESat-2) and the Global Ecosystem Dynamics Investigation (GEDI), provide global observations of forest structure but are spatially sparse and subject to inherent uncertainties. In contrast, near-surface LiDAR platforms, such as airborne and unmanned aerial vehicle (UAV) LiDAR systems, offer much finer measurements of forest canopy structure, and a growing number of countries have made these datasets openly available. In this study, a state-of-the-art monocular depth estimation model, Depth Anything V2, was trained using approximately 16,000 km2 of canopy height models (CHMs) derived from publicly available airborne LiDAR point clouds and related products across multiple countries, together with 3 m resolution PlanetScope and airborne RGB imagery. The trained model, referred to as Depth2CHM, enables the estimation of spatially continuous CHMs directly from PlanetScope RGB imagery. Independent validation was conducted at sites in China (approximately 1 km2) and the United States (approximately 116 km2). The results showed that Depth2CHM could accurately estimate canopy height, with biases of 0.59 m and 0.41 m and root mean square errors (RMSEs) of 2.54 m and 5.75 m for these two sites, respectively. Compared with an existing global meter-resolution CHM product, the mean absolute error is reduced by approximately 1.5 m and the RMSE by approximately 2 m. These results demonstrated that monocular depth estimation networks trained with large-scale airborne LiDAR-derived canopy height data provide a promising and scalable pathway for high-resolution, spatially continuous forest canopy height estimation from satellite RGB imagery.

</details>


### [51] [ProtoQuant: Quantization of Prototypical Parts For General and Fine-Grained Image Classification](https://arxiv.org/abs/2602.06592)
*Mikołaj Janusz,Adam Wróbel,Bartosz Zieliński,Dawid Rymarczyk*

Main category: cs.CV

TL;DR: ProtoQuant通过潜在向量量化解决原型漂移问题，实现高效、可解释的大规模图像分类。


<details>
  <summary>Details</summary>
Motivation: 解决原型漂移问题，提高原型部分模型在ImageNet规模上的泛化能力，同时保持计算效率。

Method: ProtoQuant采用潜在空间中的离散学习码本约束原型，确保其对训练数据的忠实表示。

Result: 在ImageNet和细粒度基准测试（CUB-200、Cars-196）上，ProtoQuant实现了竞争性分类准确率，并保持了与其他原型部分方法相当的可解释性指标。

Conclusion: ProtoQuant通过潜在向量量化实现了原型稳定性和可解释性，无需更新主干网络，适用于大规模数据集。

Abstract: Prototypical parts-based models offer a "this looks like that" paradigm for intrinsic interpretability, yet they typically struggle with ImageNet-scale generalization and often require computationally expensive backbone finetuning. Furthermore, existing methods frequently suffer from "prototype drift," where learned prototypes lack tangible grounding in the training distribution and change their activation under small perturbations. We present ProtoQuant, a novel architecture that achieves prototype stability and grounded interpretability through latent vector quantization. By constraining prototypes to a discrete learned codebook within the latent space, we ensure they remain faithful representations of the training data without the need to update the backbone. This design allows ProtoQuant to function as an efficient, interpretable head that scales to large-scale datasets. We evaluate ProtoQuant on ImageNet and several fine-grained benchmarks (CUB-200, Cars-196). Our results demonstrate that ProtoQuant achieves competitive classification accuracy while generalizing to ImageNet and comparable interpretability metrics to other prototypical-parts-based methods.

</details>


### [52] [FloorplanVLM: A Vision-Language Model for Floorplan Vectorization](https://arxiv.org/abs/2602.06507)
*Yuanqing Liu,Ziming Yang,Yulong Li,Yue Yang*

Main category: cs.CV

TL;DR: FloorplanVLM通过图像条件序列建模和渐进训练策略，高效转换栅格平面图为矢量图形，性能显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决传统基于像素的方法依赖脆弱启发式或基于查询的Transformer生成碎片化房间的问题，实现复杂几何的全局拓扑精确表示。

Method: FloorplanVLM采用'像素到序列'的范式，直接输出结构化JSON序列，结合大规模数据集（Floorplan-2M和Floorplan-HQ-300K）和渐进式训练策略（SFT和GRPO）。

Result: 在FPBench-2K基准测试中，FloorplanVLM外部墙IoU达到92.52%，并在非曼哈顿架构中表现出强大的泛化能力。

Conclusion: FloorplanVLM通过统一的图像条件序列建模框架，成功解决了将栅格平面图转换为工程级矢量图形的挑战，展示了卓越的结构有效性和泛化能力。

Abstract: Converting raster floorplans into engineering-grade vector graphics is challenging due to complex topology and strict geometric constraints. To address this, we present FloorplanVLM, a unified framework that reformulates floorplan vectorization as an image-conditioned sequence modeling task. Unlike pixel-based methods that rely on fragile heuristics or query-based transformers that generate fragmented rooms, our model directly outputs structured JSON sequences representing the global topology. This 'pixels-to-sequence' paradigm enables the precise and holistic constraint satisfaction of complex geometries, such as slanted walls and curved arcs. To support this data-hungry approach, we introduce a scalable data engine: we construct a large-scale dataset (Floorplan-2M) and a high-fidelity subset (Floorplan-HQ-300K) to balance geometric diversity and pixel-level precision. We then employ a progressive training strategy, using Supervised Fine-Tuning (SFT) for structural grounding and quality annealing, followed by Group Relative Policy Optimization (GRPO) for strict geometric alignment. To standardize evaluation on complex layouts, we establish and open-source FPBench-2K. Evaluated on this rigorous benchmark, FloorplanVLM demonstrates exceptional structural validity, achieving $\textbf{92.52%}$ external-wall IoU and robust generalization across non-Manhattan architectures.

</details>


### [53] [DAVE: Distribution-aware Attribution via ViT Gradient Decomposition](https://arxiv.org/abs/2602.06613)
*Adam Wróbel,Siddhartha Gairola,Jacek Tabor,Bernt Schiele,Bartosz Zieliński,Dawid Rymarczyk*

Main category: cs.CV

TL;DR: DAVE是一种基于ViT梯度分解的归因方法，有效减少架构伪影，提升归因图稳定性。


<details>
  <summary>Details</summary>
Motivation: ViT在计算机视觉中占主导地位，但其高分辨率归因图存在稳定性问题，现有方法多依赖粗糙的补丁级归因。

Method: DAVE通过结构化分解输入梯度，利用ViT的架构特性，分离局部等变和稳定的组件。

Result: DAVE能够有效减少架构诱导的伪影，生成更稳定的高分辨率归因图。

Conclusion: DAVE提供了一种基于ViT梯度分解的数学基础方法，能够有效分离局部等变和稳定的输入输出映射组件，从而减少架构诱导的伪影。

Abstract: Vision Transformers (ViTs) have become a dominant architecture in computer vision, yet producing stable and high-resolution attribution maps for these models remains challenging. Architectural components such as patch embeddings and attention routing often introduce structured artifacts in pixel-level explanations, causing many existing methods to rely on coarse patch-level attributions. We introduce DAVE \textit{(\underline{D}istribution-aware \underline{A}ttribution via \underline{V}iT Gradient D\underline{E}composition)}, a mathematically grounded attribution method for ViTs based on a structured decomposition of the input gradient. By exploiting architectural properties of ViTs, DAVE isolates locally equivariant and stable components of the effective input--output mapping. It separates these from architecture-induced artifacts and other sources of instability.

</details>


### [54] [MicroBi-ConvLSTM: An Ultra-Lightweight Efficient Model for Human Activity Recognition on Resource Constrained Devices](https://arxiv.org/abs/2602.06523)
*Mridankan Mandal*

Main category: cs.CV

TL;DR: MicroBi-ConvLSTM是一种超轻量级HAR模型，参数仅11.4K，在多种基准测试中表现优异，量化后适合边缘设备部署。


<details>
  <summary>Details</summary>
Motivation: 解决资源受限可穿戴设备上HAR模型在内存和计算预算严格限制下的准确性与轻量化平衡问题。

Method: 采用两阶段卷积特征提取和4倍时间池化，结合单层双向LSTM层构建超轻量级卷积-循环架构。

Result: 在八个HAR基准测试中表现优异，如UCI-HAR的93.41%宏F1，SKODA组装手势的94.46%，Daphnet步态冻结检测的88.98%。INT8量化后平均F1分数仅下降0.21%。

Conclusion: MicroBi-ConvLSTM通过两阶段卷积特征提取和4倍时间池化，结合单层双向LSTM，实现了平均11.4K参数的轻量化设计，显著降低了参数数量，同时保持了线性复杂度。在多种HAR基准测试中表现优异，且INT8量化后部署体积仅23.0 KB，适合资源受限的边缘设备。

Abstract: Human Activity Recognition (HAR) on resource constrained wearables requires models that balance accuracy against strict memory and computational budgets. State of the art lightweight architectures such as TinierHAR (34K parameters) and TinyHAR (55K parameters) achieve strong accuracy, but exceed memory budgets of microcontrollers with limited SRAM once operating system overhead is considered. We present MicroBi-ConvLSTM, an ultra-lightweight convolutional-recurrent architecture achieving 11.4K parameters on average through two stage convolutional feature extraction with 4x temporal pooling and a single bidirectional LSTM layer. This represents 2.9x parameter reduction versus TinierHAR and 11.9x versus DeepConvLSTM while preserving linear O(N) complexity. Evaluation across eight diverse HAR benchmarks shows that MicroBi-ConvLSTM maintains competitive performance within the ultra-lightweight regime: 93.41% macro F1 on UCI-HAR, 94.46% on SKODA assembly gestures, and 88.98% on Daphnet gait freeze detection. Systematic ablation reveals task dependent component contributions where bidirectionality benefits episodic event detection, but provides marginal gains on periodic locomotion. INT8 post training quantization incurs only 0.21% average F1-score degradation, yielding a 23.0 KB average deployment footprint suitable for memory constrained edge devices.

</details>


### [55] [AdaptOVCD: Training-Free Open-Vocabulary Remote Sensing Change Detection via Adaptive Information Fusion](https://arxiv.org/abs/2602.06529)
*Mingyu Dou,Shi Qiu,Ming Hu,Yifan Chen,Huping Ye,Xiaohan Liao,Zhe Sun*

Main category: cs.CV

TL;DR: AdaptOVCD是一种无训练的开放词汇变化检测框架，通过多层次信息融合和预训练模型协同，实现了高性能和强泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法依赖预定义类别和大规模像素级标注的问题，提升在开放世界场景中的泛化性和适用性。

Method: 提出AdaptOVCD框架，结合数据、特征和决策层面的多层次信息融合，包括自适应辐射对齐（ARA）、自适应变化阈值（ACT）和自适应置信过滤（ACF），并与SAM-HQ、DINOv3和DGTRS-CLIP等预训练模型协同工作。

Result: 在九种场景的综合评估中，AdaptOVCD以零样本方式检测任意类别变化，性能显著优于现有无训练方法，并在跨数据集评估中接近全监督性能上限。

Conclusion: AdaptOVCD通过双维度多层次信息融合，实现了在开放词汇变化检测中的高性能和强泛化能力，显著优于现有无训练方法，并在跨数据集评估中达到了84.89%的全监督性能上限。

Abstract: Remote sensing change detection plays a pivotal role in domains such as environmental monitoring, urban planning, and disaster assessment. However, existing methods typically rely on predefined categories and large-scale pixel-level annotations, which limit their generalization and applicability in open-world scenarios. To address these limitations, this paper proposes AdaptOVCD, a training-free Open-Vocabulary Change Detection (OVCD) architecture based on dual-dimensional multi-level information fusion. The framework integrates multi-level information fusion across data, feature, and decision levels vertically while incorporating targeted adaptive designs horizontally, achieving deep synergy among heterogeneous pre-trained models to effectively mitigate error propagation. Specifically, (1) at the data level, Adaptive Radiometric Alignment (ARA) fuses radiometric statistics with original texture features and synergizes with SAM-HQ to achieve radiometrically consistent segmentation; (2) at the feature level, Adaptive Change Thresholding (ACT) combines global difference distributions with edge structure priors and leverages DINOv3 to achieve robust change detection; (3) at the decision level, Adaptive Confidence Filtering (ACF) integrates semantic confidence with spatial constraints and collaborates with DGTRS-CLIP to achieve high-confidence semantic identification. Comprehensive evaluations across nine scenarios demonstrate that AdaptOVCD detects arbitrary category changes in a zero-shot manner, significantly outperforming existing training-free methods. Meanwhile, it achieves 84.89\% of the fully-supervised performance upper bound in cross-dataset evaluations and exhibits superior generalization capabilities. The code is available at https://github.com/Dmygithub/AdaptOVCD.

</details>


### [56] [Universal Anti-forensics Attack against Image Forgery Detection via Multi-modal Guidance](https://arxiv.org/abs/2602.06530)
*Haipeng Li,Rongxuan Peng,Anwei Luo,Shunquan Tan,Changsheng Chen,Anastasia Antsiferova*

Main category: cs.CV

TL;DR: ForgeryEraser通过多模态引导攻击AIGC检测器，显著降低其性能并生成一致解释。


<details>
  <summary>Details</summary>
Motivation: 现有评估协议忽视抗取证攻击，无法确保AIGC检测器在现实应用中的全面鲁棒性。

Method: 提出ForgeryEraser框架，利用多模态引导损失将伪造图像嵌入推向文本衍生的真实锚点，同时远离伪造锚点，无需访问目标AIGC检测器。

Result: 实验表明ForgeryEraser在全局合成和局部编辑基准上均导致先进AIGC检测器性能显著下降，并生成一致的解释。

Conclusion: ForgeryEraser框架通过多模态引导损失有效消除了伪造痕迹，显著降低了先进AIGC检测器的性能，并生成与真实图像一致的解释。

Abstract: The rapid advancement of AI-Generated Content (AIGC) technologies poses significant challenges for authenticity assessment. However, existing evaluation protocols largely overlook anti-forensics attack, failing to ensure the comprehensive robustness of state-of-the-art AIGC detectors in real-world applications. To bridge this gap, we propose ForgeryEraser, a framework designed to execute universal anti-forensics attack without access to the target AIGC detectors. We reveal an adversarial vulnerability stemming from the systemic reliance on Vision-Language Models (VLMs) as shared backbones (e.g., CLIP), where downstream AIGC detectors inherit the feature space of these publicly accessible models. Instead of traditional logit-based optimization, we design a multi-modal guidance loss to drive forged image embeddings within the VLM feature space toward text-derived authentic anchors to erase forgery traces, while repelling them from forgery anchors. Extensive experiments demonstrate that ForgeryEraser causes substantial performance degradation to advanced AIGC detectors on both global synthesis and local editing benchmarks. Moreover, ForgeryEraser induces explainable forensic models to generate explanations consistent with authentic images for forged images. Our code will be made publicly available.

</details>


### [57] [Gold Exploration using Representations from a Multispectral Autoencoder](https://arxiv.org/abs/2602.06748)
*Argyro Tsandalidou,Konstantinos Dogeas,Eleftheria Tetoula Tsonga,Elisavet Parselia,Georgios Tsimiklis,George Arvanitakis*

Main category: cs.CV

TL;DR: 利用Sentinel-2图像和自编码器基础模型提升金矿区域识别的准确性。


<details>
  <summary>Details</summary>
Motivation: 由于现场矿物勘探数据成本高且有限，利用卫星图像进行大规模成矿预测。

Method: 使用预训练的Isometric自编码器基础模型，从多光谱Sentinel-2图像中学习生成表征，并将其作为轻量级XGBoost分类器的输入。

Result: 提出的方法将补丁级准确率从0.51提高到0.68，图像级准确率从0.55提高到0.73，表明生成嵌入能捕获可转移的矿物学模式。

Conclusion: 该研究展示了基础模型表征在矿物勘探中的潜力，能够提高效率、可扩展性和全球适用性。

Abstract: Satellite imagery is employed for large-scale prospectivity mapping due to the high cost and typically limited availability of on-site mineral exploration data. In this work, we present a proof-of-concept framework that leverages generative representations learned from multispectral Sentinel-2 imagery to identify gold-bearing regions from space. An autoencoder foundation model, called Isometric, which is pretrained on the large-scale FalconSpace-S2 v1.0 dataset, produces information-dense spectral-spatial representations that serve as inputs to a lightweight XGBoost classifier. We compare this representation-based approach with a raw spectral input baseline using a dataset of 63 Sentinel-2 images from known gold and non-gold locations. The proposed method improves patch-level accuracy from 0.51 to 0.68 and image-level accuracy from 0.55 to 0.73, demonstrating that generative embeddings capture transferable mineralogical patterns even with limited labeled data. These results highlight the potential of foundation-model representations to make mineral exploration more efficient, scalable, and globally applicable.

</details>


### [58] [NECromancer: Breathing Life into Skeletons via BVH Animation](https://arxiv.org/abs/2602.06548)
*Mingxi Xu,Qi Wang,Zhengyu Wen,Phong Dao Thien,Zhengyu Li,Ning Zhang,Xiaoyu He,Wei Zhao,Kehong Gong,Mingyuan Zhang*

Main category: cs.CV

TL;DR: NECromancer 是一种通用运动标记化框架，通过编码骨架结构、压缩运动序列和聚合数据集，实现跨物种运动分析与合成。


<details>
  <summary>Details</summary>
Motivation: 现有运动标记化方法受限于特定物种的骨架，无法适应多样形态。NEC 旨在解决这一问题，直接处理任意 BVH 骨架。

Method: NEC 包含三个组件：(1) Ontology-aware Skeletal Graph Encoder (OwO) 编码 BVH 文件的结构先验；(2) Topology-Agnostic Tokenizer (TAT) 将运动序列压缩为通用的离散表示；(3) Unified BVH Universe (UvU) 数据集，聚合异构骨架的 BVH 运动。

Result: 实验表明，NEC 在高压缩下实现高保真重建，有效解耦运动与骨架结构，其标记空间支持多种跨形态运动任务。

Conclusion: NECromancer (NEC) 提出了一种通用的运动标记化框架，能够跨多样形态进行运动分析和合成，支持跨物种运动转移、合成、去噪、生成以及文本-运动检索。

Abstract: Motion tokenization is a key component of generalizable motion models, yet most existing approaches are restricted to species-specific skeletons, limiting their applicability across diverse morphologies. We propose NECromancer (NEC), a universal motion tokenizer that operates directly on arbitrary BVH skeletons. NEC consists of three components: (1) an Ontology-aware Skeletal Graph Encoder (OwO) that encodes structural priors from BVH files, including joint semantics, rest-pose offsets, and skeletal topology, into skeletal embeddings; (2) a Topology-Agnostic Tokenizer (TAT) that compresses motion sequences into a universal, topology-invariant discrete representation; and (3) the Unified BVH Universe (UvU), a large-scale dataset aggregating BVH motions across heterogeneous skeletons. Experiments show that NEC achieves high-fidelity reconstruction under substantial compression and effectively disentangles motion from skeletal structure. The resulting token space supports cross-species motion transfer, composition, denoising, generation with token-based models, and text-motion retrieval, establishing a unified framework for motion analysis and synthesis across diverse morphologies. Demo page: https://animotionlab.github.io/NECromancer/

</details>


### [59] [Rethinking Multi-Condition DiTs: Eliminating Redundant Attention via Position-Alignment and Keyword-Scoping](https://arxiv.org/abs/2602.06850)
*Chao Zhou,Tianyi Wei,Yiling Chen,Wenbo Zhou,Nenghai Yu*

Main category: cs.CV

TL;DR: PKA框架通过PAA和KSA高效消除多条件控制中的冗余，结合CSAS策略加速收敛，显著提升推理速度和资源利用率。


<details>
  <summary>Details</summary>
Motivation: 现代文本到图像模型在基于提示的生成方面表现出色，但在空间布局或主题外观等细粒度控制方面存在不足。多条件控制可以解决这一问题，但在Diffusion Transformers (DiTs)中的集成受到传统“连接并关注”策略的限制，该策略在条件数量增加时会导致二次计算和内存开销。

Method: 提出了Position-aligned and Keyword-scoped Attention (PKA)框架，包括Position-Aligned Attention (PAA)和Keyword-Scoped Attention (KSA)，并结合Conditional Sensitivity-Aware Sampling (CSAS)策略以加速收敛。

Result: PKA实现了10.0倍的推理加速和5.1倍的VRAM节省，显著提升了多条件生成的效率和资源利用率。

Conclusion: PKA框架通过Position-Aligned Attention (PAA)和Keyword-Scoped Attention (KSA)显著提升了多条件控制的效率，实现了10.0倍的推理加速和5.1倍的VRAM节省，为高保真多条件生成提供了可扩展且资源友好的解决方案。

Abstract: While modern text-to-image models excel at prompt-based generation, they often lack the fine-grained control necessary for specific user requirements like spatial layouts or subject appearances. Multi-condition control addresses this, yet its integration into Diffusion Transformers (DiTs) is bottlenecked by the conventional ``concatenate-and-attend'' strategy, which suffers from quadratic computational and memory overhead as the number of conditions scales. Our analysis reveals that much of this cross-modal interaction is spatially or semantically redundant. To this end, we propose Position-aligned and Keyword-scoped Attention (PKA), a highly efficient framework designed to eliminate these redundancies. Specifically, Position-Aligned Attention (PAA) linearizes spatial control by enforcing localized patch alignment, while Keyword-Scoped Attention (KSA) prunes irrelevant subject-driven interactions via semantic-aware masking. To facilitate efficient learning, we further introduce a Conditional Sensitivity-Aware Sampling (CSAS) strategy that reweights the training objective towards critical denoising phases, drastically accelerating convergence and enhancing conditional fidelity. Empirically, PKA delivers a 10.0$\times$ inference speedup and a 5.1$\times$ VRAM saving, providing a scalable and resource-friendly solution for high-fidelity multi-conditioned generation.

</details>


### [60] [An Integer Linear Programming Approach to Geometrically Consistent Partial-Partial Shape Matching](https://arxiv.org/abs/2602.06590)
*Viktoria Ehm,Paul Roetzer,Florian Bernard,Daniel Cremers*

Main category: cs.CV

TL;DR: 首个针对部分-部分3D形状匹配的整数线性规划方法，利用几何一致性先验，实现高质量匹配和可扩展性。


<details>
  <summary>Details</summary>
Motivation: 部分-部分3D形状匹配是最真实的场景（如3D扫描），但现有研究较少，因其需同时解决未知重叠区域和精确对应关系的挑战。

Method: 采用整数线性规划方法，结合几何一致性作为强先验，实现重叠区域的鲁棒估计和邻域保持的对应关系计算。

Result: 实验证明，该方法在匹配误差和平滑度方面均取得高质量结果，且比先前方法更具可扩展性。

Conclusion: 本文提出的整数线性规划方法在部分-部分3D形状匹配中表现出色，不仅匹配误差低且平滑度高，且具有更好的可扩展性。

Abstract: The task of establishing correspondences between two 3D shapes is a long-standing challenge in computer vision. While numerous studies address full-full and partial-full 3D shape matching, only a limited number of works have explored the partial-partial setting, very likely due to its unique challenges: we must compute accurate correspondences while at the same time find the unknown overlapping region. Nevertheless, partial-partial 3D shape matching reflects the most realistic setting, as in many real-world cases, such as 3D scanning, shapes are only partially observable. In this work, we introduce the first integer linear programming approach specifically designed to address the distinctive challenges of partial-partial shape matching. Our method leverages geometric consistency as a strong prior, enabling both robust estimation of the overlapping region and computation of neighbourhood-preserving correspondences. We empirically demonstrate that our approach achieves high-quality matching results both in terms of matching error and smoothness. Moreover, we show that our method is more scalable than previous formalisms.

</details>


### [61] [NanoFLUX: Distillation-Driven Compression of Large Text-to-Image Generation Models for Mobile Devices](https://arxiv.org/abs/2602.06879)
*Ruchika Chavhan,Malcolm Chadwick,Alberto Gil Couto Pimentel Ramos,Luca Morreale,Mehdi Noroozi,Abhinav Mehrotra*

Main category: cs.CV

TL;DR: NanoFLUX是一种从17B FLUX.1-Schnell蒸馏而来的2.4B文本到图像流匹配模型，通过压缩策略和新技术实现了移动设备上的高效高质量图像生成。


<details>
  <summary>Details</summary>
Motivation: 大规模文本到图像扩散模型在视觉质量上不断提升，但其规模扩大导致先进模型与设备端解决方案之间的差距加大。

Method: 1. 通过修剪扩散变压器中的冗余组件，将模型大小从12B压缩至2B；2. 引入基于ResNet的令牌下采样机制，降低延迟；3. 提出一种新颖的文本编码器蒸馏方法，利用采样期间去噪器早期层的视觉信号。

Result: NanoFLUX在移动设备上生成512x512图像仅需约2.5秒，展示了高质量设备端文本到图像生成的可行性。

Conclusion: NanoFLUX成功地将大规模文本到图像扩散模型压缩至适合移动设备的规模，同时保持了高质量的生成能力，证明了高质量设备端文本到图像生成的可行性。

Abstract: While large-scale text-to-image diffusion models continue to improve in visual quality, their increasing scale has widened the gap between state-of-the-art models and on-device solutions. To address this gap, we introduce NanoFLUX, a 2.4B text-to-image flow-matching model distilled from 17B FLUX.1-Schnell using a progressive compression pipeline designed to preserve generation quality. Our contributions include: (1) A model compression strategy driven by pruning redundant components in the diffusion transformer, reducing its size from 12B to 2B; (2) A ResNet-based token downsampling mechanism that reduces latency by allowing intermediate blocks to operate on lower-resolution tokens while preserving high-resolution processing elsewhere; (3) A novel text encoder distillation approach that leverages visual signals from early layers of the denoiser during sampling. Empirically, NanoFLUX generates 512 x 512 images in approximately 2.5 seconds on mobile devices, demonstrating the feasibility of high-quality on-device text-to-image generation.

</details>


### [62] [PANC: Prior-Aware Normalized Cut for Object Segmentation](https://arxiv.org/abs/2602.06912)
*Juan Gutiérrez,Victor Gutiérrez-Garcia,José Luis Blanco-Murillo*

Main category: cs.CV

TL;DR: PANC是一种弱监督光谱分割框架，通过少量标注视觉token生成稳定、可控的对象掩码，在多个数据集上达到SotA性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有无监督分割方法对初始化、种子顺序和阈值启发式敏感的问题，提供稳定、可控且可重复的对象掩码。

Method: 通过增强token-token亲和力图并引入少量先验锚点，操纵图拓扑以偏向与标注一致的分区。

Result: 在标准基准测试（如DUTS-TE、ECSSD、MS COCO）上表现优异，在CrackForest、CUB-200-2011和HAM10000数据集上分别达到96.8%、78.0%和78.8%的平均mIoU。

Conclusion: PANC框架在弱监督和无监督方法中实现了最先进的性能，特别是在密集标注成本高或类内差异细微的领域。

Abstract: Fully unsupervised segmentation pipelines naively seek the most salient object, should this be present. As a result, most of the methods reported in the literature deliver non-deterministic partitions that are sensitive to initialization, seed order, and threshold heuristics.
  We propose PANC, a weakly supervised spectral segmentation framework that uses a minimal set of annotated visual tokens to produce stable, controllable, and reproducible object masks. From the TokenCut approach, we augment the token-token affinity graph with a handful of priors coupled to anchor nodes. By manipulating the graph topology, we bias the spectral eigenspace toward partitions that are consistent with the annotations. Our approach preserves the global grouping enforced by dense self-supervised visual features, trading annotated tokens for significant gains in reproducibility, user control, and segmentation quality.
  Using 5 to 30 annotations per dataset, our training-free method achieves state-of-the-art performance among weakly and unsupervised approaches on standard benchmarks (e.g., DUTS-TE, ECSSD, MS COCO). Contrarily, it excels in domains where dense labels are costly or intra-class differences are subtle. We report strong and reliable results on homogeneous, fine-grained, and texture-limited domains, achieving 96.8% (+14.43% over SotA), 78.0% (+0.2%), and 78.8% (+0.37%) average mean intersection-over-union (mIoU) on CrackForest (CFD), CUB-200-2011, and HAM10000 datasets, respectively. For multi-object benchmarks, the framework showcases explicit, user-controllable semantic segmentation.

</details>


### [63] [CauCLIP: Bridging the Sim-to-Real Gap in Surgical Video Understanding via Causality-Inspired Vision-Language Modeling](https://arxiv.org/abs/2602.06619)
*Yuxin He,An Li,Cheng Xue*

Main category: cs.CV

TL;DR: CauCLIP利用因果启发的视觉语言框架，通过领域不变表示学习，显著提升了手术阶段识别的泛化能力。


<details>
  <summary>Details</summary>
Motivation: 手术阶段识别对智能手术室至关重要，但现有模型受限于标注数据不足和合成与真实数据的领域差距。

Method: 提出了CauCLIP框架，结合频率增强策略和因果抑制损失，以学习领域不变表示并强化因果手术特征。

Result: 在SurgVisDom硬适应基准测试中，CauCLIP显著优于所有竞争方法。

Conclusion: CauCLIP通过因果启发的视觉语言框架和领域不变表示学习，显著提升了手术阶段识别的领域泛化能力，证明了因果引导的视觉语言模型在手术视频理解中的有效性。

Abstract: Surgical phase recognition is a critical component for context-aware decision support in intelligent operating rooms, yet training robust models is hindered by limited annotated clinical videos and large domain gaps between synthetic and real surgical data. To address this, we propose CauCLIP, a causality-inspired vision-language framework that leverages CLIP to learn domain-invariant representations for surgical phase recognition without access to target domain data. Our approach integrates a frequency-based augmentation strategy to perturb domain-specific attributes while preserving semantic structures, and a causal suppression loss that mitigates non-causal biases and reinforces causal surgical features. These components are combined in a unified training framework that enables the model to focus on stable causal factors underlying surgical workflows. Experiments on the SurgVisDom hard adaptation benchmark demonstrate that our method substantially outperforms all competing approaches, highlighting the effectiveness of causality-guided vision-language models for domain-generalizable surgical video understanding.

</details>


### [64] [PlanViz: Evaluating Planning-Oriented Image Generation and Editing for Computer-Use Tasks](https://arxiv.org/abs/2602.06663)
*Junxian Li,Kai Liu,Leyang Chen,Weida Wang,Zhixin Wang,Jiaqi Xu,Fan Li,Renjing Pei,Linghe Kong,Yulun Zhang*

Main category: cs.CV

TL;DR: PlanViz是一个评估UMMs在计算机使用任务中图像生成与编辑能力的新基准，揭示了其局限性并提出了未来研究方向。


<details>
  <summary>Details</summary>
Motivation: 探索UMMs在计算机使用任务中的潜力，尤其是需要空间推理和程序理解的图像生成与编辑能力。

Method: 设计了三个新的子任务（路线规划、工作图表、网页&UI展示），并通过人工标注问题和参考图像确保数据质量，提出了任务适应性评分PlanScore。

Result: 实验揭示了UMMs在完成计算机使用任务时的关键局限性。

Conclusion: PlanViz benchmark揭示了UMMs在计算机使用任务中的局限性，并提出了未来研究的机遇。

Abstract: Unified multimodal models (UMMs) have shown impressive capabilities in generating natural images and supporting multimodal reasoning. However, their potential in supporting computer-use planning tasks, which are closely related to our lives, remain underexplored. Image generation and editing in computer-use tasks require capabilities like spatial reasoning and procedural understanding, and it is still unknown whether UMMs have these capabilities to finish these tasks or not. Therefore, we propose PlanViz, a new benchmark designed to evaluate image generation and editing for computer-use tasks. To achieve the goal of our evaluation, we focus on sub-tasks which frequently involve in daily life and require planning steps. Specifically, three new sub-tasks are designed: route planning, work diagramming, and web&UI displaying. We address challenges in data quality ensuring by curating human-annotated questions and reference images, and a quality control process. For challenges of comprehensive and exact evaluation, a task-adaptive score, PlanScore, is proposed. The score helps understanding the correctness, visual quality and efficiency of generated images. Through experiments, we highlight key limitations and opportunities for future research on this topic.

</details>


### [65] [CytoCrowd: A Multi-Annotator Benchmark Dataset for Cytology Image Analysis](https://arxiv.org/abs/2602.06674)
*Yonghao Si,Xingyuan Zeng,Zhao Chen,Libin Zheng,Caleb Chen Cao,Lei Chen,Jian Yin*

Main category: cs.CV

TL;DR: CytoCrowd是一个新型公共基准数据集，包含冲突注释和黄金标准，用于医学图像分析中的计算机视觉任务和注释聚合算法评估。


<details>
  <summary>Details</summary>
Motivation: 解决医学图像分析中高质量标注数据集的不足，特别是缺乏反映真实世界专家分歧的数据集或独立黄金标准的问题。

Method: 引入CytoCrowd数据集，包含446张高分辨率图像，每张图像提供四位独立病理学家的原始冲突注释和一位资深专家建立的高质量黄金标准。

Result: 实验展示了CytoCrowd带来的挑战，并验证了其作为标准计算机视觉任务和注释聚合算法评估测试平台的价值。

Conclusion: CytoCrowd被证明是开发下一代医学图像分析模型的宝贵资源，其双重结构为计算机视觉任务和注释聚合算法提供了多功能基准。

Abstract: High-quality annotated datasets are crucial for advancing machine learning in medical image analysis. However, a critical gap exists: most datasets either offer a single, clean ground truth, which hides real-world expert disagreement, or they provide multiple annotations without a separate gold standard for objective evaluation. To bridge this gap, we introduce CytoCrowd, a new public benchmark for cytology analysis. The dataset features 446 high-resolution images, each with two key components: (1) raw, conflicting annotations from four independent pathologists, and (2) a separate, high-quality gold-standard ground truth established by a senior expert. This dual structure makes CytoCrowd a versatile resource. It serves as a benchmark for standard computer vision tasks, such as object detection and classification, using the ground truth. Simultaneously, it provides a realistic testbed for evaluating annotation aggregation algorithms that must resolve expert disagreements. We provide comprehensive baseline results for both tasks. Our experiments demonstrate the challenges presented by CytoCrowd and establish its value as a resource for developing the next generation of models for medical image analysis.

</details>


### [66] [Can We Build a Monolithic Model for Fake Image Detection? SICA: Semantic-Induced Constrained Adaptation for Unified-Yet-Discriminative Artifact Feature Space Reconstruction](https://arxiv.org/abs/2602.06676)
*Bo Du,Xiaochen Ma,Xuekang Zhu,Zhe Yang,Chaogun Niu,Jian Liu,Ji-Zhe Zhou*

Main category: cs.CV

TL;DR: SICA通过语义引导重构伪影特征空间，首次实现高性能单一FID模型，显著超越现有方法。


<details>
  <summary>Details</summary>
Motivation: 发现异构现象（不同子域伪影的固有差异）是导致现有单一FID模型性能不佳的根本原因，提出需要重构兼具统一性和区分性的伪影特征空间。

Method: 提出SICA方法，通过高级语义引导的约束适应，重构伪影特征空间，解决异构现象导致的特征空间崩溃问题。

Result: 在OpenMMSec数据集上，SICA优于15种现有方法，并以近乎正交的方式重构了目标特征空间，验证了假设。

Conclusion: SICA（Semantic-Induced Constrained Adaptation）作为首个统一的FID（Fake Image Detection）范式，通过利用高级语义作为结构先验，成功重构了具有统一性又具区分性的伪影特征空间，显著提升了性能。

Abstract: Fake Image Detection (FID), aiming at unified detection across four image forensic subdomains, is critical in real-world forensic scenarios. Compared with ensemble approaches, monolithic FID models are theoretically more promising, but to date, consistently yield inferior performance in practice. In this work, by discovering the ``heterogeneous phenomenon'', which is the intrinsic distinctness of artifacts across subdomains, we diagnose the cause of this underperformance for the first time: the collapse of the artifact feature space driven by such phenomenon. The core challenge for developing a practical monolithic FID model thus boils down to the ``unified-yet-discriminative" reconstruction of the artifact feature space. To address this paradoxical challenge, we hypothesize that high-level semantics can serve as a structural prior for the reconstruction, and further propose Semantic-Induced Constrained Adaptation (SICA), the first monolithic FID paradigm. Extensive experiments on our OpenMMSec dataset demonstrate that SICA outperforms 15 state-of-the-art methods and reconstructs the target unified-yet-discriminative artifact feature space in a near-orthogonal manner, thus firmly validating our hypothesis. The code and dataset are available at:https: //github.com/scu-zjz/SICA_OpenMMSec.

</details>


### [67] [Clinical-Prior Guided Multi-Modal Learning with Latent Attention Pooling for Gait-Based Scoliosis Screening](https://arxiv.org/abs/2602.06743)
*Dong Chen,Zizhuang Wei,Jialei Xu,Xinyang Sun,Zonglin He,Meiru An,Huili Peng,Yong Hu,Kenneth MC Cheung*

Main category: cs.CV

TL;DR: ScoliGait数据集和多模态框架显著提升了青少年特发性脊柱侧弯的步态分析性能，解决了现有方法的局限。


<details>
  <summary>Details</summary>
Motivation: 传统筛查方法主观性强、难以扩展且依赖专业临床知识，而现有视频步态分析存在数据泄露或模型过于简化的问题。

Method: 提出了一个多模态框架，整合了临床先验引导的动力学知识图谱和潜在注意力池化机制，融合视频、文本和知识图谱模态。

Result: 在非重复受试者基准测试中，该方法显著提升了性能，建立了新的最先进水平。

Conclusion: 该研究为青少年特发性脊柱侧弯（AIS）的评估提供了一个稳健、可解释且临床基础的方法，支持可扩展、非侵入性的筛查。

Abstract: Adolescent Idiopathic Scoliosis (AIS) is a prevalent spinal deformity whose progression can be mitigated through early detection. Conventional screening methods are often subjective, difficult to scale, and reliant on specialized clinical expertise. Video-based gait analysis offers a promising alternative, but current datasets and methods frequently suffer from data leakage, where performance is inflated by repeated clips from the same individual, or employ oversimplified models that lack clinical interpretability. To address these limitations, we introduce ScoliGait, a new benchmark dataset comprising 1,572 gait video clips for training and 300 fully independent clips for testing. Each clip is annotated with radiographic Cobb angles and descriptive text based on clinical kinematic priors. We propose a multi-modal framework that integrates a clinical-prior-guided kinematic knowledge map for interpretable feature representation, alongside a latent attention pooling mechanism to fuse video, text, and knowledge map modalities. Our method establishes a new state-of-the-art, demonstrating a significant performance gap on a realistic, non-repeating subject benchmark. Our approach establishes a new state of the art, showing a significant performance gain on a realistic, subject-independent benchmark. This work provides a robust, interpretable, and clinically grounded foundation for scalable, non-invasive AIS assessment.

</details>


### [68] [Revisiting Emotions Representation for Recognition in the Wild](https://arxiv.org/abs/2602.06778)
*Joao Baptista Cardia Neto,Claudio Ferrari,Stefano Berretti*

Main category: cs.CV

TL;DR: 本文提出一种将情绪描述为概率分布的新方法，通过VAD空间映射自动重新标注数据集，丰富了情绪描述的复杂性。


<details>
  <summary>Details</summary>
Motivation: 传统面部情绪识别将情绪简化为单一标签分类，无法准确表示自发情绪的多面性。

Method: 利用Valence-Arousal-Dominance（VAD）空间中的概率分布映射，自动重新标注现有数据集，以估计面部图像属于每种情感分布的可能性。

Result: 初步实验展示了该方法的优势，并提出了新的研究方向。

Conclusion: 本文提出了一种新颖的方法，将复杂情绪状态描述为情感类别的概率分布，并通过自动重新标注现有数据集来验证其有效性。

Abstract: Facial emotion recognition has been typically cast as a single-label classification problem of one out of six prototypical emotions. However, that is an oversimplification that is unsuitable for representing the multifaceted spectrum of spontaneous emotional states, which are most often the result of a combination of multiple emotions contributing at different intensities. Building on this, a promising direction that was explored recently is to cast emotion recognition as a distribution learning problem. Still, such approaches are limited in that research datasets are typically annotated with a single emotion class. In this paper, we contribute a novel approach to describe complex emotional states as probability distributions over a set of emotion classes. To do so, we propose a solution to automatically re-label existing datasets by exploiting the result of a study in which a large set of both basic and compound emotions is mapped to probability distributions in the Valence-Arousal-Dominance (VAD) space. In this way, given a face image annotated with VAD values, we can estimate the likelihood of it belonging to each of the distributions, so that emotional states can be described as a mixture of emotions, enriching their description, while also accounting for the ambiguous nature of their perception. In a preliminary set of experiments, we illustrate the advantages of this solution and a new possible direction of investigation. Data annotations are available at https://github.com/jbcnrlz/affectnet-b-annotation.

</details>


### [69] [Machine Learning for Detection and Severity Estimation of Sweetpotato Weevil Damage in Field and Lab Conditions](https://arxiv.org/abs/2602.06786)
*Doreen M. Chelangat,Sudi Murindanyi,Bruce Mugizi,Paul Musana,Benard Yada,Milton A. Otema,Florence Osaru,Andrew Katumba,Joyce Nakatumba-Nabende*

Main category: cs.CV

TL;DR: 本研究提出了一种基于计算机视觉的自动化评估方法，用于检测甘薯象鼻虫损害，显著提升了评估效率和准确性，对育种项目和粮食安全具有重要价值。


<details>
  <summary>Details</summary>
Motivation: 传统评估象鼻虫损害的方法依赖人工评分，劳动密集、主观性强且结果不一致，严重阻碍了培育抗性甘薯品种的育种项目。

Method: 研究采用计算机视觉方法，包括在田间环境中训练分类模型预测根部损害严重程度，以及在实验室环境中使用YOLO12模型结合根部分割和分块策略进行小对象检测。

Result: 田间分类模型的测试准确率为71.43%，实验室检测模型的平均精度为77.7%，能够有效识别微小的象鼻虫取食孔。

Conclusion: 计算机视觉技术为甘薯育种项目提供了高效、客观且可扩展的评估工具，显著提升了表型分析效率，对减轻象鼻虫对粮食安全的负面影响至关重要。

Abstract: Sweetpotato weevils (Cylas spp.) are considered among the most destructive pests impacting sweetpotato production, particularly in sub-Saharan Africa. Traditional methods for assessing weevil damage, predominantly relying on manual scoring, are labour-intensive, subjective, and often yield inconsistent results. These challenges significantly hinder breeding programs aimed at developing resilient sweetpotato varieties. This study introduces a computer vision-based approach for the automated evaluation of weevil damage in both field and laboratory contexts. In the field settings, we collected data to train classification models to predict root-damage severity levels, achieving a test accuracy of 71.43%. Additionally, we established a laboratory dataset and designed an object detection pipeline employing YOLO12, a leading real-time detection model. This methodology incorporated a two-stage laboratory pipeline that combined root segmentation with a tiling strategy to improve the detectability of small objects. The resulting model demonstrated a mean average precision of 77.7% in identifying minute weevil feeding holes. Our findings indicate that computer vision technologies can provide efficient, objective, and scalable assessment tools that align seamlessly with contemporary breeding workflows. These advancements represent a significant improvement in enhancing phenotyping efficiency within sweetpotato breeding programs and play a crucial role in mitigating the detrimental effects of weevils on food security.

</details>


### [70] [A Unified Formula for Affine Transformations between Calibrated Cameras](https://arxiv.org/abs/2602.06805)
*Levente Hajder*

Main category: cs.CV

TL;DR: 本文推导了校准视图间局部图像块仿射变换的闭式表达式，揭示了其与相机姿态、图像坐标和表面法线的函数关系。


<details>
  <summary>Details</summary>
Motivation: 研究校准视图间局部图像块的变换关系，以更好地理解图像处理和计算机视觉中的几何变换。

Method: 通过数学推导，得到了仿射变换的闭式表达式。

Result: 成功推导出仿射变换的闭式表达式，并明确了其与相对相机姿态、图像坐标和局部表面法线的关系。

Conclusion: 本文推导出了校准视图之间局部图像块仿射变换的闭式表达式，证明了该变换是相对相机姿态、图像坐标和局部表面法线的函数。

Abstract: In this technical note, we derive a closed-form expression for the affine transformation mapping local image patches between two calibrated views. We show that the transformation is a function of the relative camera pose, the image coordinates, and the local surface normal.

</details>


### [71] [RAIGen: Rare Attribute Identification in Text-to-Image Generative Models](https://arxiv.org/abs/2602.06806)
*Silpa Vadakkeeveetil Sreelatha,Dan Wang,Serge Belongie,Muhammad Awais,Anjan Dutta*

Main category: cs.CV

TL;DR: RAIGen 是一种无监督框架，用于发现扩散模型中的罕见属性，支持跨模型审计和针对性生成。


<details>
  <summary>Details</summary>
Motivation: 现有方法要么局限于预定义的公平类别，要么仅识别多数属性，忽视了数据分布中未被充分代表的罕见或少数特征。

Method: RAIGen 利用 Matryoshka Sparse Autoencoders 和一种结合神经元激活频率与语义独特性的新少数度量，来识别可解释的神经元。

Result: 实验表明，RAIGen 能够在 Stable Diffusion 中发现超出固定公平类别的属性，可扩展至 SDXL 等更大模型。

Conclusion: RAIGen 是一种新颖的无监督框架，用于发现扩散模型中的罕见属性，支持跨架构的系统审计，并在生成过程中有针对性地放大这些属性。

Abstract: Text-to-image diffusion models achieve impressive generation quality but inherit and amplify training-data biases, skewing coverage of semantic attributes. Prior work addresses this in two ways. Closed-set approaches mitigate biases in predefined fairness categories (e.g., gender, race), assuming socially salient minority attributes are known a priori. Open-set approaches frame the task as bias identification, highlighting majority attributes that dominate outputs. Both overlook a complementary task: uncovering rare or minority features underrepresented in the data distribution (social, cultural, or stylistic) yet still encoded in model representations. We introduce RAIGen, the first framework, to our knowledge, for un-supervised rare-attribute discovery in diffusion models. RAIGen leverages Matryoshka Sparse Autoencoders and a novel minority metric combining neuron activation frequency with semantic distinctiveness to identify interpretable neurons whose top-activating images reveal underrepresented attributes. Experiments show RAIGen discovers attributes beyond fixed fairness categories in Stable Diffusion, scales to larger models such as SDXL, supports systematic auditing across architectures, and enables targeted amplification of rare attributes during generation.

</details>


### [72] [GaussianPOP: Principled Simplification Framework for Compact 3D Gaussian Splatting via Error Quantification](https://arxiv.org/abs/2602.06830)
*Soonbin Lee,Yeong-Gyu Kim,Simon Sasse,Tomas M. Borges,Yago Sanchez,Eun-Seok Ryu,Thomas Schierl,Cornelius Hellge*

Main category: cs.CV

TL;DR: GaussianPOP是一种基于分析误差量化的3D高斯Splatting简化框架，通过新颖误差准则和高效算法，显著提升模型紧凑性与渲染质量的权衡。


<details>
  <summary>Details</summary>
Motivation: 现有3D高斯Splatting简化方法使用的重要性评分（如混合权重或灵敏度）未基于视觉误差指标，导致紧凑性和渲染保真度之间的权衡不理想。

Method: 提出了一种新颖的误差准则，直接从3DGS渲染方程中推导，通过高效算法实现单次前向传播的误差计算，支持训练中修剪和训练后简化。

Result: 实验结果表明，GaussianPOP在两种应用场景下均优于现有最先进的修剪方法，实现了更优的模型紧凑性和高质量渲染的平衡。

Conclusion: GaussianPOP通过基于分析的高斯误差量化，提供了一种新的简化框架，显著提升了模型紧凑性和渲染质量之间的权衡表现。

Abstract: Existing 3D Gaussian Splatting simplification methods commonly use importance scores, such as blending weights or sensitivity, to identify redundant Gaussians. However, these scores are not driven by visual error metrics, often leading to suboptimal trade-offs between compactness and rendering fidelity. We present GaussianPOP, a principled simplification framework based on analytical Gaussian error quantification. Our key contribution is a novel error criterion, derived directly from the 3DGS rendering equation, that precisely measures each Gaussian's contribution to the rendered image. By introducing a highly efficient algorithm, our framework enables practical error calculation in a single forward pass. The framework is both accurate and flexible, supporting on-training pruning as well as post-training simplification via iterative error re-quantification for improved stability. Experimental results show that our method consistently outperforms existing state-of-the-art pruning methods across both application scenarios, achieving a superior trade-off between model compactness and high rendering quality.

</details>


### [73] [Parameters as Experts: Adapting Vision Models with Dynamic Parameter Routing](https://arxiv.org/abs/2602.06862)
*Meng Lou,Stanley Yu,Yizhou Yu*

Main category: cs.CV

TL;DR: AdaRoute是一种新型适配器方法，通过动态路由和共享专家中心优化密集预测任务的参数高效微调，性能媲美全微调。


<details>
  <summary>Details</summary>
Motivation: 现有参数高效微调方法在复杂密集预测任务中存在输入无关建模和跨层表示冗余的问题。

Method: 提出AdaRoute方法，采用混合专家（MoE）架构，通过动态参数路由机制生成输入依赖的权重矩阵，实现低秩自适应。

Result: 在语义分割、目标检测、实例分割和全景分割等多种视觉任务中，AdaRoute表现出优越性能。

Conclusion: AdaRoute通过动态参数路由机制和共享专家中心，显著提升了参数高效微调在密集预测任务中的性能，实现了与全微调相当的效果。

Abstract: Adapting pre-trained vision models using parameter-efficient fine-tuning (PEFT) remains challenging, as it aims to achieve performance comparable to full fine-tuning using a minimal number of trainable parameters. When applied to complex dense prediction tasks, existing methods exhibit limitations, including input-agnostic modeling and redundant cross-layer representations. To this end, we propose AdaRoute, a new adapter-style method featuring a simple mixture-of-experts (MoE) architecture. Specifically, we introduce shared expert centers, where each expert is a trainable parameter matrix. During a feedforward pass, each AdaRoute module in the network dynamically generates weight matrices tailored for the current module via a simple dynamic parameter routing mechanism, which selectively aggregates parameter matrices in the corresponding expert center. Dynamic weight matrices in AdaRoute modules facilitate low-rank adaptation in an input-dependent manner, thus generating more customized and powerful feature representations. Moreover, since AdaRoute modules across multiple network layers share the same expert center, they improve feature diversity by promoting implicit cross-layer feature interaction. Extensive experiments demonstrate the superiority of AdaRoute on diverse vision tasks, including semantic segmentation, object detection and instance segmentation, and panoptic segmentation. Code will be available at: https://bit.ly/3NZcr0H.

</details>


### [74] [RFDM: Residual Flow Diffusion Model for Efficient Causal Video Editing](https://arxiv.org/abs/2602.06871)
*Mohammadreza Salehi,Mehdi Noroozi,Luca Morreale,Ruchika Chavhan,Malcolm Chadwick,Alberto Gil Ramos,Abhinav Mehrotra*

Main category: cs.CV

TL;DR: RFDM 是一种高效的自回归视频编辑模型，通过残差预测优化处理，性能媲美3D模型，计算成本低且支持变长输入。


<details>
  <summary>Details</summary>
Motivation: 解决现有视频编辑方法对固定长度输入和高计算资源的需求，探索自回归视频生成在编辑中的应用。

Method: 基于2D图像扩散模型，通过条件化前一帧预测来适应视频编辑，提出残差流扩散模型（RFDM）以利用视频的时间冗余。

Result: RFDM 在全局/局部风格迁移和对象移除任务上优于基于I2I的方法，计算效率与图像模型相当，且不受输入视频长度限制。

Conclusion: RFDM 是一种高效的视频编辑模型，通过帧间残差预测优化处理，在保持计算效率的同时，性能媲美全时空（3D）V2V模型。

Abstract: Instructional video editing applies edits to an input video using only text prompts, enabling intuitive natural-language control. Despite rapid progress, most methods still require fixed-length inputs and substantial compute. Meanwhile, autoregressive video generation enables efficient variable-length synthesis, yet remains under-explored for video editing. We introduce a causal, efficient video editing model that edits variable-length videos frame by frame. For efficiency, we start from a 2D image-to-image (I2I) diffusion model and adapt it to video-to-video (V2V) editing by conditioning the edit at time step t on the model's prediction at t-1. To leverage videos' temporal redundancy, we propose a new I2I diffusion forward process formulation that encourages the model to predict the residual between the target output and the previous prediction. We call this Residual Flow Diffusion Model (RFDM), which focuses the denoising process on changes between consecutive frames. Moreover, we propose a new benchmark that better ranks state-of-the-art methods for editing tasks. Trained on paired video data for global/local style transfer and object removal, RFDM surpasses I2I-based methods and competes with fully spatiotemporal (3D) V2V models, while matching the compute of image models and scaling independently of input video length. More content can be found in: https://smsd75.github.io/RFDM_page/

</details>


### [75] [Prompt Reinjection: Alleviating Prompt Forgetting in Multimodal Diffusion Transformers](https://arxiv.org/abs/2602.06886)
*Yuxuan Yao,Yuxuan Chen,Hui Li,Kaihui Cheng,Qipeng Guo,Yuwei Sun,Zilong Dong,Jingdong Wang,Siyu Zhu*

Main category: cs.CV

TL;DR: MMDiTs在文本到图像生成中存在提示遗忘现象，通过提示重注入方法可有效缓解，提升生成质量。


<details>
  <summary>Details</summary>
Motivation: 观察到在多模态扩散变换器中，随着网络深度的增加，文本分支中的提示语义逐渐被遗忘。

Method: 提出了一种无训练的提示重注入方法，将早期层的提示表征重新注入到后期层。

Result: 在GenEval、DPG和T2I-CompBench++上的实验显示，该方法在指令遵循能力、偏好、美学和整体文本-图像生成质量上均有提升。

Conclusion: 通过引入无训练的提示重注入方法，有效缓解了多模态扩散变换器在文本到图像生成中的提示遗忘现象，提升了指令遵循能力和生成质量。

Abstract: Multimodal Diffusion Transformers (MMDiTs) for text-to-image generation maintain separate text and image branches, with bidirectional information flow between text tokens and visual latents throughout denoising. In this setting, we observe a prompt forgetting phenomenon: the semantics of the prompt representation in the text branch is progressively forgotten as depth increases. We further verify this effect on three representative MMDiTs--SD3, SD3.5, and FLUX.1 by probing linguistic attributes of the representations over the layers in the text branch. Motivated by these findings, we introduce a training-free approach, prompt reinjection, which reinjects prompt representations from early layers into later layers to alleviate this forgetting. Experiments on GenEval, DPG, and T2I-CompBench++ show consistent gains in instruction-following capability, along with improvements on metrics capturing preference, aesthetics, and overall text--image generation quality.

</details>


### [76] [Seeing Beyond Redundancy: Task Complexity's Role in Vision Token Specialization in VLLMs](https://arxiv.org/abs/2602.06914)
*Darryl Hannan,John Cooper,Dylan White,Yijing Watkins*

Main category: cs.CV

TL;DR: 研究探讨了VLLMs在复杂视觉任务中表现不佳的原因，发现视觉任务复杂度与压缩相关，高复杂度数据比例能改善模型性能。


<details>
  <summary>Details</summary>
Motivation: 理解VLLMs在处理细粒度视觉信息或空间推理任务时表现不佳的原因，尤其是视觉冗余如何影响模型性能。

Method: 引入了一个简单的合成基准数据集来探测各种视觉特征，并设计了一套衡量视觉冗余的指标，同时通过微调VLLMs在多个复杂视觉任务上探索冗余和压缩的变化。

Result: 发现任务复杂度与视觉压缩之间存在关联，高复杂度视觉数据比例对改善VLLMs的视觉表示分布和性能至关重要。

Conclusion: 本研究揭示了视觉任务复杂度与视觉压缩之间的联系，表明高复杂度视觉数据比例对改进VLLMs的视觉表示分布及提升复杂视觉任务性能至关重要。

Abstract: Vision capabilities in vision large language models (VLLMs) have consistently lagged behind their linguistic capabilities. In particular, numerous benchmark studies have demonstrated that VLLMs struggle when fine-grained visual information or spatial reasoning is required. However, we do not yet understand exactly why VLLMs struggle so much with these tasks relative to others. Some works have focused on visual redundancy as an explanation, where high-level visual information is uniformly spread across numerous tokens and specific, fine-grained visual information is discarded. In this work, we investigate this premise in greater detail, seeking to better understand exactly how various types of visual information are processed by the model and what types of visual information are discarded. To do so, we introduce a simple synthetic benchmark dataset that is specifically constructed to probe various visual features, along with a set of metrics for measuring visual redundancy, allowing us to better understand the nuances of their relationship. Then, we explore fine-tuning VLLMs on a number of complex visual tasks to better understand how redundancy and compression change based upon the complexity of the data that a model is trained on. We find that there is a connection between task complexity and visual compression, implying that having a sufficient ratio of high complexity visual data is crucial for altering the way that VLLMs distribute their visual representation and consequently improving their performance on complex visual tasks. We hope that this work will provide valuable insights for training the next generation of VLLMs.

</details>


### [77] [Reliable Mislabel Detection for Video Capsule Endoscopy Data](https://arxiv.org/abs/2602.06938)
*Julia Werner,Julius Oexle,Oliver Bause,Maxime Le Floch,Franz Brinkmann,Hannah Tolle,Jochen Hampe,Oliver Bringmann*

Main category: cs.CV

TL;DR: 该论文提出了一种医学数据集错误标签检测框架，验证于视频胶囊内窥镜数据，结果显示其能有效识别错误标记并提升异常检测性能。


<details>
  <summary>Details</summary>
Motivation: 在医学影像中，获取大规模且准确标注的数据集尤为困难，且类别边界常模糊不清，这限制了基于机器学习的分类性能。

Method: 引入了一个用于医学数据集中错误标签检测的框架，并在两个最大的公开可用的视频胶囊内窥镜数据集上进行了验证。

Result: 框架成功识别出错误标记的样本，经过重新标注后，异常检测性能得到提升。

Conclusion: 提出的框架成功检测出错误标记的数据，并在清理数据集后相比现有基线提高了异常检测性能。

Abstract: The classification performance of deep neural networks relies strongly on access to large, accurately annotated datasets. In medical imaging, however, obtaining such datasets is particularly challenging since annotations must be provided by specialized physicians, which severely limits the pool of annotators. Furthermore, class boundaries can often be ambiguous or difficult to define which further complicates machine learning-based classification. In this paper, we want to address this problem and introduce a framework for mislabel detection in medical datasets. This is validated on the two largest, publicly available datasets for Video Capsule Endoscopy, an important imaging procedure for examining the gastrointestinal tract based on a video stream of lowresolution images. In addition, potentially mislabeled samples identified by our pipeline were reviewed and re-annotated by three experienced gastroenterologists. Our results show that the proposed framework successfully detects incorrectly labeled data and results in an improved anomaly detection performance after cleaning the datasets compared to current baselines.

</details>


### [78] [CineScene: Implicit 3D as Effective Scene Representation for Cinematic Video Generation](https://arxiv.org/abs/2602.06959)
*Kaiyi Huang,Yukun Huang,Yu Li,Jianhong Bai,Xintao Wang,Zinan Lin,Xuefei Ning,Jiwen Yu,Pengfei Wan,Yu Wang,Xihui Liu*

Main category: cs.CV

TL;DR: CineScene利用隐式3D感知和上下文条件机制，从静态图像生成动态主体视频，保持场景一致性并支持用户指定相机轨迹。


<details>
  <summary>Details</summary>
Motivation: 解决实景拍摄成本高的问题，实现通过静态环境图像生成动态主体视频并保持场景一致性的任务。

Method: 利用VGGT编码场景图像为视觉表示，通过额外的上下文拼接将空间先验注入预训练的文本到视频生成模型，并采用随机打乱输入场景图像的训练策略。

Result: CineScene在场景一致的电影视频生成中达到最先进性能，能处理大范围相机运动并适应多样化环境。

Conclusion: CineScene通过隐式3D感知场景表示和创新的上下文条件机制，实现了高质量、场景一致的电影视频生成，并在大范围相机运动和多样化环境中表现出色。

Abstract: Cinematic video production requires control over scene-subject composition and camera movement, but live-action shooting remains costly due to the need for constructing physical sets. To address this, we introduce the task of cinematic video generation with decoupled scene context: given multiple images of a static environment, the goal is to synthesize high-quality videos featuring dynamic subject while preserving the underlying scene consistency and following a user-specified camera trajectory. We present CineScene, a framework that leverages implicit 3D-aware scene representation for cinematic video generation. Our key innovation is a novel context conditioning mechanism that injects 3D-aware features in an implicit way: By encoding scene images into visual representations through VGGT, CineScene injects spatial priors into a pretrained text-to-video generation model by additional context concatenation, enabling camera-controlled video synthesis with consistent scenes and dynamic subjects. To further enhance the model's robustness, we introduce a simple yet effective random-shuffling strategy for the input scene images during training. To address the lack of training data, we construct a scene-decoupled dataset with Unreal Engine 5, containing paired videos of scenes with and without dynamic subjects, panoramic images representing the underlying static scene, along with their camera trajectories. Experiments show that CineScene achieves state-of-the-art performance in scene-consistent cinematic video generation, handling large camera movements and demonstrating generalization across diverse environments.

</details>


### [79] [MedMO: Grounding and Understanding Multimodal Large Language Model for Medical Images](https://arxiv.org/abs/2602.06965)
*Ankan Deria,Komal Kumar,Adinath Madhavrao Dukre,Eran Segal,Salman Khan,Imran Razzak*

Main category: cs.CV

TL;DR: MedMO is a medical foundation model that outperforms existing MLLMs in various tasks through multi-stage training, showing strong performance in accuracy and spatial reasoning.


<details>
  <summary>Details</summary>
Motivation: The adoption of multimodal large language models (MLLMs) in medicine is limited by gaps in domain coverage, modality alignment, and grounded reasoning.

Method: MedMO follows a multi-stage training recipe: cross-modal pretraining, instruction tuning on multi-task supervision, and reinforcement learning with verifiable rewards.

Result: MedMO achieves significant improvements in accuracy and performance across VQA, text-based QA, medical report generation, and grounding tasks, outperforming baselines and SOTA models.

Conclusion: MedMO consistently outperforms existing open-source medical MLLMs across multiple modalities and tasks, demonstrating robust spatial reasoning and broad cross-modality generalization.

Abstract: Multimodal large language models (MLLMs) have rapidly advanced, yet their adoption in medicine remains limited by gaps in domain coverage, modality alignment, and grounded reasoning. In this work, we introduce MedMO, a medical foundation model built upon a generalized MLLM architecture and trained exclusively on large-scale, domain-specific data. MedMO follows a multi-stage training recipe: (i) cross-modal pretraining to align heterogeneous visual encoders with a medical language backbone; (ii) instruction tuning on multi-task supervision that spans captioning, VQA, report generation, retrieval, and grounded disease localization with bounding boxes; and (iii) reinforcement learning with verifiable rewards that combine factuality checks with a box-level GIoU reward to strengthen spatial grounding and step-by-step reasoning in complex clinical scenarios. MedMO consistently outperforms strong open-source medical MLLMs across multiple modalities and tasks. On VQA benchmarks, MedMO achieves an average accuracy improvement of +13.7% over the baseline and performs within 1.9% of the SOTA Fleming-VL. For text-based QA, it attains +6.9% over the baseline and +14.5% over Fleming-VL. In medical report generation, MedMO delivers significant gains in both semantic and clinical accuracy. Moreover, it exhibits strong grounding capability, achieving an IoU improvement of +40.4 over the baseline and +37.0% over Fleming-VL, underscoring its robust spatial reasoning and localization performance. Evaluations across radiology, ophthalmology, and pathology-microscopy confirm MedMO's broad cross-modality generalization. We release two versions of MedMO: 4B and 8B. Project is available at https://genmilab.github.io/MedMO-Page

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [80] [Real time, cross platform visualizations with zero dependencies for the N-body package REBOUND](https://arxiv.org/abs/2602.06735)
*Hanno Rein*

Main category: cs.GR

TL;DR: 本文介绍了一种无需外部库的实时可视化新方法，通过WebAssembly和内置Web服务器实现跨平台3D交互式可视化。


<details>
  <summary>Details</summary>
Motivation: 现有的可视化工具依赖外部库，增加了开发者和用户的入门门槛，且长期支持存在不确定性。

Method: 利用WebAssembly重用现有的OpenGL可视化代码，通过HTTP通信和内置Web服务器，提供本地和远程实时可视化。

Result: 实现了基于浏览器的3D交互式可视化，支持所有主流操作系统，并提供多种操作模式。

Conclusion: 本文提出了一种无需依赖外部库的实时可视化新方法，适用于多种科学和非科学领域的实时可视化需求。

Abstract: Visualizations have become an indispensable part of the scientific process. A vibrant ecosystem of visualization tools exists, catering to a wide variety of different needs. Real-time visualizations of numerical simulations offer scientists immediate feedback about the status of their simulations and can also be valuable educational and outreach tools. Developing a visualization tool with support for different operating systems, CPU/GPU architectures, and programming languages can be a challenge. It is common to use one or more graphics or UI libraries to act as abstraction layers and hide the underlying complexity. Whereas external libraries greatly simplify the initial programming effort, we argue that relying on them introduces new dependencies and problems, such as a higher entry barriers for new developers and users, and uncertainty regarding long-term support. In this paper we present a new approach for real time visualizations which we have implemented for the N-body package REBOUND. We propose to use a web browser to handle GPU accelerated rendering. This enables us to offer 3D, interactive visualizations on all major operating systems. What makes our new approach unique is that we achieve this without the need for any external libraries. We utilize WebAssembly to reuse existing OpenGL visualization code. Using communication via HTTP and a custom built-in web server, we are able to provide both local and remote real time visualizations. In addition to the browser based real time visualization, our approach offers other additional operating modes, including simulations running entirely within the browser, visualizations within jupyter notebooks, and traditional standalone visualizations using OpenGL. We focus on the implementation in REBOUND but the concepts and ideas discussed can be applied to many other areas in need of scientific and non-scientific real time visualizations.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [81] [Jackpot: Optimal Budgeted Rejection Sampling for Extreme Actor-Policy Mismatch Reinforcement Learning](https://arxiv.org/abs/2602.06107)
*Zhuoming Chen,Hongyi Liu,Yang Zhou,Haizhong Zheng,Beidi Chen*

Main category: cs.AI

TL;DR: Jackpot框架通过OBRS减少rollout模型与策略间的分布差异，提升RL在LLMs中的效率和稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决RL在LLMs中因rollout成本高而效率低下的问题，同时避免因解耦rollout生成与策略优化导致的分布不匹配问题。

Method: Jackpot框架整合了OBRS程序、统一的训练目标（联合更新策略和rollout模型）以及高效的系统实现（top-$k$概率估计和批次级偏差校正）。

Result: Jackpot显著提升了训练稳定性，在训练Qwen3-8B-Base时，性能接近on-policy RL（300更新步骤，批次大小64）。

Conclusion: OBRS-based alignment advances the practical decoupling of rollout generation from policy optimization in RL for LLMs, enhancing efficiency and stability.

Abstract: Reinforcement learning (RL) for large language models (LLMs) remains expensive, particularly because the rollout is expensive. Decoupling rollout generation from policy optimization (e.g., leveraging a more efficient model to rollout) could enable substantial efficiency gains, yet doing so introduces a severe distribution mismatch that destabilizes learning. We propose Jackpot, a framework that leverages Optimal Budget Rejection Sampling (OBRS) to directly reduce the discrepancy between the rollout model and the evolving policy. Jackpot integrates a principled OBRS procedure, a unified training objective that jointly updates the policy and rollout models, and an efficient system implementation enabled by top-$k$ probability estimation and batch-level bias correction. Our theoretical analysis shows that OBRS consistently moves the rollout distribution closer to the target distribution under a controllable acceptance budget. Empirically, \sys substantially improves training stability compared to importance-sampling baselines, achieving performance comparable to on-policy RL when training Qwen3-8B-Base for up to 300 update steps of batchsize 64. Taken together, our results show that OBRS-based alignment brings us a step closer to practical and effective decoupling of rollout generation from policy optimization for RL for LLMs.

</details>


### [82] [Large Language Model Reasoning Failures](https://arxiv.org/abs/2602.06176)
*Peiyang Song,Pengrui Han,Noah Goodman*

Main category: cs.AI

TL;DR: 论文系统调查了LLM的推理失败，提出分类框架和缓解策略，并开源相关研究资源库。


<details>
  <summary>Details</summary>
Motivation: 尽管LLMs在推理任务上表现出色，但仍存在显著的推理失败，尤其是在简单场景中。为了系统理解和解决这些问题，作者进行了首次全面调查。

Method: 论文引入了一个新颖的分类框架，将推理分为具身和非具身类型，并进一步细分为非正式（直觉）和正式（逻辑）推理。同时，将推理失败分为三类：基础性失败、应用特定限制和鲁棒性问题。

Result: 论文提供了对LLM推理失败的系统性分类、定义、原因分析和缓解策略，并发布了相关研究的GitHub资源库。

Conclusion: 该论文通过系统调查和分类框架，揭示了大型语言模型（LLMs）在推理能力上的系统性弱点，并提出了缓解策略，为未来研究提供了指导。

Abstract: Large Language Models (LLMs) have exhibited remarkable reasoning capabilities, achieving impressive results across a wide range of tasks. Despite these advances, significant reasoning failures persist, occurring even in seemingly simple scenarios. To systematically understand and address these shortcomings, we present the first comprehensive survey dedicated to reasoning failures in LLMs. We introduce a novel categorization framework that distinguishes reasoning into embodied and non-embodied types, with the latter further subdivided into informal (intuitive) and formal (logical) reasoning. In parallel, we classify reasoning failures along a complementary axis into three types: fundamental failures intrinsic to LLM architectures that broadly affect downstream tasks; application-specific limitations that manifest in particular domains; and robustness issues characterized by inconsistent performance across minor variations. For each reasoning failure, we provide a clear definition, analyze existing studies, explore root causes, and present mitigation strategies. By unifying fragmented research efforts, our survey provides a structured perspective on systemic weaknesses in LLM reasoning, offering valuable insights and guiding future research towards building stronger, more reliable, and robust reasoning capabilities. We additionally release a comprehensive collection of research works on LLM reasoning failures, as a GitHub repository at https://github.com/Peiyang-Song/Awesome-LLM-Reasoning-Failures, to provide an easy entry point to this area.

</details>


### [83] [Do It for HER: First-Order Temporal Logic Reward Specification in Reinforcement Learning (Extended Version)](https://arxiv.org/abs/2602.06227)
*Pierriccardo Olivieri,Fausto Lasca,Alessandro Gianola,Matteo Papini*

Main category: cs.AI

TL;DR: 提出了一种基于LTLfMT的框架，用于在MDP中指定非马尔可夫奖励，通过理论和实践方法解决挑战，实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 为了解决在非结构化异构数据域中复杂任务的逻辑指定问题，并消除手动谓词编码的需求。

Method: 利用线性时序逻辑模理论（LTLfMT）和基于奖励机器与后见之明经验回放（HER）的方法，解决了奖励稀疏性和复杂任务指定问题。

Result: 实验证明，该方法能够自然指定复杂任务，且定制的HER实现对解决复杂目标任务至关重要。

Conclusion: 论文提出了一种基于LTLfMT的新框架，用于在具有大状态空间的MDP中逻辑指定非马尔可夫奖励，并通过理论和实践方法解决了相关挑战。实验结果表明，该方法在复杂任务中表现优异。

Abstract: In this work, we propose a novel framework for the logical specification of non-Markovian rewards in Markov Decision Processes (MDPs) with large state spaces. Our approach leverages Linear Temporal Logic Modulo Theories over finite traces (LTLfMT), a more expressive extension of classical temporal logic in which predicates are first-order formulas of arbitrary first-order theories rather than simple Boolean variables. This enhanced expressiveness enables the specification of complex tasks over unstructured and heterogeneous data domains, promoting a unified and reusable framework that eliminates the need for manual predicate encoding. However, the increased expressive power of LTLfMT introduces additional theoretical and computational challenges compared to standard LTLf specifications. We address these challenges from a theoretical standpoint, identifying a fragment of LTLfMT that is tractable but sufficiently expressive for reward specification in an infinite-state-space context. From a practical perspective, we introduce a method based on reward machines and Hindsight Experience Replay (HER) to translate first-order logic specifications and address reward sparsity. We evaluate this approach to a continuous-control setting using Non-Linear Arithmetic Theory, showing that it enables natural specification of complex tasks. Experimental results show how a tailored implementation of HER is fundamental in solving tasks with complex goals.

</details>


### [84] [Do LLMs Act Like Rational Agents? Measuring Belief Coherence in Probabilistic Decision Making](https://arxiv.org/abs/2602.06286)
*Khurram Yamin,Jingjing Tang,Santiago Cortes-Gomez,Amit Sharma,Eric Horvitz,Bryan Wilder*

Main category: cs.AI

TL;DR: 论文研究了LLMs在高风险决策中的理性效用最大化能力，发现其推断与理想贝叶斯模型存在差异，并提出了验证方法。


<details>
  <summary>Details</summary>
Motivation: 研究LLMs作为代理在高风险领域中的决策逻辑是否理性，以解决其难以解释的问题。

Method: 通过诊断挑战问题分析LLMs的行为，比较其推断与理想贝叶斯效用最大化的关系。

Result: 研究发现LLMs的推断与理想贝叶斯效用最大化存在差异，并提出了验证其信念真实性的方法。

Conclusion: 该论文探讨了大型语言模型（LLMs）在高风险决策中的理性效用最大化能力，并提出了可证伪的条件来验证其报告的信念是否真实。研究结果对LLMs在医疗诊断等领域的应用具有重要启示。

Abstract: Large language models (LLMs) are increasingly deployed as agents in high-stakes domains where optimal actions depend on both uncertainty about the world and consideration of utilities of different outcomes, yet their decision logic remains difficult to interpret. We study whether LLMs are rational utility maximizers with coherent beliefs and stable preferences. We consider behaviors of models for diagnosis challenge problems. The results provide insights about the relationship of LLM inferences to ideal Bayesian utility maximization for elicited probabilities and observed actions. Our approach provides falsifiable conditions under which the reported probabilities \emph{cannot} correspond to the true beliefs of any rational agent. We apply this methodology to multiple medical diagnostic domains with evaluations across several LLMs. We discuss implications of the results and directions forward for uses of LLMs in guiding high-stakes decisions.

</details>


### [85] [Exposing Weaknesses of Large Reasoning Models through Graph Algorithm Problems](https://arxiv.org/abs/2602.06319)
*Qifan Zhang,Jianhao Ruan,Aochuan Chen,Kang Zeng,Nuo Chen,Jing Tang,Jia Li*

Main category: cs.AI

TL;DR: GrAlgoBench是一个图算法问题基准，揭示了LRMs在长上下文和过度思考方面的弱点，为推理研究提供了新测试平台。


<details>
  <summary>Details</summary>
Motivation: 现有数学、代码和常识推理基准存在局限性，缺乏长上下文评估、挑战不足且答案难以程序化验证。

Method: 引入了GrAlgoBench，一个通过图算法问题评估LRMs的基准。这些问题适合测试推理能力，需要长上下文推理、允许难度级别精细控制，并支持标准化、程序化评估。

Result: 系统实验揭示了当前LRMs的两大弱点：随着上下文长度增加，准确性急剧下降（图节点超过120时低于50%），以及过度思考现象（由大量无效自我验证导致）。

Conclusion: GrAlgoBench通过图算法问题揭示了当前大型推理模型（LRMs）的两大弱点：上下文长度增加时准确性急剧下降，以及过度思考现象。该基准为LRMs的研究提供了一个严格、多维且实际相关的测试平台。

Abstract: Large Reasoning Models (LRMs) have advanced rapidly; however, existing benchmarks in mathematics, code, and common-sense reasoning remain limited. They lack long-context evaluation, offer insufficient challenge, and provide answers that are difficult to verify programmatically. We introduce GrAlgoBench, a benchmark designed to evaluate LRMs through graph algorithm problems. Such problems are particularly well suited for probing reasoning abilities: they demand long-context reasoning, allow fine-grained control of difficulty levels, and enable standardized, programmatic evaluation. Across nine tasks, our systematic experiments reveal two major weaknesses of current LRMs. First, accuracy deteriorates sharply as context length increases, falling below 50% once graphs exceed 120 nodes. This degradation is driven by frequent execution errors, weak memory, and redundant reasoning. Second, LRMs suffer from an over-thinking phenomenon, primarily caused by extensive yet largely ineffective self-verification, which inflates reasoning traces without improving correctness. By exposing these limitations, GrAlgoBench establishes graph algorithm problems as a rigorous, multidimensional, and practically relevant testbed for advancing the study of reasoning in LRMs. Code is available at https://github.com/Bklight999/GrAlgoBench.

</details>


### [86] [Trifuse: Enhancing Attention-Based GUI Grounding via Multimodal Fusion](https://arxiv.org/abs/2602.06351)
*Longhui Ma,Di Zhao,Siwei Wang,Zhao Lv,Miao Wang*

Main category: cs.AI

TL;DR: Trifuse通过融合注意力、OCR和语义线索，解决了GUI基础任务中数据依赖和可靠性问题，表现优异且通用性强。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖大规模数据微调MLLMs或基于注意力的定位，前者数据需求高且泛化性差，后者因缺乏显式空间锚点而可靠性低。

Method: Trifuse采用Consensus-SinglePeak (CS)融合策略，整合注意力、OCR文本线索和图标级语义，实现跨模态一致性和精准定位。

Result: 在四个基准测试中，Trifuse无需任务特定微调即表现优异，且OCR和语义线索的加入显著提升了注意力基础的定位性能。

Conclusion: Trifuse通过整合注意力机制、OCR文本线索和图标级语义，显著提升了GUI基础任务的性能，减少了对昂贵标注数据的依赖。

Abstract: GUI grounding maps natural language instructions to the correct interface elements, serving as the perception foundation for GUI agents. Existing approaches predominantly rely on fine-tuning multimodal large language models (MLLMs) using large-scale GUI datasets to predict target element coordinates, which is data-intensive and generalizes poorly to unseen interfaces. Recent attention-based alternatives exploit localization signals in MLLMs attention mechanisms without task-specific fine-tuning, but suffer from low reliability due to the lack of explicit and complementary spatial anchors in GUI images. To address this limitation, we propose Trifuse, an attention-based grounding framework that explicitly integrates complementary spatial anchors. Trifuse integrates attention, OCR-derived textual cues, and icon-level caption semantics via a Consensus-SinglePeak (CS) fusion strategy that enforces cross-modal agreement while retaining sharp localization peaks. Extensive evaluations on four grounding benchmarks demonstrate that Trifuse achieves strong performance without task-specific fine-tuning, substantially reducing the reliance on expensive annotated data. Moreover, ablation studies reveal that incorporating OCR and caption cues consistently improves attention-based grounding performance across different backbones, highlighting its effectiveness as a general framework for GUI grounding.

</details>


### [87] [Difficulty-Estimated Policy Optimization](https://arxiv.org/abs/2602.06375)
*Yu Zhao,Fan Jiang,Tianle Liu,Bo Zeng,Yu Liu,Longyue Wang,Weihua Luo*

Main category: cs.AI

TL;DR: DEPO通过动态难度估计优化训练数据选择，显著降低计算成本，提升推理模型的效率和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: GRPO在遇到过于简单或复杂的问题时，梯度信号衰减问题严重，现有方法如DAPO无法解决计算开销大的问题。

Method: 提出Difficulty-Estimated Policy Optimization (DEPO)框架，集成在线难度估计器动态评估和过滤训练数据。

Result: DEPO实现了高达2倍的rollout成本降低，且不影响模型性能。

Conclusion: DEPO显著降低了训练高性能推理模型的计算门槛，为推理扩展提供了更可持续的路径。

Abstract: Recent advancements in Large Reasoning Models (LRMs), exemplified by DeepSeek-R1, have underscored the potential of scaling inference-time compute through Group Relative Policy Optimization (GRPO). However, GRPO frequently suffers from gradient signal attenuation when encountering problems that are either too trivial or overly complex. In these scenarios, the disappearance of inter-group advantages makes the gradient signal susceptible to noise, thereby jeopardizing convergence stability. While variants like DAPO attempt to rectify gradient vanishing, they do not alleviate the substantial computational overhead incurred by exhaustive rollouts on low-utility samples. In this paper, we propose Difficulty-Estimated Policy Optimization (DEPO), a novel framework designed to optimize the efficiency and robustness of reasoning alignment. DEPO integrates an online Difficulty Estimator that dynamically assesses and filters training data before the rollout phase. This mechanism ensures that computational resources are prioritized for samples with high learning potential. Empirical results demonstrate that DEPO achieves up to a 2x reduction in rollout costs without compromising model performance. Our approach significantly lowers the computational barrier for training high-performance reasoning models, offering a more sustainable path for reasoning scaling. Code and data will be released upon acceptance.

</details>


### [88] [Unlocking Noisy Real-World Corpora for Foundation Model Pre-Training via Quality-Aware Tokenization](https://arxiv.org/abs/2602.06394)
*Arvid E. Gollwitzer,Paridhi Latawa,David de Gruijl,Deepak A. Subramanian,Adrián Noriega de la Colina*

Main category: cs.AI

TL;DR: QA-Token是一种质量感知分词方法，通过双层优化和强化学习提升噪声数据的分词效果，在基因组学和金融领域表现优异。


<details>
  <summary>Details</summary>
Motivation: 当前的分词方法在处理序列数据时未考虑信号质量，限制了其在噪声真实世界语料库上的有效性。

Method: 提出了QA-Token（质量感知分词），包括：(i) 双层优化公式联合优化词汇构建和下游性能，(ii) 通过质量感知奖励学习合并策略的强化学习方法，(iii) 通过Gumbel-Softmax松弛实现自适应参数学习的端到端优化。

Result: 实验评估显示一致改进：基因组学（变异调用F1提升6.7个百分点）、金融（夏普比率提升30%）。在基础模型规模上，分词了1.7万亿碱基对的预训练语料库，实现了最先进的病原体检测（94.53 MCC），同时减少了15%的token数量。

Conclusion: QA-Token通过将数据可靠性直接纳入词汇构建，显著提升了在噪声真实世界语料库上的表现，并在多个领域实现了性能提升。

Abstract: Current tokenization methods process sequential data without accounting for signal quality, limiting their effectiveness on noisy real-world corpora. We present QA-Token (Quality-Aware Tokenization), which incorporates data reliability directly into vocabulary construction. We make three key contributions: (i) a bilevel optimization formulation that jointly optimizes vocabulary construction and downstream performance, (ii) a reinforcement learning approach that learns merge policies through quality-aware rewards with convergence guarantees, and (iii) an adaptive parameter learning mechanism via Gumbel-Softmax relaxation for end-to-end optimization. Our experimental evaluation demonstrates consistent improvements: genomics (6.7 percentage point F1 gain in variant calling over BPE), finance (30% Sharpe ratio improvement). At foundation scale, we tokenize a pretraining corpus comprising 1.7 trillion base-pairs and achieve state-of-the-art pathogen detection (94.53 MCC) while reducing token count by 15%. We unlock noisy real-world corpora, spanning petabases of genomic sequences and terabytes of financial time series, for foundation model training with zero inference overhead.

</details>


### [89] [Intrinsic Stability Limits of Autoregressive Reasoning: Structural Consequences for Long-Horizon Execution](https://arxiv.org/abs/2602.06413)
*Hsien-Jyh Liao*

Main category: cs.AI

TL;DR: 论文指出自回归生成的过程不稳定性是长视野推理失败的根本原因，提出离散分段和图状结构（如DAG）是稳定推理的关键，并呼吁未来系统转向结构化治理。


<details>
  <summary>Details</summary>
Motivation: 尽管大型语言模型（LLM）展现出强大的推理能力，但在长视野任务中性能急剧下降。传统解释归因于任务复杂性，但作者认为这些解释不完整，提出自回归执行存在内在稳定性限制。

Method: 通过理论推导（Theorem A）和实证研究（合成环境和真实TextWorld任务），分析了自回归推理中的决策优势衰减现象。

Result: 理论推导显示单路径自回归推理中的决策优势随执行长度指数衰减，实证研究验证了性能悬崖的存在，与理论预测一致。

Conclusion: 研究发现，自回归生成的过程级不稳定性是长视野推理的根本约束，而非单纯的任务复杂性。稳定的长视野推理需要离散分段，自然诱导出图状执行结构（如DAG）。短视野评估协议可能掩盖结构不稳定性，未来推理系统可能需要从规模扩展转向结构化治理。

Abstract: Large language models (LLMs) demonstrate remarkable reasoning capabilities, yet their performance often deteriorates sharply in long-horizon tasks, exhibiting systematic breakdown beyond certain scales. Conventional explanations primarily attribute this phenomenon to task complexity, such as combinatorial search explosion or long-term credit assignment challenges. In this work, we argue that these explanations are incomplete: even in linear, unbranched tasks without semantic ambiguity, autoregressive execution is subject to an intrinsic stability limit.
  We propose that the fundamental constraint on long-horizon reasoning arises from process-level instability in autoregressive generation rather than solely from search or task complexity, reframing long-horizon reasoning as a problem of structural governance. We derive Theorem~A, showing that decision advantage in single-path autoregressive reasoning decays exponentially with execution length, imposing a fundamental bound on maintainable reasoning chains. This result implies a structural consequence: stable long-horizon reasoning requires discrete segmentation, naturally inducing graph-like execution structures such as directed acyclic graphs (DAGs).
  Empirical studies in both synthetic environments and real TextWorld tasks reveal observable performance cliffs consistent with theoretical predictions. Our findings provide a dynamical perspective on long-horizon reasoning failure and suggest new limitations on maintaining long-term coherence under purely autoregressive architectures. Furthermore, we highlight that short-horizon evaluation protocols may obscure structural instability, indicating a potential shift from scaling toward structured governance in future reasoning systems.

</details>


### [90] [AgentCPM-Explore: Realizing Long-Horizon Deep Exploration for Edge-Scale Agents](https://arxiv.org/abs/2602.06485)
*Haotian Chen,Xin Cong,Shengda Fan,Yuyang Fu,Ziqin Gong,Yaxi Lu,Yishan Li,Boye Niu,Chengjun Pan,Zijun Song,Huadong Wang,Yesai Wu,Yueying Wu,Zihao Xie,Yukun Yan,Zhong Zhang,Yankai Lin,Zhiyuan Liu,Maosong Sun*

Main category: cs.AI

TL;DR: AgentCPM-Explore, a 4B-parameter agent model, overcomes edge-scale bottlenecks and achieves top performance, proving edge-scale models' underestimated potential.


<details>
  <summary>Details</summary>
Motivation: To address the underexplored capabilities of edge-scale models and overcome bottlenecks like catastrophic forgetting, reward signal noise, and reasoning degradation.

Method: A holistic training framework featuring parameter-space model fusion, reward signal denoising, and contextual information refinement.

Result: Achieves SOTA performance among 4B-class models, matches or surpasses 8B-class SOTA models, and outperforms larger-scale models in several benchmarks, with 97.09% accuracy on GAIA tasks.

Conclusion: AgentCPM-Explore effectively unlocks the significant potential of edge-scale models, demonstrating that their bottleneck is inference stability rather than inherent capability.

Abstract: While Large Language Model (LLM)-based agents have shown remarkable potential for solving complex tasks, existing systems remain heavily reliant on large-scale models, leaving the capabilities of edge-scale models largely underexplored. In this paper, we present the first systematic study on training agentic models at the 4B-parameter scale. We identify three primary bottlenecks hindering the performance of edge-scale models: catastrophic forgetting during Supervised Fine-Tuning (SFT), sensitivity to reward signal noise during Reinforcement Learning (RL), and reasoning degradation caused by redundant information in long-context scenarios. To address the issues, we propose AgentCPM-Explore, a compact 4B agent model with high knowledge density and strong exploration capability. We introduce a holistic training framework featuring parameter-space model fusion, reward signal denoising, and contextual information refinement. Through deep exploration, AgentCPM-Explore achieves state-of-the-art (SOTA) performance among 4B-class models, matches or surpasses 8B-class SOTA models on four benchmarks, and even outperforms larger-scale models such as Claude-4.5-Sonnet or DeepSeek-v3.2 in five benchmarks. Notably, AgentCPM-Explore achieves 97.09% accuracy on GAIA text-based tasks under pass@64. These results provide compelling evidence that the bottleneck for edge-scale models is not their inherent capability ceiling, but rather their inference stability. Based on our well-established training framework, AgentCPM-Explore effectively unlocks the significant, yet previously underestimated, potential of edge-scale models.

</details>


### [91] [JADE: Expert-Grounded Dynamic Evaluation for Open-Ended Professional Tasks](https://arxiv.org/abs/2602.06486)
*Lanbo Lin,Jiayao Liu,Tianyuan Yang,Li Cai,Yuanwu Xu,Lei Wei,Sicong Xie,Guannan Zhang*

Main category: cs.AI

TL;DR: JADE框架结合预定义评估技能和动态声明评估，解决了开放专业任务评估中的严谨性与灵活性困境，实验验证了其稳定性和跨领域有效性。


<details>
  <summary>Details</summary>
Motivation: 评估开放专业任务时，静态评分标准虽然严谨但缺乏灵活性，而基于LLM的评估方法虽然灵活但存在不稳定性和偏见。人类专家通过结合领域基础原则和动态评估来解决这一困境，JADE框架受此启发。

Method: 提出了JADE框架，包含两层：第一层将专家知识编码为预定义的评估技能，提供稳定的评估标准；第二层进行报告特定的、基于声明的评估，灵活评估多样化的推理策略，并通过证据依赖性门控来无效化基于被反驳声明的结论。

Result: 在BizBench上的实验表明，JADE提高了评估稳定性，并揭示了基于整体LLM的评估方法所遗漏的关键代理失败模式。此外，JADE与专家制定的评分标准高度一致，并能有效迁移到医学领域基准测试。

Conclusion: JADE框架通过结合预定义的评估技能和动态的、基于声明的评估，有效解决了评估开放专业任务时的严谨性与灵活性之间的困境，并在BizBench和医学领域基准测试中验证了其跨领域的有效性。

Abstract: Evaluating agentic AI on open-ended professional tasks faces a fundamental dilemma between rigor and flexibility. Static rubrics provide rigorous, reproducible assessment but fail to accommodate diverse valid response strategies, while LLM-as-a-judge approaches adapt to individual responses yet suffer from instability and bias. Human experts address this dilemma by combining domain-grounded principles with dynamic, claim-level assessment. Inspired by this process, we propose JADE, a two-layer evaluation framework. Layer 1 encodes expert knowledge as a predefined set of evaluation skills, providing stable evaluation criteria. Layer 2 performs report-specific, claim-level evaluation to flexibly assess diverse reasoning strategies, with evidence-dependency gating to invalidate conclusions built on refuted claims. Experiments on BizBench show that JADE improves evaluation stability and reveals critical agent failure modes missed by holistic LLM-based evaluators. We further demonstrate strong alignment with expert-authored rubrics and effective transfer to a medical-domain benchmark, validating JADE across professional domains. Our code is publicly available at https://github.com/smiling-world/JADE.

</details>


### [92] [Progress Constraints for Reinforcement Learning in Behavior Trees](https://arxiv.org/abs/2602.06525)
*Finn Rietz,Mart Kartašev,Johannes A. Stork,Petter Ögren*

Main category: cs.AI

TL;DR: 该论文提出了一种结合行为树与强化学习的新方法，通过进度约束机制优化控制器学习，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 结合BTs的结构化领域知识与RL的自动学习能力，以解决RL在稀疏奖励、安全探索和长时程信用分配方面的挑战，同时避免控制器之间的相互抵消问题。

Method: 提出了一种新颖的进度约束机制，利用可行性估计器根据理论上的BT收敛结果限制允许的动作集。

Result: 在2D概念验证和高保真仓库环境中的实证评估表明，该方法在性能、样本效率和约束满足方面优于先前的BT-RL集成方法。

Conclusion: 通过引入进度约束机制，该论文提出了一种有效的行为树（BTs）与强化学习（RL）集成方法，显著提升了性能、样本效率和约束满足度。

Abstract: Behavior Trees (BTs) provide a structured and reactive framework for decision-making, commonly used to switch between sub-controllers based on environmental conditions. Reinforcement Learning (RL), on the other hand, can learn near-optimal controllers but sometimes struggles with sparse rewards, safe exploration, and long-horizon credit assignment. Combining BTs with RL has the potential for mutual benefit: a BT design encodes structured domain knowledge that can simplify RL training, while RL enables automatic learning of the controllers within BTs. However, naive integration of BTs and RL can lead to some controllers counteracting other controllers, possibly undoing previously achieved subgoals, thereby degrading the overall performance. To address this, we propose progress constraints, a novel mechanism where feasibility estimators constrain the allowed action set based on theoretical BT convergence results. Empirical evaluations in a 2D proof-of-concept and a high-fidelity warehouse environment demonstrate improved performance, sample efficiency, and constraint satisfaction, compared to prior methods of BT-RL integration.

</details>


### [93] [HyPER: Bridging Exploration and Exploitation for Scalable LLM Reasoning with Hypothesis Path Expansion and Reduction](https://arxiv.org/abs/2602.06527)
*Shengxuan Qiu,Haochen Huang,Shuzhang Zhong,Pengfei Zuo,Meng Li*

Main category: cs.AI

TL;DR: HyPER 是一种动态调整多路径推理中计算资源分配的方法，显著提升准确率并降低计算开销。


<details>
  <summary>Details</summary>
Motivation: 现有方法在探索-利用权衡上表现僵化，而正确与错误推理路径往往在后期才分叉，因此需要动态调整计算资源分配。

Method: HyPER 提出了一种无训练的在线控制策略，包括从探索到利用的动态转换机制、无需全路径重采样的令牌级细化机制，以及基于长度和置信度的聚合策略。

Result: 在四个混合专家语言模型上的实验表明，HyPER 在准确率上提升了8%至10%，同时令牌使用量减少了25%至40%。

Conclusion: HyPER 通过在混合专家模型中动态调整计算资源分配，显著提升了推理准确率并降低了计算开销，证明了其在多路径解码中的优越性。

Abstract: Scaling test-time compute with multi-path chain-of-thought improves reasoning accuracy, but its effectiveness depends critically on the exploration-exploitation trade-off. Existing approaches address this trade-off in rigid ways: tree-structured search hard-codes exploration through brittle expansion rules that interfere with post-trained reasoning, while parallel reasoning over-explores redundant hypothesis paths and relies on weak answer selection. Motivated by the observation that the optimal balance is phase-dependent and that correct and incorrect reasoning paths often diverge only at late stages, we reformulate test-time scaling as a dynamic expand-reduce control problem over a pool of hypotheses. We propose HyPER, a training-free online control policy for multi-path decoding in mixture-of-experts models that reallocates computation under a fixed budget using lightweight path statistics. HyPER consists of an online controller that transitions from exploration to exploitation as the hypothesis pool evolves, a token-level refinement mechanism that enables efficient generation-time exploitation without full-path resampling, and a length- and confidence-aware aggregation strategy for reliable answer-time exploitation. Experiments on four mixture-of-experts language models across diverse reasoning benchmarks show that HyPER consistently achieves a superior accuracy-compute trade-off, improving accuracy by 8 to 10 percent while reducing token usage by 25 to 40 percent.

</details>


### [94] [LogicSkills: A Structured Benchmark for Formal Reasoning in Large Language Models](https://arxiv.org/abs/2602.06533)
*Brian Rabern,Philipp Mondorf,Barbara Plank*

Main category: cs.AI

TL;DR: LogicSkills基准揭示大型语言模型在形式推理中依赖表面模式，符号化和反模型构建能力不足。


<details>
  <summary>Details</summary>
Motivation: 探究大型语言模型真正掌握的核心逻辑技能，而非仅依赖表面模式。

Method: 引入LogicSkills基准，隔离三种形式推理基础技能：形式符号化、反模型构建和有效性评估，使用两变量一阶逻辑片段并通过SMT求解器Z3验证。

Result: 模型在有效性评估上表现良好，但在符号化和反模型构建上显著较弱。

Conclusion: 大型语言模型在形式推理的核心技能上表现不均衡，尤其在符号化和反模型构建方面较弱，表明其依赖表面模式而非真正的符号或规则推理。

Abstract: Large language models have demonstrated notable performance across various logical reasoning benchmarks. However, it remains unclear which core logical skills they truly master. To address this, we introduce LogicSkills, a unified benchmark designed to isolate three fundamental skills in formal reasoning: (i) $\textit{formal symbolization}\unicode{x2014}$translating premises into first-order logic; (ii) $\textit{countermodel construction}\unicode{x2014}$formulating a finite structure in which all premises are true while the conclusion is false; and (iii) $\textit{validity assessment}\unicode{x2014}$deciding whether a conclusion follows from a given set of premises. Items are drawn from the two-variable fragment of first-order logic (without identity) and are presented in both natural English and a Carroll-style language with nonce words. All examples are verified for correctness and non-triviality using the SMT solver Z3. Across leading models, performance is high on validity but substantially lower on symbolization and countermodel construction, suggesting reliance on surface-level patterns rather than genuine symbolic or rule-based reasoning.

</details>


### [95] [AgentCPM-Report: Interleaving Drafting and Deepening for Open-Ended Deep Research](https://arxiv.org/abs/2602.06540)
*Yishan Li,Wentong Chen,Yukun Yan,Mingwei Li,Sen Mei,Xiaorong Wang,Kunpeng Liu,Xin Cong,Shuo Wang,Zhong Zhang,Yaxi Lu,Zhenghao Liu,Yankai Lin,Zhiyuan Liu,Maosong Sun*

Main category: cs.AI

TL;DR: AgentCPM-Report 是一个轻量级本地解决方案，通过动态修订大纲的框架和8B参数代理，显著提升深度研究报告生成能力，实验表现优于闭源系统。


<details>
  <summary>Details</summary>
Motivation: 当前深度研究报告生成系统依赖闭源或在线大模型，存在部署障碍及用户数据安全和隐私问题，需要一种轻量级本地解决方案。

Method: 采用 Writing As Reasoning Policy (WARP) 框架，结合 Evidence-Based Drafting 和 Reasoning-Driven Deepening 策略，以及 Multi-Stage Agentic Training 方法（包括冷启动、原子技能强化学习和整体管道强化学习）。

Result: 在 DeepResearch Bench、DeepConsult 和 DeepResearch Gym 上的实验表明，AgentCPM-Report 在 Insight 方面显著优于领先的闭源系统。

Conclusion: AgentCPM-Report 提出了一种轻量级但高性能的本地解决方案，通过动态修订大纲的框架和8B参数的研究代理，显著提升了深度研究报告的生成能力，并在实验中超越了领先的闭源系统。

Abstract: Generating deep research reports requires large-scale information acquisition and the synthesis of insight-driven analysis, posing a significant challenge for current language models. Most existing approaches follow a plan-then-write paradigm, whose performance heavily depends on the quality of the initial outline. However, constructing a comprehensive outline itself demands strong reasoning ability, causing current deep research systems to rely almost exclusively on closed-source or online large models. This reliance raises practical barriers to deployment and introduces safety and privacy concerns for user-authored data. In this work, we present AgentCPM-Report, a lightweight yet high-performing local solution composed of a framework that mirrors the human writing process and an 8B-parameter deep research agent. Our framework uses a Writing As Reasoning Policy (WARP), which enables models to dynamically revise outlines during report generation. Under this policy, the agent alternates between Evidence-Based Drafting and Reasoning-Driven Deepening, jointly supporting information acquisition, knowledge refinement, and iterative outline evolution. To effectively equip small models with this capability, we introduce a Multi-Stage Agentic Training strategy, consisting of cold-start, atomic skill RL, and holistic pipeline RL. Experiments on DeepResearch Bench, DeepConsult, and DeepResearch Gym demonstrate that AgentCPM-Report outperforms leading closed-source systems, with substantial gains in Insight.

</details>


### [96] [SeeUPO: Sequence-Level Agentic-RL with Convergence Guarantees](https://arxiv.org/abs/2602.06554)
*Tianyi Hu,Qingxu Fu,Yanxi Chen,Zhaoyang Liu,Bolin Ding*

Main category: cs.AI

TL;DR: 论文提出SeeUPO，一种在多轮交互中具有收敛保证的RL方法，实验证明其性能显著优于现有算法。


<details>
  <summary>Details</summary>
Motivation: 现有骨干RL算法在多轮场景中缺乏已验证的收敛保证，导致训练不稳定或无法收敛到最优策略。

Method: 提出SeeUPO，将多轮交互建模为顺序执行的多臂赌博问题，通过反向执行顺序的逐轮策略更新，确保单调改进并通过逆向归纳收敛到全局最优解。

Result: 在AppWorld和BFCL v4上的实验显示，SeeUPO相比现有算法在Qwen3-14B和Qwen2.5-14B上分别实现了43.3%-54.6%和24.1%-41.9%的相对增益，且训练稳定性更优。

Conclusion: SeeUPO（Sequence-level Sequential Update Policy Optimization）作为一种无需评论家且具有收敛保证的方法，在多轮交互场景中显著优于现有骨干RL算法，实验证明了其训练稳定性和性能提升。

Abstract: Reinforcement learning (RL) has emerged as the predominant paradigm for training large language model (LLM)-based AI agents. However, existing backbone RL algorithms lack verified convergence guarantees in agentic scenarios, especially in multi-turn settings, which can lead to training instability and failure to converge to optimal policies.
  In this paper, we systematically analyze how different combinations of policy update mechanisms and advantage estimation methods affect convergence properties in single/multi-turn scenarios. We find that REINFORCE with Group Relative Advantage Estimation (GRAE) can converge to the globally optimal under undiscounted conditions, but the combination of PPO & GRAE breaks PPO's original monotonic improvement property. Furthermore, we demonstrate that mainstream backbone RL algorithms cannot simultaneously achieve both critic-free and convergence guarantees in multi-turn scenarios.
  To address this, we propose SeeUPO (Sequence-level Sequential Update Policy Optimization), a critic-free approach with convergence guarantees for multi-turn interactions. SeeUPO models multi-turn interaction as sequentially executed multi-agent bandit problems. Through turn-by-turn sequential policy updates in reverse execution order, it ensures monotonic improvement and convergence to global optimal solution via backward induction.
  Experiments on AppWorld and BFCL v4 demonstrate SeeUPO's substantial improvements over existing backbone algorithms: relative gains of 43.3%-54.6% on Qwen3-14B and 24.1%-41.9% on Qwen2.5-14B (averaged across benchmarks), along with superior training stability.

</details>


### [97] [Same Answer, Different Representations: Hidden instability in VLMs](https://arxiv.org/abs/2602.06652)
*Farooq Ahmad Wani,Alessandro Suglia,Rohit Saxena,Aryo Pradipta Gema,Wai-Chung Kwan,Fazl Barez,Maria Sofia Bucarelli,Fabrizio Silvestri,Pasquale Minervini*

Main category: cs.AI

TL;DR: 现有VLMs鲁棒性评估不足，新框架揭示模型在内部表示稳定性、规模效应和任务特异性三方面的失效模式。


<details>
  <summary>Details</summary>
Motivation: 现有VLMs鲁棒性评估仅依赖输出级不变性，隐含假设稳定预测反映稳定的多模态处理，但这一假设不足。需更全面评估模型内部表示稳定性。

Method: 提出表示感知和频率感知的评估框架，通过测量内部嵌入漂移、频谱敏感性和结构平滑性（视觉令牌的空间一致性），结合标准标签指标，在SEEDBench、MMMU和POPE数据集上评估现代VLMs。

Result: 发现三种失效模式：1) 预测答案不变时内部表示显著漂移；2) 模型规模扩大不提升鲁棒性，敏感性反而可能增加；3) 扰动对不同任务影响各异，可能损害推理或减少幻觉。

Conclusion: 现代视觉语言模型（VLMs）在输出不变性评估中存在不足，需引入表示感知和频率感知的评估框架以更全面衡量模型鲁棒性。研究发现模型在预测答案不变时内部表示可能发生显著漂移，且模型规模扩大不必然提升鲁棒性，任务类型也影响扰动效果。

Abstract: The robustness of Vision Language Models (VLMs) is commonly assessed through output-level invariance, implicitly assuming that stable predictions reflect stable multimodal processing. In this work, we argue that this assumption is insufficient. We introduce a representation-aware and frequency-aware evaluation framework that measures internal embedding drift, spectral sensitivity, and structural smoothness (spatial consistency of vision tokens), alongside standard label-based metrics. Applying this framework to modern VLMs across the SEEDBench, MMMU, and POPE datasets reveals three distinct failure modes. First, models frequently preserve predicted answers while undergoing substantial internal representation drift; for perturbations such as text overlays, this drift approaches the magnitude of inter-image variability, indicating that representations move to regions typically occupied by unrelated inputs despite unchanged outputs. Second, robustness does not improve with scale; larger models achieve higher accuracy but exhibit equal or greater sensitivity, consistent with sharper yet more fragile decision boundaries. Third, we find that perturbations affect tasks differently: they harm reasoning when they disrupt how models combine coarse and fine visual cues, but on the hallucination benchmarks, they can reduce false positives by making models generate more conservative answers.

</details>


### [98] [Autoregressive Models for Knowledge Graph Generation](https://arxiv.org/abs/2602.06707)
*Thiviyan Thanapalasingam,Antonis Vozikis,Peter Bloem,Paul Groth*

Main category: cs.AI

TL;DR: ARK系列自回归模型通过序列化处理知识图谱，无需显式规则即可学习语义约束，在生成新图谱时保持高语义有效性，适用于知识库补全等任务。


<details>
  <summary>Details</summary>
Motivation: 知识图谱生成需要模型学习三元组间的复杂语义依赖，同时保持领域有效性约束。传统链接预测方法独立评分三元组，无法捕捉子图间的相互依赖关系。

Method: 提出了ARK（自回归知识图谱生成）系列模型，将图谱视为（头实体，关系，尾实体）三元组的序列，通过自回归方式生成知识图谱。模型无需显式规则监督，直接从数据中学习隐式语义约束。

Result: 在IntelliGraphs基准测试中，模型在多样化数据集上实现了89.2%至100.0%的语义有效性，并生成了训练中未见的新图谱。

Conclusion: 自回归模型为知识图谱生成提供了一个有效框架，适用于知识库补全和查询回答等实际应用。

Abstract: Knowledge Graph (KG) generation requires models to learn complex semantic dependencies between triples while maintaining domain validity constraints. Unlike link prediction, which scores triples independently, generative models must capture interdependencies across entire subgraphs to produce semantically coherent structures. We present ARK (Auto-Regressive Knowledge Graph Generation), a family of autoregressive models that generate KGs by treating graphs as sequences of (head, relation, tail) triples. ARK learns implicit semantic constraints directly from data, including type consistency, temporal validity, and relational patterns, without explicit rule supervision. On the IntelliGraphs benchmark, our models achieve 89.2% to 100.0% semantic validity across diverse datasets while generating novel graphs not seen during training. We also introduce SAIL, a variational extension of ARK that enables controlled generation through learned latent representations, supporting both unconditional sampling and conditional completion from partial graphs. Our analysis reveals that model capacity (hidden dimensionality >= 64) is more critical than architectural depth for KG generation, with recurrent architectures achieving comparable validity to transformer-based alternatives while offering substantial computational efficiency. These results demonstrate that autoregressive models provide an effective framework for KG generation, with practical applications in knowledge base completion and query answering.

</details>


### [99] [Semantically Labelled Automata for Multi-Task Reinforcement Learning with LTL Instructions](https://arxiv.org/abs/2602.06746)
*Alessandro Abate,Giuseppe De Giacomo,Mathias Jackermeier,Jan Kretínský,Maximilian Prokop,Christoph Weinhuber*

Main category: cs.AI

TL;DR: 提出基于语义LTL到自动机转换的任务嵌入技术，提升多任务RL性能，支持复杂规范。


<details>
  <summary>Details</summary>
Motivation: 研究多任务强化学习（RL）中通用策略的学习问题，特别是在任务以线性时序逻辑（LTL）公式指定的情况下，现有方法难以处理复杂规范。

Method: 通过新型语义LTL到自动机的转换技术，生成带有丰富结构化信息的自动机，用于动态计算和任务嵌入提取。

Result: 实验结果表明，该方法在多个领域中实现了最先进的性能，并能扩展到现有方法无法处理的复杂规范。

Conclusion: 该论文提出了一种新颖的任务嵌入技术，利用语义LTL到自动机的转换，能够高效计算自动机、提取任务嵌入并支持完整的LTL，实验证明其性能优于现有方法。

Abstract: We study multi-task reinforcement learning (RL), a setting in which an agent learns a single, universal policy capable of generalising to arbitrary, possibly unseen tasks. We consider tasks specified as linear temporal logic (LTL) formulae, which are commonly used in formal methods to specify properties of systems, and have recently been successfully adopted in RL. In this setting, we present a novel task embedding technique leveraging a new generation of semantic LTL-to-automata translations, originally developed for temporal synthesis. The resulting semantically labelled automata contain rich, structured information in each state that allow us to (i) compute the automaton efficiently on-the-fly, (ii) extract expressive task embeddings used to condition the policy, and (iii) naturally support full LTL. Experimental results in a variety of domains demonstrate that our approach achieves state-of-the-art performance and is able to scale to complex specifications where existing methods fail.

</details>


### [100] [Towards Understanding What State Space Models Learn About Code](https://arxiv.org/abs/2602.06774)
*Jiali Wu,Abhinav Anand,Shweta Verma,Mira Mezini*

Main category: cs.AI

TL;DR: SSMs在代码任务中表现优异但机制不明，分析发现其预训练强于Transformers但微调时有遗忘问题，通过频域框架和架构改进提升了性能。


<details>
  <summary>Details</summary>
Motivation: 尽管SSMs在代码理解任务中表现出色，但其内部机制仍不明确，需要系统性分析以揭示其学习内容和与Transformer的比较优势。

Method: 提出了SSM-Interpret，一个频域框架，用于诊断SSM在微调过程中的频谱偏移问题，并基于分析结果提出架构改进。

Result: 分析显示SSMs在预训练中优于Transformers，但在微调时会遗忘某些语法和语义关系，尤其是在短程依赖任务中。

Conclusion: 通过引入SSM-Interpret框架和架构改进，显著提升了基于SSM的代码模型性能，验证了分析对模型优化的直接贡献。

Abstract: State Space Models (SSMs) have emerged as an efficient alternative to the transformer architecture. Recent studies show that SSMs can match or surpass Transformers on code understanding tasks, such as code retrieval, when trained under similar conditions. However, their internal mechanisms remain a black box. We present the first systematic analysis of what SSM-based code models actually learn and perform the first comparative analysis of SSM and Transformer-based code models. Our analysis reveals that SSMs outperform Transformers at capturing code syntax and semantics in pretraining but forgets certain syntactic and semantic relations during fine-tuning on task, especially when the task emphasizes short-range dependencies. To diagnose this, we introduce SSM-Interpret, a frequency-domain framework that exposes a spectral shift toward short-range dependencies during fine-tuning. Guided by these findings, we propose architectural modifications that significantly improve the performance of SSM-based code model, validating that our analysis directly enables better models.

</details>


### [101] [Wild Guesses and Mild Guesses in Active Concept Learning](https://arxiv.org/abs/2602.06818)
*Anirudh Chari,Neil Pattanaik*

Main category: cs.AI

TL;DR: 研究比较了两种主动概念学习策略（EIG和PTS），发现EIG在复杂规则中有效，但在简单概念上表现不佳，而PTS通过选择安全查询在简单规则上表现更好，支持'确认偏误'可能是理性适应的观点。


<details>
  <summary>Details</summary>
Motivation: 探讨主动概念学习中查询选择的信息量与学习者生成和评分假设的稳定性之间的权衡。

Method: 研究采用了一种神经符号贝叶斯学习器，其假设是由大型语言模型（LLM）生成的可执行程序，并通过贝叶斯更新重新加权。比较了两种查询策略：理性主动学习器（EIG）和人类类似的正测试策略（PTS）。

Result: 在经典数字游戏的概念学习任务中，EIG在需要证伪的情况下（如复合或例外规则）有效，但在简单概念上表现不佳。PTS虽信息次优，但通过选择'安全'查询保持提案有效性，在简单规则上收敛更快。

Conclusion: 研究结果表明，'确认偏误'可能并非认知错误，而是一种在人类思维特有的稀疏、开放假设空间中维持可处理推理的理性适应。

Abstract: Human concept learning is typically active: learners choose which instances to query or test in order to reduce uncertainty about an underlying rule or category. Active concept learning must balance informativeness of queries against the stability of the learner that generates and scores hypotheses. We study this trade-off in a neuro-symbolic Bayesian learner whose hypotheses are executable programs proposed by a large language model (LLM) and reweighted by Bayesian updating. We compare a Rational Active Learner that selects queries to maximize approximate expected information gain (EIG) and the human-like Positive Test Strategy (PTS) that queries instances predicted to be positive under the current best hypothesis. Across concept-learning tasks in the classic Number Game, EIG is effective when falsification is necessary (e.g., compound or exception-laden rules), but underperforms on simple concepts. We trace this failure to a support mismatch between the EIG policy and the LLM proposal distribution: highly diagnostic boundary queries drive the posterior toward regions where the generator produces invalid or overly specific programs, yielding a support-mismatch trap in the particle approximation. PTS is information-suboptimal but tends to maintain proposal validity by selecting "safe" queries, leading to faster convergence on simple rules. Our results suggest that "confirmation bias" may not be a cognitive error, but rather a rational adaptation for maintaining tractable inference in the sparse, open-ended hypothesis spaces characteristic of human thought.

</details>


### [102] [ScaleEnv: Scaling Environment Synthesis from Scratch for Generalist Interactive Tool-Use Agent Training](https://arxiv.org/abs/2602.06820)
*Dunwei Tu,Hongyan Hao,Hansi Yang,Yihao Chen,Yi-Kai Zhang,Zhikang Xia,Yu Yang,Yueqing Sun,Xingchen Liu,Furao Shen,Qi Gu,Hui Su,Xunliang Cai*

Main category: cs.AI

TL;DR: ScaleEnv是一个从零构建完全交互式环境的框架，通过程序化测试和任务验证提升智能体性能，证明了环境多样性对泛化能力的关键作用。


<details>
  <summary>Details</summary>
Motivation: 为了解决交互环境稀缺及现有合成方法在环境多样性和可扩展性方面的局限性，作者提出了ScaleEnv框架。

Method: ScaleEnv通过程序化测试确保环境可靠性，并通过工具依赖图扩展和可执行动作验证来保证任务的完整性和可解性。

Result: 在未见过的多轮工具使用基准测试（如$τ^2$-Bench和VitaBench）上，ScaleEnv表现出显著的性能提升，并证明了环境多样性对模型泛化性能的重要性。

Conclusion: ScaleEnv框架通过程序化测试和任务完整性验证，显著提升了智能体在未见过的多轮工具使用基准测试中的表现，证明了其强大的泛化能力。此外，研究还表明增加环境多样性对智能体学习的稳健性至关重要。

Abstract: Training generalist agents capable of adapting to diverse scenarios requires interactive environments for self-exploration. However, interactive environments remain critically scarce, and existing synthesis methods suffer from significant limitations regarding environmental diversity and scalability. To address these challenges, we introduce ScaleEnv, a framework that constructs fully interactive environments and verifiable tasks entirely from scratch. Specifically, ScaleEnv ensures environment reliability through procedural testing, and guarantees task completeness and solvability via tool dependency graph expansion and executable action verification. By enabling agents to learn through exploration within ScaleEnv, we demonstrate significant performance improvements on unseen, multi-turn tool-use benchmarks such as $τ^2$-Bench and VitaBench, highlighting strong generalization capabilities. Furthermore, we investigate the relationship between increasing number of domains and model generalization performance, providing empirical evidence that scaling environmental diversity is critical for robust agent learning.

</details>


### [103] [POP: Online Structural Pruning Enables Efficient Inference of Large Foundation Models](https://arxiv.org/abs/2602.06822)
*Yi Chen,Wonjin Shin,Shuhong Liu,Tho Mai,Jeongmo Lee,Chuanbo Hua,Kun Wang,Jun Liu,Joo-Young Kim*

Main category: cs.AI

TL;DR: POP是一种在线结构化剪枝框架，通过动态分区和掩码实现高效剪枝，无需预处理即可提升大型基础模型的推理效率。


<details>
  <summary>Details</summary>
Motivation: 当前结构化剪枝方法在推理过程中采用固定剪枝决策，忽视了自回归令牌生成中出现的稀疏模式，限制了大型基础模型的性能提升。

Method: POP将模型通道划分为保留、候选和剪枝区域，预填充阶段定义粗粒度剪枝分区，解码阶段在候选区域内生成细粒度掩码，避免全通道重新评估。

Result: POP在多种大型基础模型（如LLMs、MoEs、VLMs）上的广泛评估显示，其准确性高于现有剪枝方法，同时计算开销和推理延迟更小。

Conclusion: POP（Partition-guided Online Pruning）作为一种轻量级、即插即用的在线结构化剪枝框架，无需预处理即可实现上下文条件动态剪枝，显著降低了计算开销和推理延迟，同时在多种大型基础模型上表现出优于现有剪枝方法的准确性。

Abstract: Large foundation models (LFMs) achieve strong performance through scaling, yet current structural pruning methods derive fixed pruning decisions during inference, overlooking sparsity patterns that emerge in the autoregressive token generation. In this paper, we propose POP (Partition-guided Online Pruning), an efficient online structural pruning framework that enables context-conditioned dynamic pruning with minimal computational overhead. POP partitions model channels into retained, candidate, and pruned regions, where prefilling defines a coarse pruning partition, and the decoding stage generates a fine-grained mask within the candidate region, avoiding full-channel re-evaluation. The coarse pruning partition preserves consistently important weights, while the fine-grained masking provides context-conditioned variation during decoding. Moreover, POP is a lightweight, plug-and-play method that requires no preprocessing, including offline calibration, retraining, or learning predictors. Extensive evaluations across diverse LFMs, including large language models (LLMs), mixture-of-experts models (MoEs), and vision-language models (VLMs), demonstrate that POP consistently delivers higher accuracy than existing pruning approaches while incurring smaller computational overhead and minimizing inference latency.

</details>


### [104] [LLM Active Alignment: A Nash Equilibrium Perspective](https://arxiv.org/abs/2602.06836)
*Tonghan Wang,Yuqi Pan,Xinyi Yang,Yanchen Jiang,Milind Tambe,David C. Parkes*

Main category: cs.AI

TL;DR: 论文提出了一种基于纳什均衡的博弈论框架，用于预测和引导LLM群体行为，避免政治排斥问题，并实现社会期望结果。


<details>
  <summary>Details</summary>
Motivation: 为了解决开放文本空间中均衡计算的难题，并引导LLM群体行为朝向社会期望结果，作者提出了这一框架。

Method: 论文通过将每个代理的行为建模为对人类子群体的混合选择，采用标准凹效用假设，推导出封闭形式的纳什均衡特征，实现系统级预测和行为解释。

Result: 在社交媒体场景中，该方法避免了LLM群体可能表现出的政治排斥问题，展示了在多领域调节多代理LLM动态的潜力。

Conclusion: 该论文提出的博弈论框架能够有效预测和引导大型语言模型（LLM）群体的行为，通过纳什均衡分析避免开放文本空间中的计算难题，并为社会期望结果提供明确指导。

Abstract: We develop a game-theoretic framework for predicting and steering the behavior of populations of large language models (LLMs) through Nash equilibrium (NE) analysis. To avoid the intractability of equilibrium computation in open-ended text spaces, we model each agent's action as a mixture over human subpopulations. Agents choose actively and strategically which groups to align with, yielding an interpretable and behaviorally substantive policy class. We derive closed-form NE characterizations, adopting standard concave-utility assumptions to enable analytical system-level predictions and give explicit, actionable guidance for shifting alignment targets toward socially desirable outcomes. The method functions as an active alignment layer on top of existing alignment pipelines such as RLHF. In a social-media setting, we show that a population of LLMs, especially reasoning-based models, may exhibit political exclusion, pathologies where some subpopulations are ignored by all LLM agents, which can be avoided by our method, illustrating the promise of applying the method to regulate multi-agent LLM dynamics across domains.

</details>


### [105] [An Adaptive Differentially Private Federated Learning Framework with Bi-level Optimization](https://arxiv.org/abs/2602.06838)
*Jin Wang,Hui Ma,Fei Xing,Ming Yan*

Main category: cs.AI

TL;DR: 提出自适应差分隐私联邦学习框架，通过客户端压缩模块和服务器端动态裁剪策略，提升异构环境下的训练稳定性和模型性能。


<details>
  <summary>Details</summary>
Motivation: 联邦学习在实际部署中常因设备异构性和非独立同分布数据导致梯度更新不稳定且偏差大，差分隐私的固定梯度裁剪和高斯噪声注入可能进一步放大梯度扰动，影响训练效果。

Method: 在客户端引入轻量级本地压缩模块以规范化中间表示并约束梯度变异性；在服务器端采用自适应梯度裁剪策略动态调整裁剪阈值，并设计约束感知聚合机制以抑制不可靠或噪声主导的客户端更新。

Result: 在CIFAR-10和SVHN数据集上的实验表明，该框架显著提升了收敛稳定性和分类准确率。

Conclusion: 本文提出了一种自适应差分隐私联邦学习框架，有效解决了设备异构性和非独立同分布数据导致的训练不稳定和性能下降问题。

Abstract: Federated learning enables collaborative model training across distributed clients while preserving data privacy. However, in practical deployments, device heterogeneity, non-independent, and identically distributed (Non-IID) data often lead to highly unstable and biased gradient updates. When differential privacy is enforced, conventional fixed gradient clipping and Gaussian noise injection may further amplify gradient perturbations, resulting in training oscillation and performance degradation and degraded model performance. To address these challenges, we propose an adaptive differentially private federated learning framework that explicitly targets model efficiency under heterogeneous and privacy-constrained settings. On the client side, a lightweight local compressed module is introduced to regularize intermediate representations and constrain gradient variability, thereby mitigating noise amplification during local optimization. On the server side, an adaptive gradient clipping strategy dynamically adjusts clipping thresholds based on historical update statistics to avoid over-clipping and noise domination. Furthermore, a constraint-aware aggregation mechanism is designed to suppress unreliable or noise-dominated client updates and stabilize global optimization. Extensive experiments on CIFAR-10 and SVHN demonstrate improved convergence stability and classification accuracy.

</details>


### [106] [From Features to Actions: Explainability in Traditional and Agentic AI Systems](https://arxiv.org/abs/2602.06841)
*Sindhuja Chaduvula,Jessee Ho,Kina Kim,Aravind Narayanan,Mahshid Alinoori,Muskan Garg,Dhanesh Ramachandram,Shaina Raza*

Main category: cs.AI

TL;DR: 研究比较了静态和代理AI系统中的解释方法，发现轨迹级解释更适合代理设置，能更有效地诊断行为故障。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型（LLMs）的发展，代理AI系统的行为在多步轨迹中展开，而现有的解释方法主要针对静态预测设计，如何将其应用于代理设置尚不明确。

Method: 通过比较静态分类任务中的基于归因的解释与代理基准（TAU-bench Airline和AssistantBench）中的基于轨迹的诊断，实证分析了两种解释方法的效果。

Result: 归因方法在静态设置中表现稳定（Spearman $ρ= 0.86$），但在代理轨迹中无法可靠诊断执行级故障；而基于轨迹的评估能一致地定位行为故障，并发现状态跟踪不一致在失败运行中更为普遍（2.7倍），且降低成功概率49%。

Conclusion: 本研究强调了在评估和诊断自主AI行为时，向轨迹级可解释性的转变的必要性。

Abstract: Over the last decade, explainable AI has primarily focused on interpreting individual model predictions, producing post-hoc explanations that relate inputs to outputs under a fixed decision structure. Recent advances in large language models (LLMs) have enabled agentic AI systems whose behaviour unfolds over multi-step trajectories. In these settings, success and failure are determined by sequences of decisions rather than a single output. While useful, it remains unclear how explanation approaches designed for static predictions translate to agentic settings where behaviour emerges over time. In this work, we bridge the gap between static and agentic explainability by comparing attribution-based explanations with trace-based diagnostics across both settings. To make this distinction explicit, we empirically compare attribution-based explanations used in static classification tasks with trace-based diagnostics used in agentic benchmarks (TAU-bench Airline and AssistantBench). Our results show that while attribution methods achieve stable feature rankings in static settings (Spearman $ρ= 0.86$), they cannot be applied reliably to diagnose execution-level failures in agentic trajectories. In contrast, trace-grounded rubric evaluation for agentic settings consistently localizes behaviour breakdowns and reveals that state tracking inconsistency is 2.7$\times$ more prevalent in failed runs and reduces success probability by 49\%. These findings motivate a shift towards trajectory-level explainability for agentic systems when evaluating and diagnosing autonomous AI behaviour.
  Resources:
  https://github.com/VectorInstitute/unified-xai-evaluation-framework https://vectorinstitute.github.io/unified-xai-evaluation-framework

</details>


### [107] [AIRS-Bench: a Suite of Tasks for Frontier AI Research Science Agents](https://arxiv.org/abs/2602.06855)
*Alisia Lupidi,Bhavul Gauri,Thomas Simon Foster,Bassel Al Omari,Despoina Magka,Alberto Pepe,Alexis Audran-Reiss,Muna Aghamelu,Nicolas Baldwin,Lucia Cipolina-Kun,Jean-Christophe Gagnon-Audet,Chee Hau Leow,Sandra Lefdal,Hossam Mossalam,Abhinav Moudgil,Saba Nazir,Emanuel Tewolde,Isabel Urrego,Jordi Armengol Estape,Amar Budhiraja,Gaurav Chaurasia,Abhishek Charnalia,Derek Dunfield,Karen Hambardzumyan,Daniel Izcovich,Martin Josifoski,Ishita Mediratta,Kelvin Niu,Parth Pathak,Michael Shvartsman,Edan Toledo,Anton Protopopov,Roberta Raileanu,Alexander Miller,Tatiana Shavrina,Jakob Foerster,Yoram Bachrach*

Main category: cs.AI

TL;DR: AIRS-Bench是一个评估LLM代理科学研究能力的基准测试，结果显示代理在部分任务中表现优于人类，但仍有改进空间。


<details>
  <summary>Details</summary>
Motivation: 加速LLM代理在科学研究中的进展。

Method: 引入AIRS-Bench，一个包含20个任务的基准测试套件，涵盖多个领域，评估代理能力，并建立基线模型。

Result: 代理在四个任务中超过人类SOTA，但在十六个任务中未能匹配，且未达到理论性能上限。

Conclusion: AIRS-Bench是一个尚未饱和的基准测试，为自主科学研究提供了显著的改进空间。

Abstract: LLM agents hold significant promise for advancing scientific research. To accelerate this progress, we introduce AIRS-Bench (the AI Research Science Benchmark), a suite of 20 tasks sourced from state-of-the-art machine learning papers. These tasks span diverse domains, including language modeling, mathematics, bioinformatics, and time series forecasting. AIRS-Bench tasks assess agentic capabilities over the full research lifecycle -- including idea generation, experiment analysis and iterative refinement -- without providing baseline code. The AIRS-Bench task format is versatile, enabling easy integration of new tasks and rigorous comparison across different agentic frameworks. We establish baselines using frontier models paired with both sequential and parallel scaffolds. Our results show that agents exceed human SOTA in four tasks but fail to match it in sixteen others. Even when agents surpass human benchmarks, they do not reach the theoretical performance ceiling for the underlying tasks. These findings indicate that AIRS-Bench is far from saturated and offers substantial room for improvement. We open-source the AIRS-Bench task definitions and evaluation code to catalyze further development in autonomous scientific research.

</details>


### [108] [Agentic Uncertainty Reveals Agentic Overconfidence](https://arxiv.org/abs/2602.06948)
*Jean Kaddour,Srijan Patel,Gbètondji Dovonon,Leo Richter,Pasquale Minervini,Matt J. Kusner*

Main category: cs.AI

TL;DR: AI代理在任务成功率预测中普遍过度自信，对抗性提示方法可改善校准效果。


<details>
  <summary>Details</summary>
Motivation: 探讨AI代理是否能准确预测自身任务成功率，以及不同评估时间点对预测准确性的影响。

Method: 通过在不同时间点（执行前、中、后）收集AI代理的成功概率估计，并采用对抗性提示重新构建评估框架。

Result: AI代理普遍表现出过度自信，某些情况下成功率仅为22%时预测为77%。对抗性提示方法在校准方面表现最佳。

Conclusion: 研究表明，AI代理在任务执行前、中、后的成功概率预测中存在过度自信现象，且通过对抗性提示重新构建评估框架可以改善校准效果。

Abstract: Can AI agents predict whether they will succeed at a task? We study agentic uncertainty by eliciting success probability estimates before, during, and after task execution. All results exhibit agentic overconfidence: some agents that succeed only 22% of the time predict 77% success. Counterintuitively, pre-execution assessment with strictly less information tends to yield better discrimination than standard post-execution review, though differences are not always significant. Adversarial prompting reframing assessment as bug-finding achieves the best calibration.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [109] [Dynamic Modeling, Parameter Identification and Numerical Analysis of Flexible Cables in Flexibly Connected Dual-AUV Systems](https://arxiv.org/abs/2602.06087)
*Kuo Chen,Minghao Dou,Qianqi Liu,Yang An,Kai Ren,Zeming WU,Yu Tian,Jie Sun,Xinping Wang,Zhier Chen,Jiancheng Yu*

Main category: cs.RO

TL;DR: 研究提出了一种动态建模框架和参数识别方法，用于描述柔性连接双AUV系统的非线性行为，通过实验和数值分析揭示了电缆在复杂边界条件下的动力学特性。


<details>
  <summary>Details</summary>
Motivation: 为了解决直接测量材料相关和流体动力系数的困难，并准确捕捉力和电缆配置的时变响应。

Method: 基于集总质量法建立了动态建模框架，结合轴向弹性、弯曲刚度、附加质量和流体动力，提出了结合物理模型与实验数据的参数识别方法。

Result: 通过多配置下的张力实验，高精度反演了等效杨氏模量和流体动力系数，数值分析表明柔性电缆的动态特性具有显著非线性，且受材料特性和AUV运动条件影响较大。

Conclusion: 本研究揭示了复杂边界条件下柔性电缆的动力学特性，为类似系统的设计、优化及进一步的控制研究提供了理论基础。

Abstract: This research presents a dynamic modeling framework and parameter identification methods for describing the highly nonlinear behaviors of flexibly connected dual-AUV systems. The modeling framework is established based on the lumped mass method, integrating axial elasticity, bending stiffness, added mass and hydrodynamic forces, thereby accurately capturing the time-varying response of the forces and cable configurations. To address the difficulty of directly measuring material-related and hydrodynamic coefficients, this research proposes a parameter identification method that combines the physical model with experimental data. High-precision inversion of the equivalent Youngs modulus and hydrodynamic coefficients is performed through tension experiments under multiple configurations, effectively demonstrating that the identified model maintains predictive consistency in various operational conditions. Further numerical analysis indicates that the dynamic properties of flexible cable exhibit significant nonlinear characteristics, which are highly dependent on material property variations and AUV motion conditions. This nonlinear dynamic behavior results in two typical response states, slack and taut, which are jointly determined by boundary conditions and hydrodynamic effects, significantly affecting the cable configuration and endpoint loads. In this research, the dynamics of flexible cables under complex boundary conditions is revealed, providing a theoretical foundation for the design, optimization and further control research of similar systems.

</details>


### [110] [Transformer-Based Reinforcement Learning for Autonomous Orbital Collision Avoidance in Partially Observable Environments](https://arxiv.org/abs/2602.06088)
*Thomas Georges,Adam Abdin*

Main category: cs.RO

TL;DR: 提出了基于Transformer的强化学习框架，用于轨道碰撞避免，有效处理部分可观测性和不完美监测问题。


<details>
  <summary>Details</summary>
Motivation: 为了解决空间操作中部分可观测性和不完美监测带来的挑战，提高碰撞避免的可靠性。

Method: 结合了可配置的遭遇模拟器、距离依赖的观测模型和序列状态估计器来表示相对运动中的不确定性，并采用了基于Transformer的POMDP架构。

Result: 该框架通过长程时间注意力机制，比传统架构更有效地解释噪声和间歇性观测，为在不完美监测环境下训练碰撞避免代理提供了基础。

Conclusion: 该论文提出了一个基于Transformer的强化学习框架，用于自主轨道碰撞避免，有效解决了部分可观测性和不完美监测的问题。

Abstract: We introduce a Transformer-based Reinforcement Learning framework for autonomous orbital collision avoidance that explicitly models the effects of partial observability and imperfect monitoring in space operations. The framework combines a configurable encounter simulator, a distance-dependent observation model, and a sequential state estimator to represent uncertainty in relative motion. A central contribution of this work is the use of transformer-based Partially Observable Markov Decision Process (POMDP) architecture, which leverage long-range temporal attention to interpret noisy and intermittent observations more effectively than traditional architectures. This integration provides a foundation for training collision avoidance agents that can operate more reliably under imperfect monitoring environments.

</details>


### [111] [Active Localization of Unstable Systems with Coarse Information](https://arxiv.org/abs/2602.06191)
*Ege Yuceel,Daniel Liberzon,Sayan Mitra*

Main category: cs.RO

TL;DR: 该论文研究了单比特传感下不稳定系统的定位和控制，提出了结合集合估计和Voronoi分区控制的算法，理论证明和实验验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 研究在单比特传感等极简反馈条件下，不稳定系统的定位和控制的基本限制。

Method: 开发了一种结合基于集合的估计器和源自Voronoi分区的控制策略的主动定位算法。

Result: 在满足条件的情况下，提出的方法能保证初始状态不确定性的指数收缩，并通过数值实验支持了这一结果。

Conclusion: 该研究为理解在极稀疏测量下不稳定系统的定位和控制提供了理论基础，并提出了一种有效的主动定位算法，通过数值实验验证了其有效性。

Abstract: We study localization and control for unstable systems under coarse, single-bit sensing. Motivated by understanding the fundamental limitations imposed by such minimal feedback, we identify sufficient conditions under which the initial state can be recovered despite instability and extremely sparse measurements. Building on these conditions, we develop an active localization algorithm that integrates a set-based estimator with a control strategy derived from Voronoi partitions, which provably estimates the initial state while ensuring the agent remains in informative regions. Under the derived conditions, the proposed approach guarantees exponential contraction of the initial-state uncertainty, and the result is further supported by numerical experiments. These findings can offer theoretical insight into localization in robotics, where sensing is often limited to coarse abstractions such as keyframes, segmentations, or line-based features.

</details>


### [112] [Bioinspired Kirigami Capsule Robot for Minimally Invasive Gastrointestinal Biopsy](https://arxiv.org/abs/2602.06207)
*Ruizhou Zhao,Yichen Chu,Shuwei Zhao,Wenchao Yue,Raymond Shing-Yan Tang,Hongliang Ren*

Main category: cs.RO

TL;DR: Kiri-Capsule 是一种新型可吞咽胶囊机器人，通过剪纸设计实现微创活检，实验证明其性能与传统活检方法相当，有望推动胶囊内窥镜诊断技术的临床应用。


<details>
  <summary>Details</summary>
Motivation: 无线胶囊内窥镜（WCE）虽革新了胃肠道诊断，但因缺乏活检能力而受限。传统活检方法侵入性强、范围有限且存在穿孔或黏膜创伤风险，而液体或微生物采样胶囊无法提供结构化组织样本。因此，亟需一种可吞咽的活检解决方案。

Method: Kiri-Capsule 是一种受剪纸启发的胶囊机器人，集成了可展开的 PI 薄膜瓣，通过紧凑的双凸轮机制驱动，实现微创且可重复的组织采集。剪纸表面在运动时保持平坦，但在凸轮驱动拉伸时转变为尖锐突起，实现可控穿透和旋转刮取，样本保留在内部扇形腔中。

Result: 实验证明，PI 薄膜的杨氏模量约为 20 MPa，展开角度稳定（15% 应变时约 34°）。离体猪组织研究表明，Kiri-Capsule 的穿透深度较浅（中位数约 0.61 mm），活检量与标准钳相当（胃部平均约 10.9 mg，肠道约 18.9 mg），且力值在胃肠道活检的安全范围内。

Conclusion: Kiri-Capsule 成功地将被动成像与功能性活检结合，提供了一种可吞咽、深度可控且适用于组织学分析的解决方案，推动了胶囊内窥镜诊断技术向安全有效的临床应用迈进。

Abstract: Wireless capsule endoscopy (WCE) has transformed gastrointestinal (GI) diagnostics by enabling noninvasive visualization of the digestive tract, yet its diagnostic yield remains constrained by the absence of biopsy capability, as histological analysis is still the gold standard for confirming disease. Conventional biopsy using forceps, needles, or rotating blades is invasive, limited in reach, and carries risks of perforation or mucosal trauma, while fluid- or microbiota-sampling capsules cannot provide structured tissue for pathology, leaving a critical gap in swallowable biopsy solutions. Here we present the Kiri-Capsule, a kirigami-inspired capsule robot that integrates deployable PI-film flaps actuated by a compact dual-cam mechanism to achieve minimally invasive and repeatable tissue collection. The kirigami surface remains flat during locomotion but transforms into sharp protrusions upon cam-driven stretching, enabling controlled penetration followed by rotary scraping, with specimens retained in internal fan-shaped cavities. Bench tests confirmed that PI films exhibit a Young's modulus of approximately 20 MPa and stable deployment angles (about 34$^\circ$ at 15% strain), while ex vivo porcine studies demonstrated shallow penetration depths (median $\sim$0.61 mm, range 0.46--0.66 mm) and biopsy yields comparable to standard forceps (mean $\sim$10.9 mg for stomach and $\sim$18.9 mg for intestine), with forces within safe ranges reported for GI biopsy. These findings demonstrate that the Kiri-Capsule bridges passive imaging and functional biopsy, providing a swallowable, depth-controlled, and histology-ready solution that advances capsule-based diagnostics toward safe and effective clinical application.

</details>


### [113] [Coupled Local and Global World Models for Efficient First Order RL](https://arxiv.org/abs/2602.06219)
*Joseph Amigo,Rooholla Khorrambakht,Nicolas Mansard,Ludovic Righetti*

Main category: cs.RO

TL;DR: 本文提出了一种在数据驱动的世界模型中训练强化学习策略的新方法，通过解耦一阶梯度技术实现高效梯度计算，显著提升了样本效率，并在操纵任务中展示了优越性能。


<details>
  <summary>Details</summary>
Motivation: 世界模型能够更准确地捕捉复杂动态和感官信息，但计算复杂度高，限制了其在操纵任务中的应用。本文旨在绕过模拟器，直接在从机器人真实环境交互中学习的世界模型中训练强化学习策略。

Method: 提出了一种通过新型解耦一阶梯度（FoG）方法在大规模扩散模型中训练策略的方法：完整的世界模型生成准确的前向轨迹，而轻量级的潜在空间代理近似其局部动力学以实现高效梯度计算。

Result: 在Push-T操纵任务中，该方法在样本效率上显著优于PPO，并在四足机器人的自我中心物体操纵任务中进一步验证了其有效性。

Conclusion: 学习基于数据驱动的世界模型是一种有前景的方法，可以在不依赖手工物理模拟器的情况下解决图像空间中难以建模的强化学习任务。

Abstract: World models offer a promising avenue for more faithfully capturing complex dynamics, including contacts and non-rigidity, as well as complex sensory information, such as visual perception, in situations where standard simulators struggle. However, these models are computationally complex to evaluate, posing a challenge for popular RL approaches that have been successfully used with simulators to solve complex locomotion tasks but yet struggle with manipulation. This paper introduces a method that bypasses simulators entirely, training RL policies inside world models learned from robots' interactions with real environments. At its core, our approach enables policy training with large-scale diffusion models via a novel decoupled first-order gradient (FoG) method: a full-scale world model generates accurate forward trajectories, while a lightweight latent-space surrogate approximates its local dynamics for efficient gradient computation. This coupling of a local and global world model ensures high-fidelity unrolling alongside computationally tractable differentiation. We demonstrate the efficacy of our method on the Push-T manipulation task, where it significantly outperforms PPO in sample efficiency. We further evaluate our approach through an ego-centric object manipulation task with a quadruped. Together, these results demonstrate that learning inside data-driven world models is a promising pathway for solving hard-to-model RL tasks in image space without reliance on hand-crafted physics simulators.

</details>


### [114] [A Dialogue-Based Human-Robot Interaction Protocol for Wheelchair and Robotic Arm Integrated Control](https://arxiv.org/abs/2602.06243)
*Guangping Liu,Nicholas Hawkins,Billy Madden,Tipu Sultan,Madi Babaiasl*

Main category: cs.RO

TL;DR: 本文提出了一种基于对话的辅助机器人交互协议，试点研究表明参与者更喜欢这种自然交互方式。


<details>
  <summary>Details</summary>
Motivation: 现有的辅助界面（如触摸屏和语音驱动预定义命令）通常不够直观，难以捕捉复杂的用户意图。

Method: 提出了一种基于对话的人机交互协议，模拟智能代理与用户沟通以理解意图并执行辅助动作。通过试点研究，五名参与者完成了五项辅助任务。

Result: 在试点研究中，参与者通过对话式交互完成了五项辅助任务，并通过问卷反馈表明对话式交互和机器人自主性受到欢迎。

Conclusion: 对话式交互和辅助机器人自主性受到大多数参与者的喜爱，表明这种自然交互方式在辅助技术中具有潜力。

Abstract: People with lower and upper body disabilities can benefit from wheelchairs and robotic arms to improve mobility and independence. Prior assistive interfaces, such as touchscreens and voice-driven predefined commands, often remain unintuitive and struggle to capture complex user intent. We propose a natural, dialogue based human robot interaction protocol that simulates an intelligent agent capable of communicating with users to understand intent and execute assistive actions. In a pilot study, five participants completed five assistive tasks (cleaning, drinking, feeding, drawer opening, and door opening) through dialogue-based interaction with a wheelchair and robotic arm. As a baseline, participants were required to open a door using the manual control (a wheelchair joystick and a game controller for the arm) and complete a questionnaire to gather their feedback. By analyzing the post-study questionnaires, we found that most participants enjoyed the dialogue-based interaction and assistive robot autonomy.

</details>


### [115] [MORPH Wheel: A Passive Variable-Radius Wheel Embedding Mechanical Behavior Logic for Input-Responsive Transformation](https://arxiv.org/abs/2602.06265)
*JaeHyung Jang,JuYeong Seo,Dae-Young Lee,Jee-Hwan Ryu*

Main category: cs.RO

TL;DR: MORPH轮是一种完全被动的可变半径轮，通过几何和柔性结构实现扭矩响应半径调节，无需电子组件，适用于不可预测环境中的机器人移动系统。


<details>
  <summary>Details</summary>
Motivation: 传统变速系统依赖执行器、传感器和主动控制，而MORPH轮旨在通过被动方式实现扭矩响应半径调节，减少复杂性和能源消耗。

Method: 设计集成了扭矩响应耦合器和弹簧加载连接支柱，通过机械方式在80毫米至45毫米之间调节轮半径，无需任何电子组件。建立了全面的分析模型来描述轮的机械行为逻辑，并实验验证了扭矩-半径和力-位移特性。

Result: 实验验证显示，MORPH轮在1.8-2.8kg重量范围内，扭矩-半径和力-位移特性与理论预测高度一致。机器人演示进一步验证了轮在不同负载、坡度和非结构化地形中被动调节半径的能力。

Conclusion: MORPH轮通过其几何形状和柔性结构实现了完全被动的半径调节，为机器人移动系统在不可预测或控制受限的环境中提供了新的被动变速和机械智能范例。

Abstract: This paper introduces the Mechacnially prOgrammed Radius-adjustable PHysical (MORPH) wheel, a fully passive variable-radius wheel that embeds mechanical behavior logic for torque-responsive transformation. Unlike conventional variable transmission systems relying on actuators, sensors, and active control, the MORPH wheel achieves passive adaptation solely through its geometry and compliant structure. The design integrates a torque-response coupler and spring-loaded connecting struts to mechanically adjust the wheel radius between 80 mm and 45 mm in response to input torque, without any electrical components. The MORPH wheel provides three unique capabilities rarely achieved simultaneously in previous passive designs: (1) bidirectional operation with unlimited rotation through a symmetric coupler; (2) high torque capacity exceeding 10 N with rigid power transmission in drive mode; and (3) precise and repeatable transmission ratio control governed by deterministic kinematics. A comprehensive analytical model was developed to describe the wheel's mechanical behavior logic, establishing threshold conditions for mode switching between direct drive and radius transformation. Experimental validation confirmed that the measured torque-radius and force-displacement characteristics closely follow theoretical predictions across wheel weights of 1.8-2.8kg. Robot-level demonstrations on varying loads (0-25kg), slopes, and unstructured terrains further verified that the MORPH wheel passively adjusts its radius to provide optimal transmission ratio. The MORPH wheel exemplifies a mechanically programmed structure, embedding intelligent, context-dependent behavior directly into its physical design. This approach offers a new paradigm for passive variable transmission and mechanical intelligence in robotic mobility systems operating in unpredictable or control-limited environments.

</details>


### [116] [A High-Fidelity Robotic Manipulator Teleoperation Framework for Human-Centered Augmented Reality Evaluation](https://arxiv.org/abs/2602.06273)
*Harsh Chhajed,Tian Guo*

Main category: cs.RO

TL;DR: ARBot是一个实时远程操作平台，用于捕捉和重放人类运动，以验证AR模型，并提供了开源工具和数据集。


<details>
  <summary>Details</summary>
Motivation: 由于人类运动的生物力学变异性，无法可靠地执行一致的运动，因此需要机器人操纵器作为人类运动的代理。

Method: 设计了ARBot平台，包括两种捕捉模型：通过自定义CV和IMU管道实现稳定的手腕运动捕捉，以及通过移动应用实现自然的6自由度控制。并设计了一个主动安全的QP控制器以确保机械臂的平滑执行。

Result: 开源了ARBot并发布了一个包含132条人类和合成轨迹的基准数据集，以支持可控和可扩展的AR评估。

Conclusion: ARBot作为一个实时远程操作平台，能够有效捕捉并准确重放人类运动，为AR跟踪和交互模型的验证提供了高保真的物理代理。

Abstract: Validating Augmented Reality (AR) tracking and interaction models requires precise, repeatable ground-truth motion. However, human users cannot reliably perform consistent motion due to biomechanical variability. Robotic manipulators are promising to act as human motion proxies if they can mimic human movements. In this work, we design and implement ARBot, a real-time teleoperation platform that can effectively capture natural human motion and accurately replay the movements via robotic manipulators. ARBot includes two capture models: stable wrist motion capture via a custom CV and IMU pipeline, and natural 6-DOF control via a mobile application. We design a proactively-safe QP controller to ensure smooth, jitter-free execution of the robotic manipulator, enabling it to function as a high-fidelity record and replay physical proxy. We open-source ARBot and release a benchmark dataset of 132 human and synthetic trajectories captured using ARBot to support controllable and scalable AR evaluation.

</details>


### [117] [Robots That Generate Planarity Through Geometry](https://arxiv.org/abs/2602.06294)
*Jakub F. Kowalewski,Abdulaziz O. Alrashed,Jacob Alpert,Rishi Ponnapalli,Lucas R. Meza,Jeffrey Ian Lipton*

Main category: cs.RO

TL;DR: 利用几何反转构建FPMs，实现无需外部计量的平面运动，误差降低10倍，适用于多尺度应用。


<details>
  <summary>Details</summary>
Motivation: 传统精密机器人运动系统依赖静态平面度，需复杂内部对齐和高公差组件，导致长且误差敏感的参考链。

Method: 通过利用球体到平面的几何反转，构建了Flat-Plane Mechanisms (FPMs)，使平面运动完全由连杆长度和连接性决定。

Result: 展示了从微米到米尺度的FPMs，证明制造误差在平面度上可降低一个数量级，并实现了一个用于计量表面扫描和3D打印的3轴定位系统。

Conclusion: 这项研究为平面运动建立了一种替代几何基础，可在不同尺寸范围内实现，并为计量学、制造和微定位开辟了新可能性。

Abstract: Constraining motion to a flat surface is a fundamental requirement for equipment across science and engineering. Modern precision robotic motion systems, such as gantries, rely on the flatness of components, including guide rails and granite surface plates. However, translating this static flatness into motion requires precise internal alignment and tight-tolerance components that create long, error-sensitive reference chains. Here, we show that by using the geometric inversion of a sphere into a plane, we can produce robotic motion systems that derive planarity entirely from link lengths and connectivity. This allows planar motion to emerge from self-referencing geometric constraints, and without external metrology. We demonstrate these Flat-Plane Mechanisms (FPMs) from micron to meter scales and show that fabrication errors can be attenuated by an order of magnitude in the resulting flatness. Finally, we present a robotic FPM-based 3-axis positioning system that can be used for metrology surface scans ($\pm 12$-mm) and 3D printing inside narrow containers. This work establishes an alternative geometric foundation for planar motion that can be realized across size scales and opens new possibilities in metrology, fabrication, and micro-positioning.

</details>


### [118] [Internalized Morphogenesis: A Self-Organizing Model for Growth, Replication, and Regeneration via Local Token Exchange in Modular Systems](https://arxiv.org/abs/2602.06296)
*Takeshi Ishida*

Main category: cs.RO

TL;DR: 该论文提出了一种仅依赖局部交互的内部化形态发生模型，通过令牌交换和内部潜力实现复杂形态行为，为自主硬件提供高效且生物合理的解决方案。


<details>
  <summary>Details</summary>
Motivation: 传统自组织模型需要在整个坐标空间进行计算，包括空区域，这对资源受限的物理模块不切实际。本研究旨在消除这一需求。

Method: 通过扩展'Ishida token模型'，模块间使用RD启发的离散模拟交换整数值，无需解微分方程。内部潜力源自令牌积累和老化，指导自主生长、收缩和复制。

Result: 在六边形网格上的模拟展示了肢体状延伸、自我分裂和结构截断后的稳健再生能力。使用体边界作为信息熵（令牌）的自然汇以维持动态平衡。

Conclusion: 该研究提出了一种仅依赖局部交互的内部化形态发生模型，为自主系统（如群体机器人和微纳米机器）提供了一种无需外部空间计算的高效方法，展示了从最小内部规则中涌现复杂形态行为的可能性。

Abstract: This study presents an internalized morphogenesis model for autonomous systems, such as swarm robotics and micro-nanomachines, that eliminates the need for external spatial computation. Traditional self-organizing models often require calculations across the entire coordinate space, including empty areas, which is impractical for resource-constrained physical modules. Our proposed model achieves complex morphogenesis through strictly local interactions between adjacent modules within the "body." By extending the "Ishida token model," modules exchange integer values using an RD-inspired discrete analogue without solving differential equations. The internal potential, derived from token accumulation and aging, guides autonomous growth, shrinkage, and replication. Simulations on a hexagonal grid demonstrated the emergence of limb-like extensions, self-division, and robust regeneration capabilities following structural amputation. A key feature is the use of the body boundary as a natural sink for information entropy (tokens) to maintain a dynamic equilibrium. These results indicate that sophisticated morphological behaviors can emerge from minimal, internal-only rules. This framework offers a computationally efficient and biologically plausible approach to developing self-repairing, adaptive, and autonomous hardware.

</details>


### [119] [Action Hallucination in Generative Visual-Language-Action Models](https://arxiv.org/abs/2602.06339)
*Harold Soh,Eugene Lim*

Main category: cs.RO

TL;DR: 研究发现生成式机器人策略存在动作幻觉问题，源于结构不匹配，需改进以提升可靠性。


<details>
  <summary>Details</summary>
Motivation: 探讨机器人基础模型（如视觉-语言-动作模型）是否真正解决了机器人学的长期挑战，特别是动作幻觉和计划级失败的问题。

Method: 分析了潜在变量生成策略中的动作幻觉及其扩展到计划级失败的问题，研究了拓扑、精度和时域三个结构障碍。

Result: 揭示了生成式机器人策略中动作幻觉的结构性根源，并提出了改进可靠性和可信度的原则性方向。

Conclusion: 尽管生成式机器人策略在表达能力上具有优势，但其在可靠性和可信度方面仍面临挑战，需要通过结构改进来解决。

Abstract: Robot Foundation Models such as Vision-Language-Action models are rapidly reshaping how robot policies are trained and deployed, replacing hand-designed planners with end-to-end generative action models. While these systems demonstrate impressive generalization, it remains unclear whether they fundamentally resolve the long-standing challenges of robotics. We address this question by analyzing action hallucinations that violate physical constraints and their extension to plan-level failures. Focusing on latent-variable generative policies, we show that hallucinations often arise from structural mismatches between feasible robot behavior and common model architectures. We study three such barriers -- topological, precision, and horizon -- and show how they impose unavoidable tradeoffs. Our analysis provides mechanistic explanations for reported empirical failures of generative robot policies and suggests principled directions for improving reliability and trustworthiness, without abandoning their expressive power.

</details>


### [120] [HiWET: Hierarchical World-Frame End-Effector Tracking for Long-Horizon Humanoid Loco-Manipulation](https://arxiv.org/abs/2602.06341)
*Zhanxiang Cao,Liyun Yan,Yang Zhang,Sirui Chen,Jianming Ma,Tianyue Zhan,Shengcheng Fu,Yufei Jia,Cewu Lu,Yue Gao*

Main category: cs.RO

TL;DR: HiWET是一种分层强化学习框架，通过世界坐标系末端执行器跟踪和KMP，解决了人形机器人运动操作中的累积漂移问题，实现了精确稳定的长时任务执行。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常在身体中心坐标系中制定命令，无法固有地校正由腿式运动引起的累积世界坐标系漂移。

Method: 提出HiWET，一种分层强化学习框架，将全局推理与动态执行解耦。高层策略生成子目标，联合优化末端执行器精度和基座定位；低层策略在稳定性约束下执行这些命令。引入Kinematic Manifold Prior（KMP），通过残差学习将操作流形嵌入动作空间。

Result: HiWET在长期世界坐标系任务中实现了精确且稳定的末端执行器跟踪。低层策略在物理人形机器人上实现了零样本仿真到现实的迁移。

Conclusion: HiWET框架通过结合显式的世界坐标系推理和分层控制，为长期的人形机器人运动操作任务提供了有效且可扩展的解决方案。

Abstract: Humanoid loco-manipulation requires executing precise manipulation tasks while maintaining dynamic stability amid base motion and impacts. Existing approaches typically formulate commands in body-centric frames, fail to inherently correct cumulative world-frame drift induced by legged locomotion. We reformulate the problem as world-frame end-effector tracking and propose HiWET, a hierarchical reinforcement learning framework that decouples global reasoning from dynamic execution. The high-level policy generates subgoals that jointly optimize end-effector accuracy and base positioning in the world frame, while the low-level policy executes these commands under stability constraints. We introduce a Kinematic Manifold Prior (KMP) that embeds the manipulation manifold into the action space via residual learning, reducing exploration dimensionality and mitigating kinematically invalid behaviors. Extensive simulation and ablation studies demonstrate that HiWET achieves precise and stable end-effector tracking in long-horizon world-frame tasks. We validate zero-shot sim-to-real transfer of the low-level policy on a physical humanoid, demonstrating stable locomotion under diverse manipulation commands. These results indicate that explicit world-frame reasoning combined with hierarchical control provides an effective and scalable solution for long-horizon humanoid loco-manipulation.

</details>


### [121] [Nipping the Drift in the Bud: Retrospective Rectification for Robust Vision-Language Navigation](https://arxiv.org/abs/2602.06356)
*Gang He,Zhenyang Liu,Kepeng Xu,Li Xu,Tong Qiao,Wenxin Yu,Chang Wu,Weiying Xie*

Main category: cs.RO

TL;DR: BudVLN通过在线学习和反事实重新锚定技术解决VLN中的指令-状态不对齐问题，显著提升导航性能。


<details>
  <summary>Details</summary>
Motivation: 现有模仿学习方法存在暴露偏差和指令-状态不对齐问题，导致推理时的小偏差累积成大错误，BudVLN旨在解决这一问题。

Method: BudVLN采用在线框架，通过反事实重新锚定和决策条件监督合成，利用测地线预言机生成纠正轨迹，确保语义一致性。

Result: 在R2R-CE和RxR-CE基准测试中，BudVLN在成功率和SPL指标上均达到最先进水平。

Conclusion: BudVLN通过在线学习和反事实重新锚定技术，有效解决了指令-状态不对齐问题，显著提升了导航性能，在R2R-CE和RxR-CE基准测试中取得了最佳成绩。

Abstract: Vision-Language Navigation (VLN) requires embodied agents to interpret natural language instructions and navigate through complex continuous 3D environments. However, the dominant imitation learning paradigm suffers from exposure bias, where minor deviations during inference lead to compounding errors. While DAgger-style approaches attempt to mitigate this by correcting error states, we identify a critical limitation: Instruction-State Misalignment. Forcing an agent to learn recovery actions from off-track states often creates supervision signals that semantically conflict with the original instruction. In response to these challenges, we introduce BudVLN, an online framework that learns from on-policy rollouts by constructing supervision to match the current state distribution. BudVLN performs retrospective rectification via counterfactual re-anchoring and decision-conditioned supervision synthesis, using a geodesic oracle to synthesize corrective trajectories that originate from valid historical states, ensuring semantic consistency. Experiments on the standard R2R-CE and RxR-CE benchmarks demonstrate that BudVLN consistently mitigates distribution shift and achieves state-of-the-art performance in both Success Rate and SPL.

</details>


### [122] [Towards Adaptive Environment Generation for Training Embodied Agents](https://arxiv.org/abs/2602.06366)
*Teresa Yeo,Dulaj Weerakoon,Dulanga Weerakoon,Archan Misra*

Main category: cs.RO

TL;DR: 提出了一种闭环环境生成方法，通过动态调整难度来提升智能体的学习效率和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 当前的开环环境生成方法不考虑智能体的表现，导致生成的环境可能过于简单或无效，限制了学习效果。

Method: 采用可控的环境表示方法，提取细粒度的性能反馈，并通过闭环适应机制将反馈转化为环境调整。

Result: 反馈驱动的环境生成方法能够针对智能体的当前能力生成更具挑战性的训练环境，从而提升学习效率和泛化能力。

Conclusion: 提出的闭环环境生成方法通过动态调整难度，有效提升了智能体在新环境中的泛化能力和学习效率。

Abstract: Embodied agents struggle to generalize to new environments, even when those environments share similar underlying structures to their training settings. Most current approaches to generating these training environments follow an open-loop paradigm, without considering the agent's current performance. While procedural generation methods can produce diverse scenes, diversity without feedback from the agent is inefficient. The generated environments may be trivially easy, providing limited learning signal. To address this, we present a proof-of-concept for closed-loop environment generation that adapts difficulty to the agent's current capabilities. Our system employs a controllable environment representation, extracts fine-grained performance feedback beyond binary success or failure, and implements a closed-loop adaptation mechanism that translates this feedback into environment modifications. This feedback-driven approach generates training environments that more challenging in the ways the agent needs to improve, enabling more efficient learning and better generalization to novel settings.

</details>


### [123] [A Consistency-Improved LiDAR-Inertial Bundle Adjustment](https://arxiv.org/abs/2602.06380)
*Xinran Li,Shuaikang Zheng,Pengcheng Zheng,Xinyang Wang,Jiacheng Li,Zhitian Li,Xudong Zou*

Main category: cs.RO

TL;DR: 本文提出了一种改进的LiDAR-惯性束调整方法，通过定制参数化和估计器解决了特征参数化和协方差估计的不一致问题，并在LiDAR-惯性里程计中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 尽管基于特征的SLAM系统通过利用边缘和平面结构取得了显著成果，但它们常因特征参数化和估计协方差的不一致估计器而受到影响。

Method: 1. 提出了一种立体投影表示法来参数化平面和边缘特征，并进行了全面的可观测性分析以支持其与一致性估计器的集成。2. 实现了基于最大后验（MAP）和首次估计雅可比（FEJ）的LiDAR-惯性束调整，以保持系统准确的估计协方差和可观测性。

Result: 所提出的方法在LiDAR-惯性里程计中验证了其有效性，提高了估计一致性。

Conclusion: 本文提出了一种改进的LiDAR-惯性束调整方法，通过定制参数化和估计器提高了SLAM系统的估计一致性，并在LiDAR-惯性里程计中验证了其有效性。

Abstract: Simultaneous Localization and Mapping (SLAM) using 3D LiDAR has emerged as a cornerstone for autonomous navigation in robotics. While feature-based SLAM systems have achieved impressive results by leveraging edge and planar structures, they often suffer from the inconsistent estimator associated with feature parameterization and estimated covariance. In this work, we present a consistency-improved LiDAR-inertial bundle adjustment (BA) with tailored parameterization and estimator. First, we propose a stereographic-projection representation parameterizing the planar and edge features, and conduct a comprehensive observability analysis to support its integrability with consistent estimator. Second, we implement a LiDAR-inertial BA with Maximum a Posteriori (MAP) formulation and First-Estimate Jacobians (FEJ) to preserve the accurate estimated covariance and observability properties of the system. Last, we apply our proposed BA method to a LiDAR-inertial odometry.

</details>


### [124] [Now You See That: Learning End-to-End Humanoid Locomotion from Raw Pixels](https://arxiv.org/abs/2602.06382)
*Wandong Sun,Yongbo Su,Leoric Huang,Alex Zhang,Dwyane Wei,Mu San,Daniel Tian,Ellie Cao,Finn Yan,Ethan Xie,Zongwu Xie*

Main category: cs.RO

TL;DR: 论文提出端到端框架，通过高保真模拟和视觉感知蒸馏解决人形机器人视觉运动中的模拟到现实差距和地形适应问题，实现了多样化环境中的稳健表现。


<details>
  <summary>Details</summary>
Motivation: 解决人形机器人视觉驱动运动中的两个基本问题：模拟到现实差距导致的感知噪声和多样化地形训练中的学习目标冲突。

Method: 论文开发了高保真深度传感器模拟以捕捉真实世界中的立体匹配伪影和校准不确定性，并提出视觉感知行为蒸馏方法，结合潜在空间对齐和噪声不变辅助任务。此外，通过地形特定奖励塑造与多批评器和多判别器学习相结合，实现了多样化地形的适应。

Result: 在两个配备不同立体深度摄像头的人形机器人平台上验证了方法的有效性，策略在多样环境中表现出稳健性能，能够无缝处理极端挑战和精细任务。

Conclusion: 该论文提出了一个端到端的框架，通过高保真深度传感器模拟和视觉感知行为蒸馏方法，解决了人形机器人视觉驱动运动中的模拟到现实差距和多样化地形适应问题，最终实现了在多种环境中的稳健表现。

Abstract: Achieving robust vision-based humanoid locomotion remains challenging due to two fundamental issues: the sim-to-real gap introduces significant perception noise that degrades performance on fine-grained tasks, and training a unified policy across diverse terrains is hindered by conflicting learning objectives. To address these challenges, we present an end-to-end framework for vision-driven humanoid locomotion. For robust sim-to-real transfer, we develop a high-fidelity depth sensor simulation that captures stereo matching artifacts and calibration uncertainties inherent in real-world sensing. We further propose a vision-aware behavior distillation approach that combines latent space alignment with noise-invariant auxiliary tasks, enabling effective knowledge transfer from privileged height maps to noisy depth observations. For versatile terrain adaptation, we introduce terrain-specific reward shaping integrated with multi-critic and multi-discriminator learning, where dedicated networks capture the distinct dynamics and motion priors of each terrain type. We validate our approach on two humanoid platforms equipped with different stereo depth cameras. The resulting policy demonstrates robust performance across diverse environments, seamlessly handling extreme challenges such as high platforms and wide gaps, as well as fine-grained tasks including bidirectional long-term staircase traversal.

</details>


### [125] [ECO: Energy-Constrained Optimization with Reinforcement Learning for Humanoid Walking](https://arxiv.org/abs/2602.06445)
*Weidong Huang,Jingwen Zhang,Jiongye Li,Shibowen Zhang,Jiayang Wu,Jiayi Wang,Hangxin Liu,Yaodong Yang,Yao Su*

Main category: cs.RO

TL;DR: ECO是一种约束强化学习框架，通过显式能量约束提升人形机器人行走的能量效率，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有MPC和RL方法依赖多目标优化框架中的能量相关指标，需要大量超参数调整且常导致次优策略。

Method: 提出ECO（Energy-Constrained Optimization）框架，将能量相关指标从奖励中分离，重新定义为显式不等式约束，并使用拉格朗日方法强制执行能量消耗和参考运动的约束。

Result: 在kid-sized人形机器人BRUCE上的实验表明，ECO相比基线方法显著降低了能量消耗，同时保持了稳健的行走性能。

Conclusion: ECO框架通过将能量相关指标作为显式不等式约束，显著提升了人形机器人的能量效率，同时保持了稳健的行走性能。

Abstract: Achieving stable and energy-efficient locomotion is essential for humanoid robots to operate continuously in real-world applications. Existing MPC and RL approaches often rely on energy-related metrics embedded within a multi-objective optimization framework, which require extensive hyperparameter tuning and often result in suboptimal policies. To address these challenges, we propose ECO (Energy-Constrained Optimization), a constrained RL framework that separates energy-related metrics from rewards, reformulating them as explicit inequality constraints. This method provides a clear and interpretable physical representation of energy costs, enabling more efficient and intuitive hyperparameter tuning for improved energy efficiency. ECO introduces dedicated constraints for energy consumption and reference motion, enforced by the Lagrangian method, to achieve stable, symmetric, and energy-efficient walking for humanoid robots. We evaluated ECO against MPC, standard RL with reward shaping, and four state-of-the-art constrained RL methods. Experiments, including sim-to-sim and sim-to-real transfers on the kid-sized humanoid robot BRUCE, demonstrate that ECO significantly reduces energy consumption compared to baselines while maintaining robust walking performance. These results highlight a substantial advancement in energy-efficient humanoid locomotion. All experimental demonstrations can be found on the project website: https://sites.google.com/view/eco-humanoid.

</details>


### [126] [User-Centric Object Navigation: A Benchmark with Integrated User Habits for Personalized Embodied Object Search](https://arxiv.org/abs/2602.06459)
*Hongcheng Wang,Jinyu Zhu,Hao Dong*

Main category: cs.RO

TL;DR: UcON是一个新的对象导航基准，通过整合用户习惯提升导航代理在个性化家庭环境中的表现。


<details>
  <summary>Details</summary>
Motivation: 现有对象导航基准未考虑用户特定的物品摆放习惯，限制了导航代理在个性化家庭环境中的适应性。

Method: 提出了一个习惯检索模块，用于提取和利用与目标对象相关的用户习惯。

Result: 实验表明，整合用户习惯能显著提高导航成功率，而当前SOTA方法在习惯驱动的物品摆放下表现大幅下降。

Conclusion: UcON是首个大规模形式化并评估基于用户习惯的对象导航的基准，显著提升了导航代理在个性化家庭环境中的适应性。

Abstract: In the evolving field of robotics, the challenge of Object Navigation (ON) in household environments has attracted significant interest. Existing ON benchmarks typically place objects in locations guided by general scene priors, without accounting for the specific placement habits of individual users. This omission limits the adaptability of navigation agents in personalized household environments. To address this, we introduce User-centric Object Navigation (UcON), a new benchmark that incorporates user-specific object placement habits, referred to as user habits. This benchmark requires agents to leverage these user habits for more informed decision-making during navigation. UcON encompasses approximately 22,600 user habits across 489 object categories. UcON is, to our knowledge, the first benchmark that explicitly formalizes and evaluates habit-conditioned object navigation at scale and covers the widest range of target object categories. Additionally, we propose a habit retrieval module to extract and utilize habits related to target objects, enabling agents to infer their likely locations more effectively. Experimental results demonstrate that current SOTA methods exhibit substantial performance degradation under habit-driven object placement, while integrating user habits consistently improves success rates. Code is available at https://github.com/whcpumpkin/User-Centric-Object-Navigation.

</details>


### [127] [MultiGraspNet: A Multitask 3D Vision Model for Multi-gripper Robotic Grasping](https://arxiv.org/abs/2602.06504)
*Stephany Ortuno-Chanelo,Paolo Rabino,Enrico Civitelli,Tatiana Tommasi,Raffaello Camoriano*

Main category: cs.RO

TL;DR: MultiGraspNet 是一种多任务 3D 深度学习方法，统一预测平行和真空夹持器的抓取姿势，显著提升通用性和抓取性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常局限于单一夹持器或依赖定制混合夹持器，缺乏通用性。MultiGraspNet 旨在解决这一问题，提升多夹持器场景下的抓取性能。

Method: MultiGraspNet 是一种多任务 3D 深度学习方法，通过共享早期特征并保留夹持器特定的细化模块，利用互补信息增强抓取鲁棒性。

Result: 实验表明，MultiGraspNet 在真实单臂多夹持器机器人设置中表现优异，真空抓取任务中抓取成功率提升 16%（已知物体）和 32%（新物体），平行抓取任务结果也具竞争力。

Conclusion: MultiGraspNet 提供了一种统一的框架，能够同时预测平行和真空夹持器的可行抓取姿势，显著提升了机器人抓取的通用性和适应性。

Abstract: Vision-based models for robotic grasping automate critical, repetitive, and draining industrial tasks. Existing approaches are typically limited in two ways: they either target a single gripper and are potentially applied on costly dual-arm setups, or rely on custom hybrid grippers that require ad-hoc learning procedures with logic that cannot be transferred across tasks, restricting their general applicability. In this work, we present MultiGraspNet, a novel multitask 3D deep learning method that predicts feasible poses simultaneously for parallel and vacuum grippers within a unified framework, enabling a single robot to handle multiple end effectors. The model is trained on the richly annotated GraspNet-1Billion and SuctionNet-1Billion datasets, which have been aligned for the purpose, and generates graspability masks quantifying the suitability of each scene point for successful grasps. By sharing early-stage features while maintaining gripper-specific refiners, MultiGraspNet effectively leverages complementary information across grasping modalities, enhancing robustness and adaptability in cluttered scenes. We characterize MultiGraspNet's performance with an extensive experimental analysis, demonstrating its competitiveness with single-task models on relevant benchmarks. We run real-world experiments on a single-arm multi-gripper robotic setup showing that our approach outperforms the vacuum baseline, grasping 16% percent more seen objects and 32% more of the novel ones, while obtaining competitive results for the parallel task.

</details>


### [128] [World-VLA-Loop: Closed-Loop Learning of Video World Model and VLA Policy](https://arxiv.org/abs/2602.06508)
*Xiaokang Liu,Zechen Bai,Hai Ci,Kevin Yuchen Ma,Mike Zheng Shou*

Main category: cs.RO

TL;DR: World-VLA-Loop通过闭环框架联合优化世界模型和VLA策略，利用SANS数据集提升动作-结果对齐，显著提升机器人学习性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于视频扩散变换器的机器人世界模型在动作跟随精度上表现不佳，限制了其在机器人学习中的应用。

Method: 提出了一个状态感知的视频世界模型，联合预测未来观察和奖励信号，并引入了SANS数据集以提高动作-结果对齐。

Result: 在仿真和现实任务中评估表明，该框架显著提升了VLA性能，建立了世界建模与策略学习的互利关系。

Conclusion: World-VLA-Loop框架通过联合优化世界模型和VLA策略，显著提升了机器人学习的性能，减少了物理交互需求。

Abstract: Recent progress in robotic world models has leveraged video diffusion transformers to predict future observations conditioned on historical states and actions. While these models can simulate realistic visual outcomes, they often exhibit poor action-following precision, hindering their utility for downstream robotic learning. In this work, we introduce World-VLA-Loop, a closed-loop framework for the joint refinement of world models and Vision-Language-Action (VLA) policies. We propose a state-aware video world model that functions as a high-fidelity interactive simulator by jointly predicting future observations and reward signals. To enhance reliability, we introduce the SANS dataset, which incorporates near-success trajectories to improve action-outcome alignment within the world model. This framework enables a closed-loop for reinforcement learning (RL) post-training of VLA policies entirely within a virtual environment. Crucially, our approach facilitates a co-evolving cycle: failure rollouts generated by the VLA policy are iteratively fed back to refine the world model precision, which in turn enhances subsequent RL optimization. Evaluations across simulation and real-world tasks demonstrate that our framework significantly boosts VLA performance with minimal physical interaction, establishing a mutually beneficial relationship between world modeling and policy learning for general-purpose robotics. Project page: https://showlab.github.io/World-VLA-Loop/.

</details>


### [129] [Beyond the Majority: Long-tail Imitation Learning for Robotic Manipulation](https://arxiv.org/abs/2602.06512)
*Junhong Zhu,Ji Zhang,Jingkuan Song,Lianli Gao,Heng Tao Shen*

Main category: cs.RO

TL;DR: 本文分析了策略学习中的长尾问题，提出APA方案，通过头部任务知识转移提升尾部任务性能，实验验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 通用机器人策略在模仿学习中的性能受限于训练数据的长尾分布，导致尾部任务泛化能力差。

Method: 通过引入APA方案，无需外部演示即可增强尾部任务的空间推理能力。

Result: 在仿真和真实世界操作任务中的实验验证了APA的有效性。

Conclusion: APA（Approaching-Phase Augmentation）是一种简单有效的方案，能够将知识从数据丰富的头部任务转移到数据稀缺的尾部任务，显著提升策略在尾部任务上的泛化能力。

Abstract: While generalist robot policies hold significant promise for learning diverse manipulation skills through imitation, their performance is often hindered by the long-tail distribution of training demonstrations. Policies learned on such data, which is heavily skewed towards a few data-rich head tasks, frequently exhibit poor generalization when confronted with the vast number of data-scarce tail tasks. In this work, we conduct a comprehensive analysis of the pervasive long-tail challenge inherent in policy learning. Our analysis begins by demonstrating the inefficacy of conventional long-tail learning strategies (e.g., re-sampling) for improving the policy's performance on tail tasks. We then uncover the underlying mechanism for this failure, revealing that data scarcity on tail tasks directly impairs the policy's spatial reasoning capability. To overcome this, we introduce Approaching-Phase Augmentation (APA), a simple yet effective scheme that transfers knowledge from data-rich head tasks to data-scarce tail tasks without requiring external demonstrations. Extensive experiments in both simulation and real-world manipulation tasks demonstrate the effectiveness of APA. Our code and demos are publicly available at: https://mldxy.github.io/Project-VLA-long-tail/.

</details>


### [130] [Primary Experimental Feedback on a Co-manipulated Robotic System for Assisted Cervical Surgery](https://arxiv.org/abs/2602.06541)
*Seifeddine Sellemi,Abdelbadia Chaker,Tanguy Vendeuvre,Terence Essomba,Med Amine Laribi*

Main category: cs.RO

TL;DR: 本研究评估了机器人辅助颈椎手术钻孔的准确性，发现系统在执行预定轨迹时存在偏差，为改进系统可靠性和临床效果提供了反馈。


<details>
  <summary>Details</summary>
Motivation: 机器人辅助手术在提高手术人体工学、精确性和工作流程效率方面具有潜力，特别是在复杂的颈椎手术中。本研究旨在量化钻孔工具相对于计划轨迹的偏差，以评估系统的可靠性。

Method: 八名经验丰富的颈椎外科医生使用机器人辅助设置进行了14次钻孔，评估系统在执行预定轨迹时的准确性。

Result: 研究发现机器人辅助系统在执行钻孔任务时存在位置和方向偏差，为系统的进一步优化和临床应用提供了依据。

Conclusion: 本研究评估了协作机器人系统在颈椎手术钻孔任务中的性能，发现其在执行预定轨迹时存在一定的位置和方向偏差，为系统可靠性和临床应用的改进提供了重要反馈。

Abstract: Robotic-assisted surgery has emerged as a promising approach to improve surgical ergonomics, precision, and workflow efficiency, particularly in complex procedures such as cervical spine surgery. In this study, we evaluate the performance of a collaborative robotic system designed to assist surgeons in drilling tasks by assessing its accuracy in executing predefined trajectories. A total of 14 drillings were performed by eight experienced cervical surgeons, utilizing a robotic-assisted setup aimed at ensuring stability and alignment. The primary objective of this study is to quantify the deviations in the position and orientation of the drilling tool relative to the planned trajectory, providing insights into the system's reliability and potential impact on clinical outcomes. While the primary function of robotic assistance in surgery is to enhance surgeon comfort and procedural guidance rather than solely optimizing precision, understanding the system's accuracy remains crucial for its effective integration into surgical practices part of this primary experimental feedback, the study offers an in-depth analysis of the co-manipulated robotic system's performance, focusing on the experimental setup and error evaluation methods. The findings of this study will contribute to the ongoing development of robotic-assisted cervical surgery, highlighting both its advantages and areas for improvement in achieving safer and more efficient surgical workflows

</details>


### [131] [The Law of Task-Achieving Body Motion: Axiomatizing Success of Robot Manipulation Actions](https://arxiv.org/abs/2602.06572)
*Malte Huerkamp,Jonas Dech,Michael Beetz*

Main category: cs.RO

TL;DR: 论文提出了一种任务达成身体运动的正确性规范，通过分解任务条件为三个谓词，支持运动合成与验证，并在厨房环境中验证了其可行性。


<details>
  <summary>Details</summary>
Motivation: 为了使自主代理在日常操作中确保其身体运动在任务请求下语义正确、在环境中因果有效且对自身体现可行，需要一种验证这些属性的方法。

Method: 引入任务-环境-体现（TEE）类，将世界状态表示为语义数字孪生（SDTs），并定义适用的物理模型，将任务达成分解为语义请求满足、因果充分性和体现层面的可行性验证。

Result: 该法则支持运动合成、给定身体运动的验证、类型化失败诊断、跨机器人和环境的可行性分析，以及对机器人身体运动的反事实推理。在厨房环境中针对三种不同的移动操作平台进行了实例化验证。

Conclusion: 论文提出了任务达成身体运动法则（Law of Task-Achieving Body Motion），作为身体运动的正确性规范，并通过分解任务达成条件为三个谓词（SatisfiesRequest、Causes、CanPerform），实现了可重用、实现无关的接口，支持运动合成与验证。

Abstract: Autonomous agents that perform everyday manipulation actions need to ensure that their body motions are semantically correct with respect to a task request, causally effective within their environment, and feasible for their embodiment. In order to enable robots to verify these properties, we introduce the Law of Task-Achieving Body Motion as an axiomatic correctness specification for body motions. To that end we introduce scoped Task-Environment-Embodiment (TEE) classes that represent world states as Semantic Digital Twins (SDTs) and define applicable physics models to decompose task achievement into three predicates: SatisfiesRequest for semantic request satisfaction over SDT state evolution; Causes for causal sufficiency under the scoped physics model; and CanPerform for safety and feasibility verification at the embodiment level. This decomposition yields a reusable, implementation-independent interface that supports motion synthesis and the verification of given body motions. It also supports typed failure diagnosis (semantic, causal, embodiment and out-of-scope), feasibility across robots and environments, and counterfactual reasoning about robot body motions. We demonstrate the usability of the law in practice by instantiating it for articulated container manipulation in kitchen environments on three contrasting mobile manipulation platforms

</details>


### [132] [Think Proprioceptively: Embodied Visual Reasoning for VLA Manipulation](https://arxiv.org/abs/2602.06575)
*Fangyuan Wang,Peng Zhou,Jiaming Qi,Shipeng Lyu,David Navarro-Alarcon,Guodong Guo*

Main category: cs.RO

TL;DR: ThinkProprio通过早期融合本体感受和指令，优化视觉注意力分配，提升性能并降低延迟。


<details>
  <summary>Details</summary>
Motivation: 解决传统VLA模型中本体感受仅作为后期条件信号的问题，使其能更早地影响指令理解和视觉注意力分配。

Method: 将本体感受转换为文本令牌序列，并与任务指令在VLM嵌入空间早期融合，从而影响视觉推理和令牌选择。

Result: 在CALVIN、LIBERO和实际操作中，ThinkProprio性能优于基线模型，推理延迟降低50%以上。

Conclusion: ThinkProprio通过早期融合本体感受和任务指令，显著提升了VLA模型的性能，同时降低了推理延迟。

Abstract: Vision-language-action (VLA) models typically inject proprioception only as a late conditioning signal, which prevents robot state from shaping instruction understanding and from influencing which visual tokens are attended throughout the policy. We introduce ThinkProprio, which converts proprioception into a sequence of text tokens in the VLM embedding space and fuses them with the task instruction at the input. This early fusion lets embodied state participate in subsequent visual reasoning and token selection, biasing computation toward action-critical evidence while suppressing redundant visual tokens. In a systematic ablation over proprioception encoding, state entry point, and action-head conditioning, we find that text tokenization is more effective than learned projectors, and that retaining roughly 15% of visual tokens can match the performance of using the full token set. Across CALVIN, LIBERO, and real-world manipulation, ThinkProprio matches or improves over strong baselines while reducing end-to-end inference latency over 50%.

</details>


### [133] [Force Generative Imitation Learning: Bridging Position Trajectory and Force Commands through Control Technique](https://arxiv.org/abs/2602.06620)
*Hiroshi Sato,Sho Sakaino,Toshiaki Tsuji*

Main category: cs.RO

TL;DR: 提出力生成模型结合反馈控制，通过无记忆设计提升对未见位置轨迹的力指令生成能力。


<details>
  <summary>Details</summary>
Motivation: 解决接触丰富任务中力指令难以获取的问题，克服预训练基础模型因硬件依赖性而难以应用的挑战。

Method: 提出力生成模型估计给定位置轨迹的力指令，并引入反馈控制机制处理未见过的位置轨迹。

Result: 实验显示反馈控制在力生成模型有记忆时不收敛，采用无记忆模型后实现稳定控制。

Conclusion: 采用无记忆模型实现稳定反馈控制，有效生成力指令，提升真实世界机器人书写任务的泛化能力。

Abstract: In contact-rich tasks, while position trajectories are often easy to obtain, appropriate force commands are typically unknown. Although it is conceivable to generate force commands using a pretrained foundation model such as Vision-Language-Action (VLA) models, force control is highly dependent on the specific hardware of the robot, which makes the application of such models challenging. To bridge this gap, we propose a force generative model that estimates force commands from given position trajectories. However, when dealing with unseen position trajectories, the model struggles to generate accurate force commands. To address this, we introduce a feedback control mechanism. Our experiments reveal that feedback control does not converge when the force generative model has memory. We therefore adopt a model without memory, enabling stable feedback control. This approach allows the system to generate force commands effectively, even for unseen position trajectories, improving generalization for real-world robot writing tasks.

</details>


### [134] [Humanoid Manipulation Interface: Humanoid Whole-Body Manipulation from Robot-Free Demonstrations](https://arxiv.org/abs/2602.06643)
*Ruiqian Nai,Boyuan Zheng,Junming Zhao,Haodong Zhu,Sicong Dai,Zunhao Chen,Yihang Hu,Yingdong Hu,Tong Zhang,Chuan Wen,Yang Gao*

Main category: cs.RO

TL;DR: HuMI是一个便携高效的框架，通过捕获人类全身运动数据并转化为机器人技能，显著提升数据收集效率和任务成功率。


<details>
  <summary>Details</summary>
Motivation: 当前人形机器人全身操控方法依赖遥操作或视觉模拟到现实的强化学习，存在硬件复杂性和奖励工程难题，限制了自主技能的多样性和环境适应性。

Method: HuMI采用便携硬件捕获全身运动数据，并设计分层学习管道将人类动作转化为机器人技能。

Result: 在五种全身任务中，HuMI的数据收集效率比遥操作提高3倍，并在未知环境中达到70%的成功率。

Conclusion: HuMI框架通过便携硬件高效采集全身运动数据，并通过分层学习管道将这些数据转化为灵巧可行的人形机器人技能，显著提升了数据收集效率和任务成功率。

Abstract: Current approaches for humanoid whole-body manipulation, primarily relying on teleoperation or visual sim-to-real reinforcement learning, are hindered by hardware logistics and complex reward engineering. Consequently, demonstrated autonomous skills remain limited and are typically restricted to controlled environments. In this paper, we present the Humanoid Manipulation Interface (HuMI), a portable and efficient framework for learning diverse whole-body manipulation tasks across various environments. HuMI enables robot-free data collection by capturing rich whole-body motion using portable hardware. This data drives a hierarchical learning pipeline that translates human motions into dexterous and feasible humanoid skills. Extensive experiments across five whole-body tasks--including kneeling, squatting, tossing, walking, and bimanual manipulation--demonstrate that HuMI achieves a 3x increase in data collection efficiency compared to teleoperation and attains a 70% success rate in unseen environments.

</details>


### [135] [RAPID: Reconfigurable, Adaptive Platform for Iterative Design](https://arxiv.org/abs/2602.06653)
*Zi Yin,Fanhong Li,Shurui Zheng,Jia Liu*

Main category: cs.RO

TL;DR: RAPID是一个模块化机器人平台，通过硬件快速重配置和软件自动适配，加速多模态策略开发，支持传感器热插拔。


<details>
  <summary>Details</summary>
Motivation: 机器人操作策略开发中，末端执行器的微小改动常需机械重装和系统重新集成，导致迭代缓慢。RAPID旨在减少这种摩擦。

Method: RAPID采用无需工具的模块化硬件架构，结合基于USB事件的驱动级物理掩码（Physical Mask），实现快速硬件重配置和实时硬件状态感知。

Result: 实验表明，RAPID将多模态配置的搭建时间缩短了两个数量级，并能在传感器热插拔时保持策略执行。

Conclusion: RAPID平台通过模块化硬件架构和配套软件栈显著减少了机器人操作策略开发中的重复配置时间，并支持运行时传感器的热插拔，为多模态消融研究提供了实用解决方案。

Abstract: Developing robotic manipulation policies is iterative and hypothesis-driven: researchers test tactile sensing, gripper geometries, and sensor placements through real-world data collection and training. Yet even minor end-effector changes often require mechanical refitting and system re-integration, slowing iteration. We present RAPID, a full-stack reconfigurable platform designed to reduce this friction. RAPID is built around a tool-free, modular hardware architecture that unifies handheld data collection and robot deployment, and a matching software stack that maintains real-time awareness of the underlying hardware configuration through a driver-level Physical Mask derived from USB events. This modular hardware architecture reduces reconfiguration to seconds and makes systematic multi-modal ablation studies practical, allowing researchers to sweep diverse gripper and sensing configurations without repeated system bring-up. The Physical Mask exposes modality presence as an explicit runtime signal, enabling auto-configuration and graceful degradation under sensor hot-plug events, so policies can continue executing when sensors are physically added or removed. System-centric experiments show that RAPID reduces the setup time for multi-modal configurations by two orders of magnitude compared to traditional workflows and preserves policy execution under runtime sensor hot-unplug events. The hardware designs, drivers, and software stack are open-sourced at https://rapid-kit.github.io/ .

</details>


### [136] [Crowd-FM: Learned Optimal Selection of Conditional Flow Matching-generated Trajectories for Crowd Navigation](https://arxiv.org/abs/2602.06698)
*Antareep Singha,Laksh Nanwani,Mathai Mathew P.,Samkit Jain,Phani Teja Singamaneni,Arun Kumar Singh,K. Madhava Krishna*

Main category: cs.RO

TL;DR: Crowd-FM通过条件流匹配和人类轨迹评分，提升机器人导航安全性和人类相似度，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决机器人在密集、非结构化人群中的安全导航问题，并提升其轨迹的人类相似度以增强环境接受度。

Method: 采用条件流匹配（CFM）策略学习碰撞自由运动基元，并通过评分网络选择最接近人类轨迹的路径。

Result: CFM策略在碰撞自由导航中成功率高于现有学习方法，结合推理时优化后甚至超越基于优化的规划方法；评分网络选择的轨迹比人工设计成本函数更接近专家数据。

Conclusion: Crowd-FM通过结合条件流匹配策略和人类轨迹评分函数，显著提升了机器人在密集人群中的导航安全性和人类相似度，优于现有学习和优化方法。

Abstract: Safe and computationally efficient local planning for mobile robots in dense, unstructured human crowds remains a fundamental challenge. Moreover, ensuring that robot trajectories are similar to how a human moves will increase the acceptance of the robot in human environments. In this paper, we present Crowd-FM, a learning-based approach to address both safety and human-likeness challenges. Our approach has two novel components. First, we train a Conditional Flow-Matching (CFM) policy over a dataset of optimally controlled trajectories to learn a set of collision-free primitives that a robot can choose at any given scenario. The chosen optimal control solver can generate multi-modal collision-free trajectories, allowing the CFM policy to learn a diverse set of maneuvers. Secondly, we learn a score function over a dataset of human demonstration trajectories that provides a human-likeness score for the flow primitives. At inference time, computing the optimal trajectory requires selecting the one with the highest score. Our approach improves the state-of-the-art by showing that our CFM policy alone can produce collision-free navigation with a higher success rate than existing learning-based baselines. Furthermore, when augmented with inference-time refinement, our approach can outperform even expensive optimisation-based planning approaches. Finally, we validate that our scoring network can select trajectories closer to the expert data than a manually designed cost function.

</details>


### [137] [Constraint Manifold Exploration for Efficient Continuous Coverage Estimation](https://arxiv.org/abs/2602.06749)
*Robert Wilbrandt,Rüdiger Dillmann*

Main category: cs.RO

TL;DR: 该论文提出了一种基于采样的方法，用于估计工业机器人手臂在复杂环境中完全覆盖工件表面的可行性，验证了其准确性和效率。


<details>
  <summary>Details</summary>
Motivation: 现有方法在分析工业机器人手臂完全覆盖工件表面的可行性方面存在不足，尤其是在保持工具垂直于表面的应用中。

Method: 论文定义了一个扩展的环境配置空间，用于表示工具位置和方向约束，并采用基于延续的方法，结合两种不同的采样策略进行探索。

Result: 通过在不同运动学和环境中的全面评估，验证了该方法在运行时和效率上的表现。

Conclusion: 该论文提出了一种基于采样的连续覆盖估计方法，能够准确高效地计算复杂表面在复杂环境中的覆盖情况。

Abstract: Many automated manufacturing processes rely on industrial robot arms to move process-specific tools along workpiece surfaces. In applications like grinding, sanding, spray painting, or inspection, they need to cover a workpiece fully while keeping their tools perpendicular to its surface. While there are approaches to generate trajectories for these applications, there are no sufficient methods for analyzing the feasibility of full surface coverage. This work proposes a sampling-based approach for continuous coverage estimation that explores reachable surface regions in the configuration space. We define an extended ambient configuration space that allows for the representation of tool position and orientation constraints. A continuation-based approach is used to explore it using two different sampling strategies. A thorough evaluation across different kinematics and environments analyzes their runtime and efficiency. This validates our ability to accurately and efficiently calculate surface coverage for complex surfaces in complicated environments.

</details>


### [138] [SuReNav: Superpixel Graph-based Constraint Relaxation for Navigation in Over-constrained Environments](https://arxiv.org/abs/2602.06807)
*Keonyoung Koh,Moonkyeong Jung,Samuel Seungsup Lee,Daehyung Park*

Main category: cs.RO

TL;DR: SuReNav通过超像素图和图神经网络模仿人类导航，在半静态环境中实现了高效且安全的规划，并在真实机器人测试中验证了其性能。


<details>
  <summary>Details</summary>
Motivation: 解决半静态环境中过度约束的规划问题，避免硬约束区域并最小化穿越低风险区域，克服传统方法依赖预定义区域成本和空间连续性带来的局限性。

Method: SuReNav是一种基于超像素图的约束松弛和导航方法，包括三个组成部分：1）生成带有区域约束的超像素图地图；2）利用图神经网络对区域约束进行松弛，以模仿人类的安全高效导航；3）交替进行松弛、规划和执行以实现完整导航。

Result: 在2D语义地图和OpenStreetMap的3D地图上，SuReNav相比现有基线方法实现了最高的完整导航人类相似度评分，并平衡了效率与安全性。

Conclusion: SuReNav方法在2D和3D地图上实现了最高的人类相似度评分，同时在效率与安全性之间保持了平衡，并在真实世界的四足机器人导航中展示了其可扩展性和泛化性能。

Abstract: We address the over-constrained planning problem in semi-static environments. The planning objective is to find a best-effort solution that avoids all hard constraint regions while minimally traversing the least risky areas. Conventional methods often rely on pre-defined area costs, limiting generalizations. Further, the spatial continuity of navigation spaces makes it difficult to identify regions that are passable without overestimation. To overcome these challenges, we propose SuReNav, a superpixel graph-based constraint relaxation and navigation method that imitates human-like safe and efficient navigation. Our framework consists of three components: 1) superpixel graph map generation with regional constraints, 2) regional-constraint relaxation using graph neural network trained on human demonstrations for safe and efficient navigation, and 3) interleaving relaxation, planning, and execution for complete navigation. We evaluate our method against state-of-the-art baselines on 2D semantic maps and 3D maps from OpenStreetMap, achieving the highest human-likeness score of complete navigation while maintaining a balanced trade-off between efficiency and safety. We finally demonstrate its scalability and generalization performance in real-world urban navigation with a quadruped robot, Spot.

</details>


### [139] [A 26-Gram Butterfly-Inspired Robot Achieving Autonomous Tailless Flight](https://arxiv.org/abs/2602.06811)
*Weibin Gu,Chenrui Feng,Lian Liu,Chen Yang,Xingchi Jiao,Yuhe Ding,Xiaofei Shi,Chao Gao,Alessandro Rizzo,Guyue Zhou*

Main category: cs.RO

TL;DR: AirPulse是一种26克蝴蝶灵感FWMAV，通过生物力学特征和STAR生成器实现无辅助控制面的稳定飞行，为轻量级FWMAV提供了新平台。


<details>
  <summary>Details</summary>
Motivation: 探索无尾双翼FWMAV的飞行控制，填补其在复杂流体结构和翼体耦合方面的研究空白。

Method: 通过复制蝴蝶飞行的关键生物力学特征，如低翼展比、柔顺的碳纤维增强翼和低频高振幅的扑动，AirPulse机器人实现了完全机载、闭环、无绳飞行。建立了扑动调制参数与力-扭矩生成的定量映射，并引入了Stroke Timing Asymmetry Rhythm（STAR）生成器，实现了平滑、稳定且线性参数化的扑动不对称控制。

Result: 自由飞行实验展示了通过角度偏移或扑动时间调制实现的稳定爬升和转向机动，这是同行评审文献中报道的最轻双翼无尾蝴蝶灵感FWMAV首次实现机载控制飞行。

Conclusion: 这项工作为轻量级、防碰撞的FWMAV提供了一个基础平台，将生物灵感与实际空中机器人技术相结合。其非侵入性的机动性非常适合现实世界应用，如狭窄空间检查和生态监测，这些是传统无人机无法触及的。同时，其生物力学保真度为解码真实蝴蝶飞行的高效但不稳定原理提供了物理模型。

Abstract: Flapping-wing micro air vehicles (FWMAVs) have demonstrated remarkable bio-inspired agility, yet tailless two-winged configurations remain largely unexplored due to their complex fluid-structure and wing-body coupling. Here we present \textit{AirPulse}, a 26-gram butterfly-inspired FWMAV that achieves fully onboard, closed-loop, untethered flight without auxiliary control surfaces. The AirPulse robot replicates key biomechanical traits of butterfly flight, including low wing aspect ratio, compliant carbon-fiber-reinforced wings, and low-frequency, high-amplitude flapping that induces cyclic variations in the center of gravity and moment of inertia, producing characteristic body undulation. We establish a quantitative mapping between flapping modulation parameters and force-torque generation, and introduce the Stroke Timing Asymmetry Rhythm (STAR) generator, enabling smooth, stable, and linearly parameterized wingstroke asymmetry for flapping control. Integrating these with an attitude controller, the AirPulse robot maintains pitch and yaw stability despite strong oscillatory dynamics. Free-flight experiments demonstrate stable climbing and turning maneuvers via either angle offset or stroke timing modulation, marking the first onboard controlled flight of the lightest two-winged, tailless butterfly-inspired FWMAV reported in peer-reviewed literature. This work corroborates a foundational platform for lightweight, collision-proof FWMAVs, bridging biological inspiration with practical aerial robotics. Their non-invasive maneuverability is ideally suited for real-world applications, such as confined-space inspection and ecological monitoring, inaccessible to traditional drones, while their biomechanical fidelity provides a physical model to decode the principles underlying the erratic yet efficient flight of real butterflies.

</details>


### [140] [DynaRetarget: Dynamically-Feasible Retargeting using Sampling-Based Trajectory Optimization](https://arxiv.org/abs/2602.06827)
*Victor Dhedin,Ilyass Taouil,Shafeef Omar,Dian Yu,Kun Tao,Angela Dai,Majid Khadiv*

Main category: cs.RO

TL;DR: DynaRetarget是一个用于将人运动重新定向到人形控制策略的完整流程，其核心是基于采样的轨迹优化框架，能处理长时程任务并泛化到不同对象属性。


<details>
  <summary>Details</summary>
Motivation: 为了解决人形机器人运动重新定向中的动态可行性问题，并克服真实世界数据收集的瓶颈，作者提出了DynaRetarget。

Method: DynaRetarget的核心是一个新颖的基于采样的轨迹优化（SBTO）框架，该框架通过逐步推进优化视野，将不完美的运动学轨迹细化为动态可行的运动。

Result: 实验验证显示，DynaRetarget成功重新定向了数百个人形物体演示，并达到了比现有技术更高的成功率。该框架还能在不同对象属性（如质量、大小和几何形状）上使用相同的跟踪目标进行泛化。

Conclusion: DynaRetarget通过其新颖的SBTO框架，成功实现了人运动到人形控制策略的重新定向，并在多样化的对象属性上表现出良好的泛化能力，为解决真实世界数据收集的瓶颈提供了可能。

Abstract: In this paper, we introduce DynaRetarget, a complete pipeline for retargeting human motions to humanoid control policies. The core component of DynaRetarget is a novel Sampling-Based Trajectory Optimization (SBTO) framework that refines imperfect kinematic trajectories into dynamically feasible motions. SBTO incrementally advances the optimization horizon, enabling optimization over the entire trajectory for long-horizon tasks. We validate DynaRetarget by successfully retargeting hundreds of humanoid-object demonstrations and achieving higher success rates than the state of the art. The framework also generalizes across varying object properties, such as mass, size, and geometry, using the same tracking objective. This ability to robustly retarget diverse demonstrations opens the door to generating large-scale synthetic datasets of humanoid loco-manipulation trajectories, addressing a major bottleneck in real-world data collection.

</details>


### [141] [Perception-Control Coupled Visual Servoing for Textureless Objects Using Keypoint-Based EKF](https://arxiv.org/abs/2602.06834)
*Allen Tao,Jun Yang,Stanko Oparnica,Wenjie Xue*

Main category: cs.RO

TL;DR: 提出闭环视觉伺服方法，结合EKF和概率控制律，提升无纹理物体在恶劣条件下的伺服性能，实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 纹理缺失物体在视觉伺服中缺乏可靠特征，且恶劣视觉条件（如遮挡）会降低精度和稳定性，需开发更鲁棒的方法。

Method: 采用基于学习的无纹理物体关键点检测，结合扩展卡尔曼滤波器（EKF）进行6D位姿估计，驱动基于位姿的视觉伺服（PBVS），并引入概率控制律计算相机速度及其不确定性。

Result: 在真实机器人平台上验证，该方法在精度和实际应用中均优于传统视觉伺服技术。

Conclusion: 本文提出了一种结合感知与控制的闭环视觉伺服方法，通过扩展卡尔曼滤波器和概率控制律，显著提升了纹理缺失物体在恶劣视觉条件下的伺服精度和稳定性。

Abstract: Visual servoing is fundamental to robotic applications, enabling precise positioning and control. However, applying it to textureless objects remains a challenge due to the absence of reliable visual features. Moreover, adverse visual conditions, such as occlusions, often corrupt visual feedback, leading to reduced accuracy and instability in visual servoing. In this work, we build upon learning-based keypoint detection for textureless objects and propose a method that enhances robustness by tightly integrating perception and control in a closed loop. Specifically, we employ an Extended Kalman Filter (EKF) that integrates per-frame keypoint measurements to estimate 6D object pose, which drives pose-based visual servoing (PBVS) for control. The resulting camera motion, in turn, enhances the tracking of subsequent keypoints, effectively closing the perception-control loop. Additionally, unlike standard PBVS, we propose a probabilistic control law that computes both camera velocity and its associated uncertainty, enabling uncertainty-aware control for safe and reliable operation. We validate our approach on real-world robotic platforms using quantitative metrics and grasping experiments, demonstrating that our method outperforms traditional visual servoing techniques in both accuracy and practical application.

</details>


### [142] [SURE: Safe Uncertainty-Aware Robot-Environment Interaction using Trajectory Optimization](https://arxiv.org/abs/2602.06864)
*Zhuocheng Zhang,Haizhou Zhao,Xudong Sun,Aaron M. Johnson,Majid Khadiv*

Main category: cs.RO

TL;DR: SURE是一种考虑接触时间不确定性的鲁棒轨迹优化框架，在倒立摆和抓蛋任务中显著提升成功率。


<details>
  <summary>Details</summary>
Motivation: 接触交互任务中的不连续动力学和传统方法对确定性接触事件的假设限制了鲁棒性和适应性。

Method: 提出SURE框架，允许多条轨迹从可能的预碰撞状态分支并在之后重新汇合到共享轨迹，实现鲁棒性和计算效率的统一。

Result: 在不确定墙壁位置的倒立摆平衡任务中，SURE成功率平均提升21.6%；在机器人抓蛋实验中，成功率提升40%。

Conclusion: SURE框架通过显式考虑接触时间不确定性，显著提升了轨迹优化的鲁棒性，在两种代表性任务中均表现出优于传统方法的性能。

Abstract: Robotic tasks involving contact interactions pose significant challenges for trajectory optimization due to discontinuous dynamics. Conventional formulations typically assume deterministic contact events, which limit robustness and adaptability in real-world settings. In this work, we propose SURE, a robust trajectory optimization framework that explicitly accounts for contact timing uncertainty. By allowing multiple trajectories to branch from possible pre-impact states and later rejoin a shared trajectory, SURE achieves both robustness and computational efficiency within a unified optimization framework. We evaluate SURE on two representative tasks with unknown impact times. In a cart-pole balancing task involving uncertain wall location, SURE achieves an average improvement of 21.6% in success rate when branch switching is enabled during control. In an egg-catching experiment using a robotic manipulator, SURE improves the success rate by 40%. These results demonstrate that SURE substantially enhances robustness compared to conventional nominal formulations.

</details>


### [143] [Consensus-based optimization (CBO): Towards Global Optimality in Robotics](https://arxiv.org/abs/2602.06868)
*Xudong Sun,Armand Jordana,Massimo Fornasier,Jalal Etesami,Majid Khadiv*

Main category: cs.RO

TL;DR: CBO是一种全局优化方法，适用于机器人轨迹优化，在多种挑战性场景中表现优于现有局部方法。


<details>
  <summary>Details</summary>
Motivation: 现有零阶优化方法（如MPPI、CEM、CMA-ES）依赖梯度估计，本质上是局部优化，无法保证全局最优。

Method: 引入共识优化（CBO）方法，并通过理论分析和示例展示其与现有方法的根本差异。

Result: 在三个挑战性轨迹优化场景中，CBO均能实现比现有方法更低的成本。

Conclusion: CBO为机器人轨迹优化提供了一个新的全局优化框架，能够在多种挑战性场景下实现比现有方法更低的成本。

Abstract: Zero-order optimization has recently received significant attention for designing optimal trajectories and policies for robotic systems. However, most existing methods (e.g., MPPI, CEM, and CMA-ES) are local in nature, as they rely on gradient estimation. In this paper, we introduce consensus-based optimization (CBO) to robotics, which is guaranteed to converge to a global optimum under mild assumptions. We provide theoretical analysis and illustrative examples that give intuition into the fundamental differences between CBO and existing methods. To demonstrate the scalability of CBO for robotics problems, we consider three challenging trajectory optimization scenarios: (1) a long-horizon problem for a simple system, (2) a dynamic balance problem for a highly underactuated system, and (3) a high-dimensional problem with only a terminal cost. Our results show that CBO is able to achieve lower costs with respect to existing methods on all three challenging settings. This opens a new framework to study global trajectory optimization in robotics.

</details>


### [144] [Strategizing at Speed: A Learned Model Predictive Game for Multi-Agent Drone Racing](https://arxiv.org/abs/2602.06925)
*Andrei-Carlo Papuc,Lasse Peters,Sihao Sun,Laura Ferranti,Javier Alonso-Mora*

Main category: cs.RO

TL;DR: LMPG方法通过减少计算延迟，在高速度无人机竞速中优于MPG和MPC。


<details>
  <summary>Details</summary>
Motivation: 研究无人机竞速中策略规划的深度问题，即在高速度和多智能体交互环境下，如何平衡策略复杂性和计算效率。

Method: 通过比较MPG（Model Predictive Game）和MPC（Model Predictive Control）两种规划范式，提出LMPG方法，利用学习技术减少计算延迟。

Result: 实验表明，MPG在中等速度下优于MPC，但在高速度下因延迟失去优势；LMPG在仿真和硬件实验中均超越两者。

Conclusion: LMPG（Learned Model Predictive Game）方法通过减少延迟，在高速度下超越了MPG和MPC，成为无人机竞速中更优的策略规划方法。

Abstract: Autonomous drone racing pushes the boundaries of high-speed motion planning and multi-agent strategic decision-making. Success in this domain requires drones not only to navigate at their limits but also to anticipate and counteract competitors' actions. In this paper, we study a fundamental question that arises in this domain: how deeply should an agent strategize before taking an action? To this end, we compare two planning paradigms: the Model Predictive Game (MPG), which finds interaction-aware strategies at the expense of longer computation times, and contouring Model Predictive Control (MPC), which computes strategies rapidly but does not reason about interactions. We perform extensive experiments to study this trade-off, revealing that MPG outperforms MPC at moderate velocities but loses its advantage at higher speeds due to latency. To address this shortcoming, we propose a Learned Model Predictive Game (LMPG) approach that amortizes model predictive gameplay to reduce latency. In both simulation and hardware experiments, we benchmark our approach against MPG and MPC in head-to-head races, finding that LMPG outperforms both baselines.

</details>


### [145] [DreamDojo: A Generalist Robot World Model from Large-Scale Human Videos](https://arxiv.org/abs/2602.06949)
*Shenyuan Gao,William Liang,Kaiyuan Zheng,Ayaan Malik,Seonghyeon Ye,Sihyun Yu,Wei-Cheng Tseng,Yuzhu Dong,Kaichun Mo,Chen-Hsuan Lin,Qianli Ma,Seungjun Nah,Loic Magne,Jiannan Xiang,Yuqi Xie,Ruijie Zheng,Dantong Niu,You Liang Tan,K. R. Zentner,George Kurian,Suneel Indupuru,Pooya Jannaty,Jinwei Gu,Jun Zhang,Jitendra Malik,Pieter Abbeel,Ming-Yu Liu,Yuke Zhu,Joel Jang,Linxi "Jim" Fan*

Main category: cs.RO

TL;DR: DreamDojo利用44k小时人类视频预训练世界模型，通过连续潜在动作解决标签稀缺问题，微调后实现高效物理模拟和实时控制，适用于开放世界任务。


<details>
  <summary>Details</summary>
Motivation: 模拟多样化环境中的动作结果对通用智能体开发至关重要，但灵巧机器人任务的世界动力学建模面临数据覆盖有限和动作标签稀缺的挑战。

Method: 提出DreamDojo基础世界模型，利用44k小时的人类第一视角视频学习多样交互和灵巧控制，并通过连续潜在动作解决动作标签稀缺问题。后通过小规模目标机器人数据微调，并设计蒸馏流程加速至实时速度。

Result: DreamDojo展现出对物理的深刻理解和精确动作可控性，在多个OOD基准测试中验证了其方法的有效性，支持实时遥操作、策略评估和基于模型的规划等应用。

Conclusion: DreamDojo通过大规模视频数据预训练和连续潜在动作的引入，显著提升了世界模型在开放世界、接触密集型任务中的模拟能力，为通用机器人世界模型的发展铺平了道路。

Abstract: Being able to simulate the outcomes of actions in varied environments will revolutionize the development of generalist agents at scale. However, modeling these world dynamics, especially for dexterous robotics tasks, poses significant challenges due to limited data coverage and scarce action labels. As an endeavor towards this end, we introduce DreamDojo, a foundation world model that learns diverse interactions and dexterous controls from 44k hours of egocentric human videos. Our data mixture represents the largest video dataset to date for world model pretraining, spanning a wide range of daily scenarios with diverse objects and skills. To address the scarcity of action labels, we introduce continuous latent actions as unified proxy actions, enhancing interaction knowledge transfer from unlabeled videos. After post-training on small-scale target robot data, DreamDojo demonstrates a strong understanding of physics and precise action controllability. We also devise a distillation pipeline that accelerates DreamDojo to a real-time speed of 10.81 FPS and further improves context consistency. Our work enables several important applications based on generative world models, including live teleoperation, policy evaluation, and model-based planning. Systematic evaluation on multiple challenging out-of-distribution (OOD) benchmarks verifies the significance of our method for simulating open-world, contact-rich tasks, paving the way for general-purpose robot world models.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [146] [SVRepair: Structured Visual Reasoning for Automated Program Repair](https://arxiv.org/abs/2602.06090)
*Xiaoxuan Tang,Jincheng Wang,Liwei Luo,Jingxuan Xu,Sheng Zhou,Dajun Chen,Wei Jiang,Yong Li*

Main category: cs.SE

TL;DR: SVRepair是一个多模态自动程序修复框架，通过结构化视觉表示和迭代分割策略，显著提升了修复性能，在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有的自动程序修复方法多为单模态，未能充分利用视觉工件中的丰富诊断信号。许多错误报告通过视觉方式传达关键信息（如布局断裂或缺失部件），但直接使用这些密集视觉输入常导致上下文丢失和噪声，使得多模态语言模型难以将视觉观察精确地定位到故障并生成可执行补丁。

Method: SVRepair首先微调了一个视觉语言模型（SVR），将异构视觉工件统一转换为语义场景图，捕捉GUI元素及其结构关系。然后基于该图驱动编码代理进行故障定位和补丁合成，并引入迭代式视觉工件分割策略，逐步缩小输入范围以减少无关上下文和幻觉。

Result: SVRepair在多个基准测试中表现优异：在SWE-Bench M上达到36.47%的准确率，在MMCode上达到38.02%，在CodeVision上达到95.12%。

Conclusion: SVRepair通过结构化视觉表示和多模态方法，显著提升了自动程序修复的性能，在多个基准测试中达到了最先进的水平。

Abstract: Large language models (LLMs) have recently shown strong potential for Automated Program Repair (APR), yet most existing approaches remain unimodal and fail to leverage the rich diagnostic signals contained in visual artifacts such as screenshots and control-flow graphs. In practice, many bug reports convey critical information visually (e.g., layout breakage or missing widgets), but directly using such dense visual inputs often causes context loss and noise, making it difficult for MLLMs to ground visual observations into precise fault localization and executable patches. To bridge this semantic gap, we propose \textbf{SVRepair}, a multimodal APR framework with structured visual representation. SVRepair first fine-tunes a vision-language model, \textbf{Structured Visual Representation (SVR)}, to uniformly transform heterogeneous visual artifacts into a \emph{semantic scene graph} that captures GUI elements and their structural relations (e.g., hierarchy), providing normalized, code-relevant context for downstream repair. Building on the graph, SVRepair drives a coding agent to localize faults and synthesize patches, and further introduces an iterative visual-artifact segmentation strategy that progressively narrows the input to bug-centered regions to suppress irrelevant context and reduce hallucinations. Extensive experiments across multiple benchmarks demonstrate state-of-the-art performance: SVRepair achieves \textbf{36.47\%} accuracy on SWE-Bench M, \textbf{38.02\%} on MMCode, and \textbf{95.12\%} on CodeVision, validating the effectiveness of SVRepair for multimodal program repair.

</details>


### [147] [Coding Agents with Environment Interaction: A Theoretical Perspective](https://arxiv.org/abs/2602.06098)
*Nicolas Menet,Michael Hersche,Andreas Krause,Abbas Rahimi*

Main category: cs.SE

TL;DR: 本文通过概率框架分析了代码生成代理的环境交互策略，证明了模糊功能相似性估计器的优势，并揭示了反向提示的局限性，提出了改进任务描述的方法。


<details>
  <summary>Details</summary>
Motivation: 探索代码生成代理在测试驱动开发中与环境交互策略的理论机制，填补当前研究的空白。

Method: 首先将几种常见的代码选择启发式方法形式化为环境感知的代码正确性估计器，并从理论上证明了基于模糊功能相似性的估计器在信噪比上严格优于基于功能等价性的估计器。其次，将反向提示建模为Thompson采样的上下文近似，并推导了具有不可观测组件的奖励函数的遗憾界。

Result: 通过理论分析和实验验证，证明了模糊功能相似性估计器的优越性，并揭示了反向提示的局限性。同时提出了改进任务描述的方法，并创建了新基准QiskitHumanEvalSimX。

Conclusion: 本文提出了一个概率框架，用于分析代码生成代理在测试驱动开发中的环境交互策略，并通过理论证明和实验验证了模糊功能相似性估计器的优势以及反向提示的局限性。

Abstract: Coding agents are increasingly utilized in test-driven software development, yet the theoretical mechanisms behind their environment-interaction strategies remain underexplored. We provide a probabilistic framework for two dominant paradigms: code selection after generation using the execution environment, and code generation conditioned on environment feedback. First, we formalize several well-established selection heuristics as environment-aware estimators of code correctness. We theoretically prove that estimators based on fuzzy functional similarity add an inductive bias and strictly dominate estimators based on functional equivalence in terms of signal-to-noise ratio. Second, we frame backprompting as an in-context approximation of Thompson sampling. We derive a novel regret bound for reward functions with unobservable components, theoretically explaining why the effectiveness of backprompting is limited by the ambiguity of the informal task description (an irreducible regret). Using three state-of-the-art open weight models, we corroborate these findings across BigCodeBenchHard, LeetCodeDataset, and QiskitHumanEvalSim. Our formalization also suggests how to improve task descriptions effectively, leading to a new benchmark, QiskitHumanEvalSimX.

</details>


### [148] [Scaling Mobile Chaos Testing with AI-Driven Test Execution](https://arxiv.org/abs/2602.06223)
*Juan Marcano,Ashish Samant,Kai Song,Lingchao Chen,Kaelan Mikowicz,Tim Smyth,Mengdie Zhang,Ali Zamani,Arturo Bravo Rovirosa,Sowjanya Puligadda,Srikanth Prodduturi,Mayank Bansal*

Main category: cs.SE

TL;DR: AI驱动的移动混沌测试系统结合DragonCrawl和uHavoc，自动化验证移动应用韧性，显著提升测试效率并识别关键风险。


<details>
  <summary>Details</summary>
Motivation: 传统混沌工程方法因用户流程、地理位置和故障场景的组合爆炸而无法扩展移动测试，需解决大规模移动应用韧性验证的挑战。

Method: 结合DragonCrawl（基于LLM的移动测试平台）和uHavoc（服务级故障注入系统），实现自适应AI驱动的测试执行，无需手动编写每种用户流程、城市和故障类型的测试用例。

Result: 自2024年Q1以来，系统在Uber的Rider、Driver和Eats应用中执行了超过18万次自动化混沌测试，识别了23个韧性风险，其中70%为架构依赖违规问题。自动根因分析将调试时间从小时缩短至分钟，精度@5达到88%。

Conclusion: 自动化移动混沌测试系统通过AI驱动的测试执行，显著提升了大规模分布式系统中移动应用的韧性验证效率，证明了在生产规模下持续验证移动应用韧性的可行性。

Abstract: Mobile applications in large-scale distributed systems are susceptible to backend service failures, yet traditional chaos engineering approaches cannot scale mobile testing due to the combinatorial explosion of flows, locations, and failure scenarios that need validation. We present an automated mobile chaos testing system that integrates DragonCrawl, an LLM-based mobile testing platform, with uHavoc, a service-level fault injection system. The key insight is that adaptive AI-driven test execution can navigate mobile applications under degraded backend conditions, eliminating the need to manually write test cases for each combination of user flow, city, and failure type. Since Q1 2024, our system has executed over 180,000 automated chaos tests across 47 critical flows in Uber's Rider, Driver, and Eats applications, representing approximately 39,000 hours of manual testing effort that would be impractical at this scale. We identified 23 resilience risks, with 70% being architectural dependency violations where non-critical service failures degraded core user flows. Twelve issues were severe enough to prevent trip requests or food orders. Two caused application crashes detectable only through mobile chaos testing, not backend testing alone. Automated root cause analysis reduced debugging time from hours to minutes, achieving 88% precision@5 in attributing mobile failures to specific backend services. This paper presents the system design, evaluates its performance under fault injection (maintaining 99% test reliability), and reports operational experience demonstrating that continuous mobile resilience validation is achievable at production scale.

</details>


### [149] [Trustworthy AI Software Engineers](https://arxiv.org/abs/2602.06310)
*Aldeida Aleti,Baishakhi Ray,Rashina Hoda,Simin Chen*

Main category: cs.SE

TL;DR: 论文探讨了AI软件工程师的可信赖性，提出了影响可信度的关键维度，并倡导在设计AI系统时采用伦理设计方法。


<details>
  <summary>Details</summary>
Motivation: 随着AI编码代理的迅速崛起，软件工程师的基本前提受到质疑，需要重新思考AI代理作为软件工程师的意义及其可信赖性。

Method: 基于软件工程（SE）的既定定义和近期关于代理AI系统的研究，将AI软件工程师概念化为人类-AI SE团队的参与者，并区分信任作为这些系统和行为者的关键属性。

Result: 识别了影响AI软件工程师可信度的关键维度，包括技术质量、透明度和责任、认知谦逊以及社会和伦理对齐，并讨论了如何评估和展示可信度。

Conclusion: 论文主张在设计、评估和治理AI软件工程系统时采用‘设计伦理’方法，以促进未来人机协作团队中的适当信任。

Abstract: With the rapid rise of AI coding agents, the fundamental premise of what it means to be a software engineer is in question. In this vision paper, we re-examine what it means for an AI agent to be considered a software engineer and then critically think about what makes such an agent trustworthy. \textit{Grounded} in established definitions of software engineering (SE) and informed by recent research on agentic AI systems, we conceptualise AI software engineers as participants in human-AI SE teams composed of human software engineers and AI models and tools, and we distinguish trustworthiness as a key property of these systems and actors rather than a subjective human attitude. Based on historical perspectives and emerging visions, we identify key dimensions that contribute to the trustworthiness of AI software engineers, spanning technical quality, transparency and accountability, epistemic humility, and societal and ethical alignment. We further discuss how trustworthiness can be evaluated and demonstrated, highlighting a fundamental trust measurement gap: not everything that matters for trust can be easily measured. Finally, we outline implications for the design, evaluation, and governance of AI SE systems, advocating for an ethics-by-design approach to enable appropriate trust in future human-AI SE teams.

</details>


### [150] [AgentStepper: Interactive Debugging of Software Development Agents](https://arxiv.org/abs/2602.06593)
*Robert Hutter,Michael Pradel*

Main category: cs.SE

TL;DR: AgentStepper是首个针对基于LLM的软件工程代理的交互式调试工具，通过结构化对话表示轨迹，支持断点、逐步执行等功能，显著提升调试效率和用户体验。


<details>
  <summary>Details</summary>
Motivation: 理解并调试基于LLM的软件工程代理具有挑战性，现有技术难以以可理解的形式展示中间过程。

Method: 通过将代理轨迹表示为结构化对话，支持断点、逐步执行、实时编辑提示和工具调用，同时捕获并显示中间代码变更。

Result: 在三种先进软件代理（ExecutionAgent、SWE-Agent、RepairAgent）上的评估显示，集成AgentStepper仅需少量代码修改（39-42行）。用户研究表明，使用AgentStepper提升了轨迹解释能力（64% vs. 67%）和错误识别成功率（17% vs. 60%），同时降低了感知工作量（如挫败感从5.4/7.0降至2.4/7.0）。

Conclusion: AgentStepper作为一种交互式调试工具，显著提升了开发者对基于LLM的软件工程代理的理解和调试能力，减少了感知工作量，并在用户研究中显示出较高的效率和成功率。

Abstract: Software development agents powered by large language models (LLMs) have shown great promise in automating tasks like environment setup, issue solving, and program repair. Unfortunately, understanding and debugging such agents remain challenging due to their complex and dynamic nature. Developers must reason about trajectories of LLM queries, tool calls, and code modifications, but current techniques reveal little of this intermediate process in a comprehensible format. The key insight of this paper is that debugging software development agents shares many similarities with conventional debugging of software programs, yet requires a higher level of abstraction that raises the level from low-level implementation details to high-level agent actions. Drawing on this insight, we introduce AgentStepper, the first interactive debugger for LLM-based software engineering agents. AgentStepper enables developers to inspect, control, and interactively manipulate agent trajectories. AgentStepper represents trajectories as structured conversations among an LLM, the agent program, and tools. It supports breakpoints, stepwise execution, and live editing of prompts and tool invocations, while capturing and displaying intermediate repository-level code changes. Our evaluation applies AgentStepper to three state-of-the-art software development agents, ExecutionAgent, SWE-Agent, and RepairAgent, showing that integrating the approach into existing agents requires minor code changes (39-42 edited lines). Moreover, we report on a user study with twelve participants, indicating that AgentStepper improves the ability of participants to interpret trajectories (64% vs. 67% mean performance) and identify bugs in the agent's implementation (17% vs. 60% success rate), while reducing perceived workload (e.g., frustration reduced from 5.4/7.0 to 2.4/7.0) compared to conventional tools.

</details>


### [151] [Code vs Serialized AST Inputs for LLM-Based Code Summarization: An Empirical Study](https://arxiv.org/abs/2602.06671)
*Shijia Dong,Haoruo Zhao,Paul Harvey*

Main category: cs.SE

TL;DR: AST(NIT)通过序列化完整AST提升LLM代码摘要效率和质量。


<details>
  <summary>Details</summary>
Motivation: 探索完整AST表示在LLM中的潜力，以提升代码摘要质量。

Method: 提出AST(NIT)，一种AST增强和序列化方法，将完整AST表示转化为LLM兼容序列。

Result: 实验显示，序列化AST减少了LLM输入长度、缩短训练时间，并达到与现有方法相当的摘要质量。

Conclusion: AST(NIT)方法通过保留词汇细节并将结构信息编码为LLM兼容序列，显著提升了代码摘要的质量和效率。

Abstract: Summarizing source code into natural language descriptions (code summarization) helps developers better understand program functionality and reduce the burden of software maintenance. Abstract Syntax Trees (ASTs), as opposed to source code, have been shown to improve summarization quality in traditional encoder-decoder-based code summarization models. However, most large language model (LLM)-based code summarization methods rely on raw code or only incorporate partial AST signals, meaning that the potential of complete AST representation has not been fully explored for LLMs. This paper presents AST(NIT), an AST augmentation and serialization method that preserves lexical details and encodes structural information into LLM-compatible sequences. Experiments with the LLaMA-3.1-8B model on the CodeXGLUE Python dataset show that the proposed serialized ASTs reduce the length of LLM inputs, require shorter training times, and achieve summarization quality comparable to existing approaches.

</details>


### [152] [Using Large Language Models to Support Automation of Failure Management in CI/CD Pipelines: A Case Study in SAP HANA](https://arxiv.org/abs/2602.06709)
*Duong Bui,Stefan Grintz,Alexander Berndt,Thomas Bach*

Main category: cs.SE

TL;DR: LLMs结合历史故障数据可高效自动化CI/CD管道故障管理，准确率高达97.4%。


<details>
  <summary>Details</summary>
Motivation: 手动进行CI/CD管道故障管理耗时且低效，传统程序无法自动处理所需的无结构信息。LLMs在处理无结构数据方面显示出潜力，因此研究其在自动化故障管理中的应用。

Method: 评估了基于LLM的系统在大型工业软件项目（SAP HANA）中自动化故障管理的能力，包括错误定位和提供精确解决方案。通过提供不同类型的领域知识（如管道信息、故障管理指令和历史故障数据）支持LLM生成精确解决方案，并进行了消融研究以确定哪种领域知识对解决方案准确性贡献最大。

Result: 历史故障数据对系统准确性贡献最大，使其在数据集中92.1%的情况下生成精确解决方案。在提供领域知识的情况下，系统正确识别错误位置的准确率为97.4%，而无领域知识时为84.2%。

Conclusion: 研究发现，当提供历史故障数据时，LLMs代表了一种有前景的自动化CI/CD管道故障管理方法。

Abstract: CI/CD pipeline failure management is time-consuming when performed manually. Automating this process is non-trivial because the information required for effective failure management is unstructured and cannot be automatically processed by traditional programs. With their ability to process unstructured data, large language models (LLMs) have shown promising results for automated failure management by previous work. Following these studies, we evaluated whether an LLM-based system could automate failure management in a CI/CD pipeline in the context of a large industrial software project, namely SAP HANA. We evaluated the ability of the LLM-based system to identify the error location and to propose exact solutions that contain no unnecessary actions. To support the LLM in generating exact solutions, we provided it with different types of domain knowledge, including pipeline information, failure management instructions, and data from historical failures. We conducted an ablation study to determine which type of domain knowledge contributed most to solution accuracy. The results show that data from historical failures contributed the most to the system's accuracy, enabling it to produce exact solutions in 92.1% of cases in our dataset. The system correctly identified the error location with 97.4% accuracy when provided with domain knowledge, compared to 84.2% accuracy without it. In conclusion, our findings indicate that LLMs, when provided with data from historical failures, represent a promising approach for automating CI/CD pipeline failure management.

</details>


### [153] [Statistical-Based Metric Threshold Setting Method for Software Fault Prediction in Firmware Projects: An Industrial Experience](https://arxiv.org/abs/2602.06831)
*Marco De Luca,Domenico Amalfitano,Anna Rita Fasolino,Porfirio Tramontana*

Main category: cs.SE

TL;DR: 提出了一种可解释的软件度量阈值方法，用于工业环境中的故障预测，替代黑盒AI模型，支持跨项目重用。


<details>
  <summary>Details</summary>
Motivation: 机器学习故障预测模型虽然准确度高，但缺乏可解释性，限制了其在工业环境中的应用。开发者需要可直接用于软件质量保证过程的可操作见解。

Method: 通过统计分析和假设检验，从三个真实世界的C嵌入式固件项目中提取软件度量，并识别区分故障与非故障函数的判别性度量及经验阈值。

Result: 实验验证表明，导出的阈值能有效识别故障倾向函数，具有高精度，符合行业标准和SQA实践。

Conclusion: 本文提出了一种基于软件度量阈值的可解释性故障预测方法，为工业环境中的软件质量保证提供了实用替代方案，支持开发者系统性评估软件质量并集成到开发流程中。

Abstract: Ensuring software quality in embedded firmware is critical, especially in safety-critical domains where compliance with functional safety standards (ISO 26262) requires strong guarantees of software reliability. While machine learning-based fault prediction models have demonstrated high accuracy, their lack of interpretability limits their adoption in industrial settings. Developers need actionable insights that can be directly employed in software quality assurance processes and guide defect mitigation strategies. In this paper, we present a structured process for defining context-specific software metric thresholds suitable for integration into fault detection workflows in industrial settings. Our approach supports cross-project fault prediction by deriving thresholds from one set of projects and applying them to independently developed firmware, thereby enabling reuse across similar software systems without retraining or domain-specific tuning. We analyze three real-world C-embedded firmware projects provided by an industrial partner, using Coverity and Understand static analysis tools to extract software metrics. Through statistical analysis and hypothesis testing, we identify discriminative metrics and derived empirical threshold values capable of distinguishing faulty from non-faulty functions. The derived thresholds are validated through an experimental evaluation, demonstrating their effectiveness in identifying fault-prone functions with high precision. The results confirm that the derived thresholds can serve as an interpretable solution for fault prediction, aligning with industry standards and SQA practices. This approach provides a practical alternative to black-box AI models, allowing developers to systematically assess software quality, take preventive actions, and integrate metric-based fault prediction into industrial development workflows to mitigate software faults.

</details>


### [154] [TraceCoder: A Trace-Driven Multi-Agent Framework for Automated Debugging of LLM-Generated Code](https://arxiv.org/abs/2602.06875)
*Jiangping Huang,Wenguang Ye,Weisong Sun,Jian Zhang,Mingyue Zhang,Yang Liu*

Main category: cs.SE

TL;DR: TraceCoder是一个多代理框架，通过运行时跟踪和因果分析提升代码修复准确性，结合历史学习机制避免重复错误，实验显示其显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有自动修复方法依赖浅层的通过/失败信号，缺乏对程序行为的深入洞察，且无法从历史失败中学习，导致修复过程低效重复。

Method: TraceCoder采用诊断探针捕获运行时跟踪，进行因果分析，并结合HLLM机制从历史失败中学习，通过回滚机制确保每次修复迭代的严格改进。

Result: TraceCoder在多个基准测试中实现了Pass@1准确率相对提升34.43%，迭代修复过程单独贡献了65.61%的相对增益。

Conclusion: TraceCoder通过其多代理协作框架和HLLM机制，显著提升了代码修复的准确性和效率，超越了现有先进基线。

Abstract: Large Language Models (LLMs) often generate code with subtle but critical bugs, especially for complex tasks. Existing automated repair methods typically rely on superficial pass/fail signals, offering limited visibility into program behavior and hindering precise error localization. In addition, without a way to learn from prior failures, repair processes often fall into repetitive and inefficient cycles. To overcome these challenges, we present TraceCoder, a collaborative multi-agent framework that emulates the observe-analyze-repair process of human experts. The framework first instruments the code with diagnostic probes to capture fine-grained runtime traces, enabling deep insight into its internal execution. It then conducts causal analysis on these traces to accurately identify the root cause of the failure. This process is further enhanced by a novel Historical Lesson Learning Mechanism (HLLM), which distills insights from prior failed repair attempts to inform subsequent correction strategies and prevent recurrence of similar mistakes. To ensure stable convergence, a Rollback Mechanism enforces that each repair iteration constitutes a strict improvement toward the correct solution. Comprehensive experiments across multiple benchmarks show that TraceCoder achieves up to a 34.43\% relative improvement in Pass@1 accuracy over existing advanced baselines. Ablation studies verify the significance of each system component, with the iterative repair process alone contributing a 65.61\% relative gain in accuracy. Furthermore, TraceCoder significantly outperforms leading iterative methods in terms of both accuracy and cost-efficiency.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [155] [IE-RAP: An Intelligence and Efficient Reader Anti-Collision Protocol for Dense RFID Networks](https://arxiv.org/abs/2602.06626)
*Hadiseh Rezaei,Rahim Taheri,Mohammad Shojafar*

Main category: cs.NI

TL;DR: IE-RAP协议结合TDMA和FDMA，显著提升RFID网络性能，减少碰撞，支持移动阅读器。


<details>
  <summary>Details</summary>
Motivation: 密集阅读器环境中，阅读器与标签之间的碰撞问题导致网络性能下降，需高效抗碰撞协议以提升性能。

Method: 采用TDMA和FDMA机制，结合SIFT函数和阅读器间距离计算技术，避免重读标签并确保通信信道的及时释放。

Result: 仿真结果显示，IE-RAP相比现有方法提升26%吞吐量，减少74%平均等待时间，降低52%能耗。

Conclusion: IE-RAP协议通过结合TDMA和FDMA机制，显著提升了RFID网络的性能，包括吞吐量、平均等待时间和能耗，同时支持移动阅读器的无缝集成。

Abstract: An advanced technology known as a radio frequency identification (RFID) system enables seamless wireless communication between tags and readers. This system operates in what is referred to as a dense reader environment, where readers are placed close to each other to optimize coverage. However, this setup comes with its challenges, as it increases the likelihood of collisions between readers and tags (reader-to-reader and reader-to-tag), leading to reduced network performance. To address this issue, various protocols have been proposed, with centralized solutions emerging as promising options due to their ability to deliver higher throughput. In this paper, we propose the Intelligence and Efficient Reader Anti-collision Protocol (IE-RAP) that improves network performance such as throughput, average waiting time, and energy consumption, which employs a powerful combination of Time Division Multiple Access (TDMA) and Frequency Division Multiple Access (FDMA) mechanisms. IE-RAP improves the efficiency of RFID networks through techniques such as the SIFT function and distance calculation between readers. By preventing re-read tags and ensuring the on-time release of the communication channel, we effectively eliminate unnecessary collisions. Our simulations emphasize the superiority of our proposed method, it increases 26% throughput, reduces 74% the average waiting time, and lower by 52% the energy consumption compared to existing approaches. Importantly, our solution supports the seamless integration of mobile readers within the network.

</details>


### [156] [Talk Like a Packet: Rethinking Network Traffic Analysis with Transformer Foundation Models](https://arxiv.org/abs/2602.06636)
*Samara Mayhoub,Chuan Heng Foh,Mahdi Boloursaz Mashhadi,Mohammad Shojafar,Rahim Tafazolli*

Main category: cs.NI

TL;DR: 本文提出基于Transformer的交通基础模型，通过统一预训练和微调流程，在多种下游任务中表现优异，展示了其在智能网络分析中的潜力。


<details>
  <summary>Details</summary>
Motivation: 受Transformer模型在自然语言处理中的成功启发，探索其作为网络流量分析基础模型的潜力。

Method: 提出了一种统一的预训练和微调流程，用于构建交通基础模型，并通过微调验证其在多种下游任务中的表现。

Result: 交通基础模型在流量分类、流量特征预测和流量生成等任务中表现优于非基础模型，且能在有限标注数据下有效学习流量表示。

Conclusion: 交通基础模型通过统一预训练和微调流程，展现出在下游任务中的广泛适用性和优越性能，为未来智能网络分析系统提供了潜力。

Abstract: Inspired by the success of Transformer-based models in natural language processing, this paper investigates their potential as foundation models for network traffic analysis. We propose a unified pre-training and fine-tuning pipeline for traffic foundation models. Through fine-tuning, we demonstrate the generalizability of the traffic foundation models in various downstream tasks, including traffic classification, traffic characteristic prediction, and traffic generation. We also compare against non-foundation baselines, demonstrating that the foundation-model backbones achieve improved performance. Moreover, we categorize existing models based on their architecture, input modality, and pre-training strategy. Our findings show that these models can effectively learn traffic representations and perform well with limited labeled datasets, highlighting their potential in future intelligent network analysis systems.

</details>


### [157] [Makespan Minimization in Split Learning: From Theory to Practice](https://arxiv.org/abs/2602.06693)
*Robert Ganian,Fionn Mc Inerney,Dimitra Tsigkari*

Main category: cs.NI

TL;DR: 论文研究了分割学习中的客户端-助手分配和任务调度问题，提出了一种5-近似算法和新的启发式算法，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决分布式机器学习中异构物联网设备的分割学习问题，通过优化客户端-助手分配和任务调度来最小化训练时间。

Method: 通过复杂性理论分析，排除了多项式时间精确算法和近似方案的可能性，并提出了一种非平凡的多项式时间5-近似算法。在此基础上，针对异构任务设置，开发了一种新的启发式算法。

Result: 证明了在异构任务设置下，除非P=NP，否则问题无法具有任何近似因子的多项式时间近似算法。提出的启发式算法在实验中表现优于现有方法。

Conclusion: 该论文提出了一种针对异构任务设置的启发式算法，并通过实验证明其优于现有方法。

Abstract: Split learning recently emerged as a solution for distributed machine learning with heterogeneous IoT devices, where clients can offload part of their training to computationally-powerful helpers. The core challenge in split learning is to minimize the training time by jointly devising the client-helper assignment and the schedule of tasks at the helpers. We first study the model where each helper has a memory cardinality constraint on how many clients it may be assigned, which represents the case of homogeneous tasks. Through complexity theory, we rule out exact polynomial-time algorithms and approximation schemes even for highly restricted instances of this problem. We complement these negative results with a non-trivial polynomial-time 5-approximation algorithm. Building on this, we then focus on the more general heterogeneous task setting considered by Tirana et al. [INFOCOM 2024], where helpers have memory capacity constraints and clients have variable memory costs. In this case, we prove that, unless P=NP, the problem cannot admit a polynomial-time approximation algorithm for any approximation factor. However, by adapting our aforementioned 5-approximation algorithm, we develop a novel heuristic for the heterogeneous task setting and show that it outperforms heuristics from prior works through extensive experiments.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [158] [Quantifying Energy-Efficient Edge Intelligence: Inference-time Scaling Laws for Heterogeneous Computing](https://arxiv.org/abs/2602.06057)
*Satyam Kumar,Saurabh Jha*

Main category: cs.DC

TL;DR: QEIL框架通过异构编排和优化维度，显著提升边缘设备上LLM推理的效率，降低能耗和延迟。


<details>
  <summary>Details</summary>
Motivation: 解决资源受限边缘设备上大语言模型推理的延迟问题，摆脱对云或数据中心基础设施的依赖。

Method: QEIL框架通过异构编排（CPU、GPU、NPU加速器）和三个优化维度（异构工作负载分配、硬件感知路由、性能-能耗权衡量化）实现高效本地LLM推理。

Result: 在五个模型家族（125M至2.6B参数）上的评估显示：通过率提升7-10.5个百分点，能耗降低35.6-78.2%，平均功耗降低68%，延迟改善15.8%，且无精度损失。

Conclusion: 研究证实，推理时间缩放定律具有普适性且与架构无关，确立了异构边缘编排作为能源受限智能系统的最佳策略。

Abstract: Large language model inference on resource constrained edge devices remains a major challenge for low latency intelligent systems, as existing solutions depend heavily on cloud or datacenter infrastructure. This work introduces QEIL, Quantifying Edge Intelligence via Inference time Scaling Laws, a unified framework for efficient local LLM inference using principled scaling laws and heterogeneous orchestration across CPU, GPU, and NPU accelerators. We derive five architecture agnostic theorems that characterize how inference efficiency scales with model size, sample budget, and device level constraints. QEIL integrates three optimization dimensions. First, inference time scaling laws show that heterogeneous workload distribution achieves superlinear efficiency gains that are not observed in homogeneous execution. Second, hardware aware routing is enabled through analytical cost models that account for compute throughput, memory bandwidth, power consumption, and thermal limits. Third, performance energy trade offs are quantified using novel metrics including Intelligence Per Watt, Energy Coverage Efficiency, and Price Power Performance. A unified orchestrator combines these components through progressive sample multiplexing to improve coverage. Extensive evaluation across five model families from 125M to 2.6B parameters demonstrates consistent gains, including 7 to 10.5 percentage point improvement in pass at k coverage, 35.6 to 78.2 percent energy reduction, 68 percent average power reduction enabling edge thermal budgets, 15.8 percent latency improvement, and zero accuracy loss. Results confirm that inference time scaling laws are universal and architecture agnostic, establishing heterogeneous edge orchestration as the optimal strategy for energy constrained intelligent systems.

</details>


### [159] [Mapping Gemma3 onto an Edge Dataflow Architecture](https://arxiv.org/abs/2602.06063)
*Shouyu Du,Miaoxiang Yu,Zhiheng Ni,Jillian Cai,Qing Yang,Tao Wei,Zhenyu Xu*

Main category: cs.DC

TL;DR: The paper presents efficient hardware-aware techniques for deploying Gemma3 models on AMD Ryzen AI NPU, achieving significant speed and power efficiency gains over iGPU and CPU.


<details>
  <summary>Details</summary>
Motivation: The motivation is to enhance the efficiency and performance of large language and vision models on tiled edge dataflow architectures, addressing the limitations of existing iGPU and CPU implementations.

Method: The paper introduces hardware-aware techniques including an efficient dequantization engine, optimized tiled matrix multiplication kernels, FlowQKV for prefill, and FusedDQP and FlowKV for decoding, alongside a compact Q4NX 4-bit quantization format.

Result: The proposed methods achieve up to 5.2× faster prefill and 4.8× faster decoding versus the iGPU, and 33.5× and 2.2× over the CPU, with power efficiency improvements of 67.2× and 222.9× compared to the iGPU and CPU, respectively.

Conclusion: The study demonstrates that modern NPUs can enable practical, low-power LLM and VLM inference at the edge, offering a scalable approach for deploying transformer-based models on tiled dataflow accelerators.

Abstract: We present the first end-to-end deployment of the Gemma3 family of large language and vision models on a tiled edge dataflow architecture (AMD Ryzen AI NPU). Our work introduces a set of hardware-aware techniques. For prefill, we introduce an efficient dequantization engine, optimize tiled matrix multiplication kernels, and propose FlowQKV, a chunked, pipelined attention mechanism. For decoding, we introduce FusedDQP, which fuses dequantization and projection into a single kernel, and FlowKV, which re-structures attention to sustain high memory bandwidth utilization. Together with a compact Q4NX 4-bit quantization format, these methods yield up to $5.2\times$ faster prefill and $4.8\times$ faster decoding versus the iGPU, and $33.5\times$ and $2.2\times$ over the CPU, respectively. Power efficiency improves by as much as $67.2\times$ and $222.9\times$ compared to the iGPU and CPU. The proposed approach demonstrates that modern NPUs can deliver practical, low-power LLM and VLM inference at the edge, and provides a generalizable blueprint for mapping transformer-based models onto tiled dataflow accelerators.

</details>


### [160] [iScheduler: Reinforcement Learning-Driven Continual Optimization for Large-Scale Resource Investment Problems](https://arxiv.org/abs/2602.06064)
*Yi-Xiang Hu,Yuke Wang,Feng Wu,Zirui Huang,Shuli Zeng,Xiang-Yang Li*

Main category: cs.DC

TL;DR: iScheduler是一个基于强化学习的调度框架，显著提升大规模任务调度的效率，并支持动态更新。


<details>
  <summary>Details</summary>
Motivation: 解决传统混合整数规划和约束规划在大规模实例上效率低下的问题，同时支持动态更新的低延迟需求。

Method: 将资源投资问题（RIP）建模为马尔可夫决策过程，通过分解子问题和顺序选择过程来构建调度方案。

Result: iScheduler在保持资源成本竞争力的同时，将可行性时间减少了高达43倍。

Conclusion: iScheduler通过强化学习驱动的迭代调度框架，显著提高了大规模任务调度的效率，并在资源成本上保持竞争力。

Abstract: Scheduling precedence-constrained tasks under shared renewable resources is central to modern computing platforms. The Resource Investment Problem (RIP) models this setting by minimizing the cost of provisioned renewable resources under precedence and timing constraints. Exact mixed-integer programming and constraint programming become impractically slow on large instances, and dynamic updates require schedule revisions under tight latency budgets. We present iScheduler, a reinforcement-learning-driven iterative scheduling framework that formulates RIP solving as a Markov decision process over decomposed subproblems and constructs schedules through sequential process selection. The framework accelerates optimization and supports reconfiguration by reusing unchanged process schedules and rescheduling only affected processes. We also release L-RIPLIB, an industrial-scale benchmark derived from cloud-platform workloads with 1,000 instances of 2,500-10,000 tasks. Experiments show that iScheduler attains competitive resource costs while reducing time to feasibility by up to 43$\times$ against strong commercial baselines.

</details>


### [161] [HQP: Sensitivity-Aware Hybrid Quantization and Pruning for Ultra-Low-Latency Edge AI Inference](https://arxiv.org/abs/2602.06069)
*Dinesh Gopalan,Ratul Ali*

Main category: cs.DC

TL;DR: HQP框架通过混合量化和剪枝，在边缘设备上实现高效模型压缩和加速，严格保证精度，性能显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 分布式边缘-云环境中对高保真实时推理的需求日益增长，需要对抗严重的延迟和能源限制，因此需要一种能协同加速模型并严格保证质量的方法。

Method: 提出了一种基于Fisher信息矩阵（FIM）高效近似的动态权重敏感性度量的敏感性感知结构剪枝算法，并结合8位后训练量化，形成混合量化和剪枝（HQP）框架。

Result: 在NVIDIA Jetson边缘平台上，HQP框架实现了最高3.12倍的推理加速和55%的模型大小缩减，同时精度下降严格控制在1.5%以内。

Conclusion: HQP框架作为一种硬件无关的解决方案，在资源受限的边缘基础设施中部署超低延迟AI方面表现出色，显著提升了推理速度和模型压缩率，同时严格保证了精度下降在可接受范围内。

Abstract: The escalating demand for high-fidelity, real-time inference in distributed edge-cloud environments necessitates aggressive model optimization to counteract severe latency and energy constraints. This paper introduces the Hybrid Quantization and Pruning (HQP) framework, a novel, integrated methodology designed to achieve synergistic model acceleration while adhering to strict quality guarantees. We detail a sensitivity-aware structural pruning algorithm that employs a dynamic weight sensitivity metric, derived from a highly efficient approximation of the Fisher Information Matrix (FIM), to guide the iterative removal of redundant filters. This pruning is strictly conditional, enforcing an adherence to a maximum permissible accuracy drop (Delta ax) before the model proceeds to 8-bit post-training quantization. This rigorous coordination is critical, as it ensures the resultant sparse model structure is maximally robust to quantization error and hardware-specific kernel optimization. Exhaustive evaluation across heterogeneous NVIDIA Jetson edge platforms, utilizing resource-efficient architectures like MobileNetV3 and ResNet-18, demonstrates that the HQP framework achieves a peak performance gain of 3.12 times inference speedup and a 55 percent model size reduction, while rigorously containing the accuracy drop below the 1.5 percent constraint. A comprehensive comparative analysis against conventional single-objective compression techniques validates the HQP framework as a superior, hardware-agnostic solution for deploying ultra-low-latency AI in resource-limited edge infrastructures.

</details>


### [162] [Computationally Efficient Laplacian CL-colME](https://arxiv.org/abs/2602.06070)
*Nikola Stankovic*

Main category: cs.DC

TL;DR: 提出CL-colME，一种更高效的C-colME变体，通过拉普拉斯共识避免高成本归一化，保持性能。


<details>
  <summary>Details</summary>
Motivation: 评估基于共识的C-colME框架，该框架依赖双重随机平均矩阵确保收敛到oracle解。

Method: 提出CL-colME，一种利用基于拉普拉斯的共识来避免计算昂贵的归一化过程的新变体。

Result: 模拟结果显示，CL-colME保持了C-colME的收敛行为和准确性，同时提高了计算效率。

Conclusion: CL-colME通过基于拉普拉斯的共识方法，在保持C-colME收敛性和准确性的同时提高了计算效率。

Abstract: Decentralized collaborative mean estimation (colME) is a fundamental task in heterogeneous networks. Its graph-based variants B-colME and C-colME achieve high scalability of the problem. This paper evaluates the consensus-based C-colME framework, which relies on doubly stochastic averaging matrices to ensure convergence to the oracle solution. We propose CL-colME, a novel variant utilizing Laplacian-based consensus to avoid the computationally expensive normalization processes. Simulation results show that the proposed CL-colME maintains the convergence behavior and accuracy of C-colME while improving computational efficiency.

</details>


### [163] [FlashSketch: Sketch-Kernel Co-Design for Fast Sparse Sketching on GPUs](https://arxiv.org/abs/2602.06071)
*Rajat Vadiraj Dwaraknath,Sungyoon Kim,Mert Pilanci*

Main category: cs.DC

TL;DR: 设计了GPU友好的稀疏草图BlockPerm-SJLT及优化内核FlashSketch，平衡效率与鲁棒性，实现1.7倍加速。


<details>
  <summary>Details</summary>
Motivation: 稀疏草图的随机稀疏性导致GPU内存访问模式不规则，降低带宽利用率，需解决这一矛盾。

Method: 设计了BlockPerm-SJLT稀疏草图及其对应的优化CUDA内核FlashSketch，通过可调参数平衡GPU效率和草图鲁棒性。

Result: FlashSketch在RandNLA基准测试和GraSS数据归因管道中表现优异，实现了显著的性能提升。

Conclusion: BlockPerm-SJLT与FlashSketch的协同设计在GPU效率和草图鲁棒性之间取得了平衡，显著提升了性能，实现了约1.7倍的全局几何平均加速。

Abstract: Sparse sketches such as the sparse Johnson-Lindenstrauss transform are a core primitive in randomized numerical linear algebra because they leverage random sparsity to reduce the arithmetic cost of sketching, while still offering strong approximation guarantees. Their random sparsity, however, is at odds with efficient implementations on modern GPUs, since it leads to irregular memory access patterns that degrade memory bandwidth utilization. Motivated by this tension, we pursue a sketch-kernel co-design approach: we design a new family of sparse sketches, BlockPerm-SJLT, whose sparsity structure is chosen to enable FlashSketch, a corresponding optimized CUDA kernel that implements these sketches efficiently. The design of BlockPerm-SJLT introduces a tunable parameter that explicitly trades off the tension between GPU-efficiency and sketching robustness. We provide theoretical guarantees for BlockPerm-SJLT under the oblivious subspace embedding (OSE) framework, and also analyze the effect of the tunable parameter on sketching quality. We empirically evaluate FlashSketch on standard RandNLA benchmarks, as well as an end-to-end ML data attribution pipeline called GraSS. FlashSketch pushes the Pareto frontier of sketching quality versus speed, across a range of regimes and tasks, and achieves a global geomean speedup of roughly 1.7x over the prior state-of-the-art GPU sketches.

</details>


### [164] [PackInfer: Compute- and I/O-Efficient Attention for Batched LLM Inference](https://arxiv.org/abs/2602.06072)
*Rui Ning,Wei Zhang,Fan Lai*

Main category: cs.DC

TL;DR: PackInfer是一种内核级注意力框架，通过负载均衡和I/O感知优化，显著提升异构批处理LLM推理的效率和吞吐量。


<details>
  <summary>Details</summary>
Motivation: 生产环境中LLM服务的批处理请求序列长度高度异构，导致计算和I/O不平衡，影响GPU资源利用率。

Method: PackInfer将异构批处理请求组织成负载均衡的执行组，通过统一内核启动和优化的KV缓存布局减少冗余计算和数据移动。

Result: PackInfer在实际工作负载中降低了推理延迟13.0-20.1%，吞吐量提升20%。

Conclusion: PackInfer通过负载均衡和I/O感知优化，显著提升了LLM推理的效率和吞吐量。

Abstract: Attention efficiency is critical to large language model (LLM) inference. While prior advances optimize attention execution for individual requests (e.g., FlashAttention), production LLM serving relies on batching requests with highly heterogeneous sequence lengths for high serving throughput. This mismatch induces severe computation and I/O imbalance, exacerbates stragglers, and underutilizes GPU resources. We present PackInfer, a kernel-level attention framework that enables compute- and I/O-aware execution for heterogeneous batched inference. PackInfer orchestrates batched requests into load-balanced execution groups, effectively saturating GPU utilization by packing multiple requests into unified kernel launches. By constructing attention kernels directly over packed query-key regions, PackInfer eliminates redundant computation and balances thread-block execution. It then incorporates I/O-aware grouping that co-locates shared-prefix requests and reorganizes KV caches into group-contiguous layouts, reducing memory fragmentation and redundant data movement as generation evolves. Evaluations on real-world workloads show that PackInfer reduces inference latency by 13.0-20.1%, and improves throughput by 20% compared to the state-of-the-art FlashAttention.

</details>


### [165] [Experimental Analysis of Server-Side Caching for Web Performance](https://arxiv.org/abs/2602.06074)
*Mohammad Umar,Bharat Tripathi*

Main category: cs.DC

TL;DR: 本文实验验证了简单服务器端内存缓存对小规模网络应用性能的显著提升效果，尤其适合教育环境等注重简单性和可重现性的场景。


<details>
  <summary>Details</summary>
Motivation: 尽管缓存技术在网络性能优化文献中已被广泛探讨，但缺乏针对小规模网络应用中简单内存缓存效果的实验研究。本文旨在填补这一研究空白。

Method: 使用轻量级网络服务器框架，在相同环境条件下通过重复HTTP请求测量响应时间，比较了无缓存和有内存缓存（固定生存时间）的两种服务器端网络应用配置的性能。

Result: 结果显示，缓存请求的响应时间显著减少。

Conclusion: 本文通过实验证明了简单的服务器端内存缓存能显著减少响应时间，适用于教育环境和小规模网络应用，其中简单性和可重现性至关重要。

Abstract: Performance in web applications is a key aspect of user experience and system scalability. Among the different techniques used to improve web application performance, caching has been widely used. While caching has been widely explored in web performance optimization literature, there is a lack of experimental work that explores the effect of simple inmemory caching in small-scale web applications. This paper fills this research gap by experimentally comparing the performance of two server-side web application configurations: one without caching and another with in-memory caching and a fixed time-tolive. The performance evaluation was conducted using a lightweight web server framework, and response times were measured using repeated HTTP requests under identical environmental conditions. The results show a significant reduction in response time for cached requests, and the findings of this paper provide valuable insights into the effectiveness of simple server-side caching in improving web application performance making it suitable for educational environments and small-scale web applications where simplicity and reproducibility are critical.

</details>


### [166] [MemGUI-Bench: Benchmarking Memory of Mobile GUI Agents in Dynamic Environments](https://arxiv.org/abs/2602.06075)
*Guangyi Liu,Pengxiang Zhao,Yaozhen Liang,Qinyi Luo,Shunye Tang,Yuxiang Chai,Weifeng Lin,Han Xiao,WenHao Wang,Siheng Chen,Zhengxi Lu,Gao Wu,Hao Wang,Liang Liu,Yong Liu*

Main category: cs.DC

TL;DR: MemGUI-Bench是一个新的移动GUI代理基准测试，专注于评估记忆能力，揭示了现有系统的不足并提出了改进方向。


<details>
  <summary>Details</summary>
Motivation: 当前移动GUI代理基准测试在评估记忆能力方面存在系统性不足，缺乏跨会话学习评估，因此需要开发一个更全面的记忆相关任务评估框架。

Method: 通过MemGUI-Bench评估11种不同架构的代理，使用pass@k和分阶段LLM-as-judge评估方法，结合Progressive Scrutiny和7个层次化指标。

Result: 实验结果显示所有评估系统均存在显著记忆缺陷，识别出5种不同的失败模式，并提出了5个设计启示。

Conclusion: 论文提出了MemGUI-Bench，一个全面的以记忆为中心的基准测试，揭示了现有移动GUI代理在记忆能力上的显著不足，并提出了5个可操作的设计启示。

Abstract: Current mobile GUI agent benchmarks systematically fail to assess memory capabilities, with only 5.2-11.8% memory-related tasks and no cross-session learning evaluation. We introduce MemGUI-Bench, a comprehensive memory-centric benchmark with pass@k and staged LLM-as-judge evaluation. Our contributions include: (1) a systematic memory taxonomy analyzing 11 agents across 5 architectures; (2) 128 tasks across 26 applications where 89.8% challenge memory through cross-temporal and cross-spatial retention; (3) MemGUI-Eval, an automated pipeline with Progressive Scrutiny and 7 hierarchical metrics; and (4) RQ-driven assessment of 11 state-of-the-art agents. Our experiments reveal significant memory deficits across all evaluated systems, identify 5 distinct failure modes, and synthesize 5 actionable design implications. All resources including code, benchmark, and evaluation results will be \textbf{\textit{fully open-sourced and continuously maintained}} at https://lgy0404.github.io/MemGUI-Bench/.

</details>


### [167] [Canzona: A Unified, Asynchronous, and Load-Balanced Framework for Distributed Matrix-based Optimizers](https://arxiv.org/abs/2602.06079)
*Liangyu Wang,Siqi Zhang,Junjie Wang,Yiming Dong,Bo Zheng,Zihan Qiu,Shengkun Tang,Di Wang,Rui Men,Dayiheng Liu*

Main category: cs.DC

TL;DR: Canzona框架通过异步和负载均衡策略，解决了分布式训练中矩阵优化器的效率问题，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有解决方案在分布式框架中无法高效协调矩阵优化器的全局更新需求与张量碎片化问题。

Method: 提出了alpha-Balanced Static Partitioning策略和Asynchronous Compute pipeline，结合Micro-Group Scheduling批量处理碎片化更新。

Result: 在256个GPU上对Qwen3模型家族（高达32B参数）的评估显示，Canzona实现了1.57倍的端到端迭代加速，并将优化器步骤延迟降低了5.8倍。

Conclusion: Canzona框架通过解耦逻辑优化器分配与物理参数分布，有效解决了分布式框架中矩阵优化器的冲突问题，显著提升了训练效率。

Abstract: The scaling of Large Language Models (LLMs) drives interest in matrix-based optimizers (e.g., Shampoo, Muon, SOAP) for their convergence efficiency; yet their requirement for holistic updates conflicts with the tensor fragmentation in distributed frameworks like Megatron. Existing solutions are suboptimal: synchronous approaches suffer from computational redundancy, while layer-wise partitioning fails to reconcile this conflict without violating the geometric constraints of efficient communication primitives. To bridge this gap, we propose Canzona, a Unified, Asynchronous, and Load-Balanced framework that decouples logical optimizer assignment from physical parameter distribution. For Data Parallelism, we introduce an alpha-Balanced Static Partitioning strategy that respects atomicity while neutralizing the load imbalance. For Tensor Parallelism, we design an Asynchronous Compute pipeline utilizing Micro-Group Scheduling to batch fragmented updates and hide reconstruction overhead. Extensive evaluations on the Qwen3 model family (up to 32B parameters) on 256 GPUs demonstrate that our approach preserves the efficiency of established parallel architectures, achieving a 1.57x speedup in end-to-end iteration time and reducing optimizer step latency by 5.8x compared to the baseline.

</details>


### [168] [LAAFD: LLM-based Agents for Accelerated FPGA Design](https://arxiv.org/abs/2602.06085)
*Maxim Moraru,Kamalavasan Kamalakkannan,Jered Dominguez-Trujillo,Patrick Diehl,Atanu Barai,Julien Loiseau,Zachary Kent Baker,Howard Pritchard,Galen M Shipman*

Main category: cs.DC

TL;DR: LAAFD通过大型语言模型自动化FPGA优化流程，显著降低专业知识需求，保持高性能。


<details>
  <summary>Details</summary>
Motivation: FPGA在科学和边缘计算中具有高性能、低延迟和能效优势，但由于需要专业硬件知识，其应用受到限制。

Method: LAAFD是一个基于大型语言模型的代理工作流，将通用C++代码转换为优化的Vitis HLS内核，自动化关键转换如深度流水线、向量化和数据流分区，并通过HLS协同仿真和综合反馈验证正确性并迭代改进执行周期。

Result: 在代表HPC常见计算模式的15个内核上，LAAFD与手动优化的Vitis HLS基线相比，实现了99.9%的几何平均性能。对于模板工作负载，LAAFD的性能与最先进的基于DSL的HLS代码生成器SODA相当，同时生成更易读的内核。

Conclusion: LAAFD显著降低了FPGA加速的专业知识门槛，同时保持了高效率。

Abstract: FPGAs offer high performance, low latency, and energy efficiency for accelerated computing, yet adoption in scientific and edge settings is limited by the specialized hardware expertise required. High-level synthesis (HLS) boosts productivity over HDLs, but competitive designs still demand hardware-aware optimizations and careful dataflow design. We introduce LAAFD, an agentic workflow that uses large language models to translate general-purpose C++ into optimized Vitis HLS kernels. LAAFD automates key transfor mations: deep pipelining, vectorization, and dataflow partitioning and closes the loop with HLS co-simulation and synthesis feedback to verify correctness while iteratively improving execution time in cycles. Over a suite of 15 kernels representing common compute patterns in HPC, LAFFD achieves 99.9% geomean performance when compared to the hand tuned baseline for Vitis HLS. For stencil workloads, LAAFD matches the performance of SODA, a state-of-the-art DSL-based HLS code generator for stencil solvers, while yielding more readable kernels. These results suggest LAAFD substantially lowers the expertise barrier to FPGA acceleration without sacrificing efficiency.

</details>


### [169] [BouquetFL: Emulating diverse participant hardware in Federated Learning](https://arxiv.org/abs/2602.06498)
*Arno Geimer*

Main category: cs.DC

TL;DR: BouquetFL 是一个在单机上模拟 FL 中异构硬件的框架，填补了现有研究的空白，使实验更接近实际条件。


<details>
  <summary>Details</summary>
Motivation: 现有的 FL 研究大多在中央机器上进行模拟，忽略了参与方之间潜在的硬件异构性，BouquetFL 旨在填补这一方法学空白。

Method: 通过资源限制编程模拟不同的硬件配置，BouquetFL 实现了在真实硬件多样性下的受控 FL 实验。

Result: BouquetFL 提供了一种可访问的方式，用于研究 FL 中的系统异构性，包括基于常见消费设备和小型实验室设备的广泛配置选项。

Conclusion: BouquetFL 提供了一个在单一物理机器上模拟异构客户端硬件的框架，使 FL 研究能够更接近实际部署条件，而无需多台物理设备。

Abstract: In Federated Learning (FL), multiple parties collaboratively train a shared Machine Learning model to encapsulate all private knowledge without exchange of information. While it has seen application in several industrial projects, most FL research considers simulations on a central machine, without considering potential hardware heterogeneity between the involved parties. In this paper, we present BouquetFL, a framework designed to address this methodological gap by simulating heterogeneous client hardware on a single physical machine. By programmatically emulating diverse hardware configurations through resource restriction, BouquetFL enables controlled FL experimentation under realistic hardware diversity. Our tool provides an accessible way to study system heterogeneity in FL without requiring multiple physical devices, thereby bringing experimental practice closer to practical deployment conditions. The target audience are FL researchers studying highly heterogeneous federations. We include a wide range of profiles derived from commonly available consumer and small-lab devices, as well as a custom hardware sampler built on real-world hardware popularity, allowing users to configure the federation according to their preference.

</details>


### [170] [FCDP: Fully Cached Data Parallel for Communication-Avoiding Large-Scale Training](https://arxiv.org/abs/2602.06499)
*Gyeongseo Park,Eungyeong Lee,Song-woo Sok,Myung-Hoon Cha,Kwangwon Koh,Baik-Song An,Hongyeon Kim,Ki-Dong Kang*

Main category: cs.DC

TL;DR: FCDP利用主机内存作为缓存层，减少节点间通信，显著提升带宽有限集群的训练吞吐量，同时保持低GPU内存占用。


<details>
  <summary>Details</summary>
Motivation: 在带宽有限的集群上，现有优化方法（如MiCS、ZeRO++）会因GPU内存缓存导致内存不足，而主机内存卸载（如ZeRO-Offload、ZeRO-Infinity）则因PCIe开销降低吞吐量。研究发现主机内存可作为快速缓存层，优于节点间通信。

Method: FCDP将前向传递参数缓存在主机内存中，并在反向传递时通过快速的节点内all-gather复用这些参数，减少了50%的节点间all-gather通信。对于参数高效微调（PEFT），FCDP选择性通信仅训练参数以最大化缓存，减少节点间流量超过99%。

Result: 在商品化集群设置中，FCDP实现了比ZeRO-3高100倍、比ZeRO++高51倍的吞吐量，同时保持了ZeRO-3的最大批处理大小。

Conclusion: FCDP通过在带宽有限的集群中利用主机内存作为快速缓存层，显著减少了节点间通信，同时保持了ZeRO-3的最小GPU内存占用，实现了比ZeRO-3和ZeRO++更高的吞吐量。

Abstract: Training billion-parameter models requires distributing model states across GPUs using fully sharded data parallel (i.e., ZeRO-3). While ZeRO-3 succeeds on clusters with high-bandwidth NVLink and InfiniBand interconnects, researchers with commodity hardware face severe inter-node all-gather bottlenecks. Existing optimizations take two approaches: GPU memory caching (MiCS, ZeRO++) trades memory capacity for reduced communication, triggering out-of-memory failures on large models; host memory offloading (ZeRO-Offload, ZeRO-Infinity) extends capacity but degrades throughput due to PCIe overhead. We observe that on bandwidth-limited clusters, host memory can serve not as an overflow tier but as a fast caching layer that outperforms inter-node communication. Based on this insight, we propose FCDP, which eliminates redundant inter-node communication while preserving ZeRO-3's minimal GPU memory footprint. FCDP caches forward-pass parameters in host memory and reuses them during the backward pass via fast intra-node all-gather, reducing inter-node all-gather by 50%. For parameter-efficient fine-tuning (PEFT), FCDP selectively communicates only trainable parameters to maximize caching, reducing inter-node traffic by over 99%. In our commodity cluster setup, FCDP achieves up to 100x higher throughput than ZeRO-3 and 51x higher than ZeRO++, while maintaining ZeRO-3's maximum batch size.

</details>


### [171] [DualMap: Enabling Both Cache Affinity and Load Balancing for Distributed LLM Serving](https://arxiv.org/abs/2602.06502)
*Ying Yuan,Pengfei Zuo,Bo Wang,Zhangyu Chen,Zhipeng Tan,Zhou Yu*

Main category: cs.DC

TL;DR: DualMap 通过双映射调度策略，结合智能候选选择与动态优化技术，实现了 LLM 服务中缓存重用与负载均衡的统一，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有调度器无法在单一映射空间内同时实现缓存亲和性与负载均衡，导致 KV 缓存重用与请求均衡分布之间存在冲突。

Method: DualMap 通过两个独立的哈希函数将请求映射到候选实例，并基于当前系统状态智能选择最佳候选，结合 SLO 感知路由、热点感知再平衡和轻量级双哈希环扩展技术。

Result: 实验表明，DualMap 在相同 TTFT SLO 约束下，有效请求容量提升了 2.25 倍。

Conclusion: DualMap 是一种双映射调度策略，成功实现了 KV 缓存亲和性与负载均衡的统一，并通过实验验证了其有效性。

Abstract: In LLM serving, reusing the KV cache of prompts across requests is critical for reducing TTFT and serving costs. Cache-affinity scheduling, which co-locates requests with the same prompt prefix to maximize KV cache reuse, often conflicts with load-balancing scheduling that distributes requests evenly across compute instances. Existing schedulers fail to reconcile this trade-off as they operate within a single mapping space, typically applying cache-affinity routing to a subset of requests and load-balanced routing to the rest, without a unified solution to achieve both goals. To address this limitation, we propose DualMap, a dual-mapping scheduling strategy for distributed LLM serving that achieves both cache affinity and load balancing. Its key idea is to map each request to two candidate instances via two independent hash functions based on the request prompt, then intelligently select the better candidate based on current system states. This design increases the likelihood that requests with shared prefixes are co-located, while evenly dispersing distinct prefixes across the cluster via ``the power of two choices''. To make DualMap robust under dynamic and skewed real-world workloads, we incorporate three techniques: 1) SLO-aware request routing, which prioritizes cache affinity but switches to load-aware scheduling when TTFT exceeds the SLO, enhancing load balance without sacrificing cache reuse; 2) hotspot-aware rebalancing, which dynamically migrates requests from overloaded to underloaded instances, mitigating hotspots and rebalancing the system; 3) lightweight dual-hash-ring scaling, which leverages a dual-hash-ring mapping to support fast and low-overhead instance scaling without costly global remapping. Experiments on real-world workloads show that DualMap improves effective request capacity by up to 2.25$\times$ under the same TTFT SLO constraints compared with SOTA work.

</details>


### [172] [Reinforcement Learning-Based Dynamic Management of Structured Parallel Farm Skeletons on Serverless Platforms](https://arxiv.org/abs/2602.06555)
*Lanpei Li,Massimo Coppola,Malio Li,Valerio Besozzi,Jack Bell,Vincenzo Lomonaco*

Main category: cs.DC

TL;DR: 提出了一个在无服务器平台上动态管理并行处理骨架的框架，结合AI驱动和反应式控制，提升了性能与资源效率。


<details>
  <summary>Details</summary>
Motivation: 目标是在保持骨架编程优势的同时，为无服务器和连续环境带来类似HPC的性能和弹性。

Method: 框架结合了可复用的Farm模板与基于Gymnasium的监控和控制层，暴露队列、时间和QoS指标给反应式和基于学习的控制器。研究了AI驱动的动态扩展在OpenFaaS上管理Farm并行度的有效性。

Result: 结果显示，AI驱动的管理比纯基于模型的性能引导更能适应平台特定限制，提升了QoS并保持了高效的资源使用和稳定的扩展行为。

Conclusion: AI驱动的动态扩展在适应平台特定限制方面优于纯基于模型的性能管理，在保持高效资源使用和稳定扩展行为的同时提升了QoS。

Abstract: We present a framework for dynamic management of structured parallel processing skeletons on serverless platforms. Our goal is to bring HPC-like performance and resilience to serverless and continuum environments while preserving the programmability benefits of skeletons. As a first step, we focus on the well known Farm pattern and its implementation on the open-source OpenFaaS platform, treating autoscaling of the worker pool as a QoS-aware resource management problem. The framework couples a reusable farm template with a Gymnasium-based monitoring and control layer that exposes queue, timing, and QoS metrics to both reactive and learning-based controllers. We investigate the effectiveness of AI-driven dynamic scaling for managing the farm's degree of parallelism via the scalability of serverless functions on OpenFaaS. In particular, we discuss the autoscaling model and its training, and evaluate two reinforcement learning (RL) policies against a baseline of reactive management derived from a simple farm performance model. Our results show that AI-based management can better accommodate platform-specific limitations than purely model-based performance steering, improving QoS while maintaining efficient resource usage and stable scaling behaviour.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [173] [Fast Makespan Minimization via Short ILPs](https://arxiv.org/abs/2602.06514)
*Danny Hermelin,Dvir Shabtay*

Main category: cs.DS

TL;DR: 利用短整数线性规划求解器改进，提出快速伪多项式时间算法，优化固定并行机makespan最小化的时间复杂度。


<details>
  <summary>Details</summary>
Motivation: 针对固定数量并行机的makespan最小化问题，现有算法在$p_{\max}$适中时的时间复杂度有待优化。

Method: 通过改进短整数线性规划求解器的运行时间，提出新的算法，其时间复杂度为$\widetilde{O}(p^{O(1)}_{\max}+n)$或$\widetilde{O}(p^{O(1)}_{\max} \cdot n)$。

Result: 新算法在$p_{\max}$适中时显著提升了时间效率，优于现有算法。

Conclusion: 本文展示了如何利用短整数线性规划求解器的改进，为固定数量并行机上的makespan最小化及相关变体提供快速的伪多项式时间算法。

Abstract: Short integer linear programs are programs with a relatively small number of constraints. We show how recent improvements on the running-times of solvers for such programs can be used to obtain fast pseudo-polynomial time algorithms for makespan minimization on a fixed number of parallel machines, and other related variants. The running times of our algorithms are all of the form $\widetilde{O}(p^{O(1)}_{\max}+n)$ or $\widetilde{O}(p^{O(1)}_{\max} \cdot n)$, where $p_{\max}$ is the maximum processing time in the input. These improve upon the time complexity of previously known algorithms for moderate values of $p_{\max}$.

</details>


### [174] [Towards Efficient Data Structures for Approximate Search with Range Queries](https://arxiv.org/abs/2602.06860)
*Ladan Kian,Dariusz R. Kowalski*

Main category: cs.DS

TL;DR: c-DAG是一种新型SRC搜索结构，通过增加节点子节点数减少假阳性，适用于隐私保护和多媒体检索。


<details>
  <summary>Details</summary>
Motivation: 解决传统范围查询在数据检索中提取精确和完整信息的高成本问题，以及现有SRC搜索产生的假阳性问题。

Method: 提出了一种新的SRC搜索结构c-DAG，通过增加节点的子节点数（c≥3）来增强1D-Tree，并进行了与1D-Tree的竞争分析。

Result: c-DAG在平均情况下实现了假阳性比率的对数级改进，并提供了扩展到查询经验分布的通用框架。

Conclusion: c-DAG结构在保持与1D-Tree相同的时间和内存复杂度的同时，平均减少了假阳性的对数因子，适用于隐私保护系统和多媒体检索。

Abstract: Range queries are simple and popular types of queries used in data retrieval. However, extracting exact and complete information using range queries is costly. As a remedy, some previous work proposed a faster principle, {\em approximate} search with range queries, also called single range cover (SRC) search. It can, however, produce some false positives. In this work we introduce a new SRC search structure, a $c$-DAG (Directed Acyclic Graph), which provably decreases the average number of false positives by logarithmic factor while keeping asymptotically same time and memory complexities as a classic tree structure. A $c$-DAG is a tunable augmentation of the 1D-Tree with denser overlapping branches ($c \geq 3$ children per node). We perform a competitive analysis of a $c$-DAG with respect to 1D-Tree and derive an additive constant time overhead and a multiplicative logarithmic improvement of the false positives ratio, on average. We also provide a generic framework to extend our results to empirical distributions of queries, and demonstrate its effectiveness for Gowalla dataset. Finally, we quantify and discuss security and privacy aspects of SRC search on $c$-DAG vs 1D-Tree, mainly mitigation of structural leakage, which makes $c$-DAG a good data structure candidate for deployment in privacy-preserving systems (e.g., searchable encryption) and multimedia retrieval.

</details>
