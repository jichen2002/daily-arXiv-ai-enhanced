<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 99]
- [cs.RO](#cs.RO) [Total: 47]
- [cs.NI](#cs.NI) [Total: 12]
- [cs.DC](#cs.DC) [Total: 7]
- [cs.DS](#cs.DS) [Total: 4]
- [cs.OS](#cs.OS) [Total: 1]
- [cs.AI](#cs.AI) [Total: 29]
- [cs.SE](#cs.SE) [Total: 17]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [Faster-GS: Analyzing and Improving Gaussian Splatting Optimization](https://arxiv.org/abs/2602.09999)
*Florian Hahlbohm,Linus Franke,Martin Eisemann,Marcus Magnor*

Main category: cs.CV

TL;DR: Faster-GS 通过整合和优化现有策略，实现了高达5倍的训练加速，同时保持视觉质量，并成功应用于4D高斯重建。


<details>
  <summary>Details</summary>
Motivation: 当前3D高斯泼溅（3DGS）的研究中，许多方法将实现层面的改进与基础算法修改混为一谈，或以性能换取保真度，导致研究领域碎片化，难以进行公平比较。

Method: 研究整合并评估了先前3DGS研究中最有效和广泛适用的策略，并加入了若干新颖优化方法。此外，还探讨了框架中未被充分研究的方面，如数值稳定性、高斯截断和梯度近似。

Result: Faster-GS 在全面的基准测试中表现出色，实现了高达5倍的训练加速，同时保持视觉质量。

Conclusion: Faster-GS 系统通过整合和优化现有策略，在保持视觉质量的同时实现了高达5倍的训练加速，为3DGS优化建立了新的成本效益和资源效率基准。此外，优化方法还成功应用于4D高斯重建，实现了高效的非刚性场景优化。

Abstract: Recent advances in 3D Gaussian Splatting (3DGS) have focused on accelerating optimization while preserving reconstruction quality. However, many proposed methods entangle implementation-level improvements with fundamental algorithmic modifications or trade performance for fidelity, leading to a fragmented research landscape that complicates fair comparison. In this work, we consolidate and evaluate the most effective and broadly applicable strategies from prior 3DGS research and augment them with several novel optimizations. We further investigate underexplored aspects of the framework, including numerical stability, Gaussian truncation, and gradient approximation. The resulting system, Faster-GS, provides a rigorously optimized algorithm that we evaluate across a comprehensive suite of benchmarks. Our experiments demonstrate that Faster-GS achieves up to 5$\times$ faster training while maintaining visual quality, establishing a new cost-effective and resource efficient baseline for 3DGS optimization. Furthermore, we demonstrate that optimizations can be applied to 4D Gaussian reconstruction, leading to efficient non-rigid scene optimization.

</details>


### [2] [UI-Venus-1.5 Technical Report](https://arxiv.org/abs/2602.09082)
*Veuns-Team,:,Changlong Gao,Zhangxuan Gu,Yulin Liu,Xinyu Qiu,Shuheng Shen,Yue Wen,Tianyu Xia,Zhenyu Xu,Zhengwen Zeng,Beitong Zhou,Xingran Zhou,Weizhi Chen,Sunhao Dai,Jingya Dou,Yichen Gong,Yuan Guo,Zhenlin Guo,Feng Li,Qian Li,Jinzhen Lin,Yuqi Zhou,Linchao Zhu,Liang Chen,Zhenyu Guo,Changhua Meng,Weiqiang Wang*

Main category: cs.CV

TL;DR: UI-Venus-1.5是一款统一的GUI代理，通过综合训练和模型合并技术，在多个基准测试中表现优异，显著超越先前基线。


<details>
  <summary>Details</summary>
Motivation: 尽管GUI代理在自动化数字环境交互方面表现出强大潜力，但实现广泛通用性和稳定任务性能仍具挑战性。

Method: UI-Venus-1.5采用了三个关键技术：综合中期训练、在线强化学习和模型合并，构建了一个统一的GUI代理。

Result: UI-Venus-1.5在ScreenSpot-Pro（69.6%）、VenusBench-GD（75.0%）和AndroidWorld（77.6%）等基准测试中创下新纪录，并在中国移动应用中展现出强大导航能力。

Conclusion: UI-Venus-1.5通过综合训练和模型合并技术，实现了在GUI代理领域的先进性能，并在多个基准测试中显著超越先前基线。

Abstract: GUI agents have emerged as a powerful paradigm for automating interactions in digital environments, yet achieving both broad generality and consistently strong task performance remains challenging.In this report, we present UI-Venus-1.5, a unified, end-to-end GUI Agent designed for robust real-world applications.The proposed model family comprises two dense variants (2B and 8B) and one mixture-of-experts variant (30B-A3B) to meet various downstream application scenarios.Compared to our previous version, UI-Venus-1.5 introduces three key technical advances: (1) a comprehensive Mid-Training stage leveraging 10 billion tokens across 30+ datasets to establish foundational GUI semantics; (2) Online Reinforcement Learning with full-trajectory rollouts, aligning training objectives with long-horizon, dynamic navigation in large-scale environments; and (3) a single unified GUI Agent constructed via Model Merging, which synthesizes domain-specific models (grounding, web, and mobile) into one cohesive checkpoint. Extensive evaluations demonstrate that UI-Venus-1.5 establishes new state-of-the-art performance on benchmarks such as ScreenSpot-Pro (69.6%), VenusBench-GD (75.0%), and AndroidWorld (77.6%), significantly outperforming previous strong baselines. In addition, UI-Venus-1.5 demonstrates robust navigation capabilities across a variety of Chinese mobile apps, effectively executing user instructions in real-world scenarios. Code: https://github.com/inclusionAI/UI-Venus; Model: https://huggingface.co/collections/inclusionAI/ui-venus

</details>


### [3] [Agent Banana: High-Fidelity Image Editing with Agentic Thinking and Tooling](https://arxiv.org/abs/2602.09084)
*Ruijie Ye,Jiayi Zhang,Zhuoxin Liu,Zihao Zhu,Siyuan Yang,Li Li,Tianfu Fu,Franck Dernoncourt,Yue Zhao,Jiacheng Zhu,Ryan Rossi,Wenhao Chai,Zhengzhong Tu*

Main category: cs.CV

TL;DR: Agent Banana框架通过分层代理机制解决图像编辑中的过度编辑、多轮编辑和分辨率问题，在4K基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有指令式图像编辑中的三大挑战：过度编辑、单轮编辑限制及低分辨率评估与真实工作流不匹配。

Method: 提出了Agent Banana框架，包含Context Folding（压缩长交互历史为结构化记忆）和Image Layer Decomposition（基于图层的局部编辑）两种关键机制。

Result: 在HDD-Bench上，Agent Banana在多轮一致性和背景保真度上表现最佳（如IC 0.871，SSIM-OM 0.84），同时在单轮编辑基准测试中保持竞争力。

Conclusion: 本研究提出Agent Banana框架，通过分层代理规划和执行机制，实现了高保真、对象感知的审慎编辑，显著提升了多轮编辑的一致性和背景保真度，并支持原生分辨率输出。

Abstract: We study instruction-based image editing under professional workflows and identify three persistent challenges: (i) editors often over-edit, modifying content beyond the user's intent; (ii) existing models are largely single-turn, while multi-turn edits can alter object faithfulness; and (iii) evaluation at around 1K resolution is misaligned with real workflows that often operate on ultra high-definition images (e.g., 4K). We propose Agent Banana, a hierarchical agentic planner-executor framework for high-fidelity, object-aware, deliberative editing. Agent Banana introduces two key mechanisms: (1) Context Folding, which compresses long interaction histories into structured memory for stable long-horizon control; and (2) Image Layer Decomposition, which performs localized layer-based edits to preserve non-target regions while enabling native-resolution outputs. To support rigorous evaluation, we build HDD-Bench, a high-definition, dialogue-based benchmark featuring verifiable stepwise targets and native 4K images (11.8M pixels) for diagnosing long-horizon failures. On HDD-Bench, Agent Banana achieves the best multi-turn consistency and background fidelity (e.g., IC 0.871, SSIM-OM 0.84, LPIPS-OM 0.12) while remaining competitive on instruction following, and also attains strong performance on standard single-turn editing benchmarks. We hope this work advances reliable, professional-grade agentic image editing and its integration into real workflows.

</details>


### [4] [SemanticMoments: Training-Free Motion Similarity via Third Moment Features](https://arxiv.org/abs/2602.09146)
*Saar Huberman,Kfir Goldberg,Or Patashnik,Sagie Benaim,Ron Mokady*

Main category: cs.CV

TL;DR: 提出SemanticMoments方法，通过语义特征时序统计改进视频运动理解，优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视频表示方法过度依赖静态外观和场景上下文，而非运动动态，且传统运动中心输入（如光流）缺乏语义基础。

Method: 提出SemanticMoments方法，利用预训练语义模型的特征计算时序统计（高阶矩）。

Result: SemanticMoments在SimMotion基准测试中表现优于现有RGB、光流和文本监督方法。

Conclusion: 本文提出了一种名为SemanticMoments的简单、无需训练的方法，通过计算预训练语义模型特征的时序统计（高阶矩），在语义特征空间中为以运动为中心的视频理解提供了可扩展且感知基础良好的解决方案。

Abstract: Retrieving videos based on semantic motion is a fundamental, yet unsolved, problem. Existing video representation approaches overly rely on static appearance and scene context rather than motion dynamics, a bias inherited from their training data and objectives. Conversely, traditional motion-centric inputs like optical flow lack the semantic grounding needed to understand high-level motion. To demonstrate this inherent bias, we introduce the SimMotion benchmarks, combining controlled synthetic data with a new human-annotated real-world dataset. We show that existing models perform poorly on these benchmarks, often failing to disentangle motion from appearance. To address this gap, we propose SemanticMoments, a simple, training-free method that computes temporal statistics (specifically, higher-order moments) over features from pre-trained semantic models. Across our benchmarks, SemanticMoments consistently outperforms existing RGB, flow, and text-supervised methods. This demonstrates that temporal statistics in a semantic feature space provide a scalable and perceptually grounded foundation for motion-centric video understanding.

</details>


### [5] [A Hybrid Deterministic Framework for Named Entity Extraction in Broadcast News Video](https://arxiv.org/abs/2602.09154)
*Andrea Filiberto Lucas,Dylan Seychell*

Main category: cs.CV

TL;DR: 该论文提出了一种自动检测和提取新闻视频中个人姓名的框架，通过模块化流程在确定性和可审计条件下运行，性能优于生成式多模态方法，并具有更高的透明度和可追溯性。


<details>
  <summary>Details</summary>
Motivation: 视频新闻内容增长需要透明可靠的方法来提取屏幕信息，但图形布局、排版惯例和平台特定设计模式的多样性使手动索引不切实际。

Method: 提出了一个可解释、模块化的提取流程，旨在在确定性和可审计条件下运行。

Result: 提出的流程在图形元素定位上达到95.8% mAP@0.5，平衡了精度（79.9%）和召回率（74.4%），避免了幻觉，并提供了每个处理阶段的完整可追溯性。

Conclusion: 该研究为现代新闻媒体中的混合多模态信息提取建立了一个方法严谨且可解释的基线。

Abstract: The growing volume of video-based news content has heightened the need for transparent and reliable methods to extract on-screen information. Yet the variability of graphical layouts, typographic conventions, and platform-specific design patterns renders manual indexing impractical. This work presents a comprehensive framework for automatically detecting and extracting personal names from broadcast and social-media-native news videos. It introduces a curated and balanced corpus of annotated frames capturing the diversity of contemporary news graphics and proposes an interpretable, modular extraction pipeline designed to operate under deterministic and auditable conditions.
  The pipeline is evaluated against a contrasting class of generative multimodal methods, revealing a clear trade-off between deterministic auditability and stochastic inference. The underlying detector achieves 95.8% mAP@0.5, demonstrating operationally robust performance for graphical element localisation. While generative systems achieve marginally higher raw accuracy (F1: 84.18% vs 77.08%), they lack the transparent data lineage required for journalistic and analytical contexts. The proposed pipeline delivers balanced precision (79.9%) and recall (74.4%), avoids hallucination, and provides full traceability across each processing stage. Complementary user findings indicate that 59% of respondents report difficulty reading on-screen names in fast-paced broadcasts, underscoring the practical relevance of the task. The results establish a methodologically rigorous and interpretable baseline for hybrid multimodal information extraction in modern news media.

</details>


### [6] [Decoding Future Risk: Deep Learning Analysis of Tubular Adenoma Whole-Slide Images](https://arxiv.org/abs/2602.09155)
*Ahmed Rahu,Brian Shula,Brandon Combs,Aqsa Sultana,Surendra P. Singh,Vijayan K. Asari,Derrick Forchetti*

Main category: cs.CV

TL;DR: 研究利用CNN分析低级别腺瘤的全切片图像，以识别预测结直肠癌风险的细微特征。


<details>
  <summary>Details</summary>
Motivation: 尽管筛查有效降低了结直肠癌的发病率，但部分低级别腺瘤患者仍会发展为结直肠癌。传统组织学评估可能无法完全捕捉恶性潜能的细微特征，因此需要更精确的方法来识别高风险患者。

Method: 研究利用数字病理学和机器学习技术，特别是卷积神经网络（CNN），对低级别管状腺瘤的全切片图像（WSIs）进行综合分析。

Result: 研究发现CNN能够检测出预测患者长期结直肠癌风险的细微组织学特征。

Conclusion: 机器学习算法，特别是卷积神经网络（CNN），能够从低级别管状腺瘤的全切片图像中识别出预测患者长期结直肠癌风险的细微组织学特征。

Abstract: Colorectal cancer (CRC) remains a significant cause of cancer-related mortality, despite the widespread implementation of prophylactic initiatives aimed at detecting and removing precancerous polyps. Although screening effectively reduces incidence, a notable portion of patients initially diagnosed with low-grade adenomatous polyps will still develop CRC later in life, even without the presence of known high-risk syndromes. Identifying which low-risk patients are at higher risk of progression is a critical unmet need for tailored surveillance and preventative therapeutic strategies. Traditional histological assessment of adenomas, while fundamental, may not fully capture subtle architectural or cytological features indicative of malignant potential. Advancements in digital pathology and machine learning provide an opportunity to analyze whole-slide images (WSIs) comprehensively and objectively. This study investigates whether machine learning algorithms, specifically convolutional neural networks (CNNs), can detect subtle histological features in WSIs of low-grade tubular adenomas that are predictive of a patient's long-term risk of developing colorectal cancer.

</details>


### [7] [All-in-One Conditioning for Text-to-Image Synthesis](https://arxiv.org/abs/2602.09165)
*Hirunima Jayasekara,Chuong Huynh,Yixuan Ren,Christabel Acquaye,Abhinav Shrivastava*

Main category: cs.CV

TL;DR: 论文提出基于场景图的文本到图像合成方法，通过ASQL Conditioner提升复杂提示下的语义保真与结构连贯性。


<details>
  <summary>Details</summary>
Motivation: 解决现有文本到图像合成模型在处理复杂文本输入时语义保真度和结构连贯性的不足，提升组合灵活性与多样性。

Method: 采用零样本的场景图条件机制，结合Attribute-Size-Quantity-Location (ASQL) Conditioner，通过轻量级语言模型生成视觉条件，并在推理时优化扩散生成过程。

Result: 提出的方法在保持文本-图像对齐的同时，支持轻量级、连贯且多样化的图像合成。

Conclusion: 论文提出了一种基于场景图结构的文本到图像合成新方法，通过ASQL Conditioner实现轻量级、连贯且多样化的图像生成，显著提升了模型的组合能力和文本-图像对齐效果。

Abstract: Accurate interpretation and visual representation of complex prompts involving multiple objects, attributes, and spatial relationships is a critical challenge in text-to-image synthesis. Despite recent advancements in generating photorealistic outputs, current models often struggle with maintaining semantic fidelity and structural coherence when processing intricate textual inputs. We propose a novel approach that grounds text-to-image synthesis within the framework of scene graph structures, aiming to enhance the compositional abilities of existing models. Eventhough, prior approaches have attempted to address this by using pre-defined layout maps derived from prompts, such rigid constraints often limit compositional flexibility and diversity. In contrast, we introduce a zero-shot, scene graph-based conditioning mechanism that generates soft visual guidance during inference. At the core of our method is the Attribute-Size-Quantity-Location (ASQL) Conditioner, which produces visual conditions via a lightweight language model and guides diffusion-based generation through inference-time optimization. This enables the model to maintain text-image alignment while supporting lightweight, coherent, and diverse image synthesis.

</details>


### [8] [Wearable environmental sensing to forecast how legged systems will interact with upcoming terrain](https://arxiv.org/abs/2602.09209)
*Michael D. Murray,James Tung,Richard W. Nuckols*

Main category: cs.CV

TL;DR: 研究证明，利用轻量级CNN-RNN模型从视觉数据预测足部触地前的COP和TOI是可行的，误差随预测窗口缩短而减小，模型运行效率高。


<details>
  <summary>Details</summary>
Motivation: 计算机视觉在步态环境分类中已有应用，但预测足部如何接触变化环境的能力尚未充分探索。

Method: 我们训练了一个CNN-RNN模型，在足部触地前的250ms窗口内连续预测COP和TOI。

Result: COP的MAE在150、100和50ms预测窗口分别为29.42mm、26.82mm和23.72mm；TOI的MAE分别为21.14ms、20.08ms和17.73ms。轻量级模型可在消费级笔记本电脑或边缘计算设备上以60 FPS运行。

Conclusion: 研究表明，利用轻量级模型从视觉数据预测COP和TOI是可行的，这对辅助系统中的预见性控制具有重要影响。

Abstract: Computer-vision (CV) has been used for environmental classification during gait and is often used to inform control in assistive systems; however, the ability to predict how the foot will contact a changing environment is underexplored. We evaluated the feasibility of forecasting the anterior-posterior (AP) foot center-of-pressure (COP) and time-of-impact (TOI) prior to foot-strike on a level-ground to stair-ascent transition. Eight subjects wore an RGB-D camera on their right shank and instrumented insoles while performing the task of stepping onto the stairs. We trained a CNN-RNN to forecast the COP and TOI continuously within a 250ms window prior to foot-strike, termed the forecast horizon (FH). The COP mean-absolute-error (MAE) at 150, 100, and 50ms FH was 29.42mm, 26.82, and 23.72mm respectively. The TOI MAE was 21.14, 20.08, and 17.73ms for 150, 100, and 50ms respectively. While torso velocity had no effect on the error in either task, faster toe-swing speeds prior to foot-strike were found to improve the prediction accuracy in the COP case, however, was insignificant in the TOI case. Further, more anterior foot-strikes were found to reduce COP prediction accuracy but did not affect the TOI prediction accuracy. We also found that our lightweight model was capable at running at 60 FPS on either a consumer grade laptop or an edge computing device. This study demonstrates that forecasting COP and TOI from visual data was feasible using a lightweight model, which may have important implications for anticipatory control in assistive systems.

</details>


### [9] [VLM-UQBench: A Benchmark for Modality-Specific and Cross-Modality Uncertainties in Vision Language Models](https://arxiv.org/abs/2602.09214)
*Chenyu Wang,Tianle Chen,H. M. Sabbir Ahmad,Kayhan Batmanghelich,Wenchao Li*

Main category: cs.CV

TL;DR: 研究提出VLM-UQBench基准，评估现有UQ方法在视觉语言模型中的表现，发现其模态特异性强且对实例级模糊性检测不足，需改进以实现可靠部署。


<details>
  <summary>Details</summary>
Motivation: 不确定性量化（UQ）对确保视觉语言模型（VLMs）的安全性和可靠性至关重要，但需要定位不确定性的来源（图像、文本或跨模态不对齐）。

Method: 引入VLM-UQBench基准，包含600个来自VizWiz数据集的真实样本，分为清洁、图像、文本和跨模态不确定性子集，并提出8种视觉、5种文本和3种跨模态扰动。进一步提出两种简单指标，用于量化UQ分数对这些扰动的敏感性及其与幻觉的相关性。

Result: 研究发现：（i）现有UQ方法表现出强烈的模态特异性依赖；（ii）模态特异性不确定性常与幻觉共存，但当前UQ分数提供的风险信号较弱且不一致；（iii）UQ方法在检测实例级模糊性方面表现不佳。

Conclusion: 当前的不确定性量化（UQ）方法与实际需求存在显著差距，需要更细粒度、模态感知的不确定性量化以实现可靠的视觉语言模型（VLM）部署。

Abstract: Uncertainty quantification (UQ) is vital for ensuring that vision-language models (VLMs) behave safely and reliably. A central challenge is to localize uncertainty to its source, determining whether it arises from the image, the text, or misalignment between the two. We introduce VLM-UQBench, a benchmark for modality-specific and cross-modal data uncertainty in VLMs, It consists of 600 real-world samples drawn from the VizWiz dataset, curated into clean, image-, text-, and cross-modal uncertainty subsets, and a scalable perturbation pipeline with 8 visual, 5 textual, and 3 cross-modal perturbations. We further propose two simple metrics that quantify the sensitivity of UQ scores to these perturbations and their correlation with hallucinations, and use them to evaluate a range of UQ methods across four VLMs and three datasets. Empirically, we find that: (i) existing UQ methods exhibit strong modality-specific specialization and substantial dependence on the underlying VLM, (ii) modality-specific uncertainty frequently co-occurs with hallucinations while current UQ scores provide only weak and inconsistent risk signals, and (iii) although UQ methods can rival reasoning-based chain-of-thought baselines on overt, group-level ambiguity, they largely fail to detect the subtle, instance-level ambiguity introduced by our perturbation pipeline. These results highlight a significant gap between current UQ practices and the fine-grained, modality-aware uncertainty required for reliable VLM deployment.

</details>


### [10] [VLM-Guided Iterative Refinement for Surgical Image Segmentation with Foundation Models](https://arxiv.org/abs/2602.09252)
*Ange Lou,Yamin Li,Qi Chang,Nan Xi,Luyuan Xie,Zichao Li,Tianyu Luan*

Main category: cs.CV

TL;DR: IR-SIS是一种支持自然语言描述的自优化手术图像分割系统，通过临床医生交互和自适应策略实现高性能。


<details>
  <summary>Details</summary>
Motivation: 现有手术图像分割方法局限于预定义类别，缺乏自适应优化和临床医生交互机制。

Method: IR-SIS利用微调的SAM3进行初始分割，通过视觉语言模型检测器械并评估分割质量，采用代理工作流自适应选择优化策略。

Result: 实验表明，IR-SIS在领域内和分布外数据上均达到最先进性能，临床医生交互进一步提升了效果。

Conclusion: IR-SIS建立了首个基于语言的自适应自优化手术分割框架，通过自然语言反馈支持临床医生参与，并在实验中获得最先进的性能。

Abstract: Surgical image segmentation is essential for robot-assisted surgery and intraoperative guidance. However, existing methods are constrained to predefined categories, produce one-shot predictions without adaptive refinement, and lack mechanisms for clinician interaction. We propose IR-SIS, an iterative refinement system for surgical image segmentation that accepts natural language descriptions. IR-SIS leverages a fine-tuned SAM3 for initial segmentation, employs a Vision-Language Model to detect instruments and assess segmentation quality, and applies an agentic workflow that adaptively selects refinement strategies. The system supports clinician-in-the-loop interaction through natural language feedback. We also construct a multi-granularity language-annotated dataset from EndoVis2017 and EndoVis2018 benchmarks. Experiments demonstrate state-of-the-art performance on both in-domain and out-of-distribution data, with clinician interaction providing additional improvements. Our work establishes the first language-based surgical segmentation framework with adaptive self-refinement capabilities.

</details>


### [11] [Rethinking Global Text Conditioning in Diffusion Transformers](https://arxiv.org/abs/2602.09268)
*Nikita Starodubcev,Daniil Pakhomov,Zongze Wu,Ilya Drobyshevskiy,Yuchen Liu,Zhonghao Wang,Yuqian Zhou,Zhe Lin,Dmitry Baranchuk*

Main category: cs.CV

TL;DR: 研究发现传统调制式文本条件贡献有限，但调整视角后池化嵌入可作为指导，显著提升性能且无需训练。


<details>
  <summary>Details</summary>
Motivation: 探讨调制式文本条件是否必要，以及是否能提供性能优势。

Method: 分析了调制式文本条件与注意力机制的对比，探索了池化嵌入作为指导的新应用方式。

Result: 池化嵌入在传统使用中贡献有限，但作为指导时可显著提升性能，适用于多种扩散模型和任务。

Conclusion: 研究发现，传统的调制式文本条件在性能上贡献有限，注意力机制已足够传递提示信息；但通过调整视角，将池化嵌入作为指导，可实现可控的属性偏移，带来显著性能提升。

Abstract: Diffusion transformers typically incorporate textual information via attention layers and a modulation mechanism using a pooled text embedding. Nevertheless, recent approaches discard modulation-based text conditioning and rely exclusively on attention. In this paper, we address whether modulation-based text conditioning is necessary and whether it can provide any performance advantage. Our analysis shows that, in its conventional usage, the pooled embedding contributes little to overall performance, suggesting that attention alone is generally sufficient for faithfully propagating prompt information. However, we reveal that the pooled embedding can provide significant gains when used from a different perspective-serving as guidance and enabling controllable shifts toward more desirable properties. This approach is training-free, simple to implement, incurs negligible runtime overhead, and can be applied to various diffusion models, bringing improvements across diverse tasks, including text-to-image/video generation and image editing.

</details>


### [12] [X-Mark: Saliency-Guided Robust Dataset Ownership Verification for Medical Imaging](https://arxiv.org/abs/2602.09284)
*Pranav Kulkarni,Junfeng Guo,Heng Huang*

Main category: cs.CV

TL;DR: X-Mark 是一种针对胸部X光的样本特异性水印方法，通过条件U-Net生成独特扰动，确保版权保护同时不损害诊断质量。


<details>
  <summary>Details</summary>
Motivation: 高质量医学影像数据集对深度学习模型训练至关重要，但其未经授权使用引发版权和伦理问题，现有水印方法在医学影像上效果不佳。

Method: 使用条件U-Net生成每个样本显著区域的独特扰动，并通过多组件训练目标确保水印效果、稳健性和诊断质量。

Result: 在CheXpert数据集上的实验验证了X-Mark的有效性，水印成功率（WSR）达100%，假阳性概率降低12%，并能抵抗潜在的自适应攻击。

Conclusion: X-Mark 是一种有效的胸部X光版权保护方法，通过特定样本的水印技术，在保持诊断质量的同时实现了高水印稳健性和视觉区分度。

Abstract: High-quality medical imaging datasets are essential for training deep learning models, but their unauthorized use raises serious copyright and ethical concerns. Medical imaging presents a unique challenge for existing dataset ownership verification methods designed for natural images, as static watermark patterns generated in fixed-scale images scale poorly dynamic and high-resolution scans with limited visual diversity and subtle anatomical structures, while preserving diagnostic quality. In this paper, we propose X-Mark, a sample-specific clean-label watermarking method for chest x-ray copyright protection. Specifically, X-Mark uses a conditional U-Net to generate unique perturbations within salient regions of each sample. We design a multi-component training objective to ensure watermark efficacy, robustness against dynamic scaling processes while preserving diagnostic quality and visual-distinguishability. We incorporate Laplacian regularization into our training objective to penalize high-frequency perturbations and achieve watermark scale-invariance. Ownership verification is performed in a black-box setting to detect characteristic behaviors in suspicious models. Extensive experiments on CheXpert verify the effectiveness of X-Mark, achieving WSR of 100% and reducing probability of false positives in Ind-M scenario by 12%, while demonstrating resistance to potential adaptive attacks.

</details>


### [13] [A Deep Multi-Modal Method for Patient Wound Healing Assessment](https://arxiv.org/abs/2602.09315)
*Subba Reddy Oota,Vijay Rowtula,Shahid Mohammed,Jeffrey Galitz,Minghsun Liu,Manish Gupta*

Main category: cs.CV

TL;DR: 本文提出一种深度多模态方法，结合伤口变量和图像预测住院风险，利用迁移学习预测愈合轨迹，旨在早期发现复杂性并减少诊断时间。


<details>
  <summary>Details</summary>
Motivation: 患者住院是伤口护理成本高的主要因素之一，延迟治疗、患者不配合或现有共病条件可能导致伤口恶化并最终住院。现有研究主要关注基于不同伤口类型的愈合轨迹。

Method: 采用基于迁移学习的伤口评估解决方案，预测伤口变量及其愈合轨迹。

Result: 开发了一种新颖模型，可预测伤口变量和愈合轨迹，有助于早期发现可能影响愈合过程的伤口复杂性。

Conclusion: 本文提出了一种深度多模态方法，通过结合伤口变量和伤口图像预测患者住院风险，旨在早期发现伤口复杂性，减少临床医生诊断时间。

Abstract: Hospitalization of patients is one of the major factors for high wound care costs. Most patients do not acquire a wound which needs immediate hospitalization. However, due to factors such as delay in treatment, patient's non-compliance or existing co-morbid conditions, an injury can deteriorate and ultimately lead to patient hospitalization. In this paper, we propose a deep multi-modal method to predict the patient's risk of hospitalization. Our goal is to predict the risk confidently by collectively using the wound variables and wound images of the patient. Existing works in this domain have mainly focused on healing trajectories based on distinct wound types. We developed a transfer learning-based wound assessment solution, which can predict both wound variables from wound images and their healing trajectories, which is our primary contribution. We argue that the development of a novel model can help in early detection of the complexities in the wound, which might affect the healing process and also reduce the time spent by a clinician to diagnose the wound.

</details>


### [14] [GAFR-Net: A Graph Attention and Fuzzy-Rule Network for Interpretable Breast Cancer Image Classification](https://arxiv.org/abs/2602.09318)
*Lin-Guo Gao,Suxing Liu*

Main category: cs.CV

TL;DR: GAFR-Net是一种结合图注意力和模糊规则的可解释网络，用于弱监督的乳腺癌组织病理学图像分类，性能优于现有方法且具有透明诊断逻辑。


<details>
  <summary>Details</summary>
Motivation: 传统深度学习架构在有限标注下性能下降且缺乏可解释性，阻碍了临床整合。为解决这些问题，提出了GAFR-Net。

Method: GAFR-Net构建了相似性驱动的图表示来建模样本间关系，并采用多头图注意力机制捕捉异质组织结构的复杂关系特征，同时通过可微分模糊规则模块将拓扑描述符编码为人类可理解的诊断逻辑。

Result: 在三个基准数据集（BreakHis、Mini-DDSM和ICIAR2018）上的广泛评估表明，GAFR-Net在多种放大倍率和分类任务中均优于现有方法。

Conclusion: GAFR-Net通过结合图注意力和模糊规则网络，在弱监督条件下实现了乳腺癌组织病理学图像的高效分类，其透明化的诊断逻辑和优异的性能表现验证了其作为临床决策支持工具的潜力。

Abstract: Accurate classification of breast cancer histopathology images is pivotal for early oncological diagnosis and therapeutic intervention.However, conventional deep learning architectures often encounter performance degradation under limited annotations and suffer from a "blackbox" nature, hindering their clinical integration. To mitigate these limitations, we propose GAFRNet, a robust and interpretable Graph Attention and FuzzyRule Network specifically engineered for histopathology image classification with scarce supervision. GAFRNet constructs a similarity-driven graph representation to model intersample relationships and employs a multihead graph attention mechanism to capture complex relational features across heterogeneous tissue structures.Concurrently, a differentiable fuzzy-rule module encodes intrinsic topological descriptorsincluding node degree, clustering coefficient, and label consistencyinto explicit, human-understandable diagnostic logic. This design establishes transparent "IF-THEN" mappings that mimic the heuristic deduction process of medical experts, providing clear reasoning behind each prediction without relying on post-hoc attribution methods. Extensive evaluations on three benchmark datasets (BreakHis, Mini-DDSM, and ICIAR2018) demonstrate that GAFR-Net consistently outperforms various state-of-the-art methods across multiple magnifications and classification tasks. These results validate the superior generalization and practical utility of GAFR-Net as a reliable decision-support tool for weakly supervised medical image analysis.

</details>


### [15] [Deep Modeling and Interpretation for Bladder Cancer Classification](https://arxiv.org/abs/2602.09324)
*Ahmad Chaddad,Yihang Wu,Xianrui Chen*

Main category: cs.CV

TL;DR: 本研究评估了多种深度模型在膀胱癌分类中的表现，发现ViT在校准和可解释性上优于CNN，但无模型能完全解决可解释性问题。


<details>
  <summary>Details</summary>
Motivation: 由于医学影像中异常区域仅占图像的一小部分，现有深度模型在医学影像分类任务中可能表现不佳，这促使本研究探索最新模型在膀胱癌分类任务中的表现。

Method: 本研究评估了13种深度模型（4种CNN和8种基于Transformer的模型），包括标准分类、校准分析和使用GradCAM++评估模型的可解释性。

Result: 实验结果显示ConvNext系列在膀胱癌图像分类中泛化能力有限（准确率约60%），而ViT在校准效果上优于ConvNext和Swin Transformer系列。

Conclusion: ConvNext系列适用于分布内样本，而ViT及其变体更适合解释分布外样本，没有模型能提供通用的可解释解决方案。

Abstract: Deep models based on vision transformer (ViT) and convolutional neural network (CNN) have demonstrated remarkable performance on natural datasets. However, these models may not be similar in medical imaging, where abnormal regions cover only a small portion of the image. This challenge motivates this study to investigate the latest deep models for bladder cancer classification tasks. We propose the following to evaluate these deep models: 1) standard classification using 13 models (four CNNs and eight transormer-based models), 2) calibration analysis to examine if these models are well calibrated for bladder cancer classification, and 3) we use GradCAM++ to evaluate the interpretability of these models for clinical diagnosis. We simulate $\sim 300$ experiments on a publicly multicenter bladder cancer dataset, and the experimental results demonstrate that the ConvNext series indicate limited generalization ability to classify bladder cancer images (e.g., $\sim 60\%$ accuracy). In addition, ViTs show better calibration effects compared to ConvNext and swin transformer series. We also involve test time augmentation to improve the models interpretability. Finally, no model provides a one-size-fits-all solution for a feasible interpretable model. ConvNext series are suitable for in-distribution samples, while ViT and its variants are suitable for interpreting out-of-distribution samples.

</details>


### [16] [Kyrtos: A methodology for automatic deep analysis of graphic charts with curves in technical documents](https://arxiv.org/abs/2602.09337)
*Michail S. Alexiou,Nikolaos G. Bourbakis*

Main category: cs.CV

TL;DR: Kyrtos方法通过聚类和图形分析自动识别技术文档中的曲线图表，并将其转换为属性图和自然语言，评估显示其高准确性。


<details>
  <summary>Details</summary>
Motivation: 技术文档中的图表包含宝贵知识，但对其整体理解依赖于对图形、表格、文本等多模态的准确分析及其关联。

Method: 采用基于聚类的方法识别曲线线段的中点，分析部分解析提取的曲线线段以捕捉方向、趋势等行为特征，并将这些关联转换为属性图和自然语言文本。

Result: 广泛的评估结果表明，Kyrtos在识别和分析多函数图表时，通过结构相似性测量展示了高准确性。

Conclusion: Kyrtos方法通过将识别到的曲线段关系转换为属性图，并进一步表达为自然语言文本和随机Petri网图，有效保留了曲线的结构特性，并在多函数图表中展示了高准确性。

Abstract: Deep Understanding of Technical Documents (DUTD) has become a very attractive field with great potential due to large amounts of accumulated documents and the valuable knowledge contained in them. In addition, the holistic understanding of technical documents depends on the accurate analysis of its particular modalities, such as graphics, tables, diagrams, text, etc. and their associations. In this paper, we introduce the Kyrtos methodology for the automatic recognition and analysis of charts with curves in graphics images of technical documents. The recognition processing part adopts a clustering based approach to recognize middle-points that delimit the line-segments that construct the illustrated curves. The analysis processing part parses the extracted line-segments of curves to capture behavioral features such as direction, trend and etc. These associations assist the conversion of recognized segments' relations into attributed graphs, for the preservation of the curves' structural characteristics. The graph relations are also are expressed into natural language (NL) text sentences, enriching the document's text and facilitating their conversion into Stochastic Petri-net (SPN) graphs, which depict the internal functionality represented in the chart image. Extensive evaluation results demonstrate the accuracy of Kyrtos' recognition and analysis methods by measuring the structural similarity between input chart curves and the approximations generated by Kyrtos for charts with multiple functions.

</details>


### [17] [Impact of domain adaptation in deep learning for medical image classifications](https://arxiv.org/abs/2602.09355)
*Yihang Wu,Ahmad Chaddad*

Main category: cs.CV

TL;DR: DA技术在医学图像分析中能提升模型性能、抗噪能力和可解释性，尤其在脑肿瘤数据集上效果显著，但在联邦学习中效果有限。


<details>
  <summary>Details</summary>
Motivation: 领域自适应（DA）是机器学习中的一个重要研究方向，旨在解决模型在不同领域间迁移时的性能下降问题。本研究旨在探索DA技术在医学图像分析中的实际应用效果。

Method: 本研究采用了10种深度学习模型模拟常见的DA技术，并在四个医学图像数据集上进行了测试，涵盖了多模态、噪声数据、联邦学习、可解释性分析和分类器校准等多种场景。

Result: 实验结果显示，在脑肿瘤数据集上使用ResNet34结合DA技术，模型性能提升了4.7%；DA还能减少高斯噪声的影响，提升约3%的准确率；在联邦学习框架中引入DA效果有限（仅提升约0.3%）；此外，DA还通过gradcam++技术提升了模型的可解释性，并在多模态数据集上降低了预期校准误差（ECE）约2%。

Conclusion: 使用领域自适应（DA）技术可以显著提升模型在医学图像数据集上的性能，尤其在脑肿瘤数据集上表现最佳，同时还能提高模型的可解释性和校准性。

Abstract: Domain adaptation (DA) is a quickly expanding area in machine learning that involves adjusting a model trained in one domain to perform well in another domain. While there have been notable progressions, the fundamental concept of numerous DA methodologies has persisted: aligning the data from various domains into a shared feature space. In this space, knowledge acquired from labeled source data can improve the model training on target data that lacks sufficient labels. In this study, we demonstrate the use of 10 deep learning models to simulate common DA techniques and explore their application in four medical image datasets. We have considered various situations such as multi-modality, noisy data, federated learning (FL), interpretability analysis, and classifier calibration. The experimental results indicate that using DA with ResNet34 in a brain tumor (BT) data set results in an enhancement of 4.7\% in model performance. Similarly, the use of DA can reduce the impact of Gaussian noise, as it provides $\sim 3\%$ accuracy increase using ResNet34 on a BT dataset. Furthermore, simply introducing DA into FL framework shows limited potential (e.g., $\sim 0.3\%$ increase in performance) for skin cancer classification. In addition, the DA method can improve the interpretability of the models using the gradcam++ technique, which offers clinical values. Calibration analysis also demonstrates that using DA provides a lower expected calibration error (ECE) value $\sim 2\%$ compared to CNN alone on a multi-modality dataset.

</details>


### [18] [Fully Differentiable Bidirectional Dual-Task Synergistic Learning for Semi-Supervised 3D Medical Image Segmentation](https://arxiv.org/abs/2602.09378)
*Jun Li*

Main category: cs.CV

TL;DR: 提出DBiSL框架，通过双向协同学习提升半监督图像分割性能，实验显示其在基准数据集上达到最先进水平。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法局限于单向交互机制（如回归到分割）的问题，充分利用在线双向跨任务协作的潜力。

Method: 提出了完全可微的双向协同学习（DBiSL）框架，整合并增强了监督学习、一致性正则化、伪监督学习和不确定性估计四个关键SSL组件。

Result: 在两个基准数据集上的实验证明了该方法的先进性能。

Conclusion: DBiSL框架在双任务驱动的半监督学习中展现了最先进的性能，为统一的SSL框架设计提供了新见解，并为更广泛的计算机视觉应用提供了通用的多任务学习框架。

Abstract: Semi-supervised learning relaxes the need of large pixel-wise labeled datasets for image segmentation by leveraging unlabeled data. The scarcity of high-quality labeled data remains a major challenge in medical image analysis due to the high annotation costs and the need for specialized clinical expertise. Semi-supervised learning has demonstrated significant potential in addressing this bottleneck, with pseudo-labeling and consistency regularization emerging as two predominant paradigms. Dual-task collaborative learning, an emerging consistency-aware paradigm, seeks to derive supplementary supervision by establishing prediction consistency between related tasks. However, current methodologies are limited to unidirectional interaction mechanisms (typically regression-to-segmentation), as segmentation results can only be transformed into regression outputs in an offline manner, thereby failing to fully exploit the potential benefits of online bidirectional cross-task collaboration. Thus, we propose a fully Differentiable Bidirectional Synergistic Learning (DBiSL) framework, which seamlessly integrates and enhances four critical SSL components: supervised learning, consistency regularization, pseudo-supervised learning, and uncertainty estimation. Experiments on two benchmark datasets demonstrate our method's state-of-the-art performance. Beyond technical contributions, this work provides new insights into unified SSL framework design and establishes a new architectural foundation for dual-task-driven SSL, while offering a generic multitask learning framework applicable to broader computer vision applications. The code will be released on github upon acceptance.

</details>


### [19] [Single-Slice-to-3D Reconstruction in Medical Imaging and Natural Objects: A Comparative Benchmark with SAM 3D](https://arxiv.org/abs/2602.09407)
*Yan Luo,Advaith Ravishankar,Serena Liu,Yutong Yang,Mengyu Wang*

Main category: cs.CV

TL;DR: The study benchmarks five image-to-3D models on medical data, finding moderate performance due to depth ambiguity, with SAM3D performing best. Multi-view reconstruction is suggested for better reliability.


<details>
  <summary>Details</summary>
Motivation: To address the high cost and long wait times of volumetric imaging in medical diagnosis and treatment planning by evaluating the transferability of geometric priors from natural to medical data in single-slice image-to-3D reconstruction.

Method: A controlled zero-shot benchmark was conducted across five state-of-the-art image-to-3D models (SAM3D, Hunyuan3D-2.1, Direct3D, Hi3DGen, TripoSG) on six medical and two natural datasets, using voxel-based and point cloud distance metrics.

Result: Voxel-based overlap was moderate across models, indicating depth reconstruction challenges. SAM3D showed the strongest topological similarity to ground truth, while other models tended to oversimplify reconstructions.

Conclusion: The study highlights the limitations of single-slice medical reconstruction and suggests multi-view image-to-3D reconstruction as a solution to improve reliability in medical 3D inference.

Abstract: A 3D understanding of anatomy is central to diagnosis and treatment planning, yet volumetric imaging remains costly with long wait times. Image-to-3D foundations models can solve this issue by reconstructing 3D data from 2D modalites. Current foundation models are trained on natural image distributions to reconstruct naturalistic objects from a single image by leveraging geometric priors across pixels. However, it is unclear whether these learned geometric priors transfer to medical data. In this study, we present a controlled zero-shot benchmark of single slice medical image-to-3D reconstruction across five state-of-the-art image-to-3D models: SAM3D, Hunyuan3D-2.1, Direct3D, Hi3DGen, and TripoSG. These are evaluated across six medical datasets spanning anatomical and pathological structures and two natrual datasets, using voxel based metrics and point cloud distance metrics. Across medical datasets, voxel based overlap remains moderate for all models, consistent with a depth reconstruction failure mode when inferring volume from a single slice. In contrast, global distance metrics show more separation between methods: SAM3D achieves the strongest overall topological similarity to ground truth medical 3D data, while alternative models are more prone to over-simplication of reconstruction. Our results quantify the limits of single-slice medical reconstruction and highlight depth ambiguity caused by the planar nature of 2D medical data, motivating multi-view image-to-3D reconstruction to enable reliable medical 3D inference.

</details>


### [20] [K-Sort Eval: Efficient Preference Evaluation for Visual Generation via Corrected VLM-as-a-Judge](https://arxiv.org/abs/2602.09411)
*Zhikai Li,Jiatong Li,Xuewen Liu,Wangbo Zhao,Pan Du,Kaicheng Zhou,Qingyi Gu,Yang You,Zhen Dong,Kurt Keutzer*

Main category: cs.CV

TL;DR: K-Sort Eval通过VLM结合后验校正和动态匹配，高效可靠地评估视觉生成模型，显著降低人工成本。


<details>
  <summary>Details</summary>
Motivation: 现有基于人工偏好的评估方法成本高且扩展性差，而直接使用VLM存在幻觉和偏差问题，需改进。

Method: 提出K-Sort Eval框架，结合后验校正和动态匹配策略，利用VLM进行模型评估。

Result: 实验表明，K-Sort Eval在90次模型运行内即可达到与人工评估一致的结果，证明了其高效性和可靠性。

Conclusion: K-Sort Eval框架通过后验校正和动态匹配策略，实现了高效且可靠的视觉生成模型评估，与人工评估结果一致且显著提高了效率。

Abstract: The rapid development of visual generative models raises the need for more scalable and human-aligned evaluation methods. While the crowdsourced Arena platforms offer human preference assessments by collecting human votes, they are costly and time-consuming, inherently limiting their scalability. Leveraging vision-language model (VLMs) as substitutes for manual judgments presents a promising solution. However, the inherent hallucinations and biases of VLMs hinder alignment with human preferences, thus compromising evaluation reliability. Additionally, the static evaluation approach lead to low efficiency. In this paper, we propose K-Sort Eval, a reliable and efficient VLM-based evaluation framework that integrates posterior correction and dynamic matching. Specifically, we curate a high-quality dataset from thousands of human votes in K-Sort Arena, with each instance containing the outputs and rankings of K models. When evaluating a new model, it undergoes (K+1)-wise free-for-all comparisons with existing models, and the VLM provide the rankings. To enhance alignment and reliability, we propose a posterior correction method, which adaptively corrects the posterior probability in Bayesian updating based on the consistency between the VLM prediction and human supervision. Moreover, we propose a dynamic matching strategy, which balances uncertainty and diversity to maximize the expected benefit of each comparison, thus ensuring more efficient evaluation. Extensive experiments show that K-Sort Eval delivers evaluation results consistent with K-Sort Arena, typically requiring fewer than 90 model runs, demonstrating both its efficiency and reliability.

</details>


### [21] [LARV: Data-Free Layer-wise Adaptive Rescaling Veneer for Model Merging](https://arxiv.org/abs/2602.09413)
*Xinyu Wang,Ke Deng,Fei Dou,Jinbo Bi,Jin Lu*

Main category: cs.CV

TL;DR: LARV是一种层间自适应缩放方法，通过抑制浅层干扰和放大深层对齐，显著提升模型合并性能。


<details>
  <summary>Details</summary>
Motivation: 现有任务向量合并方法忽视了大型视觉变换器中层间异质性，导致浅层敏感干扰和深层任务特征不稳定。

Method: LARV是一种无需训练、无需数据的层间自适应缩放方法，通过简单的确定性调度，抑制浅层干扰并放大深层对齐。

Result: 在FusionBench上，LARV显著提升了所有任务向量基线的性能，例如Iso-C + LARV在ViT-B/32上达到85.9%，ViT-B/16上89.2%，ViT-L/14上92.6%。

Conclusion: LARV通过层间自适应调整，显著提升了模型合并的性能，使其成为一种鲁棒的、层感知的过程，而非均匀处理。

Abstract: Model merging aims to combine multiple fine-tuned models into a single multi-task model without access to training data. Existing task-vector merging methods such as TIES, TSV-M, and Iso-C/CTS differ in their aggregation rules but treat all layers nearly uniformly. This assumption overlooks the strong layer-wise heterogeneity in large vision transformers, where shallow layers are sensitive to interference while deeper layers encode stable task-specific features. We introduce LARV, a training-free, data-free, merger-agnostic Layer-wise Adaptive Rescaling Veneer that plugs into any task-vector merger and assigns a per-layer scale to each task vector before aggregation, and show it consistently boosts diverse merging rules. LARV adaptively suppresses shallow-layer interference and amplifies deeper-layer alignment using a simple deterministic schedule, requiring no retraining or modification to existing mergers. To our knowledge, this is the first work to perform layer-aware scaling for task-vector merging. LARV computes simple data-free layer proxies and turns them into scales through a lightweight rule; we study several instantiations within one framework (e.g., tiered two/three-level scaling with fixed values, or continuous mappings) and show that tiered choices offer the best robustness, while continuous mappings remain an ablation. LARV is orthogonal to the base merger and adds negligible cost. On FusionBench with Vision Transformers, LARV consistently improves all task-vector baselines across 8/14/20-task settings; for example, Iso-C + LARV reaches 85.9% on ViT-B/32, 89.2% on ViT-B/16, and 92.6% on ViT-L/14. Layerwise analysis and corruption tests further indicate that LARV suppresses shallow-layer interference while modestly amplifying deeper, task-stable features, turning model merging into a robust, layer-aware procedure rather than a uniform one.

</details>


### [22] [Stability and Concentration in Nonlinear Inverse Problems with Block-Structured Parameters: Lipschitz Geometry, Identifiability, and an Application to Gaussian Splatting](https://arxiv.org/abs/2602.09415)
*Joe-Mei Feng,Hsin-Hsiung Kao*

Main category: cs.CV

TL;DR: 该论文提出了一个算子理论框架，用于分析非线性逆问题的稳定性和统计集中，特别适用于现代成像和可微分渲染中的高维问题。


<details>
  <summary>Details</summary>
Motivation: 研究动机在于解决现代成像和可微分渲染中出现的高维非线性逆问题的稳定性和统计集中问题。

Method: 通过结合块状Lipschitz几何、局部可识别性和亚高斯噪声的统一假设，建立了确定性稳定性不等式、最小二乘失配函数的全局Lipschitz边界以及非渐近集中估计。

Result: 结果表明，参数误差界限具有高概率，且仅依赖于前向算子，与任何特定重建算法无关。具体实例中，高斯溅射渲染算子验证了所提出的假设，并导出了控制其Lipschitz连续性和分辨率依赖可观测性的显式常数。

Conclusion: 该论文为非线性逆问题中的稳定性和统计集中提供了一个算子理论框架，揭示了在高维非线性逆问题中操作层面的限制。

Abstract: We develop an operator-theoretic framework for stability and statistical concentration in nonlinear inverse problems with block-structured parameters. Under a unified set of assumptions combining blockwise Lipschitz geometry, local identifiability, and sub-Gaussian noise, we establish deterministic stability inequalities, global Lipschitz bounds for least-squares misfit functionals, and nonasymptotic concentration estimates. These results yield high-probability parameter error bounds that are intrinsic to the forward operator and independent of any specific reconstruction algorithm. As a concrete instantiation, we verify that the Gaussian Splatting rendering operator satisfies the proposed assumptions and derive explicit constants governing its Lipschitz continuity and resolution-dependent observability. This leads to a fundamental stability--resolution tradeoff, showing that estimation error is inherently constrained by the ratio between image resolution and model complexity. Overall, the analysis characterizes operator-level limits for a broad class of high-dimensional nonlinear inverse problems arising in modern imaging and differentiable rendering.

</details>


### [23] [Bridging the Modality Gap in Roadside LiDAR: A Training-Free Vision-Language Model Framework for Vehicle Classification](https://arxiv.org/abs/2602.09425)
*Yiqiao Li,Bo Shang,Jie Wei*

Main category: cs.CV

TL;DR: 该研究提出了一种无需参数微调的VLM适配框架，通过深度感知图像生成将稀疏LiDAR数据转换为2D代理，显著减少标注需求，在少样本条件下实现竞争性卡车分类准确率，并验证了其作为冷启动策略的实用性。


<details>
  <summary>Details</summary>
Motivation: 当前基于LiDAR的细粒度卡车分类方法因依赖监督深度学习和劳动密集型手动标注而面临可扩展性挑战，视觉语言模型（VLM）虽具有少样本泛化的潜力，但其在路边LiDAR中的应用受到稀疏3D点云与密集2D图像之间的模态差距限制。

Method: 提出了一种新的深度感知图像生成流水线，通过噪声去除、时空配准、方向校正、形态学操作和各向异性平滑处理，将稀疏、遮挡的LiDAR扫描转换为深度编码的2D视觉代理。

Result: 在20个车辆类别的真实数据集上验证，该方法仅需每类16-30个样本即可达到竞争性分类准确率，并在极低样本（k < 4）下表现出“语义锚定”效应，同时在冷启动策略中展示了VLM生成标签用于引导轻量监督模型的有效性。

Conclusion: 该框架通过将现成的视觉语言模型（VLM）应用于细粒度卡车分类，无需参数微调，显著降低了初始手动标注的密集需求，为智能交通系统（ITS）提供了一种实用的方法。

Abstract: Fine-grained truck classification is critical for intelligent transportation systems (ITS), yet current LiDAR-based methods face scalability challenges due to their reliance on supervised deep learning and labor-intensive manual annotation. Vision-Language Models (VLMs) offer promising few-shot generalization, but their application to roadside LiDAR is limited by a modality gap between sparse 3D point clouds and dense 2D imagery. We propose a framework that bridges this gap by adapting off-the-shelf VLMs for fine-grained truck classification without parameter fine-tuning. Our new depth-aware image generation pipeline applies noise removal, spatial and temporal registration, orientation rectification, morphological operations, and anisotropic smoothing to transform sparse, occluded LiDAR scans into depth-encoded 2D visual proxies. Validated on a real-world dataset of 20 vehicle classes, our approach achieves competitive classification accuracy with as few as 16-30 examples per class, offering a scalable alternative to data-intensive supervised baselines. We further observe a "Semantic Anchor" effect: text-based guidance regularizes performance in ultra-low-shot regimes $k < 4$, but degrades accuracy in more-shot settings due to semantic mismatch. Furthermore, we demonstrate the efficacy of this framework as a Cold Start strategy, using VLM-generated labels to bootstrap lightweight supervised models. Notably, the few-shot VLM-based model achieves over correct classification rate of 75 percent for specific drayage categories (20ft, 40ft, and 53ft containers) entirely without the costly training or fine-tuning, significantly reducing the intensive demands of initial manual labeling, thus achieving a method of practical use in ITS applications.

</details>


### [24] [SceneReVis: A Self-Reflective Vision-Grounded Framework for 3D Indoor Scene Synthesis via Multi-turn RL](https://arxiv.org/abs/2602.09432)
*Yang Zhao,Shizhao Sun,Meisheng Zhang,Yingdong Shi,Xubo Yang,Jiang Bian*

Main category: cs.CV

TL;DR: SceneReVis通过迭代‘诊断-行动’循环和多模态反馈，显著提升3D场景合成的准确性和鲁棒性，实验证明其性能优越。


<details>
  <summary>Details</summary>
Motivation: 解决现有单次3D场景合成方法因缺乏深思熟虑的推理而导致的空间幻觉（如碰撞）问题。

Method: 提出了SceneReVis框架，结合了监督微调和代理强化学习的双阶段训练方法，并构建了SceneChain-12k数据集以支持逐步推理。

Result: 实验表明，SceneReVis在高保真生成和目标导向优化方面达到了最先进的性能，且对长尾领域具有强大的泛化能力。

Conclusion: SceneReVis通过引入‘诊断-行动’循环和多模态反馈，显著提升了3D场景合成的准确性和鲁棒性，尤其在处理空间冲突和长尾领域方面表现出色。

Abstract: Current one-pass 3D scene synthesis methods often suffer from spatial hallucinations, such as collisions, due to a lack of deliberative reasoning. To bridge this gap, we introduce SceneReVis, a vision-grounded self-reflection framework that employs an iterative ``diagnose-and-act'' loop to explicitly intercept and resolve spatial conflicts using multi-modal feedback. To support this step-wise paradigm, we construct SceneChain-12k, a large-scale dataset of causal construction trajectories derived through a novel reverse engineering pipeline. We further propose a two-stage training recipe that transitions from Supervised Fine-Tuning to Agentic Reinforcement Learning, evolving the model into an active spatial planner. Extensive experiments demonstrate that SceneReVis achieves state-of-the-art performance in high-fidelity generation and goal-oriented optimization, with robust generalization to long-tail domains.

</details>


### [25] [Fine-T2I: An Open, Large-Scale, and Diverse Dataset for High-Quality T2I Fine-Tuning](https://arxiv.org/abs/2602.09439)
*Xu Ma,Yitian Zhang,Qihua Dong,Yun Fu*

Main category: cs.CV

TL;DR: Fine-T2I是一个高质量、开放的T2I微调数据集，结合合成与真实图像，严格筛选后包含600万对数据，显著提升模型性能。


<details>
  <summary>Details</summary>
Motivation: 当前公开的T2I微调数据集普遍存在分辨率低、文本-图像对齐差或多样性有限的问题，导致开源模型与企业级模型之间存在性能差距。

Method: 结合现代模型生成的合成图像和专业摄影师精心挑选的真实图像，经过严格筛选（95%的候选被移除），最终构建了一个包含600万文本-图像对、约2TB的大规模数据集。

Result: 在多种预训练扩散和自回归模型上微调Fine-T2I，均能提升生成质量和指令遵循能力，经人类评估、视觉比较和自动指标验证。

Conclusion: Fine-T2I数据集通过高质量和开放的特性，显著提升了文本到图像（T2I）微调的性能，缩小了开源研究模型与企业级模型之间的差距。

Abstract: High-quality and open datasets remain a major bottleneck for text-to-image (T2I) fine-tuning. Despite rapid progress in model architectures and training pipelines, most publicly available fine-tuning datasets suffer from low resolution, poor text-image alignment, or limited diversity, resulting in a clear performance gap between open research models and enterprise-grade models. In this work, we present Fine-T2I, a large-scale, high-quality, and fully open dataset for T2I fine-tuning. Fine-T2I spans 10 task combinations, 32 prompt categories, 11 visual styles, and 5 prompt templates, and combines synthetic images generated by strong modern models with carefully curated real images from professional photographers. All samples are rigorously filtered for text-image alignment, visual fidelity, and prompt quality, with over 95% of initial candidates removed. The final dataset contains over 6 million text-image pairs, around 2 TB on disk, approaching the scale of pretraining datasets while maintaining fine-tuning-level quality. Across a diverse set of pretrained diffusion and autoregressive models, fine-tuning on Fine-T2I consistently improves both generation quality and instruction adherence, as validated by human evaluation, visual comparison, and automatic metrics. We release Fine-T2I under an open license to help close the data gap in T2I fine-tuning in the open community.

</details>


### [26] [A Scoping Review of Deep Learning for Urban Visual Pollution and Proposal of a Real-Time Monitoring Framework with a Visual Pollution Index](https://arxiv.org/abs/2602.09446)
*Mohammad Masudur Rahman,Md. Rashedur Rahman,Ashraful Islam,Saadia B Alam,M Ashraful Amin*

Main category: cs.CV

TL;DR: 本综述总结了基于深度学习的城市视觉污染检测方法，提出一个整合视觉污染指数的管理框架，呼吁统一系统以支持可持续城市美学。


<details>
  <summary>Details</summary>
Motivation: 城市视觉污染（UVP）已成为一个关键问题，但自动检测和应用研究仍较为分散。

Method: 遵循PRISMA-ScR指南，系统检索和审查了七个学术数据库（Scopus、Web of Science、IEEE Xplore、ACM DL、ScienceDirect、SpringerNatureLink和Wiley），筛选出26篇文章。

Result: 大多数研究集中于特定污染物类别，并采用YOLO、Faster R-CNN和EfficientDet等架构的变体。现有数据集局限于特定区域且缺乏标准化分类。少数研究将检测整合到实时应用系统中，但地理分布不均。

Conclusion: 本综述强调了需要一个统一的UVP管理系统，包括污染物分类、跨城市基准数据集、通用深度学习模型以及支持可持续城市美学和提升城市居民福祉的评估指数。

Abstract: Urban Visual Pollution (UVP) has emerged as a critical concern, yet research on automatic detection and application remains fragmented. This scoping review maps the existing deep learning-based approaches for detecting, classifying, and designing a comprehensive application framework for visual pollution management. Following the PRISMA-ScR guidelines, seven academic databases (Scopus, Web of Science, IEEE Xplore, ACM DL, ScienceDirect, SpringerNatureLink, and Wiley) were systematically searched and reviewed, and 26 articles were found. Most research focuses on specific pollutant categories and employs variations of YOLO, Faster R-CNN, and EfficientDet architectures. Although several datasets exist, they are limited to specific areas and lack standardized taxonomies. Few studies integrate detection into real-time application systems, yet they tend to be geographically skewed. We proposed a framework for monitoring visual pollution that integrates a visual pollution index to assess the severity of visual pollution for a certain area. This review highlights the need for a unified UVP management system that incorporates pollutant taxonomy, a cross-city benchmark dataset, a generalized deep learning model, and an assessment index that supports sustainable urban aesthetics and enhances the well-being of urban dwellers.

</details>


### [27] [Look-Ahead and Look-Back Flows: Training-Free Image Generation with Trajectory Smoothing](https://arxiv.org/abs/2602.09449)
*Yan Luo,Henry Huang,Todd Y. Zhou,Mengyu Wang*

Main category: cs.CV

TL;DR: 本文提出两种无需训练的潜在轨迹调整方法（Look-Ahead和Look-Back），通过直接优化潜在空间生成路径减少误差，实验证明其在多个数据集上优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有方法通过调整流速度场（$v$）改进图像生成，但会引入误差并沿生成路径传播。而潜在轨迹（$z$）的调整可通过预训练速度网络自然校正，减少误差累积。

Method: 提出了两种基于未来和过去速度信息（$v$和$z$）的无需训练潜在轨迹调整方法：Look-Ahead（使用曲率门控权重平均当前和下一步潜在）和Look-Back（使用指数移动平均平滑潜在）。

Result: 在COCO17、CUB-200和Flickr30K等多个数据集上，所提方法在广泛实验和综合评价指标中显著优于各种最先进模型。

Conclusion: 本文提出的两种无需训练的潜在轨迹调整方法（Look-Ahead和Look-Back）显著优于现有技术，通过直接优化潜在空间中的生成路径，减少了误差累积。

Abstract: Recent advances have reformulated diffusion models as deterministic ordinary differential equations (ODEs) through the framework of flow matching, providing a unified formulation for the noise-to-data generative process. Various training-free flow matching approaches have been developed to improve image generation through flow velocity field adjustment, eliminating the need for costly retraining. However, Modifying the velocity field $v$ introduces errors that propagate through the full generation path, whereas adjustments to the latent trajectory $z$ are naturally corrected by the pretrained velocity network, reducing error accumulation. In this paper, we propose two complementary training-free latent-trajectory adjustment approaches based on future and past velocity $v$ and latent trajectory $z$ information that refine the generative path directly in latent space. We propose two training-free trajectory smoothing schemes: \emph{Look-Ahead}, which averages the current and next-step latents using a curvature-gated weight, and \emph{Look-Back}, which smoothes latents using an exponential moving average with decay. We demonstrate through extensive experiments and comprehensive evaluation metrics that the proposed training-free trajectory smoothing models substantially outperform various state-of-the-art models across multiple datasets including COCO17, CUB-200, and Flickr30K.

</details>


### [28] [ArtifactLens: Hundreds of Labels Are Enough for Artifact Detection with VLMs](https://arxiv.org/abs/2602.09475)
*James Burgess,Rameen Abdal,Dan Stoddart,Sergey Tulyakov,Serena Yeung-Levy,Kuan-Chieh Jackson Wang*

Main category: cs.CV

TL;DR: ArtifactLens利用预训练VLM的知识，通过少量标注数据和创新架构，高效检测图像生成器的伪影，并在多个数据集上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现代图像生成器产生的图像非常逼真，但伪影（如扭曲的手或物体）仍暴露其合成来源。检测这些伪影对于基准测试和改进生成器至关重要，但现有方法需要大量标注数据，成本高昂。

Method: ArtifactLens采用多组件架构，结合上下文学习和文本指令优化，并引入了新颖的改进。

Result: ArtifactLens在五个人类伪影基准测试中达到最先进水平，且仅需每个伪影类别几百个标注示例。

Conclusion: ArtifactLens通过少量标注数据和创新的多组件架构，在多个数据集上实现了最先进的性能，并能推广到其他类型的伪影和AIGC检测任务。

Abstract: Modern image generators produce strikingly realistic images, where only artifacts like distorted hands or warped objects reveal their synthetic origin. Detecting these artifacts is essential: without detection, we cannot benchmark generators or train reward models to improve them. Current detectors fine-tune VLMs on tens of thousands of labeled images, but this is expensive to repeat whenever generators evolve or new artifact types emerge. We show that pretrained VLMs already encode the knowledge needed to detect artifacts - with the right scaffolding, this capability can be unlocked using only a few hundred labeled examples per artifact category. Our system, ArtifactLens, achieves state-of-the-art on five human artifact benchmarks (the first evaluation across multiple datasets) while requiring orders of magnitude less labeled data. The scaffolding consists of a multi-component architecture with in-context learning and text instruction optimization, with novel improvements to each. Our methods generalize to other artifact types - object morphology, animal anatomy, and entity interactions - and to the distinct task of AIGC detection.

</details>


### [29] [FD-DB: Frequency-Decoupled Dual-Branch Network for Unpaired Synthetic-to-Real Domain Translation](https://arxiv.org/abs/2602.09476)
*Chuanhai Zang,Jiabao Hu,XW Song*

Main category: cs.CV

TL;DR: FD-DB是一种频率解耦的双分支模型，通过可解释的低频编辑和高频残差补偿，有效减少合成数据到真实数据的域偏移，提升下游任务性能。


<details>
  <summary>Details</summary>
Motivation: 合成数据与真实数据之间存在外观和成像差异，导致严重的域偏移，影响下游任务性能。现有方法在真实感和结构稳定性之间存在权衡。

Method: 提出FD-DB模型，通过低频可解释编辑和高频残差补偿的双分支设计，结合门控融合机制和两阶段训练策略，实现合成数据到真实数据的无监督转换。

Result: 在YCB-V数据集上的实验表明，FD-DB提高了真实域的外观一致性，显著提升了语义分割性能，同时保持了几何和语义结构。

Conclusion: FD-DB通过频率解耦的双分支模型，有效解决了合成数据到真实数据的域适应问题，显著提升了语义分割性能，同时保持了几何和语义结构的稳定性。

Abstract: Synthetic data provide low-cost, accurately annotated samples for geometry-sensitive vision tasks, but appearance and imaging differences between synthetic and real domains cause severe domain shift and degrade downstream performance. Unpaired synthetic-to-real translation can reduce this gap without paired supervision, yet existing methods often face a trade-off between photorealism and structural stability: unconstrained generation may introduce deformation or spurious textures, while overly rigid constraints limit adaptation to real-domain statistics. We propose FD-DB, a frequency-decoupled dual-branch model that separates appearance transfer into low-frequency interpretable editing and high-frequency residual compensation. The interpretable branch predicts physically meaningful editing parameters (white balance, exposure, contrast, saturation, blur, and grain) to build a stable low-frequency appearance base with strong content preservation. The free branch complements fine details through residual generation, and a gated fusion mechanism combines the two branches under explicit frequency constraints to limit low-frequency drift. We further adopt a two-stage training schedule that first stabilizes the editing branch and then releases the residual branch to improve optimization stability. Experiments on the YCB-V dataset show that FD-DB improves real-domain appearance consistency and significantly boosts downstream semantic segmentation performance while preserving geometric and semantic structures.

</details>


### [30] [Weakly Supervised Contrastive Learning for Histopathology Patch Embeddings](https://arxiv.org/abs/2602.09477)
*Bodong Zhang,Xiwen Li,Hamid Manoochehri,Xiaoya Tang,Deepika Sirohi,Beatrice S. Knudsen,Tolga Tasdizen*

Main category: cs.CV

TL;DR: WeakSupCon框架通过融入bag-level标签信息，提升了MIL性能，无需实例级伪标签。


<details>
  <summary>Details</summary>
Motivation: 数字病理学WSIs的分析面临训练标签有限的挑战，而现有的MIL方法忽视了特征表示学习。

Method: 提出WeakSupCon框架，不依赖实例级伪标签，但能在特征空间中有效分离不同标签的patch。

Result: 实验结果表明，WeakSupCon生成的图像特征在三个数据集上优于自监督对比学习方法。

Conclusion: 论文提出了一种名为WeakSupCon的新型特征表示学习框架，该框架在训练过程中融入了bag-level标签信息，有效提升了MIL性能。

Abstract: Digital histopathology whole slide images (WSIs) provide gigapixel-scale high-resolution images that are highly useful for disease diagnosis. However, digital histopathology image analysis faces significant challenges due to the limited training labels, since manually annotating specific regions or small patches cropped from large WSIs requires substantial time and effort. Weakly supervised multiple instance learning (MIL) offers a practical and efficient solution by requiring only bag-level (slide-level) labels, while each bag typically contains multiple instances (patches). Most MIL methods directly use frozen image patch features generated by various image encoders as inputs and primarily focus on feature aggregation. However, feature representation learning for encoder pretraining in MIL settings has largely been neglected.
  In our work, we propose a novel feature representation learning framework called weakly supervised contrastive learning (WeakSupCon) that incorporates bag-level label information during training. Our method does not rely on instance-level pseudo-labeling, yet it effectively separates patches with different labels in the feature space. Experimental results demonstrate that the image features generated by our WeakSupCon method lead to improved downstream MIL performance compared to self-supervised contrastive learning approaches in three datasets. Our related code is available at github.com/BzhangURU/Paper_WeakSupCon_for_MIL

</details>


### [31] [Beyond Next-Token Alignment: Distilling Multimodal Large Language Models via Token Interactions](https://arxiv.org/abs/2602.09483)
*Lin Chen,Xiaoke Zhao,Kun Ding,Weiwei Feng,Changtao Miao,Zili Wang,Wenxuan Guo,Ying Wang,Kaiyuan Zheng,Bo Zhang,Zhe Li,Shiming Xiang*

Main category: cs.CV

TL;DR: Align-TI 是一种基于令牌交互的知识蒸馏框架，通过动态对齐视觉和生成逻辑，显著提升了多模态模型的压缩效果。


<details>
  <summary>Details</summary>
Motivation: 现有的知识蒸馏方法主要依赖静态的令牌对齐，忽略了动态令牌交互在多模态理解和生成中的关键作用。

Method: Align-TI 包含两个核心组件：IVA（对齐视觉信息提取能力）和 TPA（对齐生成逻辑），分别关注视觉-指令令牌交互和生成令牌间的动态交互。

Result: 实验表明，Align-TI 比 Vanilla KD 提升了 2.6%，且蒸馏后的 Align-TI-2B 甚至超越了更大的 LLaVA-1.5-7B 模型 7.0%。

Conclusion: Align-TI 提出了一种新的知识蒸馏框架，通过关注动态令牌交互，显著提升了多模态大型语言模型的压缩效果，并在实验中超越了现有方法。

Abstract: Multimodal Large Language Models (MLLMs) demonstrate impressive cross-modal capabilities, yet their substantial size poses significant deployment challenges. Knowledge distillation (KD) is a promising solution for compressing these models, but existing methods primarily rely on static next-token alignment, neglecting the dynamic token interactions, which embed essential capabilities for multimodal understanding and generation. To this end, we introduce Align-TI, a novel KD framework designed from the perspective of Token Interactions. Our approach is motivated by the insight that MLLMs rely on two primary interactions: vision-instruction token interactions to extract relevant visual information, and intra-response token interactions for coherent generation. Accordingly, Align-TI introduces two components: IVA enables the student model to imitate the teacher's instruction-relevant visual information extract capability by aligning on salient visual regions. TPA captures the teacher's dynamic generative logic by aligning the sequential token-to-token transition probabilities. Extensive experiments demonstrate Align-TI's superiority. Notably, our approach achieves $2.6\%$ relative improvement over Vanilla KD, and our distilled Align-TI-2B even outperforms LLaVA-1.5-7B (a much larger MLLM) by $7.0\%$, establishing a new state-of-the-art distillation framework for training parameter-efficient MLLMs. Code is available at https://github.com/lchen1019/Align-TI.

</details>


### [32] [Federated Learning for Surgical Vision in Appendicitis Classification: Results of the FedSurg EndoVis 2024 Challenge](https://arxiv.org/abs/2510.04772)
*Max Kirchner,Hanna Hoffmann,Alexander C. Jenke,Oliver L. Saldanha,Kevin Pfeiffer,Weam Kanjo,Julia Alekseenko,Claas de Boer,Santhi Raj Kolamuri,Lorenzo Mazza,Nicolas Padoy,Sophia Bano,Annika Reinke,Lena Maier-Hein,Danail Stoyanov,Jakob N. Kather,Fiona R. Kolbinger,Sebastian Bodenstedt,Stefanie Speidel*

Main category: cs.CV

TL;DR: FedSurg挑战旨在评估联邦学习在手术视频分类中的表现，发现泛化能力有限但微调后有所提升，ViViT模型表现最佳，强调了架构选择和预处理的重要性。


<details>
  <summary>Details</summary>
Motivation: The FedSurg challenge was designed to benchmark the state of the art in federated learning for surgical video classification. Its goal was to assess how well current methods generalize to unseen clinical centers and adapt through local fine-tuning while enabling collaborative model development without sharing patient data.

Method: Participants developed strategies to classify inflammation stages in appendicitis using a preliminary version of the multi-center Appendix300 video dataset. The challenge evaluated two tasks: generalization to an unseen center and center-specific adaptation after fine-tuning. Submitted approaches included foundation models with linear probing, metric learning with triplet loss, and various FL aggregation schemes (FedAvg, FedMedian, FedSAM). Performance was assessed using F1-score and Expected Cost, with ranking robustness evaluated via bootstrapping and statistical testing.

Result: In the generalization task, performance across centers was limited. In the adaptation task, all teams improved after fine-tuning, though ranking stability was low. The ViViT-based submission achieved the strongest overall performance. The challenge highlighted limitations in generalization, sensitivity to class imbalance, and difficulties in hyperparameter tuning in decentralized training, while spatiotemporal modeling and context-aware preprocessing emerged as promising strategies.

Conclusion: The FedSurg Challenge establishes the first benchmark for evaluating FL strategies in surgical video classification. Findings highlight the trade-off between local personalization and global robustness, and underscore the importance of architecture choice, preprocessing, and loss design. This benchmarking offers a reference point for future development of imbalance-aware, adaptive, and robust FL methods in clinical surgical AI.

Abstract: Purpose: The FedSurg challenge was designed to benchmark the state of the art in federated learning for surgical video classification. Its goal was to assess how well current methods generalize to unseen clinical centers and adapt through local fine-tuning while enabling collaborative model development without sharing patient data. Methods: Participants developed strategies to classify inflammation stages in appendicitis using a preliminary version of the multi-center Appendix300 video dataset. The challenge evaluated two tasks: generalization to an unseen center and center-specific adaptation after fine-tuning. Submitted approaches included foundation models with linear probing, metric learning with triplet loss, and various FL aggregation schemes (FedAvg, FedMedian, FedSAM). Performance was assessed using F1-score and Expected Cost, with ranking robustness evaluated via bootstrapping and statistical testing. Results: In the generalization task, performance across centers was limited. In the adaptation task, all teams improved after fine-tuning, though ranking stability was low. The ViViT-based submission achieved the strongest overall performance. The challenge highlighted limitations in generalization, sensitivity to class imbalance, and difficulties in hyperparameter tuning in decentralized training, while spatiotemporal modeling and context-aware preprocessing emerged as promising strategies. Conclusion: The FedSurg Challenge establishes the first benchmark for evaluating FL strategies in surgical video classification. Findings highlight the trade-off between local personalization and global robustness, and underscore the importance of architecture choice, preprocessing, and loss design. This benchmarking offers a reference point for future development of imbalance-aware, adaptive, and robust FL methods in clinical surgical AI.

</details>


### [33] [OSI: One-step Inversion Excels in Extracting Diffusion Watermarks](https://arxiv.org/abs/2602.09494)
*Yuwei Chen,Zhenliang He,Jia Tang,Meina Kan,Shiguang Shan*

Main category: cs.CV

TL;DR: OSI是一种快速、准确的一步水印提取方法，比传统方法快20倍，准确率更高，且支持更大的水印容量。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于高斯阴影的水印提取方法需要多步扩散反演，计算成本高且耗时的问题。

Method: OSI将水印提取重新定义为可学习的符号分类问题，避免了初始噪声的精确回归。通过从扩散主干初始化OSI模型，并在合成的噪声-图像对上微调，实现一步提取。

Result: OSI比多步扩散反演方法快20倍，提取准确率更高，水印有效载荷容量翻倍。

Conclusion: OSI方法显著提高了水印提取的速度和准确性，同时增加了水印的有效载荷容量，展示了其广泛的适用性。

Abstract: Watermarking is an important mechanism for provenance and copyright protection of diffusion-generated images. Training-free methods, exemplified by Gaussian Shading, embed watermarks into the initial noise of diffusion models with negligible impact on the quality of generated images. However, extracting this type of watermark typically requires multi-step diffusion inversion to obtain precise initial noise, which is computationally expensive and time-consuming. To address this issue, we propose One-step Inversion (OSI), a significantly faster and more accurate method for extracting Gaussian Shading style watermarks. OSI reformulates watermark extraction as a learnable sign classification problem, which eliminates the need for precise regression of the initial noise. Then, we initialize the OSI model from the diffusion backbone and finetune it on synthesized noise-image pairs with a sign classification objective. In this manner, the OSI model is able to accomplish the watermark extraction efficiently in only one step. Our OSI substantially outperforms the multi-step diffusion inversion method: it is 20x faster, achieves higher extraction accuracy, and doubles the watermark payload capacity. Extensive experiments across diverse schedulers, diffusion backbones, and cryptographic schemes consistently show improvements, demonstrating the generality of our OSI framework.

</details>


### [34] [Equilibrium contrastive learning for imbalanced image classification](https://arxiv.org/abs/2602.09506)
*Sumin Roh,Harim Kim,Ho Yun Lee,Il Yong Chun*

Main category: cs.CV

TL;DR: ECL是一种监督对比学习框架，通过几何平衡解决数据不平衡问题，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有监督对比学习方法在数据不平衡时存在两个局限性：未考虑类均值/原型与分类器的对齐，以及原型作为额外样本时贡献不平衡。

Method: ECL框架包含两个主要组件：一是促进表示几何平衡（即类样本坍缩和类均值均匀分布的规则单纯形几何），二是通过对齐分类器权重和类原型建立分类器-类中心几何平衡。

Result: 在CIFAR-10(0)-LT、ImageNet-LT及两个医学数据集（ISIC 2019和LCCT）上的实验表明，ECL优于现有的SOTA监督对比学习方法。

Conclusion: ECL框架通过促进几何平衡，在数据不平衡的情况下实现了类特征、均值和分类器的和谐平衡，显著提升了现有监督对比学习方法的性能。

Abstract: Contrastive learning (CL) is a predominant technique in image classification, but they showed limited performance with an imbalanced dataset. Recently, several supervised CL methods have been proposed to promote an ideal regular simplex geometric configuration in the representation space-characterized by intra-class feature collapse and uniform inter-class mean spacing, especially for imbalanced datasets. In particular, existing prototype-based methods include class prototypes, as additional samples to consider all classes. However, the existing CL methods suffer from two limitations. First, they do not consider the alignment between the class means/prototypes and classifiers, which could lead to poor generalization. Second, existing prototype-based methods treat prototypes as only one additional sample per class, making their influence depend on the number of class instances in a batch and causing unbalanced contributions across classes. To address these limitations, we propose Equilibrium Contrastive Learning (ECL), a supervised CL framework designed to promote geometric equilibrium, where class features, means, and classifiers are harmoniously balanced under data imbalance. The proposed ECL framework uses two main components. First, ECL promotes the representation geometric equilibrium (i.e., a regular simplex geometry characterized by collapsed class samples and uniformly distributed class means), while balancing the contributions of class-average features and class prototypes. Second, ECL establishes a classifier-class center geometric equilibrium by aligning classifier weights and class prototypes. We ran experiments with three long-tailed datasets, the CIFAR-10(0)-LT, ImageNet-LT, and the two imbalanced medical datasets, the ISIC 2019 and our constructed LCCT dataset. Results show that ECL outperforms existing SOTA supervised CL methods designed for imbalanced classification.

</details>


### [35] [Robust Depth Super-Resolution via Adaptive Diffusion Sampling](https://arxiv.org/abs/2602.09510)
*Kun Wang,Yun Zhu,Pan Zhou,Na Zhao*

Main category: cs.CV

TL;DR: AdaDS是一种基于扩散模型的深度超分辨率框架，通过自适应噪声注入提升对退化输入的鲁棒性，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 传统方法在严重或未知退化条件下直接回归深度值常产生伪影，AdaDS旨在解决这一问题。

Method: AdaDS利用高斯平滑的收缩特性，自适应选择扩散轨迹的起始时间步，并注入定制噪声以将中间样本定位在目标后验分布的高概率区域。

Result: 在真实世界和合成基准测试中，AdaDS展示了卓越的零样本泛化能力和对多样化退化模式的鲁棒性。

Conclusion: AdaDS框架通过自适应选择扩散轨迹的起始时间步并注入定制噪声，显著提升了深度超分辨率任务的鲁棒性和泛化能力，优于现有方法。

Abstract: We propose AdaDS, a generalizable framework for depth super-resolution that robustly recovers high-resolution depth maps from arbitrarily degraded low-resolution inputs. Unlike conventional approaches that directly regress depth values and often exhibit artifacts under severe or unknown degradation, AdaDS capitalizes on the contraction property of Gaussian smoothing: as noise accumulates in the forward process, distributional discrepancies between degraded inputs and their pristine high-quality counterparts diminish, ultimately converging to isotropic Gaussian prior. Leveraging this, AdaDS adaptively selects a starting timestep in the reverse diffusion trajectory based on estimated refinement uncertainty, and subsequently injects tailored noise to position the intermediate sample within the high-probability region of the target posterior distribution. This strategy ensures inherent robustness, enabling generative prior of a pre-trained diffusion model to dominate recovery even when upstream estimations are imperfect. Extensive experiments on real-world and synthetic benchmarks demonstrate AdaDS's superior zero-shot generalization and resilience to diverse degradation patterns compared to state-of-the-art methods.

</details>


### [36] [Energy-Efficient Fast Object Detection on Edge Devices for IoT Systems](https://arxiv.org/abs/2602.09515)
*Mas Nurul Achmadiah,Afaroj Ahamad,Chi-Chia Sun,Wen-Kai Kuo*

Main category: cs.CV

TL;DR: 论文提出了一种基于帧差法的轻量级AI分类器，适用于物联网系统中的快速目标检测，显著提升了能效和准确率，同时降低了延迟。


<details>
  <summary>Details</summary>
Motivation: 物联网系统需要节能且高效的快速目标检测方法，而端到端方法在此类任务中表现不佳，因此研究旨在提出一种更优的解决方案。

Method: 研究采用了帧差法，并在三种边缘设备（AMD AlveoT M U50、Jetson Orin Nano和Hailo-8T M AI加速器）及四种模型（包括人工神经网络和Transformer模型）上进行了实现。测试类别包括鸟类、汽车、火车和飞机。

Result: 实验结果显示，MobileNet模型在帧差法下表现最佳，具有高准确率、低延迟和高能效；与端到端方法相比，平均准确率提升28.314%，能效提升3.6倍，延迟降低39.305%。火车和飞机的检测准确率较低。

Conclusion: 该论文提出的基于帧差法的AI分类器在物联网系统中实现了高效、低延迟和节能的快速目标检测，尤其适用于需要快速移动目标检测和高准确率的应用。

Abstract: This paper presents an Internet of Things (IoT) application that utilizes an AI classifier for fast-object detection using the frame difference method. This method, with its shorter duration, is the most efficient and suitable for fast-object detection in IoT systems, which require energy-efficient applications compared to end-to-end methods. We have implemented this technique on three edge devices: AMD AlveoT M U50, Jetson Orin Nano, and Hailo-8T M AI Accelerator, and four models with artificial neural networks and transformer models. We examined various classes, including birds, cars, trains, and airplanes. Using the frame difference method, the MobileNet model consistently has high accuracy, low latency, and is highly energy-efficient. YOLOX consistently shows the lowest accuracy, lowest latency, and lowest efficiency. The experimental results show that the proposed algorithm has improved the average accuracy gain by 28.314%, the average efficiency gain by 3.6 times, and the average latency reduction by 39.305% compared to the end-to-end method. Of all these classes, the faster objects are trains and airplanes. Experiments show that the accuracy percentage for trains and airplanes is lower than other categories. So, in tasks that require fast detection and accurate results, end-to-end methods can be a disaster because they cannot handle fast object detection. To improve computational efficiency, we designed our proposed method as a lightweight detection algorithm. It is well suited for applications in IoT systems, especially those that require fast-moving object detection and higher accuracy.

</details>


### [37] [A Universal Action Space for General Behavior Analysis](https://arxiv.org/abs/2602.09518)
*Hung-Shuo Chang,Yue-Cheng Yang,Yu-Hsi Chen,Wei-Hsin Chen,Chien-Yao Wang,James C. Liao,Chien-Chang Chen,Hen-Hsen Huang,Hong-Yuan Mark Liao*

Main category: cs.CV

TL;DR: 论文提出了一种基于深度学习和大规模标注数据集的通用动作空间（UAS），用于分析哺乳动物和黑猩猩行为，解决了传统手工特征方法的局限性。


<details>
  <summary>Details</summary>
Motivation: 早期基于手工特征的行为分析方法鲁棒性和泛化能力有限，而深度学习和大规模视觉识别（如ImageNet）的发展为行为分析提供了新的范式。

Method: 利用现有标注的人类动作数据集构建通用动作空间（UAS），并将其作为基础分析哺乳动物和黑猩猩行为数据集。

Result: 成功构建了通用动作空间（UAS），并开源了相关代码（GitHub）。

Conclusion: 该论文通过构建大规模通用动作空间（UAS），成功将人类动作数据集的标注方法应用于哺乳动物和黑猩猩行为数据集的分析与分类。

Abstract: Analyzing animal and human behavior has long been a challenging task in computer vision. Early approaches from the 1970s to the 1990s relied on hand-crafted edge detection, segmentation, and low-level features such as color, shape, and texture to locate objects and infer their identities-an inherently ill-posed problem. Behavior analysis in this era typically proceeded by tracking identified objects over time and modeling their trajectories using sparse feature points, which further limited robustness and generalization. A major shift occurred with the introduction of ImageNet by Deng and Li in 2010, which enabled large-scale visual recognition through deep neural networks and effectively served as a comprehensive visual dictionary. This development allowed object recognition to move beyond complex low-level processing toward learned high-level representations. In this work, we follow this paradigm to build a large-scale Universal Action Space (UAS) using existing labeled human-action datasets. We then use this UAS as the foundation for analyzing and categorizing mammalian and chimpanzee behavior datasets. The source code is released on GitHub at https://github.com/franktpmvu/Universal-Action-Space.

</details>


### [38] [Attention to details, logits to truth: visual-aware attention and logits enhancement to mitigate hallucinations in LVLMs](https://arxiv.org/abs/2602.09521)
*Jingyi Wang,Fei Li,Rujie Liu*

Main category: cs.CV

TL;DR: 提出了一种无需训练的注意力干预算法，通过重加权矩阵和视觉注意力注入减少幻觉现象，实验证明有效。


<details>
  <summary>Details</summary>
Motivation: 现有的大型视觉语言模型视觉注意力不足导致幻觉现象，而现有方法对所有视觉令牌增强注意力会增加对任务无关令牌的关注，因此需要一种更精准的方法。

Method: 提出了一种无需训练的注意力干预算法，通过视觉-文本交叉注意力子矩阵构建重加权矩阵来重新分配注意力，并在束搜索解码中注入视觉注意力值以增强视觉令牌的贡献。

Result: 实验表明，该方法在主流大型视觉语言模型中显著减少了幻觉现象。

Conclusion: 该方法显著减少了主流大型视觉语言模型中的幻觉现象，同时保持了生成内容的准确性和连贯性。

Abstract: Existing Large Vision-Language Models (LVLMs) exhibit insufficient visual attention, leading to hallucinations. To alleviate this problem, some previous studies adjust and amplify visual attention. These methods present a limitation that boosting attention for all visual tokens inevitably increases attention to task irrelevant tokens. To tackle this challenge, we propose a training free attentional intervention algorithm to enhance the attention of task-relevant tokens based on the argument that task-relevant tokens generally demonstrate high visual-textual similarities. Specifically, the vision-text cross-attention submatrices, which represent visual-textual correlations, are extracted to construct the reweighting matrices to reallocate attention. Besides, to enhance the contribution of visual tokens, we inject visual attention values into the beam search decoding to identify solutions with higher visual attention. Extensive experiments demonstrate that this method significantly reduces hallucinations across mainstream LVLMs, while preserving the accuracy and coherence of generated content.

</details>


### [39] [Singpath-VL Technical Report](https://arxiv.org/abs/2602.09523)
*Zhen Qiu,Kaiwen Xiao,Zhengwei Lu,Xiangyu Liu,Lei Zhao,Hao Zhang*

Main category: cs.CV

TL;DR: Singpath-VL通过合成数据集和微调模型，填补宫颈细胞学AI助手空白，表现优异并开源部分数据。


<details>
  <summary>Details</summary>
Motivation: 尽管多模态大语言模型在计算病理学领域取得进展，但由于缺乏大规模高质量标注数据集，其在细胞病理学（尤其是宫颈细胞学）的应用仍不足。

Method: 开发了三阶段流水线合成百万级图像描述数据集，利用通用MLLM作为弱标注器，通过共识融合和专家知识注入优化输出，并采用多阶段策略微调Qwen3-VL-4B模型。

Result: Singpath-VL在细粒度形态感知和细胞级诊断分类上表现优异，部分合成数据集和基准将开源。

Conclusion: Singpath-VL填补了宫颈细胞学AI助手的空白，通过合成大规模高质量数据集和微调Qwen3-VL-4B模型，展示了在细粒度形态感知和细胞级诊断分类上的卓越性能。

Abstract: We present Singpath-VL, a vision-language large model, to fill the vacancy of AI assistant in cervical cytology. Recent advances in multi-modal large language models (MLLMs) have significantly propelled the field of computational pathology. However, their application in cytopathology, particularly cervical cytology, remains underexplored, primarily due to the scarcity of large-scale, high-quality annotated datasets. To bridge this gap, we first develop a novel three-stage pipeline to synthesize a million-scale image-description dataset. The pipeline leverages multiple general-purpose MLLMs as weak annotators, refines their outputs through consensus fusion and expert knowledge injection, and produces high-fidelity descriptions of cell morphology. Using this dataset, we then fine-tune the Qwen3-VL-4B model via a multi-stage strategy to create a specialized cytopathology MLLM. The resulting model, named Singpath-VL, demonstrates superior performance in fine-grained morphological perception and cell-level diagnostic classification. To advance the field, we will open-source a portion of the synthetic dataset and benchmark.

</details>


### [40] [HLGFA: High-Low Resolution Guided Feature Alignment for Unsupervised Anomaly Detection](https://arxiv.org/abs/2602.09524)
*Han Zhou,Yuxuan Gao,Yinchao Du,Xuezhe Zheng*

Main category: cs.CV

TL;DR: HLGFA通过高低分辨率特征对齐实现无监督工业异常检测，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决工业异常检测中缺陷样本稀缺且需可靠检测的问题，避免依赖像素级重建。

Method: 提出HLGFA框架，通过共享冻结骨干网络处理双分辨率输入，提取多级特征，并通过条件调制和门控残差校正细化低分辨率特征。

Result: 在MVTec AD数据集上达到97.9%像素级AUROC和97.5%图像级AUROC。

Conclusion: HLGFA框架通过高低分辨率特征对齐的方法，在无监督工业异常检测中取得了显著效果，优于现有基于重建和特征的方法。

Abstract: Unsupervised industrial anomaly detection (UAD) is essential for modern manufacturing inspection, where defect samples are scarce and reliable detection is required. In this paper, we propose HLGFA, a high-low resolution guided feature alignment framework that learns normality by modeling cross-resolution feature consistency between high-resolution and low-resolution representations of normal samples, instead of relying on pixel-level reconstruction. Dual-resolution inputs are processed by a shared frozen backbone to extract multi-level features, and high-resolution representations are decomposed into structure and detail priors to guide the refinement of low-resolution features through conditional modulation and gated residual correction. During inference, anomalies are naturally identified as regions where cross-resolution alignment breaks down. In addition, a noise-aware data augmentation strategy is introduced to suppress nuisance-induced responses commonly observed in industrial environments. Extensive experiments on standard benchmarks demonstrate the effectiveness of HLGFA, achieving 97.9% pixel-level AUROC and 97.5% image-level AUROC on the MVTec AD dataset, outperforming representative reconstruction-based and feature-based methods.

</details>


### [41] [SchröMind: Mitigating Hallucinations in Multimodal Large Language Models via Solving the Schrödinger Bridge Problem](https://arxiv.org/abs/2602.09528)
*Ziqiang Shi,Rujie Liu,Shanshan Yu,Satoshi Munakata,Koichi Shirahata*

Main category: cs.CV

TL;DR: SchröMind通过解决薛定谔桥问题减少MLLMs的幻觉，实验证明其在POPE和MME基准上性能优越且计算开销低。


<details>
  <summary>Details</summary>
Motivation: 尽管MLLMs在多领域取得显著成功，但在医疗等高风险领域中的应用仍受限于幻觉问题（生成文本与视觉输入矛盾或忽略）。作者认为MLLMs能理解图像但难以生成准确token序列，且自回归文本生成特性阻碍错误修正。

Method: 提出了SchröMind框架，通过轻量级训练建立幻觉激活与真实激活之间的token级映射，以最小传输成本解决薛定谔桥问题。

Result: 在POPE和MME基准测试中，SchröMind表现出色，实现了最先进的性能，且仅引入最小计算开销。

Conclusion: SchröMind框架通过解决薛定谔桥问题，有效减少了MLLMs在医疗等高风险领域中的幻觉现象，同时在保持模型原有能力的基础上，仅引入了最小的计算开销。

Abstract: Recent advancements in Multimodal Large Language Models (MLLMs) have achieved significant success across various domains. However, their use in high-stakes fields like healthcare remains limited due to persistent hallucinations, where generated text contradicts or ignores visual input. We contend that MLLMs can comprehend images but struggle to produce accurate token sequences. Minor perturbations can shift attention from truthful to untruthful states, and the autoregressive nature of text generation often prevents error correction. To address this, we propose SchröMind-a novel framework reducing hallucinations via solving the Schrödinger bridge problem. It establishes a token-level mapping between hallucinatory and truthful activations with minimal transport cost through lightweight training, while preserving the model's original capabilities. Extensive experiments on the POPE and MME benchmarks demonstrate the superiority of Schrödinger, which achieves state-of-the-art performance while introducing only minimal computational overhead.

</details>


### [42] [SCA-Net: Spatial-Contextual Aggregation Network for Enhanced Small Building and Road Change Detection](https://arxiv.org/abs/2602.09529)
*Emad Gholibeigi,Abbas Koochari,Azadeh ZamaniFar*

Main category: cs.CV

TL;DR: SCA-Net 是一种基于 Change-Agent 的增强架构，通过多尺度分析和注意力机制显著提升了遥感影像变化检测的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 遥感影像中的自动化变化检测对城市管理、环境监测和灾害评估至关重要，但现有深度学习方法在小物体检测敏感度和计算成本方面存在挑战。

Method: SCA-Net 结合了多种创新技术，包括差异金字塔块、自适应多尺度处理模块（结合形状感知和高分辨率增强块）、多级注意力机制（PPM 和 CSAGate），以及动态复合损失函数和四阶段训练策略。

Result: 在 LEVIR-CD 和 LEVIR-MCI 数据集上的评估显示，SCA-Net 在 mIoU 上提升了 2.64%，小建筑物 IoU 提升了 57.9%，同时训练时间减少了 61%。

Conclusion: SCA-Net 提供了一种高效、准确且稳健的解决方案，适用于实际的遥感影像变化检测应用，显著提升了小物体检测的敏感度并降低了计算成本。

Abstract: Automated change detection in remote sensing imagery is critical for urban management, environmental monitoring, and disaster assessment. While deep learning models have advanced this field, they often struggle with challenges like low sensitivity to small objects and high computational costs. This paper presents SCA-Net, an enhanced architecture built upon the Change-Agent framework for precise building and road change detection in bi-temporal images. Our model incorporates several key innovations: a novel Difference Pyramid Block for multi-scale change analysis, an Adaptive Multi-scale Processing module combining shape-aware and high-resolution enhancement blocks, and multi-level attention mechanisms (PPM and CSAGate) for joint contextual and detail processing. Furthermore, a dynamic composite loss function and a four-phase training strategy are introduced to stabilize training and accelerate convergence. Comprehensive evaluations on the LEVIR-CD and LEVIR-MCI datasets demonstrate SCA-Net's superior performance over Change-Agent and other state-of-the-art methods. Our approach achieves a significant 2.64% improvement in mean Intersection over Union (mIoU) on LEVIR-MCI and a remarkable 57.9% increase in IoU for small buildings, while reducing the training time by 61%. This work provides an efficient, accurate, and robust solution for practical change detection applications.

</details>


### [43] [DR.Experts: Differential Refinement of Distortion-Aware Experts for Blind Image Quality Assessment](https://arxiv.org/abs/2602.09531)
*Bohan Fu,Guanyi Qin,Fazhan Zhang,Zihao Huang,Mingxuan Li,Runze Hu*

Main category: cs.CV

TL;DR: DR.Experts是一种新型的盲图像质量评估框架，通过整合失真先验和动态加权机制，显著提升了评估性能。


<details>
  <summary>Details</summary>
Motivation: 现有盲图像质量评估模型因缺乏可靠的失真先验，导致对细微失真线索的捕捉不足，与人类主观判断不一致。

Method: 提出DR.Experts框架，利用退化感知的视觉语言模型获取失真特定先验，并通过失真显著性差异模块和动态失真加权模块进行精炼与融合。

Result: 在五个具有挑战性的BIQA基准测试中，DR.Experts优于现有方法，展现出卓越的泛化能力和数据效率。

Conclusion: DR.Experts框架通过显式整合失真先验，显著提升了盲图像质量评估的性能，并在多个基准测试中表现出优越的泛化能力和数据效率。

Abstract: Blind Image Quality Assessment, aiming to replicate human perception of visual quality without reference, plays a key role in vision tasks, yet existing models often fail to effectively capture subtle distortion cues, leading to a misalignment with human subjective judgments. We identify that the root cause of this limitation lies in the lack of reliable distortion priors, as methods typically learn shallow relationships between unified image features and quality scores, resulting in their insensitive nature to distortions and thus limiting their performance. To address this, we introduce DR.Experts, a novel prior-driven BIQA framework designed to explicitly incorporate distortion priors, enabling a reliable quality assessment. DR.Experts begins by leveraging a degradation-aware vision-language model to obtain distortion-specific priors, which are further refined and enhanced by the proposed Distortion-Saliency Differential Module through distinguishing them from semantic attentions, thereby ensuring the genuine representations of distortions. The refined priors, along with semantics and bridging representation, are then fused by a proposed mixture-of-experts style module named the Dynamic Distortion Weighting Module. This mechanism weights each distortion-specific feature as per its perceptual impact, ensuring that the final quality prediction aligns with human perception. Extensive experiments conducted on five challenging BIQA benchmarks demonstrate the superiority of DR.Experts over current methods and showcase its excellence in terms of generalization and data efficiency.

</details>


### [44] [RAD: Retrieval-Augmented Monocular Metric Depth Estimation for Underrepresented Classes](https://arxiv.org/abs/2602.09532)
*Michael Baltaxe,Dan Levi,Sagie Benaim*

Main category: cs.CV

TL;DR: RAD是一种检索增强的单目深度估计框架，通过检索相似上下文提升代表性不足类别的深度估计准确性，在多个数据集上显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 解决单目深度估计在复杂场景中代表性不足类别上准确性不足的挑战。

Method: RAD采用不确定性感知检索机制识别输入中的低置信度区域，并检索包含语义相似内容的RGB-D上下文样本，随后通过双流网络处理输入和检索上下文，并使用匹配的交叉注意力模块融合它们。

Result: 在NYU Depth v2、KITTI和Cityscapes数据集上，RAD分别将相对绝对误差降低了29.2%、13.3%和7.2%，同时在标准基准测试中保持竞争力。

Conclusion: RAD框架通过检索增强方法显著提升了单目深度估计在代表性不足类别上的准确性，并在多个基准测试中优于现有技术。

Abstract: Monocular Metric Depth Estimation (MMDE) is essential for physically intelligent systems, yet accurate depth estimation for underrepresented classes in complex scenes remains a persistent challenge. To address this, we propose RAD, a retrieval-augmented framework that approximates the benefits of multi-view stereo by utilizing retrieved neighbors as structural geometric proxies. Our method first employs an uncertainty-aware retrieval mechanism to identify low-confidence regions in the input and retrieve RGB-D context samples containing semantically similar content. We then process both the input and retrieved context via a dual-stream network and fuse them using a matched cross-attention module, which transfers geometric information only at reliable point correspondences. Evaluations on NYU Depth v2, KITTI, and Cityscapes demonstrate that RAD significantly outperforms state-of-the-art baselines on underrepresented classes, reducing relative absolute error by 29.2% on NYU Depth v2, 13.3% on KITTI, and 7.2% on Cityscapes, while maintaining competitive performance on standard in-domain benchmarks.

</details>


### [45] [AUHead: Realistic Emotional Talking Head Generation via Action Units Control](https://arxiv.org/abs/2602.09534)
*Jiayi Lyu,Leigang Qu,Wenjing Zhang,Hanyu Jiang,Kai Liu,Zhenglin Zhou,Xiaobo Xia,Jian Xue,Tat-Seng Chua*

Main category: cs.CV

TL;DR: AUHead通过两阶段方法实现精细情感控制，显著提升视频生成的情感真实感和视觉质量。


<details>
  <summary>Details</summary>
Motivation: 现有方法在精细情感控制方面存在不足，导致情感表达不够细腻。

Method: 采用两阶段方法：第一阶段通过空间-时间AU标记化和'情感-后-AU'思维链机制从音频中分离AUs；第二阶段提出AU驱动的可控扩散模型，通过结构化2D面部表示和跨注意力模块合成视频。

Result: 在基准数据集上，AUHead在情感真实感、唇同步和视觉连贯性方面表现优异。

Conclusion: AUHead方法在情感真实感、准确的唇同步和视觉连贯性方面表现优异，显著超越了现有技术。

Abstract: Realistic talking-head video generation is critical for virtual avatars, film production, and interactive systems. Current methods struggle with nuanced emotional expressions due to the lack of fine-grained emotion control. To address this issue, we introduce a novel two-stage method (AUHead) to disentangle fine-grained emotion control, i.e. , Action Units (AUs), from audio and achieve controllable generation. In the first stage, we explore the AU generation abilities of large audio-language models (ALMs), by spatial-temporal AU tokenization and an "emotion-then-AU" chain-of-thought mechanism. It aims to disentangle AUs from raw speech, effectively capturing subtle emotional cues. In the second stage, we propose an AU-driven controllable diffusion model that synthesizes realistic talking-head videos conditioned on AU sequences. Specifically, we first map the AU sequences into the structured 2D facial representation to enhance spatial fidelity, and then model the AU-vision interaction within cross-attention modules. To achieve flexible AU-quality trade-off control, we introduce an AU disentanglement guidance strategy during inference, further refining the emotional expressiveness and identity consistency of the generated videos. Results on benchmark datasets demonstrate that our approach achieves competitive performance in emotional realism, accurate lip synchronization, and visual coherence, significantly surpassing existing techniques. Our implementation is available at https://github.com/laura990501/AUHead_ICLR

</details>


### [46] [Scalpel: Fine-Grained Alignment of Attention Activation Manifolds via Mixture Gaussian Bridges to Mitigate Multimodal Hallucination](https://arxiv.org/abs/2602.09541)
*Ziqiang Shi,Rujie Liu,Shanshan Yu,Satoshi Munakata,Koichi Shirahata*

Main category: cs.CV

TL;DR: Scalpel通过优化注意力分布减少视觉语言模型中的幻觉，无需额外计算，性能优越。


<details>
  <summary>Details</summary>
Motivation: 大型视觉语言模型由于大型语言模型的强先验和跨模态注意力不对齐，常产生与视觉内容不一致的输出（幻觉现象）。

Method: Scalpel利用高斯混合模型捕捉注意力在信任和幻觉流形中的多峰分布，并通过熵最优传输（等价于薛定谔桥问题）精确映射高斯分量。在推理过程中，动态调整干预强度和方向。

Result: 实验证明，Scalpel在多个数据集和基准测试中有效减轻了幻觉，优于先前方法，且无需额外计算，仅需单次解码步骤。

Conclusion: Scalpel方法通过优化注意力激活分布，有效减少了大型视觉语言模型中的幻觉现象，且在多个数据集和基准测试中表现优异，实现了最先进的性能。

Abstract: Rapid progress in large vision-language models (LVLMs) has achieved unprecedented performance in vision-language tasks. However, due to the strong prior of large language models (LLMs) and misaligned attention across modalities, LVLMs often generate outputs inconsistent with visual content - termed hallucination. To address this, we propose \textbf{Scalpel}, a method that reduces hallucination by refining attention activation distributions toward more credible regions. Scalpel predicts trusted attention directions for each head in Transformer layers during inference and adjusts activations accordingly. It employs a Gaussian mixture model to capture multi-peak distributions of attention in trust and hallucination manifolds, and uses entropic optimal transport (equivalent to Schrödinger bridge problem) to map Gaussian components precisely. During mitigation, Scalpel dynamically adjusts intervention strength and direction based on component membership and mapping relationships between hallucination and trust activations. Extensive experiments across multiple datasets and benchmarks demonstrate that Scalpel effectively mitigates hallucinations, outperforming previous methods and achieving state-of-the-art performance. Moreover, Scalpel is model- and data-agnostic, requiring no additional computation, only a single decoding step.

</details>


### [47] [Delving into Spectral Clustering with Vision-Language Representations](https://arxiv.org/abs/2602.09586)
*Bo Peng,Yuanwei Hu,Bo Liu,Ling Chen,Jie Lu,Zhen Fang*

Main category: cs.CV

TL;DR: 本文提出了一种基于神经正切核的多模态谱聚类方法，通过结合视觉和语义信息提升聚类效果，实验证明其性能显著优于现有技术。


<details>
  <summary>Details</summary>
Motivation: 现有谱聚类方法多基于单模态，未能充分利用多模态表示的丰富信息。受视觉语言预训练成功的启发，本文旨在将谱聚类从单模态扩展到多模态领域。

Method: 该方法结合神经正切核与正名词（语义接近目标图像的词语），将图像间的亲和力定义为视觉接近性和语义重叠的结合，并通过正则化亲和力扩散机制自适应地集成不同提示诱导的亲和力矩阵。

Result: 在16个基准测试（包括经典、大规模、细粒度和域转移数据集）上的广泛实验表明，该方法在性能上显著优于现有技术。

Conclusion: 本文提出的Neural Tangent Kernel Spectral Clustering方法通过利用预训练的视觉语言模型中的跨模态对齐，显著提升了谱聚类的性能，并在多个基准测试中大幅超越现有技术。

Abstract: Spectral clustering is known as a powerful technique in unsupervised data analysis. The vast majority of approaches to spectral clustering are driven by a single modality, leaving the rich information in multi-modal representations untapped. Inspired by the recent success of vision-language pre-training, this paper enriches the landscape of spectral clustering from a single-modal to a multi-modal regime. Particularly, we propose Neural Tangent Kernel Spectral Clustering that leverages cross-modal alignment in pre-trained vision-language models. By anchoring the neural tangent kernel with positive nouns, i.e., those semantically close to the images of interest, we arrive at formulating the affinity between images as a coupling of their visual proximity and semantic overlap. We show that this formulation amplifies within-cluster connections while suppressing spurious ones across clusters, hence encouraging block-diagonal structures. In addition, we present a regularized affinity diffusion mechanism that adaptively ensembles affinity matrices induced by different prompts. Extensive experiments on \textbf{16} benchmarks -- including classical, large-scale, fine-grained and domain-shifted datasets -- manifest that our method consistently outperforms the state-of-the-art by a large margin.

</details>


### [48] [MieDB-100k: A Comprehensive Dataset for Medical Image Editing](https://arxiv.org/abs/2602.09587)
*Yongfan Lai,Wen Qian,Bo Liu,Hongyan Li,Hao Luo,Fan Wang,Bohan Zhuang,Shenda Hong*

Main category: cs.CV

TL;DR: 提出MieDB-100k，一个大规模、高质量、多样化的文本引导医学图像编辑数据集，通过专家模型和合成方法构建，实验证明其训练模型性能优越且泛化能力强。


<details>
  <summary>Details</summary>
Motivation: 高质量数据的稀缺性是适应多模态生成模型进行医学图像编辑的主要瓶颈，现有数据集在多样性、医学图像理解及质量与可扩展性平衡方面存在不足。

Method: 通过结合模态特定专家模型和基于规则的数据合成方法构建数据管道，并经过严格人工检查以确保临床保真度。

Result: 使用MieDB-100k训练的模型在开源和专有模型上表现一致优越，并展现出强大的泛化能力。

Conclusion: MieDB-100k数据集有望成为专业医学图像编辑未来发展的基石。

Abstract: The scarcity of high-quality data remains a primary bottleneck in adapting multimodal generative models for medical image editing. Existing medical image editing datasets often suffer from limited diversity, neglect of medical image understanding and inability to balance quality with scalability. To address these gaps, we propose MieDB-100k, a large-scale, high-quality and diverse dataset for text-guided medical image editing. It categorizes editing tasks into perspectives of Perception, Modification and Transformation, considering both understanding and generation abilities. We construct MieDB-100k via a data curation pipeline leveraging both modality-specific expert models and rule-based data synthetic methods, followed by rigorous manual inspection to ensure clinical fidelity. Extensive experiments demonstrate that model trained with MieDB-100k consistently outperform both open-source and proprietary models while exhibiting strong generalization ability. We anticipate that this dataset will serve as a cornerstone for future advancements in specialized medical image editing.

</details>


### [49] [Hand2World: Autoregressive Egocentric Interaction Generation via Free-Space Hand Gestures](https://arxiv.org/abs/2602.09600)
*Yuxi Wang,Wenqi Ouyang,Tianyi Wei,Yi Dong,Zhiqi Shen,Xingang Pan*

Main category: cs.CV

TL;DR: Hand2World是一个统一的自动回归框架，通过遮挡不变手部条件化和显式相机几何注入，解决了自由空间手势生成中的分布偏移和模糊性问题，显著提升了视频生成的感知质量和3D一致性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在从单场景图像和自由空间手势生成以自我为中心的交互视频，合成真实感视频，其中手部进入场景、与物体交互，并在头部运动下诱导合理世界动态。

Method: Hand2World采用基于投影3D手部网格的遮挡不变手部条件化，通过每像素Plücker射线嵌入注入显式相机几何，将相机运动与手部运动解耦，防止背景漂移。此外，开发了全自动单目注释流程，并将双向扩散模型提炼为因果生成器。

Result: 在三个以自我为中心的交互基准测试中，Hand2World在感知质量和3D一致性方面显示出显著改进，同时支持相机控制和长时程交互生成。

Conclusion: Hand2World通过其统一的自动回归框架，解决了自由空间手势与接触密集训练数据之间的分布偏移、单目视图中手部运动与相机运动的模糊性以及任意长度视频生成的挑战，显著提升了感知质量和3D一致性，并支持相机控制和长时程交互生成。

Abstract: Egocentric interactive world models are essential for augmented reality and embodied AI, where visual generation must respond to user input with low latency, geometric consistency, and long-term stability. We study egocentric interaction generation from a single scene image under free-space hand gestures, aiming to synthesize photorealistic videos in which hands enter the scene, interact with objects, and induce plausible world dynamics under head motion. This setting introduces fundamental challenges, including distribution shift between free-space gestures and contact-heavy training data, ambiguity between hand motion and camera motion in monocular views, and the need for arbitrary-length video generation. We present Hand2World, a unified autoregressive framework that addresses these challenges through occlusion-invariant hand conditioning based on projected 3D hand meshes, allowing visibility and occlusion to be inferred from scene context rather than encoded in the control signal. To stabilize egocentric viewpoint changes, we inject explicit camera geometry via per-pixel Plücker-ray embeddings, disentangling camera motion from hand motion and preventing background drift. We further develop a fully automated monocular annotation pipeline and distill a bidirectional diffusion model into a causal generator, enabling arbitrary-length synthesis. Experiments on three egocentric interaction benchmarks show substantial improvements in perceptual quality and 3D consistency while supporting camera control and long-horizon interactive generation.

</details>


### [50] [Tele-Omni: a Unified Multimodal Framework for Video Generation and Editing](https://arxiv.org/abs/2602.09609)
*Jialun Liu,Yukuo Ma,Xiao Cao,Tian Li,Gonghu Shang,Haibin Huang,Chi Zhang,Xuelong Li,Cong Liu,Junqi Liu,Jiakui Hu,Robby T. Tan,Shiwen Zhang,Liying Yang,Xiaoyan Yang,Qizhen Weng,Xiangzhen Chang,Yuanzhi Liang,Yifan Xu,Zhiyong Huang,Zuoxin Li,Xuelong Li*

Main category: cs.CV

TL;DR: Tele-Omni是一个统一的多模态视频生成与编辑框架，支持多模态指令（文本、图像、参考视频），通过解耦指令解析与视频合成实现灵活控制，并在多个任务上表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有基于扩散的视频生成方法多为任务特定且主要依赖文本指令，限制了处理多模态输入、上下文参考和多样化视频生成与编辑场景的能力。此外，许多视频编辑方法依赖于针对单个操作精心设计的管道，阻碍了可扩展性和可组合性。

Method: Tele-Omni利用预训练的多模态大语言模型解析异构指令并推断结构化生成或编辑意图，同时基于扩散的生成器根据这些结构化信号执行高质量视频合成。为了在异构视频任务中实现联合训练，引入了一个任务感知数据处理管道，将多模态输入统一为结构化指令格式，同时保留任务特定约束。

Result: Tele-Omni支持广泛的视频中心任务，包括文本到视频生成、图像到视频生成、首尾帧视频生成、上下文视频生成和上下文视频编辑。

Conclusion: Tele-Omni通过解耦指令解析与视频合成，并结合任务感知数据设计，实现了灵活的多模态控制，同时保持了强时间连贯性和视觉一致性。实验结果表明，Tele-Omni在多个任务上具有竞争力。

Abstract: Recent advances in diffusion-based video generation have substantially improved visual fidelity and temporal coherence. However, most existing approaches remain task-specific and rely primarily on textual instructions, limiting their ability to handle multimodal inputs, contextual references, and diverse video generation and editing scenarios within a unified framework. Moreover, many video editing methods depend on carefully engineered pipelines tailored to individual operations, which hinders scalability and composability. In this paper, we propose Tele-Omni, a unified multimodal framework for video generation and editing that follows multimodal instructions, including text, images, and reference videos, within a single model. Tele-Omni leverages pretrained multimodal large language models to parse heterogeneous instructions and infer structured generation or editing intents, while diffusion-based generators perform high-quality video synthesis conditioned on these structured signals. To enable joint training across heterogeneous video tasks, we introduce a task-aware data processing pipeline that unifies multimodal inputs into a structured instruction format while preserving task-specific constraints. Tele-Omni supports a wide range of video-centric tasks, including text-to-video generation, image-to-video generation, first-last-frame video generation, in-context video generation, and in-context video editing. By decoupling instruction parsing from video synthesis and combining it with task-aware data design, Tele-Omni achieves flexible multimodal control while maintaining strong temporal coherence and visual consistency. Experimental results demonstrate that Tele-Omni achieves competitive performance across multiple tasks.

</details>


### [51] [LiDAR-based 3D Change Detection at City Scale](https://arxiv.org/abs/2510.21112)
*Hezam Albagami,Haitian Wang,Xinyu Wang,Muhammad Ibrahim,Zainy M. Malakan,Abdullah M. Alqamdi,Mohammed H. Alghamdi,Ajmal Mian*

Main category: cs.CV

TL;DR: 提出了一种不确定性感知的城市尺度LiDAR变化检测方法，通过多分辨率对齐和语义优化，显著提升了检测精度。


<details>
  <summary>Details</summary>
Motivation: 传统DSM和图像差分方法对垂直偏差和视角不匹配敏感，而原始点云或体素模型需要大量内存且假设完美对齐。

Method: 提出了一种基于不确定性的对象中心方法，结合多分辨率NDT和点对平面ICP方法进行数据对齐，并通过语义和实例分割优化几何关联。

Result: 在Subiaco数据集上的实验显示，该方法在准确率、mF1和mIoU上分别比Triplet KPConv提高了0.3、0.6和1.1个百分点。

Conclusion: 该方法在城市尺度LiDAR变化检测中表现出色，准确率达到95.3%，显著优于基线方法Triplet KPConv。

Abstract: High-definition 3D city maps enable city planning and change detection, which is essential for municipal compliance, map maintenance, and asset monitoring, including both built structures and urban greenery. Conventional Digital Surface Model (DSM) and image differencing are sensitive to vertical bias and viewpoint mismatch, while original point cloud or voxel models require large memory, assume perfect alignment, and degrade thin structures. We propose an uncertainty-aware, object-centric method for city-scale LiDAR-based change detection. Our method aligns data from different time periods using multi-resolution Normal Distributions Transform (NDT) and a point-to-plane Iterative Closest Point (ICP) method, normalizes elevation, and computes a per-point level of detection from registration covariance and surface roughness to calibrate change decisions. Geometry-based associations are refined by semantic and instance segmentation and optimized using class-constrained bipartite assignment with augmented dummies to handle split-merge cases. Tiled processing bounds memory and preserves narrow ground changes, while instance-level decisions integrate overlap, displacement, and volumetric differences under local detection gating. We perform experiments on a Subiaco (Western Australia) dataset captured in 2023 and again in 2025. Our method achieves 95.3% accuracy, 90.8% mF1, and 82.9% mIoU, improving over the strongest baseline, Triplet KPConv, by 0.3, 0.6, and 1.1 points, respectively. The datasets are available on IEEE DataPort (2023: https://ieee-dataport.org/documents/2023-subiaco-wa-3d-hd-lidar-point-cloud-maps-dataset and 2025: https://ieee-dataport.org/documents/2025-subiaco-wa-3d-hd-lidar-gnss-point-cloud-maps-dataset). The source code is available at https://github.com/HaitianWang/IEEE-Sensor-Journal-Changing-Detection.

</details>


### [52] [AGMark: Attention-Guided Dynamic Watermarking for Large Vision-Language Models](https://arxiv.org/abs/2602.09611)
*Yue Li,Xin Yi,Dongsheng Shi,Yongyi Cui,Gerard de Melo,Linlin Wang*

Main category: cs.CV

TL;DR: AGMark是一种新型动态水印框架，通过动态识别语义关键证据和上下文连贯线索，结合不确定性感知和证据校准，显著提升了生成质量和视觉保真度，同时保持高检测准确性和抗攻击能力。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉无关水印可能引入视觉无关标记并破坏视觉基础，而视觉特定水印则依赖静态、一次性估计的视觉关键权重，忽略了权重分布密度，导致动态视觉依赖变化无法适应，并可能引入低质量标记。

Method: AGMark通过动态识别基于注意力权重的语义关键证据和上下文感知的连贯线索，实现了更自适应和校准的证据权重分布。同时，结合不确定性感知（标记熵）和证据校准（权重密度），动态确定语义关键标记的比例，从而避免无关标记的引入。

Result: 实验结果表明，AGMark在生成质量和视觉语义保真度上显著优于传统方法，特别是在生成后期阶段表现尤为突出。检测准确性（至少99.36% AUC）和抗攻击能力（至少88.61% AUC）均保持高度竞争力。

Conclusion: AGMark框架在保持视觉保真度的同时，显著提升了生成质量和视觉语义保真度，特别是在生成后期阶段表现尤为突出。该框架在不牺牲推理效率的情况下，保持了极高的检测准确性和强大的抗攻击能力，为多模态水印技术树立了新标准。

Abstract: Watermarking has emerged as a pivotal solution for content traceability and intellectual property protection in Large Vision-Language Models (LVLMs). However, vision-agnostic watermarks may introduce visually irrelevant tokens and disrupt visual grounding by enforcing indiscriminate pseudo-random biases. Additionally, current vision-specific watermarks rely on a static, one-time estimation of vision critical weights and ignore the weight distribution density when determining the proportion of protected tokens. This design fails to account for dynamic changes in visual dependence during generation and may introduce low-quality tokens in the long tail. To address these challenges, we propose Attention-Guided Dynamic Watermarking (AGMark), a novel framework that embeds detectable signals while strictly preserving visual fidelity. At each decoding step, AGMark first dynamically identifies semantic-critical evidence based on attention weights for visual relevance, together with context-aware coherence cues, resulting in a more adaptive and well-calibrated evidence-weight distribution. It then determines the proportion of semantic-critical tokens by jointly considering uncertainty awareness (token entropy) and evidence calibration (weight density), thereby enabling adaptive vocabulary partitioning to avoid irrelevant tokens. Empirical results confirm that AGMark outperforms conventional methods, observably improving generation quality and yielding particularly strong gains in visual semantic fidelity in the later stages of generation. The framework maintains highly competitive detection accuracy (at least 99.36\% AUC) and robust attack resilience (at least 88.61\% AUC) without sacrificing inference efficiency, effectively establishing a new standard for reliability-preserving multi-modal watermarking.

</details>


### [53] [Perception with Guarantees: Certified Pose Estimation via Reachability Analysis](https://arxiv.org/abs/2602.10032)
*Tobias Ladner,Yasser Shoukry,Matthias Althoff*

Main category: cs.CV

TL;DR: 本文提出了一种基于相机图像和目标几何的3D姿态认证估计方法，通过形式化边界和可达性分析，实现了安全关键领域的高效准确定位。


<details>
  <summary>Details</summary>
Motivation: 在安全关键领域，粗略的姿态估计不足以确保安全性，且外部服务（如GPS）可能不可靠，因此需要一种可靠的方法来精确估计姿态。

Method: 利用可达性分析和形式神经网络验证的最新成果，计算并形式化边界姿态。

Result: 实验证明，该方法在合成和真实世界实验中都能高效准确地定位智能体。

Conclusion: 本文提出了一种仅依靠相机图像和已知目标几何形状的3D姿态认证估计方法，通过形式化边界和结合可达性分析与形式神经网络验证的最新成果，实现了高效准确的定位。

Abstract: Agents in cyber-physical systems are increasingly entrusted with safety-critical tasks. Ensuring safety of these agents often requires localizing the pose for subsequent actions. Pose estimates can, e.g., be obtained from various combinations of lidar sensors, cameras, and external services such as GPS. Crucially, in safety-critical domains, a rough estimate is insufficient to formally determine safety, i.e., guaranteeing safety even in the worst-case scenario, and external services might additionally not be trustworthy. We address this problem by presenting a certified pose estimation in 3D solely from a camera image and a well-known target geometry. This is realized by formally bounding the pose, which is computed by leveraging recent results from reachability analysis and formal neural network verification. Our experiments demonstrate that our approach efficiently and accurately localizes agents in both synthetic and real-world experiments.

</details>


### [54] [Towards Training-free Multimodal Hate Localisation with Large Language Models](https://arxiv.org/abs/2602.09637)
*Yueming Sun,Long Yang,Jianbo Jiao,Zeyu Fu*

Main category: cs.CV

TL;DR: LELA是一种无需训练的LLM框架，通过多模态分解和多阶段提示方案实现仇恨视频的细粒度定位，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 在线视频中仇恨内容的泛滥对个人福祉和社会和谐构成严重威胁，而现有解决方案要么依赖大规模人工标注，要么缺乏细粒度的时间精度。

Method: LELA通过将视频分解为五种模态（图像、语音、OCR、音乐和视频上下文），并采用多阶段提示方案计算每帧的仇恨分数，结合组合匹配机制增强跨模态推理。

Result: 在HateMM和MultiHateClip两个基准测试中，LELA显著优于所有现有的无需训练基线方法。

Conclusion: LELA作为一种无需训练的大语言模型框架，在仇恨视频定位任务中表现出色，为可扩展和可解释的仇恨内容检测奠定了坚实基础。

Abstract: The proliferation of hateful content in online videos poses severe threats to individual well-being and societal harmony. However, existing solutions for video hate detection either rely heavily on large-scale human annotations or lack fine-grained temporal precision. In this work, we propose LELA, the first training-free Large Language Model (LLM) based framework for hate video localization. Distinct from state-of-the-art models that depend on supervised pipelines, LELA leverages LLMs and modality-specific captioning to detect and temporally localize hateful content in a training-free manner. Our method decomposes a video into five modalities, including image, speech, OCR, music, and video context, and uses a multi-stage prompting scheme to compute fine-grained hateful scores for each frame. We further introduce a composition matching mechanism to enhance cross-modal reasoning. Experiments on two challenging benchmarks, HateMM and MultiHateClip, demonstrate that LELA outperforms all existing training-free baselines by a large margin. We also provide extensive ablations and qualitative visualizations, establishing LELA as a strong foundation for scalable and interpretable hate video localization.

</details>


### [55] [SAGE: Scalable Agentic 3D Scene Generation for Embodied AI](https://arxiv.org/abs/2602.10116)
*Hongchi Xia,Xuan Li,Zhaoshuo Li,Qianli Ma,Jiashu Xu,Ming-Yu Liu,Yin Cui,Tsung-Yi Lin,Wei-Chiu Ma,Shenlong Wang,Shuran Song,Fangyin Wei*

Main category: cs.CV

TL;DR: SAGE是一个智能代理框架，自动生成模拟就绪的3D环境，通过迭代优化确保场景的真实性和物理有效性，支持具身AI的策略训练。


<details>
  <summary>Details</summary>
Motivation: 现实世界数据收集成本高且不安全，需要可扩展、真实且模拟就绪的3D环境。现有系统依赖基于规则或任务特定的流程，常产生伪影和物理无效场景。

Method: SAGE结合布局和对象组合生成器与评估语义合理性、视觉真实性和物理稳定性的批评家，通过迭代推理和自适应工具选择自我优化场景。

Result: 生成的场景真实、多样，可直接部署于现代模拟器中进行策略训练。纯基于此数据的策略训练显示出明显的扩展趋势，并能泛化到未见过的对象和布局。

Conclusion: SAGE框架通过智能代理生成模拟就绪的3D环境，显著提升了真实性和多样性，为具身AI的策略训练提供了可扩展的解决方案。

Abstract: Real-world data collection for embodied agents remains costly and unsafe, calling for scalable, realistic, and simulator-ready 3D environments. However, existing scene-generation systems often rely on rule-based or task-specific pipelines, yielding artifacts and physically invalid scenes. We present SAGE, an agentic framework that, given a user-specified embodied task (e.g., "pick up a bowl and place it on the table"), understands the intent and automatically generates simulation-ready environments at scale. The agent couples multiple generators for layout and object composition with critics that evaluate semantic plausibility, visual realism, and physical stability. Through iterative reasoning and adaptive tool selection, it self-refines the scenes until meeting user intent and physical validity. The resulting environments are realistic, diverse, and directly deployable in modern simulators for policy training. Policies trained purely on this data exhibit clear scaling trends and generalize to unseen objects and layouts, demonstrating the promise of simulation-driven scaling for embodied AI. Code, demos, and the SAGE-10k dataset can be found on the project page here: https://nvlabs.github.io/sage.

</details>


### [56] [VideoAfford: Grounding 3D Affordance from Human-Object-Interaction Videos via Multimodal Large Language Model](https://arxiv.org/abs/2602.09638)
*Hanqing Wang,Mingyu Liu,Xiaoyu Chen,Chengwei MA,Yiming Zhong,Wenti Yin,Yuhao Liu,Zhiqing Cui,Jiahao Yuan,Lu Dai,Zhiyuan Ma,Hui Xiong*

Main category: cs.CV

TL;DR: 论文提出VideoAfford模型，结合动态交互视频数据集VIDA和多模态大语言模型，显著提升3D affordance grounding性能。


<details>
  <summary>Details</summary>
Motivation: 现有研究主要依赖静态线索（如语言和图像）学习affordance知识，缺乏动态交互上下文。为解决这一问题，作者收集了VIDA数据集，并提出了VideoAfford模型。

Method: 基于VIDA数据集，提出了VideoAfford模型，利用多模态大语言模型和潜在动作编码器提取动态交互先验，并通过空间感知损失函数增强3D空间知识。

Result: 实验表明，VideoAfford显著优于现有方法，并展现出强大的开放世界泛化和affordance推理能力。

Conclusion: 该论文提出了VideoAfford模型，通过结合多模态大语言模型和动态交互先验知识，显著提升了3D affordance grounding的性能，并展示了强大的开放世界泛化能力。所有数据集和代码将公开发布以推动该领域的研究。

Abstract: 3D affordance grounding aims to highlight the actionable regions on 3D objects, which is crucial for robotic manipulation. Previous research primarily focused on learning affordance knowledge from static cues such as language and images, which struggle to provide sufficient dynamic interaction context that can reveal temporal and causal cues. To alleviate this predicament, we collect a comprehensive video-based 3D affordance dataset, \textit{VIDA}, which contains 38K human-object-interaction videos covering 16 affordance types, 38 object categories, and 22K point clouds. Based on \textit{VIDA}, we propose a strong baseline: VideoAfford, which activates multimodal large language models with additional affordance segmentation capabilities, enabling both world knowledge reasoning and fine-grained affordance grounding within a unified framework. To enhance action understanding capability, we leverage a latent action encoder to extract dynamic interaction priors from HOI videos. Moreover, we introduce a \textit{spatial-aware} loss function to enable VideoAfford to obtain comprehensive 3D spatial knowledge. Extensive experimental evaluations demonstrate that our model significantly outperforms well-established methods and exhibits strong open-world generalization with affordance reasoning abilities. All datasets and code will be publicly released to advance research in this area.

</details>


### [57] [Time2General: Learning Spatiotemporal Invariant Representations for Domain-Generalization Video Semantic Segmentation](https://arxiv.org/abs/2602.09648)
*Siyu Chen,Ting Han,Haoling Huang,Chaolei Wang,Chengzheng Fu,Duxin Zhu,Guorong Cai,Jinhe Su*

Main category: cs.CV

TL;DR: Time2General是一个基于稳定性查询的DGVSS框架，通过时空记忆解码器和掩码时间一致性损失解决帧间闪烁问题，显著提升跨域性能和时间稳定性。


<details>
  <summary>Details</summary>
Motivation: 解决领域偏移和时间采样偏移导致的帧间闪烁问题，保持视频流中的时间一致性预测。

Method: 提出了基于稳定性查询的DGVSS框架Time2General，包括时空记忆解码器和掩码时间一致性损失。

Result: 在多个驾驶基准测试中表现出显著的跨域准确性和时间稳定性提升。

Conclusion: Time2General显著提升了跨域准确性和时间稳定性，同时在高达18 FPS的速度下运行。

Abstract: Domain Generalized Video Semantic Segmentation (DGVSS) is trained on a single labeled driving domain and is directly deployed on unseen domains without target labels and test-time adaptation while maintaining temporally consistent predictions over video streams. In practice, both domain shift and temporal-sampling shift break correspondence-based propagation and fixed-stride temporal aggregation, causing severe frame-to-frame flicker even in label-stable regions. We propose Time2General, a DGVSS framework built on Stability Queries. Time2General introduces a Spatio-Temporal Memory Decoder that aggregates multi-frame context into a clip-level spatio-temporal memory and decodes temporally consistent per-frame masks without explicit correspondence propagation. To further suppress flicker and improve robustness to varying sampling rates, the Masked Temporal Consistency Loss is proposed to regularize temporal prediction discrepancies across different strides, and randomize training strides to expose the model to diverse temporal gaps. Extensive experiments on multiple driving benchmarks show that Time2General achieves a substantial improvement in cross-domain accuracy and temporal stability over prior DGSS and VSS baselines while running at up to 18 FPS. Code will be released after the review process.

</details>


### [58] [TreeCUA: Efficiently Scaling GUI Automation with Tree-Structured Verifiable Evolution](https://arxiv.org/abs/2602.09662)
*Deyang Jiang,Jing Huang,Xuanle Zhao,Lei Chen,Liming Zheng,Fanfan Liu,Haibo Qiu,Peng Shi,Zhixiong Zeng*

Main category: cs.CV

TL;DR: TreeCUA通过树状结构和多智能体协作高效扩展GUI自动化，改进规划能力并展示强泛化。


<details>
  <summary>Details</summary>
Motivation: 现有工作主要关注GUI基础而非更关键的GUI规划，需更高效的数据收集方法。GUI探索过程通常呈树状结构，早期功能入口点更频繁被探索。

Method: 提出TreeCUA，采用多智能体协作框架探索环境、验证动作、总结轨迹并评估质量，设计基于树的拓扑结构存储和重放重复探索节点，以及自适应探索算法平衡深度和广度。

Result: 实验结果显示TreeCUA和TreeCUA-DPO显著提升性能，OOD研究进一步验证其强泛化能力。

Conclusion: TreeCUA和TreeCUA-DPO在GUI自动化规划方面表现出显著改进，且具备强大的泛化能力。所有轨迹节点信息和代码将在GitHub上公开。

Abstract: Effectively scaling GUI automation is essential for computer-use agents (CUAs); however, existing work primarily focuses on scaling GUI grounding rather than the more crucial GUI planning, which requires more sophisticated data collection. In reality, the exploration process of a CUA across apps/desktops/web pages typically follows a tree structure, with earlier functional entry points often being explored more frequently. Thus, organizing large-scale trajectories into tree structures can reduce data cost and streamline the data scaling of GUI planning. In this work, we propose TreeCUA to efficiently scale GUI automation with tree-structured verifiable evolution. We propose a multi-agent collaborative framework to explore the environment, verify actions, summarize trajectories, and evaluate quality to generate high-quality and scalable GUI trajectories. To improve efficiency, we devise a novel tree-based topology to store and replay duplicate exploration nodes, and design an adaptive exploration algorithm to balance the depth (\emph{i.e.}, trajectory difficulty) and breadth (\emph{i.e.}, trajectory diversity). Moreover, we develop world knowledge guidance and global memory backtracking to avoid low-quality generation. Finally, we naturally extend and propose the TreeCUA-DPO method from abundant tree node information, improving GUI planning capability by referring to the branch information of adjacent trajectories. Experimental results show that TreeCUA and TreeCUA-DPO offer significant improvements, and out-of-domain (OOD) studies further demonstrate strong generalization. All trajectory node information and code will be available at https://github.com/UITron-hub/TreeCUA.

</details>


### [59] [GenSeg-R1: RL-Driven Vision-Language Grounding for Fine-Grained Referring Segmentation](https://arxiv.org/abs/2602.09701)
*Sandesh Hegde,Jaison Saji Chacko,Debarshi Banerjee,Uma Mahesh*

Main category: cs.CV

TL;DR: GenSeg-R1通过解耦推理-分割流程和GRPO微调，在多个数据集上显著提升细粒度参考图像分割性能。


<details>
  <summary>Details</summary>
Motivation: 解决细粒度参考图像分割中高质量掩码生成和推理链标注依赖的问题。

Method: 采用解耦的reason-then-segment流程，结合VLM（Qwen3-VL模型）和冻结的SAM 2分割器，通过GRPO进行微调，无需监督推理链注释。

Result: 在RefCOCOg验证集上，GenSeg-R1-8B达到0.7127 cIoU和0.7382 mIoU，显著优于基线；在GRefCOCO上，GenSeg-R1-G实现76.69%目标mIoU和82.40%无目标提示准确率；在ReasonSeg测试中，GenSeg-R1-4B达到68.40% mIoU。

Conclusion: GenSeg-R1框架通过解耦的推理-分割流程显著提升了细粒度参考图像分割的性能，尤其在无监督推理链注释的情况下，通过GRPO微调Qwen3-VL模型，取得了优于基线和现有方法的结果。

Abstract: We study fine-grained referring image segmentation via a decoupled reason-then-segment pipeline. A vision-language model (VLM) receives an image and a natural-language query, reasons about the scene, and emits structured spatial prompts: a bounding box plus two interior keypoints for every referred instance. A frozen promptable segmenter (SAM 2) converts these prompts into high-quality masks.
  Within our GenSeg-R1 framework we finetune Qwen3-VL models (4B and 8B parameters) using Group Relative Policy Optimization (GRPO), requiring no supervised reasoning-chain annotations. On RefCOCOg validation our best model (GenSeg-R1-8B) achieves 0.7127 cIoU and 0.7382 mIoU, substantially outperforming the corresponding Qwen3-VL Instruct baselines (+15.3 and +21.9 points, respectively) and surpassing Seg-Zero-7B [3] by +3.3 cIoU under identical evaluation.
  We further introduce GenSeg-R1-G, a variant trained on GRefCOCO [9] with a SAM 2 in-the-loop reward that directly optimizes mask quality. On GRefCOCO validation GenSeg-R1-G achieves 76.69% target mIoU with 82.40% accuracy on negative (no-target) prompts, substantially outperforming Seg-R1-7B and Seg-Zero-7B, which lack no-target detection capability. On ReasonSeg test, GenSeg-R1-4B reaches 68.40% mIoU, surpassing Seg-Zero-7B by +7.0 and Seg-R1-7B by +10.7 points.

</details>


### [60] [Semi-supervised Liver Segmentation and Patch-based Fibrosis Staging with Registration-aided Multi-parametric MRI](https://arxiv.org/abs/2602.09686)
*Boya Wang,Ruizhe Li,Chao Chen,Xin Chen*

Main category: cs.CV

TL;DR: 研究开发了一个多任务深度学习框架，用于肝脏分割和肝纤维化分期，有效处理多模态MRI数据和有限标注问题，代码已开源。


<details>
  <summary>Details</summary>
Motivation: 肝脏纤维化在临床实践中具有重大挑战，需要精确的肝脏分割和疾病分期方法。

Method: 采用半监督学习模型结合图像分割和配准技术处理肝脏分割任务，利用基于patch的方法进行肝纤维化分期。

Result: 该方法在独立测试集（包括分布内和分布外案例）上表现良好，适用于三通道和七通道MRI数据。

Conclusion: 该研究提出的多任务深度学习框架在肝脏分割和肝纤维化分期中表现出色，有效解决了多模态MRI数据、有限标注和领域偏移等挑战。

Abstract: Liver fibrosis poses a substantial challenge in clinical practice, emphasizing the necessity for precise liver segmentation and accurate disease staging. Based on the CARE Liver 2025 Track 4 Challenge, this study introduces a multi-task deep learning framework developed for liver segmentation (LiSeg) and liver fibrosis staging (LiFS) using multiparametric MRI. The LiSeg phase addresses the challenge of limited annotated images and the complexities of multi-parametric MRI data by employing a semi-supervised learning model that integrates image segmentation and registration. By leveraging both labeled and unlabeled data, the model overcomes the difficulties introduced by domain shifts and variations across modalities. In the LiFS phase, we employed a patchbased method which allows the visualization of liver fibrosis stages based on the classification outputs. Our approach effectively handles multimodality imaging data, limited labels, and domain shifts. The proposed method has been tested by the challenge organizer on an independent test set that includes in-distribution (ID) and out-of-distribution (OOD) cases using three-channel MRIs (T1, T2, DWI) and seven-channel MRIs (T1, T2, DWI, GED1-GED4). The code is freely available. Github link: https://github.com/mileywang3061/Care-Liver

</details>


### [61] [From Lightweight CNNs to SpikeNets: Benchmarking Accuracy-Energy Tradeoffs with Pruned Spiking SqueezeNet](https://arxiv.org/abs/2602.09717)
*Radib Bin Kabir,Tawsif Tashwar Dipto,Mehedi Ahamed,Sabbir Ahmed,Md Hasanul Kabir*

Main category: cs.CV

TL;DR: 论文系统化评估了轻量级SNN（由CNN转换而来），证明其能效显著优于CNN，并通过剪枝进一步优化，为边缘部署提供高性能低功耗方案。


<details>
  <summary>Details</summary>
Motivation: 探索轻量级CNN到SNN的转换方法，填补现有研究在小型模型上的空白，为边缘智能提供高效低功耗解决方案。

Method: 通过将轻量级CNN架构（如ShuffleNet、SqueezeNet等）转换为基于LIF神经元的SNN，并采用替代梯度下降训练，构建系统化基准。进一步对SNN-SqueezeNet进行结构化剪枝。

Result: SNN相比CNN能实现最高15.7倍的能效提升，剪枝后的SNN-SqueezeNet-P在CIFAR-10上准确率提升6%，参数减少19%，能耗降低88.1%。

Conclusion: 轻量级SNN（特别是经过剪枝优化的SNN-SqueezeNet-P）在边缘部署中展现出实用性和低功耗优势，几乎达到CNN的准确率但能耗显著降低。

Abstract: Spiking Neural Networks (SNNs) are increasingly studied as energy-efficient alternatives to Convolutional Neural Networks (CNNs), particularly for edge intelligence. However, prior work has largely emphasized large-scale models, leaving the design and evaluation of lightweight CNN-to-SNN pipelines underexplored. In this paper, we present the first systematic benchmark of lightweight SNNs obtained by converting compact CNN architectures into spiking networks, where activations are modeled with Leaky-Integrate-and-Fire (LIF) neurons and trained using surrogate gradient descent under a unified setup. We construct spiking variants of ShuffleNet, SqueezeNet, MnasNet, and MixNet, and evaluate them on CIFAR-10, CIFAR-100, and TinyImageNet, measuring accuracy, F1-score, parameter count, computational complexity, and energy consumption. Our results show that SNNs can achieve up to 15.7x higher energy efficiency than their CNN counterparts while retaining competitive accuracy. Among these, the SNN variant of SqueezeNet consistently outperforms other lightweight SNNs. To further optimize this model, we apply a structured pruning strategy that removes entire redundant modules, yielding a pruned architecture, SNN-SqueezeNet-P. This pruned model improves CIFAR-10 accuracy by 6% and reduces parameters by 19% compared to the original SNN-SqueezeNet. Crucially, it narrows the gap with CNN-SqueezeNet, achieving nearly the same accuracy (only 1% lower) but with an 88.1% reduction in energy consumption due to sparse spike-driven computations. Together, these findings establish lightweight SNNs as practical, low-power alternatives for edge deployment, highlighting a viable path toward deploying high-performance, low-power intelligence on the edge.

</details>


### [62] [Stroke3D: Lifting 2D strokes into rigged 3D model via latent diffusion models](https://arxiv.org/abs/2602.09713)
*Ruisi Zhao,Haoren Zheng,Zongxin Yang,Hehe Fan,Yi Yang*

Main category: cs.CV

TL;DR: Stroke3D是一个从用户输入的2D笔画和文本生成可动画3D网格的新框架，通过两阶段流程实现可控骨架和高质量网格的生成。


<details>
  <summary>Details</summary>
Motivation: 现有3D生成方法难以生成可动画的几何体，而绑定技术缺乏对骨架创建的细粒度控制。

Method: 采用两阶段流程：1）可控骨架生成（使用Sk-VAE和Sk-DiT），2）通过TextuRig和SKA-DPO增强网格合成。

Result: 实验表明，Stroke3D能生成合理的骨架和高质量的网格。

Conclusion: Stroke3D框架通过结合用户输入的2D笔画和文本提示，直接生成可动画的3D网格，为3D内容创作提供了更直观的工作流程。

Abstract: Rigged 3D assets are fundamental to 3D deformation and animation. However, existing 3D generation methods face challenges in generating animatable geometry, while rigging techniques lack fine-grained structural control over skeleton creation. To address these limitations, we introduce Stroke3D, a novel framework that directly generates rigged meshes from user inputs: 2D drawn strokes and a descriptive text prompt. Our approach pioneers a two-stage pipeline that separates the generation into: 1) Controllable Skeleton Generation, we employ the Skeletal Graph VAE (Sk-VAE) to encode the skeleton's graph structure into a latent space, where the Skeletal Graph DiT (Sk-DiT) generates a skeletal embedding. The generation process is conditioned on both the text for semantics and the 2D strokes for explicit structural control, with the VAE's decoder reconstructing the final high-quality 3D skeleton; and 2) Enhanced Mesh Synthesis via TextuRig and SKA-DPO, where we then synthesize a textured mesh conditioned on the generated skeleton. For this stage, we first enhance an existing skeleton-to-mesh model by augmenting its training data with TextuRig: a dataset of textured and rigged meshes with captions, curated from Objaverse-XL. Additionally, we employ a preference optimization strategy, SKA-DPO, guided by a skeleton-mesh alignment score, to further improve geometric fidelity. Together, our framework enables a more intuitive workflow for creating ready to animate 3D content. To the best of our knowledge, our work is the first to generate rigged 3D meshes conditioned on user-drawn 2D strokes. Extensive experiments demonstrate that Stroke3D produces plausible skeletons and high-quality meshes.

</details>


### [63] [Code2World: A GUI World Model via Renderable Code Generation](https://arxiv.org/abs/2602.09856)
*Yuhao Zheng,Li'an Zhong,Yi Wang,Rui Dai,Kaikui Liu,Xiangxiang Chu,Linyuan Lv,Philip Torr,Kevin Qinghong Lin*

Main category: cs.CV

TL;DR: Code2World通过生成可渲染代码提升GUI代理预测能力，显著优化导航任务表现。


<details>
  <summary>Details</summary>
Motivation: 解决现有基于文本和像素的方法在视觉保真度和结构可控性上的不足，提升GUI代理的预测能力。

Method: 构建AndroidCode数据集，通过视觉反馈修订机制生成高质量屏幕-动作对；采用SFT和Render-Aware Reinforcement Learning优化视觉语义保真度和动作一致性。

Result: Code2World-8B在下一UI预测任务中表现最佳，显著提升Gemini-2.5-Flash在AndroidWorld导航任务中的成功率（+9.5%）。

Conclusion: Code2World通过生成可渲染代码模拟下一视觉状态，显著提升了GUI代理的预测能力和下游导航成功率，尤其在AndroidWorld导航任务中表现突出。

Abstract: Autonomous GUI agents interact with environments by perceiving interfaces and executing actions. As a virtual sandbox, the GUI World model empowers agents with human-like foresight by enabling action-conditioned prediction. However, existing text- and pixel-based approaches struggle to simultaneously achieve high visual fidelity and fine-grained structural controllability. To this end, we propose Code2World, a vision-language coder that simulates the next visual state via renderable code generation. Specifically, to address the data scarcity problem, we construct AndroidCode by translating GUI trajectories into high-fidelity HTML and refining synthesized code through a visual-feedback revision mechanism, yielding a corpus of over 80K high-quality screen-action pairs. To adapt existing VLMs into code prediction, we first perform SFT as a cold start for format layout following, then further apply Render-Aware Reinforcement Learning which uses rendered outcome as the reward signal by enforcing visual semantic fidelity and action consistency. Extensive experiments demonstrate that Code2World-8B achieves the top-performing next UI prediction, rivaling the competitive GPT-5 and Gemini-3-Pro-Image. Notably, Code2World significantly enhances downstream navigation success rates in a flexible manner, boosting Gemini-2.5-Flash by +9.5% on AndroidWorld navigation. The code is available at https://github.com/AMAP-ML/Code2World.

</details>


### [64] [Allure of Craquelure: A Variational-Generative Approach to Crack Detection in Paintings](https://arxiv.org/abs/2602.09730)
*Laura Paul,Holger Rauhut,Martin Burger,Samira Kabri,Tim Roith*

Main category: cs.CV

TL;DR: 论文提出混合方法，利用深度生成模型和变分函数分解图像，实现数字化绘画中裂纹的自动检测，支持艺术品保护。


<details>
  <summary>Details</summary>
Motivation: 由于裂纹与画笔笔触或头发等类似艺术特征在视觉上的相似性，自动检测数字化绘画中的裂纹仍然具有挑战性，这对评估退化和指导修复至关重要。

Method: 采用深度生成模型作为艺术品的基础先验，结合Mumford-Shah型变分函数和裂纹先验来捕捉裂纹结构，通过联合优化生成像素级裂纹定位图。

Result: 该方法能够有效分解图像，生成像素级的裂纹定位图，支持艺术品的详细分析和保护。

Conclusion: 该论文提出了一种混合方法，通过将裂纹检测建模为逆问题，成功分解图像为无裂纹绘画和裂纹组件，为艺术品的保护和修复提供了有效工具。

Abstract: Recent advances in imaging technologies, deep learning and numerical performance have enabled non-invasive detailed analysis of artworks, supporting their documentation and conservation. In particular, automated detection of craquelure in digitized paintings is crucial for assessing degradation and guiding restoration, yet remains challenging due to the possibly complex scenery and the visual similarity between cracks and crack-like artistic features such as brush strokes or hair. We propose a hybrid approach that models crack detection as an inverse problem, decomposing an observed image into a crack-free painting and a crack component. A deep generative model is employed as powerful prior for the underlying artwork, while crack structures are captured using a Mumford--Shah-type variational functional together with a crack prior. Joint optimization yields a pixel-level map of crack localizations in the painting.

</details>


### [65] [SARS: A Novel Face and Body Shape and Appearance Aware 3D Reconstruction System extends Morphable Models](https://arxiv.org/abs/2602.09918)
*Gulraiz Khan,Kenneth Y. Wertheim,Kevin Pimbblet,Waqas Ahmed*

Main category: cs.CV

TL;DR: 本文提出SARS系统，通过单张图像重建包含高层面部特征的3D人体模型，弥补了现有研究忽略语义特征的不足。


<details>
  <summary>Details</summary>
Motivation: 现有3D人体重建研究仅关注全局面部结构或几何形状，忽略了年龄、性别等面部语义特征。

Method: 结合身份和表情的混合形状与基础面部网格，创建详细的3D模型，并通过调整多样参数控制3D Morphable模型的变化。

Result: SARS系统能够有效重建包含高层面部特征的3D人体模型。

Conclusion: 本文提出了一种形状和外观感知的3D重建系统（SARS），能够从单张图像中提取身体和面部信息，准确重建人体的3D模型。

Abstract: Morphable Models (3DMMs) are a type of morphable model that takes 2D images as inputs and recreates the structure and physical appearance of 3D objects, especially human faces and bodies. 3DMM combines identity and expression blendshapes with a basic face mesh to create a detailed 3D model. The variability in the 3D Morphable models can be controlled by tuning diverse parameters. They are high-level image descriptors, such as shape, texture, illumination, and camera parameters. Previous research in 3D human reconstruction concentrated solely on global face structure or geometry, ignoring face semantic features such as age, gender, and facial landmarks characterizing facial boundaries, curves, dips, and wrinkles. In order to accommodate changes in these high-level facial characteristics, this work introduces a shape and appearance-aware 3D reconstruction system (named SARS by us), a c modular pipeline that extracts body and face information from a single image to properly rebuild the 3D model of the human full body.

</details>


### [66] [Toward Fine-Grained Facial Control in 3D Talking Head Generation](https://arxiv.org/abs/2602.09736)
*Shaoyang Xie,Xiaofeng Cong,Baosheng Yu,Zhipeng Gui,Jie Gui,Yuan Yan Tang,James Tin-Yau Kwok*

Main category: cs.CV

TL;DR: FG-3DGS通过频率感知解耦和后期渲染对齐，提升了说话头部生成的精细控制和唇同步准确性。


<details>
  <summary>Details</summary>
Motivation: 解决音频驱动说话头部生成中的唇同步不准确和面部抖动问题，避免恐怖谷效应。

Method: 引入频率感知解耦策略，分别建模低频和高频面部区域，并应用高斯增量预测动态，结合后渲染对齐机制。

Result: 在广泛使用的数据集上，FG-3DGS优于现有技术，生成高质量视频。

Conclusion: FG-3DGS方法在生成高保真、唇同步的说话头部视频方面优于现有技术，解决了精细面部动作控制的挑战。

Abstract: Audio-driven talking head generation is a core component of digital avatars, and 3D Gaussian Splatting has shown strong performance in real-time rendering of high-fidelity talking heads. However, achieving precise control over fine-grained facial movements remains a significant challenge, particularly due to lip-synchronization inaccuracies and facial jitter, both of which can contribute to the uncanny valley effect. To address these challenges, we propose Fine-Grained 3D Gaussian Splatting (FG-3DGS), a novel framework that enables temporally consistent and high-fidelity talking head generation. Our method introduces a frequency-aware disentanglement strategy to explicitly model facial regions based on their motion characteristics. Low-frequency regions, such as the cheeks, nose, and forehead, are jointly modeled using a standard MLP, while high-frequency regions, including the eyes and mouth, are captured separately using a dedicated network guided by facial area masks. The predicted motion dynamics, represented as Gaussian deltas, are applied to the static Gaussians to generate the final head frames, which are rendered via a rasterizer using frame-specific camera parameters. Additionally, a high-frequency-refined post-rendering alignment mechanism, learned from large-scale audio-video pairs by a pretrained model, is incorporated to enhance per-frame generation and achieve more accurate lip synchronization. Extensive experiments on widely used datasets for talking head generation demonstrate that our method outperforms recent state-of-the-art approaches in producing high-fidelity, lip-synced talking head videos.

</details>


### [67] [Monocular Normal Estimation via Shading Sequence Estimation](https://arxiv.org/abs/2602.09929)
*Zongrui Li,Xinhua Ma,Minghui Hu,Yunqing Zhao,Yingchen Yu,Qian Zheng,Chang Liu,Xudong Jiang,Song Bai*

Main category: cs.CV

TL;DR: RoSE通过着色序列估计解决法线估计中的3D错位问题，性能领先。


<details>
  <summary>Details</summary>
Motivation: 现有方法直接预测法线图时存在3D错位问题，因几何差异仅通过细微颜色变化反映，模型难以区分和重建。

Method: 提出RoSE方法，利用图像到视频生成模型预测着色序列，并通过普通最小二乘问题转换为法线图。训练使用合成数据集MultiShade。

Result: RoSE在真实世界基准数据集上表现优异，达到最先进水平。

Conclusion: RoSE通过将法线估计重新定义为着色序列估计，有效解决了现有方法中的3D错位问题，并在真实世界基准数据集上实现了最先进的性能。

Abstract: Monocular normal estimation aims to estimate the normal map from a single RGB image of an object under arbitrary lights. Existing methods rely on deep models to directly predict normal maps. However, they often suffer from 3D misalignment: while the estimated normal maps may appear to have a correct appearance, the reconstructed surfaces often fail to align with the geometric details. We argue that this misalignment stems from the current paradigm: the model struggles to distinguish and reconstruct varying geometry represented in normal maps, as the differences in underlying geometry are reflected only through relatively subtle color variations. To address this issue, we propose a new paradigm that reformulates normal estimation as shading sequence estimation, where shading sequences are more sensitive to various geometric information. Building on this paradigm, we present RoSE, a method that leverages image-to-video generative models to predict shading sequences. The predicted shading sequences are then converted into normal maps by solving a simple ordinary least-squares problem. To enhance robustness and better handle complex objects, RoSE is trained on a synthetic dataset, MultiShade, with diverse shapes, materials, and light conditions. Experiments demonstrate that RoSE achieves state-of-the-art performance on real-world benchmark datasets for object-based monocular normal estimation.

</details>


### [68] [Robust Vision Systems for Connected and Autonomous Vehicles: Security Challenges and Attack Vectors](https://arxiv.org/abs/2602.09740)
*Sandeep Gupta,Roberto Passerone*

Main category: cs.CV

TL;DR: 本文研究了CAV视觉系统的鲁棒性，提出了参考架构并分析了攻击向量对安全性的影响。


<details>
  <summary>Details</summary>
Motivation: 研究CAV视觉系统的鲁棒性对于实现L5级自动驾驶至关重要，可靠的视觉系统是安全导航的基础。

Method: 分析了CAV导航中的关键传感器和视觉组件，推导出CAVVS的参考架构，并评估了攻击向量对CIA三原则的影响。

Result: 提出了CAVVS的参考架构，识别了潜在的攻击面，并评估了攻击向量对CIA的影响。

Conclusion: 该研究为CAV视觉系统（CAVVS）提供了参考架构，并详细分析了攻击向量及其对CIA三原则的影响，强调了制定稳健安全措施的重要性。

Abstract: This article investigates the robustness of vision systems in Connected and Autonomous Vehicles (CAVs), which is critical for developing Level-5 autonomous driving capabilities. Safe and reliable CAV navigation undeniably depends on robust vision systems that enable accurate detection of objects, lane markings, and traffic signage. We analyze the key sensors and vision components essential for CAV navigation to derive a reference architecture for CAV vision system (CAVVS). This reference architecture provides a basis for identifying potential attack surfaces of CAVVS. Subsequently, we elaborate on identified attack vectors targeting each attack surface, rigorously evaluating their implications for confidentiality, integrity, and availability (CIA). Our study provides a comprehensive understanding of attack vector dynamics in vision systems, which is crucial for formulating robust security measures that can uphold the principles of the CIA triad.

</details>


### [69] [Unbalanced optimal transport for robust longitudinal lesion evolution with registration-aware and appearance-guided priors](https://arxiv.org/abs/2602.09933)
*Melika Qahqaie,Dominik Neumann,Tobias Heimann,Andreas Maier,Veronika A. Zimmer*

Main category: cs.CV

TL;DR: 提出一种基于UOT的注册感知匹配器，用于纵向CT扫描中病变匹配，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 评估癌症患者纵向CT扫描中病变演变对治疗反应至关重要，但传统基于几何邻近度的二分匹配方法在病变出现、消失、合并或分裂时表现不佳。

Method: 采用不平衡最优传输（UOT）方法，结合几何归一化、局部注册信任度和外观一致性，通过相对剪枝生成稀疏传输计划，无需重新训练或启发式规则。

Result: 在纵向CT数据上，该方法在边缘检测精确率、召回率、病变状态召回率及病变图组件F1分数上均优于基线方法。

Conclusion: 该论文提出的基于不平衡最优传输（UOT）的注册感知匹配器，在纵向CT扫描中显著提高了病变边缘检测的精确率和召回率，优于仅基于距离的基线方法。

Abstract: Evaluating lesion evolution in longitudinal CT scans of can cer patients is essential for assessing treatment response, yet establishing reliable lesion correspondence across time remains challenging. Standard bipartite matchers, which rely on geometric proximity, struggle when lesions appear, disappear, merge, or split. We propose a registration-aware matcher based on unbalanced optimal transport (UOT) that accommodates unequal lesion mass and adapts priors to patient-level tumor-load changes. Our transport cost blends (i) size-normalized geometry, (ii) local registration trust from the deformation-field Jacobian, and (iii) optional patch-level appearance consistency. The resulting transport plan is sparsified by relative pruning, yielding one-to-one matches as well as new, disappearing, merging, and splitting lesions without retraining or heuristic rules. On longitudinal CT data, our approach achieves consistently higher edge-detection precision and recall, improved lesion-state recall, and superior lesion-graph component F1 scores versus distance-only baselines.

</details>


### [70] [Self-Supervised Learning as Discrete Communication](https://arxiv.org/abs/2602.09764)
*Kawtar Zaher,Ilyass Moummad,Olivier Buisson,Alexis Joly*

Main category: cs.CV

TL;DR: 本研究提出了一种离散通信框架的自监督学习方法，通过二进制通道传输语义信息，生成结构化的表示，实验证明其优于连续对齐方法。


<details>
  <summary>Details</summary>
Motivation: 现有的自监督学习方法通过连续特征对齐学习视觉表示，缺乏对信息结构的控制，本研究旨在通过离散通信框架解决这一问题。

Method: 将视觉自监督学习框架化为教师和学生网络之间的离散通信过程，通过固定容量的二进制通道传输语义信息，使用二元交叉熵目标和编码率正则化项来优化。

Result: 实验表明，该方法在图像分类、检索、密集视觉预测任务及领域自适应中均优于连续对齐基线，二进制编码形成了紧凑且信息丰富的离散语言。

Conclusion: 通过离散通信框架，本研究成功地将自监督学习转化为一个信息结构化的过程，生成的二进制编码不仅紧凑且富含语义信息，可跨类别重用。

Abstract: Most self-supervised learning (SSL) methods learn continuous visual representations by aligning different views of the same input, offering limited control over how information is structured across representation dimensions. In this work, we frame visual self-supervised learning as a discrete communication process between a teacher and a student network, where semantic information is transmitted through a fixed-capacity binary channel. Rather than aligning continuous features, the student predicts multi-label binary messages produced by the teacher. Discrete agreement is enforced through an element-wise binary cross-entropy objective, while a coding-rate regularization term encourages effective utilization of the constrained channel, promoting structured representations. We further show that periodically reinitializing the projection head strengthens this effect by encouraging embeddings that remain predictive across multiple discrete encodings. Extensive experiments demonstrate consistent improvements over continuous agreement baselines on image classification, retrieval, and dense visual prediction tasks, as well as under domain shift through self-supervised adaptation. Beyond backbone representations, we analyze the learned binary codes and show that they form a compact and informative discrete language, capturing semantic factors reusable across classes.

</details>


### [71] [Where Do Images Come From? Analyzing Captions to Geographically Profile Datasets](https://arxiv.org/abs/2602.09775)
*Abhipsa Basu,Yugam Bahl,Kirti Bhagat,Preethi Seshadri,R. Venkatesh Babu,Danish Pruthi*

Main category: cs.CV

TL;DR: 研究发现文本到图像模型的训练数据地理分布严重偏向高GDP国家，且代表性高不保证多样性。


<details>
  <summary>Details</summary>
Motivation: 探讨文本到图像模型的训练数据地理分布是否具有代表性，揭示数据集中存在的偏见。

Method: 通过使用LLM从标题中提取位置信息，对三个广泛使用的多模态数据集（Re-LAION、DataComp1B和Conceptual Captions）进行地理分析。

Result: 美国、英国和加拿大占样本的48.0%，而南美和非洲国家仅占1.8%和3.8%。GDP与数据代表性呈强相关（ρ=0.82）。非英语子集也偏向主要使用这些语言的国家。

Conclusion: 研究表明，文本到图像模型在生成地理代表性图像方面存在不足，训练数据的地理分布严重偏向高GDP国家，且代表性高并不等同于视觉或语义多样性。

Abstract: Recent studies show that text-to-image models often fail to generate geographically representative images, raising concerns about the representativeness of their training data and motivating the question: which parts of the world do these training examples come from? We geographically profile large-scale multimodal datasets by mapping image-caption pairs to countries based on location information extracted from captions using LLMs. Studying English captions from three widely used datasets (Re-LAION, DataComp1B, and Conceptual Captions) across $20$ common entities (e.g., house, flag), we find that the United States, the United Kingdom, and Canada account for $48.0\%$ of samples, while South American and African countries are severely under-represented with only $1.8\%$ and $3.8\%$ of images, respectively. We observe a strong correlation between a country's GDP and its representation in the data ($ρ= 0.82$). Examining non-English subsets for $4$ languages from the Re-LAION dataset, we find that representation skews heavily toward countries where these languages are predominantly spoken. Additionally, we find that higher representation does not necessarily translate to greater visual or semantic diversity. Finally, analyzing country-specific images generated by Stable Diffusion v1.3 trained on Re-LAION, we show that while generations appear realistic, they are severely limited in their coverage compared to real-world images.

</details>


### [72] [Bladder Vessel Segmentation using a Hybrid Attention-Convolution Framework](https://arxiv.org/abs/2602.09949)
*Franziska Krauß,Matthias Ege,Zoltan Lovasz,Albrecht Bartz-Schmidt,Igor Tsaur,Oliver Sawodny,Carina Veil*

Main category: cs.CV

TL;DR: HAC架构结合Transformer和CNN，优化血管分割，显著提升膀胱癌监测中的导航可靠性。


<details>
  <summary>Details</summary>
Motivation: 膀胱的可变形和中空特性缺乏稳定的地标，而现有血管分割方法难以应对内窥镜数据中的复杂问题，如稀疏标签、伪影和黏膜褶皱。

Method: 采用混合注意力-卷积（HAC）架构，结合Transformer捕获全局血管拓扑先验，CNN学习残差细化图以精确恢复细血管细节。通过优化训练数据和自监督预训练策略解决数据稀缺问题。

Result: 在BlaVeS数据集上评估，HAC方法达到高准确率（0.94）、卓越的精确度（0.61）和clDice（0.66），显著优于现有医学分割模型。

Conclusion: HAC架构通过结合Transformer和CNN，成功解决了膀胱癌监测中血管分割的挑战，提供了临床导航所需的可靠结构稳定性。

Abstract: Urinary bladder cancer surveillance requires tracking tumor sites across repeated interventions, yet the deformable and hollow bladder lacks stable landmarks for orientation. While blood vessels visible during endoscopy offer a patient-specific "vascular fingerprint" for navigation, automated segmentation is challenged by imperfect endoscopic data, including sparse labels, artifacts like bubbles or variable lighting, continuous deformation, and mucosal folds that mimic vessels. State-of-the-art vessel segmentation methods often fail to address these domain-specific complexities. We introduce a Hybrid Attention-Convolution (HAC) architecture that combines Transformers to capture global vessel topology prior with a CNN that learns a residual refinement map to precisely recover thin-vessel details. To prioritize structural connectivity, the Transformer is trained on optimized ground truth data that exclude short and terminal branches. Furthermore, to address data scarcity, we employ a physics-aware pretraining, that is a self-supervised strategy using clinically grounded augmentations on unlabeled data. Evaluated on the BlaVeS dataset, consisting of endoscopic video frames, our approach achieves high accuracy (0.94) and superior precision (0.61) and clDice (0.66) compared to state-of-the-art medical segmentation models. Crucially, our method successfully suppresses false positives from mucosal folds that dynamically appear and vanish as the bladder fills and empties during surgery. Hence, HAC provides the reliable structural stability required for clinical navigation.

</details>


### [73] [SciFlow-Bench: Evaluating Structure-Aware Scientific Diagram Generation via Inverse Parsing](https://arxiv.org/abs/2602.09809)
*Tong Zhang,Honglin Lin,Zhou Liu,Chong Chen,Wentao Zhang*

Main category: cs.CV

TL;DR: SciFlow-Bench是一个新的基准，用于评估科学图表生成的结构正确性，通过逆向解析生成的图像回结构化图进行比较，实验显示结构正确性仍是挑战。


<details>
  <summary>Details</summary>
Motivation: 现代文本到图像模型通常产生视觉上合理但结构上不正确的结果，现有基准要么依赖于图像中心或主观指标，要么评估中间符号表示而非最终渲染图像，导致基于像素的图表生成研究不足。

Method: 我们引入了SciFlow-Bench，这是一个结构优先的基准，用于直接从像素级输出评估科学图表生成。该基准通过一个闭环、往返协议，将生成的图表图像逆向解析回结构化图进行比较。

Result: 实验表明，保持结构正确性仍然是一个基本挑战，特别是对于具有复杂拓扑结构的图表。

Conclusion: 保持结构正确性仍然是科学图表生成的一个基本挑战，特别是对于具有复杂拓扑结构的图表，这强调了结构感知评估的必要性。

Abstract: Scientific diagrams convey explicit structural information, yet modern text-to-image models often produce visually plausible but structurally incorrect results. Existing benchmarks either rely on image-centric or subjective metrics insensitive to structure, or evaluate intermediate symbolic representations rather than final rendered images, leaving pixel-based diagram generation underexplored. We introduce SciFlow-Bench, a structure-first benchmark for evaluating scientific diagram generation directly from pixel-level outputs. Built from real scientific PDFs, SciFlow-Bench pairs each source framework figure with a canonical ground-truth graph and evaluates models as black-box image generators under a closed-loop, round-trip protocol that inverse-parses generated diagram images back into structured graphs for comparison. This design enforces evaluation by structural recoverability rather than visual similarity alone, and is enabled by a hierarchical multi-agent system that coordinates planning, perception, and structural reasoning. Experiments show that preserving structural correctness remains a fundamental challenge, particularly for diagrams with complex topology, underscoring the need for structure-aware evaluation.

</details>


### [74] [Coupled Inference in Diffusion Models for Semantic Decomposition](https://arxiv.org/abs/2602.09983)
*Calvin Yeung,Ali Zakeri,Zhuowen Zou,Mohsen Imani*

Main category: cs.CV

TL;DR: 本文提出了一种基于耦合扩散模型的语义分解方法，通过逆问题和重建引导优化分解性能，实证优于谐振子网络。


<details>
  <summary>Details</summary>
Motivation: 受到Hopfield网络与扩散模型相似性的启发，旨在解决绑定表示的分解问题，以支持有效的识别、推理和编辑。

Method: 通过将语义分解视为逆问题，并利用重建驱动的引导项耦合扩散过程，鼓励因子估计的组合与绑定向量匹配，同时引入了一种新颖的迭代采样方案。

Result: 实证结果表明，耦合推理框架在一系列合成语义分解任务中优于谐振子网络。

Conclusion: 本文提出了一种基于耦合扩散模型的语义分解框架，证明了其在合成语义分解任务中优于谐振子网络，并指出基于注意力的谐振子网络是该框架的特例。

Abstract: Many visual scenes can be described as compositions of latent factors. Effective recognition, reasoning, and editing often require not only forming such compositional representations, but also solving the decomposition problem. One popular choice for constructing these representations is through the binding operation. Resonator networks, which can be understood as coupled Hopfield networks, were proposed as a way to perform decomposition on such bound representations. Recent works have shown notable similarities between Hopfield networks and diffusion models. Motivated by these observations, we introduce a framework for semantic decomposition using coupled inference in diffusion models. Our method frames semantic decomposition as an inverse problem and couples the diffusion processes using a reconstruction-driven guidance term that encourages the composition of factor estimates to match the bound vector. We also introduce a novel iterative sampling scheme that improves the performance of our model. Finally, we show that attention-based resonator networks are a special case of our framework. Empirically, we demonstrate that our coupled inference framework outperforms resonator networks across a range of synthetic semantic decomposition tasks.

</details>


### [75] [CompSplat: Compression-aware 3D Gaussian Splatting for Real-world Video](https://arxiv.org/abs/2602.09816)
*Hojun Song,Heejung Choi,Aro Kim,Chae-yeong Song,Gahyeon Kim,Soo Ye Kim,Jaehyup Lee,Sang-hyo Park*

Main category: cs.CV

TL;DR: CompSplat是一个压缩感知的NVS训练框架，通过建模压缩特性和自适应策略，显著提升了在严重压缩下的渲染和姿态准确性。


<details>
  <summary>Details</summary>
Motivation: 解决真实世界视频中因长序列、不规则相机轨迹和未知姿态导致的姿态漂移、特征错位和几何失真问题，以及压缩带来的不一致性。

Method: 提出CompSplat，一个压缩感知的训练框架，通过显式建模帧级压缩特性来缓解帧间不一致性和累积几何误差。

Result: 在Tanks and Temples、Free和Hike等挑战性基准测试中，CompSplat实现了最先进的渲染质量和姿态准确性。

Conclusion: CompSplat显著提升了在严重压缩条件下的渲染质量和姿态准确性，超越了现有最新的NVS方法。

Abstract: High-quality novel view synthesis (NVS) from real-world videos is crucial for applications such as cultural heritage preservation, digital twins, and immersive media. However, real-world videos typically contain long sequences with irregular camera trajectories and unknown poses, leading to pose drift, feature misalignment, and geometric distortion during reconstruction. Moreover, lossy compression amplifies these issues by introducing inconsistencies that gradually degrade geometry and rendering quality. While recent studies have addressed either long-sequence NVS or unposed reconstruction, compression-aware approaches still focus on specific artifacts or limited scenarios, leaving diverse compression patterns in long videos insufficiently explored. In this paper, we propose CompSplat, a compression-aware training framework that explicitly models frame-wise compression characteristics to mitigate inter-frame inconsistency and accumulated geometric errors. CompSplat incorporates compression-aware frame weighting and an adaptive pruning strategy to enhance robustness and geometric consistency, particularly under heavy compression. Extensive experiments on challenging benchmarks, including Tanks and Temples, Free, and Hike, demonstrate that CompSplat achieves state-of-the-art rendering quality and pose accuracy, significantly surpassing most recent state-of-the-art NVS approaches under severe compression conditions.

</details>


### [76] [SAKED: Mitigating Hallucination in Large Vision-Language Models via Stability-Aware Knowledge Enhanced Decoding](https://arxiv.org/abs/2602.09825)
*Zhaoxu Li,Chenqi Kong,Peijun Bao,Song Xia,Yi Tu,Yi Yu,Xinghao Jiang,Xudong Jiang*

Main category: cs.CV

TL;DR: SAKED通过量化知识稳定性动态利用可靠知识，无需训练即可减少LVLM幻觉，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 受人类在不确定或犹豫时更容易出错的启发，研究模型内部知识的不稳定性如何导致LVLM的幻觉问题。

Method: 提出Stability-Aware Knowledge-Enhanced Decoding (SAKED)，引入层间知识稳定性评分（KSS）来量化模型内部知识的稳定性，并通过对比最稳定和最不稳定层来抑制解码噪声。

Result: SAKED在多种模型、任务和基准测试中实现了最先进的幻觉缓解性能。

Conclusion: SAKED方法通过量化知识稳定性并动态利用最可靠的内部知识，有效减少了LVLM中的幻觉现象，且无需额外训练即可集成到不同架构中，实验证明其在多个任务和基准测试中达到了最先进的性能。

Abstract: Hallucinations in Large Vision-Language Models (LVLMs) pose significant security and reliability risks in real-world applications. Inspired by the observation that humans are more error-prone when uncertain or hesitant, we investigate how instability in a model 's internal knowledge contributes to LVLM hallucinations. We conduct extensive empirical analyses from three perspectives, namely attention heads, model layers, and decoding tokens, and identify three key hallucination patterns: (i) visual activation drift across attention heads, (ii) pronounced knowledge fluctuations across layers, and (iii) visual focus distraction between neighboring output tokens. Building on these findings, we propose Stability-Aware Knowledge-Enhanced Decoding (SAKED), which introduces a layer-wise Knowledge Stability Score (KSS) to quantify knowledge stability throughout the model. By contrasting the most stability-aware and stability-agnostic layers, SAKED suppresses decoding noise and dynamically leverages the most reliable internal knowledge for faithful token generation. Moreover, SAKED is training-free and can be seamlessly integrated into different architectures. Extensive experiments demonstrate that SAKED achieves state-of-the-art performance for hallucination mitigation on various models, tasks, and benchmarks.

</details>


### [77] [ARK: A Dual-Axis Multimodal Retrieval Benchmark along Reasoning and Knowledge](https://arxiv.org/abs/2602.09839)
*Yijie Lin,Guofeng Ding,Haochen Zhou,Haobin Li,Mouxing Yang,Xi Peng*

Main category: cs.CV

TL;DR: ARK是一个多模态检索基准，通过知识领域和推理技能分析检索性能，发现现有模型在复杂推理和专业知识上存在显著不足。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试主要关注日常图像的语义匹配，缺乏对专业知识和复杂推理的诊断。ARK旨在填补这一空白，分析多模态检索的知识领域和推理技能。

Method: ARK基准测试通过两个互补的视角分析多模态检索：知识领域（五个领域，17个子类型）和推理技能（六类）。评估使用单模态和多模态查询及候选，涵盖16种异构视觉数据类型，并设计有针对性的困难负样本以避免捷径匹配。

Result: 评估了23种代表性检索模型，发现知识密集型和推理密集型检索之间存在显著差距，细粒度视觉和空间推理是主要瓶颈。

Conclusion: ARK基准测试揭示了知识密集型和推理密集型检索之间的显著差距，细粒度的视觉和空间推理是持续的瓶颈。简单的增强方法如重排序和重写能带来一致的改进，但仍有很大的提升空间。

Abstract: Existing multimodal retrieval benchmarks largely emphasize semantic matching on daily-life images and offer limited diagnostics of professional knowledge and complex reasoning. To address this gap, we introduce ARK, a benchmark designed to analyze multimodal retrieval from two complementary perspectives: (i) knowledge domains (five domains with 17 subtypes), which characterize the content and expertise retrieval relies on, and (ii) reasoning skills (six categories), which characterize the type of inference over multimodal evidence required to identify the correct candidate. Specifically, ARK evaluates retrieval with both unimodal and multimodal queries and candidates, covering 16 heterogeneous visual data types. To avoid shortcut matching during evaluation, most queries are paired with targeted hard negatives that require multi-step reasoning. We evaluate 23 representative text-based and multimodal retrievers on ARK and observe a pronounced gap between knowledge-intensive and reasoning-intensive retrieval, with fine-grained visual and spatial reasoning emerging as persistent bottlenecks. We further show that simple enhancements such as re-ranking and rewriting yield consistent improvements, but substantial headroom remains.

</details>


### [78] [Fake-HR1: Rethinking reasoning of vision language model for synthetic image detection](https://arxiv.org/abs/2602.10042)
*Changjiang Jiang,Xinkuan Sha,Fengchang Yu,Jingjing Liu,Jian Liu,Mingqi Fang,Chenfeng Zhang,Wei Lu*

Main category: cs.CV

TL;DR: Fake-HR1是首个基于生成检测任务特性自适应决定推理需求的混合推理模型，通过两阶段训练实现高效检测。


<details>
  <summary>Details</summary>
Motivation: 解决传统CoT推理在检测合成图像时因过长推理导致的资源冗余问题。

Method: 提出两阶段训练框架：混合微调（HFT）冷启动初始化，随后通过混合推理分组策略优化（HGRPO）进行在线强化学习。

Result: Fake-HR1能自适应选择推理模式，在推理能力和生成检测性能上均优于现有模型，同时显著提升响应效率。

Conclusion: Fake-HR1通过自适应推理显著提升了生成检测任务的效率和性能，超越了现有LLM模型。

Abstract: Recent studies have demonstrated that incorporating Chain-of-Thought (CoT) reasoning into the detection process can enhance a model's ability to detect synthetic images. However, excessively lengthy reasoning incurs substantial resource overhead, including token consumption and latency, which is particularly redundant when handling obviously generated forgeries. To address this issue, we propose Fake-HR1, a large-scale hybrid-reasoning model that, to the best of our knowledge, is the first to adaptively determine whether reasoning is necessary based on the characteristics of the generative detection task. To achieve this, we design a two-stage training framework: we first perform Hybrid Fine-Tuning (HFT) for cold-start initialization, followed by online reinforcement learning with Hybrid-Reasoning Grouped Policy Optimization (HGRPO) to implicitly learn when to select an appropriate reasoning mode. Experimental results show that Fake-HR1 adaptively performs reasoning across different types of queries, surpassing existing LLMs in both reasoning ability and generative detection performance, while significantly improving response efficiency.

</details>


### [79] [Kelix Technique Report](https://arxiv.org/abs/2602.09843)
*Boyang Ding,Chenglong Chu,Dunju Zang,Han Li,Jiangxia Cao,Kun Gai,Muhao Wei,Ruiming Tang,Shiyao Wang,Siyang Mao,Xinchen Luo,Yahui Liu,Zhixin Ling,Zhuoran Yang,Ziming Li,Chengru Song,Guorui Zhou,Guowang Zhang,Hao Peng,Hao Wang,Jiaxin Deng,Jin Ouyang,Jinghao Zhang,Lejian Ren,Qianqian Wang,Qigen Hu,Tao Wang,Xingmei Wang,Yiping Yang,Zixing Zhang,Ziqi Wang*

Main category: cs.CV

TL;DR: Kelix是一种完全离散的自回归统一模型，通过改进离散视觉标记化技术，显著提升了多模态理解能力，缩小了与连续特征模型的差距。


<details>
  <summary>Details</summary>
Motivation: 现有的视觉语言模型（VLMs）多采用离散文本标记与连续视觉特征的混合接口，导致模型偏向理解且难以充分利用非文本数据的自监督学习。

Method: 采用离散视觉标记化技术，构建完全离散的自回归统一模型Kelix。

Result: Kelix在理解能力上显著优于现有离散视觉标记化方法，接近连续特征VLMs的表现。

Conclusion: Kelix模型成功弥合了离散与连续视觉表示之间的理解差距，实现了完全离散的自回归统一建模。

Abstract: Autoregressive large language models (LLMs) scale well by expressing diverse tasks as sequences of discrete natural-language tokens and training with next-token prediction, which unifies comprehension and generation under self-supervision. Extending this paradigm to multimodal data requires a shared, discrete representation across modalities. However, most vision-language models (VLMs) still rely on a hybrid interface: discrete text tokens paired with continuous Vision Transformer (ViT) features. Because supervision is largely text-driven, these models are often biased toward understanding and cannot fully leverage large-scale self-supervised learning on non-text data. Recent work has explored discrete visual tokenization to enable fully autoregressive multimodal modeling, showing promising progress toward unified understanding and generation. Yet existing discrete vision tokens frequently lose information due to limited code capacity, resulting in noticeably weaker understanding than continuous-feature VLMs. We present Kelix, a fully discrete autoregressive unified model that closes the understanding gap between discrete and continuous visual representations.

</details>


### [80] [Causality in Video Diffusers is Separable from Denoising](https://arxiv.org/abs/2602.10095)
*Xingjian Bai,Guande He,Zhengqi Li,Eli Shechtman,Xun Huang,Zongze Wu*

Main category: cs.CV

TL;DR: SCD架构解耦时间推理与去噪，提升效率且不牺牲生成质量。


<details>
  <summary>Details</summary>
Motivation: 现有因果扩散模型将时间推理与迭代去噪过程纠缠在一起，导致计算冗余和效率低下。研究发现早期层特征相似，深层注意力稀疏，表明二者可分离。

Method: 提出了可分离因果扩散（SCD）架构，通过因果变换器编码器实现每帧一次的时间推理，轻量级扩散解码器实现多步帧级渲染。

Result: 在合成和真实基准测试中，SCD在预训练和后训练任务上均显著提升性能，同时保持或超越生成质量。

Conclusion: SCD架构通过解耦时间推理和多步去噪过程，显著提高了吞吐量和每帧延迟，同时生成质量与现有因果扩散基线相当或更优。

Abstract: Causality -- referring to temporal, uni-directional cause-effect relationships between components -- underlies many complex generative processes, including videos, language, and robot trajectories. Current causal diffusion models entangle temporal reasoning with iterative denoising, applying causal attention across all layers, at every denoising step, and over the entire context. In this paper, we show that the causal reasoning in these models is separable from the multi-step denoising process. Through systematic probing of autoregressive video diffusers, we uncover two key regularities: (1) early layers produce highly similar features across denoising steps, indicating redundant computation along the diffusion trajectory; and (2) deeper layers exhibit sparse cross-frame attention and primarily perform intra-frame rendering. Motivated by these findings, we introduce Separable Causal Diffusion (SCD), a new architecture that explicitly decouples once-per-frame temporal reasoning, via a causal transformer encoder, from multi-step frame-wise rendering, via a lightweight diffusion decoder. Extensive experiments on both pretraining and post-training tasks across synthetic and real benchmarks show that SCD significantly improves throughput and per-frame latency while matching or surpassing the generation quality of strong causal diffusion baselines.

</details>


### [81] [Reason-IAD: Knowledge-Guided Dynamic Latent Reasoning for Explainable Industrial Anomaly Detection](https://arxiv.org/abs/2602.09850)
*Peng Chen,Chao Huang,Yunkang Cao,Chengliang Liu,Wenqiang Wang,Mingbo Yang,Li Shen,Wenqi Ren,Xiaochun Cao*

Main category: cs.CV

TL;DR: Reason-IAD是一个知识引导的动态潜在推理框架，通过检索增强的知识模块和熵驱动推理机制，显著提升了工业异常检测的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有的多模态大语言模型（MLLMs）在通用数据上预训练，难以捕捉特定类别的异常，限制了检测准确性和可解释性。

Method: Reason-IAD包含两个核心组件：检索增强的知识模块（引入类别特定文本描述）和熵驱动的潜在推理机制（在紧凑潜在空间中进行迭代探索）。此外，动态视觉注入策略选择性地将信息量最高的图像块纳入潜在序列。

Result: 实验结果表明，Reason-IAD在工业异常检测任务中 consistently outperforms state-of-the-art methods。

Conclusion: Reason-IAD通过知识引导的动态潜在推理框架，显著提升了工业异常检测的准确性和可解释性，并在实验中超越了现有最先进方法。

Abstract: Industrial anomaly detection demands precise reasoning over fine-grained defect patterns. However, existing multimodal large language models (MLLMs), pretrained on general-domain data, often struggle to capture category-specific anomalies, thereby limiting both detection accuracy and interpretability. To address these limitations, we propose Reason-IAD, a knowledge-guided dynamic latent reasoning framework for explainable industrial anomaly detection. Reason-IAD comprises two core components. First, a retrieval-augmented knowledge module incorporates category-specific textual descriptions into the model input, enabling context-aware reasoning over domain-specific defects. Second, an entropy-driven latent reasoning mechanism conducts iterative exploration within a compact latent space using optimizable latent think tokens, guided by an entropy-based reward that encourages confident and stable predictions. Furthermore, a dynamic visual injection strategy selectively incorporates the most informative image patches into the latent sequence, directing the reasoning process toward regions critical for anomaly detection. Extensive experimental results demonstrate that Reason-IAD consistently outperforms state-of-the-art methods. The code will be publicly available at https://github.com/chenpeng052/Reason-IAD.

</details>


### [82] [Olaf-World: Orienting Latent Actions for Video World Modeling](https://arxiv.org/abs/2602.10104)
*Yuxin Jiang,Yuchao Gu,Ivor W. Tsang,Mike Zheng Shou*

Main category: cs.CV

TL;DR: 提出 Seq$Δ$-REPA 和 Olaf-World，通过序列级控制效果对齐学习结构化潜在动作空间，显著提升迁移和适应能力。


<details>
  <summary>Details</summary>
Motivation: 解决潜在动作学习中跨上下文迁移失败的问题，即潜在动作往往与场景特定线索纠缠且缺乏共享坐标系。

Method: 引入 Seq$Δ$-REPA，一种序列级控制效果对齐目标，将潜在动作与自监督视频编码器的时序特征差异对齐，并构建了 Olaf-World 流程。

Result: 实验表明，该方法学习的潜在动作空间更具结构性，零样本动作迁移和新控制接口适应能力优于现有基线。

Conclusion: Seq$Δ$-REPA 和 Olaf-World 通过学习更结构化的潜在动作空间，显著提升了零样本动作迁移和新控制接口的数据高效适应能力。

Abstract: Scaling action-controllable world models is limited by the scarcity of action labels. While latent action learning promises to extract control interfaces from unlabeled video, learned latents often fail to transfer across contexts: they entangle scene-specific cues and lack a shared coordinate system. This occurs because standard objectives operate only within each clip, providing no mechanism to align action semantics across contexts. Our key insight is that although actions are unobserved, their semantic effects are observable and can serve as a shared reference. We introduce Seq$Δ$-REPA, a sequence-level control-effect alignment objective that anchors integrated latent action to temporal feature differences from a frozen, self-supervised video encoder. Building on this, we present Olaf-World, a pipeline that pretrains action-conditioned video world models from large-scale passive video. Extensive experiments demonstrate that our method learns a more structured latent action space, leading to stronger zero-shot action transfer and more data-efficient adaptation to new control interfaces than state-of-the-art baselines.

</details>


### [83] [Free-GVC: Towards Training-Free Extreme Generative Video Compression with Temporal Coherence](https://arxiv.org/abs/2602.09868)
*Xiaoyue Ling,Chuqin Zhou,Chunyi Li,Yunuo Chen,Yuan Tian,Guo Lu,Wenjun Zhang*

Main category: cs.CV

TL;DR: Free-GVC是一种无训练生成视频压缩框架，通过潜在轨迹压缩和自适应质量控制，显著提升超低比特率下的视频质量。


<details>
  <summary>Details</summary>
Motivation: 现有生成视频压缩方法在超低比特率下存在时间相关性利用不足，导致闪烁和时间一致性差的问题。

Method: 提出Free-GVC框架，采用基于视频扩散先验的潜在轨迹压缩方法，包含自适应质量控制模块和组间对齐模块。

Result: 实验显示Free-GVC在DISTS指标上平均降低93.29% BD-Rate，用户研究证实其在超低比特率下的优越感知质量和时间一致性。

Conclusion: Free-GVC通过创新的无训练生成视频压缩框架，显著提升了超低比特率下的视觉质量和时间一致性，实验证明其性能优于现有神经编解码器。

Abstract: Building on recent advances in video generation, generative video compression has emerged as a new paradigm for achieving visually pleasing reconstructions. However, existing methods exhibit limited exploitation of temporal correlations, causing noticeable flicker and degraded temporal coherence at ultra-low bitrates. In this paper, we propose Free-GVC, a training-free generative video compression framework that reformulates video coding as latent trajectory compression guided by a video diffusion prior. Our method operates at the group-of-pictures (GOP) level, encoding video segments into a compact latent space and progressively compressing them along the diffusion trajectory. To ensure perceptually consistent reconstruction across GOPs, we introduce an Adaptive Quality Control module that dynamically constructs an online rate-perception surrogate model to predict the optimal diffusion step for each GOP. In addition, an Inter-GOP Alignment module establishes frame overlap and performs latent fusion between adjacent groups, thereby mitigating flicker and enhancing temporal coherence. Experiments show that Free-GVC achieves an average of 93.29% BD-Rate reduction in DISTS over the latest neural codec DCVC-RT, and a user study further confirms its superior perceptual quality and temporal coherence at ultra-low bitrates.

</details>


### [84] [BabyMamba-HAR: Lightweight Selective State Space Models for Efficient Human Activity Recognition on Resource Constrained Devices](https://arxiv.org/abs/2602.09872)
*Mridankan Mandal*

Main category: cs.CV

TL;DR: BabyMamba-HAR提出两种轻量级Mamba架构，在资源受限的HAR任务中高效匹配TinyHAR性能，计算量减少11倍，双向扫描和时间注意力池化显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决在内存和计算资源受限的可穿戴设备上实现高精度HAR的挑战，同时探索SSM在TinyML领域的应用设计空间。

Method: 论文提出了两种轻量级Mamba架构：CI-BabyMamba-HAR（通道独立处理）和Crossover-BiDir-BabyMamba-HAR（早期融合处理），结合了权重绑定的双向扫描和轻量级时间注意力池化。

Result: Crossover-BiDir-BabyMamba-HAR在八个基准测试中平均宏F1-score达到86.52%，参数约27K，MACs为2.21M，性能与TinyHAR相当但计算量减少11倍。双向扫描和时间注意力池化分别贡献了8.42%和8.94%的F1-score提升。

Conclusion: BabyMamba-HAR框架通过两种新颖的轻量级Mamba架构（CI-BabyMamba-HAR和Crossover-BiDir-BabyMamba-HAR）在资源受限的HAR任务中实现了高效性能，为TinyML领域的SSM部署提供了实用设计原则。

Abstract: Human activity recognition (HAR) on wearable and mobile devices is constrained by memory footprint and computational budget, yet competitive accuracy must be maintained across heterogeneous sensor configurations. Selective state space models (SSMs) offer linear time sequence processing with input dependent gating, presenting a compelling alternative to quadratic complexity attention mechanisms. However, the design space for deploying SSMs in the TinyML regime remains largely unexplored. In this paper, BabyMamba-HAR is introduced, a framework comprising two novel lightweight Mamba inspired architectures optimized for resource constrained HAR: (1) CI-BabyMamba-HAR, using a channel independent stem that processes each sensor channel through shared weight, but instance independent transformations to prevent cross channel noise propagation, and (2) Crossover-BiDir-BabyMamba-HAR, using an early fusion stem that achieves channel count independent computational complexity. Both variants incorporate weight tied bidirectional scanning and lightweight temporal attention pooling. Through evaluation across eight diverse benchmarks, it is demonstrated that Crossover-BiDir-BabyMamba-HAR achieves 86.52% average macro F1-score with approximately 27K parameters and 2.21M MACs, matching TinyHAR (86.16%) while requiring 11x fewer MACs on high channel datasets. Systematic ablation studies reveal that bidirectional scanning contributes up to 8.42% F1-score improvement, and gated temporal attention provides up to 8.94% F1-score gain over mean pooling. These findings establish practical design principles for deploying selective state space models as efficient TinyML backbones for HAR.

</details>


### [85] [MVISTA-4D: View-Consistent 4D World Model with Test-Time Action Inference for Robotic Manipulation](https://arxiv.org/abs/2602.09878)
*Jiaxu Wang,Yicheng Jiang,Tianlun He,Jingkai Sun,Qiang Zhang,Junhao He,Jiahang Cao,Zesen Gan,Mingyuan Sun,Qiming Shao,Xiangyu Yue*

Main category: cs.CV

TL;DR: 该论文提出了一种4D世界模型，通过跨视图和跨模态特征融合实现几何一致的任意视角RGBD生成，并通过动作优化策略提升下游操作性能。


<details>
  <summary>Details</summary>
Motivation: 现有的机器人操作方法在4D场景动态预测方面存在局限性，无法同时支持纯图像预测和部分3D几何推理。因此，需要一种能够预测完整4D场景动态的模型。

Method: 论文设计了跨视图和跨模态特征融合机制，联合促进RGB与深度之间的一致性，并强制视图间的几何对齐。此外，提出了一种测试时动作优化策略和残差逆动力学模型，以解决逆动力学问题。

Result: 在三个数据集上的实验表明，该模型在4D场景生成和下游操作任务中表现出色。

Conclusion: 该论文提出了一种新颖的4D世界模型，通过实验验证了其在4D场景生成和下游操作任务中的优越性能，并通过消融研究提供了关键设计选择的实用见解。

Abstract: World-model-based imagine-then-act becomes a promising paradigm for robotic manipulation, yet existing approaches typically support either purely image-based forecasting or reasoning over partial 3D geometry, limiting their ability to predict complete 4D scene dynamics. This work proposes a novel embodied 4D world model that enables geometrically consistent, arbitrary-view RGBD generation: given only a single-view RGBD observation as input, the model imagines the remaining viewpoints, which can then be back-projected and fused to assemble a more complete 3D structure across time. To efficiently learn the multi-view, cross-modality generation, we explicitly design cross-view and cross-modality feature fusion that jointly encourage consistency between RGB and depth and enforce geometric alignment across views. Beyond prediction, converting generated futures into actions is often handled by inverse dynamics, which is ill-posed because multiple actions can explain the same transition. We address this with a test-time action optimization strategy that backpropagates through the generative model to infer a trajectory-level latent best matching the predicted future, and a residual inverse dynamics model that turns this trajectory prior into accurate executable actions. Experiments on three datasets demonstrate strong performance on both 4D scene generation and downstream manipulation, and ablations provide practical insights into the key design choices.

</details>


### [86] [AdaTSQ: Pushing the Pareto Frontier of Diffusion Transformers via Temporal-Sensitivity Quantization](https://arxiv.org/abs/2602.09883)
*Shaoqiu Zhang,Zizhong Ding,Kaicheng Yang,Junyi Wu,Xianglong Yan,Xi Li,Bingnan Duan,Jianping Fang,Yulun Zhang*

Main category: cs.CV

TL;DR: AdaTSQ是一种针对Diffusion Transformers的后训练量化框架，通过动态位宽分配和时间校准，提升了效率和生成质量。


<details>
  <summary>Details</summary>
Motivation: 解决Diffusion Transformers在边缘设备上部署时的高计算成本和内存占用问题。

Method: 提出了Pareto感知的时间动态位宽分配策略和Fisher引导的时间校准机制。

Result: 在四个先进的DiTs上实验表明，AdaTSQ显著优于现有方法如SVDQuant和ViDiT-Q。

Conclusion: AdaTSQ提出了一种新颖的后训练量化框架，通过利用DiTs的时间敏感性，显著提升了效率和生成质量的平衡。

Abstract: Diffusion Transformers (DiTs) have emerged as the state-of-the-art backbone for high-fidelity image and video generation. However, their massive computational cost and memory footprint hinder deployment on edge devices. While post-training quantization (PTQ) has proven effective for large language models (LLMs), directly applying existing methods to DiTs yields suboptimal results due to the neglect of the unique temporal dynamics inherent in diffusion processes. In this paper, we propose AdaTSQ, a novel PTQ framework that pushes the Pareto frontier of efficiency and quality by exploiting the temporal sensitivity of DiTs. First, we propose a Pareto-aware timestep-dynamic bit-width allocation strategy. We model the quantization policy search as a constrained pathfinding problem. We utilize a beam search algorithm guided by end-to-end reconstruction error to dynamically assign layer-wise bit-widths across different timesteps. Second, we propose a Fisher-guided temporal calibration mechanism. It leverages temporal Fisher information to prioritize calibration data from highly sensitive timesteps, seamlessly integrating with Hessian-based weight optimization. Extensive experiments on four advanced DiTs (e.g., Flux-Dev, Flux-Schnell, Z-Image, and Wan2.1) demonstrate that AdaTSQ significantly outperforms state-of-the-art methods like SVDQuant and ViDiT-Q. Our code will be released at https://github.com/Qiushao-E/AdaTSQ.

</details>


### [87] [A benchmark for video-based laparoscopic skill analysis and assessment](https://arxiv.org/abs/2602.09927)
*Isabel Funke,Sebastian Bodenstedt,Felix von Bechtolsheim,Florian Oehme,Michael Maruschke,Stefanie Herrlich,Jürgen Weitz,Marius Distler,Sören Torge Mees,Stefanie Speidel*

Main category: cs.CV

TL;DR: LASANA数据集解决了手术技能评估中数据不足的问题，提供了1270个标注视频和基准结果。


<details>
  <summary>Details</summary>
Motivation: 解决深度学习模型开发和评估中可用标注数据集规模有限的问题。

Method: 引入LASANA数据集，包含1270个立体视频记录，每个记录标注有结构化技能评分和任务特定错误的二进制标签。

Result: 提供了预定义的数据分割和深度学习模型的基线结果，作为未来比较的参考点。

Conclusion: LASANA数据集的引入为基于视频的手术技能评估和错误识别提供了基准，并为未来研究提供了参考基线。

Abstract: Laparoscopic surgery is a complex surgical technique that requires extensive training. Recent advances in deep learning have shown promise in supporting this training by enabling automatic video-based assessment of surgical skills. However, the development and evaluation of deep learning models is currently hindered by the limited size of available annotated datasets. To address this gap, we introduce the Laparoscopic Skill Analysis and Assessment (LASANA) dataset, comprising 1270 stereo video recordings of four basic laparoscopic training tasks. Each recording is annotated with a structured skill rating, aggregated from three independent raters, as well as binary labels indicating the presence or absence of task-specific errors. The majority of recordings originate from a laparoscopic training course, thereby reflecting a natural variation in the skill of participants. To facilitate benchmarking of both existing and novel approaches for video-based skill assessment and error recognition, we provide predefined data splits for each task. Furthermore, we present baseline results from a deep learning model as a reference point for future comparisons.

</details>


### [88] [GeoFormer: A Swin Transformer-Based Framework for Scene-Level Building Height and Footprint Estimation from Sentinel Imagery](https://arxiv.org/abs/2602.09932)
*Han Jinzhen,JinByeong Lee,JiSung Kim,MinKyung Cho,DaHee Kim,HongSik Yun*

Main category: cs.CV

TL;DR: GeoFormer利用开源数据和Transformer框架，显著提升建筑高度和足迹估计精度，适用于跨城市应用。


<details>
  <summary>Details</summary>
Motivation: 解决三维城市数据稀缺问题，因依赖专有传感器或跨城市泛化能力差。

Method: 使用Swin Transformer框架，结合Sentinel-1/2影像和公开DEM数据，采用地理分块策略确保训练与测试集的空间独立性。

Result: 在54个城市中，建筑高度RMSE为3.19米，足迹RMSE为0.05，分别比最强CNN基线提高7.5%和15.3%。

Conclusion: GeoFormer通过开源框架和公开数据，显著提高了建筑高度和足迹的估计精度，并在跨大陆迁移中保持了良好的性能。

Abstract: Accurate three-dimensional urban data are critical for climate modelling, disaster risk assessment, and urban planning, yet remain scarce due to reliance on proprietary sensors or poor cross-city generalisation. We propose GeoFormer, an open-source Swin Transformer framework that jointly estimates building height (BH) and footprint (BF) on a 100 m grid using only Sentinel-1/2 imagery and open DEM data. A geo-blocked splitting strategy ensures strict spatial independence between training and test sets. Evaluated over 54 diverse cities, GeoFormer achieves a BH RMSE of 3.19 m and a BF RMSE of 0.05, improving 7.5% and 15.3% over the strongest CNN baseline, while maintaining under 3.5 m BH RMSE in cross-continent transfer. Ablation studies confirm that DEM is indispensable for height estimation and that optical reflectance dominates over SAR, though multi-source fusion yields the best overall accuracy. All code, weights, and global products are publicly released.

</details>


### [89] [VersaViT: Enhancing MLLM Vision Backbones via Task-Guided Optimization](https://arxiv.org/abs/2602.09934)
*Yikun Liu,Yuan Liu,Shangzhe Di,Haicheng Wang,Zhongyin Zhao,Le Tian,Xiao Zhou,Jie Zhou,Jiangchao Yao,Yanfeng Wang,Weidi Xie*

Main category: cs.CV

TL;DR: VersaViT通过多任务协作后训练优化MLLMs视觉编码器，使其成为通用视觉骨干。


<details>
  <summary>Details</summary>
Motivation: 探讨MLLMs中的视觉编码器是否能作为通用视觉骨干，可靠执行经典视觉中心任务。

Method: 提出VersaViT，一种多任务框架，通过轻量级任务头和多粒度监督优化视觉主干。

Result: 在各种下游任务中验证了VersaViT的有效性，展示了其在语言介导推理和像素级理解中的通用性。

Conclusion: VersaViT通过多任务协作后训练框架，成功优化了视觉主干，使其成为适用于语言介导推理和像素级理解的通用视觉骨干。

Abstract: Multimodal Large Language Models (MLLMs) have recently achieved remarkable success in visual-language understanding, demonstrating superior high-level semantic alignment within their vision encoders. An important question thus arises: Can these encoders serve as versatile vision backbones, capable of reliably performing classic vision-centric tasks as well? To address the question, we make the following contributions: (i) we identify that the vision encoders within MLLMs exhibit deficiencies in their dense feature representations, as evidenced by their suboptimal performance on dense prediction tasks (e.g., semantic segmentation, depth estimation); (ii) we propose VersaViT, a well-rounded vision transformer that instantiates a novel multi-task framework for collaborative post-training. This framework facilitates the optimization of the vision backbone via lightweight task heads with multi-granularity supervision; (iii) extensive experiments across various downstream tasks demonstrate the effectiveness of our method, yielding a versatile vision backbone suited for both language-mediated reasoning and pixel-level understanding.

</details>


### [90] [Learning to Detect Baked Goods with Limited Supervision](https://arxiv.org/abs/2602.09979)
*Thomas H. Schmitt,Maximilian Bundscherer,Tobias Bocklet*

Main category: cs.CV

TL;DR: 提出自动化监控德国面包店剩余产品的方案，通过弱监督和伪标签微调训练YOLOv11，性能超越完全监督基线。


<details>
  <summary>Details</summary>
Motivation: 自动化监控剩余产品可以优化生产，尤其对德国面包店至关重要，因为新鲜烘焙食品保质期短。现有开放词汇检测器（如OWLv2、Grounding DINO）不足以完成任务。

Method: 提出了两种训练工作流程：1）结合OWLv2和Grounding DINO定位与图像级监督进行弱监督训练；2）通过使用Segment Anything 2作为伪标签传播模型对视频帧进行微调以提高视角鲁棒性。最终选择YOLOv11进行检测任务。

Result: 仅依赖图像级监督的模型实现了0.91的平均精度（mAP）。通过伪标签微调，模型性能在非理想部署条件下提升了19.3%。

Conclusion: 结合两种工作流程训练的模型在非理想部署条件下超越了完全监督的基线模型，尽管仅依赖于图像级监督。

Abstract: Monitoring leftover products provides valuable insights that can be used to optimize future production. This is especially important for German bakeries because freshly baked goods have a very short shelf life. Automating this process can reduce labor costs, improve accuracy, and streamline operations. We propose automating this process using an object detection model to identify baked goods from images. However, the large diversity of German baked goods makes fully supervised training prohibitively expensive and limits scalability. Although open-vocabulary detectors (e.g., OWLv2, Grounding DINO) offer lexibility, we demonstrate that they are insufficient for our task. While motivated by bakeries, our work addresses the broader challenges of deploying computer vision in industries, where tasks are specialized and annotated datasets are scarce. We compile dataset splits with varying supervision levels, covering 19 classes of baked goods. We propose two training workflows to train an object detection model with limited supervision. First, we combine OWLv2 and Grounding DINO localization with image-level supervision to train the model in a weakly supervised manner. Second, we improve viewpoint robustness by fine-tuning on video frames annotated using Segment Anything 2 as a pseudo-label propagation model. Using these workflows, we train YOLOv11 for our detection task due to its favorable speed accuracy tradeoff. Relying solely on image-level supervision, the model achieves a mean Average Precision (mAP) of 0.91. Finetuning with pseudo-labels raises model performance by 19.3% under non-ideal deployment conditions. Combining these workflows trains a model that surpasses our fully-supervised baseline model under non-ideal deployment conditions, despite relying only on image-level supervision.

</details>


### [91] [Efficient Special Stain Classification](https://arxiv.org/abs/2602.09989)
*Oskar Thaeter,Christian Grashei,Anette Haas,Elisa Schmoeckel,Han Li,Peter J. Schüffler*

Main category: cs.CV

TL;DR: 比较两种自动染色分类方法，缩略图方法在泛化能力和效率上表现更优，适合数字病理工作流程。


<details>
  <summary>Details</summary>
Motivation: 病理学中染色技术的准确元数据对临床档案的质量控制和计算病理数据集的完整性至关重要。

Method: 比较了两种自动分类方法：多实例学习（MIL）管道和提出的轻量级缩略图方法。

Result: 在内部测试数据中，MIL表现最佳（16类宏F1：0.941；14类合并：0.969），而缩略图方法仍具竞争力（分别为0.897和0.953）。在外部TCGA数据中，缩略图模型泛化能力最佳（加权F1：0.843 vs. MIL的0.807）。缩略图方法还提高了两个数量级的吞吐量（5.635 vs. MIL的0.018 slides/s）。

Conclusion: 基于缩略图的分类方法为数字病理工作流程中的常规视觉质量控制提供了可扩展且稳健的解决方案。

Abstract: Stains are essential in histopathology to visualize specific tissue characteristics, with Haematoxylin and Eosin (H&E) serving as the clinical standard. However, pathologists frequently
  utilize a variety of special stains for the diagnosis of specific morphologies. Maintaining accurate metadata for these slides is critical for quality control in clinical archives and for
  the integrity of computational pathology datasets. In this work, we compare two approaches for automated classification of stains using whole slide images, covering the 14 most commonly
  used special stains in our institute alongside standard and frozen-section H&E. We evaluate a Multi-Instance Learning (MIL) pipeline and a proposed lightweight thumbnail-based approach.
  On internal test data, MIL achieved the highest performance (macro F1: 0.941 for 16 classes; 0.969 for 14 merged classes), while the thumbnail approach remained competitive (0.897 and
  0.953, respectively). On external TCGA data, the thumbnail model generalized best (weighted F1: 0.843 vs. 0.807 for MIL). The thumbnail approach also increased throughput by two orders of
  magnitude (5.635 vs. 0.018 slides/s for MIL with all patches). We conclude that thumbnail-based classification provides a scalable and robust solution for routine visual quality control
  in digital pathology workflows.

</details>


### [92] [Simple Image Processing and Similarity Measures Can Link Data Samples across Databases through Brain MRI](https://arxiv.org/abs/2602.10043)
*Gaurang Sharma,Harri Polonen,Juha Pajula,Jutta Suksi,Jussi Tohka*

Main category: cs.CV

TL;DR: 研究发现，去标识化处理的头部MRI图像仍可通过图像相似度计算实现跨数据库个体匹配，对医疗数据隐私政策提出新挑战。


<details>
  <summary>Details</summary>
Motivation: 现有监管框架要求去除MRI图像中的潜在标识符以保护隐私，但研究发现脑实质中的独特特征仍可能导致个体被重新识别，因此需要评估这一隐私风险。

Method: 采用标准预处理步骤后，通过图像相似度计算方法，评估了不同时间间隔、扫描仪类型、空间分辨率和采集协议下的MRI图像匹配准确性。

Result: 在各种条件下，包括时间间隔、扫描仪类型、空间分辨率和采集协议的差异，几乎实现了完美的匹配准确率。

Conclusion: 研究表明，即使是经过去标识化处理的头部MRI图像，仍可能通过标准预处理和图像相似度计算实现跨数据库的个体匹配，这对医疗数据共享的隐私政策提出了新的挑战。

Abstract: Head Magnetic Resonance Imaging (MRI) is routinely collected and shared for research under strict regulatory frameworks. These frameworks require removing potential identifiers before sharing. But, even after skull stripping, the brain parenchyma contains unique signatures that can match other MRIs from the same participants across databases, posing a privacy risk if additional data features are available. Current regulatory frameworks often mandate evaluating such risks based on the assessment of a certain level of reasonableness. Prior studies have already suggested that a brain MRI could enable participant linkage, but they have relied on training-based or computationally intensive methods.
  Here, we demonstrate that linking an individual's skull-stripped T1-weighted MRI, which may lead to re-identification if other identifiers are available, is possible using standard preprocessing followed by image similarity computation. Nearly perfect linkage accuracy was achieved in matching data samples across various time intervals, scanner types, spatial resolutions, and acquisition protocols, despite potential cognitive decline, simulating MRI matching across databases. These results aim to contribute meaningfully to the development of thoughtful, forward-looking policies in medical data sharing.

</details>


### [93] [Conformal Prediction Sets for Instance Segmentation](https://arxiv.org/abs/2602.10045)
*Kerri Lu,Dan M. Kluger,Stephen Bates,Sherrie Wang*

Main category: cs.CV

TL;DR: 提出保形预测算法为实例分割提供不确定性量化，实验验证其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有实例分割模型缺乏不确定性量化，无法保证预测掩码接近真实值。

Method: 引入保形预测算法，为实例分割生成置信集，并通过理论和实验验证其有效性。

Result: 实验表明，该算法能根据查询难度调整预测集大小，并达到目标覆盖率，优于现有基线方法。

Conclusion: 本文提出了一种用于实例分割的保形预测算法，能够生成自适应的置信集，并提供概率保证，确保预测结果与真实对象掩码具有高IoU。

Abstract: Current instance segmentation models achieve high performance on average predictions, but lack principled uncertainty quantification: their outputs are not calibrated, and there is no guarantee that a predicted mask is close to the ground truth. To address this limitation, we introduce a conformal prediction algorithm to generate adaptive confidence sets for instance segmentation. Given an image and a pixel coordinate query, our algorithm generates a confidence set of instance predictions for that pixel, with a provable guarantee for the probability that at least one of the predictions has high Intersection-Over-Union (IoU) with the true object instance mask. We apply our algorithm to instance segmentation examples in agricultural field delineation, cell segmentation, and vehicle detection. Empirically, we find that our prediction sets vary in size based on query difficulty and attain the target coverage, outperforming existing baselines such as Learn Then Test, Conformal Risk Control, and morphological dilation-based methods. We provide versions of the algorithm with asymptotic and finite sample guarantees.

</details>


### [94] [Spatio-Temporal Attention for Consistent Video Semantic Segmentation in Automated Driving](https://arxiv.org/abs/2602.10052)
*Serin Varghese,Kevin Ross,Fabian Hueger,Kira Maag*

Main category: cs.CV

TL;DR: 提出STA机制，通过融入多帧上下文提升视频语义分割的时空一致性，实验显示显著效果提升。


<details>
  <summary>Details</summary>
Motivation: 现有模型独立处理视频帧，未能利用时间一致性，这在动态场景中可能显著提升准确性和稳定性。

Method: 提出了一种时空注意力（STA）机制，扩展了transformer的注意力块以融入多帧上下文，从而实现对视频语义分割的鲁棒时空特征表示。该方法在保持计算效率的同时，仅需对现有架构进行最小改动。

Result: 在Cityscapes和BDD100k数据集上的评估显示，STA在时间一致性指标上提升了9.20个百分点，在mIoU上提升了1.76个百分点。

Conclusion: STA机制作为一种有效的架构增强，显著提升了视频语义分割的准确性和稳定性，特别是在动态场景中。

Abstract: Deep neural networks, especially transformer-based architectures, have achieved remarkable success in semantic segmentation for environmental perception. However, existing models process video frames independently, thus failing to leverage temporal consistency, which could significantly improve both accuracy and stability in dynamic scenes. In this work, we propose a Spatio-Temporal Attention (STA) mechanism that extends transformer attention blocks to incorporate multi-frame context, enabling robust temporal feature representations for video semantic segmentation. Our approach modifies standard self-attention to process spatio-temporal feature sequences while maintaining computational efficiency and requiring minimal changes to existing architectures. STA demonstrates broad applicability across diverse transformer architectures and remains effective across both lightweight and larger-scale models. A comprehensive evaluation on the Cityscapes and BDD100k datasets shows substantial improvements of 9.20 percentage points in temporal consistency metrics and up to 1.76 percentage points in mean intersection over union compared to single-frame baselines. These results demonstrate STA as an effective architectural enhancement for video-based semantic segmentation applications.

</details>


### [95] [Can Image Splicing and Copy-Move Forgery Be Detected by the Same Model? Forensim: An Attention-Based State-Space Approach](https://arxiv.org/abs/2602.10079)
*Soumyaroop Nandi,Prem Natarajan*

Main category: cs.CV

TL;DR: Forensim是一种基于注意力的图像伪造检测框架，联合定位篡改和源区域，性能优越，并发布了新数据集CMFD-Anything。


<details>
  <summary>Details</summary>
Motivation: 传统方法仅依赖伪影线索检测伪造区域，可能导致误解（如抗议图像中插入的暴力行为），因此需要联合定位源和目标区域以理解上下文。

Method: Forensim采用基于注意力的状态空间框架，结合视觉状态空间模型和区域块注意力模块，实现端到端训练和精确定位。

Result: Forensim在标准基准测试中表现优异，并能输出三类掩码（原始、源、目标），支持拼接和复制-移动伪造的检测。

Conclusion: Forensim通过联合定位篡改区域和源区域，在图像伪造检测中实现了最先进的性能，并提出了新的数据集CMFD-Anything以解决现有数据集的局限性。

Abstract: We introduce Forensim, an attention-based state-space framework for image forgery detection that jointly localizes both manipulated (target) and source regions. Unlike traditional approaches that rely solely on artifact cues to detect spliced or forged areas, Forensim is designed to capture duplication patterns crucial for understanding context. In scenarios such as protest imagery, detecting only the forged region, for example a duplicated act of violence inserted into a peaceful crowd, can mislead interpretation, highlighting the need for joint source-target localization. Forensim outputs three-class masks (pristine, source, target) and supports detection of both splicing and copy-move forgeries within a unified architecture. We propose a visual state-space model that leverages normalized attention maps to identify internal similarities, paired with a region-based block attention module to distinguish manipulated regions. This design enables end-to-end training and precise localization. Forensim achieves state-of-the-art performance on standard benchmarks. We also release CMFD-Anything, a new dataset addressing limitations of existing copy-move forgery datasets.

</details>


### [96] [4RC: 4D Reconstruction via Conditional Querying Anytime and Anywhere](https://arxiv.org/abs/2602.10094)
*Yihang Luo,Shangchen Zhou,Yushi Lan,Xingang Pan,Chen Change Loy*

Main category: cs.CV

TL;DR: 4RC是一个统一的4D重建框架，通过编码-查询范式联合捕捉几何与运动，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有的方法通常将运动与几何解耦，或仅生成有限的4D属性（如稀疏轨迹或双视角场景流），4RC旨在学习一个全面的4D表示，联合捕捉密集场景几何和运动动态。

Method: 4RC采用了一种新颖的“编码一次，随时随地查询”范式，通过Transformer主干将整个视频编码为紧凑的时空潜在空间，并通过条件解码器高效查询任意帧的3D几何和运动。

Result: 4RC在多个4D重建任务中表现优于现有方法。

Conclusion: 4RC在广泛的4D重建任务中优于现有及同期方法，证明了其统一框架的有效性。

Abstract: We present 4RC, a unified feed-forward framework for 4D reconstruction from monocular videos. Unlike existing approaches that typically decouple motion from geometry or produce limited 4D attributes such as sparse trajectories or two-view scene flow, 4RC learns a holistic 4D representation that jointly captures dense scene geometry and motion dynamics. At its core, 4RC introduces a novel encode-once, query-anywhere and anytime paradigm: a transformer backbone encodes the entire video into a compact spatio-temporal latent space, from which a conditional decoder can efficiently query 3D geometry and motion for any query frame at any target timestamp. To facilitate learning, we represent per-view 4D attributes in a minimally factorized form by decomposing them into base geometry and time-dependent relative motion. Extensive experiments demonstrate that 4RC outperforms prior and concurrent methods across a wide range of 4D reconstruction tasks.

</details>


### [97] [VideoWorld 2: Learning Transferable Knowledge from Real-world Videos](https://arxiv.org/abs/2602.10102)
*Zhongwei Ren,Yunchao Wei,Xiao Yu,Guixun Luo,Yao Zhao,Bingyi Kang,Jiashi Feng,Xiaojie Jin*

Main category: cs.CV

TL;DR: VideoWorld 2通过动态增强的潜在动态模型（dLDM）直接从原始视频学习可迁移知识，显著提升任务成功率，并开源代码以促进研究。


<details>
  <summary>Details</summary>
Motivation: 从无标签视频数据中学习可迁移知识并应用于新环境是智能代理的基本能力。VideoWorld 2旨在直接从原始真实世界视频中学习可迁移知识。

Method: VideoWorld 2引入了动态增强的潜在动态模型（dLDM），将动作动态与视觉外观解耦，通过预训练的视频扩散模型处理视觉外观建模，使dLDM能够学习紧凑且与任务相关的动态潜在编码。这些潜在编码通过自回归建模学习任务策略。

Result: 在真实世界手工制作任务中，VideoWorld 2实现了高达70%的任务成功率提升，并生成了连贯的长执行视频。在机器人领域，它从Open-X数据集中获取了有效的操作知识，显著提升了CALVIN上的任务性能。

Conclusion: VideoWorld 2展示了从原始视频中直接学习可迁移世界知识的潜力，显著提升了任务成功率，并支持长时程推理。所有代码、数据和模型将开源以促进进一步研究。

Abstract: Learning transferable knowledge from unlabeled video data and applying it in new environments is a fundamental capability of intelligent agents. This work presents VideoWorld 2, which extends VideoWorld and offers the first investigation into learning transferable knowledge directly from raw real-world videos. At its core, VideoWorld 2 introduces a dynamic-enhanced Latent Dynamics Model (dLDM) that decouples action dynamics from visual appearance: a pretrained video diffusion model handles visual appearance modeling, enabling the dLDM to learn latent codes that focus on compact and meaningful task-related dynamics. These latent codes are then modeled autoregressively to learn task policies and support long-horizon reasoning. We evaluate VideoWorld 2 on challenging real-world handcraft making tasks, where prior video generation and latent-dynamics models struggle to operate reliably. Remarkably, VideoWorld 2 achieves up to 70% improvement in task success rate and produces coherent long execution videos. In robotics, we show that VideoWorld 2 can acquire effective manipulation knowledge from the Open-X dataset, which substantially improves task performance on CALVIN. This study reveals the potential of learning transferable world knowledge directly from raw videos, with all code, data, and models to be open-sourced for further research.

</details>


### [98] [ConsID-Gen: View-Consistent and Identity-Preserving Image-to-Video Generation](https://arxiv.org/abs/2602.10113)
*Mingyang Wu,Ashirbad Mishra,Soumik Dey,Shuo Xing,Naveen Ravipati,Hansi Wu,Binbin Li,Zhengzhong Tu*

Main category: cs.CV

TL;DR: ConsID-Gen通过数据与模型双管齐下，解决了I2V生成中的外观漂移和几何失真问题，显著提升了视频质量。


<details>
  <summary>Details</summary>
Motivation: 解决现有I2V管道中因单视图2D观测稀疏性和弱跨模态对齐导致的外观漂移和几何失真问题。

Method: 提出了ConsID-Gen框架，通过双流视觉几何编码器和文本视觉连接器融合语义与结构线索，并利用未定位辅助视图增强首帧。

Result: 在ConsIDVid-Bench上，ConsID-Gen在多个指标上表现最佳，尤其在身份保真度和时间一致性方面。

Conclusion: ConsID-Gen框架在ConsIDVid-Bench上表现优异，显著提升了身份保真度和时间一致性，超越了现有视频生成模型如Wan2.1和HunyuanVideo。

Abstract: Image-to-Video generation (I2V) animates a static image into a temporally coherent video sequence following textual instructions, yet preserving fine-grained object identity under changing viewpoints remains a persistent challenge. Unlike text-to-video models, existing I2V pipelines often suffer from appearance drift and geometric distortion, artifacts we attribute to the sparsity of single-view 2D observations and weak cross-modal alignment. Here we address this problem from both data and model perspectives. First, we curate ConsIDVid, a large-scale object-centric dataset built with a scalable pipeline for high-quality, temporally aligned videos, and establish ConsIDVid-Bench, where we present a novel benchmarking and evaluation framework for multi-view consistency using metrics sensitive to subtle geometric and appearance deviations. We further propose ConsID-Gen, a view-assisted I2V generation framework that augments the first frame with unposed auxiliary views and fuses semantic and structural cues via a dual-stream visual-geometric encoder as well as a text-visual connector, yielding unified conditioning for a Diffusion Transformer backbone. Experiments across ConsIDVid-Bench demonstrate that ConsID-Gen consistently outperforms in multiple metrics, with the best overall performance surpassing leading video generation models like Wan2.1 and HunyuanVideo, delivering superior identity fidelity and temporal coherence under challenging real-world scenarios. We will release our model and dataset at https://myangwu.github.io/ConsID-Gen.

</details>


### [99] [Quantum Multiple Rotation Averaging](https://arxiv.org/abs/2602.10115)
*Shuteng Wang,Natacha Kuete Meli,Michael Möller,Vladislav Golyanik*

Main category: cs.CV

TL;DR: IQARS利用量子退火技术改进多旋转平均问题，精度提升12%，尽管硬件尚不成熟。


<details>
  <summary>Details</summary>
Motivation: 传统方法（如L1-IRLS和Shonan）在高噪声环境下易陷入局部最优且依赖凸松弛，导致精度下降，需要一种能更好保持旋转流形几何特性的新方法。

Method: IQARS将多旋转平均问题重新表述为一系列局部二次非凸子问题，通过二值化后在量子退火器上执行，利用量子隧穿和并行性高效探索解空间。

Result: 在合成和真实数据集上，IQARS在D-Wave退火器上比最佳经典方法Shonan精度提升约12%。

Conclusion: IQARS算法通过量子退火技术解决了传统多旋转平均方法在高噪声场景下的局限性，显著提升了精度，尽管当前量子退火硬件仍处于早期阶段。

Abstract: Multiple rotation averaging (MRA) is a fundamental optimization problem in 3D vision and robotics that aims to recover globally consistent absolute rotations from noisy relative measurements. Established classical methods, such as L1-IRLS and Shonan, face limitations including local minima susceptibility and reliance on convex relaxations that fail to preserve the exact manifold geometry, leading to reduced accuracy in high-noise scenarios. We introduce IQARS (Iterative Quantum Annealing for Rotation Synchronization), the first algorithm that reformulates MRA as a sequence of local quadratic non-convex sub-problems executable on quantum annealers after binarization, to leverage inherent hardware advantages. IQARS removes convex relaxation dependence and better preserves non-Euclidean rotation manifold geometry while leveraging quantum tunneling and parallelism for efficient solution space exploration. We evaluate IQARS's performance on synthetic and real-world datasets. While current annealers remain in their nascent phase and only support solving problems of limited scale with constrained performance, we observed that IQARS on D-Wave annealers can already achieve ca. 12% higher accuracy than Shonan, i.e., the best-performing classical method evaluated empirically.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [100] [SceneSmith: Agentic Generation of Simulation-Ready Indoor Scenes](https://arxiv.org/abs/2602.09153)
*Nicholas Pfaff,Thomas Cohn,Sergey Zakharov,Rick Cory,Russ Tedrake*

Main category: cs.RO

TL;DR: SceneSmith通过分层代理框架生成高真实性和物理复杂性的室内仿真环境，显著优于现有方法，并支持机器人策略评估。


<details>
  <summary>Details</summary>
Motivation: 现有仿真环境无法捕捉真实室内空间的多样性和物理复杂性，限制了机器人训练和评估的效果。

Method: SceneSmith采用分层代理框架，通过设计师、评论家和协调者三种VLM代理的交互，分阶段从建筑布局到家具布置再到小物件填充生成场景，并整合了文本到3D合成、数据集检索和物理属性估计技术。

Result: SceneSmith生成的对象数量是现有方法的3-6倍，碰撞率低于2%，96%的对象在物理模拟中保持稳定，用户研究中真实性和提示忠实度分别达到92%和91%的胜率。

Conclusion: SceneSmith通过分层代理框架成功生成了高真实性和高物理复杂性的室内环境，显著优于现有方法，并展示了其在机器人策略评估中的实际应用价值。

Abstract: Simulation has become a key tool for training and evaluating home robots at scale, yet existing environments fail to capture the diversity and physical complexity of real indoor spaces. Current scene synthesis methods produce sparsely furnished rooms that lack the dense clutter, articulated furniture, and physical properties essential for robotic manipulation. We introduce SceneSmith, a hierarchical agentic framework that generates simulation-ready indoor environments from natural language prompts. SceneSmith constructs scenes through successive stages$\unicode{x2013}$from architectural layout to furniture placement to small object population$\unicode{x2013}$each implemented as an interaction among VLM agents: designer, critic, and orchestrator. The framework tightly integrates asset generation through text-to-3D synthesis for static objects, dataset retrieval for articulated objects, and physical property estimation. SceneSmith generates 3-6x more objects than prior methods, with <2% inter-object collisions and 96% of objects remaining stable under physics simulation. In a user study with 205 participants, it achieves 92% average realism and 91% average prompt faithfulness win rates against baselines. We further demonstrate that these environments can be used in an end-to-end pipeline for automatic robot policy evaluation.

</details>


### [101] [Feasible Static Workspace Optimization of Tendon Driven Continuum Robot based on Euclidean norm](https://arxiv.org/abs/2602.09046)
*Mohammad Jabari,Carmen Visconte,Giuseppe Quaglia,Med Amine Laribi*

Main category: cs.RO

TL;DR: 该论文通过遗传算法优化肌腱驱动连续机器人的肌腱力设计，以最大化其可行静态工作空间，并在外部载荷下验证了方法的有效性。


<details>
  <summary>Details</summary>
Motivation: 研究旨在优化肌腱驱动连续机器人的设计，以扩展其可行静态工作空间，即使在外部载荷作用下也能保持高效性能。

Method: 使用遗传算法优化肌腱力作为设计变量，以最大化TDCR尖端位置的欧几里得范数为目标，同时考虑外部载荷（如力和扭矩）的影响。

Result: 仿真结果表明，所提出的方法能有效识别最优肌腱力，最大化可行静态工作空间，并在外部力和扭矩影响下仍保持良好性能。

Conclusion: 该论文提出了一种基于可行静态工作空间（FSW）的肌腱驱动连续机器人（TDCR）优化设计方法，并通过遗传算法验证了其有效性。

Abstract: This paper focuses on the optimal design of a tendon-driven continuum robot (TDCR) based on its feasible static workspace (FSW). The TDCR under consideration is a two-segment robot driven by eight tendons, with four tendon actuators per segment. Tendon forces are treated as design variables, while the feasible static workspace (FSW) serves as the optimization objective. To determine the robot's feasible static workspace, a genetic algorithm optimization approach is employed to maximize a Euclidian norm of the TDCR's tip position over the workspace. During the simulations, the robot is subjected to external loads, including torques and forces. The results demonstrate the effectiveness of the proposed method in identifying optimal tendon forces to maximize the feasible static workspace, even under the influence of external forces and torques.

</details>


### [102] [Legs Over Arms: On the Predictive Value of Lower-Body Pose for Human Trajectory Prediction from Egocentric Robot Perception](https://arxiv.org/abs/2602.09076)
*Nhat Le,Daeun Song,Xuesu Xiao*

Main category: cs.RO

TL;DR: 通过分析人类骨骼特征（尤其是下半身3D关键点）可显著提升轨迹预测精度，为社交机器人导航提供实用设计参考。


<details>
  <summary>Details</summary>
Motivation: 预测人类轨迹对于社交机器人在拥挤环境中的导航至关重要，现有方法大多将人类视为质点，本研究旨在通过利用不同骨骼特征提高预测准确性。

Method: 系统评估了2D和3D骨骼关键点及衍生的生物力学线索作为额外输入的预测效用，并在JRDB数据集和新的360度全景视频数据集上进行了全面研究。

Result: 关注下半身3D关键点可使平均位移误差降低13%，而将3D关键点输入与生物力学线索结合可进一步提升1-4%的性能。即使在2D关键点输入下，性能增益依然存在。

Conclusion: 机器人通过观察人类腿部运动可以有效预测行人轨迹，这为社交机器人导航的感知能力设计提供了实用见解。

Abstract: Predicting human trajectory is crucial for social robot navigation in crowded environments. While most existing approaches treat human as point mass, we present a study on multi-agent trajectory prediction that leverages different human skeletal features for improved forecast accuracy. In particular, we systematically evaluate the predictive utility of 2D and 3D skeletal keypoints and derived biomechanical cues as additional inputs. Through a comprehensive study on the JRDB dataset and another new dataset for social navigation with 360-degree panoramic videos, we find that focusing on lower-body 3D keypoints yields a 13% reduction in Average Displacement Error and augmenting 3D keypoint inputs with corresponding biomechanical cues provides a further 1-4% improvement. Notably, the performance gain persists when using 2D keypoint inputs extracted from equirectangular panoramic images, indicating that monocular surround vision can capture informative cues for motion forecasting. Our finding that robots can forecast human movement efficiently by watching their legs provides actionable insights for designing sensing capabilities for social robot navigation.

</details>


### [103] [Agile asymmetric multi-legged locomotion: contact planning via geometric mechanics and spin model duality](https://arxiv.org/abs/2602.09123)
*Jackson Habala,Gabriel B. Margolis,Tianyu Wang,Pratyush Bhatt,Juntao He,Naheel Naeem,Zhaochen Xu,Pulkit Agrawal,Daniel I. Goldman,Di Luo,Baxi Chong*

Main category: cs.RO

TL;DR: 研究开发了一种多足机器人控制框架，通过对称性破缺优化步态，使六足机器人速度提升50%。


<details>
  <summary>Details</summary>
Motivation: 当前多足机器人研究集中于双足或四足机器人，缺乏对更多足机器人运动性能提升的系统性控制框架。

Method: 利用几何力学将接触丰富的运动规划简化为图优化问题，并采用统计力学中的自旋模型对偶框架来利用对称性破缺。

Result: 提出的框架使六足机器人实现了0.61体长/周期的前向速度（比传统步态提升50%），并在控制和硬件层面展现了不对称性。

Conclusion: 该研究提出了一种基于几何力学和统计力学的多足机器人控制框架，通过对称性破缺和最优步态重组，显著提升了六足机器人的运动性能。

Abstract: Legged robot research is presently focused on bipedal or quadrupedal robots, despite capabilities to build robots with many more legs to potentially improve locomotion performance. This imbalance is not necessarily due to hardware limitations, but rather to the absence of principled control frameworks that explain when and how additional legs improve locomotion performance. In multi-legged systems, coordinating many simultaneous contacts introduces a severe curse of dimensionality that challenges existing modeling and control approaches. As an alternative, multi-legged robots are typically controlled using low-dimensional gaits originally developed for bipeds or quadrupeds. These strategies fail to exploit the new symmetries and control opportunities that emerge in higher-dimensional systems. In this work, we develop a principled framework for discovering new control structures in multi-legged locomotion. We use geometric mechanics to reduce contact-rich locomotion planning to a graph optimization problem, and propose a spin model duality framework from statistical mechanics to exploit symmetry breaking and guide optimal gait reorganization. Using this approach, we identify an asymmetric locomotion strategy for a hexapod robot that achieves a forward speed of 0.61 body lengths per cycle (a 50% improvement over conventional gaits). The resulting asymmetry appears at both the control and hardware levels. At the control level, the body orientation oscillates asymmetrically between fast clockwise and slow counterclockwise turning phases for forward locomotion. At the hardware level, two legs on the same side remain unactuated and can be replaced with rigid parts without degrading performance. Numerical simulations and robophysical experiments validate the framework and reveal novel locomotion behaviors that emerge from symmetry reforming in high-dimensional embodied systems.

</details>


### [104] [Elements of Robot Morphology: Supporting Designers in Robot Form Exploration](https://arxiv.org/abs/2602.09203)
*Amy Koike,Ge,Guo,Xinning He,Callie Y. Kim,Dakota Sullivan,Bilge Mutlu*

Main category: cs.RO

TL;DR: 论文提出机器人形态设计框架及实践工具包，通过案例验证其有效性。


<details>
  <summary>Details</summary>
Motivation: 机器人形态设计在HRI中至关重要，但缺乏系统性探索框架，因此研究旨在填补这一空白。

Method: 通过分析现有机器人，提出包含感知、关节、末端执行器、移动和结构五个基本元素的框架，并开发了MEB工具包进行实践验证。

Result: 框架和工具包在案例研究和工作坊中表现出色，支持多样化的机器人形态探索与协作设计。

Conclusion: 论文提出了‘机器人形态学元素’框架及‘形态探索块’（MEB）工具包，通过案例研究和设计工作坊验证了其在机器人形态分析、构思、反思及协作设计中的有效性。

Abstract: Robot morphology, the form, shape, and structure of robots, is a key design space in human-robot interaction (HRI), shaping how robots function, express themselves, and interact with people. Yet, despite its importance, little is known about how design frameworks can guide systematic form exploration. To address this gap, we introduce Elements of Robot Morphology, a framework that identifies five fundamental elements: perception, articulation, end effectors, locomotion, and structure. Derived from an analysis of existing robots, the framework supports structured exploration of diverse robot forms. To operationalize the framework, we developed Morphology Exploration Blocks (MEB), a set of tangible blocks that enable hands-on, collaborative experimentation with robot morphologies. We evaluate the framework and toolkit through a case study and design workshops, showing how they support analysis, ideation, reflection, and collaborative robot design.

</details>


### [105] [Risk-Aware Obstacle Avoidance Algorithm for Real-Time Applications](https://arxiv.org/abs/2602.09204)
*Ozan Kaya,Emir Cem Gezer,Roger Skjetne,Ingrid Bouwer Utne*

Main category: cs.RO

TL;DR: 该研究提出了一种混合风险感知导航架构，结合概率建模和轨迹优化，显著提升了自主水面舰艇在动态环境中的安全性和适应性。


<details>
  <summary>Details</summary>
Motivation: 为应对海洋环境中的不确定性，开发能够感知、推理并在不确定性下行动的自主导航系统。

Method: 结合概率障碍物建模与平滑轨迹优化，使用风险偏置RRT*规划器生成无碰撞路径，并通过B样条算法优化轨迹连续性。

Result: 实验结果表明，该系统能够安全导航、保持平滑轨迹，并动态适应环境风险变化，相比传统方法在安全性和自主性上有所提升。

Conclusion: 该研究提出的混合风险感知导航架构在不确定和动态环境中展现出更高的操作安全性和自主性，是一种有前景的解决方案。

Abstract: Robust navigation in changing marine environments requires autonomous systems capable of perceiving, reasoning, and acting under uncertainty. This study introduces a hybrid risk-aware navigation architecture that integrates probabilistic modeling of obstacles along the vehicle path with smooth trajectory optimization for autonomous surface vessels. The system constructs probabilistic risk maps that capture both obstacle proximity and the behavior of dynamic objects. A risk-biased Rapidly Exploring Random Tree (RRT) planner leverages these maps to generate collision-free paths, which are subsequently refined using B-spline algorithms to ensure trajectory continuity. Three distinct RRT* rewiring modes are implemented based on the cost function: minimizing the path length, minimizing risk, and optimizing a combination of the path length and total risk. The framework is evaluated in experimental scenarios containing both static and dynamic obstacles. The results demonstrate the system's ability to navigate safely, maintain smooth trajectories, and dynamically adapt to changing environmental risks. Compared with conventional LIDAR or vision-only navigation approaches, the proposed method shows improvements in operational safety and autonomy, establishing it as a promising solution for risk-aware autonomous vehicle missions in uncertain and dynamic environments.

</details>


### [106] [From Legible to Inscrutable Trajectories: (Il)legible Motion Planning Accounting for Multiple Observers](https://arxiv.org/abs/2602.09227)
*Ananya Yammanuru,Maria Lusardi,Nancy M. Amato,Katherine Driggs-Campbell*

Main category: cs.RO

TL;DR: 本文提出MMLO-LMP问题，旨在生成对友好观察者清晰、对敌对观察者模糊的轨迹，并介绍了解决方案DUBIOUS。


<details>
  <summary>Details</summary>
Motivation: 在合作环境中，机器人需要清晰传达意图；在对抗环境中，则需要隐藏意图。本文探讨了在多观察者且观察者动机不同的环境中，如何生成既对友好观察者清晰又对敌对观察者模糊的轨迹。

Method: 提出了DUBIOUS，一种轨迹优化器，用于解决MMLO-LMP问题。

Result: DUBIOUS能够生成在观察者动机和有限可见区域之间平衡的轨迹。

Conclusion: 未来工作包括MMLO-LMP的多种变体，如移动观察者和观察者团队合作。

Abstract: In cooperative environments, such as in factories or assistive scenarios, it is important for a robot to communicate its intentions to observers, who could be either other humans or robots. A legible trajectory allows an observer to quickly and accurately predict an agent's intention. In adversarial environments, such as in military operations or games, it is important for a robot to not communicate its intentions to observers. An illegible trajectory leads an observer to incorrectly predict the agent's intention or delays when an observer is able to make a correct prediction about the agent's intention. However, in some environments there are multiple observers, each of whom may be able to see only part of the environment, and each of whom may have different motives. In this work, we introduce the Mixed-Motive Limited-Observability Legible Motion Planning (MMLO-LMP) problem, which requires a motion planner to generate a trajectory that is legible to observers with positive motives and illegible to observers with negative motives while also considering the visibility limitations of each observer. We highlight multiple strategies an agent can take while still achieving the problem objective. We also present DUBIOUS, a trajectory optimizer that solves MMLO-LMP. Our results show that DUBIOUS can generate trajectories that balance legibility with the motives and limited visibility regions of the observers. Future work includes many variations of MMLO-LMP, including moving observers and observer teaming.

</details>


### [107] [STaR: Scalable Task-Conditioned Retrieval for Long-Horizon Multimodal Robot Memory](https://arxiv.org/abs/2602.09255)
*Mingfeng Yuan,Hao Zhang,Mahan Mohammadi,Runhao Li,Jinjun Shan,Steven L. Waslander*

Main category: cs.RO

TL;DR: STaR是一个用于移动机器人的长期记忆和推理框架，通过多模态记忆和高效检索算法，显著提升了导航任务的性能和实用性。


<details>
  <summary>Details</summary>
Motivation: 解决移动机器人在多样开放动态场景中长期部署时的核心挑战，即构建可扩展的长期记忆以支持规划、检索和推理。

Method: STaR框架通过构建任务无关的多模态长期记忆，并结合基于信息瓶颈原则的可扩展任务条件检索算法，实现了对开放指令的精确响应和导航规划。

Result: 在NaVQA和WH-VQA数据集上，STaR表现优于基线方法，成功率和空间误差均有显著改善，并在真实机器人部署中验证了其鲁棒性。

Conclusion: STaR框架在室内外环境中均表现出色，成功降低了空间误差并提高了任务成功率，展示了其在长期记忆和上下文推理中的实用性和可扩展性。

Abstract: Mobile robots are often deployed over long durations in diverse open, dynamic scenes, including indoor setting such as warehouses and manufacturing facilities, and outdoor settings such as agricultural and roadway operations. A core challenge is to build a scalable long-horizon memory that supports an agentic workflow for planning, retrieval, and reasoning over open-ended instructions at variable granularity, while producing precise, actionable answers for navigation. We present STaR, an agentic reasoning framework that (i) constructs a task-agnostic, multimodal long-term memory that generalizes to unseen queries while preserving fine-grained environmental semantics (object attributes, spatial relations, and dynamic events), and (ii) introduces a Scalable TaskConditioned Retrieval algorithm based on the Information Bottleneck principle to extract from long-term memory a compact, non-redundant, information-rich set of candidate memories for contextual reasoning. We evaluate STaR on NaVQA (mixed indoor/outdoor campus scenes) and WH-VQA, a customized warehouse benchmark with many visually similar objects built with Isaac Sim, emphasizing contextual reasoning. Across the two datasets, STaR consistently outperforms strong baselines, achieving higher success rates and markedly lower spatial error. We further deploy STaR on a real Husky wheeled robot in both indoor and outdoor environments, demonstrating robust longhorizon reasoning, scalability, and practical utility.

</details>


### [108] [Data-centric Design of Learning-based Surgical Gaze Perception Models in Multi-Task Simulation](https://arxiv.org/abs/2602.09259)
*Yizhou Li,Shuyuan Yang,Jiaji Su,Zonghe Chua*

Main category: cs.RO

TL;DR: The study explores how different expertise levels and perceptual modalities affect gaze supervision in surgical training, using a novel dataset and models to show that passive gaze can partially substitute for active gaze, with novice labels offering a scalable solution.


<details>
  <summary>Details</summary>
Motivation: In robot-assisted minimally invasive surgery (RMIS), reduced haptic feedback and depth cues increase reliance on expert visual perception, motivating gaze-guided training and learning-based surgical perception models. However, operative expert gaze is costly to collect, and it remains unclear how the source of gaze supervision, both expertise level (intermediate vs. novice) and perceptual modality (active execution vs. passive viewing), shapes what attention models learn.

Method: The research introduced a paired active-passive, multi-task surgical gaze dataset collected on the da Vinci SimNow simulator across four drills. Active gaze was recorded during task execution using a VR headset with eye tracking, and corresponding videos were reused to collect passive gaze from observers. The study quantified skill- and modality-dependent differences in gaze organization and evaluated the substitutability of passive gaze for operative supervision using fixation density overlap analyses and single-frame saliency modeling.

Result: Models trained on passive gaze recovered a substantial portion of intermediate active attention, but with predictable degradation, and transfer was asymmetric between active and passive targets. MSI-Net produced stable, interpretable predictions, whereas SalGAN was unstable and often poorly aligned with human fixations.

Conclusion: The study suggests that novice passive gaze labels can approximate intermediate-passive targets with limited loss on higher-quality demonstrations, offering a practical approach for scalable, crowd-sourced gaze supervision in surgical coaching and perception modeling.

Abstract: In robot-assisted minimally invasive surgery (RMIS), reduced haptic feedback and depth cues increase reliance on expert visual perception, motivating gaze-guided training and learning-based surgical perception models. However, operative expert gaze is costly to collect, and it remains unclear how the source of gaze supervision, both expertise level (intermediate vs. novice) and perceptual modality (active execution vs. passive viewing), shapes what attention models learn. We introduce a paired active-passive, multi-task surgical gaze dataset collected on the da Vinci SimNow simulator across four drills. Active gaze was recorded during task execution using a VR headset with eye tracking, and the corresponding videos were reused as stimuli to collect passive gaze from observers, enabling controlled same-video comparisons. We quantify skill- and modality-dependent differences in gaze organization and evaluate the substitutability of passive gaze for operative supervision using fixation density overlap analyses and single-frame saliency modeling. Across settings, MSI-Net produced stable, interpretable predictions, whereas SalGAN was unstable and often poorly aligned with human fixations. Models trained on passive gaze recovered a substantial portion of intermediate active attention, but with predictable degradation, and transfer was asymmetric between active and passive targets. Notably, novice passive labels approximated intermediate-passive targets with limited loss on higher-quality demonstrations, suggesting a practical path for scalable, crowd-sourced gaze supervision in surgical coaching and perception modeling.

</details>


### [109] [Disambiguating Anthropomorphism and Anthropomimesis in Human-Robot Interaction](https://arxiv.org/abs/2602.09287)
*Minja Axelsson,Henry Shevlin*

Main category: cs.RO

TL;DR: 本文初步区分了HRI中的拟人化（用户感知）和拟人模仿（开发者设计），明确了责任主体，为未来研究提供了理论基础。


<details>
  <summary>Details</summary>
Motivation: 为了澄清人机交互领域中拟人化和拟人模仿的理论混淆，明确责任方（用户对拟人化负责，开发者对拟人模仿负责），为未来的机器人设计和评估提供理论基础。

Method: 通过定义和对比拟人化（用户感知机器人的人类特质）和拟人模仿（开发者设计机器人的人类特质），对这两个概念进行了初步澄清和探索。

Result: 提出了拟人化和拟人模仿的明确定义，并区分了二者的责任主体，为未来研究提供了理论工具。

Conclusion: 本文初步区分了人机交互（HRI）和社会机器人学中的拟人化（anthropomorphism）和拟人模仿（anthropomimesis）理论概念，为未来研究提供了清晰的理论基础。

Abstract: In this preliminary work, we offer an initial disambiguation of the theoretical concepts anthropomorphism and anthropomimesis in Human-Robot Interaction (HRI) and social robotics. We define anthropomorphism as users perceiving human-like qualities in robots, and anthropomimesis as robot developers designing human-like features into robots. This contribution aims to provide a clarification and exploration of these concepts for future HRI scholarship, particularly regarding the party responsible for human-like qualities - robot perceiver for anthropomorphism, and robot designer for anthropomimesis. We provide this contribution so that researchers can build on these disambiguated theoretical concepts for future robot design and evaluation.

</details>


### [110] [CAPER: Constrained and Procedural Reasoning for Robotic Scientific Experiments](https://arxiv.org/abs/2602.09367)
*Jinghan Yang,Jingyi Hou,Xinbo Yu,Wei He,Yifan Wu*

Main category: cs.RO

TL;DR: CAPER框架通过责任分离和中间表示，提升机器人科学实验的可控性和鲁棒性，尤其在低数据和长时程任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 科学实验室中的机器人辅助需要程序正确的长时程操作、有限监督下的可靠执行以及低演示条件下的鲁棒性，这些条件对端到端视觉-语言-动作（VLA）模型提出了巨大挑战。

Method: CAPER采用责任分离的结构：任务级推理在明确约束下生成程序有效的动作序列，中层多模态基础实现子任务而不将空间决策委托给大型语言模型，低层控制通过最少演示的强化学习适应物理不确定性。

Result: 在科学工作流基准和公共长时程操作数据集上的实验表明，CAPER在成功率、程序正确性方面均有显著提升，尤其是在低数据和长时程设置下。

Conclusion: CAPER框架通过明确限制规划和控制流程中的学习和推理环节，显著提高了机器人科学实验的可控性、鲁棒性和数据效率。

Abstract: Robotic assistance in scientific laboratories requires procedurally correct long-horizon manipulation, reliable execution under limited supervision, and robustness in low-demonstration regimes. Such conditions greatly challenge end-to-end vision-language-action (VLA) models, whose assumptions of recoverable errors and data-driven policy learning often break down in protocol-sensitive experiments. We propose CAPER, a framework for Constrained And ProcEdural Reasoning for robotic scientific experiments, which explicitly restricts where learning and reasoning occur in the planning and control pipeline. Rather than strengthening end-to-end policies, CAPER enforces a responsibility-separated structure: task-level reasoning generates procedurally valid action sequences under explicit constraints, mid-level multimodal grounding realizes subtasks without delegating spatial decision-making to large language models, and low-level control adapts to physical uncertainty via reinforcement learning with minimal demonstrations. By encoding procedural commitments through interpretable intermediate representations, CAPER prevents execution-time violations of experimental logic, improving controllability, robustness, and data efficiency. Experiments on a scientific workflow benchmark and a public long-horizon manipulation dataset demonstrate consistent improvements in success rate and procedural correctness, particularly in low-data and long-horizon settings.

</details>


### [111] [Certified Gradient-Based Contact-Rich Manipulation via Smoothing-Error Reachable Tubes](https://arxiv.org/abs/2602.09368)
*Wei-Chen Li,Glen Chou*

Main category: cs.RO

TL;DR: 通过平滑动力学并量化补偿误差，该方法在真实混合动力学上实现了约束满足和目标可达性的保证，是首个可验证的基于梯度的接触丰富操作策略合成方法。


<details>
  <summary>Details</summary>
Motivation: 基于梯度的控制器优化方法在物理先验和可微分模拟器的支持下能高效工作，但混合接触动力学带来的不连续或消失梯度使接触丰富的操作任务仍具挑战性。

Method: 提出了一种基于凸优化的新型可微分模拟器，平滑接触动力学和几何形状，并通过系统可达集的分析边界来优化时变仿射反馈策略。

Result: 在平面推动、物体旋转和手内灵巧操作等任务中，该方法实现了比基线更低的安违规和目标误差，同时保证了约束满足。

Conclusion: 该方法首次将可微分物理与集值鲁棒控制结合，为接触丰富的操作任务提供了首个可验证的基于梯度的策略合成方法，实现了在真实混合动力学上的约束满足和目标可达性保证。

Abstract: Gradient-based methods can efficiently optimize controllers using physical priors and differentiable simulators, but contact-rich manipulation remains challenging due to discontinuous or vanishing gradients from hybrid contact dynamics. Smoothing the dynamics yields continuous gradients, but the resulting model mismatch can cause controller failures when executed on real systems. We address this trade-off by planning with smoothed dynamics while explicitly quantifying and compensating for the induced errors, providing formal guarantees of constraint satisfaction and goal reachability on the true hybrid dynamics. Our method smooths both contact dynamics and geometry via a novel differentiable simulator based on convex optimization, which enables us to characterize the discrepancy from the true dynamics as a set-valued deviation. This deviation constrains the optimization of time-varying affine feedback policies through analytical bounds on the system's reachable set, enabling robust constraint satisfaction guarantees for the true closed-loop hybrid dynamics, while relying solely on informative gradients from the smoothed dynamics. We evaluate our method on several contact-rich tasks, including planar pushing, object rotation, and in-hand dexterous manipulation, achieving guaranteed constraint satisfaction with lower safety violation and goal error than baselines. By bridging differentiable physics with set-valued robust control, our method is the first certifiable gradient-based policy synthesis method for contact-rich manipulation.

</details>


### [112] [Phase-Aware Policy Learning for Skateboard Riding of Quadruped Robots via Feature-wise Linear Modulation](https://arxiv.org/abs/2602.09370)
*Minsung Yoon,Jeil Jeong,Sung-Eui Yoon*

Main category: cs.RO

TL;DR: PAPL是一个针对四足机器人滑板控制的强化学习框架，通过相位感知调制层解决多模态挑战，仿真和现实验证有效。


<details>
  <summary>Details</summary>
Motivation: 解决滑板作为个人移动设备时，四足机器人因感知驱动交互和多模态控制目标带来的策略学习挑战。

Method: 采用强化学习框架PAPL，集成相位条件特征线性调制层到执行器和评论家网络中，实现跨相位共享机器人特定知识的统一策略。

Result: 仿真验证了指令跟踪准确性，通过消融研究量化各组件贡献，并与腿式和轮腿式基线比较运动效率，展示了现实世界可迁移性。

Conclusion: PAPL框架通过整合相位感知的调制层，成功解决了四足机器人在滑板控制中的多模态挑战，并在仿真和现实中验证了其有效性和可迁移性。

Abstract: Skateboards offer a compact and efficient means of transportation as a type of personal mobility device. However, controlling them with legged robots poses several challenges for policy learning due to perception-driven interactions and multi-modal control objectives across distinct skateboarding phases. To address these challenges, we introduce Phase-Aware Policy Learning (PAPL), a reinforcement-learning framework tailored for skateboarding with quadruped robots. PAPL leverages the cyclic nature of skateboarding by integrating phase-conditioned Feature-wise Linear Modulation layers into actor and critic networks, enabling a unified policy that captures phase-dependent behaviors while sharing robot-specific knowledge across phases. Our evaluations in simulation validate command-tracking accuracy and conduct ablation studies quantifying each component's contribution. We also compare locomotion efficiency against leg and wheel-leg baselines and show real-world transferability.

</details>


### [113] [Sci-VLA: Agentic VLA Inference Plugin for Long-Horizon Tasks in Scientific Experiments](https://arxiv.org/abs/2602.09430)
*Yiwen Pang,Bo Zhou,Changjin Li,Xuanhao Wang,Shengxiang Xu,Deng-Bao Wang,Min-Ling Zhang,Shimin Di*

Main category: cs.RO

TL;DR: 提出一种无需额外训练的LLM代理插件，解决VLA模型在科学实验复合任务中的过渡操作问题，显著提升成功率并实现仿真到现实的迁移。


<details>
  <summary>Details</summary>
Motivation: 科学实验通常由多个原子任务组成的长时程任务，现有VLA模型在训练时仅针对原子任务，无法有效处理复合任务中的过渡操作。

Method: 引入基于LLM的代理推理机制，显式推断过渡步骤并生成过渡性机器人动作代码，指导VLA模型完成复合任务。

Result: 在仿真环境中，该方法将每个原子任务的平均成功率提高了42%，并能轻松迁移到真实实验室。

Conclusion: 提出的Agentic VLA Inference Plugin通过LLM代理机制有效解决了VLA模型在复合任务中的过渡操作问题，无需额外训练即可提升执行效果，并成功从仿真迁移到现实实验室。

Abstract: Robotic laboratories play a critical role in autonomous scientific discovery by enabling scalable, continuous experimental execution. Recent vision-language-action (VLA) models offer a promising foundation for robotic laboratories. However, scientific experiments typically involve long-horizon tasks composed of multiple atomic tasks, posing a fundamental challenge to existing VLA models. While VLA models fine-tuned for scientific tasks can reliably execute atomic experimental actions seen during training, they often fail to perform composite tasks formed by reordering and composing these known atomic actions. This limitation arises from a distributional mismatch between training-time atomic tasks and inference-time composite tasks, which prevents VLA models from executing necessary transitional operations between atomic tasks. To address this challenge, we propose an Agentic VLA Inference Plugin for Long-Horizon Tasks in Scientific Experiments. It introduces an LLM-based agentic inference mechanism that intervenes when executing sequential manipulation tasks. By performing explicit transition inference and generating transitional robotic action code, the proposed plugin guides VLA models through missing transitional steps, enabling reliable execution of composite scientific workflows without any additional training. This inference-only intervention makes our method computationally efficient, data-efficient, and well-suited for open-ended and long-horizon robotic laboratory tasks. We build 3D assets of scientific instruments and common scientific operating scenes within an existing simulation environment. In these scenes, we have verified that our method increases the average success rate per atomic task by 42\% during inference. Furthermore, we show that our method can be easily transferred from the simulation to real scientific laboratories.

</details>


### [114] [LLM-Grounded Dynamic Task Planning with Hierarchical Temporal Logic for Human-Aware Multi-Robot Collaboration](https://arxiv.org/abs/2602.09472)
*Shuyuan Hu,Tao Lin,Kai Ye,Yang Yang,Tianwei Zhang*

Main category: cs.RO

TL;DR: 论文提出了一种结合LLM和LTL的神经符号框架，通过动态调整计划解决STAP问题，实验证明其在动态环境中优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM生成的计划在长时程场景中缺乏运动学可行性和效率，而传统的LTL方法在动态环境中计算可扩展性有限。因此，需要一种能够结合两者优势的新方法。

Method: 论文采用了一种神经符号框架，将LLM推理与分层LTL规范相结合，通过后退水平规划（RHP）循环和实时感知动态调整计划。

Result: 实验结果表明，该方法在成功率和交互流畅性上显著优于基线方法，并有效减少了规划延迟。

Conclusion: 该论文提出的神经符号框架成功地将LLM推理与分层LTL规范相结合，解决了STAP问题，并在动态环境中表现出色，显著提高了成功率和交互流畅性，同时最小化了规划延迟。

Abstract: While Large Language Models (LLM) enable non-experts to specify open-world multi-robot tasks, the generated plans often lack kinematic feasibility and are not efficient, especially in long-horizon scenarios. Formal methods like Linear Temporal Logic (LTL) offer correctness and optimal guarantees, but are typically confined to static, offline settings and struggle with computational scalability. To bridge this gap, we propose a neuro-symbolic framework that grounds LLM reasoning into hierarchical LTL specifications and solves the corresponding Simultaneous Task Allocation and Planning (STAP) problem. Unlike static approaches, our system resolves stochastic environmental changes, such as moving users or updated instructions via a receding horizon planning (RHP) loop with real-time perception, which dynamically refines plans through a hierarchical state space. Extensive real-world experiments demonstrate that our approach significantly outperforms baseline methods in success rate and interaction fluency while minimizing planning latency.

</details>


### [115] [Optimal Control of Microswimmers for Trajectory Tracking Using Bayesian Optimization](https://arxiv.org/abs/2602.09563)
*Lucas Palazzolo,Mickaël Binois,Laëtitia Giraldi*

Main category: cs.RO

TL;DR: 研究提出了一种结合B样条参数化和贝叶斯优化的方法，用于微游泳体的轨迹跟踪控制，展示了其在复杂流体环境中的适用性和鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 微游泳体的轨迹跟踪是微机器人领域的关键挑战，低雷诺数动力学使控制设计尤为复杂。

Method: 研究将轨迹跟踪问题表述为最优控制问题，并采用B样条参数化与贝叶斯优化相结合的方法，避免了复杂的梯度计算。

Result: 该方法成功应用于鞭毛磁性游泳体和三球游泳体模型，能够适应并部分补偿壁诱导的流体动力学效应，且适用于不同精度的模型。

Conclusion: 该研究展示了贝叶斯优化作为一种多功能工具在微尺度运动控制中的潜力，特别是在处理复杂流体-结构相互作用时的鲁棒性和通用性。

Abstract: Trajectory tracking for microswimmers remains a key challenge in microrobotics, where low-Reynolds-number dynamics make control design particularly complex. In this work, we formulate the trajectory tracking problem as an optimal control problem and solve it using a combination of B-spline parametrization with Bayesian optimization, allowing the treatment of high computational costs without requiring complex gradient computations. Applied to a flagellated magnetic swimmer, the proposed method reproduces a variety of target trajectories, including biologically inspired paths observed in experimental studies. We further evaluate the approach on a three-sphere swimmer model, demonstrating that it can adapt to and partially compensate for wall-induced hydrodynamic effects. The proposed optimization strategy can be applied consistently across models of different fidelity, from low-dimensional ODE-based models to high-fidelity PDE-based simulations, showing its robustness and generality. These results highlight the potential of Bayesian optimization as a versatile tool for optimal control strategies in microscale locomotion under complex fluid-structure interactions.

</details>


### [116] [Sample-Efficient Real-World Dexterous Policy Fine-Tuning via Action-Chunked Critics and Normalizing Flows](https://arxiv.org/abs/2602.09580)
*Chenyu Yang,Denis Tarasov,Davide Liconti,Hehui Zheng,Robert K. Katzschmann*

Main category: cs.RO

TL;DR: SOFT-FLOW是一种基于归一化流和动作块级评论家的样本高效微调框架，解决了灵巧操作中的多模态动作和长时程信用分配问题，在真实机器人硬件上表现出色。


<details>
  <summary>Details</summary>
Motivation: 现实世界中灵巧操作策略的微调面临多模态动作分布和有限交互预算的挑战，传统高斯策略和扩散策略无法有效应对。

Method: SOFT-FLOW框架结合了归一化流（NF）策略和动作块级评论家，通过精确的多模态动作块似然和保守的策略更新，提高了样本效率。

Result: SOFT-FLOW在两项灵巧操作任务中实现了稳定且高效的适应，优于标准方法。

Conclusion: SOFT-FLOW在现实世界的灵巧操作任务中表现出色，特别是在需要长时程精确控制的任务中，如剪刀剪胶带和手掌向下抓握的立方体旋转。

Abstract: Real-world fine-tuning of dexterous manipulation policies remains challenging due to limited real-world interaction budgets and highly multimodal action distributions. Diffusion-based policies, while expressive, do not permit conservative likelihood-based updates during fine-tuning because action probabilities are intractable. In contrast, conventional Gaussian policies collapse under multimodality, particularly when actions are executed in chunks, and standard per-step critics fail to align with chunked execution, leading to poor credit assignment. We present SOFT-FLOW, a sample-efficient off-policy fine-tuning framework with normalizing flow (NF) to address these challenges. The normalizing flow policy yields exact likelihoods for multimodal action chunks, allowing conservative, stable policy updates through likelihood regularization and thereby improving sample efficiency. An action-chunked critic evaluates entire action sequences, aligning value estimation with the policy's temporal structure and improving long-horizon credit assignment. To our knowledge, this is the first demonstration of a likelihood-based, multimodal generative policy combined with chunk-level value learning on real robotic hardware. We evaluate SOFT-FLOW on two challenging dexterous manipulation tasks in the real world: cutting tape with scissors retrieved from a case, and in-hand cube rotation with a palm-down grasp -- both of which require precise, dexterous control over long horizons. On these tasks, SOFT-FLOW achieves stable, sample-efficient adaptation where standard methods struggle.

</details>


### [117] [Preference Aligned Visuomotor Diffusion Policies for Deformable Object Manipulation](https://arxiv.org/abs/2602.09583)
*Marco Moletta,Michael C. Welle,Danica Kragic*

Main category: cs.RO

TL;DR: RKO结合RPO和KTO优势，通过有限演示调整预训练策略，在布料折叠任务中实现高效个性化机器人行为。


<details>
  <summary>Details</summary>
Motivation: 人类对操作任务的偏好微妙且个性化，但机器人领域对此研究不足，尤其是在可变形物体（如衣物和织物）操作中。

Method: RKO是一种结合RPO和KTO框架优势的新型偏好对齐方法，通过有限演示调整预训练的视觉运动扩散策略。

Result: RKO在多种衣物和偏好设置的真实布料折叠任务中，表现优于常见的偏好学习框架和基线扩散策略。

Conclusion: RKO方法在复杂可变形物体操作任务中展现了优越的性能和样本效率，证明了结构化偏好学习对扩展个性化机器人行为的重要性和可行性。

Abstract: Humans naturally develop preferences for how manipulation tasks should be performed, which are often subtle, personal, and difficult to articulate. Although it is important for robots to account for these preferences to increase personalization and user satisfaction, they remain largely underexplored in robotic manipulation, particularly in the context of deformable objects like garments and fabrics. In this work, we study how to adapt pretrained visuomotor diffusion policies to reflect preferred behaviors using limited demonstrations. We introduce RKO, a novel preference-alignment method that combines the benefits of two recent frameworks: RPO and KTO. We evaluate RKO against common preference learning frameworks, including these two, as well as a baseline vanilla diffusion policy, on real-world cloth-folding tasks spanning multiple garments and preference settings. We show that preference-aligned policies (particularly RKO) achieve superior performance and sample efficiency compared to standard diffusion policy fine-tuning. These results highlight the importance and feasibility of structured preference learning for scaling personalized robot behavior in complex deformable object manipulation tasks.

</details>


### [118] [AnyTouch 2: General Optical Tactile Representation Learning For Dynamic Tactile Perception](https://arxiv.org/abs/2602.09617)
*Ruoxuan Feng,Yuxuan Zhou,Siyu Mei,Dongzhan Zhou,Pengwei Wang,Shaowei Cui,Bin Fang,Guocai Yao,Di Hu*

Main category: cs.RO

TL;DR: ToucHD数据集和AnyTouch 2框架填补了触觉数据中动态信息的空白，通过分层感知能力和统一的表示学习框架，提升了机器人对触觉动态的感知和理解。


<details>
  <summary>Details</summary>
Motivation: 现实世界中丰富的接触操作需要机器人感知时间触觉反馈、捕捉细微的表面变形，并推理对象属性和力动力学。尽管光学触觉传感器能提供丰富信息，但现有触觉数据集和模型仍有限，主要关注对象级属性（如材料），而忽略了物理交互中的细粒度触觉时间动态。

Method: 提出了AnyTouch 2框架，这是一个通用的触觉表示学习框架，能够统一对象级理解和细粒度、力感知的动态感知。该框架从模型角度捕捉像素级和动作特定的帧间变形，并显式建模物理力动力学。

Result: 实验结果表明，AnyTouch 2在涵盖静态对象属性和动态物理属性的基准测试中表现一致且强大，能够支持从基本对象级理解到力感知灵巧操作的多层次动态感知能力。

Conclusion: 实验结果表明，AnyTouch 2框架在多种传感器和任务中表现一致且强大，能够有效统一对象级理解和细粒度、力感知的动态感知。

Abstract: Real-world contact-rich manipulation demands robots to perceive temporal tactile feedback, capture subtle surface deformations, and reason about object properties as well as force dynamics. Although optical tactile sensors are uniquely capable of providing such rich information, existing tactile datasets and models remain limited. These resources primarily focus on object-level attributes (e.g., material) while largely overlooking fine-grained tactile temporal dynamics during physical interactions. We consider that advancing dynamic tactile perception requires a systematic hierarchy of dynamic perception capabilities to guide both data collection and model design. To address the lack of tactile data with rich dynamic information, we present ToucHD, a large-scale hierarchical tactile dataset spanning tactile atomic actions, real-world manipulations, and touch-force paired data. Beyond scale, ToucHD establishes a comprehensive tactile dynamic data ecosystem that explicitly supports hierarchical perception capabilities from the data perspective. Building on it, we propose AnyTouch 2, a general tactile representation learning framework for diverse optical tactile sensors that unifies object-level understanding with fine-grained, force-aware dynamic perception. The framework captures both pixel-level and action-specific deformations across frames, while explicitly modeling physical force dynamics, thereby learning multi-level dynamic perception capabilities from the model perspective. We evaluate our model on benchmarks that covers static object properties and dynamic physical attributes, as well as real-world manipulation tasks spanning multiple tiers of dynamic perception capabilities-from basic object-level understanding to force-aware dexterous manipulation. Experimental results demonstrate consistent and strong performance across sensors and tasks.

</details>


### [119] [TeleGate: Whole-Body Humanoid Teleoperation via Gated Expert Selection with Motion Prior](https://arxiv.org/abs/2602.09628)
*Jie Li,Bing Tang,Feng Wu,Rongyun Cao*

Main category: cs.RO

TL;DR: TeleGate通过动态激活专家策略和预测未来运动意图，实现了高精度实时全身遥操作。


<details>
  <summary>Details</summary>
Motivation: 开发一个统一的控制器，支持多样化的复杂人体运动，避免知识蒸馏带来的性能下降。

Method: 训练一个轻量级门控网络动态激活专家策略，并引入VAE运动先验模块提取隐含的未来运动意图。

Result: 仅用2.5小时的运动捕捉数据训练，TeleGate在多种动态运动中实现了高精度实时遥操作，显著优于基线方法。

Conclusion: TeleGate框架通过保留领域专家策略的全部能力，并引入轻量级门控网络和VAE运动先验模块，成功实现了高精度实时全身遥操作，显著优于基线方法。

Abstract: Real-time whole-body teleoperation is a critical method for humanoid robots to perform complex tasks in unstructured environments. However, developing a unified controller that robustly supports diverse human motions remains a significant challenge. Existing methods typically distill multiple expert policies into a single general policy, which often inevitably leads to performance degradation, particularly on highly dynamic motions. This paper presents TeleGate, a unified whole-body teleoperation framework for humanoid robots that achieves high-precision tracking across various motions while avoiding the performance loss inherent in knowledge distillation. Our key idea is to preserve the full capability of domain-specific expert policies by training a lightweight gating network, which dynamically activates experts in real-time based on proprioceptive states and reference trajectories. Furthermore, to compensate for the absence of future reference trajectories in real-time teleoperation, we introduce a VAE-based motion prior module that extracts implicit future motion intent from historical observations, enabling anticipatory control for motions requiring prediction such as jumping and standing up. We conducted empirical evaluations in simulation and also deployed our technique on the Unitree G1 humanoid robot. Using only 2.5 hours of motion capture data for training, our TeleGate achieves high-precision real-time teleoperation across diverse dynamic motions (e.g., running, fall recovery, and jumping), significantly outperforming the baseline methods in both tracking accuracy and success rate.

</details>


### [120] [AutoFly: Vision-Language-Action Model for UAV Autonomous Navigation in the Wild](https://arxiv.org/abs/2602.09657)
*Xiaolou Sun,Wufei Si,Wenhui Ni,Yuntian Li,Dongming Wu,Fei Xie,Runwei Guan,He-Yang Xu,Henghui Ding,Yuan Wu,Yutao Yue,Yongming Huang,Hui Xiong*

Main category: cs.RO

TL;DR: AutoFly是一种端到端的VLA模型，通过伪深度编码器和两阶段训练策略提升无人机自主导航能力，实验显示其成功率优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现实世界中无人机导航通常缺乏详细的导航指令，仅能提供粗略的位置或方向指导，因此需要一种能够自主规划和避障的导航方法。

Method: AutoFly采用端到端的Vision-Language-Action（VLA）模型，结合伪深度编码器从RGB输入中提取深度感知特征，并通过渐进式两阶段训练策略对齐视觉、深度和语言表示与动作策略。

Result: AutoFly在实验中比现有VLA基线成功率高出3.9%，且在模拟和真实环境中表现一致。

Conclusion: AutoFly模型通过结合伪深度编码器和两阶段训练策略，显著提升了无人机在未知环境中的自主导航能力，并在实验中获得比现有VLA基线更高的成功率。

Abstract: Vision-language navigation (VLN) requires intelligent agents to navigate environments by interpreting linguistic instructions alongside visual observations, serving as a cornerstone task in Embodied AI. Current VLN research for unmanned aerial vehicles (UAVs) relies on detailed, pre-specified instructions to guide the UAV along predetermined routes. However, real-world outdoor exploration typically occurs in unknown environments where detailed navigation instructions are unavailable. Instead, only coarse-grained positional or directional guidance can be provided, requiring UAVs to autonomously navigate through continuous planning and obstacle avoidance. To bridge this gap, we propose AutoFly, an end-to-end Vision-Language-Action (VLA) model for autonomous UAV navigation. AutoFly incorporates a pseudo-depth encoder that derives depth-aware features from RGB inputs to enhance spatial reasoning, coupled with a progressive two-stage training strategy that effectively aligns visual, depth, and linguistic representations with action policies. Moreover, existing VLN datasets have fundamental limitations for real-world autonomous navigation, stemming from their heavy reliance on explicit instruction-following over autonomous decision-making and insufficient real-world data. To address these issues, we construct a novel autonomous navigation dataset that shifts the paradigm from instruction-following to autonomous behavior modeling through: (1) trajectory collection emphasizing continuous obstacle avoidance, autonomous planning, and recognition workflows; (2) comprehensive real-world data integration. Experimental results demonstrate that AutoFly achieves a 3.9% higher success rate compared to state-of-the-art VLA baselines, with consistent performance across simulated and real environments.

</details>


### [121] [RANT: Ant-Inspired Multi-Robot Rainforest Exploration Using Particle Filter Localisation and Virtual Pheromone Coordination](https://arxiv.org/abs/2602.09661)
*Ameer Alhashemi,Layan Abdulhadi,Karam Abuodeh,Tala Baghdadi,Suryanarayana Datla*

Main category: cs.RO

TL;DR: RANT是一种蚂蚁启发的多机器人探索框架，通过粒子滤波和虚拟信息素协调在噪声环境中提高探索效率，团队规模增大会带来干扰。


<details>
  <summary>Details</summary>
Motivation: 解决噪声和不确定环境中多机器人探索的挑战，提高覆盖率和热点召回率。

Method: 结合粒子滤波定位、基于梯度的热点利用行为控制器和轻量级虚拟信息素协调机制。

Result: 实验表明粒子滤波对热点定位至关重要，协调机制显著减少重叠，团队规模增大覆盖但收益递减。

Conclusion: RANT框架通过粒子滤波定位、行为控制器和虚拟信息素协调机制，在噪声环境中有效提高了多机器人探索的覆盖率和热点召回率，但团队规模增大会因干扰而带来收益递减。

Abstract: This paper presents RANT, an ant-inspired multi-robot exploration framework for noisy, uncertain environments. A team of differential-drive robots navigates a 10 x 10 m terrain, collects noisy probe measurements of a hidden richness field, and builds local probabilistic maps while the supervisor maintains a global evaluation. RANT combines particle-filter localisation, a behaviour-based controller with gradient-driven hotspot exploitation, and a lightweight no-revisit coordination mechanism based on virtual pheromone blocking. We experimentally analyse how team size, localisation fidelity, and coordination influence coverage, hotspot recall, and redundancy. Results show that particle filtering is essential for reliable hotspot engagement, coordination substantially reduces overlap, and increasing team size improves coverage but yields diminishing returns due to interference.

</details>


### [122] [Fast Motion Planning for Non-Holonomic Mobile Robots via a Rectangular Corridor Representation of Structured Environments](https://arxiv.org/abs/2602.09714)
*Alejandro Gonzalez-Garcia,Sebastiaan Wyns,Sonia De Santis,Jan Swevers,Wilm Decré*

Main category: cs.RO

TL;DR: 提出了一种高效的非完整自主移动机器人运动规划框架，通过自由空间分解和在线规划，显著减少了搜索空间并生成了运动学可行的轨迹，适用于复杂结构化环境。


<details>
  <summary>Details</summary>
Motivation: 传统的基于网格的规划器在可扩展性方面存在困难，而许多运动学可行的规划器由于搜索空间复杂性带来了巨大的计算负担。为了克服这些限制，本研究提出了一种新方法。

Method: 引入了一种确定性自由空间分解方法，创建了一个紧凑的重叠矩形走廊图，显著减少了搜索空间，同时保持了路径分辨率。随后，框架通过在线运动规划找到矩形序列，并使用分析规划器生成近乎时间最优且运动学可行的轨迹。

Result: 该方法显著提高了运动规划的效率和可扩展性，适用于高度复杂但结构化的环境。

Conclusion: 该框架通过公开的开源软件实现，并通过大量仿真和物理机器人实验验证了其高效性，适用于大规模导航。

Abstract: We present a complete framework for fast motion planning of non-holonomic autonomous mobile robots in highly complex but structured environments. Conventional grid-based planners struggle with scalability, while many kinematically-feasible planners impose a significant computational burden due to their search space complexity. To overcome these limitations, our approach introduces a deterministic free-space decomposition that creates a compact graph of overlapping rectangular corridors. This method enables a significant reduction in the search space, without sacrificing path resolution. The framework then performs online motion planning by finding a sequence of rectangles and generating a near-time-optimal, kinematically-feasible trajectory using an analytical planner. The result is a highly efficient solution for large-scale navigation. We validate our framework through extensive simulations and on a physical robot. The implementation is publicly available as open-source software.

</details>


### [123] [Rethinking Visual-Language-Action Model Scaling: Alignment, Mixture, and Regularization](https://arxiv.org/abs/2602.09722)
*Ye Wang,Sipeng Zheng,Hao Luo,Wanpeng Zhang,Haoqi Yuan,Chaoyi Xu,Haiweng Xu,Yicheng Feng,Mingyang Yu,Zhiyu Kang,Zongqing Lu,Qin Jin*

Main category: cs.RO

TL;DR: 研究分析了VLA模型在机器人控制中的扩展效果，发现统一动作表示是关键，数据混合需谨慎，常规正则化策略效果有限。


<details>
  <summary>Details</summary>
Motivation: 探讨标准‘扩展数据’方法在机器人领域的适用性，特别是在训练数据因机器人本体、传感器和动作空间的异构性而复杂的情况下。

Method: 使用一个代表性的VLA框架，结合视觉-语言主干和流匹配技术，在匹配条件下消融关键设计决策，并在广泛的仿真和真实机器人实验中评估。

Result: 研究表明，统一的末端执行器（EEF）相对动作表示对跨本体转移至关重要；简单混合异构机器人数据集可能导致负迁移；直观的训练正则化策略（如感官丢弃和多阶段微调）在大规模下并不总能提升性能。

Conclusion: 这项研究挑战了关于视觉-语言-动作（VLA）模型在机器人控制中扩展的常见假设，并提供了从多样化机器人数据训练大规模VLA策略的实用指导。

Abstract: While Vision-Language-Action (VLA) models show strong promise for generalist robot control, it remains unclear whether -- and under what conditions -- the standard "scale data" recipe translates to robotics, where training data is inherently heterogeneous across embodiments, sensors, and action spaces. We present a systematic, controlled study of VLA scaling that revisits core training choices for pretraining across diverse robots. Using a representative VLA framework that combines a vision-language backbone with flow-matching, we ablate key design decisions under matched conditions and evaluate in extensive simulation and real-robot experiments. To improve the reliability of real-world results, we introduce a Grouped Blind Ensemble protocol that blinds operators to model identity and separates policy execution from outcome judgment, reducing experimenter bias. Our analysis targets three dimensions of VLA scaling. (1) Physical alignment: we show that a unified end-effector (EEF)-relative action representation is critical for robust cross-embodiment transfer. (2) Embodiment mixture: we find that naively pooling heterogeneous robot datasets often induces negative transfer rather than gains, underscoring the fragility of indiscriminate data scaling. (3) Training regularization: we observe that intuitive strategies, such as sensory dropout and multi-stage fine-tuning, do not consistently improve performance at scale. Together, this study challenge some common assumptions about embodied scaling and provide practical guidance for training large-scale VLA policies from diverse robotic data. Project website: https://research.beingbeyond.com/rethink_vla

</details>


### [124] [NavDreamer: Video Models as Zero-Shot 3D Navigators](https://arxiv.org/abs/2602.09765)
*Xijie Huang,Weiqi Gai,Tianyue Wu,Congyu Wang,Zhiyang Liu,Xin Zhou,Yuze Wu,Fei Gao*

Main category: cs.RO

TL;DR: NavDreamer利用视频生成模型实现语言指令到导航轨迹的转换，通过优化方法和逆动力学模型提升导航性能，实验验证其强大泛化能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有视觉-语言-动作模型在导航任务中数据稀缺、多样性不足及静态表示无法捕捉时空动态和物理规律的问题。

Method: 提出了NavDreamer框架，利用生成视频模型处理时空信息和物理动态，结合采样优化方法和逆动力学模型解码可执行路径。

Result: 实验表明NavDreamer在新物体和未见环境中表现出强大的泛化能力，视频规划特别适合导航的高级决策特性。

Conclusion: NavDreamer通过视频生成模型作为语言指令与导航轨迹的通用接口，展示了在导航任务中的强大零样本泛化能力，并通过采样优化方法和逆动力学模型提升了导航的准确性和可执行性。

Abstract: Previous Vision-Language-Action models face critical limitations in navigation: scarce, diverse data from labor-intensive collection and static representations that fail to capture temporal dynamics and physical laws. We propose NavDreamer, a video-based framework for 3D navigation that leverages generative video models as a universal interface between language instructions and navigation trajectories. Our main hypothesis is that video's ability to encode spatiotemporal information and physical dynamics, combined with internet-scale availability, enables strong zero-shot generalization in navigation. To mitigate the stochasticity of generative predictions, we introduce a sampling-based optimization method that utilizes a VLM for trajectory scoring and selection. An inverse dynamics model is employed to decode executable waypoints from generated video plans for navigation. To systematically evaluate this paradigm in several video model backbones, we introduce a comprehensive benchmark covering object navigation, precise navigation, spatial grounding, language control, and scene reasoning. Extensive experiments demonstrate robust generalization across novel objects and unseen environments, with ablation studies revealing that navigation's high-level decision-making nature makes it particularly suited for video-based planning.

</details>


### [125] [Diverse Skill Discovery for Quadruped Robots via Unsupervised Learning](https://arxiv.org/abs/2602.09767)
*Ruopeng Cui,Yifei Bi,Haojie Luo,Wei Li*

Main category: cs.RO

TL;DR: 本文提出OMoE架构和多判别器框架，解决无监督技能发现中的行为重叠和奖励滥用问题，显著提升效率和多样性。


<details>
  <summary>Details</summary>
Motivation: 现有无监督技能发现方法存在学习效率低和技能多样性不足的问题，亟需改进。

Method: 采用正交混合专家（OMoE）架构和多判别器框架，分别解决行为表示重叠和奖励信号滥用问题。

Result: 在12-DOF Unitree A1四足机器人上验证了方法的有效性，状态空间覆盖率提升了18.3%。

Conclusion: 本文提出的OMoE架构和多判别器框架有效解决了现有技能发现方法的局限性，显著提升了训练效率和技能多样性。

Abstract: Reinforcement learning necessitates meticulous reward shaping by specialists to elicit target behaviors, while imitation learning relies on costly task-specific data. In contrast, unsupervised skill discovery can potentially reduce these burdens by learning a diverse repertoire of useful skills driven by intrinsic motivation. However, existing methods exhibit two key limitations: they typically rely on a single policy to master a versatile repertoire of behaviors without modeling the shared structure or distinctions among them, which results in low learning efficiency; moreover, they are susceptible to reward hacking, where the reward signal increases and converges rapidly while the learned skills display insufficient actual diversity. In this work, we introduce an Orthogonal Mixture-of-Experts (OMoE) architecture that prevents diverse behaviors from collapsing into overlapping representations, enabling a single policy to master a wide spectrum of locomotion skills. In addition, we design a multi-discriminator framework in which different discriminators operate on distinct observation spaces, effectively mitigating reward hacking. We evaluated our method on the 12-DOF Unitree A1 quadruped robot, demonstrating a diverse set of locomotion skills. Our experiments demonstrate that the proposed framework boosts training efficiency and yields an 18.3\% expansion in state-space coverage compared to the baseline.

</details>


### [126] [Design and Evaluation of an Assisted Programming Interface for Behavior Trees in Robotics](https://arxiv.org/abs/2602.09772)
*Jonathan Styrud,Matteo Iovino,Rebecca Stower,Mart Kartašev,Mikael Norrlöf,Mårten Björkman,Christian Smith*

Main category: cs.RO

TL;DR: BETR-GUI通过结合AI辅助与拖放编辑器，显著提升机器人编程效率，用户表现优于单独AI。


<details>
  <summary>Details</summary>
Motivation: 探索如何将行为树（BT）程序表示技术与完整图形用户界面（GUI）结合，以允许用户验证和编辑自动化方法生成的行为树，从而更快创建反应式机器人程序。

Method: 结合大语言模型、规划、遗传编程和贝叶斯优化，开发了拖放式图形用户界面（BETR-GUI）。

Result: 60名参与者的用户研究表明，结合不同辅助方法的BETR-GUI能帮助用户更高效完成机器人编程任务，且完整版BETR-GUI的用户表现优于单独运行的AI助手。

Conclusion: BETR-GUI结合多种辅助方法（如大语言模型、规划、遗传编程和贝叶斯优化）与拖放编辑器，显著提升了用户在机器人编程任务中的表现，且人类使用完整版BETR-GUI的表现优于单独运行的AI助手。

Abstract: The possibility to create reactive robot programs faster without the need for extensively trained programmers is becoming increasingly important. So far, it has not been explored how various techniques for creating Behavior Tree (BT) program representations could be combined with complete graphical user interfaces (GUIs) to allow a human user to validate and edit trees suggested by automated methods. In this paper, we introduce BEhavior TRee GUI (BETR-GUI) for creating BTs with the help of an AI assistant that combines methods using large language models, planning, genetic programming, and Bayesian optimization with a drag-and-drop editor. A user study with 60 participants shows that by combining different assistive methods, BETR-GUI enables users to perform better at solving the robot programming tasks. The results also show that humans using the full variant of BETR-GUI perform better than the AI assistant running on its own.

</details>


### [127] [BagelVLA: Enhancing Long-Horizon Manipulation via Interleaved Vision-Language-Action Generation](https://arxiv.org/abs/2602.09849)
*Yucheng Hu,Jianke Zhang,Yuanfei Luo,Yanjiang Guo,Xiaoyu Chen,Xinshu Sun,Kun Feng,Qingzhou Lu,Sheng Chen,Yangang Zhang,Wei Li,Jianyu Chen*

Main category: cs.RO

TL;DR: BagelVLA整合语言规划和视觉预测，通过RFG高效耦合模态，显著提升复杂任务性能。


<details>
  <summary>Details</summary>
Motivation: 现有的VLA模型通常单独处理语言规划或视觉预测，导致在复杂任务中表现不佳。

Method: BagelVLA是一个统一框架，结合了语言规划和视觉预测，并引入Residual Flow Guidance（RFG）来高效耦合这些模态。

Result: BagelVLA在多个模拟和真实世界基准测试中显著优于现有基线，尤其是在需要多阶段推理的任务中。

Conclusion: BagelVLA通过整合语言规划、视觉预测和动作生成，显著提升了复杂、长周期操作任务的性能。

Abstract: Equipping embodied agents with the ability to reason about tasks, foresee physical outcomes, and generate precise actions is essential for general-purpose manipulation. While recent Vision-Language-Action (VLA) models have leveraged pre-trained foundation models, they typically focus on either linguistic planning or visual forecasting in isolation. These methods rarely integrate both capabilities simultaneously to guide action generation, leading to suboptimal performance in complex, long-horizon manipulation tasks. To bridge this gap, we propose BagelVLA, a unified model that integrates linguistic planning, visual forecasting, and action generation within a single framework. Initialized from a pretrained unified understanding and generative model, BagelVLA is trained to interleave textual reasoning and visual prediction directly into the action execution loop. To efficiently couple these modalities, we introduce Residual Flow Guidance (RFG), which initializes from current observation and leverages single-step denoising to extract predictive visual features, guiding action generation with minimal latency. Extensive experiments demonstrate that BagelVLA outperforms existing baselines by a significant margin on multiple simulated and real-world benchmarks, particularly in tasks requiring multi-stage reasoning.

</details>


### [128] [TriPilot-FF: Coordinated Whole-Body Teleoperation with Force Feedback](https://arxiv.org/abs/2602.09888)
*Zihao Li,Yanan Zhou,Ranpeng Qiu,Hangyu Wu,Guoqiang Ren,Weiming Zhi*

Main category: cs.RO

TL;DR: TriPilot-FF是一种低成本全身遥操作系统，通过脚踏板触觉反馈和双手机器人跟随，提升移动机械臂的操作效率和避障能力。


<details>
  <summary>Details</summary>
Motivation: 现有移动机械臂遥操作界面多为手控，忽略了脚控通道的潜力，导致操作协调性和避障能力不足。

Method: TriPilot-FF结合了脚踏板触觉反馈（基于激光雷达的障碍物距离信号）和上半身双手机器人跟随遥操作，支持实时力反馈和视觉引导。

Result: 系统在长时间任务和精确移动协调中表现优异，反馈信号提升了ACT策略的性能。

Conclusion: TriPilot-FF通过低成本激光雷达和脚踏板触觉反馈，实现了移动机械臂的全身遥操作，提升了操作效率和避障能力，并通过反馈信号优化了ACT策略的性能。

Abstract: Mobile manipulators broaden the operational envelope for robot manipulation. However, the whole-body teleoperation of such robots remains a problem: operators must coordinate a wheeled base and two arms while reasoning about obstacles and contact. Existing interfaces are predominantly hand-centric (e.g., VR controllers and joysticks), leaving foot-operated channels underexplored for continuous base control. We present TriPilot-FF, an open-source whole-body teleoperation system for a custom bimanual mobile manipulator that introduces a foot-operated pedal with lidar-driven pedal haptics, coupled with upper-body bimanual leader-follower teleoperation. Using only a low-cost base-mounted lidar, TriPilot-FF renders a resistive pedal cue from proximity-to-obstacle signals in the commanded direction, shaping operator commands toward collision-averse behaviour without an explicit collision-avoidance controller. The system also supports arm-side force reflection for contact awareness and provides real-time force and visual guidance of bimanual manipulability to prompt mobile base repositioning, thereby improving reach. We demonstrate the capability of TriPilot-FF to effectively ``co-pilot'' the human operator over long time-horizons and tasks requiring precise mobile base movement and coordination. Finally, we incorporate teleoperation feedback signals into an Action Chunking with Transformers (ACT) policy and demonstrate improved performance when the additional information is available. We release the pedal device design, full software stack, and conduct extensive real-world evaluations on a bimanual wheeled platform. The project page of TriPilot-FF is http://bit.ly/46H3ZJT.

</details>


### [129] [TaCo: A Benchmark for Lossless and Lossy Codecs of Heterogeneous Tactile Data](https://arxiv.org/abs/2602.09893)
*Zhengxue Cheng,Yan Zhao,Keyu Wang,Hengdi Zhang,Li Song*

Main category: cs.RO

TL;DR: TaCo是首个触觉数据编解码器基准，评估了30种压缩方法，开发了专为触觉数据训练的TaCo-LL和TaCo-L，性能优越。


<details>
  <summary>Details</summary>
Motivation: 触觉感知对具身智能至关重要，但高效的触觉数据压缩在严格带宽限制下的实时机器人应用中仍未被充分探索。

Method: 通过评估30种压缩方法（包括现成算法和神经编解码器），在五种不同传感器类型的数据集上，系统测试了无损和有损压缩方案在四个关键任务中的表现。

Result: TaCo-LL（无损）和TaCo-L（有损）在触觉数据上表现优异，验证了其优越性能。

Conclusion: TaCo基准为触觉数据压缩领域提供了首个全面评估框架，揭示了压缩效率与任务性能之间的关键权衡，为未来触觉感知的进步铺平了道路。

Abstract: Tactile sensing is crucial for embodied intelligence, providing fine-grained perception and control in complex environments. However, efficient tactile data compression, which is essential for real-time robotic applications under strict bandwidth constraints, remains underexplored. The inherent heterogeneity and spatiotemporal complexity of tactile data further complicate this challenge. To bridge this gap, we introduce TaCo, the first comprehensive benchmark for Tactile data Codecs. TaCo evaluates 30 compression methods, including off-the-shelf compression algorithms and neural codecs, across five diverse datasets from various sensor types. We systematically assess both lossless and lossy compression schemes on four key tasks: lossless storage, human visualization, material and object classification, and dexterous robotic grasping. Notably, we pioneer the development of data-driven codecs explicitly trained on tactile data, TaCo-LL (lossless) and TaCo-L (lossy). Results have validated the superior performance of our TaCo-LL and TaCo-L. This benchmark provides a foundational framework for understanding the critical trade-offs between compression efficiency and task performance, paving the way for future advances in tactile perception.

</details>


### [130] [Instruct2Act: From Human Instruction to Actions Sequencing and Execution via Robot Action Network for Robotic Manipulation](https://arxiv.org/abs/2602.09940)
*Archit Sharma,Dharmendra Sharma,John Rebeiro,Peeyush Thakur,Narendra Dhar,Laxmidhar Behera*

Main category: cs.RO

TL;DR: 提出轻量级全设备端流程，通过两阶段解析指令并生成精确轨迹，实现高效机器人操作，验证了90%成功率与快速响应。


<details>
  <summary>Details</summary>
Motivation: 机器人因计算和感知限制难以在现实环境中执行自由形式的人类指令，需轻量级、完全在设备上的解决方案。

Method: 采用两阶段流程：(i) Instruct2Act模块，使用紧凑的BiLSTM与多头注意力自编码器将指令解析为有序原子动作序列；(ii) 机器人动作网络（RAN），结合动态自适应轨迹径向网络（DATRN）和基于YOLOv8的视觉环境分析器生成精确控制轨迹。

Result: 在自定义数据集上，Instruct2Act达到91.5%的子动作预测准确率；真实机器人评估中，四项任务总体成功率为90%，子动作推断时间<3.8秒，端到端执行时间30-60秒。

Conclusion: 研究表明，通过细粒度的指令到动作解析，结合基于DATRN的轨迹生成和视觉引导的接地，为资源受限、单摄像头环境下的确定性实时操作提供了实用路径。

Abstract: Robots often struggle to follow free-form human instructions in real-world settings due to computational and sensing limitations. We address this gap with a lightweight, fully on-device pipeline that converts natural-language commands into reliable manipulation. Our approach has two stages: (i) the instruction to actions module (Instruct2Act), a compact BiLSTM with a multi-head-attention autoencoder that parses an instruction into an ordered sequence of atomic actions (e.g., reach, grasp, move, place); and (ii) the robot action network (RAN), which uses the dynamic adaptive trajectory radial network (DATRN) together with a vision-based environment analyzer (YOLOv8) to generate precise control trajectories for each sub-action. The entire system runs on a modest system with no cloud services. On our custom proprietary dataset, Instruct2Act attains 91.5% sub-actions prediction accuracy while retaining a small footprint. Real-robot evaluations across four tasks (pick-place, pick-pour, wipe, and pick-give) yield an overall 90% success; sub-action inference completes in < 3.8s, with end-to-end executions in 30-60s depending on task complexity. These results demonstrate that fine-grained instruction-to-action parsing, coupled with DATRN-based trajectory generation and vision-guided grounding, provides a practical path to deterministic, real-time manipulation in resource-constrained, single-camera settings.

</details>


### [131] [Hydra-Nav: Object Navigation via Adaptive Dual-Process Reasoning](https://arxiv.org/abs/2602.09972)
*Zixuan Wang,Huang Fang,Shaoan Wang,Yuanfei Luo,Heng Dong,Wei Li,Yiming Gan*

Main category: cs.RO

TL;DR: Hydra-Nav是一种自适应切换慢速推理和快速执行的VLM架构，通过三阶段训练提升目标导航的效率和成功率，实验表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有视觉语言模型（VLM）在目标导航中因时空推理能力不足导致成功率低和定位效率低下，而现有改进方法又带来过高计算开销。

Method: Hydra-Nav采用三阶段训练课程：(i) 空间-动作对齐以加强轨迹规划，(ii) 记忆-推理整合以增强长期探索中的时空推理，(iii) 迭代拒绝微调以在关键决策点选择性推理。

Result: Hydra-Nav在HM3D、MP3D和OVON基准测试中分别以11.1%、17.4%和21.2%的优势超越次优方法，且新指标SOT显示自适应推理显著提升搜索效率。

Conclusion: Hydra-Nav通过自适应切换慢速系统（用于分析探索历史和制定高层计划）和快速系统（用于高效执行），显著提升了目标导航的成功率和效率。实验证明其在多个基准测试中表现优异，并引入了新的效率评估指标SOT。

Abstract: While large vision-language models (VLMs) show promise for object goal navigation, current methods still struggle with low success rates and inefficient localization of unseen objects--failures primarily attributed to weak temporal-spatial reasoning. Meanwhile, recent attempts to inject reasoning into VLM-based agents improve success rates but incur substantial computational overhead. To address both the ineffectiveness and inefficiency of existing approaches, we introduce Hydra-Nav, a unified VLM architecture that adaptively switches between a deliberative slow system for analyzing exploration history and formulating high-level plans, and a reactive fast system for efficient execution. We train Hydra-Nav through a three-stage curriculum: (i) spatial-action alignment to strengthen trajectory planning, (ii) memory-reasoning integration to enhance temporal-spatial reasoning over long-horizon exploration, and (iii) iterative rejection fine-tuning to enable selective reasoning at critical decision points. Extensive experiments demonstrate that Hydra-Nav achieves state-of-the-art performance on the HM3D, MP3D, and OVON benchmarks, outperforming the second-best methods by 11.1%, 17.4%, and 21.2%, respectively. Furthermore, we introduce SOT (Success weighted by Operation Time), a new metric to measure search efficiency across VLMs with varying reasoning intensity. Results show that adaptive reasoning significantly enhances search efficiency over fixed-frequency baselines.

</details>


### [132] [RoboInter: A Holistic Intermediate Representation Suite Towards Robotic Manipulation](https://arxiv.org/abs/2602.09973)
*Hao Li,Ziqin Wang,Zi-han Ding,Shuai Yang,Yilun Chen,Yang Tian,Xiaolin Hu,Tai Wang,Dahua Lin,Feng Zhao,Si Liu,Jiangmiao Pang*

Main category: cs.RO

TL;DR: RoboInter通过大规模数据集和中间表示模型，解决了机器人操作数据集的局限性，提升了VLA模型的泛化和推理能力。


<details>
  <summary>Details</summary>
Motivation: 现有机器人操作数据集成本高、特定于具体实现、覆盖范围和多样性不足，限制了VLA模型的泛化能力。

Method: 引入了RoboInter Manipulation Suite，包括数据、基准和中间表示模型。具体包括RoboInter-Tool（轻量级GUI）和RoboInter-Data（大规模数据集），并在此基础上开发了RoboInter-VQA和RoboInter-VLA。

Result: RoboInter-Data包含超过23万次操作和571个场景，提供超过10类中间表示的密集逐帧标注，显著超越先前工作的规模和标注质量。

Conclusion: RoboInter为通过细粒度和多样化的中间表示推进稳健和可泛化的机器人学习提供了实用基础。

Abstract: Advances in large vision-language models (VLMs) have stimulated growing interest in vision-language-action (VLA) systems for robot manipulation. However, existing manipulation datasets remain costly to curate, highly embodiment-specific, and insufficient in coverage and diversity, thereby hindering the generalization of VLA models. Recent approaches attempt to mitigate these limitations via a plan-then-execute paradigm, where high-level plans (e.g., subtasks, trace) are first generated and subsequently translated into low-level actions, but they critically rely on extra intermediate supervision, which is largely absent from existing datasets. To bridge this gap, we introduce the RoboInter Manipulation Suite, a unified resource including data, benchmarks, and models of intermediate representations for manipulation. It comprises RoboInter-Tool, a lightweight GUI that enables semi-automatic annotation of diverse representations, and RoboInter-Data, a large-scale dataset containing over 230k episodes across 571 diverse scenes, which provides dense per-frame annotations over more than 10 categories of intermediate representations, substantially exceeding prior work in scale and annotation quality. Building upon this foundation, RoboInter-VQA introduces 9 spatial and 20 temporal embodied VQA categories to systematically benchmark and enhance the embodied reasoning capabilities of VLMs. Meanwhile, RoboInter-VLA offers an integrated plan-then-execute framework, supporting modular and end-to-end VLA variants that bridge high-level planning with low-level execution via intermediate supervision. In total, RoboInter establishes a practical foundation for advancing robust and generalizable robotic learning via fine-grained and diverse intermediate representations.

</details>


### [133] [Acoustic Drone Package Delivery Detection](https://arxiv.org/abs/2602.09991)
*François Marcoux,François Grondin*

Main category: cs.RO

TL;DR: 首个基于声学的无人机投递检测算法，利用麦克风阵列和深度学习，有效识别投递事件，准确率高，误报率低。


<details>
  <summary>Details</summary>
Motivation: 近年来，无人机在监狱等限制区域的非法投递成为重大安全挑战，但现有研究多集中于无人机检测或定位，对投递事件的识别关注不足。

Method: 提出了一种基于地面麦克风阵列的声学包裹投递检测算法，利用深度神经网络从梅尔频谱图中检测无人机存在并估计螺旋桨转速，通过分析叶片通过频率（BPF）的突变识别投递时刻。

Result: 算法在无人机距离麦克风阵列150米内时，叶片通过频率估计的平均绝对误差为16赫兹；无人机存在检测准确率达97%；投递事件识别正确率为96%，误报率为8%。

Conclusion: 本研究展示了仅使用声学信号在100米范围内识别无人机投递事件的可行性，为限制区域的安全监控提供了新的解决方案。

Abstract: In recent years, the illicit use of unmanned aerial vehicles (UAVs) for deliveries in restricted area such as prisons became a significant security challenge. While numerous studies have focused on UAV detection or localization, little attention has been given to delivery events identification. This study presents the first acoustic package delivery detection algorithm using a ground-based microphone array. The proposed method estimates both the drone's propeller speed and the delivery event using solely acoustic features. A deep neural network detects the presence of a drone and estimates the propeller's rotation speed or blade passing frequency (BPF) from a mel spectrogram. The algorithm analyzes the BPFs to identify probable delivery moments based on sudden changes before and after a specific time. Results demonstrate a mean absolute error of the blade passing frequency estimator of 16 Hz when the drone is less than 150 meters away from the microphone array. The drone presence detection estimator has a accuracy of 97%. The delivery detection algorithm correctly identifies 96% of events with a false positive rate of 8%. This study shows that deliveries can be identified using acoustic signals up to a range of 100 meters.

</details>


### [134] [A Collaborative Safety Shield for Safe and Efficient CAV Lane Changes in Congested On-Ramp Merging](https://arxiv.org/abs/2602.10007)
*Bharathkumar Hegde,Melanie Bouroche*

Main category: cs.RO

TL;DR: 提出MARL-MASS，结合MASS与MARL，平衡安全与效率，在拥堵交通中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有车道变换控制器要么确保安全，要么协作提高交通效率，但未同时考虑这两个冲突目标。

Method: 提出了多智能体安全盾（MASS），通过控制屏障函数（CBFs）实现安全与协作的车道变换，并扩展了多智能体强化学习（MARL）车道变换控制器。

Result: MASS通过严格遵循安全约束实现了协作车道变换，定制奖励函数提高了MARL策略的稳定性。

Conclusion: MARL-MASS有效平衡了在拥堵交通中确保安全与提高交通效率之间的权衡。

Abstract: Lane changing in dense traffic is a significant challenge for Connected and Autonomous Vehicles (CAVs). Existing lane change controllers primarily either ensure safety or collaboratively improve traffic efficiency, but do not consider these conflicting objectives together. To address this, we propose the Multi-Agent Safety Shield (MASS), designed using Control Barrier Functions (CBFs) to enable safe and collaborative lane changes. The MASS enables collaboration by capturing multi-agent interactions among CAVs through interaction topologies constructed as a graph using a simple algorithm. Further, a state-of-the-art Multi-Agent Reinforcement Learning (MARL) lane change controller is extended by integrating MASS to ensure safety and defining a customised reward function to prioritise efficiency improvements. As a result, we propose a lane change controller, known as MARL-MASS, and evaluate it in a congested on-ramp merging simulation. The results demonstrate that MASS enables collaborative lane changes with safety guarantees by strictly respecting the safety constraints. Moreover, the proposed custom reward function improves the stability of MARL policies trained with a safety shield. Overall, by encouraging the exploration of a collaborative lane change policy while respecting safety constraints, MARL-MASS effectively balances the trade-off between ensuring safety and improving traffic efficiency in congested traffic. The code for MARL-MASS is available with an open-source licence at https://github.com/hkbharath/MARL-MASS

</details>


### [135] [Learning Force-Regulated Manipulation with a Low-Cost Tactile-Force-Controlled Gripper](https://arxiv.org/abs/2602.10013)
*Xuhui Kang,Tongxuan Tian,Sung-Wook Lee,Binghao Huang,Yunzhu Li,Yen-Ling Kuo*

Main category: cs.RO

TL;DR: 开发低成本力控夹爪TF-Gripper和RETAF框架，实现机器人精确力控，提升抓取稳定性，触觉反馈是关键。


<details>
  <summary>Details</summary>
Motivation: 赋予机器人像人类一样通过触觉反馈精确调节力的能力，解决商业夹爪成本高或最小力过大不适用于日常力敏感物体的问题。

Method: 开发了低成本、力控的平行夹爪TF-Gripper，并设计了配套的远程操作设备记录人力数据；提出了RETAF框架，将力控与臂姿预测解耦，利用手腕图像和触觉反馈高频调节力。

Result: TF-Gripper和RETAF在五种需要精确力控的真实任务中表现优异，直接力控显著提升抓取稳定性和任务性能，触觉反馈对力调节至关重要，RETAF优于基线方法。

Conclusion: 本研究通过TF-Gripper和RETAF框架的引入，显著提升了机器人在精确力控任务中的表现，为力控策略学习在机器人操作中的规模化应用开辟了新路径。

Abstract: Successfully manipulating many everyday objects, such as potato chips, requires precise force regulation. Failure to modulate force can lead to task failure or irreversible damage to the objects. Humans can precisely achieve this by adapting force from tactile feedback, even within a short period of physical contact. We aim to give robots this capability. However, commercial grippers exhibit high cost or high minimum force, making them unsuitable for studying force-controlled policy learning with everyday force-sensitive objects. We introduce TF-Gripper, a low-cost (~$150) force-controlled parallel-jaw gripper that integrates tactile sensing as feedback. It has an effective force range of 0.45-45N and is compatible with different robot arms. Additionally, we designed a teleoperation device paired with TF-Gripper to record human-applied grasping forces. While standard low-frequency policies can be trained on this data, they struggle with the reactive, contact-dependent nature of force regulation. To overcome this, we propose RETAF (REactive Tactile Adaptation of Force), a framework that decouples grasping force control from arm pose prediction. RETAF regulates force at high frequency using wrist images and tactile feedback, while a base policy predicts end-effector pose and gripper open/close action. We evaluate TF-Gripper and RETAF across five real-world tasks requiring precise force regulation. Results show that compared to position control, direct force control significantly improves grasp stability and task performance. We further show that tactile feedback is essential for force regulation, and that RETAF consistently outperforms baselines and can be integrated with various base policies. We hope this work opens a path for scaling the learning of force-controlled policies in robotic manipulation. Project page: https://force-gripper.github.io .

</details>


### [136] [RoboSubtaskNet: Temporal Sub-task Segmentation for Human-to-Robot Skill Transfer in Real-World Environments](https://arxiv.org/abs/2602.10015)
*Dharmendra Sharma,Archit Sharma,John Reberio,Vaibhav Kesharwani,Peeyush Thakur,Narendra Kumar Dhar,Laxmidhar Behera*

Main category: cs.RO

TL;DR: RoboSubtaskNet 是一个用于视频子任务分割的多阶段框架，结合了注意力增强的 I3D 特征和改进的 MS-TCN，在多个基准测试中表现优异，并在实际机器人操作中验证了可靠性。


<details>
  <summary>Details</summary>
Motivation: 在长未修剪视频中定位和分类细粒度子任务片段对于安全的人机协作至关重要，尤其是需要直接可机器人执行的子任务标签。

Method: RoboSubtaskNet 是一个多阶段框架，结合了注意力增强的 I3D 特征（RGB 加光流）和改进的 MS-TCN（采用斐波那契扩张计划），并使用了复合目标函数（交叉熵和时间正则化项）来减少过度分割并鼓励有效的子任务进展。

Result: RoboSubtaskNet 在 GTEA、Breakfast 和 RoboSubtask 基准测试中表现优异，具体指标为：GTEA（F1 @ 50 = 79.5%, Edit = 88.6%, Acc = 78.9%）、Breakfast（F1 @ 50 = 30.4%, Edit = 52.0%, Acc = 53.5%）和 RoboSubtask（F1 @ 50 = 94.2%, Edit = 95.6%, Acc = 92.2%）。物理试验中任务成功率约为 91.25%。

Conclusion: RoboSubtaskNet 展示了一条从视频子任务理解到实际机器人操作的实用路径，其性能在多个基准测试中优于现有方法，并在物理试验中验证了端到端行为的可靠性。

Abstract: Temporally locating and classifying fine-grained sub-task segments in long, untrimmed videos is crucial to safe human-robot collaboration. Unlike generic activity recognition, collaborative manipulation requires sub-task labels that are directly robot-executable. We present RoboSubtaskNet, a multi-stage human-to-robot sub-task segmentation framework that couples attention-enhanced I3D features (RGB plus optical flow) with a modified MS-TCN employing a Fibonacci dilation schedule to capture better short-horizon transitions such as reach-pick-place. The network is trained with a composite objective comprising cross-entropy and temporal regularizers (truncated MSE and a transition-aware term) to reduce over-segmentation and to encourage valid sub-task progressions. To close the gap between vision benchmarks and control, we introduce RoboSubtask, a dataset of healthcare and industrial demonstrations annotated at the sub-task level and designed for deterministic mapping to manipulator primitives. Empirically, RoboSubtaskNet outperforms MS-TCN and MS-TCN++ on GTEA and our RoboSubtask benchmark (boundary-sensitive and sequence metrics), while remaining competitive on the long-horizon Breakfast benchmark. Specifically, RoboSubtaskNet attains F1 @ 50 = 79.5%, Edit = 88.6%, Acc = 78.9% on GTEA; F1 @ 50 = 30.4%, Edit = 52.0%, Acc = 53.5% on Breakfast; and F1 @ 50 = 94.2%, Edit = 95.6%, Acc = 92.2% on RoboSubtask. We further validate the full perception-to-execution pipeline on a 7-DoF Kinova Gen3 manipulator, achieving reliable end-to-end behavior in physical trials (overall task success approx 91.25%). These results demonstrate a practical path from sub-task level video understanding to deployed robotic manipulation in real-world settings.

</details>


### [137] [A Collision-Free Sway Damping Model Predictive Controller for Safe and Reactive Forestry Crane Navigation](https://arxiv.org/abs/2602.10035)
*Marc-Philip Ecker,Christoph Fröhlich,Johannes Huemer,David Gruber,Bernhard Bischof,Tobias Glück,Wolfgang Kemmetmüller*

Main category: cs.RO

TL;DR: 首个结合碰撞避免和载荷摆控制的MPC框架，实时适应环境，实验验证有效。


<details>
  <summary>Details</summary>
Motivation: 林业起重机在动态、非结构化的户外环境中操作，需要同时解决碰撞避免和载荷摆控制问题，现有方法往往单独处理这些挑战。

Method: 通过将基于LiDAR的环境映射直接集成到MPC中，利用在线欧几里得距离场（EDF）实现实时环境适应。

Result: 实验验证表明，该控制器能有效抑制摆荡并成功避开障碍物。

Conclusion: 该研究提出了一种结合碰撞避免和载荷摆控制的统一模型预测控制（MPC）框架，并在真实林业起重机上验证了其有效性。

Abstract: Forestry cranes operate in dynamic, unstructured outdoor environments where simultaneous collision avoidance and payload sway control are critical for safe navigation. Existing approaches address these challenges separately, either focusing on sway damping with predefined collision-free paths or performing collision avoidance only at the global planning level. We present the first collision-free, sway-damping model predictive controller (MPC) for a forestry crane that unifies both objectives in a single control framework. Our approach integrates LiDAR-based environment mapping directly into the MPC using online Euclidean distance fields (EDF), enabling real-time environmental adaptation. The controller simultaneously enforces collision constraints while damping payload sway, allowing it to (i) replan upon quasi-static environmental changes, (ii) maintain collision-free operation under disturbances, and (iii) provide safe stopping when no bypass exists. Experimental validation on a real forestry crane demonstrates effective sway damping and successful obstacle avoidance. A video can be found at https://youtu.be/tEXDoeLLTxA.

</details>


### [138] [Humanoid Factors: Design Principles for AI Humanoids in Human Worlds](https://arxiv.org/abs/2602.10069)
*Xinyuan Liu,Eren Sadikoglu,Ransalu Senanayake,Lixiao Huang*

Main category: cs.RO

TL;DR: 文章提出了‘人形机器人因素’框架，围绕物理、认知、社会和伦理四个支柱，旨在指导人形机器人的设计与评估，以适应与人类的长期共存。


<details>
  <summary>Details</summary>
Motivation: 随着人形机器人逐渐进入人类的工作场所、家庭和公共空间，设计挑战不仅需要考虑人类因素，还需考虑机器人因素，因为两者将在同一环境中共存和互动。

Method: 文章介绍了一个围绕四个支柱（物理、认知、社会和伦理）构建的框架，并通过实际案例评估了一个真实世界的人形机器人控制算法。

Result: 通过框架的应用，文章展示了传统机器人任务完成指标如何忽视了关键的人类认知和互动原则。

Conclusion: 文章提出了‘人形机器人因素’作为一个基础框架，用于设计、评估和治理人与机器人长期共存的问题。

Abstract: Human factors research has long focused on optimizing environments, tools, and systems to account for human performance. Yet, as humanoid robots begin to share our workplaces, homes, and public spaces, the design challenge expands. We must now consider not only factors for humans but also factors for humanoids, since both will coexist and interact within the same environments. Unlike conventional machines, humanoids introduce expectations of human-like behavior, communication, and social presence, which reshape usability, trust, and safety considerations. In this article, we introduce the concept of humanoid factors as a framework structured around four pillars - physical, cognitive, social, and ethical - that shape the development of humanoids to help them effectively coexist and collaborate with humans. This framework characterizes the overlap and divergence between human capabilities and those of general-purpose humanoids powered by AI foundation models. To demonstrate our framework's practical utility, we then apply the framework to evaluate a real-world humanoid control algorithm, illustrating how conventional task completion metrics in robotics overlook key human cognitive and interaction principles. We thus position humanoid factors as a foundational framework for designing, evaluating, and governing sustained human-humanoid coexistence.

</details>


### [139] [UniVTAC: A Unified Simulation Platform for Visuo-Tactile Manipulation Data Generation, Learning, and Benchmarking](https://arxiv.org/abs/2602.10093)
*Baijun Chen,Weijie Wan,Tianxing Chen,Xianda Guo,Congsheng Xu,Yuanyang Qi,Haojie Zhang,Longyan Wu,Tianling Xu,Zixuan Li,Yizhe Wu,Rui Li,Xiaokang Yang,Ping Luo,Wei Sui,Yao Mu*

Main category: cs.RO

TL;DR: UniVTAC是一个仿真触觉数据合成平台，通过其编码器显著提升了触觉驱动策略的性能。


<details>
  <summary>Details</summary>
Motivation: 解决触觉数据获取成本高、缺乏统一评估平台的问题，以提升接触密集型任务的鲁棒性。

Method: 提出了UniVTAC平台，支持三种常用视觉-触觉传感器，并设计了大尺度仿真合成数据的编码器训练方法。

Result: UniVTAC编码器在基准测试中平均成功率提升17.1%，真实世界实验任务成功率提高25%。

Conclusion: UniVTAC平台及其编码器显著提升了触觉驱动策略的性能，实验证明在仿真和现实世界中均能有效提高任务成功率。

Abstract: Robotic manipulation has seen rapid progress with vision-language-action (VLA) policies. However, visuo-tactile perception is critical for contact-rich manipulation, as tasks such as insertion are difficult to complete robustly using vision alone. At the same time, acquiring large-scale and reliable tactile data in the physical world remains costly and challenging, and the lack of a unified evaluation platform further limits policy learning and systematic analysis. To address these challenges, we propose UniVTAC, a simulation-based visuo-tactile data synthesis platform that supports three commonly used visuo-tactile sensors and enables scalable and controllable generation of informative contact interactions. Based on this platform, we introduce the UniVTAC Encoder, a visuo-tactile encoder trained on large-scale simulation-synthesized data with designed supervisory signals, providing tactile-centric visuo-tactile representations for downstream manipulation tasks. In addition, we present the UniVTAC Benchmark, which consists of eight representative visuo-tactile manipulation tasks for evaluating tactile-driven policies. Experimental results show that integrating the UniVTAC Encoder improves average success rates by 17.1% on the UniVTAC Benchmark, while real-world robotic experiments further demonstrate a 25% improvement in task success. Our webpage is available at https://univtac.github.io/.

</details>


### [140] [VLA-JEPA: Enhancing Vision-Language-Action Model with Latent World Model](https://arxiv.org/abs/2602.10098)
*Jingwen Sun,Wenyao Zhang,Zekun Qi,Shaojie Ren,Zezhi Liu,Hanxin Zhu,Guangzhong Sun,Xin Jin,Zhibo Chen*

Main category: cs.RO

TL;DR: VLA-JEPA通过泄漏无关的状态预测方法，在潜在空间学习动态抽象，显著提升了视觉-语言-动作策略的性能。


<details>
  <summary>Details</summary>
Motivation: 当前基于互联网视频的视觉-语言-动作策略预训练方法容易受到外观偏差、无关运动和信息泄漏的影响，VLA-JEPA旨在通过设计避免这些问题。

Method: VLA-JEPA采用JEPA风格的预训练框架，通过目标编码器生成未来帧的潜在表示，学生路径仅观察当前帧，未来信息仅作为监督目标而非输入。该方法在潜在空间而非像素空间进行预测，从而学习到对相机运动和无关背景变化鲁棒的动态抽象。

Result: 在LIBERO、LIBERO-Plus、SimplerEnv和真实世界操作任务上的实验表明，VLA-JEPA在泛化性和鲁棒性上均优于现有方法。

Conclusion: VLA-JEPA通过引入泄漏无关的状态预测方法，显著提升了视觉-语言-动作策略的泛化能力和鲁棒性，实验结果表明其在多个任务上优于现有方法。

Abstract: Pretraining Vision-Language-Action (VLA) policies on internet-scale video is appealing, yet current latent-action objectives often learn the wrong thing: they remain anchored to pixel variation rather than action-relevant state transitions, making them vulnerable to appearance bias, nuisance motion, and information leakage. We introduce VLA-JEPA, a JEPA-style pretraining framework that sidesteps these pitfalls by design. The key idea is \emph{leakage-free state prediction}: a target encoder produces latent representations from future frames, while the student pathway sees only the current observation -- future information is used solely as supervision targets, never as input. By predicting in latent space rather than pixel space, VLA-JEPA learns dynamics abstractions that are robust to camera motion and irrelevant background changes. This yields a simple two-stage recipe -- JEPA pretraining followed by action-head fine-tuning -- without the multi-stage complexity of prior latent-action pipelines. Experiments on LIBERO, LIBERO-Plus, SimplerEnv and real-world manipulation tasks show that VLA-JEPA achieves consistent gains in generalization and robustness over existing methods.

</details>


### [141] [Robo3R: Enhancing Robotic Manipulation with Accurate Feed-Forward 3D Reconstruction](https://arxiv.org/abs/2602.10101)
*Sizhe Yang,Linning Xu,Hao Li,Juncheng Mu,Jia Zeng,Dahua Lin,Jiangmiao Pang*

Main category: cs.RO

TL;DR: Robo3R是一种实时RGB图像到3D几何的模型，通过联合推断局部几何和相机姿态，实现高精度重建，显著提升机器人操作任务性能。


<details>
  <summary>Details</summary>
Motivation: 解决现有深度传感器噪声大、材质敏感，以及重建模型缺乏物理交互所需精度和度量一致性的问题。

Method: Robo3R采用前馈模型，结合尺度不变的局部几何推断和相对相机姿态估计，通过全局相似变换统一到机器人坐标系。采用掩码点头生成精细点云，并基于关键点的PnP公式优化相机外参和全局对齐。

Result: Robo3R在合成数据集Robo3R-4M上训练，性能优于现有重建方法和深度传感器，并在模仿学习、仿真到现实迁移、抓取合成和无碰撞运动规划等任务中表现优异。

Conclusion: Robo3R展示了在机器人操作任务中作为替代3D感知模块的潜力，通过高精度重建和全局对齐，显著提升了多种下游任务的性能。

Abstract: 3D spatial perception is fundamental to generalizable robotic manipulation, yet obtaining reliable, high-quality 3D geometry remains challenging. Depth sensors suffer from noise and material sensitivity, while existing reconstruction models lack the precision and metric consistency required for physical interaction. We introduce Robo3R, a feed-forward, manipulation-ready 3D reconstruction model that predicts accurate, metric-scale scene geometry directly from RGB images and robot states in real time. Robo3R jointly infers scale-invariant local geometry and relative camera poses, which are unified into the scene representation in the canonical robot frame via a learned global similarity transformation. To meet the precision demands of manipulation, Robo3R employs a masked point head for sharp, fine-grained point clouds, and a keypoint-based Perspective-n-Point (PnP) formulation to refine camera extrinsics and global alignment. Trained on Robo3R-4M, a curated large-scale synthetic dataset with four million high-fidelity annotated frames, Robo3R consistently outperforms state-of-the-art reconstruction methods and depth sensors. Across downstream tasks including imitation learning, sim-to-real transfer, grasp synthesis, and collision-free motion planning, we observe consistent gains in performance, suggesting the promise of this alternative 3D sensing module for robotic manipulation.

</details>


### [142] [DexImit: Learning Bimanual Dexterous Manipulation from Monocular Human Videos](https://arxiv.org/abs/2602.10105)
*Juncheng Mu,Sizhe Yang,Yiming Bao,Hojin Bae,Tianming Wei,Linning Xu,Boyi Li,Huazhe Xu,Jiangmiao Pang*

Main category: cs.RO

TL;DR: DexImit是一个自动化框架，将人类操作视频转化为机器人数据，解决了数据稀缺问题。


<details>
  <summary>Details</summary>
Motivation: 解决双手机器人操作中数据稀缺问题，利用人类操作视频作为知识载体。

Method: DexImit采用四阶段生成流程：手-物体交互重建、子任务分解与双手调度、机器人轨迹合成、数据增强。

Result: DexImit能够生成大规模机器人数据，支持多样化的操作任务，如工具使用、长时程任务和精细操作。

Conclusion: DexImit通过将人类操作视频转化为机器人可用的数据，有效解决了数据稀缺问题，提升了机器人学习的泛化能力。

Abstract: Data scarcity fundamentally limits the generalization of bimanual dexterous manipulation, as real-world data collection for dexterous hands is expensive and labor-intensive. Human manipulation videos, as a direct carrier of manipulation knowledge, offer significant potential for scaling up robot learning. However, the substantial embodiment gap between human hands and robotic dexterous hands makes direct pretraining from human videos extremely challenging. To bridge this gap and unleash the potential of large-scale human manipulation video data, we propose DexImit, an automated framework that converts monocular human manipulation videos into physically plausible robot data, without any additional information. DexImit employs a four-stage generation pipeline: (1) reconstructing hand-object interactions from arbitrary viewpoints with near-metric scale; (2) performing subtask decomposition and bimanual scheduling; (3) synthesizing robot trajectories consistent with the demonstrated interactions; (4) comprehensive data augmentation for zero-shot real-world deployment. Building on these designs, DexImit can generate large-scale robot data based on human videos, either from the Internet or video generation models. DexImit is capable of handling diverse manipulation tasks, including tool use (e.g., cutting an apple), long-horizon tasks (e.g., making a beverage), and fine-grained manipulations (e.g., stacking cups).

</details>


### [143] [EgoHumanoid: Unlocking In-the-Wild Loco-Manipulation with Robot-Free Egocentric Demonstration](https://arxiv.org/abs/2602.10106)
*Modi Shi,Shijia Peng,Jin Chen,Haoran Jiang,Yinghui Li,Di Huang,Ping Luo,Hongyang Li,Li Chen*

Main category: cs.RO

TL;DR: EgoHumanoid通过人类示范与机器人数据结合，实现了人形机器人的高效移动操作，性能提升显著。


<details>
  <summary>Details</summary>
Motivation: 探索人类示范在更具挑战性的人形机器人移动操作任务中的潜力，以解决数据需求大的问题。

Method: 引入了一个系统化的对齐流程，包括硬件设计和数据处理，特别关注视角和动作对齐，以弥合人类与机器人之间的形态差异。

Result: 结合人类示范的EgoHumanoid框架在未见环境中性能提升51%，显著优于仅使用机器人数据的基线。

Conclusion: EgoHumanoid框架通过结合人类示范和少量机器人数据，成功实现了人形机器人在多样化真实环境中的移动操作任务，显著提升了性能。

Abstract: Human demonstrations offer rich environmental diversity and scale naturally, making them an appealing alternative to robot teleoperation. While this paradigm has advanced robot-arm manipulation, its potential for the more challenging, data-hungry problem of humanoid loco-manipulation remains largely unexplored. We present EgoHumanoid, the first framework to co-train a vision-language-action policy using abundant egocentric human demonstrations together with a limited amount of robot data, enabling humanoids to perform loco-manipulation across diverse real-world environments. To bridge the embodiment gap between humans and robots, including discrepancies in physical morphology and viewpoint, we introduce a systematic alignment pipeline spanning from hardware design to data processing. A portable system for scalable human data collection is developed, and we establish practical collection protocols to improve transferability. At the core of our human-to-humanoid alignment pipeline lies two key components. The view alignment reduces visual domain discrepancies caused by camera height and perspective variation. The action alignment maps human motions into a unified, kinematically feasible action space for humanoid control. Extensive real-world experiments demonstrate that incorporating robot-free egocentric data significantly outperforms robot-only baselines by 51\%, particularly in unseen environments. Our analysis further reveals which behaviors transfer effectively and the potential for scaling human data.

</details>


### [144] [ST4VLA: Spatially Guided Training for Vision-Language-Action Models](https://arxiv.org/abs/2602.10109)
*Jinhui Ye,Fangjing Wang,Ning Gao,Junqiu Yu,Yangkun Zhu,Bin Wang,Jinyu Zhang,Weiyang Jin,Yanwei Fu,Feng Zheng,Yilun Chen,Jiangmiao Pang*

Main category: cs.RO

TL;DR: ST4VLA是一个通过空间引导训练提升视觉-语言-动作模型性能的双系统框架，显著提高了机器人的任务执行能力和泛化能力。


<details>
  <summary>Details</summary>
Motivation: 现有的大规模视觉-语言模型在多模态理解方面表现出色，但在需要将指令转化为低级运动动作的具身任务中表现不足。

Method: ST4VLA采用双系统框架，包括空间接地预训练和空间引导动作后训练两个阶段，通过空间提示和空间先验对齐动作学习。

Result: ST4VLA在Google Robot和WidowX Robot上的性能分别从66.1提升至84.6和从54.7提升至73.2，并在SimplerEnv上建立了新的最先进结果。

Conclusion: ST4VLA通过空间引导训练显著提升了视觉-语言-动作模型的性能，在多个机器人平台上实现了新的最先进结果，并展示了更强的泛化能力和鲁棒性。

Abstract: Large vision-language models (VLMs) excel at multimodal understanding but fall short when extended to embodied tasks, where instructions must be transformed into low-level motor actions. We introduce ST4VLA, a dual-system Vision-Language-Action framework that leverages Spatial Guided Training to align action learning with spatial priors in VLMs. ST4VLA includes two stages: (i) spatial grounding pre-training, which equips the VLM with transferable priors via scalable point, box, and trajectory prediction from both web-scale and robot-specific data, and (ii) spatially guided action post-training, which encourages the model to produce richer spatial priors to guide action generation via spatial prompting. This design preserves spatial grounding during policy learning and promotes consistent optimization across spatial and action objectives. Empirically, ST4VLA achieves substantial improvements over vanilla VLA, with performance increasing from 66.1 -> 84.6 on Google Robot and from 54.7 -> 73.2 on WidowX Robot, establishing new state-of-the-art results on SimplerEnv. It also demonstrates stronger generalization to unseen objects and paraphrased instructions, as well as robustness to long-horizon perturbations in real-world settings. These results highlight scalable spatially guided training as a promising direction for robust, generalizable robot learning. Source code, data and models are released at https://internrobotics.github.io/internvla-m1.github.io/

</details>


### [145] [Learning Agile Quadrotor Flight in the Real World](https://arxiv.org/abs/2602.10111)
*Yunfan Ren,Zhiyuan Zhu,Jiaxu Xing,Davide Scaramuzza*

Main category: cs.RO

TL;DR: 提出无需精确建模的自适应框架，通过ATS和在线残差学习提升四旋翼敏捷飞行性能，实验验证其高效性和稳健性。


<details>
  <summary>Details</summary>
Motivation: 解决基于学习的控制器在现实环境中因模型误差和不确定性导致的性能受限问题，探索在线适应机制以提升敏捷飞行的安全性和性能。

Method: 提出自适应时间缩放（ATS）主动探索平台物理极限，并采用在线残差学习增强简单名义模型。基于学习的混合模型，进一步提出现实锚定短时域反向传播（RASH-BPTT）实现高效稳健的飞行策略更新。

Result: 实验表明，四旋翼能在约100秒飞行时间内将保守基础策略的峰值速度从1.9 m/s提升至7.3 m/s，可靠执行接近执行器饱和极限的敏捷机动。

Conclusion: 基于学习的控制器在敏捷四旋翼飞行中表现出色，但通常依赖于大量仿真训练，需要精确的系统辨识以实现有效的仿真到现实转移。然而，即使建模精确，固定策略仍易受分布外场景影响。本文提出的自适应框架无需精确系统辨识或离线仿真到现实转移，通过自适应时间缩放和在线残差学习，显著提升了飞行性能。

Abstract: Learning-based controllers have achieved impressive performance in agile quadrotor flight but typically rely on massive training in simulation, necessitating accurate system identification for effective Sim2Real transfer. However, even with precise modeling, fixed policies remain susceptible to out-of-distribution scenarios, ranging from external aerodynamic disturbances to internal hardware degradation. To ensure safety under these evolving uncertainties, such controllers are forced to operate with conservative safety margins, inherently constraining their agility outside of controlled settings. While online adaptation offers a potential remedy, safely exploring physical limits remains a critical bottleneck due to data scarcity and safety risks. To bridge this gap, we propose a self-adaptive framework that eliminates the need for precise system identification or offline Sim2Real transfer. We introduce Adaptive Temporal Scaling (ATS) to actively explore platform physical limits, and employ online residual learning to augment a simple nominal model. {Based on the learned hybrid model, we further propose Real-world Anchored Short-horizon Backpropagation Through Time (RASH-BPTT) to achieve efficient and robust in-flight policy updates. Extensive experiments demonstrate that our quadrotor reliably executes agile maneuvers near actuator saturation limits. The system evolves a conservative base policy with a peak speed of 1.9 m/s to 7.3 m/s within approximately 100 seconds of flight time. These findings underscore that real-world adaptation serves not merely to compensate for modeling errors, but as a practical mechanism for sustained performance improvement in aggressive flight regimes.

</details>


### [146] [Decoupled MPPI-Based Multi-Arm Motion Planning](https://arxiv.org/abs/2602.10114)
*Dan Evron,Elias Goldsztejn,Ronen I. Brafman*

Main category: cs.RO

TL;DR: 扩展STORM算法为MR-STORM，通过分布式处理多机器人运动规划，显著提升性能。


<details>
  <summary>Details</summary>
Motivation: 现有的基于采样的运动规划算法在多臂联合控制时扩展性差，需要改进。

Method: 扩展了STORM算法，使其以分布式方式处理多机器人，包括动态障碍物处理、运动计划前缀共享和动态优先级方案。

Result: MR-STORM在静态和动态障碍物环境下均优于现有算法。

Conclusion: MR-STORM算法在静态和动态障碍物环境下均表现出优于现有算法的性能。

Abstract: Recent advances in sampling-based motion planning algorithms for high DOF arms leverage GPUs to provide SOTA performance. These algorithms can be used to control multiple arms jointly, but this approach scales poorly. To address this, we extend STORM, a sampling-based model-predictive-control (MPC) motion planning algorithm, to handle multiple robots in a distributed fashion. First, we modify STORM to handle dynamic obstacles. Then, we let each arm compute its own motion plan prefix, which it shares with the other arms, which treat it as a dynamic obstacle. Finally, we add a dynamic priority scheme. The new algorithm, MR-STORM, demonstrates clear empirical advantages over SOTA algorithms when operating with both static and dynamic obstacles.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [147] [Probabilistic Fair Ordering of Events](https://arxiv.org/abs/2602.09148)
*Muhammad Haseeb,Jinkun Geng,Aurojit Panda,Radhika Mittal,Nirav Atre,Srinivas Narayana,Anirudh Sivaraman*

Main category: cs.NI

TL;DR: Tommy利用统计模型和社会选择理论，解决了时钟同步误差导致的公平排序问题，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 由于时钟同步存在固有缺陷，不同客户端在短时间内生成的事件可能无法可靠排序，因此需要一种能够处理这种同步误差的公平排序方法。

Method: Tommy采用了一种统计模型来比较带有噪声的时间戳，利用社会选择理论中的排名机制处理不可传递的比较问题。

Result: Tommy能够生成事件的部分排序，相比Spanner TrueTime基线方法，显著提高了公平性。

Conclusion: Tommy通过将排序问题映射到社会选择理论中的经典排名问题，提供了一种部分事件排序方法，显著提高了公平性，优于基于Spanner TrueTime的基线方法。

Abstract: A growing class of applications depends on fair ordering, where events that occur earlier should be processed before later ones. Providing such guarantees is difficult in practice because clock synchronization is inherently imperfect: events generated at different clients within a short time window may carry timestamps that cannot be reliably ordered. Rather than attempting to eliminate synchronization error, we embrace it and establish a probabilistically fair sequencing process. Tommy is a sequencer that uses a statistical model of per-clock synchronization error to compare noisy timestamps probabilistically. Although this enables ordering of two events, the probabilistic comparator is intransitive, making global ordering non-trivial. We address this challenge by mapping the sequencing problem to a classical ranking problem from social choice theory, which offers principled mechanisms for reasoning with intransitive comparisons. Using this formulation, Tommy produces a partial order of events, achieving significantly better fairness than a Spanner TrueTime-based baseline approach.

</details>


### [148] [Harvest: Adaptive Photonic Switching Schedules for Collective Communication in Scale-up Domains](https://arxiv.org/abs/2602.09188)
*Mahir Rahman,Samuel Joseph,Nihar Kodkani,Behnaz Arzani,Vamsi Addanki*

Main category: cs.NI

TL;DR: Harvest是一种系统方法，用于合成光子互连中的拓扑重新配置计划，以最小化集体完成时间。它通过动态程序和拓扑优化，平衡重新配置延迟与拥塞和传播延迟，显著优于静态和每步重新配置的基线。


<details>
  <summary>Details</summary>
Motivation: 随着芯片间硅光子学因其带宽和能效优势而受到关注，其电路交换性质引发了集体通信中互连何时及如何重新配置的基本问题。直接光路径可减少拥塞和传播延迟，但每次重新配置都会产生不可忽视的开销，使得每步重新配置变得不切实际。

Method: Harvest通过将合成问题转化为动态程序，并利用拓扑优化子问题，为任意集体通信算法生成重新配置计划。此外，通过利用递归加倍（Recursive Doubling）算法的结构，无需优化器即可合成最优重新配置计划。

Result: 通过数据包级和流级评估，以及在商用GPU上的硬件仿真，Harvest生成的计划在多种集体算法中显著减少了集体完成时间。

Conclusion: Harvest提出的方法显著减少了光子互连中集体通信的完成时间，相比静态互连和每步重新配置的基线方法，表现出更好的性能。

Abstract: As chip-to-chip silicon photonics gain traction for their bandwidth and energy efficiency, their circuit-switched nature raises a fundamental question for collective communication: when and how should the interconnect be reconfigured to realize these benefits? Establishing direct optical paths can reduce congestion and propagation delay, but each reconfiguration incurs non-negligible overhead, making naive per-step reconfiguration impractical.
  We present Harvest, a systematic approach for synthesizing topology reconfiguration schedules that minimize collective completion time in photonic interconnects. Given a collective communication algorithm and its fixed communication schedule, Harvest determines how the interconnect should evolve over the course of the collective, explicitly balancing reconfiguration delay against congestion and propagation delay. We reduce the synthesis problem into a dynamic program with an underlying topology optimization subproblem and show that the approach applies to arbitrary collective communication algorithms. Furthermore, we exploit the algorithmic structure of a well-known AllReduce algorithm (Recursive Doubling) to synthesize optimal reconfiguration schedules without using any optimizers. By parameterizing the formulation using reconfiguration delay, Harvest naturally adapts to various photonic technologies. Using packet-level and flow-level evaluations, as well as hardware emulation on commercial GPUs, we show that the schedules synthesized by Harvest significantly reduce collective completion time across multiple collective algorithms compared to static interconnects and reconfigure-every-step baselines.

</details>


### [149] [XLB: A High Performance Layer-7 Load Balancer for Microservices using eBPF-based In-kernel Interposition](https://arxiv.org/abs/2602.09473)
*Yuejie Wang,Chenchen Shou,Jiaxu Qian,Guyue Liu*

Main category: cs.NI

TL;DR: XLB是一种基于eBPF的内核级L7负载均衡架构，相比传统方案显著提升了微服务的性能和效率。


<details>
  <summary>Details</summary>
Motivation: 微服务对负载均衡器提出了更高的性能和隔离要求，传统基于sidecar的负载均衡器无法满足这些需求。

Method: 利用eBPF在内核中实现核心负载均衡逻辑，通过新颖的套接字层重定向和嵌套eBPF映射设计解决连接管理和状态维护挑战。

Result: 与广泛使用的微服务负载均衡器（Istio和Cilium）相比，XLB在50个微服务实例上实现了高达1.5倍的吞吐量提升和60%的端到端延迟降低。

Conclusion: XLB作为一种新型的L7负载均衡架构，通过内核级别的介入和eBPF技术，显著提升了性能，适用于高需求的微服务环境。

Abstract: L7 load balancers are a fundamental building block in microservices as they enable fine-grained traffic distribution. Compared to monolithic applications, microservices demand higher performance and stricter isolation from load balancers. This is due to the increased number of instances, longer service chains, and the necessity for co-location with services on the same host. Traditional sidecar-based load balancers are ill-equipped to meet these demands, often resulting in significant performance degradation.
  In this work, we present XLB, a novel architecture that reshapes L7 load balancers as in-kernel interposition operating on the socket layer. We leverage eBPF to implement the core load balancing logic in the kernel, and address the connection management and state maintenance challenges through novel socket layer redirection and nested eBPF maps designs. XLB eliminates the extra overhead of scheduling, communication, and data movement, resulting in a more lightweight, scalable, and efficient L7 load balancer architecture. Compared to the widely used microservices load balancers (Istio and Cilium), over 50 microservice instances, XLB achieves up to 1.5x higher throughput and 60% lower end-to-end latency.

</details>


### [150] [QoS Identifier and Slice Mapping in 5G and Non-Terrestrial Network Interconnected Systems](https://arxiv.org/abs/2602.09493)
*Yuma Abe,Mariko Sekiguchi,Amane Miura*

Main category: cs.NI

TL;DR: 论文提出了一种优化框架，通过引入NQI和流量分组，解决了NTN系统中5G流量管理的挑战，并通过模拟验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 现有5G QoS标识符（5QI）无法充分捕捉NTN环境中的多样化延迟、容量和可靠性需求，尤其在NTN作为回程时，难以管理大量5G流量和高效分配资源。

Method: 框架包括5QI到NQI的映射、NTN流量到NTN切片的映射，以及切片级别的流量和路由优化，并通过数值模拟评估了不同映射方案对网络性能的影响。

Result: 通过提出的优化框架，实现了对NTN系统中5G流量的高效管理和资源分配，提升了整体网络性能。

Conclusion: 论文提出了一种优化框架，通过引入NTN QoS标识符（NQI）和基于相似需求的5G流量分组，提升了非地面网络（NTN）系统中的QoS处理能力，实现了对大量5G流量的统一资源控制和路由优化。

Abstract: The interconnection of 5G and non-terrestrial networks (NTNs) has been actively studied to expand connectivity beyond conventional terrestrial infrastructure. In the 3GPP standardization of 5G systems, the 5G Quality of Service (QoS) Identifier (5QI) is defined to characterize the QoS requirements of different traffic requirements. However, it falls short in capturing the diverse latency, capacity, and reliability profiles of NTN environments, particularly when NTNs are used as backhaul. Furthermore, it is difficult to manage individual traffic flows and perform efficient resource allocation and routing when a large number of 5G traffic flows are present in NTN systems. To address these challenges, we propose an optimization framework that enhances QoS handling by introducing an NTN QoS Identifier (NQI) and grouping 5G traffic into NTN slices based on similar requirements. This enables unified resource control and routing for a large number of 5G flows in NTN systems. In this paper, we present the detailed procedure of the proposed framework, which consists of 5QI to NQI mapping, NTN traffic to NTN slice mapping, and slice-level flow and routing optimization. We evaluate the framework by comparing multiple mapping schemes through numerical simulations and analyze their impact on overall network performance.

</details>


### [151] [ISO FastLane: Faster ISO 11783 with Dual Stack Approach as a Short Term Solution](https://arxiv.org/abs/2602.09633)
*Timo Oksanen*

Main category: cs.NI

TL;DR: ISO FastLane 是一种无需更改应用层代码的双栈方案，通过以太网路由点对点 ISOBUS 流量，显著提升性能，兼容现有设备。


<details>
  <summary>Details</summary>
Motivation: 农业行业十多年来一直在寻找 ISO 11783 (ISOBUS) 250 kbit/s CAN 总线的高速替代方案，但尚未有协议级解决方案达到标准化。现代设备已受限于总线带宽。

Method: 采用无网关的双栈方法，通过简单的第 3 层路由决策和轻量级对等发现机制（AACL），将点对点 ISOBUS 流量路由到以太网，同时保留广播消息在现有 CAN 总线上。

Result: 初步测试表明，ISO FastLane 将虚拟终端对象池上传速度提高了 8 倍，任务控制器消息速率超过当前规范限制的 100 倍。

Conclusion: ISO FastLane 提供了一种无需等待长期高速 ISOBUS 解决方案的即时性能提升方法，完全基于现有的 J1939 和 ISO 11783 标准，可在几周内由 ISOBUS 工程师实现。

Abstract: The agricultural industry has been searching for a high-speed successor to the 250~kbit/s CAN bus backbone of ISO~11783 (ISOBUS) for over a decade, yet no protocol-level solution has reached standardization. Meanwhile, modern planters, sprayers, and Virtual Terminals are already constrained by the bus bandwidth. This paper presents ISO FastLane, a gateway-less dual-stack approach that routes point-to-point ISOBUS traffic over Ethernet while keeping broadcast messages on the existing CAN bus. The solution requires no new state machines, no middleware, and no changes to application layer code: only a simple Layer~3 routing decision and a lightweight peer discovery mechanism called Augmented Address Claim (AACL). Legacy devices continue to operate unmodified and unaware of FastLane traffic. Preliminary tests reported on the paper demonstrate that ISO FastLane accelerates Virtual Terminal object pool uploads by factor of 8 and sustains Task Controller message rates over 100 times beyond the current specification limit. Because ISO FastLane builds entirely on existing J1939 and ISO~11783 conventions, it can be implemented by ISOBUS engineers in a matter of weeks. This is delivering tangible performance gains today, without waiting for the long-term High Speed ISOBUS solution.

</details>


### [152] [Optimally Deployed Multistatic OTFS-ISAC Design With Kalman-Based Tracking of Targets](https://arxiv.org/abs/2602.09776)
*Jyotsna Rani,Kuntal Deka,Ganesh Prasad,Zilong Liu*

Main category: cs.NI

TL;DR: 论文研究了OTFS调制在车辆网络中的多静态ISAC应用，提出了一种结合KF的三角测量框架和接收器布局策略，显著提升了感知和通信性能。


<details>
  <summary>Details</summary>
Motivation: 研究正交时频空间（OTFS）调制辅助的多静态集成感知与通信（ISAC）在车辆网络中的应用，利用其延迟-多普勒鲁棒性来增强通信和高分辨率感知。

Method: 论文提出了一种基于三角测量的部署框架，结合卡尔曼滤波（KF），用于精确的目标定位和速度估计，并设计了一种次优的多静态接收器布局策略以减少目标定位误差。

Result: 数值结果表明，所提方法在动态环境中有效，显著降低了感知误差和误码率（BER）。

Conclusion: 该论文通过数值结果展示了在感知误差和误码率（BER）性能上的显著提升，验证了所提框架和策略的有效性。

Abstract: This paper studies orthogonal time-frequency space (OTFS) modulation aided multistatic integrated sensing and communication (ISAC) in vehicular networks, whereby its delay-Doppler robustness is exploited for enhanced communication and high-resolution sensing. We present a triangulation-based deployment framework combined with Kalman filtering (KF) that enables accurate target localization and velocity estimation. In addition, we assess the ISAC performance in the multistatic topology to determine its effectiveness in the dynamic environment. Further, a suboptimal placement strategy for the multistatic receivers is devised to reduce the targets' localization error. Numerical results demonstrate significant reductions in the sensing error and bit error rate (BER) performances.

</details>


### [153] [6G NTN Waveforms: A Comparison of OTFS, AFDM and OCDM in LEO Satellite Channels](https://arxiv.org/abs/2602.09834)
*Baidyanath Mandal,Aniruddha Chandra,Rastislav Roka,Jarosław Wojtun,Jan Kelner,Cezary Ziołkowski*

Main category: cs.NI

TL;DR: 比较了OTFS、AFDM和OCDM三种超越OFDM波形在6G NTN中的BER性能，发现AFDM和OTFS优于OCDM，AFDM在高SNR下表现最佳。


<details>
  <summary>Details</summary>
Motivation: 研究适用于6G非地面网络（NTN）的高移动性场景的超越OFDM波形性能。

Method: 使用MMSE-SD算法进行信道均衡，并在四种不同的NTN TDL模型（TDL-A、TDL-B、TDL-C、TDL-D）上比较BER性能。

Result: AFDM和OTFS在所有TDL模型中表现优于OCDM，AFDM在高SNR下的TDL-B和TDL-C中表现最佳。

Conclusion: AFDM和OTFS在所有TDL模型中表现优于OCDM，其中AFDM在高信噪比（SNR）下的TDL-B和TDL-C模型中表现最佳。

Abstract: Sixth generation (6G) physical layer (PHY) is evolving beyond the legacy orthogonal frequency division multiplexing (OFDM)-based waveforms. In this paper, we compare the bit error rate (BER) performance of three beyond-OFDM waveforms, namely, orthogonal time-frequency-space (OTFS) modulation, affine frequency division multiplexing (AFDM), and orthogonal chirp division multiplexing (OCDM), which are particularly suitable for the highly mobile non-terrestrial network (NTN) vertical of 6G. In order to characterize the effect of mobility and Doppler shift in low Earth orbit (LEO) satellites, we performed BER comparisons over four different NTN tapped-delay-line (TDL) models, TDL-A, TDL-B, TDL-C, and TDL-D, as specified in the 3rd generation partnership project (3GPP) technical report TR 38.811. After channel equalization, a minimum mean squared error with successive detection (MMSE-SD) algorithm was used to enhance the BER performance. It was found that AFDM and OTFS consistently outperformed OCDM across all TDL models, while AFDM performed better than OTFS in TDL-B and TDL-C, in the high signal-to-noise ratio (SNR) regime. The complete simulation framework is made available as an open-source code for quick validation and further development.

</details>


### [154] [Hybrid Responsible AI-Stochastic Approach for SLA Compliance in Multivendor 6G Networks](https://arxiv.org/abs/2602.09841)
*Emanuel Figetakis,Ahmed Refaey Hussein*

Main category: cs.NI

TL;DR: 混合负责AI框架在6G网络中提升公平性与责任追踪能力，实验显示显著性能提升。


<details>
  <summary>Details</summary>
Motivation: AI与6G网络自动化的融合在多供应商管理系统中带来了透明度、公平性和责任归属的新挑战，封闭循环AI编排虽提升适应性，但也导致责任缺口。

Method: 论文提出了一种混合负责AI-随机学习框架，将公平性、鲁棒性和可审计性直接嵌入网络控制循环，结合RAI游戏与随机优化，实现动态对抗重加权和跨异构供应商领域的概率探索。

Result: 实验表明，混合模型在最差组准确率上提升10.5%，WGAcc达60.5%，AvgAcc为72.7%，优于传统方法。审计机制成功追踪99%的模拟SLA违规至责任AI实体。

Conclusion: 该论文提出的混合框架在6G多供应商网络中增强了公平性、鲁棒性，并建立了具体的责任框架，为自主SLA保障提供了可行方案。

Abstract: The convergence of AI and 6G network automation introduces new challenges in maintaining transparency, fairness, and accountability across multivendor management systems. Although closed-loop AI orchestration improves adaptability and self-optimization, it also creates a responsibility gap, where violations of SLAs cannot be causally attributed to specific agents or vendors. This paper presents a hybrid responsible AI-stochastic learning framework that embeds fairness, robustness, and auditability directly into the network control loop. The framework integrates RAI games with stochastic optimization, enabling dynamic adversarial reweighting and probabilistic exploration across heterogeneous vendor domains. An RAAP continuously records AI-driven decision trajectories and produces dual accountability reports: user-level SLA summaries and operator-level responsibility analytics. Experimental evaluations on synthetic two-class multigroup datasets demonstrate that the proposed hybrid model improves the accuracy of the worst group by up to 10.5\%. Specifically, hybrid RAI achieved a WGAcc of 60.5\% and an AvgAcc of 72.7\%, outperforming traditional RAI-GA (50.0\%) and ERM (21.5\%). The audit mechanism successfully traced 99\% simulated SLA violations to the AI entities responsible, producing both vendor and agent-level accountability indices. These results confirm that the proposed hybrid approach enhances fairness and robustness as well as establishes a concrete accountability framework for autonomous SLA assurance in multivendor 6G networks.

</details>


### [155] [Tracing Data Packet Paths over the Internet using Traceroute](https://arxiv.org/abs/2602.09857)
*Thomas Dreibholz,Somnath Mazumdar*

Main category: cs.NI

TL;DR: 五年数据分析显示IP路径非确定性，受ISP和协议版本影响。


<details>
  <summary>Details</summary>
Motivation: 研究IP数据通信随时间变化的特性，从终端系统视角出发，不依赖网络运营商。

Method: 基于五年观测数据的追踪驱动分析，涵盖六大ISP、二十个自治系统和十四个国家。

Result: 用户数据包传输路径非确定性，常非最短地理路径；路由跨越多国且绕行；ISP类型和IP协议版本影响传输延迟。

Conclusion: IP数据包传输路径具有非确定性，且受ISP类型和IP协议版本影响。

Abstract: Network communication using the Internet Protocol (IP) is a pillar of modern Internet applications. IP allows data packets to travel the world through a complex set of interconnected computer networks managed by different operators. How IP-based data communication changes over time can be interesting from an end-system's perspective without relying on underlying network providers. This article presents an extensive, trace-driven analysis of user data traffic (covering five years of observations, six large Internet service providers (covering research, business and consumer category type), twenty autonomous systems, and fourteen countries.
  Our three primary findings are: i users data packet transmission paths are not deterministic and does not always select the geographically shortest path; ii) user packets take different routes that cover many countries and detour between two fixed points. Even after changing the types of Internet service provider type (e.g., from commercial to research), the routing can differ significantly between two locations. iii) Packet transmission delay can be influenced by changing the Internet service provider and IP protocol versions (i.e., from IPv4 to IPv6).

</details>


### [156] [SCOPE: A Training-Free Online 3D Deployment for UAV-BSs with Theoretical Analysis and Comparative Study](https://arxiv.org/abs/2602.09971)
*Chuan-Chi Lai*

Main category: cs.NI

TL;DR: SCOPE是一种无训练、在线的3D无人机部署框架，通过周长提取和最小包围圆算法优化部署，显著降低计算延迟并提高能源效率。


<details>
  <summary>Details</summary>
Motivation: 解决无人机基站部署在异构用户分布中的效率问题，克服现有数据驱动方法的高训练开销和泛化能力不足。

Method: 结合周长提取机制与最小包围圆算法，动态优化3D无人机位置。

Result: SCOPE在用户满意度上与DRL方法相当，但计算延迟显著降低（毫秒级 vs. 小时级训练），且能源效率更高。

Conclusion: SCOPE框架通过无训练和在线3D部署，显著降低了计算延迟并提高了能源效率，适用于实时应急部署。

Abstract: Unmanned Aerial Vehicle (UAV)-mounted Base Stations (UAV-BSs) offer a flexible solution for serving ground users in temporary hotspot scenarios. However, efficiently deploying UAV-BSs to satisfy heterogeneous user distributions remains a challenging optimization problem. While recent data-driven approaches, particularly Deep Reinforcement Learning (DRL), have shown promise in dynamic environments, they often suffer from prohibitive training overhead, poor generalization to topology changes, and high computational complexity. To address these limitations, this paper proposes Satisfaction-driven Coverage Optimization via Perimeter Extraction (SCOPE), a training-free and online 3D deployment framework. Unlike heuristic baselines that rely on fixed-altitude assumptions, SCOPE integrates a perimeter extraction mechanism with the Smallest Enclosing Circle (SEC) algorithm to dynamically optimize 3D UAV positions. Theoretically, we provide a rigorous convergence proof of the proposed algorithm and derive its polynomial time complexity of $O(N^2 \log N)$. Experimentally, we conduct a comprehensive comparative study against state-of-the-art DRL baselines (e.g., PPO). Simulation results demonstrate that SCOPE achieves comparable user satisfaction to DRL methods but significantly lower computational latency (milliseconds vs. hours of training) and superior energy efficiency, making it an ideal solution for real-time, on-demand emergency deployment.

</details>


### [157] [ORCHID: Fairness-Aware Orchestration in Mission-Critical Air-Ground Integrated Networks](https://arxiv.org/abs/2602.09994)
*Chuan-Chi Lai,Chi Jai Choy*

Main category: cs.NI

TL;DR: ORCHID是一种稳定性增强的两阶段学习框架，解决了多无人机协同中的不稳定性和能效-公平性平衡问题，实验证明其性能优越。


<details>
  <summary>Details</summary>
Motivation: 针对传统深度强化学习方法在多无人机协同中的不稳定性和能效与公平性难以平衡的问题，提出了ORCHID框架。

Method: ORCHID 采用了两阶段学习框架，包括GBS感知的拓扑分区策略和Reset-and-Finetune机制，以稳定学习过程并抑制梯度方差。

Result: 实验证明ORCHID在关键任务场景中实现了鲁棒收敛和弹性连接，且在能效和公平性上优于现有基线方法。

Conclusion: ORCHID 框架在6G空地一体化网络中展现出卓越的性能，不仅解决了多无人机协同中的稳定性问题，还在能效与服务公平性之间实现了意想不到的协同效应。

Abstract: In the era of 6G Air-Ground Integrated Networks (AGINs), Unmanned Aerial Vehicles (UAVs) are pivotal for providing on-demand wireless coverage in mission-critical environments, such as post-disaster rescue operations. However, traditional Deep Reinforcement Learning (DRL) approaches for multi-UAV orchestration often face critical challenges: instability due to the non-stationarity of multi-agent environments and the difficulty of balancing energy efficiency with service equity. To address these issues, this paper proposes ORCHID (Orchestration of Resilient Coverage via Hybrid Intelligent Deployment), a novel stability-enhanced two-stage learning framework. First, ORCHID leverages a GBS-aware topology partitioning strategy to mitigate the exploration cold-start problem. Second, we introduce a Reset-and-Finetune (R\&F) mechanism within the MAPPO architecture that stabilizes the learning process via synchronized learning rate decay and optimizer state resetting. This mechanism effectively suppresses gradient variance to prevent policy degradation, thereby ensuring algorithmic resilience in dynamic environments. Furthermore, we uncover a counter-intuitive efficiency-fairness synergy: contrary to the conventional trade-off, our results demonstrate that the proposed Max-Min Fairness (MMF) design not only guarantees service for cell-edge users but also achieves superior energy efficiency compared to Proportional Fairness (PF), which tends to converge to suboptimal greedy equilibria. Extensive experiments confirm that ORCHID occupies a superior Pareto-dominant position compared to state-of-the-art baselines, ensuring robust convergence and resilient connectivity in mission-critical scenarios.

</details>


### [158] [Resilient Topology-Aware Coordination for Dynamic 3D UAV Networks under Node Failure](https://arxiv.org/abs/2602.10029)
*Chuan-Chi Lai*

Main category: cs.NI

TL;DR: TAG-MAPPO框架通过图基特征聚合提升3D网络在节点故障下的自愈能力，显著优于传统方法。


<details>
  <summary>Details</summary>
Motivation: 解决多智能体强化学习在突发节点故障下因动态拓扑变形而表现不佳的问题。

Method: 通过图基特征聚合与残差自我状态融合机制捕捉代理间复杂依赖关系，实现快速拓扑自适应。

Result: TAG-MAPPO在稳定性和效率上均优于基线，减少冗余切换达50%，并在灾难性节点故障后15个时间步内恢复90%以上服务覆盖。

Conclusion: 该研究提出了一种拓扑感知的TAG-MAPPO框架，显著提升了3D空中-地面集成网络在节点故障下的自愈能力，为弹性6G空中网络的实现提供了坚实基础。

Abstract: In 3D Aerial-Ground Integrated Networks (AGINs), ensuring continuous service coverage under unexpected hardware failures is critical for mission-critical applications. While Multi-Agent Reinforcement Learning (MARL) has shown promise in autonomous coordination, its resilience under sudden node failures remains a challenge due to dynamic topology deformation. This paper proposes a Topology-Aware Graph MAPPO (TAG-MAPPO) framework designed to enhance system survivability through autonomous 3D spatial reconfiguration. Our framework incorporates graph-based feature aggregation with a residual ego-state fusion mechanism to capture intricate inter-agent dependencies. This architecture enables the surviving swarm to rapidly adapt its topology compared to conventional Multi-Layer Perceptron (MLP) based approaches. Extensive simulations across heterogeneous environments, ranging from interference-limited Crowded Urban to sparse Rural areas, validate the proposed approach. The results demonstrate that TAG-MAPPO consistently outperforms baselines in both stability and efficiency; specifically, it reduces redundant handoffs by up to 50 percent while maintaining a lead in energy efficiency. Most notably, the framework exhibits exceptional self-healing capabilities following a catastrophic node failure. TAG-MAPPO restores over 90 percent of the pre-failure service coverage within 15 time steps, exhibiting a significantly faster V-shaped recovery trajectory than MLP baselines. Furthermore, in dense urban scenarios, the framework achieves a post-failure Jain's Fairness Index that even surpasses its original four-UAV configuration by effectively resolving service overlaps. These findings suggest that topology-aware coordination is essential for the realization of resilient 6G aerial networks and provides a robust foundation for adaptive deployments in volatile environments.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [159] [ALPHA-PIM: Analysis of Linear Algebraic Processing for High-Performance Graph Applications on a Real Processing-In-Memory System](https://arxiv.org/abs/2602.09174)
*Marzieh Barkhordar,Alireza Tabatabaeian,Mohammad Sadrosadati,Christina Giannoula,Juan Gomez Luna,Izzat El Hajj,Onur Mutlu,Alaa R. Alameldeen*

Main category: cs.DC

TL;DR: 本文研究了在真实PIM系统上加速图处理的潜力，通过实现算法、性能分析和基线比较，提出了未来PIM硬件设计的关键改进方向。


<details>
  <summary>Details</summary>
Motivation: 大规模图数据集处理在传统CPU和GPU架构中面临数据移动瓶颈，导致性能和能效受限，PIM技术有望通过近内存计算解决这一问题。

Method: 在UPMEM的通用PIM架构上实现了代表性图算法，对其性能进行了表征并与CPU和GPU基线进行了比较。

Result: 研究发现，优化数据分区策略对性能至关重要，同时指出了当前PIM架构在指令级并行性、DMA引擎和核心间互联网络等方面的改进机会。

Conclusion: 本研究强调了在PIM架构中选择最优数据分区策略的重要性，并指出了当前PIM架构在计算、内存和通信子系统方面的关键硬件限制，为未来改进提供了方向。

Abstract: Processing large-scale graph datasets is computationally intensive and time-consuming. Processor-centric CPU and GPU architectures, commonly used for graph applications, often face bottlenecks caused by extensive data movement between the processor and memory units due to low data reuse. As a result, these applications are often memory-bound, limiting both performance and energy efficiency due to excessive data transfers. Processing-In-Memory (PIM) offers a promising approach to mitigate data movement bottlenecks by integrating computation directly within or near memory. Although several previous studies have introduced custom PIM proposals for graph processing, they do not leverage real-world PIM systems.
  This work aims to explore the capabilities and characteristics of common graph algorithms on a real-world PIM system to accelerate data-intensive graph workloads. To this end, we (1) implement representative graph algorithms on UPMEM's general-purpose PIM architecture; (2) characterize their performance and identify key bottlenecks; (3) compare results against CPU and GPU baselines; and (4) derive insights to guide future PIM hardware design.
  Our study underscores the importance of selecting optimal data partitioning strategies across PIM cores to maximize performance. Additionally, we identify critical hardware limitations in current PIM architectures and emphasize the need for future enhancements across computation, memory, and communication subsystems. Key opportunities for improvement include increasing instruction-level parallelism, developing improved DMA engines with non-blocking capabilities, and enabling direct interconnection networks among PIM cores to reduce data transfer overheads.

</details>


### [160] [LLM-CoOpt: A Co-Design and Optimization Framework for Efficient LLM Inference on Heterogeneous Platforms](https://arxiv.org/abs/2602.09323)
*Jie Kong,Wei Wang,Jiehan Zhou,Chen Yu*

Main category: cs.DC

TL;DR: LLM-CoOpt通过算法-硬件协同设计优化LLM推理，提升吞吐量和延迟，保持准确性。


<details>
  <summary>Details</summary>
Motivation: 解决LLM推理中的内存带宽瓶颈、计算冗余和长序列处理效率低下的问题。

Method: LLM-CoOpt集成了三种关键策略：Opt-KV优化KV缓存读写路径并引入FP8量化；Opt-GQA通过分组查询注意力降低计算复杂度；Opt-Pa采用分块和延迟内存映射处理长序列。

Result: 在LLaMa-13BGPTQ模型上，LLM-CoOpt将推理吞吐量提升至多13.43%，延迟降低至多16.79%，且保持模型准确性。

Conclusion: LLM-CoOpt通过算法-硬件协同设计框架显著提升了LLM推理的吞吐量和延迟，同时保持了模型准确性，为大规模语言模型的现实推理提供了高性能优化路径。

Abstract: Major challenges in LLMs inference remain frequent memory bandwidth bottlenecks, computational redundancy, and inefficiencies in long-sequence processing. To address these issues, we propose LLM-CoOpt, a comprehensive algorithmhardware co-design framework aimed at improving both throughput and latency in LLM inference. LLM-CoOpt integrates three key strategies: (1) Key-Value Cache Optimization, termed Opt-KV, which improves memory access efficiency by optimizing both KV cache write and read paths, and introduces FP8 quantization to reduce memory footprint while maintaining accuracy; (2) Grouped-Query Attention for Computational Efficiency, termed Opt-GQA, which reduces the overall computational complexity by restructuring multi-head self-attention into grouped-query attention with shared key-value projections, enabling higher throughput and lower resource consumption; (3) Paged Attention for Long- Sequence Processing, termed Opt-Pa, which adopts a two-step strategy to first segment long sequences into manageable chunks and then apply lazy memory mapping and computation, significantly reducing memory pressure and improving performance on long-context inputs.Experiments on the LLaMa-13BGPTQ model demonstrate that LLM-CoOpt increases inference throughput by up to 13.43%, reduces latency by up to 16.79%, and maintains model accuracy. These results confirm that LLM-CoOpt provides a practical, high-performance optimization path for real-world inference of large-scale language models.

</details>


### [161] [The Coordination Criterion](https://arxiv.org/abs/2602.09435)
*Joseph M. Hellerstein*

Main category: cs.DC

TL;DR: 论文提出了一个通用标准，用于判断分布式规范是否需要协调，基于异步消息传递模型中的历史扩展单调性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是确定分布式规范何时本质上需要协调，而不是由特定协议或实现策略强加的。

Method: 论文基于Lamport历史（部分有序的执行顺序）和规范定义的观察结果，提出了一个协调标准，不依赖于特定的编程语言、对象实现或协议结构。

Result: 结果表明，规范在历史扩展下相对于观察结果的单调性是无协调实现的充要条件。

Conclusion: 该论文提出了一个通用的协调标准，明确了在异步消息传递模型中，规范是否允许无协调实现的边界条件。

Abstract: When is coordination intrinsically required by a distributed specification, rather than imposed by a particular protocol or implementation strategy? We give a general answer using minimal assumptions. In an asynchronous message-passing model, we show that a specification admits a coordination-free implementation if and only if it is monotone with respect to history extension under an appropriate order on observable outcomes.
  This Coordination Criterion is stated directly over Lamport histories -- partially ordered executions under happens-before -- and specification-defined observable outcomes, without assuming any particular programming language, object implementation, or protocol structure. It yields a sharp boundary between specifications that can be implemented without coordination and those for which coordination is unavoidable. The criterion provides a uniform explanation for a range of classical results, including CAP-style impossibility, CALM-style coordination-freedom, agreement and snapshot tasks, transactional isolation levels, and invariant confluence -- all instances of the same underlying semantic phenomenon.

</details>


### [162] [It's not a lie if you don't get caught: simplifying reconfiguration in SMR through dirty logs](https://arxiv.org/abs/2602.09441)
*Allen Clement,Natacha Crooks,Neil Giridharan,Alex Shamis*

Main category: cs.DC

TL;DR: Gauss是一个重新配置引擎，通过模块化设计支持独立升级共识协议及其组件，减少全局停机时间。


<details>
  <summary>Details</summary>
Motivation: 现有共识协议很少讨论重新配置，且将成员变更与特定算法紧密耦合，导致无法独立升级组件并强制昂贵停机。模块化对生产部署的可维护性和系统演进至关重要。

Method: 引入共识协议内部日志与暴露给RSM节点的净化外部日志之间的区分，设计Gauss重新配置引擎。

Result: 在Rialo区块链上的初步评估表明，这种关注点分离使得SMR堆栈能够在一系列多样化协议实现中无缝演进。

Conclusion: Gauss通过将共识协议视为可互换模块，实现了SMR堆栈的无缝演进，支持独立升级成员资格、故障阈值和共识协议本身，且全局停机时间最小。

Abstract: Production state-machine replication (SMR) implementations are complex, multi-layered architectures comprising data dissemination, ordering, execution, and reconfiguration components. Existing research consensus protocols rarely discuss reconfiguration. Those that do tightly couple membership changes to a specific algorithm. This prevents the independent upgrade of individual building blocks and forces expensive downtime when transitioning to new protocol implementations. Instead, modularity is essential for maintainability and system evolution in production deployments. We present Gauss, a reconfiguration engine designed to treat consensus protocols as interchangeable modules. By introducing a distinction between a consensus protocol's inner log and a sanitized outer log exposed to the RSM node, Gauss allows engineers to upgrade membership, failure thresholds, and the consensus protocol itself independently and with minimal global downtime. Our initial evaluation on the Rialo blockchain shows that this separation of concerns enables a seamless evolution of the SMR stack across a sequence of diverse protocol implementations.

</details>


### [163] [High-performance Vector-length Agnostic Quantum Circuit Simulations on ARM Processors](https://arxiv.org/abs/2602.09604)
*Ruimin Shi,Gabin Schieffer,Pei-Hung Lin,Maya Gokhale,Andreas Herten,Ivy Peng*

Main category: cs.DC

TL;DR: 研究通过量子模拟验证VLA设计的高性能可移植性，提出优化技术并在多平台实现显著加速。


<details>
  <summary>Details</summary>
Motivation: 探讨在高性能处理器中，新兴向量架构（如ARM SVE和RISC-V RVV）是否能在向量长度无关设计中实现高性能可移植性。

Method: 提出VLA设计及优化技术，包括VLEN自适应内存布局调整、负载缓冲、细粒度循环控制和基于门融合的算术强度适配。

Result: 在A64FX上实现4.5倍加速，Grace上2.5倍，Graviton上1.5倍。

Conclusion: 该研究通过量子态向量模拟工作负载，验证了在向量长度无关（VLA）设计中实现高性能可移植性的可行性，并提出了一套关键优化技术。

Abstract: ARM SVE and RISC-V RVV are emerging vector architectures in high-end processors that support vectorization of flexible vector length. In this work, we leverage an important workload for quantum computing, quantum state-vector simulations, to understand whether high-performance portability can be achieved in a vector-length agnostic (VLA) design. We propose a VLA design and optimization techniques critical for achieving high performance, including VLEN-adaptive memory layout adjustment, load buffering, fine-grained loop control, and gate fusion-based arithmetic intensity adaptation. We provide an implementation in Google's Qsim and evaluate five quantum circuits of up to 36 qubits on three ARM processors, including NVIDIA Grace, AWS Graviton3, and Fujitsu A64FX. By defining new metrics and PMU events to quantify vectorization activities, we draw generic insights for future VLA designs. Our single-source implementation of VLA quantum simulations achieves up to 4.5x speedup on A64FX, 2.5x speedup on Grace, and 1.5x speedup on Graviton.

</details>


### [164] [Revealing the Challenges of Attention-FFN Disaggregation for Modern MoE Models and Hardware Systems](https://arxiv.org/abs/2602.09721)
*Guowei Liu,Hongming Li,Yaning Guo,Yongxi Lyu,Mo Zhou,Yi Liu,Zhaogeng Li,Yanpeng Wang*

Main category: cs.DC

TL;DR: AFD在特定硬件和模型组合下表现更佳，但受限于带宽和不平衡惩罚，非通用解决方案。


<details>
  <summary>Details</summary>
Motivation: 大规模MoE模型部署面临内存容量和带宽挑战，AFD作为解耦计算和内存资源的潜在架构，其性能边界尚未充分探索。

Method: 通过将roofline模型扩展到通信层面，分析互连带宽、算术强度和硬件FLOPS利用率（HFU）的关系。

Result: 分析揭示了标准集群上的死区：增加FFN实例数量无法提高HFU，因计算工作负载受限于扩展带宽；AFD的离散节点级扩展比EP的连续批次调整产生更高不平衡惩罚。但在特定条件下（如Superpod级硬件和粗粒度专家模型），AFD可能更有效。

Conclusion: AFD是一种针对特定硬件-模型组合的有前景方法，而非通用解决方案。

Abstract: Deploying large-scale MoE models presents challenges in memory capacity and bandwidth for expert activation. While Attention-FFN Disaggregation (AFD) has emerged as a potential architecture to decouple compute and memory resources, its performance boundaries compared to standard large-scale Expert Parallelism (EP) remain underexplored. In this paper, we conduct a systematic analysis of AFD by extending the roofline model to the communication level, correlating interconnect bandwidth, arithmetic intensity, and Hardware FLOPS Utilization (HFU). Our analysis reveals a dead zone on standard clusters: increasing FFN instance count fails to improve HFU as computational workload is capped by scale-out bandwidth, causing operator active time to shrink relative to the fixed latency budget. We further show that AFD's discrete node-level scaling incurs higher imbalance penalties than EP's continuous batch adjustment. Nevertheless, these limitations diminish under specific conditions: Superpod-class hardware with abundant interconnect bandwidth and models with coarse-grained experts and lower sparsity are more likely to benefit from AFD. These findings position AFD as a promising approach for specific hardware-model combinations rather than a universal solution.

</details>


### [165] [Efficient Remote Prefix Fetching with GPU-native Media ASICs](https://arxiv.org/abs/2602.09725)
*Liang Mi,Weijun Wang,Jinghan Chen,Ting Cao,Haipeng Dai,Yunxin Liu*

Main category: cs.DC

TL;DR: KVFetcher 利用 GPU 视频编解码器优化远程 KV 缓存重用，显著提升带宽受限场景下的性能，降低 TTFT 达 3.51 倍。


<details>
  <summary>Details</summary>
Motivation: 远程 KV 缓存重用在高带宽网络中表现优异，但在带宽受限场景下性能显著下降。现有解决方案通过压缩传输 KV 缓存，但解压开销抵消了重用优势。

Method: KVFetcher 采用两种技术：编解码友好的张量布局将 KV 缓存压缩为紧凑的视频格式，实现快速传输；高效的 KV 获取器以流水线方式协调传输、解码和恢复，消除资源争用并掩盖网络波动。

Result: 实验表明，KVFetcher 在保持无损精度的同时，将 TTFT 降低了最多 3.51 倍，优于现有方法。

Conclusion: KVFetcher 通过 GPU 原生视频编解码器实现了高效且广泛可部署的远程 KV 缓存重用方案，显著提升了带宽受限场景下的性能。

Abstract: Remote KV cache reuse fetches KV cache for identical contexts from remote storage, avoiding recomputation, accelerating LLM inference. While it excels in high-speed networks, its performance degrades significantly in bandwidth-limited scenarios. Recent studies address this by transmitting KV caches in compressed form, but the associated heavyweight decompression counteracts the KV reuse benefits. In this paper, we propose an efficient and widely deployable remote KV cache reuse solution that leverages GPU-native video codecs. Our system, KVFetcher, enables effective KV cache coding with two techniques. The codec-friendly tensor layout compresses the KV cache in a highly compact video format, enabling fast transmission. The efficient KV fetcher orchestrates the transmission, decoding, and restoration of compressed KV caches in an efficient pipelined manner, eliminating resource contention, masking network fluctuations, and achieving minimum time-to-first-token (TTFT). We prototype KVFetcher on diverse GPUs from high- to low-end. Experiments reveal that it reduces TTFT by up to 3.51 times while maintaining lossless accuracy, compared to SOTA methods.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [166] [The Price of Privacy For Approximating Max-CSP](https://arxiv.org/abs/2602.09273)
*Prathamesh Dharangutte,Jingcheng Liu,Pasin Manurangsi,Akbar Rafiey,Phanu Vajanopath,Zongrui Zou*

Main category: cs.DS

TL;DR: 研究差分隐私下Max-CSPs的近似算法，发现高隐私预算时算法性能受限，但对特定CSP可通过牺牲效率放宽假设。


<details>
  <summary>Details</summary>
Motivation: 研究差分隐私下Max-CSPs的近似算法，旨在分类给定隐私预算ε下的最佳近似比，并探索在保持隐私的同时优化计算效率的可能性。

Method: 通过信息论分析，研究分类了给定隐私预算ε下可能的近似比。设计了一个多项式时间算法，在实例有界度且无三角形的假设下匹配了这一界限。

Result: 在高隐私预算（ε≪1）时，任何ε-DP算法的近似比无法显著优于随机分配。对于特定CSP，移除某些假设（如无三角形或有界度）是可能的，但会降低计算效率。

Conclusion: 在差分隐私（DP）下，对于最大约束满足问题（Max-CSPs），研究展示了在高隐私预算（ε≪1）时，任何ε-DP算法的近似比无法超过随机分配超过O(ε)。对于特定CSP（如Max-Cut或Max k-XOR），可以移除某些假设（如无三角形或有界度），但会牺牲计算效率。

Abstract: We study approximation algorithms for Maximum Constraint Satisfaction Problems (Max-CSPs) under differential privacy (DP) where the constraints are considered sensitive data. Information-theoretically, we aim to classify the best approximation ratios possible for a given privacy budget $\varepsilon$. In the high-privacy regime ($\varepsilon \ll 1$), we show that any $\varepsilon$-DP algorithm cannot beat a random assignment by more than $O(\varepsilon)$ in the approximation ratio. We devise a polynomial-time algorithm which matches this barrier under the assumptions that the instances are bounded-degree and triangle-free. Finally, we show that one or both of these assumptions can be removed for specific CSPs--such as Max-Cut or Max $k$-XOR--albeit at the cost of computational efficiency.

</details>


### [167] [Beyond Vizing Chains: Improved Recourse in Dynamic Edge Coloring](https://arxiv.org/abs/2602.09497)
*Yaniv Sadeh,Haim Kaplan*

Main category: cs.DS

TL;DR: 论文提出了一种基于shift-tree的新技术，用于动态图中边着色的高效维护，实现了紧密的recourse界限并降低了颜色需求。


<details>
  <summary>Details</summary>
Motivation: 研究动态图中边着色的维护问题，特别是最小化每次边更新时的recolor次数（recourse）。

Method: 论文引入了一种称为shift-tree的对象，用于跟踪多种可能的重新着色方案，并结合其他技术，实现了多项式时间内的小recourse维护。

Result: 提出了一种确定性算法，对于大调色板（$C \ge 0.62Δ$）实现了紧密的recourse界限（$O\big( \frac{\log n}{\log \frac{Δ+C}{Δ-C}}\big)$），并在低arboricity图中进一步降低了颜色需求（$C \ge (2+ε)α- 1$）。

Conclusion: 该论文提出了一种基于shift-tree的新技术，用于在完全动态图中维护$(Δ+C)$-边着色，并实现了紧密的recourse界限。此外，该技术还适用于低arboricity图，并在现有基础上进一步降低了颜色需求。

Abstract: We study the maintenance of a $(Δ+C)$-edge-coloring ($C\ge 1$) in a fully dynamic graph $G$ with maximum degree $Δ$. We focus on minimizing \emph{recourse} which equals the number of recolored edges per edge updates.
  We present a new technique based on an object which we call a \emph{shift-tree}. This object tracks multiple possible recolorings of $G$ and enables us to maintain a proper coloring with small recourse in polynomial time. We shift colors over a path of edges, but unlike many other algorithms, we do not use \emph{fans} and \emph{alternating bicolored paths}.
  We combine the shift-tree with additional techniques to obtain an algorithm with a \emph{tight} recourse of $O\big( \frac{\log n}{\log \frac{Δ+C}{Δ-C}}\big)$ for all $C \ge 0.62Δ$ where $Δ-C = O(n^{1-δ})$. Our algorithm is the first deterministic algorithm to establish tight bounds for large palettes, and the first to do so when $Δ-C=o(Δ)$. This result settles the theoretical complexity of the recourse for large palettes. Furthermore, we believe that viewing the possible shifts as a tree can lead to similar tree-based techniques that extend to lower values of $C$, and to improved update times.
  A second application is to graphs with low arboricity $α$. Previous works [BCPS24, CRV24] achieve $O(ε^{-1}\log n)$ recourse per update with $C\ge (4+ε)α$, and we improve by achieving the same recourse while only requiring $C \ge (2+ε)α- 1$. This result is $Δ$-adaptive, i.e., it uses $Δ_t+C$ colors where $Δ_t$ is the current maximum degree.
  Trying to understand the limitations of our technique, and shift-based algorithms in general, we show a separation between the recourse achievable by algorithms that only shift colors along a path, and more general algorithms such as ones using the Nibbling Method [BGW21, BCPS24].

</details>


### [168] [Maximizing Diversity in (near-)Median String Selection](https://arxiv.org/abs/2602.10050)
*Diptarka Chakraborty,Rudrayan Kundu,Nidhi Purohit,Aravinda Kanchana Ruwanpathirana*

Main category: cs.DS

TL;DR: 研究解决了生成多个多样且近似最优的汉明中值字符串的问题，提出了精确和近似算法。


<details>
  <summary>Details</summary>
Motivation: 现代应用常需生成多个（近似）最优且多样的中值字符串，以增强决策的灵活性和鲁棒性。

Method: 研究首先针对直径变体问题引入精确算法，随后提出$(1-ε)$-近似算法（适用于任何$ε>0$）用于和分散度，以及双标准近似算法用于更复杂的极小分散度情况。

Result: 研究成功提出了精确算法和近似算法，能够生成多样且近似最优的汉明中值字符串。

Conclusion: 本研究通过引入精确算法和近似算法，解决了在汉明距离下生成多个（近似）最优且多样的中值字符串的问题，增强了决策的灵活性和鲁棒性。

Abstract: Given a set of strings over a specified alphabet, identifying a median or consensus string that minimizes the total distance to all input strings is a fundamental data aggregation problem. When the Hamming distance is considered as the underlying metric, this problem has extensive applications, ranging from bioinformatics to pattern recognition. However, modern applications often require the generation of multiple (near-)optimal yet diverse median strings to enhance flexibility and robustness in decision-making.
  In this study, we address this need by focusing on two prominent diversity measures: sum dispersion and min dispersion. We first introduce an exact algorithm for the diameter variant of the problem, which identifies pairs of near-optimal medians that are maximally diverse. Subsequently, we propose a $(1-ε)$-approximation algorithm (for any $ε>0$) for sum dispersion, as well as a bi-criteria approximation algorithm for the more challenging min dispersion case, allowing the generation of multiple (more than two) diverse near-optimal Hamming medians. Our approach primarily leverages structural insights into the Hamming median space and also draws on techniques from error-correcting code construction to establish these results.

</details>


### [169] [Beyond a Single Queue: Multi-Level-Multi-Queue as an Effective Design for SSSP problems on GPUs](https://arxiv.org/abs/2602.10080)
*Zhengding Hu,Jingwen Sun,Le Jiang,Yuhao Wang,Junqing Lin,Yi Zong,Guangzhong Sun*

Main category: cs.DS

TL;DR: MLMQ是一种新型GPU数据结构，通过多级队列和协作机制显著提升单源最短路径问题处理效率。


<details>
  <summary>Details</summary>
Motivation: 现有GPU解决方案效率低下，主要依赖单一固定队列设计，导致同步开销大、内存延迟高且适应性差。

Method: 提出了MultiLevelMultiQueue（MLMQ）数据结构，通过多级并行和内存层次结构分布多个队列，并引入了缓存式协作机制和模块化队列设计。

Result: MLMQ实现了平均1.87x至17.13x的加速比，代码已开源。

Conclusion: MLMQ设计显著提升了GPU上单源最短路径问题的处理效率，平均加速比达到1.87x至17.13x。

Abstract: As one of the most fundamental problems in graph processing, the Single-Source Shortest Path (SSSP) problem plays a critical role in numerous application scenarios. However, existing GPU-based solutions remain inefficient, as they typically rely on a single, fixed queue design that incurs severe synchronization overhead, high memory latency, and poor adaptivity to diverse inputs. To address these inefficiencies, we propose MultiLevelMultiQueue (MLMQ), a novel data structure that distributes multiple queues across the GPU's multi-level parallelism and memory hierarchy. To realize MLMQ, we introduce a cache-like collaboration mechanism for efficient inter-queue coordination, and develop a modular queue design based on unified Read and Write primitives. Within this framework, we expand the optimization space by designing a set of GPU-friendly queues, composing them across multiple levels, and further providing an input-adaptive MLMQ configuration scheme. Our MLMQ design achieves average speedups of 1.87x to 17.13x over state-of-the-art implementations. Our code is open-sourced at https://github.com/Leo9660/MLMQ.git.

</details>


<div id='cs.OS'></div>

# cs.OS [[Back]](#toc)

### [170] [AgentCgroup: Understanding and Controlling OS Resources of AI Agents](https://arxiv.org/abs/2602.09345)
*Yusheng Zheng,Jiakun Fan,Quanzhi Fu,Yiwei Yang,Wei Zhang,Andi Quinn*

Main category: cs.OS

TL;DR: 论文分析了AI编码代理的OS级资源动态，发现现有资源控制存在三个不匹配，并提出了基于eBPF的AgentCgroup解决方案，初步验证有效。


<details>
  <summary>Details</summary>
Motivation: 随着AI代理在多租户云环境中的部署增加，其工具调用的资源需求多样且波动快速，现有资源控制方法存在粒度、响应速度和适应性不匹配的问题。

Method: 论文对144个软件工程任务进行了系统性的OS级资源动态分析，使用SWE-rebench基准测试和两种LLM模型，揭示了资源使用的动态特性，并基于这些发现设计了AgentCgroup。

Result: 研究发现：(1) OS级执行占任务延迟的56-74%；(2) 内存是并发瓶颈；(3) 内存峰值与工具调用相关，峰值与平均值比高达15.4倍；(4) 资源需求在任务、运行和模型间高度不可预测。

Conclusion: 论文提出了AgentCgroup，一种基于eBPF的资源控制器，通过层次化cgroup结构、内核级监控和运行时自适应策略，解决了现有资源控制中的三个不匹配问题，初步评估显示其改善了多租户隔离并减少了资源浪费。

Abstract: AI agents are increasingly deployed in multi-tenant cloud environments, where they execute diverse tool calls within sandboxed containers, each call with distinct resource demands and rapid fluctuations. We present a systematic characterization of OS-level resource dynamics in sandboxed AI coding agents, analyzing 144 software engineering tasks from the SWE-rebench benchmark across two LLM models. Our measurements reveal that (1) OS-level execution (tool calls, container and agent initialization) accounts for 56-74% of end-to-end task latency; (2) memory, not CPU, is the concurrency bottleneck; (3) memory spikes are tool-call-driven with a up to 15.4x peak-to-average ratio; and (4) resource demands are highly unpredictable across tasks, runs, and models. Comparing these characteristics against serverless, microservice, and batch workloads, we identify three mismatches in existing resource controls: a granularity mismatch (container-level policies vs. tool-call-level dynamics), a responsiveness mismatch (user-space reaction vs. sub-second unpredictable bursts), and an adaptability mismatch (history-based prediction vs. non-deterministic stateful execution). We propose AgentCgroup , an eBPF-based resource controller that addresses these mismatches through hierarchical cgroup structures aligned with tool-call boundaries, in-kernel enforcement via sched_ext and memcg_bpf_ops, and runtime-adaptive policies driven by in-kernel monitoring. Preliminary evaluation demonstrates improved multi-tenant isolation and reduced resource waste.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [171] [A Small-Scale System for Autoregressive Program Synthesis Enabling Controlled Experimentation](https://arxiv.org/abs/2602.09112)
*Russ Webb,Jason Ramapuram*

Main category: cs.AI

TL;DR: Cadmus系统通过小型低成本模型在程序合成任务中超越GPT-5，提供透明可控的研究平台，避免LLMs的混杂因素。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型（LLMs）在程序合成研究中存在分布控制、计算成本高和透明度不足等问题，需探索小型模型的替代方案。

Method: 开发了Cadmus系统，包括整数虚拟机、多样化真实程序数据集和低成本训练的自动回归Transformer模型。

Result: Cadmus模型在特定任务（如整数算术程序完成）上表现优于GPT-5（100% vs 95%），并揭示了GPT-5因未知先验导致的推理混杂因素。

Conclusion: 小型模型如Cadmus在特定任务上能超越大型模型（如GPT-5），同时提供更高的透明度和可控性，适合需要精细控制训练分布的研究。

Abstract: What research can be pursued with small models trained to complete true programs? Typically, researchers study program synthesis via large language models (LLMs) which introduce issues such as knowing what is in or out of distribution, understanding fine-tuning effects, understanding the effects of tokenization, and higher demand on compute and storage to carry out experiments. We present a system called Cadmus which includes an integer virtual machine (VM), a dataset composed of true programs of diverse tasks, and an autoregressive transformer model that is trained for under \$200 of compute cost. The system can be used to study program completion, out-of-distribution representations, inductive reasoning, and instruction following in a setting where researchers have effective and affordable fine-grained control of the training distribution and the ability to inspect and instrument models. Smaller models working on complex reasoning tasks enable instrumentation and investigations that may be prohibitively expensive on larger models. To demonstrate that these tasks are complex enough to be of interest, we show that these Cadmus models outperform GPT-5 (by achieving 100\% accuracy while GPT-5 has 95\% accuracy) even on a simple task of completing correct, integer arithmetic programs in our domain-specific language (DSL) while providing transparency into the dataset's relationship to the problem. We also show that GPT-5 brings unknown priors into its reasoning process when solving the same tasks, demonstrating a confounding factor that prevents the use of large-scale LLMs for some investigations where the training set relationship to the task needs to be fully understood.

</details>


### [172] [Uncertainty-Aware Multimodal Emotion Recognition through Dirichlet Parameterization](https://arxiv.org/abs/2602.09121)
*Rémi Grzeczkowicz,Eric Soriano,Ali Janati,Miyu Zhang,Gerard Comas-Quiles,Victor Carballo Araruna,Aneesh Jonelagadda*

Main category: cs.AI

TL;DR: 提出一种轻量级、隐私保护的多模态情感识别框架，采用模块化设计和不确定性融合机制，在多个数据集上表现优异且高效。


<details>
  <summary>Details</summary>
Motivation: 设计一个轻量级且保护隐私的多模态情感识别框架，适用于边缘设备部署，并解决多模态不确定性融合问题。

Method: 使用三种模态（语音、文本和面部图像），每种模态通过专用骨干网络处理（Emotion2Vec、ResNet和DistilRoBERTa），并引入基于Dempster-Shafer理论和Dirichlet证据的模型和任务无关融合机制。

Result: 在五个基准数据集上验证，该方法在保持计算效率的同时达到竞争性准确率，且对模糊或缺失输入具有鲁棒性。

Conclusion: 该框架强调模块化、可扩展性和实际可行性，为医疗保健、人机交互等情感感知应用中的不确定性感知多模态系统铺平了道路。

Abstract: In this work, we present a lightweight and privacy-preserving Multimodal Emotion Recognition (MER) framework designed for deployment on edge devices. To demonstrate framework's versatility, our implementation uses three modalities - speech, text and facial imagery. However, the system is fully modular, and can be extended to support other modalities or tasks. Each modality is processed through a dedicated backbone optimized for inference efficiency: Emotion2Vec for speech, a ResNet-based model for facial expressions, and DistilRoBERTa for text. To reconcile uncertainty across modalities, we introduce a model- and task-agnostic fusion mechanism grounded in Dempster-Shafer theory and Dirichlet evidence. Operating directly on model logits, this approach captures predictive uncertainty without requiring additional training or joint distribution estimation, making it broadly applicable beyond emotion recognition. Validation on five benchmark datasets (eNTERFACE05, MEAD, MELD, RAVDESS and CREMA-D) show that our method achieves competitive accuracy while remaining computationally efficient and robust to ambiguous or missing inputs. Overall, the proposed framework emphasizes modularity, scalability, and real-world feasibility, paving the way toward uncertainty-aware multimodal systems for healthcare, human-computer interaction, and other emotion-informed applications.

</details>


### [173] [PABU: Progress-Aware Belief Update for Efficient LLM Agents](https://arxiv.org/abs/2602.09138)
*Haitao Jiang,Lin Ge,Hengrui Cai,Rui Song*

Main category: cs.AI

TL;DR: PABU框架通过选择性保留历史信息和进度预测，显著提升LLM代理的任务完成率和效率。


<details>
  <summary>Details</summary>
Motivation: 解决LLM代理因依赖完整动作-观察历史而导致的冗余行为和推理成本高的问题。

Method: 提出了Progress-Aware Belief Update (PABU)框架，通过预测相对进度并选择性保留关键历史信息来优化决策。

Result: 在AgentGym基准测试中，PABU任务完成率达到81.0%，比现有技术提升23.9%，且交互步骤减少26.9%。

Conclusion: PABU框架通过显式建模任务进度和选择性保留历史信息，显著提升了任务完成率和效率，证明了其有效性。

Abstract: Large Language Model (LLM) agents commonly condition actions on full action-observation histories, which introduce task-irrelevant information that easily leads to redundant actions and higher inference cost. We propose Progress-Aware Belief Update (PABU), a belief-state framework that compactly represents an agent's state by explicitly modeling task progress and selectively retaining past actions and observations. At each step, the agent predicts its relative progress since the previous round and decides whether the newly encountered interaction should be stored, conditioning future decisions only on the retained subset. Across eight environments in the AgentGym benchmark, and using identical training trajectories, PABU achieves an 81.0% task completion rate, outperforming previous State of the art (SoTA) models with full-history belief by 23.9%. Additionally, PABU's progress-oriented action selection improves efficiency, reducing the average number of interaction steps to 9.5, corresponding to a 26.9% reduction. Ablation studies show that both explicit progress prediction and selective retention are necessary for robust belief learning and performance gains.

</details>


### [174] [CoMMa: Contribution-Aware Medical Multi-Agents From A Game-Theoretic Perspective](https://arxiv.org/abs/2602.09159)
*Yichen Wu,Yujin Oh,Sangjoon Park,Kailong Fan,Dania Daye,Hana Farzaneh,Xiang Li,Raul Uppot,Quanzheng Li*

Main category: cs.AI

TL;DR: CoMMa是一个分散式LLM智能体框架，通过游戏理论目标协调专家，实现稳健决策，优于现有基线。


<details>
  <summary>Details</summary>
Motivation: 解决需要基于动态、异构患者数据进行推理的肿瘤学决策支持任务。

Method: CoMMa采用确定性嵌入投影来近似贡献感知的信用分配，通过估计每个智能体的边际效用实现显式证据归因。

Result: 在包括真实世界多学科肿瘤委员会数据集在内的多样肿瘤学基准测试中，CoMMa实现了更高的准确性和更稳定的性能。

Conclusion: CoMMa框架在多样化的肿瘤学基准测试中表现出更高的准确性和稳定性，优于数据集中化和基于角色的多智能体基线。

Abstract: Recent multi-agent frameworks have broadened the ability to tackle oncology decision support tasks that require reasoning over dynamic, heterogeneous patient data. We propose Contribution-Aware Medical Multi-Agents (CoMMa), a decentralized LLM-agent framework in which specialists operate on partitioned evidence and coordinate through a game-theoretic objective for robust decision-making. In contrast to most agent architectures relying on stochastic narrative-based reasoning, CoMMa utilizes deterministic embedding projections to approximate contribution-aware credit assignment. This yields explicit evidence attribution by estimating each agent's marginal utility, producing interpretable and mathematically grounded decision pathways with improved stability. Evaluated on diverse oncology benchmarks, including a real-world multidisciplinary tumor board dataset, CoMMa achieves higher accuracy and more stable performance than data-centralized and role-based multi-agents baselines.

</details>


### [175] [FlyAOC: Evaluating Agentic Ontology Curation of Drosophila Scientific Knowledge Bases](https://arxiv.org/abs/2602.09163)
*Xingjian Zhang,Sophia Moylan,Ziyang Xiong,Qiaozhu Mei,Yichen Luo,Jiaqi W. Ma*

Main category: cs.AI

TL;DR: FlyBench是一个评估AI代理从科学文献中进行端到端本体论标注的基准测试，多智能体架构表现最佳，但仍需改进。


<details>
  <summary>Details</summary>
Motivation: 科学知识库的维护需要专家进行复杂的标注工作，现有基准测试未能捕捉端到端的标注流程，因此需要一个新的基准测试来评估AI代理的完整能力。

Method: 提出了FlyBench基准测试，包含16,898篇全文论文的语料库和7,397个专家标注的基因注释，评估了四种基线代理架构（记忆、固定流程、单智能体和多智能体）。

Result: 多智能体架构表现优于其他简单架构，但所有基线仍有改进空间，代理主要利用检索确认已有知识而非发现新信息。

Conclusion: FlyBench作为一个端到端的基准测试，旨在评估AI代理在科学文献中进行本体论标注的能力，展示了多智能体架构的优势，并指出了未来在检索增强科学推理方面的研究方向。

Abstract: Scientific knowledge bases accelerate discovery by curating findings from primary literature into structured, queryable formats for both human researchers and emerging AI systems. Maintaining these resources requires expert curators to search relevant papers, reconcile evidence across documents, and produce ontology-grounded annotations - a workflow that existing benchmarks, focused on isolated subtasks like named entity recognition or relation extraction, do not capture. We present FlyBench to evaluate AI agents on end-to-end agentic ontology curation from scientific literature. Given only a gene symbol, agents must search and read from a corpus of 16,898 full-text papers to produce structured annotations: Gene Ontology terms describing function, expression patterns, and historical synonyms linking decades of nomenclature. The benchmark includes 7,397 expert-curated annotations across 100 genes drawn from FlyBase, the Drosophila (fruit fly) knowledge base. We evaluate four baseline agent architectures: memorization, fixed pipeline, single-agent, and multi-agent. We find that architectural choices significantly impact performance, with multi-agent designs outperforming simpler alternatives, yet scaling backbone models yields diminishing returns. All baselines leave substantial room for improvement. Our analysis surfaces several findings to guide future development; for example, agents primarily use retrieval to confirm parametric knowledge rather than discover new information. We hope FlyBench will drive progress on retrieval-augmented scientific reasoning, a capability with broad applications across scientific domains.

</details>


### [176] [Human Control Is the Anchor, Not the Answer: Early Divergence of Oversight in Agentic AI Communities](https://arxiv.org/abs/2602.09286)
*Hanjing Shi,Dominic DiFranzo*

Main category: cs.AI

TL;DR: 本文通过分析两个Reddit社区，展示了不同角色对AI代理监督期望的差异，提出应根据角色设计监督机制。


<details>
  <summary>Details</summary>
Motivation: 研究的动机在于探讨早期采用阶段中，不同社会技术角色对AI代理监督期望的差异。

Method: 本文采用了主题建模、共享比较空间、粗粒度监督主题抽象、参与度加权显著性以及分歧测试等方法。

Result: 研究结果显示，两个社区（r/OpenClaw和r/Moltbook）在监督期望上存在显著差异（JSD=0.418，余弦相似度=0.372，排列检验p=0.0005）。r/OpenClaw关注执行护栏和恢复（行动风险），而r/Moltbook则强调身份、合法性和公共互动中的问责（意义风险）。

Conclusion: 本文的结论是，针对不同角色的AI代理，设计与其角色相匹配的监督机制比一刀切的控制政策更为有效。

Abstract: Oversight for agentic AI is often discussed as a single goal ("human control"), yet early adoption may produce role-specific expectations. We present a comparative analysis of two newly active Reddit communities in Jan--Feb 2026 that reflect different socio-technical roles: r/OpenClaw (deployment and operations) and r/Moltbook (agent-centered social interaction). We conceptualize this period as an early-stage crystallization phase, where oversight expectations form before norms reach equilibrium.
  Using topic modeling in a shared comparison space, a coarse-grained oversight-theme abstraction, engagement-weighted salience, and divergence tests, we show the communities are strongly separable (JSD =0.418, cosine =0.372, permutation $p=0.0005$). Across both communities, "human control" is an anchor term, but its operational meaning diverges: r/OpenClaw} emphasizes execution guardrails and recovery (action-risk), while r/Moltbook} emphasizes identity, legitimacy, and accountability in public interaction (meaning-risk). The resulting distinction offers a portable lens for designing and evaluating oversight mechanisms that match agent role, rather than applying one-size-fits-all control policies.

</details>


### [177] [Measuring Dataset Diversity from a Geometric Perspective](https://arxiv.org/abs/2602.09340)
*Yang Ba,Mohammad Sadeq Abolhasani,Michelle V Mancenido,Rong Pan*

Main category: cs.AI

TL;DR: 提出基于拓扑数据分析的持久性景观多样性度量（PLDiv），弥补现有方法忽略几何结构的不足，实验验证其有效性和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有多样性度量主要关注分布变化或熵，而忽略了数据集的几何结构，因此需要一种能够捕捉几何和结构特性的新方法。

Method: 通过拓扑数据分析（TDA）和持久性景观（PLs）框架，提取和量化数据的几何特征。

Result: 实验表明，PLDiv能够有效捕捉数据集的几何多样性，并在多种模态中表现出强大的性能。

Conclusion: 本文提出的基于持久性景观（PLs）的多样性度量（PLDiv）是一种强大、可靠且可解释的工具，能够直接关联数据的多样性与底层几何结构，为数据集构建、增强和评估提供了基础性工具。

Abstract: Diversity can be broadly defined as the presence of meaningful variation across elements, which can be viewed from multiple perspectives, including statistical variation and geometric structural richness in the dataset. Existing diversity metrics, such as feature-space dispersion and metric-space magnitude, primarily capture distributional variation or entropy, while largely neglecting the geometric structure of datasets. To address this gap, we introduce a framework based on topological data analysis (TDA) and persistence landscapes (PLs) to extract and quantify geometric features from data. This approach provides a theoretically grounded means of measuring diversity beyond entropy, capturing the rich geometric and structural properties of datasets. Through extensive experiments across diverse modalities, we demonstrate that our proposed PLs-based diversity metric (PLDiv) is powerful, reliable, and interpretable, directly linking data diversity to its underlying geometry and offering a foundational tool for dataset construction, augmentation, and evaluation.

</details>


### [178] [Auditing Multi-Agent LLM Reasoning Trees Outperforms Majority Vote and LLM-as-Judge](https://arxiv.org/abs/2602.09341)
*Wei Yang,Shixuan Li,Heng Ping,Peiyu Zhang,Paul Bogdan,Jesse Thomason*

Main category: cs.AI

TL;DR: AgentAuditor通过Reasoning Tree和ACPO优化多智能体决策，显著提升准确性。


<details>
  <summary>Details</summary>
Motivation: 现有多数投票方法忽视推理痕迹的证据结构，且在共谋共识下脆弱，导致智能体因共享偏见而收敛于错误结论。

Method: AgentAuditor采用Reasoning Tree路径搜索替代多数投票，结合ACPO方法训练裁决器，以证据为基础优化少数选择。

Result: 在5种流行设置中，AgentAuditor比多数投票绝对准确率提升5%，比LLM-as-Judge提升3%。

Conclusion: AgentAuditor通过引入Reasoning Tree和ACPO方法，显著提升了多智能体系统的决策准确性，尤其在处理多数投票失败案例时表现优异。

Abstract: Multi-agent systems (MAS) can substantially extend the reasoning capacity of large language models (LLMs), yet most frameworks still aggregate agent outputs with majority voting. This heuristic discards the evidential structure of reasoning traces and is brittle under the confabulation consensus, where agents share correlated biases and converge on the same incorrect rationale. We introduce AgentAuditor, which replaces voting with a path search over a Reasoning Tree that explicitly represents agreements and divergences among agent traces. AgentAuditor resolves conflicts by comparing reasoning branches at critical divergence points, turning global adjudication into efficient, localized verification. We further propose Anti-Consensus Preference Optimization (ACPO), which trains the adjudicator on majority-failure cases and rewards evidence-based minority selections over popular errors. AgentAuditor is agnostic to MAS setting, and we find across 5 popular settings that it yields up to 5% absolute accuracy improvement over a majority vote, and up to 3% over using LLM-as-Judge.

</details>


### [179] [Not-in-Perspective: Towards Shielding Google's Perspective API Against Adversarial Negation Attacks](https://arxiv.org/abs/2602.09343)
*Michail S. Alexiou,J. Sukarno Mertoguno*

Main category: cs.AI

TL;DR: 提出了一种结合形式推理和机器学习的方法，有效提升毒性检测系统对抗否定攻击的能力。


<details>
  <summary>Details</summary>
Motivation: 社交媒体平台上网络欺凌和有毒评论的增加，需要更有效的监控和调节方式；现有基于统计的解决方案容易受到逻辑修改（如否定）的对抗攻击。

Method: 提出了一套基于形式推理的方法论，作为预处理和后处理步骤，围绕现有的机器学习毒性检测系统。

Result: 实验结果表明，混合方法在对抗否定攻击数据集上优于纯统计解决方案。

Conclusion: 混合形式推理和机器学习的方法在对抗否定攻击方面优于纯统计解决方案，显著提高了毒性检测的准确性和有效性。

Abstract: The rise of cyberbullying in social media platforms involving toxic comments has escalated the need for effective ways to monitor and moderate online interactions. Existing solutions of automated toxicity detection systems, are based on a machine or deep learning algorithms. However, statistics-based solutions are generally prone to adversarial attacks that contain logic based modifications such as negation in phrases and sentences. In that regard, we present a set of formal reasoning-based methodologies that wrap around existing machine learning toxicity detection systems. Acting as both pre-processing and post-processing steps, our formal reasoning wrapper helps alleviating the negation attack problems and significantly improves the accuracy and efficacy of toxicity scoring. We evaluate different variations of our wrapper on multiple machine learning models against a negation adversarial dataset. Experimental results highlight the improvement of hybrid (formal reasoning and machine-learning) methods against various purely statistical solutions.

</details>


### [180] [Image Quality in the Era of Artificial Intelligence](https://arxiv.org/abs/2602.09347)
*Jana G. Delfino,Jason L. Granstedt,Frank W. Samuelson,Robert Ochs,Krishna Juluru*

Main category: cs.AI

TL;DR: AI在放射学图像重建和增强中表现优异，但存在新失败模式和感知与信息脱节问题，需理解其局限性以确保安全有效使用。


<details>
  <summary>Details</summary>
Motivation: 随着AI在放射学中的快速部署，尽管其在图像重建和增强方面表现出色，但也引入了新的失败模式并可能加剧图像感知质量与信息内容之间的脱节，因此需要理解这些局限性以确保技术的安全有效使用。

Method: 本文通过分析AI在放射学图像重建和增强中的应用，探讨了其潜在失败模式和信息内容与感知质量之间的脱节问题。

Result: 本文指出AI在放射学图像处理中的局限性，并提出了如何在使用中最大化其益处同时最小化风险的建议。

Conclusion: 本文强调了在放射学中应用AI进行图像重建和增强时，了解其局限性对于安全有效使用技术的重要性，旨在帮助用户在享受技术益处的同时最小化风险。

Abstract: Artificial intelligence (AI) is being deployed within radiology at a rapid pace. AI has proven an excellent tool for reconstructing and enhancing images that appear sharper, smoother, and more detailed, can be acquired more quickly, and allowing clinicians to review them more rapidly. However, incorporation of AI also introduces new failure modes and can exacerbate the disconnect between perceived quality of an image and information content of that image. Understanding the limitations of AI-enabled image reconstruction and enhancement is critical for safe and effective use of the technology. Hence, the purpose of this communication is to bring awareness to limitations when AI is used to reconstruct or enhance a radiological image, with the goal of enabling users to reap benefits of the technology while minimizing risks.

</details>


### [181] [P1-VL: Bridging Visual Perception and Scientific Reasoning in Physics Olympiads](https://arxiv.org/abs/2602.09443)
*Yun Luo,Futing Wang,Qianjia Cheng,Fangchen Yu,Haodi Lei,Jianhao Yan,Chenxi Li,Jiacheng Chen,Yufeng Zhao,Haiyuan Wan,Yuchen Zhang,Shenghe Zheng,Junchi Yao,Qingyang Zhang,Haonan He,Wenxuan Zeng,Li Sheng,Chengxing Xie,Yuxin Zuo,Yizhuo Li,Yulun Wu,Rui Huang,Dongzhan Zhou,Kai Chen,Yu Qiao,Lei Bai,Yu Cheng,Ning Ding,Bowen Zhou,Peng Ye,Ganqu Cui*

Main category: cs.AI

TL;DR: P1-VL开源视觉语言模型通过课程强化学习和代理增强技术，在物理推理中取得突破，成为开源模型中的最先进性能。


<details>
  <summary>Details</summary>
Motivation: 解决大型语言模型在物理推理中视觉与逻辑的鸿沟，特别是在奥林匹克竞赛级别，图表包含的约束条件对推理至关重要。

Method: 结合课程强化学习和代理增强技术，P1-VL模型通过渐进难度扩展和迭代自我验证实现了先进的科学推理。

Result: P1-VL-235B-A22B在HiPhO基准测试中取得12枚金牌，成为开源视觉语言模型中的最先进性能，全球排名第二。

Conclusion: P1-VL模型通过开源方式为通用物理智能奠定了基础，显著提升了机器在科学发现中将视觉感知与抽象物理定律对齐的能力。

Abstract: The transition from symbolic manipulation to science-grade reasoning represents a pivotal frontier for Large Language Models (LLMs), with physics serving as the critical test anchor for binding abstract logic to physical reality. Physics demands that a model maintain physical consistency with the laws governing the universe, a task that fundamentally requires multimodal perception to ground abstract logic in reality. At the Olympiad level, diagrams are often constitutive rather than illustrative, containing essential constraints, such as boundary conditions and spatial symmetries, that are absent from the text. To bridge this visual-logical gap, we introduce P1-VL, a family of open-source vision-language models engineered for advanced scientific reasoning. Our method harmonizes Curriculum Reinforcement Learning, which employs progressive difficulty expansion to stabilize post-training, with Agentic Augmentation, enabling iterative self-verification at inference. Evaluated on HiPhO, a rigorous benchmark of 13 exams from 2024-2025, our flagship P1-VL-235B-A22B becomes the first open-source Vision-Language Model (VLM) to secure 12 gold medals and achieves the state-of-the-art performance in the open-source models. Our agent-augmented system achieves the No.2 overall rank globally, trailing only Gemini-3-Pro. Beyond physics, P1-VL demonstrates remarkable scientific reasoning capacity and generalizability, establishing significant leads over base models in STEM benchmarks. By open-sourcing P1-VL, we provide a foundational step toward general-purpose physical intelligence to better align visual perceptions with abstract physical laws for machine scientific discovery.

</details>


### [182] [SpotAgent: Grounding Visual Geo-localization in Large Vision-Language Models through Agentic Reasoning](https://arxiv.org/abs/2602.09463)
*Furong Jia,Ling Dai,Wenjin Deng,Fan Zhang,Chen Hu,Daxin Jiang,Yu Liu*

Main category: cs.AI

TL;DR: SpotAgent通过工具辅助验证和多阶段训练，提升了地理定位的准确性和可验证性。


<details>
  <summary>Details</summary>
Motivation: 解决大型视觉语言模型在视觉线索稀疏、长尾和高度模糊的真实场景中表现不佳的问题，避免因内部知识限制产生自信但无根据的预测。

Method: 提出SpotAgent框架，采用3阶段后训练流程：监督微调（SFT）、多智能体框架合成的轨迹进行代理冷启动、强化学习优化推理能力，并结合空间感知动态过滤策略提升效率。

Result: 在标准基准测试中，SpotAgent实现了最先进的性能，显著减少了幻觉并提供了精确且可验证的地理定位。

Conclusion: SpotAgent通过结合视觉解释与工具辅助验证，显著提升了地理定位的准确性和可验证性，有效减少了幻觉现象。

Abstract: Large Vision-Language Models (LVLMs) have demonstrated strong reasoning capabilities in geo-localization, yet they often struggle in real-world scenarios where visual cues are sparse, long-tailed, and highly ambiguous. Previous approaches, bound by internal knowledge, often fail to provide verifiable results, yielding confident but ungrounded predictions when faced with confounded evidence. To address these challenges, we propose SpotAgent, a framework that formalizes geo-localization into an agentic reasoning process that leverages expert-level reasoning to synergize visual interpretation with tool-assisted verification. SpotAgent actively explores and verifies visual cues by leveraging external tools (e.g., web search, maps) through a ReAct diagram. We introduce a 3-stage post-training pipeline starting with a Supervised Fine-Tuning (SFT) stage for basic alignment, followed by an Agentic Cold Start phase utilizing high-quality trajectories synthesized via a Multi-Agent framework, aiming to instill tool-calling expertise. Subsequently, the model's reasoning capabilities are refined through Reinforcement Learning. We propose a Spatially-Aware Dynamic Filtering strategy to enhance the efficiency of the RL stage by prioritizing learnable samples based on spatial difficulty. Extensive experiments on standard benchmarks demonstrate that SpotAgent achieves state-of-the-art performance, effectively mitigating hallucinations while delivering precise and verifiable geo-localization.

</details>


### [183] [Bridging Efficiency and Transparency: Explainable CoT Compression in Multimodal Large Reasoning Models](https://arxiv.org/abs/2602.09485)
*Yizhi Wang,Linan Yue,Min-Ling Zhang*

Main category: cs.AI

TL;DR: XMCC通过强化学习优化多模态思维链压缩，缩短推理路径并保留关键步骤，同时提供解释。


<details>
  <summary>Details</summary>
Motivation: 解决长思维链中存在的冗余推理步骤影响推理效率的问题，同时避免现有方法可能损害视觉-文本推理完整性或缺乏解释性的缺陷。

Method: XMCC将压缩建模为顺序决策过程，通过强化学习进行优化。

Result: 在代表性多模态推理基准测试中，XMCC不仅减少了推理长度，还提供了可解释的解释。

Conclusion: XMCC作为一种可解释的多模态思维链压缩器，通过强化学习优化压缩过程，有效缩短推理路径，同时保留关键推理步骤和答案正确性，并生成自然语言解释，验证了其有效性。

Abstract: Long chains of thought (Long CoTs) are widely employed in multimodal reasoning models to tackle complex tasks by capturing detailed visual information. However, these Long CoTs are often excessively lengthy and contain redundant reasoning steps, which can hinder inference efficiency. Compressing these long CoTs is a natural solution, yet existing approaches face two major challenges: (1) they may compromise the integrity of visual-textual reasoning by removing essential alignment cues, and (2) the compression process lacks explainability, making it difficult to discern which information is critical. To address these problems, we propose XMCC, an eXplainable Multimodal CoT Compressor that formulates compression as a sequential decision-making process optimized via reinforcement learning. XMCC can effectively shorten reasoning trajectories while preserving key reasoning steps and answer correctness, and simultaneously generates natural-language explanations for its compression decisions. Extensive experiments on representative multimodal reasoning benchmarks demonstrate that XMCC not only reduces reasoning length but also provides explainable explanations, validating its effectiveness.

</details>


### [184] [Computing Conditional Shapley Values Using Tabular Foundation Models](https://arxiv.org/abs/2602.09489)
*Lars Henry Berge Olsen,Dennis Christensen*

Main category: cs.AI

TL;DR: TabPFN利用上下文学习高效计算Shapley值，在多数情况下性能最优，运行时间大幅缩短。


<details>
  <summary>Details</summary>
Motivation: Shapley值是可解释AI的核心，但计算成本高，尤其在特征依赖时。传统方法需大量条件期望近似，而深度学习因需重复训练难以应用。TabPFN通过上下文学习解决了这一计算瓶颈。

Method: 使用TabPFN的多种变体计算Shapley值，并在模拟和真实数据集上与现有最优方法进行性能对比。

Result: 在大多数情况下，TabPFN表现最佳；少数情况下虽稍逊于最优方法，但运行时间显著缩短。

Conclusion: TabPFN在大多数情况下表现最佳，即使在某些情况下稍逊于最优方法，其运行时间也大幅缩短。未来可通过进一步优化表格基础模型，使其更适用于条件Shapley值估计。

Abstract: Shapley values have become a cornerstone of explainable AI, but they are computationally expensive to use, especially when features are dependent. Evaluating them requires approximating a large number of conditional expectations, either via Monte Carlo integration or regression. Until recently it has not been possible to fully exploit deep learning for the regression approach, because retraining for each conditional expectation takes too long. Tabular foundation models such as TabPFN overcome this computational hurdle by leveraging in-context learning, so each conditional expectation can be approximated without any re-training. In this paper, we compute Shapley values with multiple variants of TabPFN and compare their performance with state-of-the-art methods on both simulated and real datasets. In most cases, TabPFN yields the best performance; where it does not, it is only marginally worse than the best method, at a fraction of the runtime. We discuss further improvements and how tabular foundation models can be better adapted specifically for conditional Shapley value estimation.

</details>


### [185] [Autoregressive Direct Preference Optimization](https://arxiv.org/abs/2602.09533)
*Masanari Oi,Mahiro Ukai,Masahiro Kaneko,Naoaki Okazaki,Nakamasa Inoue*

Main category: cs.AI

TL;DR: 本文提出了ADPO，通过显式引入自回归假设改进了DPO，并首次区分了token长度和反馈长度，为LLM偏好优化提供了新视角。


<details>
  <summary>Details</summary>
Motivation: 现有的DPO方法广泛依赖响应级的Bradley-Terry模型，但其自回归假设仅在推导目标函数后引入，可能限制了其潜力。

Method: 通过重新审视DPO的理论基础，提出了一种新的公式，在应用BT模型之前显式引入自回归假设，并推导出ADPO的损失函数。

Result: ADPO的损失函数形式优雅，将求和操作移到了log-sigmoid函数外，并通过理论分析揭示了token长度和反馈长度的重要性。

Conclusion: 本文提出了一种名为Autoregressive DPO (ADPO)的新变体，通过显式引入自回归假设，改进了DPO方法，并首次区分了token长度和反馈长度两种度量，为LLM中的偏好优化提供了新的理论视角。

Abstract: Direct preference optimization (DPO) has emerged as a promising approach for aligning large language models (LLMs) with human preferences. However, the widespread reliance on the response-level Bradley-Terry (BT) model may limit its full potential, as the reference and learnable models are assumed to be autoregressive only after deriving the objective function. Motivated by this limitation, we revisit the theoretical foundations of DPO and propose a novel formulation that explicitly introduces the autoregressive assumption prior to applying the BT model. By reformulating and extending DPO, we derive a novel variant, termed Autoregressive DPO (ADPO), that explicitly integrates autoregressive modeling into the preference optimization framework. Without violating the theoretical foundations, the derived loss takes an elegant form: it shifts the summation operation in the DPO objective outside the log-sigmoid function. Furthermore, through theoretical analysis of ADPO, we show that there exist two length measures to be considered when designing DPO-based algorithms: the token length $μ$ and the feedback length $μ$'. To the best of our knowledge, we are the first to explicitly distinguish these two measures and analyze their implications for preference optimization in LLMs.

</details>


### [186] [Detecting radar targets swarms in range profiles with a partially complex-valued neural network](https://arxiv.org/abs/2602.09597)
*Martin Bauw*

Main category: cs.AI

TL;DR: 本文提出部分复数神经网络用于雷达多目标检测，实验证明其在处理目标邻近和回波失真时优于传统脉冲压缩方法。


<details>
  <summary>Details</summary>
Motivation: 雷达目标检测常受杂波、波形失真及目标邻近影响，传统方法在处理多目标时效果不佳。

Method: 提出了一种部分复数神经网络，作为自适应范围剖面处理，与传统的脉冲压缩方法进行比较。

Result: 实验表明，部分复数神经网络能一次性处理整个接收信号，生成完整的检测剖面，优于脉冲压缩方法。

Conclusion: 部分复数神经网络在雷达多目标检测中表现出色，尤其在处理目标邻近和回波失真时优于传统脉冲压缩方法。

Abstract: Correctly detecting radar targets is usually challenged by clutter and waveform distortion. An additional difficulty stems from the relative proximity of several targets, the latter being perceived as a single target in the worst case, or influencing each other's detection thresholds. The negative impact of targets proximity notably depends on the range resolution defined by the radar parameters and the adaptive threshold adopted. This paper addresses the matter of targets detection in radar range profiles containing multiple targets with varying proximity and distorted echoes. Inspired by recent contributions in the radar and signal processing literature, this work proposes partially complex-valued neural networks as an adaptive range profile processing. Simulated datasets are generated and experiments are conducted to compare a common pulse compression approach with a simple neural network partially defined by complex-valued parameters. Whereas the pulse compression processes one pulse length at a time, the neural network put forward is a generative architecture going through the entire received signal in one go to generate a complete detection profile.

</details>


### [187] [FLINGO -- Instilling ASP Expressiveness into Linear Integer Constraints](https://arxiv.org/abs/2602.09620)
*Jorge Fandinno,Pedro Cabalar,Philipp Wanko,Torsten Schaub*

Main category: cs.AI

TL;DR: FLINGO语言将ASP的表达能力融入CASP的数值约束中，并通过翻译机制实现兼容。


<details>
  <summary>Details</summary>
Motivation: 现有的CASP求解器在数值约束处理上更接近后端表达，导致ASP中的许多表达能力（如默认值、非确定性赋值等）丢失。

Method: 提出了FLINGO语言及其工具，将ASP的表达能力（如默认值、非确定性赋值等）融入数值约束，并提供了从FLINGO语法到标准CASP程序（CLINGCON格式）的翻译方法。

Result: FLINGO语言成功保留了ASP的表达能力，并通过示例展示了其应用。

Conclusion: FLINGO语言和工具成功地将ASP的表达能力融入数值约束中，并通过翻译机制将其转换为标准的CASP程序。

Abstract: Constraint Answer Set Programming (CASP) is a hybrid paradigm that enriches Answer Set Programming (ASP) with numerical constraint processing, something required in many real-world applications. The usual specification of constraints in most CASP solvers is closer to the numerical back-end expressiveness and semantics, rather than to standard specification in ASP. In the latter, numerical attributes are represented with predicates and this allows declaring default values, leaving the attribute undefined, making non-deterministic assignments with choice rules or using aggregated values. In CASP, most (if not all) of these features are lost once we switch to a constraint-based representation of those same attributes. In this paper, we present the FLINGO language (and tool) that incorporates the aforementioned expressiveness inside the numerical constraints and we illustrate its use with several examples. Based on previous work that established its semantic foundations, we also present a translation from the newly introduced FLINGO syntax to regular CASP programs following the CLINGCON input format.

</details>


### [188] [ClinAlign: Scaling Healthcare Alignment from Clinician Preference](https://arxiv.org/abs/2602.09653)
*Shiwei Lyu,Xidong Wang,Lei Liu,Hao Zhu,Chaohe Zhang,Jian Wang,Jinjie Gu,Benyou Wang,Yue Shen*

Main category: cs.AI

TL;DR: 提出两阶段框架（数据集+原则提炼）提升LLM医疗输出与临床偏好的对齐，小模型表现优于大模型。


<details>
  <summary>Details</summary>
Motivation: 现有方法依赖粗粒度目标或不可靠的自动评估，难以满足专业医疗标准的需求。

Method: 1. 构建HealthRubrics数据集（7,034个医生验证的偏好示例）；2. 提炼为HealthPrinciples（119条可复用的临床原则）；3. 应用于离线对齐和推理时自修订。

Result: 30B参数模型（仅激活3B）在HealthBench-Hard上达到33.4%，优于更大模型如Deepseek-R1和o3。

Conclusion: 提出的两阶段框架（HealthRubrics和HealthPrinciples）有效解决了LLM输出与临床医生细粒度偏好的对齐问题，显著提升了模型在医疗领域的表现。

Abstract: Although large language models (LLMs) demonstrate expert-level medical knowledge, aligning their open-ended outputs with fine-grained clinician preferences remains challenging. Existing methods often rely on coarse objectives or unreliable automated judges that are weakly grounded in professional guidelines. We propose a two-stage framework to address this gap. First, we introduce HealthRubrics, a dataset of 7,034 physician-verified preference examples in which clinicians refine LLM-drafted rubrics to meet rigorous medical standards. Second, we distill these rubrics into HealthPrinciples: 119 broadly reusable, clinically grounded principles organized by clinical dimensions, enabling scalable supervision beyond manual annotation. We use HealthPrinciples for (1) offline alignment by synthesizing rubrics for unlabeled queries and (2) an inference-time tool for guided self-revision. A 30B parameter model that activates only 3B parameters at inference trained with our framework achieves 33.4% on HealthBench-Hard, outperforming much larger models including Deepseek-R1 and o3, establishing a resource-efficient baseline for clinical alignment.

</details>


### [189] [GHS-TDA: A Synergistic Reasoning Framework Integrating Global Hypothesis Space with Topological Data Analysis](https://arxiv.org/abs/2602.09794)
*Jiaquan Zhang,Chaoning Zhang,Shuxu Chen,Xudong Wang,Zhenzhen Huang,Pengcheng Zheng,Shuai Yuan,Sheng Zheng,Qigan Sun,Jie Zou,Lik-Hang Lee,Yang Yang*

Main category: cs.AI

TL;DR: GHS-TDA通过全局假设图和拓扑数据分析改进CoT，解决了现有方法的敏感性和冗余问题，提升了推理的准确性和可解释性。


<details>
  <summary>Details</summary>
Motivation: 现有CoT方法存在两个根本性局限：推理过程对早期决策高度敏感，且缺乏全局协调和修订机制；缺乏结构化分析技术过滤冗余推理和提取关键推理特征，导致推理过程不稳定且可解释性有限。

Method: GHS-TDA首先构建语义丰富的全局假设图以聚合、对齐和协调多个候选推理路径，随后应用基于持久同调的拓扑数据分析来捕获稳定的多尺度结构，去除冗余和不一致，提取更可靠的推理骨架。

Result: GHS-TDA在多个推理基准测试中均表现出更高的准确性和鲁棒性。

Conclusion: GHS-TDA通过结合推理多样性和拓扑稳定性，实现了自适应收敛，生成了高置信度和可解释的推理路径，在多个推理基准测试中均优于现有方法。

Abstract: Chain-of-Thought (CoT) has been shown to significantly improve the reasoning accuracy of large language models (LLMs) on complex tasks. However, due to the autoregressive, step-by-step generation paradigm, existing CoT methods suffer from two fundamental limitations. First, the reasoning process is highly sensitive to early decisions: once an initial error is introduced, it tends to propagate and amplify through subsequent steps, while the lack of a global coordination and revision mechanism makes such errors difficult to correct, ultimately leading to distorted reasoning chains. Second, current CoT approaches lack structured analysis techniques for filtering redundant reasoning and extracting key reasoning features, resulting in unstable reasoning processes and limited interpretability. To address these issues, we propose GHS-TDA. GHS-TDA first constructs a semantically enriched global hypothesis graph to aggregate, align, and coordinate multiple candidate reasoning paths, thereby providing alternative global correction routes when local reasoning fails. It then applies topological data analysis based on persistent homology to capture stable multi-scale structures, remove redundancy and inconsistencies, and extract a more reliable reasoning skeleton. By jointly leveraging reasoning diversity and topological stability, GHS-TDA achieves self-adaptive convergence, produces high-confidence and interpretable reasoning paths, and consistently outperforms strong baselines in terms of both accuracy and robustness across multiple reasoning benchmarks.

</details>


### [190] [Symbolic Pattern Temporal Numeric Planning with Intermediate Conditions and Effects](https://arxiv.org/abs/2602.09798)
*Matteo Cardellini,Enrico Giunchiglia*

Main category: cs.AI

TL;DR: 扩展符号模式规划（SPP）至时间规划领域，Patty规划器在无ICEs领域表现最佳，在ICEs领域表现相当，实际应用中更优。


<details>
  <summary>Details</summary>
Motivation: 解决时间规划中动作重叠和中间条件/效果（ICEs）的复杂性问题，提升规划器的性能和适用性。

Method: 通过扩展符号模式规划（SPP）方法，将模式编码为SMT公式，并在模式不准确时逐步扩展直至找到有效计划。

Result: 实验表明Patty规划器在无ICEs的时间领域表现最佳，在ICEs领域与现有最优规划器相当，并在实际应用中表现更优。

Conclusion: SPP方法成功扩展至包含中间条件和效果（ICEs）的时间规划领域，Patty规划器在多数无ICEs的时间领域表现优异，并在ICEs领域与现有最优搜索规划器表现相当，甚至在某些实际应用场景中表现更优。

Abstract: Recently, a Symbolic Pattern Planning (SPP) approach was proposed for numeric planning where a pattern (i.e., a finite sequence of actions) suggests a causal order between actions. The pattern is then encoded in a SMT formula whose models correspond to valid plans. If the suggestion by the pattern is inaccurate and no valid plan can be found, the pattern is extended until it contains the causal order of actions in a valid plan, making the approach complete. In this paper, we extend the SPP approach to the temporal planning with Intermediate Conditions and Effects (ICEs) fragment, where $(i)$ actions are durative (and thus can overlap over time) and have conditions/effects which can be checked/applied at any time during an action's execution, and $(ii)$ one can specify plan's conditions/effects that must be checked/applied at specific times during the plan execution. Experimental results show that our SPP planner Patty $(i)$ outperforms all other planners in the literature in the majority of temporal domains without ICEs, $(ii)$ obtains comparable results with the SoTA search planner for ICS in literature domains with ICEs, and $(iii)$ outperforms the same planner in a novel domain based on a real-world application.

</details>


### [191] [Would a Large Language Model Pay Extra for a View? Inferring Willingness to Pay from Subjective Choices](https://arxiv.org/abs/2602.09802)
*Manon Reusens,Sofie Goethals,Toon Calders,David Martens*

Main category: cs.AI

TL;DR: 研究评估LLMs在主观决策中的表现，发现其能生成有意义的支付意愿值，但存在偏差且高估人类基准，需通过模型调整优化。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs在旅行助手等应用中的部署增多，研究其在无客观正确答案情境下的主观决策能力，以评估其实际应用潜力。

Method: 研究采用多项逻辑回归模型分析LLMs在旅行助手情境中的决策，推导隐含的支付意愿（WTP）估计值，并与经济学文献中的人类基准值进行比较。

Result: 研究发现，大型LLMs能生成有意义的WTP值，但存在系统性偏差且整体高估人类WTP，尤其在昂贵选项或商业导向角色下。调整模型对廉价选项的偏好后，估值更接近人类基准。

Conclusion: 研究发现，虽然大型语言模型（LLMs）能够生成有意义的主观决策支持，但在属性层面存在系统性偏差，且整体上会高估人类的支付意愿（WTP）。通过调整模型选择和提示设计，可以更接近人类基准值。

Abstract: As Large Language Models (LLMs) are increasingly deployed in applications such as travel assistance and purchasing support, they are often required to make subjective choices on behalf of users in settings where no objectively correct answer exists. We study LLM decision-making in a travel-assistant context by presenting models with choice dilemmas and analyzing their responses using multinomial logit models to derive implied willingness to pay (WTP) estimates. These WTP values are subsequently compared to human benchmark values from the economics literature. In addition to a baseline setting, we examine how model behavior changes under more realistic conditions, including the provision of information about users' past choices and persona-based prompting. Our results show that while meaningful WTP values can be derived for larger LLMs, they also display systematic deviations at the attribute level. Additionally, they tend to overestimate human WTP overall, particularly when expensive options or business-oriented personas are introduced. Conditioning models on prior preferences for cheaper options yields valuations that are closer to human benchmarks. Overall, our findings highlight both the potential and the limitations of using LLMs for subjective decision support and underscore the importance of careful model selection, prompt design, and user representation when deploying such systems in practice.

</details>


### [192] [Efficient Unsupervised Environment Design through Hierarchical Policy Representation Learning](https://arxiv.org/abs/2602.09813)
*Dexun Li,Sidney Tio,Pradeep Varakantham*

Main category: cs.AI

TL;DR: 提出分层MDP框架，通过生成模型减少师生互动需求，在资源受限场景中高效生成训练环境，实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 解决现有无监督环境设计（UED）方法在资源受限场景中因依赖无限环境生成而变得不切实际的问题。

Method: 引入了一个分层马尔可夫决策过程（MDP）框架，教师代理利用从评估环境中获取的学生策略表示来生成训练环境，并结合生成模型增强数据集以减少互动需求。

Result: 在多个领域的实验中，该方法在单次互动中表现优于基线方法，且所需师生互动更少。

Conclusion: 该论文提出了一种分层MDP框架，用于在资源受限的情况下高效生成训练环境，减少了师生互动需求，并在多个领域中验证了其优越性。

Abstract: Unsupervised Environment Design (UED) has emerged as a promising approach to developing general-purpose agents through automated curriculum generation. Popular UED methods focus on Open-Endedness, where teacher algorithms rely on stochastic processes for infinite generation of useful environments. This assumption becomes impractical in resource-constrained scenarios where teacher-student interaction opportunities are limited. To address this challenge, we introduce a hierarchical Markov Decision Process (MDP) framework for environment design. Our framework features a teacher agent that leverages student policy representations derived from discovered evaluation environments, enabling it to generate training environments based on the student's capabilities. To improve efficiency, we incorporate a generative model that augments the teacher's training dataset with synthetic data, reducing the need for teacher-student interactions. In experiments across several domains, we show that our method outperforms baseline approaches while requiring fewer teacher-student interactions in a single episode. The results suggest the applicability of our approach in settings where training opportunities are limited.

</details>


### [193] [Why Do AI Agents Systematically Fail at Cloud Root Cause Analysis?](https://arxiv.org/abs/2602.09937)
*Taeyoon Kim,Woohyeok Park,Hoyeong Yun,Kyungyong Lee*

Main category: cs.AI

TL;DR: 本文通过分析LLM-based RCA代理的失败类型，发现主要问题源于代理架构而非模型本身，提示工程效果有限，但改进通信协议可显著减少失败。


<details>
  <summary>Details</summary>
Motivation: 大规模云系统中的故障导致重大财务损失，自动化根因分析（RCA）对运营稳定性至关重要。现有系统即使使用强大模型，检测准确率仍低，且评估框架仅关注最终答案正确性，未揭示代理推理失败原因。

Method: 执行完整的OpenRCA基准测试，覆盖五个LLM模型，生成1,675次代理运行，并将观察到的失败分类为12种陷阱类型。

Result: 分析显示，最普遍的陷阱（如幻觉数据解释和不完整探索）在所有模型中均存在，表明这些失败源于共享代理架构而非个别模型限制。提示工程无法解决主要陷阱，而丰富代理间通信协议可将通信相关失败减少15个百分点。

Conclusion: 本文的pitfall分类和诊断方法为设计更可靠的云RCA自主代理奠定了基础。

Abstract: Failures in large-scale cloud systems incur substantial financial losses, making automated Root Cause Analysis (RCA) essential for operational stability. Recent efforts leverage Large Language Model (LLM) agents to automate this task, yet existing systems exhibit low detection accuracy even with capable models, and current evaluation frameworks assess only final answer correctness without revealing why the agent's reasoning failed. This paper presents a process level failure analysis of LLM-based RCA agents. We execute the full OpenRCA benchmark across five LLM models, producing 1,675 agent runs, and classify observed failures into 12 pitfall types across intra-agent reasoning, inter-agent communication, and agent-environment interaction. Our analysis reveals that the most prevalent pitfalls, notably hallucinated data interpretation and incomplete exploration, persist across all models regardless of capability tier, indicating that these failures originate from the shared agent architecture rather than from individual model limitations. Controlled mitigation experiments further show that prompt engineering alone cannot resolve the dominant pitfalls, whereas enriching the inter-agent communication protocol reduces communication-related failures by up to 15 percentage points. The pitfall taxonomy and diagnostic methodology developed in this work provide a foundation for designing more reliable autonomous agents for cloud RCA.

</details>


### [194] [Closing Reasoning Gaps in Clinical Agents with Differential Reasoning Learning](https://arxiv.org/abs/2602.09945)
*Jinsong Liu,Yuhang Jiang,Ramayya Krishnan,Rema Padman,Yiye Zhang,Jiang Bian*

Main category: cs.AI

TL;DR: DRL框架通过分析推理差异并利用检索增强生成技术，显著提升了临床决策支持的准确性和推理忠实度。


<details>
  <summary>Details</summary>
Motivation: 临床决策支持不仅需要正确答案，还需要临床有效的推理过程。现有方法在推理忠实度上存在不足，需改进。

Method: 提出差异推理学习（DRL）框架，通过图编辑距离（GED）分析推理差异，并利用LLM作为裁判对齐语义节点，最终通过检索增强生成（RAG）技术检索知识库中的指令来增强代理提示。

Result: 在开放医学问答基准和内部临床数据的RVA预测任务中，DRL框架在最终答案准确性和推理忠实度上均优于基线方法。

Conclusion: DRL框架通过学习和纠正推理差异，提升了临床决策支持系统的准确性和推理忠实度，为复杂推理场景下的可靠临床决策提供了支持。

Abstract: Clinical decision support requires not only correct answers but also clinically valid reasoning. We propose Differential Reasoning Learning (DRL), a framework that improves clinical agents by learning from reasoning discrepancies. From reference reasoning rationales (e.g., physician-authored clinical rationale, clinical guidelines, or outputs from more capable models) and the agent's free-form chain-of-thought (CoT), DRL extracts reasoning graphs as directed acyclic graphs (DAGs) and performs a clinically weighted graph edit distance (GED)-based discrepancy analysis. An LLM-as-a-judge aligns semantically equivalent nodes and diagnoses discrepancies between graphs. These graph-level discrepancy diagnostics are converted into natural-language instructions and stored in a Differential Reasoning Knowledge Base (DR-KB). At inference, we retrieve top-$k$ instructions via Retrieval-Augmented Generation (RAG) to augment the agent prompt and patch likely logic gaps. Evaluation on open medical question answering (QA) benchmarks and a Return Visit Admissions (RVA) prediction task from internal clinical data demonstrates gains over baselines, improving both final-answer accuracy and reasoning fidelity. Ablation studies confirm gains from infusing reference reasoning rationales and the top-$k$ retrieval strategy. Clinicians' review of the output provides further assurance of the approach. Together, results suggest that DRL supports more reliable clinical decision-making in complex reasoning scenarios and offers a practical mechanism for deployment under limited token budgets.

</details>


### [195] [ESTAR: Early-Stopping Token-Aware Reasoning For Efficient Inference](https://arxiv.org/abs/2602.10004)
*Junda Wang,Zhichao Yang,Dongxu Zhang,Sanjit Singh Batra,Robert E. Tillman*

Main category: cs.AI

TL;DR: ESTAR通过早期停止机制减少大型推理模型的冗余计算，提升效率且不牺牲准确性。


<details>
  <summary>Details</summary>
Motivation: 大型推理模型在生成长链式推理时存在计算冗余，尤其在正确答案已得出后仍继续推理，浪费计算资源。

Method: 结合了基于轨迹的分类器、监督微调以及带有计算感知奖励的<stop>感知强化学习，以减少推理冗余。

Result: 在四个推理数据集上，ESTAR将推理长度减少了约3.7倍（从4,799降至1,290），同时保持准确性（74.9% vs. 74.2%）。

Conclusion: ESTAR作为一种简单而强大的机制，显著提高了大型推理模型的效率，同时保持了准确性，展示了跨领域的强泛化能力。

Abstract: Large reasoning models (LRMs) achieve state-of-the-art performance by generating long chains-of-thought, but often waste computation on redundant reasoning after the correct answer has already been reached. We introduce Early-Stopping for Token-Aware Reasoning (ESTAR), which detects and reduces such reasoning redundancy to improve efficiency without sacrificing accuracy. Our method combines (i) a trajectory-based classifier that identifies when reasoning can be safely stopped, (ii) supervised fine-tuning to teach LRMs to propose self-generated <stop> signals, and (iii) <stop>-aware reinforcement learning that truncates rollouts at self-generated stop points with compute-aware rewards. Experiments on four reasoning datasets show that ESTAR reduces reasoning length by about 3.7x (from 4,799 to 1,290) while preserving accuracy (74.9% vs. 74.2%), with strong cross-domain generalization. These results highlight early stopping as a simple yet powerful mechanism for improving reasoning efficiency in LRMs.

</details>


### [196] [Discovering High Level Patterns from Simulation Traces](https://arxiv.org/abs/2602.10009)
*Sean Memery,Kartic Subr*

Main category: cs.AI

TL;DR: 论文提出了一种自然语言引导的方法，从模拟日志中提取粗粒度模式，提升了语言模型在物理任务中的表现。


<details>
  <summary>Details</summary>
Motivation: 语言模型在涉及物理的任务中表现不佳，因其物理推理能力仅从观察数据中学习，而非基于模拟。现有方法（如包含模拟轨迹作为上下文）可扩展性差。

Method: 通过合成程序操作模拟日志，并将其映射到一系列高级激活模式（如“刚体碰撞”、“稳定支撑”等）。

Result: 在两个物理基准测试中，该方法生成的模拟日志注释表示更适用于自然语言推理，并能从自然语言目标生成有效的奖励程序。

Conclusion: 论文提出了一种通过自然语言引导从详细模拟日志中发现粗粒度模式的方法，显著提升了语言模型在物理系统中的自然语言推理能力。

Abstract: Artificial intelligence (AI) agents embedded in environments with physics-based interaction face many challenges including reasoning, planning, summarization, and question answering. This problem is exacerbated when a human user wishes to either guide or interact with the agent in natural language. Although the use of Language Models (LMs) is the default choice, as an AI tool, they struggle with tasks involving physics. The LM's capability for physical reasoning is learned from observational data, rather than being grounded in simulation. A common approach is to include simulation traces as context, but this suffers from poor scalability as simulation traces contain larger volumes of fine-grained numerical and semantic data. In this paper, we propose a natural language guided method to discover coarse-grained patterns (e.g., 'rigid-body collision', 'stable support', etc.) from detailed simulation logs. Specifically, we synthesize programs that operate on simulation logs and map them to a series of high level activated patterns. We show, through two physics benchmarks, that this annotated representation of the simulation log is more amenable to natural language reasoning about physical systems. We demonstrate how this method enables LMs to generate effective reward programs from goals specified in natural language, which may be used within the context of planning or supervised learning.

</details>


### [197] [Chain of Mindset: Reasoning with Adaptive Cognitive Modes](https://arxiv.org/abs/2602.10063)
*Tianyi Jiang,Arctanx An,Hengyi Feng,Naixin Zhai,Haodong Li,Xiaomin Yu,Jiahui Liu,Hanwen Du,Shuo Zhang,Zhi Yang,Jie Huang,Yuhua Li,Yongxin Ni,Huacan Wang,Ronghao Chen*

Main category: cs.AI

TL;DR: CoM 是一种无需训练的代理框架，通过动态协调四种思维方式提升LLM推理能力，在多个任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有LLM推理方法固定使用单一思维方式，忽略了不同问题解决阶段需要不同思维方式，限制了模型的智能水平。

Method: CoM 将推理过程分解为四种功能异构的思维方式：空间、收敛、发散和算法，并通过Meta-Agent动态选择最优思维方式，同时使用双向上下文门过滤跨模块信息流。

Result: 在六个挑战性基准测试中，CoM 在 Qwen3-VL-32B-Instruct 和 Gemini-2.0-Flash 上分别以4.96%和4.72%的准确率优势超越了最强基线模型。

Conclusion: Chain of Mindset (CoM) 框架通过动态选择和协调四种不同的思维方式，显著提升了LLM在复杂任务中的表现，并在多个基准测试中实现了最先进的性能。

Abstract: Human problem-solving is never the repetition of a single mindset, by which we mean a distinct mode of cognitive processing. When tackling a specific task, we do not rely on a single mindset; instead, we integrate multiple mindsets within the single solution process. However, existing LLM reasoning methods fall into a common trap: they apply the same fixed mindset across all steps, overlooking that different stages of solving the same problem require fundamentally different mindsets. This single-minded assumption prevents models from reaching the next level of intelligence. To address this limitation, we propose Chain of Mindset (CoM), a training-free agentic framework that enables step-level adaptive mindset orchestration. CoM decomposes reasoning into four functionally heterogeneous mindsets: Spatial, Convergent, Divergent, and Algorithmic. A Meta-Agent dynamically selects the optimal mindset based on the evolving reasoning state, while a bidirectional Context Gate filters cross-module information flow to maintain effectiveness and efficiency. Experiments across six challenging benchmarks spanning mathematics, code generation, scientific QA, and spatial reasoning demonstrate that CoM achieves state-of-the-art performance, outperforming the strongest baseline by 4.96\% and 4.72\% in overall accuracy on Qwen3-VL-32B-Instruct and Gemini-2.0-Flash, while balancing reasoning efficiency. Our code is publicly available at \href{https://github.com/QuantaAlpha/chain-of-mindset}{https://github.com/QuantaAlpha/chain-of-mindset}.

</details>


### [198] [CODE-SHARP: Continuous Open-ended Discovery and Evolution of Skills as Hierarchical Reward Programs](https://arxiv.org/abs/2602.10085)
*Richard Bornemann,Pierluigi Vito Amadori,Antoine Cully*

Main category: cs.AI

TL;DR: CODE-SHARP框架利用基础模型自动化生成奖励函数，使智能体在开放技能发现和复杂任务中表现卓越。


<details>
  <summary>Details</summary>
Motivation: 解决强化学习在开放技能发现中依赖手工设计奖励函数的局限性，实现无需预先定义任务的自动化奖励设计。

Method: 引入Continuous Open-ended Discovery and Evolution of Skills as Hierarchical Reward Programs (CODE-SHARP)框架，利用基础模型开放性地扩展和精炼分层技能存档，结构化为可执行奖励函数的代码有向图。

Result: 在Craftax环境中，经过CODE-SHARP训练的智能体能够解决日益长视野的目标，且在复杂任务中平均表现优于预训练代理和任务特定专家策略134%以上。

Conclusion: CODE-SHARP框架通过利用基础模型开放性地扩展和精炼分层技能存档，显著提升了智能体在复杂、长视野任务中的表现，超越了预训练代理和任务特定专家策略。

Abstract: Developing agents capable of open-endedly discovering and learning novel skills is a grand challenge in Artificial Intelligence. While reinforcement learning offers a powerful framework for training agents to master complex skills, it typically relies on hand-designed reward functions. This is infeasible for open-ended skill discovery, where the set of meaningful skills is not known a priori. While recent methods have shown promising results towards automating reward function design, they remain limited to refining rewards for pre-defined tasks. To address this limitation, we introduce Continuous Open-ended Discovery and Evolution of Skills as Hierarchical Reward Programs (CODE-SHARP), a novel framework leveraging Foundation Models (FM) to open-endedly expand and refine a hierarchical skill archive, structured as a directed graph of executable reward functions in code. We show that a goal-conditioned agent trained exclusively on the rewards generated by the discovered SHARP skills learns to solve increasingly long-horizon goals in the Craftax environment. When composed by a high-level FM-based planner, the discovered skills enable a single goal-conditioned agent to solve complex, long-horizon tasks, outperforming both pretrained agents and task-specific expert policies by over $134$% on average. We will open-source our code and provide additional videos $\href{https://sites.google.com/view/code-sharp/homepage}{here}$.

</details>


### [199] [Agent World Model: Infinity Synthetic Environments for Agentic Reinforcement Learning](https://arxiv.org/abs/2602.10090)
*Zhaoyang Wang,Canwen Xu,Boyi Liu,Yite Wang,Siwei Han,Zhewei Yao,Huaxiu Yao,Yuxiong He*

Main category: cs.AI

TL;DR: AWM是一个合成环境生成管道，支持高效、可靠的多轮工具使用代理训练，显著提升泛化能力。


<details>
  <summary>Details</summary>
Motivation: 大规模语言模型（LLM）驱动的自主代理在多轮交互任务中表现受限，主要由于缺乏多样且可靠的环境。

Method: 提出了AWM，一个全合成环境生成管道，能够生成1000个涵盖日常场景的环境，每个环境平均配备35种工具，并通过代码驱动和数据库支持确保状态转换的可靠性。

Result: 实验表明，在合成环境中训练的代理在三个基准测试中表现出强大的分布外泛化能力。

Conclusion: AWM（Agent World Model）通过全合成环境生成管道，显著提升了多轮工具使用代理的训练效率和泛化能力，证明了合成环境在强化学习中的有效性。

Abstract: Recent advances in large language model (LLM) have empowered autonomous agents to perform complex tasks that require multi-turn interactions with tools and environments. However, scaling such agent training is limited by the lack of diverse and reliable environments. In this paper, we propose Agent World Model (AWM), a fully synthetic environment generation pipeline. Using this pipeline, we scale to 1,000 environments covering everyday scenarios, in which agents can interact with rich toolsets (35 tools per environment on average) and obtain high-quality observations. Notably, these environments are code-driven and backed by databases, providing more reliable and consistent state transitions than environments simulated by LLMs. Moreover, they enable more efficient agent interaction compared with collecting trajectories from realistic environments. To demonstrate the effectiveness of this resource, we perform large-scale reinforcement learning for multi-turn tool-use agents. Thanks to the fully executable environments and accessible database states, we can also design reliable reward functions. Experiments on three benchmarks show that training exclusively in synthetic environments, rather than benchmark-specific ones, yields strong out-of-distribution generalization. The code is available at https://github.com/Snowflake-Labs/agent-world-model.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [200] [RuleFlow : Generating Reusable Program Optimizations with LLMs](https://arxiv.org/abs/2602.09051)
*Avaljot Singh,Dushyant Bharadwaj,Stefanos Baziotis,Kaushik Varadharajan,Charith Mendis*

Main category: cs.SE

TL;DR: RuleFlow 通过三阶段方法优化 Pandas 程序，性能显著优于现有 SOTA。


<details>
  <summary>Details</summary>
Motivation: 现有系统或编译器方法要么笨重，要么优化有限；而基于 LLM 的方法虽然能合成非平凡优化，但不可靠、成本高且产出低。

Method: 采用三阶段方法：1) 发现每个程序的优化；2) 将优化转化为通用重写规则；3) 将规则集成到编译器中自动应用。

Result: 在 PandasBench 上，RuleFlow 比之前的编译器 SOTA（Dias）快 4.3 倍，比系统 SOTA（Modin）快 1914.9 倍。

Conclusion: RuleFlow 是一种新型的 Pandas 优化框架，通过三阶段方法（发现、桥接、部署）实现了显著的性能提升，成为 PandasBench 上的新 SOTA。

Abstract: Optimizing Pandas programs is a challenging problem. Existing systems and compiler-based approaches offer reliability but are either heavyweight or support only a limited set of optimizations. Conversely, using LLMs in a per-program optimization methodology can synthesize nontrivial optimizations, but is unreliable, expensive, and offers a low yield. In this work, we introduce a hybrid approach that works in a 3-stage manner that decouples discovery from deployment and connects them via a novel bridge. First, it discovers per-program optimizations (discovery). Second, they are converted into generalised rewrite rules (bridge). Finally, these rules are incorporated into a compiler that can automatically apply them wherever applicable, eliminating repeated reliance on LLMs (deployment). We demonstrate that RuleFlow is the new state-of-the-art (SOTA) Pandas optimization framework on PandasBench, a challenging Pandas benchmark consisting of Python notebooks. Across these notebooks, we achieve a speedup of up to 4.3x over Dias, the previous compiler-based SOTA, and 1914.9x over Modin, the previous systems-based SOTA.
  Our code is available at https://github.com/ADAPT-uiuc/RuleFlow.

</details>


### [201] [Predicting Open Source Software Sustainability with Deep Temporal Neural Hierarchical Architectures and Explainable AI](https://arxiv.org/abs/2602.09064)
*S M Rakib Ul Karim,Wenyi Lu,Enock Kasaadha,Sean Goggins*

Main category: cs.SE

TL;DR: 论文提出一个分层预测框架，结合多维度指标和可解释AI，准确分类开源软件项目的生命周期阶段，强调社区参与和贡献活动的重要性。


<details>
  <summary>Details</summary>
Motivation: 理解开源软件项目的生命周期轨迹对评估项目组织和健康状况至关重要，但现有方法多依赖静态或聚合指标，无法全面反映可持续性的动态发展。

Method: 论文采用了一种结合工程化表格指标和24个月时间序列活动的多阶段分类管道，并应用可解释AI技术分析特征类别对预测的贡献。

Result: 在大量开源仓库上的评估显示，该框架在生命周期阶段分类上的总体准确率超过94%，贡献活动和社区相关特征被识别为主导信号。

Conclusion: 该论文提出的分层预测框架能够有效识别开源软件项目的生命周期阶段，准确率超过94%，强调了贡献活动和社区参与动态在项目可持续性中的核心作用。

Abstract: Open Source Software (OSS) projects follow diverse lifecycle trajectories shaped by evolving patterns of contribution, coordination, and community engagement. Understanding these trajectories is essential for stakeholders seeking to assess project organization and health at scale. However, prior work has largely relied on static or aggregated metrics, such as project age or cumulative activity, providing limited insight into how OSS sustainability unfolds over time. In this paper, we propose a hierarchical predictive framework that models OSS projects as belonging to distinct lifecycle stages grounded in established socio-technical categorizations of OSS development. Rather than treating sustainability solely as project longevity, these lifecycle stages operationalize sustainability as a multidimensional construct integrating contribution activity, community participation, and maintenance dynamics. The framework combines engineered tabular indicators with 24-month temporal activity sequences and employs a multi-stage classification pipeline to distinguish lifecycle stages associated with different coordination and participation regimes. To support transparency, we incorporate explainable AI techniques to examine the relative contribution of feature categories to model predictions. Evaluated on a large corpus of OSS repositories, the proposed approach achieves over 94\% overall accuracy in lifecycle stage classification. Attribution analyses consistently identify contribution activity and community-related features as dominant signals, highlighting the central role of collective participation dynamics.

</details>


### [202] [DRAGON: Robust Classification for Very Large Collections of Software Repositories](https://arxiv.org/abs/2602.09071)
*Stefano Balla,Stefano Zacchiroli,Thomas Degueule,Jean-Rémy Falleri,Romain Robbes*

Main category: cs.SE

TL;DR: DRAGON 是一种基于轻量级信号的大规模软件仓库分类器，性能优于现有方法，且对 README 缺失具有鲁棒性。


<details>
  <summary>Details</summary>
Motivation: 现有方法过于依赖 README 文件等元数据，而这些数据在实际大规模场景中常缺失，限制了其适用性。

Method: DRAGON 仅依赖版本控制系统中常见的轻量级信号（如文件和目录名称，以及可选的 README 文件）进行分类。

Result: 在仓库分类任务中，DRAGON 将 F1@5 从 54.8% 提升至 60.8%，且在没有 README 时性能仅下降 6%。

Conclusion: DRAGON 是一种适用于大规模软件仓库分类的鲁棒性方法，即使在缺乏 README 文件的情况下仍能保持较高性能，且预测标签语义接近正确主题，提升了实际应用价值。

Abstract: The ability to automatically classify source code repositories with ''topics'' that reflect their content and purpose is very useful, especially when navigating or searching through large software collections. However, existing approaches often rely heavily on README files and other metadata, which are frequently missing, limiting their applicability in real-world large-scale settings. We present DRAGON, a repository classifier designed for very large and diverse software collections. It operates entirely on lightweight signals commonly stored in version control systems: file and directory names, and optionally the README when available. In repository classification at scale, DRAGON improves F1@5 from 54.8% to 60.8%, surpassing the state of the art. DRAGON remains effective even when README files are absent, with performance degrading by only 6% w.r.t. when they are present. This robustness makes it practical for real-world settings where documentation is sparse or inconsistent. Furthermore, many of the remaining classification errors are near misses, where predicted labels are semantically close to the correct topics. This property increases the practical value of the predictions in real-world software collections, where suggesting a few related topics can still guide search and discovery. As a byproduct of developing DRAGON, we also release the largest open dataset to date for repository classification, consisting of 825 thousand repositories with associated ground-truth topics, sourced from the Software Heritage archive, providing a foundation for future large-scale and language-agnostic research on software repository understanding.

</details>


### [203] [AIDev: Studying AI Coding Agents on GitHub](https://arxiv.org/abs/2602.09185)
*Hao Li,Haoxiang Zhang,Ahmed E. Hassan*

Main category: cs.SE

TL;DR: AIDev是一个大规模数据集，收集了五种AI编码代理在GitHub上的拉取请求，为研究AI在软件工程中的应用提供了基础。


<details>
  <summary>Details</summary>
Motivation: 尽管AI编码代理在软件工程中的作用日益显著，但研究社区缺乏关于这些代理在现实项目中如何使用的全面数据集。

Method: 通过收集和分析来自GitHub的932,791个由五种AI代理（OpenAI Codex、Devin、GitHub Copilot、Cursor和Claude Code）生成的拉取请求（Agentic-PRs），构建了AIDev数据集。

Result: AIDev数据集包含932,791个Agentic-PRs，覆盖116,211个仓库和72,189名开发者，并提供了一个精选子集（33,596个Agentic-PRs），包含评论、审查、提交和相关问题等详细信息。

Conclusion: AIDev数据集为研究AI编码代理在现实项目中的使用提供了全面的基础，有助于未来在AI采用、开发者生产力和人机协作方面的研究。

Abstract: AI coding agents are rapidly transforming software engineering by performing tasks such as feature development, debugging, and testing. Despite their growing impact, the research community lacks a comprehensive dataset capturing how these agents are used in real-world projects. To address this gap, we introduce AIDev, a large-scale dataset focused on agent-authored pull requests (Agentic-PRs) in real-world GitHub repositories. AIDev aggregates 932,791 Agentic-PRs produced by five agents: OpenAI Codex, Devin, GitHub Copilot, Cursor, and Claude Code. These PRs span 116,211 repositories and involve 72,189 developers. In addition, AIDev includes a curated subset of 33,596 Agentic-PRs from 2,807 repositories with over 100 stars, providing further information such as comments, reviews, commits, and related issues. This dataset offers a foundation for future research on AI adoption, developer productivity, and human-AI collaboration in the new era of software engineering.
  > AI Agent, Agentic AI, Coding Agent, Agentic Coding, Agentic Software Engineering, Agentic Engineering

</details>


### [204] [Towards an OSF-based Registered Report Template for Software Engineering Controlled Experiments](https://arxiv.org/abs/2602.09292)
*Ana B. M. Bett,Thais S. Nepomuceno,Edson OliveiraJr,Maria Teresa Baldassarre,Valdemar V. Graciano Neto,Marcos Kalinowski*

Main category: cs.SE

TL;DR: 本文探讨了在软件工程受控实验中采用注册报告（RR）的初步成果，发现现有OSF RR模板无法完全满足指南要求，建议制定SE特定RR指南。


<details>
  <summary>Details</summary>
Motivation: 解决受控实验描述缺乏严谨性导致的再现性和透明度问题，通过RR机制（如预先注册假设、方法和分析）来减少问题实践（如p-hacking、发表偏倚）。

Method: 分析了选定的OSF RR类型模板，对照了受控实验的文档指南。

Result: 分析显示，虽然一种RR类型与指南中的许多建议一致，但无一能全面覆盖指南，且OSF RR模板自定义存在局限性。

Conclusion: 尽管ESE领域有所进展，但实验规划和文档仍缺乏严谨性，影响了可重复性。建议采用基于OSF的RR，但目前尚无完全符合指南的RR类型，因此制定SE特定的RR指南至关重要。

Abstract: Context: The empirical software engineering (ESE) community has contributed to improving experimentation over the years. However, there is still a lack of rigor in describing controlled experiments, hindering reproducibility and transparency. Registered Reports (RR) have been discussed in the ESE community to address these issues. A RR registers a study's hypotheses, methods, and/or analyses before execution, involving peer review and potential acceptance before data collection. This helps mitigate problematic practices such as p-hacking, publication bias, and inappropriate post hoc analysis. Objective: This paper presents initial results toward establishing an RR template for Software Engineering controlled experiments using the Open Science Framework (OSF). Method: We analyzed templates of selected OSF RR types in light of documentation guidelines for controlled experiments. Results: The observed lack of rigor motivated our investigation of OSF-based RR types. Our analysis showed that, although one of the RR types aligned with many of the documentation suggestions contained in the guidelines, none of them covered the guidelines comprehensively. The study also highlights limitations in OSF RR template customization. Conclusion: Despite progress in ESE, planning and documenting experiments still lack rigor, compromising reproducibility. Adopting OSF-based RRs is proposed. However, no currently available RR type fully satisfies the guidelines. Establishing RR-specific guidelines for SE is deemed essential.

</details>


### [205] [Cross-Project Flakiness: A Case Study of the OpenStack Ecosystem](https://arxiv.org/abs/2602.09311)
*Tao Xiao,Dong Wang,Shane McIntosh,Hideaki Hata,Yasutaka Kamei*

Main category: cs.SE

TL;DR: 本文研究了OpenStack生态系统中测试不稳定性的广泛影响，发现跨项目和不一致不稳定性普遍存在，并提出了改进协调和配置的建议。


<details>
  <summary>Details</summary>
Motivation: 测试的不稳定性（flakiness）会削弱开发者对测试结果的信任，浪费计算资源，并影响CI的可靠性。此前的研究主要集中在单个项目内的测试不稳定性，而其对整个生态系统的影响尚未充分探索。

Method: 通过分析649个OpenStack项目，识别了1,535个跨项目不稳定测试和1,105个不一致不稳定测试。

Result: 研究发现跨项目不稳定性影响了55%的OpenStack项目，显著增加了审查时间和计算成本。70%的单元测试表现出跨项目不稳定性，挑战了单元测试固有隔离性的假设。

Conclusion: 研究强调了在复杂生态系统中需要更好的协调、标准化的CI配置以及改进的测试隔离策略。

Abstract: Automated regression testing is a cornerstone of modern software development, often contributing directly to code review and Continuous Integration (CI). Yet some tests suffer from flakiness, where their outcomes vary non-deterministically. Flakiness erodes developer trust in test results, wastes computational resources, and undermines CI reliability. While prior research has examined test flakiness within individual projects, its broader ecosystem-wide impact remains largely unexplored. In this paper, we present an empirical study of test flakiness in the OpenStack ecosystem, which focuses on (1) cross-project flakiness, where flaky tests impact multiple projects, and (2) inconsistent flakiness, where a test exhibits flakiness in some projects but remains stable in others. By analyzing 649 OpenStack projects, we identify 1,535 cross-project flaky tests and 1,105 inconsistently flaky tests. We find that cross-project flakiness affects 55% of OpenStack projects and significantly increases both review time and computational costs. Surprisingly, 70% of unit tests exhibit cross-project flakiness, challenging the assumption that unit tests are inherently insulated from issues that span modules like integration and system-level tests. Through qualitative analysis, we observe that race conditions in CI, inconsistent build configurations, and dependency mismatches are the primary causes of inconsistent flakiness. These findings underline the need for better coordination across complex ecosystems, standardized CI configurations, and improved test isolation strategies.

</details>


### [206] [SWE-AGI: Benchmarking Specification-Driven Software Construction with MoonBit in the Era of Autonomous Agents](https://arxiv.org/abs/2602.09447)
*Zhirui Zhang,Hongbo Zhang,Haoxiang Fei,Zhiyuan Bao,Yubin Chen,Zhengyu Lei,Ziyue Liu,Yixuan Sun,Mingkun Xiao,Zihang Ye,Yu Zhang,Hongcheng Zhu,Yuxiang Wen,Heung-Yeung Shum*

Main category: cs.SE

TL;DR: SWE-AGI是一个评估LLM从规范构建生产级软件的基准，结果显示前沿模型表现优异，但大规模代码库中代码阅读成为瓶颈。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）从明确规范自主构建生产级软件的能力。

Method: 引入SWE-AGI基准，评估基于MoonBit的端到端规范驱动软件系统构建能力，要求LLM代理从权威标准和RFC严格实现解析器、解释器等。

Result: gpt-5.3-codex表现最佳（解决19/22任务，86.4%），但随着任务难度增加，性能显著下降，尤其在规范密集型系统中。

Conclusion: 尽管基于规范的自主软件工程逐渐可行，但在可靠支持生产级开发之前仍存在重大挑战。

Abstract: Although large language models (LLMs) have demonstrated impressive coding capabilities, their ability to autonomously build production-scale software from explicit specifications remains an open question. We introduce SWE-AGI, an open-source benchmark for evaluating end-to-end, specification-driven construction of software systems written in MoonBit. SWE-AGI tasks require LLM-based agents to implement parsers, interpreters, binary decoders, and SAT solvers strictly from authoritative standards and RFCs under a fixed API scaffold. Each task involves implementing 1,000-10,000 lines of core logic, corresponding to weeks or months of engineering effort for an experienced human developer. By leveraging the nascent MoonBit ecosystem, SWE-AGI minimizes data leakage, forcing agents to rely on long-horizon architectural reasoning rather than code retrieval. Across frontier models, gpt-5.3-codex achieves the best overall performance (solving 19/22 tasks, 86.4%), outperforming claude-opus-4.6 (15/22, 68.2%), and kimi-2.5 exhibits the strongest performance among open-source models. Performance degrades sharply with increasing task difficulty, particularly on hard, specification-intensive systems. Behavioral analysis further reveals that as codebases scale, code reading, rather than writing, becomes the dominant bottleneck in AI-assisted development. Overall, while specification-driven autonomous software engineering is increasingly viable, substantial challenges remain before it can reliably support production-scale development.

</details>


### [207] [AlgoVeri: An Aligned Benchmark for Verified Code Generation on Classical Algorithms](https://arxiv.org/abs/2602.09464)
*Haoyu Zhao,Ziran Yang,Jiawei Li,Deyuan He,Zenan Li,Chi Jin,Venugopal V. Veeravalli,Aarti Gupta,Sanjeev Arora*

Main category: cs.SE

TL;DR: AlgoVeri 是一个跨范式验证编码基准测试，揭示了不同语言设计对 AI 模型性能的影响，特别是在 Dafny、Verus 和 Lean 中的显著差异。


<details>
  <summary>Details</summary>
Motivation: 现有基准测试仅针对个别语言/工具（如 Dafny、Verus 和 Lean），且任务差异大，性能数据无法直接比较，因此需要一种统一的跨范式评估方法。

Method: 提出了 AlgoVeri 基准测试，用于评估 Dafny、Verus 和 Lean 中 77 种经典算法的验证编码能力，并通过统一的函数合约进行对比。

Result: 前沿模型在 Dafny 中表现较好（40.3%），但在 Verus（24.7%）和 Lean（7.8%）中表现显著下降。此外，Gemini-3 通过迭代修复提升了性能，而 GPT-OSS 则早期饱和。

Conclusion: AlgoVeri 揭示了验证系统在跨范式评估中的关键能力差距，特别是在不同语言设计（如 Dafny、Verus 和 Lean）下的性能差异。

Abstract: Vericoding refers to the generation of formally verified code from rigorous specifications. Recent AI models show promise in vericoding, but a unified methodology for cross-paradigm evaluation is lacking. Existing benchmarks test only individual languages/tools (e.g., Dafny, Verus, and Lean) and each covers very different tasks, so the performance numbers are not directly comparable. We address this gap with AlgoVeri, a benchmark that evaluates vericoding of $77$ classical algorithms in Dafny, Verus, and Lean. By enforcing identical functional contracts, AlgoVeri reveals critical capability gaps in verification systems. While frontier models achieve tractable success in Dafny ($40.3$% for Gemini-3 Flash), where high-level abstractions and SMT automation simplify the workflow, performance collapses under the systems-level memory constraints of Verus ($24.7$%) and the explicit proof construction required by Lean (7.8%). Beyond aggregate metrics, we uncover a sharp divergence in test-time compute dynamics: Gemini-3 effectively utilizes iterative repair to boost performance (e.g., tripling pass rates in Dafny), whereas GPT-OSS saturates early. Finally, our error analysis shows that language design affects the refinement trajectory: while Dafny allows models to focus on logical correctness, Verus and Lean trap models in persistent syntactic and semantic barriers. All data and evaluation code can be found at https://github.com/haoyuzhao123/algoveri.

</details>


### [208] [Toward Linking Declined Proposals and Source Code: An Exploratory Study on the Go Repository](https://arxiv.org/abs/2602.09467)
*Sota Nakashima,Masanari Kondo,Mahmoud Alfadel,Aly Ahmad,Toshihiro Nakae,Hidenori Matsuzaki*

Main category: cs.SE

TL;DR: 本研究首次探索了开源项目中被拒绝贡献与源代码的链接方法，使用LLM驱动的流程取得了较高的准确率和精确度，但冗余讨论和信息不足是主要挑战。


<details>
  <summary>Details</summary>
Motivation: 被拒绝的贡献背后的讨论包含有价值的设计理由和软件决策的隐含知识，这些信息有助于理解为什么某些功能或变更被拒绝。

Method: 研究设计了一个基于LLM的流程，用于将被拒绝的提案（GitHub问题）链接到源代码，并在Go官方仓库的提案数据集上进行了测试。

Result: 实验结果显示，流程在选择正确的粒度级别上准确率为0.836，生成的链接在相应粒度上的平均精确度为0.643。失败分析表明，讨论冗余和缺乏具体信息是链接生成失败的主要原因。

Conclusion: 本研究首次尝试在开源软件项目中建立被拒绝贡献与相关源代码之间的可追溯性链接，提出了一个初步的链接方法，并通过实证分析讨论了影响链接生成的因素。

Abstract: Traceability links are key information sources for software developers, connecting software artifacts (e.g., linking requirements to the corresponding source code). In open-source software (OSS) projects, such links play an important role, particularly between the contributions (e.g., GitHub issues) and the corresponding source code. Through these links, developers can trace the discussions in contributions and uncover design rationales, constraints, and security concerns. Previous studies have mainly examined accepted contributions, while those declined after discussion have been overlooked. The discussions behind declined contributions contain valuable design rationales and implicit knowledge about software decision-making, as the reasons behind the decline often reveal the criteria used to judge what should or should not be implemented. In this study, we present the first attempt to establish traceability links between declined contributions and related source code. We propose an initial linking approach and conduct an empirical analysis of the generated links to discuss factors affecting link generation. As our dataset, we use proposals from the official Go repository, which are GitHub issues used to propose new features or language changes. To link declined proposals to source code, we designed an LLM-driven pipeline. Our results showed that the pipeline selected the correct granularity for each declined proposal with an accuracy of 0.836, and generated correct links at that granularity with a mean precision of 0.643. To clarify the challenges of linking declined proposals, we performed a failure analysis. In the declined proposals where the pipeline failed to generate links, the discussions were often redundant and lacked concrete information (e.g., how the feature should be implemented).

</details>


### [209] [SWE-Bench Mobile: Can Large Language Model Agents Develop Industry-Level Mobile Applications?](https://arxiv.org/abs/2602.09540)
*Muxin Tian,Zhe Wang,Blair Yang,Zhenwei Tang,Kunlun Zhu,Honghua Dong,Hanchen Li,Xinni Xie,Guangjing Wang,Jiaxuan You*

Main category: cs.SE

TL;DR: SWE-Bench Mobile基准评估显示AI编码代理在工业级移动应用开发中表现有限，最佳成功率仅12%，商业代理优于开源。


<details>
  <summary>Details</summary>
Motivation: 探讨大型语言模型代理是否能开发工业级移动应用，并评估其在真实软件工程任务中的表现。

Method: 引入了SWE-Bench Mobile基准，评估了22种代理模型配置在四种编码代理上的表现。

Result: 最佳配置的任务成功率仅为12%，商业代理普遍优于开源替代品，简单的‘防御性编程’提示优于复杂提示。

Conclusion: 研究发现当前AI编码代理的能力与工业级需求之间存在显著差距，但提供了对实践者和研究者的可行见解。

Abstract: Can large language model agents develop industry-level mobile applications? We introduce \textbf{SWE-Bench Mobile}, a benchmark for evaluating coding agents on realistic software engineering tasks derived from a production iOS codebase. Unlike existing benchmarks that focus on isolated problems or bug fixes, SWE-Bench Mobile captures the full complexity of industrial development: multi-modal inputs (PRDs and Figma designs), a large-scale mixed Swift/Objective-C codebase, and comprehensive test suites. We evaluate 22 agent-model configurations across four coding agents -- three commercial (Cursor, Codex, Claude Code) and one open-source (OpenCode) -- and find that even the best configurations achieve only 12\% task success rate. Our analysis reveals that (1) agent design matters as much as model capability -- the same model shows up to 6$\times$ performance gap across agents, (2) commercial agents consistently outperform open-source alternatives, and (3) simple ``Defensive Programming'' prompts outperform complex ones by 7.4\%. These findings highlight a significant gap between current agent capabilities and industrial requirements, while providing actionable insights for practitioners and researchers. We release SWE-Bench Mobile as a \textit{hosted benchmark challenge} to prevent data contamination and ensure fair evaluation. The public leaderboard and development toolkit are available at https://swebenchmobile.com.

</details>


### [210] [Generative AI Adoption in an Energy Company: Exploring Challenges and Use Cases](https://arxiv.org/abs/2602.09846)
*Malik Abdul Sami,Zeeshan Rasheed,Meri Olenius,Muhammad Waseem,Kai-Kristian Kemell,Jussi Rasku,Pekka Abrahamsson*

Main category: cs.SE

TL;DR: 研究探讨能源公司员工对AI的理解及潜在应用，通过访谈发现AI在报告、预测等领域的实用性，并提出渐进式引入GenAI和LLM工具的方法。


<details>
  <summary>Details</summary>
Motivation: 探讨能源公司员工如何理解AI的采用，并识别AI和基于LLM的代理工作流如何协助日常活动。

Method: 通过为期四周的十六次半结构化访谈，涵盖九个部门，辅以内部文件和研究者观察，收集数据并进行分析。

Result: 分析确定了员工认为AI有用的领域，包括报告工作、预测、数据处理、维护相关任务和异常检测。参与者还描述了如何通过渐进式步骤引入GenAI和基于LLM的工具，以与现有工作流程保持一致。

Conclusion: 该研究概述了能源行业中AI的采用情况，并提供了一个结构化基础，用于识别实际实施的切入点以及跨行业的比较研究。

Abstract: Organisations are examining how generative AI can support their operational work and decision-making processes. This study investigates how employees in a energy company understand AI adoption and identify areas where AI and LLMs-based agentic workflows could assist daily activities. Data was collected in four weeks through sixteen semi-structured interviews across nine departments, supported by internal documents and researcher observations. The analysis identified areas where employees positioned AI as useful, including reporting work, forecasting, data handling, maintenance-related tasks, and anomaly detection. Participants also described how GenAI and LLM-based tools could be introduced through incremental steps that align with existing workflows. The study provides an overview view of AI adoption in the energy sector and offers a structured basis for identifying entry points for practical implementation and comparative research across industries.

</details>


### [211] [Immersion in the GitHub Universe: Scaling Coding Agents to Mastery](https://arxiv.org/abs/2602.09892)
*Jiale Zhao,Guoxin Chen,Fanzhe Meng,Minghao Li,Jie Chen,Hui Xu,Yongshuai Sun,Xin Zhao,Ruihua Song,Yuan Zhang,Peng Wang,Cheng Chen,Jirong Wen,Kai Jia*

Main category: cs.SE

TL;DR: ScaleSWE通过自动化多智能体工作流构建了最大规模的软件工程数据集，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现实世界软件工程任务的掌握从根本上受到大规模、高质量训练数据稀缺的限制。这类数据的扩展受到环境设置复杂性、单元测试生成和问题描述整理的制约。

Method: ScaleSWE是一个自动化、沙盒化的多智能体工作流，协调三个专门智能体进行环境设置、测试创建和问题描述合成，处理了5200个仓库中的600万次拉取请求，生成了ScaleSWE数据集。

Result: ScaleSWE生成了100k个经过验证的SWE实例，是迄今为止最大的此类数据集。在仓库多样性和任务复杂性方面显著超越现有数据集。通过提炼71498条高质量轨迹并微调Qwen30BA3BInstruct，ScaleSWE智能体在SWE Bench Verified上实现了64%的解决率，比基础模型提高了近三倍。

Conclusion: ScaleSWE提供了一种可扩展、可复现的数据构建方法，以推进基于LLM的软件工程发展。ScaleSWE数据集将公开可用。

Abstract: Achieving mastery in real world software engineering tasks is fundamentally bottlenecked by the scarcity of large scale, high quality training data. Scaling such data has been limited by the complexity of environment setup, unit test generation, and problem statement curation. In this paper, we propose ScaleSWE, an automated, sandboxed multi agent workflow designed to construct high quality SWE data at scale. The system coordinates three specialized agents for environment setup, test creation, and problem description synthesis to process 6 million pull requests across 5200 repositories, producing Scale SWE Data: 100k verified SWE instances, the largest such dataset to date. It substantially surpasses existing real world datasets in repository diversity and reflects realistic task complexity. We further demonstrate the dataset utility for training by distilling 71498 high quality trajectories and finetuning Qwen30BA3BInstruct to produce ScaleSWE Agent. Our agent achieves a 64 resolve rate on SWE Bench Verified a nearly three fold improvement over the base model. ScaleSWE provides a scalable, reproducible approach for data construction to advance LLM based software engineering. Scale SWE will be publicly available.

</details>


### [212] [Operationalizing Human Values in the Requirements Engineering Process of Ethics-Aware Autonomous Systems](https://arxiv.org/abs/2602.09921)
*Everaldo Silva Júnior,Lina Marsso,Ricardo Caldas,Marsha Chechik,Genaína Nunes Rodrigues*

Main category: cs.SE

TL;DR: 论文提出了一种结合人类价值观与软件需求的方法，通过SLEEC需求实现自动化冲突检测，并在医疗案例中验证。


<details>
  <summary>Details</summary>
Motivation: 由于人类价值观的模糊性、多元性和上下文依赖性，将其与功能和适应性需求操作化具有挑战性。需要明确的表示来支持价值冲突的获取、分析和协商。

Method: 提出了一种需求工程方法，将人类价值观作为规范性目标，并与功能和适应性目标对齐，系统地操作化为SLEEC需求。

Result: 通过医疗体感网络案例研究验证了该方法的可行性。

Conclusion: 该论文提出了一种将人类价值观与功能和适应性需求相结合的工程方法，通过SLEEC需求实现自动化检查和冲突检测，并在医疗体感网络案例中验证了其可行性。

Abstract: Operationalizing human values alongside functional and adaptation requirements remains challenging due to their ambiguous, pluralistic, and context-dependent nature. Explicit representations are needed to support the elicitation, analysis, and negotiation of value conflicts beyond traditional software engineering abstractions. In this work, we propose a requirements engineering approach for ethics-aware autonomous systems that captures human values as normative goals and aligns them with functional and adaptation goals. These goals are systematically operationalized into Social, Legal, Ethical, Empathetic, and Cultural (SLEEC) requirements, enabling automated well-formedness checking, conflict detection, and early design-time negotiation. We demonstrate the feasibility of the approach through a medical Body Sensor Network case study.

</details>


### [213] [JMigBench: A Benchmark for Evaluating LLMs on Source Code Migration (Java 8 to Java 11)](https://arxiv.org/abs/2602.09930)
*Nishil Amin,Zhiwei Fei,Xiang Li,Justyna Petke,He Ye*

Main category: cs.SE

TL;DR: 研究构建了一个基准测试 JMigBench 来评估 LLMs 在 Java 8 到 11 的代码迁移任务中的表现，发现 Mistral Codestral 能部分自动化简单任务，但复杂任务仍需人工。


<details>
  <summary>Details</summary>
Motivation: 评估大型语言模型（LLMs）在源代码迁移任务中的表现，特别是从 Java 8 升级到 Java 11 的函数迁移。

Method: 构建了一个涵盖八类废弃 API 的精细数据集，并使用 CodeBLEU 和基于关键词的指标评估 Mistral Codestral 模型在词汇和语义相似性以及迁移正确性方面的表现。

Result: Mistral Codestral 在简单的 API 替换任务中表现中等（11.11% 的案例完全正确），但在复杂迁移任务中表现不佳。

Conclusion: Mistral Codestral 能够部分减少开发人员在重复性迁移任务中的工作量，但在复杂的迁移任务（如 CORBA 或 JAX-WS）中表现不佳，尚无法完全替代人工。

Abstract: We build a benchmark to evaluate large language models (LLMs) for source code migration tasks, specifically upgrading functions from Java 8 to Java 11. We first collected a dataset of function pairs from open-source repositories, but limitations in data quality led us to construct a refined dataset covering eight categories of deprecated APIs. Using this dataset, the Mistral Codestral model was evaluated with CodeBLEU and keyword-based metrics to measure lexical and semantic similarity as well as migration correctness. Results show that the evaluated model (Mistral Codestral) can handle trivial one-to-one API substitutions with moderate success, achieving identical migrations in 11.11% of the cases, but it struggles with more complex migrations such as CORBA or JAX-WS. These findings suggest Mistral Codestral can partially reduce developer effort by automating repetitive migration tasks but cannot yet replace humans within the scope of the JMigBench benchmark. The benchmark and analysis provide a foundation for future work on expanding datasets, refining prompting strategies, and improving migration performance across different LLMs.

</details>


### [214] [QEMI: A Quantum Software Stacks Testing Framework via Equivalence Modulo Inputs](https://arxiv.org/abs/2602.09942)
*Junjie Luo,Shangzhou Xia,Fuyuan Zhang,Jianjun Zhao*

Main category: cs.SE

TL;DR: QEMI利用EMI思想改进量子软件测试，通过死代码变体检测出多个bug，填补了语义保留变换在量子程序分析中的空白。


<details>
  <summary>Details</summary>
Motivation: 量子软件栈的正确性验证因缺乏可靠的预期行为基准（oracle问题）而面临挑战，现有方法多依赖等效电路变换或后端修改，亟需新测试技术。

Method: 基于Equivalence Modulo Inputs (EMI)思想，提出Quantum EMI (QEMI)方法，包括随机量子程序生成器和死代码移除变体生成技术。

Result: 在Qiskit、Q#和Cirq中成功检测出11个崩溃bug和1个行为不一致问题。

Conclusion: QEMI提出了一种新的量子软件栈测试方法，通过生成带有死代码的随机量子程序并利用EMI技术生成变体，成功检测出Qiskit、Q#和Cirq中的多个bug，扩展了量子软件测试的技术手段。

Abstract: As quantum algorithms and hardware continue to evolve, ensuring the correctness of the quantum software stack (QSS) has become increasingly important. However, testing QSSes remains challenging due to the oracle problem, i.e., the lack of a reliable ground truth for expected program behavior. Existing metamorphic testing approaches often rely on equivalent circuit transformations, backend modifications, or parameter tuning to address this issue. In this work, inspired by Equivalence Modulo Inputs (EMI), we propose Quantum EMI (QEMI), a new testing approach for QSSes. Our key contributions include: (1) a random quantum program generator that produces code with dead code based on quantum control-flow structures, and (2) an adaptation of the EMI technique from classical compiler testing to generate variants by removing dead code. By comparing the behavior of these variants, we can detect potential bugs in QSS implementations. We applied QEMI to Qiskit, Q#, and Cirq, and successfully identified 11 crash bugs and 1 behavioral inconsistency. QEMI expands the limited set of testing techniques available for quantum software stacks by going beyond structural transformations and incorporating semantics-preserving ones into quantum program analysis.

</details>


### [215] [Environment-in-the-Loop: Rethinking Code Migration with LLM-based Agents](https://arxiv.org/abs/2602.09944)
*Xiang Li,Zhiwei Fei,Ying Ma,Jerry Zhang,Sarro Federica,He Ye*

Main category: cs.SE

TL;DR: 论文指出自动化代码迁移需结合环境交互，提出新框架范式并探讨未来方向，强调环境交互对完整自动化的重要性。


<details>
  <summary>Details</summary>
Motivation: 现代软件系统持续升级代码以增强功能、安全性和性能，但自动化代码迁移研究中环境交互的探索相对不足，导致对目标环境的理解不充分、反馈周期延长和效率降低。

Method: 首先概述了自动化环境构建的现状，然后提出了一种将自动化环境设置与代码迁移工作流紧密结合的新框架范式。

Result: 研究发现，缺乏自动化环境交互的代码迁移自动化是不完整的。提出的新框架范式为解决这一问题提供了方向。

Conclusion: 论文强调了自动化环境交互在代码迁移中的重要性，指出缺乏这一环节会导致效率低下。提出了一个将自动化环境设置与代码迁移紧密结合的新框架范式，并探讨了未来研究方向。

Abstract: Modern software systems continuously undergo code upgrades to enhance functionality, security, and performance, and Large Language Models (LLMs) have demonstrated remarkable capabilities in code migration tasks. However, while research on automated code migration which including refactoring, API adaptation, and dependency updates has advanced rapidly, the exploration of the automated environment interaction that must accompany it remains relatively scarce. In practice, code and its environment are intricately intertwined. Relying solely on static analysis of the environment leads to an inadequate understanding of the target setting, prolongs feedback cycles, and consequently causes significant rework and project delays, thereby reducing overall efficiency. We contend that successful software evolution demands a holistic perspective that integrates both code and environment migration. To understand the current landscape and challenges, we first provide an overview of the status of automated environment construction. We then propose a novel framework paradigm that tightly integrates automated environment setup with the code migration workflow. Finally, we explore the challenges and future directions for automated environment interaction within the code migration domain. Our findings emphasize that without automated environment interaction, the automation of code migration is only half complete.

</details>


### [216] [Artisan: Agentic Artifact Evaluation](https://arxiv.org/abs/2602.10046)
*Doehyun Baek,Michael Pradel*

Main category: cs.SE

TL;DR: Artisan是一个自动化LLM代理，通过代码生成任务和自动化判断机制高效复现研究结果，显著优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 当前人工的工件评估过程劳动密集且仅一次性评估部分论文，需自动化支持。

Method: 将复现问题构建为代码生成任务，并设计自动化判断机制以避免简单解决方案。

Result: Artisan在Artisan-Bench基准测试中表现优异，生成复现脚本的效率是基线的3.14倍，平均每任务耗时0.45美元和48分钟。

Conclusion: Artisan是一个有效的自动化工具，能够生成44/60的复现脚本，显著优于现有基线，并在过程中发现了20个新错误。

Abstract: Artifact evaluation has become standard practice in the software engineering community to ensure the reproducibility of research results. However, the current manual process is labor-intensive, and hence, done only as a one-time assessment for a subset of all papers. To support the artifact evaluation effort, we present Artisan, an automated LLM agent for reproducing research results given a paper and its artifact. The approach is enabled by two key contributions: First, we frame the reproduction problem as a code generation task where the goal is to generate a reproduction script that, when executed, reproduces the results reported in a paper. Unlike prior work on automatically reproducing research results in other domains, this formulation allows for running the script independently of the agent and for assessing the reproduction process at a fine-grained level. Second, we design automated judging mechanism that guides the agent toward the expected results without revealing them and that prevent trivial solutions, such as simply copying checked-in results. To evaluate Artisan, we introduce Artisan-Bench, the first benchmark assessing the ability to generate reproduction scripts and the first benchmark for automated artifact evaluation in software engineering. Artisan-Bench comprises 60 tasks derived from 23 software engineering papers, covering different research areas and programming languages. We validate all tasks in Artisan-Bench for reproducibility to ensure that the tasks are feasible. Our experiments show that Artisan is effective, producing 44/60 reproduction scripts and outperforming the best available baseline, a vanilla LLM agent (mini-swe-agent), by 3.14$\times$ in terms of reproduction scripts generated while taking $0.45 and 48 minutes, on average per task. Artisan also helped uncover 20 new errors in either the paper or artifact.

</details>
