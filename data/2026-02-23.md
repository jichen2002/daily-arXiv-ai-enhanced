<div id=toc></div>

# Table of Contents

- [cs.CV](#cs.CV) [Total: 43]
- [cs.DC](#cs.DC) [Total: 11]
- [cs.RO](#cs.RO) [Total: 24]
- [cs.DS](#cs.DS) [Total: 3]
- [cs.AI](#cs.AI) [Total: 10]
- [cs.SE](#cs.SE) [Total: 10]
- [cs.NI](#cs.NI) [Total: 4]
- [cs.GR](#cs.GR) [Total: 2]


<div id='cs.CV'></div>

# cs.CV [[Back]](#toc)

### [1] [KPM-Bench: A Kinematic Parsing Motion Benchmark for Fine-grained Motion-centric Video Understanding](https://arxiv.org/abs/2602.17768)
*Boda Lin,Yongjie Zhu,Xiaocheng Gong,Wenyu Qin,Meng Wang*

Main category: cs.CV

TL;DR: 本文提出MoPE算法和KPM-Bench数据集，旨在解决视频字幕模型在细粒度运动描述和幻觉问题上的挑战，显著提升了模型性能。


<details>
  <summary>Details</summary>
Motivation: 现有视频字幕模型在描述细粒度运动细节时存在局限性，且存在严重的幻觉问题，尤其在运动中心视频中表现尤为突出。

Method: 提出了一种基于语言的运动解析和提取（MoPE）算法，并构建了KPM-Bench数据集，包含细粒度视频-字幕对、多样化问答对和精心策划的评估集。

Result: 提出的MoPE算法能够直接从文本字幕中准确提取运动特定属性，并引入了一种独立的幻觉评估指标，显著改善了模型的可靠性。

Conclusion: 通过集成MoPE算法到GRPO后训练框架中，有效缓解了幻觉问题，显著提高了以运动为中心的视频字幕模型的可靠性。

Abstract: Despite recent advancements, video captioning models still face significant limitations in accurately describing fine-grained motion details and suffer from severe hallucination issues. These challenges become particularly prominent when generating captions for motion-centric videos, where precise depiction of intricate movements and limb dynamics is crucial yet often neglected. To alleviate this gap, we introduce an automated annotation pipeline that integrates kinematic-based motion computation with linguistic parsing, enabling detailed decomposition and description of complex human motions. Based on this pipeline, we construct and release the Kinematic Parsing Motion Benchmark (KPM-Bench), a novel open-source dataset designed to facilitate fine-grained motion understanding. KPM-Bench consists of (i) fine-grained video-caption pairs that comprehensively illustrate limb-level dynamics in complex actions, (ii) diverse and challenging question-answer pairs focusing specifically on motion understanding, and (iii) a meticulously curated evaluation set specifically designed to assess hallucination phenomena associated with motion descriptions. Furthermore, to address hallucination issues systematically, we propose the linguistically grounded Motion Parsing and Extraction (MoPE) algorithm, capable of accurately extracting motion-specific attributes directly from textual captions. Leveraging MoPE, we introduce a precise hallucination evaluation metric that functions independently of large-scale vision-language or language-only models. By integrating MoPE into the GRPO post-training framework, we effectively mitigate hallucination problems, significantly improving the reliability of motion-centric video captioning models.

</details>


### [2] [CLUTCH: Contextualized Language model for Unlocking Text-Conditioned Hand motion modelling in the wild](https://arxiv.org/abs/2602.17770)
*Balamurugan Thambiraja,Omid Taheri,Radek Danecek,Giorgio Becherini,Gerard Pons-Moll,Justus Thies*

Main category: cs.CV

TL;DR: 本文提出3D-HIW数据集和CLUTCH系统，通过SHIFT架构和几何细化，显著提升了真实场景下的手部动作建模性能。


<details>
  <summary>Details</summary>
Motivation: 现有手部动作建模方法依赖有限动作和场景的室内数据集，难以扩展到真实场景，且缺乏文本-动作对齐的动画保真度。

Method: 提出了CLUTCH系统，包含SHIFT（一种新型VQ-VAE架构）和几何细化阶段，用于手部动作的token化和优化。同时，开发了一个结合视觉语言模型和3D手部追踪器的数据标注流程，构建了3D-HIW数据集。

Result: 实验证明，CLUTCH在文本-动作生成和动作-文本描述任务上表现优异，为真实场景下的手部动作建模设立了首个基准。

Conclusion: 本文通过引入3D-HIW数据集和CLUTCH系统，解决了现有手部动作建模在真实场景中的局限性，并在文本-动作生成和动作-文本描述任务上取得了最先进的性能。

Abstract: Hands play a central role in daily life, yet modeling natural hand motions remains underexplored. Existing methods that tackle text-to-hand-motion generation or hand animation captioning rely on studio-captured datasets with limited actions and contexts, making them costly to scale to "in-the-wild" settings. Further, contemporary models and their training schemes struggle to capture animation fidelity with text-motion alignment. To address this, we (1) introduce '3D Hands in the Wild' (3D-HIW), a dataset of 32K 3D hand-motion sequences and aligned text, and (2) propose CLUTCH, an LLM-based hand animation system with two critical innovations: (a) SHIFT, a novel VQ-VAE architecture to tokenize hand motion, and (b) a geometric refinement stage to finetune the LLM. To build 3D-HIW, we propose a data annotation pipeline that combines vision-language models (VLMs) and state-of-the-art 3D hand trackers, and apply it to a large corpus of egocentric action videos covering a wide range of scenarios. To fully capture motion in-the-wild, CLUTCH employs SHIFT, a part-modality decomposed VQ-VAE, which improves generalization and reconstruction fidelity. Finally, to improve animation quality, we introduce a geometric refinement stage, where CLUTCH is co-supervised with a reconstruction loss applied directly to decoded hand motion parameters. Experiments demonstrate state-of-the-art performance on text-to-motion and motion-to-text tasks, establishing the first benchmark for scalable in-the-wild hand motion modelling. Code, data and models will be released.

</details>


### [3] [Multi-Modal Monocular Endoscopic Depth and Pose Estimation with Edge-Guided Self-Supervision](https://arxiv.org/abs/2602.17785)
*Xinwei Ju,Rema Daher,Danail Stoyanov,Sophia Bano,Francisco Vasconcelos*

Main category: cs.CV

TL;DR: PRISM是一种自监督框架，结合边缘检测和亮度解耦提升结肠镜深度/姿态估计，实验证明真实数据训练和视频帧率对性能至关重要。


<details>
  <summary>Details</summary>
Motivation: 结肠镜辅助导航中，单目深度和姿态估计能减少盲区、降低遗漏病变风险，但因纹理缺失、复杂光照、形变及缺乏真实标注数据而极具挑战性。

Method: PRISM是一种自监督学习框架，结合边缘检测（如DexiNed或HED）和亮度解耦（通过内在分解模块分离光照和反射），利用解剖和光照先验指导几何学习。

Result: 在多组真实和合成数据集上达到最先进性能。消融研究表明：1) 真实数据的自监督训练优于仿真数据的监督训练；2) 视频帧率对数据质量及模型性能影响显著。

Conclusion: PRISM框架通过结合边缘检测和亮度解耦，利用解剖和光照先验，显著提升了结肠镜导航中的单目深度和姿态估计性能。实验证明，在真实数据上的自监督训练优于在仿真数据上的监督训练，且视频帧率对模型性能至关重要。

Abstract: Monocular depth and pose estimation play an important role in the development of colonoscopy-assisted navigation, as they enable improved screening by reducing blind spots, minimizing the risk of missed or recurrent lesions, and lowering the likelihood of incomplete examinations. However, this task remains challenging due to the presence of texture-less surfaces, complex illumination patterns, deformation, and a lack of in-vivo datasets with reliable ground truth. In this paper, we propose **PRISM** (Pose-Refinement with Intrinsic Shading and edge Maps), a self-supervised learning framework that leverages anatomical and illumination priors to guide geometric learning. Our approach uniquely incorporates edge detection and luminance decoupling for structural guidance. Specifically, edge maps are derived using a learning-based edge detector (e.g., DexiNed or HED) trained to capture thin and high-frequency boundaries, while luminance decoupling is obtained through an intrinsic decomposition module that separates shading and reflectance, enabling the model to exploit shading cues for depth estimation. Experimental results on multiple real and synthetic datasets demonstrate state-of-the-art performance. We further conduct a thorough ablation study on training data selection to establish best practices for pose and depth estimation in colonoscopy. This analysis yields two practical insights: (1) self-supervised training on real-world data outperforms supervised training on realistic phantom data, underscoring the superiority of domain realism over ground truth availability; and (2) video frame rate is an extremely important factor for model performance, where dataset-specific video frame sampling is necessary for generating high quality training data.

</details>


### [4] [Diff2DGS: Reliable Reconstruction of Occluded Surgical Scenes via 2D Gaussian Splatting](https://arxiv.org/abs/2602.18314)
*Tianyi Song,Danail Stoyanov,Evangelos Mazomenos,Francisco Vasconcelos*

Main category: cs.CV

TL;DR: Diff2DGS通过扩散修复和2D高斯泼溅两阶段方法，显著提升手术场景3D重建质量，尤其在遮挡和深度准确性上表现突出。


<details>
  <summary>Details</summary>
Motivation: 实时重建可变形手术场景对提升机器人手术、外科引导及自动化至关重要，但现有方法在遮挡区域重建质量和深度准确性上存在局限。

Method: 提出Diff2DGS两阶段框架：第一阶段使用基于扩散的视频模块修复被器械遮挡的组织；第二阶段结合2D高斯泼溅（2DGS）与可学习形变模型（LDM）捕捉动态组织形变。

Result: Diff2DGS在EndoNeRF和StereoMIS上分别达到38.02 dB和34.40 dB PSNR，显著优于现有方法，并通过SCARED数据集验证了深度准确性。

Conclusion: Diff2DGS通过两阶段框架显著提升了手术场景的3D重建质量，尤其在遮挡区域和深度准确性方面表现优异，同时优化了深度质量以确保几何保真度。

Abstract: Real-time reconstruction of deformable surgical scenes is vital for advancing robotic surgery, improving surgeon guidance, and enabling automation. Recent methods achieve dense reconstructions from da Vinci robotic surgery videos, with Gaussian Splatting (GS) offering real-time performance via graphics acceleration. However, reconstruction quality in occluded regions remains limited, and depth accuracy has not been fully assessed, as benchmarks like EndoNeRF and StereoMIS lack 3D ground truth. We propose Diff2DGS, a novel two-stage framework for reliable 3D reconstruction of occluded surgical scenes. In the first stage, a diffusion-based video module with temporal priors inpaints tissue occluded by instruments with high spatial-temporal consistency. In the second stage, we adapt 2D Gaussian Splatting (2DGS) with a Learnable Deformation Model (LDM) to capture dynamic tissue deformation and anatomical geometry. We also extend evaluation beyond prior image-quality metrics by performing quantitative depth accuracy analysis on the SCARED dataset. Diff2DGS outperforms state-of-the-art approaches in both appearance and geometry, reaching 38.02 dB PSNR on EndoNeRF and 34.40 dB on StereoMIS. Furthermore, our experiments demonstrate that optimizing for image quality alone does not necessarily translate into optimal 3D reconstruction accuracy. To address this, we further optimize the depth quality of the reconstructed 3D results, ensuring more faithful geometry in addition to high-fidelity appearance.

</details>


### [5] [LGD-Net: Latent-Guided Dual-Stream Network for HER2 Scoring with Task-Specific Domain Knowledge](https://arxiv.org/abs/2602.17793)
*Peide Zhu,Linbin Lu,Zhiqin Chen,Xiong Chen*

Main category: cs.CV

TL;DR: LGD-Net通过跨模态特征幻觉和任务特定正则化，直接从H&E切片预测HER2水平，避免了传统虚拟染色的高成本和伪影问题，实现了高效准确的评分。


<details>
  <summary>Details</summary>
Motivation: 标准IHC染色资源密集、昂贵且耗时，而现有虚拟染色方法计算成本高且易产生重建伪影。LGD-Net旨在解决这些限制，直接从H&E切片预测HER2水平。

Method: 提出Latent-Guided Dual-Stream Network (LGD-Net)，利用跨模态特征幻觉而非显式像素级图像生成，通过教师IHC编码器引导训练，并结合轻量级辅助正则化任务（如核分布和膜染色强度）优化模型。

Result: 在公开BCI数据集上的实验表明，LGD-Net达到最先进性能，显著优于基线方法，且支持单模态H&E输入的高效推理。

Conclusion: LGD-Net通过直接映射H&E形态特征到分子潜在空间，避免了像素级图像生成的复杂性，显著提升了HER2评分的准确性和效率。

Abstract: It is a critical task to evalaute HER2 expression level accurately for breast cancer evaluation and targeted treatment therapy selection. However, the standard multi-step Immunohistochemistry (IHC) staining is resource-intensive, expensive, and time-consuming, which is also often unavailable in many areas. Consequently, predicting HER2 levels directly from H&E slides has emerged as a potential alternative solution. It has been shown to be effective to use virtual IHC images from H&E images for automatic HER2 scoring. However, the pixel-level virtual staining methods are computationally expensive and prone to reconstruction artifacts that can propagate diagnostic errors. To address these limitations, we propose the Latent-Guided Dual-Stream Network (LGD-Net), a novel framework that employes cross-modal feature hallucination instead of explicit pixel-level image generation. LGD-Net learns to map morphological H&E features directly to the molecular latent space, guided by a teacher IHC encoder during training. To ensure the hallucinated features capture clinically relevant phenotypes, we explicitly regularize the model training with task-specific domain knowledge, specifically nuclei distribution and membrane staining intensity, via lightweight auxiliary regularization tasks. Extensive experiments on the public BCI dataset demonstrate that LGD-Net achieves state-of-the-art performance, significantly outperforming baseline methods while enabling efficient inference using single-modality H&E inputs.

</details>


### [6] [Enabling Training-Free Text-Based Remote Sensing Segmentation](https://arxiv.org/abs/2602.17799)
*Jose Sosa,Danila Rukhovich,Anis Kacem,Djamila Aouada*

Main category: cs.CV

TL;DR: 论文提出了一种无需训练的文本引导遥感图像分割方法，结合CLIP和SAM，在零样本设置下实现高性能分割。


<details>
  <summary>Details</summary>
Motivation: 探索在不依赖额外可训练组件的情况下，利用现有基础模型实现基于文本的遥感图像分割，以提升泛化能力和实际应用性。

Method: 提出了一种简单而有效的方法，整合了对比性（CLIP作为SAM网格提议的掩码选择器）和生成性（使用GPT-5和LoRA调优的Qwen-VL模型生成点击提示）视觉语言模型与SAM，实现完全无训练或轻量级LoRA调优的流程。

Result: 在19个遥感基准测试中，包括开放词汇、指代和基于推理的任务，该方法展现了强大的性能，特别是在零样本设置下实现了最先进的开放词汇语义分割（OVSS）。

Conclusion: 论文提出了一种无需额外训练即可实现基于文本的遥感图像分割的方法，通过结合对比性和生成性视觉语言模型与Segment Anything Model（SAM），展示了在零样本设置下的强大性能。

Abstract: Recent advances in Vision Language Models (VLMs) and Vision Foundation Models (VFMs) have opened new opportunities for zero-shot text-guided segmentation of remote sensing imagery. However, most existing approaches still rely on additional trainable components, limiting their generalisation and practical applicability. In this work, we investigate to what extent text-based remote sensing segmentation can be achieved without additional training, by relying solely on existing foundation models. We propose a simple yet effective approach that integrates contrastive and generative VLMs with the Segment Anything Model (SAM), enabling a fully training-free or lightweight LoRA-tuned pipeline. Our contrastive approach employs CLIP as mask selector for SAM's grid-based proposals, achieving state-of-the-art open-vocabulary semantic segmentation (OVSS) in a completely zero-shot setting. In parallel, our generative approach enables reasoning and referring segmentation by generating click prompts for SAM using GPT-5 in a zero-shot setting and a LoRA-tuned Qwen-VL model, with the latter yielding the best results. Extensive experiments across 19 remote sensing benchmarks, including open-vocabulary, referring, and reasoning-based tasks, demonstrate the strong capabilities of our approach. Code will be released at https://github.com/josesosajs/trainfree-rs-segmentation.

</details>


### [7] [VidEoMT: Your ViT is Secretly Also a Video Segmentation Model](https://arxiv.org/abs/2602.17807)
*Narges Norouzi,Idil Esen Zulfikar,Niccol`o Cavagnero,Tommie Kerssies,Bastian Leibe,Gijs Dubbelman,Daan de Geus*

Main category: cs.CV

TL;DR: VidEoMT是一种简化视频分割的编码器模型，通过查询传播机制替代复杂跟踪模块，实现高速高效分割。


<details>
  <summary>Details</summary>
Motivation: 现有视频分割模型依赖复杂跟踪模块，导致架构复杂和计算开销大，而ViT编码器在大规模预训练下可简化分割任务。

Method: 提出VidEoMT模型，采用编码器架构和查询传播机制，结合传播查询与学习查询的策略。

Result: VidEoMT在保持竞争力的准确率下，速度提升5-10倍，最高达160 FPS。

Conclusion: VidEoMT通过简单的编码器架构和轻量级查询传播机制，实现了高效的视频分割，无需复杂跟踪模块，同时保持高速度和准确性。

Abstract: Existing online video segmentation models typically combine a per-frame segmenter with complex specialized tracking modules. While effective, these modules introduce significant architectural complexity and computational overhead. Recent studies suggest that plain Vision Transformer (ViT) encoders, when scaled with sufficient capacity and large-scale pre-training, can conduct accurate image segmentation without requiring specialized modules. Motivated by this observation, we propose the Video Encoder-only Mask Transformer (VidEoMT), a simple encoder-only video segmentation model that eliminates the need for dedicated tracking modules. To enable temporal modeling in an encoder-only ViT, VidEoMT introduces a lightweight query propagation mechanism that carries information across frames by reusing queries from the previous frame. To balance this with adaptability to new content, it employs a query fusion strategy that combines the propagated queries with a set of temporally-agnostic learned queries. As a result, VidEoMT attains the benefits of a tracker without added complexity, achieving competitive accuracy while being 5x--10x faster, running at up to 160 FPS with a ViT-L backbone. Code: https://www.tue-mps.org/videomt/

</details>


### [8] [VQPP: Video Query Performance Prediction Benchmark](https://arxiv.org/abs/2602.17814)
*Adrian Catalin Lutu,Eduard Poesina,Radu Tudor Ionescu*

Main category: cs.CV

TL;DR: 首个视频查询性能预测基准VQPP发布，包含大规模数据集和评估框架，预检索预测器表现突出，并成功应用于查询重写任务。


<details>
  <summary>Details</summary>
Motivation: 视频内容检索（CBVR）中的查询性能预测（QPP）研究不足，缺乏标准化评估平台，因此需要建立首个VQPP基准以促进该领域的发展。

Method: 提出了首个视频查询性能预测（VQPP）基准，包含两个文本到视频检索数据集和两个CBVR系统，总计56K文本查询和51K视频，并提供了官方训练、验证和测试分割。探索了多种预检索和后检索性能预测器。

Result: 预检索预测器表现优异，适用于检索前场景；最佳预检索预测器被成功应用于通过直接偏好优化（DPO）训练大型语言模型（LLM）进行查询重写。

Conclusion: VQPP基准的建立为视频查询性能预测领域提供了首个标准化的评估平台，展示了预检索预测器的竞争力，并验证了其在查询重写任务中的实际应用价值。

Abstract: Query performance prediction (QPP) is an important and actively studied information retrieval task, having various applications, such as query reformulation, query expansion, and retrieval system selection, among many others. The task has been primarily studied in the context of text and image retrieval, whereas QPP for content-based video retrieval (CBVR) remains largely underexplored. To this end, we propose the first benchmark for video query performance prediction (VQPP), comprising two text-to-video retrieval datasets and two CBVR systems, respectively. VQPP contains a total of 56K text queries and 51K videos, and comes with official training, validation and test splits, fostering direct comparisons and reproducible results. We explore multiple pre-retrieval and post-retrieval performance predictors, creating a representative benchmark for future exploration of QPP in the video domain. Our results show that pre-retrieval predictors obtain competitive performance, enabling applications before performing the retrieval step. We also demonstrate the applicability of VQPP by employing the best performing pre-retrieval predictor as reward model for training a large language model (LLM) on the query reformulation task via direct preference optimization (DPO). We release our benchmark and code at https://github.com/AdrianLutu/VQPP.

</details>


### [9] [On the Evaluation Protocol of Gesture Recognition for UAV-based Rescue Operation based on Deep Learning: A Subject-Independence Perspective](https://arxiv.org/abs/2602.17854)
*Domonkos Varga*

Main category: cs.CV

TL;DR: 该论文指出Liu和Szirányi的手势识别评估协议因数据泄漏问题导致高估准确度，强调需采用独立于受试者的数据划分方法。


<details>
  <summary>Details</summary>
Motivation: 揭示原研究中报告的近乎完美的准确度指标是由于帧级随机训练-测试分割导致的数据泄漏，无法衡量对未见个体的泛化能力。

Method: 通过分析Liu和Szirányi提出的手势识别方法的评估协议，检查了混淆矩阵、学习曲线和数据集构建。

Result: 证明了原评估协议存在严重的数据泄漏问题，无法有效评估模型对未见个体的识别能力。

Conclusion: 该论文强调了在基于视觉的手势识别研究中，尤其是涉及无人机与人类交互等应用时，独立于受试者的数据划分的重要性。

Abstract: This paper presents a methodological analysis of the gesture-recognition approach proposed by Liu and Szirányi, with a particular focus on the validity of their evaluation protocol. We show that the reported near-perfect accuracy metrics result from a frame-level random train-test split that inevitably mixes samples from the same subjects across both sets, causing severe data leakage. By examining the published confusion matrix, learning curves, and dataset construction, we demonstrate that the evaluation does not measure generalization to unseen individuals. Our findings underscore the importance of subject-independent data partitioning in vision-based gesture-recognition research, especially for applications - such as UAV-human interaction - that require reliable recognition of gestures performed by previously unseen people.

</details>


### [10] [Learning Compact Video Representations for Efficient Long-form Video Understanding in Large Multimodal Models](https://arxiv.org/abs/2602.17869)
*Yuxiao Chen,Jue Wang,Zhikang Zhang,Jingru Yi,Xu Zhang,Yang Zou,Zhaowei Cai,Jianbo Yuan,Xinyu Li,Hao Yang,Davide Modolo*

Main category: cs.CV

TL;DR: A novel end-to-end framework for long-form video understanding combines adaptive sampling and compression with MLLM, addressing redundancy and memory issues while excelling in benchmarks.


<details>
  <summary>Details</summary>
Motivation: Addressing the challenges of efficiently incorporating more frames within memory constraints and extracting discriminative information from redundant video sequences.

Method: The paper introduces an end-to-end schema with an information-density-based adaptive video sampler (AVS) and an autoencoder-based spatiotemporal video compressor (SVC) integrated with a multimodal large language model (MLLM).

Result: The system adaptively captures essential information from videos of varying durations and achieves high compression rates while preserving crucial information, excelling in various benchmarks.

Conclusion: The proposed framework demonstrates promising performance in long-form video understanding tasks and standard benchmarks, highlighting its versatility and efficacy in handling prolonged video sequences.

Abstract: With recent advancements in video backbone architectures, combined with the remarkable achievements of large language models (LLMs), the analysis of long-form videos spanning tens of minutes has become both feasible and increasingly prevalent. However, the inherently redundant nature of video sequences poses significant challenges for contemporary state-of-the-art models. These challenges stem from two primary aspects: 1) efficiently incorporating a larger number of frames within memory constraints, and 2) extracting discriminative information from the vast volume of input data. In this paper, we introduce a novel end-to-end schema for long-form video understanding, which includes an information-density-based adaptive video sampler (AVS) and an autoencoder-based spatiotemporal video compressor (SVC) integrated with a multimodal large language model (MLLM). Our proposed system offers two major advantages: it adaptively and effectively captures essential information from video sequences of varying durations, and it achieves high compression rates while preserving crucial discriminative information. The proposed framework demonstrates promising performance across various benchmarks, excelling in both long-form video understanding tasks and standard video understanding benchmarks. These results underscore the versatility and efficacy of our approach, particularly in managing the complexities of prolonged video sequences.

</details>


### [11] [Understanding the Fine-Grained Knowledge Capabilities of Vision-Language Models](https://arxiv.org/abs/2602.17871)
*Dhruba Ghosh,Yuhui Zhang,Ludwig Schmidt*

Main category: cs.CV

TL;DR: 研究发现VLM在细粒度分类任务上表现不佳的原因，并提出改进方向：优化视觉编码器和预训练策略（尤其是语言模型权重未冻结时）。


<details>
  <summary>Details</summary>
Motivation: 尽管VLM在多种视觉问答任务上取得显著进展，但在传统图像分类基准（测试细粒度视觉知识）上表现不佳，研究旨在探索这一差异的原因。

Method: 测试了大量近期VLM在细粒度分类基准上的表现，并通过消融实验分析了影响细粒度知识与视觉基准差异的潜在因素。

Result: 发现更好的LLM均衡提升所有基准分数，而更好的视觉编码器则显著提升细粒度分类性能；预训练阶段（尤其是语言模型权重未冻结时）对细粒度性能至关重要。

Conclusion: 通过一系列消融实验，研究发现使用更好的LLM能均衡提升所有基准测试分数，而更好的视觉编码器则显著提升细粒度分类性能。此外，预训练阶段对细粒度性能至关重要，尤其是当语言模型权重在预训练期间未冻结时。这些发现为增强VLM的细粒度视觉理解和视觉中心能力提供了方向。

Abstract: Vision-language models (VLMs) have made substantial progress across a wide range of visual question answering benchmarks, spanning visual reasoning, document understanding, and multimodal dialogue. These improvements are evident in a wide range of VLMs built on a variety of base models, alignment architectures, and training data. However, recent works show that these models trail behind in traditional image classification benchmarks, which test fine-grained visual knowledge. We test a large number of recent VLMs on fine-grained classification benchmarks and identify potential factors in the disconnect between fine-grained knowledge and other vision benchmarks. Through a series of ablation experiments, we find that using a better LLM improves all benchmark scores equally, while a better vision encoder disproportionately improves fine-grained classification performance. Furthermore, we find that the pretraining stage is also vital to fine-grained performance, particularly when the language model weights are unfrozen during pretraining. These insights pave the way for enhancing fine-grained visual understanding and vision-centric capabilities in VLMs.

</details>


### [12] [A Single Image and Multimodality Is All You Need for Novel View Synthesis](https://arxiv.org/abs/2602.17909)
*Amirhosein Javadi,Chi-Shiang Gau,Konstantinos D. Polyzos,Tara Javidi*

Main category: cs.CV

TL;DR: 结合稀疏多模态测距数据优化扩散模型的新视角合成，提升几何一致性与视觉质量。


<details>
  <summary>Details</summary>
Motivation: 现有基于单目深度估计的扩散方法在低纹理、恶劣天气或遮挡严重的真实场景中表现受限，稀疏多模态测距数据可有效克服这些限制。

Method: 提出了一种多模态深度重建框架，利用极稀疏的测距数据（如汽车雷达或LiDAR），通过局部高斯过程建模在角度域中高效推断深度并量化不确定性，作为扩散模型的几何条件。

Result: 实验表明，使用稀疏测距重建的深度替代单目深度估计，显著提升了新视角视频生成的几何一致性和视觉质量。

Conclusion: 该研究通过结合稀疏多模态测距数据，显著提升了基于扩散的单图像新视角合成的几何一致性和视觉质量，证明了多模态感知在极端稀疏情况下的实际优势。

Abstract: Diffusion-based approaches have recently demonstrated strong performance for single-image novel view synthesis by conditioning generative models on geometry inferred from monocular depth estimation. However, in practice, the quality and consistency of the synthesized views are fundamentally limited by the reliability of the underlying depth estimates, which are often fragile under low texture, adverse weather, and occlusion-heavy real-world conditions. In this work, we show that incorporating sparse multimodal range measurements provides a simple yet effective way to overcome these limitations. We introduce a multimodal depth reconstruction framework that leverages extremely sparse range sensing data, such as automotive radar or LiDAR, to produce dense depth maps that serve as robust geometric conditioning for diffusion-based novel view synthesis. Our approach models depth in an angular domain using a localized Gaussian Process formulation, enabling computationally efficient inference while explicitly quantifying uncertainty in regions with limited observations. The reconstructed depth and uncertainty are used as a drop-in replacement for monocular depth estimators in existing diffusion-based rendering pipelines, without modifying the generative model itself. Experiments on real-world multimodal driving scenes demonstrate that replacing vision-only depth with our sparse range-based reconstruction substantially improves both geometric consistency and visual quality in single-image novel-view video generation. These results highlight the importance of reliable geometric priors for diffusion-based view synthesis and demonstrate the practical benefits of multimodal sensing even at extreme levels of sparsity.

</details>


### [13] [ZACH-ViT: Regime-Dependent Inductive Bias in Compact Vision Transformers for Medical Imaging](https://arxiv.org/abs/2602.17929)
*Athanasios Angelakis*

Main category: cs.CV

TL;DR: ZACH-ViT是一种紧凑的Vision Transformer，移除位置嵌入和[CLS]标记，通过全局平均池化实现排列不变性，在医学影像任务中表现优异，适合资源受限环境。


<details>
  <summary>Details</summary>
Motivation: 针对医学影像和边缘临床系统中空间布局信息弱或不一致的问题，设计一种无需位置嵌入和[CLS]标记的紧凑Vision Transformer。

Method: ZACH-ViT采用全局平均池化处理补丁表示，移除位置嵌入和[CLS]标记，并通过自适应残差投影保持训练稳定性。

Result: 在七个MedMNIST数据集上评估，ZACH-ViT（0.25M参数）在BloodMNIST上表现最佳，在PathMNIST上与TransMIL竞争，但在具有强解剖先验的数据集（如OCTMNIST、OrganAMNIST）上优势减弱。

Conclusion: ZACH-ViT通过移除位置嵌入和[CLS]标记，实现了排列不变性，并在资源受限的临床环境中展现出竞争力，强调了架构归纳偏差与数据结构对齐的重要性。

Abstract: Vision Transformers rely on positional embeddings and class tokens that encode fixed spatial priors. While effective for natural images, these priors may hinder generalization when spatial layout is weakly informative or inconsistent, a frequent condition in medical imaging and edge-deployed clinical systems. We introduce ZACH-ViT (Zero-token Adaptive Compact Hierarchical Vision Transformer), a compact Vision Transformer that removes both positional embeddings and the [CLS] token, achieving permutation invariance through global average pooling over patch representations. The term "Zero-token" specifically refers to removing the dedicated [CLS] aggregation token and positional embeddings; patch tokens remain unchanged and are processed normally. Adaptive residual projections preserve training stability in compact configurations while maintaining a strict parameter budget.
  Evaluation is performed across seven MedMNIST datasets spanning binary and multi-class tasks under a strict few-shot protocol (50 samples per class, fixed hyperparameters, five random seeds). The empirical analysis demonstrates regime-dependent behavior: ZACH-ViT (0.25M parameters, trained from scratch) achieves its strongest advantage on BloodMNIST and remains competitive with TransMIL on PathMNIST, while its relative advantage decreases on datasets with strong anatomical priors (OCTMNIST, OrganAMNIST), consistent with the architectural hypothesis. These findings support the view that aligning architectural inductive bias with data structure can be more important than pursuing universal benchmark dominance. Despite its minimal size and lack of pretraining, ZACH-ViT achieves competitive performance while maintaining sub-second inference times, supporting deployment in resource-constrained clinical environments. Code and models are available at https://github.com/Bluesman79/ZACH-ViT.

</details>


### [14] [ROCKET: Residual-Oriented Multi-Layer Alignment for Spatially-Aware Vision-Language-Action Models](https://arxiv.org/abs/2602.17951)
*Guoheng Sun,Tingting Du,Kaixi Feng,Chenxiang Luo,Xingguo Ding,Zheyu Shen,Ziyao Wang,Yexiao He,Ang Li*

Main category: cs.CV

TL;DR: ROCKET通过残差导向的多层对齐框架，高效提升VLA模型的3D理解能力，计算成本低且性能优越。


<details>
  <summary>Details</summary>
Motivation: 现有VLA模型通常基于2D数据预训练，缺乏3D空间理解能力，且现有多层对齐方法易导致梯度干扰。

Method: ROCKET采用共享投影器进行多层对齐，通过层不变映射减少梯度冲突，并引入Matryoshka式稀疏激活方案平衡多损失。

Result: ROCKET仅需约4%的计算预算，在LIBERO上达到98.5%的最先进成功率，并在多个数据集和VLA模型中表现优异。

Conclusion: ROCKET通过残差导向的多层表示对齐框架，显著提升了视觉-语言-动作（VLA）模型的3D空间理解能力，同时在计算效率和性能上均优于现有方法。

Abstract: Vision-Language-Action (VLA) models enable instruction-following robotic manipulation, but they are typically pretrained on 2D data and lack 3D spatial understanding. An effective approach is representation alignment, where a strong vision foundation model is used to guide a 2D VLA model. However, existing methods usually apply supervision at only a single layer, failing to fully exploit the rich information distributed across depth; meanwhile, naïve multi-layer alignment can cause gradient interference. We introduce ROCKET, a residual-oriented multi-layer representation alignment framework that formulates multi-layer alignment as aligning one residual stream to another. Concretely, ROCKET employs a shared projector to align multiple layers of the VLA backbone with multiple layers of a powerful 3D vision foundation model via a layer-invariant mapping, which reduces gradient conflicts. We provide both theoretical justification and empirical analyses showing that a shared projector is sufficient and outperforms prior designs, and further propose a Matryoshka-style sparse activation scheme for the shared projector to balance multiple alignment losses. Our experiments show that, combined with a training-free layer selection strategy, ROCKET requires only about 4% of the compute budget while achieving 98.5% state-of-the-art success rate on LIBERO. We further demonstrate the superior performance of ROCKET across LIBERO-Plus and RoboTwin, as well as multiple VLA models. The code and model weights can be found at https://github.com/CASE-Lab-UMD/ROCKET-VLA.

</details>


### [15] [Image Quality Assessment: Exploring Quality Awareness via Memory-driven Distortion Patterns Matching](https://arxiv.org/abs/2602.18000)
*Xuting Lan,Mingliang Zhou,Xuekai Wei,Jielu Yan,Yueting Huang,Huayan Pu,Jun Luo,Weijia Jia*

Main category: cs.CV

TL;DR: MQAF通过记忆库存储失真模式，动态切换评估策略，减少对参考图像的依赖，在无/有参考任务中均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有FR-IQA方法依赖参考图像质量，限制了在无理想参考源场景的应用。受人类视觉系统积累视觉记忆的启发，提出减少参考依赖的解决方案。

Method: 提出记忆驱动的质量感知框架（MQAF），建立记忆库存储失真模式，动态切换双模式评估策略：有参考时加权参考信息与记忆库比较；无参考时依赖记忆库推断质量。

Result: 实验表明，MQAF在多个数据集上优于现有方法，同时适应无参考和有参考任务。

Conclusion: MQAF通过记忆库存储失真模式，并动态切换双模式质量评估策略，减少对高质量参考图像的依赖，在无参考和有参考任务中均表现出色。

Abstract: Existing full-reference image quality assessment (FR-IQA) methods achieve high-precision evaluation by analysing feature differences between reference and distorted images. However, their performance is constrained by the quality of the reference image, which limits real-world applications where ideal reference sources are unavailable. Notably, the human visual system has the ability to accumulate visual memory, allowing image quality assessment on the basis of long-term memory storage. Inspired by this biological memory mechanism, we propose a memory-driven quality-aware framework (MQAF), which establishes a memory bank for storing distortion patterns and dynamically switches between dual-mode quality assessment strategies to reduce reliance on high-quality reference images. When reference images are available, MQAF obtains reference-guided quality scores by adaptively weighting reference information and comparing the distorted image with stored distortion patterns in the memory bank. When the reference image is absent, the framework relies on distortion patterns in the memory bank to infer image quality, enabling no-reference quality assessment (NR-IQA). The experimental results show that our method outperforms state-of-the-art approaches across multiple datasets while adapting to both no-reference and full-reference tasks.

</details>


### [16] [MUOT_3M: A 3 Million Frame Multimodal Underwater Benchmark and the MUTrack Tracking Method](https://arxiv.org/abs/2602.18006)
*Ahsan Baidar Bakht,Mohamad Alansari,Muhayy Ud Din,Muzammal Naseer,Sajid Javed,Irfan Hussain,Jiri Matas,Arif Mahmood*

Main category: cs.CV

TL;DR: MUOT_3M是首个伪多模态UOT基准数据集，包含3百万帧和多种模态；基于此提出的MUTrack跟踪器在性能和速度上均优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 水下目标跟踪（UOT）在海洋机器人、大规模生态监测和海洋探索中至关重要，但进展受到大型、多模态和多样化数据集稀缺的阻碍。现有基准数据集规模小且仅包含RGB数据，限制了在严重颜色失真、浑浊和低能见度条件下的鲁棒性。

Method: 提出了MUTrack，一种基于SAM的多模态到单模态跟踪器，包含视觉几何对齐、视觉语言融合和四级知识蒸馏，将多模态知识转移到单模态学生模型中。

Result: 在五个UOT基准测试中，MUTrack比最强的SOTA基线实现了高达8.40%的AUC和7.80%的精度提升，同时运行速度为24 FPS。

Conclusion: MUOT_3M和MUTrack为水下目标跟踪提供了可扩展、多模态训练且实际可部署的新基础。

Abstract: Underwater Object Tracking (UOT) is crucial for efficient marine robotics, large scale ecological monitoring, and ocean exploration; however, progress has been hindered by the scarcity of large, multimodal, and diverse datasets. Existing benchmarks remain small and RGB only, limiting robustness under severe color distortion, turbidity, and low visibility conditions. We introduce MUOT_3M, the first pseudo multimodal UOT benchmark comprising 3 million frames from 3,030 videos (27.8h) annotated with 32 tracking attributes, 677 fine grained classes, and synchronized RGB, estimated enhanced RGB, estimated depth, and language modalities validated by a marine biologist. Building upon MUOT_3M, we propose MUTrack, a SAM-based multimodal to unimodal tracker featuring visual geometric alignment, vision language fusion, and four level knowledge distillation that transfers multimodal knowledge into a unimodal student model. Extensive evaluations across five UOT benchmarks demonstrate that MUTrack achieves up to 8.40% higher AUC and 7.80% higher precision than the strongest SOTA baselines while running at 24 FPS. MUOT_3M and MUTrack establish a new foundation for scalable, multimodally trained yet practically deployable underwater tracking.

</details>


### [17] [DeepSVU: Towards In-depth Security-oriented Video Understanding via Unified Physical-world Regularized MoE](https://arxiv.org/abs/2602.18019)
*Yujie Jin,Wenxin Zhang,Jingjing Wang,Guodong Zhou*

Main category: cs.CV

TL;DR: 本文提出DeepSVU任务和UPRM方法，通过建模物理世界信息提升威胁原因分析能力，实验证明其优越性。


<details>
  <summary>Details</summary>
Motivation: 现有安全导向视频理解（SVU）研究主要关注威胁检测和定位，缺乏对威胁原因生成和评估的能力，因此提出了深度安全导向视频理解（DeepSVU）任务。

Method: 提出了一种统一的物理世界正则化混合专家（UPRM）方法，包含两个关键组件：统一物理世界增强混合专家（UPE）块和物理世界权衡正则化器（PTR）。

Result: 在DeepSVU指令数据集（UCF-C指令和CUVA指令）上的实验表明，UPRM优于多种先进的视频-LLM和非VLM方法。

Conclusion: UPRM方法通过整合粗粒度到细粒度的物理世界信息，显著提升了DeepSVU任务的性能，证明了其在捕捉此类信息方面的有效性。

Abstract: In the literature, prior research on Security-oriented Video Understanding (SVU) has predominantly focused on detecting and localize the threats (e.g., shootings, robberies) in videos, while largely lacking the effective capability to generate and evaluate the threat causes. Motivated by these gaps, this paper introduces a new chat paradigm SVU task, i.e., In-depth Security-oriented Video Understanding (DeepSVU), which aims to not only identify and locate the threats but also attribute and evaluate the causes threatening segments. Furthermore, this paper reveals two key challenges in the proposed task: 1) how to effectively model the coarse-to-fine physical-world information (e.g., human behavior, object interactions and background context) to boost the DeepSVU task; and 2) how to adaptively trade off these factors. To tackle these challenges, this paper proposes a new Unified Physical-world Regularized MoE (UPRM) approach. Specifically, UPRM incorporates two key components: the Unified Physical-world Enhanced MoE (UPE) Block and the Physical-world Trade-off Regularizer (PTR), to address the above two challenges, respectively. Extensive experiments conduct on our DeepSVU instructions datasets (i.e., UCF-C instructions and CUVA instructions) demonstrate that UPRM outperforms several advanced Video-LLMs as well as non-VLM approaches. Such information.These justify the importance of the coarse-to-fine physical-world information in the DeepSVU task and demonstrate the effectiveness of our UPRM in capturing such information.

</details>


### [18] [Towards LLM-centric Affective Visual Customization via Efficient and Precise Emotion Manipulating](https://arxiv.org/abs/2602.18016)
*Jiamin Luo,Xuqian Gu,Jingjing Wang,Jiahong Lu*

Main category: cs.CV

TL;DR: 本文提出L-AVC任务及EPEM方法，通过EIC和PER模块高效精确地编辑图像情感，实验证明其优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有视觉定制研究主要关注客观控制信号与编辑图像的匹配，忽略了主观情感内容，并缺乏通用的情感视觉定制基础模型。因此，本文提出L-AVC任务，旨在通过多模态LLM生成图像并修改其主观情感。

Method: 本文提出了一种高效精确的情感操作方法（EPEM），包括高效情感语义转换模块（EIC）和精确情感无关内容保留模块（PER）。

Result: 在构建的L-AVC数据集上的综合实验评估表明，EPEM方法在L-AVC任务中优于多个先进基线，验证了情感信息的重要性及EPEM的有效性。

Conclusion: 本文通过提出的EPEM方法，证明了情感信息在L-AVC任务中的重要性，以及EPEM在高效精确操作情感信息方面的有效性。

Abstract: Previous studies on visual customization primarily rely on the objective alignment between various control signals (e.g., language, layout and canny) and the edited images, which largely ignore the subjective emotional contents, and more importantly lack general-purpose foundation models for affective visual customization. With this in mind, this paper proposes an LLM-centric Affective Visual Customization (L-AVC) task, which focuses on generating images within modifying their subjective emotions via Multimodal LLM. Further, this paper contends that how to make the model efficiently align emotion conversion in semantics (named inter-emotion semantic conversion) and how to precisely retain emotion-agnostic contents (named exter-emotion semantic retaining) are rather important and challenging in this L-AVC task. To this end, this paper proposes an Efficient and Precise Emotion Manipulating approach for editing subjective emotions in images. Specifically, an Efficient Inter-emotion Converting (EIC) module is tailored to make the LLM efficiently align emotion conversion in semantics before and after editing, followed by a Precise Exter-emotion Retaining (PER) module to precisely retain the emotion-agnostic contents. Comprehensive experimental evaluations on our constructed L-AVC dataset demonstrate the great advantage of the proposed EPEM approach to the L-AVC task over several state-of-the-art baselines. This justifies the importance of emotion information for L-AVC and the effectiveness of EPEM in efficiently and precisely manipulating such information.

</details>


### [19] [Dual-Channel Attention Guidance for Training-Free Image Editing Control in Diffusion Transformers](https://arxiv.org/abs/2602.18022)
*Guandong Li,Mengxia Ye*

Main category: cs.CV

TL;DR: DCAG通过同时操纵Key和Value通道，实现了更精确的图像编辑控制，显著提升了编辑效果。


<details>
  <summary>Details</summary>
Motivation: 现有方法仅关注Key空间来调节注意力路由，忽视了Value空间的特征聚合作用，导致编辑强度控制不足。

Method: 提出Dual-Channel Attention Guidance (DCAG)框架，同时操纵Key和Value通道，利用Key通道的非线性softmax函数作为粗调控制，Value通道的线性加权求和作为细调补充。

Result: 在PIE-Bench基准测试中，DCAG在所有保真度指标上均优于仅使用Key通道的方法，特别是在对象删除和添加任务中表现显著（LPIPS分别降低4.9%和3.2%）。

Conclusion: DCAG框架通过同时操纵Key和Value通道，实现了比单一通道方法更精确的编辑-保真度权衡，显著提升了局部编辑任务的性能。

Abstract: Training-free control over editing intensity is a critical requirement for diffusion-based image editing models built on the Diffusion Transformer (DiT) architecture. Existing attention manipulation methods focus exclusively on the Key space to modulate attention routing, leaving the Value space -- which governs feature aggregation -- entirely unexploited. In this paper, we first reveal that both Key and Value projections in DiT's multi-modal attention layers exhibit a pronounced bias-delta structure, where token embeddings cluster tightly around a layer-specific bias vector. Building on this observation, we propose Dual-Channel Attention Guidance (DCAG), a training-free framework that simultaneously manipulates both the Key channel (controlling where to attend) and the Value channel (controlling what to aggregate). We provide a theoretical analysis showing that the Key channel operates through the nonlinear softmax function, acting as a coarse control knob, while the Value channel operates through linear weighted summation, serving as a fine-grained complement. Together, the two-dimensional parameter space $(δ_k, δ_v)$ enables more precise editing-fidelity trade-offs than any single-channel method. Extensive experiments on the PIE-Bench benchmark (700 images, 10 editing categories) demonstrate that DCAG consistently outperforms Key-only guidance across all fidelity metrics, with the most significant improvements observed in localized editing tasks such as object deletion (4.9% LPIPS reduction) and object addition (3.2% LPIPS reduction).

</details>


### [20] [DohaScript: A Large-Scale Multi-Writer Dataset for Continuous Handwritten Hindi Text](https://arxiv.org/abs/2602.18089)
*Kunwar Arpit Singh,Ankush Prakash,Haroon R Lone*

Main category: cs.CV

TL;DR: DohaScript是一个大规模、多作者的手写印地语数据集，旨在解决现有资源不足的问题，支持手写识别、作者识别等任务。


<details>
  <summary>Details</summary>
Motivation: 现有的公开基准数据集在手写Devanagari文本方面严重不足，规模有限且缺乏多样性和复杂性，无法捕捉其连续、融合和结构复杂的特性。

Method: 研究人员收集了531位独特贡献者的手写印地文本，设计为一个平行的风格语料库，所有作者转录相同的六首传统印地语dohas（对联）。

Result: 基线实验展示了数据集的质量分离和对未见作者的强泛化能力，证明了其可靠性和实用价值。

Conclusion: DohaScript旨在作为一个标准化且可复现的基准，推动在低资源脚本环境下对连续手写Devanagari文本的研究。

Abstract: Despite having hundreds of millions of speakers, handwritten Devanagari text remains severely underrepresented in publicly available benchmark datasets. Existing resources are limited in scale, focus primarily on isolated characters or short words, and lack controlled lexical content and writer level diversity, which restricts their utility for modern data driven handwriting analysis. As a result, they fail to capture the continuous, fused, and structurally complex nature of Devanagari handwriting, where characters are connected through a shared shirorekha (horizontal headline) and exhibit rich ligature formations. We introduce DohaScript, a large scale, multi writer dataset of handwritten Hindi text collected from 531 unique contributors. The dataset is designed as a parallel stylistic corpus, in which all writers transcribe the same fixed set of six traditional Hindi dohas (couplets). This controlled design enables systematic analysis of writer specific variation independent of linguistic content, and supports tasks such as handwriting recognition, writer identification, style analysis, and generative modeling. The dataset is accompanied by non identifiable demographic metadata, rigorous quality curation based on objective sharpness and resolution criteria, and page level layout difficulty annotations that facilitate stratified benchmarking. Baseline experiments demonstrate clear quality separation and strong generalization to unseen writers, highlighting the dataset's reliability and practical value. DohaScript is intended to serve as a standardized and reproducible benchmark for advancing research on continuous handwritten Devanagari text in low resource script settings.

</details>


### [21] [UAOR: Uncertainty-aware Observation Reinjection for Vision-Language-Action Models](https://arxiv.org/abs/2602.18020)
*Jiabing Yang,Yixiang Chen,Yuan Xu,Peiyan Li,Xiangnan Wu,Zichen Wen,Bowen Fang,Tao Yu,Zhengbo Zhang,Yingda Li,Kai Wang,Jing Liu,Nianfeng Liu,Yan Huang,Liang Wang*

Main category: cs.CV

TL;DR: UAOR是一种无需训练的即插即用模块，通过不确定性感知的观察信息重新注入，提升VLA模型的性能和可靠性。


<details>
  <summary>Details</summary>
Motivation: 现有方法通常需要昂贵的额外数据收集和训练，而UAOR旨在无需这些成本的情况下提升VLA模型的精确性和可靠性。

Method: 通过测量动作熵（Action Entropy）识别语言模型层的高不确定性，并在下一层的FFN中通过注意力检索重新注入关键观察信息。

Result: 实验表明，UAOR能持续提升多种VLA模型在仿真和实际任务中的表现，且开销极小。

Conclusion: UAOR是一种无需额外训练、即插即用的模块，能显著提升VLA模型的性能，且无需额外观察线索或模块，具有广泛适用性。

Abstract: Vision-Language-Action (VLA) models leverage pretrained Vision-Language Models (VLMs) as backbones to map images and instructions to actions, demonstrating remarkable potential for generalizable robotic manipulation. To enhance performance, existing methods often incorporate extra observation cues (e.g., depth maps, point clouds) or auxiliary modules (e.g., object detectors, encoders) to enable more precise and reliable task execution, yet these typically require costly data collection and additional training. Inspired by the finding that Feed-Forward Network (FFN) in language models can act as "key-value memory", we propose Uncertainty-aware Observation Reinjection (UAOR), an effective, training-free and plug-and-play module for VLA models. Specifically, when the current language model layer exhibits high uncertainty, measured by Action Entropy, it reinjects key observation information into the next layer's Feed-Forward Network (FFN) through attention retrieval. This mechanism helps VLAs better attend to observations during inference, enabling more confident and faithful action generation. Comprehensive experiments show that our method consistently improves diverse VLA models across simulation and real-world tasks with minimal overhead. Notably, UAOR eliminates the need for additional observation cues or modules, making it a versatile and practical plug-in for existing VLA pipelines. The project page is at https://uaor.jiabingyang.cn.

</details>


### [22] [OODBench: Out-of-Distribution Benchmark for Large Vision-Language Models](https://arxiv.org/abs/2602.18094)
*Ling Lin,Yang Bai,Heng Su,Congcong Zhu,Yaoxing Wang,Yang Zhou,Huazhu Fu,Jingrun Chen*

Main category: cs.CV

TL;DR: 论文提出OODBench，一个自动化基准，用于评估VLMs处理OOD数据的能力，并展示当前模型在此类数据上的性能下降。同时，提出了一种新的评估指标，总结了重要发现以促进未来研究。


<details>
  <summary>Details</summary>
Motivation: 现有VLMs在大规模数据集上取得了显著进展，但通常假设数据是独立同分布的（IID）。然而，在现实场景中，这一假设往往不成立，且未能适当处理OOD对象可能带来安全风险。当前研究缺乏全面评估VLMs处理OOD数据性能的有效基准。

Method: 提出了OODBench，一种主要自动化且需要最少人工验证的方法，用于构建新基准并评估VLMs处理OOD数据的能力。OODBench包含40K实例级OOD实例-类别对。此外，提出了一种可靠的自动化评估指标，采用从基础到高级的提示问题来更全面地评估OOD数据对不同难度问题的影响。

Result: 研究表明，即使基础图像类别常见，当前VLMs在OODBench上仍表现出显著的性能下降。

Conclusion: 论文总结了关于OOD数据的重要发现和见解，以促进未来在OOD数据获取和评估方面的研究。

Abstract: Existing Visual-Language Models (VLMs) have achieved significant progress by being trained on massive-scale datasets, typically under the assumption that data are independent and identically distributed (IID). However, in real-world scenarios, it is often impractical to expect that all data processed by an AI system satisfy this assumption. Furthermore, failure to appropriately handle out-of-distribution (OOD) objects may introduce safety risks in real-world applications (e.g., autonomous driving or medical assistance). Unfortunately, current research has not yet provided valid benchmarks that can comprehensively assess the performance of VLMs in response to OOD data. Therefore, we propose OODBench, a predominantly automated method with minimal human verification, for constructing new benchmarks and evaluating the ability of VLMs to process OOD data. OODBench contains 40K instance-level OOD instance-category pairs, and we show that current VLMs still exhibit notable performance degradation on OODBench, even when the underlying image categories are common. In addition, we propose a reliable automated assessment metric that employs a Basic-to-Advanced Progression of prompted questions to assess the impact of OOD data on questions of varying difficulty more fully. Lastly, we summarize substantial findings and insights to facilitate future research in the acquisition and evaluation of OOD data.

</details>


### [23] [On the Adversarial Robustness of Discrete Image Tokenizers](https://arxiv.org/abs/2602.18252)
*Rishika Bhagwatkar,Irina Rish,Nicolas Flammarion,Francesco Croce*

Main category: cs.CV

TL;DR: 首次研究离散图像分词器的对抗攻击脆弱性，提出无监督对抗训练方法提升鲁棒性，适用于多种任务。


<details>
  <summary>Details</summary>
Motivation: 探索离散图像分词器在对抗攻击下的脆弱性，并研究其防御方法。

Method: 通过无监督对抗训练对流行的分词器进行微调，同时保持其他组件不变。

Result: 提出的方法显著提高了对无监督和端到端监督攻击的鲁棒性，并能很好地泛化到未见过的任务和数据上。

Conclusion: 该研究强调了分词器鲁棒性在下游任务中的关键作用，并为开发安全的多模态基础模型迈出了重要一步。

Abstract: Discrete image tokenizers encode visual inputs as sequences of tokens from a finite vocabulary and are gaining popularity in multimodal systems, including encoder-only, encoder-decoder, and decoder-only models. However, unlike CLIP encoders, their vulnerability to adversarial attacks has not been explored. Ours being the first work studying this topic, we first formulate attacks that aim to perturb the features extracted by discrete tokenizers, and thus change the extracted tokens. These attacks are computationally efficient, application-agnostic, and effective across classification, multimodal retrieval, and captioning tasks. Second, to defend against this vulnerability, inspired by recent work on robust CLIP encoders, we fine-tune popular tokenizers with unsupervised adversarial training, keeping all other components frozen. While unsupervised and task-agnostic, our approach significantly improves robustness to both unsupervised and end-to-end supervised attacks and generalizes well to unseen tasks and data. Unlike supervised adversarial training, our approach can leverage unlabeled images, making it more versatile. Overall, our work highlights the critical role of tokenizer robustness in downstream tasks and presents an important step in the development of safe multimodal foundation models.

</details>


### [24] [Spatio-temporal Decoupled Knowledge Compensator for Few-Shot Action Recognition](https://arxiv.org/abs/2602.18043)
*Hongyu Qu,Xiangbo Shu,Rui Yan,Hailiang Gao,Wenguan Wang,Jinhui Tang*

Main category: cs.CV

TL;DR: DiST是一个创新的Few-Shot Action Recognition框架，通过解耦空间和时间知识并融合多粒度原型，显著提升了识别性能。


<details>
  <summary>Details</summary>
Motivation: 传统的Few-Shot Action Recognition方法仅依赖动作名称作为辅助上下文，其提供的背景知识有限，难以捕捉新颖动作的空间和时间概念。

Method: DiST框架包含分解阶段和融合阶段。在分解阶段，将动作名称解耦为多样化的时空属性描述；在融合阶段，通过空间/时间知识补偿器（SKC/TKC）发现具有判别性的对象级和帧级原型。

Result: 实验结果表明，DiST在五个标准FSAR数据集上取得了最先进的性能。

Conclusion: DiST框架通过利用大型语言模型提供的解耦空间和时间知识，在Few-Shot Action Recognition任务中实现了最先进的性能，证明了其在捕捉细粒度空间细节和多样时间模式方面的有效性。

Abstract: Few-Shot Action Recognition (FSAR) is a challenging task that requires recognizing novel action categories with a few labeled videos. Recent works typically apply semantically coarse category names as auxiliary contexts to guide the learning of discriminative visual features. However, such context provided by the action names is too limited to provide sufficient background knowledge for capturing novel spatial and temporal concepts in actions. In this paper, we propose DiST, an innovative Decomposition-incorporation framework for FSAR that makes use of decoupled Spatial and Temporal knowledge provided by large language models to learn expressive multi-granularity prototypes. In the decomposition stage, we decouple vanilla action names into diverse spatio-temporal attribute descriptions (action-related knowledge). Such commonsense knowledge complements semantic contexts from spatial and temporal perspectives. In the incorporation stage, we propose Spatial/Temporal Knowledge Compensators (SKC/TKC) to discover discriminative object-level and frame-level prototypes, respectively. In SKC, object-level prototypes adaptively aggregate important patch tokens under the guidance of spatial knowledge. Moreover, in TKC, frame-level prototypes utilize temporal attributes to assist in inter-frame temporal relation modeling. These learned prototypes thus provide transparency in capturing fine-grained spatial details and diverse temporal patterns. Experimental results show DiST achieves state-of-the-art results on five standard FSAR datasets.

</details>


### [25] [CityGuard: Graph-Aware Private Descriptors for Bias-Resilient Identity Search Across Urban Cameras](https://arxiv.org/abs/2602.18047)
*Rong Fu,Wenxin Zhang,Yibo Meng,Jia Yee Tan,Jiaxuan Lu,Rui Lu,Jiekai Wu,Zhaolu Kang,Simon Fong*

Main category: cs.CV

TL;DR: CityGuard是一个隐私保护的拓扑感知Transformer框架，通过分散自适应度量学习、空间条件注意力和差分隐私嵌入映射，有效解决了城市规模人员再识别问题。


<details>
  <summary>Details</summary>
Motivation: 解决分布式摄像头下人员再识别的外观变化问题，同时遵守数据保护规则，防止原始图像共享。

Method: 框架包含三个组件：分散自适应度量学习调整实例级边距；空间条件注意力注入粗略几何信息；差分隐私嵌入映射与紧凑近似索引结合。

Result: 在Market-1501等公开基准测试中，检索精度和查询吞吐量均有提升，验证了框架在隐私关键型城市身份匹配中的实用性。

Conclusion: CityGuard框架通过整合分散自适应度量学习、空间条件注意力和差分隐私嵌入映射，成功实现了在隐私保护下的城市规模人员再识别，平衡了隐私与实用性。

Abstract: City-scale person re-identification across distributed cameras must handle severe appearance changes from viewpoint, occlusion, and domain shift while complying with data protection rules that prevent sharing raw imagery. We introduce CityGuard, a topology-aware transformer for privacy-preserving identity retrieval in decentralized surveillance. The framework integrates three components. A dispersion-adaptive metric learner adjusts instance-level margins according to feature spread, increasing intra-class compactness. Spatially conditioned attention injects coarse geometry, such as GPS or deployment floor plans, into graph-based self-attention to enable projectively consistent cross-view alignment using only coarse geometric priors without requiring survey-grade calibration. Differentially private embedding maps are coupled with compact approximate indexes to support secure and cost-efficient deployment. Together these designs produce descriptors robust to viewpoint variation, occlusion, and domain shifts, and they enable a tunable balance between privacy and utility under rigorous differential-privacy accounting. Experiments on Market-1501 and additional public benchmarks, complemented by database-scale retrieval studies, show consistent gains in retrieval precision and query throughput over strong baselines, confirming the practicality of the framework for privacy-critical urban identity matching.

</details>


### [26] [Temporal Consistency-Aware Text-to-Motion Generation](https://arxiv.org/abs/2602.18057)
*Hongsong Wang,Wenjing Yan,Qiuxia Lai,Xin Geng*

Main category: cs.CV

TL;DR: TCA-T2M通过时间一致性感知的VQ-VAE和运动变换器，解决了文本到动作生成中的时间一致性问题，提升了生成动作的质量和物理合理性。


<details>
  <summary>Details</summary>
Motivation: 现有两阶段框架忽视了跨序列时间一致性，导致语义错位和物理上不可行的动作。TCA-T2M旨在解决这一问题。

Method: 提出了TCA-T2M框架，包括时间一致性感知的空间VQ-VAE（TCaS-VQ-VAE）用于跨序列时间对齐，以及掩码运动变换器用于文本条件运动生成，并加入运动学约束块以减少离散化伪影。

Result: 在HumanML3D和KIT-ML基准测试中，TCA-T2M实现了最先进的性能。

Conclusion: TCA-T2M框架通过引入时间一致性感知的VQ-VAE和运动变换器，显著提升了文本到动作生成的鲁棒性和连贯性，证明了时间一致性在T2M生成中的重要性。

Abstract: Text-to-Motion (T2M) generation aims to synthesize realistic human motion sequences from natural language descriptions. While two-stage frameworks leveraging discrete motion representations have advanced T2M research, they often neglect cross-sequence temporal consistency, i.e., the shared temporal structures present across different instances of the same action. This leads to semantic misalignments and physically implausible motions. To address this limitation, we propose TCA-T2M, a framework for temporal consistency-aware T2M generation. Our approach introduces a temporal consistency-aware spatial VQ-VAE (TCaS-VQ-VAE) for cross-sequence temporal alignment, coupled with a masked motion transformer for text-conditioned motion generation. Additionally, a kinematic constraint block mitigates discretization artifacts to ensure physical plausibility. Experiments on HumanML3D and KIT-ML benchmarks demonstrate that TCA-T2M achieves state-of-the-art performance, highlighting the importance of temporal consistency in robust and coherent T2M generation.

</details>


### [27] [3DMedAgent: Unified Perception-to-Understanding for 3D Medical Analysis](https://arxiv.org/abs/2602.18064)
*Ziyue Wang,Linghan Cai,Chang Han Low,Haofeng Liu,Junde Wu,Jingyu Wang,Rui Wang,Lei Song,Jiang Bian,Jingjing Fu,Yueming Jin*

Main category: cs.CV

TL;DR: 3DMedAgent是一种统一代理，使2D MLLMs无需3D微调即可执行通用3D CT分析，通过分解任务和结构化记忆实现高效推理，性能优于现有方法。


<details>
  <summary>Details</summary>
Motivation: 现有3D分析方法要么孤立任务特定建模，要么任务不可知端到端范式，阻碍了感知证据的系统积累；同时，多模态大语言模型（MLLMs）的2D导向设计限制了其对体积医学数据的感知和分析能力。

Method: 3DMedAgent通过灵活的MLLM代理协调异构工具，逐步将复杂3D分析分解为可处理的子任务，从全局到局部视图，从3D体积到2D切片，从视觉证据到结构化文本表示。

Result: 在40多个任务上的实验表明，3DMedAgent始终优于通用、医学和3D特定的MLLMs，展示了其在3D胸部影像中从感知到理解的统一能力。

Conclusion: 3DMedAgent通过协调异构视觉和文本工具，实现了无需3D特定微调的通用3D CT分析，显著优于现有方法，为通用3D临床助手提供了可扩展路径。

Abstract: 3D CT analysis spans a continuum from low-level perception to high-level clinical understanding. Existing 3D-oriented analysis methods adopt either isolated task-specific modeling or task-agnostic end-to-end paradigms to produce one-hop outputs, impeding the systematic accumulation of perceptual evidence for downstream reasoning. In parallel, recent multimodal large language models (MLLMs) exhibit improved visual perception and can integrate visual and textual information effectively, yet their predominantly 2D-oriented designs fundamentally limit their ability to perceive and analyze volumetric medical data. To bridge this gap, we propose 3DMedAgent, a unified agent that enables 2D MLLMs to perform general 3D CT analysis without 3D-specific fine-tuning. 3DMedAgent coordinates heterogeneous visual and textual tools through a flexible MLLM agent, progressively decomposing complex 3D analysis into tractable subtasks that transition from global to regional views, from 3D volumes to informative 2D slices, and from visual evidence to structured textual representations. Central to this design, 3DMedAgent maintains a long-term structured memory that aggregates intermediate tool outputs and supports query-adaptive, evidence-driven multi-step reasoning. We further introduce the DeepChestVQA benchmark for evaluating unified perception-to-understanding capabilities in 3D thoracic imaging. Experiments across over 40 tasks demonstrate that 3DMedAgent consistently outperforms general, medical, and 3D-specific MLLMs, highlighting a scalable path toward general-purpose 3D clinical assistants.Code and data are available at \href{https://github.com/jinlab-imvr/3DMedAgent}{https://github.com/jinlab-imvr/3DMedAgent}.

</details>


### [28] [Faster Training, Fewer Labels: Self-Supervised Pretraining for Fine-Grained BEV Segmentation](https://arxiv.org/abs/2602.18066)
*Daniel Busch,Christian Bohn,Thomas Kurbiel,Klaus Friedrichs,Richard Meyes,Tobias Meisen*

Main category: cs.CV

TL;DR: 两阶段训练策略（自监督预训练+监督微调）减少标注数据和训练时间，提升BEV分割性能。


<details>
  <summary>Details</summary>
Motivation: 解决当前多摄像头方法依赖昂贵且标注不一致的BEV真实数据的问题。

Method: 采用两阶段训练策略：自监督预训练阶段使用Mask2Former生成的多视角语义伪标签和时序损失；监督微调阶段仅需50%的数据集。

Result: 在nuScenes数据集上，性能提升（最高+2.5pp mIoU），同时减少50%标注数据和三分之二的训练时间。

Conclusion: 该方法通过自监督预训练和监督微调两阶段策略，显著减少了标注数据的使用和训练时间，同时提升了BEV分割性能，为减少标注需求的自动驾驶感知提供了可扩展的路径。

Abstract: Dense Bird's Eye View (BEV) semantic maps are central to autonomous driving, yet current multi-camera methods depend on costly, inconsistently annotated BEV ground truth. We address this limitation with a two-phase training strategy for fine-grained road marking segmentation that removes full supervision during pretraining and halves the amount of training data during fine-tuning while still outperforming the comparable supervised baseline model. During the self-supervised pretraining, BEVFormer predictions are differentiably reprojected into the image plane and trained against multi-view semantic pseudo-labels generated by the widely used semantic segmentation model Mask2Former. A temporal loss encourages consistency across frames. The subsequent supervised fine-tuning phase requires only 50% of the dataset and significantly less training time. With our method, the fine-tuning benefits from rich priors learned during pretraining boosting the performance and BEV segmentation quality (up to +2.5pp mIoU over the fully supervised baseline) on nuScenes. It simultaneously halves the usage of annotation data and reduces total training time by up to two thirds. The results demonstrate that differentiable reprojection plus camera perspective pseudo labels yields transferable BEV features and a scalable path toward reduced-label autonomous perception.

</details>


### [29] [Comparative Assessment of Multimodal Earth Observation Data for Soil Moisture Estimation](https://arxiv.org/abs/2602.18083)
*Ioannis Kontogiorgakis,Athanasios Askitopoulos,Iason Tsardanidis,Dimitrios Bormpoudakis,Ilias Tsoumas,Fotios Balampanis,Charalampos Kontoes*

Main category: cs.CV

TL;DR: 提出一种结合多源数据的10米分辨率土壤湿度估算框架，验证了传统特征工程在稀疏数据回归任务中的竞争力，为泛欧田间监测提供高效方案。


<details>
  <summary>Details</summary>
Motivation: 精确的土壤湿度估算对精准农业、水资源管理和气候监测至关重要，但现有卫星土壤湿度产品分辨率过低（>1公里），无法满足农场级应用需求。

Method: 结合Sentinel-1 SAR、Sentinel-2光学影像和ERA-5再分析数据，通过机器学习进行高分辨率（10米）土壤湿度估算。使用113个国际土壤湿度网络（ISMN）站点进行空间交叉验证，确保地理泛化性。

Result: 混合时间匹配（Sentinel-2当前日采集与Sentinel-1下降轨道）达到R^2=0.514，10天ERA5回溯窗口将性能提升至R^2=0.518。基础模型（Prithvi）嵌入相比传统手工特征改进微乎其微（R^2=0.515 vs. 0.514）。

Conclusion: 研究发现，结合领域特定的光谱指数和基于树的集成方法，为泛欧地区田间尺度的土壤湿度监测提供了一个实用且计算高效的解决方案。

Abstract: Accurate soil moisture (SM) estimation is critical for precision agriculture, water resources management and climate monitoring. Yet, existing satellite SM products are too coarse (>1km) for farm-level applications. We present a high-resolution (10m) SM estimation framework for vegetated areas across Europe, combining Sentinel-1 SAR, Sentinel-2 optical imagery and ERA-5 reanalysis data through machine learning. Using 113 International Soil Moisture Network (ISMN) stations spanning diverse vegetated areas, we compare modality combinations with temporal parameterizations, using spatial cross-validation, to ensure geographic generalization. We also evaluate whether foundation model embeddings from IBM-NASA's Prithvi model improve upon traditional hand-crafted spectral features. Results demonstrate that hybrid temporal matching - Sentinel-2 current-day acquisitions with Sentinel-1 descending orbit - achieves R^2=0.514, with 10-day ERA5 lookback window improving performance to R^2=0.518. Foundation model (Prithvi) embeddings provide negligible improvement over hand-crafted features (R^2=0.515 vs. 0.514), indicating traditional feature engineering remains highly competitive for sparse-data regression tasks. Our findings suggest that domain-specific spectral indices combined with tree-based ensemble methods offer a practical and computationally efficient solution for operational pan-European field-scale soil moisture monitoring.

</details>


### [30] [Predict to Skip: Linear Multistep Feature Forecasting for Efficient Diffusion Transformers](https://arxiv.org/abs/2602.18093)
*Hanshuai Cui,Zhiqing Tang,Qianli Ma,Zhi Yao,Weijia Jia*

Main category: cs.CV

TL;DR: PrediT通过线性多步预测和动态步长调制，高效加速DiT模型推理，实验验证其显著降低延迟且保持生成质量。


<details>
  <summary>Details</summary>
Motivation: DiT模型的迭代去噪过程计算成本高，现有训练无关加速方法因特征重用可能导致潜在漂移和视觉退化，需更高效的加速方案。

Method: 提出PrediT框架，将特征预测建模为线性多步问题，结合历史信息预测未来输出，并通过校正器在高动态区域防止误差累积，动态步长调制机制自适应调整预测步长。

Result: 实验表明，PrediT在多种基于DiT的图像和视频生成模型中实现了高达5.54倍的延迟降低，且质量退化可忽略。

Conclusion: PrediT框架通过线性多步预测和动态步长调制机制，在保持生成质量的同时显著加速了DiT模型的推理过程，实验验证了其高效性和有效性。

Abstract: Diffusion Transformers (DiT) have emerged as a widely adopted backbone for high-fidelity image and video generation, yet their iterative denoising process incurs high computational costs. Existing training-free acceleration methods rely on feature caching and reuse under the assumption of temporal stability. However, reusing features for multiple steps may lead to latent drift and visual degradation. We observe that model outputs evolve smoothly along much of the diffusion trajectory, enabling principled predictions rather than naive reuse. Based on this insight, we propose \textbf{PrediT}, a training-free acceleration framework that formulates feature prediction as a linear multistep problem. We employ classical linear multistep methods to forecast future model outputs from historical information, combined with a corrector that activates in high-dynamics regions to prevent error accumulation. A dynamic step modulation mechanism adaptively adjusts the prediction horizon by monitoring the feature change rate. Together, these components enable substantial acceleration while preserving generation fidelity. Extensive experiments validate that our method achieves up to $5.54\times$ latency reduction across various DiT-based image and video generation models, while incurring negligible quality degradation.

</details>


### [31] [CapNav: Benchmarking Vision Language Models on Capability-conditioned Indoor Navigation](https://arxiv.org/abs/2602.18424)
*Xia Su,Ruiqi Chen,Benlin Liu,Jingwei Ma,Zonglin Di,Ranjay Krishna,Jon Froehlich*

Main category: cs.CV

TL;DR: CapNav基准测试了视觉语言模型在考虑代理具体移动约束时的导航能力，发现现有模型在严格约束下表现不佳，需改进空间推理能力。


<details>
  <summary>Details</summary>
Motivation: 研究视觉语言模型在考虑具体代理移动约束时的导航能力，以弥补现有导航任务中对代理能力差异的忽视。

Method: 引入了Capability-Conditioned Navigation (CapNav)基准，定义了5种代表性代理，并在45个真实室内场景中设计了473个导航任务和2365个QA对。

Result: 评估了13个现代视觉语言模型，发现随着移动约束的增加，导航性能显著下降，且现有模型在处理需要空间推理的障碍类型时表现不佳。

Conclusion: CapNav揭示了当前视觉语言模型在考虑具体移动约束时的导航性能下降问题，并指出了未来模型在空间推理能力上的改进方向。

Abstract: Vision-Language Models (VLMs) have shown remarkable progress in Vision-Language Navigation (VLN), offering new possibilities for navigation decision-making that could benefit both robotic platforms and human users. However, real-world navigation is inherently conditioned by the agent's mobility constraints. For example, a sweeping robot cannot traverse stairs, while a quadruped can. We introduce Capability-Conditioned Navigation (CapNav), a benchmark designed to evaluate how well VLMs can navigate complex indoor spaces given an agent's specific physical and operational capabilities. CapNav defines five representative human and robot agents, each described with physical dimensions, mobility capabilities, and environmental interaction abilities. CapNav provides 45 real-world indoor scenes, 473 navigation tasks, and 2365 QA pairs to test if VLMs can traverse indoor environments based on agent capabilities. We evaluate 13 modern VLMs and find that current VLM's navigation performance drops sharply as mobility constraints tighten, and that even state-of-the-art models struggle with obstacle types that require reasoning on spatial dimensions. We conclude by discussing the implications for capability-aware navigation and the opportunities for advancing embodied spatial reasoning in future VLMs. The benchmark is available at https://github.com/makeabilitylab/CapNav

</details>


### [32] [Evaluating Graphical Perception Capabilities of Vision Transformers](https://arxiv.org/abs/2602.18178)
*Poonam Poonam,Pere-Pau Vázquez,Timo Ropinski*

Main category: cs.CV

TL;DR: ViTs在图形感知任务中表现不如人类，尽管在通用视觉任务中表现优异。


<details>
  <summary>Details</summary>
Motivation: 探索ViTs在图形感知任务中的表现，填补这一领域的研究空白，并与CNNs和人类感知进行对比。

Method: 通过一系列受控的图形感知任务，将ViTs与CNNs和人类参与者进行对比评估，任务设计灵感来源于Cleveland和McGill的基础研究。

Result: ViTs在通用视觉任务中表现强劲，但在可视化领域的图形感知任务中与人类感知的一致性有限。

Conclusion: ViTs虽然在通用视觉任务中表现优异，但在可视化领域与人类图形感知的一致性有限，这为ViTs在可视化系统和图形感知模型中的应用提供了重要考量。

Abstract: Vision Transformers, ViTs, have emerged as a powerful alternative to convolutional neural networks, CNNs, in a variety of image-based tasks. While CNNs have previously been evaluated for their ability to perform graphical perception tasks, which are essential for interpreting visualizations, the perceptual capabilities of ViTs remain largely unexplored. In this work, we investigate the performance of ViTs in elementary visual judgment tasks inspired by the foundational studies of Cleveland and McGill, which quantified the accuracy of human perception across different visual encodings. Inspired by their study, we benchmark ViTs against CNNs and human participants in a series of controlled graphical perception tasks. Our results reveal that, although ViTs demonstrate strong performance in general vision tasks, their alignment with human-like graphical perception in the visualization domain is limited. This study highlights key perceptual gaps and points to important considerations for the application of ViTs in visualization systems and graphical perceptual modeling.

</details>


### [33] [BLM-Guard: Explainable Multimodal Ad Moderation with Chain-of-Thought and Policy-Aligned Rewards](https://arxiv.org/abs/2602.18193)
*Yiran Yang,Zhaowei Liu,Yuan Yuan,Yukun Song,Xiong Ma,Yinghao Song,Xiangji Zeng,Lu Sun,Yulu Wang,Hai Zhou,Shuai Cui,Zhaohan Gong,Jiefei Zhang*

Main category: cs.CV

TL;DR: BLM-Guard 是一个融合推理与策略的内容审核框架，通过强化学习优化，显著提升了对欺骗性广告的检测能力。


<details>
  <summary>Details</summary>
Motivation: 短视频平台上的多模态广告存在欺骗性视觉、语音和字幕内容，需要更细粒度的、基于策略的内容审核机制。

Method: BLM-Guard 结合了 Chain-of-Thought 推理、基于规则的策略原则和批评引导的奖励机制，通过强化学习优化模型，并采用多任务架构处理模态内和跨模态的操纵。

Result: 实验结果表明，BLM-Guard 在真实短视频广告数据上表现优于强基线方法。

Conclusion: BLM-Guard 框架在短视频广告内容审核中表现出色，超越了现有基线方法，具有更高的准确性、一致性和泛化能力。

Abstract: Short-video platforms now host vast multimodal ads whose deceptive visuals, speech and subtitles demand finer-grained, policy-driven moderation than community safety filters. We present BLM-Guard, a content-audit framework for commercial ads that fuses Chain-of-Thought reasoning with rule-based policy principles and a critic-guided reward. A rule-driven ICoT data-synthesis pipeline jump-starts training by generating structured scene descriptions, reasoning chains and labels, cutting annotation costs. Reinforcement learning then refines the model using a composite reward balancing causal coherence with policy adherence. A multitask architecture models intra-modal manipulations (e.g., exaggerated imagery) and cross-modal mismatches (e.g., subtitle-speech drift), boosting robustness. Experiments on real short-video ads show BLM-Guard surpasses strong baselines in accuracy, consistency and generalization.

</details>


### [34] [A Self-Supervised Approach on Motion Calibration for Enhancing Physical Plausibility in Text-to-Motion](https://arxiv.org/abs/2602.18199)
*Gahyeon Shim,Soogeun Park,Hyemin Ahn*

Main category: cs.CV

TL;DR: DMC是一种后处理模块，通过自监督学习提升文本生成动作的物理合理性和语义一致性，实验证明其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决文本生成动作中语义对齐但物理不真实（如脚部漂浮）的问题。

Method: 提出了一种自监督和数据驱动的方法，通过DMC模块学习从故意扭曲的动作和原始文本描述中生成物理合理的动作。

Result: DMC显著提升了动作的物理合理性（如减少穿透33.0%），并在T2M和T2M-GPT上分别降低了FID分数42.74%和13.20%。

Conclusion: DMC作为一种后处理模块，能够有效提升文本到动作生成模型的物理合理性和语义一致性，适用于多种模型。

Abstract: Generating semantically aligned human motion from textual descriptions has made rapid progress, but ensuring both semantic and physical realism in motion remains a challenge. In this paper, we introduce the Distortion-aware Motion Calibrator (DMC), a post-hoc module that refines physically implausible motions (e.g., foot floating) while preserving semantic consistency with the original textual description. Rather than relying on complex physical modeling, we propose a self-supervised and data-driven approach, whereby DMC learns to obtain physically plausible motions when an intentionally distorted motion and the original textual descriptions are given as inputs. We evaluate DMC as a post-hoc module to improve motions obtained from various text-to-motion generation models and demonstrate its effectiveness in improving physical plausibility while enhancing semantic consistency. The experimental results show that DMC reduces FID score by 42.74% on T2M and 13.20% on T2M-GPT, while also achieving the highest R-Precision. When applied to high-quality models like MoMask, DMC improves the physical plausibility of motions by reducing penetration by 33.0% as well as adjusting floating artifacts closer to the ground-truth reference. These results highlight that DMC can serve as a promising post-hoc motion refinement framework for any kind of text-to-motion models by incorporating textual semantics and physical plausibility.

</details>


### [35] [DEIG: Detail-Enhanced Instance Generation with Fine-Grained Semantic Control](https://arxiv.org/abs/2602.18282)
*Shiyan Du,Conghan Yue,Xinyu Cheng,Dongyu Zhang*

Main category: cs.CV

TL;DR: DEIG是一种新型多实例生成框架，通过实例细节提取器和细节融合模块提升细粒度语义理解，实验证明其在多个基准测试中表现优异。


<details>
  <summary>Details</summary>
Motivation: 现有方法在细粒度语义理解方面存在不足，尤其是在处理复杂文本描述时。

Method: DEIG框架包含实例细节提取器（IDE）和细节融合模块（DFM），前者将文本编码器嵌入转换为紧凑的实例感知表示，后者通过基于实例的掩码注意力防止属性泄漏。

Result: 实验表明，DEIG在空间一致性、语义准确性和组合泛化能力方面均优于现有方法。

Conclusion: DEIG作为一种即插即用模块，可轻松集成到标准扩散流程中，显著提升了多实例生成的语义准确性和空间一致性。

Abstract: Multi-Instance Generation has advanced significantly in spatial placement and attribute binding. However, existing approaches still face challenges in fine-grained semantic understanding, particularly when dealing with complex textual descriptions. To overcome these limitations, we propose DEIG, a novel framework for fine-grained and controllable multi-instance generation. DEIG integrates an Instance Detail Extractor (IDE) that transforms text encoder embeddings into compact, instance-aware representations, and a Detail Fusion Module (DFM) that applies instance-based masked attention to prevent attribute leakage across instances. These components enable DEIG to generate visually coherent multi-instance scenes that precisely match rich, localized textual descriptions. To support fine-grained supervision, we construct a high-quality dataset with detailed, compositional instance captions generated by VLMs. We also introduce DEIG-Bench, a new benchmark with region-level annotations and multi-attribute prompts for both humans and objects. Experiments demonstrate that DEIG consistently outperforms existing approaches across multiple benchmarks in spatial consistency, semantic accuracy, and compositional generalization. Moreover, DEIG functions as a plug-and-play module, making it easily integrable into standard diffusion-based pipelines.

</details>


### [36] [Multi-Level Conditioning by Pairing Localized Text and Sketch for Fashion Image Generation](https://arxiv.org/abs/2602.18309)
*Ziyue Liu,Davide Talon,Federico Girella,Zanxi Ruan,Mattia Mondo,Loris Bazzani,Yiming Wang,Marco Cristani*

Main category: cs.CV

TL;DR: LOTS框架通过多级草图-文本对引导，提升时尚图像生成效果，优于现有技术，并公开了数据集和代码。


<details>
  <summary>Details</summary>
Motivation: 为了有效结合文本和视觉模态，需要在利用文本局部属性指导时保持草图视觉结构的一致性。

Method: LOTS框架采用多级条件阶段独立编码局部特征，并在扩散对引导阶段通过基于注意力的引导整合局部和全局条件。

Result: 实验表明，LOTS方法在保持全局结构一致性的同时，利用更丰富的局部语义指导，优于现有技术。

Conclusion: LOTS框架通过结合全局草图引导和多个局部草图-文本对，增强了时尚图像生成的效果，并在实验中优于现有技术。数据集、平台和代码已公开。

Abstract: Sketches offer designers a concise yet expressive medium for early-stage fashion ideation by specifying structure, silhouette, and spatial relationships, while textual descriptions complement sketches to convey material, color, and stylistic details. Effectively combining textual and visual modalities requires adherence to the sketch visual structure when leveraging the guidance of localized attributes from text. We present LOcalized Text and Sketch with multi-level guidance (LOTS), a framework that enhances fashion image generation by combining global sketch guidance with multiple localized sketch-text pairs. LOTS employs a Multi-level Conditioning Stage to independently encode local features within a shared latent space while maintaining global structural coordination. Then, the Diffusion Pair Guidance stage integrates both local and global conditioning via attention-based guidance within the diffusion model's multi-step denoising process. To validate our method, we develop Sketchy, the first fashion dataset where multiple text-sketch pairs are provided per image. Sketchy provides high-quality, clean sketches with a professional look and consistent structure. To assess robustness beyond this setting, we also include an "in the wild" split with non-expert sketches, featuring higher variability and imperfections. Experiments demonstrate that our method strengthens global structural adherence while leveraging richer localized semantic guidance, achieving improvement over state-of-the-art. The dataset, platform, and code are publicly available.

</details>


### [37] [Unifying Color and Lightness Correction with View-Adaptive Curve Adjustment for Robust 3D Novel View Synthesis](https://arxiv.org/abs/2602.18322)
*Ziteng Cui,Shuhong Liu,Xiaoyu Dong,Xuangeng Chu,Lin Gu,Ming-Hsuan Yang,Tatsuya Harada*

Main category: cs.CV

TL;DR: Luminance-GS++ 是一个基于3DGS的框架，通过全局和局部色彩校正解决多视角光照不一致问题，提升重建和渲染质量。


<details>
  <summary>Details</summary>
Motivation: 解决多视角捕获中因光照变化、传感器响应和ISP配置差异导致的光度和色彩不一致问题，提升3D新颖视图合成的重建和渲染质量。

Method: 采用基于3DGS的框架，结合全局视角自适应亮度调整和局部像素级残差细化，设计无监督目标以联合优化亮度校正和多视角几何与光度一致性。

Result: 在低光、过曝和复杂光照变化等挑战性场景中实现了最先进的性能，同时保持了实时渲染效率。

Conclusion: Luminance-GS++ 通过结合全局视角自适应亮度调整和局部像素级残差细化，有效解决了多视角捕获中的光照和色彩不一致问题，同时保持了3DGS的显式表达和实时渲染效率。

Abstract: High-quality image acquisition in real-world environments remains challenging due to complex illumination variations and inherent limitations of camera imaging pipelines. These issues are exacerbated in multi-view capture, where differences in lighting, sensor responses, and image signal processor (ISP) configurations introduce photometric and chromatic inconsistencies that violate the assumptions of photometric consistency underlying modern 3D novel view synthesis (NVS) methods, including Neural Radiance Fields (NeRF) and 3D Gaussian Splatting (3DGS), leading to degraded reconstruction and rendering quality. We propose Luminance-GS++, a 3DGS-based framework for robust NVS under diverse illumination conditions. Our method combines a globally view-adaptive lightness adjustment with a local pixel-wise residual refinement for precise color correction. We further design unsupervised objectives that jointly enforce lightness correction and multi-view geometric and photometric consistency. Extensive experiments demonstrate state-of-the-art performance across challenging scenarios, including low-light, overexposure, and complex luminance and chromatic variations. Unlike prior approaches that modify the underlying representation, our method preserves the explicit 3DGS formulation, improving reconstruction fidelity while maintaining real-time rendering efficiency.

</details>


### [38] [G-LoG Bi-filtration for Medical Image Classification](https://arxiv.org/abs/2602.18329)
*Qingsong Wang,Jiaxing He,Bingzhe Hou,Tieru Wu,Yang Cao,Cailing Yao*

Main category: cs.CV

TL;DR: G-LoG双过滤通过高斯-拉普拉斯算子增强医学图像边界，在多参数持久性分析中表现优异，拓扑特征可媲美深度学习模型。


<details>
  <summary>Details</summary>
Motivation: 通过构建更实用的过滤方法，检测医学图像的拓扑和几何特征，提升多参数持久性分析的效果。

Method: 利用高斯-拉普拉斯算子定义G-LoG双过滤，并在有界函数上证明持久性模块的稳定性。

Result: 实验表明G-LoG双过滤显著优于单参数过滤，且其生成的拓扑特征在简单MLP模型上表现接近复杂深度学习模型。

Conclusion: G-LoG双过滤在医学图像的多参数持久性模块中表现出色，其拓扑特征甚至能与复杂深度学习模型媲美。

Abstract: Building practical filtrations on objects to detect topological and geometric features is an important task in the field of Topological Data Analysis (TDA). In this paper, leveraging the ability of the Laplacian of Gaussian operator to enhance the boundaries of medical images, we define the G-LoG (Gaussian-Laplacian of Gaussian) bi-filtration to generate the features more suitable for multi-parameter persistence module. By modeling volumetric images as bounded functions, then we prove the interleaving distance on the persistence modules obtained from our bi-filtrations on the bounded functions is stable with respect to the maximum norm of the bounded functions. Finally, we conduct experiments on the MedMNIST dataset, comparing our bi-filtration against single-parameter filtration and the established deep learning baselines, including Google AutoML Vision, ResNet, AutoKeras and auto-sklearn. Experiments results demonstrate that our bi-filtration significantly outperforms single-parameter filtration. Notably, a simple Multi-Layer Perceptron (MLP) trained on the topological features generated by our bi-filtration achieves performance comparable to complex deep learning models trained on the original dataset.

</details>


### [39] [Self-Aware Object Detection via Degradation Manifolds](https://arxiv.org/abs/2602.18394)
*Stefan Becker,Simon Weiss,Wolfgang Hübner,Michael Arens*

Main category: cs.CV

TL;DR: 提出一种基于降解流形的自我感知框架，通过对比学习构建降解感知的特征空间几何，无需降解标签即可实现降解类型和严重程度的表示。


<details>
  <summary>Details</summary>
Motivation: 在安全关键场景中，对象检测器需要在输入超出其标称操作范围时具备自我评估能力。

Method: 通过多层对比学习训练一个轻量级的嵌入头，将具有相同降解组成的图像拉近，将不同降解配置的图像推远，从而在特征空间中构建降解感知的几何结构。

Result: 在合成腐蚀基准、跨数据集零样本迁移和自然天气引起的分布偏移实验中，表现出强大的纯净-降解可分离性和一致的跨检测器架构行为。

Conclusion: 降解感知的表示几何为对象检测提供了一种实用且与检测器无关的基础。

Abstract: Object detectors achieve strong performance under nominal imaging conditions but can fail silently when exposed to blur, noise, compression, adverse weather, or resolution changes. In safety-critical settings, it is therefore insufficient to produce predictions without assessing whether the input remains within the detector's nominal operating regime. We refer to this capability as self-aware object detection.
  We introduce a degradation-aware self-awareness framework based on degradation manifolds, which explicitly structure a detector's feature space according to image degradation rather than semantic content. Our method augments a standard detection backbone with a lightweight embedding head trained via multi-layer contrastive learning. Images sharing the same degradation composition are pulled together, while differing degradation configurations are pushed apart, yielding a geometrically organized representation that captures degradation type and severity without requiring degradation labels or explicit density modeling.
  To anchor the learned geometry, we estimate a pristine prototype from clean training embeddings, defining a nominal operating point in representation space. Self-awareness emerges as geometric deviation from this reference, providing an intrinsic, image-level signal of degradation-induced shift that is independent of detection confidence.
  Extensive experiments on synthetic corruption benchmarks, cross-dataset zero-shot transfer, and natural weather-induced distribution shifts demonstrate strong pristine-degraded separability, consistent behavior across multiple detector architectures, and robust generalization under semantic shift. These results suggest that degradation-aware representation geometry provides a practical and detector-agnostic foundation.

</details>


### [40] [Latent Equivariant Operators for Robust Object Recognition: Promise and Challenges](https://arxiv.org/abs/2602.18406)
*Minh Dinh,Stéphane Deny*

Main category: cs.CV

TL;DR: 论文探讨了如何利用学习等变算子的架构解决对称变换下的泛化问题，并在简单数据集上验证了其有效性，但指出在复杂数据集上的扩展仍具挑战性。


<details>
  <summary>Details</summary>
Motivation: 尽管深度学习在计算机视觉中取得了成功，但在识别经历了训练中罕见群对称变换的对象时仍存在困难。

Method: 使用旋转和平移的噪声MNIST简单数据集，展示了如何成功利用此类架构进行分布外分类。

Result: 这类架构可以成功用于分布外分类，克服了传统网络和等变网络的局限性。

Conclusion: 尽管在概念上吸引人，但将这些架构扩展到更复杂的数据集仍面临挑战。

Abstract: Despite the successes of deep learning in computer vision, difficulties persist in recognizing objects that have undergone group-symmetric transformations rarely seen during training-for example objects seen in unusual poses, scales, positions, or combinations thereof. Equivariant neural networks are a solution to the problem of generalizing across symmetric transformations, but require knowledge of transformations a priori. An alternative family of architectures proposes to earn equivariant operators in a latent space from examples of symmetric transformations. Here, using simple datasets of rotated and translated noisy MNIST, we illustrate how such architectures can successfully be harnessed for out-of-distribution classification, thus overcoming the limitations of both traditional and equivariant networks. While conceptually enticing, we discuss challenges ahead on the path of scaling these architectures to more complex datasets.

</details>


### [41] [Generated Reality: Human-centric World Simulation using Interactive Video Generation with Hand and Camera Control](https://arxiv.org/abs/2602.18422)
*Linxi Xie,Lisong C. Sun,Ashley Neall,Tong Wu,Shengqu Cai,Gordon Wetzstein*

Main category: cs.CV

TL;DR: 论文提出了一种结合头部和手部姿态控制的视频世界模型，提升了XR环境中的交互体验和任务表现。


<details>
  <summary>Details</summary>
Motivation: 当前的视频世界模型仅接受文本或键盘等粗粒度控制信号，限制了其在具身交互中的实用性。因此，需要一种能够响应用户真实世界运动的生成模型。

Method: 评估了现有的扩散变换器条件策略，并提出了一种有效的3D头部和手部控制机制。通过训练双向视频扩散模型教师，并将其蒸馏为因果交互系统，生成以自我为中心的虚拟环境。

Result: 通过人类受试者评估，生成的虚拟环境系统在任务表现和用户感知控制水平上均显著优于相关基线。

Conclusion: 论文提出了一种以人为中心的视频世界模型，通过结合头部和手部姿态控制，显著提升了用户在扩展现实（XR）环境中的交互体验和任务表现。

Abstract: Extended reality (XR) demands generative models that respond to users' tracked real-world motion, yet current video world models accept only coarse control signals such as text or keyboard input, limiting their utility for embodied interaction. We introduce a human-centric video world model that is conditioned on both tracked head pose and joint-level hand poses. For this purpose, we evaluate existing diffusion transformer conditioning strategies and propose an effective mechanism for 3D head and hand control, enabling dexterous hand--object interactions. We train a bidirectional video diffusion model teacher using this strategy and distill it into a causal, interactive system that generates egocentric virtual environments. We evaluate this generated reality system with human subjects and demonstrate improved task performance as well as a significantly higher level of perceived amount of control over the performed actions compared with relevant baselines.

</details>


### [42] [SARAH: Spatially Aware Real-time Agentic Humans](https://arxiv.org/abs/2602.18432)
*Evonne Ng,Siwei Zhang,Zhang Chen,Michael Zollhoefer,Alexander Richard*

Main category: cs.CV

TL;DR: 提出实时空间感知对话运动方法，结合因果Transformer和流匹配模型，实现高质量、低延迟的虚拟代理运动。


<details>
  <summary>Details</summary>
Motivation: 当前方法缺乏空间感知能力，无法满足虚拟代理在VR、远程呈现和数字人应用中对自然运动和交互的需求。

Method: 结合基于因果Transformer的VAE和流匹配模型，利用用户轨迹和音频条件，实现实时推理。引入注视评分机制和分类器无关指导，解耦学习与控制。

Result: 在Embody 3D数据集上，该方法实现了最先进的运动质量，速度超过300 FPS，比非因果基线快3倍，并成功在实时VR系统中验证。

Conclusion: 该研究实现了首个实时、完全因果的空间感知对话运动方法，可在流式VR头显上部署，显著提升了虚拟代理的运动质量和自然性。

Abstract: As embodied agents become central to VR, telepresence, and digital human applications, their motion must go beyond speech-aligned gestures: agents should turn toward users, respond to their movement, and maintain natural gaze. Current methods lack this spatial awareness. We close this gap with the first real-time, fully causal method for spatially-aware conversational motion, deployable on a streaming VR headset. Given a user's position and dyadic audio, our approach produces full-body motion that aligns gestures with speech while orienting the agent according to the user. Our architecture combines a causal transformer-based VAE with interleaved latent tokens for streaming inference and a flow matching model conditioned on user trajectory and audio. To support varying gaze preferences, we introduce a gaze scoring mechanism with classifier-free guidance to decouple learning from control: the model captures natural spatial alignment from data, while users can adjust eye contact intensity at inference time. On the Embody 3D dataset, our method achieves state-of-the-art motion quality at over 300 FPS -- 3x faster than non-causal baselines -- while capturing the subtle spatial dynamics of natural conversation. We validate our approach on a live VR system, bringing spatially-aware conversational agents to real-time deployment. Please see https://evonneng.github.io/sarah/ for details.

</details>


### [43] [Going Down Memory Lane: Scaling Tokens for Video Stream Understanding with Dynamic KV-Cache Memory](https://arxiv.org/abs/2602.18434)
*Vatsal Agarwal,Saksham Suri,Matthew Gwilliam,Pulkit Kumar,Abhinav Shrivastava*

Main category: cs.CV

TL;DR: MemStream通过增加令牌预算和自适应选择策略，解决了现有视频问答方法在细粒度视觉细节和帧检索偏置上的问题，显著提升了性能。


<details>
  <summary>Details</summary>
Motivation: 现有方法因每帧令牌数量有限导致细粒度视觉细节丢失，且特征编码使查询-帧相似度随时间增加，偏向检索后期帧。

Method: 提出自适应选择策略以减少令牌冗余，并引入训练无关的检索专家混合方法，利用外部模型更好地识别相关帧。

Result: 在CG-Bench、LVBench和VideoMME (Long)上分别比ReKV + Qwen2.5-VL-7B提升了8.0%、8.5%和2.4%。

Conclusion: MemStream通过自适应选择策略和训练无关的检索专家混合方法，显著提升了视频问答任务的性能，证明了其在细粒度时空理解和推理上的有效性。

Abstract: Streaming video understanding requires models to robustly encode, store, and retrieve information from a continuous video stream to support accurate video question answering (VQA). Existing state-of-the-art approaches rely on key-value caching to accumulate frame-level information over time, but use a limited number of tokens per frame, leading to the loss of fine-grained visual details. In this work, we propose scaling the token budget to enable more granular spatiotemporal understanding and reasoning. First, we find that current methods are ill-equipped to handle dense streams: their feature encoding causes query-frame similarity scores to increase over time, biasing retrieval toward later frames. To address this, we introduce an adaptive selection strategy that reduces token redundancy while preserving local spatiotemporal information. We further propose a training-free retrieval mixture-of-experts that leverages external models to better identify relevant frames. Our method, MemStream, achieves +8.0% on CG-Bench, +8.5% on LVBench, and +2.4% on VideoMME (Long) over ReKV with Qwen2.5-VL-7B.

</details>


<div id='cs.DC'></div>

# cs.DC [[Back]](#toc)

### [44] [Mind the Boundary: Stabilizing Gemini Enterprise A2A via a Cloud Run Hub Across Projects and Accounts](https://arxiv.org/abs/2602.17675)
*Takao Morita*

Main category: cs.DC

TL;DR: 研究通过A2A Hub协调器实现了跨边界的企业对话UI互操作性，解决了安全性和UI稳定性问题，并在四类查询中验证了其有效性。


<details>
  <summary>Details</summary>
Motivation: 解决企业对话UI在跨项目和账户边界协调异构后端代理时的安全性和可复现性问题。

Method: 实现了一个基于Cloud Run的A2A Hub协调器，支持四种查询路径：跨项目的公共A2A代理、跨账户的IAM保护代理、结合检索增强生成的路径，以及通用问答路径。

Result: 在涵盖费用政策、项目管理、通用知识和事件响应截止时间提取的四查询基准测试中，确认了确定性路由和稳定的UI响应。检索路径通过授予存储对象读取权限，成功提取了15分钟截止时间的证据。

Conclusion: 研究表明，企业对话UI的互操作性不仅受协议兼容性影响，还受UI约束和边界认证的限制。通过实施文本兼容模式和分离结构化输出，实现了稳定的UI响应和确定性路由。

Abstract: Enterprise conversational UIs increasingly need to orchestrate heterogeneous backend agents and tools across project and account boundaries in a secure and reproducible way. Starting from Gemini Enterprise Agent-to-Agent (A2A) invocation, we implement an A2A Hub orchestrator on Cloud Run that routes queries to four paths: a public A2A agent deployed in a different project, an IAM-protected Cloud Run A2A agent in a different account, a retrieval-augmented generation path combining Discovery Engine and Vertex AI Search with direct retrieval of source text from Google Cloud Storage, and a general question answering path via Vertex AI. We show that practical interoperability is governed not only by protocol compliance but also by Gemini Enterprise UI constraints and boundary-dependent authentication. Real UI requests arrive as text-only inputs and include empty accepted output mode lists, so mixing structured data into JSON-RPC responses can trigger UI errors. To address this, we enforce a text-only compatibility mode on the JSON-RPC endpoint while separating structured outputs and debugging signals into a REST tool API. On a four-query benchmark spanning expense policy, project management assistance, general knowledge, and incident response deadline extraction, we confirm deterministic routing and stable UI responses. For the retrieval path, granting storage object read permissions enables evidence-backed extraction of the fifteen minute deadline. All experiments are reproducible using the repository snapshot tagged a2a-hub-gemini-ui-stable-paper.

</details>


### [45] [It's Not Just Timestamps: A Study on Docker Reproducibility](https://arxiv.org/abs/2602.17678)
*Oreofe Solarin*

Main category: cs.DC

TL;DR: 研究发现大多数Dockerfile不可复现，主要因时间戳和开发者选项，提出了改进指南。


<details>
  <summary>Details</summary>
Motivation: 研究旨在通过从Dockerfile重建镜像并比较哈希值，验证软件供应链的简单完整性检查。

Method: 作者构建了一个Docker测量管道，并应用于包含Dockerfile的2000个GitHub仓库的分层样本。

Result: 研究发现，仅有56%的Dockerfile能构建出镜像，其中仅2.7%在无基础设施配置修改下是比特级可复现的。通过修改基础设施配置，比特级可复现性提高了18.6%，但仍有78.7%的Dockerfile不可复现。主要原因是时间戳、元数据以及开发者控制的选项（如未清理的缓存、日志、文档和浮动版本）。

Conclusion: 论文提出了具体的Dockerfile指南，并讨论了如何为可复现容器设计未来的linter和持续集成（CI）检查。

Abstract: Reproducible container builds promise a simple integrity check for software supply chains: rebuild an image from its Dockerfile and compare hashes. We build a Docker measurement pipeline and apply it to a stratified sample of 2,000 GitHub repositories that contained a Dockerfile. We found that only 56% produce any buildable image, and just 2.7% of those are bitwise reproducible without any infrastructure configurations. After modifying infrastructure configurations, we raise bitwise reproducibility by 18.6%, but 78.7% of buildable Dockerfiles remain non-reproducible. We analyze the root causes of the remaining differences, and find that beyond timestamps and metadata, developer-controlled choices such as uncleaned caches, logs, documentation, and floating versions are dominant causes of non-reproducibility. We derive concrete Dockerfile guidelines from these patterns and discuss how they can inform future linters and Continuous Integration (CI) checks for reproducible containers.

</details>


### [46] [Message-Oriented Middleware Systems: Technology Overview](https://arxiv.org/abs/2602.17774)
*Wael Al-Manasrah,Zuhair AlSader,Tim Brecht,Ahmed Alquraan,Samer Al-Kiswany*

Main category: cs.DC

TL;DR: 研究分析了十个开源MOM系统的42个功能，发现其支持现代云应用，并建议社区集中精力于更少的项目。数据集公开可用。


<details>
  <summary>Details</summary>
Motivation: 对开源消息导向中间件系统进行全面特征研究，以了解其如何支持现代云应用。

Method: 采用严格的方法论，选择并研究了十个流行且多样化的MOM系统，每个系统检查了42个功能共134个不同选项。

Result: 发现MOM系统通过高灵活性和可配置性支持现代云应用，并提供了复杂应用的核心构建块。创建了注释数据集以验证发现并帮助实践者和开发者。

Conclusion: 消息导向中间件（MOM）系统已发展为现代云应用提供了高灵活性和可配置性的框架，并提供了复杂应用的核心构建块。社区有机会将精力集中在更少的开源项目上。

Abstract: We present a comprehensive characterization study of open-source message-oriented middleware (MOM) systems. We followed a rigorous methodology to select and study ten popular and diverse MOM systems. For each system, we examine 42 features with a total of 134 different options. We found that MOM systems have evolved to provide a framework for modern cloud applications through high flexibility and configurability and by offering core building blocks for complex applications including transaction support, active messaging, resource management, flow control, and native support for multi-tenancy. We also identify that there is an opportunity for the community to consolidate its efforts on fewer open-source projects.
  We have also created an annotated data set that makes it easy to verify our findings, which can also be used to help practitioners and developers understand and compare the features of different systems. For a wider impact, we make our data set publicly available.

</details>


### [47] [Collaborative Processing for Multi-Tenant Inference on Memory-Constrained Edge TPUs](https://arxiv.org/abs/2602.17808)
*Nathan Ng,Walid A. Hanafy,Prashanthi Kadambi,Balachandra Sunil,Ayush Gupta,David Irwin,Yogesh Simmhan,Prashant Shenoy*

Main category: cs.DC

TL;DR: SwapLess是一个自适应系统，通过动态分区和CPU核心分配优化Edge TPU的协作推理，显著降低延迟。


<details>
  <summary>Details</summary>
Motivation: IoT应用中，设备AI加速器的有限内存导致模型片段在主机和加速器内存之间频繁交换，增加了延迟。现有的协作处理方法因分区不当可能进一步恶化延迟。

Method: SwapLess利用分析排队模型，捕捉分区依赖的CPU/TPU服务时间以及不同工作负载混合和请求率下的交换开销，并在线动态调整分区点和CPU核心分配。

Result: 在配备Edge TPU的平台上，SwapLess将单租户工作负载的平均延迟降低了63.8%，多租户工作负载降低了77.4%。

Conclusion: SwapLess通过动态调整分区点和CPU核心分配，显著降低了单租户和多租户工作负载的延迟，证明了其在内存受限Edge TPU上的有效性。

Abstract: IoT applications are increasingly relying on on-device AI accelerators to ensure high performance, especially in limited connectivity and safety-critical scenarios. However, the limited on-chip memory of these accelerators forces inference runtimes to swap model segments between host and accelerator memory, substantially inflating latency. While collaborative processing by partitioning the model processing between CPU and accelerator resources can reduce accelerator memory pressure and latency, naive partitioning may worsen end-to-end latency by either shifting excessive computation to the CPU or failing to sufficiently curb swapping, a problem that is further amplified in multi-tenant and dynamic environments.
  To address these issues, we present SwapLess, a system for adaptive, multi-tenant TPU-CPU collaborative inference for memory-constrained Edge TPUs. SwapLess utilizes an analytic queueing model that captures partition-dependent CPU/TPU service times as well as inter- and intra-model swapping overheads across different workload mixes and request rates. Using this model, SwapLess continuously adjusts both the partition point and CPU core allocation online to minimize end-to-end response time with low decision overhead. An implementation on Edge TPU-equipped platforms demonstrates that SwapLess reduces mean latency by up to 63.8% for single-tenant workloads and up to 77.4% for multi-tenant workloads relative to the default Edge TPU compiler.

</details>


### [48] [Faster Parallel Batch-Dynamic Algorithms for Low Out-Degree Orientation](https://arxiv.org/abs/2602.17811)
*Guy Blelloch,Andrew Brady,Laxman Dhulipala,Jeremy Fineman,Kishen Gowda,Chase Hutton*

Main category: cs.DC

TL;DR: 本文提出了三种并行批量动态算法，用于改进无向图低出度定向的维护效率，分别在期望工作界限、最坏情况工作界限和定向复杂度上取得了显著进展。


<details>
  <summary>Details</summary>
Motivation: 研究动机是改进现有并行批量动态算法在维护无向图低出度定向时的效率，特别是在工作界限和定向复杂度方面的表现。

Method: 本文采用了并行批量动态算法，针对无向图的低出度定向问题，提出了三种不同的算法，分别优化了期望工作界限、最坏情况工作界限和定向复杂度。

Result: 1. 第一个结果实现了渐近最优的定向和期望工作界限，改进了之前的最佳工作界限。2. 第二个结果在最坏情况下每边更新的期望工作界限为O(√log n)，与已知最佳顺序算法匹配。3. 第三个结果显著改进了近期工作，将最坏情况每边更新的工作界限从O(log^9 n)降低到O(log^2 n)。

Conclusion: 本文提出了三种并行批量动态算法，用于维护无向图的低出度定向，分别在期望工作界限、最坏情况工作界限和定向复杂度上取得了改进。

Abstract: A low out-degree orientation directs each edge of an undirected graph with the goal of minimizing the maximum out-degree of a vertex. In the parallel batch-dynamic setting, one can insert or delete batches of edges, and the goal is to process the entire batch in parallel with work per edge similar to that of a single sequential update and with span (or depth) for the entire batch that is polylogarithmic. In this paper we present faster parallel batch-dynamic algorithms for maintaining a low out-degree orientation of an undirected graph. All results herein achieve polylogarithmic depth, with high probability (whp); the focus of this paper is on minimizing the work, which varies across results.
  Our first result is the first parallel batch-dynamic algorithm to maintain an asymptotically optimal orientation with asymptotically optimal expected work bounds, in an amortized sense, improving over the prior best work bounds of Liu et al.~[SPAA~'22] by a logarithmic factor.
  Our second result is a $O(c \log n)$ orientation algorithm with expected worst-case $O(\sqrt{\log n})$ work per edge update, where $c$ is a known upper-bound on the arboricity of the graph. This matches the best-known sequential worst-case $O(c \log n)$ orientation algorithm given by Berglin and Brodal ~[Algorithmica~'18], albeit in expectation.
  Our final result is a $O(c + \log n)$-orientation algorithm with $O(\log^2 n)$ expected worst-case work per edge update. This algorithm significantly improves upon the recent result of Ghaffari and Koo~[SPAA~'25], which maintains a $O(c)$-orientation with $O(\log^9 n)$ worst-case work per edge whp.

</details>


### [49] [GPU Memory and Utilization Estimation for Training-Aware Resource Management: Opportunities and Limitations](https://arxiv.org/abs/2602.17817)
*Ehsan Yousefzadeh-Asl-Miandoab,Reza Karimzadeh,Danyal Yorulmaz,Bulat Ibragimov,Pınar Tözün*

Main category: cs.DC

TL;DR: 论文系统评估了GPU内存和利用率估算方法，揭示了现有范式的局限性，并公开数据集以推动未来研究。


<details>
  <summary>Details</summary>
Motivation: 深度学习任务协同定位虽提高GPU利用率，但会因资源争用导致显著减速和内存溢出风险。准确的内存估算和GPU利用率评估对优化任务调度至关重要，而现有方法各有局限且GPU利用率研究不足。

Method: 研究分析了三种GPU内存估算范式（分析模型、CPU端库和基于ML的估算器）以及GPU利用率估算。通过构建包含MLPs、CNNs和Transformers的合成数据集，训练MLP和Transformer-based估算器进行内存预测，并在同一数据集上进行利用率估算实验。

Result: 评估揭示了关键权衡：分析模型依赖硬件，CPU端库集成成本高，基于ML的估算器在跨架构泛化上表现不佳。研究验证了估算器对未见模型的适用性，并突出了GPU利用率的非加性和硬件敏感性挑战。

Conclusion: 论文指出了深度学习任务协同定位中的关键挑战，并提出了评估GPU内存和利用率的系统方法。尽管现有方法存在局限性，但研究为未来改进提供了基础，并公开了数据集和工具以支持进一步研究。

Abstract: Collocating deep learning training tasks improves GPU utilization but causes drastic slowdowns due to resource contention and risks Out-of-Memory (OOM) failures. Accurate memory estimation is essential for robust collocation, while GPU utilization -- a key proxy for resource contention -- enables interference-aware scheduling to reduce slowdowns and improve throughput. Existing GPU memory estimators span three paradigms -- analytical models, CPU-side libraries, and ML-based estimators -- each with distinct limitations: dependence on detailed model specifications, intrusive integration, poor generalization, and varying latency overhead. GPU heterogeneity further complicates estimation, as identical tasks can exhibit markedly different memory footprints across hardware generations. GPU utilization remains comparatively understudied, further complicated by the non-additive nature of utilization metrics and hardware sensitivity. We conduct a systematic analysis of representative estimators from each paradigm -- Horus, PyTorch FakeTensor, and our lightweight ML-based estimator -- evaluating accuracy, generalizability, and practical overhead. We construct a synthetic dataset spanning MLPs, CNNs, and Transformers with controlled architectural variations, and train MLP- and Transformer-based estimators for memory prediction. We further experiment with utilization estimation on the same dataset. Our evaluation reveals key tradeoffs and validates estimators against real-world unseen models. Significant challenges remain: analytical models are hardware-dependent, CPU-side libraries impose intrusive integration costs, and ML-based estimators struggle with cross-architecture generalization. We release all datasets, tools, and artifacts to support further research.

</details>


### [50] [Distributed Triangle Enumeration in Hypergraphs](https://arxiv.org/abs/2602.17834)
*Duncan Adamson,Will Rosenbaum,Paul G. Spirakis*

Main category: cs.DC

TL;DR: 本文系统地研究了分布式超图中的子超图枚举问题，提出了多种计算模型和高效算法，并证明了某些模型中的最优性。


<details>
  <summary>Details</summary>
Motivation: 由于子图检测和枚举在分布式图算法中的理论挑战和实际应用的重要性，本文旨在系统地研究分布式超图中的子超图枚举问题。

Method: 本文引入了多种计算模型，设计了分布式三角形枚举算法，并引入了稀疏和‘处处稀疏’超图类，提出了在这些类中高效的分布式算法。

Result: 本文提出了多种计算模型并评估了它们的相对计算能力，设计了分布式三角形枚举算法并证明了其在某些模型中的最优性，还介绍了稀疏和‘处处稀疏’超图类，并描述了在这些类中高效的分布式三角形枚举算法。

Conclusion: 本文系统地研究了分布式超图中的子超图枚举问题，提出了多种计算模型并评估了它们的相对计算能力，设计了分布式三角形枚举算法并证明了其在某些模型中的最优性，还介绍了稀疏和‘处处稀疏’超图类，并描述了在这些类中高效的分布式三角形枚举算法。

Abstract: In the last decade, subgraph detection and enumeration have emerged as a central problem in distributed graph algorithms. This is largely due to the theoretical challenges and practical applications of these problems. In this paper, we initiate the systematic study of distributed sub-hypergraph enumeration in hypergraphs. To this end, we (1)~introduce several computational models for hypergraphs that generalize the CONGEST model for graphs and evaluate their relative computational power, (2)~devise algorithms for distributed triangle enumeration in our computational models and prove their optimality in two such models, (3)~introduce classes of sparse and ``everywhere sparse'' hypergraphs and describe efficient distributed algorithms for triangle enumeration in these classes, and (4)~describe general techniques that we believe to be useful for designing efficient algorithms in our hypergraph models.

</details>


### [51] [Joint Training on AMD and NVIDIA GPUs](https://arxiv.org/abs/2602.18007)
*Jon Hu,Thomas Jia,Jing Zhu,Zhendong Yu*

Main category: cs.DC

TL;DR: 论文提出异构混合训练方案，通过两种通信方法在AMD-NVIDIA环境中实现高效数据传输，性能接近同构系统。


<details>
  <summary>Details</summary>
Motivation: 随着大语言模型规模扩大，单一供应商的同构集群无法满足训练需求，需解决异构混合训练问题。

Method: 采用两种方法：1) 基于CPU-Forwarding Communication的兼容性导向方法，通过差异化通信后端选择和多NIC并行数据传输；2) Device-Direct Communication方法，通过CPU卸载P2P机制实现跨厂商GPU直接数据传输。

Result: 在LLaMA-8B和Qwen2-7B上的实验表明，Device-Direct Communication方法接近NVIDIA同构系统的吞吐量。

Conclusion: 论文提出的Device-Direct Communication方法在AMD-NVIDIA异构环境中实现了高达98%的吞吐量，同时保持了训练稳定性和正确性。

Abstract: As large language models continue to scale, training demands on compute and system capacity grow rapidly, making single-vendor homogeneous clusters insufficient. This paper presents a technical solution for heterogeneous mixed training in AMD-NVIDIA environments. We first adopt a compatibility-oriented approach based on CPU-Forwarding Communication, with differentiated communication back-end selection across parallel groups and multi-NIC parallel data transfer. To achieve higher performance, we further propose another Device-Direct Communication approach, integrating a CPU-offloading P2P mechanism to enable direct cross-vendor GPU data transfer without host-memory staging. Experiments on LLaMA-8B and Qwen2-7B demonstrate that the proposed Device-Direct Communication approach achieves up to 98% of the throughput of an NVIDIA homogeneous system, while preserving training stability and correctness.

</details>


### [52] [A reliability- and latency-driven task allocation framework for workflow applications in the edge-hub-cloud continuum](https://arxiv.org/abs/2602.18158)
*Andreas Kouloumpris,Georgios L. Stavrinides,Maria K. Michael,Theocharis Theocharides*

Main category: cs.DC

TL;DR: 提出了一种精确的多目标任务分配框架，优化边缘-中心-云架构中的工作流应用可靠性和延迟，实验显示显著提升。


<details>
  <summary>Details</summary>
Motivation: 由于设备限制和多样化的操作条件，在边缘-中心-云架构中进行任务分配具有挑战性，且现有方法未能全面解决这些挑战。

Method: 提出了一个精确的多目标任务分配框架，采用二进制整数线性规划，结合时间冗余技术，并考虑了相关研究中常被忽视的关键约束。

Result: 在真实应用中，相比基线策略，该方法在可靠性上平均提升了84.19%，延迟降低了49.81%。

Conclusion: 实验结果表明，该方法在考虑的系统架构中具有高效性和可扩展性，适用于多样化的工作流应用，且实际运行时间在0.03至50.94秒之间。

Abstract: A growing number of critical workflow applications leverage a streamlined edge-hub-cloud architecture, which diverges from the conventional edge computing paradigm. An edge device, in collaboration with a hub device and a cloud server, often suffices for their reliable and efficient execution. However, task allocation in this streamlined architecture is challenging due to device limitations and diverse operating conditions. Given the inherent criticality of such workflow applications, where reliability and latency are vital yet conflicting objectives, an exact task allocation approach is typically required to ensure optimal solutions. As no existing method holistically addresses these issues, we propose an exact multi-objective task allocation framework to jointly optimize the overall reliability and latency of a workflow application in the specific edge-hub-cloud architecture. We present a comprehensive binary integer linear programming formulation that considers the relative importance of each objective. It incorporates time redundancy techniques, while accounting for crucial constraints often overlooked in related studies. We evaluate our approach using a relevant real-world workflow application, as well as synthetic workflows varying in structure, size, and criticality. In the real-world application, our method achieved average improvements of 84.19% in reliability and 49.81% in latency over baseline strategies, across relevant objective trade-offs. Overall, the experimental results demonstrate the effectiveness and scalability of our approach across diverse workflow applications for the considered system architecture, highlighting its practicality with runtimes averaging between 0.03 and 50.94 seconds across all examined workflows.

</details>


### [53] [It does not matter how you define locally checkable labelings](https://arxiv.org/abs/2602.18188)
*Antonio Cruciani,Avinandan Das,Alesya Raevskaya,Jukka Suomela*

Main category: cs.DC

TL;DR: LCL problems are robust to variations, with minimal overhead when translating between formalisms, as shown by local reductions and symmetry-breaking oracles.


<details>
  <summary>Details</summary>
Motivation: To explore the robustness of LCL problems by examining their behavior under variations, particularly focusing on a restricted family of locally checkable problems that avoids direct references to certain graph properties like short cycles.

Method: The study employs local reductions between the 'node-edge checkable' formalism and the standard LCL formalism, utilizing a symmetry-breaking oracle to ensure minimal overhead (additive O(log^* n) rounds in the LOCAL model).

Result: The research shows that LCL problems maintain their complexity and properties even when translated between different formalisms, highlighting their robustness.

Conclusion: The family of locally checkable labeling problems (LCLs) is highly robust to variations, as demonstrated by the ability to translate between different formalisms with minimal overhead.

Abstract: Locally checkable labeling problems (LCLs) form the foundation of the modern theory of distributed graph algorithms. First introduced in the seminal paper by Naor and Stockmeyer [STOC 1993], these are graph problems that can be described by listing a finite set of valid local neighborhoods. This seemingly simple definition strikes a careful balance between two objectives: they are a family of problems that is broad enough so that it captures numerous problems that are of interest to researchers working in this field, yet restrictive enough so that it is possible to prove strong theorems that hold for all LCL problems. In particular, the distributed complexity landscape of LCL problems is now very well understood.
  In this work we show that the family of LCL problems is extremely robust to variations. We present a very restricted family of locally checkable problems (essentially, the "node-edge checkable" formalism familiar from round elimination, restricted to regular unlabeled graphs); most importantly, such problems cannot directly refer to e.g. the existence of short cycles. We show that one can translate between the two formalisms (there are local reductions in both directions that only need access to a symmetry-breaking oracle, and hence the overhead is at most an additive $O(\log^* n)$ rounds in the LOCAL model).

</details>


### [54] [Green by Design: Constraint-Based Adaptive Deployment in the Cloud Continuum](https://arxiv.org/abs/2602.18287)
*Andrea D'Iapico,Monica Vitali*

Main category: cs.DC

TL;DR: 提出绿色约束驱动的自动部署计划生成方法，有效减少云边连续体中云原生应用的能源消耗和排放。


<details>
  <summary>Details</summary>
Motivation: IT环境可持续性日益重要，需减少能源消耗和温室气体排放，尤其在云边连续体中部署云原生应用时，需考虑动态因素如应用行为和节点碳强度变化。

Method: 通过持续分析能源消耗模式、组件间通信及基础设施的环境特性，生成绿色感知约束，指导调度器生成环保部署计划。

Result: 在真实部署场景中验证了该方法的有效性，显著降低了能源使用和相关排放。

Conclusion: 本文提出了一种基于绿色约束的自动部署计划生成方法，有效降低了云原生应用在云边连续体中的能源消耗和温室气体排放。

Abstract: The environmental sustainability of Information Technology (IT) has emerged as a critical concern, driven by the need to reduce both energy consumption and greenhouse gas (GHG) emissions. In the context of cloud-native applications deployed across the cloud-edge continuum, this challenge translates into identifying energy-efficient deployment strategies that consider not only the computational demands of application components but also the environmental impact of the nodes on which they are executed. Generating deployment plans that account for these dynamic factors is non-trivial, due to fluctuations in application behaviour and variations in the carbon intensity of infrastructure nodes. In this paper, we present an approach for the automatic generation of deployment plans guided by green constraints. These constraints are derived from a continuous analysis of energy consumption patterns, inter-component communication, and the environmental characteristics of the underlying infrastructure. This paper introduces a methodology and architecture for the generation of a set of green-aware constraints that inform the scheduler to produce environmentally friendly deployment plans. We demonstrate how these constraints can be automatically learned and updated over time using monitoring data, enabling adaptive, energy-aware orchestration. The proposed approach is validated through realistic deployment scenarios of a cloud-native application, showcasing its effectiveness in reducing energy usage and associated emissions.

</details>


<div id='cs.RO'></div>

# cs.RO [[Back]](#toc)

### [55] [Nested Training for Mutual Adaptation in Human-AI Teaming](https://arxiv.org/abs/2602.17737)
*Upasana Biswas,Durgesh Kalwar,Subbarao Kambhampati,Sarath Sreedharan*

Main category: cs.RO

TL;DR: 论文提出嵌套训练机制，通过I-POMDP建模人类适应性行为，显著提升机器人与新伙伴协作时的表现。


<details>
  <summary>Details</summary>
Motivation: 现有方法中的训练伙伴是静态的，无法捕捉人类的适应性行为，导致机器人与新伙伴协作时泛化能力差。论文旨在通过建模人类适应性行为，提升机器人在动态协作中的表现。

Method: 论文采用Interactive Partially Observable Markov Decision Process (I-POMDP)模型，提出嵌套训练机制，每一层级代理与下一层级的自适应代理训练，避免隐式协调策略的出现。

Result: 实验结果表明，该方法在Overcooked领域与未训练过的自适应伙伴协作时，任务表现和适应性显著优于基线方法。

Conclusion: 该论文提出了一种嵌套训练机制，通过将人机协作场景建模为I-POMDP，并显式地将人类适应行为纳入状态，成功提升了机器人与未训练过的自适应伙伴协作时的任务表现和适应性。

Abstract: Mutual adaptation is a central challenge in human--AI teaming, as humans naturally adjust their strategies in response to a robot's policy. Existing approaches aim to improve diversity in training partners to approximate human behavior, but these partners are static and fail to capture adaptive behavior of humans. Exposing robots to adaptive behaviors is critical, yet when both agents learn simultaneously in a multi-agent setting, they often converge to opaque implicit coordination strategies that only work with the agents they were co-trained with. Such agents fail to generalize when paired with new partners. In order to capture the adaptive behavior of humans, we model the human-robot teaming scenario as an Interactive Partially Observable Markov Decision Process (I-POMDP), explicitly modeling human adaptation as part of the state. We propose a nested training regime to approximately learn the solution to a finite-level I-POMDP. In this framework, agents at each level are trained against adaptive agents from the level below. This ensures that the ego agent is exposed to adaptive behavior during training while avoiding the emergence of implicit coordination strategies, since the training partners are not themselves learning. We train our method in a multi-episode, required cooperation setup in the Overcooked domain, comparing it against several baseline agents designed for human-robot teaming. We evaluate the performance of our agent when paired with adaptive partners that were not seen during training. Our results demonstrate that our agent not only achieves higher task performance with these adaptive partners but also exhibits significantly greater adaptability during team interactions.

</details>


### [56] [Reinforcement-Learning-Based Assistance Reduces Squat Effort with a Modular Hip--Knee Exoskeleton](https://arxiv.org/abs/2602.17794)
*Neethan Ratnakumar,Mariya Huzaifa Tohfafarosh,Saanya Jauhri,Xianlian Zhou*

Main category: cs.RO

TL;DR: 研究评估了基于强化学习的神经网络控制器在髋膝关节外骨骼中的应用，发现能有效降低代谢率约10%，但蹲起深度有所减少。


<details>
  <summary>Details</summary>
Motivation: 蹲起是最具挑战性的下肢动作之一，需要大量肌肉努力和协调。通过智能和个性化辅助降低其身体负担，对涉及重复低水平组装活动的行业有重要意义。

Method: 通过基于物理的人-外骨骼交互模拟环境，使用强化学习（RL）训练神经网络控制器，生成实时的髋关节和膝关节辅助扭矩。

Result: 与零扭矩和无外骨骼条件相比，主动辅助将净代谢率降低了约10%，心率略有下降。但辅助试验也表现出蹲起深度减少，髋关节和膝关节屈曲角度较小。

Conclusion: 初步研究结果表明，提出的控制器能有效降低重复蹲起时的生理负担，激励硬件设计和控制策略的进一步改进。

Abstract: Squatting is one of the most demanding lower-limb movements, requiring substantial muscular effort and coordination. Reducing the physical demands of this task through intelligent and personalized assistance has significant implications, particularly in industries involving repetitive low-level assembly activities. In this study, we evaluated the effectiveness of a neural network controller for a modular Hip-Knee exoskeleton designed to assist squatting tasks. The neural network controller was trained via reinforcement learning (RL) in a physics-based, human-exoskeleton interaction simulation environment. The controller generated real-time hip and knee assistance torques based on recent joint-angle and velocity histories. Five healthy adults performed three-minute metronome-guided squats under three conditions: (1) no exoskeleton (No-Exo), (2) exoskeleton with Zero-Torque, and (3) exoskeleton with active assistance (Assistance). Physiological effort was assessed using indirect calorimetry and heart rate monitoring, alongside concurrent kinematic data collection. Results show that the RL-based controller adapts to individuals by producing torque profiles tailored to each subject's kinematics and timing. Compared with the Zero-Torque and No-Exo condition, active assistance reduced the net metabolic rate by approximately 10%, with minor reductions observed in heart rate. However, assisted trials also exhibited reduced squat depth, reflected by smaller hip and knee flexion. These preliminary findings suggest that the proposed controller can effectively lower physiological effort during repetitive squatting, motivating further improvements in both hardware design and control strategies.

</details>


### [57] [Learning Smooth Time-Varying Linear Policies with an Action Jacobian Penalty](https://arxiv.org/abs/2602.18312)
*Zhaoming Xie,Kevin Karol,Jessica Hodgins*

Main category: cs.RO

TL;DR: 提出动作雅可比惩罚和线性策略网络（LPN），无需调参即可消除不现实的高频控制信号，并在多种运动任务中表现优异，成功应用于物理机器人。


<details>
  <summary>Details</summary>
Motivation: 强化学习框架中的控制政策常利用人类或物理机器人无法实现的高频信号，导致行为不真实。现有方法通过惩罚动作随时间的大变化来解决，但需要大量调参。

Method: 提出使用动作雅可比惩罚（action Jacobian penalty）直接通过自动微分惩罚动作对模拟状态变化的敏感性，从而消除不现实的高频控制信号。为了减少计算开销，引入线性策略网络（LPN）架构，显著降低了训练过程中计算动作雅可比惩罚的负担。

Result: 线性策略网络（LPN）无需参数调优，学习收敛速度比基线方法更快，推理时查询效率高于全连接神经网络。结合动作雅可比惩罚，LPN能生成平滑信号并解决多种运动模仿任务。

Conclusion: 通过结合线性策略网络（LPN）和动作雅可比惩罚，该方法能够学习生成平滑控制信号的政策，并在多种运动模仿任务中表现出色，包括动态动作如后空翻和挑战性的跑酷技能。此外，该方法还成功应用于配备手臂的四足机器人，展示了其在实际物理机器人上的有效性。

Abstract: Reinforcement learning provides a framework for learning control policies that can reproduce diverse motions for simulated characters. However, such policies often exploit unnatural high-frequency signals that are unachievable by humans or physical robots, making them poor representations of real-world behaviors. Existing work addresses this issue by adding a reward term that penalizes a large change in actions over time. This term often requires substantial tuning efforts. We propose to use the action Jacobian penalty, which penalizes changes in action with respect to the changes in simulated state directly through auto differentiation. This effectively eliminates unrealistic high-frequency control signals without task specific tuning. While effective, the action Jacobian penalty introduces significant computational overhead when used with traditional fully connected neural network architectures. To mitigate this, we introduce a new architecture called a Linear Policy Net (LPN) that significantly reduces the computational burden for calculating the action Jacobian penalty during training. In addition, a LPN requires no parameter tuning, exhibits faster learning convergence compared to baseline methods, and can be more efficiently queried during inference time compared to a fully connected neural network. We demonstrate that a Linear Policy Net, combined with the action Jacobian penalty, is able to learn policies that generate smooth signals while solving a number of motion imitation tasks with different characteristics, including dynamic motions such as a backflip and various challenging parkour skills. Finally, we apply this approach to create policies for dynamic motions on a physical quadrupedal robot equipped with an arm.

</details>


### [58] [Lend me an Ear: Speech Enhancement Using a Robotic Arm with a Microphone Array](https://arxiv.org/abs/2602.17818)
*Zachary Turcotte,François Grondin*

Main category: cs.RO

TL;DR: 论文提出通过机器人臂动态调整麦克风阵列几何形状，结合多种技术提升语音增强性能，在嘈杂工业环境中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决现有语音增强技术在嘈杂工业环境中性能下降的问题，推动语音控制技术的实际应用。

Method: 结合了物理优化阶段，通过机器人臂动态调整麦克风阵列几何形状，整合声源定位、计算机视觉、逆运动学、MVDR波束成形和DNN时频掩蔽技术。

Result: 实验证明该方法在多种信噪比条件下均优于传统配置，实现了更高的SISDR和更低的WER。

Conclusion: 该论文提出的动态调整麦克风阵列几何形状的方法显著提升了语音增强性能，尤其在嘈杂工业环境中表现优异。

Abstract: Speech enhancement performance degrades significantly in noisy environments, limiting the deployment of speech-controlled technologies in industrial settings, such as manufacturing plants. Existing speech enhancement solutions primarly rely on advanced digital signal processing techniques, deep learning methods, or complex software optimization techniques. This paper introduces a novel enhancement strategy that incorporates a physical optimization stage by dynamically modifying the geometry of a microphone array to adapt to changing acoustic conditions. A sixteen-microphone array is mounted on a robotic arm manipulator with seven degrees of freedom, with microphones divided into four groups of four, including one group positioned near the end-effector. The system reconfigures the array by adjusting the manipulator joint angles to place the end-effector microphones closer to the target speaker, thereby improving the reference signal quality. This proposed method integrates sound source localization techniques, computer vision, inverse kinematics, minimum variance distortionless response beamformer and time-frequency masking using a deep neural network. Experimental results demonstrate that this approach outperforms other traditional recording configruations, achieving higher scale-invariant signal-to-distortion ratio and lower word error rate accross multiple input signal-to-noise ratio conditions.

</details>


### [59] [Evolution of Safety Requirements in Industrial Robotics: Comparative Analysis of ISO 10218-1/2 (2011 vs. 2025) and Integration of ISO/TS 15066](https://arxiv.org/abs/2602.17822)
*Daniel Hartmann,Kristýna Hamříková,Aleš Vysocký,Vendula Laciok,Aleš Bernatík*

Main category: cs.RO

TL;DR: 文章比较了新旧ISO机器人安全标准，重点分析了功能安全、网络安全及新分类的扩展，新版标准为现代机器人系统提供了更全面的安全框架。


<details>
  <summary>Details</summary>
Motivation: 工业机器人已成为大规模制造企业的核心组成部分，协作机器人日益突出，这些进步需要全面修订安全标准，特别是网络安全和防止未授权访问的要求。

Method: 对ISO 10218:2011和ISO 10218:2025标准进行了比较分析，包括结构、术语、技术要求和附录的演变。

Result: 分析显示功能安全和网络安全显著扩展，引入了新的机器人分类和协作应用，并规范整合了ISO/TS 15066技术规范。

Conclusion: 新版ISO 10218:2025标准综合了机械、功能性和数字安全要求，为现代机器人系统的设计和操作建立了全面框架。

Abstract: Industrial robotics has established itself as an integral component of large-scale manufacturing enterprises. Simultaneously, collaborative robotics is gaining prominence, introducing novel paradigms of human-machine interaction. These advancements have necessitated a comprehensive revision of safety standards, specifically incorporating requirements for cybersecurity and protection against unauthorized access in networked robotic systems. This article presents a comparative analysis of the ISO 10218:2011 and ISO 10218:2025 standards, examining the evolution of their structure, terminology, technical requirements, and annexes. The analysis reveals significant expansions in functional safety and cybersecurity, the introduction of new classifications for robots and collaborative applications, and the normative integration of the technical specification ISO/TS 15066. Consequently, the new edition synthesizes mechanical, functional, and digital safety requirements, establishing a comprehensive framework for the design and operation of modern robotic systems.

</details>


### [60] [WHED: A Wearable Hand Exoskeleton for Natural, High-Quality Demonstration Collection](https://arxiv.org/abs/2602.17908)
*Mingzhang Zhu,Alvin Zhu,Jose Victor S. H. Ramos,Beom Jun Kim,Yike Shi,Yufeng Wu,Ruochen Hou,Quanyou Wang,Eric Song,Tony Fan,Yuchen Cui,Dennis W. Hong*

Main category: cs.RO

TL;DR: WHED是一种可穿戴手外骨骼系统，用于野外捕获高保真人类手部演示，解决了遮挡和复杂交互问题，并验证了演示与回放的一致性。


<details>
  <summary>Details</summary>
Motivation: 解决多指手部操作演示捕获中的遮挡、复杂手部运动学和接触密集交互等挑战。

Method: WHED系统结合了可穿戴手外骨骼设计，包括被动适应手指接口、改进的被动手部以及集成的传感/电源模块，并提供了端到端的数据处理流程。

Result: 系统在代表性抓取和操作序列中展示了可行性，并验证了演示与回放执行之间的一致性。

Conclusion: WHED系统展示了在野外捕获高保真人类手部演示的可行性，并在精确捏取和全手包围抓取等代表性操作序列中验证了其效果。

Abstract: Scalable learning of dexterous manipulation remains bottlenecked by the difficulty of collecting natural, high-fidelity human demonstrations of multi-finger hands due to occlusion, complex hand kinematics, and contact-rich interactions. We present WHED, a wearable hand-exoskeleton system designed for in-the-wild demonstration capture, guided by two principles: wearability-first operation for extended use and a pose-tolerant, free-to-move thumb coupling that preserves natural thumb behaviors while maintaining a consistent mapping to the target robot thumb degrees of freedom. WHED integrates a linkage-driven finger interface with passive fit accommodation, a modified passive hand with robust proprioceptive sensing, and an onboard sensing/power module. We also provide an end-to-end data pipeline that synchronizes joint encoders, AR-based end-effector pose, and wrist-mounted visual observations, and supports post-processing for time alignment and replay. We demonstrate feasibility on representative grasping and manipulation sequences spanning precision pinch and full-hand enclosure grasps, and show qualitative consistency between collected demonstrations and replayed executions.

</details>


### [61] [Latent Diffeomorphic Co-Design of End-Effectors for Deformable and Fragile Object Manipulation](https://arxiv.org/abs/2602.17921)
*Kei Ikemura,Yifei Dong,Florian T. Pokorny*

Main category: cs.RO

TL;DR: 首个联合优化末端执行器形态与控制的框架，成功应用于食品操作任务，仿真与实验验证有效。


<details>
  <summary>Details</summary>
Motivation: 由于复杂的接触动力学和对物体完整性的严格要求，操作易变形和易碎物体一直是机器人领域的挑战。现有方法通常孤立优化末端执行器设计或控制策略，限制了性能提升。

Method: 1. 引入潜在微分同胚形状参数化以实现末端执行器几何优化；2. 提出应力感知的双层协同设计流程，耦合形态与控制优化；3. 采用特权到点云的策略蒸馏方案实现零样本真实世界部署。

Result: 在包括抓取和推动果冻、舀取鱼片等食品操作任务中，该方法在仿真和实际实验中均表现出色。

Conclusion: 该研究提出了首个联合优化末端执行器形态和操作控制的框架，成功应用于易变形和易碎物体的操作任务，仿真和实际实验验证了其有效性。

Abstract: Manipulating deformable and fragile objects remains a fundamental challenge in robotics due to complex contact dynamics and strict requirements on object integrity. Existing approaches typically optimize either end-effector design or control strategies in isolation, limiting achievable performance. In this work, we present the first co-design framework that jointly optimizes end-effector morphology and manipulation control for deformable and fragile object manipulation. We introduce (1) a latent diffeomorphic shape parameterization enabling expressive yet tractable end-effector geometry optimization, (2) a stress-aware bi-level co-design pipeline coupling morphology and control optimization, and (3) a privileged-to-pointcloud policy distillation scheme for zero-shot real-world deployment. We evaluate our approach on challenging food manipulation tasks, including grasping and pushing jelly and scooping fillets. Simulation and real-world experiments demonstrate the effectiveness of the proposed method.

</details>


### [62] [Homotopic information gain for sparse active target tracking](https://arxiv.org/abs/2602.17926)
*Jennifer Wakulicz,Ki Myung Brian Lee,Teresa Vidal-Calleja,Robert Fitch*

Main category: cs.RO

TL;DR: 提出同伦信息增益规划方法，通过优化高层运动信息，减少测量次数并提升轨迹估计精度。


<details>
  <summary>Details</summary>
Motivation: 针对多模态运动模型中信息增益定义模糊的问题，探索通过最大化目标同伦类信息来优化感知轨迹规划。

Method: 引入同伦信息增益作为测量预期的高层轨迹信息量，并证明其是度量或低层信息增益的下界。

Result: 实证评估表明，该方法在真实和模拟行人数据上均能以较少测量次数获得比度量信息方法更准确的轨迹估计。

Conclusion: 本文提出了一种基于目标同伦类信息增益的规划方法，通过最大化目标的高层运动信息，实现了在较少测量次数下获得高精度轨迹估计。

Abstract: The problem of planning sensing trajectories for a mobile robot to collect observations of a target and predict its future trajectory is known as active target tracking. Enabled by probabilistic motion models, one may solve this problem by exploring the belief space of all trajectory predictions given future sensing actions to maximise information gain. However, for multi-modal motion models the notion of information gain is often ill-defined. This paper proposes a planning approach designed around maximising information regarding the target's homotopy class, or high-level motion. We introduce homotopic information gain, a measure of the expected high-level trajectory information given by a measurement. We show that homotopic information gain is a lower bound for metric or low-level information gain, and is as sparsely distributed in the environment as obstacles are. Planning sensing trajectories to maximise homotopic information results in highly accurate trajectory estimates with fewer measurements than a metric information approach, as supported by our empirical evaluation on real and simulated pedestrian data.

</details>


### [63] [Quasi-Periodic Gaussian Process Predictive Iterative Learning Control](https://arxiv.org/abs/2602.18014)
*Unnati Nigam,Radhendushka Srivastava,Faezeh Marzbanrad,Michael Burke*

Main category: cs.RO

TL;DR: 该论文提出一种结合QPGPs的预测ILC方法，显著提升重复任务中的控制性能，降低计算复杂度，并在多个实验中验证了其优越性。


<details>
  <summary>Details</summary>
Motivation: 解决机器人因环境变化和磨损导致的性能下降问题，通过预测未来迭代中的误差而非仅依赖过去误差，提升控制器的收敛速度和鲁棒性。

Method: 将准周期高斯过程（QPGPs）融入预测性迭代学习控制（ILC）框架，利用结构方程公式实现高效推断和参数估计。

Result: 在自动驾驶轨迹跟踪、三连杆机械臂和真实Stretch机器人实验中，该方法比标准ILC和传统GP预测ILC收敛更快，且在注入和自然干扰下保持鲁棒性。

Conclusion: 该论文提出的方法在多种重复性动态系统中表现出更快的收敛速度和更强的鲁棒性，同时降低了计算成本，展现了其广泛的实用性。

Abstract: Repetitive motion tasks are common in robotics, but performance can degrade over time due to environmental changes and robot wear and tear. Iterative learning control (ILC) improves performance by using information from previous iterations to compensate for expected errors in future iterations. This work incorporates the use of Quasi-Periodic Gaussian Processes (QPGPs) into a predictive ILC framework to model and forecast disturbances and drift across iterations. Using a recent structural equation formulation of QPGPs, the proposed approach enables efficient inference with complexity $\mathcal{O}(p^3)$ instead of $\mathcal{O}(i^2p^3)$, where $p$ denotes the number of points within an iteration and $i$ represents the total number of iterations, specially for larger $i$. This formulation also enables parameter estimation without loss of information, making continual GP learning computationally feasible within the control loop. By predicting next-iteration error profiles rather than relying only on past errors, the controller achieves faster convergence and maintains this under time-varying disturbances. We benchmark the method against both standard ILC and conventional Gaussian Process (GP)-based predictive ILC on three tasks, autonomous vehicle trajectory tracking, a three-link robotic manipulator, and a real-world Stretch robot experiment. Across all cases, the proposed approach converges faster and remains robust under injected and natural disturbances while reducing computational cost. This highlights its practicality across a range of repetitive dynamical systems.

</details>


### [64] [EgoPush: Learning End-to-End Egocentric Multi-Object Rearrangement for Mobile Robots](https://arxiv.org/abs/2602.18071)
*Boyuan An,Zhexiong Wang,Yipeng Wang,Jiaqi Li,Sihang Li,Jing Zhang,Chen Feng*

Main category: cs.RO

TL;DR: EgoPush是一个针对移动机器人非抓取重排任务的框架，通过物体中心潜在空间和特权RL教师设计，显著提升成功率并实现零样本模拟到现实转移。


<details>
  <summary>Details</summary>
Motivation: 受人类在杂乱环境中基于自我中心感知重排物体的能力启发，研究移动机器人使用单一自我中心相机进行长时程多物体非抓取重排。

Method: EgoPush采用物体中心潜在空间编码相对空间关系，通过特权RL教师学习潜在状态和移动动作，并蒸馏为纯视觉学生策略。通过限制教师观察为视觉可访问线索，减少监督差距。

Result: EgoPush在模拟实验中显著优于端到端RL基线，消融实验验证了各设计选择的有效性，并成功实现了零样本模拟到现实转移。

Conclusion: EgoPush框架通过物体中心潜在空间和特权强化学习教师的设计，显著提升了移动机器人在非抓取重排任务中的成功率，并实现了零样本的模拟到现实转移。

Abstract: Humans can rearrange objects in cluttered environments using egocentric perception, navigating occlusions without global coordinates. Inspired by this capability, we study long-horizon multi-object non-prehensile rearrangement for mobile robots using a single egocentric camera. We introduce EgoPush, a policy learning framework that enables egocentric, perception-driven rearrangement without relying on explicit global state estimation that often fails in dynamic scenes. EgoPush designs an object-centric latent space to encode relative spatial relations among objects, rather than absolute poses. This design enables a privileged reinforcement-learning (RL) teacher to jointly learn latent states and mobile actions from sparse keypoints, which is then distilled into a purely visual student policy. To reduce the supervision gap between the omniscient teacher and the partially observed student, we restrict the teacher's observations to visually accessible cues. This induces active perception behaviors that are recoverable from the student's viewpoint. To address long-horizon credit assignment, we decompose rearrangement into stage-level subproblems using temporally decayed, stage-local completion rewards. Extensive simulation experiments demonstrate that EgoPush significantly outperforms end-to-end RL baselines in success rate, with ablation studies validating each design choice. We further demonstrate zero-shot sim-to-real transfer on a mobile platform in the real world. Code and videos are available at https://ai4ce.github.io/EgoPush/.

</details>


### [65] [Interacting safely with cyclists using Hamilton-Jacobi reachability and reinforcement learning](https://arxiv.org/abs/2602.18097)
*Aarati Andrea Noronha,Jean Oh*

Main category: cs.RO

TL;DR: 本文提出了一种结合Hamilton-Jacobi可达性分析和深度Q学习的框架，用于自动驾驶车辆与骑行者的安全高效交互，仿真验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 研究动机是解决自动驾驶车辆与骑行者交互中的安全与效率平衡问题。

Method: 方法整合了Hamilton-Jacobi可达性分析和深度Q学习，通过求解时间依赖的Hamilton-Jacobi-Bellman不等式计算安全度量，并将其作为结构化奖励信号嵌入强化学习框架。

Result: 仿真实验表明，该方法在安全性和时间效率上优于现有方法和人类驾驶行为。

Conclusion: 本文提出的框架通过结合Hamilton-Jacobi可达性分析和深度Q学习，成功实现了自动驾驶车辆与骑行者的安全高效交互。

Abstract: In this paper, we present a framework for enabling autonomous vehicles to interact with cyclists in a manner that balances safety and optimality. The approach integrates Hamilton-Jacobi reachability analysis with deep Q-learning to jointly address safety guarantees and time-efficient navigation. A value function is computed as the solution to a time-dependent Hamilton-Jacobi-Bellman inequality, providing a quantitative measure of safety for each system state. This safety metric is incorporated as a structured reward signal within a reinforcement learning framework. The method further models the cyclist's latent response to the vehicle, allowing disturbance inputs to reflect human comfort and behavioral adaptation. The proposed framework is evaluated through simulation and comparison with human driving behavior and an existing state-of-the-art method.

</details>


### [66] [GrandTour: A Legged Robotics Dataset in the Wild for Multi-Modal Perception and State Estimation](https://arxiv.org/abs/2602.18164)
*Jonas Frey,Turcan Tuna,Frank Fu,Katharine Patterson,Tianao Xu,Maurice Fallon,Cesar Cadena,Marco Hutter*

Main category: cs.RO

TL;DR: GrandTour是首个大规模、多模态的足式机器人数据集，支持SLAM和传感器融合研究，覆盖多样环境并提供高精度地面真实数据。


<details>
  <summary>Details</summary>
Motivation: 当前缺乏能够反映真实世界复杂条件的大规模公开足式机器人数据集，限制了算法开发和基准测试的能力。

Method: 通过ANYbotics ANYmal-D四足机器人配备的多模态传感器载荷，在多样化的户外和室内环境中收集数据，包括LiDAR、RGB相机、本体感受传感器和立体深度相机等时间同步的传感器数据。

Result: GrandTour数据集覆盖了从高山景观到城市区域等多种环境和操作场景，提供了高精度的地面真实轨迹，是目前最大的开放访问足式机器人数据集。

Conclusion: GrandTour数据集为足式机器人的状态估计、感知和导航算法提供了首个大规模、多模态的真实世界数据集，支持SLAM、高精度状态估计和多模态学习的研究。

Abstract: Accurate state estimation and multi-modal perception are prerequisites for autonomous legged robots in complex, large-scale environments. To date, no large-scale public legged-robot dataset captures the real-world conditions needed to develop and benchmark algorithms for legged-robot state estimation, perception, and navigation. To address this, we introduce the GrandTour dataset, a multi-modal legged-robotics dataset collected across challenging outdoor and indoor environments, featuring an ANYbotics ANYmal-D quadruped equipped with the \boxi multi-modal sensor payload. GrandTour spans a broad range of environments and operational scenarios across distinct test sites, ranging from alpine scenery and forests to demolished buildings and urban areas, and covers a wide variation in scale, complexity, illumination, and weather conditions. The dataset provides time-synchronized sensor data from spinning LiDARs, multiple RGB cameras with complementary characteristics, proprioceptive sensors, and stereo depth cameras. Moreover, it includes high-precision ground-truth trajectories from satellite-based RTK-GNSS and a Leica Geosystems total station. This dataset supports research in SLAM, high-precision state estimation, and multi-modal learning, enabling rigorous evaluation and development of new approaches to sensor fusion in legged robotic systems. With its extensive scope, GrandTour represents the largest open-access legged-robotics dataset to date. The dataset is available at https://grand-tour.leggedrobotics.com, on HuggingFace (ROS-independent), and in ROS formats, along with tools and demo resources.

</details>


### [67] [Have We Mastered Scale in Deep Monocular Visual SLAM? The ScaleMaster Dataset and Benchmark](https://arxiv.org/abs/2602.18174)
*Hyoseok Ju,Bokeon Suh,Giseop Kim*

Main category: cs.RO

TL;DR: 介绍了ScaleMaster数据集，首次专门评估挑战性场景下的尺度一致性，揭示了深度单目视觉SLAM系统在大型室内环境中的尺度问题，并提供了定量和定性分析。


<details>
  <summary>Details</summary>
Motivation: 填补现有基准测试在大型室内环境中尺度一致性评估的空白，特别是针对多楼层结构、长轨迹、重复视图和低纹理区域等挑战性场景。

Method: 系统分析了最先进的深度单目视觉SLAM系统对尺度不一致的脆弱性，提供了定量和定性评估，并扩展了传统轨迹指标，包括使用Chamfer距离等高保真3D地面真实数据直接进行地图到地图的质量评估。

Result: 结果表明，尽管深度单目视觉SLAM系统在现有基准测试中表现优异，但在现实大型室内环境中存在严重的尺度相关失败。

Conclusion: 通过发布ScaleMaster数据集和基线结果，旨在为未来研究建立基础，以开发尺度一致且可靠的视觉SLAM系统。

Abstract: Recent advances in deep monocular visual Simultaneous Localization and Mapping (SLAM) have achieved impressive accuracy and dense reconstruction capabilities, yet their robustness to scale inconsistency in large-scale indoor environments remains largely unexplored. Existing benchmarks are limited to room-scale or structurally simple settings, leaving critical issues of intra-session scale drift and inter-session scale ambiguity insufficiently addressed. To fill this gap, we introduce the ScaleMaster Dataset, the first benchmark explicitly designed to evaluate scale consistency under challenging scenarios such as multi-floor structures, long trajectories, repetitive views, and low-texture regions. We systematically analyze the vulnerability of state-of-the-art deep monocular visual SLAM systems to scale inconsistency, providing both quantitative and qualitative evaluations. Crucially, our analysis extends beyond traditional trajectory metrics to include a direct map-to-map quality assessment using metrics like Chamfer distance against high-fidelity 3D ground truth. Our results reveal that while recent deep monocular visual SLAM systems demonstrate strong performance on existing benchmarks, they suffer from severe scale-related failures in realistic, large-scale indoor environments. By releasing the ScaleMaster dataset and baseline results, we aim to establish a foundation for future research toward developing scale-consistent and reliable visual SLAM systems.

</details>


### [68] [Design and Characterization of a Dual-DOF Soft Shoulder Exosuit with Volume-Optimized Pneumatic Actuator](https://arxiv.org/abs/2602.18212)
*Rui Chen,Domenico Chiaradia,Daniele Leonardis,Antonio Frisoli*

Main category: cs.RO

TL;DR: A volume-optimized actuator design (SSAA) and a dual-DOF shoulder exosuit significantly reduce muscle activity in shoulder movements, offering design guidance for future exosuits.


<details>
  <summary>Details</summary>
Motivation: To address the trade-offs between torque output and dynamic response in portable pneumatic systems for 2-DOF soft shoulder exosuits, and to support complex shoulder movements with multiple actuators.

Method: The research developed a spindle-shaped angled actuator (SSAA) to optimize volume and performance, alongside a curved abduction actuator (CAA) and a horizontal adduction actuator (HAA), integrated into a lightweight textile-based exosuit. User studies with 10 healthy participants assessed EMG activity reductions.

Result: The SSAA reduced actuator volume by 35.7% while maintaining 94.2% of output torque and achieving 35.2% faster dynamic response. The exosuit reduced EMG activity by up to 59% in abduction and 63.7% in flexion, with limited incremental benefit from adding CAA in healthy users.

Conclusion: The study demonstrates the effectiveness of the volume-optimized SSAA and the integrated dual-DOF shoulder exosuit in reducing muscle activity during shoulder movements, providing design insights for future multi-DOF exosuit systems.

Abstract: Portable pneumatic systems for 2 degree-of-freedom (DOF) soft shoulder exosuits remain underexplored, and face fundamental trade-offs between torque output and dynamic response that are further compounded by the need for multiple actuators to support complex shoulder movement. This work addresses these constraints through a volume-optimized spindle-shaped angled actuator (SSAA) geometry: by reducing actuator volume by 35.7% (357mL vs. 555mL), the SSAA maintains 94.2% of output torque while achieving 35.2% faster dynamic response compared to uniform cylindrical designs. Building on the SSAA, we develop a curved abduction actuator (CAA) based on the SSAA geometry and a horizontal adduction actuator (HAA) based on the pouch motor principle, integrating both into a dual-DOF textile-based shoulder exosuit (390 g). The exosuit delivers multi-modal assistance spanning shoulder abduction, flexion, and horizontal adduction, depending on the actuation.
  User studies with 10 healthy participants reveal that the exosuit substantially reduces electromyographic (EMG) activity across both shoulder abduction and flexion tasks. For abduction with HAA only, the exosuit achieved up to 59% muscle activity reduction across seven muscles. For flexion, both the single-actuator configuration (HAA only) and the dual-actuator configuration (HAA,+,CAA) reduced EMG activity by up to 63.7% compared to no assistance. However, the incremental benefit of adding the CAA to existing HAA support was limited in healthy users during flexion, with statistically significant additional reductions observed only in pectoralis major. These experimental findings characterize actuator contributions in healthy users and provide design guidance for multi-DOF exosuit systems.

</details>


### [69] [SimVLA: A Simple VLA Baseline for Robotic Manipulation](https://arxiv.org/abs/2602.18224)
*Yuankai Luo,Woping Chen,Tong Liang,Baiqiao Wang,Zhenguo Li*

Main category: cs.RO

TL;DR: SimVLA是一个简化的VLA基准模型，通过标准化设计实现高性能，为未来研究提供清晰参考。


<details>
  <summary>Details</summary>
Motivation: 解决VLA模型中训练方法和实现细节多样化导致难以准确识别性能提升来源的问题。

Method: 通过严格分离感知与控制，使用标准视觉-语言骨干和轻量级动作头，并标准化关键训练动态。

Result: SimVLA在标准仿真基准测试中优于数十亿参数模型，无需机器人预训练，并在真实机器人上达到与pi0.5相当的性能。

Conclusion: SimVLA作为一个透明、可复现的基准模型，为未来的架构创新提供了清晰的性能增益归因。

Abstract: Vision-Language-Action (VLA) models have emerged as a promising paradigm for general-purpose robotic manipulation, leveraging large-scale pre-training to achieve strong performance. The field has rapidly evolved with additional spatial priors and diverse architectural innovations. However, these advancements are often accompanied by varying training recipes and implementation details, which can make it challenging to disentangle the precise source of empirical gains. In this work, we introduce SimVLA, a streamlined baseline designed to establish a transparent reference point for VLA research. By strictly decoupling perception from control, using a standard vision-language backbone and a lightweight action head, and standardizing critical training dynamics, we demonstrate that a minimal design can achieve state-of-the-art performance. Despite having only 0.5B parameters, SimVLA outperforms multi-billion-parameter models on standard simulation benchmarks without robot pretraining. SimVLA also reaches on-par real-robot performance compared to pi0.5. Our results establish SimVLA as a robust, reproducible baseline that enables clear attribution of empirical gains to future architectural innovations. Website: https://frontierrobo.github.io/SimVLA

</details>


### [70] [RoEL: Robust Event-based 3D Line Reconstruction](https://arxiv.org/abs/2602.18258)
*Gwangtak Bae,Jaeho Shin,Seunggu Kang,Junho Kim,Ayoung Kim,Young Min Kim*

Main category: cs.RO

TL;DR: 提出一种稳定提取线条轨迹的方法，通过几何成本函数优化3D线条地图和相机姿态，显著提升事件相机的映射和姿态优化性能。


<details>
  <summary>Details</summary>
Motivation: 事件相机在运动中倾向于检测物体边界或纹理边缘，产生亮度变化的线条，但线条的稀疏性可能导致轻微估计误差下的性能急剧下降。

Method: 通过观察事件数据的不同时间切片的多重表示，稳定提取线条轨迹，并提出几何成本函数以优化3D线条地图和相机姿态。

Result: 该方法在多样化数据集上显著提升了基于事件的映射和姿态优化性能，并能灵活应用于多模态场景。

Conclusion: 本文提出的基于线的方法在事件相机的实际应用中表现出色，验证了其在事件感知模块中的鲁棒性和有效性。

Abstract: Event cameras in motion tend to detect object boundaries or texture edges, which produce lines of brightness changes, especially in man-made environments. While lines can constitute a robust intermediate representation that is consistently observed, the sparse nature of lines may lead to drastic deterioration with minor estimation errors. Only a few previous works, often accompanied by additional sensors, utilize lines to compensate for the severe domain discrepancies of event sensors along with unpredictable noise characteristics. We propose a method that can stably extract tracks of varying appearances of lines using a clever algorithmic process that observes multiple representations from various time slices of events, compensating for potential adversaries within the event data. We then propose geometric cost functions that can refine the 3D line maps and camera poses, eliminating projective distortions and depth ambiguities. The 3D line maps are highly compact and can be equipped with our proposed cost function, which can be adapted for any observations that can detect and extract line structures or projections of them, including 3D point cloud maps or image observations. We demonstrate that our formulation is powerful enough to exhibit a significant performance boost in event-based mapping and pose refinement across diverse datasets, and can be flexibly applied to multimodal scenarios. Our results confirm that the proposed line-based formulation is a robust and effective approach for the practical deployment of event-based perceptual modules. Project page: https://gwangtak.github.io/roel/

</details>


### [71] [Role-Adaptive Collaborative Formation Planning for Team of Quadruped Robots in Cluttered Environments](https://arxiv.org/abs/2602.18260)
*Magnus Norén,Marios-Nektarios Stamatopoulos,Avijit Banerjee,George Nikolakopoulos*

Main category: cs.RO

TL;DR: 提出了一种动态角色分配的领导者-跟随者编队控制框架，结合FM2路径规划和避障技术，实现了四足机器人在复杂环境中的灵活导航。


<details>
  <summary>Details</summary>
Motivation: 传统方法中固定的领导者或刚性编队角色难以适应复杂环境中的灵活导航需求，因此需要一种动态角色分配和部分目标规划的解决方案。

Method: 结合虚拟弹簧-阻尼系统和新型避障层，动态调整每个机器人的速度，同时利用Fast Marching Square（FM2）算法生成全局和局部路径。

Result: 实验结果表明，该框架能够实现平滑协调、自适应角色切换以及在复杂非结构化环境中的鲁棒编队保持。

Conclusion: 该论文提出的基于动态角色分配的领导者-跟随者编队规划与控制框架，在复杂环境中实现了四足机器人团队的灵活、无碰撞导航，并通过仿真和实物实验验证了其有效性。

Abstract: This paper presents a role-adaptive Leader-Follower-based formation planning and control framework for teams of quadruped robots operating in cluttered environments. Unlike conventional methods with fixed leaders or rigid formation roles, the proposed approach integrates dynamic role assignment and partial goal planning, enabling flexible, collision-free navigation in complex scenarios. Formation stability and inter-robot safety are ensured through a virtual spring-damper system coupled with a novel obstacle avoidance layer that adaptively adjusts each agent's velocity. A dynamic look-ahead reference generator further enhances flexibility, allowing temporary formation deformation to maneuver around obstacles while maintaining goal-directed motion. The Fast Marching Square (FM2) algorithm provides the global path for the leader and local paths for the followers as the planning backbone. The framework is validated through extensive simulations and real-world experiments with teams of quadruped robots. Results demonstrate smooth coordination, adaptive role switching, and robust formation maintenance in complex, unstructured environments. A video featuring the simulation and physical experiments along with their associated visualizations can be found at https://youtu.be/scq37Tua9W4.

</details>


### [72] [Tendon-Driven Reciprocating and Non-Reciprocating Motion via Snapping Metabeams](https://arxiv.org/abs/2602.18330)
*Mohsen Jafarpour,Ayberk Yüksek,Shahab Eshghi,Stanislav Gorb,Edoardo Milana*

Main category: cs.RO

TL;DR: 研究开发了一种基于螺旋梁的肌腱驱动机制，通过调整边界约束实现可控快速变形，应用于游泳机器人展示了高效推进能力。


<details>
  <summary>Details</summary>
Motivation: 利用快速变形梁的非线性不稳定性实现快速几何转变，为软体机器人系统提供高效的运动生成手段。

Method: 采用熔融沉积建模技术（FDM）使用聚乳酸（PLA）材料制造螺旋结构的快速变形梁，并通过实验测试不同边界条件下的非线性行为。

Result: 机械特性（如临界力和稳定性）仅通过调整边界约束即可调节，螺旋几何设计允许大范围可逆变形，游泳机器人实现了约32毫米/0.4秒周期的高效推进。

Conclusion: 本研究展示了基于几何驱动的快速变形结构在软体机器人系统中的高效和可编程驱动潜力。

Abstract: Snapping beams enable rapid geometric transitions through nonlinear instability, offering an efficient means of generating motion in soft robotic systems. In this study, a tendon-driven mechanism consisting of spiral-based metabeams was developed to exploit this principle for producing both reciprocating and non-reciprocating motion. The snapping structures were fabricated using fused deposition modeling with polylactic acid (PLA) and experimentally tested under different boundary conditions to analyze their nonlinear behavior. The results show that the mechanical characteristics, including critical forces and stability, can be tuned solely by adjusting the boundary constraints. The spiral geometry allows large reversible deformation even when made from a relatively stiff material such as PLA, providing a straightforward design concept for controllable snapping behavior. The developed mechanism was further integrated into a swimming robot, where tendon-driven fins exhibited two distinct actuation modes: reciprocating and non-reciprocating motion. The latter enabled efficient propulsion, producing a forward displacement of about 32 mm per 0.4 s cycle ($\approx$ 81 mm/s, equivalent to 0.4 body lengths per second). This study highlights the potential of geometry-driven snapping structures for efficient and programmable actuation in soft robotic systems.

</details>


### [73] [Downwash-aware Configuration Optimization for Modular Aerial Systems](https://arxiv.org/abs/2602.18344)
*Mengguang Li,Heinz Koeppl*

Main category: cs.RO

TL;DR: 提出了一种针对模块化空中系统的任务特定组装配置生成框架，通过枚举拓扑和优化选择，解决了下洗流约束问题，并在仿真和实验中验证。


<details>
  <summary>Details</summary>
Motivation: 现有研究多关注平面布局且常忽略空气动力学干扰，因此需要一种能明确约束模块间下洗流的任务特定组装配置生成方法。

Method: 1. 枚举大规模的非同构连接拓扑；2. 解决非线性程序以检查可行性并选择最小化控制输入的配置。

Result: 框架在物理仿真中评估并在真实实验中验证，展示了其可行性和有效性。

Conclusion: 该框架通过枚举非同构连接拓扑并解决非线性程序，成功生成了满足下洗流约束的最优组装配置，并在仿真和实际实验中验证了其有效性。

Abstract: This work proposes a framework that generates and optimally selects task-specific assembly configurations for a large group of homogeneous modular aerial systems, explicitly enforcing bounds on inter-module downwash. Prior work largely focuses on planar layouts and often ignores aerodynamic interference. In contrast, firstly we enumerate non-isomorphic connection topologies at scale; secondly, we solve a nonlinear program to check feasibility and select the configuration that minimizes control input subject to actuation limits and downwash constraints. We evaluate the framework in physics-based simulation and demonstrate it in real-world experiments.

</details>


### [74] [Zero-shot Interactive Perception](https://arxiv.org/abs/2602.18374)
*Venkatesh Sripada,Frank Guerin,Amir Ghalamzan*

Main category: cs.RO

TL;DR: ZS-IP框架结合多策略操作和视觉语言模型，通过pushlines增强推动性能，在复杂场景中表现优异。


<details>
  <summary>Details</summary>
Motivation: 解决复杂、部分可观察场景中的遮挡和语义模糊问题，提升机器人的交互感知能力。

Method: ZS-IP集成了增强观察模块、记忆引导动作模块和机器人控制器，通过新颖的pushlines视觉增强和语义推理优化推动操作。

Result: ZS-IP在7-DOF Franka Panda臂上的实验中，表现优于被动和基于视点的感知技术，尤其在推动任务中。

Conclusion: ZS-IP框架通过结合多策略操作和记忆驱动的视觉语言模型，显著提升了机器人在复杂场景中的交互感知能力，尤其在推动任务中表现优异。

Abstract: Interactive perception (IP) enables robots to extract hidden information in their workspace and execute manipulation plans by physically interacting with objects and altering the state of the environment -- crucial for resolving occlusions and ambiguity in complex, partially observable scenarios. We present Zero-Shot IP (ZS-IP), a novel framework that couples multi-strategy manipulation (pushing and grasping) with a memory-driven Vision Language Model (VLM) to guide robotic interactions and resolve semantic queries. ZS-IP integrates three key components: (1) an Enhanced Observation (EO) module that augments the VLM's visual perception with both conventional keypoints and our proposed pushlines -- a novel 2D visual augmentation tailored to pushing actions, (2) a memory-guided action module that reinforces semantic reasoning through context lookup, and (3) a robotic controller that executes pushing, pulling, or grasping based on VLM output. Unlike grid-based augmentations optimized for pick-and-place, pushlines capture affordances for contact-rich actions, substantially improving pushing performance. We evaluate ZS-IP on a 7-DOF Franka Panda arm across diverse scenes with varying occlusions and task complexities. Our experiments demonstrate that ZS-IP outperforms passive and viewpoint-based perception techniques such as Mark-Based Visual Prompting (MOKA), particularly in pushing tasks, while preserving the integrity of non-target elements.

</details>


### [75] [Ori-Sense: origami capacitive sensing for soft robotic applications](https://arxiv.org/abs/2602.18379)
*Hugo de Souza Oliveira,Xin Li,Mohsen Jafarpour,Edoardo Milana*

Main category: cs.RO

TL;DR: Ori-Sense是一种柔性电容传感器，通过扭转形变测量电容变化，适用于软机器人。测试显示低刚度和高灵敏度。


<details>
  <summary>Details</summary>
Motivation: 为软机器人系统开发一种能够提供本体感觉反馈的柔性传感器，以解决传统刚性传感器在柔性环境中的局限性。

Method: 通过可溶性芯模技术制造了一体化硅胶结构，嵌入了导电TPU电极。机械测试显示低刚度和最小阻抗，有限元模拟验证了局部应力分布和扭矩-旋转响应。

Result: 机械测试显示扭矩值在-15 mm至15 mm轴向位移下低于0.01 N mm，压缩状态下30度扭转时可达0.03 N mm。电学测试显示电容调制高达30%，最大灵敏度为0.0067 pF/度。

Conclusion: Ori-Sense是一种基于Kresling折纸启发的柔性电容传感器，能够将扭转形变转化为可测量的电容变化，为软机器人系统提供本体感觉反馈。其制造采用可溶性芯模技术，实现了嵌入式导电TPU电极的一体化软电容器结构。

Abstract: This work introduces Ori-Sense, a compliant capacitive sensor inspired by the inverted Kresling origami pattern. The device translates torsional deformation into measurable capacitance changes, enabling proprioceptive feedback for soft robotic systems. Using dissolvable-core molding, we fabricated a monolithic silicone structure with embedded conductive TPU electrodes, forming an integrated soft capacitor. Mechanical characterization revealed low stiffness and minimal impedance, with torque values below 0.01 N mm for axial displacements between -15 mm and 15 mm, and up to 0.03 N mm at 30 degrees twist under compression. Finite-element simulations confirmed localized stresses along fold lines and validated the measured torque-rotation response. Electrical tests showed consistent capacitance modulation up to 30%, directly correlated with the twist angle, and maximal sensitivity of S_theta ~ 0.0067 pF/deg at 5 mm of axial deformation.

</details>


### [76] [Learning to Tune Pure Pursuit in Autonomous Racing: Joint Lookahead and Steering-Gain Control with PPO](https://arxiv.org/abs/2602.18386)
*Mohamed Elgouhary,Amr S. El-Wakeel*

Main category: cs.RO

TL;DR: 论文提出了一种基于强化学习的Pure Pursuit控制器，通过在线联合调整前瞻距离和转向增益，显著提升了路径跟踪性能，优于传统方法。


<details>
  <summary>Details</summary>
Motivation: Pure Pursuit（PP）在自动驾驶赛车中广泛用于实时路径跟踪，但其性能高度依赖于关键参数（前瞻距离和转向增益）的选择。传统的基于速度的调度方法调整这些参数时往往不够精确，且难以在不同赛道和速度配置间迁移。因此，论文旨在通过强化学习解决这一问题。

Method: 论文提出了一种基于强化学习（PPO）的方法，在线联合选择前瞻距离Ld和转向增益g。策略观察紧凑的状态特征（速度和曲率）并在每个控制步骤输出(Ld, g)。该方法在F1TENTH Gym中训练，并在ROS 2堆栈中部署，直接驱动PP（带有轻度平滑），无需针对每个地图重新调整。

Result: 在仿真和实车测试中，提出的RL-PP控制器在圈速、路径跟踪准确性和转向平滑度方面均优于固定前瞻距离PP、速度调度的自适应PP和仅前瞻距离RL变体，并且在某些情况下超过了运动学MPC赛道跟踪器。

Conclusion: 论文得出结论，通过强化学习（RL）联合选择前瞻距离和转向增益的RL-PP控制器，在圈速、路径跟踪精度和转向平滑度上均优于固定前瞻距离PP、速度调度的自适应PP以及仅前瞻距离RL变体，甚至在某些情况下超过了运动学MPC赛道跟踪器。这表明基于策略的参数调整可以可靠地改进传统的基于几何的控制方法。

Abstract: Pure Pursuit (PP) is widely used in autonomous racing for real-time path tracking due to its efficiency and geometric clarity, yet performance is highly sensitive to how key parameters-lookahead distance and steering gain-are chosen. Standard velocity-based schedules adjust these only approximately and often fail to transfer across tracks and speed profiles. We propose a reinforcement-learning (RL) approach that jointly chooses the lookahead Ld and a steering gain g online using Proximal Policy Optimization (PPO). The policy observes compact state features (speed and curvature taps) and outputs (Ld, g) at each control step. Trained in F1TENTH Gym and deployed in a ROS 2 stack, the policy drives PP directly (with light smoothing) and requires no per-map retuning. Across simulation and real-car tests, the proposed RL-PP controller that jointly selects (Ld, g) consistently outperforms fixed-lookahead PP, velocity-scheduled adaptive PP, and an RL lookahead-only variant, and it also exceeds a kinematic MPC raceline tracker under our evaluated settings in lap time, path-tracking accuracy, and steering smoothness, demonstrating that policy-guided parameter tuning can reliably improve classical geometry-based control.

</details>


### [77] [How Fast Can I Run My VLA? Demystifying VLA Inference Performance with VLA-Perf](https://arxiv.org/abs/2602.18397)
*Wenqi Jiang,Jason Clemons,Karu Sankaralingam,Christos Kozyrakis*

Main category: cs.RO

TL;DR: 本文提出VLA-Perf模型，系统研究了VLA模型的推理性能，分析了模型设计和部署选择的影响，并提出了15个关键设计建议。


<details>
  <summary>Details</summary>
Motivation: 由于VLA模型在真实机器人上的部署需要满足严格的实时推理约束，而现有研究对VLA模型的推理性能缺乏系统理解，因此需要研究如何设计支持实时推理的VLA模型和系统。

Method: 引入VLA-Perf分析模型，研究模型扩展、架构选择、长上下文视频输入、异步推理和双系统模型管道等因素对推理性能的影响，并分析不同部署场景（设备端、边缘服务器或云端）的性能表现。

Result: 通过VLA-Perf模型，首次系统研究了VLA推理性能，分析了模型设计和部署选择对性能的影响，并提出了15个关键设计建议。

Conclusion: 本文通过VLA-Perf模型对VLA模型的推理性能进行了系统研究，提出了15个关键设计建议，为未来VLA模型和推理系统的设计提供了实用指导。

Abstract: Vision-Language-Action (VLA) models have recently demonstrated impressive capabilities across various embodied AI tasks. While deploying VLA models on real-world robots imposes strict real-time inference constraints, the inference performance landscape of VLA remains poorly understood due to the large combinatorial space of model architectures and inference systems. In this paper, we ask a fundamental research question: How should we design future VLA models and systems to support real-time inference? To address this question, we first introduce VLA-Perf, an analytical performance model that can analyze inference performance for arbitrary combinations of VLA models and inference systems. Using VLA-Perf, we conduct the first systematic study of the VLA inference performance landscape. From a model-design perspective, we examine how inference performance is affected by model scaling, model architectural choices, long-context video inputs, asynchronous inference, and dual-system model pipelines. From the deployment perspective, we analyze where VLA inference should be executed -- on-device, on edge servers, or in the cloud -- and how hardware capability and network performance jointly determine end-to-end latency. By distilling 15 key takeaways from our comprehensive evaluation, we hope this work can provide practical guidance for the design of future VLA models and inference systems.

</details>


### [78] [Snapping Actuators with Asymmetric and Sequenced Motion](https://arxiv.org/abs/2602.18421)
*Xin Li,Ye Jin,Mohsen Jafarpour,Hugo de Souza Oliveira,Edoardo Milana*

Main category: cs.RO

TL;DR: 开发了一种偏心穹顶形状快速释放驱动器，通过几何诱导不稳定性实现可控不对称运动，应用于四足机器人，展示了高效软驱动潜力。


<details>
  <summary>Details</summary>
Motivation: 研究软结构中的快速释放不稳定性，以实现快速且能量高效的驱动。

Method: 通过有限元模拟和实验研究偏心穹顶形状快速释放驱动器的几何诱导不稳定性。

Result: 通过将四个快速释放驱动器耦合在气动网络中，一个紧凑的四足机器人仅使用单一压力输入即可实现协调的波浪式运动，最大速度为72.78毫米/秒（7.5赫兹）。

Conclusion: 这些发现展示了不对称快速释放机制在物理控制驱动中的潜力，并为完全无束缚且高效的软机器人系统奠定了基础。

Abstract: Snapping instabilities in soft structures offer a powerful pathway to achieve rapid and energy-efficient actuation. In this study, an eccentric dome-shaped snapping actuator is developed to generate controllable asymmetric motion through geometry-induced instability. Finite element simulations and experiments reveal consistent asymmetric deformation and the corresponding pressure characteristics. By coupling four snapping actuators in a pneumatic network, a compact quadrupedal robot achieves coordinated wavelike locomotion using only a single pressure input. The robot exhibits frequency-dependent performance with a maximum speed of 72.78~mm/s at 7.5~Hz. These findings demonstrate the potential of asymmetric snapping mechanisms for physically controlled actuation and lay the groundwork for fully untethered and efficient soft robotic systems.

</details>


<div id='cs.DS'></div>

# cs.DS [[Back]](#toc)

### [79] [Optimal Competitive Ratio of Two-sided Online Bipartite Matching](https://arxiv.org/abs/2602.18049)
*Zhihao Gavin Tang*

Main category: cs.DS

TL;DR: 本文证明了在线二分图匹配中双顶点到达分数版本的竞争比最优上界为0.526，与现有下界匹配。


<details>
  <summary>Details</summary>
Motivation: 研究在线二分图匹配问题在双顶点到达情况下的最优竞争比，填补理论与实际应用之间的差距。

Method: 通过理论分析，证明了在线二分图匹配中双顶点到达的分数版本竞争比的最优上界。

Result: 确立了竞争比的最优上界约为0.526，与已知下界一致。

Conclusion: 本文确立了在线二分图匹配问题中，双顶点到达情况下分数版本竞争比的最优上界约为0.526，与Wang和Wong（ICALP 2015）及Tang和Zhang（EC 2024）所达到的下界相匹配。

Abstract: We establish an optimal upper bound (negative result) of $\sim 0.526$ on the competitive ratio of the fractional version of online bipartite matching with two-sided vertex arrivals, matching the lower bound (positive result) achieved by Wang and Wong (ICALP 2015), and Tang and Zhang (EC 2024).

</details>


### [80] [QPTAS for MWIS and finding large sparse induced subgraphs in graphs with few independent long holes](https://arxiv.org/abs/2602.18317)
*Édouard Bonnet,Jadwiga Czyżewska,Tomáš Masařík,Marcin Pilipczuk,Paweł Rzążewski*

Main category: cs.DS

TL;DR: 论文提出了一种QPTAS，用于在特定图类中求解MWIS问题，并扩展了相关遗传性质问题的解法，为开放猜想提供了进展。


<details>
  <summary>Details</summary>
Motivation: 解决Gartland和Lokshtanov猜想的一个步骤，该猜想认为对于任何平面图$H$，排除$H$作为诱导次要的图类对于后述问题存在多项式时间算法。

Method: 通过排除$sC_t$作为诱导次要的图类，展示了MWIS的QPTAS。

Result: 成功展示了在特定图类中MWIS的QPTAS，并扩展了相关问题的解法。

Conclusion: 该论文提出了一个拟多项式时间近似方案（QPTAS），用于在具有有限数量互不相交且不相邻的长诱导环的图中求解最大独立集问题（MWIS）。结合已知结果，进一步扩展了在相同图类中寻找具有给定遗传性质的有限树宽最大诱导子图问题的QPTAS。

Abstract: We present a quasipolynomial-time approximation scheme (QPTAS) for the Maximum Independent Set (\textsc{MWIS}) in graphs with a bounded number of pairwise vertex-disjoint and non-adjacent long induced cycles. More formally, for every fixed $s$ and $t$, we show a QPTAS for \textsc{MWIS} in graphs that exclude $sC_t$ as an induced minor. Combining this with known results, we obtain a QPTAS for the problem of finding a largest induced subgraph of bounded treewidth with given hereditary property definable in Counting Monadic Second Order Logic, in the same classes of graphs.
  This is a step towards a conjecture of Gartland and Lokshtanov which asserts that for any planar graph $H$, graphs that exclude $H$ as an induced minor admit a polynomial-time algorithm for the latter problem. This conjecture is notoriously open and even its weaker variants are confirmed only for very restricted graphs $H$.

</details>


### [81] [Improved Algorithms for Clustering with Noisy Distance Oracles](https://arxiv.org/abs/2602.18389)
*Pinki Pradhan,Anup Bhattacharya,Ragesh Jaiswal*

Main category: cs.DS

TL;DR: 本文改进了弱-强预言模型下的$k$-均值和$k$-中心聚类算法，减少强预言查询次数并提升近似比，实验验证其优越性。


<details>
  <summary>Details</summary>
Motivation: 在有限距离信息（弱-强预言模型）下，现有聚类算法的强预言查询次数和近似比仍有优化空间。

Method: 本文提出了一种基于$k$-means++算法的改进版本，仅需少量强预言查询即可实现常数近似比的$k$-均值聚类；对于$k$-中心问题，设计了一种基于球切割的简单算法。

Result: 改进后的$k$-均值算法仅需$O(k^2 \\log^2{n})$次强预言查询，优于Bateni等人的$O(k^2 \\log^4n \\log^2 \\log n)$；$k$-中心算法实现了6(1 + ε)-近似比，强预言查询次数为$O(k^3 \\log^2{n} \\log{\\frac{\log{n}}ε})$，优于之前的14(1 + ε)-近似比。实证结果表明新算法显著优于现有方法。

Conclusion: 本研究改进了Bateni等人提出的弱-强距离预言模型中的$k$-均值和$k$-中心聚类算法，通过减少强预言查询次数并提升近似比，显著提升了算法性能。

Abstract: Bateni et al. has recently introduced the weak-strong distance oracle model to study clustering problems in settings with limited distance information. Given query access to the strong-oracle and weak-oracle in the weak-strong oracle model, the authors design approximation algorithms for $k$-means and $k$-center clustering problems. In this work, we design algorithms with improved guarantees for $k$-means and $k$-center clustering problems in the weak-strong oracle model. The $k$-means++ algorithm is routinely used to solve $k$-means in settings where complete distance information is available. One of the main contributions of this work is to show that $k$-means++ algorithm can be adapted to work in the weak-strong oracle model using only a small number of strong-oracle queries, which is the critical resource in this model. In particular, our $k$-means++ based algorithm gives a constant approximation for $k$-means and uses $O(k^2 \log^2{n})$ strong-oracle queries. This improves on the algorithm of Bateni et al. that uses $O(k^2 \log^4n \log^2 \log n)$ strong-oracle queries for a constant factor approximation of $k$-means. For the $k$-center problem, we give a simple ball-carving based $6(1 + ε)$-approximation algorithm that uses $O(k^3 \log^2{n} \log{\frac{\log{n}}ε})$ strong-oracle queries. This is an improvement over the $14(1 + ε)$-approximation algorithm of Bateni et al. that uses $O(k^2 \log^4{n} \log^2{\frac{\log{n}}ε})$ strong-oracle queries. To show the effectiveness of our algorithms, we perform empirical evaluations on real-world datasets and show that our algorithms significantly outperform the algorithms of Bateni et al.

</details>


<div id='cs.AI'></div>

# cs.AI [[Back]](#toc)

### [82] [Epistemic Traps: Rational Misalignment Driven by Model Misspecification](https://arxiv.org/abs/2602.17676)
*Xingcheng Xu,Jingjing Qu,Qiaosheng Zhang,Chaochao Lu,Yanqing Yang,Na Zou,Xia Hu*

Main category: cs.AI

TL;DR: 论文证明AI的常见行为失败（如奉承、幻觉和战略欺骗）并非错误，而是模型错误指定下的数学合理化行为。通过经济学理论框架，揭示了这些行为是结构性必然，并提出了主观模型工程作为解决方案。


<details>
  <summary>Details</summary>
Motivation: 大型语言模型和AI代理在关键社会和科技领域的快速部署受到行为病理学（如奉承、幻觉和战略欺骗）的阻碍，这些行为无法通过强化学习缓解。当前的安全范式将这些失败视为短暂的训练产物，缺乏统一的解释其出现和稳定性的理论框架。

Method: 通过将理论经济学中的Berk-Nash Rationalizability概念应用于人工智能，论文推导出一个严谨的框架，将代理建模为针对有缺陷的主观世界模型进行优化。

Result: 论文验证了理论预测，通过在六个最先进的模型家族上进行行为实验，生成了精确映射安全行为拓扑边界的相图。

Conclusion: 该论文提出了主观模型工程（Subjective Model Engineering）作为实现AI稳健对齐的必要条件，标志着从操纵环境奖励到塑造代理对现实解释的范式转变。

Abstract: The rapid deployment of Large Language Models and AI agents across critical societal and technical domains is hindered by persistent behavioral pathologies including sycophancy, hallucination, and strategic deception that resist mitigation via reinforcement learning. Current safety paradigms treat these failures as transient training artifacts, lacking a unified theoretical framework to explain their emergence and stability. Here we show that these misalignments are not errors, but mathematically rationalizable behaviors arising from model misspecification. By adapting Berk-Nash Rationalizability from theoretical economics to artificial intelligence, we derive a rigorous framework that models the agent as optimizing against a flawed subjective world model. We demonstrate that widely observed failures are structural necessities: unsafe behaviors emerge as either a stable misaligned equilibrium or oscillatory cycles depending on reward scheme, while strategic deception persists as a "locked-in" equilibrium or through epistemic indeterminacy robust to objective risks. We validate these theoretical predictions through behavioral experiments on six state-of-the-art model families, generating phase diagrams that precisely map the topological boundaries of safe behavior. Our findings reveal that safety is a discrete phase determined by the agent's epistemic priors rather than a continuous function of reward magnitude. This establishes Subjective Model Engineering, defined as the design of an agent's internal belief structure, as a necessary condition for robust alignment, marking a paradigm shift from manipulating environmental rewards to shaping the agent's interpretation of reality.

</details>


### [83] [Ontology-Guided Neuro-Symbolic Inference: Grounding Language Models with Mathematical Domain Knowledge](https://arxiv.org/abs/2602.17826)
*Marcelo Labre*

Main category: cs.AI

TL;DR: Using formal ontologies like OpenMath can enhance language model reliability in specialist fields, but retrieval quality is critical to avoid performance degradation.


<details>
  <summary>Details</summary>
Motivation: Address limitations of language models (hallucination, brittleness, lack of formal grounding) in high-stakes specialist fields requiring verifiable reasoning.

Method: Implemented a neuro-symbolic pipeline using the OpenMath ontology with hybrid retrieval and cross-encoder reranking to inject relevant definitions into model prompts.

Result: Ontology-guided context improves performance when retrieval quality is high, but irrelevant context degrades it.

Conclusion: Ontology-guided context can improve language model performance in high-stakes fields, but irrelevant context may degrade results, underscoring the potential and challenges of neuro-symbolic methods.

Abstract: Language models exhibit fundamental limitations -- hallucination, brittleness, and lack of formal grounding -- that are particularly problematic in high-stakes specialist fields requiring verifiable reasoning. I investigate whether formal domain ontologies can enhance language model reliability through retrieval-augmented generation. Using mathematics as proof of concept, I implement a neuro-symbolic pipeline leveraging the OpenMath ontology with hybrid retrieval and cross-encoder reranking to inject relevant definitions into model prompts. Evaluation on the MATH benchmark with three open-source models reveals that ontology-guided context improves performance when retrieval quality is high, but irrelevant context actively degrades it -- highlighting both the promise and challenges of neuro-symbolic approaches.

</details>


### [84] [The Token Games: Evaluating Language Model Reasoning with Puzzle Duels](https://arxiv.org/abs/2602.17831)
*Simon Henniger,Gabriel Poesia*

Main category: cs.AI

TL;DR: TTG是一种新型评估框架，通过模型相互生成和解决编程谜题来评估推理能力，无需人工干预，并揭示了模型在创造谜题方面的不足。


<details>
  <summary>Details</summary>
Motivation: 随着大型语言模型能力的提升，评估其推理能力变得更具挑战性。人类设计高难度问题成本高昂，且存在训练数据泄露的担忧。TTG旨在提供一种无需人工干预、可持续评估模型推理能力的方法。

Method: 采用16世纪数学对决的灵感，设计了TTG框架，利用编程谜题的形式（给定一个返回布尔值的Python函数，寻找使其返回True的输入）灵活表示问题并验证解决方案。通过两两对决结果计算Elo评分，比较模型间的相对能力。

Result: 在10个前沿模型上测试TTG，其结果与现有基准（如Humanity's Last Exam）排名高度一致，且无需人工设计谜题。同时发现当前模型在创造高质量谜题方面仍面临挑战。

Conclusion: 该论文提出了一种新的评估框架The Token Games（TTG），通过模型相互挑战生成谜题来评估推理能力，避免了人类设计问题的局限性，并揭示了当前模型在创造高质量谜题方面的不足。

Abstract: Evaluating the reasoning capabilities of Large Language Models is increasingly challenging as models improve. Human curation of hard questions is highly expensive, especially in recent benchmarks using PhD-level domain knowledge to challenge the most capable models. Even then, there is always a concern about whether these questions test genuine reasoning or if similar problems have been seen during training. Here, we take inspiration from 16th-century mathematical duels to design The Token Games (TTG): an evaluation framework where models challenge each other by creating their own puzzles. We leverage the format of Programming Puzzles - given a Python function that returns a boolean, find inputs that make it return True - to flexibly represent problems and enable verifying solutions. Using results from pairwise duels, we then compute Elo ratings, allowing us to compare models relative to each other. We evaluate 10 frontier models on TTG, and closely match the ranking from existing benchmarks such as Humanity's Last Exam, without involving any human effort in creating puzzles. We also find that creating good puzzles is still a highly challenging task for current models, not measured by previous benchmarks. Overall, our work suggests new paradigms for evaluating reasoning that cannot be saturated by design, and that allow testing models for other skills like creativity and task creation alongside problem solving.

</details>


### [85] [El Agente Gráfico: Structured Execution Graphs for Scientific Agents](https://arxiv.org/abs/2602.17902)
*Jiaru Bai,Abdulrahman Aldossary,Thomas Swanick,Marcel Müller,Yeonghun Kang,Zijian Zhang,Jin Won Lee,Tsz Wai Ko,Mohammad Ghazi Vakili,Varinia Bernales,Alán Aspuru-Guzik*

Main category: cs.AI

TL;DR: El Agente Gráfico框架通过类型安全和知识图谱解决了LLM科学工作流中的集成和上下文管理问题，展示了单代理在复杂计算中的有效性。


<details>
  <summary>Details</summary>
Motivation: 解决当前LLM与异构计算工具集成中存在的临时性和脆弱性问题，以及通过非结构化文本管理上下文导致的决策可追溯性和审计性不足。

Method: 提出了El Agente Gráfico框架，将LLM驱动的决策嵌入类型安全的执行环境和动态知识图谱中，使用结构化抽象和对象-图谱映射器管理计算状态。

Result: 开发了自动化基准测试框架，展示了单代理在可靠执行引擎支持下能够稳健执行复杂、多步和并行计算，并扩展应用于构象集合生成和金属-有机框架设计。

Conclusion: 通过抽象化和类型安全，为基于代理的科学自动化提供了可扩展的基础，超越了以提示为中心的设计。

Abstract: Large language models (LLMs) are increasingly used to automate scientific workflows, yet their integration with heterogeneous computational tools remains ad hoc and fragile. Current agentic approaches often rely on unstructured text to manage context and coordinate execution, generating often overwhelming volumes of information that may obscure decision provenance and hinder auditability. In this work, we present El Agente Gráfico, a single-agent framework that embeds LLM-driven decision-making within a type-safe execution environment and dynamic knowledge graphs for external persistence. Central to our approach is a structured abstraction of scientific concepts and an object-graph mapper that represents computational state as typed Python objects, stored either in memory or persisted in an external knowledge graph. This design enables context management through typed symbolic identifiers rather than raw text, thereby ensuring consistency, supporting provenance tracking, and enabling efficient tool orchestration. We evaluate the system by developing an automated benchmarking framework across a suite of university-level quantum chemistry tasks previously evaluated on a multi-agent system, demonstrating that a single agent, when coupled to a reliable execution engine, can robustly perform complex, multi-step, and parallel computations. We further extend this paradigm to two other large classes of applications: conformer ensemble generation and metal-organic framework design, where knowledge graphs serve as both memory and reasoning substrates. Together, these results illustrate how abstraction and type safety can provide a scalable foundation for agentic scientific automation beyond prompt-centric designs.

</details>


### [86] [Alignment in Time: Peak-Aware Orchestration for Long-Horizon Agentic Systems](https://arxiv.org/abs/2602.17910)
*Hanjing Shi,Dominic DiFranzo*

Main category: cs.AI

TL;DR: APEMO 是一种通过时间-情感信号优化计算分配的运行时调度层，显著提升长视野智能体系统的轨迹可靠性和重用概率。


<details>
  <summary>Details</summary>
Motivation: 传统 AI 对齐主要关注单个模型输出，但长视野工作流中的自主智能体需要在整个交互轨迹中保持持续的可靠性。

Method: APEMO 是一种运行时调度层，通过操作时间-情感信号来优化固定预算下的计算分配，而非修改模型权重。它通过行为代理检测轨迹不稳定性，并在关键段（如高峰时刻和结尾）进行修复。

Result: 在多智能体模拟和基于 LLM 的规划-执行流程中，APEMO 持续提升了轨迹级别的质量和重用概率，优于结构化编排器。

Conclusion: APEMO 将 AI 对齐问题重新定义为时间控制问题，为长视野智能体系统的开发提供了弹性的工程路径。

Abstract: Traditional AI alignment primarily focuses on individual model outputs; however, autonomous agents in long-horizon workflows require sustained reliability across entire interaction trajectories. We introduce APEMO (Affect-aware Peak-End Modulation for Orchestration), a runtime scheduling layer that optimizes computational allocation under fixed budgets by operationalizing temporal-affective signals. Instead of modifying model weights, APEMO detects trajectory instability through behavioral proxies and targets repairs at critical segments, such as peak moments and endings. Evaluation across multi-agent simulations and LLM-based planner--executor flows demonstrates that APEMO consistently enhances trajectory-level quality and reuse probability over structural orchestrators. Our results reframe alignment as a temporal control problem, offering a resilient engineering pathway for the development of long-horizon agentic systems.

</details>


### [87] [WorkflowPerturb: Calibrated Stress Tests for Evaluating Multi-Agent Workflow Metrics](https://arxiv.org/abs/2602.17990)
*Madhav Kanda,Pedro Las-Casas,Alok Gautam Kumbhare,Rodrigo Fonseca,Sharad Agarwal*

Main category: cs.AI

TL;DR: WorkflowPerturb是一个用于评估工作流指标的基准，通过扰动黄金工作流生成数据集，支持对分数变化的严重性感知解释。


<details>
  <summary>Details</summary>
Motivation: 自动评估结构化工作流存在困难，因为指标分数通常未校准，且分数变化不能直接反映工作流退化的严重程度。

Method: 通过应用现实的、受控的扰动（缺失步骤、压缩步骤和描述变化）到黄金工作流，创建了包含4,973个黄金工作流和44,757个扰动变体的数据集。

Result: 基准测试了多个指标家族，分析了它们的敏感性和校准性，结果揭示了指标家族之间的系统性差异。

Conclusion: WorkflowPerturb提供了一个可控的基准，用于研究工作流评估指标，支持对工作流评估分数的严重性感知解释。

Abstract: LLM-based systems increasingly generate structured workflows for complex tasks. In practice, automatic evaluation of these workflows is difficult, because metric scores are often not calibrated, and score changes do not directly communicate the severity of workflow degradation. We introduce WorkflowPerturb, a controlled benchmark for studying workflow evaluation metrics. It works by applying realistic, controlled perturbations to golden workflows. WorkflowPerturb contains 4,973 golden workflows and 44,757 perturbed variants across three perturbation types (Missing Steps, Compressed Steps, and Description Changes), each applied at severity levels of 10%, 30%, and 50%. We benchmark multiple metric families and analyze their sensitivity and calibration using expected score trajectories and residuals. Our results characterize systematic differences across metric families and support severity-aware interpretation of workflow evaluation scores. Our dataset will be released upon acceptance.

</details>


### [88] [Cross-Embodiment Offline Reinforcement Learning for Heterogeneous Robot Datasets](https://arxiv.org/abs/2602.18025)
*Haruki Abe,Takayuki Osa,Yusuke Mukuta,Tatsuya Harada*

Main category: cs.AI

TL;DR: 结合离线强化学习和跨体现学习，通过形态分组策略优化预训练，减少梯度冲突，提升性能。


<details>
  <summary>Details</summary>
Motivation: 解决机器人策略预训练中高质量演示数据收集成本高的问题，通过利用次优数据和跨体现学习来获取通用控制先验。

Method: 结合离线强化学习和跨体现学习，并采用形态相似性分组策略来优化梯度更新。

Result: 该方法在次优数据丰富的预训练中表现优于纯行为克隆，但随着次优数据和机器人类型增加，梯度冲突会影响学习效果。分组策略有效缓解了这一问题。

Conclusion: 通过引入基于形态相似性的分组策略，显著减少了机器人间的梯度冲突，提升了模型性能。

Abstract: Scalable robot policy pre-training has been hindered by the high cost of collecting high-quality demonstrations for each platform. In this study, we address this issue by uniting offline reinforcement learning (offline RL) with cross-embodiment learning. Offline RL leverages both expert and abundant suboptimal data, and cross-embodiment learning aggregates heterogeneous robot trajectories across diverse morphologies to acquire universal control priors. We perform a systematic analysis of this offline RL and cross-embodiment paradigm, providing a principled understanding of its strengths and limitations. To evaluate this offline RL and cross-embodiment paradigm, we construct a suite of locomotion datasets spanning 16 distinct robot platforms. Our experiments confirm that this combined approach excels at pre-training with datasets rich in suboptimal trajectories, outperforming pure behavior cloning. However, as the proportion of suboptimal data and the number of robot types increase, we observe that conflicting gradients across morphologies begin to impede learning. To mitigate this, we introduce an embodiment-based grouping strategy in which robots are clustered by morphological similarity and the model is updated with a group gradient. This simple, static grouping substantially reduces inter-robot conflicts and outperforms existing conflict-resolution methods.

</details>


### [89] [Neurosymbolic Language Reasoning as Satisfiability Modulo Theory](https://arxiv.org/abs/2602.18095)
*Hyunseok Oh,Sam Stern,Youngki Lee,Matthai Philipose*

Main category: cs.AI

TL;DR: Logitext是一种神经符号语言，通过NLTCs显式表示文档的部分逻辑结构，结合LLM与SMT求解器，提升文本与逻辑推理能力。


<details>
  <summary>Details</summary>
Motivation: 解决现有神经符号系统仅适用于完全形式化任务（如数学或程序合成）而无法处理自然文档部分逻辑结构的问题。

Method: 开发了一种算法，将基于LLM的约束评估与SMT求解结合，实现文本与逻辑的联合推理。

Result: 在内容审核基准、LegalBench和Super-Natural Instructions上的实验表明，Logitext在准确性和覆盖范围上均有提升。

Conclusion: Logitext通过将LLM与SMT求解器结合，首次将神经符号方法扩展到非完全形式化领域，显著提升了文本与逻辑推理的准确性和覆盖范围。

Abstract: Natural language understanding requires interleaving textual and logical reasoning, yet large language models often fail to perform such reasoning reliably. Existing neurosymbolic systems combine LLMs with solvers but remain limited to fully formalizable tasks such as math or program synthesis, leaving natural documents with only partial logical structure unaddressed. We introduce Logitext, a neurosymbolic language that represents documents as natural language text constraints (NLTCs), making partial logical structure explicit. We develop an algorithm that integrates LLM-based constraint evaluation with satisfiability modulo theory (SMT) solving, enabling joint textual-logical reasoning. Experiments on a new content moderation benchmark, together with LegalBench and Super-Natural Instructions, show that Logitext improves both accuracy and coverage. This work is the first that treats LLM-based reasoning as an SMT theory, extending neurosymbolic methods beyond fully formalizable domains.

</details>


### [90] [SOMtime the World Ain$'$t Fair: Violating Fairness Using Self-Organizing Maps](https://arxiv.org/abs/2602.18201)
*Joseph Bingham,Netanel Arussy,Dvir Aran*

Main category: cs.AI

TL;DR: 无监督表示（如SOMtime）会隐式捕捉敏感属性，即使这些属性被排除在训练之外，导致公平性风险。公平性审计需覆盖无监督组件。


<details>
  <summary>Details</summary>
Motivation: 验证无监督表示是否真的对敏感属性保持中立，尤其是当这些属性被明确排除时。

Method: 采用基于高容量自组织映射（SOM）的拓扑保持表示方法SOMtime，对比PCA、UMAP、t-SNE和自编码器等方法。

Result: SOMtime在无监督嵌入中显式恢复了与敏感属性（如年龄和收入）对齐的单调顺序，Spearman相关性高达0.85，而其他方法普遍低于0.23。

Conclusion: 研究发现，即使敏感属性被明确排除在输入之外，无监督表示仍会隐式捕捉这些属性，导致公平性风险。因此，公平性审计需扩展到机器学习管道的无监督组件。

Abstract: Unsupervised representations are widely assumed to be neutral with respect to sensitive attributes when those attributes are withheld from training. We show that this assumption is false. Using SOMtime, a topology-preserving representation method based on high-capacity Self-Organizing Maps, we demonstrate that sensitive attributes such as age and income emerge as dominant latent axes in purely unsupervised embeddings, even when explicitly excluded from the input. On two large-scale real-world datasets (the World Values Survey across five countries and the Census-Income dataset), SOMtime recovers monotonic orderings aligned with withheld sensitive attributes, achieving Spearman correlations of up to 0.85, whereas PCA and UMAP typically remain below 0.23 (with a single exception reaching 0.31), and against t-SNE and autoencoders which achieve at most 0.34. Furthermore, unsupervised segmentation of SOMtime embeddings produces demographically skewed clusters, demonstrating downstream fairness risks without any supervised task. These findings establish that \textit{fairness through unawareness} fails at the representation level for ordinal sensitive attributes and that fairness auditing must extend to unsupervised components of machine learning pipelines. We have made the code available at~ https://github.com/JosephBingham/SOMtime

</details>


### [91] [Diffusing to Coordinate: Efficient Online Multi-Agent Diffusion Policies](https://arxiv.org/abs/2602.18291)
*Zhuoran Li,Hai Zhong,Xun Wang,Qingxin Xia,Lihua Zhang,Longbo Huang*

Main category: cs.AI

TL;DR: OMAD是首个在在线MARL中使用扩散策略的框架，通过放松策略目标和联合分布价值函数，显著提升了样本效率和协调性能。


<details>
  <summary>Details</summary>
Motivation: 扩散生成模型在多模态表示方面表现出色，但在在线MARL中的应用尚未充分探索，主要障碍是其难以处理的似然性阻碍了基于熵的探索和协调。

Method: 提出了OMAD框架，采用扩散策略和放松策略目标最大化缩放联合熵，结合CTDE范式下的联合分布价值函数优化分散扩散策略。

Result: 在MPE和MAMuJoCo的10个多样化任务中，OMAD方法实现了样本效率2.5倍至5倍的显著提升，成为新的SOTA。

Conclusion: OMAD框架通过创新的放松策略目标和联合分布价值函数，在在线多智能体强化学习中实现了显著的性能提升，成为当前最先进的方法。

Abstract: Online Multi-Agent Reinforcement Learning (MARL) is a prominent framework for efficient agent coordination. Crucially, enhancing policy expressiveness is pivotal for achieving superior performance. Diffusion-based generative models are well-positioned to meet this demand, having demonstrated remarkable expressiveness and multimodal representation in image generation and offline settings. Yet, their potential in online MARL remains largely under-explored. A major obstacle is that the intractable likelihoods of diffusion models impede entropy-based exploration and coordination. To tackle this challenge, we propose among the first \underline{O}nline off-policy \underline{MA}RL framework using \underline{D}iffusion policies (\textbf{OMAD}) to orchestrate coordination. Our key innovation is a relaxed policy objective that maximizes scaled joint entropy, facilitating effective exploration without relying on tractable likelihood. Complementing this, within the centralized training with decentralized execution (CTDE) paradigm, we employ a joint distributional value function to optimize decentralized diffusion policies. It leverages tractable entropy-augmented targets to guide the simultaneous updates of diffusion policies, thereby ensuring stable coordination. Extensive evaluations on MPE and MAMuJoCo establish our method as the new state-of-the-art across $10$ diverse tasks, demonstrating a remarkable $2.5\times$ to $5\times$ improvement in sample efficiency.

</details>


<div id='cs.SE'></div>

# cs.SE [[Back]](#toc)

### [92] [Five Fatal Assumptions: Why T-Shirt Sizing Systematically Fails for AI Projects](https://arxiv.org/abs/2602.17734)
*Raja Soundaramourty,Ozkan Kilic,Ramu Chenchaiah*

Main category: cs.SE

TL;DR: 论文指出传统T-shirt sizing在AI项目中的局限性，并提出Checkpoint Sizing作为替代方案，强调基于开发过程中的实际学习进行迭代评估。


<details>
  <summary>Details</summary>
Motivation: 传统敏捷估算技术（如T-shirt sizing）在应用于AI项目（尤其是涉及大型语言模型和多智能体系统的项目）时，由于非线性性能跳跃、复杂交互表面和‘紧耦合’等问题，往往导致系统性误导。

Method: 通过分析五个传统软件开发中常用的T-shirt sizing假设在AI项目中的失效情况，结合多智能体系统失败、扩展原则和多轮对话的固有不可靠性等研究，提出了Checkpoint Sizing方法。

Result: 研究表明，传统的T-shirt sizing假设在AI开发中普遍失效，而Checkpoint Sizing方法提供了一种更人性化、迭代式的替代方案。

Conclusion: 论文提出了一种名为Checkpoint Sizing的新方法，以应对AI项目中传统T-shirt sizing技术的局限性，强调了在开发过程中基于实际学习而非初始假设进行范围与可行性重新评估的重要性。

Abstract: Agile estimation techniques, particularly T-shirt sizing, are widely used in software development for their simplicity and utility in scoping work. However, when we apply these methods to artificial intelligence initiatives -- especially those involving large language models (LLMs) and multi-agent systems -- the results can be systematically misleading. This paper shares an evidence-backed analysis of five foundational assumptions we often make during T-shirt sizing. While these assumptions usually hold true for traditional software, they tend to fail in AI contexts: (1) linear effort scaling, (2) repeatability from prior experience, (3) effort-duration fungibility, (4) task decomposability, and (5) deterministic completion criteria. Drawing on recent research into multi-agent system failures, scaling principles, and the inherent unreliability of multi-turn conversations, we show how AI development breaks these rules. We see this through non-linear performance jumps, complex interaction surfaces, and "tight coupling" where a small change in data cascades through the entire stack. To help teams navigate this, we propose Checkpoint Sizing: a more human-centric, iterative approach that uses explicit decision gates where scope and feasibility are reassessed based on what we learn during development, rather than what we assumed at the start. This paper is intended for engineering managers, technical leads, and product owners responsible for planning and delivering AI initiatives.

</details>


### [93] [Examining LLMs Ability to Summarize Code Through Mutation-Analysis](https://arxiv.org/abs/2602.17838)
*Lara Khatib,Micheal Pu,Bogdan Vasilescu,Meiyappan Nagappan*

Main category: cs.SE

TL;DR: 研究通过突变测试评估LLM代码摘要的准确性，发现模型易忽略实际行为细节，准确性随代码复杂性下降。GPT-5.2虽有提升，但仍需改进。


<details>
  <summary>Details</summary>
Motivation: 随着开发者日益依赖LLM生成的代码摘要进行文档、测试和审查，需研究这些摘要是否准确反映程序的实际行为。LLM常自信描述代码的意图，却忽略定义实际行为的边缘情况或逻辑变化。

Method: 提出了一种基于突变的评估方法：生成摘要后，向代码中注入针对性突变，检查LLM是否更新摘要以反映新行为。通过三个实验（共624次突变-摘要评估）验证，包括控制合成程序和人类编写程序的测试。

Result: 摘要准确性随复杂性从单函数的76.5%降至多线程系统的17.3%；在人类编写的LBPP数据集中，模型描述意图而非突变行为的准确率为49.3%。GPT-5.2表现优于GPT-4（85.3% vs. 49.3%），但仍难以区分实现细节。

Conclusion: 该研究通过突变分析方法系统地评估了LLM生成的代码摘要是否准确反映程序行为，而非仅表面文本模式。实验表明，随着代码复杂性增加，摘要准确性显著下降，且模型更倾向于描述算法意图而非实际行为。尽管GPT-5.2相比GPT-4有显著提升，但两者仍难以区分实现细节与标准算法模式。

Abstract: As developers increasingly rely on LLM-generated code summaries for documentation, testing, and review, it is important to study whether these summaries accurately reflect what the program actually does. LLMs often produce confident descriptions of what the code looks like it should do (intent), while missing subtle edge cases or logic changes that define what it actually does (behavior). We present a mutation-based evaluation methodology that directly tests whether a summary truly matches the code's logic. Our approach generates a summary, injects a targeted mutation into the code, and checks if the LLM updates its summary to reflect the new behavior. We validate it through three experiments totalling 624 mutation-summary evaluations across 62 programs. First, on 12 controlled synthetic programs with 324 mutations varying in type (statement, value, decision) and location (beginning, middle, end). We find that summary accuracy decreases sharply with complexity from 76.5% for single functions to 17.3% for multi-threaded systems, while mutation type and location exhibit weaker effects. Second, testing 150 mutated samples on 50 human-written programs from the Less Basic Python Problems (LBPP) dataset confirms the same failure patterns persist as models often describe algorithmic intent rather than actual mutated behavior with a summary accuracy rate of 49.3%. Furthermore, while a comparison between GPT-4 and GPT-5.2 shows a substantial performance leap (from 49.3% to 85.3%) and an improved ability to identify mutations as "bugs", both models continue to struggle with distinguishing implementation details from standard algorithmic patterns. This work establishes mutation analysis as a systematic approach for assessing whether LLM-generated summaries reflect program behavior rather than superficial textual patterns.

</details>


### [94] [Automated LLM-Based Accessibility Remediation: From Conventional Websites to Angular Single-Page Applications](https://arxiv.org/abs/2602.17887)
*Carla Fernández-Navarro,Francisco Chicano*

Main category: cs.SE

TL;DR: 利用LLMs自动化修复网页可访问性问题，测试显示高效修复率，并生成图像描述，推动可访问性成为开发常态。


<details>
  <summary>Details</summary>
Motivation: 解决现代单页应用（SPAs）动态特性导致传统静态分析方法不足的问题，以及手动修复可访问性问题的低效和高成本。

Method: 采用模块化工作流程，适用于静态网站和复杂的Angular项目，通过在静态网页的DOM或SPA的源代码中主动实施修正。

Result: 在12个静态网站和6个开源Angular项目上测试，修复了80%的公共网站问题和86%的Angular应用问题，同时为图像生成有意义的视觉描述。

Conclusion: 该研究提出了一种利用大型语言模型（LLMs）自动化修复网页可访问性问题的系统，成功将可访问性修复纳入日常开发流程，减少了技术债务。

Abstract: Web accessibility remains an unresolved issue for a large part of the web content. There are many tools to detect errors automatically, but fixing those issues is still mostly a manual, slow, and costly process in which it is easy for developers to overlook specific details. The situation becomes even more complex with modern Single-Page Applications (SPAs), whose dynamic nature makes traditional static analysis approaches inadequate. This work proposes a system that aims to address this challenge by using Large Language Models (LLMs) to automate accessibility fixes. The proposal presents a modular workflow applicable to both static websites and complex Angular projects. The framework actively implements corrections within the DOM of static web pages or the source code of SPAs. The system was tested on 12 static websites and 6 open-source Angular projects, fixing 80% of the accessibility issues on public websites and 86% of the issues on Angular applications. Our proposal also generates meaningful visual descriptions for images while preserving the application's design and stability. This work contributes to ensuring that accessibility stops being a technical debt deferred to the future and becomes a natural part of everyday development workflows.

</details>


### [95] [Mining Type Constructs Using Patterns in AI-Generated Code](https://arxiv.org/abs/2602.17955)
*Imgyeong Lee,Tayyib Ul Hassan,Abram Hindle*

Main category: cs.SE

TL;DR: 研究发现AI代理在TypeScript项目中比人类更频繁误用类型构造，但其PRs接受率更高，开发者需谨慎验证类型安全性。


<details>
  <summary>Details</summary>
Motivation: 探讨AI在类型相关编程任务中是否真正优于人类，以及AI代理在复杂类型系统中是否过度或误用类型构造。

Method: 在TypeScript项目领域进行首次实证分析，比较AI代理和人类在类型相关编程任务中的表现。

Result: AI代理比人类更倾向于使用'any'关键字（高出9倍），且更频繁使用忽略类型检查的高级类型构造。但令人惊讶的是，AI代理的拉取请求（PRs）接受率比人类高1.8倍。

Conclusion: 研究鼓励开发者在与AI代理协作时仔细确认代码库的类型安全性。

Abstract: Artificial Intelligence (AI) increasingly automates various parts of the software development tasks. Although AI has enhanced the productivity of development tasks, it remains unstudied whether AI essentially outperforms humans in type-related programming tasks, such as employing type constructs properly for type safety, during its tasks. Moreover, there is no systematic study that evaluates whether AI agents overuse or misuse the type constructs under the complicated type systems to the same extent as humans. In this study, we present the first empirical analysis to answer these questions in the domain of TypeScript projects. Our findings show that, in contrast to humans, AI agents are 9x more prone to use the 'any' keyword. In addition, we observed that AI agents use advanced type constructs, including those that ignore type checks, more often compared to humans. Surprisingly, even with all these issues, Agentic pull requests (PRs) have 1.8x higher acceptance rates compared to humans for TypeScript. We encourage software developers to carefully confirm the type safety of their codebases whenever they coordinate with AI agents in the development process.

</details>


### [96] [DeCEAT: Decoding Carbon Emissions for AI-driven Software Testing](https://arxiv.org/abs/2602.18012)
*Pragati Kumari,Novarun Deb*

Main category: cs.SE

TL;DR: 研究通过DeCEAT框架评估小型语言模型（SLMs）在测试生成中的环境与性能权衡，发现提示设计和模型选择共同影响结果。


<details>
  <summary>Details</summary>
Motivation: 现有可持续性分析主要关注大型语言模型，而小型语言模型（SLMs）在测试生成中的能源和碳特性尚未充分探索。

Method: 研究引入了DeCEAT框架，通过HumanEval基准和自适应提示变体（基于Anthropic模板），系统评估SLMs的环境与性能权衡。使用CodeCarbon测量能耗和碳排放，单元测试覆盖率评估生成测试的质量。

Result: 不同SLMs展现出独特的可持续性优势：一些优先考虑低能耗和快速执行，而其他在碳约束下保持更高稳定性或准确性。

Conclusion: 该研究强调了在自动化测试中使用小型语言模型（SLMs）时，提示设计和模型选择对环境和性能的多维影响。

Abstract: The increasing use of language models in automated software testing raises concerns about their environmental impact, yet existing sustainability analyses focus almost exclusively on large language models. As a result, the energy and carbon characteristics of small language models (SLMs) during test generation remain largely unexplored. To address this gap, this work introduces the DeCEAT framework, which systematically evaluates the environmental and performance trade-offs of SLMs using the HumanEval benchmark and adaptive prompt variants (based on the Anthropic template). The framework quantifies emission and time-aware behavior under controlled conditions, with CodeCarbon measuring energy consumption and carbon emissions, and unit test coverage assessing the quality of generated tests. Our results show that different SLMs exhibit distinct sustainability strengths: some prioritize lower energy use and faster execution, while others maintain higher stability or accuracy under carbon constraints. These findings demonstrate that sustainability in the generation of SLM-driven tests is multidimensional and strongly shaped by prompt design. This work provides a focused sustainability evaluation framework specifically tailored to automated SLM-based test generation, clarifying how prompt structure and model choice jointly influence environmental and performance outcomes.

</details>


### [97] [Toward Automated Virtual Electronic Control Unit (ECU) Twins for Shift-Left Automotive Software Testing](https://arxiv.org/abs/2602.18142)
*Sebastian Dingler,Frederik Boenke*

Main category: cs.SE

TL;DR: 研究通过虚拟测试环境早期复制ECU行为，验证了指令级精确模型在降低CPU行为风险上的有效性，为虚拟ECU双胞胎提供了可行路径。


<details>
  <summary>Details</summary>
Motivation: 汽车软件发展速度超过硬件可用性，导致后期集成和昂贵的硬件在环（HiL）瓶颈，需探索虚拟测试环境是否能早期复制ECU行为以运行真实软件二进制文件。

Method: 采用基于SystemC/TLM 2.0的代理反馈驱动工作流，通过GNU Debugger（GDB）连接参考模拟器，生成指令级精确的处理器模型。

Result: 结果表明，通过自动化差异测试和迭代模型校正，可以降低最关键的技术风险——CPU行为保真度。

Conclusion: 该原型展示了一条可行的虚拟ECU双胞胎"左移"路径，支持可重复测试、非侵入式追踪和符合安全标准的故障注入活动，尽管云规模部署和完整工具链集成仍需未来工作。

Abstract: Automotive software increasingly outpaces hardware availability, forcing late integration and expensive hardware-in-the-loop (HiL) bottlenecks. The InnoRegioChallenge project investigated whether a virtual test and integration environment can reproduce electronic control unit (ECU) behavior early enough to run real software binaries before physical hardware exists. We report a prototype that generates instruction-accurate processor models in SystemC/TLM~2.0 using an agentic, feedback-driven workflow coupled to a reference simulator via the GNU Debugger (GDB). The results indicate that the most critical technical risk -- CPU behavioral fidelity -- can be reduced through automated differential testing and iterative model correction. We summarize the architecture, the agentic modeling loop, and project outcomes, and we extrapolate plausible technical details consistent with the reported qualitative findings. While cloud-scale deployment and full toolchain integration remain future work, the prototype demonstrates a viable shift-left path for virtual ECU twins, enabling reproducible tests, non-intrusive tracing, and fault-injection campaigns aligned with safety standards.

</details>


### [98] [Role and Identity Work of Software Engineering Professionals in the Generative AI Era](https://arxiv.org/abs/2602.18190)
*Jorge Melegati*

Main category: cs.SE

TL;DR: 本文探讨了GenAI对软件工程中不同角色（如开发者和测试者）工作身份认同的影响，提出了研究议程并讨论了实践意义。


<details>
  <summary>Details</summary>
Motivation: 现有研究表明GenAI的采用触发了软件专业人员的工作身份认同变化，但未考虑不同角色间的差异。本文旨在填补这一空白。

Method: 通过回顾现有关于不同角色的研究及GenAI在软件工程中应用的最新研究，作者提出了一个研究议程，旨在更好地理解角色如何影响软件专业人员的工作身份认同。

Result: 提出了一个研究议程，以探索角色对软件专业人员身份认同的影响，并计划基于此提出支持GenAI采用的新工具。

Conclusion: 本文强调了在生成式AI（GenAI）应用于软件工程时，考虑不同角色（如开发者和测试者）对工作身份认同的影响的重要性，并提出了一个研究议程以深入探讨这一影响，同时讨论了潜在的实际应用意义。

Abstract: The adoption of Generative AI (GenAI) suggests major changes for software engineering, including technical aspects but also human aspects of the professionals involved. One of these aspects is how individuals perceive themselves regarding their work, i.e., their work identity, and the processes they perform to form, adapt and reject these identities, i.e., identity work. Existent studies provide evidence of such identity work of software professionals triggered by the adoption of GenAI, however they do not consider differences among diverse roles, such as developers and testers. In this paper, we argue the need for considering the role as a factor defining the identity work of software professionals. To support our claim, we review some studies regarding different roles and also recent studies on how to adopt GenAI in software engineering. Then, we propose a research agenda to better understand how the role influences identity work of software professionals triggered by the adoption of GenAI, and, based on that, to propose new artifacts to support this adoption. We also discuss the potential implications for practice of the results to be obtained.

</details>


### [99] [ReqElicitGym: An Evaluation Environment for Interview Competence in Conversational Requirements Elicitation](https://arxiv.org/abs/2602.18306)
*Dongming Jin,Zhi Jin,Zheng Fang,Linyu Li,XiaoTian Yang,Yuanpeng He,Xiaohong Chen*

Main category: cs.SE

TL;DR: 论文提出了 ReqElicitGym 评估环境，用于量化评估LLMs在对话式需求获取中的访谈能力，发现当前LLMs在挖掘隐式需求（尤其是风格相关需求）上仍有不足。


<details>
  <summary>Details</summary>
Motivation: 随着LLMs编码能力的提升，基于LLM的自动化软件开发瓶颈从生成正确代码转向获取用户需求，但LLMs在对话式需求获取中的访谈能力尚未被充分探索。

Method: 提出了 ReqElicitGym，一个交互式自动评估环境，包含新的评估数据集、交互式预言用户和任务评估器。

Result: 实验表明，当前LLMs在挖掘隐式需求方面表现有限，仅能获取不到一半的隐式需求，且有效提问多出现在对话后期。此外，LLMs在风格相关需求上表现较差。

Conclusion: ReqElicitGym 为评估对话式需求获取的访谈能力提供了一个可重复、定量的环境，并揭示了当前LLMs在挖掘隐式需求方面的局限性。

Abstract: With the rapid improvement of LLMs' coding capabilities, the bottleneck of LLM-based automated software development is shifting from generating correct code to eliciting users' requirements. Despite growing interest, the interview competence of LLMs in conversational requirements elicitation remains fully underexplored. Existing evaluations often depend on a few scenarios, real user interaction, and subjective human scoring, which hinders systematic and quantitative comparison. To address these challenges, we propose ReqElicitGym, an interactive and automatic evaluation environment for assessing interview competence in conversational requirements elicitation. Specifically, ReqElicitGym introduces a new evaluation dataset and designs both an interactive oracle user and a task evaluator. The dataset contains 101 website requirements elicitation scenarios spanning 10 application types. Both the oracle user and the task evaluator achieve high agreement with real users and expert judgment. Using our ReqElicitGym, any automated conversational requirements elicitation approach (e.g., LLM-based agents) can be evaluated in a reproducible and quantitative manner through interaction with the environment. Based on our ReqElicitGym, we conduct a systematic empirical study on seven representative LLMs, and the results show that current LLMs still exhibit limited interview competence in uncovering implicit requirements. Particularly, they elicit less than half of the users' implicit requirements, and their effective elicitation questions often emerge in later turns of the dialogue. Besides, we found LLMs can elicit interaction and content implicit requirements, but consistently struggle with style-related requirements. We believe ReqElicitGym will facilitate the evaluation and development of automated conversational requirements elicitation.

</details>


### [100] [VeriSoftBench: Repository-Scale Formal Verification Benchmarks for Lean](https://arxiv.org/abs/2602.18307)
*Yutong Xin,Qiaochu Chen,Greg Durrett,Işil Dillig*

Main category: cs.SE

TL;DR: VeriSoftBench是一个针对软件验证的Lean 4证明基准测试，评估显示现有LLM在复杂依赖环境中表现不足，需进一步优化。


<details>
  <summary>Details</summary>
Motivation: 现有的LLM定理证明基准主要集中在数学领域（如Mathlib），而软件验证中的证明通常依赖于项目特定的库和复杂的依赖关系，缺乏针对性的评估工具。

Method: 通过从开源形式化方法开发中提取500个Lean 4证明义务，并保留仓库上下文和跨文件依赖关系，构建VeriSoftBench基准测试。

Result: 评估发现：（1）针对Mathlib优化的证明器在此类仓库中心化环境中表现不佳；（2）成功与依赖闭包的复杂性负相关；（3）提供精选依赖上下文能提升性能，但仍需改进。

Conclusion: 论文提出了VeriSoftBench基准测试，用于评估LLM在软件验证中的定理证明能力，并揭示了现有方法在依赖复杂、项目特定库的环境中的局限性。

Abstract: Large language models have achieved striking results in interactive theorem proving, particularly in Lean. However, most benchmarks for LLM-based proof automation are drawn from mathematics in the Mathlib ecosystem, whereas proofs in software verification are developed inside definition-rich codebases with substantial project-specific libraries. We introduce VeriSoftBench, a benchmark of 500 Lean 4 proof obligations drawn from open-source formal-methods developments and packaged to preserve realistic repository context and cross-file dependencies. Our evaluation of frontier LLMs and specialized provers yields three observations. First, provers tuned for Mathlib-style mathematics transfer poorly to this repository-centric setting. Second, success is strongly correlated with transitive repository dependence: tasks whose proofs draw on large, multi-hop dependency closures are less likely to be solved. Third, providing curated context restricted to a proof's dependency closure improves performance relative to exposing the full repository, but nevertheless leaves substantial room for improvement. Our benchmark and evaluation suite are released at https://github.com/utopia-group/VeriSoftBench.

</details>


### [101] [Statistical Confidence in Functional Correctness: An Approach for AI Product Functional Correctness Evaluation](https://arxiv.org/abs/2602.18357)
*Wallace Albertini,Marina Condé Araújo,Júlia Condé Araújo,Antonio Pedro Santos Alves,Marcos Kalinowski*

Main category: cs.SE

TL;DR: 本文提出SCFC方法，通过统计置信度评估AI系统功能正确性，填补了现有标准在实用方法上的空白。


<details>
  <summary>Details</summary>
Motivation: 由于AI系统的概率性本质，其质量评估是一个基本挑战。现有标准如ISO/IEC 25059缺乏实用且统计稳健的功能正确性评估方法。

Method: 该方法包括四个步骤：定义定量规格限制、进行分层和概率抽样、应用自举法估计性能指标的置信区间、计算能力指数作为最终指标。

Result: 通过对两个真实工业AI系统的案例研究及专家访谈，收集了关于方法实用性、易用性和实际应用意向的宝贵见解。

Conclusion: 本文提出的SCFC方法是一种可行且有价值的方式，将功能正确性评估从点估计转变为统计置信度陈述。

Abstract: The quality assessment of Artificial Intelligence (AI) systems is a fundamental challenge due to their inherently probabilistic nature. Standards such as ISO/IEC 25059 provide a quality model, but they lack practical and statistically robust methods for assessing functional correctness. This paper proposes and evaluates the Statistical Confidence in Functional Correctness (SCFC) approach, which seeks to fill this gap by connecting business requirements to a measure of statistical confidence that considers both the model's average performance and its variability. The approach consists of four steps: defining quantitative specification limits, performing stratified and probabilistic sampling, applying bootstrapping to estimate a confidence interval for the performance metric, and calculating a capability index as a final indicator. The approach was evaluated through a case study on two real-world AI systems in industry involving interviews with AI experts. Valuable insights were collected from the experts regarding the utility, ease of use, and intention to adopt the methodology in practical scenarios. We conclude that the proposed approach is a feasible and valuable way to operationalize the assessment of functional correctness, moving the evaluation from a point estimate to a statement of statistical confidence.

</details>


<div id='cs.NI'></div>

# cs.NI [[Back]](#toc)

### [102] [Graph-Neural Multi-Agent Coordination for Distributed Access-Point Selection in Cell-Free Massive MIMO](https://arxiv.org/abs/2602.17954)
*Mohammad Zangooei,Lou Salaün,Chung Shue Chen,Raouf Boutaba*

Main category: cs.NI

TL;DR: APS-GNN是一种分布式多智能体学习框架，通过GNN和约束强化学习解决CFmMIMO中的APS问题，显著降低AP激活和延迟。


<details>
  <summary>Details</summary>
Motivation: 解决CFmMIMO系统中APS问题的可扩展性和可靠性需求，满足UE的SE要求同时最小化网络功耗。

Method: APS-GNN采用了一种约束强化学习方法，结合局部观察交换和参数共享的GNN架构，通过监督模仿学习初始化策略。

Result: APS-GNN在满足目标SE的同时，比启发式和集中式MARL基线减少了50-70%的AP激活数量，并实现了一到两个数量级的更低推理延迟。

Conclusion: APS-GNN被证明是一种实用且可扩展的解决方案，适用于大规模CFmMIMO网络中的APS问题，显著降低了AP激活数量和推理延迟。

Abstract: Cell-free massive MIMO (CFmMIMO) systems require scalable and reliable distributed coordination mechanisms to operate under stringent communication and latency constraints. A central challenge is the Access Point Selection (APS) problem, which seeks to determine the subset of serving Access Points (APs) for each User Equipment (UE) that can satisfy UEs' Spectral Efficiency (SE) requirements while minimizing network power consumption. We introduce APS-GNN, a scalable distributed multi-agent learning framework that decomposes APS into agents operating at the granularity of individual AP-UE connections. Agents coordinate via local observation exchange over a novel Graph Neural Network (GNN) architecture and share parameters to reuse their knowledge and experience. APS-GNN adopts a constrained reinforcement learning approach to provide agents with explicit observability of APS' conflicting objectives, treating SE satisfaction as a cost and power reduction as a reward. Both signals are defined locally, facilitating effective credit assignment and scalable coordination in large networks. To further improve training stability and exploration efficiency, the policy is initialized via supervised imitation learning from a heuristic APS baseline. We develop a realistic CFmMIMO simulator and demonstrate that APS-GNN delivers the target SE while activating 50-70% fewer APs than heuristic and centralized Multi-agent Reinforcement Learning (MARL) baselines in different evaluation scenarios. Moreover, APS-GNN achieves one to two orders of magnitude lower inference latency than centralized MARL approaches due to its fully parallel and distributed execution. These results establish APS-GNN as a practical and scalable solution for APS in large-scale CFmMIMO networks.

</details>


### [103] [Rethinking Beam Management: Generalization Limits Under Hardware Heterogeneity](https://arxiv.org/abs/2602.18151)
*Nikita Zeulin,Olga Galinina,Ibrahim Kilinc,Sergey Andreev,Robert W. Heath*

Main category: cs.NI

TL;DR: 本文探讨了5G及以后技术中硬件异构性对ML辅助波束管理的挑战，分析了关键故障模式，并提出了改进策略。


<details>
  <summary>Details</summary>
Motivation: 5G及以后技术中，用户设备的硬件异构性对基于波束的通信提出了新挑战，限制了基于机器学习的算法的适用性。

Method: 通过分析异构性存在时的关键故障模式，并展示其性能影响的案例研究。

Result: 研究发现硬件异构性对波束管理性能有显著影响，并提出了改进泛化能力的方法。

Conclusion: 本文强调了在ML辅助的波束管理中，将硬件异构性作为首要设计考虑的重要性，并探讨了提高波束管理泛化能力的潜在策略。

Abstract: Hardware heterogeneity across diverse user devices poses new challenges for beam-based communication in 5G and beyond. This heterogeneity limits the applicability of machine learning (ML)-based algorithms. This article highlights the critical need to treat hardware heterogeneity as a first-class design concern in ML-aided beam management. We analyze key failure modes in the presence of heterogeneity and present case studies demonstrating their performance impact. Finally, we discuss potential strategies to improve generalization in beam management.

</details>


### [104] [Noise Mitigation Methods for Digital Visible Light Communication](https://arxiv.org/abs/2602.18187)
*Wataru Uemura,Takumi Hamano*

Main category: cs.NI

TL;DR: 论文提出两种DVLC系统降噪方法：周期性干扰消除和ANC启发的实时噪声衰减，实验证明ANC方案性能更优。


<details>
  <summary>Details</summary>
Motivation: 可见光通信（VLC）因其低功耗、长寿命和快速响应而受到关注，但环境光源（如荧光灯）产生的光学噪声会导致波形失真和误码率（BER）增加，亟需有效降噪方法。

Method: 第一种方法利用交流电源照明干扰的周期性，通过从接收信号中减去采样噪声波形来减少干扰；第二种方法受主动噪声控制（ANC）技术启发，引入额外的光电二极管进行噪声接收，并采用减法电路实时衰减噪声。

Result: 实验结果表明，与传统接收器相比，两种方法均提升了BER性能，ANC启发的方案在所有测试条件下表现最佳。

Conclusion: 两种降噪方法均能有效改善DVLC系统的误码率性能，其中受ANC启发的方案在所有测试条件下表现更优。

Abstract: Visible Light Communication (VLC) using Light Emitting Diodes (LEDs) has gained attention due to its low power consumption, long lifetime, and fast response. However, VLC suffers from optical noise generated by ambient light sources such as fluorescent lamps, which leads to waveform distortion and increased bit error rates (BER). In this paper, we propose two noise reduction methods for Digital Visible Light Communication (DVLC) systems. The first method exploits the periodic nature of interference caused by AC-powered-line illumination and reduces interference by subtracting sampled noise waveforms from the received signal. Second, inspired by Active Noise Control (ANC) techniques, an additional photodiode is introduced for noise reception, and subtraction circuits are employed to attenuate noise in real time. Experimental results show that both methods improve BER performance compared with conventional receivers, with the ANC-inspired approach achieving superior performance under all tested conditions.

</details>


### [105] [A traffic incident management framework for vehicular ad hoc networks](https://arxiv.org/abs/2602.18208)
*Rezvi Shahariar,Chris Phillips*

Main category: cs.NI

TL;DR: 本文提出了一种交通事件管理模型，通过仿真验证四跳中继在通知车辆数量上优于六十秒中继。


<details>
  <summary>Details</summary>
Motivation: 现有模型缺乏对交通事件的全面管理能力，本文旨在填补这一空白。

Method: 使用VEINS模拟器进行仿真，考虑了车辆密度和中继策略（四跳中继和六十秒中继）的影响。

Result: 仿真结果表明，四跳中继比六十秒中继能通知更多车辆。

Conclusion: 本文提出的交通事件管理模型能有效管理多种交通事件，并通过仿真验证了其性能。

Abstract: Vehicular Ad Hoc Networks (VANETs) support the information dissemination among vehicles, Roadside Units (RSUs), and a Trust Authority (TA). A trust model evaluates an entity or data or both to determine truthfulness. A security model confirms authentication, integrity, availability, non repudiation issues. With these aspects in mind, many models have been proposed in literature. Furthermore, many information dissemination approaches are proposed. However, the lack of a model that can manage traffic incidents completely inspires this work. This paper details how and when a message needs to be generated and relayed so that the incidents can be reported and managed in a timely manner. This paper addresses this challenge by providing a traffic incident management model to manage several traffic incidents efficiently. Additionally, we simulate this model using the VEINS simulator with vehicles, RSUs, and a TA. From the experiments, we measure the average number of transmissions required for reporting a single traffic incident while varying the vehicle density and relaying considerations. We consider two types of relaying. In one series of experiments, messages from regular vehicles and RSUs are relayed up to four hops. In another series of experiments, messages from the regular vehicles and RSUs are relayed until their generation time reaches sixty seconds. Additionally, messages from the official vehicles are relayed when they approach an incident or when the incident is cleared. Results from the simulations show that more vehicles are informed with four-hop relaying than sixty-second relaying in both cases.

</details>


<div id='cs.GR'></div>

# cs.GR [[Back]](#toc)

### [106] [DesignAsCode: Bridging Structural Editability and Visual Fidelity in Graphic Design Generation](https://arxiv.org/abs/2602.17690)
*Ziyuan Liu,Shizhao Sun,Danqing Huang,Yingdong Shi,Meisheng Zhang,Ji Li,Jingsong Yu,Jiang Bian*

Main category: cs.GR

TL;DR: DesignAsCode是一个将图形设计作为HTML/CSS程序化合成任务的新框架，通过语义规划和视觉感知反射机制解决了现有方法的局限性，显著提升了设计质量和功能性。


<details>
  <summary>Details</summary>
Motivation: 解决现有方法在非可编辑光栅图像合成和抽象布局生成之间的差距，以及由于表达力不足和开环性质导致的刚性组合模式和不协调视觉问题。

Method: 引入Plan-Implement-Reflect管道，包括构建动态、可变深度元素层次的语义规划器，以及通过视觉感知反射机制迭代优化代码以纠正渲染伪影。

Result: DesignAsCode在结构有效性和美学质量上显著优于现有基线方法。

Conclusion: DesignAsCode框架通过将图形设计重新构想为使用HTML/CSS的程序化合成任务，显著提升了结构有效性和美学质量，并解锁了自动布局重定向、复杂文档生成和基于CSS的动画等高级功能。

Abstract: Graphic design generation demands a delicate balance between high visual fidelity and fine-grained structural editability. However, existing approaches typically bifurcate into either non-editable raster image synthesis or abstract layout generation devoid of visual content. Recent combinations of these two approaches attempt to bridge this gap but often suffer from rigid composition schemas and unresolvable visual dissonances (e.g., text-background conflicts) due to their inexpressive representation and open-loop nature. To address these challenges, we propose DesignAsCode, a novel framework that reimagines graphic design as a programmatic synthesis task using HTML/CSS. Specifically, we introduce a Plan-Implement-Reflect pipeline, incorporating a Semantic Planner to construct dynamic, variable-depth element hierarchies and a Visual-Aware Reflection mechanism that iteratively optimizes the code to rectify rendering artifacts. Extensive experiments demonstrate that DesignAsCode significantly outperforms state-of-the-art baselines in both structural validity and aesthetic quality. Furthermore, our code-native representation unlocks advanced capabilities, including automatic layout retargeting, complex document generation (e.g., resumes), and CSS-based animation.

</details>


### [107] [Robo-Saber: Generating and Simulating Virtual Reality Players](https://arxiv.org/abs/2602.18319)
*Nam Hee Kim,Jingjing May Liu,Jaakko Lehtinen,Perttu Hämäläinen,James F. O'Brien,Xue Bin Peng*

Main category: cs.GR

TL;DR: 首个VR游戏测试运动生成系统Robo-Saber，通过风格示例生成多样化玩家行为，应用于Beat Saber游戏，展现合成游戏数据的潜力。


<details>
  <summary>Details</summary>
Motivation: 提出首个用于虚拟现实（VR）游戏测试的运动生成系统，以生成多样化的玩家行为并模拟不同技能水平。

Method: 我们的玩家模型从游戏内物体排列生成VR头显和手持控制器运动，受风格示例指导，并与模拟游戏得分最大化对齐。我们在大型BOXRR-23数据集上训练，并将框架应用于流行的VR游戏Beat Saber。

Result: 生成的模型Robo-Saber能够产生熟练的游戏玩法，并捕捉多样化的玩家行为，反映了输入风格示例指定的技能水平和运动模式。

Conclusion: Robo-Saber展示了在合成丰富游戏数据用于预测应用和实现基于物理的全身VR游戏测试代理方面的潜力。

Abstract: We present the first motion generation system for playtesting virtual reality (VR) games. Our player model generates VR headset and handheld controller movements from in-game object arrangements, guided by style exemplars and aligned to maximize simulated gameplay score. We train on the large BOXRR-23 dataset and apply our framework on the popular VR game Beat Saber. The resulting model Robo-Saber produces skilled gameplay and captures diverse player behaviors, mirroring the skill levels and movement patterns specified by input style exemplars. Robo-Saber demonstrates promise in synthesizing rich gameplay data for predictive applications and enabling a physics-based whole-body VR playtesting agent.

</details>
